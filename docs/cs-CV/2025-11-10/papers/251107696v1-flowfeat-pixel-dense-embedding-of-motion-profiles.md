---
layout: default
title: FlowFeat: Pixel-Dense Embedding of Motion Profiles
---

# FlowFeat: Pixel-Dense Embedding of Motion Profiles

**arXiv**: [2511.07696v1](https://arxiv.org/abs/2511.07696) | [PDF](https://arxiv.org/pdf/2511.07696.pdf)

**ä½œè€…**: Nikita Araslanov, Anna Sonnweber, Daniel Cremers

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-10

**å¤‡æ³¨**: Project website: https://tum-vision.github.io/flowfeat

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFlowFeatï¼Œé€šè¿‡è¿åŠ¨è½®å»“åµŒå…¥å®žçŽ°åƒç´ çº§å¯†é›†å›¾åƒè¡¨å¾ï¼Œæå‡å¤šç§è§†è§‰ä»»åŠ¡æ€§èƒ½ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å¯†é›†é¢„æµ‹` `å›¾åƒè¡¨å¾` `è¿åŠ¨è½®å»“` `è‡ªç›‘ç£å­¦ä¹ ` `å…‰æµä¼°è®¡` `è§†é¢‘åˆ†å‰²` `æ·±åº¦ä¼°è®¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰Transformerç­‰ç½‘ç»œäº§ç”Ÿä½Žåˆ†è¾¨çŽ‡ç‰¹å¾å›¾ï¼Œä¸é€‚ç”¨äºŽå¯†é›†é¢„æµ‹ä»»åŠ¡ï¼Œé™åˆ¶äº†è®¡ç®—æœºè§†è§‰åº”ç”¨ã€‚
2. FlowFeaté€šè¿‡è’¸é¦æŠ€æœ¯åµŒå…¥è¿åŠ¨è½®å»“åˆ†å¸ƒï¼Œåˆ©ç”¨å…‰æµç½‘ç»œå’Œè§†é¢‘æ•°æ®è¿›è¡Œè‡ªç›‘ç£è®­ç»ƒï¼Œç»Ÿè®¡è¿‘ä¼¼ apparent motionã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒFlowFeatæ˜¾è‘—æå‡äº†å¤šç§ç¼–ç å™¨åœ¨è§†é¢‘åˆ†å‰²ã€æ·±åº¦ä¼°è®¡å’Œè¯­ä¹‰åˆ†å‰²ç­‰ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œä¸”è®¡ç®—æˆæœ¬ä½Žã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜åˆ†è¾¨çŽ‡ã€å¤šä»»åŠ¡çš„ç‰¹å¾è¡¨ç¤ºæ–¹æ³•FlowFeatã€‚FlowFeatçš„æ ¸å¿ƒæ˜¯ä¸€ç§æ–°é¢–çš„è’¸é¦æŠ€æœ¯ï¼Œå®ƒåµŒå…¥äº† plausible çš„ apparent motions åˆ†å¸ƒï¼Œå³è¿åŠ¨è½®å»“ã€‚é€šè¿‡åˆ©ç”¨å…‰æµç½‘ç»œå’Œå¤šæ ·åŒ–çš„è§†é¢‘æ•°æ®ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªæœ‰æ•ˆçš„è‡ªç›‘ç£è®­ç»ƒæ¡†æž¶ï¼Œè¯¥æ¡†æž¶å¯ä»¥ç»Ÿè®¡è¿‘ä¼¼ apparent motionã€‚å‡­å€Ÿå…¶å“è¶Šçš„ç©ºé—´ç»†èŠ‚æ°´å¹³ï¼ŒFlowFeat ç¼–ç äº†å¼•äººæ³¨ç›®çš„å‡ ä½•å’Œè¯­ä¹‰çº¿ç´¢ï¼ŒåŒæ—¶è¡¨çŽ°å‡ºé«˜åº¦çš„æ—¶é—´ä¸€è‡´æ€§ã€‚å®žéªŒè¡¨æ˜Žï¼ŒFlowFeat æ˜¾è‘—å¢žå¼ºäº†äº”ç§æœ€å…ˆè¿›ç¼–ç å™¨å’Œæ›¿ä»£ä¸Šé‡‡æ ·ç­–ç•¥åœ¨ä¸‰ä¸ªå¯†é›†ä»»åŠ¡ï¼ˆè§†é¢‘å¯¹è±¡åˆ†å‰²ã€å•ç›®æ·±åº¦ä¼°è®¡å’Œè¯­ä¹‰åˆ†å‰²ï¼‰ä¸­çš„è¡¨å¾èƒ½åŠ›ã€‚è®­ç»ƒ FlowFeat çš„è®¡ç®—æˆæœ¬ä½Žå»‰ï¼Œå¹¶ä¸”å¯¹ä¸å‡†ç¡®çš„å…‰æµä¼°è®¡å…·æœ‰é²æ£’æ€§ï¼Œå³ä½¿åœ¨ä½¿ç”¨æ— ç›‘ç£å…‰æµç½‘ç»œæ—¶ä»ç„¶éžå¸¸æœ‰æ•ˆã€‚æˆ‘ä»¬çš„å·¥ä½œæœç€å¯é ä¸”é€šç”¨çš„å¯†é›†å›¾åƒè¡¨ç¤ºè¿ˆå‡ºäº†ä¸€æ­¥ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰åŸºäºŽTransformerçš„å›¾åƒè¡¨å¾æ–¹æ³•é€šå¸¸ç”Ÿæˆä½Žåˆ†è¾¨çŽ‡çš„ç‰¹å¾å›¾ï¼Œè¿™å¯¹äºŽéœ€è¦åƒç´ çº§åˆ«ç²¾ç»†ä¿¡æ¯çš„å¯†é›†é¢„æµ‹ä»»åŠ¡ï¼ˆå¦‚è¯­ä¹‰åˆ†å‰²ã€æ·±åº¦ä¼°è®¡ç­‰ï¼‰æ¥è¯´æ˜¯ä¸å¤Ÿçš„ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥æ•æ‰å›¾åƒä¸­çš„ç»†èŠ‚ä¿¡æ¯å’Œç²¾ç¡®çš„å‡ ä½•ç»“æž„ï¼Œä»Žè€Œé™åˆ¶äº†å…¶åœ¨è¿™äº›ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFlowFeatçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å­¦ä¹ å’ŒåµŒå…¥å›¾åƒä¸­åƒç´ çº§åˆ«çš„è¿åŠ¨ä¿¡æ¯ï¼ˆå³è¿åŠ¨è½®å»“ï¼‰ï¼Œæ¥å¢žå¼ºå›¾åƒè¡¨å¾çš„ä¸°å¯Œæ€§å’Œç©ºé—´ç»†èŠ‚ã€‚é€šè¿‡å°†è¿åŠ¨ä¿¡æ¯ä½œä¸ºä¸€ç§é¢å¤–çš„ç‰¹å¾åµŒå…¥åˆ°å›¾åƒè¡¨å¾ä¸­ï¼ŒFlowFeatèƒ½å¤Ÿæä¾›æ›´ç²¾ç¡®çš„å‡ ä½•å’Œè¯­ä¹‰çº¿ç´¢ï¼Œä»Žè€Œæå‡å¯†é›†é¢„æµ‹ä»»åŠ¡çš„æ€§èƒ½ã€‚è¿™ç§æ–¹æ³•å€Ÿé‰´äº†å…‰æµä¼°è®¡çš„æ€æƒ³ï¼Œä½†ä¸æ˜¯ç›´æŽ¥ä½¿ç”¨å…‰æµï¼Œè€Œæ˜¯å­¦ä¹ ä¸€ä¸ªè¿åŠ¨åˆ†å¸ƒã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šFlowFeatçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) ä½¿ç”¨å…‰æµç½‘ç»œä¼°è®¡è§†é¢‘å¸§ä¹‹é—´çš„å…‰æµï¼›2) åŸºäºŽä¼°è®¡çš„å…‰æµï¼Œæž„å»ºè¿åŠ¨è½®å»“çš„åˆ†å¸ƒï¼›3) ä½¿ç”¨è’¸é¦æŠ€æœ¯å°†è¿åŠ¨è½®å»“çš„åˆ†å¸ƒåµŒå…¥åˆ°å›¾åƒç‰¹å¾ä¸­ï¼Œç”ŸæˆFlowFeatç‰¹å¾ï¼›4) å°†FlowFeatç‰¹å¾ä¸ŽçŽ°æœ‰çš„å›¾åƒç¼–ç å™¨ï¼ˆå¦‚Transformerï¼‰çš„è¾“å‡ºè¿›è¡Œèžåˆï¼Œå¾—åˆ°å¢žå¼ºçš„å›¾åƒè¡¨å¾ï¼›5) ä½¿ç”¨å¢žå¼ºçš„å›¾åƒè¡¨å¾è¿›è¡Œä¸‹æ¸¸çš„å¯†é›†é¢„æµ‹ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šFlowFeatçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶è¿åŠ¨è½®å»“åµŒå…¥çš„è’¸é¦æŠ€æœ¯ã€‚ä¸Žç›´æŽ¥ä½¿ç”¨å…‰æµä½œä¸ºç‰¹å¾ä¸åŒï¼ŒFlowFeatå­¦ä¹ ä¸€ä¸ªè¿åŠ¨åˆ†å¸ƒï¼Œè¿™ä½¿å¾—å®ƒå¯¹å…‰æµä¼°è®¡çš„è¯¯å·®æ›´åŠ é²æ£’ã€‚æ­¤å¤–ï¼ŒFlowFeaté‡‡ç”¨è‡ªç›‘ç£çš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€äººå·¥æ ‡æ³¨çš„è¿åŠ¨æ•°æ®ï¼Œé™ä½Žäº†è®­ç»ƒæˆæœ¬ã€‚é€šè¿‡å°†è¿åŠ¨ä¿¡æ¯åµŒå…¥åˆ°å›¾åƒç‰¹å¾ä¸­ï¼ŒFlowFeatèƒ½å¤Ÿæä¾›æ›´ä¸°å¯Œçš„å‡ ä½•å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œä»Žè€Œæå‡å¯†é›†é¢„æµ‹ä»»åŠ¡çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šFlowFeatä½¿ç”¨å…‰æµç½‘ç»œï¼ˆå¯ä»¥æ˜¯ç›‘ç£æˆ–æ— ç›‘ç£çš„ï¼‰æ¥ä¼°è®¡è§†é¢‘å¸§ä¹‹é—´çš„å…‰æµã€‚è¿åŠ¨è½®å»“çš„åˆ†å¸ƒå¯ä»¥é€šè¿‡å¯¹å…‰æµè¿›è¡Œç»Ÿè®¡åˆ†æžå¾—åˆ°ã€‚è’¸é¦è¿‡ç¨‹ä½¿ç”¨ä¸€ä¸ªå°çš„ç¥žç»ç½‘ç»œæ¥å­¦ä¹ å¦‚ä½•å°†è¿åŠ¨è½®å»“åµŒå…¥åˆ°å›¾åƒç‰¹å¾ä¸­ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬ä¸€ä¸ªé‡æž„æŸå¤±å’Œä¸€ä¸ªå¯¹æ¯”æŸå¤±ï¼Œç”¨äºŽä¿è¯åµŒå…¥çš„è¿åŠ¨ä¿¡æ¯èƒ½å¤Ÿå‡†ç¡®åœ°é‡æž„å…‰æµï¼Œå¹¶ä¸”èƒ½å¤ŸåŒºåˆ†ä¸åŒçš„è¿åŠ¨æ¨¡å¼ã€‚å…·ä½“å‚æ•°è®¾ç½®å–å†³äºŽæ‰€ä½¿ç”¨çš„å…‰æµç½‘ç»œå’Œå›¾åƒç¼–ç å™¨ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒFlowFeatèƒ½å¤Ÿæ˜¾è‘—æå‡çŽ°æœ‰å›¾åƒç¼–ç å™¨åœ¨è§†é¢‘å¯¹è±¡åˆ†å‰²ã€å•ç›®æ·±åº¦ä¼°è®¡å’Œè¯­ä¹‰åˆ†å‰²ç­‰ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨è§†é¢‘å¯¹è±¡åˆ†å‰²ä»»åŠ¡ä¸­ï¼ŒFlowFeatèƒ½å¤Ÿå°†æ€§èƒ½æå‡5%ä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒFlowFeatå¯¹å…‰æµä¼°è®¡çš„è¯¯å·®å…·æœ‰é²æ£’æ€§ï¼Œå³ä½¿ä½¿ç”¨æ— ç›‘ç£å…‰æµç½‘ç»œä¹Ÿèƒ½å–å¾—è‰¯å¥½çš„æ•ˆæžœã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒFlowFeatæ˜¯ä¸€ç§æœ‰æ•ˆä¸”é€šç”¨çš„å›¾åƒè¡¨å¾æ–¹æ³•ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

FlowFeatåœ¨è§†é¢‘å¯¹è±¡åˆ†å‰²ã€å•ç›®æ·±åº¦ä¼°è®¡å’Œè¯­ä¹‰åˆ†å‰²ç­‰å¯†é›†é¢„æµ‹ä»»åŠ¡ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºŽè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€è§†é¢‘ç›‘æŽ§ç­‰é¢†åŸŸï¼Œæé«˜è¿™äº›åº”ç”¨å¯¹çŽ¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›å’Œç†è§£èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒFlowFeatçš„è‡ªç›‘ç£è®­ç»ƒæ–¹å¼ä½¿å…¶æ˜“äºŽæ‰©å±•åˆ°æ–°çš„æ•°æ®é›†å’Œä»»åŠ¡ä¸­ï¼Œå…·æœ‰å¾ˆé«˜çš„å®žé™…åº”ç”¨ä»·å€¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Dense and versatile image representations underpin the success of virtually all computer vision applications. However, state-of-the-art networks, such as transformers, produce low-resolution feature grids, which are suboptimal for dense prediction tasks. To address this limitation, we present FlowFeat, a high-resolution and multi-task feature representation. The key ingredient behind FlowFeat is a novel distillation technique that embeds a distribution of plausible apparent motions, or motion profiles. By leveraging optical flow networks and diverse video data, we develop an effective self-supervised training framework that statistically approximates the apparent motion. With its remarkable level of spatial detail, FlowFeat encodes a compelling degree of geometric and semantic cues while exhibiting high temporal consistency. Empirically, FlowFeat significantly enhances the representational power of five state-of-the-art encoders and alternative upsampling strategies across three dense tasks: video object segmentation, monocular depth estimation and semantic segmentation. Training FlowFeat is computationally inexpensive and robust to inaccurate flow estimation, remaining highly effective even when using unsupervised flow networks. Our work takes a step forward towards reliable and versatile dense image representations.

