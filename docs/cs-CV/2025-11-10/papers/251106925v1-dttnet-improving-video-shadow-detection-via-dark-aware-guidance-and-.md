---
layout: default
title: DTTNet: Improving Video Shadow Detection via Dark-Aware Guidance and Tokenized Temporal Modeling
---

# DTTNet: Improving Video Shadow Detection via Dark-Aware Guidance and Tokenized Temporal Modeling

**arXiv**: [2511.06925v1](https://arxiv.org/abs/2511.06925) | [PDF](https://arxiv.org/pdf/2511.06925.pdf)

**ä½œè€…**: Zhicheng Li, Kunyang Sun, Rui Yao, Hancheng Zhu, Fuyuan Hu, Jiaqi Zhao, Zhiwen Shao, Yong Zhou

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDTTNetï¼Œé€šè¿‡æš—æ„ŸçŸ¥å¼•å¯¼å’Œä»¤ç‰ŒåŒ–æ—¶åºå»ºæ¨¡æ”¹è¿›è§†é¢‘é˜´å½±æ£€æµ‹**

**å…³é”®è¯**: `è§†é¢‘é˜´å½±æ£€æµ‹` `è§†è§‰-è¯­è¨€åŒ¹é…` `æš—æ„ŸçŸ¥è¯­ä¹‰` `ä»¤ç‰ŒåŒ–æ—¶åºå»ºæ¨¡` `å®žæ—¶æŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†é¢‘é˜´å½±æ£€æµ‹é¢ä¸´é˜´å½±-èƒŒæ™¯æ¨¡ç³Šå’ŒåŠ¨æ€é˜´å½±å˜å½¢æŒ‘æˆ˜
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨è§†è§‰-è¯­è¨€åŒ¹é…æ¨¡å—å’Œæš—æ„ŸçŸ¥è¯­ä¹‰å—åŒºåˆ†é˜´å½±ï¼Œä»¤ç‰ŒåŒ–æ—¶åºå—é«˜æ•ˆå»ºæ¨¡æ—¶åº
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®žçŽ°æœ€å…ˆè¿›ç²¾åº¦å’Œå®žæ—¶æŽ¨ç†æ•ˆçŽ‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video shadow detection confronts two entwined difficulties: distinguishing
> shadows from complex backgrounds and modeling dynamic shadow deformations under
> varying illumination. To address shadow-background ambiguity, we leverage
> linguistic priors through the proposed Vision-language Match Module (VMM) and a
> Dark-aware Semantic Block (DSB), extracting text-guided features to explicitly
> differentiate shadows from dark objects. Furthermore, we introduce adaptive
> mask reweighting to downweight penumbra regions during training and apply edge
> masks at the final decoder stage for better supervision. For temporal modeling
> of variable shadow shapes, we propose a Tokenized Temporal Block (TTB) that
> decouples spatiotemporal learning. TTB summarizes cross-frame shadow semantics
> into learnable temporal tokens, enabling efficient sequence encoding with
> minimal computation overhead. Comprehensive Experiments on multiple benchmark
> datasets demonstrate state-of-the-art accuracy and real-time inference
> efficiency. Codes are available at https://github.com/city-cheng/DTTNet.

