---
layout: default
title: LeCoT: revisiting network architecture for two-view correspondence pruning
---

# LeCoT: revisiting network architecture for two-view correspondence pruning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.07078" target="_blank" class="toolbar-btn">arXiv: 2511.07078v1</a>
    <a href="https://arxiv.org/pdf/2511.07078.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.07078v1" 
            onclick="toggleFavorite(this, '2511.07078v1', 'LeCoT: revisiting network architecture for two-view correspondence pruning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Luanyuan Dai, Xiaoyu Du, Jinhui Tang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-10

**Â§áÊ≥®**: Just accepted at SCIENCE CHINA Information Sciences

**DOI**: [10.1007/s11432-024-4555-x](https://doi.org/10.1007/s11432-024-4555-x)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/Dailuanyuan2024/LeCoT-Revisiting-Network-Architecture-for-Two-View-Correspondence-Pruning)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**LeCoTÔºöÈÄöËøáÁ©∫Èó¥-ÈÄöÈÅìËûçÂêàTransformerÊîπËøõÂèåËßÜÂõæÂØπÂ∫îÂÖ≥Á≥ªÂâ™Êûù**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ÂØπÂ∫îÂÖ≥Á≥ªÂâ™Êûù` `ÂèåËßÜÂõæÂá†‰Ωï` `Transformer` `ÂÖ®Â±Ä‰∏ä‰∏ãÊñá` `ËßÜËßâÂÆö‰Ωç`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂèåËßÜÂõæÂØπÂ∫îÂÖ≥Á≥ªÂâ™ÊûùÊñπÊ≥ï‰æùËµñMLPÔºåÁº∫‰πèÊúâÊïàÂà©Áî®ÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰ø°ÊÅØÁöÑËÉΩÂäõ„ÄÇ
2. LeCoTÈÄöËøáÁ©∫Èó¥-ÈÄöÈÅìËûçÂêàTransformerÂùóÔºåÂú®‰∏çÂêåÈò∂ÊÆµËá™ÁÑ∂Âú∞Âà©Áî®ÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåLeCoTÂú®Â§ö‰∏™ËßÜËßâ‰ªªÂä°‰∏≠Ë∂ÖË∂ä‰∫ÜÁé∞ÊúâÊúÄ‰ºòÊñπÊ≥ïÔºå‰æãÂ¶ÇÁõ∏ÂØπÂßøÊÄÅ‰º∞ËÆ°„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂèåËßÜÂõæÂØπÂ∫îÂÖ≥Á≥ªÂâ™ÊûùÊó®Âú®‰ªéÂàùÂßãÂØπÂ∫îÂÖ≥Á≥ª‰∏≠ÂáÜÁ°ÆÁßªÈô§ÈîôËØØÂØπÂ∫îÂÖ≥Á≥ªÔºàÂ§ñÁÇπÔºâÔºåÂπ∂ÂπøÊ≥õÂ∫îÁî®‰∫éÂêÑÁßçËÆ°ÁÆóÊú∫ËßÜËßâ‰ªªÂä°„ÄÇÁõÆÂâçÊµÅË°åÁöÑÁ≠ñÁï•ÈááÁî®Â§öÂ±ÇÊÑüÁü•Êú∫ÔºàMLPÔºâ‰Ωú‰∏∫È™®Âπ≤ÁΩëÁªúÔºåÂπ∂ËæÖ‰ª•È¢ùÂ§ñÁöÑÊ®°ÂùóÊù•Â¢ûÂº∫ÁΩëÁªúÂ§ÑÁêÜ‰∏ä‰∏ãÊñá‰ø°ÊÅØÁöÑËÉΩÂäõÔºåËÄåËøôÊ≠£ÊòØMLPÁöÑÂ∑≤Áü•Â±ÄÈôêÊÄß„ÄÇ‰∏éÊ≠§Áõ∏ÂèçÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑËßÜËßíÔºåÊó†ÈúÄÈ¢ùÂ§ñÁöÑËÆæËÆ°Ê®°ÂùóÂç≥ÂèØÊçïËé∑ÂØπÂ∫îÂÖ≥Á≥ª‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Âêç‰∏∫LeCoTÁöÑÂèåËßÜÂõæÂØπÂ∫îÂÖ≥Á≥ªÂâ™ÊûùÁΩëÁªúÔºåËØ•ÁΩëÁªúÂèØ‰ª•Ëá™ÁÑ∂Âú∞Âà©Áî®‰∏çÂêåÈò∂ÊÆµÁöÑÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåLeCoTÁöÑÊ†∏ÂøÉËÆæËÆ°ÊòØÁ©∫Èó¥-ÈÄöÈÅìËûçÂêàTransformerÂùóÔºåËøôÊòØ‰∏ÄÁßçÊñ∞ÊèêÂá∫ÁöÑÁªÑ‰ª∂ÔºåÂèØÊúâÊïàÂà©Áî®Á®ÄÁñèÂØπÂ∫îÂÖ≥Á≥ª‰∏≠ÁöÑÁ©∫Èó¥ÂíåÈÄöÈÅìÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÈõÜÊàê‰∫ÜÊâÄÊèêÂá∫ÁöÑÈ¢ÑÊµãÂùóÔºåËØ•È¢ÑÊµãÂùóÂà©Áî®Êù•Ëá™‰∏≠Èó¥Èò∂ÊÆµÁöÑÂØπÂ∫îÂÖ≥Á≥ªÁâπÂæÅÊù•ÁîüÊàêÊ¶ÇÁéáÈõÜÔºåËØ•Ê¶ÇÁéáÈõÜÂÖÖÂΩìÂêéÁª≠Â≠¶‰π†Èò∂ÊÆµÁöÑÊåáÂØº‰ø°ÊÅØÔºå‰ªéËÄå‰ΩøÁΩëÁªúËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÊçïËé∑È≤ÅÊ£íÁöÑÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊ≠§È¢ÑÊµãÂùó‰ºöÈÄêÊ≠•ÁªÜÂåñÊ¶ÇÁéáÈõÜÔºå‰ªéËÄåÁºìËß£‰º†ÁªüÊñπÊ≥ï‰∏≠Â∏∏ËßÅÁöÑ‰ø°ÊÅØ‰∏¢Â§±ÈóÆÈ¢ò„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åËØÅÊòéÔºåÊâÄÊèêÂá∫ÁöÑLeCoTÂú®ÂØπÂ∫îÂÖ≥Á≥ªÂâ™Êûù„ÄÅÁõ∏ÂØπÂßøÊÄÅ‰º∞ËÆ°„ÄÅÂçïÂ∫îÊÄß‰º∞ËÆ°„ÄÅËßÜËßâÂÆö‰ΩçÂíå3DÈáçÂª∫‰ªªÂä°‰∏≠Âùá‰ºò‰∫éÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇ‰ª£Á†ÅÂ∑≤Âú®https://github.com/Dailuanyuan2024/LeCoT-Revisiting-Network-Architecture-for-Two-View-Correspondence-PruningÊèê‰æõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂèåËßÜÂõæÂØπÂ∫îÂÖ≥Á≥ªÂâ™ÊûùÊó®Âú®‰ªé‰∏§ÂπÖÂõæÂÉèÁöÑÂàùÂßãÂåπÈÖçÂÖ≥Á≥ª‰∏≠ÂéªÈô§ÈîôËØØÂåπÈÖçÔºàÂ§ñÁÇπÔºâÔºå‰ªéËÄåÊèêÈ´òÂêéÁª≠‰ªªÂä°ÁöÑÁ≤æÂ∫¶„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÁâπÂà´ÊòØÂü∫‰∫éMLPÁöÑÊñπÊ≥ïÔºåÈöæ‰ª•ÊúâÊïàÂú∞ÊçïÊçâÂíåÂà©Áî®ÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºåÂØºËá¥Ââ™ÊûùÊïàÊûú‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöLeCoTÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáËÆæËÆ°‰∏ÄÁßçÊñ∞ÁöÑÁΩëÁªúÊû∂ÊûÑÔºå‰ΩøÂÖ∂ËÉΩÂ§üËá™ÁÑ∂Âú∞„ÄÅÊúâÊïàÂú∞Âà©Áî®ÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇËØ•Êû∂ÊûÑÁöÑÊ†∏ÂøÉÊòØÁ©∫Èó¥-ÈÄöÈÅìËûçÂêàTransformerÂùóÔºåÂÆÉËÉΩÂ§üÂêåÊó∂ËÄÉËôëÁ©∫Èó¥ÂíåÈÄöÈÅìÁª¥Â∫¶ÁöÑÂÖ®Â±Ä‰ø°ÊÅØÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÁêÜËß£ÂØπÂ∫îÂÖ≥Á≥ª‰πãÈó¥ÁöÑÁõ∏‰∫í‰æùËµñÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöLeCoTÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÂê´Â§ö‰∏™Èò∂ÊÆµÔºåÊØè‰∏™Èò∂ÊÆµÈÉΩÂåÖÂê´Á©∫Èó¥-ÈÄöÈÅìËûçÂêàTransformerÂùó„ÄÇÁΩëÁªúÈ¶ñÂÖàÊèêÂèñÂØπÂ∫îÂÖ≥Á≥ªÁöÑÁâπÂæÅÔºåÁÑ∂ÂêéÈÄöËøáÂ§ö‰∏™TransformerÂùóËøõË°åÂ§ÑÁêÜÔºåÈÄêÊ≠•ÊèêÂèñÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåLeCoTËøòÂåÖÂê´‰∏Ä‰∏™È¢ÑÊµãÂùóÔºåËØ•ÂùóÂà©Áî®‰∏≠Èó¥Èò∂ÊÆµÁöÑÁâπÂæÅÊù•ÁîüÊàêÊ¶ÇÁéáÈõÜÔºåÊåáÂØºÂêéÁª≠Â≠¶‰π†„ÄÇÊ¶ÇÁéáÈõÜ‰ºöÈÄêÊ≠•ÁªÜÂåñÔºåÁºìËß£‰ø°ÊÅØ‰∏¢Â§±ÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöLeCoTÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÁ©∫Èó¥-ÈÄöÈÅìËûçÂêàTransformerÂùóÁöÑËÆæËÆ°„ÄÇ‰∏é‰º†ÁªüÁöÑTransformerÂè™ÂÖ≥Ê≥®Á©∫Èó¥ÊàñÈÄöÈÅìÁª¥Â∫¶‰∏çÂêåÔºåËØ•Ê®°ÂùóÂêåÊó∂ËÄÉËôë‰∫Ü‰∏§‰∏™Áª¥Â∫¶Ôºå‰ªéËÄåÊõ¥ÂÖ®Èù¢Âú∞ÊçïÊçâÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåÈÄêÊ≠•ÁªÜÂåñÁöÑÈ¢ÑÊµãÂùó‰πüÊòØ‰∏Ä‰∏™ÂàõÊñ∞ÁÇπÔºåÂÆÉËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®‰∏≠Èó¥Èò∂ÊÆµÁöÑÁâπÂæÅÔºåÊèêÈ´òÂâ™ÊûùÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÁ©∫Èó¥-ÈÄöÈÅìËûçÂêàTransformerÂùóÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÁªÜËäÇÊú™Áü•Ôºå‰ΩÜÂèØ‰ª•Êé®ÊµãÂÖ∂ÈááÁî®‰∫ÜÊüêÁßçÂΩ¢ÂºèÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂Ôºå‰ª•‰æøÂú®Á©∫Èó¥ÂíåÈÄöÈÅìÁª¥Â∫¶‰∏äÈÄâÊã©ÊÄßÂú∞ÂÖ≥Ê≥®ÈáçË¶Å‰ø°ÊÅØ„ÄÇÈ¢ÑÊµãÂùóÁöÑÂÖ∑‰ΩìÁªìÊûÑÂíåÊçüÂ§±ÂáΩÊï∞‰πüÊú™Áü•Ôºå‰ΩÜÂèØ‰ª•Êé®ÊµãÂÖ∂ÁõÆÊ†áÊòØÊúÄÂ∞èÂåñÈ¢ÑÊµãÊ¶ÇÁéá‰∏éÁúüÂÆûÊ†áÁ≠æ‰πãÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

LeCoTÂú®Â§ö‰∏™‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂú®ÂØπÂ∫îÂÖ≥Á≥ªÂâ™Êûù‰ªªÂä°‰∏äÔºåLeCoT‰ºò‰∫éÁé∞ÊúâÊúÄ‰ºòÊñπÊ≥ï„ÄÇÂú®Áõ∏ÂØπÂßøÊÄÅ‰º∞ËÆ°„ÄÅÂçïÂ∫îÊÄß‰º∞ËÆ°„ÄÅËßÜËßâÂÆö‰ΩçÂíå3DÈáçÂª∫Á≠â‰∏ãÊ∏∏‰ªªÂä°‰∏≠ÔºåLeCoT‰πüÂèñÂæó‰∫ÜÊõ¥Â•ΩÁöÑÁªìÊûúÔºåËØÅÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÊèêÂçáÂπÖÂ∫¶ÈúÄË¶ÅÂú®ËÆ∫Êñá‰∏≠Êü•Êâæ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

LeCoTÂú®Êú∫Âô®‰∫∫ÂØºËà™„ÄÅÂ¢ûÂº∫Áé∞ÂÆû„ÄÅ‰∏âÁª¥ÈáçÂª∫„ÄÅËßÜËßâÂÆö‰ΩçÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂáÜÁ°ÆÁöÑÂØπÂ∫îÂÖ≥Á≥ªÂâ™ÊûùËÉΩÂ§üÊèêÈ´òËøô‰∫õÂ∫îÁî®‰∏≠‰ΩçÂßø‰º∞ËÆ°„ÄÅÂú∞ÂõæÊûÑÂª∫Á≠âÂÖ≥ÈîÆ‰ªªÂä°ÁöÑÁ≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄßÔºå‰ªéËÄåÊèêÂçáÊï¥‰ΩìÁ≥ªÁªüÊÄßËÉΩ„ÄÇËØ•Á†îÁ©∂ÁöÑÊú™Êù•ÂΩ±ÂìçÂú®‰∫éÊé®Âä®ËÆ°ÁÆóÊú∫ËßÜËßâÈ¢ÜÂüüÂØπ‰∏ä‰∏ãÊñá‰ø°ÊÅØÂà©Áî®ÁöÑÊ∑±ÂÖ•Á†îÁ©∂„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Two-view correspondence pruning aims to accurately remove incorrect correspondences (outliers) from initial ones and is widely applied to various computer vision tasks. Current popular strategies adopt multilayer perceptron (MLP) as the backbone, supplemented by additional modules to enhance the network ability to handle context information, which is a known limitation of MLPs. In contrast, we introduce a novel perspective for capturing correspondence context information without extra design modules. To this end, we design a two-view correspondence pruning network called LeCoT, which can naturally leverage global context information at different stages. Specifically, the core design of LeCoT is the Spatial-Channel Fusion Transformer block, a newly proposed component that efficiently utilizes both spatial and channel global context information among sparse correspondences. In addition, we integrate the proposed prediction block that utilizes correspondence features from intermediate stages to generate a probability set, which acts as guiding information for subsequent learning phases, allowing the network to more effectively capture robust global context information. Notably, this prediction block progressively refines the probability set, thereby mitigating the issue of information loss that is common in the traditional one. Extensive experiments prove that the proposed LeCoT outperforms state-of-the-art methods in correspondence pruning, relative pose estimation, homography estimation, visual localization, and $3$D~reconstruction tasks. The code is provided in https://github.com/Dailuanyuan2024/LeCoT-Revisiting-Network-Architecture-for-Two-View-Correspondence-Pruning.

