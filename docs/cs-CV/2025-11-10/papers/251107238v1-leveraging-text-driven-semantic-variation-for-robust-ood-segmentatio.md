---
layout: default
title: Leveraging Text-Driven Semantic Variation for Robust OOD Segmentation
---

# Leveraging Text-Driven Semantic Variation for Robust OOD Segmentation

**arXiv**: [2511.07238v1](https://arxiv.org/abs/2511.07238) | [PDF](https://arxiv.org/pdf/2511.07238.pdf)

**ä½œè€…**: Seungheon Song, Jaekoo Lee

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–‡æœ¬é©±åŠ¨OODåˆ†å‰²æ–¹æ³•ï¼Œåˆ©ç”¨è§†è§‰è¯­è¨€ç©ºé—´æå‡è‡ªåŠ¨é©¾é©¶å¼‚å¸¸åˆ†å‰²é²æ£’æ€§**

**å…³é”®è¯**: `OODåˆ†å‰²` `è§†è§‰è¯­è¨€æ¨¡åž‹` `è‡ªåŠ¨é©¾é©¶å®‰å…¨` `è¯­ä¹‰å¢žå¼º` `Transformerè§£ç å™¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‡ªåŠ¨é©¾é©¶ä¸­OODåˆ†å‰²å¯¹å®‰å…¨è‡³å…³é‡è¦ï¼Œä½†çŽ°æœ‰æ–¹æ³•æœªå……åˆ†åˆ©ç”¨è¯­è¨€çŸ¥è¯†
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆè§†è§‰è¯­è¨€ç¼–ç å™¨ä¸ŽTransformerè§£ç å™¨ï¼Œä½¿ç”¨è·ç¦»æç¤ºå’Œè¯­ä¹‰å¢žå¼º
3. å®žéªŒæ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®žçŽ°SOTAæ€§èƒ½ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æ³›åŒ–æ€§å’Œé²æ£’æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In autonomous driving and robotics, ensuring road safety and reliable
> decision-making critically depends on out-of-distribution (OOD) segmentation.
> While numerous methods have been proposed to detect anomalous objects on the
> road, leveraging the vision-language space-which provides rich linguistic
> knowledge-remains an underexplored field. We hypothesize that incorporating
> these linguistic cues can be especially beneficial in the complex contexts
> found in real-world autonomous driving scenarios.
>   To this end, we present a novel approach that trains a Text-Driven OOD
> Segmentation model to learn a semantically diverse set of objects in the
> vision-language space. Concretely, our approach combines a vision-language
> model's encoder with a transformer decoder, employs Distance-Based OOD prompts
> located at varying semantic distances from in-distribution (ID) classes, and
> utilizes OOD Semantic Augmentation for OOD representations. By aligning visual
> and textual information, our approach effectively generalizes to unseen objects
> and provides robust OOD segmentation in diverse driving environments.
>   We conduct extensive experiments on publicly available OOD segmentation
> datasets such as Fishyscapes, Segment-Me-If-You-Can, and Road Anomaly datasets,
> demonstrating that our approach achieves state-of-the-art performance across
> both pixel-level and object-level evaluations. This result underscores the
> potential of vision-language-based OOD segmentation to bolster the safety and
> reliability of future autonomous driving systems.

