---
layout: default
title: Improving Deepfake Detection with Reinforcement Learning-Based Adaptive Data Augmentation
---

# Improving Deepfake Detection with Reinforcement Learning-Based Adaptive Data Augmentation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.07051" target="_blank" class="toolbar-btn">arXiv: 2511.07051v1</a>
    <a href="https://arxiv.org/pdf/2511.07051.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.07051v1" 
            onclick="toggleFavorite(this, '2511.07051v1', 'Improving Deepfake Detection with Reinforcement Learning-Based Adaptive Data Augmentation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yuxuan Zhou, Tao Yu, Wen Huang, Yuheng Zhang, Tao Dai, Shu-Tao Xia

**ÂàÜÁ±ª**: cs.CV, cs.CR

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-10

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑËá™ÈÄÇÂ∫îÊï∞ÊçÆÂ¢ûÂº∫ÊñπÊ≥ïCRDAÔºåÊèêÂçáDeepfakeÊ£ÄÊµãÂô®ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `DeepfakeÊ£ÄÊµã` `Êï∞ÊçÆÂ¢ûÂº∫` `Âº∫ÂåñÂ≠¶‰π†` `Âõ†ÊûúÊé®Êñ≠` `Ê≥õÂåñËÉΩÂäõ` `ÂØπÊäóÊ†∑Êú¨` `Ëá™ÈÄÇÂ∫îÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâDeepfakeÊ£ÄÊµãÂô®‰æùËµñÂõ∫ÂÆöÊï∞ÊçÆÂ¢ûÂº∫Á≠ñÁï•ÔºåÊó†Ê≥ïÊúâÊïàÂ∫îÂØπÁúüÂÆû‰∏ñÁïå‰∏≠‰∏çÊñ≠ÊºîÂèòÁöÑ‰º™ÈÄ†ÊäÄÊúØÂ§çÊùÇÊÄß„ÄÇ
2. CRDAÊ°ÜÊû∂ÁªìÂêàÂº∫ÂåñÂ≠¶‰π†ÂíåÂõ†ÊûúÊé®Êñ≠ÔºåÂä®ÊÄÅÈÄâÊã©Â¢ûÂº∫Âä®‰ΩúÂπ∂ÁîüÊàêÂØπÊäóÊ†∑Êú¨ÔºåÂºïÂØºÊ£ÄÊµãÂô®Â≠¶‰π†Â§öÈ¢ÜÂüü‰º™ÈÄ†ÁâπÂæÅ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCRDAÊòæËëóÊèêÂçá‰∫ÜÊ£ÄÊµãÂô®Âú®Ë∑®ÂüüÊï∞ÊçÆÈõÜ‰∏äÁöÑÊ≥õÂåñËÉΩÂäõÔºå‰ºò‰∫éÂΩìÂâçÊúÄ‰ºòÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ê∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµãÂô®ÁöÑÊ≥õÂåñËÉΩÂäõÂØπ‰∫éÂÆûÈôÖÂ∫îÁî®Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÈÄöËøáÂêàÊàê‰º™ÈÄ†‰∫∫ËÑ∏ÁîüÊàêÊï∞ÊçÆÂ¢ûÂº∫ÂèØ‰ª•ÊúâÊïàÊèêÂçáÊ≥õÂåñËÉΩÂäõÔºå‰ΩÜÂΩìÂâçÊúÄ‰ºòÊñπÊ≥ï‰æùËµñ‰∫éÂõ∫ÂÆöÁöÑÁ≠ñÁï•„ÄÇÊú¨ÊñáÊèêÂá∫‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢òÔºöÂçï‰∏ÄÈùôÊÄÅÂ¢ûÂº∫ÊòØÂê¶Ë∂≥Â§üÔºüÊàñËÄÖ‰º™ÈÄ†ÁâπÂæÅÁöÑÂ§öÊ†∑ÊÄßÊòØÂê¶ÈúÄË¶ÅÂä®ÊÄÅÊñπÊ≥ïÔºüÁé∞ÊúâÊñπÊ≥ïÂøΩÁï•‰∫ÜÁúüÂÆû‰º™ÈÄ†ÊäÄÊúØÁöÑÂ§çÊùÇÊÄßÊºîÂèòÔºà‰æãÂ¶ÇÔºåÈù¢ÈÉ®Êâ≠Êõ≤„ÄÅË°®ÊÉÖÊìçÁ∫µÔºâÔºåËÄåÂõ∫ÂÆöÁ≠ñÁï•Êó†Ê≥ïÂÆåÂÖ®Ê®°ÊãüËøô‰∫õÂ§çÊùÇÊÄß„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜCRDAÔºàCurriculum Reinforcement-Learning Data AugmentationÔºâÔºå‰∏Ä‰∏™ÂºïÂØºÊ£ÄÊµãÂô®ÈÄêÊ≠•ÊéåÊè°‰ªéÁÆÄÂçïÂà∞Â§çÊùÇÁöÑÂ§öÈ¢ÜÂüü‰º™ÈÄ†ÁâπÂæÅÁöÑÊñ∞Ê°ÜÊû∂„ÄÇCRDAÈÄöËøáÂèØÈÖçÁΩÆÁöÑ‰º™ÈÄ†Êìç‰ΩúÊ±†ÂêàÊàêÂ¢ûÂº∫Ê†∑Êú¨ÔºåÂπ∂Âä®ÊÄÅÁîüÊàêÈíàÂØπÊ£ÄÊµãÂô®ÂΩìÂâçÂ≠¶‰π†Áä∂ÊÄÅÁöÑÂØπÊäóÊ†∑Êú¨„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÁöÑÊ†∏ÂøÉÊòØÊï¥ÂêàÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÂíåÂõ†ÊûúÊé®Êñ≠„ÄÇRLÊô∫ËÉΩ‰ΩìÂü∫‰∫éÊ£ÄÊµãÂô®ÊÄßËÉΩÂä®ÊÄÅÈÄâÊã©Â¢ûÂº∫Âä®‰ΩúÔºå‰ª•ÊúâÊïàÊé¢Á¥¢ÂπøÈòîÁöÑÂ¢ûÂº∫Á©∫Èó¥ÔºåÈÄÇÂ∫îÊó•ÁõäÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑ‰º™ÈÄ†„ÄÇÂêåÊó∂ÔºåÊô∫ËÉΩ‰ΩìÂºïÂÖ•Âä®‰ΩúÁ©∫Èó¥ÂèòÂåñ‰ª•ÁîüÊàêÂºÇÊûÑ‰º™ÈÄ†Ê®°ÂºèÔºåÂπ∂Áî±Âõ†ÊûúÊé®Êñ≠ÂºïÂØº‰ª•ÂáèËΩªËôöÂÅáÁõ∏ÂÖ≥ÊÄßÔºåÊäëÂà∂‰∏é‰ªªÂä°Êó†ÂÖ≥ÁöÑÂÅèÂ∑ÆÔºåÂπ∂‰∏ìÊ≥®‰∫éÂõ†Êûú‰∏çÂèòÁâπÂæÅ„ÄÇËøôÁßçÈõÜÊàêÈÄöËøáÂ∞ÜÂêàÊàêÂ¢ûÂº∫Ê®°Âºè‰∏éÊ®°ÂûãÂ≠¶‰π†ÁöÑË°®Á§∫Ëß£ËÄ¶ÔºåÁ°Æ‰øù‰∫ÜÈ≤ÅÊ£íÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÊòæËëóÊèêÈ´ò‰∫ÜÊ£ÄÊµãÂô®ÁöÑÊ≥õÂåñËÉΩÂäõÔºå‰ºò‰∫éÂ§ö‰∏™Ë∑®ÂüüÊï∞ÊçÆÈõÜ‰∏äÁöÑSOTAÊñπÊ≥ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâDeepfakeÊ£ÄÊµãÂô®Âú®Èù¢ÂØπÁúüÂÆûÂú∫ÊôØÊó∂ÔºåÊ≥õÂåñËÉΩÂäõ‰∏çË∂≥„ÄÇ‰∏ªË¶ÅÂéüÂõ†ÊòØÁé∞ÊúâÊï∞ÊçÆÂ¢ûÂº∫ÊñπÊ≥ïÈááÁî®Âõ∫ÂÆöÁöÑÁ≠ñÁï•ÔºåÊó†Ê≥ïÊ®°ÊãüÁúüÂÆû‰∏ñÁïå‰∏≠‰º™ÈÄ†ÊäÄÊúØÁöÑÂ§çÊùÇÊÄßÂíåÂ§öÊ†∑ÊÄßÔºå‰æãÂ¶ÇÈù¢ÈÉ®Êâ≠Êõ≤„ÄÅË°®ÊÉÖÊìçÁ∫µÁ≠â„ÄÇËøô‰∫õÂõ∫ÂÆöÁ≠ñÁï•ÂÆπÊòìÂØºËá¥Ê®°ÂûãÂ≠¶‰π†Âà∞‰∏é‰ªªÂä°Êó†ÂÖ≥ÁöÑÂÅèÂ∑ÆÔºå‰ªéËÄåÂΩ±ÂìçÂÖ∂Âú®Êú™ËßÅËøáÁöÑÊï∞ÊçÆ‰∏äÁöÑË°®Áé∞„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Âº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÂä®ÊÄÅÂú∞ÈÄâÊã©Êï∞ÊçÆÂ¢ûÂº∫Á≠ñÁï•ÔºåÂπ∂ÁªìÂêàÂõ†ÊûúÊé®Êñ≠Êù•ÂáèÂ∞ëÊ®°ÂûãÂ≠¶‰π†Âà∞ÁöÑËôöÂÅáÁõ∏ÂÖ≥ÊÄß„ÄÇÈÄöËøáRLÔºåÂèØ‰ª•Ê†πÊçÆÊ£ÄÊµãÂô®ÁöÑÂ≠¶‰π†Áä∂ÊÄÅÔºåËá™ÈÄÇÂ∫îÂú∞ÁîüÊàêÊõ¥ÂÖ∑ÊåëÊàòÊÄßÁöÑÂØπÊäóÊ†∑Êú¨Ôºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂõ†ÊûúÊé®Êñ≠ÂàôÁî®‰∫éÂºïÂØºÊ®°ÂûãÂÖ≥Ê≥®Âõ†Êûú‰∏çÂèòÁâπÂæÅÔºåÊäëÂà∂‰∏é‰ªªÂä°Êó†ÂÖ≥ÁöÑÂÅèÂ∑Æ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCRDAÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏â‰∏™Ê®°ÂùóÔºö‰º™ÈÄ†Êìç‰ΩúÊ±†„ÄÅÂº∫ÂåñÂ≠¶‰π†Êô∫ËÉΩ‰ΩìÂíåDeepfakeÊ£ÄÊµãÂô®„ÄÇ‰º™ÈÄ†Êìç‰ΩúÊ±†ÂåÖÂê´Â§öÁßç‰º™ÈÄ†ÊäÄÊúØÔºåÂ¶ÇÈù¢ÈÉ®‰∫§Êç¢„ÄÅË°®ÊÉÖÊìçÁ∫µÁ≠â„ÄÇÂº∫ÂåñÂ≠¶‰π†Êô∫ËÉΩ‰ΩìÊ†πÊçÆÊ£ÄÊµãÂô®ÁöÑÊÄßËÉΩÔºå‰ªé‰º™ÈÄ†Êìç‰ΩúÊ±†‰∏≠ÈÄâÊã©ÂêàÈÄÇÁöÑÂ¢ûÂº∫Âä®‰ΩúÔºåÁîüÊàêÂØπÊäóÊ†∑Êú¨„ÄÇDeepfakeÊ£ÄÊµãÂô®ÂàôÂà©Áî®Ëøô‰∫õÂ¢ûÂº∫ÂêéÁöÑÊï∞ÊçÆËøõË°åËÆ≠ÁªÉÔºåÊèêÈ´òÂÖ∂Ê≥õÂåñËÉΩÂäõ„ÄÇÊï¥‰∏™ËøáÁ®ãÊòØ‰∏Ä‰∏™Âæ™ÁéØËø≠‰ª£ÁöÑËøáÁ®ãÔºåÊô∫ËÉΩ‰Ωì‰∏çÊñ≠Ë∞ÉÊï¥Â¢ûÂº∫Á≠ñÁï•ÔºåÊ£ÄÊµãÂô®‰∏çÊñ≠ÊèêÈ´òÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöCRDAÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÂº∫ÂåñÂ≠¶‰π†ÂíåÂõ†ÊûúÊé®Êñ≠ÁªìÂêàËµ∑Êù•ÔºåÁî®‰∫éËá™ÈÄÇÂ∫îÂú∞ÁîüÊàêÊï∞ÊçÆÂ¢ûÂº∫Ê†∑Êú¨„ÄÇ‰∏é‰º†ÁªüÁöÑÂõ∫ÂÆöÊï∞ÊçÆÂ¢ûÂº∫ÊñπÊ≥ïÁõ∏ÊØîÔºåCRDAËÉΩÂ§üÊ†πÊçÆÊ£ÄÊµãÂô®ÁöÑÂ≠¶‰π†Áä∂ÊÄÅÂä®ÊÄÅÂú∞Ë∞ÉÊï¥Â¢ûÂº∫Á≠ñÁï•Ôºå‰ªéËÄåÊõ¥Â•ΩÂú∞Ê®°ÊãüÁúüÂÆû‰∏ñÁïå‰∏≠‰º™ÈÄ†ÊäÄÊúØÁöÑÂ§çÊùÇÊÄßÂíåÂ§öÊ†∑ÊÄß„ÄÇÂêåÊó∂ÔºåÂõ†ÊûúÊé®Êñ≠ÁöÑÂºïÂÖ•ÂèØ‰ª•ÂáèÂ∞ëÊ®°ÂûãÂ≠¶‰π†Âà∞ÁöÑËôöÂÅáÁõ∏ÂÖ≥ÊÄßÔºåÊèêÈ´òÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöCRDA‰ΩøÁî®‰∏Ä‰∏™Âü∫‰∫éÁ≠ñÁï•Ê¢ØÂ∫¶ÁöÑÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÊù•ËÆ≠ÁªÉÊô∫ËÉΩ‰Ωì„ÄÇÊô∫ËÉΩ‰ΩìÁöÑÁä∂ÊÄÅÊòØÊ£ÄÊµãÂô®ÁöÑÊÄßËÉΩÊåáÊ†áÔºåÂä®‰ΩúÊòØ‰ªé‰º™ÈÄ†Êìç‰ΩúÊ±†‰∏≠ÈÄâÊã©ÁöÑÂ¢ûÂº∫Âä®‰Ωú„ÄÇÂ•ñÂä±ÂáΩÊï∞Ê†πÊçÆÊ£ÄÊµãÂô®Âú®Â¢ûÂº∫Êï∞ÊçÆ‰∏äÁöÑÊÄßËÉΩÊù•ËÆæËÆ°ÔºåÁõÆÊ†áÊòØÊúÄÂ§ßÂåñÊ£ÄÊµãÂô®ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÂõ†ÊûúÊé®Êñ≠ÈÄöËøáÂºïÂÖ•Âπ≤È¢ÑÂèòÈáèÊù•ÂÆûÁé∞ÔºåÁî®‰∫éËØÜÂà´ÂíåÊ∂àÈô§‰∏é‰ªªÂä°Êó†ÂÖ≥ÁöÑÂÅèÂ∑Æ„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÊ†πÊçÆ‰∏çÂêåÁöÑÊï∞ÊçÆÈõÜÂíå‰ªªÂä°ËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCRDAÂú®Â§ö‰∏™Ë∑®ÂüüÊï∞ÊçÆÈõÜ‰∏äÊòæËëóÊèêÈ´ò‰∫ÜDeepfakeÊ£ÄÊµãÂô®ÁöÑÊ≥õÂåñËÉΩÂäõÔºå‰æãÂ¶ÇÂú®FaceForensics++Êï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉÁöÑÊ®°ÂûãÔºåÂú®Celeb-DFÊï∞ÊçÆÈõÜ‰∏äÁöÑÂáÜÁ°ÆÁéáÊèêÂçá‰∫ÜX%Ôºå‰ºò‰∫éÂΩìÂâçÊúÄ‰ºòÊñπÊ≥ï„ÄÇÊ∂àËûçÂÆûÈ™åÈ™åËØÅ‰∫ÜÂº∫ÂåñÂ≠¶‰π†ÂíåÂõ†ÊûúÊé®Êñ≠Âú®ÊèêÂçáÊ®°ÂûãÊ≥õÂåñËÉΩÂäõ‰∏≠ÁöÑ‰ΩúÁî®„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊèêÂçáDeepfakeÊ£ÄÊµãÁ≥ªÁªüÂú®Á§æ‰∫§Â™í‰Ωì„ÄÅÂú®Á∫øËßÜÈ¢ëÂπ≥Âè∞„ÄÅÂÆâÂÖ®ÁõëÊéßÁ≠âÈ¢ÜÂüüÁöÑÊÄßËÉΩÔºåÊúâÊïàËØÜÂà´ÂíåÈò≤ËåÉÊÅ∂ÊÑè‰º™ÈÄ†ÂÜÖÂÆπÔºåÁª¥Êä§ÁΩëÁªúÂÆâÂÖ®ÂíåÁ§æ‰ºöÁ®≥ÂÆö„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ï‰πüÂèØÊé®ÂπøÂà∞ÂÖ∂‰ªñÂØπÊäóÊ†∑Êú¨ÁîüÊàêÂíåÊ®°ÂûãÈ≤ÅÊ£íÊÄßÊèêÂçáÁöÑ‰ªªÂä°‰∏≠„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The generalization capability of deepfake detectors is critical for real-world use. Data augmentation via synthetic fake face generation effectively enhances generalization, yet current SoTA methods rely on fixed strategies-raising a key question: Is a single static augmentation sufficient, or does the diversity of forgery features demand dynamic approaches? We argue existing methods overlook the evolving complexity of real-world forgeries (e.g., facial warping, expression manipulation), which fixed policies cannot fully simulate. To address this, we propose CRDA (Curriculum Reinforcement-Learning Data Augmentation), a novel framework guiding detectors to progressively master multi-domain forgery features from simple to complex. CRDA synthesizes augmented samples via a configurable pool of forgery operations and dynamically generates adversarial samples tailored to the detector's current learning state. Central to our approach is integrating reinforcement learning (RL) and causal inference. An RL agent dynamically selects augmentation actions based on detector performance to efficiently explore the vast augmentation space, adapting to increasingly challenging forgeries. Simultaneously, the agent introduces action space variations to generate heterogeneous forgery patterns, guided by causal inference to mitigate spurious correlations-suppressing task-irrelevant biases and focusing on causally invariant features. This integration ensures robust generalization by decoupling synthetic augmentation patterns from the model's learned representations. Extensive experiments show our method significantly improves detector generalizability, outperforming SOTA methods across multiple cross-domain datasets.

