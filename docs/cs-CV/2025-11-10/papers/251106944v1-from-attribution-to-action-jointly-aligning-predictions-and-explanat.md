---
layout: default
title: From Attribution to Action: Jointly ALIGNing Predictions and Explanations
---

# From Attribution to Action: Jointly ALIGNing Predictions and Explanations

**arXiv**: [2511.06944v1](https://arxiv.org/abs/2511.06944) | [PDF](https://arxiv.org/pdf/2511.06944.pdf)

**ä½œè€…**: Dongsheng Hong, Chao Chen, Yanhui Chen, Shanshan Lin, Zhihao Chen, Xiangwen Liao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºALIGNæ¡†æž¶ä»¥è”åˆä¼˜åŒ–åˆ†ç±»å™¨å’ŒæŽ©ç å™¨ï¼Œæå‡æ¨¡åž‹å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›**

**å…³é”®è¯**: `è§£é‡Šå¼•å¯¼å­¦ä¹ ` `æŽ©ç ç”Ÿæˆ` `é¢†åŸŸæ³›åŒ–` `å¯è§£é‡Šæ€§` `è”åˆè®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§£é‡Šå¼•å¯¼å­¦ä¹ ä¾èµ–å¤–éƒ¨æ³¨é‡Šæˆ–å¯å‘å¼åˆ†å‰²ï¼Œç›‘ç£ä¿¡å·è´¨é‡ä½Žä¸”éš¾ä»¥æ‰©å±•
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡è¿­ä»£è®­ç»ƒï¼ŒæŽ©ç å™¨ç”Ÿæˆä»»åŠ¡ç›¸å…³è½¯æŽ©ç ï¼Œåˆ†ç±»å™¨ä¼˜åŒ–é¢„æµ‹å‡†ç¡®æ€§å’Œå¯¹é½æ€§
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨VLCSå’ŒTerra IncognitaåŸºå‡†ä¸Šï¼ŒALIGNåœ¨åˆ†å¸ƒå†…å¤–å‡ä¼˜äºŽåŸºçº¿ï¼Œè§£é‡Šè´¨é‡æ›´é«˜

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Explanation-guided learning (EGL) has shown promise in aligning model
> predictions with interpretable reasoning, particularly in computer vision
> tasks. However, most approaches rely on external annotations or heuristic-based
> segmentation to supervise model explanations, which can be noisy, imprecise and
> difficult to scale. In this work, we provide both empirical and theoretical
> evidence that low-quality supervision signals can degrade model performance
> rather than improve it. In response, we propose ALIGN, a novel framework that
> jointly trains a classifier and a masker in an iterative manner. The masker
> learns to produce soft, task-relevant masks that highlight informative regions,
> while the classifier is optimized for both prediction accuracy and alignment
> between its saliency maps and the learned masks. By leveraging high-quality
> masks as guidance, ALIGN improves both interpretability and generalizability,
> showing its superiority across various settings. Experiments on the two domain
> generalization benchmarks, VLCS and Terra Incognita, show that ALIGN
> consistently outperforms six strong baselines in both in-distribution and
> out-of-distribution settings. Besides, ALIGN also yields superior explanation
> quality concerning sufficiency and comprehensiveness, highlighting its
> effectiveness in producing accurate and interpretable models.

