---
layout: default
title: TwinOR: Photorealistic Digital Twins of Dynamic Operating Rooms for Embodied AI Research
---

# TwinOR: Photorealistic Digital Twins of Dynamic Operating Rooms for Embodied AI Research

**arXiv**: [2511.07412v1](https://arxiv.org/abs/2511.07412) | [PDF](https://arxiv.org/pdf/2511.07412.pdf)

**ä½œè€…**: Han Zhang, Yiqing Shen, Roger D. Soberanis-Mukul, Ankita Ghosh, Hao Ding, Lalithkumar Seenivasan, Jose L. Porras, Zhekai Mao, Chenjia Li, Wenjie Xiao, Lonny Yarmus, Angela Christine Argento, Masaru Ishii, Mathias Unberath

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTwinORæ¡†æž¶ä»¥æž„å»ºæ‰‹æœ¯å®¤åŠ¨æ€æ•°å­—å­ªç”Ÿï¼Œæ”¯æŒå…·èº«AIç ”ç©¶ã€‚**

**å…³é”®è¯**: `æ•°å­—å­ªç”Ÿ` `æ‰‹æœ¯å®¤æ¨¡æ‹Ÿ` `å…·èº«AI` `3Dé‡å»º` `å¤šè§†è§’æ„ŸçŸ¥` `è™šæ‹ŸçŽ¯å¢ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‰‹æœ¯å®¤å®‰å…¨é™åˆ¶é˜»ç¢å…·èº«AIåœ¨çœŸå®žçŽ¯å¢ƒä¸­æ„ŸçŸ¥ä¸Žäº¤äº’ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä»Žè§†é¢‘é‡å»ºé™æ€å‡ ä½•ï¼Œå¤šè§†è§’æ„ŸçŸ¥åŠ¨æ€è¿åŠ¨ï¼Œèžåˆä¸ºæ²‰æµ¸å¼3DçŽ¯å¢ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåˆæˆæ•°æ®ä½¿æ¨¡åž‹æ€§èƒ½æŽ¥è¿‘çœŸå®žæ•°æ®é›†ï¼ŒéªŒè¯ä¼ æ„Ÿå™¨çº§çœŸå®žæ„Ÿã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Developing embodied AI for intelligent surgical systems requires safe,
> controllable environments for continual learning and evaluation. However,
> safety regulations and operational constraints in operating rooms (ORs) limit
> embodied agents from freely perceiving and interacting in realistic settings.
> Digital twins provide high-fidelity, risk-free environments for exploration and
> training. How we may create photorealistic and dynamic digital representations
> of ORs that capture relevant spatial, visual, and behavioral complexity remains
> unclear. We introduce TwinOR, a framework for constructing photorealistic,
> dynamic digital twins of ORs for embodied AI research. The system reconstructs
> static geometry from pre-scan videos and continuously models human and
> equipment motion through multi-view perception of OR activities. The static and
> dynamic components are fused into an immersive 3D environment that supports
> controllable simulation and embodied exploration. The proposed framework
> reconstructs complete OR geometry with centimeter level accuracy while
> preserving dynamic interaction across surgical workflows, enabling realistic
> renderings and a virtual playground for embodied AI systems. In our
> experiments, TwinOR simulates stereo and monocular sensor streams for geometry
> understanding and visual localization tasks. Models such as FoundationStereo
> and ORB-SLAM3 on TwinOR-synthesized data achieve performance within their
> reported accuracy on real indoor datasets, demonstrating that TwinOR provides
> sensor-level realism sufficient for perception and localization challenges. By
> establishing a real-to-sim pipeline for constructing dynamic, photorealistic
> digital twins of OR environments, TwinOR enables the safe, scalable, and
> data-efficient development and benchmarking of embodied AI, ultimately
> accelerating the deployment of embodied AI from sim-to-real.

