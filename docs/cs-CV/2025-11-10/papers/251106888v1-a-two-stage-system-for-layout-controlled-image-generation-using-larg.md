---
layout: default
title: A Two-Stage System for Layout-Controlled Image Generation using Large Language Models and Diffusion Models
---

# A Two-Stage System for Layout-Controlled Image Generation using Large Language Models and Diffusion Models

**arXiv**: [2511.06888v1](https://arxiv.org/abs/2511.06888) | [PDF](https://arxiv.org/pdf/2511.06888.pdf)

**ä½œè€…**: Jan-Hendrik Koch, Jonas Krumme, Konrad Gadzicki

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸¤é˜¶æ®µç³»ç»Ÿä»¥è§£å†³æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­å¯¹è±¡è®¡æ•°å’Œç©ºé—´å¸ƒå±€æŽ§åˆ¶ä¸è¶³çš„é—®é¢˜**

**å…³é”®è¯**: `å¸ƒå±€æŽ§åˆ¶å›¾åƒç”Ÿæˆ` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `æ‰©æ•£æ¨¡åž‹` `ä¸¤é˜¶æ®µç³»ç»Ÿ` `å¯¹è±¡å¬å›žçŽ‡` `æ¡ä»¶ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡åž‹ç¼ºä¹å¯¹å¯¹è±¡æ•°é‡å’Œç©ºé—´æŽ’åˆ—çš„ç²¾ç¡®æŽ§åˆ¶
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å¤§åž‹è¯­è¨€æ¨¡åž‹ç”Ÿæˆç»“æž„åŒ–å¸ƒå±€ï¼Œå¸ƒå±€æ¡ä»¶æ‰©æ•£æ¨¡åž‹åˆæˆå›¾åƒ
3. å®žéªŒæˆ–æ•ˆæžœï¼šå¯¹è±¡å¬å›žçŽ‡ä»Ž57.2%æå‡è‡³99.9%ï¼Œæ¯”è¾ƒControlNetå’ŒGLIGENçš„æƒè¡¡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-to-image diffusion models exhibit remarkable generative capabilities,
> but lack precise control over object counts and spatial arrangements. This work
> introduces a two-stage system to address these compositional limitations. The
> first stage employs a Large Language Model (LLM) to generate a structured
> layout from a list of objects. The second stage uses a layout-conditioned
> diffusion model to synthesize a photorealistic image adhering to this layout.
> We find that task decomposition is critical for LLM-based spatial planning; by
> simplifying the initial generation to core objects and completing the layout
> with rule-based insertion, we improve object recall from 57.2% to 99.9% for
> complex scenes. For image synthesis, we compare two leading conditioning
> methods: ControlNet and GLIGEN. After domain-specific finetuning on
> table-setting datasets, we identify a key trade-off: ControlNet preserves
> text-based stylistic control but suffers from object hallucination, while
> GLIGEN provides superior layout fidelity at the cost of reduced prompt-based
> controllability. Our end-to-end system successfully generates images with
> specified object counts and plausible spatial arrangements, demonstrating the
> viability of a decoupled approach for compositionally controlled synthesis.

