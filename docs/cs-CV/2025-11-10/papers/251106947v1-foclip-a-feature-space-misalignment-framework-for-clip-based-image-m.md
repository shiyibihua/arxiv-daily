---
layout: default
title: FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image Manipulation and Detection
---

# FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image Manipulation and Detection

**arXiv**: [2511.06947v1](https://arxiv.org/abs/2511.06947) | [PDF](https://arxiv.org/pdf/2511.06947.pdf)

**ä½œè€…**: Yulin Chen, Zeyuan Wang, Tianyuan Yu, Yingmei Wei, Liang Bai

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-10

**å¤‡æ³¨**: 15 page, 9 figures, published to PRCV

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFoCLIPæ¡†æž¶ï¼Œé€šè¿‡ç‰¹å¾ç©ºé—´é”™ä½æ”»å‡»å’Œé˜²å¾¡CLIPæ¨¡åž‹ï¼Œæå‡å›¾åƒç¯¡æ”¹æ£€æµ‹èƒ½åŠ›ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `CLIPæ¨¡åž‹` `å¯¹æŠ—æ”»å‡»` `ç‰¹å¾ç©ºé—´é”™ä½` `å›¾åƒè´¨é‡è¯„ä¼°` `ç¯¡æ”¹æ£€æµ‹` `å¤šæ¨¡æ€å­¦ä¹ ` `å›¾åƒå¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. CLIPæ¨¡åž‹çš„å¤šæ¨¡æ€å¯¹é½ç‰¹æ€§ä½¿å…¶æ˜“å—æ”»å‡»ï¼ŒçŽ°æœ‰çš„å›¾åƒè´¨é‡è¯„ä¼°æŒ‡æ ‡å­˜åœ¨è„†å¼±æ€§ã€‚
2. FoCLIPæ¡†æž¶é€šè¿‡ç‰¹å¾å¯¹é½ã€åˆ†æ•°å¹³è¡¡å’Œåƒç´ ä¿æŠ¤ï¼Œåœ¨ç‰¹å¾ç©ºé—´ä¸­å®žçŽ°å›¾åƒå’Œæ–‡æœ¬çš„é”™ä½ï¼Œä»Žè€Œæ¬ºéª—CLIPæ¨¡åž‹ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒFoCLIPèƒ½æ˜¾è‘—æé«˜CLIPscoreï¼ŒåŒæ—¶ä¿æŒå›¾åƒè§†è§‰è´¨é‡ï¼Œå¹¶æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„ç¯¡æ”¹æ£€æµ‹æ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºFoCLIPï¼Œä¸€ä¸ªç”¨äºŽæ¬ºéª—åŸºäºŽCLIPçš„å›¾åƒè´¨é‡è¯„ä¼°æŒ‡æ ‡çš„ç‰¹å¾ç©ºé—´é”™ä½æ¡†æž¶ã€‚FoCLIPåŸºäºŽéšæœºæ¢¯åº¦ä¸‹é™æŠ€æœ¯ï¼Œé›†æˆäº†ä¸‰ä¸ªå…³é”®ç»„ä»¶æ¥æž„å»ºæ¬ºéª—æ ·æœ¬ï¼šç‰¹å¾å¯¹é½ï¼ˆä½œä¸ºæ ¸å¿ƒæ¨¡å—ï¼Œå‡å°‘å›¾åƒ-æ–‡æœ¬æ¨¡æ€å·®è·ï¼‰ã€åˆ†æ•°åˆ†å¸ƒå¹³è¡¡æ¨¡å—å’Œåƒç´ ä¿æŠ¤æ­£åˆ™åŒ–ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æœ€å¤§åŒ–å„ç§è¾“å…¥æç¤ºä¸‹çš„CLIPscoreé¢„æµ‹ï¼Œå³ä½¿ä»Žäººç±»æ„ŸçŸ¥è§’åº¦æ¥çœ‹ï¼Œå›¾åƒåœ¨è§†è§‰ä¸Šæ— æ³•è¯†åˆ«æˆ–ä¸Žå¯¹æŠ—æ€§æç¤ºåœ¨è¯­ä¹‰ä¸Šä¸ä¸€è‡´ã€‚åœ¨åä¸ªè‰ºæœ¯æ°ä½œæç¤ºå’ŒImageNetå­é›†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œä¼˜åŒ–çš„å›¾åƒå¯ä»¥åœ¨ä¿æŒé«˜è§†è§‰ä¿çœŸåº¦çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜CLIPscoreã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘çŽ°ç°åº¦è½¬æ¢ä¼šå¯¼è‡´æ¬ºéª—å›¾åƒä¸­æ˜¾è‘—çš„ç‰¹å¾é€€åŒ–ï¼Œè¡¨çŽ°ä¸ºCLIPscoreçš„æ˜Žæ˜¾é™ä½Žï¼ŒåŒæ—¶ä¿æŒä¸ŽåŽŸå§‹å›¾åƒçš„ç»Ÿè®¡ä¸€è‡´æ€§ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é¢œè‰²é€šé“æ•æ„Ÿæ€§é©±åŠ¨çš„ç¯¡æ”¹æ£€æµ‹æœºåˆ¶ï¼Œåœ¨æ ‡å‡†åŸºå‡†ä¸Šå®žçŽ°äº†91%çš„å‡†ç¡®çŽ‡ã€‚æ€»ä¹‹ï¼Œè¿™é¡¹å·¥ä½œä¸ºåŸºäºŽCLIPçš„å¤šæ¨¡æ€ç³»ç»Ÿä¸­çš„ç‰¹å¾é”™ä½ä»¥åŠç›¸åº”çš„é˜²å¾¡æ–¹æ³•å»ºç«‹äº†ä¸€æ¡å®žç”¨çš„é€”å¾„ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šCLIPæ¨¡åž‹åœ¨å›¾åƒè´¨é‡è¯„ä¼°ç­‰ä»»åŠ¡ä¸­è¡¨çŽ°å‡ºè‰²ï¼Œä½†å…¶ç²¾ç»†çš„å¤šæ¨¡æ€å¯¹é½ä½¿å…¶å®¹æ˜“å—åˆ°å¯¹æŠ—æ”»å‡»ã€‚çŽ°æœ‰æ–¹æ³•éš¾ä»¥åœ¨ä¿æŒå›¾åƒè§†è§‰è´¨é‡çš„åŒæ—¶ï¼Œæœ‰æ•ˆåœ°æ¬ºéª—CLIPæ¨¡åž‹ï¼Œå¯¼è‡´CLIPscoreçš„è¯¯åˆ¤ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ–¹æ³•æ¥ç³»ç»Ÿæ€§åœ°ç ”ç©¶å’Œåˆ©ç”¨CLIPæ¨¡åž‹çš„è„†å¼±æ€§ï¼Œå¹¶å¼€å‘ç›¸åº”çš„é˜²å¾¡æœºåˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFoCLIPçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åœ¨ç‰¹å¾ç©ºé—´ä¸­å¼•å…¥å›¾åƒå’Œæ–‡æœ¬ä¹‹é—´çš„é”™ä½ï¼Œä½¿å¾—å›¾åƒåœ¨è§†è§‰ä¸Šä¿æŒå¯ä¿¡çš„åŒæ—¶ï¼Œå…¶CLIPscoreè¢«æ˜¾è‘—æé«˜ã€‚è¿™ç§é”™ä½æ˜¯é€šè¿‡ä¼˜åŒ–å›¾åƒï¼Œä½¿å…¶åœ¨CLIPçš„å›¾åƒç‰¹å¾ç©ºé—´ä¸­æ›´æŽ¥è¿‘ç›®æ ‡æ–‡æœ¬çš„ç‰¹å¾è¡¨ç¤ºæ¥å®žçŽ°çš„ã€‚åŒæ—¶ï¼Œä¸ºäº†é˜²æ­¢å›¾åƒè´¨é‡è¿‡åº¦ä¸‹é™ï¼Œå¼•å…¥äº†åƒç´ ä¿æŠ¤æ­£åˆ™åŒ–ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šFoCLIPæ¡†æž¶ä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼š1) ç‰¹å¾å¯¹é½æ¨¡å—ï¼šé€šè¿‡ä¼˜åŒ–å›¾åƒï¼Œä½¿å…¶CLIPå›¾åƒç‰¹å¾ä¸Žç›®æ ‡æ–‡æœ¬ç‰¹å¾å¯¹é½ï¼Œä»Žè€Œæé«˜CLIPscoreã€‚2) åˆ†æ•°åˆ†å¸ƒå¹³è¡¡æ¨¡å—ï¼šæ—¨åœ¨å¹³è¡¡ä¸åŒæç¤ºä¸‹çš„CLIPscoreé¢„æµ‹ï¼Œé¿å…æ¨¡åž‹è¿‡åº¦ä¾èµ–ç‰¹å®šæç¤ºã€‚3) åƒç´ ä¿æŠ¤æ­£åˆ™åŒ–ï¼šé€šè¿‡çº¦æŸåƒç´ å€¼çš„å˜åŒ–ï¼Œä¿æŒå›¾åƒçš„è§†è§‰è´¨é‡ã€‚æ•´ä¸ªæµç¨‹é€šè¿‡éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰è¿›è¡Œä¼˜åŒ–ï¼Œè¿­ä»£æ›´æ–°å›¾åƒï¼Œç›´åˆ°æ»¡è¶³é¢„è®¾çš„CLIPscoreç›®æ ‡æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šFoCLIPçš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ä¸ªç‰¹å¾ç©ºé—´é”™ä½æ¡†æž¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æ¬ºéª—CLIPæ¨¡åž‹ï¼ŒåŒæ—¶ä¿æŒå›¾åƒçš„è§†è§‰è´¨é‡ã€‚ä¸Žä¼ ç»Ÿçš„å¯¹æŠ—æ”»å‡»æ–¹æ³•ä¸åŒï¼ŒFoCLIPç›´æŽ¥åœ¨CLIPçš„ç‰¹å¾ç©ºé—´ä¸­è¿›è¡Œæ“ä½œï¼Œé¿å…äº†å¯¹åƒç´ ç©ºé—´çš„ç›´æŽ¥å¹²æ‰°ï¼Œä»Žè€Œæ›´å¥½åœ°ä¿æŒäº†å›¾åƒçš„è§†è§‰ä¿çœŸåº¦ã€‚æ­¤å¤–ï¼Œæå‡ºçš„é¢œè‰²é€šé“æ•æ„Ÿæ€§é©±åŠ¨çš„ç¯¡æ”¹æ£€æµ‹æœºåˆ¶ï¼Œä¸ºé˜²å¾¡åŸºäºŽCLIPçš„æ”»å‡»æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯ã€‚

**å…³é”®è®¾è®¡**ï¼šç‰¹å¾å¯¹é½æ¨¡å—ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œè¡¡é‡å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾ä¹‹é—´çš„è·ç¦»ã€‚åˆ†æ•°åˆ†å¸ƒå¹³è¡¡æ¨¡å—ä½¿ç”¨KLæ•£åº¦ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œçº¦æŸä¸åŒæç¤ºä¸‹çš„CLIPscoreåˆ†å¸ƒã€‚åƒç´ ä¿æŠ¤æ­£åˆ™åŒ–ä½¿ç”¨L2èŒƒæ•°ï¼Œé™åˆ¶åƒç´ å€¼çš„å˜åŒ–å¹…åº¦ã€‚é¢œè‰²é€šé“æ•æ„Ÿæ€§åˆ†æžé€šè¿‡ç°åº¦è½¬æ¢æ¥è¯„ä¼°ä¸åŒé¢œè‰²é€šé“å¯¹CLIPscoreçš„å½±å“ï¼Œå¹¶ä»¥æ­¤ä¸ºåŸºç¡€è®¾è®¡ç¯¡æ”¹æ£€æµ‹å™¨ã€‚å…·ä½“å‚æ•°è®¾ç½®ï¼ˆå¦‚å­¦ä¹ çŽ‡ã€æ­£åˆ™åŒ–ç³»æ•°ç­‰ï¼‰æ ¹æ®å®žéªŒç»“æžœè¿›è¡Œè°ƒæ•´ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒFoCLIPèƒ½å¤Ÿæ˜¾è‘—æé«˜å›¾åƒçš„CLIPscoreï¼ŒåŒæ—¶ä¿æŒè¾ƒé«˜çš„è§†è§‰è´¨é‡ã€‚åœ¨è‰ºæœ¯æ°ä½œæç¤ºå’ŒImageNetå­é›†ä¸Šï¼Œä¼˜åŒ–åŽçš„å›¾åƒCLIPscoreå¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚æ­¤å¤–ï¼Œæå‡ºçš„é¢œè‰²é€šé“æ•æ„Ÿæ€§é©±åŠ¨çš„ç¯¡æ”¹æ£€æµ‹æœºåˆ¶åœ¨æ ‡å‡†åŸºå‡†ä¸Šå®žçŽ°äº†91%çš„å‡†ç¡®çŽ‡ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

FoCLIPçš„ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽè¯„ä¼°å’Œæé«˜å¤šæ¨¡æ€æ¨¡åž‹çš„å®‰å…¨æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å›¾åƒè´¨é‡è¯„ä¼°ã€å›¾åƒæ£€ç´¢å’Œå†…å®¹å®¡æ ¸ç­‰é¢†åŸŸã€‚é€šè¿‡ç†è§£å’Œé˜²å¾¡é’ˆå¯¹CLIPæ¨¡åž‹çš„æ”»å‡»ï¼Œå¯ä»¥æå‡è¿™äº›åº”ç”¨åœ¨å¯¹æŠ—çŽ¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æå‡ºçš„ç¯¡æ”¹æ£€æµ‹æ–¹æ³•å¯ä»¥ç”¨äºŽè¯†åˆ«æ¶æ„ç¯¡æ”¹çš„å›¾åƒï¼Œä¿æŠ¤ç”¨æˆ·å…å—è™šå‡ä¿¡æ¯çš„ä¾µå®³ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The well-aligned attribute of CLIP-based models enables its effective application like CLIPscore as a widely adopted image quality assessment metric. However, such a CLIP-based metric is vulnerable for its delicate multimodal alignment. In this work, we propose \textbf{FoCLIP}, a feature-space misalignment framework for fooling CLIP-based image quality metric. Based on the stochastic gradient descent technique, FoCLIP integrates three key components to construct fooling examples: feature alignment as the core module to reduce image-text modality gaps, the score distribution balance module and pixel-guard regularization, which collectively optimize multimodal output equilibrium between CLIPscore performance and image quality. Such a design can be engineered to maximize the CLIPscore predictions across diverse input prompts, despite exhibiting either visual unrecognizability or semantic incongruence with the corresponding adversarial prompts from human perceptual perspectives. Experiments on ten artistic masterpiece prompts and ImageNet subsets demonstrate that optimized images can achieve significant improvement in CLIPscore while preserving high visual fidelity. In addition, we found that grayscale conversion induces significant feature degradation in fooling images, exhibiting noticeable CLIPscore reduction while preserving statistical consistency with original images. Inspired by this phenomenon, we propose a color channel sensitivity-driven tampering detection mechanism that achieves 91% accuracy on standard benchmarks. In conclusion, this work establishes a practical pathway for feature misalignment in CLIP-based multimodal systems and the corresponding defense method.

