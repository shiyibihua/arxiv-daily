---
layout: default
title: FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image Manipulation and Detection
---

# FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image Manipulation and Detection

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.06947" target="_blank" class="toolbar-btn">arXiv: 2511.06947v1</a>
    <a href="https://arxiv.org/pdf/2511.06947.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.06947v1" 
            onclick="toggleFavorite(this, '2511.06947v1', 'FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image Manipulation and Detection')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yulin Chen, Zeyuan Wang, Tianyuan Yu, Yingmei Wei, Liang Bai

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-10

**Â§áÊ≥®**: 15 page, 9 figures, published to PRCV

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫FoCLIPÊ°ÜÊû∂ÔºåÈÄöËøáÁâπÂæÅÁ©∫Èó¥Èîô‰ΩçÊîªÂáªÂíåÈò≤Âæ°CLIPÊ®°ÂûãÔºåÊèêÂçáÂõæÂÉèÁØ°ÊîπÊ£ÄÊµãËÉΩÂäõ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `CLIPÊ®°Âûã` `ÂØπÊäóÊîªÂáª` `ÁâπÂæÅÁ©∫Èó¥Èîô‰Ωç` `ÂõæÂÉèË¥®ÈáèËØÑ‰º∞` `ÁØ°ÊîπÊ£ÄÊµã` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ÂõæÂÉèÂ§ÑÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. CLIPÊ®°ÂûãÁöÑÂ§öÊ®°ÊÄÅÂØπÈΩêÁâπÊÄß‰ΩøÂÖ∂ÊòìÂèóÊîªÂáªÔºåÁé∞ÊúâÁöÑÂõæÂÉèË¥®ÈáèËØÑ‰º∞ÊåáÊ†áÂ≠òÂú®ËÑÜÂº±ÊÄß„ÄÇ
2. FoCLIPÊ°ÜÊû∂ÈÄöËøáÁâπÂæÅÂØπÈΩê„ÄÅÂàÜÊï∞Âπ≥Ë°°ÂíåÂÉèÁ¥†‰øùÊä§ÔºåÂú®ÁâπÂæÅÁ©∫Èó¥‰∏≠ÂÆûÁé∞ÂõæÂÉèÂíåÊñáÊú¨ÁöÑÈîô‰ΩçÔºå‰ªéËÄåÊ¨∫È™óCLIPÊ®°Âûã„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåFoCLIPËÉΩÊòæËëóÊèêÈ´òCLIPscoreÔºåÂêåÊó∂‰øùÊåÅÂõæÂÉèËßÜËßâË¥®ÈáèÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊúâÊïàÁöÑÁØ°ÊîπÊ£ÄÊµãÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫FoCLIPÔºå‰∏Ä‰∏™Áî®‰∫éÊ¨∫È™óÂü∫‰∫éCLIPÁöÑÂõæÂÉèË¥®ÈáèËØÑ‰º∞ÊåáÊ†áÁöÑÁâπÂæÅÁ©∫Èó¥Èîô‰ΩçÊ°ÜÊû∂„ÄÇFoCLIPÂü∫‰∫éÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÊäÄÊúØÔºåÈõÜÊàê‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÁªÑ‰ª∂Êù•ÊûÑÂª∫Ê¨∫È™óÊ†∑Êú¨ÔºöÁâπÂæÅÂØπÈΩêÔºà‰Ωú‰∏∫Ê†∏ÂøÉÊ®°ÂùóÔºåÂáèÂ∞ëÂõæÂÉè-ÊñáÊú¨Ê®°ÊÄÅÂ∑ÆË∑ùÔºâ„ÄÅÂàÜÊï∞ÂàÜÂ∏ÉÂπ≥Ë°°Ê®°ÂùóÂíåÂÉèÁ¥†‰øùÊä§Ê≠£ÂàôÂåñ„ÄÇËøôÁßçËÆæËÆ°Êó®Âú®ÊúÄÂ§ßÂåñÂêÑÁßçËæìÂÖ•ÊèêÁ§∫‰∏ãÁöÑCLIPscoreÈ¢ÑÊµãÔºåÂç≥‰Ωø‰ªé‰∫∫Á±ªÊÑüÁü•ËßíÂ∫¶Êù•ÁúãÔºåÂõæÂÉèÂú®ËßÜËßâ‰∏äÊó†Ê≥ïËØÜÂà´Êàñ‰∏éÂØπÊäóÊÄßÊèêÁ§∫Âú®ËØ≠‰πâ‰∏ä‰∏ç‰∏ÄËá¥„ÄÇÂú®ÂçÅ‰∏™Ëâ∫ÊúØÊù∞‰ΩúÊèêÁ§∫ÂíåImageNetÂ≠êÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºå‰ºòÂåñÁöÑÂõæÂÉèÂèØ‰ª•Âú®‰øùÊåÅÈ´òËßÜËßâ‰øùÁúüÂ∫¶ÁöÑÂêåÊó∂ÔºåÊòæËëóÊèêÈ´òCLIPscore„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂèëÁé∞ÁÅ∞Â∫¶ËΩ¨Êç¢‰ºöÂØºËá¥Ê¨∫È™óÂõæÂÉè‰∏≠ÊòæËëóÁöÑÁâπÂæÅÈÄÄÂåñÔºåË°®Áé∞‰∏∫CLIPscoreÁöÑÊòéÊòæÈôç‰ΩéÔºåÂêåÊó∂‰øùÊåÅ‰∏éÂéüÂßãÂõæÂÉèÁöÑÁªüËÆ°‰∏ÄËá¥ÊÄß„ÄÇÂèóÊ≠§ÂêØÂèëÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÈ¢úËâ≤ÈÄöÈÅìÊïèÊÑüÊÄßÈ©±Âä®ÁöÑÁØ°ÊîπÊ£ÄÊµãÊú∫Âà∂ÔºåÂú®Ê†áÂáÜÂü∫ÂáÜ‰∏äÂÆûÁé∞‰∫Ü91%ÁöÑÂáÜÁ°ÆÁéá„ÄÇÊÄª‰πãÔºåËøôÈ°πÂ∑•‰Ωú‰∏∫Âü∫‰∫éCLIPÁöÑÂ§öÊ®°ÊÄÅÁ≥ªÁªü‰∏≠ÁöÑÁâπÂæÅÈîô‰Ωç‰ª•ÂèäÁõ∏Â∫îÁöÑÈò≤Âæ°ÊñπÊ≥ïÂª∫Á´ã‰∫Ü‰∏ÄÊù°ÂÆûÁî®ÁöÑÈÄîÂæÑ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöCLIPÊ®°ÂûãÂú®ÂõæÂÉèË¥®ÈáèËØÑ‰º∞Á≠â‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂÖ∂Á≤æÁªÜÁöÑÂ§öÊ®°ÊÄÅÂØπÈΩê‰ΩøÂÖ∂ÂÆπÊòìÂèóÂà∞ÂØπÊäóÊîªÂáª„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•Âú®‰øùÊåÅÂõæÂÉèËßÜËßâË¥®ÈáèÁöÑÂêåÊó∂ÔºåÊúâÊïàÂú∞Ê¨∫È™óCLIPÊ®°ÂûãÔºåÂØºËá¥CLIPscoreÁöÑËØØÂà§„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶Å‰∏ÄÁßçÊñπÊ≥ïÊù•Á≥ªÁªüÊÄßÂú∞Á†îÁ©∂ÂíåÂà©Áî®CLIPÊ®°ÂûãÁöÑËÑÜÂº±ÊÄßÔºåÂπ∂ÂºÄÂèëÁõ∏Â∫îÁöÑÈò≤Âæ°Êú∫Âà∂„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöFoCLIPÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂú®ÁâπÂæÅÁ©∫Èó¥‰∏≠ÂºïÂÖ•ÂõæÂÉèÂíåÊñáÊú¨‰πãÈó¥ÁöÑÈîô‰ΩçÔºå‰ΩøÂæóÂõæÂÉèÂú®ËßÜËßâ‰∏ä‰øùÊåÅÂèØ‰ø°ÁöÑÂêåÊó∂ÔºåÂÖ∂CLIPscoreË¢´ÊòæËëóÊèêÈ´ò„ÄÇËøôÁßçÈîô‰ΩçÊòØÈÄöËøá‰ºòÂåñÂõæÂÉèÔºå‰ΩøÂÖ∂Âú®CLIPÁöÑÂõæÂÉèÁâπÂæÅÁ©∫Èó¥‰∏≠Êõ¥Êé•ËøëÁõÆÊ†áÊñáÊú¨ÁöÑÁâπÂæÅË°®Á§∫Êù•ÂÆûÁé∞ÁöÑ„ÄÇÂêåÊó∂Ôºå‰∏∫‰∫ÜÈò≤Ê≠¢ÂõæÂÉèË¥®ÈáèËøáÂ∫¶‰∏ãÈôçÔºåÂºïÂÖ•‰∫ÜÂÉèÁ¥†‰øùÊä§Ê≠£ÂàôÂåñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöFoCLIPÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏â‰∏™Ê®°ÂùóÔºö1) ÁâπÂæÅÂØπÈΩêÊ®°ÂùóÔºöÈÄöËøá‰ºòÂåñÂõæÂÉèÔºå‰ΩøÂÖ∂CLIPÂõæÂÉèÁâπÂæÅ‰∏éÁõÆÊ†áÊñáÊú¨ÁâπÂæÅÂØπÈΩêÔºå‰ªéËÄåÊèêÈ´òCLIPscore„ÄÇ2) ÂàÜÊï∞ÂàÜÂ∏ÉÂπ≥Ë°°Ê®°ÂùóÔºöÊó®Âú®Âπ≥Ë°°‰∏çÂêåÊèêÁ§∫‰∏ãÁöÑCLIPscoreÈ¢ÑÊµãÔºåÈÅøÂÖçÊ®°ÂûãËøáÂ∫¶‰æùËµñÁâπÂÆöÊèêÁ§∫„ÄÇ3) ÂÉèÁ¥†‰øùÊä§Ê≠£ÂàôÂåñÔºöÈÄöËøáÁ∫¶ÊùüÂÉèÁ¥†ÂÄºÁöÑÂèòÂåñÔºå‰øùÊåÅÂõæÂÉèÁöÑËßÜËßâË¥®Èáè„ÄÇÊï¥‰∏™ÊµÅÁ®ãÈÄöËøáÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÔºàSGDÔºâËøõË°å‰ºòÂåñÔºåËø≠‰ª£Êõ¥Êñ∞ÂõæÂÉèÔºåÁõ¥Âà∞Êª°Ë∂≥È¢ÑËÆæÁöÑCLIPscoreÁõÆÊ†áÊàñËææÂà∞ÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöFoCLIPÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÁâπÂæÅÁ©∫Èó¥Èîô‰ΩçÊ°ÜÊû∂ÔºåËÉΩÂ§üÊúâÊïàÂú∞Ê¨∫È™óCLIPÊ®°ÂûãÔºåÂêåÊó∂‰øùÊåÅÂõæÂÉèÁöÑËßÜËßâË¥®Èáè„ÄÇ‰∏é‰º†ÁªüÁöÑÂØπÊäóÊîªÂáªÊñπÊ≥ï‰∏çÂêåÔºåFoCLIPÁõ¥Êé•Âú®CLIPÁöÑÁâπÂæÅÁ©∫Èó¥‰∏≠ËøõË°åÊìç‰ΩúÔºåÈÅøÂÖç‰∫ÜÂØπÂÉèÁ¥†Á©∫Èó¥ÁöÑÁõ¥Êé•Âπ≤Êâ∞Ôºå‰ªéËÄåÊõ¥Â•ΩÂú∞‰øùÊåÅ‰∫ÜÂõæÂÉèÁöÑËßÜËßâ‰øùÁúüÂ∫¶„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫ÁöÑÈ¢úËâ≤ÈÄöÈÅìÊïèÊÑüÊÄßÈ©±Âä®ÁöÑÁØ°ÊîπÊ£ÄÊµãÊú∫Âà∂Ôºå‰∏∫Èò≤Âæ°Âü∫‰∫éCLIPÁöÑÊîªÂáªÊèê‰æõ‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊÄùË∑Ø„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÁâπÂæÅÂØπÈΩêÊ®°Âùó‰ΩøÁî®‰ΩôÂº¶Áõ∏‰ººÂ∫¶‰Ωú‰∏∫ÊçüÂ§±ÂáΩÊï∞ÔºåË°°ÈáèÂõæÂÉèÂíåÊñáÊú¨ÁâπÂæÅ‰πãÈó¥ÁöÑË∑ùÁ¶ª„ÄÇÂàÜÊï∞ÂàÜÂ∏ÉÂπ≥Ë°°Ê®°Âùó‰ΩøÁî®KLÊï£Â∫¶‰Ωú‰∏∫ÊçüÂ§±ÂáΩÊï∞ÔºåÁ∫¶Êùü‰∏çÂêåÊèêÁ§∫‰∏ãÁöÑCLIPscoreÂàÜÂ∏É„ÄÇÂÉèÁ¥†‰øùÊä§Ê≠£ÂàôÂåñ‰ΩøÁî®L2ËåÉÊï∞ÔºåÈôêÂà∂ÂÉèÁ¥†ÂÄºÁöÑÂèòÂåñÂπÖÂ∫¶„ÄÇÈ¢úËâ≤ÈÄöÈÅìÊïèÊÑüÊÄßÂàÜÊûêÈÄöËøáÁÅ∞Â∫¶ËΩ¨Êç¢Êù•ËØÑ‰º∞‰∏çÂêåÈ¢úËâ≤ÈÄöÈÅìÂØπCLIPscoreÁöÑÂΩ±ÂìçÔºåÂπ∂‰ª•Ê≠§‰∏∫Âü∫Á°ÄËÆæËÆ°ÁØ°ÊîπÊ£ÄÊµãÂô®„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÔºàÂ¶ÇÂ≠¶‰π†Áéá„ÄÅÊ≠£ÂàôÂåñÁ≥ªÊï∞Á≠âÔºâÊ†πÊçÆÂÆûÈ™åÁªìÊûúËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåFoCLIPËÉΩÂ§üÊòæËëóÊèêÈ´òÂõæÂÉèÁöÑCLIPscoreÔºåÂêåÊó∂‰øùÊåÅËæÉÈ´òÁöÑËßÜËßâË¥®Èáè„ÄÇÂú®Ëâ∫ÊúØÊù∞‰ΩúÊèêÁ§∫ÂíåImageNetÂ≠êÈõÜ‰∏äÔºå‰ºòÂåñÂêéÁöÑÂõæÂÉèCLIPscoreÂæóÂà∞‰∫ÜÊòæËëóÊèêÂçá„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫ÁöÑÈ¢úËâ≤ÈÄöÈÅìÊïèÊÑüÊÄßÈ©±Âä®ÁöÑÁØ°ÊîπÊ£ÄÊµãÊú∫Âà∂Âú®Ê†áÂáÜÂü∫ÂáÜ‰∏äÂÆûÁé∞‰∫Ü91%ÁöÑÂáÜÁ°ÆÁéáÔºåÈ™åËØÅ‰∫ÜËØ•ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

FoCLIPÁöÑÁ†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËØÑ‰º∞ÂíåÊèêÈ´òÂ§öÊ®°ÊÄÅÊ®°ÂûãÁöÑÂÆâÂÖ®ÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂõæÂÉèË¥®ÈáèËØÑ‰º∞„ÄÅÂõæÂÉèÊ£ÄÁ¥¢ÂíåÂÜÖÂÆπÂÆ°Ê†∏Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÁêÜËß£ÂíåÈò≤Âæ°ÈíàÂØπCLIPÊ®°ÂûãÁöÑÊîªÂáªÔºåÂèØ‰ª•ÊèêÂçáËøô‰∫õÂ∫îÁî®Âú®ÂØπÊäóÁéØÂ¢É‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•Á†îÁ©∂ÊèêÂá∫ÁöÑÁØ°ÊîπÊ£ÄÊµãÊñπÊ≥ïÂèØ‰ª•Áî®‰∫éËØÜÂà´ÊÅ∂ÊÑèÁØ°ÊîπÁöÑÂõæÂÉèÔºå‰øùÊä§Áî®Êà∑ÂÖçÂèóËôöÂÅá‰ø°ÊÅØÁöÑ‰æµÂÆ≥„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The well-aligned attribute of CLIP-based models enables its effective application like CLIPscore as a widely adopted image quality assessment metric. However, such a CLIP-based metric is vulnerable for its delicate multimodal alignment. In this work, we propose \textbf{FoCLIP}, a feature-space misalignment framework for fooling CLIP-based image quality metric. Based on the stochastic gradient descent technique, FoCLIP integrates three key components to construct fooling examples: feature alignment as the core module to reduce image-text modality gaps, the score distribution balance module and pixel-guard regularization, which collectively optimize multimodal output equilibrium between CLIPscore performance and image quality. Such a design can be engineered to maximize the CLIPscore predictions across diverse input prompts, despite exhibiting either visual unrecognizability or semantic incongruence with the corresponding adversarial prompts from human perceptual perspectives. Experiments on ten artistic masterpiece prompts and ImageNet subsets demonstrate that optimized images can achieve significant improvement in CLIPscore while preserving high visual fidelity. In addition, we found that grayscale conversion induces significant feature degradation in fooling images, exhibiting noticeable CLIPscore reduction while preserving statistical consistency with original images. Inspired by this phenomenon, we propose a color channel sensitivity-driven tampering detection mechanism that achieves 91% accuracy on standard benchmarks. In conclusion, this work establishes a practical pathway for feature misalignment in CLIP-based multimodal systems and the corresponding defense method.

