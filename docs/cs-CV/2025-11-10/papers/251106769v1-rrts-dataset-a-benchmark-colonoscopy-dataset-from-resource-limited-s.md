---
layout: default
title: RRTS Dataset: A Benchmark Colonoscopy Dataset from Resource-Limited Settings for Computer-Aided Diagnosis Research
---

# RRTS Dataset: A Benchmark Colonoscopy Dataset from Resource-Limited Settings for Computer-Aided Diagnosis Research

**arXiv**: [2511.06769v1](https://arxiv.org/abs/2511.06769) | [PDF](https://arxiv.org/pdf/2511.06769.pdf)

**ä½œè€…**: Ridoy Chandra Shil, Ragib Abid, Tasnia Binte Mamun, Samiul Based Shuvo, Masfique Ahmed Bhuiyan, Jahid Ferdous

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBUETæ¯è‚‰æ•°æ®é›†ä»¥è§£å†³èµ„æºå—é™çŽ¯å¢ƒä¸‹ç»“è‚ é•œå›¾åƒè¯Šæ–­çš„å¤æ‚æ€§æŒ‘æˆ˜**

**å…³é”®è¯**: `ç»“è‚ é•œæ•°æ®é›†` `æ¯è‚‰æ£€æµ‹` `è®¡ç®—æœºè¾…åŠ©è¯Šæ–­` `å›¾åƒåˆ†å‰²` `çœŸå®žä¸–ç•Œä¼ªå½±` `åŸºå‡†æµ‹è¯•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ç»“è‚ é•œæ•°æ®é›†æ ·æœ¬å°ã€å›¾åƒç²¾é€‰ï¼Œç¼ºä¹çœŸå®žä¸–ç•Œä¼ªå½±ï¼Œéš¾ä»¥æ”¯æŒä¸´åºŠå®žè·µã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ”¶é›†1,288å¼ æ¯è‚‰å›¾åƒå’Œ1,657å¼ æ— æ¯è‚‰å›¾åƒï¼ŒåŒ…å«è¿åŠ¨æ¨¡ç³Šç­‰å¤šæ ·ä¼ªå½±ï¼Œä¸“å®¶æ ‡æ³¨æŽ©ç ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåŸºå‡†æµ‹è¯•æ˜¾ç¤ºåˆ†ç±»å‡†ç¡®çŽ‡æœ€é«˜90.8%ï¼Œåˆ†å‰²Diceåˆ†æ•°æœ€é«˜0.64ï¼Œåæ˜ çœŸå®žä¸–ç•Œéš¾åº¦ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Background and Objective: Colorectal cancer prevention relies on early
> detection of polyps during colonoscopy. Existing public datasets, such as
> CVC-ClinicDB and Kvasir-SEG, provide valuable benchmarks but are limited by
> small sample sizes, curated image selection, or lack of real-world artifacts.
> There remains a need for datasets that capture the complexity of clinical
> practice, particularly in resource-constrained settings. Methods: We introduce
> a dataset, BUET Polyp Dataset (BPD), of colonoscopy images collected using
> Olympus 170 and Pen- tax i-Scan series endoscopes under routine clinical
> conditions. The dataset contains images with corresponding expert-annotated
> binary masks, reflecting diverse challenges such as motion blur, specular
> highlights, stool artifacts, blood, and low-light frames. Annotations were
> manually reviewed by clinical experts to ensure quality. To demonstrate
> baseline performance, we provide bench- mark results for classification using
> VGG16, ResNet50, and InceptionV3, and for segmentation using UNet variants with
> VGG16, ResNet34, and InceptionV4 backbones. Results: The dataset comprises
> 1,288 images with polyps from 164 patients with corresponding ground-truth
> masks and 1,657 polyp-free images from 31 patients. Benchmarking experiments
> achieved up to 90.8% accuracy for binary classification (VGG16) and a maximum
> Dice score of 0.64 with InceptionV4-UNet for segmentation. Performance was
> lower compared to curated datasets, reflecting the real-world difficulty of
> images with artifacts and variable quality.

