---
layout: default
title: Flexible Concept Bottleneck Model
---

# Flexible Concept Bottleneck Model

**arXiv**: [2511.06678v1](https://arxiv.org/abs/2511.06678) | [PDF](https://arxiv.org/pdf/2511.06678.pdf)

**ä½œè€…**: Xingbo Du, Qiantong Dou, Lei Fan, Rui Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºçµæ´»æ¦‚å¿µç“¶é¢ˆæ¨¡åž‹ä»¥è§£å†³åŠ¨æ€æ¦‚å¿µé€‚åº”é—®é¢˜**

**å…³é”®è¯**: `æ¦‚å¿µç“¶é¢ˆæ¨¡åž‹` `è§†è§‰è¯­è¨€æ¨¡åž‹` `åŠ¨æ€æ¦‚å¿µé€‚åº”` `è¶…ç½‘ç»œ` `ç¨€ç–æœ€å¤§æ¨¡å—`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŸºäºŽè§†è§‰è¯­è¨€æ¨¡åž‹çš„æ¦‚å¿µç“¶é¢ˆæ¨¡åž‹åœ¨å¼•å…¥æ–°æ¦‚å¿µæ—¶éœ€å®Œå…¨é‡è®­ç»ƒï¼Œé™åˆ¶çµæ´»æ€§
2. è®¾è®¡è¶…ç½‘ç»œåŸºäºŽæ¦‚å¿µåµŒå…¥ç”Ÿæˆé¢„æµ‹æƒé‡ï¼Œæ— éœ€é‡è®­ç»ƒå³å¯æ•´åˆæ–°æ¦‚å¿µ
3. åœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°ä¸Žå…ˆè¿›åŸºçº¿ç›¸å½“çš„å‡†ç¡®çŽ‡ï¼Œå¹¶å±•ç¤ºå¯¹æœªè§æ¦‚å¿µçš„å¼ºé€‚åº”æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Concept bottleneck models (CBMs) improve neural network interpretability by
> introducing an intermediate layer that maps human-understandable concepts to
> predictions. Recent work has explored the use of vision-language models (VLMs)
> to automate concept selection and annotation. However, existing VLM-based CBMs
> typically require full model retraining when new concepts are involved, which
> limits their adaptability and flexibility in real-world scenarios, especially
> considering the rapid evolution of vision-language foundation models. To
> address these issues, we propose Flexible Concept Bottleneck Model (FCBM),
> which supports dynamic concept adaptation, including complete replacement of
> the original concept set. Specifically, we design a hypernetwork that generates
> prediction weights based on concept embeddings, allowing seamless integration
> of new concepts without retraining the entire model. In addition, we introduce
> a modified sparsemax module with a learnable temperature parameter that
> dynamically selects the most relevant concepts, enabling the model to focus on
> the most informative features. Extensive experiments on five public benchmarks
> demonstrate that our method achieves accuracy comparable to state-of-the-art
> baselines with a similar number of effective concepts. Moreover, the model
> generalizes well to unseen concepts with just a single epoch of fine-tuning,
> demonstrating its strong adaptability and flexibility.

