---
layout: default
title: Dynamics-Decoupled Trajectory Alignment for Sim-to-Real Transfer in Reinforcement Learning for Autonomous Driving
---

# Dynamics-Decoupled Trajectory Alignment for Sim-to-Real Transfer in Reinforcement Learning for Autonomous Driving

**arXiv**: [2511.07155v1](https://arxiv.org/abs/2511.07155) | [PDF](https://arxiv.org/pdf/2511.07155.pdf)

**ä½œè€…**: Thomas Steinecker, Alexander Bienemann, Denis Trescher, Thorsten Luettel, Mirko Maehlisch

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŠ¨æ€è§£è€¦è½¨è¿¹å¯¹é½æ¡†æž¶ï¼Œå®žçŽ°å¼ºåŒ–å­¦ä¹ åœ¨è‡ªåŠ¨é©¾é©¶ä¸­çš„é›¶æ ·æœ¬ä»¿çœŸåˆ°çŽ°å®žè¿ç§»**

**å…³é”®è¯**: `ä»¿çœŸåˆ°çŽ°å®žè¿ç§»` `å¼ºåŒ–å­¦ä¹ ` `è‡ªåŠ¨é©¾é©¶` `è½¨è¿¹å¯¹é½` `åŠ¨æ€è§£è€¦` `é›¶æ ·æœ¬å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä»¿çœŸä¸ŽçŽ°å®žé—´è½¦è¾†åŠ¨æ€ä¸åŒ¹é…ï¼Œé˜»ç¢å¼ºåŒ–å­¦ä¹ ä»£ç†ç›´æŽ¥éƒ¨ç½²
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æ—¶ç©ºå¯¹é½ç­–ç•¥ï¼Œå°†è¿åŠ¨è§„åˆ’ä¸ŽæŽ§åˆ¶è§£è€¦ï¼Œä½¿ç”¨è’¸é¦è½¨è¿¹é¢„æµ‹å’ŒStanleyæŽ§åˆ¶å™¨
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žè½¦è¾†ä¸ŠéªŒè¯ï¼Œå®žçŽ°é›¶æ ·æœ¬è¿ç§»ï¼Œæå‡é²æ£’æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reinforcement learning (RL) has shown promise in robotics, but deploying RL
> on real vehicles remains challenging due to the complexity of vehicle dynamics
> and the mismatch between simulation and reality. Factors such as tire
> characteristics, road surface conditions, aerodynamic disturbances, and vehicle
> load make it infeasible to model real-world dynamics accurately, which hinders
> direct transfer of RL agents trained in simulation. In this paper, we present a
> framework that decouples motion planning from vehicle control through a spatial
> and temporal alignment strategy between a virtual vehicle and the real system.
> An RL agent is first trained in simulation using a kinematic bicycle model to
> output continuous control actions. Its behavior is then distilled into a
> trajectory-predicting agent that generates finite-horizon ego-vehicle
> trajectories, enabling synchronization between virtual and real vehicles. At
> deployment, a Stanley controller governs lateral dynamics, while longitudinal
> alignment is maintained through adaptive update mechanisms that compensate for
> deviations between virtual and real trajectories. We validate our approach on a
> real vehicle and demonstrate that the proposed alignment strategy enables
> robust zero-shot transfer of RL-based motion planning from simulation to
> reality, successfully decoupling high-level trajectory generation from
> low-level vehicle control.

