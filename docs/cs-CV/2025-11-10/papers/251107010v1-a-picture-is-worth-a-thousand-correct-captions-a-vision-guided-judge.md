---
layout: default
title: A Picture is Worth a Thousand (Correct) Captions: A Vision-Guided Judge-Corrector System for Multimodal Machine Translation
---

# A Picture is Worth a Thousand (Correct) Captions: A Vision-Guided Judge-Corrector System for Multimodal Machine Translation

**arXiv**: [2511.07010v1](https://arxiv.org/abs/2511.07010) | [PDF](https://arxiv.org/pdf/2511.07010.pdf)

**ä½œè€…**: Siddharth Betala, Kushan Raj, Vipul Betala, Rohan Saswade

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§†è§‰å¼•å¯¼çš„è¯„åˆ¤-çº æ­£ç³»ç»Ÿï¼Œé€šè¿‡è‡ªåŠ¨é”™è¯¯æ£€æµ‹ä¸Žçº æ­£æå‡å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘è´¨é‡ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘` `é”™è¯¯æ£€æµ‹ä¸Žçº æ­£` `å‚æ•°é«˜æ•ˆå¾®è°ƒ` `è§†è§‰å¼•å¯¼ç³»ç»Ÿ` `BLEUåˆ†æ•°è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè®­ç»ƒæ•°æ®ä¸­å­˜åœ¨ç¿»è¯‘é”™è¯¯å’Œè§†è§‰æ­§ä¹‰ï¼Œå½±å“å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘æ€§èƒ½ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å¤šæ¨¡æ€è¯­è¨€æ¨¡åž‹åˆ†ç±»ç¿»è¯‘é”™è¯¯ï¼Œå¹¶è·¯ç”±åˆ°GPT-4o-miniæˆ–IndicTrans2è¿›è¡Œçº æ­£ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨è‹±è¯­-å­ŸåŠ æ‹‰è¯­ç­‰è¯­è¨€å¯¹ä¸Šï¼ŒBLEUåˆ†æ•°å¹³å‡æå‡0.10è‡³1.30ç‚¹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this paper, we describe our system under the team name BLEU Monday for the
> English-to-Indic Multimodal Translation Task at WAT 2025. We participate in the
> text-only translation tasks for English-Hindi, English-Bengali,
> English-Malayalam, and English-Odia language pairs. We present a two-stage
> approach that addresses quality issues in the training data through automated
> error detection and correction, followed by parameter-efficient model
> fine-tuning.
>   Our methodology introduces a vision-augmented judge-corrector pipeline that
> leverages multimodal language models to systematically identify and correct
> translation errors in the training data. The judge component classifies
> translations into three categories: correct, visually ambiguous (requiring
> image context), or mistranslated (poor translation quality). Identified errors
> are routed to specialized correctors: GPT-4o-mini regenerates captions
> requiring visual disambiguation, while IndicTrans2 retranslates cases with pure
> translation quality issues. This automated pipeline processes 28,928 training
> examples across four languages, correcting an average of 17.1% of captions per
> language.
>   We then apply Low-Rank Adaptation (LoRA) to fine-tune the IndicTrans2
> en-indic 200M distilled model on both original and corrected datasets. Training
> on corrected data yields consistent improvements, with BLEU score gains of
> +1.30 for English-Bengali on the evaluation set (42.00 -> 43.30) and +0.70 on
> the challenge set (44.90 -> 45.60), +0.60 for English-Odia on the evaluation
> set (41.00 -> 41.60), and +0.10 for English-Hindi on the challenge set (53.90
> -> 54.00).

