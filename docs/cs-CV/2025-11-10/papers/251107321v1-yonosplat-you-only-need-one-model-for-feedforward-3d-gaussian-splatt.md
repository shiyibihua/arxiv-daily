---
layout: default
title: YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting
---

# YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting

**arXiv**: [2511.07321v1](https://arxiv.org/abs/2511.07321) | [PDF](https://arxiv.org/pdf/2511.07321.pdf)

**ä½œè€…**: Botao Ye, Boqi Chen, Haofei Xu, Daniel Barath, Marc Pollefeys

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºYoNoSplatå‰é¦ˆæ¨¡åž‹ä»¥ä»Žä»»æ„å›¾åƒé‡å»ºé«˜è´¨é‡3Dé«˜æ–¯æº…å°„è¡¨ç¤º**

**å…³é”®è¯**: `3Dé«˜æ–¯æº…å°„` `ç›¸æœºå§¿æ€ä¼°è®¡` `å‰é¦ˆæ¨¡åž‹` `æ— æ ‡å®šè¾“å…¥` `åœºæ™¯é‡å»º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä»Žæ— ç»“æž„å›¾åƒé›†åˆå¿«é€Ÿçµæ´»é‡å»º3Dåœºæ™¯ä»å…·æŒ‘æˆ˜æ€§
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ··åˆè®­ç»ƒç­–ç•¥è”åˆå­¦ä¹ 3Dé«˜æ–¯å’Œç›¸æœºå‚æ•°ï¼Œé¿å…è®­ç»ƒä¸ç¨³å®š
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­å®žçŽ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œé‡å»º100è§†å›¾ä»…éœ€2.69ç§’

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Fast and flexible 3D scene reconstruction from unstructured image collections
> remains a significant challenge. We present YoNoSplat, a feedforward model that
> reconstructs high-quality 3D Gaussian Splatting representations from an
> arbitrary number of images. Our model is highly versatile, operating
> effectively with both posed and unposed, calibrated and uncalibrated inputs.
> YoNoSplat predicts local Gaussians and camera poses for each view, which are
> aggregated into a global representation using either predicted or provided
> poses. To overcome the inherent difficulty of jointly learning 3D Gaussians and
> camera parameters, we introduce a novel mixing training strategy. This approach
> mitigates the entanglement between the two tasks by initially using
> ground-truth poses to aggregate local Gaussians and gradually transitioning to
> a mix of predicted and ground-truth poses, which prevents both training
> instability and exposure bias. We further resolve the scale ambiguity problem
> by a novel pairwise camera-distance normalization scheme and by embedding
> camera intrinsics into the network. Moreover, YoNoSplat also predicts intrinsic
> parameters, making it feasible for uncalibrated inputs. YoNoSplat demonstrates
> exceptional efficiency, reconstructing a scene from 100 views (at 280x518
> resolution) in just 2.69 seconds on an NVIDIA GH200 GPU. It achieves
> state-of-the-art performance on standard benchmarks in both pose-free and
> pose-dependent settings. Our project page is at
> https://botaoye.github.io/yonosplat/.

