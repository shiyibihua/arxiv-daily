---
layout: default
title: Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection
---

# Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection

**arXiv**: [2511.07301v1](https://arxiv.org/abs/2511.07301) | [PDF](https://arxiv.org/pdf/2511.07301.pdf)

**ä½œè€…**: Huizai Yao, Sicheng Zhao, Pengteng Li, Yi Cui, Shuo Lu, Weiyu Guo, Yunfan Lu, Yijie Xu, Hui Xiong

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè§†è§‰åŸºç¡€æ¨¡å‹çš„æºè‡ªç”±ç›®æ ‡æ£€æµ‹æ¡†æ¶ï¼Œä»¥æå‡è·¨åŸŸæ³›åŒ–èƒ½åŠ›**

**å…³é”®è¯**: `æºè‡ªç”±ç›®æ ‡æ£€æµ‹` `è§†è§‰åŸºç¡€æ¨¡å‹` `ç‰¹å¾å¯¹é½` `ä¼ªæ ‡ç­¾èåˆ` `è·¨åŸŸæ³›åŒ–` `å¯¹æ¯”å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æºè‡ªç”±ç›®æ ‡æ£€æµ‹ä¾èµ–æºæ¨¡å‹å†…éƒ¨çŸ¥è¯†ï¼Œå¯¼è‡´è·¨åŸŸæ³›åŒ–å—é™å’Œä¼ªæ ‡ç­¾åå·®
2. å¼•å…¥ä¸‰ä¸ªæ¨¡å—ï¼šå…¨å±€ç‰¹å¾å¯¹é½ã€å®ä¾‹ç‰¹å¾å¯¹é½å’Œä¼ªæ ‡ç­¾èåˆï¼Œåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹å¢å¼ºç‰¹å¾ä¸æ ‡ç­¾è´¨é‡
3. åœ¨å…­ä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°æœ€ä¼˜æ€§èƒ½ï¼ŒéªŒè¯æ–¹æ³•åœ¨æå‡è¿ç§»æ€§å’Œåˆ¤åˆ«æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Source-Free Object Detection (SFOD) aims to adapt a source-pretrained object
> detector to a target domain without access to source data. However, existing
> SFOD methods predominantly rely on internal knowledge from the source model,
> which limits their capacity to generalize across domains and often results in
> biased pseudo-labels, thereby hindering both transferability and
> discriminability. In contrast, Vision Foundation Models (VFMs), pretrained on
> massive and diverse data, exhibit strong perception capabilities and broad
> generalization, yet their potential remains largely untapped in the SFOD
> setting. In this paper, we propose a novel SFOD framework that leverages VFMs
> as external knowledge sources to jointly enhance feature alignment and label
> quality. Specifically, we design three VFM-based modules: (1) Patch-weighted
> Global Feature Alignment (PGFA) distills global features from VFMs using
> patch-similarity-based weighting to enhance global feature transferability; (2)
> Prototype-based Instance Feature Alignment (PIFA) performs instance-level
> contrastive learning guided by momentum-updated VFM prototypes; and (3)
> Dual-source Enhanced Pseudo-label Fusion (DEPF) fuses predictions from
> detection VFMs and teacher models via an entropy-aware strategy to yield more
> reliable supervision. Extensive experiments on six benchmarks demonstrate that
> our method achieves state-of-the-art SFOD performance, validating the
> effectiveness of integrating VFMs to simultaneously improve transferability and
> discriminability.

