---
layout: default
title: ProcGen3D: Learning Neural Procedural Graph Representations for Image-to-3D Reconstruction
---

# ProcGen3D: Learning Neural Procedural Graph Representations for Image-to-3D Reconstruction

**arXiv**: [2511.07142v1](https://arxiv.org/abs/2511.07142) | [PDF](https://arxiv.org/pdf/2511.07142.pdf)

**ä½œè€…**: Xinyi Zhang, Daoyi Gao, Naiqi Li, Angela Dai

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºProcGen3Dæ–¹æ³•ï¼Œé€šè¿‡å›¾åƒç”Ÿæˆç¨‹åºåŒ–å›¾ä»¥é‡å»º3Då¯¹è±¡**

**å…³é”®è¯**: `å›¾åƒåˆ°3Dé‡å»º` `ç¨‹åºåŒ–å›¾è¡¨ç¤º` `Transformeræ¨¡åž‹` `Monte Carloæ ‘æœç´¢` `3Då†…å®¹ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä»ŽRGBå›¾åƒé‡å»ºå¤æ‚3Dèµ„äº§ï¼Œéœ€é«˜æ•ˆè¡¨ç¤ºä¸Žç”Ÿæˆæ–¹æ³•
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨åŸºäºŽå›¾çš„ç¨‹åºåŒ–è¡¨ç¤ºï¼Œç»“åˆTransformerå’ŒMCTSé‡‡æ ·ä¼˜åŒ–å¯¹é½
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä»™äººæŽŒã€æ ‘æœ¨å’Œæ¡¥æ¢ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œæå‡çœŸå®žå›¾åƒæ³›åŒ–èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce ProcGen3D, a new approach for 3D content creation by generating
> procedural graph abstractions of 3D objects, which can then be decoded into
> rich, complex 3D assets. Inspired by the prevalent use of procedural generators
> in production 3D applications, we propose a sequentialized, graph-based
> procedural graph representation for 3D assets. We use this to learn to
> approximate the landscape of a procedural generator for image-based 3D
> reconstruction. We employ edge-based tokenization to encode the procedural
> graphs, and train a transformer prior to predict the next token conditioned on
> an input RGB image. Crucially, to enable better alignment of our generated
> outputs to an input image, we incorporate Monte Carlo Tree Search (MCTS) guided
> sampling into our generation process, steering output procedural graphs towards
> more image-faithful reconstructions. Our approach is applicable across a
> variety of objects that can be synthesized with procedural generators.
> Extensive experiments on cacti, trees, and bridges show that our neural
> procedural graph generation outperforms both state-of-the-art generative 3D
> methods and domain-specific modeling techniques. Furthermore, this enables
> improved generalization on real-world input images, despite training only on
> synthetic data.

