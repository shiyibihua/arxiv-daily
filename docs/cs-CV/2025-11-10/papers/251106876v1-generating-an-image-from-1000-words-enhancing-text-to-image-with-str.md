---
layout: default
title: Generating an Image From 1,000 Words: Enhancing Text-to-Image With Structured Captions
---

# Generating an Image From 1,000 Words: Enhancing Text-to-Image With Structured Captions

**arXiv**: [2511.06876v1](https://arxiv.org/abs/2511.06876) | [PDF](https://arxiv.org/pdf/2511.06876.pdf)

**ä½œè€…**: Eyal Gutflaish, Eliran Kachlon, Hezi Zisman, Tal Hacham, Nimrod Sarid, Alexander Visheratin, Saar Huberman, Gal Davidi, Guy Bukchin, Kfir Goldberg, Ron Mokady

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽé•¿ç»“æž„åŒ–æè¿°çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡åž‹ï¼Œä»¥è§£å†³è¾“å…¥ç¨€ç–å¯¼è‡´çš„æŽ§åˆ¶æ€§é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `é•¿ç»“æž„åŒ–æè¿°` `DimFusionæœºåˆ¶` `TaBRè¯„ä¼°åè®®` `FIBOæ¨¡åž‹` `æŽ§åˆ¶æ€§å¢žå¼º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŸ­æç¤ºä¸Žä¸°å¯Œè§†è§‰è¾“å‡ºä¸åŒ¹é…ï¼Œå¯¼è‡´æ¨¡åž‹æŽ§åˆ¶æ€§å·®å’Œç»†èŠ‚å¡«å……åå·®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®­ç»ƒé¦–ä¸ªå¼€æºæ¨¡åž‹ä½¿ç”¨é•¿ç»“æž„åŒ–æè¿°ï¼Œå¹¶å¼•å…¥DimFusionæœºåˆ¶é«˜æ•ˆå¤„ç†é•¿è¾“å…¥ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šé€šè¿‡TaBRè¯„ä¼°åè®®å’ŒFIBOæ¨¡åž‹ï¼Œåœ¨å¼€æºæ¨¡åž‹ä¸­å®žçŽ°æœ€å…ˆè¿›çš„æç¤ºå¯¹é½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-to-image models have rapidly evolved from casual creative tools to
> professional-grade systems, achieving unprecedented levels of image quality and
> realism. Yet, most models are trained to map short prompts into detailed
> images, creating a gap between sparse textual input and rich visual outputs.
> This mismatch reduces controllability, as models often fill in missing details
> arbitrarily, biasing toward average user preferences and limiting precision for
> professional use. We address this limitation by training the first open-source
> text-to-image model on long structured captions, where every training sample is
> annotated with the same set of fine-grained attributes. This design maximizes
> expressive coverage and enables disentangled control over visual factors. To
> process long captions efficiently, we propose DimFusion, a fusion mechanism
> that integrates intermediate tokens from a lightweight LLM without increasing
> token length. We also introduce the Text-as-a-Bottleneck Reconstruction (TaBR)
> evaluation protocol. By assessing how well real images can be reconstructed
> through a captioning-generation loop, TaBR directly measures controllability
> and expressiveness, even for very long captions where existing evaluation
> methods fail. Finally, we demonstrate our contributions by training the
> large-scale model FIBO, achieving state-of-the-art prompt alignment among
> open-source models. Model weights are publicly available at
> https://huggingface.co/briaai/FIBO

