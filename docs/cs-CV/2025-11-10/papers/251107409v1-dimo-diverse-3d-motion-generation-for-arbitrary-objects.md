---
layout: default
title: DIMO: Diverse 3D Motion Generation for Arbitrary Objects
---

# DIMO: Diverse 3D Motion Generation for Arbitrary Objects

**arXiv**: [2511.07409v1](https://arxiv.org/abs/2511.07409) | [PDF](https://arxiv.org/pdf/2511.07409.pdf)

**ä½œè€…**: Linzhan Mou, Jiahui Lei, Chen Wang, Lingjie Liu, Kostas Daniilidis

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDIMOæ–¹æ³•ï¼Œä»Žå•å¼ å›¾åƒç”Ÿæˆä»»æ„ç‰©ä½“çš„å¤šæ ·3Dè¿åŠ¨ã€‚**

**å…³é”®è¯**: `3Dè¿åŠ¨ç”Ÿæˆ` `å•å›¾åƒè¾“å…¥` `æ½œç©ºé—´å­¦ä¹ ` `å…³é”®ç‚¹è½¨è¿¹` `3Dé«˜æ–¯æ¨¡åž‹` `è¯­è¨€å¼•å¯¼ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä»Žå•å¼ å›¾åƒç”Ÿæˆä»»æ„ç‰©ä½“çš„å¤šæ ·3Dè¿åŠ¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨è§†é¢‘æ¨¡åž‹æå–è¿åŠ¨æ¨¡å¼ï¼ŒåµŒå…¥å…±äº«æ½œç©ºé—´ï¼Œè§£ç ä¸ºå…³é”®ç‚¹è½¨è¿¹é©±åŠ¨3Dé«˜æ–¯ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ”¯æŒ3Dè¿åŠ¨æ’å€¼å’Œè¯­è¨€å¼•å¯¼ç”Ÿæˆï¼Œå®žçŽ°å•æ¬¡å‰å‘æŽ¨ç†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present DIMO, a generative approach capable of generating diverse 3D
> motions for arbitrary objects from a single image. The core idea of our work is
> to leverage the rich priors in well-trained video models to extract the common
> motion patterns and then embed them into a shared low-dimensional latent space.
> Specifically, we first generate multiple videos of the same object with diverse
> motions. We then embed each motion into a latent vector and train a shared
> motion decoder to learn the distribution of motions represented by a structured
> and compact motion representation, i.e., neural key point trajectories. The
> canonical 3D Gaussians are then driven by these key points and fused to model
> the geometry and appearance. During inference time with learned latent space,
> we can instantly sample diverse 3D motions in a single-forward pass and support
> several interesting applications including 3D motion interpolation and
> language-guided motion generation. Our project page is available at
> https://linzhanm.github.io/dimo.

