---
layout: default
title: NOVO: Bridging LLaVA and SAM with Visual-only Prompts for Reasoning Segmentation
---

# NOVO: Bridging LLaVA and SAM with Visual-only Prompts for Reasoning Segmentation

**arXiv**: [2511.06651v1](https://arxiv.org/abs/2511.06651) | [PDF](https://arxiv.org/pdf/2511.06651.pdf)

**ä½œè€…**: Kyung-Yoon Yoon, Yeong-Jun Cho

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNOVOæ¡†æž¶ï¼Œé€šè¿‡è§†è§‰æç¤ºæ¡¥æŽ¥è§†è§‰è¯­è¨€æ¨¡åž‹ä¸Žåˆ†å‰²æ¨¡åž‹ï¼Œå®žçŽ°æŽ¨ç†åˆ†å‰²ã€‚**

**å…³é”®è¯**: `æŽ¨ç†åˆ†å‰²` `è§†è§‰æç¤º` `Segment Anything Model` `è§†è§‰è¯­è¨€æ¨¡åž‹` `æ— è®­ç»ƒç»†åŒ–` `å®žä¾‹åˆ†å‰²`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•ä¾èµ–æ–‡æœ¬åµŒå…¥ï¼Œé™åˆ¶äº†åˆ†å‰²æ¨¡åž‹ä¸Žè§†è§‰è¯­è¨€æ¨¡åž‹çš„ç›´æŽ¥é›†æˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šNOVOä»ŽVLMè¾“å‡ºç”Ÿæˆç²—æŽ©ç å’Œç‚¹æç¤ºï¼Œå…¼å®¹SAMå¹¶å¼•å…¥æ— è®­ç»ƒç»†åŒ–æ¨¡å—ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨RISegåŸºå‡†ä¸Šå®žçŽ°SOTAæ€§èƒ½ï¼Œæå‡åˆ†å‰²è´¨é‡å’Œå¯æ‰©å±•æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this study, we propose NOVO (NO text, Visual-Only prompts), a novel
> framework that bridges vision-language models (VLMs) and segmentation models
> through visual-only prompts. Unlike prior approaches that feed text-derived SEG
> token embeddings into segmentation models, NOVO instead generates a coarse mask
> and point prompts from the VLM output. These visual prompts are compatible with
> the Segment Anything Model (SAM), preserving alignment with its pretrained
> capabilities. To further enhance boundary quality and enable instance-level
> segmentation, we introduce a training-free refinement module that reduces
> visual artifacts and improves the quality of segmentation masks. We also
> present RISeg, a new benchmark comprising 918 images, 2,533 instance-level
> masks, and diverse reasoning queries to evaluate this task. Experiments
> demonstrate that NOVO achieves state-of-the-art performance across multiple
> metrics and model sizes, demonstrating its effectiveness and scalability in
> reasoning segmentation.

