---
layout: default
title: Verifying rich robustness properties for neural networks
---

# Verifying rich robustness properties for neural networks

**arXiv**: [2511.07293v1](https://arxiv.org/abs/2511.07293) | [PDF](https://arxiv.org/pdf/2511.07293.pdf)

**ä½œè€…**: Mohammad Afzal, S. Akshay, Ashutosh Gupta

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€æ¡†æž¶ä»¥éªŒè¯ç¥žç»ç½‘ç»œé²æ£’æ€§å˜ä½“ï¼Œæ”¯æŒç½®ä¿¡åº¦è€ƒé‡ã€‚**

**å…³é”®è¯**: `ç¥žç»ç½‘ç»œéªŒè¯` `é²æ£’æ€§è§„èŒƒ` `ç½®ä¿¡åº¦è€ƒé‡` `ç»Ÿä¸€éªŒè¯æ¡†æž¶` `è¿‘ä¼¼è¯¯å·®æŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•å¿½ç•¥ç¥žç»ç½‘ç»œè¾“å‡ºç½®ä¿¡åº¦ï¼Œä¸”ç¼–ç å¤æ‚ï¼Œéš¾ä»¥éªŒè¯å¤šç§é²æ£’æ€§å˜ä½“ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨ç®€å•è¯­æ³•å®šä¹‰è§„èŒƒï¼Œé€šè¿‡æ·»åŠ å±‚ç»Ÿä¸€éªŒè¯ï¼Œå…¼å®¹çŽ°æœ‰å·¥å…·å¹¶æŽ§åˆ¶è¿‘ä¼¼è¯¯å·®ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨8870ä¸ªåŸºå‡†æµ‹è¯•ä¸­éªŒè¯ï¼Œæ¶µç›–138Må‚æ•°ç½‘ç»œï¼Œæ€§èƒ½ä¼˜äºŽç›´æŽ¥ç¼–ç æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Robustness is a important problem in AI alignment and safety, with models
> such as neural networks being increasingly used in safety-critical systems. In
> the last decade, a large body of work has emerged on local robustness, i.e.,
> checking if the decision of a neural network remains unchanged when the input
> is slightly perturbed. However, many of these approaches require specialized
> encoding and often ignore the confidence of a neural network on its output. In
> this paper, our goal is to build a generalized framework to specify and verify
> variants of robustness in neural network verification. We propose a
> specification framework using a simple grammar, which is flexible enough to
> capture most existing variants. This allows us to introduce new variants of
> robustness that take into account the confidence of the neural network in its
> outputs. Next, we develop a novel and powerful unified technique to verify all
> such variants in a homogeneous way, viz., by adding a few additional layers to
> the neural network. This enables us to use any state-of-the-art neural network
> verification tool, without having to tinker with the encoding within, while
> incurring an approximation error that we show is bounded. We perform an
> extensive experimental evaluation over a large suite of 8870 benchmarks having
> 138M parameters in a largest network, and show that we are able to capture a
> wide set of robustness variants and outperform direct encoding approaches by a
> significant margin.

