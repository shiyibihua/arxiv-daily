---
layout: default
title: ClusterMine: Robust Label-Free Visual Out-Of-Distribution Detection via Concept Mining from Text Corpora
---

# ClusterMine: Robust Label-Free Visual Out-Of-Distribution Detection via Concept Mining from Text Corpora

**arXiv**: [2511.07068v1](https://arxiv.org/abs/2511.07068) | [PDF](https://arxiv.org/pdf/2511.07068.pdf)

**ä½œè€…**: Nikolas Adaloglou, Diana Petrusheva, Mohamed Asker, Felix Michels, Markus Kollmann

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºClusterMineæ–¹æ³•ï¼Œé€šè¿‡æ–‡æœ¬è¯­æ–™åº“æŒ–æŽ˜æ¦‚å¿µå®žçŽ°æ— æ ‡ç­¾è§†è§‰åˆ†å¸ƒå¤–æ£€æµ‹**

**å…³é”®è¯**: `è§†è§‰åˆ†å¸ƒå¤–æ£€æµ‹` `æ¦‚å¿µæŒ–æŽ˜` `é›¶æ ·æœ¬å­¦ä¹ ` `CLIPæ¨¡åž‹` `æ— ç›‘ç£å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§†è§‰åˆ†å¸ƒå¤–æ£€æµ‹ä¾èµ–é¢„å®šä¹‰æ ‡ç­¾ï¼Œéš¾ä»¥åº”å¯¹æ ‡ç­¾ç¼ºå¤±æˆ–åˆ†å¸ƒåç§»
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆè§†è§‰èšç±»å’Œé›¶æ ·æœ¬å›¾æ–‡ä¸€è‡´æ€§ï¼Œä»Žæ–‡æœ¬è¯­æ–™åº“è‡ªåŠ¨æŒ–æŽ˜æ­£æ¦‚å¿µ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šç§CLIPæ¨¡åž‹ä¸Šå®žçŽ°SOTAæ€§èƒ½ï¼Œå¯¹åˆ†å¸ƒåç§»å…·æœ‰å¼ºé²æ£’æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large-scale visual out-of-distribution (OOD) detection has witnessed
> remarkable progress by leveraging vision-language models such as CLIP. However,
> a significant limitation of current methods is their reliance on a pre-defined
> set of in-distribution (ID) ground-truth label names (positives). These fixed
> label names can be unavailable, unreliable at scale, or become less relevant
> due to in-distribution shifts after deployment. Towards truly unsupervised OOD
> detection, we utilize widely available text corpora for positive label mining,
> bypassing the need for positives. In this paper, we utilize widely available
> text corpora for positive label mining under a general concept mining paradigm.
> Within this framework, we propose ClusterMine, a novel positive label mining
> method. ClusterMine is the first method to achieve state-of-the-art OOD
> detection performance without access to positive labels. It extracts positive
> concepts from a large text corpus by combining visual-only sample consistency
> (via clustering) and zero-shot image-text consistency. Our experimental study
> reveals that ClusterMine is scalable across a plethora of CLIP models and
> achieves state-of-the-art robustness to covariate in-distribution shifts. The
> code is available at https://github.com/HHU-MMBS/clustermine_wacv_official.

