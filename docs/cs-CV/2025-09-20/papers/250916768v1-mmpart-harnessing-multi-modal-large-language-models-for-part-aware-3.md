---
layout: default
title: MMPart: Harnessing Multi-Modal Large Language Models for Part-Aware 3D Generation
---

# MMPart: Harnessing Multi-Modal Large Language Models for Part-Aware 3D Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16768" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16768v1</a>
  <a href="https://arxiv.org/pdf/2509.16768.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16768v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16768v1', 'MMPart: Harnessing Multi-Modal Large Language Models for Part-Aware 3D Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Omid Bonakdar, Nasser Mozayani

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MMPartï¼šåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œéƒ¨ä»¶æ„ŸçŸ¥çš„3Dç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dç”Ÿæˆ` `éƒ¨ä»¶æ„ŸçŸ¥` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `VLM` `å›¾åƒç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dç”Ÿæˆæ–¹æ³•ç¼ºä¹ç»“æ„ä¿¡æ¯ï¼Œé™åˆ¶äº†ç¼–è¾‘å’Œè¯­ä¹‰ç†è§£ï¼Œéƒ¨ä»¶æ„ŸçŸ¥çš„3Dç”Ÿæˆæ—¨åœ¨è§£å†³æ­¤é—®é¢˜ã€‚
2. MMPartåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæç¤ºï¼ŒæŒ‡å¯¼ç”Ÿæˆæ¨¡å‹ç”Ÿæˆéƒ¨ä»¶çš„å­¤ç«‹å›¾åƒï¼Œå¹¶è¿›è¡Œå¤šè§†è§’é‡å»ºã€‚
3. è¯¥æ–¹æ³•å…è®¸ç”¨æˆ·æ§åˆ¶éƒ¨ä»¶åˆ†ç¦»ï¼Œå¹¶èƒ½è¾ƒå¥½åœ°æƒ³è±¡è¢«é®æŒ¡éƒ¨åˆ†ï¼Œä»è€Œç”Ÿæˆæ›´å…·ç»“æ„ä¿¡æ¯çš„3Dæ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”Ÿæˆå¼3Då»ºæ¨¡æŠ€æœ¯åœ¨VR/ARã€å…ƒå®‡å®™å’Œæœºå™¨äººç­‰é¢†åŸŸå‘å±•è¿…é€Ÿã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°æ–¹æ³•å°†ç›®æ ‡å¯¹è±¡è¡¨ç¤ºä¸ºå°é—­ç½‘æ ¼ï¼Œç¼ºä¹ç»“æ„ä¿¡æ¯ï¼Œé™åˆ¶äº†ç¼–è¾‘ã€åŠ¨ç”»å’Œè¯­ä¹‰ç†è§£ã€‚éƒ¨ä»¶æ„ŸçŸ¥çš„3Dç”Ÿæˆé€šè¿‡å°†å¯¹è±¡åˆ†è§£ä¸ºæœ‰æ„ä¹‰çš„ç»„ä»¶æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†ç°æœ‰æµç¨‹é¢ä¸´æŒ‘æˆ˜ï¼šç”¨æˆ·æ— æ³•æ§åˆ¶å“ªäº›å¯¹è±¡è¢«åˆ†ç¦»ä»¥åŠæ¨¡å‹å¦‚ä½•æƒ³è±¡è¢«é®æŒ¡çš„éƒ¨åˆ†ã€‚æœ¬æ–‡æå‡ºäº†MMPartï¼Œä¸€ä¸ªåˆ›æ–°çš„æ¡†æ¶ï¼Œç”¨äºä»å•å¼ å›¾åƒç”Ÿæˆéƒ¨ä»¶æ„ŸçŸ¥çš„3Dæ¨¡å‹ã€‚é¦–å…ˆï¼Œä½¿ç”¨VLMåŸºäºè¾“å…¥å›¾åƒå’Œç”¨æˆ·æè¿°ç”Ÿæˆä¸€ç»„æç¤ºã€‚æ¥ä¸‹æ¥ï¼Œç”Ÿæˆæ¨¡å‹åŸºäºåˆå§‹å›¾åƒå’Œä¸Šä¸€æ­¥çš„æç¤ºï¼ˆæ§åˆ¶å§¿åŠ¿å¹¶æŒ‡å¯¼æ¨¡å‹å¦‚ä½•æƒ³è±¡å…ˆå‰é®æŒ¡çš„åŒºåŸŸï¼‰ç”Ÿæˆæ¯ä¸ªå¯¹è±¡çš„å­¤ç«‹å›¾åƒã€‚ç„¶åï¼Œæ¯ä¸ªå›¾åƒè¿›å…¥å¤šè§†å›¾ç”Ÿæˆé˜¶æ®µï¼Œç”Ÿæˆæ¥è‡ªä¸åŒè§†è§’çš„å¤šä¸ªä¸€è‡´å›¾åƒã€‚æœ€åï¼Œé‡å»ºæ¨¡å‹å°†æ¯ä¸ªå¤šè§†å›¾å›¾åƒè½¬æ¢ä¸º3Dæ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Dç”Ÿæˆæ–¹æ³•é€šå¸¸ç”Ÿæˆå°é—­çš„ç½‘æ ¼æ¨¡å‹ï¼Œç¼ºä¹éƒ¨ä»¶çº§åˆ«çš„ç»“æ„ä¿¡æ¯ï¼Œéš¾ä»¥è¿›è¡Œç¼–è¾‘ã€åŠ¨ç”»åˆ¶ä½œå’Œè¯­ä¹‰ç†è§£ã€‚æ­¤å¤–ï¼Œç°æœ‰éƒ¨ä»¶æ„ŸçŸ¥çš„3Dç”Ÿæˆæ–¹æ³•ç”¨æˆ·æ§åˆ¶æ€§è¾ƒå·®ï¼Œæ— æ³•æŒ‡å®šå“ªäº›éƒ¨ä»¶éœ€è¦åˆ†ç¦»ï¼Œå¹¶ä¸”åœ¨ç”Ÿæˆåˆ†ç¦»éƒ¨ä»¶æ—¶ï¼Œå¯¹äºè¢«é®æŒ¡åŒºåŸŸçš„æƒ³è±¡èƒ½åŠ›æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMMPartçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„å¼ºå¤§èƒ½åŠ›ï¼Œä»å•å¼ è¾“å…¥å›¾åƒä¸­æå–è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶ç”ŸæˆæŒ‡å¯¼æ€§çš„æ–‡æœ¬æç¤ºã€‚è¿™äº›æç¤ºä¸ä»…æè¿°äº†å›¾åƒä¸­çš„å¯¹è±¡ï¼Œè¿˜åŒ…å«äº†ç”¨æˆ·å¯¹éƒ¨ä»¶åˆ†ç¦»çš„æ„å›¾å’Œå¯¹é®æŒ¡åŒºåŸŸçš„æƒ³è±¡ã€‚é€šè¿‡è¿™äº›æç¤ºï¼Œå¯ä»¥å¼•å¯¼ç”Ÿæˆæ¨¡å‹ç”Ÿæˆæ›´ç¬¦åˆç”¨æˆ·æ„å›¾ä¸”å…·æœ‰åˆç†ç»“æ„çš„éƒ¨ä»¶åŒ–3Dæ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMMPartæ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼š1) æç¤ºç”Ÿæˆé˜¶æ®µï¼šä½¿ç”¨VLMåˆ†æè¾“å…¥å›¾åƒå’Œç”¨æˆ·æè¿°ï¼Œç”Ÿæˆä¸€ç»„æ–‡æœ¬æç¤ºï¼Œç”¨äºæŒ‡å¯¼åç»­çš„éƒ¨ä»¶å›¾åƒç”Ÿæˆã€‚2) éƒ¨ä»¶å›¾åƒç”Ÿæˆé˜¶æ®µï¼šåŸºäºåˆå§‹å›¾åƒå’Œç”Ÿæˆçš„æç¤ºï¼Œç”Ÿæˆæ¯ä¸ªéƒ¨ä»¶çš„å­¤ç«‹å›¾åƒï¼Œè¿™äº›å›¾åƒåŒ…å«äº†å¯¹é®æŒ¡åŒºåŸŸçš„åˆç†æƒ³è±¡ã€‚3) å¤šè§†å›¾3Dé‡å»ºé˜¶æ®µï¼šå¯¹æ¯ä¸ªéƒ¨ä»¶çš„å­¤ç«‹å›¾åƒè¿›è¡Œå¤šè§†å›¾ç”Ÿæˆï¼Œç„¶åä½¿ç”¨3Dé‡å»ºæ¨¡å‹å°†å¤šè§†å›¾å›¾åƒè½¬æ¢ä¸º3Dæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šMMPartçš„å…³é”®åˆ›æ–°åœ¨äºåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ¥å¢å¼ºéƒ¨ä»¶æ„ŸçŸ¥çš„3Dç”Ÿæˆè¿‡ç¨‹ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMMPartèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç”¨æˆ·æ„å›¾ï¼Œå¹¶ç”Ÿæˆæ›´å…·ç»“æ„ä¿¡æ¯å’Œå¯æ§æ€§çš„3Dæ¨¡å‹ã€‚æ­¤å¤–ï¼Œé€šè¿‡VLMç”Ÿæˆçš„æç¤ºï¼ŒMMPartèƒ½å¤Ÿæœ‰æ•ˆåœ°è§£å†³é®æŒ¡é—®é¢˜ï¼Œç”Ÿæˆåˆç†çš„éƒ¨ä»¶å‡ ä½•å½¢çŠ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æç¤ºç”Ÿæˆé˜¶æ®µï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„VLMæ¨¡å‹ï¼Œå¹¶è®¾è®¡æœ‰æ•ˆçš„æç¤ºå·¥ç¨‹ç­–ç•¥ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„æç¤ºèƒ½å¤Ÿå‡†ç¡®åœ°æè¿°å›¾åƒå†…å®¹å’Œç”¨æˆ·æ„å›¾ã€‚åœ¨éƒ¨ä»¶å›¾åƒç”Ÿæˆé˜¶æ®µï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„ç”Ÿæˆæ¨¡å‹ï¼Œå¹¶è®¾è®¡åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„å›¾åƒå…·æœ‰é«˜è´¨é‡å’Œä¸€è‡´æ€§ã€‚åœ¨å¤šè§†å›¾3Dé‡å»ºé˜¶æ®µï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„é‡å»ºæ¨¡å‹ï¼Œå¹¶è®¾è®¡åˆé€‚çš„ä¼˜åŒ–ç­–ç•¥ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„3Dæ¨¡å‹å…·æœ‰å‡†ç¡®çš„å‡ ä½•å½¢çŠ¶å’Œæ‹“æ‰‘ç»“æ„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æå‡ºäº†MMPartæ¡†æ¶ï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œéƒ¨ä»¶æ„ŸçŸ¥çš„3Dç”Ÿæˆï¼Œç”¨æˆ·å¯ä»¥æ§åˆ¶éƒ¨ä»¶åˆ†ç¦»ï¼Œå¹¶èƒ½è¾ƒå¥½åœ°æƒ³è±¡è¢«é®æŒ¡éƒ¨åˆ†ï¼Œä»è€Œç”Ÿæˆæ›´å…·ç»“æ„ä¿¡æ¯çš„3Dæ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMMPartåœ¨éƒ¨ä»¶åˆ†ç¦»å’Œé®æŒ¡å¤„ç†æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç”Ÿæˆçš„ä¸‰ç»´æ¨¡å‹å…·æœ‰æ›´é«˜çš„è´¨é‡å’Œå¯ç¼–è¾‘æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MMPartå¯åº”ç”¨äºVR/ARå†…å®¹åˆ›ä½œã€å…ƒå®‡å®™åœºæ™¯æ„å»ºã€æœºå™¨äººç¯å¢ƒæ„ŸçŸ¥ä¸äº¤äº’ç­‰é¢†åŸŸã€‚è¯¥æ–¹æ³•ç”Ÿæˆçš„éƒ¨ä»¶æ„ŸçŸ¥3Dæ¨¡å‹å…·æœ‰æ›´é«˜çš„å¯ç¼–è¾‘æ€§å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œèƒ½å¤Ÿæå‡ç”¨æˆ·åœ¨è™šæ‹Ÿç¯å¢ƒä¸­çš„äº¤äº’ä½“éªŒï¼Œå¹¶ä¸ºæœºå™¨äººæä¾›æ›´ç²¾ç¡®çš„ç¯å¢ƒç†è§£èƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ™ºèƒ½åˆ¶é€ ã€æ¸¸æˆå¼€å‘ç­‰æ›´å¤šé¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generative 3D modeling has advanced rapidly, driven by applications in VR/AR, metaverse, and robotics. However, most methods represent the target object as a closed mesh devoid of any structural information, limiting editing, animation, and semantic understanding. Part-aware 3D generation addresses this problem by decomposing objects into meaningful components, but existing pipelines face challenges: in existing methods, the user has no control over which objects are separated and how model imagine the occluded parts in isolation phase. In this paper, we introduce MMPart, an innovative framework for generating part-aware 3D models from a single image. We first use a VLM to generate a set of prompts based on the input image and user descriptions. In the next step, a generative model generates isolated images of each object based on the initial image and the previous step's prompts as supervisor (which control the pose and guide model how imagine previously occluded areas). Each of those images then enters the multi-view generation stage, where a number of consistent images from different views are generated. Finally, a reconstruction model converts each of these multi-view images into a 3D model.

