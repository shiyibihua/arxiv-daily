---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-08-04
---

# cs.CVï¼ˆ2025-08-04ï¼‰

ğŸ“Š å…± **7** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (2)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250802106v1-towards-immersive-human-x-interaction-a-real-time-framework-for-phys.html">Towards Immersive Human-X Interaction: A Real-Time Framework for Physically Plausible Motion Synthesis</a></td>
  <td>æå‡ºHuman-Xæ¡†æ¶ä»¥è§£å†³å®æ—¶äººæœºäº¤äº’çš„ç‰©ç†å¯è¡Œæ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02106v1" data-paper-url="./papers/250802106v1-towards-immersive-human-x-interaction-a-real-time-framework-for-phys.html" onclick="toggleFavorite(this, '2508.02106v1', 'Towards Immersive Human-X Interaction: A Real-Time Framework for Physically Plausible Motion Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250802419v1-modality-bias-in-lvlms-analyzing-and-mitigating-object-hallucination.html">Modality Bias in LVLMs: Analyzing and Mitigating Object Hallucination via Attention Lens</a></td>
  <td>æå‡ºæ³¨æ„åŠ›è°ƒæ•´æ–¹æ³•ä»¥ç¼“è§£LVLMä¸­çš„ç‰©ä½“å¹»è§‰é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02419v1" data-paper-url="./papers/250802419v1-modality-bias-in-lvlms-analyzing-and-mitigating-object-hallucination.html" onclick="toggleFavorite(this, '2508.02419v1', 'Modality Bias in LVLMs: Analyzing and Mitigating Object Hallucination via Attention Lens')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>3</td>
  <td><a href="./papers/250802549v4-monodream-monocular-vision-language-navigation-with-panoramic-dreami.html">MonoDream: Monocular Vision-Language Navigation with Panoramic Dreaming</a></td>
  <td>æå‡ºMonoDreamä»¥è§£å†³å•ç›®è§†è§‰å¯¼èˆªæ€§èƒ½ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">VLA</span> <span class="paper-tag">VLN</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02549v4" data-paper-url="./papers/250802549v4-monodream-monocular-vision-language-navigation-with-panoramic-dreami.html" onclick="toggleFavorite(this, '2508.02549v4', 'MonoDream: Monocular Vision-Language Navigation with Panoramic Dreaming')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250802890v1-visucraft-enhancing-large-vision-language-models-for-complex-visual-.html">VisuCraft: Enhancing Large Vision-Language Models for Complex Visual-Guided Creative Content Generation via Structured Information Extraction</a></td>
  <td>æå‡ºVisuCraftä»¥è§£å†³å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹åœ¨åˆ›æ„å†…å®¹ç”Ÿæˆä¸­çš„å±€é™æ€§</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span> <span class="paper-tag">visual grounding</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02890v1" data-paper-url="./papers/250802890v1-visucraft-enhancing-large-vision-language-models-for-complex-visual-.html" onclick="toggleFavorite(this, '2508.02890v1', 'VisuCraft: Enhancing Large Vision-Language Models for Complex Visual-Guided Creative Content Generation via Structured Information Extraction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>5</td>
  <td><a href="./papers/250802905v1-how-would-it-sound-material-controlled-multimodal-acoustic-profile-g.html">How Would It Sound? Material-Controlled Multimodal Acoustic Profile Generation for Indoor Scenes</a></td>
  <td>æå‡ºææ–™æ§åˆ¶çš„å¤šæ¨¡æ€å£°å­¦ç‰¹å¾ç”Ÿæˆä»¥è§£å†³å®¤å†…å£°å­¦å»ºæ¨¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">PULSE</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02905v1" data-paper-url="./papers/250802905v1-how-would-it-sound-material-controlled-multimodal-acoustic-profile-g.html" onclick="toggleFavorite(this, '2508.02905v1', 'How Would It Sound? Material-Controlled Multimodal Acoustic Profile Generation for Indoor Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>6</td>
  <td><a href="./papers/250802917v1-following-route-instructions-using-large-vision-language-models-a-co.html">Following Route Instructions using Large Vision-Language Models: A Comparison between Low-level and Panoramic Action Spaces</a></td>
  <td>åˆ©ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œè·¯å¾„æŒ‡å¼•ï¼Œæ¯”è¾ƒä½çº§ä¸å…¨æ™¯åŠ¨ä½œç©ºé—´</td>
  <td class="tags-cell"><span class="paper-tag">egocentric</span> <span class="paper-tag">VLN</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02917v1" data-paper-url="./papers/250802917v1-following-route-instructions-using-large-vision-language-models-a-co.html" onclick="toggleFavorite(this, '2508.02917v1', 'Following Route Instructions using Large Vision-Language Models: A Comparison between Low-level and Panoramic Action Spaces')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>7</td>
  <td><a href="./papers/250802944v1-x-actor-emotional-and-expressive-long-range-portrait-acting-from-aud.html">X-Actor: Emotional and Expressive Long-Range Portrait Acting from Audio</a></td>
  <td>æå‡ºX-Actorä»¥è§£å†³é•¿è§†é¢‘æƒ…æ„Ÿè¡¨è¾¾é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion latent</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02944v1" data-paper-url="./papers/250802944v1-x-actor-emotional-and-expressive-long-range-portrait-acting-from-aud.html" onclick="toggleFavorite(this, '2508.02944v1', 'X-Actor: Emotional and Expressive Long-Range Portrait Acting from Audio')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)