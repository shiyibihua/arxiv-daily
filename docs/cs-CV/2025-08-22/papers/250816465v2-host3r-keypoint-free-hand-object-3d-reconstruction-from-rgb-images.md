---
layout: default
title: HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images
---

# HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.16465" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.16465v2</a>
  <a href="https://arxiv.org/pdf/2508.16465.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.16465v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.16465v2', 'HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Anilkumar Swamy, Vincent Leroy, Philippe Weinzaepfel, Jean-SÃ©bastien Franco, GrÃ©gory Rogez

**åˆ†ç±»**: cs.CV, cs.AI, cs.HC, cs.LG, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-22 (æ›´æ–°: 2025-08-25)

**å¤‡æ³¨**: 12 pages, 8 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHOSt3Rä»¥è§£å†³æ— å…³é”®ç‚¹æ‰‹-ç‰©ä½“3Dé‡å»ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `æ‰‹-ç‰©ä½“é‡å»º` `3Dé‡å»º` `æ— å…³é”®ç‚¹æ£€æµ‹` `å¤šè§†å›¾é‡å»º` `äººæœºäº¤äº’` `å¢å¼ºç°å®` `è™šæ‹Ÿç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ‰‹-ç‰©ä½“3Dé‡å»ºæ–¹æ³•ä¾èµ–å…³é”®ç‚¹æ£€æµ‹ï¼Œéš¾ä»¥å¤„ç†å¤æ‚ç‰©ä½“å‡ ä½•å’Œé®æŒ¡é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºHOSt3Rï¼Œä¸€ä¸ªæ— å…³é”®ç‚¹æ£€æµ‹çš„æ‰‹-ç‰©ä½“3Då˜æ¢ä¼°è®¡æ–¹æ³•ï¼Œç»“åˆå¤šè§†å›¾é‡å»ºã€‚
3. HOSt3Råœ¨SHOWMeåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶åœ¨HO3Dæ•°æ®é›†ä¸Šå±•ç¤ºäº†è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰‹-ç‰©ä½“3Dé‡å»ºåœ¨æœºå™¨äººäº¤äº’å’Œæ²‰æµ¸å¼AR/VRä½“éªŒä¸­å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºå…³é”®ç‚¹æ£€æµ‹æŠ€æœ¯ï¼Œé¢ä¸´å¤šæ ·ç‰©ä½“å‡ ä½•ã€å¼±çº¹ç†å’Œç›¸äº’é®æŒ¡ç­‰æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å…¶å¯æ‰©å±•æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— å…³é”®ç‚¹æ£€æµ‹çš„æ‰‹-ç‰©ä½“3Då˜æ¢ä¼°è®¡æ–¹æ³•HOSt3Rï¼Œç»“åˆå¤šè§†å›¾é‡å»ºç®¡é“ï¼Œèƒ½å¤Ÿå‡†ç¡®æ¢å¤æ‰‹-ç‰©ä½“3Då½¢çŠ¶ã€‚è¯¥æ–¹æ³•ä¸ä¾èµ–äºé¢„æ‰«æçš„ç‰©ä½“æ¨¡æ¿æˆ–ç›¸æœºå†…å‚ï¼Œåœ¨SHOWMeåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨HO3Dæ•°æ®é›†ä¸Šå±•ç¤ºäº†å¯¹æœªè§ç‰©ä½“ç±»åˆ«çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ‰‹-ç‰©ä½“3Dé‡å»ºä¸­å¯¹å…³é”®ç‚¹æ£€æµ‹çš„ä¾èµ–é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šæ ·ç‰©ä½“å‡ ä½•ã€å¼±çº¹ç†å’Œç›¸äº’é®æŒ¡æ—¶è¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHOSt3Ré€šè¿‡ç›´æ¥ä»å•ç›®è§†é¢‘ä¸­ä¼°è®¡æ‰‹-ç‰©ä½“3Då˜æ¢ï¼Œé¿å…äº†å…³é”®ç‚¹æ£€æµ‹çš„å¤æ‚æ€§ï¼Œæ—¨åœ¨å®ç°æ— ç¼ã€éä¾µå…¥å¼çš„3Dé‡å»ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆä»å•ç›®è§†é¢‘ä¸­æå–æ‰‹-ç‰©ä½“çš„3Då˜æ¢ï¼Œç„¶åå°†è¿™äº›å˜æ¢æ•´åˆåˆ°å¤šè§†å›¾é‡å»ºç®¡é“ä¸­ï¼Œä»¥æ¢å¤æ‰‹-ç‰©ä½“çš„3Då½¢çŠ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šHOSt3Rçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶æ— å…³é”®ç‚¹æ£€æµ‹çš„è®¾è®¡ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨æ²¡æœ‰é¢„æ‰«æç‰©ä½“æ¨¡æ¿æˆ–ç›¸æœºå†…å‚çš„æƒ…å†µä¸‹ï¼Œè¿›è¡Œé«˜æ•ˆçš„3Dé‡å»ºã€‚è¿™ä¸€è®¾è®¡æ˜¾è‘—æé«˜äº†æ–¹æ³•çš„å¯æ‰©å±•æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒHOSt3Ré‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–3Då˜æ¢ä¼°è®¡ï¼Œå¹¶è®¾è®¡äº†é€‚åº”ä¸åŒç‰©ä½“å‡ ä½•çš„ç½‘ç»œç»“æ„ï¼Œä»¥å¢å¼ºå…¶é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚è¯¥æ–¹æ³•çš„å‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ç¡®ä¿åœ¨å¤šç§åœºæ™¯ä¸‹çš„æœ€ä½³æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨SHOWMeåŸºå‡†æµ‹è¯•ä¸­ï¼ŒHOSt3Rè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼Œåœ¨HO3Dæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å±•ç¤ºäº†å¯¹æœªè§ç‰©ä½“ç±»åˆ«çš„è‰¯å¥½æ³›åŒ–èƒ½åŠ›ï¼ŒéªŒè¯äº†å…¶å¹¿æ³›é€‚ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

HOSt3Råœ¨äººæœºäº¤äº’ã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶æ— å…³é”®ç‚¹æ£€æµ‹çš„ç‰¹æ€§ä½¿å¾—åœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œå®æ—¶3Dé‡å»ºæˆä¸ºå¯èƒ½ï¼Œèƒ½å¤Ÿæå‡ç”¨æˆ·ä½“éªŒå¹¶æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Hand-object 3D reconstruction has become increasingly important for applications in human-robot interaction and immersive AR/VR experiences. A common approach for object-agnostic hand-object reconstruction from RGB sequences involves a two-stage pipeline: hand-object 3D tracking followed by multi-view 3D reconstruction. However, existing methods rely on keypoint detection techniques, such as Structure from Motion (SfM) and hand-keypoint optimization, which struggle with diverse object geometries, weak textures, and mutual hand-object occlusions, limiting scalability and generalization. As a key enabler to generic and seamless, non-intrusive applicability, we propose in this work a robust, keypoint detector-free approach to estimating hand-object 3D transformations from monocular motion video/images. We further integrate this with a multi-view reconstruction pipeline to accurately recover hand-object 3D shape. Our method, named HOSt3R, is unconstrained, does not rely on pre-scanned object templates or camera intrinsics, and reaches state-of-the-art performance for the tasks of object-agnostic hand-object 3D transformation and shape estimation on the SHOWMe benchmark. We also experiment on sequences from the HO3D dataset, demonstrating generalization to unseen object categories.

