---
layout: default
title: Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation
---

# Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10395" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10395v2</a>
  <a href="https://arxiv.org/pdf/2506.10395.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10395v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10395v2', 'Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhiyang Xu, Jiuhai Chen, Zhaojiang Lin, Xichen Pan, Lifu Huang, Tianyi Zhou, Madian Khabsa, Qifan Wang, Di Jin, Michihiro Yasunaga, Lili Yu, Xi Victoria Lin, Shaoliang Nie

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12 (æ›´æ–°: 2025-07-12)

**å¤‡æ³¨**: Unified image understanding and generation model

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPiscesä»¥è§£å†³å¤šæ¨¡æ€å›¾åƒç†è§£ä¸ç”Ÿæˆçš„ç»Ÿä¸€æ¨¡å‹æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨¡å‹` `å›¾åƒç†è§£` `å›¾åƒç”Ÿæˆ` `è‡ªå›å½’æ¨¡å‹` `è§†è§‰ç¼–ç ` `æ·±åº¦å­¦ä¹ ` `æ¨¡å‹ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹åœ¨å›¾åƒç†è§£å’Œç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œä¸»è¦ç”±äºè§†è§‰ç‰¹å¾å’Œè®­ç»ƒè¿‡ç¨‹çš„å·®å¼‚ã€‚
2. Piscesé€šè¿‡è§£è€¦è§†è§‰ç¼–ç æ¶æ„å’Œå®šåˆ¶çš„è®­ç»ƒæŠ€æœ¯ï¼Œä¼˜åŒ–äº†å¤šæ¨¡æ€ç”Ÿæˆè¿‡ç¨‹ï¼Œä»è€Œæå‡äº†æ¨¡å‹æ€§èƒ½ã€‚
3. åœ¨è¶…è¿‡20ä¸ªå…¬å…±åŸºå‡†ä¸Šï¼ŒPiscesåœ¨å›¾åƒç†è§£ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶åœ¨GenEvalåŸºå‡†ä¸Šå±•ç°äº†å¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›å±•ä½¿å¾—å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹èƒ½å¤Ÿåœ¨ç»Ÿä¸€æ¡†æ¶ä¸‹å¤„ç†å›¾åƒç†è§£å’Œç”Ÿæˆä»»åŠ¡ã€‚ç„¶è€Œï¼Œç»Ÿä¸€æ¨¡å‹åœ¨è¿™ä¸¤é¡¹ä»»åŠ¡ä¸­çš„è¡¨ç°å¾€å¾€ä¸åŠä¸“é—¨æ¨¡å‹ã€‚æœ¬æ–‡æå‡ºPiscesï¼Œä¸€ä¸ªè‡ªå›å½’çš„å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹ï¼Œé€šè¿‡æ–°é¢–çš„è§£è€¦è§†è§‰ç¼–ç æ¶æ„å’Œé’ˆå¯¹å¤šæ¨¡æ€ç”Ÿæˆä¼˜åŒ–çš„è®­ç»ƒæŠ€æœ¯æ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚ç»“åˆç²¾å¿ƒçš„æ•°æ®ç­–åˆ’ã€é¢„è®­ç»ƒå’Œå¾®è°ƒï¼ŒPiscesåœ¨å›¾åƒç†è§£å’Œç”Ÿæˆä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºè‰²ã€‚æˆ‘ä»¬åœ¨20å¤šä¸ªå…¬å…±åŸºå‡†ä¸Šè¯„ä¼°äº†Piscesï¼Œç»“æœæ˜¾ç¤ºå…¶åœ¨å¤šç§ä»»åŠ¡ä¸­å‡è¡¨ç°å¼ºåŠ²ï¼Œå¹¶åœ¨å›¾åƒç”Ÿæˆçš„å¹¿æ³›é‡‡ç”¨åŸºå‡†GenEvalä¸Šå±•ç°å‡ºç¨³å¥çš„ç”Ÿæˆèƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹åœ¨å›¾åƒç†è§£ä¸ç”Ÿæˆä»»åŠ¡ä¸­æ€§èƒ½ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è§†è§‰ç‰¹å¾æ—¶ï¼Œå¾€å¾€æ— æ³•å…¼é¡¾ä¸¤è€…çš„éœ€æ±‚ï¼Œå¯¼è‡´æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPiscesçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è§£è€¦è§†è§‰ç¼–ç æ¶æ„ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåˆ†åˆ«ä¼˜åŒ–å›¾åƒç†è§£å’Œç”Ÿæˆçš„ç‰¹å¾è¡¨ç¤ºï¼Œä»è€Œæé«˜æ•´ä½“æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPiscesçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®ç­–åˆ’ã€é¢„è®­ç»ƒå’Œå¾®è°ƒä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œé€šè¿‡ç²¾å¿ƒé€‰æ‹©å’Œå¤„ç†æ•°æ®é›†æ¥å¢å¼ºæ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›ï¼›å…¶æ¬¡ï¼Œè¿›è¡Œé¢„è®­ç»ƒä»¥å­¦ä¹ é€šç”¨çš„è§†è§‰ç‰¹å¾ï¼›æœ€åï¼Œé€šè¿‡å¾®è°ƒæ¥é€‚åº”ç‰¹å®šä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šPiscesçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è§£è€¦çš„è§†è§‰ç¼–ç å™¨è®¾è®¡ï¼Œè¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿç‹¬ç«‹å¤„ç†å›¾åƒç†è§£å’Œç”Ÿæˆä»»åŠ¡çš„ç‰¹å¾ï¼Œä»è€Œå…‹æœäº†ä¼ ç»Ÿç»Ÿä¸€æ¨¡å‹çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼ŒPiscesé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡å›¾åƒç†è§£ä¸ç”Ÿæˆçš„è®­ç»ƒç›®æ ‡ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šå¼•å…¥äº†å¤šå±‚æ¬¡çš„è§†è§‰ç¼–ç å™¨ï¼Œä»¥æ•æ‰ä¸åŒå±‚æ¬¡çš„ç‰¹å¾ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒPiscesåœ¨è¶…è¿‡20ä¸ªå…¬å…±åŸºå‡†ä¸Šå±•ç°äº†å¼ºåŠ²çš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨å›¾åƒç†è§£ä»»åŠ¡ä¸­ï¼Œæ˜¾è‘—è¶…è¶Šäº†å¤šä¸ªåŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œåœ¨GenEvalåŸºå‡†ä¸Šï¼ŒPiscesçš„ç”Ÿæˆèƒ½åŠ›ä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Piscesæ¨¡å‹åœ¨å›¾åƒç†è§£å’Œç”Ÿæˆé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œèƒ½å¤Ÿç”¨äºæ™ºèƒ½å›¾åƒæœç´¢ã€è‡ªåŠ¨å›¾åƒæ ‡æ³¨ã€å†…å®¹ç”Ÿæˆç­‰ä»»åŠ¡ã€‚å…¶åˆ›æ–°çš„è§£è€¦è®¾è®¡ä¸ºæœªæ¥å¤šæ¨¡æ€æ¨¡å‹çš„å‘å±•æä¾›äº†æ–°çš„æ€è·¯ï¼Œå¯èƒ½æ¨åŠ¨ç›¸å…³æŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­çš„è½åœ°ä¸æ™®åŠã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in large language models (LLMs) have enabled multimodal foundation models to tackle both image understanding and generation within a unified framework. Despite these gains, unified models often underperform compared to specialized models in either task. A key challenge in developing unified models lies in the inherent differences between the visual features needed for image understanding versus generation, as well as the distinct training processes required for each modality. In this work, we introduce Pisces, an auto-regressive multimodal foundation model that addresses this challenge through a novel decoupled visual encoding architecture and tailored training techniques optimized for multimodal generation. Combined with meticulous data curation, pretraining, and finetuning, Pisces achieves competitive performance in both image understanding and image generation. We evaluate Pisces on over 20 public benchmarks for image understanding, where it demonstrates strong performance across a wide range of tasks. Additionally, on GenEval, a widely adopted benchmark for image generation, Pisces exhibits robust generative capabilities. Our extensive analysis reveals the synergistic relationship between image understanding and generation, and the benefits of using separate visual encoders, advancing the field of unified multimodal models.

