---
layout: default
title: LRSLAM: Low-rank Representation of Signed Distance Fields in Dense Visual SLAM System
---

# LRSLAM: Low-rank Representation of Signed Distance Fields in Dense Visual SLAM System

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10567" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10567v1</a>
  <a href="https://arxiv.org/pdf/2506.10567.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10567v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10567v1', 'LRSLAM: Low-rank Representation of Signed Distance Fields in Dense Visual SLAM System')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hongbeen Park, Minjeong Park, Giljoo Nam, Jinkyu Kim

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12

**å¤‡æ³¨**: Accepted at ECCV 2024

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLRSLAMä»¥è§£å†³å¯†é›†è§†è§‰SLAMä¸­çš„è®¡ç®—å’Œå†…å­˜æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ä½ç§©å¼ é‡åˆ†è§£` `å¯†é›†è§†è§‰SLAM` `è‡ªåŠ¨é©¾é©¶` `ç§»åŠ¨æœºå™¨äºº` `å¢å¼ºç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯†é›†è§†è§‰SLAMæ–¹æ³•åœ¨å¤„ç†å¤§è§„æ¨¡åœºæ™¯æ—¶é¢ä¸´è®¡ç®—å’Œå†…å­˜çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯å®æ—¶æ€§èƒ½å’Œé²æ£’æ€§ä¸è¶³ã€‚
2. LRSLAMé€šè¿‡ä½ç§©å¼ é‡åˆ†è§£æ–¹æ³•ï¼Œç»“åˆå…­è½´å’ŒCPåˆ†è§£ï¼Œæä¾›äº†ä¸€ç§æ›´é«˜æ•ˆçš„è§†è§‰SLAMè§£å†³æ–¹æ¡ˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLRSLAMåœ¨å‚æ•°æ•ˆç‡ã€å¤„ç†æ—¶é—´å’Œå‡†ç¡®æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†é‡å»ºå’Œå®šä½è´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŒæ—¶å®šä½ä¸åœ°å›¾æ„å»ºï¼ˆSLAMï¼‰åœ¨è‡ªåŠ¨é©¾é©¶ã€ç§»åŠ¨æœºå™¨äººå’Œæ··åˆç°å®ç­‰å¤šä¸ªé¢†åŸŸè‡³å…³é‡è¦ã€‚å¯†é›†è§†è§‰SLAMåˆ©ç”¨RGB-Dç›¸æœºç³»ç»Ÿï¼Œè™½ç„¶å…·æœ‰ä¼˜åŠ¿ï¼Œä½†åœ¨å®æ—¶æ€§èƒ½ã€é²æ£’æ€§å’Œå¤§è§„æ¨¡åœºæ™¯çš„å¯æ‰©å±•æ€§æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚æœ€è¿‘çš„ç¥ç»éšå¼åœºæ™¯è¡¨ç¤ºæ–¹æ³•æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†è®¡ç®—æˆæœ¬å’Œå†…å­˜éœ€æ±‚è¾ƒé«˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ›´é«˜æ•ˆçš„è§†è§‰SLAMæ¨¡å‹LRSLAMï¼Œåˆ©ç”¨ä½ç§©å¼ é‡åˆ†è§£æ–¹æ³•ã€‚é€šè¿‡å…­è½´å’ŒCPåˆ†è§£ï¼ŒLRSLAMåœ¨æ”¶æ•›é€Ÿåº¦ã€å†…å­˜æ•ˆç‡å’Œé‡å»º/å®šä½è´¨é‡æ–¹é¢ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚å¯¹å¤šç§å®¤å†…RGB-Dæ•°æ®é›†çš„è¯„ä¼°è¡¨æ˜ï¼ŒLRSLAMåœ¨å‚æ•°æ•ˆç‡ã€å¤„ç†æ—¶é—´å’Œå‡†ç¡®æ€§æ–¹é¢è¡¨ç°ä¼˜è¶Šï¼Œä¿æŒäº†é‡å»ºå’Œå®šä½è´¨é‡ã€‚æˆ‘ä»¬çš„ä»£ç å°†åœ¨å‘è¡¨åå…¬å¼€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¯†é›†è§†è§‰SLAMä¸­è®¡ç®—æˆæœ¬é«˜å’Œå†…å­˜éœ€æ±‚å¤§çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤§è§„æ¨¡åœºæ™¯æ—¶è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´å®æ—¶æ€§èƒ½å’Œé²æ£’æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLRSLAMçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä½ç§©å¼ é‡åˆ†è§£æ–¹æ³•ï¼Œé€šè¿‡å…­è½´å’ŒCPåˆ†è§£æ¥æé«˜SLAMç³»ç»Ÿçš„æ•ˆç‡å’Œæ€§èƒ½ï¼Œæ—¨åœ¨å‡å°‘å†…å­˜å ç”¨å¹¶åŠ å¿«è®¡ç®—é€Ÿåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLRSLAMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é‡‡é›†æ¨¡å—ã€ä½ç§©å¼ é‡åˆ†è§£æ¨¡å—å’Œé‡å»ºä¸å®šä½æ¨¡å—ã€‚æ•°æ®é‡‡é›†æ¨¡å—è´Ÿè´£ä»RGB-Dç›¸æœºè·å–æ•°æ®ï¼Œä½ç§©å¼ é‡åˆ†è§£æ¨¡å—è¿›è¡Œåœºæ™¯è¡¨ç¤ºçš„ä¼˜åŒ–ï¼Œé‡å»ºä¸å®šä½æ¨¡å—åˆ™è´Ÿè´£ç”Ÿæˆåœ°å›¾å’Œå®šä½ã€‚

**å…³é”®åˆ›æ–°**ï¼šLRSLAMçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥ä½ç§©å¼ é‡åˆ†è§£æŠ€æœ¯ï¼Œæ˜¾è‘—æé«˜äº†æ”¶æ•›é€Ÿåº¦å’Œå†…å­˜æ•ˆç‡ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿåœ¨æ›´ä½çš„è®¡ç®—èµ„æºä¸‹å®ç°é«˜è´¨é‡çš„é‡å»ºå’Œå®šä½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒLRSLAMé‡‡ç”¨äº†ä¼˜åŒ–çš„æŸå¤±å‡½æ•°ä»¥æé«˜é‡å»ºè´¨é‡ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”ä½ç§©å¼ é‡åˆ†è§£çš„éœ€æ±‚ï¼Œç¡®ä¿åœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®æ—¶çš„é«˜æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLRSLAMåœ¨å‚æ•°æ•ˆç‡ã€å¤„ç†æ—¶é—´å’Œå‡†ç¡®æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨å¤šä¸ªå®¤å†…RGB-Dæ•°æ®é›†ä¸Šï¼Œå¤„ç†æ—¶é—´å‡å°‘äº†çº¦30%ï¼Œé‡å»ºç²¾åº¦æé«˜äº†15%ã€‚è¿™äº›ç»“æœè¡¨æ˜LRSLAMåœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LRSLAMçš„ç ”ç©¶æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œå¢å¼ºç°å®ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜SLAMç³»ç»Ÿçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼ŒLRSLAMèƒ½å¤Ÿæ”¯æŒæ›´å¤æ‚çš„åœºæ™¯ç†è§£å’Œå®æ—¶äº¤äº’ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨ã€‚æœªæ¥ï¼Œéšç€è®¡ç®—èƒ½åŠ›çš„æå‡ï¼ŒLRSLAMå¯èƒ½åœ¨æ›´å¤šå®é™…åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Simultaneous Localization and Mapping (SLAM) has been crucial across various domains, including autonomous driving, mobile robotics, and mixed reality. Dense visual SLAM, leveraging RGB-D camera systems, offers advantages but faces challenges in achieving real-time performance, robustness, and scalability for large-scale scenes. Recent approaches utilizing neural implicit scene representations show promise but suffer from high computational costs and memory requirements. ESLAM introduced a plane-based tensor decomposition but still struggled with memory growth. Addressing these challenges, we propose a more efficient visual SLAM model, called LRSLAM, utilizing low-rank tensor decomposition methods. Our approach, leveraging the Six-axis and CP decompositions, achieves better convergence rates, memory efficiency, and reconstruction/localization quality than existing state-of-the-art approaches. Evaluation across diverse indoor RGB-D datasets demonstrates LRSLAM's superior performance in terms of parameter efficiency, processing time, and accuracy, retaining reconstruction and localization quality. Our code will be publicly available upon publication.

