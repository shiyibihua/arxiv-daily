---
layout: default
title: Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs
---

# Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10967" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10967v2</a>
  <a href="https://arxiv.org/pdf/2506.10967.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10967v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10967v2', 'Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qizhe Zhang, Mengzhen Liu, Lichen Li, Ming Lu, Yuan Zhang, Junwen Pan, Qi She, Shanghang Zhang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12 (æ›´æ–°: 2025-07-01)

**å¤‡æ³¨**: 22 pages, 5 figures, code: https://github.com/Theia-4869/CDPruner, project page: https://theia-4869.github.io/CDPruner

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Theia-4869/CDPruner)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCDPrunerä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­çš„è§†è§‰tokenå†—ä½™é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰tokenä¿®å‰ª` `æ¡ä»¶å¤šæ ·æ€§` `å†³å®šæ€§ç‚¹è¿‡ç¨‹` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è§†è§‰-è¯­è¨€åŸºå‡†` `é«˜æ•ˆæ¨ç†` `æ¨¡å‹æ— å…³`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰tokenä¿®å‰ªæ–¹æ³•è¦ä¹ˆä¾èµ–äºæ³¨æ„åŠ›æœºåˆ¶ï¼Œå¯¼è‡´å†—ä½™tokençš„ä¿ç•™ï¼Œè¦ä¹ˆåŸºäºç›¸ä¼¼æ€§ï¼Œå¿½è§†æŒ‡ä»¤ç›¸å…³æ€§ï¼Œé€ æˆæ€§èƒ½ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºCDPrunerï¼Œé€šè¿‡æœ€å¤§åŒ–æ¡ä»¶å¤šæ ·æ€§æ¥ä¼˜åŒ–tokenä¿®å‰ªï¼Œå®šä¹‰äº†åŸºäºæŒ‡ä»¤çš„æ¡ä»¶ç›¸ä¼¼æ€§ï¼Œå¹¶åˆ©ç”¨DPPé‡æ–°æ„å»ºä¿®å‰ªé—®é¢˜ã€‚
3. CDPruneråœ¨LLaVAæ¨¡å‹ä¸Šå®ç°äº†95%çš„FLOPså‡å°‘å’Œ78%çš„CUDAå»¶è¿Ÿé™ä½ï¼ŒåŒæ—¶ä¿æŒ94%çš„åŸå§‹å‡†ç¡®ç‡ï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­ï¼Œè¾“å…¥è§†è§‰tokençš„é•¿åº¦é€šå¸¸æ˜¾è‘—å¤§äºæ–‡æœ¬tokenï¼Œå¯¼è‡´é«˜æ¨ç†æˆæœ¬ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡æ³¨æ„åŠ›æˆ–ç›¸ä¼¼æ€§è¿›è¡Œtokenä¿®å‰ªï¼Œä½†å­˜åœ¨ä¿ç•™å†—ä½™tokenæˆ–å¿½è§†æŒ‡ä»¤ç›¸å…³æ€§çš„é—®é¢˜ï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è§†è§‰tokenä¿®å‰ªæ–¹æ³•CDPrunerï¼Œæ—¨åœ¨æœ€å¤§åŒ–ä¿ç•™tokençš„æ¡ä»¶å¤šæ ·æ€§ã€‚æˆ‘ä»¬å®šä¹‰äº†åŸºäºæŒ‡ä»¤çš„è§†è§‰tokenæ¡ä»¶ç›¸ä¼¼æ€§ï¼Œå¹¶é€šè¿‡å†³å®šæ€§ç‚¹è¿‡ç¨‹ï¼ˆDPPï¼‰é‡æ–°æ„å»ºtokenä¿®å‰ªé—®é¢˜ï¼Œä»¥æœ€å¤§åŒ–æ‰€é€‰å­é›†çš„æ¡ä»¶å¤šæ ·æ€§ã€‚CDPruneræ— éœ€è®­ç»ƒä¸”ä¸æ¨¡å‹æ— å…³ï¼Œé€‚ç”¨äºå¤šç§MLLMsã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCDPruneråœ¨å¤šä¸ªè§†è§‰-è¯­è¨€åŸºå‡†ä¸Šå»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ï¼Œèƒ½å¤Ÿåœ¨é«˜å‹ç¼©æ¯”ä¸‹ä¿æŒå¼ºæ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­è§†è§‰tokenå†—ä½™çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä¿®å‰ªè¿‡ç¨‹ä¸­è¦ä¹ˆä¿ç•™äº†å¤§é‡é‡å¤tokenï¼Œè¦ä¹ˆå¿½è§†äº†ä¸ç”¨æˆ·æŒ‡ä»¤çš„ç›¸å…³æ€§ï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCDPrunerçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æœ€å¤§åŒ–æ¡ä»¶å¤šæ ·æ€§æ¥ä¼˜åŒ–tokençš„é€‰æ‹©ã€‚é€šè¿‡å®šä¹‰è§†è§‰tokençš„æ¡ä»¶ç›¸ä¼¼æ€§ï¼Œç¡®ä¿æ‰€é€‰tokenä¸ä»…å¤šæ ·åŒ–ï¼Œè¿˜èƒ½ä¸ç”¨æˆ·æŒ‡ä»¤ç´§å¯†ç›¸å…³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCDPrunerçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œè®¡ç®—è§†è§‰tokençš„æ¡ä»¶ç›¸ä¼¼æ€§ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨å†³å®šæ€§ç‚¹è¿‡ç¨‹ï¼ˆDPPï¼‰è¿›è¡Œtokençš„é€‰æ‹©ï¼Œä»¥æœ€å¤§åŒ–æ‰€é€‰å­é›†çš„æ¡ä»¶å¤šæ ·æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šCDPrunerçš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†æ¡ä»¶å¤šæ ·æ€§æœ€å¤§åŒ–çš„æ¦‚å¿µï¼Œä¸ç°æœ‰çš„æ³¨æ„åŠ›å’Œç›¸ä¼¼æ€§æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°é€‰æ‹©ä¸æŒ‡ä»¤ç›¸å…³çš„å¤šæ ·åŒ–tokenã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒCDPrunerä¸éœ€è¦é¢å¤–çš„è®­ç»ƒè¿‡ç¨‹ï¼Œä¸”ä¸æ¨¡å‹æ— å…³ï¼Œèƒ½å¤Ÿæ–¹ä¾¿åœ°åº”ç”¨äºä¸åŒçš„MLLMsã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œéœ€å‚è€ƒå®Œæ•´è®ºæ–‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CDPruneråœ¨LLaVAæ¨¡å‹ä¸Šå®ç°äº†95%çš„FLOPså‡å°‘å’Œ78%çš„CUDAå»¶è¿Ÿé™ä½ï¼ŒåŒæ—¶ä¿æŒ94%çš„åŸå§‹å‡†ç¡®ç‡ï¼Œå±•ç¤ºäº†å…¶åœ¨è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸­çš„æ˜¾è‘—æ€§èƒ½æå‡ï¼Œç¡®ç«‹äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è§†è§‰é—®ç­”ã€å›¾åƒæè¿°ç”Ÿæˆå’Œå¤šæ¨¡æ€å†…å®¹æ£€ç´¢ç­‰ã€‚é€šè¿‡ä¼˜åŒ–è§†è§‰tokençš„é€‰æ‹©ï¼ŒCDPrunerèƒ½å¤Ÿæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒé«˜æ€§èƒ½ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In multimodal large language models (MLLMs), the length of input visual tokens is often significantly greater than that of their textual counterparts, leading to a high inference cost. Many works aim to address this issue by removing redundant visual tokens. However, current approaches either rely on attention-based pruning, which retains numerous duplicate tokens, or use similarity-based pruning, overlooking the instruction relevance, consequently causing suboptimal performance. In this paper, we go beyond attention or similarity by proposing a novel visual token pruning method named CDPruner, which maximizes the conditional diversity of retained tokens. We first define the conditional similarity between visual tokens conditioned on the instruction, and then reformulate the token pruning problem with determinantal point process (DPP) to maximize the conditional diversity of the selected subset. The proposed CDPruner is training-free and model-agnostic, allowing easy application to various MLLMs. Extensive experiments across diverse MLLMs show that CDPruner establishes new state-of-the-art on various vision-language benchmarks. By maximizing conditional diversity through DPP, the selected subset better represents the input images while closely adhering to user instructions, thereby preserving strong performance even with high reduction ratios. When applied to LLaVA, CDPruner reduces FLOPs by 95\% and CUDA latency by 78\%, while maintaining 94\% of the original accuracy. Our code is available at https://github.com/Theia-4869/CDPruner.

