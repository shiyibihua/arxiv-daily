---
layout: default
title: Towards Robust Multimodal Emotion Recognition under Missing Modalities and Distribution Shifts
---

# Towards Robust Multimodal Emotion Recognition under Missing Modalities and Distribution Shifts

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10452" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.10452v1</a>
  <a href="https://arxiv.org/pdf/2506.10452.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10452v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10452v1', 'Towards Robust Multimodal Emotion Recognition under Missing Modalities and Distribution Shifts')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Guowei Zhong, Ruohong Huan, Mingzhen Wu, Ronghua Liang, Peng Chen

**ÂàÜÁ±ª**: cs.CV, cs.CL, cs.LG, cs.MM

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-12

**Â§áÊ≥®**: Submitted to TAC. The code is available at https://github.com/gw-zhong/CIDer

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/gw-zhong/CIDer)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫CIDerÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÊÉÖÊÑüËØÜÂà´‰∏≠ÁöÑÁº∫Â§±Ê®°ÊÄÅÂíåÂàÜÂ∏ÉÂÅèÁßªÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÊÉÖÊÑüËØÜÂà´` `Ê®°ÊÄÅÁº∫Â§±` `ÂàÜÂ∏ÉÂÅèÁßª` `Âõ†ÊûúÊé®Êñ≠` `Ëá™Ëí∏È¶è` `Ê∑±Â∫¶Â≠¶‰π†` `ÊÉÖÊÑüÂàÜÊûê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂ§öÊ®°ÊÄÅÊÉÖÊÑüËØÜÂà´ÊñπÊ≥ïÂú®Â§ÑÁêÜÊ®°ÊÄÅÁº∫Â§±ÂíåÂàÜÂ∏ÉÂÅèÁßªÊó∂Â≠òÂú®Â±ÄÈôêÊÄßÔºåÈÄöÂ∏∏‰æùËµñÁâπÂÆöÊ®°ÂûãÊàñÂºïÂÖ•ËøáÂ§öÂèÇÊï∞„ÄÇ
2. Êú¨ÊñáÊèêÂá∫CIDerÊ°ÜÊû∂ÔºåÈÄöËøáÊ®°ÂûãÁâπÂÆöËá™Ëí∏È¶èÂíåÊ®°ÂûãÊó†ÂÖ≥Âõ†ÊûúÊé®Êñ≠Ê®°ÂùóÔºåËß£ÂÜ≥Ê®°ÊÄÅÁº∫Â§±ÂíåOODÈóÆÈ¢ò„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåCIDerÂú®RMFMÂíåOODÂú∫ÊôØ‰∏ãË°®Áé∞‰ºòÂºÇÔºåÂèÇÊï∞Êõ¥Â∞ëÔºåËÆ≠ÁªÉÈÄüÂ∫¶Êõ¥Âø´ÔºåÁõ∏ËæÉ‰∫éÁé∞ÊúâÊñπÊ≥ïÊúâÊòæËëóÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËøëÂπ¥Êù•ÔºåÂ§öÊ®°ÊÄÅÊÉÖÊÑüËØÜÂà´ÔºàMERÔºâÂú®Â§ÑÁêÜÊ®°ÊÄÅÁº∫Â§±ÂíåÂàÜÂ∏ÉÂÅèÁßªÔºàOODÔºâÊï∞ÊçÆÊñπÈù¢Èù¢‰∏¥ÊåëÊàò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñÁâπÂÆöÊ®°ÂûãÊàñÂºïÂÖ•ËøáÂ§öÂèÇÊï∞ÔºåÈôêÂà∂‰∫ÜÂÖ∂ÂÆûÁî®ÊÄß„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÈ≤ÅÊ£íMERÊ°ÜÊû∂CIDerÔºåÂπ∂ÂºïÂÖ•‰∫ÜÈöèÊú∫Ê®°ÊÄÅÁâπÂæÅÁº∫Â§±ÔºàRMFMÔºâËøô‰∏ÄÊñ∞‰ªªÂä°Ôºå‰ª•Êé®ÂπøÊ®°ÊÄÅÁº∫Â§±ÁöÑÂÆö‰πâ„ÄÇCIDerÈõÜÊàê‰∫ÜÊ®°ÂûãÁâπÂÆöËá™Ëí∏È¶èÔºàMSSDÔºâÊ®°ÂùóÂíåÊ®°ÂûãÊó†ÂÖ≥Âõ†ÊûúÊé®Êñ≠ÔºàMACIÔºâÊ®°ÂùóÔºåÂâçËÄÖÈÄöËøáÊùÉÈáçÂÖ±‰∫´Ëá™Ëí∏È¶èÊñπÊ≥ïÂ¢ûÂº∫‰∫ÜÂú®RMFM‰ªªÂä°‰∏ãÁöÑÈ≤ÅÊ£íÊÄßÔºåÂêéËÄÖÂàôÂà©Áî®Âõ†ÊûúÂõæÁºìËß£Ê†áÁ≠æÂíåËØ≠Ë®ÄÂÅèËßÅ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCIDerÂú®RMFMÂíåOODÂú∫ÊôØ‰∏ãÂùáË°®Áé∞Âá∫Ëâ≤ÔºåÂèÇÊï∞Êõ¥Â∞ëÔºåËÆ≠ÁªÉÈÄüÂ∫¶Êõ¥Âø´Ôºå‰∏îÂÆûÁé∞‰ª£Á†ÅÂ∑≤ÂÖ¨ÂºÄ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÊÉÖÊÑüËØÜÂà´‰∏≠Ê®°ÊÄÅÁº∫Â§±ÂíåÂàÜÂ∏ÉÂÅèÁßªÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄ‰æùËµñÁâπÂÆöÊ®°ÂûãÔºåÂØºËá¥Âú®Â§ÑÁêÜÁº∫Â§±Ê®°ÊÄÅÂíåOODÊï∞ÊçÆÊó∂ÁöÑÈ≤ÅÊ£íÊÄß‰∏çË∂≥Ôºå‰∏îÂºïÂÖ•ËøáÂ§öÂèÇÊï∞‰ΩøÂæóÂÆûÈôÖÂ∫îÁî®ÂèóÈôê„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöCIDerÊ°ÜÊû∂ÈÄöËøáÂºïÂÖ•ÈöèÊú∫Ê®°ÊÄÅÁâπÂæÅÁº∫Â§±ÔºàRMFMÔºâ‰ªªÂä°ÔºåÊé®ÂπøÊ®°ÊÄÅÁº∫Â§±ÁöÑÂÆö‰πâÔºåÂπ∂ÁªìÂêàÊ®°ÂûãÁâπÂÆöËá™Ëí∏È¶èÔºàMSSDÔºâÂíåÊ®°ÂûãÊó†ÂÖ≥Âõ†ÊûúÊé®Êñ≠ÔºàMACIÔºâÊ®°ÂùóÔºåÂ¢ûÂº∫Ê®°ÂûãÂú®‰∏çÂêåÂú∫ÊôØ‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCIDerÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨MSSDÊ®°ÂùóÂíåMACIÊ®°Âùó„ÄÇMSSDÈÄöËøáÊùÉÈáçÂÖ±‰∫´Ëá™Ëí∏È¶èÊñπÊ≥ïÔºåÂ¢ûÂº∫‰ΩéÂ±ÇÁâπÂæÅ„ÄÅÊ≥®ÊÑèÂäõÂõæÂíåÈ´òÂ±ÇË°®Á§∫ÁöÑÈ≤ÅÊ£íÊÄßÔºõMACIÂàôÂà©Áî®Âõ†ÊûúÂõæÂíåÂ§öÊ®°ÊÄÅÂõ†ÊûúÊ®°ÂùóÔºàMCMÔºâÊù•ÁºìËß£Ê†áÁ≠æÂíåËØ≠Ë®ÄÂÅèËßÅ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöCIDerÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂Ê®°ÂùóÂåñËÆæËÆ°Ôºå‰ΩøÂæóÂú®Â§ÑÁêÜÊ®°ÊÄÅÁº∫Â§±ÂíåOODÈóÆÈ¢òÊó∂ÔºåËÉΩÂ§üÁã¨Á´ãÊèêÂçáÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÔºå‰∏î‰ªÖÈúÄÂ∞ëÈáèÈ¢ùÂ§ñÂèÇÊï∞„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®MSSDÊ®°Âùó‰∏≠ÔºåÈááÁî®ÊùÉÈáçÂÖ±‰∫´ÁöÑËá™Ëí∏È¶èÁ≠ñÁï•ÔºåÈôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÔºõWSAMÊ®°ÂùóÁî®‰∫éÂáèÂ∞ëËÆ°ÁÆóË¥üÊãÖÔºõMCTÊ®°ÂùóÂàôÂÆûÁé∞È´òÊïàÁöÑÂ§öÊ®°ÊÄÅËûçÂêà„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCIDerÂú®RMFMÂíåOODÂú∫ÊôØ‰∏ãÁöÑË°®Áé∞‰ºò‰∫éÁé∞ÊúâÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÔºåÂèÇÊï∞Êõ¥Â∞ëÔºåËÆ≠ÁªÉÈÄüÂ∫¶Êõ¥Âø´„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåCIDerÂú®OOD‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÈ™åËØÅ‰∫ÜÂÖ∂È´òÊïàÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÊÉÖÊÑüÂàÜÊûê„ÄÅÁ§æ‰∫§Â™í‰ΩìÁõëÊµãÂíå‰∫∫Êú∫‰∫§‰∫íÁ≠â„ÄÇÈÄöËøáÊèêÂçáÂ§öÊ®°ÊÄÅÊÉÖÊÑüËØÜÂà´ÁöÑÈ≤ÅÊ£íÊÄßÔºåCIDerËÉΩÂ§üÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Êõ¥Â•ΩÂú∞Â§ÑÁêÜÊ®°ÊÄÅÁº∫Â§±ÂíåÂàÜÂ∏ÉÂÅèÁßªÈóÆÈ¢òÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent advancements in Multimodal Emotion Recognition (MER) face challenges in addressing both modality missing and Out-Of-Distribution (OOD) data simultaneously. Existing methods often rely on specific models or introduce excessive parameters, which limits their practicality. To address these issues, we propose a novel robust MER framework, Causal Inference Distiller (CIDer), and introduce a new task, Random Modality Feature Missing (RMFM), to generalize the definition of modality missing. CIDer integrates two key components: a Model-Specific Self-Distillation (MSSD) module and a Model-Agnostic Causal Inference (MACI) module. MSSD enhances robustness under the RMFM task through a weight-sharing self-distillation approach applied across low-level features, attention maps, and high-level representations. Additionally, a Word-level Self-aligned Attention Module (WSAM) reduces computational complexity, while a Multimodal Composite Transformer (MCT) facilitates efficient multimodal fusion. To tackle OOD challenges, MACI employs a tailored causal graph to mitigate label and language biases using a Multimodal Causal Module (MCM) and fine-grained counterfactual texts. Notably, MACI can independently enhance OOD generalization with minimal additional parameters. Furthermore, we also introduce the new repartitioned MER OOD datasets. Experimental results demonstrate that CIDer achieves robust performance in both RMFM and OOD scenarios, with fewer parameters and faster training compared to state-of-the-art methods. The implementation of this work is publicly accessible at https://github.com/gw-zhong/CIDer.

