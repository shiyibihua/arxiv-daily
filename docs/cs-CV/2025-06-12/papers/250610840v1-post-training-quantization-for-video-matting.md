---
layout: default
title: Post-Training Quantization for Video Matting
---

# Post-Training Quantization for Video Matting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10840" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.10840v1</a>
  <a href="https://arxiv.org/pdf/2506.10840.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10840v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10840v1', 'Post-Training Quantization for Video Matting')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Tianrui Zhu, Houyuan Chen, Ruihao Gong, Michele Magno, Haotong Qin, Kai Zhang

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-12

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ÂêéËÆ≠ÁªÉÈáèÂåñÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥ËßÜÈ¢ëÊä†ÂõæÊ®°ÂûãÁöÑËµÑÊ∫êÈôêÂà∂ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÊä†Âõæ` `ÂêéËÆ≠ÁªÉÈáèÂåñ` `Ê®°ÂûãÂéãÁº©` `ÂÖâÊµÅËæÖÂä©` `ÁªüËÆ°Ê†°ÂáÜ` `ËÆ°ÁÆóÊú∫ËßÜËßâ` `ËµÑÊ∫êÂèóÈôêËÆæÂ§á`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëÊä†ÂõæÊ®°ÂûãÂú®ËµÑÊ∫êÂèóÈôêËÆæÂ§á‰∏äÈÉ®ÁΩ≤Êó∂ÔºåËÆ°ÁÆóÂ§çÊùÇÂ∫¶È´ò‰∏îÈöæ‰ª•‰øùÊåÅÂáÜÁ°ÆÊÄßÂíåÊó∂Èó¥‰∏ÄËá¥ÊÄß„ÄÇ
2. ÊèêÂá∫‰∫Ü‰∏ÄÁßç‰∏§Èò∂ÊÆµÁöÑPTQÁ≠ñÁï•ÔºåÁªìÂêàÂùóÈáçÂª∫‰ºòÂåñÂíåÂÖ®Â±ÄÂèÇÊï∞Ê†°ÂáÜÔºå‰ª•ÂáèÂ∞ëÂáÜÁ°ÆÊÄßÊçüÂ§±„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPTQ4VMÂú®‰∏çÂêå‰ΩçÂÆΩ‰∏ãÁöÑÂáÜÁ°ÆÊÄßËææÂà∞ÊúÄÂÖàËøõÊ∞¥Âπ≥Ôºå4‰ΩçÈáèÂåñÊÄßËÉΩÊé•ËøëÂÖ®Á≤æÂ∫¶Ê®°ÂûãÔºåÂêåÊó∂ËäÇÁúÅ8ÂÄçFLOP„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜÈ¢ëÊä†ÂõæÂú®ÁîµÂΩ±Âà∂‰ΩúÂíåËôöÊãüÁé∞ÂÆûÁ≠âÂ∫îÁî®‰∏≠Ëá≥ÂÖ≥ÈáçË¶ÅÔºå‰ΩÜÂú®ËµÑÊ∫êÂèóÈôêËÆæÂ§á‰∏äÈÉ®ÁΩ≤ÂÖ∂ËÆ°ÁÆóÂØÜÈõÜÂûãÊ®°ÂûãÈù¢‰∏¥ÊåëÊàò„ÄÇÈáèÂåñÊòØÊ®°ÂûãÂéãÁº©ÂíåÂä†ÈÄüÁöÑÂÖ≥ÈîÆÊäÄÊúØ„ÄÇÂêéËÆ≠ÁªÉÈáèÂåñÔºàPTQÔºâ‰Ωú‰∏∫‰∏ÄÁßçÈ´òÊïàÁöÑÊñπÊ≥ïÔºåÂú®ËßÜÈ¢ëÊä†ÂõæÈ¢ÜÂüü‰ªçÂ§Ñ‰∫éÂàùÊ≠•Èò∂ÊÆµÔºåÈù¢‰∏¥‰øùÊåÅÂáÜÁ°ÆÊÄßÂíåÊó∂Èó¥‰∏ÄËá¥ÊÄßÁöÑÈáçÂ§ßÊåëÊàò„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñ‰∏îÈÄöÁî®ÁöÑPTQÊ°ÜÊû∂Ôºå‰∏ìÈó®ÈíàÂØπËßÜÈ¢ëÊä†ÂõæÊ®°ÂûãÔºåÊ†áÂøóÁùÄËØ•È¢ÜÂüüÁöÑÈ¶ñÊ¨°Á≥ªÁªüÊÄßÂ∞ùËØï„ÄÇÊàë‰ª¨ÁöÑË¥°ÁåÆÂåÖÊã¨Ôºö‰∏ÄÁßçÁªìÂêàÂùóÈáçÂª∫‰ºòÂåñÁöÑ‰∏§Èò∂ÊÆµPTQÁ≠ñÁï•„ÄÅÁªüËÆ°È©±Âä®ÁöÑÂÖ®Â±Ä‰ªøÂ∞ÑÊ†°ÂáÜÊñπÊ≥ï‰ª•ÂèäÂÖâÊµÅËæÖÂä©ÁªÑ‰ª∂ÔºåÊòæËëóÊèêÂçá‰∫ÜÊ®°ÂûãÂú®Â§çÊùÇÂú∫ÊôØ‰∏≠Âå∫ÂàÜÁßªÂä®ÂâçÊôØÁöÑËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ËßÜÈ¢ëÊä†ÂõæÊ®°ÂûãÂú®ËµÑÊ∫êÂèóÈôêËÆæÂ§á‰∏äÈÉ®ÁΩ≤Êó∂ÁöÑËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÂíåÂáÜÁ°ÆÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÁöÑÂêéËÆ≠ÁªÉÈáèÂåñÊñπÊ≥ïÂú®‰øùÊåÅÊ®°ÂûãÊÄßËÉΩÊñπÈù¢Â≠òÂú®ÊòæËëó‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÂú®ËßÜÈ¢ëÂ§ÑÁêÜ‰ªªÂä°‰∏≠„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂêéËÆ≠ÁªÉÈáèÂåñÊ°ÜÊû∂ÔºåÈááÁî®‰∏§Èò∂ÊÆµÁ≠ñÁï•ÔºåÈ¶ñÂÖàËøõË°åÂø´ÈÄüÁ®≥ÂÆöÁöÑÂàùÂßãÈáèÂåñÔºåÁÑ∂ÂêéÈÄöËøáÂÖ®Â±ÄÊ†°ÂáÜÈáèÂåñÂèÇÊï∞Êù•ÊúÄÂ∞èÂåñÂáÜÁ°ÆÊÄßÊçüÂ§±„ÄÇËøôÁßçËÆæËÆ°Êó®Âú®ÊúâÊïàÊçïÊçâÂ±ÄÈÉ®‰æùËµñÊÄßÂπ∂ÂáèÂ∞ëÁªüËÆ°Â§±Áúü„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºöÁ¨¨‰∏ÄÈò∂ÊÆµÊòØÂü∫‰∫éÂùóÈáçÂª∫ÁöÑ‰ºòÂåñÔºåÂø´ÈÄüËøõË°åÂàùÂßãÈáèÂåñÔºõÁ¨¨‰∫åÈò∂ÊÆµÊòØÂÖ®Â±Ä‰ªøÂ∞ÑÊ†°ÂáÜÔºàGACÔºâÔºåÁî®‰∫éË∞ÉÊï¥ÈáèÂåñÂèÇÊï∞„ÄÇËøòÂºïÂÖ•‰∫ÜÂÖâÊµÅËæÖÂä©ÁªÑ‰ª∂ÔºàOFAÔºâÔºåÂà©Áî®Êó∂Èó¥ÂíåËØ≠‰πâÂÖàÈ™åÊåáÂØºÈáèÂåñËøáÁ®ã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÁªüËÆ°È©±Âä®ÁöÑÂÖ®Â±Ä‰ªøÂ∞ÑÊ†°ÂáÜÊñπÊ≥ïÔºåËÉΩÂ§üË°•ÂÅøÂõ†ÂøΩÁï•BNÂ±ÇÊïàÂ∫îËÄåÂØºËá¥ÁöÑÁ¥ØÁßØÁªüËÆ°Â§±ÁúüÔºåÊòæËëóÈôç‰ΩéÁé∞ÊúâPTQÊñπÊ≥ïÂú®ËßÜÈ¢ëÊä†Âõæ‰ªªÂä°‰∏≠ÁöÑËØØÂ∑Æ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äÔºåÈááÁî®‰∫ÜÈÄÇÂ∫îÊÄßË∞ÉÊï¥ÁöÑÈáèÂåñÁ≠ñÁï•ÔºåÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°ËÄÉËôë‰∫ÜÊ®°ÂûãÂú®‰∏çÂêåÂú∫ÊôØ‰∏ãÁöÑË°®Áé∞ÔºåÁΩëÁªúÁªìÊûÑ‰∏äÁªìÂêà‰∫ÜÂÖâÊµÅ‰ø°ÊÅØ‰ª•Â¢ûÂº∫Ê®°ÂûãÂØπÂä®ÊÄÅÂâçÊôØÁöÑËØÜÂà´ËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåPTQ4VMÂú®‰∏çÂêå‰ΩçÂÆΩ‰∏ãÁöÑÂáÜÁ°ÆÊÄßË∂ÖËøá‰∫ÜÁé∞ÊúâÁöÑÈáèÂåñÊñπÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÂú®4‰ΩçÈáèÂåñÊó∂ÔºåÂÖ∂ÊÄßËÉΩÊé•ËøëÂÖ®Á≤æÂ∫¶Ê®°ÂûãÔºå‰∏îÂÆûÁé∞‰∫Ü8ÂÄçÁöÑFLOPËäÇÁúÅÔºåÂ±ïÁé∞‰∫ÜÊòæËëóÁöÑÊïàÁéáÊèêÂçá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÁîµÂΩ±Âà∂‰Ωú„ÄÅËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÂú∫ÊôØÔºåËÉΩÂ§üÂú®ËµÑÊ∫êÂèóÈôêÁöÑËÆæÂ§á‰∏äÂÆûÁé∞È´òÊïàÁöÑËßÜÈ¢ëÊä†ÂõæÂ§ÑÁêÜÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™å„ÄÇÊú™Êù•ÔºåËØ•Ê°ÜÊû∂ÂèØËÉΩÊé®Âä®Êõ¥Â§öËÆ°ÁÆóÊú∫ËßÜËßâ‰ªªÂä°ÁöÑÈáèÂåñÁ†îÁ©∂Ôºå‰øÉËøõÊô∫ËÉΩËÆæÂ§áÁöÑÊôÆÂèäÂíåÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Video matting is crucial for applications such as film production and virtual reality, yet deploying its computationally intensive models on resource-constrained devices presents challenges. Quantization is a key technique for model compression and acceleration. As an efficient approach, Post-Training Quantization (PTQ) is still in its nascent stages for video matting, facing significant hurdles in maintaining accuracy and temporal coherence. To address these challenges, this paper proposes a novel and general PTQ framework specifically designed for video matting models, marking, to the best of our knowledge, the first systematic attempt in this domain. Our contributions include: (1) A two-stage PTQ strategy that combines block-reconstruction-based optimization for fast, stable initial quantization and local dependency capture, followed by a global calibration of quantization parameters to minimize accuracy loss. (2) A Statistically-Driven Global Affine Calibration (GAC) method that enables the network to compensate for cumulative statistical distortions arising from factors such as neglected BN layer effects, even reducing the error of existing PTQ methods on video matting tasks up to 20%. (3) An Optical Flow Assistance (OFA) component that leverages temporal and semantic priors from frames to guide the PTQ process, enhancing the model's ability to distinguish moving foregrounds in complex scenes and ultimately achieving near full-precision performance even under ultra-low-bit quantization. Comprehensive quantitative and visual results show that our PTQ4VM achieves the state-of-the-art accuracy performance across different bit-widths compared to the existing quantization methods. We highlight that the 4-bit PTQ4VM even achieves performance close to the full-precision counterpart while enjoying 8x FLOP savings.

