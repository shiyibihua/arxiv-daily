---
layout: default
title: SynDoc: A Hybrid Discriminative-Generative Framework for Enhancing Synthetic Domain-Adaptive Document Key Information Extraction
---

# SynDoc: A Hybrid Discriminative-Generative Framework for Enhancing Synthetic Domain-Adaptive Document Key Information Extraction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23273" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23273v1</a>
  <a href="https://arxiv.org/pdf/2509.23273.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23273v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23273v1', 'SynDoc: A Hybrid Discriminative-Generative Framework for Enhancing Synthetic Domain-Adaptive Document Key Information Extraction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yihao Ding, Soyeon Caren Han, Yanbei Jiang, Yan Li, Zechuan Li, Yifan Peng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

**å¤‡æ³¨**: Work in progress

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SynDocï¼šä¸€ç§æ··åˆåˆ¤åˆ«-ç”Ÿæˆæ¡†æ¶ï¼Œç”¨äºå¢å¼ºåˆæˆé¢†åŸŸè‡ªé€‚åº”æ–‡æ¡£å…³é”®ä¿¡æ¯æå–**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æ¡£ç†è§£` `å…³é”®ä¿¡æ¯æå–` `é¢†åŸŸè‡ªé€‚åº”` `åˆæˆæ•°æ®` `åˆ¤åˆ«æ¨¡å‹` `ç”Ÿæˆæ¨¡å‹` `æŒ‡ä»¤è°ƒä¼˜` `é€’å½’æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é¢†åŸŸç‰¹å®šæ–‡æ¡£ç†è§£ä¸­å­˜åœ¨å¹»è§‰ã€é¢†åŸŸé€‚åº”æ€§å·®å’Œä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ç­‰é—®é¢˜ã€‚
2. SynDocæ¡†æ¶ç»“åˆåˆ¤åˆ«æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹ï¼Œåˆ©ç”¨åˆæˆæ•°æ®å’Œè‡ªé€‚åº”æŒ‡ä»¤è°ƒä¼˜æ¥æå‡é¢†åŸŸçŸ¥è¯†æå–èƒ½åŠ›ã€‚
3. SynDocé€šè¿‡é€’å½’æ¨ç†æœºåˆ¶è¿­ä»£ä¼˜åŒ–æ¨¡å‹è¾“å‡ºï¼Œå®ç°äº†ç¨³å®šå’Œç²¾ç¡®çš„æ–‡æ¡£ç†è§£ï¼Œæå‡äº†å…³é”®ä¿¡æ¯æå–æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é¢†åŸŸç‰¹å®šçš„å¯Œè§†è§‰æ–‡æ¡£ç†è§£ï¼ˆVRDUï¼‰ç”±äºåŒ»å­¦ã€é‡‘èå’Œææ–™ç§‘å­¦ç­‰é¢†åŸŸæ–‡æ¡£çš„å¤æ‚æ€§å’Œæ•æ„Ÿæ€§è€Œé¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚ç°æœ‰çš„å¤§å‹ï¼ˆå¤šæ¨¡æ€ï¼‰è¯­è¨€æ¨¡å‹ï¼ˆLLM/MLLMï¼‰å–å¾—äº†å¯å–œçš„æˆæœï¼Œä½†é¢ä¸´å¹»è§‰ã€é¢†åŸŸé€‚åº”ä¸è¶³ä»¥åŠä¾èµ–å¤§é‡å¾®è°ƒæ•°æ®é›†ç­‰å±€é™æ€§ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶SynDocï¼Œå®ƒç»“åˆäº†åˆ¤åˆ«æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹æ¥åº”å¯¹è¿™äº›æŒ‘æˆ˜ã€‚SynDocé‡‡ç”¨ç¨³å¥çš„åˆæˆæ•°æ®ç”Ÿæˆå·¥ä½œæµç¨‹ï¼Œåˆ©ç”¨ç»“æ„ä¿¡æ¯æå–å’Œé¢†åŸŸç‰¹å®šçš„æŸ¥è¯¢ç”Ÿæˆæ¥äº§ç”Ÿé«˜è´¨é‡çš„æ ‡æ³¨ã€‚é€šè¿‡è‡ªé€‚åº”æŒ‡ä»¤è°ƒä¼˜ï¼ŒSynDocæé«˜äº†åˆ¤åˆ«æ¨¡å‹æå–é¢†åŸŸç‰¹å®šçŸ¥è¯†çš„èƒ½åŠ›ã€‚åŒæ—¶ï¼Œé€’å½’æ¨ç†æœºåˆ¶è¿­ä»£åœ°ç»†åŒ–ä¸¤ä¸ªæ¨¡å‹çš„è¾“å‡ºï¼Œä»¥å®ç°ç¨³å®šå’Œå‡†ç¡®çš„é¢„æµ‹ã€‚è¯¥æ¡†æ¶å±•ç¤ºäº†å¯æ‰©å±•ã€é«˜æ•ˆå’Œç²¾ç¡®çš„æ–‡æ¡£ç†è§£ï¼Œå¹¶å¼¥åˆäº†é¢†åŸŸç‰¹å®šé€‚åº”å’Œé€šç”¨ä¸–ç•ŒçŸ¥è¯†ä¹‹é—´çš„å·®è·ï¼Œä»è€Œå®ç°æ–‡æ¡£å…³é”®ä¿¡æ¯æå–ä»»åŠ¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³é¢†åŸŸç‰¹å®šå¯Œè§†è§‰æ–‡æ¡£ç†è§£ï¼ˆVRDUï¼‰ä¸­ï¼Œç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLM/MLLMï¼‰å­˜åœ¨çš„å¹»è§‰é—®é¢˜ã€é¢†åŸŸé€‚åº”æ€§ä¸è¶³ä»¥åŠå¯¹å¤§é‡å¾®è°ƒæ•°æ®é›†çš„ä¾èµ–é—®é¢˜ã€‚è¿™äº›é—®é¢˜é™åˆ¶äº†LLM/MLLMåœ¨åŒ»å­¦ã€é‡‘èå’Œææ–™ç§‘å­¦ç­‰é¢†åŸŸçš„åº”ç”¨ï¼Œå› ä¸ºè¿™äº›é¢†åŸŸçš„æ–‡æ¡£é€šå¸¸å¤æ‚ä¸”æ•æ„Ÿã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSynDocçš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆåˆ¤åˆ«æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹ï¼Œåˆ©ç”¨åˆæˆæ•°æ®ç”Ÿæˆå’Œè‡ªé€‚åº”æŒ‡ä»¤è°ƒä¼˜æ¥æå‡æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„çŸ¥è¯†æå–èƒ½åŠ›ã€‚é€šè¿‡ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆæ•°æ®ï¼Œå¹¶åˆ©ç”¨è¿™äº›æ•°æ®å¯¹åˆ¤åˆ«æ¨¡å‹è¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å°†é¢†åŸŸçŸ¥è¯†æ³¨å…¥åˆ°æ¨¡å‹ä¸­ã€‚åŒæ—¶ï¼Œé€’å½’æ¨ç†æœºåˆ¶å¯ä»¥è¿­ä»£åœ°ç»†åŒ–æ¨¡å‹è¾“å‡ºï¼Œä»è€Œæé«˜é¢„æµ‹çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSynDocæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) åˆæˆæ•°æ®ç”Ÿæˆæ¨¡å—ï¼Œåˆ©ç”¨ç»“æ„ä¿¡æ¯æå–å’Œé¢†åŸŸç‰¹å®šçš„æŸ¥è¯¢ç”Ÿæˆæ¥äº§ç”Ÿé«˜è´¨é‡çš„æ ‡æ³¨æ•°æ®ï¼›2) è‡ªé€‚åº”æŒ‡ä»¤è°ƒä¼˜æ¨¡å—ï¼Œç”¨äºæå‡åˆ¤åˆ«æ¨¡å‹æå–é¢†åŸŸç‰¹å®šçŸ¥è¯†çš„èƒ½åŠ›ï¼›3) é€’å½’æ¨ç†æ¨¡å—ï¼Œè¿­ä»£åœ°ç»†åŒ–åˆ¤åˆ«æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºï¼Œä»¥å®ç°ç¨³å®šå’Œå‡†ç¡®çš„é¢„æµ‹ã€‚æ•´ä½“æµç¨‹æ˜¯å…ˆç”Ÿæˆåˆæˆæ•°æ®ï¼Œç„¶åä½¿ç”¨è¿™äº›æ•°æ®å¯¹åˆ¤åˆ«æ¨¡å‹è¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜ï¼Œæœ€åé€šè¿‡é€’å½’æ¨ç†æœºåˆ¶ä¼˜åŒ–æ¨¡å‹è¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šSynDocçš„å…³é”®åˆ›æ–°åœ¨äºå…¶æ··åˆåˆ¤åˆ«-ç”Ÿæˆæ¡†æ¶ï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆåœ°ç»“åˆäº†åˆ¤åˆ«æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹çš„ä¼˜åŠ¿ã€‚ä¸ä¼ ç»Ÿçš„ä»…ä¾èµ–åˆ¤åˆ«æ¨¡å‹æˆ–ç”Ÿæˆæ¨¡å‹çš„æ–¹æ³•ç›¸æ¯”ï¼ŒSynDocèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨é¢†åŸŸçŸ¥è¯†ï¼Œå¹¶æé«˜é¢„æµ‹çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒSynDocçš„åˆæˆæ•°æ®ç”Ÿæˆå·¥ä½œæµç¨‹å’Œè‡ªé€‚åº”æŒ‡ä»¤è°ƒä¼˜æ–¹æ³•ä¹Ÿå…·æœ‰åˆ›æ–°æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°è§£å†³é¢†åŸŸé€‚åº”æ€§é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­æåˆ°ä½¿ç”¨ç»“æ„ä¿¡æ¯æå–å’Œé¢†åŸŸç‰¹å®šçš„æŸ¥è¯¢ç”Ÿæˆæ¥äº§ç”Ÿé«˜è´¨é‡çš„æ ‡æ³¨æ•°æ®ï¼Œä½†æ²¡æœ‰è¯¦ç»†è¯´æ˜å…·ä½“çš„ç»“æ„ä¿¡æ¯æå–æ–¹æ³•å’ŒæŸ¥è¯¢ç”Ÿæˆç­–ç•¥ã€‚è‡ªé€‚åº”æŒ‡ä»¤è°ƒä¼˜çš„å…·ä½“å®ç°ç»†èŠ‚ä¹Ÿæœªè¯¦ç»†æè¿°ï¼Œä¾‹å¦‚æŒ‡ä»¤çš„è®¾è®¡ã€æŸå¤±å‡½æ•°çš„é€‰æ‹©ç­‰ã€‚é€’å½’æ¨ç†æœºåˆ¶çš„å…·ä½“å®ç°ç»†èŠ‚ï¼Œä¾‹å¦‚è¿­ä»£æ¬¡æ•°ã€åœæ­¢æ¡ä»¶ç­‰ï¼Œä¹Ÿæœªè¯¦ç»†è¯´æ˜ã€‚è¿™äº›ç»†èŠ‚éœ€è¦åœ¨è®ºæ–‡çš„åç»­ç« èŠ‚æˆ–è¡¥å……ææ–™ä¸­æŸ¥æ‰¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

æ‘˜è¦ä¸­æåˆ°SynDocæ¡†æ¶å±•ç¤ºäº†å¯æ‰©å±•ã€é«˜æ•ˆå’Œç²¾ç¡®çš„æ–‡æ¡£ç†è§£ï¼Œå¹¶å¼¥åˆäº†é¢†åŸŸç‰¹å®šé€‚åº”å’Œé€šç”¨ä¸–ç•ŒçŸ¥è¯†ä¹‹é—´çš„å·®è·ï¼Œä»è€Œå®ç°æ–‡æ¡£å…³é”®ä¿¡æ¯æå–ä»»åŠ¡ã€‚ä½†å…·ä½“çš„å®éªŒç»“æœå’Œæ€§èƒ½æ•°æ®æœªåœ¨æ‘˜è¦ä¸­ç»™å‡ºï¼Œéœ€è¦åœ¨è®ºæ–‡æ­£æ–‡ä¸­æŸ¥æ‰¾å…·ä½“çš„å®éªŒæ•°æ®å’Œå¯¹æ¯”ç»“æœï¼Œæ‰èƒ½æ›´å‡†ç¡®åœ°è¯„ä¼°SynDocçš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SynDocæ¡†æ¶åœ¨åŒ»å­¦ã€é‡‘èã€ææ–™ç§‘å­¦ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºè‡ªåŠ¨åŒ–æ–‡æ¡£å…³é”®ä¿¡æ¯æå–ï¼Œæé«˜å·¥ä½œæ•ˆç‡ï¼Œé™ä½äººå·¥æˆæœ¬ã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»å­¦é¢†åŸŸï¼Œå¯ä»¥ç”¨äºæå–ç—…å†ä¸­çš„å…³é”®ä¿¡æ¯ï¼Œè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œè¯Šæ–­å’Œæ²»ç–—ã€‚åœ¨é‡‘èé¢†åŸŸï¼Œå¯ä»¥ç”¨äºæå–è´¢åŠ¡æŠ¥è¡¨ä¸­çš„å…³é”®ä¿¡æ¯ï¼Œè¾…åŠ©æŠ•èµ„è€…è¿›è¡Œå†³ç­–ã€‚è¯¥ç ”ç©¶çš„æœªæ¥å½±å“åœ¨äºæ¨åŠ¨é¢†åŸŸç‰¹å®šVRDUæŠ€æœ¯çš„å‘å±•ï¼Œä¿ƒè¿›äººå·¥æ™ºèƒ½åœ¨å„ä¸ªè¡Œä¸šçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Domain-specific Visually Rich Document Understanding (VRDU) presents significant challenges due to the complexity and sensitivity of documents in fields such as medicine, finance, and material science. Existing Large (Multimodal) Language Models (LLMs/MLLMs) achieve promising results but face limitations such as hallucinations, inadequate domain adaptation, and reliance on extensive fine-tuning datasets. This paper introduces SynDoc, a novel framework that combines discriminative and generative models to address these challenges. SynDoc employs a robust synthetic data generation workflow, using structural information extraction and domain-specific query generation to produce high-quality annotations. Through adaptive instruction tuning, SynDoc improves the discriminative model's ability to extract domain-specific knowledge. At the same time, a recursive inferencing mechanism iteratively refines the output of both models for stable and accurate predictions. This framework demonstrates scalable, efficient, and precise document understanding and bridges the gap between domain-specific adaptation and general world knowledge for document key information extraction tasks.

