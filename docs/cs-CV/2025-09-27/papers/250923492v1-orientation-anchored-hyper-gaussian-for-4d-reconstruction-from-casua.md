---
layout: default
title: Orientation-anchored Hyper-Gaussian for 4D Reconstruction from Casual Videos
---

# Orientation-anchored Hyper-Gaussian for 4D Reconstruction from Casual Videos

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23492" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23492v1</a>
  <a href="https://arxiv.org/pdf/2509.23492.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23492v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23492v1', 'Orientation-anchored Hyper-Gaussian for 4D Reconstruction from Casual Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junyi Wu, Jiachen Tao, Haoxuan Wang, Gaowen Liu, Ramana Rao Kompella, Yan Yan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

**å¤‡æ³¨**: NeurIPS 2025. Code: \href{https://github.com/adreamwu/OriGS}{OriGS}

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ–¹å‘é”šå®šçš„è¶…é«˜æ–¯æ–¹æ³•OriGSï¼Œç”¨äºä»å•ç›®è§†é¢‘ä¸­è¿›è¡Œé«˜è´¨é‡4Dé‡å»ºã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `4Dé‡å»º` `åŠ¨æ€åœºæ™¯` `é«˜æ–¯æº…å°„` `æ–¹å‘åœº` `è¶…é«˜æ–¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŠ¨æ€åœºæ™¯é‡å»ºæ–¹æ³•ä¾èµ–ä½ç§©å‡è®¾ï¼Œéš¾ä»¥å»ºæ¨¡å¤æ‚ã€å±€éƒ¨çš„å½¢å˜ã€‚
2. OriGSé€šè¿‡å…¨å±€æ–¹å‘åœºæŒ‡å¯¼ï¼Œå°†æ—¶é—´ã€ç©ºé—´ã€å‡ ä½•å’Œæ–¹å‘åµŒå…¥è¶…é«˜æ–¯è¡¨ç¤ºï¼Œå®ç°åŒºåŸŸç‰¹å®šå½¢å˜æ¨æ–­ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒOriGSåœ¨çœŸå®åŠ¨æ€åœºæ™¯ä¸­å®ç°äº†æ¯”ä¸»æµæ–¹æ³•æ›´é«˜çš„é‡å»ºä¿çœŸåº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºæ–¹å‘é”šå®šé«˜æ–¯æº…å°„(OriGS)çš„æ–°æ¡†æ¶ï¼Œç”¨äºä»éšæ„æ‹æ‘„çš„å•ç›®è§†é¢‘ä¸­è¿›è¡Œé«˜è´¨é‡çš„4Dé‡å»ºã€‚è™½ç„¶æœ€è¿‘çš„ç ”ç©¶é€šè¿‡å„ç§è¿åŠ¨é”šç‚¹ï¼ˆå¦‚å›¾èŠ‚ç‚¹æˆ–æ ·æ¡æ§åˆ¶ç‚¹ï¼‰å°†3Dé«˜æ–¯æº…å°„æ‰©å±•åˆ°åŠ¨æ€åœºæ™¯ï¼Œä½†å®ƒä»¬é€šå¸¸ä¾èµ–äºä½ç§©å‡è®¾ï¼Œå¹¶ä¸”åœ¨å»ºæ¨¡éçº¦æŸåŠ¨æ€ä¸­å›ºæœ‰çš„å¤æ‚ã€ç‰¹å®šåŒºåŸŸçš„å½¢å˜æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚OriGSé€šè¿‡å¼•å…¥åŸºäºåœºæ™¯æ–¹å‘çš„è¶…ç»´è¡¨ç¤ºæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æˆ‘ä»¬é¦–å…ˆä¼°è®¡ä¸€ä¸ªå…¨å±€æ–¹å‘åœºï¼Œè¯¥æ–¹å‘åœºåœ¨ç©ºé—´å’Œæ—¶é—´ä¸Šä¼ æ’­ä¸»è¦çš„å‘å‰æ–¹å‘ï¼Œä½œä¸ºåŠ¨æ€å»ºæ¨¡çš„ç¨³å®šç»“æ„æŒ‡å¯¼ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–¹å‘æ„ŸçŸ¥è¶…é«˜æ–¯ï¼Œè¿™æ˜¯ä¸€ç§ç»Ÿä¸€çš„å…¬å¼ï¼Œå°†æ—¶é—´ã€ç©ºé—´ã€å‡ ä½•å’Œæ–¹å‘åµŒå…¥åˆ°ä¸€ä¸ªè¿è´¯çš„æ¦‚ç‡çŠ¶æ€ä¸­ã€‚è¿™ä½¿å¾—èƒ½å¤Ÿé€šè¿‡æœ‰åŸåˆ™çš„æ¡ä»¶åˆ‡ç‰‡æ¥æ¨æ–­ç‰¹å®šåŒºåŸŸçš„å½¢å˜ï¼Œä»è€Œè‡ªé€‚åº”åœ°æ•è·ä¸å…¨å±€è¿åŠ¨æ„å›¾å¯¹é½çš„å„ç§å±€éƒ¨åŠ¨æ€ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®åŠ¨æ€åœºæ™¯ä¸­ï¼ŒOriGSçš„é‡å»ºä¿çœŸåº¦ä¼˜äºä¸»æµæ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºé«˜æ–¯æº…å°„çš„åŠ¨æ€åœºæ™¯é‡å»ºæ–¹æ³•ï¼Œä¾‹å¦‚ä½¿ç”¨å›¾èŠ‚ç‚¹æˆ–æ ·æ¡æ§åˆ¶ç‚¹ä½œä¸ºè¿åŠ¨é”šç‚¹ï¼Œé€šå¸¸ä¾èµ–äºä½ç§©å‡è®¾æ¥ç®€åŒ–åŠ¨æ€å»ºæ¨¡ã€‚ç„¶è€Œï¼ŒçœŸå®ä¸–ç•Œçš„åŠ¨æ€åœºæ™¯å¾€å¾€åŒ…å«å¤æ‚çš„ã€ç‰¹å®šåŒºåŸŸçš„å½¢å˜ï¼Œè¿™äº›å½¢å˜éš¾ä»¥ç”¨ä½ç§©æ¨¡å‹å‡†ç¡®æ•æ‰ï¼Œå¯¼è‡´é‡å»ºè´¨é‡ä¸‹é™ã€‚å› æ­¤ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°å»ºæ¨¡éçº¦æŸåŠ¨æ€åœºæ™¯ä¸­çš„å¤æ‚å±€éƒ¨å½¢å˜æ˜¯æœ¬æ–‡è¦è§£å†³çš„å…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åœºæ™¯çš„æ–¹å‘ä¿¡æ¯ä½œä¸ºåŠ¨æ€å»ºæ¨¡çš„å…ˆéªŒçŸ¥è¯†ï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰å±€éƒ¨å½¢å˜ã€‚å…·ä½“æ¥è¯´ï¼Œè®ºæ–‡é¦–å…ˆä¼°è®¡ä¸€ä¸ªå…¨å±€æ–¹å‘åœºï¼Œè¯¥æ–¹å‘åœºæè¿°äº†åœºæ™¯ä¸­æ¯ä¸ªç‚¹åœ¨æ¯ä¸ªæ—¶åˆ»çš„ä¸»è¦è¿åŠ¨æ–¹å‘ã€‚ç„¶åï¼Œè®ºæ–‡å°†æ—¶é—´ã€ç©ºé—´ã€å‡ ä½•å’Œæ–¹å‘ä¿¡æ¯åµŒå…¥åˆ°ä¸€ä¸ªè¶…é«˜æ–¯è¡¨ç¤ºä¸­ï¼Œå¹¶åˆ©ç”¨æ–¹å‘åœºå¯¹è¶…é«˜æ–¯è¿›è¡Œæ¡ä»¶åˆ‡ç‰‡ï¼Œä»è€Œå®ç°å¯¹ç‰¹å®šåŒºåŸŸå½¢å˜çš„æ¨æ–­ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿè‡ªé€‚åº”åœ°æ•æ‰ä¸å…¨å±€è¿åŠ¨æ„å›¾å¯¹é½çš„å„ç§å±€éƒ¨åŠ¨æ€ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOriGSçš„æ•´ä½“æ¡†æ¶å¯ä»¥åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1) å…¨å±€æ–¹å‘åœºä¼°è®¡ï¼šè¯¥é˜¶æ®µçš„ç›®æ ‡æ˜¯ä¼°è®¡åœºæ™¯ä¸­æ¯ä¸ªç‚¹åœ¨æ¯ä¸ªæ—¶åˆ»çš„ä¸»è¦è¿åŠ¨æ–¹å‘ã€‚è®ºæ–‡ä½¿ç”¨ä¸€ç§åŸºäºå…‰æµçš„æ–¹æ³•æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚2) æ–¹å‘æ„ŸçŸ¥è¶…é«˜æ–¯å»ºæ¨¡ï¼šè¯¥é˜¶æ®µçš„ç›®æ ‡æ˜¯å°†æ—¶é—´ã€ç©ºé—´ã€å‡ ä½•å’Œæ–¹å‘ä¿¡æ¯åµŒå…¥åˆ°ä¸€ä¸ªè¶…é«˜æ–¯è¡¨ç¤ºä¸­ï¼Œå¹¶åˆ©ç”¨æ–¹å‘åœºå¯¹è¶…é«˜æ–¯è¿›è¡Œæ¡ä»¶åˆ‡ç‰‡ï¼Œä»è€Œå®ç°å¯¹ç‰¹å®šåŒºåŸŸå½¢å˜çš„æ¨æ–­ã€‚è®ºæ–‡ä½¿ç”¨ä¸€ç§åŸºäºé«˜æ–¯æ··åˆæ¨¡å‹çš„æ–¹æ³•æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šOriGSçš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†æ–¹å‘æ„ŸçŸ¥è¶…é«˜æ–¯è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºèƒ½å¤Ÿå°†æ—¶é—´ã€ç©ºé—´ã€å‡ ä½•å’Œæ–¹å‘ä¿¡æ¯ç»Ÿä¸€åˆ°ä¸€ä¸ªæ¦‚ç‡æ¡†æ¶ä¸­ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒOriGSä¸éœ€è¦ä¾èµ–ä½ç§©å‡è®¾ï¼Œå› æ­¤èƒ½å¤Ÿæ›´å¥½åœ°å»ºæ¨¡å¤æ‚ã€å±€éƒ¨å½¢å˜ã€‚æ­¤å¤–ï¼ŒOriGSåˆ©ç”¨å…¨å±€æ–¹å‘åœºä½œä¸ºåŠ¨æ€å»ºæ¨¡çš„å…ˆéªŒçŸ¥è¯†ï¼Œä»è€Œæé«˜äº†é‡å»ºçš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…¨å±€æ–¹å‘åœºä¼°è®¡é˜¶æ®µï¼Œè®ºæ–‡ä½¿ç”¨äº†ä¸€ç§é²æ£’çš„å…‰æµç®—æ³•æ¥å¤„ç†é®æŒ¡å’Œå™ªå£°ã€‚åœ¨æ–¹å‘æ„ŸçŸ¥è¶…é«˜æ–¯å»ºæ¨¡é˜¶æ®µï¼Œè®ºæ–‡ä½¿ç”¨äº†ä¸€ç§è‡ªé€‚åº”çš„å¸¦å®½é€‰æ‹©æ–¹æ³•æ¥ç¡®å®šé«˜æ–¯æ··åˆæ¨¡å‹çš„å‚æ•°ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°ï¼Œè¯¥æŸå¤±å‡½æ•°é¼“åŠ±è¶…é«˜æ–¯è¡¨ç¤ºä¸å…¨å±€æ–¹å‘åœºå¯¹é½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒOriGSåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®åŠ¨æ€åœºæ™¯ä¸­å®ç°äº†æ¯”ä¸»æµæ–¹æ³•æ›´é«˜çš„é‡å»ºä¿çœŸåº¦ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸä¸ªåœºæ™¯ä¸­ï¼ŒOriGSçš„PSNRæ¯”ç°æœ‰æ–¹æ³•æé«˜äº†çº¦2dBï¼ŒLPIPSé™ä½äº†çº¦0.05ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒOriGSèƒ½å¤Ÿæœ‰æ•ˆåœ°å»ºæ¨¡å¤æ‚ã€å±€éƒ¨å½¢å˜ï¼Œä»è€Œæé«˜åŠ¨æ€åœºæ™¯é‡å»ºçš„è´¨é‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

OriGSåœ¨åŠ¨æ€åœºæ™¯é‡å»ºé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚å®ƒå¯ä»¥ç”¨äºåˆ›å»ºé«˜è´¨é‡çš„åŠ¨æ€3Dæ¨¡å‹ï¼Œä»è€Œä¸ºç”¨æˆ·æä¾›æ›´åŠ æ²‰æµ¸å¼çš„ä½“éªŒã€‚æ­¤å¤–ï¼ŒOriGSè¿˜å¯ä»¥ç”¨äºåˆ†æå’Œç†è§£åŠ¨æ€åœºæ™¯ï¼Œä¾‹å¦‚è¿åŠ¨æ•æ‰ã€è¡Œä¸ºè¯†åˆ«ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present Orientation-anchored Gaussian Splatting (OriGS), a novel framework for high-quality 4D reconstruction from casually captured monocular videos. While recent advances extend 3D Gaussian Splatting to dynamic scenes via various motion anchors, such as graph nodes or spline control points, they often rely on low-rank assumptions and fall short in modeling complex, region-specific deformations inherent to unconstrained dynamics. OriGS addresses this by introducing a hyperdimensional representation grounded in scene orientation. We first estimate a Global Orientation Field that propagates principal forward directions across space and time, serving as stable structural guidance for dynamic modeling. Built upon this, we propose Orientation-aware Hyper-Gaussian, a unified formulation that embeds time, space, geometry, and orientation into a coherent probabilistic state. This enables inferring region-specific deformation through principled conditioned slicing, adaptively capturing diverse local dynamics in alignment with global motion intent. Experiments demonstrate the superior reconstruction fidelity of OriGS over mainstream methods in challenging real-world dynamic scenes.

