---
layout: default
title: Reinforcement Learning-Based Prompt Template Stealing for Text-to-Image Models
---

# Reinforcement Learning-Based Prompt Template Stealing for Text-to-Image Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00046" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00046v1</a>
  <a href="https://arxiv.org/pdf/2510.00046.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00046v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00046v1', 'Reinforcement Learning-Based Prompt Template Stealing for Text-to-Image Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaotian Zou

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

**å¤‡æ³¨**: 10 pages, 3 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„RLStealeræ¡†æ¶ï¼Œç”¨äºæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ä¸­çš„æç¤ºæ¨¡æ¿çªƒå–ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `æç¤ºå·¥ç¨‹` `æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹` `å®‰å…¨æ¼æ´` `æç¤ºçªƒå–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æç¤ºäº¤æ˜“å¸‚åœºå­˜åœ¨å®‰å…¨é£é™©ï¼Œå³ç²¾å¿ƒè®¾è®¡çš„æç¤ºæ¨¡æ¿å®¹æ˜“è¢«çªƒå–ï¼Œä½†ç¼ºä¹æœ‰æ•ˆçš„é˜²å¾¡æœºåˆ¶ã€‚
2. RLStealerå°†æç¤ºæ¨¡æ¿çªƒå–å»ºæ¨¡ä¸ºåºåˆ—å†³ç­–é—®é¢˜ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ æ¢ç´¢æç¤ºç©ºé—´ï¼Œå¹¶ä½¿ç”¨åŸºäºç›¸ä¼¼æ€§çš„å¥–åŠ±å‡½æ•°å¼•å¯¼å­¦ä¹ ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒRLStealeråœ¨çªƒå–æç¤ºæ¨¡æ¿æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¸”æ”»å‡»æˆæœ¬è¿œä½äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰æ”¹å˜äº†æ–‡æœ¬åˆ°å›¾åƒçš„å·¥ä½œæµç¨‹ï¼Œä½¿è®¾è®¡è€…èƒ½å¤Ÿä»¥å‰æ‰€æœªæœ‰çš„é€Ÿåº¦åˆ›å»ºæ–°çš„è§†è§‰æ¦‚å¿µã€‚è¿™ç§è¿›æ­¥å‚¬ç”Ÿäº†ä¸€ä¸ªè“¬å‹ƒå‘å±•çš„æç¤ºäº¤æ˜“å¸‚åœºï¼Œåœ¨è¿™ä¸ªå¸‚åœºä¸Šï¼Œå¯ä»¥è´­ä¹°å’Œå‡ºå”®èƒ½å¤Ÿè¯±å¯¼å•†æ ‡é£æ ¼çš„ç²¾é€‰æç¤ºã€‚è™½ç„¶æç¤ºäº¤æ˜“åœ¨å•†ä¸šä¸Šå…·æœ‰å¸å¼•åŠ›ï¼Œä½†ä¹Ÿå¼•å…¥äº†ä¸€ä¸ªå¾ˆå¤§ç¨‹åº¦ä¸Šæœªç»æ£€éªŒçš„å®‰å…¨é£é™©ï¼šæç¤ºæœ¬èº«å¯èƒ½ä¼šè¢«ç›—ã€‚æœ¬æ–‡æ­ç¤ºäº†è¿™ç§æ¼æ´ï¼Œå¹¶æå‡ºäº†RLStealerï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„æç¤ºåæ¼”æ¡†æ¶ï¼Œå®ƒä»…ä»ä¸€å°éƒ¨åˆ†ç¤ºä¾‹å›¾åƒä¸­æ¢å¤å…¶æ¨¡æ¿ã€‚RLStealerå°†æ¨¡æ¿çªƒå–è§†ä¸ºä¸€ä¸ªåºåˆ—å†³ç­–é—®é¢˜ï¼Œå¹¶é‡‡ç”¨å¤šä¸ªåŸºäºç›¸ä¼¼æ€§çš„åé¦ˆä¿¡å·ä½œä¸ºå¥–åŠ±å‡½æ•°ï¼Œä»¥æœ‰æ•ˆåœ°æ¢ç´¢æç¤ºç©ºé—´ã€‚åœ¨å…¬å¼€åŸºå‡†ä¸Šçš„å…¨é¢å®éªŒè¡¨æ˜ï¼ŒRLStealerè·å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶å°†æ€»æ”»å‡»æˆæœ¬é™ä½åˆ°ç°æœ‰åŸºçº¿æ‰€éœ€æˆæœ¬çš„13%ä»¥ä¸‹ã€‚æˆ‘ä»¬çš„è¿›ä¸€æ­¥åˆ†æè¯å®ï¼ŒRLStealerå¯ä»¥æœ‰æ•ˆåœ°æ¨å¹¿åˆ°ä¸åŒçš„å›¾åƒé£æ ¼ï¼Œä»è€Œæœ‰æ•ˆåœ°çªƒå–æœªè§è¿‡çš„æç¤ºæ¨¡æ¿ã€‚æˆ‘ä»¬çš„ç ”ç©¶å¼ºè°ƒäº†æç¤ºäº¤æ˜“ä¸­å›ºæœ‰çš„ç´§è¿«å®‰å…¨å¨èƒï¼Œå¹¶ä¸ºåœ¨æ–°å…´çš„MLLMå¸‚åœºä¸­å¼€å‘ä¿æŠ¤æ ‡å‡†å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ä¸­æç¤ºæ¨¡æ¿è¢«çªƒå–çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æŸ¥è¯¢æˆ–è®¡ç®—èµ„æºï¼Œæ•ˆç‡ä½ä¸‹ï¼Œå¹¶ä¸”éš¾ä»¥æ³›åŒ–åˆ°ä¸åŒçš„å›¾åƒé£æ ¼ã€‚å› æ­¤ï¼Œå¦‚ä½•é«˜æ•ˆã€å‡†ç¡®åœ°ä»å°‘é‡ç¤ºä¾‹å›¾åƒä¸­æ¢å¤æç¤ºæ¨¡æ¿æˆä¸ºä¸€ä¸ªé‡è¦çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æç¤ºæ¨¡æ¿çªƒå–é—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªåºåˆ—å†³ç­–è¿‡ç¨‹ï¼Œå¹¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ æ¥å¯»æ‰¾æœ€ä¼˜çš„æç¤ºæ¨¡æ¿ã€‚é€šè¿‡å°†ç”Ÿæˆçš„å›¾åƒä¸ç›®æ ‡å›¾åƒè¿›è¡Œæ¯”è¾ƒï¼Œå¹¶ä½¿ç”¨ç›¸ä¼¼æ€§åº¦é‡ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œå¼•å¯¼æ™ºèƒ½ä½“é€æ­¥ä¼˜åŒ–æç¤ºæ¨¡æ¿ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æ¢ç´¢æç¤ºç©ºé—´ï¼Œå¹¶æ‰¾åˆ°èƒ½å¤Ÿç”Ÿæˆä¸ç›®æ ‡å›¾åƒç›¸ä¼¼å›¾åƒçš„æç¤ºæ¨¡æ¿ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRLStealeræ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) æç¤ºç”Ÿæˆå™¨ï¼šè´Ÿè´£ç”Ÿæˆå€™é€‰çš„æç¤ºæ¨¡æ¿ã€‚2) æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼šæ ¹æ®ç”Ÿæˆçš„æç¤ºæ¨¡æ¿ç”Ÿæˆå›¾åƒã€‚3) å¥–åŠ±å‡½æ•°ï¼šè¯„ä¼°ç”Ÿæˆå›¾åƒä¸ç›®æ ‡å›¾åƒä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œå¹¶ç»™å‡ºå¥–åŠ±ä¿¡å·ã€‚4) å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼šæ ¹æ®å¥–åŠ±ä¿¡å·è°ƒæ•´æç¤ºç”Ÿæˆå™¨çš„ç­–ç•¥ï¼Œä»¥ç”Ÿæˆæ›´å¥½çš„æç¤ºæ¨¡æ¿ã€‚æ•´ä¸ªæµç¨‹æ˜¯ä¸€ä¸ªè¿­ä»£çš„è¿‡ç¨‹ï¼Œæ™ºèƒ½ä½“ä¸æ–­åœ°æ¢ç´¢å’Œå­¦ä¹ ï¼Œæœ€ç»ˆæ‰¾åˆ°èƒ½å¤Ÿç”Ÿæˆä¸ç›®æ ‡å›¾åƒç›¸ä¼¼å›¾åƒçš„æç¤ºæ¨¡æ¿ã€‚

**å…³é”®åˆ›æ–°**ï¼šRLStealerçš„å…³é”®åˆ›æ–°åœ¨äºå°†å¼ºåŒ–å­¦ä¹ å¼•å…¥åˆ°æç¤ºæ¨¡æ¿çªƒå–é—®é¢˜ä¸­ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºä¼˜åŒ–çš„æ–¹æ³•ç›¸æ¯”ï¼Œå¼ºåŒ–å­¦ä¹ èƒ½å¤Ÿæ›´å¥½åœ°æ¢ç´¢æç¤ºç©ºé—´ï¼Œå¹¶æ‰¾åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚æ­¤å¤–ï¼ŒRLStealerè¿˜è®¾è®¡äº†å¤šä¸ªåŸºäºç›¸ä¼¼æ€§çš„å¥–åŠ±å‡½æ•°ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°ç”Ÿæˆå›¾åƒçš„è´¨é‡ï¼Œä»è€Œæé«˜çªƒå–æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šRLStealerä½¿ç”¨äº†Actor-Criticæ¶æ„çš„å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼ŒActorè´Ÿè´£ç”Ÿæˆæç¤ºæ¨¡æ¿ï¼ŒCriticè´Ÿè´£è¯„ä¼°æç¤ºæ¨¡æ¿çš„è´¨é‡ã€‚å¥–åŠ±å‡½æ•°ä½¿ç”¨äº†å¤šç§ç›¸ä¼¼æ€§åº¦é‡ï¼ŒåŒ…æ‹¬åƒç´ çº§åˆ«çš„ç›¸ä¼¼æ€§ã€æ„ŸçŸ¥ç›¸ä¼¼æ€§å’Œè¯­ä¹‰ç›¸ä¼¼æ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ä½¿ç”¨äº†ç»éªŒå›æ”¾å’Œç›®æ ‡ç½‘ç»œç­‰æŠ€æœ¯æ¥æé«˜å¼ºåŒ–å­¦ä¹ çš„ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

RLStealeråœ¨å…¬å¼€åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”å°†æ€»æ”»å‡»æˆæœ¬é™ä½åˆ°ç°æœ‰åŸºçº¿æ–¹æ³•æ‰€éœ€æˆæœ¬çš„13%ä»¥ä¸‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRLStealerèƒ½å¤Ÿæœ‰æ•ˆåœ°æ³›åŒ–åˆ°ä¸åŒçš„å›¾åƒé£æ ¼ï¼Œå¹¶æˆåŠŸçªƒå–æœªè§è¿‡çš„æç¤ºæ¨¡æ¿ï¼ŒéªŒè¯äº†å…¶é«˜æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè¯„ä¼°å’Œæå‡æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„å®‰å…¨æ€§ï¼Œé˜²æ­¢æ¶æ„ç”¨æˆ·çªƒå–å’Œæ»¥ç”¨æç¤ºæ¨¡æ¿ã€‚åŒæ—¶ï¼Œè¯¥ç ”ç©¶ä¹Ÿä¸ºæç¤ºäº¤æ˜“å¸‚åœºçš„å®‰å…¨è§„èŒƒåˆ¶å®šæä¾›äº†å‚è€ƒï¼Œæœ‰åŠ©äºæ„å»ºæ›´å®‰å…¨ã€å¯é çš„å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆç”Ÿæ€ç³»ç»Ÿã€‚æœªæ¥ï¼Œå¯ä»¥è¿›ä¸€æ­¥ç ”ç©¶é˜²å¾¡æç¤ºçªƒå–çš„ç­–ç•¥ï¼Œä¾‹å¦‚æ°´å°æŠ€æœ¯æˆ–æç¤ºåŠ å¯†æŠ€æœ¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) have transformed text-to-image workflows, allowing designers to create novel visual concepts with unprecedented speed. This progress has given rise to a thriving prompt trading market, where curated prompts that induce trademark styles are bought and sold. Although commercially attractive, prompt trading also introduces a largely unexamined security risk: the prompts themselves can be stolen.
>   In this paper, we expose this vulnerability and present RLStealer, a reinforcement learning based prompt inversion framework that recovers its template from only a small set of example images. RLStealer treats template stealing as a sequential decision making problem and employs multiple similarity based feedback signals as reward functions to effectively explore the prompt space. Comprehensive experiments on publicly available benchmarks demonstrate that RLStealer gets state-of-the-art performance while reducing the total attack cost to under 13% of that required by existing baselines. Our further analysis confirms that RLStealer can effectively generalize across different image styles to efficiently steal unseen prompt templates. Our study highlights an urgent security threat inherent in prompt trading and lays the groundwork for developing protective standards in the emerging MLLMs marketplace.

