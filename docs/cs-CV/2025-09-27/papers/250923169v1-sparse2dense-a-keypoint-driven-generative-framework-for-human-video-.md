---
layout: default
title: Sparse2Dense: A Keypoint-driven Generative Framework for Human Video Compression and Vertex Prediction
---

# Sparse2Dense: A Keypoint-driven Generative Framework for Human Video Compression and Vertex Prediction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23169" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23169v1</a>
  <a href="https://arxiv.org/pdf/2509.23169.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23169v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23169v1', 'Sparse2Dense: A Keypoint-driven Generative Framework for Human Video Compression and Vertex Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Bolin Chen, Ru-Ling Liao, Yan Ye, Jie Chen, Shanzhi Yin, Xinrui Ju, Shiqi Wang, Yibo Fan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Sparse2Denseï¼šä¸€ç§å…³é”®ç‚¹é©±åŠ¨çš„ç”Ÿæˆæ¡†æ¶ï¼Œç”¨äºäººä½“è§†é¢‘å‹ç¼©å’Œé¡¶ç‚¹é¢„æµ‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `äººä½“è§†é¢‘å‹ç¼©` `é¡¶ç‚¹é¢„æµ‹` `å…³é”®ç‚¹é©±åŠ¨` `ç”Ÿæˆæ¨¡å‹` `å¤šä»»åŠ¡å­¦ä¹ ` `æ·±åº¦å­¦ä¹ ` `ä½æ¯”ç‰¹ç‡` `å‡ ä½•ä¸€è‡´æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨è¶…ä½æ¯”ç‰¹ç‡ä¸‹åŒæ—¶å®ç°äººä½“è§†é¢‘å‹ç¼©å’Œç²¾ç¡®çš„é¡¶ç‚¹é¢„æµ‹ï¼Œéœ€è¦å…¼é¡¾è¿åŠ¨å»ºæ¨¡ã€å¤–è§‚åˆæˆå’Œå‡ ä½•ä¸€è‡´æ€§ã€‚
2. Sparse2Denseæ¡†æ¶åˆ©ç”¨ç¨€ç–3Då…³é”®ç‚¹ä½œä¸ºä¼ è¾“ç¬¦å·ï¼Œé€šè¿‡å…³é”®ç‚¹é©±åŠ¨çš„ç”Ÿæˆæ¨¡å‹ï¼Œå®ç°è§†é¢‘åˆæˆå’Œé¡¶ç‚¹é¢„æµ‹ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSparse2Denseåœ¨å‹ç¼©æ€§èƒ½ä¸Šä¼˜äºä¼ ç»Ÿç¼–è§£ç å™¨ï¼Œå¹¶èƒ½ä¸ºå‡ ä½•åº”ç”¨æä¾›ç²¾ç¡®çš„é¡¶ç‚¹é¢„æµ‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºSparse2Denseçš„å…³é”®ç‚¹é©±åŠ¨ç”Ÿæˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¸¦å®½å—é™çš„å¤šåª’ä½“åº”ç”¨ä¸­ï¼Œè¶…ä½æ¯”ç‰¹ç‡äººä½“è§†é¢‘å‹ç¼©å’Œç²¾ç¡®é¡¶ç‚¹é¢„æµ‹çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æå…¶ç¨€ç–çš„3Då…³é”®ç‚¹ä½œä¸ºç´§å‡‘çš„ä¼ è¾“ç¬¦å·ï¼Œå®ç°è¶…ä½æ¯”ç‰¹ç‡çš„äººä½“è§†é¢‘å‹ç¼©å’Œç²¾ç¡®çš„äººä½“é¡¶ç‚¹é¢„æµ‹ã€‚æ ¸å¿ƒåˆ›æ–°åœ¨äºåŸºäºå¤šä»»åŠ¡å­¦ä¹ å’Œå…³é”®ç‚¹æ„ŸçŸ¥çš„æ·±åº¦ç”Ÿæˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿé€šè¿‡ç´§å‡‘çš„3Då…³é”®ç‚¹ç¼–ç å¤æ‚çš„äººä½“è¿åŠ¨ï¼Œå¹¶åˆ©ç”¨è¿™äº›ç¨€ç–å…³é”®ç‚¹ä¼°è®¡å¯†é›†è¿åŠ¨ï¼Œä»è€Œåˆæˆå…·æœ‰æ—¶é—´ä¸€è‡´æ€§å’Œé€¼çœŸçº¹ç†çš„è§†é¢‘ã€‚æ­¤å¤–ï¼Œè¿˜é›†æˆäº†ä¸€ä¸ªé¡¶ç‚¹é¢„æµ‹å™¨ï¼Œé€šè¿‡ä¸è§†é¢‘ç”Ÿæˆè”åˆä¼˜åŒ–æ¥å­¦ä¹ äººä½“é¡¶ç‚¹å‡ ä½•ç»“æ„ï¼Œç¡®ä¿è§†è§‰å†…å®¹å’Œå‡ ä½•ç»“æ„ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSparse2Denseåœ¨äººä½“è§†é¢‘å‹ç¼©æ–¹é¢ä¼˜äºä¼ ç»Ÿçš„/ç”Ÿæˆè§†é¢‘ç¼–è§£ç å™¨ï¼ŒåŒæ—¶èƒ½å¤Ÿä¸ºä¸‹æ¸¸å‡ ä½•åº”ç”¨æä¾›ç²¾ç¡®çš„äººä½“é¡¶ç‚¹é¢„æµ‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„äººä½“è§†é¢‘å‹ç¼©æ–¹æ³•åœ¨ä½æ¯”ç‰¹ç‡ä¸‹éš¾ä»¥ä¿æŒè§†é¢‘è´¨é‡å’Œå‡ ä½•ç»“æ„çš„å‡†ç¡®æ€§ã€‚ä¼ ç»Ÿçš„ç¼–è§£ç å™¨æ— æ³•æœ‰æ•ˆåˆ©ç”¨äººä½“è¿åŠ¨çš„å…ˆéªŒçŸ¥è¯†ï¼Œè€ŒåŸºäºç”Ÿæˆæ¨¡å‹çš„æ–¹æ³•é€šå¸¸è®¡ç®—å¤æ‚åº¦é«˜ï¼Œéš¾ä»¥å®ç°å®æ—¶åº”ç”¨ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨æä½çš„æ¯”ç‰¹ç‡ä¸‹å®ç°é«˜è´¨é‡çš„äººä½“è§†é¢‘å‹ç¼©å’Œç²¾ç¡®çš„é¡¶ç‚¹é¢„æµ‹æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSparse2Denseçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨äººä½“éª¨éª¼å…³é”®ç‚¹ä½œä¸ºè§†é¢‘å†…å®¹çš„ç¨€ç–è¡¨ç¤ºï¼Œé€šè¿‡å­¦ä¹ å…³é”®ç‚¹åˆ°å¯†é›†è§†é¢‘å¸§çš„æ˜ å°„å…³ç³»ï¼Œå®ç°è§†é¢‘çš„å‹ç¼©å’Œé‡å»ºã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨äººä½“è¿åŠ¨çš„ç»“æ„åŒ–ä¿¡æ¯ï¼Œé™ä½ä¼ è¾“çš„æ•°æ®é‡ï¼ŒåŒæ—¶ä¿æŒè§†é¢‘çš„è§†è§‰è´¨é‡å’Œå‡ ä½•ä¸€è‡´æ€§ã€‚å…³é”®ç‚¹ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œè¿æ¥äº†è§†é¢‘ç”Ÿæˆå’Œé¡¶ç‚¹é¢„æµ‹ä¸¤ä¸ªä»»åŠ¡ï¼Œå®ç°äº†è”åˆä¼˜åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSparse2Denseæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼šè§†é¢‘ç”Ÿæˆæ¨¡å—å’Œé¡¶ç‚¹é¢„æµ‹æ¨¡å—ã€‚è§†é¢‘ç”Ÿæˆæ¨¡å—ä»¥ç¨€ç–çš„3Då…³é”®ç‚¹ä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡ä¸€ä¸ªå¤šä»»åŠ¡å­¦ä¹ çš„æ·±åº¦ç”Ÿæˆæ¨¡å‹ï¼Œç”Ÿæˆå…·æœ‰æ—¶é—´ä¸€è‡´æ€§å’Œé€¼çœŸçº¹ç†çš„è§†é¢‘å¸§ã€‚é¡¶ç‚¹é¢„æµ‹æ¨¡å—åˆ™åˆ©ç”¨ç›¸åŒçš„å…³é”®ç‚¹ä¿¡æ¯ï¼Œé¢„æµ‹äººä½“ç½‘æ ¼æ¨¡å‹çš„é¡¶ç‚¹åæ ‡ã€‚è¿™ä¸¤ä¸ªæ¨¡å—é€šè¿‡è”åˆä¼˜åŒ–ï¼Œå…±äº«å…³é”®ç‚¹è¡¨ç¤ºï¼Œä»è€Œä¿è¯è§†è§‰å†…å®¹å’Œå‡ ä½•ç»“æ„çš„ä¸€è‡´æ€§ã€‚æ•´ä½“æµç¨‹æ˜¯ä»è¾“å…¥è§†é¢‘ä¸­æå–å…³é”®ç‚¹ï¼Œå°†å…³é”®ç‚¹è¿›è¡Œå‹ç¼©å’Œä¼ è¾“ï¼Œç„¶ååœ¨æ¥æ”¶ç«¯åˆ©ç”¨Sparse2Denseæ¡†æ¶è¿›è¡Œè§†é¢‘é‡å»ºå’Œé¡¶ç‚¹é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šSparse2Denseçš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§å…³é”®ç‚¹é©±åŠ¨çš„ç”Ÿæˆæ¡†æ¶ï¼Œå°†äººä½“è§†é¢‘å‹ç¼©å’Œé¡¶ç‚¹é¢„æµ‹ä¸¤ä¸ªä»»åŠ¡ç»Ÿä¸€åˆ°ä¸€ä¸ªæ¡†æ¶ä¸­ã€‚ä¸ä¼ ç»Ÿçš„è§†é¢‘ç¼–è§£ç å™¨ç›¸æ¯”ï¼ŒSparse2Denseèƒ½å¤Ÿåˆ©ç”¨äººä½“è¿åŠ¨çš„ç»“æ„åŒ–ä¿¡æ¯ï¼Œå®ç°æ›´é«˜æ•ˆçš„å‹ç¼©ã€‚ä¸ç°æœ‰çš„åŸºäºç”Ÿæˆæ¨¡å‹çš„è§†é¢‘å‹ç¼©æ–¹æ³•ç›¸æ¯”ï¼ŒSparse2Denseé€šè¿‡å…³é”®ç‚¹ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œé™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œå¹¶å®ç°äº†è§†é¢‘ç”Ÿæˆå’Œé¡¶ç‚¹é¢„æµ‹çš„è”åˆä¼˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è§†é¢‘ç”Ÿæˆæ¨¡å—ä¸­ï¼Œé‡‡ç”¨äº†å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥ï¼ŒåŒæ—¶é¢„æµ‹è§†é¢‘å¸§å’Œå…‰æµä¿¡æ¯ï¼Œä»¥æé«˜è§†é¢‘çš„æ—¶é—´ä¸€è‡´æ€§ã€‚åœ¨é¡¶ç‚¹é¢„æµ‹æ¨¡å—ä¸­ï¼Œé‡‡ç”¨äº†å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰æ¥å­¦ä¹ äººä½“ç½‘æ ¼æ¨¡å‹çš„ç»“æ„ä¿¡æ¯ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬è§†é¢‘é‡å»ºæŸå¤±ã€å…‰æµæŸå¤±å’Œé¡¶ç‚¹é¢„æµ‹æŸå¤±ï¼Œé€šè¿‡è”åˆä¼˜åŒ–è¿™äº›æŸå¤±å‡½æ•°ï¼Œå®ç°è§†é¢‘ç”Ÿæˆå’Œé¡¶ç‚¹é¢„æµ‹çš„ååŒè®­ç»ƒã€‚å…³é”®ç‚¹çš„æå–ä½¿ç”¨äº†ç°æˆçš„å§¿æ€ä¼°è®¡æ¨¡å‹ï¼Œä¾‹å¦‚OpenPoseã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSparse2Denseåœ¨äººä½“è§†é¢‘å‹ç¼©æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œåœ¨ç›¸åŒæ¯”ç‰¹ç‡ä¸‹ï¼Œè§†é¢‘è´¨é‡ä¼˜äºä¼ ç»Ÿçš„H.264å’ŒH.265ç¼–è§£ç å™¨ï¼Œä»¥åŠåŸºäºç”Ÿæˆæ¨¡å‹çš„è§†é¢‘å‹ç¼©æ–¹æ³•ã€‚åŒæ—¶ï¼ŒSparse2Denseèƒ½å¤Ÿä¸ºä¸‹æ¸¸å‡ ä½•åº”ç”¨æä¾›ç²¾ç¡®çš„äººä½“é¡¶ç‚¹é¢„æµ‹ï¼Œé¡¶ç‚¹é¢„æµ‹çš„å‡†ç¡®ç‡ä¼˜äºç°æœ‰çš„é¡¶ç‚¹é¢„æµ‹æ–¹æ³•ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†çš„å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Sparse2Denseæ¡†æ¶åœ¨å¸¦å®½å—é™çš„äººä½“ä¸­å¿ƒåª’ä½“ä¼ è¾“æ–¹é¢å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚å®æ—¶è¿åŠ¨åˆ†æã€è™šæ‹ŸäººåŠ¨ç”»å’Œæ²‰æµ¸å¼å¨±ä¹ã€‚å®ƒå¯ä»¥ç”¨äºè¿œç¨‹ä¼šè®®ã€åœ¨çº¿æ•™è‚²ã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰åœºæ™¯ï¼Œåœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œéœ€è¦ä¼ è¾“äººä½“è¿åŠ¨ä¿¡æ¯ï¼Œä½†å¸¦å®½èµ„æºæœ‰é™ã€‚é€šè¿‡Sparse2Denseï¼Œå¯ä»¥å®ç°ä½å¸¦å®½ä¸‹çš„é«˜è´¨é‡äººä½“è§†é¢‘ä¼ è¾“å’Œç²¾ç¡®çš„é¡¶ç‚¹é¢„æµ‹ï¼Œä»è€Œæå‡ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> For bandwidth-constrained multimedia applications, simultaneously achieving ultra-low bitrate human video compression and accurate vertex prediction remains a critical challenge, as it demands the harmonization of dynamic motion modeling, detailed appearance synthesis, and geometric consistency. To address this challenge, we propose Sparse2Dense, a keypoint-driven generative framework that leverages extremely sparse 3D keypoints as compact transmitted symbols to enable ultra-low bitrate human video compression and precise human vertex prediction. The key innovation is the multi-task learning-based and keypoint-aware deep generative model, which could encode complex human motion via compact 3D keypoints and leverage these sparse keypoints to estimate dense motion for video synthesis with temporal coherence and realistic textures. Additionally, a vertex predictor is integrated to learn human vertex geometry through joint optimization with video generation, ensuring alignment between visual content and geometric structure. Extensive experiments demonstrate that the proposed Sparse2Dense framework achieves competitive compression performance for human video over traditional/generative video codecs, whilst enabling precise human vertex prediction for downstream geometry applications. As such, Sparse2Dense is expected to facilitate bandwidth-efficient human-centric media transmission, such as real-time motion analysis, virtual human animation, and immersive entertainment.

