---
layout: default
title: Streamline pathology foundation model by cross-magnification distillation
---

# Streamline pathology foundation model by cross-magnification distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23097" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23097v2</a>
  <a href="https://arxiv.org/pdf/2509.23097.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23097v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23097v2', 'Streamline pathology foundation model by cross-magnification distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziyu Su, Abdul Rehman Akbar, Usama Sajjad, Anil V. Parwani, Muhammad Khalid Khan Niazi

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27 (æ›´æ–°: 2025-10-01)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè·¨å€ç‡è’¸é¦çš„è½»é‡çº§ç—…ç†å­¦åŸºç¡€æ¨¡å‹XMAGï¼ŒåŠ é€Ÿä¸´åºŠéƒ¨ç½²ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç—…ç†å­¦` `åŸºç¡€æ¨¡å‹` `çŸ¥è¯†è’¸é¦` `è·¨å€ç‡` `è½»é‡åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç—…ç†å­¦åŸºç¡€æ¨¡å‹å‚æ•°é‡å·¨å¤§ï¼Œä¸”ä¾èµ–é«˜å€ç‡å›¾åƒï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œéš¾ä»¥åœ¨ä¸´åºŠç¯å¢ƒä¸­éƒ¨ç½²ã€‚
2. XMAGé€šè¿‡è·¨å€ç‡è’¸é¦ï¼Œå°†20å€æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†è¿ç§»åˆ°5å€å­¦ç”Ÿæ¨¡å‹ï¼Œæ˜¾è‘—é™ä½è®¡ç®—éœ€æ±‚ã€‚
3. XMAGåœ¨å¤šç§ç™Œç—‡ç±»å‹çš„ç—…ç†å­¦åˆ†æä»»åŠ¡ä¸­ï¼Œå®ç°äº†ä¸å¤§å‹æ¨¡å‹æ¥è¿‘çš„ç²¾åº¦ï¼Œä½†é€Ÿåº¦æå‡30å€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§è½»é‡çº§ç—…ç†å­¦åŸºç¡€æ¨¡å‹XMAGï¼Œé€šè¿‡è·¨å€ç‡è’¸é¦å°†å…ˆè¿›çš„20å€æ”¾å¤§å€ç‡æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†è¿ç§»åˆ°é«˜æ•ˆçš„5å€æ”¾å¤§å€ç‡å­¦ç”Ÿæ¨¡å‹æ¶æ„ã€‚XMAGé‡‡ç”¨ç´§å‡‘çš„éª¨å¹²ç½‘ç»œï¼Œå®Œå…¨åœ¨5å€æ”¾å¤§å€ç‡ä¸‹è¿è¡Œï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ¯ä¸ªå…¨åˆ‡ç‰‡å›¾åƒï¼ˆWSIï¼‰æ‰€éœ€çš„å›¾åƒå—æ•°é‡å‡å°‘äº†11.3å€ã€‚è¯¥æ–‡æå‡ºçš„æ–°å‹è’¸é¦æ¡†æ¶åŒ…å«åŒå±‚çŸ¥è¯†è¿ç§»ï¼Œå¯¹é½å…¨å±€å›¾åƒè¡¨ç¤ºå’Œå±€éƒ¨ç©ºé—´tokenæ˜ å°„ã€‚XMAGåœ¨ä»å…¬å¼€æ•°æ®é›†æ•´ç†çš„349ä¸‡å¼ å›¾åƒä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨æ¶µç›–å¤šç§ç™Œç—‡ç±»å‹çš„å…­é¡¹ä¸´åºŠç›¸å…³ç»„ç»‡ç—…ç†å­¦åˆ†æä»»åŠ¡ä¸­è¯„ä¼°äº†æ€§èƒ½ã€‚XMAGå®ç°äº†ä¸æ›´å¤§çš„åŸºç¡€æ¨¡å‹ç›¸å·®ä¸åˆ°1%çš„è¯Šæ–­å‡†ç¡®ç‡ï¼ŒåŒæ—¶å¤„ç†é€Ÿåº¦æé«˜äº†30å€ï¼Œè¾¾åˆ°æ¯åˆ†é’Ÿå¤„ç†8.8å¼ WSIçš„é€Ÿåº¦ã€‚è·¨æœºæ„éªŒè¯è¯å®äº†å…¶å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ–‡è¿˜å¼€å‘äº†ä¸€ç§ç«¯åˆ°ç«¯è®­ç»ƒç­–ç•¥ï¼Œä»¥è¿›ä¸€æ­¥æé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Œä½¿å…¶æ¥è¿‘æ›´å¤§çš„åŸºç¡€æ¨¡å‹çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè·¨å€ç‡è’¸é¦æ˜¯éƒ¨ç½²èµ„æºå—é™çš„ä¸´åºŠç¯å¢ƒä¸­åŸºç¡€æ¨¡å‹èƒ½åŠ›çš„å¯è¡Œæ–¹æ³•ï¼Œæœ‰å¯èƒ½å®ç°å®æ—¶ç—…ç†å­¦AIé›†æˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ç—…ç†å­¦åŸºç¡€æ¨¡å‹è™½ç„¶åœ¨æ€§èƒ½ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å…¶åºå¤§çš„å‚æ•°é‡å’Œå¯¹é«˜å€ç‡å›¾åƒçš„ä¾èµ–å¯¼è‡´è®¡ç®—æˆæœ¬è¿‡é«˜ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„ä¸´åºŠç¯å¢ƒä¸­éƒ¨ç½²ã€‚è¿™é™åˆ¶äº†å®ƒä»¬åœ¨å®æ—¶ç—…ç†å­¦åˆ†æä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è·¨å€ç‡è’¸é¦ï¼Œå°†é«˜å€ç‡ï¼ˆ20xï¼‰æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†è¿ç§»åˆ°ä½å€ç‡ï¼ˆ5xï¼‰å­¦ç”Ÿæ¨¡å‹ã€‚è¿™æ ·å¯ä»¥åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½è®¡ç®—å¤æ‚åº¦ï¼Œå› ä¸ºä½å€ç‡å›¾åƒåŒ…å«çš„å›¾åƒå—æ•°é‡æ›´å°‘ï¼Œè®¡ç®—é‡æ›´å°ã€‚é€‰æ‹©5xä½œä¸ºç›®æ ‡å€ç‡ï¼Œæ—¨åœ¨åœ¨ä¿¡æ¯é‡å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šXMAGçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) æ•™å¸ˆæ¨¡å‹è®­ç»ƒï¼šä½¿ç”¨ç°æœ‰çš„é«˜æ€§èƒ½åŸºç¡€æ¨¡å‹ï¼ˆåœ¨20xå€ç‡ä¸‹è®­ç»ƒï¼‰ä½œä¸ºæ•™å¸ˆæ¨¡å‹ã€‚2) å­¦ç”Ÿæ¨¡å‹æ„å»ºï¼šæ„å»ºä¸€ä¸ªå‚æ•°é‡æ›´å°çš„å­¦ç”Ÿæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨5xå€ç‡ä¸‹è¿è¡Œã€‚3) è·¨å€ç‡è’¸é¦ï¼šä½¿ç”¨åŒå±‚çŸ¥è¯†è¿ç§»ç­–ç•¥ï¼Œå°†æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†è¿ç§»åˆ°å­¦ç”Ÿæ¨¡å‹ã€‚è¿™åŒ…æ‹¬å…¨å±€å›¾åƒè¡¨ç¤ºçš„å¯¹é½å’Œå±€éƒ¨ç©ºé—´tokenæ˜ å°„çš„å¯¹é½ã€‚4) ç«¯åˆ°ç«¯è®­ç»ƒï¼šé‡‡ç”¨ç«¯åˆ°ç«¯è®­ç»ƒç­–ç•¥è¿›ä¸€æ­¥ä¼˜åŒ–å­¦ç”Ÿæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šXMAGçš„å…³é”®åˆ›æ–°åœ¨äºå…¶è·¨å€ç‡è’¸é¦æ¡†æ¶ï¼Œç‰¹åˆ«æ˜¯åŒå±‚çŸ¥è¯†è¿ç§»ç­–ç•¥ã€‚ä¼ ç»Ÿçš„çŸ¥è¯†è’¸é¦æ–¹æ³•é€šå¸¸åªå…³æ³¨å…¨å±€å›¾åƒè¡¨ç¤ºçš„å¯¹é½ï¼Œè€ŒXMAGåŒæ—¶è€ƒè™‘äº†å…¨å±€å’Œå±€éƒ¨ä¿¡æ¯ï¼Œé€šè¿‡å¯¹é½ç©ºé—´tokenæ˜ å°„ï¼Œä½¿å¾—å­¦ç”Ÿæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„ç©ºé—´ç‰¹å¾è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œé’ˆå¯¹ç—…ç†å›¾åƒçš„ç‰¹ç‚¹ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ï¼Œä»¥æ›´å¥½åœ°è¿›è¡ŒçŸ¥è¯†è¿ç§»ã€‚

**å…³é”®è®¾è®¡**ï¼šXMAGçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç´§å‡‘çš„éª¨å¹²ç½‘ç»œï¼šå­¦ç”Ÿæ¨¡å‹é‡‡ç”¨è½»é‡çº§çš„å·ç§¯ç¥ç»ç½‘ç»œä½œä¸ºéª¨å¹²ç½‘ç»œï¼Œä»¥å‡å°‘å‚æ•°é‡ã€‚2) åŒå±‚çŸ¥è¯†è¿ç§»ï¼šå…¨å±€å›¾åƒè¡¨ç¤ºçš„å¯¹é½ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æŸå¤±å‡½æ•°ï¼Œå±€éƒ¨ç©ºé—´tokenæ˜ å°„çš„å¯¹é½ä½¿ç”¨KLæ•£åº¦æŸå¤±å‡½æ•°ã€‚3) ç«¯åˆ°ç«¯è®­ç»ƒç­–ç•¥ï¼šé‡‡ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°å’ŒçŸ¥è¯†è’¸é¦æŸå¤±å‡½æ•°çš„åŠ æƒå’Œä½œä¸ºæ€»æŸå¤±å‡½æ•°ï¼Œè¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒã€‚å…·ä½“æƒé‡æ¯”ä¾‹æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

XMAGåœ¨å…­é¡¹ä¸´åºŠç›¸å…³çš„ç»„ç»‡ç—…ç†å­¦åˆ†æä»»åŠ¡ä¸­ï¼Œå®ç°äº†ä¸å¤§å‹åŸºç¡€æ¨¡å‹ç›¸å·®ä¸åˆ°1%çš„è¯Šæ–­å‡†ç¡®ç‡ï¼ŒåŒæ—¶å¤„ç†é€Ÿåº¦æé«˜äº†30å€ï¼Œè¾¾åˆ°æ¯åˆ†é’Ÿå¤„ç†8.8å¼ WSIçš„é€Ÿåº¦ã€‚è·¨æœºæ„éªŒè¯ä¹Ÿè¯å®äº†XMAGå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒXMAGåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

XMAGçš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®æ—¶ç—…ç†è¯Šæ–­ã€è¿œç¨‹ç—…ç†ä¼šè¯Šã€ç—…ç†å›¾åƒè¾…åŠ©åˆ†æç­‰ã€‚é€šè¿‡é™ä½è®¡ç®—æˆæœ¬ï¼ŒXMAGä½¿å¾—åœ¨èµ„æºå—é™çš„ä¸´åºŠç¯å¢ƒä¸­éƒ¨ç½²é«˜æ€§èƒ½ç—…ç†å­¦AIæˆä¸ºå¯èƒ½ï¼Œæœ‰åŠ©äºæé«˜è¯Šæ–­æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œæ”¹å–„æ‚£è€…é¢„åã€‚æœªæ¥ï¼ŒXMAGå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–åŒ»å­¦å›¾åƒåˆ†æä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Foundation models (FM) have transformed computational pathology but remain computationally prohibitive for clinical deployment due to their massive parameter counts and high-magnification processing requirements. Here, we introduce XMAG, a lightweight FM developed through corss-magnification distillation that transfers knowledge from state-of-the-art 20x magnification teacher to an efficient 5x magnification student architecture. XMAG employs a compact backbone and operates entirely at 5x, requiring 11.3 times fewer patches per whole slide image (WSI) compared to existing approaches. Our Novel distillation framework incorporates dual-level knowledge transfer, aligning both global image representations and local spatial token mapping. We trained XMAG on 3.49 million images curated from publicly available datasets and evaluated performance across six clinically relevant histopathology analysis tasks spanning multiple cancer types. XMAG achieved diagnostic accuracy within 1% of substantially larger foundation models while delivering 30-fold processing acceleration, reaching 8.8 WSIs per minute processing speed. Our cross-institutional validation confirmed robust generalization. Further, we developed an end-to-end training strategy to further boost our model's performance to approach the larger FMs' performance. These results establish cross-magnification distillation as a viable approach for deploying FM capabilities in resource-constrained clinical environments, potentially enabling real-time pathology AI integration.

