---
layout: default
title: 3DPCNet: Pose Canonicalization for Robust Viewpoint-Invariant 3D Kinematic Analysis from Monocular RGB cameras
---

# 3DPCNet: Pose Canonicalization for Robust Viewpoint-Invariant 3D Kinematic Analysis from Monocular RGB cameras

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23455" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.23455v1</a>
  <a href="https://arxiv.org/pdf/2509.23455.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23455v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23455v1', '3DPCNet: Pose Canonicalization for Robust Viewpoint-Invariant 3D Kinematic Analysis from Monocular RGB cameras')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Tharindu Ekanayake, Constantino √Ålvarez Casado, Miguel Bordallo L√≥pez

**ÂàÜÁ±ª**: cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-27

**Â§áÊ≥®**: 8 pages, 6 figures, 1 table, 21 references, conference, Code available at: https://github.com/tharindu326/3DPCNet

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫3DPCNet‰ª•Ëß£ÂÜ≥ÂçïÁõÆRGBÊëÑÂÉèÂ§¥‰∏ãÁöÑ3DÂßøÊÄÅÊ†áÂáÜÂåñÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `3DÂßøÊÄÅ‰º∞ËÆ°` `ÂçïÁõÆÊëÑÂÉèÂ§¥` `ËøêÂä®ÂàÜÊûê` `Ëá™ÁõëÁù£Â≠¶‰π†` `ÂõæÂç∑ÁßØÁΩëÁªú` `ÂèòÊç¢Âô®` `ËßÜËßíÊ†áÂáÜÂåñ` `ÂÅ•Â∫∑ÁõëÊµã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂçïÁõÆ3DÂßøÊÄÅ‰º∞ËÆ°ÊñπÊ≥ïÁîüÊàêÁöÑÈ™®Êû∂‰æùËµñ‰∫éÊëÑÂÉèÊú∫ËßÜËßíÔºåÂØºËá¥ËøêÂä®‰ø°Âè∑ÁöÑÊØîËæÉÂàÜÊûêÂèòÂæóÂ§çÊùÇ„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫ÁöÑ3DPCNetÊ®°ÂùóËÉΩÂ§üÂ∞ÜËæìÂÖ•ÁöÑ3DÂßøÊÄÅÊ†°Ê≠£‰∏∫‰∏ÄËá¥ÁöÑË∫´‰Ωì‰∏≠ÂøÉÊ†áÂáÜÊ°ÜÊû∂ÔºåÂ¢ûÂº∫‰∫ÜÂßøÊÄÅÁöÑÂèØÊØîÊÄß„ÄÇ
3. Âú®MM-FiÂü∫ÂáÜÊµãËØï‰∏≠Ôºå3DPCNetÊòæËëóÈôç‰Ωé‰∫ÜÂπ≥ÂùáÊóãËΩ¨ËØØÂ∑ÆÂíåÊØè‰∏™ÂÖ≥ËäÇ‰ΩçÁΩÆÁöÑËØØÂ∑ÆÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂçïÁõÆ3DÂßøÊÄÅ‰º∞ËÆ°Âô®ÁîüÊàê‰ª•Áõ∏Êú∫‰∏∫‰∏≠ÂøÉÁöÑÈ™®Êû∂ÔºåÂØºËá¥ËßÜËßí‰æùËµñÁöÑËøêÂä®‰ø°Âè∑ÔºåÁªôÂÅ•Â∫∑ÂíåËøêÂä®ÁßëÂ≠¶Á≠âÂ∫îÁî®ÁöÑÊØîËæÉÂàÜÊûêÂ∏¶Êù•Âõ∞Èöæ„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü3DPCNetÔºåËøôÊòØ‰∏Ä‰∏™Á¥ßÂáëÁöÑ„ÄÅ‰∏é‰º∞ËÆ°Âô®Êó†ÂÖ≥ÁöÑÊ®°ÂùóÔºåÁõ¥Êé•ÂØπ3DÂÖ≥ËäÇÂùêÊ†áËøõË°åÂ§ÑÁêÜÔºåÂ∞Ü‰ªª‰ΩïËæìÂÖ•ÂßøÊÄÅÊ†°Ê≠£‰∏∫‰∏ÄËá¥ÁöÑ„ÄÅ‰ª•Ë∫´‰Ωì‰∏∫‰∏≠ÂøÉÁöÑÊ†áÂáÜÊ°ÜÊû∂„ÄÇËØ•Ê®°ÂûãÈÄöËøáÈó®Êéß‰∫§ÂèâÊ≥®ÊÑèÊú∫Âà∂ËûçÂêà‰∫ÜÂõæÂç∑ÁßØÁΩëÁªúÁöÑÂ±ÄÈÉ®È™®Êû∂ÁâπÂæÅÂíåÂèòÊç¢Âô®ÁöÑÂÖ®Â±Ä‰∏ä‰∏ãÊñá„ÄÇÊ®°ÂûãÈ¢ÑÊµãÁöÑËøûÁª≠6DÊóãËΩ¨Ë¢´Êò†Â∞ÑÂà∞SO(3)Áü©Èòµ‰ª•ÂØπÈΩêÂßøÊÄÅ„ÄÇÂú®MM-FiÊï∞ÊçÆÈõÜ‰∏äËøõË°åËá™ÁõëÁù£ËÆ≠ÁªÉÔºå‰ΩøÁî®ÂêàÊàêÊóãËΩ¨ÂßøÊÄÅÔºåÈÄöËøáÂ§çÂêàÊçüÂ§±Á°Æ‰øùÂáÜÁ°ÆÁöÑÊóãËΩ¨ÂíåÂßøÊÄÅÈáçÂª∫„ÄÇ3DPCNetÂú®MM-FiÂü∫ÂáÜ‰∏äÂ∞ÜÂπ≥ÂùáÊóãËΩ¨ËØØÂ∑Æ‰ªé20¬∞‰ª•‰∏äÈôç‰ΩéÂà∞3.4¬∞ÔºåÊØè‰∏™ÂÖ≥ËäÇ‰ΩçÁΩÆÁöÑÂπ≥ÂùáËØØÂ∑Æ‰ªéÁ∫¶64ÊØ´Á±≥Èôç‰ΩéÂà∞47ÊØ´Á±≥„ÄÇÂØπTotalCaptureÊï∞ÊçÆÈõÜÁöÑÂÆöÊÄßËØÑ‰º∞Ëøõ‰∏ÄÊ≠•ËØÅÊòé‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïËÉΩÂ§ü‰ªéËßÜÈ¢ë‰∏≠ÁîüÊàê‰∏éÁúüÂÆûIMU‰º†ÊÑüÂô®Êï∞ÊçÆÂº∫ËßÜËßâÂØπÂ∫îÁöÑÂä†ÈÄüÂ∫¶‰ø°Âè∑ÔºåÁ°ÆËÆ§Êàë‰ª¨ÁöÑÊ®°ÂùóÊ∂àÈô§‰∫ÜËßÜËßíÂèòÂºÇÊÄßÔºå‰ªéËÄåÂÆûÁé∞Áâ©ÁêÜ‰∏äÂêàÁêÜÁöÑËøêÂä®ÂàÜÊûê„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂçïÁõÆRGBÊëÑÂÉèÂ§¥‰∏ã3DÂßøÊÄÅ‰º∞ËÆ°ÁöÑËßÜËßí‰æùËµñÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÁîüÊàêÁöÑÂßøÊÄÅ‰ø°Âè∑Èöæ‰ª•ËøõË°åÊØîËæÉÂàÜÊûêÔºåÂ∞§ÂÖ∂Âú®ÂÅ•Â∫∑ÂíåËøêÂä®ÁßëÂ≠¶È¢ÜÂüü„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**Ôºö3DPCNetÈÄöËøáÂ∞ÜËæìÂÖ•ÁöÑ3DÂÖ≥ËäÇÂùêÊ†áËΩ¨Êç¢‰∏∫‰∏ÄËá¥ÁöÑË∫´‰Ωì‰∏≠ÂøÉÊ†áÂáÜÊ°ÜÊû∂ÔºåÊ∂àÈô§‰∫ÜËßÜËßíÂèòÂºÇÊÄß„ÄÇËØ•ÊñπÊ≥ïÁªìÂêà‰∫ÜÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄÁâπÂæÅÔºåÁ°Æ‰øù‰∫ÜÂßøÊÄÅÁöÑÂáÜÁ°ÆÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**Ôºö3DPCNetÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏Ä‰∏™Ê∑∑ÂêàÁºñÁ†ÅÂô®ÔºåÂà©Áî®ÂõæÂç∑ÁßØÁΩëÁªúÊèêÂèñÂ±ÄÈÉ®È™®Êû∂ÁâπÂæÅÔºåÂπ∂ÈÄöËøáÂèòÊç¢Âô®Ëé∑ÂèñÂÖ®Â±Ä‰∏ä‰∏ãÊñá„ÄÇÊ®°ÂûãÈÄöËøáÈó®Êéß‰∫§ÂèâÊ≥®ÊÑèÊú∫Âà∂ËûçÂêàËøô‰∫õÁâπÂæÅÔºåÊúÄÁªàÈ¢ÑÊµãÂá∫6DÊóãËΩ¨„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™‰º∞ËÆ°Âô®Êó†ÂÖ≥ÁöÑÊ®°ÂùóÔºåËÉΩÂ§üÁõ¥Êé•Â§ÑÁêÜ3DÂÖ≥ËäÇÂùêÊ†áÔºåÂπ∂ÈÄöËøáËá™ÁõëÁù£Â≠¶‰π†ËøõË°åËÆ≠ÁªÉ„ÄÇËøôÁßçÊñπÊ≥ï‰∏éÁé∞ÊúâÁöÑ‰æùËµñ‰∫éÁâπÂÆö‰º∞ËÆ°Âô®ÁöÑÊäÄÊúØÊúâÊú¨Ë¥®Âå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊ®°Âûã‰ΩøÁî®Â§çÂêàÊçüÂ§±ÂáΩÊï∞ËøõË°åËÆ≠ÁªÉÔºåÁ°Æ‰øù‰∫ÜÊóãËΩ¨ÁöÑÂáÜÁ°ÆÊÄßÂíåÂßøÊÄÅÁöÑÈáçÂª∫„ÄÇÈÄöËøáÂêàÊàêÊóãËΩ¨ÂßøÊÄÅËøõË°åËá™ÁõëÁù£ËÆ≠ÁªÉÔºå‰ºòÂåñ‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®MM-FiÂü∫ÂáÜÊµãËØï‰∏≠Ôºå3DPCNetÂ∞ÜÂπ≥ÂùáÊóãËΩ¨ËØØÂ∑Æ‰ªé20¬∞‰ª•‰∏äÈôç‰ΩéËá≥3.4¬∞ÔºåÊØè‰∏™ÂÖ≥ËäÇ‰ΩçÁΩÆÁöÑÂπ≥ÂùáËØØÂ∑Æ‰ªéÁ∫¶64ÊØ´Á±≥Èôç‰ΩéËá≥47ÊØ´Á±≥ÔºåÊòæÁ§∫Âá∫ÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÊ≠§Â§ñÔºåÂÆöÊÄßËØÑ‰º∞Ë°®ÊòéÂÖ∂ÁîüÊàêÁöÑÂä†ÈÄüÂ∫¶‰ø°Âè∑‰∏éÁúüÂÆûIMU‰º†ÊÑüÂô®Êï∞ÊçÆÂÖ∑ÊúâÂº∫ËßÜËßâÂØπÂ∫îÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÁâπÂà´ÊòØÂú®ÂÅ•Â∫∑ÁõëÊµã„ÄÅËøêÂä®ÂàÜÊûêÂíåËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊ∂àÈô§ËßÜËßí‰æùËµñÊÄßÔºå3DPCNetËÉΩÂ§üÊèê‰æõÊõ¥‰∏ÄËá¥ÂíåÂèØÈù†ÁöÑËøêÂä®ÂàÜÊûêÔºåÂ∏ÆÂä©Á†îÁ©∂‰∫∫ÂëòÂíå‰∏ì‰∏ö‰∫∫Â£´Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåËØÑ‰º∞ËøêÂä®Ë°®Áé∞„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Monocular 3D pose estimators produce camera-centered skeletons, creating view-dependent kinematic signals that complicate comparative analysis in applications such as health and sports science. We present 3DPCNet, a compact, estimator-agnostic module that operates directly on 3D joint coordinates to rectify any input pose into a consistent, body-centered canonical frame. Its hybrid encoder fuses local skeletal features from a graph convolutional network with global context from a transformer via a gated cross-attention mechanism. From this representation, the model predicts a continuous 6D rotation that is mapped to an $SO(3)$ matrix to align the pose. We train the model in a self-supervised manner on the MM-Fi dataset using synthetically rotated poses, guided by a composite loss ensuring both accurate rotation and pose reconstruction. On the MM-Fi benchmark, 3DPCNet reduces the mean rotation error from over 20$^{\circ}$ to 3.4$^{\circ}$ and the Mean Per Joint Position Error from ~64 mm to 47 mm compared to a geometric baseline. Qualitative evaluations on the TotalCapture dataset further demonstrate that our method produces acceleration signals from video that show strong visual correspondence to ground-truth IMU sensor data, confirming that our module removes viewpoint variability to enable physically plausible motion analysis.

