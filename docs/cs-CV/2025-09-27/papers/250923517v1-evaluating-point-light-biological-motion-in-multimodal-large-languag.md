---
layout: default
title: Evaluating point-light biological motion in multimodal large language models
---

# Evaluating point-light biological motion in multimodal large language models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23517" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23517v1</a>
  <a href="https://arxiv.org/pdf/2509.23517.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23517v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23517v1', 'Evaluating point-light biological motion in multimodal large language models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Akila Kadambi, Marco Iacoboni, Lisa Aziz-Zadeh, Srini Narayanan

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ActPLDåŸºå‡†æµ‹è¯•æ­ç¤ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç†è§£ç‚¹å…‰ç”Ÿç‰©è¿åŠ¨æ–¹é¢çš„ä¸è¶³**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `ç‚¹å…‰æ˜¾ç¤º` `åŠ¨ä½œç†è§£` `å…·èº«æ™ºèƒ½` `åŸºå‡†æµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨åŠ¨ä½œç†è§£æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†ä»…ä¾èµ–è¿åŠ¨ä¿¡æ¯çš„ç‚¹å…‰æ˜¾ç¤ºæ—¶ã€‚
2. æå‡ºActPLDåŸºå‡†ï¼Œåˆ©ç”¨ç‚¹å…‰æ˜¾ç¤ºè¯„ä¼°MLLMå¯¹åŠ¨ä½œçš„ç†è§£èƒ½åŠ›ï¼Œèšç„¦äºæ—¶ç©ºä¿¡æ¯å’ŒåŠ¨ä½œè¯­ä¹‰ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰æ¨¡å‹åœ¨ActPLDä¸Šçš„è¡¨ç°æ™®éè¾ƒä½ï¼Œçªæ˜¾äº†æ¨¡å‹åœ¨åŠ¨ä½œå’Œæ—¶ç©ºç†è§£æ–¹é¢çš„å·®è·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»èƒ½å¤Ÿä»æç®€çš„è§†è§‰çº¿ç´¢ä¸­æå–ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ï¼Œç‚¹å…‰æ˜¾ç¤ºï¼ˆPLDï¼‰å°±æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ï¼Œå®ƒç”±ç¨€ç–çš„ç‚¹é›†ç»„æˆï¼Œè¿™äº›ç‚¹å®šä½äºäººä½“å…³é”®å…³èŠ‚ã€‚è¿™ç§èƒ½åŠ›åœ¨æ—©æœŸå‘å±•ä¸­å°±å·²å‡ºç°ï¼Œå¹¶ä¸”å¾ˆå¤§ç¨‹åº¦ä¸Šå½’å› äºäººç±»çš„å…·èº«ç»éªŒã€‚ç”±äºPLDå°†èº«ä½“è¿åŠ¨ä½œä¸ºæ„ä¹‰çš„å”¯ä¸€æ¥æºï¼Œå› æ­¤å®ƒä»¬æ˜¯æµ‹è¯•è¿™äº›ç³»ç»Ÿä¸­åŠ¨ä½œç†è§£çº¦æŸçš„å…³é”®åˆºæ¿€ã€‚æœ¬æ–‡æå‡ºäº†ActPLDï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªè¯„ä¼°MLLMä»äººç±»PLDä¸­è¿›è¡ŒåŠ¨ä½œå¤„ç†çš„åŸºå‡†ã€‚æµ‹è¯•çš„æ¨¡å‹åŒ…æ‹¬æœ€å…ˆè¿›çš„ä¸“æœ‰å’Œå¼€æºç³»ç»Ÿï¼Œæ¶µç›–å•äººåŠ¨ä½œå’Œç¤¾äº¤äº’åŠ¨PLDã€‚ç»“æœè¡¨æ˜ï¼Œè¿™äº›æ¨¡å‹çš„ä¸€è‡´æ€§è¡¨ç°éƒ½å¾ˆä½ï¼Œæ­ç¤ºäº†åœ¨åŠ¨ä½œå’Œæ—¶ç©ºç†è§£æ–¹é¢çš„æ ¹æœ¬å·®è·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ç†è§£äººç±»åŠ¨ä½œçš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»…æä¾›ç‚¹å…‰æ˜¾ç¤ºï¼ˆPLDï¼‰è¿™ç§æç®€è§†è§‰ä¿¡æ¯çš„æƒ…å†µä¸‹ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†PLDæ—¶è¡¨ç°ä¸ä½³ï¼Œæ— æ³•æœ‰æ•ˆæå–åŠ¨ä½œçš„è¯­ä¹‰ä¿¡æ¯ï¼Œè¿™è¡¨æ˜æ¨¡å‹åœ¨æ—¶ç©ºæ¨ç†å’ŒåŠ¨ä½œç†è§£æ–¹é¢å­˜åœ¨æ ¹æœ¬ç¼ºé™·ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨PLDä½œä¸ºä¸€ç§å…³é”®åˆºæ¿€ï¼Œå› ä¸ºå®ƒä»…åŒ…å«èº«ä½“è¿åŠ¨ä¿¡æ¯ï¼Œæ’é™¤äº†å…¶ä»–è§†è§‰å¹²æ‰°ã€‚é€šè¿‡æ„å»ºActPLDåŸºå‡†ï¼Œå¯ä»¥ç³»ç»Ÿåœ°è¯„ä¼°MLLMåœ¨ç†è§£ä¸åŒç±»å‹çš„åŠ¨ä½œï¼ˆåŒ…æ‹¬å•äººåŠ¨ä½œå’Œç¤¾äº¤äº’åŠ¨ï¼‰æ–¹é¢çš„èƒ½åŠ›ï¼Œä»è€Œæ­ç¤ºæ¨¡å‹åœ¨åŠ¨ä½œç†è§£æ–¹é¢çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šActPLDåŸºå‡†åŒ…å«ä¸€ç³»åˆ—äººç±»åŠ¨ä½œçš„PLDè§†é¢‘ï¼Œè¿™äº›è§†é¢‘è¢«è¾“å…¥åˆ°ä¸åŒçš„MLLMä¸­è¿›è¡ŒåŠ¨ä½œè¯†åˆ«æˆ–æè¿°ã€‚æ¨¡å‹çš„è¾“å‡ºä¸é¢„å®šä¹‰çš„æ ‡ç­¾æˆ–æè¿°è¿›è¡Œæ¯”è¾ƒï¼Œä»¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚æµ‹è¯•æµç¨‹åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹æ¨ç†å’Œæ€§èƒ½è¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ActPLDåŸºå‡†ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°MLLMä»PLDä¸­ç†è§£äººç±»åŠ¨ä½œçš„åŸºå‡†ã€‚ä¸ä¼ ç»Ÿçš„åŠ¨ä½œè¯†åˆ«æ•°æ®é›†ä¸åŒï¼ŒActPLDæ›´åŠ å…³æ³¨æ¨¡å‹å¯¹è¿åŠ¨ä¿¡æ¯çš„ç†è§£èƒ½åŠ›ï¼Œè€Œä¸æ˜¯å¯¹å¤–è§‚ä¿¡æ¯çš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šActPLDåŸºå‡†åŒ…å«å•äººåŠ¨ä½œå’Œç¤¾äº¤äº’åŠ¨åŠ¨ä½œï¼Œæ¶µç›–äº†å¤šç§ä¸åŒçš„åŠ¨ä½œç±»å‹ã€‚è®ºæ–‡é€‰æ‹©äº†å¤šä¸ªæœ€å…ˆè¿›çš„ä¸“æœ‰å’Œå¼€æºMLLMè¿›è¡Œæµ‹è¯•ï¼Œå¹¶ä½¿ç”¨äº†æ ‡å‡†çš„è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚å‡†ç¡®ç‡å’ŒF1åˆ†æ•°ï¼‰æ¥è¡¡é‡æ¨¡å‹çš„æ€§èƒ½ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„å–å†³äºæ‰€æµ‹è¯•çš„MLLMã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŒ…æ‹¬GPT-4å’ŒGeminiåœ¨å†…çš„å¤šä¸ªæœ€å…ˆè¿›çš„MLLMåœ¨ActPLDåŸºå‡†ä¸Šçš„è¡¨ç°æ™®éè¾ƒä½ï¼Œè¿™è¡¨æ˜è¿™äº›æ¨¡å‹åœ¨ç†è§£ç‚¹å…‰ç”Ÿç‰©è¿åŠ¨æ–¹é¢å­˜åœ¨æ˜¾è‘—å·®è·ã€‚å³ä½¿æ˜¯ä¸“é—¨é’ˆå¯¹è§†é¢‘ç†è§£è¿›è¡Œè®­ç»ƒçš„æ¨¡å‹ï¼Œå…¶æ€§èƒ½ä¹Ÿè¿œä½äºäººç±»æ°´å¹³ï¼Œçªæ˜¾äº†æ¨¡å‹åœ¨æ—¶ç©ºæ¨ç†å’ŒåŠ¨ä½œè¯­ä¹‰ç†è§£æ–¹é¢çš„ä¸è¶³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè¯„ä¼°å’Œæ”¹è¿›å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨åŠ¨ä½œç†è§£æ–¹é¢çš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æœºå™¨äººã€è™šæ‹Ÿç°å®å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜æ¨¡å‹å¯¹è¿åŠ¨ä¿¡æ¯çš„ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥ä½¿æœºå™¨äººæ›´å¥½åœ°ç†è§£äººç±»çš„æ„å›¾ï¼Œä»è€Œå®ç°æ›´è‡ªç„¶å’Œæœ‰æ•ˆçš„äº¤äº’ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ä¿ƒè¿›å¯¹äººç±»åŠ¨ä½œæ„ŸçŸ¥æœºåˆ¶çš„æ·±å…¥ç†è§£ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Humans can extract rich semantic information from minimal visual cues, as demonstrated by point-light displays (PLDs), which consist of sparse sets of dots localized to key joints of the human body. This ability emerges early in development and is largely attributed to human embodied experience. Since PLDs isolate body motion as the sole source of meaning, they represent key stimuli for testing the constraints of action understanding in these systems. Here we introduce ActPLD, the first benchmark to evaluate action processing in MLLMs from human PLDs. Tested models include state-of-the-art proprietary and open-source systems on single-actor and socially interacting PLDs. Our results reveal consistently low performance across models, introducing fundamental gaps in action and spatiotemporal understanding.

