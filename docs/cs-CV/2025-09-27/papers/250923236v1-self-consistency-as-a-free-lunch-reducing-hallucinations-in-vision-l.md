---
layout: default
title: Self-Consistency as a Free Lunch: Reducing Hallucinations in Vision-Language Models via Self-Reflection
---

# Self-Consistency as a Free Lunch: Reducing Hallucinations in Vision-Language Models via Self-Reflection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23236" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23236v1</a>
  <a href="https://arxiv.org/pdf/2509.23236.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23236v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23236v1', 'Self-Consistency as a Free Lunch: Reducing Hallucinations in Vision-Language Models via Self-Reflection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mingfei Han, Haihong Hao, Jinxing Zhou, Zhihui Li, Yuhui Zheng, Xueqing Deng, Linjie Yang, Xiaojun Chang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè‡ªåæ€çš„è‡ªæ´½æ€§æ–¹æ³•ï¼Œå‡å°‘è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€æ¨¡å‹` `å¹»è§‰å‡å°‘` `è‡ªæ´½æ€§` `è‡ªç›‘ç£å­¦ä¹ ` `è‡ªåæ€` `äº‹å®åŸºç¡€` `æŒ‡ä»¤éµå¾ª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œå½±å“å¯é æ€§ï¼Œä¸”ä¾èµ–å¤§é‡äººå·¥æ ‡æ³¨æˆ–å¤–éƒ¨æ¨¡å‹ç›‘ç£ã€‚
2. è®ºæ–‡æå‡ºåˆ©ç”¨æ¨¡å‹è‡ªèº«åœ¨é•¿å›å¤å’ŒçŸ­ç­”æ¡ˆé—´çš„è‡ªæ´½æ€§ï¼Œè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ï¼Œæ— éœ€é¢å¤–æ ‡æ³¨ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†äº‹å®åŸºç¡€å’Œå¯é æ€§ï¼Œå¹¶ä¿æŒäº†æŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€æ¨¡å‹ç»å¸¸äº§ç”Ÿå¹»è§‰ï¼Œç”Ÿæˆä¸å­˜åœ¨çš„å¯¹è±¡æˆ–ä¸å‡†ç¡®çš„å±æ€§ï¼Œä»è€Œé™ä½è¾“å‡ºçš„å¯é æ€§ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–å¤§é‡äººå·¥æ ‡æ³¨æˆ–æ¥è‡ªæ›´å¼ºå¤§æ¨¡å‹çš„å¤–éƒ¨ç›‘ç£æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œåˆ©ç”¨æ¨¡å‹åœ¨é•¿å›å¤å’ŒçŸ­ç­”æ¡ˆä¹‹é—´çš„è‡ªæ´½æ€§æ¥ç”Ÿæˆè®­ç»ƒæ‰€éœ€çš„åå¥½å¯¹ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œç®€çŸ­çš„äºŒå…ƒé—®é¢˜å¾€å¾€äº§ç”Ÿé«˜åº¦å¯é çš„å›å¤ï¼Œå¯ç”¨äºæŸ¥è¯¢ç›®æ ‡æ¨¡å‹ä»¥è¯„ä¼°å’Œæ’åºå…¶ç”Ÿæˆçš„å›å¤ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªè‡ªåæ€æµç¨‹ï¼Œå°†è¯¦ç»†çš„æ¨¡å‹å›å¤ä¸ç®€æ´çš„äºŒå…ƒç­”æ¡ˆè¿›è¡Œæ¯”è¾ƒï¼Œå¹¶åˆ©ç”¨ä¸ä¸€è‡´ä¿¡å·è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼Œæ— éœ€äººå·¥æ ‡æ³¨æˆ–åŸºäºå¤–éƒ¨æ¨¡å‹çš„ç›‘ç£ã€‚é€šè¿‡ä»…ä¾èµ–è‡ªæ´½æ€§è€Œéå¤–éƒ¨ç›‘ç£ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œå¯æœ‰æ•ˆå‡å°‘ä½¿ç”¨æœªæ ‡è®°æ•°æ®çš„å¹»è§‰ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ï¼ˆå³AMBERã€MultiObject-Hal (ROPE)ã€Object HalBenchå’ŒMMHal-Benchï¼‰ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨äº‹å®åŸºç¡€å’Œå¯é æ€§æ–¹é¢æœ‰æ˜¾è‘—æ”¹è¿›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¿æŒäº†å¼ºå¤§çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼ŒLLaVA-Benchå’ŒMMBenchä¸Šçš„æ€§èƒ½æå‡è¯æ˜äº†è¿™ä¸€ç‚¹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†è§‰-è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæè¿°æ—¶ï¼Œå®¹æ˜“å‡ºç°â€œå¹»è§‰â€ç°è±¡ï¼Œå³ç”Ÿæˆä¸å›¾åƒå†…å®¹ä¸ç¬¦çš„å¯¹è±¡æˆ–å±æ€§ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºäººå·¥æ ‡æ³¨çš„æ•°æ®æˆ–æ›´å¼ºå¤§çš„å¤–éƒ¨æ¨¡å‹è¿›è¡Œç›‘ç£è®­ç»ƒï¼Œæˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥æ‰©å±•ã€‚å› æ­¤ï¼Œå¦‚ä½•åˆ©ç”¨æ— æ ‡æ³¨æ•°æ®ï¼Œæœ‰æ•ˆå‡å°‘è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰é—®é¢˜æ˜¯ä¸€ä¸ªé‡è¦çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ¨¡å‹è‡ªèº«çš„è‡ªæ´½æ€§ä½œä¸ºç›‘ç£ä¿¡å·ã€‚å…·ä½“æ¥è¯´ï¼Œæ¨¡å‹å¯¹äºåŒä¸€ä¸ªå›¾åƒçš„è¯¦ç»†æè¿°ï¼ˆé•¿å›å¤ï¼‰å’Œç®€çŸ­çš„æ˜¯éåˆ¤æ–­ï¼ˆçŸ­ç­”æ¡ˆï¼‰åº”è¯¥ä¿æŒä¸€è‡´ã€‚å¦‚æœæ¨¡å‹ç”Ÿæˆçš„é•¿å›å¤ä¸é€šè¿‡çŸ­ç­”æ¡ˆéªŒè¯çš„ç»“æœä¸ä¸€è‡´ï¼Œåˆ™è®¤ä¸ºè¯¥é•¿å›å¤å­˜åœ¨å¹»è§‰ã€‚é€šè¿‡è¿™ç§è‡ªåæ€æœºåˆ¶ï¼Œå¯ä»¥è‡ªåŠ¨ç”Ÿæˆç”¨äºè®­ç»ƒçš„åå¥½å¯¹ï¼Œå¼•å¯¼æ¨¡å‹å­¦ä¹ æ›´å¯é çš„è¾“å‡ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä¸€ä¸ªè‡ªåæ€æµç¨‹ã€‚é¦–å…ˆï¼Œæ¨¡å‹ç”Ÿæˆå¯¹å›¾åƒçš„è¯¦ç»†æè¿°ï¼ˆé•¿å›å¤ï¼‰ã€‚ç„¶åï¼Œé’ˆå¯¹è¯¥æè¿°ç”Ÿæˆä¸€ç³»åˆ—ç®€çŸ­çš„äºŒå…ƒé—®é¢˜ï¼Œå¹¶è®©æ¨¡å‹å›ç­”è¿™äº›é—®é¢˜ï¼ˆçŸ­ç­”æ¡ˆï¼‰ã€‚æ¥ç€ï¼Œæ¯”è¾ƒé•¿å›å¤å’ŒçŸ­ç­”æ¡ˆä¹‹é—´çš„ä¸€è‡´æ€§ã€‚å¦‚æœå­˜åœ¨ä¸ä¸€è‡´ï¼Œåˆ™å°†è¯¥é•¿å›å¤æ ‡è®°ä¸ºå­˜åœ¨å¹»è§‰ã€‚æœ€åï¼Œåˆ©ç”¨è¿™äº›æ ‡è®°çš„æ•°æ®ç”Ÿæˆåå¥½å¯¹ï¼Œç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œä½¿å…¶æ›´å€¾å‘äºç”Ÿæˆä¸çŸ­ç­”æ¡ˆä¸€è‡´çš„é•¿å›å¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°åœ¨äºåˆ©ç”¨äº†æ¨¡å‹è‡ªèº«çš„è‡ªæ´½æ€§ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œæ— éœ€äººå·¥æ ‡æ³¨æˆ–å¤–éƒ¨æ¨¡å‹ã€‚è¿™ç§è‡ªç›‘ç£çš„æ–¹å¼é™ä½äº†è®­ç»ƒæˆæœ¬ï¼Œæé«˜äº†å¯æ‰©å±•æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡æ¯”è¾ƒé•¿å›å¤å’ŒçŸ­ç­”æ¡ˆçš„ä¸€è‡´æ€§ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ£€æµ‹å’Œçº æ­£æ¨¡å‹ä¸­çš„å¹»è§‰é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¦‚ä½•ç”Ÿæˆæœ‰æ•ˆçš„äºŒå…ƒé—®é¢˜ï¼Œä»¥è¦†ç›–é•¿å›å¤ä¸­çš„å…³é”®ä¿¡æ¯ï¼›2) å¦‚ä½•å®šä¹‰é•¿å›å¤å’ŒçŸ­ç­”æ¡ˆä¹‹é—´çš„ä¸€è‡´æ€§æ ‡å‡†ï¼›3) å¦‚ä½•åˆ©ç”¨ä¸ä¸€è‡´ä¿¡å·ç”Ÿæˆé«˜è´¨é‡çš„åå¥½å¯¹ï¼Œä»¥æŒ‡å¯¼æ¨¡å‹çš„è®­ç»ƒã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªæ˜ç¡®ç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨AMBERã€MultiObject-Hal (ROPE)ã€Object HalBenchå’ŒMMHal-Benchç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†äº‹å®åŸºç¡€å’Œå¯é æ€§ã€‚åŒæ—¶ï¼Œè¯¥æ–¹æ³•åœ¨LLaVA-Benchå’ŒMMBenchä¸Šä¿æŒäº†å¼ºå¤§çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œè¡¨æ˜å…¶åœ¨å‡å°‘å¹»è§‰çš„åŒæ—¶ï¼Œæ²¡æœ‰ç‰ºç‰²æ¨¡å‹çš„é€šç”¨æ€§èƒ½ã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®åœ¨è®ºæ–‡ä¸­ç»™å‡ºï¼Œæ­¤å¤„çœç•¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºéœ€è¦é«˜åº¦å¯é çš„è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—å½±åƒè¯Šæ–­ã€æ™ºèƒ½å®¢æœç­‰ã€‚é€šè¿‡å‡å°‘æ¨¡å‹ä¸­çš„å¹»è§‰ï¼Œå¯ä»¥æé«˜ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯ä¿¡åº¦ï¼Œä»è€Œä¿ƒè¿›è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•æ— éœ€äººå·¥æ ‡æ³¨çš„ç‰¹æ€§ï¼Œä½¿å…¶å…·æœ‰å¾ˆé«˜çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-language models often hallucinate details, generating non-existent objects or inaccurate attributes that compromise output reliability. Existing methods typically address these issues via extensive human annotations or external supervision from more powerful models. In this work, we present a novel framework that leverages the model's self-consistency between long responses and short answers to generate preference pairs for training. We observe that short binary questions tend to yield highly reliable responses, which can be used to query the target model to evaluate and rank its generated responses. Specifically, we design a self-reflection pipeline where detailed model responses are compared against concise binary answers, and inconsistency signals are utilized to automatically curate high-quality training data without human annotations or external model-based supervision. By relying solely on self-consistency rather than external supervision, our method offers a scalable and efficient solution that effectively reduces hallucinations using unlabeled data. Extensive experiments on multiple benchmarks, i.e., AMBER, MultiObject-Hal (ROPE), Object HalBench, and MMHal-Bench, demonstrate significant improvements in factual grounding and reliability. Moreover, our approach maintains robust instruction-following ability, as evidenced by enhanced performance on LLaVA-Bench and MMBench.

