---
layout: default
title: PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting
---

# PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04545" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04545v5</a>
  <a href="https://arxiv.org/pdf/2509.04545.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04545v5" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04545v5', 'PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Linqing Wang, Ximing Xing, Yiji Cheng, Zhiyuan Zhao, Donghao Li, Tiankai Hang, Jiale Tao, Qixun Wang, Ruihuang Li, Comi Chen, Xin Li, Mingrui Wu, Xinchi Deng, Shuyang Gu, Chunyu Wang, Qinglin Lu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-04 (æ›´æ–°: 2025-09-23)

**å¤‡æ³¨**: Technical Report. Project Page: https://hunyuan-promptenhancer.github.io/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPromptEnhancerï¼Œé€šè¿‡æ€ç»´é“¾æç¤ºé‡å†™å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `æç¤ºå·¥ç¨‹` `æ€ç»´é“¾` `å¼ºåŒ–å­¦ä¹ ` `å›¾åƒ-æ–‡æœ¬å¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹åœ¨å¤„ç†å¤æ‚æç¤ºæ—¶ï¼Œéš¾ä»¥å‡†ç¡®å‘ˆç°å±æ€§ç»‘å®šã€å¦å®šå’Œç»„åˆå…³ç³»ç­‰ï¼Œå¯¼è‡´ç”¨æˆ·æ„å›¾ä¸ç”Ÿæˆç»“æœä¸åŒ¹é…ã€‚
2. PromptEnhanceré€šè¿‡è®­ç»ƒä¸€ä¸ªæ€ç»´é“¾ï¼ˆCoTï¼‰é‡å†™å™¨ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ å’Œä¸“é—¨è®¾è®¡çš„å¥–åŠ±æ¨¡å‹AlignEvaluatorï¼Œç”Ÿæˆæ›´ç²¾ç¡®çš„æç¤ºã€‚
3. å®éªŒè¡¨æ˜ï¼ŒPromptEnhanceræ˜¾è‘—æé«˜äº†å›¾åƒ-æ–‡æœ¬å¯¹é½ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªæ–°çš„é«˜è´¨é‡äººç±»åå¥½åŸºå‡†ï¼Œä¿ƒè¿›æœªæ¥ç ”ç©¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºPromptEnhancerï¼Œä¸€ç§æ–°é¢–ä¸”é€šç”¨çš„æç¤ºé‡å†™æ¡†æ¶ï¼Œç”¨äºå¢å¼ºé¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ¨¡å‹ï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹æƒé‡ã€‚ä¸ä¾èµ–äºæ¨¡å‹ç‰¹å®šå¾®è°ƒæˆ–éšå¼å¥–åŠ±ä¿¡å·ï¼ˆå¦‚å›¾åƒå¥–åŠ±åˆ†æ•°ï¼‰çš„ç°æœ‰æ–¹æ³•ä¸åŒï¼Œè¯¥æ¡†æ¶å°†é‡å†™å™¨ä¸ç”Ÿæˆå™¨è§£è€¦ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸€ä¸ªæ€ç»´é“¾ï¼ˆCoTï¼‰é‡å†™å™¨ï¼Œå¹¶ç”±ä¸€ä¸ªåä¸ºAlignEvaluatorçš„ä¸“ç”¨å¥–åŠ±æ¨¡å‹æŒ‡å¯¼ã€‚AlignEvaluatoråŸºäºå¯¹å¸¸è§T2Iå¤±è´¥æ¨¡å¼çš„å…¨é¢åˆ†æï¼Œä»24ä¸ªå…³é”®ç‚¹çš„ç³»ç»Ÿåˆ†ç±»ä¸­æå–ï¼Œæä¾›æ˜¾å¼å’Œç»†ç²’åº¦çš„åé¦ˆã€‚é€šè¿‡ä¼˜åŒ–CoTé‡å†™å™¨ä»¥æœ€å¤§åŒ–æ¥è‡ªAlignEvaluatorçš„å¥–åŠ±ï¼Œè¯¥æ¡†æ¶å­¦ä¹ ç”Ÿæˆèƒ½å¤Ÿè¢«T2Iæ¨¡å‹æ›´ç²¾ç¡®åœ°è§£é‡Šçš„æç¤ºã€‚åœ¨HunyuanImage 2.1æ¨¡å‹ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒPromptEnhanceræ˜¾è‘—æé«˜äº†å„ç§è¯­ä¹‰å’Œç»„åˆæŒ‘æˆ˜ä¸­çš„å›¾åƒ-æ–‡æœ¬å¯¹é½ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°çš„é«˜è´¨é‡äººç±»åå¥½åŸºå‡†ï¼Œä»¥ä¿ƒè¿›æœªæ¥åœ¨è¯¥æ–¹å‘çš„ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨å¤„ç†å¤æ‚çš„ç”¨æˆ·æç¤ºæ—¶ï¼Œç»å¸¸å‡ºç°å›¾åƒä¸æ–‡æœ¬æè¿°ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å±æ€§ç»‘å®šã€å¦å®šå’Œç»„åˆå…³ç³»ç­‰æ–¹é¢ã€‚ç°æœ‰çš„æ–¹æ³•é€šå¸¸éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒæˆ–è€…ä¾èµ–éšå¼çš„å¥–åŠ±ä¿¡å·ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ä¸”ç¼ºä¹æ˜ç¡®çš„æŒ‡å¯¼ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPromptEnhancerçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æç¤ºé‡å†™å™¨ä¸å›¾åƒç”Ÿæˆå™¨è§£è€¦ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸€ä¸ªæ€ç»´é“¾ï¼ˆCoTï¼‰é‡å†™å™¨ï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆæ›´ç¬¦åˆå›¾åƒç”Ÿæˆå™¨ç†è§£çš„æç¤ºã€‚é€šè¿‡æ˜¾å¼çš„å¥–åŠ±æ¨¡å‹AlignEvaluatorï¼Œä¸ºé‡å†™å™¨æä¾›ç»†ç²’åº¦çš„åé¦ˆï¼Œä»è€Œä¼˜åŒ–é‡å†™è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPromptEnhanceræ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ï¼ˆT2I Modelï¼‰ã€æ€ç»´é“¾æç¤ºé‡å†™å™¨ï¼ˆCoT Rewriterï¼‰å’Œå¯¹é½è¯„ä¼°å™¨ï¼ˆAlignEvaluatorï¼‰ã€‚é¦–å…ˆï¼Œç”¨æˆ·è¾“å…¥åŸå§‹æç¤ºï¼ŒCoT Rewriteræ ¹æ®åŸå§‹æç¤ºç”Ÿæˆæ–°çš„æç¤ºã€‚ç„¶åï¼ŒT2I Modelæ ¹æ®æ–°çš„æç¤ºç”Ÿæˆå›¾åƒã€‚æœ€åï¼ŒAlignEvaluatorè¯„ä¼°ç”Ÿæˆå›¾åƒä¸åŸå§‹æç¤ºçš„å¯¹é½ç¨‹åº¦ï¼Œå¹¶å°†è¯„ä¼°ç»“æœä½œä¸ºå¥–åŠ±ä¿¡å·åé¦ˆç»™CoT Rewriterï¼Œç”¨äºä¼˜åŒ–é‡å†™ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šPromptEnhancerçš„å…³é”®åˆ›æ–°åœ¨äºå°†æç¤ºé‡å†™è¿‡ç¨‹ä¸å›¾åƒç”Ÿæˆè¿‡ç¨‹è§£è€¦ï¼Œå¹¶å¼•å…¥äº†æ˜¾å¼çš„å¯¹é½è¯„ä¼°å™¨AlignEvaluatorã€‚AlignEvaluatoråŸºäºå¯¹T2Iæ¨¡å‹å¸¸è§å¤±è´¥æ¨¡å¼çš„åˆ†æï¼Œæä¾›ç»†ç²’åº¦çš„åé¦ˆï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°æŒ‡å¯¼æç¤ºé‡å†™å™¨çš„è®­ç»ƒã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒPromptEnhanceræ— éœ€ä¿®æ”¹å›¾åƒç”Ÿæˆæ¨¡å‹çš„æƒé‡ï¼Œå…·æœ‰æ›´å¥½çš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šAlignEvaluatorçš„è®¾è®¡æ˜¯å…³é”®ã€‚å®ƒåŸºäºå¯¹T2Iæ¨¡å‹å¸¸è§å¤±è´¥æ¨¡å¼çš„ç³»ç»Ÿåˆ†ç±»ï¼Œå®šä¹‰äº†24ä¸ªå…³é”®ç‚¹ï¼Œç”¨äºè¯„ä¼°ç”Ÿæˆå›¾åƒä¸åŸå§‹æç¤ºçš„å¯¹é½ç¨‹åº¦ã€‚CoT Rewriterä½¿ç”¨å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ–æ¥è‡ªAlignEvaluatorçš„å¥–åŠ±ã€‚å…·ä½“çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•å’Œå¥–åŠ±å‡½æ•°çš„è®¾è®¡å¯¹æœ€ç»ˆæ•ˆæœæœ‰é‡è¦å½±å“ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†HunyuanImage 2.1æ¨¡å‹è¿›è¡Œå®éªŒï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªæ–°çš„é«˜è´¨é‡äººç±»åå¥½åŸºå‡†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨HunyuanImage 2.1æ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPromptEnhanceræ˜¾è‘—æé«˜äº†å›¾åƒ-æ–‡æœ¬å¯¹é½ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚æç¤ºæ—¶ã€‚æ­¤å¤–ï¼Œè¯¥è®ºæ–‡è¿˜æ„å»ºäº†ä¸€ä¸ªæ–°çš„é«˜è´¨é‡äººç±»åå¥½åŸºå‡†ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æœ‰ä»·å€¼çš„èµ„æºã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PromptEnhancerå¯åº”ç”¨äºå„ç§æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆåœºæ™¯ï¼Œä¾‹å¦‚è‰ºæœ¯åˆ›ä½œã€äº§å“è®¾è®¡ã€è™šæ‹Ÿç°å®ç­‰ã€‚é€šè¿‡æé«˜ç”Ÿæˆå›¾åƒä¸ç”¨æˆ·æ„å›¾çš„å¯¹é½ç¨‹åº¦ï¼Œå¯ä»¥æå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶ä¿ƒè¿›æ–‡æœ¬åˆ°å›¾åƒç”ŸæˆæŠ€æœ¯åœ¨æ›´å¹¿æ³›é¢†åŸŸçš„åº”ç”¨ã€‚è¯¥ç ”ç©¶ä¹Ÿæœ‰åŠ©äºæå‡AIæ¨¡å‹çš„å¯æ§æ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in text-to-image (T2I) diffusion models have demonstrated remarkable capabilities in generating high-fidelity images. However, these models often struggle to faithfully render complex user prompts, particularly in aspects like attribute binding, negation, and compositional relationships. This leads to a significant mismatch between user intent and the generated output. To address this challenge, we introduce PromptEnhancer, a novel and universal prompt rewriting framework that enhances any pretrained T2I model without requiring modifications to its weights. Unlike prior methods that rely on model-specific fine-tuning or implicit reward signals like image-reward scores, our framework decouples the rewriter from the generator. We achieve this by training a Chain-of-Thought (CoT) rewriter through reinforcement learning, guided by a dedicated reward model we term the AlignEvaluator. The AlignEvaluator is trained to provide explicit and fine-grained feedback based on a systematic taxonomy of 24 key points, which are derived from a comprehensive analysis of common T2I failure modes. By optimizing the CoT rewriter to maximize the reward from our AlignEvaluator, our framework learns to generate prompts that are more precisely interpreted by T2I models. Extensive experiments on the HunyuanImage 2.1 model demonstrate that PromptEnhancer significantly improves image-text alignment across a wide range of semantic and compositional challenges. Furthermore, we introduce a new, high-quality human preference benchmark to facilitate future research in this direction.

