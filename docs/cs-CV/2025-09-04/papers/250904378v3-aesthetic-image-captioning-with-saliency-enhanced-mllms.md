---
layout: default
title: Aesthetic Image Captioning with Saliency Enhanced MLLMs
---

# Aesthetic Image Captioning with Saliency Enhanced MLLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04378" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04378v3</a>
  <a href="https://arxiv.org/pdf/2509.04378.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04378v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04378v3', 'Aesthetic Image Captioning with Saliency Enhanced MLLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yilin Tao, Jiashui Huang, Huaze Xu, Ling Shao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-04 (æ›´æ–°: 2025-09-09)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºASE-MLLMï¼Œé€šè¿‡æ˜¾è‘—æ€§å¢å¼ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æå‡å›¾åƒç¾å­¦æè¿°ç”Ÿæˆæ•ˆæœ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾åƒç¾å­¦æè¿°ç”Ÿæˆ` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `ç¾å­¦æ˜¾è‘—æ€§` `äº¤å‰æ³¨æ„åŠ›æœºåˆ¶` `å›¾åƒç¼–ç å™¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰AICæ–¹æ³•ä¾èµ–å¾®è°ƒMLLMï¼Œç¼ºä¹å¯¹ç¾å­¦å†…å®¹çš„é’ˆå¯¹æ€§å…³æ³¨ï¼Œå¯¼è‡´ç”Ÿæˆæè¿°ä¸å¤Ÿå‡†ç¡®ã€‚
2. ASE-MLLMé€šè¿‡å¼•å…¥å›¾åƒç¾å­¦æ˜¾è‘—æ€§æ¨¡å—ï¼ˆIASMï¼‰å’ŒIAS-ViTç¼–ç å™¨ï¼Œæ˜¾å¼åœ°å°†ç¾å­¦æ˜¾è‘—æ€§èå…¥MLLMã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒASE-MLLMåœ¨ä¸»æµAICåŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•å’Œé€šç”¨MLLMï¼Œè¾¾åˆ°SOTAæ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å›¾åƒç¾å­¦æè¿°ç”Ÿæˆï¼ˆAICï¼‰æ—¨åœ¨ç”Ÿæˆå›¾åƒç¾å­¦çš„æ–‡æœ¬æè¿°ï¼Œæ˜¯è®¡ç®—ç¾å­¦é¢†åŸŸçš„ä¸€ä¸ªå…³é”®ç ”ç©¶æ–¹å‘ã€‚è¿‘å¹´æ¥ï¼Œé¢„è®­ç»ƒçš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰å‘å±•è¿…é€Ÿï¼Œæ˜¾è‘—æ¨åŠ¨äº†æ•´åˆè§†è§‰å’Œæ–‡æœ¬æ¨¡æ€çš„å›¾åƒç¾å­¦ç ”ç©¶ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤§å¤šæ•°å›¾åƒç¾å­¦ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨é¢„æµ‹ç¾å­¦è¯„åˆ†ï¼Œåœ¨AICä¸­çš„åº”ç”¨æœ‰é™ã€‚ç°æœ‰çš„åˆ©ç”¨MLLMçš„AICå·¥ä½œä¸»è¦ä¾èµ–äºå¾®è°ƒæ–¹æ³•ï¼Œè€Œæ²¡æœ‰ä¸“é—¨è°ƒæ•´MLLMä»¥å…³æ³¨ç›®æ ‡ç¾å­¦å†…å®¹ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ç¾å­¦æ˜¾è‘—æ€§å¢å¼ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆASE-MLLMï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯æ¡†æ¶ï¼Œå®ƒæ˜¾å¼åœ°å°†ç¾å­¦æ˜¾è‘—æ€§èå…¥åˆ°MLLMä¸­ã€‚åœ¨è¿™ä¸ªæ¡†æ¶ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†å›¾åƒç¾å­¦æ˜¾è‘—æ€§æ¨¡å—ï¼ˆIASMï¼‰ï¼Œå®ƒèƒ½å¤Ÿé«˜æ•ˆä¸”æœ‰æ•ˆåœ°ä»å›¾åƒä¸­æå–ç¾å­¦æ˜¾è‘—æ€§ç‰¹å¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†IAS-ViTä½œä¸ºMLLMçš„å›¾åƒç¼–ç å™¨ï¼Œè¯¥æ¨¡å—é€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å°†ç¾å­¦æ˜¾è‘—æ€§ç‰¹å¾ä¸åŸå§‹å›¾åƒç‰¹å¾èåˆã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒASE-MLLMæ˜¯ç¬¬ä¸€ä¸ªå°†å›¾åƒç¾å­¦æ˜¾è‘—æ€§é›†æˆåˆ°MLLMä¸­ï¼Œä¸“é—¨ç”¨äºAICä»»åŠ¡çš„æ¡†æ¶ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å½“å‰ä¸»æµçš„AICåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•å’Œé€šç”¨MLLMï¼Œå®ç°äº†æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å›¾åƒç¾å­¦æè¿°ç”Ÿæˆï¼ˆAICï¼‰ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„æ½œåŠ›ï¼Œç”Ÿæˆå‡†ç¡®ä¸”å…·æœ‰ç¾å­¦é’ˆå¯¹æ€§çš„å›¾åƒæè¿°çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºå¯¹é€šç”¨MLLMè¿›è¡Œå¾®è°ƒï¼Œç¼ºä¹å¯¹å›¾åƒç¾å­¦æ˜¾è‘—æ€§ç‰¹å¾çš„å…³æ³¨ï¼Œå¯¼è‡´ç”Ÿæˆçš„æè¿°ä¸å¤Ÿç²¾ç»†å’Œå‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ˜¾å¼åœ°å°†å›¾åƒçš„ç¾å­¦æ˜¾è‘—æ€§ä¿¡æ¯èå…¥åˆ°MLLMä¸­ï¼Œå¼•å¯¼æ¨¡å‹å…³æ³¨å›¾åƒä¸­ä¸ç¾å­¦ç›¸å…³çš„å…³é”®åŒºåŸŸï¼Œä»è€Œç”Ÿæˆæ›´å‡†ç¡®ã€æ›´å…·ç¾å­¦ä»·å€¼çš„æè¿°ã€‚é€šè¿‡å¼•å…¥å›¾åƒç¾å­¦æ˜¾è‘—æ€§æ¨¡å—ï¼ˆIASMï¼‰æå–æ˜¾è‘—æ€§ç‰¹å¾ï¼Œå¹¶è®¾è®¡IAS-ViTç¼–ç å™¨å°†è¿™äº›ç‰¹å¾ä¸åŸå§‹å›¾åƒç‰¹å¾èåˆï¼Œä½¿å¾—MLLMèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å›¾åƒçš„ç¾å­¦å†…æ¶µã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šASE-MLLMæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) å›¾åƒç¾å­¦æ˜¾è‘—æ€§æ¨¡å—ï¼ˆIASMï¼‰ï¼šç”¨äºæå–å›¾åƒçš„ç¾å­¦æ˜¾è‘—æ€§ç‰¹å¾ã€‚2) IAS-ViTç¼–ç å™¨ï¼šå°†IASMæå–çš„æ˜¾è‘—æ€§ç‰¹å¾ä¸åŸå§‹å›¾åƒç‰¹å¾èåˆï¼Œä½œä¸ºMLLMçš„å›¾åƒç¼–ç å™¨ã€‚3) MLLMï¼šåˆ©ç”¨èåˆåçš„å›¾åƒç‰¹å¾ç”Ÿæˆå›¾åƒçš„ç¾å­¦æè¿°ã€‚æ•´ä¸ªæ¡†æ¶é‡‡ç”¨ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºé¦–æ¬¡å°†å›¾åƒç¾å­¦æ˜¾è‘—æ€§æ˜¾å¼åœ°èå…¥åˆ°MLLMä¸­ï¼Œç”¨äºAICä»»åŠ¡ã€‚é€šè¿‡IASMå’ŒIAS-ViTçš„è®¾è®¡ï¼Œä½¿å¾—MLLMèƒ½å¤Ÿæ›´å¥½åœ°å…³æ³¨å›¾åƒä¸­çš„ç¾å­¦ç›¸å…³åŒºåŸŸï¼Œä»è€Œç”Ÿæˆæ›´å‡†ç¡®ã€æ›´å…·ç¾å­¦ä»·å€¼çš„æè¿°ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒASE-MLLMä¸å†ä»…ä»…ä¾èµ–äºå¯¹é€šç”¨MLLMçš„å¾®è°ƒï¼Œè€Œæ˜¯é€šè¿‡å¼•å…¥ä¸“é—¨çš„ç¾å­¦æ˜¾è‘—æ€§æ¨¡å—æ¥æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šIASMçš„å…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ï¼Œä½†å…¶ç›®æ ‡æ˜¯æå–å›¾åƒçš„ç¾å­¦æ˜¾è‘—æ€§ç‰¹å¾ã€‚IAS-ViTç¼–ç å™¨é€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å°†IASMæå–çš„æ˜¾è‘—æ€§ç‰¹å¾ä¸åŸå§‹å›¾åƒç‰¹å¾èåˆã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ç»†èŠ‚æœªçŸ¥ï¼Œä½†åº”è¯¥åŒ…å«å¯¹ç”Ÿæˆæè¿°çš„å‡†ç¡®æ€§å’Œç¾å­¦ä»·å€¼çš„çº¦æŸã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­å¯èƒ½æœ‰æ‰€æè¿°ï¼Œä½†æ­¤å¤„æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒASE-MLLMåœ¨ä¸»æµAICåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•å’Œé€šç”¨MLLMï¼Œå®ç°äº†æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„æ€§èƒ½ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­åº”è¯¥æœ‰è¯¦ç»†çš„æè¿°ï¼Œä½†æ­¤å¤„æœªçŸ¥ã€‚è¯¥ç»“æœéªŒè¯äº†å°†å›¾åƒç¾å­¦æ˜¾è‘—æ€§èå…¥MLLMçš„æœ‰æ•ˆæ€§ï¼Œä¸ºAICé¢†åŸŸçš„ç ”ç©¶æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½ç›¸å†Œç®¡ç†ã€å›¾åƒæœç´¢å¼•æ“ã€ç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·ä¸Šä¼ çš„ç…§ç‰‡è‡ªåŠ¨ç”Ÿæˆå…·æœ‰ç¾å­¦ä»·å€¼çš„æè¿°ï¼Œæ–¹ä¾¿ç”¨æˆ·åˆ†äº«å’Œäº¤æµã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºè‰ºæœ¯åˆ›ä½œã€è®¾è®¡è¾…åŠ©ç­‰é¢†åŸŸï¼Œä¸ºäººç±»æä¾›æ›´æ™ºèƒ½ã€æ›´ä¾¿æ·çš„ç¾å­¦ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Aesthetic Image Captioning (AIC) aims to generate textual descriptions of image aesthetics, becoming a key research direction in the field of computational aesthetics. In recent years, pretrained Multimodal Large Language Models (MLLMs) have advanced rapidly, leading to a significant increase in image aesthetics research that integrates both visual and textual modalities. However, most existing studies on image aesthetics primarily focus on predicting aesthetic ratings and have shown limited application in AIC. Existing AIC works leveraging MLLMs predominantly rely on fine-tuning methods without specifically adapting MLLMs to focus on target aesthetic content. To address this limitation, we propose the Aesthetic Saliency Enhanced Multimodal Large Language Model (ASE-MLLM), an end-to-end framework that explicitly incorporates aesthetic saliency into MLLMs. Within this framework, we introduce the Image Aesthetic Saliency Module (IASM), which efficiently and effectively extracts aesthetic saliency features from images. Additionally, we design IAS-ViT as the image encoder for MLLMs, this module fuses aesthetic saliency features with original image features via a cross-attention mechanism. To the best of our knowledge, ASE-MLLM is the first framework to integrate image aesthetic saliency into MLLMs specifically for AIC tasks. Extensive experiments demonstrated that our approach significantly outperformed traditional methods and generic MLLMs on current mainstream AIC benchmarks, achieving state-of-the-art (SOTA) performance.

