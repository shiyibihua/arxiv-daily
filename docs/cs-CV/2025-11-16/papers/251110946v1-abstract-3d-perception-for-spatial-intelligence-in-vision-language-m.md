---
layout: default
title: Abstract 3D Perception for Spatial Intelligence in Vision-Language Models
---

# Abstract 3D Perception for Spatial Intelligence in Vision-Language Models

**arXiv**: [2511.10946v1](https://arxiv.org/abs/2511.10946) | [PDF](https://arxiv.org/pdf/2511.10946.pdf)

**ä½œè€…**: Yifan Liu, Fangneng Zhan, Kaichen Zhou, Yilun Du, Paul Pu Liang, Hanspeter Pfister

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSandboxVLMæ¡†æž¶ä»¥å¢žå¼ºè§†è§‰è¯­è¨€æ¨¡åž‹çš„ä¸‰ç»´ç©ºé—´æ™ºèƒ½**

**å…³é”®è¯**: `ä¸‰ç»´æ„ŸçŸ¥` `è§†è§‰è¯­è¨€æ¨¡åž‹` `ç©ºé—´æ™ºèƒ½` `æŠ½è±¡è¾¹ç•Œæ¡†` `é›¶æ ·æœ¬å­¦ä¹ ` `æ¨¡æ€é¸¿æ²Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§‰è¯­è¨€æ¨¡åž‹åœ¨3Dä»»åŠ¡ä¸­å­˜åœ¨æ¨¡æ€é¸¿æ²Ÿï¼Œå¯¼è‡´ä»Ž2Dè¾“å…¥ä¸­æ£€ç´¢3Dä¿¡æ¯æ•ˆçŽ‡ä½Žä¸‹
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨æŠ½è±¡è¾¹ç•Œæ¡†ç¼–ç å‡ ä½•ç»“æž„å’Œç‰©ç†è¿åŠ¨ï¼Œè®¾è®¡å¤šé˜¶æ®µ3Dæ„ŸçŸ¥ç®¡é“
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹ï¼ŒSAT RealåŸºå‡†ä¸Šæ€§èƒ½æå‡8.3%ï¼Œæ— éœ€é¢å¤–è®­ç»ƒ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-language models (VLMs) struggle with 3D-related tasks such as spatial cognition and physical understanding, which are crucial for real-world applications like robotics and embodied agents. We attribute this to a modality gap between the 3D tasks and the 2D training of VLM, which led to inefficient retrieval of 3D information from 2D input. To bridge this gap, we introduce SandboxVLM, a simple yet effective framework that leverages abstract bounding boxes to encode geometric structure and physical kinematics for VLM. Specifically, we design a 3D Sandbox reconstruction and perception pipeline comprising four stages: generating multi-view priors with abstract control, proxy elevation, multi-view voting and clustering, and 3D-aware reasoning. Evaluated in zero-shot settings across multiple benchmarks and VLM backbones, our approach consistently improves spatial intelligence, achieving an 8.3\% gain on SAT Real compared with baseline methods for instance. These results demonstrate that equipping VLMs with a 3D abstraction substantially enhances their 3D reasoning ability without additional training, suggesting new possibilities for general-purpose embodied intelligence.

