---
layout: default
title: Positional Bias in Multimodal Embedding Models: Do They Favor the Beginning, the Middle, or the End?
---

# Positional Bias in Multimodal Embedding Models: Do They Favor the Beginning, the Middle, or the End?

**arXiv**: [2511.11216v1](https://arxiv.org/abs/2511.11216) | [PDF](https://arxiv.org/pdf/2511.11216.pdf)

**ä½œè€…**: Kebin Wu, Fatima Albreiki

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶å¤šæ¨¡æ€åµŒå…¥æ¨¡åž‹ä¸­çš„ä½ç½®åå·®åŠå…¶åœ¨å›¾åƒ-æ–‡æœ¬æ£€ç´¢ä¸­çš„å½±å“**

**å…³é”®è¯**: `ä½ç½®åå·®` `å¤šæ¨¡æ€åµŒå…¥æ¨¡åž‹` `å›¾åƒ-æ–‡æœ¬æ£€ç´¢` `æ–‡æœ¬ç¼–ç å™¨` `å›¾åƒç¼–ç å™¨` `è®­ç»ƒæŸå¤±`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€è¡¨ç¤ºæ¨¡åž‹ä¸­å­˜åœ¨ä½ç½®åå·®ï¼Œå³æ¨¡åž‹è¿‡åº¦å¼ºè°ƒè¾“å…¥ä½ç½®è€Œéžå†…å®¹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŒºåˆ†ä¸Šä¸‹æ–‡é‡è¦æ€§ä¸Žä½ç½®åå·®ï¼Œè¯„ä¼°ä¸åŒæ¨¡åž‹å’Œæ•°æ®é›†ä¸­çš„åå·®ç¨‹åº¦ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ–‡æœ¬ç¼–ç å™¨åå‘è¾“å…¥å¼€å¤´ï¼Œå›¾åƒç¼–ç å™¨åå‘å¼€å¤´å’Œç»“å°¾ï¼Œåå·®æºäºŽå¤šç§å› ç´ ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Positional bias - where models overemphasize certain positions regardless of content - has been shown to negatively impact model performance across various tasks. While recent research has extensively examined positional bias in text generation models, its presence and effects in representation models remain underexplored. Even less is known about such biases in multimodal models. In this work, we investigate positional bias in multimodal representation models, specifically in the context of image-text retrieval. We begin by distinguishing between context importance and positional bias, and then assess the presence and extent of positional bias across different models and datasets. Our experiments demonstrate that positional bias is prevalent in multimodal models, but manifests differently across modalities: text encoders tend to exhibit bias toward the beginning of the input, whereas image encoders show bias at both the beginning and end. Furthermore, we find that this bias arises from, or is amplified by, a combination of factors, including the positional encoding scheme, training loss, context importance, and the nature of using image-text pairs in multimodal training.

