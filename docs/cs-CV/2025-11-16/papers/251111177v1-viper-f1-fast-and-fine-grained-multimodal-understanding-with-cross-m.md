---
layout: default
title: Viper-F1: Fast and Fine-Grained Multimodal Understanding with Cross-Modal State-Space Modulation
---

# Viper-F1: Fast and Fine-Grained Multimodal Understanding with Cross-Modal State-Space Modulation

**arXiv**: [2511.11177v1](https://arxiv.org/abs/2511.11177) | [PDF](https://arxiv.org/pdf/2511.11177.pdf)

**ä½œè€…**: Quoc-Huy Trinh, Mustapha Abdullahi, Do Duy Hung Trinh, Bo Zhao, Debesh Jha

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºViper-F1ä»¥è§£å†³å¤šæ¨¡æ€æ¨¡åž‹é«˜è®¡ç®—æˆæœ¬å’Œç»†ç²’åº¦è§†è§‰ç†è§£ä¸è¶³çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€ç†è§£` `çŠ¶æ€ç©ºé—´æ¨¡åž‹` `è§†è§‰è¯­è¨€æ¨¡åž‹` `é«˜æ•ˆæŽ¨ç†` `ç»†ç²’åº¦è§†è§‰å®šä½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¤§æ¨¡åž‹è®¡ç®—æˆæœ¬é«˜ï¼Œåœ¨èµ„æºå—é™åœºæ™¯éƒ¨ç½²å›°éš¾ã€‚
2. ä½¿ç”¨æ¶²æ€çŠ¶æ€ç©ºé—´åŠ¨æ€æ›¿ä»£æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¹¶å¼•å…¥ä»¤ç‰Œ-ç½‘æ ¼ç›¸å…³æ¨¡å—å¢žå¼ºè§†è§‰å®šä½ã€‚
3. å®žéªŒæ˜¾ç¤ºæ¨¡åž‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®žçŽ°é«˜æ•ˆã€å‡†ç¡®çš„ç»†ç²’åº¦ç†è§£ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in multimodal large language models (MLLMs) have enabled impressive progress in vision-language understanding, yet their high computational cost limits deployment in resource-constrained scenarios such as robotic manipulation, personal assistants, and smart cameras. Most existing methods rely on Transformer-based cross-attention, whose quadratic complexity hinders efficiency. Moreover, small vision-language models often struggle to precisely capture fine-grained, task-relevant visual regions, leading to degraded performance on fine-grained reasoning tasks that limit their effectiveness in the real world. To address these issues, we introduce Viper-F1, a Hybrid State-Space Vision-Language Model that replaces attention with efficient Liquid State-Space Dynamics. To further enhance visual grounding, we propose a Token-Grid Correlation Module, which computes lightweight correlations between text tokens and image patches and modulates the state-space dynamics via FiLM conditioning. This enables the model to selectively emphasize visual regions relevant to the textual prompt while maintaining linear-time inference. Experimental results across multiple benchmarks demonstrate that Viper-F1 achieves accurate, fine-grained understanding with significantly improved efficiency.

