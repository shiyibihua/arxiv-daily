---
layout: default
title: Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective
---

# Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective

**arXiv**: [2511.11478v1](https://arxiv.org/abs/2511.11478) | [PDF](https://arxiv.org/pdf/2511.11478.pdf)

**ä½œè€…**: Nhat Chung, Taisei Hanyu, Toan Nguyen, Huy Le, Frederick Bumgarner, Duy Minh Ho Nguyen, Khoa Vo, Kashu Yamazaki, Chase Rainwater, Tung Kieu, Anh Nguyen, Ngan Le

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEmbodied-SlotSSMæ¡†æž¶ä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­éžé©¬å°”å¯å¤«æŽ¨ç†çš„å¯æ‰©å±•æ€§é—®é¢˜**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `éžé©¬å°”å¯å¤«æŽ¨ç†` `å¯¹è±¡ä¸­å¿ƒè§†è§‰` `æ§½ä½çŠ¶æ€ç©ºé—´æ¨¡åž‹` `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡åž‹` `é•¿åºåˆ—ä»»åŠ¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨äººæ“ä½œä¸­å¯¹è±¡çº§éƒ¨åˆ†å¯è§‚æµ‹æ€§å¯¼è‡´è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡åž‹åœ¨é•¿åºåˆ—ä¸­æŽ¨ç†å›°éš¾
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ§½ä½çŠ¶æ€ç©ºé—´å»ºæ¨¡å’Œå…³ç³»ç¼–ç å™¨å®žçŽ°æ—¶ç©ºä¸€è‡´çš„æ§½ä½èº«ä»½ä¸ŽåŠ¨ä½œé¢„æµ‹
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨LIBERO-Memä»»åŠ¡å¥—ä»¶ä¸ŠéªŒè¯äº†æ¡†æž¶çš„åŸºå‡†æ€§èƒ½å’Œå¯æ‰©å±•æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> As embodied agents operate in increasingly complex environments, the ability to perceive, track, and reason about individual object instances over time becomes essential, especially in tasks requiring sequenced interactions with visually similar objects. In these non-Markovian settings, key decision cues are often hidden in object-specific histories rather than the current scene. Without persistent memory of prior interactions (what has been interacted with, where it has been, or how it has changed) visuomotor policies may fail, repeat past actions, or overlook completed ones. To surface this challenge, we introduce LIBERO-Mem, a non-Markovian task suite for stress-testing robotic manipulation under object-level partial observability. It combines short- and long-horizon object tracking with temporally sequenced subgoals, requiring reasoning beyond the current frame. However, vision-language-action (VLA) models often struggle in such settings, with token scaling quickly becoming intractable even for tasks spanning just a few hundred frames. We propose Embodied-SlotSSM, a slot-centric VLA framework built for temporal scalability. It maintains spatio-temporally consistent slot identities and leverages them through two mechanisms: (1) slot-state-space modeling for reconstructing short-term history, and (2) a relational encoder to align the input tokens with action decoding. Together, these components enable temporally grounded, context-aware action prediction. Experiments show Embodied-SlotSSM's baseline performance on LIBERO-Mem and general tasks, offering a scalable solution for non-Markovian reasoning in object-centric robotic policies.

