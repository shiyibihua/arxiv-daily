---
layout: default
title: AccKV: Towards Efficient Audio-Video LLMs Inference via Adaptive-Focusing and Cross-Calibration KV Cache Optimization
---

# AccKV: Towards Efficient Audio-Video LLMs Inference via Adaptive-Focusing and Cross-Calibration KV Cache Optimization

**arXiv**: [2511.11106v1](https://arxiv.org/abs/2511.11106) | [PDF](https://arxiv.org/pdf/2511.11106.pdf)

**ä½œè€…**: Zhonghua Jiang, Kui Chen, Kunxi Li, Keting Yin, Yiyun Zhou, Zhaode Wang, Chengfei Lv, Shengyu Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAccKVæ¡†æž¶ä»¥ä¼˜åŒ–éŸ³è§†é¢‘å¤§è¯­è¨€æ¨¡åž‹æŽ¨ç†æ•ˆçŽ‡**

**å…³é”®è¯**: `KVç¼“å­˜ä¼˜åŒ–` `éŸ³è§†é¢‘å¤§è¯­è¨€æ¨¡åž‹` `å¤šæ¨¡æ€å¯¹é½` `è®¡ç®—æ•ˆçŽ‡` `è‡ªé€‚åº”èšç„¦`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šéŸ³è§†é¢‘æ¨¡æ€KVç¼“å­˜å¯¼è‡´è®¡ç®—æ•ˆçŽ‡ä½Žå’Œä¿¡æ¯æ··æ·†ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå±‚è‡ªé€‚åº”èšç„¦å’Œè·¨æ¨¡æ€æ ¡å‡†æŠ€æœ¯ä¼˜åŒ–KVç¼“å­˜ã€‚
3. å®žéªŒæ•ˆæžœï¼šæ˜¾è‘—æå‡è®¡ç®—æ•ˆçŽ‡åŒæ—¶ä¿æŒæ¨¡åž‹å‡†ç¡®æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advancements in Audio-Video Large Language Models (AV-LLMs) have enhanced their capabilities in tasks like audio-visual question answering and multimodal dialog systems. Video and audio introduce an extended temporal dimension, resulting in a larger key-value (KV) cache compared to static image embedding. A naive optimization strategy is to selectively focus on and retain KV caches of audio or video based on task. However, in the experiment, we observed that the attention of AV-LLMs to various modalities in the high layers is not strictly dependent on the task. In higher layers, the attention of AV-LLMs shifts more towards the video modality. In addition, we also found that directly integrating temporal KV of audio and spatial-temporal KV of video may lead to information confusion and significant performance degradation of AV-LLMs. If audio and video are processed indiscriminately, it may also lead to excessive compression or reservation of a certain modality, thereby disrupting the alignment between modalities. To address these challenges, we propose AccKV, an Adaptive-Focusing and Cross-Calibration KV cache optimization framework designed specifically for efficient AV-LLMs inference. Our method is based on layer adaptive focusing technology, selectively focusing on key modalities according to the characteristics of different layers, and enhances the recognition of heavy hitter tokens through attention redistribution. In addition, we propose a Cross-Calibration technique that first integrates inefficient KV caches within the audio and video modalities, and then aligns low-priority modalities with high-priority modalities to selectively evict KV cache of low-priority modalities. The experimental results show that AccKV can significantly improve the computational efficiency of AV-LLMs while maintaining accuracy.

