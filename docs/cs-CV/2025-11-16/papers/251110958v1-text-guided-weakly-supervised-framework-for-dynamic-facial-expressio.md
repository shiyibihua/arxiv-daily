---
layout: default
title: Text-guided Weakly Supervised Framework for Dynamic Facial Expression Recognition
---

# Text-guided Weakly Supervised Framework for Dynamic Facial Expression Recognition

**arXiv**: [2511.10958v1](https://arxiv.org/abs/2511.10958) | [PDF](https://arxiv.org/pdf/2511.10958.pdf)

**ä½œè€…**: Gunho Jung, Heejo Kong, Seong-Whan Lee

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–‡æœ¬å¼•å¯¼å¼±ç›‘ç£æ¡†æž¶TG-DFERä»¥è§£å†³åŠ¨æ€é¢éƒ¨è¡¨æƒ…è¯†åˆ«ä¸­çš„è§†è§‰å¤šæ ·æ€§å’Œæ—¶åºå¤æ‚æ€§**

**å…³é”®è¯**: `åŠ¨æ€é¢éƒ¨è¡¨æƒ…è¯†åˆ«` `å¼±ç›‘ç£å­¦ä¹ ` `å¤šå®žä¾‹å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡åž‹` `æ—¶åºå»ºæ¨¡` `æƒ…æ„Ÿè¯†åˆ«`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŠ¨æ€é¢éƒ¨è¡¨æƒ…è¯†åˆ«å­˜åœ¨å¤šå¯¹ä¸€æ ‡æ³¨é—®é¢˜ï¼Œè§†é¢‘å¸§ä¸Žå•ä¸€æƒ…æ„Ÿæ ‡ç­¾ä¸åŒ¹é…ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆè§†è§‰è¯­è¨€é¢„è®­ç»ƒæ¨¡åž‹ï¼Œé€šè¿‡æ–‡æœ¬æè¿°æä¾›è¯­ä¹‰æŒ‡å¯¼ï¼Œå¢žå¼ºå¤šå®žä¾‹å­¦ä¹ ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¼±ç›‘ç£ä¸‹ï¼ŒTG-DFERæé«˜äº†æ³›åŒ–æ€§ã€å¯è§£é‡Šæ€§å’Œæ—¶åºæ•æ„Ÿæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Dynamic facial expression recognition (DFER) aims to identify emotional states by modeling the temporal changes in facial movements across video sequences. A key challenge in DFER is the many-to-one labeling problem, where a video composed of numerous frames is assigned a single emotion label. A common strategy to mitigate this issue is to formulate DFER as a Multiple Instance Learning (MIL) problem. However, MIL-based approaches inherently suffer from the visual diversity of emotional expressions and the complexity of temporal dynamics. To address this challenge, we propose TG-DFER, a text-guided weakly supervised framework that enhances MIL-based DFER by incorporating semantic guidance and coherent temporal modeling. We incorporate a vision-language pre-trained (VLP) model is integrated to provide semantic guidance through fine-grained textual descriptions of emotional context. Furthermore, we introduce visual prompts, which align enriched textual emotion labels with visual instance features, enabling fine-grained reasoning and frame-level relevance estimation. In addition, a multi-grained temporal network is designed to jointly capture short-term facial dynamics and long-range emotional flow, ensuring coherent affective understanding across time. Extensive results demonstrate that TG-DFER achieves improved generalization, interpretability, and temporal sensitivity under weak supervision.

