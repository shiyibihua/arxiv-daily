---
layout: default
title: DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry
---

# DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.12653" target="_blank" class="toolbar-btn">arXiv: 2511.12653v1</a>
    <a href="https://arxiv.org/pdf/2511.12653.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.12653v1" 
            onclick="toggleFavorite(this, '2511.12653v1', 'DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Cheng Liao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DPVO-QAT++ï¼šå¼‚æ„é‡åŒ–æ„ŸçŸ¥è®­ç»ƒä¸CUDAæ ¸èåˆï¼Œæå‡æ·±åº¦Patchè§†è§‰é‡Œç¨‹è®¡æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è§†è§‰é‡Œç¨‹è®¡` `å¼‚æ„ç²¾åº¦é‡åŒ–` `é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ` `CUDAæ ¸èåˆ` `æ·±åº¦å­¦ä¹ ` `åµŒå…¥å¼ç³»ç»Ÿ` `è‡ªä¸»å¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ·±åº¦å­¦ä¹ è§†è§‰SLAMç³»ç»Ÿå‡ ä½•æ¨ç†èƒ½åŠ›å¼ºï¼Œä½†è®¡ç®—å¼€é”€å¤§ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™å¹³å°éƒ¨ç½²ã€‚
2. DPVO-QAT++é‡‡ç”¨å¼‚æ„ç²¾åº¦é‡åŒ–å’ŒCUDAæ ¸èåˆï¼Œåœ¨ä¿è¯ç²¾åº¦çš„å‰æä¸‹ï¼Œé™ä½å†…å­˜å ç”¨å¹¶åŠ é€Ÿè®¡ç®—ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDPVO-QAT++åœ¨TartanAirå’ŒEuRoCæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†FPSï¼Œé™ä½äº†å»¶è¿Ÿå’Œå†…å­˜å ç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ†å±‚é‡åŒ–ä¼˜åŒ–æ¡†æ¶DPVO-QAT++ï¼Œæ—¨åœ¨è§£å†³åŸºäºæ·±åº¦å­¦ä¹ çš„è§†è§‰SLAMç³»ç»Ÿè®¡ç®—å¼€é”€è¿‡å¤§ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„è‡ªä¸»å¹³å°ä¸Šéƒ¨ç½²çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å¯å­¦ä¹ çš„å°ºåº¦å‚æ•°åŒ–ã€è§†è§‰é‡Œç¨‹è®¡ï¼ˆVOï¼‰å‰ç«¯å’Œåç«¯çš„å¼‚æ„ç²¾åº¦è®¾è®¡ï¼ˆå‰ç«¯æµ®ç‚¹ä¼ªé‡åŒ–ä¸FP16/FP32ï¼Œåç«¯å…¨ç²¾åº¦ï¼‰ä»¥åŠç”¨äºä¼ªé‡åŒ–çš„GPUåŸç”Ÿæ ¸èåˆï¼ˆè‡ªå®šä¹‰CUDAæ ¸ï¼‰çš„ååŒé›†æˆï¼Œæ˜¾è‘—å‡å°‘äº†å†…å­˜å ç”¨å¹¶æé«˜äº†å¤„ç†é€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†åŸå§‹æ¨¡å‹çš„è½¨è¿¹ç²¾åº¦ã€‚åœ¨TartanAiræ•°æ®é›†ä¸Šï¼Œè¯¥æ¡†æ¶å®ç°äº†å¹³å‡FPSæé«˜52.1%ï¼Œä¸­å€¼å»¶è¿Ÿé™ä½29.1%ï¼Œå³°å€¼GPUå†…å­˜å ç”¨å‡å°‘64.9%ï¼Œå¹¶åœ¨32ä¸ªéªŒè¯åºåˆ—ä¸Šä¿æŒäº†ä¸åŸå§‹DPVOæ¨¡å‹ç›¸å½“çš„è½¨è¿¹ç²¾åº¦ï¼ˆATEï¼‰ã€‚åœ¨EuRoCæ•°æ®é›†ä¸Šï¼Œè¯¥æ¡†æ¶å®ç°äº†å¹³å‡FPSæé«˜30.1%ï¼Œä¸­å€¼å»¶è¿Ÿé™ä½23.1%ï¼Œå³°å€¼GPUå†…å­˜å ç”¨å‡å°‘37.7%ï¼Œå¹¶åœ¨11ä¸ªéªŒè¯åºåˆ—ä¸Šä¿æŒäº†ç›¸å½“çš„è½¨è¿¹ç²¾åº¦ï¼ˆATEï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDPVO-QAT++æœ‰æ•ˆåœ°å¼¥åˆäº†é«˜ç²¾åº¦æ·±åº¦VOä¸å®é™…éƒ¨ç½²çš„æ•ˆç‡è¦æ±‚ä¹‹é—´çš„å·®è·ï¼Œä¸ºè¯¥æŠ€æœ¯åœ¨ç°å®ä¸–ç•ŒåµŒå…¥å¼å¹³å°ä¸Šçš„åº”ç”¨æä¾›äº†ä¸€ç§å¯è¡Œçš„å·¥ç¨‹èŒƒä¾‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ·±åº¦å­¦ä¹ è§†è§‰é‡Œç¨‹è®¡ï¼ˆVOï¼‰è™½ç„¶ç²¾åº¦é«˜ï¼Œä½†è®¡ç®—é‡å¤§ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„åµŒå…¥å¼å¹³å°ä¸Šå®æ—¶è¿è¡Œã€‚ç°æœ‰çš„é‡åŒ–æ–¹æ³•è™½ç„¶å¯ä»¥é™ä½è®¡ç®—é‡ï¼Œä½†é€šå¸¸ä¼šç‰ºç‰²ç²¾åº¦ï¼Œå¹¶ä¸”å¯¹ä¸åŒçš„VOæ¨¡å—é‡‡ç”¨ç›¸åŒçš„é‡åŒ–ç­–ç•¥ï¼Œå¿½ç•¥äº†ä¸åŒæ¨¡å—å¯¹ç²¾åº¦çš„ä¸åŒéœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDPVO-QAT++çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨å¼‚æ„é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰å’ŒCUDAæ ¸èåˆï¼Œåœ¨ä¿è¯VOç²¾åº¦çš„å‰æä¸‹ï¼Œæœ€å¤§é™åº¦åœ°é™ä½è®¡ç®—é‡å’Œå†…å­˜å ç”¨ã€‚é€šè¿‡å¯¹VOå‰ç«¯å’Œåç«¯é‡‡ç”¨ä¸åŒçš„é‡åŒ–ç­–ç•¥ï¼Œå¹¶åˆ©ç”¨CUDAæ ¸èåˆä¼˜åŒ–é‡åŒ–è¿‡ç¨‹ï¼Œå®ç°äº†æ€§èƒ½å’Œç²¾åº¦çš„å¹³è¡¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDPVO-QAT++æ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªéƒ¨åˆ†ï¼šå¯å­¦ä¹ çš„å°ºåº¦å‚æ•°åŒ–ã€å¼‚æ„ç²¾åº¦é‡åŒ–å’ŒGPUåŸç”Ÿæ ¸èåˆã€‚é¦–å…ˆï¼Œå¼•å…¥å¯å­¦ä¹ çš„å°ºåº¦å‚æ•°ï¼Œæé«˜é‡åŒ–æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚ç„¶åï¼Œå¯¹VOå‰ç«¯é‡‡ç”¨ä½ç²¾åº¦é‡åŒ–ï¼ˆFP16/FP32ä¼ªé‡åŒ–ï¼‰ï¼Œå¯¹VOåç«¯é‡‡ç”¨å…¨ç²¾åº¦ï¼Œå®ç°å¼‚æ„ç²¾åº¦é‡åŒ–ã€‚æœ€åï¼Œåˆ©ç”¨CUDAæ ¸èåˆä¼˜åŒ–ä¼ªé‡åŒ–è¿‡ç¨‹ï¼Œæé«˜è®¡ç®—æ•ˆç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šDPVO-QAT++çš„å…³é”®åˆ›æ–°åœ¨äºå¼‚æ„ç²¾åº¦é‡åŒ–å’ŒGPUåŸç”Ÿæ ¸èåˆã€‚å¼‚æ„ç²¾åº¦é‡åŒ–å…è®¸å¯¹VOçš„ä¸åŒæ¨¡å—é‡‡ç”¨ä¸åŒçš„é‡åŒ–ç­–ç•¥ï¼Œä»è€Œåœ¨ä¿è¯ç²¾åº¦çš„å‰æä¸‹ï¼Œæœ€å¤§é™åº¦åœ°é™ä½è®¡ç®—é‡ã€‚GPUåŸç”Ÿæ ¸èåˆé€šè¿‡è‡ªå®šä¹‰CUDAæ ¸ä¼˜åŒ–é‡åŒ–è¿‡ç¨‹ï¼Œè¿›ä¸€æ­¥æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šVOå‰ç«¯é‡‡ç”¨æµ®ç‚¹ä¼ªé‡åŒ–ï¼Œä½¿ç”¨å¯å­¦ä¹ çš„scaleå‚æ•°æ¥è°ƒæ•´é‡åŒ–èŒƒå›´ï¼Œå¹¶é€šè¿‡QATæ¥ä¼˜åŒ–è¿™äº›å‚æ•°ã€‚VOåç«¯ä¿æŒå…¨ç²¾åº¦ï¼Œä»¥ä¿è¯å…³é”®çš„å‡ ä½•è®¡ç®—ç²¾åº¦ã€‚CUDAæ ¸èåˆé’ˆå¯¹ä¼ªé‡åŒ–æ“ä½œï¼Œä¾‹å¦‚clampå’Œroundï¼Œè¿›è¡Œä¼˜åŒ–ï¼Œå‡å°‘kernel launchçš„å¼€é”€ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬è½¨è¿¹è¯¯å·®å’Œé‡åŒ–æŸå¤±ï¼Œä»¥å¹³è¡¡ç²¾åº¦å’Œé‡åŒ–å¸¦æ¥çš„æ€§èƒ½æå‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DPVO-QAT++åœ¨TartanAiræ•°æ®é›†ä¸Šå®ç°äº†å¹³å‡FPSæé«˜52.1%ï¼Œä¸­å€¼å»¶è¿Ÿé™ä½29.1%ï¼Œå³°å€¼GPUå†…å­˜å ç”¨å‡å°‘64.9%ï¼ŒåŒæ—¶ä¿æŒäº†ä¸åŸå§‹DPVOæ¨¡å‹ç›¸å½“çš„è½¨è¿¹ç²¾åº¦ã€‚åœ¨EuRoCæ•°æ®é›†ä¸Šï¼Œå®ç°äº†å¹³å‡FPSæé«˜30.1%ï¼Œä¸­å€¼å»¶è¿Ÿé™ä½23.1%ï¼Œå³°å€¼GPUå†…å­˜å ç”¨å‡å°‘37.7%ï¼ŒåŒæ ·ä¿æŒäº†ç›¸å½“çš„è½¨è¿¹ç²¾åº¦ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒDPVO-QAT++åœ¨æ€§èƒ½æå‡å’Œç²¾åº¦ä¿æŒæ–¹é¢éƒ½å–å¾—äº†æ˜¾è‘—çš„æˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DPVO-QAT++é€‚ç”¨äºèµ„æºå—é™çš„è‡ªä¸»å¯¼èˆªå¹³å°ï¼Œå¦‚æ— äººæœºã€æœºå™¨äººç­‰ã€‚é€šè¿‡é™ä½è®¡ç®—é‡å’Œå†…å­˜å ç”¨ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä½¿é«˜ç²¾åº¦çš„æ·±åº¦å­¦ä¹ è§†è§‰é‡Œç¨‹è®¡åœ¨è¿™äº›å¹³å°ä¸Šå®æ—¶è¿è¡Œï¼Œä»è€Œæé«˜è‡ªä¸»å¯¼èˆªç³»ç»Ÿçš„æ€§èƒ½å’Œå¯é æ€§ã€‚è¯¥ç ”ç©¶æˆæœå¯¹äºæ¨åŠ¨æ·±åº¦å­¦ä¹ åœ¨åµŒå…¥å¼ç³»ç»Ÿä¸­çš„åº”ç”¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deep learning-based Visual SLAM (vSLAM) systems exhibit exceptional geometric reasoning capabilities, yet their prohibitive computational overhead severely restricts deployment on resource-constrained autonomous platforms. This paper presents a hierarchical quantization optimization framework, DPVO-QAT++ (DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry). Through the synergistic integration of learnable scale parameterization, a heterogeneous precision design for the Visual Odometry (VO) front-end and back-end (front-end floating-point fake quantization with FP16/FP32; back-end full precision), and GPU-native kernel fusion for fake quantization (custom CUDA kernels), our framework significantly reduces memory footprint and increases processing speed while preserving the trajectory accuracy of the original model. On the TartanAir dataset, our framework achieves an average FPS increase of 52.1%, a 29.1% reduction in median latency, and a 64.9% reduction in peak GPU memory reservation, while maintaining trajectory accuracy (ATE) comparable to the original DPVO model across 32 validation sequences. On the EuRoC dataset, it realizes an average FPS increase of 30.1%, a 23.1% reduction in median latency, and a 37.7% reduction in peak GPU memory reservation, maintaining comparable trajectory accuracy (ATE) across 11 validation sequences. Experimental results demonstrate that DPVO-QAT++ effectively bridges the gap between high-precision deep VO and the efficiency requirements for practical deployment, offering a viable engineering paradigm for the application of this technology on real-world embedded platforms.
>   Keywords: Visual Odometry, Heterogeneous Precision Architecture, Quantization-Aware Training, CUDA Kernel Fusion, Scale-Only Training, Deep Patch Visual Odometry, GPU-Native Kernel Fusion.

