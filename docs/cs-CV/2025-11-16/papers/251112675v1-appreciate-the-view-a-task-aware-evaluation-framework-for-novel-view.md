---
layout: default
title: Appreciate the View: A Task-Aware Evaluation Framework for Novel View Synthesis
---

# Appreciate the View: A Task-Aware Evaluation Framework for Novel View Synthesis

**arXiv**: [2511.12675v1](https://arxiv.org/abs/2511.12675) | [PDF](https://arxiv.org/pdf/2511.12675.pdf)

**ä½œè€…**: Saar Stern, Ido Sobol, Or Litany

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-16

**å¤‡æ³¨**: 3DV 2026. Project page: https://saarst.github.io/appreciate-the-view-website

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä»»åŠ¡æ„ŸçŸ¥çš„æ–°è§†è§’åˆæˆè¯„ä¼°æ¡†æž¶ï¼Œè§£å†³çŽ°æœ‰æŒ‡æ ‡ä¸Žäººç±»æ„ŸçŸ¥ä¸ä¸€è‡´é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æ–°è§†è§’åˆæˆ` `è¯„ä¼°æŒ‡æ ‡` `ä»»åŠ¡æ„ŸçŸ¥` `Zero123` `ç”Ÿæˆæ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–°è§†è§’åˆæˆ(NVS)è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚åƒç´ ç›¸ä¼¼åº¦ç­‰ï¼Œæ— æ³•å‡†ç¡®åæ˜ ç”Ÿæˆå›¾åƒçš„çœŸå®žæ€§å’Œè§†è§’å˜æ¢çš„å¿ å®žæ€§ã€‚
2. åˆ©ç”¨å¼ºå¤§çš„NVSåŸºç¡€æ¨¡åž‹Zero123çš„ç‰¹å¾ï¼Œé€šè¿‡è½»é‡çº§å¾®è°ƒï¼Œæå‡ºä»»åŠ¡æ„ŸçŸ¥çš„è¯„ä¼°æ¡†æž¶ï¼Œå¢žå¼ºåˆ¤åˆ«èƒ½åŠ›ã€‚
3. å¼•å…¥åŸºäºŽå‚è€ƒçš„$D_{	ext{PRISM}}$å’Œæ— å‚è€ƒçš„$	ext{MMD}_{	ext{PRISM}}$ä¸¤ä¸ªæŒ‡æ ‡ï¼Œä¸Žäººç±»åå¥½æ›´ä¸€è‡´ï¼Œèƒ½æ›´å¯é åœ°è¯†åˆ«é”™è¯¯ç”Ÿæˆã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–°è§†è§’åˆæˆ(NVS)çš„ç›®æ ‡æ˜¯ä»Žæœªè§è¿‡çš„è§†è§’ç”Ÿæˆç»™å®šå†…å®¹é€¼çœŸçš„å›¾åƒã€‚ç„¶è€Œï¼Œå¦‚ä½•ä¿è¯ç”Ÿæˆçš„å›¾åƒçœŸæ­£åæ˜ äº†é¢„æœŸçš„å˜æ¢ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦çš„æŒ‘æˆ˜ã€‚å°½ç®¡æœ€è¿‘çš„ç”Ÿæˆæ¨¡åž‹ï¼Œç‰¹åˆ«æ˜¯åŸºäºŽæ‰©æ•£çš„æ–¹æ³•ï¼Œå·²ç»æ˜¾è‘—æé«˜äº†NVSçš„è´¨é‡ï¼Œä½†çŽ°æœ‰çš„è¯„ä¼°æŒ‡æ ‡éš¾ä»¥è¯„ä¼°ç”Ÿæˆçš„å›¾åƒæ˜¯å¦æ—¢é€¼çœŸåˆå¿ å®žäºŽæºè§†å›¾å’Œé¢„æœŸçš„è§†ç‚¹å˜æ¢ã€‚æ ‡å‡†çš„æŒ‡æ ‡ï¼Œå¦‚åƒç´ çº§ç›¸ä¼¼åº¦å’ŒåŸºäºŽåˆ†å¸ƒçš„åº¦é‡ï¼Œå¸¸å¸¸é”™è¯¯åœ°å°†ä¸æ­£ç¡®çš„ç»“æžœæŽ’åœ¨å‰é¢ï¼Œå› ä¸ºå®ƒä»¬æœªèƒ½æ•æ‰åˆ°æºå›¾åƒã€è§†ç‚¹å˜åŒ–å’Œç”Ÿæˆè¾“å‡ºä¹‹é—´ç»†å¾®çš„å…³ç³»ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä»»åŠ¡æ„ŸçŸ¥çš„è¯„ä¼°æ¡†æž¶ï¼Œè¯¥æ¡†æž¶åˆ©ç”¨äº†å¼ºå¤§çš„NVSåŸºç¡€æ¨¡åž‹Zero123çš„ç‰¹å¾ï¼Œå¹¶ç»“åˆè½»é‡çº§çš„å¾®è°ƒæ­¥éª¤æ¥å¢žå¼ºåˆ¤åˆ«èƒ½åŠ›ã€‚ä½¿ç”¨è¿™äº›ç‰¹å¾ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸¤ä¸ªäº’è¡¥çš„è¯„ä¼°æŒ‡æ ‡ï¼šä¸€ä¸ªåŸºäºŽå‚è€ƒçš„åˆ†æ•°$D_{	ext{PRISM}}$å’Œä¸€ä¸ªæ— å‚è€ƒçš„åˆ†æ•°$	ext{MMD}_{	ext{PRISM}}$ã€‚ä¸¤è€…éƒ½èƒ½å¯é åœ°è¯†åˆ«ä¸æ­£ç¡®çš„ç”Ÿæˆç»“æžœï¼Œå¹¶æ ¹æ®äººç±»åå¥½ç ”ç©¶å¯¹æ¨¡åž‹è¿›è¡ŒæŽ’åºï¼Œä»Žè€Œè§£å†³äº†NVSè¯„ä¼°ä¸­çš„ä¸€ä¸ªæ ¹æœ¬æ€§å·®è·ã€‚æˆ‘ä»¬çš„æ¡†æž¶æä¾›äº†ä¸€ç§åŽŸåˆ™æ€§å’Œå®žç”¨çš„æ–¹æ³•æ¥è¯„ä¼°åˆæˆè´¨é‡ï¼Œä¸ºæ–°è§†è§’åˆæˆä¸­æ›´å¯é çš„è¿›å±•é“ºå¹³äº†é“è·¯ã€‚ä¸ºäº†è¿›ä¸€æ­¥æ”¯æŒè¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„æ— å‚è€ƒæŒ‡æ ‡åº”ç”¨äºŽToys4Kã€Google Scanned Objects (GSO)å’ŒOmniObject3Dè¿™ä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸­çš„å…­ç§NVSæ–¹æ³•ï¼Œå…¶ä¸­$	ext{MMD}_{	ext{PRISM}}$äº§ç”Ÿäº†ä¸€ä¸ªæ¸…æ™°è€Œç¨³å®šçš„æŽ’åï¼Œè¾ƒä½Žçš„åˆ†æ•°å§‹ç»ˆè¡¨æ˜Žæ›´å¼ºçš„æ¨¡åž‹ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ–°è§†è§’åˆæˆ(NVS)æ—¨åœ¨ä»Žä¸åŒè§†è§’ç”Ÿæˆå›¾åƒï¼Œä½†çŽ°æœ‰è¯„ä¼°æŒ‡æ ‡æ— æ³•å‡†ç¡®è¡¡é‡ç”Ÿæˆå›¾åƒçš„è´¨é‡ï¼Œç‰¹åˆ«æ˜¯çœŸå®žæ€§å’Œè§†è§’å˜æ¢çš„å¿ å®žæ€§ã€‚ä¼ ç»Ÿçš„åƒç´ çº§ç›¸ä¼¼åº¦ç­‰æŒ‡æ ‡æ— æ³•æ•æ‰æºå›¾åƒã€è§†è§’å˜åŒ–å’Œç”Ÿæˆå›¾åƒä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œå¯¼è‡´è¯„ä¼°ç»“æžœä¸Žäººç±»æ„ŸçŸ¥ä¸ä¸€è‡´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸€ä¸ªå¼ºå¤§çš„é¢„è®­ç»ƒNVSæ¨¡åž‹ï¼ˆZero123ï¼‰æå–çš„ç‰¹å¾ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œè½»é‡çº§çš„å¾®è°ƒï¼Œä»¥å¢žå¼ºç‰¹å¾çš„åˆ¤åˆ«èƒ½åŠ›ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥èŽ·å¾—æ›´å…·è¯­ä¹‰ä¿¡æ¯çš„ç‰¹å¾è¡¨ç¤ºï¼Œä»Žè€Œæ›´å‡†ç¡®åœ°è¯„ä¼°ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥è¯„ä¼°æ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„NVSæ¨¡åž‹ï¼ˆZero123ï¼‰æå–æºå›¾åƒå’Œç”Ÿæˆå›¾åƒçš„ç‰¹å¾ã€‚2) å¯¹æå–çš„ç‰¹å¾è¿›è¡Œè½»é‡çº§çš„å¾®è°ƒï¼Œä»¥å¢žå¼ºå…¶åˆ¤åˆ«èƒ½åŠ›ã€‚3) åŸºäºŽå¾®è°ƒåŽçš„ç‰¹å¾ï¼Œè®¡ç®—ä¸¤ä¸ªè¯„ä¼°æŒ‡æ ‡ï¼šåŸºäºŽå‚è€ƒçš„$D_{	ext{PRISM}}$å’Œæ— å‚è€ƒçš„$	ext{MMD}_{	ext{PRISM}}$ã€‚$D_{	ext{PRISM}}$è¡¡é‡ç”Ÿæˆå›¾åƒä¸Žå‚è€ƒå›¾åƒä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œè€Œ$	ext{MMD}_{	ext{PRISM}}$è¡¡é‡ç”Ÿæˆå›¾åƒåˆ†å¸ƒä¸ŽçœŸå®žå›¾åƒåˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ä¸ªä»»åŠ¡æ„ŸçŸ¥çš„è¯„ä¼°æ¡†æž¶ï¼Œè¯¥æ¡†æž¶åˆ©ç”¨äº†é¢„è®­ç»ƒNVSæ¨¡åž‹çš„ç‰¹å¾ï¼Œå¹¶é€šè¿‡å¾®è°ƒå¢žå¼ºäº†ç‰¹å¾çš„åˆ¤åˆ«èƒ½åŠ›ã€‚ä¸Žä¼ ç»Ÿçš„è¯„ä¼°æŒ‡æ ‡ç›¸æ¯”ï¼Œè¯¥æ¡†æž¶èƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°ç”Ÿæˆå›¾åƒçš„çœŸå®žæ€§å’Œè§†è§’å˜æ¢çš„å¿ å®žæ€§ï¼Œå¹¶ä¸”ä¸Žäººç±»æ„ŸçŸ¥æ›´ä¸€è‡´ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸¤ä¸ªäº’è¡¥çš„è¯„ä¼°æŒ‡æ ‡ï¼Œåˆ†åˆ«æ˜¯åŸºäºŽå‚è€ƒçš„$D_{	ext{PRISM}}$å’Œæ— å‚è€ƒçš„$	ext{MMD}_{	ext{PRISM}}$ï¼Œå¯ä»¥æ ¹æ®ä¸åŒçš„åº”ç”¨åœºæ™¯é€‰æ‹©åˆé€‚çš„æŒ‡æ ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å…³é”®çš„è®¾è®¡åŒ…æ‹¬ï¼š1) é€‰æ‹©Zero123ä½œä¸ºåŸºç¡€æ¨¡åž‹ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªå¼ºå¤§çš„NVSæ¨¡åž‹ï¼Œèƒ½å¤Ÿæå–ä¸°å¯Œçš„å›¾åƒç‰¹å¾ã€‚2) ä½¿ç”¨è½»é‡çº§çš„å¾®è°ƒæ–¹æ³•ï¼Œä»¥é¿å…è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚3) è®¾è®¡äº†ä¸¤ä¸ªäº’è¡¥çš„è¯„ä¼°æŒ‡æ ‡ï¼Œåˆ†åˆ«æ˜¯åŸºäºŽå‚è€ƒçš„$D_{	ext{PRISM}}$å’Œæ— å‚è€ƒçš„$	ext{MMD}_{	ext{PRISM}}$ï¼Œå¯ä»¥æ ¹æ®ä¸åŒçš„åº”ç”¨åœºæ™¯é€‰æ‹©åˆé€‚çš„æŒ‡æ ‡ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æž„ç­‰ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜Žï¼Œå±žäºŽæœªçŸ¥ä¿¡æ¯ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæå‡ºçš„$	ext{MMD}_{	ext{PRISM}}$æŒ‡æ ‡åœ¨Toys4Kã€GSOå’ŒOmniObject3Dä¸‰ä¸ªæ•°æ®é›†ä¸Šï¼Œå¯¹å…­ç§NVSæ–¹æ³•è¿›è¡Œäº†ç¨³å®šæŽ’åºï¼Œä¸”æŽ’åºç»“æžœä¸Žäººç±»åå¥½ä¸€è‡´ã€‚è¾ƒä½Žçš„$	ext{MMD}_{	ext{PRISM}}$åˆ†æ•°å§‹ç»ˆå¯¹åº”äºŽæ›´å¼ºçš„æ¨¡åž‹ï¼ŒéªŒè¯äº†è¯¥æŒ‡æ ‡çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæ–°è§†è§’åˆæˆæ¨¡åž‹çš„è¯„ä¼°ä¸Žæ”¹è¿›ï¼ŒæŽ¨åŠ¨ç›¸å…³æŠ€æœ¯å‘å±•ã€‚åœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€è™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žç­‰é¢†åŸŸï¼Œé«˜è´¨é‡çš„æ–°è§†è§’åˆæˆè‡³å…³é‡è¦ï¼Œè¯¥è¯„ä¼°æ¡†æž¶èƒ½å¸®åŠ©é€‰æ‹©å’Œä¼˜åŒ–æ›´å¯é çš„NVSæ¨¡åž‹ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The goal of Novel View Synthesis (NVS) is to generate realistic images of a given content from unseen viewpoints. But how can we trust that a generated image truly reflects the intended transformation? Evaluating its reliability remains a major challenge. While recent generative models, particularly diffusion-based approaches, have significantly improved NVS quality, existing evaluation metrics struggle to assess whether a generated image is both realistic and faithful to the source view and intended viewpoint transformation. Standard metrics, such as pixel-wise similarity and distribution-based measures, often mis-rank incorrect results as they fail to capture the nuanced relationship between the source image, viewpoint change, and generated output. We propose a task-aware evaluation framework that leverages features from a strong NVS foundation model, Zero123, combined with a lightweight tuning step to enhance discrimination. Using these features, we introduce two complementary evaluation metrics: a reference-based score, $D_{\text{PRISM}}$, and a reference-free score, $\text{MMD}_{\text{PRISM}}$. Both reliably identify incorrect generations and rank models in agreement with human preference studies, addressing a fundamental gap in NVS evaluation. Our framework provides a principled and practical approach to assessing synthesis quality, paving the way for more reliable progress in novel view synthesis. To further support this goal, we apply our reference-free metric to six NVS methods across three benchmarks: Toys4K, Google Scanned Objects (GSO), and OmniObject3D, where $\text{MMD}_{\text{PRISM}}$ produces a clear and stable ranking, with lower scores consistently indicating stronger models.

