---
layout: default
title: Accelerating Controllable Generation via Hybrid-grained Cache
---

# Accelerating Controllable Generation via Hybrid-grained Cache

**arXiv**: [2511.11031v1](https://arxiv.org/abs/2511.11031) | [PDF](https://arxiv.org/pdf/2511.11031.pdf)

**ä½œè€…**: Lin Liu, Huixia Ben, Shuo Wang, Jinda Lu, Junxiang Qiu, Shengeng Tang, Yanbin Hao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ··åˆç²’åº¦ç¼“å­˜ä»¥åŠ é€Ÿå¯æŽ§ç”Ÿæˆæ¨¡åž‹çš„è®¡ç®—æ•ˆçŽ‡**

**å…³é”®è¯**: `å¯æŽ§ç”Ÿæˆæ¨¡åž‹` `è®¡ç®—æ•ˆçŽ‡ä¼˜åŒ–` `ç¼“å­˜ç­–ç•¥` `ç‰¹å¾é‡ç”¨` `è·¨æ³¨æ„åŠ›å›¾`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¯æŽ§ç”Ÿæˆæ¨¡åž‹è®¡ç®—éœ€æ±‚é«˜ï¼Œå¯¼è‡´ç”Ÿæˆæ•ˆçŽ‡æ™®éè¾ƒä½Ž
2. é‡‡ç”¨å—çº§ç²—ç²’åº¦ç¼“å­˜å’Œæç¤ºçº§ç»†ç²’åº¦ç¼“å­˜ï¼ŒåŠ¨æ€ç»•è¿‡å†—ä½™è®¡ç®—
3. åœ¨COCO-Stuffæ•°æ®é›†ä¸Šï¼Œè®¡ç®—æˆæœ¬é™ä½Ž63%ï¼Œè¯­ä¹‰ä¿çœŸåº¦æŸå¤±å°äºŽ1.5%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Controllable generative models have been widely used to improve the realism of synthetic visual content. However, such models must handle control conditions and content generation computational requirements, resulting in generally low generation efficiency. To address this issue, we propose a Hybrid-Grained Cache (HGC) approach that reduces computational overhead by adopting cache strategies with different granularities at different computational stages. Specifically, (1) we use a coarse-grained cache (block-level) based on feature reuse to dynamically bypass redundant computations in encoder-decoder blocks between each step of model reasoning. (2) We design a fine-grained cache (prompt-level) that acts within a module, where the fine-grained cache reuses cross-attention maps within consecutive reasoning steps and extends them to the corresponding module computations of adjacent steps. These caches of different granularities can be seamlessly integrated into each computational link of the controllable generation process. We verify the effectiveness of HGC on four benchmark datasets, especially its advantages in balancing generation efficiency and visual quality. For example, on the COCO-Stuff segmentation benchmark, our HGC significantly reduces the computational cost (MACs) by 63% (from 18.22T to 6.70T), while keeping the loss of semantic fidelity (quantized performance degradation) within 1.5%.

