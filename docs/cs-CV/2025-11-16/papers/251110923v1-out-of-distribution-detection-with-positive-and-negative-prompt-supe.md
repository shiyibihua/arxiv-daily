---
layout: default
title: Out-of-Distribution Detection with Positive and Negative Prompt Supervision Using Large Language Models
---

# Out-of-Distribution Detection with Positive and Negative Prompt Supervision Using Large Language Models

**arXiv**: [2511.10923v1](https://arxiv.org/abs/2511.10923) | [PDF](https://arxiv.org/pdf/2511.10923.pdf)

**ä½œè€…**: Zhixia He, Chen Zhao, Minglai Shao, Xintao Wu, Xujiang Zhao, Dong Li, Qin Tian, Linlin Yu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ­£è´Ÿæç¤ºç›‘ç£æ–¹æ³•ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡åž‹å¢žå¼ºè§†è§‰æ¨¡æ€çš„åˆ†å¸ƒå¤–æ£€æµ‹æ€§èƒ½ã€‚**

**å…³é”®è¯**: `åˆ†å¸ƒå¤–æ£€æµ‹` `è§†è§‰è¯­è¨€æ¨¡åž‹` `æç¤ºä¼˜åŒ–` `å›¾æž¶æž„` `èƒ½é‡æ£€æµ‹å™¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè´Ÿæç¤ºå¯èƒ½æ•èŽ·é‡å æˆ–è¯¯å¯¼ä¿¡æ¯ï¼Œå¯¼è‡´åˆ†å¸ƒå¤–æ£€æµ‹æ•ˆæžœä¸ä½³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä¼˜åŒ–æ­£è´Ÿæç¤ºï¼Œè´Ÿæç¤ºèšç„¦ç±»é—´ç‰¹å¾ï¼Œå¹¶é€šè¿‡å›¾æž¶æž„ä¼ æ’­è¯­ä¹‰ç›‘ç£ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CIFAR-100å’ŒImageNet-1KåŸºå‡†ä¸Šï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Out-of-distribution (OOD) detection is committed to delineating the classification boundaries between in-distribution (ID) and OOD images. Recent advances in vision-language models (VLMs) have demonstrated remarkable OOD detection performance by integrating both visual and textual modalities. In this context, negative prompts are introduced to emphasize the dissimilarity between image features and prompt content. However, these prompts often include a broad range of non-ID features, which may result in suboptimal outcomes due to the capture of overlapping or misleading information. To address this issue, we propose Positive and Negative Prompt Supervision, which encourages negative prompts to capture inter-class features and transfers this semantic knowledge to the visual modality to enhance OOD detection performance. Our method begins with class-specific positive and negative prompts initialized by large language models (LLMs). These prompts are subsequently optimized, with positive prompts focusing on features within each class, while negative prompts highlight features around category boundaries. Additionally, a graph-based architecture is employed to aggregate semantic-aware supervision from the optimized prompt representations and propagate it to the visual branch, thereby enhancing the performance of the energy-based OOD detector. Extensive experiments on two benchmarks, CIFAR-100 and ImageNet-1K, across eight OOD datasets and five different LLMs, demonstrate that our method outperforms state-of-the-art baselines.

