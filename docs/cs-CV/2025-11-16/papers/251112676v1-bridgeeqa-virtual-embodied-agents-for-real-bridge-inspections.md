---
layout: default
title: BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections
---

# BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.12676" target="_blank" class="toolbar-btn">arXiv: 2511.12676v1</a>
    <a href="https://arxiv.org/pdf/2511.12676.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.12676v1" 
            onclick="toggleFavorite(this, '2511.12676v1', 'BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Subin Varghese, Joshua Gao, Asad Ur Rahman, Vedhus Hoskere

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBridgeEQAæ¡¥æ¢æ£€æµ‹åŸºå‡†ä¸EMVRæ¨¡å‹ï¼Œè§£å†³å…·èº«ç¯å¢ƒé—®ç­”ä¸­çš„å¤šå°ºåº¦æ¨ç†éš¾é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å…·èº«ç¯å¢ƒé—®ç­”` `æ¡¥æ¢æ£€æµ‹` `è§†è§‰æ¨ç†` `åœºæ™¯å›¾` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å…·èº«ç¯å¢ƒé—®ç­”åŸºå‡†éš¾ä»¥æ•æ‰çœŸå®åœºæ™¯çš„å¤æ‚æ€§ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤šå°ºåº¦æ¨ç†å’Œé•¿ç¨‹ç©ºé—´ç†è§£çš„åŸºç¡€è®¾æ–½æ£€æµ‹é¢†åŸŸã€‚
2. æå‡ºBridgeEQAåŸºå‡†ï¼Œåˆ©ç”¨ä¸“ä¸šæ¡¥æ¢æ£€æµ‹æŠ¥å‘Šå’Œå›¾åƒï¼Œæ„å»ºæ›´è´´è¿‘å®é™…åº”ç”¨çš„å…·èº«ç¯å¢ƒé—®ç­”ä»»åŠ¡ã€‚
3. æå‡ºEMVRæ¨¡å‹ï¼Œé€šè¿‡å›¾åƒåœºæ™¯å›¾ä¸Šçš„åºåˆ—å¯¼èˆªï¼Œå¢å¼ºæ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„è§†è§‰æ¨ç†èƒ½åŠ›ï¼Œå¹¶åœ¨BridgeEQAä¸ŠéªŒè¯äº†æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºBridgeEQAï¼Œä¸€ä¸ªç”¨äºçœŸå®æ¡¥æ¢æ£€æµ‹çš„å…·èº«ç¯å¢ƒé—®ç­”(EQA)åŸºå‡†ã€‚è¯¥åŸºå‡†åŒ…å«2200ä¸ªå¼€æ”¾è¯æ±‡é—®ç­”å¯¹ï¼ŒåŸºäº200ä¸ªçœŸå®æ¡¥æ¢åœºæ™¯çš„ä¸“ä¸šæ£€æµ‹æŠ¥å‘Šå’Œå›¾åƒæ•°æ®ï¼Œå¹³å‡æ¯ä¸ªåœºæ™¯åŒ…å«47.93å¼ å›¾åƒã€‚é—®é¢˜éœ€è¦ç»¼åˆå¤šå¼ å›¾åƒä¸­çš„è§†è§‰è¯æ®ï¼Œå¹¶å°†ç­”æ¡ˆä¸ç¾å›½å›½å®¶æ¡¥æ¢æ¸…å•(NBI)çš„çŠ¶å†µè¯„çº§å¯¹é½ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„EQAæŒ‡æ ‡â€”â€”å›¾åƒå¼•ç”¨ç›¸å…³æ€§ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹å¼•ç”¨ç›¸å…³å›¾åƒçš„èƒ½åŠ›ã€‚å¯¹ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹çš„è¯„ä¼°è¡¨æ˜ï¼Œåœ¨æƒ…æ™¯è®°å¿†EQAè®¾ç½®ä¸‹å­˜åœ¨æ˜¾è‘—çš„æ€§èƒ½å·®è·ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºå…·èº«è®°å¿†è§†è§‰æ¨ç†(EMVR)æ¨¡å‹ï¼Œå°†æ£€æµ‹å»ºæ¨¡ä¸ºåŸºäºå›¾åƒåœºæ™¯å›¾çš„é¡ºåºå¯¼èˆªï¼Œå¹¶åœ¨è¯¥åŸºå‡†ä¸Šå–å¾—äº†ä¼˜äºåŸºçº¿çš„æ€§èƒ½ã€‚æ•°æ®é›†å’Œä»£ç å·²å…¬å¼€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰å…·èº«ç¯å¢ƒé—®ç­”ï¼ˆEQAï¼‰æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ï¼Œç‰¹åˆ«æ˜¯åŸºç¡€è®¾æ–½æ£€æµ‹é¢†åŸŸï¼Œé¢ä¸´æŒ‘æˆ˜ã€‚è¿™äº›åœºæ™¯éœ€è¦æ¨¡å‹å…·å¤‡å¤šå°ºåº¦æ¨ç†ã€é•¿ç¨‹ç©ºé—´ç†è§£å’Œå¤æ‚çš„è¯­ä¹‰å…³ç³»ï¼Œè€Œç°æœ‰åŸºå‡†éš¾ä»¥å……åˆ†æ¨¡æ‹Ÿè¿™äº›å¤æ‚æ€§ï¼Œå¯¼è‡´æ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨æƒ…æ™¯è®°å¿†è¿›è¡Œæ¨ç†ï¼Œå¯¼è‡´æ€§èƒ½ç“¶é¢ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ¡¥æ¢æ£€æµ‹ä»»åŠ¡å»ºæ¨¡ä¸ºåœ¨å›¾åƒåœºæ™¯å›¾ä¸Šçš„é¡ºåºå¯¼èˆªé—®é¢˜ã€‚é€šè¿‡æ„å»ºå›¾åƒä¹‹é—´çš„è¿æ¥å…³ç³»ï¼Œè®©æ™ºèƒ½ä½“èƒ½å¤Ÿé€æ­¥æ¢ç´¢ç¯å¢ƒï¼Œæ”¶é›†è¯æ®ï¼Œå¹¶æœ€ç»ˆå›ç­”é—®é¢˜ã€‚è¿™ç§æ–¹æ³•æ¨¡æ‹Ÿäº†äººç±»æ£€æŸ¥å‘˜åœ¨å®é™…åœºæ™¯ä¸­çš„å·¥ä½œæ–¹å¼ï¼Œæœ‰åŠ©äºæé«˜æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œæ³›åŒ–æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEMVRæ¨¡å‹ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) å›¾åƒç‰¹å¾æå–æ¨¡å—ï¼Œç”¨äºæå–å›¾åƒçš„è§†è§‰ç‰¹å¾ï¼›2) åœºæ™¯å›¾æ„å»ºæ¨¡å—ï¼ŒåŸºäºå›¾åƒä¹‹é—´çš„ç©ºé—´å…³ç³»æ„å»ºåœºæ™¯å›¾ï¼›3) å¯¼èˆªæ¨¡å—ï¼Œæ™ºèƒ½ä½“åœ¨åœºæ™¯å›¾ä¸Šè¿›è¡Œå¯¼èˆªï¼Œé€‰æ‹©ä¸‹ä¸€ä¸ªè¦è®¿é—®çš„å›¾åƒï¼›4) è§†è§‰æ¨ç†æ¨¡å—ï¼Œç»¼åˆå·²è®¿é—®å›¾åƒçš„è§†è§‰ç‰¹å¾å’Œé—®é¢˜ä¿¡æ¯ï¼Œè¿›è¡Œæ¨ç†å¹¶ç”Ÿæˆç­”æ¡ˆã€‚æ•´ä¸ªè¿‡ç¨‹å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šEMVRçš„å…³é”®åˆ›æ–°åœ¨äºå°†å…·èº«ç¯å¢ƒé—®ç­”ä»»åŠ¡è½¬åŒ–ä¸ºå›¾åƒåœºæ™¯å›¾ä¸Šçš„å¯¼èˆªé—®é¢˜ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨å›¾åƒä¹‹é—´çš„ç©ºé—´å…³ç³»ï¼Œå¸®åŠ©æ™ºèƒ½ä½“æ›´å¥½åœ°ç†è§£ç¯å¢ƒï¼Œå¹¶è¿›è¡Œå¤šæ­¥æ¨ç†ã€‚æ­¤å¤–ï¼Œæå‡ºçš„å›¾åƒå¼•ç”¨ç›¸å…³æ€§æŒ‡æ ‡ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹åœ¨EQAä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åœºæ™¯å›¾æ„å»ºä¸­ï¼Œå¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰å®šä½æ¨¡å‹æ¥ä¼°è®¡å›¾åƒä¹‹é—´çš„ç›¸å¯¹ä½ç½®å…³ç³»ã€‚å¯¼èˆªæ¨¡å—å¯ä»¥ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•è¿›è¡Œè®­ç»ƒï¼Œå¥–åŠ±å‡½æ•°å¯ä»¥æ ¹æ®å›ç­”çš„å‡†ç¡®æ€§å’Œå›¾åƒå¼•ç”¨ç›¸å…³æ€§è¿›è¡Œè®¾è®¡ã€‚è§†è§‰æ¨ç†æ¨¡å—å¯ä»¥ä½¿ç”¨Transformerç­‰æ¨¡å‹ï¼Œå°†è§†è§‰ç‰¹å¾å’Œé—®é¢˜ä¿¡æ¯è¿›è¡Œèåˆï¼Œå¹¶ç”Ÿæˆç­”æ¡ˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„EMVRæ¨¡å‹åœ¨BridgeEQAåŸºå‡†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä¼˜äºç°æœ‰çš„è§†è§‰è¯­è¨€æ¨¡å‹ã€‚EMVRåœ¨å›ç­”å‡†ç¡®ç‡å’Œå›¾åƒå¼•ç”¨ç›¸å…³æ€§æ–¹é¢å‡æœ‰æå‡ï¼ŒéªŒè¯äº†å…¶åœ¨å¤æ‚åœºæ™¯ä¸‹è¿›è¡Œè§†è§‰æ¨ç†çš„æœ‰æ•ˆæ€§ã€‚è¯¥ç ”ç©¶ä¸ºå…·èº«ç¯å¢ƒé—®ç­”é¢†åŸŸæä¾›äº†ä¸€ä¸ªæ–°çš„åŸºå‡†å’Œä¸€ç§æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ¡¥æ¢ã€é“è·¯ã€éš§é“ç­‰åŸºç¡€è®¾æ–½çš„è‡ªåŠ¨åŒ–æ£€æµ‹ä¸ç»´æŠ¤ã€‚é€šè¿‡éƒ¨ç½²å…·èº«æ™ºèƒ½ä½“ï¼Œå¯ä»¥é™ä½äººå·¥æ£€æµ‹çš„æˆæœ¬å’Œé£é™©ï¼Œæé«˜æ£€æµ‹æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–éœ€è¦å¤æ‚è§†è§‰æ¨ç†çš„é¢†åŸŸï¼Œå¦‚æ™ºèƒ½å®‰é˜²ã€æœºå™¨äººå¯¼èˆªç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deploying embodied agents that can answer questions about their surroundings in realistic real-world settings remains difficult, partly due to the scarcity of benchmarks that faithfully capture practical operating conditions. We propose infrastructure inspection as a compelling domain for open-vocabulary Embodied Question Answering (EQA): it naturally demands multi-scale reasoning, long-range spatial understanding, and complex semantic relationships, while offering unique evaluation advantages via standardized National Bridge Inventory (NBI) condition ratings (0-9), professional inspection reports, and egocentric imagery.
>   We introduce BridgeEQA, a benchmark of 2,200 open-vocabulary question-answer pairs (in the style of OpenEQA) grounded in professional inspection reports across 200 real-world bridge scenes with 47.93 images on average per scene. Questions require synthesizing visual evidence across multiple images and aligning responses with NBI condition ratings. We further propose a new EQA metric Image Citation Relevance to evaluate the ability of a model to cite relevant images.
>   Evaluations of state-of-the-art vision-language models reveal substantial performance gaps under episodic memory EQA settings. To address this, we propose Embodied Memory Visual Reasoning (EMVR), which formulates inspection as sequential navigation over an image-based scene graph: images are nodes, and an agent takes actions to traverse views, compare evidence, and reason within a Markov decision process. EMVR shows strong performance over the baselines. We publicly release both the dataset and code.

