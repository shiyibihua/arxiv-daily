---
layout: default
title: WEAVE: Unleashing and Benchmarking the In-context Interleaved Comprehension and Generation
---

# WEAVE: Unleashing and Benchmarking the In-context Interleaved Comprehension and Generation

**arXiv**: [2511.11434v1](https://arxiv.org/abs/2511.11434) | [PDF](https://arxiv.org/pdf/2511.11434.pdf)

**ä½œè€…**: Wei Chow, Jiachun Pan, Yongyuan Liang, Mingze Zhou, Xue Song, Liyu Jia, Saining Zhang, Siliang Tang, Juncheng Li, Fengda Zhang, Weijia Wu, Hanwang Zhang, Tat-Seng Chua

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWEAVEå¥—ä»¶ä»¥è§£å†³å¤šæ¨¡æ€æ¨¡åž‹ä¸­å¤šè½®ä¸Šä¸‹æ–‡ç†è§£ä¸Žç”Ÿæˆçš„åŸºå‡†ç¼ºå¤±é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨¡åž‹` `å¤šè½®å¯¹è¯` `å›¾åƒç”Ÿæˆ` `è§†è§‰è®°å¿†` `åŸºå‡†è¯„ä¼°` `ä¸Šä¸‹æ–‡ç†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ•°æ®é›†èšç„¦å•è½®äº¤äº’ï¼Œæ— æ³•æ•æ‰çœŸå®žä¸–ç•Œå›¾åƒåˆ›ä½œçš„å¤šè½®ä¸Šä¸‹æ–‡ä¾èµ–
2. æž„å»ºWEAVE-100kå¤§è§„æ¨¡æ•°æ®é›†å’ŒWEAVEBenchåŸºå‡†ï¼Œæ”¯æŒå¤šè½®ç†è§£ã€ç¼–è¾‘å’Œç”Ÿæˆä»»åŠ¡
3. å®žéªŒæ˜¾ç¤ºè®­ç»ƒæå‡æ¨¡åž‹è§†è§‰è®°å¿†å’Œç”Ÿæˆèƒ½åŠ›ï¼Œä½†å¤šè½®ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä»å­˜æŒ‘æˆ˜

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in unified multimodal models (UMMs) have enabled impressive progress in visual comprehension and generation. However, existing datasets and benchmarks focus primarily on single-turn interactions, failing to capture the multi-turn, context-dependent nature of real-world image creation and editing. To address this gap, we present WEAVE, the first suite for in-context interleaved cross-modality comprehension and generation. Our suite consists of two complementary parts. WEAVE-100k is a large-scale dataset of 100K interleaved samples spanning over 370K dialogue turns and 500K images, covering comprehension, editing, and generation tasks that require reasoning over historical context. WEAVEBench is a human-annotated benchmark with 100 tasks based on 480 images, featuring a hybrid VLM judger evaluation framework based on both the reference image and the combination of the original image with editing instructions that assesses models' abilities in multi-turn generation, visual memory, and world-knowledge reasoning across diverse domains. Experiments demonstrate that training on WEAVE-100k enables vision comprehension, image editing, and comprehension-generation collaboration capabilities. Furthermore, it facilitates UMMs to develop emergent visual-memory capabilities, while extensive evaluations on WEAVEBench expose the persistent limitations and challenges of current approaches in multi-turn, context-aware image generation and editing. We believe WEAVE provides a view and foundation for studying in-context interleaved comprehension and generation for multi-modal community.

