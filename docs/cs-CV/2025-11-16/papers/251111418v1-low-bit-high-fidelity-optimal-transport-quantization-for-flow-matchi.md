---
layout: default
title: Low-Bit, High-Fidelity: Optimal Transport Quantization for Flow Matching
---

# Low-Bit, High-Fidelity: Optimal Transport Quantization for Flow Matching

**arXiv**: [2511.11418v1](https://arxiv.org/abs/2511.11418) | [PDF](https://arxiv.org/pdf/2511.11418.pdf)

**ä½œè€…**: Dara Varam, Diaa A. Abuhani, Imran Zualkernan, Raghad AlDamani, Lujain Khalil

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæœ€ä¼˜ä¼ è¾“çš„åŽè®­ç»ƒé‡åŒ–æ–¹æ³•ï¼Œä»¥åŽ‹ç¼©æµåŒ¹é…ç”Ÿæˆæ¨¡åž‹ç”¨äºŽè¾¹ç¼˜AIéƒ¨ç½²**

**å…³é”®è¯**: `æµåŒ¹é…ç”Ÿæˆæ¨¡åž‹` `åŽè®­ç»ƒé‡åŒ–` `æœ€ä¼˜ä¼ è¾“` `æ¨¡åž‹åŽ‹ç¼©` `è¾¹ç¼˜AI` `ç”Ÿæˆè´¨é‡ä¿æŒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æµåŒ¹é…ç”Ÿæˆæ¨¡åž‹å› é«˜ç²¾åº¦å‚æ•°éœ€æ±‚éš¾ä»¥å®žé™…éƒ¨ç½²ï¼Œé¢ä¸´åŽ‹ç¼©æŒ‘æˆ˜
2. é‡‡ç”¨æœ€ä¼˜ä¼ è¾“é‡åŒ–æœ€å°åŒ–æƒé‡é‡åŒ–å‰åŽ2-Wassersteinè·ç¦»ï¼Œä¼˜äºŽå‡åŒ€ã€åˆ†æ®µå’Œå¯¹æ•°é‡åŒ–
3. ç†è®ºåˆ†æžé‡åŒ–ç”Ÿæˆé€€åŒ–ä¸Šç•Œï¼Œå®žéªŒåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šä¿æŒç”Ÿæˆè´¨é‡è‡³2-3æ¯”ç‰¹

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Flow Matching (FM) generative models offer efficient simulation-free training and deterministic sampling, but their practical deployment is challenged by high-precision parameter requirements. We adapt optimal transport (OT)-based post-training quantization to FM models, minimizing the 2-Wasserstein distance between quantized and original weights, and systematically compare its effectiveness against uniform, piecewise, and logarithmic quantization schemes. Our theoretical analysis provides upper bounds on generative degradation under quantization, and empirical results across five benchmark datasets of varying complexity show that OT-based quantization preserves both visual generation quality and latent space stability down to 2-3 bits per parameter, where alternative methods fail. This establishes OT-based quantization as a principled, effective approach to compress FM generative models for edge and embedded AI applications.

