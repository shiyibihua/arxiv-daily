---
layout: default
title: Comprehension of Multilingual Expressions Referring to Target Objects in Visual Inputs
---

# Comprehension of Multilingual Expressions Referring to Target Objects in Visual Inputs

**arXiv**: [2511.11427v1](https://arxiv.org/abs/2511.11427) | [PDF](https://arxiv.org/pdf/2511.11427.pdf)

**ä½œè€…**: Francisco Nogueira, Alexandre Bernardino, Bruno Martins

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šè¯­è¨€æ•°æ®é›†ä¸Žæ³¨æ„åŠ›é”šå®šæž¶æž„ä»¥è§£å†³å¤šè¯­è¨€æŒ‡ä»£è¡¨è¾¾ç†è§£é—®é¢˜**

**å…³é”®è¯**: `å¤šè¯­è¨€æŒ‡ä»£è¡¨è¾¾ç†è§£` `æ³¨æ„åŠ›é”šå®šæž¶æž„` `æœºå™¨ç¿»è¯‘æ•°æ®é›†` `è§†è§‰è¯­è¨€æ¨¡åž‹` `å¤šè¯­è¨€è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæŒ‡ä»£è¡¨è¾¾ç†è§£ç ”ç©¶ä»¥è‹±è¯­ä¸ºä¸­å¿ƒï¼Œéš¾ä»¥æ»¡è¶³å¤šè¯­è¨€éƒ¨ç½²éœ€æ±‚ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºç»Ÿä¸€å¤šè¯­è¨€æ•°æ®é›†ï¼Œå¹¶è®¾è®¡åŸºäºŽæ³¨æ„åŠ›é”šå®šçš„ç¥žç»ç½‘ç»œæž¶æž„ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨RefCOCOå¤šè¯­è¨€è¯„ä¼°ä¸­å‡†ç¡®çŽ‡è¾¾86.9%ï¼Œæ€§èƒ½è·¨è¯­è¨€ä¸€è‡´ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Referring Expression Comprehension (REC) requires models to localize objects in images based on natural language descriptions. Research on the area remains predominantly English-centric, despite increasing global deployment demands. This work addresses multilingual REC through two main contributions. First, we construct a unified multilingual dataset spanning 10 languages, by systematically expanding 12 existing English REC benchmarks through machine translation and context-based translation enhancement. The resulting dataset comprises approximately 8 million multilingual referring expressions across 177,620 images, with 336,882 annotated objects. Second, we introduce an attention-anchored neural architecture that uses multilingual SigLIP2 encoders. Our attention-based approach generates coarse spatial anchors from attention distributions, which are subsequently refined through learned residuals. Experimental evaluation demonstrates competitive performance on standard benchmarks, e.g. achieving 86.9% accuracy at IoU@50 on RefCOCO aggregate multilingual evaluation, compared to an English-only result of 91.3%. Multilingual evaluation shows consistent capabilities across languages, establishing the practical feasibility of multilingual visual grounding systems. The dataset and model are available at $\href{https://multilingual.franreno.com}{multilingual.franreno.com}$.

