---
layout: default
title: OPFormer: Object Pose Estimation leveraging foundation model with geometric encoding
---

# OPFormer: Object Pose Estimation leveraging foundation model with geometric encoding

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.12614" target="_blank" class="toolbar-btn">arXiv: 2511.12614v1</a>
    <a href="https://arxiv.org/pdf/2511.12614.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.12614v1" 
            onclick="toggleFavorite(this, '2511.12614v1', 'OPFormer: Object Pose Estimation leveraging foundation model with geometric encoding')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Artem Moroz, V√≠t Zeman, Martin Mik≈°√≠k, Elizaveta Isianova, Miroslav David, Pavel Burget, Varun Burde

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.LG, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-16

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**OPFormerÔºöÂà©Áî®Âá†‰ΩïÁºñÁ†ÅÂíåÂü∫Á°ÄÊ®°ÂûãËøõË°åÁâ©‰ΩìÂßøÊÄÅ‰º∞ËÆ°**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Áâ©‰ΩìÂßøÊÄÅ‰º∞ËÆ°` `Transformer` `Âü∫Á°ÄÊ®°Âûã` `Âá†‰ΩïÁºñÁ†Å` `NOCS` `Êú∫Âô®‰∫∫ÊäìÂèñ` `ËÆ°ÁÆóÊú∫ËßÜËßâ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁâ©‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÊñπÊ≥ïÂú®Â§ÑÁêÜÁº∫‰πè3DÊ®°ÂûãÊàñÈÅÆÊå°‰∏•ÈáçÁöÑÂú∫ÊôØÊó∂Èù¢‰∏¥ÊåëÊàòÔºåÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñÊÄßÊúâÂæÖÊèêÈ´ò„ÄÇ
2. OPFormerÂà©Áî®TransformerÊû∂ÊûÑÂíåÂü∫Á°ÄÊ®°ÂûãÊèêÂèñÈ≤ÅÊ£íÁâπÂæÅÔºåÂπ∂ÁªìÂêàNOCSÂá†‰ΩïÂÖàÈ™åÔºåÂÆûÁé∞Êõ¥Á≤æÁ°ÆÁöÑÂßøÊÄÅ‰º∞ËÆ°„ÄÇ
3. Âú®BOPÂü∫ÂáÜÊµãËØï‰∏≠ÔºåOPFormerÂú®ÂáÜÁ°ÆÊÄßÂíåÊïàÁéá‰πãÈó¥ÂèñÂæó‰∫ÜÂπ≥Ë°°ÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁªü‰∏ÄÁöÑÁ´ØÂà∞Á´ØÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂Êó†ÁºùÈõÜÊàê‰∫ÜÁâ©‰ΩìÊ£ÄÊµãÂíåÂßøÊÄÅ‰º∞ËÆ°ÔºåÂπ∂ÂÖ∑ÊúâÈÄöÁî®ÁöÑÂêØÂä®ÊµÅÁ®ã„ÄÇËØ•ÊµÅÁ®ãÈ¶ñÂÖàÈÄöËøáÂêØÂä®Èò∂ÊÆµÔºå‰ªé‰º†ÁªüÁöÑ3D CADÊ®°ÂûãÁîüÊàêÁâ©‰ΩìË°®Á§∫ÔºåÊàñËÄÖÂú®Ê≤°ÊúâCADÊ®°ÂûãÁöÑÊÉÖÂÜµ‰∏ãÔºåÈÄöËøáÂ§öËßÜËßíÂõæÂÉèÂø´ÈÄüÈáçÂª∫È´ò‰øùÁúüÁ•ûÁªèË°®Á§∫(NeRF)„ÄÇÁªôÂÆöÊµãËØïÂõæÂÉèÔºåÁ≥ªÁªüÈ¶ñÂÖà‰ΩøÁî®CNOSÊ£ÄÊµãÂô®ÂÆö‰ΩçÁõÆÊ†áÁâ©‰Ωì„ÄÇÂØπ‰∫éÊØè‰∏™Ê£ÄÊµãÂà∞ÁöÑÁâ©‰ΩìÔºåÊèêÂá∫ÁöÑÂßøÊÄÅ‰º∞ËÆ°Ê®°ÂùóOPFormerÊé®Êñ≠Á≤æÁ°ÆÁöÑ6DÂßøÊÄÅ„ÄÇOPFormerÁöÑÊ†∏ÂøÉÊòØÂü∫‰∫éTransformerÁöÑÊû∂ÊûÑÔºåÂÆÉÂà©Áî®Âü∫Á°ÄÊ®°ÂûãËøõË°åÈ≤ÅÊ£íÁöÑÁâπÂæÅÊèêÂèñ„ÄÇÂÆÉÈÄöËøáËÅîÂêàÁºñÁ†ÅÂ§ö‰∏™Ê®°ÊùøËßÜÂõæÊù•Â≠¶‰π†ÂÖ®Èù¢ÁöÑÁâ©‰ΩìË°®Á§∫ÔºåÂπ∂‰ΩøÁî®ÂΩí‰∏ÄÂåñÁâ©‰ΩìÂùêÊ†áÁ©∫Èó¥(NOCS)Âà©Áî®ÊòæÂºèÁöÑ3DÂá†‰ΩïÂÖàÈ™åÊù•‰∏∞ÂØåËøô‰∫õÁâπÂæÅ„ÄÇÁÑ∂ÂêéÔºåËß£Á†ÅÂô®Âª∫Á´ãÈ≤ÅÊ£íÁöÑ2D-3DÂØπÂ∫îÂÖ≥Á≥ª‰ª•Á°ÆÂÆöÊúÄÁªàÂßøÊÄÅ„ÄÇÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑBOPÂü∫ÂáÜÊµãËØï‰∏≠ËØÑ‰º∞Ë°®ÊòéÔºåËØ•ÈõÜÊàêÁ≥ªÁªüÂú®ÂáÜÁ°ÆÊÄßÂíåÊïàÁéá‰πãÈó¥ÂèñÂæó‰∫ÜÂæàÂ•ΩÁöÑÂπ≥Ë°°ÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®Âü∫‰∫éÊ®°ÂûãÂíåÊó†Ê®°ÂûãÂú∫ÊôØ‰∏≠ÁöÑÂÆûÈôÖÈÄÇÁî®ÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁâ©‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÊñπÊ≥ïÂú®Áº∫‰πè3D CADÊ®°ÂûãÊàñÂ≠òÂú®‰∏•ÈáçÈÅÆÊå°ÁöÑÊÉÖÂÜµ‰∏ãÔºåÊÄßËÉΩ‰ºöÊòæËëó‰∏ãÈôç„ÄÇÊ≠§Â§ñÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞ËûçÂêà2DÂõæÂÉè‰ø°ÊÅØÂíå3DÂá†‰ΩïÂÖàÈ™å‰πüÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇËøô‰∫õÈóÆÈ¢òÈôêÂà∂‰∫ÜÂßøÊÄÅ‰º∞ËÆ°Âú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöOPFormerÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑÂü∫Á°ÄÊ®°ÂûãÊèêÂèñÂõæÂÉèÁöÑÈ≤ÅÊ£íÁâπÂæÅÔºåÂπ∂ÁªìÂêàÊòæÂºèÁöÑ3DÂá†‰ΩïÂÖàÈ™å‰ø°ÊÅØÔºàÈÄöËøáNOCSË°®Á§∫ÔºâÊù•ÊèêÂçáÂßøÊÄÅ‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇÈÄöËøáTransformerÊû∂ÊûÑÔºåÂèØ‰ª•ÊúâÊïàÂú∞Â≠¶‰π†Áâ©‰ΩìÊ®°ÊùøËßÜÂõæ‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÁêÜËß£Áâ©‰ΩìÁöÑ3DÁªìÊûÑ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöOPFormerÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Áâ©‰ΩìÊ£ÄÊµãÊ®°ÂùóÔºà‰ΩøÁî®CNOSÊ£ÄÊµãÂô®ÔºâÁî®‰∫éÂÆö‰ΩçÂõæÂÉè‰∏≠ÁöÑÁõÆÊ†áÁâ©‰ΩìÔºõ2) ÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºåÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑÂü∫Á°ÄÊ®°ÂûãÊèêÂèñÂõæÂÉèÁâπÂæÅÔºõ3) ÂßøÊÄÅ‰º∞ËÆ°Ê®°ÂùóÔºàOPFormerÔºâÔºåËØ•Ê®°Âùó‰ΩøÁî®TransformerÊû∂ÊûÑÔºåÂ∞ÜÊèêÂèñÁöÑÂõæÂÉèÁâπÂæÅ‰∏éNOCSÂá†‰ΩïÂÖàÈ™åËøõË°åËûçÂêàÔºåÂπ∂È¢ÑÊµãÁâ©‰ΩìÁöÑ6DÂßøÊÄÅ„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØÁ´ØÂà∞Á´ØÂèØËÆ≠ÁªÉÁöÑ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöOPFormerÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) Â∞ÜÈ¢ÑËÆ≠ÁªÉÁöÑÂü∫Á°ÄÊ®°ÂûãÂºïÂÖ•Âà∞Áâ©‰ΩìÂßøÊÄÅ‰º∞ËÆ°‰ªªÂä°‰∏≠ÔºåÂà©Áî®ÂÖ∂Âº∫Â§ßÁöÑÁâπÂæÅÊèêÂèñËÉΩÂäõÔºõ2) ÊòæÂºèÂú∞Âà©Áî®NOCSÂá†‰ΩïÂÖàÈ™åÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞Á∫¶ÊùüÂßøÊÄÅ‰º∞ËÆ°ËøáÁ®ãÔºõ3) ‰ΩøÁî®TransformerÊû∂ÊûÑÂ≠¶‰π†Áâ©‰ΩìÊ®°ÊùøËßÜÂõæ‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÁêÜËß£Áâ©‰ΩìÁöÑ3DÁªìÊûÑ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåOPFormerËÉΩÂ§üÊõ¥Â•ΩÂú∞Â§ÑÁêÜÁº∫‰πè3DÊ®°ÂûãÊàñÂ≠òÂú®ÈÅÆÊå°ÁöÑÂú∫ÊôØ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöOPFormerÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑËßÜËßâTransformerÔºà‰æãÂ¶ÇÔºåViTÔºâ‰Ωú‰∏∫ÁâπÂæÅÊèêÂèñÂô®Ôºõ2) ‰ΩøÁî®NOCSË°®Á§∫Êù•ÁºñÁ†ÅÁâ©‰ΩìÁöÑ3DÂá†‰Ωï‰ø°ÊÅØÔºõ3) ‰ΩøÁî®TransformerÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®Êû∂ÊûÑÔºåÂÖ∂‰∏≠ÁºñÁ†ÅÂô®Áî®‰∫éËûçÂêàÂõæÂÉèÁâπÂæÅÂíåNOCSÂá†‰ΩïÂÖàÈ™åÔºåËß£Á†ÅÂô®Áî®‰∫éÈ¢ÑÊµãÁâ©‰ΩìÁöÑ6DÂßøÊÄÅÔºõ4) ‰ΩøÁî®ÂêàÈÄÇÁöÑÊçüÂ§±ÂáΩÊï∞Êù•ËÆ≠ÁªÉÊï¥‰∏™ÁΩëÁªúÔºå‰æãÂ¶ÇÔºå‰ΩøÁî®ChamferË∑ùÁ¶ªÊù•Ë°°ÈáèÈ¢ÑÊµãÁöÑNOCSÂùêÊ†á‰∏éÁúüÂÆûNOCSÂùêÊ†á‰πãÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

OPFormerÂú®BOPÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊúâÁ´û‰∫âÂäõÁöÑÁªìÊûúÔºåÁâπÂà´ÊòØÂú®Â§ÑÁêÜÁº∫‰πè3DÊ®°ÂûãÊàñÂ≠òÂú®ÈÅÆÊå°ÁöÑÂú∫ÊôØ‰∏≠ÔºåÊÄßËÉΩ‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåOPFormerÂú®ÂáÜÁ°ÆÊÄßÂíåÊïàÁéá‰πãÈó¥ÂèñÂæó‰∫ÜÂæàÂ•ΩÁöÑÂπ≥Ë°°ÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÔºà‰æãÂ¶ÇÔºåÂπ≥ÂùáÁ≤æÂ∫¶„ÄÅÂè¨ÂõûÁéáÔºâÈúÄË¶ÅÂú®ËÆ∫Êñá‰∏≠Êü•Êâæ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

OPFormerÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÊäìÂèñ„ÄÅÂ¢ûÂº∫Áé∞ÂÆû„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüü„ÄÇÂú®Êú∫Âô®‰∫∫ÊäìÂèñ‰∏≠ÔºåÂáÜÁ°ÆÁöÑÁâ©‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÊòØÂÆûÁé∞ÂèØÈù†ÊäìÂèñÁöÑÂÖ≥ÈîÆ„ÄÇÂú®Â¢ûÂº∫Áé∞ÂÆû‰∏≠ÔºåOPFormerÂèØ‰ª•Áî®‰∫éÂ∞ÜËôöÊãüÁâ©‰ΩìÁ≤æÁ°ÆÂú∞Âè†Âä†Âà∞ÁúüÂÆûÂú∫ÊôØ‰∏≠„ÄÇÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåOPFormerÂèØ‰ª•Áî®‰∫éËØÜÂà´ÂíåÂÆö‰ΩçÂë®Âõ¥ÁöÑÁâ©‰ΩìÔºå‰ªéËÄåÊèêÈ´òÈ©æÈ©∂ÂÆâÂÖ®ÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We introduce a unified, end-to-end framework that seamlessly integrates object detection and pose estimation with a versatile onboarding process. Our pipeline begins with an onboarding stage that generates object representations from either traditional 3D CAD models or, in their absence, by rapidly reconstructing a high-fidelity neural representation (NeRF) from multi-view images. Given a test image, our system first employs the CNOS detector to localize target objects. For each detection, our novel pose estimation module, OPFormer, infers the precise 6D pose. The core of OPFormer is a transformer-based architecture that leverages a foundation model for robust feature extraction. It uniquely learns a comprehensive object representation by jointly encoding multiple template views and enriches these features with explicit 3D geometric priors using Normalized Object Coordinate Space (NOCS). A decoder then establishes robust 2D-3D correspondences to determine the final pose. Evaluated on the challenging BOP benchmarks, our integrated system demonstrates a strong balance between accuracy and efficiency, showcasing its practical applicability in both model-based and model-free scenarios.

