---
layout: default
title: Preserving Cross-Modal Consistency for CLIP-based Class-Incremental Learning
---

# Preserving Cross-Modal Consistency for CLIP-based Class-Incremental Learning

**arXiv**: [2511.10974v1](https://arxiv.org/abs/2511.10974) | [PDF](https://arxiv.org/pdf/2511.10974.pdf)

**ä½œè€…**: Haoran Chen, Houze Xu, Micah Goldblum, Daoguo Dong, Zuxuan Wu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDMCæ¡†æž¶ä»¥è§£å†³CLIPç±»å¢žé‡å­¦ä¹ ä¸­çš„è·¨æ¨¡æ€å¯¹é½é—®é¢˜**

**å…³é”®è¯**: `ç±»å¢žé‡å­¦ä¹ ` `è·¨æ¨¡æ€å¯¹é½` `è½¯æç¤ºä¼˜åŒ–` `æœ€ä¼˜ä¼ è¾“æ ¡å‡†` `è§†è§‰è¯­è¨€æ¨¡åž‹` `ç”Ÿæˆå¼å›žæ”¾`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šCLIPç±»å¢žé‡å­¦ä¹ ä¸­æ–‡æœ¬åŽŸåž‹è¿‡æ‹Ÿåˆæ–°ç±»å¯¼è‡´åˆ†ç±»å™¨åå·®
2. æ–¹æ³•è¦ç‚¹ï¼šä¸¤é˜¶æ®µæ¡†æž¶è§£è€¦è§†è§‰ç¼–ç å™¨å’Œæ–‡æœ¬è½¯æç¤ºä¼˜åŒ–ä»¥ä¿æŒè·¨æ¨¡æ€ä¸€è‡´æ€§
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®žçŽ°SOTAï¼ŒDMC-OTå¹³å‡æå‡å‡†ç¡®çŽ‡1.80%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Class-incremental learning (CIL) enables models to continuously learn new categories from sequential tasks without forgetting previously acquired knowledge. While recent advances in vision-language models such as CLIP have demonstrated strong generalization across domains, extending them to continual settings remains challenging. In particular, learning task-specific soft prompts for newly introduced classes often leads to severe classifier bias, as the text prototypes overfit to recent categories when prior data are unavailable. In this paper, we propose DMC, a simple yet effective two-stage framework for CLIP-based CIL that decouples the adaptation of the vision encoder and the optimization of textual soft prompts. Each stage is trained with the other frozen, allowing one modality to act as a stable semantic anchor for the other to preserve cross-modal alignment. Furthermore, current CLIP-based CIL approaches typically store class-wise Gaussian statistics for generative replay, yet they overlook the distributional drift that arises when the vision encoder is updated over time. To address this issue, we introduce DMC-OT, an enhanced version of DMC that incorporates an optimal-transport guided calibration strategy to align memory statistics across evolving encoders, along with a task-specific prompting design that enhances inter-task separability. Extensive experiments on CIFAR-100, Imagenet-R, CUB-200, and UCF-101 demonstrate that both DMC and DMC-OT achieve state-of-the-art performance, with DMC-OT further improving accuracy by an average of 1.80%.

