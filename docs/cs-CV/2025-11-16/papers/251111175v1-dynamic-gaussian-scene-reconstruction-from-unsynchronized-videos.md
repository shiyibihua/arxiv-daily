---
layout: default
title: Dynamic Gaussian Scene Reconstruction from Unsynchronized Videos
---

# Dynamic Gaussian Scene Reconstruction from Unsynchronized Videos

**arXiv**: [2511.11175v1](https://arxiv.org/abs/2511.11175) | [PDF](https://arxiv.org/pdf/2511.11175.pdf)

**ä½œè€…**: Zhixin Xu, Hengyu Zhou, Yuan Liu, Wenhan Xue, Hao Pan, Wenping Wang, Bin Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŠ¨æ€é«˜æ–¯åœºæ™¯é‡å»ºæ–¹æ³•ä»¥è§£å†³éžåŒæ­¥å¤šè§†è§’è§†é¢‘çš„æ—¶é—´å¯¹é½é—®é¢˜**

**å…³é”®è¯**: `åŠ¨æ€åœºæ™¯é‡å»º` `4Dé«˜æ–¯æº…å°„` `æ—¶é—´å¯¹é½` `å¤šè§†è§’è§†é¢‘` `éžåŒæ­¥æ•°æ®` `è®¡ç®—æœºè§†è§‰`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šè§†è§’è§†é¢‘å› ç›¸æœºè§¦å‘å»¶è¿Ÿå¯¼è‡´æ—¶é—´ä¸åŒæ­¥ï¼Œé™ä½Žé‡å»ºè´¨é‡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ç²—åˆ°ç²¾å¯¹é½æ¨¡å—ä¼°è®¡å¹¶è¡¥å¿ç›¸æœºæ—¶é—´åç§»ï¼Œå®žçŽ°å­å¸§ç²¾åº¦ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒæ˜¾ç¤ºæ–¹æ³•æœ‰æ•ˆå¤„ç†æ—¶é—´é”™ä½è§†é¢‘ï¼Œæ˜¾è‘—æå‡åŸºçº¿æ–¹æ³•æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-view video reconstruction plays a vital role in computer vision, enabling applications in film production, virtual reality, and motion analysis. While recent advances such as 4D Gaussian Splatting (4DGS) have demonstrated impressive capabilities in dynamic scene reconstruction, they typically rely on the assumption that input video streams are temporally synchronized. However, in real-world scenarios, this assumption often fails due to factors like camera trigger delays or independent recording setups, leading to temporal misalignment across views and reduced reconstruction quality. To address this challenge, a novel temporal alignment strategy is proposed for high-quality 4DGS reconstruction from unsynchronized multi-view videos. Our method features a coarse-to-fine alignment module that estimates and compensates for each camera's time shift. The method first determines a coarse, frame-level offset and then refines it to achieve sub-frame accuracy. This strategy can be integrated as a readily integrable module into existing 4DGS frameworks, enhancing their robustness when handling asynchronous data. Experiments show that our approach effectively processes temporally misaligned videos and significantly enhances baseline methods.

