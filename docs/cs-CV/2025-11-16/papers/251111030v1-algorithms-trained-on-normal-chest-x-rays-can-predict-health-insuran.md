---
layout: default
title: Algorithms Trained on Normal Chest X-rays Can Predict Health Insurance Types
---

# Algorithms Trained on Normal Chest X-rays Can Predict Health Insurance Types

**arXiv**: [2511.11030v1](https://arxiv.org/abs/2511.11030) | [PDF](https://arxiv.org/pdf/2511.11030.pdf)

**ä½œè€…**: Chi-Yu Chen, Rawan Abulibdeh, Arash Asgari, Leo Anthony Celi, Deirdre Goode, Hassan Hamidi, Laleh Seyyed-Kalantari, Po-Chih Kuo, Ned McCague, Thomas Sounack

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åŸºäºŽæ­£å¸¸èƒ¸éƒ¨Xå…‰ç‰‡é¢„æµ‹å¥åº·ä¿é™©ç±»åž‹ï¼Œæ­ç¤ºåŒ»ç–—AIä¸­çš„ç¤¾ä¼šä¸å¹³ç­‰ä¿¡å·**

**å…³é”®è¯**: `èƒ¸éƒ¨Xå…‰åˆ†æž` `åŒ»ç–—AIå…¬å¹³æ€§` `ç¤¾ä¼šç»æµŽé¢„æµ‹` `æ·±åº¦å­¦ä¹ æ¨¡åž‹` `å›¾åƒç‰¹å¾æå–` `ç¤¾ä¼šä¸å¹³ç­‰æ£€æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŒ»ç–—AIæ¨¡åž‹èƒ½å¦ä»Žæ­£å¸¸èƒ¸éƒ¨Xå…‰ç‰‡ä¸­æ£€æµ‹ç¤¾ä¼šä¸å¹³ç­‰ï¼Œå¦‚å¥åº·ä¿é™©ç±»åž‹ä½œä¸ºç¤¾ä¼šç»æµŽåœ°ä½ä»£ç†ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨DenseNet121ã€SwinV2-Bå’ŒMedMambaç­‰å…ˆè¿›æž¶æž„ï¼Œåœ¨MIMIC-CXR-JPGå’ŒCheXpertæ•°æ®é›†ä¸Šè®­ç»ƒã€‚
3. å®žéªŒæ•ˆæžœï¼šæ¨¡åž‹é¢„æµ‹AUCçº¦0.67-0.68ï¼Œä¿¡å·åœ¨æŽ§åˆ¶å¹´é¾„ã€ç§æ—å’Œæ€§åˆ«åŽä»å­˜åœ¨ï¼Œä¸”å‘ˆå¼¥æ•£åˆ†å¸ƒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Artificial intelligence is revealing what medicine never intended to encode. Deep vision models, trained on chest X-rays, can now detect not only disease but also invisible traces of social inequality. In this study, we show that state-of-the-art architectures (DenseNet121, SwinV2-B, MedMamba) can predict a patient's health insurance type, a strong proxy for socioeconomic status, from normal chest X-rays with significant accuracy (AUC around 0.67 on MIMIC-CXR-JPG, 0.68 on CheXpert). The signal persists even when age, race, and sex are controlled for, and remains detectable when the model is trained exclusively on a single racial group. Patch-based occlusion reveals that the signal is diffuse rather than localized, embedded in the upper and mid-thoracic regions. This suggests that deep networks may be internalizing subtle traces of clinical environments, equipment differences, or care pathways; learning socioeconomic segregation itself. These findings challenge the assumption that medical images are neutral biological data. By uncovering how models perceive and exploit these hidden social signatures, this work reframes fairness in medical AI: the goal is no longer only to balance datasets or adjust thresholds, but to interrogate and disentangle the social fingerprints embedded in clinical data itself.

