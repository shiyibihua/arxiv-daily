---
layout: default
title: CLUE: Controllable Latent space of Unprompted Embeddings for Diversity Management in Text-to-Image Synthesis
---

# CLUE: Controllable Latent space of Unprompted Embeddings for Diversity Management in Text-to-Image Synthesis

**arXiv**: [2511.10993v1](https://arxiv.org/abs/2511.10993) | [PDF](https://arxiv.org/pdf/2511.10993.pdf)

**ä½œè€…**: Keunwoo Park, Jihye Chae, Joong Ho Ahn, Jihoon Kweon

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCLUEæ¡†æž¶ï¼Œé€šè¿‡å¯æŽ§æ½œåœ¨ç©ºé—´åœ¨æœ‰é™æ•°æ®ä¸‹å®žçŽ°å¤šæ ·ç¨³å®šå›¾åƒç”Ÿæˆã€‚**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒåˆæˆ` `å¯æŽ§æ½œåœ¨ç©ºé—´` `æ•°æ®å¢žå¼º` `åŒ»å­¦å›¾åƒç”Ÿæˆ` `Stable Diffusion` `å¤šæ ·æ€§ç®¡ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ–‡æœ¬åˆ°å›¾åƒåˆæˆåœ¨ä¸“ä¸šé¢†åŸŸï¼ˆå¦‚åŒ»å­¦ï¼‰æ•°æ®æœ‰é™æ—¶ï¼Œéš¾ä»¥å¹³è¡¡å¤šæ ·æ€§ä¸Žç¨³å®šæ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽStable Diffusionï¼Œå¼•å…¥Style Encoderå’Œé¢å¤–æ³¨æ„åŠ›å±‚ï¼Œç‹¬ç«‹äºŽæç¤ºæŽ§åˆ¶é£Žæ ¼åµŒå…¥ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨è€³ç‚Žæ•°æ®é›†ä¸Šï¼ŒFIDé™è‡³9.30ï¼Œåˆæˆæ•°æ®è®­ç»ƒF1è¾¾83.21%ï¼Œä¼˜äºŽåŸºçº¿ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-to-image synthesis models require the ability to generate diverse images while maintaining stability. To overcome this challenge, a number of methods have been proposed, including the collection of prompt-image datasets and the integration of additional data modalities during training. Although these methods have shown promising results in general domains, they face limitations when applied to specialized fields such as medicine, where only limited types and insufficient amounts of data are available. We present CLUE (Controllable Latent space of Unprompted Embeddings), a generative model framework that achieves diverse generation while maintaining stability through fixed-format prompts without requiring any additional data. Based on the Stable Diffusion architecture, CLUE employs a Style Encoder that processes images and prompts to generate style embeddings, which are subsequently fed into a new second attention layer of the U-Net architecture. Through Kullback-Leibler divergence, the latent space achieves continuous representation of image features within Gaussian regions, independent of prompts. Performance was assessed on otitis media dataset. CLUE reduced FID to 9.30 (vs. 46.81) and improved recall to 70.29% (vs. 49.60%). A classifier trained on synthetic-only data at 1000% scale achieved an F1 score of 83.21% (vs. 73.83%). Combining synthetic data with equal amounts of real data achieved an F1 score of 94.76%, higher than when using only real data. On an external dataset, synthetic-only training achieved an F1 score of 76.77% (vs. 60.61%) at 1000% scale. The combined approach achieved an F1 score of 85.78%, higher than when using only the internal dataset. These results demonstrate that CLUE enables diverse yet stable image generation from limited datasets and serves as an effective data augmentation method for domain-specific applications.

