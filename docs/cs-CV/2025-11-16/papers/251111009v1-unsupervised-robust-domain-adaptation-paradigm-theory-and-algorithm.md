---
layout: default
title: Unsupervised Robust Domain Adaptation: Paradigm, Theory and Algorithm
---

# Unsupervised Robust Domain Adaptation: Paradigm, Theory and Algorithm

**arXiv**: [2511.11009v1](https://arxiv.org/abs/2511.11009) | [PDF](https://arxiv.org/pdf/2511.11009.pdf)

**ä½œè€…**: Fuxiang Huang, Xiaowei Fu, Shiyu Ye, Lina Ma, Wen Li, Xinbo Gao, David Zhang, Lei Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ— ç›‘ç£é²æ£’åŸŸé€‚åº”èŒƒå¼ä¸ŽDARTç®—æ³•ï¼Œä»¥è§£å†³åŸŸé€‚åº”ä¸­å¯¹æŠ—æ”»å‡»é²æ£’æ€§é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ— ç›‘ç£åŸŸé€‚åº”` `å¯¹æŠ—é²æ£’æ€§` `æ³›åŒ–ç†è®º` `è§£è€¦è’¸é¦` `DARTç®—æ³•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿå¯¹æŠ—è®­ç»ƒåœ¨æ— ç›‘ç£åŸŸé€‚åº”ä¸­å¤±æ•ˆï¼Œå› å­˜åœ¨å†…åœ¨çº ç¼ æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥URDAèŒƒå¼ä¸ŽDARTç®—æ³•ï¼Œé€šè¿‡è§£è€¦è’¸é¦å®žçŽ°é²æ£’åŒ–è®­ç»ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠéªŒè¯ï¼ŒDARTå¢žå¼ºé²æ£’æ€§åŒæ—¶ä¿æŒåŸŸé€‚åº”èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Unsupervised domain adaptation (UDA) aims to transfer knowledge from a label-rich source domain to an unlabeled target domain by addressing domain shifts. Most UDA approaches emphasize transfer ability, but often overlook robustness against adversarial attacks. Although vanilla adversarial training (VAT) improves the robustness of deep neural networks, it has little effect on UDA. This paper focuses on answering three key questions: 1) Why does VAT, known for its defensive effectiveness, fail in the UDA paradigm? 2) What is the generalization bound theory under attacks and how does it evolve from classical UDA theory? 3) How can we implement a robustification training procedure without complex modifications? Specifically, we explore and reveal the inherent entanglement challenge in general UDA+VAT paradigm, and propose an unsupervised robust domain adaptation (URDA) paradigm. We further derive the generalization bound theory of the URDA paradigm so that it can resist adversarial noise and domain shift. To the best of our knowledge, this is the first time to establish the URDA paradigm and theory. We further introduce a simple, novel yet effective URDA algorithm called Disentangled Adversarial Robustness Training (DART), a two-step training procedure that ensures both transferability and robustness. DART first pre-trains an arbitrary UDA model, and then applies an instantaneous robustification post-training step via disentangled distillation.Experiments on four benchmark datasets with/without attacks show that DART effectively enhances robustness while maintaining domain adaptability, and validate the URDA paradigm and theory.

