---
layout: default
title: Rethinking Efficient Mixture-of-Experts for Remote Sensing Modality-Missing Classification
---

# Rethinking Efficient Mixture-of-Experts for Remote Sensing Modality-Missing Classification

**arXiv**: [2511.11460v1](https://arxiv.org/abs/2511.11460) | [PDF](https://arxiv.org/pdf/2511.11460.pdf)

**ä½œè€…**: Qinghao Gao, Jianhai Qu, Yunsong Li, Weiqiang Dong

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç¼ºå¤±æ„ŸçŸ¥æ··åˆLoRAæ¡†æž¶ä»¥è§£å†³é¥æ„Ÿå¤šæ¨¡æ€åˆ†ç±»ä¸­çš„æ¨¡æ€ç¼ºå¤±é—®é¢˜**

**å…³é”®è¯**: `é¥æ„Ÿå¤šæ¨¡æ€åˆ†ç±»` `æ¨¡æ€ç¼ºå¤±å¤„ç†` `æ··åˆä¸“å®¶æ¨¡åž‹` `å‚æ•°é«˜æ•ˆé€‚åº”` `åŒè·¯ç”±æœºåˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé¥æ„Ÿå¤šæ¨¡æ€åˆ†ç±»å› çŽ¯å¢ƒå¹²æ‰°æˆ–ä¼ æ„Ÿå™¨æ•…éšœå¯¼è‡´æ¨¡æ€ç¼ºå¤±ï¼Œæ€§èƒ½ä¸‹é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥åŒè·¯ç”±æœºåˆ¶ï¼ŒåŠ¨æ€æ¿€æ´»ä¸“å®¶å¤„ç†ç¼ºå¤±æ¨¡å¼ï¼Œé™æ€å…±äº«è·¨æ¨¡æ€çŸ¥è¯†ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å±•çŽ°å¼ºé²æ£’æ€§å’Œæ³›åŒ–æ€§ï¼Œè®¡ç®—å¼€é”€ä½Žã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal classification in remote sensing often suffers from missing modalities caused by environmental interference, sensor failures, or atmospheric effects, which severely degrade classification performance. Existing two-stage adaptation methods are computationally expensive and assume complete multimodal data during training, limiting their generalization to real-world incompleteness. To overcome these issues, we propose a Missing-aware Mixture-of-Loras (MaMOL) framework that reformulates modality missing as a multi-task learning problem. MaMOL introduces a dual-routing mechanism: a task-oriented dynamic router that adaptively activates experts for different missing patterns, and a modality-specific-shared static router that maintains stable cross-modal knowledge sharing. Unlike prior methods that train separate networks for each missing configuration, MaMOL achieves parameter-efficient adaptation via lightweight expert updates and shared expert reuse. Experiments on multiple remote sensing benchmarks demonstrate superior robustness and generalization under varying missing rates, with minimal computational overhead. Moreover, transfer experiments on natural image datasets validate its scalability and cross-domain applicability, highlighting MaMOL as a general and efficient solution for incomplete multimodal learning.

