---
layout: default
title: 3D Gaussian and Diffusion-Based Gaze Redirection
---

# 3D Gaussian and Diffusion-Based Gaze Redirection

**arXiv**: [2511.11231v1](https://arxiv.org/abs/2511.11231) | [PDF](https://arxiv.org/pdf/2511.11231.pdf)

**ä½œè€…**: Abiram Panchalingam, Indu Bodala, Stuart Middleton

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDiT-Gazeæ¡†æž¶ä»¥å¢žå¼º3Dè§†çº¿é‡å®šå‘çš„ä¿çœŸåº¦å’Œå‡†ç¡®æ€§**

**å…³é”®è¯**: `è§†çº¿é‡å®šå‘` `æ‰©æ•£å˜æ¢å™¨` `3Dé«˜æ–¯æº…å°„` `å¼±ç›‘ç£å­¦ä¹ ` `æ­£äº¤çº¦æŸæŸå¤±` `åˆæˆæ•°æ®ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰3Dé«˜æ–¯æº…å°„æ¨¡åž‹åœ¨æ¸²æŸ“ç»†å¾®è¿žç»­è§†çº¿è½¬ç§»æ—¶å­˜åœ¨å›°éš¾
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆæ‰©æ•£å˜æ¢å™¨ã€å¼±ç›‘ç£ç­–ç•¥å’Œæ­£äº¤çº¦æŸæŸå¤±æå‡åˆæˆè´¨é‡
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ„ŸçŸ¥è´¨é‡å’Œé‡å®šå‘ç²¾åº¦ä¸Šè¾¾åˆ°æ–°SOTAï¼Œè¯¯å·®é™ä½Žè‡³6.353åº¦

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> High-fidelity gaze redirection is critical for generating augmented data to improve the generalization of gaze estimators. 3D Gaussian Splatting (3DGS) models like GazeGaussian represent the state-of-the-art but can struggle with rendering subtle, continuous gaze shifts. In this paper, we propose DiT-Gaze, a framework that enhances 3D gaze redirection models using a novel combination of Diffusion Transformer (DiT), weak supervision across gaze angles, and an orthogonality constraint loss. DiT allows higher-fidelity image synthesis, while our weak supervision strategy using synthetically generated intermediate gaze angles provides a smooth manifold of gaze directions during training. The orthogonality constraint loss mathematically enforces the disentanglement of internal representations for gaze, head pose, and expression. Comprehensive experiments show that DiT-Gaze sets a new state-of-the-art in both perceptual quality and redirection accuracy, reducing the state-of-the-art gaze error by 4.1% to 6.353 degrees, providing a superior method for creating synthetic training data. Our code and models will be made available for the research community to benchmark against.

