---
layout: default
title: Scalable Policy Evaluation with Video World Models
---

# Scalable Policy Evaluation with Video World Models

**arXiv**: [2511.11520v1](https://arxiv.org/abs/2511.11520) | [PDF](https://arxiv.org/pdf/2511.11520.pdf)

**ä½œè€…**: Wei-Cheng Tseng, Jinwei Gu, Qinsheng Zhang, Hanzi Mao, Ming-Yu Liu, Florian Shkurti, Lin Yen-Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽåŠ¨ä½œæ¡ä»¶è§†é¢‘ç”Ÿæˆæ¨¡åž‹çš„å¯æ‰©å±•ç­–ç•¥è¯„ä¼°æ–¹æ³•ï¼Œä»¥è§£å†³æœºå™¨äººç­–ç•¥çœŸå®žæµ‹è¯•æˆæœ¬é«˜çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `ç­–ç•¥è¯„ä¼°` `è§†é¢‘ç”Ÿæˆæ¨¡åž‹` `åŠ¨ä½œæ¡ä»¶å»ºæ¨¡` `æœºå™¨äººæ“ä½œ` `æ¨¡æ‹Ÿåˆ°çŽ°å®žå·®è·` `å¯æ‰©å±•å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨äººç­–ç•¥çœŸå®žè¯„ä¼°æˆæœ¬é«˜ã€é£Žé™©å¤§ï¼Œä»¿çœŸçŽ¯å¢ƒæž„å»ºå›°éš¾ä¸”å­˜åœ¨æ¨¡æ‹Ÿåˆ°çŽ°å®žçš„å·®è·ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†åŠ¨ä½œæ¡ä»¶èžå…¥é¢„è®­ç»ƒè§†é¢‘ç”Ÿæˆæ¨¡åž‹ï¼Œåˆ©ç”¨äº’è”ç½‘è§†é¢‘æ•°æ®å‡å°‘é…å¯¹æ•°æ®éœ€æ±‚ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ç­–ç•¥æŽ’åºå’Œé¢„æµ‹å€¼ä¸Žå®žé™…å€¼ç›¸å…³æ€§ç­‰æŒ‡æ ‡ä¸Šï¼Œæ¨¡åž‹æ˜¾ç¤ºå‡ºæ— éœ€çœŸå®žäº¤äº’çš„è¯„ä¼°æ½œåŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Training generalist policies for robotic manipulation has shown great promise, as they enable language-conditioned, multi-task behaviors across diverse scenarios. However, evaluating these policies remains difficult because real-world testing is expensive, time-consuming, and labor-intensive. It also requires frequent environment resets and carries safety risks when deploying unproven policies on physical robots. Manually creating and populating simulation environments with assets for robotic manipulation has not addressed these issues, primarily due to the significant engineering effort required and the often substantial sim-to-real gap, both in terms of physics and rendering. In this paper, we explore the use of action-conditional video generation models as a scalable way to learn world models for policy evaluation. We demonstrate how to incorporate action conditioning into existing pre-trained video generation models. This allows leveraging internet-scale in-the-wild online videos during the pre-training stage, and alleviates the need for a large dataset of paired video-action data, which is expensive to collect for robotic manipulation. Our paper examines the effect of dataset diversity, pre-trained weight and common failure cases for the proposed evaluation pipeline.Our experiments demonstrate that, across various metrics, including policy ranking and the correlation between actual policy values and predicted policy values, these models offer a promising approach for evaluating policies without requiring real-world interactions.

