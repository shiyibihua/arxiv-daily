---
layout: default
title: Arcee: Differentiable Recurrent State Chain for Generative Vision Modeling with Mamba SSMs
---

# Arcee: Differentiable Recurrent State Chain for Generative Vision Modeling with Mamba SSMs

**arXiv**: [2511.11243v1](https://arxiv.org/abs/2511.11243) | [PDF](https://arxiv.org/pdf/2511.11243.pdf)

**ä½œè€…**: Jitesh Chavan, Rohit Lal, Anand Kamat, Mengjia Xu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºArceeè·¨å—å¾ªçŽ¯çŠ¶æ€é“¾ï¼Œä»¥æ”¹è¿›è§†è§‰ç”Ÿæˆå»ºæ¨¡ä¸­çš„çŠ¶æ€ç©ºé—´æ¨¡åž‹**

**å…³é”®è¯**: `çŠ¶æ€ç©ºé—´æ¨¡åž‹` `è§†è§‰ç”Ÿæˆ` `å¯å¾®åˆ†è¾¹ç•Œ` `Mambaæ¨¡åž‹` `å¾ªçŽ¯çŠ¶æ€é“¾`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šMambaæ¨¡åž‹åœ¨å—é—´é‡ç½®çŠ¶æ€ï¼Œä¸¢å¼ƒå‰ä¸€å—çš„ç»ˆç«¯çŠ¶æ€ç©ºé—´è¡¨ç¤º
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å¯å¾®åˆ†è¾¹ç•Œæ˜ å°„ï¼Œé‡ç”¨ç»ˆç«¯çŠ¶æ€ä½œä¸ºä¸‹ä¸€å—åˆå§‹æ¡ä»¶
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CelebA-HQæ— æ¡ä»¶ç”Ÿæˆä¸­ï¼ŒFIDä»Ž82.81é™è‡³15.33

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> State-space models (SSMs), Mamba in particular, are increasingly adopted for long-context sequence modeling, providing linear-time aggregation via an input-dependent, causal selective-scan operation. Along this line, recent "Mamba-for-vision" variants largely explore multiple scan orders to relax strict causality for non-sequential signals (e.g., images). Rather than preserving cross-block memory, the conventional formulation of the selective-scan operation in Mamba reinitializes each block's state-space dynamics from zero, discarding the terminal state-space representation (SSR) from the previous block. Arcee, a cross-block recurrent state chain, reuses each block's terminal state-space representation as the initial condition for the next block. Handoff across blocks is constructed as a differentiable boundary map whose Jacobian enables end-to-end gradient flow across terminal boundaries. Key to practicality, Arcee is compatible with all prior "vision-mamba" variants, parameter-free, and incurs constant, negligible cost. As a modeling perspective, we view terminal SSR as a mild directional prior induced by a causal pass over the input, rather than an estimator of the non-sequential signal itself. To quantify the impact, for unconditional generation on CelebA-HQ (256$\times$256) with Flow Matching, Arcee reduces FID$\downarrow$ from $82.81$ to $15.33$ ($5.4\times$ lower) on a single scan-order Zigzag Mamba baseline. Efficient CUDA kernels and training code will be released to support rigorous and reproducible research.

