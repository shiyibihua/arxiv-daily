---
layout: default
title: Boosting Neural Video Representation via Online Structural Reparameterization
---

# Boosting Neural Video Representation via Online Structural Reparameterization

**arXiv**: [2511.11071v1](https://arxiv.org/abs/2511.11071) | [PDF](https://arxiv.org/pdf/2511.11071.pdf)

**ä½œè€…**: Ziyi Li, Qingyu Mao, Shuai Liu, Qilei Li, Fanyang Meng, Yongsheng Liang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåœ¨çº¿ç»“æž„é‡å‚æ•°åŒ–æ¡†æž¶ä»¥å¢žå¼ºç¥žç»è§†é¢‘è¡¨ç¤ºèƒ½åŠ›**

**å…³é”®è¯**: `ç¥žç»è§†é¢‘è¡¨ç¤º` `åœ¨çº¿é‡å‚æ•°åŒ–` `è§†é¢‘åŽ‹ç¼©` `æ¨¡åž‹å®¹é‡å¢žå¼º` `è®¡ç®—æ•ˆçŽ‡ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç¥žç»è§†é¢‘è¡¨ç¤ºæ¨¡åž‹å®¹é‡æœ‰é™ï¼Œå¯¼è‡´æ€§èƒ½ç“¶é¢ˆå’Œè®¡ç®—å¼€é”€å¤§
2. å¼•å…¥å¤šåˆ†æ”¯å·ç§¯å—å’Œåœ¨çº¿é‡å‚æ•°åŒ–ï¼ŒåŠ¨æ€èžåˆå‚æ•°æå‡æ¨¡åž‹èƒ½åŠ›
3. å®žéªŒæ˜¾ç¤ºPSNRå¹³å‡æå‡0.37-2.7 dBï¼Œä¿æŒè®­ç»ƒå’ŒæŽ¨ç†æ•ˆçŽ‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Neural Video Representation~(NVR) is a promising paradigm for video compression, showing great potential in improving video storage and transmission efficiency. While recent advances have made efforts in architectural refinements to improve representational capability, these methods typically involve complex designs, which may incur increased computational overhead and lack the flexibility to integrate into other frameworks. Moreover, the inherent limitation in model capacity restricts the expressiveness of NVR networks, resulting in a performance bottleneck. To overcome these limitations, we propose Online-RepNeRV, a NVR framework based on online structural reparameterization. Specifically, we propose a universal reparameterization block named ERB, which incorporates multiple parallel convolutional paths to enhance the model capacity. To mitigate the overhead, an online reparameterization strategy is adopted to dynamically fuse the parameters during training, and the multi-branch structure is equivalently converted into a single-branch structure after training. As a result, the additional computational and parameter complexity is confined to the encoding stage, without affecting the decoding efficiency. Extensive experiments on mainstream video datasets demonstrate that our method achieves an average PSNR gain of 0.37-2.7 dB over baseline methods, while maintaining comparable training time and decoding speed.

