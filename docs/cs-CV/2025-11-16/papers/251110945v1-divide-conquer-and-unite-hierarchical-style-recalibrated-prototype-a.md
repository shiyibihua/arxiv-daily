---
layout: default
title: Divide, Conquer and Unite: Hierarchical Style-Recalibrated Prototype Alignment for Federated Medical Image Segmentation
---

# Divide, Conquer and Unite: Hierarchical Style-Recalibrated Prototype Alignment for Federated Medical Image Segmentation

**arXiv**: [2511.10945v1](https://arxiv.org/abs/2511.10945) | [PDF](https://arxiv.org/pdf/2511.10945.pdf)

**ä½œè€…**: Xingyue Zhao, Wenke Huang, Xingguang Wang, Haoyu Zhao, Linghao Zhuang, Anwen Jiang, Guancheng Wan, Mang Ye

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFedBCSä»¥è§£å†³è”é‚¦åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„ç‰¹å¾å¼‚æž„æ€§é—®é¢˜**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `åŒ»å­¦å›¾åƒåˆ†å‰²` `åŽŸåž‹å¯¹é½` `é£Žæ ¼é‡æ ¡å‡†` `ç‰¹å¾å¼‚æž„æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè”é‚¦å­¦ä¹ ä¸­ç‰¹å¾å¼‚æž„æ€§å¯¼è‡´åˆ†å‰²æ€§èƒ½ä¸‹é™ï¼ŒçŽ°æœ‰æ–¹æ³•å¿½ç•¥å¤šå±‚çº§ä¸Šä¸‹æ–‡å’Œé£Žæ ¼åå·®ç´¯ç§¯ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥é¢‘çŽ‡åŸŸè‡ªé€‚åº”é£Žæ ¼é‡æ ¡å‡†å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥åŒå±‚çº§åŽŸåž‹å¯¹é½ï¼Œæž„å»ºåŸŸä¸å˜åŽŸåž‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å…¬å¼€æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæ–¹æ³•è¡¨çŽ°å‡ºæ˜¾è‘—æ€§èƒ½æå‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Federated learning enables multiple medical institutions to train a global model without sharing data, yet feature heterogeneity from diverse scanners or protocols remains a major challenge. Many existing works attempt to address this issue by leveraging model representations (e.g., mean feature vectors) to correct local training; however, they often face two key limitations: 1) Incomplete Contextual Representation Learning: Current approaches primarily focus on final-layer features, overlooking critical multi-level cues and thus diluting essential context for accurate segmentation. 2) Layerwise Style Bias Accumulation: Although utilizing representations can partially align global features, these methods neglect domain-specific biases within intermediate layers, allowing style discrepancies to build up and reduce model robustness. To address these challenges, we propose FedBCS to bridge feature representation gaps via domain-invariant contextual prototypes alignment. Specifically, we introduce a frequency-domain adaptive style recalibration into prototype construction that not only decouples content-style representations but also learns optimal style parameters, enabling more robust domain-invariant prototypes. Furthermore, we design a context-aware dual-level prototype alignment method that extracts domain-invariant prototypes from different layers of both encoder and decoder and fuses them with contextual information for finer-grained representation alignment. Extensive experiments on two public datasets demonstrate that our method exhibits remarkable performance.

