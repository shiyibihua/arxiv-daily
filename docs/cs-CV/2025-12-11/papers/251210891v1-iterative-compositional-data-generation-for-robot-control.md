---
layout: default
title: Iterative Compositional Data Generation for Robot Control
---

# Iterative Compositional Data Generation for Robot Control

**arXiv**: [2512.10891v1](https://arxiv.org/abs/2512.10891) | [PDF](https://arxiv.org/pdf/2512.10891.pdf)

**ä½œè€…**: Anh-Quan Pham, Marcel Hussing, Shubhankar P. Patankar, Dani S. Bassett, Jorge Mendez-Mendez, Eric Eaton

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­ä¹‰ç»„åˆæ‰©æ•£å˜æ¢å™¨ï¼Œé€šè¿‡è¿­ä»£è‡ªæ”¹è¿›è§£å†³æœºå™¨äººæŽ§åˆ¶ä¸­æœªè§ä»»åŠ¡ç»„åˆçš„æ•°æ®ç”Ÿæˆé—®é¢˜ã€‚**

**å…³é”®è¯**: `æœºå™¨äººæŽ§åˆ¶` `æ•°æ®ç”Ÿæˆ` `æ‰©æ•£æ¨¡åž‹` `ç»„åˆå­¦ä¹ ` `é›¶æ ·æœ¬æ³›åŒ–` `ç¦»çº¿å¼ºåŒ–å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨äººæ“ä½œæ•°æ®æ”¶é›†æ˜‚è´µï¼ŒçŽ°æœ‰ç”Ÿæˆæ¨¡åž‹éš¾ä»¥æ³›åŒ–åˆ°æœªè§ä»»åŠ¡ç»„åˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡å› å­åŒ–è¿‡æ¸¡çš„æ‰©æ•£å˜æ¢å™¨ï¼Œå­¦ä¹ ç»„ä»¶äº¤äº’ï¼Œå¹¶å¼•å…¥è¿­ä»£è‡ªæ”¹è¿›è¿‡ç¨‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æœªè§ä»»åŠ¡ä¸Šå®žçŽ°é›¶æ ·æœ¬é«˜è´¨é‡æ•°æ®ç”Ÿæˆï¼Œæ˜¾è‘—æå‡æ€§èƒ½ï¼Œè§£å†³å¤§éƒ¨åˆ†ä»»åŠ¡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Collecting robotic manipulation data is expensive, making it impractical to acquire demonstrations for the combinatorially large space of tasks that arise in multi-object, multi-robot, and multi-environment settings. While recent generative models can synthesize useful data for individual tasks, they do not exploit the compositional structure of robotic domains and struggle to generalize to unseen task combinations. We propose a semantic compositional diffusion transformer that factorizes transitions into robot-, object-, obstacle-, and objective-specific components and learns their interactions through attention. Once trained on a limited subset of tasks, we show that our model can zero-shot generate high-quality transitions from which we can learn control policies for unseen task combinations. Then, we introduce an iterative self-improvement procedure in which synthetic data is validated via offline reinforcement learning and incorporated into subsequent training rounds. Our approach substantially improves zero-shot performance over monolithic and hard-coded compositional baselines, ultimately solving nearly all held-out tasks and demonstrating the emergence of meaningful compositional structure in the learned representations.

