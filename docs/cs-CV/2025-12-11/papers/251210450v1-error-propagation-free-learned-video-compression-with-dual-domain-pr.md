---
layout: default
title: Error-Propagation-Free Learned Video Compression With Dual-Domain Progressive Temporal Alignment
---

# Error-Propagation-Free Learned Video Compression With Dual-Domain Progressive Temporal Alignment

**arXiv**: [2512.10450v1](https://arxiv.org/abs/2512.10450) | [PDF](https://arxiv.org/pdf/2512.10450.pdf)

**ä½œè€…**: Han Li, Shaohui Li, Wenrui Dai, Chenglin Li, Xinlong Pan, Haipeng Wang, Junni Zou, Hongkai Xiong

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒåŸŸæ¸è¿›æ—¶åŸŸå¯¹é½ä¸Žè´¨é‡æ¡ä»¶ä¸“å®¶æ··åˆçš„ç»Ÿä¸€å˜æ¢æ¡†æž¶ï¼Œä»¥æ¶ˆé™¤å­¦ä¹ è§†é¢‘åŽ‹ç¼©ä¸­çš„è¯¯å·®ä¼ æ’­ã€‚**

**å…³é”®è¯**: `å­¦ä¹ è§†é¢‘åŽ‹ç¼©` `è¯¯å·®ä¼ æ’­æ¶ˆé™¤` `åŒåŸŸæ—¶åŸŸå¯¹é½` `è´¨é‡æ¡ä»¶ä¸“å®¶æ··åˆ` `è¿åŠ¨ä¼°è®¡ä¸Žè¡¥å¿`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å­¦ä¹ è§†é¢‘åŽ‹ç¼©æ¡†æž¶åœ¨è¿åŠ¨ä¼°è®¡ä¸Žè¡¥å¿ä¸­å­˜åœ¨æ—¶åŸŸå¯¹é½ä¸å‡†ç¡®ä¸Žè¯¯å·®ä¼ æ’­çš„å›°å¢ƒã€‚
2. æå‡ºåŒåŸŸæ¸è¿›æ—¶åŸŸå¯¹é½ï¼Œç»“åˆç²—åƒç´ åŸŸå¯¹é½å’Œç²¾ç‚¼æ½œåœ¨åŸŸå¯¹é½ï¼Œå¢žå¼ºæ—¶åŸŸä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒç«žäº‰æ€§çŽ‡å¤±çœŸæ€§èƒ½çš„åŒæ—¶ï¼ŒæˆåŠŸæ¶ˆé™¤äº†è¯¯å·®ä¼ æ’­ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Existing frameworks for learned video compression suffer from a dilemma between inaccurate temporal alignment and error propagation for motion estimation and compensation (ME/MC). The separate-transform framework employs distinct transforms for intra-frame and inter-frame compression to yield impressive rate-distortion (R-D) performance but causes evident error propagation, while the unified-transform framework eliminates error propagation via shared transforms but is inferior in ME/MC in shared latent domains. To address this limitation, in this paper, we propose a novel unifiedtransform framework with dual-domain progressive temporal alignment and quality-conditioned mixture-of-expert (QCMoE) to enable quality-consistent and error-propagation-free streaming for learned video compression. Specifically, we propose dualdomain progressive temporal alignment for ME/MC that leverages coarse pixel-domain alignment and refined latent-domain alignment to significantly enhance temporal context modeling in a coarse-to-fine fashion. The coarse pixel-domain alignment efficiently handles simple motion patterns with optical flow estimated from a single reference frame, while the refined latent-domain alignment develops a Flow-Guided Deformable Transformer (FGDT) over latents from multiple reference frames to achieve long-term motion refinement (LTMR) for complex motion patterns. Furthermore, we design a QCMoE module for continuous bit-rate adaptation that dynamically assigns different experts to adjust quantization steps per pixel based on target quality and content rather than relies on a single quantization step. QCMoE allows continuous and consistent rate control with appealing R-D performance. Experimental results show that the proposed method achieves competitive R-D performance compared with the state-of-the-arts, while successfully eliminating error propagation.

