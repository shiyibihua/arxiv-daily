---
layout: default
title: DOCR-Inspector: Fine-Grained and Automated Evaluation of Document Parsing with VLM
---

# DOCR-Inspector: Fine-Grained and Automated Evaluation of Document Parsing with VLM

**arXiv**: [2512.10619v1](https://arxiv.org/abs/2512.10619) | [PDF](https://arxiv.org/pdf/2512.10619.pdf)

**ä½œè€…**: Qintong Zhang, Junyuan Zhang, Zhifei Ren, Linke Ouyang, Zichen Wen, Junbo Niu, Yuan Qu, Bin Wang, Ka-Ho Chow, Conghui He, Wentao Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDOCR-Inspectorï¼Œé€šè¿‡ç»†ç²’åº¦é”™è¯¯æ£€æµ‹ä¸ŽVLMè¯„ä¼°è§£å†³æ–‡æ¡£è§£æžè´¨é‡è¯„ä¼°éš¾é¢˜ã€‚**

**å…³é”®è¯**: `æ–‡æ¡£è§£æžè¯„ä¼°` `è§†è§‰è¯­è¨€æ¨¡åž‹` `ç»†ç²’åº¦é”™è¯¯æ£€æµ‹` `è´¨é‡è¯„ä¼°åŸºå‡†` `è‡ªåŠ¨åŒ–è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ ‡å‡†åŸºå‡†å­˜åœ¨åå·®ï¼Œæ•´ä½“è¯„åˆ†æŽ©ç›–é”™è¯¯æ¨¡å¼ï¼Œéš¾ä»¥å¯é è¯„ä¼°çœŸå®žåœºæ™¯æ–‡æ¡£è§£æžè´¨é‡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽVLM-as-a-Judgeï¼Œå®šä¹‰28ç§é”™è¯¯ç±»åž‹ï¼Œé‡‡ç”¨Chain-of-ChecklistæŽ¨ç†è¿›è¡Œåˆ†å±‚è´¨é‡è¯„ä¼°ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨DOCRcaseBenchä¸Šè¶…è¶Šå•†ä¸šå’Œå¼€æºæ¨¡åž‹ï¼Œè¯„ä¼°ç»“æžœå¯æŒ‡å¯¼è§£æžç»“æžœä¼˜åŒ–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Document parsing aims to transform unstructured PDF images into semi-structured data, facilitating the digitization and utilization of information in diverse domains. While vision language models (VLMs) have significantly advanced this task, achieving reliable, high-quality parsing in real-world scenarios remains challenging. Common practice often selects the top-performing model on standard benchmarks. However, these benchmarks may carry dataset-specific biases, leading to inconsistent model rankings and limited correlation with real-world performance. Moreover, benchmark metrics typically provide only overall scores, which can obscure distinct error patterns in output. This raises a key challenge: how can we reliably and comprehensively assess document parsing quality in the wild? We address this problem with DOCR-Inspector, which formalizes document parsing assessment as fine-grained error detection and analysis. Leveraging VLM-as-a-Judge, DOCR-Inspector analyzes a document image and its parsed output, identifies all errors, assigns them to one of 28 predefined types, and produces a comprehensive quality assessment. To enable this capability, we construct DOCRcase-200K for training and propose the Chain-of-Checklist reasoning paradigm to enable the hierarchical structure of parsing quality assessment. For empirical validation, we introduce DOCRcaseBench, a set of 882 real-world document parsing cases with manual annotations. On this benchmark, DOCR-Inspector-7B outperforms commercial models like Gemini 2.5 Pro, as well as leading open-source models. Further experiments demonstrate that its quality assessments provide valuable guidance for parsing results refinement, making DOCR-Inspector both a practical evaluator and a driver for advancing document parsing systems at scale. Model and code are released at: https://github.com/ZZZZZQT/DOCR-Inspector.

