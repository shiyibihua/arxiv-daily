---
layout: default
title: Metacognitive Sensitivity for Test-Time Dynamic Model Selection
---

# Metacognitive Sensitivity for Test-Time Dynamic Model Selection

**arXiv**: [2512.10451v1](https://arxiv.org/abs/2512.10451) | [PDF](https://arxiv.org/pdf/2512.10451.pdf)

**ä½œè€…**: Le Tuan Minh Trinh, Le Minh Vu Pham, Thi Minh Anh Pham, An Duc Nguyen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå…ƒè®¤çŸ¥æ•æ„Ÿæ€§çš„æµ‹è¯•æ—¶åŠ¨æ€æ¨¡åž‹é€‰æ‹©æ¡†æž¶ï¼Œä»¥æå‡é›†æˆæŽ¨ç†å‡†ç¡®æ€§ã€‚**

**å…³é”®è¯**: `å…ƒè®¤çŸ¥æ•æ„Ÿæ€§` `æµ‹è¯•æ—¶æ¨¡åž‹é€‰æ‹©` `ç½®ä¿¡åº¦æ ¡å‡†` `å¤šè‡‚è€è™Žæœº` `é›†æˆå­¦ä¹ ` `æ·±åº¦å­¦ä¹ è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ·±åº¦å­¦ä¹ æ¨¡åž‹ç½®ä¿¡åº¦æ ¡å‡†ä¸ä½³ï¼Œæ— æ³•å¯é åæ˜ è‡ªèº«å‡†ç¡®æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥å¿ƒç†å­¦æŒ‡æ ‡meta-d'è¯„ä¼°å…ƒè®¤çŸ¥æ•æ„Ÿæ€§ï¼Œå¹¶ç”¨äºŽåŸºäºŽå¤šè‡‚è€è™Žæœºçš„åŠ¨æ€æ¨¡åž‹é€‰æ‹©ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†å’Œæ¨¡åž‹ç»„åˆä¸ŠéªŒè¯ï¼Œè¯¥æ–¹æ³•ä¼˜äºŽåŸºç¡€æ¨¡åž‹ï¼Œæå‡è”åˆæŽ¨ç†å‡†ç¡®æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> A key aspect of human cognition is metacognition - the ability to assess one's own knowledge and judgment reliability. While deep learning models can express confidence in their predictions, they often suffer from poor calibration, a cognitive bias where expressed confidence does not reflect true competence. Do models truly know what they know? Drawing from human cognitive science, we propose a new framework for evaluating and leveraging AI metacognition. We introduce meta-d', a psychologically-grounded measure of metacognitive sensitivity, to characterise how reliably a model's confidence predicts its own accuracy. We then use this dynamic sensitivity score as context for a bandit-based arbiter that performs test-time model selection, learning which of several expert models to trust for a given task. Our experiments across multiple datasets and deep learning model combinations (including CNNs and VLMs) demonstrate that this metacognitive approach improves joint-inference accuracy over constituent models. This work provides a novel behavioural account of AI models, recasting ensemble selection as a problem of evaluating both short-term signals (confidence prediction scores) and medium-term traits (metacognitive sensitivity).

