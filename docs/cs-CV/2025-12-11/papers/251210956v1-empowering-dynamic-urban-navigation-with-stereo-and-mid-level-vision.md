---
layout: default
title: Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision
---

# Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.10956" target="_blank" class="toolbar-btn">arXiv: 2512.10956v1</a>
    <a href="https://arxiv.org/pdf/2512.10956.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10956v1" 
            onclick="toggleFavorite(this, '2512.10956v1', 'Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Wentao Zhou, Xuweiyi Chen, Vignesh Rajagopal, Jeffrey Chen, Rohan Chandra, Zezhou Cheng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

**å¤‡æ³¨**: Project Page: https://www.cs.virginia.edu/~tsx4zn/stereowalk/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**StereoWalkerï¼šèåˆåŒç›®è§†è§‰ä¸ä¸­å±‚è§†è§‰å¢å¼ºåŠ¨æ€åŸå¸‚å¯¼èˆª**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `åŒç›®è§†è§‰` `æœºå™¨äººå¯¼èˆª` `ä¸­å±‚è§†è§‰` `æ·±åº¦ä¼°è®¡` `åŠ¨æ€ç¯å¢ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç«¯åˆ°ç«¯æœºå™¨äººå¯¼èˆªæ¨¡å‹ä¾èµ–å•ç›®è§†è§‰ï¼Œå¿½ç•¥ä¸­å±‚è§†è§‰ä¿¡æ¯ï¼Œå¯¼è‡´åœ¨åŠ¨æ€ç¯å¢ƒä¸­å‡ ä½•ç†è§£ä¸è¶³ã€‚
2. StereoWalkeråˆ©ç”¨åŒç›®è§†è§‰è§£å†³æ·±åº¦å°ºåº¦æ¨¡ç³Šï¼Œå¹¶ç»“åˆæ·±åº¦ä¼°è®¡å’Œåƒç´ è·Ÿè¸ªç­‰ä¸­å±‚è§†è§‰æ¨¡å—å¢å¼ºå‡ ä½•å’Œè¿åŠ¨ç†è§£ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒStereoWalkerä»…ç”¨å°‘é‡æ•°æ®å³å¯è¾¾åˆ°ç”šè‡³è¶…è¶Šç°æœ‰å•ç›®æ–¹æ³•çš„æ€§èƒ½ï¼ŒéªŒè¯äº†ä¸­å±‚è§†è§‰çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯­è¨€å’Œè§†è§‰é¢†åŸŸçš„åŸºç¡€æ¨¡å‹çš„æˆåŠŸæ¿€å‘äº†å¯¹å®Œå…¨ç«¯åˆ°ç«¯æœºå™¨äººå¯¼èˆªåŸºç¡€æ¨¡å‹ï¼ˆNFMsï¼‰çš„ç ”ç©¶ã€‚NFMsç›´æ¥å°†å•ç›®è§†è§‰è¾“å…¥æ˜ å°„åˆ°æ§åˆ¶åŠ¨ä½œï¼Œå®Œå…¨å¿½ç•¥äº†ä¸­å±‚è§†è§‰æ¨¡å—ï¼ˆè·Ÿè¸ªã€æ·±åº¦ä¼°è®¡ç­‰ï¼‰ã€‚è™½ç„¶è§†è§‰èƒ½åŠ›å°†éšå¼å‡ºç°çš„å‡è®¾å¼•äººæ³¨ç›®ï¼Œä½†å®ƒéœ€è¦å¤§é‡çš„åƒç´ åˆ°åŠ¨ä½œçš„ç›‘ç£ï¼Œè€Œè¿™äº›ç›‘ç£å¾ˆéš¾è·å¾—ã€‚åœ¨åŠ¨æ€å’Œéç»“æ„åŒ–ç¯å¢ƒä¸­ï¼ŒæŒ‘æˆ˜å°¤å…¶æ˜æ˜¾ï¼Œå› ä¸ºç¨³å¥çš„å¯¼èˆªéœ€è¦ç²¾ç¡®çš„å‡ ä½•å’ŒåŠ¨æ€ç†è§£ï¼Œè€Œå•ç›®è§†å›¾ä¸­çš„æ·±åº¦å°ºåº¦æ¨¡ç³Šè¿›ä¸€æ­¥é™åˆ¶äº†ç²¾ç¡®çš„ç©ºé—´æ¨ç†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜ï¼Œä¾èµ–å•ç›®è§†è§‰å¹¶å¿½ç•¥ä¸­å±‚è§†è§‰å…ˆéªŒæ˜¯ä½æ•ˆçš„ã€‚æˆ‘ä»¬æå‡ºäº†StereoWalkerï¼Œå®ƒä½¿ç”¨åŒç›®è¾“å…¥å’Œæ˜¾å¼ä¸­å±‚è§†è§‰ï¼ˆå¦‚æ·±åº¦ä¼°è®¡å’Œå¯†é›†åƒç´ è·Ÿè¸ªï¼‰æ¥å¢å¼ºNFMsã€‚æˆ‘ä»¬çš„ç›´è§‰å¾ˆç®€å•ï¼šåŒç›®è¾“å…¥è§£å†³äº†æ·±åº¦å°ºåº¦æ¨¡ç³Šï¼Œè€Œç°ä»£ä¸­å±‚è§†è§‰æ¨¡å‹æä¾›äº†åŠ¨æ€åœºæ™¯ä¸­å¯é çš„å‡ ä½•å’Œè¿åŠ¨ç»“æ„ã€‚æˆ‘ä»¬è¿˜ç­–åˆ’äº†ä¸€ä¸ªå¤§å‹åŒç›®å¯¼èˆªæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«æ¥è‡ªäº’è”ç½‘åŒç›®è§†é¢‘çš„è‡ªåŠ¨åŠ¨ä½œæ³¨é‡Šï¼Œä»¥æ”¯æŒStereoWalkerçš„è®­ç»ƒå¹¶ä¿ƒè¿›æœªæ¥çš„ç ”ç©¶ã€‚é€šè¿‡æˆ‘ä»¬çš„å®éªŒï¼Œæˆ‘ä»¬å‘ç°ä¸­å±‚è§†è§‰ä½¿StereoWalkerèƒ½å¤Ÿä»¥ä»…1.5%çš„è®­ç»ƒæ•°æ®è¾¾åˆ°ä¸æœ€å…ˆè¿›æŠ€æœ¯ç›¸å½“çš„æ€§èƒ½ï¼Œå¹¶ä½¿ç”¨å®Œæ•´æ•°æ®è¶…è¶Šæœ€å…ˆè¿›æŠ€æœ¯ã€‚æˆ‘ä»¬è¿˜è§‚å¯Ÿåˆ°ï¼ŒåŒç›®è§†è§‰æ¯”å•ç›®è¾“å…¥äº§ç”Ÿæ›´é«˜çš„å¯¼èˆªæ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºå•ç›®è§†è§‰çš„ç«¯åˆ°ç«¯å¯¼èˆªæ¨¡å‹åœ¨åŠ¨æ€åŸå¸‚ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ï¼Œä¸»è¦åŸå› æ˜¯å•ç›®è§†è§‰å­˜åœ¨æ·±åº¦å°ºåº¦æ¨¡ç³Šï¼Œéš¾ä»¥å‡†ç¡®ç†è§£åœºæ™¯çš„å‡ ä½•ç»“æ„å’Œè¿åŠ¨ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œå®Œå…¨ä¾èµ–ç«¯åˆ°ç«¯å­¦ä¹ éœ€è¦å¤§é‡åƒç´ çº§åˆ«çš„åŠ¨ä½œæ ‡æ³¨æ•°æ®ï¼Œè·å–æˆæœ¬é«˜æ˜‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åŒç›®è§†è§‰æä¾›å‡†ç¡®çš„æ·±åº¦ä¿¡æ¯ï¼Œå¹¶ç»“åˆä¸­å±‚è§†è§‰æ¨¡å—ï¼ˆå¦‚æ·±åº¦ä¼°è®¡å’Œå¯†é›†åƒç´ è·Ÿè¸ªï¼‰æ¥æ˜¾å¼åœ°æå–åœºæ™¯çš„å‡ ä½•å’Œè¿åŠ¨ç»“æ„ã€‚é€šè¿‡èåˆè¿™äº›ä¿¡æ¯ï¼Œæ¨¡å‹å¯ä»¥æ›´æœ‰æ•ˆåœ°è¿›è¡Œç©ºé—´æ¨ç†å’Œå¯¼èˆªå†³ç­–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šStereoWalkerçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) åŒç›®è§†è§‰è¾“å…¥ï¼šä½¿ç”¨åŒç›®ç›¸æœºè·å–å·¦å³å›¾åƒï¼›2) æ·±åº¦ä¼°è®¡ï¼šåˆ©ç”¨åŒç›®å›¾åƒä¼°è®¡åœºæ™¯çš„æ·±åº¦å›¾ï¼›3) å¯†é›†åƒç´ è·Ÿè¸ªï¼šè·Ÿè¸ªå›¾åƒä¸­åƒç´ çš„è¿åŠ¨è½¨è¿¹ï¼Œæå–è¿åŠ¨ä¿¡æ¯ï¼›4) å¯¼èˆªç­–ç•¥å­¦ä¹ ï¼šå°†åŒç›®å›¾åƒã€æ·±åº¦å›¾å’Œè¿åŠ¨ä¿¡æ¯ä½œä¸ºè¾“å…¥ï¼Œå­¦ä¹ å¯¼èˆªç­–ç•¥ï¼Œè¾“å‡ºæ§åˆ¶æŒ‡ä»¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†åŒç›®è§†è§‰å’Œä¸­å±‚è§†è§‰æ¨¡å—æ˜¾å¼åœ°èå…¥åˆ°ç«¯åˆ°ç«¯å¯¼èˆªæ¨¡å‹ä¸­ã€‚ä¸ä»¥å¾€ä¾èµ–å•ç›®è§†è§‰å’Œéšå¼å­¦ä¹ å‡ ä½•ä¿¡æ¯çš„æ¨¡å‹ç›¸æ¯”ï¼ŒStereoWalkerèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨å‡ ä½•å’Œè¿åŠ¨ä¿¡æ¯ï¼Œä»è€Œæé«˜å¯¼èˆªæ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ç°æœ‰çš„æ·±åº¦ä¼°è®¡å’Œåƒç´ è·Ÿè¸ªæ¨¡å‹ï¼Œé¿å…ä»å¤´è®­ç»ƒï¼›2) è®¾è®¡åˆé€‚çš„ç½‘ç»œç»“æ„ï¼Œå°†åŒç›®å›¾åƒã€æ·±åº¦å›¾å’Œè¿åŠ¨ä¿¡æ¯èåˆåœ¨ä¸€èµ·ï¼›3) é‡‡ç”¨æ¨¡ä»¿å­¦ä¹ çš„æ–¹å¼è®­ç»ƒå¯¼èˆªç­–ç•¥ï¼Œåˆ©ç”¨è‡ªåŠ¨æ ‡æ³¨çš„æ•°æ®è¿›è¡Œè®­ç»ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

StereoWalkeråœ¨å®éªŒä¸­è¡¨ç°å‡ºè‰²ï¼Œä»…ä½¿ç”¨1.5%çš„è®­ç»ƒæ•°æ®å³å¯è¾¾åˆ°ä¸æœ€å…ˆè¿›å•ç›®æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ï¼Œä½¿ç”¨å®Œæ•´æ•°æ®é›†æ—¶ï¼Œæ€§èƒ½è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚å®éªŒè¿˜è¯æ˜ï¼ŒåŒç›®è§†è§‰è¾“å…¥æ˜¾è‘—ä¼˜äºå•ç›®è§†è§‰è¾“å…¥ï¼ŒéªŒè¯äº†åŒç›®è§†è§‰å’Œä¸­å±‚è§†è§‰å¯¹äºåŠ¨æ€åŸå¸‚å¯¼èˆªçš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€æ— äººæœºç­‰é¢†åŸŸã€‚é€šè¿‡æå‡æœºå™¨äººåœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ï¼Œå¯ä»¥æé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§ï¼Œæ‰©å±•æœºå™¨äººçš„åº”ç”¨èŒƒå›´ï¼Œä¾‹å¦‚åœ¨ç‰©æµã€å®‰é˜²ã€å·¡æ£€ç­‰åœºæ™¯ä¸­å®ç°è‡ªä¸»å¯¼èˆªã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The success of foundation models in language and vision motivated research in fully end-to-end robot navigation foundation models (NFMs). NFMs directly map monocular visual input to control actions and ignore mid-level vision modules (tracking, depth estimation, etc) entirely. While the assumption that vision capabilities will emerge implicitly is compelling, it requires large amounts of pixel-to-action supervision that are difficult to obtain. The challenge is especially pronounced in dynamic and unstructured settings, where robust navigation requires precise geometric and dynamic understanding, while the depth-scale ambiguity in monocular views further limits accurate spatial reasoning. In this paper, we show that relying on monocular vision and ignoring mid-level vision priors is inefficient.
>   We present StereoWalker, which augments NFMs with stereo inputs and explicit mid-level vision such as depth estimation and dense pixel tracking. Our intuition is straightforward: stereo inputs resolve the depth-scale ambiguity, and modern mid-level vision models provide reliable geometric and motion structure in dynamic scenes. We also curate a large stereo navigation dataset with automatic action annotation from Internet stereo videos to support training of StereoWalker and to facilitate future research. Through our experiments, we find that mid-level vision enables StereoWalker to achieve a comparable performance as the state-of-the-art using only 1.5% of the training data, and surpasses the state-of-the-art using the full data. We also observe that stereo vision yields higher navigation performance than monocular input.

