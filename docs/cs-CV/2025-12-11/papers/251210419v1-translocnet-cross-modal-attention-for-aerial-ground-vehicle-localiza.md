---
layout: default
title: TransLocNet: Cross-Modal Attention for Aerial-Ground Vehicle Localization with Contrastive Learning
---

# TransLocNet: Cross-Modal Attention for Aerial-Ground Vehicle Localization with Contrastive Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.10419" target="_blank" class="toolbar-btn">arXiv: 2512.10419v1</a>
    <a href="https://arxiv.org/pdf/2512.10419.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10419v1" 
            onclick="toggleFavorite(this, '2512.10419v1', 'TransLocNet: Cross-Modal Attention for Aerial-Ground Vehicle Localization with Contrastive Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Phu Pham, Damon Conover, Aniket Bera

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-11

**Â§áÊ≥®**: 8 pages, 4 figures, 4 tables

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**TransLocNetÔºöÂü∫‰∫éË∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÂíåÂØπÊØîÂ≠¶‰π†ÁöÑÊó†‰∫∫Êú∫-Âú∞Èù¢ËΩ¶ËæÜÂÆö‰Ωç**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Êó†‰∫∫Êú∫ÂÆö‰Ωç` `Âú∞Èù¢ËΩ¶ËæÜÂÆö‰Ωç` `Ë∑®Ê®°ÊÄÅËûçÂêà` `Ê≥®ÊÑèÂäõÊú∫Âà∂` `ÂØπÊØîÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Êó†‰∫∫Êú∫-Âú∞Èù¢ËΩ¶ËæÜÂÆö‰ΩçÈù¢‰∏¥ËßÜËßíÂíåÊ®°ÊÄÅÂ∑ÆÂºÇÂ∑®Â§ßÁöÑÊåëÊàòÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàËûçÂêàÂºÇÊûÑÊï∞ÊçÆ„ÄÇ
2. TransLocNetÂà©Áî®Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÂ∞ÜÊøÄÂÖâÈõ∑ËææÂá†‰Ωï‰ø°ÊÅØ‰∏éËà™ÊãçËØ≠‰πâ‰∏ä‰∏ãÊñáËøõË°åÊúâÊïàËûçÂêà„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåTransLocNetÂú®ÂÆö‰ΩçÁ≤æÂ∫¶‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂Âú®ÂêàÊàêÂíåÁúüÂÆûÊï∞ÊçÆÈõÜ‰∏äÂùáË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫TransLocNetÔºå‰∏Ä‰∏™Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÊ°ÜÊû∂ÔºåÁî®‰∫éËûçÂêàÊøÄÂÖâÈõ∑ËææÂá†‰Ωï‰ø°ÊÅØ‰∏éÊó†‰∫∫Êú∫Ëà™ÊãçËØ≠‰πâ‰∏ä‰∏ãÊñáÔºåËß£ÂÜ≥Êó†‰∫∫Êú∫-Âú∞Èù¢ËΩ¶ËæÜÂÆö‰ΩçÈöæÈ¢ò„ÄÇËØ•ÊñπÊ≥ïÈÄöËøáÂèåÂêëÊ≥®ÊÑèÂäõÊú∫Âà∂Â∞ÜÊøÄÂÖâÈõ∑ËææÊâ´ÊèèÊäïÂΩ±Âà∞È∏üÁû∞ÂõæË°®Á§∫ÔºåÂπ∂‰∏éËà™ÊãçÁâπÂæÅÂØπÈΩêÔºåÁÑ∂Âêé‰ΩøÁî®‰ººÁÑ∂ÂõæËß£Á†ÅÂô®ËæìÂá∫‰ΩçÁΩÆÂíåÊñπÂêëÁöÑÁ©∫Èó¥Ê¶ÇÁéáÂàÜÂ∏É„ÄÇÂØπÊØîÂ≠¶‰π†Ê®°ÂùóÁî®‰∫éÂº∫Âà∂ÊâßË°åÂÖ±‰∫´ÂµåÂÖ•Á©∫Èó¥Ôºå‰ª•ÊîπÂñÑË∑®Ê®°ÊÄÅÂØπÈΩê„ÄÇÂú®CARLAÂíåKITTIÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåTransLocNet‰ºò‰∫éÁé∞ÊúâÊäÄÊúØÔºåÂÆö‰ΩçËØØÂ∑ÆÊúÄÂ§öÂèØÈôç‰Ωé63%ÔºåÂπ∂ÂÆûÁé∞‰∫öÁ±≥Á∫ß„ÄÅ‰∫öÂ∫¶Á∫ßÁöÑÁ≤æÂ∫¶„ÄÇÁªìÊûúË°®ÊòéÔºåTransLocNetÂú®ÂêàÊàêÂíåÁúüÂÆûÁéØÂ¢É‰∏≠ÂùáËÉΩÊèê‰æõÈ≤ÅÊ£í‰∏îÈÄöÁî®ÁöÑÊó†‰∫∫Êú∫-Âú∞Èù¢ËΩ¶ËæÜÂÆö‰Ωç„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊó†‰∫∫Êú∫‰∏éÂú∞Èù¢ËΩ¶ËæÜÁöÑÂÆö‰ΩçÊòØ‰∏Ä‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÈóÆÈ¢òÔºå‰∏ªË¶ÅÁóõÁÇπÂú®‰∫éÂú∞Èù¢ÊøÄÂÖâÈõ∑ËææÊï∞ÊçÆÂíåÁ©∫‰∏≠ÂõæÂÉèÊï∞ÊçÆ‰πãÈó¥Â≠òÂú®Â∑®Â§ßÁöÑËßÜËßíÂ∑ÆÂºÇÂíåÊ®°ÊÄÅÂ∑ÆÂºÇ„ÄÇÁé∞ÊúâÁöÑÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂú∞Â∞ÜËøô‰∏§ÁßçÂºÇÊûÑÊï∞ÊçÆËûçÂêàËµ∑Êù•ÔºåÂØºËá¥ÂÆö‰ΩçÁ≤æÂ∫¶‰∏çÈ´ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöTransLocNetÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÂ∞ÜÊøÄÂÖâÈõ∑ËææÁöÑÂá†‰Ωï‰ø°ÊÅØÂíåËà™ÊãçÂõæÂÉèÁöÑËØ≠‰πâ‰ø°ÊÅØËøõË°åÊúâÊïàËûçÂêà„ÄÇÈÄöËøáÂ≠¶‰π†‰∏§ÁßçÊ®°ÊÄÅ‰πãÈó¥ÁöÑÂÖ≥ËÅîÊÄßÔºå‰ªéËÄåÊèêÈ´òÂÆö‰ΩçÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇÂØπÊØîÂ≠¶‰π†ÁöÑÂºïÂÖ•Ëøõ‰∏ÄÊ≠•Â¢ûÂº∫‰∫ÜË∑®Ê®°ÊÄÅÁâπÂæÅÁöÑÂØπÈΩê„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöTransLocNetÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÊøÄÂÖâÈõ∑ËææÊï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºåÂ∞ÜÊøÄÂÖâÈõ∑ËææÊâ´ÊèèÊï∞ÊçÆÊäïÂΩ±Âà∞È∏üÁû∞ÂõæÔºàBEVÔºâË°®Á§∫Ôºõ2) ÁâπÂæÅÊèêÂèñÔºåÂàÜÂà´‰ªéBEVÊøÄÂÖâÈõ∑ËææÊï∞ÊçÆÂíåËà™ÊãçÂõæÂÉè‰∏≠ÊèêÂèñÁâπÂæÅÔºõ3) Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÊ®°ÂùóÔºåÂà©Áî®ÂèåÂêëÊ≥®ÊÑèÂäõÊú∫Âà∂Â∞ÜÊøÄÂÖâÈõ∑ËææÁâπÂæÅÂíåËà™ÊãçÂõæÂÉèÁâπÂæÅËøõË°åÂØπÈΩêÂíåËûçÂêàÔºõ4) ‰ººÁÑ∂ÂõæËß£Á†ÅÂô®ÔºåÊ†πÊçÆËûçÂêàÂêéÁöÑÁâπÂæÅÁîüÊàê‰ΩçÁΩÆÂíåÊñπÂêëÁöÑÊ¶ÇÁéáÂàÜÂ∏ÉÔºõ5) ÂØπÊØîÂ≠¶‰π†Ê®°ÂùóÔºåÈÄöËøáÊúÄÂ∞èÂåñÊ≠£Ê†∑Êú¨ÂØπ‰πãÈó¥ÁöÑË∑ùÁ¶ªÔºåÊúÄÂ§ßÂåñË¥üÊ†∑Êú¨ÂØπ‰πãÈó¥ÁöÑË∑ùÁ¶ªÔºåÊù•Â≠¶‰π†‰∏Ä‰∏™ÂÖ±‰∫´ÁöÑÂµåÂÖ•Á©∫Èó¥„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöTransLocNetÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÊ°ÜÊû∂ÔºåËÉΩÂ§üÊúâÊïàÂú∞ËûçÂêàÊøÄÂÖâÈõ∑ËææÂá†‰Ωï‰ø°ÊÅØÂíåËà™ÊãçËØ≠‰πâ‰∏ä‰∏ãÊñáÔºõ2) ÂºïÂÖ•‰∫ÜÂØπÊØîÂ≠¶‰π†Ê®°ÂùóÔºåËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜË∑®Ê®°ÊÄÅÁâπÂæÅÁöÑÂØπÈΩêÊïàÊûúÔºõ3) ËÆæËÆ°‰∫Ü‰∏Ä‰∏™‰ººÁÑ∂ÂõæËß£Á†ÅÂô®ÔºåËÉΩÂ§üËæìÂá∫‰ΩçÁΩÆÂíåÊñπÂêëÁöÑÊ¶ÇÁéáÂàÜÂ∏ÉÔºå‰ªéËÄåÊèê‰æõÊõ¥‰∏∞ÂØåÁöÑÂÆö‰Ωç‰ø°ÊÅØ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÊ®°Âùó‰∏≠Ôºå‰ΩøÁî®‰∫ÜÂèåÂêëÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÂàÜÂà´‰ªéÊøÄÂÖâÈõ∑ËææÁâπÂæÅÂíåËà™ÊãçÂõæÂÉèÁâπÂæÅÁöÑËßíÂ∫¶ËøõË°åÊ≥®ÊÑèÂäõËÆ°ÁÆó„ÄÇÂØπÊØîÂ≠¶‰π†Ê®°Âùó‰ΩøÁî®‰∫ÜInfoNCEÊçüÂ§±ÂáΩÊï∞ÔºåÁî®‰∫éÂ≠¶‰π†‰∏Ä‰∏™ÂÖ±‰∫´ÁöÑÂµåÂÖ•Á©∫Èó¥„ÄÇ‰ººÁÑ∂ÂõæËß£Á†ÅÂô®‰ΩøÁî®Âç∑ÁßØÁ•ûÁªèÁΩëÁªúÊù•ÁîüÊàê‰ΩçÁΩÆÂíåÊñπÂêëÁöÑÊ¶ÇÁéáÂàÜÂ∏É„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÔºàÂ¶ÇÊ≥®ÊÑèÂäõÂ§¥ÁöÑÊï∞Èáè„ÄÅÂç∑ÁßØÊ†∏ÁöÑÂ§ßÂ∞èÁ≠âÔºâÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰ΩìÁöÑÊï∞ÊçÆÈõÜËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

TransLocNetÂú®CARLAÂíåKITTIÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂÆûÈ™åÔºåÁªìÊûúË°®ÊòéÂÖ∂ÊÄßËÉΩ‰ºò‰∫éÁé∞ÊúâÊäÄÊúØ„ÄÇÂú®CARLAÊï∞ÊçÆÈõÜ‰∏äÔºåTransLocNetÂ∞ÜÂÆö‰ΩçËØØÂ∑ÆÈôç‰Ωé‰∫ÜÈ´òËææ63%ÔºåÂπ∂Âú®KITTIÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫Ü‰∫öÁ±≥Á∫ß„ÄÅ‰∫öÂ∫¶Á∫ßÁöÑÂÆö‰ΩçÁ≤æÂ∫¶„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåTransLocNetÂú®ÂêàÊàêÂíåÁúüÂÆûÁéØÂ¢É‰∏≠ÂùáËÉΩÊèê‰æõÈ≤ÅÊ£í‰∏îÈÄöÁî®ÁöÑÊó†‰∫∫Êú∫-Âú∞Èù¢ËΩ¶ËæÜÂÆö‰Ωç„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËá™Âä®È©æÈ©∂„ÄÅÊó†‰∫∫Êú∫ÂØºËà™„ÄÅÊú∫Âô®‰∫∫ÂÆö‰ΩçÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáËûçÂêàÊó†‰∫∫Êú∫Ëà™ÊãçÂõæÂÉèÂíåÂú∞Èù¢ÊøÄÂÖâÈõ∑ËææÊï∞ÊçÆÔºåÂèØ‰ª•ÂÆûÁé∞Êõ¥Á≤æÁ°Æ„ÄÅÊõ¥È≤ÅÊ£íÁöÑÂÆö‰ΩçÔºåÊèêÈ´òÁ≥ªÁªüÁöÑÂÆâÂÖ®ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂú®Êô∫ÊÖßÂüéÂ∏Ç„ÄÅÁâ©ÊµÅÈÖçÈÄÅ„ÄÅÁÅæÂÆ≥ÊïëÊè¥Á≠âÂú∫ÊôØ‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Aerial-ground localization is difficult due to large viewpoint and modality gaps between ground-level LiDAR and overhead imagery. We propose TransLocNet, a cross-modal attention framework that fuses LiDAR geometry with aerial semantic context. LiDAR scans are projected into a bird's-eye-view representation and aligned with aerial features through bidirectional attention, followed by a likelihood map decoder that outputs spatial probability distributions over position and orientation. A contrastive learning module enforces a shared embedding space to improve cross-modal alignment. Experiments on CARLA and KITTI show that TransLocNet outperforms state-of-the-art baselines, reducing localization error by up to 63% and achieving sub-meter, sub-degree accuracy. These results demonstrate that TransLocNet provides robust and generalizable aerial-ground localization in both synthetic and real-world settings.

