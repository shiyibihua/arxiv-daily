---
layout: default
title: WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World
---

# WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World

**arXiv**: [2512.10958v1](https://arxiv.org/abs/2512.10958) | [PDF](https://arxiv.org/pdf/2512.10958.pdf)

**ä½œè€…**: Ao Liang, Lingdong Kong, Tianyi Yan, Hongsi Liu, Wesley Yang, Ziqi Huang, Wei Yin, Jialong Zuo, Yixuan Hu, Dekai Zhu, Dongyue Lu, Youquan Liu, Guangfeng Jiang, Linfeng Li, Xiangtai Li, Long Zhuo, Lai Xing Ng, Benoit R. Cottereau, Changxin Gao, Liang Pan, Wei Tsang Ooi, Ziwei Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWorldLensåŸºå‡†ä»¥å…¨é¢è¯„ä¼°é©¾é©¶ä¸–ç•Œæ¨¡åž‹çš„çœŸå®žæ€§ä¸ŽåŠŸèƒ½æ€§**

**å…³é”®è¯**: `ä¸–ç•Œæ¨¡åž‹è¯„ä¼°` `é©¾é©¶åœºæ™¯ç”Ÿæˆ` `å‡ ä½•ä¸€è‡´æ€§` `ç‰©ç†åˆç†æ€§` `äººç±»åå¥½æ ‡æ³¨` `è’¸é¦è¯„ä¼°æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç”Ÿæˆä¸–ç•Œæ¨¡åž‹ç¼ºä¹ç»Ÿä¸€è¯„ä¼°æ ‡å‡†ï¼Œéš¾ä»¥è¡¡é‡å‡ ä½•ã€ç‰©ç†å’Œè¡Œä¸ºå¯é æ€§
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºæ¶µç›–ç”Ÿæˆã€é‡å»ºã€åŠ¨ä½œè·Ÿéšã€ä¸‹æ¸¸ä»»åŠ¡å’Œäººç±»åå¥½çš„äº”ç»´åº¦è¯„ä¼°æ¡†æž¶
3. å®žéªŒæˆ–æ•ˆæžœï¼šåˆ›å»ºWorldLens-26Kæ•°æ®é›†å’ŒWorldLens-Agentæ¨¡åž‹ï¼Œå®žçŽ°å¯æ‰©å±•ã€å¯è§£é‡Šçš„è¯„åˆ†

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generative world models are reshaping embodied AI, enabling agents to synthesize realistic 4D driving environments that look convincing but often fail physically or behaviorally. Despite rapid progress, the field still lacks a unified way to assess whether generated worlds preserve geometry, obey physics, or support reliable control. We introduce WorldLens, a full-spectrum benchmark evaluating how well a model builds, understands, and behaves within its generated world. It spans five aspects -- Generation, Reconstruction, Action-Following, Downstream Task, and Human Preference -- jointly covering visual realism, geometric consistency, physical plausibility, and functional reliability. Across these dimensions, no existing world model excels universally: those with strong textures often violate physics, while geometry-stable ones lack behavioral fidelity. To align objective metrics with human judgment, we further construct WorldLens-26K, a large-scale dataset of human-annotated videos with numerical scores and textual rationales, and develop WorldLens-Agent, an evaluation model distilled from these annotations to enable scalable, explainable scoring. Together, the benchmark, dataset, and agent form a unified ecosystem for measuring world fidelity -- standardizing how future models are judged not only by how real they look, but by how real they behave.

