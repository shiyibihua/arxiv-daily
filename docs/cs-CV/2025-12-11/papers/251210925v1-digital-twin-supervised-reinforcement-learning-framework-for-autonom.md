---
layout: default
title: Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation
---

# Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation

**arXiv**: [2512.10925v1](https://arxiv.org/abs/2512.10925) | [PDF](https://arxiv.org/pdf/2512.10925.pdf)

**ä½œè€…**: Zamirddine Mari, Mohamad Motasem Nawaf, Pierre Drap

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ•°å­—å­ªç”Ÿç›‘ç£çš„å¼ºåŒ–å­¦ä¹ æ¡†æž¶ï¼Œç”¨äºŽæ°´ä¸‹è‡ªä¸»å¯¼èˆªä»¥åº”å¯¹æ— GPSå’Œéšœç¢ç‰©æŒ‘æˆ˜ã€‚**

**å…³é”®è¯**: `æ°´ä¸‹è‡ªä¸»å¯¼èˆª` `å¼ºåŒ–å­¦ä¹ ` `æ•°å­—å­ªç”Ÿ` `éšœç¢ç‰©é¿è®©` `ä»¿çœŸè¿ç§»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ°´ä¸‹çŽ¯å¢ƒå› æ— GPSã€èƒ½è§åº¦ä½Žå’Œéšœç¢ç‰©å­˜åœ¨ï¼Œè‡ªä¸»å¯¼èˆªé¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽPPOç®—æ³•ï¼Œç»“åˆç›®æ ‡å¯¼èˆªä¿¡æ¯ã€è™šæ‹Ÿå ç”¨ç½‘æ ¼å’Œå°„çº¿æŠ•å°„çš„è§‚æµ‹ç©ºé—´è¿›è¡Œå­¦ä¹ ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ¨¡æ‹Ÿå’Œç‰©ç†BlueROV2ä¸ŠéªŒè¯ï¼ŒPPOç­–ç•¥åœ¨å¤æ‚çŽ¯å¢ƒä¸­ä¼˜äºŽDWAï¼Œå‡å°‘ç¢°æ’žå¹¶å®žçŽ°ä»¿çœŸåˆ°çŽ°å®žçš„è¿ç§»ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Autonomous navigation in underwater environments remains a major challenge due to the absence of GPS, degraded visibility, and the presence of submerged obstacles. This article investigates these issues through the case of the BlueROV2, an open platform widely used for scientific experimentation. We propose a deep reinforcement learning approach based on the Proximal Policy Optimization (PPO) algorithm, using an observation space that combines target-oriented navigation information, a virtual occupancy grid, and ray-casting along the boundaries of the operational area. The learned policy is compared against a reference deterministic kinematic planner, the Dynamic Window Approach (DWA), commonly employed as a robust baseline for obstacle avoidance. The evaluation is conducted in a realistic simulation environment and complemented by validation on a physical BlueROV2 supervised by a 3D digital twin of the test site, helping to reduce risks associated with real-world experimentation. The results show that the PPO policy consistently outperforms DWA in highly cluttered environments, notably thanks to better local adaptation and reduced collisions. Finally, the experiments demonstrate the transferability of the learned behavior from simulation to the real world, confirming the relevance of deep RL for autonomous navigation in underwater robotics.

