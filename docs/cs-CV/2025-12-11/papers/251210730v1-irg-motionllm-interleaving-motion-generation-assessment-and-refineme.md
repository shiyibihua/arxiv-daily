---
layout: default
title: IRG-MotionLLM: Interleaving Motion Generation, Assessment and Refinement for Text-to-Motion Generation
---

# IRG-MotionLLM: Interleaving Motion Generation, Assessment and Refinement for Text-to-Motion Generation

**arXiv**: [2512.10730v1](https://arxiv.org/abs/2512.10730) | [PDF](https://arxiv.org/pdf/2512.10730.pdf)

**ä½œè€…**: Yuan-Ming Li, Qize Yang, Nan Lei, Shenghao Fu, Ling-An Zeng, Jian-Fang Hu, Xihan Wei, Wei-Shi Zheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIRG-MotionLLMæ¨¡åž‹ï¼Œé€šè¿‡äº¤ç»‡è¿åŠ¨ç”Ÿæˆã€è¯„ä¼°ä¸Žç²¾ç‚¼æå‡æ–‡æœ¬åˆ°è¿åŠ¨ç”Ÿæˆæ€§èƒ½ã€‚**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°è¿åŠ¨ç”Ÿæˆ` `è¿åŠ¨è¯„ä¼°` `è¿åŠ¨ç²¾ç‚¼` `å¤§è¯­è¨€æ¨¡åž‹` `è¿­ä»£å¯¹è¯` `æ•°æ®åˆæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è¿åŠ¨æ„ŸçŸ¥å¤§è¯­è¨€æ¨¡åž‹å°†ç†è§£ä¸Žç”Ÿæˆåˆ†ç¦»ï¼Œç¼ºä¹ä»»åŠ¡é—´äº¤äº’åé¦ˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥IRMoGenèŒƒå¼ï¼Œé€šè¿‡è¿­ä»£æ–‡æœ¬-è¿åŠ¨å¯¹è¯ç´§å¯†è€¦åˆç”Ÿæˆã€è¯„ä¼°ä¸Žç²¾ç‚¼ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¨¡åž‹åœ¨æ ‡å‡†åŸºå‡†ä¸Šä¼˜äºŽåŸºçº¿ï¼Œè¯„ä¼°ä¸Žç²¾ç‚¼ä»»åŠ¡æ˜¾è‘—æ”¹å–„æ–‡æœ¬-è¿åŠ¨å¯¹é½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in motion-aware large language models have shown remarkable promise for unifying motion understanding and generation tasks. However, these models typically treat understanding and generation separately, limiting the mutual benefits that could arise from interactive feedback between tasks. In this work, we reveal that motion assessment and refinement tasks act as crucial bridges to enable bidirectional knowledge flow between understanding and generation. Leveraging this insight, we propose Interleaved Reasoning for Motion Generation (IRMoGen), a novel paradigm that tightly couples motion generation with assessment and refinement through iterative text-motion dialogue. To realize this, we introduce IRG-MotionLLM, the first model that seamlessly interleaves motion generation, assessment, and refinement to improve generation performance. IRG-MotionLLM is developed progressively with a novel three-stage training scheme, initializing and subsequently enhancing native IRMoGen capabilities. To facilitate this development, we construct an automated data engine to synthesize interleaved reasoning annotations from existing text-motion datasets. Extensive experiments demonstrate that: (i) Assessment and refinement tasks significantly improve text-motion alignment; (ii) Interleaving motion generation, assessment, and refinement steps yields consistent performance gains across training stages; and (iii) IRG-MotionLLM clearly outperforms the baseline model and achieves advanced performance on standard text-to-motion generation benchmarks. Cross-evaluator testing further validates its effectiveness. Code & Data: https://github.com/HumanMLLM/IRG-MotionLLM/tree/main.

