---
layout: default
title: LabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification
---

# LabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification

**arXiv**: [2512.10793v1](https://arxiv.org/abs/2512.10793) | [PDF](https://arxiv.org/pdf/2512.10793.pdf)

**ä½œè€…**: Michael Schlee, Christoph Weisser, Timo KivimÃ¤ki, Melchizedek Mashiku, Benjamin Saefken

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLabelFusionèžåˆæ–¹æ³•ï¼Œç»“åˆä¼ ç»ŸTransformeråˆ†ç±»å™¨ä¸ŽLLMsï¼Œå®žçŽ°é²æ£’æ–‡æœ¬åˆ†ç±»**

**å…³é”®è¯**: `æ–‡æœ¬åˆ†ç±»` `èžåˆé›†æˆ` `å¤§è¯­è¨€æ¨¡åž‹` `Transformeråˆ†ç±»å™¨` `ç«¯åˆ°ç«¯è®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•èžåˆä¼ ç»ŸTransformeråˆ†ç±»å™¨ä¸ŽLLMsçš„ä¼˜åŠ¿ï¼Œæå‡æ–‡æœ¬åˆ†ç±»çš„å‡†ç¡®æ€§å’Œæˆæœ¬æ•ˆçŽ‡
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æ‹¼æŽ¥MLéª¨å¹²åµŒå…¥å’ŒLLMç”Ÿæˆçš„åˆ†å€¼ï¼Œè¾“å…¥FusionMLPè¿›è¡Œç«¯åˆ°ç«¯å­¦ä¹ èžåˆ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨AG Newså’ŒReuters 21578æ•°æ®é›†ä¸Šåˆ†åˆ«è¾¾åˆ°92.4%å’Œ92.3%çš„å‡†ç¡®çŽ‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> LabelFusion is a fusion ensemble for text classification that learns to combine a traditional transformer-based classifier (e.g., RoBERTa) with one or more Large Language Models (LLMs such as OpenAI GPT, Google Gemini, or DeepSeek) to deliver accurate and cost-aware predictions across multi-class and multi-label tasks. The package provides a simple high-level interface (AutoFusionClassifier) that trains the full pipeline end-to-end with minimal configuration, and a flexible API for advanced users. Under the hood, LabelFusion integrates vector signals from both sources by concatenating the ML backbone's embeddings with the LLM-derived per-class scores -- obtained through structured prompt-engineering strategies -- and feeds this joint representation into a compact multi-layer perceptron (FusionMLP) that produces the final prediction. This learned fusion approach captures complementary strengths of LLM reasoning and traditional transformer-based classifiers, yielding robust performance across domains -- achieving 92.4% accuracy on AG News and 92.3% on 10-class Reuters 21578 topic classification -- while enabling practical trade-offs between accuracy, latency, and cost.

