---
layout: default
title: Cooperative Retrieval-Augmented Generation for Question Answering: Mutual Information Exchange and Ranking by Contrasting Layers
---

# Cooperative Retrieval-Augmented Generation for Question Answering: Mutual Information Exchange and Ranking by Contrasting Layers

**arXiv**: [2512.10422v1](https://arxiv.org/abs/2512.10422) | [PDF](https://arxiv.org/pdf/2512.10422.pdf)

**ä½œè€…**: Youmin Ko, Sungjong Seo, Hyunjoon Kim

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoopRAGæ¡†æž¶ï¼Œé€šè¿‡æ£€ç´¢å™¨ä¸ŽLLMååŒåŠå±‚é—´å¯¹æ¯”æŽ’åºï¼Œæå‡é—®ç­”ä»»åŠ¡ä¸­æ£€ç´¢ä¸Žç”Ÿæˆçš„å‡†ç¡®æ€§ã€‚**

**å…³é”®è¯**: `æ£€ç´¢å¢žå¼ºç”Ÿæˆ` `å¤šè·³é—®ç­”` `ååŒå­¦ä¹ ` `å±‚é—´å¯¹æ¯”` `æŽ¨ç†é“¾é‡å»º` `æ–‡æ¡£é‡æŽ’`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é’ˆå¯¹çŽ°æœ‰RAGæ–¹æ³•åœ¨ç®€å•å’Œå¤šè·³é—®ç­”ä¸­æ˜“å‡ºçŽ°é”™è¯¯æ£€ç´¢å’Œå¹»è§‰çš„é—®é¢˜ã€‚
2. é‡‡ç”¨é—®é¢˜åˆ†è§£ã€æŽ¨ç†é“¾æŽ©ç ã€æ–‡æ¡£æ£€ç´¢ä¸Žå±‚é—´å¯¹æ¯”é‡æŽ’ã€LLMå¡«å……é‡å»ºçš„ååŒæœºåˆ¶ã€‚
3. å®žéªŒè¡¨æ˜Žåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ£€ç´¢å’Œé—®ç­”æ€§èƒ½ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œä»£ç å·²å¼€æºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Since large language models (LLMs) have a tendency to generate factually inaccurate output, retrieval-augmented generation (RAG) has gained significant attention as a key means to mitigate this downside of harnessing only LLMs. However, existing RAG methods for simple and multi-hop question answering (QA) are still prone to incorrect retrievals and hallucinations. To address these limitations, we propose CoopRAG, a novel RAG framework for the question answering task in which a retriever and an LLM work cooperatively with each other by exchanging informative knowledge, and the earlier and later layers of the retriever model work cooperatively with each other to accurately rank the retrieved documents relevant to a given query. In this framework, we (i) unroll a question into sub-questions and a reasoning chain in which uncertain positions are masked, (ii) retrieve the documents relevant to the question augmented with the sub-questions and the reasoning chain, (iii) rerank the documents by contrasting layers of the retriever, and (iv) reconstruct the reasoning chain by filling the masked positions via the LLM. Our experiments demonstrate that CoopRAG consistently outperforms state-of-the-art QA methods on three multi-hop QA datasets as well as a simple QA dataset in terms of both the retrieval and QA performances. Our code is available.\footnote{https://github.com/meaningful96/CoopRAG}

