---
layout: default
title: GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting
---

# GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting

**arXiv**: [2512.10939v1](https://arxiv.org/abs/2512.10939) | [PDF](https://arxiv.org/pdf/2512.10939.pdf)

**ä½œè€…**: Madhav Agarwal, Mingtian Zhang, Laura Sevilla-Lara, Steven McDonagh

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽ3D Morphable Modelså’ŒTransformerçš„Gaussian Splattingæ–¹æ³•ï¼Œä»¥ç”Ÿæˆå®žæ—¶ç¨³å®šçš„éŸ³é¢‘é©±åŠ¨3Dè¯´è¯å¤´**

**å…³é”®è¯**: `3Dè¯´è¯å¤´ç”Ÿæˆ` `Gaussian Splatting` `éŸ³é¢‘é©±åŠ¨` `æ—¶é—´ä¸€è‡´æ€§` `3D Morphable Models` `Transformeré¢„æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•åœ¨å®žæ—¶æ€§å’Œæ—¶é—´ç¨³å®šæ€§ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´è§†é¢‘ä¼ªå½±å’Œä¸ç¨³å®šè¾“å‡º
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨3D Morphable Modelsæ˜ å°„Gaussian Splattingï¼Œç»“åˆTransformerä»ŽéŸ³é¢‘ç›´æŽ¥é¢„æµ‹å‚æ•°ä»¥é©±åŠ¨æ—¶é—´ä¸€è‡´æ€§
3. å®žéªŒæˆ–æ•ˆæžœï¼šä»Žå•ç›®è§†é¢‘å’Œç‹¬ç«‹éŸ³é¢‘è¾“å…¥ç”Ÿæˆå®žæ—¶è¯´è¯å¤´è§†é¢‘ï¼Œåœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸­æŠ¥å‘Šç«žäº‰æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Speech-driven talking heads have recently emerged and enable interactive avatars. However, real-world applications are limited, as current methods achieve high visual fidelity but slow or fast yet temporally unstable. Diffusion methods provide realistic image generation, yet struggle with oneshot settings. Gaussian Splatting approaches are real-time, yet inaccuracies in facial tracking, or inconsistent Gaussian mappings, lead to unstable outputs and video artifacts that are detrimental to realistic use cases. We address this problem by mapping Gaussian Splatting using 3D Morphable Models to generate person-specific avatars. We introduce transformer-based prediction of model parameters, directly from audio, to drive temporal consistency. From monocular video and independent audio speech inputs, our method enables generation of real-time talking head videos where we report competitive quantitative and qualitative performance.

