---
layout: default
title: Topology-Agnostic Animal Motion Generation from Text Prompt
---

# Topology-Agnostic Animal Motion Generation from Text Prompt

**arXiv**: [2512.10352v1](https://arxiv.org/abs/2512.10352) | [PDF](https://arxiv.org/pdf/2512.10352.pdf)

**ä½œè€…**: Keyi Chen, Mingze Sun, Zhenyu Liu, Zhangquan Chen, Ruqi Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmniZooæ•°æ®é›†ä¸Žæ‹“æ‰‘æ— å…³è¿åŠ¨ç”Ÿæˆæ¡†æž¶ï¼Œä»¥è§£å†³åŠ¨ç‰©è¿åŠ¨ç”Ÿæˆä¸­éª¨æž¶æ‹“æ‰‘å›ºå®šå’Œç¼ºä¹ç»Ÿä¸€æ¨¡åž‹çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `åŠ¨ç‰©è¿åŠ¨ç”Ÿæˆ` `æ‹“æ‰‘æ— å…³å»ºæ¨¡` `æ–‡æœ¬é©±åŠ¨åŠ¨ç”»` `éª¨æž¶åµŒå…¥` `è·¨ç‰©ç§è¿ç§»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•ä¾èµ–å›ºå®šéª¨æž¶æ¨¡æ¿ï¼Œæ— æ³•æ³›åŒ–åˆ°ä¸åŒæˆ–æ‰°åŠ¨æ‹“æ‰‘ï¼Œä¸”ç¼ºä¹å¤§è§„æ¨¡å¼‚æž„åŠ¨ç‰©è¿åŠ¨æ•°æ®å’Œç»Ÿä¸€ç”Ÿæˆæ¡†æž¶ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥OmniZooå¤§è§„æ¨¡åŠ¨ç‰©è¿åŠ¨æ•°æ®é›†ï¼Œå¹¶æå‡ºåŸºäºŽæ‹“æ‰‘æ„ŸçŸ¥éª¨æž¶åµŒå…¥æ¨¡å—çš„è‡ªå›žå½’ç”Ÿæˆæ¡†æž¶ï¼Œèžåˆæ–‡æœ¬è¯­ä¹‰ç”Ÿæˆä»»æ„éª¨æž¶çš„è¿åŠ¨ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¨¡åž‹èƒ½ç”Ÿæˆæ—¶é—´è¿žè´¯ã€ç‰©ç†åˆç†ã€è¯­ä¹‰å¯¹é½çš„è¿åŠ¨ï¼Œå¹¶æ”¯æŒè·¨ç‰©ç§è¿åŠ¨é£Žæ ¼è¿ç§»ï¼Œå…·ä½“æ€§èƒ½æŒ‡æ ‡æœªçŸ¥ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Motion generation is fundamental to computer animation and widely used across entertainment, robotics, and virtual environments. While recent methods achieve impressive results, most rely on fixed skeletal templates, which prevent them from generalizing to skeletons with different or perturbed topologies. We address the core limitation of current motion generation methods - the combined lack of large-scale heterogeneous animal motion data and unified generative frameworks capable of jointly modeling arbitrary skeletal topologies and textual conditions. To this end, we introduce OmniZoo, a large-scale animal motion dataset spanning 140 species and 32,979 sequences, enriched with multimodal annotations. Building on OmniZoo, we propose a generalized autoregressive motion generation framework capable of producing text-driven motions for arbitrary skeletal topologies. Central to our model is a Topology-aware Skeleton Embedding Module that encodes geometric and structural properties of any skeleton into a shared token space, enabling seamless fusion with textual semantics. Given a text prompt and a target skeleton, our method generates temporally coherent, physically plausible, and semantically aligned motions, and further enables cross-species motion style transfer.

