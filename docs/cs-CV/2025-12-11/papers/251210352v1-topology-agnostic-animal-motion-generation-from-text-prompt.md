---
layout: default
title: Topology-Agnostic Animal Motion Generation from Text Prompt
---

# Topology-Agnostic Animal Motion Generation from Text Prompt

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.10352" target="_blank" class="toolbar-btn">arXiv: 2512.10352v1</a>
    <a href="https://arxiv.org/pdf/2512.10352.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10352v1" 
            onclick="toggleFavorite(this, '2512.10352v1', 'Topology-Agnostic Animal Motion Generation from Text Prompt')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Keyi Chen, Mingze Sun, Zhenyu Liu, Zhangquan Chen, Ruqi Huang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-11

**Â§áÊ≥®**: 10 pages, 7 figures.Conference submission

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫OmniZooÊï∞ÊçÆÈõÜÂíåÊãìÊâëÊó†ÂÖ≥ÁöÑÂä®Áâ©ËøêÂä®ÁîüÊàêÊ°ÜÊû∂ÔºåËß£ÂÜ≥ÂºÇÊûÑÈ™®È™ºÂíåÊñáÊú¨È©±Âä®ÁöÑÂä®Áâ©ËøêÂä®ÁîüÊàêÈóÆÈ¢ò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `Âä®Áâ©ËøêÂä®ÁîüÊàê` `ÊñáÊú¨È©±Âä®ËøêÂä®` `ÊãìÊâëÊó†ÂÖ≥` `È™®È™ºÂµåÂÖ•` `Ëá™ÂõûÂΩíÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËøêÂä®ÁîüÊàêÊñπÊ≥ï‰æùËµñÂõ∫ÂÆöÈ™®È™ºÊ®°ÊùøÔºåÈöæ‰ª•Â§ÑÁêÜ‰∏çÂêåÊàñÊâ∞Âä®ÊãìÊâëÁªìÊûÑÁöÑÂä®Áâ©È™®È™º„ÄÇ
2. ÊèêÂá∫ÊãìÊâëÊÑüÁü•ÁöÑÈ™®È™ºÂµåÂÖ•Ê®°ÂùóÔºåÂ∞ÜÈ™®È™ºÁöÑÂá†‰ΩïÂíåÁªìÊûÑÂ±ûÊÄßÁºñÁ†ÅÂà∞ÂÖ±‰∫´Á©∫Èó¥ÔºåËûçÂêàÊñáÊú¨ËØ≠‰πâ„ÄÇ
3. ÊûÑÂª∫Â§ßËßÑÊ®°Âä®Áâ©ËøêÂä®Êï∞ÊçÆÈõÜOmniZooÔºåÂåÖÂê´140‰∏™Áâ©ÁßçÂíå32,979‰∏™Â∫èÂàóÔºåÂπ∂ËøõË°åÂ§öÊ®°ÊÄÅÊ†áÊ≥®„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊãìÊâëÊó†ÂÖ≥ÁöÑÂä®Áâ©ËøêÂä®ÁîüÊàêÊñπÊ≥ïÔºåÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÊñπÊ≥ï‰æùËµñÂõ∫ÂÆöÈ™®È™ºÊ®°ÊùøÔºåÊó†Ê≥ïÊ≥õÂåñÂà∞‰∏çÂêåÊàñÊâ∞Âä®ÊãìÊâëÁªìÊûÑÁöÑÈóÆÈ¢ò„ÄÇ‰∏∫Ê≠§Ôºå‰ΩúËÄÖÊûÑÂª∫‰∫ÜÂ§ßËßÑÊ®°Âä®Áâ©ËøêÂä®Êï∞ÊçÆÈõÜOmniZooÔºåÂåÖÂê´140‰∏™Áâ©ÁßçÂíå32,979‰∏™Â∫èÂàóÔºåÂπ∂ËøõË°å‰∫ÜÂ§öÊ®°ÊÄÅÊ†áÊ≥®„ÄÇÂü∫‰∫éOmniZooÔºå‰ΩúËÄÖÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âπø‰πâÁöÑËá™ÂõûÂΩíËøêÂä®ÁîüÊàêÊ°ÜÊû∂ÔºåËÉΩÂ§ü‰∏∫‰ªªÊÑèÈ™®È™ºÊãìÊâëÁîüÊàêÊñáÊú¨È©±Âä®ÁöÑËøêÂä®„ÄÇËØ•Ê®°ÂûãÁöÑÂÖ≥ÈîÆÂú®‰∫éÊãìÊâëÊÑüÁü•È™®È™ºÂµåÂÖ•Ê®°ÂùóÔºåÂÆÉÂ∞Ü‰ªª‰ΩïÈ™®È™ºÁöÑÂá†‰ΩïÂíåÁªìÊûÑÂ±ûÊÄßÁºñÁ†ÅÂà∞ÂÖ±‰∫´ÁöÑtokenÁ©∫Èó¥‰∏≠Ôºå‰ªéËÄåÂÆûÁé∞‰∏éÊñáÊú¨ËØ≠‰πâÁöÑÊó†ÁºùËûçÂêà„ÄÇËØ•ÊñπÊ≥ïËÉΩÂ§üÁîüÊàêÊó∂Èó¥ËøûË¥Ø„ÄÅÁâ©ÁêÜÂêàÁêÜ‰∏îËØ≠‰πâÂØπÈΩêÁöÑËøêÂä®ÔºåÂπ∂Ëøõ‰∏ÄÊ≠•ÂÆûÁé∞Ë∑®Áâ©ÁßçÁöÑËøêÂä®È£éÊ†ºËøÅÁßª„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËøêÂä®ÁîüÊàêÊñπÊ≥ï‰∏ªË¶Å‰æùËµñ‰∫éÂõ∫ÂÆöÁöÑÈ™®È™ºÊ®°ÊùøÔºåËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®Â§ÑÁêÜÂÖ∑Êúâ‰∏çÂêåÊàñÊâ∞Âä®ÊãìÊâëÁªìÊûÑÁöÑÂä®Áâ©È™®È™ºÊó∂ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÁº∫‰πèÂ§ßËßÑÊ®°ÁöÑ„ÄÅÂåÖÂê´ÂºÇÊûÑÂä®Áâ©ËøêÂä®Êï∞ÊçÆÁöÑÊï∞ÊçÆÈõÜÔºå‰ª•ÂèäËÉΩÂ§üÁªü‰∏ÄÂª∫Ê®°‰ªªÊÑèÈ™®È™ºÊãìÊâëÂíåÊñáÊú¨Êù°‰ª∂ÁöÑÁîüÊàêÊ°ÜÊû∂ÔºåÊòØÂΩìÂâçÊñπÊ≥ïÁöÑ‰∏ªË¶ÅÁóõÁÇπ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™ËÉΩÂ§üÊÑüÁü•È™®È™ºÊãìÊâëÁªìÊûÑÁöÑÂµåÂÖ•Ê®°ÂùóÔºåÂ∞Ü‰∏çÂêåÊãìÊâëÁªìÊûÑÁöÑÈ™®È™ºÊò†Â∞ÑÂà∞Áªü‰∏ÄÁöÑÁâπÂæÅÁ©∫Èó¥Ôºå‰ªéËÄåÂÆûÁé∞‰∏éÊñáÊú¨‰ø°ÊÅØÁöÑÊúâÊïàËûçÂêà„ÄÇÈÄöËøáËá™ÂõûÂΩíÁöÑÊñπÂºèÔºåÈÄêÊ≠•ÁîüÊàêÁ¨¶ÂêàÊñáÊú¨ÊèèËø∞ÁöÑ„ÄÅÂÖ∑ÊúâÊó∂Èó¥ËøûË¥ØÊÄßÂíåÁâ©ÁêÜÂêàÁêÜÊÄßÁöÑÂä®Áâ©ËøêÂä®„ÄÇËøôÁßçËÆæËÆ°ÂÖÅËÆ∏Ê®°ÂûãÂ§ÑÁêÜÂêÑÁßçÂä®Áâ©ÁöÑÈ™®È™ºÁªìÊûÑÔºåÂπ∂Ê†πÊçÆÊñáÊú¨ÊèêÁ§∫ÁîüÊàêÁõ∏Â∫îÁöÑËøêÂä®„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÊãìÊâëÊÑüÁü•È™®È™ºÂµåÂÖ•Ê®°ÂùóÔºöË¥üË¥£Â∞ÜÈ™®È™ºÁöÑÂá†‰ΩïÂíåÁªìÊûÑ‰ø°ÊÅØÁºñÁ†Å‰∏∫ÁâπÂæÅÂêëÈáè„ÄÇ2) ÊñáÊú¨ÁºñÁ†ÅÂô®ÔºöË¥üË¥£Â∞ÜÊñáÊú¨ÊèêÁ§∫ÁºñÁ†Å‰∏∫ËØ≠‰πâÂêëÈáè„ÄÇ3) Ëá™ÂõûÂΩíËøêÂä®ÁîüÊàêÂô®ÔºöÂü∫‰∫éÈ™®È™ºÂµåÂÖ•ÂíåÊñáÊú¨ËØ≠‰πâÔºåÈÄêÊ≠•ÁîüÊàêËøêÂä®Â∫èÂàó„ÄÇËØ•ÁîüÊàêÂô®ÈÄöÂ∏∏ÈááÁî®TransformerÊû∂ÊûÑÔºåËÉΩÂ§üÊçïÊçâËøêÂä®Â∫èÂàó‰∏≠ÁöÑÊó∂Èó¥‰æùËµñÂÖ≥Á≥ª„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÊãìÊâëÊÑüÁü•È™®È™ºÂµåÂÖ•Ê®°Âùó„ÄÇËØ•Ê®°ÂùóËÉΩÂ§üÂ≠¶‰π†Âà∞È™®È™ºÁöÑÂÜÖÂú®ÁªìÊûÑÔºåÂπ∂Â∞ÜÂÖ∂Ë°®Á§∫‰∏∫‰∏éÊãìÊâëÁªìÊûÑÊó†ÂÖ≥ÁöÑÁâπÂæÅÂêëÈáè„ÄÇËøô‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂ§ÑÁêÜÂêÑÁßç‰∏çÂêåÊãìÊâëÁªìÊûÑÁöÑÈ™®È™ºÔºåËÄåÊó†ÈúÄÈíàÂØπÊØèÁßçÈ™®È™ºÁªìÊûÑËøõË°åÂçïÁã¨ËÆ≠ÁªÉ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÊ≥õÂåñËÉΩÂäõÂíåÁÅµÊ¥ªÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊãìÊâëÊÑüÁü•È™®È™ºÂµåÂÖ•Ê®°ÂùóÂèØËÉΩ‰ΩøÁî®ÂõæÁ•ûÁªèÁΩëÁªúÔºàGNNÔºâÊù•ÁºñÁ†ÅÈ™®È™ºÁöÑËøûÊé•ÂÖ≥Á≥ªÂíåÂÖ≥ËäÇÁöÑÂá†‰Ωï‰ø°ÊÅØ„ÄÇÊçüÂ§±ÂáΩÊï∞ÈÄöÂ∏∏ÂåÖÊã¨ËøêÂä®È¢ÑÊµãÊçüÂ§±„ÄÅÊñáÊú¨ÂØπÈΩêÊçüÂ§±ÂíåÁâ©ÁêÜÂêàÁêÜÊÄßÊçüÂ§±„ÄÇËøêÂä®È¢ÑÊµãÊçüÂ§±Áî®‰∫éÁ°Æ‰øùÁîüÊàêÁöÑËøêÂä®‰∏éÊñáÊú¨ÊèèËø∞‰∏ÄËá¥ÔºåÊñáÊú¨ÂØπÈΩêÊçüÂ§±Áî®‰∫éÁ°Æ‰øùÈ™®È™ºÂµåÂÖ•‰∏éÊñáÊú¨ËØ≠‰πâÂØπÈΩêÔºåÁâ©ÁêÜÂêàÁêÜÊÄßÊçüÂ§±Áî®‰∫éÁ°Æ‰øùÁîüÊàêÁöÑËøêÂä®Á¨¶ÂêàÁâ©ÁêÜËßÑÂæã„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÊûÑÂª∫‰∫ÜÂåÖÂê´140‰∏™Áâ©ÁßçÁöÑÂ§ßËßÑÊ®°Âä®Áâ©ËøêÂä®Êï∞ÊçÆÈõÜOmniZoo„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÁîüÊàêÊó∂Èó¥ËøûË¥Ø„ÄÅÁâ©ÁêÜÂêàÁêÜ‰∏îËØ≠‰πâÂØπÈΩêÁöÑÂä®Áâ©ËøêÂä®„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòËÉΩÂ§üÂÆûÁé∞Ë∑®Áâ©ÁßçÁöÑËøêÂä®È£éÊ†ºËøÅÁßªÔºå‰æãÂ¶ÇËÆ©‰∏ÄÂè™Áå´Ê®°‰ªøÁãóÁöÑË∑ëÊ≠•ÂßøÂäø„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫ø‰ø°ÊÅØÊú™Áü•„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éËÆ°ÁÆóÊú∫Âä®Áîª„ÄÅÊ∏∏ÊàèÂºÄÂèë„ÄÅÊú∫Âô®‰∫∫ÊéßÂà∂ÂíåËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂèØ‰ª•Ê†πÊçÆÊñáÊú¨ÊèèËø∞Ëá™Âä®ÁîüÊàêÂêÑÁßçÂä®Áâ©ÁöÑËøêÂä®Âä®ÁîªÔºå‰∏∫Ê∏∏ÊàèËßíËâ≤Ëµã‰∫àÊõ¥ÈÄºÁúüÁöÑË°å‰∏∫ÔºåÊàñËÄÖÊéßÂà∂Êú∫Âô®‰∫∫Ê®°‰ªøÂä®Áâ©ÁöÑËøêÂä®ÊñπÂºè„ÄÇËØ•ÊäÄÊúØËøòÊúâÊΩúÂäõÂ∫îÁî®‰∫éÁîüÁâ©ÂäõÂ≠¶Á†îÁ©∂ÔºåÂ∏ÆÂä©ÂàÜÊûêÂíåÁêÜËß£Âä®Áâ©ÁöÑËøêÂä®Êú∫Âà∂„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Motion generation is fundamental to computer animation and widely used across entertainment, robotics, and virtual environments. While recent methods achieve impressive results, most rely on fixed skeletal templates, which prevent them from generalizing to skeletons with different or perturbed topologies. We address the core limitation of current motion generation methods - the combined lack of large-scale heterogeneous animal motion data and unified generative frameworks capable of jointly modeling arbitrary skeletal topologies and textual conditions. To this end, we introduce OmniZoo, a large-scale animal motion dataset spanning 140 species and 32,979 sequences, enriched with multimodal annotations. Building on OmniZoo, we propose a generalized autoregressive motion generation framework capable of producing text-driven motions for arbitrary skeletal topologies. Central to our model is a Topology-aware Skeleton Embedding Module that encodes geometric and structural properties of any skeleton into a shared token space, enabling seamless fusion with textual semantics. Given a text prompt and a target skeleton, our method generates temporally coherent, physically plausible, and semantically aligned motions, and further enables cross-species motion style transfer.

