---
layout: default
title: Visual Funnel: Resolving Contextual Blindness in Multimodal Large Language Models
---

# Visual Funnel: Resolving Contextual Blindness in Multimodal Large Language Models

**arXiv**: [2512.10362v1](https://arxiv.org/abs/2512.10362) | [PDF](https://arxiv.org/pdf/2512.10362.pdf)

**ä½œè€…**: Woojun Jung, Jaehoon Go, Mingyu Jeon, Sunjae Yoon, Junyeong Kim

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVisual Funnelä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ä¸­çš„ä¸Šä¸‹æ–‡ç›²åŒºé—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `ä¸Šä¸‹æ–‡ç›²åŒº` `è§†è§‰ç»†èŠ‚æ„ŸçŸ¥` `æ— è®­ç»ƒæ–¹æ³•` `å±‚æ¬¡åŒ–ä¸Šä¸‹æ–‡` `æ³¨æ„åŠ›ç†µ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹åœ¨ç²¾ç»†è§†è§‰ç»†èŠ‚æ„ŸçŸ¥ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´ä¸Šä¸‹æ–‡ç›²åŒºï¼Œå½±å“é«˜ç²¾åº¦ä»»åŠ¡åº”ç”¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ— è®­ç»ƒçš„ä¸¤æ­¥æ³•ï¼Œé€šè¿‡ä¸Šä¸‹æ–‡é”šå®šå’Œç†µç¼©æ”¾ç»„åˆæž„å»ºå±‚æ¬¡åŒ–ä¸Šä¸‹æ–‡ï¼ŒåŠ¨æ€ç¡®å®šè£å‰ªå¤§å°å’Œä¸­å¿ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å®žéªŒä¸­æ˜¾è‘—ä¼˜äºŽå•è£å‰ªå’Œéžç»“æž„åŒ–å¤šè£å‰ªåŸºçº¿ï¼ŒéªŒè¯å±‚æ¬¡åŒ–ç»“æž„å¯¹è§£å†³ä¸Šä¸‹æ–‡ç›²åŒºçš„å…³é”®ä½œç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) demonstrate impressive reasoning capabilities, but often fail to perceive fine-grained visual details, limiting their applicability in precision-demanding tasks. While methods that crop salient regions of an image offer a partial solution, we identify a critical limitation they introduce: "Contextual Blindness". This failure occurs due to structural disconnect between high-fidelity details (from the crop) and the broader global context (from the original image), even when all necessary visual information is present. We argue that this limitation stems not from a lack of information 'Quantity', but from a lack of 'Structural Diversity' in the model's input. To resolve this, we propose Visual Funnel, a training-free, two-step approach. Visual Funnel first performs Contextual Anchoring to identify the region of interest in a single forward pass. It then constructs an Entropy-Scaled Portfolio that preserves the hierarchical context - ranging from focal detail to broader surroundings - by dynamically determining crop sizes based on attention entropy and refining crop centers. Through extensive experiments, we demonstrate that Visual Funnel significantly outperforms naive single-crop and unstructured multi-crop baselines. Our results further validate that simply adding more unstructured crops provides limited or even detrimental benefits, confirming that the hierarchical structure of our portfolio is key to resolving Contextual Blindness.

