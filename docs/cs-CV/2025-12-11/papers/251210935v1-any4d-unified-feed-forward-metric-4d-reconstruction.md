---
layout: default
title: Any4D: Unified Feed-Forward Metric 4D Reconstruction
---

# Any4D: Unified Feed-Forward Metric 4D Reconstruction

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.10935" target="_blank" class="toolbar-btn">arXiv: 2512.10935v1</a>
    <a href="https://arxiv.org/pdf/2512.10935.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10935v1" 
            onclick="toggleFavorite(this, '2512.10935v1', 'Any4D: Unified Feed-Forward Metric 4D Reconstruction')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jay Karhade, Nikhil Keetha, Yuchen Zhang, Tanisha Gupta, Akash Sharma, Sebastian Scherer, Deva Ramanan

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.LG, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-11

**Â§áÊ≥®**: Project Website: https://any-4d.github.io/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Any4DÔºöÁªü‰∏ÄÂâçÈ¶àÂºèÂ∫¶Èáè4DÈáçÂª∫Ê°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `4DÈáçÂª∫` `Â§öËßÜËßíÂ≠¶‰π†` `TransformerÁΩëÁªú` `Âú∫ÊôØÊµÅ‰º∞ËÆ°` `Â§öÊ®°ÊÄÅËûçÂêà`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ4DÈáçÂª∫ÊñπÊ≥ïÈÄöÂ∏∏Â±ÄÈôê‰∫éÂèåËßÜËßíÂú∫ÊôØÊµÅÊàñÁ®ÄÁñèÁÇπË∑üË∏™Ôºå‰∏îÈöæ‰ª•ËûçÂêàÂ§öÁßç‰º†ÊÑüÂô®Êï∞ÊçÆ„ÄÇ
2. Any4DÈááÁî®Ê®°ÂùóÂåñË°®Á§∫ÔºåÂà©Áî®Ëá™‰∏≠ÂøÉÂíåÊú¨‰∏≠ÂøÉÂõ†Á¥†ÁºñÁ†Å4DÂú∫ÊôØÔºåÂÆûÁé∞Â§öÊ®°ÊÄÅÊï∞ÊçÆËûçÂêà„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåAny4DÂú®Á≤æÂ∫¶‰∏äÊèêÂçá2-3ÂÄçÔºåËÆ°ÁÆóÊïàÁéáÊèêÂçá15ÂÄçÔºå‰∏∫‰∏ãÊ∏∏Â∫îÁî®Êèê‰æõÂèØËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫Any4DÔºå‰∏Ä‰∏™ÂèØÊâ©Â±ïÁöÑÂ§öËßÜËßíTransformerÔºåÁî®‰∫éÂ∫¶ÈáèÂ∞∫Â∫¶‰∏ãÁöÑÁ®†ÂØÜÂâçÈ¶àÂºè4DÈáçÂª∫„ÄÇAny4DÁõ¥Êé•ÁîüÊàêNÂ∏ßÁöÑÈÄêÂÉèÁ¥†ËøêÂä®ÂíåÂá†‰ΩïÈ¢ÑÊµãÔºåËøô‰∏é‰ª•ÂæÄ‰∏ªË¶ÅÂÖ≥Ê≥®ÂèåËßÜËßíÁ®†ÂØÜÂú∫ÊôØÊµÅÊàñÁ®ÄÁñè3DÁÇπË∑üË∏™ÁöÑÂ∑•‰Ωú‰∏çÂêå„ÄÇÊ≠§Â§ñÔºå‰∏éÂÖ∂‰ªñÊúÄËøëÁöÑÂçïÁõÆRGBËßÜÈ¢ë4DÈáçÂª∫ÊñπÊ≥ï‰∏çÂêåÔºåAny4DÂèØ‰ª•Â§ÑÁêÜÈ¢ùÂ§ñÁöÑÊ®°ÊÄÅÂíå‰º†ÊÑüÂô®Êï∞ÊçÆÔºå‰æãÂ¶ÇRGB-DÂ∏ß„ÄÅÂü∫‰∫éIMUÁöÑËá™ËøêÂä®ÂíåÈõ∑ËææÂ§öÊôÆÂãíÊµãÈáèÔºàÂ¶ÇÊûúÂèØÁî®Ôºâ„ÄÇËØ•Ê°ÜÊû∂ÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é4DÂú∫ÊôØÁöÑÊ®°ÂùóÂåñË°®Á§∫ÔºõÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊØè‰∏™ËßÜËßíÁöÑ4DÈ¢ÑÊµã‰ΩøÁî®‰ª•Â±ÄÈÉ®Áõ∏Êú∫ÂùêÊ†áË°®Á§∫ÁöÑÂêÑÁßçËá™‰∏≠ÂøÉÂõ†Á¥†ÔºàÊ∑±Â∫¶ÂõæÂíåÁõ∏Êú∫ÂÜÖÂèÇÔºâÂíå‰ª•ÂÖ®Â±Ä‰∏ñÁïåÂùêÊ†áË°®Á§∫ÁöÑÊú¨‰∏≠ÂøÉÂõ†Á¥†ÔºàÁõ∏Êú∫Â§ñÂèÇÂíåÂú∫ÊôØÊµÅÔºâËøõË°åÁºñÁ†Å„ÄÇÊàë‰ª¨Âú®ÂêÑÁßçËÆæÁΩÆ‰∏≠ÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩ‚Äî‚ÄîÂú®ÂáÜÁ°ÆÊÄßÔºàËØØÂ∑ÆÈôç‰Ωé2-3ÂÄçÔºâÂíåËÆ°ÁÆóÊïàÁéáÔºàÈÄüÂ∫¶ÊèêÈ´ò15ÂÄçÔºâÊñπÈù¢Ôºå‰∏∫Â§ö‰∏™‰∏ãÊ∏∏Â∫îÁî®ÂºÄËæü‰∫ÜÈÅìË∑Ø„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞Êúâ4DÈáçÂª∫ÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÂèåËßÜËßíÁ®†ÂØÜÂú∫ÊôØÊµÅÊàñÁ®ÄÁñè3DÁÇπË∑üË∏™ÔºåÈöæ‰ª•Â§ÑÁêÜÂ§öËßÜËßíÂíåÂ§öÊ®°ÊÄÅÊï∞ÊçÆÔºå‰æãÂ¶ÇRGB-D„ÄÅIMUÂíåÈõ∑Ëææ‰ø°ÊÅØ„ÄÇËøô‰∫õÊñπÊ≥ïÂú®Á≤æÂ∫¶„ÄÅÊïàÁéáÂíåÈÄöÁî®ÊÄßÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöAny4DÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈááÁî®‰∏ÄÁßçÊ®°ÂùóÂåñÁöÑ4DÂú∫ÊôØË°®Á§∫ÊñπÊ≥ïÔºåÂ∞ÜÂú∫ÊôØÂàÜËß£‰∏∫Ëá™‰∏≠ÂøÉÂõ†Á¥†ÔºàÂ¶ÇÊ∑±Â∫¶ÂõæÂíåÁõ∏Êú∫ÂÜÖÂèÇÔºåÂú®Â±ÄÈÉ®Áõ∏Êú∫ÂùêÊ†áÁ≥ª‰∏ãË°®Á§∫ÔºâÂíåÊú¨‰∏≠ÂøÉÂõ†Á¥†ÔºàÂ¶ÇÁõ∏Êú∫Â§ñÂèÇÂíåÂú∫ÊôØÊµÅÔºåÂú®ÂÖ®Â±Ä‰∏ñÁïåÂùêÊ†áÁ≥ª‰∏ãË°®Á§∫Ôºâ„ÄÇËøôÁßçËß£ËÄ¶ÁöÑËÆæËÆ°‰ΩøÂæóAny4DËÉΩÂ§üÁÅµÊ¥ªÂú∞ËûçÂêàÊù•Ëá™‰∏çÂêå‰º†ÊÑüÂô®ÁöÑÊï∞ÊçÆÔºåÂπ∂ËøõË°åÈ´òÊïàÁöÑ4DÈáçÂª∫„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAny4DÈááÁî®‰∏Ä‰∏™Â§öËßÜËßíTransformerÊû∂ÊûÑÔºåËæìÂÖ•‰∏∫Â§öÂ∏ßÂõæÂÉè‰ª•ÂèäÂèØÈÄâÁöÑRGB-DÊï∞ÊçÆ„ÄÅIMUÊï∞ÊçÆÂíåÈõ∑ËææÊï∞ÊçÆ„ÄÇËØ•ÁΩëÁªúÈ¶ñÂÖàÊèêÂèñÊØè‰∏™ËßÜËßíÁöÑÁâπÂæÅÔºåÁÑ∂ÂêéÂà©Áî®TransformerËøõË°åË∑®ËßÜËßíÁöÑ‰ø°ÊÅØËûçÂêà„ÄÇÁΩëÁªúËæìÂá∫ÊØè‰∏™ÂÉèÁ¥†ÁöÑËøêÂä®ÂíåÂá†‰ΩïÈ¢ÑÊµãÔºåÂåÖÊã¨Ê∑±Â∫¶Âõæ„ÄÅÂú∫ÊôØÊµÅÂíåÁõ∏Êú∫‰ΩçÂßø„ÄÇËøô‰∫õÈ¢ÑÊµãÂàÜÂà´Âú®Â±ÄÈÉ®Áõ∏Êú∫ÂùêÊ†áÁ≥ªÂíåÂÖ®Â±Ä‰∏ñÁïåÂùêÊ†áÁ≥ª‰∏ãË°®Á§∫„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAny4DÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Ê®°ÂùóÂåñÁöÑ4DÂú∫ÊôØË°®Á§∫ÊñπÊ≥ïÔºå‰ª•ÂèäËÉΩÂ§üÂ§ÑÁêÜÂ§öÁßç‰º†ÊÑüÂô®Êï∞ÊçÆÁöÑËÉΩÂäõ„ÄÇÈÄöËøáÂ∞ÜÂú∫ÊôØÂàÜËß£‰∏∫Ëá™‰∏≠ÂøÉÂíåÊú¨‰∏≠ÂøÉÂõ†Á¥†ÔºåAny4DËÉΩÂ§üÊúâÊïàÂú∞ËûçÂêàÊù•Ëá™‰∏çÂêåËßÜËßíÁöÑÂíå‰∏çÂêåÊ®°ÊÄÅÁöÑ‰ø°ÊÅØÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÂáÜÁ°ÆÂíåÈ≤ÅÊ£íÁöÑ4DÈáçÂª∫„ÄÇÊ≠§Â§ñÔºåAny4DÈááÁî®ÂâçÈ¶àÂºèÊû∂ÊûÑÔºåÈÅøÂÖç‰∫ÜËø≠‰ª£‰ºòÂåñÔºåÊèêÈ´ò‰∫ÜËÆ°ÁÆóÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAny4D‰ΩøÁî®TransformerËøõË°åË∑®ËßÜËßí‰ø°ÊÅØËûçÂêàÔºåÂπ∂ËÆæËÆ°‰∫Ü‰∏ìÈó®ÁöÑÊçüÂ§±ÂáΩÊï∞Êù•Á∫¶ÊùüÊ∑±Â∫¶Âõæ„ÄÅÂú∫ÊôØÊµÅÂíåÁõ∏Êú∫‰ΩçÂßøÁöÑÈ¢ÑÊµã„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÂÖâÂ∫¶‰∏ÄËá¥ÊÄßÊçüÂ§±„ÄÅÂá†‰Ωï‰∏ÄËá¥ÊÄßÊçüÂ§±ÂíåËøêÂä®‰∏ÄËá¥ÊÄßÊçüÂ§±„ÄÇÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÊ†πÊçÆ‰∏çÂêåÁöÑÊï∞ÊçÆÈõÜÂíå‰ªªÂä°ËøõË°åË∞ÉÊï¥„ÄÇÂÖ∑‰ΩìÁªÜËäÇÊú™Âú®ÊëòË¶Å‰∏≠ËØ¶ÁªÜËØ¥ÊòéÔºåÈúÄË¶ÅÂèÇËÄÉËÆ∫ÊñáÂÖ®Êñá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Any4DÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÊëòË¶Å‰∏≠ÊèêÂà∞ÔºåAny4DÂú®Á≤æÂ∫¶‰∏äÊØîÁé∞ÊúâÊñπÊ≥ïÊèêÂçá‰∫Ü2-3ÂÄçÔºàËØØÂ∑ÆÈôç‰Ωé2-3ÂÄçÔºâÔºåËÆ°ÁÆóÊïàÁéáÊèêÂçá‰∫Ü15ÂÄç„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéAny4DÂú®4DÈáçÂª∫ÊñπÈù¢ÂÖ∑ÊúâÊòæËëóÁöÑ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Any4DÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨Ëá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÂíåËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÊûÑÂª∫Âä®ÊÄÅÂú∫ÊôØÁöÑ‰∏âÁª¥Ê®°ÂûãÔºå‰º∞ËÆ°Áâ©‰ΩìÁöÑËøêÂä®ËΩ®ËøπÔºå‰ª•ÂèäËøõË°åÂú∫ÊôØÁêÜËß£ÂíåÈ¢ÑÊµã„ÄÇËØ•Á†îÁ©∂ÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂú®‰∫éÊèêÈ´ò‰∫Ü4DÈáçÂª∫ÁöÑÁ≤æÂ∫¶ÂíåÊïàÁéáÔºå‰∏∫‰∏ãÊ∏∏Â∫îÁî®Êèê‰æõ‰∫ÜÊõ¥ÂèØÈù†ÁöÑÊï∞ÊçÆÂü∫Á°Ä„ÄÇÊú™Êù•ÔºåAny4DÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞Êõ¥Â§ßËßÑÊ®°ÁöÑÂú∫ÊôØÂíåÊõ¥Â§çÊùÇÁöÑÂä®ÊÄÅÁéØÂ¢É„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We present Any4D, a scalable multi-view transformer for metric-scale, dense feed-forward 4D reconstruction. Any4D directly generates per-pixel motion and geometry predictions for N frames, in contrast to prior work that typically focuses on either 2-view dense scene flow or sparse 3D point tracking. Moreover, unlike other recent methods for 4D reconstruction from monocular RGB videos, Any4D can process additional modalities and sensors such as RGB-D frames, IMU-based egomotion, and Radar Doppler measurements, when available. One of the key innovations that allows for such a flexible framework is a modular representation of a 4D scene; specifically, per-view 4D predictions are encoded using a variety of egocentric factors (depthmaps and camera intrinsics) represented in local camera coordinates, and allocentric factors (camera extrinsics and scene flow) represented in global world coordinates. We achieve superior performance across diverse setups - both in terms of accuracy (2-3X lower error) and compute efficiency (15X faster), opening avenues for multiple downstream applications.

