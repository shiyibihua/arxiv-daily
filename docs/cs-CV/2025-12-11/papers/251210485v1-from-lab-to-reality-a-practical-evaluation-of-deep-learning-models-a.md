---
layout: default
title: From Lab to Reality: A Practical Evaluation of Deep Learning Models and LLMs for Vulnerability Detection
---

# From Lab to Reality: A Practical Evaluation of Deep Learning Models and LLMs for Vulnerability Detection

**arXiv**: [2512.10485v1](https://arxiv.org/abs/2512.10485) | [PDF](https://arxiv.org/pdf/2512.10485.pdf)

**ä½œè€…**: Chaomeng Lu, Bert Lagaisse

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°æ·±åº¦å­¦ä¹ ä¸ŽLLMåœ¨æ¼æ´žæ£€æµ‹ä¸­çš„å®žé™…åº”ç”¨ï¼Œæ­ç¤ºå­¦æœ¯åŸºå‡†ä¸ŽçŽ°å®žéƒ¨ç½²é—´çš„å·®è·**

**å…³é”®è¯**: `æ¼æ´žæ£€æµ‹` `æ·±åº¦å­¦ä¹ æ¨¡åž‹` `å¤§è¯­è¨€æ¨¡åž‹` `æ³›åŒ–è¯„ä¼°` `ä»£ç è¡¨ç¤ºåˆ†æž` `éƒ¨ç½²æ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ·±åº¦å­¦ä¹ æ¨¡åž‹åœ¨åŸºå‡†æ•°æ®é›†ä¸Šè¡¨çŽ°è‰¯å¥½ï¼Œä½†çœŸå®žä¸–ç•Œæœ‰æ•ˆæ€§æœªçŸ¥ï¼Œå­˜åœ¨æ³›åŒ–æŒ‘æˆ˜
2. æ–¹æ³•è¦ç‚¹ï¼šç³»ç»Ÿè¯„ä¼°ReVealå’ŒLineVulæ¨¡åž‹ï¼Œç»“åˆLLMsåœ¨VentiVulæ•°æ®é›†ä¸Šè¿›è¡Œéƒ¨ç½²æµ‹è¯•
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¨¡åž‹åœ¨è¡¨ç¤ºç©ºé—´éš¾ä»¥åŒºåˆ†æ¼æ´žï¼Œè·¨æ•°æ®é›†æ³›åŒ–å·®ï¼ŒVentiVulä¸Šæ€§èƒ½å¤§å¹…ä¸‹é™

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vulnerability detection methods based on deep learning (DL) have shown strong performance on benchmark datasets, yet their real-world effectiveness remains underexplored. Recent work suggests that both graph neural network (GNN)-based and transformer-based models, including large language models (LLMs), yield promising results when evaluated on curated benchmark datasets. These datasets are typically characterized by consistent data distributions and heuristic or partially noisy labels. In this study, we systematically evaluate two representative DL models-ReVeal and LineVul-across four representative datasets: Juliet, Devign, BigVul, and ICVul. Each model is trained independently on each respective dataset, and their code representations are analyzed using t-SNE to uncover vulnerability related patterns. To assess realistic applicability, we deploy these models along with four pretrained LLMs, Claude 3.5 Sonnet, GPT-o3-mini, GPT-4o, and GPT-5 on a curated dataset, VentiVul, comprising 20 recently (May 2025) fixed vulnerabilities from the Linux kernel. Our experiments reveal that current models struggle to distinguish vulnerable from non-vulnerable code in representation space and generalize poorly across datasets with differing distributions. When evaluated on VentiVul, our newly constructed time-wise out-of-distribution dataset, performance drops sharply, with most models failing to detect vulnerabilities reliably. These results expose a persistent gap between academic benchmarks and real-world deployment, emphasizing the value of our deployment-oriented evaluation framework and the need for more robust code representations and higher-quality datasets.

