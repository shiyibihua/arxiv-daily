---
layout: default
title: Is the Information Bottleneck Robust Enough? Towards Label-Noise Resistant Information Bottleneck Learning
---

# Is the Information Bottleneck Robust Enough? Towards Label-Noise Resistant Information Bottleneck Learning

**arXiv**: [2512.10573v1](https://arxiv.org/abs/2512.10573) | [PDF](https://arxiv.org/pdf/2512.10573.pdf)

**ä½œè€…**: Yi Huang, Qingyun Sun, Yisen Gao, Haonan Yuan, Xingcheng Fu, Jianxin Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLaT-IBæ–¹æ³•ä»¥è§£å†³ä¿¡æ¯ç“¶é¢ˆåœ¨æ ‡ç­¾å™ªå£°ä¸‹çš„è„†å¼±æ€§é—®é¢˜**

**å…³é”®è¯**: `ä¿¡æ¯ç“¶é¢ˆ` `æ ‡ç­¾å™ªå£°é²æ£’æ€§` `æ½œåœ¨è§£è€¦` `äº’ä¿¡æ¯æ­£åˆ™åŒ–` `è¡¨ç¤ºå­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¿¡æ¯ç“¶é¢ˆä¾èµ–å‡†ç¡®æ ‡ç­¾ï¼Œæ˜“å—æ ‡ç­¾å™ªå£°å½±å“å¯¼è‡´æ€§èƒ½ä¸‹é™
2. å¼•å…¥æœ€å°å……åˆ†æ¸…æ´å‡†åˆ™ï¼Œé€šè¿‡å™ªå£°æ„ŸçŸ¥æ½œåœ¨è§£è€¦åˆ†ç¦»å¹²å‡€ä¸Žå™ªå£°ä¿¡æ¯
3. å®žéªŒæ˜¾ç¤ºLaT-IBåœ¨æ ‡ç­¾å™ªå£°ä¸‹å…·æœ‰ä¼˜è¶Šçš„é²æ£’æ€§å’Œæ•ˆçŽ‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The Information Bottleneck (IB) principle facilitates effective representation learning by preserving label-relevant information while compressing irrelevant information. However, its strong reliance on accurate labels makes it inherently vulnerable to label noise, prevalent in real-world scenarios, resulting in significant performance degradation and overfitting. To address this issue, we propose LaT-IB, a novel Label-Noise ResistanT Information Bottleneck method which introduces a "Minimal-Sufficient-Clean" (MSC) criterion. Instantiated as a mutual information regularizer to retain task-relevant information while discarding noise, MSC addresses standard IB's vulnerability to noisy label supervision. To achieve this, LaT-IB employs a noise-aware latent disentanglement that decomposes the latent representation into components aligned with to the clean label space and the noise space. Theoretically, we first derive mutual information bounds for each component of our objective including prediction, compression, and disentanglement, and moreover prove that optimizing it encourages representations invariant to input noise and separates clean and noisy label information. Furthermore, we design a three-phase training framework: Warmup, Knowledge Injection and Robust Training, to progressively guide the model toward noise-resistant representations. Extensive experiments demonstrate that LaT-IB achieves superior robustness and efficiency under label noise, significantly enhancing robustness and applicability in real-world scenarios with label noise.

