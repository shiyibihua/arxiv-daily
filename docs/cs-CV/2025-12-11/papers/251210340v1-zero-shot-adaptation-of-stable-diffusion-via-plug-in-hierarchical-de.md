---
layout: default
title: Zero-shot Adaptation of Stable Diffusion via Plug-in Hierarchical Degradation Representation for Real-World Super-Resolution
---

# Zero-shot Adaptation of Stable Diffusion via Plug-in Hierarchical Degradation Representation for Real-World Super-Resolution

**arXiv**: [2512.10340v1](https://arxiv.org/abs/2512.10340) | [PDF](https://arxiv.org/pdf/2512.10340.pdf)

**ä½œè€…**: Yi-Cheng Liao, Shyang-En Weng, Yu-Syuan Xu, Chi-Wei Hsiao, Wei-Chen Chiu, Ching-Chun Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHD-CLIPæ’ä»¶æ¨¡å—ä»¥è§£å†³çœŸå®žä¸–ç•Œè¶…åˆ†è¾¨çŽ‡ä¸­æœªçŸ¥å¤æ‚é€€åŒ–é—®é¢˜**

**å…³é”®è¯**: `çœŸå®žä¸–ç•Œè¶…åˆ†è¾¨çŽ‡` `æ‰©æ•£æ¨¡åž‹` `é€€åŒ–è¡¨ç¤º` `é›¶æ ·æœ¬é€‚åº”` `å³æ’å³ç”¨æ¨¡å—` `åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçœŸå®žä¸–ç•Œå›¾åƒè¶…åˆ†è¾¨çŽ‡é¢ä¸´æœªçŸ¥è€¦åˆé€€åŒ–ï¼ŒçŽ°æœ‰æ–¹æ³•ä¾èµ–å·²çŸ¥é€€åŒ–ç¨‹åº¦ä¸”CLIPæ— æ³•æ•æ‰æ•°å€¼ä¸¥é‡æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šHD-CLIPå°†ä½Žè´¨é‡å›¾åƒåˆ†è§£ä¸ºè¯­ä¹‰åµŒå…¥å’Œæœ‰åºé€€åŒ–åµŒå…¥ï¼Œæ”¯æŒæœªè§é€€åŒ–çº§åˆ«çš„æ’å€¼ï¼Œé€šè¿‡CFGå’ŒCFPGé›†æˆåˆ°æ‰©æ•£æ¨¡åž‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šä½œä¸ºå³æ’å³ç”¨æ¨¡å—ï¼Œæ— éœ€è®­ç»ƒå³å¯æå‡å¤šç§æ¡†æž¶çš„ç»†èŠ‚ä¿çœŸåº¦å’Œæ„ŸçŸ¥çœŸå®žæ„Ÿï¼Œåœ¨å¤šæ ·æ•°æ®é›†ä¸ŠéªŒè¯æœ‰æ•ˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Real-World Image Super-Resolution (Real-ISR) aims to recover high-quality images from low-quality inputs degraded by unknown and complex real-world factors. Real-world scenarios involve diverse and coupled degradations, making it necessary to provide diffusion models with richer and more informative guidance. However, existing methods often assume known degradation severity and rely on CLIP text encoders that cannot capture numerical severity, limiting their generalization ability. To address this, we propose \textbf{HD-CLIP} (\textbf{H}ierarchical \textbf{D}egradation CLIP), which decomposes a low-quality image into a semantic embedding and an ordinal degradation embedding that captures ordered relationships and allows interpolation across unseen levels. Furthermore, we integrated it into diffusion models via classifier-free guidance (CFG) and proposed classifier-free projection guidance (CFPG). HD-CLIP leverages semantic cues to guide generative restoration while using degradation cues to suppress undesired hallucinations and artifacts. As a \textbf{plug-and-play module}, HD-CLIP can be seamlessly integrated into various super-resolution frameworks without training, significantly improving detail fidelity and perceptual realism across diverse real-world datasets.

