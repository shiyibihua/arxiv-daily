---
layout: default
title: ConStruct: Structural Distillation of Foundation Models for Prototype-Based Weakly Supervised Histopathology Segmentation
---

# ConStruct: Structural Distillation of Foundation Models for Prototype-Based Weakly Supervised Histopathology Segmentation

**arXiv**: [2512.10316v1](https://arxiv.org/abs/2512.10316) | [PDF](https://arxiv.org/pdf/2512.10316.pdf)

**ä½œè€…**: Khang Le, Ha Thach, Anh M. Vu, Trang T. K. Vo, Han H. Huynh, David Yang, Minh H. N. Le, Thanh-Huy Nguyen, Akash Awasthi, Chandra Mohan, Zhu Han, Hien Van Nguyen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŽŸåž‹å­¦ä¹ æ¡†æž¶ä»¥è§£å†³å¼±ç›‘ç£ç»„ç»‡ç—…ç†å­¦åˆ†å‰²ä¸­ç»“æž„å®Œæ•´æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§é—®é¢˜**

**å…³é”®è¯**: `å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²` `ç»„ç»‡ç—…ç†å­¦å›¾åƒ` `åŽŸåž‹å­¦ä¹ ` `ç»“æž„è’¸é¦` `æ–‡æœ¬å¼•å¯¼å¯¹é½` `åŸºç¡€æ¨¡åž‹é›†æˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¼±ç›‘ç£ç»„ç»‡ç—…ç†å­¦åˆ†å‰²ä¸­åˆ†ç±»æ¨¡åž‹ä»…å®šä½æœ€æ˜¾è‘—åŒºåŸŸï¼Œéš¾ä»¥æ•èŽ·ç»„ç»‡ç»“æž„çš„å®Œæ•´ç©ºé—´èŒƒå›´ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆCONCHçš„å½¢æ€æ„ŸçŸ¥è¡¨ç¤ºã€SegFormerçš„å¤šå°ºåº¦ç»“æž„çº¿ç´¢å’Œæ–‡æœ¬å¼•å¯¼è¯­ä¹‰å¯¹é½ï¼Œé€šè¿‡æ–‡æœ¬å¼•å¯¼åŽŸåž‹åˆå§‹åŒ–å’Œç»“æž„è’¸é¦æœºåˆ¶ç”Ÿæˆé«˜è´¨é‡ä¼ªæŽ©ç ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨BCSS-WSSSæ•°æ®é›†ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œæå‡å®šä½å®Œæ•´æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§ï¼Œè®¡ç®—é«˜æ•ˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Weakly supervised semantic segmentation (WSSS) in histopathology relies heavily on classification backbones, yet these models often localize only the most discriminative regions and struggle to capture the full spatial extent of tissue structures. Vision-language models such as CONCH offer rich semantic alignment and morphology-aware representations, while modern segmentation backbones like SegFormer preserve fine-grained spatial cues. However, combining these complementary strengths remains challenging, especially under weak supervision and without dense annotations. We propose a prototype learning framework for WSSS in histopathological images that integrates morphology-aware representations from CONCH, multi-scale structural cues from SegFormer, and text-guided semantic alignment to produce prototypes that are simultaneously semantically discriminative and spatially coherent. To effectively leverage these heterogeneous sources, we introduce text-guided prototype initialization that incorporates pathology descriptions to generate more complete and semantically accurate pseudo-masks. A structural distillation mechanism transfers spatial knowledge from SegFormer to preserve fine-grained morphological patterns and local tissue boundaries during prototype learning. Our approach produces high-quality pseudo masks without pixel-level annotations, improves localization completeness, and enhances semantic consistency across tissue types. Experiments on BCSS-WSSS datasets demonstrate that our prototype learning framework outperforms existing WSSS methods while remaining computationally efficient through frozen foundation model backbones and lightweight trainable adapters.

