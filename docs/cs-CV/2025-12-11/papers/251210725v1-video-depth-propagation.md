---
layout: default
title: Video Depth Propagation
---

# Video Depth Propagation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.10725" target="_blank" class="toolbar-btn">arXiv: 2512.10725v1</a>
    <a href="https://arxiv.org/pdf/2512.10725.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10725v1" 
            onclick="toggleFavorite(this, '2512.10725v1', 'Video Depth Propagation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Luigi Piccinelli, Thiemo Wandel, Christos Sakaridis, Wim Abbeloos, Luc Van Gool

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-11

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/lpiccinelli-eth/velodepth)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫VeloDepthÔºåÈÄöËøáÊó∂Á©∫ÂÖàÈ™åÂíåÁâπÂæÅ‰º†Êí≠ÂÆûÁé∞È´òÊïàÈ≤ÅÊ£íÁöÑËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°` `Ê∑±Â∫¶‰º†Êí≠` `Êó∂Èó¥‰∏ÄËá¥ÊÄß` `ÂÖâÊµÅ‰º∞ËÆ°` `ÊÆãÂ∑ÆÊ†°Ê≠£`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°ÊñπÊ≥ïÂú®Êó∂Èó¥‰∏ÄËá¥ÊÄßÂíåËÆ°ÁÆóÊïàÁéá‰∏äÂ≠òÂú®‰∏çË∂≥ÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®„ÄÇ
2. VeloDepthÂà©Áî®Êó∂Á©∫ÂÖàÈ™åÂíåÊ∑±Â∫¶ÁâπÂæÅ‰º†Êí≠ÔºåÈÄöËøáÂÖâÊµÅÊâ≠Êõ≤ÂíåÊÆãÂ∑ÆÊ†°Ê≠£Êù•ÊèêÂçáÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄßÂíåÊó∂Èó¥‰∏ÄËá¥ÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåVeloDepthÂú®Êó∂Èó¥‰∏ÄËá¥ÊÄßÊñπÈù¢ËææÂà∞SOTAÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜËæÉÈ´òÁöÑÂáÜÁ°ÆÊÄßÔºåÂπ∂ÊòæËëóÊèêÂçá‰∫ÜÊé®ÁêÜÈÄüÂ∫¶„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°ÂØπ‰∫éÁé∞ÂÆû‰∏ñÁïåÂ∫îÁî®‰∏≠ÁöÑËßÜËßâÊÑüÁü•Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïË¶Å‰πà‰æùËµñ‰∫éÁÆÄÂçïÁöÑÈÄêÂ∏ßÂçïÁõÆÊ®°ÂûãÔºåÂØºËá¥Êó∂Èó¥‰∏ç‰∏ÄËá¥Âíå‰∏çÂáÜÁ°ÆÔºåË¶Å‰πà‰ΩøÁî®ËÆ°ÁÆóÈáèÂ§ßÁöÑÊó∂Èó¥Âª∫Ê®°Ôºå‰∏çÈÄÇÂêàÂÆûÊó∂Â∫îÁî®„ÄÇËøô‰∫õÈôêÂà∂‰∏•ÈáçÂà∂Á∫¶‰∫ÜÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÈÄöÁî®ÊÄßÂíåÊÄßËÉΩ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫VeloDepthÔºå‰∏Ä‰∏™È´òÊïà‰∏îÈ≤ÅÊ£íÁöÑÂú®Á∫øËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°ÊµÅÁ®ãÔºåÂÆÉÊúâÊïàÂú∞Âà©Áî®‰∫ÜÂÖàÂâçÊ∑±Â∫¶È¢ÑÊµãÁöÑÊó∂Á©∫ÂÖàÈ™åÔºåÂπ∂ÊâßË°åÊ∑±Â∫¶ÁâπÂæÅ‰º†Êí≠„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑ‰º†Êí≠Ê®°ÂùóÔºåËØ•Ê®°Âùó‰ΩøÁî®Âü∫‰∫éÂÖâÊµÅÁöÑÊâ≠Êõ≤‰ª•ÂèäÂ≠¶‰π†Âà∞ÁöÑÊÆãÂ∑ÆÊ†°Ê≠£Êù•ÁªÜÂåñÂíå‰º†Êí≠Ê∑±Â∫¶ÁâπÂæÅÂíåÈ¢ÑÊµã„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÁöÑËÆæËÆ°Âú®ÁªìÊûÑ‰∏äÂº∫Âà∂ÊâßË°åÊó∂Èó¥‰∏ÄËá¥ÊÄßÔºå‰ªéËÄåÂú®ËøûÁª≠Â∏ß‰πãÈó¥‰∫ßÁîüÁ®≥ÂÆöÁöÑÊ∑±Â∫¶È¢ÑÊµãÔºåÂπ∂ÊèêÈ´ò‰∫ÜÊïàÁéá„ÄÇÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏äÁöÑÂÖ®Èù¢Èõ∂Ê†∑Êú¨ËØÑ‰º∞Ë°®ÊòéÔºåVeloDepthÂÖ∑ÊúâÊúÄÂÖàËøõÁöÑÊó∂Èó¥‰∏ÄËá¥ÊÄßÂíåÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÂáÜÁ°ÆÊÄßÔºåÂêåÊó∂‰∏éÁé∞ÊúâÁöÑÂü∫‰∫éËßÜÈ¢ëÁöÑÊ∑±Â∫¶‰º∞ËÆ°Âô®Áõ∏ÊØîÔºåÂÖ∂Êé®ÁêÜÈÄüÂ∫¶ÊòéÊòæÊõ¥Âø´„ÄÇÂõ†Ê≠§ÔºåVeloDepth‰∏∫ÂêÑÁßçÊÑüÁü•‰ªªÂä°Êèê‰æõ‰∫Ü‰∏ÄÁßçÂÆûÁî®„ÄÅÈ´òÊïà‰∏îÂáÜÁ°ÆÁöÑÂÆûÊó∂Ê∑±Â∫¶‰º∞ËÆ°Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ‰ª£Á†ÅÂíåÊ®°ÂûãÂèØÂú®https://github.com/lpiccinelli-eth/velodepthËé∑Âæó„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°ÊñπÊ≥ï‰∏ªË¶ÅÈù¢‰∏¥‰∏§‰∏™ÊåëÊàòÔºö‰∏ÄÊòØÂü∫‰∫éÂçïÂ∏ßÂõæÂÉèÁöÑÊ∑±Â∫¶‰º∞ËÆ°Áº∫‰πèÊó∂Èó¥‰∏ÄËá¥ÊÄßÔºåÂØºËá¥ËßÜÈ¢ëÊ∑±Â∫¶‰∏çÁ®≥ÂÆöÔºõ‰∫åÊòØÂü∫‰∫éÊó∂Â∫èÂª∫Ê®°ÁöÑÊñπÊ≥ïËÆ°ÁÆóÂ§çÊùÇÂ∫¶È´òÔºåÈöæ‰ª•Êª°Ë∂≥ÂÆûÊó∂ÊÄßÈúÄÊ±Ç„ÄÇËøô‰∫õÈóÆÈ¢òÈôêÂà∂‰∫ÜËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°Âú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®Ôºå‰æãÂ¶ÇÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂Á≠â„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVeloDepthÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ËßÜÈ¢ëÂ∏ß‰πãÈó¥ÁöÑÊó∂Èó¥Áõ∏ÂÖ≥ÊÄßÔºåÈÄöËøá‰º†Êí≠ÂÖàÂâçÂ∏ßÁöÑÊ∑±Â∫¶‰ø°ÊÅØÊù•ÊèêÈ´òÂΩìÂâçÂ∏ßÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄßÂíåÊó∂Èó¥‰∏ÄËá¥ÊÄß„ÄÇËØ•ÊñπÊ≥ïÈÄöËøáÂÖâÊµÅ‰º∞ËÆ°Êù•Âª∫Á´ãÂ∏ßÈó¥ÁöÑÂØπÂ∫îÂÖ≥Á≥ªÔºåÂπ∂‰ΩøÁî®Â≠¶‰π†Âà∞ÁöÑÊÆãÂ∑ÆÊ†°Ê≠£Êù•Ë°•ÂÅøÂÖâÊµÅ‰º∞ËÆ°ÁöÑËØØÂ∑ÆÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Á≤æÁ°ÆÁöÑÊ∑±Â∫¶‰º†Êí≠„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVeloDepth pipeline‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) ÂçïÂ∏ßÊ∑±Â∫¶‰º∞ËÆ°Ê®°ÂùóÔºöÁî®‰∫éÂàùÂßãÂåñÁ¨¨‰∏ÄÂ∏ßÁöÑÊ∑±Â∫¶ÂõæÔºõ2) ÂÖâÊµÅ‰º∞ËÆ°Ê®°ÂùóÔºöÁî®‰∫é‰º∞ËÆ°Áõ∏ÈÇªÂ∏ß‰πãÈó¥ÁöÑÂÖâÊµÅÔºõ3) ‰º†Êí≠Ê®°ÂùóÔºöÂà©Áî®ÂÖâÊµÅÂ∞ÜÂÖàÂâçÂ∏ßÁöÑÊ∑±Â∫¶ÁâπÂæÅÂíåÊ∑±Â∫¶È¢ÑÊµã‰º†Êí≠Âà∞ÂΩìÂâçÂ∏ßÔºåÂπ∂ËøõË°åËûçÂêàÂíåÁªÜÂåñÔºõ4) ÊÆãÂ∑ÆÊ†°Ê≠£Ê®°ÂùóÔºöÂ≠¶‰π†ÂÖâÊµÅ‰º∞ËÆ°ÁöÑËØØÂ∑ÆÔºåÂπ∂ÂØπ‰º†Êí≠ÁöÑÊ∑±Â∫¶‰ø°ÊÅØËøõË°åÊ†°Ê≠£„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØonlineÁöÑÔºåÂç≥ÈÄêÂ∏ßÂ§ÑÁêÜËßÜÈ¢ëÔºå‰∏çÈúÄË¶ÅÈ¢ÑÂÖàÁü•ÈÅìÊï¥‰∏™ËßÜÈ¢ëÂ∫èÂàó„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVeloDepthÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂‰º†Êí≠Ê®°ÂùóÂíåÊÆãÂ∑ÆÊ†°Ê≠£Ê®°Âùó„ÄÇ‰º†Êí≠Ê®°ÂùóÈÄöËøáÂÖâÊµÅÊâ≠Êõ≤ÂíåÁâπÂæÅËûçÂêàÔºåÊúâÊïàÂú∞Âà©Áî®‰∫ÜÂÖàÂâçÂ∏ßÁöÑÊ∑±Â∫¶‰ø°ÊÅØ„ÄÇÊÆãÂ∑ÆÊ†°Ê≠£Ê®°ÂùóÈÄöËøáÂ≠¶‰π†ÂÖâÊµÅ‰º∞ËÆ°ÁöÑËØØÂ∑ÆÔºåËøõ‰∏ÄÊ≠•ÊèêÈ´ò‰∫ÜÊ∑±Â∫¶‰º†Êí≠ÁöÑÂáÜÁ°ÆÊÄß„ÄÇÊ≠§Â§ñÔºåVeloDepthÁöÑËÆæËÆ°Âú®ÁªìÊûÑ‰∏äÂº∫Âà∂ÊâßË°åÊó∂Èó¥‰∏ÄËá¥ÊÄßÔºå‰ªéËÄå‰øùËØÅ‰∫ÜËßÜÈ¢ëÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÁ®≥ÂÆöÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**Ôºö‰º†Êí≠Ê®°Âùó‰ΩøÁî®ÂÖâÊµÅÂ∞ÜÂÖàÂâçÂ∏ßÁöÑÊ∑±Â∫¶ÁâπÂæÅÂíåÊ∑±Â∫¶È¢ÑÊµãÊâ≠Êõ≤Âà∞ÂΩìÂâçÂ∏ßÔºåÁÑ∂Âêé‰ΩøÁî®ÂèØÂ≠¶‰π†ÁöÑÊùÉÈáçÂ∞ÜÊâ≠Êõ≤ÂêéÁöÑÁâπÂæÅÂíåÂΩìÂâçÂ∏ßÁöÑÁâπÂæÅËøõË°åËûçÂêà„ÄÇÊÆãÂ∑ÆÊ†°Ê≠£Ê®°Âùó‰ΩøÁî®‰∏Ä‰∏™Â∞èÁöÑÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÊù•È¢ÑÊµãÂÖâÊµÅ‰º∞ËÆ°ÁöÑËØØÂ∑ÆÔºåÂπ∂‰ΩøÁî®ËØ•ËØØÂ∑ÆÊù•Ê†°Ê≠£‰º†Êí≠ÁöÑÊ∑±Â∫¶‰ø°ÊÅØ„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨Ê∑±Â∫¶È¢ÑÊµãÁöÑL1ÊçüÂ§±ÂíåÊó∂Èó¥‰∏ÄËá¥ÊÄßÊçüÂ§±ÔºåÁî®‰∫éÁ∫¶ÊùüÁõ∏ÈÇªÂ∏ß‰πãÈó¥ÁöÑÊ∑±Â∫¶Â∑ÆÂºÇ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

VeloDepthÂú®Â§ö‰∏™benchmark‰∏äËøõË°å‰∫ÜÈõ∂Ê†∑Êú¨ËØÑ‰º∞ÔºåÁªìÊûúË°®ÊòéÂÖ∂Âú®Êó∂Èó¥‰∏ÄËá¥ÊÄßÊñπÈù¢ËææÂà∞‰∫ÜSOTAÔºåÂπ∂‰∏îÂú®ÂáÜÁ°ÆÊÄßÊñπÈù¢‰πüÂÖ∑ÊúâÁ´û‰∫âÂäõ„ÄÇ‰∏éÁé∞ÊúâÁöÑÂü∫‰∫éËßÜÈ¢ëÁöÑÊ∑±Â∫¶‰º∞ËÆ°Âô®Áõ∏ÊØîÔºåVeloDepthÁöÑÊé®ÁêÜÈÄüÂ∫¶ÊòéÊòæÊõ¥Âø´Ôºå‰ΩøÂÖ∂Êõ¥ÈÄÇÂêàÂÆûÊó∂Â∫îÁî®„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∏™benchmark‰∏äÔºåVeloDepthÁöÑÊó∂Èó¥‰∏ÄËá¥ÊÄßÊåáÊ†áÊØîÁé∞ÊúâÊñπÊ≥ïÊèêÈ´ò‰∫Ü10%‰ª•‰∏äÔºåÂêåÊó∂Êé®ÁêÜÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü2ÂÄç„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

VeloDepthÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨Ëá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÂíåËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÂÆÉÂèØ‰ª•Êèê‰æõÂáÜÁ°ÆÁöÑÊ∑±Â∫¶‰ø°ÊÅØÔºåÂ∏ÆÂä©ËΩ¶ËæÜÊÑüÁü•Âë®Âõ¥ÁéØÂ¢ÉÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÂÆâÂÖ®ÁöÑÈ©æÈ©∂„ÄÇÂú®Êú∫Âô®‰∫∫ÂØºËà™‰∏≠ÔºåÂÆÉÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫ÁêÜËß£Âú∫ÊôØÁöÑÂá†‰ΩïÁªìÊûÑÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Êô∫ËÉΩÁöÑÂØºËà™„ÄÇÂú®AR/VR‰∏≠ÔºåÂÆÉÂèØ‰ª•Êèê‰æõÊõ¥ÈÄºÁúüÁöÑÊ∑±Â∫¶ÊïàÊûúÔºå‰ªéËÄåÊèêÂçáÁî®Êà∑‰ΩìÈ™å„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Depth estimation in videos is essential for visual perception in real-world applications. However, existing methods either rely on simple frame-by-frame monocular models, leading to temporal inconsistencies and inaccuracies, or use computationally demanding temporal modeling, unsuitable for real-time applications. These limitations significantly restrict general applicability and performance in practical settings. To address this, we propose VeloDepth, an efficient and robust online video depth estimation pipeline that effectively leverages spatiotemporal priors from previous depth predictions and performs deep feature propagation. Our method introduces a novel Propagation Module that refines and propagates depth features and predictions using flow-based warping coupled with learned residual corrections. In addition, our design structurally enforces temporal consistency, resulting in stable depth predictions across consecutive frames with improved efficiency. Comprehensive zero-shot evaluation on multiple benchmarks demonstrates the state-of-the-art temporal consistency and competitive accuracy of VeloDepth, alongside its significantly faster inference compared to existing video-based depth estimators. VeloDepth thus provides a practical, efficient, and accurate solution for real-time depth estimation suitable for diverse perception tasks. Code and models are available at https://github.com/lpiccinelli-eth/velodepth

