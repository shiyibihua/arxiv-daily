---
layout: default
title: Sample-wise Adaptive Weighting for Transfer Consistency in Adversarial Distillation
---

# Sample-wise Adaptive Weighting for Transfer Consistency in Adversarial Distillation

**arXiv**: [2512.10275v1](https://arxiv.org/abs/2512.10275) | [PDF](https://arxiv.org/pdf/2512.10275.pdf)

**ä½œè€…**: Hongsin Lee, Hye Won Chung

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ ·æœ¬è‡ªé€‚åº”å¯¹æŠ—è’¸é¦ä»¥æå‡å¯¹æŠ—é²æ£’æ€§è½¬ç§»æ•ˆæžœ**

**å…³é”®è¯**: `å¯¹æŠ—è’¸é¦` `é²æ£’æ€§è½¬ç§»` `æ ·æœ¬è‡ªé€‚åº”` `å¯¹æŠ—è®­ç»ƒ` `æ•™å¸ˆ-å­¦ç”Ÿç½‘ç»œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¼ºæ•™å¸ˆç½‘ç»œæœªå¿…æå‡å­¦ç”Ÿé²æ£’æ€§ï¼Œå­˜åœ¨é²æ£’é¥±å’ŒçŽ°è±¡
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå¯¹æŠ—å¯è½¬ç§»æ€§ï¼Œè‡ªé€‚åº”é‡åŠ æƒè®­ç»ƒæ ·æœ¬ï¼Œæ— é¢å¤–è®¡ç®—æˆæœ¬
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CIFAR-10ç­‰æ•°æ®é›†ä¸Šï¼ŒSAADä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œæå‡AutoAttacké²æ£’æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Adversarial distillation in the standard min-max adversarial training framework aims to transfer adversarial robustness from a large, robust teacher network to a compact student. However, existing work often neglects to incorporate state-of-the-art robust teachers. Through extensive analysis, we find that stronger teachers do not necessarily yield more robust students-a phenomenon known as robust saturation. While typically attributed to capacity gaps, we show that such explanations are incomplete. Instead, we identify adversarial transferability-the fraction of student-crafted adversarial examples that remain effective against the teacher-as a key factor in successful robustness transfer. Based on this insight, we propose Sample-wise Adaptive Adversarial Distillation (SAAD), which reweights training examples by their measured transferability without incurring additional computational cost. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet show that SAAD consistently improves AutoAttack robustness over prior methods. Our code is available at https://github.com/HongsinLee/saad.

