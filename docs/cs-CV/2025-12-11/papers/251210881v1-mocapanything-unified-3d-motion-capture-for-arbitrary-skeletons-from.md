---
layout: default
title: MoCapAnything: Unified 3D Motion Capture for Arbitrary Skeletons from Monocular Videos
---

# MoCapAnything: Unified 3D Motion Capture for Arbitrary Skeletons from Monocular Videos

**arXiv**: [2512.10881v1](https://arxiv.org/abs/2512.10881) | [PDF](https://arxiv.org/pdf/2512.10881.pdf)

**ä½œè€…**: Kehong Gong, Zhengyu Wen, Weixia He, Mingxi Xu, Qi Wang, Ning Zhang, Zhengyu Li, Dongze Lian, Wei Zhao, Xiaoyu He, Mingyuan Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMoCapAnythingæ¡†æž¶ï¼Œé€šè¿‡å•ç›®è§†é¢‘å’Œä»»æ„éª¨éª¼èµ„äº§å®žçŽ°ç±»åˆ«æ— å…³çš„3Dè¿åŠ¨æ•æ‰ã€‚**

**å…³é”®è¯**: `3Dè¿åŠ¨æ•æ‰` `å•ç›®è§†é¢‘` `ç±»åˆ«æ— å…³` `é€†è¿åŠ¨å­¦` `éª¨éª¼åŠ¨ç”»` `è·¨ç‰©ç§é‡å®šå‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è¿åŠ¨æ•æ‰æµç¨‹é€šå¸¸é’ˆå¯¹ç‰¹å®šç‰©ç§æˆ–æ¨¡æ¿ï¼Œç¼ºä¹é€šç”¨æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å‚è€ƒå¼•å¯¼çš„åˆ†è§£æ¡†æž¶ï¼Œé¢„æµ‹3Då…³èŠ‚è½¨è¿¹å¹¶é€šè¿‡çº¦æŸæ„ŸçŸ¥é€†è¿åŠ¨å­¦æ¢å¤èµ„äº§ç‰¹å®šæ—‹è½¬ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŸºå‡†æµ‹è¯•å’Œé‡Žå¤–è§†é¢‘ä¸­ç”Ÿæˆé«˜è´¨é‡éª¨éª¼åŠ¨ç”»ï¼Œæ”¯æŒè·¨ç‰©ç§é‡å®šå‘ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Motion capture now underpins content creation far beyond digital humans, yet most existing pipelines remain species- or template-specific. We formalize this gap as Category-Agnostic Motion Capture (CAMoCap): given a monocular video and an arbitrary rigged 3D asset as a prompt, the goal is to reconstruct a rotation-based animation such as BVH that directly drives the specific asset. We present MoCapAnything, a reference-guided, factorized framework that first predicts 3D joint trajectories and then recovers asset-specific rotations via constraint-aware inverse kinematics. The system contains three learnable modules and a lightweight IK stage: (1) a Reference Prompt Encoder that extracts per-joint queries from the asset's skeleton, mesh, and rendered images; (2) a Video Feature Extractor that computes dense visual descriptors and reconstructs a coarse 4D deforming mesh to bridge the gap between video and joint space; and (3) a Unified Motion Decoder that fuses these cues to produce temporally coherent trajectories. We also curate Truebones Zoo with 1038 motion clips, each providing a standardized skeleton-mesh-render triad. Experiments on both in-domain benchmarks and in-the-wild videos show that MoCapAnything delivers high-quality skeletal animations and exhibits meaningful cross-species retargeting across heterogeneous rigs, enabling scalable, prompt-driven 3D motion capture for arbitrary assets. Project page: https://animotionlab.github.io/MoCapAnything/

