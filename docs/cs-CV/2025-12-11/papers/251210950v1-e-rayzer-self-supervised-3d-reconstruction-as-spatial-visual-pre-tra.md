---
layout: default
title: E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training
---

# E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.10950" target="_blank" class="toolbar-btn">arXiv: 2512.10950v1</a>
    <a href="https://arxiv.org/pdf/2512.10950.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10950v1" 
            onclick="toggleFavorite(this, '2512.10950v1', 'E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Qitao Zhao, Hao Tan, Qianqian Wang, Sai Bi, Kai Zhang, Kalyan Sunkavalli, Shubham Tulsiani, Hanwen Jiang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-11

**å¤‡æ³¨**: Project website: https://qitaozhao.github.io/E-RayZer

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**E-RayZerï¼šæå‡ºè‡ªç›‘ç£3Dé‡å»ºæ¡†æ¶ï¼Œä½œä¸ºç©ºé—´è§†è§‰é¢„è®­ç»ƒæ¨¡å‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è‡ªç›‘ç£å­¦ä¹ ` `3Dé‡å»º` `è§†è§‰é¢„è®­ç»ƒ` `å¤šè§†å›¾å‡ ä½•` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªç›‘ç£æ–¹æ³•åœ¨å¤šè§†å›¾å›¾åƒä¸­å­¦ä¹ 3Dæ„ŸçŸ¥è¡¨ç¤ºæ–¹é¢æ¢ç´¢ä¸è¶³ï¼Œå­˜åœ¨é—´æ¥æ¨æ–­3Då‡ ä½•çš„å±€é™ã€‚
2. E-RayZeré€šè¿‡æ˜¾å¼å‡ ä½•ç›´æ¥åœ¨3Dç©ºé—´ä¸­è¿›è¡Œè‡ªç›‘ç£é‡å»ºï¼Œé¿å…äº†æ·å¾„æ–¹æ¡ˆï¼Œå­¦ä¹ å‡ ä½•å¯é çš„è¡¨ç¤ºã€‚
3. å¼•å…¥ç»†ç²’åº¦å­¦ä¹ è¯¾ç¨‹ï¼Œæ— ç›‘ç£åœ°ç»„ç»‡è®­ç»ƒæ ·æœ¬ï¼Œåè°ƒå¼‚æ„æ•°æ®ï¼Œå®éªŒè¡¨æ˜E-RayZeræ€§èƒ½æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºE-RayZerï¼Œä¸€ä¸ªè‡ªç›‘ç£çš„å¤§å‹3Dè§†è§‰æ¨¡å‹ï¼Œç›´æ¥ä»æ— æ ‡ç­¾å›¾åƒä¸­å­¦ä¹ å…·æœ‰3Dæ„ŸçŸ¥èƒ½åŠ›çš„è¡¨ç¤ºã€‚ä¸å…ˆå‰çš„è‡ªç›‘ç£æ–¹æ³•ï¼ˆå¦‚RayZerï¼‰é€šè¿‡æ½œåœ¨ç©ºé—´è§†å›¾åˆæˆé—´æ¥æ¨æ–­3Dä¸åŒï¼ŒE-RayZerç›´æ¥åœ¨3Dç©ºé—´ä¸­æ“ä½œï¼Œåˆ©ç”¨æ˜¾å¼å‡ ä½•è¿›è¡Œè‡ªç›‘ç£3Dé‡å»ºã€‚è¿™ç§å…¬å¼é¿å…äº†æ·å¾„è§£å†³æ–¹æ¡ˆï¼Œå¹¶äº§ç”Ÿå‡ ä½•ä¸Šå¯é çš„è¡¨ç¤ºã€‚ä¸ºäº†ç¡®ä¿æ”¶æ•›æ€§å’Œå¯æ‰©å±•æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„ç»†ç²’åº¦å­¦ä¹ è¯¾ç¨‹ï¼Œä»¥å®Œå…¨æ— ç›‘ç£çš„æ–¹å¼ç»„ç»‡ä»æ˜“åˆ°éš¾çš„æ ·æœ¬è®­ç»ƒï¼Œå¹¶åè°ƒå¼‚æ„æ•°æ®æºã€‚å®éªŒè¡¨æ˜ï¼ŒE-RayZeråœ¨å§¿æ€ä¼°è®¡æ–¹é¢æ˜¾è‘—ä¼˜äºRayZerï¼Œåœ¨é‡å»ºæ–¹é¢è¾¾åˆ°ç”šè‡³è¶…è¿‡äº†å®Œå…¨ç›‘ç£çš„æ¨¡å‹ï¼ˆå¦‚VGGTï¼‰ã€‚æ­¤å¤–ï¼Œå½“è¿ç§»åˆ°3Dä¸‹æ¸¸ä»»åŠ¡æ—¶ï¼Œå…¶å­¦ä¹ åˆ°çš„è¡¨ç¤ºä¼˜äºé¢†å…ˆçš„è§†è§‰é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚DINOv3ã€CroCo v2ã€VideoMAE V2å’ŒRayZerï¼‰ï¼Œä»è€Œå°†E-RayZerç¡®ç«‹ä¸º3Dæ„ŸçŸ¥è§†è§‰é¢„è®­ç»ƒçš„æ–°èŒƒä¾‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è‡ªç›‘ç£3Dè¡¨ç¤ºå­¦ä¹ æ–¹æ³•ï¼Œä¾‹å¦‚RayZerï¼Œé€šå¸¸é€šè¿‡æ½œåœ¨ç©ºé—´è§†å›¾åˆæˆæ¥é—´æ¥æ¨æ–­3Då‡ ä½•ï¼Œè¿™å¯èƒ½å¯¼è‡´å­¦ä¹ åˆ°çš„è¡¨ç¤ºç¼ºä¹çœŸå®çš„3Då‡ ä½•æ„ŸçŸ¥ï¼Œå®¹æ˜“å—åˆ°æ·å¾„æ–¹æ¡ˆçš„å½±å“ã€‚å› æ­¤ï¼Œå¦‚ä½•ç›´æ¥ä»å¤šè§†å›¾å›¾åƒä¸­å­¦ä¹ å…·æœ‰æ˜¾å¼3Då‡ ä½•æ„ŸçŸ¥çš„è¡¨ç¤ºï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šE-RayZerçš„æ ¸å¿ƒæ€è·¯æ˜¯ç›´æ¥åœ¨3Dç©ºé—´ä¸­è¿›è¡Œè‡ªç›‘ç£é‡å»ºï¼Œåˆ©ç”¨æ˜¾å¼å‡ ä½•ä¿¡æ¯æ¥çº¦æŸå­¦ä¹ è¿‡ç¨‹ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´å‡†ç¡®ã€æ›´é²æ£’çš„3Dè¡¨ç¤ºï¼Œé¿å…äº†é—´æ¥æ¨æ–­å¸¦æ¥çš„è¯¯å·®ç´¯ç§¯å’Œæ·å¾„æ–¹æ¡ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šE-RayZerçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¤šè§†å›¾å›¾åƒè¾“å…¥ï¼›2) 3Dé‡å»ºæ¨¡å—ï¼Œè¯¥æ¨¡å—ç›´æ¥åœ¨3Dç©ºé—´ä¸­è¿›è¡Œæ“ä½œï¼Œåˆ©ç”¨æ˜¾å¼å‡ ä½•ä¿¡æ¯è¿›è¡Œè‡ªç›‘ç£é‡å»ºï¼›3) ç»†ç²’åº¦å­¦ä¹ è¯¾ç¨‹ï¼Œç”¨äºç»„ç»‡è®­ç»ƒæ ·æœ¬ï¼Œå¹¶åè°ƒå¼‚æ„æ•°æ®æºï¼›4) è¡¨ç¤ºå­¦ä¹ æ¨¡å—ï¼Œç”¨äºå­¦ä¹ å…·æœ‰3Dæ„ŸçŸ¥èƒ½åŠ›çš„è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šE-RayZeræœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå…¶ç›´æ¥åœ¨3Dç©ºé—´ä¸­è¿›è¡Œè‡ªç›‘ç£é‡å»ºï¼Œå¹¶åˆ©ç”¨æ˜¾å¼å‡ ä½•ä¿¡æ¯æ¥çº¦æŸå­¦ä¹ è¿‡ç¨‹ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒE-RayZeré¿å…äº†é—´æ¥æ¨æ–­å¸¦æ¥çš„è¯¯å·®ç´¯ç§¯å’Œæ·å¾„æ–¹æ¡ˆï¼Œèƒ½å¤Ÿå­¦ä¹ åˆ°æ›´å‡†ç¡®ã€æ›´é²æ£’çš„3Dè¡¨ç¤ºã€‚æ­¤å¤–ï¼Œç»†ç²’åº¦å­¦ä¹ è¯¾ç¨‹ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ç‚¹ï¼Œå®ƒèƒ½å¤Ÿæœ‰æ•ˆåœ°ç»„ç»‡è®­ç»ƒæ ·æœ¬ï¼Œå¹¶åè°ƒå¼‚æ„æ•°æ®æºï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ”¶æ•›æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šE-RayZerçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ä½“ç´ ç½‘æ ¼æˆ–ç‚¹äº‘ç­‰æ˜¾å¼å‡ ä½•è¡¨ç¤ºï¼›2) è®¾è®¡åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚3Dé‡å»ºæŸå¤±ã€å‡ ä½•ä¸€è‡´æ€§æŸå¤±ç­‰ï¼Œä»¥çº¦æŸå­¦ä¹ è¿‡ç¨‹ï¼›3) è®¾è®¡ç»†ç²’åº¦å­¦ä¹ è¯¾ç¨‹ï¼Œä¾‹å¦‚ä»æ˜“åˆ°éš¾çš„æ ·æœ¬æ’åºã€å¼‚æ„æ•°æ®æºçš„æƒé‡è°ƒæ•´ç­‰ï¼›4) é€‰æ‹©åˆé€‚çš„ç½‘ç»œç»“æ„ï¼Œä¾‹å¦‚3Då·ç§¯ç¥ç»ç½‘ç»œã€å›¾ç¥ç»ç½‘ç»œç­‰ï¼Œä»¥å¤„ç†3Dæ•°æ®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

E-RayZeråœ¨å§¿æ€ä¼°è®¡æ–¹é¢æ˜¾è‘—ä¼˜äºRayZerï¼Œåœ¨é‡å»ºæ–¹é¢è¾¾åˆ°ç”šè‡³è¶…è¿‡äº†å®Œå…¨ç›‘ç£çš„æ¨¡å‹ï¼ˆå¦‚VGGTï¼‰ã€‚å½“è¿ç§»åˆ°3Dä¸‹æ¸¸ä»»åŠ¡æ—¶ï¼Œå…¶å­¦ä¹ åˆ°çš„è¡¨ç¤ºä¼˜äºé¢†å…ˆçš„è§†è§‰é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚DINOv3ã€CroCo v2ã€VideoMAE V2å’ŒRayZerï¼‰ã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒE-RayZerèƒ½å¤Ÿå­¦ä¹ åˆ°æ›´å‡†ç¡®ã€æ›´é²æ£’çš„3Dè¡¨ç¤ºï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

E-RayZeråœ¨æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®ã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºæ„å»ºæ›´æ™ºèƒ½ã€æ›´å¯é çš„3Dæ„ŸçŸ¥ç³»ç»Ÿï¼Œä»è€Œæé«˜æœºå™¨äººçš„è‡ªä¸»æ€§å’Œé€‚åº”æ€§ï¼Œæ”¹å–„ç”¨æˆ·åœ¨è™šæ‹Ÿç¯å¢ƒä¸­çš„æ²‰æµ¸æ„Ÿå’Œäº¤äº’ä½“éªŒã€‚æ­¤å¤–ï¼ŒE-RayZerè¿˜å¯ä»¥ç”¨äº3Då†…å®¹ç”Ÿæˆã€åœºæ™¯ç†è§£ç­‰ä»»åŠ¡ï¼Œä¸ºç›¸å…³é¢†åŸŸçš„ç ”ç©¶å’Œåº”ç”¨æä¾›æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Self-supervised pre-training has revolutionized foundation models for languages, individual 2D images and videos, but remains largely unexplored for learning 3D-aware representations from multi-view images. In this paper, we present E-RayZer, a self-supervised large 3D Vision model that learns truly 3D-aware representations directly from unlabeled images. Unlike prior self-supervised methods such as RayZer that infer 3D indirectly through latent-space view synthesis, E-RayZer operates directly in 3D space, performing self-supervised 3D reconstruction with Explicit geometry. This formulation eliminates shortcut solutions and yields representations that are geometrically grounded. To ensure convergence and scalability, we introduce a novel fine-grained learning curriculum that organizes training from easy to hard samples and harmonizes heterogeneous data sources in an entirely unsupervised manner. Experiments demonstrate that E-RayZer significantly outperforms RayZer on pose estimation, matches or sometimes surpasses fully supervised reconstruction models such as VGGT. Furthermore, its learned representations outperform leading visual pre-training models (e.g., DINOv3, CroCo v2, VideoMAE V2, and RayZer) when transferring to 3D downstream tasks, establishing E-RayZer as a new paradigm for 3D-aware visual pre-training.

