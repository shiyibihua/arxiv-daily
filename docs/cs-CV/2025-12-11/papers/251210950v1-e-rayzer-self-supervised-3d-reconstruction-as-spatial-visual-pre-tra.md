---
layout: default
title: E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training
---

# E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training

**arXiv**: [2512.10950v1](https://arxiv.org/abs/2512.10950) | [PDF](https://arxiv.org/pdf/2512.10950.pdf)

**ä½œè€…**: Qitao Zhao, Hao Tan, Qianqian Wang, Sai Bi, Kai Zhang, Kalyan Sunkavalli, Shubham Tulsiani, Hanwen Jiang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºE-RayZerï¼Œé€šè¿‡æ˜¾å¼å‡ ä½•çš„è‡ªç›‘ç£ä¸‰ç»´é‡å»ºå®žçŽ°ä¸‰ç»´æ„ŸçŸ¥è§†è§‰é¢„è®­ç»ƒã€‚**

**å…³é”®è¯**: `ä¸‰ç»´é‡å»º` `è‡ªç›‘ç£å­¦ä¹ ` `è§†è§‰é¢„è®­ç»ƒ` `å¤šè§†å›¾å›¾åƒ` `å‡ ä½•è¡¨ç¤º` `è¯¾ç¨‹å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‡ªç›‘ç£é¢„è®­ç»ƒåœ¨ä¸‰ç»´æ„ŸçŸ¥è¡¨ç¤ºå­¦ä¹ ä¸Šæœªå……åˆ†æŽ¢ç´¢ï¼ŒçŽ°æœ‰æ–¹æ³•å¦‚RayZerä¾èµ–éšå¼è§†å›¾åˆæˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç›´æŽ¥åœ¨ä¸‰ç»´ç©ºé—´è¿›è¡Œè‡ªç›‘ç£é‡å»ºï¼Œå¼•å…¥ç»†ç²’åº¦å­¦ä¹ è¯¾ç¨‹ä»¥ä¼˜åŒ–æ”¶æ•›å’Œå¯æ‰©å±•æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å§¿æ€ä¼°è®¡ä¸Šæ˜¾è‘—ä¼˜äºŽRayZerï¼Œä¸‹æ¸¸ä»»åŠ¡ä¸­è¶…è¶ŠDINOv3ç­‰é¢†å…ˆæ¨¡åž‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Self-supervised pre-training has revolutionized foundation models for languages, individual 2D images and videos, but remains largely unexplored for learning 3D-aware representations from multi-view images. In this paper, we present E-RayZer, a self-supervised large 3D Vision model that learns truly 3D-aware representations directly from unlabeled images. Unlike prior self-supervised methods such as RayZer that infer 3D indirectly through latent-space view synthesis, E-RayZer operates directly in 3D space, performing self-supervised 3D reconstruction with Explicit geometry. This formulation eliminates shortcut solutions and yields representations that are geometrically grounded. To ensure convergence and scalability, we introduce a novel fine-grained learning curriculum that organizes training from easy to hard samples and harmonizes heterogeneous data sources in an entirely unsupervised manner. Experiments demonstrate that E-RayZer significantly outperforms RayZer on pose estimation, matches or sometimes surpasses fully supervised reconstruction models such as VGGT. Furthermore, its learned representations outperform leading visual pre-training models (e.g., DINOv3, CroCo v2, VideoMAE V2, and RayZer) when transferring to 3D downstream tasks, establishing E-RayZer as a new paradigm for 3D-aware visual pre-training.

