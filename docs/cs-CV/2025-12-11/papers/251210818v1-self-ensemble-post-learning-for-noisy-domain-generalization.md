---
layout: default
title: Self-Ensemble Post Learning for Noisy Domain Generalization
---

# Self-Ensemble Post Learning for Noisy Domain Generalization

**arXiv**: [2512.10818v1](https://arxiv.org/abs/2512.10818) | [PDF](https://arxiv.org/pdf/2512.10818.pdf)

**ä½œè€…**: Wang Lu, Jindong Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªé›†æˆåŽå­¦ä¹ æ–¹æ³•ä»¥è§£å†³å¸¦å™ªå£°æ ‡ç­¾çš„åŸŸæ³›åŒ–é—®é¢˜**

**å…³é”®è¯**: `åŸŸæ³›åŒ–` `å™ªå£°æ ‡ç­¾` `ç‰¹å¾æŽ¢æµ‹` `é›†æˆå­¦ä¹ ` `åŠç›‘ç£è®­ç»ƒ` `é²æ£’æ€§å¢žå¼º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŸŸæ³›åŒ–ä¸­å™ªå£°æ ‡ç­¾åŠ å‰§æ·±å±‚ä¼ªç‰¹å¾æ”¾å¤§ï¼Œå¯¼è‡´ç®—æ³•æ€§èƒ½ä¸‹é™
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨æ¨¡åž‹ä¸­é—´ç‰¹å¾è®­ç»ƒå¤šä¸ªæŽ¢æµ‹åˆ†ç±»å™¨ï¼Œé€šè¿‡é›†æˆé¢„æµ‹æå‡ç‰¹å¾å¤šæ ·æ€§
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒè¯„ä¼°æ˜¾ç¤ºæ–¹æ³•å¢žå¼ºçŽ°æœ‰æ–¹æ³•é²æ£’æ€§ï¼Œå…·æœ‰é«˜çµæ´»æ€§çš„å®žé™…åº”ç”¨æ½œåŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While computer vision and machine learning have made great progress, their robustness is still challenged by two key issues: data distribution shift and label noise. When domain generalization (DG) encounters noise, noisy labels further exacerbate the emergence of spurious features in deep layers, i.e. spurious feature enlargement, leading to a degradation in the performance of existing algorithms. This paper, starting from domain generalization, explores how to make existing methods rework when meeting noise. We find that the latent features inside the model have certain discriminative capabilities, and different latent features focus on different parts of the image. Based on these observations, we propose the Self-Ensemble Post Learning approach (SEPL) to diversify features which can be leveraged. Specifically, SEPL consists of two parts: feature probing training and prediction ensemble inference. It leverages intermediate feature representations within the model architecture, training multiple probing classifiers to fully exploit the capabilities of pre-trained models, while the final predictions are obtained through the integration of outputs from these diverse classification heads. Considering the presence of noisy labels, we employ semi-supervised algorithms to train probing classifiers. Given that different probing classifiers focus on different areas, we integrate their predictions using a crowdsourcing inference approach. Extensive experimental evaluations demonstrate that the proposed method not only enhances the robustness of existing methods but also exhibits significant potential for real-world applications with high flexibility.

