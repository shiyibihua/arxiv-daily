---
layout: default
title: UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning
---

# UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning

**arXiv**: [2512.10492v1](https://arxiv.org/abs/2512.10492) | [PDF](https://arxiv.org/pdf/2512.10492.pdf)

**ä½œè€…**: Jiaxi Wu, Tiantian Zhang, Yuxing Wang, Yongzhe Chang, Xueqian Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUACERæ¡†æž¶ï¼Œé€šè¿‡ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„è¯„è®ºå®¶é›†æˆï¼Œè§£å†³å¯¹æŠ—å¼ºåŒ–å­¦ä¹ ä¸­çš„è®­ç»ƒä¸ç¨³å®šé—®é¢˜ã€‚**

**å…³é”®è¯**: `å¯¹æŠ—å¼ºåŒ–å­¦ä¹ ` `è¯„è®ºå®¶é›†æˆ` `ä¸ç¡®å®šæ€§æ„ŸçŸ¥` `è®­ç»ƒç¨³å®šæ€§` `é©¬å°”å¯å¤«åšå¼ˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¯¹æŠ—å¼ºåŒ–å­¦ä¹ ä¸­å¯è®­ç»ƒå¯¹æ‰‹å¯¼è‡´å­¦ä¹ åŠ¨æ€éžå¹³ç¨³ï¼ŒåŠ å‰§è®­ç»ƒä¸ç¨³å®šå’Œæ”¶æ•›å›°éš¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å¤šæ ·åŒ–è¯„è®ºå®¶é›†æˆå’ŒåŸºäºŽæ–¹å·®çš„Qå€¼èšåˆç­–ç•¥ï¼ŒåŠ¨æ€è°ƒèŠ‚æŽ¢ç´¢-åˆ©ç”¨æƒè¡¡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªMuJoCoæŽ§åˆ¶é—®é¢˜ä¸ŠéªŒè¯ï¼ŒUACERåœ¨æ€§èƒ½ã€ç¨³å®šæ€§å’Œæ•ˆçŽ‡ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Robust adversarial reinforcement learning has emerged as an effective paradigm for training agents to handle uncertain disturbance in real environments, with critical applications in sequential decision-making domains such as autonomous driving and robotic control. Within this paradigm, agent training is typically formulated as a zero-sum Markov game between a protagonist and an adversary to enhance policy robustness. However, the trainable nature of the adversary inevitably induces non-stationarity in the learning dynamics, leading to exacerbated training instability and convergence difficulties, particularly in high-dimensional complex environments. In this paper, we propose a novel approach, Uncertainty-Aware Critic Ensemble for robust adversarial Reinforcement learning (UACER), which consists of two strategies: 1) Diversified critic ensemble: a diverse set of K critic networks is exploited in parallel to stabilize Q-value estimation rather than conventional single-critic architectures for both variance reduction and robustness enhancement. 2) Time-varying Decay Uncertainty (TDU) mechanism: advancing beyond simple linear combinations, we develop a variance-derived Q-value aggregation strategy that explicitly incorporates epistemic uncertainty to dynamically regulate the exploration-exploitation trade-off while simultaneously stabilizing the training process. Comprehensive experiments across several MuJoCo control problems validate the superior effectiveness of UACER, outperforming state-of-the-art methods in terms of overall performance, stability, and efficiency.

