---
layout: default
title: Simple Yet Effective Selective Imputation for Incomplete Multi-view Clustering
---

# Simple Yet Effective Selective Imputation for Incomplete Multi-view Clustering

**arXiv**: [2512.10327v1](https://arxiv.org/abs/2512.10327) | [PDF](https://arxiv.org/pdf/2512.10327.pdf)

**ä½œè€…**: Cai Xu, Jinlong Liu, Yilin Zhang, Ziyu Guan, Wei Zhao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€‰æ‹©æ€§æ’è¡¥æ–¹æ³•ä»¥è§£å†³ä¸å®Œæ•´å¤šè§†å›¾èšç±»ä¸­çš„å™ªå£°ä¸Žåå·®é—®é¢˜**

**å…³é”®è¯**: `ä¸å®Œæ•´å¤šè§†å›¾èšç±»` `é€‰æ‹©æ€§æ’è¡¥` `å˜åˆ†è‡ªç¼–ç å™¨` `é«˜æ–¯æ··åˆå…ˆéªŒ` `æ•°æ®é©±åŠ¨æ–¹æ³•` `æ¨¡åž‹æ— å…³æ¨¡å—`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¸å®Œæ•´å¤šè§†å›¾æ•°æ®ä¸­ï¼Œç›²ç›®æ’è¡¥å¼•å…¥å™ªå£°ï¼Œè€Œå…æ’è¡¥æ–¹æ³•åœ¨ä¸¥é‡ä¸å®Œæ•´æ—¶ç¼ºä¹è·¨è§†å›¾äº’è¡¥æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽä¿¡æ¯é‡è¯„ä¼°é€‰æ‹©æ€§æ’è¡¥ï¼Œç»“åˆå˜åˆ†è‡ªç¼–ç å™¨ä¸Žé«˜æ–¯æ··åˆå…ˆéªŒå­¦ä¹ èšç±»å‹å¥½è¡¨ç¤ºã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨æ›´çŽ°å®žçš„ä¸å¹³è¡¡ç¼ºå¤±åœºæ™¯ä¸‹ä¼˜äºŽæ’è¡¥å’Œå…æ’è¡¥æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Incomplete multi-view data, where different views suffer from missing and unbalanced observations, pose significant challenges for clustering. Existing imputation-based methods attempt to estimate missing views to restore data associations, but indiscriminate imputation often introduces noise and bias, especially when the available information is insufficient. Imputation-free methods avoid this risk by relying solely on observed data, but struggle under severe incompleteness due to the lack of cross-view complementarity. To address this issue, we propose Informativeness-based Selective imputation Multi-View Clustering (ISMVC). Our method evaluates the imputation-relevant informativeness of each missing position based on intra-view similarity and cross-view consistency, and selectively imputes only when sufficient support is available. Furthermore, we integrate this selection with a variational autoencoder equipped with a mixture-of-Gaussians prior to learn clustering-friendly latent representations. By performing distribution-level imputation, ISMVC not only stabilizes the aggregation of posterior distributions but also explicitly models imputation uncertainty, enabling robust fusion and preventing overconfident reconstructions. Compared with existing cautious imputation strategies that depend on training dynamics or model feedback, our method is lightweight, data-driven, and model-agnostic. It can be readily integrated into existing IMC models as a plug-in module. Extensive experiments on multiple benchmark datasets under a more realistic and challenging unbalanced missing scenario demonstrate that our method outperforms both imputation-based and imputation-free approaches.

