---
layout: default
title: Multi-Granular Node Pruning for Circuit Discovery
---

# Multi-Granular Node Pruning for Circuit Discovery

**arXiv**: [2512.10903v1](https://arxiv.org/abs/2512.10903) | [PDF](https://arxiv.org/pdf/2512.10903.pdf)

**ä½œè€…**: Muhammad Umair Haider, Hammad Rizwan, Hassan Sajjad, A. B. Siddique

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šç²’åº¦èŠ‚ç‚¹å‰ªæžæ¡†æž¶ä»¥è§£å†³å¤§è¯­è¨€æ¨¡åž‹ç”µè·¯å‘çŽ°ä¸­çš„å¯æ‰©å±•æ€§ä¸Žç²’åº¦é™åˆ¶é—®é¢˜**

**å…³é”®è¯**: `ç”µè·¯å‘çŽ°` `èŠ‚ç‚¹å‰ªæž` `å¤šç²’åº¦ä¼˜åŒ–` `å¤§è¯­è¨€æ¨¡åž‹` `ç¨€ç–åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–è¿­ä»£è¾¹å‰ªæžï¼Œè®¡ç®—æˆæœ¬é«˜ä¸”ç²’åº¦ç²—ï¼Œå¿½ç•¥ç¥žç»å…ƒçº§ç»“æž„
2. å¼•å…¥å¯å­¦ä¹ æŽ©ç ä¸Žç²’åº¦ç‰¹å®šç¨€ç–æƒ©ç½šï¼Œåœ¨ç»Ÿä¸€ä¼˜åŒ–ä¸­å®žçŽ°ä»Žå—åˆ°ç¥žç»å…ƒçš„å¤šç²’åº¦å‰ªæž
3. å®žéªŒæ˜¾ç¤ºèŠ‚ç‚¹æ›´å°‘ã€å†…å­˜å ç”¨é™ä½Ž5-10å€ï¼ŒåŒæ—¶ä¿æŒä»»åŠ¡æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP blocks, overlooking finer structures like individual neurons. We propose a node-level pruning framework for circuit discovery that addresses both scalability and granularity limitations. Our method introduces learnable masks across multiple levels of granularity, from entire blocks to individual neurons, within a unified optimization objective. Granularity-specific sparsity penalties guide the pruning process, allowing a comprehensive compression in a single fine-tuning run. Empirically, our approach identifies circuits that are smaller in nodes than those discovered by prior methods; moreover, we demonstrate that many neurons deemed important by coarse methods are actually irrelevant, while still maintaining task performance. Furthermore, our method has a significantly lower memory footprint, 5-10x, as it does not require keeping intermediate activations in the memory to work.

