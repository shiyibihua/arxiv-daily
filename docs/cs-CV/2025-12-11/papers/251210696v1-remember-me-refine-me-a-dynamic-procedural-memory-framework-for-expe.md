---
layout: default
title: Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution
---

# Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution

**arXiv**: [2512.10696v1](https://arxiv.org/abs/2512.10696) | [PDF](https://arxiv.org/pdf/2512.10696.pdf)

**ä½œè€…**: Zouying Cao, Jiaji Deng, Li Yu, Weikang Zhou, Zhaoyang Liu, Bolin Ding, Hai Zhao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºReMeåŠ¨æ€ç¨‹åºè®°å¿†æ¡†æž¶ï¼Œä»¥è§£å†³LLMä»£ç†ä¸­é™æ€è®°å¿†ç§¯ç´¯é—®é¢˜ï¼Œå®žçŽ°ç»éªŒé©±åŠ¨è¿›åŒ–ã€‚**

**å…³é”®è¯**: `ç¨‹åºè®°å¿†` `LLMä»£ç†` `ç»éªŒè’¸é¦` `åŠ¨æ€æŽ¨ç†` `è®°å¿†ç²¾ç‚¼` `ç»ˆèº«å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰LLMä»£ç†è®°å¿†æ¡†æž¶å¤šä¸ºè¢«åŠ¨ç§¯ç´¯ï¼Œç¼ºä¹åŠ¨æ€æŽ¨ç†ä¸Žä¼˜åŒ–æœºåˆ¶ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å¤šé¢è’¸é¦ã€ä¸Šä¸‹æ–‡è‡ªé€‚åº”é‡ç”¨å’ŒåŸºäºŽæ•ˆç”¨çš„ç²¾ç‚¼ï¼Œå®žçŽ°è®°å¿†å…¨ç”Ÿå‘½å‘¨æœŸåˆ›æ–°ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨BFCL-V3å’ŒAppWorldä¸Šè¾¾åˆ°SOTAï¼ŒQwen3-8B+ReMeè¶…è¶Šæ›´å¤§æ— è®°å¿†æ¨¡åž‹ï¼Œæ˜¾ç¤ºå†…å­˜ç¼©æ”¾æ•ˆåº”ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Procedural memory enables large language model (LLM) agents to internalize "how-to" knowledge, theoretically reducing redundant trial-and-error. However, existing frameworks predominantly suffer from a "passive accumulation" paradigm, treating memory as a static append-only archive. To bridge the gap between static storage and dynamic reasoning, we propose $\textbf{ReMe}$ ($\textit{Remember Me, Refine Me}$), a comprehensive framework for experience-driven agent evolution. ReMe innovates across the memory lifecycle via three mechanisms: 1) $\textit{multi-faceted distillation}$, which extracts fine-grained experiences by recognizing success patterns, analyzing failure triggers and generating comparative insights; 2) $\textit{context-adaptive reuse}$, which tailors historical insights to new contexts via scenario-aware indexing; and 3) $\textit{utility-based refinement}$, which autonomously adds valid memories and prunes outdated ones to maintain a compact, high-quality experience pool. Extensive experiments on BFCL-V3 and AppWorld demonstrate that ReMe establishes a new state-of-the-art in agent memory system. Crucially, we observe a significant memory-scaling effect: Qwen3-8B equipped with ReMe outperforms larger, memoryless Qwen3-14B, suggesting that self-evolving memory provides a computation-efficient pathway for lifelong learning. We release our code and the $\texttt{reme.library}$ dataset to facilitate further research.

