---
layout: default
title: Script Gap: Evaluating LLM Triage on Indian Languages in Native vs Roman Scripts in a Real World Setting
---

# Script Gap: Evaluating LLM Triage on Indian Languages in Native vs Roman Scripts in a Real World Setting

**arXiv**: [2512.10780v1](https://arxiv.org/abs/2512.10780) | [PDF](https://arxiv.org/pdf/2512.10780.pdf)

**ä½œè€…**: Manurag Khullar, Utkarsh Desai, Poorva Malviya, Aman Dalmia, Zheyuan Ryan Shi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°LLMåœ¨å°åº¦è¯­è¨€åŽŸç”Ÿä¸Žç½—é©¬åŒ–è„šæœ¬ä¸‹çš„åˆ†è¯Šæ€§èƒ½ï¼Œæ­ç¤ºç½—é©¬åŒ–å¯¼è‡´å¯é æ€§ä¸‹é™**

**å…³é”®è¯**: `LLMåˆ†è¯Šè¯„ä¼°` `ç½—é©¬åŒ–è„šæœ¬å½±å“` `å°åº¦è¯­è¨€å¤„ç†` `ä¸´åºŠåº”ç”¨å¯é æ€§` `çœŸå®žä¸–ç•Œæ•°æ®`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šLLMåœ¨å°åº¦ä¸´åºŠåº”ç”¨ä¸­ï¼Œç”¨æˆ·å¸¸ç”¨ç½—é©¬åŒ–æ–‡æœ¬è€ŒéžåŽŸç”Ÿè„šæœ¬ï¼ŒçŽ°æœ‰ç ”ç©¶ç¼ºä¹çœŸå®žæ•°æ®è¯„ä¼°è¿™ç§æ‹¼å†™å˜ä½“å¯¹å¯é æ€§çš„å½±å“ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽçœŸå®žä¸–ç•Œæ•°æ®é›†ï¼Œå¯¹äº”ç§å°åº¦è¯­è¨€å’Œå°¼æ³Šå°”è¯­çš„ç”¨æˆ·æŸ¥è¯¢ï¼Œæ¯”è¾ƒLLMåœ¨åŽŸç”Ÿä¸Žç½—é©¬åŒ–è„šæœ¬ä¸‹çš„åˆ†è¯Šæ€§èƒ½ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç»“æžœæ˜¾ç¤ºç½—é©¬åŒ–æ¶ˆæ¯æ€§èƒ½ä¸€è‡´ä¸‹é™ï¼ŒF1åˆ†æ•°ä½Ž5-12ç‚¹ï¼Œå¯èƒ½å¯¼è‡´è¿‘200ä¸‡é¢å¤–åˆ†è¯Šé”™è¯¯ï¼Œæ¨¡åž‹è™½èƒ½æŽ¨æ–­è¯­ä¹‰æ„å›¾ä½†åˆ†ç±»è¾“å‡ºè„†å¼±ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Language Models (LLMs) are increasingly deployed in high-stakes clinical applications in India. In many such settings, speakers of Indian languages frequently communicate using romanized text rather than native scripts, yet existing research rarely evaluates this orthographic variation using real-world data. We investigate how romanization impacts the reliability of LLMs in a critical domain: maternal and newborn healthcare triage. We benchmark leading LLMs on a real-world dataset of user-generated queries spanning five Indian languages and Nepali. Our results reveal consistent degradation in performance for romanized messages, with F1 scores trailing those of native scripts by 5-12 points. At our partner maternal health organization in India, this gap could cause nearly 2 million excess errors in triage. Crucially, this performance gap by scripts is not due to a failure in clinical reasoning. We demonstrate that LLMs often correctly infer the semantic intent of romanized queries. Nevertheless, their final classification outputs remain brittle in the presence of orthographic noise in romanized inputs. Our findings highlight a critical safety blind spot in LLM-based health systems: models that appear to understand romanized input may still fail to act on it reliably.

