---
layout: default
title: LGAN: An Efficient High-Order Graph Neural Network via the Line Graph Aggregation
---

# LGAN: An Efficient High-Order Graph Neural Network via the Line Graph Aggregation

**arXiv**: [2512.10735v1](https://arxiv.org/abs/2512.10735) | [PDF](https://arxiv.org/pdf/2512.10735.pdf)

**ä½œè€…**: Lin Du, Lu Bai, Jincheng Li, Lixin Cui, Hangyuan Du, Lichi Zhang, Yuting Chen, Zhao Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLGANä»¥é«˜æ•ˆæå‡å›¾åˆ†ç±»çš„è¡¨è¾¾èƒ½åŠ›ä¸Žå¯è§£é‡Šæ€§**

**å…³é”®è¯**: `å›¾ç¥žç»ç½‘ç»œ` `é«˜é˜¶è¡¨è¾¾` `çº¿å›¾èšåˆ` `å›¾åˆ†ç±»` `å¯è§£é‡Šæ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é—®é¢˜ï¼šçŽ°æœ‰GNNè¡¨è¾¾èƒ½åŠ›å—é™äºŽ1-WLæµ‹è¯•ï¼Œä¸”k-WLæ–¹æ³•è®¡ç®—æˆæœ¬é«˜ã€å¯è§£é‡Šæ€§å·®
2. æ–¹æ³•ï¼šé€šè¿‡èŠ‚ç‚¹ä¸­å¿ƒè¯±å¯¼å­å›¾æž„å»ºçº¿å›¾ï¼Œå®žçŽ°é«˜é˜¶èšåˆï¼Œç†è®ºè¯æ˜Žä¼˜äºŽ2-WLä¸”å¤æ‚åº¦ä½Ž
3. æ•ˆæžœï¼šåœ¨åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šå…ˆè¿›k-WL GNNï¼Œå¹¶æä¾›æ›´å¥½çš„å¯è§£é‡Šæ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Graph Neural Networks (GNNs) have emerged as a dominant paradigm for graph classification. Specifically, most existing GNNs mainly rely on the message passing strategy between neighbor nodes, where the expressivity is limited by the 1-dimensional Weisfeiler-Lehman (1-WL) test. Although a number of k-WL-based GNNs have been proposed to overcome this limitation, their computational cost increases rapidly with k, significantly restricting the practical applicability. Moreover, since the k-WL models mainly operate on node tuples, these k-WL-based GNNs cannot retain fine-grained node- or edge-level semantics required by attribution methods (e.g., Integrated Gradients), leading to the less interpretable problem. To overcome the above shortcomings, in this paper, we propose a novel Line Graph Aggregation Network (LGAN), that constructs a line graph from the induced subgraph centered at each node to perform the higher-order aggregation. We theoretically prove that the LGAN not only possesses the greater expressive power than the 2-WL under injective aggregation assumptions, but also has lower time complexity. Empirical evaluations on benchmarks demonstrate that the LGAN outperforms state-of-the-art k-WL-based GNNs, while offering better interpretability.

