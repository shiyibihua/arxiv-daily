---
layout: default
title: User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation
---

# User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation

**arXiv**: [2512.10322v1](https://arxiv.org/abs/2512.10322) | [PDF](https://arxiv.org/pdf/2512.10322.pdf)

**ä½œè€…**: Yongqiang Yu, Xuhui Li, Hazza Mahmood, Jinxing Zhou, Haodong Hong, Longtao Jiang, Zhiqiang Xu, Qi Wu, Xiaojun Chang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç”¨æˆ·åé¦ˆé©±åŠ¨çš„æŒç»­é€‚åº”æ¡†æž¶ï¼Œä»¥å¢žå¼ºè§†è§‰è¯­è¨€å¯¼èˆªåœ¨çœŸå®žéƒ¨ç½²ä¸­çš„æ€§èƒ½ã€‚**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€å¯¼èˆª` `æŒç»­é€‚åº”` `ç”¨æˆ·åé¦ˆ` `è®°å¿†åº“çƒ­å¯åŠ¨` `é€šç”¨åœºæ™¯é€‚åº”`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰é€šç”¨åœºæ™¯é€‚åº”æ–¹æ³•å¿½ç•¥ç”¨æˆ·åé¦ˆï¼Œä¾èµ–æ— ç›‘ç£é€‚åº”ï¼Œé™åˆ¶çœŸå®žåº”ç”¨æ•ˆæžœã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆç”¨æˆ·åé¦ˆï¼ˆæŒ‡ä»¤å’Œçº æ­£ä¿¡å·ï¼‰ç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ï¼Œç»“åˆè®°å¿†åº“çƒ­å¯åŠ¨æœºåˆ¶æå‡é€‚åº”æ•ˆçŽ‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨GSA-R2RåŸºå‡†ä¸Šè¶…è¶ŠåŸºçº¿ï¼Œæé«˜å¯¼èˆªæˆåŠŸçŽ‡å’Œè·¯å¾„æ•ˆçŽ‡ï¼Œé€‚åº”è®¾ç½®ä¸‹è¡¨çŽ°ç¨³å¥ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-and-Language Navigation (VLN) requires agents to navigate complex environments by following natural-language instructions. General Scene Adaptation for VLN (GSA-VLN) shifts the focus from zero-shot generalization to continual, environment-specific adaptation, narrowing the gap between static benchmarks and real-world deployment. However, current GSA-VLN frameworks exclude user feedback, relying solely on unsupervised adaptation from repeated environmental exposure. In practice, user feedback offers natural and valuable supervision that can significantly enhance adaptation quality. We introduce a user-feedback-driven adaptation framework that extends GSA-VLN by systematically integrating human interactions into continual learning. Our approach converts user feedback-navigation instructions and corrective signals-into high-quality, environment-aligned training data, enabling efficient and realistic adaptation. A memory-bank warm-start mechanism further reuses previously acquired environmental knowledge, mitigating cold-start degradation and ensuring stable redeployment. Experiments on the GSA-R2R benchmark show that our method consistently surpasses strong baselines such as GR-DUET, improving navigation success and path efficiency. The memory-bank warm start stabilizes early navigation and reduces performance drops after updates. Results under both continual and hybrid adaptation settings confirm the robustness and generality of our framework, demonstrating sustained improvement across diverse deployment conditions.

