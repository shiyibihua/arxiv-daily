---
layout: default
title: Point2Pose: A Generative Framework for 3D Human Pose Estimation with Multi-View Point Cloud Dataset
---

# Point2Pose: A Generative Framework for 3D Human Pose Estimation with Multi-View Point Cloud Dataset

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.10321" target="_blank" class="toolbar-btn">arXiv: 2512.10321v1</a>
    <a href="https://arxiv.org/pdf/2512.10321.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10321v1" 
            onclick="toggleFavorite(this, '2512.10321v1', 'Point2Pose: A Generative Framework for 3D Human Pose Estimation with Multi-View Point Cloud Dataset')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Hyunsoo Lee, Daeum Jeon, Hyeokjae Oh

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-11

**Â§áÊ≥®**: WACV 2026 camera ready

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Point2PoseÔºöÊèêÂá∫‰∏ÄÁßçÂü∫‰∫éÂ§öËßÜËßíÁÇπ‰∫ëÊï∞ÊçÆÈõÜÁöÑ3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÁîüÊàêÊ°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°` `ÁîüÊàêÊ®°Âûã` `ÁÇπ‰∫ëÂ§ÑÁêÜ` `Ê≥®ÊÑèÂäõÊú∫Âà∂` `Êó∂Á©∫Âª∫Ê®°` `Â§öËßÜËßíÊï∞ÊçÆ` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. 3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°Èù¢‰∏¥‰∫∫‰ΩìÂá†‰ΩïÂ§çÊùÇ„ÄÅÂÖ≥ËäÇËá™ÈÅÆÊå°‰ª•ÂèäÁº∫‰πèÂ§ßËßÑÊ®°ÁúüÂÆûËøêÂä®Êï∞ÊçÆÈõÜÁ≠âÊåëÊàò„ÄÇ
2. Point2PoseÈÄöËøáÊó∂Á©∫ÁÇπ‰∫ëÁºñÁ†ÅÂô®ÂíåÂßøÊÄÅÁâπÂæÅÁºñÁ†ÅÂô®ÊèêÂèñÁâπÂæÅÔºåÂπ∂‰ΩøÁî®Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÁîüÊàêÂºèÂõûÂΩíÂô®Âª∫Ê®°ÂßøÊÄÅÂàÜÂ∏É„ÄÇ
3. ÊèêÂá∫ÁöÑMVPose3DÊï∞ÊçÆÈõÜÂåÖÂê´IMUÊï∞ÊçÆ„ÄÅÂ§öËßÜËßíÁÇπ‰∫ëÂíåRGBÂõæÂÉèÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéËØ•ÊñπÊ≥ï‰ºò‰∫éÁé∞ÊúâÂü∫Á∫øÊ®°Âûã„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÁîüÊàêÂºèÊñπÊ≥ïÁî®‰∫é3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°„ÄÇÁî±‰∫é‰∫∫‰ΩìÂ§çÊùÇÁöÑÂá†‰ΩïÁªìÊûÑ„ÄÅÂÖ≥ËäÇÁöÑËá™ÈÅÆÊå°‰ª•ÂèäÂØπÂ§ßËßÑÊ®°ÁúüÂÆû‰∏ñÁïåËøêÂä®Êï∞ÊçÆÈõÜÁöÑÈúÄÊ±ÇÔºå3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°Èù¢‰∏¥ÁùÄÂá†‰∏™ÂÖ≥ÈîÆÊåëÊàò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÊåëÊàòÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜPoint2PoseÔºåËØ•Ê°ÜÊû∂ÊúâÊïàÂú∞Âª∫Ê®°‰∫Ü‰ª•ËøûÁª≠ÁÇπ‰∫ëÂíåÂßøÊÄÅÂéÜÂè≤‰∏∫Êù°‰ª∂ÁöÑ‰∫∫‰ΩìÂßøÊÄÅÂàÜÂ∏É„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÈááÁî®Êó∂Á©∫ÁÇπ‰∫ëÁºñÁ†ÅÂô®ÂíåÂßøÊÄÅÁâπÂæÅÁºñÁ†ÅÂô®Êù•ÊèêÂèñÂÖ≥ËäÇÁõ∏ÂÖ≥ÁöÑÁâπÂæÅÔºåÁÑ∂Âêé‰ΩøÁî®Âü∫‰∫éÊ≥®ÊÑèÂäõÁöÑÁîüÊàêÂºèÂõûÂΩíÂô®„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Â§ßËßÑÊ®°ÂÆ§ÂÜÖÊï∞ÊçÆÈõÜMVPose3DÔºåÂÖ∂‰∏≠ÂåÖÂê´Â§öÁßçÊ®°ÊÄÅÔºåÂåÖÊã¨ÈùûÂπ≥Âá°‰∫∫‰ΩìËøêÂä®ÁöÑIMUÊï∞ÊçÆ„ÄÅÂØÜÈõÜÁöÑÂ§öËßÜËßíÁÇπ‰∫ëÂíåRGBÂõæÂÉè„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï‰ºò‰∫éÂü∫Á∫øÊ®°ÂûãÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÂêÑÁßçÊï∞ÊçÆÈõÜ‰∏äÁöÑÂçìË∂äÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•Â§ÑÁêÜ‰∫∫‰ΩìÂ§çÊùÇÁöÑÂá†‰ΩïÁªìÊûÑ„ÄÅÂÖ≥ËäÇËá™ÈÅÆÊå°‰ª•ÂèäÁº∫‰πèÂ§ßËßÑÊ®°ÁúüÂÆû‰∏ñÁïåËøêÂä®Êï∞ÊçÆÈõÜÁöÑÈóÆÈ¢ò„ÄÇËøô‰∫õÈóÆÈ¢òÂØºËá¥ÂßøÊÄÅ‰º∞ËÆ°Á≤æÂ∫¶‰∏çÈ´òÔºåÈ≤ÅÊ£íÊÄßËæÉÂ∑Æ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ÁîüÊàêÊ®°ÂûãÔºåÂ∞Ü3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÈóÆÈ¢òËΩ¨Âåñ‰∏∫‰∏Ä‰∏™Êù°‰ª∂ÁîüÊàêÈóÆÈ¢ò„ÄÇÈÄöËøáÂª∫Ê®°‰ª•ËøûÁª≠ÁÇπ‰∫ëÂíåÂßøÊÄÅÂéÜÂè≤‰∏∫Êù°‰ª∂ÁöÑ‰∫∫‰ΩìÂßøÊÄÅÂàÜÂ∏ÉÔºåÂèØ‰ª•Êõ¥Â•ΩÂú∞Âà©Áî®Êó∂Á©∫‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òÂßøÊÄÅ‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPoint2PoseÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏â‰∏™Ê®°ÂùóÔºöÊó∂Á©∫ÁÇπ‰∫ëÁºñÁ†ÅÂô®„ÄÅÂßøÊÄÅÁâπÂæÅÁºñÁ†ÅÂô®ÂíåÂü∫‰∫éÊ≥®ÊÑèÂäõÁöÑÁîüÊàêÂºèÂõûÂΩíÂô®„ÄÇÈ¶ñÂÖàÔºåÊó∂Á©∫ÁÇπ‰∫ëÁºñÁ†ÅÂô®Áî®‰∫éÊèêÂèñÁÇπ‰∫ëÂ∫èÂàó‰∏≠ÁöÑÊó∂Á©∫ÁâπÂæÅÔºõÁÑ∂ÂêéÔºåÂßøÊÄÅÁâπÂæÅÁºñÁ†ÅÂô®Áî®‰∫éÊèêÂèñÂéÜÂè≤ÂßøÊÄÅÁöÑÁâπÂæÅÔºõÊúÄÂêéÔºåÂü∫‰∫éÊ≥®ÊÑèÂäõÁöÑÁîüÊàêÂºèÂõûÂΩíÂô®Â∞ÜÊèêÂèñÁöÑÁâπÂæÅËûçÂêàÔºåÂπ∂ÁîüÊàêÂΩìÂâçÊó∂ÂàªÁöÑ3D‰∫∫‰ΩìÂßøÊÄÅ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫éÁîüÊàêÊ®°ÂûãÁöÑ3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°Ê°ÜÊû∂ÔºåËÉΩÂ§üÊúâÊïàÂú∞Âª∫Ê®°‰∫∫‰ΩìÂßøÊÄÅÁöÑÂàÜÂ∏ÉÔºåÂπ∂Âà©Áî®Êó∂Á©∫‰ø°ÊÅØÊèêÈ´ò‰º∞ËÆ°Á≤æÂ∫¶„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫ÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÂÖ≥Ê≥®ÂÖ≥ÈîÆÂÖ≥ËäÇÔºå‰ªéËÄåÊèêÈ´ò‰º∞ËÆ°ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊõ¥Â•ΩÂú∞Â§ÑÁêÜËá™ÈÅÆÊå°ÂíåÂô™Â£∞Á≠âÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊó∂Á©∫ÁÇπ‰∫ëÁºñÁ†ÅÂô®ÈááÁî®PointNet++ÁΩëÁªúÁªìÊûÑÔºåÁî®‰∫éÊèêÂèñÁÇπ‰∫ëÁâπÂæÅ„ÄÇÂßøÊÄÅÁâπÂæÅÁºñÁ†ÅÂô®ÈááÁî®LSTMÁΩëÁªúÁªìÊûÑÔºåÁî®‰∫éÊèêÂèñÂéÜÂè≤ÂßøÊÄÅÁöÑÊó∂Â∫èÁâπÂæÅ„ÄÇÊ≥®ÊÑèÂäõÊú∫Âà∂ÈááÁî®TransformerÁªìÊûÑÔºåÁî®‰∫éËûçÂêàÁÇπ‰∫ëÁâπÂæÅÂíåÂßøÊÄÅÁâπÂæÅ„ÄÇÊçüÂ§±ÂáΩÊï∞ÈááÁî®ÂùáÊñπËØØÂ∑ÆÊçüÂ§±ÂáΩÊï∞ÔºåÁî®‰∫éË°°Èáè‰º∞ËÆ°ÂßøÊÄÅ‰∏éÁúüÂÆûÂßøÊÄÅ‰πãÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇÊï∞ÊçÆÈõÜMVPose3DÂåÖÂê´Â§öÁßçÊ®°ÊÄÅÊï∞ÊçÆÔºå‰∏∫Ê®°ÂûãÁöÑËÆ≠ÁªÉÊèê‰æõ‰∫Ü‰∏∞ÂØåÁöÑ‰ø°ÊÅØ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPoint2PoseÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏ä‰ºò‰∫éÁé∞ÊúâÁöÑÂü∫Á∫øÊ®°Âûã„ÄÇÂ∞§ÂÖ∂ÊòØÂú®MVPose3DÊï∞ÊçÆÈõÜ‰∏äÔºåËØ•ÊñπÊ≥ïÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®Â§ÑÁêÜÂ§çÊùÇÂú∫ÊôØÂíåÂ§öÊ®°ÊÄÅÊï∞ÊçÆÊñπÈù¢ÁöÑ‰ºòÂäø„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜËÆ∫ÊñáÂº∫Ë∞É‰∫Ü‰ºò‰∫éÂü∫Á∫øÊ®°Âûã„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫é‰∫∫Êú∫‰∫§‰∫í„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅËøêÂä®ÂàÜÊûê„ÄÅÊô∫ËÉΩÁõëÊéßÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®ËôöÊãüÁé∞ÂÆû‰∏≠ÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïÂÆûÁé∞Êõ¥Ëá™ÁÑ∂„ÄÅÊõ¥ÈÄºÁúüÁöÑ‰∫∫‰ΩìÂßøÊÄÅÊçïÊçâÔºõÂú®ËøêÂä®ÂàÜÊûê‰∏≠ÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïÂàÜÊûêËøêÂä®ÂëòÁöÑÂä®‰ΩúÔºåÊèêÈ´òËÆ≠ÁªÉÊïàÊûúÔºõÂú®Êô∫ËÉΩÁõëÊéß‰∏≠ÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïËØÜÂà´ÂºÇÂ∏∏Ë°å‰∏∫ÔºåÊèêÈ´òÂÆâÂÖ®ÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We propose a novel generative approach for 3D human pose estimation. 3D human pose estimation poses several key challenges due to the complex geometry of the human body, self-occluding joints, and the requirement for large-scale real-world motion datasets. To address these challenges, we introduce Point2Pose, a framework that effectively models the distribution of human poses conditioned on sequential point cloud and pose history. Specifically, we employ a spatio-temporal point cloud encoder and a pose feature encoder to extract joint-wise features, followed by an attention-based generative regressor. Additionally, we present a large-scale indoor dataset MVPose3D, which contains multiple modalities, including IMU data of non-trivial human motions, dense multi-view point clouds, and RGB images. Experimental results show that the proposed method outperforms the baseline models, demonstrating its superior performance across various datasets.

