---
layout: default
title: Long-LRM++: Preserving Fine Details in Feed-Forward Wide-Coverage Reconstruction
---

# Long-LRM++: Preserving Fine Details in Feed-Forward Wide-Coverage Reconstruction

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.10267" target="_blank" class="toolbar-btn">arXiv: 2512.10267v1</a>
    <a href="https://arxiv.org/pdf/2512.10267.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10267v1" 
            onclick="toggleFavorite(this, '2512.10267v1', 'Long-LRM++: Preserving Fine Details in Feed-Forward Wide-Coverage Reconstruction')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Chen Ziwen, Hao Tan, Peng Wang, Zexiang Xu, Li Fuxin

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-11

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Long-LRM++ÔºöÁªìÂêàÂçäÊòæÂºèË°®Ëææ‰∏éËΩªÈáèËß£Á†ÅÂô®ÔºåÂÆûÁé∞È´òË¥®Èáè„ÄÅÂÆûÊó∂ÁöÑÂÆΩË¶ÜÁõñÂú∫ÊôØÈáçÂª∫„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `‰∏âÁª¥ÈáçÂª∫` `È´òÊñØÊ∫ÖÂ∞Ñ` `ÈöêÂºèË°®Ëææ` `ÂÆûÊó∂Ê∏≤Êüì` `ÂçäÊòæÂºèË°®Á§∫` `ËΩªÈáèÁ∫ßËß£Á†ÅÂô®` `Â§öËßÜËßíÈáçÂª∫` `Âú∫ÊôØÈáçÂª∫`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÈÄöÁî®È´òÊñØÊ∫ÖÂ∞ÑÊñπÊ≥ïÂú®ÈáçÂª∫Á≤æÁªÜÁªìÊûÑÊó∂ÊòìÂá∫Áé∞Ê®°Á≥äÔºåÈöêÂºèË°®ËææÊñπÊ≥ïÊ∏≤ÊüìË¥®ÈáèÈ´ò‰ΩÜËÆ°ÁÆóÈáèÂ§ßÔºåÈöæ‰ª•ÂÆûÊó∂Ê∏≤Êüì„ÄÇ
2. Long-LRM++ÈááÁî®ÂçäÊòæÂºèÂú∫ÊôØË°®Á§∫ÔºåÁªìÂêàËΩªÈáèÁ∫ßËß£Á†ÅÂô®ÔºåÊó®Âú®ÂÖºÈ°æÊ∏≤ÊüìË¥®ÈáèÂíåÂÆûÊó∂ÊÄßÔºåÂÆûÁé∞È´òÊïàÁöÑÂú∫ÊôØÈáçÂª∫„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåLong-LRM++Âú®DL3DVÊï∞ÊçÆÈõÜ‰∏äËææÂà∞LaCTÁöÑÊ∏≤ÊüìË¥®ÈáèÔºåÂπ∂Âú®A100 GPU‰∏äÂÆûÁé∞14 FPSÁöÑÂÆûÊó∂Ê∏≤ÊüìÔºåÂêåÊó∂ÂÖ∑Â§áËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈÄöÁî®È´òÊñØÊ∫ÖÂ∞Ñ(GS)ÁöÑÊúÄÊñ∞ËøõÂ±ï‰ΩøÂæóËÉΩÂ§ü‰ªéÊï∞ÂçÅ‰∏™ËæìÂÖ•ËßÜÂõæËøõË°åÂâçÈ¶àÂú∫ÊôØÈáçÂª∫„ÄÇLong-LRMÊòæËëóÂú∞Â∞ÜËøôÁßçËåÉÂºèÊâ©Â±ïÂà∞32‰∏™ËæìÂÖ•ÂõæÂÉèÔºåÂàÜËæ®Áéá‰∏∫950x540Ôºå‰ªéËÄåÂú®Âçï‰∏™ÂâçÂêë‰º†ÈÄí‰∏≠ÂÆûÁé∞360¬∞Âú∫ÊôØÁ∫ßÈáçÂª∫„ÄÇÁÑ∂ËÄåÔºåÁõ¥Êé•‰∏ÄÊ¨°ÊÄßÈ¢ÑÊµãÊï∞Áôæ‰∏á‰∏™È´òÊñØÂèÇÊï∞‰ªçÁÑ∂ÂØπËØØÂ∑ÆÈ´òÂ∫¶ÊïèÊÑüÔºö‰ΩçÁΩÆÊàñÂÖ∂‰ªñÂ±ûÊÄß‰∏äÁöÑÂæÆÂ∞è‰∏çÂáÜÁ°Æ‰ºöÂØºËá¥ÊòéÊòæÁöÑÊ®°Á≥äÔºåÂ∞§ÂÖ∂ÊòØÂú®ÊñáÊú¨Á≠âÁ≤æÁªÜÁªìÊûÑ‰∏≠„ÄÇ‰∏éÊ≠§ÂêåÊó∂ÔºåLVSMÂíåLaCTÁ≠âÈöêÂºèË°®Á§∫ÊñπÊ≥ïÈÄöËøáÂ∞ÜÂú∫ÊôØ‰ø°ÊÅØÂéãÁº©Âà∞Ê®°ÂûãÊùÉÈáç‰∏≠ÔºåËÄå‰∏çÊòØÊòæÂºèÈ´òÊñØ‰∏≠ÔºåÂπ∂‰ΩøÁî®ÂÆåÊï¥ÁöÑtransformerÊàñTTTÈ™®Âπ≤Ëß£Á†ÅRGBÂ∏ßÔºå‰ªéËÄåÂ±ïÁ§∫‰∫ÜÊòæËëóÊõ¥È´òÁöÑÊ∏≤Êüì‰øùÁúüÂ∫¶„ÄÇÁÑ∂ËÄåÔºåÂØπ‰∫éÊØè‰∏™Ê∏≤ÊüìÂ∏ßÁöÑËøôÁßçËÆ°ÁÆóÂØÜÈõÜÂûãËß£ÂéãÁº©ËøáÁ®ã‰ΩøÂæóÂÆûÊó∂Ê∏≤ÊüìÂèòÂæó‰∏çÂèØË°å„ÄÇËøô‰∫õËßÇÂØüÁªìÊûúÊèêÂá∫‰∫ÜÂÖ≥ÈîÆÈóÆÈ¢òÔºöÊ∑±Â∫¶„ÄÅÈ°∫Â∫èÁöÑ‚ÄúËß£ÂéãÁº©‚ÄùËøáÁ®ãÊòØÂøÖË¶ÅÁöÑÂêóÔºüÊàë‰ª¨ËÉΩÂê¶Âú®‰øùÊåÅÈöêÂºèË°®Á§∫‰ºòÂäøÁöÑÂêåÊó∂ÂÆûÁé∞ÂÆûÊó∂ÊÄßËÉΩÔºüÊàë‰ª¨‰ΩøÁî®Long-LRM++Êù•Ëß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåLong-LRM++ÈááÁî®ÂçäÊòæÂºèÂú∫ÊôØË°®Á§∫ÔºåÂπ∂ÁªìÂêàËΩªÈáèÁ∫ßËß£Á†ÅÂô®„ÄÇLong-LRM++Âú®DL3DV‰∏äÂåπÈÖç‰∫ÜLaCTÁöÑÊ∏≤ÊüìË¥®ÈáèÔºåÂêåÊó∂Âú®A100 GPU‰∏äÂÆûÁé∞‰∫ÜÂÆûÊó∂14 FPSÊ∏≤ÊüìÔºåÂÖãÊúç‰∫ÜÂÖàÂâçÈöêÂºèÊñπÊ≥ïÁöÑÈÄüÂ∫¶ÈôêÂà∂„ÄÇÊàë‰ª¨ÁöÑËÆæËÆ°ËøòÊâ©Â±ïÂà∞64‰∏™ËæìÂÖ•ËßÜÂõæÔºåÂàÜËæ®Áéá‰∏∫950x540ÔºåÂ±ïÁ§∫‰∫ÜÂØπÂ¢ûÂä†ÁöÑËæìÂÖ•ÈïøÂ∫¶ÁöÑÂº∫Â§ßÊ≥õÂåñËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºå‰∏éÁõ¥Êé•‰ªéÈ´òÊñØÊ∏≤ÊüìÊ∑±Â∫¶Áõ∏ÊØîÔºåLong-LRM++Âú®ScanNetv2‰∏äÊèê‰æõ‰∫ÜÂçìË∂äÁöÑÊñ∞ËßÜËßíÊ∑±Â∫¶È¢ÑÊµã„ÄÇÂπøÊ≥õÁöÑÊ∂àËûçÁ†îÁ©∂È™åËØÅ‰∫ÜÊâÄÊèêÂá∫Ê°ÜÊû∂‰∏≠ÊØè‰∏™ÁªÑ‰ª∂ÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰ªéÂ§öËßÜËßíÂõæÂÉèÈáçÂª∫‰∏âÁª¥Âú∫ÊôØÁöÑÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÂÖ≥Ê≥®Â¶Ç‰ΩïÂú®‰øùËØÅÊ∏≤ÊüìË¥®ÈáèÔºàÁâπÂà´ÊòØÁ≤æÁªÜÁªìÊûÑÔºâÁöÑÂêåÊó∂ÔºåÂÆûÁé∞ÂÆûÊó∂Ê∏≤Êüì„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÂ¶ÇLong-LRMÔºåËôΩÁÑ∂ËÉΩÂø´ÈÄüÈáçÂª∫Ôºå‰ΩÜÂú®Á≤æÁªÜÁªìÊûÑ‰∏äÂ≠òÂú®Ê®°Á≥äÔºõËÄåÈöêÂºèË°®ËææÊñπÊ≥ïÔºåÂ¶ÇLaCTÔºåËôΩÁÑ∂Ê∏≤ÊüìË¥®ÈáèÈ´òÔºå‰ΩÜËÆ°ÁÆóÈáèÂ§ßÔºåÊó†Ê≥ïÂÆûÊó∂Ê∏≤Êüì„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈááÁî®‰∏ÄÁßçÂçäÊòæÂºèÁöÑÂú∫ÊôØË°®Á§∫ÊñπÊ≥ïÔºåÂç≥‰∏çÂÆåÂÖ®‰æùËµñÊòæÂºèÁöÑÈ´òÊñØÂèÇÊï∞Ôºå‰πü‰∏çÂÆåÂÖ®‰æùËµñÈöêÂºèÁöÑÊ®°ÂûãÊùÉÈáç„ÄÇÈÄöËøáÁªìÂêàÊòæÂºèË°®ËææÁöÑÂø´ÈÄüÊÄßÂíåÈöêÂºèË°®ËææÁöÑÈ´òË¥®ÈáèÔºåÂπ∂ËÆæËÆ°‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑËß£Á†ÅÂô®Ôºå‰ªéËÄåÂú®Ê∏≤ÊüìË¥®ÈáèÂíåÈÄüÂ∫¶‰πãÈó¥ÂèñÂæóÂπ≥Ë°°„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöLong-LRM++ÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Â§öËßÜËßíÂõæÂÉèËæìÂÖ•Ôºõ2) ÁâπÂæÅÊèêÂèñÁΩëÁªúÔºàÂèØËÉΩÊòØ‰øÆÊîπËøáÁöÑLong-LRMÁöÑencoderÔºâÔºõ3) ÂçäÊòæÂºèÂú∫ÊôØË°®Á§∫Ôºà‰æãÂ¶ÇÔºåÁ®ÄÁñèÁöÑÈ´òÊñØÂèÇÊï∞Âä†‰∏ä‰∏Ä‰∫õÈöêÂºèÁâπÂæÅÔºâÔºõ4) ËΩªÈáèÁ∫ßËß£Á†ÅÂô®ÔºåÁî®‰∫éÂ∞ÜÂçäÊòæÂºèË°®Á§∫Ëß£Á†Å‰∏∫RGBÂõæÂÉèÔºõ5) Ê∏≤ÊüìÊ®°ÂùóÔºåÂ∞ÜËß£Á†ÅÂêéÁöÑ‰ø°ÊÅØÊ∏≤ÊüìÊàêÊúÄÁªàÂõæÂÉè„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØ‰∏Ä‰∏™ÂâçÂêëËøáÁ®ãÔºåÂèØ‰ª•ÂÆûÁé∞Âø´ÈÄüÊ∏≤Êüì„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöLong-LRM++ÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÂçäÊòæÂºèÁöÑÂú∫ÊôØË°®Á§∫ÂíåËΩªÈáèÁ∫ßËß£Á†ÅÂô®ÁöÑËÆæËÆ°„ÄÇ‰∏éÂÆåÂÖ®ÊòæÂºèÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÂçäÊòæÂºèË°®Á§∫ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÊçïÊçâÂú∫ÊôØÁöÑÁªÜËäÇ‰ø°ÊÅØÔºõ‰∏éÂÆåÂÖ®ÈöêÂºèÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåËΩªÈáèÁ∫ßËß£Á†ÅÂô®ËÉΩÂ§üÊòæËëóÈôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶Ôºå‰ªéËÄåÂÆûÁé∞ÂÆûÊó∂Ê∏≤Êüì„ÄÇËøôÁßçÊ∑∑ÂêàÁ≠ñÁï•ÊòØËØ•ÊñπÊ≥ïÁöÑÊ†∏ÂøÉÂàõÊñ∞„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰∏≠ÂèØËÉΩÂåÖÂê´‰ª•‰∏ãÂÖ≥ÈîÆËÆæËÆ°ÁªÜËäÇÔºö1) ÂçäÊòæÂºèË°®Á§∫ÁöÑÂÖ∑‰ΩìÂΩ¢ÂºèÔºå‰æãÂ¶ÇÔºåÈ´òÊñØÂèÇÊï∞ÁöÑÊï∞Èáè„ÄÅÈöêÂºèÁâπÂæÅÁöÑÁª¥Â∫¶Á≠âÔºõ2) ËΩªÈáèÁ∫ßËß£Á†ÅÂô®ÁöÑÁΩëÁªúÁªìÊûÑÔºå‰æãÂ¶ÇÔºåÂç∑ÁßØÂ±Ç„ÄÅÂÖ®ËøûÊé•Â±Ç„ÄÅÊ≥®ÊÑèÂäõÊú∫Âà∂Á≠âÔºõ3) ÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°Ôºå‰æãÂ¶ÇÔºåRGBÈáçÂª∫ÊçüÂ§±„ÄÅÊ∑±Â∫¶ÊçüÂ§±„ÄÅÊ≠£ÂàôÂåñÈ°πÁ≠âÔºõ4) ËÆ≠ÁªÉÁ≠ñÁï•Ôºå‰æãÂ¶ÇÔºåÂ≠¶‰π†Áéá„ÄÅbatch size„ÄÅ‰ºòÂåñÂô®Á≠â„ÄÇËøô‰∫õÁªÜËäÇÂØπÊúÄÁªàÁöÑÊÄßËÉΩËá≥ÂÖ≥ÈáçË¶ÅÔºå‰ΩÜÂÖ∑‰ΩìÁªÜËäÇÈúÄË¶ÅÂèÇËÄÉËÆ∫ÊñáÂéüÊñá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Long-LRM++Âú®DL3DVÊï∞ÊçÆÈõÜ‰∏äËææÂà∞‰∫Ü‰∏éLaCTÁõ∏ÂΩìÁöÑÊ∏≤ÊüìË¥®ÈáèÔºåÂêåÊó∂Âú®A100 GPU‰∏äÂÆûÁé∞‰∫Ü14 FPSÁöÑÂÆûÊó∂Ê∏≤ÊüìÔºåÊòæËëó‰ºò‰∫éÁé∞ÊúâÈöêÂºèË°®ËææÊñπÊ≥ïÁöÑÈÄüÂ∫¶„ÄÇÊ≠§Â§ñÔºåLong-LRM++Âú®ScanNetv2Êï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜÊõ¥Â•ΩÁöÑÊñ∞ËßÜËßíÊ∑±Â∫¶È¢ÑÊµãÔºåÂπ∂‰∏îËÉΩÂ§üÊâ©Â±ïÂà∞64‰∏™ËæìÂÖ•ËßÜÂõæÔºåÂ±ïÁ§∫‰∫ÜËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊ∂àËûçÂÆûÈ™åÈ™åËØÅ‰∫ÜÂêÑ‰∏™ÁªÑ‰ª∂ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Long-LRM++Âú®‰∏âÁª¥ÈáçÂª∫È¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆû„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊ∏∏ÊàèÂºÄÂèëÁ≠â„ÄÇËØ•ÊñπÊ≥ïËÉΩÂ§üÂø´ÈÄü„ÄÅÈ´òË¥®ÈáèÂú∞ÈáçÂª∫Âú∫ÊôØÔºå‰∏∫Áî®Êà∑Êèê‰æõÊ≤âÊµ∏ÂºèÁöÑ‰ΩìÈ™åÔºåÂπ∂‰∏∫Êú∫Âô®‰∫∫Êèê‰æõÂáÜÁ°ÆÁöÑÁéØÂ¢ÉÊÑüÁü•‰ø°ÊÅØ„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÂ∫îÁî®‰∫éÊõ¥Â§ßËßÑÊ®°„ÄÅÊõ¥Â§çÊùÇÁöÑÂú∫ÊôØÈáçÂª∫ÔºåÂπ∂‰∏éÂÖ∂‰ªñÊäÄÊúØÁõ∏ÁªìÂêàÔºåÂÆûÁé∞Êõ¥Êô∫ËÉΩÂåñÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent advances in generalizable Gaussian splatting (GS) have enabled feed-forward reconstruction of scenes from tens of input views. Long-LRM notably scales this paradigm to 32 input images at $950\times540$ resolution, achieving 360¬∞ scene-level reconstruction in a single forward pass. However, directly predicting millions of Gaussian parameters at once remains highly error-sensitive: small inaccuracies in positions or other attributes lead to noticeable blurring, particularly in fine structures such as text. In parallel, implicit representation methods such as LVSM and LaCT have demonstrated significantly higher rendering fidelity by compressing scene information into model weights rather than explicit Gaussians, and decoding RGB frames using the full transformer or TTT backbone. However, this computationally intensive decompression process for every rendered frame makes real-time rendering infeasible. These observations raise key questions: Is the deep, sequential "decompression" process necessary? Can we retain the benefits of implicit representations while enabling real-time performance? We address these questions with Long-LRM++, a model that adopts a semi-explicit scene representation combined with a lightweight decoder. Long-LRM++ matches the rendering quality of LaCT on DL3DV while achieving real-time 14 FPS rendering on an A100 GPU, overcoming the speed limitations of prior implicit methods. Our design also scales to 64 input views at the $950\times540$ resolution, demonstrating strong generalization to increased input lengths. Additionally, Long-LRM++ delivers superior novel-view depth prediction on ScanNetv2 compared to direct depth rendering from Gaussians. Extensive ablation studies validate the effectiveness of each component in the proposed framework.

