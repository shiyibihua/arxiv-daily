---
layout: default
title: Perceive, Reflect and Understand Long Video: Progressive Multi-Granular Clue Exploration with Interactive Agents
---

# Perceive, Reflect and Understand Long Video: Progressive Multi-Granular Clue Exploration with Interactive Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.24943" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.24943v1</a>
  <a href="https://arxiv.org/pdf/2509.24943.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.24943v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.24943v1', 'Perceive, Reflect and Understand Long Video: Progressive Multi-Granular Clue Exploration with Interactive Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiahua Li, Kun Wei, Zhe Xu, Zibo Su, Xu Yang, Cheng Deng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**CogniGPTï¼šäº¤äº’å¼å¤šç²’åº¦çº¿ç´¢æ¢ç´¢ï¼Œæå‡é•¿è§†é¢‘ç†è§£çš„æ•ˆç‡ä¸å¯é æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿è§†é¢‘ç†è§£` `å¤šç²’åº¦æ„ŸçŸ¥` `äº¤äº’å¼ä»£ç†` `è§†è§‰è®¤çŸ¥` `å¤§å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºLLMçš„é•¿è§†é¢‘ç†è§£æ–¹æ³•åœ¨æ•è·å…³é”®ä¿¡æ¯çš„å®Œæ•´æ€§å’Œæ•ˆç‡ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥å…¼é¡¾ã€‚
2. CogniGPTé€šè¿‡å¤šç²’åº¦æ„ŸçŸ¥ä»£ç†å’ŒéªŒè¯å¢å¼ºåå°„ä»£ç†çš„äº¤äº’ï¼Œæ¨¡æ‹Ÿäººç±»è§†è§‰è®¤çŸ¥è¿‡ç¨‹ï¼Œé«˜æ•ˆæ¢ç´¢ä»»åŠ¡ç›¸å…³çº¿ç´¢ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒCogniGPTåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œåœ¨EgoSchemaä¸Šä»…ç”¨å°‘é‡å¸§å°±è¾¾åˆ°ä¸Gemini 1.5-Proç›¸å½“çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é•¿è§†é¢‘ç”±äºå…¶æ—¶é—´å¤æ‚æ€§å’Œç¨€ç–çš„ä»»åŠ¡ç›¸å…³ä¿¡æ¯ï¼Œç»™AIç³»ç»Ÿå¸¦æ¥äº†å·¨å¤§çš„æ¨ç†æŒ‘æˆ˜ã€‚å°½ç®¡å„ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–¹æ³•åœ¨é•¿è§†é¢‘ç†è§£æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†å®ƒä»¬åœ¨æ•è·ä»»åŠ¡å…³é”®ä¿¡æ¯çš„å®Œæ•´æ€§å’Œæ•ˆç‡æ–¹é¢ä»ç„¶å­˜åœ¨å›°éš¾ã€‚å—äººç±»æ¸è¿›å¼è§†è§‰è®¤çŸ¥çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†CogniGPTï¼Œä¸€ä¸ªåˆ©ç”¨å¤šç²’åº¦æ„ŸçŸ¥ä»£ç†ï¼ˆMGPAï¼‰å’ŒéªŒè¯å¢å¼ºåå°„ä»£ç†ï¼ˆVERAï¼‰ä¹‹é—´çš„äº¤äº’å¾ªç¯çš„æ¡†æ¶ï¼Œç”¨äºé«˜æ•ˆå’Œå¯é çš„é•¿è§†é¢‘ç†è§£ã€‚å…·ä½“æ¥è¯´ï¼ŒMGPAæ¨¡ä»¿äººç±»è§†è§‰çš„å‘æ•£å’Œèšç„¦æ³¨æ„åŠ›æ¥æ•è·ä»»åŠ¡ç›¸å…³ä¿¡æ¯ï¼Œè€ŒVERAéªŒè¯æ„ŸçŸ¥åˆ°çš„å…³é”®çº¿ç´¢ï¼Œä»¥å‡è½»å¹»è§‰å¹¶ä¼˜åŒ–åç»­çš„æ„ŸçŸ¥ç­–ç•¥ã€‚é€šè¿‡è¿™ç§äº¤äº’è¿‡ç¨‹ï¼ŒCogniGPTæ¢ç´¢æœ€å°‘æ•°é‡çš„ä¿¡æ¯ä¸°å¯Œä¸”å¯é çš„ä»»åŠ¡ç›¸å…³çº¿ç´¢ã€‚åœ¨EgoSchemaã€Video-MMEã€NExT-QAå’ŒMovieChatæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCogniGPTåœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨EgoSchemaä¸Šï¼Œå®ƒä»…ä½¿ç”¨11.2å¸§å°±è¶…è¶Šäº†ç°æœ‰çš„å…è®­ç»ƒæ–¹æ³•ï¼Œå¹¶è¾¾åˆ°äº†ä¸Gemini 1.5-Proç›¸å½“çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šé•¿è§†é¢‘ç†è§£ä»»åŠ¡é¢ä¸´æ—¶é—´è·¨åº¦å¤§ã€ä¿¡æ¯å†—ä½™ã€å…³é”®ä¿¡æ¯ç¨€ç–ç­‰æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨ä¿è¯ä¿¡æ¯å®Œæ•´æ€§çš„åŒæ—¶ï¼Œå®ç°é«˜æ•ˆæ¨ç†ï¼Œå¹¶ä¸”å®¹æ˜“äº§ç”Ÿå¹»è§‰ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ¨¡ä»¿äººç±»çš„è§†è§‰è®¤çŸ¥è¿‡ç¨‹ï¼Œé‡‡ç”¨æ¸è¿›å¼ã€äº¤äº’å¼çš„æ¢ç´¢æ–¹å¼ã€‚é€šè¿‡å‘æ•£å’Œèšç„¦æ³¨æ„åŠ›ï¼Œé€æ­¥æå–å…³é”®ä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨éªŒè¯æœºåˆ¶å‡å°‘å¹»è§‰ï¼Œæé«˜ä¿¡æ¯å¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCogniGPTåŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå¤šç²’åº¦æ„ŸçŸ¥ä»£ç†ï¼ˆMGPAï¼‰å’ŒéªŒè¯å¢å¼ºåå°„ä»£ç†ï¼ˆVERAï¼‰ã€‚MGPAè´Ÿè´£ä»è§†é¢‘ä¸­æå–ä¸åŒç²’åº¦çš„ä¿¡æ¯ï¼Œæ¨¡æ‹Ÿäººç±»è§†è§‰çš„å‘æ•£å’Œèšç„¦è¿‡ç¨‹ã€‚VERAåˆ™è´Ÿè´£éªŒè¯MGPAæå–çš„å…³é”®çº¿ç´¢ï¼Œè¯„ä¼°å…¶å¯é æ€§ï¼Œå¹¶æŒ‡å¯¼MGPAè¿›è¡Œåç»­çš„æ„ŸçŸ¥ç­–ç•¥è°ƒæ•´ã€‚è¿™ä¸¤ä¸ªæ¨¡å—é€šè¿‡äº¤äº’å¾ªç¯ï¼Œé€æ­¥æç‚¼å‡ºæœ€ç›¸å…³çš„ä»»åŠ¡ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥äº¤äº’å¼çš„ä»£ç†æ¶æ„ï¼Œæ¨¡æ‹Ÿäººç±»è§†è§‰è®¤çŸ¥è¿‡ç¨‹ï¼Œå®ç°é«˜æ•ˆä¸”å¯é çš„é•¿è§†é¢‘ç†è§£ã€‚é€šè¿‡å¤šç²’åº¦æ„ŸçŸ¥å’ŒéªŒè¯æœºåˆ¶ï¼Œæœ‰æ•ˆå‡å°‘äº†å¹»è§‰ï¼Œæé«˜äº†ä¿¡æ¯æå–çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šMGPAé‡‡ç”¨å¤šå±‚çº§çš„è§†è§‰ç‰¹å¾æå–å™¨ï¼Œæ•æ‰ä¸åŒæ—¶é—´å°ºåº¦çš„ä¿¡æ¯ã€‚VERAä½¿ç”¨LLMè¿›è¡Œçº¿ç´¢éªŒè¯ï¼Œå¹¶æ ¹æ®éªŒè¯ç»“æœè°ƒæ•´MGPAçš„æ³¨æ„åŠ›æƒé‡ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡æ—¨åœ¨é¼“åŠ±MGPAæå–æ›´å¯é ã€æ›´ç›¸å…³çš„çº¿ç´¢ï¼Œå¹¶æƒ©ç½šVERAçš„é”™è¯¯éªŒè¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CogniGPTåœ¨EgoSchemaæ•°æ®é›†ä¸Šï¼Œä»…ä½¿ç”¨11.2å¸§å°±è¶…è¶Šäº†ç°æœ‰çš„å…è®­ç»ƒæ–¹æ³•ï¼Œå¹¶è¾¾åˆ°äº†ä¸Gemini 1.5-Proç›¸å½“çš„æ€§èƒ½ã€‚åœ¨Video-MMEã€NExT-QAå’ŒMovieChatç­‰æ•°æ®é›†ä¸Šä¹Ÿå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†å…¶åœ¨é•¿è§†é¢‘ç†è§£æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCogniGPTåœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CogniGPTå¯åº”ç”¨äºæ™ºèƒ½ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ã€è§†é¢‘å†…å®¹åˆ†æã€æ™ºèƒ½å®¢æœç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½ç›‘æ§ä¸­ï¼Œå¯ä»¥å¿«é€Ÿå®šä½å¼‚å¸¸äº‹ä»¶ï¼›åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥å‡†ç¡®ç†è§£å¤æ‚çš„äº¤é€šåœºæ™¯ï¼›åœ¨è§†é¢‘å†…å®¹åˆ†æä¸­ï¼Œå¯ä»¥è‡ªåŠ¨æå–å…³é”®ä¿¡æ¯ï¼Œç”Ÿæˆæ‘˜è¦æˆ–æ ‡ç­¾ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæå‡AIç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æ„ŸçŸ¥å’Œç†è§£èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Long videos, characterized by temporal complexity and sparse task-relevant information, pose significant reasoning challenges for AI systems. Although various Large Language Model (LLM)-based approaches have advanced long video understanding, they still struggle to achieve both completeness and efficiency in capturing task-critical information. Inspired by human progressive visual cognition, we propose CogniGPT, a framework that leverages an interactive loop between Multi-Granular Perception Agent (MGPA) and Verification-Enhanced Reflection Agent (VERA) for efficient and reliable long video understanding. Specifically, MGPA mimics human visual divergent and focused attention to capture task-related information, while VERA verifies perceived key clues to mitigate hallucination and optimize subsequent perception strategies. Through this interactive process, CogniGPT explores a minimal set of informative and reliable task-related clues. Extensive experiments on EgoSchema, Video-MME, NExT-QA, and MovieChat datasets demonstrate CogniGPT's superiority in both accuracy and efficiency. Notably, on EgoSchema, it surpasses existing training-free methods using only 11.2 frames and achieves performance comparable to Gemini 1.5-Pro.

