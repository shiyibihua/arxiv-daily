---
layout: default
title: DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation
---

# DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.24896" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.24896v1</a>
  <a href="https://arxiv.org/pdf/2509.24896.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.24896v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.24896v1', 'DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xi Chen, Hongxun Yao, Zhaopan Xu, Kui Jiang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

**å¤‡æ³¨**: 5 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDAMï¼Œåˆ©ç”¨å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹è¿›è¡Œæ— æºåŸŸè‡ªé€‚åº”åŒé‡ä¸»åŠ¨å­¦ä¹ ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ— æºåŸŸè‡ªé€‚åº”` `ä¸»åŠ¨å­¦ä¹ ` `å¤šæ¨¡æ€å­¦ä¹ ` `è§†è§‰-è¯­è¨€æ¨¡å‹` `çŸ¥è¯†è’¸é¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ— æºåŸŸä¸»åŠ¨åŸŸè‡ªé€‚åº”æ–¹æ³•æœªèƒ½æœ‰æ•ˆèåˆè§†è§‰-è¯­è¨€æ¨¡å‹å’Œæ•°æ®ç›‘ç£ï¼Œå¯¼è‡´çŸ¥è¯†è¿ç§»æ•ˆç‡å—é™ã€‚
2. DAMæ¡†æ¶æ•´åˆViLæ¨¡å‹çš„å¤šæ¨¡æ€ç›‘ç£å’Œäººå·¥æ ‡æ³¨ï¼Œå½¢æˆåŒé‡ç›‘ç£ä¿¡å·ï¼Œæå‡ç›®æ ‡åŸŸæ¨¡å‹çš„å­¦ä¹ æ•ˆæœã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDAMåœ¨å¤šä¸ªSFADAåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ— æºåŸŸä¸»åŠ¨åŸŸè‡ªé€‚åº”(SFADA)æ—¨åœ¨åˆ©ç”¨ä¸»åŠ¨å­¦ä¹ é€‰æ‹©çš„å°‘é‡äººå·¥æ ‡æ³¨ï¼Œå¢å¼ºçŸ¥è¯†ä»æºæ¨¡å‹åˆ°æ— æ ‡ç­¾ç›®æ ‡åŸŸçš„è¿ç§»ã€‚ç°æœ‰ç ”ç©¶å¼•å…¥è§†è§‰-è¯­è¨€(ViL)æ¨¡å‹ä»¥æå‡ä¼ªæ ‡ç­¾è´¨é‡æˆ–ç‰¹å¾å¯¹é½ï¼Œä½†å¸¸å°†ViLå’Œæ•°æ®ç›‘ç£è§†ä¸ºç‹¬ç«‹æ¥æºï¼Œç¼ºä¹æœ‰æ•ˆèåˆã€‚ä¸ºå…‹æœæ­¤é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºåŸºäºå¤šæ¨¡æ€(DAM)åŸºç¡€æ¨¡å‹çš„åŒé‡ä¸»åŠ¨å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ•´åˆViLæ¨¡å‹çš„å¤šæ¨¡æ€ç›‘ç£ï¼Œä»¥è¡¥å……ç¨€ç–çš„äººå·¥æ ‡æ³¨ï¼Œä»è€Œå½¢æˆåŒé‡ç›‘ç£ä¿¡å·ã€‚DAMåˆå§‹åŒ–ç¨³å®šçš„ViLå¼•å¯¼ç›®æ ‡ï¼Œå¹¶é‡‡ç”¨åŒå‘è’¸é¦æœºåˆ¶ï¼Œåœ¨è¿­ä»£è‡ªé€‚åº”è¿‡ç¨‹ä¸­ä¿ƒè¿›ç›®æ ‡æ¨¡å‹ä¸åŒé‡ç›‘ç£ä¹‹é—´çš„çŸ¥è¯†äº’æ¢ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDAMå§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨å¤šä¸ªSFADAåŸºå‡†å’Œä¸»åŠ¨å­¦ä¹ ç­–ç•¥ä¸Šå–å¾—äº†æ–°çš„state-of-the-artã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ— æºåŸŸä¸»åŠ¨åŸŸè‡ªé€‚åº”(SFADA)é—®é¢˜ï¼Œå³åœ¨æ²¡æœ‰æºåŸŸæ•°æ®çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨å°‘é‡äººå·¥æ ‡æ³¨å°†çŸ¥è¯†ä»æºæ¨¡å‹è¿ç§»åˆ°æ— æ ‡ç­¾ç›®æ ‡åŸŸã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å°†è§†è§‰-è¯­è¨€(ViL)æ¨¡å‹æä¾›çš„å¤šæ¨¡æ€ä¿¡æ¯å’Œäººå·¥æ ‡æ³¨çš„æ•°æ®ç›‘ç£è§†ä¸ºç‹¬ç«‹çš„ç›‘ç£æ¥æºï¼Œç¼ºä¹æœ‰æ•ˆçš„èåˆæœºåˆ¶ï¼Œå¯¼è‡´ç›®æ ‡åŸŸæ¨¡å‹å­¦ä¹ æ•ˆç‡ä¸é«˜ï¼Œæ€§èƒ½æå‡æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ViLæ¨¡å‹æä¾›çš„å¤šæ¨¡æ€ä¿¡æ¯æ¥è¾…åŠ©äººå·¥æ ‡æ³¨ï¼Œå½¢æˆåŒé‡ç›‘ç£ä¿¡å·ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°æŒ‡å¯¼ç›®æ ‡åŸŸæ¨¡å‹çš„å­¦ä¹ ã€‚é€šè¿‡åŒå‘è’¸é¦æœºåˆ¶ï¼Œä¿ƒè¿›ç›®æ ‡æ¨¡å‹ä¸ViLæ¨¡å‹ä»¥åŠäººå·¥æ ‡æ³¨æ•°æ®ä¹‹é—´çš„çŸ¥è¯†äº’æ¢ï¼Œæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDAMæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) ViLå¼•å¯¼çš„ç›®æ ‡åˆå§‹åŒ–ï¼šåˆ©ç”¨ViLæ¨¡å‹ä¸ºç›®æ ‡åŸŸæ•°æ®ç”Ÿæˆåˆå§‹çš„ä¼ªæ ‡ç­¾ï¼Œä½œä¸ºç›®æ ‡æ¨¡å‹å­¦ä¹ çš„èµ·ç‚¹ã€‚2) åŒé‡ç›‘ç£ä¿¡å·èåˆï¼šå°†ViLæ¨¡å‹æä¾›çš„å¤šæ¨¡æ€ç›‘ç£ä¿¡å·ä¸äººå·¥æ ‡æ³¨çš„æ•°æ®ç›‘ç£ä¿¡å·è¿›è¡Œèåˆï¼Œå½¢æˆåŒé‡ç›‘ç£ä¿¡å·ã€‚3) åŒå‘è’¸é¦æœºåˆ¶ï¼šé€šè¿‡åŒå‘è’¸é¦ï¼Œç›®æ ‡æ¨¡å‹ä»ViLæ¨¡å‹å’Œäººå·¥æ ‡æ³¨æ•°æ®ä¸­å­¦ä¹ çŸ¥è¯†ï¼ŒåŒæ—¶ViLæ¨¡å‹ä¹Ÿä»ç›®æ ‡æ¨¡å‹ä¸­å­¦ä¹ ç›®æ ‡åŸŸçš„ç‰¹å®šçŸ¥è¯†ï¼Œå®ç°çŸ¥è¯†çš„äº’æ¢å’Œæå‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†åŒé‡ä¸»åŠ¨å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°èåˆViLæ¨¡å‹æä¾›çš„å¤šæ¨¡æ€ä¿¡æ¯å’Œäººå·¥æ ‡æ³¨çš„æ•°æ®ç›‘ç£ï¼Œå½¢æˆæ›´å¼ºçš„ç›‘ç£ä¿¡å·ã€‚æ­¤å¤–ï¼ŒåŒå‘è’¸é¦æœºåˆ¶èƒ½å¤Ÿä¿ƒè¿›ç›®æ ‡æ¨¡å‹ä¸ViLæ¨¡å‹ä¹‹é—´çš„çŸ¥è¯†äº’æ¢ï¼Œè¿›ä¸€æ­¥æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDAMèƒ½å¤Ÿæ›´å……åˆ†åœ°åˆ©ç”¨ViLæ¨¡å‹æä¾›çš„å¤šæ¨¡æ€ä¿¡æ¯ï¼Œä»è€Œåœ¨SFADAä»»åŠ¡ä¸­å–å¾—æ›´å¥½çš„æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šDAMæ¡†æ¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ViLæ¨¡å‹çš„é€‰æ‹©ï¼šé€‰æ‹©åˆé€‚çš„ViLæ¨¡å‹ï¼Œä¾‹å¦‚CLIPï¼Œä»¥æä¾›é«˜è´¨é‡çš„å¤šæ¨¡æ€ä¿¡æ¯ã€‚2) ä¼ªæ ‡ç­¾ç”Ÿæˆç­–ç•¥ï¼šè®¾è®¡æœ‰æ•ˆçš„ä¼ªæ ‡ç­¾ç”Ÿæˆç­–ç•¥ï¼Œä»¥ç¡®ä¿ä¼ªæ ‡ç­¾çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚3) åŒå‘è’¸é¦æŸå¤±å‡½æ•°ï¼šè®¾è®¡åˆé€‚çš„åŒå‘è’¸é¦æŸå¤±å‡½æ•°ï¼Œä»¥ä¿ƒè¿›ç›®æ ‡æ¨¡å‹ä¸ViLæ¨¡å‹ä¹‹é—´çš„çŸ¥è¯†äº’æ¢ã€‚4) ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ï¼šé€‰æ‹©åˆé€‚çš„ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ï¼Œä¾‹å¦‚ä¸ç¡®å®šæ€§é‡‡æ ·ï¼Œä»¥é€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„æ ·æœ¬è¿›è¡Œäººå·¥æ ‡æ³¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDAMåœ¨å¤šä¸ªSFADAåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨Office-Homeæ•°æ®é›†ä¸Šï¼ŒDAMç›¸æ¯”ç°æœ‰æœ€ä½³æ–¹æ³•æå‡äº†5%ä»¥ä¸Šçš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼ŒDAMåœ¨ä¸åŒçš„ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ä¸‹å‡è¡¨ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§æ— æºåŸŸè‡ªé€‚åº”åœºæ™¯ï¼Œä¾‹å¦‚ï¼šåŒ»ç–—å½±åƒè¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªç­‰ã€‚åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œè·å–å¤§é‡æ ‡æ³¨æ•°æ®æˆæœ¬é«˜æ˜‚ï¼Œè€Œåˆ©ç”¨é¢„è®­ç»ƒçš„ViLæ¨¡å‹å¯ä»¥æœ‰æ•ˆé™ä½æ ‡æ³¨æˆæœ¬ï¼Œæå‡æ¨¡å‹åœ¨ç›®æ ‡åŸŸçš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•å…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Source-free active domain adaptation (SFADA) enhances knowledge transfer from a source model to an unlabeled target domain using limited manual labels selected via active learning. While recent domain adaptation studies have introduced Vision-and-Language (ViL) models to improve pseudo-label quality or feature alignment, they often treat ViL-based and data supervision as separate sources, lacking effective fusion. To overcome this limitation, we propose Dual Active learning with Multimodal (DAM) foundation model, a novel framework that integrates multimodal supervision from a ViL model to complement sparse human annotations, thereby forming a dual supervisory signal. DAM initializes stable ViL-guided targets and employs a bidirectional distillation mechanism to foster mutual knowledge exchange between the target model and the dual supervisions during iterative adaptation. Extensive experiments demonstrate that DAM consistently outperforms existing methods and sets a new state-of-the-art across multiple SFADA benchmarks and active learning strategies.

