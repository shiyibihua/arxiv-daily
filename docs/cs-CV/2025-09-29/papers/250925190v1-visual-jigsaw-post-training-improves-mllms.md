---
layout: default
title: Visual Jigsaw Post-Training Improves MLLMs
---

# Visual Jigsaw Post-Training Improves MLLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25190" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25190v1</a>
  <a href="https://arxiv.org/pdf/2509.25190.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25190v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25190v1', 'Visual Jigsaw Post-Training Improves MLLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Penghao Wu, Yushan Zhang, Haiwen Diao, Bo Li, Lewei Lu, Ziwei Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://penghao-wu.github.io/visual_jigsaw/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Visual Jigsawï¼šé€šè¿‡è§†è§‰æ‹¼å›¾åè®­ç»ƒæå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è§†è§‰ç†è§£` `è‡ªç›‘ç£å­¦ä¹ ` `åè®­ç»ƒ` `è§†è§‰æ‹¼å›¾` `å¼ºåŒ–å­¦ä¹ ` `è§†è§‰æ¨¡æ€` `æ’åºä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰MLLMåè®­ç»ƒæ–¹æ³•ä¾§é‡äºæ–‡æœ¬ï¼Œå¿½ç•¥äº†è§†è§‰ç†è§£çš„æå‡ï¼Œè§†è§‰ä¿¡æ¯ä»…ä½œä¸ºæ–‡æœ¬æ¨ç†çš„è¾…åŠ©ã€‚
2. Visual Jigsawé€šè¿‡è‡ªç›‘ç£çš„è§†è§‰æ‹¼å›¾ä»»åŠ¡ï¼Œè®©æ¨¡å‹å­¦ä¹ é‡å»ºæ‰“ä¹±çš„è§†è§‰ä¿¡æ¯ï¼Œä»è€Œæå‡è§†è§‰ç†è§£èƒ½åŠ›ã€‚
3. å®éªŒè¯æ˜ï¼ŒVisual Jigsawåœ¨å›¾åƒã€è§†é¢‘å’Œ3Dæ•°æ®ä¸Šå‡èƒ½æœ‰æ•ˆæå‡MLLMçš„ç»†ç²’åº¦æ„ŸçŸ¥ã€æ—¶é—´æ¨ç†å’Œç©ºé—´ç†è§£èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºå¼ºåŒ–å­¦ä¹ çš„åè®­ç»ƒå·²æˆä¸ºå¢å¼ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰å¯¹é½å’Œæ¨ç†èƒ½åŠ›çš„æœ‰æ•ˆèŒƒä¾‹ã€‚è™½ç„¶ä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„åè®­ç»ƒå¯¹äºå¢å¼º MLLM å¯¹è§†è§‰ä¿¡å·çš„å†…åœ¨ç†è§£è‡³å…³é‡è¦ï¼Œä½†å½“å‰çš„åè®­ç»ƒèŒƒä¾‹ä¸»è¦ä»¥æ–‡æœ¬ä¸ºä¸­å¿ƒï¼Œå…¶ä¸­å¯†é›†çš„è§†è§‰è¾“å…¥ä»…ç”¨äºæå–ç¨€ç–çš„çº¿ç´¢ä»¥è¿›è¡ŒåŸºäºæ–‡æœ¬çš„æ¨ç†ã€‚è™½ç„¶å­˜åœ¨ä¸€äº›æœè¿™ä¸ªæ–¹å‘å‘å±•çš„æ–¹æ³•ï¼Œä½†å®ƒä»¬é€šå¸¸ä»ç„¶ä¾èµ–æ–‡æœ¬ä½œä¸ºä¸­é—´åª’ä»‹æˆ–å¼•å…¥é¢å¤–çš„è§†è§‰ç”Ÿæˆè®¾è®¡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº† Visual Jigsawï¼Œè¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„è‡ªç›‘ç£åè®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨åŠ å¼º MLLM ä¸­çš„è§†è§‰ç†è§£ã€‚Visual Jigsaw è¢«æ„å»ºä¸ºä¸€ä¸ªé€šç”¨çš„æ’åºä»»åŠ¡ï¼šè§†è§‰è¾“å…¥è¢«åˆ†å‰²ã€æ‰“ä¹±ï¼Œæ¨¡å‹å¿…é¡»é€šè¿‡ç”Ÿæˆè‡ªç„¶è¯­è¨€ä¸­çš„æ­£ç¡®æ’åˆ—æ¥é‡å»ºè§†è§‰ä¿¡æ¯ã€‚è¿™è‡ªç„¶åœ°ä¸æ¥è‡ªå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰å¯¹é½ï¼Œä¸éœ€è¦é¢å¤–çš„è§†è§‰ç”Ÿæˆç»„ä»¶ï¼Œå¹¶è‡ªåŠ¨å¯¼å‡ºå…¶ç›‘ç£ä¿¡å·ï¼Œæ— éœ€ä»»ä½•æ³¨é‡Šã€‚æˆ‘ä»¬åœ¨ä¸‰ç§è§†è§‰æ¨¡æ€ï¼ˆåŒ…æ‹¬å›¾åƒã€è§†é¢‘å’Œ 3D æ•°æ®ï¼‰ä¸Šå®ä¾‹åŒ– Visual Jigsawã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œåœ¨ç»†ç²’åº¦æ„ŸçŸ¥ã€æ—¶é—´æ¨ç†å’Œ 3D ç©ºé—´ç†è§£æ–¹é¢éƒ½æœ‰æ˜¾è‘—æ”¹è¿›ã€‚æˆ‘ä»¬çš„å‘ç°çªå‡ºäº†ä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„è‡ªç›‘ç£ä»»åŠ¡åœ¨åè®­ç»ƒ MLLM ä¸­çš„æ½œåŠ›ï¼Œå¹¶æ—¨åœ¨æ¿€å‘å¯¹ä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„å‰ç½®ä»»åŠ¡è®¾è®¡çš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰MLLMçš„åè®­ç»ƒæ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ–‡æœ¬æ¨¡æ€ï¼Œè§†è§‰ä¿¡æ¯é€šå¸¸è¢«ç”¨ä½œæ–‡æœ¬æ¨ç†çš„è¾…åŠ©ã€‚è¿™å¯¼è‡´æ¨¡å‹åœ¨è§†è§‰ç†è§£æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ç»†ç²’åº¦æ„ŸçŸ¥ã€æ—¶é—´æ¨ç†å’Œ3Dç©ºé—´ç†è§£ç­‰ä»»åŠ¡ä¸Šã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆä¾èµ–æ–‡æœ¬ä½œä¸ºä¸­é—´åª’ä»‹ï¼Œè¦ä¹ˆå¼•å…¥é¢å¤–çš„è§†è§‰ç”Ÿæˆæ¨¡å—ï¼Œå¢åŠ äº†å¤æ‚æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVisual Jigsawçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸€ä¸ªè‡ªç›‘ç£çš„è§†è§‰æ‹¼å›¾ä»»åŠ¡æ¥æå‡MLLMçš„è§†è§‰ç†è§£èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œå°†è§†è§‰è¾“å…¥åˆ†å‰²æˆå¤šä¸ªéƒ¨åˆ†å¹¶æ‰“ä¹±é¡ºåºï¼Œç„¶åè¦æ±‚æ¨¡å‹é¢„æµ‹æ­£ç¡®çš„æ’åˆ—é¡ºåºã€‚è¿™ç§æ–¹å¼è¿«ä½¿æ¨¡å‹å­¦ä¹ ç†è§£è§†è§‰ä¿¡æ¯ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œæå‡å…¶è§†è§‰ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVisual Jigsawçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š1) è§†è§‰è¾“å…¥åˆ†å‰²ï¼šå°†å›¾åƒã€è§†é¢‘æˆ–3Dæ•°æ®åˆ†å‰²æˆå¤šä¸ªpatchã€‚2) é¡ºåºæ‰“ä¹±ï¼šéšæœºæ‰“ä¹±è¿™äº›patchçš„é¡ºåºã€‚3) æ¨¡å‹é¢„æµ‹ï¼šMLLMæ¥æ”¶æ‰“ä¹±é¡ºåºçš„patchï¼Œå¹¶é¢„æµ‹æ­£ç¡®çš„æ’åˆ—é¡ºåºï¼Œä»¥è‡ªç„¶è¯­è¨€å½¢å¼è¾“å‡ºã€‚4) å¥–åŠ±è®¡ç®—ï¼šæ ¹æ®é¢„æµ‹çš„æ’åˆ—é¡ºåºä¸çœŸå®é¡ºåºçš„åŒ¹é…ç¨‹åº¦è®¡ç®—å¥–åŠ±ï¼Œä½¿ç”¨å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šVisual Jigsawçš„å…³é”®åˆ›æ–°åœ¨äºå…¶è‡ªç›‘ç£çš„è§†è§‰æ‹¼å›¾ä»»åŠ¡è®¾è®¡ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒä¸éœ€è¦é¢å¤–çš„æ–‡æœ¬æ ‡æ³¨æˆ–è§†è§‰ç”Ÿæˆæ¨¡å—ï¼Œè€Œæ˜¯é€šè¿‡ä¸€ä¸ªç®€å•çš„æ’åºä»»åŠ¡æ¥æå‡è§†è§‰ç†è§£èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¯ä»¥å¾ˆå®¹æ˜“åœ°åº”ç”¨äºä¸åŒçš„è§†è§‰æ¨¡æ€ï¼ŒåŒ…æ‹¬å›¾åƒã€è§†é¢‘å’Œ3Dæ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šVisual Jigsawçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) Patchåˆ†å‰²ç­–ç•¥ï¼šæ ¹æ®ä¸åŒçš„è§†è§‰æ¨¡æ€é€‰æ‹©åˆé€‚çš„åˆ†å‰²ç­–ç•¥ã€‚2) æ’åˆ—é¡ºåºé¢„æµ‹ï¼šä½¿ç”¨è‡ªç„¶è¯­è¨€ç”Ÿæˆæ¨¡å‹é¢„æµ‹patchçš„æ’åˆ—é¡ºåºã€‚3) å¥–åŠ±å‡½æ•°ï¼šä½¿ç”¨BLEU scoreç­‰æŒ‡æ ‡æ¥è¡¡é‡é¢„æµ‹çš„æ’åˆ—é¡ºåºä¸çœŸå®é¡ºåºçš„åŒ¹é…ç¨‹åº¦ã€‚4) å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼šä½¿ç”¨PPOç­‰ç®—æ³•æ¥è®­ç»ƒæ¨¡å‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVisual Jigsaw åœ¨å›¾åƒã€è§†é¢‘å’Œ 3D æ•°æ®ä¸Šå‡èƒ½æœ‰æ•ˆæå‡ MLLM çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨ç»†ç²’åº¦å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ï¼ŒVisual Jigsaw èƒ½å¤Ÿæ˜¾è‘—æé«˜æ¨¡å‹çš„å‡†ç¡®ç‡ã€‚åœ¨è§†é¢‘æ—¶é—´æ¨ç†ä»»åŠ¡ä¸­ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å‡†ç¡®åœ°é¢„æµ‹äº‹ä»¶çš„å‘ç”Ÿé¡ºåºã€‚åœ¨ 3D ç©ºé—´ç†è§£ä»»åŠ¡ä¸­ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç‰©ä½“çš„ç©ºé—´å…³ç³»ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Visual Jigsaw æœ‰æ½œåŠ›åº”ç”¨äºå„ç§éœ€è¦ç»†ç²’åº¦è§†è§‰ç†è§£çš„å¤šæ¨¡æ€ä»»åŠ¡ï¼Œä¾‹å¦‚è§†é¢‘å†…å®¹åˆ†æã€åŒ»å­¦å½±åƒè¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººå¯¼èˆªã€‚é€šè¿‡æå‡ MLLM çš„è§†è§‰ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥æé«˜è¿™äº›åº”ç”¨åœºæ™¯çš„æ€§èƒ½å’Œå¯é æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„å¤šæ¨¡æ€äººå·¥æ™ºèƒ½ç ”ç©¶æä¾›æ–°çš„æ–¹å‘ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement learning based post-training has recently emerged as a powerful paradigm for enhancing the alignment and reasoning capabilities of multimodal large language models (MLLMs). While vision-centric post-training is crucial for enhancing MLLMs' intrinsic understanding of visual signals, current post-training paradigms are predominantly text-centric, where dense visual inputs are only leveraged to extract sparse cues for text-based reasoning. There exist a few approaches in this direction, however, they often still rely on text as an intermediate mediator or introduce additional visual generative designs. In this work, we introduce Visual Jigsaw, a generic self-supervised post-training framework designed to strengthen visual understanding in MLLMs. Visual Jigsaw is formulated as a general ordering task: visual inputs are partitioned, shuffled, and the model must reconstruct the visual information by producing the correct permutation in natural language. This naturally aligns with reinforcement learning from verifiable rewards (RLVR), requires no additional visual generative components, and derives its supervisory signal automatically without any annotations. We instantiate Visual Jigsaw across three visual modalities, including images, videos, and 3D data. Extensive experiments demonstrate substantial improvements in fine-grained perception, temporal reasoning, and 3D spatial understanding. Our findings highlight the potential of self-supervised vision-centric tasks in post-training MLLMs and aim to inspire further research on vision-centric pretext designs. Project Page: https://penghao-wu.github.io/visual_jigsaw/

