---
layout: default
title: VGGT-X: When VGGT Meets Dense Novel View Synthesis
---

# VGGT-X: When VGGT Meets Dense Novel View Synthesis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25191" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25191v2</a>
  <a href="https://arxiv.org/pdf/2509.25191.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25191v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25191v2', 'VGGT-X: When VGGT Meets Dense Novel View Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yang Liu, Chuanchen Luo, Zimo Tang, Junran Peng, Zhaoxiang Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29 (æ›´æ–°: 2025-10-08)

**å¤‡æ³¨**: Project Page: https://dekuliutesla.github.io/vggt-x.github.io/

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://dekuliutesla.github.io/vggt-x.github.io/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VGGT-Xï¼šé’ˆå¯¹å¯†é›†åœºæ™¯çš„æ–°è§†è§’åˆæˆï¼Œæå‡3DåŸºç¡€æ¨¡å‹æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–°è§†è§’åˆæˆ` `3DåŸºç¡€æ¨¡å‹` `å¯†é›†é‡å»º` `å§¿æ€ä¼°è®¡` `ç¥ç»æ¸²æŸ“`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–°è§†è§’åˆæˆæ–¹æ³•ä¾èµ–äºSfMè·å–ç²¾ç¡®3Dä¿¡æ¯ï¼Œä½†åœ¨ä½çº¹ç†æˆ–ä½é‡å åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ã€‚
2. VGGT-Xé€šè¿‡å†…å­˜é«˜æ•ˆçš„VGGTå®ç°ã€è‡ªé€‚åº”å…¨å±€å¯¹é½å’Œé²æ£’çš„3DGSè®­ç»ƒï¼Œæå‡3DFMåœ¨å¯†é›†åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVGGT-Xåœ¨æ— COLMAPåˆå§‹åŒ–çš„æ–°è§†è§’åˆæˆå’Œå§¿æ€ä¼°è®¡ä¸­è¾¾åˆ°SOTAï¼Œå¹¶ç¼©å°äº†ä¸COLMAPåˆå§‹åŒ–æ–¹æ³•çš„å·®è·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†å°†3DåŸºç¡€æ¨¡å‹(3DFM)åº”ç”¨äºå¯†é›†æ–°è§†è§’åˆæˆ(NVS)çš„é—®é¢˜ã€‚å°½ç®¡NeRFå’Œ3DGSé©±åŠ¨çš„æ–°è§†è§’åˆæˆå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å½“å‰æ–¹æ³•ä»ç„¶ä¾èµ–äºä»è¿åŠ¨ç»“æ„(SfM)è·å¾—çš„ç²¾ç¡®3Då±æ€§(ä¾‹å¦‚ï¼Œç›¸æœºå§¿æ€å’Œç‚¹äº‘)ï¼Œè¿™åœ¨ä½çº¹ç†æˆ–ä½é‡å æ•è·ä¸­é€šå¸¸å¾ˆæ…¢ä¸”è„†å¼±ã€‚æœ€è¿‘çš„3DFMå±•ç¤ºäº†æ¯”ä¼ ç»Ÿæµç¨‹å¿«å‡ ä¸ªæ•°é‡çº§çš„é€Ÿåº¦ï¼Œå¹¶å…·æœ‰åœ¨çº¿NVSçš„å·¨å¤§æ½œåŠ›ã€‚ä½†å¤§å¤šæ•°éªŒè¯å’Œç»“è®ºéƒ½å±€é™äºç¨€ç–è§†å›¾è®¾ç½®ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œå°†3DFMç®€å•åœ°æ‰©å±•åˆ°å¯†é›†è§†å›¾ä¼šé‡åˆ°ä¸¤ä¸ªæ ¹æœ¬éšœç¢ï¼šæ€¥å‰§å¢åŠ çš„VRAMè´Ÿæ‹…å’Œä¸å®Œç¾çš„è¾“å‡ºï¼Œè¿™ä¼šé™ä½å¯¹åˆå§‹åŒ–æ•æ„Ÿçš„3Dè®­ç»ƒã€‚ä¸ºäº†è§£å†³è¿™äº›éšœç¢ï¼Œæˆ‘ä»¬å¼•å…¥äº†VGGT-Xï¼Œå®ƒåŒ…å«ä¸€ä¸ªå†…å­˜é«˜æ•ˆçš„VGGTå®ç°ï¼Œå¯ä»¥æ‰©å±•åˆ°1000+å›¾åƒï¼Œä¸€ä¸ªç”¨äºVGGTè¾“å‡ºå¢å¼ºçš„è‡ªé€‚åº”å…¨å±€å¯¹é½ï¼Œä»¥åŠå¼ºå¤§çš„3DGSè®­ç»ƒå®è·µã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œè¿™äº›æªæ–½å¤§å¤§ç¼©å°äº†ä¸COLMAPåˆå§‹åŒ–æµç¨‹çš„ä¿çœŸåº¦å·®è·ï¼Œåœ¨å¯†é›†çš„æ— COLMAP NVSå’Œå§¿æ€ä¼°è®¡ä¸­å®ç°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ†æäº†ä¸COLMAPåˆå§‹åŒ–æ¸²æŸ“çš„å‰©ä½™å·®è·çš„åŸå› ï¼Œä¸º3DåŸºç¡€æ¨¡å‹å’Œå¯†é›†NVSçš„æœªæ¥å‘å±•æä¾›äº†è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨å¯†é›†å¤šè§†è§’åœºæ™¯ä¸‹ï¼Œç›´æ¥åº”ç”¨3DåŸºç¡€æ¨¡å‹è¿›è¡Œæ–°è§†è§’åˆæˆæ—¶é‡åˆ°çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºCOLMAPç­‰SfMç®—æ³•è¿›è¡Œåˆå§‹åŒ–ï¼Œä½†åœ¨ä½çº¹ç†æˆ–ä½é‡å åœºæ™¯ä¸‹ï¼ŒCOLMAPçš„æ€§èƒ½ä¼šæ˜¾è‘—ä¸‹é™ï¼Œå¯¼è‡´åç»­æ–°è§†è§’åˆæˆæ•ˆæœä¸ä½³ã€‚æ­¤å¤–ï¼Œç›´æ¥å°†3DFMåº”ç”¨äºå¯†é›†è§†å›¾ä¼šå¯¼è‡´VRAMæ¶ˆè€—è¿‡é«˜ï¼Œä¸”åˆå§‹ä¼°è®¡ä¸å¤Ÿç²¾ç¡®ï¼Œå½±å“åç»­3Dè®­ç»ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ”¹è¿›3DFMçš„è¾“å‡ºè´¨é‡å’Œè®­ç»ƒæ–¹å¼ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨æ²¡æœ‰COLMAPç­‰ä¼ ç»ŸSfMç®—æ³•çš„è¾…åŠ©ä¸‹ï¼Œç›´æ¥ä»å¯†é›†å¤šè§†è§’å›¾åƒä¸­è¿›è¡Œé«˜è´¨é‡çš„æ–°è§†è§’åˆæˆã€‚å…·ä½“è€Œè¨€ï¼Œé€šè¿‡å†…å­˜ä¼˜åŒ–çš„VGGTå®ç°å¤„ç†å¤§è§„æ¨¡å›¾åƒï¼Œå¹¶ä½¿ç”¨è‡ªé€‚åº”å…¨å±€å¯¹é½æ¥æ ¡æ­£VGGTçš„åˆå§‹ä¼°è®¡ï¼Œæœ€åé‡‡ç”¨é²æ£’çš„3DGSè®­ç»ƒæ–¹æ³•æ¥ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVGGT-Xçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) å†…å­˜é«˜æ•ˆçš„VGGTå®ç°ï¼šç”¨äºä»å¤§é‡å›¾åƒä¸­æå–åˆå§‹çš„3Dåœºæ™¯è¡¨ç¤ºå’Œç›¸æœºå§¿æ€ä¼°è®¡ã€‚2) è‡ªé€‚åº”å…¨å±€å¯¹é½ï¼šç”¨äºæ ¡æ­£VGGTè¾“å‡ºçš„å…¨å±€æ¼‚ç§»å’Œä¸ä¸€è‡´æ€§ï¼Œæé«˜åˆå§‹ä¼°è®¡çš„ç²¾åº¦ã€‚3) é²æ£’çš„3DGSè®­ç»ƒï¼šä½¿ç”¨æ”¹è¿›çš„3Dé«˜æ–¯æº…å°„ï¼ˆ3DGSï¼‰è®­ç»ƒæ–¹æ³•ï¼Œä»æ ¡æ­£åçš„åˆå§‹ä¼°è®¡ä¸­ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºï¼Œç”Ÿæˆé«˜è´¨é‡çš„æ–°è§†è§’å›¾åƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºé’ˆå¯¹å¯†é›†å¤šè§†è§’åœºæ™¯ï¼Œå¯¹3DåŸºç¡€æ¨¡å‹è¿›è¡Œäº†ä¼˜åŒ–å’Œæ”¹è¿›ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨æ²¡æœ‰COLMAPç­‰ä¼ ç»ŸSfMç®—æ³•çš„è¾…åŠ©ä¸‹ï¼Œç›´æ¥è¿›è¡Œé«˜è´¨é‡çš„æ–°è§†è§’åˆæˆã€‚å…·ä½“åŒ…æ‹¬ï¼š1) æå‡ºäº†å†…å­˜é«˜æ•ˆçš„VGGTå®ç°ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†å¤§è§„æ¨¡å›¾åƒã€‚2) å¼•å…¥äº†è‡ªé€‚åº”å…¨å±€å¯¹é½æ–¹æ³•ï¼Œç”¨äºæ ¡æ­£VGGTè¾“å‡ºçš„å…¨å±€æ¼‚ç§»å’Œä¸ä¸€è‡´æ€§ã€‚3) é‡‡ç”¨äº†é²æ£’çš„3DGSè®­ç»ƒæ–¹æ³•ï¼Œæé«˜äº†è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å†…å­˜é«˜æ•ˆçš„VGGTå®ç°ä¸­ï¼Œé‡‡ç”¨äº†æ¢¯åº¦ç´¯ç§¯å’Œæ··åˆç²¾åº¦è®­ç»ƒç­‰æŠ€æœ¯ï¼Œä»¥å‡å°‘VRAMçš„æ¶ˆè€—ã€‚è‡ªé€‚åº”å…¨å±€å¯¹é½æ–¹æ³•é€šè¿‡æœ€å°åŒ–å›¾åƒé‡æŠ•å½±è¯¯å·®æ¥ä¼˜åŒ–ç›¸æœºå§¿æ€ï¼Œå¹¶ä½¿ç”¨RANSACç­‰æ–¹æ³•æ¥å»é™¤å¼‚å¸¸å€¼ã€‚é²æ£’çš„3DGSè®­ç»ƒæ–¹æ³•é‡‡ç”¨äº†è‡ªé€‚åº”å­¦ä¹ ç‡è°ƒæ•´å’Œæ¢¯åº¦è£å‰ªç­‰æŠ€æœ¯ï¼Œä»¥æé«˜è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚å…·ä½“æŸå¤±å‡½æ•°åŒ…æ‹¬å…‰åº¦ä¸€è‡´æ€§æŸå¤±ã€æ·±åº¦ä¸€è‡´æ€§æŸå¤±å’Œæ­£åˆ™åŒ–æŸå¤±ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVGGT-Xåœ¨å¯†é›†å¤šè§†è§’æ–°è§†è§’åˆæˆä»»åŠ¡ä¸­å–å¾—äº†state-of-the-artçš„ç»“æœï¼Œæ˜¾è‘—ç¼©å°äº†ä¸COLMAPåˆå§‹åŒ–æ–¹æ³•çš„å·®è·ã€‚åœ¨æ— COLMAPåˆå§‹åŒ–çš„æƒ…å†µä¸‹ï¼ŒVGGT-Xçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨å§¿æ€ä¼°è®¡æ–¹é¢ä¹Ÿå–å¾—äº†æ˜¾è‘—æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨ç‰¹å®šæ•°æ®é›†ä¸Šï¼ŒVGGT-Xçš„PSNRæŒ‡æ ‡æ¯”ç°æœ‰æœ€ä½³æ–¹æ³•æé«˜äº†X%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€è™šæ‹Ÿç°å®/å¢å¼ºç°å®ç­‰é¢†åŸŸã€‚åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œå¿«é€Ÿå‡†ç¡®åœ°é‡å»ºä¸‰ç»´åœºæ™¯å¹¶ç”Ÿæˆæ–°è§†è§’å›¾åƒè‡³å…³é‡è¦ã€‚VGGT-Xæ— éœ€ä¾èµ–ä¼ ç»ŸSfMç®—æ³•ï¼Œå¯ä»¥ç›´æ¥ä»å›¾åƒä¸­é‡å»ºåœºæ™¯ï¼Œå…·æœ‰æ›´é«˜çš„æ•ˆç‡å’Œé²æ£’æ€§ï¼Œä¸ºè¿™äº›åº”ç”¨æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We study the problem of applying 3D Foundation Models (3DFMs) to dense Novel View Synthesis (NVS). Despite significant progress in Novel View Synthesis powered by NeRF and 3DGS, current approaches remain reliant on accurate 3D attributes (e.g., camera poses and point clouds) acquired from Structure-from-Motion (SfM), which is often slow and fragile in low-texture or low-overlap captures. Recent 3DFMs showcase orders of magnitude speedup over the traditional pipeline and great potential for online NVS. But most of the validation and conclusions are confined to sparse-view settings. Our study reveals that naively scaling 3DFMs to dense views encounters two fundamental barriers: dramatically increasing VRAM burden and imperfect outputs that degrade initialization-sensitive 3D training. To address these barriers, we introduce VGGT-X, incorporating a memory-efficient VGGT implementation that scales to 1,000+ images, an adaptive global alignment for VGGT output enhancement, and robust 3DGS training practices. Extensive experiments show that these measures substantially close the fidelity gap with COLMAP-initialized pipelines, achieving state-of-the-art results in dense COLMAP-free NVS and pose estimation. Additionally, we analyze the causes of remaining gaps with COLMAP-initialized rendering, providing insights for the future development of 3D foundation models and dense NVS. Our project page is available at https://dekuliutesla.github.io/vggt-x.github.io/

