---
layout: default
title: Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection
---

# Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25502" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.25502v1</a>
  <a href="https://arxiv.org/pdf/2509.25502.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25502v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25502v1', 'Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Kaiqing Lin, Zhiyuan Yan, Ruoxin Chen, Junyan Ye, Ke-Yue Zhang, Yue Zhou, Peng Jin, Bin Li, Taiping Yao, Shouhong Ding

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-29

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Forensic-ChatÊ°ÜÊû∂ÔºåÊèêÂçáÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®‰º™ÈÄ†ÂõæÂÉèÊ£ÄÊµã‰∏≠ÁöÑÊ≥õÂåñÊÄßÂíåÂèØËß£ÈáäÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `‰º™ÈÄ†ÂõæÂÉèÊ£ÄÊµã` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `ÂèØËß£ÈáäÊÄß` `ËßÜËßâÊÑüÁü•` `ÂÖàÁúãÂêéÊé®ÁêÜ` `ÂõæÂÉèÂèñËØÅ` `Forensic-Chat` `ExplainFake-Bench`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâMLLMsÂú®‰º™ÈÄ†ÂõæÂÉèÊ£ÄÊµã‰∏≠Ë°®Áé∞‰∏ç‰Ω≥Ôºå‰∏ªË¶ÅÂéüÂõ†ÊòØËßÜËßâÁºñÁ†ÅÂô®ÂØπ‰ΩéÁ∫ß‰º™ÈÄ†‰ø°Âè∑‰∏çÊïèÊÑüÔºå‰∏îÂæÆË∞ÉÊï∞ÊçÆ‰∏éÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÂàÜÂ∏ÉÂ≠òÂú®Â∑ÆÂºÇ„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‚ÄúÂÖàÁúãÂêéÊé®ÁêÜ‚ÄùÁöÑËåÉÂºèÔºåÈÄöËøáËÆ≠ÁªÉMLLMsÊÑüÁü•‰º™ÈÄ†ÁóïËøπÔºåÂ¢ûÂº∫ÂÖ∂ËßÜËßâÊÑüÁü•ËÉΩÂäõÔºå‰ªéËÄåÊèêÂçáÊ£ÄÊµãÊÄßËÉΩ„ÄÇ
3. ËÆ∫ÊñáÊèêÂá∫‰∫ÜForensic-ChatÊ°ÜÊû∂ÂíåExplainFake-BenchÂü∫ÂáÜÔºåÂÆûÈ™åË°®ÊòéËØ•ÊñπÊ≥ïÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÊ≥õÂåñÊÄßÂíåÂèØËß£ÈáäÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÈíàÂØπÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÂú®AIÁîüÊàêÂõæÂÉèÊ£ÄÊµã‰∏≠Ë°®Áé∞‰∏ç‰Ω≥ÁöÑÈóÆÈ¢òÔºåÊåáÂá∫ÂÖ∂Ê†πÊú¨ÂéüÂõ†Âú®‰∫éÊ®°ÂûãÂú®‚ÄúÁúüÊ≠£ÁúãÂà∞‚Äù‰º™ÈÄ†ÁóïËøπ‰πãÂâçÂ∞±ÂºÄÂßãÊé®ÁêÜ„ÄÇÁé∞ÊúâMLLMsÁöÑËßÜËßâÁºñÁ†ÅÂô®‰∏ªË¶ÅÈíàÂØπËØ≠‰πâËØÜÂà´‰ºòÂåñÔºåÂØπ‰ΩéÁ∫ß‰º™ÈÄ†‰ø°Âè∑‰∏çÊïèÊÑü„ÄÇÊ≠§Â§ñÔºåÊ£ÄÊµãÂæÆË∞ÉÊï∞ÊçÆ‰∏éÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÁöÑÂàÜÂ∏ÉÂ∑ÆÂºÇÂØºËá¥Ê®°ÂûãÁÅæÈöæÊÄßÂú∞ÈÅóÂøòÈ¢ÑËÆ≠ÁªÉÁü•ËØÜ„ÄÇ‰∏∫Ê≠§ÔºåËÆ∫ÊñáÊèêÂá∫‚ÄúÂÖàÁúãÂêéÊé®ÁêÜ‚ÄùÁöÑÊñ∞ËåÉÂºèÔºåËÆ≠ÁªÉMLLMsÊÑüÁü•‰º™ÈÄ†ÁóïËøπÔºåÂ¢ûÂº∫ÂÖ∂‰º™ÈÄ†ÊÑüÁü•ËÉΩÂäõÔºå‰ªéËÄå‰ΩøÂêéÁª≠Êé®ÁêÜÂª∫Á´ãÂú®ÂÆûÈôÖËßÇÂØü‰πã‰∏ä„ÄÇËÆ∫ÊñáÊèêÂá∫‰∫ÜForensic-ChatÔºå‰∏Ä‰∏™ÈÄöÁî®„ÄÅÂèØËß£Èáä‰∏îÊîØÊåÅÂ§öËΩÆÂØπËØùÁöÑ‰º™ÈÄ†ÂõæÂÉèÊ£ÄÊµãÂä©ÊâãÔºåÂπ∂ÊèêÂá∫‰∫ÜExplainFake-BenchÔºå‰∏Ä‰∏™Áî®‰∫éËØÑ‰º∞MLLMÂõæÂÉèÂèñËØÅÂèØËß£ÈáäÊÄßÁöÑÂü∫ÂáÜ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂÖ∑Êúâ‰ºòË∂äÁöÑÊ≥õÂåñÊÄßÂíåÂèØÈù†ÁöÑÂèØËß£ÈáäÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊñπÊ≥ïÁõ¥Êé•‰ΩøÁî®Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâËøõË°å‰º™ÈÄ†ÂõæÂÉèÊ£ÄÊµãÔºå‰ΩÜÁî±‰∫éMLLMsÁöÑËßÜËßâÁºñÁ†ÅÂô®‰∏ªË¶ÅÈíàÂØπËØ≠‰πâËØÜÂà´‰ºòÂåñÔºåÂØπÂõæÂÉè‰∏≠ÁªÜÂæÆÁöÑ‰º™ÈÄ†ÁóïËøπÊÑüÁü•ËÉΩÂäõ‰∏çË∂≥ÔºåÂØºËá¥Ê£ÄÊµãÊÄßËÉΩ‰∏ç‰Ω≥„ÄÇÊ≠§Â§ñÔºåÁî®‰∫éÂæÆË∞ÉÁöÑÊï∞ÊçÆÈõÜÈÄöÂ∏∏ÈááÁî®Êåá‰ª§ÂºèÊ†ºÂºèÔºå‰∏éMLLMsÈ¢ÑËÆ≠ÁªÉÊó∂Êé•Ëß¶Âà∞ÁöÑÂ§öÊ†∑ÂåñÊï∞ÊçÆÂàÜÂ∏ÉÂ≠òÂú®ÊòæËëóÂ∑ÆÂºÇÔºåÂØºËá¥Ê®°ÂûãÂÆπÊòìÂà©Áî®ËØ≠Ë®ÄÊç∑ÂæÑÔºå‰ªéËÄåÈÅóÂøòÈ¢ÑËÆ≠ÁªÉÁü•ËØÜ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØ‚ÄúÂÖàÁúãÂêéÊé®ÁêÜ‚ÄùÔºåÂç≥È¶ñÂÖàËÆ≠ÁªÉMLLMsÂÖ∑Â§áÊÑüÁü•‰º™ÈÄ†ÂõæÂÉè‰∏≠ÂêÑÁßç‰º™ÈÄ†ÁóïËøπÁöÑËÉΩÂäõÔºåÁÑ∂ÂêéÂÜçËøõË°åÊé®ÁêÜÂà§Êñ≠„ÄÇÈÄöËøáÂ¢ûÂº∫Ê®°ÂûãÂØπ‰º™ÈÄ†ÁóïËøπÁöÑÊÑüÁü•ËÉΩÂäõÔºå‰ΩøÂÖ∂Êé®ÁêÜËøáÁ®ãËÉΩÂ§üÂª∫Á´ãÂú®ÂèØÈù†ÁöÑËßÜËßâËØÅÊçÆ‰πã‰∏äÔºå‰ªéËÄåÊèêÈ´òÊ£ÄÊµãÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫ÜForensic-ChatÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂Êó®Âú®ÊûÑÂª∫‰∏Ä‰∏™ÈÄöÁî®„ÄÅÂèØËß£Èáä‰∏îÊîØÊåÅÂ§öËΩÆÂØπËØùÁöÑ‰º™ÈÄ†ÂõæÂÉèÊ£ÄÊµãÂä©Êâã„ÄÇÊ°ÜÊû∂ÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÁªÜËäÇÊú™Âú®ÊëòË¶Å‰∏≠ËØ¶ÁªÜËØ¥ÊòéÔºå‰ΩÜÂèØ‰ª•Êé®Êñ≠ÂÖ∂ÂåÖÂê´‰∏Ä‰∏™ÁªèËøáÁâπÊÆäËÆ≠ÁªÉÁöÑËßÜËßâÁºñÁ†ÅÂô®ÔºåÁî®‰∫éÊèêÂèñÂõæÂÉè‰∏≠ÁöÑ‰º™ÈÄ†ÁóïËøπÁâπÂæÅÔºå‰ª•Âèä‰∏Ä‰∏™Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºåÁî®‰∫éÊ†πÊçÆÊèêÂèñÁöÑÁâπÂæÅËøõË°åÊé®ÁêÜÂíåÁîüÊàêËß£Èáä„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‚ÄúÂÖàÁúãÂêéÊé®ÁêÜ‚ÄùÁöÑËåÉÂºèÔºåÂº∫Ë∞É‰∫ÜËßÜËßâÊÑüÁü•Âú®‰º™ÈÄ†ÂõæÂÉèÊ£ÄÊµã‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ¥Êé•Âà©Áî®MLLMsËøõË°åÊé®ÁêÜ‰∏çÂêåÔºåËØ•ÊñπÊ≥ïÈ¶ñÂÖàÂÖ≥Ê≥®Â¶Ç‰ΩïÂ¢ûÂº∫Ê®°ÂûãÂØπ‰º™ÈÄ†ÁóïËøπÁöÑÊÑüÁü•ËÉΩÂäõÔºåÁÑ∂ÂêéÂÜçËøõË°åÊé®ÁêÜ„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÊèêÂá∫‰∫ÜExplainFake-BenchÂü∫ÂáÜÔºåÁî®‰∫éËØÑ‰º∞MLLMÂú®ÂõæÂÉèÂèñËØÅÊñπÈù¢ÁöÑÂèØËß£ÈáäÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊëòË¶Å‰∏≠Ê≤°ÊúâÊèê‰æõÂÖ≥‰∫éÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆ„ÄÅÊçüÂ§±ÂáΩÊï∞„ÄÅÁΩëÁªúÁªìÊûÑÁ≠âÊäÄÊúØÁªÜËäÇ„ÄÇ‰ΩÜÂèØ‰ª•Êé®ÊµãÔºåËßÜËßâÁºñÁ†ÅÂô®ÁöÑËÆ≠ÁªÉÂèØËÉΩÈááÁî®‰∫Ü‰∏ìÈó®ËÆæËÆ°ÁöÑÊçüÂ§±ÂáΩÊï∞Ôºå‰ª•ÈºìÂä±Ê®°ÂûãÂ≠¶‰π†Âà∞ÂØπ‰º™ÈÄ†ÁóïËøπÊïèÊÑüÁöÑÁâπÂæÅË°®Á§∫„ÄÇExplainFake-BenchÂü∫ÂáÜÂèØËÉΩÂåÖÂê´Â§öÁßçÁ±ªÂûãÁöÑ‰º™ÈÄ†ÂõæÂÉèÂíåÁõ∏Â∫îÁöÑËß£ÈáäÔºåÁî®‰∫éËØÑ‰º∞Ê®°ÂûãÁîüÊàêËß£ÈáäÁöÑÂáÜÁ°ÆÊÄßÂíåÂÆåÊï¥ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÊèêÂá∫‰∫ÜForensic-ChatÊ°ÜÊû∂ÂíåExplainFake-BenchÂü∫ÂáÜÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéËØ•ÊñπÊ≥ïÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÊ≥õÂåñÊÄßÂíåÂèØËß£ÈáäÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÊú™Âú®ÊëòË¶Å‰∏≠ÁªôÂá∫Ôºå‰ΩÜÂº∫Ë∞É‰∫ÜËØ•ÊñπÊ≥ïÂú®Ê≥õÂåñÊÄßÂíåÂèØËß£ÈáäÊÄßÊñπÈù¢ÁöÑ‰ºòÂäøÔºåË°®ÊòéÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÈ≤ÅÊ£íÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂú®Á∫øÂÜÖÂÆπÂÆ°Ê†∏„ÄÅÊñ∞ÈóªÁúüÂÆûÊÄßÈ™åËØÅ„ÄÅÁ§æ‰∫§Â™í‰ΩìÂπ≥Âè∞ÁÆ°ÁêÜÁ≠âÈ¢ÜÂüüÔºåÂ∏ÆÂä©ËØÜÂà´ÂíåËøáÊª§AIÁîüÊàêÁöÑËôöÂÅáÂõæÂÉèÔºåÁª¥Êä§ÁΩëÁªú‰ø°ÊÅØÂÆâÂÖ®ÔºåÈò≤Ê≠¢ËôöÂÅá‰ø°ÊÅØ‰º†Êí≠ÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÁ§æ‰ºö‰ª∑ÂÄºÂíåÂ∫îÁî®ÂâçÊôØ„ÄÇÊú™Êù•ÂèØËøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞ËßÜÈ¢ëÁ≠âÂÖ∂‰ªñÂ™í‰ΩìÂΩ¢ÂºèÁöÑ‰º™ÈÄ†Ê£ÄÊµã„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Detecting AI-generated images with multimodal large language models (MLLMs) has gained increasing attention, due to their rich world knowledge, common-sense reasoning, and potential for explainability. However, naively applying those MLLMs for detection often leads to suboptimal performance. We argue that the root of this failure lies in a fundamental mismatch: MLLMs are asked to reason about fakes before they can truly see them. First, they do not really see: existing MLLMs' vision encoders are primarily optimized for semantic-oriented recognition rather than the perception of low-level signals, leaving them insensitive to subtle forgery traces. Without access to reliable perceptual evidence, the model grounds its judgment on incomplete and limited visual observations. Second, existing finetuning data for detection typically uses narrow, instruction-style formats, which diverge sharply from the diverse, heterogeneous distributions seen in pretraining. In the absence of meaningful visual cues, the model therefore exploits these linguistic shortcuts, resulting in catastrophic forgetting of pretrained knowledge (even the basic dialogue capabilities). In response, we advocate for a new paradigm: seeing before reasoning. We propose that MLLMs should first be trained to perceive artifacts-strengthening their artifact-aware visual perception-so that subsequent reasoning is grounded in actual observations. We therefore propose Forensic-Chat, a generalizable, explainable, and still-conversational (for multi-round dialogue) assistant for fake image detection. We also propose ExplainFake-Bench, a benchmark tailored for the evaluation of the MLLM's explainability for image forensics from five key aspects. Extensive experiments show its superiority of generalization and genuinely reliable explainability.

