---
layout: default
title: SCOPE: Semantic Conditioning for Sim2Real Category-Level Object Pose Estimation in Robotics
---

# SCOPE: Semantic Conditioning for Sim2Real Category-Level Object Pose Estimation in Robotics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.24572" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.24572v1</a>
  <a href="https://arxiv.org/pdf/2509.24572.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.24572v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.24572v1', 'SCOPE: Semantic Conditioning for Sim2Real Category-Level Object Pose Estimation in Robotics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Peter HÃ¶nig, Stefan Thalhammer, Jean-Baptiste Weibel, Matthias Hirschmanner, Markus Vincze

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/hoenigpeter/scope)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SCOPEï¼šåŸºäºè¯­ä¹‰æ¡ä»¶æ‰©æ•£æ¨¡å‹çš„æœºå™¨äººSim2Realç±»åˆ«çº§ç‰©ä½“å§¿æ€ä¼°è®¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `ç‰©ä½“å§¿æ€ä¼°è®¡` `ç±»åˆ«çº§ä¼°è®¡` `Sim2Real` `æ‰©æ•£æ¨¡å‹` `DINOv2` `è¯­ä¹‰å…ˆéªŒ` `æœºå™¨äººæ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç‰©ä½“æ“ä½œæ–¹æ³•åœ¨å¼€æ”¾ç¯å¢ƒä¸­éš¾ä»¥å¤„ç†æœªçŸ¥ç‰©ä½“ï¼Œéœ€è¦è¯­ä¹‰ç†è§£ä»¥æ³›åŒ–åˆ°å·²çŸ¥ç±»åˆ«ä¹‹å¤–ã€‚
2. SCOPEåˆ©ç”¨DINOv2ç‰¹å¾ä½œä¸ºè¿ç»­è¯­ä¹‰å…ˆéªŒï¼Œç»“åˆæ‰©æ•£æ¨¡å‹è¿›è¡Œç±»åˆ«çº§ç‰©ä½“å§¿æ€ä¼°è®¡ï¼Œæ— éœ€ç¦»æ•£ç±»åˆ«æ ‡ç­¾ã€‚
3. SCOPEåœ¨åˆæˆæ•°æ®è®­ç»ƒä¸­è¶…è¶Šç°æœ‰æŠ€æœ¯ï¼Œå¹¶åœ¨å®ä¾‹çº§æ•°æ®é›†ä¸Šå±•ç¤ºäº†å¯¹æœªçŸ¥ç‰©ä½“çš„æŠ“å–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºSCOPEï¼Œä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„ç±»åˆ«çº§ç‰©ä½“å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨DINOv2ç‰¹å¾ä½œä¸ºè¿ç»­è¯­ä¹‰å…ˆéªŒï¼Œæ¶ˆé™¤äº†å¯¹ç¦»æ•£ç±»åˆ«æ ‡ç­¾çš„éœ€æ±‚ã€‚ç»“åˆé€¼çœŸçš„è®­ç»ƒæ•°æ®å’Œç‚¹æ³•çº¿çš„å™ªå£°æ¨¡å‹ï¼ŒSCOPEç¼©å°äº†ç±»åˆ«çº§ç‰©ä½“å§¿æ€ä¼°è®¡ä¸­çš„Sim2Realå·®è·ã€‚é€šè¿‡äº¤å‰æ³¨æ„åŠ›æ³¨å…¥è¿ç»­è¯­ä¹‰å…ˆéªŒï¼ŒSCOPEèƒ½å¤Ÿå­¦ä¹ è·¨è¶Šå·²çŸ¥ç±»åˆ«åˆ†å¸ƒä¹‹å¤–çš„ç‰©ä½“å®ä¾‹çš„è§„èŒƒåŒ–ç‰©ä½“åæ ‡ç³»ã€‚åœ¨åˆæˆè®­ç»ƒçš„ç±»åˆ«çº§ç‰©ä½“å§¿æ€ä¼°è®¡ä¸­ï¼ŒSCOPEä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨5Â°5cmæŒ‡æ ‡ä¸Šå®ç°äº†31.9%çš„ç›¸å¯¹æ”¹è¿›ã€‚åœ¨ä¸¤ä¸ªå®ä¾‹çº§æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ³›åŒ–åˆ°å·²çŸ¥ç‰©ä½“ç±»åˆ«ä¹‹å¤–ï¼Œä»è€Œèƒ½å¤Ÿä»¥é«˜è¾¾100%çš„æˆåŠŸç‡æŠ“å–æœªçŸ¥ç±»åˆ«çš„æœªè§ç‰©ä½“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ç±»åˆ«çº§ç‰©ä½“å§¿æ€ä¼°è®¡æ–¹æ³•é€šå¸¸ä¾èµ–äºç¦»æ•£çš„ç±»åˆ«æ ‡ç­¾ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨å¼€æ”¾ç¯å¢ƒä¸­å¤„ç†æœªçŸ¥ç‰©ä½“çš„èƒ½åŠ›ã€‚Sim2Realå·®è·ä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºåœ¨ä»¿çœŸç¯å¢ƒä¸­è®­ç»ƒçš„æ¨¡å‹éš¾ä»¥ç›´æ¥åº”ç”¨äºçœŸå®ä¸–ç•Œã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSCOPEçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨DINOv2ç‰¹å¾ä½œä¸ºè¿ç»­çš„è¯­ä¹‰å…ˆéªŒï¼Œå–ä»£ç¦»æ•£çš„ç±»åˆ«æ ‡ç­¾ã€‚é€šè¿‡å°†è¯­ä¹‰ä¿¡æ¯èå…¥åˆ°æ‰©æ•£æ¨¡å‹ä¸­ï¼ŒSCOPEèƒ½å¤Ÿå­¦ä¹ åˆ°è·¨è¶Šä¸åŒç±»åˆ«å’Œå®ä¾‹çš„ç‰©ä½“å§¿æ€è¡¨ç¤ºï¼Œä»è€Œå®ç°æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œä½¿ç”¨é€¼çœŸçš„è®­ç»ƒæ•°æ®å’Œç‚¹æ³•çº¿çš„å™ªå£°æ¨¡å‹æ¥ç¼©å°Sim2Realå·®è·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSCOPEçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) DINOv2ç‰¹å¾æå–å™¨ï¼Œç”¨äºæå–è¾“å…¥ç‚¹äº‘çš„è¯­ä¹‰ç‰¹å¾ï¼›2) æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºç”Ÿæˆç‰©ä½“å§¿æ€çš„å€™é€‰è§£ï¼›3) äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºå°†DINOv2ç‰¹å¾æ³¨å…¥åˆ°æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼›4) æŸå¤±å‡½æ•°ï¼Œç”¨äºä¼˜åŒ–æ¨¡å‹çš„å‚æ•°ï¼ŒåŒ…æ‹¬å§¿æ€æŸå¤±å’Œè¯­ä¹‰ä¸€è‡´æ€§æŸå¤±ã€‚

**å…³é”®åˆ›æ–°**ï¼šSCOPEæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºä½¿ç”¨è¿ç»­çš„è¯­ä¹‰å…ˆéªŒï¼ˆDINOv2ç‰¹å¾ï¼‰æ¥æŒ‡å¯¼ç‰©ä½“å§¿æ€ä¼°è®¡ï¼Œè€Œä¸æ˜¯ä¾èµ–äºç¦»æ•£çš„ç±»åˆ«æ ‡ç­¾ã€‚è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ³›åŒ–åˆ°æœªçŸ¥ç‰©ä½“å’Œç±»åˆ«ã€‚æ­¤å¤–ï¼Œé€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å°†è¯­ä¹‰ä¿¡æ¯èå…¥åˆ°æ‰©æ•£æ¨¡å‹ä¸­ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨è¯­ä¹‰ä¿¡æ¯æ¥æé«˜å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šSCOPEçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é€¼çœŸçš„åˆæˆæ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä»¥å‡å°‘Sim2Realå·®è·ï¼›2) å¼•å…¥ç‚¹æ³•çº¿çš„å™ªå£°æ¨¡å‹ï¼Œä»¥æé«˜æ¨¡å‹å¯¹å™ªå£°çš„é²æ£’æ€§ï¼›3) ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å°†DINOv2ç‰¹å¾æ³¨å…¥åˆ°æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼›4) è®¾è®¡åˆé€‚çš„æŸå¤±å‡½æ•°ï¼ŒåŒ…æ‹¬å§¿æ€æŸå¤±å’Œè¯­ä¹‰ä¸€è‡´æ€§æŸå¤±ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹çš„å‚æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SCOPEåœ¨åˆæˆè®­ç»ƒçš„ç±»åˆ«çº§ç‰©ä½“å§¿æ€ä¼°è®¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œåœ¨5Â°5cmæŒ‡æ ‡ä¸Šå®ç°äº†31.9%çš„ç›¸å¯¹æ”¹è¿›ã€‚æ­¤å¤–ï¼Œåœ¨ä¸¤ä¸ªå®ä¾‹çº§æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSCOPEèƒ½å¤ŸæˆåŠŸæŠ“å–æœªçŸ¥ç±»åˆ«çš„æœªè§ç‰©ä½“ï¼ŒæˆåŠŸç‡é«˜è¾¾100%ï¼Œå±•ç¤ºäº†å…¶å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SCOPEåœ¨æœºå™¨äººæ“ä½œé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½ä»“å‚¨ã€è‡ªåŠ¨åŒ–è£…é…ã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰ã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººåœ¨å¼€æ”¾ç¯å¢ƒä¸­è¯†åˆ«å’ŒæŠ“å–å„ç§ç‰©ä½“ï¼Œå³ä½¿è¿™äº›ç‰©ä½“æ˜¯æœªçŸ¥çš„æˆ–å±äºæ–°çš„ç±»åˆ«ã€‚è¯¥ç ”ç©¶çš„æˆæœå¯ä»¥æé«˜æœºå™¨äººçš„è‡ªä¸»æ€§å’Œé€‚åº”æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°å®Œæˆå„ç§ä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Object manipulation requires accurate object pose estimation. In open environments, robots encounter unknown objects, which requires semantic understanding in order to generalize both to known categories and beyond. To resolve this challenge, we present SCOPE, a diffusion-based category-level object pose estimation model that eliminates the need for discrete category labels by leveraging DINOv2 features as continuous semantic priors. By combining these DINOv2 features with photorealistic training data and a noise model for point normals, we reduce the Sim2Real gap in category-level object pose estimation. Furthermore, injecting the continuous semantic priors via cross-attention enables SCOPE to learn canonicalized object coordinate systems across object instances beyond the distribution of known categories. SCOPE outperforms the current state of the art in synthetically trained category-level object pose estimation, achieving a relative improvement of 31.9\% on the 5$^\circ$5cm metric. Additional experiments on two instance-level datasets demonstrate generalization beyond known object categories, enabling grasping of unseen objects from unknown categories with a success rate of up to 100\%. Code available: https://github.com/hoenigpeter/scope.

