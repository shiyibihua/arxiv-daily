---
layout: default
title: AutoQ-VIS: Improving Unsupervised Video Instance Segmentation via Automatic Quality Assessment
---

# AutoQ-VIS: Improving Unsupervised Video Instance Segmentation via Automatic Quality Assessment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19808" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19808v1</a>
  <a href="https://arxiv.org/pdf/2508.19808.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19808v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19808v1', 'AutoQ-VIS: Improving Unsupervised Video Instance Segmentation via Automatic Quality Assessment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kaixuan Lu, Mehmet Onurcan Kaya, Dim P. Papadopoulos

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

**å¤‡æ³¨**: Accepted to ICCV 2025 Workshop LIMIT

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/wcbup/AutoQ-VIS)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAutoQ-VISä»¥è§£å†³æ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²ä¸­çš„è´¨é‡è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è§†é¢‘å®ä¾‹åˆ†å‰²` `æ— ç›‘ç£å­¦ä¹ ` `è´¨é‡è¯„ä¼°` `è‡ªæˆ‘è®­ç»ƒ` `åˆæˆæ•°æ®` `æ·±åº¦å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²æ–¹æ³•åœ¨å¤„ç†åƒç´ çº§æ©ç å’Œæ—¶é—´ä¸€è‡´æ€§æ ‡ç­¾æ—¶é¢ä¸´æ ‡æ³¨å›°éš¾ã€‚
2. AutoQ-VISé€šè¿‡è´¨é‡å¼•å¯¼çš„è‡ªæˆ‘è®­ç»ƒï¼Œå»ºç«‹ä¼ªæ ‡ç­¾ç”Ÿæˆä¸è´¨é‡è¯„ä¼°çš„é—­ç¯ç³»ç»Ÿï¼Œé€æ­¥é€‚åº”çœŸå®è§†é¢‘ã€‚
3. åœ¨YouTubeVIS-2019éªŒè¯é›†ä¸Šï¼ŒAutoQ-VISçš„AP50è¾¾åˆ°äº†52.6ï¼Œè¶…è¶Šäº†VideoCutLERï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†é¢‘å®ä¾‹åˆ†å‰²ï¼ˆVISï¼‰é¢ä¸´æ˜¾è‘—çš„æ ‡æ³¨æŒ‘æˆ˜ï¼Œå› ä¸ºå®ƒéœ€è¦åƒç´ çº§æ©ç å’Œæ—¶é—´ä¸€è‡´æ€§æ ‡ç­¾ã€‚è™½ç„¶æœ€è¿‘çš„æ— ç›‘ç£æ–¹æ³•å¦‚VideoCutLERé€šè¿‡åˆæˆæ•°æ®æ¶ˆé™¤äº†å…‰æµä¾èµ–ï¼Œä½†ä»å—é™äºåˆæˆä¸çœŸå®åŸŸä¹‹é—´çš„å·®è·ã€‚æˆ‘ä»¬æå‡ºäº†AutoQ-VISï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ— ç›‘ç£æ¡†æ¶ï¼Œé€šè¿‡è´¨é‡å¼•å¯¼çš„è‡ªæˆ‘è®­ç»ƒæ¥å¼¥åˆè¿™ä¸€å·®è·ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¼ªæ ‡ç­¾ç”Ÿæˆå’Œè‡ªåŠ¨è´¨é‡è¯„ä¼°ä¹‹é—´å»ºç«‹äº†é—­ç¯ç³»ç»Ÿï¼Œä½¿å¾—ä»åˆæˆè§†é¢‘åˆ°çœŸå®è§†é¢‘çš„é€æ­¥é€‚åº”æˆä¸ºå¯èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨YouTubeVIS-2019éªŒè¯é›†ä¸Šï¼ŒAutoQ-VISè¾¾åˆ°äº†52.6çš„AP50ï¼Œè¶…è¶Šäº†ä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•VideoCutLER 4.4ä¸ªç™¾åˆ†ç‚¹ï¼ŒåŒæ—¶æ— éœ€äººå·¥æ ‡æ³¨ã€‚è¿™è¯æ˜äº†è´¨é‡æ„ŸçŸ¥è‡ªæˆ‘è®­ç»ƒåœ¨æ— ç›‘ç£VISä¸­çš„å¯è¡Œæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†é¢‘å®ä¾‹åˆ†å‰²éœ€è¦åŒæ—¶å¤„ç†åƒç´ çº§æ©ç å’Œæ—¶é—´ä¸€è‡´æ€§æ ‡ç­¾ï¼Œç°æœ‰æ— ç›‘ç£æ–¹æ³•å¦‚VideoCutLERè™½ç„¶æ¶ˆé™¤äº†å…‰æµä¾èµ–ï¼Œä½†ä»é¢ä¸´åˆæˆä¸çœŸå®è§†é¢‘ä¹‹é—´çš„åŸŸå·®è·é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAutoQ-VISé€šè¿‡è´¨é‡å¼•å¯¼çš„è‡ªæˆ‘è®­ç»ƒæ–¹æ³•ï¼Œå»ºç«‹ä¼ªæ ‡ç­¾ç”Ÿæˆä¸è‡ªåŠ¨è´¨é‡è¯„ä¼°ä¹‹é—´çš„é—­ç¯ï¼Œæ—¨åœ¨æœ‰æ•ˆåœ°ä»åˆæˆè§†é¢‘é€‚åº”åˆ°çœŸå®è§†é¢‘ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¼ªæ ‡ç­¾ç”Ÿæˆæ¨¡å—å’Œè´¨é‡è¯„ä¼°æ¨¡å—ï¼ŒäºŒè€…ç›¸äº’ä½œç”¨ï¼Œå½¢æˆä¸€ä¸ªé—­ç¯ç³»ç»Ÿã€‚ä¼ªæ ‡ç­¾ç”Ÿæˆæ¨¡å—è´Ÿè´£ç”Ÿæˆåˆæ­¥çš„å®ä¾‹åˆ†å‰²ç»“æœï¼Œè€Œè´¨é‡è¯„ä¼°æ¨¡å—åˆ™å¯¹è¿™äº›ç»“æœè¿›è¡Œè¯„ä¼°å¹¶åé¦ˆï¼Œä»¥æ”¹è¿›ä¼ªæ ‡ç­¾çš„è´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šAutoQ-VISçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†è´¨é‡æ„ŸçŸ¥çš„è‡ªæˆ‘è®­ç»ƒæœºåˆ¶ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨æ— ç›‘ç£çš„æƒ…å†µä¸‹é€æ­¥æé«˜å¯¹çœŸå®è§†é¢‘çš„é€‚åº”èƒ½åŠ›ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„é™æ€è®­ç»ƒæ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒAutoQ-VISé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡ä¼ªæ ‡ç­¾çš„ç”Ÿæˆå’Œè´¨é‡è¯„ä¼°ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥æé«˜æ¨¡å‹å¯¹è§†é¢‘å†…å®¹çš„ç†è§£èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒAutoQ-VISåœ¨YouTubeVIS-2019éªŒè¯é›†ä¸Šè¾¾åˆ°äº†52.6çš„AP50ï¼Œè¶…è¶Šäº†ä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•VideoCutLER 4.4ä¸ªç™¾åˆ†ç‚¹ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨æ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²ä»»åŠ¡ä¸­çš„å“è¶Šæ€§èƒ½ï¼Œä¸”æ— éœ€ä»»ä½•äººå·¥æ ‡æ³¨ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬è‡ªåŠ¨è§†é¢‘ç¼–è¾‘ã€ç›‘æ§è§†é¢‘åˆ†æå’Œæ™ºèƒ½äº¤é€šç³»ç»Ÿç­‰é¢†åŸŸã€‚é€šè¿‡æ— ç›‘ç£çš„è§†é¢‘å®ä¾‹åˆ†å‰²ï¼Œèƒ½å¤Ÿé™ä½äººå·¥æ ‡æ³¨æˆæœ¬ï¼Œæé«˜è§†é¢‘å¤„ç†çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Video Instance Segmentation (VIS) faces significant annotation challenges due to its dual requirements of pixel-level masks and temporal consistency labels. While recent unsupervised methods like VideoCutLER eliminate optical flow dependencies through synthetic data, they remain constrained by the synthetic-to-real domain gap. We present AutoQ-VIS, a novel unsupervised framework that bridges this gap through quality-guided self-training. Our approach establishes a closed-loop system between pseudo-label generation and automatic quality assessment, enabling progressive adaptation from synthetic to real videos. Experiments demonstrate state-of-the-art performance with 52.6 $\text{AP}_{50}$ on YouTubeVIS-2019 val set, surpassing the previous state-of-the-art VideoCutLER by 4.4$\%$, while requiring no human annotations. This demonstrates the viability of quality-aware self-training for unsupervised VIS. The source code of our method is available at https://github.com/wcbup/AutoQ-VIS.

