---
layout: default
title: Scalable Object Detection in the Car Interior With Vision Foundation Models
---

# Scalable Object Detection in the Car Interior With Vision Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19651" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19651v1</a>
  <a href="https://arxiv.org/pdf/2508.19651.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19651v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19651v1', 'Scalable Object Detection in the Car Interior With Vision Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: BÃ¡lint MÃ©szÃ¡ros, Ahmet Firintepe, Sebastian Schmidt, Stephan GÃ¼nnemann

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºODALæ¡†æ¶ä»¥è§£å†³è½¦å†…ç‰©ä½“æ£€æµ‹ä¸å®šä½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è½¦å†…ç‰©ä½“æ£€æµ‹` `åˆ†å¸ƒå¼è®¡ç®—` `åœºæ™¯ç†è§£` `åŸºç¡€æ¨¡å‹` `å¾®è°ƒæŠ€æœ¯` `æ™ºèƒ½æ±½è½¦` `AIåŠ©æ‰‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è½¦è½½ç³»ç»Ÿä¸­å—é™äºè®¡ç®—èµ„æºï¼Œéš¾ä»¥å®ç°é«˜æ•ˆçš„ç‰©ä½“æ£€æµ‹ä¸å®šä½ã€‚
2. æœ¬æ–‡æå‡ºçš„ODALæ¡†æ¶é€šè¿‡åˆ†å¸ƒå¼æ¶æ„ï¼Œç»“åˆè½¦è½½ä¸äº‘ç«¯è®¡ç®—ï¼Œæå‡äº†è½¦å†…åœºæ™¯ç†è§£èƒ½åŠ›ã€‚
3. ç»è¿‡å¾®è°ƒçš„ODAL-LLaVAæ¨¡å‹åœ¨ODAL_scoreä¸Šè¾¾åˆ°89%ï¼Œè¾ƒåŸºçº¿æå‡71%ï¼Œå¹¶è¶…è¶ŠGPT-4oè¿‘20%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è½¦å†…çš„AIä»»åŠ¡ï¼Œå¦‚è¯†åˆ«å’Œå®šä½å¤–éƒ¨å¼•å…¥çš„ç‰©ä½“ï¼Œå¯¹äºä¸ªäººåŠ©æ‰‹çš„å“åº”è´¨é‡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè½¦è½½ç³»ç»Ÿçš„è®¡ç®—èµ„æºå—é™ï¼Œé™åˆ¶äº†æ­¤ç±»è§£å†³æ–¹æ¡ˆçš„ç›´æ¥éƒ¨ç½²ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†æ–°é¢–çš„ç‰©ä½“æ£€æµ‹ä¸å®šä½ï¼ˆODALï¼‰æ¡†æ¶ï¼Œåˆ©ç”¨åˆ†å¸ƒå¼æ¶æ„å°†è®¡ç®—ä»»åŠ¡åˆ†é…åˆ°è½¦è½½ç³»ç»Ÿå’Œäº‘ç«¯ï¼Œä»è€Œå…‹æœäº†ç›´æ¥åœ¨è½¦å†…è¿è¡ŒåŸºç¡€æ¨¡å‹çš„èµ„æºé™åˆ¶ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ODALbenchä½œä¸ºæ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå…¨é¢è¯„ä¼°æ£€æµ‹å’Œå®šä½æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨è¯¥é¢†åŸŸå»ºç«‹äº†æ–°çš„æ ‡å‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è½¦å†…ç‰©ä½“æ£€æµ‹ä¸å®šä½çš„è®¡ç®—èµ„æºé™åˆ¶é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è½¦è½½ç³»ç»Ÿä¸­éš¾ä»¥é«˜æ•ˆè¿è¡Œï¼Œå½±å“äº†AIåŠ©æ‰‹çš„å“åº”è´¨é‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šODALæ¡†æ¶é€šè¿‡åˆ†å¸ƒå¼æ¶æ„ï¼Œå°†è®¡ç®—ä»»åŠ¡åˆ†é…åˆ°è½¦è½½ç³»ç»Ÿå’Œäº‘ç«¯ï¼Œä»è€Œæœ‰æ•ˆåˆ©ç”¨èµ„æºï¼Œæå‡æ£€æµ‹ä¸å®šä½çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šODALæ¡†æ¶åŒ…æ‹¬æ•°æ®é‡‡é›†ã€æ¨¡å‹æ¨ç†å’Œç»“æœèåˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é‡‡é›†é€šè¿‡è½¦è½½æ‘„åƒå¤´è·å–åœºæ™¯ä¿¡æ¯ï¼Œæ¨¡å‹æ¨ç†åœ¨äº‘ç«¯å’Œè½¦è½½ç³»ç»Ÿä¹‹é—´åˆ†é…ï¼Œæœ€åè¿›è¡Œç»“æœèåˆä»¥è¾“å‡ºæœ€ç»ˆæ£€æµ‹ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šODALæ¡†æ¶çš„åˆ›æ–°åœ¨äºå…¶åˆ†å¸ƒå¼è®¡ç®—è®¾è®¡ï¼Œä½¿å¾—åŸºç¡€æ¨¡å‹å¯ä»¥åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­é«˜æ•ˆè¿è¡Œï¼Œæ˜¾è‘—æå‡äº†æ£€æµ‹æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹é€‰æ‹©ä¸Šï¼Œæœ¬æ–‡æ¯”è¾ƒäº†GPT-4oä¸è½»é‡çº§çš„LLaVA 1.5 7Bæ¨¡å‹ï¼Œå¹¶é€šè¿‡å¾®è°ƒæå‡äº†è½»é‡æ¨¡å‹çš„æ€§èƒ½ï¼Œæœ€ç»ˆå®ç°äº†é«˜è¾¾89%çš„ODAL_scoreã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒåçš„ODAL-LLaVAæ¨¡å‹åœ¨ODAL_scoreä¸Šè¾¾åˆ°89%ï¼Œè¾ƒåŸºçº¿æå‡71%ï¼Œå¹¶ä¸”åœ¨æ£€æµ‹å‡†ç¡®æ€§ä¸Šæ˜¾è‘—é™ä½äº†å¹»è§‰ç°è±¡ï¼Œå…¶ODAL_SNRæ˜¯GPT-4oçš„ä¸‰å€ï¼Œå±•ç¤ºäº†è¯¥æ¡†æ¶çš„å¼ºå¤§æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æ±½è½¦ã€è‡ªåŠ¨é©¾é©¶å’Œè½¦è½½ä¸ªäººåŠ©æ‰‹ç­‰ã€‚é€šè¿‡æé«˜è½¦å†…ç‰©ä½“æ£€æµ‹ä¸å®šä½çš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒå’Œå®‰å…¨æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½äº¤é€šç³»ç»Ÿçš„å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶è¿˜å¯æ‰©å±•åˆ°å…¶ä»–éœ€è¦å®æ—¶åœºæ™¯ç†è§£çš„é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> AI tasks in the car interior like identifying and localizing externally introduced objects is crucial for response quality of personal assistants. However, computational resources of on-board systems remain highly constrained, restricting the deployment of such solutions directly within the vehicle. To address this limitation, we propose the novel Object Detection and Localization (ODAL) framework for interior scene understanding. Our approach leverages vision foundation models through a distributed architecture, splitting computational tasks between on-board and cloud. This design overcomes the resource constraints of running foundation models directly in the car. To benchmark model performance, we introduce ODALbench, a new metric for comprehensive assessment of detection and localization.Our analysis demonstrates the framework's potential to establish new standards in this domain. We compare the state-of-the-art GPT-4o vision foundation model with the lightweight LLaVA 1.5 7B model and explore how fine-tuning enhances the lightweight models performance. Remarkably, our fine-tuned ODAL-LLaVA model achieves an ODAL$_{score}$ of 89%, representing a 71% improvement over its baseline performance and outperforming GPT-4o by nearly 20%. Furthermore, the fine-tuned model maintains high detection accuracy while significantly reducing hallucinations, achieving an ODAL$_{SNR}$ three times higher than GPT-4o.

