---
layout: default
title: Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization
---

# Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.20181" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.20181v1</a>
  <a href="https://arxiv.org/pdf/2508.20181.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.20181v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.20181v1', 'Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alberto Compagnoni, Davide Caffagni, Nicholas Moratelli, Lorenzo Baraldi, Marcella Cornia, Rita Cucchiara

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

**å¤‡æ³¨**: BMVC 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/aimagelab/CHAIR-DPO)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCHAIR-DPOä»¥å‡å°‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å¹»è§‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å¹»è§‰é—®é¢˜` `ç›´æ¥åå¥½ä¼˜åŒ–` `CHAIRæŒ‡æ ‡` `æ¨¡å‹å¾®è°ƒ` `è‡ªç„¶è¯­è¨€å¤„ç†` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤šç§ä»»åŠ¡æ—¶ï¼Œä»ç„¶å­˜åœ¨ç”Ÿæˆä¸è§†è§‰è¾“å…¥ä¸ç¬¦çš„å¹»è§‰ç°è±¡ï¼Œå½±å“å…¶å¯é æ€§ã€‚
2. æœ¬æ–‡æå‡ºCHAIR-DPOæ–¹æ³•ï¼Œé€šè¿‡CHAIRæŒ‡æ ‡ä¼˜åŒ–ç”Ÿæˆç­”æ¡ˆçš„åå¥½ï¼Œå‡å°‘å¹»è§‰ç°è±¡çš„å‘ç”Ÿã€‚
3. å®éªŒè¡¨æ˜ï¼ŒCHAIR-DPOåœ¨å¤šä¸ªå¹»è§‰åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—é™ä½äº†å¹»è§‰ç­”æ¡ˆçš„æ¯”ä¾‹ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä½œä¸ºç»Ÿä¸€æ¥å£ï¼Œèƒ½å¤Ÿå¤„ç†ä»è‡ªç„¶è¯­è¨€å¤„ç†åˆ°è®¡ç®—æœºè§†è§‰çš„å¤šç§ä»»åŠ¡ã€‚å°½ç®¡åœ¨è®¸å¤šåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†MLLMsä»ç„¶å­˜åœ¨å¹»è§‰ç°è±¡ï¼Œå³ç”Ÿæˆçš„ç­”æ¡ˆä¸è§†è§‰è¾“å…¥ä¸ç¬¦ã€‚æœ¬æ–‡å°†å¹»è§‰é—®é¢˜è§†ä¸ºå¯¹é½é—®é¢˜ï¼Œæ—¨åœ¨å¼•å¯¼MLLMsç”Ÿæˆä¸å¸¦å¹»è§‰çš„å†…å®¹ã€‚ä¸éœ€è¦å¤æ‚ç®¡é“æ„å»ºåˆæˆåå¥½æ•°æ®çš„ç°æœ‰æ–¹æ³•ä¸åŒï¼Œæœ¬æ–‡åˆ©ç”¨CHAIRæŒ‡æ ‡æ¥åŒºåˆ†ç”Ÿæˆç­”æ¡ˆçš„ä¼˜åŠ£ï¼Œå¹¶é€šè¿‡ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰å¯¹ç°æˆçš„MLLMsè¿›è¡Œå¾®è°ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCHAIR-DPOæœ‰æ•ˆå‡å°‘äº†å¤šä¸ªå¹»è§‰åŸºå‡†ä¸Šçš„å¹»è§‰ç­”æ¡ˆï¼Œè¯æ˜äº†CHAIRåŸºç¡€å¥–åŠ±çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºç°çš„å¹»è§‰ç°è±¡ï¼Œå³ç”Ÿæˆçš„å†…å®¹ä¸è§†è§‰è¾“å…¥ä¸ä¸€è‡´ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–å¤æ‚çš„ç®¡é“å’Œåˆæˆæ•°æ®ï¼Œéš¾ä»¥å®ç°æœ‰æ•ˆå¯¹é½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¹»è§‰é—®é¢˜è§†ä¸ºå¯¹é½é—®é¢˜ï¼Œé€šè¿‡CHAIRæŒ‡æ ‡æ¥ä¼˜åŒ–ç”Ÿæˆå†…å®¹çš„åå¥½ï¼Œç›´æ¥å¼•å¯¼æ¨¡å‹ç”Ÿæˆæ›´å‡†ç¡®çš„ç­”æ¡ˆã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨ç®€åŒ–è®­ç»ƒè¿‡ç¨‹ï¼Œé¿å…ä¾èµ–å¤æ‚çš„åˆæˆæ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä½¿ç”¨CHAIRæŒ‡æ ‡è¯„ä¼°ç”Ÿæˆç­”æ¡ˆçš„ä¼˜åŠ£ï¼Œåˆ©ç”¨ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰å¯¹ç°æˆçš„MLLMsè¿›è¡Œå¾®è°ƒã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬ç”Ÿæˆç­”æ¡ˆçš„è¯„ä¼°ã€åå¥½é€‰æ‹©å’Œæ¨¡å‹å¾®è°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šCHAIR-DPOæ–¹æ³•çš„åˆ›æ–°åœ¨äºåˆ©ç”¨CHAIRæŒ‡æ ‡è¿›è¡Œåå¥½ä¼˜åŒ–ï¼ŒåŒºåˆ«äºä»¥å¾€ä¾èµ–å¤æ‚åˆæˆæ•°æ®çš„å¯¹é½æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•ä¸ä»…ç®€åŒ–äº†è®­ç»ƒæµç¨‹ï¼Œè¿˜æé«˜äº†æ¨¡å‹ç”Ÿæˆç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒCHAIRæŒ‡æ ‡ç”¨äºè¯„ä¼°ç”Ÿæˆç­”æ¡ˆçš„å¹»è§‰ç¨‹åº¦ï¼ŒDPOåˆ™é€šè¿‡ä¼˜åŒ–æŸå¤±å‡½æ•°æ¥è°ƒæ•´æ¨¡å‹çš„ç”Ÿæˆåå¥½ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCHAIR-DPOåœ¨å¤šä¸ªå¹»è§‰åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—é™ä½äº†å¹»è§‰ç­”æ¡ˆçš„æ¯”ä¾‹ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®éœ€æŸ¥é˜…åŸæ–‡ï¼‰ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•è¡¨ç°å‡ºæ›´ä¼˜çš„æ€§èƒ½ï¼ŒéªŒè¯äº†CHAIRåŸºç¡€å¥–åŠ±çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨å†…å®¹ç”Ÿæˆå’Œå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿç­‰ã€‚é€šè¿‡å‡å°‘å¹»è§‰ç°è±¡ï¼ŒCHAIR-DPOèƒ½å¤Ÿæå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿçš„å¯é æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) emerge as a unified interface to address a multitude of tasks, ranging from NLP to computer vision. Despite showcasing state-of-the-art results in many benchmarks, a long-standing issue is the tendency of MLLMs to hallucinate, that is to generate answers to the user's query that are not reflected in the visual input. In this paper, we address the problem of hallucinations as an alignment problem, seeking to steer the MLLM so that it prefers generating content without hallucinations. In contrast to recent approaches that require complicated pipelines to build synthetic preference data for alignment training, often relying on proprietary models, we capitalize on the well-known CHAIR metric, originally proposed to gauge the degree of hallucinations in image captioning. Given a pair of generated answers, we leverage CHAIR to distinguish winner and loser options (i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf MLLMs via Direct Preference Optimization (DPO). The resulting method, which we refer to as CHAIR-DPO, effectively diminishes the amount of hallucinated answers on several hallucination benchmarks, demonstrating the effectiveness of fine-tuning the MLLM with a CHAIR-based reward. Source code and trained models are publicly available at https://github.com/aimagelab/CHAIR-DPO.

