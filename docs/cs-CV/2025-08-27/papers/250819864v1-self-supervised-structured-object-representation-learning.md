---
layout: default
title: Self-supervised structured object representation learning
---

# Self-supervised structured object representation learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19864" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19864v1</a>
  <a href="https://arxiv.org/pdf/2508.19864.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19864v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19864v1', 'Self-supervised structured object representation learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Oussama Hadjerci, Antoine Letienne, Mohamed Abbas Hedjazi, Adel Hafiane

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªç›‘ç£ç»“æ„åŒ–ç‰©ä½“è¡¨ç¤ºå­¦ä¹ ä»¥æå‡è§†è§‰ç†è§£èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è‡ªç›‘ç£å­¦ä¹ ` `ç»“æ„åŒ–è¡¨ç¤º` `ç‰©ä½“æ£€æµ‹` `è§†è§‰ç†è§£` `ProtoScaleæ¨¡å—`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨å…¨å±€å›¾åƒç†è§£ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ•æ‰åœºæ™¯çš„ç»“æ„åŒ–è¡¨ç¤ºæ–¹é¢å­˜åœ¨ä¸è¶³ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç›‘ç£æ–¹æ³•ï¼Œé€šè¿‡è¯­ä¹‰åˆ†ç»„ã€å®ä¾‹åˆ†ç¦»å’Œå±‚æ¬¡ç»“æ„é€æ­¥æ„å»ºç»“æ„åŒ–è§†è§‰è¡¨ç¤ºã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç‰©ä½“æ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨æœ‰é™æ ‡æ³¨æ•°æ®å’Œè¾ƒå°‘å¾®è°ƒå‘¨æœŸçš„æƒ…å†µä¸‹ï¼Œè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰å·²æˆä¸ºå­¦ä¹ è§†è§‰è¡¨ç¤ºçš„å¼ºå¤§æŠ€æœ¯ã€‚å°½ç®¡è¿‘æœŸçš„SSLæ–¹æ³•åœ¨å…¨å±€å›¾åƒç†è§£æ–¹é¢å–å¾—äº†æ˜¾è‘—æˆæœï¼Œä½†åœ¨æ•æ‰åœºæ™¯ä¸­çš„ç»“æ„åŒ–è¡¨ç¤ºæ–¹é¢ä»ç„¶å­˜åœ¨å±€é™æ€§ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§è‡ªç›‘ç£æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆè¯­ä¹‰åˆ†ç»„ã€å®ä¾‹çº§åˆ†ç¦»å’Œå±‚æ¬¡ç»“æ„ï¼Œé€æ­¥æ„å»ºç»“æ„åŒ–è§†è§‰è¡¨ç¤ºã€‚æˆ‘ä»¬çš„æ–¹æ³•åŸºäºä¸€ç§æ–°é¢–çš„ProtoScaleæ¨¡å—ï¼Œèƒ½å¤Ÿè·¨å¤šä¸ªç©ºé—´å°ºåº¦æ•æ‰è§†è§‰å…ƒç´ ã€‚ä¸ä¾èµ–éšæœºè£å‰ªå’Œå…¨å±€åµŒå…¥çš„å¸¸è§ç­–ç•¥ä¸åŒï¼Œæˆ‘ä»¬åœ¨å¢å¼ºè§†å›¾ä¸­ä¿ç•™å®Œæ•´çš„åœºæ™¯ä¸Šä¸‹æ–‡ï¼Œä»¥æé«˜åœ¨å¯†é›†é¢„æµ‹ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªæ•°æ®é›†ï¼ˆCOCOå’ŒUA-DETRACï¼‰çš„ç»„åˆå­é›†ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å­¦ä¹ çš„ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„è¡¨ç¤ºå¢å¼ºäº†ç›‘ç£ç‰©ä½“æ£€æµ‹ï¼Œå¹¶åœ¨æœ‰é™æ ‡æ³¨æ•°æ®å’Œè¾ƒå°‘å¾®è°ƒå‘¨æœŸçš„æƒ…å†µä¸‹è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨æ•æ‰åœºæ™¯ç»“æ„åŒ–è¡¨ç¤ºæ–¹é¢çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯åœ¨å¯†é›†é¢„æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–éšæœºè£å‰ªå’Œå…¨å±€åµŒå…¥ï¼Œå¯¼è‡´ä¿¡æ¯ä¸¢å¤±ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºProtoScaleæ¨¡å—çš„è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆè¯­ä¹‰åˆ†ç»„ã€å®ä¾‹åˆ†ç¦»å’Œå±‚æ¬¡ç»“æ„ï¼Œé€æ­¥æ„å»ºç»“æ„åŒ–è§†è§‰è¡¨ç¤ºï¼Œä»è€Œä¿ç•™å®Œæ•´çš„åœºæ™¯ä¸Šä¸‹æ–‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªé˜¶æ®µï¼Œé¦–å…ˆè¿›è¡Œè¯­ä¹‰åˆ†ç»„ï¼Œç„¶åè¿›è¡Œå®ä¾‹çº§åˆ†ç¦»ï¼Œæœ€åé€šè¿‡å±‚æ¬¡ç»“æ„æ•´åˆä¿¡æ¯ã€‚ProtoScaleæ¨¡å—åœ¨ä¸åŒç©ºé—´å°ºåº¦ä¸Šæ•æ‰è§†è§‰å…ƒç´ ï¼Œç¡®ä¿ä¿¡æ¯çš„å…¨é¢æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºProtoScaleæ¨¡å—çš„è®¾è®¡ï¼Œå®ƒä¸ä¼ ç»Ÿæ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºèƒ½å¤Ÿåœ¨ä¿ç•™åœºæ™¯ä¸Šä¸‹æ–‡çš„åŒæ—¶ï¼Œè¿›è¡Œå¤šå°ºåº¦çš„è§†è§‰å…ƒç´ æ•æ‰ï¼Œä»è€Œæå‡äº†è¡¨ç¤ºçš„ç»“æ„åŒ–ç¨‹åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ä»¥å¹³è¡¡ä¸åŒä»»åŠ¡çš„éœ€æ±‚ï¼ŒåŒæ—¶ç½‘ç»œç»“æ„è®¾è®¡ä¸Šå¼•å…¥äº†å±‚æ¬¡åŒ–çš„ç‰¹å¾æå–æ¨¡å—ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚å®éªŒä¸­ä½¿ç”¨äº†COCOå’ŒUA-DETRACæ•°æ®é›†çš„ç»„åˆå­é›†è¿›è¡ŒéªŒè¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨ç‰©ä½“æ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨ä½¿ç”¨æœ‰é™æ ‡æ³¨æ•°æ®å’Œè¾ƒå°‘å¾®è°ƒå‘¨æœŸçš„æƒ…å†µä¸‹ï¼Œè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°äº†XX%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººè§†è§‰å’Œæ™ºèƒ½ç›‘æ§ç­‰ã€‚é€šè¿‡æå‡ç‰©ä½“æ£€æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨å®é™…åœºæ™¯ä¸­å®ç°æ›´é«˜æ•ˆçš„è§†è§‰ç†è§£ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Self-supervised learning (SSL) has emerged as a powerful technique for learning visual representations. While recent SSL approaches achieve strong results in global image understanding, they are limited in capturing the structured representation in scenes. In this work, we propose a self-supervised approach that progressively builds structured visual representations by combining semantic grouping, instance level separation, and hierarchical structuring. Our approach, based on a novel ProtoScale module, captures visual elements across multiple spatial scales. Unlike common strategies like DINO that rely on random cropping and global embeddings, we preserve full scene context across augmented views to improve performance in dense prediction tasks. We validate our method on downstream object detection tasks using a combined subset of multiple datasets (COCO and UA-DETRAC). Experimental results show that our method learns object centric representations that enhance supervised object detection and outperform the state-of-the-art methods, even when trained with limited annotated data and fewer fine-tuning epochs.

