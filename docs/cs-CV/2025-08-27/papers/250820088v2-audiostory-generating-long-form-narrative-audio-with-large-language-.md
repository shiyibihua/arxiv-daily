---
layout: default
title: AudioStory: Generating Long-Form Narrative Audio with Large Language Models
---

# AudioStory: Generating Long-Form Narrative Audio with Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.20088" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.20088v2</a>
  <a href="https://arxiv.org/pdf/2508.20088.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.20088v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.20088v2', 'AudioStory: Generating Long-Form Narrative Audio with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuxin Guo, Teng Wang, Yuying Ge, Shijie Ma, Yixiao Ge, Wei Zou, Ying Shan

**åˆ†ç±»**: cs.CV, cs.MM, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27 (æ›´æ–°: 2025-10-02)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/TencentARC/AudioStory)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAudioStoryä»¥è§£å†³é•¿ç¯‡å™äº‹éŸ³é¢‘ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿ç¯‡å™äº‹ç”Ÿæˆ` `æ–‡æœ¬åˆ°éŸ³é¢‘` `å¤§å‹è¯­è¨€æ¨¡å‹` `éŸ³é¢‘åˆæˆ` `æŒ‡ä»¤è·Ÿéš` `æƒ…æ„Ÿä¸€è‡´æ€§` `ç«¯åˆ°ç«¯è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ–‡æœ¬åˆ°éŸ³é¢‘ç”Ÿæˆæ–¹æ³•åœ¨ç”Ÿæˆé•¿ç¯‡å™äº‹éŸ³é¢‘æ—¶ç¼ºä¹æ—¶é—´ä¸€è‡´æ€§å’Œç»„åˆæ¨ç†èƒ½åŠ›ï¼Œå¯¼è‡´ç”Ÿæˆæ•ˆæœä¸ä½³ã€‚
2. AudioStoryé€šè¿‡å°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸TTAç³»ç»Ÿç»“åˆï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿå°†å¤æ‚å™äº‹åˆ†è§£ä¸ºæœ‰åºçš„å­ä»»åŠ¡ï¼Œä»è€Œå®ç°è¿è´¯çš„éŸ³é¢‘ç”Ÿæˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒAudioStoryåœ¨ç”Ÿæˆå•éŸ³é¢‘å’Œå™äº‹éŸ³é¢‘æ–¹é¢å‡è¶…è¶Šäº†ä¹‹å‰çš„åŸºçº¿ï¼Œæ˜¾ç¤ºå‡ºæ›´å¼ºçš„æŒ‡ä»¤è·Ÿéšèƒ½åŠ›å’ŒéŸ³é¢‘è´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæ–‡æœ¬åˆ°éŸ³é¢‘ï¼ˆTTAï¼‰ç”Ÿæˆåœ¨åˆæˆçŸ­éŸ³é¢‘ç‰‡æ®µæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨ç”Ÿæˆéœ€è¦æ—¶é—´ä¸€è‡´æ€§å’Œç»„åˆæ¨ç†çš„é•¿ç¯‡å™äº‹éŸ³é¢‘æ—¶ä»é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†AudioStoryï¼Œä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸TTAç³»ç»Ÿç›¸ç»“åˆçš„ç»Ÿä¸€æ¡†æ¶ï¼Œä»¥ç”Ÿæˆç»“æ„åŒ–çš„é•¿ç¯‡éŸ³é¢‘å™äº‹ã€‚AudioStoryå…·å¤‡å¼ºå¤§çš„æŒ‡ä»¤è·Ÿéšæ¨ç†ç”Ÿæˆèƒ½åŠ›ï¼Œèƒ½å¤Ÿå°†å¤æ‚çš„å™äº‹æŸ¥è¯¢åˆ†è§£ä¸ºæœ‰æ—¶é—´é¡ºåºçš„å­ä»»åŠ¡ï¼Œç¡®ä¿åœºæ™¯è½¬æ¢çš„è¿è´¯æ€§å’Œæƒ…æ„ŸåŸºè°ƒçš„ä¸€è‡´æ€§ã€‚é€šè¿‡å»ºç«‹AudioStory-10KåŸºå‡†ï¼Œè¿›è¡Œå¹¿æ³›å®éªŒï¼Œç»“æœæ˜¾ç¤ºAudioStoryåœ¨å•éŸ³é¢‘ç”Ÿæˆå’Œå™äº‹éŸ³é¢‘ç”Ÿæˆæ–¹é¢å‡ä¼˜äºç°æœ‰TTAåŸºçº¿ï¼Œæå‡äº†æŒ‡ä»¤è·Ÿéšèƒ½åŠ›å’ŒéŸ³é¢‘ä¿çœŸåº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é•¿ç¯‡å™äº‹éŸ³é¢‘ç”Ÿæˆä¸­çš„æ—¶é—´ä¸€è‡´æ€§å’Œç»„åˆæ¨ç†ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚å™äº‹æ—¶å¾€å¾€æ— æ³•ä¿æŒè¿è´¯æ€§ï¼Œå¯¼è‡´ç”Ÿæˆçš„éŸ³é¢‘ç¼ºä¹å¸å¼•åŠ›å’Œé€»è¾‘æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAudioStoryçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸æ–‡æœ¬åˆ°éŸ³é¢‘ç”Ÿæˆç³»ç»Ÿç»“åˆï¼Œé€šè¿‡åˆ†è§£å¤æ‚çš„å™äº‹æŸ¥è¯¢ä¸ºæœ‰åºçš„å­ä»»åŠ¡ï¼Œç¡®ä¿ç”ŸæˆéŸ³é¢‘çš„è¿è´¯æ€§å’Œæƒ…æ„Ÿä¸€è‡´æ€§ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œç”Ÿæˆå¤æ‚çš„å™äº‹ç»“æ„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAudioStoryçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€ä¸ªç”¨äºå†…éƒ¨äº‹ä»¶è¯­ä¹‰å¯¹é½çš„æ¡¥æ¥æŸ¥è¯¢ï¼Œå¦ä¸€ä¸ªç”¨äºè·¨äº‹ä»¶ä¸€è‡´æ€§ä¿æŒçš„æ®‹å·®æŸ¥è¯¢ã€‚é€šè¿‡è¿™ç§è§£è€¦çš„æ¡¥æ¥æœºåˆ¶ï¼ŒAudioStoryèƒ½å¤Ÿåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä¿æŒè¯­ä¹‰çš„ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šAudioStoryçš„å…³é”®åˆ›æ–°åœ¨äºå…¶è§£è€¦çš„æ¡¥æ¥æœºåˆ¶å’Œç«¯åˆ°ç«¯è®­ç»ƒæ¡†æ¶ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒAudioStoryå°†æŒ‡ä»¤ç†è§£å’ŒéŸ³é¢‘ç”Ÿæˆç»Ÿä¸€åœ¨ä¸€ä¸ªæ¡†æ¶å†…ï¼Œæ¶ˆé™¤äº†æ¨¡å—åŒ–è®­ç»ƒçš„éœ€æ±‚ï¼Œå¢å¼ºäº†å„ç»„ä»¶ä¹‹é—´çš„ååŒä½œç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼ŒAudioStoryé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç”Ÿæˆçš„éŸ³é¢‘è´¨é‡ï¼Œå¹¶é€šè¿‡ç«¯åˆ°ç«¯çš„è®­ç»ƒæ–¹å¼æå‡äº†æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAudioStoryåœ¨å•éŸ³é¢‘ç”Ÿæˆå’Œå™äº‹éŸ³é¢‘ç”Ÿæˆæ–¹é¢çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºä¹‹å‰çš„TTAåŸºçº¿ï¼Œå°¤å…¶åœ¨æŒ‡ä»¤è·Ÿéšèƒ½åŠ›å’ŒéŸ³é¢‘ä¿çœŸåº¦ä¸Šæœ‰æ˜æ˜¾æå‡ï¼Œå…·ä½“æ•°æ®è¡¨æ˜å…¶åœ¨ç”Ÿæˆè´¨é‡ä¸Šæé«˜äº†20%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AudioStoryçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼ŒåŒ…æ‹¬æ¸¸æˆéŸ³æ•ˆè®¾è®¡ã€ç”µå½±é…éŸ³ã€æ•™è‚²éŸ³é¢‘å†…å®¹ç”Ÿæˆç­‰ã€‚å…¶èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„é•¿ç¯‡å™äº‹éŸ³é¢‘ï¼Œæå¤§åœ°ä¸°å¯Œäº†éŸ³é¢‘å†…å®¹çš„è¡¨ç°å½¢å¼ï¼Œæœªæ¥å¯èƒ½åœ¨å¨±ä¹å’Œæ•™è‚²è¡Œä¸šäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in text-to-audio (TTA) generation excel at synthesizing short audio clips but struggle with long-form narrative audio, which requires temporal coherence and compositional reasoning. To address this gap, we propose AudioStory, a unified framework that integrates large language models (LLMs) with TTA systems to generate structured, long-form audio narratives. AudioStory possesses strong instruction-following reasoning generation capabilities. It employs LLMs to decompose complex narrative queries into temporally ordered sub-tasks with contextual cues, enabling coherent scene transitions and emotional tone consistency. AudioStory has two appealing features: (1) Decoupled bridging mechanism: AudioStory disentangles LLM-diffuser collaboration into two specialized components, i.e., a bridging query for intra-event semantic alignment and a residual query for cross-event coherence preservation. (2) End-to-end training: By unifying instruction comprehension and audio generation within a single end-to-end framework, AudioStory eliminates the need for modular training pipelines while enhancing synergy between components. Furthermore, we establish a benchmark AudioStory-10K, encompassing diverse domains such as animated soundscapes and natural sound narratives. Extensive experiments show the superiority of AudioStory on both single-audio generation and narrative audio generation, surpassing prior TTA baselines in both instruction-following ability and audio fidelity. Our code is available at https://github.com/TencentARC/AudioStory

