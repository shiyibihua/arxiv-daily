---
layout: default
title: Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors
---

# Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.20089" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.20089v1</a>
  <a href="https://arxiv.org/pdf/2508.20089.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.20089v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.20089v1', 'Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ross J Gardiner, Guillaume Mougeot, Sareh Rowlands, Benno I Simmons, Flemming Helsing, Toke Thomas HÃ¸ye

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè½»é‡çº§åˆ†ç±»æ–¹æ³•ä»¥è§£å†³è›¾ç±»ç»†ç²’åº¦è¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è›¾ç±»è¯†åˆ«` `çŸ¥è¯†è’¸é¦` `è½»é‡çº§æ¨¡å‹` `é¢†åŸŸé€‚åº”` `ç”Ÿç‰©ç›‘æµ‹` `è®¡ç®—æœºè§†è§‰` `ç”Ÿæ€ä¿æŠ¤`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è›¾ç±»ç‰©ç§è¯†åˆ«ä¸­é¢ä¸´é¢†åŸŸè½¬ç§»é—®é¢˜ï¼Œå¯¼è‡´å‡†ç¡®æ€§ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºç»“åˆä¸“å®¶æ ‡æ³¨æ•°æ®ä¸BioCLIP2çŸ¥è¯†è’¸é¦çš„è½»é‡çº§åˆ†ç±»æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜è¯†åˆ«å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBioCLIP2æ¨¡å‹æ€§èƒ½ä¼˜è¶Šï¼Œè’¸é¦æ¨¡å‹åœ¨é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ä¿æŒäº†é«˜å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯¹è‡ªåŠ¨æ‘„åƒç³»ç»Ÿæ‹æ‘„çš„é³ç¿…ç›®ï¼ˆè›¾ç±»ï¼‰å›¾åƒè¿›è¡Œæ ‡æ³¨å¯¹äºç†è§£æ˜†è™«æ•°é‡ä¸‹é™è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç”±äºç²¾å¿ƒç­–åˆ’çš„å›¾åƒä¸å™ªå£°è¾ƒå¤§çš„ç°åœºå›¾åƒä¹‹é—´å­˜åœ¨é¢†åŸŸè½¬ç§»ï¼Œå‡†ç¡®çš„ç‰©ç§è¯†åˆ«é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§è½»é‡çº§åˆ†ç±»æ–¹æ³•ï¼Œç»“åˆæœ‰é™çš„ä¸“å®¶æ ‡æ³¨ç°åœºæ•°æ®ä¸é«˜æ€§èƒ½BioCLIP2åŸºç¡€æ¨¡å‹çš„çŸ¥è¯†è’¸é¦ï¼Œåº”ç”¨äºConvNeXt-tinyæ¶æ„ã€‚å¯¹æ¥è‡ªAMIæ‘„åƒç³»ç»Ÿçš„101ç§ä¸¹éº¦è›¾ç±»çš„å®éªŒè¡¨æ˜ï¼ŒBioCLIP2æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œè€Œæˆ‘ä»¬è’¸é¦çš„è½»é‡çº§æ¨¡å‹åœ¨è®¡ç®—æˆæœ¬æ˜¾è‘—é™ä½çš„æƒ…å†µä¸‹å®ç°äº†å¯æ¯”çš„å‡†ç¡®æ€§ã€‚è¿™äº›å‘ç°ä¸ºé«˜æ•ˆæ˜†è™«ç›‘æµ‹ç³»ç»Ÿçš„å¼€å‘å’Œç»†ç²’åº¦åˆ†ç±»çš„é¢†åŸŸé—´å·®è·å¼¥åˆæä¾›äº†å®ç”¨æŒ‡å¯¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è›¾ç±»ç‰©ç§è¯†åˆ«ä¸­çš„é¢†åŸŸè½¬ç§»é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å™ªå£°è¾ƒå¤§çš„ç°åœºå›¾åƒæ—¶å‡†ç¡®æ€§ä¸è¶³ï¼Œå¯¼è‡´ç‰©ç§è¯†åˆ«å›°éš¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§è½»é‡çº§çš„åˆ†ç±»æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆæœ‰é™çš„ä¸“å®¶æ ‡æ³¨æ•°æ®ä¸é«˜æ€§èƒ½çš„BioCLIP2åŸºç¡€æ¨¡å‹è¿›è¡ŒçŸ¥è¯†è’¸é¦ï¼Œæ—¨åœ¨æé«˜æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸå›¾åƒä¸Šçš„é€‚åº”èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€çŸ¥è¯†è’¸é¦å’Œæ¨¡å‹è®­ç»ƒä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ”¶é›†ä¸“å®¶æ ‡æ³¨çš„ç°åœºæ•°æ®ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨BioCLIP2æ¨¡å‹è¿›è¡ŒçŸ¥è¯†è’¸é¦ï¼›æœ€åï¼ŒåŸºäºConvNeXt-tinyæ¶æ„è¿›è¡Œæ¨¡å‹è®­ç»ƒä¸ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†çŸ¥è¯†è’¸é¦ä¸æœ‰é™çš„ä¸“å®¶æ ‡æ³¨æ•°æ®ç›¸ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°é¢–çš„è½»é‡çº§æ¨¡å‹ï¼Œæ˜¾è‘—æé«˜äº†åœ¨é¢†åŸŸè½¬ç§»æƒ…å†µä¸‹çš„åˆ†ç±»æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ConvNeXt-tinyæ¶æ„ï¼Œè®¾ç½®äº†é€‚å½“çš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–è’¸é¦è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†æ¨¡å‹åœ¨è®¡ç®—æ•ˆç‡å’Œå‡†ç¡®æ€§ä¸Šçš„å¹³è¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒBioCLIP2æ¨¡å‹åœ¨101ç§ä¸¹éº¦è›¾ç±»çš„è¯†åˆ«ä¸­æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œè’¸é¦åçš„è½»é‡çº§æ¨¡å‹åœ¨è®¡ç®—æˆæœ¬é™ä½çš„åŒæ—¶ï¼Œå‡†ç¡®æ€§ä¸BioCLIP2ç›¸å½“ï¼Œå±•ç¤ºäº†é«˜æ•ˆçš„åˆ†ç±»èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”Ÿæ€ç›‘æµ‹ã€å†œä¸šå®³è™«ç®¡ç†å’Œç”Ÿç‰©å¤šæ ·æ€§ä¿æŠ¤ç­‰ã€‚é€šè¿‡æé«˜è›¾ç±»ç‰©ç§çš„è¯†åˆ«å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿä¸ºæ˜†è™«æ•°é‡å˜åŒ–çš„ç ”ç©¶æä¾›é‡è¦æ•°æ®æ”¯æŒï¼Œè¿›è€Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç§‘å­¦ç ”ç©¶å’Œæ”¿ç­–åˆ¶å®šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Labelling images of Lepidoptera (moths) from automated camera systems is vital for understanding insect declines. However, accurate species identification is challenging due to domain shifts between curated images and noisy field imagery. We propose a lightweight classification approach, combining limited expert-labelled field data with knowledge distillation from the high-performance BioCLIP2 foundation model into a ConvNeXt-tiny architecture. Experiments on 101 Danish moth species from AMI camera systems demonstrate that BioCLIP2 substantially outperforms other methods and that our distilled lightweight model achieves comparable accuracy with significantly reduced computational cost. These insights offer practical guidelines for the development of efficient insect monitoring systems and bridging domain gaps for fine-grained classification.

