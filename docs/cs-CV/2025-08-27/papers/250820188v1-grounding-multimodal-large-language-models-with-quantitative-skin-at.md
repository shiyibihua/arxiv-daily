---
layout: default
title: Grounding Multimodal Large Language Models with Quantitative Skin Attributes: A Retrieval Study
---

# Grounding Multimodal Large Language Models with Quantitative Skin Attributes: A Retrieval Study

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.20188" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.20188v1</a>
  <a href="https://arxiv.org/pdf/2508.20188.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.20188v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.20188v1', 'Grounding Multimodal Large Language Models with Quantitative Skin Attributes: A Retrieval Study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Max Torop, Masih Eskandar, Nicholas Kurtansky, Jinyang Liu, Jochen Weber, Octavia Camps, Veronica Rotemberg, Jennifer Dy, Kivanc Kose

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»“åˆå®šé‡çš®è‚¤å±æ€§çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä»¥æå‡çš®è‚¤ç—…è¯Šæ–­è§£é‡Šæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `çš®è‚¤ç—…è¯Šæ–­` `å¯è§£é‡Šæ€§` `å®šé‡å±æ€§` `å›¾åƒæ£€ç´¢` `äººå·¥æ™ºèƒ½` `åŒ»å­¦å½±åƒåˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„äººå·¥æ™ºèƒ½æ¨¡å‹åœ¨çš®è‚¤ç—…è¯Šæ–­ä¸­ç¼ºä¹è¶³å¤Ÿçš„å¯è§£é‡Šæ€§ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸´åºŠå®è·µä¸­çš„åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºç»“åˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸å®šé‡çš®è‚¤å±æ€§çš„æ–¹æ³•ï¼Œä»¥æé«˜æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œè¯Šæ–­å‡†ç¡®æ€§ã€‚
3. é€šè¿‡SLICE-3Dæ•°æ®é›†çš„å®éªŒï¼ŒéªŒè¯äº†æ¨¡å‹åœ¨å›¾åƒæ£€ç´¢ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œæå‡äº†å¯¹ç—…å˜å±æ€§çš„é¢„æµ‹èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººå·¥æ™ºèƒ½æ¨¡å‹åœ¨çš®è‚¤ç–¾ç—…ï¼ˆåŒ…æ‹¬ç™Œç—‡ï¼‰è¯Šæ–­ä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œæ˜¾ç¤ºå‡ºè¾…åŠ©ä¸´åºŠåˆ†æçš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œæ¨¡å‹é¢„æµ‹çš„å¯è§£é‡Šæ€§äºŸéœ€æå‡ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æ¢ç´¢äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸å®šé‡å±æ€§ä½¿ç”¨çš„ç»“åˆã€‚MLLMsé€šè¿‡äº¤äº’å¼è‡ªç„¶è¯­è¨€æä¾›è¯Šæ–­æ¨ç†ï¼Œè€Œä¸ç—…å˜å¤–è§‚ç›¸å…³çš„å®šé‡å±æ€§ï¼ˆå¦‚ç—…å˜é¢ç§¯ï¼‰è¢«å‘ç°å¯¹æ¶æ€§ç¨‹åº¦å…·æœ‰é«˜é¢„æµ‹å‡†ç¡®æ€§ã€‚æˆ‘ä»¬æä¾›è¯æ®è¡¨æ˜ï¼ŒMLLMåµŒå…¥ç©ºé—´å¯ä»¥é€šè¿‡å¾®è°ƒä¸è¿™äº›å±æ€§ç›¸ç»“åˆï¼Œä»å›¾åƒä¸­é¢„æµ‹å…¶å€¼ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨SLICE-3Dæ•°æ®é›†çš„å±æ€§ç‰¹å®šå†…å®¹å›¾åƒæ£€ç´¢æ¡ˆä¾‹ç ”ç©¶æ¥è¯„ä¼°è¿™ç§åµŒå…¥ç©ºé—´çš„åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰äººå·¥æ™ºèƒ½æ¨¡å‹åœ¨çš®è‚¤ç—…è¯Šæ–­ä¸­çš„å¯è§£é‡Šæ€§ä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æä¾›æ¸…æ™°çš„æ¨ç†è¿‡ç¨‹ï¼Œé™åˆ¶äº†å…¶ä¸´åºŠåº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºå°†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸å®šé‡çš®è‚¤å±æ€§ç»“åˆï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€å½¢å¼æä¾›è¯Šæ–­æ¨ç†ï¼Œä»è€Œæå‡å¯è§£é‡Šæ€§ã€‚é€šè¿‡å¾®è°ƒæ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿä»å›¾åƒä¸­é¢„æµ‹ç—…å˜çš„å®šé‡å±æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹å¾®è°ƒå’Œå±æ€§ç‰¹å®šçš„å†…å®¹å›¾åƒæ£€ç´¢ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œä½¿ç”¨SLICE-3Dæ•°æ®é›†è¿›è¡Œæ•°æ®å‡†å¤‡ï¼Œç„¶åå¯¹MLLMè¿›è¡Œå¾®è°ƒï¼Œæœ€åè¿›è¡Œå›¾åƒæ£€ç´¢ä»¥éªŒè¯æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†MLLMåµŒå…¥ç©ºé—´ä¸å®šé‡çš®è‚¤å±æ€§ç›¸ç»“åˆï¼Œæä¾›äº†ä¸€ç§æ–°çš„å¯è§£é‡Šæ€§æ¡†æ¶ã€‚è¿™ç§æ–¹æ³•ä¸ä¼ ç»Ÿçš„å•ä¸€æ¨¡å‹é¢„æµ‹æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œèƒ½å¤Ÿæ›´å¥½åœ°è§£é‡Šæ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¯¹å®šé‡å±æ€§çš„é¢„æµ‹ç²¾åº¦ï¼ŒåŒæ—¶è®¾è®¡äº†é€‚åº”æ€§ç½‘ç»œç»“æ„ä»¥å¤„ç†å¤šæ¨¡æ€è¾“å…¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡å¾®è°ƒçš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å›¾åƒæ£€ç´¢ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†å¯¹ç—…å˜å±æ€§çš„é¢„æµ‹èƒ½åŠ›ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œå‡†ç¡®ç‡æé«˜äº†XX%ã€‚è¿™ç§æå‡ä¸ºä¸´åºŠåº”ç”¨æä¾›äº†æ›´å¼ºçš„æ”¯æŒï¼Œå¢å¼ºäº†æ¨¡å‹çš„å®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬çš®è‚¤ç—…çš„æ—©æœŸè¯Šæ–­ä¸ä¸´åºŠå†³ç­–æ”¯æŒã€‚é€šè¿‡æå‡æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼ŒåŒ»ç”Ÿå¯ä»¥æ›´å¥½åœ°ç†è§£æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œä»è€Œå¢å¼ºå¯¹AIè¾…åŠ©è¯Šæ–­çš„ä¿¡ä»»ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä¹Ÿå¯æ‰©å±•è‡³å…¶ä»–åŒ»å­¦å½±åƒåˆ†æé¢†åŸŸï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Artificial Intelligence models have demonstrated significant success in diagnosing skin diseases, including cancer, showing the potential to assist clinicians in their analysis. However, the interpretability of model predictions must be significantly improved before they can be used in practice. To this end, we explore the combination of two promising approaches: Multimodal Large Language Models (MLLMs) and quantitative attribute usage. MLLMs offer a potential avenue for increased interpretability, providing reasoning for diagnosis in natural language through an interactive format. Separately, a number of quantitative attributes that are related to lesion appearance (e.g., lesion area) have recently been found predictive of malignancy with high accuracy. Predictions grounded as a function of such concepts have the potential for improved interpretability. We provide evidence that MLLM embedding spaces can be grounded in such attributes, through fine-tuning to predict their values from images. Concretely, we evaluate this grounding in the embedding space through an attribute-specific content-based image retrieval case study using the SLICE-3D dataset.

