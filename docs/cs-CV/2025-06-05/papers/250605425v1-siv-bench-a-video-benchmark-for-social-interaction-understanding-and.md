---
layout: default
title: SIV-Bench: A Video Benchmark for Social Interaction Understanding and Reasoning
---

# SIV-Bench: A Video Benchmark for Social Interaction Understanding and Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05425" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05425v1</a>
  <a href="https://arxiv.org/pdf/2506.05425.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05425v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05425v1', 'SIV-Bench: A Video Benchmark for Social Interaction Understanding and Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fanqi Kong, Weiqin Zu, Xinyu Chen, Yaodong Yang, Song-Chun Zhu, Xue Feng

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://kfq20.github.io/sivbench/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSIV-Benchä»¥è§£å†³ç¤¾äº¤äº’åŠ¨ç†è§£ä¸æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¤¾äº¤äº’åŠ¨ç†è§£` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è§†é¢‘åŸºå‡†` `ç¤¾äº¤çŠ¶æ€æ¨ç†` `å…³ç³»æ¨ç†` `åŠ¨æ€é¢„æµ‹` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç†è§£å’Œæ¨ç†ç¤¾äº¤äº’åŠ¨æ—¶é¢ä¸´å¤šæ¨¡æ€çº¿ç´¢å’ŒåŠ¨æ€è¡Œä¸ºçš„å¤æ‚æ€§ï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºSIV-BenchåŸºå‡†ï¼Œé€šè¿‡2792ä¸ªè§†é¢‘å’Œ8792ä¸ªé—®ç­”å¯¹ï¼Œç³»ç»Ÿè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç¤¾äº¤ç†è§£å’Œæ¨ç†ä¸­çš„èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡æ¨¡å‹åœ¨ç¤¾äº¤åœºæ™¯ç†è§£ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ç¤¾äº¤çŠ¶æ€æ¨ç†å’ŒåŠ¨æ€é¢„æµ‹ä¸Šå­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå°¤å…¶åœ¨å…³ç³»æ¨ç†æ–¹é¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»ç¤¾äº¤äº’åŠ¨çš„ä¸°å¯Œå¤šæ ·æ€§ï¼ŒåŒ…æ‹¬å¤šæ¨¡æ€çº¿ç´¢ã€ä¸å¯è§‚å¯Ÿçš„å…³ç³»å’Œå¿ƒç†çŠ¶æ€ï¼Œä»¥åŠåŠ¨æ€è¡Œä¸ºï¼Œä¸ºäººå·¥æ™ºèƒ½å¸¦æ¥äº†å·¨å¤§çš„æŒ‘æˆ˜ã€‚ä¸ºæ¨åŠ¨è¯¥é¢†åŸŸçš„ç ”ç©¶ï¼Œæˆ‘ä»¬æå‡ºäº†SIV-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„è§†é¢‘åŸºå‡†ï¼Œç”¨äºä¸¥æ ¼è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨ç¤¾äº¤åœºæ™¯ç†è§£ï¼ˆSSUï¼‰ã€ç¤¾äº¤çŠ¶æ€æ¨ç†ï¼ˆSSRï¼‰å’Œç¤¾äº¤åŠ¨æ€é¢„æµ‹ï¼ˆSDPï¼‰æ–¹é¢çš„èƒ½åŠ›ã€‚SIV-BenchåŒ…å«2792ä¸ªè§†é¢‘ç‰‡æ®µå’Œ8792å¯¹ç²¾å¿ƒç”Ÿæˆçš„é—®é¢˜-ç­”æ¡ˆå¯¹ï¼Œæ•°æ®æ¥æºäºäººç±»ä¸LLMçš„åä½œæµç¨‹ï¼Œæ¶µç›–äº†TikTokå’ŒYouTubeä¸Šçš„å¤šç§è§†é¢‘ç±»å‹å’Œæ–‡åŒ–èƒŒæ™¯ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œå°½ç®¡æ¨¡å‹åœ¨SSUæ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨SSRå’ŒSDPæ–¹é¢å­˜åœ¨æ˜¾è‘—å›°éš¾ï¼Œå…³ç³»æ¨ç†ï¼ˆRIï¼‰æ˜¯ä¸€ä¸ªæ˜æ˜¾çš„ç“¶é¢ˆã€‚ç ”ç©¶è¿˜ç¡®è®¤äº†è½¬å½•å¯¹è¯åœ¨ç†è§£å¤æ‚ç¤¾äº¤äº’åŠ¨ä¸­çš„å…³é”®ä½œç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç¤¾äº¤äº’åŠ¨ç†è§£ä¸æ¨ç†çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šæ¨¡æ€çº¿ç´¢å’ŒåŠ¨æ€è¡Œä¸ºæ—¶è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨å…³ç³»æ¨ç†æ–¹é¢å­˜åœ¨æ˜æ˜¾ç“¶é¢ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºSIV-BenchåŸºå‡†ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç¤¾äº¤åœºæ™¯ç†è§£ã€ç¤¾äº¤çŠ¶æ€æ¨ç†å’Œç¤¾äº¤åŠ¨æ€é¢„æµ‹ä¸­çš„èƒ½åŠ›ï¼Œæ—¨åœ¨è¯†åˆ«æ¨¡å‹çš„ä¼˜åŠ¿ä¸ä¸è¶³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSIV-Benchçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è§†é¢‘æ•°æ®æ”¶é›†ã€é—®é¢˜ç”Ÿæˆå’Œç­”æ¡ˆå¯¹çš„æ„å»ºï¼Œæ¶µç›–å¤šç§è§†é¢‘ç±»å‹å’Œæ–‡åŒ–èƒŒæ™¯ï¼Œå¹¶è®¾ç½®ä¸åŒçš„æ–‡æœ¬çº¿ç´¢åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šSIV-Benchçš„åˆ›æ–°ç‚¹åœ¨äºå…¶ç»¼åˆæ€§çš„æ•°æ®é›†å’Œè¯„ä¼°æ¡†æ¶ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡äººç±»ä¸LLMçš„åä½œç”Ÿæˆé—®é¢˜-ç­”æ¡ˆå¯¹ï¼Œæä¾›äº†æ›´ä¸ºçœŸå®çš„ç¤¾äº¤äº’åŠ¨åœºæ™¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œé‡‡ç”¨äº†å¤šæ ·åŒ–çš„è§†é¢‘æ¥æºå’Œé—®ç­”ç”Ÿæˆç­–ç•¥ï¼ŒåŒæ—¶å…³æ³¨æ–‡æœ¬çº¿ç´¢çš„å½±å“ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚å®éªŒä¸­è¿˜åˆ†æäº†è½¬å½•å¯¹è¯å¯¹ç†è§£å¤æ‚ç¤¾äº¤äº’åŠ¨çš„å¸®åŠ©ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç¤¾äº¤åœºæ™¯ç†è§£ï¼ˆSSUï¼‰æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ç¤¾äº¤çŠ¶æ€æ¨ç†ï¼ˆSSRï¼‰å’Œç¤¾äº¤åŠ¨æ€é¢„æµ‹ï¼ˆSDPï¼‰æ–¹é¢çš„è¡¨ç°æ˜¾è‘—ä¸è¶³ï¼Œå°¤å…¶åœ¨å…³ç³»æ¨ç†ï¼ˆRIï¼‰ä¸Šå­˜åœ¨æ˜æ˜¾ç“¶é¢ˆã€‚æ¨¡å‹åœ¨SSUä»»åŠ¡ä¸­çš„å‡†ç¡®ç‡é«˜è¾¾XX%ï¼Œè€Œåœ¨SSRå’ŒSDPä»»åŠ¡ä¸­åˆ™ä¸‹é™è‡³YY%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤æœºå™¨äººã€æ™ºèƒ½å®¢æœå’Œäººæœºäº¤äº’ç­‰ï¼Œèƒ½å¤Ÿæå‡äººå·¥æ™ºèƒ½åœ¨ç†è§£å’Œæ¨ç†äººç±»ç¤¾äº¤è¡Œä¸ºæ–¹é¢çš„èƒ½åŠ›ï¼Œæ¨åŠ¨æ›´æ™ºèƒ½çš„ç¤¾äº¤AIç³»ç»Ÿçš„å‘å±•ã€‚æœªæ¥ï¼ŒSIV-Benchå¯èƒ½æˆä¸ºç¤¾äº¤æ™ºèƒ½AIç ”ç©¶çš„é‡è¦åŸºå‡†ï¼Œä¿ƒè¿›ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rich and multifaceted nature of human social interaction, encompassing multimodal cues, unobservable relations and mental states, and dynamical behavior, presents a formidable challenge for artificial intelligence. To advance research in this area, we introduce SIV-Bench, a novel video benchmark for rigorously evaluating the capabilities of Multimodal Large Language Models (MLLMs) across Social Scene Understanding (SSU), Social State Reasoning (SSR), and Social Dynamics Prediction (SDP). SIV-Bench features 2,792 video clips and 8,792 meticulously generated question-answer pairs derived from a human-LLM collaborative pipeline. It is originally collected from TikTok and YouTube, covering a wide range of video genres, presentation styles, and linguistic and cultural backgrounds. It also includes a dedicated setup for analyzing the impact of different textual cues-original on-screen text, added dialogue, or no text. Our comprehensive experiments on leading MLLMs reveal that while models adeptly handle SSU, they significantly struggle with SSR and SDP, where Relation Inference (RI) is an acute bottleneck, as further examined in our analysis. Our study also confirms the critical role of transcribed dialogue in aiding comprehension of complex social interactions. By systematically identifying current MLLMs' strengths and limitations, SIV-Bench offers crucial insights to steer the development of more socially intelligent AI. The dataset and code are available at https://kfq20.github.io/sivbench/.

