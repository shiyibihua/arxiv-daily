---
layout: default
title: AV-Reasoner: Improving and Benchmarking Clue-Grounded Audio-Visual Counting for MLLMs
---

# AV-Reasoner: Improving and Benchmarking Clue-Grounded Audio-Visual Counting for MLLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05328" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05328v2</a>
  <a href="https://arxiv.org/pdf/2506.05328.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05328v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05328v2', 'AV-Reasoner: Improving and Benchmarking Clue-Grounded Audio-Visual Counting for MLLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lidong Lu, Guo Chen, Zhiqi Li, Yicheng Liu, Tong Lu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05 (æ›´æ–°: 2025-07-22)

**å¤‡æ³¨**: 21 pages, 11 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCG-AV-CountingåŸºå‡†ä¸AV-Reasoneræ¨¡å‹ä»¥æå‡å¤šæ¨¡æ€è®¡æ•°èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿è§†é¢‘ç†è§£` `å¤šæ¨¡æ€è®¡æ•°` `çº¿ç´¢é©±åŠ¨` `å¼ºåŒ–å­¦ä¹ ` `æ¨¡å‹æ³›åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨è®¡æ•°ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œå—é™äºçŸ­è§†é¢‘å’Œç¼ºä¹çº¿ç´¢æ³¨é‡Šç­‰é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºCG-AV-CountingåŸºå‡†å’ŒAV-Reasoneræ¨¡å‹ï¼Œé€šè¿‡æ‰‹åŠ¨æ³¨é‡Šå’Œå¼ºåŒ–å­¦ä¹ æå‡è®¡æ•°èƒ½åŠ›ã€‚
3. AV-Reasoneråœ¨å¤šä¸ªåŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œä½†åœ¨åŸŸå¤–åŸºå‡†ä¸Šæ¨ç†èƒ½åŠ›æœªèƒ½æå‡æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡è§†é¢‘ç†è§£å–å¾—äº†è¿›å±•ï¼Œç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è®¡æ•°ä»»åŠ¡ä¸Šä»ç„¶å­˜åœ¨å›°éš¾ã€‚ç°æœ‰åŸºå‡†å—é™äºçŸ­è§†é¢‘ã€å°é—­å¼æŸ¥è¯¢ã€ç¼ºä¹çº¿ç´¢æ³¨é‡Šå’Œå¤šæ¨¡æ€è¦†ç›–ä¸è¶³ã€‚æœ¬æ–‡æå‡ºCG-AV-Countingï¼Œè¿™æ˜¯ä¸€ä¸ªæ‰‹åŠ¨æ³¨é‡Šçš„çº¿ç´¢é©±åŠ¨è®¡æ•°åŸºå‡†ï¼ŒåŒ…å«1,027ä¸ªå¤šæ¨¡æ€é—®é¢˜å’Œ5,845ä¸ªæ³¨é‡Šçº¿ç´¢ï¼Œè¦†ç›–497ä¸ªé•¿è§†é¢‘ã€‚è¯¥åŸºå‡†æ”¯æŒé»‘ç®±å’Œç™½ç®±è¯„ä¼°ï¼Œä¸ºç«¯åˆ°ç«¯å’ŒåŸºäºæ¨ç†çš„è®¡æ•°æä¾›äº†å…¨é¢çš„æµ‹è¯•å¹³å°ã€‚ä¸ºæå‡æ¨¡å‹çš„è®¡æ•°èƒ½åŠ›ï¼Œæˆ‘ä»¬æå‡ºäº†AV-Reasoneræ¨¡å‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡GRPOå’Œè¯¾ç¨‹å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œä»¥ä»ç›¸å…³ä»»åŠ¡ä¸­æ³›åŒ–è®¡æ•°èƒ½åŠ›ã€‚AV-Reasoneråœ¨å¤šä¸ªåŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå±•ç¤ºäº†å¼ºåŒ–å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚ç„¶è€Œï¼Œå®éªŒè¡¨æ˜ï¼Œåœ¨åŸŸå¤–åŸºå‡†ä¸Šï¼Œè¯­è¨€ç©ºé—´çš„æ¨ç†æœªèƒ½å¸¦æ¥æ€§èƒ½æå‡ã€‚ä»£ç å’ŒåŸºå‡†å·²å‘å¸ƒåœ¨https://av-reasoner.github.ioã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨è®¡æ•°ä»»åŠ¡ä¸­çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯çŸ­è§†é¢‘å’Œç¼ºä¹çº¿ç´¢æ³¨é‡Šçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚è®¡æ•°ä»»åŠ¡æ—¶è¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†å…¶åº”ç”¨åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºCG-AV-CountingåŸºå‡†ï¼Œé€šè¿‡æ‰‹åŠ¨æ³¨é‡Šçš„çº¿ç´¢é©±åŠ¨è®¡æ•°ä»»åŠ¡ï¼Œç»“åˆAV-Reasoneræ¨¡å‹ï¼Œåˆ©ç”¨GRPOå’Œè¯¾ç¨‹å­¦ä¹ æ¥æå‡æ¨¡å‹çš„è®¡æ•°èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨é€šè¿‡ç›¸å…³ä»»åŠ¡çš„æ³›åŒ–æ¥å¢å¼ºæ¨¡å‹çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAV-Reasoneræ¨¡å‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚æ•°æ®é¢„å¤„ç†é˜¶æ®µè´Ÿè´£ç”Ÿæˆå¤šæ¨¡æ€é—®é¢˜å’Œçº¿ç´¢ï¼Œæ¨¡å‹è®­ç»ƒé˜¶æ®µåˆ©ç”¨å¼ºåŒ–å­¦ä¹ è¿›è¡Œä¼˜åŒ–ï¼Œè¯„ä¼°é˜¶æ®µåˆ™é€šè¿‡é»‘ç®±å’Œç™½ç®±æ–¹æ³•è¿›è¡Œæ€§èƒ½æµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†CG-AV-CountingåŸºå‡†å’ŒAV-Reasoneræ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡çº¿ç´¢é©±åŠ¨çš„æ–¹å¼æ¥å¢å¼ºè®¡æ•°èƒ½åŠ›ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„ç›´æ¥è®¡æ•°æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†GRPOï¼ˆGradient Reinforcement Policy Optimizationï¼‰ä½œä¸ºè®­ç»ƒç­–ç•¥ï¼Œå¹¶ç»“åˆè¯¾ç¨‹å­¦ä¹ æ–¹æ³•ï¼Œä»¥é€æ­¥æå‡æ¨¡å‹çš„è®¡æ•°èƒ½åŠ›ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†å¤šæ¨¡æ€ä¿¡æ¯çš„èåˆï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†ä¸åŒæ¨¡æ€çš„æ•°æ®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

AV-Reasoneråœ¨å¤šä¸ªåŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå±•ç¤ºäº†å¼ºåŒ–å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚åœ¨ç‰¹å®šåŸºå‡†ä¸Šï¼Œæ¨¡å‹çš„æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°XX%ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ç„¶è€Œï¼Œåœ¨åŸŸå¤–åŸºå‡†ä¸Šï¼Œæ¨ç†èƒ½åŠ›æœªèƒ½å¸¦æ¥é¢„æœŸçš„æ€§èƒ½æå‡ï¼Œè¡¨æ˜ä»éœ€è¿›ä¸€æ­¥ç ”ç©¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è§†é¢‘ç›‘æ§ã€æ™ºèƒ½äº¤é€šã€ç¤¾äº¤åª’ä½“å†…å®¹åˆ†æç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€è®¡æ•°èƒ½åŠ›ï¼ŒAV-Reasoneræ¨¡å‹èƒ½å¤Ÿåœ¨å¤æ‚åœºæ™¯ä¸­æä¾›æ›´å‡†ç¡®çš„è®¡æ•°ç»“æœï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite progress in video understanding, current MLLMs struggle with counting tasks. Existing benchmarks are limited by short videos, close-set queries, lack of clue annotations, and weak multimodal coverage. In this paper, we introduce CG-AV-Counting, a manually-annotated clue-grounded counting benchmark with 1,027 multimodal questions and 5,845 annotated clues over 497 long videos. It supports both black-box and white-box evaluation, serving as a comprehensive testbed for both end-to-end and reasoning-based counting. To explore ways to improve model's counting capability, we propose AV-Reasoner, a model trained with GRPO and curriculum learning to generalize counting ability from related tasks. AV-Reasoner achieves state-of-the-art results across multiple benchmarks, demonstrating the effectiveness of reinforcement learning. However, experiments show that on out-of-domain benchmarks, reasoning in the language space fails to bring performance gains. The code and benchmark have been released on https://av-reasoner.github.io.

