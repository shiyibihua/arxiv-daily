---
layout: default
title: EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh
---

# EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05554" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05554v1</a>
  <a href="https://arxiv.org/pdf/2506.05554.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05554v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05554v1', 'EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tao Hu, Haoyang Peng, Xiao Liu, Yuewen Ma

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEX-4Dä»¥è§£å†³æç«¯è§†è§’è§†é¢‘åˆæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `è§†é¢‘åˆæˆ` `æ·±åº¦å­¦ä¹ ` `å‡ ä½•ä¸€è‡´æ€§` `é®æŒ¡å¤„ç†` `è™šæ‹Ÿç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æç«¯è§†è§’ä¸‹ç”Ÿæˆé«˜è´¨é‡è§†é¢‘æ—¶ï¼Œå¸¸é¢ä¸´å‡ ä½•ä¸ä¸€è‡´å’Œé®æŒ¡ä¼ªå½±çš„é—®é¢˜ï¼Œå½±å“è§†è§‰æ•ˆæœã€‚
2. EX-4Dæ¡†æ¶é€šè¿‡æ·±åº¦æ°´å¯†ç½‘æ ¼è¡¨ç¤ºï¼Œæ˜¾å¼å»ºæ¨¡å¯è§ä¸é®æŒ¡åŒºåŸŸï¼Œç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•çš„ä¸è¶³ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEX-4Dåœ¨ç‰©ç†ä¸€è‡´æ€§å’Œæç«¯è§†è§’è´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæå‡äº†è§†é¢‘ç”Ÿæˆçš„å®ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”Ÿæˆé«˜è´¨é‡çš„å¯æ§è§†é¢‘ä»å•ç›®è¾“å…¥æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨æç«¯è§†è§’ä¸‹ã€‚ç°æœ‰æ–¹æ³•å¸¸å¸¸åœ¨å‡ ä½•ä¸€è‡´æ€§å’Œè¾¹ç•Œé®æŒ¡ä¼ªå½±æ–¹é¢å­˜åœ¨é—®é¢˜ï¼Œå¯¼è‡´è§†è§‰è´¨é‡ä¸‹é™ã€‚æœ¬æ–‡æå‡ºäº†EX-4Dï¼Œä¸€ä¸ªé€šè¿‡æ·±åº¦æ°´å¯†ç½‘æ ¼è¡¨ç¤ºæ¥è§£å†³è¿™äº›æŒ‘æˆ˜çš„æ–°æ¡†æ¶ã€‚è¯¥è¡¨ç¤ºé€šè¿‡æ˜¾å¼å»ºæ¨¡å¯è§å’Œé®æŒ¡åŒºåŸŸï¼Œç¡®ä¿åœ¨æç«¯ç›¸æœºå§¿æ€ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚ä¸ºå…‹æœç¼ºä¹é…å¯¹å¤šè§†è§’æ•°æ®é›†çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¨¡æ‹Ÿé®æŒ¡ç­–ç•¥ï¼Œä»…ä»å•ç›®è§†é¢‘ç”Ÿæˆæœ‰æ•ˆçš„è®­ç»ƒæ•°æ®ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨è½»é‡çº§çš„åŸºäºLoRAçš„è§†é¢‘æ‰©æ•£é€‚é…å™¨åˆæˆé«˜è´¨é‡ã€ç‰©ç†ä¸€è‡´ä¸”æ—¶é—´è¿è´¯çš„è§†é¢‘ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒEX-4Dåœ¨ç‰©ç†ä¸€è‡´æ€§å’Œæç«¯è§†è§’è´¨é‡æ–¹é¢è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿå®ç°å®ç”¨çš„4Dè§†é¢‘ç”Ÿæˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»å•ç›®è¾“å…¥ç”Ÿæˆé«˜è´¨é‡å¯æ§è§†é¢‘æ—¶åœ¨æç«¯è§†è§’ä¸‹çš„å‡ ä½•ä¸ä¸€è‡´å’Œé®æŒ¡ä¼ªå½±é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™äº›æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´è§†è§‰è´¨é‡ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEX-4Dæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯é‡‡ç”¨æ·±åº¦æ°´å¯†ç½‘æ ¼è¡¨ç¤ºï¼Œæ˜¾å¼å»ºæ¨¡å¯è§å’Œé®æŒ¡åŒºåŸŸï¼Œä»¥ç¡®ä¿åœ¨æç«¯ç›¸æœºå§¿æ€ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†é®æŒ¡å’Œå‡ ä½•å¤±çœŸé—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEX-4Dçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ·±åº¦æ°´å¯†ç½‘æ ¼çš„æ„å»ºã€æ¨¡æ‹Ÿé®æŒ¡ç­–ç•¥ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œä»¥åŠåŸºäºLoRAçš„è§†é¢‘æ‰©æ•£é€‚é…å™¨ã€‚è¯¥æ¡†æ¶é€šè¿‡è¿™äº›æ¨¡å—ååŒå·¥ä½œï¼Œå®ç°é«˜è´¨é‡è§†é¢‘çš„åˆæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæ·±åº¦æ°´å¯†ç½‘æ ¼çš„ä½¿ç”¨ï¼Œå®ƒæä¾›äº†ä¸€ç§å¼ºå¥çš„å‡ ä½•å…ˆéªŒï¼Œæ˜¾è‘—æå‡äº†åœ¨æç«¯è§†è§’ä¸‹çš„åˆæˆè´¨é‡ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„åŸºäºå›¾åƒçš„åˆæˆæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†æ¨¡æ‹Ÿé®æŒ¡ç­–ç•¥æ¥ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œé¿å…äº†å¯¹é…å¯¹å¤šè§†è§’æ•°æ®é›†çš„ä¾èµ–ã€‚åŒæ—¶ï¼ŒLoRAé€‚é…å™¨çš„è½»é‡åŒ–è®¾è®¡ä½¿å¾—è§†é¢‘åˆæˆè¿‡ç¨‹æ›´åŠ é«˜æ•ˆï¼Œç¡®ä¿äº†ç‰©ç†ä¸€è‡´æ€§å’Œæ—¶é—´è¿è´¯æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒEX-4Dåœ¨ç‰©ç†ä¸€è‡´æ€§å’Œæç«¯è§†è§’è´¨é‡æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¶…è¿‡20%ã€‚è¿™ä¸€æˆæœä¸º4Dè§†é¢‘ç”Ÿæˆæä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ï¼Œå…·æœ‰é‡è¦çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EX-4Dçš„ç ”ç©¶æˆæœåœ¨è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®å’Œå½±è§†åˆ¶ä½œç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡ç”Ÿæˆé«˜è´¨é‡çš„4Dè§†é¢‘ï¼Œè¯¥æŠ€æœ¯å¯ä»¥æå‡ç”¨æˆ·ä½“éªŒï¼Œæ¨åŠ¨å†…å®¹åˆ›ä½œçš„åˆ›æ–°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generating high-quality camera-controllable videos from monocular input is a challenging task, particularly under extreme viewpoint. Existing methods often struggle with geometric inconsistencies and occlusion artifacts in boundaries, leading to degraded visual quality. In this paper, we introduce EX-4D, a novel framework that addresses these challenges through a Depth Watertight Mesh representation. The representation serves as a robust geometric prior by explicitly modeling both visible and occluded regions, ensuring geometric consistency in extreme camera pose. To overcome the lack of paired multi-view datasets, we propose a simulated masking strategy that generates effective training data only from monocular videos. Additionally, a lightweight LoRA-based video diffusion adapter is employed to synthesize high-quality, physically consistent, and temporally coherent videos. Extensive experiments demonstrate that EX-4D outperforms state-of-the-art methods in terms of physical consistency and extreme-view quality, enabling practical 4D video generation.

