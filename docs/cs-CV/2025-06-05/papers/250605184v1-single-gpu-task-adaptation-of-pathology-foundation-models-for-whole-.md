---
layout: default
title: Single GPU Task Adaptation of Pathology Foundation Models for Whole Slide Image Analysis
---

# Single GPU Task Adaptation of Pathology Foundation Models for Whole Slide Image Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05184" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05184v1</a>
  <a href="https://arxiv.org/pdf/2506.05184.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05184v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05184v1', 'Single GPU Task Adaptation of Pathology Foundation Models for Whole Slide Image Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Neeraj Kumar, Swaraj Nanda, Siddharth Singi, Jamal Benhamida, David Kim, Jie-Fu Chen, Amir Momeni-Boroujeni, Gregory M. Goldgof, Gabriele Campanella, Chad Vanderbilt

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTAPFMä»¥è§£å†³ç—…ç†åŸºç¡€æ¨¡å‹åœ¨å…¨åˆ‡ç‰‡å›¾åƒåˆ†æä¸­çš„é€‚åº”æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç—…ç†åŸºç¡€æ¨¡å‹` `å…¨åˆ‡ç‰‡å›¾åƒ` `å¤šå®ä¾‹å­¦ä¹ ` `è§†è§‰å˜æ¢å™¨` `ä¸´åºŠåº”ç”¨` `çªå˜é¢„æµ‹` `å¤šæ ‡ç­¾åˆ†ç±»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å°†é¢„è®­ç»ƒçš„ç—…ç†åŸºç¡€æ¨¡å‹é€‚åº”äºç‰¹å®šä¸´åºŠä»»åŠ¡æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯ç¼ºä¹è¶³å¤Ÿçš„æ ‡ç­¾ä¿¡æ¯ã€‚
2. è®ºæ–‡æå‡ºçš„TAPFMæ–¹æ³•åˆ©ç”¨è§†è§‰å˜æ¢å™¨çš„æ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œå¤šå®ä¾‹å­¦ä¹ èšåˆï¼Œä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºå’Œæ³¨æ„åŠ›æƒé‡ã€‚
3. åœ¨è†€èƒ±ç™Œå’Œè‚ºè…ºç™Œçš„çªå˜é¢„æµ‹ä»»åŠ¡ä¸­ï¼ŒTAPFMè¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç—…ç†åŸºç¡€æ¨¡å‹ï¼ˆPFMsï¼‰å·²æˆä¸ºåˆ†æå…¨åˆ‡ç‰‡å›¾åƒï¼ˆWSIsï¼‰çš„å¼ºå¤§å·¥å…·ã€‚ç„¶è€Œï¼Œå°†è¿™äº›é¢„è®­ç»ƒçš„PFMsé€‚åº”äºç‰¹å®šä¸´åºŠä»»åŠ¡é¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œä¸»è¦æ˜¯ç”±äºä»…æœ‰çš„å¼±æ ‡ç­¾ï¼ˆWSIçº§åˆ«ï¼‰å¯¹äºåƒå…†åƒç´ å›¾åƒçš„é™åˆ¶ï¼Œ necessitating multiple instance learning (MIL)èŒƒå¼ä»¥æœ‰æ•ˆè¿›è¡ŒWSIåˆ†æã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å•GPUä»»åŠ¡é€‚åº”PFMsçš„æ–¹æ³•ï¼ˆTAPFMï¼‰ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨è§†è§‰å˜æ¢å™¨ï¼ˆViTï¼‰æ³¨æ„åŠ›è¿›è¡ŒMILèšåˆï¼ŒåŒæ—¶ä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºå’Œæ³¨æ„åŠ›æƒé‡ã€‚æ‰€æå‡ºçš„æ–¹æ³•ä¸ºMILèšåˆå™¨å’ŒPFMç»´æŠ¤ç‹¬ç«‹çš„è®¡ç®—å›¾ï¼Œä»¥åˆ›å»ºç¨³å®šçš„è®­ç»ƒåŠ¨æ€ï¼Œä¸ä¸‹æ¸¸ä»»åŠ¡ç›®æ ‡å¯¹é½ã€‚é€šè¿‡åœ¨è†€èƒ±ç™Œå’Œè‚ºè…ºç™Œçš„çªå˜é¢„æµ‹ä»»åŠ¡ä¸Šè¿›è¡Œè¯„ä¼°ï¼ŒTAPFMå§‹ç»ˆä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼ŒH-Optimus-0ï¼ˆTAPFMï¼‰è¶…è¶Šäº†åŸºå‡†ã€‚TAPFMè¿˜æœ‰æ•ˆå¤„ç†å¯æ“ä½œçªå˜çš„å¤šæ ‡ç­¾åˆ†ç±»ã€‚å› æ­¤ï¼ŒTAPFMä½¿å¾—åœ¨æ ‡å‡†ç¡¬ä»¶ä¸Šå¯¹å¼ºå¤§çš„é¢„è®­ç»ƒPFMsè¿›è¡Œé€‚åº”æˆä¸ºå¯èƒ½ï¼Œé€‚ç”¨äºå„ç§ä¸´åºŠåº”ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•æœ‰æ•ˆåœ°å°†é¢„è®­ç»ƒçš„ç—…ç†åŸºç¡€æ¨¡å‹ï¼ˆPFMsï¼‰é€‚åº”äºç‰¹å®šçš„ä¸´åºŠä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨ä»…æœ‰WSIçº§åˆ«çš„å¼±æ ‡ç­¾æƒ…å†µä¸‹ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†åƒå…†åƒç´ å›¾åƒæ—¶è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„TAPFMæ–¹æ³•é€šè¿‡ä½¿ç”¨è§†è§‰å˜æ¢å™¨ï¼ˆViTï¼‰æ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œå¤šå®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰èšåˆï¼Œä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºå’Œæ³¨æ„åŠ›æƒé‡ï¼Œä»è€Œæé«˜æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„é€‚åº”æ€§å’Œæ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTAPFMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šMILèšåˆå™¨å’ŒPFMã€‚å®ƒä»¬åˆ†åˆ«ç»´æŠ¤ç‹¬ç«‹çš„è®¡ç®—å›¾ï¼Œä»¥ç¡®ä¿è®­ç»ƒè¿‡ç¨‹çš„ç¨³å®šæ€§ï¼Œå¹¶ä¸ä¸‹æ¸¸ä»»åŠ¡ç›®æ ‡ä¿æŒä¸€è‡´ã€‚

**å…³é”®åˆ›æ–°**ï¼šTAPFMçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶ç‹¬ç‰¹çš„è®­ç»ƒåŠ¨æ€è®¾è®¡ï¼Œé€šè¿‡åˆ†ç¦»MILèšåˆå™¨å’ŒPFMçš„è®¡ç®—å›¾ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„é€‚åº”èƒ½åŠ›å’Œç¨³å®šæ€§ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€è®¡ç®—å›¾è®¾è®¡å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒTAPFMé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†è§†è§‰å˜æ¢å™¨çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥å¢å¼ºç‰¹å¾æå–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨è†€èƒ±ç™Œå’Œè‚ºè…ºç™Œçš„çªå˜é¢„æµ‹ä»»åŠ¡ä¸­ï¼ŒTAPFMçš„è¡¨ç°æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼ŒH-Optimus-0ï¼ˆTAPFMï¼‰åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†æ›´é«˜çš„å‡†ç¡®ç‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„æ½œåœ¨åº”ç”¨åœºæ™¯ï¼Œå°¤å…¶æ˜¯åœ¨åŒ»å­¦å½±åƒåˆ†æé¢†åŸŸã€‚é€šè¿‡æé«˜ç—…ç†åŸºç¡€æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„é€‚åº”æ€§ï¼ŒTAPFMå¯ä»¥å¸®åŠ©ä¸´åºŠåŒ»ç”Ÿæ›´å‡†ç¡®åœ°è¿›è¡Œç–¾ç—…è¯Šæ–­å’Œçªå˜é¢„æµ‹ï¼Œè¿›è€Œæ¨åŠ¨ä¸ªæ€§åŒ–åŒ»ç–—çš„å‘å±•ã€‚æœªæ¥ï¼ŒTAPFMçš„æŠ€æœ¯æ¡†æ¶ä¹Ÿå¯æ‰©å±•è‡³å…¶ä»–åŒ»å­¦å›¾åƒåˆ†æä»»åŠ¡ï¼Œæå‡æ•´ä½“åŒ»ç–—æ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Pathology foundation models (PFMs) have emerged as powerful tools for analyzing whole slide images (WSIs). However, adapting these pretrained PFMs for specific clinical tasks presents considerable challenges, primarily due to the availability of only weak (WSI-level) labels for gigapixel images, necessitating multiple instance learning (MIL) paradigm for effective WSI analysis. This paper proposes a novel approach for single-GPU \textbf{T}ask \textbf{A}daptation of \textbf{PFM}s (TAPFM) that uses vision transformer (\vit) attention for MIL aggregation while optimizing both for feature representations and attention weights. The proposed approach maintains separate computational graphs for MIL aggregator and the PFM to create stable training dynamics that align with downstream task objectives during end-to-end adaptation. Evaluated on mutation prediction tasks for bladder cancer and lung adenocarcinoma across institutional and TCGA cohorts, TAPFM consistently outperforms conventional approaches, with H-Optimus-0 (TAPFM) outperforming the benchmarks. TAPFM effectively handles multi-label classification of actionable mutations as well. Thus, TAPFM makes adaptation of powerful pre-trained PFMs practical on standard hardware for various clinical applications.

