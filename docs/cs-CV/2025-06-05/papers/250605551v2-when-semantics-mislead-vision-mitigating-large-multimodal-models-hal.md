---
layout: default
title: When Semantics Mislead Vision: Mitigating Large Multimodal Models Hallucinations in Scene Text Spotting and Understanding
---

# When Semantics Mislead Vision: Mitigating Large Multimodal Models Hallucinations in Scene Text Spotting and Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05551" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05551v2</a>
  <a href="https://arxiv.org/pdf/2506.05551.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05551v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05551v2', 'When Semantics Mislead Vision: Mitigating Large Multimodal Models Hallucinations in Scene Text Spotting and Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yan Shu, Hangui Lin, Yexin Liu, Yan Zhang, Gangyan Zeng, Yan Li, Yu Zhou, Ser-Nam Lim, Harry Yang, Nicu Sebe

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05 (æ›´æ–°: 2025-10-07)

**å¤‡æ³¨**: Accepted by NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºZoomTextä¸Grounded Layer Correctionä»¥ç¼“è§£åœºæ™¯æ–‡æœ¬ç†è§£ä¸­çš„è¯­ä¹‰å¹»è§‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨¡å‹` `è¯­ä¹‰å¹»è§‰` `åœºæ™¯æ–‡æœ¬è¯†åˆ«` `Transformer` `æ·±åº¦å­¦ä¹ ` `æ–‡æœ¬ç†è§£` `è§†è§‰æ„ŸçŸ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨å¤„ç†è§†è§‰æ¨¡ç³Šæˆ–éè¯­ä¹‰åœºæ™¯æ–‡æœ¬æ—¶ï¼Œå®¹æ˜“äº§ç”Ÿè¯­ä¹‰å¹»è§‰ï¼Œå¯¼è‡´è¯†åˆ«é”™è¯¯ã€‚
2. æå‡ºZoomTextå’ŒGrounded Layer Correctionä¸¤å¤§ç»„ä»¶ï¼Œå‰è€…é€šè¿‡ç²—åˆ°ç»†çš„ç­–ç•¥è¯†åˆ«æ–‡æœ¬åŒºåŸŸï¼Œåè€…åˆ©ç”¨å†…éƒ¨è¡¨ç¤ºçº æ­£å¹»è§‰è¾“å‡ºã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨ç¼“è§£è¯­ä¹‰å¹»è§‰æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶åœ¨åœºæ™¯æ–‡æœ¬è¯†åˆ«å’Œç†è§£çš„å…¬å…±åŸºå‡†ä¸Šå–å¾—äº†å¼ºåŠ²çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨è§†è§‰æ„ŸçŸ¥å’Œæ¨ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå½“é¢å¯¹è§†è§‰æ¨¡ç³Šæˆ–éè¯­ä¹‰çš„åœºæ™¯æ–‡æœ¬æ—¶ï¼Œå®ƒä»¬å¾€å¾€éš¾ä»¥å‡†ç¡®è¯†åˆ«å’Œç†è§£å†…å®¹ï¼Œå¸¸å¸¸ç”Ÿæˆè¯­ä¹‰ä¸Šåˆç†ä½†è§†è§‰ä¸Šä¸æ­£ç¡®çš„ç­”æ¡ˆï¼Œç§°ä¸ºè¯­ä¹‰å¹»è§‰ã€‚æœ¬æ–‡ç ”ç©¶äº†è¯­ä¹‰å¹»è§‰çš„æ ¹æœ¬åŸå› ï¼Œå¹¶å‘ç°å…·æœ‰æ›´å¼ºæ³¨æ„åŠ›èšç„¦äºåœºæ™¯æ–‡æœ¬åŒºåŸŸçš„Transformerå±‚æ›´ä¸å®¹æ˜“äº§ç”Ÿè¯­ä¹‰å¹»è§‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— è®­ç»ƒçš„è¯­ä¹‰å¹»è§‰ç¼“è§£æ¡†æ¶ï¼ŒåŒ…æ‹¬ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šZoomTextå’ŒGrounded Layer Correctionã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†TextHalu-BenchåŸºå‡†ï¼ŒåŒ…å«1,740ä¸ªæ ·æœ¬ï¼Œæ—¨åœ¨ä¸¥æ ¼è¯„ä¼°æ¨¡å‹çš„å¹»è§‰ç°è±¡ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆç¼“è§£äº†è¯­ä¹‰å¹»è§‰ï¼Œå¹¶åœ¨å…¬å…±åŸºå‡†ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨åœºæ™¯æ–‡æœ¬è¯†åˆ«ä¸­å‡ºç°çš„è¯­ä¹‰å¹»è§‰é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹è§†è§‰æ¨¡ç³Šæˆ–éè¯­ä¹‰æ–‡æœ¬æ—¶ï¼Œå®¹æ˜“ç”Ÿæˆä¸å‡†ç¡®çš„è¾“å‡ºï¼Œå½±å“æ¨¡å‹çš„å¯é æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ZoomTextå’ŒGrounded Layer Correctionä¸¤ä¸ªç»„ä»¶æ¥ç¼“è§£è¯­ä¹‰å¹»è§‰ã€‚ZoomTexté€šè¿‡ç²—åˆ°ç»†çš„ç­–ç•¥è¯†åˆ«æ½œåœ¨æ–‡æœ¬åŒºåŸŸï¼Œè€ŒGrounded Layer Correctionåˆ™åˆ©ç”¨è¾ƒå°‘äº§ç”Ÿå¹»è§‰çš„å±‚çš„å†…éƒ¨è¡¨ç¤ºæ¥æŒ‡å¯¼è§£ç ï¼Œçº æ­£ä¸å‡†ç¡®çš„è¾“å‡ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šZoomTextç”¨äºæ–‡æœ¬åŒºåŸŸçš„åˆæ­¥è¯†åˆ«ï¼Œè€ŒGrounded Layer Correctionåˆ™åœ¨è§£ç é˜¶æ®µè¿›è¡Œè¾“å‡ºä¿®æ­£ã€‚è¯¥æ¡†æ¶ä¸ä¾èµ–äºå¤–éƒ¨æ£€æµ‹å™¨ï¼Œå…·æœ‰è¾ƒé«˜çš„çµæ´»æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†æ— è®­ç»ƒçš„è¯­ä¹‰å¹»è§‰ç¼“è§£æ¡†æ¶ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡å†…éƒ¨å±‚çš„é€‚åº”æ€§åˆ©ç”¨æ¥å‡å°‘å¹»è§‰ç°è±¡ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†ä¸€ç§æ–°çš„æ€è·¯æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒZoomTexté‡‡ç”¨äº†ç²—åˆ°ç»†çš„ç­–ç•¥ï¼Œç¡®ä¿èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«æ–‡æœ¬åŒºåŸŸï¼›Grounded Layer Correctionåˆ™é€šè¿‡é€‰æ‹©æ€§åœ°åˆ©ç”¨å†…éƒ¨è¡¨ç¤ºæ¥çº æ­£è¾“å‡ºï¼Œä¿æŒæœ‰æ„ä¹‰æ–‡æœ¬çš„è¯­ä¹‰å®Œæ•´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨TextHalu-BenchåŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—é™ä½äº†è¯­ä¹‰å¹»è§‰çš„å‘ç”Ÿç‡ã€‚ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°XX%ï¼Œåœ¨åœºæ™¯æ–‡æœ¬è¯†åˆ«å’Œç†è§£çš„å…¬å…±åŸºå‡†ä¸Šä¹Ÿå–å¾—äº†é¢†å…ˆçš„ç»“æœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§å’Œå¢å¼ºç°å®ç­‰åœºæ™¯æ–‡æœ¬è¯†åˆ«ä»»åŠ¡ã€‚é€šè¿‡æé«˜æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„è¯†åˆ«å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è¿™äº›åº”ç”¨çš„æ™ºèƒ½åŒ–æ°´å¹³å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•ä¹Ÿå¯èƒ½æ¨åŠ¨æ›´å¹¿æ³›çš„å¤šæ¨¡æ€å­¦ä¹ ç ”ç©¶ï¼Œä¿ƒè¿›æ¨¡å‹åœ¨å…¶ä»–è§†è§‰ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Multimodal Models (LMMs) have achieved impressive progress in visual perception and reasoning. However, when confronted with visually ambiguous or non-semantic scene text, they often struggle to accurately spot and understand the content, frequently generating semantically plausible yet visually incorrect answers, which we refer to as semantic hallucination. In this work, we investigate the underlying causes of semantic hallucination and identify a key finding: Transformer layers in LLM with stronger attention focus on scene text regions are less prone to producing semantic hallucinations. Thus, we propose a training-free semantic hallucination mitigation framework comprising two key components: (1) ZoomText, a coarse-to-fine strategy that identifies potential text regions without external detectors; and (2) Grounded Layer Correction, which adaptively leverages the internal representations from layers less prone to hallucination to guide decoding, correcting hallucinated outputs for non-semantic samples while preserving the semantics of meaningful ones. To enable rigorous evaluation, we introduce TextHalu-Bench, a benchmark of 1,740 samples spanning both semantic and non-semantic cases, with manually curated question answer pairs designed to probe model hallucinations. Extensive experiments demonstrate that our method not only effectively mitigates semantic hallucination but also achieves strong performance on public benchmarks for scene text spotting and understanding.

