---
layout: default
title: From Play to Replay: Composed Video Retrieval for Temporally Fine-Grained Videos
---

# From Play to Replay: Composed Video Retrieval for Temporally Fine-Grained Videos

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05274" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05274v2</a>
  <a href="https://arxiv.org/pdf/2506.05274.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05274v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05274v2', 'From Play to Replay: Composed Video Retrieval for Temporally Fine-Grained Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Animesh Gupta, Jay Parmar, Ishan Rajendrakumar Dave, Mubarak Shah

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05 (æ›´æ–°: 2025-11-20)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTF-CoVRä»¥è§£å†³ç»†ç²’åº¦è§†é¢‘æ£€ç´¢é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç»†ç²’åº¦è§†é¢‘æ£€ç´¢` `è§†é¢‘ç¼–ç ` `å¯¹æ¯”å­¦ä¹ ` `å¤šæ¨¡æ€æ£€ç´¢` `ä½“è‚²è§†é¢‘åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„CoVRæ–¹æ³•ä¸»è¦å…³æ³¨å¤–è§‚å˜åŒ–ï¼Œæœªèƒ½æœ‰æ•ˆå¤„ç†ç»†ç²’åº¦çš„æ—¶é—´å·®å¼‚ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºTF-CoVRï¼Œæ„å»ºäº†ä¸€ä¸ªæ–°çš„åŸºå‡†ï¼Œåˆ©ç”¨å¤§è§„æ¨¡æ•°æ®é›†å’Œå¤šç›®æ ‡è§†é¢‘å…³è”ï¼Œå¢å¼ºäº†æ£€ç´¢çš„çµæ´»æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒTF-CoVR-Baseåœ¨é›¶-shotå’Œå¾®è°ƒæƒ…å†µä¸‹å‡æ˜¾è‘—æå‡äº†æ£€ç´¢æ€§èƒ½ï¼ŒmAP@50ä»5.92æå‡è‡³7.51ï¼Œå¾®è°ƒåè¾¾åˆ°27.22ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Composed Video Retrieval (CoVR)æ—¨åœ¨æ ¹æ®æŸ¥è¯¢è§†é¢‘å’Œæè¿°ä¿®æ”¹çš„æ–‡æœ¬æ£€ç´¢ç›®æ ‡è§†é¢‘ã€‚ç°æœ‰çš„CoVRåŸºå‡†ä¸»è¦å…³æ³¨å¤–è§‚å˜åŒ–æˆ–ç²—ç•¥äº‹ä»¶å˜åŒ–ï¼Œæœªèƒ½æœ‰æ•ˆæ•æ‰ç»†å¾®ã€å¿«é€Ÿçš„æ—¶é—´å·®å¼‚ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡å¼•å…¥TF-CoVRï¼Œè¿™æ˜¯é¦–ä¸ªä¸“æ³¨äºç»†ç²’åº¦CoVRçš„å¤§è§„æ¨¡åŸºå‡†ï¼Œæ¶µç›–ä½“æ“å’Œè·³æ°´é¢†åŸŸï¼Œæä¾›æ¥è‡ªFineGymå’ŒFineDivingæ•°æ®é›†çš„18ä¸‡å¯¹ä¸‰å…ƒç»„ã€‚TF-CoVRé€šè¿‡æ„å»ºæ¯ä¸ª<æŸ¥è¯¢ï¼Œä¿®æ”¹>å¯¹ï¼Œå…³è”å¤šä¸ªæœ‰æ•ˆç›®æ ‡è§†é¢‘ï¼Œåæ˜ äº†å®é™…ä»»åŠ¡çš„å¤æ‚æ€§ã€‚ä¸ºå»ºæ¨¡è¿™äº›æ—¶é—´åŠ¨æ€ï¼Œæå‡ºäº†TF-CoVR-Baseï¼Œä¸€ä¸ªç®€æ´çš„ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†æ£€ç´¢æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰CoVRæ–¹æ³•åœ¨ç»†ç²’åº¦è§†é¢‘æ£€ç´¢ä¸­çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯æ— æ³•æœ‰æ•ˆæ•æ‰å¿«é€Ÿçš„æ—¶é—´å˜åŒ–å’Œå¤šç›®æ ‡è§†é¢‘çš„å…³è”æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºTF-CoVRåŸºå‡†ï¼Œé€šè¿‡æ„å»º<æŸ¥è¯¢ï¼Œä¿®æ”¹>å¯¹ï¼Œåˆ©ç”¨å¤§è§„æ¨¡æ•°æ®é›†ä¸­çš„å¤šç›®æ ‡è§†é¢‘ï¼Œå¢å¼ºäº†æ£€ç´¢çš„å®ç”¨æ€§å’Œçµæ´»æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTF-CoVR-Baseé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼šç¬¬ä¸€é˜¶æ®µå¯¹è§†é¢‘ç¼–ç å™¨è¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥è·å¾—æ—¶é—´ä¸Šå…·æœ‰åŒºåˆ†æ€§çš„åµŒå…¥ï¼›ç¬¬äºŒé˜¶æ®µé€šè¿‡å¯¹æ¯”å­¦ä¹ å°†æ„å»ºçš„æŸ¥è¯¢ä¸å€™é€‰è§†é¢‘è¿›è¡Œå¯¹é½ã€‚

**å…³é”®åˆ›æ–°**ï¼šTF-CoVRæ˜¯é¦–ä¸ªä¸“æ³¨äºç»†ç²’åº¦CoVRçš„å¤§è§„æ¨¡åŸºå‡†ï¼Œèƒ½å¤Ÿå¤„ç†å¤šä¸ªæœ‰æ•ˆç›®æ ‡è§†é¢‘çš„å…³è”ï¼Œæ˜¾è‘—æå‡äº†æ£€ç´¢çš„å‡†ç¡®æ€§å’Œå®ç”¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼Œç¡®ä¿æŸ¥è¯¢ä¸å€™é€‰è§†é¢‘ä¹‹é—´çš„åµŒå…¥å¯¹é½ï¼ŒåŒæ—¶åœ¨è§†é¢‘ç¼–ç å™¨çš„è®¾è®¡ä¸Šæ³¨é‡æ—¶é—´ç‰¹å¾çš„æå–ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨TF-CoVRåŸºå‡†ä¸Šï¼ŒTF-CoVR-Baseåœ¨é›¶-shotæƒ…å†µä¸‹çš„mAP@50ä»5.92æå‡è‡³7.51ï¼Œç»è¿‡å¾®è°ƒåï¼ŒçŠ¶æ€-of-the-artæ€§èƒ½ä»19.83æå‡è‡³27.22ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨ä½“è‚²è§†é¢‘åˆ†æã€è‡ªåŠ¨åŒ–è§†é¢‘æ‘˜è¦ç”Ÿæˆç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜ç»†ç²’åº¦è§†é¢‘æ£€ç´¢çš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿä¸ºè¿åŠ¨å‘˜è¡¨ç°åˆ†æã€èµ›äº‹å›æ”¾å’Œè§‚ä¼—ä½“éªŒæå‡æä¾›æ”¯æŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Composed Video Retrieval (CoVR) retrieves a target video given a query video and a modification text describing the intended change. Existing CoVR benchmarks emphasize appearance shifts or coarse event changes and therefore do not test the ability to capture subtle, fast-paced temporal differences. We introduce TF-CoVR, the first large-scale benchmark dedicated to temporally fine-grained CoVR. TF-CoVR focuses on gymnastics and diving, and provides 180K triplets drawn from FineGym and FineDiving datasets. Previous CoVR benchmarks, focusing on temporal aspect, link each query to a single target segment taken from the same video, limiting practical usefulness. In TF-CoVR, we instead construct each <query, modification> pair by prompting an LLM with the label differences between clips drawn from different videos; every pair is thus associated with multiple valid target videos (3.9 on average), reflecting real-world tasks such as sports-highlight generation. To model these temporal dynamics, we propose TF-CoVR-Base, a concise two-stage training framework: (i) pre-train a video encoder on fine-grained action classification to obtain temporally discriminative embeddings; (ii) align the composed query with candidate videos using contrastive learning. We conduct the first comprehensive study of image, video, and general multimodal embedding (GME) models on temporally fine-grained composed retrieval in both zero-shot and fine-tuning regimes. On TF-CoVR, TF-CoVR-Base improves zero-shot mAP@50 from 5.92 (LanguageBind) to 7.51, and after fine-tuning raises the state-of-the-art from 19.83 to 27.22.

