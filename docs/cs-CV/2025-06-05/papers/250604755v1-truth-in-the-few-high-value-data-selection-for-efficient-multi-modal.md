---
layout: default
title: Truth in the Few: High-Value Data Selection for Efficient Multi-Modal Reasoning
---

# Truth in the Few: High-Value Data Selection for Efficient Multi-Modal Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04755" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.04755v1</a>
  <a href="https://arxiv.org/pdf/2506.04755.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04755v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04755v1', 'Truth in the Few: High-Value Data Selection for Efficient Multi-Modal Reasoning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Shenshen Li, Kaiyuan Deng, Lei Wang, Hao Yang, Chong Peng, Peng Yan, Fumin Shen, Heng Tao Shen, Xing Xu

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.MM

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-05

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/Leo-ssl/RAP)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫RAPÊñπÊ≥ï‰ª•È´òÊïàÈÄâÊã©Â§öÊ®°ÊÄÅÊé®ÁêÜ‰∏≠ÁöÑÈ´ò‰ª∑ÂÄºÊï∞ÊçÆ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÊé®ÁêÜ` `Êï∞ÊçÆÈÄâÊã©` `È´ò‰ª∑ÂÄºÊï∞ÊçÆ` `Âõ†ÊûúÊé®ÁêÜ` `Ê≥®ÊÑèÂäõÊú∫Âà∂` `ËÆ°ÁÆóÊïàÁéá` `Êú∫Âô®Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÊôÆÈÅç‰æùËµñÂ§ßÈáèËÆ≠ÁªÉÊï∞ÊçÆÔºåÂØºËá¥Êï∞ÊçÆÂÜó‰ΩôÂíåÈ´òÊòÇÁöÑËÆ°ÁÆóÊàêÊú¨„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫ÁöÑRAPÊñπÊ≥ïÈÄöËøáËØÜÂà´ËÆ§Áü•Ê†∑Êú¨Ôºå‰ºòÂåñÊï∞ÊçÆÈÄâÊã©ÔºåÊèêÂçáÂ§öÊ®°ÊÄÅÊé®ÁêÜÊïàÁéá„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåRAPÂú®ÂÖ≠‰∏™Êï∞ÊçÆÈõÜ‰∏ä‰ΩøÁî®9.3%ÁöÑÊï∞ÊçÆÂÆûÁé∞‰∫ÜÊÄßËÉΩÊèêÂçáÔºåËÆ°ÁÆóÊàêÊú¨ÊòæËëóÈôç‰Ωé„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â∞ΩÁÆ°Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÂú®Â§çÊùÇÊé®ÁêÜ‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜÊôÆÈÅçËÆ§‰∏∫ÈúÄË¶ÅÂ§ßÈáèËÆ≠ÁªÉÊï∞ÊçÆÊù•ÊèêÂçáÂÖ∂Â§öÊ®°ÊÄÅÊé®ÁêÜËÉΩÂäõÔºåÂØºËá¥Êï∞ÊçÆÂÜó‰ΩôÂíåËÆ°ÁÆóÊàêÊú¨È´òÊòÇ„ÄÇÊú¨ÊñáÊåëÊàòËøô‰∏ÄÂÅáËÆæÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊï∞ÊçÆÈÄâÊã©ËåÉÂºè‚Äî‚ÄîÊé®ÁêÜÊøÄÊ¥ªÊΩúÂäõÔºàRAPÔºâÔºåÈÄöËøáËØÑ‰º∞Ê†∑Êú¨ÊøÄÂèëÁúüÂÆûÂ§öÊ®°ÊÄÅÊé®ÁêÜÁöÑÊΩúÂäõÊù•ËØÜÂà´ËÆ§Áü•Ê†∑Êú¨„ÄÇRAP‰ΩøÁî®‰∏§Áßç‰∫íË°•ÁöÑ‰º∞ËÆ°Âô®ÔºöÂõ†ÊûúÂ∑ÆÂºÇ‰º∞ËÆ°Âô®ÔºàCDEÔºâÂíåÊ≥®ÊÑèÂäõÁΩÆ‰ø°Â∫¶‰º∞ËÆ°Âô®ÔºàACEÔºâÔºåÂπ∂ÂºïÂÖ•ÈöæÂ∫¶ÊÑüÁü•ÊõøÊç¢Ê®°ÂùóÔºàDRMÔºâ‰ª•Á°Æ‰øùÂ§çÊùÇÊÄß„ÄÇÂÆûÈ™åË°®ÊòéÔºåRAPÊñπÊ≥ï‰ªÖ‰ΩøÁî®9.3%ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºåÊÄßËÉΩ‰ºòË∂äÔºåËÆ°ÁÆóÊàêÊú¨Èôç‰ΩéË∂ÖËøá43%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÊé®ÁêÜ‰∏≠ÂØπÂ§ßÈáèËÆ≠ÁªÉÊï∞ÊçÆÁöÑ‰æùËµñÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂØºËá¥Êï∞ÊçÆÂÜó‰ΩôÂíåËÆ°ÁÆóÊàêÊú¨È´òÊòÇ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáËØÜÂà´‰ªÖÈúÄÂ∞ëÈáèÈ´ò‰ª∑ÂÄºÁöÑËÆ§Áü•Ê†∑Êú¨ÔºåRAPÊñπÊ≥ïËÉΩÂ§üÂú®‰øùÊåÅÊé®ÁêÜËÉΩÂäõÁöÑÂêåÊó∂ÔºåÊòæËëóÂáèÂ∞ëÊâÄÈúÄÊï∞ÊçÆÈáè„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRAPÊñπÊ≥ïÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂõ†ÊûúÂ∑ÆÂºÇ‰º∞ËÆ°Âô®ÔºàCDEÔºâÂíåÊ≥®ÊÑèÂäõÁΩÆ‰ø°Â∫¶‰º∞ËÆ°Âô®ÔºàACEÔºâÔºåÂπ∂ÁªìÂêàÈöæÂ∫¶ÊÑüÁü•ÊõøÊç¢Ê®°ÂùóÔºàDRMÔºâ‰ª•Á°Æ‰øùÊ†∑Êú¨ÁöÑÂ§çÊùÇÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöRAPÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÈÄöËøáCDEÂíåACEÁöÑÁªÑÂêàÔºåËÉΩÂ§üÊúâÊïàËØÜÂà´Âá∫ÂØπÊé®ÁêÜÊúâÂÆûÈôÖË¥°ÁåÆÁöÑÊ†∑Êú¨Ôºå‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåÊòæËëóÈôç‰Ωé‰∫ÜÂØπÂÜó‰ΩôÊï∞ÊçÆÁöÑ‰æùËµñ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöCDEÂü∫‰∫éÊΩúÂú®ÁªìÊûúÊ®°ÂûãÂéüÁêÜÔºåACEÂà©Áî®tokenÁ∫ßËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåDRMÂàôÊõøÊç¢ÁÆÄÂçïÂÆû‰æã‰ª•Â¢ûÂä†ËÆ§Áü•ÊåëÊàòÊÄßÔºåÁ°Æ‰øùÊé®ÁêÜÁöÑÂ§çÊùÇÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåRAPÊñπÊ≥ïÂú®ÂÖ≠‰∏™Êï∞ÊçÆÈõÜ‰∏ä‰ªÖ‰ΩøÁî®9.3%ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºå‰æùÁÑ∂ÂÆûÁé∞‰∫Ü‰ºòË∂äÁöÑÊÄßËÉΩÔºåËÆ°ÁÆóÊàêÊú¨Èôç‰ΩéË∂ÖËøá43%„ÄÇËøô‰∏ÄÁªìÊûúÊòæËëó‰ºò‰∫é‰º†ÁªüÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÈ´ò‰ª∑ÂÄºÊï∞ÊçÆÈÄâÊã©ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩÈóÆÁ≠îÁ≥ªÁªü„ÄÅÂõæÂÉèÁêÜËß£ÂíåÂ§öÊ®°ÊÄÅ‰∫§‰∫íÁ≠â„ÄÇÈÄöËøáÈ´òÊïàÁöÑÊï∞ÊçÆÈÄâÊã©ÔºåRAPÊñπÊ≥ïËÉΩÂ§üÂú®ËµÑÊ∫êÊúâÈôêÁöÑÊÉÖÂÜµ‰∏ãÊèêÂçáÂ§öÊ®°ÊÄÅÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> While multi-modal large language models (MLLMs) have made significant progress in complex reasoning tasks via reinforcement learning, it is commonly believed that extensive training data is necessary for improving multi-modal reasoning ability, inevitably leading to data redundancy and substantial computational costs. However, can smaller high-value datasets match or outperform full corpora for multi-modal reasoning in MLLMs? In this work, we challenge this assumption through a key observation: meaningful multi-modal reasoning is triggered by only a sparse subset of training samples, termed cognitive samples, whereas the majority contribute marginally. Building on this insight, we propose a novel data selection paradigm termed Reasoning Activation Potential (RAP), which identifies cognitive samples by estimating each sample's potential to stimulate genuine multi-modal reasoning by two complementary estimators: 1) Causal Discrepancy Estimator (CDE) based on the potential outcome model principle, eliminates samples that overly rely on language priors by comparing outputs between multi-modal and text-only inputs; 2) Attention Confidence Estimator (ACE), which exploits token-level self-attention to discard samples dominated by irrelevant but over-emphasized tokens in intermediate reasoning stages. Moreover, we introduce a Difficulty-aware Replacement Module (DRM) to substitute trivial instances with cognitively challenging ones, thereby ensuring complexity for robust multi-modal reasoning. Experiments on six datasets show that our RAP method consistently achieves superior performance using only 9.3% of the training data, while reducing computational costs by over 43%. Our code is available at https://github.com/Leo-ssl/RAP.

