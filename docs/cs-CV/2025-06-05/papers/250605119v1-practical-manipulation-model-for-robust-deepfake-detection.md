---
layout: default
title: Practical Manipulation Model for Robust Deepfake Detection
---

# Practical Manipulation Model for Robust Deepfake Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05119" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05119v1</a>
  <a href="https://arxiv.org/pdf/2506.05119.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05119v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05119v1', 'Practical Manipulation Model for Robust Deepfake Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Benedikt Hopf, Radu Timofte

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/BenediktHopf/PMM)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå®ç”¨æ“æ§æ¨¡å‹ä»¥å¢å¼ºæ·±ä¼ªæ£€æµ‹çš„é²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `æ·±ä¼ªæ£€æµ‹` `é²æ£’æ€§` `å›¾åƒå¤„ç†` `ä¼ªé€ æ ·æœ¬` `æœºå™¨å­¦ä¹ ` `æ•°æ®å¢å¼º` `æ¨¡å‹è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ·±ä¼ªæ£€æµ‹æ¨¡å‹åœ¨éç†æƒ³æ¡ä»¶ä¸‹çš„æ€§èƒ½ä¸ç¨³å®šï¼Œå®¹æ˜“è¢«è§„é¿ï¼Œå½±å“å®é™…åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºçš„å®ç”¨æ“æ§æ¨¡å‹é€šè¿‡å¼•å…¥å¤šæ ·åŒ–çš„ä¼ªé€ æ–¹å¼å’Œå¼ºé™è´¨è®­ç»ƒï¼Œå¢å¼ºäº†æ¨¡å‹çš„é²æ£’æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨æ ‡å‡†åŸºå‡†æ•°æ®é›†ä¸Šçš„æ€§èƒ½æ˜¾è‘—æå‡ï¼Œç‰¹åˆ«æ˜¯åœ¨DFDCå’ŒDFDCPæ•°æ®é›†ä¸Šåˆ†åˆ«æé«˜äº†3.51%å’Œ6.21%çš„AUCã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°ä»£æ·±ä¼ªæ£€æµ‹æ¨¡å‹åœ¨è·¨æ•°æ®é›†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨éç†æƒ³æ¡ä»¶ä¸‹çš„æ£€æµ‹æ€§èƒ½ä»ç„¶ä¸ç¨³å®šï¼Œé™åˆ¶äº†å…¶åœ¨æŸäº›åŸºå‡†æ•°æ®é›†ä¸Šçš„æˆåŠŸã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å®ç”¨æ“æ§æ¨¡å‹ï¼ˆPMMï¼‰ï¼Œæ‰©å±•äº†ä¼ªé€ çš„ç©ºé—´ï¼Œé‡‡ç”¨äº†æ³Šæ¾æ··åˆã€æ›´å¤šæ ·çš„æ©ç ã€ç”Ÿæˆå™¨ä¼ªå½±å’Œå¹²æ‰°ç‰©ã€‚é€šè¿‡åœ¨è®­ç»ƒå›¾åƒä¸­æ·»åŠ å¼ºé™è´¨ï¼Œæå‡äº†æ£€æµ‹å™¨çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨DFDCå’ŒDFDCPæ•°æ®é›†ä¸Šï¼Œæ¨¡å‹çš„AUCåˆ†åˆ«æé«˜äº†3.51%å’Œ6.21%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ·±ä¼ªæ£€æµ‹æ¨¡å‹åœ¨éç†æƒ³æ¡ä»¶ä¸‹çš„é²æ£’æ€§ä¸è¶³é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹å¤šæ ·åŒ–ä¼ªé€ æ‰‹æ®µæ—¶çš„æ€§èƒ½ä¸ç¨³å®šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå®ç”¨æ“æ§æ¨¡å‹ï¼ˆPMMï¼‰ï¼Œé€šè¿‡å¼•å…¥æ³Šæ¾æ··åˆå’Œå¤šæ ·åŒ–çš„æ©ç ç­‰æŠ€æœ¯ï¼Œæ‰©å±•ä¼ªé€ æ ·æœ¬çš„ç©ºé—´ï¼ŒåŒæ—¶åœ¨è®­ç»ƒä¸­åŠ å…¥å¼ºé™è´¨ï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ä¼ªé€ æ ·æœ¬ç”Ÿæˆã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚ä¼ªé€ æ ·æœ¬ç”Ÿæˆæ¨¡å—é‡‡ç”¨æ³Šæ¾æ··åˆå’Œå¤šæ ·åŒ–æ©ç ï¼Œè®­ç»ƒæ¨¡å—åˆ™å¼•å…¥å¼ºé™è´¨æŠ€æœ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ‰©å±•äº†ä¼ªé€ æ ·æœ¬çš„ç”Ÿæˆæ–¹å¼ï¼Œç»“åˆå¤šç§é™è´¨æŠ€æœ¯ï¼Œä½¿å¾—æ¨¡å‹åœ¨é¢å¯¹çœŸå®ä¸–ç•Œçš„ä¼ªé€ æ—¶è¡¨ç°æ›´ä¸ºç¨³å¥ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†å¤šæ ·åŒ–çš„æ©ç å’Œç”Ÿæˆå™¨ä¼ªå½±ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šæ³¨é‡å¯¹æŠ—æ€§è®­ç»ƒï¼Œç½‘ç»œç»“æ„åˆ™åŸºäºç°æœ‰çš„LAAéª¨å¹²ç½‘ç»œè¿›è¡Œæ”¹è¿›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„å®ç”¨æ“æ§æ¨¡å‹åœ¨DFDCå’ŒDFDCPæ•°æ®é›†ä¸Šåˆ†åˆ«æé«˜äº†3.51%å’Œ6.21%çš„AUCï¼Œç›¸è¾ƒäºç°æœ‰çš„æœ€å…ˆè¿›LAAéª¨å¹²ç½‘ç»œï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„é²æ£’æ€§å’Œæ£€æµ‹æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸ã€è§†é¢‘ç›‘æ§ç³»ç»Ÿå’Œæ–°é—»çœŸå®æ€§éªŒè¯ç­‰ã€‚é€šè¿‡æé«˜æ·±ä¼ªæ£€æµ‹çš„é²æ£’æ€§ï¼Œå¯ä»¥æœ‰æ•ˆé˜²æ­¢è™šå‡ä¿¡æ¯çš„ä¼ æ’­ï¼Œå¢å¼ºå…¬ä¼—å¯¹æ•°å­—å†…å®¹çš„ä¿¡ä»»ã€‚æœªæ¥ï¼Œè¯¥æ¨¡å‹çš„åº”ç”¨å¯èƒ½ä¼šæ‰©å±•åˆ°æ›´å¤šéœ€è¦å›¾åƒçœŸå®æ€§éªŒè¯çš„åœºæ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Modern deepfake detection models have achieved strong performance even on the challenging cross-dataset task. However, detection performance under non-ideal conditions remains very unstable, limiting success on some benchmark datasets and making it easy to circumvent detection. Inspired by the move to a more real-world degradation model in the area of image super-resolution, we have developed a Practical Manipulation Model (PMM) that covers a larger set of possible forgeries. We extend the space of pseudo-fakes by using Poisson blending, more diverse masks, generator artifacts, and distractors. Additionally, we improve the detectors' generality and robustness by adding strong degradations to the training images. We demonstrate that these changes not only significantly enhance the model's robustness to common image degradations but also improve performance on standard benchmark datasets. Specifically, we show clear increases of $3.51\%$ and $6.21\%$ AUC on the DFDC and DFDCP datasets, respectively, over the s-o-t-a LAA backbone. Furthermore, we highlight the lack of robustness in previous detectors and our improvements in this regard. Code can be found at https://github.com/BenediktHopf/PMM

