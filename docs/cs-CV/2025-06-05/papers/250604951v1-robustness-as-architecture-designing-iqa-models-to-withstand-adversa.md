---
layout: default
title: Robustness as Architecture: Designing IQA Models to Withstand Adversarial Perturbations
---

# Robustness as Architecture: Designing IQA Models to Withstand Adversarial Perturbations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04951" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04951v1</a>
  <a href="https://arxiv.org/pdf/2506.04951.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04951v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04951v1', 'Robustness as Architecture: Designing IQA Models to Withstand Adversarial Perturbations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Igor Meleshin, Anna Chistyakova, Anastasia Antsiferova, Dmitriy Vatolin

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ¶æ„è®¾è®¡çš„IQæ¨¡å‹ä»¥å¢å¼ºé²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å›¾åƒè´¨é‡è¯„ä¼°` `å¯¹æŠ—æ€§æ”»å‡»` `é²æ£’æ€§è®¾è®¡` `æ·±åº¦å­¦ä¹ ` `æ¨¡å‹ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„IQAæ¨¡å‹åœ¨é¢å¯¹å¯¹æŠ—æ€§æ‰°åŠ¨æ—¶è¡¨ç°å‡ºè„†å¼±æ€§ï¼Œå¯¼è‡´è¯„åˆ†å¤±çœŸå¹¶å½±å“ä¿¡ä»»åº¦ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡è®¾è®¡æ¨¡å‹æ¶æ„æ¥å¢å¼ºé²æ£’æ€§ï¼Œè€Œéä¾èµ–äºå¯¹æŠ—è®­ç»ƒç­‰æ•°æ®é©±åŠ¨çš„æ–¹æ³•ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¶æ„èƒ½å¤Ÿæœ‰æ•ˆæŠµå¾¡å¯¹æŠ—æ”»å‡»ï¼Œä¸”æ— éœ€æ˜¾è‘—ä¿®æ”¹åŸå§‹æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å›¾åƒè´¨é‡è¯„ä¼°ï¼ˆIQAï¼‰æ¨¡å‹åœ¨ç°å®ç³»ç»Ÿä¸­è¢«å¹¿æ³›åº”ç”¨äºå›¾åƒè´¨é‡è¯„ä¼°ï¼Œä½†å…¶å›ºæœ‰çš„ä¸ç¨³å®šæ€§ä½¿å¾—æ¨¡å‹æ˜“å—å¯¹æŠ—æ€§æ‰°åŠ¨çš„å½±å“ï¼Œå¯¼è‡´è¯„åˆ†å¤±çœŸå¹¶å‰Šå¼±ä¿¡ä»»ã€‚ä¼ ç»Ÿæ–¹æ³•é€šè¿‡æ•°æ®é©±åŠ¨çš„é˜²å¾¡æ‰‹æ®µæ¥è§£å†³è¿™äº›è„†å¼±æ€§ï¼Œä½†æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è§†è§’ï¼šå°†é²æ£’æ€§è§†ä¸ºä¸€ç§æ¶æ„å…ˆéªŒã€‚é€šè¿‡é‡æ–°è®¾è®¡æ¨¡å‹çš„å†…éƒ¨ç»“æ„ï¼ŒæŠ‘åˆ¶å¯¹æ‰°åŠ¨çš„æ•æ„Ÿæ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é²æ£’çš„IQAæ¶æ„ï¼Œèƒ½å¤Ÿåœ¨ä¸éœ€è¦å¯¹æŠ—è®­ç»ƒæˆ–æ˜¾è‘—æ”¹å˜åŸå§‹æ¨¡å‹çš„æƒ…å†µä¸‹æŠµå¾¡å¯¹æŠ—æ”»å‡»ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å›¾åƒè´¨é‡è¯„ä¼°æ¨¡å‹åœ¨å¯¹æŠ—æ€§æ‰°åŠ¨ä¸‹çš„è„†å¼±æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å¯¹æŠ—è®­ç»ƒç­‰æ•°æ®é©±åŠ¨çš„é˜²å¾¡æ‰‹æ®µï¼Œå­˜åœ¨ä¸€å®šçš„å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºå°†é²æ£’æ€§è§†ä¸ºä¸€ç§æ¶æ„è®¾è®¡çš„å…ˆéªŒï¼Œé€šè¿‡é‡å¡‘æ¨¡å‹çš„å†…éƒ¨ç»“æ„ï¼ŒæŠ‘åˆ¶å…¶å¯¹æ‰°åŠ¨çš„æ•æ„Ÿæ€§ï¼Œä»æ ¹æœ¬ä¸Šå¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¿¡æ¯æµçš„æ­£äº¤æ€§çº¦æŸã€èŒƒæ•°ä¿æŒæ“ä½œä»¥åŠé€šè¿‡å‰ªæå’Œå¾®è°ƒæ¥è¿›ä¸€æ­¥ç¨³å®šç³»ç»Ÿã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬ä¿¡æ¯æµæ§åˆ¶æ¨¡å—å’Œæ¨¡å‹ä¼˜åŒ–æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†é²æ£’æ€§è®¾è®¡ä¸ºæ¶æ„çš„ä¸€éƒ¨åˆ†ï¼Œè€Œéé€šè¿‡è®­ç»ƒæ¥è·å¾—ã€‚è¿™ä¸€æ€è·¯ä¸ä¼ ç»Ÿæ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œå¼ºè°ƒè®¾è®¡ä¼˜äºå­¦ä¹ ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†æ­£äº¤ä¿¡æ¯æµçº¦æŸå’ŒèŒƒæ•°ä¿æŒæ“ä½œï¼Œç¡®ä¿ç½‘ç»œåœ¨å¤„ç†è¾“å…¥æ—¶ä¿æŒç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡å‰ªæå’Œå¾®è°ƒè¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼Œæå‡é²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„é²æ£’IQAæ¶æ„åœ¨é¢å¯¹å¯¹æŠ—æ€§æ”»å‡»æ—¶ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨å¯¹æŠ—æ”»å‡»ä¸‹çš„è¯„åˆ†ç¨³å®šæ€§æé«˜äº†20%ä»¥ä¸Šï¼Œä¸”åœ¨ä¸éœ€è¦å¯¹æŠ—è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œä¾ç„¶ä¿æŒäº†è¾ƒé«˜çš„è¯„åˆ†å‡†ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å›¾åƒå‹ç¼©ã€å¢å¼ºã€ç”Ÿæˆå’Œæµåª’ä½“ç­‰å¤šä¸ªå®é™…åœºæ™¯ã€‚é€šè¿‡å¢å¼ºIQAæ¨¡å‹çš„é²æ£’æ€§ï¼Œå¯ä»¥æé«˜ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œç”¨æˆ·ä¿¡ä»»åº¦ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„æœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Image Quality Assessment (IQA) models are increasingly relied upon to evaluate image quality in real-world systems -- from compression and enhancement to generation and streaming. Yet their adoption brings a fundamental risk: these models are inherently unstable. Adversarial manipulations can easily fool them, inflating scores and undermining trust. Traditionally, such vulnerabilities are addressed through data-driven defenses -- adversarial retraining, regularization, or input purification. But what if this is the wrong lens? What if robustness in perceptual models is not something to learn but something to design? In this work, we propose a provocative idea: robustness as an architectural prior. Rather than training models to resist perturbations, we reshape their internal structure to suppress sensitivity from the ground up. We achieve this by enforcing orthogonal information flow, constraining the network to norm-preserving operations -- and further stabilizing the system through pruning and fine-tuning. The result is a robust IQA architecture that withstands adversarial attacks without requiring adversarial training or significant changes to the original model. This approach suggests a shift in perspective: from optimizing robustness through data to engineering it through design.

