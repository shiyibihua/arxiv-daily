---
layout: default
title: MINT-CoT: Enabling Interleaved Visual Tokens in Mathematical Chain-of-Thought Reasoning
---

# MINT-CoT: Enabling Interleaved Visual Tokens in Mathematical Chain-of-Thought Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05331" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05331v1</a>
  <a href="https://arxiv.org/pdf/2506.05331.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05331v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05331v1', 'MINT-CoT: Enabling Interleaved Visual Tokens in Mathematical Chain-of-Thought Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xinyan Chen, Renrui Zhang, Dongzhi Jiang, Aojun Zhou, Shilin Yan, Weifeng Lin, Hongsheng Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

**å¤‡æ³¨**: Code is released at https://github.com/xinyan-cxy/MINT-CoT

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/xinyan-cxy/MINT-CoT)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMINT-CoTä»¥è§£å†³å¤šæ¨¡æ€æ•°å­¦æ¨ç†ä¸­çš„è§†è§‰ä¿¡å·æ•´åˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ•°å­¦æ¨ç†` `å¤šæ¨¡æ€å­¦ä¹ ` `è§†è§‰ä¿¡å·æ•´åˆ` `é“¾å¼æ€ç»´` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€æ•°å­¦æ¨ç†ä¸­é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¯¹ç²—ç³™å›¾åƒåŒºåŸŸçš„ä¾èµ–ã€è§†è§‰ç¼–ç å™¨å¯¹æ•°å­¦å†…å®¹çš„æ„ŸçŸ¥èƒ½åŠ›æœ‰é™ï¼Œä»¥åŠå¯¹å¤–éƒ¨è§†è§‰ä¿®æ”¹èƒ½åŠ›çš„ä¾èµ–ã€‚
2. æœ¬æ–‡æå‡ºMINT-CoTï¼Œé€šè¿‡å¼•å…¥æ•°å­¦äº¤ç»‡ä»¤ç‰Œï¼ŒåŠ¨æ€é€‰æ‹©ä¸æ¨ç†æ­¥éª¤ç›¸å…³çš„è§†è§‰ä»¤ç‰Œï¼Œä»è€Œå®ç°æ–‡æœ¬æ¨ç†ä¸è§†è§‰ä¿¡å·çš„æœ‰æ•ˆäº¤ç»‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMINT-CoT-7Bæ¨¡å‹åœ¨MathVistaã€GeoQAå’ŒMMStarç­‰åŸºå‡†ä¸Šåˆ†åˆ«æå‡äº†34.08%ã€28.78%å’Œ23.2%çš„æ€§èƒ½ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é“¾å¼æ€ç»´ï¼ˆCoTï¼‰åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æ˜¾è‘—å¢å¼ºäº†æ•°å­¦æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨å¤šæ¨¡æ€é¢†åŸŸçš„æ‰©å±•ä»é¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆé‡‡ç”¨ç±»ä¼¼æ–‡æœ¬çš„æ¨ç†æ–¹å¼å¤„ç†å›¾åƒè¾“å…¥ï¼Œè¦ä¹ˆè¯•å›¾å°†è§†è§‰ä¿¡å·ä¸æ•°å­¦CoTäº¤ç»‡ï¼Œä½†å­˜åœ¨ä¾èµ–ç²—ç³™çš„å›¾åƒåŒºåŸŸã€è§†è§‰ç¼–ç å™¨å¯¹æ•°å­¦å†…å®¹æ„ŸçŸ¥æœ‰é™ä»¥åŠä¾èµ–å¤–éƒ¨èƒ½åŠ›è¿›è¡Œè§†è§‰ä¿®æ”¹ç­‰ä¸‰å¤§å…³é”®é™åˆ¶ã€‚æœ¬æ–‡æå‡ºMINT-CoTï¼Œå¼•å…¥æ•°å­¦äº¤ç»‡ä»¤ç‰Œä»¥å®ç°è§†è§‰æ¨ç†ï¼ŒåŠ¨æ€é€‰æ‹©æ•°å­¦å›¾å½¢ä¸­çš„è§†è§‰åŒºåŸŸï¼Œå¹¶æ„å»ºåŒ…å«54Kæ•°å­¦é—®é¢˜çš„MINT-CoTæ•°æ®é›†ï¼Œæ”¯æŒé€æ­¥è®­ç»ƒç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMINT-CoT-7Bæ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€æ•°å­¦æ¨ç†ä¸­è§†è§‰ä¿¡å·æ•´åˆä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºç²—ç³™çš„å›¾åƒåŒºåŸŸï¼Œå¯¼è‡´å¯¹æ•°å­¦å†…å®¹çš„ç†è§£å’Œæ¨ç†èƒ½åŠ›å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMINT-CoTçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥æ•°å­¦äº¤ç»‡ä»¤ç‰Œï¼ŒåŠ¨æ€é€‰æ‹©ä¸æ¨ç†æ­¥éª¤ç›¸å…³çš„è§†è§‰åŒºåŸŸï¼Œä»è€Œå®ç°æ–‡æœ¬ä¸è§†è§‰ä¿¡æ¯çš„æœ‰æ•ˆäº¤ç»‡ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æé«˜æ¨¡å‹å¯¹æ•°å­¦é—®é¢˜çš„ç†è§£å’Œè§£å†³èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMINT-CoTçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šæ–‡æœ¬ä»…CoTçš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€äº¤ç»‡CoTçš„SFTï¼Œä»¥åŠäº¤ç»‡CoTçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ã€‚æ¯ä¸ªé˜¶æ®µé€æ­¥å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œè§†è§‰æ•´åˆèƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šMINT-CoTçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†æ•°å­¦äº¤ç»‡ä»¤ç‰Œï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤ŸåŠ¨æ€é€‰æ‹©ä»»æ„å½¢çŠ¶çš„è§†è§‰åŒºåŸŸï¼Œä¸æ–‡æœ¬æ¨ç†æ­¥éª¤ç›¸ç»“åˆã€‚è¿™ä¸€æ–¹æ³•ä¸ç°æœ‰ä¾èµ–å›ºå®šå½¢çŠ¶åŒºåŸŸçš„æŠ€æœ¯æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ä¸¥æ ¼çš„æ•°æ®ç”Ÿæˆç®¡é“ï¼Œæ„å»ºäº†åŒ…å«54Kæ•°å­¦é—®é¢˜çš„æ•°æ®é›†ï¼Œç¡®ä¿æ¯ä¸ªæ¨ç†æ­¥éª¤ä¸è§†è§‰åŒºåŸŸåœ¨ä»¤ç‰Œçº§åˆ«ä¸Šå¯¹é½ã€‚æ­¤å¤–ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨äº†å¤šç§æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç­–ç•¥ï¼Œä»¥æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMINT-CoT-7Bæ¨¡å‹åœ¨MathVistaã€GeoQAå’ŒMMStaråŸºå‡†ä¸Šåˆ†åˆ«æå‡äº†34.08%ã€28.78%å’Œ23.2%çš„æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨å¤šæ¨¡æ€æ•°å­¦æ¨ç†ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MINT-CoTçš„ç ”ç©¶æˆæœåœ¨æ•™è‚²ã€æ™ºèƒ½è¾…å¯¼ã€ä»¥åŠæ•°å­¦é—®é¢˜æ±‚è§£ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æœ‰æ•ˆæ•´åˆè§†è§‰ä¿¡æ¯ä¸æ–‡æœ¬æ¨ç†ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¸®åŠ©å­¦ç”Ÿæ›´å¥½åœ°ç†è§£æ•°å­¦æ¦‚å¿µï¼Œæå‡å­¦ä¹ æ•ˆæœï¼Œå¹¶ä¸ºæœªæ¥çš„æ™ºèƒ½æ•™è‚²ç³»ç»Ÿå¥ å®šåŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Chain-of-Thought (CoT) has widely enhanced mathematical reasoning in Large Language Models (LLMs), but it still remains challenging for extending it to multimodal domains. Existing works either adopt a similar textual reasoning for image input, or seek to interleave visual signals into mathematical CoT. However, they face three key limitations for math problem-solving: reliance on coarse-grained box-shaped image regions, limited perception of vision encoders on math content, and dependence on external capabilities for visual modification. In this paper, we propose MINT-CoT, introducing Mathematical INterleaved Tokens for Chain-of-Thought visual reasoning. MINT-CoT adaptively interleaves relevant visual tokens into textual reasoning steps via an Interleave Token, which dynamically selects visual regions of any shapes within math figures. To empower this capability, we construct the MINT-CoT dataset, containing 54K mathematical problems aligning each reasoning step with visual regions at the token level, accompanied by a rigorous data generation pipeline. We further present a three-stage MINT-CoT training strategy, progressively combining text-only CoT SFT, interleaved CoT SFT, and interleaved CoT RL, which derives our MINT-CoT-7B model. Extensive experiments demonstrate the effectiveness of our method for effective visual interleaved reasoning in mathematical domains, where MINT-CoT-7B outperforms the baseline model by +34.08% on MathVista, +28.78% on GeoQA, and +23.2% on MMStar, respectively. Our code and data are available at https://github.com/xinyan-cxy/MINT-CoT

