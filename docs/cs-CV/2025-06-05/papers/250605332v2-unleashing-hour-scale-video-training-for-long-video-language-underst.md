---
layout: default
title: Unleashing Hour-Scale Video Training for Long Video-Language Understanding
---

# Unleashing Hour-Scale Video Training for Long Video-Language Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05332" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05332v2</a>
  <a href="https://arxiv.org/pdf/2506.05332.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05332v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05332v2', 'Unleashing Hour-Scale Video Training for Long Video-Language Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jingyang Lin, Jialian Wu, Ximeng Sun, Ze Wang, Jiang Liu, Yusheng Su, Xiaodong Yu, Hao Chen, Jiebo Luo, Zicheng Liu, Emad Barsoum

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05 (æ›´æ–°: 2025-12-01)

**å¤‡æ³¨**: NeurIPS 2025, Project page: https://videomarathon.github.io/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVideoMarathonæ•°æ®é›†ä»¥è§£å†³é•¿è§†é¢‘è¯­è¨€ç†è§£è®­ç»ƒä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿è§†é¢‘ç†è§£` `è§†é¢‘è¯­è¨€æ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ ` `æ•°æ®é›†æ„å»º` `å†…å­˜å¢å¼º` `é—®ç­”ç³»ç»Ÿ` `è§†é¢‘ç†è§£ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é•¿è§†é¢‘è¯­è¨€ç†è§£æ–¹æ³•å—é™äºç¼ºä¹é«˜è´¨é‡çš„é•¿è§†é¢‘æ•°æ®é›†ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆæœä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºVideoMarathonæ•°æ®é›†ï¼ŒåŒ…å«9700å°æ—¶çš„é•¿è§†é¢‘å’Œ330ä¸‡ä¸ªé«˜è´¨é‡é—®ç­”å¯¹ï¼Œæ”¯æŒå¤šç§è§†é¢‘ç†è§£ä»»åŠ¡ã€‚
3. Hour-LLaVAæ¨¡å‹åœ¨å¤šä¸ªé•¿è§†é¢‘è¯­è¨€åŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ŒéªŒè¯äº†VideoMarathonæ•°æ®é›†çš„é«˜è´¨é‡å’ŒHour-LLaVAæ¨¡å‹çš„ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œé•¿è§†é¢‘è¯­è¨€ç†è§£åŸºå‡†æ¨åŠ¨äº†è§†é¢‘å¤§è§„æ¨¡å¤šæ¨¡æ€æ¨¡å‹ï¼ˆVideo-LMMsï¼‰çš„è¿›å±•ã€‚ç„¶è€Œï¼Œç¼ºä¹è‰¯å¥½æ³¨é‡Šçš„é•¿è§†é¢‘ä½¿å¾—å°æ—¶çº§Video-LMMsçš„è®­ç»ƒå°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡æå‡ºäº†VideoMarathonï¼Œä¸€ä¸ªå¤§è§„æ¨¡çš„å°æ—¶çº§è§†é¢‘æŒ‡ä»¤è·Ÿéšæ•°æ®é›†ï¼ŒåŒ…å«çº¦9700å°æ—¶çš„é•¿è§†é¢‘ï¼Œè§†é¢‘æ—¶é•¿ä»3åˆ°60åˆ†é’Ÿä¸ç­‰ã€‚è¯¥æ•°æ®é›†åŒ…å«330ä¸‡ä¸ªé«˜è´¨é‡çš„é—®ç­”å¯¹ï¼Œæ¶µç›–å…­ä¸ªåŸºæœ¬ä¸»é¢˜ï¼šæ—¶é—´æ€§ã€ç©ºé—´æ€§ã€ç‰©ä½“ã€åŠ¨ä½œã€åœºæ™¯å’Œäº‹ä»¶ã€‚ä¸ç°æœ‰è§†é¢‘æŒ‡ä»¤æ•°æ®é›†ç›¸æ¯”ï¼ŒVideoMarathonæ˜¾è‘—æ‰©å±•äº†è®­ç»ƒè§†é¢‘çš„æ—¶é•¿ï¼Œå¹¶æ”¯æŒ22ç§éœ€è¦çŸ­æœŸå’Œé•¿æœŸè§†é¢‘ç†è§£çš„å¤šæ ·ä»»åŠ¡ã€‚åŸºäºVideoMarathonï¼Œæœ¬æ–‡æå‡ºäº†Hour-LLaVAï¼Œä¸€ä¸ªå¼ºå¤§ä¸”é«˜æ•ˆçš„å°æ—¶çº§è§†é¢‘è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿä»¥1-FPSçš„é‡‡æ ·ç‡è¿›è¡Œå°æ—¶çº§è§†é¢‘è®­ç»ƒå’Œæ¨ç†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³é•¿è§†é¢‘è¯­è¨€ç†è§£ä¸­ç¼ºä¹é«˜è´¨é‡é•¿è§†é¢‘æ•°æ®é›†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºçŸ­è§†é¢‘ï¼Œå¯¼è‡´æ¨¡å‹åœ¨å¤„ç†é•¿è§†é¢‘æ—¶æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºVideoMarathonæ•°æ®é›†ï¼ŒåŒ…å«å¤§é‡é•¿è§†é¢‘åŠé«˜è´¨é‡é—®ç­”å¯¹ï¼Œä»¥æ”¯æŒé•¿è§†é¢‘è¯­è¨€ç†è§£çš„è®­ç»ƒã€‚åŒæ—¶ï¼Œè®¾è®¡Hour-LLaVAæ¨¡å‹ï¼Œåˆ©ç”¨å†…å­˜å¢å¼ºæ¨¡å—è¿›è¡Œé«˜æ•ˆçš„è§†é¢‘è¯­è¨€å»ºæ¨¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHour-LLaVAæ¨¡å‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬è§†é¢‘è¾“å…¥æ¨¡å—ã€å†…å­˜å¢å¼ºæ¨¡å—å’Œè¯­è¨€ç†è§£æ¨¡å—ã€‚è§†é¢‘è¾“å…¥æ¨¡å—è´Ÿè´£å¤„ç†é•¿è§†é¢‘ï¼Œå†…å­˜å¢å¼ºæ¨¡å—åˆ™æ•´åˆç›¸å…³è¯­ä¹‰ä¿¡æ¯ï¼Œæœ€åè¯­è¨€ç†è§£æ¨¡å—è¿›è¡Œæ¨ç†å’Œè¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºVideoMarathonæ•°æ®é›†çš„æ„å»ºå’ŒHour-LLaVAæ¨¡å‹çš„è®¾è®¡ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒHour-LLaVAèƒ½å¤Ÿåœ¨1-FPSçš„é‡‡æ ·ç‡ä¸‹è¿›è¡Œé«˜æ•ˆæ¨ç†ï¼Œæ˜¾è‘—æå‡äº†é•¿è§†é¢‘ç†è§£çš„èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šHour-LLaVAæ¨¡å‹é‡‡ç”¨äº†é€‚åº”æ€§å†…å­˜å¢å¼ºæœºåˆ¶ï¼Œèƒ½å¤ŸåŠ¨æ€æ•´åˆé—®é¢˜ç›¸å…³çš„æ—¶ç©ºä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæ¨¡å‹çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ä¼˜åŒ–é•¿è§†é¢‘çš„ç†è§£æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒHour-LLaVAæ¨¡å‹åœ¨å¤šä¸ªé•¿è§†é¢‘è¯­è¨€åŸºå‡†ä¸Šå–å¾—äº†æœ€ä½³æ€§èƒ½ï¼ŒéªŒè¯äº†VideoMarathonæ•°æ®é›†çš„é«˜è´¨é‡ã€‚å…·ä½“è€Œè¨€ï¼ŒHour-LLaVAåœ¨æŸäº›ä»»åŠ¡ä¸Šç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æå‡äº†è¶…è¿‡10%çš„å‡†ç¡®ç‡ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨é•¿è§†é¢‘ç†è§£ä¸­çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è§†é¢‘å†…å®¹æ£€ç´¢ã€æ™ºèƒ½ç›‘æ§ã€æ•™è‚²è§†é¢‘åˆ†æç­‰ã€‚é€šè¿‡æå‡é•¿è§†é¢‘ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´ç²¾å‡†çš„ä¿¡æ¯æ£€ç´¢å’Œå†…å®¹æ¨èï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent long-form video-language understanding benchmarks have driven progress in video large multimodal models (Video-LMMs). However, the scarcity of well-annotated long videos has left the training of hour-long Video-LMMs underexplored. To close this gap, we present VideoMarathon, a large-scale hour-long video instruction-following dataset. This dataset includes around 9,700 hours of long videos sourced from diverse domains, ranging from 3 to 60 minutes per video. Specifically, it contains 3.3M high-quality QA pairs, spanning six fundamental topics: temporality, spatiality, object, action, scene, and event. Compared to existing video instruction datasets, VideoMarathon significantly extends training video durations up to 1 hour, and supports 22 diverse tasks requiring both short- and long-term video comprehension. Building on VideoMarathon, we propose Hour-LLaVA, a powerful and efficient Video-LMM for hour-scale video-language modeling. It enables hour-long video training and inference at 1-FPS sampling by leveraging a memory augmentation module, which adaptively integrates question-relevant and spatiotemporally informative semantics from the cached full video context. In our experiments, Hour-LLaVA achieves the best performance on multiple representative long video-language benchmarks, demonstrating the high quality of the VideoMarathon dataset and the superiority of the Hour-LLaVA model.

