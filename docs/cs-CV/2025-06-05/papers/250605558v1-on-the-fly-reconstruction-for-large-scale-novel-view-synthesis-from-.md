---
layout: default
title: On-the-fly Reconstruction for Large-Scale Novel View Synthesis from Unposed Images
---

# On-the-fly Reconstruction for Large-Scale Novel View Synthesis from Unposed Images

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05558" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05558v1</a>
  <a href="https://arxiv.org/pdf/2506.05558.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05558v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05558v1', 'On-the-fly Reconstruction for Large-Scale Novel View Synthesis from Unposed Images')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Andreas Meuleman, Ishaan Shah, Alexandre Lanvin, Bernhard Kerbl, George Drettakis

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

**æœŸåˆŠ**: ACM Transactions on Graphics 44, 4 (August 2025)

**DOI**: [10.1145/3730913](https://doi.org/10.1145/3730913)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§å³æ—¶é‡å»ºæ–¹æ³•ä»¥è§£å†³å¤§è§„æ¨¡æ–°è§†è§’åˆæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `æ–°è§†è§’åˆæˆ` `å³æ—¶é‡å»º` `é«˜æ–¯æ•£å°„` `å§¿æ€ä¼°è®¡` `å¤§è§„æ¨¡åœºæ™¯` `è®¡ç®—æœºè§†è§‰` `è™šæ‹Ÿç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å§¿æ€ä¼°è®¡å’Œ3DGSä¼˜åŒ–ä¸Šè€—æ—¶è¾ƒé•¿ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶éœ€æ±‚ã€‚
2. æå‡ºäº†ä¸€ç§å³æ—¶é‡å»ºæ–¹æ³•ï¼Œç»“åˆå¿«é€Ÿå§¿æ€ä¼°è®¡å’Œé«˜æ•ˆçš„é«˜æ–¯åŸè¯­é‡‡æ ·ï¼Œæå‡äº†å¤„ç†é€Ÿåº¦ã€‚
3. åœ¨å¤šç§æ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨é€Ÿåº¦å’Œå›¾åƒè´¨é‡ä¸Šä¸å…¶ä»–æ–¹æ³•å…·æœ‰ç«äº‰åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¾å°„åœºæ–¹æ³•å¦‚3Dé«˜æ–¯æ•£å°„ï¼ˆ3DGSï¼‰èƒ½å¤Ÿè½»æ¾ä»ç…§ç‰‡ä¸­é‡å»ºï¼Œå®ç°è‡ªç”±è§†ç‚¹å¯¼èˆªã€‚ç„¶è€Œï¼Œä½¿ç”¨è¿åŠ¨ç»“æ„å’Œ3DGSä¼˜åŒ–è¿›è¡Œå§¿æ€ä¼°è®¡ä»éœ€æ•°åˆ†é’Ÿåˆ°æ•°å°æ—¶çš„è®¡ç®—æ—¶é—´ã€‚ç»“åˆSLAMæ–¹æ³•çš„3DGSè™½ç„¶é€Ÿåº¦è¾ƒå¿«ï¼Œä½†åœ¨å®½åŸºçº¿å’Œå¤§åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å³æ—¶æ–¹æ³•ï¼Œåœ¨æ•è·åç«‹å³ç”Ÿæˆç›¸æœºå§¿æ€å’Œè®­ç»ƒå¥½çš„3DGSï¼Œèƒ½å¤Ÿå¤„ç†æœ‰åºç…§ç‰‡åºåˆ—çš„å¯†é›†å’Œå®½åŸºçº¿æ•è·åŠå¤§è§„æ¨¡åœºæ™¯ã€‚æˆ‘ä»¬é¦–å…ˆå¼•å…¥å¿«é€Ÿåˆå§‹å§¿æ€ä¼°è®¡ï¼Œåˆ©ç”¨å­¦ä¹ ç‰¹å¾å’ŒGPUå‹å¥½çš„å°å‹æŸè°ƒæ•´ã€‚æ¥ç€ï¼Œé€šè¿‡ç›´æ¥é‡‡æ ·é«˜æ–¯åŸè¯­çš„ä½ç½®å’Œå½¢çŠ¶ï¼Œé€æ­¥ç”Ÿæˆæ‰€éœ€çš„åŸè¯­ï¼Œæ˜¾è‘—åŠ é€Ÿè®­ç»ƒã€‚æˆ‘ä»¬çš„å¢é‡æ–¹æ³•é€šè¿‡å¼•å…¥å¯æ‰©å±•çš„è¾å°„åœºæ„å»ºï¼Œé€æ­¥èšç±»3DGSåŸè¯­ï¼Œå­˜å‚¨åœ¨é”šç‚¹ä¸­å¹¶ä»GPUå¸è½½ï¼Œå¤„ç†å¤§è§„æ¨¡åœºæ™¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è§„æ¨¡æ–°è§†è§’åˆæˆä¸­çš„å³æ—¶é‡å»ºé—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å§¿æ€ä¼°è®¡å’Œä¼˜åŒ–ä¸Šè€—æ—¶è¾ƒé•¿ï¼Œå½±å“å®æ—¶åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§å³æ—¶æ–¹æ³•ï¼Œé€šè¿‡å¿«é€Ÿå§¿æ€ä¼°è®¡å’Œé«˜æ•ˆçš„é«˜æ–¯åŸè¯­é‡‡æ ·ï¼Œèƒ½å¤Ÿåœ¨æ•è·åç«‹å³ç”Ÿæˆç›¸æœºå§¿æ€å’Œ3DGSï¼Œæ»¡è¶³å®æ—¶éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬å¿«é€Ÿåˆå§‹å§¿æ€ä¼°è®¡ã€ç›´æ¥é‡‡æ ·é«˜æ–¯åŸè¯­ã€å¢é‡ç”ŸæˆåŸè¯­ã€èšç±»å’Œå­˜å‚¨åŸè¯­ç­‰æ¨¡å—ï¼Œç¡®ä¿é«˜æ•ˆå¤„ç†å¤§è§„æ¨¡åœºæ™¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºç»“åˆäº†å¿«é€Ÿå§¿æ€ä¼°è®¡ä¸å¢é‡ç”Ÿæˆé«˜æ–¯åŸè¯­çš„ç­–ç•¥ï¼Œä½¿å¾—åœ¨å¤„ç†å¤§è§„æ¨¡åœºæ™¯æ—¶èƒ½å¤Ÿæ˜¾è‘—åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šé‡‡ç”¨äº†GPUå‹å¥½çš„å°å‹æŸè°ƒæ•´æ–¹æ³•è¿›è¡Œå§¿æ€ä¼°è®¡ï¼Œå¹¶é€šè¿‡é€æ­¥èšç±»å’Œåˆå¹¶é«˜æ–¯åŸè¯­æ¥ä¼˜åŒ–å­˜å‚¨å’Œè®¡ç®—æ•ˆç‡ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡åœ¨æ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†é€Ÿåº¦ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨å¤šç§æ•è·åœºæ™¯å’Œåœºæ™¯å¤§å°ä¸‹å®ç°å³æ—¶å¤„ç†ï¼Œä¿æŒå›¾åƒè´¨é‡ä¸é€Ÿåº¦çš„ç«äº‰åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®å’Œè®¡ç®—æœºå›¾å½¢å­¦ç­‰ï¼Œèƒ½å¤Ÿä¸ºå®æ—¶åœºæ™¯é‡å»ºå’Œè‡ªç”±è§†ç‚¹å¯¼èˆªæä¾›æŠ€æœ¯æ”¯æŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Radiance field methods such as 3D Gaussian Splatting (3DGS) allow easy reconstruction from photos, enabling free-viewpoint navigation. Nonetheless, pose estimation using Structure from Motion and 3DGS optimization can still each take between minutes and hours of computation after capture is complete. SLAM methods combined with 3DGS are fast but struggle with wide camera baselines and large scenes. We present an on-the-fly method to produce camera poses and a trained 3DGS immediately after capture. Our method can handle dense and wide-baseline captures of ordered photo sequences and large-scale scenes. To do this, we first introduce fast initial pose estimation, exploiting learned features and a GPU-friendly mini bundle adjustment. We then introduce direct sampling of Gaussian primitive positions and shapes, incrementally spawning primitives where required, significantly accelerating training. These two efficient steps allow fast and robust joint optimization of poses and Gaussian primitives. Our incremental approach handles large-scale scenes by introducing scalable radiance field construction, progressively clustering 3DGS primitives, storing them in anchors, and offloading them from the GPU. Clustered primitives are progressively merged, keeping the required scale of 3DGS at any viewpoint. We evaluate our solution on a variety of datasets and show that our solution can provide on-the-fly processing of all the capture scenarios and scene sizes we target while remaining competitive with other methods that only handle specific capture styles or scene sizes in speed, image quality, or both.

