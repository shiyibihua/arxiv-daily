---
layout: default
title: MonkeyOCR: Document Parsing with a Structure-Recognition-Relation Triplet Paradigm
---

# MonkeyOCR: Document Parsing with a Structure-Recognition-Relation Triplet Paradigm

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05218" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.05218v1</a>
  <a href="https://arxiv.org/pdf/2506.05218.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05218v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05218v1', 'MonkeyOCR: Document Parsing with a Structure-Recognition-Relation Triplet Paradigm')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zhang Li, Yuliang Liu, Qiang Liu, Zhiyin Ma, Ziyang Zhang, Shuo Zhang, Zidun Guo, Jiarui Zhang, Xinyu Wang, Xiang Bai

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-05

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/Yuliang-Liu/MonkeyOCR)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MonkeyOCR‰ª•Ëß£ÂÜ≥ÊñáÊ°£Ëß£ÊûêÊïàÁéá‰∏éÂáÜÁ°ÆÊÄßÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÊñáÊ°£Ëß£Êûê` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `ÁªìÊûÑËØÜÂà´` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Êï∞ÊçÆÈõÜÊûÑÂª∫` `Êú∫Âô®Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñáÊ°£Ëß£ÊûêÊñπÊ≥ïÂæÄÂæÄ‰æùËµñÂ§çÊùÇÁöÑÂ§öÂ∑•ÂÖ∑ÁÆ°ÈÅìÔºåÊïàÁéá‰Ωé‰∏ã‰∏îÈöæ‰ª•Êâ©Â±ï„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫ÁöÑMonkeyOCRÈÄöËøáÁªìÊûÑ-ËØÜÂà´-ÂÖ≥Á≥ª‰∏âÂÖÉÁªÑËåÉÂºèÔºåÁÆÄÂåñ‰∫ÜÊñáÊ°£Ëß£ÊûêËøáÁ®ãÔºåÊèêÈ´ò‰∫ÜÂ§ÑÁêÜÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåMonkeyOCRÂú®Â§ö‰∏™‰ªªÂä°‰∏äË∂ÖË∂ä‰∫ÜMinerUÔºåÁâπÂà´ÊòØÂú®Â§ÑÁêÜÂÖ¨ÂºèÂíåË°®Ê†ºÊó∂ÔºåÊèêÂçáÂπÖÂ∫¶ÊòæËëó„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êàë‰ª¨‰ªãÁªç‰∫ÜMonkeyOCRÔºå‰∏ÄÁßçÁî®‰∫éÊñáÊ°£Ëß£ÊûêÁöÑËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºåÈÄöËøáÂà©Áî®ÁªìÊûÑ-ËØÜÂà´-ÂÖ≥Á≥ªÔºàSRRÔºâ‰∏âÂÖÉÁªÑËåÉÂºèÔºåÊé®Âä®‰∫ÜËØ•È¢ÜÂüüÁöÑÊúÄÊñ∞ËøõÂ±ï„ÄÇËØ•ËÆæËÆ°ÁÆÄÂåñ‰∫ÜÂ§çÊùÇÁöÑÂ§öÂ∑•ÂÖ∑ÁÆ°ÈÅìÔºåÈÅøÂÖç‰∫Ü‰ΩøÁî®Â§ßÂûãÁ´ØÂà∞Á´ØÊ®°ÂûãÂ§ÑÁêÜÂÆåÊï¥È°µÈù¢ÁöÑ‰ΩéÊïà„ÄÇÂú®SRR‰∏≠ÔºåÊñáÊ°£Ëß£ÊûêË¢´ÊäΩË±°‰∏∫‰∏â‰∏™Âü∫Êú¨ÈóÆÈ¢ò‚Äî‚Äî‚ÄúÂÆÉÂú®Âì™ÈáåÔºü‚ÄùÔºàÁªìÊûÑÔºâ„ÄÅ‚ÄúÂÆÉÊòØ‰ªÄ‰πàÔºü‚ÄùÔºàËØÜÂà´ÔºâÂíå‚ÄúÂÆÉÊòØÂ¶Ç‰ΩïÁªÑÁªáÁöÑÔºü‚ÄùÔºàÂÖ≥Á≥ªÔºâÔºåÂàÜÂà´ÂØπÂ∫îÂ∏ÉÂ±ÄÂàÜÊûê„ÄÅÂÜÖÂÆπËØÜÂà´ÂíåÈÄªËæëÊéíÂ∫è„ÄÇËøôÁßçËÅöÁÑ¶ÁöÑÂàÜËß£ÊñπÊ≥ïÂú®‰∏çÁâ∫Áâ≤Á≤æÂ∫¶ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂÆûÁé∞‰∫ÜÈ´òÊïà„ÄÅÂèØÊâ©Â±ïÁöÑÂ§ÑÁêÜ„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫ÜMonkeyDocÔºåËøôÊòØËøÑ‰ªä‰∏∫Ê≠¢ÊúÄÂÖ®Èù¢ÁöÑÊñáÊ°£Ëß£ÊûêÊï∞ÊçÆÈõÜÔºåÂåÖÂê´390‰∏á‰∏™ÂÆû‰æãÔºåÊ∂µÁõñ‰∏≠Ëã±ÊñáÂçÅÁßçÊñáÊ°£Á±ªÂûã„ÄÇÂÆûÈ™åË°®ÊòéÔºåMonkeyOCRÂú®ÊåëÊàòÊÄßÂÜÖÂÆπÔºàÂ¶ÇÂÖ¨ÂºèÂíåË°®Ê†ºÔºâ‰∏äË°®Áé∞Âá∫ÊòæËëóÊèêÂçáÔºåÊï¥‰ΩìÊÄßËÉΩË∂ÖËøá‰∫ÜMinerU„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÊñáÊ°£Ëß£Êûê‰∏≠ÁöÑÊïàÁéá‰∏éÂáÜÁ°ÆÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂ¶ÇMinerU‰æùËµñÂ§çÊùÇÁöÑÂ§öÂ∑•ÂÖ∑ÁÆ°ÈÅìÔºåÂØºËá¥Â§ÑÁêÜÊïàÁéá‰Ωé‰∏ãÔºå‰∏îÂ§ßÂûãÁ´ØÂà∞Á´ØÊ®°ÂûãÂú®Â§ÑÁêÜÂÆåÊï¥È°µÈù¢Êó∂Â≠òÂú®ÊÄßËÉΩÁì∂È¢à„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑMonkeyOCRÈÄöËøáÁªìÊûÑ-ËØÜÂà´-ÂÖ≥Á≥ªÔºàSRRÔºâ‰∏âÂÖÉÁªÑËåÉÂºèÔºåÂ∞ÜÊñáÊ°£Ëß£ÊûêÂàÜËß£‰∏∫‰∏â‰∏™Âü∫Êú¨ÈóÆÈ¢òÔºå‰ªéËÄåÁÆÄÂåñ‰∫ÜÂ§ÑÁêÜÊµÅÁ®ãÂπ∂ÊèêÈ´ò‰∫ÜÊïàÁéá„ÄÇËøôÊ†∑ÁöÑËÆæËÆ°‰ΩøÂæóÊ®°ÂûãËÉΩÂ§ü‰∏ìÊ≥®‰∫éÊØè‰∏™Â≠ê‰ªªÂä°ÔºåÈÅøÂÖç‰∫ÜÂÖ®Â±Ä‰ºòÂåñÁöÑÂ§çÊùÇÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMonkeyOCRÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÁªìÊûÑÂàÜÊûêÔºàÁ°ÆÂÆöÂÖÉÁ¥†‰ΩçÁΩÆÔºâ„ÄÅÂÜÖÂÆπËØÜÂà´ÔºàËØÜÂà´ÊñáÊ°£ÂÜÖÂÆπÔºâÂíåÂÖ≥Á≥ªÂàÜÊûêÔºàÁêÜËß£ÂÜÖÂÆπ‰πãÈó¥ÁöÑÈÄªËæëÂÖ≥Á≥ªÔºâ„ÄÇÈÄöËøáËøôÁßçÊ®°ÂùóÂåñËÆæËÆ°ÔºåÊ®°ÂûãËÉΩÂ§üÈ´òÊïàÂ§ÑÁêÜÊñáÊ°£„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éSRR‰∏âÂÖÉÁªÑËåÉÂºèÁöÑÂºïÂÖ•ÔºåÂÆÉ‰∏éÁé∞ÊúâÊñπÊ≥ïÁöÑÊú¨Ë¥®Âå∫Âà´Âú®‰∫éÂ∞ÜÊñáÊ°£Ëß£Êûê‰ªªÂä°ÁªÜÂåñ‰∏∫‰∏â‰∏™Áã¨Á´ã‰ΩÜÁõ∏ÂÖ≥ÁöÑÂ≠ê‰ªªÂä°Ôºå‰ªéËÄåÂÆûÁé∞‰∫ÜÊõ¥È´òÁöÑÂ§ÑÁêÜÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏äÔºåMonkeyOCR‰ΩøÁî®‰∫Ü3BÂèÇÊï∞ÁöÑÁªìÊûÑÔºåËÉΩÂ§üÂú®Âçï‰∏™NVIDIA 3090 GPU‰∏äÈ´òÊïàÊé®ÁêÜ„ÄÇÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁªèËøá‰ºòÂåñÔºå‰ª•Á°Æ‰øùÂú®Â§ÑÁêÜÂ§çÊùÇÊñáÊ°£Êó∂ÁöÑÈ´òÊïàÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåËÆ≠ÁªÉÁ≠ñÁï•Â∞ÜÂú®ÂêéÁª≠ÁöÑ‰ª£Á†ÅÂíåÊ®°ÂûãÂèëÂ∏É‰∏≠Êèê‰æõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMonkeyOCRÂú®ÊñáÊ°£Ëß£Êûê‰ªªÂä°‰∏äÂπ≥ÂùáË∂ÖË∂äMinerU 5.1%ÔºåÂú®Â§ÑÁêÜÂÖ¨ÂºèÂíåË°®Ê†ºÁ≠âÊåëÊàòÊÄßÂÜÖÂÆπÊó∂ÂàÜÂà´ÊèêÂçá15.0%Âíå8.6%„ÄÇÊ≠§Â§ñÔºåMonkeyOCRÁöÑÂ§ÑÁêÜÈÄüÂ∫¶‰∏∫ÊØèÁßí0.84È°µÔºåÊòæËëóÂø´‰∫éMinerUÁöÑ0.65È°µÂíåQwen2.5-VL-7BÁöÑ0.12È°µ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MonkeyOCRÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÊñáÊ°£Ëá™Âä®ÂåñÂ§ÑÁêÜ„ÄÅ‰ø°ÊÅØÊèêÂèñ„ÄÅÊô∫ËÉΩÊêúÁ¥¢ÂºïÊìéÁ≠â„ÄÇÂÖ∂È´òÊïàÁöÑÊñáÊ°£Ëß£ÊûêËÉΩÂäõÂèØ‰ª•Â§ßÂπÖÊèêÂçá‰ºÅ‰∏öÂú®ÊñáÊ°£ÁÆ°ÁêÜÂíåÊï∞ÊçÆÂàÜÊûêÊñπÈù¢ÁöÑÊïàÁéáÔºåÊú™Êù•ÂèØËÉΩÂú®Ê≥ïÂæã„ÄÅÈáëËûç„ÄÅÊïôËÇ≤Á≠âË°å‰∏ö‰∫ßÁîüÊ∑±ËøúÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We introduce MonkeyOCR, a vision-language model for document parsing that advances the state of the art by leveraging a Structure-Recognition-Relation (SRR) triplet paradigm. This design simplifies what would otherwise be a complex multi-tool pipeline (as in MinerU's modular approach) and avoids the inefficiencies of processing full pages with giant end-to-end models (e.g., large multimodal LLMs like Qwen-VL). In SRR, document parsing is abstracted into three fundamental questions - "Where is it?" (structure), "What is it?" (recognition), and "How is it organized?" (relation) - corresponding to layout analysis, content identification, and logical ordering. This focused decomposition balances accuracy and speed: it enables efficient, scalable processing without sacrificing precision. To train and evaluate this approach, we introduce the MonkeyDoc (the most comprehensive document parsing dataset to date), with 3.9 million instances spanning over ten document types in both Chinese and English. Experiments show that MonkeyOCR outperforms MinerU by an average of 5.1%, with particularly notable improvements on challenging content such as formulas (+15.0%) and tables (+8.6%). Remarkably, our 3B-parameter model surpasses much larger and top-performing models, including Qwen2.5-VL (72B) and Gemini 2.5 Pro, achieving state-of-the-art average performance on English document parsing tasks. In addition, MonkeyOCR processes multi-page documents significantly faster (0.84 pages per second compared to 0.65 for MinerU and 0.12 for Qwen2.5-VL-7B). The 3B model can be efficiently deployed for inference on a single NVIDIA 3090 GPU. Code and models will be released at https://github.com/Yuliang-Liu/MonkeyOCR.

