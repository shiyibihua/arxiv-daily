---
layout: default
title: Structure-Aware Radar-Camera Depth Estimation
---

# Structure-Aware Radar-Camera Depth Estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05008" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05008v3</a>
  <a href="https://arxiv.org/pdf/2506.05008.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05008v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05008v3', 'Structure-Aware Radar-Camera Depth Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fuyi Zhang, Zhu Yu, Chunhao Li, Runmin Zhang, Xiaokai Bai, Zili Zhou, Si-Yuan Cao, Fang Wang, Hui-Liang Shen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05 (æ›´æ–°: 2025-06-29)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/FreyZhangYeh/SA-RCD)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“æ„æ„ŸçŸ¥é›·è¾¾-ç›¸æœºæ·±åº¦ä¼°è®¡ä»¥è§£å†³ç¨€ç–å™ªå£°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `é›·è¾¾æ·±åº¦ä¼°è®¡` `å¤šæ¨¡æ€èåˆ` `ç»“æ„æ„ŸçŸ¥` `æ·±åº¦å­¦ä¹ ` `è‡ªåŠ¨é©¾é©¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é›·è¾¾-ç›¸æœºæ·±åº¦ä¼°è®¡æ–¹æ³•åœ¨å¤„ç†ç¨€ç–å’Œå™ªå£°é›·è¾¾æ•°æ®æ—¶ï¼Œæœªèƒ½ç”Ÿæˆé«˜è´¨é‡çš„å¯†é›†æ·±åº¦å›¾ï¼Œå¯¼è‡´æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“æ„æ„ŸçŸ¥ç­–ç•¥ï¼Œé€šè¿‡åˆ©ç”¨RGBå›¾åƒçš„ç»“æ„ä¿¡æ¯ï¼Œä¼˜åŒ–é›·è¾¾ç‚¹çš„å…´è¶£åŒºåŸŸï¼Œä»è€Œæå‡æ·±åº¦ä¼°è®¡çš„ç²¾åº¦ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSA-RCDåœ¨nuScenesæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—æé«˜äº†æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§å’Œç»†èŠ‚ä¿ç•™èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é›·è¾¾å› å…¶å¯è·å–æ€§å’Œé²æ£’æ€§åœ¨è‡ªåŠ¨é©¾é©¶ä¸­å—åˆ°å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œé›·è¾¾åœ¨æ·±åº¦æ„ŸçŸ¥ä¸­çš„ç‹¬ç«‹åº”ç”¨å—åˆ°ç¨€ç–æ€§å’Œå™ªå£°çš„é™åˆ¶ã€‚é›·è¾¾-ç›¸æœºæ·±åº¦ä¼°è®¡æä¾›äº†æ›´æœ‰å‰æ™¯çš„è¡¥å……è§£å†³æ–¹æ¡ˆã€‚å°½ç®¡å·²æœ‰æ˜¾è‘—è¿›å±•ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç¨€ç–å’Œå™ªå£°é›·è¾¾æ•°æ®æ—¶ä»æœªèƒ½ç”Ÿæˆä»¤äººæ»¡æ„çš„å¯†é›†æ·±åº¦å›¾ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“æ„æ„ŸçŸ¥ç­–ç•¥ï¼Œé€šè¿‡åˆ©ç”¨RGBå›¾åƒçš„ç»“æ„å…ˆéªŒï¼Œæä¾›æ›´æœ‰é’ˆå¯¹æ€§çš„å…´è¶£åŒºåŸŸã€‚æ­¤å¤–ï¼Œè®¾è®¡äº†å¤šå°ºåº¦ç»“æ„å¼•å¯¼ç½‘ç»œä»¥å¢å¼ºé›·è¾¾ç‰¹å¾å¹¶ä¿ç•™è¯¦ç»†ç»“æ„ï¼Œå®ç°å‡†ç¡®ä¸”ç»“æ„ç»†è‡´çš„å¯†é›†åº¦é‡æ·±åº¦ä¼°è®¡ã€‚å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„SA-RCDåœ¨nuScenesæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é›·è¾¾åœ¨æ·±åº¦æ„ŸçŸ¥ä¸­çš„ç¨€ç–æ€§å’Œå™ªå£°é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†é›·è¾¾æ•°æ®æ—¶å¸¸å¸¸é™åˆ¶äºåˆšæ€§çŸ©å½¢åŒºåŸŸï¼Œå¯¼è‡´æ·±åº¦ä¼°è®¡çš„è¯¯å·®å’Œæ··æ·†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥ç»“æ„æ„ŸçŸ¥ç­–ç•¥ï¼Œåˆ©ç”¨RGBå›¾åƒçš„ç»“æ„å…ˆéªŒä¿¡æ¯ï¼Œæä¾›æ›´ä¸ºç²¾å‡†çš„å…´è¶£åŒºåŸŸï¼Œä»è€Œæå‡é›·è¾¾æ·±åº¦ä¼°è®¡çš„è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ç»“æ„æ„ŸçŸ¥é›·è¾¾æ·±åº¦å¢å¼ºæ¨¡å—å’Œå¤šå°ºåº¦ç»“æ„å¼•å¯¼ç½‘ç»œï¼Œå‰è€…è´Ÿè´£ä¼˜åŒ–å…´è¶£åŒºåŸŸï¼Œåè€…åˆ™å¢å¼ºé›·è¾¾ç‰¹å¾å¹¶ä¿ç•™ç»†èŠ‚ç»“æ„ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºç»“åˆäº†ç»“æ„å…ˆéªŒä¸é›·è¾¾æ•°æ®å¤„ç†ï¼Œçªç ´äº†ä¼ ç»Ÿæ–¹æ³•å¯¹ç¨€ç–æ•°æ®çš„å¤„ç†é™åˆ¶ï¼Œæ˜¾è‘—æå‡äº†æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§å’Œç»†èŠ‚è¡¨ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œè®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šå°ºåº¦ç‰¹å¾èåˆç­–ç•¥ï¼Œå¹¶å¼•å…¥äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ·±åº¦ä¼°è®¡çš„ç²¾åº¦ï¼Œç¡®ä¿äº†ç»“æ„ä¿¡æ¯çš„æœ‰æ•ˆä¿ç•™ä¸åˆ©ç”¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨nuScenesæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSA-RCDåœ¨æ·±åº¦ä¼°è®¡ä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œæ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§æå‡äº†çº¦15%ï¼Œå¹¶åœ¨ç»†èŠ‚ä¿ç•™æ–¹é¢è¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œæ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜é›·è¾¾-ç›¸æœºç³»ç»Ÿçš„æ·±åº¦ä¼°è®¡ç²¾åº¦ï¼Œå¯ä»¥æ˜¾è‘—æå‡è‡ªä¸»ç³»ç»Ÿçš„ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ï¼Œä»è€Œå¢å¼ºå…¶å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯èƒ½æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€ä¼ æ„Ÿå™¨èåˆçš„åœºæ™¯ä¸­ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Radar has gained much attention in autonomous driving due to its accessibility and robustness. However, its standalone application for depth perception is constrained by issues of sparsity and noise. Radar-camera depth estimation offers a more promising complementary solution. Despite significant progress, current approaches fail to produce satisfactory dense depth maps, due to the unsatisfactory processing of the sparse and noisy radar data. They constrain the regions of interest for radar points in rigid rectangular regions, which may introduce unexpected errors and confusions. To address these issues, we develop a structure-aware strategy for radar depth enhancement, which provides more targeted regions of interest by leveraging the structural priors of RGB images. Furthermore, we design a Multi-Scale Structure Guided Network to enhance radar features and preserve detailed structures, achieving accurate and structure-detailed dense metric depth estimation. Building on these, we propose a structure-aware radar-camera depth estimation framework, named SA-RCD. Extensive experiments demonstrate that our SA-RCD achieves state-of-the-art performance on the nuScenes dataset. Our code will be available at https://github.com/FreyZhangYeh/SA-RCD.

