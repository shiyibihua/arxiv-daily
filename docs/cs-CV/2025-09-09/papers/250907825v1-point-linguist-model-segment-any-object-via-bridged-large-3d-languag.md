---
layout: default
title: Point Linguist Model: Segment Any Object via Bridged Large 3D-Language Model
---

# Point Linguist Model: Segment Any Object via Bridged Large 3D-Language Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07825" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07825v1</a>
  <a href="https://arxiv.org/pdf/2509.07825.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07825v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07825v1', 'Point Linguist Model: Segment Any Object via Bridged Large 3D-Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhuoxu Huang, Mingqi Gao, Jungong Han

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPoint Linguist Modelï¼Œé€šè¿‡æ¡¥æ¥3D-è¯­è¨€å¤§æ¨¡å‹å®ç°ä»»æ„ç‰©ä½“åˆ†å‰²**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dç‰©ä½“åˆ†å‰²` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç‚¹äº‘å¤„ç†` `è¯­ä¹‰ç†è§£` `å‡ ä½•æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨3Dç‰©ä½“åˆ†å‰²ä¸­ï¼ŒLLMä¸3Dç‚¹äº‘çš„è¡¨ç¤ºä¸å¯¹é½ï¼Œå¯¼è‡´è¾“å…¥æ—¶è¯­ä¹‰ä¿¡æ¯å¼±åŒ–ï¼Œè¾“å‡ºæ—¶ç²¾åº¦æŸå¤±ã€‚
2. PLMé€šè¿‡Object-centric Discriminative Representation (OcDR)å­¦ä¹ ç‰©ä½“ä¸­å¿ƒtokensï¼Œå¹¶ä½¿ç”¨Geometric Reactivation Decoder (GRD)èåˆå‡ ä½•ä¿¡æ¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒPLMåœ¨å¤šä¸ªæ•°æ®é›†å’Œä»»åŠ¡ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºPoint Linguist Model (PLM)ï¼Œæ—¨åœ¨è§£å†³3Dç‰©ä½“åˆ†å‰²ä¸­å¤§å‹è¯­è¨€æ¨¡å‹(LLM)ä¸3Dç‚¹äº‘ä¹‹é—´è¡¨ç¤ºä¸å¯¹é½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å—é™äºè¾“å…¥å’Œè¾“å‡ºé˜¶æ®µçš„ä¸å¯¹é½ï¼šè¾“å…¥æ—¶ï¼Œå¯†é›†çš„ç‚¹äº‘å—éœ€è¦å¤§é‡é¢„å¯¹é½ï¼Œå‰Šå¼±äº†ç‰©ä½“çº§åˆ«çš„è¯­ä¹‰å¹¶æ··æ·†äº†ç›¸ä¼¼çš„å¹²æ‰°ç‰©ï¼›è¾“å‡ºæ—¶ï¼Œé¢„æµ‹ä»…ä¾èµ–äºå¯†é›†ç‰¹å¾ï¼Œç¼ºä¹æ˜ç¡®çš„å‡ ä½•çº¿ç´¢ï¼Œå¯¼è‡´ç²¾ç»†ç²¾åº¦æŸå¤±ã€‚PLMé€šè¿‡å¼•å…¥Object-centric Discriminative Representation (OcDR)å­¦ä¹ ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„tokensï¼Œæ•æ‰ç›®æ ‡è¯­ä¹‰å’Œåœºæ™¯å…³ç³»ï¼Œç¼“è§£ä¸å¯¹é½ï¼Œå¢å¼ºå¯¹å¹²æ‰°ç‰©çš„é²æ£’æ€§ï¼Œå¹¶ä¿ƒè¿›LLMä¸­çš„è¯­ä¹‰çº§åˆ«æ¨ç†ã€‚æ­¤å¤–ï¼ŒGeometric Reactivation Decoder (GRD)ç»“åˆOcDR tokenså’Œç›¸åº”çš„å¯†é›†ç‰¹å¾é¢„æµ‹maskï¼Œä¿ç•™äº†å…¨é¢çš„å¯†é›†ç‰¹å¾ã€‚å®éªŒè¡¨æ˜ï¼ŒPLMåœ¨ScanNetv2ä¸Šå®ç°äº†+7.3 mIoUçš„æå‡ï¼Œåœ¨Multi3DReferä¸Šå®ç°äº†+6.0 mIoUçš„æå‡ï¼Œå¹¶åœ¨7ä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æŒç»­çš„æ”¶ç›Šï¼Œè¯æ˜äº†å…¶åœ¨é²æ£’3Dç†è§£æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Dç‰©ä½“åˆ†å‰²æ–¹æ³•åœ¨åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¶ï¼Œé¢ä¸´LLMå¤„ç†é«˜å±‚è¯­ä¹‰tokenä¸3Dç‚¹äº‘ä»…åŒ…å«å¯†é›†å‡ ä½•ç»“æ„ä¹‹é—´çš„è¡¨ç¤ºä¸å¯¹é½é—®é¢˜ã€‚è¿™ç§ä¸å¯¹é½é™åˆ¶äº†è¾“å…¥å’Œè¾“å‡ºä¸¤ä¸ªé˜¶æ®µã€‚åœ¨è¾“å…¥é˜¶æ®µï¼Œéœ€è¦å¯¹å¯†é›†çš„ç‚¹äº‘å—è¿›è¡Œé¢„å¯¹é½ï¼Œè¿™å‰Šå¼±äº†ç‰©ä½“çº§åˆ«çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶å®¹æ˜“æ··æ·†ç›¸ä¼¼çš„å¹²æ‰°ç‰©ã€‚åœ¨è¾“å‡ºé˜¶æ®µï¼Œé¢„æµ‹ä»…ä»…ä¾èµ–äºå¯†é›†ç‰¹å¾ï¼Œç¼ºä¹æ˜ç¡®çš„å‡ ä½•çº¿ç´¢ï¼Œå¯¼è‡´åˆ†å‰²ç²¾åº¦ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼¥åˆLLMå’Œ3Dç‚¹äº‘ä¹‹é—´çš„è¡¨ç¤ºå·®è·ï¼Œæ— éœ€å¤§è§„æ¨¡çš„3D-æ–‡æœ¬æˆ–3D-å›¾åƒé¢„å¯¹é½ã€‚é€šè¿‡å­¦ä¹ ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„åˆ¤åˆ«æ€§è¡¨ç¤ºï¼ˆObject-centric Discriminative Representation, OcDRï¼‰ï¼Œä½¿å¾—3Dç‚¹äº‘èƒ½å¤Ÿæ›´å¥½åœ°è¡¨è¾¾ç‰©ä½“çº§åˆ«çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä»è€Œä¸LLMçš„tokenå¯¹é½ã€‚åŒæ—¶ï¼Œåˆ©ç”¨å‡ ä½•é‡æ¿€æ´»è§£ç å™¨ï¼ˆGeometric Reactivation Decoder, GRDï¼‰å°†LLMæ¨ç†å‡ºçš„å‡ ä½•ä¿¡æ¯ä¸åŸå§‹çš„å¯†é›†ç‰¹å¾ç›¸ç»“åˆï¼Œä»¥æé«˜åˆ†å‰²çš„ç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPLMçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ç‰¹å¾æå–æ¨¡å—ï¼Œç”¨äºæå–3Dç‚¹äº‘çš„å¯†é›†ç‰¹å¾ï¼›2) Object-centric Discriminative Representation (OcDR)æ¨¡å—ï¼Œç”¨äºå­¦ä¹ ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„åˆ¤åˆ«æ€§è¡¨ç¤ºï¼›3) LLMæ¨ç†æ¨¡å—ï¼Œåˆ©ç”¨LLMå¯¹OcDR tokensè¿›è¡Œè¯­ä¹‰æ¨ç†ï¼›4) Geometric Reactivation Decoder (GRD)æ¨¡å—ï¼Œå°†LLMæ¨ç†å‡ºçš„å‡ ä½•ä¿¡æ¯ä¸åŸå§‹çš„å¯†é›†ç‰¹å¾ç›¸ç»“åˆï¼Œç”Ÿæˆæœ€ç»ˆçš„åˆ†å‰²maskã€‚

**å…³é”®åˆ›æ–°**ï¼šPLMæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºObject-centric Discriminative Representation (OcDR)å’ŒGeometric Reactivation Decoder (GRD)çš„è®¾è®¡ã€‚OcDRé€šè¿‡å­¦ä¹ ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„tokensï¼Œç¼“è§£äº†LLMå’Œ3Dç‚¹äº‘ä¹‹é—´çš„è¡¨ç¤ºä¸å¯¹é½é—®é¢˜ï¼Œå¢å¼ºäº†å¯¹å¹²æ‰°ç‰©çš„é²æ£’æ€§ã€‚GRDåˆ™é€šè¿‡å°†LLMæ¨ç†å‡ºçš„å‡ ä½•ä¿¡æ¯ä¸åŸå§‹çš„å¯†é›†ç‰¹å¾ç›¸ç»“åˆï¼Œæé«˜äº†åˆ†å‰²çš„ç²¾åº¦ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒPLMæ— éœ€å¤§è§„æ¨¡çš„é¢„å¯¹é½ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨LLMçš„è¯­ä¹‰æ¨ç†èƒ½åŠ›å’Œ3Dç‚¹äº‘çš„å‡ ä½•ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šOcDRé‡‡ç”¨hard negative-awareè®­ç»ƒç›®æ ‡ï¼Œé¼“åŠ±å­¦ä¹ åˆ°çš„tokensèƒ½å¤ŸåŒºåˆ†ç›®æ ‡ç‰©ä½“å’Œç›¸ä¼¼çš„å¹²æ‰°ç‰©ã€‚GRDé€šè¿‡å°†OcDR tokensæºå¸¦çš„LLMæ¨ç†å‡ºçš„å‡ ä½•ä¿¡æ¯ä¸å¯¹åº”çš„å¯†é›†ç‰¹å¾è¿›è¡Œèåˆï¼Œä¿ç•™äº†å…¨é¢çš„å¯†é›†ç‰¹å¾ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼Œä¾‹å¦‚æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼Œä»¥åŠOcDRå’ŒGRDä¸­ä½¿ç”¨çš„å…·ä½“ç½‘ç»œå±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PLMåœ¨ScanNetv2å’ŒMulti3DReferæ•°æ®é›†ä¸Šåˆ†åˆ«å–å¾—äº†+7.3 mIoUå’Œ+6.0 mIoUçš„æ˜¾è‘—æå‡ã€‚æ­¤å¤–ï¼Œåœ¨åŒ…å«3D referring segmentationç­‰4ä¸ªä¸åŒä»»åŠ¡çš„7ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒPLMå‡å–å¾—äº†æŒç»­çš„æ”¶ç›Šï¼Œè¯æ˜äº†å…¶åœ¨é²æ£’3Dç†è§£æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒPLMèƒ½å¤Ÿæœ‰æ•ˆåœ°ç¼“è§£LLMå’Œ3Dç‚¹äº‘ä¹‹é—´çš„è¡¨ç¤ºä¸å¯¹é½é—®é¢˜ï¼Œå¹¶æé«˜3Dç‰©ä½“åˆ†å‰²çš„ç²¾åº¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PLMåœ¨3Dåœºæ™¯ç†è§£æ–¹é¢å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰ã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å‘¨å›´ç¯å¢ƒï¼Œä»è€Œå®ç°æ›´æ™ºèƒ½çš„äº¤äº’å’Œå¯¼èˆªã€‚åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼ŒPLMå¯ä»¥æé«˜è½¦è¾†å¯¹å‘¨å›´ç‰©ä½“çš„è¯†åˆ«å’Œåˆ†å‰²ç²¾åº¦ï¼Œä»è€Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚åœ¨VR/ARé¢†åŸŸï¼ŒPLMå¯ä»¥ç”¨äºåˆ›å»ºæ›´é€¼çœŸçš„3Dåœºæ™¯å’Œæ›´è‡ªç„¶çš„äº¤äº’ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> 3D object segmentation with Large Language Models (LLMs) has become a prevailing paradigm due to its broad semantics, task flexibility, and strong generalization. However, this paradigm is hindered by representation misalignment: LLMs process high-level semantic tokens, whereas 3D point clouds convey only dense geometric structures. In prior methods, misalignment limits both input and output. At the input stage, dense point patches require heavy pre-alignment, weakening object-level semantics and confusing similar distractors. At the output stage, predictions depend only on dense features without explicit geometric cues, leading to a loss of fine-grained accuracy. To address these limitations, we present the Point Linguist Model (PLM), a general framework that bridges the representation gap between LLMs and dense 3D point clouds without requiring large-scale pre-alignment between 3D-text or 3D-images. Specifically, we introduce Object-centric Discriminative Representation (OcDR), which learns object-centric tokens that capture target semantics and scene relations under a hard negative-aware training objective. This mitigates the misalignment between LLM tokens and 3D points, enhances resilience to distractors, and facilitates semantic-level reasoning within LLMs. For accurate segmentation, we introduce the Geometric Reactivation Decoder (GRD), which predicts masks by combining OcDR tokens carrying LLM-inferred geometry with corresponding dense features, preserving comprehensive dense features throughout the pipeline. Extensive experiments show that PLM achieves significant improvements of +7.3 mIoU on ScanNetv2 and +6.0 mIoU on Multi3DRefer for 3D referring segmentation, with consistent gains across 7 benchmarks spanning 4 different tasks, demonstrating the effectiveness of comprehensive object-centric reasoning for robust 3D understanding.

