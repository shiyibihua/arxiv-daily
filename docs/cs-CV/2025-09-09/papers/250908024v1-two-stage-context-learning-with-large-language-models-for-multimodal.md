---
layout: default
title: Two Stage Context Learning with Large Language Models for Multimodal Stance Detection on Climate Change
---

# Two Stage Context Learning with Large Language Models for Multimodal Stance Detection on Climate Change

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.08024" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.08024v1</a>
  <a href="https://arxiv.org/pdf/2509.08024.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.08024v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.08024v1', 'Two Stage Context Learning with Large Language Models for Multimodal Stance Detection on Climate Change')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lata Pangtey, Omkar Kabde, Shahid Shafi Dar, Nagendra Kumar

**åˆ†ç±»**: cs.CV, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åŒé˜¶æ®µä¸Šä¸‹æ–‡å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºæ°”å€™å˜åŒ–å¤šæ¨¡æ€ç«‹åœºæ£€æµ‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `ç«‹åœºæ£€æµ‹` `å¤§è¯­è¨€æ¨¡å‹` `Transformer` `æ°”å€™å˜åŒ–` `ç¤¾äº¤åª’ä½“åˆ†æ` `å›¾åƒå­—å¹•ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç«‹åœºæ£€æµ‹æ–¹æ³•ä¸»è¦ä¾èµ–æ–‡æœ¬ä¿¡æ¯ï¼Œå¿½ç•¥äº†ç¤¾äº¤åª’ä½“ä¸­æ™®éå­˜åœ¨çš„è§†è§‰ä¿¡æ¯ï¼Œå¯¼è‡´æ€§èƒ½å—é™ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§åŒé˜¶æ®µä¸Šä¸‹æ–‡å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æå–æ–‡æœ¬æ‘˜è¦ï¼Œå¹¶ç”Ÿæˆé¢†åŸŸç›¸å…³çš„å›¾åƒæè¿°ï¼Œä»è€Œèåˆå¤šæ¨¡æ€ä¿¡æ¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨MultiClimateæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå„é¡¹æŒ‡æ ‡å‡ä¼˜äºç°æœ‰æœ€ä½³æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€æ•°å­—å¹³å°ä¸Šä¿¡æ¯çš„å¿«é€Ÿæ‰©æ•£ï¼Œç«‹åœºæ£€æµ‹å·²æˆä¸ºç¤¾äº¤åª’ä½“åˆ†æä¸­çš„ä¸€é¡¹å…³é”®æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¤§å¤šåªå…³æ³¨æ–‡æœ¬æ•°æ®ï¼Œè€Œç°å®ä¸–ç•Œçš„ç¤¾äº¤åª’ä½“å†…å®¹è¶Šæ¥è¶Šå¤šåœ°å°†æ–‡æœ¬ä¸è§†è§‰å…ƒç´ ç»“åˆï¼Œå› æ­¤éœ€è¦æ›´å…ˆè¿›çš„å¤šæ¨¡æ€æ–¹æ³•ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€ç«‹åœºæ£€æµ‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡åˆ†å±‚èåˆæ–¹æ³•æ•´åˆæ–‡æœ¬å’Œè§†è§‰ä¿¡æ¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä»æºæ–‡æœ¬ä¸­æ£€ç´¢ä¸ç«‹åœºç›¸å…³çš„æ‘˜è¦ï¼ŒåŒæ—¶é¢†åŸŸæ„ŸçŸ¥çš„å›¾åƒå­—å¹•ç”Ÿæˆå™¨åœ¨ç›®æ ‡ä¸»é¢˜çš„ä¸Šä¸‹æ–‡ä¸­è§£é‡Šè§†è§‰å†…å®¹ã€‚ç„¶åï¼Œé€šè¿‡ä¸€ä¸ªä¸“é—¨çš„Transformeræ¨¡å—ï¼Œå°†è¿™äº›æ¨¡æ€ä¸å›å¤æ–‡æœ¬è”åˆå»ºæ¨¡ï¼Œè¯¥æ¨¡å—æ•è·æ–‡æœ¬å’Œå›¾åƒä¹‹é—´çš„äº¤äº’ã€‚æ‰€æå‡ºçš„æ¨¡æ€èåˆæ¡†æ¶æ•´åˆäº†ä¸åŒçš„æ¨¡æ€ï¼Œä»¥ä¿ƒè¿›ç¨³å¥çš„ç«‹åœºåˆ†ç±»ã€‚æˆ‘ä»¬åœ¨MultiClimateæ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯¥æ•°æ®é›†æ˜¯æ°”å€™å˜åŒ–ç›¸å…³ç«‹åœºæ£€æµ‹çš„åŸºå‡†ï¼ŒåŒ…å«å¯¹é½çš„è§†é¢‘å¸§å’Œæ–‡æœ¬è®°å½•ã€‚æˆ‘ä»¬åˆ†åˆ«å®ç°äº†76.2%çš„å‡†ç¡®ç‡ã€76.3%çš„ç²¾ç¡®ç‡ã€76.2%çš„å¬å›ç‡å’Œ76.2%çš„F1åˆ†æ•°ï¼Œä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ°”å€™å˜åŒ–é¢†åŸŸç¤¾äº¤åª’ä½“å†…å®¹çš„å¤šæ¨¡æ€ç«‹åœºæ£€æµ‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–æ–‡æœ¬ä¿¡æ¯ï¼Œå¿½ç•¥äº†å›¾åƒç­‰è§†è§‰ä¿¡æ¯ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨å¤šæ¨¡æ€æ•°æ®ä¹‹é—´çš„å…³è”æ€§ï¼Œå¯¼è‡´ç«‹åœºæ£€æµ‹çš„å‡†ç¡®ç‡ä¸é«˜ã€‚æ­¤å¤–ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°èåˆæ–‡æœ¬å’Œå›¾åƒä¿¡æ¯ä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æå–æ–‡æœ¬ä¸­çš„å…³é”®ä¿¡æ¯ï¼Œå¹¶ç»“åˆé¢†åŸŸæ„ŸçŸ¥çš„å›¾åƒæè¿°ç”Ÿæˆå™¨æ¥ç†è§£å›¾åƒå†…å®¹ï¼Œä»è€Œå®ç°æ–‡æœ¬å’Œå›¾åƒä¿¡æ¯çš„æœ‰æ•ˆèåˆã€‚é€šè¿‡åŒé˜¶æ®µä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å¤šæ¨¡æ€æ•°æ®ä¹‹é—´çš„å…³è”æ€§ï¼Œä»è€Œæé«˜ç«‹åœºæ£€æµ‹çš„å‡†ç¡®ç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼šç”¨äºä»æºæ–‡æœ¬ä¸­æå–ä¸ç«‹åœºç›¸å…³çš„æ‘˜è¦ä¿¡æ¯ã€‚2) é¢†åŸŸæ„ŸçŸ¥çš„å›¾åƒå­—å¹•ç”Ÿæˆå™¨ï¼šç”¨äºåœ¨ç›®æ ‡ä¸»é¢˜çš„ä¸Šä¸‹æ–‡ä¸­è§£é‡Šè§†è§‰å†…å®¹ã€‚3) Transformeræ¨¡å—ï¼šç”¨äºè”åˆå»ºæ¨¡æ–‡æœ¬ï¼ˆåŒ…æ‹¬å›å¤æ–‡æœ¬å’ŒLLMç”Ÿæˆçš„æ‘˜è¦ï¼‰å’Œå›¾åƒä¿¡æ¯ï¼Œæ•è·å®ƒä»¬ä¹‹é—´çš„äº¤äº’ã€‚æ•´ä½“æµç¨‹æ˜¯å…ˆåˆ†åˆ«å¤„ç†æ–‡æœ¬å’Œå›¾åƒä¿¡æ¯ï¼Œç„¶åå°†å®ƒä»¬èåˆåœ¨ä¸€èµ·è¿›è¡Œç«‹åœºåˆ†ç±»ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºåŒé˜¶æ®µä¸Šä¸‹æ–‡å­¦ä¹ æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å’Œé¢†åŸŸæ„ŸçŸ¥çš„å›¾åƒå­—å¹•ç”Ÿæˆå™¨æ¥æå–æ–‡æœ¬å’Œå›¾åƒä¸­çš„å…³é”®ä¿¡æ¯ï¼Œä»è€Œå®ç°å¤šæ¨¡æ€ä¿¡æ¯çš„æœ‰æ•ˆèåˆã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å¤šæ¨¡æ€æ•°æ®ä¹‹é—´çš„å…³è”æ€§ï¼Œä»è€Œæé«˜ç«‹åœºæ£€æµ‹çš„å‡†ç¡®ç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­ä½¿ç”¨äº†Transformeræ¨¡å—æ¥å»ºæ¨¡æ–‡æœ¬å’Œå›¾åƒä¹‹é—´çš„äº¤äº’ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æ²¡æœ‰è¯¦ç»†æè¿°ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚æŸå¤±å‡½æ•°ä¹Ÿæœªæ˜ç¡®è¯´æ˜ï¼Œæ¨æµ‹å¯èƒ½ä½¿ç”¨äº†äº¤å‰ç†µæŸå¤±å‡½æ•°è¿›è¡Œåˆ†ç±»ä»»åŠ¡çš„è®­ç»ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨MultiClimateæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå‡†ç¡®ç‡è¾¾åˆ°76.2%ï¼Œç²¾ç¡®ç‡è¾¾åˆ°76.3%ï¼Œå¬å›ç‡è¾¾åˆ°76.2%ï¼ŒF1åˆ†æ•°è¾¾åˆ°76.2%ï¼Œå‡ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°èåˆæ–‡æœ¬å’Œå›¾åƒä¿¡æ¯ï¼Œæé«˜å¤šæ¨¡æ€ç«‹åœºæ£€æµ‹çš„å‡†ç¡®ç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºç¤¾äº¤åª’ä½“èˆ†æƒ…åˆ†æã€è™šå‡ä¿¡æ¯æ£€æµ‹ã€å…¬å…±å«ç”Ÿäº‹ä»¶ç›‘æµ‹ç­‰é¢†åŸŸã€‚é€šè¿‡å‡†ç¡®è¯†åˆ«ç”¨æˆ·å¯¹ç‰¹å®šäº‹ä»¶æˆ–è¯é¢˜çš„ç«‹åœºï¼Œå¯ä»¥å¸®åŠ©æ”¿åºœã€ä¼ä¸šå’Œç ”ç©¶æœºæ„æ›´å¥½åœ°äº†è§£ç¤¾ä¼šèˆ†è®ºï¼Œåˆ¶å®šåˆç†çš„æ”¿ç­–å’Œåº”å¯¹æªæ–½ï¼Œå¹¶åŠæ—¶å‘ç°å’Œå¤„ç†è™šå‡ä¿¡æ¯ï¼Œç»´æŠ¤ç¤¾ä¼šç¨³å®šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the rapid proliferation of information across digital platforms, stance detection has emerged as a pivotal challenge in social media analysis. While most of the existing approaches focus solely on textual data, real-world social media content increasingly combines text with visual elements creating a need for advanced multimodal methods. To address this gap, we propose a multimodal stance detection framework that integrates textual and visual information through a hierarchical fusion approach. Our method first employs a Large Language Model to retrieve stance-relevant summaries from source text, while a domain-aware image caption generator interprets visual content in the context of the target topic. These modalities are then jointly modeled along with the reply text, through a specialized transformer module that captures interactions between the texts and images. The proposed modality fusion framework integrates diverse modalities to facilitate robust stance classification. We evaluate our approach on the MultiClimate dataset, a benchmark for climate change-related stance detection containing aligned video frames and transcripts. We achieve accuracy of 76.2%, precision of 76.3%, recall of 76.2% and F1-score of 76.2%, respectively, outperforming existing state-of-the-art approaches.

