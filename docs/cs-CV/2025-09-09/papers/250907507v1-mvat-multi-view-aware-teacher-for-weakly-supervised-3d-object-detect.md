---
layout: default
title: MVAT: Multi-View Aware Teacher for Weakly Supervised 3D Object Detection
---

# MVAT: Multi-View Aware Teacher for Weakly Supervised 3D Object Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07507" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07507v1</a>
  <a href="https://arxiv.org/pdf/2509.07507.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07507v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07507v1', 'MVAT: Multi-View Aware Teacher for Weakly Supervised 3D Object Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Saad Lahlali, Alexandre Fournier Montgieux, Nicolas Granger, HervÃ© Le Borgne, Quoc Cuong Pham

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09

**å¤‡æ³¨**: Accepted at WACV 2026

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/CEA-LIST/MVAT)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MVATï¼šå¤šè§†è§’æ„ŸçŸ¥æ•™å¸ˆç½‘ç»œç”¨äºå¼±ç›‘ç£3Dç›®æ ‡æ£€æµ‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼±ç›‘ç£å­¦ä¹ ` `3Dç›®æ ‡æ£€æµ‹` `å¤šè§†è§’å­¦ä¹ ` `Teacher-Studentæ¨¡å‹` `ç‚¹äº‘èšåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¼±ç›‘ç£3Dç›®æ ‡æ£€æµ‹æ–¹æ³•ä¾èµ–2Dæ¡†ï¼Œå­˜åœ¨æŠ•å½±æ­§ä¹‰å’Œå•è§†è§’é®æŒ¡é—®é¢˜ï¼Œå¯¼è‡´3Dæ¡†ä¼°è®¡ä¸å‡†ç¡®ã€‚
2. MVATåˆ©ç”¨æ—¶åºå¤šè§†è§’ä¿¡æ¯ï¼Œèšåˆå¯¹è±¡ä¸­å¿ƒç‚¹äº‘æ„å»ºå®Œæ•´3Dè¡¨ç¤ºï¼Œå¹¶é‡‡ç”¨Teacher-Studentè’¸é¦æ¡†æ¶ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMVATåœ¨nuSceneså’ŒWaymo Openæ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œæ˜¾è‘—ç¼©å°äº†ä¸å…¨ç›‘ç£æ–¹æ³•çš„å·®è·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

3Dç›®æ ‡æ£€æµ‹ä¸­ï¼Œ3Dæ•°æ®æ ‡æ³¨æˆæœ¬é«˜æ˜‚ï¼Œå› æ­¤æœ¬æ–‡æå‡ºä¸€ç§å¼±ç›‘ç£æ ‡æ³¨æ–¹æ³•MVATï¼Œè¯¥æ–¹æ³•ä¾èµ–äºæ›´å®¹æ˜“è·å–çš„2Dæ¡†æ ‡æ³¨ã€‚ä»…ä¾èµ–2Dæ¡†ä¼šå¼•å…¥æŠ•å½±æ­§ä¹‰ï¼Œå› ä¸ºå•ä¸ª2Dæ¡†å¯èƒ½å¯¹åº”å¤šä¸ªæœ‰æ•ˆçš„3Då§¿æ€ã€‚æ­¤å¤–ï¼Œå•è§†è§’ä¸‹çš„éƒ¨åˆ†é®æŒ¡ä½¿å¾—å‡†ç¡®çš„3Dæ¡†ä¼°è®¡å˜å¾—å›°éš¾ã€‚MVATåˆ©ç”¨åºåˆ—æ•°æ®ä¸­çš„æ—¶åºå¤šè§†è§’ä¿¡æ¯æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚è¯¥æ–¹æ³•éšæ—¶é—´èšåˆä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„ç‚¹äº‘ï¼Œä»¥æ„å»ºå°½å¯èƒ½å¯†é›†å’Œå®Œæ•´çš„3Då¯¹è±¡è¡¨ç¤ºã€‚é‡‡ç”¨Teacher-Studentè’¸é¦èŒƒå¼ï¼šTeacherç½‘ç»œä»å•ä¸ªè§†è§’å­¦ä¹ ï¼Œä½†ç›®æ ‡æ¥è‡ªæ—¶åºèšåˆçš„é™æ€å¯¹è±¡ã€‚ç„¶åï¼ŒTeacherç”Ÿæˆé«˜è´¨é‡çš„ä¼ªæ ‡ç­¾ï¼ŒStudentå­¦ä¹ ä»å•ä¸ªè§†è§’é¢„æµ‹é™æ€å’Œç§»åŠ¨å¯¹è±¡ã€‚æ•´ä¸ªæ¡†æ¶åŒ…å«ä¸€ä¸ªå¤šè§†è§’2DæŠ•å½±æŸå¤±ï¼Œä»¥å¼ºåˆ¶é¢„æµ‹çš„3Dæ¡†ä¸æ‰€æœ‰å¯ç”¨çš„2Dæ ‡æ³¨ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚åœ¨nuSceneså’ŒWaymo Openæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMVATåœ¨å¼±ç›‘ç£3Dç›®æ ‡æ£€æµ‹æ–¹é¢å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—ç¼©å°äº†ä¸å…¨ç›‘ç£æ–¹æ³•çš„å·®è·ï¼Œè€Œæ— éœ€ä»»ä½•3Dæ¡†æ ‡æ³¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¼±ç›‘ç£3Dç›®æ ‡æ£€æµ‹ä¸­ï¼Œä»…ä½¿ç”¨2Dæ¡†æ ‡æ³¨å¸¦æ¥çš„3Då§¿æ€ä¼°è®¡ä¸å‡†ç¡®é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å—é™äº2Dåˆ°3Dçš„æŠ•å½±æ­§ä¹‰ï¼Œä»¥åŠå•è§†è§’ä¸‹ç›®æ ‡çš„éƒ¨åˆ†é®æŒ¡ï¼Œéš¾ä»¥è·å¾—é«˜è´¨é‡çš„3Dç›®æ ‡æ£€æµ‹ç»“æœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ—¶åºå¤šè§†è§’ä¿¡æ¯ï¼Œé€šè¿‡èšåˆå¤šä¸ªè§†è§’ä¸‹çš„ç‚¹äº‘æ•°æ®ï¼Œæ„å»ºæ›´å®Œæ•´ã€æ›´é²æ£’çš„3Dç›®æ ‡è¡¨ç¤ºã€‚åŒæ—¶ï¼Œé‡‡ç”¨Teacher-Studentè’¸é¦æ¡†æ¶ï¼Œåˆ©ç”¨èšåˆåçš„3Dä¿¡æ¯ç”Ÿæˆä¼ªæ ‡ç­¾ï¼ŒæŒ‡å¯¼Studentç½‘ç»œå­¦ä¹ å•è§†è§’ä¸‹çš„3Dç›®æ ‡æ£€æµ‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMVATæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) å¯¹è±¡ä¸­å¿ƒç‚¹äº‘èšåˆæ¨¡å—ï¼šå°†åŒä¸€å¯¹è±¡çš„ç‚¹äº‘åœ¨ä¸åŒæ—¶é—´æ­¥è¿›è¡Œèšåˆï¼Œå½¢æˆæ›´å®Œæ•´çš„3Dè¡¨ç¤ºã€‚2) Teacherç½‘ç»œï¼šåŸºäºèšåˆåçš„ç‚¹äº‘å­¦ä¹ 3Dç›®æ ‡æ£€æµ‹ï¼Œç”Ÿæˆé«˜è´¨é‡çš„ä¼ªæ ‡ç­¾ã€‚3) Studentç½‘ç»œï¼šå­¦ä¹ ä»å•è§†è§’ç‚¹äº‘é¢„æµ‹3Dç›®æ ‡ï¼Œå¹¶æ¥å—Teacherç½‘ç»œç”Ÿæˆçš„ä¼ªæ ‡ç­¾çš„æŒ‡å¯¼ã€‚4) å¤šè§†è§’2DæŠ•å½±æŸå¤±ï¼šå¼ºåˆ¶3Dé¢„æµ‹ç»“æœä¸æ‰€æœ‰å¯ç”¨çš„2Dæ ‡æ³¨ä¿æŒä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨æ—¶åºå¤šè§†è§’ä¿¡æ¯è¿›è¡Œç‚¹äº‘èšåˆï¼Œä»è€Œå…‹æœäº†å•è§†è§’ä¸‹ç›®æ ‡é®æŒ¡å’Œ2D-3DæŠ•å½±æ­§ä¹‰çš„é—®é¢˜ã€‚æ­¤å¤–ï¼ŒTeacher-Studentè’¸é¦æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å°†èšåˆåçš„3Dä¿¡æ¯ä¼ é€’ç»™å•è§†è§’Studentç½‘ç»œï¼Œæå‡äº†å¼±ç›‘ç£å­¦ä¹ çš„æ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMVATèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨å¼±ç›‘ç£ä¿¡æ¯ï¼Œç”Ÿæˆæ›´å‡†ç¡®çš„3Dç›®æ ‡æ£€æµ‹ç»“æœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç‚¹äº‘èšåˆæ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨å¯¹è±¡ä¸­å¿ƒçš„å¯¹é½æ–¹å¼ï¼Œä»¥ç¡®ä¿ä¸åŒè§†è§’ä¸‹çš„ç‚¹äº‘èƒ½å¤Ÿæ­£ç¡®åœ°èåˆã€‚åœ¨Teacherç½‘ç»œä¸­ï¼Œä½¿ç”¨äº†æ›´å¼ºçš„ç½‘ç»œç»“æ„å’Œæ›´é•¿çš„è®­ç»ƒæ—¶é—´ï¼Œä»¥ä¿è¯å…¶èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„ä¼ªæ ‡ç­¾ã€‚å¤šè§†è§’2DæŠ•å½±æŸå¤±çš„è®¾è®¡ï¼Œåˆ™ä¿è¯äº†3Dé¢„æµ‹ç»“æœä¸2Dæ ‡æ³¨çš„ä¸€è‡´æ€§ï¼Œè¿›ä¸€æ­¥æå‡äº†æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MVATåœ¨nuSceneså’ŒWaymo Openæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œåœ¨å¼±ç›‘ç£3Dç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸Šè¾¾åˆ°äº†SOTAæ°´å¹³ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMVATèƒ½å¤Ÿæ˜¾è‘—ç¼©å°ä¸å…¨ç›‘ç£æ–¹æ³•çš„æ€§èƒ½å·®è·ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MVATåœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚é€šè¿‡åˆ©ç”¨æ›´å®¹æ˜“è·å–çš„2Dæ ‡æ³¨ï¼Œé™ä½äº†3Dç›®æ ‡æ£€æµ‹çš„æ ‡æ³¨æˆæœ¬ï¼ŒåŠ é€Ÿäº†3Dç›®æ ‡æ£€æµ‹æŠ€æœ¯åœ¨å®é™…åœºæ™¯ä¸­çš„éƒ¨ç½²ã€‚è¯¥ç ”ç©¶çš„æˆæœæœ‰åŠ©äºæ¨åŠ¨è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸçš„å‘å±•ï¼Œæé«˜ç³»ç»Ÿçš„æ„ŸçŸ¥èƒ½åŠ›å’Œå®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Annotating 3D data remains a costly bottleneck for 3D object detection, motivating the development of weakly supervised annotation methods that rely on more accessible 2D box annotations. However, relying solely on 2D boxes introduces projection ambiguities since a single 2D box can correspond to multiple valid 3D poses. Furthermore, partial object visibility under a single viewpoint setting makes accurate 3D box estimation difficult. We propose MVAT, a novel framework that leverages temporal multi-view present in sequential data to address these challenges. Our approach aggregates object-centric point clouds across time to build 3D object representations as dense and complete as possible. A Teacher-Student distillation paradigm is employed: The Teacher network learns from single viewpoints but targets are derived from temporally aggregated static objects. Then the Teacher generates high quality pseudo-labels that the Student learns to predict from a single viewpoint for both static and moving objects. The whole framework incorporates a multi-view 2D projection loss to enforce consistency between predicted 3D boxes and all available 2D annotations. Experiments on the nuScenes and Waymo Open datasets demonstrate that MVAT achieves state-of-the-art performance for weakly supervised 3D object detection, significantly narrowing the gap with fully supervised methods without requiring any 3D box annotations. % \footnote{Code available upon acceptance} Our code is available in our public repository (\href{https://github.com/CEA-LIST/MVAT}{code}).

