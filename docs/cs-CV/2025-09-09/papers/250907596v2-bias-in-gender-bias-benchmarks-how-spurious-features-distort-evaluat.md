---
layout: default
title: Bias in Gender Bias Benchmarks: How Spurious Features Distort Evaluation
---

# Bias in Gender Bias Benchmarks: How Spurious Features Distort Evaluation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07596" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07596v2</a>
  <a href="https://arxiv.org/pdf/2509.07596.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07596v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07596v2', 'Bias in Gender Bias Benchmarks: How Spurious Features Distort Evaluation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yusuke Hirota, Ryo Hachiuma, Boyi Li, Ximing Lu, Michael Ross Boone, Boris Ivanovic, Yejin Choi, Marco Pavone, Yu-Chiang Frank Wang, Noa Garcia, Yuta Nakashima, Chao-Han Huck Yang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09 (æ›´æ–°: 2025-10-06)

**å¤‡æ³¨**: ICCV 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºæ€§åˆ«åè§åŸºå‡†æµ‹è¯•ä¸­çš„è™šå‡ç‰¹å¾é—®é¢˜ï¼Œå¹¶æå‡ºæ›´å¯é çš„è¯„ä¼°æ–¹æ³•ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ€§åˆ«åè§` `è§†è§‰-è¯­è¨€æ¨¡å‹` `å…¬å¹³æ€§è¯„ä¼°` `è™šå‡ç›¸å…³æ€§` `ç‰¹å¾æ•æ„Ÿæ€§` `åŸºå‡†æµ‹è¯•` `æ¨¡å‹é²æ£’æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ€§åˆ«åè§è¯„ä¼°åŸºå‡†å­˜åœ¨æ€§åˆ«ä¸éæ€§åˆ«ç‰¹å¾çš„è™šå‡ç›¸å…³æ€§ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœå¯èƒ½ä¸å‡†ç¡®ã€‚
2. é€šè¿‡æ‰°åŠ¨åŸºå‡†æµ‹è¯•ä¸­çš„éæ€§åˆ«ç‰¹å¾ï¼Œé‡åŒ–è¿™äº›ç‰¹å¾å¯¹æ€§åˆ«åè§è¯„ä¼°çš„å½±å“ï¼Œæ­ç¤ºå…¶æ•æ„Ÿæ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå³ä½¿å¾®å°çš„æ‰°åŠ¨ä¹Ÿä¼šæ˜¾è‘—æ”¹å˜åè§è¯„ä¼°ç»“æœï¼Œå»ºè®®æŠ¥å‘Šç‰¹å¾æ•æ„Ÿæ€§ä»¥æå‡è¯„ä¼°å¯é æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€åŸºç¡€æ¨¡å‹(VLMs)ä¸­çš„æ€§åˆ«åè§å¼•å‘äº†å¯¹å…¶å®‰å…¨éƒ¨ç½²çš„æ‹…å¿§ï¼Œé€šå¸¸ä½¿ç”¨å¸¦æœ‰çœŸå®ä¸–ç•Œå›¾åƒæ€§åˆ«æ³¨é‡Šçš„åŸºå‡†è¿›è¡Œè¯„ä¼°ã€‚ç„¶è€Œï¼Œè¿™äº›åŸºå‡†é€šå¸¸åŒ…å«æ€§åˆ«ä¸éæ€§åˆ«ç‰¹å¾ï¼ˆå¦‚ç‰©ä½“å’ŒèƒŒæ™¯ï¼‰ä¹‹é—´çš„è™šå‡ç›¸å…³æ€§ã€‚æœ¬æ–‡æ—¨åœ¨ç ”ç©¶è™šå‡ç‰¹å¾æ˜¯å¦ä¼šæ‰­æ›²æ€§åˆ«åè§è¯„ä¼°ã€‚é€šè¿‡ç³»ç»Ÿåœ°æ‰°åŠ¨å››ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†ï¼ˆCOCO-genderã€FACETã€MIAPå’ŒPHASEï¼‰ä»¥åŠå„ç§VLMsä¸­çš„éæ€§åˆ«ç‰¹å¾ï¼Œé‡åŒ–äº†å®ƒä»¬å¯¹åè§è¯„ä¼°çš„å½±å“ã€‚ç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯æœ€å°çš„æ‰°åŠ¨ï¼Œä¾‹å¦‚ä»…å±è”½10%çš„ç‰©ä½“æˆ–è½»å¾®æ¨¡ç³ŠèƒŒæ™¯ï¼Œä¹Ÿä¼šæ˜¾è‘—æ”¹å˜åè§åˆ†æ•°ï¼Œåœ¨ç”Ÿæˆå¼VLMsä¸­æŒ‡æ ‡å˜åŒ–é«˜è¾¾175%ï¼Œåœ¨CLIPå˜ä½“ä¸­é«˜è¾¾43%ã€‚è¿™è¡¨æ˜å½“å‰çš„åè§è¯„ä¼°é€šå¸¸åæ˜ äº†æ¨¡å‹å¯¹è™šå‡ç‰¹å¾çš„å“åº”ï¼Œè€Œä¸æ˜¯æ€§åˆ«åè§æœ¬èº«ï¼Œä»è€Œé™ä½äº†å…¶å¯é æ€§ã€‚ç”±äºåˆ›å»ºæ— è™šå‡ç‰¹å¾çš„åŸºå‡†å…·æœ‰æ ¹æœ¬æ€§çš„æŒ‘æˆ˜ï¼Œå»ºè®®åœ¨æŠ¥å‘Šåè§æŒ‡æ ‡çš„åŒæ—¶æŠ¥å‘Šç‰¹å¾æ•æ„Ÿæ€§æµ‹é‡ç»“æœï¼Œä»¥å®ç°æ›´å¯é çš„åè§è¯„ä¼°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰æ€§åˆ«åè§è¯„ä¼°ä¾èµ–äºå¸¦æœ‰æ€§åˆ«æ ‡æ³¨çš„å›¾åƒæ•°æ®é›†ã€‚ç„¶è€Œï¼Œè¿™äº›æ•°æ®é›†å¾€å¾€å­˜åœ¨â€œè™šå‡ç›¸å…³æ€§â€é—®é¢˜ï¼Œå³å›¾åƒä¸­çš„éæ€§åˆ«ç‰¹å¾ï¼ˆå¦‚ç‰©ä½“ã€åœºæ™¯ï¼‰ä¸æ€§åˆ«æ ‡ç­¾å­˜åœ¨ç»Ÿè®¡ä¸Šçš„å…³è”ã€‚è¿™å¯¼è‡´æ¨¡å‹å¯èƒ½å¹¶éçœŸæ­£å­¦ä¹ åˆ°æ€§åˆ«ç›¸å…³çš„ç‰¹å¾ï¼Œè€Œæ˜¯å­¦ä¹ åˆ°äº†è¿™äº›è™šå‡ç›¸å…³æ€§ï¼Œä»è€Œä½¿å¾—è¯„ä¼°ç»“æœäº§ç”Ÿåå·®ã€‚ç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆåŒºåˆ†æ¨¡å‹å¯¹çœŸå®æ€§åˆ«ç‰¹å¾å’Œè™šå‡ç›¸å…³ç‰¹å¾çš„å“åº”ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å¯é ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç³»ç»Ÿæ€§åœ°æ‰°åŠ¨å›¾åƒä¸­çš„éæ€§åˆ«ç‰¹å¾ï¼Œè§‚å¯Ÿæ¨¡å‹åè§è¯„ä¼°ç»“æœçš„å˜åŒ–ã€‚å¦‚æœæ¨¡å‹å¯¹è¿™äº›æ‰°åŠ¨éå¸¸æ•æ„Ÿï¼Œè¯´æ˜å…¶åè§è¯„ä¼°ç»“æœå¾ˆå¤§ç¨‹åº¦ä¸Šå—åˆ°è™šå‡ç›¸å…³æ€§çš„å½±å“ï¼Œè€ŒéçœŸæ­£çš„æ€§åˆ«åè§ã€‚é€šè¿‡é‡åŒ–è¿™ç§æ•æ„Ÿæ€§ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹çš„æ€§åˆ«åè§ç¨‹åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæœ¬æ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1ï¼‰é€‰æ‹©å¸¸ç”¨çš„æ€§åˆ«åè§è¯„ä¼°åŸºå‡†æ•°æ®é›†ï¼ˆCOCO-gender, FACET, MIAP, PHASEï¼‰ï¼›2ï¼‰é€‰æ‹©å¤šç§è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰è¿›è¡Œè¯„ä¼°ï¼ŒåŒ…æ‹¬ç”Ÿæˆå¼æ¨¡å‹å’ŒCLIPå˜ä½“ï¼›3ï¼‰è®¾è®¡å¤šç§æ‰°åŠ¨ç­–ç•¥ï¼Œé’ˆå¯¹å›¾åƒä¸­çš„éæ€§åˆ«ç‰¹å¾è¿›è¡Œä¿®æ”¹ï¼Œä¾‹å¦‚å±è”½ç‰©ä½“ã€æ¨¡ç³ŠèƒŒæ™¯ç­‰ï¼›4ï¼‰ä½¿ç”¨åŸå§‹å›¾åƒå’Œæ‰°åŠ¨åçš„å›¾åƒåˆ†åˆ«è¿›è¡Œåè§è¯„ä¼°ï¼Œè®¡ç®—åè§æŒ‡æ ‡çš„å˜åŒ–ï¼›5ï¼‰åˆ†æåè§æŒ‡æ ‡å˜åŒ–ä¸æ‰°åŠ¨ç¨‹åº¦ä¹‹é—´çš„å…³ç³»ï¼Œé‡åŒ–æ¨¡å‹å¯¹éæ€§åˆ«ç‰¹å¾çš„æ•æ„Ÿæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæ­ç¤ºäº†æ€§åˆ«åè§è¯„ä¼°ä¸­è™šå‡ç›¸å…³æ€§çš„é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§é€šè¿‡æ‰°åŠ¨éæ€§åˆ«ç‰¹å¾æ¥é‡åŒ–æ¨¡å‹å¯¹è¿™äº›è™šå‡ç›¸å…³æ€§æ•æ„Ÿæ€§çš„æ–¹æ³•ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡çš„æ–¹æ³•èƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹çš„çœŸå®æ€§åˆ«åè§ç¨‹åº¦ï¼Œé¿å…äº†è™šå‡ç›¸å…³æ€§å¸¦æ¥çš„å¹²æ‰°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ‰°åŠ¨ç­–ç•¥çš„è®¾è®¡ä¸Šï¼Œæœ¬æ–‡è€ƒè™‘äº†å¤šç§ä¸åŒçš„æ‰°åŠ¨æ–¹å¼ï¼ŒåŒ…æ‹¬ï¼š1ï¼‰ç‰©ä½“å±è”½ï¼šéšæœºå±è”½å›¾åƒä¸­çš„éƒ¨åˆ†ç‰©ä½“ï¼Œæ¨¡æ‹Ÿç‰©ä½“ç‰¹å¾çš„ç¼ºå¤±ï¼›2ï¼‰èƒŒæ™¯æ¨¡ç³Šï¼šå¯¹å›¾åƒèƒŒæ™¯è¿›è¡Œæ¨¡ç³Šå¤„ç†ï¼Œé™ä½èƒŒæ™¯ç‰¹å¾çš„å½±å“ï¼›3ï¼‰é¢œè‰²æ‰°åŠ¨ï¼šå¯¹å›¾åƒé¢œè‰²è¿›è¡Œéšæœºè°ƒæ•´ï¼Œæ”¹å˜å›¾åƒçš„æ•´ä½“é£æ ¼ã€‚é€šè¿‡è¿™äº›ä¸åŒçš„æ‰°åŠ¨æ–¹å¼ï¼Œå¯ä»¥æ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹å¯¹ä¸åŒç±»å‹éæ€§åˆ«ç‰¹å¾çš„æ•æ„Ÿæ€§ã€‚åœ¨åè§æŒ‡æ ‡çš„é€‰æ‹©ä¸Šï¼Œæœ¬æ–‡ä½¿ç”¨äº†å¸¸ç”¨çš„åè§è¯„ä¼°æŒ‡æ ‡ï¼Œä¾‹å¦‚æ€§åˆ«åˆ†ç±»å‡†ç¡®ç‡å·®å¼‚ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿å¯¹å›¾åƒè¿›è¡Œå¾®å°çš„éæ€§åˆ«ç‰¹å¾æ‰°åŠ¨ï¼ˆå¦‚å±è”½10%çš„ç‰©ä½“æˆ–è½»å¾®æ¨¡ç³ŠèƒŒæ™¯ï¼‰ï¼Œä¹Ÿä¼šå¯¼è‡´ç”Ÿæˆå¼VLMsçš„åè§æŒ‡æ ‡å˜åŒ–é«˜è¾¾175%ï¼ŒCLIPå˜ä½“çš„åè§æŒ‡æ ‡å˜åŒ–é«˜è¾¾43%ã€‚è¿™çªæ˜¾äº†ç°æœ‰åŸºå‡†æµ‹è¯•å¯¹è™šå‡ç›¸å…³æ€§çš„æ•æ„Ÿæ€§ï¼Œå¹¶å¼ºè°ƒäº†åœ¨è¯„ä¼°æ€§åˆ«åè§æ—¶è€ƒè™‘ç‰¹å¾æ•æ„Ÿæ€§çš„å¿…è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè§†è§‰-è¯­è¨€æ¨¡å‹çš„å…¬å¹³æ€§è¯„ä¼°ä¸æ”¹è¿›ã€‚é€šè¿‡è¯†åˆ«å’Œå‡è½»æ¨¡å‹å¯¹è™šå‡ç›¸å…³æ€§çš„ä¾èµ–ï¼Œå¯ä»¥å¼€å‘å‡ºæ›´å…¬å¹³ã€æ›´å¯é çš„AIç³»ç»Ÿï¼Œé¿å…åœ¨äººè„¸è¯†åˆ«ã€å›¾åƒæœç´¢ç­‰åº”ç”¨ä¸­äº§ç”Ÿæ€§åˆ«æ­§è§†ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥æ¢ç´¢æ›´æœ‰æ•ˆçš„å»åè§æ–¹æ³•ï¼Œå¹¶æ„å»ºæ›´å¯é çš„æ— ååŸºå‡†æ•°æ®é›†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Gender bias in vision-language foundation models (VLMs) raises concerns about their safe deployment and is typically evaluated using benchmarks with gender annotations on real-world images. However, as these benchmarks often contain spurious correlations between gender and non-gender features, such as objects and backgrounds, we identify a critical oversight in gender bias evaluation: Do spurious features distort gender bias evaluation? To address this question, we systematically perturb non-gender features across four widely used benchmarks (COCO-gender, FACET, MIAP, and PHASE) and various VLMs to quantify their impact on bias evaluation. Our findings reveal that even minimal perturbations, such as masking just 10% of objects or weakly blurring backgrounds, can dramatically alter bias scores, shifting metrics by up to 175% in generative VLMs and 43% in CLIP variants. This suggests that current bias evaluations often reflect model responses to spurious features rather than gender bias, undermining their reliability. Since creating spurious feature-free benchmarks is fundamentally challenging, we recommend reporting bias metrics alongside feature-sensitivity measurements to enable a more reliable bias assessment.

