---
layout: default
title: One View, Many Worlds: Single-Image to 3D Object Meets Generative Domain Randomization for One-Shot 6D Pose Estimation
---

# One View, Many Worlds: Single-Image to 3D Object Meets Generative Domain Randomization for One-Shot 6D Pose Estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07978" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07978v1</a>
  <a href="https://arxiv.org/pdf/2509.07978.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07978v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07978v1', 'One View, Many Worlds: Single-Image to 3D Object Meets Generative Domain Randomization for One-Shot 6D Pose Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zheng Geng, Nan Wang, Shaocong Xu, Chongjie Ye, Bohan Li, Zhaoxi Chen, Sida Peng, Hao Zhao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09

**å¤‡æ³¨**: CoRL 2025 Oral, Project page: https://gzwsama.github.io/OnePoseviaGen.github.io/

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://gzwsama.github.io/OnePoseviaGen.github.io/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**OnePoseViaGenï¼šç»“åˆå•å›¾3Dç”Ÿæˆä¸ç”ŸæˆåŸŸéšæœºåŒ–çš„ä¸€é˜¶æ®µ6Dä½å§¿ä¼°è®¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `6Dä½å§¿ä¼°è®¡` `å•è§†è§’å›¾åƒ` `3Dç”Ÿæˆ` `ç”ŸæˆåŸŸéšæœºåŒ–` `æœºå™¨äººæŠ“å–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥å¤„ç†å•è§†è§’6Dä½å§¿ä¼°è®¡ä¸­3Dæ¨¡å‹ç¼ºå¤±ã€å•è§†è§’é‡å»ºç¼ºä¹å°ºåº¦ä¿¡æ¯ä»¥åŠç”Ÿæˆæ¨¡å‹ä¸çœŸå®å›¾åƒä¹‹é—´å­˜åœ¨åŸŸå·®å¼‚ç­‰é—®é¢˜ã€‚
2. OnePoseViaGené€šè¿‡ç»“åˆå¤šè§†è§’ç‰¹å¾åŒ¹é…ä¸æ¸²æŸ“-æ¯”è¾ƒä¼˜åŒ–è¿›è¡Œä½å§¿ç²¾è°ƒï¼Œå¹¶åˆ©ç”¨æ–‡æœ¬å¼•å¯¼çš„ç”ŸæˆåŸŸéšæœºåŒ–ç­–ç•¥æå‡æ¨¡å‹åœ¨çœŸå®åœºæ™¯çš„æ³›åŒ–èƒ½åŠ›ã€‚
3. åœ¨YCBInEOATã€Toyota-Lightå’ŒLM-Oç­‰åŸºå‡†æµ‹è¯•ä¸­ï¼ŒOnePoseViaGenæ˜¾è‘—è¶…è¶Šç°æœ‰æŠ€æœ¯æ°´å¹³ï¼Œå¹¶åœ¨çœŸå®æœºå™¨äººæŠ“å–å®éªŒä¸­éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºOnePoseViaGenï¼Œä¸€ä¸ªè§£å†³å•å¼ å‚è€ƒå›¾åƒä¼°è®¡ä»»æ„æœªè§ç‰©ä½“6Dä½å§¿çš„æµç¨‹ï¼Œè¯¥é—®é¢˜å¯¹åœ¨çœŸå®ä¸–ç•Œé•¿å°¾åˆ†å¸ƒä¸­è¿è¡Œçš„æœºå™¨äººè‡³å…³é‡è¦ã€‚è¯¥æµç¨‹åŒ…å«ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šé¦–å…ˆï¼Œä¸€ä¸ªç”±ç²—åˆ°ç²¾çš„å¯¹é½æ¨¡å—ï¼Œé€šè¿‡ç»“åˆå¤šè§†è§’ç‰¹å¾åŒ¹é…ä¸æ¸²æŸ“-æ¯”è¾ƒä¼˜åŒ–ï¼Œè”åˆä¼˜åŒ–å°ºåº¦å’Œä½å§¿ï¼›å…¶æ¬¡ï¼Œä¸€ä¸ªæ–‡æœ¬å¼•å¯¼çš„ç”ŸæˆåŸŸéšæœºåŒ–ç­–ç•¥ï¼Œç”¨äºå¤šæ ·åŒ–çº¹ç†ï¼Œä»è€Œèƒ½å¤Ÿä½¿ç”¨åˆæˆæ•°æ®æœ‰æ•ˆåœ°å¾®è°ƒä½å§¿ä¼°è®¡å™¨ã€‚è¿™äº›æ­¥éª¤å…±åŒä½¿å¾—é«˜ä¿çœŸå•è§†è§’3Dç”Ÿæˆèƒ½å¤Ÿæ”¯æŒå¯é çš„ä¸€é˜¶æ®µ6Dä½å§¿ä¼°è®¡ã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ï¼ˆYCBInEOATã€Toyota-Lightã€LM-Oï¼‰ä¸Šï¼ŒOnePoseViaGenå–å¾—äº†è¿œè¶…ç°æœ‰æ–¹æ³•çš„state-of-the-artæ€§èƒ½ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡çœŸå®æœºå™¨äººæ‰‹çš„é²æ£’çµå·§æŠ“å–ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨çœŸå®ä¸–ç•Œæ“ä½œä¸­çš„å®ç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å•å¼ å›¾åƒä¸‹ï¼Œå¯¹æœªè§è¿‡çš„ç‰©ä½“çš„6Dä½å§¿ä¼°è®¡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é¢ä¸´çš„ç—›ç‚¹åœ¨äºï¼šç¼ºä¹ç‰©ä½“çš„3Dæ¨¡å‹ï¼Œå•è§†è§’é‡å»ºçš„3Dæ¨¡å‹ç¼ºå°‘å°ºåº¦ä¿¡æ¯ï¼Œä»¥åŠåˆæˆæ•°æ®å’ŒçœŸå®æ•°æ®ä¹‹é—´å­˜åœ¨è¾ƒå¤§çš„domain gapï¼Œå¯¼è‡´æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å•è§†è§’å›¾åƒç”Ÿæˆç‰©ä½“çš„3Dæ¨¡å‹ï¼Œå¹¶ç»“åˆç”ŸæˆåŸŸéšæœºåŒ–æŠ€æœ¯æ¥å¼¥åˆåˆæˆæ•°æ®å’ŒçœŸå®æ•°æ®ä¹‹é—´çš„domain gapã€‚é€šè¿‡ä¸€ä¸ªcoarse-to-fineçš„å¯¹é½æ¨¡å—ï¼Œå…ˆç²—ç•¥ä¼°è®¡ä½å§¿ï¼Œå†é€šè¿‡render-and-compareçš„æ–¹å¼è¿›è¡Œç²¾ç»†è°ƒæ•´ã€‚åŒæ—¶ï¼Œåˆ©ç”¨æ–‡æœ¬å¼•å¯¼çš„ç”ŸæˆåŸŸéšæœºåŒ–ç­–ç•¥ï¼Œç”Ÿæˆå…·æœ‰å¤šæ ·åŒ–çº¹ç†çš„åˆæˆæ•°æ®ï¼Œç”¨äºè®­ç»ƒä½å§¿ä¼°è®¡å™¨ï¼Œæé«˜å…¶é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOnePoseViaGençš„æ•´ä½“æµç¨‹åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) å•è§†è§’3Dæ¨¡å‹ç”Ÿæˆï¼šåˆ©ç”¨å•å¼ å›¾åƒç”Ÿæˆç‰©ä½“çš„3Dæ¨¡å‹ã€‚2) ç²—ç•¥ä½å§¿ä¼°è®¡ï¼šä½¿ç”¨å¤šè§†è§’ç‰¹å¾åŒ¹é…è¿›è¡Œç²—ç•¥çš„ä½å§¿ä¼°è®¡ã€‚3) ä½å§¿ç²¾è°ƒï¼šé€šè¿‡render-and-compareçš„æ–¹å¼ï¼Œå°†æ¸²æŸ“çš„å›¾åƒä¸çœŸå®å›¾åƒè¿›è¡Œæ¯”è¾ƒï¼Œä¼˜åŒ–ä½å§¿å‚æ•°ã€‚4) ç”ŸæˆåŸŸéšæœºåŒ–ï¼šåˆ©ç”¨æ–‡æœ¬å¼•å¯¼çš„ç”Ÿæˆæ¨¡å‹ï¼Œç”Ÿæˆå…·æœ‰å¤šæ ·åŒ–çº¹ç†çš„åˆæˆæ•°æ®ã€‚5) ä½å§¿ä¼°è®¡å™¨è®­ç»ƒï¼šä½¿ç”¨åˆæˆæ•°æ®å¾®è°ƒä½å§¿ä¼°è®¡å™¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§ç»“åˆå•è§†è§’3Dç”Ÿæˆå’Œç”ŸæˆåŸŸéšæœºåŒ–çš„æ–¹æ³•ï¼Œç”¨äºè§£å†³å•å¼ å›¾åƒä¸‹çš„6Dä½å§¿ä¼°è®¡é—®é¢˜ã€‚2) è®¾è®¡äº†ä¸€ä¸ªcoarse-to-fineçš„å¯¹é½æ¨¡å—ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°ä¼˜åŒ–ä½å§¿å’Œå°ºåº¦ã€‚3) æå‡ºäº†ä¸€ä¸ªæ–‡æœ¬å¼•å¯¼çš„ç”ŸæˆåŸŸéšæœºåŒ–ç­–ç•¥ï¼Œèƒ½å¤Ÿç”Ÿæˆå…·æœ‰å¤šæ ·åŒ–çº¹ç†çš„åˆæˆæ•°æ®ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦ç‰©ä½“çš„3Dæ¨¡å‹ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†domain gapé—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨coarse-to-fineå¯¹é½æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†å¤šè§†è§’ç‰¹å¾åŒ¹é…æ¥è·å–ç²—ç•¥çš„ä½å§¿ä¼°è®¡ï¼Œç„¶åé€šè¿‡render-and-compareçš„æ–¹å¼ï¼Œè®¡ç®—æ¸²æŸ“å›¾åƒå’ŒçœŸå®å›¾åƒä¹‹é—´çš„å·®å¼‚ï¼Œå¹¶ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•ä¼˜åŒ–ä½å§¿å‚æ•°ã€‚åœ¨ç”ŸæˆåŸŸéšæœºåŒ–ç­–ç•¥ä¸­ï¼Œä½¿ç”¨äº†æ–‡æœ¬æè¿°æ¥å¼•å¯¼ç”Ÿæˆæ¨¡å‹ç”Ÿæˆå…·æœ‰ä¸åŒçº¹ç†çš„åˆæˆæ•°æ®ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬ä½å§¿æŸå¤±ã€å°ºåº¦æŸå¤±å’Œæ¸²æŸ“æŸå¤±ç­‰ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

OnePoseViaGenåœ¨YCBInEOATã€Toyota-Lightå’ŒLM-Oç­‰åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨YCBInEOATæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•çš„ä½å§¿ä¼°è®¡ç²¾åº¦æå‡äº†è¶…è¿‡10%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜åœ¨çœŸå®æœºå™¨äººæŠ“å–å®éªŒä¸­è¡¨ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§ï¼ŒæˆåŠŸå®ç°äº†å¯¹æœªè§ç‰©ä½“çš„çµå·§æŠ“å–ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæœºå™¨äººæ“ä½œã€å¢å¼ºç°å®ã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œæœºå™¨äººå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯è¯†åˆ«å¹¶æŠ“å–æœªè§è¿‡çš„ç‰©ä½“ï¼Œä»è€Œå®ç°æ›´æ™ºèƒ½åŒ–çš„æ“ä½œã€‚åœ¨AR/VRåº”ç”¨ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯å°†è™šæ‹Ÿç‰©ä½“ä¸çœŸå®åœºæ™¯è¿›è¡Œç²¾ç¡®å¯¹é½ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºå·¥ä¸šè‡ªåŠ¨åŒ–ã€æ™ºèƒ½åˆ¶é€ ç­‰é¢†åŸŸï¼Œæé«˜ç”Ÿäº§æ•ˆç‡å’Œäº§å“è´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Estimating the 6D pose of arbitrary unseen objects from a single reference image is critical for robotics operating in the long-tail of real-world instances. However, this setting is notoriously challenging: 3D models are rarely available, single-view reconstructions lack metric scale, and domain gaps between generated models and real-world images undermine robustness. We propose OnePoseViaGen, a pipeline that tackles these challenges through two key components. First, a coarse-to-fine alignment module jointly refines scale and pose by combining multi-view feature matching with render-and-compare refinement. Second, a text-guided generative domain randomization strategy diversifies textures, enabling effective fine-tuning of pose estimators with synthetic data. Together, these steps allow high-fidelity single-view 3D generation to support reliable one-shot 6D pose estimation. On challenging benchmarks (YCBInEOAT, Toyota-Light, LM-O), OnePoseViaGen achieves state-of-the-art performance far surpassing prior approaches. We further demonstrate robust dexterous grasping with a real robot hand, validating the practicality of our method in real-world manipulation. Project page: https://gzwsama.github.io/OnePoseviaGen.github.io/

