---
layout: default
title: Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search
---

# Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07969" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07969v1</a>
  <a href="https://arxiv.org/pdf/2509.07969.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07969v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07969v1', 'Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xin Lai, Junyi Li, Wei Li, Tao Liu, Tianjian Li, Hengshuang Zhao

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09

**å¤‡æ³¨**: Code, datasets, models are available at https://github.com/Mini-o3/Mini-o3. Project Page: https://mini-o3.github.io/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Mini-o3ï¼šé€šè¿‡æ‰©å±•æ¨ç†æ¨¡å¼å’Œäº¤äº’è½®æ•°ï¼Œæå‡è§†è§‰æœç´¢æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰æœç´¢` `å¤šæ¨¡æ€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `æ¢ç´¢å¼æ¨ç†` `äº¤äº’å¼å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¼€æºå¤šæ¨¡æ€æ¨¡å‹åœ¨è§†è§‰æœç´¢ä¸­æ¨ç†æ¨¡å¼å•è°ƒï¼Œäº¤äº’è½®æ•°æœ‰é™ï¼Œéš¾ä»¥åº”å¯¹å¤æ‚ä»»åŠ¡ã€‚
2. Mini-o3é€šè¿‡æ„å»ºæ•°æ®é›†ã€è¿­ä»£æ•°æ®æ”¶é›†å’Œè¿‡åº¦è½®æ¬¡æ©è”½ç­–ç•¥ï¼Œæ‰©å±•æ¨ç†æ¨¡å¼å’Œäº¤äº’è½®æ•°ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMini-o3èƒ½ç”Ÿæˆæ·±åº¦æ¨ç†è·¯å¾„ï¼Œæ˜¾è‘—æå‡å¤æ‚è§†è§‰æœç´¢ä»»åŠ¡çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åˆ©ç”¨åŸºäºå›¾åƒçš„å·¥å…·å’Œå¼ºåŒ–å­¦ä¹ æ¥è§£å†³è§†è§‰é—®é¢˜ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¼€æºæ–¹æ³•é€šå¸¸è¡¨ç°å‡ºå•è°ƒçš„æ¨ç†æ¨¡å¼ï¼Œå¹¶ä¸”åªå…è®¸æœ‰é™çš„äº¤äº’è½®æ•°ï¼Œè¿™ä½¿å¾—å®ƒä»¬ä¸è¶³ä»¥åº”å¯¹éœ€è¦åå¤è¯•éªŒæ¢ç´¢çš„å›°éš¾ä»»åŠ¡ã€‚æœ¬æ–‡é€šè¿‡æ‰©å±•åŸºäºå·¥å…·çš„äº¤äº’æ¥è§£å†³è¿™ä¸€é™åˆ¶ï¼Œå¹¶å¼•å…¥Mini-o3ï¼Œè¯¥ç³»ç»Ÿæ‰§è¡Œæ·±åº¦ã€å¤šè½®æ¨ç†ï¼ˆè·¨è¶Šæ•°åæ­¥ï¼‰ï¼Œå¹¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„è§†è§‰æœç´¢ä»»åŠ¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„å¤ç°OpenAI o3é£æ ¼è¡Œä¸ºçš„æ–¹æ³•åŒ…æ‹¬ä¸‰ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ„å»ºäº†Visual Probe Datasetï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«æ•°åƒä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„è§†è§‰æœç´¢é—®é¢˜çš„é›†åˆï¼Œä¸“ä¸ºæ¢ç´¢æ€§æ¨ç†è€Œè®¾è®¡ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªè¿­ä»£æ•°æ®æ”¶é›†ç®¡é“ï¼Œä»¥è·å¾—å±•ç¤ºå¤šæ ·åŒ–æ¨ç†æ¨¡å¼çš„å†·å¯åŠ¨è½¨è¿¹ï¼ŒåŒ…æ‹¬æ·±åº¦ä¼˜å…ˆæœç´¢ã€åå¤è¯•éªŒå’Œç›®æ ‡ç»´æŠ¤ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è¿‡åº¦è½®æ¬¡æ©è”½ç­–ç•¥ï¼Œä»¥é˜²æ­¢åœ¨å¼ºåŒ–å­¦ä¹ æœŸé—´æƒ©ç½šè¿‡åº¦è½®æ¬¡å“åº”ï¼ˆé‚£äº›è¾¾åˆ°æœ€å¤§è½®æ•°çš„å“åº”ï¼‰ï¼Œä»è€Œå¹³è¡¡è®­ç»ƒæ—¶æ•ˆç‡ä¸æµ‹è¯•æ—¶å¯æ‰©å±•æ€§ã€‚å°½ç®¡ä»…ä½¿ç”¨å…­ä¸ªäº¤äº’è½®æ¬¡çš„ä¸Šé™è¿›è¡Œè®­ç»ƒï¼Œä½†æˆ‘ä»¬çš„æ¨¡å‹åœ¨æ¨ç†æ—¶ç”Ÿæˆè‡ªç„¶æ‰©å±•åˆ°æ•°åè½®çš„è½¨è¿¹ï¼Œå¹¶ä¸”å‡†ç¡®æ€§éšç€è½®æ•°çš„å¢åŠ è€Œæé«˜ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼ŒMini-o3äº§ç”Ÿä¸°å¯Œçš„æ¨ç†æ¨¡å¼å’Œæ·±åº¦æ€è€ƒè·¯å¾„ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†å…·æœ‰æŒ‘æˆ˜æ€§çš„è§†è§‰æœç´¢é—®é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰å¼€æºæ–¹æ³•åœ¨è§†è§‰æœç´¢ä»»åŠ¡ä¸­ï¼Œæ¨ç†æ¨¡å¼å•ä¸€ï¼Œäº¤äº’è½®æ•°å—é™ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆçš„æ¢ç´¢å¼æ¨ç†ï¼Œå¯¼è‡´åœ¨å¤æ‚è§†è§‰æœç´¢ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚ç—›ç‚¹åœ¨äºç¼ºä¹è¶³å¤Ÿæ·±åº¦çš„æ¨ç†èƒ½åŠ›å’Œçµæ´»çš„äº¤äº’æœºåˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMini-o3çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ‰©å±•å·¥å…·çš„ä½¿ç”¨å’Œäº¤äº’è½®æ•°ï¼Œæ¨¡æ‹Ÿäººç±»åœ¨è§£å†³å¤æ‚è§†è§‰æœç´¢é—®é¢˜æ—¶çš„æ¢ç´¢è¿‡ç¨‹ã€‚é€šè¿‡æ„å»ºä¸“é—¨çš„æ•°æ®é›†ã€è¿­ä»£æ•°æ®æ”¶é›†å’Œç‰¹æ®Šçš„è®­ç»ƒç­–ç•¥ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°å¤šæ ·åŒ–çš„æ¨ç†æ¨¡å¼ï¼Œå¹¶åœ¨æ¨ç†æ—¶èƒ½å¤Ÿè‡ªé€‚åº”åœ°è¿›è¡Œå¤šè½®äº¤äº’ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMini-o3çš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼šVisual Probe Datasetçš„æ„å»ºï¼Œç”¨äºæä¾›å…·æœ‰æŒ‘æˆ˜æ€§çš„è§†è§‰æœç´¢é—®é¢˜ï¼›è¿­ä»£æ•°æ®æ”¶é›†ç®¡é“ï¼Œç”¨äºç”ŸæˆåŒ…å«å¤šæ ·åŒ–æ¨ç†æ¨¡å¼çš„å†·å¯åŠ¨è½¨è¿¹ï¼›ä»¥åŠåŸºäºå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå…¶ä¸­é‡‡ç”¨äº†è¿‡åº¦è½®æ¬¡æ©è”½ç­–ç•¥ã€‚æ¨¡å‹é€šè¿‡ä¸ç¯å¢ƒè¿›è¡Œå¤šè½®äº¤äº’ï¼Œé€æ­¥ç¼©å°æœç´¢èŒƒå›´ï¼Œæœ€ç»ˆæ‰¾åˆ°ç›®æ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šMini-o3çš„å…³é”®åˆ›æ–°åœ¨äºå…¶èƒ½å¤Ÿçªç ´äº¤äº’è½®æ•°çš„é™åˆ¶ï¼Œåœ¨è®­ç»ƒæ—¶ä»…ä½¿ç”¨æœ‰é™çš„è½®æ•°ï¼Œä½†åœ¨æ¨ç†æ—¶èƒ½å¤Ÿè‡ªé€‚åº”åœ°æ‰©å±•åˆ°æ•°åè½®ã€‚è¿™å¾—ç›Šäºè¿‡åº¦è½®æ¬¡æ©è”½ç­–ç•¥ï¼Œè¯¥ç­–ç•¥é¿å…äº†å¯¹è¶…è¿‡é¢„è®¾è½®æ•°çš„è¡Œä¸ºè¿›è¡Œæƒ©ç½šï¼Œä»è€Œé¼“åŠ±æ¨¡å‹æ¢ç´¢æ›´é•¿çš„æ¨ç†è·¯å¾„ã€‚

**å…³é”®è®¾è®¡**ï¼šVisual Probe DatasetåŒ…å«æ•°åƒä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„è§†è§‰æœç´¢é—®é¢˜ï¼Œæ¶µç›–äº†å„ç§åœºæ™¯å’Œç›®æ ‡ã€‚è¿­ä»£æ•°æ®æ”¶é›†ç®¡é“é‡‡ç”¨äººå·¥æ ‡æ³¨å’Œæ¨¡å‹ç”Ÿæˆç›¸ç»“åˆçš„æ–¹å¼ï¼Œç¡®ä¿æ•°æ®çš„å¤šæ ·æ€§å’Œè´¨é‡ã€‚è¿‡åº¦è½®æ¬¡æ©è”½ç­–ç•¥é€šè¿‡åœ¨å¼ºåŒ–å­¦ä¹ çš„æŸå¤±å‡½æ•°ä¸­å¯¹è¶…è¿‡æœ€å¤§è½®æ•°çš„è¡Œä¸ºè¿›è¡Œæ©è”½ï¼Œé¿å…äº†æ¨¡å‹è¿‡æ—©æ”¶æ•›åˆ°çŸ­è·¯å¾„ï¼Œä»è€Œé¼“åŠ±æ¨¡å‹æ¢ç´¢æ›´é•¿çš„æ¨ç†è·¯å¾„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Mini-o3åœ¨è§†è§‰æœç´¢ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å°½ç®¡è®­ç»ƒæ—¶ä»…ä½¿ç”¨æœ€å¤š6è½®äº¤äº’ï¼Œä½†åœ¨æ¨ç†æ—¶èƒ½å¤Ÿæ‰©å±•åˆ°æ•°åè½®ï¼Œå¹¶ä¸”å‡†ç¡®ç‡éšç€è½®æ•°çš„å¢åŠ è€Œæé«˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMini-o3èƒ½å¤Ÿç”Ÿæˆä¸°å¯Œçš„æ¨ç†æ¨¡å¼å’Œæ·±åº¦æ€è€ƒè·¯å¾„ï¼Œæœ‰æ•ˆè§£å†³äº†å…·æœ‰æŒ‘æˆ˜æ€§çš„è§†è§‰æœç´¢é—®é¢˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Mini-o3åœ¨è§†è§‰æœç´¢ã€æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½åŠ©æ‰‹ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºå¼€å‘æ›´æ™ºèƒ½çš„å›¾åƒæœç´¢å¼•æ“ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿæ‰¾åˆ°æ‰€éœ€ä¿¡æ¯ã€‚åœ¨æœºå™¨äººé¢†åŸŸï¼Œå®ƒå¯ä»¥ç”¨äºæå‡æœºå™¨äººçš„ç¯å¢ƒæ„ŸçŸ¥å’Œè‡ªä¸»å¯¼èˆªèƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å¯ä»¥ä½œä¸ºæ™ºèƒ½åŠ©æ‰‹çš„æ ¸å¿ƒæ¨¡å—ï¼Œæ”¯æŒæ›´å¤æ‚çš„è§†è§‰ä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in large multimodal models have leveraged image-based tools with reinforcement learning to tackle visual problems. However, existing open-source approaches often exhibit monotonous reasoning patterns and allow only a limited number of interaction turns, making them inadequate for difficult tasks that require trial-and-error exploration. In this work, we address this limitation by scaling up tool-based interactions and introduce Mini-o3, a system that executes deep, multi-turn reasoning -- spanning tens of steps -- and achieves state-of-the-art performance on challenging visual search tasks. Our recipe for reproducing OpenAI o3-style behaviors comprises three key components. First, we construct the Visual Probe Dataset, a collection of thousands of challenging visual search problems designed for exploratory reasoning. Second, we develop an iterative data collection pipeline to obtain cold-start trajectories that exhibit diverse reasoning patterns, including depth-first search, trial-and-error, and goal maintenance. Third, we propose an over-turn masking strategy that prevents penalization of over-turn responses (those that hit the maximum number of turns) during reinforcement learning, thereby balancing training-time efficiency with test-time scalability. Despite training with an upper bound of only six interaction turns, our model generates trajectories that naturally scale to tens of turns at inference time, with accuracy improving as the number of turns increases. Extensive experiments demonstrate that Mini-o3 produces rich reasoning patterns and deep thinking paths, effectively solving challenging visual search problems.

