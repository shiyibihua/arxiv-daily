---
layout: default
title: Adapting Medical Vision Foundation Models for Volumetric Medical Image Segmentation via Active Learning and Selective Semi-supervised Fine-tuning
---

# Adapting Medical Vision Foundation Models for Volumetric Medical Image Segmentation via Active Learning and Selective Semi-supervised Fine-tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10784" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.10784v2</a>
  <a href="https://arxiv.org/pdf/2509.10784.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10784v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10784v2', 'Adapting Medical Vision Foundation Models for Volumetric Medical Image Segmentation via Active Learning and Selective Semi-supervised Fine-tuning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Jin Yang, Daniel S. Marcus, Aristeidis Sotiras

**ÂàÜÁ±ª**: eess.IV, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-13 (Êõ¥Êñ∞: 2025-10-21)

**Â§áÊ≥®**: 17 pages, 5 figures, 8 tables

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ASFDAÊñπÊ≥ïÔºåÈÄöËøá‰∏ªÂä®Â≠¶‰π†ÂíåÈÄâÊã©ÊÄßÂçäÁõëÁù£ÂæÆË∞ÉÔºåÈ´òÊïàÈÄÇÈÖçÂåªÂ≠¶ËßÜËßâÂü∫Á°ÄÊ®°ÂûãËøõË°åÂåªÂ≠¶ÂõæÂÉèÂàÜÂâ≤„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂåªÂ≠¶ÂõæÂÉèÂàÜÂâ≤` `‰∏ªÂä®Â≠¶‰π†` `ÂçäÁõëÁù£Â≠¶‰π†` `È¢ÜÂüüËá™ÈÄÇÂ∫î` `ÂåªÂ≠¶ËßÜËßâÂü∫Á°ÄÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÈöèÊú∫ÈÄâÊã©Ê†∑Êú¨ÂæÆË∞ÉÂåªÂ≠¶ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÔºåÊïàÁéá‰ΩéÔºåÊó†Ê≥ï‰øùËØÅÁõÆÊ†áÂüüÁöÑÊúÄ‰Ω≥ÊÄßËÉΩ„ÄÇ
2. ASFDAÊñπÊ≥ïÈÄöËøá‰∏ªÂä®Â≠¶‰π†ÈÄâÊã©‰ø°ÊÅØÈáèÂ§ßÁöÑÊ†∑Êú¨ÔºåÂπ∂ÁªìÂêàÈÄâÊã©ÊÄßÂçäÁõëÁù£ÂæÆË∞ÉÔºåÊèêÂçáÊ®°ÂûãÂú®ÁõÆÊ†áÂüüÁöÑÂàÜÂâ≤ÊÄßËÉΩ„ÄÇ
3. ËØ•ÊñπÊ≥ïËÆæËÆ°‰∫ÜDKDÂíåASD‰∏§ÁßçÊü•ËØ¢ÊåáÊ†áÔºåÂàÜÂà´Ë°°ÈáèÊ∫ê-ÁõÆÊ†áÁü•ËØÜÂ∑ÆË∑ùÂíåËß£ÂâñÂàÜÂâ≤ÈöæÂ∫¶ÔºåÊåáÂØºÊ†∑Êú¨ÈÄâÊã©„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂåªÂ≠¶ËßÜËßâÂü∫Á°ÄÊ®°Âûã(Med-VFMs)Áî±‰∫éÈÄöËøáÂ§ßÈáèÊú™Ê†áÊ≥®ÂõæÂÉèÁöÑËá™ÁõëÁù£È¢ÑËÆ≠ÁªÉÂ≠¶‰π†Âà∞ÁöÑÁü•ËØÜÔºåÂÖ∑ÊúâÂçìË∂äÁöÑÂåªÂ≠¶ÂõæÂÉèÁêÜËß£ËÉΩÂäõ„ÄÇ‰∏∫‰∫ÜÊèêÈ´òÂÆÉ‰ª¨Âú®Ëá™ÈÄÇÂ∫î‰∏ãÊ∏∏ËØÑ‰º∞ÔºàÂ∞§ÂÖ∂ÊòØÂàÜÂâ≤Ôºâ‰∏≠ÁöÑÊÄßËÉΩÔºåÈÄöÂ∏∏‰ºöÈöèÊú∫ÈÄâÊã©ÁõÆÊ†áÈ¢ÜÂüüÁöÑ‰∏Ä‰∫õÊ†∑Êú¨ËøõË°åÂæÆË∞É„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁº∫‰πèÊé¢Á¥¢Â¶Ç‰ΩïÈ´òÊïàÂú∞Ë∞ÉÊï¥Med-VFMs‰ª•Âú®ÁõÆÊ†áÈ¢ÜÂüü‰∏äÂÆûÁé∞ÊúÄ‰Ω≥ÊÄßËÉΩÁöÑÂ∑•‰Ωú„ÄÇÂõ†Ê≠§ÔºåËø´ÂàáÈúÄË¶ÅËÆæËÆ°‰∏ÄÁßçÊúâÊïàÁöÑÂæÆË∞ÉMed-VFMsÁöÑÊñπÊ≥ïÔºåÈÄöËøáÈÄâÊã©‰ø°ÊÅØÈáèÂ§ßÁöÑÊ†∑Êú¨Êù•ÊúÄÂ§ßÂåñÂÆÉ‰ª¨Âú®ÁõÆÊ†áÈ¢ÜÂüü‰∏äÁöÑÈÄÇÂ∫îÊÄßËÉΩ„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞Ëøô‰∏ÄÁõÆÊ†áÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßç‰∏ªÂä®Êó†Ê∫êÂüüËá™ÈÄÇÂ∫î(ASFDA)ÊñπÊ≥ïÔºå‰ª•ÊúâÊïàÂú∞Â∞ÜMed-VFMsÈÄÇÂ∫î‰∫éÁõÆÊ†áÈ¢ÜÂüüÁöÑ‰ΩìÁßØÂåªÂ≠¶ÂõæÂÉèÂàÜÂâ≤„ÄÇËØ•ASFDAÈááÁî®‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑ‰∏ªÂä®Â≠¶‰π†(AL)ÊñπÊ≥ïÔºå‰ªéÁõÆÊ†áÈ¢ÜÂüü‰∏≠ÈÄâÊã©‰ø°ÊÅØÈáèÊúÄÂ§ßÁöÑÊ†∑Êú¨Êù•ÂæÆË∞ÉMed-VFMsÔºåËÄåÊó†ÈúÄËÆøÈóÆÊ∫êÈ¢ÑËÆ≠ÁªÉÊ†∑Êú¨Ôºå‰ªéËÄå‰ª•ÊúÄÂ∞èÁöÑÈÄâÊã©È¢ÑÁÆóÊúÄÂ§ßÂåñÂÆÉ‰ª¨ÁöÑÊÄßËÉΩ„ÄÇÂú®ËØ•ALÊñπÊ≥ï‰∏≠ÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏ÄÁßç‰∏ªÂä®ÊµãËØïÊó∂Ê†∑Êú¨Êü•ËØ¢Á≠ñÁï•ÔºåÈÄöËøá‰∏§‰∏™Êü•ËØ¢ÊåáÊ†á‰ªéÁõÆÊ†áÂüü‰∏≠ÈÄâÊã©Ê†∑Êú¨ÔºåÂåÖÊã¨Â§öÊ†∑ÂåñÁü•ËØÜÊï£Â∫¶(DKD)ÂíåËß£ÂâñÂàÜÂâ≤ÈöæÂ∫¶(ASD)„ÄÇDKDÊó®Âú®Ë°°ÈáèÊ∫ê-ÁõÆÊ†áÁü•ËØÜÂ∑ÆË∑ùÂíåÂüüÂÜÖÂ§öÊ†∑ÊÄß„ÄÇÂÆÉÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑÁü•ËØÜÊù•ÊåáÂØº‰ªéÁõÆÊ†áÂüü‰∏≠Êü•ËØ¢Ê∫ê‰∏çÁõ∏‰ººÂíåËØ≠‰πâÂ§öÊ†∑ÁöÑÊ†∑Êú¨„ÄÇASDÊó®Âú®ÈÄöËøáËá™ÈÄÇÂ∫îÂú∞ÊµãÈáèÂâçÊôØÂå∫ÂüüÁöÑÈ¢ÑÊµãÁÜµÊù•ËØÑ‰º∞Ëß£ÂâñÁªìÊûÑÂàÜÂâ≤ÁöÑÈöæÂ∫¶„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÁöÑASFDAÊñπÊ≥ïÈááÁî®ÈÄâÊã©ÊÄßÂçäÁõëÁù£ÂæÆË∞ÉÔºåÈÄöËøáËØÜÂà´Êú™Êü•ËØ¢Ê†∑Êú¨‰∏≠ÂÖ∑ÊúâÈ´òÂèØÈù†ÊÄßÁöÑÊ†∑Êú¨Êù•ÊèêÈ´òÂæÆË∞ÉÁöÑÊÄßËÉΩÂíåÊïàÁéá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂåªÂ≠¶ËßÜËßâÂü∫Á°ÄÊ®°Âûã(Med-VFMs)Âú®ÁâπÂÆöÁõÆÊ†áÂüüÁöÑÂåªÂ≠¶ÂõæÂÉèÂàÜÂâ≤‰ªªÂä°‰∏≠ÔºåÂ¶Ç‰ΩïÈ´òÊïàÂú∞ËøõË°åÊ®°ÂûãÈÄÇÈÖçÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈááÁî®ÈöèÊú∫ÈÄâÊã©Ê†∑Êú¨ËøõË°åÂæÆË∞ÉÔºå‰ΩÜËøôÁßçÊñπÊ≥ïÂøΩÁï•‰∫ÜÊ†∑Êú¨ÁöÑ‰ø°ÊÅØÈáèÂ∑ÆÂºÇÔºåÂØºËá¥ÂæÆË∞ÉÊïàÁéá‰Ωé‰∏ãÔºå‰∏îÊó†Ê≥ï‰øùËØÅÊ®°ÂûãÂú®ÁõÆÊ†áÂüü‰∏äÁöÑÊúÄ‰Ω≥ÊÄßËÉΩ„ÄÇÁé∞ÊúâÊñπÊ≥ïÁöÑÁóõÁÇπÂú®‰∫éÁº∫‰πè‰∏ÄÁßçÊúâÊïàÁöÑÊ†∑Êú¨ÈÄâÊã©Á≠ñÁï•Ôºå‰ª•ÊúÄÂ∞èÁöÑÊ†áÊ≥®‰ª£‰ª∑ÂÆûÁé∞Ê®°ÂûãÊÄßËÉΩÁöÑÊúÄÂ§ßÂåñÊèêÂçá„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøá‰∏ªÂä®Â≠¶‰π†(Active Learning)Êù•ÈÄâÊã©‰ø°ÊÅØÈáèÊúÄÂ§ßÁöÑÊ†∑Êú¨ËøõË°åÂæÆË∞ÉÔºåÂπ∂ÁªìÂêàÈÄâÊã©ÊÄßÂçäÁõëÁù£ÂæÆË∞ÉÊù•Ëøõ‰∏ÄÊ≠•ÊèêÂçáÊÄßËÉΩÂíåÊïàÁéá„ÄÇ‰∏ªÂä®Â≠¶‰π†ËÉΩÂ§ü‰ªéÁõÆÊ†áÂüü‰∏≠ÊåëÈÄâÂá∫ÂØπÊ®°ÂûãÂ≠¶‰π†ÊúÄÊúâÂ∏ÆÂä©ÁöÑÊ†∑Êú¨Ôºå‰ªéËÄåÂáèÂ∞ëÊ†áÊ≥®ÊàêÊú¨ÔºåÊèêÈ´òÂæÆË∞ÉÊïàÁéá„ÄÇÈÄâÊã©ÊÄßÂçäÁõëÁù£ÂæÆË∞ÉÂàôÂà©Áî®Êú™Ê†áÊ≥®Ê†∑Êú¨‰∏≠ÁΩÆ‰ø°Â∫¶È´òÁöÑÈ¢ÑÊµãÁªìÊûúÔºåËøõ‰∏ÄÊ≠•Â¢ûÂº∫Ê®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöASFDAÊñπÊ≥ï‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö
1. **‰∏ªÂä®ÊµãËØïÊó∂Ê†∑Êú¨Êü•ËØ¢(Active Test Time Sample Query)**ÔºöÂà©Áî®DKDÂíåASD‰∏§ÁßçÊü•ËØ¢ÊåáÊ†áÔºå‰ªéÁõÆÊ†áÂüü‰∏≠ÈÄâÊã©‰ø°ÊÅØÈáèÊúÄÂ§ßÁöÑÊ†∑Êú¨„ÄÇ
2. **Ê®°ÂûãÂæÆË∞É(Fine-tuning)**Ôºö‰ΩøÁî®‰∏ªÂä®Â≠¶‰π†ÈÄâÊã©ÁöÑÊ†∑Êú¨ÂØπMed-VFMsËøõË°åÂæÆË∞É„ÄÇ
3. **ÈÄâÊã©ÊÄßÂçäÁõëÁù£ÂæÆË∞É(Selective Semi-supervised Fine-tuning)**Ôºö‰ªéÂâ©‰ΩôÊú™Ê†áÊ≥®Ê†∑Êú¨‰∏≠ÈÄâÊã©ÁΩÆ‰ø°Â∫¶È´òÁöÑÊ†∑Êú¨Ôºå‰∏éÂ∑≤Ê†áÊ≥®Ê†∑Êú¨‰∏ÄËµ∑ËøõË°åÂçäÁõëÁù£ÂæÆË∞É„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÊèêÂá∫‰∫ÜÁªìÂêàÂ§öÊ†∑ÂåñÁü•ËØÜÊï£Â∫¶(DKD)ÂíåËß£ÂâñÂàÜÂâ≤ÈöæÂ∫¶(ASD)ÁöÑ‰∏ªÂä®Â≠¶‰π†Ê†∑Êú¨ÈÄâÊã©Á≠ñÁï•„ÄÇDKDÁî®‰∫éË°°ÈáèÊ∫êÂüüÂíåÁõÆÊ†áÂüü‰πãÈó¥ÁöÑÁü•ËØÜÂ∑ÆË∑ù‰ª•ÂèäÁõÆÊ†áÂüüÂÜÖÈÉ®ÁöÑÂ§öÊ†∑ÊÄßÔºåÁ°Æ‰øùÈÄâÊã©ÁöÑÊ†∑Êú¨Êó¢ËÉΩÂº•Ë°•Áü•ËØÜÂ∑ÆË∑ùÔºåÂèàËÉΩË¶ÜÁõñÁõÆÊ†áÂüüÁöÑÂ§öÁßçÊÉÖÂÜµ„ÄÇASDÂàôÁî®‰∫éËØÑ‰º∞Ëß£ÂâñÁªìÊûÑÂàÜÂâ≤ÁöÑÈöæÂ∫¶Ôºå‰ºòÂÖàÈÄâÊã©Èöæ‰ª•ÂàÜÂâ≤ÁöÑÊ†∑Êú¨Ôºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÂØπÂ§çÊùÇÁªìÊûÑÁöÑÂàÜÂâ≤ËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**Ôºö
* **Â§öÊ†∑ÂåñÁü•ËØÜÊï£Â∫¶(DKD)**ÔºöÂÖ∑‰ΩìËÆ°ÁÆóÊñπÊ≥ïÊú™Áü•Ôºå‰ΩÜÂÖ∂ÁõÆÁöÑÊòØÈÄâÊã©‰∏éÊ∫êÂüüÂ∑ÆÂºÇÂ§ß‰∏îËØ≠‰πâÂ§öÊ†∑ÁöÑÊ†∑Êú¨„ÄÇ
* **Ëß£ÂâñÂàÜÂâ≤ÈöæÂ∫¶(ASD)**ÔºöÈÄöËøáËá™ÈÄÇÂ∫îÂú∞ÊµãÈáèÂâçÊôØÂå∫ÂüüÁöÑÈ¢ÑÊµãÁÜµÊù•ËØÑ‰º∞ÂàÜÂâ≤ÈöæÂ∫¶ÔºåÁÜµË∂äÈ´òË°®Á§∫ÂàÜÂâ≤Ë∂äÂõ∞Èöæ„ÄÇ
* **ÈÄâÊã©ÊÄßÂçäÁõëÁù£ÂæÆË∞É**ÔºöÂÖ∑‰ΩìÈÄâÊã©Ê†áÂáÜÊú™Áü•Ôºå‰ΩÜÂÖ∂ÁõÆÁöÑÊòØÈÄâÊã©È¢ÑÊµãÁΩÆ‰ø°Â∫¶È´òÁöÑÊú™Ê†áÊ≥®Ê†∑Êú¨„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÊèêÂá∫‰∫ÜASFDAÊñπÊ≥ïÔºåÈÄöËøá‰∏ªÂä®Â≠¶‰π†ÂíåÈÄâÊã©ÊÄßÂçäÁõëÁù£ÂæÆË∞ÉÔºåÊúâÊïàÊèêÂçá‰∫ÜÂåªÂ≠¶ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÂú®ÁõÆÊ†áÂüüÁöÑÂàÜÂâ≤ÊÄßËÉΩ„ÄÇËôΩÁÑ∂ÂÖ∑‰ΩìÂÆûÈ™åÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜËØ•ÊñπÊ≥ïÂú®Èôç‰ΩéÊ†áÊ≥®ÊàêÊú¨„ÄÅÊèêÈ´òÂæÆË∞ÉÊïàÁéáÊñπÈù¢ÂÖ∑ÊúâÊòæËëó‰ºòÂäøÔºåÊúâÊúõÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÂèñÂæóËâØÂ•ΩÊïàÊûú„ÄÇ‰∏éÈöèÊú∫ÈÄâÊã©Ê†∑Êú¨ÁöÑÂæÆË∞ÉÊñπÊ≥ïÁõ∏ÊØîÔºåASFDAÊñπÊ≥ïËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®ÊúâÈôêÁöÑÊ†áÊ≥®ËµÑÊ∫êÔºåÂÆûÁé∞Êõ¥È´òÁöÑÂàÜÂâ≤Á≤æÂ∫¶„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÂåªÂ≠¶ÂõæÂÉèÂàÜÊûêÈ¢ÜÂüüÔºå‰æãÂ¶ÇÁñæÁóÖËØäÊñ≠„ÄÅÊâãÊúØËßÑÂàíÂíåÁñóÊïàËØÑ‰º∞„ÄÇÈÄöËøáÈ´òÊïàÂú∞ÈÄÇÈÖçÂåªÂ≠¶ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÔºåÂèØ‰ª•Èôç‰ΩéÊ†áÊ≥®ÊàêÊú¨ÔºåÊèêÈ´òÂàÜÂâ≤Á≤æÂ∫¶Ôºå‰ªéËÄåËæÖÂä©ÂåªÁîüËøõË°åÊõ¥ÂáÜÁ°Æ„ÄÅÊõ¥Âø´ÈÄüÁöÑËØäÊñ≠ÂíåÊ≤ªÁñó„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÊé®ÂπøÂà∞ÂÖ∂‰ªñÂåªÂ≠¶ÂõæÂÉèÊ®°ÊÄÅÂíå‰∏¥Â∫äÂ∫îÁî®Âú∫ÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Medical Vision Foundation Models (Med-VFMs) have superior capabilities of interpreting medical images due to the knowledge learned from self-supervised pre-training with extensive unannotated images. To improve their performance on adaptive downstream evaluations, especially segmentation, a few samples from target domains are selected randomly for fine-tuning them. However, there lacks works to explore the way of adapting Med-VFMs to achieve the optimal performance on target domains efficiently. Thus, it is highly demanded to design an efficient way of fine-tuning Med-VFMs by selecting informative samples to maximize their adaptation performance on target domains. To achieve this, we propose an Active Source-Free Domain Adaptation (ASFDA) method to efficiently adapt Med-VFMs to target domains for volumetric medical image segmentation. This ASFDA employs a novel Active Learning (AL) method to select the most informative samples from target domains for fine-tuning Med-VFMs without the access to source pre-training samples, thus maximizing their performance with the minimal selection budget. In this AL method, we design an Active Test Time Sample Query strategy to select samples from the target domains via two query metrics, including Diversified Knowledge Divergence (DKD) and Anatomical Segmentation Difficulty (ASD). DKD is designed to measure the source-target knowledge gap and intra-domain diversity. It utilizes the knowledge of pre-training to guide the querying of source-dissimilar and semantic-diverse samples from the target domains. ASD is designed to evaluate the difficulty in segmentation of anatomical structures by measuring predictive entropy from foreground regions adaptively. Additionally, our ASFDA method employs a Selective Semi-supervised Fine-tuning to improve the performance and efficiency of fine-tuning by identifying samples with high reliability from unqueried ones.

