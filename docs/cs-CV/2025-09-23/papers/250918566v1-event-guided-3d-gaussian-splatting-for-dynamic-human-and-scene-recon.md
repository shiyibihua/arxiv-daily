---
layout: default
title: Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction
---

# Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.18566" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.18566v1</a>
  <a href="https://arxiv.org/pdf/2509.18566.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.18566v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.18566v1', 'Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaoting Yin, Hao Shi, Kailun Yang, Jiajun Zhai, Shangwei Guo, Lin Wang, Kaiwei Wang

**åˆ†ç±»**: cs.CV, cs.RO, eess.IV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-23

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºäº‹ä»¶ç›¸æœºå¼•å¯¼çš„3Dé«˜æ–¯æº…å°„æ–¹æ³•ï¼Œç”¨äºåŠ¨æ€äººä½“å’Œåœºæ™¯é‡å»º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `äº‹ä»¶ç›¸æœº` `3Dé«˜æ–¯æº…å°„` `åŠ¨æ€é‡å»º` `äººä½“å»ºæ¨¡` `åœºæ™¯é‡å»º` `å•ç›®è§†è§‰` `è¿åŠ¨æ¨¡ç³Š`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å•ç›®è§†é¢‘é‡å»ºåŠ¨æ€äººä½“å’Œé™æ€åœºæ™¯é¢ä¸´è¿åŠ¨æ¨¡ç³ŠæŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å¿«é€Ÿè¿åŠ¨ä¸‹ï¼ŒRGBå¸§è´¨é‡ä¸‹é™ã€‚
2. åˆ©ç”¨äº‹ä»¶ç›¸æœºé«˜æ—¶é—´åˆ†è¾¨ç‡çš„ä¼˜åŠ¿ï¼Œæå‡ºåŸºäº3Dé«˜æ–¯æº…å°„çš„äº‹ä»¶å¼•å¯¼äººä½“-åœºæ™¯è”åˆé‡å»ºæ¡†æ¶ã€‚
3. é€šè¿‡äº‹ä»¶å¼•å¯¼çš„æŸå¤±å‡½æ•°åŒ¹é…æ¸²æŸ“äº®åº¦å˜åŒ–ä¸äº‹ä»¶æµï¼Œæå‡å¿«é€Ÿè¿åŠ¨åŒºåŸŸçš„é‡å»ºä¿çœŸåº¦ï¼Œå¹¶åœ¨benchmarkä¸Šå–å¾—SOTAç»“æœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„äº‹ä»¶å¼•å¯¼çš„äººä½“-åœºæ™¯é‡å»ºæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡3Dé«˜æ–¯æº…å°„ä»å•ä¸ªå•ç›®äº‹ä»¶ç›¸æœºè”åˆå»ºæ¨¡äººä½“å’Œåœºæ™¯ã€‚å…·ä½“æ¥è¯´ï¼Œç»Ÿä¸€çš„3Dé«˜æ–¯é›†åˆæºå¸¦å¯å­¦ä¹ çš„è¯­ä¹‰å±æ€§ï¼›åªæœ‰è¢«åˆ†ç±»ä¸ºäººä½“çš„Gaussiansæ‰è¿›è¡Œå½¢å˜ä»¥ç”¨äºåŠ¨ç”»ï¼Œè€Œåœºæ™¯Gaussiansä¿æŒé™æ€ã€‚ä¸ºäº†å¯¹æŠ—æ¨¡ç³Šï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§äº‹ä»¶å¼•å¯¼çš„æŸå¤±ï¼Œè¯¥æŸå¤±å°†è¿ç»­æ¸²æŸ“ä¹‹é—´çš„æ¨¡æ‹Ÿäº®åº¦å˜åŒ–ä¸äº‹ä»¶æµè¿›è¡ŒåŒ¹é…ï¼Œä»è€Œæé«˜äº†å¿«é€Ÿç§»åŠ¨åŒºåŸŸçš„å±€éƒ¨ä¿çœŸåº¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ— éœ€å¤–éƒ¨äººä½“æ©æ¨¡ï¼Œå¹¶ç®€åŒ–äº†ç®¡ç†å•ç‹¬é«˜æ–¯é›†åˆçš„è¿‡ç¨‹ã€‚åœ¨ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ZJU-MoCap-Blurå’ŒMMHPSD-Blurä¸Šï¼Œå®ƒæä¾›äº†æœ€å…ˆè¿›çš„äººä½“-åœºæ™¯é‡å»ºï¼Œä¸å¼ºå¤§çš„åŸºçº¿ç›¸æ¯”ï¼Œåœ¨PSNR/SSIMæ–¹é¢æœ‰æ˜¾è‘—æé«˜ï¼Œå¹¶é™ä½äº†LPIPSï¼Œå°¤å…¶æ˜¯åœ¨é«˜é€Ÿå¯¹è±¡ä¸Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»å•ç›®äº‹ä»¶ç›¸æœºæ•°æ®ä¸­ï¼ŒåŒæ—¶é‡å»ºåŠ¨æ€äººä½“å’Œé™æ€åœºæ™¯çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¿«é€Ÿè¿åŠ¨æ—¶ï¼Œç”±äºRGBå›¾åƒçš„è¿åŠ¨æ¨¡ç³Šï¼Œé‡å»ºæ•ˆæœä¸ä½³ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤–éƒ¨äººä½“æ©æ¨¡ï¼Œå¢åŠ äº†å¤æ‚æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨äº‹ä»¶ç›¸æœºçš„é«˜æ—¶é—´åˆ†è¾¨ç‡ç‰¹æ€§ï¼Œç»“åˆ3Dé«˜æ–¯æº…å°„æŠ€æœ¯ï¼Œå®ç°å¯¹åŠ¨æ€äººä½“å’Œé™æ€åœºæ™¯çš„è”åˆå»ºæ¨¡ã€‚é€šè¿‡äº‹ä»¶å¼•å¯¼çš„æŸå¤±å‡½æ•°ï¼Œå°†æ¸²æŸ“å›¾åƒçš„äº®åº¦å˜åŒ–ä¸äº‹ä»¶æµè¿›è¡ŒåŒ¹é…ï¼Œä»è€Œåœ¨å¿«é€Ÿè¿åŠ¨åŒºåŸŸæé«˜é‡å»ºçš„ä¿çœŸåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ä½¿ç”¨3Dé«˜æ–¯æº…å°„è¡¨ç¤ºåœºæ™¯å’Œäººä½“ï¼›2) ä¸ºæ¯ä¸ªé«˜æ–¯èµ‹äºˆå¯å­¦ä¹ çš„è¯­ä¹‰å±æ€§ï¼ŒåŒºåˆ†äººä½“å’Œåœºæ™¯ï¼›3) å¯¹äººä½“é«˜æ–¯è¿›è¡Œå½¢å˜ä»¥å®ç°åŠ¨ç”»æ•ˆæœï¼Œåœºæ™¯é«˜æ–¯ä¿æŒé™æ€ï¼›4) ä½¿ç”¨äº‹ä»¶å¼•å¯¼çš„æŸå¤±å‡½æ•°ä¼˜åŒ–é«˜æ–¯å‚æ•°ï¼Œæé«˜é‡å»ºè´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§äº‹ä»¶å¼•å¯¼çš„æŸå¤±å‡½æ•°ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨äº‹ä»¶ç›¸æœºæ•°æ®æ¥æé«˜é‡å»ºè´¨é‡ï¼Œå°¤å…¶æ˜¯åœ¨å¿«é€Ÿè¿åŠ¨åŒºåŸŸï¼›2) æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„3Dé«˜æ–¯è¡¨ç¤ºæ–¹æ³•ï¼Œèƒ½å¤ŸåŒæ—¶å»ºæ¨¡åŠ¨æ€äººä½“å’Œé™æ€åœºæ™¯ï¼Œæ— éœ€å¤–éƒ¨äººä½“æ©æ¨¡ã€‚

**å…³é”®è®¾è®¡**ï¼šäº‹ä»¶å¼•å¯¼çš„æŸå¤±å‡½æ•°è®¡ç®—è¿ç»­æ¸²æŸ“å¸§ä¹‹é—´çš„äº®åº¦å˜åŒ–ï¼Œå¹¶å°†å…¶ä¸äº‹ä»¶æµè¿›è¡ŒåŒ¹é…ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡æ¸²æŸ“å¾—åˆ°ä¸¤å¸§å›¾åƒï¼Œè®¡ç®—åƒç´ çº§åˆ«çš„äº®åº¦å·®å¼‚ï¼Œç„¶åä¸äº‹ä»¶ç›¸æœºè®°å½•çš„äº‹ä»¶ä¿¡æ¯è¿›è¡Œå¯¹æ¯”ï¼Œæœ€å°åŒ–ä¸¤è€…ä¹‹é—´çš„å·®å¼‚ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†å¯å­¦ä¹ çš„è¯­ä¹‰å±æ€§ï¼Œç”¨äºåŒºåˆ†äººä½“å’Œåœºæ™¯é«˜æ–¯ï¼Œå¹¶ä½¿ç”¨å½¢å˜åœºå¯¹äººä½“é«˜æ–¯è¿›è¡ŒåŠ¨ç”»ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨ZJU-MoCap-Blurå’ŒMMHPSD-Blurä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å–å¾—äº†state-of-the-artçš„ç»“æœã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨PSNRå’ŒSSIMæŒ‡æ ‡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼ŒLPIPSæŒ‡æ ‡ä¹Ÿå¾—åˆ°äº†æœ‰æ•ˆé™ä½ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†é«˜é€Ÿè¿åŠ¨å¯¹è±¡æ—¶ï¼Œä¼˜åŠ¿æ›´åŠ æ˜æ˜¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨äº‹ä»¶ç›¸æœºæ•°æ®ï¼Œæé«˜åŠ¨æ€äººä½“å’Œåœºæ™¯çš„é‡å»ºè´¨é‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€äººæœºäº¤äº’ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºåˆ›å»ºæ›´åŠ é€¼çœŸçš„è™šæ‹ŸåŒ–èº«ï¼Œæˆ–è€…åœ¨ARåº”ç”¨ä¸­å®ç°å¯¹åŠ¨æ€äººä½“å’Œå‘¨å›´ç¯å¢ƒçš„å®æ—¶é‡å»ºå’Œäº¤äº’ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºè¿åŠ¨åˆ†æã€åŠ¨ä½œæ•æ‰ç­‰é¢†åŸŸï¼Œä¸ºç›¸å…³ç ”ç©¶æä¾›æ›´å‡†ç¡®çš„æ•°æ®æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reconstructing dynamic humans together with static scenes from monocular videos remains difficult, especially under fast motion, where RGB frames suffer from motion blur. Event cameras exhibit distinct advantages, e.g., microsecond temporal resolution, making them a superior sensing choice for dynamic human reconstruction. Accordingly, we present a novel event-guided human-scene reconstruction framework that jointly models human and scene from a single monocular event camera via 3D Gaussian Splatting. Specifically, a unified set of 3D Gaussians carries a learnable semantic attribute; only Gaussians classified as human undergo deformation for animation, while scene Gaussians stay static. To combat blur, we propose an event-guided loss that matches simulated brightness changes between consecutive renderings with the event stream, improving local fidelity in fast-moving regions. Our approach removes the need for external human masks and simplifies managing separate Gaussian sets. On two benchmark datasets, ZJU-MoCap-Blur and MMHPSD-Blur, it delivers state-of-the-art human-scene reconstruction, with notable gains over strong baselines in PSNR/SSIM and reduced LPIPS, especially for high-speed subjects.

