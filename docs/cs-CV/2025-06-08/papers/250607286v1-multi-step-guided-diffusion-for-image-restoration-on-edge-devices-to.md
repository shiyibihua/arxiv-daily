---
layout: default
title: Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI
---

# Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.07286" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.07286v1</a>
  <a href="https://arxiv.org/pdf/2506.07286.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.07286v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.07286v1', 'Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aditya Chakravarty

**åˆ†ç±»**: cs.CV, cs.LG, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-08

**å¤‡æ³¨**: Accepted in CVPR 2025 Embodied AI Workshop

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ­¥å¼•å¯¼æ‰©æ•£ä»¥æå‡è¾¹ç¼˜è®¾å¤‡å›¾åƒæ¢å¤èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾åƒæ¢å¤` `æ‰©æ•£æ¨¡å‹` `å¤šæ­¥ä¼˜åŒ–` `è¾¹ç¼˜è®¡ç®—` `åµŒå…¥å¼AI` `æ— äººæœº` `ç§»åŠ¨æœºå™¨äºº` `å®æ—¶å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å›¾åƒæ¢å¤æ–¹æ³•å¦‚MPGDä»…åœ¨å»å™ªæ­¥éª¤ä¸­è¿›è¡Œå•ä¸€æ¢¯åº¦æ›´æ–°ï¼Œå¯¼è‡´æ¢å¤æ•ˆæœå—é™ï¼Œå°¤å…¶åœ¨åµŒå…¥å¼æˆ–åˆ†å¸ƒå¤–åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ­¥ä¼˜åŒ–ç­–ç•¥ï¼Œé€šè¿‡åœ¨æ¯ä¸ªå»å™ªæ—¶é—´æ­¥å†…è¿›è¡Œå¤šæ¬¡æ¢¯åº¦æ›´æ–°ï¼Œæ˜¾è‘—æå‡å›¾åƒæ¢å¤çš„è´¨é‡å’Œé²æ£’æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¢åŠ æ¯æ­¥çš„æ¢¯åº¦æ›´æ–°æ¬¡æ•°èƒ½å¤Ÿæœ‰æ•ˆæé«˜LPIPSå’ŒPSNRæŒ‡æ ‡ï¼Œä¸”å»¶è¿Ÿå¢åŠ æå°ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰©æ•£æ¨¡å‹åœ¨è§£å†³é€†é—®é¢˜æ–¹é¢å±•ç°äº†æ˜¾è‘—çš„çµæ´»æ€§ï¼Œä½†ç°æœ‰æ–¹æ³•å¦‚å•ä¸€æ¢¯åº¦æ›´æ–°çš„æµå½¢ä¿æŒå¼•å¯¼æ‰©æ•£ï¼ˆMPGDï¼‰åœ¨å›¾åƒæ¢å¤çš„ä¿çœŸåº¦å’Œé²æ£’æ€§ä¸Šå­˜åœ¨å±€é™ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ­¥ä¼˜åŒ–ç­–ç•¥ï¼Œåœ¨æ¯ä¸ªå»å™ªæ—¶é—´æ­¥å†…è¿›è¡Œå¤šæ¬¡æ¢¯åº¦æ›´æ–°ï¼Œä»è€Œæ˜¾è‘—æå‡å›¾åƒè´¨é‡ã€æ„ŸçŸ¥å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¢åŠ æ¯æ­¥çš„æ¢¯åº¦æ›´æ–°æ¬¡æ•°èƒ½å¤Ÿåœ¨ä¿æŒä½å»¶è¿Ÿçš„åŒæ—¶ï¼Œæå‡LPIPSå’ŒPSNRæŒ‡æ ‡ã€‚æˆ‘ä»¬åœ¨Jetson Orin Nanoä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•ï¼Œç»“æœæ˜¾ç¤ºMPGDåœ¨è‡ªç„¶å’Œç©ºä¸­åœºæ™¯ä¸­å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¡¨æ˜å…¶ä½œä¸ºè½»é‡çº§å®æ—¶è§†è§‰æ„ŸçŸ¥æ¨¡å—çš„æ½œåŠ›ï¼Œé€‚ç”¨äºæ— äººæœºå’Œç§»åŠ¨æœºå™¨äººç­‰åµŒå…¥å¼AIä»£ç†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å›¾åƒæ¢å¤æ–¹æ³•åœ¨å»å™ªè¿‡ç¨‹ä¸­ä»…è¿›è¡Œå•ä¸€æ¢¯åº¦æ›´æ–°æ‰€å¯¼è‡´çš„æ¢å¤æ•ˆæœä¸ä½³çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨åµŒå…¥å¼è®¾å¤‡å’Œåˆ†å¸ƒå¤–åœºæ™¯ä¸­è¡¨ç°ä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºåœ¨æ¯ä¸ªå»å™ªæ—¶é—´æ­¥å†…è¿›è¡Œå¤šæ¬¡æ¢¯åº¦æ›´æ–°çš„å¤šæ­¥ä¼˜åŒ–ç­–ç•¥ï¼Œä»¥æå‡å›¾åƒè´¨é‡å’Œæ„ŸçŸ¥å‡†ç¡®æ€§ã€‚é€šè¿‡è¿™ç§è®¾è®¡ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒä½å»¶è¿Ÿçš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªå»å™ªæ—¶é—´æ­¥ï¼Œæ¯ä¸ªæ—¶é—´æ­¥å†…è¿›è¡Œå¤šæ¬¡æ¢¯åº¦æ›´æ–°ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬å›¾åƒè¾“å…¥ã€å»å™ªå¤„ç†å’Œè¾“å‡ºè¯„ä¼°ï¼Œç¡®ä¿æ¯ä¸ªæ­¥éª¤éƒ½èƒ½æœ‰æ•ˆæå‡å›¾åƒè´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥å¤šæ­¥æ¢¯åº¦æ›´æ–°æœºåˆ¶ï¼Œä¸ä¼ ç»Ÿçš„å•æ­¥æ›´æ–°æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†å›¾åƒæ¢å¤çš„ä¿çœŸåº¦å’Œé²æ£’æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œä¼˜åŒ–äº†æ¯ä¸ªæ—¶é—´æ­¥çš„æ›´æ–°æ¬¡æ•°ï¼Œå¹¶é‡‡ç”¨äº†é€‚å½“çš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡æ¢å¤è´¨é‡ä¸è®¡ç®—æ•ˆç‡ï¼Œç¡®ä¿åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°å®æ—¶å¤„ç†ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œè¶…å‚æ•°è®¾ç½®åœ¨å®éªŒä¸­è¿›è¡Œäº†è¯¦ç»†è°ƒä¼˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¢åŠ æ¯æ­¥çš„æ¢¯åº¦æ›´æ–°æ¬¡æ•°åï¼ŒLPIPSå’ŒPSNRæŒ‡æ ‡å‡æœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“æå‡å¹…åº¦æœªçŸ¥ã€‚è¯¥æ–¹æ³•åœ¨Jetson Orin Nanoä¸ŠéªŒè¯ï¼Œè¡¨æ˜å…¶åœ¨è‡ªç„¶å’Œç©ºä¸­åœºæ™¯ä¸­çš„è‰¯å¥½æ³›åŒ–èƒ½åŠ›ï¼Œå±•ç°å‡ºä½œä¸ºå®æ—¶è§†è§‰æ„ŸçŸ¥æ¨¡å—çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ— äººæœºã€ç§»åŠ¨æœºå™¨äººç­‰åµŒå…¥å¼AIä»£ç†çš„å®æ—¶è§†è§‰æ„ŸçŸ¥ã€‚é€šè¿‡æä¾›è½»é‡çº§çš„å›¾åƒæ¢å¤æ¨¡å—ï¼Œèƒ½å¤Ÿåœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­å®ç°é«˜è´¨é‡çš„å›¾åƒå¤„ç†ï¼Œæå‡è‡ªåŠ¨åŒ–ç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³å’Œé€‚åº”èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Diffusion models have shown remarkable flexibility for solving inverse problems without task-specific retraining. However, existing approaches such as Manifold Preserving Guided Diffusion (MPGD) apply only a single gradient update per denoising step, limiting restoration fidelity and robustness, especially in embedded or out-of-distribution settings. In this work, we introduce a multistep optimization strategy within each denoising timestep, significantly enhancing image quality, perceptual accuracy, and generalization. Our experiments on super-resolution and Gaussian deblurring demonstrate that increasing the number of gradient updates per step improves LPIPS and PSNR with minimal latency overhead. Notably, we validate this approach on a Jetson Orin Nano using degraded ImageNet and a UAV dataset, showing that MPGD, originally trained on face datasets, generalizes effectively to natural and aerial scenes. Our findings highlight MPGD's potential as a lightweight, plug-and-play restoration module for real-time visual perception in embodied AI agents such as drones and mobile robots.

