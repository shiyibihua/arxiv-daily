---
layout: default
title: DReX: Pure Vision Fusion of Self-Supervised and Convolutional Representations for Image Complexity Prediction
---

# DReX: Pure Vision Fusion of Self-Supervised and Convolutional Representations for Image Complexity Prediction

**arXiv**: [2511.16991v1](https://arxiv.org/abs/2511.16991) | [PDF](https://arxiv.org/pdf/2511.16991.pdf)

**ä½œè€…**: Jonathan Skaza, Parsa Madinei, Ziqi Wen, Miguel Eckstein

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDReXèžåˆè‡ªç›‘ç£ä¸Žå·ç§¯è¡¨ç¤ºï¼Œç”¨äºŽå›¾åƒå¤æ‚åº¦é¢„æµ‹ã€‚**

**å…³é”®è¯**: `å›¾åƒå¤æ‚åº¦é¢„æµ‹` `ç‰¹å¾èžåˆ` `è‡ªç›‘ç£å­¦ä¹ ` `å·ç§¯ç¥žç»ç½‘ç»œ` `æ³¨æ„åŠ›æœºåˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§‰å¤æ‚åº¦é¢„æµ‹ï¼Œåº”ç”¨äºŽå›¾åƒåŽ‹ç¼©å’Œè®¤çŸ¥ç§‘å­¦ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šèžåˆResNet-50å’ŒDINOv3ç‰¹å¾ï¼Œä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨IC9600åŸºå‡†ä¸Šè¾¾åˆ°SOTAï¼Œå‚æ•°å‡å°‘21.5å€ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Visual complexity prediction is a fundamental problem in computer vision with applications in image compression, retrieval, and classification. Understanding what makes humans perceive an image as complex is also a long-standing question in cognitive science. Recent approaches have leveraged multimodal models that combine visual and linguistic representations, but it remains unclear whether language information is necessary for this task. We propose DReX (DINO-ResNet Fusion), a vision-only model that fuses self-supervised and convolutional representations through a learnable attention mechanism to predict image complexity. Our architecture integrates multi-scale hierarchical features from ResNet-50 with semantically rich representations from DINOv3 ViT-S/16, enabling the model to capture both low-level texture patterns and high-level semantic structure. DReX achieves state-of-the-art performance on the IC9600 benchmark (Pearson r = 0.9581), surpassing previous methods--including those trained on multimodal image-text data--while using approximately 21.5x fewer learnable parameters. Furthermore, DReX generalizes robustly across multiple datasets and metrics, achieving superior results on Pearson and Spearman correlation, Root Mean Square Error (RMSE), and Mean Absolute Error (MAE). Ablation and attention analyses confirm that DReX leverages complementary cues from both backbones, with the DINOv3 [CLS] token enhancing sensitivity to visual complexity. Our findings suggest that visual features alone can be sufficient for human-aligned complexity prediction and that, when properly fused, self-supervised transformers and supervised deep convolutional neural networks offer complementary and synergistic benefits for this task.

