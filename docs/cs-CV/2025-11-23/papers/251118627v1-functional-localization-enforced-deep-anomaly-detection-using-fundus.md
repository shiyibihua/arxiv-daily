---
layout: default
title: Functional Localization Enforced Deep Anomaly Detection Using Fundus Images
---

# Functional Localization Enforced Deep Anomaly Detection Using Fundus Images

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.18627" target="_blank" class="toolbar-btn">arXiv: 2511.18627v1</a>
    <a href="https://arxiv.org/pdf/2511.18627.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.18627v1" 
            onclick="toggleFavorite(this, '2511.18627v1', 'Functional Localization Enforced Deep Anomaly Detection Using Fundus Images')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Jan Benedikt Ruhland, Thorsten Papenbrock, Jan-Peter Sowa, Ali Canbay, Nicole Eter, Bernd Freisleben, Dominik Heider

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-23

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨çœ¼åº•å›¾åƒå’ŒåŠŸèƒ½å®šä½å¢å¼ºçš„æ·±åº¦å¼‚å¸¸æ£€æµ‹æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `çœ¼åº•å›¾åƒåˆ†æ` `è§†ç½‘è†œç–¾ç—…æ£€æµ‹` `Vision Transformer` `GANomaly` `å¼‚å¸¸æ£€æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çœ¼åº•å›¾åƒè§†ç½‘è†œç–¾ç—…æ£€æµ‹å—æˆåƒè´¨é‡ã€æ—©æœŸç—…å˜ç»†å¾®å’Œæ•°æ®é›†å·®å¼‚å½±å“ï¼Œç°æœ‰æ–¹æ³•æ³›åŒ–æ€§ä¸è¶³ã€‚
2. æå‡ºä¸€ç§åŸºäºVision Transformerçš„åˆ†ç±»å™¨å’ŒGANomalyçš„å¼‚å¸¸æ£€æµ‹å™¨ï¼Œç»“åˆåŠŸèƒ½å®šä½å¢å¼ºæ£€æµ‹æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒViTåˆ†ç±»å™¨åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒGANomalyå¼‚å¸¸æ£€æµ‹å™¨å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»çœ¼åº•å›¾åƒä¸­å¯é åœ°æ£€æµ‹è§†ç½‘è†œç–¾ç—…é¢ä¸´ç€æˆåƒè´¨é‡çš„å¯å˜æ€§ã€æ—©æœŸé˜¶æ®µè¡¨ç°çš„ç»†å¾®å·®åˆ«ä»¥åŠæ•°æ®é›†ä¹‹é—´çš„é¢†åŸŸè½¬ç§»ç­‰æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåœ°è¯„ä¼°äº†Vision Transformer (ViT)åˆ†ç±»å™¨åœ¨å¤šä¸ªå¼‚æ„å…¬å…±æ•°æ®é›†ä»¥åŠå†…éƒ¨åˆ›å»ºçš„é«˜è´¨é‡çœ¼åº•æ•°æ®é›†AEyeDBä¸Šçš„å¤šç§å¢å¼ºç­–ç•¥ã€‚ViTè¡¨ç°å‡ºå§‹ç»ˆå¦‚ä¸€çš„å¼ºå¤§æ€§èƒ½ï¼Œåœ¨ä¸åŒæ•°æ®é›†å’Œç–¾ç—…ä¸Šçš„å‡†ç¡®ç‡èŒƒå›´ä¸º0.789åˆ°0.843ã€‚ç³–å°¿ç—…è§†ç½‘è†œç—…å˜å’Œå¹´é¾„ç›¸å…³æ€§é»„æ–‘å˜æ€§è¢«å¯é åœ°æ£€æµ‹åˆ°ï¼Œè€Œé’å…‰çœ¼ä»ç„¶æ˜¯æœ€å¸¸è¢«é”™è¯¯åˆ†ç±»çš„ç–¾ç—…ã€‚å‡ ä½•å’Œé¢œè‰²å¢å¼ºæä¾›äº†æœ€ç¨³å®šçš„æ”¹è¿›ï¼Œè€Œç›´æ–¹å›¾å‡è¡¡åŒ–æœ‰åˆ©äºä»¥ç»“æ„ç»†å¾®ä¹‹å¤„ä¸ºä¸»çš„æ•°æ®é›†ã€‚æ‹‰æ™®æ‹‰æ–¯å¢å¼ºé™ä½äº†ä¸åŒè®¾ç½®ä¸‹çš„æ€§èƒ½ã€‚åœ¨Papilaæ•°æ®é›†ä¸Šï¼Œé‡‡ç”¨å‡ ä½•å¢å¼ºçš„ViTå®ç°äº†0.91çš„AUCï¼Œä¼˜äºå…ˆå‰æŠ¥å‘Šçš„å·ç§¯é›†æˆåŸºçº¿ï¼ˆAUCä¸º0.87ï¼‰ï¼Œçªå‡ºäº†Transformeræ¶æ„å’Œå¤šæ•°æ®é›†è®­ç»ƒçš„ä¼˜åŠ¿ã€‚ä¸ºäº†è¡¥å……åˆ†ç±»å™¨ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŸºäºGANomalyçš„å¼‚å¸¸æ£€æµ‹å™¨ï¼Œå®ç°äº†0.76çš„AUCï¼ŒåŒæ—¶æä¾›äº†å›ºæœ‰çš„åŸºäºé‡å»ºçš„å¯è§£é‡Šæ€§å’Œå¯¹æœªè§æ•°æ®çš„é²æ£’æ³›åŒ–ã€‚ä½¿ç”¨GUESSçš„æ¦‚ç‡æ ¡å‡†ä¸ºæœªæ¥çš„ä¸´åºŠå®æ–½æä¾›äº†ç‹¬ç«‹äºé˜ˆå€¼çš„å†³ç­–æ”¯æŒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçœ¼åº•å›¾åƒåˆ†ææ—¨åœ¨è¾…åŠ©è¯Šæ–­å„ç§è§†ç½‘è†œç–¾ç—…ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä¸åŒè´¨é‡ã€ä¸åŒæ¥æºçš„å›¾åƒæ—¶ï¼Œå®¹æ˜“å—åˆ°é¢†åŸŸåç§»çš„å½±å“ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸‹é™ã€‚æ­¤å¤–ï¼Œæ—©æœŸç—…å˜çš„ç»†å¾®ç‰¹å¾éš¾ä»¥æ•æ‰ï¼Œä¹Ÿå¢åŠ äº†è¯Šæ–­éš¾åº¦ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚å·ç§¯ç¥ç»ç½‘ç»œï¼Œåœ¨æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬ç ”ç©¶çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Vision Transformer (ViT) å¼ºå¤§çš„å…¨å±€å»ºæ¨¡èƒ½åŠ›ï¼Œç»“åˆæ•°æ®å¢å¼ºç­–ç•¥ï¼Œæé«˜æ¨¡å‹å¯¹ä¸åŒæ•°æ®é›†å’Œç–¾ç—…çš„æ³›åŒ–èƒ½åŠ›ã€‚åŒæ—¶ï¼Œåˆ©ç”¨GANomalyè¿›è¡Œå¼‚å¸¸æ£€æµ‹ï¼Œæä¾›åŸºäºé‡å»ºçš„å¯è§£é‡Šæ€§ï¼Œå¢å¼ºæ¨¡å‹å¯¹æœªçŸ¥ç—…å˜çš„è¯†åˆ«èƒ½åŠ›ã€‚é€šè¿‡æ¦‚ç‡æ ¡å‡†ï¼Œä¸ºä¸´åºŠå†³ç­–æä¾›æ›´å¯é çš„ä¾æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼š1) åŸºäºViTçš„åˆ†ç±»å™¨ï¼Œç”¨äºå¯¹å¸¸è§è§†ç½‘è†œç–¾ç—…è¿›è¡Œåˆ†ç±»ï¼›2) åŸºäºGANomalyçš„å¼‚å¸¸æ£€æµ‹å™¨ï¼Œç”¨äºæ£€æµ‹æœªçŸ¥æˆ–ç½•è§çš„ç—…å˜ã€‚ViTåˆ†ç±»å™¨é¦–å…ˆåœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†å’Œè‡ªå»ºæ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åé’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œå¾®è°ƒã€‚GANomalyåˆ™é€šè¿‡å­¦ä¹ æ­£å¸¸çœ¼åº•å›¾åƒçš„åˆ†å¸ƒï¼Œæ£€æµ‹ä¸æ­£å¸¸åˆ†å¸ƒåå·®è¾ƒå¤§çš„å¼‚å¸¸å›¾åƒã€‚æœ€åï¼Œä½¿ç”¨GUESSè¿›è¡Œæ¦‚ç‡æ ¡å‡†ï¼Œå°†æ¨¡å‹è¾“å‡ºè½¬åŒ–ä¸ºå¯é çš„æ¦‚ç‡ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šä¸»è¦åˆ›æ–°ç‚¹åœ¨äºï¼š1) å°†ViTåº”ç”¨äºçœ¼åº•å›¾åƒåˆ†ç±»ï¼Œåˆ©ç”¨å…¶å…¨å±€å»ºæ¨¡èƒ½åŠ›æé«˜åˆ†ç±»ç²¾åº¦ï¼›2) ç»“åˆGANomalyè¿›è¡Œå¼‚å¸¸æ£€æµ‹ï¼Œå¢å¼ºæ¨¡å‹å¯¹æœªçŸ¥ç—…å˜çš„è¯†åˆ«èƒ½åŠ›ï¼Œå¹¶æä¾›å¯è§£é‡Šæ€§ï¼›3) é€šè¿‡å¤šæ•°æ®é›†è®­ç»ƒå’Œæ•°æ®å¢å¼ºï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼›4) ä½¿ç”¨GUESSè¿›è¡Œæ¦‚ç‡æ ¡å‡†ï¼Œä¸ºä¸´åºŠå†³ç­–æä¾›æ›´å¯é çš„ä¾æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šViTåˆ†ç±»å™¨é‡‡ç”¨æ ‡å‡†çš„Transformeræ¶æ„ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„æƒé‡è¿›è¡Œåˆå§‹åŒ–ã€‚æ•°æ®å¢å¼ºç­–ç•¥åŒ…æ‹¬å‡ ä½•å˜æ¢ï¼ˆæ—‹è½¬ã€ç¼©æ”¾ã€å¹³ç§»ï¼‰å’Œé¢œè‰²å˜æ¢ï¼ˆäº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦ï¼‰ã€‚GANomalyé‡‡ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œç»“æ„ï¼Œç”Ÿæˆå™¨å­¦ä¹ å°†æ½œåœ¨ç©ºé—´å‘é‡æ˜ å°„åˆ°çœ¼åº•å›¾åƒï¼Œåˆ¤åˆ«å™¨åŒºåˆ†çœŸå®å›¾åƒå’Œç”Ÿæˆå›¾åƒã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬å¯¹æŠ—æŸå¤±ã€é‡å»ºæŸå¤±å’Œç¼–ç å™¨æŸå¤±ï¼Œç”¨äºçº¦æŸç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„å­¦ä¹ ã€‚GUESSç”¨äºæ ¡å‡†æ¨¡å‹è¾“å‡ºçš„æ¦‚ç‡ï¼Œä½¿å…¶æ›´æ¥è¿‘çœŸå®æ¦‚ç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ViTåˆ†ç±»å™¨åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œå‡†ç¡®ç‡èŒƒå›´ä¸º0.789åˆ°0.843ã€‚åœ¨Papilaæ•°æ®é›†ä¸Šï¼Œé‡‡ç”¨å‡ ä½•å¢å¼ºçš„ViTå®ç°äº†0.91çš„AUCï¼Œä¼˜äºå…ˆå‰æŠ¥å‘Šçš„å·ç§¯é›†æˆåŸºçº¿ï¼ˆAUCä¸º0.87ï¼‰ã€‚GANomalyå¼‚å¸¸æ£€æµ‹å™¨å®ç°äº†0.76çš„AUCï¼Œå¹¶æä¾›äº†åŸºäºé‡å»ºçš„å¯è§£é‡Šæ€§ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨çœ¼åº•å›¾åƒåˆ†ææ–¹é¢å…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºçœ¼ç§‘ç–¾ç—…çš„è¾…åŠ©è¯Šæ–­ï¼Œå°¤å…¶æ˜¯åœ¨ç¼ºä¹ä¸“ä¸šåŒ»ç”Ÿæˆ–èµ„æºæœ‰é™çš„åœ°åŒºã€‚é€šè¿‡è‡ªåŠ¨åˆ†æçœ¼åº•å›¾åƒï¼Œå¯ä»¥å¿«é€Ÿç­›æŸ¥å‡ºæ½œåœ¨çš„æ‚£è€…ï¼Œå¹¶æä¾›åˆæ­¥çš„è¯Šæ–­å»ºè®®ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºç›‘æµ‹ç–¾ç—…è¿›å±•ï¼Œè¯„ä¼°æ²»ç–—æ•ˆæœï¼Œä»¥åŠå‘ç°æ–°çš„ç—…å˜ç±»å‹ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›é›†æˆåˆ°è¿œç¨‹åŒ»ç–—å¹³å°ä¸­ï¼Œå®ç°æ›´ä¾¿æ·ã€é«˜æ•ˆçš„çœ¼ç§‘åŒ»ç–—æœåŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reliable detection of retinal diseases from fundus images is challenged by the variability in imaging quality, subtle early-stage manifestations, and domain shift across datasets. In this study, we systematically evaluated a Vision Transformer (ViT) classifier under multiple augmentation and enhancement strategies across several heterogeneous public datasets, as well as the AEyeDB dataset, a high-quality fundus dataset created in-house and made available for the research community. The ViT demonstrated consistently strong performance, with accuracies ranging from 0.789 to 0.843 across datasets and diseases. Diabetic retinopathy and age-related macular degeneration were detected reliably, whereas glaucoma remained the most frequently misclassified disease. Geometric and color augmentations provided the most stable improvements, while histogram equalization benefited datasets dominated by structural subtlety. Laplacian enhancement reduced performance across different settings.
>   On the Papila dataset, the ViT with geometric augmentation achieved an AUC of 0.91, outperforming previously reported convolutional ensemble baselines (AUC of 0.87), underscoring the advantages of transformer architectures and multi-dataset training. To complement the classifier, we developed a GANomaly-based anomaly detector, achieving an AUC of 0.76 while providing inherent reconstruction-based explainability and robust generalization to unseen data. Probabilistic calibration using GUESS enabled threshold-independent decision support for future clinical implementation.

