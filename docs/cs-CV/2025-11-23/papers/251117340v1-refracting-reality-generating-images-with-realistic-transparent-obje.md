---
layout: default
title: Refracting Reality: Generating Images with Realistic Transparent Objects
---

# Refracting Reality: Generating Images with Realistic Transparent Objects

**arXiv**: [2511.17340v1](https://arxiv.org/abs/2511.17340) | [PDF](https://arxiv.org/pdf/2511.17340.pdf)

**ä½œè€…**: Yue Yin, Enze Tao, Dylan Campbell

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæŠ˜å°„å®šå¾‹çš„å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œä»¥è§£å†³é€æ˜Žç‰©ä½“æ¸²æŸ“ä¸å‡†ç¡®çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `å›¾åƒç”Ÿæˆ` `é€æ˜Žç‰©ä½“æ¸²æŸ“` `æŠ˜å°„æ¨¡æ‹Ÿ` `å…‰å­¦çº¦æŸ` `åƒç´ åŒæ­¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç”Ÿæˆæ¨¡åž‹åœ¨é€æ˜Žç‰©ä½“æ¸²æŸ“ä¸­æŠ˜å°„æ•ˆæžœå·®ï¼Œæœªå……åˆ†å­¦ä¹ å…‰å­¦è§„å¾‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ–¯æ¶…å°”æŠ˜å°„å®šå¾‹åŒæ­¥åƒç´ ï¼Œç»“åˆå…¨æ™¯å›¾åƒæ¢å¤ä¸å¯è§è¡¨é¢ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç”Ÿæˆå›¾åƒåœ¨å…‰å­¦åˆç†æ€§ä¸Šæ˜¾è‘—æå‡ï¼Œç¬¦åˆç‰©ç†çº¦æŸã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generative image models can produce convincingly real images, with plausible shapes, textures, layouts and lighting. However, one domain in which they perform notably poorly is in the synthesis of transparent objects, which exhibit refraction, reflection, absorption and scattering. Refraction is a particular challenge, because refracted pixel rays often intersect with surfaces observed in other parts of the image, providing a constraint on the color. It is clear from inspection that generative models have not distilled the laws of optics sufficiently well to accurately render refractive objects. In this work, we consider the problem of generating images with accurate refraction, given a text prompt. We synchronize the pixels within the object's boundary with those outside by warping and merging the pixels using Snell's Law of Refraction, at each step of the generation trajectory. For those surfaces that are not directly observed in the image, but are visible via refraction or reflection, we recover their appearance by synchronizing the image with a second generated image -- a panorama centered at the object -- using the same warping and merging procedure. We demonstrate that our approach generates much more optically-plausible images that respect the physical constraints.

