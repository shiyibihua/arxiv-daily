---
layout: default
title: Energy Scaling Laws for Diffusion Models: Quantifying Compute and Carbon Emissions in Image Generation
---

# Energy Scaling Laws for Diffusion Models: Quantifying Compute and Carbon Emissions in Image Generation

**arXiv**: [2511.17031v1](https://arxiv.org/abs/2511.17031) | [PDF](https://arxiv.org/pdf/2511.17031.pdf)

**ä½œè€…**: Aniketh Iyengar, Jiaqi Han, Boris Ruf, Vincent Grari, Marcin Detyniecki, Stefano Ermon

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè®¡ç®—å¤æ‚åº¦çš„æ‰©æ•£æ¨¡åž‹èƒ½è€—é¢„æµ‹æ–¹æ³•ï¼Œä»¥æ”¯æŒå¯æŒç»­AIéƒ¨ç½²ã€‚**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹` `èƒ½è€—é¢„æµ‹` `ç¼©æ”¾å®šå¾‹` `GPUèƒ½è€—` `å¯æŒç»­AI`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ‰©æ•£æ¨¡åž‹å›¾åƒç”Ÿæˆèƒ½è€—é«˜ï¼Œç¼ºä¹è·¨æ¨¡åž‹å’Œç¡¬ä»¶çš„é¢„æµ‹æ–¹æ³•ã€‚
2. é‡‡ç”¨Kaplanç¼©æ”¾å®šå¾‹ï¼Œåˆ†è§£æŽ¨ç†è¿‡ç¨‹ï¼Œå‡è®¾åŽ»å™ªæ“ä½œä¸»å¯¼èƒ½è€—ã€‚
3. å¤šæ¨¡åž‹å’ŒGPUå®žéªŒéªŒè¯é¢„æµ‹å‡†ç¡®æ€§é«˜ï¼Œæ”¯æŒè·¨æž¶æž„æ³›åŒ–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The rapidly growing computational demands of diffusion models for image generation have raised significant concerns about energy consumption and environmental impact. While existing approaches to energy optimization focus on architectural improvements or hardware acceleration, there is a lack of principled methods to predict energy consumption across different model configurations and hardware setups. We propose an adaptation of Kaplan scaling laws to predict GPU energy consumption for diffusion models based on computational complexity (FLOPs). Our approach decomposes diffusion model inference into text encoding, iterative denoising, and decoding components, with the hypothesis that denoising operations dominate energy consumption due to their repeated execution across multiple inference steps. We conduct comprehensive experiments across four state-of-the-art diffusion models (Stable Diffusion 2, Stable Diffusion 3.5, Flux, and Qwen) on three GPU architectures (NVIDIA A100, A4000, A6000), spanning various inference configurations including resolution (256x256 to 1024x1024), precision (fp16/fp32), step counts (10-50), and classifier-free guidance settings. Our energy scaling law achieves high predictive accuracy within individual architectures (R-squared > 0.9) and exhibits strong cross-architecture generalization, maintaining high rank correlations across models and enabling reliable energy estimation for unseen model-hardware combinations. These results validate the compute-bound nature of diffusion inference and provide a foundation for sustainable AI deployment planning and carbon footprint estimation.

