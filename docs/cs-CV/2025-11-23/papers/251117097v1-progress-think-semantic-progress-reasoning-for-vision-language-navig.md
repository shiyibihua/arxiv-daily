---
layout: default
title: Progress-Think: Semantic Progress Reasoning for Vision-Language Navigation
---

# Progress-Think: Semantic Progress Reasoning for Vision-Language Navigation

**arXiv**: [2511.17097v1](https://arxiv.org/abs/2511.17097) | [PDF](https://arxiv.org/pdf/2511.17097.pdf)

**ä½œè€…**: Shuo Wang, Yucheng Wang, Guoxin Lian, Yongcai Wang, Maiyue Chen, Kaihui Wang, Bo Zhang, Zhizhong Su, Yutian Zhou, Wanting Li, Deying Li, Zhaoxin Fan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­ä¹‰è¿›å±•æŽ¨ç†æ–¹æ³•ä»¥æå‡è§†è§‰è¯­è¨€å¯¼èˆªçš„è¿žè´¯æ€§**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€å¯¼èˆª` `è¯­ä¹‰è¿›å±•æŽ¨ç†` `è‡ªå¯¹é½é¢„è®­ç»ƒ` `å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–` `å¤šæ­¥æŒ‡ä»¤ç†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•å¿½è§†è§‚å¯Ÿä¸ŽæŒ‡ä»¤åºåˆ—çš„å•è°ƒå…±è¿›ç‰¹æ€§ï¼Œå¯¼è‡´å¯¼èˆªä¸ä¸€è‡´ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡ä¸‰é˜¶æ®µæ¡†æž¶å®žçŽ°è¯­ä¹‰è¿›å±•é¢„æµ‹ï¼Œæ— éœ€æ˜‚è´µæ ‡æ³¨ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨R2R-CEå’ŒRxR-CEæ•°æ®é›†ä¸Šå®žçŽ°æœ€å…ˆè¿›çš„æˆåŠŸçŽ‡å’Œæ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language Navigation requires agents to act coherently over long horizons by understanding not only local visual context but also how far they have advanced within a multi-step instruction. However, recent Vision-Language-Action models focus on direct action prediction and earlier progress methods predict numeric achievements; both overlook the monotonic co-progression property of the observation and instruction sequences. Building on this insight, Progress-Think introduces semantic progress reasoning, predicting instruction-style progress from visual observations to enable more accurate navigation. To achieve this without expensive annotations, we propose a three-stage framework. In the initial stage, Self-Aligned Progress Pretraining bootstraps a reasoning module via a novel differentiable alignment between visual history and instruction prefixes. Then, Progress-Guided Policy Pretraining injects learned progress states into the navigation context, guiding the policy toward consistent actions. Finally, Progress-Policy Co-Finetuning jointly optimizes both modules with tailored progress-aware reinforcement objectives. Experiments on R2R-CE and RxR-CE show state-of-the-art success and efficiency, demonstrating that semantic progress yields a more consistent representation of navigation advancement.

