---
layout: default
title: SPAGS: Sparse-View Articulated Object Reconstruction from Single State via Planar Gaussian Splatting
---

# SPAGS: Sparse-View Articulated Object Reconstruction from Single State via Planar Gaussian Splatting

**arXiv**: [2511.17092v1](https://arxiv.org/abs/2511.17092) | [PDF](https://arxiv.org/pdf/2511.17092.pdf)

**ä½œè€…**: Di Wu, Liu Liu, Xueyu Yuan, Qiaoyu Jun, Wenxiao Chen, Ruilong Yan, Yiming Tang, Liangtu Song

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå¹³é¢é«˜æ–¯æº…å°„çš„ç¨€ç–è§†å›¾é“°æŽ¥ç‰©ä½“é‡å»ºæ¡†æž¶ï¼Œä»…éœ€å•çŠ¶æ€å›¾åƒè¾“å…¥**

**å…³é”®è¯**: `é“°æŽ¥ç‰©ä½“é‡å»º` `å¹³é¢é«˜æ–¯æº…å°„` `ç¨€ç–è§†å›¾` `éƒ¨ä»¶åˆ†å‰²` `æ·±åº¦å¹³æ»‘æ­£åˆ™åŒ–` `å°‘æ ·æœ¬æ‰©æ•£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰é“°æŽ¥ç‰©ä½“é‡å»ºæ–¹æ³•éœ€å¤šé˜¶æ®µå¤šè§†å›¾è¾“å…¥ï¼Œæˆæœ¬é«˜æ˜‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥é«˜æ–¯ä¿¡æ¯åœºæ„ŸçŸ¥æœ€ä¼˜è§†å›¾ï¼ŒåŽ‹ç¼©3Dé«˜æ–¯ä¸ºå¹³é¢é«˜æ–¯ä¼˜åŒ–
3. å®žéªŒæ•ˆæžœï¼šåœ¨åˆæˆå’ŒçœŸå®žæ•°æ®ä¸Šå®žçŽ°æ›´é«˜ä¿çœŸåº¦çš„éƒ¨ä»¶çº§è¡¨é¢é‡å»º

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Articulated objects are ubiquitous in daily environments, and their 3D reconstruction holds great significance across various fields. However, existing articulated object reconstruction methods typically require costly inputs such as multi-stage and multi-view observations. To address the limitations, we propose a category-agnostic articulated object reconstruction framework via planar Gaussian Splatting, which only uses sparse-view RGB images from a single state. Specifically, we first introduce a Gaussian information field to perceive the optimal sparse viewpoints from candidate camera poses. Then we compress 3D Gaussians into planar Gaussians to facilitate accurate estimation of normal and depth. The planar Gaussians are optimized in a coarse-to-fine manner through depth smooth regularization and few-shot diffusion. Moreover, we introduce a part segmentation probability for each Gaussian primitive and update them by back-projecting part segmentation masks of renderings. Extensive experimental results demonstrate that our method achieves higher-fidelity part-level surface reconstruction on both synthetic and real-world data than existing methods. Codes will be made publicly available.

