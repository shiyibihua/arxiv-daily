---
layout: default
title: Scaling Self-Supervised and Cross-Modal Pretraining for Volumetric CT Transformers
---

# Scaling Self-Supervised and Cross-Modal Pretraining for Volumetric CT Transformers

**arXiv**: [2511.17209v1](https://arxiv.org/abs/2511.17209) | [PDF](https://arxiv.org/pdf/2511.17209.pdf)

**ä½œè€…**: Cris Claessens, Christiaan Viviers, Giacomo D'Amicantonio, Egor Bondarev, Fons van der Sommen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSPECTREåŸºç¡€æ¨¡åž‹ï¼Œé€šè¿‡è‡ªç›‘ç£ä¸Žè·¨æ¨¡æ€é¢„è®­ç»ƒè§£å†³ä½“ç§¯CTè¡¨ç¤ºå­¦ä¹ æŒ‘æˆ˜**

**å…³é”®è¯**: `ä½“ç§¯CTè¡¨ç¤ºå­¦ä¹ ` `è‡ªç›‘ç£é¢„è®­ç»ƒ` `è·¨æ¨¡æ€å¯¹é½` `3Dè§†è§‰Transformer` `åŒ»å­¦å½±åƒåŸºç¡€æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä½“ç§¯CTå­˜åœ¨ä»¤ç‰Œæ‰©å±•ã€å‡ ä½•å„å‘å¼‚æ€§åŠå¼±ç›‘ç£ï¼Œæ ‡å‡†Transformeræ–¹æ³•ä¸é€‚ç”¨
2. æ–¹æ³•è¦ç‚¹ï¼šè”åˆä¼˜åŒ–å±€éƒ¨å’Œå…¨å±€Transformerï¼Œç»“åˆDINOè‡ªè’¸é¦ä¸ŽSigLIPè·¨æ¨¡æ€å¯¹é½
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªCTåŸºå‡†æµ‹è¯•ä¸­ï¼Œé›¶æ ·æœ¬å’Œå¾®è°ƒè®¾ç½®ä¸‹å‡ä¼˜äºŽå…ˆå‰æ¨¡åž‹

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce SPECTRE, a fully transformer-based foundation model for volumetric computed tomography (CT). Our Self-Supervised & Cross-Modal Pretraining for CT Representation Extraction (SPECTRE) approach utilizes scalable 3D Vision Transformer architectures and modern self-supervised and vision-language pretraining strategies to learn general-purpose CT representations. Volumetric CT poses unique challenges, such as extreme token scaling, geometric anisotropy, and weak or noisy clinical supervision, that make standard transformer and contrastive learning recipes ineffective out of the box. The framework jointly optimizes a local transformer for high-resolution volumetric feature extraction and a global transformer for whole-scan context modeling, making large-scale 3D attention computationally tractable. Notably, SPECTRE is trained exclusively on openly available CT datasets, demonstrating that high-performing, generalizable representations can be achieved without relying on private data. Pretraining combines DINO-style self-distillation with SigLIP-based vision-language alignment using paired radiology reports, yielding features that are both geometrically consistent and clinically meaningful. Across multiple CT benchmarks, SPECTRE consistently outperforms prior CT foundation models in both zero-shot and fine-tuned settings, establishing SPECTRE as a scalable, open, and fully transformer-based foundation model for 3D medical imaging.

