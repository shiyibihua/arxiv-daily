---
layout: default
title: Sparse Mixture-of-Experts for Multi-Channel Imaging: Are All Channel Interactions Required?
---

# Sparse Mixture-of-Experts for Multi-Channel Imaging: Are All Channel Interactions Required?

**arXiv**: [2511.17400v1](https://arxiv.org/abs/2511.17400) | [PDF](https://arxiv.org/pdf/2511.17400.pdf)

**ä½œè€…**: Sukwon Yun, Heming Yao, Burkhard Hoeckendorf, David Richmond, Aviv Regev, Russell Littman

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMoE-ViTä»¥è§£å†³å¤šé€šé“å›¾åƒä¸­æ³¨æ„åŠ›è®¡ç®—æ•ˆçŽ‡ä½Žçš„é—®é¢˜**

**å…³é”®è¯**: `ç¨€ç–æ··åˆä¸“å®¶` `å¤šé€šé“å›¾åƒ` `è§†è§‰Transformer` `æ³¨æ„åŠ›æ•ˆçŽ‡` `è®¡ç®—ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šé€šé“å›¾åƒä¸­é€šé“äº¤äº’å»ºæ¨¡å¯¼è‡´æ³¨æ„åŠ›è®¡ç®—äºŒæ¬¡å¢žé•¿ï¼Œæ•ˆçŽ‡ä½Žä¸‹
2. é‡‡ç”¨ç¨€ç–æ··åˆä¸“å®¶æž¶æž„ï¼Œå°†é€šé“è§†ä¸ºä¸“å®¶ï¼Œè½»é‡è·¯ç”±å™¨é€‰æ‹©ç›¸å…³ä¸“å®¶
3. åœ¨JUMP-CPå’ŒSo2Satæ•°æ®é›†ä¸Šå®žçŽ°æ•ˆçŽ‡æå‡ï¼Œæ€§èƒ½æœªæŸå¤±æˆ–å¢žå¼º

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision Transformers ($\text{ViTs}$) have become the backbone of vision foundation models, yet their optimization for multi-channel domains - such as cell painting or satellite imagery - remains underexplored. A key challenge in these domains is capturing interactions between channels, as each channel carries different information. While existing works have shown efficacy by treating each channel independently during tokenization, this approach naturally introduces a major computational bottleneck in the attention block - channel-wise comparisons leads to a quadratic growth in attention, resulting in excessive $\text{FLOPs}$ and high training cost. In this work, we shift focus from efficacy to the overlooked efficiency challenge in cross-channel attention and ask: "Is it necessary to model all channel interactions?". Inspired by the philosophy of Sparse Mixture-of-Experts ($\text{MoE}$), we propose MoE-ViT, a Mixture-of-Experts architecture for multi-channel images in $\text{ViTs}$, which treats each channel as an expert and employs a lightweight router to select only the most relevant experts per patch for attention. Proof-of-concept experiments on real-world datasets - JUMP-CP and So2Sat - demonstrate that $\text{MoE-ViT}$ achieves substantial efficiency gains without sacrificing, and in some cases enhancing, performance, making it a practical and attractive backbone for multi-channel imaging.

