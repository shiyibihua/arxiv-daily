---
layout: default
title: MultiPriv: Benchmarking Individual-Level Privacy Reasoning in Vision-Language Models
---

# MultiPriv: Benchmarking Individual-Level Privacy Reasoning in Vision-Language Models

**arXiv**: [2511.16940v1](https://arxiv.org/abs/2511.16940) | [PDF](https://arxiv.org/pdf/2511.16940.pdf)

**ä½œè€…**: Xiongtao Sun, Hui Li, Jiaming Zhang, Yujie Yang, Kaili Liu, Ruxin Feng, Wen Jun Tan, Wei Yang Bryan Lim

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMultiPrivåŸºå‡†ä»¥è¯„ä¼°è§†è§‰è¯­è¨€æ¨¡åž‹ä¸­çš„ä¸ªä½“çº§éšç§æŽ¨ç†é£Žé™©**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡åž‹` `éšç§æŽ¨ç†åŸºå‡†` `ä¸ªä½“æ¡£æ¡ˆæž„å»º` `å¤šæ¨¡æ€æ•°æ®é›†` `å®‰å…¨å¯¹é½è¯„ä¼°` `éšç§é£Žé™©åˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰éšç§åŸºå‡†æ— æ³•è¯„ä¼°VLMsä»Žåˆ†å¸ƒå¼ä¿¡æ¯æŽ¨æ–­ä¸ªä½“æ¡£æ¡ˆçš„æŽ¨ç†é£Žé™©
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºåŒè¯­å¤šæ¨¡æ€æ•°æ®é›†ï¼ŒåŒ…å«åˆæˆä¸ªä½“æ¡£æ¡ˆï¼Œæ”¯æŒä¹é¡¹éšç§æŽ¨ç†ä»»åŠ¡
3. å®žéªŒæˆ–æ•ˆæžœï¼šè¯„ä¼°50å¤šä¸ªVLMsï¼Œæ­ç¤ºæŽ¨ç†é£Žé™©é«˜ã€æ„ŸçŸ¥æŒ‡æ ‡é¢„æµ‹å·®ã€å®‰å…¨å¯¹é½æ— æ•ˆ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Modern Vision-Language Models (VLMs) demonstrate sophisticated reasoning, escalating privacy risks beyond simple attribute perception to individual-level linkage. Current privacy benchmarks are structurally insufficient for this new threat, as they primarily evaluate privacy perception while failing to address the more critical risk of privacy reasoning: a VLM's ability to infer and link distributed information to construct individual profiles. To address this critical gap, we propose \textbf{MultiPriv}, the first benchmark designed to systematically evaluate individual-level privacy reasoning in VLMs. We introduce the \textbf{Privacy Perception and Reasoning (PPR)} framework and construct a novel, bilingual multimodal dataset to support it. The dataset uniquely features a core component of synthetic individual profiles where identifiers (e.g., faces, names) are meticulously linked to sensitive attributes. This design enables nine challenging tasks evaluating the full PPR spectrum, from attribute detection to cross-image re-identification and chained inference. We conduct a large-scale evaluation of over 50 foundational and commercial VLMs. Our analysis reveals: (1) Many VLMs possess significant, unmeasured reasoning-based privacy risks. (2) Perception-level metrics are poor predictors of these reasoning risks, revealing a critical evaluation gap. (3) Existing safety alignments are inconsistent and ineffective against such reasoning-based attacks. MultiPriv exposes systemic vulnerabilities and provides the necessary framework for developing robust, privacy-preserving VLMs.

