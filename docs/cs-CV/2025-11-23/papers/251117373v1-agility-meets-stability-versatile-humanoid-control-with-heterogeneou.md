---
layout: default
title: Agility Meets Stability: Versatile Humanoid Control with Heterogeneous Data
---

# Agility Meets Stability: Versatile Humanoid Control with Heterogeneous Data

**arXiv**: [2511.17373v1](https://arxiv.org/abs/2511.17373) | [PDF](https://arxiv.org/pdf/2511.17373.pdf)

**ä½œè€…**: Yixuan Pan, Ruoyi Qiao, Li Chen, Kashyap Chitta, Liang Pan, Haoguang Mai, Qingwen Bu, Hao Zhao, Cunyuan Zheng, Ping Luo, Hongyang Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAMSæ¡†æž¶ä»¥ç»Ÿä¸€äººå½¢æœºå™¨äººçš„åŠ¨æ€è¿åŠ¨è·Ÿè¸ªä¸Žæžç«¯å¹³è¡¡æŽ§åˆ¶**

**å…³é”®è¯**: `äººå½¢æœºå™¨äººæŽ§åˆ¶` `å¼‚æž„æ•°æ®å­¦ä¹ ` `æ··åˆå¥–åŠ±è®¾è®¡` `è‡ªé€‚åº”è®­ç»ƒç­–ç•¥` `åŠ¨æ€è¿åŠ¨è·Ÿè¸ª` `å¹³è¡¡ç»´æŠ¤`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•åœ¨æ•æ·æ€§ä¸Žç¨³å®šæ€§é—´éš¾ä»¥å…¼é¡¾ï¼Œå¯¼è‡´æŽ§åˆ¶å™¨åŠŸèƒ½å•ä¸€ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨å¼‚æž„æ•°æ®æºå’Œæ··åˆå¥–åŠ±æ–¹æ¡ˆï¼Œç»“åˆè‡ªé€‚åº”å­¦ä¹ ç­–ç•¥è®­ç»ƒå•ä¸€ç­–ç•¥ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä»¿çœŸå’ŒçœŸå®žæœºå™¨äººä¸ŠéªŒè¯ï¼Œèƒ½æ‰§è¡Œèˆžè¹ˆã€å¥”è·‘åŠé›¶æ ·æœ¬å¹³è¡¡åŠ¨ä½œã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Humanoid robots are envisioned to perform a wide range of tasks in human-centered environments, requiring controllers that combine agility with robust balance. Recent advances in locomotion and whole-body tracking have enabled impressive progress in either agile dynamic skills or stability-critical behaviors, but existing methods remain specialized, focusing on one capability while compromising the other. In this work, we introduce AMS (Agility Meets Stability), the first framework that unifies both dynamic motion tracking and extreme balance maintenance in a single policy. Our key insight is to leverage heterogeneous data sources: human motion capture datasets that provide rich, agile behaviors, and physically constrained synthetic balance motions that capture stability configurations. To reconcile the divergent optimization goals of agility and stability, we design a hybrid reward scheme that applies general tracking objectives across all data while injecting balance-specific priors only into synthetic motions. Further, an adaptive learning strategy with performance-driven sampling and motion-specific reward shaping enables efficient training across diverse motion distributions. We validate AMS extensively in simulation and on a real Unitree G1 humanoid. Experiments demonstrate that a single policy can execute agile skills such as dancing and running, while also performing zero-shot extreme balance motions like Ip Man's Squat, highlighting AMS as a versatile control paradigm for future humanoid applications.

