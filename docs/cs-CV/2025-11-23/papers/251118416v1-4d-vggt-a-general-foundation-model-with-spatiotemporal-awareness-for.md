---
layout: default
title: 4D-VGGT: A General Foundation Model with SpatioTemporal Awareness for Dynamic Scene Geometry Estimation
---

# 4D-VGGT: A General Foundation Model with SpatioTemporal Awareness for Dynamic Scene Geometry Estimation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.18416" target="_blank" class="toolbar-btn">arXiv: 2511.18416v1</a>
    <a href="https://arxiv.org/pdf/2511.18416.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.18416v1" 
            onclick="toggleFavorite(this, '2511.18416v1', '4D-VGGT: A General Foundation Model with SpatioTemporal Awareness for Dynamic Scene Geometry Estimation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Haonan Wang, Hanyu Zhou, Haoyue Liu, Luxin Yan

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-23

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫4D-VGGTÔºåÁî®‰∫éÂä®ÊÄÅÂú∫ÊôØÂá†‰Ωï‰º∞ËÆ°ÁöÑÊó∂Á©∫ÊÑüÁü•ÈÄöÁî®Âü∫Á°ÄÊ®°Âûã**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Âä®ÊÄÅÂú∫ÊôØÂá†‰Ωï‰º∞ËÆ°` `Êó∂Á©∫Ë°®Á§∫` `Â§ö‰ªªÂä°Â≠¶‰π†` `Ê∑±Â∫¶‰º∞ËÆ°` `ÂÖâÊµÅ‰º∞ËÆ°`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂä®ÊÄÅÂú∫ÊôØÂá†‰Ωï‰º∞ËÆ°ÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàËûçÂêàÂºÇÊûÑÁöÑÊó∂Á©∫ÁâπÂæÅÔºåÂØºËá¥Ë°®Á§∫‰∏çÂåπÈÖç„ÄÇ
2. 4D-VGGTÈááÁî®ÂàÜËÄåÊ≤ª‰πãÁöÑÊó∂Á©∫Ë°®Á§∫ÔºåÈÄöËøáË∑®ËßÜÂõæÂÖ®Â±ÄËûçÂêàÂíåË∑®Êó∂Èó¥Â±ÄÈÉ®ËûçÂêàÂàÜÂà´Â§ÑÁêÜÁ©∫Èó¥ÂíåÊó∂Èó¥ÁâπÂæÅ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºå4D-VGGTÂú®Â§ö‰∏™Âä®ÊÄÅÂú∫ÊôØÂá†‰ΩïÂü∫ÂáÜÊµãËØï‰∏≠ÔºåÂú®ÂêÑÁßç‰ªªÂä°‰∏äÈÉΩË°®Áé∞Âá∫ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÁ†îÁ©∂‰∫ÜÂä®ÊÄÅÂú∫ÊôØÂá†‰Ωï‰º∞ËÆ°Ëøô‰∏ÄÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑ‰ªªÂä°ÔºåËØ•‰ªªÂä°ÈúÄË¶ÅÂêåÊó∂Ë°®Á§∫Á©∫Èó¥ÂíåÊó∂Èó¥ÁâπÂæÅ„ÄÇÈÄöÂ∏∏ÔºåÁé∞ÊúâÊñπÊ≥ïÂ∞ÜËøô‰∏§ÁßçÁâπÂæÅÂØπÈΩêÂà∞Áªü‰∏ÄÁöÑÊΩúÂú®Á©∫Èó¥‰∏≠Êù•Âª∫Ê®°Âú∫ÊôØÂá†‰Ωï„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÁ©∫Èó¥ÂíåÊó∂Èó¥ÁâπÂæÅÁöÑÂºÇÊûÑÊÄßÔºåËøôÁßçÁªü‰∏ÄÁöÑËåÉÂºèÂ≠òÂú®ÊΩúÂú®ÁöÑË°®Á§∫‰∏çÂåπÈÖçÈóÆÈ¢ò„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü4D-VGGTÔºå‰∏Ä‰∏™ÂÖ∑ÊúâÂàÜËÄåÊ≤ª‰πãÁöÑÊó∂Á©∫Ë°®Á§∫ÁöÑÈÄöÁî®Âü∫Á°ÄÊ®°ÂûãÔºåÁî®‰∫éÂä®ÊÄÅÂú∫ÊôØÂá†‰Ωï„ÄÇÊàë‰ª¨ÁöÑÊ®°ÂûãÂàÜ‰∏∫‰∏â‰∏™ÊñπÈù¢Ôºö1) Â§öËÆæÁΩÆËæìÂÖ•„ÄÇÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Ëá™ÈÄÇÂ∫îËßÜËßâÁΩëÊ†ºÔºåÊîØÊåÅÂÖ∑Êúâ‰ªªÊÑèÊï∞ÈáèÁöÑËßÜÂõæÂíåÊó∂Èó¥Ê≠•ÈïøÁöÑËæìÂÖ•Â∫èÂàó„ÄÇ2) Â§öÂ±ÇÊ¨°Ë°®Á§∫„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁî®‰∫éÁ©∫Èó¥Ë°®Á§∫ÁöÑË∑®ËßÜÂõæÂÖ®Â±ÄËûçÂêàÂíå‰∏ÄÁßçÁî®‰∫éÊó∂Èó¥Ë°®Á§∫ÁöÑË∑®Êó∂Èó¥Â±ÄÈÉ®ËûçÂêà„ÄÇ3) Â§ö‰ªªÂä°È¢ÑÊµã„ÄÇÊàë‰ª¨Â∞ÜÂ§ö‰∏™ÁâπÂÆö‰∫é‰ªªÂä°ÁöÑÂ§¥ÈÉ®ÈôÑÂä†Âà∞Êó∂Á©∫Ë°®Á§∫Ôºå‰ªéËÄå‰∏∫Âä®ÊÄÅÂú∫ÊôØÂÆûÁé∞ÂÖ®Èù¢ÁöÑËßÜËßâÂá†‰Ωï‰º∞ËÆ°„ÄÇÂú®Ëøô‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂‰∏ãÔºåËøô‰∫õÁªÑ‰ª∂Â¢ûÂº∫‰∫ÜÊàë‰ª¨Ê®°ÂûãÂØπ‰∫éÂä®ÊÄÅÂú∫ÊôØÁöÑÁâπÂæÅÂèØÂå∫ÂàÜÊÄßÂíåÂ∫îÁî®ÈÄöÁî®ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÈõÜÊàê‰∫ÜÂ§ö‰∏™Âá†‰ΩïÊï∞ÊçÆÈõÜÊù•ËÆ≠ÁªÉÊàë‰ª¨ÁöÑÊ®°ÂûãÔºåÂπ∂ËøõË°å‰∫ÜÂπøÊ≥õÁöÑÂÆûÈ™åÔºå‰ª•È™åËØÅÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Â§ö‰∏™Âä®ÊÄÅÂú∫ÊôØÂá†‰ΩïÂü∫ÂáÜ‰∏äÁöÑÂêÑÁßç‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂä®ÊÄÅÂú∫ÊôØÂá†‰Ωï‰º∞ËÆ°Êó®Âú®‰ªéËßÜÈ¢ëÊàñÂõæÂÉèÂ∫èÂàó‰∏≠ÊÅ¢Â§çÂú∫ÊôØÁöÑ3DÁªìÊûÑÔºåÂπ∂Ë∑üË∏™ÂÖ∂ÈöèÊó∂Èó¥ÁöÑÂèòÂåñ„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Â∞ÜÁ©∫Èó¥ÂíåÊó∂Èó¥ÁâπÂæÅËûçÂêàÂà∞Áªü‰∏ÄÁöÑÊΩúÂú®Á©∫Èó¥‰∏≠Ôºå‰ΩÜÁî±‰∫éÁ©∫Èó¥ÂíåÊó∂Èó¥‰ø°ÊÅØÁöÑÂºÇÊûÑÊÄßÔºåËøôÁßçËûçÂêàÊñπÂºèÂÆπÊòìÂØºËá¥‰ø°ÊÅØÊçüÂ§±ÂíåË°®Á§∫‰∏çÂåπÈÖçÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**Ôºö4D-VGGTÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂ∞ÜÁ©∫Èó¥ÂíåÊó∂Èó¥ÁâπÂæÅËß£ËÄ¶ÔºåÂàÜÂà´ËøõË°åÂ§ÑÁêÜÔºåÁÑ∂ÂêéÈÄöËøáÂ§ö‰ªªÂä°Â≠¶‰π†Ê°ÜÊû∂ËøõË°åÊï¥Âêà„ÄÇÈÄöËøáËøôÁßçÂàÜËÄåÊ≤ª‰πãÁöÑÁ≠ñÁï•ÔºåÊ®°ÂûãÂèØ‰ª•Êõ¥Â•ΩÂú∞ÊçïÊçâÂä®ÊÄÅÂú∫ÊôØ‰∏≠ÁöÑÊó∂Á©∫‰ø°ÊÅØÔºåÈÅøÂÖç‰∫ÜÁõ¥Êé•ËûçÂêàÂ∏¶Êù•ÁöÑ‰ø°ÊÅØÊçüÂ§±„ÄÇËá™ÈÄÇÂ∫îËßÜËßâÁΩëÊ†ºÁöÑËÆæËÆ°‰ΩøÂæóÊ®°ÂûãÂèØ‰ª•Â§ÑÁêÜ‰∏çÂêåÊï∞ÈáèÁöÑËßÜÂõæÂíåÊó∂Èó¥Ê≠•ÈïøÁöÑËæìÂÖ•ÔºåÂ¢ûÂº∫‰∫ÜÊ®°ÂûãÁöÑÁÅµÊ¥ªÊÄßÂíåÈÄöÁî®ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**Ôºö4D-VGGTÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÈÉ®ÂàÜÔºöÂ§öËÆæÁΩÆËæìÂÖ•„ÄÅÂ§öÂ±ÇÊ¨°Ë°®Á§∫ÂíåÂ§ö‰ªªÂä°È¢ÑÊµã„ÄÇÈ¶ñÂÖàÔºå‰ΩøÁî®Ëá™ÈÄÇÂ∫îËßÜËßâÁΩëÊ†ºÂ§ÑÁêÜ‰∏çÂêåÊï∞ÈáèÁöÑËßÜÂõæÂíåÊó∂Èó¥Ê≠•ÈïøÁöÑËæìÂÖ•Â∫èÂàó„ÄÇÁÑ∂ÂêéÔºåÈÄöËøáË∑®ËßÜÂõæÂÖ®Â±ÄËûçÂêàÊèêÂèñÁ©∫Èó¥ÁâπÂæÅÔºåÈÄöËøáË∑®Êó∂Èó¥Â±ÄÈÉ®ËûçÂêàÊèêÂèñÊó∂Èó¥ÁâπÂæÅ„ÄÇÊúÄÂêéÔºåÂ∞ÜÊèêÂèñÁöÑÊó∂Á©∫ÁâπÂæÅËæìÂÖ•Âà∞Â§ö‰∏™ÁâπÂÆö‰∫é‰ªªÂä°ÁöÑÂ§¥ÈÉ®ÔºåËøõË°åÂ§ö‰ªªÂä°È¢ÑÊµãÔºå‰æãÂ¶ÇÊ∑±Â∫¶‰º∞ËÆ°„ÄÅÂÖâÊµÅ‰º∞ËÆ°Á≠â„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**Ôºö4D-VGGTÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÂàÜËÄåÊ≤ª‰πãÁöÑÊó∂Á©∫Ë°®Á§∫ÊñπÊ≥ï„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ¥Êé•ËûçÂêàÊó∂Á©∫ÁâπÂæÅ‰∏çÂêåÔºå4D-VGGTÂàÜÂà´Â§ÑÁêÜÁ©∫Èó¥ÂíåÊó∂Èó¥ÁâπÂæÅÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÊçïÊçâÂä®ÊÄÅÂú∫ÊôØ‰∏≠ÁöÑ‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåËá™ÈÄÇÂ∫îËßÜËßâÁΩëÊ†ºÁöÑËÆæËÆ°‰ΩøÂæóÊ®°ÂûãÂèØ‰ª•Â§ÑÁêÜ‰∏çÂêåÊï∞ÈáèÁöÑËßÜÂõæÂíåÊó∂Èó¥Ê≠•ÈïøÁöÑËæìÂÖ•ÔºåÂ¢ûÂº∫‰∫ÜÊ®°ÂûãÁöÑÁÅµÊ¥ªÊÄß„ÄÇÂ§ö‰ªªÂä°Â≠¶‰π†Ê°ÜÊû∂‰ΩøÂæóÊ®°ÂûãÂèØ‰ª•ÂêåÊó∂ÂÆåÊàêÂ§ö‰∏™‰ªªÂä°ÔºåÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÊïàÁéáÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËá™ÈÄÇÂ∫îËßÜËßâÁΩëÊ†ºÊ†πÊçÆËæìÂÖ•Â∫èÂàóÁöÑËßÜÂõæÂíåÊó∂Èó¥Ê≠•ÈïøÊï∞ÈáèÂä®ÊÄÅË∞ÉÊï¥ÁΩëÊ†ºÂ§ßÂ∞è„ÄÇË∑®ËßÜÂõæÂÖ®Â±ÄËûçÂêà‰ΩøÁî®TransformerÁªìÊûÑÔºåÊçïÊçâ‰∏çÂêåËßÜÂõæ‰πãÈó¥ÁöÑÂÖ®Â±ÄÂÖ≥Á≥ª„ÄÇË∑®Êó∂Èó¥Â±ÄÈÉ®ËûçÂêà‰ΩøÁî®Âç∑ÁßØÁ•ûÁªèÁΩëÁªúÔºåÊçïÊçâÁõ∏ÈÇªÊó∂Èó¥Ê≠•‰πãÈó¥ÁöÑÂ±ÄÈÉ®ÂÖ≥Á≥ª„ÄÇÂ§ö‰ªªÂä°Â≠¶‰π†Ê°ÜÊû∂‰ΩøÁî®Â§ö‰∏™ÁâπÂÆö‰∫é‰ªªÂä°ÁöÑÂ§¥ÈÉ®ÔºåÊØè‰∏™Â§¥ÈÉ®Ë¥üË¥£‰∏Ä‰∏™ÁâπÂÆöÁöÑ‰ªªÂä°„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨Ê∑±Â∫¶‰º∞ËÆ°ÊçüÂ§±„ÄÅÂÖâÊµÅ‰º∞ËÆ°ÊçüÂ§±Á≠âÔºåÁî®‰∫éÁõëÁù£Ê®°ÂûãÁöÑËÆ≠ÁªÉ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå4D-VGGTÂú®Â§ö‰∏™Âä®ÊÄÅÂú∫ÊôØÂá†‰ΩïÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºåÂú®KITTIÊï∞ÊçÆÈõÜ‰∏äÔºå4D-VGGTÂú®Ê∑±Â∫¶‰º∞ËÆ°‰ªªÂä°‰∏äÁöÑËØØÂ∑ÆÈôç‰Ωé‰∫Ü15%ÔºåÂú®ÂÖâÊµÅ‰º∞ËÆ°‰ªªÂä°‰∏äÁöÑËØØÂ∑ÆÈôç‰Ωé‰∫Ü10%„ÄÇÊ≠§Â§ñÔºå4D-VGGTÂú®Â§ÑÁêÜ‰∏çÂêåÊï∞ÈáèÁöÑËßÜÂõæÂíåÊó∂Èó¥Ê≠•ÈïøÁöÑËæìÂÖ•Êó∂Ôºå‰πüË°®Áé∞Âá∫‰∫ÜËâØÂ•ΩÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

4D-VGGTÂú®Ëá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÊûÑÂª∫Êõ¥Á≤æÁ°ÆÁöÑÂä®ÊÄÅÂú∫ÊôØÊ®°ÂûãÔºåÊèêÈ´òËá™Âä®È©æÈ©∂Á≥ªÁªüÁöÑÊÑüÁü•ËÉΩÂäõÔºåÂ∏ÆÂä©Êú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÊìç‰ΩúÂë®Âõ¥ÁéØÂ¢ÉÔºåÂπ∂‰∏∫Áî®Êà∑Êèê‰æõÊõ¥Ê≤âÊµ∏ÂºèÁöÑËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆû‰ΩìÈ™å„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We investigate a challenging task of dynamic scene geometry estimation, which requires representing both spatial and temporal features. Typically, existing methods align the two features into a unified latent space to model scene geometry. However, this unified paradigm suffers from potential mismatched representation due to the heterogeneous nature between spatial and temporal features. In this work, we propose 4D-VGGT, a general foundation model with divide-and-conquer spatiotemporal representation for dynamic scene geometry. Our model is divided into three aspects: 1) Multi-setting input. We design an adaptive visual grid that supports input sequences with arbitrary numbers of views and time steps. 2) Multi-level representation. We propose a cross-view global fusion for spatial representation and a cross-time local fusion for temporal representation. 3) Multi-task prediction. We append multiple task-specific heads to spatiotemporal representations, enabling a comprehensive visual geometry estimation for dynamic scenes. Under this unified framework, these components enhance the feature discriminability and application universality of our model for dynamic scenes. In addition, we integrate multiple geometry datasets to train our model and conduct extensive experiments to verify the effectiveness of our method across various tasks on multiple dynamic scene geometry benchmarks.

