---
layout: default
title: GPR-OdomNet: Difference and Similarity-Driven Odometry Estimation Network for Ground Penetrating Radar-Based Localization
---

# GPR-OdomNet: Difference and Similarity-Driven Odometry Estimation Network for Ground Penetrating Radar-Based Localization

**arXiv**: [2511.17457v1](https://arxiv.org/abs/2511.17457) | [PDF](https://arxiv.org/pdf/2511.17457.pdf)

**ä½œè€…**: Huaichao Wang, Xuanxin Fan, Ji Liu, Haifeng Li, Dezhen Song

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGPR-OdomNetï¼Œåˆ©ç”¨B-scanå›¾åƒç›¸ä¼¼ä¸Žå·®å¼‚ç‰¹å¾ï¼Œæå‡æŽ¢åœ°é›·è¾¾å®šä½ç²¾åº¦ã€‚**

**å…³é”®è¯**: `æŽ¢åœ°é›·è¾¾å®šä½` `é‡Œç¨‹è®¡ä¼°è®¡` `B-scanå›¾åƒå¤„ç†` `ç¥žç»ç½‘ç»œ` `å¤šå°ºåº¦ç‰¹å¾æå–` `ç›¸ä¼¼æ€§åˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæŽ¢åœ°é›·è¾¾B-scanå›¾åƒå·®å¼‚å°ï¼ŒçŽ°æœ‰æ–¹æ³•è·ç¦»ä¼°è®¡ä¸å‡†ç¡®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç¥žç»ç½‘ç»œæå–å¤šå°ºåº¦ç‰¹å¾ï¼Œåˆ†æžç›¸ä¼¼ä¸Žå·®å¼‚ä»¥ä¼°è®¡æ¬§æ°è·ç¦»ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨CMU-GPRæ•°æ®é›†ä¸Šï¼ŒRMSEé™ä½Ž10.2%ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> When performing robot/vehicle localization using ground penetrating radar (GPR) to handle adverse weather and environmental conditions, existing techniques often struggle to accurately estimate distances when processing B-scan images with minor distinctions. This study introduces a new neural network-based odometry method that leverages the similarity and difference features of GPR B-scan images for precise estimation of the Euclidean distances traveled between the B-scan images. The new custom neural network extracts multi-scale features from B-scan images taken at consecutive moments and then determines the Euclidean distance traveled by analyzing the similarities and differences between these features. To evaluate our method, an ablation study and comparison experiments have been conducted using the publicly available CMU-GPR dataset. The experimental results show that our method consistently outperforms state-of-the-art counterparts in all tests. Specifically, our method achieves a root mean square error (RMSE), and achieves an overall weighted RMSE of 0.449 m across all data sets, which is a 10.2\% reduction in RMSE when compared to the best state-of-the-art method.

