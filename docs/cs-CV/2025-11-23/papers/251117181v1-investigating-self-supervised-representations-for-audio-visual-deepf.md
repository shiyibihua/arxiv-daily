---
layout: default
title: Investigating self-supervised representations for audio-visual deepfake detection
---

# Investigating self-supervised representations for audio-visual deepfake detection

**arXiv**: [2511.17181v1](https://arxiv.org/abs/2511.17181) | [PDF](https://arxiv.org/pdf/2511.17181.pdf)

**ä½œè€…**: Dragos-Alexandru Boldisor, Stefan Smeu, Dan Oneata, Elisabeta Oneata

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç³»ç»Ÿè¯„ä¼°è‡ªç›‘ç£è¡¨å¾åœ¨éŸ³è§†é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ã€å¯è§£é‡Šæ€§å’Œäº’è¡¥æ€§**

**å…³é”®è¯**: `è‡ªç›‘ç£è¡¨å¾` `éŸ³è§†é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹` `å¤šæ¨¡æ€è¯„ä¼°` `å¯è§£é‡Šæ€§åˆ†æž` `è·¨æ•°æ®é›†æ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‡ªç›‘ç£è¡¨å¾åœ¨éŸ³è§†é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹ä¸­çš„åº”ç”¨æ½œåŠ›æœªè¢«å……åˆ†æŽ¢ç´¢ï¼Œä¸”è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç³»ç»Ÿè¯„ä¼°è‡ªç›‘ç£ç‰¹å¾åœ¨éŸ³é¢‘ã€è§†é¢‘å’Œå¤šæ¨¡æ€ä¸­çš„è¡¨çŽ°ï¼Œå…³æ³¨è¯­ä¹‰åŒºåŸŸè€Œéžè™šå‡ä¼ªå½±ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå‘çŽ°ç‰¹å¾æ•èŽ·äº’è¡¥çš„ä¼ªé€ ç›¸å…³ä¿¡æ¯ï¼Œä½†æ³›åŒ–å¤±è´¥å¯èƒ½æºäºŽæ•°æ®é›†ç‰¹æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Self-supervised representations excel at many vision and speech tasks, but their potential for audio-visual deepfake detection remains underexplored. Unlike prior work that uses these features in isolation or buried within complex architectures, we systematically evaluate them across modalities (audio, video, multimodal) and domains (lip movements, generic visual content). We assess three key dimensions: detection effectiveness, interpretability of encoded information, and cross-modal complementarity. We find that most self-supervised features capture deepfake-relevant information, and that this information is complementary. Moreover, models primarily attend to semantically meaningful regions rather than spurious artifacts. Yet none generalize reliably across datasets. This generalization failure likely stems from dataset characteristics, not from the features themselves latching onto superficial patterns. These results expose both the promise and fundamental challenges of self-supervised representations for deepfake detection: while they learn meaningful patterns, achieving robust cross-domain performance remains elusive.

