---
layout: default
title: Preventing Shortcut Learning in Medical Image Analysis through Intermediate Layer Knowledge Distillation from Specialist Teachers
---

# Preventing Shortcut Learning in Medical Image Analysis through Intermediate Layer Knowledge Distillation from Specialist Teachers

**arXiv**: [2511.17421v1](https://arxiv.org/abs/2511.17421) | [PDF](https://arxiv.org/pdf/2511.17421.pdf)

**ä½œè€…**: Christopher Boland, Sotirios Tsaftaris, Sonia Dahdouh

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸­é—´å±‚çŸ¥è¯†è’¸é¦æ¡†æž¶ä»¥è§£å†³åŒ»å­¦å›¾åƒåˆ†æžä¸­çš„æ·å¾„å­¦ä¹ é—®é¢˜**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒåˆ†æž` `æ·å¾„å­¦ä¹ ` `çŸ¥è¯†è’¸é¦` `ä¸­é—´å±‚å­¦ä¹ ` `ç¨³å¥æ€§æå‡` `æ·±åº¦å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ·±åº¦å­¦ä¹ æ¨¡åž‹æ˜“å­¦ä¹ è®­ç»ƒæ•°æ®ä¸­è™šå‡ç›¸å…³ç‰¹å¾ï¼Œå¯¼è‡´åŒ»å­¦å›¾åƒé¢„æµ‹ç¼ºä¹ç¨³å¥æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨ä»»åŠ¡ç›¸å…³æ•°æ®å¾®è°ƒçš„æ•™å¸ˆç½‘ç»œï¼ŒæŒ‡å¯¼å­¦ç”Ÿç½‘ç»œä¸­é—´å±‚ï¼Œç¼“è§£æ·å¾„å­¦ä¹ ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šä¼˜äºŽä¼ ç»Ÿæ–¹æ³•ï¼ŒæŽ¥è¿‘æ— åæ•°æ®åŸºçº¿ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deep learning models are prone to learning shortcut solutions to problems using spuriously correlated yet irrelevant features of their training data. In high-risk applications such as medical image analysis, this phenomenon may prevent models from using clinically meaningful features when making predictions, potentially leading to poor robustness and harm to patients. We demonstrate that different types of shortcuts (those that are diffuse and spread throughout the image, as well as those that are localized to specific areas) manifest distinctly across network layers and can, therefore, be more effectively targeted through mitigation strategies that target the intermediate layers. We propose a novel knowledge distillation framework that leverages a teacher network fine-tuned on a small subset of task-relevant data to mitigate shortcut learning in a student network trained on a large dataset corrupted with a bias feature. Through extensive experiments on CheXpert, ISIC 2017, and SimBA datasets using various architectures (ResNet-18, AlexNet, DenseNet-121, and 3D CNNs), we demonstrate consistent improvements over traditional Empirical Risk Minimization, augmentation-based bias-mitigation, and group-based bias-mitigation approaches. In many cases, we achieve comparable performance with a baseline model trained on bias-free data, even on out-of-distribution test data. Our results demonstrate the practical applicability of our approach to real-world medical imaging scenarios where bias annotations are limited and shortcut features are difficult to identify a priori.

