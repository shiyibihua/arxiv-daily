---
layout: default
title: R-AVST: Empowering Video-LLMs with Fine-Grained Spatio-Temporal Reasoning in Complex Audio-Visual Scenarios
---

# R-AVST: Empowering Video-LLMs with Fine-Grained Spatio-Temporal Reasoning in Complex Audio-Visual Scenarios

**arXiv**: [2511.16901v1](https://arxiv.org/abs/2511.16901) | [PDF](https://arxiv.org/pdf/2511.16901.pdf)

**ä½œè€…**: Lu Zhu, Tiantian Geng, Yangye Chen, Teng Wang, Ping Lu, Feng Zheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºR-AVSTæ•°æ®é›†ä¸ŽAVST-Zeroæ¨¡åž‹ä»¥å¢žå¼ºå¤æ‚è§†å¬åœºæ™¯ä¸­çš„ç»†ç²’åº¦æ—¶ç©ºæŽ¨ç†**

**å…³é”®è¯**: `è§†å¬æ—¶ç©ºæŽ¨ç†` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `å¼ºåŒ–å­¦ä¹ ` `æ•°æ®é›†æž„å»º` `è§†é¢‘ç†è§£` `ç»†ç²’åº¦æ ‡æ³¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰å¤šæ¨¡æ€å¤§æ¨¡åž‹åœ¨å¤æ‚çœŸå®žä¸–ç•Œè§†å¬äº‹ä»¶ä¸­è¡¨çŽ°ä¸è¶³ï¼Œç¼ºä¹ç»†ç²’åº¦æ—¶ç©ºæŽ¨ç†èƒ½åŠ›ã€‚
2. æž„å»ºR-AVSTæ•°æ®é›†ï¼Œå«5Kè§†é¢‘ä¸Ž27Kå¯¹è±¡ï¼Œå¹¶å®šä¹‰ä¸‰ä¸ªæ ¸å¿ƒä»»åŠ¡ç”Ÿæˆ8Ké—®ç­”å¯¹ã€‚
3. æå‡ºAVST-Zeroæ¨¡åž‹ï¼ŒåŸºäºŽå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–è¡Œä¸ºï¼Œå®žéªŒæ˜¾ç¤ºåœ¨R-AVSTä¸Šæ€§èƒ½ä¼˜è¶Šã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recently, rapid advancements have been made in multimodal large language models (MLLMs), especially in video understanding tasks. However, current research focuses on simple video scenarios, failing to reflect the complex and diverse nature of real-world audio-visual events in videos. To bridge this gap, we firstly introduce R-AVST, a dataset for audio-visual reasoning featuring fine-grained spatio-temporal annotations. In constructing this, we design a pipeline consisting of LLM-based key object extraction, automatic spatial annotation and manual quality inspection, resulting in over 5K untrimmed videos with 27K objects across 100 types of audio-visual events. Building on this dataset, we define three core tasks for spatio-temporal reasoning in audio-visual scenes and generate more than 8K high-quality, evenly distributed question-answer pairs to effectively benchmark model performance. To further enhance reasoning, we propose AVST-Zero, a reinforcement learning-based model that avoids intermediate supervision, directly optimizing behavior via carefully designed multi-dimensional rewards. Extensive experiments validate the effectiveness of our R-AVST in advancing audio-visual spatio-temporal reasoning, upon which AVST-Zero demonstrates competitive performance compared to existing models. To the best of our knowledge, R-AVST is the first dataset designed for real-world audio-visual spatio-temporal reasoning, and AVST-Zero offers a novel perspective for tackling future challenges in this domain.

