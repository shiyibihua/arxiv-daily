---
layout: default
title: IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic Industrial Navigation
---

# IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic Industrial Navigation

**arXiv**: [2511.17384v1](https://arxiv.org/abs/2511.17384) | [PDF](https://arxiv.org/pdf/2511.17384.pdf)

**ä½œè€…**: Yifan Li, Lichi Li, Anh Dao, Xinyu Zhou, Yicheng Qiao, Zheda Mai, Daeun Lee, Zichen Chen, Zhen Tan, Mohit Bansal, Yu Kong

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIndustryNavåŸºå‡†ä»¥è¯„ä¼°å…·èº«ä»£ç†åœ¨åŠ¨æ€å·¥ä¸šå¯¼èˆªä¸­çš„ç©ºé—´æŽ¨ç†èƒ½åŠ›**

**å…³é”®è¯**: `å…·èº«æ™ºèƒ½` `ç©ºé—´æŽ¨ç†` `åŠ¨æ€å¯¼èˆª` `å·¥ä¸šçŽ¯å¢ƒ` `åŸºå‡†è¯„ä¼°` `ç¢°æ’žé¿å…`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å…·èº«åŸºå‡†åœ¨åŠ¨æ€çœŸå®žçŽ¯å¢ƒä¸­ç©ºé—´æŽ¨ç†è¯„ä¼°ä¸è¶³ï¼Œèšç„¦é™æ€å®¶åº­åœºæ™¯
2. åŸºäºŽ12ä¸ªé«˜ä¿çœŸUnityä»“åº“åœºæ™¯ï¼Œç»“åˆè‡ªæˆ‘ä¸­å¿ƒè§†è§‰ä¸Žå…¨å±€é‡Œç¨‹è®¡è¯„ä¼°è§„åˆ’
3. å¼•å…¥ç¢°æ’žçŽ‡å’Œè­¦å‘ŠçŽ‡æŒ‡æ ‡ï¼Œå‘çŽ°ä¸»æµVLLMsåœ¨è·¯å¾„è§„åˆ’å’Œé¿éšœæ–¹é¢å­˜åœ¨ç¼ºé™·

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While Visual Large Language Models (VLLMs) show great promise as embodied agents, they continue to face substantial challenges in spatial reasoning. Existing embodied benchmarks largely focus on passive, static household environments and evaluate only isolated capabilities, failing to capture holistic performance in dynamic, real-world complexity. To fill this gap, we present IndustryNav, the first dynamic industrial navigation benchmark for active spatial reasoning. IndustryNav leverages 12 manually created, high-fidelity Unity warehouse scenarios featuring dynamic objects and human movement. Our evaluation employs a PointGoal navigation pipeline that effectively combines egocentric vision with global odometry to assess holistic local-global planning. Crucially, we introduce the "collision rate" and "warning rate" metrics to measure safety-oriented behaviors and distance estimation. A comprehensive study of nine state-of-the-art VLLMs (including models such as GPT-5-mini, Claude-4.5, and Gemini-2.5) reveals that closed-source models maintain a consistent advantage; however, all agents exhibit notable deficiencies in robust path planning, collision avoidance and active exploration. This highlights a critical need for embodied research to move beyond passive perception and toward tasks that demand stable planning, active exploration, and safe behavior in dynamic, real-world environment.

