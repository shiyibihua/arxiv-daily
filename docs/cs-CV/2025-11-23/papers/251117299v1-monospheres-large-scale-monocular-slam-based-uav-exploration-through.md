---
layout: default
title: MonoSpheres: Large-Scale Monocular SLAM-Based UAV Exploration through Perception-Coupled Mapping and Planning
---

# MonoSpheres: Large-Scale Monocular SLAM-Based UAV Exploration through Perception-Coupled Mapping and Planning

**arXiv**: [2511.17299v1](https://arxiv.org/abs/2511.17299) | [PDF](https://arxiv.org/pdf/2511.17299.pdf)

**ä½œè€…**: TomÃ¡Å¡ Musil, MatÄ›j PetrlÃ­k, Martin Saska

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMonoSpheresæ–¹æ³•ï¼Œé€šè¿‡æ„ŸçŸ¥è€¦åˆçš„å»ºå›¾ä¸Žè§„åˆ’å®žçŽ°å•ç›®SLAMæ— äººæœºå¤§è§„æ¨¡æŽ¢ç´¢**

**å…³é”®è¯**: `å•ç›®SLAM` `æ— äººæœºæŽ¢ç´¢` `æ„ŸçŸ¥è€¦åˆè§„åˆ’` `ç¨€ç–æ·±åº¦å»ºå›¾` `å‰æ²¿æŽ¢ç´¢` `ä¸ç¡®å®šæ€§å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå•ç›®ç›¸æœºåœ¨æœªçŸ¥çŽ¯å¢ƒä¸­è‡ªä¸»æŽ¢ç´¢æ—¶ï¼Œæ·±åº¦æ•°æ®ç¨€ç–ã€è‡ªç”±ç©ºé—´é—´éš™å’Œæ·±åº¦ä¸ç¡®å®šæ€§å¤§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå»ºå›¾æ¨¡å—è¿‡é‡‡æ ·çº¹ç†ç¨€ç–åŒºåŸŸï¼Œè§„åˆ’æ¨¡å—å¿«é€Ÿé‡è§„åˆ’å¹¶æ„ŸçŸ¥æ„ŸçŸ¥èˆªå‘æŽ§åˆ¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žå’Œæ¨¡æ‹ŸçŽ¯å¢ƒä¸­å¹¿æ³›è¯„ä¼°ï¼Œé¦–æ¬¡å®žçŽ°çœŸå®žä¸–ç•Œéžç»“æž„åŒ–æˆ·å¤–3Då•ç›®æŽ¢ç´¢ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Autonomous exploration of unknown environments is a key capability for mobile robots, but it is largely unsolved for robots equipped with only a single monocular camera and no dense range sensors. In this paper, we present a novel approach to monocular vision-based exploration that can safely cover large-scale unstructured indoor and outdoor 3D environments by explicitly accounting for the properties of a sparse monocular SLAM frontend in both mapping and planning. The mapping module solves the problems of sparse depth data, free-space gaps, and large depth uncertainty by oversampling free space in texture-sparse areas and keeping track of obstacle position uncertainty. The planning module handles the added free-space uncertainty through rapid replanning and perception-aware heading control. We further show that frontier-based exploration is possible with sparse monocular depth data when parallax requirements and the possibility of textureless surfaces are taken into account. We evaluate our approach extensively in diverse real-world and simulated environments, including ablation studies. To the best of the authors' knowledge, the proposed method is the first to achieve 3D monocular exploration in real-world unstructured outdoor environments. We open-source our implementation to support future research.

