---
layout: default
title: Intervene-All-Paths: Unified Mitigation of LVLM Hallucinations across Alignment Formats
---

# Intervene-All-Paths: Unified Mitigation of LVLM Hallucinations across Alignment Formats

**arXiv**: [2511.17254v1](https://arxiv.org/abs/2511.17254) | [PDF](https://arxiv.org/pdf/2511.17254.pdf)

**ä½œè€…**: Jiaye Qian, Ge Zheng, Yuchen Zhu, Sibei Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€å¹²é¢„æ¡†æž¶ä»¥ç¼“è§£å¤šæ¨¡æ€å¤§æ¨¡åž‹åœ¨ä¸åŒå¯¹é½æ ¼å¼ä¸‹çš„å¹»è§‰é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§æ¨¡åž‹` `å¹»è§‰ç¼“è§£` `å› æžœè·¯å¾„å¹²é¢„` `å¯¹é½æ ¼å¼é€‚åº”` `Transformeræž¶æž„`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€å¤§æ¨¡åž‹åœ¨å›¾åƒ-æ–‡æœ¬ä»»åŠ¡ä¸­æ˜“äº§ç”Ÿå¹»è§‰ï¼ŒæºäºŽå¤šä¸ªå› æžœè·¯å¾„çš„äº¤äº’ä½œç”¨
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽTransformerå› æžœæž¶æž„ï¼Œè¯†åˆ«å¹¶å¹²é¢„å…³é”®å¹»è§‰å¤´ï¼Œé€‚åº”åˆ¤åˆ«å¼å’Œç”Ÿæˆå¼å¯¹é½æ ¼å¼
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•ä¸€è‡´å‡å°‘ä¸åŒå¯¹é½ç±»åž‹çš„å¹»è§‰

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite their impressive performance across a wide range of tasks, Large Vision-Language Models (LVLMs) remain prone to hallucination. In this study, we propose a comprehensive intervention framework aligned with the transformer's causal architecture in LVLMs, integrating the effects of different intervention paths on hallucination. We find that hallucinations in LVLMs do not arise from a single causal path, but rather from the interplay among image-to-input-text, image-to-output-text, and text-to-text pathways. For the first time, we also find that LVLMs rely on different pathways depending on the question-answer alignment format. Building on these insights, we propose simple yet effective methods to identify and intervene on critical hallucination heads within each pathway, tailored to discriminative and generative formats. Experiments across multiple benchmarks demonstrate that our approach consistently reduces hallucinations across diverse alignment types.

