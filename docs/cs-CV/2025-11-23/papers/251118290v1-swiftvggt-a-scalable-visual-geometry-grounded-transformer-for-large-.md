---
layout: default
title: SwiftVGGT: A Scalable Visual Geometry Grounded Transformer for Large-Scale Scenes
---

# SwiftVGGT: A Scalable Visual Geometry Grounded Transformer for Large-Scale Scenes

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.18290" target="_blank" class="toolbar-btn">arXiv: 2511.18290v1</a>
    <a href="https://arxiv.org/pdf/2511.18290.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.18290v1" 
            onclick="toggleFavorite(this, '2511.18290v1', 'SwiftVGGT: A Scalable Visual Geometry Grounded Transformer for Large-Scale Scenes')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jungho Lee, Minhyeok Lee, Sunghun Yang, Minseok Kang, Sangyoun Lee

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-23

**Â§áÊ≥®**: Project Page: https://Jho-Yonsei.github.io/SwiftVGGT/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**SwiftVGGTÔºö‰∏ÄÁßçÂèØÊâ©Â±ïÁöÑËßÜËßâÂá†‰ΩïÁ∫¶ÊùüTransformerÔºåÁî®‰∫éÂ§ßËßÑÊ®°Âú∫ÊôØ‰∏âÁª¥ÈáçÂª∫„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `‰∏âÁª¥ÈáçÂª∫` `Â§ßËßÑÊ®°Âú∫ÊôØ` `ËßÜËßâÂá†‰Ωï` `Transformer` `ÂõûÁéØÊ£ÄÊµã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂ§ßËßÑÊ®°‰∏âÁª¥ÈáçÂª∫ÊñπÊ≥ïÂú®Á≤æÂ∫¶ÂíåÊïàÁéá‰πãÈó¥Â≠òÂú®ÊùÉË°°ÔºåÈöæ‰ª•ÂÖºÈ°æÈ´òË¥®ÈáèÂíåÂø´ÈÄüÊé®ÁêÜ„ÄÇ
2. SwiftVGGTÈÄöËøáÊó†ÈúÄËÆ≠ÁªÉÁöÑÂõûÁéØÊ£ÄÊµãÂíåÈ´òÊïàÁöÑÁÇπÈááÊ†∑ÂØπÈΩêÔºåÂú®‰øùËØÅÂÖ®Â±Ä‰∏ÄËá¥ÊÄßÁöÑÂêåÊó∂ÊòæËëóÊèêÂçáÊé®ÁêÜÈÄüÂ∫¶„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåSwiftVGGTÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÈáçÂª∫Ë¥®ÈáèÔºå‰∏îÊé®ÁêÜÊó∂Èó¥‰ªÖ‰∏∫Áé∞ÊúâVGGTÊñπÊ≥ïÁöÑ33%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßËßÑÊ®°Âú∫ÊôØÁöÑ‰∏âÁª¥ÈáçÂª∫ÊòØ‰∏âÁª¥ÊÑüÁü•‰∏≠ÁöÑ‰∏ÄÈ°πÂü∫Êú¨‰ªªÂä°Ôºå‰ΩÜÁ≤æÂ∫¶ÂíåËÆ°ÁÆóÊïàÁéá‰πãÈó¥ÁöÑÂõ∫ÊúâÊùÉË°°‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÈáçÂ§ßÊåëÊàò„ÄÇÁé∞ÊúâÊñπÊ≥ïË¶Å‰πà‰ºòÂÖàËÄÉËôëÈÄüÂ∫¶ËÄå‰∫ßÁîü‰ΩéË¥®ÈáèÁöÑÁªìÊûúÔºåË¶Å‰πà‰ª•ÁºìÊÖ¢ÁöÑÊé®ÁêÜÊó∂Èó¥‰∏∫‰ª£‰ª∑Êù•ÂÆûÁé∞È´òË¥®ÈáèÁöÑÈáçÂª∫„ÄÇÊú¨ÊñáÊèêÂá∫SwiftVGGTÔºå‰∏ÄÁßçÊó†ÈúÄËÆ≠ÁªÉÁöÑÊñπÊ≥ïÔºåÂèØÊòæËëóÂáèÂ∞ëÊé®ÁêÜÊó∂Èó¥ÔºåÂêåÊó∂‰øùÊåÅÈ´òË¥®ÈáèÁöÑÂØÜÈõÜ‰∏âÁª¥ÈáçÂª∫„ÄÇ‰∏∫‰∫Ü‰øùÊåÅÂ§ßËßÑÊ®°Âú∫ÊôØ‰∏≠ÁöÑÂÖ®Â±Ä‰∏ÄËá¥ÊÄßÔºåSwiftVGGTÊâßË°åÂõûÁéØÊ£ÄÊµãÔºåËÄåÊó†ÈúÄ‰æùËµñÂ§ñÈÉ®ËßÜËßâÂÆö‰ΩçËØÜÂà´ÔºàVPRÔºâÊ®°ÂûãÔºå‰ªéËÄåÊ∂àÈô§‰∫ÜÂÜó‰ΩôËÆ°ÁÆóÔºåÂπ∂ÂÆûÁé∞‰∫ÜÂÖ¨ÈáåÁ∫ßÁéØÂ¢É‰∏ãÁöÑÁ≤æÁ°ÆÈáçÂª∫„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆÄÂçïËÄåÊúâÊïàÁöÑÁÇπÈááÊ†∑ÊñπÊ≥ïÔºå‰ΩøÁî®Âü∫‰∫éÂçï‰∏™Sim(3)ÁöÑÂ•áÂºÇÂÄºÂàÜËß£ÔºàSVDÔºâÊ≠•È™§Êù•ÂØπÈΩêÁõ∏ÈÇªÂùóÔºå‰ªéËÄåÊ∂àÈô§‰∫ÜÂÖàÂâçÂ∑•‰Ωú‰∏≠Â∏∏Áî®ÁöÑËø≠‰ª£ÈáçÂä†ÊùÉÊúÄÂ∞è‰∫å‰πòÔºàIRLSÔºâ‰ºòÂåñÔºå‰ªéËÄåÊòæËëóÊèêÈ´ò‰∫ÜÈÄüÂ∫¶„ÄÇÊàë‰ª¨Âú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äËØÑ‰º∞‰∫ÜSwiftVGGTÔºåÁªìÊûúË°®ÊòéÔºåÂÆÉÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÈáçÂª∫Ë¥®ÈáèÔºåÂêåÊó∂‰ªÖÈúÄÊúÄËøëÂü∫‰∫éVGGTÁöÑÂ§ßËßÑÊ®°ÈáçÂª∫ÊñπÊ≥ï33%ÁöÑÊé®ÁêÜÊó∂Èó¥„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂ§ßËßÑÊ®°Âú∫ÊôØÁöÑ‰∏âÁª¥ÈáçÂª∫ÈúÄË¶ÅÂú®Á≤æÂ∫¶ÂíåÊïàÁéá‰πãÈó¥ËøõË°åÊùÉË°°„ÄÇÁé∞ÊúâÊñπÊ≥ïË¶Å‰πàÈÄüÂ∫¶Âø´‰ΩÜË¥®ÈáèÂ∑ÆÔºåË¶Å‰πàË¥®ÈáèÈ´ò‰ΩÜÈÄüÂ∫¶ÊÖ¢„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫Ü‰øùËØÅÂÖ®Â±Ä‰∏ÄËá¥ÊÄßÔºåÈÄöÂ∏∏ÈúÄË¶Å‰æùËµñÂ§ñÈÉ®ÁöÑËßÜËßâÂÆö‰ΩçËØÜÂà´ÔºàVPRÔºâÊ®°ÂûãËøõË°åÂõûÁéØÊ£ÄÊµãÔºåËøôÂ¢ûÂä†‰∫ÜËÆ°ÁÆóË¥üÊãÖ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSwiftVGGTÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂú®‰øùËØÅÈáçÂª∫Ë¥®ÈáèÁöÑÂâçÊèê‰∏ãÔºåÈÄöËøá‰ºòÂåñÂõûÁéØÊ£ÄÊµãÂíåÁÇπ‰∫ëÂØπÈΩê‰∏§‰∏™ÂÖ≥ÈîÆÊ≠•È™§Êù•ÊòæËëóÊèêÂçáÊé®ÁêÜÈÄüÂ∫¶„ÄÇÂÆÉÈÅøÂÖç‰∫ÜÂØπÂ§ñÈÉ®VPRÊ®°ÂûãÁöÑ‰æùËµñÔºåÂπ∂ÈááÁî®‰∫Ü‰∏ÄÁßçÈ´òÊïàÁöÑÁÇπÈááÊ†∑ÂØπÈΩêÊñπÊ≥ï„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSwiftVGGTÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) ÁâπÂæÅÊèêÂèñ‰∏éÂåπÈÖçÔºõ2) Âü∫‰∫éËßÜËßâÂá†‰ΩïÁöÑÂõûÁéØÊ£ÄÊµãÔºåÊó†ÈúÄÂ§ñÈÉ®VPRÊ®°ÂûãÔºõ3) Âü∫‰∫éSim(3)-SVDÁöÑÁÇπ‰∫ëÂùóÂØπÈΩêÔºõ4) ÂØÜÈõÜ‰∏âÁª¥ÈáçÂª∫„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSwiftVGGTÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) Êó†ÈúÄÂ§ñÈÉ®VPRÊ®°ÂûãÁöÑÂõûÁéØÊ£ÄÊµãÔºåÈôç‰Ωé‰∫ÜËÆ°ÁÆóÂ§çÊùÇÂ∫¶Ôºõ2) Âü∫‰∫éÂçï‰∏™Sim(3)-SVDÊ≠•È™§ÁöÑÁÇπ‰∫ëÂùóÂØπÈΩêÔºåÈÅøÂÖç‰∫ÜËÄóÊó∂ÁöÑËø≠‰ª£‰ºòÂåñÔºåÊòæËëóÊèêÂçá‰∫ÜÈÄüÂ∫¶„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöSwiftVGGTÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰∏ÄÁßçÁÆÄÂçïËÄåÊúâÊïàÁöÑÁÇπÈááÊ†∑ÊñπÊ≥ïÔºåÁî®‰∫éÈÄâÊã©Áî®‰∫éÂØπÈΩêÁöÑ‰ª£Ë°®ÊÄßÁÇπÔºõ2) ‰ΩøÁî®Âçï‰∏™Sim(3)-SVDÊ≠•È™§ËøõË°åÁÇπ‰∫ëÂùóÂØπÈΩêÔºåÈÅøÂÖç‰∫ÜËø≠‰ª£ÈáçÂä†ÊùÉÊúÄÂ∞è‰∫å‰πòÔºàIRLSÔºâ‰ºòÂåñÔºõ3) ÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÂèØËÉΩÂåÖÂê´Âá†‰Ωï‰∏ÄËá¥ÊÄßÁ∫¶ÊùüÔºå‰ª•‰øùËØÅÈáçÂª∫ÁöÑÂáÜÁ°ÆÊÄßÔºàÂÖ∑‰ΩìÁªÜËäÇÊú™Áü•Ôºâ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SwiftVGGTÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®‰øùÊåÅÊúÄÂÖàËøõÈáçÂª∫Ë¥®ÈáèÁöÑÂêåÊó∂ÔºåÊé®ÁêÜÊó∂Èó¥‰ªÖ‰∏∫Áé∞ÊúâÂü∫‰∫éVGGTÁöÑÂ§ßËßÑÊ®°ÈáçÂª∫ÊñπÊ≥ïÁöÑ33%„ÄÇËøôË°®ÊòéSwiftVGGTÂú®ÊïàÁéáÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊèêÂçáÔºå‰ΩøÂÖ∂Êõ¥ÈÄÇÁî®‰∫éÂÆûÈôÖÂ∫îÁî®„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SwiftVGGTÂú®Â§ßËßÑÊ®°Âú∫ÊôØÁöÑ‰∏âÁª¥ÈáçÂª∫ÊñπÈù¢ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇËá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÂüéÂ∏ÇÂª∫Ê®°„ÄÅËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇËØ•ÊñπÊ≥ïËÉΩÂ§üÂø´ÈÄü‰∏îÂáÜÁ°ÆÂú∞ÈáçÂª∫Â§ßËßÑÊ®°ÁéØÂ¢ÉÔºå‰∏∫Ëøô‰∫õÂ∫îÁî®Êèê‰æõÂèØÈù†ÁöÑ‰∏âÁª¥Âú∞Âõæ‰ø°ÊÅØÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊΩúÂú®ÁöÑÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> 3D reconstruction in large-scale scenes is a fundamental task in 3D perception, but the inherent trade-off between accuracy and computational efficiency remains a significant challenge. Existing methods either prioritize speed and produce low-quality results, or achieve high-quality reconstruction at the cost of slow inference times. In this paper, we propose SwiftVGGT, a training-free method that significantly reduce inference time while preserving high-quality dense 3D reconstruction. To maintain global consistency in large-scale scenes, SwiftVGGT performs loop closure without relying on the external Visual Place Recognition (VPR) model. This removes redundant computation and enables accurate reconstruction over kilometer-scale environments. Furthermore, we propose a simple yet effective point sampling method to align neighboring chunks using a single Sim(3)-based Singular Value Decomposition (SVD) step. This eliminates the need for the Iteratively Reweighted Least Squares (IRLS) optimization commonly used in prior work, leading to substantial speed-ups. We evaluate SwiftVGGT on multiple datasets and show that it achieves state-of-the-art reconstruction quality while requiring only 33% of the inference time of recent VGGT-based large-scale reconstruction approaches.

