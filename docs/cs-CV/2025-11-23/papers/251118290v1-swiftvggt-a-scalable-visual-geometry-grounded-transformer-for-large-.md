---
layout: default
title: SwiftVGGT: A Scalable Visual Geometry Grounded Transformer for Large-Scale Scenes
---

# SwiftVGGT: A Scalable Visual Geometry Grounded Transformer for Large-Scale Scenes

**arXiv**: [2511.18290v1](https://arxiv.org/abs/2511.18290) | [PDF](https://arxiv.org/pdf/2511.18290.pdf)

**ä½œè€…**: Jungho Lee, Minhyeok Lee, Sunghun Yang, Minseok Kang, Sangyoun Lee

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-23

**å¤‡æ³¨**: Project Page: https://Jho-Yonsei.github.io/SwiftVGGT/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SwiftVGGTï¼šä¸€ç§å¯æ‰©å±•çš„è§†è§‰å‡ ä½•çº¦æŸTransformerï¼Œç”¨äºŽå¤§è§„æ¨¡åœºæ™¯ä¸‰ç»´é‡å»ºã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `ä¸‰ç»´é‡å»º` `å¤§è§„æ¨¡åœºæ™¯` `è§†è§‰å‡ ä½•` `Transformer` `å›žçŽ¯æ£€æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¤§è§„æ¨¡ä¸‰ç»´é‡å»ºæ–¹æ³•åœ¨ç²¾åº¦å’Œæ•ˆçŽ‡ä¹‹é—´å­˜åœ¨æƒè¡¡ï¼Œéš¾ä»¥å…¼é¡¾é«˜è´¨é‡å’Œå¿«é€ŸæŽ¨ç†ã€‚
2. SwiftVGGTé€šè¿‡æ— éœ€è®­ç»ƒçš„å›žçŽ¯æ£€æµ‹å’Œé«˜æ•ˆçš„ç‚¹é‡‡æ ·å¯¹é½ï¼Œåœ¨ä¿è¯å…¨å±€ä¸€è‡´æ€§çš„åŒæ—¶æ˜¾è‘—æå‡æŽ¨ç†é€Ÿåº¦ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒSwiftVGGTåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®žçŽ°äº†æœ€å…ˆè¿›çš„é‡å»ºè´¨é‡ï¼Œä¸”æŽ¨ç†æ—¶é—´ä»…ä¸ºçŽ°æœ‰VGGTæ–¹æ³•çš„33%ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è§„æ¨¡åœºæ™¯çš„ä¸‰ç»´é‡å»ºæ˜¯ä¸‰ç»´æ„ŸçŸ¥ä¸­çš„ä¸€é¡¹åŸºæœ¬ä»»åŠ¡ï¼Œä½†ç²¾åº¦å’Œè®¡ç®—æ•ˆçŽ‡ä¹‹é—´çš„å›ºæœ‰æƒè¡¡ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚çŽ°æœ‰æ–¹æ³•è¦ä¹ˆä¼˜å…ˆè€ƒè™‘é€Ÿåº¦è€Œäº§ç”Ÿä½Žè´¨é‡çš„ç»“æžœï¼Œè¦ä¹ˆä»¥ç¼“æ…¢çš„æŽ¨ç†æ—¶é—´ä¸ºä»£ä»·æ¥å®žçŽ°é«˜è´¨é‡çš„é‡å»ºã€‚æœ¬æ–‡æå‡ºSwiftVGGTï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼Œå¯æ˜¾è‘—å‡å°‘æŽ¨ç†æ—¶é—´ï¼ŒåŒæ—¶ä¿æŒé«˜è´¨é‡çš„å¯†é›†ä¸‰ç»´é‡å»ºã€‚ä¸ºäº†ä¿æŒå¤§è§„æ¨¡åœºæ™¯ä¸­çš„å…¨å±€ä¸€è‡´æ€§ï¼ŒSwiftVGGTæ‰§è¡Œå›žçŽ¯æ£€æµ‹ï¼Œè€Œæ— éœ€ä¾èµ–å¤–éƒ¨è§†è§‰å®šä½è¯†åˆ«ï¼ˆVPRï¼‰æ¨¡åž‹ï¼Œä»Žè€Œæ¶ˆé™¤äº†å†—ä½™è®¡ç®—ï¼Œå¹¶å®žçŽ°äº†å…¬é‡Œçº§çŽ¯å¢ƒä¸‹çš„ç²¾ç¡®é‡å»ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„ç‚¹é‡‡æ ·æ–¹æ³•ï¼Œä½¿ç”¨åŸºäºŽå•ä¸ªSim(3)çš„å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰æ­¥éª¤æ¥å¯¹é½ç›¸é‚»å—ï¼Œä»Žè€Œæ¶ˆé™¤äº†å…ˆå‰å·¥ä½œä¸­å¸¸ç”¨çš„è¿­ä»£é‡åŠ æƒæœ€å°äºŒä¹˜ï¼ˆIRLSï¼‰ä¼˜åŒ–ï¼Œä»Žè€Œæ˜¾è‘—æé«˜äº†é€Ÿåº¦ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°äº†SwiftVGGTï¼Œç»“æžœè¡¨æ˜Žï¼Œå®ƒå®žçŽ°äº†æœ€å…ˆè¿›çš„é‡å»ºè´¨é‡ï¼ŒåŒæ—¶ä»…éœ€æœ€è¿‘åŸºäºŽVGGTçš„å¤§è§„æ¨¡é‡å»ºæ–¹æ³•33%çš„æŽ¨ç†æ—¶é—´ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤§è§„æ¨¡åœºæ™¯çš„ä¸‰ç»´é‡å»ºéœ€è¦åœ¨ç²¾åº¦å’Œæ•ˆçŽ‡ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚çŽ°æœ‰æ–¹æ³•è¦ä¹ˆé€Ÿåº¦å¿«ä½†è´¨é‡å·®ï¼Œè¦ä¹ˆè´¨é‡é«˜ä½†é€Ÿåº¦æ…¢ã€‚æ­¤å¤–ï¼Œä¸ºäº†ä¿è¯å…¨å±€ä¸€è‡´æ€§ï¼Œé€šå¸¸éœ€è¦ä¾èµ–å¤–éƒ¨çš„è§†è§‰å®šä½è¯†åˆ«ï¼ˆVPRï¼‰æ¨¡åž‹è¿›è¡Œå›žçŽ¯æ£€æµ‹ï¼Œè¿™å¢žåŠ äº†è®¡ç®—è´Ÿæ‹…ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSwiftVGGTçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨ä¿è¯é‡å»ºè´¨é‡çš„å‰æä¸‹ï¼Œé€šè¿‡ä¼˜åŒ–å›žçŽ¯æ£€æµ‹å’Œç‚¹äº‘å¯¹é½ä¸¤ä¸ªå…³é”®æ­¥éª¤æ¥æ˜¾è‘—æå‡æŽ¨ç†é€Ÿåº¦ã€‚å®ƒé¿å…äº†å¯¹å¤–éƒ¨VPRæ¨¡åž‹çš„ä¾èµ–ï¼Œå¹¶é‡‡ç”¨äº†ä¸€ç§é«˜æ•ˆçš„ç‚¹é‡‡æ ·å¯¹é½æ–¹æ³•ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šSwiftVGGTçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) ç‰¹å¾æå–ä¸ŽåŒ¹é…ï¼›2) åŸºäºŽè§†è§‰å‡ ä½•çš„å›žçŽ¯æ£€æµ‹ï¼Œæ— éœ€å¤–éƒ¨VPRæ¨¡åž‹ï¼›3) åŸºäºŽSim(3)-SVDçš„ç‚¹äº‘å—å¯¹é½ï¼›4) å¯†é›†ä¸‰ç»´é‡å»ºã€‚

**å…³é”®åˆ›æ–°**ï¼šSwiftVGGTçš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) æ— éœ€å¤–éƒ¨VPRæ¨¡åž‹çš„å›žçŽ¯æ£€æµ‹ï¼Œé™ä½Žäº†è®¡ç®—å¤æ‚åº¦ï¼›2) åŸºäºŽå•ä¸ªSim(3)-SVDæ­¥éª¤çš„ç‚¹äº‘å—å¯¹é½ï¼Œé¿å…äº†è€—æ—¶çš„è¿­ä»£ä¼˜åŒ–ï¼Œæ˜¾è‘—æå‡äº†é€Ÿåº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šSwiftVGGTçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„ç‚¹é‡‡æ ·æ–¹æ³•ï¼Œç”¨äºŽé€‰æ‹©ç”¨äºŽå¯¹é½çš„ä»£è¡¨æ€§ç‚¹ï¼›2) ä½¿ç”¨å•ä¸ªSim(3)-SVDæ­¥éª¤è¿›è¡Œç‚¹äº‘å—å¯¹é½ï¼Œé¿å…äº†è¿­ä»£é‡åŠ æƒæœ€å°äºŒä¹˜ï¼ˆIRLSï¼‰ä¼˜åŒ–ï¼›3) æŸå¤±å‡½æ•°çš„è®¾è®¡å¯èƒ½åŒ…å«å‡ ä½•ä¸€è‡´æ€§çº¦æŸï¼Œä»¥ä¿è¯é‡å»ºçš„å‡†ç¡®æ€§ï¼ˆå…·ä½“ç»†èŠ‚æœªçŸ¥ï¼‰ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

SwiftVGGTåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒæœ€å…ˆè¿›é‡å»ºè´¨é‡çš„åŒæ—¶ï¼ŒæŽ¨ç†æ—¶é—´ä»…ä¸ºçŽ°æœ‰åŸºäºŽVGGTçš„å¤§è§„æ¨¡é‡å»ºæ–¹æ³•çš„33%ã€‚è¿™è¡¨æ˜ŽSwiftVGGTåœ¨æ•ˆçŽ‡æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æå‡ï¼Œä½¿å…¶æ›´é€‚ç”¨äºŽå®žé™…åº”ç”¨ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

SwiftVGGTåœ¨å¤§è§„æ¨¡åœºæ™¯çš„ä¸‰ç»´é‡å»ºæ–¹é¢å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€åŸŽå¸‚å»ºæ¨¡ã€è™šæ‹ŸçŽ°å®žå’Œå¢žå¼ºçŽ°å®žç­‰é¢†åŸŸã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿå¿«é€Ÿä¸”å‡†ç¡®åœ°é‡å»ºå¤§è§„æ¨¡çŽ¯å¢ƒï¼Œä¸ºè¿™äº›åº”ç”¨æä¾›å¯é çš„ä¸‰ç»´åœ°å›¾ä¿¡æ¯ï¼Œå…·æœ‰é‡è¦çš„å®žé™…ä»·å€¼å’Œæ½œåœ¨çš„æœªæ¥å½±å“ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> 3D reconstruction in large-scale scenes is a fundamental task in 3D perception, but the inherent trade-off between accuracy and computational efficiency remains a significant challenge. Existing methods either prioritize speed and produce low-quality results, or achieve high-quality reconstruction at the cost of slow inference times. In this paper, we propose SwiftVGGT, a training-free method that significantly reduce inference time while preserving high-quality dense 3D reconstruction. To maintain global consistency in large-scale scenes, SwiftVGGT performs loop closure without relying on the external Visual Place Recognition (VPR) model. This removes redundant computation and enables accurate reconstruction over kilometer-scale environments. Furthermore, we propose a simple yet effective point sampling method to align neighboring chunks using a single Sim(3)-based Singular Value Decomposition (SVD) step. This eliminates the need for the Iteratively Reweighted Least Squares (IRLS) optimization commonly used in prior work, leading to substantial speed-ups. We evaluate SwiftVGGT on multiple datasets and show that it achieves state-of-the-art reconstruction quality while requiring only 33% of the inference time of recent VGGT-based large-scale reconstruction approaches.

