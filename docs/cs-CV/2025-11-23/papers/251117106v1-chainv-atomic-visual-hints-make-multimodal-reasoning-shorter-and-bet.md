---
layout: default
title: ChainV: Atomic Visual Hints Make Multimodal Reasoning Shorter and Better
---

# ChainV: Atomic Visual Hints Make Multimodal Reasoning Shorter and Better

**arXiv**: [2511.17106v1](https://arxiv.org/abs/2511.17106) | [PDF](https://arxiv.org/pdf/2511.17106.pdf)

**ä½œè€…**: Yuan Zhang, Ming Lu, Junwen Pan, Tao Huang, Kuan Cheng, Qi She, Shanghang Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºChainVæ¡†æž¶ï¼Œé€šè¿‡åŠ¨æ€è§†è§‰æç¤ºä¼˜åŒ–å¤šæ¨¡æ€æŽ¨ç†çš„å‡†ç¡®æ€§ä¸Žæ•ˆçŽ‡**

**å…³é”®è¯**: `å¤šæ¨¡æ€æŽ¨ç†` `è§†è§‰æç¤ºé€‰æ‹©` `æŽ¨ç†æ•ˆçŽ‡ä¼˜åŒ–` `æ³¨æ„åŠ›æœºåˆ¶` `æ•°å­¦æŽ¨ç†åŸºå‡†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€æŽ¨ç†æ¨¡åž‹å­˜åœ¨å†—ä½™è‡ªåæ€ï¼Œå¯¼è‡´æŽ¨ç†é“¾è¿‡é•¿ä¸”æ•ˆçŽ‡ä½Žä¸‹
2. æ–¹æ³•è¦ç‚¹ï¼šåŠ¨æ€é€‰æ‹©åŽŸå­è§†è§‰æç¤ºï¼ŒåŸºäºŽæ³¨æ„åŠ›å¼ºåº¦ä¸Žä¸€è‡´æ€§è¯„ä¼°ä¼˜åŒ–æŽ¨ç†è¿‡ç¨‹
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨MathVistaç­‰åŸºå‡†ä¸Šæå‡å‡†ç¡®çŽ‡2.3%ï¼Œé™ä½Žå»¶è¿Ÿ51.4%å’Œè¾“å‡ºé•¿åº¦24.5%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in multimodal reasoning models have demonstrated impressive capabilities across text and vision. However, even leading models exhibit redundant self-reflection when generating lengthy reasoning chains. While training-free CoT compression methods have emerged in the LLMs domain, they rely on static visual references and thus provide limited gains for multimodal reasoning. Therefore, we propose ChainV, a framework that dynamically integrates visual hints into the reasoning process, thereby making multimodal reasoning shorter and better. Specifically, ChainV first performs a coarse visual patch selection based on the previous reasoning step, then refines it by identifying the most representative atomic visual hint according to the averaged attention intensity. Additionally, ChainV introduces a consistency-based evaluation mechanism to assess the reliability of the chosen hint, guiding the model to adaptively adjust its level of self-reflection. Eventually, the pixel coordinates of the selected visual hint and its reliability are incorporated into thinking with a Bernoulli stochastic process. Experiments indicate that our method significantly improves reasoning accuracy and efficiency, especially on math-intensive benchmarks where visual hints are crucial for multi-step symbolic reasoning. For example, ChainV achieves $2.3\%$ improvement on the MathVista within MIMO-VL-RL, while reducing inference latency by $51.4\%$ and shortening output token length by $24.5\%$.

