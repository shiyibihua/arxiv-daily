---
layout: default
title: Warm Diffusion: Recipe for Blur-Noise Mixture Diffusion Models
---

# Warm Diffusion: Recipe for Blur-Noise Mixture Diffusion Models

**arXiv**: [2511.16904v1](https://arxiv.org/abs/2511.16904) | [PDF](https://arxiv.org/pdf/2511.16904.pdf)

**ä½œè€…**: Hao-Chien Hsueh, Chi-En Yen, Wen-Hsiao Peng, Ching-Chun Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWarm Diffusionä»¥ç»“åˆå™ªå£°ä¸Žæ¨¡ç³Šæ‰©æ•£ä¼˜åŠ¿ï¼Œæå‡å›¾åƒç”Ÿæˆè´¨é‡**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹` `å›¾åƒç”Ÿæˆ` `æ¨¡ç³Šå™ªå£°æ··åˆ` `è°±åˆ†æž` `åŽ»å™ªåŽ»æ¨¡ç³Š`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçƒ­æ‰©æ•£å¿½ç•¥å›¾åƒç›¸å…³æ€§ï¼Œå†·æ‰©æ•£ç¼ºä¹å™ªå£°å¯¼è‡´æ•°æ®æµå½¢é—®é¢˜
2. æ–¹æ³•è¦ç‚¹ï¼šè”åˆæŽ§åˆ¶æ¨¡ç³Šå’Œå™ªå£°ï¼Œåˆ©ç”¨è°±ä¾èµ–ç®€åŒ–åŽ»å™ªä¸ŽåŽ»æ¨¡ç³Šè¿‡ç¨‹
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­éªŒè¯æ¨¡åž‹æœ‰æ•ˆæ€§ï¼Œæ”¹å–„ç”Ÿæˆæ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Diffusion probabilistic models have achieved remarkable success in generative tasks across diverse data types. While recent studies have explored alternative degradation processes beyond Gaussian noise, this paper bridges two key diffusion paradigms: hot diffusion, which relies entirely on noise, and cold diffusion, which uses only blurring without noise. We argue that hot diffusion fails to exploit the strong correlation between high-frequency image detail and low-frequency structures, leading to random behaviors in the early steps of generation. Conversely, while cold diffusion leverages image correlations for prediction, it neglects the role of noise (randomness) in shaping the data manifold, resulting in out-of-manifold issues and partially explaining its performance drop. To integrate both strengths, we propose Warm Diffusion, a unified Blur-Noise Mixture Diffusion Model (BNMD), to control blurring and noise jointly. Our divide-and-conquer strategy exploits the spectral dependency in images, simplifying score model estimation by disentangling the denoising and deblurring processes. We further analyze the Blur-to-Noise Ratio (BNR) using spectral analysis to investigate the trade-off between model learning dynamics and changes in the data manifold. Extensive experiments across benchmarks validate the effectiveness of our approach for image generation.

