---
layout: default
title: Image-Plane Geometric Decoding for View-Invariant Indoor Scene Reconstruction
---

# Image-Plane Geometric Decoding for View-Invariant Indoor Scene Reconstruction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25744" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25744v2</a>
  <a href="https://arxiv.org/pdf/2509.25744.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25744v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25744v2', 'Image-Plane Geometric Decoding for View-Invariant Indoor Scene Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mingyang Li, Yimeng Fan, Changsong Liu, Lixue Xu, Xin Wang, Yanyan Liu, Wei Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30 (æ›´æ–°: 2025-10-27)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå›¾åƒå¹³é¢å‡ ä½•è§£ç æ¡†æ¶ï¼Œè§£å†³å®¤å†…åœºæ™¯é‡å»ºå¯¹è§†è§’ä¾èµ–çš„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å®¤å†…åœºæ™¯é‡å»º` `è§†è§’ä¸å˜æ€§` `å›¾åƒå¹³é¢è§£ç ` `ä¸‰ç»´é‡å»º` `å•è§†è§’é‡å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºä½“ç´ çš„å®¤å†…åœºæ™¯é‡å»ºæ–¹æ³•ä¾èµ–å¤šè§†è§’å‡ ä½•çº¦æŸï¼Œè§†è§’å¯†åº¦ä¸è¶³æ—¶é‡å»ºè´¨é‡ä¸‹é™ã€‚
2. è®ºæ–‡æå‡ºå›¾åƒå¹³é¢è§£ç æ¡†æ¶ï¼Œåˆ©ç”¨å•è§†è§’å›¾åƒå†…çš„ç©ºé—´ä¿¡æ¯ï¼Œå‡å°‘å¯¹å¤šè§†è§’å‡ ä½•çº¦æŸçš„ä¾èµ–ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è§†è§’æ•°é‡å‡å°‘40%çš„æƒ…å†µä¸‹ï¼Œä»èƒ½ä¿æŒé«˜è´¨é‡é‡å»ºï¼Œå…·æœ‰è‰¯å¥½çš„è§†è§’ä¸å˜æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºä½“ç´ çš„å®¤å†…åœºæ™¯é‡å»ºæ–¹æ³•å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œå®æ—¶éƒ¨ç½²æ½œåŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¾èµ–äºå¤šè§†è§’åƒç´ åæŠ•å½±å…‰çº¿ç›¸äº¤ä½œä¸ºå¼±å‡ ä½•çº¦æŸæ¥ç¡®å®šç©ºé—´ä½ç½®ï¼Œå¯¼è‡´é‡å»ºè´¨é‡ä¸¥é‡å—è¾“å…¥è§†è§’å¯†åº¦çš„å½±å“ï¼Œåœ¨é‡å åŒºåŸŸå’Œæœªè§‚å¯ŸåŒºåŸŸæ€§èƒ½ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºä¸€ç§å›¾åƒå¹³é¢è§£ç æ¡†æ¶ï¼Œé€šè¿‡åˆ©ç”¨å•è§†è§’å†…çš„ç©ºé—´ä¿¡æ¯æ¥å‡å°‘å¯¹è§†è§’é—´å‡ ä½•çº¦æŸçš„ä¾èµ–ã€‚è¯¥æ¡†æ¶åŒ…å«åƒç´ çº§ç½®ä¿¡åº¦ç¼–ç å™¨ã€ä»¿å°„è¡¥å¿æ¨¡å—å’Œå›¾åƒå¹³é¢ç©ºé—´è§£ç å™¨ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œèƒ½å¤Ÿè§£ç å›¾åƒä¸­é€šè¿‡ç‰©ç†æˆåƒè¿‡ç¨‹ç¼–ç çš„ä¸‰ç»´ç»“æ„ä¿¡æ¯ï¼Œæœ‰æ•ˆä¿ç•™ç©ºé—´å‡ ä½•ç‰¹å¾ï¼Œæ˜¾è‘—å¢å¼ºè§†è§’ä¸å˜é‡å»ºèƒ½åŠ›ã€‚åœ¨å®¤å†…åœºæ™¯é‡å»ºæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å…·æœ‰ä¼˜è¶Šçš„é‡å»ºç¨³å®šæ€§ï¼Œåœ¨è§†è§’æ•°é‡å‡å°‘40%çš„æƒ…å†µä¸‹ï¼Œä»èƒ½ä¿æŒå‡ ä¹ç›¸åŒçš„è´¨é‡ï¼Œå˜å¼‚ç³»æ•°ä¸º0.24%ï¼Œæ€§èƒ½ä¿æŒç‡ä¸º99.7%ï¼Œæœ€å¤§æ€§èƒ½ä¸‹é™ä¸º0.42%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œåˆ©ç”¨è§†è§’å†…ç©ºé—´ä¿¡æ¯ä¸ºå®é™…åº”ç”¨ä¸­è§†è§’å—é™çš„åœºæ™¯æä¾›äº†ä¸€ç§é²æ£’çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºä½“ç´ çš„å®¤å†…åœºæ™¯é‡å»ºæ–¹æ³•ï¼Œä¸¥é‡ä¾èµ–å¤šè§†è§’å›¾åƒæä¾›çš„å‡ ä½•çº¦æŸã€‚å…·ä½“æ¥è¯´ï¼Œè¿™äº›æ–¹æ³•é€šè¿‡åæŠ•å½±åƒç´ å…‰çº¿å¹¶åœ¨ç©ºé—´ä¸­æ±‚äº¤æ¥ç¡®å®šä¸‰ç»´ç‚¹çš„ä½ç½®ã€‚å½“è§†è§’æ•°é‡ä¸è¶³æˆ–è§†è§’åˆ†å¸ƒä¸å‡åŒ€æ—¶ï¼Œå…‰çº¿ç›¸äº¤çš„ç²¾åº¦ä¼šæ˜¾è‘—ä¸‹é™ï¼Œå¯¼è‡´é‡å»ºè´¨é‡é™ä½ï¼Œå°¤å…¶æ˜¯åœ¨é®æŒ¡åŒºåŸŸå’Œæœªè§‚æµ‹åŒºåŸŸã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å‡å°‘å¯¹å¤šè§†è§’å‡ ä½•çº¦æŸçš„ä¾èµ–ï¼Œè½¬è€Œåˆ©ç”¨å•å¼ å›¾åƒä¸­è•´å«çš„ç©ºé—´ä¿¡æ¯ã€‚ä½œè€…è®¤ä¸ºï¼Œå•å¼ å›¾åƒé€šè¿‡ç‰©ç†æˆåƒè¿‡ç¨‹å·²ç»ç¼–ç äº†ä¸‰ç»´åœºæ™¯çš„ç»“æ„ä¿¡æ¯ï¼Œä¾‹å¦‚è¾¹ç¼˜ã€çº¹ç†å’Œç©ºé—´å…³ç³»ã€‚é€šè¿‡è®¾è®¡åˆé€‚çš„ç½‘ç»œç»“æ„ï¼Œå¯ä»¥ä»å•å¼ å›¾åƒä¸­è§£ç å‡ºè¿™äº›ä¸‰ç»´ä¿¡æ¯ï¼Œä»è€Œå®ç°è§†è§’ä¸å˜çš„é‡å»ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•æå‡ºçš„å›¾åƒå¹³é¢è§£ç æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) åƒç´ çº§ç½®ä¿¡åº¦ç¼–ç å™¨ï¼šç”¨äºæå–å›¾åƒçš„ç‰¹å¾ï¼Œå¹¶ä¼°è®¡æ¯ä¸ªåƒç´ çš„ç½®ä¿¡åº¦ï¼Œä»¥åŒºåˆ†å¯é å’Œä¸å¯é çš„ä¿¡æ¯ã€‚2) ä»¿å°„è¡¥å¿æ¨¡å—ï¼šç”¨äºè¡¥å¿ç”±äºè§†è§’å˜åŒ–å¼•èµ·çš„å›¾åƒä»¿å°„å˜æ¢ï¼Œä»è€Œå¯¹é½ä¸åŒè§†è§’çš„ç‰¹å¾ã€‚3) å›¾åƒå¹³é¢ç©ºé—´è§£ç å™¨ï¼šç”¨äºä»å›¾åƒç‰¹å¾ä¸­è§£ç å‡ºä¸‰ç»´ç»“æ„ä¿¡æ¯ï¼Œä¾‹å¦‚æ·±åº¦ã€è¡¨é¢æ³•çº¿ç­‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºï¼Œå®ƒå°†ä¸‰ç»´é‡å»ºé—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªå›¾åƒè§£ç é—®é¢˜ï¼Œå³ä»å•å¼ å›¾åƒä¸­è§£ç å‡ºä¸‰ç»´åœºæ™¯çš„ç»“æ„ä¿¡æ¯ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ä¾èµ–å¤šè§†è§’å‡ ä½•çº¦æŸä¸åŒï¼Œè¯¥æ–¹æ³•æ›´åŠ æ³¨é‡åˆ©ç”¨å•è§†è§’å›¾åƒä¸­çš„ç©ºé—´ä¿¡æ¯ï¼Œä»è€Œæé«˜äº†é‡å»ºçš„é²æ£’æ€§å’Œè§†è§’ä¸å˜æ€§ã€‚è¿™ç§æ€è·¯çš„è½¬å˜ä½¿å¾—åœ¨è§†è§’å—é™çš„åœºæ™¯ä¸‹è¿›è¡Œé«˜è´¨é‡é‡å»ºæˆä¸ºå¯èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåƒç´ çº§ç½®ä¿¡åº¦ç¼–ç å™¨å¯èƒ½é‡‡ç”¨å·ç§¯ç¥ç»ç½‘ç»œæå–å›¾åƒç‰¹å¾ï¼Œå¹¶ä½¿ç”¨sigmoidå‡½æ•°é¢„æµ‹åƒç´ ç½®ä¿¡åº¦ã€‚ä»¿å°„è¡¥å¿æ¨¡å—å¯èƒ½ä½¿ç”¨å¯å˜å½¢å·ç§¯æˆ–æ³¨æ„åŠ›æœºåˆ¶æ¥å¯¹é½ä¸åŒè§†è§’çš„ç‰¹å¾ã€‚å›¾åƒå¹³é¢ç©ºé—´è§£ç å™¨å¯èƒ½é‡‡ç”¨U-Netç»“æ„ï¼Œé€æ­¥è§£ç å‡ºæ·±åº¦å›¾æˆ–ç‚¹äº‘ã€‚æŸå¤±å‡½æ•°å¯èƒ½åŒ…æ‹¬æ·±åº¦æŸå¤±ã€æ³•çº¿æŸå¤±å’Œå‡ ä½•ä¸€è‡´æ€§æŸå¤±ï¼Œä»¥çº¦æŸé‡å»ºç»“æœçš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®éœ€è¦åœ¨è®ºæ–‡ä¸­è¿›ä¸€æ­¥æŸ¥æ‰¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è§†è§’æ•°é‡å‡å°‘40%çš„æƒ…å†µä¸‹ï¼Œä»èƒ½ä¿æŒå‡ ä¹ç›¸åŒçš„é‡å»ºè´¨é‡ï¼Œå˜å¼‚ç³»æ•°ä»…ä¸º0.24%ï¼Œæ€§èƒ½ä¿æŒç‡ä¸º99.7%ï¼Œæœ€å¤§æ€§èƒ½ä¸‹é™ä»…ä¸º0.42%ã€‚è¿™äº›æ•°æ®è¡¨æ˜ï¼Œè¯¥æ–¹æ³•å…·æœ‰ä¼˜è¶Šçš„è§†è§’ä¸å˜æ€§å’Œé²æ£’æ€§ï¼Œæ˜¾è‘—ä¼˜äºä¾èµ–å¤šè§†è§’å‡ ä½•çº¦æŸçš„ä¼ ç»Ÿæ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€ä¸‰ç»´åœ°å›¾æ„å»ºç­‰é¢†åŸŸã€‚åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œå³ä½¿è§†è§’æœ‰é™ï¼Œæœºå™¨äººä¹Ÿèƒ½å‡†ç¡®é‡å»ºå‘¨å›´ç¯å¢ƒï¼Œä»è€Œå®ç°è‡ªä¸»å¯¼èˆªã€‚åœ¨è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ä¸­ï¼Œå¯ä»¥åˆ©ç”¨å°‘é‡å›¾åƒå¿«é€Ÿæ„å»ºé€¼çœŸçš„ä¸‰ç»´åœºæ™¯ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºä¸‰ç»´åœ°å›¾æ„å»ºï¼Œå°¤å…¶æ˜¯åœ¨å®¤å†…ç¯å¢ƒç­‰è§†è§’å—é™çš„åœºæ™¯ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Volume-based indoor scene reconstruction methods offer superior generalization capability and real-time deployment potential. However, existing methods rely on multi-view pixel back-projection ray intersections as weak geometric constraints to determine spatial positions. This dependence results in reconstruction quality being heavily influenced by input view density. Performance degrades in overlapping regions and unobserved areas.To address these limitations, we reduce dependency on inter-view geometric constraints by exploiting spatial information within individual views. We propose an image-plane decoding framework with three core components: Pixel-level Confidence Encoder, Affine Compensation Module, and Image-Plane Spatial Decoder. These modules decode three-dimensional structural information encoded in images through physical imaging processes. The framework effectively preserves spatial geometric features including edges, hollow structures, and complex textures. It significantly enhances view-invariant reconstruction.Experiments on indoor scene reconstruction datasets confirm superior reconstruction stability. Our method maintains nearly identical quality when view count reduces by 40%. It achieves a coefficient of variation of 0.24%, performance retention rate of 99.7%, and maximum performance drop of 0.42%. These results demonstrate that exploiting intra-view spatial information provides a robust solution for view-limited scenarios in practical applications.

