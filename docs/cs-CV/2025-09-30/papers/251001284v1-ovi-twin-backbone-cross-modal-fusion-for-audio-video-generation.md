---
layout: default
title: Ovi: Twin Backbone Cross-Modal Fusion for Audio-Video Generation
---

# Ovi: Twin Backbone Cross-Modal Fusion for Audio-Video Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.01284" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.01284v1</a>
  <a href="https://arxiv.org/pdf/2510.01284.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.01284v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.01284v1', 'Ovi: Twin Backbone Cross-Modal Fusion for Audio-Video Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chetwin Low, Weimin Wang, Calder Katyal

**åˆ†ç±»**: cs.MM, cs.CV, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://aaxwaz.github.io/Ovi)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Oviï¼šåŸºäºå­ªç”Ÿéª¨å¹²è·¨æ¨¡æ€èåˆçš„éŸ³è§†é¢‘ç”Ÿæˆæ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éŸ³è§†é¢‘ç”Ÿæˆ` `è·¨æ¨¡æ€èåˆ` `æ‰©æ•£æ¨¡å‹` `å­ªç”Ÿç½‘ç»œ` `DiT` `Transformer` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰éŸ³è§†é¢‘ç”Ÿæˆæ–¹æ³•ä¾èµ–å¤æ‚çš„å¤šé˜¶æ®µæ¶æ„æˆ–å£°éŸ³å’Œè§†è§‰çš„é¡ºåºåˆæˆï¼Œç¼ºä¹ç»Ÿä¸€æ€§ã€‚
2. Ovié€šè¿‡å­ªç”ŸDiTæ¨¡å—çš„å—çŠ¶è·¨æ¨¡æ€èåˆï¼Œå°†éŸ³è§†é¢‘å»ºæ¨¡ä¸ºå•ä¸€ç”Ÿæˆè¿‡ç¨‹ï¼Œå®ç°è‡ªç„¶åŒæ­¥ã€‚
3. Oviåœ¨å¤§é‡éŸ³è§†é¢‘æ•°æ®ä¸Šè®­ç»ƒï¼Œç”Ÿæˆé€¼çœŸéŸ³æ•ˆå’Œå¯Œå«æƒ…æ„Ÿçš„è¯­éŸ³ï¼Œåˆ¶ä½œç”µå½±çº§è§†é¢‘ç‰‡æ®µã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºéŸ³è§†é¢‘ç”Ÿæˆçš„ç»Ÿä¸€èŒƒå¼Oviï¼Œå®ƒå°†ä¸¤ç§æ¨¡æ€å»ºæ¨¡ä¸ºå•ä¸€çš„ç”Ÿæˆè¿‡ç¨‹ã€‚é€šè¿‡ä½¿ç”¨å­ªç”ŸDiTæ¨¡å—çš„å—çŠ¶è·¨æ¨¡æ€èåˆï¼ŒOviå®ç°äº†è‡ªç„¶çš„åŒæ­¥ï¼Œå¹¶æ¶ˆé™¤äº†å¯¹å•ç‹¬æµæ°´çº¿æˆ–äº‹åå¯¹é½çš„éœ€æ±‚ã€‚ä¸ºäº†ä¿ƒè¿›ç»†ç²’åº¦çš„å¤šæ¨¡æ€èåˆå»ºæ¨¡ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸å¼ºå¤§çš„é¢„è®­ç»ƒè§†é¢‘æ¨¡å‹ç›¸åŒçš„æ¶æ„åˆå§‹åŒ–äº†ä¸€ä¸ªéŸ³é¢‘å¡”ã€‚éŸ³é¢‘å¡”ä»å¤´å¼€å§‹åœ¨æ•°åä¸‡å°æ—¶çš„åŸå§‹éŸ³é¢‘ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ ç”Ÿæˆé€¼çœŸçš„éŸ³æ•ˆï¼Œä»¥åŠä¼ è¾¾ä¸°å¯Œçš„è¯´è¯äººèº«ä»½å’Œæƒ…æ„Ÿçš„è¯­éŸ³ã€‚é€šè¿‡åœ¨æµ·é‡çš„è§†é¢‘è¯­æ–™åº“ä¸Šï¼Œä»¥å—çŠ¶äº¤æ¢æ—¶é—´ä¿¡æ¯ï¼ˆé€šè¿‡ç¼©æ”¾çš„RoPEåµŒå…¥ï¼‰å’Œè¯­ä¹‰ä¿¡æ¯ï¼ˆé€šè¿‡åŒå‘äº¤å‰æ³¨æ„åŠ›ï¼‰çš„æ–¹å¼è”åˆè®­ç»ƒç›¸åŒçš„è§†é¢‘å’ŒéŸ³é¢‘å¡”ï¼Œä»è€Œå®ç°èåˆã€‚æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œç”µå½±çº§çš„è§†é¢‘å‰ªè¾‘åˆ¶ä½œï¼Œå…·æœ‰è‡ªç„¶çš„è¯­éŸ³å’Œå‡†ç¡®çš„ã€ä¸Šä¸‹æ–‡åŒ¹é…çš„éŸ³æ•ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šéŸ³è§†é¢‘ç”Ÿæˆä»»åŠ¡æ—¨åœ¨æ ¹æ®ç»™å®šçš„æ¡ä»¶ï¼ˆä¾‹å¦‚æ–‡æœ¬æè¿°ã€éŸ³ä¹ç­‰ï¼‰ç”Ÿæˆä¸ä¹‹å¯¹åº”çš„è§†é¢‘å†…å®¹ï¼ŒåŒ…æ‹¬è§†è§‰ç”»é¢å’Œå£°éŸ³ã€‚ç°æœ‰çš„æ–¹æ³•é€šå¸¸é‡‡ç”¨å¤šé˜¶æ®µçš„å¤æ‚æ¶æ„ï¼Œæˆ–è€…åˆ†åˆ«ç”ŸæˆéŸ³é¢‘å’Œè§†é¢‘ï¼Œç„¶åè¿›è¡ŒåæœŸçš„å¯¹é½å’Œèåˆï¼Œè¿™å¯¼è‡´äº†ç”Ÿæˆè¿‡ç¨‹çš„å¤æ‚æ€§å¢åŠ ï¼Œå¹¶ä¸”éš¾ä»¥ä¿è¯éŸ³è§†é¢‘ä¹‹é—´çš„è‡ªç„¶åŒæ­¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOviçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†éŸ³è§†é¢‘ç”Ÿæˆè§†ä¸ºä¸€ä¸ªç»Ÿä¸€çš„ç”Ÿæˆè¿‡ç¨‹ï¼Œé€šè¿‡å…±äº«çš„ç”Ÿæˆæ¨¡å‹åŒæ—¶ç”ŸæˆéŸ³é¢‘å’Œè§†é¢‘ï¼Œä»è€Œå®ç°éŸ³è§†é¢‘ä¹‹é—´çš„è‡ªç„¶åŒæ­¥ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼ŒOvié‡‡ç”¨äº†å­ªç”Ÿéª¨å¹²ç½‘ç»œç»“æ„ï¼Œåˆ†åˆ«å¤„ç†éŸ³é¢‘å’Œè§†é¢‘ä¿¡æ¯ï¼Œå¹¶é€šè¿‡è·¨æ¨¡æ€èåˆæ¨¡å—å®ç°ä¿¡æ¯äº¤äº’ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOviçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦çš„æ¨¡å—ï¼šéŸ³é¢‘å¡”å’Œè§†é¢‘å¡”ã€‚è¿™ä¸¤ä¸ªå¡”éƒ½åŸºäºDiTï¼ˆDiffusion Transformerï¼‰æ¶æ„ï¼Œå¹¶ä¸”å…·æœ‰ç›¸åŒçš„ç½‘ç»œç»“æ„ã€‚éŸ³é¢‘å¡”è´Ÿè´£ç”ŸæˆéŸ³é¢‘ä¿¡æ¯ï¼Œè§†é¢‘å¡”è´Ÿè´£ç”Ÿæˆè§†é¢‘ä¿¡æ¯ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒéŸ³é¢‘å¡”é¦–å…ˆåœ¨å¤§é‡çš„éŸ³é¢‘æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå­¦ä¹ ç”Ÿæˆé€¼çœŸçš„éŸ³æ•ˆå’Œè¯­éŸ³ã€‚ç„¶åï¼ŒéŸ³é¢‘å¡”å’Œè§†é¢‘å¡”åœ¨å¤§é‡çš„éŸ³è§†é¢‘æ•°æ®ä¸Šè¿›è¡Œè”åˆè®­ç»ƒï¼Œé€šè¿‡è·¨æ¨¡æ€èåˆæ¨¡å—å®ç°ä¿¡æ¯äº¤äº’ã€‚è·¨æ¨¡æ€èåˆæ¨¡å—é‡‡ç”¨å—çŠ¶ç»“æ„ï¼Œåœ¨ä¸åŒçš„ç½‘ç»œå±‚ä¹‹é—´è¿›è¡Œä¿¡æ¯äº¤æ¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šOviçš„å…³é”®åˆ›æ–°åœ¨äºä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š1) ç»Ÿä¸€çš„éŸ³è§†é¢‘ç”ŸæˆèŒƒå¼ï¼Œå°†éŸ³è§†é¢‘ç”Ÿæˆè§†ä¸ºä¸€ä¸ªå•ä¸€çš„ç”Ÿæˆè¿‡ç¨‹ï¼›2) å­ªç”Ÿéª¨å¹²ç½‘ç»œç»“æ„ï¼Œåˆ†åˆ«å¤„ç†éŸ³é¢‘å’Œè§†é¢‘ä¿¡æ¯ï¼Œå¹¶é€šè¿‡è·¨æ¨¡æ€èåˆæ¨¡å—å®ç°ä¿¡æ¯äº¤äº’ï¼›3) å—çŠ¶è·¨æ¨¡æ€èåˆæ¨¡å—ï¼Œåœ¨ä¸åŒçš„ç½‘ç»œå±‚ä¹‹é—´è¿›è¡Œä¿¡æ¯äº¤æ¢ï¼Œä»è€Œå®ç°ç»†ç²’åº¦çš„å¤šæ¨¡æ€èåˆã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒOvié¿å…äº†å¤æ‚çš„å¤šé˜¶æ®µæ¶æ„å’ŒåæœŸçš„å¯¹é½æ“ä½œï¼Œä»è€Œç®€åŒ–äº†ç”Ÿæˆè¿‡ç¨‹ï¼Œå¹¶æé«˜äº†éŸ³è§†é¢‘ä¹‹é—´çš„åŒæ­¥æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šOviçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨DiTä½œä¸ºéª¨å¹²ç½‘ç»œï¼ŒDiTæ˜¯ä¸€ç§åŸºäºTransformerçš„æ‰©æ•£æ¨¡å‹ï¼Œå…·æœ‰å¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›ï¼›2) ä½¿ç”¨ç¼©æ”¾çš„RoPEï¼ˆRotary Position Embeddingï¼‰åµŒå…¥æ¥ç¼–ç æ—¶é—´ä¿¡æ¯ï¼Œä»è€Œå®ç°éŸ³è§†é¢‘ä¹‹é—´çš„æ—¶é—´åŒæ­¥ï¼›3) ä½¿ç”¨åŒå‘äº¤å‰æ³¨æ„åŠ›æœºåˆ¶æ¥å®ç°è·¨æ¨¡æ€èåˆï¼Œä»è€Œå®ç°éŸ³è§†é¢‘ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ï¼›4) ä½¿ç”¨å¤§é‡çš„éŸ³è§†é¢‘æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä»è€Œæé«˜æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡å±•ç¤ºäº†Oviåœ¨ç”Ÿæˆé«˜è´¨é‡éŸ³è§†é¢‘æ–¹é¢çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿç”Ÿæˆå…·æœ‰è‡ªç„¶è¯­éŸ³å’Œå‡†ç¡®éŸ³æ•ˆçš„ç”µå½±çº§è§†é¢‘ç‰‡æ®µã€‚é€šè¿‡ä¸ç°æœ‰æ–¹æ³•çš„å¯¹æ¯”ï¼ŒOviåœ¨éŸ³è§†é¢‘åŒæ­¥æ€§å’Œç”Ÿæˆè´¨é‡æ–¹é¢éƒ½å–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚è®ºæ–‡è¿˜æä¾›äº†å¤§é‡çš„å®éªŒç»“æœå’Œå¯è§†åŒ–æ¡ˆä¾‹ï¼Œè¯æ˜äº†Oviçš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†ä»demoæ•ˆæœæ¥çœ‹ï¼Œç”Ÿæˆè´¨é‡è¾ƒé«˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Oviå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚ç”µå½±åˆ¶ä½œã€æ¸¸æˆå¼€å‘ã€è™šæ‹Ÿç°å®ã€å¹¿å‘Šåˆ›æ„ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºç”Ÿæˆå…·æœ‰è‡ªç„¶è¯­éŸ³å’Œå‡†ç¡®éŸ³æ•ˆçš„ç”µå½±ç‰‡æ®µï¼Œåˆ›å»ºæ²‰æµ¸å¼çš„æ¸¸æˆä½“éªŒï¼Œè®¾è®¡å¼•äººå…¥èƒœçš„å¹¿å‘Šå†…å®¹ã€‚æ­¤å¤–ï¼ŒOviè¿˜å¯ä»¥ç”¨äºè¾…åŠ©éŸ³è§†é¢‘ç¼–è¾‘ï¼Œä¾‹å¦‚è‡ªåŠ¨ç”ŸæˆèƒŒæ™¯éŸ³ä¹ã€æ·»åŠ éŸ³æ•ˆç­‰ï¼Œä»è€Œæé«˜ç¼–è¾‘æ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Audio-video generation has often relied on complex multi-stage architectures or sequential synthesis of sound and visuals. We introduce Ovi, a unified paradigm for audio-video generation that models the two modalities as a single generative process. By using blockwise cross-modal fusion of twin-DiT modules, Ovi achieves natural synchronization and removes the need for separate pipelines or post hoc alignment. To facilitate fine-grained multimodal fusion modeling, we initialize an audio tower with an architecture identical to that of a strong pretrained video model. Trained from scratch on hundreds of thousands of hours of raw audio, the audio tower learns to generate realistic sound effects, as well as speech that conveys rich speaker identity and emotion. Fusion is obtained by jointly training the identical video and audio towers via blockwise exchange of timing (via scaled-RoPE embeddings) and semantics (through bidirectional cross-attention) on a vast video corpus. Our model enables cinematic storytelling with natural speech and accurate, context-matched sound effects, producing movie-grade video clips. All the demos, code and model weights are published at https://aaxwaz.github.io/Ovi

