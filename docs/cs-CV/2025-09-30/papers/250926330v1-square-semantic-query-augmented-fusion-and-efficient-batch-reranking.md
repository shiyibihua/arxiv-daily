---
layout: default
title: SQUARE: Semantic Query-Augmented Fusion and Efficient Batch Reranking for Training-free Zero-Shot Composed Image Retrieval
---

# SQUARE: Semantic Query-Augmented Fusion and Efficient Batch Reranking for Training-free Zero-Shot Composed Image Retrieval

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26330" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26330v1</a>
  <a href="https://arxiv.org/pdf/2509.26330.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26330v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26330v1', 'SQUARE: Semantic Query-Augmented Fusion and Efficient Batch Reranking for Training-free Zero-Shot Composed Image Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ren-Di Wu, Yu-Yen Lin, Huei-Fang Yang

**åˆ†ç±»**: cs.CV, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: 20 pages, 9 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSQUAREæ¡†æ¶ï¼Œé€šè¿‡è¯­ä¹‰å¢å¼ºå’Œé«˜æ•ˆé‡æ’åºå®ç°å…è®­ç»ƒé›¶æ ·æœ¬ç»„åˆå›¾åƒæ£€ç´¢**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç»„åˆå›¾åƒæ£€ç´¢` `é›¶æ ·æœ¬å­¦ä¹ ` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è¯­ä¹‰å¢å¼º` `æ‰¹é‡æ’åº`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é›¶æ ·æœ¬ç»„åˆå›¾åƒæ£€ç´¢æ—¨åœ¨æ ¹æ®å‚è€ƒå›¾åƒå’Œæ–‡æœ¬ä¿®æ”¹æ£€ç´¢ç›®æ ‡å›¾åƒï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥å‡†ç¡®æ•æ‰ç”¨æˆ·æ„å›¾ã€‚
2. SQUAREæ¡†æ¶åˆ©ç”¨MLLMç”Ÿæˆç›®æ ‡å›¾åƒçš„æè¿°ï¼Œå¢å¼ºæŸ¥è¯¢åµŒå…¥ï¼Œå¹¶ä½¿ç”¨é«˜æ•ˆæ‰¹é‡æ’åºç­–ç•¥æå‡æ£€ç´¢ç²¾åº¦ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSQUAREåœ¨å¤šä¸ªCIRåŸºå‡†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå³ä½¿ä½¿ç”¨è½»é‡çº§é¢„è®­ç»ƒæ¨¡å‹ä¹Ÿèƒ½ä¿æŒé«˜æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºSQUAREï¼Œä¸€ç§æ–°é¢–çš„ä¸¤é˜¶æ®µå…è®­ç»ƒæ¡†æ¶ï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)æ¥å¢å¼ºé›¶æ ·æœ¬ç»„åˆå›¾åƒæ£€ç´¢(ZS-CIR)ã€‚åœ¨è¯­ä¹‰æŸ¥è¯¢å¢å¼ºèåˆ(SQAF)é˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨MLLMç”Ÿæˆçš„å…³äºç›®æ ‡å›¾åƒçš„æè¿°æ¥ä¸°å¯Œä»è§†è§‰-è¯­è¨€æ¨¡å‹(VLM)ï¼ˆå¦‚CLIPï¼‰å¯¼å‡ºçš„æŸ¥è¯¢åµŒå…¥ã€‚è¿™äº›æè¿°æä¾›é«˜å±‚æ¬¡çš„è¯­ä¹‰æŒ‡å¯¼ï¼Œä½¿æŸ¥è¯¢èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰ç”¨æˆ·çš„æ„å›¾å¹¶æé«˜å…¨å±€æ£€ç´¢è´¨é‡ã€‚åœ¨é«˜æ•ˆæ‰¹é‡æ’åº(EBR)é˜¶æ®µï¼Œå°†æ’åé å‰çš„å€™é€‰å›¾åƒä»¥å¸¦æœ‰è§†è§‰æ ‡è®°çš„å›¾åƒç½‘æ ¼å½¢å¼å‘ˆç°ç»™MLLMï¼ŒMLLMå¯¹æ‰€æœ‰å€™é€‰å›¾åƒæ‰§è¡Œè”åˆè§†è§‰-è¯­ä¹‰æ¨ç†ã€‚æˆ‘ä»¬çš„é‡æ’åºç­–ç•¥åœ¨å•æ¬¡ä¼ é€’ä¸­è¿è¡Œï¼Œå¹¶äº§ç”Ÿæ›´å‡†ç¡®çš„æ’åã€‚å®éªŒè¡¨æ˜ï¼ŒSQUAREä»¥å…¶ç®€å•æ€§å’Œæœ‰æ•ˆæ€§ï¼Œåœ¨å››ä¸ªæ ‡å‡†CIRåŸºå‡†ä¸Šå®ç°äº†å¼ºå¤§çš„æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå³ä½¿ä½¿ç”¨è½»é‡çº§é¢„è®­ç»ƒæ¨¡å‹ï¼Œå®ƒä¹Ÿèƒ½ä¿æŒé«˜æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æ½œåœ¨çš„é€‚ç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç»„åˆå›¾åƒæ£€ç´¢(CIR)æ—¨åœ¨æ ¹æ®ç»™å®šçš„å‚è€ƒå›¾åƒå’Œæ–‡æœ¬æè¿°ï¼Œæ£€ç´¢å‡ºæ—¢åŒ…å«å‚è€ƒå›¾åƒçš„è§†è§‰å†…å®¹ï¼Œåˆç¬¦åˆæ–‡æœ¬æè¿°ä¿®æ”¹çš„ç›®æ ‡å›¾åƒã€‚ç°æœ‰çš„å…è®­ç»ƒé›¶æ ·æœ¬CIRæ–¹æ³•ï¼Œè™½ç„¶ä¸éœ€è¦ç‰¹å®šä»»åŠ¡çš„è®­ç»ƒæ•°æ®ï¼Œä½†éš¾ä»¥å‡†ç¡®æ•æ‰ç”¨æˆ·çš„æ„å›¾ï¼Œå¯¼è‡´æ£€ç´¢æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSQUAREçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)çš„å¼ºå¤§è¯­ä¹‰ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œæ¥å¢å¼ºæŸ¥è¯¢çš„è¡¨è¾¾èƒ½åŠ›ï¼Œå¹¶å¯¹æ£€ç´¢ç»“æœè¿›è¡Œæ›´ç²¾ç¡®çš„é‡æ’åºã€‚é€šè¿‡MLLMç”Ÿæˆç›®æ ‡å›¾åƒçš„è¯­ä¹‰æè¿°ï¼Œå¯ä»¥å¼¥è¡¥è§†è§‰-è¯­è¨€æ¨¡å‹(VLM)åœ¨ç†è§£å¤æ‚æ–‡æœ¬ä¿®æ”¹æ„å›¾æ–¹é¢çš„ä¸è¶³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSQUAREæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šè¯­ä¹‰æŸ¥è¯¢å¢å¼ºèåˆ(SQAF)å’Œé«˜æ•ˆæ‰¹é‡æ’åº(EBR)ã€‚åœ¨SQAFé˜¶æ®µï¼Œé¦–å…ˆä½¿ç”¨VLMï¼ˆå¦‚CLIPï¼‰æå–å‚è€ƒå›¾åƒå’Œæ–‡æœ¬æè¿°çš„ç‰¹å¾ï¼Œç„¶ååˆ©ç”¨MLLMç”Ÿæˆç›®æ ‡å›¾åƒçš„æè¿°ï¼Œå¹¶å°†è¿™äº›æè¿°èå…¥åˆ°æŸ¥è¯¢åµŒå…¥ä¸­ã€‚åœ¨EBRé˜¶æ®µï¼Œå°†SQAFé˜¶æ®µæ£€ç´¢å‡ºçš„Top-Kä¸ªå€™é€‰å›¾åƒä»¥å›¾åƒç½‘æ ¼çš„å½¢å¼è¾“å…¥åˆ°MLLMä¸­ï¼ŒMLLMå¯¹è¿™äº›å€™é€‰å›¾åƒè¿›è¡Œè”åˆè§†è§‰-è¯­ä¹‰æ¨ç†ï¼Œå¹¶æ ¹æ®æ¨ç†ç»“æœé‡æ–°æ’åºã€‚

**å…³é”®åˆ›æ–°**ï¼šSQUAREçš„å…³é”®åˆ›æ–°åœ¨äºåˆ©ç”¨MLLMæ¥å¢å¼ºæŸ¥è¯¢çš„è¯­ä¹‰è¡¨è¾¾èƒ½åŠ›ï¼Œå¹¶è¿›è¡Œé«˜æ•ˆçš„æ‰¹é‡æ’åºã€‚ä¼ ç»Ÿçš„VLMåœ¨å¤„ç†å¤æ‚çš„æ–‡æœ¬ä¿®æ”¹æ„å›¾æ—¶å­˜åœ¨å±€é™æ€§ï¼Œè€ŒMLLMå¯ä»¥æä¾›æ›´ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ï¼Œä»è€Œæé«˜æ£€ç´¢çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒEBRé˜¶æ®µçš„è”åˆè§†è§‰-è¯­ä¹‰æ¨ç†å¯ä»¥æ›´å¥½åœ°æ•æ‰å€™é€‰å›¾åƒä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œäº§ç”Ÿæ›´å‡†ç¡®çš„æ’åã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨SQAFé˜¶æ®µï¼ŒMLLMç”Ÿæˆçš„æè¿°è¢«ç”¨æ¥å¢å¼ºVLMæå–çš„æŸ¥è¯¢åµŒå…¥ã€‚å…·ä½“æ¥è¯´ï¼Œå¯ä»¥å°†MLLMç”Ÿæˆçš„æè¿°è½¬æ¢ä¸ºæ–‡æœ¬åµŒå…¥ï¼Œç„¶åä¸VLMæå–çš„å›¾åƒå’Œæ–‡æœ¬åµŒå…¥è¿›è¡Œèåˆã€‚èåˆçš„æ–¹å¼å¯ä»¥æ˜¯ç®€å•çš„æ‹¼æ¥ï¼Œä¹Ÿå¯ä»¥æ˜¯æ›´å¤æ‚çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚åœ¨EBRé˜¶æ®µï¼Œå›¾åƒç½‘æ ¼çš„å¤§å°å’Œè§†è§‰æ ‡è®°çš„è®¾è®¡ä¼šå½±å“MLLMçš„æ¨ç†æ•ˆæœã€‚æ­¤å¤–ï¼Œå¦‚ä½•è®¾è®¡æŸå¤±å‡½æ•°æ¥æŒ‡å¯¼MLLMè¿›è¡Œé‡æ’åºä¹Ÿæ˜¯ä¸€ä¸ªå…³é”®çš„æŠ€æœ¯ç»†èŠ‚ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„åœ¨è®ºæ–‡ä¸­æœªæ˜ç¡®è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SQUAREæ¡†æ¶åœ¨å››ä¸ªæ ‡å‡†CIRåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­æœªæ˜ç¡®ç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚ä½†è®ºæ–‡å¼ºè°ƒï¼Œå³ä½¿ä½¿ç”¨è½»é‡çº§é¢„è®­ç»ƒæ¨¡å‹ï¼ŒSQUAREä¹Ÿèƒ½ä¿æŒé«˜æ€§èƒ½ï¼Œè¡¨æ˜å…¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œå®ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SQUAREæ¡†æ¶å¯åº”ç”¨äºç”µå•†ã€æœç´¢å¼•æ“ã€å›¾åƒç¼–è¾‘ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨ç”µå•†å¹³å°ä¸Šï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ä¸Šä¼ ä¸€å¼ å‚è€ƒå›¾ç‰‡å¹¶æ·»åŠ æ–‡å­—æè¿°ï¼ˆå¦‚â€œçº¢è‰²è¿è¡£è£™â€ï¼‰æ¥æ£€ç´¢ç›®æ ‡å•†å“ã€‚åœ¨å›¾åƒç¼–è¾‘é¢†åŸŸï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡æŒ‡å®šå‚è€ƒå›¾åƒå’Œä¿®æ”¹æè¿°ï¼ˆå¦‚â€œå»é™¤èƒŒæ™¯â€ï¼‰æ¥ç”Ÿæˆæ–°çš„å›¾åƒã€‚è¯¥ç ”ç©¶çš„æœªæ¥å½±å“åœ¨äºæ¨åŠ¨é›¶æ ·æœ¬ç»„åˆå›¾åƒæ£€ç´¢æŠ€æœ¯çš„å‘å±•ï¼Œé™ä½å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œå¹¶æé«˜æ£€ç´¢çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Composed Image Retrieval (CIR) aims to retrieve target images that preserve the visual content of a reference image while incorporating user-specified textual modifications. Training-free zero-shot CIR (ZS-CIR) approaches, which require no task-specific training or labeled data, are highly desirable, yet accurately capturing user intent remains challenging. In this paper, we present SQUARE, a novel two-stage training-free framework that leverages Multimodal Large Language Models (MLLMs) to enhance ZS-CIR. In the Semantic Query-Augmented Fusion (SQAF) stage, we enrich the query embedding derived from a vision-language model (VLM) such as CLIP with MLLM-generated captions of the target image. These captions provide high-level semantic guidance, enabling the query to better capture the user's intent and improve global retrieval quality. In the Efficient Batch Reranking (EBR) stage, top-ranked candidates are presented as an image grid with visual marks to the MLLM, which performs joint visual-semantic reasoning across all candidates. Our reranking strategy operates in a single pass and yields more accurate rankings. Experiments show that SQUARE, with its simplicity and effectiveness, delivers strong performance on four standard CIR benchmarks. Notably, it maintains high performance even with lightweight pre-trained, demonstrating its potential applicability.

