---
layout: default
title: A Multimodal LLM Approach for Visual Question Answering on Multiparametric 3D Brain MRI
---

# A Multimodal LLM Approach for Visual Question Answering on Multiparametric 3D Brain MRI

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25889" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25889v2</a>
  <a href="https://arxiv.org/pdf/2509.25889.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25889v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25889v2', 'A Multimodal LLM Approach for Visual Question Answering on Multiparametric 3D Brain MRI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Arvind Murari Vepa, Yannan Yu, Jingru Gan, Anthony Cuturrufo, Weikai Li, Wei Wang, Fabien Scalzo, Yizhou Sun

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30 (æ›´æ–°: 2025-10-01)

**å¤‡æ³¨**: 23 pages, 3 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºmpLLMï¼Œç”¨äºå¤šå‚æ•°3Dè„‘éƒ¨MRIçš„è§†è§‰é—®ç­”ï¼Œæå‡åŒ»å­¦è¯Šæ–­æ•ˆç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `è§†è§‰é—®ç­”` `åŒ»å­¦å½±åƒ` `3D MRI` `æ··åˆä¸“å®¶æ¨¡å‹` `æ·±åº¦å­¦ä¹ ` `åŒ»å­¦è¯Šæ–­`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŒ»å­¦VQAæ–¹æ³•ç¼ºä¹å¯¹å¤šæ¨¡æ€3D MRIæ•°æ®çš„æœ‰æ•ˆå¤„ç†ï¼Œé™åˆ¶äº†è¯Šæ–­çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚
2. mpLLMé€šè¿‡åˆ†å±‚æ··åˆä¸“å®¶æ¶æ„ï¼Œèåˆæ¨¡æ€çº§å’Œtokençº§ä¿¡æ¯ï¼Œå®ç°å¯¹å¤šæ¨¡æ€3D MRIæ•°æ®çš„æœ‰æ•ˆç†è§£ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒmpLLMåœ¨å¤šä¸ªmpMRIæ•°æ®é›†ä¸Šä¼˜äºç°æœ‰åŒ»å­¦VLMåŸºçº¿ï¼Œå¹³å‡æå‡5.3%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºmpLLMçš„æç¤ºæ¡ä»¶åˆ†å±‚æ··åˆä¸“å®¶(MoE)æ¶æ„ï¼Œç”¨äºå¤šå‚æ•°3Dè„‘éƒ¨MRI(mpMRI)çš„è§†è§‰é—®ç­”ã€‚mpLLMé€šè¿‡æ¨¡æ€çº§å’Œtokençº§æŠ•å½±ä¸“å®¶è¿›è¡Œè·¯ç”±ï¼Œèåˆå¤šä¸ªç›¸äº’å…³è”çš„3Dæ¨¡æ€ï¼Œä»è€Œå®ç°é«˜æ•ˆè®­ç»ƒï¼Œæ— éœ€å›¾åƒ-æŠ¥å‘Šé¢„è®­ç»ƒã€‚ä¸ºäº†è§£å†³æœ‰é™çš„å›¾åƒ-æ–‡æœ¬é…å¯¹ç›‘ç£é—®é¢˜ï¼ŒmpLLMé›†æˆäº†ä¸€ç§åˆæˆè§†è§‰é—®ç­”(VQA)åè®®ï¼Œè¯¥åè®®ä»åˆ†å‰²æ³¨é‡Šç”ŸæˆåŒ»å­¦ç›¸å…³çš„VQAï¼Œå¹¶ä¸åŒ»å­¦ä¸“å®¶åˆä½œè¿›è¡Œä¸´åºŠéªŒè¯ã€‚åœ¨å¤šä¸ªmpMRIæ•°æ®é›†ä¸Šï¼ŒmpLLMçš„æ€§èƒ½å¹³å‡è¶…è¿‡äº†å¼ºå¤§çš„åŒ»å­¦VLMåŸºçº¿5.3%ã€‚æœ¬ç ”ç©¶çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼š(1)é¦–ä¸ªç»è¿‡ä¸´åºŠéªŒè¯çš„3Dè„‘éƒ¨mpMRIçš„VQAæ•°æ®é›†ï¼Œ(2)ä¸€ç§å¤„ç†å¤šä¸ªç›¸äº’å…³è”çš„3Dæ¨¡æ€çš„æ–°å‹å¤šæ¨¡æ€LLMï¼Œä»¥åŠ(3)å¼ºå¤§çš„å®éªŒç»“æœï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„åŒ»å­¦å®ç”¨æ€§ã€‚æ¶ˆèå®éªŒçªå‡ºäº†æ¨¡æ€çº§å’Œtokençº§ä¸“å®¶ä»¥åŠæç¤ºæ¡ä»¶è·¯ç”±çš„é‡è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šå‚æ•°3Dè„‘éƒ¨MRIï¼ˆmpMRIï¼‰çš„è§†è§‰é—®ç­”ï¼ˆVQAï¼‰é—®é¢˜ã€‚ç°æœ‰çš„åŒ»å­¦VQAæ–¹æ³•é€šå¸¸éš¾ä»¥æœ‰æ•ˆå¤„ç†å¤šæ¨¡æ€3D MRIæ•°æ®ï¼Œå¹¶ä¸”ç¼ºä¹è¶³å¤Ÿçš„å›¾åƒ-æ–‡æœ¬é…å¯¹ç›‘ç£ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½å—é™ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å¯èƒ½æ— æ³•å……åˆ†åˆ©ç”¨ä¸åŒæ¨¡æ€ä¹‹é—´çš„å…³è”æ€§ï¼Œä»è€Œå½±å“è¯Šæ–­çš„å‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸€ä¸ªæç¤ºæ¡ä»¶åˆ†å±‚æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¶æ„ï¼Œå³mpLLMï¼Œæ¥èåˆå¤šä¸ªç›¸äº’å…³è”çš„3Dæ¨¡æ€ã€‚é€šè¿‡æ¨¡æ€çº§å’Œtokençº§æŠ•å½±ä¸“å®¶è¿›è¡Œè·¯ç”±ï¼ŒmpLLMèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å­¦ä¹ ä¸åŒæ¨¡æ€ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶åˆ©ç”¨åˆæˆVQAæ•°æ®æ¥å¼¥è¡¥æœ‰é™çš„å›¾åƒ-æ–‡æœ¬é…å¯¹ç›‘ç£ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šmpLLMçš„æ•´ä½“æ¶æ„æ˜¯ä¸€ä¸ªåˆ†å±‚MoEæ¨¡å‹ï¼ŒåŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) å¤šæ¨¡æ€3D MRIè¾“å…¥ï¼›2) æ¨¡æ€çº§ä¸“å®¶ï¼Œç”¨äºå¤„ç†ä¸åŒæ¨¡æ€çš„ç‰¹å¾ï¼›3) tokençº§ä¸“å®¶ï¼Œç”¨äºèåˆä¸åŒæ¨¡æ€çš„tokenä¿¡æ¯ï¼›4) æç¤ºæ¡ä»¶è·¯ç”±æœºåˆ¶ï¼Œæ ¹æ®é—®é¢˜æç¤ºåŠ¨æ€é€‰æ‹©ä¸“å®¶ï¼›5) VQAé¢„æµ‹æ¨¡å—ï¼Œç”Ÿæˆç­”æ¡ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹å¤šæ¨¡æ€3D MRIæ•°æ®çš„åˆ†å±‚MoEæ¶æ„ï¼Œèƒ½å¤Ÿæœ‰æ•ˆèåˆä¸åŒæ¨¡æ€çš„ä¿¡æ¯ï¼›2) å¼•å…¥äº†åˆæˆVQAåè®®ï¼Œåˆ©ç”¨åˆ†å‰²æ³¨é‡Šç”ŸæˆåŒ»å­¦ç›¸å…³çš„VQAæ•°æ®ï¼Œç¼“è§£äº†æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼›3) æå‡ºäº†æç¤ºæ¡ä»¶è·¯ç”±æœºåˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®é—®é¢˜åŠ¨æ€é€‰æ‹©ä¸“å®¶ï¼Œæé«˜æ¨¡å‹çš„é€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šmpLLMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨3Då·ç§¯ç¥ç»ç½‘ç»œæå–MRIå›¾åƒç‰¹å¾ï¼›2) è®¾è®¡äº†æ¨¡æ€çº§å’Œtokençº§ä¸“å®¶ç½‘ç»œï¼Œç”¨äºå¤„ç†ä¸åŒæ¨¡æ€å’Œtokençš„ä¿¡æ¯ï¼›3) é‡‡ç”¨äº†äº¤å‰ç†µæŸå¤±å‡½æ•°è¿›è¡ŒVQAä»»åŠ¡çš„è®­ç»ƒï¼›4) ä½¿ç”¨äº†ä¸´åºŠä¸“å®¶è¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿æ¨¡å‹çš„åŒ»å­¦å®ç”¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

mpLLMåœ¨å¤šä¸ªmpMRIæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå¹³å‡è¶…è¿‡äº†å¼ºå¤§çš„åŒ»å­¦VLMåŸºçº¿5.3%ã€‚æ¶ˆèå®éªŒè¡¨æ˜ï¼Œæ¨¡æ€çº§å’Œtokençº§ä¸“å®¶ä»¥åŠæç¤ºæ¡ä»¶è·¯ç”±å¯¹æ¨¡å‹æ€§èƒ½è‡³å…³é‡è¦ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ„å»ºäº†é¦–ä¸ªç»è¿‡ä¸´åºŠéªŒè¯çš„3Dè„‘éƒ¨mpMRIçš„VQAæ•°æ®é›†ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†å®è´µèµ„æºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåŒ»å­¦å½±åƒè¾…åŠ©è¯Šæ–­ï¼Œå¸®åŠ©åŒ»ç”Ÿæ›´å‡†ç¡®ã€é«˜æ•ˆåœ°åˆ†æè„‘éƒ¨MRIå›¾åƒï¼Œä»è€Œæé«˜è¯Šæ–­æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–åŒ»å­¦å½±åƒæ¨¡æ€å’Œç–¾ç—…çš„è¯Šæ–­ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚æœªæ¥ï¼Œç»“åˆæ‚£è€…çš„ä¸´åºŠä¿¡æ¯ï¼Œå¯ä»¥å®ç°æ›´ä¸ªæ€§åŒ–çš„è¯Šæ–­å’Œæ²»ç–—æ–¹æ¡ˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce mpLLM, a prompt-conditioned hierarchical mixture-of-experts (MoE) architecture for visual question answering over multi-parametric 3D brain MRI (mpMRI). mpLLM routes across modality-level and token-level projection experts to fuse multiple interrelated 3D modalities, enabling efficient training without image-report pretraining. To address limited image-text paired supervision, mpLLM integrates a synthetic visual question answering (VQA) protocol that generates medically relevant VQA from segmentation annotations, and we collaborate with medical experts for clinical validation. mpLLM outperforms strong medical VLM baselines by 5.3% on average across multiple mpMRI datasets. Our study features three main contributions: (1) the first clinically validated VQA dataset for 3D brain mpMRI, (2) a novel multimodal LLM that handles multiple interrelated 3D modalities, and (3) strong empirical results that demonstrate the medical utility of our methodology. Ablations highlight the importance of modality-level and token-level experts and prompt-conditioned routing.

