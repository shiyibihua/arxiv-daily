---
layout: default
title: Logo-VGR: Visual Grounded Reasoning for Open-world Logo Recognition
---

# Logo-VGR: Visual Grounded Reasoning for Open-world Logo Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25811" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.25811v1</a>
  <a href="https://arxiv.org/pdf/2509.25811.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25811v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25811v1', 'Logo-VGR: Visual Grounded Reasoning for Open-world Logo Recognition')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zichen Liang, Jingjing Fei, Jie Wang, Zheming Yang, Changqing Li, Pei Wu, Minghui Qiu, Fei Yang, Xialei Liu

**ÂàÜÁ±ª**: cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-30

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Logo-VGRÔºåÈÄöËøáËßÜËßâÂ∏∏ËØÜÊé®ÁêÜÂÆûÁé∞ÂºÄÊîæ‰∏ñÁïåLogoËØÜÂà´**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `LogoËØÜÂà´` `ËßÜËßâÂ∏∏ËØÜÊé®ÁêÜ` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ÂºÄÊîæ‰∏ñÁïå` `‰∫ßÂìÅÂÆ°Ê†∏`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâLogoËØÜÂà´ÊñπÊ≥ï‰æùËµñËÆ∞ÂøÜÂ§ßÈáèÂìÅÁâåË°®Á§∫ÔºåÈöæ‰ª•ÈÄÇÂ∫îÂºÄÊîæ‰∏ñÁïå‰∏≠‰∏çÊñ≠Ê∂åÁé∞ÁöÑÊñ∞ÂìÅÁâå„ÄÇ
2. Logo-VGRÂ∞ÜLogoËØÜÂà´ËΩ¨Âåñ‰∏∫ÊØîËæÉ‰ªªÂä°ÔºåÂπ∂ÂºïÂÖ•LogoÊÑüÁü•Â∏∏ËØÜÂíåÂºïÂØºÁöÑËßÜËßâÊé®ÁêÜÔºåÊèêÂçáÊ≥õÂåñËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåLogo-VGRÂú®Êú™ËßÅËøáÁöÑÂìÅÁâåËØÜÂà´‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåOODÊÄßËÉΩÊèêÂçáËøë10‰∏™ÁÇπ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂºÄÊîæ‰∏ñÁïåLogoËØÜÂà´Âü∫ÂáÜÔºåÊó®Âú®Ëß£ÂÜ≥Êô∫ËÉΩ‰∫ßÂìÅÂÆ°Ê†∏‰∏≠ËØ•È¢ÜÂüüÂ∫îÁî®‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇ‰∏é‰º†ÁªüLogoËØÜÂà´ÊñπÊ≥ï‰æùËµñ‰∫éËÆ∞ÂøÜÊï∞‰∏á‰∏™ÂìÅÁâåË°®Á§∫‰∏çÂêåÔºåÊú¨ÊñáÊèêÂá∫ÁöÑLogo-VGRÊñπÊ≥ïËÉΩÂ§üÊé®ÂπøÂà∞Â§ßËßÑÊ®°ÂìÅÁâåËØÜÂà´Ôºå‰ªÖÈúÄÂ∞ëÈáèÂìÅÁâåÁöÑÁõëÁù£„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÊàë‰ª¨Â∞ÜLogoËØÜÂà´ÈáçÊñ∞ÂÆö‰πâ‰∏∫‰∏ÄÁßçÂü∫‰∫éÊØîËæÉÁöÑ‰ªªÂä°ÔºåË¶ÅÊ±ÇÊ®°ÂûãÂ∞Ü‰∫ßÂìÅÂõæÂÉè‰∏éÂÄôÈÄâLogoËøõË°åÂåπÈÖçÔºåËÄå‰∏çÊòØÁõ¥Êé•ÁîüÊàêÂìÅÁâåÊ†áÁ≠æ„ÄÇÊàë‰ª¨ËøòËßÇÂØüÂà∞ÔºåÁé∞ÊúâÊ®°ÂûãÂÄæÂêë‰∫éÈÄöËøáËÆ∞ÂøÜÂìÅÁâåÂàÜÂ∏ÉÊù•ËøáÂ∫¶ÊãüÂêàÔºåËÄå‰∏çÊòØÂ≠¶‰π†È≤ÅÊ£íÁöÑÂ§öÊ®°ÊÄÅÊé®ÁêÜÔºåËøôÂØºËá¥‰∫ÜÂú®Êú™ËßÅÂìÅÁâå‰∏äÁöÑÊÄßËÉΩ‰∏ç‰Ω≥„ÄÇ‰∏∫‰∫ÜÂÖãÊúçËøô‰∏ÄÈôêÂà∂ÔºåLogo-VGRÂºïÂÖ•‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÈ¢ÜÂüüÁâπÂÆöÂ§öÊ®°ÊÄÅÊé®ÁêÜËåÉÂºèÔºöLogoÊÑüÁü•Â∏∏ËØÜÊ≥®ÂÖ•È¢ÜÂüüÁü•ËØÜÔºåLogoÂºïÂØºÁöÑËßÜËßâÂ∏∏ËØÜÊé®ÁêÜÂ¢ûÂº∫‰∫ÜÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåLogo-VGRÂú®OODËÆæÁΩÆ‰∏≠‰ºò‰∫éÂº∫Â§ßÁöÑÂü∫Á∫øËøë10‰∏™ÁÇπÔºåËØÅÊòé‰∫ÜÂÖ∂ÂçìË∂äÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâLogoËØÜÂà´ÊñπÊ≥ï‰∏ªË¶Å‰æùËµñ‰∫éËÆ∞ÂøÜÂ§ßÈáèÂ∑≤Áü•ÂìÅÁâåÁöÑËßÜËßâÁâπÂæÅÔºåËøôÂú®ÂºÄÊîæ‰∏ñÁïåÂú∫ÊôØ‰∏ãÊòØ‰∏çÂèØË°åÁöÑÔºåÂõ†‰∏∫Êñ∞ÂìÅÁâå‰∏çÊñ≠Ê∂åÁé∞ÔºåÈúÄË¶ÅÊ®°ÂûãÂÖ∑Â§áËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÁé∞ÊúâÊñπÊ≥ïÂÆπÊòìËøáÊãüÂêàÂ∑≤Áü•ÂìÅÁâåÁöÑÂàÜÂ∏ÉÔºåÂØºËá¥Âú®Êñ∞ÂìÅÁâå‰∏äÁöÑËØÜÂà´ÊïàÊûúÂæàÂ∑Æ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜLogoËØÜÂà´ÈóÆÈ¢òËΩ¨Âåñ‰∏∫‰∏Ä‰∏™ÊØîËæÉ‰ªªÂä°ÔºåÂç≥ÁªôÂÆö‰∏ÄÂº†‰∫ßÂìÅÂõæÁâáÂíå‰∏ÄÁªÑÂÄôÈÄâLogoÔºåÊ®°ÂûãÈúÄË¶ÅÂà§Êñ≠Âì™‰∏™Logo‰∏é‰∫ßÂìÅÂõæÁâáÊúÄÂåπÈÖç„ÄÇËøôÁßçÊñπÊ≥ïÈÅøÂÖç‰∫ÜÁõ¥Êé•È¢ÑÊµãÂìÅÁâåÊ†áÁ≠æÔºå‰ªéËÄåÂáèÂ∞ë‰∫ÜÂØπÂ∑≤Áü•ÂìÅÁâåÊï∞ÊçÆÁöÑ‰æùËµñÔºåÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÂêåÊó∂ÔºåÂºïÂÖ•È¢ÜÂüüÁü•ËØÜÂíåËßÜËßâÊé®ÁêÜÊù•Â¢ûÂº∫Ê®°ÂûãÁöÑÂà§Êñ≠ËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöLogo-VGRÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöLogoÊÑüÁü•Â∏∏ËØÜÔºàLogo Perception GroundingÔºâÂíåLogoÂºïÂØºÁöÑËßÜËßâÂ∏∏ËØÜÊé®ÁêÜÔºàLogo-Guided Visual Grounded ReasoningÔºâ„ÄÇLogoÊÑüÁü•Â∏∏ËØÜÊ®°ÂùóË¥üË¥£Ê≥®ÂÖ•È¢ÜÂüüÁü•ËØÜÔºå‰æãÂ¶ÇLogoÁöÑÂ∏∏ËßÅÂΩ¢Áä∂„ÄÅÈ¢úËâ≤Âíå‰ΩçÁΩÆÁ≠â„ÄÇLogoÂºïÂØºÁöÑËßÜËßâÂ∏∏ËØÜÊé®ÁêÜÊ®°ÂùóÂàôÂà©Áî®Ëøô‰∫õÈ¢ÜÂüüÁü•ËØÜÊù•ÊåáÂØºÊ®°ÂûãËøõË°åËßÜËßâÊé®ÁêÜÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÁêÜËß£‰∫ßÂìÅÂõæÁâáÂíåLogo‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÂÖàÊèêÂèñ‰∫ßÂìÅÂõæÂÉèÂíåÂÄôÈÄâLogoÁöÑËßÜËßâÁâπÂæÅÔºåÁÑ∂ÂêéÈÄöËøáLogoÊÑüÁü•Â∏∏ËØÜÊ®°ÂùóÊ≥®ÂÖ•È¢ÜÂüüÁü•ËØÜÔºåÊúÄÂêéÂà©Áî®LogoÂºïÂØºÁöÑËßÜËßâÂ∏∏ËØÜÊé®ÁêÜÊ®°ÂùóËøõË°åÂåπÈÖçÂà§Êñ≠„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂºïÂÖ•‰∫ÜÈ¢ÜÂüüÁâπÂÆöÁöÑÂ§öÊ®°ÊÄÅÊé®ÁêÜËåÉÂºèÔºåÂç≥LogoÊÑüÁü•Â∏∏ËØÜÂíåLogoÂºïÂØºÁöÑËßÜËßâÂ∏∏ËØÜÊé®ÁêÜ„ÄÇËøô‰∏éÁé∞ÊúâÊñπÊ≥ï‰ªÖ‰ªÖ‰æùËµñËßÜËßâÁâπÂæÅÁöÑËÆ∞ÂøÜÂíåÂåπÈÖçÊúâÊú¨Ë¥®Âå∫Âà´„ÄÇÈÄöËøáÊ≥®ÂÖ•È¢ÜÂüüÁü•ËØÜÂíåÂºïÂØºËßÜËßâÊé®ÁêÜÔºåÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£‰∫ßÂìÅÂõæÁâáÂíåLogo‰πãÈó¥ÁöÑËØ≠‰πâÂÖ≥Á≥ªÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöLogoÊÑüÁü•Â∏∏ËØÜÊ®°ÂùóÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÊñπÂºèÊú™Áü•ÔºåÂèØËÉΩ‰ΩøÁî®‰∫ÜÁü•ËØÜÂõæË∞±ÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÊù•Ëé∑ÂèñLogoÁöÑÈ¢ÜÂüüÁü•ËØÜ„ÄÇLogoÂºïÂØºÁöÑËßÜËßâÂ∏∏ËØÜÊé®ÁêÜÊ®°ÂùóÂèØËÉΩÈááÁî®‰∫ÜÊ≥®ÊÑèÂäõÊú∫Âà∂ÊàñÂõæÁ•ûÁªèÁΩëÁªúÁ≠âÊäÄÊúØÔºå‰ª•‰æøÊõ¥Â•ΩÂú∞Âà©Áî®È¢ÜÂüüÁü•ËØÜÊù•ÊåáÂØºËßÜËßâÊé®ÁêÜ„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÂèØËÉΩÂåÖÊã¨ÂØπÊØîÊçüÂ§±Êàñ‰∫§ÂèâÁÜµÊçüÂ§±ÔºåÁî®‰∫éËÆ≠ÁªÉÊ®°ÂûãËøõË°åÂåπÈÖçÂà§Êñ≠„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠ÂèØËÉΩÊ≤°ÊúâËØ¶ÁªÜÊèèËø∞ÔºåÈúÄË¶ÅËøõ‰∏ÄÊ≠•Á†îÁ©∂„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Logo-VGRÂú®ÂºÄÊîæ‰∏ñÁïåLogoËØÜÂà´‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂ∞§ÂÖ∂ÊòØÂú®OODÔºàOut-of-DistributionÔºâËÆæÁΩÆ‰∏ãÔºåÁõ∏ËæÉ‰∫éÁé∞ÊúâÂü∫Á∫øÊñπÊ≥ïÔºåÊÄßËÉΩÊèêÂçá‰∫ÜËøë10‰∏™ÁôæÂàÜÁÇπ„ÄÇËøôË°®ÊòéLogo-VGRÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÊ≥õÂåñËÉΩÂäõÔºåËÉΩÂ§üÊúâÊïàËØÜÂà´Êú™ËßÅËøáÁöÑÂìÅÁâåLogo„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊåáÊ†áÂíåÂØπÊØîÂü∫Á∫øÈúÄË¶ÅÂú®ËÆ∫Êñá‰∏≠Êü•Êâæ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩ‰∫ßÂìÅÂÆ°Ê†∏„ÄÅÁîµÂïÜÂπ≥Âè∞ÂïÜÂìÅËØÜÂà´„ÄÅÂìÅÁâåÁõëÊµãÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáËá™Âä®ËØÜÂà´‰∫ßÂìÅÂõæÁâá‰∏≠ÁöÑLogoÔºåÂèØ‰ª•Âø´ÈÄüÂà§Êñ≠ÂïÜÂìÅÁúü‰º™„ÄÅËøõË°åÂìÅÁâåÊ∫ØÊ∫êÔºåÂπ∂ÊúâÊïàËøáÊª§ËøùËßÑÂïÜÂìÅÔºåÊèêÂçáÂπ≥Âè∞ÁÆ°ÁêÜÊïàÁéáÂíåÁî®Êà∑‰ΩìÈ™å„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØËøòÂèØÊâ©Â±ïÂà∞ÂÖ∂‰ªñÈ¢ÜÂüüÔºåÂ¶ÇÂïÜÊ†á‰æµÊùÉÊ£ÄÊµã„ÄÅÂπøÂëäÂÜÖÂÆπÂÆ°Ê†∏Á≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent advances in multimodal large language models (MLLMs) have been primarily evaluated on general-purpose benchmarks, while their applications in domain-specific scenarios, such as intelligent product moderation, remain underexplored. To address this gap, we introduce an open-world logo recognition benchmark, a core challenge in product moderation. Unlike traditional logo recognition methods that rely on memorizing representations of tens of thousands of brands-an impractical approach in real-world settings-our proposed method, Logo-VGR, enables generalization to large-scale brand recognition with supervision from only a small subset of brands. Specifically, we reformulate logo recognition as a comparison-based task, requiring the model to match product images with candidate logos rather than directly generating brand labels. We further observe that existing models tend to overfit by memorizing brand distributions instead of learning robust multimodal reasoning, which results in poor performance on unseen brands. To overcome this limitation, Logo-VGR introduces a new paradigm of domain-specific multimodal reasoning: Logo Perception Grounding injects domain knowledge, and Logo-Guided Visual Grounded Reasoning enhances the model's reasoning capability. Experimental results show that Logo-VGR outperforms strong baselines by nearly 10 points in OOD settings, demonstrating superior generalization.

