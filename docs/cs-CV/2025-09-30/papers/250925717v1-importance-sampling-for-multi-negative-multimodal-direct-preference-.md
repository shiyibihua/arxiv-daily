---
layout: default
title: Importance Sampling for Multi-Negative Multimodal Direct Preference Optimization
---

# Importance Sampling for Multi-Negative Multimodal Direct Preference Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25717" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25717v1</a>
  <a href="https://arxiv.org/pdf/2509.25717.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25717v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25717v1', 'Importance Sampling for Multi-Negative Multimodal Direct Preference Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xintong Li, Chuhan Wang, Junda Wu, Rohan Surana, Tong Yu, Julian McAuley, Jingbo Shang

**åˆ†ç±»**: cs.CV, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMISP-DPOæ¡†æ¶ä»¥è§£å†³å¤šæ¨¡æ€åå¥½ä¼˜åŒ–ä¸­çš„è´Ÿæ ·æœ¬é€‰æ‹©é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `ç›´æ¥åå¥½ä¼˜åŒ–` `è´Ÿæ ·æœ¬é€‰æ‹©` `Plackett-Luceæ¨¡å‹` `é‡è¦æ€§é‡‡æ ·` `CLIP` `è¯­ä¹‰åå·®` `ç¨€ç–è‡ªç¼–ç å™¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç›´æ¥åå¥½ä¼˜åŒ–æ–¹æ³•è¿‡äºä¾èµ–ç®€åŒ–çš„æˆå¯¹æ¯”è¾ƒï¼Œå¯¼è‡´ç”Ÿæˆçš„è´Ÿæ ·æœ¬æ— æ³•æœ‰æ•ˆæ•æ‰å¤šæ¨¡æ€åå¥½çš„å¤æ‚æ€§ã€‚
2. æœ¬æ–‡æå‡ºMISP-DPOæ¡†æ¶ï¼Œé€šè¿‡Plackett-Luceæ¨¡å‹å¼•å…¥å¤šä¸ªè¯­ä¹‰å¤šæ ·çš„è´Ÿæ ·æœ¬ï¼Œåˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨å’Œé‡è¦æ€§é‡‡æ ·ç­–ç•¥æå‡è®­ç»ƒæ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMISP-DPOåœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶åœ¨å¤šæ¨¡æ€å¯¹é½ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰æœ€è¿‘å·²ä»æ–‡æœ¬æ¨¡å‹æ‰©å±•åˆ°è§†è§‰è¯­è¨€æ¨¡å‹ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¾èµ–äºè¿‡äºç®€åŒ–çš„æˆå¯¹æ¯”è¾ƒï¼Œä»…ç”Ÿæˆå•ä¸€è´Ÿæ ·æœ¬ï¼Œæœªèƒ½æ•æ‰å¤šæ¨¡æ€åå¥½çš„å¤æ‚æ€§ï¼Œå¯¼è‡´ä¼˜åŒ–åå·®å’Œå¹»è§‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†MISP-DPOæ¡†æ¶ï¼Œé¦–æ¬¡é€šè¿‡Plackett-Luceæ¨¡å‹åœ¨å¤šæ¨¡æ€DPOä¸­å¼•å…¥å¤šä¸ªè¯­ä¹‰å¤šæ ·çš„è´Ÿæ ·æœ¬ã€‚è¯¥æ–¹æ³•åœ¨CLIPç©ºé—´ä¸­åµŒå…¥æç¤ºå’Œå€™é€‰å›¾åƒï¼Œå¹¶åº”ç”¨ç¨€ç–è‡ªç¼–ç å™¨æ­ç¤ºè¯­ä¹‰åå·®ã€‚è´Ÿæ ·æœ¬çš„é€‰æ‹©åŸºäºé‡æ„éš¾åº¦ã€ä¸æ­£æ ·æœ¬çš„è¯­ä¹‰åå·®å’Œç›¸äº’å¤šæ ·æ€§ï¼Œä»è€Œæä¾›æ›´å¹¿æ³›å’Œæ›´å…·ä¿¡æ¯é‡çš„ç›‘ç£ã€‚é€šè¿‡å¼•å…¥é‡è¦æ€§é‡‡æ ·ç­–ç•¥ï¼ŒMISP-DPOæ˜¾è‘—æé«˜äº†è®­ç»ƒæ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨äº”ä¸ªä¸åŒåŸºå‡†ä¸ŠæŒç»­æ”¹å–„äº†å¤šæ¨¡æ€å¯¹é½ï¼ŒéªŒè¯äº†è¯­ä¹‰æ„ŸçŸ¥çš„å¤šè´Ÿæ ·æœ¬é‡‡æ ·åœ¨åå¥½å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€ç›´æ¥åå¥½ä¼˜åŒ–æ–¹æ³•ä¸­è´Ÿæ ·æœ¬é€‰æ‹©çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•ä»…ä¾èµ–å•ä¸€è´Ÿæ ·æœ¬ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰å¤æ‚çš„å¤šæ¨¡æ€åå¥½ï¼Œå¯¼è‡´ä¼˜åŒ–åå·®å’Œå¹»è§‰ç°è±¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMISP-DPOæ¡†æ¶é€šè¿‡å¼•å…¥å¤šä¸ªè¯­ä¹‰å¤šæ ·çš„è´Ÿæ ·æœ¬ï¼Œåˆ©ç”¨Plackett-Luceæ¨¡å‹è¿›è¡Œå¤šè´Ÿæ ·æœ¬æ¯”è¾ƒï¼Œä»è€Œå¢å¼ºæ¨¡å‹å¯¹å¤šæ¨¡æ€åå¥½çš„ç†è§£å’Œä¼˜åŒ–ã€‚è¯¥è®¾è®¡æ—¨åœ¨é€šè¿‡ä¸°å¯Œçš„è´Ÿæ ·æœ¬ä¿¡æ¯æ¥æ”¹å–„è®­ç»ƒæ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•é¦–å…ˆåœ¨CLIPç©ºé—´ä¸­åµŒå…¥æç¤ºå’Œå€™é€‰å›¾åƒï¼Œç„¶ååº”ç”¨ç¨€ç–è‡ªç¼–ç å™¨æ¥æ­ç¤ºè¯­ä¹‰åå·®ï¼Œæœ€åé€šè¿‡é‡æ„éš¾åº¦ã€è¯­ä¹‰åå·®å’Œå¤šæ ·æ€§é€‰æ‹©è´Ÿæ ·æœ¬ï¼Œå¹¶é‡‡ç”¨Plackett-Luceç›®æ ‡å’Œé‡è¦æ€§é‡‡æ ·ç­–ç•¥è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šMISP-DPOçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºé¦–æ¬¡å°†å¤šä¸ªè¯­ä¹‰å¤šæ ·çš„è´Ÿæ ·æœ¬å¼•å…¥å¤šæ¨¡æ€DPOï¼Œé€šè¿‡Plackett-Luceæ¨¡å‹å’Œé‡è¦æ€§é‡‡æ ·ç­–ç•¥æ˜¾è‘—æå‡äº†è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMISP-DPOèƒ½å¤Ÿæ›´å…¨é¢åœ°æ•æ‰å¤šæ¨¡æ€åå¥½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è´Ÿæ ·æœ¬é€‰æ‹©ä¸­ï¼Œé‡æ„éš¾åº¦ã€ä¸æ­£æ ·æœ¬çš„è¯­ä¹‰åå·®å’Œç›¸äº’å¤šæ ·æ€§æ˜¯å…³é”®å‚æ•°ã€‚æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡‡ç”¨Plackett-Luceç›®æ ‡æ¥å¤„ç†å¤šè´Ÿæ ·æœ¬æ¯”è¾ƒï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ å¤šæ¨¡æ€åå¥½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨äº”ä¸ªä¸åŒçš„åŸºå‡†æµ‹è¯•ä¸­ï¼ŒMISP-DPOç›¸è¾ƒäºç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€å¯¹é½ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®è¡¨æ˜ï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡æé«˜äº†çº¦15%ï¼ŒéªŒè¯äº†è¯­ä¹‰æ„ŸçŸ¥çš„å¤šè´Ÿæ ·æœ¬é‡‡æ ·åœ¨åå¥½å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šæ¨¡æ€æ¨èç³»ç»Ÿã€å›¾åƒä¸æ–‡æœ¬çš„è”åˆç†è§£ã€ä»¥åŠäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€åå¥½å­¦ä¹ çš„æ•ˆæœï¼ŒMISP-DPOèƒ½å¤Ÿä¸ºæ™ºèƒ½æ¨èå’Œå†…å®¹ç”Ÿæˆç­‰é¢†åŸŸæä¾›æ›´ç²¾å‡†çš„ç”¨æˆ·ä½“éªŒï¼Œæœªæ¥å¯èƒ½åœ¨å•†ä¸šå’Œå­¦æœ¯ç ”ç©¶ä¸­äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Direct Preference Optimization (DPO) has recently been extended from text-only models to vision-language models. However, existing methods rely on oversimplified pairwise comparisons, generating a single negative image via basic perturbations or similarity-based retrieval, which fail to capture the complex nature of multimodal preferences, inducing optimization bias and hallucinations. To address this issue, we propose MISP-DPO, the first framework to incorporate multiple, semantically diverse negative images in multimodal DPO via the Plackett-Luce model. Our method embeds prompts and candidate images in CLIP (Contrastive Language-Image Pretraining) space and applies a sparse autoencoder to uncover semantic deviations into interpretable factors. Negative samples are selected based on reconstruction difficulty, semantic deviation from the positive, and mutual diversity, yielding broader and more informative supervision. To handle multi-negative comparisons, we adopt a Plackett-Luce objective and introduce an importance sampling strategy that improves training efficiency. Experiments across five diverse benchmarks demonstrate that MISP-DPO consistently improves multimodal alignment over prior methods, validating the effectiveness of semantic-aware, multi-negative sampling in preference-based learning.

