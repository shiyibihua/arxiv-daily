---
layout: default
title: PFDepth: Heterogeneous Pinhole-Fisheye Joint Depth Estimation via Distortion-aware Gaussian-Splatted Volumetric Fusion
---

# PFDepth: Heterogeneous Pinhole-Fisheye Joint Depth Estimation via Distortion-aware Gaussian-Splatted Volumetric Fusion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26008" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26008v1</a>
  <a href="https://arxiv.org/pdf/2509.26008.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26008v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26008v1', 'PFDepth: Heterogeneous Pinhole-Fisheye Joint Depth Estimation via Distortion-aware Gaussian-Splatted Volumetric Fusion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhiwei Zhang, Ruikai Xu, Weijian Zhang, Zhizhong Zhang, Xin Tan, Jingyu Gong, Yuan Xie, Lizhuang Ma

**åˆ†ç±»**: cs.CV, cs.AI, cs.CG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: Accepted by ACM MM 2025 Conference

**DOI**: [10.1145/3746027.3755159](https://doi.org/10.1145/3746027.3755159)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PFDepthï¼šæå‡ºä¸€ç§åŸºäºç•¸å˜æ„ŸçŸ¥é«˜æ–¯æº…å°„ä½“ç´ èåˆçš„å¼‚æ„é’ˆå­”-é±¼çœ¼è”åˆæ·±åº¦ä¼°è®¡æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `æ·±åº¦ä¼°è®¡` `å¤šè§†è§’å‡ ä½•` `é’ˆå­”ç›¸æœº` `é±¼çœ¼ç›¸æœº` `å¼‚æ„ä¼ æ„Ÿå™¨èåˆ` `ä¸‰ç»´é‡å»º` `é«˜æ–¯æº…å°„`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ·±åº¦ä¼°è®¡æ–¹æ³•éš¾ä»¥æœ‰æ•ˆèåˆé’ˆå­”ç›¸æœºå’Œå°è§†åœºé±¼çœ¼ç›¸æœºçš„äº’è¡¥ä¿¡æ¯ï¼Œå¯¼è‡´æ·±åº¦ä¼°è®¡ç²¾åº¦å—é™ã€‚
2. PFDepthé€šè¿‡æ˜¾å¼åœ°å°†å¼‚æ„è§†è§’çš„2Dç‰¹å¾æå‡åˆ°3Dä½“ç´ ç©ºé—´ï¼Œå¹¶è®¾è®¡å¼‚æ„ç©ºé—´èåˆæ¨¡å—ï¼Œå®ç°è·¨è§†è§’ç‰¹å¾çš„æœ‰æ•ˆèåˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒPFDepthåœ¨KITTI-360å’ŒRealHetæ•°æ®é›†ä¸Šä¼˜äºä¸»æµæ·±åº¦ç½‘ç»œï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºå¼‚æ„å¤šè§†è§’æ·±åº¦ä¼°è®¡çš„é’ˆå­”-é±¼çœ¼æ¡†æ¶PFDepthã€‚æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨é’ˆå­”å’Œé±¼çœ¼å›¾åƒçš„äº’è¡¥ç‰¹æ€§ï¼ˆæ— ç•¸å˜vs.æœ‰ç•¸å˜ï¼Œå°vs.å¤§è§†åœºï¼Œè¿œåœºvs.è¿‘åœºï¼‰è¿›è¡Œè”åˆä¼˜åŒ–ã€‚PFDepthé‡‡ç”¨ç»Ÿä¸€çš„æ¶æ„ï¼Œèƒ½å¤Ÿå¤„ç†ä»»æ„ç»„åˆçš„å…·æœ‰ä¸åŒå†…å¤–å‚æ•°çš„é’ˆå­”å’Œé±¼çœ¼ç›¸æœºã€‚åœ¨PFDepthä¸­ï¼Œé¦–å…ˆå°†æ¥è‡ªæ¯ä¸ªå¼‚æ„è§†è§’çš„2Dç‰¹å¾æ˜¾å¼åœ°æå‡åˆ°è§„èŒƒçš„3Dä½“ç´ ç©ºé—´ä¸­ã€‚ç„¶åï¼Œè®¾è®¡äº†ä¸€ä¸ªåä¸ºå¼‚æ„ç©ºé—´èåˆçš„æ ¸å¿ƒæ¨¡å—æ¥å¤„ç†å’Œèåˆè·¨é‡å å’Œéé‡å åŒºåŸŸçš„ç•¸å˜æ„ŸçŸ¥ä½“ç´ ç‰¹å¾ã€‚æ­¤å¤–ï¼Œå·§å¦™åœ°å°†ä¼ ç»Ÿçš„ä½“ç´ èåˆé‡æ–°è¡¨è¿°ä¸ºä¸€ç§æ–°çš„3Dé«˜æ–¯è¡¨ç¤ºï¼Œå…¶ä¸­å¯å­¦ä¹ çš„æ½œåœ¨é«˜æ–¯çƒåŠ¨æ€åœ°é€‚åº”å±€éƒ¨å›¾åƒçº¹ç†ï¼Œä»¥å®ç°æ›´ç²¾ç»†çš„3Dèšåˆã€‚æœ€åï¼Œå°†èåˆçš„ä½“ç´ ç‰¹å¾æ¸²æŸ“æˆå¤šè§†è§’æ·±åº¦å›¾ã€‚é€šè¿‡å¤§é‡çš„å®éªŒï¼Œè¯æ˜PFDepthåœ¨KITTI-360å’ŒRealHetæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¼˜äºå½“å‰ä¸»æµçš„æ·±åº¦ç½‘ç»œã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯å¯¹å¼‚æ„é’ˆå­”-é±¼çœ¼æ·±åº¦ä¼°è®¡çš„é¦–æ¬¡ç³»ç»Ÿç ”ç©¶ï¼Œæä¾›äº†æŠ€æœ¯åˆ›æ–°å’Œæœ‰ä»·å€¼çš„ç»éªŒè§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¼‚æ„å¤šè§†è§’æ·±åº¦ä¼°è®¡é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•æœ‰æ•ˆåœ°èåˆé’ˆå­”ç›¸æœºå’Œé±¼çœ¼ç›¸æœºçš„æ•°æ®ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥å¤„ç†é±¼çœ¼ç›¸æœºçš„ç•¸å˜ï¼Œæˆ–è€…æ— æ³•å……åˆ†åˆ©ç”¨ä¸¤ç§ç›¸æœºè§†åœºå¤§å°å’Œæ™¯æ·±èŒƒå›´çš„äº’è¡¥ä¼˜åŠ¿ï¼Œå¯¼è‡´æ·±åº¦ä¼°è®¡ç²¾åº¦ä¸é«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é’ˆå­”ç›¸æœºå’Œé±¼çœ¼ç›¸æœºçš„äº’è¡¥ç‰¹æ€§è¿›è¡Œè”åˆä¼˜åŒ–ã€‚å…·ä½“æ¥è¯´ï¼Œé’ˆå­”ç›¸æœºå›¾åƒæ— ç•¸å˜ï¼Œé€‚åˆè¿œè·ç¦»æ·±åº¦ä¼°è®¡ï¼›é±¼çœ¼ç›¸æœºè§†åœºå¤§ï¼Œé€‚åˆè¿‘è·ç¦»æ·±åº¦ä¼°è®¡ã€‚é€šè¿‡å°†ä¸¤ç§ç›¸æœºçš„æ•°æ®èåˆï¼Œå¯ä»¥æé«˜æ·±åº¦ä¼°è®¡çš„ç²¾åº¦å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPFDepthçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ç‰¹å¾æå–ï¼šä»æ¯ä¸ªè§†è§’çš„å›¾åƒä¸­æå–2Dç‰¹å¾ã€‚2) ç©ºé—´æå‡ï¼šå°†2Dç‰¹å¾æå‡åˆ°3Dä½“ç´ ç©ºé—´ã€‚3) å¼‚æ„ç©ºé—´èåˆï¼šèåˆæ¥è‡ªä¸åŒè§†è§’çš„ä½“ç´ ç‰¹å¾ã€‚4) æ·±åº¦æ¸²æŸ“ï¼šå°†èåˆåçš„ä½“ç´ ç‰¹å¾æ¸²æŸ“æˆå¤šè§†è§’æ·±åº¦å›¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†å¼‚æ„ç©ºé—´èåˆæ¨¡å—å’ŒåŸºäºé«˜æ–¯æº…å°„çš„ä½“ç´ è¡¨ç¤ºã€‚å¼‚æ„ç©ºé—´èåˆæ¨¡å—èƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†å’Œèåˆæ¥è‡ªé’ˆå­”ç›¸æœºå’Œé±¼çœ¼ç›¸æœºçš„ç‰¹å¾ï¼Œè€ƒè™‘åˆ°é±¼çœ¼ç›¸æœºçš„ç•¸å˜ã€‚åŸºäºé«˜æ–¯æº…å°„çš„ä½“ç´ è¡¨ç¤ºèƒ½å¤Ÿæ›´ç²¾ç»†åœ°è¡¨ç¤º3Dç©ºé—´ï¼Œä»è€Œæé«˜æ·±åº¦ä¼°è®¡çš„ç²¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¼‚æ„ç©ºé—´èåˆæ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†å¯å­¦ä¹ çš„æƒé‡æ¥æ§åˆ¶ä¸åŒè§†è§’ç‰¹å¾çš„è´¡çŒ®ã€‚åœ¨åŸºäºé«˜æ–¯æº…å°„çš„ä½“ç´ è¡¨ç¤ºä¸­ï¼Œé«˜æ–¯çƒçš„å‚æ•°ï¼ˆå¦‚ä¸­å¿ƒä½ç½®ã€æ–¹å·®ï¼‰æ˜¯å¯å­¦ä¹ çš„ï¼Œå¯ä»¥åŠ¨æ€åœ°é€‚åº”å±€éƒ¨å›¾åƒçº¹ç†ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æ·±åº¦æŸå¤±å’Œå‡ ä½•ä¸€è‡´æ€§æŸå¤±ï¼Œç”¨äºçº¦æŸæ·±åº¦å›¾çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PFDepthåœ¨KITTI-360å’ŒRealHetæ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚ç›¸è¾ƒäºç°æœ‰ä¸»æµæ·±åº¦ç½‘ç»œï¼ŒPFDepthåœ¨æ·±åº¦ä¼°è®¡ç²¾åº¦ä¸Šæœ‰æ˜¾è‘—æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPFDepthèƒ½å¤Ÿæœ‰æ•ˆåœ°èåˆé’ˆå­”ç›¸æœºå’Œé±¼çœ¼ç›¸æœºçš„æ•°æ®ï¼Œä»è€Œæé«˜æ·±åº¦ä¼°è®¡çš„ç²¾åº¦å’Œé²æ£’æ€§ã€‚å…·ä½“æå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æ•°æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€ä¸‰ç»´é‡å»ºç­‰é¢†åŸŸã€‚é€šè¿‡èåˆå¤šç§ç±»å‹çš„ç›¸æœºæ•°æ®ï¼Œå¯ä»¥æé«˜ç¯å¢ƒæ„ŸçŸ¥çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œä»è€Œæå‡ç›¸å…³ç³»ç»Ÿçš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•ç”Ÿæˆé«˜ç²¾åº¦çš„æ·±åº¦å›¾ï¼Œè¾…åŠ©è½¦è¾†è¿›è¡Œéšœç¢ç‰©æ£€æµ‹å’Œè·¯å¾„è§„åˆ’ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this paper, we present the first pinhole-fisheye framework for heterogeneous multi-view depth estimation, PFDepth. Our key insight is to exploit the complementary characteristics of pinhole and fisheye imagery (undistorted vs. distorted, small vs. large FOV, far vs. near field) for joint optimization. PFDepth employs a unified architecture capable of processing arbitrary combinations of pinhole and fisheye cameras with varied intrinsics and extrinsics. Within PFDepth, we first explicitly lift 2D features from each heterogeneous view into a canonical 3D volumetric space. Then, a core module termed Heterogeneous Spatial Fusion is designed to process and fuse distortion-aware volumetric features across overlapping and non-overlapping regions. Additionally, we subtly reformulate the conventional voxel fusion into a novel 3D Gaussian representation, in which learnable latent Gaussian spheres dynamically adapt to local image textures for finer 3D aggregation. Finally, fused volume features are rendered into multi-view depth maps. Through extensive experiments, we demonstrate that PFDepth sets a state-of-the-art performance on KITTI-360 and RealHet datasets over current mainstream depth networks. To the best of our knowledge, this is the first systematic study of heterogeneous pinhole-fisheye depth estimation, offering both technical novelty and valuable empirical insights.

