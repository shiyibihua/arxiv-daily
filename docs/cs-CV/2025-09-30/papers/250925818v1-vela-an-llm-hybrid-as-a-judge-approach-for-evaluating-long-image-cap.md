---
layout: default
title: VELA: An LLM-Hybrid-as-a-Judge Approach for Evaluating Long Image Captions
---

# VELA: An LLM-Hybrid-as-a-Judge Approach for Evaluating Long Image Captions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25818" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25818v1</a>
  <a href="https://arxiv.org/pdf/2509.25818.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25818v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25818v1', 'VELA: An LLM-Hybrid-as-a-Judge Approach for Evaluating Long Image Captions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kazuki Matsuda, Yuiga Wada, Shinnosuke Hirano, Seitaro Otsuki, Komei Sugiura

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: EMNLP 2025 Main Conference

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VELAï¼šæå‡ºä¸€ç§LLMæ··åˆåˆ¤åˆ«å™¨æ–¹æ³•ï¼Œç”¨äºè¯„ä¼°é•¿å›¾åƒæè¿°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿å›¾åƒæè¿°è¯„ä¼°` `å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹` `LLM-as-a-Judge` `æ··åˆåˆ¤åˆ«å™¨` `LongCap-Arena`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å›¾åƒæè¿°è¯„ä¼°æŒ‡æ ‡ä¸»è¦é’ˆå¯¹çŸ­æ–‡æœ¬ï¼Œæ— æ³•æœ‰æ•ˆè¯„ä¼°MLLMç”Ÿæˆçš„é•¿æ–‡æœ¬æè¿°ã€‚
2. VELAé‡‡ç”¨LLMæ··åˆåˆ¤åˆ«å™¨æ¡†æ¶ï¼Œæ—¨åœ¨æå‡é•¿æ–‡æœ¬å›¾åƒæè¿°è¯„ä¼°çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚
3. LongCap-ArenaåŸºå‡†çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒVELAåœ¨é•¿æ–‡æœ¬æè¿°è¯„ä¼°ä»»åŠ¡ä¸Šè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶å…³æ³¨äºè‡ªåŠ¨è¯„ä¼°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹(MLLM)ç”Ÿæˆçš„é•¿è€Œè¯¦ç»†çš„å›¾åƒæè¿°ã€‚ç°æœ‰çš„å›¾åƒæè¿°è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡ä¸»è¦ä¸ºçŸ­æè¿°è®¾è®¡ï¼Œä¸é€‚ç”¨äºé•¿æè¿°çš„è¯„ä¼°ã€‚æ­¤å¤–ï¼Œæœ€è¿‘çš„LLM-as-a-Judgeæ–¹æ³•ç”±äºä¾èµ–è‡ªå›å½’æ¨ç†å’Œè§†è§‰ä¿¡æ¯çš„æ—©æœŸèåˆï¼Œæ¨ç†é€Ÿåº¦è¾ƒæ…¢ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºVELAï¼Œä¸€ç§åœ¨æ–°å‹LLMæ··åˆåˆ¤åˆ«å™¨æ¡†æ¶å†…å¼€å‘çš„é•¿æè¿°è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†LongCap-Arenaï¼Œä¸€ä¸ªä¸“é—¨ä¸ºè¯„ä¼°é•¿æè¿°æŒ‡æ ‡è€Œè®¾è®¡çš„åŸºå‡†ã€‚è¯¥åŸºå‡†åŒ…å«7,805å¼ å›¾åƒï¼Œå¯¹åº”çš„äººå·¥æä¾›çš„é•¿å‚è€ƒæè¿°å’Œé•¿å€™é€‰æè¿°ï¼Œä»¥åŠæ¥è‡ªä¸‰ä¸ªä¸åŒè§’åº¦ï¼ˆæè¿°æ€§ã€ç›¸å…³æ€§å’Œæµç•…æ€§ï¼‰çš„32,246ä¸ªäººå·¥åˆ¤æ–­ã€‚å®éªŒè¡¨æ˜ï¼ŒVELAä¼˜äºç°æœ‰æŒ‡æ ‡ï¼Œå¹¶åœ¨LongCap-Arenaä¸Šå®ç°äº†è¶…äººçš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³é•¿å›¾åƒæè¿°çš„è‡ªåŠ¨è¯„ä¼°é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ä¸ºçŸ­æ–‡æœ¬è®¾è®¡çš„è¯„ä¼°æŒ‡æ ‡ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰é•¿æè¿°çš„ä¸°å¯Œç»†èŠ‚å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œç›´æ¥ä½¿ç”¨LLMä½œä¸ºåˆ¤åˆ«å™¨çš„æ–¹æ³•ï¼Œç”±äºè‡ªå›å½’æ¨ç†å’Œè§†è§‰ä¿¡æ¯æ—©æœŸèåˆï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œæ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨LLMçš„å¼ºå¤§è¯­è¨€ç†è§£èƒ½åŠ›ï¼Œä½†é¿å…å®Œå…¨ä¾èµ–è‡ªå›å½’æ¨ç†ï¼Œå¹¶é‡‡ç”¨æ··åˆåˆ¤åˆ«å™¨æ¡†æ¶ã€‚é€šè¿‡ç»“åˆä¸åŒçš„è¯„ä¼°ç­–ç•¥ï¼Œæå‡è¯„ä¼°çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVELAçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è§†è§‰ç‰¹å¾æå–æ¨¡å—ï¼Œç”¨äºæå–å›¾åƒçš„è§†è§‰ç‰¹å¾ï¼›2) æ–‡æœ¬ç‰¹å¾æå–æ¨¡å—ï¼Œç”¨äºæå–å‚è€ƒæè¿°å’Œå€™é€‰æè¿°çš„æ–‡æœ¬ç‰¹å¾ï¼›3) LLMæ··åˆåˆ¤åˆ«å™¨ï¼Œè¯¥åˆ¤åˆ«å™¨ç»“åˆäº†ä¸åŒçš„è¯„ä¼°ç­–ç•¥ï¼Œä¾‹å¦‚åŸºäºç›¸ä¼¼åº¦çš„è¯„ä¼°å’ŒåŸºäºLLMçš„è¯„ä¼°ï¼›4) èåˆæ¨¡å—ï¼Œç”¨äºèåˆä¸åŒè¯„ä¼°ç­–ç•¥çš„ç»“æœï¼Œå¾—åˆ°æœ€ç»ˆçš„è¯„ä¼°åˆ†æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šVELAçš„å…³é”®åˆ›æ–°åœ¨äºLLMæ··åˆåˆ¤åˆ«å™¨æ¡†æ¶ã€‚è¯¥æ¡†æ¶å…è®¸çµæ´»åœ°ç»“åˆä¸åŒçš„è¯„ä¼°ç­–ç•¥ï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰é•¿æè¿°çš„å¤æ‚æ€§å’Œç»†å¾®å·®åˆ«ã€‚æ­¤å¤–ï¼Œé€šè¿‡é¿å…å®Œå…¨ä¾èµ–è‡ªå›å½’æ¨ç†ï¼ŒVELAæ˜¾è‘—æé«˜äº†è¯„ä¼°æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šVELAçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰æ¨¡å‹ï¼ˆå¦‚CLIPï¼‰æå–å›¾åƒç‰¹å¾ï¼›2) ä½¿ç”¨é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼ˆå¦‚BERTæˆ–LLaMAï¼‰æå–æ–‡æœ¬ç‰¹å¾ï¼›3) è®¾è®¡åˆé€‚çš„ç›¸ä¼¼åº¦åº¦é‡å‡½æ•°ï¼Œç”¨äºè®¡ç®—å‚è€ƒæè¿°å’Œå€™é€‰æè¿°ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼›4) è®¾è®¡åˆé€‚çš„LLMæç¤ºè¯­ï¼Œå¼•å¯¼LLMè¿›è¡Œè¯„ä¼°ï¼›5) ä½¿ç”¨åŠ æƒå¹³å‡æˆ–å­¦ä¹ çš„æ–¹æ³•èåˆä¸åŒè¯„ä¼°ç­–ç•¥çš„ç»“æœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VELAåœ¨LongCap-ArenaåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†ç°æœ‰çš„è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡ï¼Œç”šè‡³è¾¾åˆ°äº†è¶…äººçš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼ŒVELAåœ¨æè¿°æ€§ã€ç›¸å…³æ€§å’Œæµç•…æ€§ä¸‰ä¸ªæ–¹é¢å‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒVELAèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°é•¿å›¾åƒæè¿°çš„è´¨é‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå¤šæ¨¡æ€å†…å®¹ç”Ÿæˆã€å›¾åƒæè¿°ç”Ÿæˆã€è§†è§‰é—®ç­”ç­‰é¢†åŸŸã€‚é«˜è´¨é‡çš„è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡èƒ½å¤Ÿä¿ƒè¿›MLLMçš„å¼€å‘å’Œä¼˜åŒ–ï¼Œæå‡ç”Ÿæˆå†…å®¹çš„è´¨é‡å’Œç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºå…¶ä»–é•¿æ–‡æœ¬ç”Ÿæˆä»»åŠ¡çš„è¯„ä¼°ï¼Œä¾‹å¦‚æ•…äº‹ç”Ÿæˆå’Œå¯¹è¯ç”Ÿæˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this study, we focus on the automatic evaluation of long and detailed image captions generated by multimodal Large Language Models (MLLMs). Most existing automatic evaluation metrics for image captioning are primarily designed for short captions and are not suitable for evaluating long captions. Moreover, recent LLM-as-a-Judge approaches suffer from slow inference due to their reliance on autoregressive inference and early fusion of visual information. To address these limitations, we propose VELA, an automatic evaluation metric for long captions developed within a novel LLM-Hybrid-as-a-Judge framework. Furthermore, we propose LongCap-Arena, a benchmark specifically designed for evaluating metrics for long captions. This benchmark comprises 7,805 images, the corresponding human-provided long reference captions and long candidate captions, and 32,246 human judgments from three distinct perspectives: Descriptiveness, Relevance, and Fluency. We demonstrated that VELA outperformed existing metrics and achieved superhuman performance on LongCap-Arena.

