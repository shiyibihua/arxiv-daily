---
layout: default
title: PRPO: Paragraph-level Policy Optimization for Vision-Language Deepfake Detection
---

# PRPO: Paragraph-level Policy Optimization for Vision-Language Deepfake Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26272" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26272v2</a>
  <a href="https://arxiv.org/pdf/2509.26272.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26272v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26272v2', 'PRPO: Paragraph-level Policy Optimization for Vision-Language Deepfake Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tuan Nguyen, Naseem Khan, Khang Tran, NhatHai Phan, Issa Khalil

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30 (æ›´æ–°: 2025-10-01)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPRPOç®—æ³•ï¼Œé€šè¿‡æ®µè½çº§ç­–ç•¥ä¼˜åŒ–æå‡è§†è§‰-è¯­è¨€å¤§æ¨¡å‹åœ¨Deepfakeæ£€æµ‹ä¸­çš„æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `Deepfakeæ£€æµ‹` `å¤šæ¨¡æ€å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `ç­–ç•¥ä¼˜åŒ–` `è§†è§‰-è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰Deepfakeæ£€æµ‹æ–¹æ³•ä¾èµ–å¤§å‹æ•°æ®é›†ï¼Œä½†é«˜è´¨é‡æ•°æ®é›†ç¨€ç¼ºï¼Œé™åˆ¶äº†å¤šæ¨¡æ€å¤§æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚
2. PRPOç®—æ³•é€šè¿‡æ®µè½çº§ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼Œå°†LLMçš„æ¨ç†è¿‡ç¨‹ä¸å›¾åƒå†…å®¹åœ¨æ®µè½çº§åˆ«è¿›è¡Œå¯¹é½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒPRPOæ˜¾è‘—æå‡äº†Deepfakeæ£€æµ‹çš„å‡†ç¡®ç‡ï¼Œå¹¶åœ¨æ¨ç†è¯„åˆ†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åˆæˆåª’ä½“çš„å¿«é€Ÿå‘å±•ä½¿å¾—Deepfakeæ£€æµ‹æˆä¸ºåœ¨çº¿å®‰å…¨å’Œä¿¡ä»»çš„å…³é”®æŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œé«˜è´¨é‡å¤§å‹æ•°æ®é›†çš„ç¨€ç¼ºé™åˆ¶äº†è¯¥é¢†åŸŸçš„è¿›å±•ã€‚å°½ç®¡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å±•ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œä½†å®ƒä»¬åœ¨Deepfakeæ£€æµ‹æ–¹é¢çš„è¡¨ç°ä¸ä½³ï¼Œå¸¸å¸¸äº§ç”Ÿä¸è§†è§‰è¯æ®ä¸ç¬¦æˆ–è™šå‡çš„è§£é‡Šã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªç”¨äºDeepfakeæ£€æµ‹çš„æ¨ç†æ ‡æ³¨æ•°æ®é›†ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ®µè½çº§ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆPRPOï¼‰çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œè¯¥ç®—æ³•åœ¨æ®µè½çº§åˆ«å°†LLMæ¨ç†ä¸å›¾åƒå†…å®¹å¯¹é½ã€‚å®éªŒè¡¨æ˜ï¼ŒPRPOæ˜¾è‘—æé«˜äº†æ£€æµ‹ç²¾åº¦ï¼Œå¹¶å®ç°äº†æœ€é«˜çš„æ¨ç†åˆ†æ•°4.55/5.0ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¡¨æ˜ï¼ŒPRPOåœ¨æµ‹è¯•æ—¶æ¡ä»¶ä¸‹æ˜æ˜¾ä¼˜äºGRPOã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†å°†å¤šæ¨¡æ€æ¨ç†å»ºç«‹åœ¨è§†è§‰è¯æ®åŸºç¡€ä¸Šçš„é‡è¦æ€§ï¼Œä»è€Œå®ç°æ›´å¯é å’Œå¯è§£é‡Šçš„Deepfakeæ£€æµ‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•åœ¨Deepfakeæ£€æµ‹ä¸­ï¼Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è™½ç„¶å…·å¤‡æ¨ç†èƒ½åŠ›ï¼Œä½†å…¶æ¨ç†ç»“æœå¾€å¾€ä¸è§†è§‰è¯æ®ä¸ä¸€è‡´ï¼Œç”šè‡³äº§ç”Ÿå¹»è§‰ã€‚ç¼ºä¹é«˜è´¨é‡çš„æ¨ç†æ ‡æ³¨æ•°æ®é›†ï¼Œä½¿å¾—æ¨¡å‹éš¾ä»¥æœ‰æ•ˆå­¦ä¹ è§†è§‰ä¿¡æ¯ä¸æ–‡æœ¬æ¨ç†ä¹‹é—´çš„å…³è”ï¼Œå¯¼è‡´æ£€æµ‹ç²¾åº¦ä¸é«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œé€šè¿‡æ®µè½çº§çš„ç­–ç•¥ä¼˜åŒ–ï¼Œå¼•å¯¼LLMç”Ÿæˆä¸è§†è§‰å†…å®¹å¯¹é½çš„æ¨ç†è¿‡ç¨‹ã€‚å…·ä½“æ¥è¯´ï¼Œå°±æ˜¯å¥–åŠ±é‚£äº›èƒ½å¤ŸåŸºäºå›¾åƒå†…å®¹è¿›è¡Œå‡†ç¡®æ¨ç†çš„æ®µè½ï¼Œæƒ©ç½šé‚£äº›ä¸å›¾åƒå†…å®¹ä¸ç¬¦æˆ–äº§ç”Ÿå¹»è§‰çš„æ®µè½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPRPOç®—æ³•çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) ä¸€ä¸ªç”¨äºDeepfakeæ£€æµ‹çš„æ¨ç†æ ‡æ³¨æ•°æ®é›†ï¼›2) ä¸€ä¸ªå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºç­–ç•¥ç½‘ç»œï¼›3) ä¸€ä¸ªå¥–åŠ±å‡½æ•°ï¼Œç”¨äºè¯„ä¼°LLMç”Ÿæˆçš„æ¨ç†æ®µè½ä¸å›¾åƒå†…å®¹çš„ä¸€è‡´æ€§ï¼›4) ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œç”¨äºä¼˜åŒ–ç­–ç•¥ç½‘ç»œï¼Œä½¿å…¶ç”Ÿæˆæ›´ç¬¦åˆè§†è§‰è¯æ®çš„æ¨ç†è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šPRPOçš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†æ®µè½çº§çš„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ã€‚ä¸ä¼ ç»Ÿçš„ç­–ç•¥ä¼˜åŒ–æ–¹æ³•ä¸åŒï¼ŒPRPOä¸æ˜¯ç›´æ¥ä¼˜åŒ–æ•´ä¸ªæ¨ç†è¿‡ç¨‹ï¼Œè€Œæ˜¯å°†æ¨ç†è¿‡ç¨‹åˆ†è§£ä¸ºå¤šä¸ªæ®µè½ï¼Œå¹¶åˆ†åˆ«å¯¹æ¯ä¸ªæ®µè½è¿›è¡Œä¼˜åŒ–ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æ›´ç²¾ç»†åœ°æ§åˆ¶LLMçš„æ¨ç†è¿‡ç¨‹ï¼Œä½¿å…¶æ›´å¥½åœ°ä¸è§†è§‰å†…å®¹å¯¹é½ã€‚

**å…³é”®è®¾è®¡**ï¼šPRPOçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ç›¸å¯¹å¥–åŠ±å‡½æ•°ï¼Œé¼“åŠ±ç”Ÿæˆæ›´ç¬¦åˆè§†è§‰è¯æ®çš„æ¨ç†æ®µè½ï¼›2) ä½¿ç”¨æ®µè½çº§çš„ç­–ç•¥æ¢¯åº¦æ›´æ–°ï¼Œæ›´ç²¾ç»†åœ°æ§åˆ¶LLMçš„æ¨ç†è¿‡ç¨‹ï¼›3) è®¾è®¡äº†ä¸“é—¨çš„æ¨ç†æ ‡æ³¨æ•°æ®é›†ï¼Œä¸ºå¼ºåŒ–å­¦ä¹ æä¾›é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ã€‚å…·ä½“æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPRPOç®—æ³•åœ¨Deepfakeæ£€æµ‹ç²¾åº¦ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼Œå¹¶ä¸”åœ¨æ¨ç†è¯„åˆ†ä¸Šè¾¾åˆ°äº†4.55/5.0ï¼Œè¡¨æ˜è¯¥ç®—æ³•èƒ½å¤Ÿç”Ÿæˆæ›´ç¬¦åˆè§†è§‰è¯æ®çš„æ¨ç†è¿‡ç¨‹ã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼ŒPRPOåœ¨æµ‹è¯•æ—¶æ¡ä»¶ä¸‹ä¼˜äºGRPOï¼ŒéªŒè¯äº†æ®µè½çº§ç­–ç•¥ä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåœ¨çº¿ç¤¾äº¤åª’ä½“å¹³å°ã€æ–°é—»åª’ä½“æœºæ„ç­‰ï¼Œç”¨äºè‡ªåŠ¨æ£€æµ‹å’Œè¯†åˆ«Deepfakeå†…å®¹ï¼Œä»è€Œå‡å°‘è™šå‡ä¿¡æ¯çš„ä¼ æ’­ï¼Œç»´æŠ¤ç½‘ç»œå®‰å…¨å’Œå…¬ä¼—ä¿¡ä»»ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€å†…å®¹çœŸå®æ€§æ£€æµ‹é¢†åŸŸï¼Œä¾‹å¦‚éŸ³é¢‘å’Œè§†é¢‘ç¯¡æ”¹æ£€æµ‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid rise of synthetic media has made deepfake detection a critical challenge for online safety and trust. Progress remains constrained by the scarcity of large, high-quality datasets. Although multimodal large language models (LLMs) exhibit strong reasoning capabilities, their performance on deepfake detection is poor, often producing explanations that are misaligned with visual evidence or hallucinatory. To address this limitation, we introduce a reasoning-annotated dataset for deepfake detection and propose Paragraph-level Relative Policy Optimization (PRPO), a reinforcement learning algorithm that aligns LLM reasoning with image content at the paragraph level. Experiments show that PRPO improves detection accuracy by a wide margin and achieves the highest reasoning score of 4.55/5.0. Ablation studies further demonstrate that PRPO significantly outperforms GRPO under test-time conditions. These results underscore the importance of grounding multimodal reasoning in visual evidence to enable more reliable and interpretable deepfake detection.

