---
layout: default
title: SETR: A Two-Stage Semantic-Enhanced Framework for Zero-Shot Composed Image Retrieval
---

# SETR: A Two-Stage Semantic-Enhanced Framework for Zero-Shot Composed Image Retrieval

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26012" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26012v1</a>
  <a href="https://arxiv.org/pdf/2509.26012.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26012v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26012v1', 'SETR: A Two-Stage Semantic-Enhanced Framework for Zero-Shot Composed Image Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuqi Xiao, Yingying Zhu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSETRï¼šä¸€ç§è¯­ä¹‰å¢å¼ºçš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œç”¨äºé›¶æ ·æœ¬ç»„åˆå›¾åƒæ£€ç´¢**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é›¶æ ·æœ¬å­¦ä¹ ` `ç»„åˆå›¾åƒæ£€ç´¢` `å¤šæ¨¡æ€å­¦ä¹ ` `è¯­ä¹‰ç†è§£` `ä¸¤é˜¶æ®µæ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é›¶æ ·æœ¬ç»„åˆå›¾åƒæ£€ç´¢æ–¹æ³•ä¾èµ–è”åˆç‰¹å¾èåˆï¼Œæ˜“å—æ— å…³èƒŒæ™¯å¹²æ‰°ï¼Œä¸”ç¼ºä¹ç»†ç²’åº¦è¯­ä¹‰å…³ç³»å»ºæ¨¡èƒ½åŠ›ã€‚
2. SETRé‡‡ç”¨ä¸¤é˜¶æ®µæ£€ç´¢ç­–ç•¥ï¼Œé¦–å…ˆé€šè¿‡äº¤é›†é©±åŠ¨çš„ç²—æ£€ç´¢è¿‡æ»¤å¹²æ‰°ï¼Œå†åˆ©ç”¨å¤šæ¨¡æ€LLMè¿›è¡Œç»†ç²’åº¦é‡æ’åºã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSETRåœ¨CIRRç­‰æ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼ŒRecall@1æå‡é«˜è¾¾15.15ä¸ªç™¾åˆ†ç‚¹ï¼ŒéªŒè¯äº†ä¸¤é˜¶æ®µæ¨ç†çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é›¶æ ·æœ¬ç»„åˆå›¾åƒæ£€ç´¢(ZS-CIR)æ—¨åœ¨ç»™å®šå‚è€ƒå›¾åƒå’Œç›¸å…³æ–‡æœ¬çš„æƒ…å†µä¸‹æ£€ç´¢ç›®æ ‡å›¾åƒï¼Œè€Œæ— éœ€æ˜‚è´µçš„ä¸‰å…ƒç»„æ ‡æ³¨ã€‚ç°æœ‰çš„åŸºäºCLIPçš„æ–¹æ³•é¢ä¸´ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š(1)åŸºäºè”åˆçš„ç‰¹å¾èåˆæ— å·®åˆ«åœ°èšåˆæ‰€æœ‰è§†è§‰çº¿ç´¢ï¼Œæºå¸¦äº†ä¸ç›¸å…³çš„èƒŒæ™¯ç»†èŠ‚ï¼Œç¨€é‡Šäº†é¢„æœŸçš„ä¿®æ”¹ï¼›(2)æ¥è‡ªCLIPåµŒå…¥çš„å…¨å±€ä½™å¼¦ç›¸ä¼¼æ€§ç¼ºä¹è§£å†³ç»†ç²’åº¦è¯­ä¹‰å…³ç³»çš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SETR(è¯­ä¹‰å¢å¼ºçš„ä¸¤é˜¶æ®µæ£€ç´¢)ã€‚åœ¨ç²—æ£€ç´¢é˜¶æ®µï¼ŒSETRå¼•å…¥äº†ä¸€ç§äº¤é›†é©±åŠ¨çš„ç­–ç•¥ï¼Œä»…ä¿ç•™å‚è€ƒå›¾åƒå’Œç›¸å…³æ–‡æœ¬ä¹‹é—´çš„é‡å è¯­ä¹‰ï¼Œä»è€Œè¿‡æ»¤æ‰è”åˆèåˆå›ºæœ‰çš„å¹²æ‰°å› ç´ ï¼Œå¹¶äº§ç”Ÿæ›´å¹²å‡€ã€é«˜ç²¾åº¦çš„å€™é€‰é›†ã€‚åœ¨ç»†ç²’åº¦é‡æ’åºé˜¶æ®µï¼Œæˆ‘ä»¬é‡‡ç”¨å…·æœ‰ä½ç§©é€‚åº”çš„é¢„è®­ç»ƒå¤šæ¨¡æ€LLMæ¥è¿›è¡ŒäºŒå…ƒè¯­ä¹‰ç›¸å…³æ€§åˆ¤æ–­(â€œæ˜¯/å¦â€)ï¼Œé€šè¿‡æ˜¾å¼éªŒè¯å…³ç³»å’Œå±æ€§çº§åˆ«çš„è¿è´¯æ€§ï¼Œè¶…è¶Šäº†CLIPçš„å…¨å±€ç‰¹å¾åŒ¹é…ã€‚è¿™ä¸¤ä¸ªé˜¶æ®µå…±åŒæ„æˆäº†ä¸€ä¸ªäº’è¡¥çš„æµç¨‹ï¼šç²—æ£€ç´¢ä»¥é«˜å¬å›ç‡ç¼©å°å€™é€‰æ± ï¼Œè€Œé‡æ’åºç¡®ä¿ä¸ç»†å¾®çš„æ–‡æœ¬ä¿®æ”¹ç²¾ç¡®å¯¹é½ã€‚åœ¨CIRRã€Fashion-IQå’ŒCIRCOä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSETRå®ç°äº†æ–°çš„æœ€å…ˆè¿›æ€§èƒ½ï¼Œåœ¨CIRRä¸Šå°†Recall@1æé«˜äº†é«˜è¾¾15.15ä¸ªç™¾åˆ†ç‚¹ã€‚æˆ‘ä»¬çš„ç»“æœç¡®ç«‹äº†ä¸¤é˜¶æ®µæ¨ç†ä½œä¸ºé²æ£’ä¸”å¯ç§»æ¤çš„ZS-CIRçš„é€šç”¨èŒƒä¾‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šé›¶æ ·æœ¬ç»„åˆå›¾åƒæ£€ç´¢(ZS-CIR)æ—¨åœ¨æ ¹æ®ç»™å®šçš„å‚è€ƒå›¾åƒå’Œæè¿°æ€§æ–‡æœ¬ï¼Œæ£€ç´¢ç»è¿‡æ–‡æœ¬æè¿°ä¿®æ”¹åçš„ç›®æ ‡å›¾åƒã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäºCLIPçš„æ–¹æ³•ï¼Œä¸»è¦ä¾èµ–äºå°†å‚è€ƒå›¾åƒå’Œæ–‡æœ¬æè¿°è¿›è¡Œç®€å•çš„è”åˆç‰¹å¾èåˆï¼Œè¿™å¯¼è‡´ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯èåˆè¿‡ç¨‹ä¸­ä¼šå¼•å…¥ä¸ç›¸å…³çš„èƒŒæ™¯ä¿¡æ¯ï¼Œå¹²æ‰°æ£€ç´¢ï¼›äºŒæ˜¯å…¨å±€ä½™å¼¦ç›¸ä¼¼åº¦åŒ¹é…éš¾ä»¥æ•æ‰ç»†ç²’åº¦çš„è¯­ä¹‰å…³ç³»ï¼Œä¾‹å¦‚å±æ€§çº§åˆ«çš„ä¿®æ”¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSETRçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ£€ç´¢è¿‡ç¨‹åˆ†è§£ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç²—æ£€ç´¢å’Œç»†ç²’åº¦é‡æ’åºã€‚ç²—æ£€ç´¢é˜¶æ®µæ—¨åœ¨å¿«é€Ÿç¼©å°æœç´¢èŒƒå›´ï¼Œä¿ç•™é«˜å¬å›ç‡ï¼›ç»†ç²’åº¦é‡æ’åºé˜¶æ®µåˆ™ä¸“æ³¨äºç²¾ç¡®åŒ¹é…ï¼Œåˆ©ç”¨æ›´å¼ºå¤§çš„è¯­ä¹‰ç†è§£èƒ½åŠ›æ¥æå‡æ£€ç´¢ç²¾åº¦ã€‚è¿™ç§ä¸¤é˜¶æ®µçš„è®¾è®¡æ—¨åœ¨å…‹æœç°æœ‰æ–¹æ³•åœ¨ç‰¹å¾èåˆå’Œè¯­ä¹‰ç†è§£æ–¹é¢çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSETRæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š
1. **ç²—æ£€ç´¢é˜¶æ®µ**ï¼šä½¿ç”¨äº¤é›†é©±åŠ¨çš„ç­–ç•¥ï¼Œæå–å‚è€ƒå›¾åƒå’Œæ–‡æœ¬æè¿°ä¹‹é—´çš„å…±äº«è¯­ä¹‰ä¿¡æ¯ï¼Œè¿‡æ»¤æ‰ä¸ç›¸å…³çš„èƒŒæ™¯ç»†èŠ‚ï¼Œç”Ÿæˆå€™é€‰é›†ã€‚
2. **ç»†ç²’åº¦é‡æ’åºé˜¶æ®µ**ï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„å¤šæ¨¡æ€LLMï¼Œå¯¹å€™é€‰é›†ä¸­çš„å›¾åƒè¿›è¡ŒäºŒå…ƒè¯­ä¹‰ç›¸å…³æ€§åˆ¤æ–­ï¼ˆâ€œæ˜¯/å¦â€ï¼‰ï¼Œåˆ¤æ–­å›¾åƒæ˜¯å¦ç¬¦åˆæ–‡æœ¬æè¿°çš„ä¿®æ”¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šSETRçš„å…³é”®åˆ›æ–°åœ¨äºï¼š
1. **äº¤é›†é©±åŠ¨çš„ç‰¹å¾æå–**ï¼šä¸åŒäºä¼ ç»Ÿçš„è”åˆç‰¹å¾èåˆï¼ŒSETRåªä¿ç•™å‚è€ƒå›¾åƒå’Œæ–‡æœ¬æè¿°ä¹‹é—´çš„é‡å è¯­ä¹‰ï¼Œå‡å°‘äº†èƒŒæ™¯å™ªå£°çš„å¹²æ‰°ã€‚
2. **å¤šæ¨¡æ€LLMçš„äºŒå…ƒè¯­ä¹‰åˆ¤æ–­**ï¼šåˆ©ç”¨LLMå¼ºå¤§çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œæ˜¾å¼åœ°éªŒè¯å›¾åƒå’Œæ–‡æœ¬æè¿°ä¹‹é—´çš„å…³ç³»å’Œå±æ€§ä¸€è‡´æ€§ï¼Œè¶…è¶Šäº†ç®€å•çš„å…¨å±€ç‰¹å¾åŒ¹é…ã€‚

**å…³é”®è®¾è®¡**ï¼š
1. **äº¤é›†é©±åŠ¨ç­–ç•¥**ï¼šå…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ï¼Œä½†æ ¸å¿ƒæ€æƒ³æ˜¯è®¾è®¡ä¸€ç§æœºåˆ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå–å‚è€ƒå›¾åƒå’Œæ–‡æœ¬æè¿°çš„å…±äº«è¯­ä¹‰ä¿¡æ¯ã€‚
2. **ä½ç§©é€‚åº”(LoRA)**ï¼šåœ¨ç»†ç²’åº¦é‡æ’åºé˜¶æ®µï¼Œä½¿ç”¨LoRAå¯¹é¢„è®­ç»ƒçš„å¤šæ¨¡æ€LLMè¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶é€‚åº”ZS-CIRä»»åŠ¡ã€‚LoRAé€šè¿‡å¼•å…¥å°‘é‡å¯è®­ç»ƒå‚æ•°ï¼Œé™ä½äº†å¾®è°ƒçš„è®¡ç®—æˆæœ¬ã€‚
3. **äºŒå…ƒè¯­ä¹‰ç›¸å…³æ€§åˆ¤æ–­**ï¼šå°†é‡æ’åºé—®é¢˜è½¬åŒ–ä¸ºäºŒå…ƒåˆ†ç±»é—®é¢˜ï¼Œä½¿ç”¨LLMåˆ¤æ–­å€™é€‰å›¾åƒæ˜¯å¦ä¸æ–‡æœ¬æè¿°ç›¸å…³ï¼Œä»è€Œå®ç°æ›´ç²¾ç¡®çš„è¯­ä¹‰åŒ¹é…ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SETRåœ¨CIRRã€Fashion-IQå’ŒCIRCOä¸‰ä¸ªæ•°æ®é›†ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨æœ€å…·æŒ‘æˆ˜æ€§çš„CIRRæ•°æ®é›†ä¸Šï¼ŒSETRçš„Recall@1æŒ‡æ ‡æå‡äº†é«˜è¾¾15.15ä¸ªç™¾åˆ†ç‚¹ï¼Œè¶…è¶Šäº†ç°æœ‰çš„SOTAæ–¹æ³•ï¼Œè¯æ˜äº†å…¶åœ¨é›¶æ ·æœ¬ç»„åˆå›¾åƒæ£€ç´¢ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SETRåœ¨ç”µå•†ã€æ—¶å°šã€å®¤å†…è®¾è®¡ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ä¸Šä¼ ä¸€å¼ æ²™å‘å›¾ç‰‡å¹¶æè¿°â€œæ¢æˆè“è‰²â€ï¼Œå¿«é€Ÿæ£€ç´¢åˆ°ç¬¦åˆè¦æ±‚çš„è“è‰²æ²™å‘ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæå‡å›¾åƒæ£€ç´¢çš„å‡†ç¡®æ€§å’Œç”¨æˆ·ä½“éªŒï¼Œå¹¶ä¸ºæ›´æ™ºèƒ½çš„å›¾åƒæœç´¢å’Œç¼–è¾‘å·¥å…·å¥ å®šåŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Zero-shot Composed Image Retrieval (ZS-CIR) aims to retrieve a target image given a reference image and a relative text, without relying on costly triplet annotations. Existing CLIP-based methods face two core challenges: (1) union-based feature fusion indiscriminately aggregates all visual cues, carrying over irrelevant background details that dilute the intended modification, and (2) global cosine similarity from CLIP embeddings lacks the ability to resolve fine-grained semantic relations. To address these issues, we propose SETR (Semantic-enhanced Two-Stage Retrieval). In the coarse retrieval stage, SETR introduces an intersection-driven strategy that retains only the overlapping semantics between the reference image and relative text, thereby filtering out distractors inherent to union-based fusion and producing a cleaner, high-precision candidate set. In the fine-grained re-ranking stage, we adapt a pretrained multimodal LLM with Low-Rank Adaptation to conduct binary semantic relevance judgments ("Yes/No"), which goes beyond CLIP's global feature matching by explicitly verifying relational and attribute-level consistency. Together, these two stages form a complementary pipeline: coarse retrieval narrows the candidate pool with high recall, while re-ranking ensures precise alignment with nuanced textual modifications. Experiments on CIRR, Fashion-IQ, and CIRCO show that SETR achieves new state-of-the-art performance, improving Recall@1 on CIRR by up to 15.15 points. Our results establish two-stage reasoning as a general paradigm for robust and portable ZS-CIR.

