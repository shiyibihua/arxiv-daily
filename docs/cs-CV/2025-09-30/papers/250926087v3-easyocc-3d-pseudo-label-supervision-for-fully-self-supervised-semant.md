---
layout: default
title: EasyOcc: 3D Pseudo-Label Supervision for Fully Self-Supervised Semantic Occupancy Prediction Models
---

# EasyOcc: 3D Pseudo-Label Supervision for Fully Self-Supervised Semantic Occupancy Prediction Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26087" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26087v3</a>
  <a href="https://arxiv.org/pdf/2509.26087.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26087v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26087v3', 'EasyOcc: 3D Pseudo-Label Supervision for Fully Self-Supervised Semantic Occupancy Prediction Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Seamie Hayes, Ganesh Sistu, CiarÃ¡n Eising

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30 (æ›´æ–°: 2025-11-27)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EasyOccï¼šåˆ©ç”¨3Dä¼ªæ ‡ç­¾ç›‘ç£å®ç°å…¨è‡ªç›‘ç£è¯­ä¹‰å æ®é¢„æµ‹æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­ä¹‰å æ®é¢„æµ‹` `è‡ªç›‘ç£å­¦ä¹ ` `3Dä¼ªæ ‡ç­¾` `è§†è§‰åŸºç¡€æ¨¡å‹` `æ—¶é—´ä¿¡æ¯èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªç›‘ç£è¯­ä¹‰å æ®é¢„æµ‹æ¨¡å‹ä¾èµ–å¤æ‚çš„æ–°è§†è§’åˆæˆç­‰æŠ€æœ¯ï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬é«˜æ˜‚å’Œå†…å­˜å ç”¨å¤§ã€‚
2. è®ºæ–‡æå‡ºåˆ©ç”¨Grounded-SAMå’ŒMetric3Dv2ç­‰åŸºç¡€æ¨¡å‹ç”Ÿæˆ3Dä¼ªæ ‡ç­¾ï¼Œå¹¶ç»“åˆæ—¶é—´ä¿¡æ¯è¿›è¡Œæ ‡ç­¾ç¨ å¯†åŒ–ï¼Œé™ä½è®¡ç®—å¤æ‚åº¦ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æ˜¾è‘—æå‡ç°æœ‰æ¨¡å‹çš„æ€§èƒ½ï¼Œä¾‹å¦‚åœ¨OccNeRFä¸ŠmIoUæå‡45%ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ›´é«˜æ•ˆçš„æ¨¡å‹EasyOccã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªç›‘ç£æ¨¡å‹åœ¨è¯­ä¹‰å æ®é¢„æµ‹é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚è¿™äº›æ¨¡å‹åˆ©ç”¨å¤æ‚çš„æŸå¤±è®¡ç®—ç­–ç•¥æ¥å¼¥è¡¥çœŸå®æ ‡ç­¾çš„ç¼ºå¤±ã€‚ä¾‹å¦‚ï¼Œæ–°è§†è§’åˆæˆã€è·¨è§†è§’æ¸²æŸ“å’Œæ·±åº¦ä¼°è®¡ç­‰æŠ€æœ¯å·²è¢«ç”¨äºè§£å†³è¯­ä¹‰å’Œæ·±åº¦æ¨¡ç³Šé—®é¢˜ã€‚ç„¶è€Œï¼Œè¿™äº›æŠ€æœ¯é€šå¸¸åœ¨è®­ç»ƒé˜¶æ®µäº§ç”Ÿé«˜æ˜‚çš„è®¡ç®—æˆæœ¬å’Œå†…å­˜ä½¿ç”¨ï¼Œå°¤å…¶æ˜¯åœ¨æ–°è§†è§’åˆæˆçš„æƒ…å†µä¸‹ã€‚ä¸ºäº†ç¼“è§£è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç”±åŸºç¡€æ¨¡å‹Grounded-SAMå’ŒMetric3Dv2ç”Ÿæˆçš„3Dä¼ªçœŸå€¼æ ‡ç­¾ï¼Œå¹¶åˆ©ç”¨æ—¶é—´ä¿¡æ¯è¿›è¡Œæ ‡ç­¾ç¨ å¯†åŒ–ã€‚æˆ‘ä»¬çš„3Dä¼ªæ ‡ç­¾å¯ä»¥è½»æ¾é›†æˆåˆ°ç°æœ‰æ¨¡å‹ä¸­ï¼Œä»è€Œæ˜¾è‘—æé«˜æ€§èƒ½ï¼Œå½“åº”ç”¨äºOccNeRFæ¨¡å‹æ—¶ï¼ŒmIoUä»9.73æé«˜åˆ°14.09ï¼Œæå‡äº†45%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç®€åŒ–çš„æ¨¡å‹EasyOccï¼Œå®ç°äº†13.86çš„mIoUã€‚è¯¥æ¨¡å‹ä»…ä»æˆ‘ä»¬çš„æ ‡ç­¾ä¸­å­¦ä¹ ï¼Œé¿å…äº†å‰é¢æåˆ°çš„å¤æ‚æ¸²æŸ“ç­–ç•¥ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å®Œæ•´åœºæ™¯ä¸Šè¯„ä¼°æ—¶è¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè€Œæ— éœ€åº”ç”¨ç›¸æœºæ©ç ï¼ŒEasyOccå®ç°äº†7.71çš„mIoUï¼Œä¼˜äºä¹‹å‰çš„æœ€ä½³æ¨¡å‹31%ã€‚è¿™äº›å‘ç°çªå‡ºäº†åŸºç¡€æ¨¡å‹ã€æ—¶é—´ä¸Šä¸‹æ–‡å’ŒæŸå¤±è®¡ç®—ç©ºé—´çš„é€‰æ‹©åœ¨è‡ªç›‘ç£å­¦ä¹ ä¸­å¯¹äºå…¨é¢åœºæ™¯ç†è§£çš„å…³é”®é‡è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è‡ªç›‘ç£è¯­ä¹‰å æ®é¢„æµ‹æ–¹æ³•ï¼Œä¾‹å¦‚åŸºäºæ–°è§†è§’åˆæˆçš„æ–¹æ³•ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œå†…å­˜ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´å’Œæ•ˆç‡ã€‚è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤æ‚çš„æ¸²æŸ“ç­–ç•¥æ¥è§£å†³è¯­ä¹‰å’Œæ·±åº¦æ¨¡ç³Šé—®é¢˜ï¼Œå¯¼è‡´è®­ç»ƒè¿‡ç¨‹ç¼“æ…¢ä¸”éš¾ä»¥æ‰©å±•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆå¦‚Grounded-SAMå’ŒMetric3Dv2ï¼‰ç”Ÿæˆé«˜è´¨é‡çš„3Dä¼ªæ ‡ç­¾ï¼Œå¹¶ç»“åˆæ—¶é—´ä¿¡æ¯æ¥æé«˜æ ‡ç­¾çš„ç¨ å¯†åº¦ã€‚é€šè¿‡ä½¿ç”¨è¿™äº›ä¼ªæ ‡ç­¾ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°åœºæ™¯çš„è¯­ä¹‰å æ®ä¿¡æ¯ï¼Œè€Œæ— éœ€ä¾èµ–å¤æ‚çš„æ¸²æŸ“è¿‡ç¨‹ã€‚è¿™æ ·å¯ä»¥æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬å’Œå†…å­˜éœ€æ±‚ï¼Œå¹¶æé«˜è®­ç»ƒæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) ä½¿ç”¨Grounded-SAMå’ŒMetric3Dv2ç­‰åŸºç¡€æ¨¡å‹ç”Ÿæˆåˆå§‹çš„3Dä¼ªæ ‡ç­¾ã€‚2) åˆ©ç”¨æ—¶é—´ä¿¡æ¯ï¼Œä¾‹å¦‚è¿ç»­å¸§ä¹‹é—´çš„ä¿¡æ¯ï¼Œå¯¹ä¼ªæ ‡ç­¾è¿›è¡Œç¨ å¯†åŒ–å’Œä¼˜åŒ–ï¼Œä»¥å‡å°‘å™ªå£°å’Œæé«˜å‡†ç¡®æ€§ã€‚3) ä½¿ç”¨ç”Ÿæˆçš„3Dä¼ªæ ‡ç­¾ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œè®­ç»ƒè¯­ä¹‰å æ®é¢„æµ‹æ¨¡å‹ã€‚4) æå‡ºä¸€ä¸ªç®€åŒ–çš„æ¨¡å‹EasyOccï¼Œç›´æ¥ä»ä¼ªæ ‡ç­¾ä¸­å­¦ä¹ ï¼Œé¿å…äº†å¤æ‚çš„æ¸²æŸ“ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰åŸºç¡€æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„3Dä¼ªæ ‡ç­¾ï¼Œå¹¶å°†å…¶åº”ç”¨äºè‡ªç›‘ç£è¯­ä¹‰å æ®é¢„æµ‹ä»»åŠ¡ã€‚ä¸ä¼ ç»Ÿçš„è‡ªç›‘ç£æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•é¿å…äº†å¤æ‚çš„æ¸²æŸ“è¿‡ç¨‹ï¼Œé™ä½äº†è®¡ç®—æˆæœ¬å’Œå†…å­˜éœ€æ±‚ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨æ—¶é—´ä¿¡æ¯è¿›è¡Œæ ‡ç­¾ç¨ å¯†åŒ–ä¹Ÿæé«˜äº†ä¼ªæ ‡ç­¾çš„è´¨é‡å’Œæ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é€‰æ‹©åˆé€‚çš„è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆGrounded-SAMå’ŒMetric3Dv2ï¼‰æ¥ç”Ÿæˆ3Dä¼ªæ ‡ç­¾ã€‚2) è®¾è®¡æœ‰æ•ˆçš„æ—¶é—´ä¿¡æ¯èåˆç­–ç•¥ï¼Œä»¥æé«˜æ ‡ç­¾çš„ç¨ å¯†åº¦å’Œå‡†ç¡®æ€§ã€‚3) è®¾è®¡ä¸€ä¸ªç®€åŒ–çš„æ¨¡å‹EasyOccï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆåœ°ä»ä¼ªæ ‡ç­¾ä¸­å­¦ä¹ ã€‚4) æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦è€ƒè™‘ä¼ªæ ‡ç­¾çš„å™ªå£°å’Œä¸ç¡®å®šæ€§ï¼Œä¾‹å¦‚å¯ä»¥ä½¿ç”¨é²æ£’çš„æŸå¤±å‡½æ•°æˆ–å¼•å…¥ç½®ä¿¡åº¦åŠ æƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æå‡ç°æœ‰è‡ªç›‘ç£è¯­ä¹‰å æ®é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨OccNeRFæ¨¡å‹ä¸Šåº”ç”¨è¯¥æ–¹æ³•åï¼ŒmIoUä»9.73æé«˜åˆ°14.09ï¼Œæå‡äº†45%ã€‚æ­¤å¤–ï¼Œæå‡ºçš„ç®€åŒ–æ¨¡å‹EasyOccä¹Ÿå–å¾—äº†13.86çš„mIoUï¼Œå¹¶ä¸”åœ¨å®Œæ•´åœºæ™¯è¯„ä¼°ä¸­ï¼ŒEasyOccå®ç°äº†7.71çš„mIoUï¼Œä¼˜äºä¹‹å‰çš„æœ€ä½³æ¨¡å‹31%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è‡ªç›‘ç£è¯­ä¹‰å æ®é¢„æµ‹é¢†åŸŸå…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€å¢å¼ºç°å®ç­‰é¢†åŸŸã€‚é€šè¿‡é«˜æ•ˆçš„è‡ªç›‘ç£å­¦ä¹ ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å‘¨å›´ç¯å¢ƒï¼Œä»è€Œæé«˜è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„å®‰å…¨æ€§ï¼Œå¢å¼ºæœºå™¨äººçš„è‡ªä¸»å¯¼èˆªèƒ½åŠ›ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›æ›´æ²‰æµ¸å¼çš„å¢å¼ºç°å®ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºä¸‰ç»´é‡å»ºã€åœºæ™¯ç†è§£ç­‰ä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Self-supervised models have recently achieved notable advancements, particularly in the domain of semantic occupancy prediction. These models utilize sophisticated loss computation strategies to compensate for the absence of ground-truth labels. For instance, techniques such as novel view synthesis, cross-view rendering, and depth estimation have been explored to address the issue of semantic and depth ambiguity. However, such techniques typically incur high computational costs and memory usage during the training stage, especially in the case of novel view synthesis. To mitigate these issues, we propose 3D pseudo-ground-truth labels generated by the foundation models Grounded-SAM and Metric3Dv2, and harness temporal information for label densification. Our 3D pseudo-labels can be easily integrated into existing models, which yields substantial performance improvements, with mIoU increasing by 45\%, from 9.73 to 14.09, when implemented into the OccNeRF model. This stands in contrast to earlier advancements in the field, which are often not readily transferable to other architectures. Additionally, we propose a streamlined model, EasyOcc, achieving 13.86 mIoU. This model conducts learning solely from our labels, avoiding complex rendering strategies mentioned previously. Furthermore, our method enables models to attain state-of-the-art performance when evaluated on the full scene without applying the camera mask, with EasyOcc achieving 7.71 mIoU, outperforming the previous best model by 31\%. These findings highlight the critical importance of foundation models, temporal context, and the choice of loss computation space in self-supervised learning for comprehensive scene understanding.

