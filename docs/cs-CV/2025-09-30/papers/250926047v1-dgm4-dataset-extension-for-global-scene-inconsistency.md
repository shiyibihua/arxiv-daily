---
layout: default
title: DGM4+: Dataset Extension for Global Scene Inconsistency
---

# DGM4+: Dataset Extension for Global Scene Inconsistency

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26047" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26047v1</a>
  <a href="https://arxiv.org/pdf/2509.26047.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26047v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26047v1', 'DGM4+: Dataset Extension for Global Scene Inconsistency')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Gagandeep Singh, Samudi Amarsinghe, Priyanka Singh, Xue Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: 8 pages, 3 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Gaganx0/DGM4plus)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DGM4+ï¼šæ‰©å±•æ•°æ®é›†ä»¥åº”å¯¹å…¨å±€åœºæ™¯ä¸ä¸€è‡´æ€§ï¼Œæå‡å¤šæ¨¡æ€ä¼ªé€ æ£€æµ‹èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€ä¼ªé€ æ£€æµ‹` `å…¨å±€åœºæ™¯ä¸ä¸€è‡´æ€§` `æ•°æ®é›†æ‰©å±•` `å‰æ™¯èƒŒæ™¯ä¸åŒ¹é…` `æ–‡æœ¬æ“çºµ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€ä¼ªé€ æ£€æµ‹æ•°æ®é›†ä¸»è¦å…³æ³¨å±€éƒ¨ç¯¡æ”¹ï¼Œç¼ºä¹å¯¹å…¨å±€åœºæ™¯ä¸ä¸€è‡´æ€§çš„æœ‰æ•ˆè¦†ç›–ï¼Œé™åˆ¶äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
2. DGM4+æ•°æ®é›†é€šè¿‡å¼•å…¥å‰æ™¯-èƒŒæ™¯ä¸åŒ¹é…å’Œæ–‡æœ¬æ“çºµçš„æ··åˆï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­å¸¸è§çš„å…¨å±€ä¼ªé€ åœºæ™¯ï¼Œå¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ã€‚
3. è¯¥æ•°æ®é›†åŒ…å«5000ä¸ªé«˜è´¨é‡æ ·æœ¬ï¼Œå¹¶é‡‡ç”¨ä¸¥æ ¼çš„è´¨é‡æ§åˆ¶æµç¨‹ï¼Œç¡®ä¿æ•°æ®çš„çœŸå®æ€§å’Œå¯é æ€§ï¼Œä¸ºå¤šæ¨¡æ€æ¨¡å‹è¯„ä¼°æä¾›åŸºå‡†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”Ÿæˆæ¨¡å‹çš„å¿«é€Ÿå‘å±•æ˜¾è‘—é™ä½äº†åˆ¶ä½œå…·æœ‰è¯´æœåŠ›çš„å¤šæ¨¡æ€è™šå‡ä¿¡æ¯çš„é—¨æ§›ã€‚ä¼ªé€ å›¾åƒå’Œç¯¡æ”¹çš„æ ‡é¢˜è¶Šæ¥è¶Šå¤šåœ°å…±åŒå‡ºç°ï¼Œä»¥åˆ›å»ºå…·æœ‰è¯´æœåŠ›çš„è™šå‡å™è¿°ã€‚æ£€æµ‹å’Œå®šä½å¤šæ¨¡æ€åª’ä½“æ“çºµ(DGM4)æ•°æ®é›†ä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶å¥ å®šäº†åŸºç¡€ï¼Œä½†å®ƒä»…é™äºå±€éƒ¨æ“çºµï¼Œå¦‚æ¢è„¸ã€å±æ€§ç¼–è¾‘å’Œæ ‡é¢˜æ›´æ”¹ã€‚è¿™ç•™ä¸‹äº†ä¸€ä¸ªå…³é”®çš„ç©ºç™½ï¼šå…¨å±€ä¸ä¸€è‡´æ€§ï¼Œä¾‹å¦‚ä¸åŒ¹é…çš„å‰æ™¯å’ŒèƒŒæ™¯ï¼Œè¿™äº›åœ¨ç°å®ä¸–ç•Œçš„ä¼ªé€ å“ä¸­éå¸¸æ™®éã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨5000ä¸ªé«˜è´¨é‡çš„æ ·æœ¬æ‰©å±•äº†DGM4ï¼Œè¿™äº›æ ·æœ¬å¼•å…¥äº†å‰æ™¯-èƒŒæ™¯(FG-BG)ä¸åŒ¹é…åŠå…¶ä¸æ–‡æœ¬æ“çºµçš„æ··åˆã€‚ä½¿ç”¨OpenAIçš„gpt-image-1å’Œç²¾å¿ƒè®¾è®¡çš„æç¤ºï¼Œæˆ‘ä»¬ç”Ÿæˆä»¥äººä¸ºä¸­å¿ƒçš„æ–°é—»é£æ ¼å›¾åƒï¼Œå…¶ä¸­çœŸå®çš„äººç‰©è¢«æ”¾ç½®åœ¨è’è°¬æˆ–ä¸å¯èƒ½çš„èƒŒæ™¯ä¸­(ä¾‹å¦‚ï¼Œä¸€ä½è€å¸ˆå¹³é™åœ°åœ¨ç«æ˜Ÿè¡¨é¢å‘å­¦ç”Ÿè®²è¯)ã€‚æ ‡é¢˜åœ¨ä¸‰ç§æ¡ä»¶ä¸‹ç”Ÿæˆï¼šå­—é¢ã€æ–‡æœ¬å±æ€§å’Œæ–‡æœ¬åˆ†å‰²ï¼Œä»è€Œäº§ç”Ÿä¸‰ä¸ªæ–°çš„æ“çºµç±»åˆ«ï¼šFG-BGã€FG-BG+TAå’ŒFG-BG+TSã€‚è´¨é‡æ§åˆ¶ç®¡é“å¼ºåˆ¶æ‰§è¡Œä¸€åˆ°ä¸‰ä¸ªå¯è§çš„é¢å­”ã€æ„ŸçŸ¥å“ˆå¸Œå»é‡ã€åŸºäºOCRçš„æ–‡æœ¬æ¸…ç†å’ŒçœŸå®çš„æ–°é—»æ ‡é¢˜é•¿åº¦ã€‚é€šè¿‡å¼•å…¥å…¨å±€æ“çºµï¼Œæˆ‘ä»¬çš„æ‰©å±•è¡¥å……äº†ç°æœ‰çš„æ•°æ®é›†ï¼Œåˆ›å»ºäº†ä¸€ä¸ªåŸºå‡†DGM4+ï¼Œç”¨äºæµ‹è¯•æ£€æµ‹å™¨åœ¨å±€éƒ¨å’Œå…¨å±€æ¨ç†ä¸Šçš„èƒ½åŠ›ã€‚è¯¥èµ„æºæ—¨åœ¨åŠ å¼ºå¯¹å¤šæ¨¡æ€æ¨¡å‹(å¦‚HAMMER)çš„è¯„ä¼°ï¼Œè¿™äº›æ¨¡å‹ç›®å‰éš¾ä»¥å¤„ç†FG-BGä¸ä¸€è‡´æ€§ã€‚æˆ‘ä»¬å‘å¸ƒäº†æˆ‘ä»¬çš„DGM4+æ•°æ®é›†å’Œç”Ÿæˆè„šæœ¬ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ•°æ®é›†å¦‚DGM4ä¸»è¦å…³æ³¨å±€éƒ¨å›¾åƒç¯¡æ”¹å’Œæ–‡æœ¬ä¿®æ”¹ï¼Œå¿½ç•¥äº†å…¨å±€åœºæ™¯ä¸ä¸€è‡´æ€§ï¼Œä¾‹å¦‚å°†äººç‰©æ”¾ç½®åœ¨ä¸åˆç†çš„èƒŒæ™¯ä¸­ã€‚è¿™ç§å…¨å±€ä¸ä¸€è‡´æ€§åœ¨å®é™…ä¼ªé€ ä¿¡æ¯ä¸­è¶Šæ¥è¶Šå¸¸è§ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ£€æµ‹æ­¤ç±»ä¼ªé€ ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ‰©å±•DGM4æ•°æ®é›†ï¼Œå¼•å…¥åŒ…å«å‰æ™¯-èƒŒæ™¯(FG-BG)ä¸åŒ¹é…çš„æ ·æœ¬ï¼Œå¹¶ç»“åˆæ–‡æœ¬æ“çºµï¼Œä»è€Œåˆ›å»ºä¸€ä¸ªæ›´å…·æŒ‘æˆ˜æ€§å’Œç°å®æ€§çš„å¤šæ¨¡æ€ä¼ªé€ æ£€æµ‹åŸºå‡†ã€‚æ ¸å¿ƒåœ¨äºæ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­å…¨å±€åœºæ™¯ä¸ä¸€è‡´æ€§çš„ä¼ªé€ æ‰‹æ³•ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDGM4+æ•°æ®é›†çš„ç”Ÿæˆæµç¨‹ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) ä½¿ç”¨OpenAIçš„gpt-image-1æ¨¡å‹ç”Ÿæˆå›¾åƒï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºï¼Œå°†çœŸå®äººç‰©æ”¾ç½®åœ¨è’è°¬æˆ–ä¸å¯èƒ½çš„èƒŒæ™¯ä¸­ã€‚2) ç”Ÿæˆä¸‰ç§ç±»å‹çš„æ ‡é¢˜ï¼šå­—é¢ã€æ–‡æœ¬å±æ€§å’Œæ–‡æœ¬åˆ†å‰²ï¼Œä¸å›¾åƒè¿›è¡Œç»„åˆã€‚3) è¿›è¡Œä¸¥æ ¼çš„è´¨é‡æ§åˆ¶ï¼ŒåŒ…æ‹¬äººè„¸æ•°é‡æ§åˆ¶ã€æ„ŸçŸ¥å“ˆå¸Œå»é‡ã€OCRæ–‡æœ¬æ¸…ç†å’Œæ ‡é¢˜é•¿åº¦æ§åˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šDGM4+çš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†å…¨å±€åœºæ™¯ä¸ä¸€è‡´æ€§ä½œä¸ºä¸€ç§æ–°çš„ä¼ªé€ ç±»å‹ï¼Œå¼¥è¡¥äº†ç°æœ‰æ•°æ®é›†çš„ä¸è¶³ã€‚æ­¤å¤–ï¼Œç»“åˆæ–‡æœ¬æ“çºµï¼Œåˆ›å»ºäº†æ›´å¤æ‚çš„å¤šæ¨¡æ€ä¼ªé€ åœºæ™¯ï¼Œæ›´è´´è¿‘çœŸå®ä¸–ç•Œçš„ä¼ªé€ ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å›¾åƒç”Ÿæˆæ–¹é¢ï¼Œä½¿ç”¨OpenAIçš„gpt-image-1æ¨¡å‹ï¼Œå¹¶è®¾è®¡äº†è¯¦ç»†çš„æç¤ºï¼Œä»¥æ§åˆ¶ç”Ÿæˆå›¾åƒçš„å†…å®¹å’Œé£æ ¼ã€‚åœ¨è´¨é‡æ§åˆ¶æ–¹é¢ï¼Œé‡‡ç”¨äº†ä¸€ç³»åˆ—ç­–ç•¥ï¼ŒåŒ…æ‹¬é™åˆ¶å›¾åƒä¸­äººè„¸çš„æ•°é‡ï¼ˆ1-3ä¸ªï¼‰ã€ä½¿ç”¨æ„ŸçŸ¥å“ˆå¸Œè¿›è¡Œé‡å¤æ•°æ®åˆ é™¤ã€ä½¿ç”¨OCRæŠ€æœ¯æ¸…ç†æ–‡æœ¬é”™è¯¯ä»¥åŠé™åˆ¶æ ‡é¢˜é•¿åº¦ï¼Œä»¥ç¡®ä¿æ•°æ®é›†çš„è´¨é‡å’ŒçœŸå®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DGM4+æ•°æ®é›†é€šè¿‡å¼•å…¥å…¨å±€åœºæ™¯ä¸ä¸€è‡´æ€§ï¼Œæ˜¾è‘—æå‡äº†å¤šæ¨¡æ€ä¼ªé€ æ£€æµ‹çš„éš¾åº¦ã€‚å®éªŒè¡¨æ˜ï¼Œç°æœ‰æ¨¡å‹å¦‚HAMMERåœ¨DGM4+æ•°æ®é›†ä¸Šçš„æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œè¡¨æ˜è¯¥æ•°æ®é›†èƒ½å¤Ÿæœ‰æ•ˆè¯„ä¼°æ¨¡å‹å¯¹å…¨å±€æ¨ç†çš„èƒ½åŠ›ã€‚DGM4+ä¸ºå¼€å‘æ›´å¼ºå¤§çš„å¤šæ¨¡æ€ä¼ªé€ æ£€æµ‹æ¨¡å‹æä¾›äº†æ–°çš„åŸºå‡†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DGM4+æ•°æ®é›†å¯ç”¨äºè®­ç»ƒå’Œè¯„ä¼°å¤šæ¨¡æ€ä¼ªé€ æ£€æµ‹æ¨¡å‹ï¼Œæé«˜æ¨¡å‹å¯¹å…¨å±€åœºæ™¯ä¸ä¸€è‡´æ€§çš„è¯†åˆ«èƒ½åŠ›ã€‚è¯¥æ•°æ®é›†æœ‰åŠ©äºå¼€å‘æ›´é²æ£’å’Œå¯é çš„ä¼ªé€ æ£€æµ‹ç³»ç»Ÿï¼Œåº”ç”¨äºç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸ã€æ–°é—»çœŸå®æ€§éªŒè¯ç­‰é¢†åŸŸï¼Œä»è€Œå‡å°‘è™šå‡ä¿¡æ¯ä¼ æ’­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid advances in generative models have significantly lowered the barrier to producing convincing multimodal disinformation. Fabricated images and manipulated captions increasingly co-occur to create persuasive false narratives. While the Detecting and Grounding Multi-Modal Media Manipulation (DGM4) dataset established a foundation for research in this area, it is restricted to local manipulations such as face swaps, attribute edits, and caption changes. This leaves a critical gap: global inconsistencies, such as mismatched foregrounds and backgrounds, which are now prevalent in real-world forgeries. To address this, we extend DGM4 with 5,000 high-quality samples that introduce Foreground-Background (FG-BG) mismatches and their hybrids with text manipulations. Using OpenAI's gpt-image-1 and carefully designed prompts, we generate human-centric news-style images where authentic figures are placed into absurd or impossible backdrops (e.g., a teacher calmly addressing students on the surface of Mars). Captions are produced under three conditions: literal, text attribute, and text split, yielding three new manipulation categories: FG-BG, FG-BG+TA, and FG-BG+TS. Quality control pipelines enforce one-to-three visible faces, perceptual hash deduplication, OCR-based text scrubbing, and realistic headline length. By introducing global manipulations, our extension complements existing datasets, creating a benchmark DGM4+ that tests detectors on both local and global reasoning. This resource is intended to strengthen evaluation of multimodal models such as HAMMER, which currently struggle with FG-BG inconsistencies. We release our DGM4+ dataset and generation script at https://github.com/Gaganx0/DGM4plus

