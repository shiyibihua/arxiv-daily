---
layout: default
title: Split-Fuse-Transport: Annotation-Free Saliency via Dual Clustering and Optimal Transport Alignment
---

# Split-Fuse-Transport: Annotation-Free Saliency via Dual Clustering and Optimal Transport Alignment

**arXiv**: [2510.17484v1](https://arxiv.org/abs/2510.17484) | [PDF](https://arxiv.org/pdf/2510.17484.pdf)

**ä½œè€…**: Muhammad Umer Ramzan, Ali Zia, Abdelwahed Khamis, Noman Ali, Usman Ali, Wei Xiang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPOTNetæ–¹æ³•ï¼Œé€šè¿‡åŒèšç±»å’Œæœ€ä¼˜ä¼ è¾“å®žçŽ°æ— æ ‡æ³¨æ˜¾è‘—ç›®æ ‡æ£€æµ‹**

**å…³é”®è¯**: `æ˜¾è‘—ç›®æ ‡æ£€æµ‹` `æ— ç›‘ç£å­¦ä¹ ` `æœ€ä¼˜ä¼ è¾“` `åŒèšç±»` `ä¼ªæŽ©ç ç”Ÿæˆ` `è®¡ç®—æœºè§†è§‰`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ˜¾è‘—ç›®æ ‡æ£€æµ‹éœ€å¯é ä¼ªæŽ©ç ï¼Œä½†çŽ°æœ‰æ–¹æ³•åœ¨åŽŸåž‹è´¨é‡å’Œå…¨å±€ä¸€è‡´æ€§ä¸Šä¸è¶³
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ç†µå¼•å¯¼åŒèšç±»ï¼Œé«˜ç†µåƒç´ è°±èšç±»ã€ä½Žç†µåƒç´ kå‡å€¼ï¼Œå¹¶ç”¨æœ€ä¼˜ä¼ è¾“å¯¹é½
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨äº”ä¸ªåŸºå‡†ä¸Šï¼ŒF-measureä¼˜äºŽæ— ç›‘ç£æ–¹æ³•26%ã€å¼±ç›‘ç£æ–¹æ³•36%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Salient object detection (SOD) aims to segment visually prominent regions in
> images and serves as a foundational task for various computer vision
> applications. We posit that SOD can now reach near-supervised accuracy without
> a single pixel-level label, but only when reliable pseudo-masks are available.
> We revisit the prototype-based line of work and make two key observations.
> First, boundary pixels and interior pixels obey markedly different geometry;
> second, the global consistency enforced by optimal transport (OT) is
> underutilized if prototype quality is weak. To address this, we introduce
> POTNet, an adaptation of Prototypical Optimal Transport that replaces POT's
> single k-means step with an entropy-guided dual-clustering head: high-entropy
> pixels are organized by spectral clustering, low-entropy pixels by k-means, and
> the two prototype sets are subsequently aligned by OT. This
> split-fuse-transport design yields sharper, part-aware pseudo-masks in a single
> forward pass, without handcrafted priors. Those masks supervise a standard
> MaskFormer-style encoder-decoder, giving rise to AutoSOD, an end-to-end
> unsupervised SOD pipeline that eliminates SelfMask's offline voting yet
> improves both accuracy and training efficiency. Extensive experiments on five
> benchmarks show that AutoSOD outperforms unsupervised methods by up to 26% and
> weakly supervised methods by up to 36% in F-measure, further narrowing the gap
> to fully supervised models.

