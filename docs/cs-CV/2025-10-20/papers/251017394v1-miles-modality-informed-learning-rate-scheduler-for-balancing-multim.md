---
layout: default
title: MILES: Modality-Informed Learning Rate Scheduler for Balancing Multimodal Learning
---

# MILES: Modality-Informed Learning Rate Scheduler for Balancing Multimodal Learning

**arXiv**: [2510.17394v1](https://arxiv.org/abs/2510.17394) | [PDF](https://arxiv.org/pdf/2510.17394.pdf)

**ä½œè€…**: Alejandro Guerra-Manzanares, Farah E. Shamout

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMILESå­¦ä¹ çŽ‡è°ƒåº¦å™¨ä»¥å¹³è¡¡å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„æ¨¡æ€è¿‡æ‹Ÿåˆé—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `å­¦ä¹ çŽ‡è°ƒåº¦` `æ¨¡æ€å¹³è¡¡` `è”åˆèžåˆæ¨¡åž‹` `æ¡ä»¶åˆ©ç”¨çŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€ç½‘ç»œè®­ç»ƒå¸¸å› æ¨¡æ€è¿‡æ‹Ÿåˆå¯¼è‡´æ€§èƒ½ä¸ä½³ï¼Œä¾èµ–å•ä¸€æ¨¡æ€
2. MILESåˆ©ç”¨æ¨¡æ€æ¡ä»¶åˆ©ç”¨çŽ‡å·®å¼‚åŠ¨æ€è°ƒæ•´å­¦ä¹ çŽ‡ï¼Œå¹³è¡¡å„æ¨¡æ€å­¦ä¹ é€Ÿåº¦
3. åœ¨å››ä¸ªå¤šæ¨¡æ€ä»»åŠ¡ä¸­ä¼˜äºŽä¸ƒç§åŸºçº¿ï¼Œæå‡å¤šæ¨¡æ€å’Œå•æ¨¡æ€é¢„æµ‹æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The aim of multimodal neural networks is to combine diverse data sources,
> referred to as modalities, to achieve enhanced performance compared to relying
> on a single modality. However, training of multimodal networks is typically
> hindered by modality overfitting, where the network relies excessively on one
> of the available modalities. This often yields sub-optimal performance,
> hindering the potential of multimodal learning and resulting in marginal
> improvements relative to unimodal models. In this work, we present the
> Modality-Informed Learning ratE Scheduler (MILES) for training multimodal joint
> fusion models in a balanced manner. MILES leverages the differences in
> modality-wise conditional utilization rates during training to effectively
> balance multimodal learning. The learning rate is dynamically adjusted during
> training to balance the speed of learning from each modality by the multimodal
> model, aiming for enhanced performance in both multimodal and unimodal
> predictions. We extensively evaluate MILES on four multimodal joint fusion
> tasks and compare its performance to seven state-of-the-art baselines. Our
> results show that MILES outperforms all baselines across all tasks and fusion
> methods considered in our study, effectively balancing modality usage during
> training. This results in improved multimodal performance and stronger modality
> encoders, which can be leveraged when dealing with unimodal samples or absent
> modalities. Overall, our work highlights the impact of balancing multimodal
> learning on improving model performance.

