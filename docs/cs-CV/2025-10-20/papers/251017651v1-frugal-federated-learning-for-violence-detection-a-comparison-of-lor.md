---
layout: default
title: Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs
---

# Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs

**arXiv**: [2510.17651v1](https://arxiv.org/abs/2510.17651) | [PDF](https://arxiv.org/pdf/2510.17651.pdf)

**ä½œè€…**: SÃ©bastien Thuau, Siba Haidar, Ayush Bajracharya, Rachid Chelouah

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¯”è¾ƒLoRAè°ƒä¼˜è§†è§‰è¯­è¨€æ¨¡åž‹ä¸Žä¸ªæ€§åŒ–CNNåœ¨è”é‚¦æš´åŠ›æ£€æµ‹ä¸­çš„æ€§èƒ½ä¸Žèƒ½æ•ˆ**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `æš´åŠ›æ£€æµ‹` `è§†è§‰è¯­è¨€æ¨¡åž‹` `ä½Žç§©é€‚åº”` `3Då·ç§¯ç¥žç»ç½‘ç»œ` `èƒ½æ•ˆåˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåœ¨éžç‹¬ç«‹åŒåˆ†å¸ƒè”é‚¦å­¦ä¹ è®¾ç½®ä¸‹ï¼Œå®žçŽ°é«˜ç²¾åº¦ã€ä½Žèƒ½è€—çš„æš´åŠ›æ£€æµ‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¯¹æ¯”é›¶æ ·æœ¬/è”é‚¦å¾®è°ƒè§†è§‰è¯­è¨€æ¨¡åž‹ä¸Žä¸ªæ€§åŒ–è®­ç»ƒç´§å‡‘3Då·ç§¯ç¥žç»ç½‘ç»œã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šä¸¤ç§æ–¹æ³•å‡†ç¡®çŽ‡è¶…90%ï¼ŒCNN3Dåœ¨ROC AUCå’Œèƒ½è€—ä¸Šç•¥ä¼˜ï¼ŒVLMsé€‚åˆä¸Šä¸‹æ–‡æŽ¨ç†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We examine frugal federated learning approaches to violence detection by
> comparing two complementary strategies: (i) zero-shot and federated fine-tuning
> of vision-language models (VLMs), and (ii) personalized training of a compact
> 3D convolutional neural network (CNN3D). Using LLaVA-7B and a 65.8M parameter
> CNN3D as representative cases, we evaluate accuracy, calibration, and energy
> usage under realistic non-IID settings.
>   Both approaches exceed 90% accuracy. CNN3D slightly outperforms Low-Rank
> Adaptation(LoRA)-tuned VLMs in ROC AUC and log loss, while using less energy.
> VLMs remain favorable for contextual reasoning and multimodal inference. We
> quantify energy and CO$_2$ emissions across training and inference, and analyze
> sustainability trade-offs for deployment.
>   To our knowledge, this is the first comparative study of LoRA-tuned
> vision-language models and personalized CNNs for federated violence detection,
> with an emphasis on energy efficiency and environmental metrics.
>   These findings support a hybrid model: lightweight CNNs for routine
> classification, with selective VLM activation for complex or descriptive
> scenarios. The resulting framework offers a reproducible baseline for
> responsible, resource-aware AI in video surveillance, with extensions toward
> real-time, multimodal, and lifecycle-aware systems.

