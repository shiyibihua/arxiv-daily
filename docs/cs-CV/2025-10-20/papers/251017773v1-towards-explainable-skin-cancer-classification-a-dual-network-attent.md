---
layout: default
title: Towards Explainable Skin Cancer Classification: A Dual-Network Attention Model with Lesion Segmentation and Clinical Metadata Fusion
---

# Towards Explainable Skin Cancer Classification: A Dual-Network Attention Model with Lesion Segmentation and Clinical Metadata Fusion

**arXiv**: [2510.17773v1](https://arxiv.org/abs/2510.17773) | [PDF](https://arxiv.org/pdf/2510.17773.pdf)

**ä½œè€…**: Md. Enamul Atiq, Shaikh Anowarul Fattah

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒç½‘ç»œæ³¨æ„åŠ›æ¨¡åž‹ï¼Œèžåˆç—…ç¶åˆ†å‰²ä¸Žä¸´åºŠå…ƒæ•°æ®ä»¥æå‡çš®è‚¤ç™Œåˆ†ç±»å‡†ç¡®æ€§ä¸Žå¯è§£é‡Šæ€§ã€‚**

**å…³é”®è¯**: `çš®è‚¤ç™Œåˆ†ç±»` `ç—…ç¶åˆ†å‰²` `æ³¨æ„åŠ›æœºåˆ¶` `ä¸´åºŠå…ƒæ•°æ®èžåˆ` `å¯è§£é‡Šæ€§AI` `æ·±åº¦å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çš®è‚¤ç™Œè¯Šæ–­é¢ä¸´ç±»å†…é«˜å˜å¼‚æ€§ä¸Žç±»é—´ç»†å¾®å·®å¼‚ï¼Œä¸”æ·±åº¦å­¦ä¹ æ¨¡åž‹å¸¸ä¸ºé»‘ç®±ï¼Œå½±å“ä¸´åºŠä¿¡ä»»ã€‚
2. æ–¹æ³•é‡‡ç”¨Deep-UNetåˆ†å‰²ç—…ç¶ï¼ŒåŒDenseNet201ç¼–ç å™¨èžåˆç‰¹å¾ï¼Œå¹¶é›†æˆä¸´åºŠå…ƒæ•°æ®ä»¥å¢žå¼ºåˆ†ç±»ã€‚
3. åœ¨HAM10000ç­‰æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæ¨¡åž‹åœ¨åˆ†å‰²ä¸Žåˆ†ç±»æ€§èƒ½ä¸Šä¼˜äºŽåŸºçº¿ï¼Œå¹¶é€šè¿‡Grad-CAMçƒ­å›¾æå‡å¯è§£é‡Šæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Skin cancer is a life-threatening disease where early detection significantly
> improves patient outcomes. Automated diagnosis from dermoscopic images is
> challenging due to high intra-class variability and subtle inter-class
> differences. Many deep learning models operate as "black boxes," limiting
> clinical trust. In this work, we propose a dual-encoder attention-based
> framework that leverages both segmented lesions and clinical metadata to
> enhance skin lesion classification in terms of both accuracy and
> interpretability. A novel Deep-UNet architecture with Dual Attention Gates
> (DAG) and Atrous Spatial Pyramid Pooling (ASPP) is first employed to segment
> lesions. The classification stage uses two DenseNet201 encoders-one on the
> original image and another on the segmented lesion whose features are fused via
> multi-head cross-attention. This dual-input design guides the model to focus on
> salient pathological regions. In addition, a transformer-based module
> incorporates patient metadata (age, sex, lesion site) into the prediction. We
> evaluate our approach on the HAM10000 dataset and the ISIC 2018 and 2019
> challenges. The proposed method achieves state-of-the-art segmentation
> performance and significantly improves classification accuracy and average AUC
> compared to baseline models. To validate our model's reliability, we use
> Gradient-weighted Class Activation Mapping (Grad-CAM) to generate heatmaps.
> These visualizations confirm that our model's predictions are based on the
> lesion area, unlike models that rely on spurious background features. These
> results demonstrate that integrating precise lesion segmentation and clinical
> data with attention-based fusion leads to a more accurate and interpretable
> skin cancer classification model.

