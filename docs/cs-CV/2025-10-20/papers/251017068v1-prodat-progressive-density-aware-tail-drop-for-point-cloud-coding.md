---
layout: default
title: ProDAT: Progressive Density-Aware Tail-Drop for Point Cloud Coding
---

# ProDAT: Progressive Density-Aware Tail-Drop for Point Cloud Coding

**arXiv**: [2510.17068v1](https://arxiv.org/abs/2510.17068) | [PDF](https://arxiv.org/pdf/2510.17068.pdf)

**ä½œè€…**: Zhe Luo, Wenjing Jia, Stuart Perry

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºProDATå¯†åº¦æ„ŸçŸ¥å°¾ä¸¢æœºåˆ¶ï¼Œå®žçŽ°ç‚¹äº‘æ¸è¿›å¼ç¼–ç ä»¥åº”å¯¹å¸¦å®½é™åˆ¶**

**å…³é”®è¯**: `ç‚¹äº‘ç¼–ç ` `æ¸è¿›è§£ç ` `å¯†åº¦æ„ŸçŸ¥` `å­¦ä¹ åž‹åŽ‹ç¼©` `ä¸‰ç»´æ•°æ®å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç‚¹äº‘æ•°æ®é‡å¤§ï¼Œå›ºå®šæ½œåœ¨è¡¨ç¤ºä¸æ”¯æŒæ¸è¿›è§£ç ï¼Œé˜»ç¢èµ„æºå—é™çŽ¯å¢ƒåº”ç”¨
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨å¯†åº¦ä¿¡æ¯æŒ‡å¯¼è‡ªé€‚åº”è§£ç æ½œåœ¨ç‰¹å¾å’Œåæ ‡ï¼Œå®žçŽ°å¤šæ¯”ç‰¹çŽ‡æ¸è¿›ç¼–ç 
3. å®žéªŒæ•ˆæžœï¼šåœ¨åŸºå‡†æ•°æ®é›†ä¸Šï¼ŒProDATå®žçŽ°æ¸è¿›ç¼–ç ï¼ŒBD-rateæå‡è¶…28.6%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Three-dimensional (3D) point clouds are becoming increasingly vital in
> applications such as autonomous driving, augmented reality, and immersive
> communication, demanding real-time processing and low latency. However, their
> large data volumes and bandwidth constraints hinder the deployment of
> high-quality services in resource-limited environments. Progres- sive coding,
> which allows for decoding at varying levels of detail, provides an alternative
> by allowing initial partial decoding with subsequent refinement. Although
> recent learning-based point cloud geometry coding methods have achieved notable
> success, their fixed latent representation does not support progressive
> decoding. To bridge this gap, we propose ProDAT, a novel density-aware
> tail-drop mechanism for progressive point cloud coding. By leveraging density
> information as a guidance signal, latent features and coordinates are decoded
> adaptively based on their significance, therefore achieving progressive
> decoding at multiple bitrates using one single model. Experimental results on
> benchmark datasets show that the proposed ProDAT not only enables progressive
> coding but also achieves superior coding efficiency compared to
> state-of-the-art learning-based coding techniques, with over 28.6% BD-rate
> improvement for PSNR- D2 on SemanticKITTI and over 18.15% for ShapeNet

