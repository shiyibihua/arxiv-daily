---
layout: default
title: Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization
---

# Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization

**arXiv**: [2510.17501v1](https://arxiv.org/abs/2510.17501) | [PDF](https://arxiv.org/pdf/2510.17501.pdf)

**ä½œè€…**: Yuanli Wu, Long Zhang, Yue Du, Bin Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè§„åˆ™å¼•å¯¼ä¼ªæ ‡ç­¾è¯„åˆ†çš„é›¶æ ·æœ¬è§†é¢‘æ‘˜è¦æ–¹æ³•ï¼Œä»¥æå‡æ³›åŒ–æ€§å’Œè¯­ä¹‰æ•æ‰èƒ½åŠ›**

**å…³é”®è¯**: `é›¶æ ·æœ¬è§†é¢‘æ‘˜è¦` `ä¼ªæ ‡ç­¾è¯„åˆ†` `ä¸Šä¸‹æ–‡æ„ŸçŸ¥æç¤º` `å¤§è¯­è¨€æ¨¡åž‹åº”ç”¨` `è§„åˆ™å¼•å¯¼è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–å¯†é›†æ ‡æ³¨æˆ–æ‰‹å·¥æç¤ºï¼Œæ³›åŒ–æ€§å·®ä¸”æˆæœ¬é«˜
2. åˆ©ç”¨å°‘é‡çœŸå®žæ ‡æ³¨ç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œæž„å»ºæ•°æ®é›†è‡ªé€‚åº”è¯„åˆ†è§„åˆ™æŒ‡å¯¼åœºæ™¯è¯„ä¼°
3. åœ¨SumMeå’ŒTVSumä¸ŠF1åˆ†æ•°è¾¾57.58å’Œ63.05ï¼Œè¶…è¶Šæ— ç›‘ç£å’Œé›¶æ ·æœ¬åŸºçº¿

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> With the rapid proliferation of video content across social media,
> surveillance, and education platforms, efficiently summarizing long videos into
> concise yet semantically faithful surrogates has become increasingly vital.
> Existing supervised methods achieve strong in-domain accuracy by learning from
> dense annotations but suffer from high labeling costs and limited cross-dataset
> generalization, while unsupervised approaches, though label-free, often fail to
> capture high-level human semantics and fine-grained narrative cues. More
> recently, zero-shot prompting pipelines have leveraged large language models
> (LLMs) for training-free video summarization, yet remain highly sensitive to
> handcrafted prompt templates and dataset-specific score normalization. To
> overcome these limitations, we introduce a rubric-guided, pseudo-labeled
> prompting framework that transforms a small subset of ground-truth annotations
> into high-confidence pseudo labels, which are aggregated into structured,
> dataset-adaptive scoring rubrics guiding interpretable scene evaluation. During
> inference, first and last segments are scored based solely on their
> descriptions, whereas intermediate ones incorporate brief contextual summaries
> of adjacent scenes to assess narrative progression and redundancy. This
> contextual prompting enables the LLM to balance local salience and global
> coherence without parameter tuning. On SumMe and TVSum, our method achieves F1
> scores of \textbf{57.58} and \textbf{63.05}, surpassing unsupervised and prior
> zero-shot baselines while approaching supervised performance. The results
> demonstrate that rubric-guided pseudo labeling effectively stabilizes LLM-based
> scoring and establishes a general, interpretable zero-shot paradigm for video
> summarization.

