---
layout: default
title: Shape-aware Inertial Poser: Motion Tracking for Humans with Diverse Shapes Using Sparse Inertial Sensors
---

# Shape-aware Inertial Poser: Motion Tracking for Humans with Diverse Shapes Using Sparse Inertial Sensors

**arXiv**: [2510.17101v1](https://arxiv.org/abs/2510.17101) | [PDF](https://arxiv.org/pdf/2510.17101.pdf)

**ä½œè€…**: Lu Yin, Ziying Shi, Yinghao Wu, Xinyu Yi, Feng Xu, Shihui Guo

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºShape-aware Inertial Poserä»¥è§£å†³ç¨€ç–æƒ¯æ€§ä¼ æ„Ÿå™¨åœ¨å¤šæ ·åŒ–äººä½“å½¢çŠ¶ä¸‹çš„è¿åŠ¨æ•æ‰é—®é¢˜**

**å…³é”®è¯**: `æƒ¯æ€§è¿åŠ¨æ•æ‰` `èº«ä½“å½¢çŠ¶ä¼°è®¡` `ä¼ æ„Ÿå™¨æµ‹é‡åˆ†è§£` `å›žå½’æ¨¡åž‹` `ç‰©ç†ä¼˜åŒ–` `å¤šæ ·åŒ–ä½“åž‹æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–æ¨¡æ¿æˆäººèº«ä½“å½¢çŠ¶ï¼Œéš¾ä»¥æ³›åŒ–åˆ°ä¸åŒä½“åž‹å¦‚å„¿ç«¥ï¼Œå› èº«ä½“å½¢çŠ¶å˜åŒ–å½±å“IMUåŠ é€Ÿåº¦æµ‹é‡
2. æ–¹æ³•åˆ†è§£ä¼ æ„Ÿå™¨æµ‹é‡ä¸ºå½¢çŠ¶å’Œå§¿æ€ç›¸å…³éƒ¨åˆ†ï¼Œé€šè¿‡å›žå½’æ¨¡åž‹è¡¥å¿å½¢çŠ¶å·®å¼‚å¹¶ä¼°è®¡å…¨å±€è¿åŠ¨
3. å®žéªŒåŸºäºŽé¦–ä¸ªåŒ…å«ä¸åŒä½“åž‹ä¸ªä½“çš„IMUæ•°æ®é›†ï¼ŒéªŒè¯SAIPèƒ½æœ‰æ•ˆå¤„ç†å¤šæ ·åŒ–èº«ä½“å½¢çŠ¶çš„è¿åŠ¨æ•æ‰

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Human motion capture with sparse inertial sensors has gained significant
> attention recently. However, existing methods almost exclusively rely on a
> template adult body shape to model the training data, which poses challenges
> when generalizing to individuals with largely different body shapes (such as a
> child). This is primarily due to the variation in IMU-measured acceleration
> caused by changes in body shape. To fill this gap, we propose Shape-aware
> Inertial Poser (SAIP), the first solution considering body shape differences in
> sparse inertial-based motion capture. Specifically, we decompose the sensor
> measurements related to shape and pose in order to effectively model their
> joint correlations. Firstly, we train a regression model to transfer the
> IMU-measured accelerations of a real body to match the template adult body
> model, compensating for the shape-related sensor measurements. Then, we can
> easily follow the state-of-the-art methods to estimate the full body motions of
> the template-shaped body. Finally, we utilize a second regression model to map
> the joint velocities back to the real body, combined with a shape-aware
> physical optimization strategy to calculate global motions on the subject.
> Furthermore, our method relies on body shape awareness, introducing the first
> inertial shape estimation scheme. This is accomplished by modeling the
> shape-conditioned IMU-pose correlation using an MLP-based network. To validate
> the effectiveness of SAIP, we also present the first IMU motion capture dataset
> containing individuals of different body sizes. This dataset features 10
> children and 10 adults, with heights ranging from 110 cm to 190 cm, and a total
> of 400 minutes of paired IMU-Motion samples. Extensive experimental results
> demonstrate that SAIP can effectively handle motion capture tasks for diverse
> body shapes. The code and dataset are available at
> https://github.com/yinlu5942/SAIP.

