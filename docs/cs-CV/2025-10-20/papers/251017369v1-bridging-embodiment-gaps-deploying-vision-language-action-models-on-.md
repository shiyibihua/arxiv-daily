---
layout: default
title: Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots
---

# Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots

**arXiv**: [2510.17369v1](https://arxiv.org/abs/2510.17369) | [PDF](https://arxiv.org/pdf/2510.17369.pdf)

**ä½œè€…**: Haochen Su, Cristian Meo, Francesco Stella, Andrea Peirone, Kai Junge, Josie Hughes

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**éƒ¨ç½²è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹äºŽè½¯æœºå™¨äººï¼Œå®žçŽ°å®‰å…¨äººæœºäº¤äº’**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `è½¯æœºå™¨äºº` `å¾®è°ƒéƒ¨ç½²` `äººæœºäº¤äº’` `å®‰å…¨æŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹éƒ¨ç½²äºŽåˆšæ€§æœºå™¨äººï¼Œç¼ºä¹å®‰å…¨äº¤äº’èƒ½åŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºç»“æž„åŒ–å¾®è°ƒæµç¨‹ï¼Œè¯„ä¼°OpenVLA-OFTå’ŒÏ€_0æ¨¡åž‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå¾®è°ƒåŽè½¯æœºå™¨äººæ€§èƒ½ä¸Žåˆšæ€§æœºå™¨äººç›¸å½“ï¼Œæ”¯æŒå®‰å…¨äº¤äº’ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Robotic systems are increasingly expected to operate in human-centered,
> unstructured environments where safety, adaptability, and generalization are
> essential. Vision-Language-Action (VLA) models have been proposed as a language
> guided generalized control framework for real robots. However, their deployment
> has been limited to conventional serial link manipulators. Coupled by their
> rigidity and unpredictability of learning based control, the ability to safely
> interact with the environment is missing yet critical. In this work, we present
> the deployment of a VLA model on a soft continuum manipulator to demonstrate
> autonomous safe human-robot interaction. We present a structured finetuning and
> deployment pipeline evaluating two state-of-the-art VLA models (OpenVLA-OFT and
> $\pi_0$) across representative manipulation tasks, and show while
> out-of-the-box policies fail due to embodiment mismatch, through targeted
> finetuning the soft robot performs equally to the rigid counterpart. Our
> findings highlight the necessity of finetuning for bridging embodiment gaps,
> and demonstrate that coupling VLA models with soft robots enables safe and
> flexible embodied AI in human-shared environments.

