---
layout: default
title: PAGE-4D: Disentangled Pose and Geometry Estimation for 4D Perception
---

# PAGE-4D: Disentangled Pose and Geometry Estimation for 4D Perception

**arXiv**: [2510.17568v1](https://arxiv.org/abs/2510.17568) | [PDF](https://arxiv.org/pdf/2510.17568.pdf)

**ä½œè€…**: Kaichen Zhou, Yuhan Wang, Grace Chen, Xinhai Chang, Gaspard Beaudouin, Fangneng Zhan, Paul Pu Liang, Mengyu Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPAGE-4Dä»¥è§£å†³åŠ¨æ€åœºæ™¯ä¸­ç›¸æœºå§¿æ€ä¸Žå‡ ä½•é‡å»ºçš„å†²çª**

**å…³é”®è¯**: `4Dæ„ŸçŸ¥` `ç›¸æœºå§¿æ€ä¼°è®¡` `æ·±åº¦é¢„æµ‹` `ç‚¹äº‘é‡å»º` `åŠ¨æ€åœºæ™¯å¤„ç†` `å¤šä»»åŠ¡å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé™æ€æ¨¡åž‹åœ¨åŠ¨æ€åœºæ™¯ä¸­è¡¨çŽ°ä¸ä½³ï¼Œä»»åŠ¡é—´å­˜åœ¨å†²çª
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨åŠ¨æ€æ„ŸçŸ¥èšåˆå™¨è§£è€¦é™æ€ä¸ŽåŠ¨æ€ä¿¡æ¯
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŠ¨æ€åœºæ™¯ä¸­ä¼˜äºŽVGGTï¼Œæå‡å§¿æ€ä¼°è®¡ä¸Žé‡å»ºç²¾åº¦

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent 3D feed-forward models, such as the Visual Geometry Grounded
> Transformer (VGGT), have shown strong capability in inferring 3D attributes of
> static scenes. However, since they are typically trained on static datasets,
> these models often struggle in real-world scenarios involving complex dynamic
> elements, such as moving humans or deformable objects like umbrellas. To
> address this limitation, we introduce PAGE-4D, a feedforward model that extends
> VGGT to dynamic scenes, enabling camera pose estimation, depth prediction, and
> point cloud reconstruction -- all without post-processing. A central challenge
> in multi-task 4D reconstruction is the inherent conflict between tasks:
> accurate camera pose estimation requires suppressing dynamic regions, while
> geometry reconstruction requires modeling them. To resolve this tension, we
> propose a dynamics-aware aggregator that disentangles static and dynamic
> information by predicting a dynamics-aware mask -- suppressing motion cues for
> pose estimation while amplifying them for geometry reconstruction. Extensive
> experiments show that PAGE-4D consistently outperforms the original VGGT in
> dynamic scenarios, achieving superior results in camera pose estimation,
> monocular and video depth estimation, and dense point map reconstruction.

