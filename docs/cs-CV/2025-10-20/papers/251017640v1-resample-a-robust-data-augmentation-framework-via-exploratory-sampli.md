---
layout: default
title: RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation
---

# RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation

**arXiv**: [2510.17640v1](https://arxiv.org/abs/2510.17640) | [PDF](https://arxiv.org/pdf/2510.17640.pdf)

**ä½œè€…**: Yuquan Xue, Guanxing Lu, Zhenyu Wu, Chuanrui Zhang, Bofang Jia, Zhengyi Gu, Yansong Tang, Ziwei Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRESampleæ¡†æž¶ï¼Œé€šè¿‡æŽ¢ç´¢æ€§é‡‡æ ·å¢žå¼ºæœºå™¨äººæ“ä½œä¸­è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹çš„é²æ£’æ€§ã€‚**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `æ•°æ®å¢žå¼º` `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `ç¦»çº¿å¼ºåŒ–å­¦ä¹ ` `åˆ†å¸ƒå¤–çŠ¶æ€` `æŽ¢ç´¢æ€§é‡‡æ ·`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ¨¡ä»¿å­¦ä¹ æ•°æ®é›†ç¼ºä¹å¤±è´¥å’Œæ¢å¤æ•°æ®ï¼Œå¯¼è‡´æ¨¡åž‹åœ¨åˆ†å¸ƒå¤–çŠ¶æ€è¡¨çŽ°ä¸ä½³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ è¯†åˆ«æ¬¡ä¼˜åŠ¨ä½œï¼Œå¹¶é€šè¿‡æŽ¢ç´¢æ€§é‡‡æ ·è‡ªåŠ¨æ‰©å……OODæ•°æ®ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨LIBEROåŸºå‡†å’ŒçœŸå®žä»»åŠ¡ä¸­éªŒè¯ï¼Œæå‡æ¨¡åž‹ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language-Action models (VLAs) have demonstrated remarkable performance
> on complex robotic manipulation tasks through imitation learning. However,
> existing imitation learning datasets contain only successful trajectories and
> lack failure or recovery data, especially for out-of-distribution (OOD) states
> where the robot deviates from the main policy due to minor perturbations or
> errors, leading VLA models to struggle with states deviating from the training
> distribution. To this end, we propose an automated OOD data augmentation
> framework named RESample through exploratory sampling. Specifically, we first
> leverage offline reinforcement learning to obtain an action-value network that
> accurately identifies sub-optimal actions under the current manipulation
> policy. We further sample potential OOD states from trajectories via rollout,
> and design an exploratory sampling mechanism that adaptively incorporates these
> action proxies into the training dataset to ensure efficiency. Subsequently,
> our framework explicitly encourages the VLAs to recover from OOD states and
> enhances their robustness against distributional shifts. We conduct extensive
> experiments on the LIBERO benchmark as well as real-world robotic manipulation
> tasks, demonstrating that RESample consistently improves the stability and
> generalization ability of VLA models.

