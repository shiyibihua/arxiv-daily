---
layout: default
title: Investigating Adversarial Robustness against Preprocessing used in Blackbox Face Recognition
---

# Investigating Adversarial Robustness against Preprocessing used in Blackbox Face Recognition

**arXiv**: [2510.17169v1](https://arxiv.org/abs/2510.17169) | [PDF](https://arxiv.org/pdf/2510.17169.pdf)

**ä½œè€…**: Roland Croft, Brian Du, Darcy Joseph, Sharath Kumar

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé¢„å¤„ç†ä¸å˜æ–¹æ³•ä»¥æå‡é»‘ç›’äººè„¸è¯†åˆ«ä¸­å¯¹æŠ—æ”»å‡»çš„è¿ç§»æ€§**

**å…³é”®è¯**: `äººè„¸è¯†åˆ«` `å¯¹æŠ—æ”»å‡»` `é»‘ç›’è®¾ç½®` `é¢„å¤„ç†æŠ€æœ¯` `è¿ç§»æ€§æå‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé»‘ç›’äººè„¸è¯†åˆ«ç³»ç»Ÿä¸­é¢„å¤„ç†å¸¸è¢«å¿½è§†ï¼Œå½±å“å¯¹æŠ—æ”»å‡»è¿ç§»æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨è¾“å…¥å˜æ¢æž„å»ºé¢„å¤„ç†ä¸å˜æ–¹æ³•ï¼Œå¢žå¼ºæ”»å‡»é²æ£’æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ”»å‡»æˆåŠŸçŽ‡æå‡è¾¾27%ï¼Œé¢„å¤„ç†é€‰æ‹©å¯é™ä½ŽæˆåŠŸçŽ‡78%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Face Recognition (FR) models have been shown to be vulnerable to adversarial
> examples that subtly alter benign facial images, exposing blind spots in these
> systems, as well as protecting user privacy. End-to-end FR systems first obtain
> preprocessed faces from diverse facial imagery prior to computing the
> similarity of the deep feature embeddings. Whilst face preprocessing is a
> critical component of FR systems, and hence adversarial attacks against them,
> we observe that this preprocessing is often overlooked in blackbox settings.
> Our study seeks to investigate the transferability of several out-of-the-box
> state-of-the-art adversarial attacks against FR when applied against different
> preprocessing techniques used in a blackbox setting. We observe that the choice
> of face detection model can degrade the attack success rate by up to 78%,
> whereas choice of interpolation method during downsampling has relatively
> minimal impacts. Furthermore, we find that the requirement for facial
> preprocessing even degrades attack strength in a whitebox setting, due to the
> unintended interaction of produced noise vectors against face detection models.
> Based on these findings, we propose a preprocessing-invariant method using
> input transformations that improves the transferability of the studied attacks
> by up to 27%. Our findings highlight the importance of preprocessing in FR
> systems, and the need for its consideration towards improving the adversarial
> generalisation of facial adversarial examples.

