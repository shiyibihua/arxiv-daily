---
layout: default
title: MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues
---

# MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues

**arXiv**: [2510.17722v1](https://arxiv.org/abs/2510.17722) | [PDF](https://arxiv.org/pdf/2510.17722.pdf)

**ä½œè€…**: Yaning Pan, Zekun Wang, Qianqian Xie, Yongqian Wen, Yuanxing Zhang, Guohui Zhang, Haoxuan Hu, Zhiyu Pan, Yibing Huang, Zhidong Gan, Yonghong Lin, An Ping, Tianhao Peng, Jiaheng Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMT-Video-BenchåŸºå‡†ä»¥è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹åœ¨å¤šè½®è§†é¢‘å¯¹è¯ä¸­çš„è¡¨çŽ°**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `è§†é¢‘ç†è§£` `å¤šè½®å¯¹è¯` `åŸºå‡†è¯„ä¼°` `äº¤äº’èƒ½åŠ›` `æ„ŸçŸ¥èƒ½åŠ›`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŸºå‡†å±€é™äºŽå•è½®é—®ç­”ï¼Œæ— æ³•è¯„ä¼°å¤šè½®å¯¹è¯çš„å¤æ‚æ€§
2. æž„å»ºåŒ…å«987ä¸ªå¤šè½®å¯¹è¯çš„åŸºå‡†ï¼Œè¯„ä¼°æ„ŸçŸ¥ä¸Žäº¤äº’ç­‰å…­é¡¹æ ¸å¿ƒèƒ½åŠ›
3. è¯„ä¼°æ˜¾ç¤ºå¼€æºä¸Žé—­æºæ¨¡åž‹åœ¨å¤šè½®è§†é¢‘å¯¹è¯ä¸­å­˜åœ¨æ˜¾è‘—æ€§èƒ½å·®è·

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The recent development of Multimodal Large Language Models (MLLMs) has
> significantly advanced AI's ability to understand visual modalities. However,
> existing evaluation benchmarks remain limited to single-turn question
> answering, overlooking the complexity of multi-turn dialogues in real-world
> scenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic video
> understanding benchmark for evaluating MLLMs in multi-turn dialogues.
> Specifically, our MT-Video-Bench mainly assesses six core competencies that
> focus on perceptivity and interactivity, encompassing 987 meticulously curated
> multi-turn dialogues from diverse domains. These capabilities are rigorously
> aligned with real-world applications, such as interactive sports analysis and
> multi-turn video-based intelligent tutoring. With MT-Video-Bench, we
> extensively evaluate various state-of-the-art open-source and closed-source
> MLLMs, revealing their significant performance discrepancies and limitations in
> handling multi-turn video dialogues. The benchmark will be publicly available
> to foster future research.

