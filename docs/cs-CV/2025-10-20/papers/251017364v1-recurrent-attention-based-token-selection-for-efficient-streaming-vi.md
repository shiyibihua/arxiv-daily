---
layout: default
title: Recurrent Attention-based Token Selection for Efficient Streaming Video-LLMs
---

# Recurrent Attention-based Token Selection for Efficient Streaming Video-LLMs

**arXiv**: [2510.17364v1](https://arxiv.org/abs/2510.17364) | [PDF](https://arxiv.org/pdf/2510.17364.pdf)

**ä½œè€…**: Vaggelis Dorovatas, Soroush Seifi, Gunshi Gupta, Rahaf Aljundi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå¾ªçŽ¯æ³¨æ„åŠ›çš„ä»¤ç‰Œé€‰æ‹©æ–¹æ³•ï¼Œä»¥æå‡æµå¼è§†é¢‘-å¤§è¯­è¨€æ¨¡åž‹çš„æ•ˆçŽ‡ã€‚**

**å…³é”®è¯**: `æµå¼è§†é¢‘å¤„ç†` `è§†è§‰ä»¤ç‰Œé€‰æ‹©` `æ³¨æ„åŠ›æœºåˆ¶` `è§†é¢‘-å¤§è¯­è¨€æ¨¡åž‹` `æ•ˆçŽ‡ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæµå¼åœºæ™¯ä¸‹ï¼Œé•¿è§†é¢‘éœ€åœ¨çº¿å¤„ç†ï¼Œæ ‡å‡†Video-LLMséš¾ä»¥å®žæ—¶å“åº”æŸ¥è¯¢ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨LLMæ³¨æ„åŠ›é€‰æ‹©è§†è§‰ä»¤ç‰Œï¼Œç»“åˆå¾ªçŽ¯å¤„ç†å’ŒåŽ†å²ä»¤ç‰Œï¼Œå®žçŽ°è½»é‡çº§é—®ç­”ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æµå¼è§†é¢‘åŸºå‡†ä¸Šè¾¾åˆ°SOTAï¼Œä¸¢å¼ƒ95%ä»¤ç‰Œæ—¶æ€§èƒ½æŸå¤±æœ€å°ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video Large Language Models (Video-LLMs) excel at understanding videos
> in-context, provided they have full access to the video when answering queries.
> However, these models face challenges in streaming scenarios where hour-long
> videos must be processed online, and questions need timely responses. In this
> work, we propose a training-free approach compatible with standard Video-LLMs,
> leveraging three key concepts: 1) LLM-informed selection of visual tokens to
> identify those that the LLM has attended to and contributed to its
> understanding of each short clip. Our attention-based selection allows us to
> discard up to ~95% of unimportant visual tokens with minimal performance loss;
> 2) Recurrent processing of past selected tokens to generate temporally coherent
> understanding of each processed clip; 3) Caption-based question answering for
> lightweight and accurate responses. Our method achieves state-of-the-art
> performance on streaming video benchmarks, striking a balance between
> efficiency and effectiveness.

