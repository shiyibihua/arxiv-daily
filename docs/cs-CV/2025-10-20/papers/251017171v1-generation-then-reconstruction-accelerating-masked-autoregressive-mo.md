---
layout: default
title: Generation then Reconstruction: Accelerating Masked Autoregressive Models via Two-Stage Sampling
---

# Generation then Reconstruction: Accelerating Masked Autoregressive Models via Two-Stage Sampling

**arXiv**: [2510.17171v1](https://arxiv.org/abs/2510.17171) | [PDF](https://arxiv.org/pdf/2510.17171.pdf)

**ä½œè€…**: Feihong Yan, Peiru Wang, Yao Zhu, Kaiyu Pang, Qingyan Wei, Huiqi Li, Linfeng Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGtRä¸¤é˜¶æ®µé‡‡æ ·æ–¹æ³•ä»¥åŠ é€ŸæŽ©ç è‡ªå›žå½’æ¨¡åž‹ï¼Œä¿æŒç”Ÿæˆè´¨é‡**

**å…³é”®è¯**: `æŽ©ç è‡ªå›žå½’æ¨¡åž‹` `ä¸¤é˜¶æ®µé‡‡æ ·` `è§†è§‰ç”ŸæˆåŠ é€Ÿ` `é¢‘çŽ‡åˆ†æž` `è®­ç»ƒæ— å…³æ–¹æ³•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æŽ©ç è‡ªå›žå½’æ¨¡åž‹å¹¶è¡Œç”Ÿæˆæ½œåŠ›å—é™äºŽç©ºé—´ç›¸å…³è§†è§‰ä»¤ç‰Œå»ºæ¨¡å¤æ‚åº¦
2. GtRåˆ†ç»“æž„ç”Ÿæˆä¸Žç»†èŠ‚é‡å»ºä¸¤é˜¶æ®µï¼Œç»“åˆé¢‘çŽ‡åŠ æƒä»¤ç‰Œé€‰æ‹©ä¼˜åŒ–è®¡ç®—åˆ†é…
3. å®žéªŒæ˜¾ç¤ºåœ¨ImageNetç­‰ä»»åŠ¡ä¸Šå®žçŽ°3.72å€åŠ é€Ÿï¼Œè´¨é‡ä¸ŽåŽŸå§‹æ¨¡åž‹ç›¸å½“

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Masked Autoregressive (MAR) models promise better efficiency in visual
> generation than autoregressive (AR) models for the ability of parallel
> generation, yet their acceleration potential remains constrained by the
> modeling complexity of spatially correlated visual tokens in a single step. To
> address this limitation, we introduce Generation then Reconstruction (GtR), a
> training-free hierarchical sampling strategy that decomposes generation into
> two stages: structure generation establishing global semantic scaffolding,
> followed by detail reconstruction efficiently completing remaining tokens.
> Assuming that it is more difficult to create an image from scratch than to
> complement images based on a basic image framework, GtR is designed to achieve
> acceleration by computing the reconstruction stage quickly while maintaining
> the generation quality by computing the generation stage slowly. Moreover,
> observing that tokens on the details of an image often carry more semantic
> information than tokens in the salient regions, we further propose
> Frequency-Weighted Token Selection (FTS) to offer more computation budget to
> tokens on image details, which are localized based on the energy of high
> frequency information. Extensive experiments on ImageNet class-conditional and
> text-to-image generation demonstrate 3.72x speedup on MAR-H while maintaining
> comparable quality (e.g., FID: 1.59, IS: 304.4 vs. original 1.59, 299.1),
> substantially outperforming existing acceleration methods across various model
> scales and generation tasks. Our codes will be released in
> https://github.com/feihongyan1/GtR.

