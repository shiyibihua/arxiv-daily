---
layout: default
title: Towards a Generalizable Fusion Architecture for Multimodal Object Detection
---

# Towards a Generalizable Fusion Architecture for Multimodal Object Detection

**arXiv**: [2510.17078v1](https://arxiv.org/abs/2510.17078) | [PDF](https://arxiv.org/pdf/2510.17078.pdf)

**ä½œè€…**: Jad Berjawi, Yoann Dupas, Christophe C'erin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFMCAFæž¶æž„ä»¥å¢žå¼ºRGBä¸Žçº¢å¤–å›¾åƒèžåˆï¼Œæå‡å¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹çš„æ³›åŒ–æ€§ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹` `å›¾åƒèžåˆ` `è·¨æ³¨æ„åŠ›æœºåˆ¶` `é¢‘åŸŸæ»¤æ³¢` `æ³›åŒ–æ€§æå‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹åœ¨æŒ‘æˆ˜æ¡ä»¶ä¸‹ä¾èµ–å¤šä¼ æ„Ÿå™¨äº’è¡¥ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•æ³›åŒ–æ€§ä¸è¶³ã€‚
2. FMCAFç»“åˆé¢‘åŸŸæ»¤æ³¢ä¸Žè·¨æ³¨æ„åŠ›èžåˆï¼ŒæŠ‘åˆ¶å†—ä½™ç‰¹å¾å¹¶ä¿ƒè¿›æ¨¡æ€é—´ç‰¹å¾å…±äº«ã€‚
3. åœ¨LLVIPå’ŒVEDAIæ•°æ®é›†ä¸Šï¼ŒFMCAFä¼˜äºŽä¼ ç»Ÿèžåˆæ–¹æ³•ï¼Œæå‡mAP@50æŒ‡æ ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal object detection improves robustness in chal- lenging conditions
> by leveraging complementary cues from multiple sensor modalities. We introduce
> Filtered Multi- Modal Cross Attention Fusion (FMCAF), a preprocess- ing
> architecture designed to enhance the fusion of RGB and infrared (IR) inputs.
> FMCAF combines a frequency- domain filtering block (Freq-Filter) to suppress
> redun- dant spectral features with a cross-attention-based fusion module (MCAF)
> to improve intermodal feature sharing. Unlike approaches tailored to specific
> datasets, FMCAF aims for generalizability, improving performance across
> different multimodal challenges without requiring dataset- specific tuning. On
> LLVIP (low-light pedestrian detec- tion) and VEDAI (aerial vehicle detection),
> FMCAF outper- forms traditional fusion (concatenation), achieving +13.9% mAP@50
> on VEDAI and +1.1% on LLVIP. These results support the potential of FMCAF as a
> flexible foundation for robust multimodal fusion in future detection pipelines.

