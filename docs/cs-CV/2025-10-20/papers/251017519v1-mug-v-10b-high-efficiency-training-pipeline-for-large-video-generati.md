---
layout: default
title: MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models
---

# MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models

**arXiv**: [2510.17519v1](https://arxiv.org/abs/2510.17519) | [PDF](https://arxiv.org/pdf/2510.17519.pdf)

**ä½œè€…**: Yongshun Zhang, Zhongyi Fan, Yonghang Zhang, Zhangzikang Li, Weifeng Chen, Zhongwei Feng, Chaoyue Wang, Peng Hou, Anxiang Zeng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé«˜æ•ˆè®­ç»ƒæ¡†æž¶ä»¥è§£å†³å¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆæ¨¡åž‹çš„èµ„æºæŒ‘æˆ˜**

**å…³é”®è¯**: `å¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆ` `é«˜æ•ˆè®­ç»ƒæ¡†æž¶` `è·¨æ¨¡æ€å¯¹é½` `å¼€æºä»£ç ` `å¤šèŠ‚ç‚¹æ‰©å±•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆè®­ç»ƒé¢ä¸´è·¨æ¨¡æ€å¯¹é½ã€é•¿åºåˆ—å’Œæ—¶ç©ºä¾èµ–ç­‰èµ„æºå¯†é›†åž‹æŒ‘æˆ˜
2. æ–¹æ³•è¦ç‚¹ï¼šä¼˜åŒ–æ•°æ®å¤„ç†ã€æ¨¡åž‹æž¶æž„ã€è®­ç»ƒç­–ç•¥å’ŒåŸºç¡€è®¾æ–½å››å¤§æ”¯æŸ±ï¼Œæå‡æ•ˆçŽ‡
3. å®žéªŒæˆ–æ•ˆæžœï¼šMUG-V 10Bæ¨¡åž‹åœ¨ç”µå•†è§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸­è¶…è¶Šå¼€æºåŸºçº¿ï¼Œå¹¶å¼€æºå®Œæ•´å †æ ˆ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In recent years, large-scale generative models for visual content
> (\textit{e.g.,} images, videos, and 3D objects/scenes) have made remarkable
> progress. However, training large-scale video generation models remains
> particularly challenging and resource-intensive due to cross-modal text-video
> alignment, the long sequences involved, and the complex spatiotemporal
> dependencies. To address these challenges, we present a training framework that
> optimizes four pillars: (i) data processing, (ii) model architecture, (iii)
> training strategy, and (iv) infrastructure for large-scale video generation
> models. These optimizations delivered significant efficiency gains and
> performance improvements across all stages of data preprocessing, video
> compression, parameter scaling, curriculum-based pretraining, and
> alignment-focused post-training. Our resulting model, MUG-V 10B, matches recent
> state-of-the-art video generators overall and, on e-commerce-oriented video
> generation tasks, surpasses leading open-source baselines in human evaluations.
> More importantly, we open-source the complete stack, including model weights,
> Megatron-Core-based large-scale training code, and inference pipelines for
> video generation and enhancement. To our knowledge, this is the first public
> release of large-scale video generation training code that exploits
> Megatron-Core to achieve high training efficiency and near-linear multi-node
> scaling, details are available in
> \href{https://github.com/Shopee-MUG/MUG-V}{our webpage}.

