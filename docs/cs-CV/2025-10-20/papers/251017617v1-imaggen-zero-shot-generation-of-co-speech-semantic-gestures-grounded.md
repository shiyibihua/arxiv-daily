---
layout: default
title: ImaGGen: Zero-Shot Generation of Co-Speech Semantic Gestures Grounded in Language and Image Input
---

# ImaGGen: Zero-Shot Generation of Co-Speech Semantic Gestures Grounded in Language and Image Input

**arXiv**: [2510.17617v1](https://arxiv.org/abs/2510.17617) | [PDF](https://arxiv.org/pdf/2510.17617.pdf)

**ä½œè€…**: Hendric Voss, Stefan Kopp

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºImaGGenç³»ç»Ÿï¼Œé€šè¿‡è¯­è¨€å’Œå›¾åƒè¾“å…¥é›¶æ ·æœ¬ç”Ÿæˆè¯­ä¹‰æ‰‹åŠ¿ä»¥å¢žå¼ºäººæœºäº¤äº’ã€‚**

**å…³é”®è¯**: `æ‰‹åŠ¿ç”Ÿæˆ` `é›¶æ ·æœ¬å­¦ä¹ ` `è¯­ä¹‰åŒ¹é…` `é€†è¿åŠ¨å­¦` `å¤šæ¨¡æ€äº¤äº’` `è™šæ‹Ÿä»£ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ‰‹åŠ¿ç”Ÿæˆæ–¹æ³•ä»…äº§ç”ŸèŠ‚æ‹æ‰‹åŠ¿ï¼Œç¼ºä¹è¯­ä¹‰è¿žè´¯æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆå›¾åƒåˆ†æžæå–ç‰©ä½“å±žæ€§ï¼Œè¯­ä¹‰åŒ¹é…é“¾æŽ¥è§†è§‰ä¸Žè¯­è¨€ï¼Œé€†è¿åŠ¨å­¦åˆæˆæ‰‹åŠ¿ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç”¨æˆ·ç ”ç©¶è¡¨æ˜Žï¼Œç”Ÿæˆæ‰‹åŠ¿åœ¨æ¨¡ç³Šè¯­éŸ³åœºæ™¯ä¸­æ˜¾è‘—æå‡ç‰©ä½“å±žæ€§è¯†åˆ«èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Human communication combines speech with expressive nonverbal cues such as
> hand gestures that serve manifold communicative functions. Yet, current
> generative gesture generation approaches are restricted to simple, repetitive
> beat gestures that accompany the rhythm of speaking but do not contribute to
> communicating semantic meaning. This paper tackles a core challenge in
> co-speech gesture synthesis: generating iconic or deictic gestures that are
> semantically coherent with a verbal utterance. Such gestures cannot be derived
> from language input alone, which inherently lacks the visual meaning that is
> often carried autonomously by gestures. We therefore introduce a zero-shot
> system that generates gestures from a given language input and additionally is
> informed by imagistic input, without manual annotation or human intervention.
> Our method integrates an image analysis pipeline that extracts key object
> properties such as shape, symmetry, and alignment, together with a semantic
> matching module that links these visual details to spoken text. An inverse
> kinematics engine then synthesizes iconic and deictic gestures and combines
> them with co-generated natural beat gestures for coherent multimodal
> communication. A comprehensive user study demonstrates the effectiveness of our
> approach. In scenarios where speech alone was ambiguous, gestures generated by
> our system significantly improved participants' ability to identify object
> properties, confirming their interpretability and communicative value. While
> challenges remain in representing complex shapes, our results highlight the
> importance of context-aware semantic gestures for creating expressive and
> collaborative virtual agents or avatars, marking a substantial step forward
> towards efficient and robust, embodied human-agent interaction. More
> information and example videos are available here:
> https://review-anon-io.github.io/ImaGGen.github.io/

