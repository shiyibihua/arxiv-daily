---
layout: default
title: HideAndSeg: an AI-based tool with automated prompting for octopus segmentation in natural habitats
---

# HideAndSeg: an AI-based tool with automated prompting for octopus segmentation in natural habitats

**arXiv**: [2511.04426v1](https://arxiv.org/abs/2511.04426) | [PDF](https://arxiv.org/pdf/2511.04426.pdf)

**ä½œè€…**: Alan de Aguiar, Michaella Pereira Andrade, Charles Morphy D. Santos, JoÃ£o Paulo Gois

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHideAndSegå·¥å…·ï¼Œé€šè¿‡è‡ªåŠ¨åŒ–æç¤ºå®žçŽ°è‡ªç„¶æ –æ¯åœ°ç« é±¼è§†é¢‘åˆ†å‰²**

**å…³é”®è¯**: `è§†é¢‘åˆ†å‰²` `æ— ç›‘ç£è¯„ä¼°` `SAM2é›†æˆ` `YOLOæ£€æµ‹` `ç« é±¼è¡Œä¸ºç ”ç©¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç« é±¼ä¼ªè£…ã€å˜å½¢å’Œé®æŒ¡å¯¼è‡´è‡ªç„¶æ –æ¯åœ°è§†é¢‘åˆ†å‰²å›°éš¾ï¼Œç¼ºä¹å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆSAM2å’ŒYOLOv11ï¼Œå…ˆæ‰‹åŠ¨ç‚¹æç¤ºç”ŸæˆæŽ©ç ï¼ŒåŽè‡ªåŠ¨è¾¹ç•Œæ¡†æç¤ºå®žçŽ°å…¨æµç¨‹è‡ªåŠ¨åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå¼•å…¥æ— ç›‘ç£æŒ‡æ ‡è¯„ä¼°åˆ†å‰²è´¨é‡ï¼Œå‡å°‘å™ªå£°ï¼Œåœ¨å®Œå…¨é®æŒ¡åŽä»èƒ½é‡è¯†åˆ«å’Œåˆ†å‰²ç« é±¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Analyzing octopuses in their natural habitats is challenging due to their
> camouflage capability, rapid changes in skin texture and color, non-rigid body
> deformations, and frequent occlusions, all of which are compounded by variable
> underwater lighting and turbidity. Addressing the lack of large-scale annotated
> datasets, this paper introduces HideAndSeg, a novel, minimally supervised
> AI-based tool for segmenting videos of octopuses. It establishes a quantitative
> baseline for this task. HideAndSeg integrates SAM2 with a custom-trained
> YOLOv11 object detector. First, the user provides point coordinates to generate
> the initial segmentation masks with SAM2. These masks serve as training data
> for the YOLO model. After that, our approach fully automates the pipeline by
> providing a bounding box prompt to SAM2, eliminating the need for further
> manual intervention. We introduce two unsupervised metrics - temporal
> consistency $DICE_t$ and new component count $NC_t$ - to quantitatively
> evaluate segmentation quality and guide mask refinement in the absence of
> ground-truth data, i.e., real-world information that serves to train, validate,
> and test AI models. Results show that HideAndSeg achieves satisfactory
> performance, reducing segmentation noise compared to the manually prompted
> approach. Our method can re-identify and segment the octopus even after periods
> of complete occlusion in natural environments, a scenario in which the manually
> prompted model fails. By reducing the need for manual analysis in real-world
> scenarios, this work provides a practical tool that paves the way for more
> efficient behavioral studies of wild cephalopods.

