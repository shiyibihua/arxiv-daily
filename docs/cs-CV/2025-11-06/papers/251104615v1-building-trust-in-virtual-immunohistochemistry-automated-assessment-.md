---
layout: default
title: Building Trust in Virtual Immunohistochemistry: Automated Assessment of Image Quality
---

# Building Trust in Virtual Immunohistochemistry: Automated Assessment of Image Quality

**arXiv**: [2511.04615v1](https://arxiv.org/abs/2511.04615) | [PDF](https://arxiv.org/pdf/2511.04615.pdf)

**ä½œè€…**: Tushar Kataria, Shikha Dubey, Mary Bronner, Jolanta Jedrzkiewicz, Ben J. Brintz, Shireen Y. Elhabian, Beatrice S. Knudsen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªåŠ¨åŒ–æ¡†æž¶è¯„ä¼°è™šæ‹Ÿå…ç–«ç»„åŒ–å›¾åƒè´¨é‡ï¼Œä»¥è§£å†³çŽ°æœ‰æŒ‡æ ‡ä¸ŽæŸ“è‰²å‡†ç¡®æ€§ä¸åŒ¹é…é—®é¢˜ã€‚**

**å…³é”®è¯**: `è™šæ‹Ÿå…ç–«ç»„åŒ–` `å›¾åƒè´¨é‡è¯„ä¼°` `åƒç´ çº§å‡†ç¡®æ€§` `é¢œè‰²åå·ç§¯` `å…¨çŽ»ç‰‡å›¾åƒ` `æŸ“è‰²å‡†ç¡®æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰å›¾åƒä¿çœŸåº¦æŒ‡æ ‡æ— æ³•å‡†ç¡®è¯„ä¼°è™šæ‹ŸIHCæŸ“è‰²å‡†ç¡®æ€§ï¼Œä¸Žç—…ç†å­¦å®¶è¯„ä¼°ç›¸å…³æ€§å·®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨é¢œè‰²åå·ç§¯ç”ŸæˆIHCé˜³æ€§åƒç´ æŽ©ç ï¼Œè®¡ç®—Diceç­‰æŒ‡æ ‡é‡åŒ–åƒç´ çº§æŸ“è‰²å‡†ç¡®æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šé…å¯¹æ¨¡åž‹å¦‚PyramidPix2PixæŸ“è‰²å‡†ç¡®æ€§æœ€é«˜ï¼Œå…¨çŽ»ç‰‡å›¾åƒè¯„ä¼°æ­ç¤ºæ€§èƒ½ä¸‹é™ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deep learning models can generate virtual immunohistochemistry (IHC) stains
> from hematoxylin and eosin (H&E) images, offering a scalable and low-cost
> alternative to laboratory IHC. However, reliable evaluation of image quality
> remains a challenge as current texture- and distribution-based metrics quantify
> image fidelity rather than the accuracy of IHC staining. Here, we introduce an
> automated and accuracy grounded framework to determine image quality across
> sixteen paired or unpaired image translation models. Using color deconvolution,
> we generate masks of pixels stained brown (i.e., IHC-positive) as predicted by
> each virtual IHC model. We use the segmented masks of real and virtual IHC to
> compute stain accuracy metrics (Dice, IoU, Hausdorff distance) that directly
> quantify correct pixel - level labeling without needing expert manual
> annotations. Our results demonstrate that conventional image fidelity metrics,
> including Frechet Inception Distance (FID), peak signal-to-noise ratio (PSNR),
> and structural similarity (SSIM), correlate poorly with stain accuracy and
> pathologist assessment. Paired models such as PyramidPix2Pix and AdaptiveNCE
> achieve the highest stain accuracy, whereas unpaired diffusion- and GAN-based
> models are less reliable in providing accurate IHC positive pixel labels.
> Moreover, whole-slide images (WSI) reveal performance declines that are
> invisible in patch-based evaluations, emphasizing the need for WSI-level
> benchmarks. Together, this framework defines a reproducible approach for
> assessing the quality of virtual IHC models, a critical step to accelerate
> translation towards routine use by pathologists.

