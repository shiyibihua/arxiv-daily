---
layout: default
title: InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual Generation
---

# InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual Generation

**arXiv**: [2511.04675v1](https://arxiv.org/abs/2511.04675) | [PDF](https://arxiv.org/pdf/2511.04675.pdf)

**ä½œè€…**: Jinlai Liu, Jian Han, Bin Yan, Hui Wu, Fengda Zhu, Xing Wang, Yi Jiang, Bingyue Peng, Zehuan Yuan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInfinityStarç»Ÿä¸€æ—¶ç©ºè‡ªå›žå½’æ¡†æž¶ï¼Œç”¨äºŽé«˜æ•ˆé«˜åˆ†è¾¨çŽ‡å›¾åƒå’Œè§†é¢‘ç”Ÿæˆ**

**å…³é”®è¯**: `æ—¶ç©ºè‡ªå›žå½’å»ºæ¨¡` `é«˜åˆ†è¾¨çŽ‡è§†é¢‘ç”Ÿæˆ` `ç»Ÿä¸€è§†è§‰ç”Ÿæˆæ¡†æž¶` `ç¦»æ•£è‡ªå›žå½’æ–¹æ³•` `é«˜æ•ˆè§†é¢‘åˆæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•ç»Ÿä¸€å»ºæ¨¡ç©ºé—´å’Œæ—¶é—´ä¾èµ–ä»¥æ”¯æŒå¤šç§è§†è§‰ç”Ÿæˆä»»åŠ¡
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨çº¯ç¦»æ•£è‡ªå›žå½’æ–¹æ³•ï¼Œè”åˆæ•èŽ·æ—¶ç©ºä¾èµ–ï¼Œæ”¯æŒæ–‡æœ¬åˆ°å›¾åƒ/è§†é¢‘ç­‰ä»»åŠ¡
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨VBenchå¾—åˆ†83.74ï¼Œç”Ÿæˆ720pè§†é¢‘é€Ÿåº¦æ¯”æ‰©æ•£æ–¹æ³•å¿«çº¦10å€

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce InfinityStar, a unified spacetime autoregressive framework for
> high-resolution image and dynamic video synthesis. Building on the recent
> success of autoregressive modeling in both vision and language, our purely
> discrete approach jointly captures spatial and temporal dependencies within a
> single architecture. This unified design naturally supports a variety of
> generation tasks such as text-to-image, text-to-video, image-to-video, and long
> interactive video synthesis via straightforward temporal autoregression.
> Extensive experiments demonstrate that InfinityStar scores 83.74 on VBench,
> outperforming all autoregressive models by large margins, even surpassing some
> diffusion competitors like HunyuanVideo. Without extra optimizations, our model
> generates a 5s, 720p video approximately 10x faster than leading
> diffusion-based methods. To our knowledge, InfinityStar is the first discrete
> autoregressive video generator capable of producing industrial level 720p
> videos. We release all code and models to foster further research in efficient,
> high-quality video generation.

