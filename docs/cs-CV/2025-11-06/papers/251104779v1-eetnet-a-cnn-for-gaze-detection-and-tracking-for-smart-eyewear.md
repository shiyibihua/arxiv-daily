---
layout: default
title: EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear
---

# EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.04779" target="_blank" class="toolbar-btn">arXiv: 2511.04779v1</a>
    <a href="https://arxiv.org/pdf/2511.04779.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.04779v1" 
            onclick="toggleFavorite(this, '2511.04779v1', 'EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Andrea Aspesi, Andrea Simpsi, Aaron Tognoli, Simone Mentasti, Luca Merigo, Matteo Matteucci

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-06

**å¤‡æ³¨**: International Joint Conference on Neural Networks (IJCNN), 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EETnetï¼šä¸ºæ™ºèƒ½çœ¼é•œè®¾è®¡çš„åŸºäºäº‹ä»¶çš„ä½åŠŸè€—æ³¨è§†æ£€æµ‹ä¸è·Ÿè¸ªCNN**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `çœ¼åŠ¨è¿½è¸ª` `äº‹ä»¶ç›¸æœº` `å·ç§¯ç¥ç»ç½‘ç»œ` `ä½åŠŸè€—` `åµŒå…¥å¼ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çœ¼åŠ¨è¿½è¸ªæ–¹æ¡ˆè®¡ç®—èµ„æºéœ€æ±‚é«˜ï¼Œéš¾ä»¥åœ¨ä½åŠŸè€—åµŒå…¥å¼è®¾å¤‡ä¸Šéƒ¨ç½²ï¼Œé™åˆ¶äº†å…¶åœ¨æ™ºèƒ½çœ¼é•œç­‰è®¾å¤‡ä¸Šçš„åº”ç”¨ã€‚
2. EETnetåˆ©ç”¨äº‹ä»¶ç›¸æœºäº§ç”Ÿçš„ç¨€ç–å¼‚æ­¥äº‹ä»¶æ•°æ®ï¼Œè®¾è®¡è½»é‡çº§CNNï¼Œé™ä½è®¡ç®—å¤æ‚åº¦ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¾®æ§åˆ¶å™¨ä¸Šè¿è¡Œã€‚
3. è®ºæ–‡æå‡ºäº†EETnetçš„åˆ†ç±»å’Œå›å½’ä¸¤ç§æ¨¡å‹ï¼Œå¹¶æä¾›äº†åœ¨å…¬å…±æ•°æ®é›†ä¸Šè®­ç»ƒã€è¯„ä¼°å’Œé‡åŒ–è¯¥ç½‘ç»œçš„æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºEETnetçš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œä¸“ä¸ºä½¿ç”¨çº¯äº‹ä»¶æ•°æ®çš„çœ¼åŠ¨è¿½è¸ªè€Œè®¾è®¡ï¼Œèƒ½å¤Ÿåœ¨èµ„æºæœ‰é™çš„å¾®æ§åˆ¶å™¨ä¸Šè¿è¡Œã€‚äº‹ä»¶ç›¸æœºæ­£æˆä¸ºé«˜æ•ˆã€ä½åŠŸè€—çœ¼åŠ¨è¿½è¸ªçš„çƒ­é—¨è§£å†³æ–¹æ¡ˆã€‚ç”±äºäº‹ä»¶æ•°æ®çš„ç¨€ç–æ€§å’Œå¼‚æ­¥æ€§ï¼Œå®ƒä»¬éœ€è¦çš„å¤„ç†èƒ½åŠ›æ›´å°‘ï¼Œå¹¶æä¾›å¾®ç§’çº§çš„å»¶è¿Ÿã€‚ç„¶è€Œï¼Œè®¸å¤šç°æœ‰è§£å†³æ–¹æ¡ˆä»…é™äºåœ¨å¼ºå¤§çš„GPUä¸Šè¿›è¡ŒéªŒè¯ï¼Œè€Œæ— æ³•åœ¨çœŸæ­£çš„åµŒå…¥å¼è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æ¦‚è¿°äº†ä¸€ç§ä½¿ç”¨å…¬å…±æ•°æ®é›†è®­ç»ƒã€è¯„ä¼°å’Œé‡åŒ–ç½‘ç»œçš„æ–¹æ³•ã€‚æœ€åï¼Œæå‡ºäº†è¯¥æ¶æ„çš„ä¸¤ä¸ªç‰ˆæœ¬ï¼šä¸€ä¸ªåˆ†ç±»æ¨¡å‹ï¼Œç”¨äºæ£€æµ‹å åŠ åœ¨åŸå§‹å›¾åƒä¸Šçš„ç½‘æ ¼ä¸Šçš„ç³å­”ï¼›ä»¥åŠä¸€ä¸ªå›å½’æ¨¡å‹ï¼Œå¯åœ¨åƒç´ çº§åˆ«è¿è¡Œã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰çœ¼åŠ¨è¿½è¸ªç³»ç»ŸåŠŸè€—é«˜ã€è®¡ç®—é‡å¤§ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„æ™ºèƒ½çœ¼é•œç­‰è®¾å¤‡ä¸Šå®æ—¶è¿è¡Œçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºä¼ ç»Ÿç›¸æœºå›¾åƒï¼Œéœ€è¦å¤§é‡çš„å›¾åƒå¤„ç†ï¼Œæˆ–è€…åªèƒ½åœ¨é«˜æ€§èƒ½GPUä¸Šè¿è¡Œï¼Œæ— æ³•æ»¡è¶³åµŒå…¥å¼è®¾å¤‡çš„éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨äº‹ä»¶ç›¸æœºäº§ç”Ÿçš„äº‹ä»¶æ•°æ®ï¼Œè¿™ç§æ•°æ®å…·æœ‰ç¨€ç–æ€§å’Œå¼‚æ­¥æ€§ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½è®¡ç®—é‡ã€‚åŒæ—¶ï¼Œè®¾è®¡ä¸€ä¸ªè½»é‡çº§çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¾®æ§åˆ¶å™¨ä¸Šé«˜æ•ˆè¿è¡Œï¼Œå®ç°ä½åŠŸè€—çš„çœ¼åŠ¨è¿½è¸ªã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEETnetçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬äº‹ä»¶æ•°æ®çš„é¢„å¤„ç†ï¼ˆå¯èƒ½åŒ…æ‹¬äº‹ä»¶çš„ç´¯ç§¯æˆ–ç¼–ç ï¼‰ï¼Œç„¶åè¾“å…¥åˆ°CNNç½‘ç»œä¸­è¿›è¡Œå¤„ç†ã€‚CNNç½‘ç»œè¾“å‡ºå¯ä»¥æ˜¯åˆ†ç±»ç»“æœï¼ˆç³å­”åœ¨ç½‘æ ¼ä¸­çš„ä½ç½®ï¼‰æˆ–å›å½’ç»“æœï¼ˆç³å­”çš„åƒç´ åæ ‡ï¼‰ã€‚è®ºæ–‡æå‡ºäº†ä¸¤ç§æ¶æ„ï¼šåˆ†ç±»æ¨¡å‹å’Œå›å½’æ¨¡å‹ã€‚åˆ†ç±»æ¨¡å‹å°†å›¾åƒåˆ’åˆ†æˆç½‘æ ¼ï¼Œé¢„æµ‹ç³å­”æ‰€åœ¨çš„ç½‘æ ¼å•å…ƒï¼›å›å½’æ¨¡å‹ç›´æ¥é¢„æµ‹ç³å­”çš„åƒç´ åæ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šEETnetçš„å…³é”®åˆ›æ–°åœ¨äºé’ˆå¯¹äº‹ä»¶æ•°æ®çš„ç‰¹æ€§ï¼Œè®¾è®¡äº†ä¸€ä¸ªè½»é‡çº§çš„CNNæ¶æ„ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨èµ„æºå—é™çš„å¾®æ§åˆ¶å™¨ä¸Šè¿è¡Œã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä½¿ç”¨å…¬å…±æ•°æ®é›†è®­ç»ƒã€è¯„ä¼°å’Œé‡åŒ–è¯¥ç½‘ç»œçš„æ–¹æ³•ï¼Œä¸ºåœ¨åµŒå…¥å¼è®¾å¤‡ä¸Šéƒ¨ç½²çœ¼åŠ¨è¿½è¸ªç³»ç»Ÿæä¾›äº†å¯è¡Œçš„æ–¹æ¡ˆã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­æåˆ°äº†ä¸¤ç§æ¨¡å‹ï¼šåˆ†ç±»æ¨¡å‹å’Œå›å½’æ¨¡å‹ã€‚åˆ†ç±»æ¨¡å‹å°†å›¾åƒåˆ’åˆ†æˆç½‘æ ¼ï¼Œä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒã€‚å›å½’æ¨¡å‹ç›´æ¥é¢„æµ‹ç³å­”çš„åƒç´ åæ ‡ï¼Œå¯ä»¥ä½¿ç”¨L1æˆ–L2æŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒã€‚å…·ä½“çš„ç½‘ç»œç»“æ„ï¼ˆå·ç§¯å±‚æ•°ã€æ»¤æ³¢å™¨å¤§å°ã€æ¿€æ´»å‡½æ•°ç­‰ï¼‰ä»¥åŠé‡åŒ–æ–¹æ³•ç­‰ç»†èŠ‚ï¼Œéœ€è¦åœ¨è®ºæ–‡ä¸­è¿›ä¸€æ­¥æŸ¥æ‰¾ã€‚å‚æ•°è®¾ç½®å¯èƒ½éœ€è¦æ ¹æ®å…·ä½“æ•°æ®é›†å’Œç¡¬ä»¶å¹³å°è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æå‡ºäº†EETnetï¼Œä¸€ä¸ªä¸“ä¸ºäº‹ä»¶æ•°æ®è®¾è®¡çš„è½»é‡çº§CNNï¼Œèƒ½å¤Ÿåœ¨å¾®æ§åˆ¶å™¨ä¸Šè¿è¡Œï¼Œå®ç°äº†ä½åŠŸè€—çš„çœ¼åŠ¨è¿½è¸ªã€‚è™½ç„¶æ‘˜è¦ä¸­æ²¡æœ‰ç»™å‡ºå…·ä½“çš„æ€§èƒ½æ•°æ®ï¼Œä½†å¼ºè°ƒäº†å…¶åœ¨åµŒå…¥å¼è®¾å¤‡ä¸Šçš„å¯è¡Œæ€§ï¼Œå¹¶æä¾›äº†è®­ç»ƒã€è¯„ä¼°å’Œé‡åŒ–ç½‘ç»œçš„æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EETnetåœ¨æ™ºèƒ½çœ¼é•œã€VR/ARè®¾å¤‡ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºç”¨æˆ·ç•Œé¢äº¤äº’ã€çœ¼æ§è¾“å…¥ã€æ³¨æ„åŠ›è¿½è¸ªã€è¾…åŠ©é©¾é©¶ç­‰åœºæ™¯ã€‚ä½åŠŸè€—çš„ç‰¹æ€§ä½¿å…¶éå¸¸é€‚åˆç”µæ± ä¾›ç”µçš„ç§»åŠ¨è®¾å¤‡ï¼Œèƒ½å¤Ÿæå‡ç”¨æˆ·ä½“éªŒå¹¶æ‰©å±•è®¾å¤‡çš„åŠŸèƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Event-based cameras are becoming a popular solution for efficient, low-power eye tracking. Due to the sparse and asynchronous nature of event data, they require less processing power and offer latencies in the microsecond range. However, many existing solutions are limited to validation on powerful GPUs, with no deployment on real embedded devices. In this paper, we present EETnet, a convolutional neural network designed for eye tracking using purely event-based data, capable of running on microcontrollers with limited resources. Additionally, we outline a methodology to train, evaluate, and quantize the network using a public dataset. Finally, we propose two versions of the architecture: a classification model that detects the pupil on a grid superimposed on the original image, and a regression model that operates at the pixel level.

