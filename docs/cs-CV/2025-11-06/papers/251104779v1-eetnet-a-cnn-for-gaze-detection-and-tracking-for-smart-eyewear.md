---
layout: default
title: EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear
---

# EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear

**arXiv**: [2511.04779v1](https://arxiv.org/abs/2511.04779) | [PDF](https://arxiv.org/pdf/2511.04779.pdf)

**ä½œè€…**: Andrea Aspesi, Andrea Simpsi, Aaron Tognoli, Simone Mentasti, Luca Merigo, Matteo Matteucci

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-06

**å¤‡æ³¨**: International Joint Conference on Neural Networks (IJCNN), 2025

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EETnetï¼šä¸ºæ™ºèƒ½çœ¼é•œè®¾è®¡çš„åŸºäºŽäº‹ä»¶çš„ä½ŽåŠŸè€—æ³¨è§†æ£€æµ‹ä¸Žè·Ÿè¸ªCNN**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `çœ¼åŠ¨è¿½è¸ª` `äº‹ä»¶ç›¸æœº` `å·ç§¯ç¥žç»ç½‘ç»œ` `ä½ŽåŠŸè€—` `åµŒå…¥å¼ç³»ç»Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰çœ¼åŠ¨è¿½è¸ªæ–¹æ¡ˆè®¡ç®—èµ„æºéœ€æ±‚é«˜ï¼Œéš¾ä»¥åœ¨ä½ŽåŠŸè€—åµŒå…¥å¼è®¾å¤‡ä¸Šéƒ¨ç½²ï¼Œé™åˆ¶äº†å…¶åœ¨æ™ºèƒ½çœ¼é•œç­‰è®¾å¤‡ä¸Šçš„åº”ç”¨ã€‚
2. EETnetåˆ©ç”¨äº‹ä»¶ç›¸æœºäº§ç”Ÿçš„ç¨€ç–å¼‚æ­¥äº‹ä»¶æ•°æ®ï¼Œè®¾è®¡è½»é‡çº§CNNï¼Œé™ä½Žè®¡ç®—å¤æ‚åº¦ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¾®æŽ§åˆ¶å™¨ä¸Šè¿è¡Œã€‚
3. è®ºæ–‡æå‡ºäº†EETnetçš„åˆ†ç±»å’Œå›žå½’ä¸¤ç§æ¨¡åž‹ï¼Œå¹¶æä¾›äº†åœ¨å…¬å…±æ•°æ®é›†ä¸Šè®­ç»ƒã€è¯„ä¼°å’Œé‡åŒ–è¯¥ç½‘ç»œçš„æ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºEETnetçš„å·ç§¯ç¥žç»ç½‘ç»œï¼Œä¸“ä¸ºä½¿ç”¨çº¯äº‹ä»¶æ•°æ®çš„çœ¼åŠ¨è¿½è¸ªè€Œè®¾è®¡ï¼Œèƒ½å¤Ÿåœ¨èµ„æºæœ‰é™çš„å¾®æŽ§åˆ¶å™¨ä¸Šè¿è¡Œã€‚äº‹ä»¶ç›¸æœºæ­£æˆä¸ºé«˜æ•ˆã€ä½ŽåŠŸè€—çœ¼åŠ¨è¿½è¸ªçš„çƒ­é—¨è§£å†³æ–¹æ¡ˆã€‚ç”±äºŽäº‹ä»¶æ•°æ®çš„ç¨€ç–æ€§å’Œå¼‚æ­¥æ€§ï¼Œå®ƒä»¬éœ€è¦çš„å¤„ç†èƒ½åŠ›æ›´å°‘ï¼Œå¹¶æä¾›å¾®ç§’çº§çš„å»¶è¿Ÿã€‚ç„¶è€Œï¼Œè®¸å¤šçŽ°æœ‰è§£å†³æ–¹æ¡ˆä»…é™äºŽåœ¨å¼ºå¤§çš„GPUä¸Šè¿›è¡ŒéªŒè¯ï¼Œè€Œæ— æ³•åœ¨çœŸæ­£çš„åµŒå…¥å¼è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æ¦‚è¿°äº†ä¸€ç§ä½¿ç”¨å…¬å…±æ•°æ®é›†è®­ç»ƒã€è¯„ä¼°å’Œé‡åŒ–ç½‘ç»œçš„æ–¹æ³•ã€‚æœ€åŽï¼Œæå‡ºäº†è¯¥æž¶æž„çš„ä¸¤ä¸ªç‰ˆæœ¬ï¼šä¸€ä¸ªåˆ†ç±»æ¨¡åž‹ï¼Œç”¨äºŽæ£€æµ‹å åŠ åœ¨åŽŸå§‹å›¾åƒä¸Šçš„ç½‘æ ¼ä¸Šçš„çž³å­”ï¼›ä»¥åŠä¸€ä¸ªå›žå½’æ¨¡åž‹ï¼Œå¯åœ¨åƒç´ çº§åˆ«è¿è¡Œã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³çŽ°æœ‰çœ¼åŠ¨è¿½è¸ªç³»ç»ŸåŠŸè€—é«˜ã€è®¡ç®—é‡å¤§ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„æ™ºèƒ½çœ¼é•œç­‰è®¾å¤‡ä¸Šå®žæ—¶è¿è¡Œçš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºŽä¼ ç»Ÿç›¸æœºå›¾åƒï¼Œéœ€è¦å¤§é‡çš„å›¾åƒå¤„ç†ï¼Œæˆ–è€…åªèƒ½åœ¨é«˜æ€§èƒ½GPUä¸Šè¿è¡Œï¼Œæ— æ³•æ»¡è¶³åµŒå…¥å¼è®¾å¤‡çš„éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨äº‹ä»¶ç›¸æœºäº§ç”Ÿçš„äº‹ä»¶æ•°æ®ï¼Œè¿™ç§æ•°æ®å…·æœ‰ç¨€ç–æ€§å’Œå¼‚æ­¥æ€§ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½Žè®¡ç®—é‡ã€‚åŒæ—¶ï¼Œè®¾è®¡ä¸€ä¸ªè½»é‡çº§çš„å·ç§¯ç¥žç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¾®æŽ§åˆ¶å™¨ä¸Šé«˜æ•ˆè¿è¡Œï¼Œå®žçŽ°ä½ŽåŠŸè€—çš„çœ¼åŠ¨è¿½è¸ªã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šEETnetçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬äº‹ä»¶æ•°æ®çš„é¢„å¤„ç†ï¼ˆå¯èƒ½åŒ…æ‹¬äº‹ä»¶çš„ç´¯ç§¯æˆ–ç¼–ç ï¼‰ï¼Œç„¶åŽè¾“å…¥åˆ°CNNç½‘ç»œä¸­è¿›è¡Œå¤„ç†ã€‚CNNç½‘ç»œè¾“å‡ºå¯ä»¥æ˜¯åˆ†ç±»ç»“æžœï¼ˆçž³å­”åœ¨ç½‘æ ¼ä¸­çš„ä½ç½®ï¼‰æˆ–å›žå½’ç»“æžœï¼ˆçž³å­”çš„åƒç´ åæ ‡ï¼‰ã€‚è®ºæ–‡æå‡ºäº†ä¸¤ç§æž¶æž„ï¼šåˆ†ç±»æ¨¡åž‹å’Œå›žå½’æ¨¡åž‹ã€‚åˆ†ç±»æ¨¡åž‹å°†å›¾åƒåˆ’åˆ†æˆç½‘æ ¼ï¼Œé¢„æµ‹çž³å­”æ‰€åœ¨çš„ç½‘æ ¼å•å…ƒï¼›å›žå½’æ¨¡åž‹ç›´æŽ¥é¢„æµ‹çž³å­”çš„åƒç´ åæ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šEETnetçš„å…³é”®åˆ›æ–°åœ¨äºŽé’ˆå¯¹äº‹ä»¶æ•°æ®çš„ç‰¹æ€§ï¼Œè®¾è®¡äº†ä¸€ä¸ªè½»é‡çº§çš„CNNæž¶æž„ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨èµ„æºå—é™çš„å¾®æŽ§åˆ¶å™¨ä¸Šè¿è¡Œã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä½¿ç”¨å…¬å…±æ•°æ®é›†è®­ç»ƒã€è¯„ä¼°å’Œé‡åŒ–è¯¥ç½‘ç»œçš„æ–¹æ³•ï¼Œä¸ºåœ¨åµŒå…¥å¼è®¾å¤‡ä¸Šéƒ¨ç½²çœ¼åŠ¨è¿½è¸ªç³»ç»Ÿæä¾›äº†å¯è¡Œçš„æ–¹æ¡ˆã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­æåˆ°äº†ä¸¤ç§æ¨¡åž‹ï¼šåˆ†ç±»æ¨¡åž‹å’Œå›žå½’æ¨¡åž‹ã€‚åˆ†ç±»æ¨¡åž‹å°†å›¾åƒåˆ’åˆ†æˆç½‘æ ¼ï¼Œä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒã€‚å›žå½’æ¨¡åž‹ç›´æŽ¥é¢„æµ‹çž³å­”çš„åƒç´ åæ ‡ï¼Œå¯ä»¥ä½¿ç”¨L1æˆ–L2æŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒã€‚å…·ä½“çš„ç½‘ç»œç»“æž„ï¼ˆå·ç§¯å±‚æ•°ã€æ»¤æ³¢å™¨å¤§å°ã€æ¿€æ´»å‡½æ•°ç­‰ï¼‰ä»¥åŠé‡åŒ–æ–¹æ³•ç­‰ç»†èŠ‚ï¼Œéœ€è¦åœ¨è®ºæ–‡ä¸­è¿›ä¸€æ­¥æŸ¥æ‰¾ã€‚å‚æ•°è®¾ç½®å¯èƒ½éœ€è¦æ ¹æ®å…·ä½“æ•°æ®é›†å’Œç¡¬ä»¶å¹³å°è¿›è¡Œè°ƒæ•´ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è®ºæ–‡æå‡ºäº†EETnetï¼Œä¸€ä¸ªä¸“ä¸ºäº‹ä»¶æ•°æ®è®¾è®¡çš„è½»é‡çº§CNNï¼Œèƒ½å¤Ÿåœ¨å¾®æŽ§åˆ¶å™¨ä¸Šè¿è¡Œï¼Œå®žçŽ°äº†ä½ŽåŠŸè€—çš„çœ¼åŠ¨è¿½è¸ªã€‚è™½ç„¶æ‘˜è¦ä¸­æ²¡æœ‰ç»™å‡ºå…·ä½“çš„æ€§èƒ½æ•°æ®ï¼Œä½†å¼ºè°ƒäº†å…¶åœ¨åµŒå…¥å¼è®¾å¤‡ä¸Šçš„å¯è¡Œæ€§ï¼Œå¹¶æä¾›äº†è®­ç»ƒã€è¯„ä¼°å’Œé‡åŒ–ç½‘ç»œçš„æ–¹æ³•ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

EETnetåœ¨æ™ºèƒ½çœ¼é•œã€VR/ARè®¾å¤‡ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºŽç”¨æˆ·ç•Œé¢äº¤äº’ã€çœ¼æŽ§è¾“å…¥ã€æ³¨æ„åŠ›è¿½è¸ªã€è¾…åŠ©é©¾é©¶ç­‰åœºæ™¯ã€‚ä½ŽåŠŸè€—çš„ç‰¹æ€§ä½¿å…¶éžå¸¸é€‚åˆç”µæ± ä¾›ç”µçš„ç§»åŠ¨è®¾å¤‡ï¼Œèƒ½å¤Ÿæå‡ç”¨æˆ·ä½“éªŒå¹¶æ‰©å±•è®¾å¤‡çš„åŠŸèƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Event-based cameras are becoming a popular solution for efficient, low-power eye tracking. Due to the sparse and asynchronous nature of event data, they require less processing power and offer latencies in the microsecond range. However, many existing solutions are limited to validation on powerful GPUs, with no deployment on real embedded devices. In this paper, we present EETnet, a convolutional neural network designed for eye tracking using purely event-based data, capable of running on microcontrollers with limited resources. Additionally, we outline a methodology to train, evaluate, and quantize the network using a public dataset. Finally, we propose two versions of the architecture: a classification model that detects the pupil on a grid superimposed on the original image, and a regression model that operates at the pixel level.

