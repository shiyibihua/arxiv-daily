---
layout: default
title: On the Equivalence of Regression and Classification
---

# On the Equivalence of Regression and Classification

**arXiv**: [2511.04422v1](https://arxiv.org/abs/2511.04422) | [PDF](https://arxiv.org/pdf/2511.04422.pdf)

**ä½œè€…**: Jayadeva, Naman Dwivedi, Hari Krishnan, N. M. Anoop Krishnan

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå›å½’ä¸åˆ†ç±»ç­‰ä»·æ€§ç†è®ºï¼Œç”¨äºä¼°è®¡å›å½’éš¾åº¦å’Œè®­ç»ƒç¥ç»ç½‘ç»œçº¿æ€§åŒ–æ˜ å°„ã€‚**

**å…³é”®è¯**: `å›å½’åˆ†ç±»ç­‰ä»·æ€§` `marginæœ€å¤§åŒ–` `å¯å›å½’æ€§åº¦é‡` `ç¥ç»ç½‘ç»œçº¿æ€§åŒ–` `æ”¯æŒå‘é‡å›å½’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå›å½’ä¸åˆ†ç±»é—´ç¼ºä¹å½¢å¼ç­‰ä»·æ€§ï¼Œä¼ ç»Ÿæ–¹æ³•ä¸­marginé¡¹ä»…ä½œä¸ºæ­£åˆ™åŒ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè¯æ˜å›å½’é—®é¢˜ä¸çº¿æ€§å¯åˆ†åˆ†ç±»ä»»åŠ¡ç­‰ä»·ï¼ŒåŸºäºæ­¤æ¨å¯¼æ–°å›å½’å…¬å¼å’Œå¯å›å½’æ€§åº¦é‡ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šåº”ç”¨ç­‰ä»·æ€§è®­ç»ƒç¥ç»ç½‘ç»œå­¦ä¹ çº¿æ€§åŒ–æ˜ å°„ï¼Œæ— éœ€å…ˆå­¦ä¹ æ¨¡å‹å³å¯ä¼°è®¡å›å½’éš¾åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A formal link between regression and classification has been tenuous. Even
> though the margin maximization term $\\|w\\|$ is used in support vector
> regression, it has at best been justified as a regularizer. We show that a
> regression problem with $M$ samples lying on a hyperplane has a one-to-one
> equivalence with a linearly separable classification task with $2M$ samples. We
> show that margin maximization on the equivalent classification task leads to a
> different regression formulation than traditionally used. Using the
> equivalence, we demonstrate a ``regressability'' measure, that can be used to
> estimate the difficulty of regressing a dataset, without needing to first learn
> a model for it. We use the equivalence to train neural networks to learn a
> linearizing map, that transforms input variables into a space where a linear
> regressor is adequate.

