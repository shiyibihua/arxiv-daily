---
layout: default
title: CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation
---

# CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation

**arXiv**: [2511.03992v1](https://arxiv.org/abs/2511.03992) | [PDF](https://arxiv.org/pdf/2511.03992.pdf)

**ä½œè€…**: Yuwen Tao, Kanglei Zhou, Xin Tan, Yuan Xie

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCaRFä»¥å¢žå¼ºå¤šè§†å›¾ä¸€è‡´æ€§åœ¨å‚è€ƒ3Dé«˜æ–¯æ³¼æº…åˆ†å‰²ä¸­**

**å…³é”®è¯**: `3Dé«˜æ–¯æ³¼æº…åˆ†å‰²` `å¤šè§†å›¾ä¸€è‡´æ€§` `ç›¸æœºå‡ ä½•ç¼–ç ` `è·¨æ¨¡æ€å¯¹é½` `è§†å›¾ç›‘ç£ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•ä¾èµ–2Dæ¸²æŸ“ä¼ªç›‘ç£å’Œè§†å›¾ç‰¹å®šç‰¹å¾ï¼Œå¯¼è‡´è·¨è§†å›¾ä¸€è‡´æ€§å·®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥GFCEç¼–ç ç›¸æœºå‡ ä½•ï¼Œç»“åˆITPVSå¯¹é½è§†å›¾é—´é«˜æ–¯é€»è¾‘ä»¥ä¼˜åŒ–ä¸€è‡´æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­mIoUå¹³å‡æå‡16.8%ã€4.3%å’Œ2.0%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Referring 3D Gaussian Splatting Segmentation (R3DGS) aims to interpret
> free-form language expressions and localize the corresponding 3D regions in
> Gaussian fields. While recent advances have introduced cross-modal alignment
> between language and 3D geometry, existing pipelines still struggle with
> cross-view consistency due to their reliance on 2D rendered pseudo supervision
> and view specific feature learning. In this work, we present Camera Aware
> Referring Field (CaRF), a fully differentiable framework that operates directly
> in the 3D Gaussian space and achieves multi view consistency. Specifically,
> CaRF introduces Gaussian Field Camera Encoding (GFCE), which incorporates
> camera geometry into Gaussian text interactions to explicitly model view
> dependent variations and enhance geometric reasoning. Building on this, In
> Training Paired View Supervision (ITPVS) is proposed to align per Gaussian
> logits across calibrated views during training, effectively mitigating single
> view overfitting and exposing inter view discrepancies for optimization.
> Extensive experiments on three representative benchmarks demonstrate that CaRF
> achieves average improvements of 16.8%, 4.3%, and 2.0% in mIoU over state of
> the art methods on the Ref LERF, LERF OVS, and 3D OVS datasets, respectively.
> Moreover, this work promotes more reliable and view consistent 3D scene
> understanding, with potential benefits for embodied AI, AR/VR interaction, and
> autonomous perception.

