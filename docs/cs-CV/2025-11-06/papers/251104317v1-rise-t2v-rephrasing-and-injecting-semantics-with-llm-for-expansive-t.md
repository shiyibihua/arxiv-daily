---
layout: default
title: RISE-T2V: Rephrasing and Injecting Semantics with LLM for Expansive Text-to-Video Generation
---

# RISE-T2V: Rephrasing and Injecting Semantics with LLM for Expansive Text-to-Video Generation

**arXiv**: [2511.04317v1](https://arxiv.org/abs/2511.04317) | [PDF](https://arxiv.org/pdf/2511.04317.pdf)

**ä½œè€…**: Xiangjun Zhang, Litong Gong, Yinglin Zheng, Yansong Liu, Wentao Jiang, Mingyi Xu, Biao Wang, Tiezheng Ge, Ming Zeng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRISE-T2Væ¡†æž¶ï¼Œé€šè¿‡é›†æˆæç¤ºé‡è¿°å’Œè¯­ä¹‰ç‰¹å¾æå–ï¼Œæå‡æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆè´¨é‡ã€‚**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆ` `æç¤ºé‡è¿°` `è¯­ä¹‰ç‰¹å¾æå–` `æ‰©æ•£æ¨¡åž‹` `å¤§è¯­è¨€æ¨¡åž‹é›†æˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–‡æœ¬åˆ°è§†é¢‘æ¨¡åž‹å¯¹ç®€æ´æç¤ºç†è§£ä¸è¶³ï¼Œå¯¼è‡´è§†é¢‘è´¨é‡ä¸‹é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥Rephrasing Adapterï¼Œåˆ©ç”¨LLMéšè—çŠ¶æ€ä½œä¸ºæ¡ä»¶ï¼Œéšå¼é‡è¿°æç¤ºã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¡†æž¶é€šç”¨ï¼Œé€‚ç”¨äºŽå¤šç§è§†é¢‘æ‰©æ•£æ¨¡åž‹ï¼Œæ˜¾è‘—æå‡è§†é¢‘ç”Ÿæˆè´¨é‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Most text-to-video(T2V) diffusion models depend on pre-trained text encoders
> for semantic alignment, yet they often fail to maintain video quality when
> provided with concise prompts rather than well-designed ones. The primary issue
> lies in their limited textual semantics understanding. Moreover, these text
> encoders cannot rephrase prompts online to better align with user intentions,
> which limits both the scalability and usability of the models, To address these
> challenges, we introduce RISE-T2V, which uniquely integrates the processes of
> prompt rephrasing and semantic feature extraction into a single and seamless
> step instead of two separate steps. RISE-T2V is universal and can be applied to
> various pre-trained LLMs and video diffusion models(VDMs), significantly
> enhancing their capabilities for T2V tasks. We propose an innovative module
> called the Rephrasing Adapter, enabling diffusion models to utilize text hidden
> states during the next token prediction of the LLM as a condition for video
> generation. By employing a Rephrasing Adapter, the video generation model can
> implicitly rephrase basic prompts into more comprehensive representations that
> better match the user's intent. Furthermore, we leverage the powerful
> capabilities of LLMs to enable video generation models to accomplish a broader
> range of T2V tasks. Extensive experiments demonstrate that RISE-T2V is a
> versatile framework applicable to different video diffusion model
> architectures, significantly enhancing the ability of T2V models to generate
> high-quality videos that align with user intent. Visual results are available
> on the webpage at https://rise-t2v.github.io.

