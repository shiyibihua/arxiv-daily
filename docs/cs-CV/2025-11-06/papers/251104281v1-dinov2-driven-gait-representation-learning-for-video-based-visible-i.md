---
layout: default
title: DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification
---

# DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification

**arXiv**: [2511.04281v1](https://arxiv.org/abs/2511.04281) | [PDF](https://arxiv.org/pdf/2511.04281.pdf)

**ä½œè€…**: Yujie Yang, Shuang Li, Jun Ye, Neng Dong, Fan Li, Huafeng Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-06

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDinoGRLæ¡†æž¶ï¼Œåˆ©ç”¨DINOv2é©±åŠ¨çš„æ­¥æ€ç‰¹å¾å­¦ä¹ ï¼Œè§£å†³è§†é¢‘å¯è§å…‰-çº¢å¤–è¡Œäººé‡è¯†åˆ«é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è§†é¢‘è¡Œäººé‡è¯†åˆ«` `å¯è§å…‰-çº¢å¤–` `æ­¥æ€ç‰¹å¾å­¦ä¹ ` `DINOv2` `è·¨æ¨¡æ€æ£€ç´¢` `ç‰¹å¾èžåˆ` `æ·±åº¦å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VVI-ReIDæ–¹æ³•å¿½ç•¥äº†æ­¥æ€ç‰¹å¾ä¸­è•´å«çš„æ—¶ç©ºåŠ¨æ€ä¿¡æ¯ï¼Œé™åˆ¶äº†è·¨æ¨¡æ€è§†é¢‘åŒ¹é…çš„èƒ½åŠ›ã€‚
2. DinoGRLæ¡†æž¶åˆ©ç”¨DINOv2çš„è§†è§‰å…ˆéªŒå­¦ä¹ æ­¥æ€ç‰¹å¾ï¼Œå¹¶è®¾è®¡SASGLå’ŒPBMGEæ¨¡å—å¢žå¼ºç‰¹å¾è¡¨ç¤ºã€‚
3. åœ¨HITSZ-VCMå’ŒBUPTæ•°æ®é›†ä¸Šï¼ŒDinoGRLæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§DINOv2é©±åŠ¨çš„æ­¥æ€è¡¨ç¤ºå­¦ä¹ (DinoGRL)æ¡†æž¶ï¼Œç”¨äºŽè§£å†³åŸºäºŽè§†é¢‘çš„å¯è§å…‰-çº¢å¤–è¡Œäººé‡è¯†åˆ«(VVI-ReID)é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ä¾§é‡äºŽåˆ©ç”¨æ¨¡æ€ä¸å˜çš„è§†è§‰ç‰¹å¾ï¼Œä½†å¿½ç•¥äº†æ­¥æ€ç‰¹å¾ï¼Œè€Œæ­¥æ€ç‰¹å¾ä¸ä»…æ¨¡æ€ä¸å˜ï¼Œè€Œä¸”å¯Œå«æ—¶é—´åŠ¨æ€ä¿¡æ¯ï¼Œé™åˆ¶äº†å®ƒä»¬å¯¹è·¨æ¨¡æ€è§†é¢‘åŒ¹é…è‡³å…³é‡è¦çš„æ—¶ç©ºä¸€è‡´æ€§è¿›è¡Œå»ºæ¨¡çš„èƒ½åŠ›ã€‚DinoGRLæ¡†æž¶åˆ©ç”¨DINOv2ä¸°å¯Œçš„è§†è§‰å…ˆéªŒçŸ¥è¯†æ¥å­¦ä¹ æ­¥æ€ç‰¹å¾ï¼Œä½œä¸ºå¤–è§‚çº¿ç´¢çš„è¡¥å……ï¼Œä»Žè€Œä¿ƒè¿›äº†é²æ£’çš„åºåˆ—çº§è·¨æ¨¡æ€æ£€ç´¢è¡¨ç¤ºã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè¯­ä¹‰æ„ŸçŸ¥è½®å»“å’Œæ­¥æ€å­¦ä¹ (SASGL)æ¨¡åž‹ï¼Œè¯¥æ¨¡åž‹åˆ©ç”¨DINOv2çš„é€šç”¨è¯­ä¹‰å…ˆéªŒç”Ÿæˆå¹¶å¢žå¼ºè½®å»“è¡¨ç¤ºï¼Œå¹¶å°†å…¶ä¸ŽReIDç›®æ ‡è”åˆä¼˜åŒ–ï¼Œä»¥å®žçŽ°è¯­ä¹‰ä¸°å¯Œçš„ä»»åŠ¡è‡ªé€‚åº”æ­¥æ€ç‰¹å¾å­¦ä¹ ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªæ¸è¿›å¼åŒå‘å¤šç²’åº¦å¢žå¼º(PBMGE)æ¨¡å—ï¼Œé€šè¿‡åœ¨å¤šä¸ªç©ºé—´ç²’åº¦ä¸Šå®žçŽ°æ­¥æ€å’Œå¤–è§‚æµä¹‹é—´çš„åŒå‘äº¤äº’æ¥é€æ­¥ç»†åŒ–ç‰¹å¾è¡¨ç¤ºï¼Œå……åˆ†åˆ©ç”¨å®ƒä»¬çš„äº’è¡¥æ€§æ¥å¢žå¼ºå…·æœ‰ä¸°å¯Œå±€éƒ¨ç»†èŠ‚çš„å…¨å±€è¡¨ç¤ºï¼Œå¹¶äº§ç”Ÿé«˜åº¦åŒºåˆ†æ€§çš„ç‰¹å¾ã€‚åœ¨HITSZ-VCMå’ŒBUPTæ•°æ®é›†ä¸Šçš„å¤§é‡å®žéªŒè¡¨æ˜Žäº†æˆ‘ä»¬æ–¹æ³•çš„ä¼˜è¶Šæ€§ï¼Œæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†é¢‘å¯è§å…‰-çº¢å¤–è¡Œäººé‡è¯†åˆ«(VVI-ReID)æ—¨åœ¨ä»Žè§†é¢‘åºåˆ—ä¸­æ£€ç´¢è·¨å¯è§å…‰å’Œçº¢å¤–æ¨¡æ€çš„åŒä¸€è¡Œäººã€‚çŽ°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºŽæ¨¡æ€ä¸å˜çš„è§†è§‰ç‰¹å¾ï¼Œä½†å¿½ç•¥äº†æ­¥æ€ç‰¹å¾ï¼Œè€Œæ­¥æ€ç‰¹å¾å…·æœ‰æ¨¡æ€ä¸å˜æ€§å’Œä¸°å¯Œçš„æ—¶åºä¿¡æ¯ï¼Œå¯¹äºŽè·¨æ¨¡æ€è§†é¢‘åŒ¹é…è‡³å…³é‡è¦ã€‚å› æ­¤ï¼Œå¦‚ä½•æœ‰æ•ˆåˆ©ç”¨æ­¥æ€ç‰¹å¾ï¼Œæå‡VVI-ReIDçš„æ€§èƒ½æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„DINOv2æ¨¡åž‹æä¾›çš„è§†è§‰å…ˆéªŒçŸ¥è¯†ï¼Œæ¥æŒ‡å¯¼æ­¥æ€ç‰¹å¾çš„å­¦ä¹ ï¼Œå¹¶å°†å…¶ä¸Žå¤–è§‚ç‰¹å¾è¿›è¡Œäº’è¡¥å¢žå¼ºã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥å­¦ä¹ åˆ°æ›´å…·åˆ¤åˆ«æ€§å’Œé²æ£’æ€§çš„åºåˆ—çº§ç‰¹å¾è¡¨ç¤ºï¼Œä»Žè€Œæå‡è·¨æ¨¡æ€æ£€ç´¢çš„å‡†ç¡®çŽ‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šDinoGRLæ¡†æž¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šè¯­ä¹‰æ„ŸçŸ¥è½®å»“å’Œæ­¥æ€å­¦ä¹ (SASGL)æ¨¡åž‹å’Œæ¸è¿›å¼åŒå‘å¤šç²’åº¦å¢žå¼º(PBMGE)æ¨¡å—ã€‚SASGLæ¨¡åž‹è´Ÿè´£ç”Ÿæˆå’Œå¢žå¼ºè½®å»“è¡¨ç¤ºï¼Œå¹¶åˆ©ç”¨DINOv2çš„è¯­ä¹‰å…ˆéªŒè¿›è¡ŒæŒ‡å¯¼ã€‚PBMGEæ¨¡å—åˆ™é€šè¿‡åœ¨å¤šä¸ªç©ºé—´ç²’åº¦ä¸Šè¿›è¡Œæ­¥æ€å’Œå¤–è§‚ç‰¹å¾çš„åŒå‘äº¤äº’ï¼Œé€æ­¥ç»†åŒ–ç‰¹å¾è¡¨ç¤ºã€‚æ•´ä½“æµç¨‹æ˜¯é¦–å…ˆé€šè¿‡SASGLå­¦ä¹ æ­¥æ€ç‰¹å¾ï¼Œç„¶åŽé€šè¿‡PBMGEå°†æ­¥æ€ç‰¹å¾å’Œå¤–è§‚ç‰¹å¾èžåˆå¢žå¼ºï¼Œæœ€åŽç”¨äºŽè¡Œäººé‡è¯†åˆ«ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽä»¥ä¸‹å‡ ç‚¹ï¼š1) åˆ©ç”¨DINOv2çš„è§†è§‰å…ˆéªŒæ¥æŒ‡å¯¼æ­¥æ€ç‰¹å¾å­¦ä¹ ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ€è·¯ï¼Œå¯ä»¥æœ‰æ•ˆæå‡æ­¥æ€ç‰¹å¾çš„è´¨é‡ã€‚2) æå‡ºäº†SASGLæ¨¡åž‹ï¼Œèƒ½å¤Ÿç”Ÿæˆå’Œå¢žå¼ºè½®å»“è¡¨ç¤ºï¼Œå¹¶åˆ©ç”¨DINOv2çš„è¯­ä¹‰å…ˆéªŒè¿›è¡ŒæŒ‡å¯¼ï¼Œä»Žè€Œå­¦ä¹ åˆ°æ›´å…·åˆ¤åˆ«æ€§çš„æ­¥æ€ç‰¹å¾ã€‚3) æå‡ºäº†PBMGEæ¨¡å—ï¼Œé€šè¿‡åœ¨å¤šä¸ªç©ºé—´ç²’åº¦ä¸Šè¿›è¡Œæ­¥æ€å’Œå¤–è§‚ç‰¹å¾çš„åŒå‘äº¤äº’ï¼Œèƒ½å¤Ÿå……åˆ†åˆ©ç”¨å®ƒä»¬çš„äº’è¡¥æ€§ï¼Œä»Žè€Œæå‡æ•´ä½“çš„ç‰¹å¾è¡¨ç¤ºèƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šSASGLæ¨¡åž‹ä½¿ç”¨DINOv2æå–çš„è¯­ä¹‰ä¿¡æ¯æ¥å¢žå¼ºè½®å»“è¡¨ç¤ºï¼Œå…·ä½“å®žçŽ°æ–¹å¼æœªçŸ¥ã€‚PBMGEæ¨¡å—é‡‡ç”¨æ¸è¿›å¼çš„æ–¹å¼ï¼Œé€æ­¥èžåˆä¸åŒç²’åº¦çš„ç‰¹å¾ï¼Œå…·ä½“ç²’åº¦åˆ’åˆ†å’Œèžåˆæ–¹å¼æœªçŸ¥ã€‚æŸå¤±å‡½æ•°æ–¹é¢ï¼Œé™¤äº†ReIDçš„æŸå¤±å‡½æ•°å¤–ï¼Œå¯èƒ½è¿˜ä½¿ç”¨äº†å…¶ä»–çš„è¾…åŠ©æŸå¤±å‡½æ•°æ¥çº¦æŸæ­¥æ€ç‰¹å¾çš„å­¦ä¹ ï¼Œå…·ä½“ç»†èŠ‚æœªçŸ¥ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒDinoGRLæ¡†æž¶åœ¨HITSZ-VCMå’ŒBUPTæ•°æ®é›†ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†çŽ°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­ç»™å‡ºï¼Œä½†æ‘˜è¦ä¸­æœªæ˜Žç¡®æåŠã€‚è¿™äº›ç»“æžœéªŒè¯äº†DinoGRLæ¡†æž¶åœ¨VVI-ReIDä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæ™ºèƒ½å®‰é˜²ã€æ™ºæ…§åŸŽå¸‚ç­‰é¢†åŸŸï¼Œä¾‹å¦‚åœ¨è·¨æ‘„åƒå¤´åœºæ™¯ä¸‹è¿›è¡Œè¡Œäººè¿½è¸ªå’Œèº«ä»½è¯†åˆ«ã€‚é€šè¿‡ç»“åˆå¯è§å…‰å’Œçº¢å¤–æ¨¡æ€çš„ä¿¡æ¯ï¼Œå¯ä»¥æé«˜åœ¨å…‰ç…§æ¡ä»¶ä¸ä½³æˆ–å­˜åœ¨é®æŒ¡æƒ…å†µä¸‹çš„è¡Œäººé‡è¯†åˆ«å‡†ç¡®çŽ‡ï¼Œå…·æœ‰é‡è¦çš„å®žé™…åº”ç”¨ä»·å€¼ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–æ¨¡æ€çš„è¡Œäººé‡è¯†åˆ«ä»»åŠ¡ä¸­ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video-based Visible-Infrared person re-identification (VVI-ReID) aims to retrieve the same pedestrian across visible and infrared modalities from video sequences. Existing methods tend to exploit modality-invariant visual features but largely overlook gait features, which are not only modality-invariant but also rich in temporal dynamics, thus limiting their ability to model the spatiotemporal consistency essential for cross-modal video matching. To address these challenges, we propose a DINOv2-Driven Gait Representation Learning (DinoGRL) framework that leverages the rich visual priors of DINOv2 to learn gait features complementary to appearance cues, facilitating robust sequence-level representations for cross-modal retrieval. Specifically, we introduce a Semantic-Aware Silhouette and Gait Learning (SASGL) model, which generates and enhances silhouette representations with general-purpose semantic priors from DINOv2 and jointly optimizes them with the ReID objective to achieve semantically enriched and task-adaptive gait feature learning. Furthermore, we develop a Progressive Bidirectional Multi-Granularity Enhancement (PBMGE) module, which progressively refines feature representations by enabling bidirectional interactions between gait and appearance streams across multiple spatial granularities, fully leveraging their complementarity to enhance global representations with rich local details and produce highly discriminative features. Extensive experiments on HITSZ-VCM and BUPT datasets demonstrate the superiority of our approach, significantly outperforming existing state-of-the-art methods.

