---
layout: default
title: DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification
---

# DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.04281" target="_blank" class="toolbar-btn">arXiv: 2511.04281v1</a>
    <a href="https://arxiv.org/pdf/2511.04281.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.04281v1" 
            onclick="toggleFavorite(this, '2511.04281v1', 'DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yujie Yang, Shuang Li, Jun Ye, Neng Dong, Fan Li, Huafeng Li

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-06

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫DinoGRLÊ°ÜÊû∂ÔºåÂà©Áî®DINOv2È©±Âä®ÁöÑÊ≠•ÊÄÅÁâπÂæÅÂ≠¶‰π†ÔºåËß£ÂÜ≥ËßÜÈ¢ëÂèØËßÅÂÖâ-Á∫¢Â§ñË°å‰∫∫ÈáçËØÜÂà´ÈóÆÈ¢ò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëË°å‰∫∫ÈáçËØÜÂà´` `ÂèØËßÅÂÖâ-Á∫¢Â§ñ` `Ê≠•ÊÄÅÁâπÂæÅÂ≠¶‰π†` `DINOv2` `Ë∑®Ê®°ÊÄÅÊ£ÄÁ¥¢` `ÁâπÂæÅËûçÂêà` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVVI-ReIDÊñπÊ≥ïÂøΩÁï•‰∫ÜÊ≠•ÊÄÅÁâπÂæÅ‰∏≠Ëï¥Âê´ÁöÑÊó∂Á©∫Âä®ÊÄÅ‰ø°ÊÅØÔºåÈôêÂà∂‰∫ÜË∑®Ê®°ÊÄÅËßÜÈ¢ëÂåπÈÖçÁöÑËÉΩÂäõ„ÄÇ
2. DinoGRLÊ°ÜÊû∂Âà©Áî®DINOv2ÁöÑËßÜËßâÂÖàÈ™åÂ≠¶‰π†Ê≠•ÊÄÅÁâπÂæÅÔºåÂπ∂ËÆæËÆ°SASGLÂíåPBMGEÊ®°ÂùóÂ¢ûÂº∫ÁâπÂæÅË°®Á§∫„ÄÇ
3. Âú®HITSZ-VCMÂíåBUPTÊï∞ÊçÆÈõÜ‰∏äÔºåDinoGRLÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçDINOv2È©±Âä®ÁöÑÊ≠•ÊÄÅË°®Á§∫Â≠¶‰π†(DinoGRL)Ê°ÜÊû∂ÔºåÁî®‰∫éËß£ÂÜ≥Âü∫‰∫éËßÜÈ¢ëÁöÑÂèØËßÅÂÖâ-Á∫¢Â§ñË°å‰∫∫ÈáçËØÜÂà´(VVI-ReID)ÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰æßÈáç‰∫éÂà©Áî®Ê®°ÊÄÅ‰∏çÂèòÁöÑËßÜËßâÁâπÂæÅÔºå‰ΩÜÂøΩÁï•‰∫ÜÊ≠•ÊÄÅÁâπÂæÅÔºåËÄåÊ≠•ÊÄÅÁâπÂæÅ‰∏ç‰ªÖÊ®°ÊÄÅ‰∏çÂèòÔºåËÄå‰∏îÂØåÂê´Êó∂Èó¥Âä®ÊÄÅ‰ø°ÊÅØÔºåÈôêÂà∂‰∫ÜÂÆÉ‰ª¨ÂØπË∑®Ê®°ÊÄÅËßÜÈ¢ëÂåπÈÖçËá≥ÂÖ≥ÈáçË¶ÅÁöÑÊó∂Á©∫‰∏ÄËá¥ÊÄßËøõË°åÂª∫Ê®°ÁöÑËÉΩÂäõ„ÄÇDinoGRLÊ°ÜÊû∂Âà©Áî®DINOv2‰∏∞ÂØåÁöÑËßÜËßâÂÖàÈ™åÁü•ËØÜÊù•Â≠¶‰π†Ê≠•ÊÄÅÁâπÂæÅÔºå‰Ωú‰∏∫Â§ñËßÇÁ∫øÁ¥¢ÁöÑË°•ÂÖÖÔºå‰ªéËÄå‰øÉËøõ‰∫ÜÈ≤ÅÊ£íÁöÑÂ∫èÂàóÁ∫ßË∑®Ê®°ÊÄÅÊ£ÄÁ¥¢Ë°®Á§∫„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ËØ≠‰πâÊÑüÁü•ËΩÆÂªìÂíåÊ≠•ÊÄÅÂ≠¶‰π†(SASGL)Ê®°ÂûãÔºåËØ•Ê®°ÂûãÂà©Áî®DINOv2ÁöÑÈÄöÁî®ËØ≠‰πâÂÖàÈ™åÁîüÊàêÂπ∂Â¢ûÂº∫ËΩÆÂªìË°®Á§∫ÔºåÂπ∂Â∞ÜÂÖ∂‰∏éReIDÁõÆÊ†áËÅîÂêà‰ºòÂåñÔºå‰ª•ÂÆûÁé∞ËØ≠‰πâ‰∏∞ÂØåÁöÑ‰ªªÂä°Ëá™ÈÄÇÂ∫îÊ≠•ÊÄÅÁâπÂæÅÂ≠¶‰π†„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∏™Ê∏êËøõÂºèÂèåÂêëÂ§öÁ≤íÂ∫¶Â¢ûÂº∫(PBMGE)Ê®°ÂùóÔºåÈÄöËøáÂú®Â§ö‰∏™Á©∫Èó¥Á≤íÂ∫¶‰∏äÂÆûÁé∞Ê≠•ÊÄÅÂíåÂ§ñËßÇÊµÅ‰πãÈó¥ÁöÑÂèåÂêë‰∫§‰∫íÊù•ÈÄêÊ≠•ÁªÜÂåñÁâπÂæÅË°®Á§∫ÔºåÂÖÖÂàÜÂà©Áî®ÂÆÉ‰ª¨ÁöÑ‰∫íË°•ÊÄßÊù•Â¢ûÂº∫ÂÖ∑Êúâ‰∏∞ÂØåÂ±ÄÈÉ®ÁªÜËäÇÁöÑÂÖ®Â±ÄË°®Á§∫ÔºåÂπ∂‰∫ßÁîüÈ´òÂ∫¶Âå∫ÂàÜÊÄßÁöÑÁâπÂæÅ„ÄÇÂú®HITSZ-VCMÂíåBUPTÊï∞ÊçÆÈõÜ‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®Êòé‰∫ÜÊàë‰ª¨ÊñπÊ≥ïÁöÑ‰ºòË∂äÊÄßÔºåÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËßÜÈ¢ëÂèØËßÅÂÖâ-Á∫¢Â§ñË°å‰∫∫ÈáçËØÜÂà´(VVI-ReID)Êó®Âú®‰ªéËßÜÈ¢ëÂ∫èÂàó‰∏≠Ê£ÄÁ¥¢Ë∑®ÂèØËßÅÂÖâÂíåÁ∫¢Â§ñÊ®°ÊÄÅÁöÑÂêå‰∏ÄË°å‰∫∫„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶Å‰æùËµñ‰∫éÊ®°ÊÄÅ‰∏çÂèòÁöÑËßÜËßâÁâπÂæÅÔºå‰ΩÜÂøΩÁï•‰∫ÜÊ≠•ÊÄÅÁâπÂæÅÔºåËÄåÊ≠•ÊÄÅÁâπÂæÅÂÖ∑ÊúâÊ®°ÊÄÅ‰∏çÂèòÊÄßÂíå‰∏∞ÂØåÁöÑÊó∂Â∫è‰ø°ÊÅØÔºåÂØπ‰∫éË∑®Ê®°ÊÄÅËßÜÈ¢ëÂåπÈÖçËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÊúâÊïàÂà©Áî®Ê≠•ÊÄÅÁâπÂæÅÔºåÊèêÂçáVVI-ReIDÁöÑÊÄßËÉΩÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑDINOv2Ê®°ÂûãÊèê‰æõÁöÑËßÜËßâÂÖàÈ™åÁü•ËØÜÔºåÊù•ÊåáÂØºÊ≠•ÊÄÅÁâπÂæÅÁöÑÂ≠¶‰π†ÔºåÂπ∂Â∞ÜÂÖ∂‰∏éÂ§ñËßÇÁâπÂæÅËøõË°å‰∫íË°•Â¢ûÂº∫„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÂèØ‰ª•Â≠¶‰π†Âà∞Êõ¥ÂÖ∑Âà§Âà´ÊÄßÂíåÈ≤ÅÊ£íÊÄßÁöÑÂ∫èÂàóÁ∫ßÁâπÂæÅË°®Á§∫Ôºå‰ªéËÄåÊèêÂçáË∑®Ê®°ÊÄÅÊ£ÄÁ¥¢ÁöÑÂáÜÁ°ÆÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöDinoGRLÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™Ê†∏ÂøÉÊ®°ÂùóÔºöËØ≠‰πâÊÑüÁü•ËΩÆÂªìÂíåÊ≠•ÊÄÅÂ≠¶‰π†(SASGL)Ê®°ÂûãÂíåÊ∏êËøõÂºèÂèåÂêëÂ§öÁ≤íÂ∫¶Â¢ûÂº∫(PBMGE)Ê®°Âùó„ÄÇSASGLÊ®°ÂûãË¥üË¥£ÁîüÊàêÂíåÂ¢ûÂº∫ËΩÆÂªìË°®Á§∫ÔºåÂπ∂Âà©Áî®DINOv2ÁöÑËØ≠‰πâÂÖàÈ™åËøõË°åÊåáÂØº„ÄÇPBMGEÊ®°ÂùóÂàôÈÄöËøáÂú®Â§ö‰∏™Á©∫Èó¥Á≤íÂ∫¶‰∏äËøõË°åÊ≠•ÊÄÅÂíåÂ§ñËßÇÁâπÂæÅÁöÑÂèåÂêë‰∫§‰∫íÔºåÈÄêÊ≠•ÁªÜÂåñÁâπÂæÅË°®Á§∫„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÈ¶ñÂÖàÈÄöËøáSASGLÂ≠¶‰π†Ê≠•ÊÄÅÁâπÂæÅÔºåÁÑ∂ÂêéÈÄöËøáPBMGEÂ∞ÜÊ≠•ÊÄÅÁâπÂæÅÂíåÂ§ñËßÇÁâπÂæÅËûçÂêàÂ¢ûÂº∫ÔºåÊúÄÂêéÁî®‰∫éË°å‰∫∫ÈáçËØÜÂà´„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ª•‰∏ãÂá†ÁÇπÔºö1) Âà©Áî®DINOv2ÁöÑËßÜËßâÂÖàÈ™åÊù•ÊåáÂØºÊ≠•ÊÄÅÁâπÂæÅÂ≠¶‰π†ÔºåËøôÊòØ‰∏ÄÁßçÊñ∞È¢ñÁöÑÊÄùË∑ØÔºåÂèØ‰ª•ÊúâÊïàÊèêÂçáÊ≠•ÊÄÅÁâπÂæÅÁöÑË¥®Èáè„ÄÇ2) ÊèêÂá∫‰∫ÜSASGLÊ®°ÂûãÔºåËÉΩÂ§üÁîüÊàêÂíåÂ¢ûÂº∫ËΩÆÂªìË°®Á§∫ÔºåÂπ∂Âà©Áî®DINOv2ÁöÑËØ≠‰πâÂÖàÈ™åËøõË°åÊåáÂØºÔºå‰ªéËÄåÂ≠¶‰π†Âà∞Êõ¥ÂÖ∑Âà§Âà´ÊÄßÁöÑÊ≠•ÊÄÅÁâπÂæÅ„ÄÇ3) ÊèêÂá∫‰∫ÜPBMGEÊ®°ÂùóÔºåÈÄöËøáÂú®Â§ö‰∏™Á©∫Èó¥Á≤íÂ∫¶‰∏äËøõË°åÊ≠•ÊÄÅÂíåÂ§ñËßÇÁâπÂæÅÁöÑÂèåÂêë‰∫§‰∫íÔºåËÉΩÂ§üÂÖÖÂàÜÂà©Áî®ÂÆÉ‰ª¨ÁöÑ‰∫íË°•ÊÄßÔºå‰ªéËÄåÊèêÂçáÊï¥‰ΩìÁöÑÁâπÂæÅË°®Á§∫ËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöSASGLÊ®°Âûã‰ΩøÁî®DINOv2ÊèêÂèñÁöÑËØ≠‰πâ‰ø°ÊÅØÊù•Â¢ûÂº∫ËΩÆÂªìË°®Á§∫ÔºåÂÖ∑‰ΩìÂÆûÁé∞ÊñπÂºèÊú™Áü•„ÄÇPBMGEÊ®°ÂùóÈááÁî®Ê∏êËøõÂºèÁöÑÊñπÂºèÔºåÈÄêÊ≠•ËûçÂêà‰∏çÂêåÁ≤íÂ∫¶ÁöÑÁâπÂæÅÔºåÂÖ∑‰ΩìÁ≤íÂ∫¶ÂàíÂàÜÂíåËûçÂêàÊñπÂºèÊú™Áü•„ÄÇÊçüÂ§±ÂáΩÊï∞ÊñπÈù¢ÔºåÈô§‰∫ÜReIDÁöÑÊçüÂ§±ÂáΩÊï∞Â§ñÔºåÂèØËÉΩËøò‰ΩøÁî®‰∫ÜÂÖ∂‰ªñÁöÑËæÖÂä©ÊçüÂ§±ÂáΩÊï∞Êù•Á∫¶ÊùüÊ≠•ÊÄÅÁâπÂæÅÁöÑÂ≠¶‰π†ÔºåÂÖ∑‰ΩìÁªÜËäÇÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåDinoGRLÊ°ÜÊû∂Âú®HITSZ-VCMÂíåBUPTÊï∞ÊçÆÈõÜ‰∏äÂùáÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÊèêÂçáÂπÖÂ∫¶Âú®ËÆ∫Êñá‰∏≠ÁªôÂá∫Ôºå‰ΩÜÊëòË¶Å‰∏≠Êú™ÊòéÁ°ÆÊèêÂèä„ÄÇËøô‰∫õÁªìÊûúÈ™åËØÅ‰∫ÜDinoGRLÊ°ÜÊû∂Âú®VVI-ReID‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩÂÆâÈò≤„ÄÅÊô∫ÊÖßÂüéÂ∏ÇÁ≠âÈ¢ÜÂüüÔºå‰æãÂ¶ÇÂú®Ë∑®ÊëÑÂÉèÂ§¥Âú∫ÊôØ‰∏ãËøõË°åË°å‰∫∫ËøΩË∏™ÂíåË∫´‰ªΩËØÜÂà´„ÄÇÈÄöËøáÁªìÂêàÂèØËßÅÂÖâÂíåÁ∫¢Â§ñÊ®°ÊÄÅÁöÑ‰ø°ÊÅØÔºåÂèØ‰ª•ÊèêÈ´òÂú®ÂÖâÁÖßÊù°‰ª∂‰∏ç‰Ω≥ÊàñÂ≠òÂú®ÈÅÆÊå°ÊÉÖÂÜµ‰∏ãÁöÑË°å‰∫∫ÈáçËØÜÂà´ÂáÜÁ°ÆÁéáÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄº„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÊ®°ÊÄÅÁöÑË°å‰∫∫ÈáçËØÜÂà´‰ªªÂä°‰∏≠„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Video-based Visible-Infrared person re-identification (VVI-ReID) aims to retrieve the same pedestrian across visible and infrared modalities from video sequences. Existing methods tend to exploit modality-invariant visual features but largely overlook gait features, which are not only modality-invariant but also rich in temporal dynamics, thus limiting their ability to model the spatiotemporal consistency essential for cross-modal video matching. To address these challenges, we propose a DINOv2-Driven Gait Representation Learning (DinoGRL) framework that leverages the rich visual priors of DINOv2 to learn gait features complementary to appearance cues, facilitating robust sequence-level representations for cross-modal retrieval. Specifically, we introduce a Semantic-Aware Silhouette and Gait Learning (SASGL) model, which generates and enhances silhouette representations with general-purpose semantic priors from DINOv2 and jointly optimizes them with the ReID objective to achieve semantically enriched and task-adaptive gait feature learning. Furthermore, we develop a Progressive Bidirectional Multi-Granularity Enhancement (PBMGE) module, which progressively refines feature representations by enabling bidirectional interactions between gait and appearance streams across multiple spatial granularities, fully leveraging their complementarity to enhance global representations with rich local details and produce highly discriminative features. Extensive experiments on HITSZ-VCM and BUPT datasets demonstrate the superiority of our approach, significantly outperforming existing state-of-the-art methods.

