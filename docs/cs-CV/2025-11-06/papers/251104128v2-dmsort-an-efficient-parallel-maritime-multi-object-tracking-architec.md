---
layout: default
title: DMSORT: An efficient parallel maritime multi-object tracking architecture for unmanned vessel platforms
---

# DMSORT: An efficient parallel maritime multi-object tracking architecture for unmanned vessel platforms

**arXiv**: [2511.04128v2](https://arxiv.org/abs/2511.04128) | [PDF](https://arxiv.org/pdf/2511.04128.pdf)

**ä½œè€…**: Shengyu Tang, Zeyuan Lu, Jiazhi Dong, Changdong Yu, Xiaoyu Wang, Yaohui Lyu, Weihao Xia

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-06 (æ›´æ–°: 2025-11-16)

**å¤‡æ³¨**: This version clarifies several citation formatting inconsistencies caused by a technical issue in the reference management software used during manuscript preparation. All scientific data, experiments, and conclusions remain fully valid and unaffected. The clarification is provided to maintain transparency and consistency in the scholarly record

**DOI**: [10.1016/j.oceaneng.2025.123045](https://doi.org/10.1016/j.oceaneng.2025.123045)

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/BiscuitsLzy/DMSORT-An-efficient-parallel-maritime-multi-object-tracking-architecture-)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DMSORTï¼šä¸€ç§é«˜æ•ˆçš„å¹¶è¡Œæµ·äº‹å¤šç›®æ ‡è·Ÿè¸ªæž¶æž„ï¼Œé€‚ç”¨äºŽæ— äººèˆ¹å¹³å°**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å¤šç›®æ ‡è·Ÿè¸ª` `æ— äººèˆ¹` `æµ·äº‹çŽ¯å¢ƒ` `è¿åŠ¨è¡¥å¿` `æ·±åº¦å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤æ‚æµ·äº‹çŽ¯å¢ƒä¸‹çš„ç›¸æœºè¿åŠ¨å’Œè§†è§‰é€€åŒ–å¯¹å¤šç›®æ ‡è·Ÿè¸ªï¼ˆMOTï¼‰æž„æˆæŒ‘æˆ˜ï¼ŒçŽ°æœ‰æ–¹æ³•éš¾ä»¥å…¼é¡¾ç²¾åº¦ä¸Žé€Ÿåº¦ã€‚
2. DMSORTé‡‡ç”¨åŒåˆ†æ”¯å¹¶è¡Œè·Ÿè¸ªå™¨ï¼Œåˆ†åˆ«å¤„ç†ç›®æ ‡æ£€æµ‹ä¸Žé‡è¯†åˆ«ä»¥åŠåŠ¨æ€ç›¸æœºè¿åŠ¨ä¼°è®¡ï¼Œå®žçŽ°è¿åŠ¨è¡¥å¿ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒDMSORTåœ¨æ–°åŠ å¡æµ·äº‹æ•°æ®é›†ä¸Šè¾¾åˆ°SOTAæ€§èƒ½ï¼Œå¹¶åœ¨ä¿æŒé«˜ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œè¿è¡Œé€Ÿåº¦æœ€å¿«ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†ç¡®ä¿èˆ¹èˆ¶å®‰å…¨èˆªè¡Œå’Œæœ‰æ•ˆæµ·äº‹ç›‘è§†ï¼Œé€šè¿‡ç¨³å¥çš„å¤šç›®æ ‡è·Ÿè¸ªï¼ˆMOTï¼‰å¯¹æµ·æ´‹çŽ¯å¢ƒè¿›è¡Œç²¾ç¡®æ„ŸçŸ¥è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå¤æ‚çš„æµ·äº‹çŽ¯å¢ƒç»å¸¸å¯¼è‡´ç›¸æœºè¿åŠ¨å’ŒéšåŽçš„è§†è§‰é€€åŒ–ï¼Œç»™MOTå¸¦æ¥é‡å¤§æŒ‘æˆ˜ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„åŒåˆ†æ”¯æµ·äº‹SORTï¼ˆDMSORTï¼‰æ–¹æ³•ç”¨äºŽæµ·äº‹MOTã€‚è¯¥æ¡†æž¶çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªå…·æœ‰ä»¿å°„è¡¥å¿çš„å¹¶è¡Œè·Ÿè¸ªå™¨ï¼Œå®ƒç»“åˆäº†ä¸€ä¸ªç›®æ ‡æ£€æµ‹å’Œé‡è¯†åˆ«ï¼ˆReIDï¼‰åˆ†æ”¯ï¼Œä»¥åŠä¸€ä¸ªç”¨äºŽåŠ¨æ€ç›¸æœºè¿åŠ¨ä¼°è®¡çš„ä¸“ç”¨åˆ†æ”¯ã€‚å…·ä½“æ¥è¯´ï¼Œä¸€ä¸ªå¯é€†æŸ±çŠ¶æ£€æµ‹ç½‘ç»œï¼ˆRCDNï¼‰è¢«é›†æˆåˆ°æ£€æµ‹æ¨¡å—ä¸­ï¼Œä»¥åˆ©ç”¨å¤šå±‚æ¬¡çš„è§†è§‰ç‰¹å¾è¿›è¡Œé²æ£’çš„ç›®æ ‡æ£€æµ‹ã€‚æ­¤å¤–ï¼Œè®¾è®¡äº†ä¸€ä¸ªè½»é‡çº§çš„åŸºäºŽTransformerçš„å¤–è§‚æå–å™¨ï¼ˆLi-TAEï¼‰æ¥æ•èŽ·å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯å¹¶ç”Ÿæˆé²æ£’çš„å¤–è§‚ç‰¹å¾ã€‚å¦ä¸€ä¸ªåˆ†æ”¯é€šè¿‡æž„å»ºæŠ•å½±å˜æ¢æ¥è§£è€¦å¹³å°å¼•èµ·çš„è¿åŠ¨å’Œç›®æ ‡å›ºæœ‰çš„è¿åŠ¨ï¼Œåœ¨å¡å°”æ›¼æ»¤æ³¢å™¨ä¸­åº”ç”¨å¹³å°è¿åŠ¨è¡¥å¿ï¼Œä»Žè€Œç¨³å®šçœŸå®žçš„ç›®æ ‡è½¨è¿¹ã€‚æœ€åŽï¼Œä¸€ä¸ªèšç±»ä¼˜åŒ–çš„ç‰¹å¾èžåˆæ¨¡å—æœ‰æ•ˆåœ°ç»“åˆäº†è¿åŠ¨å’Œå¤–è§‚çº¿ç´¢ï¼Œä»¥ç¡®ä¿åœ¨å™ªå£°ã€é®æŒ¡å’Œæ¼‚ç§»ä¸‹çš„èº«ä»½ä¸€è‡´æ€§ã€‚åœ¨æ–°åŠ å¡æµ·äº‹æ•°æ®é›†ä¸Šçš„å¤§é‡è¯„ä¼°è¡¨æ˜Žï¼ŒDMSORTå®žçŽ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒDMSORTåœ¨çŽ°æœ‰çš„åŸºäºŽReIDçš„MOTæ¡†æž¶ä¸­å®žçŽ°äº†æœ€å¿«çš„è¿è¡Œæ—¶é—´ï¼ŒåŒæ—¶ä¿æŒäº†é«˜èº«ä»½ä¸€è‡´æ€§å’Œå¯¹æŠ–åŠ¨å’Œé®æŒ¡çš„é²æ£’æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤æ‚æµ·äº‹çŽ¯å¢ƒä¸‹ï¼Œç”±äºŽç›¸æœºè¿åŠ¨å’Œè§†è§‰é€€åŒ–å¯¼è‡´çš„å¤šç›®æ ‡è·Ÿè¸ªï¼ˆMOTï¼‰é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•éš¾ä»¥åœ¨ç²¾åº¦ã€é€Ÿåº¦å’Œé²æ£’æ€§ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œå°¤å…¶æ˜¯åœ¨å­˜åœ¨å™ªå£°ã€é®æŒ¡å’Œæ¼‚ç§»çš„æƒ…å†µä¸‹ï¼Œç›®æ ‡èº«ä»½å®¹æ˜“ä¸¢å¤±ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDMSORTçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†MOTä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªå¹¶è¡Œåˆ†æ”¯ï¼šä¸€ä¸ªåˆ†æ”¯è´Ÿè´£ç›®æ ‡æ£€æµ‹å’Œé‡è¯†åˆ«ï¼ˆReIDï¼‰ï¼Œæå–ç›®æ ‡çš„è§†è§‰ç‰¹å¾ï¼›å¦ä¸€ä¸ªåˆ†æ”¯è´Ÿè´£ä¼°è®¡å’Œè¡¥å¿ç”±å¹³å°è¿åŠ¨å¼•èµ·çš„ç›¸æœºè¿åŠ¨ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è§£è€¦å¹³å°è¿åŠ¨å’Œç›®æ ‡è‡ªèº«è¿åŠ¨ï¼Œä»Žè€Œæé«˜è·Ÿè¸ªçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šDMSORTçš„æ•´ä½“æž¶æž„æ˜¯ä¸€ä¸ªåŒåˆ†æ”¯å¹¶è¡Œè·Ÿè¸ªå™¨ã€‚ä¸»è¦åŒ…å«ä»¥ä¸‹æ¨¡å—ï¼š1) Reversible Columnar Detection Network (RCDN)ï¼šç”¨äºŽç›®æ ‡æ£€æµ‹ï¼Œæå–å¤šå±‚æ¬¡è§†è§‰ç‰¹å¾ã€‚2) Lightweight Transformer-based Appearance Extractor (Li-TAE)ï¼šç”¨äºŽæå–ç›®æ ‡çš„å…¨å±€ä¸Šä¸‹æ–‡å¤–è§‚ç‰¹å¾ã€‚3) è¿åŠ¨ä¼°è®¡åˆ†æ”¯ï¼šé€šè¿‡æž„å»ºæŠ•å½±å˜æ¢ä¼°è®¡å¹³å°è¿åŠ¨ã€‚4) å¡å°”æ›¼æ»¤æ³¢å™¨ï¼šç»“åˆè¿åŠ¨ä¼°è®¡ç»“æžœè¿›è¡Œå¹³å°è¿åŠ¨è¡¥å¿ï¼Œç¨³å®šç›®æ ‡è½¨è¿¹ã€‚5) èšç±»ä¼˜åŒ–çš„ç‰¹å¾èžåˆæ¨¡å—ï¼šèžåˆè¿åŠ¨å’Œå¤–è§‚ç‰¹å¾ï¼Œç¡®ä¿èº«ä»½ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šDMSORTçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶åŒåˆ†æ”¯å¹¶è¡Œè·Ÿè¸ªæž¶æž„å’Œè¿åŠ¨è¡¥å¿æœºåˆ¶ã€‚é€šè¿‡å¹¶è¡Œå¤„ç†è§†è§‰ç‰¹å¾å’Œè¿åŠ¨ä¿¡æ¯ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°åº”å¯¹å¤æ‚æµ·äº‹çŽ¯å¢ƒä¸­çš„æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼ŒRCDNå’ŒLi-TAEçš„è®¾è®¡ä¹Ÿæé«˜äº†ç›®æ ‡æ£€æµ‹å’Œå¤–è§‚ç‰¹å¾æå–çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šRCDNé‡‡ç”¨å¯é€†æŸ±çŠ¶ç»“æž„ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°åˆ©ç”¨å¤šå±‚æ¬¡è§†è§‰ç‰¹å¾ã€‚Li-TAEé‡‡ç”¨è½»é‡çº§Transformerç»“æž„ï¼Œå¯ä»¥åœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶é™ä½Žè®¡ç®—å¤æ‚åº¦ã€‚è¿åŠ¨ä¼°è®¡åˆ†æ”¯é€šè¿‡æž„å»ºæŠ•å½±å˜æ¢æ¥ä¼°è®¡å¹³å°è¿åŠ¨ï¼Œå¹¶å°†å…¶åº”ç”¨äºŽå¡å°”æ›¼æ»¤æ³¢å™¨ä¸­è¿›è¡Œè¿åŠ¨è¡¥å¿ã€‚èšç±»ä¼˜åŒ–çš„ç‰¹å¾èžåˆæ¨¡å—é‡‡ç”¨è‡ªé€‚åº”æƒé‡ï¼Œæ ¹æ®ä¸åŒæƒ…å†µè°ƒæ•´è¿åŠ¨å’Œå¤–è§‚ç‰¹å¾çš„è´¡çŒ®ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

DMSORTåœ¨æ–°åŠ å¡æµ·äº‹æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨MOTAã€IDF1ç­‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒDMSORTåœ¨ä¿æŒé«˜èº«ä»½ä¸€è‡´æ€§å’Œå¯¹æŠ–åŠ¨å’Œé®æŒ¡çš„é²æ£’æ€§çš„åŒæ—¶ï¼Œå®žçŽ°äº†æœ€å¿«çš„è¿è¡Œé€Ÿåº¦ï¼Œä½¿å…¶æ›´é€‚åˆäºŽå®žæ—¶åº”ç”¨ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

DMSORTå¯å¹¿æ³›åº”ç”¨äºŽæ— äººèˆ¹ã€è‡ªä¸»æ°´é¢èˆ°è‰‡ç­‰å¹³å°ï¼Œå®žçŽ°è‡ªä¸»å¯¼èˆªã€çŽ¯å¢ƒæ„ŸçŸ¥å’Œç›®æ ‡ç›‘è§†ã€‚è¯¥ç ”ç©¶æˆæžœæœ‰åŠ©äºŽæå‡æµ·ä¸Šäº¤é€šå®‰å…¨ã€æµ·æ´‹èµ„æºç®¡ç†å’Œæµ·ä¸Šå®‰é˜²èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®žé™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„å‘å±•å‰æ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Accurate perception of the marine environment through robust multi-object tracking (MOT) is essential for ensuring safe vessel navigation and effective maritime surveillance. However, the complicated maritime environment often causes camera motion and subsequent visual degradation, posing significant challenges to MOT. To address this challenge, we propose an efficient Dual-branch Maritime SORT (DMSORT) method for maritime MOT. The core of the framework is a parallel tracker with affine compensation, which incorporates an object detection and re-identification (ReID) branch, along with a dedicated branch for dynamic camera motion estimation. Specifically, a Reversible Columnar Detection Network (RCDN) is integrated into the detection module to leverage multi-level visual features for robust object detection. Furthermore, a lightweight Transformer-based appearance extractor (Li-TAE) is designed to capture global contextual information and generate robust appearance features. Another branch decouples platform-induced and target-intrinsic motion by constructing a projective transformation, applying platform-motion compensation within the Kalman filter, and thereby stabilizing true object trajectories. Finally, a clustering-optimized feature fusion module effectively combines motion and appearance cues to ensure identity consistency under noise, occlusion, and drift. Extensive evaluations on the Singapore Maritime Dataset demonstrate that DMSORT achieves state-of-the-art performance. Notably, DMSORT attains the fastest runtime among existing ReID-based MOT frameworks while maintaining high identity consistency and robustness to jitter and occlusion. Code is available at: https://github.com/BiscuitsLzy/DMSORT-An-efficient-parallel-maritime-multi-object-tracking-architecture-.

