---
layout: default
title: When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation
---

# When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation

**arXiv**: [2511.04084v1](https://arxiv.org/abs/2511.04084) | [PDF](https://arxiv.org/pdf/2511.04084.pdf)

**ä½œè€…**: Nishchal Sapkota, Haoyan Shi, Yejia Zhang, Xianshi Ma, Bofang Zheng, Danny Z. Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUKASTæž¶æž„ï¼Œé›†æˆKANsäºŽSwin Transformerï¼Œæå‡åŒ»å­¦å›¾åƒåˆ†å‰²çš„æ•°æ®æ•ˆçŽ‡ä¸Žæ€§èƒ½ã€‚**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒåˆ†å‰²` `Swin Transformer` `Kolmogorov-Arnoldç½‘ç»œ` `æ•°æ®æ•ˆçŽ‡` `å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åŒ»å­¦å›¾åƒåˆ†å‰²é¢ä¸´é•¿ç¨‹ä¾èµ–å»ºæ¨¡éš¾å’Œæ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚
2. åœ¨Swin Transformerç¼–ç å™¨ä¸­å¼•å…¥æœ‰ç†å‡½æ•°KANsï¼Œä¼˜åŒ–è®¡ç®—æ•ˆçŽ‡ä¸Žè¡¨è¾¾èƒ½åŠ›ã€‚
3. åœ¨å¤šä¸ª2D/3DåŸºå‡†æµ‹è¯•ä¸­å®žçŽ°SOTAï¼Œæ•°æ®ç¨€ç¼ºä¸‹è¡¨çŽ°ä¼˜å¼‚ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Medical image segmentation is critical for accurate diagnostics and treatment
> planning, but remains challenging due to complex anatomical structures and
> limited annotated training data. CNN-based segmentation methods excel at local
> feature extraction, but struggle with modeling long-range dependencies.
> Transformers, on the other hand, capture global context more effectively, but
> are inherently data-hungry and computationally expensive. In this work, we
> introduce UKAST, a U-Net like architecture that integrates rational-function
> based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders. By
> leveraging rational base functions and Group Rational KANs (GR-KANs) from the
> Kolmogorov-Arnold Transformer (KAT), our architecture addresses the
> inefficiencies of vanilla spline-based KANs, yielding a more expressive and
> data-efficient framework with reduced FLOPs and only a very small increase in
> parameter count compared to SwinUNETR. UKAST achieves state-of-the-art
> performance on four diverse 2D and 3D medical image segmentation benchmarks,
> consistently surpassing both CNN- and Transformer-based baselines. Notably, it
> attains superior accuracy in data-scarce settings, alleviating the data-hungry
> limitations of standard Vision Transformers. These results show the potential
> of KAN-enhanced Transformers to advance data-efficient medical image
> segmentation. Code is available at: https://github.com/nsapkota417/UKAST

