---
layout: default
title: Simple 3D Pose Features Support Human and Machine Social Scene Understanding
---

# Simple 3D Pose Features Support Human and Machine Social Scene Understanding

**arXiv**: [2511.03988v1](https://arxiv.org/abs/2511.03988) | [PDF](https://arxiv.org/pdf/2511.03988.pdf)

**ä½œè€…**: Wenshuo Qin, Leyla Isik

**åˆ†ç±»**: cs.CV, q-bio.NC

**å‘å¸ƒæ—¥æœŸ**: 2025-11-06

**å¤‡æ³¨**: 28 pages, 6 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽ3Då§¿æ€ç‰¹å¾çš„äººæœºç¤¾äº¤åœºæ™¯ç†è§£æ–¹æ³•ï¼Œè¶…è¶ŠçŽ°æœ‰AIæ¨¡åž‹ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸Žååº” (Interaction & Reaction)**

**å…³é”®è¯**: `3Då§¿æ€ä¼°è®¡` `ç¤¾äº¤åœºæ™¯ç†è§£` `äººæœºäº¤äº’` `æ·±åº¦å­¦ä¹ ` `è§†è§‰ç‰¹å¾` `è¡Œä¸ºè¯†åˆ«` `äººå·¥æ™ºèƒ½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰AIè§†è§‰æ¨¡åž‹åœ¨ç¤¾äº¤äº’åŠ¨è¯†åˆ«æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆåˆ©ç”¨3Då§¿æ€ä¿¡æ¯ã€‚
2. è®ºæ–‡æå‡ºåˆ©ç”¨3Däººä½“å§¿æ€ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯é¢éƒ¨æœå‘ç­‰ç®€å•ç‰¹å¾ï¼Œæ¥æå‡ç¤¾äº¤åœºæ™¯ç†è§£èƒ½åŠ›ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒåŸºäºŽ3Då§¿æ€ç‰¹å¾çš„æ–¹æ³•è¶…è¶Šäº†çŽ°æœ‰AIæ¨¡åž‹ï¼Œå¹¶èƒ½æœ‰æ•ˆæå‡å…¶æ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»èƒ½å¤Ÿè¿…é€Ÿä¸”æ¯«ä¸è´¹åŠ›åœ°ä»Žè§†è§‰è¾“å…¥ä¸­æå–å…³äºŽä»–äººç¤¾äº¤äº’åŠ¨çš„å„ç§ä¿¡æ¯ï¼Œä»Žè¯¸å¦‚ä¸¤ä¸ªäººæ˜¯å¦é¢å¯¹é¢ä¹‹ç±»çš„è§†è§‰ç©ºé—´çº¿ç´¢åˆ°æ›´é«˜çº§åˆ«çš„ä¿¡æ¯ã€‚ç„¶è€Œï¼Œæ”¯æŒè¿™äº›èƒ½åŠ›çš„è®¡ç®—ä»ç„¶çŸ¥ä¹‹ç”šå°‘ï¼Œå¹¶ä¸”ç¤¾äº¤äº’åŠ¨è¯†åˆ«ä»ç„¶æŒ‘æˆ˜ç€å³ä½¿æ˜¯æœ€å…ˆè¿›çš„AIè§†è§‰ç³»ç»Ÿã€‚æœ¬æ–‡å‡è®¾äººç±»ä¾èµ–äºŽ3Dè§†è§‰ç©ºé—´å§¿æ€ä¿¡æ¯æ¥è¿›è¡Œç¤¾äº¤äº’åŠ¨åˆ¤æ–­ï¼Œè€Œè¿™åœ¨å¤§å¤šæ•°AIè§†è§‰æ¨¡åž‹ä¸­æ˜¯ç¼ºå¤±çš„ã€‚ä¸ºäº†éªŒè¯è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬ç»“åˆäº†æœ€å…ˆè¿›çš„å§¿æ€å’Œæ·±åº¦ä¼°è®¡ç®—æ³•æ¥æå–æç»˜æ—¥å¸¸äººç±»åŠ¨ä½œçš„çŸ­è§†é¢‘ç‰‡æ®µä¸­äººç‰©çš„3Då…³èŠ‚ä½ç½®ï¼Œå¹¶å°†å®ƒä»¬é¢„æµ‹äººç±»ç¤¾äº¤äº’åŠ¨åˆ¤æ–­çš„èƒ½åŠ›ä¸Žå½“å‰çš„AIè§†è§‰æ¨¡åž‹è¿›è¡Œäº†æ¯”è¾ƒã€‚æƒŠäººçš„æ˜¯ï¼Œ3Då…³èŠ‚ä½ç½®ä¼˜äºŽå¤§å¤šæ•°å½“å‰çš„AIè§†è§‰æ¨¡åž‹ï¼Œæ­ç¤ºäº†å…³é”®çš„ç¤¾äº¤ä¿¡æ¯å­˜åœ¨äºŽæ˜¾å¼çš„èº«ä½“ä½ç½®ä¸­ï¼Œè€Œä¸æ˜¯å¤§å¤šæ•°è§†è§‰æ¨¡åž‹çš„å­¦ä¹ ç‰¹å¾ä¸­ï¼Œç”šè‡³åŒ…æ‹¬ç”¨äºŽæå–å…³èŠ‚ä½ç½®çš„å§¿æ€æ¨¡åž‹çš„é€å±‚åµŒå…¥ã€‚ä¸ºäº†æ­ç¤ºäººç±»ç”¨äºŽè¿›è¡Œç¤¾äº¤åˆ¤æ–­çš„å…³é”®å§¿æ€ç‰¹å¾ï¼Œæˆ‘ä»¬æŽ¨å¯¼å‡ºä¸€ä¸ªç´§å‡‘çš„3Dç¤¾äº¤å§¿æ€ç‰¹å¾é›†ï¼Œä»…æè¿°è§†é¢‘ä¸­é¢éƒ¨çš„3Dä½ç½®å’Œæ–¹å‘ã€‚æˆ‘ä»¬å‘çŽ°è¿™äº›æœ€å°çš„æè¿°ç¬¦ä¸Žå®Œæ•´3Då…³èŠ‚é›†çš„é¢„æµ‹å¼ºåº¦ç›¸åŒ¹é…ï¼Œå¹¶ä¸”åœ¨ä¸Žå®ƒä»¬çš„åµŒå…¥ç›¸ç»“åˆæ—¶ï¼Œæ˜¾ç€æé«˜äº†çŽ°æˆçš„AIè§†è§‰æ¨¡åž‹çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæ¯ä¸ªçŽ°æˆçš„AIè§†è§‰æ¨¡åž‹ä¸­3Dç¤¾äº¤å§¿æ€ç‰¹å¾çš„è¡¨ç¤ºç¨‹åº¦é¢„æµ‹äº†è¯¥æ¨¡åž‹åŒ¹é…äººç±»ç¤¾äº¤åˆ¤æ–­çš„èƒ½åŠ›ã€‚æ€»ä¹‹ï¼Œæˆ‘ä»¬çš„å‘çŽ°æä¾›äº†å¼ºæœ‰åŠ›çš„è¯æ®ï¼Œè¡¨æ˜Žäººç±»çš„ç¤¾äº¤åœºæ™¯ç†è§£ä¾èµ–äºŽ3Då§¿æ€çš„æ˜¾å¼è¡¨ç¤ºï¼Œå¹¶ä¸”å¯ä»¥ç”±ç®€å•çš„ã€ç»“æž„åŒ–çš„è§†è§‰ç©ºé—´åŽŸè¯­æ¥æ”¯æŒã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰AIè§†è§‰æ¨¡åž‹åœ¨ç†è§£ç¤¾äº¤åœºæ™¯ï¼Œç‰¹åˆ«æ˜¯è¯†åˆ«äººç±»ä¹‹é—´çš„äº’åŠ¨å…³ç³»æ—¶ï¼Œè¡¨çŽ°ä¸ä½³ã€‚å®ƒä»¬é€šå¸¸ä¾èµ–äºŽå­¦ä¹ åˆ°çš„ç‰¹å¾ï¼Œè€Œå¿½ç•¥äº†æ˜¾å¼çš„3Då§¿æ€ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯äººä½“å…³èŠ‚çš„3Dä½ç½®å’Œé¢éƒ¨æœå‘ç­‰å…³é”®çº¿ç´¢ã€‚è¿™å¯¼è‡´æ¨¡åž‹éš¾ä»¥å‡†ç¡®åˆ¤æ–­äººç‰©ä¹‹é—´çš„ç¤¾äº¤å…³ç³»å’Œæ„å›¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼ºè°ƒ3Då§¿æ€ä¿¡æ¯åœ¨ç¤¾äº¤åœºæ™¯ç†è§£ä¸­çš„é‡è¦æ€§ã€‚ä½œè€…è®¤ä¸ºï¼Œäººç±»åœ¨è¿›è¡Œç¤¾äº¤åˆ¤æ–­æ—¶ï¼Œä¼šä¾èµ–äºŽæ˜¾å¼çš„3Då§¿æ€ä¿¡æ¯ï¼Œä¾‹å¦‚äººç‰©ä¹‹é—´çš„ç›¸å¯¹ä½ç½®ã€é¢éƒ¨æœå‘ç­‰ã€‚å› æ­¤ï¼Œé€šè¿‡æå–å’Œåˆ©ç”¨è¿™äº›3Då§¿æ€ç‰¹å¾ï¼Œå¯ä»¥æœ‰æ•ˆæå‡AIæ¨¡åž‹åœ¨ç¤¾äº¤åœºæ™¯ç†è§£æ–¹é¢çš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) ä½¿ç”¨å§¿æ€å’Œæ·±åº¦ä¼°è®¡ç®—æ³•ä»Žè§†é¢‘ä¸­æå–äººç‰©çš„3Då…³èŠ‚ä½ç½®ï¼›2) ä»Ž3Då…³èŠ‚ä½ç½®ä¸­æå–ç´§å‡‘çš„3Dç¤¾äº¤å§¿æ€ç‰¹å¾ï¼Œä¾‹å¦‚é¢éƒ¨ä½ç½®å’Œæ–¹å‘ï¼›3) å°†æå–çš„3Dç¤¾äº¤å§¿æ€ç‰¹å¾ä¸ŽçŽ°æœ‰AIè§†è§‰æ¨¡åž‹çš„åµŒå…¥ç›¸ç»“åˆï¼›4) ä½¿ç”¨ç»“åˆåŽçš„ç‰¹å¾è¿›è¡Œç¤¾äº¤äº’åŠ¨åˆ¤æ–­ï¼Œå¹¶ä¸Žäººç±»çš„åˆ¤æ–­è¿›è¡Œæ¯”è¾ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) è¯æ˜Žäº†æ˜¾å¼çš„3Då§¿æ€ä¿¡æ¯åœ¨ç¤¾äº¤åœºæ™¯ç†è§£ä¸­çš„é‡è¦æ€§ï¼Œè¶…è¶Šäº†çŽ°æœ‰AIæ¨¡åž‹å­¦ä¹ åˆ°çš„ç‰¹å¾ï¼›2) æå‡ºäº†ä¸€ä¸ªç´§å‡‘çš„3Dç¤¾äº¤å§¿æ€ç‰¹å¾é›†ï¼Œä»…åŒ…å«é¢éƒ¨ä½ç½®å’Œæ–¹å‘ç­‰ç®€å•ä¿¡æ¯ï¼Œä½†å´èƒ½æœ‰æ•ˆæå‡æ¨¡åž‹æ€§èƒ½ï¼›3) æ­ç¤ºäº†AIè§†è§‰æ¨¡åž‹ä¸­3Dç¤¾äº¤å§¿æ€ç‰¹å¾çš„è¡¨ç¤ºç¨‹åº¦ä¸Žæ¨¡åž‹åŒ¹é…äººç±»ç¤¾äº¤åˆ¤æ–­èƒ½åŠ›ä¹‹é—´çš„å…³ç³»ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨çŽ°æˆçš„å§¿æ€å’Œæ·±åº¦ä¼°è®¡ç®—æ³•ï¼Œé¿å…äº†ä»Žå¤´è®­ç»ƒæ¨¡åž‹çš„å¤æ‚æ€§ï¼›2) è®¾è®¡äº†ä¸€ä¸ªç´§å‡‘çš„3Dç¤¾äº¤å§¿æ€ç‰¹å¾é›†ï¼Œå‡å°‘äº†è®¡ç®—é‡ï¼Œå¹¶çªå‡ºäº†å…³é”®ä¿¡æ¯ï¼›3) å°†3Dç¤¾äº¤å§¿æ€ç‰¹å¾ä¸ŽçŽ°æœ‰AIè§†è§‰æ¨¡åž‹çš„åµŒå…¥ç›¸ç»“åˆï¼Œå……åˆ†åˆ©ç”¨äº†çŽ°æœ‰æ¨¡åž‹çš„å­¦ä¹ èƒ½åŠ›ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œä»…ä½¿ç”¨3Då…³èŠ‚ä½ç½®å°±èƒ½è¶…è¶Šå¤§å¤šæ•°çŽ°æœ‰AIè§†è§‰æ¨¡åž‹åœ¨ç¤¾äº¤äº’åŠ¨åˆ¤æ–­æ–¹é¢çš„æ€§èƒ½ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œä»…åŒ…å«é¢éƒ¨ä½ç½®å’Œæ–¹å‘çš„ç´§å‡‘3Dç¤¾äº¤å§¿æ€ç‰¹å¾é›†ï¼Œä¸Žå®Œæ•´3Då…³èŠ‚é›†çš„é¢„æµ‹å¼ºåº¦ç›¸åŒ¹é…ï¼Œå¹¶ä¸”åœ¨ä¸ŽçŽ°æœ‰AIè§†è§‰æ¨¡åž‹çš„åµŒå…¥ç›¸ç»“åˆæ—¶ï¼Œæ˜¾è‘—æé«˜äº†å…¶æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæ¨¡åž‹ä¸­3Dç¤¾äº¤å§¿æ€ç‰¹å¾çš„è¡¨ç¤ºç¨‹åº¦ä¸Žæ¨¡åž‹åŒ¹é…äººç±»ç¤¾äº¤åˆ¤æ–­èƒ½åŠ›ä¹‹é—´å­˜åœ¨æ­£ç›¸å…³å…³ç³»ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽç¤¾äº¤æœºå™¨äººã€æ™ºèƒ½ç›‘æŽ§ã€äººæœºäº¤äº’ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œç¤¾äº¤æœºå™¨äººå¯ä»¥åˆ©ç”¨3Då§¿æ€ä¿¡æ¯æ›´å‡†ç¡®åœ°ç†è§£äººç±»çš„ç¤¾äº¤è¡Œä¸ºï¼Œä»Žè€Œåšå‡ºæ›´è‡ªç„¶çš„ååº”ã€‚æ™ºèƒ½ç›‘æŽ§ç³»ç»Ÿå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯è¯†åˆ«å¼‚å¸¸ç¤¾äº¤è¡Œä¸ºï¼Œä¾‹å¦‚æ½œåœ¨çš„å†²çªæˆ–æš´åŠ›äº‹ä»¶ã€‚äººæœºäº¤äº’ç³»ç»Ÿå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯æ›´å¥½åœ°ç†è§£ç”¨æˆ·çš„æ„å›¾ï¼Œæä¾›æ›´ä¸ªæ€§åŒ–çš„æœåŠ¡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Humans can quickly and effortlessly extract a variety of information about others' social interactions from visual input, ranging from visuospatial cues like whether two people are facing each other to higher-level information. Yet, the computations supporting these abilities remain poorly understood, and social interaction recognition continues to challenge even the most advanced AI vision systems. Here, we hypothesized that humans rely on 3D visuospatial pose information to make social interaction judgments, which is absent in most AI vision models. To test this, we combined state-of-the-art pose and depth estimation algorithms to extract 3D joint positions of people in short video clips depicting everyday human actions and compared their ability to predict human social interaction judgments with current AI vision models. Strikingly, 3D joint positions outperformed most current AI vision models, revealing that key social information is available in explicit body position but not in the learned features of most vision models, including even the layer-wise embeddings of the pose models used to extract joint positions. To uncover the critical pose features humans use to make social judgments, we derived a compact set of 3D social pose features describing only the 3D position and direction of faces in the videos. We found that these minimal descriptors matched the predictive strength of the full set of 3D joints and significantly improved the performance of off-the-shelf AI vision models when combined with their embeddings. Moreover, the degree to which 3D social pose features were represented in each off-the-shelf AI vision model predicted the model's ability to match human social judgments. Together, our findings provide strong evidence that human social scene understanding relies on explicit representations of 3D pose and can be supported by simple, structured visuospatial primitives.

