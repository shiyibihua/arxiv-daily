---
layout: default
title: Simple 3D Pose Features Support Human and Machine Social Scene Understanding
---

# Simple 3D Pose Features Support Human and Machine Social Scene Understanding

**arXiv**: [2511.03988v1](https://arxiv.org/abs/2511.03988) | [PDF](https://arxiv.org/pdf/2511.03988.pdf)

**ä½œè€…**: Wenshuo Qin, Leyla Isik

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡º3Dç¤¾äº¤å§¿æ€ç‰¹å¾ä»¥æå‡äººæœºç¤¾äº¤åœºæ™¯ç†è§£æ€§èƒ½**

**å…³é”®è¯**: `3Då§¿æ€ä¼°è®¡` `ç¤¾äº¤äº¤äº’è¯†åˆ«` `è§†è§‰ç‰¹å¾æå–` `äººç±»è¡Œä¸ºç†è§£` `AIè§†è§‰æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šäººç±»ç¤¾äº¤äº¤äº’è¯†åˆ«åœ¨AIè§†è§‰ç³»ç»Ÿä¸­ä»å…·æŒ‘æˆ˜ï¼Œå¯èƒ½å› ç¼ºä¹3Då§¿æ€ä¿¡æ¯ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆå§¿æ€ä¸Žæ·±åº¦ä¼°è®¡ç®—æ³•æå–3Då…³èŠ‚ä½ç½®ï¼Œå¹¶æŽ¨å¯¼ç´§å‡‘3Dç¤¾äº¤å§¿æ€ç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼š3Då§¿æ€ç‰¹å¾ä¼˜äºŽå¤šæ•°AIæ¨¡åž‹ï¼Œå¹¶æå‡çŽ°æˆæ¨¡åž‹æ€§èƒ½ï¼ŒåŒ¹é…äººç±»åˆ¤æ–­ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Humans can quickly and effortlessly extract a variety of information about
> others' social interactions from visual input, ranging from visuospatial cues
> like whether two people are facing each other to higher-level information. Yet,
> the computations supporting these abilities remain poorly understood, and
> social interaction recognition continues to challenge even the most advanced AI
> vision systems. Here, we hypothesized that humans rely on 3D visuospatial pose
> information to make social interaction judgments, which is absent in most AI
> vision models. To test this, we combined state-of-the-art pose and depth
> estimation algorithms to extract 3D joint positions of people in short video
> clips depicting everyday human actions and compared their ability to predict
> human social interaction judgments with current AI vision models. Strikingly,
> 3D joint positions outperformed most current AI vision models, revealing that
> key social information is available in explicit body position but not in the
> learned features of most vision models, including even the layer-wise
> embeddings of the pose models used to extract joint positions. To uncover the
> critical pose features humans use to make social judgments, we derived a
> compact set of 3D social pose features describing only the 3D position and
> direction of faces in the videos. We found that these minimal descriptors
> matched the predictive strength of the full set of 3D joints and significantly
> improved the performance of off-the-shelf AI vision models when combined with
> their embeddings. Moreover, the degree to which 3D social pose features were
> represented in each off-the-shelf AI vision model predicted the model's ability
> to match human social judgments. Together, our findings provide strong evidence
> that human social scene understanding relies on explicit representations of 3D
> pose and can be supported by simple, structured visuospatial primitives.

