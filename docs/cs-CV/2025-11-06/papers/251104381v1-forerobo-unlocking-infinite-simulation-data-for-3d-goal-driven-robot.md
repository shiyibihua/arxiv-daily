---
layout: default
title: ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation
---

# ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation

**arXiv**: [2511.04381v1](https://arxiv.org/abs/2511.04381) | [PDF](https://arxiv.org/pdf/2511.04381.pdf)

**ä½œè€…**: Dexin wang, Faliang Chang, Chunsheng Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºForeRoboç”Ÿæˆå¼æœºå™¨äººä»£ç†ï¼Œåˆ©ç”¨æ— é™ä»¿çœŸæ•°æ®è§£å†³3Dç›®æ ‡é©±åŠ¨æ“ä½œé—®é¢˜**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `ç”Ÿæˆå¼ä»¿çœŸ` `3Dç›®æ ‡é¢„æµ‹` `ä»¿çœŸåˆ°çœŸå®žè¿ç§»` `çŠ¶æ€ç”Ÿæˆæ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé«˜æ•ˆåˆ©ç”¨ä»¿çœŸèŽ·å–é«˜çº§æ“ä½œæŠ€èƒ½ï¼Œé¿å…ç«¯åˆ°ç«¯ç­–ç•¥å­¦ä¹ çš„ä½Žæ•ˆæ€§
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆç”ŸæˆèŒƒå¼ä¸Žç»å…¸æŽ§åˆ¶ï¼Œé€šè¿‡propose-generate-learn-actuateå¾ªçŽ¯ç”Ÿæˆç›®æ ‡çŠ¶æ€
3. å®žéªŒæ•ˆæžœï¼šåœ¨å¤šç§ä»»åŠ¡ä¸­å¹³å‡æå‡56.32%ï¼ŒçœŸå®žä¸–ç•Œé›¶æ ·æœ¬è¿ç§»æˆåŠŸçŽ‡79.28%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Efficiently leveraging simulation to acquire advanced manipulation skills is
> both challenging and highly significant. We introduce \textit{ForeRobo}, a
> generative robotic agent that utilizes generative simulations to autonomously
> acquire manipulation skills driven by envisioned goal states. Instead of
> directly learning low-level policies, we advocate integrating generative
> paradigms with classical control. Our approach equips a robotic agent with a
> self-guided \textit{propose-generate-learn-actuate} cycle. The agent first
> proposes the skills to be acquired and constructs the corresponding simulation
> environments; it then configures objects into appropriate arrangements to
> generate skill-consistent goal states (\textit{ForeGen}). Subsequently, the
> virtually infinite data produced by ForeGen are used to train the proposed
> state generation model (\textit{ForeFormer}), which establishes point-wise
> correspondences by predicting the 3D goal position of every point in the
> current state, based on the scene state and task instructions. Finally,
> classical control algorithms are employed to drive the robot in real-world
> environments to execute actions based on the envisioned goal states. Compared
> with end-to-end policy learning methods, ForeFormer offers superior
> interpretability and execution efficiency. We train and benchmark ForeFormer
> across a variety of rigid-body and articulated-object manipulation tasks, and
> observe an average improvement of 56.32\% over the state-of-the-art state
> generation models, demonstrating strong generality across different
> manipulation patterns. Moreover, in real-world evaluations involving more than
> 20 robotic tasks, ForeRobo achieves zero-shot sim-to-real transfer and exhibits
> remarkable generalization capabilities, attaining an average success rate of
> 79.28\%.

