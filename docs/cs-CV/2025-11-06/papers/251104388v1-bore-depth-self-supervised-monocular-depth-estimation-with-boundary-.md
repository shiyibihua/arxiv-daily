---
layout: default
title: BoRe-Depth: Self-supervised Monocular Depth Estimation with Boundary Refinement for Embedded Systems
---

# BoRe-Depth: Self-supervised Monocular Depth Estimation with Boundary Refinement for Embedded Systems

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.04388" target="_blank" class="toolbar-btn">arXiv: 2511.04388v1</a>
    <a href="https://arxiv.org/pdf/2511.04388.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.04388v1" 
            onclick="toggleFavorite(this, '2511.04388v1', 'BoRe-Depth: Self-supervised Monocular Depth Estimation with Boundary Refinement for Embedded Systems')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Chang Liu, Juan Li, Sheng Zhang, Chang Liu, Jie Li, Xu Zhang

**ÂàÜÁ±ª**: cs.CV, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-06

**Â§áÊ≥®**: 8 pages, 5 figures, published to IROS 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/liangxiansheng093/BoRe-Depth)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫BoRe-DepthÊ®°ÂûãÔºåÂú®ÂµåÂÖ•ÂºèÁ≥ªÁªü‰∏äÂÆûÁé∞È´òÁ≤æÂ∫¶„ÄÅÈ´òÊïàÁéáÁöÑÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÔºåÂπ∂ÊèêÂçáËæπÁïåË¥®Èáè„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°` `ÂµåÂÖ•ÂºèÁ≥ªÁªü` `ËæπÁïåÁªÜÂåñ` `ÁâπÂæÅËûçÂêà` `ËØ≠‰πâÂàÜÂâ≤`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÊñπÊ≥ïÂú®ÂµåÂÖ•ÂºèÁ≥ªÁªü‰∏äÈù¢‰∏¥Ê∑±Â∫¶‰º∞ËÆ°ÊÄßËÉΩÂ∑ÆÂíåÂØπË±°ËæπÁïåÊ®°Á≥äÁöÑÊåëÊàò„ÄÇ
2. BoRe-DepthÊ®°ÂûãÈÄöËøáÂ¢ûÂº∫ÁâπÂæÅËá™ÈÄÇÂ∫îËûçÂêàÊ®°ÂùóÔºàEFAFÔºâÂíåËØ≠‰πâÁü•ËØÜÈõÜÊàêÔºåÊèêÂçáËæπÁïåÁªÜËäÇË°®Á§∫ÂíåÂØπË±°ËØÜÂà´ËÉΩÂäõ„ÄÇ
3. BoRe-DepthÂú®NVIDIA Jetson Orin‰∏ä‰ª•50.7 FPSËøêË°åÔºåÂπ∂Âú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏ä‰ºò‰∫éÂÖ∂‰ªñËΩªÈáèÁ∫ßÊ®°Âûã„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫BoRe-DepthÁöÑÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°Ê®°ÂûãÔºåËØ•Ê®°Âûã‰ªÖÂåÖÂê´870‰∏á‰∏™ÂèÇÊï∞ÔºåÊó®Âú®ÂµåÂÖ•ÂºèÁ≥ªÁªü‰∏äÂÆûÁé∞Á≤æÁ°ÆÁöÑÊ∑±Â∫¶Âõæ‰º∞ËÆ°ÔºåÂπ∂ÊòæËëóÊèêÈ´òËæπÁïåË¥®Èáè„ÄÇÈ¶ñÂÖàÔºåËÆæËÆ°‰∫Ü‰∏Ä‰∏™Â¢ûÂº∫ÁâπÂæÅËá™ÈÄÇÂ∫îËûçÂêàÊ®°ÂùóÔºàEFAFÔºâÔºåËá™ÈÄÇÂ∫îÂú∞ËûçÂêàÊ∑±Â∫¶ÁâπÂæÅÔºå‰ª•Â¢ûÂº∫ËæπÁïåÁªÜËäÇÁöÑË°®Á§∫„ÄÇÂÖ∂Ê¨°ÔºåÂ∞ÜËØ≠‰πâÁü•ËØÜÈõÜÊàêÂà∞ÁºñÁ†ÅÂô®‰∏≠Ôºå‰ª•ÊèêÈ´òÂØπË±°ËØÜÂà´ÂíåËæπÁïåÊÑüÁü•ËÉΩÂäõ„ÄÇÊúÄÂêéÔºåBoRe-DepthÈÉ®ÁΩ≤Âú®NVIDIA Jetson Orin‰∏äÔºåÂπ∂‰ª•50.7 FPSÁöÑÊïàÁéáËøêË°å„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®Â§ö‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊï∞ÊçÆÈõÜ‰∏äÊòéÊòæ‰ºò‰∫éÂÖàÂâçÁöÑËΩªÈáèÁ∫ßÊ®°ÂûãÔºåÂπ∂‰∏îÊèê‰æõ‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑËØ¶ÁªÜÊ∂àËûçÁ†îÁ©∂„ÄÇ‰ª£Á†ÅÂ∑≤Âú®https://github.com/liangxiansheng093/BoRe-Depth‰∏äÂèëÂ∏É„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°Âú®ÂµåÂÖ•ÂºèÁ≥ªÁªü‰∏äÁöÑÂ∫îÁî®ÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ËÆ°ÁÆóËµÑÊ∫êÂèóÈôêÁöÑÊÉÖÂÜµ‰∏ãÔºåÈöæ‰ª•‰øùËØÅÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÁ≤æÂ∫¶ÂíåËæπÁïåË¥®ÈáèÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂØπË±°ËæπÁïåÂ§ÑÂÆπÊòìÂá∫Áé∞Ê®°Á≥ä‰∏çÊ∏ÖÁöÑÊÉÖÂÜµ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáËÆæËÆ°ËΩªÈáèÁ∫ßÁöÑÁΩëÁªúÁªìÊûÑÔºåÂπ∂ÁªìÂêàÁâπÂæÅËá™ÈÄÇÂ∫îËûçÂêàÂíåËØ≠‰πâ‰ø°ÊÅØÂºïÂØºÔºåÂú®‰øùËØÅËÆ°ÁÆóÊïàÁéáÁöÑÂêåÊó∂ÔºåÊèêÂçáÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÁ≤æÂ∫¶ÂíåËæπÁïåË¥®Èáè„ÄÇÈÄöËøáEFAFÊ®°ÂùóÂ¢ûÂº∫ËæπÁïåÁªÜËäÇÁöÑË°®Á§∫ÔºåÂπ∂Âà©Áî®ËØ≠‰πâ‰ø°ÊÅØÊèêÈ´òÂØπË±°ËØÜÂà´ÂíåËæπÁïåÊÑüÁü•ËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöBoRe-DepthÊ®°Âûã‰∏ªË¶ÅÂåÖÂê´ÁºñÁ†ÅÂô®„ÄÅËß£Á†ÅÂô®ÂíåÂ¢ûÂº∫ÁâπÂæÅËá™ÈÄÇÂ∫îËûçÂêàÊ®°ÂùóÔºàEFAFÔºâ„ÄÇÁºñÁ†ÅÂô®Ë¥üË¥£ÊèêÂèñÂõæÂÉèÁâπÂæÅÔºåÂπ∂ÈõÜÊàêËØ≠‰πâÁü•ËØÜ„ÄÇEFAFÊ®°ÂùóËá™ÈÄÇÂ∫îÂú∞ËûçÂêà‰∏çÂêåÂ∞∫Â∫¶ÁöÑÊ∑±Â∫¶ÁâπÂæÅÔºåÂ¢ûÂº∫ËæπÁïåÁªÜËäÇÁöÑË°®Á§∫„ÄÇËß£Á†ÅÂô®ÂàôÊ†πÊçÆËûçÂêàÂêéÁöÑÁâπÂæÅÁîüÊàêÊúÄÁªàÁöÑÊ∑±Â∫¶Âõæ„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØ‰ªéËæìÂÖ•ÂõæÂÉèÂºÄÂßãÔºåÁªèËøáÁºñÁ†ÅÂô®ÊèêÂèñÁâπÂæÅÔºåÁÑ∂ÂêéÈÄöËøáEFAFÊ®°ÂùóËøõË°åÁâπÂæÅËûçÂêàÔºåÊúÄÂêéÁî±Ëß£Á†ÅÂô®ÁîüÊàêÊ∑±Â∫¶Âõæ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ¢ûÂº∫ÁâπÂæÅËá™ÈÄÇÂ∫îËûçÂêàÊ®°ÂùóÔºàEFAFÔºâÁöÑËÆæËÆ°ÔºåËØ•Ê®°ÂùóËÉΩÂ§üËá™ÈÄÇÂ∫îÂú∞ËûçÂêà‰∏çÂêåÂ∞∫Â∫¶ÁöÑÊ∑±Â∫¶ÁâπÂæÅÔºå‰ªéËÄåÊúâÊïàÂú∞Â¢ûÂº∫ËæπÁïåÁªÜËäÇÁöÑË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÂ∞ÜËØ≠‰πâÁü•ËØÜÈõÜÊàêÂà∞ÁºñÁ†ÅÂô®‰∏≠Ôºå‰πüÊúâÂä©‰∫éÊèêÈ´òÂØπË±°ËØÜÂà´ÂíåËæπÁïåÊÑüÁü•ËÉΩÂäõÔºåËøôÊòØ‰∏éÁé∞ÊúâËΩªÈáèÁ∫ßÊ®°ÂûãÁöÑÊú¨Ë¥®Âå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöEFAFÊ®°ÂùóÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÁªÜËäÇÊú™Áü•Ôºå‰ΩÜÂèØ‰ª•Êé®ÊµãÂÖ∂ÂèØËÉΩÈááÁî®‰∫ÜÊ≥®ÊÑèÂäõÊú∫Âà∂ÊàñËÄÖÂÖ∂‰ªñËá™ÈÄÇÂ∫îÊùÉÈáçÂàÜÈÖçÊñπÊ≥ïÔºå‰ª•ÂÆûÁé∞‰∏çÂêåÂ∞∫Â∫¶ÁâπÂæÅÁöÑÊúâÊïàËûçÂêà„ÄÇÊçüÂ§±ÂáΩÊï∞ÊñπÈù¢ÔºåËÆ∫ÊñáÂèØËÉΩÈááÁî®‰∫ÜÊ∑±Â∫¶ÂõûÂΩíÂ∏∏Áî®ÁöÑL1ÊçüÂ§±ÊàñL2ÊçüÂ§±ÔºåÂπ∂ÂèØËÉΩÁªìÂêà‰∫ÜËæπÁïåÊçüÂ§±Ôºå‰ª•Ëøõ‰∏ÄÊ≠•ÊèêÂçáËæπÁïåË¥®Èáè„ÄÇÁΩëÁªúÁªìÊûÑÊñπÈù¢Ôºå‰∏∫‰∫Ü‰øùËØÅËΩªÈáèÂåñÔºåÂèØËÉΩÈááÁî®‰∫ÜMobileNetÊàñËÄÖShuffleNetÁ≠âËΩªÈáèÁ∫ßÈ™®Âπ≤ÁΩëÁªú„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

BoRe-DepthÊ®°ÂûãÂú®NVIDIA Jetson Orin‰∏äÂÆûÁé∞‰∫Ü50.7 FPSÁöÑËøêË°åÈÄüÂ∫¶ÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÂµåÂÖ•ÂºèÁ≥ªÁªü‰∏äÁöÑÈ´òÊïàÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Ê®°ÂûãÂú®Â§ö‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊï∞ÊçÆÈõÜ‰∏äÊòéÊòæ‰ºò‰∫éÂÖàÂâçÁöÑËΩªÈáèÁ∫ßÊ®°ÂûãÔºåÂ∞§ÂÖ∂ÊòØÂú®ËæπÁïåË¥®ÈáèÊñπÈù¢ÊúâÊòæËëóÊèêÂçá„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÊèêÂçáÂπÖÂ∫¶ÈúÄË¶ÅÂú®ËÆ∫Êñá‰∏≠Ëøõ‰∏ÄÊ≠•Êü•Êâæ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊó†‰∫∫Êú∫„ÄÅÊú∫Âô®‰∫∫„ÄÅËá™Âä®È©æÈ©∂Á≠âÂµåÂÖ•ÂºèÁ≥ªÁªü‰∏≠Ôºå‰∏∫Ëøô‰∫õÁ≥ªÁªüÊèê‰æõ‰ΩéÊàêÊú¨„ÄÅÈ´òÁ≤æÂ∫¶ÁöÑ‰∏âÁª¥ÊÑüÁü•ËÉΩÂäõ„ÄÇÈÄöËøáÊèêÂçáÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÁ≤æÂ∫¶ÂíåËæπÁïåË¥®ÈáèÔºåÂèØ‰ª•ÊèêÈ´òËøô‰∫õÁ≥ªÁªüÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÂØºËà™„ÄÅÈÅøÈöúÂíåÁõÆÊ†áËØÜÂà´ËÉΩÂäõÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄºÂíåÂπøÈòîÁöÑÂ∏ÇÂú∫ÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Depth estimation is one of the key technologies for realizing 3D perception in unmanned systems. Monocular depth estimation has been widely researched because of its low-cost advantage, but the existing methods face the challenges of poor depth estimation performance and blurred object boundaries on embedded systems. In this paper, we propose a novel monocular depth estimation model, BoRe-Depth, which contains only 8.7M parameters. It can accurately estimate depth maps on embedded systems and significantly improves boundary quality. Firstly, we design an Enhanced Feature Adaptive Fusion Module (EFAF) which adaptively fuses depth features to enhance boundary detail representation. Secondly, we integrate semantic knowledge into the encoder to improve the object recognition and boundary perception capabilities. Finally, BoRe-Depth is deployed on NVIDIA Jetson Orin, and runs efficiently at 50.7 FPS. We demonstrate that the proposed model significantly outperforms previous lightweight models on multiple challenging datasets, and we provide detailed ablation studies for the proposed methods. The code is available at https://github.com/liangxiansheng093/BoRe-Depth.

