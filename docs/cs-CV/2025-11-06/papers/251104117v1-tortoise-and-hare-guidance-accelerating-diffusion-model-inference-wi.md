---
layout: default
title: Tortoise and Hare Guidance: Accelerating Diffusion Model Inference with Multirate Integration
---

# Tortoise and Hare Guidance: Accelerating Diffusion Model Inference with Multirate Integration

**arXiv**: [2511.04117v1](https://arxiv.org/abs/2511.04117) | [PDF](https://arxiv.org/pdf/2511.04117.pdf)

**ä½œè€…**: Yunghee Lee, Byeonghyun Pak, Junwha Hong, Hoseong Kim

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTortoise and Hare Guidanceä»¥åŠ é€Ÿæ‰©æ•£æ¨¡åž‹æŽ¨ç†å¹¶ä¿æŒé«˜ä¿çœŸç”Ÿæˆ**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹` `æŽ¨ç†åŠ é€Ÿ` `å¤šé€ŸçŽ‡ç§¯åˆ†` `åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼` `å‡½æ•°è¯„ä¼°ä¼˜åŒ–` `å›¾åƒç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‰©æ•£æ¨¡åž‹æŽ¨ç†é€Ÿåº¦æ…¢ï¼Œä¼ ç»Ÿæ±‚è§£å™¨æœªå……åˆ†åˆ©ç”¨é¢å¤–å¼•å¯¼é¡¹çš„å†—ä½™æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†CFG ODEé‡æž„ä¸ºå¤šé€ŸçŽ‡ç³»ç»Ÿï¼Œåˆ†åˆ«ç”¨ç»†/ç²—ç½‘æ ¼ç§¯åˆ†å™ªå£°ä¼°è®¡å’Œé¢å¤–å¼•å¯¼ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå‡å°‘å‡½æ•°è¯„ä¼°æ¬¡æ•°è¾¾30%ï¼Œç”Ÿæˆä¿çœŸåº¦å‡ ä¹Žæ— æŸå¤±ï¼Œä¼˜äºŽçŽ°æœ‰è®­ç»ƒå…è´¹åŠ é€Ÿå™¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this paper, we propose Tortoise and Hare Guidance (THG), a training-free
> strategy that accelerates diffusion sampling while maintaining high-fidelity
> generation. We demonstrate that the noise estimate and the additional guidance
> term exhibit markedly different sensitivity to numerical error by reformulating
> the classifier-free guidance (CFG) ODE as a multirate system of ODEs. Our
> error-bound analysis shows that the additional guidance branch is more robust
> to approximation, revealing substantial redundancy that conventional solvers
> fail to exploit. Building on this insight, THG significantly reduces the
> computation of the additional guidance: the noise estimate is integrated with
> the tortoise equation on the original, fine-grained timestep grid, while the
> additional guidance is integrated with the hare equation only on a coarse grid.
> We also introduce (i) an error-bound-aware timestep sampler that adaptively
> selects step sizes and (ii) a guidance-scale scheduler that stabilizes large
> extrapolation spans. THG reduces the number of function evaluations (NFE) by up
> to 30% with virtually no loss in generation fidelity ($\Delta$ImageReward
> $\leq$ 0.032) and outperforms state-of-the-art CFG-based training-free
> accelerators under identical computation budgets. Our findings highlight the
> potential of multirate formulations for diffusion solvers, paving the way for
> real-time high-quality image synthesis without any model retraining. The source
> code is available at https://github.com/yhlee-add/THG.

