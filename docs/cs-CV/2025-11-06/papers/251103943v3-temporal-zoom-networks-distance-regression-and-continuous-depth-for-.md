---
layout: default
title: Temporal Zoom Networks: Distance Regression and Continuous Depth for Efficient Action Localization
---

# Temporal Zoom Networks: Distance Regression and Continuous Depth for Efficient Action Localization

**arXiv**: [2511.03943v3](https://arxiv.org/abs/2511.03943) | [PDF](https://arxiv.org/pdf/2511.03943.pdf)

**ä½œè€…**: Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-06 (æ›´æ–°: 2025-11-13)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¾¹ç•Œè·ç¦»å›žå½’ä¸Žè‡ªé€‚åº”æ—¶é—´ç»†åŒ–ä»¥æå‡åŠ¨ä½œå®šä½æ•ˆçŽ‡**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æ—¶é—´åŠ¨ä½œå®šä½` `è¾¹ç•Œæ£€æµ‹` `æ·±åº¦å­¦ä¹ ` `è‡ªé€‚åº”è®¡ç®—` `è§†é¢‘ç†è§£` `å˜æ¢å™¨` `ä¿¡æ¯è®º` `æ•ˆçŽ‡æå‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰çš„æ—¶é—´åŠ¨ä½œå®šä½æ–¹æ³•åœ¨å¤„ç†æ¨¡ç³Šè¾¹ç•Œæ—¶æ•ˆçŽ‡ä½Žä¸‹ï¼Œå¯¼è‡´è®¡ç®—èµ„æºæµªè´¹ã€‚
2. æœ¬æ–‡æå‡ºè¾¹ç•Œè·ç¦»å›žå½’ï¼ˆBDRï¼‰å’Œè‡ªé€‚åº”æ—¶é—´ç»†åŒ–ï¼ˆATRï¼‰ä¸¤ç§åˆ›æ–°æ–¹æ³•ï¼Œæå‡äº†è¾¹ç•Œæ£€æµ‹çš„ç²¾åº¦å’Œè®¡ç®—æ•ˆçŽ‡ã€‚
3. åœ¨THUMOS14æ•°æ®é›†ä¸Šï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å‡å°‘FLOPsçš„åŒæ—¶ï¼Œæå‡äº†mAP@0.7çš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨çŸ­åŠ¨ä½œæ£€æµ‹ä¸Šè¡¨çŽ°çªå‡ºã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ—¶é—´åŠ¨ä½œå®šä½éœ€è¦ç²¾ç¡®çš„è¾¹ç•Œæ£€æµ‹å’Œè®¡ç®—æ•ˆçŽ‡ã€‚çŽ°æœ‰æ–¹æ³•åœ¨æ‰€æœ‰æ—¶é—´ä½ç½®ä¸Šå‡åŒ€è®¡ç®—ï¼Œå¯¼è‡´åœ¨ç®€å•è¾¹ç•Œä¸Šæµªè´¹èµ„æºï¼Œè€Œåœ¨æ¨¡ç³Šè¾¹ç•Œä¸Šå´éš¾ä»¥å¤„ç†ã€‚æœ¬æ–‡æå‡ºäº†ä¸¤é¡¹äº’è¡¥åˆ›æ–°ï¼šè¾¹ç•Œè·ç¦»å›žå½’ï¼ˆBDRï¼‰ï¼Œç”¨æœ‰ç¬¦å·è·ç¦»å›žå½’æ›¿ä»£åŸºäºŽåˆ†ç±»çš„è¾¹ç•Œæ£€æµ‹ï¼Œé™ä½Žäº†3.3è‡³16.7å€çš„æ–¹å·®ï¼›è‡ªé€‚åº”æ—¶é—´ç»†åŒ–ï¼ˆATRï¼‰ï¼Œåœ¨å›°éš¾è¾¹ç•Œé™„è¿‘è¿žç»­åˆ†é…å˜æ¢å™¨æ·±åº¦ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæœ¬æ–‡æ–¹æ³•åœ¨THUMOS14æ•°æ®é›†ä¸Šå®žçŽ°äº†56.5%çš„mAP@0.7ï¼Œä½¿ç”¨151G FLOPsï¼Œæ¯”ActionFormer++å‡å°‘36%çš„FLOPsï¼ŒåŒæ—¶åœ¨çŸ­åŠ¨ä½œä¸ŠèŽ·å¾—æ˜¾è‘—æå‡ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ—¶é—´åŠ¨ä½œå®šä½ä¸­çš„è¾¹ç•Œæ£€æµ‹ç²¾åº¦å’Œè®¡ç®—æ•ˆçŽ‡é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•åœ¨æ‰€æœ‰æ—¶é—´ä½ç½®å‡åŒ€åˆ†é…è®¡ç®—èµ„æºï¼Œå¯¼è‡´åœ¨ç®€å•è¾¹ç•Œä¸Šæµªè´¹ï¼Œè€Œåœ¨æ¨¡ç³Šè¾¹ç•Œä¸Šå´éš¾ä»¥å–å¾—è‰¯å¥½æ•ˆæžœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºè¾¹ç•Œè·ç¦»å›žå½’ï¼ˆBDRï¼‰å’Œè‡ªé€‚åº”æ—¶é—´ç»†åŒ–ï¼ˆATRï¼‰ä¸¤ç§æ–¹æ³•ã€‚BDRé€šè¿‡æœ‰ç¬¦å·è·ç¦»å›žå½’æ›¿ä»£åˆ†ç±»æ–¹æ³•ï¼Œå‡å°‘äº†è¾¹ç•Œæ£€æµ‹çš„æ–¹å·®ï¼›ATRåˆ™æ ¹æ®å›°éš¾è¾¹ç•Œçš„éœ€è¦ï¼ŒåŠ¨æ€è°ƒæ•´å˜æ¢å™¨çš„æ·±åº¦åˆ†é…ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè¾¹ç•Œè·ç¦»å›žå½’æ¨¡å—å’Œè‡ªé€‚åº”æ—¶é—´ç»†åŒ–æ¨¡å—ã€‚BDRæ¨¡å—è´Ÿè´£è¾¹ç•Œçš„ç²¾ç¡®å®šä½ï¼Œè€ŒATRæ¨¡å—åˆ™æ ¹æ®è¾¹ç•Œçš„å¤æ‚æ€§åŠ¨æ€è°ƒæ•´è®¡ç®—èµ„æºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ç§ç†è®ºåŸºç¡€çš„è·ç¦»å…¬å¼ï¼Œå¹¶é€šè¿‡ä¿¡æ¯è®ºåˆ†æžå±•ç¤ºäº†æœ€ä½³æ–¹å·®ç¼©æ”¾ã€‚æ­¤å¤–ï¼ŒATRæœºåˆ¶é¿å…äº†ç¦»æ•£è·¯ç”±çš„å¤æ‚æ€§ï¼Œå®žçŽ°äº†è®¡ç®—èµ„æºçš„æœ‰æ•ˆåˆ†é…ã€‚

**å…³é”®è®¾è®¡**ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒBDRé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–è·ç¦»å›žå½’çš„ç²¾åº¦ï¼›ATRåˆ™é€šè¿‡åŠ¨æ€è°ƒæ•´å‚æ•°ï¼Œç¡®ä¿åœ¨å›°éš¾è¾¹ç•Œé™„è¿‘åˆ†é…æ›´å¤šçš„è®¡ç®—èµ„æºã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼Œæœ¬æ–‡æ–¹æ³•åœ¨THUMOS14æ•°æ®é›†ä¸Šå®žçŽ°äº†56.5%çš„mAP@0.7ï¼Œä½¿ç”¨151G FLOPsï¼Œè¾ƒActionFormer++å‡å°‘36%çš„FLOPsã€‚åŒæ—¶ï¼Œç›¸è¾ƒäºŽå‡åŒ€åŸºçº¿ï¼Œæœ¬æ–‡æ–¹æ³•æå‡äº†2.9%çš„mAP@0.7ï¼Œä¸”åœ¨çŸ­åŠ¨ä½œæ£€æµ‹ä¸Šè¡¨çŽ°å°¤ä¸ºçªå‡ºï¼Œæå‡å¹…åº¦è¾¾åˆ°4.2%ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è§†é¢‘ç†è§£ã€ç›‘æŽ§ç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡åŠ¨ä½œå®šä½çš„æ•ˆçŽ‡å’Œç²¾åº¦ï¼Œå¯ä»¥æ›´å¥½åœ°æ”¯æŒå®žæ—¶ç›‘æŽ§ã€è¡Œä¸ºè¯†åˆ«å’Œæ™ºèƒ½åˆ†æžç­‰ä»»åŠ¡ï¼Œè¿›è€ŒæŽ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸Žåº”ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Temporal action localization requires both precise boundary detection and computational efficiency. Current methods apply uniform computation across all temporal positions, wasting resources on easy boundaries while struggling with ambiguous ones. We address this through two complementary innovations: Boundary Distance Regression (BDR), which replaces classification-based boundary detection with signed-distance regression achieving 3.3--16.7$\times$ lower variance; and Adaptive Temporal Refinement (ATR), which allocates transformer depth continuously ($Ï„\in[0,1]$) to concentrate computation near difficult boundaries. On THUMOS14, our method achieves 56.5\% mAP@0.7 and 58.2\% average mAP@[0.3:0.7] with 151G FLOPs, using 36\% fewer FLOPs than ActionFormer++ (55.7\% mAP@0.7 at 235G). Compared to uniform baselines, we achieve +2.9\% mAP@0.7 (+1.8\% avg mAP, 5.4\% relative) with 24\% fewer FLOPs and 29\% lower latency, with particularly strong gains on short actions (+4.2\%, 8.6\% relative). Training requires 1.29$\times$ baseline FLOPs, but this one-time cost is amortized over many inference runs; knowledge distillation further reduces this to 1.1$\times$ while retaining 99.5\% accuracy. Our contributions include: (i) a theoretically-grounded distance formulation with information-theoretic analysis showing optimal variance scaling; (ii) a continuous depth allocation mechanism avoiding discrete routing complexity; and (iii) consistent improvements across four datasets with gains correlating with boundary heterogeneity.

