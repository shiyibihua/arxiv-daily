---
layout: default
title: A Task-Efficient Reinforcement Learning Task-Motion Planner for Safe Human-Robot Cooperation
---

# A Task-Efficient Reinforcement Learning Task-Motion Planner for Safe Human-Robot Cooperation

**arXiv**: [2510.12477v1](https://arxiv.org/abs/2510.12477) | [PDF](https://arxiv.org/pdf/2510.12477.pdf)

**ä½œè€…**: Gaoyuan Liu, Joris de Winter, Kelly Merckaert, Denis Steckelmacher, Ann Nowe, Bram Vanderborght

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ··åˆå¼ºåŒ–å­¦ä¹ ä»»åŠ¡è¿åŠ¨è§„åˆ’æ¡†æž¶ï¼Œä»¥æå‡äººæœºåä½œçš„å®‰å…¨æ€§ä¸Žæ•ˆçŽ‡**

**å…³é”®è¯**: `äººæœºåä½œ` `å¼ºåŒ–å­¦ä¹ è§„åˆ’` `è¿åŠ¨è§„åˆ’` `å®‰å…¨æœºå™¨äºº` `ä»»åŠ¡æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šäººæœºåä½œä¸­å®‰å…¨æœºåˆ¶å¸¸é™ä½Žä»»åŠ¡æ•ˆçŽ‡ï¼Œé¢‘ç¹è¿åŠ¨é‡è§„åˆ’å¢žåŠ è®¡ç®—è´Ÿæ‹…ä¸Žå¤±è´¥é£Žé™©
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆå¼ºåŒ–å­¦ä¹ ä»»åŠ¡è§„åˆ’å™¨ä¸Žäº¤äº’å¼è¿åŠ¨è§„åˆ’å™¨ï¼Œå­¦ä¹ å®‰å…¨ä»»åŠ¡åºåˆ—å¹¶å®žæ—¶é¿éšœ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä»¿çœŸä¸ŽçœŸå®žæœºå™¨äººéªŒè¯ï¼Œå‡å°‘é‡è§„åˆ’æ¬¡æ•°ä¸Žå¤±è´¥å‘½ä»¤é‡å¤ï¼Œæå‡ååº”èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In a Human-Robot Cooperation (HRC) environment, safety and efficiency are the
> two core properties to evaluate robot performance. However, safety mechanisms
> usually hinder task efficiency since human intervention will cause backup
> motions and goal failures of the robot. Frequent motion replanning will
> increase the computational load and the chance of failure. In this paper, we
> present a hybrid Reinforcement Learning (RL) planning framework which is
> comprised of an interactive motion planner and a RL task planner. The RL task
> planner attempts to choose statistically safe and efficient task sequences
> based on the feedback from the motion planner, while the motion planner keeps
> the task execution process collision-free by detecting human arm motions and
> deploying new paths when the previous path is not valid anymore. Intuitively,
> the RL agent will learn to avoid dangerous tasks, while the motion planner
> ensures that the chosen tasks are safe. The proposed framework is validated on
> the cobot in both simulation and the real world, we compare the planner with
> hard-coded task motion planning methods. The results show that our planning
> framework can 1) react to uncertain human motions at both joint and task
> levels; 2) reduce the times of repeating failed goal commands; 3) reduce the
> total number of replanning requests.

