---
layout: default
title: BIGFix: Bidirectional Image Generation with Token Fixing
---

# BIGFix: Bidirectional Image Generation with Token Fixing

**arXiv**: [2510.12231v1](https://arxiv.org/abs/2510.12231) | [PDF](https://arxiv.org/pdf/2510.12231.pdf)

**ä½œè€…**: Victor Besnier, David Hurych, Andrei Bursuc, Eduardo Valle

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBIGFixæ–¹æ³•ï¼Œé€šè¿‡è¿­ä»£ä¿®å¤ä»¤ç‰Œè§£å†³å¹¶è¡Œä»¤ç‰Œé¢„æµ‹ä¸­çš„ç»“æž„ä¸ä¸€è‡´é—®é¢˜ã€‚**

**å…³é”®è¯**: `å›¾åƒç”Ÿæˆ` `è§†é¢‘ç”Ÿæˆ` `å¹¶è¡Œä»¤ç‰Œé¢„æµ‹` `ä»¤ç‰Œä¿®å¤` `æŽ¨ç†æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¹¶è¡Œä»¤ç‰Œé¢„æµ‹å¯¼è‡´ç»“æž„ä¸ä¸€è‡´ï¼Œç¼ºä¹å›žæº¯æœºåˆ¶ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ–°é¢–è®­ç»ƒæ–¹æ¡ˆæ³¨å…¥éšæœºä»¤ç‰Œï¼Œå®žçŽ°è¿­ä»£ä»¤ç‰Œä¿®å¤ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å›¾åƒå’Œè§†é¢‘ç”Ÿæˆæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡ç”Ÿæˆè´¨é‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in image and video generation have raised significant
> interest from both academia and industry. A key challenge in this field is
> improving inference efficiency, as model size and the number of inference steps
> directly impact the commercial viability of generative models while also posing
> fundamental scientific challenges. A promising direction involves combining
> auto-regressive sequential token modeling with multi-token prediction per step,
> reducing inference time by up to an order of magnitude. However, predicting
> multiple tokens in parallel can introduce structural inconsistencies due to
> token incompatibilities, as capturing complex joint dependencies during
> training remains challenging. Traditionally, once tokens are sampled, there is
> no mechanism to backtrack and refine erroneous predictions. We propose a method
> for self-correcting image generation by iteratively refining sampled tokens. We
> achieve this with a novel training scheme that injects random tokens in the
> context, improving robustness and enabling token fixing during sampling. Our
> method preserves the efficiency benefits of parallel token prediction while
> significantly enhancing generation quality. We evaluate our approach on image
> generation using the ImageNet-256 and CIFAR-10 datasets, as well as on video
> generation with UCF-101 and NuScenes, demonstrating substantial improvements
> across both modalities.

