---
layout: default
title: MCOP: Multi-UAV Collaborative Occupancy Prediction
---

# MCOP: Multi-UAV Collaborative Occupancy Prediction

**arXiv**: [2510.12679v1](https://arxiv.org/abs/2510.12679) | [PDF](https://arxiv.org/pdf/2510.12679.pdf)

**ä½œè€…**: Zefu Lin, Wenbo Chen, Xiaojuan Jin, Yuran Yang, Lue Fan, Yixin Zhang, Yufeng Zhang, Zhaoxiang Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ— äººæœºåä½œå ç”¨é¢„æµ‹æ¡†æž¶ä»¥è§£å†³BEVæ–¹æ³•è¯­ä¹‰å‡ ä½•ä¿¡æ¯ç¼ºå¤±ä¸Žæ€§èƒ½ä¸‹é™é—®é¢˜**

**å…³é”®è¯**: `å¤šæ— äººæœºåä½œ` `å ç”¨é¢„æµ‹` `3Dæ„ŸçŸ¥` `ç‰¹å¾æ•´åˆ` `é€šä¿¡ä¼˜åŒ–` `æ— äººæœºç¾¤ç³»ç»Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. BEVæ–¹æ³•å› è¾¹ç•Œæ¡†è¡¨ç¤ºæ— æ³•æ•æ‰å®Œæ•´è¯­ä¹‰å‡ ä½•ä¿¡æ¯ï¼Œä¸”å¯¹æœªå®šä¹‰æˆ–é®æŒ¡å¯¹è±¡æ€§èƒ½æ˜¾è‘—ä¸‹é™
2. é›†æˆç©ºé—´æ„ŸçŸ¥ç‰¹å¾ç¼–ç ä¸Žè·¨ä»£ç†ç‰¹å¾æ•´åˆï¼Œä¿ç•™3Dç»“æž„ä¸Žè¯­ä¹‰ï¼›å¼•å…¥é«˜åº¦æ„ŸçŸ¥ç‰¹å¾åŽ‹ç¼©ä¸ŽåŒæŽ©ç æ„ŸçŸ¥æŒ‡å¯¼ä»¥æå‡æ•ˆçŽ‡
3. æ‰©å±•ä¸‰ä¸ªæ•°æ®é›†è¯„ä¼°ï¼Œå®žéªŒæ˜¾ç¤ºæ–¹æ³•åœ¨ç²¾åº¦ä¸Šè¾¾åˆ°æœ€ä¼˜ï¼ŒåŒæ—¶é€šä¿¡å¼€é”€å¤§å¹…é™ä½Ž

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Unmanned Aerial Vehicle (UAV) swarm systems necessitate efficient
> collaborative perception mechanisms for diverse operational scenarios. Current
> Bird's Eye View (BEV)-based approaches exhibit two main limitations:
> bounding-box representations fail to capture complete semantic and geometric
> information of the scene, and their performance significantly degrades when
> encountering undefined or occluded objects. To address these limitations, we
> propose a novel multi-UAV collaborative occupancy prediction framework. Our
> framework effectively preserves 3D spatial structures and semantics through
> integrating a Spatial-Aware Feature Encoder and Cross-Agent Feature
> Integration. To enhance efficiency, we further introduce Altitude-Aware Feature
> Reduction to compactly represent scene information, along with a Dual-Mask
> Perceptual Guidance mechanism to adaptively select features and reduce
> communication overhead. Due to the absence of suitable benchmark datasets, we
> extend three datasets for evaluation: two virtual datasets (Air-to-Pred-Occ and
> UAV3D-Occ) and one real-world dataset (GauUScene-Occ). Experiments results
> demonstrate that our method achieves state-of-the-art accuracy, significantly
> outperforming existing collaborative methods while reducing communication
> overhead to only a fraction of previous approaches.

