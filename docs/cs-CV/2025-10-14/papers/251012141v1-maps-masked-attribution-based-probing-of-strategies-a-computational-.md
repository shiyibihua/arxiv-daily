---
layout: default
title: MAPS: Masked Attribution-based Probing of Strategies- A computational framework to align human and model explanations
---

# MAPS: Masked Attribution-based Probing of Strategies- A computational framework to align human and model explanations

**arXiv**: [2510.12141v1](https://arxiv.org/abs/2510.12141) | [PDF](https://arxiv.org/pdf/2510.12141.pdf)

**ä½œè€…**: Sabine Muzellec, Yousif Kashef Alghetaa, Simon Kornblith, Kohitij Kar

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMAPSæ¡†æž¶ä»¥å¯¹é½äººç±»ä¸Žæ¨¡åž‹è§£é‡Šï¼Œè¯„ä¼°ç¥žç»ç½‘ç»œè§£é‡Šæ–¹æ³•ã€‚**

**å…³é”®è¯**: `è§†è§‰è§£é‡Šå¯¹é½` `å½’å› å›¾åˆ†æž` `è¡Œä¸ºéªŒè¯` `ç¥žç»ç½‘ç»œè§£é‡Š` `è®¡ç®—æ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šäººç±»è§†è§‰ç­–ç•¥éš¾ä»¥ç›´æŽ¥æµ‹é‡ï¼Œéœ€å¯¹é½äººå·¥ç¥žç»ç½‘ç»œè§£é‡Šã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†å½’å› å›¾è½¬æ¢ä¸ºè§£é‡ŠæŽ©ç å›¾åƒï¼Œæ¯”è¾ƒäººç±»åœ¨æœ‰é™åƒç´ å›¾åƒä¸Šçš„å‡†ç¡®çŽ‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šéªŒè¯MAPSåœ¨æ¨¡åž‹é—´æ¢å¤çœŸå®žç›¸ä¼¼æ€§ï¼Œå¹¶è¯†åˆ«ä¸Žç”Ÿç‰©è§†è§‰å¯¹é½çš„è§£é‡Šæ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Human core object recognition depends on the selective use of visual
> information, but the strategies guiding these choices are difficult to measure
> directly. We present MAPS (Masked Attribution-based Probing of Strategies), a
> behaviorally validated computational tool that tests whether explanations
> derived from artificial neural networks (ANNs) can also explain human vision.
> MAPS converts attribution maps into explanation-masked images (EMIs) and
> compares image-by-image human accuracies on these minimal images with limited
> pixel budgets with accuracies on the full stimuli. MAPS provides a principled
> way to evaluate and choose among competing ANN interpretability methods. In
> silico, EMI-based behavioral similarity between models reliably recovers the
> ground-truth similarity computed from their attribution maps, establishing
> which explanation methods best capture the model's strategy. When applied to
> humans and macaques, MAPS identifies ANN-explanation combinations whose
> explanations align most closely with biological vision, achieving the
> behavioral validity of Bubble masks while requiring far fewer behavioral
> trials. Because it needs only access to model attributions and a modest set of
> behavioral data on the original images, MAPS avoids exhaustive psychophysics
> while offering a scalable tool for adjudicating explanations and linking human
> behavior, neural activity, and model decisions under a common standard.

