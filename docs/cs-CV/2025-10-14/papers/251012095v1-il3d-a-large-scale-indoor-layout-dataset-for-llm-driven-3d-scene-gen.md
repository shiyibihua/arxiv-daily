---
layout: default
title: IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation
---

# IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation

**arXiv**: [2510.12095v1](https://arxiv.org/abs/2510.12095) | [PDF](https://arxiv.org/pdf/2510.12095.pdf)

**ä½œè€…**: Wenxu Zhou, Kaixuan Nie, Hang Du, Dong Yin, Wei Huang, Siqiang Guo, Xiaobo Zhang, Pengbo Hu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIL3Dæ•°æ®é›†ä»¥æ”¯æŒLLMé©±åŠ¨çš„3Då®¤å†…åœºæ™¯ç”Ÿæˆ**

**å…³é”®è¯**: `3Dåœºæ™¯ç”Ÿæˆ` `å®¤å†…å¸ƒå±€æ•°æ®é›†` `å¤§è¯­è¨€æ¨¡åž‹` `å¤šæ¨¡æ€å­¦ä¹ ` `ç›‘ç£å¾®è°ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç¼ºä¹å¤šæ ·é«˜è´¨é‡è®­ç»ƒæ•°æ®ç”¨äºŽå®¤å†…å¸ƒå±€è®¾è®¡å’Œ3Dåœºæ™¯ç”Ÿæˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºå¤§è§„æ¨¡æ•°æ®é›†ï¼ŒåŒ…å«å®¤å†…å¸ƒå±€ã€3Då¯¹è±¡å’Œè‡ªç„¶è¯­è¨€æ³¨é‡Šã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç›‘ç£å¾®è°ƒLLMåœ¨IL3Dä¸Šæå‡æ³›åŒ–èƒ½åŠ›ï¼Œä¼˜äºŽå…¶ä»–æ•°æ®é›†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this study, we present IL3D, a large-scale dataset meticulously designed
> for large language model (LLM)-driven 3D scene generation, addressing the
> pressing demand for diverse, high-quality training data in indoor layout
> design. Comprising 27,816 indoor layouts across 18 prevalent room types and a
> library of 29,215 high-fidelity 3D object assets, IL3D is enriched with
> instance-level natural language annotations to support robust multimodal
> learning for vision-language tasks. We establish rigorous benchmarks to
> evaluate LLM-driven scene generation. Experimental results show that supervised
> fine-tuning (SFT) of LLMs on IL3D significantly improves generalization and
> surpasses the performance of SFT on other datasets. IL3D offers flexible
> multimodal data export capabilities, including point clouds, 3D bounding boxes,
> multiview images, depth maps, normal maps, and semantic masks, enabling
> seamless adaptation to various visual tasks. As a versatile and robust
> resource, IL3D significantly advances research in 3D scene generation and
> embodied intelligence, by providing high-fidelity scene data to support
> environment perception tasks of embodied agents.

