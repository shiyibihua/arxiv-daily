---
layout: default
title: G4Splat: Geometry-Guided Gaussian Splatting with Generative Prior
---

# G4Splat: Geometry-Guided Gaussian Splatting with Generative Prior

**arXiv**: [2510.12099v1](https://arxiv.org/abs/2510.12099) | [PDF](https://arxiv.org/pdf/2510.12099.pdf)

**ä½œè€…**: Junfeng Ni, Yixin Chen, Zhifei Yang, Yu Liu, Ruijie Lu, Song-Chun Zhu, Siyuan Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå‡ ä½•å¼•å¯¼çš„é«˜æ–¯æ³¼æº…æ–¹æ³•ï¼Œåˆ©ç”¨ç”Ÿæˆå…ˆéªŒå¢žå¼º3Dåœºæ™¯é‡å»º**

**å…³é”®è¯**: `3Dåœºæ™¯é‡å»º` `é«˜æ–¯æ³¼æº…` `ç”Ÿæˆå…ˆéªŒ` `å‡ ä½•æŒ‡å¯¼` `å¤šè§†å›¾ä¸€è‡´æ€§` `æ·±åº¦ä¼°è®¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ç¼ºä¹å¯é å‡ ä½•ç›‘ç£ï¼Œå¯¼è‡´é‡å»ºè´¨é‡å·®å’Œå¤šè§†å›¾ä¸ä¸€è‡´
2. åˆ©ç”¨å¹³é¢ç»“æž„èŽ·å–ç²¾ç¡®æ·±åº¦å›¾ï¼Œå¹¶æ•´åˆå‡ ä½•æŒ‡å¯¼ä»¥æ”¹è¿›å¯è§æ€§æŽ©ç å’Œè§†å›¾é€‰æ‹©
3. åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®žéªŒï¼Œå‡ ä½•å’Œå¤–è§‚é‡å»ºä¼˜äºŽåŸºçº¿ï¼Œæ”¯æŒå•è§†å›¾å’Œæ— ä½å§¿è§†é¢‘è¾“å…¥

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite recent advances in leveraging generative prior from pre-trained
> diffusion models for 3D scene reconstruction, existing methods still face two
> critical limitations. First, due to the lack of reliable geometric supervision,
> they struggle to produce high-quality reconstructions even in observed regions,
> let alone in unobserved areas. Second, they lack effective mechanisms to
> mitigate multi-view inconsistencies in the generated images, leading to severe
> shape-appearance ambiguities and degraded scene geometry. In this paper, we
> identify accurate geometry as the fundamental prerequisite for effectively
> exploiting generative models to enhance 3D scene reconstruction. We first
> propose to leverage the prevalence of planar structures to derive accurate
> metric-scale depth maps, providing reliable supervision in both observed and
> unobserved regions. Furthermore, we incorporate this geometry guidance
> throughout the generative pipeline to improve visibility mask estimation, guide
> novel view selection, and enhance multi-view consistency when inpainting with
> video diffusion models, resulting in accurate and consistent scene completion.
> Extensive experiments on Replica, ScanNet++, and DeepBlending show that our
> method consistently outperforms existing baselines in both geometry and
> appearance reconstruction, particularly for unobserved regions. Moreover, our
> method naturally supports single-view inputs and unposed videos, with strong
> generalizability in both indoor and outdoor scenarios with practical real-world
> applicability. The project page is available at
> https://dali-jack.github.io/g4splat-web/.

