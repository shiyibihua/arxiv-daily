---
layout: default
title: DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving
---

# DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving

**arXiv**: [2510.12796v1](https://arxiv.org/abs/2510.12796) | [PDF](https://arxiv.org/pdf/2510.12796.pdf)

**ä½œè€…**: Yingyan Li, Shuyao Shang, Weisong Liu, Bing Zhan, Haochen Wang, Yuqi Wang, Yuntao Chen, Xiaoman Wang, Yasong An, Chufeng Tang, Lu Hou, Lue Fan, Zhaoxiang Zhang

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDriveVLA-W0è®­ç»ƒèŒƒå¼ï¼Œåˆ©ç”¨ä¸–ç•Œæ¨¡å‹é¢„æµ‹æœªæ¥å›¾åƒä»¥å¢å¼ºè‡ªåŠ¨é©¾é©¶VLAæ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹` `ä¸–ç•Œå»ºæ¨¡` `è‡ªç›‘ç£å­¦ä¹ ` `æ•°æ®ç¼©æ”¾å®šå¾‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šVLAæ¨¡å‹å­˜åœ¨ç›‘ç£ä¸è¶³ï¼Œæ¨¡å‹å®¹é‡å¤§ä½†ä»…ç”±ç¨€ç–åŠ¨ä½œç›‘ç£ï¼Œè¡¨ç¤ºèƒ½åŠ›æœªå……åˆ†åˆ©ç”¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä¸–ç•Œå»ºæ¨¡é¢„æµ‹æœªæ¥å›¾åƒï¼Œæä¾›å¯†é›†è‡ªç›‘ç£ä¿¡å·ï¼Œå­¦ä¹ é©¾é©¶ç¯å¢ƒåŠ¨æ€ã€‚
3. å®éªŒæ•ˆæœï¼šåœ¨NAVSIMåŸºå‡†å’Œå†…éƒ¨æ•°æ®é›†ä¸Šæ˜¾è‘—è¶…è¶ŠåŸºçº¿ï¼Œå¹¶æ”¾å¤§æ•°æ®ç¼©æ”¾å®šå¾‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Scaling Vision-Language-Action (VLA) models on large-scale data offers a
> promising path to achieving a more generalized driving intelligence. However,
> VLA models are limited by a ``supervision deficit'': the vast model capacity is
> supervised by sparse, low-dimensional actions, leaving much of their
> representational power underutilized. To remedy this, we propose
> \textbf{DriveVLA-W0}, a training paradigm that employs world modeling to
> predict future images. This task generates a dense, self-supervised signal that
> compels the model to learn the underlying dynamics of the driving environment.
> We showcase the paradigm's versatility by instantiating it for two dominant VLA
> archetypes: an autoregressive world model for VLAs that use discrete visual
> tokens, and a diffusion world model for those operating on continuous visual
> features. Building on the rich representations learned from world modeling, we
> introduce a lightweight action expert to address the inference latency for
> real-time deployment. Extensive experiments on the NAVSIM v1/v2 benchmark and a
> 680x larger in-house dataset demonstrate that DriveVLA-W0 significantly
> outperforms BEV and VLA baselines. Crucially, it amplifies the data scaling
> law, showing that performance gains accelerate as the training dataset size
> increases.

