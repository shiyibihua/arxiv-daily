---
layout: default
title: MMOT: The First Challenging Benchmark for Drone-based Multispectral Multi-Object Tracking
---

# MMOT: The First Challenging Benchmark for Drone-based Multispectral Multi-Object Tracking

**arXiv**: [2510.12565v1](https://arxiv.org/abs/2510.12565) | [PDF](https://arxiv.org/pdf/2510.12565.pdf)

**ä½œè€…**: Tianhao Li, Tingfa Xu, Ying Wang, Haolin Qin, Xu Lin, Jianan Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMMOTåŸºå‡†ä¸Žå¤šå…‰è°±æ–¹æ¡ˆï¼Œä»¥æå‡æ— äººæœºå¤šç›®æ ‡è·Ÿè¸ªåœ¨å¤æ‚åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚**

**å…³é”®è¯**: `å¤šå…‰è°±å¤šç›®æ ‡è·Ÿè¸ª` `æ— äººæœºåŸºå‡†` `æ–¹å‘æ„ŸçŸ¥è·Ÿè¸ª` `å…‰è°±ç‰¹å¾æå–` `å°ç›®æ ‡è·Ÿè¸ª`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ— äººæœºå¤šç›®æ ‡è·Ÿè¸ªå› ç›®æ ‡å°ã€é®æŒ¡ä¸¥é‡å’ŒèƒŒæ™¯æ‚ä¹±è€Œä¸å¯é ï¼ŒRGBæ–¹æ³•ä¾èµ–ç©ºé—´å¤–è§‚æ˜“é€€åŒ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥å¤§è§„æ¨¡å¤šå…‰è°±æ•°æ®é›†MMOTï¼Œå¹¶è®¾è®¡å…‰è°±3D-Stemå’Œæ–¹å‘æ„ŸçŸ¥è·Ÿè¸ªæ–¹æ¡ˆå¢žå¼ºç‰¹å¾æå–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå¤šå…‰è°±è¾“å…¥æ˜¾è‘—ä¼˜äºŽRGBåŸºçº¿ï¼Œå°¤å…¶åœ¨å°ç›®æ ‡å’Œå¯†é›†åœºæ™¯ä¸­æå‡è·Ÿè¸ªæ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Drone-based multi-object tracking is essential yet highly challenging due to
> small targets, severe occlusions, and cluttered backgrounds. Existing RGB-based
> tracking algorithms heavily depend on spatial appearance cues such as color and
> texture, which often degrade in aerial views, compromising reliability.
> Multispectral imagery, capturing pixel-level spectral reflectance, provides
> crucial cues that enhance object discriminability under degraded spatial
> conditions. However, the lack of dedicated multispectral UAV datasets has
> hindered progress in this domain. To bridge this gap, we introduce MMOT, the
> first challenging benchmark for drone-based multispectral multi-object
> tracking. It features three key characteristics: (i) Large Scale - 125 video
> sequences with over 488.8K annotations across eight categories; (ii)
> Comprehensive Challenges - covering diverse conditions such as extreme small
> targets, high-density scenarios, severe occlusions, and complex motion; and
> (iii) Precise Oriented Annotations - enabling accurate localization and reduced
> ambiguity under aerial perspectives. To better extract spectral features and
> leverage oriented annotations, we further present a multispectral and
> orientation-aware MOT scheme adapting existing methods, featuring: (i) a
> lightweight Spectral 3D-Stem integrating spectral features while preserving
> compatibility with RGB pretraining; (ii) an orientation-aware Kalman filter for
> precise state estimation; and (iii) an end-to-end orientation-adaptive
> transformer. Extensive experiments across representative trackers consistently
> show that multispectral input markedly improves tracking performance over RGB
> baselines, particularly for small and densely packed objects. We believe our
> work will advance drone-based multispectral multi-object tracking research. Our
> MMOT, code, and benchmarks are publicly available at
> https://github.com/Annzstbl/MMOT.

