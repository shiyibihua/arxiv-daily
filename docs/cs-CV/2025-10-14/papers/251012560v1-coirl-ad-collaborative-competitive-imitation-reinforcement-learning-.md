---
layout: default
title: CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving
---

# CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving

**arXiv**: [2510.12560v1](https://arxiv.org/abs/2510.12560) | [PDF](https://arxiv.org/pdf/2510.12560.pdf)

**ä½œè€…**: Xiaoji Zheng, Ziyuan Yang, Yanhao Chen, Yuhang Peng, Yuanrong Tang, Gengyuan Liu, Bokui Chen, Jiangtao Gong

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoIRL-ADæ¡†æž¶ï¼Œç»“åˆæ¨¡ä»¿ä¸Žå¼ºåŒ–å­¦ä¹ æå‡è‡ªåŠ¨é©¾é©¶æ³›åŒ–èƒ½åŠ›**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `æ¨¡ä»¿å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `åŒç­–ç•¥æ¡†æž¶` `æ³›åŒ–èƒ½åŠ›` `é•¿å°¾åœºæ™¯`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ¨¡åž‹ä»…ç”¨æ¨¡ä»¿å­¦ä¹ æ³›åŒ–èƒ½åŠ›å·®ï¼Œå¼ºåŒ–å­¦ä¹ æ ·æœ¬æ•ˆçŽ‡ä½Žä¸”ä¸ç¨³å®š
2. é‡‡ç”¨ç«žäº‰æ€§åŒç­–ç•¥æ¡†æž¶ï¼Œè®©æ¨¡ä»¿ä¸Žå¼ºåŒ–å­¦ä¹ ä»£ç†åœ¨è®­ç»ƒä¸­äº¤äº’ï¼Œé¿å…æ¢¯åº¦å†²çª
3. åœ¨nuScenesæ•°æ®é›†ä¸Šç¢°æ’žçŽ‡é™ä½Ž18%ï¼Œæ³›åŒ–èƒ½åŠ›å’Œé•¿å°¾åœºæ™¯æ€§èƒ½æå‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> End-to-end autonomous driving models trained solely with imitation learning
> (IL) often suffer from poor generalization. In contrast, reinforcement learning
> (RL) promotes exploration through reward maximization but faces challenges such
> as sample inefficiency and unstable convergence. A natural solution is to
> combine IL and RL. Moving beyond the conventional two-stage paradigm (IL
> pretraining followed by RL fine-tuning), we propose CoIRL-AD, a competitive
> dual-policy framework that enables IL and RL agents to interact during
> training. CoIRL-AD introduces a competition-based mechanism that facilitates
> knowledge exchange while preventing gradient conflicts. Experiments on the
> nuScenes dataset show an 18% reduction in collision rate compared to baselines,
> along with stronger generalization and improved performance on long-tail
> scenarios. Code is available at: https://github.com/SEU-zxj/CoIRL-AD.

