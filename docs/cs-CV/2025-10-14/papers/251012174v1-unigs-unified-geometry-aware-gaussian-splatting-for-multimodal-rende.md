---
layout: default
title: UniGS: Unified Geometry-Aware Gaussian Splatting for Multimodal Rendering
---

# UniGS: Unified Geometry-Aware Gaussian Splatting for Multimodal Rendering

**arXiv**: [2510.12174v1](https://arxiv.org/abs/2510.12174) | [PDF](https://arxiv.org/pdf/2510.12174.pdf)

**ä½œè€…**: Yusen Xie, Zhenmin Huang, Jianhao Jiao, Dimitrios Kanoulas, Jun Ma

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUniGSç»Ÿä¸€æ¡†æž¶ï¼Œå®žçŽ°é«˜ä¿çœŸå¤šæ¨¡æ€3Dé‡å»ºï¼ŒåŸºäºŽå‡ ä½•æ„ŸçŸ¥é«˜æ–¯æº…å°„ã€‚**

**å…³é”®è¯**: `3Dé«˜æ–¯æº…å°„` `å¤šæ¨¡æ€æ¸²æŸ“` `å‡ ä½•ä¸€è‡´æ€§` `å¯å¾®å…‰æ …åŒ–` `CUDAåŠ é€Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€3Dé‡å»ºä¸­å‡ ä½•ä¸€è‡´æ€§ä¸Žæ¸²æŸ“æ•ˆçŽ‡çš„æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡æ–°è®¾è®¡å…‰æ …åŒ–ï¼Œä½¿ç”¨å¯å¾®å…‰çº¿-æ¤­çƒç›¸äº¤ä¼˜åŒ–æ·±åº¦å’Œè¡¨é¢æ³•çº¿ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®šé‡å®šæ€§å®žéªŒæ˜¾ç¤ºåœ¨æ‰€æœ‰æ¨¡æ€ä¸Šè¾¾åˆ°æœ€å…ˆè¿›é‡å»ºç²¾åº¦ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this paper, we propose UniGS, a unified map representation and
> differentiable framework for high-fidelity multimodal 3D reconstruction based
> on 3D Gaussian Splatting. Our framework integrates a CUDA-accelerated
> rasterization pipeline capable of rendering photo-realistic RGB images,
> geometrically accurate depth maps, consistent surface normals, and semantic
> logits simultaneously. We redesign the rasterization to render depth via
> differentiable ray-ellipsoid intersection rather than using Gaussian centers,
> enabling effective optimization of rotation and scale attribute through
> analytic depth gradients. Furthermore, we derive the analytic gradient
> formulation for surface normal rendering, ensuring geometric consistency among
> reconstructed 3D scenes. To improve computational and storage efficiency, we
> introduce a learnable attribute that enables differentiable pruning of
> Gaussians with minimal contribution during training. Quantitative and
> qualitative experiments demonstrate state-of-the-art reconstruction accuracy
> across all modalities, validating the efficacy of our geometry-aware paradigm.
> Source code and multimodal viewer will be available on GitHub.

