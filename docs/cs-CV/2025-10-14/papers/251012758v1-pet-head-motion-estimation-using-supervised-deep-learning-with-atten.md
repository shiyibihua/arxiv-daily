---
layout: default
title: PET Head Motion Estimation Using Supervised Deep Learning with Attention
---

# PET Head Motion Estimation Using Supervised Deep Learning with Attention

**arXiv**: [2510.12758v1](https://arxiv.org/abs/2510.12758) | [PDF](https://arxiv.org/pdf/2510.12758.pdf)

**ä½œè€…**: Zhuotong Cai, Tianyi Zeng, Jiazhen Zhang, ElÃ©onore V. Lieffrig, Kathryn Fontaine, Chenyu You, Enette Mae Revilla, James S. Duncan, Jingmin Xin, Yihuan Lu, John A. Onofrey

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæ³¨æ„åŠ›æœºåˆ¶çš„æ·±åº¦å­¦ä¹ æ¨¡åž‹DL-HMC++ï¼Œç”¨äºŽPETå¤´éƒ¨è¿åŠ¨ä¼°è®¡ä¸Žæ ¡æ­£ã€‚**

**å…³é”®è¯**: `PETæˆåƒ` `å¤´éƒ¨è¿åŠ¨æ ¡æ­£` `æ·±åº¦å­¦ä¹ ` `æ³¨æ„åŠ›æœºåˆ¶` `ç›‘ç£å­¦ä¹ ` `åŒ»å­¦å›¾åƒåˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤´éƒ¨è¿åŠ¨å¯¼è‡´PETæˆåƒä¼ªå½±å’Œå®šé‡è¯¯å·®ï¼Œå½±å“ç¥žç»ç–¾ç—…è¯Šæ–­ã€‚
2. ä½¿ç”¨ç›‘ç£å­¦ä¹ å’Œäº¤å‰æ³¨æ„åŠ›ï¼Œä»Ž3D PETåŽŸå§‹æ•°æ®é¢„æµ‹åˆšæ€§å¤´éƒ¨è¿åŠ¨ã€‚
3. åœ¨å¤šç§æ‰«æå™¨å’Œç¤ºè¸ªå‰‚ä¸ŠéªŒè¯ï¼Œæ€§èƒ½ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼ŒæŽ¥è¿‘é‡‘æ ‡å‡†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Head movement poses a significant challenge in brain positron emission
> tomography (PET) imaging, resulting in image artifacts and tracer uptake
> quantification inaccuracies. Effective head motion estimation and correction
> are crucial for precise quantitative image analysis and accurate diagnosis of
> neurological disorders. Hardware-based motion tracking (HMT) has limited
> applicability in real-world clinical practice. To overcome this limitation, we
> propose a deep-learning head motion correction approach with cross-attention
> (DL-HMC++) to predict rigid head motion from one-second 3D PET raw data.
> DL-HMC++ is trained in a supervised manner by leveraging existing dynamic PET
> scans with gold-standard motion measurements from external HMT. We evaluate
> DL-HMC++ on two PET scanners (HRRT and mCT) and four radiotracers (18F-FDG,
> 18F-FPEB, 11C-UCB-J, and 11C-LSN3172176) to demonstrate the effectiveness and
> generalization of the approach in large cohort PET studies. Quantitative and
> qualitative results demonstrate that DL-HMC++ consistently outperforms
> state-of-the-art data-driven motion estimation methods, producing motion-free
> images with clear delineation of brain structures and reduced motion artifacts
> that are indistinguishable from gold-standard HMT. Brain region of interest
> standard uptake value analysis exhibits average difference ratios between
> DL-HMC++ and gold-standard HMT to be 1.2 plus-minus 0.5% for HRRT and 0.5
> plus-minus 0.2% for mCT. DL-HMC++ demonstrates the potential for data-driven
> PET head motion correction to remove the burden of HMT, making motion
> correction accessible to clinical populations beyond research settings. The
> code is available at https://github.com/maxxxxxxcai/DL-HMC-TMI.

