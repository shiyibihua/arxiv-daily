---
layout: default
title: Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector
---

# Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector

**arXiv**: [2510.12287v1](https://arxiv.org/abs/2510.12287) | [PDF](https://arxiv.org/pdf/2510.12287.pdf)

**ä½œè€…**: Sifan Li, Hongkai Chen, Yujun Cai, Qingwen Ye, Liyang Chen, Junsong Yuan, Yiwei Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºè§†è§‰è¯­è¨€æ¨¡åž‹å› æŠ•å½±å™¨è¯­ä¹‰çº ç¼ å¯¼è‡´å¾½æ ‡å¹»è§‰ï¼Œå¹¶æå‡ºç¼“è§£æ–¹æ³•**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡åž‹` `å¾½æ ‡å¹»è§‰` `æŠ•å½±å™¨åˆ†æž` `è¯­ä¹‰çº ç¼ ` `OCRå¼•å¯¼è§£ç ` `å¤šæ¨¡æ€é²æ£’æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§‰è¯­è¨€æ¨¡åž‹åœ¨æ— æ–‡å­—å¾½æ ‡ä¸Šäº§ç”Ÿå“ç‰Œåç§°å¹»è§‰ï¼Œä¾èµ–ç¬¦å·å…ˆéªŒè€ŒéžçœŸå®žå­—å½¢æ„ŸçŸ¥ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡åµŒå…¥åˆ†æžå’Œé’ˆå¯¹æ€§æ¶ˆèžï¼Œè¯†åˆ«å¹¶å‡å°‘æŠ•å½±å™¨ç»´åº¦ä¸­çš„å¹»è§‰ç›¸å…³å­ç©ºé—´ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨æ‰°åŠ¨å’Œé®æŒ¡æµ‹è¯•ä¸­ï¼Œå¹»è§‰æŒç»­å­˜åœ¨ï¼Œæ¶ˆèžæ–¹æ³•æ˜¾è‘—é™ä½Žé”™è¯¯å¹¶ä¿æŒOCRå‡†ç¡®æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision Language Models (VLMs) have achieved impressive progress in multimodal
> reasoning; yet, they remain vulnerable to hallucinations, where outputs are not
> grounded in visual evidence. In this paper, we investigate a previously
> overlooked setting: logo hallucination, where models generate brand names or
> textual content despite logos containing no visible words. Using curated splits
> of pure symbols, hybrids, and text-bearing logos, as well as the challenging
> Hard-60 subset, we systematically measure hallucination across leading VLMs. We
> further probe robustness through nine structured perturbations and show that
> hallucinations persist even under strong distortions, with occlusion exposing
> the sharpest weaknesses. Embedding-level analysis with open-weight LLaVA
> demonstrates that hallucination is tied to a small subset of projector
> dimensions, and targeted ablation substantially reduces errors while preserving
> OCR accuracy. Together, these findings reveal that VLMs often rely on symbolic
> priors rather than genuine glyph perception, particularly for iconic circular
> logos, and that projector subspaces play a decisive role in this failure mode.
> Our work contributes both a novel diagnostic lens and actionable mitigation
> insights, highlighting projector disentanglement and OCR-guided decoding as
> promising directions for building more trustworthy multimodal systems.

