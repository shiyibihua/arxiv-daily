---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-10-11
---

# cs.CVï¼ˆ2025-10-11ï¼‰

ğŸ“Š å…± **26** ç¯‡è®ºæ–‡
 | ğŸ”— **4** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (9 ğŸ”—2)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (7 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (3)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251010011v1-mimo-a-medical-vision-language-model-with-visual-referring-multimoda.html">MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output</a></td>
  <td>MIMOï¼šä¸€ç§å…·æœ‰è§†è§‰æŒ‡ä»£å¤šæ¨¡æ€è¾“å…¥å’Œåƒç´ çº§å®šä½å¤šæ¨¡æ€è¾“å‡ºçš„åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10011v1" onclick="toggleFavorite(this, '2510.10011v1', 'MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251010366v1-vision4ppg-emergent-ppg-analysis-capability-of-vision-foundation-mod.html">Vision4PPG: Emergent PPG Analysis Capability of Vision Foundation Models for Vital Signs like Blood Pressure</a></td>
  <td>Vision4PPGï¼šåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹è¿›è¡ŒPPGåˆ†æï¼Œå®ç°è¡€å‹ç­‰ç”Ÿå‘½ä½“å¾çš„é¢„æµ‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10366v1" onclick="toggleFavorite(this, '2510.10366v1', 'Vision4PPG: Emergent PPG Analysis Capability of Vision Foundation Models for Vital Signs like Blood Pressure')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251015963v2-esca-contextualizing-embodied-agents-via-scene-graph-generation.html">ESCA: Contextualizing Embodied Agents via Scene-Graph Generation</a></td>
  <td>æå‡ºESCAæ¡†æ¶ï¼Œé€šè¿‡åœºæ™¯å›¾ç”Ÿæˆå¢å¼ºå…·èº«æ™ºèƒ½ä½“çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.15963v2" onclick="toggleFavorite(this, '2510.15963v2', 'ESCA: Contextualizing Embodied Agents via Scene-Graph Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251010196v1-from-generic-to-specialized-a-subspecialty-diagnostic-system-powered.html">From Generic to Specialized: A Subspecialty Diagnostic System Powered by Self-Supervised Learning for Cervical Histopathology</a></td>
  <td>CerS-Pathï¼šåŸºäºè‡ªç›‘ç£å­¦ä¹ çš„å®«é¢ˆç»„ç»‡ç—…ç†äºšä¸“ç§‘è¯Šæ–­ç³»ç»Ÿ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10196v1" onclick="toggleFavorite(this, '2510.10196v1', 'From Generic to Specialized: A Subspecialty Diagnostic System Powered by Self-Supervised Learning for Cervical Histopathology')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251017847v1-coido-efficient-data-selection-for-visual-instruction-tuning-via-cou.html">CoIDO: Efficient Data Selection for Visual Instruction Tuning via Coupled Importance-Diversity Optimization</a></td>
  <td>CoIDOï¼šé€šè¿‡è€¦åˆé‡è¦æ€§-å¤šæ ·æ€§ä¼˜åŒ–å®ç°è§†è§‰æŒ‡ä»¤è°ƒä¼˜çš„é«˜æ•ˆæ•°æ®é€‰æ‹©</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.17847v1" onclick="toggleFavorite(this, '2510.17847v1', 'CoIDO: Efficient Data Selection for Visual Instruction Tuning via Coupled Importance-Diversity Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251010022v1-q-adapter-visual-query-adapter-for-extracting-textually-related-feat.html">Q-Adapter: Visual Query Adapter for Extracting Textually-related Features in Video Captioning</a></td>
  <td>æå‡ºQ-Adapterï¼Œé€šè¿‡å¯å­¦ä¹ æŸ¥è¯¢tokené«˜æ•ˆæå–è§†é¢‘å­—å¹•ç›¸å…³è§†è§‰ç‰¹å¾ï¼Œå®ç°å‚æ•°é«˜æ•ˆçš„è§†é¢‘å­—å¹•ç”Ÿæˆã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10022v1" onclick="toggleFavorite(this, '2510.10022v1', 'Q-Adapter: Visual Query Adapter for Extracting Textually-related Features in Video Captioning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251009981v1-scaling-traffic-insights-with-ai-and-language-model-powered-camera-s.html">Scaling Traffic Insights with AI and Language Model-Powered Camera Systems for Data-Driven Transportation Decision Making</a></td>
  <td>æå‡ºåŸºäºAIå’Œè¯­è¨€æ¨¡å‹çš„äº¤é€šæ‘„åƒå¤´ç³»ç»Ÿï¼Œç”¨äºå¤§è§„æ¨¡äº¤é€šæ´å¯Ÿå’Œæ•°æ®é©±åŠ¨çš„å†³ç­–</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.09981v1" onclick="toggleFavorite(this, '2510.09981v1', 'Scaling Traffic Insights with AI and Language Model-Powered Camera Systems for Data-Driven Transportation Decision Making')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251013652v1-editcast3d-single-frame-guided-3d-editing-with-video-propagation-and.html">EditCast3D: Single-Frame-Guided 3D Editing with Video Propagation and View Selection</a></td>
  <td>EditCast3Dï¼šåˆ©ç”¨è§†é¢‘ä¼ æ’­å’Œè§†å›¾é€‰æ‹©å®ç°å•å¸§å¼•å¯¼çš„3Dç¼–è¾‘</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.13652v1" onclick="toggleFavorite(this, '2510.13652v1', 'EditCast3D: Single-Frame-Guided 3D Editing with Video Propagation and View Selection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251010292v1-from-programs-to-poses-factored-real-world-scene-generation-via-lear.html">From Programs to Poses: Factored Real-World Scene Generation via Learned Program Libraries</a></td>
  <td>FactoredScenesï¼šé€šè¿‡å­¦ä¹ ç¨‹åºåº“ç”Ÿæˆå¯åˆ†è§£çš„çœŸå®ä¸–ç•Œåœºæ™¯ï¼Œè§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10292v1" onclick="toggleFavorite(this, '2510.10292v1', 'From Programs to Poses: Factored Real-World Scene Generation via Learned Program Libraries')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (7 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>10</td>
  <td><a href="./papers/251010097v2-gesplat-robust-pose-free-3d-reconstruction-via-geometry-guided-gauss.html">Gesplat: Robust Pose-Free 3D Reconstruction via Geometry-Guided Gaussian Splatting</a></td>
  <td>Gesplatï¼šåŸºäºå‡ ä½•å¼•å¯¼é«˜æ–¯æº…å°„çš„é²æ£’æ— å§¿æ€3Dé‡å»º</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10097v2" onclick="toggleFavorite(this, '2510.10097v2', 'Gesplat: Robust Pose-Free 3D Reconstruction via Geometry-Guided Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251010257v1-opacity-gradient-driven-density-control-for-compact-and-efficient-fe.html">Opacity-Gradient Driven Density Control for Compact and Efficient Few-Shot 3D Gaussian Splatting</a></td>
  <td>æå‡ºåŸºäºä¸é€æ˜åº¦æ¢¯åº¦çš„å¯†åº¦æ§åˆ¶æ–¹æ³•ï¼Œæå‡å°‘æ ·æœ¬3Dé«˜æ–¯æº…å°„çš„æ•ˆç‡å’Œç´§å‡‘æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10257v1" onclick="toggleFavorite(this, '2510.10257v1', 'Opacity-Gradient Driven Density Control for Compact and Efficient Few-Shot 3D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251010030v1-p-4dgs-predictive-4d-gaussian-splatting-with-90times-compression.html">P-4DGS: Predictive 4D Gaussian Splatting with 90$\times$ Compression</a></td>
  <td>æå‡ºP-4DGSä»¥è§£å†³åŠ¨æ€åœºæ™¯å»ºæ¨¡ä¸­çš„é«˜å†…å­˜æ¶ˆè€—é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10030v1" onclick="toggleFavorite(this, '2510.10030v1', 'P-4DGS: Predictive 4D Gaussian Splatting with 90$\times$ Compression')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251010342v1-ordinal-scale-traffic-congestion-classification-with-multi-modal-vis.html">Ordinal Scale Traffic Congestion Classification with Multi-Modal Vision-Language and Motion Analysis</a></td>
  <td>æå‡ºå¤šæ¨¡æ€èåˆæ¡†æ¶ï¼Œç”¨äºåºæ•°å°ºåº¦ä¸‹çš„äº¤é€šæ‹¥å µç­‰çº§åˆ†ç±»</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10342v1" onclick="toggleFavorite(this, '2510.10342v1', 'Ordinal Scale Traffic Congestion Classification with Multi-Modal Vision-Language and Motion Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251010360v1-ortho-fuse-orthomosaic-generation-for-sparse-high-resolution-crop-he.html">Ortho-Fuse: Orthomosaic Generation for Sparse High-Resolution Crop Health Maps Through Intermediate Optical Flow Estimation</a></td>
  <td>Ortho-Fuseï¼šé€šè¿‡å…‰æµä¼°è®¡ä¸ºç¨€ç–é«˜åˆ†è¾¨ç‡ä½œç‰©å¥åº·åœ°å›¾ç”Ÿæˆæ­£å°„å½±åƒ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10360v1" onclick="toggleFavorite(this, '2510.10360v1', 'Ortho-Fuse: Orthomosaic Generation for Sparse High-Resolution Crop Health Maps Through Intermediate Optical Flow Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251010194v2-b2n3d-progressive-learning-from-binary-to-n-ary-relationships-for-3d.html">B2N3D: Progressive Learning from Binary to N-ary Relationships for 3D Object Grounding</a></td>
  <td>æå‡ºB2N3Dæ¡†æ¶ï¼Œé€šè¿‡äºŒå…ƒåˆ°Nå…ƒå…³ç³»æ¸è¿›å­¦ä¹ å®ç°æ›´ç²¾ç¡®çš„3Dç‰©ä½“å®šä½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10194v2" onclick="toggleFavorite(this, '2510.10194v2', 'B2N3D: Progressive Learning from Binary to N-ary Relationships for 3D Object Grounding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251010152v1-color3d-controllable-and-consistent-3d-colorization-with-personalize.html">Color3D: Controllable and Consistent 3D Colorization with Personalized Colorizer</a></td>
  <td>Color3Dï¼šåŸºäºä¸ªæ€§åŒ–ç€è‰²å™¨çš„å¯æ§ä¸€è‡´3Dç€è‰²æ¡†æ¶</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10152v1" onclick="toggleFavorite(this, '2510.10152v1', 'Color3D: Controllable and Consistent 3D Colorization with Personalized Colorizer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/251010104v1-answer-consistent-chain-of-thought-reinforcement-learning-for-multi-.html">Answer-Consistent Chain-of-thought Reinforcement Learning For Multi-modal Large Langauge Models</a></td>
  <td>æå‡ºACREï¼Œé€šè¿‡ä¸€è‡´æ€§å¼ºåŒ–å­¦ä¹ æå‡å¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨è§†è§‰é—®ç­”ä»»åŠ¡ä¸­çš„æ¨ç†ä¸€è‡´æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10104v1" onclick="toggleFavorite(this, '2510.10104v1', 'Answer-Consistent Chain-of-thought Reinforcement Learning For Multi-modal Large Langauge Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251010287v1-bridging-perspectives-foundation-model-guided-bev-maps-for-3d-object.html">Bridging Perspectives: Foundation Model Guided BEV Maps for 3D Object Detection and Tracking</a></td>
  <td>æå‡ºDualViewDistillï¼Œåˆ©ç”¨åŸºç¡€æ¨¡å‹å¼•å¯¼çš„BEVåœ°å›¾æå‡3Dç›®æ ‡æ£€æµ‹ä¸è·Ÿè¸ªæ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10287v1" onclick="toggleFavorite(this, '2510.10287v1', 'Bridging Perspectives: Foundation Model Guided BEV Maps for 3D Object Detection and Tracking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251010068v2-probabilistic-hyper-graphs-using-multiple-randomly-masked-autoencode.html">Probabilistic Hyper-Graphs using Multiple Randomly Masked Autoencoders for Semi-supervised Multi-modal Multi-task Learning</a></td>
  <td>æå‡ºPHG-MAEæ¨¡å‹ï¼Œç»“åˆç¥ç»å›¾å’Œæ©ç è‡ªç¼–ç å™¨ï¼Œç”¨äºåŠç›‘ç£å¤šæ¨¡æ€å¤šä»»åŠ¡å­¦ä¹ ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10068v2" onclick="toggleFavorite(this, '2510.10068v2', 'Probabilistic Hyper-Graphs using Multiple Randomly Masked Autoencoders for Semi-supervised Multi-modal Multi-task Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251010051v1-complementary-and-contrastive-learning-for-audio-visual-segmentation.html">Complementary and Contrastive Learning for Audio-Visual Segmentation</a></td>
  <td>æå‡ºCCFormerï¼Œé€šè¿‡äº’è¡¥å¯¹æ¯”å­¦ä¹ å®ç°æ›´ç²¾å‡†çš„éŸ³è§†é¢‘åˆ†å‰²</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10051v1" onclick="toggleFavorite(this, '2510.10051v1', 'Complementary and Contrastive Learning for Audio-Visual Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/251010160v2-safire-saccade-fixation-reiteration-with-mamba-for-referring-image-s.html">SaFiRe: Saccade-Fixation Reiteration with Mamba for Referring Image Segmentation</a></td>
  <td>æå‡ºSaFiReæ¡†æ¶ï¼Œåˆ©ç”¨Mambaè§£å†³æŒ‡ä»£å›¾åƒåˆ†å‰²ä¸­å¤æ‚è¡¨è¾¾å¼çš„éš¾é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10160v2" onclick="toggleFavorite(this, '2510.10160v2', 'SaFiRe: Saccade-Fixation Reiteration with Mamba for Referring Image Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>22</td>
  <td><a href="./papers/251010111v2-training-free-in-context-forensic-chain-for-image-manipulation-detec.html">Training-Free In-Context Forensic Chain for Image Manipulation Detection and Localization</a></td>
  <td>æå‡ºå…è®­ç»ƒçš„ä¸Šä¸‹æ–‡å–è¯é“¾ICFCï¼Œç”¨äºå›¾åƒç¯¡æ”¹æ£€æµ‹ä¸å®šä½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10111v2" onclick="toggleFavorite(this, '2510.10111v2', 'Training-Free In-Context Forensic Chain for Image Manipulation Detection and Localization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/251010073v1-securewebarena-a-holistic-security-evaluation-benchmark-for-lvlm-bas.html">SecureWebArena: A Holistic Security Evaluation Benchmark for LVLM-based Web Agents</a></td>
  <td>SecureWebArenaï¼šLVLM Web Agentå®‰å…¨è¯„ä¼°çš„ç»¼åˆåŸºå‡†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10073v1" onclick="toggleFavorite(this, '2510.10073v1', 'SecureWebArena: A Holistic Security Evaluation Benchmark for LVLM-based Web Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/251009996v1-burstdeflicker-a-benchmark-dataset-for-flicker-removal-in-dynamic-sc.html">BurstDeflicker: A Benchmark Dataset for Flicker Removal in Dynamic Scenes</a></td>
  <td>æå‡ºBurstDeflickeræ•°æ®é›†ï¼Œç”¨äºåŠ¨æ€åœºæ™¯ä¸‹å›¾åƒé—ªçƒæ¶ˆé™¤ç ”ç©¶ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.09996v1" onclick="toggleFavorite(this, '2510.09996v1', 'BurstDeflicker: A Benchmark Dataset for Flicker Removal in Dynamic Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>25</td>
  <td><a href="./papers/251010084v1-tracking-the-spatiotemporal-evolution-of-landslide-scars-using-a-vis.html">Tracking the Spatiotemporal Evolution of Landslide Scars Using a Vision Foundation Model: A Novel and Universal Framework</a></td>
  <td>æå‡ºåŸºäºè§†è§‰åŸºç¡€æ¨¡å‹çš„æ»‘å¡ç–¤ç—•æ—¶ç©ºæ¼”åŒ–è¿½è¸ªæ¡†æ¶ï¼Œå®ç°è¿ç»­ç›‘æµ‹ä¸é¢„è­¦ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10084v1" onclick="toggleFavorite(this, '2510.10084v1', 'Tracking the Spatiotemporal Evolution of Landslide Scars Using a Vision Foundation Model: A Novel and Universal Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/251009936v1-semi-disentangled-spatiotemporal-implicit-neural-representations-of-.html">Semi-disentangled spatiotemporal implicit neural representations of longitudinal neuroimaging data for trajectory classification</a></td>
  <td>æå‡ºä¸€ç§åŠè§£è€¦æ—¶ç©ºéšå¼ç¥ç»è¡¨ç¤ºæ–¹æ³•ï¼Œç”¨äºçºµå‘ç¥ç»å½±åƒæ•°æ®çš„è½¨è¿¹åˆ†ç±»ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.09936v1" onclick="toggleFavorite(this, '2510.09936v1', 'Semi-disentangled spatiotemporal implicit neural representations of longitudinal neuroimaging data for trajectory classification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)