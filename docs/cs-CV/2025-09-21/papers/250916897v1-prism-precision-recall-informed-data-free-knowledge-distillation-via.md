---
layout: default
title: PRISM: Precision-Recall Informed Data-Free Knowledge Distillation via Generative Diffusion
---

# PRISM: Precision-Recall Informed Data-Free Knowledge Distillation via Generative Diffusion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16897" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16897v1</a>
  <a href="https://arxiv.org/pdf/2509.16897.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16897v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16897v1', 'PRISM: Precision-Recall Informed Data-Free Knowledge Distillation via Generative Diffusion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xuewan He, Jielei Wang, Zihan Cheng, Yuchen Su, Shiyue Huang, Guoming Lu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-21

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PRISMï¼šé€šè¿‡ç”Ÿæˆæ‰©æ•£æ¨¡å‹å®ç°ç²¾ç¡®ç‡-å¬å›ç‡æŒ‡å¯¼çš„æ— æ•°æ®çŸ¥è¯†è’¸é¦**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ— æ•°æ®çŸ¥è¯†è’¸é¦` `ç”Ÿæˆæ‰©æ•£æ¨¡å‹` `ç²¾ç¡®ç‡-å¬å›ç‡` `èƒ½é‡å¼•å¯¼` `æç¤ºå·¥ç¨‹` `é¢†åŸŸæ³›åŒ–` `å›¾åƒåˆæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ— æ•°æ®çŸ¥è¯†è’¸é¦æ–¹æ³•åœ¨å¤§è§„æ¨¡å›¾åƒåˆæˆæ—¶æ˜“å‡ºç°æ¨¡å¼å´©æºƒï¼Œé™åˆ¶äº†çŸ¥è¯†è¿ç§»æ•ˆæœã€‚
2. PRISMæå‡ºä¸€ç§ç²¾ç¡®ç‡-å¬å›ç‡æŒ‡å¯¼çš„åˆæˆæ–¹æ³•ï¼Œé€šè¿‡èƒ½é‡å¼•å¯¼å’Œå¤šæ ·åŒ–æç¤ºå·¥ç¨‹æå‡æ•°æ®è´¨é‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒPRISMåœ¨å¤šä¸ªå¤§è§„æ¨¡å›¾åƒæ•°æ®é›†ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶æå‡äº†æ¨¡å‹çš„é¢†åŸŸæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ— æ•°æ®çŸ¥è¯†è’¸é¦(DFKD)åœ¨æ— æ³•è®¿é—®çœŸå®åˆ†å¸ƒå†…(ID)æ•°æ®çš„æƒ…å†µä¸‹ï¼Œå°†çŸ¥è¯†ä»æ•™å¸ˆæ¨¡å‹è¿ç§»åˆ°å­¦ç”Ÿæ¨¡å‹ã€‚ç°æœ‰æ–¹æ³•åœ¨å°è§„æ¨¡å›¾åƒä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨åˆæˆå¤§è§„æ¨¡å›¾åƒæ—¶å®¹æ˜“å‡ºç°æ¨¡å¼å´©æºƒï¼Œå¯¼è‡´çŸ¥è¯†è¿ç§»å—é™ã€‚æœ€è¿‘ï¼Œåˆ©ç”¨å…ˆè¿›çš„ç”Ÿæˆæ¨¡å‹åˆæˆé€¼çœŸçš„å›¾åƒæˆä¸ºä¸€ç§æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œç›´æ¥ä½¿ç”¨ç°æˆçš„æ‰©æ•£æ¨¡å‹ç”Ÿæˆæ•°æ®é›†é¢ä¸´ç²¾ç¡®ç‡-å¬å›ç‡çš„æŒ‘æˆ˜ï¼š1)ç¡®ä¿åˆæˆæ•°æ®ä¸çœŸå®åˆ†å¸ƒå¯¹é½ï¼Œ2)ç¡®ä¿è¦†ç›–çœŸå®IDæµå½¢ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºPRISMï¼Œä¸€ç§ç²¾ç¡®ç‡-å¬å›ç‡æŒ‡å¯¼çš„åˆæˆæ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥èƒ½é‡å¼•å¯¼çš„åˆ†å¸ƒå¯¹é½ï¼Œä»¥é¿å…ç”Ÿæˆåˆ†å¸ƒå¤–æ ·æœ¬ï¼Œå¹¶è®¾è®¡å¤šæ ·åŒ–çš„æç¤ºå·¥ç¨‹ï¼Œä»¥å¢å¼ºå¯¹çœŸå®IDæµå½¢çš„è¦†ç›–ã€‚åœ¨å„ç§å¤§è§„æ¨¡å›¾åƒæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†PRISMçš„ä¼˜è¶Šæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯æ˜äº†ä½¿ç”¨PRISMè®­ç»ƒçš„æ¨¡å‹è¡¨ç°å‡ºå¼ºå¤§çš„é¢†åŸŸæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ— æ•°æ®çŸ¥è¯†è’¸é¦ï¼ˆDFKDï¼‰ä¸­ï¼Œåˆ©ç”¨ç”Ÿæˆæ¨¡å‹åˆæˆå¤§è§„æ¨¡å›¾åƒæ—¶é¢ä¸´çš„ç²¾ç¡®ç‡å’Œå¬å›ç‡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨åˆæˆå¤§è§„æ¨¡å›¾åƒæ—¶å®¹æ˜“å‡ºç°æ¨¡å¼å´©æºƒï¼Œå¯¼è‡´åˆæˆæ•°æ®è´¨é‡ä¸é«˜ï¼Œæ— æ³•æœ‰æ•ˆè¿›è¡ŒçŸ¥è¯†è¿ç§»ã€‚ç—›ç‚¹åœ¨äºå¦‚ä½•ç”Ÿæˆæ—¢ç¬¦åˆçœŸå®æ•°æ®åˆ†å¸ƒï¼Œåˆèƒ½è¦†ç›–çœŸå®æ•°æ®æµå½¢çš„æ•°æ®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆèƒ½é‡å¼•å¯¼å’Œå¤šæ ·åŒ–æç¤ºå·¥ç¨‹ï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­åŒæ—¶ä¼˜åŒ–åˆæˆæ•°æ®çš„ç²¾ç¡®ç‡å’Œå¬å›ç‡ã€‚é€šè¿‡èƒ½é‡å¼•å¯¼é¿å…ç”Ÿæˆåˆ†å¸ƒå¤–æ ·æœ¬ï¼Œä¿è¯åˆæˆæ•°æ®çš„ç²¾ç¡®ç‡ï¼›é€šè¿‡å¤šæ ·åŒ–æç¤ºå·¥ç¨‹ï¼Œå°½å¯èƒ½è¦†ç›–çœŸå®æ•°æ®æµå½¢ï¼Œä¿è¯åˆæˆæ•°æ®çš„å¬å›ç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPRISMçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šèƒ½é‡å¼•å¯¼çš„åˆ†å¸ƒå¯¹é½å’Œå¤šæ ·åŒ–æç¤ºå·¥ç¨‹ã€‚é¦–å…ˆï¼Œåˆ©ç”¨èƒ½é‡å‡½æ•°è¯„ä¼°ç”Ÿæˆæ ·æœ¬çš„è´¨é‡ï¼Œå¹¶å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹æœç€èƒ½é‡è¾ƒä½çš„æ–¹å‘è¿›è¡Œï¼Œä»è€Œä¿è¯ç”Ÿæˆæ ·æœ¬ä¸çœŸå®æ•°æ®åˆ†å¸ƒå¯¹é½ã€‚ç„¶åï¼Œé€šè¿‡è®¾è®¡å¤šæ ·åŒ–çš„æç¤ºï¼Œé¼“åŠ±ç”Ÿæˆæ¨¡å‹æ¢ç´¢ä¸åŒçš„æ•°æ®æ¨¡å¼ï¼Œä»è€Œæé«˜å¯¹çœŸå®æ•°æ®æµå½¢çš„è¦†ç›–ã€‚è¿™ä¸¤ä¸ªæ¨¡å—ååŒå·¥ä½œï¼Œå…±åŒæå‡åˆæˆæ•°æ®çš„è´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šPRISMçš„å…³é”®åˆ›æ–°åœ¨äºå°†èƒ½é‡å‡½æ•°å’Œæç¤ºå·¥ç¨‹ç»“åˆèµ·æ¥ï¼Œç”¨äºæŒ‡å¯¼ç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒï¼Œä»è€Œåœ¨æ— æ•°æ®çŸ¥è¯†è’¸é¦ä¸­å®ç°æ›´å¥½çš„æ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒPRISMä¸ä»…å…³æ³¨ç”Ÿæˆæ•°æ®çš„é€¼çœŸåº¦ï¼Œè¿˜å…³æ³¨ç”Ÿæˆæ•°æ®çš„å¤šæ ·æ€§å’Œåˆ†å¸ƒå¯¹é½ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°è¿›è¡ŒçŸ¥è¯†è¿ç§»ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨èƒ½é‡å¼•å¯¼çš„åˆ†å¸ƒå¯¹é½ä¸­ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„åˆ†ç±»å™¨æå–ç‰¹å¾ï¼Œå¹¶è®¡ç®—ç”Ÿæˆæ ·æœ¬çš„èƒ½é‡å€¼ã€‚åœ¨å¤šæ ·åŒ–æç¤ºå·¥ç¨‹ä¸­ï¼Œè®¾è®¡äº†ä¸€ç³»åˆ—ä¸åŒçš„æç¤ºï¼Œå¹¶ä½¿ç”¨è¿™äº›æç¤ºæ¥ç”Ÿæˆä¸åŒçš„æ ·æœ¬ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬èƒ½é‡æŸå¤±å’Œå¤šæ ·æ€§æŸå¤±ï¼Œç”¨äºä¼˜åŒ–ç”Ÿæˆæ¨¡å‹çš„å‚æ•°ã€‚å…·ä½“å‚æ•°è®¾ç½®æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡åœ¨å¤šä¸ªå¤§è§„æ¨¡å›¾åƒæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜PRISMæ˜¾è‘—ä¼˜äºç°æœ‰çš„æ— æ•°æ®çŸ¥è¯†è’¸é¦æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨ImageNetæ•°æ®é›†ä¸Šï¼Œä½¿ç”¨PRISMè®­ç»ƒçš„å­¦ç”Ÿæ¨¡å‹æ¯”ä½¿ç”¨å…¶ä»–æ–¹æ³•è®­ç»ƒçš„å­¦ç”Ÿæ¨¡å‹æé«˜äº†å¤šä¸ªç™¾åˆ†ç‚¹çš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜è¯æ˜äº†ä½¿ç”¨PRISMè®­ç»ƒçš„æ¨¡å‹å…·æœ‰æ›´å¼ºçš„é¢†åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œåœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šè¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PRISMå¯åº”ç”¨äºå„ç§éœ€è¦çŸ¥è¯†è’¸é¦ä½†æ— æ³•è®¿é—®åŸå§‹æ•°æ®çš„åœºæ™¯ï¼Œä¾‹å¦‚æ¨¡å‹å‹ç¼©ã€è”é‚¦å­¦ä¹ å’Œéšç§ä¿æŠ¤ç­‰ã€‚é€šè¿‡ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆæ•°æ®ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å°†çŸ¥è¯†ä»å¤§å‹æ•™å¸ˆæ¨¡å‹è¿ç§»åˆ°å°å‹å­¦ç”Ÿæ¨¡å‹ï¼Œä»è€Œé™ä½è®¡ç®—æˆæœ¬å’Œå­˜å‚¨éœ€æ±‚ã€‚æ­¤å¤–ï¼ŒPRISMè¿˜å¯ä»¥ç”¨äºæ•°æ®å¢å¼ºï¼Œæé«˜æ¨¡å‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Data-free knowledge distillation (DFKD) transfers knowledge from a teacher to a student without access to the real in-distribution (ID) data. While existing methods perform well on small-scale images, they suffer from mode collapse when synthesizing large-scale images, resulting in limited knowledge transfer. Recently, leveraging advanced generative models to synthesize photorealistic images has emerged as a promising alternative. Nevertheless, directly using off-the-shelf diffusion to generate datasets faces the precision-recall challenges: 1) ensuring synthetic data aligns with the real distribution, and 2) ensuring coverage of the real ID manifold. In response, we propose PRISM, a precision-recall informed synthesis method. Specifically, we introduce Energy-guided Distribution Alignment to avoid the generation of out-of-distribution samples, and design the Diversified Prompt Engineering to enhance coverage of the real ID manifold. Extensive experiments on various large-scale image datasets demonstrate the superiority of PRISM. Moreover, we demonstrate that models trained with PRISM exhibit strong domain generalization.

