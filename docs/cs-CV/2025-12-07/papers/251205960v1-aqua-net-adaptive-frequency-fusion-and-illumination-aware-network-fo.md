---
layout: default
title: AQUA-Net: Adaptive Frequency Fusion and Illumination Aware Network for Underwater Image Enhancement
---

# AQUA-Net: Adaptive Frequency Fusion and Illumination Aware Network for Underwater Image Enhancement

**arXiv**: [2512.05960v1](https://arxiv.org/abs/2512.05960) | [PDF](https://arxiv.org/pdf/2512.05960.pdf)

**ä½œè€…**: Munsif Ali, Najmul Hassan, Lucia Ventura, Davide Di Bari, Simonepietro Canese

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAQUA-Netä»¥è§£å†³æ°´ä¸‹å›¾åƒå¢žå¼ºä¸­çš„é¢œè‰²å¤±çœŸã€ä½Žå¯¹æ¯”åº¦å’Œå®žæ—¶éƒ¨ç½²é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ°´ä¸‹å›¾åƒå¢žå¼º` `é¢‘çŽ‡èžåˆ` `å…‰ç…§æ„ŸçŸ¥` `æ·±åº¦å­¦ä¹ æ¨¡åž‹` `å®žæ—¶åº”ç”¨` `æ•°æ®é›†æž„å»º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ°´ä¸‹å›¾åƒå› å…‰å¸æ”¶å’Œæ•£å°„å¯¼è‡´é¢œè‰²å¤±çœŸã€ä½Žå¯¹æ¯”åº¦å’Œé›¾çŠ¶å¤–è§‚ã€‚
2. AQUA-Neté›†æˆæ®‹å·®ç¼–ç è§£ç å™¨ï¼Œåœ¨é¢‘çŽ‡å’Œå…‰ç…§åŸŸæ“ä½œï¼Œé€šè¿‡é¢‘çŽ‡èžåˆå’Œå…‰ç…§æ„ŸçŸ¥æ¢å¤ç»†èŠ‚ã€‚
3. å®žéªŒè¡¨æ˜Žæ¨¡åž‹åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ€§èƒ½ä¸ŽSOTAç›¸å½“ï¼Œå‚æ•°æ›´å°‘ï¼Œæ³›åŒ–èƒ½åŠ›å¼ºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Underwater images often suffer from severe color distortion, low contrast, and a hazy appearance due to wavelength-dependent light absorption and scattering. Simultaneously, existing deep learning models exhibit high computational complexity, which limits their practical deployment for real-time underwater applications. To address these challenges, this paper presents a novel underwater image enhancement model, called Adaptive Frequency Fusion and Illumination Aware Network (AQUA-Net). It integrates a residual encoder decoder with dual auxiliary branches, which operate in the frequency and illumination domains. The frequency fusion encoder enriches spatial representations with frequency cues from the Fourier domain and preserves fine textures and structural details. Inspired by Retinex, the illumination-aware decoder performs adaptive exposure correction through a learned illumination map that separates reflectance from lighting effects. This joint spatial, frequency, and illumination design enables the model to restore color balance, visual contrast, and perceptual realism under diverse underwater conditions. Additionally, we present a high-resolution, real-world underwater video-derived dataset from the Mediterranean Sea, which captures challenging deep-sea conditions with realistic visual degradations to enable robust evaluation and development of deep learning models. Extensive experiments on multiple benchmark datasets show that AQUA-Net performs on par with SOTA in both qualitative and quantitative evaluations while using less number of parameters. Ablation studies further confirm that the frequency and illumination branches provide complementary contributions that improve visibility and color representation. Overall, the proposed model shows strong generalization capability and robustness, and it provides an effective solution for real-world underwater imaging applications.

