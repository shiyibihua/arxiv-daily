---
layout: default
title: Decoding with Structured Awareness: Integrating Directional, Frequency-Spatial, and Structural Attention for Medical Image Segmentation
---

# Decoding with Structured Awareness: Integrating Directional, Frequency-Spatial, and Structural Attention for Medical Image Segmentation

**arXiv**: [2512.05494v1](https://arxiv.org/abs/2512.05494) | [PDF](https://arxiv.org/pdf/2512.05494.pdf)

**ä½œè€…**: Fan Zhang, Zhiwei Gu, Hua Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé›†æˆæ–¹å‘ã€é¢‘ç©ºå’Œç»“æž„æ³¨æ„åŠ›çš„è§£ç å™¨æ¡†æž¶ï¼Œä»¥è§£å†³åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­è¾¹ç¼˜ç»†èŠ‚å’Œç©ºé—´è¿žç»­æ€§å»ºæ¨¡é—®é¢˜ã€‚**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒåˆ†å‰²` `æ³¨æ„åŠ›æœºåˆ¶` `é¢‘ç©ºèžåˆ` `ç»“æž„å»ºæ¨¡` `è§£ç å™¨ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é’ˆå¯¹Transformerè§£ç å™¨åœ¨è¾¹ç¼˜ç»†èŠ‚ã€å±€éƒ¨çº¹ç†å’Œç©ºé—´è¿žç»­æ€§å»ºæ¨¡æ–¹é¢çš„å±€é™æ€§ã€‚
2. æ ¸å¿ƒæ¨¡å—åŒ…æ‹¬æ–¹å‘å¼•å¯¼çš„ACFAã€é¢‘ç©ºèžåˆçš„TFFAå’Œç»“æž„æ„ŸçŸ¥çš„SMMMï¼Œå¢žå¼ºå…¨å±€ä¾èµ–å’Œå±€éƒ¨ä¿¡æ¯ä¿ç•™ã€‚
3. å®žéªŒè¡¨æ˜Žåœ¨è‚¿ç˜¤åˆ†å‰²å’Œå™¨å®˜è¾¹ç•Œæå–ç­‰ä»»åŠ¡ä¸­æå‡åˆ†å‰²ç²¾åº¦å’Œæ¨¡åž‹æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> To address the limitations of Transformer decoders in capturing edge details, recognizing local textures and modeling spatial continuity, this paper proposes a novel decoder framework specifically designed for medical image segmentation, comprising three core modules. First, the Adaptive Cross-Fusion Attention (ACFA) module integrates channel feature enhancement with spatial attention mechanisms and introduces learnable guidance in three directions (planar, horizontal, and vertical) to enhance responsiveness to key regions and structural orientations. Second, the Triple Feature Fusion Attention (TFFA) module fuses features from Spatial, Fourier and Wavelet domains, achieving joint frequency-spatial representation that strengthens global dependency and structural modeling while preserving local information such as edges and textures, making it particularly effective in complex and blurred boundary scenarios. Finally, the Structural-aware Multi-scale Masking Module (SMMM) optimizes the skip connections between encoder and decoder by leveraging multi-scale context and structural saliency filtering, effectively reducing feature redundancy and improving semantic interaction quality. Working synergistically, these modules not only address the shortcomings of traditional decoders but also significantly enhance performance in high-precision tasks such as tumor segmentation and organ boundary extraction, improving both segmentation accuracy and model generalization. Experimental results demonstrate that this framework provides an efficient and practical solution for medical image segmentation.

