---
layout: default
title: Learning High-Fidelity Cloth Animation via Skinning-Free Image Transfer
---

# Learning High-Fidelity Cloth Animation via Skinning-Free Image Transfer

**arXiv**: [2512.05593v1](https://arxiv.org/abs/2512.05593) | [PDF](https://arxiv.org/pdf/2512.05593.pdf)

**ä½œè€…**: Rong Wang, Wei Mao, Changsheng Lu, Hongdong Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå…è’™çš®å›¾åƒè½¬ç§»æ–¹æ³•ä»¥ç”Ÿæˆé«˜ä¿çœŸ3Dæœè£…åŠ¨ç”»**

**å…³é”®è¯**: `3Dæœè£…åŠ¨ç”»` `å›¾åƒè½¬ç§»` `é«˜é¢‘ç»†èŠ‚æ¢å¤` `å…è’™çš®æ–¹æ³•` `è™šæ‹Ÿè¯•ç©¿`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰åŸºäºŽçº¿æ€§æ··åˆè’™çš®çš„æ–¹æ³•åœ¨æœè£…å˜å½¢æ—¶æ˜“äº§ç”Ÿå½¢çŠ¶é”™ä½ï¼Œå½±å“é«˜é¢‘çš±çº¹æ¢å¤ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç‹¬ç«‹ä¼°è®¡é¡¶ç‚¹ä½ç½®å’Œæ³•çº¿ä»¥è§£è€¦ä½Žé¢‘å½¢çŠ¶ä¸Žé«˜é¢‘ç»†èŠ‚ï¼Œé€šè¿‡å›¾åƒè½¬ç§»åˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹æå‡è§†è§‰è´¨é‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šç§æœè£…ç±»åž‹ä¸Šæ˜¾è‘—æå‡åŠ¨ç”»è´¨é‡ï¼Œæ¢å¤æ›´ç²¾ç»†çš±çº¹ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present a novel method for generating 3D garment deformations from given body poses, which is key to a wide range of applications, including virtual try-on and extended reality. To simplify the cloth dynamics, existing methods mostly rely on linear blend skinning to obtain low-frequency posed garment shape and only regress high-frequency wrinkles. However, due to the lack of explicit skinning supervision, such skinning-based approach often produces misaligned shapes when posing the garment, consequently corrupts the high-frequency signals and fails to recover high-fidelity wrinkles. To tackle this issue, we propose a skinning-free approach by independently estimating posed (i) vertex position for low-frequency posed garment shape, and (ii) vertex normal for high-frequency local wrinkle details. In this way, each frequency modality can be effectively decoupled and directly supervised by the geometry of the deformed garment. To further improve the visual quality of animation, we propose to encode both vertex attributes as rendered texture images, so that 3D garment deformation can be equivalently achieved via 2D image transfer. This enables us to leverage powerful pretrained image models to recover fine-grained visual details in wrinkles, while maintaining superior scalability for garments of diverse topologies without relying on manual UV partition. Finally, we propose a multimodal fusion to incorporate constraints from both frequency modalities and robustly recover deformed 3D garments from transferred images. Extensive experiments show that our method significantly improves animation quality on various garment types and recovers finer wrinkles than state-of-the-art methods.

