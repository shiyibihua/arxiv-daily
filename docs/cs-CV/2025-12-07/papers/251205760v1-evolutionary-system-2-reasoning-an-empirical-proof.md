---
layout: default
title: Evolutionary System 2 Reasoning: An Empirical Proof
---

# Evolutionary System 2 Reasoning: An Empirical Proof

**arXiv**: [2512.05760v1](https://arxiv.org/abs/2512.05760) | [PDF](https://arxiv.org/pdf/2512.05760.pdf)

**ä½œè€…**: Zeyuan Ma, Wenqi Huang, Guo-Huan Song, Hongshu Guo, Sijie Ma, Zhiguang Cao, Yue-Jiao Gong

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¿›åŒ–æŽ¨ç†ä¼˜åŒ–æ¡†æž¶ï¼Œé€šè¿‡è¿›åŒ–ç­–ç•¥å¢žå¼ºå¤§è¯­è¨€æ¨¡åž‹çš„ç³»ç»Ÿ2æŽ¨ç†èƒ½åŠ›ã€‚**

**å…³é”®è¯**: `è¿›åŒ–æŽ¨ç†ä¼˜åŒ–` `ç³»ç»Ÿ2æŽ¨ç†` `å¤§è¯­è¨€æ¨¡åž‹` `è¿›åŒ–ç­–ç•¥` `æŽ¨ç†èƒ½åŠ›å¢žå¼º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è¯­è¨€æ¨¡åž‹åœ¨é€šç”¨æ™ºèƒ½å’Œç³»ç»Ÿ2æŽ¨ç†æ–¹é¢ä»æœ‰é™ï¼Œèƒ½å¦è¿›åŒ–èŽ·å¾—ç±»ä¼¼äººç±»çš„æŽ¨ç†èƒ½åŠ›ï¼Ÿ
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨è¿›åŒ–ç­–ç•¥å¯¹LLMç§ç¾¤è¿›è¡Œé€‚è€…ç”Ÿå­˜ä¼˜åŒ–ï¼Œæœ€å¤§åŒ–æœ€ä½³ä¸ªä½“çš„é‡åŒ–æŽ¨ç†åˆ†æ•°ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒæ˜¾ç¤ºGPT-5æŽ¨ç†èƒ½åŠ›æœ‰é™ï¼Œä½†Qwen-7Bç»ç®€å•è¿›åŒ–å¾ªçŽ¯åŽå¯æ˜¾è‘—æå‡æŽ¨ç†èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Machine intelligence marks the ultimate dream of making machines' intelligence comparable to human beings. While recent progress in Large Language Models (LLMs) show substantial specific skills for a wide array of downstream tasks, they more or less fall shorts in general intelligence. Following correlation between intelligence and system 2 reasoning (slow thinking), in this paper, we aim to answering a worthwhile research question: could machine intelligence such as LLMs be evolved to acquire reasoning ability (not specific skill) just like our human beings? To this end, we propose evolutionary reasoning optimization (ERO) framework which performs survival of the fittest over a population of LLMs to search for individual with strong reasoning ability. Given a reasoning task, ERO first initializes multiple LLMs as a population, after which an evolutionary strategy evolves the population to maximize quantified reasoning score of the best individual. Based on experiments on representative testsuites, we claim two surprising empirical discoveries: i) the latest LLMs such as GPT-5 still show limited system 2 reasoning ability; ii) with simple evolution-loop of ERO, a relatively weak model (Qwen-7B) could be enhanced to emerge powerful reasoning ability. Our project can be accessed at https://github.com/MetaEvo/ERO for reproduction needs.

