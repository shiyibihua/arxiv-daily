---
layout: default
title: The Dynamic Prior: Understanding 3D Structures for Casual Dynamic Videos
---

# The Dynamic Prior: Understanding 3D Structures for Casual Dynamic Videos

**arXiv**: [2512.05398v1](https://arxiv.org/abs/2512.05398) | [PDF](https://arxiv.org/pdf/2512.05398.pdf)

**ä½œè€…**: Zhuoyuan Wu, Xurui Yang, Jiahui Huang, Yue Wang, Jun Gao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDynamic Priorä»¥åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡åž‹å’ŒSAM2æå‡åŠ¨æ€è§†é¢‘ä¸­çš„3Dç»“æž„ç†è§£**

**å…³é”®è¯**: `åŠ¨æ€è§†é¢‘ç†è§£` `3Dç»“æž„é‡å»º` `è§†è§‰è¯­è¨€æ¨¡åž‹` `è¿åŠ¨åˆ†å‰²` `ç›¸æœºå§¿æ€ä¼˜åŒ–` `æ·±åº¦ä¼°è®¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŠ¨æ€ç‰©ä½“å¹²æ‰°ä¼ ç»Ÿæ–¹æ³•å¯¹ç›¸æœºå§¿æ€å’Œ3Då‡ ä½•çš„ä¼°è®¡ï¼ŒçŽ°æœ‰å­¦ä¹ æ³•ä¾èµ–å¤§è§„æ¨¡æ•°æ®é›†å¯¼è‡´åˆ†å‰²ä¸å‡†ç¡®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆè§†è§‰è¯­è¨€æ¨¡åž‹çš„æŽ¨ç†èƒ½åŠ›å’ŒSAM2çš„ç²¾ç»†åˆ†å‰²ï¼Œæ— éœ€ä»»åŠ¡ç‰¹å®šè®­ç»ƒå³å¯è¯†åˆ«åŠ¨æ€ç‰©ä½“ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åˆæˆå’ŒçœŸå®žè§†é¢‘ä¸ŠéªŒè¯ï¼ŒåŠ¨æ€åˆ†å‰²æ€§èƒ½é¢†å…ˆï¼Œå¹¶æ˜¾è‘—æå‡3Dç»“æž„ç†è§£çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Estimating accurate camera poses, 3D scene geometry, and object motion from in-the-wild videos is a long-standing challenge for classical structure from motion pipelines due to the presence of dynamic objects. Recent learning-based methods attempt to overcome this challenge by training motion estimators to filter dynamic objects and focus on the static background. However, their performance is largely limited by the availability of large-scale motion segmentation datasets, resulting in inaccurate segmentation and, therefore, inferior structural 3D understanding. In this work, we introduce the Dynamic Prior (\ourmodel) to robustly identify dynamic objects without task-specific training, leveraging the powerful reasoning capabilities of Vision-Language Models (VLMs) and the fine-grained spatial segmentation capacity of SAM2. \ourmodel can be seamlessly integrated into state-of-the-art pipelines for camera pose optimization, depth reconstruction, and 4D trajectory estimation. Extensive experiments on both synthetic and real-world videos demonstrate that \ourmodel not only achieves state-of-the-art performance on motion segmentation, but also significantly improves accuracy and robustness for structural 3D understanding.

