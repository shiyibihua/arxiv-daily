---
layout: default
title: MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models
---

# MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models

**arXiv**: [2512.05530v1](https://arxiv.org/abs/2512.05530) | [PDF](https://arxiv.org/pdf/2512.05530.pdf)

**ä½œè€…**: Chuang Yu, Jinmiao Zhao, Mingxuan Zhao, Yunpeng Liu, Xiujun Shu, Yuanhao Feng, Bo Wang, Xiangyu Yue

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMINDæ¡†æž¶ä»¥è§£å†³å¤šæ¨¡æ€å¤§æ¨¡åž‹åœ¨å¤šç†æ€§æŽ¨ç†ä¸­çš„è¯­ä¹‰å»ºæ¨¡ä¸è¶³å’Œé€»è¾‘é²æ£’æ€§é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§æ¨¡åž‹` `å¤šç†æ€§æŽ¨ç†` `åˆ¤åˆ«æ€§æŽ¨ç†` `è¯­ä¹‰å¯¹é½` `æ•°æ®é›†æ‰©å±•` `é€»è¾‘æ ¡æ­£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€å¤§æ¨¡åž‹åœ¨å¤šç†æ€§è¯­ä¹‰å»ºæ¨¡æœ‰é™ã€é€»è¾‘é²æ£’æ€§ä¸è¶³ï¼Œæ˜“å—å¤æ‚åœºæ™¯è¯¯å¯¼ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥RADèŒƒå¼æ‰©å±•æ•°æ®é›†ï¼Œè®¾è®¡P2CLç­–ç•¥è¿›è¡Œä¸¤é˜¶æ®µæ ¡æ­£å­¦ä¹ ï¼Œé‡‡ç”¨MCAä¼˜åŒ–ç­–ç•¥å¯¹é½è¯­ä¹‰ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šå®žçŽ°SOTAæ€§èƒ½ï¼Œæ¶µç›–ç§‘å­¦ã€å¸¸è¯†å’Œæ•°å­¦åœºæ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recently, multimodal large language models (MLLMs) have been widely applied to reasoning tasks. However, they suffer from limited multi-rationale semantic modeling, insufficient logical robustness, and are susceptible to misleading interpretations in complex scenarios. Therefore, we propose a Multi-rationale INtegrated Discriminative (MIND) reasoning framework, which is designed to endow MLLMs with human-like cognitive abilities of "Understand -> Rethink -> Correct", and achieves a paradigm evolution from passive imitation-based reasoning to active discriminative reasoning. Specifically, we introduce a Rationale Augmentation and Discrimination (RAD) paradigm, which automatically and efficiently expands existing datasets by generating diverse rationales, providing a unified and extensible data foundation. Meanwhile, we design a Progressive Two-stage Correction Learning (P2CL) strategy. The first phase enhances multi-rationale positive learning, while the second phase enables active logic discrimination and correction. In addition, to mitigate representation entanglement in the multi-rationale semantic space, we propose a Multi-rationale Contrastive Alignment (MCA) optimization strategy, which achieves semantic aggregation of correct reasoning and boundary separation of incorrect reasoning. Extensive experiments demonstrate that the proposed MIND reasoning framework achieves state-of-the-art (SOTA) performance on multiple public datasets covering scientific, commonsense, and mathematical scenarios. It provides a new perspective for advancing MLLMs towards higher levels of cognitive intelligence. Our code is available at https://github.com/YuChuang1205/MIND

