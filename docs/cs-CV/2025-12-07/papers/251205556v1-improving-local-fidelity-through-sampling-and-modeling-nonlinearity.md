---
layout: default
title: Improving Local Fidelity Through Sampling and Modeling Nonlinearity
---

# Improving Local Fidelity Through Sampling and Modeling Nonlinearity

**arXiv**: [2512.05556v1](https://arxiv.org/abs/2512.05556) | [PDF](https://arxiv.org/pdf/2512.05556.pdf)

**ä½œè€…**: Sanjeev Shrestha, Rahul Dubey, Hui Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽMARSå’ŒN-ballé‡‡æ ·çš„æ–¹æ³•ï¼Œä»¥æå‡é»‘ç›’æ¨¡åž‹å±€éƒ¨è§£é‡Šçš„ä¿çœŸåº¦ã€‚**

**å…³é”®è¯**: `å±€éƒ¨å¯è§£é‡Šæ€§` `éžçº¿æ€§å»ºæ¨¡` `MARS` `N-ballé‡‡æ ·` `é»‘ç›’æ¨¡åž‹è§£é‡Š` `ä¿çœŸåº¦æå‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šLIMEå‡è®¾å±€éƒ¨å†³ç­–è¾¹ç•Œçº¿æ€§ï¼Œæ— æ³•æ•æ‰éžçº¿æ€§å…³ç³»ï¼Œå¯¼è‡´è§£é‡Šä¸å‡†ç¡®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨MARSå»ºæ¨¡éžçº¿æ€§å±€éƒ¨è¾¹ç•Œï¼Œç»“åˆN-ballé‡‡æ ·æŠ€æœ¯ç›´æŽ¥é‡‡æ ·ï¼Œæé«˜è§£é‡Šçš„å¿ å®žæ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä¸‰ä¸ªUCIæ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œç›¸æ¯”åŸºçº¿å¹³å‡é™ä½Ž37%çš„RMSEï¼Œæ˜¾è‘—æå‡å±€éƒ¨ä¿çœŸåº¦ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> With the increasing complexity of black-box machine learning models and their adoption in high-stakes areas, it is critical to provide explanations for their predictions. Local Interpretable Model-agnostic Explanation (LIME) is a widely used technique that explains the prediction of any classifier by learning an interpretable model locally around the predicted instance. However, it assumes that the local decision boundary is linear and fails to capture the non-linear relationships, leading to incorrect explanations. In this paper, we propose a novel method that can generate high-fidelity explanations. Multivariate adaptive regression splines (MARS) is used to model non-linear local boundaries that effectively captures the underlying behavior of the reference model, thereby enhancing the local fidelity of the explanation. Additionally, we utilize the N-ball sampling technique, which samples directly from the desired distribution instead of reweighting samples as done in LIME, further improving the faithfulness score. We evaluate our method on three UCI datasets across different classifiers and varying kernel widths. Experimental results show that our method yields more faithful explanations compared to baselines, achieving an average reduction of 37% in root mean square error, significantly improving local fidelity.

