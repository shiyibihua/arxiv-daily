---
layout: default
title: Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception
---

# Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception

**arXiv**: [2512.05937v1](https://arxiv.org/abs/2512.05937) | [PDF](https://arxiv.org/pdf/2512.05937.pdf)

**ä½œè€…**: Anne Sielemann, Valentin Barner, Stefan Wolf, Masoud Roschani, Jens Ziehn, Juergen Beyerer

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆæˆæ•°æ®é›†æ–¹æ³•ä»¥é‡åŒ–èƒŒæ™¯ç›¸å…³æ€§å¯¹è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ä¸­æ·±åº¦å­¦ä¹ åˆ†ç±»ä¸ç‰¹å¾é‡è¦æ€§çš„å½±å“**

**å…³é”®è¯**: `å¯è§£é‡ŠAI` `åˆæˆæ•°æ®é›†` `èƒŒæ™¯ç›¸å…³æ€§` `ç‰¹å¾é‡è¦æ€§` `äº¤é€šæ ‡å¿—è¯†åˆ«` `æ·±åº¦å­¦ä¹ åˆ†ç±»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰å¯è§£é‡ŠAIæ–¹æ³•éš¾ä»¥å®šé‡æµ‹è¯•èƒŒæ™¯åƒç´ å¯¹åˆ†ç±»ç»“æœçš„å½±å“ï¼Œå¯¼è‡´è§£é‡Šæœ¬èº«ç¼ºä¹è§£é‡Šæ€§
2. æ–¹æ³•è¦ç‚¹ï¼šç³»ç»Ÿç”Ÿæˆå…­ä¸ªåˆæˆæ•°æ®é›†ï¼Œä»…æ”¹å˜ç›¸æœºå˜åŒ–å’ŒèƒŒæ™¯ç›¸å…³æ€§ï¼Œä»¥éš”ç¦»èƒŒæ™¯å½±å“
3. å®éªŒæˆ–æ•ˆæœï¼šé‡åŒ–èƒŒæ™¯ç‰¹å¾é‡è¦æ€§å˜åŒ–ï¼Œæ­ç¤ºè®­ç»ƒåŸŸå˜åŒ–å¦‚ä½•å½±å“åˆ†ç±»æ€§èƒ½

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Common approaches to explainable AI (XAI) for deep learning focus on analyzing the importance of input features on the classification task in a given model: saliency methods like SHAP and GradCAM are used to measure the impact of spatial regions of the input image on the classification result. Combined with ground truth information about the location of the object in the input image (e.g., a binary mask), it is determined whether object pixels had a high impact on the classification result, or whether the classification focused on background pixels. The former is considered to be a sign of a healthy classifier, whereas the latter is assumed to suggest overfitting on spurious correlations. A major challenge, however, is that these intuitive interpretations are difficult to test quantitatively, and hence the output of such explanations lacks an explanation itself. One particular reason is that correlations in real-world data are difficult to avoid, and whether they are spurious or legitimate is debatable. Synthetic data in turn can facilitate to actively enable or disable correlations where desired but often lack a sufficient quantification of realism and stochastic properties. [...] Therefore, we systematically generate six synthetic datasets for the task of traffic sign recognition, which differ only in their degree of camera variation and background correlation [...] to quantify the isolated influence of background correlation, different levels of camera variation, and considered traffic sign shapes on the classification performance, as well as background feature importance. [...] Results include a quantification of when and how much background features gain importance to support the classification task based on changes in the training domain [...].
>   Download: synset.de/datasets/synset-signset-ger/background-effect

