---
layout: default
title: Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling
---

# Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling

**arXiv**: [2512.05809v1](https://arxiv.org/abs/2512.05809) | [PDF](https://arxiv.org/pdf/2512.05809.pdf)

**ä½œè€…**: Saurav Jha, M. Jehanzeb Mirza, Wei Lin, Shiqi Yang, Sarath Chandar

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºViSAæ¡†æž¶ä»¥æ”¹è¿›ä¸–ç•Œæ¨¡åž‹åœ¨ç©ºé—´æŽ¨ç†ä¸­çš„æµ‹è¯•æ—¶éªŒè¯æ•ˆæžœ**

**å…³é”®è¯**: `ç©ºé—´æŽ¨ç†` `æµ‹è¯•æ—¶ç¼©æ”¾` `ä¸–ç•Œæ¨¡åž‹` `è§†è§‰è¯­è¨€æ¨¡åž‹` `éªŒè¯æ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§‰è¯­è¨€æ¨¡åž‹åœ¨éœ€è¦å¤šè§†è§’ç†è§£çš„ç©ºé—´æŽ¨ç†ä»»åŠ¡ä¸­è¡¨çŽ°æœ‰é™ï¼ŒçŽ°æœ‰æµ‹è¯•æ—¶éªŒè¯æ–¹æ³•å­˜åœ¨æ ¡å‡†ä¸è¶³å’Œåå·®é—®é¢˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥åŸºäºŽç©ºé—´æ–­è¨€çš„éªŒè¯æ¡†æž¶ï¼Œé€šè¿‡å¯éªŒè¯çš„å¸§é”šå®šå¾®å£°æ˜Žæ¥æ”¹è¿›å¥–åŠ±ä¿¡å·ï¼Œå‡å°‘è½¨è¿¹é€‰æ‹©åå·®ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨SAT-RealåŸºå‡†ä¸Šæå‡ç©ºé—´æŽ¨ç†æ€§èƒ½ï¼Œä½†åœ¨MMSI-Benchä¸Šæœªå®žçŽ°ä¸€è‡´æ”¹è¿›ï¼Œæ­ç¤ºä¸–ç•Œæ¨¡åž‹çš„ä¿¡æ¯ç“¶é¢ˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language Models (VLMs) remain limited in spatial reasoning tasks that require multi-view understanding and embodied perspective shifts. Recent approaches such as MindJourney attempt to mitigate this gap through test-time scaling where a world model imagines action-conditioned trajectories and a heuristic verifier selects helpful views from such trajectories. In this work, we systematically examine how such test-time verifiers behave across benchmarks, uncovering both their promise and their pitfalls. Our uncertainty-based analyses show that MindJourney's verifier provides little meaningful calibration, and that random scoring often reduces answer entropy equally well, thus exposing systematic action biases and unreliable reward signals. To mitigate these, we introduce a Verification through Spatial Assertions (ViSA) framework that grounds the test-time reward in verifiable, frame-anchored micro-claims. This principled verifier consistently improves spatial reasoning on the SAT-Real benchmark and corrects trajectory-selection biases through more balanced exploratory behavior. However, on the challenging MMSI-Bench, none of the verifiers, including ours, achieve consistent scaling, suggesting that the current world models form an information bottleneck where imagined views fail to enrich fine-grained reasoning. Together, these findings chart the bad, good, and ugly aspects of test-time verification for world-model-based reasoning. Our code is available at https://github.com/chandar-lab/visa-for-mindjourney.

