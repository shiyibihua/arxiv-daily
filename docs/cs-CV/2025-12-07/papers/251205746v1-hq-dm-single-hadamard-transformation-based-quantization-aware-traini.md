---
layout: default
title: HQ-DM: Single Hadamard Transformation-Based Quantization-Aware Training for Low-Bit Diffusion Models
---

# HQ-DM: Single Hadamard Transformation-Based Quantization-Aware Training for Low-Bit Diffusion Models

**arXiv**: [2512.05746v1](https://arxiv.org/abs/2512.05746) | [PDF](https://arxiv.org/pdf/2512.05746.pdf)

**ä½œè€…**: Shizhuo Mao, Hongtao Zou, Qihu Xie, Song Chen, Yi Kang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHQ-DMæ¡†æž¶ï¼Œé€šè¿‡å•å“ˆè¾¾çŽ›å˜æ¢è§£å†³ä½Žæ¯”ç‰¹æ‰©æ•£æ¨¡åž‹é‡åŒ–ä¸­çš„æ¿€æ´»å¼‚å¸¸å€¼é—®é¢˜**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹` `é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ` `ä½Žæ¯”ç‰¹é‡åŒ–` `å“ˆè¾¾çŽ›å˜æ¢` `å›¾åƒç”Ÿæˆ` `æ¨¡åž‹åŽ‹ç¼©`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ‰©æ•£æ¨¡åž‹é‡åŒ–æ–¹æ³•åœ¨ä½Žæ¯”ç‰¹åœºæ™¯ä¸‹å› æ¿€æ´»çŸ©é˜µå¼‚å¸¸å€¼å¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å•å“ˆè¾¾çŽ›å˜æ¢å¤„ç†æ¿€æ´»çŸ©é˜µï¼Œå‡å°‘å¼‚å¸¸å€¼åŒæ—¶æ”¯æŒINTå·ç§¯å¹¶é˜²æ­¢æƒé‡å¼‚å¸¸å€¼æ”¾å¤§
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ImageNet 256x256æ•°æ®é›†ä¸Šï¼ŒW4A4å’ŒW4A4é‡åŒ–æ–¹æ¡ˆç›¸æ¯”çŽ°æœ‰æ–¹æ³•æå‡Inception Scoreè¾¾12.8%å’Œ467.73%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Diffusion models have demonstrated significant applications in the field of image generation. However, their high computational and memory costs pose challenges for deployment. Model quantization has emerged as a promising solution to reduce storage overhead and accelerate inference. Nevertheless, existing quantization methods for diffusion models struggle to mitigate outliers in activation matrices during inference, leading to substantial performance degradation under low-bit quantization scenarios. To address this, we propose HQ-DM, a novel Quantization-Aware Training framework that applies Single Hadamard Transformation to activation matrices. This approach effectively reduces activation outliers while preserving model performance under quantization. Compared to traditional Double Hadamard Transformation, our proposed scheme offers distinct advantages by seamlessly supporting INT convolution operations while preventing the amplification of weight outliers. For conditional generation on the ImageNet 256x256 dataset using the LDM-4 model, our W4A4 and W4A3 quantization schemes improve the Inception Score by 12.8% and 467.73%, respectively, over the existing state-of-the-art method.

