---
layout: default
title: ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering
---

# ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering

**arXiv**: [2512.05430v1](https://arxiv.org/abs/2512.05430) | [PDF](https://arxiv.org/pdf/2512.05430.pdf)

**ä½œè€…**: Daeyong Kwon, SeungHeon Doh, Juhan Nam

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºArtistMusåŸºå‡†å’ŒMusWikiDBæ•°æ®åº“ï¼Œä»¥è§£å†³éŸ³ä¹é—®ç­”ä¸­æ£€ç´¢å¢žå¼ºç”Ÿæˆè¯„ä¼°ä¸è¶³çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `éŸ³ä¹é—®ç­”` `æ£€ç´¢å¢žå¼ºç”Ÿæˆ` `è‰ºæœ¯å®¶å…ƒæ•°æ®` `å‘é‡æ•°æ®åº“` `åŸºå‡†è¯„ä¼°` `éŸ³ä¹ä¿¡æ¯æ£€ç´¢`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è¯­è¨€æ¨¡åž‹åœ¨éŸ³ä¹æŽ¨ç†ä¸­å› é¢„è®­ç»ƒæ•°æ®ç¨€ç–è€Œå—é™ï¼Œç¼ºä¹åŸºäºŽè‰ºæœ¯å®¶å…ƒæ•°æ®çš„é—®ç­”èµ„æºã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºåŒ…å«144Kç»´åŸºé¡µé¢çš„MusWikiDBå‘é‡æ•°æ®åº“å’Œ500ä½è‰ºæœ¯å®¶çš„ArtistMusåŸºå‡†ï¼Œæ”¯æŒæ£€ç´¢å¢žå¼ºç”Ÿæˆè¯„ä¼°ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ£€ç´¢å¢žå¼ºç”Ÿæˆæ˜¾è‘—æå‡äº‹å®žå‡†ç¡®æ€§ï¼Œå¼€æºæ¨¡åž‹æ”¹è¿›è¾¾+56.8ä¸ªç™¾åˆ†ç‚¹ï¼Œå¹¶ä¼˜äºŽé€šç”¨ç»´åŸºè¯­æ–™åº“ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in large language models (LLMs) have transformed open-domain question answering, yet their effectiveness in music-related reasoning remains limited due to sparse music knowledge in pretraining data. While music information retrieval and computational musicology have explored structured and multimodal understanding, few resources support factual and contextual music question answering (MQA) grounded in artist metadata or historical context. We introduce MusWikiDB, a vector database of 3.2M passages from 144K music-related Wikipedia pages, and ArtistMus, a benchmark of 1,000 questions on 500 diverse artists with metadata such as genre, debut year, and topic. These resources enable systematic evaluation of retrieval-augmented generation (RAG) for MQA. Experiments show that RAG markedly improves factual accuracy; open-source models gain up to +56.8 percentage points (for example, Qwen3 8B improves from 35.0 to 91.8), approaching proprietary model performance. RAG-style fine-tuning further boosts both factual recall and contextual reasoning, improving results on both in-domain and out-of-domain benchmarks. MusWikiDB also yields approximately 6 percentage points higher accuracy and 40% faster retrieval than a general-purpose Wikipedia corpus. We release MusWikiDB and ArtistMus to advance research in music information retrieval and domain-specific question answering, establishing a foundation for retrieval-augmented reasoning in culturally rich domains such as music.

