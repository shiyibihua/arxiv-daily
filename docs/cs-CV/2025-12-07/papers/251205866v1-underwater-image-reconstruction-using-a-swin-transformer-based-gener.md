---
layout: default
title: Underwater Image Reconstruction Using a Swin Transformer-Based Generator and PatchGAN Discriminator
---

# Underwater Image Reconstruction Using a Swin Transformer-Based Generator and PatchGAN Discriminator

**arXiv**: [2512.05866v1](https://arxiv.org/abs/2512.05866) | [PDF](https://arxiv.org/pdf/2512.05866.pdf)

**ä½œè€…**: Md. Mahbub Hasan Akash, Aria Tasnim Mridula, Sheekar Banerjee, Ishtiak Al Mamoon

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽSwin Transformerç”Ÿæˆå™¨å’ŒPatchGANåˆ¤åˆ«å™¨çš„GANæ¡†æž¶ä»¥è§£å†³æ°´ä¸‹å›¾åƒé‡å»ºé—®é¢˜**

**å…³é”®è¯**: `æ°´ä¸‹å›¾åƒé‡å»º` `Swin Transformer` `ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ` `PatchGANåˆ¤åˆ«å™¨` `å…¨å±€ä¾èµ–å»ºæ¨¡` `é¢œè‰²æ ¡æ­£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ°´ä¸‹æˆåƒå› æ³¢é•¿ä¾èµ–å¸æ”¶å’Œæ•£å°„å¯¼è‡´é¢œè‰²å¤±çœŸã€ä½Žå¯¹æ¯”åº¦å’Œé›¾éœ¾æ•ˆåº”ï¼Œä¼ ç»Ÿæ–¹æ³•å—é™äºŽå±€éƒ¨æ„Ÿå—é‡Žå’Œå…¨å±€ä¾èµ–å»ºæ¨¡ä¸è¶³
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨U-Netç»“æž„é›†æˆSwin Transformerå—ä½œä¸ºç”Ÿæˆå™¨ï¼Œæ•èŽ·å±€éƒ¨ç‰¹å¾å’Œé•¿ç¨‹ä¾èµ–ï¼Œç»“åˆPatchGANåˆ¤åˆ«å™¨è¿›è¡Œå¯¹æŠ—è®­ç»ƒä»¥ä¿ç•™é«˜é¢‘ç»†èŠ‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨EUVPæ•°æ®é›†ä¸Šè¯„ä¼°ï¼ŒPSNRè¾¾24.76 dBã€SSIMè¾¾0.89ï¼Œè§†è§‰ç»“æžœæœ‰æ•ˆæ¢å¤é¢œè‰²å¹³è¡¡ã€æå‡å¯¹æ¯”åº¦å’Œå‡å°‘é›¾éœ¾

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Underwater imaging is essential for marine exploration, environmental monitoring, and infrastructure inspection. However, water causes severe image degradation through wavelength-dependent absorption and scattering, resulting in color distortion, low contrast, and haze effects. Traditional reconstruction methods and convolutional neural network-based approaches often fail to adequately address these challenges due to limited receptive fields and inability to model global dependencies. This paper presented a novel deep learning framework that integrated a Swin Transformer architecture within a generative adversarial network (GAN) for underwater image reconstruction. Our generator employed a U-Net structure with Swin Transformer blocks to capture both local features and long-range dependencies crucial for color correction across entire images. A PatchGAN discriminator provided adversarial training to ensure high-frequency detail preservation. We trained and evaluated our model on the EUVP dataset, which contains paired underwater images of varying quality. Quantitative results demonstrate stateof-the-art performance with PSNR of 24.76 dB and SSIM of 0.89, representing significant improvements over existing methods. Visual results showed effective color balance restoration, contrast improvement, and haze reduction. An ablation study confirms the superiority of our Swin Transformer designed over convolutional alternatives. The proposed method offers robust underwater image reconstruction suitable for various marine applications.

