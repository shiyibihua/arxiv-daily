---
layout: default
title: Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models
---

# Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models

**arXiv**: [2512.05658v1](https://arxiv.org/abs/2512.05658) | [PDF](https://arxiv.org/pdf/2512.05658.pdf)

**ä½œè€…**: Pietro Ferrazzi, Aitor Soroa, Rodrigo Agerri

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæ£€ç´¢å¢žå¼ºç”Ÿæˆçš„å¤šè¯­è¨€åŒ»ç–—æŽ¨ç†è½¨è¿¹æ–¹æ³•ï¼Œä»¥æå‡å¤§åž‹è¯­è¨€æ¨¡åž‹åœ¨åŒ»ç–—é—®ç­”ä¸­çš„å¯é æ€§å’Œæ€§èƒ½ã€‚**

**å…³é”®è¯**: `åŒ»ç–—é—®ç­”` `å¤šè¯­è¨€æŽ¨ç†` `æ£€ç´¢å¢žå¼ºç”Ÿæˆ` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `ç›‘ç£å¾®è°ƒ` `ä¸Šä¸‹æ–‡å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰åŒ»ç–—é—®ç­”æ–¹æ³•å¤šèšç„¦è‹±è¯­ï¼Œä¾èµ–é€šç”¨å¤§åž‹è¯­è¨€æ¨¡åž‹è’¸é¦ï¼ŒåŒ»ç–—çŸ¥è¯†å¯é æ€§å­˜ç–‘ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ£€ç´¢å¢žå¼ºç”ŸæˆæŠ€æœ¯ï¼ŒåŸºäºŽç»´åŸºç™¾ç§‘åŒ»ç–—ä¿¡æ¯ï¼Œç”Ÿæˆè‹±è¯­ã€æ„å¤§åˆ©è¯­å’Œè¥¿ç­ç‰™è¯­çš„æŽ¨ç†è½¨è¿¹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŒ»ç–—é—®ç­”åŸºå‡†æµ‹è¯•ä¸­ï¼Œé€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ å’Œç›‘ç£å¾®è°ƒï¼ŒæŽ¨ç†è½¨è¿¹æå‡äº†æ€§èƒ½ï¼Œåœ¨8Bå‚æ•°æ¨¡åž‹ä¸­è¾¾åˆ°å…ˆè¿›æ°´å¹³ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Language Models (LLMs) with reasoning capabilities have recently demonstrated strong potential in medical Question Answering (QA). Existing approaches are largely English-focused and primarily rely on distillation from general-purpose LLMs, raising concerns about the reliability of their medical knowledge. In this work, we present a method to generate multilingual reasoning traces grounded in factual medical knowledge. We produce 500k traces in English, Italian, and Spanish, using a retrievalaugmented generation approach over medical information from Wikipedia. The traces are generated to solve medical questions drawn from MedQA and MedMCQA, which we extend to Italian and Spanish. We test our pipeline in both in-domain and outof-domain settings across Medical QA benchmarks, and demonstrate that our reasoning traces improve performance both when utilized via in-context learning (few-shot) and supervised fine-tuning, yielding state-of-the-art results among 8B-parameter LLMs. We believe that these resources can support the development of safer, more transparent clinical decision-support tools in multilingual settings. We release the full suite of resources: reasoning traces, translated QA datasets, Medical-Wikipedia, and fine-tuned models.

