---
layout: default
title: Ontology Learning with LLMs: A Benchmark Study on Axiom Identification
---

# Ontology Learning with LLMs: A Benchmark Study on Axiom Identification

**arXiv**: [2512.05594v1](https://arxiv.org/abs/2512.05594) | [PDF](https://arxiv.org/pdf/2512.05594.pdf)

**ä½œè€…**: Roos M. Bakker, Daan L. Di Scala, Maaike H. T. de Boer, Stephan A. Raaijmakers

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOntoAxiomåŸºå‡†ä»¥è¯„ä¼°LLMsåœ¨å…¬ç†è¯†åˆ«ä¸­çš„æ€§èƒ½ï¼Œæ”¯æŒæœ¬ä½“å·¥ç¨‹è‡ªåŠ¨åŒ–ã€‚**

**å…³é”®è¯**: `æœ¬ä½“å­¦ä¹ ` `å…¬ç†è¯†åˆ«` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `åŸºå‡†æµ‹è¯•` `æç¤ºç­–ç•¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‡ªåŠ¨åŒ–æœ¬ä½“å­¦ä¹ ä¸­çš„å…¬ç†è¯†åˆ«ï¼Œå³å®šä¹‰ç±»ä¸Žå±žæ€§é—´é€»è¾‘å…³ç³»çš„åŸºç¡€ç»„ä»¶ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥OntoAxiomåŸºå‡†ï¼ŒåŒ…å«9ä¸ªæœ¬ä½“å’Œ2771ä¸ªå…¬ç†ï¼Œæµ‹è¯•12ä¸ªLLMsçš„ä¸¤ç§æç¤ºç­–ç•¥ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šAxiom-by-Axiomæç¤ºç­–ç•¥ä¼˜äºŽç›´æŽ¥æ–¹æ³•ï¼Œä½†æ€§èƒ½å› å…¬ç†ç±»åž‹å’Œæœ¬ä½“è€Œå¼‚ï¼ŒLLMså¯æä¾›å€™é€‰å…¬ç†è¾…åŠ©å·¥ç¨‹å¸ˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Ontologies are an important tool for structuring domain knowledge, but their development is a complex task that requires significant modelling and domain expertise. Ontology learning, aimed at automating this process, has seen advancements in the past decade with the improvement of Natural Language Processing techniques, and especially with the recent growth of Large Language Models (LLMs). This paper investigates the challenge of identifying axioms: fundamental ontology components that define logical relations between classes and properties. In this work, we introduce an Ontology Axiom Benchmark OntoAxiom, and systematically test LLMs on that benchmark for axiom identification, evaluating different prompting strategies, ontologies, and axiom types. The benchmark consists of nine medium-sized ontologies with together 17.118 triples, and 2.771 axioms. We focus on subclass, disjoint, subproperty, domain, and range axioms. To evaluate LLM performance, we compare twelve LLMs with three shot settings and two prompting strategies: a Direct approach where we query all axioms at once, versus an Axiom-by-Axiom (AbA) approach, where each prompt queries for one axiom only. Our findings show that the AbA prompting leads to higher F1 scores than the direct approach. However, performance varies across axioms, suggesting that certain axioms are more challenging to identify. The domain also influences performance: the FOAF ontology achieves a score of 0.642 for the subclass axiom, while the music ontology reaches only 0.218. Larger LLMs outperform smaller ones, but smaller models may still be viable for resource-constrained settings. Although performance overall is not high enough to fully automate axiom identification, LLMs can provide valuable candidate axioms to support ontology engineers with the development and refinement of ontologies.

