---
layout: default
title: VRSA: Jailbreaking Multimodal Large Language Models through Visual Reasoning Sequential Attack
---

# VRSA: Jailbreaking Multimodal Large Language Models through Visual Reasoning Sequential Attack

**arXiv**: [2512.05853v1](https://arxiv.org/abs/2512.05853) | [PDF](https://arxiv.org/pdf/2512.05853.pdf)

**ä½œè€…**: Shiji Zhao, Shukun Xiong, Yao Huang, Yan Jin, Zhenyu Wu, Jiyang Guan, Ranjie Duan, Jialing Tao, Hui Xue, Xingxing Wei

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§†è§‰æŽ¨ç†åºåˆ—æ”»å‡»ä»¥è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹åœ¨è§†è§‰æ¨¡æ€ä¸­çš„å®‰å…¨é£Žé™©**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `è§†è§‰æŽ¨ç†æ”»å‡»` `è¶Šç‹±æ”»å‡»` `å®‰å…¨è¯„ä¼°` `åºåˆ—å›¾åƒç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹åœ¨è§†è§‰æ¨¡æ€ä¸­çš„æŽ¨ç†å®‰å…¨é£Žé™©è¢«å¿½è§†ï¼Œæ˜“è¢«ç”¨äºŽè¶Šç‹±æ”»å‡»ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡åˆ†è§£æœ‰å®³æ–‡æœ¬ä¸ºåºåˆ—ç›¸å…³å­å›¾åƒï¼Œç»“åˆè‡ªé€‚åº”åœºæ™¯ä¼˜åŒ–å’Œè¯­ä¹‰è¿žè´¯è¡¥å…¨ï¼Œè¯±å¯¼æ¨¡åž‹è¾“å‡ºæœ‰å®³å†…å®¹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¼€æºå’Œé—­æºæ¨¡åž‹ä¸Šå®žçŽ°è¾ƒé«˜æ”»å‡»æˆåŠŸçŽ‡ï¼Œä¼˜äºŽçŽ°æœ‰è¶Šç‹±æ”»å‡»æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) are widely used in various fields due to their powerful cross-modal comprehension and generation capabilities. However, more modalities bring more vulnerabilities to being utilized for jailbreak attacks, which induces MLLMs to output harmful content. Due to the strong reasoning ability of MLLMs, previous jailbreak attacks try to explore reasoning safety risk in text modal, while similar threats have been largely overlooked in the visual modal. To fully evaluate potential safety risks in the visual reasoning task, we propose Visual Reasoning Sequential Attack (VRSA), which induces MLLMs to gradually externalize and aggregate complete harmful intent by decomposing the original harmful text into several sequentially related sub-images. In particular, to enhance the rationality of the scene in the image sequence, we propose Adaptive Scene Refinement to optimize the scene most relevant to the original harmful query. To ensure the semantic continuity of the generated image, we propose Semantic Coherent Completion to iteratively rewrite each sub-text combined with contextual information in this scene. In addition, we propose Text-Image Consistency Alignment to keep the semantical consistency. A series of experiments demonstrates that the VRSA can achieve a higher attack success rate compared with the state-of-the-art jailbreak attack methods on both the open-source and closed-source MLLMs such as GPT-4o and Claude-4.5-Sonnet.

