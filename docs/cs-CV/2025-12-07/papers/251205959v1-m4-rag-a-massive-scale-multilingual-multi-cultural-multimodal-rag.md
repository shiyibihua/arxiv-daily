---
layout: default
title: M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG
---

# M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG

**arXiv**: [2512.05959v1](https://arxiv.org/abs/2512.05959) | [PDF](https://arxiv.org/pdf/2512.05959.pdf)

**ä½œè€…**: David Anugraha, Patrick Amadeus Irawan, Anshul Singh, En-Shiun Annie Lee, Genta Indra Winata

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºM4-RAGåŸºå‡†ä»¥è¯„ä¼°å¤šè¯­è¨€å¤šæ¨¡æ€æ£€ç´¢å¢žå¼ºç”Ÿæˆåœ¨è§†è§‰é—®ç­”ä¸­çš„æ€§èƒ½**

**å…³é”®è¯**: `å¤šè¯­è¨€å¤šæ¨¡æ€æ£€ç´¢å¢žå¼ºç”Ÿæˆ` `è§†è§‰é—®ç­”åŸºå‡†` `æ–‡åŒ–å¤šæ ·æ€§è¯„ä¼°` `å—æŽ§æ£€ç´¢çŽ¯å¢ƒ` `æ¨¡åž‹è§„æ¨¡ä¸Žæ€§èƒ½åˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šè¯­è¨€å¤šæ¨¡æ€æ£€ç´¢å¢žå¼ºç”Ÿæˆåœ¨è§†è§‰é—®ç­”ä¸­ç ”ç©¶ä¸è¶³ï¼ŒçŽ°æœ‰æ¨¡åž‹å—é™äºŽé™æ€æ•°æ®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºå¤§è§„æ¨¡åŸºå‡†ï¼Œè¦†ç›–42ç§è¯­è¨€å’Œ56ç§æ–¹è¨€ï¼ŒåŒ…å«8ä¸‡å¯¹æ–‡åŒ–å¤šæ ·å›¾åƒ-é—®é¢˜ï¼Œå¹¶å»ºç«‹å—æŽ§æ£€ç´¢çŽ¯å¢ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç³»ç»Ÿè¯„ä¼°æ˜¾ç¤ºæ£€ç´¢å¢žå¼ºå¯¹å°æ¨¡åž‹æœ‰ç›Šï¼Œä½†å¯¹å¤§æ¨¡åž‹æ€§èƒ½å¯èƒ½ä¸‹é™ï¼Œæ­ç¤ºæ¨¡åž‹è§„æ¨¡ä¸Žæ£€ç´¢æ•ˆæžœä¸åŒ¹é…ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.

