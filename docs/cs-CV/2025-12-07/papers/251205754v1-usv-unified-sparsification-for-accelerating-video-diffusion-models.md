---
layout: default
title: USV: Unified Sparsification for Accelerating Video Diffusion Models
---

# USV: Unified Sparsification for Accelerating Video Diffusion Models

**arXiv**: [2512.05754v1](https://arxiv.org/abs/2512.05754) | [PDF](https://arxiv.org/pdf/2512.05754.pdf)

**ä½œè€…**: Xinjian Wu, Hongmei Wang, Yuan Zhou, Qinglin Lu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUSVæ¡†æž¶ï¼Œé€šè¿‡ç»Ÿä¸€ç¨€ç–åŒ–åŠ é€Ÿè§†é¢‘æ‰©æ•£æ¨¡åž‹ï¼Œè§£å†³å†—ä½™è®¡ç®—ç“¶é¢ˆé—®é¢˜ã€‚**

**å…³é”®è¯**: `è§†é¢‘æ‰©æ•£æ¨¡åž‹` `ç¨€ç–åŒ–åŠ é€Ÿ` `åŠ¨æ€ç­–ç•¥` `è”åˆä¼˜åŒ–` `è®¡ç®—å†—ä½™` `åŽ»å™ªåŠ é€Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†é¢‘æ‰©æ•£æ¨¡åž‹é¢ä¸´å…¨å±€æ—¶ç©ºæ³¨æ„åŠ›äºŒæ¬¡å¤æ‚åº¦å’Œé•¿è¿­ä»£åŽ»å™ªè½¨è¿¹çš„è®¡ç®—å†—ä½™ã€‚
2. USVè”åˆä¼˜åŒ–æ¨¡åž‹å†…éƒ¨è®¡ç®—å’Œé‡‡æ ·è¿‡ç¨‹ï¼Œå­¦ä¹ åŠ¨æ€ç¨€ç–åŒ–ç­–ç•¥ï¼ŒåŒ…æ‹¬å‰ªæžæ³¨æ„åŠ›è¿žæŽ¥ã€åˆå¹¶ç›¸ä¼¼ä»¤ç‰Œå’Œå‡å°‘åŽ»å™ªæ­¥æ•°ã€‚
3. å®žéªŒæ˜¾ç¤ºUSVåœ¨åŽ»å™ªè¿‡ç¨‹åŠ é€Ÿè¾¾83.3%ï¼Œç«¯åˆ°ç«¯åŠ é€Ÿ22.7%ï¼ŒåŒæ—¶ä¿æŒé«˜è§†è§‰ä¿çœŸåº¦ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The scalability of high-fidelity video diffusion models (VDMs) is constrained by two key sources of redundancy: the quadratic complexity of global spatio-temporal attention and the computational overhead of long iterative denoising trajectories. Existing accelerators -- such as sparse attention and step-distilled samplers -- typically target a single dimension in isolation and quickly encounter diminishing returns, as the remaining bottlenecks become dominant. In this work, we introduce USV (Unified Sparsification for Video diffusion models), an end-to-end trainable framework that overcomes this limitation by jointly orchestrating sparsification across both the model's internal computation and its sampling process. USV learns a dynamic, data- and timestep-dependent sparsification policy that prunes redundant attention connections, adaptively merges semantically similar tokens, and reduces denoising steps, treating them not as independent tricks but as coordinated actions within a single optimization objective. This multi-dimensional co-design enables strong mutual reinforcement among previously disjoint acceleration strategies. Extensive experiments on large-scale video generation benchmarks demonstrate that USV achieves up to 83.3% speedup in the denoising process and 22.7% end-to-end acceleration, while maintaining high visual fidelity. Our results highlight unified, dynamic sparsification as a practical path toward efficient, high-quality video generation.

