---
layout: default
title: MoEGCL: Mixture of Ego-Graphs Contrastive Representation Learning for Multi-View Clustering
---

# MoEGCL: Mixture of Ego-Graphs Contrastive Representation Learning for Multi-View Clustering

**arXiv**: [2511.05876v3](https://arxiv.org/abs/2511.05876) | [PDF](https://arxiv.org/pdf/2511.05876.pdf)

**ä½œè€…**: Jian Zhu, Xin Zou, Jun Sun, Cheng Luo, Lei Liu, Lingfang Zeng, Ning Zhang, Bian Wu, Chang Tang, Lirong Dai

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-08 (æ›´æ–°: 2025-11-29)

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/HackerHyper/MoEGCL)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMoEGCLï¼Œé€šè¿‡æ··åˆè‡ª Ego å›¾å¯¹æ¯”å­¦ä¹ æå‡å¤šè§†å›¾èšç±»æ€§èƒ½**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šè§†å›¾èšç±»` `å›¾ç¥žç»ç½‘ç»œ` `å¯¹æ¯”å­¦ä¹ ` `è‡ª Ego å›¾` `æ··åˆä¸“å®¶ç½‘ç»œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨å¤šè§†å›¾èšç±»ä¸­é‡‡ç”¨ç²—ç²’åº¦çš„å›¾èžåˆç­–ç•¥ï¼Œå¿½ç•¥äº†æ ·æœ¬çº§åˆ«çš„ç»†ç²’åº¦ä¿¡æ¯ã€‚
2. MoEGCL æå‡ºæ··åˆè‡ª Ego å›¾èžåˆï¼ˆMoEGFï¼‰å’Œ Ego å›¾å¯¹æ¯”å­¦ä¹ ï¼ˆEGCLï¼‰ï¼Œå®žçŽ°æ ·æœ¬çº§åˆ«çš„ç»†ç²’åº¦å›¾èžåˆå’Œè¡¨ç¤ºå¯¹é½ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒMoEGCL åœ¨æ·±åº¦å¤šè§†å›¾èšç±»ä»»åŠ¡ä¸­å–å¾—äº† state-of-the-art çš„æ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå›¾ç¥žç»ç½‘ç»œï¼ˆGNNsï¼‰çš„è¿›æ­¥æ˜¾è‘—æŽ¨åŠ¨äº†å¤šè§†å›¾èšç±»ï¼ˆMVCï¼‰çš„å‘å±•ã€‚ç„¶è€Œï¼ŒçŽ°æœ‰æ–¹æ³•é¢ä¸´ç²—ç²’åº¦å›¾èžåˆçš„é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œå½“å‰çš„æ–¹æ³•é€šå¸¸ä¸ºæ¯ä¸ªè§†å›¾ç”Ÿæˆä¸€ä¸ªå•ç‹¬çš„å›¾ç»“æž„ï¼Œç„¶åŽåœ¨è§†å›¾çº§åˆ«æ‰§è¡Œå›¾ç»“æž„çš„åŠ æƒèžåˆï¼Œè¿™æ˜¯ä¸€ç§ç›¸å¯¹ç²—ç•¥çš„ç­–ç•¥ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆè‡ª Ego å›¾å¯¹æ¯”è¡¨ç¤ºå­¦ä¹ ï¼ˆMoEGCLï¼‰ã€‚å®ƒä¸»è¦ç”±ä¸¤ä¸ªæ¨¡å—ç»„æˆã€‚ç‰¹åˆ«åœ°ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ›æ–°çš„æ··åˆè‡ª Ego å›¾èžåˆï¼ˆMoEGFï¼‰ï¼Œå®ƒæž„å»º Ego å›¾ï¼Œå¹¶åˆ©ç”¨æ··åˆä¸“å®¶ç½‘ç»œæ¥å®žçŽ°æ ·æœ¬çº§åˆ«ä¸Šçš„ç»†ç²’åº¦ Ego å›¾èžåˆï¼Œè€Œä¸æ˜¯ä¼ ç»Ÿçš„è§†å›¾çº§åˆ«èžåˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº† Ego å›¾å¯¹æ¯”å­¦ä¹ ï¼ˆEGCLï¼‰æ¨¡å—ï¼Œä»¥å°†èžåˆçš„è¡¨ç¤ºä¸Žç‰¹å®šäºŽè§†å›¾çš„è¡¨ç¤ºå¯¹é½ã€‚EGCL æ¨¡å—å¢žå¼ºäº†æ¥è‡ªåŒä¸€ç°‡çš„æ ·æœ¬çš„è¡¨ç¤ºç›¸ä¼¼æ€§ï¼Œè€Œä¸ä»…ä»…æ˜¯æ¥è‡ªåŒä¸€æ ·æœ¬çš„è¡¨ç¤ºç›¸ä¼¼æ€§ï¼Œä»Žè€Œè¿›ä¸€æ­¥æå‡äº†ç»†ç²’åº¦å›¾è¡¨ç¤ºã€‚å¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒMoEGCL åœ¨æ·±åº¦å¤šè§†å›¾èšç±»ä»»åŠ¡ä¸­å®žçŽ°äº†æœ€å…ˆè¿›çš„ç»“æžœã€‚æºä»£ç å¯åœ¨ https://github.com/HackerHyper/MoEGCL å…¬å¼€èŽ·å¾—ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„å¤šè§†å›¾èšç±»æ–¹æ³•é€šå¸¸åœ¨è§†å›¾çº§åˆ«è¿›è¡Œå›¾èžåˆï¼Œå¿½ç•¥äº†æ ·æœ¬çº§åˆ«çš„ç»†ç²’åº¦ä¿¡æ¯ã€‚è¿™ç§ç²—ç²’åº¦çš„èžåˆæ–¹å¼æ— æ³•å……åˆ†åˆ©ç”¨ä¸åŒè§†å›¾ä¹‹é—´çš„äº’è¡¥ä¿¡æ¯ï¼Œå¯¼è‡´èšç±»æ€§èƒ½å—é™ã€‚çŽ°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ•æ‰ä¸åŒè§†å›¾ä¸­åŒä¸€æ ·æœ¬çš„ç»†å¾®å·®å¼‚å’Œå…³è”æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMoEGCL çš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨æ ·æœ¬çº§åˆ«è¿›è¡Œç»†ç²’åº¦çš„å›¾èžåˆï¼Œå¹¶åˆ©ç”¨å¯¹æ¯”å­¦ä¹ æ¥å¯¹é½èžåˆåŽçš„è¡¨ç¤ºå’Œè§†å›¾ç‰¹å®šçš„è¡¨ç¤ºã€‚é€šè¿‡æž„å»º Ego å›¾å¹¶ä½¿ç”¨æ··åˆä¸“å®¶ç½‘ç»œè¿›è¡Œèžåˆï¼Œå¯ä»¥æ›´ç²¾ç»†åœ°æ•æ‰æ ·æœ¬åœ¨ä¸åŒè§†å›¾ä¸­çš„ç‰¹å¾ã€‚å¯¹æ¯”å­¦ä¹ åˆ™ç”¨äºŽå¢žå¼ºåŒä¸€ç°‡æ ·æœ¬çš„è¡¨ç¤ºç›¸ä¼¼æ€§ï¼Œä»Žè€Œæé«˜èšç±»æ•ˆæžœã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šMoEGCL ä¸»è¦åŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼šæ··åˆè‡ª Ego å›¾èžåˆï¼ˆMoEGFï¼‰å’Œ Ego å›¾å¯¹æ¯”å­¦ä¹ ï¼ˆEGCLï¼‰ã€‚é¦–å…ˆï¼ŒMoEGF æ¨¡å—ä¸ºæ¯ä¸ªæ ·æœ¬æž„å»º Ego å›¾ï¼Œç„¶åŽåˆ©ç”¨æ··åˆä¸“å®¶ç½‘ç»œåœ¨æ ·æœ¬çº§åˆ«èžåˆè¿™äº› Ego å›¾ã€‚èžåˆåŽçš„è¡¨ç¤ºéšåŽè¢«è¾“å…¥åˆ° EGCL æ¨¡å—ï¼Œè¯¥æ¨¡å—é€šè¿‡å¯¹æ¯”å­¦ä¹ å°†èžåˆçš„è¡¨ç¤ºä¸Žè§†å›¾ç‰¹å®šçš„è¡¨ç¤ºå¯¹é½ã€‚æ•´ä¸ªæ¡†æž¶æ—¨åœ¨å­¦ä¹ æ›´å…·åˆ¤åˆ«æ€§çš„å¤šè§†å›¾è¡¨ç¤ºï¼Œä»Žè€Œæé«˜èšç±»æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šMoEGCL çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†æ··åˆè‡ª Ego å›¾èžåˆï¼ˆMoEGFï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—å®žçŽ°äº†æ ·æœ¬çº§åˆ«çš„ç»†ç²’åº¦å›¾èžåˆã€‚ä¸Žä¼ ç»Ÿçš„è§†å›¾çº§åˆ«èžåˆç›¸æ¯”ï¼ŒMoEGF èƒ½å¤Ÿæ›´ç²¾ç»†åœ°æ•æ‰æ ·æœ¬åœ¨ä¸åŒè§†å›¾ä¸­çš„ç‰¹å¾ï¼Œä»Žè€Œå­¦ä¹ åˆ°æ›´å…·åˆ¤åˆ«æ€§çš„è¡¨ç¤ºã€‚æ­¤å¤–ï¼ŒEGCL æ¨¡å—é€šè¿‡å¯¹æ¯”å­¦ä¹ å¢žå¼ºäº†åŒä¸€ç°‡æ ·æœ¬çš„è¡¨ç¤ºç›¸ä¼¼æ€§ï¼Œè¿›ä¸€æ­¥æé«˜äº†èšç±»æ•ˆæžœã€‚

**å…³é”®è®¾è®¡**ï¼šMoEGF æ¨¡å—ä½¿ç”¨æ··åˆä¸“å®¶ç½‘ç»œæ¥èžåˆ Ego å›¾ã€‚æ¯ä¸ªä¸“å®¶ç½‘ç»œè´Ÿè´£å­¦ä¹ ç‰¹å®šè§†å›¾çš„ç‰¹å¾ï¼Œè€Œæ··åˆæƒé‡åˆ™æ ¹æ®æ ·æœ¬çš„ç‰¹å¾åŠ¨æ€è°ƒæ•´ã€‚EGCL æ¨¡å—ä½¿ç”¨ InfoNCE æŸå¤±å‡½æ•°è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œè¯¥æŸå¤±å‡½æ•°æ—¨åœ¨æœ€å¤§åŒ–åŒä¸€ç°‡æ ·æœ¬çš„è¡¨ç¤ºç›¸ä¼¼æ€§ï¼ŒåŒæ—¶æœ€å°åŒ–ä¸åŒç°‡æ ·æœ¬çš„è¡¨ç¤ºç›¸ä¼¼æ€§ã€‚å…·ä½“çš„ç½‘ç»œç»“æž„å’Œå‚æ•°è®¾ç½®éœ€è¦æ ¹æ®å…·ä½“æ•°æ®é›†è¿›è¡Œè°ƒæ•´ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

MoEGCL åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®žéªŒï¼Œç»“æžœè¡¨æ˜Žå…¶æ€§èƒ½ä¼˜äºŽçŽ°æœ‰çš„å¤šè§†å›¾èšç±»æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›æ•°æ®é›†ä¸Šï¼ŒMoEGCL çš„èšç±»å‡†ç¡®çŽ‡ï¼ˆACCï¼‰å’Œå½’ä¸€åŒ–äº’ä¿¡æ¯ï¼ˆNMIï¼‰æŒ‡æ ‡æå‡äº† 5% ä»¥ä¸Šã€‚å®žéªŒç»“æžœéªŒè¯äº† MoEGCL åœ¨ç»†ç²’åº¦å›¾èžåˆå’Œå¯¹æ¯”å­¦ä¹ æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

MoEGCL å¯åº”ç”¨äºŽå¤šç§éœ€è¦å¤šè§†å›¾æ•°æ®èšç±»çš„åœºæ™¯ï¼Œä¾‹å¦‚ç¤¾äº¤ç½‘ç»œåˆ†æžï¼ˆåŸºäºŽç”¨æˆ·è¡Œä¸ºã€å…´è¶£ç­‰å¤šè§†å›¾æ•°æ®è¿›è¡Œç”¨æˆ·èšç±»ï¼‰ã€ç”Ÿç‰©ä¿¡æ¯å­¦ï¼ˆåŸºäºŽåŸºå› è¡¨è¾¾ã€è›‹ç™½è´¨ç›¸äº’ä½œç”¨ç­‰å¤šè§†å›¾æ•°æ®è¿›è¡Œç–¾ç—…äºšåž‹åˆ†ç±»ï¼‰ã€å›¾åƒèšç±»ï¼ˆåŸºäºŽä¸åŒç‰¹å¾æå–æ–¹æ³•å¾—åˆ°çš„å¤šè§†å›¾å›¾åƒæ•°æ®è¿›è¡Œå›¾åƒèšç±»ï¼‰ç­‰ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºŽæå‡å¤šè§†å›¾æ•°æ®åˆ†æžçš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In recent years, the advancement of Graph Neural Networks (GNNs) has significantly propelled progress in Multi-View Clustering (MVC). However, existing methods face the problem of coarse-grained graph fusion. Specifically, current approaches typically generate a separate graph structure for each view and then perform weighted fusion of graph structures at the view level, which is a relatively rough strategy. To address this limitation, we present a novel Mixture of Ego-Graphs Contrastive Representation Learning (MoEGCL). It mainly consists of two modules. In particular, we propose an innovative Mixture of Ego-Graphs Fusion (MoEGF), which constructs ego graphs and utilizes a Mixture-of-Experts network to implement fine-grained fusion of ego graphs at the sample level, rather than the conventional view-level fusion. Additionally, we present the Ego Graph Contrastive Learning (EGCL) module to align the fused representation with the view-specific representation. The EGCL module enhances the representation similarity of samples from the same cluster, not merely from the same sample, further boosting fine-grained graph representation. Extensive experiments demonstrate that MoEGCL achieves state-of-the-art results in deep multi-view clustering tasks. The source code is publicly available at https://github.com/HackerHyper/MoEGCL.

