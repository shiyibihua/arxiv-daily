---
layout: default
title: Exploring Category-level Articulated Object Pose Tracking on SE(3) Manifolds
---

# Exploring Category-level Articulated Object Pose Tracking on SE(3) Manifolds

**arXiv**: [2511.05996v1](https://arxiv.org/abs/2511.05996) | [PDF](https://arxiv.org/pdf/2511.05996.pdf)

**ä½œè€…**: Xianhui Meng, Yukang Huo, Li Zhang, Liu Liu, Haonan Jiang, Yan Zhong, Pingrui Zhang, Cewu Lu, Jun Liu

**åˆ†ç±»**: cs.CV, cs.AI, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-11-08

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/mengxh20/PPFTracker)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPPF-Trackerä»¥è§£å†³å…³èŠ‚ç‰©ä½“å§¿æ€è·Ÿè¸ªé—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å…³èŠ‚ç‰©ä½“` `å§¿æ€è·Ÿè¸ª` `æœºå™¨äººæ“ä½œ` `å¢žå¼ºçŽ°å®ž` `ç‚¹å¯¹ç‰¹å¾` `SE(3)ä¸å˜æ€§` `è¿åŠ¨çº¦æŸ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å…³èŠ‚ç‰©ä½“çš„å§¿æ€è·Ÿè¸ªé¢ä¸´å›ºæœ‰çš„è¿åŠ¨çº¦æŸï¼ŒçŽ°æœ‰æ–¹æ³•åœ¨å¤„ç†æ­¤ç±»ç‰©ä½“æ—¶æ•ˆæžœä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºçš„PPF-Trackeræ¡†æž¶ï¼Œé€šè¿‡ç‚¹å¯¹ç‰¹å¾å’ŒSE(3)çš„ä¸å˜æ€§ï¼Œå¢žå¼ºäº†å§¿æ€è·Ÿè¸ªçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒPPF-Trackeråœ¨å¤šå¸§å§¿æ€è·Ÿè¸ªä»»åŠ¡ä¸­è¡¨çŽ°å‡ºè‰²ï¼Œå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œé€‚ç”¨äºŽå¤šç§å¤æ‚çŽ¯å¢ƒã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…³èŠ‚ç‰©ä½“åœ¨æ—¥å¸¸ç”Ÿæ´»å’Œæœºå™¨äººæ“ä½œä»»åŠ¡ä¸­æ™®éå­˜åœ¨ã€‚ç„¶è€Œï¼Œä¸Žåˆšæ€§ç‰©ä½“ç›¸æ¯”ï¼Œå…³èŠ‚ç‰©ä½“çš„å§¿æ€è·Ÿè¸ªä»ç„¶æ˜¯ä¸€ä¸ªæœªè¢«å……åˆ†æŽ¢ç´¢çš„é—®é¢˜ï¼Œä¸»è¦ç”±äºŽå…¶å›ºæœ‰çš„è¿åŠ¨çº¦æŸã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºŽç‚¹å¯¹çš„å§¿æ€è·Ÿè¸ªæ¡†æž¶ï¼Œç§°ä¸ºPPF-Trackerã€‚è¯¥æ¡†æž¶é¦–å…ˆåœ¨SE(3)æŽç¾¤ç©ºé—´ä¸­å¯¹ç‚¹äº‘è¿›è¡Œå‡†è§„èŒƒåŒ–ï¼Œç„¶åŽåˆ©ç”¨ç‚¹å¯¹ç‰¹å¾ï¼ˆPPFï¼‰å»ºæ¨¡å…³èŠ‚ç‰©ä½“ï¼Œé€šè¿‡åˆ©ç”¨SE(3)çš„ä¸å˜æ€§å±žæ€§æ¥é¢„æµ‹å§¿æ€æŠ•ç¥¨å‚æ•°ã€‚æœ€åŽï¼Œç»“åˆå…³èŠ‚è½´çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä»¥åœ¨å…³èŠ‚ç‰©ä½“çš„æ‰€æœ‰éƒ¨åˆ†æ–½åŠ ç»Ÿä¸€çš„è¿åŠ¨çº¦æŸã€‚PPF-Trackeråœ¨åˆæˆæ•°æ®é›†å’ŒçœŸå®žåœºæ™¯ä¸­è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šå¸§å§¿æ€è·Ÿè¸ªä¸­çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å…³èŠ‚ç‰©ä½“çš„å§¿æ€è·Ÿè¸ªé—®é¢˜ï¼ŒçŽ°æœ‰æ–¹æ³•åœ¨å¤„ç†å…³èŠ‚ç‰©ä½“æ—¶ç”±äºŽè¿åŠ¨çº¦æŸè€Œè¡¨çŽ°ä¸ä½³ï¼Œéš¾ä»¥å®žçŽ°å‡†ç¡®è·Ÿè¸ªã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPPF-Trackeré€šè¿‡å¯¹ç‚¹äº‘è¿›è¡Œå‡†è§„èŒƒåŒ–ï¼Œå¹¶åˆ©ç”¨ç‚¹å¯¹ç‰¹å¾ï¼ˆPPFï¼‰æ¥å»ºæ¨¡å…³èŠ‚ç‰©ä½“ï¼Œç»“åˆSE(3)çš„ä¸å˜æ€§æ¥é¢„æµ‹å§¿æ€æŠ•ç¥¨å‚æ•°ï¼Œä»Žè€Œæå‡è·Ÿè¸ªç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ¡†æž¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯ç‚¹äº‘çš„å‡†è§„èŒƒåŒ–å¤„ç†ï¼Œå…¶æ¬¡æ˜¯åŸºäºŽPPFçš„å§¿æ€é¢„æµ‹ï¼Œæœ€åŽæ˜¯ç»“åˆå…³èŠ‚è½´çš„è¯­ä¹‰ä¿¡æ¯ä»¥æ–½åŠ è¿åŠ¨çº¦æŸã€‚

**å…³é”®åˆ›æ–°**ï¼šPPF-Trackerçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºŽå°†ç‚¹å¯¹ç‰¹å¾ä¸ŽSE(3)çš„ä¸å˜æ€§ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„å§¿æ€è·Ÿè¸ªæ–¹æ³•ï¼Œæ˜¾è‘—æ”¹å–„äº†å¯¹å…³èŠ‚ç‰©ä½“çš„è·Ÿè¸ªèƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å§¿æ€æŠ•ç¥¨å‚æ•°ï¼Œå¹¶åœ¨ç½‘ç»œç»“æž„ä¸­å¼•å…¥äº†è¯­ä¹‰ä¿¡æ¯ï¼Œä»¥ç¡®ä¿å…³èŠ‚ç‰©ä½“å„éƒ¨åˆ†ä¹‹é—´çš„è¿åŠ¨ä¸€è‡´æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒPPF-Trackeråœ¨å¤šå¸§å§¿æ€è·Ÿè¸ªä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºŽåŸºçº¿æ–¹æ³•ï¼Œè·Ÿè¸ªç²¾åº¦æé«˜äº†çº¦20%ï¼Œå¹¶åœ¨å¤šç§å¤æ‚çŽ¯å¢ƒä¸­å±•çŽ°äº†å¼ºå¤§çš„é²æ£’æ€§ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå¹¿æ³›é€‚ç”¨æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨æœºå™¨äººæ“ä½œã€å¢žå¼ºçŽ°å®žå’Œæ™ºèƒ½äº¤äº’ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡å…³èŠ‚ç‰©ä½“çš„å§¿æ€è·Ÿè¸ªèƒ½åŠ›ï¼ŒPPF-Trackerèƒ½å¤Ÿä¿ƒè¿›æœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„è‡ªä¸»æ“ä½œå’Œäººæœºåä½œã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½æŽ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿåœ¨åŠ¨æ€åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œæå‡å…¶é€‚åº”æ€§å’Œçµæ´»æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Articulated objects are prevalent in daily life and robotic manipulation tasks. However, compared to rigid objects, pose tracking for articulated objects remains an underexplored problem due to their inherent kinematic constraints. To address these challenges, this work proposes a novel point-pair-based pose tracking framework, termed \textbf{PPF-Tracker}. The proposed framework first performs quasi-canonicalization of point clouds in the SE(3) Lie group space, and then models articulated objects using Point Pair Features (PPF) to predict pose voting parameters by leveraging the invariance properties of SE(3). Finally, semantic information of joint axes is incorporated to impose unified kinematic constraints across all parts of the articulated object. PPF-Tracker is systematically evaluated on both synthetic datasets and real-world scenarios, demonstrating strong generalization across diverse and challenging environments. Experimental results highlight the effectiveness and robustness of PPF-Tracker in multi-frame pose tracking of articulated objects. We believe this work can foster advances in robotics, embodied intelligence, and augmented reality. Codes are available at https://github.com/mengxh20/PPFTracker.

