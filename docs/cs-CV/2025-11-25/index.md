---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-11-25
---

# cs.CVï¼ˆ2025-11-25ï¼‰

ğŸ“Š å…± **50** ç¯‡è®ºæ–‡
 | ğŸ”— **8** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (22 ğŸ”—4)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (15 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (10 ğŸ”—2)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1)</a>
<a href="#æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting" class="interest-badge">æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction-matching" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction & Matching) (1 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (22 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251120804v1-Î´-nerf-incremental-refinement-of-neural-radiance-fields-through-resi.html">$Î”$-NeRF: Incremental Refinement of Neural Radiance Fields through Residual Control and Knowledge Transfer</a></td>
  <td>æå‡º$Î”$-NeRFï¼Œé€šè¿‡æ®‹å·®æ§åˆ¶å’ŒçŸ¥è¯†è¿ç§»å®ç°ç¥ç»è¾å°„åœºçš„å¢é‡ä¼˜åŒ–ï¼Œé€‚ç”¨äºå«æ˜Ÿå›¾åƒç­‰åºåˆ—æ•°æ®åœºæ™¯ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20804v1" onclick="toggleFavorite(this, '2511.20804v1', '$Î”$-NeRF: Incremental Refinement of Neural Radiance Fields through Residual Control and Knowledge Transfer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251120058v1-delightmono-enhancing-self-supervised-monocular-depth-estimation-in-.html">DeLightMono: Enhancing Self-Supervised Monocular Depth Estimation in Endoscopy by Decoupling Uneven Illumination</a></td>
  <td>DeLightMonoï¼šé€šè¿‡è§£è€¦ä¸å‡åŒ€å…‰ç…§å¢å¼ºå†…çª¥é•œè‡ªç›‘ç£å•ç›®æ·±åº¦ä¼°è®¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20058v1" onclick="toggleFavorite(this, '2511.20058v1', 'DeLightMono: Enhancing Self-Supervised Monocular Depth Estimation in Endoscopy by Decoupling Uneven Illumination')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251120003v1-redefining-radar-segmentation-simultaneous-static-moving-segmentatio.html">Redefining Radar Segmentation: Simultaneous Static-Moving Segmentation and Ego-Motion Estimation using Radar Point Clouds</a></td>
  <td>æå‡ºåŸºäºé›·è¾¾ç‚¹äº‘çš„é™æ€-åŠ¨æ€åˆ†å‰²ä¸è‡ªè¿åŠ¨ä¼°è®¡åŒæ­¥æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20003v1" onclick="toggleFavorite(this, '2511.20003v1', 'Redefining Radar Segmentation: Simultaneous Static-Moving Segmentation and Ego-Motion Estimation using Radar Point Clouds')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251120646v1-3d-aware-multi-task-learning-with-cross-view-correlations-for-dense-.html">3D-Aware Multi-Task Learning with Cross-View Correlations for Dense Scene Understanding</a></td>
  <td>æå‡ºåŸºäºè·¨è§†è§’ç›¸å…³æ€§çš„3Dæ„ŸçŸ¥å¤šä»»åŠ¡å­¦ä¹ ï¼Œç”¨äºå¯†é›†åœºæ™¯ç†è§£</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20646v1" onclick="toggleFavorite(this, '2511.20646v1', '3D-Aware Multi-Task Learning with Cross-View Correlations for Dense Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251120348v2-material-informed-gaussian-splatting-for-3d-world-reconstruction-in-.html">Material-informed Gaussian Splatting for 3D World Reconstruction in a Digital Twin</a></td>
  <td>æå‡ºåŸºäºæè´¨ä¿¡æ¯çš„3Dé«˜æ–¯æº…å°„æ–¹æ³•ï¼Œç”¨äºæ•°å­—å­ªç”Ÿä¸­çš„ä¸‰ç»´ä¸–ç•Œé‡å»º</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20348v2" onclick="toggleFavorite(this, '2511.20348v2', 'Material-informed Gaussian Splatting for 3D World Reconstruction in a Digital Twin')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251119971v1-vggt4d-mining-motion-cues-in-visual-geometry-transformers-for-4d-sce.html">VGGT4D: Mining Motion Cues in Visual Geometry Transformers for 4D Scene Reconstruction</a></td>
  <td>VGGT4Dï¼šæŒ–æ˜è§†è§‰å‡ ä½•Transformerä¸­çš„è¿åŠ¨çº¿ç´¢ï¼Œç”¨äº4Dåœºæ™¯é‡å»º</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19971v1" onclick="toggleFavorite(this, '2511.19971v1', 'VGGT4D: Mining Motion Cues in Visual Geometry Transformers for 4D Scene Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251120020v1-acit-attention-guided-cross-modal-interaction-transformer-for-pedest.html">ACIT: Attention-Guided Cross-Modal Interaction Transformer for Pedestrian Crossing Intention Prediction</a></td>
  <td>æå‡ºACITæ¨¡å‹ï¼Œåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶å’Œè·¨æ¨¡æ€äº¤äº’Transformeræå‡è¡Œäººè¿‡è¡—æ„å›¾é¢„æµ‹ç²¾åº¦ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20020v1" onclick="toggleFavorite(this, '2511.20020v1', 'ACIT: Attention-Guided Cross-Modal Interaction Transformer for Pedestrian Crossing Intention Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251120853v2-modest-multi-optics-depth-of-field-stereo-dataset.html">MODEST: Multi-Optics Depth-of-Field Stereo Dataset</a></td>
  <td>MODESTï¼šå¤šå…‰åœˆæ™¯æ·±ç«‹ä½“è§†è§‰æ•°æ®é›†ï¼Œå¼¥åˆçœŸå®å…‰å­¦ä¸åˆæˆæ•°æ®å·®è·</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20853v2" onclick="toggleFavorite(this, '2511.20853v2', 'MODEST: Multi-Optics Depth-of-Field Stereo Dataset')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251200080v1-conceptual-evaluation-of-deep-visual-stereo-odometry-for-the-marwin-.html">Conceptual Evaluation of Deep Visual Stereo Odometry for the MARWIN Radiation Monitoring Robot in Accelerator Tunnels</a></td>
  <td>æ¢ç´¢æ·±åº¦è§†è§‰ç«‹ä½“é‡Œç¨‹è®¡åœ¨åŠ é€Ÿå™¨éš§é“è¾å°„ç›‘æµ‹æœºå™¨äººä¸­çš„åº”ç”¨</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00080v1" onclick="toggleFavorite(this, '2512.00080v1', 'Conceptual Evaluation of Deep Visual Stereo Odometry for the MARWIN Radiation Monitoring Robot in Accelerator Tunnels')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251120065v1-flatec-frequency-disentangled-latent-triplanes-for-efficient-compres.html">FLaTEC: Frequency-Disentangled Latent Triplanes for Efficient Compression of LiDAR Point Clouds</a></td>
  <td>FLaTECï¼šæå‡ºé¢‘ç‡è§£è€¦çš„éšå¼ä¸‰å¹³é¢è¡¨ç¤ºï¼Œé«˜æ•ˆå‹ç¼©LiDARç‚¹äº‘ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20065v1" onclick="toggleFavorite(this, '2511.20065v1', 'FLaTEC: Frequency-Disentangled Latent Triplanes for Efficient Compression of LiDAR Point Clouds')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251211811v2-enhancing-geo-localization-for-crowdsourced-flood-imagery-via-llm-gu.html">Enhancing Geo-localization for Crowdsourced Flood Imagery via LLM-Guided Attention</a></td>
  <td>VPR-AttLLMï¼šåˆ©ç”¨LLMå¼•å¯¼çš„æ³¨æ„åŠ›å¢å¼ºä¼—åŒ…æ´ªæ°´å›¾åƒçš„åœ°ç†å®šä½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11811v2" onclick="toggleFavorite(this, '2512.11811v2', 'Enhancing Geo-localization for Crowdsourced Flood Imagery via LLM-Guided Attention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251119827v1-redirector-creating-any-length-video-retakes-with-rotary-camera-enco.html">ReDirector: Creating Any-Length Video Retakes with Rotary Camera Encoding</a></td>
  <td>ReDirectorï¼šåˆ©ç”¨æ—‹è½¬ç›¸æœºç¼–ç ç”Ÿæˆä»»æ„é•¿åº¦çš„è§†é¢‘é‡æ‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19827v1" onclick="toggleFavorite(this, '2511.19827v1', 'ReDirector: Creating Any-Length Video Retakes with Rotary Camera Encoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251120366v2-vggtface-topologically-consistent-facial-geometry-reconstruction-in-.html">VGGTFace: Topologically Consistent Facial Geometry Reconstruction in the Wild</a></td>
  <td>VGGTFaceï¼šåˆ©ç”¨3DåŸºç¡€æ¨¡å‹å®ç°æ‹“æ‰‘ä¸€è‡´çš„äººè„¸å‡ ä½•é‡å»º</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20366v2" onclick="toggleFavorite(this, '2511.20366v2', 'VGGTFace: Topologically Consistent Facial Geometry Reconstruction in the Wild')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251120343v1-amb3r-accurate-feed-forward-metric-scale-3d-reconstruction-with-back.html">AMB3R: Accurate Feed-forward Metric-scale 3D Reconstruction with Backend</a></td>
  <td>AMB3Rï¼šåˆ©ç”¨ç´§å‡‘ä½“ç´ åç«¯å®ç°ç²¾ç¡®çš„åº¦é‡å°ºåº¦ä¸‰ç»´é‡å»º</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20343v1" onclick="toggleFavorite(this, '2511.20343v1', 'AMB3R: Accurate Feed-forward Metric-scale 3D Reconstruction with Backend')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251119854v2-stavatar-soft-binding-and-temporal-density-control-for-monocular-3d-.html">STAvatar: Soft Binding and Temporal Density Control for Monocular 3D Head Avatars Reconstruction</a></td>
  <td>STAvatarï¼šæå‡ºè½¯ç»‘å®šä¸æ—¶åºå¯†åº¦æ§åˆ¶çš„å•ç›®3Då¤´éƒ¨Avataré‡å»ºæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19854v2" onclick="toggleFavorite(this, '2511.19854v2', 'STAvatar: Soft Binding and Temporal Density Control for Monocular 3D Head Avatars Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251120865v1-estimating-fog-parameters-from-a-sequence-of-stereo-images.html">Estimating Fog Parameters from a Sequence of Stereo Images</a></td>
  <td>æå‡ºä¸€ç§åŸºäºç«‹ä½“å›¾åƒåºåˆ—çš„é›¾å‚æ•°åŠ¨æ€ä¼°è®¡æ–¹æ³•ï¼Œé€‚ç”¨äºè§†è§‰SLAMå’Œé‡Œç¨‹è®¡ç³»ç»Ÿã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20865v1" onclick="toggleFavorite(this, '2511.20865v1', 'Estimating Fog Parameters from a Sequence of Stereo Images')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251120525v1-mistake-attribution-fine-grained-mistake-understanding-in-egocentric.html">Mistake Attribution: Fine-Grained Mistake Understanding in Egocentric Videos</a></td>
  <td>æå‡ºMistake Attribution (MATT)ä»»åŠ¡ï¼Œç”¨äºç»†ç²’åº¦ç†è§£ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘ä¸­çš„äººç±»é”™è¯¯ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20525v1" onclick="toggleFavorite(this, '2511.20525v1', 'Mistake Attribution: Fine-Grained Mistake Understanding in Egocentric Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251120253v1-zoo3d-zero-shot-3d-object-detection-at-scene-level.html">Zoo3D: Zero-Shot 3D Object Detection at Scene Level</a></td>
  <td>Zoo3Dï¼šæå‡ºä¸€ç§åœºæ™¯çº§é›¶æ ·æœ¬3Dç›®æ ‡æ£€æµ‹æ¡†æ¶ï¼Œæ— éœ€è®­ç»ƒå³å¯å®ç°SOTAæ€§èƒ½ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20253v1" onclick="toggleFavorite(this, '2511.20253v1', 'Zoo3D: Zero-Shot 3D Object Detection at Scene Level')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251120088v1-explainable-visual-anomaly-detection-via-concept-bottleneck-models.html">Explainable Visual Anomaly Detection via Concept Bottleneck Models</a></td>
  <td>æå‡ºåŸºäºæ¦‚å¿µç“¶é¢ˆæ¨¡å‹çš„å¯è§£é‡Šè§†è§‰å¼‚å¸¸æ£€æµ‹æ–¹æ³•CONVAD</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20088v1" onclick="toggleFavorite(this, '2511.20088v1', 'Explainable Visual Anomaly Detection via Concept Bottleneck Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251120032v1-tell-model-where-to-look-mitigating-hallucinations-in-mllms-by-visio.html">Tell Model Where to Look: Mitigating Hallucinations in MLLMs by Vision-Guided Attention</a></td>
  <td>æå‡ºè§†è§‰å¼•å¯¼æ³¨æ„åŠ›æœºåˆ¶ï¼ˆVGAï¼‰ï¼Œç¼“è§£å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20032v1" onclick="toggleFavorite(this, '2511.20032v1', 'Tell Model Where to Look: Mitigating Hallucinations in MLLMs by Vision-Guided Attention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/251120721v1-foundry-distilling-3d-foundation-models-for-the-edge.html">Foundry: Distilling 3D Foundation Models for the Edge</a></td>
  <td>Foundryï¼šè¾¹ç¼˜è®¾å¤‡3DåŸºç¡€æ¨¡å‹è’¸é¦ï¼Œä¿æŒé€šç”¨æ€§çš„åŒæ—¶å®ç°é«˜æ•ˆå‹ç¼©</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20721v1" onclick="toggleFavorite(this, '2511.20721v1', 'Foundry: Distilling 3D Foundation Models for the Edge')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251120011v1-multi-context-fusion-transformer-for-pedestrian-crossing-intention-p.html">Multi-Context Fusion Transformer for Pedestrian Crossing Intention Prediction in Urban Environments</a></td>
  <td>æå‡ºå¤šä¸Šä¸‹æ–‡èåˆTransformerï¼ˆMFTï¼‰ç”¨äºåŸå¸‚ç¯å¢ƒä¸­è¡Œäººæ„å›¾é¢„æµ‹ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20011v1" onclick="toggleFavorite(this, '2511.20011v1', 'Multi-Context Fusion Transformer for Pedestrian Crossing Intention Prediction in Urban Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (15 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>23</td>
  <td><a href="./papers/251120278v1-dapointmamba-domain-adaptive-point-mamba-for-point-cloud-completion.html">DAPointMamba: Domain Adaptive Point Mamba for Point Cloud Completion</a></td>
  <td>DAPointMambaï¼šé¢å‘ç‚¹äº‘è¡¥å…¨çš„é¢†åŸŸè‡ªé€‚åº”Point Mambaæ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20278v1" onclick="toggleFavorite(this, '2511.20278v1', 'DAPointMamba: Domain Adaptive Point Mamba for Point Cloud Completion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/251120041v1-mfm-point-multi-scale-flow-matching-for-point-cloud-generation.html">MFM-point: Multi-scale Flow Matching for Point Cloud Generation</a></td>
  <td>MFM-Pointï¼šå¤šå°ºåº¦æµåŒ¹é…ç‚¹äº‘ç”Ÿæˆæ–¹æ³•ï¼Œæå‡ç‚¹äº‘ç”Ÿæˆè´¨é‡ä¸å¯æ‰©å±•æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20041v1" onclick="toggleFavorite(this, '2511.20041v1', 'MFM-point: Multi-scale Flow Matching for Point Cloud Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/251120325v1-ad-r1-closed-loop-reinforcement-learning-for-end-to-end-autonomous-d.html">AD-R1: Closed-Loop Reinforcement Learning for End-to-End Autonomous Driving with Impartial World Models</a></td>
  <td>AD-R1ï¼šåŸºäºå…¬æ­£ä¸–ç•Œæ¨¡å‹çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶é—­ç¯å¼ºåŒ–å­¦ä¹ </td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20325v1" onclick="toggleFavorite(this, '2511.20325v1', 'AD-R1: Closed-Loop Reinforcement Learning for End-to-End Autonomous Driving with Impartial World Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/251120216v1-costnav-a-navigation-benchmark-for-cost-aware-evaluation-of-embodied.html">CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents</a></td>
  <td>æå‡ºCostNavä»¥è§£å†³å¯¼èˆªä»»åŠ¡ç»æµå¯è¡Œæ€§è¯„ä¼°é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20216v1" onclick="toggleFavorite(this, '2511.20216v1', 'CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/251120431v2-bric-bridging-kinematic-plans-and-physical-control-at-test-time.html">BRIC: Bridging Kinematic Plans and Physical Control at Test Time</a></td>
  <td>BRICï¼šæ¡¥æ¥è¿åŠ¨è§„åˆ’ä¸ç‰©ç†æ§åˆ¶çš„æµ‹è¯•æ—¶è‡ªé€‚åº”æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20431v2" onclick="toggleFavorite(this, '2511.20431v2', 'BRIC: Bridging Kinematic Plans and Physical Control at Test Time')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/251119882v1-chessmamba-structure-aware-interleaving-of-state-spaces-for-change-d.html">ChessMamba: Structure-Aware Interleaving of State Spaces for Change Detection in Remote Sensing Images</a></td>
  <td>ChessMambaï¼šä¸€ç§ç»“æ„æ„ŸçŸ¥çš„çŠ¶æ€ç©ºé—´äº¤é”™æ–¹æ³•ï¼Œç”¨äºé¥æ„Ÿå›¾åƒå˜åŒ–æ£€æµ‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19882v1" onclick="toggleFavorite(this, '2511.19882v1', 'ChessMamba: Structure-Aware Interleaving of State Spaces for Change Detection in Remote Sensing Images')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/251120549v1-flash-dmd-towards-high-fidelity-few-step-image-generation-with-effic.html">Flash-DMD: Towards High-Fidelity Few-Step Image Generation with Efficient Distillation and Joint Reinforcement Learning</a></td>
  <td>Flash-DMDï¼šé€šè¿‡é«˜æ•ˆè’¸é¦ä¸è”åˆå¼ºåŒ–å­¦ä¹ å®ç°é«˜ä¿çœŸå¿«é€Ÿå›¾åƒç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20549v1" onclick="toggleFavorite(this, '2511.20549v1', 'Flash-DMD: Towards High-Fidelity Few-Step Image Generation with Efficient Distillation and Joint Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>30</td>
  <td><a href="./papers/251120095v1-wpt-world-to-policy-transfer-via-online-world-model-distillation.html">WPT: World-to-Policy Transfer via Online World Model Distillation</a></td>
  <td>æå‡ºWPTï¼šé€šè¿‡åœ¨çº¿ä¸–ç•Œæ¨¡å‹è’¸é¦å®ç°ä¸–ç•Œåˆ°ç­–ç•¥çš„è¿ç§»ï¼Œæå‡è§„åˆ’æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20095v1" onclick="toggleFavorite(this, '2511.20095v1', 'WPT: World-to-Policy Transfer via Online World Model Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>31</td>
  <td><a href="./papers/251119963v1-mambaeye-a-size-agnostic-visual-encoder-with-causal-sequential-proce.html">MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing</a></td>
  <td>MambaEyeï¼šåŸºäºå› æœåºåˆ—å¤„ç†çš„å°ºå¯¸æ— å…³è§†è§‰ç¼–ç å™¨</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19963v1" onclick="toggleFavorite(this, '2511.19963v1', 'MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>32</td>
  <td><a href="./papers/251120415v2-majutsucity-language-driven-aesthetic-adaptive-city-generation-with-.html">MajutsuCity: Language-driven Aesthetic-adaptive City Generation with Controllable 3D Assets and Layouts</a></td>
  <td>MajutsuCityï¼šæå‡ºè¯­è¨€é©±åŠ¨çš„ç¾å­¦è‡ªé€‚åº”åŸå¸‚ç”Ÿæˆæ¡†æ¶ï¼Œå¯æ§3Dèµ„äº§ä¸å¸ƒå±€ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20415v2" onclick="toggleFavorite(this, '2511.20415v2', 'MajutsuCity: Language-driven Aesthetic-adaptive City Generation with Controllable 3D Assets and Layouts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>33</td>
  <td><a href="./papers/251120270v1-drl-guided-neural-batch-sampling-for-semi-supervised-pixel-level-ano.html">DRL-Guided Neural Batch Sampling for Semi-Supervised Pixel-Level Anomaly Detection</a></td>
  <td>æå‡ºåŸºäºDRLå¼•å¯¼çš„ç¥ç»æ‰¹é‡é‡‡æ ·åŠç›‘ç£åƒç´ çº§å¼‚å¸¸æ£€æµ‹æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20270v1" onclick="toggleFavorite(this, '2511.20270v1', 'DRL-Guided Neural Batch Sampling for Semi-Supervised Pixel-Level Anomaly Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>34</td>
  <td><a href="./papers/251120151v1-hybrid-convolution-and-frequency-state-space-network-for-image-compr.html">Hybrid Convolution and Frequency State Space Network for Image Compression</a></td>
  <td>æå‡ºHCFSSNetï¼Œä¸€ç§æ··åˆå·ç§¯å’Œé¢‘ç‡çŠ¶æ€ç©ºé—´ç½‘ç»œçš„å›¾åƒå‹ç¼©æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20151v1" onclick="toggleFavorite(this, '2511.20151v1', 'Hybrid Convolution and Frequency State Space Network for Image Compression')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>35</td>
  <td><a href="./papers/251120784v1-one-patch-is-all-you-need-joint-surface-material-reconstruction-and-.html">One Patch is All You Need: Joint Surface Material Reconstruction and Classification from Minimal Visual Cues</a></td>
  <td>SMARCï¼šä»…éœ€å›¾åƒ10%åŒºåŸŸï¼Œå³å¯å®ç°è¡¨é¢æè´¨é‡å»ºä¸åˆ†ç±»</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20784v1" onclick="toggleFavorite(this, '2511.20784v1', 'One Patch is All You Need: Joint Surface Material Reconstruction and Classification from Minimal Visual Cues')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>36</td>
  <td><a href="./papers/251120422v1-vibraverse-a-large-scale-geometry-acoustics-alignment-dataset-for-ph.html">VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning</a></td>
  <td>VibraVerseï¼šæ„å»ºå¤§è§„æ¨¡å‡ ä½•-å£°å­¦å¯¹é½æ•°æ®é›†ï¼Œå®ç°ç‰©ç†ä¸€è‡´çš„å¤šæ¨¡æ€å­¦ä¹ </td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20422v1" onclick="toggleFavorite(this, '2511.20422v1', 'VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>37</td>
  <td><a href="./papers/251120716v1-video-object-recognition-in-mobile-edge-networks-local-tracking-or-e.html">Video Object Recognition in Mobile Edge Networks: Local Tracking or Edge Detection?</a></td>
  <td>é’ˆå¯¹ç§»åŠ¨è¾¹ç¼˜ç½‘ç»œè§†é¢‘ç›®æ ‡è¯†åˆ«ï¼Œæå‡ºåŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”è·Ÿè¸ªä¸æ£€æµ‹ç®—æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20716v1" onclick="toggleFavorite(this, '2511.20716v1', 'Video Object Recognition in Mobile Edge Networks: Local Tracking or Edge Detection?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (10 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>38</td>
  <td><a href="./papers/251120354v1-gs-checker-tampering-localization-for-3d-gaussian-splatting.html">GS-Checker: Tampering Localization for 3D Gaussian Splatting</a></td>
  <td>GS-Checkerï¼šæå‡º3Dé«˜æ–¯æº…å°„ç¯¡æ”¹å®šä½æ–¹æ³•ï¼Œä¿éšœ3Då†…å®¹å®‰å…¨</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20354v1" onclick="toggleFavorite(this, '2511.20354v1', 'GS-Checker: Tampering Localization for 3D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>39</td>
  <td><a href="./papers/251119861v2-gigaworld-0-world-models-as-data-engine-to-empower-embodied-ai.html">GigaWorld-0: World Models as Data Engine to Empower Embodied AI</a></td>
  <td>GigaWorld-0ï¼šæ„å»ºä¸–ç•Œæ¨¡å‹ä½œä¸ºæ•°æ®å¼•æ“ï¼Œèµ‹èƒ½å…·èº«æ™ºèƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19861v2" onclick="toggleFavorite(this, '2511.19861v2', 'GigaWorld-0: World Models as Data Engine to Empower Embodied AI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>40</td>
  <td><a href="./papers/251120359v1-from-passive-perception-to-active-memory-a-weakly-supervised-image-m.html">From Passive Perception to Active Memory: A Weakly Supervised Image Manipulation Localization Framework Driven by Coarse-Grained Annotations</a></td>
  <td>æå‡ºBoxPromptIMLæ¡†æ¶ï¼Œä»¥ä½æˆæœ¬ç²—ç•¥æ ‡æ³¨å®ç°å›¾åƒç¯¡æ”¹ç²¾ç¡®å®šä½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20359v1" onclick="toggleFavorite(this, '2511.20359v1', 'From Passive Perception to Active Memory: A Weakly Supervised Image Manipulation Localization Framework Driven by Coarse-Grained Annotations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>41</td>
  <td><a href="./papers/251120156v1-map-world-masked-action-planning-and-path-integral-world-model-for-a.html">Map-World: Masked Action planning and Path-Integral World Model for Autonomous Driving</a></td>
  <td>æå‡ºMAP-Worldï¼Œç»“åˆæ©ç åŠ¨ä½œè§„åˆ’ä¸è·¯å¾„ç§¯åˆ†ä¸–ç•Œæ¨¡å‹ï¼Œå®ç°è‡ªåŠ¨é©¾é©¶å¤šæ¨¡æ€è¿åŠ¨è§„åˆ’ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20156v1" onclick="toggleFavorite(this, '2511.20156v1', 'Map-World: Masked Action planning and Path-Integral World Model for Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>42</td>
  <td><a href="./papers/251120620v1-wanderland-geometrically-grounded-simulation-for-open-world-embodied.html">Wanderland: Geometrically Grounded Simulation for Open-World Embodied AI</a></td>
  <td>Wanderlandï¼šé¢å‘å¼€æ”¾ä¸–ç•Œå…·èº«AIçš„å‡ ä½•æ ¡å‡†ä»¿çœŸæ¡†æ¶</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20620v1" onclick="toggleFavorite(this, '2511.20620v1', 'Wanderland: Geometrically Grounded Simulation for Open-World Embodied AI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>43</td>
  <td><a href="./papers/251120722v1-dinolizer-learning-from-the-best-for-generative-inpainting-localizat.html">DinoLizer: Learning from the Best for Generative Inpainting Localization</a></td>
  <td>DinoLizerï¼šåˆ©ç”¨DINOv2å­¦ä¹ ç”Ÿæˆå¼å›¾åƒä¿®å¤ç¯¡æ”¹åŒºåŸŸçš„å®šä½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20722v1" onclick="toggleFavorite(this, '2511.20722v1', 'DinoLizer: Learning from the Best for Generative Inpainting Localization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>44</td>
  <td><a href="./papers/251120351v2-thinking-in-360-humanoid-visual-search-in-the-wild.html">Thinking in 360Â°: Humanoid Visual Search in the Wild</a></td>
  <td>æå‡ºH* BenchåŸºå‡†ï¼Œç ”ç©¶å…·èº«æ™ºèƒ½ä½“åœ¨360Â°å…¨æ™¯å›¾åƒä¸­çš„è§†è§‰æœç´¢èƒ½åŠ›ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20351v2" onclick="toggleFavorite(this, '2511.20351v2', 'Thinking in 360Â°: Humanoid Visual Search in the Wild')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>45</td>
  <td><a href="./papers/251119972v2-boosting-reasoning-in-large-multimodal-models-via-activation-replay.html">Boosting Reasoning in Large Multimodal Models via Activation Replay</a></td>
  <td>æå‡ºActivation Replayï¼Œé€šè¿‡æ¿€æ´»é‡æ”¾æå‡å¤§å‹å¤šæ¨¡æ€æ¨¡å‹æ¨ç†èƒ½åŠ›ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19972v2" onclick="toggleFavorite(this, '2511.19972v2', 'Boosting Reasoning in Large Multimodal Models via Activation Replay')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>46</td>
  <td><a href="./papers/251120615v1-evaluating-the-performance-of-deep-learning-models-in-whole-body-dyn.html">Evaluating the Performance of Deep Learning Models in Whole-body Dynamic 3D Posture Prediction During Load-reaching Activities</a></td>
  <td>æå‡ºåŸºäºTransformerçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹è´Ÿé‡æ´»åŠ¨ä¸­å…¨èº«åŠ¨æ€3Då§¿æ€ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20615v1" onclick="toggleFavorite(this, '2511.20615v1', 'Evaluating the Performance of Deep Learning Models in Whole-body Dynamic 3D Posture Prediction During Load-reaching Activities')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>47</td>
  <td><a href="./papers/251120223v1-v-attack-targeting-disentangled-value-features-for-controllable-adve.html">V-Attack: Targeting Disentangled Value Features for Controllable Adversarial Attacks on LVLMs</a></td>
  <td>V-Attacké€šè¿‡æ“æ§è§£è€¦çš„Valueç‰¹å¾ï¼Œå®ç°å¯¹LVLMçš„å¯æ§å¯¹æŠ—æ”»å‡»ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20223v1" onclick="toggleFavorite(this, '2511.20223v1', 'V-Attack: Targeting Disentangled Value Features for Controllable Adversarial Attacks on LVLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>48</td>
  <td><a href="./papers/251120446v1-learning-to-generate-human-human-object-interactions-from-textual-de.html">Learning to Generate Human-Human-Object Interactions from Textual Descriptions</a></td>
  <td>æå‡ºHHOIç”Ÿæˆæ¡†æ¶ï¼Œä»æ–‡æœ¬æè¿°ç”Ÿæˆäºº-äºº-ç‰©äº¤äº’åœºæ™¯ï¼Œå¹¶æ„å»ºäº†ç›¸å…³æ•°æ®é›†ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20446v1" onclick="toggleFavorite(this, '2511.20446v1', 'Learning to Generate Human-Human-Object Interactions from Textual Descriptions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting">ğŸ”¬ æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>49</td>
  <td><a href="./papers/251119909v1-motion-marionette-rethinking-rigid-motion-transfer-via-prior-guidanc.html">Motion Marionette: Rethinking Rigid Motion Transfer via Prior Guidance</a></td>
  <td>æå‡ºMotion Marionetteä»¥è§£å†³åˆšæ€§è¿åŠ¨è½¬ç§»é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19909v1" onclick="toggleFavorite(this, '2511.19909v1', 'Motion Marionette: Rethinking Rigid Motion Transfer via Prior Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction-matching">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction & Matching) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>50</td>
  <td><a href="./papers/251120157v3-skel-cf-coarse-to-fine-biomechanical-skeleton-and-surface-mesh-recov.html">SKEL-CF: Coarse-to-Fine Biomechanical Skeleton and Surface Mesh Recovery</a></td>
  <td>æå‡ºSKEL-CFæ¡†æ¶ï¼Œç”¨äºä»å›¾åƒä¸­æ¢å¤ç”Ÿç‰©åŠ›å­¦éª¨éª¼å’Œè¡¨é¢ç½‘æ ¼ï¼Œæå‡äººä½“è¿åŠ¨åˆ†æçš„çœŸå®æ€§ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20157v3" onclick="toggleFavorite(this, '2511.20157v3', 'SKEL-CF: Coarse-to-Fine Biomechanical Skeleton and Surface Mesh Recovery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)