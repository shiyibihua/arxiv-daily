---
layout: default
title: M$^3$Prune: Hierarchical Communication Graph Pruning for Efficient Multi-Modal Multi-Agent Retrieval-Augmented Generation
---

# M$^3$Prune: Hierarchical Communication Graph Pruning for Efficient Multi-Modal Multi-Agent Retrieval-Augmented Generation

**arXiv**: [2511.19969v1](https://arxiv.org/abs/2511.19969) | [PDF](https://arxiv.org/pdf/2511.19969.pdf)

**ä½œè€…**: Weizi Shao, Taolin Zhang, Zijie Zhou, Chen Chen, Chengyu Wang, Xiaofeng He

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMÂ³Pruneæ¡†æž¶ä»¥ä¼˜åŒ–å¤šæ¨¡æ€å¤šä»£ç†æ£€ç´¢å¢žå¼ºç”Ÿæˆçš„é€šä¿¡æ•ˆçŽ‡**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ£€ç´¢å¢žå¼ºç”Ÿæˆ` `å¤šä»£ç†ç³»ç»Ÿ` `å›¾å‰ªæž` `é€šä¿¡ä¼˜åŒ–` `ä»¤ç‰Œæ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šä»£ç†ç³»ç»Ÿå­˜åœ¨é«˜ä»¤ç‰Œå¼€é”€å’Œè®¡ç®—æˆæœ¬ï¼Œé˜»ç¢å¤§è§„æ¨¡éƒ¨ç½²ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å±‚æ¬¡åŒ–å›¾å‰ªæžï¼ŒåŽ»é™¤å†—ä½™è¾¹ï¼Œå¹³è¡¡æ€§èƒ½ä¸Žå¼€é”€ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºŽå•ä»£ç†å’Œå¤šä»£ç†ç³»ç»Ÿï¼Œæ˜¾è‘—å‡å°‘ä»¤ç‰Œæ¶ˆè€—ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advancements in multi-modal retrieval-augmented generation (mRAG), which enhance multi-modal large language models (MLLMs) with external knowledge, have demonstrated that the collective intelligence of multiple agents can significantly outperform a single model through effective communication. Despite impressive performance, existing multi-agent systems inherently incur substantial token overhead and increased computational costs, posing challenges for large-scale deployment. To address these issues, we propose a novel Multi-Modal Multi-agent hierarchical communication graph PRUNING framework, termed M$^3$Prune. Our framework eliminates redundant edges across different modalities, achieving an optimal balance between task performance and token overhead. Specifically, M$^3$Prune first applies intra-modal graph sparsification to textual and visual modalities, identifying the edges most critical for solving the task. Subsequently, we construct a dynamic communication topology using these key edges for inter-modal graph sparsification. Finally, we progressively prune redundant edges to obtain a more efficient and hierarchical topology. Extensive experiments on both general and domain-specific mRAG benchmarks demonstrate that our method consistently outperforms both single-agent and robust multi-agent mRAG systems while significantly reducing token consumption.

