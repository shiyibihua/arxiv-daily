---
layout: default
title: Simulated Self-Assessment in Large Language Models: A Psychometric Approach to AI Self-Efficacy
---

# Simulated Self-Assessment in Large Language Models: A Psychometric Approach to AI Self-Efficacy

**arXiv**: [2511.19872v1](https://arxiv.org/abs/2511.19872) | [PDF](https://arxiv.org/pdf/2511.19872.pdf)

**ä½œè€…**: Daniel I Jackson, Emma L Jensen, Syed-Amad Hussain, Emre Sezgin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¿ƒç†æµ‹é‡æç¤ºæ³•ä»¥è¯„ä¼°å¤§è¯­è¨€æ¨¡åž‹åœ¨ä»»åŠ¡ä¸­çš„æ¨¡æ‹Ÿè‡ªæˆ‘æ•ˆèƒ½**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹` `è‡ªæˆ‘æ•ˆèƒ½è¯„ä¼°` `å¿ƒç†æµ‹é‡æç¤º` `ä»»åŠ¡æ€§èƒ½` `äººæœºäº¤äº’` `æ¨¡åž‹å¯é æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è¯­è¨€æ¨¡åž‹çš„è‡ªæˆ‘è¯„ä¼°æ˜¯å¦å¯é åæ˜ å…¶å®žé™…èƒ½åŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ”¹ç¼–é€šç”¨è‡ªæˆ‘æ•ˆèƒ½é‡è¡¨ï¼Œåœ¨å››ç§æ¡ä»¶ä¸‹æµ‹è¯•åç§æ¨¡åž‹ã€‚
3. å®žéªŒæ•ˆæžœï¼šè‡ªæˆ‘è¯„ä¼°ç¨³å®šä½†æœªæ ¡å‡†ï¼Œé«˜è‡ªä¿¡æ¨¡åž‹æ€»ç»“èƒ½åŠ›å¼±ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Self-assessment is a key aspect of reliable intelligence, yet evaluations of large language models (LLMs) focus mainly on task accuracy. We adapted the 10-item General Self-Efficacy Scale (GSES) to elicit simulated self-assessments from ten LLMs across four conditions: no task, computational reasoning, social reasoning, and summarization. GSES responses were highly stable across repeated administrations and randomized item orders. However, models showed significantly different self-efficacy levels across conditions, with aggregate scores lower than human norms. All models achieved perfect accuracy on computational and social questions, whereas summarization performance varied widely. Self-assessment did not reliably reflect ability: several low-scoring models performed accurately, while some high-scoring models produced weaker summaries. Follow-up confidence prompts yielded modest, mostly downward revisions, suggesting mild overestimation in first-pass assessments. Qualitative analysis showed that higher self-efficacy corresponded to more assertive, anthropomorphic reasoning styles, whereas lower scores reflected cautious, de-anthropomorphized explanations. Psychometric prompting provides structured insight into LLM communication behavior but not calibrated performance estimates.

