---
layout: default
title: HiCoGen: Hierarchical Compositional Text-to-Image Generation in Diffusion Models via Reinforcement Learning
---

# HiCoGen: Hierarchical Compositional Text-to-Image Generation in Diffusion Models via Reinforcement Learning

**arXiv**: [2511.19965v1](https://arxiv.org/abs/2511.19965) | [PDF](https://arxiv.org/pdf/2511.19965.pdf)

**ä½œè€…**: Hongji Yang, Yucheng Zhou, Wencheng Han, Runzhou Tao, Zhongying Qiu, Jianfei Yang, Jianbing Shen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHiCoGenæ¡†æž¶ä»¥è§£å†³å¤æ‚æç¤ºä¸‹å›¾åƒç”Ÿæˆçš„æ¦‚å¿µé—æ¼ä¸Žç»„åˆæ€§é—®é¢˜**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `æ‰©æ•£æ¨¡åž‹` `å¼ºåŒ–å­¦ä¹ ` `å±‚æ¬¡ç»„åˆ` `æ¦‚å¿µåˆæˆ` `åŸºå‡†è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ‰©æ•£æ¨¡åž‹åœ¨å¤æ‚å¤šå¯¹è±¡æç¤ºä¸‹æ˜“å‡ºçŽ°æ¦‚å¿µé—æ¼ã€æ··æ·†å’Œç»„åˆæ€§å·®
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨LLMåˆ†è§£æç¤ºå¹¶è¿­ä»£åˆæˆï¼Œç»“åˆå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ç”Ÿæˆè¿‡ç¨‹
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨HiCoPromptåŸºå‡†ä¸Šæ˜¾è‘—æå‡æ¦‚å¿µè¦†ç›–çŽ‡å’Œç»„åˆå‡†ç¡®æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in diffusion models have demonstrated impressive capability in generating high-quality images for simple prompts. However, when confronted with complex prompts involving multiple objects and hierarchical structures, existing models struggle to accurately follow instructions, leading to issues such as concept omission, confusion, and poor compositionality. To address these limitations, we propose a Hierarchical Compositional Generative framework (HiCoGen) built upon a novel Chain of Synthesis (CoS) paradigm. Instead of monolithic generation, HiCoGen first leverages a Large Language Model (LLM) to decompose complex prompts into minimal semantic units. It then synthesizes these units iteratively, where the image generated in each step provides crucial visual context for the next, ensuring all textual concepts are faithfully constructed into the final scene. To further optimize this process, we introduce a reinforcement learning (RL) framework. Crucially, we identify that the limited exploration of standard diffusion samplers hinders effective RL. We theoretically prove that sample diversity is maximized by concentrating stochasticity in the early generation stages and, based on this insight, propose a novel Decaying Stochasticity Schedule to enhance exploration. Our RL algorithm is then guided by a hierarchical reward mechanism that jointly evaluates the image at the global, subject, and relationship levels. We also construct HiCoPrompt, a new text-to-image benchmark with hierarchical prompts for rigorous evaluation. Experiments show our approach significantly outperforms existing methods in both concept coverage and compositional accuracy.

