---
layout: default
title: Quantifying the Privacy Implications of High-Fidelity Synthetic Network Traffic
---

# Quantifying the Privacy Implications of High-Fidelity Synthetic Network Traffic

**arXiv**: [2511.20497v1](https://arxiv.org/abs/2511.20497) | [PDF](https://arxiv.org/pdf/2511.20497.pdf)

**ä½œè€…**: Van Tran, Shinan Liu, Tian Li, Nick Feamster

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»¼åˆéšç§æŒ‡æ ‡ä»¥è¯„ä¼°é«˜ä¿çœŸåˆæˆç½‘ç»œæµé‡çš„éšç§æ³„éœ²é£Žé™©**

**å…³é”®è¯**: `åˆæˆç½‘ç»œæµé‡` `éšç§æŒ‡æ ‡` `æˆå‘˜æŽ¨ç†æ”»å‡»` `æ•°æ®æå–æ”»å‡»` `ç”Ÿæˆæ¨¡åž‹è¯„ä¼°` `éšç§æ³„éœ²é£Žé™©`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåˆæˆç½‘ç»œæµé‡å¯èƒ½æ³„éœ²æ•æ„Ÿä¿¡æ¯ï¼Œéšç§é£Žé™©æœªå……åˆ†é‡åŒ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆæˆå‘˜æŽ¨ç†æ”»å‡»ã€æ•°æ®æå–æ”»å‡»åŠç½‘ç»œç‰¹å®šæ ‡è¯†ç¬¦æž„å»ºéšç§æŒ‡æ ‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè¯„ä¼°å¤šç§ç”Ÿæˆæ¨¡åž‹ï¼Œéšç§é£Žé™©å·®å¼‚å¤§ï¼Œæ”»å‡»æˆåŠŸçŽ‡æœ€é«˜è¾¾100%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> To address the scarcity and privacy concerns of network traffic data, various generative models have been developed to produce synthetic traffic. However, synthetic traffic is not inherently privacy-preserving, and the extent to which it leaks sensitive information, and how to measure such leakage, remain largely unexplored. This challenge is further compounded by the diversity of model architectures, which shape how traffic is represented and synthesized. We introduce a comprehensive set of privacy metrics for synthetic network traffic, combining standard approaches like membership inference attacks (MIA) and data extraction attacks with network-specific identifiers and attributes. Using these metrics, we systematically evaluate the vulnerability of different representative generative models and examine the factors that influence attack success. Our results reveal substantial variability in privacy risks across models and datasets. MIA success ranges from 0% to 88%, and up to 100% of network identifiers can be recovered from generated traffic, highlighting serious privacy vulnerabilities. We further identify key factors that significantly affect attack outcomes, including training data diversity and how well the generative model fits the training data. These findings provide actionable guidance for designing and deploying generative models that minimize privacy leakage, establishing a foundation for safer synthetic network traffic generation.

