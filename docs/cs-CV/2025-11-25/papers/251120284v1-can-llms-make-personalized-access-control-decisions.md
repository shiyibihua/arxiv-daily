---
layout: default
title: Can LLMs Make (Personalized) Access Control Decisions?
---

# Can LLMs Make (Personalized) Access Control Decisions?

**arXiv**: [2511.20284v1](https://arxiv.org/abs/2511.20284) | [PDF](https://arxiv.org/pdf/2511.20284.pdf)

**ä½œè€…**: Friederike Groschupp, Daniele Lain, Aritra Dhar, Lara Magdalena Lazier, Srdjan ÄŒapkun

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆ©ç”¨LLMè¿›è¡ŒåŠ¨æ€è®¿é—®æŽ§åˆ¶å†³ç­–ä»¥å‡è½»ç”¨æˆ·è®¤çŸ¥è´Ÿæ‹…ã€‚**

**å…³é”®è¯**: `è®¿é—®æŽ§åˆ¶å†³ç­–` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `ç”¨æˆ·éšç§åå¥½` `å®‰å…¨æƒè¡¡` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç³»ç»Ÿå¤æ‚æ€§å¢žåŠ å¯¼è‡´ç”¨æˆ·è®¿é—®æŽ§åˆ¶å†³ç­–è®¤çŸ¥è´Ÿæ‹…è¿‡é‡ã€‚
2. åˆ©ç”¨LLMå¤„ç†è‡ªç„¶è¯­è¨€åå¥½ï¼Œå®žçŽ°åŠ¨æ€ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥å†³ç­–ã€‚
3. ç”¨æˆ·ç ”ç©¶æ˜¾ç¤ºLLMå†³ç­–å‡†ç¡®çŽ‡è¾¾86%ï¼Œä½†ä¸ªæ€§åŒ–å¯èƒ½è¿åå®‰å…¨æœ€ä½³å®žè·µã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Precise access control decisions are crucial to the security of both traditional applications and emerging agent-based systems. Typically, these decisions are made by users during app installation or at runtime. Due to the increasing complexity and automation of systems, making these access control decisions can add a significant cognitive load on users, often overloading them and leading to suboptimal or even arbitrary access control decisions. To address this problem, we propose to leverage the processing and reasoning capabilities of large language models (LLMs) to make dynamic, context-aware decisions aligned with the user's security preferences. For this purpose, we conducted a user study, which resulted in a dataset of 307 natural-language privacy statements and 14,682 access control decisions made by users. We then compare these decisions against those made by two versions of LLMs: a general and a personalized one, for which we also gathered user feedback on 1,446 of its decisions.
>   Our results show that in general, LLMs can reflect users' preferences well, achieving up to 86\% accuracy when compared to the decision made by the majority of users. Our study also reveals a crucial trade-off in personalizing such a system: while providing user-specific privacy preferences to the LLM generally improves agreement with individual user decisions, adhering to those preferences can also violate some security best practices. Based on our findings, we discuss design and risk considerations for implementing a practical natural-language-based access control system that balances personalization, security, and utility.

