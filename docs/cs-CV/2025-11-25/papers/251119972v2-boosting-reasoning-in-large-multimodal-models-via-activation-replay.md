---
layout: default
title: Boosting Reasoning in Large Multimodal Models via Activation Replay
---

# Boosting Reasoning in Large Multimodal Models via Activation Replay

**arXiv**: [2511.19972v2](https://arxiv.org/abs/2511.19972) | [PDF](https://arxiv.org/pdf/2511.19972.pdf)

**ä½œè€…**: Yun Xing, Xiaobin Hu, Qingdong He, Jiangning Zhang, Shuicheng Yan, Shijian Lu, Yu-Gang Jiang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25 (æ›´æ–°: 2025-11-27)

**å¤‡æ³¨**: 11 figures, 10 tables

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºActivation Replayï¼Œé€šè¿‡æ¿€æ´»é‡æ”¾æå‡å¤§åž‹å¤šæ¨¡æ€æ¨¡åž‹æŽ¨ç†èƒ½åŠ›ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æŽ¨ç†` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `å¼ºåŒ–å­¦ä¹ ` `æ¿€æ´»é‡æ”¾` `ä½Žç†µæ¿€æ´»` `è§†è§‰æ™ºèƒ½ä½“` `è§†é¢‘ç†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•å¯¹RLVRæå‡LMMæŽ¨ç†èƒ½åŠ›çš„æœºåˆ¶ç†è§£ä¸è¶³ï¼Œç¼ºä¹æœ‰æ•ˆåˆ©ç”¨æ¿€æ´»ä¿¡æ¯çš„ç­–ç•¥ã€‚
2. æå‡ºActivation Replayï¼Œé€šè¿‡é‡æ”¾ä½Žç†µæ¿€æ´»æ¥è°ƒèŠ‚RLVRåŽçš„LMMï¼Œæå‡æŽ¨ç†èƒ½åŠ›ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒActivation Replayåœ¨å¤šç§æŽ¨ç†ä»»åŠ¡ä¸Šæœ‰æ•ˆï¼Œæå‡Pass@KæŒ‡æ ‡ï¼Œå¹¶æ‰©å¤§æŽ¨ç†è¦†ç›–èŒƒå›´ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ—¨åœ¨æ·±å…¥ç†è§£ä½¿ç”¨å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ (RLVR)æå‡å¤§åž‹å¤šæ¨¡æ€æ¨¡åž‹(LMMs)æŽ¨ç†èƒ½åŠ›çš„å†…åœ¨æœºåˆ¶ã€‚é€šè¿‡logit lensè§†è§’ï¼Œç ”ç©¶å‘çŽ°RLVRä¸»è¦å½±å“ä½Žç†µæ¿€æ´»ï¼Œè€Œå¯¹é«˜ç†µæ¿€æ´»å½±å“è¾ƒå°ã€‚å—æ­¤å¯å‘ï¼Œè®ºæ–‡æå‡ºActivation Replayï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼Œé€šè¿‡åœ¨æµ‹è¯•æ—¶æ“çºµè§†è§‰tokensï¼Œé‡æ”¾æ¥è‡ªåŸºç¡€LMMè¾“å…¥ä¸Šä¸‹æ–‡çš„ä½Žç†µæ¿€æ´»ï¼Œä»¥è°ƒèŠ‚RLVRåŽçš„æ¨¡åž‹ï¼Œä»Žè€Œæå‡å¤šæ¨¡æ€æŽ¨ç†èƒ½åŠ›ã€‚å®žéªŒè¡¨æ˜Žï¼ŒActivation Replayåœ¨æ•°å­¦ã€è§†è§‰æ™ºèƒ½ä½“å’Œè§†é¢‘æŽ¨ç†ç­‰åœºæ™¯ä¸­å‡èƒ½æœ‰æ•ˆæå‡æŽ¨ç†èƒ½åŠ›ï¼Œæé«˜Pass@KæŒ‡æ ‡ï¼Œå¹¶ç¼“è§£RLVRå¸¦æ¥çš„æŽ¨ç†è¦†ç›–èŒƒå›´ç¼©å°é—®é¢˜ã€‚å¯¹æ¯”å®žéªŒéªŒè¯äº†é‡æ”¾ä½Žç†µæ¿€æ´»ä¼˜äºŽé«˜ç†µæ¿€æ´»ï¼Œä»¥åŠæ“çºµè¾“å…¥tokensä¼˜äºŽç›´æŽ¥è·¨æ¨¡åž‹å¹²é¢„ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§åž‹å¤šæ¨¡æ€æ¨¡åž‹ï¼ˆLMMsï¼‰åœ¨ç»è¿‡åŸºäºŽå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰åŽï¼Œå…¶æŽ¨ç†èƒ½åŠ›æå‡çš„å†…åœ¨æœºåˆ¶ä¸æ˜Žç¡®çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ç¼ºä¹å¯¹RLVRå¦‚ä½•å½±å“æ¨¡åž‹å†…éƒ¨æ¿€æ´»çš„æ·±å…¥ç†è§£ï¼Œä»¥åŠå¦‚ä½•æœ‰æ•ˆåˆ©ç”¨è¿™äº›æ¿€æ´»ä¿¡æ¯æ¥è¿›ä¸€æ­¥æå‡æŽ¨ç†èƒ½åŠ›ã€‚RLVRè™½ç„¶èƒ½æå‡æŽ¨ç†èƒ½åŠ›ï¼Œä½†ä¹Ÿå¯èƒ½å¯¼è‡´æŽ¨ç†è¦†ç›–èŒƒå›´ç¼©å°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è§‚å¯Ÿåˆ°RLVRä¸»è¦å½±å“ä½Žç†µæ¿€æ´»ï¼Œè€Œå¯¹é«˜ç†µæ¿€æ´»å½±å“è¾ƒå°ã€‚åŸºäºŽæ­¤ï¼Œè®ºæ–‡æå‡ºé€šè¿‡åœ¨æµ‹è¯•æ—¶é‡æ”¾ä½Žç†µæ¿€æ´»æ¥è°ƒèŠ‚RLVRåŽçš„æ¨¡åž‹ï¼Œä»Žè€Œåœ¨ä¸è¿›è¡Œé¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹æå‡æŽ¨ç†èƒ½åŠ›ã€‚è¿™ç§æ€è·¯çš„åˆç†æ€§åœ¨äºŽï¼Œä½Žç†µæ¿€æ´»å¯èƒ½åŒ…å«æ¨¡åž‹æŽ¨ç†è¿‡ç¨‹ä¸­æ›´å…³é”®çš„ä¿¡æ¯ï¼Œé€šè¿‡é‡æ”¾è¿™äº›æ¿€æ´»å¯ä»¥å¼•å¯¼æ¨¡åž‹è¿›è¡Œæ›´å‡†ç¡®çš„æŽ¨ç†ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šActivation Replayçš„æŠ€æœ¯æ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) ä½¿ç”¨åŸºç¡€LMMå¤„ç†è¾“å…¥ä¸Šä¸‹æ–‡ï¼ŒèŽ·å–ä½Žç†µæ¿€æ´»ï¼›2) ä½¿ç”¨RLVRåŽçš„LMMå¤„ç†ç›¸åŒçš„è¾“å…¥ä¸Šä¸‹æ–‡ï¼›3) åœ¨RLVRåŽçš„LMMä¸­ï¼Œé€šè¿‡æ“çºµè§†è§‰tokensï¼Œé‡æ”¾æ¥è‡ªåŸºç¡€LMMçš„ä½Žç†µæ¿€æ´»ï¼›4) ä½¿ç”¨é‡æ”¾æ¿€æ´»åŽçš„RLVRæ¨¡åž‹è¿›è¡ŒæŽ¨ç†å¹¶è¾“å‡ºç»“æžœã€‚æ•´ä¸ªè¿‡ç¨‹æ— éœ€è®­ç»ƒï¼Œä»…åœ¨æµ‹è¯•é˜¶æ®µè¿›è¡Œã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºActivation Replayè¿™ä¸€ç®€å•è€Œæœ‰æ•ˆçš„è®­ç»ƒ-freeæ–¹æ³•ï¼Œé€šè¿‡é‡æ”¾ä½Žç†µæ¿€æ´»æ¥æå‡LMMçš„æŽ¨ç†èƒ½åŠ›ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒActivation Replayä¸éœ€è¦é¢å¤–çš„è®­ç»ƒï¼Œå¯ä»¥ç›´æŽ¥åº”ç”¨äºŽå·²ç»ç»è¿‡RLVRè®­ç»ƒçš„æ¨¡åž‹ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é€šè¿‡å®žéªŒéªŒè¯äº†é‡æ”¾ä½Žç†µæ¿€æ´»ä¼˜äºŽé‡æ”¾é«˜ç†µæ¿€æ´»ï¼Œä»¥åŠæ“çºµè¾“å…¥tokensä¼˜äºŽç›´æŽ¥è·¨æ¨¡åž‹å¹²é¢„ã€‚

**å…³é”®è®¾è®¡**ï¼šActivation Replayçš„å…³é”®è®¾è®¡åœ¨äºŽå¦‚ä½•é€‰æ‹©å’Œé‡æ”¾ä½Žç†µæ¿€æ´»ã€‚è®ºæ–‡é€šè¿‡è®¡ç®—è§†è§‰tokensçš„ç†µå€¼æ¥é€‰æ‹©ä½Žç†µæ¿€æ´»ï¼Œå…·ä½“å®žçŽ°ç»†èŠ‚æœªçŸ¥ã€‚é‡æ”¾çš„æ–¹å¼æ˜¯é€šè¿‡æ“çºµè§†è§‰tokensï¼Œå°†åŸºç¡€LMMçš„ä½Žç†µæ¿€æ´»æ³¨å…¥åˆ°RLVRåŽçš„LMMä¸­ã€‚å…·ä½“æ“çºµæ–¹å¼å’Œå‚æ•°è®¾ç½®æœªçŸ¥ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒActivation Replayåœ¨æ•°å­¦ã€è§†è§‰æ™ºèƒ½ä½“å’Œè§†é¢‘æŽ¨ç†ç­‰å¤šç§åœºæ™¯ä¸­å‡èƒ½æœ‰æ•ˆæå‡æŽ¨ç†èƒ½åŠ›ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›ä»»åŠ¡ä¸Šï¼ŒPass@KæŒ‡æ ‡å¾—åˆ°äº†æ˜¾è‘—æå‡ï¼Œå¹¶ä¸”ç¼“è§£äº†RLVRå¸¦æ¥çš„æŽ¨ç†è¦†ç›–èŒƒå›´ç¼©å°é—®é¢˜ã€‚å¯¹æ¯”å®žéªŒéªŒè¯äº†é‡æ”¾ä½Žç†µæ¿€æ´»ä¼˜äºŽé«˜ç†µæ¿€æ´»ï¼Œä»¥åŠæ“çºµè¾“å…¥tokensä¼˜äºŽç›´æŽ¥è·¨æ¨¡åž‹å¹²é¢„ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

Activation Replayå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ä»¥åº”ç”¨äºŽå„ç§éœ€è¦å¤šæ¨¡æ€æŽ¨ç†çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ç­‰ã€‚è¯¥æ–¹æ³•æ— éœ€é¢å¤–è®­ç»ƒï¼Œå¯ä»¥å¿«é€Ÿæå‡çŽ°æœ‰LMMçš„æŽ¨ç†èƒ½åŠ›ï¼Œå…·æœ‰å¾ˆé«˜çš„å®žé™…åº”ç”¨ä»·å€¼ã€‚æœªæ¥å¯ä»¥æŽ¢ç´¢å¦‚ä½•æ›´æœ‰æ•ˆåœ°é€‰æ‹©å’Œé‡æ”¾æ¿€æ´»ï¼Œä»¥åŠå¦‚ä½•å°†Activation Replayä¸Žå…¶ä»–æŽ¨ç†å¢žå¼ºæŠ€æœ¯ç›¸ç»“åˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recently, Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an effective approach to incentivizing reasoning capability in Large Multimodal Models (LMMs), while the underlying mechanisms behind this post-training paradigm are poorly understood. We begin by exploring how input activations are affected by RLVR through the perspective of logit lens. Our systematic investigations across multiple post-trained LMMs suggest that RLVR shifts low-entropy activations unexpectedly, while high-entropy ones are less affected. We further demonstrate that such phenomena are associated with LMM reasoning by controlled experiments, suggesting a potentially beneficial role of modulating low-entropy activations. To this end, we propose Activation Replay, a novel simple yet effective training-free approach that boosts multimodal reasoning of post-trained LMMs without requiring expensive policy optimization. Our design involves manipulation of visual tokens at test time, replaying low-entropy activations from the input context of base LMMs to regulating the RLVR counterparts. Activation Replay triggers better reasoning across diverse scenarios, including mathematics, o3-like visual agents, and video reasoning. We further show that Activation Replay boosts Pass@K and mitigates narrower reasoning coverage of RLVR. Our design is compared against alternative choices, such as replaying high-entropy activations instead of low-entropy ones, or direct cross-model intervention instead of manipulating input tokens, demonstrating the superiority of our implementation. Codes will be made publicly available.

