---
layout: default
title: Boosting Reasoning in Large Multimodal Models via Activation Replay
---

# Boosting Reasoning in Large Multimodal Models via Activation Replay

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.19972" target="_blank" class="toolbar-btn">arXiv: 2511.19972v2</a>
    <a href="https://arxiv.org/pdf/2511.19972.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.19972v2" 
            onclick="toggleFavorite(this, '2511.19972v2', 'Boosting Reasoning in Large Multimodal Models via Activation Replay')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yun Xing, Xiaobin Hu, Qingdong He, Jiangning Zhang, Shuicheng Yan, Shijian Lu, Yu-Gang Jiang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-25 (Êõ¥Êñ∞: 2025-11-27)

**Â§áÊ≥®**: 11 figures, 10 tables

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Activation ReplayÔºåÈÄöËøáÊøÄÊ¥ªÈáçÊîæÊèêÂçáÂ§ßÂûãÂ§öÊ®°ÊÄÅÊ®°ÂûãÊé®ÁêÜËÉΩÂäõÔºåÊó†ÈúÄÈ¢ùÂ§ñËÆ≠ÁªÉ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÊé®ÁêÜ` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Âº∫ÂåñÂ≠¶‰π†` `ÊøÄÊ¥ªÈáçÊîæ` `‰ΩéÁÜµÊøÄÊ¥ª` `ËßÜËßâÊô∫ËÉΩ‰Ωì` `ËßÜÈ¢ëÁêÜËß£`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂØπRLVRÊèêÂçáLMMÊé®ÁêÜËÉΩÂäõÁöÑÊú∫Âà∂ÁêÜËß£‰∏çË∂≥ÔºåÁº∫‰πèÊúâÊïàÂà©Áî®ÊøÄÊ¥ª‰ø°ÊÅØÁöÑÁ≠ñÁï•„ÄÇ
2. ÊèêÂá∫Activation ReplayÔºåÈÄöËøáÈáçÊîæ‰ΩéÁÜµÊøÄÊ¥ªÊù•Ë∞ÉËäÇRLVRÂêéÁöÑLMMÔºåÊèêÂçáÊé®ÁêÜËÉΩÂäõÔºåÊó†ÈúÄÈ¢ùÂ§ñËÆ≠ÁªÉ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåActivation ReplayÂú®Â§öÁßçÊé®ÁêÜ‰ªªÂä°‰∏äÊúâÊïàÔºåÊèêÂçáPass@KÊåáÊ†áÔºåÂπ∂Êâ©Â§ßÊé®ÁêÜË¶ÜÁõñËåÉÂõ¥„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊó®Âú®Ê∑±ÂÖ•ÁêÜËß£‰ΩøÁî®ÂèØÈ™åËØÅÂ•ñÂä±ÁöÑÂº∫ÂåñÂ≠¶‰π†(RLVR)ÊèêÂçáÂ§ßÂûãÂ§öÊ®°ÊÄÅÊ®°Âûã(LMMs)Êé®ÁêÜËÉΩÂäõÁöÑÂÜÖÂú®Êú∫Âà∂„ÄÇÈÄöËøálogit lensËßÜËßíÔºåÁ†îÁ©∂ÂèëÁé∞RLVR‰∏ªË¶ÅÂΩ±Âìç‰ΩéÁÜµÊøÄÊ¥ªÔºåËÄåÂØπÈ´òÁÜµÊøÄÊ¥ªÂΩ±ÂìçËæÉÂ∞è„ÄÇÂèóÊ≠§ÂêØÂèëÔºåËÆ∫ÊñáÊèêÂá∫Activation ReplayÔºå‰∏ÄÁßçÊó†ÈúÄËÆ≠ÁªÉÁöÑÊñπÊ≥ïÔºåÈÄöËøáÂú®ÊµãËØïÊó∂ÊìçÁ∫µËßÜËßâtokensÔºåÈáçÊîæÊù•Ëá™Âü∫Á°ÄLMMËæìÂÖ•‰∏ä‰∏ãÊñáÁöÑ‰ΩéÁÜµÊøÄÊ¥ªÔºå‰ª•Ë∞ÉËäÇRLVRÂêéÁöÑÊ®°ÂûãÔºå‰ªéËÄåÊèêÂçáÂ§öÊ®°ÊÄÅÊé®ÁêÜËÉΩÂäõ„ÄÇÂÆûÈ™åË°®ÊòéÔºåActivation ReplayÂú®Êï∞Â≠¶„ÄÅËßÜËßâÊô∫ËÉΩ‰ΩìÂíåËßÜÈ¢ëÊé®ÁêÜÁ≠âÂú∫ÊôØ‰∏≠ÂùáËÉΩÊúâÊïàÊèêÂçáÊé®ÁêÜËÉΩÂäõÔºåÊèêÈ´òPass@KÊåáÊ†áÔºåÂπ∂ÁºìËß£RLVRÂ∏¶Êù•ÁöÑÊé®ÁêÜË¶ÜÁõñËåÉÂõ¥Áº©Â∞èÈóÆÈ¢ò„ÄÇÂØπÊØîÂÆûÈ™åÈ™åËØÅ‰∫ÜÈáçÊîæ‰ΩéÁÜµÊøÄÊ¥ª‰ºò‰∫éÈ´òÁÜµÊøÄÊ¥ªÔºå‰ª•ÂèäÊìçÁ∫µËæìÂÖ•tokens‰ºò‰∫éÁõ¥Êé•Ë∑®Ê®°ÂûãÂπ≤È¢Ñ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßÂûãÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºàLMMsÔºâÂú®ÁªèËøáÂü∫‰∫éÂèØÈ™åËØÅÂ•ñÂä±ÁöÑÂº∫ÂåñÂ≠¶‰π†ÔºàRLVRÔºâÂêéÔºåÂÖ∂Êé®ÁêÜËÉΩÂäõÊèêÂçáÁöÑÂÜÖÂú®Êú∫Âà∂‰∏çÊòéÁ°ÆÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèÂØπRLVRÂ¶Ç‰ΩïÂΩ±ÂìçÊ®°ÂûãÂÜÖÈÉ®ÊøÄÊ¥ªÁöÑÊ∑±ÂÖ•ÁêÜËß£Ôºå‰ª•ÂèäÂ¶Ç‰ΩïÊúâÊïàÂà©Áî®Ëøô‰∫õÊøÄÊ¥ª‰ø°ÊÅØÊù•Ëøõ‰∏ÄÊ≠•ÊèêÂçáÊé®ÁêÜËÉΩÂäõ„ÄÇRLVRËôΩÁÑ∂ËÉΩÊèêÂçáÊé®ÁêÜËÉΩÂäõÔºå‰ΩÜ‰πüÂèØËÉΩÂØºËá¥Êé®ÁêÜË¶ÜÁõñËåÉÂõ¥Áº©Â∞è„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØËßÇÂØüÂà∞RLVR‰∏ªË¶ÅÂΩ±Âìç‰ΩéÁÜµÊøÄÊ¥ªÔºåËÄåÂØπÈ´òÁÜµÊøÄÊ¥ªÂΩ±ÂìçËæÉÂ∞è„ÄÇÂü∫‰∫éÊ≠§ÔºåËÆ∫ÊñáÊèêÂá∫ÈÄöËøáÂú®ÊµãËØïÊó∂ÈáçÊîæ‰ΩéÁÜµÊøÄÊ¥ªÊù•Ë∞ÉËäÇRLVRÂêéÁöÑÊ®°ÂûãÔºå‰ªéËÄåÂú®‰∏çËøõË°åÈ¢ùÂ§ñËÆ≠ÁªÉÁöÑÊÉÖÂÜµ‰∏ãÊèêÂçáÊé®ÁêÜËÉΩÂäõ„ÄÇËøôÁßçÊÄùË∑ØÁöÑÂêàÁêÜÊÄßÂú®‰∫éÔºå‰ΩéÁÜµÊøÄÊ¥ªÂèØËÉΩÂåÖÂê´Ê®°ÂûãÊé®ÁêÜËøáÁ®ã‰∏≠Êõ¥ÂÖ≥ÈîÆÁöÑ‰ø°ÊÅØÔºåÈÄöËøáÈáçÊîæËøô‰∫õÊøÄÊ¥ªÂèØ‰ª•ÂºïÂØºÊ®°ÂûãËøõË°åÊõ¥ÂáÜÁ°ÆÁöÑÊé®ÁêÜ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöActivation ReplayÁöÑÊäÄÊúØÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê≠•È™§Ôºö1) ‰ΩøÁî®Âü∫Á°ÄLMMÂ§ÑÁêÜËæìÂÖ•‰∏ä‰∏ãÊñáÔºåËé∑Âèñ‰ΩéÁÜµÊøÄÊ¥ªÔºõ2) ‰ΩøÁî®RLVRÂêéÁöÑLMMÂ§ÑÁêÜÁõ∏ÂêåÁöÑËæìÂÖ•‰∏ä‰∏ãÊñáÔºõ3) Âú®RLVRÂêéÁöÑLMM‰∏≠ÔºåÈÄöËøáÊìçÁ∫µËßÜËßâtokensÔºåÈáçÊîæÊù•Ëá™Âü∫Á°ÄLMMÁöÑ‰ΩéÁÜµÊøÄÊ¥ªÔºõ4) ‰ΩøÁî®ÈáçÊîæÊøÄÊ¥ªÂêéÁöÑRLVRÊ®°ÂûãËøõË°åÊé®ÁêÜÂπ∂ËæìÂá∫ÁªìÊûú„ÄÇÊï¥‰∏™ËøáÁ®ãÊó†ÈúÄËÆ≠ÁªÉÔºå‰ªÖÂú®ÊµãËØïÈò∂ÊÆµËøõË°å„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫Activation ReplayËøô‰∏ÄÁÆÄÂçïËÄåÊúâÊïàÁöÑËÆ≠ÁªÉ-freeÊñπÊ≥ïÔºåÈÄöËøáÈáçÊîæ‰ΩéÁÜµÊøÄÊ¥ªÊù•ÊèêÂçáLMMÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåActivation Replay‰∏çÈúÄË¶ÅÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉÔºåÂèØ‰ª•Áõ¥Êé•Â∫îÁî®‰∫éÂ∑≤ÁªèÁªèËøáRLVRËÆ≠ÁªÉÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÈÄöËøáÂÆûÈ™åÈ™åËØÅ‰∫ÜÈáçÊîæ‰ΩéÁÜµÊøÄÊ¥ª‰ºò‰∫éÈáçÊîæÈ´òÁÜµÊøÄÊ¥ªÔºå‰ª•ÂèäÊìçÁ∫µËæìÂÖ•tokens‰ºò‰∫éÁõ¥Êé•Ë∑®Ê®°ÂûãÂπ≤È¢Ñ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöActivation ReplayÁöÑÂÖ≥ÈîÆËÆæËÆ°Âú®‰∫éÂ¶Ç‰ΩïÈÄâÊã©ÂíåÈáçÊîæ‰ΩéÁÜµÊøÄÊ¥ª„ÄÇËÆ∫ÊñáÈÄöËøáËÆ°ÁÆóËßÜËßâtokensÁöÑÁÜµÂÄºÊù•ÈÄâÊã©‰ΩéÁÜµÊøÄÊ¥ªÔºåÂÖ∑‰ΩìÂÆûÁé∞ÁªÜËäÇÊú™Áü•„ÄÇÈáçÊîæÁöÑÊñπÂºèÊòØÈÄöËøáÊìçÁ∫µËßÜËßâtokensÔºåÂ∞ÜÂü∫Á°ÄLMMÁöÑ‰ΩéÁÜµÊøÄÊ¥ªÊ≥®ÂÖ•Âà∞RLVRÂêéÁöÑLMM‰∏≠„ÄÇÂÖ∑‰ΩìÊìçÁ∫µÊñπÂºèÂíåÂèÇÊï∞ËÆæÁΩÆÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåActivation ReplayÂú®Êï∞Â≠¶„ÄÅËßÜËßâÊô∫ËÉΩ‰ΩìÂíåËßÜÈ¢ëÊé®ÁêÜÁ≠âÂ§öÁßçÂú∫ÊôØ‰∏≠ÂùáËÉΩÊúâÊïàÊèêÂçáÊé®ÁêÜËÉΩÂäõ„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∫õ‰ªªÂä°‰∏äÔºåPass@KÊåáÊ†áÂæóÂà∞‰∫ÜÊòæËëóÊèêÂçáÔºåÂπ∂‰∏îÁºìËß£‰∫ÜRLVRÂ∏¶Êù•ÁöÑÊé®ÁêÜË¶ÜÁõñËåÉÂõ¥Áº©Â∞èÈóÆÈ¢ò„ÄÇÂØπÊØîÂÆûÈ™åÈ™åËØÅ‰∫ÜÈáçÊîæ‰ΩéÁÜµÊøÄÊ¥ª‰ºò‰∫éÈ´òÁÜµÊøÄÊ¥ªÔºå‰ª•ÂèäÊìçÁ∫µËæìÂÖ•tokens‰ºò‰∫éÁõ¥Êé•Ë∑®Ê®°ÂûãÂπ≤È¢Ñ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Activation ReplayÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØ‰ª•Â∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÂ§öÊ®°ÊÄÅÊé®ÁêÜÁöÑÂú∫ÊôØÔºå‰æãÂ¶ÇÊô∫ËÉΩÂÆ¢Êúç„ÄÅËá™Âä®È©æÈ©∂„ÄÅÂåªÁñóËØäÊñ≠Á≠â„ÄÇËØ•ÊñπÊ≥ïÊó†ÈúÄÈ¢ùÂ§ñËÆ≠ÁªÉÔºåÂèØ‰ª•Âø´ÈÄüÊèêÂçáÁé∞ÊúâLMMÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂÖ∑ÊúâÂæàÈ´òÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄº„ÄÇÊú™Êù•ÂèØ‰ª•Êé¢Á¥¢Â¶Ç‰ΩïÊõ¥ÊúâÊïàÂú∞ÈÄâÊã©ÂíåÈáçÊîæÊøÄÊ¥ªÔºå‰ª•ÂèäÂ¶Ç‰ΩïÂ∞ÜActivation Replay‰∏éÂÖ∂‰ªñÊé®ÁêÜÂ¢ûÂº∫ÊäÄÊúØÁõ∏ÁªìÂêà„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recently, Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an effective approach to incentivizing reasoning capability in Large Multimodal Models (LMMs), while the underlying mechanisms behind this post-training paradigm are poorly understood. We begin by exploring how input activations are affected by RLVR through the perspective of logit lens. Our systematic investigations across multiple post-trained LMMs suggest that RLVR shifts low-entropy activations unexpectedly, while high-entropy ones are less affected. We further demonstrate that such phenomena are associated with LMM reasoning by controlled experiments, suggesting a potentially beneficial role of modulating low-entropy activations. To this end, we propose Activation Replay, a novel simple yet effective training-free approach that boosts multimodal reasoning of post-trained LMMs without requiring expensive policy optimization. Our design involves manipulation of visual tokens at test time, replaying low-entropy activations from the input context of base LMMs to regulating the RLVR counterparts. Activation Replay triggers better reasoning across diverse scenarios, including mathematics, o3-like visual agents, and video reasoning. We further show that Activation Replay boosts Pass@K and mitigates narrower reasoning coverage of RLVR. Our design is compared against alternative choices, such as replaying high-entropy activations instead of low-entropy ones, or direct cross-model intervention instead of manipulating input tokens, demonstrating the superiority of our implementation. Codes will be made publicly available.

