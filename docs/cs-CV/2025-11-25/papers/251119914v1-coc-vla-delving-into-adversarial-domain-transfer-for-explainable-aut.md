---
layout: default
title: CoC-VLA: Delving into Adversarial Domain Transfer for Explainable Autonomous Driving via Chain-of-Causality Visual-Language-Action Model
---

# CoC-VLA: Delving into Adversarial Domain Transfer for Explainable Autonomous Driving via Chain-of-Causality Visual-Language-Action Model

**arXiv**: [2511.19914v1](https://arxiv.org/abs/2511.19914) | [PDF](https://arxiv.org/pdf/2511.19914.pdf)

**ä½œè€…**: Dapeng Zhang, Fei Shen, Rui Zhao, Yinda Chen, Peng Zhi, Chenyang Li, Rui Zhou, Qingguo Zhou

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoC-VLAæ¡†æž¶ï¼Œé€šè¿‡å¯¹æŠ—åŸŸè¿ç§»è§£å†³è‡ªåŠ¨é©¾é©¶é•¿å°¾åœºæ™¯å¤„ç†é—®é¢˜**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `å¯¹æŠ—åŸŸè¿ç§»` `è§†è§‰è¯­è¨€æ¨¡åž‹` `é•¿å°¾åœºæ™¯å¤„ç†` `é“¾å¼å› æžœæŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•éš¾ä»¥æ•´åˆä»¿çœŸä¸ŽçœŸå®žä¸–ç•Œæ•°æ®çš„é•¿å°¾åœºæ™¯å¤„ç†ä¼˜åŠ¿
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ•™å¸ˆ-å­¦ç”ŸVLMæ¨¡åž‹å’Œåˆ¤åˆ«å™¨ï¼Œå®žçŽ°ä»¿çœŸåˆ°çœŸå®žä¸–ç•Œçš„å¯¹æŠ—è¿ç§»
3. å®žéªŒæˆ–æ•ˆæžœï¼šæœªçŸ¥ï¼Œä½†æ¡†æž¶æ—¨åœ¨æå‡è‡ªåŠ¨é©¾é©¶åœ¨å¤æ‚åœºæ™¯ä¸­çš„æŽ¨ç†å’Œå¯è§£é‡Šæ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Autonomous driving represents a prominent application of artificial intelligence. Recent approaches have shifted from focusing solely on common scenarios to addressing complex, long-tail situations such as subtle human behaviors, traffic accidents, and non-compliant driving patterns. Given the demonstrated capabilities of large language models (LLMs) in understanding visual and natural language inputs and following instructions, recent methods have integrated LLMs into autonomous driving systems to enhance reasoning, interpretability, and performance across diverse scenarios. However, existing methods typically rely either on real-world data, which is suitable for industrial deployment, or on simulation data tailored to rare or hard case scenarios. Few approaches effectively integrate the complementary advantages of both data sources. To address this limitation, we propose a novel VLM-guided, end-to-end adversarial transfer framework for autonomous driving that transfers long-tail handling capabilities from simulation to real-world deployment, named CoC-VLA. The framework comprises a teacher VLM model, a student VLM model, and a discriminator. Both the teacher and student VLM models utilize a shared base architecture, termed the Chain-of-Causality Visual-Language Model (CoC VLM), which integrates temporal information via an end-to-end text adapter. This architecture supports chain-of-thought reasoning to infer complex driving logic. The teacher and student VLM models are pre-trained separately on simulated and real-world datasets. The discriminator is trained adversarially to facilitate the transfer of long-tail handling capabilities from simulated to real-world environments by the student VLM model, using a novel backpropagation strategy.

