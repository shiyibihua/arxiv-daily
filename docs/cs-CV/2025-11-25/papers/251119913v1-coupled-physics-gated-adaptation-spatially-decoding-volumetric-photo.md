---
layout: default
title: Coupled Physics-Gated Adaptation: Spatially Decoding Volumetric Photochemical Conversion in Complex 3D-Printed Objects
---

# Coupled Physics-Gated Adaptation: Spatially Decoding Volumetric Photochemical Conversion in Complex 3D-Printed Objects

**arXiv**: [2511.19913v1](https://arxiv.org/abs/2511.19913) | [PDF](https://arxiv.org/pdf/2511.19913.pdf)

**ä½œè€…**: Maryam Eftekharifar, Churun Zhang, Jialiang Wei, Xudong Cao, Hossein Heidari

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºC-PGAæ¡†æž¶ä»¥é¢„æµ‹å¤æ‚3Dæ‰“å°ç‰©ä½“çš„å…‰åŒ–å­¦è½¬åŒ–çŠ¶æ€**

**å…³é”®è¯**: `3Dè§†è§‰é¢„æµ‹` `å¤šæ¨¡æ€èžåˆ` `ç‰©ç†å¼•å¯¼è°ƒåˆ¶` `å…‰åŒ–å­¦è½¬åŒ–` `ä½“ç§¯å±žæ€§ä¼°è®¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä»Ž3Dè§†è§‰æ•°æ®é¢„æµ‹éžè§†è§‰ä½“ç§¯ç‰©ç†å±žæ€§ï¼Œä¼ ç»Ÿæ¨¡åž‹ç¼ºä¹ç‰©ç†è€¦åˆåç½®
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å‡ ä½•å’Œè¿‡ç¨‹å‚æ•°ä½œä¸ºQueryï¼Œé€šè¿‡FiLMåŠ¨æ€é—¨æŽ§å’Œè°ƒåˆ¶åŒ3Dè§†è§‰æµ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåŸºäºŽæœ€å¤§å…‰å­¦æ‰“å°æ•°æ®é›†ï¼Œå®žçŽ°è™šæ‹ŸåŒ–å­¦è¡¨å¾ï¼Œæ— éœ€åŽæ‰“å°æµ‹é‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present a framework that pioneers the prediction of photochemical conversion in complex three-dimensionally printed objects, introducing a challenging new computer vision task: predicting dense, non-visual volumetric physical properties from 3D visual data. This approach leverages the largest-ever optically printed 3D specimen dataset, comprising a large family of parametrically designed complex minimal surface structures that have undergone terminal chemical characterisation. Conventional vision models are ill-equipped for this task, as they lack an inductive bias for the coupled, non-linear interactions of optical physics (diffraction, absorption) and material physics (diffusion, convection) that govern the final chemical state. To address this, we propose Coupled Physics-Gated Adaptation (C-PGA), a novel multimodal fusion architecture. Unlike standard concatenation, C-PGA explicitly models physical coupling by using sparse geometrical and process parameters (e.g., surface transport, print layer height) as a Query to dynamically gate and adapt the dense visual features via feature-wise linear modulation (FiLM). This mechanism spatially modulates dual 3D visual streams-extracted by parallel 3D-CNNs processing raw projection stacks and their diffusion-diffraction corrected counterparts allowing the model to recalibrate its visual perception based on the physical context. This approach offers a breakthrough in virtual chemical characterisation, eliminating the need for traditional post-print measurements and enabling precise control over the chemical conversion state.

