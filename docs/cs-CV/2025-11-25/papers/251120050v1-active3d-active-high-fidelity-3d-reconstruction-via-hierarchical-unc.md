---
layout: default
title: Active3D: Active High-Fidelity 3D Reconstruction via Hierarchical Uncertainty Quantification
---

# Active3D: Active High-Fidelity 3D Reconstruction via Hierarchical Uncertainty Quantification

**arXiv**: [2511.20050v1](https://arxiv.org/abs/2511.20050) | [PDF](https://arxiv.org/pdf/2511.20050.pdf)

**ä½œè€…**: Yan Li, Yingzhao Li, Gim Hee Lee

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸»åŠ¨æŽ¢ç´¢æ¡†æž¶ä»¥è§£å†³é«˜ä¿çœŸ3Dé‡å»ºé—®é¢˜**

**å…³é”®è¯**: `ä¸»åŠ¨3Dé‡å»º` `ä¸ç¡®å®šæ€§é‡åŒ–` `æ··åˆè¡¨ç¤º` `ä¸‹ä¸€æœ€ä½³è§†è§’è§„åˆ’` `æœºå™¨äººæ„ŸçŸ¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•åœ¨ä¸»åŠ¨æŽ¢ç´¢ä¸­é«˜æ•ˆé‡å»ºé«˜ä¿çœŸ3Dåœºæ™¯
2. æ–¹æ³•è¦ç‚¹ï¼šèžåˆéšå¼-æ˜¾å¼è¡¨ç¤ºå’Œåˆ†å±‚ä¸ç¡®å®šæ€§é‡åŒ–
3. å®žéªŒæ•ˆæžœï¼šåœ¨åŸºå‡†æµ‹è¯•ä¸­å®žçŽ°é«˜ç²¾åº¦ã€å®Œæ•´æ€§å’Œæ¸²æŸ“è´¨é‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this paper, we present an active exploration framework for high-fidelity 3D reconstruction that incrementally builds a multi-level uncertainty space and selects next-best-views through an uncertainty-driven motion planner. We introduce a hybrid implicit-explicit representation that fuses neural fields with Gaussian primitives to jointly capture global structural priors and locally observed details. Based on this hybrid state, we derive a hierarchical uncertainty volume that quantifies both implicit global structure quality and explicit local surface confidence. To focus optimization on the most informative regions, we propose an uncertainty-driven keyframe selection strategy that anchors high-entropy viewpoints as sparse attention nodes, coupled with a viewpoint-space sliding window for uncertainty-aware local refinement. The planning module formulates next-best-view selection as an Expected Hybrid Information Gain problem and incorporates a risk-sensitive path planner to ensure efficient and safe exploration. Extensive experiments on challenging benchmarks demonstrate that our approach consistently achieves state-of-the-art accuracy, completeness, and rendering quality, highlighting its effectiveness for real-world active reconstruction and robotic perception tasks.

