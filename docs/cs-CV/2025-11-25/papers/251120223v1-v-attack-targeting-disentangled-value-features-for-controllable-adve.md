---
layout: default
title: V-Attack: Targeting Disentangled Value Features for Controllable Adversarial Attacks on LVLMs
---

# V-Attack: Targeting Disentangled Value Features for Controllable Adversarial Attacks on LVLMs

**arXiv**: [2511.20223v1](https://arxiv.org/abs/2511.20223) | [PDF](https://arxiv.org/pdf/2511.20223.pdf)

**ä½œè€…**: Sen Nie, Jie Zhang, Jianxin Yan, Shiguang Shan, Xilin Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºV-Attackæ–¹æ³•ï¼Œé€šè¿‡æ“çºµå€¼ç‰¹å¾å®žçŽ°å¯æŽ§å¯¹æŠ—æ”»å‡»ï¼Œè§£å†³LVLMä¸­è¯­ä¹‰æ“æŽ§ä¸ç²¾ç¡®é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¯¹æŠ—æ”»å‡»` `å¤§åž‹è§†è§‰è¯­è¨€æ¨¡åž‹` `å€¼ç‰¹å¾` `è¯­ä¹‰æ“æŽ§` `å¯æŽ§æ”»å‡»` `æ³¨æ„åŠ›æœºåˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰å¯¹æŠ—æ”»å‡»æ–¹æ³•å› è¯­ä¹‰çº ç¼ éš¾ä»¥ç²¾ç¡®æ“æŽ§å›¾åƒä¸­ç‰¹å®šæ¦‚å¿µã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨å€¼ç‰¹å¾ä½œä¸ºç²¾ç¡®æ“æŽ§æ‰‹æŸ„ï¼Œå¼•å…¥è‡ªå€¼å¢žå¼ºå’Œæ–‡æœ¬å¼•å¯¼å€¼æ“çºµæ¨¡å—ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šç§LVLMä¸Šæ”»å‡»æˆåŠŸçŽ‡å¹³å‡æå‡36%ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Adversarial attacks have evolved from simply disrupting predictions on conventional task-specific models to the more complex goal of manipulating image semantics on Large Vision-Language Models (LVLMs). However, existing methods struggle with controllability and fail to precisely manipulate the semantics of specific concepts in the image. We attribute this limitation to semantic entanglement in the patch-token representations on which adversarial attacks typically operate: global context aggregated by self-attention in the vision encoder dominates individual patch features, making them unreliable handles for precise local semantic manipulation. Our systematic investigation reveals a key insight: value features (V) computed within the transformer attention block serve as much more precise handles for manipulation. We show that V suppresses global-context channels, allowing it to retain high-entropy, disentangled local semantic information. Building on this discovery, we propose V-Attack, a novel method designed for precise local semantic attacks. V-Attack targets the value features and introduces two core components: (1) a Self-Value Enhancement module to refine V's intrinsic semantic richness, and (2) a Text-Guided Value Manipulation module that leverages text prompts to locate source concept and optimize it toward a target concept. By bypassing the entangled patch features, V-Attack achieves highly effective semantic control. Extensive experiments across diverse LVLMs, including LLaVA, InternVL, DeepseekVL and GPT-4o, show that V-Attack improves the attack success rate by an average of 36% over state-of-the-art methods, exposing critical vulnerabilities in modern visual-language understanding. Our code and data are available https://github.com/Summu77/V-Attack.

