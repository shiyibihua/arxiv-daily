---
layout: default
title: DLADiff: A Dual-Layer Defense Framework against Fine-Tuning and Zero-Shot Customization of Diffusion Models
---

# DLADiff: A Dual-Layer Defense Framework against Fine-Tuning and Zero-Shot Customization of Diffusion Models

**arXiv**: [2511.19910v1](https://arxiv.org/abs/2511.19910) | [PDF](https://arxiv.org/pdf/2511.19910.pdf)

**ä½œè€…**: Jun Jia, Hongyi Miao, Yingjie Zhou, Linhan Cao, Yanwei Jiang, Wangqiu Zhou, Dandan Zhu, Hua Yang, Wei Sun, Xiongkuo Min, Guangtao Zhai

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDLADiffæ¡†æž¶ä»¥é˜²å¾¡æ‰©æ•£æ¨¡åž‹çš„å¾®è°ƒä¸Žé›¶æ ·æœ¬å®šåˆ¶æ”»å‡»**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹é˜²å¾¡` `é¢éƒ¨éšç§ä¿æŠ¤` `å¯¹æŠ—è®­ç»ƒ` `é›¶æ ·æœ¬ç”Ÿæˆ` `å¾®è°ƒæ”»å‡»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‰©æ•£æ¨¡åž‹å®šåˆ¶åŒ–æŠ€æœ¯å¨èƒé¢éƒ¨éšç§ï¼ŒçŽ°æœ‰é˜²å¾¡å¤šå¿½ç•¥é›¶æ ·æœ¬æ–¹æ³•
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åŒå±‚æœºåˆ¶ï¼Œç»“åˆDSURå’ŒADFTå¯¹æŠ—å¾®è°ƒï¼Œç®€å•å±‚é˜²å¾¡é›¶æ ·æœ¬ç”Ÿæˆ
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒæ˜¾ç¤ºåœ¨é˜²å¾¡å¾®è°ƒå’Œé›¶æ ·æœ¬ç”Ÿæˆä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> With the rapid advancement of diffusion models, a variety of fine-tuning methods have been developed, enabling high-fidelity image generation with high similarity to the target content using only 3 to 5 training images. More recently, zero-shot generation methods have emerged, capable of producing highly realistic outputs from a single reference image without altering model weights. However, technological advancements have also introduced significant risks to facial privacy. Malicious actors can exploit diffusion model customization with just a few or even one image of a person to create synthetic identities nearly identical to the original identity. Although research has begun to focus on defending against diffusion model customization, most existing defense methods target fine-tuning approaches and neglect zero-shot generation defenses. To address this issue, this paper proposes Dual-Layer Anti-Diffusion (DLADiff) to defense both fine-tuning methods and zero-shot methods. DLADiff contains a dual-layer protective mechanism. The first layer provides effective protection against unauthorized fine-tuning by leveraging the proposed Dual-Surrogate Models (DSUR) mechanism and Alternating Dynamic Fine-Tuning (ADFT), which integrates adversarial training with the prior knowledge derived from pre-fine-tuned models. The second layer, though simple in design, demonstrates strong effectiveness in preventing image generation through zero-shot methods. Extensive experimental results demonstrate that our method significantly outperforms existing approaches in defending against fine-tuning of diffusion models and achieves unprecedented performance in protecting against zero-shot generation.

