---
layout: default
title: Map-World: Masked Action planning and Path-Integral World Model for Autonomous Driving
---

# Map-World: Masked Action planning and Path-Integral World Model for Autonomous Driving

**arXiv**: [2511.20156v1](https://arxiv.org/abs/2511.20156) | [PDF](https://arxiv.org/pdf/2511.20156.pdf)

**ä½œè€…**: Bin Hu, Zijian Lu, Haicheng Liao, Chengran Yuan, Bin Rao, Yongkang Li, Guofa Li, Zhiyong Cui, Cheng-zhong Xu, Zhenning Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMAP-Worldæ¡†æž¶ï¼Œé€šè¿‡æŽ©ç åŠ¨ä½œè§„åˆ’å’Œè·¯å¾„ç§¯åˆ†ä¸–ç•Œæ¨¡åž‹å®žçŽ°è‡ªåŠ¨é©¾é©¶å¤šæ¨¡æ€è¿åŠ¨è§„åˆ’ã€‚**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶è§„åˆ’` `å¤šæ¨¡æ€è½¨è¿¹` `ä¸–ç•Œæ¨¡åž‹` `æŽ©ç åºåˆ—` `è·¯å¾„ç§¯åˆ†` `å®žæ—¶æŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è‡ªåŠ¨é©¾é©¶è¿åŠ¨è§„åˆ’éœ€å¤„ç†å¤šæ¨¡æ€æœªæ¥ï¼Œä½†çŽ°æœ‰æ–¹æ³•ä¾èµ–æ‰‹å·¥é”šç‚¹æˆ–å¼ºåŒ–å­¦ä¹ ï¼Œä¸¢å¼ƒä¿¡æ¯å¹¶å¤æ‚åŒ–ä¼˜åŒ–ã€‚
2. MAP-Worldç»“åˆæŽ©ç åŠ¨ä½œè§„åˆ’å’Œè·¯å¾„åŠ æƒä¸–ç•Œæ¨¡åž‹ï¼Œç”Ÿæˆå¤šæ ·è½¨è¿¹å¹¶åŸºäºŽè¯­ä¹‰æŸå¤±å­¦ä¹ å…¨éƒ¨åˆ†å¸ƒã€‚
3. åœ¨NAVSIMä¸ŠåŒ¹é…é”šç‚¹æ–¹æ³•ï¼Œå®žçŽ°ä¸–ç•Œæ¨¡åž‹æ–¹æ³•ä¸­æœ€ä¼˜æ€§èƒ½ï¼Œä¿æŒå®žæ—¶æŽ¨ç†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Motion planning for autonomous driving must handle multiple plausible futures while remaining computationally efficient. Recent end-to-end systems and world-model-based planners predict rich multi-modal trajectories, but typically rely on handcrafted anchors or reinforcement learning to select a single best mode for training and control. This selection discards information about alternative futures and complicates optimization. We propose MAP-World, a prior-free multi-modal planning framework that couples masked action planning with a path-weighted world model. The Masked Action Planning (MAP) module treats future ego motion as masked sequence completion: past waypoints are encoded as visible tokens, future waypoints are represented as mask tokens, and a driving-intent path provides a coarse scaffold. A compact latent planning state is expanded into multiple trajectory queries with injected noise, yielding diverse, temporally consistent modes without anchor libraries or teacher policies. A lightweight world model then rolls out future BEV semantics conditioned on each candidate trajectory. During training, semantic losses are computed as an expectation over modes, using trajectory probabilities as discrete path weights, so the planner learns from the full distribution of plausible futures instead of a single selected path. On NAVSIM, our method matches anchor-based approaches and achieves state-of-the-art performance among world-model-based methods, while avoiding reinforcement learning and maintaining real-time inference latency.

