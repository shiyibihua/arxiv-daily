---
layout: default
title: VGGT4D: Mining Motion Cues in Visual Geometry Transformers for 4D Scene Reconstruction
---

# VGGT4D: Mining Motion Cues in Visual Geometry Transformers for 4D Scene Reconstruction

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.19971" target="_blank" class="toolbar-btn">arXiv: 2511.19971v1</a>
    <a href="https://arxiv.org/pdf/2511.19971.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.19971v1" 
            onclick="toggleFavorite(this, '2511.19971v1', 'VGGT4D: Mining Motion Cues in Visual Geometry Transformers for 4D Scene Reconstruction')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yu Hu, Chong Cheng, Sicheng Yu, Xiaoyang Guo, Hao Wang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-25

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**VGGT4DÔºöÊåñÊéòËßÜËßâÂá†‰ΩïTransformer‰∏≠ÁöÑËøêÂä®Á∫øÁ¥¢ÔºåÁî®‰∫é4DÂú∫ÊôØÈáçÂª∫**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `4DÂú∫ÊôØÈáçÂª∫` `Âä®ÊÄÅÂú∫ÊôØÁêÜËß£` `ËßÜËßâÂá†‰ΩïTransformer` `ËøêÂä®Á∫øÁ¥¢ÊåñÊéò` `ÂÖçËÆ≠ÁªÉÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Âä®ÊÄÅÂú∫ÊôØÈáçÂª∫ÁöÑÂÖ≥ÈîÆÊåëÊàòÂú®‰∫éÂ¶Ç‰ΩïÊúâÊïàÂàÜÁ¶ªÂä®ÊÄÅÁâ©‰ΩìÂíåÈùôÊÄÅËÉåÊôØÔºåÁé∞ÊúâÊñπÊ≥ï‰æùËµñÂ§ñÈÉ®‰ø°ÊÅØÊàñÈúÄË¶ÅÂ§ßÈáè‰ºòÂåñ„ÄÇ
2. VGGT4DÈÄöËøáÊåñÊéòVGGT‰∏≠ÈöêÂê´ÁöÑÂä®ÊÄÅÁ∫øÁ¥¢ÔºåÂà©Áî®GramÁõ∏‰ººÊÄßÂíåÊäïÂΩ±Ê¢ØÂ∫¶ÁªÜÂåñÔºåÂÆûÁé∞Âä®ÊÄÅÁâ©‰ΩìÁöÑÁ≤æÁ°ÆÂàÜÂâ≤„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåVGGT4DÂú®Âä®ÊÄÅÁâ©‰ΩìÂàÜÂâ≤„ÄÅÁõ∏Êú∫ÂßøÊÄÅ‰º∞ËÆ°ÂíåÂØÜÈõÜÈáçÂª∫ÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºå‰∏îÊîØÊåÅÈïøÂ∫èÂàóÊé®ÁêÜ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âä®ÊÄÅ4DÂú∫ÊôØÈáçÂª∫ÊûÅÂÖ∑ÊåëÊàòÊÄßÔºåÂõ†‰∏∫ÂÆÉÈúÄË¶ÅÁ®≥ÂÅ•Âú∞Â∞ÜÂä®ÊÄÅÁâ©‰Ωì‰ªéÈùôÊÄÅËÉåÊôØ‰∏≠ÂàÜÁ¶ªÂá∫Êù•„ÄÇËôΩÁÑ∂ÂÉèVGGTËøôÊ†∑ÁöÑ3DÂü∫Á°ÄÊ®°ÂûãÊèê‰æõ‰∫ÜÁ≤æÁ°ÆÁöÑ3DÂá†‰Ωï‰ø°ÊÅØÔºå‰ΩÜÂΩìÁßªÂä®Áâ©‰ΩìÂç†ÊçÆ‰∏ªÂØºÂú∞‰ΩçÊó∂ÔºåÂÆÉ‰ª¨ÁöÑÊÄßËÉΩ‰ºöÊòæËëó‰∏ãÈôç„ÄÇÁé∞ÊúâÁöÑ4DÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÂ§ñÈÉ®ÂÖàÈ™å„ÄÅÁπÅÈáçÁöÑÂêé‰ºòÂåñÔºåÊàñËÄÖÈúÄË¶ÅÂú®4DÊï∞ÊçÆÈõÜ‰∏äËøõË°åÂæÆË∞É„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜVGGT4DÔºå‰∏Ä‰∏™Êó†ÈúÄËÆ≠ÁªÉÁöÑÊ°ÜÊû∂ÔºåÊâ©Â±ï‰∫Ü3DÂü∫Á°ÄÊ®°ÂûãVGGTÔºåÁî®‰∫éÁ®≥ÂÅ•ÁöÑ4DÂú∫ÊôØÈáçÂª∫„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂü∫‰∫é‰∏Ä‰∏™ÂÖ≥ÈîÆÂèëÁé∞ÔºöVGGTÁöÑÂÖ®Â±ÄÊ≥®ÊÑèÂäõÂ±ÇÂ∑≤ÁªèÈöêÂºèÂú∞ÁºñÁ†Å‰∫Ü‰∏∞ÂØåÁöÑ„ÄÅÈÄêÂ±ÇÁöÑÂä®ÊÄÅÁ∫øÁ¥¢„ÄÇ‰∏∫‰∫ÜËé∑ÂæóËß£ËÄ¶ÈùôÊÄÅÂíåÂä®ÊÄÅÂÖÉÁ¥†ÁöÑÊé©Á†ÅÔºåÊàë‰ª¨ÈÄöËøáGramÁõ∏‰ººÊÄßÊåñÊéòÂíåÊîæÂ§ßÂÖ®Â±ÄÂä®ÊÄÅÁ∫øÁ¥¢ÔºåÂπ∂Âú®Êó∂Èó¥Á™óÂè£ÂÜÖËÅöÂêàÂÆÉ‰ª¨„ÄÇ‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•ÈîêÂåñÊé©Á†ÅËæπÁïåÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÁî±ÊäïÂΩ±Ê¢ØÂ∫¶È©±Âä®ÁöÑÁªÜÂåñÁ≠ñÁï•„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨Â∞ÜËøô‰∫õÁ≤æÁ°ÆÁöÑÊé©Á†ÅÈõÜÊàêÂà∞VGGTÁöÑÊó©ÊúüÊé®ÁêÜÈò∂ÊÆµÔºåÊúâÊïàÂú∞ÂáèËΩª‰∫ÜËøêÂä®ÂØπÂßøÊÄÅ‰º∞ËÆ°ÂíåÂá†‰ΩïÈáçÂª∫ÁöÑÂπ≤Êâ∞„ÄÇÂú®ÂÖ≠‰∏™Êï∞ÊçÆÈõÜ‰∏äÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Âä®ÊÄÅÂØπË±°ÂàÜÂâ≤„ÄÅÁõ∏Êú∫ÂßøÊÄÅ‰º∞ËÆ°ÂíåÂØÜÈõÜÈáçÂª∫ÊñπÈù¢ÂèñÂæó‰∫Ü‰ºòÂºÇÁöÑÊÄßËÉΩ„ÄÇÂÆÉËøòÊîØÊåÅÂØπË∂ÖËøá500Â∏ßÁöÑÂ∫èÂàóËøõË°åÂçïÊ¨°Êé®ÁêÜ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂä®ÊÄÅ4DÂú∫ÊôØÈáçÂª∫Êó®Âú®‰ªéËßÜÈ¢ëÂ∫èÂàó‰∏≠ÊÅ¢Â§çÂú∫ÊôØÁöÑ3DÂá†‰ΩïÁªìÊûÑ‰ª•ÂèäÈöèÊó∂Èó¥ÂèòÂåñÁöÑÂä®ÊÄÅÁâ©‰Ωì„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÂåÖÂê´Â§ßÈáèËøêÂä®Áâ©‰ΩìÁöÑÂú∫ÊôØÊó∂ÔºåÂæÄÂæÄÁî±‰∫éÂä®ÊÄÅÁâ©‰Ωì‰∏éÈùôÊÄÅËÉåÊôØÁöÑÊ∑∑Ê∑ÜËÄåÂØºËá¥ÈáçÂª∫Ë¥®Èáè‰∏ãÈôç„ÄÇÊ≠§Â§ñÔºåËÆ∏Â§öÊñπÊ≥ï‰æùËµñ‰∫éÈ¢ùÂ§ñÁöÑÂÖàÈ™åÁü•ËØÜÊàñÈúÄË¶ÅËÄóÊó∂ÁöÑÂêéÂ§ÑÁêÜ‰ºòÂåñÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®ËåÉÂõ¥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVGGT4DÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂà©Áî®3DÂü∫Á°ÄÊ®°ÂûãVGGT‰∏≠Â∑≤ÁªèÂ≠òÂú®ÁöÑ„ÄÅ‰ΩÜÊú™Ë¢´ÂÖÖÂàÜÂà©Áî®ÁöÑÂä®ÊÄÅÁ∫øÁ¥¢„ÄÇ‰ΩúËÄÖÂèëÁé∞ÔºåVGGTÁöÑÂÖ®Â±ÄÊ≥®ÊÑèÂäõÂ±ÇÂú®‰∏çÂêåÂ±ÇÁ∫ß‰∏äÈöêÂºèÂú∞ÁºñÁ†Å‰∫ÜÂú∫ÊôØ‰∏≠ÁöÑËøêÂä®‰ø°ÊÅØ„ÄÇÈÄöËøáÊúâÊïàÂú∞ÊåñÊéòÂíåÊîæÂ§ßËøô‰∫õÂä®ÊÄÅÁ∫øÁ¥¢ÔºåÂèØ‰ª•ÂÆûÁé∞Âä®ÊÄÅÁâ©‰ΩìÂíåÈùôÊÄÅËÉåÊôØÁöÑËß£ËÄ¶Ôºå‰ªéËÄåÊèêÈ´ò4DÂú∫ÊôØÈáçÂª∫ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVGGT4DÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏â‰∏™Èò∂ÊÆµÔºö1) Âä®ÊÄÅÁ∫øÁ¥¢ÊåñÊéò‰∏éËÅöÂêàÔºöÂà©Áî®GramÁü©ÈòµËÆ°ÁÆóVGGTÂêÑÂ±ÇÁâπÂæÅ‰πãÈó¥ÁöÑÁõ∏‰ººÊÄßÔºåÊèêÂèñÂä®ÊÄÅÁ∫øÁ¥¢ÔºåÂπ∂Âú®Êó∂Èó¥Á™óÂè£ÂÜÖËøõË°åËÅöÂêàÔºåÁîüÊàêÂàùÂßãÁöÑÂä®ÊÄÅÁâ©‰ΩìÊé©Á†Å„ÄÇ2) Êé©Á†ÅÁªÜÂåñÔºöÈÄöËøáÊäïÂΩ±Ê¢ØÂ∫¶È©±Âä®ÁöÑÁªÜÂåñÁ≠ñÁï•Ôºå‰ºòÂåñÊé©Á†ÅËæπÁïåÔºåÊèêÈ´òÂàÜÂâ≤Á≤æÂ∫¶„ÄÇ3) ÈõÜÊàêÂà∞VGGTÊé®ÁêÜÔºöÂ∞ÜÁªÜÂåñÂêéÁöÑÊé©Á†ÅÈõÜÊàêÂà∞VGGTÁöÑÊó©ÊúüÊé®ÁêÜÈò∂ÊÆµÔºåÊäëÂà∂ËøêÂä®Âπ≤Êâ∞ÔºåÊèêÂçáÂßøÊÄÅ‰º∞ËÆ°ÂíåÂá†‰ΩïÈáçÂª∫ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVGGT4DÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Êó†ÈúÄËÆ≠ÁªÉÁöÑÁâπÊÄßÔºå‰ª•ÂèäÂØπÁé∞Êúâ3DÂü∫Á°ÄÊ®°ÂûãVGGTÁöÑÊúâÊïàÂà©Áî®„ÄÇ‰∏éÈúÄË¶ÅÂ§ßÈáèËÆ≠ÁªÉÊï∞ÊçÆÊàñ‰æùËµñÂ§ñÈÉ®ÂÖàÈ™åÁöÑÊñπÊ≥ï‰∏çÂêåÔºåVGGT4DÁõ¥Êé•‰ªéVGGTÁöÑÂÜÖÈÉ®Ë°®Á§∫‰∏≠ÊåñÊéòÂä®ÊÄÅÁ∫øÁ¥¢ÔºåÂÆûÁé∞‰∫ÜÂØπÂä®ÊÄÅÂú∫ÊôØÁöÑÈ≤ÅÊ£íÈáçÂª∫„ÄÇÊ≠§Â§ñÔºåÊäïÂΩ±Ê¢ØÂ∫¶È©±Âä®ÁöÑÊé©Á†ÅÁªÜÂåñÁ≠ñÁï•Ëøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÂàÜÂâ≤Á≤æÂ∫¶„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Âä®ÊÄÅÁ∫øÁ¥¢ÊåñÊéòÈò∂ÊÆµÔºå‰ΩøÁî®GramÁü©ÈòµËÆ°ÁÆóÁâπÂæÅÁõ∏‰ººÊÄßÔºåËÉΩÂ§üÊçïÊçâ‰∏çÂêåÂ±ÇÁ∫ß‰∏äÁöÑËøêÂä®‰ø°ÊÅØ„ÄÇÊó∂Èó¥Á™óÂè£ÁöÑÈïøÂ∫¶ÈúÄË¶ÅÊ†πÊçÆÂú∫ÊôØÁöÑËøêÂä®ÈÄüÂ∫¶ËøõË°åË∞ÉÊï¥„ÄÇÊäïÂΩ±Ê¢ØÂ∫¶ÁªÜÂåñÁ≠ñÁï•Âà©Áî®ÂõæÂÉèÊ¢ØÂ∫¶‰ø°ÊÅØÊù•‰ºòÂåñÊé©Á†ÅËæπÁïåÔºåÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÈúÄË¶ÅÂπ≥Ë°°ÂàÜÂâ≤Á≤æÂ∫¶ÂíåËæπÁïåÈîêÂåñ„ÄÇÂ∞ÜÊé©Á†ÅÈõÜÊàêÂà∞VGGTÊó©ÊúüÊé®ÁêÜÈò∂ÊÆµÔºåÂèØ‰ª•ÊúâÊïàÊäëÂà∂ËøêÂä®ÂØπÂêéÁª≠Â§ÑÁêÜÁöÑÂΩ±Âìç„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

VGGT4DÂú®ÂÖ≠‰∏™Êï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂú®Âä®ÊÄÅÁâ©‰ΩìÂàÜÂâ≤„ÄÅÁõ∏Êú∫ÂßøÊÄÅ‰º∞ËÆ°ÂíåÂØÜÈõÜÈáçÂª∫ÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇËØ•ÊñπÊ≥ïÊó†ÈúÄËÆ≠ÁªÉÔºåÂèØ‰ª•Áõ¥Êé•Â∫îÁî®‰∫éÁé∞ÊúâÁöÑ3DÂü∫Á°ÄÊ®°ÂûãVGGT„ÄÇÊ≠§Â§ñÔºåVGGT4DÊîØÊåÅÂØπË∂ÖËøá500Â∏ßÁöÑÈïøÂ∫èÂàóËøõË°åÂçïÊ¨°Êé®ÁêÜÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂È´òÊïàÊÄßÂíåÂèØÊâ©Â±ïÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

VGGT4DÂú®Êú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫ÁêÜËß£Âä®ÊÄÅÁéØÂ¢ÉÔºå‰ªéËÄåÂÅöÂá∫Êõ¥ÂÆâÂÖ®„ÄÅÊõ¥ÊúâÊïàÁöÑÂÜ≥Á≠ñ„ÄÇÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÂáÜÁ°ÆÁöÑ4DÂú∫ÊôØÈáçÂª∫ÂèØ‰ª•ÊèêÈ´òËΩ¶ËæÜÂØπÂë®Âõ¥ÁéØÂ¢ÉÁöÑÊÑüÁü•ËÉΩÂäõÔºåÂ¢ûÂº∫È©æÈ©∂ÂÆâÂÖ®ÊÄß„ÄÇÂú®Â¢ûÂº∫Áé∞ÂÆû‰∏≠ÔºåVGGT4DÂèØ‰ª•ÂÆûÁé∞Êõ¥ÈÄºÁúüÁöÑËôöÊãüÁâ©‰Ωì‰∏éÁúüÂÆûÂú∫ÊôØÁöÑ‰∫§‰∫í„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Reconstructing dynamic 4D scenes is challenging, as it requires robust disentanglement of dynamic objects from the static background. While 3D foundation models like VGGT provide accurate 3D geometry, their performance drops markedly when moving objects dominate. Existing 4D approaches often rely on external priors, heavy post-optimization, or require fine-tuning on 4D datasets. In this paper, we propose VGGT4D, a training-free framework that extends the 3D foundation model VGGT for robust 4D scene reconstruction. Our approach is motivated by the key finding that VGGT's global attention layers already implicitly encode rich, layer-wise dynamic cues. To obtain masks that decouple static and dynamic elements, we mine and amplify global dynamic cues via gram similarity and aggregate them across a temporal window. To further sharpen mask boundaries, we introduce a refinement strategy driven by projection gradient. We then integrate these precise masks into VGGT's early-stage inference, effectively mitigating motion interference in both pose estimation and geometric reconstruction. Across six datasets, our method achieves superior performance in dynamic object segmentation, camera pose estimation, and dense reconstruction. It also supports single-pass inference on sequences longer than 500 frames.

