---
layout: default
title: Towards Trustworthy Wi-Fi Sensing: Systematic Evaluation of Deep Learning Model Robustness to Adversarial Attacks
---

# Towards Trustworthy Wi-Fi Sensing: Systematic Evaluation of Deep Learning Model Robustness to Adversarial Attacks

**arXiv**: [2511.20456v1](https://arxiv.org/abs/2511.20456) | [PDF](https://arxiv.org/pdf/2511.20456.pdf)

**ä½œè€…**: Shreevanth Krishnaa Gopalakrishnan, Stephen Hailes

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç³»ç»Ÿè¯„ä¼°Wi-Fiæ„ŸçŸ¥æ·±åº¦å­¦ä¹ æ¨¡åž‹å¯¹æŠ—æ”»å‡»çš„é²æ£’æ€§ï¼Œä»¥æå‡å¯ä¿¡èµ–æ€§**

**å…³é”®è¯**: `Wi-Fiæ„ŸçŸ¥` `å¯¹æŠ—æ”»å‡»` `æ¨¡åž‹é²æ£’æ€§` `ä¿¡é“çŠ¶æ€ä¿¡æ¯` `æ·±åº¦å­¦ä¹ è¯„ä¼°` `å®‰å…¨æ— çº¿ç³»ç»Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šCSIæ·±åº¦å­¦ä¹ æ¨¡åž‹æ˜“å—å¯¹æŠ—æ”»å‡»ï¼Œå¨èƒæ— çº¿æ„ŸçŸ¥å®‰å…¨ä¸Žå¯é æ€§
2. æ–¹æ³•è¦ç‚¹ï¼šå»ºç«‹è¯„ä¼°æ¡†æž¶ï¼Œæ¯”è¾ƒä¸åŒæ¨¡åž‹åœ¨å¤šç§å¨èƒæ¨¡åž‹ä¸‹çš„é²æ£’æ€§
3. å®žéªŒæˆ–æ•ˆæžœï¼šå°æ¨¡åž‹é²æ£’æ€§å·®ï¼Œç‰©ç†å¯è¡Œæ‰°åŠ¨é™ä½Žæ”»å‡»æˆåŠŸçŽ‡ï¼Œå¯¹æŠ—è®­ç»ƒæå‡é²æ£’æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Machine learning has become integral to Channel State Information (CSI)-based human sensing systems and is expected to power applications such as device-free activity recognition and identity detection in future cellular and Wi-Fi generations. However, these systems rely on models whose decisions can be subtly perturbed, raising concerns for security and reliability in ubiquitous sensing. Quantifying and understanding the robustness of such models, defined as their ability to maintain accurate predictions under adversarial perturbations, is therefore critical before wireless sensing can be safely deployed in real-world environments.
>   This work presents a systematic evaluation of the robustness of CSI deep learning models under diverse threat models (white-box, black-box/transfer, and universal perturbations) and varying degrees of attack realism. We establish a framework to compare compact temporal autoencoder models with larger deep architectures across three public datasets, quantifying how model scale, training regime, and physical constraints influence robustness. Our experiments show that smaller models, while efficient and equally performant on clean data, are markedly less robust. We further confirm that physically realizable signal-space perturbations, designed to be feasible in real wireless channels, significantly reduce attack success compared to unconstrained feature-space attacks. Adversarial training mitigates these vulnerabilities, improving mean robust accuracy with only moderate degradation in clean performance across both model classes. As wireless sensing advances towards reliable, cross-domain operation, these findings provide quantitative baselines for robustness estimation and inform design principles for secure and trustworthy human-centered sensing systems.

