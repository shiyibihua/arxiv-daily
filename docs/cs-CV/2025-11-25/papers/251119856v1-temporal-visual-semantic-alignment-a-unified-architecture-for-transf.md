---
layout: default
title: Temporal-Visual Semantic Alignment: A Unified Architecture for Transferring Spatial Priors from Vision Models to Zero-Shot Temporal Tasks
---

# Temporal-Visual Semantic Alignment: A Unified Architecture for Transferring Spatial Priors from Vision Models to Zero-Shot Temporal Tasks

**arXiv**: [2511.19856v1](https://arxiv.org/abs/2511.19856) | [PDF](https://arxiv.org/pdf/2511.19856.pdf)

**ä½œè€…**: Xiangkai Ma, Han Zhang, Wenzhong Li, Sanglu Lu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTimeArtistæ¡†æž¶ï¼Œå®žçŽ°æ—¶é—´åºåˆ—ä¸Žè§†è§‰è¯­ä¹‰å¯¹é½ï¼Œç”¨äºŽé›¶æ ·æœ¬æ—¶åºä»»åŠ¡å’Œå›¾åƒç”Ÿæˆã€‚**

**å…³é”®è¯**: `æ—¶é—´åºåˆ—åˆ†æž` `è·¨æ¨¡æ€å¯¹é½` `é›¶æ ·æœ¬å­¦ä¹ ` `å›¾åƒç”Ÿæˆ` `è¯­ä¹‰çº§è¡¨ç¤º` `è‡ªç›‘ç£è®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•å°†æ—¶é—´åºåˆ—è½¬ä¸ºä¼ªå›¾åƒï¼Œä½†ç¼ºä¹è¯­ä¹‰çº§å¯¹é½ï¼Œæ— æ³•æ•æ‰æ—¶åºæ³¢åŠ¨ä¸Žè§†è§‰æ¦‚å¿µçš„å…³ç³»ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨é¢„çƒ­å¯¹é½èŒƒå¼ï¼Œå…ˆè‡ªç›‘ç£å­¦ä¹ æ¨¡æ€å…±äº«è¡¨ç¤ºï¼Œå†å†»ç»“ç¼–ç å™¨å¹¶å¼•å…¥æŠ•å½±å®žçŽ°è¡¨ç¤ºçº§å¯¹é½ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å›¾åƒç”ŸæˆæŒ‡æ ‡ä¸Šè¡¨çŽ°æ»¡æ„ï¼Œå¹¶åœ¨é›¶æ ·æœ¬æ—¶åºä»»åŠ¡ä¸­å–å¾—ä¼˜è¶Šç»“æžœï¼ŒéªŒè¯äº†è·¨æ¨¡æ€ç”Ÿæˆèƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Multimodal Models (LMMs) have achieved remarkable progress in aligning and generating content across text and image modalities. However, the potential of using non-visual, continuous sequential, as a conditioning signal for high-fidelity image generation remains largely unexplored. Furthermore, existing methods that convert series into "pseudo-images" for temporal forecasting fail to establish semantic-level alignment. In this paper, we propose TimeArtist, a temporal-visual conversion framework that pioneers semantic-level alignment between time series fluctuations and visual concepts. It pioneers a "warmup-align" paradigm: first, a dual-autoencoder and shared quantizer are self-supervised trained on large-scale datasets to learn modality-shared representations. Then, the encoders and quantizer are frozen, and a projection is introduced to align temporal and visual samples at the representation level. TimeArtist establishes a versatile cross-modal framework, enabling high-quality, diverse image generation directly from time series, while capturing temporal fluctuation patterns to render images as styles transfer. Extensive experiments show that TimeArtist achieves satisfactory performance in image generation metrics, while also attaining superior results in zero-shot temporal tasks. Our work establishes a new paradigm for cross-modal generation, bridging the gap between temporal dynamics and visual semantics.

