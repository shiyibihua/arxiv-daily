---
layout: default
title: A System-Level Taxonomy of Failure Modes in Large Language Model Applications
---

# A System-Level Taxonomy of Failure Modes in Large Language Model Applications

**arXiv**: [2511.19933v1](https://arxiv.org/abs/2511.19933) | [PDF](https://arxiv.org/pdf/2511.19933.pdf)

**ä½œè€…**: Vaishali Vinay

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç³»ç»Ÿçº§æ•…éšœæ¨¡å¼åˆ†ç±»æ³•ä»¥è§£å†³å¤§è¯­è¨€æ¨¡åž‹åº”ç”¨ä¸­çš„å¯é æ€§é—®é¢˜**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹æ•…éšœæ¨¡å¼` `ç³»ç»Ÿçº§åˆ†ç±»æ³•` `å¯é æ€§è®¾è®¡åŽŸåˆ™` `è¯„ä¼°ç›‘æŽ§å·®è·` `ç”Ÿäº§éƒ¨ç½²æŒ‘æˆ˜`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è¯­è¨€æ¨¡åž‹åœ¨çœŸå®žåº”ç”¨ä¸­å­˜åœ¨éšè—æ•…éšœæ¨¡å¼ï¼Œå¦‚æŽ¨ç†æ¼‚ç§»å’Œå·¥å…·è°ƒç”¨é”™è¯¯
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºåŒ…å«15ç§æ•…éšœæ¨¡å¼çš„åˆ†ç±»æ³•ï¼Œåˆ†æžè¯„ä¼°ä¸Žç›‘æŽ§å®žè·µçš„å·®è·
3. å®žéªŒæˆ–æ•ˆæžœï¼šæœªçŸ¥å…·ä½“å®žéªŒï¼Œä½†æå‡ºè®¾è®¡åŽŸåˆ™ä»¥æå‡ç³»ç»Ÿå¯é æ€§å’Œæˆæœ¬æ„è¯†

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large language models (LLMs) are being rapidly integrated into decision-support tools, automation workflows, and AI-enabled software systems. However, their behavior in production environments remains poorly understood, and their failure patterns differ fundamentally from those of traditional machine learning models. This paper presents a system-level taxonomy of fifteen hidden failure modes that arise in real-world LLM applications, including multi-step reasoning drift, latent inconsistency, context-boundary degradation, incorrect tool invocation, version drift, and cost-driven performance collapse. Using this taxonomy, we analyze the growing gap in evaluation and monitoring practices: existing benchmarks measure knowledge or reasoning but provide little insight into stability, reproducibility, drift, or workflow integration. We further examine the production challenges associated with deploying LLMs - including observability limitations, cost constraints, and update-induced regressions - and outline high-level design principles for building reliable, maintainable, and cost-aware LLM systems. Finally, we outline high-level design principles for building reliable, maintainable, and cost-aware LLM-based systems. By framing LLM reliability as a system-engineering problem rather than a purely model-centric one, this work provides an analytical foundation for future research on evaluation methodology, AI system robustness, and dependable LLM deployment.

