---
layout: default
title: HBridge: H-Shape Bridging of Heterogeneous Experts for Unified Multimodal Understanding and Generation
---

# HBridge: H-Shape Bridging of Heterogeneous Experts for Unified Multimodal Understanding and Generation

**arXiv**: [2511.20520v1](https://arxiv.org/abs/2511.20520) | [PDF](https://arxiv.org/pdf/2511.20520.pdf)

**ä½œè€…**: Xiang Wang, Zhifei Zhang, He Zhang, Zhe Lin, Yuqian Zhou, Qing Liu, Shiwei Zhang, Yijun Li, Shaoteng Liu, Haitian Zheng, Jason Kuen, Yuehuan Wang, Changxin Gao, Nong Sang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHBridgeä»¥è§£å†³å¼‚æž„ä¸“å®¶èžåˆä¸­çš„æ¨¡æ€å·®å¼‚é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€ç†è§£` `å¼‚æž„ä¸“å®¶èžåˆ` `éžå¯¹ç§°æž¶æž„` `æ³¨æ„åŠ›å…±äº«ä¼˜åŒ–` `è¯­ä¹‰å¯¹é½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¯¹ç§°è®¾è®¡åœ¨ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡åž‹ä¸­å¯¼è‡´æ¨¡æ€å·®å¼‚ï¼Œå½±å“æ€§èƒ½ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨éžå¯¹ç§°Hå½¢æž¶æž„ï¼Œé€‰æ‹©æ€§æ¡¥æŽ¥ä¸­é—´å±‚ï¼Œå‡å°‘æ³¨æ„åŠ›å…±äº«ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨çŽ°ä¼˜è¶Šï¼Œæå‡ç”Ÿæˆè´¨é‡å’Œæ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent unified models integrate understanding experts (e.g., LLMs) with generative experts (e.g., diffusion models), achieving strong multimodal performance. However, recent advanced methods such as BAGEL and LMFusion follow the Mixture-of-Transformers (MoT) paradigm, adopting a symmetric design that mirrors one expert to another for convenient initialization and fusion, which remains suboptimal due to inherent modality discrepancies. In this work, we propose HBridge, an asymmetric H-shaped architecture that enables heterogeneous experts to optimally leverage pretrained priors from their respective modality domains. Unlike prior dense fusion strategies that straightforwardly connect all layers between experts via shared attention, HBridge selectively bridges intermediate layers, reducing over 40% attention sharing, which improves efficiency and enhances generation quality. Shallow and deep layers, which capture modality-specific representations, are decoupled, while mid-layer bridging promotes semantic alignment. To further strengthen cross-modal coherence, we introduce semantic reconstruction tokens that explicitly guide the generative expert to reconstruct visual semantic tokens of the target image. Extensive experiments across multiple benchmarks demonstrate the effectiveness and superior performance of HBridge, establishing a new paradigm for unified multimodal generation.

