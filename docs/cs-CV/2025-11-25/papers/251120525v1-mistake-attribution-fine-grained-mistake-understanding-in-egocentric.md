---
layout: default
title: Mistake Attribution: Fine-Grained Mistake Understanding in Egocentric Videos
---

# Mistake Attribution: Fine-Grained Mistake Understanding in Egocentric Videos

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.20525" target="_blank" class="toolbar-btn">arXiv: 2511.20525v1</a>
    <a href="https://arxiv.org/pdf/2511.20525.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.20525v1" 
            onclick="toggleFavorite(this, '2511.20525v1', 'Mistake Attribution: Fine-Grained Mistake Understanding in Egocentric Videos')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Yayuan Li, Aadit Jain, Filippos Bellos, Jason J. Corso

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25

**å¤‡æ³¨**: 11 pages, 4 figures, 6 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMistake Attribution (MATT)ä»»åŠ¡ï¼Œç”¨äºç»†ç²’åº¦ç†è§£ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘ä¸­çš„äººç±»é”™è¯¯ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `é”™è¯¯å½’å› ` `ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒè§†é¢‘` `ç»†ç²’åº¦ç†è§£` `è§†é¢‘è¯­è¨€æ¨¡å‹` `æ³¨æ„åŠ›æœºåˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é”™è¯¯ç†è§£å·¥ä½œç¼ºä¹ç»†ç²’åº¦è¾“å‡ºï¼Œæ— æ³•å…·ä½“å®šä½é”™è¯¯åŸå› å’Œå‘ç”Ÿä½ç½®ã€‚
2. æå‡ºMistake Attributionä»»åŠ¡ï¼Œå°†é”™è¯¯å½’å› äºæŒ‡ä»¤æ–‡æœ¬çš„è¯­ä¹‰è§’è‰²ã€ä¸å¯é€†è½¬çš„æ—¶é—´ç‚¹å’Œç©ºé—´ä½ç½®ã€‚
3. æ„å»ºMisEngineæ•°æ®å¼•æ“ï¼Œç”Ÿæˆå¤§è§„æ¨¡é”™è¯¯æ•°æ®é›†ï¼Œå¹¶æå‡ºMisFormeræ¨¡å‹ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†Mistake Attribution (MATT)ä»»åŠ¡ï¼Œæ—¨åœ¨å¯¹ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘ä¸­äººç±»çš„é”™è¯¯è¿›è¡Œç»†ç²’åº¦ç†è§£ã€‚ä¸ä»¥å¾€ç¼ºä¹ç»†ç²’åº¦è¾“å‡ºçš„é”™è¯¯ç†è§£å·¥ä½œä¸åŒï¼ŒMATTå°†é”™è¯¯å…·ä½“åœ°å½’å› äºè¾“å…¥çš„æŒ‡ä»¤æ–‡æœ¬æˆ–å°è¯•è§†é¢‘ã€‚MATTç¡®å®šè¿åäº†æŒ‡ä»¤çš„å“ªä¸ªéƒ¨åˆ†ï¼ˆè¯­ä¹‰è§’è‰²ï¼‰ï¼Œåå·®å˜å¾—ä¸å¯é€†è½¬çš„æ—¶é—´ç‚¹ï¼ˆPoint-of-No-Return, PNRï¼‰ï¼Œä»¥åŠé”™è¯¯å‡ºç°åœ¨PNRå¸§ä¸­çš„ä½ç½®ã€‚æˆ‘ä»¬å¼€å‘äº†MisEngineï¼Œä¸€ä¸ªæ•°æ®å¼•æ“ï¼Œå¯ä»¥ä»ç°æœ‰æ•°æ®é›†ä¸­è‡ªåŠ¨æ„å»ºå…·æœ‰ä¸°å¯Œå½’å› ä¿¡æ¯çš„é”™è¯¯æ ·æœ¬ï¼Œå¹¶ç»§æ‰¿å®ƒä»¬çš„æ³¨é‡Šã€‚åº”ç”¨äºå¤§å‹ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è¯­æ–™åº“ï¼ŒMisEngineäº§ç”Ÿäº†EPIC-KITCHENS-Må’ŒEgo4D-Mä¸¤ä¸ªæ•°æ®é›†ï¼Œå®ƒä»¬æ¯”ä»¥å¾€çš„é”™è¯¯æ•°æ®é›†å¤§ä¸¤ä¸ªæ•°é‡çº§ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†MisFormerï¼Œä¸€ä¸ªç»Ÿä¸€çš„åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ï¼Œç”¨äºè·¨è¯­ä¹‰ï¼ˆä»€ä¹ˆï¼‰ã€æ—¶é—´ï¼ˆä½•æ—¶ï¼‰å’Œç©ºé—´ï¼ˆä½•åœ°ï¼‰ç»´åº¦è¿›è¡Œé”™è¯¯å½’å› ï¼Œå¹¶ä½¿ç”¨MisEngineç›‘ç£è¿›è¡Œè®­ç»ƒã€‚åœ¨æˆ‘ä»¬æ–°çš„æ•°æ®é›†å’Œå…ˆå‰çš„åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMisFormerä¼˜äºå¼ºå¤§çš„è§†é¢‘-è¯­è¨€ã€æ—¶é—´å®šä½ã€æ‰‹-å¯¹è±¡äº¤äº’å’Œé”™è¯¯æ£€æµ‹åŸºçº¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘ä¸­äººç±»é”™è¯¯ç†è§£çš„ç»†ç²’åº¦é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªèƒ½æ£€æµ‹é”™è¯¯ï¼Œè€Œæ— æ³•æä¾›é”™è¯¯çš„å…·ä½“åŸå› ã€å‘ç”Ÿæ—¶é—´ä»¥åŠå‘ç”Ÿä½ç½®ç­‰ä¿¡æ¯ã€‚è¿™é™åˆ¶äº†å¯¹äººç±»è¡Œä¸ºçš„æ·±å…¥ç†è§£å’Œæ™ºèƒ½åŠ©æ‰‹çš„æœ‰æ•ˆå¹²é¢„ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†é”™è¯¯å½’å› åˆ†è§£ä¸ºä¸‰ä¸ªç»´åº¦ï¼šè¯­ä¹‰ï¼ˆæŒ‡ä»¤çš„å“ªä¸ªéƒ¨åˆ†è¢«è¿åï¼‰ã€æ—¶é—´ï¼ˆåå·®å˜å¾—ä¸å¯é€†è½¬çš„æ—¶é—´ç‚¹ï¼‰å’Œç©ºé—´ï¼ˆé”™è¯¯å‘ç”Ÿçš„å…·ä½“ä½ç½®ï¼‰ã€‚é€šè¿‡å¯¹è¿™ä¸‰ä¸ªç»´åº¦è¿›è¡Œå»ºæ¨¡ï¼Œå¯ä»¥å®ç°å¯¹é”™è¯¯çš„ç»†ç²’åº¦ç†è§£ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼šMisEngineæ•°æ®å¼•æ“å’ŒMisFormeræ¨¡å‹ã€‚MisEngineè´Ÿè´£ä»ç°æœ‰æ•°æ®é›†ä¸­è‡ªåŠ¨æ„å»ºå…·æœ‰ä¸°å¯Œå½’å› ä¿¡æ¯çš„é”™è¯¯æ ·æœ¬ã€‚MisFormeræ˜¯ä¸€ä¸ªç»Ÿä¸€çš„åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ï¼Œç”¨äºè·¨è¯­ä¹‰ã€æ—¶é—´å’Œç©ºé—´ç»´åº¦è¿›è¡Œé”™è¯¯å½’å› ã€‚è¯¥æ¨¡å‹æ¥æ”¶è§†é¢‘å’ŒæŒ‡ä»¤æ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºé”™è¯¯å‘ç”Ÿçš„è¯­ä¹‰è§’è‰²ã€Point-of-No-Return (PNR)ä»¥åŠPNRå¸§ä¸­çš„é”™è¯¯ä½ç½®ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†Mistake Attribution (MATT)ä»»åŠ¡ï¼Œå¹¶è®¾è®¡äº†MisEngineæ•°æ®å¼•æ“å’ŒMisFormeræ¨¡å‹æ¥è§£å†³è¯¥ä»»åŠ¡ã€‚MATTä»»åŠ¡å®šä¹‰äº†é”™è¯¯å½’å› çš„ä¸‰ä¸ªç»´åº¦ï¼Œä¸ºç»†ç²’åº¦é”™è¯¯ç†è§£æä¾›äº†æ˜ç¡®çš„ç›®æ ‡ã€‚MisEngineèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆå¤§è§„æ¨¡çš„é”™è¯¯æ•°æ®é›†ï¼Œè§£å†³äº†æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚MisFormeræ¨¡å‹åˆ™é€šè¿‡ç»Ÿä¸€çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°äº†è·¨å¤šä¸ªç»´åº¦çš„é”™è¯¯å½’å› ã€‚

**å…³é”®è®¾è®¡**ï¼šMisFormeræ¨¡å‹é‡‡ç”¨Transformeræ¶æ„ï¼Œä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶æ¥å»ºæ¨¡è§†é¢‘å’Œæ–‡æœ¬ä¹‹é—´çš„å…³ç³»ã€‚æ¨¡å‹åŒ…å«ä¸‰ä¸ªè¾“å‡ºåˆ†æ”¯ï¼Œåˆ†åˆ«é¢„æµ‹è¯­ä¹‰è§’è‰²ã€PNRå’Œé”™è¯¯ä½ç½®ã€‚PNRçš„é¢„æµ‹é‡‡ç”¨æ—¶é—´å®šä½çš„æ–¹æ³•ï¼Œä½¿ç”¨åˆ†ç±»å™¨é¢„æµ‹æ¯ä¸ªå¸§æ˜¯å¦ä¸ºPNRã€‚é”™è¯¯ä½ç½®çš„é¢„æµ‹é‡‡ç”¨ç›®æ ‡æ£€æµ‹çš„æ–¹æ³•ï¼Œä½¿ç”¨è¾¹ç•Œæ¡†å›å½’æ¥å®šä½é”™è¯¯åœ¨PNRå¸§ä¸­çš„ä½ç½®ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬è¯­ä¹‰è§’è‰²åˆ†ç±»æŸå¤±ã€PNRæ—¶é—´å®šä½æŸå¤±å’Œé”™è¯¯ä½ç½®æ£€æµ‹æŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æå‡ºäº†EPIC-KITCHENS-Må’ŒEgo4D-Mä¸¤ä¸ªå¤§è§„æ¨¡é”™è¯¯æ•°æ®é›†ï¼Œæ¯”ä»¥å¾€æ•°æ®é›†å¤§ä¸¤ä¸ªæ•°é‡çº§ã€‚MisFormeræ¨¡å‹åœ¨è¿™äº›æ•°æ®é›†ä»¥åŠå…ˆå‰çš„åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†ç°æœ‰çš„è§†é¢‘-è¯­è¨€ã€æ—¶é—´å®šä½ã€æ‰‹-å¯¹è±¡äº¤äº’å’Œé”™è¯¯æ£€æµ‹åŸºçº¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½åŠ©æ‰‹ã€æœºå™¨äººè¾…åŠ©æ•™å­¦ã€äººæœºäº¤äº’ç­‰é¢†åŸŸã€‚é€šè¿‡ç†è§£äººç±»åœ¨æ“ä½œè¿‡ç¨‹ä¸­çš„é”™è¯¯ï¼Œæ™ºèƒ½ç³»ç»Ÿå¯ä»¥æä¾›æ›´ç²¾å‡†çš„æŒ‡å¯¼å’Œå¸®åŠ©ï¼Œæé«˜æ“ä½œæ•ˆç‡å’Œå®‰å…¨æ€§ã€‚ä¾‹å¦‚ï¼Œåœ¨çƒ¹é¥ªæ•™å­¦ä¸­ï¼Œç³»ç»Ÿå¯ä»¥è¯†åˆ«ç”¨æˆ·åœ¨å“ªä¸ªæ­¥éª¤å‡ºé”™ï¼Œå¹¶ç»™å‡ºç›¸åº”çš„çº æ­£å»ºè®®ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce Mistake Attribution (MATT), a task for fine-grained understanding of human mistakes in egocentric video. Unlike prior mistake understanding work, which lacks fine-grained output, MATT concretely attributes mistakes to the input instruction text or the attempt video. MATT determines what part of the instruction is violated (semantic role), when the deviation becomes irreversible (the Point-of-No-Return, PNR), and where the mistake appears in the PNR frame. We develop MisEngine, a data engine that automatically constructs attribution-rich mistake samples from existing datasets and inherits their annotations. Applied to large egocentric corpora, MisEngine yields EPIC-KITCHENS-M and Ego4D-M, two datasets that are up to two orders of magnitude larger than prior mistake datasets. We then present MisFormer, a unified attention-based model for mistake attribution across semantic (what), temporal (when), and spatial (where) dimensions, trained using MisEngine supervision. Experiments on our new datasets and prior benchmarks show that MisFormer outperforms strong video-language, temporal localization, hand-object interaction, and mistake-detection baselines.

