---
layout: default
title: 3D-Aware Multi-Task Learning with Cross-View Correlations for Dense Scene Understanding
---

# 3D-Aware Multi-Task Learning with Cross-View Correlations for Dense Scene Understanding

**arXiv**: [2511.20646v1](https://arxiv.org/abs/2511.20646) | [PDF](https://arxiv.org/pdf/2511.20646.pdf)

**ä½œè€…**: Xiaoye Wang, Chen Tang, Xiangyu Yue, Wei-Hong Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25

**å¤‡æ³¨**: 3D-aware Multi-task Learning, Cross-view Correlations, Code will be available at https://github.com/WeiHongLee/CrossView3DMTL

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè·¨è§†è§’ç›¸å…³æ€§çš„3Dæ„ŸçŸ¥å¤šä»»åŠ¡å­¦ä¹ ï¼Œç”¨äºŽå¯†é›†åœºæ™¯ç†è§£**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `å¤šä»»åŠ¡å­¦ä¹ ` `3Dæ„ŸçŸ¥` `è·¨è§†è§’ç›¸å…³æ€§` `ä»£ä»·ä½“` `åœºæ™¯ç†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰MTLæ–¹æ³•åœ¨2Då›¾åƒç©ºé—´æ•èŽ·è·¨ä»»åŠ¡å…³ç³»ï¼Œç¼ºä¹3Dæ„ŸçŸ¥ï¼Œé™åˆ¶äº†åœºæ™¯ç†è§£èƒ½åŠ›ã€‚
2. æå‡ºè·¨è§†è§’æ¨¡å—ï¼ˆCvMï¼‰ï¼Œé€šè¿‡ä»£ä»·ä½“æ•´åˆè·¨è§†è§’ä¿¡æ¯ï¼Œæ³¨å…¥å‡ ä½•ä¸€è‡´æ€§ï¼Œå¢žå¼º3Dæ„ŸçŸ¥ã€‚
3. CvMæ¨¡å—æ˜“äºŽé›†æˆï¼Œåœ¨NYUv2å’ŒPASCAL-Contextæ•°æ®é›†ä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œæå‡äº†MTLæ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ—¨åœ¨è§£å†³è®­ç»ƒå•ä¸ªç½‘ç»œä»¥è”åˆæ‰§è¡Œå¤šä¸ªå¯†é›†é¢„æµ‹ä»»åŠ¡ï¼ˆå¦‚åˆ†å‰²å’Œæ·±åº¦ä¼°è®¡ï¼‰çš„å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ä¸»è¦åœ¨2Då›¾åƒç©ºé—´ä¸­æ•èŽ·è·¨ä»»åŠ¡å…³ç³»ï¼Œé€šå¸¸å¯¼è‡´ç¼ºä¹3Dæ„ŸçŸ¥çš„éžç»“æž„åŒ–ç‰¹å¾ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œ3Dæ„ŸçŸ¥å¯¹äºŽå»ºæ¨¡å¯¹å…¨é¢åœºæ™¯ç†è§£è‡³å…³é‡è¦çš„è·¨ä»»åŠ¡ç›¸å…³æ€§è‡³å…³é‡è¦ã€‚æˆ‘ä»¬æå‡ºé€šè¿‡æ•´åˆè·¨è§†è§’çš„å…³è”ï¼ˆå³ä»£ä»·ä½“ï¼‰ä½œä¸ºMTLç½‘ç»œä¸­çš„å‡ ä½•ä¸€è‡´æ€§æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§çš„è·¨è§†è§’æ¨¡å—ï¼ˆCvMï¼‰ï¼Œè¯¥æ¨¡å—åœ¨ä»»åŠ¡ä¹‹é—´å…±äº«ï¼Œä»¥äº¤æ¢è·¨è§†è§’çš„ä¿¡æ¯å¹¶æ•èŽ·è·¨è§†è§’çš„ç›¸å…³æ€§ï¼Œå¹¶ä¸Žæ¥è‡ªMTLç¼–ç å™¨çš„ç‰¹å¾é›†æˆï¼Œç”¨äºŽå¤šä»»åŠ¡é¢„æµ‹ã€‚è¯¥æ¨¡å—ä¸Žæž¶æž„æ— å…³ï¼Œå¯ä»¥åº”ç”¨äºŽå•è§†å›¾å’Œå¤šè§†å›¾æ•°æ®ã€‚åœ¨NYUv2å’ŒPASCAL-Contextä¸Šçš„å¤§é‡ç»“æžœè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆåœ°å°†å‡ ä½•ä¸€è‡´æ€§æ³¨å…¥åˆ°çŽ°æœ‰çš„MTLæ–¹æ³•ä¸­ï¼Œä»Žè€Œæé«˜æ€§èƒ½ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•åœ¨å¯†é›†åœºæ™¯ç†è§£ä»»åŠ¡ä¸­ï¼Œä¸»è¦ä¾èµ–äºŽ2Då›¾åƒç©ºé—´ä¸­çš„ç‰¹å¾å…³è”ï¼Œå¿½ç•¥äº†åœºæ™¯çš„3Då‡ ä½•ä¿¡æ¯ã€‚è¿™å¯¼è‡´ç½‘ç»œå­¦ä¹ åˆ°çš„ç‰¹å¾ç¼ºä¹3Dæ„ŸçŸ¥èƒ½åŠ›ï¼Œé™åˆ¶äº†å…¶å¯¹åœºæ™¯çš„å…¨é¢ç†è§£ï¼Œå°¤å…¶æ˜¯åœ¨åˆ†å‰²å’Œæ·±åº¦ä¼°è®¡ç­‰ä»»åŠ¡ä¸­ï¼Œ3Dä¿¡æ¯è‡³å…³é‡è¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†3Då‡ ä½•ä¿¡æ¯æ˜¾å¼åœ°å¼•å…¥åˆ°å¤šä»»åŠ¡å­¦ä¹ æ¡†æž¶ä¸­ã€‚å…·ä½“è€Œè¨€ï¼Œé€šè¿‡æž„å»ºè·¨è§†è§’çš„ä»£ä»·ä½“ï¼ˆcost volumeï¼‰æ¥æ•æ‰ä¸åŒè§†è§’ä¹‹é—´çš„å‡ ä½•ä¸€è‡´æ€§ï¼Œå¹¶å°†è¿™ç§å‡ ä½•ä¸€è‡´æ€§ä½œä¸ºä¸€ç§å…ˆéªŒçŸ¥è¯†æ³¨å…¥åˆ°ç½‘ç»œä¸­ï¼Œä»Žè€Œå¢žå¼ºç½‘ç»œå¯¹3Dåœºæ™¯çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…å«ä¸€ä¸ªå¤šä»»åŠ¡å­¦ä¹ ç¼–ç å™¨å’Œä¸€ä¸ªè·¨è§†è§’æ¨¡å—ï¼ˆCvMï¼‰ã€‚ç¼–ç å™¨è´Ÿè´£æå–å›¾åƒç‰¹å¾ï¼ŒCvMæ¨¡å—åˆ™è´Ÿè´£åœ¨ä¸åŒè§†è§’ä¹‹é—´äº¤æ¢ä¿¡æ¯ï¼Œæž„å»ºä»£ä»·ä½“ï¼Œå¹¶æå–è·¨è§†è§’çš„ç›¸å…³æ€§ç‰¹å¾ã€‚è¿™äº›ç‰¹å¾éšåŽä¸Žç¼–ç å™¨çš„ç‰¹å¾èžåˆï¼Œç”¨äºŽå¤šä»»åŠ¡é¢„æµ‹ã€‚è¯¥æ¡†æž¶æ˜¯æž¶æž„æ— å…³çš„ï¼Œå¯ä»¥ä¸ŽçŽ°æœ‰çš„å¤šä»»åŠ¡å­¦ä¹ ç½‘ç»œç»“åˆä½¿ç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šå…³é”®åˆ›æ–°åœ¨äºŽå¼•å…¥äº†è·¨è§†è§’æ¨¡å—ï¼ˆCvMï¼‰ï¼Œé€šè¿‡ä»£ä»·ä½“æ˜¾å¼åœ°å»ºæ¨¡äº†è·¨è§†è§’çš„å‡ ä½•ä¸€è‡´æ€§ã€‚è¿™ä¸Žä»¥å¾€ä¸»è¦å…³æ³¨2Då›¾åƒç©ºé—´ç‰¹å¾å…³è”çš„æ–¹æ³•ä¸åŒï¼ŒCvMæ¨¡å—èƒ½å¤Ÿæœ‰æ•ˆåœ°å°†3Då‡ ä½•ä¿¡æ¯èžå…¥åˆ°å¤šä»»åŠ¡å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œä»Žè€Œæå‡äº†ç½‘ç»œçš„3Dæ„ŸçŸ¥èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šCvMæ¨¡å—çš„è®¾è®¡æ˜¯è½»é‡çº§çš„ï¼Œæ˜“äºŽé›†æˆåˆ°çŽ°æœ‰çš„å¤šä»»åŠ¡å­¦ä¹ ç½‘ç»œä¸­ã€‚å…·ä½“å®žçŽ°ç»†èŠ‚åŒ…æ‹¬ï¼šå¦‚ä½•æž„å»ºä»£ä»·ä½“ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨å“ªäº›ç‰¹å¾è¿›è¡ŒåŒ¹é…ï¼‰ï¼Œå¦‚ä½•æå–è·¨è§†è§’ç›¸å…³æ€§ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨å·ç§¯ç¥žç»ç½‘ç»œï¼‰ï¼Œä»¥åŠå¦‚ä½•å°†è¿™äº›ç‰¹å¾ä¸Žç¼–ç å™¨çš„ç‰¹å¾è¿›è¡Œèžåˆï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶ï¼‰ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿéœ€è¦è€ƒè™‘å¦‚ä½•å¹³è¡¡ä¸åŒä»»åŠ¡ä¹‹é—´çš„å­¦ä¹ ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨å‡ ä½•ä¸€è‡´æ€§ä¿¡æ¯æ¥çº¦æŸç½‘ç»œçš„å­¦ä¹ ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨NYUv2å’ŒPASCAL-Contextæ•°æ®é›†ä¸Šçš„å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡å¤šä»»åŠ¡å­¦ä¹ çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨NYUv2æ•°æ®é›†ä¸Šï¼Œåˆ†å‰²ä»»åŠ¡çš„æ€§èƒ½æå‡äº†X%ï¼Œæ·±åº¦ä¼°è®¡ä»»åŠ¡çš„æ€§èƒ½æå‡äº†Y%ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€å¢žå¼ºçŽ°å®žç­‰é¢†åŸŸã€‚é€šè¿‡æå‡åœºæ™¯ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥æé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„çŽ¯å¢ƒæ„ŸçŸ¥ç²¾åº¦ï¼Œå¢žå¼ºæœºå™¨äººå¯¹å¤æ‚çŽ¯å¢ƒçš„é€‚åº”æ€§ï¼Œå¹¶ä¸ºARåº”ç”¨æä¾›æ›´é€¼çœŸçš„3Dåœºæ™¯é‡å»ºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper addresses the challenge of training a single network to jointly perform multiple dense prediction tasks, such as segmentation and depth estimation, i.e., multi-task learning (MTL). Current approaches mainly capture cross-task relations in the 2D image space, often leading to unstructured features lacking 3D-awareness. We argue that 3D-awareness is vital for modeling cross-task correlations essential for comprehensive scene understanding. We propose to address this problem by integrating correlations across views, i.e., cost volume, as geometric consistency in the MTL network. Specifically, we introduce a lightweight Cross-view Module (CvM), shared across tasks, to exchange information across views and capture cross-view correlations, integrated with a feature from MTL encoder for multi-task predictions. This module is architecture-agnostic and can be applied to both single and multi-view data. Extensive results on NYUv2 and PASCAL-Context demonstrate that our method effectively injects geometric consistency into existing MTL methods to improve performance.

