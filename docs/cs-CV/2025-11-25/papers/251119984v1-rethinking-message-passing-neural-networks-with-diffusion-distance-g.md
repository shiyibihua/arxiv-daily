---
layout: default
title: Rethinking Message Passing Neural Networks with Diffusion Distance-guided Stress Majorization
---

# Rethinking Message Passing Neural Networks with Diffusion Distance-guided Stress Majorization

**arXiv**: [2511.19984v1](https://arxiv.org/abs/2511.19984) | [PDF](https://arxiv.org/pdf/2511.19984.pdf)

**ä½œè€…**: Haoran Zheng, Renchi Yang, Yubo Zhou, Jianliang Xu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDDSMæ¨¡åž‹ä»¥è§£å†³å›¾ç¥žç»ç½‘ç»œä¸­çš„è¿‡å¹³æ»‘å’Œè¿‡ç›¸å…³é—®é¢˜**

**å…³é”®è¯**: `æ¶ˆæ¯ä¼ é€’ç¥žç»ç½‘ç»œ` `æ‰©æ•£è·ç¦»` `åº”åŠ›ä¼˜åŒ–` `å›¾å­¦ä¹ ` `è¿‡å¹³æ»‘é—®é¢˜`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šMPNNå› æœ€å°åŒ–Dirichletèƒ½é‡å¯¼è‡´è¿‡å¹³æ»‘å’Œè¿‡ç›¸å…³
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆåº”åŠ›ä¼˜åŒ–ã€æ­£äº¤æ­£åˆ™åŒ–å’Œæ‰©æ•£è·ç¦»æŒ‡å¯¼æ¶ˆæ¯ä¼ é€’
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨15ä¸ªåŸºçº¿ä¸­ï¼ŒäºŽåŒè´¨å’Œå¼‚è´¨å›¾ä¸Šè¡¨çŽ°æ˜¾è‘—æå‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Message passing neural networks (MPNNs) have emerged as go-to models for learning on graph-structured data in the past decade. Despite their effectiveness, most of such models still incur severe issues such as over-smoothing and -correlation, due to their underlying objective of minimizing the Dirichlet energy and the derived neighborhood aggregation operations. In this paper, we propose the DDSM, a new MPNN model built on an optimization framework that includes the stress majorization and orthogonal regularization for overcoming the above issues. Further, we introduce the diffusion distances for nodes into the framework to guide the new message passing operations and develop efficient algorithms for distance approximations, both backed by rigorous theoretical analyses. Our comprehensive experiments showcase that DDSM consistently and considerably outperforms 15 strong baselines on both homophilic and heterophilic graphs.

