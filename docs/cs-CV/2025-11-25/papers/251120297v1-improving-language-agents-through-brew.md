---
layout: default
title: Improving Language Agents through BREW
---

# Improving Language Agents through BREW

**arXiv**: [2511.20297v1](https://arxiv.org/abs/2511.20297) | [PDF](https://arxiv.org/pdf/2511.20297.pdf)

**ä½œè€…**: Shashank Kirtania, Param Biyani, Priyanshu Gupta, Yasharth Bajpai, Roshni Iyer, Sumit Gulwani, Gustavo Soares

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBREWæ¡†æž¶ï¼Œé€šè¿‡æž„å»ºå’Œç²¾ç‚¼çŸ¥è¯†åº“ä¼˜åŒ–è¯­è¨€æ™ºèƒ½ä½“æ€§èƒ½ã€‚**

**å…³é”®è¯**: `è¯­è¨€æ™ºèƒ½ä½“ä¼˜åŒ–` `çŸ¥è¯†åº“æž„å»º` `ç»“æž„åŒ–è®°å¿†` `ä»»åŠ¡è¯„åˆ†` `è¡Œä¸ºå‡†åˆ™` `è®¡ç®—æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ™ºèƒ½ä½“è®­ç»ƒæ–¹æ³•è®¡ç®—å¼€é”€å¤§ä¸”ç­–ç•¥éš¾ä»¥è§£é‡Šå’Œé€‚åº”ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨ä»»åŠ¡è¯„åˆ†å’Œè¡Œä¸ºå‡†åˆ™æž„å»ºç»“æž„åŒ–è®°å¿†ï¼Œæå‡æ£€ç´¢å’Œç²¾ç‚¼æ•ˆçŽ‡ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†ä¸Šä»»åŠ¡ç²¾åº¦æå‡10-20%ï¼Œå·¥å…·è°ƒç”¨å‡å°‘10-15%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Language Model (LLM)-based agents are increasingly applied to tasks requiring structured reasoning, tool use, and environmental adaptation, such as data manipulation, multistep planning, and computer-use automation. However, despite their versatility, current training paradigms for model weight optimization methods, like PPO and GRPO, remain relatively impractical with their high computational overhead for rollout convergence. In addition, the resulting agent policies are difficult to interpret, adapt, or incrementally improve. To address this, we investigate creating and refining structured memory of experiential learning of an agent from its environment as an alternative route to agent optimization. We introduce BREW (Bootstrapping expeRientially-learned Environmental knoWledge), a framework for agent optimization for downstream tasks via KB construction and refinement. In our formulation, we introduce an effective method for partitioning agent memory for more efficient retrieval and refinement. BREW uses task graders and behavior rubrics to learn insights while leveraging state-space search for ensuring robustness from the noise and non-specificity in natural language. Empirical results on real world, domain-grounded benchmarks -- OSWorld, $Ï„^2$Bench, and SpreadsheetBench -- show BREW achieves $10-20\%$ improvement in task precision, $10-15\%$ reduction in API/tool calls leading to faster execution time, all while maintaining computational efficiency on par with base models. Unlike prior work where memory is treated as static context, we establish the KB as a modular and controllable substrate for agent optimization -- an explicit lever for shaping behavior in a transparent, interpretable, and extensible manner.

