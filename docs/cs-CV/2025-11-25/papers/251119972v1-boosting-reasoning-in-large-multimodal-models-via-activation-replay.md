---
layout: default
title: Boosting Reasoning in Large Multimodal Models via Activation Replay
---

# Boosting Reasoning in Large Multimodal Models via Activation Replay

**arXiv**: [2511.19972v1](https://arxiv.org/abs/2511.19972) | [PDF](https://arxiv.org/pdf/2511.19972.pdf)

**ä½œè€…**: Yun Xing, Xiaobin Hu, Qingdong He, Jiangning Zhang, Shuicheng Yan, Shijian Lu, Yu-Gang Jiang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¿€æ´»é‡æ”¾ä»¥æå‡åŽè®­ç»ƒå¤§åž‹å¤šæ¨¡æ€æ¨¡åž‹çš„æŽ¨ç†èƒ½åŠ›**

**å…³é”®è¯**: `å¤§åž‹å¤šæ¨¡æ€æ¨¡åž‹` `æŽ¨ç†èƒ½åŠ›æå‡` `æ¿€æ´»é‡æ”¾` `åŽè®­ç»ƒä¼˜åŒ–` `å¤šæ¨¡æ€æŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šRLVRåŽè®­ç»ƒæœºåˆ¶æœªæ˜Žï¼Œå½±å“ä½Žç†µæ¿€æ´»ï¼Œå¯èƒ½é˜»ç¢æŽ¨ç†ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ— éœ€è®­ç»ƒï¼Œæµ‹è¯•æ—¶é‡æ”¾åŸºç¡€æ¨¡åž‹ä½Žç†µæ¿€æ´»è°ƒèŠ‚RLVRæ¨¡åž‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæå‡æ•°å­¦ã€è§†è§‰ä»£ç†å’Œè§†é¢‘æŽ¨ç†æ€§èƒ½ï¼Œæ”¹å–„Pass@KæŒ‡æ ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recently, Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an effective approach to incentivizing reasoning capability in Large Multimodal Models (LMMs), while the underlying mechanisms behind this post-training paradigm are poorly understood. We begin by exploring how input activations are affected by RLVR through the perspective of logit lens. Our systematic investigations across multiple post-trained LMMs suggest that RLVR shifts low-entropy activations unexpectedly, while high-entropy ones are less affected. We further demonstrate that such phenomena are associated with LMM reasoning by controlled experiments, suggesting a potentially beneficial role of modulating low-entropy activations. To this end, we propose Activation Replay, a novel simple yet effective training-free approach that boosts multimodal reasoning of post-trained LMMs without requiring expensive policy optimization. Our design involves manipulation of visual tokens at test time, replaying low-entropy activations from the input context of base LMMs to regulating the RLVR counterparts. Activation Replay triggers better reasoning across diverse scenarios, including mathematics, o3-like visual agents, and video reasoning. We further show that Activation Replay boosts Pass@K and mitigates narrower reasoning coverage of RLVR. Our design is compared against alternative choices, such as replaying high-entropy activations instead of low-entropy ones, or direct cross-model intervention instead of manipulating input tokens, demonstrating the superiority of our implementation. Codes will be made publicly available.

