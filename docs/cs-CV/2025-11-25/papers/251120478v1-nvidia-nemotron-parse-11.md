---
layout: default
title: NVIDIA Nemotron Parse 1.1
---

# NVIDIA Nemotron Parse 1.1

**arXiv**: [2511.20478v1](https://arxiv.org/abs/2511.20478) | [PDF](https://arxiv.org/pdf/2511.20478.pdf)

**ä½œè€…**: Kateryna Chumachenko, Amala Sanjay Deshmukh, Jarno Seppanen, Ilia Karmanov, Chia-Chih Chen, Lukas Voegtle, Philipp Fischer, Marek Wawrzos, Saeid Motiian, Roman Ageev, Kedi Wu, Alexandre Milesi, Maryam Moosaei, Krzysztof Pawelec, Padmavathy Subramanian, Mehrzad Samadi, Xin Yu, Celina Dear, Sarah Stoddard, Jenna Diamond, Jesse Oliver, Leanna Chraghchian, Patrick Skelly, Tom Balough, Yao Xu, Jane Polak Scowcroft, Daniel Korzekwa, Darragh Hanley, Sandip Bhaskar, Timo Roman, Karan Sapra, Andrew Tao, Bryan Catanzaro

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNemotron-Parse-1.1è½»é‡æ–‡æ¡£è§£æžæ¨¡åž‹ï¼Œæå‡OCRã€è¡¨æ ¼è§£æžå’Œå›¾è¡¨æ–‡æœ¬æå–èƒ½åŠ›ã€‚**

**å…³é”®è¯**: `æ–‡æ¡£è§£æž` `OCRæ¨¡åž‹` `è¡¨æ ¼è§£æž` `è½»é‡æž¶æž„` `ç¼–ç å™¨-è§£ç å™¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè½»é‡æ–‡æ¡£è§£æžéœ€é«˜æ•ˆå¤„ç†OCRã€è¡¨æ ¼å’Œå›¾è¡¨æ–‡æœ¬ï¼Œæ”¯æŒé•¿åºåˆ—è¾“å‡ºã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨æž¶æž„ï¼Œå‚æ•°é‡885Mï¼ŒåŒ…æ‹¬ç´§å‡‘è¯­è¨€è§£ç å™¨ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å…¬å…±åŸºå‡†ä¸Šå®žçŽ°ç«žäº‰æ€§å‡†ç¡®çŽ‡ï¼Œå¹¶å‘å¸ƒä¼˜åŒ–ç‰ˆæœ¬æå‡é€Ÿåº¦ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce Nemotron-Parse-1.1, a lightweight document parsing and OCR model that advances the capabilities of its predecessor, Nemoretriever-Parse-1.0. Nemotron-Parse-1.1 delivers improved capabilities across general OCR, markdown formatting, structured table parsing, and text extraction from pictures, charts, and diagrams. It also supports a longer output sequence length for visually dense documents. As with its predecessor, it extracts bounding boxes of text segments, as well as corresponding semantic classes. Nemotron-Parse-1.1 follows an encoder-decoder architecture with 885M parameters, including a compact 256M-parameter language decoder. It achieves competitive accuracy on public benchmarks making it a strong lightweight OCR solution. We release the model weights publicly on Huggingface, as well as an optimized NIM container, along with a subset of the training data as part of the broader Nemotron-VLM-v2 dataset. Additionally, we release Nemotron-Parse-1.1-TC which operates on a reduced vision token length, offering a 20% speed improvement with minimal quality degradation.

