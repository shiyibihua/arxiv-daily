---
layout: default
title: EmoFeedback2: Reinforcement of Continuous Emotional Image Generation via LVLM-based Reward and Textual Feedback
---

# EmoFeedback2: Reinforcement of Continuous Emotional Image Generation via LVLM-based Reward and Textual Feedback

**arXiv**: [2511.19982v1](https://arxiv.org/abs/2511.19982) | [PDF](https://arxiv.org/pdf/2511.19982.pdf)

**ä½œè€…**: Jingyang Jia, Kai Shu, Gang Yang, Long Xing, Xun Chen, Aiping Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEmoFeedback2èŒƒå¼ï¼Œé€šè¿‡LVLMå¥–åŠ±ä¸Žæ–‡æœ¬åé¦ˆå¼ºåŒ–è¿žç»­æƒ…æ„Ÿå›¾åƒç”Ÿæˆ**

**å…³é”®è¯**: `è¿žç»­æƒ…æ„Ÿå›¾åƒç”Ÿæˆ` `å¤§è§†è§‰è¯­è¨€æ¨¡åž‹` `å¼ºåŒ–å¾®è°ƒ` `æƒ…æ„Ÿå¥–åŠ±` `æ–‡æœ¬åé¦ˆ` `æƒ…æ„Ÿä¿çœŸåº¦`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ç¼ºä¹æƒ…æ„Ÿåé¦ˆï¼Œéš¾ä»¥æŽ§åˆ¶å›¾åƒæƒ…æ„Ÿè¿žç»­æ€§
2. åˆ©ç”¨å¾®è°ƒLVLMæä¾›å¥–åŠ±å’Œæ–‡æœ¬åé¦ˆï¼Œå¢žå¼ºæƒ…æ„Ÿè¿žç»­æ€§å’Œä¿çœŸåº¦
3. å®žéªŒæ˜¾ç¤ºåœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œç”Ÿæˆé«˜è´¨é‡æƒ…æ„Ÿå›¾åƒ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Continuous emotional image generation (C-EICG) is emerging rapidly due to its ability to produce images aligned with both user descriptions and continuous emotional values. However, existing approaches lack emotional feedback from generated images, limiting the control of emotional continuity. Additionally, their simple alignment between emotions and naively generated texts fails to adaptively adjust emotional prompts according to image content, leading to insufficient emotional fidelity. To address these concerns, we propose a novel generation-understanding-feedback reinforcement paradigm (EmoFeedback2) for C-EICG, which exploits the reasoning capability of the fine-tuned large vision-language model (LVLM) to provide reward and textual feedback for generating high-quality images with continuous emotions. Specifically, we introduce an emotion-aware reward feedback strategy, where the LVLM evaluates the emotional values of generated images and computes the reward against target emotions, guiding the reinforcement fine-tuning of the generative model and enhancing the emotional continuity of images. Furthermore, we design a self-promotion textual feedback framework, in which the LVLM iteratively analyzes the emotional content of generated images and adaptively produces refinement suggestions for the next-round prompt, improving the emotional fidelity with fine-grained content. Extensive experimental results demonstrate that our approach effectively generates high-quality images with the desired emotions, outperforming existing state-of-the-art methods in our custom dataset. The code and dataset will be released soon.

