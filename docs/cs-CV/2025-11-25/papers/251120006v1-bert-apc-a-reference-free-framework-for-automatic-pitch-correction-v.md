---
layout: default
title: BERT-APC: A Reference-free Framework for Automatic Pitch Correction via Musical Context Inference
---

# BERT-APC: A Reference-free Framework for Automatic Pitch Correction via Musical Context Inference

**arXiv**: [2511.20006v1](https://arxiv.org/abs/2511.20006) | [PDF](https://arxiv.org/pdf/2511.20006.pdf)

**ä½œè€…**: Sungjae Kim, Kihyun Na, Jinyoung Choi, Injung Kim

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBERT-APCæ¡†æž¶ï¼Œé€šè¿‡éŸ³ä¹ä¸Šä¸‹æ–‡æŽ¨ç†å®žçŽ°æ— å‚è€ƒéŸ³é«˜æ ¡æ­£**

**å…³é”®è¯**: `è‡ªåŠ¨éŸ³é«˜æ ¡æ­£` `éŸ³ä¹è¯­è¨€æ¨¡åž‹` `æ— å‚è€ƒç³»ç»Ÿ` `éŸ³é«˜é¢„æµ‹` `æ•°æ®å¢žå¼º` `è‡ªç„¶æ€§ä¿æŒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è‡ªåŠ¨éŸ³é«˜æ ¡æ­£ç³»ç»Ÿä¾èµ–å‚è€ƒéŸ³é«˜æˆ–ç®€å•ä¼°è®¡ç®—æ³•ï¼Œéš¾ä»¥ä¿æŒè‡ªç„¶æ€§å’Œè¡¨çŽ°åŠ›
2. ç»“åˆå›ºå®šéŸ³é«˜é¢„æµ‹å™¨å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥éŸ³é«˜é¢„æµ‹å™¨ï¼Œåˆ©ç”¨éŸ³ä¹è¯­è¨€æ¨¡åž‹æŽ¨æ–­æ„å›¾éŸ³é«˜åºåˆ—
3. åœ¨é«˜åº¦å¤±è°æ ·æœ¬ä¸ŠéŸ³é«˜é¢„æµ‹å‡†ç¡®çŽ‡æå‡10.49%ï¼ŒMOSæµ‹è¯•å¾—åˆ†4.32ï¼Œä¼˜äºŽAutoTuneå’ŒMelodyne

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Automatic Pitch Correction (APC) enhances vocal recordings by aligning pitch deviations with the intended musical notes. However, existing APC systems either rely on reference pitches, which limits their practical applicability, or employ simple pitch estimation algorithms that often fail to preserve expressiveness and naturalness. We propose BERT-APC, a novel reference-free APC framework that corrects pitch errors while maintaining the natural expressiveness of vocal performances. In BERT-APC, a novel stationary pitch predictor first estimates the perceived pitch of each note from the detuned singing voice. A context-aware note pitch predictor estimates the intended pitch sequence by leveraging a music language model repurposed to incorporate musical context. Finally, a note-level correction algorithm fixes pitch errors while preserving intentional pitch deviations for emotional expression. In addition, we introduce a learnable data augmentation strategy that improves the robustness of the music language model by simulating realistic detuning patterns. Compared to two recent singing voice transcription models, BERT-APC demonstrated superior performance in note pitch prediction, outperforming the second-best model, ROSVOT, by 10.49%p on highly detuned samples in terms of the raw pitch accuracy. In the MOS test, BERT-APC achieved the highest score of $4.32 \pm 0.15$, which is significantly higher than those of the widely-used commercial APC tools, AutoTune ($3.22 \pm 0.18$) and Melodyne ($3.08 \pm 0.18$), while maintaining a comparable ability to preserve expressive nuances. To the best of our knowledge, this is the first APC model that leverages a music language model to achieve reference-free pitch correction with symbolic musical context. The corrected audio samples of BERT-APC are available online.

