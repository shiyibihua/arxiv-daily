---
layout: default
title: GigaWorld-0: World Models as Data Engine to Empower Embodied AI
---

# GigaWorld-0: World Models as Data Engine to Empower Embodied AI

**arXiv**: [2511.19861v2](https://arxiv.org/abs/2511.19861) | [PDF](https://arxiv.org/pdf/2511.19861.pdf)

**ä½œè€…**: GigaWorld Team, Angen Ye, Boyuan Wang, Chaojun Ni, Guan Huang, Guosheng Zhao, Haoyun Li, Jiagang Zhu, Kerui Li, Mengyuan Xu, Qiuping Deng, Siting Wang, Wenkang Qin, Xinze Chen, Xiaofeng Wang, Yankai Wang, Yu Cao, Yifan Chang, Yuan Xu, Yun Ye, Yang Wang, Yukun Zhou, Zhengyuan Zhang, Zhehao Dong, Zheng Zhu

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25 (æ›´æ–°: 2025-11-30)

**å¤‡æ³¨**: Project Page: https://giga-world-0.github.io/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**GigaWorld-0ï¼šæž„å»ºä¸–ç•Œæ¨¡åž‹ä½œä¸ºæ•°æ®å¼•æ“Žï¼Œèµ‹èƒ½å…·èº«æ™ºèƒ½ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `ä¸–ç•Œæ¨¡åž‹` `å…·èº«æ™ºèƒ½` `æ•°æ®å¼•æ“Ž` `è§†é¢‘ç”Ÿæˆ` `3Dç”Ÿæˆ` `æœºå™¨äººå­¦ä¹ ` `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `åˆæˆæ•°æ®`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å…·èº«æ™ºèƒ½æ–¹æ³•é¢ä¸´æ•°æ®æ•ˆçŽ‡å’Œæ³›åŒ–æ€§æŒ‘æˆ˜ï¼ŒçœŸå®žä¸–ç•Œæ•°æ®æ˜‚è´µä¸”éš¾ä»¥è¦†ç›–æ‰€æœ‰åœºæ™¯ã€‚
2. GigaWorld-0æå‡ºä¸€ç§ä¸–ç•Œæ¨¡åž‹æ¡†æž¶ï¼Œé€šè¿‡è§†é¢‘å’Œ3Dç”ŸæˆæŠ€æœ¯åˆæˆé«˜è´¨é‡ã€å¤šæ ·åŒ–çš„å…·èº«äº¤äº’æ•°æ®ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œä½¿ç”¨GigaWorld-0ç”Ÿæˆçš„æ•°æ®è®­ç»ƒçš„VLAæ¨¡åž‹åœ¨çœŸå®žæœºå™¨äººä»»åŠ¡ä¸­è¡¨çŽ°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†GigaWorld-0ï¼Œä¸€ä¸ªç»Ÿä¸€çš„ä¸–ç•Œæ¨¡åž‹æ¡†æž¶ï¼Œä¸“é—¨è®¾è®¡ä½œä¸ºè§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)å­¦ä¹ çš„æ•°æ®å¼•æ“Žã€‚GigaWorld-0é›†æˆäº†ä¸¤ä¸ªååŒç»„ä»¶ï¼šGigaWorld-0-Videoï¼Œåˆ©ç”¨å¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆï¼Œåœ¨å¤–è§‚ã€ç›¸æœºè§†è§’å’ŒåŠ¨ä½œè¯­ä¹‰çš„ç²¾ç»†æŽ§åˆ¶ä¸‹ï¼Œäº§ç”Ÿå¤šæ ·ã€çº¹ç†ä¸°å¯Œä¸”æ—¶é—´ä¸Šè¿žè´¯çš„å…·èº«åºåˆ—ï¼›GigaWorld-0-3Dï¼Œç»“åˆäº†3Dç”Ÿæˆå»ºæ¨¡ã€3Dé«˜æ–¯æº…å°„é‡å»ºã€ç‰©ç†å¯å¾®ç³»ç»Ÿè¾¨è¯†å’Œå¯æ‰§è¡Œçš„è¿åŠ¨è§„åˆ’ï¼Œä»¥ç¡®ä¿å‡ ä½•ä¸€è‡´æ€§å’Œç‰©ç†çœŸå®žæ„Ÿã€‚å®ƒä»¬çš„è”åˆä¼˜åŒ–å®žçŽ°äº†å…·èº«äº¤äº’æ•°æ®çš„å¯æ‰©å±•åˆæˆï¼Œè¿™äº›æ•°æ®åœ¨è§†è§‰ä¸Šå¼•äººæ³¨ç›®ã€ç©ºé—´ä¸Šè¿žè´¯ã€ç‰©ç†ä¸Šåˆç†ä¸”ä¸ŽæŒ‡ä»¤å¯¹é½ã€‚é€šè¿‡é«˜æ•ˆçš„GigaTrainæ¡†æž¶ï¼Œåˆ©ç”¨FP8ç²¾åº¦å’Œç¨€ç–æ³¨æ„åŠ›ï¼Œå¤§å¹…é™ä½Žäº†å†…å­˜å’Œè®¡ç®—éœ€æ±‚ï¼Œä»Žè€Œå®žçŽ°äº†å¤§è§„æ¨¡è®­ç»ƒã€‚ç»¼åˆè¯„ä¼°è¡¨æ˜Žï¼ŒGigaWorld-0ç”Ÿæˆé«˜è´¨é‡ã€å¤šæ ·åŒ–å’Œå¯æŽ§çš„æ•°æ®ã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼Œåœ¨GigaWorld-0ç”Ÿæˆçš„æ•°æ®ä¸Šè®­ç»ƒçš„VLAæ¨¡åž‹ï¼ˆä¾‹å¦‚ï¼ŒGigaBrain-0ï¼‰å®žçŽ°äº†å¼ºå¤§çš„çœŸå®žä¸–ç•Œæ€§èƒ½ï¼Œæ˜¾è‘—æé«˜äº†åœ¨ç‰©ç†æœºå™¨äººä¸Šçš„æ³›åŒ–èƒ½åŠ›å’Œä»»åŠ¡æˆåŠŸçŽ‡ï¼Œè€Œæ— éœ€åœ¨è®­ç»ƒæœŸé—´è¿›è¡Œä»»ä½•çœŸå®žä¸–ç•Œçš„äº¤äº’ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰å…·èº«æ™ºèƒ½å­¦ä¹ æ–¹æ³•ä¾èµ–å¤§é‡çœŸå®žä¸–ç•Œæ•°æ®ï¼Œæˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥è¦†ç›–å„ç§åœºæ™¯å’Œäº¤äº’æ–¹å¼ã€‚è¿™é™åˆ¶äº†æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›å’Œåœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„é€‚åº”æ€§ã€‚å› æ­¤ï¼Œå¦‚ä½•é«˜æ•ˆåœ°ç”Ÿæˆé«˜è´¨é‡ã€å¤šæ ·åŒ–çš„å…·èº«äº¤äº’æ•°æ®ï¼Œæˆä¸ºæå‡å…·èº«æ™ºèƒ½æ¨¡åž‹æ€§èƒ½çš„å…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGigaWorld-0çš„æ ¸å¿ƒæ€è·¯æ˜¯æž„å»ºä¸€ä¸ªä¸–ç•Œæ¨¡åž‹ï¼Œè¯¥æ¨¡åž‹èƒ½å¤Ÿç”Ÿæˆè§†è§‰ä¸Šé€¼çœŸã€ç‰©ç†ä¸Šåˆç†ä¸”ä¸ŽæŒ‡ä»¤å¯¹é½çš„å…·èº«äº¤äº’æ•°æ®ã€‚é€šè¿‡å¤§è§„æ¨¡ç”Ÿæˆåˆæˆæ•°æ®ï¼Œå¯ä»¥æœ‰æ•ˆé™ä½Žå¯¹çœŸå®žä¸–ç•Œæ•°æ®çš„ä¾èµ–ï¼Œå¹¶æå‡æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¥æ–¹æ³•å°†è§†é¢‘ç”Ÿæˆå’Œ3Dç”Ÿæˆç›¸ç»“åˆï¼Œä»¥ç¡®ä¿æ•°æ®çš„å¤šæ ·æ€§ã€å‡ ä½•ä¸€è‡´æ€§å’Œç‰©ç†çœŸå®žæ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šGigaWorld-0æ¡†æž¶åŒ…å«ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼šGigaWorld-0-Videoå’ŒGigaWorld-0-3Dã€‚GigaWorld-0-Videoåˆ©ç”¨å¤§è§„æ¨¡è§†é¢‘ç”ŸæˆæŠ€æœ¯ï¼Œç”Ÿæˆå…·æœ‰å¤šæ ·å¤–è§‚ã€ç›¸æœºè§†è§’å’ŒåŠ¨ä½œè¯­ä¹‰çš„å…·èº«åºåˆ—ã€‚GigaWorld-0-3Dç»“åˆäº†3Dç”Ÿæˆå»ºæ¨¡ã€3Dé«˜æ–¯æº…å°„é‡å»ºã€ç‰©ç†å¯å¾®ç³»ç»Ÿè¾¨è¯†å’Œå¯æ‰§è¡Œçš„è¿åŠ¨è§„åˆ’ï¼Œä»¥ç¡®ä¿æ•°æ®çš„å‡ ä½•ä¸€è‡´æ€§å’Œç‰©ç†çœŸå®žæ€§ã€‚è¿™ä¸¤ä¸ªç»„ä»¶é€šè¿‡è”åˆä¼˜åŒ–ï¼Œç”Ÿæˆé«˜è´¨é‡çš„å…·èº«äº¤äº’æ•°æ®ã€‚æ­¤å¤–ï¼ŒGigaTrainæ¡†æž¶åˆ©ç”¨FP8ç²¾åº¦å’Œç¨€ç–æ³¨æ„åŠ›ï¼Œé™ä½Žäº†å¤§è§„æ¨¡è®­ç»ƒçš„è®¡ç®—å’Œå†…å­˜éœ€æ±‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šGigaWorld-0çš„å…³é”®åˆ›æ–°åœ¨äºŽå°†è§†é¢‘ç”Ÿæˆå’Œ3Dç”Ÿæˆç›¸ç»“åˆï¼Œä»¥ç”Ÿæˆé«˜è´¨é‡ã€å¤šæ ·åŒ–ä¸”ç‰©ç†ä¸Šåˆç†çš„å…·èº«äº¤äº’æ•°æ®ã€‚è¿™ç§æ–¹æ³•ä¸ä»…èƒ½å¤Ÿç”Ÿæˆè§†è§‰ä¸Šé€¼çœŸçš„åœºæ™¯ï¼Œè¿˜èƒ½å¤Ÿä¿è¯åœºæ™¯çš„å‡ ä½•ä¸€è‡´æ€§å’Œç‰©ç†çœŸå®žæ€§ï¼Œä»Žè€Œä½¿æ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ ç‰©ç†ä¸–ç•Œçš„è§„å¾‹ã€‚æ­¤å¤–ï¼ŒGigaTrainæ¡†æž¶é€šè¿‡FP8ç²¾åº¦å’Œç¨€ç–æ³¨æ„åŠ›ï¼Œæ˜¾è‘—é™ä½Žäº†å¤§è§„æ¨¡è®­ç»ƒçš„è®¡ç®—å’Œå†…å­˜éœ€æ±‚ï¼Œä½¿å¾—åœ¨å¤§åž‹æ•°æ®é›†ä¸Šè®­ç»ƒå¤æ‚çš„å…·èº«æ™ºèƒ½æ¨¡åž‹æˆä¸ºå¯èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šGigaWorld-0-Videoé‡‡ç”¨å¤§è§„æ¨¡è§†é¢‘ç”Ÿæˆæ¨¡åž‹ï¼Œé€šè¿‡æŽ§åˆ¶å¤–è§‚ã€ç›¸æœºè§†è§’å’ŒåŠ¨ä½œè¯­ä¹‰ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„å…·èº«åºåˆ—ã€‚GigaWorld-0-3Dé‡‡ç”¨3Dé«˜æ–¯æº…å°„é‡å»ºæŠ€æœ¯ï¼Œä»Žå¤šè§†è§’å›¾åƒä¸­é‡å»ºå‡ºé«˜è´¨é‡çš„3Dåœºæ™¯ã€‚ç‰©ç†å¯å¾®ç³»ç»Ÿè¾¨è¯†ç”¨äºŽå­¦ä¹ åœºæ™¯çš„ç‰©ç†å±žæ€§ï¼Œä¾‹å¦‚è´¨é‡ã€æ‘©æ“¦åŠ›ç­‰ã€‚å¯æ‰§è¡Œçš„è¿åŠ¨è§„åˆ’ç”¨äºŽç”Ÿæˆåˆç†çš„æœºå™¨äººè¿åŠ¨è½¨è¿¹ã€‚GigaTrainæ¡†æž¶é‡‡ç”¨FP8ç²¾åº¦ï¼Œé™ä½Žäº†å†…å­˜å ç”¨ï¼Œå¹¶é‡‡ç”¨ç¨€ç–æ³¨æ„åŠ›ï¼Œå‡å°‘äº†è®¡ç®—é‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨GigaWorld-0ç”Ÿæˆçš„æ•°æ®ä¸Šè®­ç»ƒçš„VLAæ¨¡åž‹ï¼ˆGigaBrain-0ï¼‰åœ¨çœŸå®žæœºå™¨äººä»»åŠ¡ä¸­è¡¨çŽ°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œæ— éœ€ä»»ä½•çœŸå®žä¸–ç•Œäº¤äº’è®­ç»ƒå³å¯å®žçŽ°å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆé™ä½Žå¯¹çœŸå®žä¸–ç•Œæ•°æ®çš„ä¾èµ–ï¼Œå¹¶æå‡å…·èº«æ™ºèƒ½æ¨¡åž‹çš„æ€§èƒ½ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

GigaWorld-0ç”Ÿæˆçš„åˆæˆæ•°æ®å¯ç”¨äºŽè®­ç»ƒå„ç§å…·èº«æ™ºèƒ½æ¨¡åž‹ï¼Œä¾‹å¦‚æœºå™¨äººå¯¼èˆªã€ç‰©ä½“æ“ä½œå’Œäººæœºäº¤äº’ã€‚è¯¥æŠ€æœ¯å¯ä»¥åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½åˆ¶é€ ã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸï¼Œé™ä½Žå¯¹çœŸå®žä¸–ç•Œæ•°æ®çš„ä¾èµ–ï¼ŒåŠ é€Ÿå…·èº«æ™ºèƒ½æŠ€æœ¯çš„è½åœ°å’Œåº”ç”¨ã€‚æœªæ¥ï¼Œå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•GigaWorld-0çš„èƒ½åŠ›ï¼Œä¾‹å¦‚æ”¯æŒæ›´å¤æ‚çš„ç‰©ç†äº¤äº’ã€æ›´é€¼çœŸçš„åœºæ™¯å’Œæ›´æ™ºèƒ½çš„ä»£ç†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> World models are emerging as a foundational paradigm for scalable, data-efficient embodied AI. In this work, we present GigaWorld-0, a unified world model framework designed explicitly as a data engine for Vision-Language-Action (VLA) learning. GigaWorld-0 integrates two synergistic components: GigaWorld-0-Video, which leverages large-scale video generation to produce diverse, texture-rich, and temporally coherent embodied sequences under fine-grained control of appearance, camera viewpoint, and action semantics; and GigaWorld-0-3D, which combines 3D generative modeling, 3D Gaussian Splatting reconstruction, physically differentiable system identification, and executable motion planning to ensure geometric consistency and physical realism. Their joint optimization enables the scalable synthesis of embodied interaction data that is visually compelling, spatially coherent, physically plausible, and instruction-aligned. Training at scale is made feasible through our efficient GigaTrain framework, which exploits FP8-precision and sparse attention to drastically reduce memory and compute requirements. We conduct comprehensive evaluations showing that GigaWorld-0 generates high-quality, diverse, and controllable data across multiple dimensions. Critically, VLA model (e.g., GigaBrain-0) trained on GigaWorld-0-generated data achieve strong real-world performance, significantly improving generalization and task success on physical robots without any real-world interaction during training.

