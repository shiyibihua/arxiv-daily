---
layout: default
title: OmniAlpha: A Sequence-to-Sequence Framework for Unified Multi-Task RGBA Generation
---

# OmniAlpha: A Sequence-to-Sequence Framework for Unified Multi-Task RGBA Generation

**arXiv**: [2511.20211v1](https://arxiv.org/abs/2511.20211) | [PDF](https://arxiv.org/pdf/2511.20211.pdf)

**ä½œè€…**: Hao Yu, Jiabo Zhan, Zile Wang, Jinglin Wang, Huaisong Zhang, Hongyu Li, Xinrui Chen, Yongxian Wei, Chun Yuan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmniAlphaç»Ÿä¸€æ¡†æž¶ä»¥è§£å†³RGBAå›¾åƒç”Ÿæˆä¸Žç¼–è¾‘çš„å¤šä»»åŠ¡éœ€æ±‚**

**å…³é”®è¯**: `RGBAå›¾åƒç”Ÿæˆ` `å¤šä»»åŠ¡å­¦ä¹ ` `æ‰©æ•£å˜æ¢å™¨` `åºåˆ—åˆ°åºåˆ—æ¡†æž¶` `AlphaLayersæ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰RGBAç”Ÿæˆæ¨¡åž‹ç¢Žç‰‡åŒ–ï¼Œç¼ºä¹ç»Ÿä¸€å¤šä»»åŠ¡èƒ½åŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨MSRoPE-BiLå¢žå¼ºDiTï¼Œæ”¯æŒå¤šRGBAå±‚å¹¶å‘å¤„ç†ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨AIM-500ä¸ŠSADé™ä½Ž84.8%ï¼Œäººç±»åå¥½èƒœçŽ‡è¶…90%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generative models have excelled in RGB synthesis, but real-world applications require RGBA manipulation. This has led to a fragmented landscape: specialized, single-task models handle alpha but lack versatility, while unified multi-task frameworks are confined to the RGB domain. To bridge this critical gap, we propose OmniAlpha, the first unified, multi-task generative framework for sequence-to-sequence RGBA image generation and editing. Its architecture features MSRoPE-BiL, a novel RoPE method with a bi-directionally extendable layer axis for its Diffusion Transformer (DiT) backbone, enabling the concurrent processing of multiple input and target RGBA layers. To power this framework, we introduce AlphaLayers, a new dataset of 1,000 high-quality, multi-layer triplets, built via a novel automated synthesis and filter pipeline. Jointly training OmniAlpha on this dataset across a comprehensive suite of 21 diverse tasks, extensive experiments demonstrate that our unified approach consistently outperforms strong, specialized baselines. Most notably, OmniAlpha achieves a dramatic 84.8% relative reduction in SAD for mask-free matting on AIM-500 and wins over 90% of human preferences in layer-conditioned completion. Our work proves that a unified, multi-task model can learn a superior shared representation for RGBA, paving the way for more powerful, layer-aware generative systems.

