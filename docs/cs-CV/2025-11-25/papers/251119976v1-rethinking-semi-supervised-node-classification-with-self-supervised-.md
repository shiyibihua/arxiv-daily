---
layout: default
title: Rethinking Semi-Supervised Node Classification with Self-Supervised Graph Clustering
---

# Rethinking Semi-Supervised Node Classification with Self-Supervised Graph Clustering

**arXiv**: [2511.19976v1](https://arxiv.org/abs/2511.19976) | [PDF](https://arxiv.org/pdf/2511.19976.pdf)

**ä½œè€…**: Songbo Wang, Renchi Yang, Yurui Lai, Xiaoyang Lin, Tsz Nam Chan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNCGCæ¡†æž¶ï¼Œç»“åˆè‡ªç›‘ç£å›¾èšç±»ä¸ŽåŠç›‘ç£åˆ†ç±»ä»¥æå‡èŠ‚ç‚¹åˆ†ç±»æ€§èƒ½**

**å…³é”®è¯**: `å›¾ç¥žç»ç½‘ç»œ` `åŠç›‘ç£èŠ‚ç‚¹åˆ†ç±»` `è‡ªç›‘ç£å›¾èšç±»` `è½¯æ­£äº¤GNN` `å¤šä»»åŠ¡å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçœŸå®žå›¾ä¸­èŠ‚ç‚¹å¸¸å½¢æˆç´§å¯†ç¤¾åŒºï¼Œä½†çŽ°æœ‰æ–¹æ³•æœªåˆ©ç”¨è¿™äº›ä¿¡å·ç¼“è§£æ ‡ç­¾ç¨€ç¼ºé—®é¢˜
2. æ–¹æ³•è¦ç‚¹ï¼šå¼€å‘è½¯æ­£äº¤GNNï¼Œç»Ÿä¸€ä¼˜åŒ–ç›®æ ‡ï¼Œå¹¶é›†æˆè‡ªç›‘ç£èšç±»æ¨¡å—ç”Ÿæˆå¹³è¡¡è½¯ä¼ªæ ‡ç­¾
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä¸ƒä¸ªçœŸå®žå›¾ä¸Šï¼ŒNCGCæ˜¾è‘—ä¼˜äºŽæµè¡ŒGNNæ¨¡åž‹å’ŒåŸºçº¿æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The emergence of graph neural networks (GNNs) has offered a powerful tool for semi-supervised node classification tasks. Subsequent studies have achieved further improvements through refining the message passing schemes in GNN models or exploiting various data augmentation techniques to mitigate limited supervision. In real graphs, nodes often tend to form tightly-knit communities/clusters, which embody abundant signals for compensating label scarcity in semi-supervised node classification but are not explored in prior methods.
>   Inspired by this, this paper presents NCGC that integrates self-supervised graph clustering and semi-supervised classification into a unified framework. Firstly, we theoretically unify the optimization objectives of GNNs and spectral graph clustering, and based on that, develop soft orthogonal GNNs (SOGNs) that leverage a refined message passing paradigm to generate node representations for both classification and clustering. On top of that, NCGC includes a self-supervised graph clustering module that enables the training of SOGNs for learning representations of unlabeled nodes in a self-supervised manner. Particularly, this component comprises two non-trivial clustering objectives and a Sinkhorn-Knopp normalization that transforms predicted cluster assignments into balanced soft pseudo-labels. Through combining the foregoing clustering module with the classification model using a multi-task objective containing the supervised classification loss on labeled data and self-supervised clustering loss on unlabeled data, NCGC promotes synergy between them and achieves enhanced model capacity. Our extensive experiments showcase that the proposed NCGC framework consistently and considerably outperforms popular GNN models and recent baselines for semi-supervised node classification on seven real graphs, when working with various classic GNN backbones.

