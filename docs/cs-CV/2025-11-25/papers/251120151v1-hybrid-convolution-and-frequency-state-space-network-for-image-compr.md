---
layout: default
title: Hybrid Convolution and Frequency State Space Network for Image Compression
---

# Hybrid Convolution and Frequency State Space Network for Image Compression

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.20151" target="_blank" class="toolbar-btn">arXiv: 2511.20151v1</a>
    <a href="https://arxiv.org/pdf/2511.20151.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.20151v1" 
            onclick="toggleFavorite(this, '2511.20151v1', 'Hybrid Convolution and Frequency State Space Network for Image Compression')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Haodong Pan, Hao Wei, Yusong Wang, Nanning Zheng, Caigui Jiang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-25

**Â§áÊ≥®**: 36 pages, 8 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫HCFSSNetÔºå‰∏ÄÁßçÊ∑∑ÂêàÂç∑ÁßØÂíåÈ¢ëÁéáÁä∂ÊÄÅÁ©∫Èó¥ÁΩëÁªúÁöÑÂõæÂÉèÂéãÁº©ÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÂõæÂÉèÂéãÁº©` `Âç∑ÁßØÁ•ûÁªèÁΩëÁªú` `Áä∂ÊÄÅÁ©∫Èó¥Ê®°Âûã` `È¢ëÁéáË∞ÉÂà∂` `Ëá™ÈÄÇÂ∫îÊØîÁâπÂàÜÈÖç`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éTransformerÂíåSSMÁöÑÂõæÂÉèÂéãÁº©ÊñπÊ≥ïÔºåËôΩÁÑ∂ÂÖ∑ÊúâÈïøÁ®ãÂª∫Ê®°ËÉΩÂäõÔºå‰ΩÜÂèØËÉΩ‰∏¢Â§±ÁªìÊûÑ‰ø°ÊÅØÊàñÂøΩÁï•È¢ëÁéáÁâπÂæÅ„ÄÇ
2. HCFSSNetÁªìÂêàCNNÊèêÂèñÈ´òÈ¢ë‰ø°ÊÅØÔºåÂπ∂ÊèêÂá∫VFSSÂùóÂª∫Ê®°‰ΩéÈ¢ë‰ø°ÊÅØÔºåÂà©Áî®AFMMËøõË°åÈ¢ëÁéáË∞ÉÂà∂ÔºåÂÆûÁé∞È´òÊïàÊØîÁâπÂàÜÈÖç„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåHCFSSNetÂú®KodakÁ≠âÊï∞ÊçÆÈõÜ‰∏äÔºåÁõ∏ÊØîVTMÈîöÁÇπÊòæËëóÈôç‰ΩéBDÁéáÔºå‰∏îÂèÇÊï∞ÈáèÊõ¥Â∞ëÔºåÊÄßËÉΩ‰ºò‰∫éÁé∞ÊúâSSMÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊ∑∑ÂêàÂç∑ÁßØÂíåÈ¢ëÁéáÁä∂ÊÄÅÁ©∫Èó¥ÁΩëÁªúÔºàHCFSSNetÔºâÁî®‰∫éÂ≠¶‰π†ÂõæÂÉèÂéãÁº©„ÄÇÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÔºàCNNÔºâËÉΩÂ§üÊúâÊïàÊçïËé∑Â±ÄÈÉ®È´òÈ¢ëÁªÜËäÇÔºåËÄåTransformerÂíåÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÔºàSSMÔºâÊèê‰æõÂº∫Â§ßÁöÑÈïøÁ®ãÂª∫Ê®°ËÉΩÂäõÔºå‰ΩÜÂèØËÉΩÂØºËá¥ÁªìÊûÑ‰ø°ÊÅØ‰∏¢Â§±ÊàñÂøΩÁï•ÂØπÂéãÁº©Ëá≥ÂÖ≥ÈáçË¶ÅÁöÑÈ¢ëÁéáÁâπÂæÅ„ÄÇHCFSSNetÂà©Áî®CNNÊèêÂèñÂ±ÄÈÉ®È´òÈ¢ëÁªìÊûÑÔºåÂπ∂ÂºïÂÖ•ËßÜËßâÈ¢ëÁéáÁä∂ÊÄÅÁ©∫Èó¥ÔºàVFSSÔºâÂùóÊù•Âª∫Ê®°ÈïøÁ®ã‰ΩéÈ¢ë‰ø°ÊÅØ„ÄÇVFSSÂùóÁªìÂêà‰∫ÜÂÖ®ÂêëÈÇªÂüüÁä∂ÊÄÅÁ©∫Èó¥ÔºàVONSSÔºâÊ®°ÂùóÔºàÊ∞¥Âπ≥„ÄÅÂûÇÁõ¥ÂíåÂØπËßíÊâ´ÊèèÁâπÂæÅÔºâ‰ª•ÂèäËá™ÈÄÇÂ∫îÈ¢ëÁéáË∞ÉÂà∂Ê®°ÂùóÔºàAFMMÔºâÔºàÂØπÁ¶ªÊï£‰ΩôÂº¶ÂèòÊç¢È¢ëÁéáÂàÜÈáèËøõË°åÂÜÖÂÆπËá™ÈÄÇÂ∫îÂä†ÊùÉÔºå‰ª•ÂÆûÁé∞Êõ¥ÊúâÊïàÁöÑÊØîÁâπÂàÜÈÖçÔºâ„ÄÇ‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•ÂáèÂ∞ëÁÜµÊ®°Âûã‰∏≠ÁöÑÂÜó‰ΩôÔºåÊàë‰ª¨Â∞ÜAFMM‰∏éSwin TransformerÈõÜÊàêÔºåÂΩ¢ÊàêÈ¢ëÁéáÊÑüÁü•ÁöÑSwin TransformerÊ≥®ÊÑèÂäõÊ®°ÂùóÔºàFSTAMÔºâÔºåÁî®‰∫éÈ¢ëÁéáÊÑüÁü•ÁöÑËæπ‰ø°ÊÅØÂª∫Ê®°„ÄÇÂú®Kodak„ÄÅTecnickÂíåCLIC Professional ValidationÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºå‰∏éÊúÄËøëÂü∫‰∫éSSMÁöÑÁºñËß£Á†ÅÂô®ÔºàÂ¶ÇMambaICÔºâÁõ∏ÊØîÔºåHCFSSNetÂÆûÁé∞‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÁéáÂ§±ÁúüÊÄßËÉΩÔºåÂêåÊó∂‰ΩøÁî®ÁöÑÂèÇÊï∞ÊòéÊòæÊõ¥Â∞ë„ÄÇÂú®Kodak„ÄÅTecnickÂíåCLIC‰∏äÔºåHCFSSNetÁõ∏ÂØπ‰∫éVTMÈîöÁÇπÂàÜÂà´Èôç‰Ωé‰∫Ü18.06%„ÄÅ24.56%Âíå22.44%ÁöÑBDÁéáÔºå‰∏∫Êú™Êù•ÁöÑÂ≠¶‰π†ÂõæÂÉèÂéãÁº©Á≥ªÁªüÊèê‰æõ‰∫Ü‰∏ÄÁßçÈ´òÊïà‰∏îÂèØËß£ÈáäÁöÑÊ∑∑ÂêàÊû∂ÊûÑ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑÂü∫‰∫éTransformerÂíåSSMÁöÑÂõæÂÉèÂéãÁº©ÊñπÊ≥ïÂú®Âª∫Ê®°ÈïøÁ®ã‰æùËµñÂÖ≥Á≥ªÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂÆÉ‰ª¨Âú®ÊçïËé∑Â±ÄÈÉ®È´òÈ¢ëÁªÜËäÇÂíå‰øùÊåÅÂõæÂÉèÁöÑÁªìÊûÑ‰ø°ÊÅØÊñπÈù¢Â≠òÂú®‰∏çË∂≥„ÄÇÊ≠§Â§ñÔºåËøô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ÂøΩÁï•‰∫ÜÂõæÂÉèÂéãÁº©‰∏≠Ëá≥ÂÖ≥ÈáçË¶ÅÁöÑÈ¢ëÁéáÁâπÂæÅÔºåÂØºËá¥ÂéãÁº©ÊïàÁéáÈôç‰Ωé„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöHCFSSNetÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜCNNÁöÑÂ±ÄÈÉ®È´òÈ¢ëÁâπÂæÅÊèêÂèñËÉΩÂäõ‰∏éÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÔºàSSMÔºâÁöÑÈïøÁ®ã‰æùËµñÂª∫Ê®°ËÉΩÂäõÁõ∏ÁªìÂêàÔºåÂπ∂ÂºïÂÖ•È¢ëÁéáË∞ÉÂà∂Êú∫Âà∂Ôºå‰ª•ÂÆûÁé∞Êõ¥È´òÊïàÁöÑÂõæÂÉèÂéãÁº©„ÄÇÈÄöËøáËøôÁßçÊ∑∑ÂêàÊû∂ÊûÑÔºåÊ®°ÂûãÂèØ‰ª•ÂêåÊó∂ÊçïËé∑ÂõæÂÉèÁöÑÂ±ÄÈÉ®ÁªÜËäÇÂíåÂÖ®Â±ÄÁªìÊûÑÔºåÂπ∂Ê†πÊçÆÂÜÖÂÆπËá™ÈÄÇÂ∫îÂú∞ÂàÜÈÖçÊØîÁâπÔºå‰ªéËÄåÊèêÈ´òÂéãÁº©ÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöHCFSSNetÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) CNNÊ®°ÂùóÔºöÁî®‰∫éÊèêÂèñÂõæÂÉèÁöÑÂ±ÄÈÉ®È´òÈ¢ëÁâπÂæÅ„ÄÇ2) ËßÜËßâÈ¢ëÁéáÁä∂ÊÄÅÁ©∫Èó¥ÔºàVFSSÔºâÂùóÔºöÁî®‰∫éÂª∫Ê®°ÈïøÁ®ã‰ΩéÈ¢ë‰ø°ÊÅØÔºåVFSSÂùóÁî±ÂÖ®ÂêëÈÇªÂüüÁä∂ÊÄÅÁ©∫Èó¥ÔºàVONSSÔºâÊ®°ÂùóÂíåËá™ÈÄÇÂ∫îÈ¢ëÁéáË∞ÉÂà∂Ê®°ÂùóÔºàAFMMÔºâÁªÑÊàê„ÄÇ3) È¢ëÁéáÊÑüÁü•ÁöÑSwin TransformerÊ≥®ÊÑèÂäõÊ®°ÂùóÔºàFSTAMÔºâÔºöÁî®‰∫éÈ¢ëÁéáÊÑüÁü•ÁöÑËæπ‰ø°ÊÅØÂª∫Ê®°ÔºåËøõ‰∏ÄÊ≠•ÂáèÂ∞ëÁÜµÊ®°Âûã‰∏≠ÁöÑÂÜó‰Ωô„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöHCFSSNetÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éVFSSÂùóÁöÑËÆæËÆ°ÔºåÂÆÉÂ∞ÜVONSSÊ®°ÂùóÂíåAFMMÊ®°ÂùóÁõ∏ÁªìÂêàÔºåÂÆûÁé∞‰∫ÜÂØπÂõæÂÉèÈ¢ëÁéáÁâπÂæÅÁöÑËá™ÈÄÇÂ∫îÂª∫Ê®°„ÄÇVONSSÊ®°ÂùóÈÄöËøáÊ∞¥Âπ≥„ÄÅÂûÇÁõ¥ÂíåÂØπËßíÊâ´ÊèèÁâπÂæÅÔºåÊçïÊçâÂõæÂÉèÁöÑÂÖ®Â±ÄÁªìÊûÑ‰ø°ÊÅØ„ÄÇAFMMÊ®°ÂùóÂàôÈÄöËøáÂØπÁ¶ªÊï£‰ΩôÂº¶ÂèòÊç¢ÔºàDCTÔºâÈ¢ëÁéáÂàÜÈáèËøõË°åÂÜÖÂÆπËá™ÈÄÇÂ∫îÂä†ÊùÉÔºåÂÆûÁé∞‰∫ÜÊõ¥ÊúâÊïàÁöÑÊØîÁâπÂàÜÈÖç„ÄÇÊ≠§Â§ñÔºåFSTAMÊ®°ÂùóÈÄöËøáÂ∞ÜAFMM‰∏éSwin TransformerÈõÜÊàêÔºåËøõ‰∏ÄÊ≠•ÊèêÈ´ò‰∫ÜËæπ‰ø°ÊÅØÂª∫Ê®°ÁöÑÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAFMMÊ®°ÂùóÁöÑÂÖ≥ÈîÆËÆæËÆ°Âú®‰∫éÂÜÖÂÆπËá™ÈÄÇÂ∫îÁöÑÈ¢ëÁéáÊùÉÈáçËÆ°ÁÆó„ÄÇËØ•Ê®°ÂùóÈ¶ñÂÖàÂØπËæìÂÖ•ÁâπÂæÅËøõË°åDCTÂèòÊç¢ÔºåÁÑ∂ÂêéÊ†πÊçÆËæìÂÖ•ÂÜÖÂÆπËÆ°ÁÆóÊØè‰∏™È¢ëÁéáÂàÜÈáèÁöÑÊùÉÈáç„ÄÇËøô‰∫õÊùÉÈáçÁî®‰∫éË∞ÉÊï¥DCTÁ≥ªÊï∞Ôºå‰ªéËÄåÂÆûÁé∞ÂØπÈ¢ëÁéáÂàÜÈáèÁöÑËá™ÈÄÇÂ∫îË∞ÉÂà∂„ÄÇVONSSÊ®°ÂùóÈááÁî®‰∫Ü‰∏ÄÁßçÂÖ®ÂêëÊâ´ÊèèÁ≠ñÁï•ÔºåÈÄöËøáÊ∞¥Âπ≥„ÄÅÂûÇÁõ¥ÂíåÂØπËßí‰∏â‰∏™ÊñπÂêëÊâ´ÊèèÁâπÂæÅÔºåÊçïÊçâÂõæÂÉèÁöÑÂÖ®Â±ÄÁªìÊûÑ‰ø°ÊÅØ„ÄÇÊçüÂ§±ÂáΩÊï∞ÊñπÈù¢ÔºåÈááÁî®‰∫ÜÁéáÂ§±Áúü‰ºòÂåñÁõÆÊ†áÔºåÂπ≥Ë°°ÂéãÁº©ÁéáÂíåÂõæÂÉèË¥®Èáè„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåHCFSSNetÂú®Kodak„ÄÅTecnickÂíåCLIC Professional ValidationÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰∏éVTMÈîöÁÇπÁõ∏ÊØîÔºåHCFSSNetÂàÜÂà´Èôç‰Ωé‰∫Ü18.06%„ÄÅ24.56%Âíå22.44%ÁöÑBDÁéá„ÄÇÊ≠§Â§ñÔºå‰∏éÊúÄËøëÂü∫‰∫éSSMÁöÑÁºñËß£Á†ÅÂô®ÔºàÂ¶ÇMambaICÔºâÁõ∏ÊØîÔºåHCFSSNetÂÆûÁé∞‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÁéáÂ§±ÁúüÊÄßËÉΩÔºåÂêåÊó∂‰ΩøÁî®ÁöÑÂèÇÊï∞ÊòéÊòæÊõ¥Â∞ëÔºåË°®ÊòéËØ•ÊñπÊ≥ïÂú®ÊïàÁéáÂíåÊÄßËÉΩÊñπÈù¢ÈÉΩÂÖ∑Êúâ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

HCFSSNetÂú®ÂõæÂÉèÂéãÁº©È¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÂ∫îÁî®‰∫éÂõæÂÉèÂ≠òÂÇ®„ÄÅÂõæÂÉè‰º†Ëæì„ÄÅËßÜÈ¢ë‰ºöËÆÆ„ÄÅÊµÅÂ™í‰ΩìÊúçÂä°Á≠âÂú∫ÊôØ„ÄÇËØ•ÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÈôç‰ΩéÂõæÂÉèÁöÑÂ≠òÂÇ®Á©∫Èó¥Âíå‰º†ËæìÂ∏¶ÂÆΩÔºåÊèêÈ´òÁî®Êà∑‰ΩìÈ™å„ÄÇÊú™Êù•ÔºåËØ•Á†îÁ©∂ÂèØ‰ª•Êâ©Â±ïÂà∞ËßÜÈ¢ëÂéãÁº©È¢ÜÂüüÔºå‰∏∫ËßÜÈ¢ëÂ∫îÁî®Êèê‰æõÊõ¥È´òÊïàÁöÑÂéãÁº©ÊñπÊ°à„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Learned image compression (LIC) has recently benefited from Transformer based and state space model (SSM) based architectures. Convolutional neural networks (CNNs) effectively capture local high frequency details, whereas Transformers and SSMs provide strong long range modeling capabilities but may cause structural information loss or ignore frequency characteristics that are crucial for compression. In this work we propose HCFSSNet, a Hybrid Convolution and Frequency State Space Network for LIC. HCFSSNet uses CNNs to extract local high frequency structures and introduces a Vision Frequency State Space (VFSS) block that models long range low frequency information. The VFSS block combines an Omni directional Neighborhood State Space (VONSS) module, which scans features horizontally, vertically and diagonally, with an Adaptive Frequency Modulation Module (AFMM) that applies content adaptive weighting of discrete cosine transform frequency components for more efficient bit allocation. To further reduce redundancy in the entropy model, we integrate AFMM with a Swin Transformer to form a Frequency Swin Transformer Attention Module (FSTAM) for frequency aware side information modeling. Experiments on the Kodak, Tecnick and CLIC Professional Validation datasets show that HCFSSNet achieves competitive rate distortion performance compared with recent SSM based codecs such as MambaIC, while using significantly fewer parameters. On Kodak, Tecnick and CLIC, HCFSSNet reduces BD rate over the VTM anchor by 18.06, 24.56 and 22.44 percent, respectively, providing an efficient and interpretable hybrid architecture for future learned image compression systems.

