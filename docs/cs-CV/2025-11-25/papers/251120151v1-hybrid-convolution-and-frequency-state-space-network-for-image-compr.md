---
layout: default
title: Hybrid Convolution and Frequency State Space Network for Image Compression
---

# Hybrid Convolution and Frequency State Space Network for Image Compression

**arXiv**: [2511.20151v1](https://arxiv.org/abs/2511.20151) | [PDF](https://arxiv.org/pdf/2511.20151.pdf)

**ä½œè€…**: Haodong Pan, Hao Wei, Yusong Wang, Nanning Zheng, Caigui Jiang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHCFSSNetæ··åˆç½‘ç»œï¼Œç»“åˆå·ç§¯ä¸Žé¢‘çŽ‡çŠ¶æ€ç©ºé—´ä»¥æå‡å­¦ä¹ å›¾åƒåŽ‹ç¼©æ€§èƒ½**

**å…³é”®è¯**: `å­¦ä¹ å›¾åƒåŽ‹ç¼©` `æ··åˆç½‘ç»œæž¶æž„` `é¢‘çŽ‡çŠ¶æ€ç©ºé—´` `è‡ªé€‚åº”é¢‘çŽ‡è°ƒåˆ¶` `ç†µæ¨¡åž‹ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šTransformerå’ŒçŠ¶æ€ç©ºé—´æ¨¡åž‹åœ¨å›¾åƒåŽ‹ç¼©ä¸­å¯èƒ½å¿½ç•¥å±€éƒ¨é«˜é¢‘ç»†èŠ‚å’Œé¢‘çŽ‡ç‰¹æ€§
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨CNNæå–å±€éƒ¨é«˜é¢‘ç»“æž„ï¼ŒVFSSå—å»ºæ¨¡é•¿ç¨‹ä½Žé¢‘ä¿¡æ¯å¹¶é›†æˆAFMMä¼˜åŒ–æ¯”ç‰¹åˆ†é…
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Kodakç­‰æ•°æ®é›†ä¸ŠBDçŽ‡é™ä½Ž18-24%ï¼Œå‚æ•°æ›´å°‘ï¼Œæ€§èƒ½ä¼˜äºŽMambaIC

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Learned image compression (LIC) has recently benefited from Transformer based and state space model (SSM) based architectures. Convolutional neural networks (CNNs) effectively capture local high frequency details, whereas Transformers and SSMs provide strong long range modeling capabilities but may cause structural information loss or ignore frequency characteristics that are crucial for compression. In this work we propose HCFSSNet, a Hybrid Convolution and Frequency State Space Network for LIC. HCFSSNet uses CNNs to extract local high frequency structures and introduces a Vision Frequency State Space (VFSS) block that models long range low frequency information. The VFSS block combines an Omni directional Neighborhood State Space (VONSS) module, which scans features horizontally, vertically and diagonally, with an Adaptive Frequency Modulation Module (AFMM) that applies content adaptive weighting of discrete cosine transform frequency components for more efficient bit allocation. To further reduce redundancy in the entropy model, we integrate AFMM with a Swin Transformer to form a Frequency Swin Transformer Attention Module (FSTAM) for frequency aware side information modeling. Experiments on the Kodak, Tecnick and CLIC Professional Validation datasets show that HCFSSNet achieves competitive rate distortion performance compared with recent SSM based codecs such as MambaIC, while using significantly fewer parameters. On Kodak, Tecnick and CLIC, HCFSSNet reduces BD rate over the VTM anchor by 18.06, 24.56 and 22.44 percent, respectively, providing an efficient and interpretable hybrid architecture for future learned image compression systems.

