---
layout: default
title: Hybrid Convolution and Frequency State Space Network for Image Compression
---

# Hybrid Convolution and Frequency State Space Network for Image Compression

**arXiv**: [2511.20151v1](https://arxiv.org/abs/2511.20151) | [PDF](https://arxiv.org/pdf/2511.20151.pdf)

**ä½œè€…**: Haodong Pan, Hao Wei, Yusong Wang, Nanning Zheng, Caigui Jiang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25

**å¤‡æ³¨**: 36 pages, 8 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHCFSSNetï¼Œä¸€ç§æ··åˆå·ç§¯å’Œé¢‘çŽ‡çŠ¶æ€ç©ºé—´ç½‘ç»œçš„å›¾åƒåŽ‹ç¼©æ–¹æ³•**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `å›¾åƒåŽ‹ç¼©` `å·ç§¯ç¥žç»ç½‘ç»œ` `çŠ¶æ€ç©ºé—´æ¨¡åž‹` `é¢‘çŽ‡è°ƒåˆ¶` `è‡ªé€‚åº”æ¯”ç‰¹åˆ†é…`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŸºäºŽTransformerå’ŒSSMçš„å›¾åƒåŽ‹ç¼©æ–¹æ³•ï¼Œè™½ç„¶å…·æœ‰é•¿ç¨‹å»ºæ¨¡èƒ½åŠ›ï¼Œä½†å¯èƒ½ä¸¢å¤±ç»“æž„ä¿¡æ¯æˆ–å¿½ç•¥é¢‘çŽ‡ç‰¹å¾ã€‚
2. HCFSSNetç»“åˆCNNæå–é«˜é¢‘ä¿¡æ¯ï¼Œå¹¶æå‡ºVFSSå—å»ºæ¨¡ä½Žé¢‘ä¿¡æ¯ï¼Œåˆ©ç”¨AFMMè¿›è¡Œé¢‘çŽ‡è°ƒåˆ¶ï¼Œå®žçŽ°é«˜æ•ˆæ¯”ç‰¹åˆ†é…ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒHCFSSNetåœ¨Kodakç­‰æ•°æ®é›†ä¸Šï¼Œç›¸æ¯”VTMé”šç‚¹æ˜¾è‘—é™ä½ŽBDçŽ‡ï¼Œä¸”å‚æ•°é‡æ›´å°‘ï¼Œæ€§èƒ½ä¼˜äºŽçŽ°æœ‰SSMæ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆå·ç§¯å’Œé¢‘çŽ‡çŠ¶æ€ç©ºé—´ç½‘ç»œï¼ˆHCFSSNetï¼‰ç”¨äºŽå­¦ä¹ å›¾åƒåŽ‹ç¼©ã€‚å·ç§¯ç¥žç»ç½‘ç»œï¼ˆCNNï¼‰èƒ½å¤Ÿæœ‰æ•ˆæ•èŽ·å±€éƒ¨é«˜é¢‘ç»†èŠ‚ï¼Œè€ŒTransformerå’ŒçŠ¶æ€ç©ºé—´æ¨¡åž‹ï¼ˆSSMï¼‰æä¾›å¼ºå¤§çš„é•¿ç¨‹å»ºæ¨¡èƒ½åŠ›ï¼Œä½†å¯èƒ½å¯¼è‡´ç»“æž„ä¿¡æ¯ä¸¢å¤±æˆ–å¿½ç•¥å¯¹åŽ‹ç¼©è‡³å…³é‡è¦çš„é¢‘çŽ‡ç‰¹å¾ã€‚HCFSSNetåˆ©ç”¨CNNæå–å±€éƒ¨é«˜é¢‘ç»“æž„ï¼Œå¹¶å¼•å…¥è§†è§‰é¢‘çŽ‡çŠ¶æ€ç©ºé—´ï¼ˆVFSSï¼‰å—æ¥å»ºæ¨¡é•¿ç¨‹ä½Žé¢‘ä¿¡æ¯ã€‚VFSSå—ç»“åˆäº†å…¨å‘é‚»åŸŸçŠ¶æ€ç©ºé—´ï¼ˆVONSSï¼‰æ¨¡å—ï¼ˆæ°´å¹³ã€åž‚ç›´å’Œå¯¹è§’æ‰«æç‰¹å¾ï¼‰ä»¥åŠè‡ªé€‚åº”é¢‘çŽ‡è°ƒåˆ¶æ¨¡å—ï¼ˆAFMMï¼‰ï¼ˆå¯¹ç¦»æ•£ä½™å¼¦å˜æ¢é¢‘çŽ‡åˆ†é‡è¿›è¡Œå†…å®¹è‡ªé€‚åº”åŠ æƒï¼Œä»¥å®žçŽ°æ›´æœ‰æ•ˆçš„æ¯”ç‰¹åˆ†é…ï¼‰ã€‚ä¸ºäº†è¿›ä¸€æ­¥å‡å°‘ç†µæ¨¡åž‹ä¸­çš„å†—ä½™ï¼Œæˆ‘ä»¬å°†AFMMä¸ŽSwin Transformeré›†æˆï¼Œå½¢æˆé¢‘çŽ‡æ„ŸçŸ¥çš„Swin Transformeræ³¨æ„åŠ›æ¨¡å—ï¼ˆFSTAMï¼‰ï¼Œç”¨äºŽé¢‘çŽ‡æ„ŸçŸ¥çš„è¾¹ä¿¡æ¯å»ºæ¨¡ã€‚åœ¨Kodakã€Tecnickå’ŒCLIC Professional Validationæ•°æ®é›†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œä¸Žæœ€è¿‘åŸºäºŽSSMçš„ç¼–è§£ç å™¨ï¼ˆå¦‚MambaICï¼‰ç›¸æ¯”ï¼ŒHCFSSNetå®žçŽ°äº†å…·æœ‰ç«žäº‰åŠ›çš„çŽ‡å¤±çœŸæ€§èƒ½ï¼ŒåŒæ—¶ä½¿ç”¨çš„å‚æ•°æ˜Žæ˜¾æ›´å°‘ã€‚åœ¨Kodakã€Tecnickå’ŒCLICä¸Šï¼ŒHCFSSNetç›¸å¯¹äºŽVTMé”šç‚¹åˆ†åˆ«é™ä½Žäº†18.06%ã€24.56%å’Œ22.44%çš„BDçŽ‡ï¼Œä¸ºæœªæ¥çš„å­¦ä¹ å›¾åƒåŽ‹ç¼©ç³»ç»Ÿæä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯è§£é‡Šçš„æ··åˆæž¶æž„ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„åŸºäºŽTransformerå’ŒSSMçš„å›¾åƒåŽ‹ç¼©æ–¹æ³•åœ¨å»ºæ¨¡é•¿ç¨‹ä¾èµ–å…³ç³»æ–¹é¢è¡¨çŽ°å‡ºè‰²ï¼Œä½†å®ƒä»¬åœ¨æ•èŽ·å±€éƒ¨é«˜é¢‘ç»†èŠ‚å’Œä¿æŒå›¾åƒçš„ç»“æž„ä¿¡æ¯æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å¿½ç•¥äº†å›¾åƒåŽ‹ç¼©ä¸­è‡³å…³é‡è¦çš„é¢‘çŽ‡ç‰¹å¾ï¼Œå¯¼è‡´åŽ‹ç¼©æ•ˆçŽ‡é™ä½Žã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHCFSSNetçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†CNNçš„å±€éƒ¨é«˜é¢‘ç‰¹å¾æå–èƒ½åŠ›ä¸ŽçŠ¶æ€ç©ºé—´æ¨¡åž‹ï¼ˆSSMï¼‰çš„é•¿ç¨‹ä¾èµ–å»ºæ¨¡èƒ½åŠ›ç›¸ç»“åˆï¼Œå¹¶å¼•å…¥é¢‘çŽ‡è°ƒåˆ¶æœºåˆ¶ï¼Œä»¥å®žçŽ°æ›´é«˜æ•ˆçš„å›¾åƒåŽ‹ç¼©ã€‚é€šè¿‡è¿™ç§æ··åˆæž¶æž„ï¼Œæ¨¡åž‹å¯ä»¥åŒæ—¶æ•èŽ·å›¾åƒçš„å±€éƒ¨ç»†èŠ‚å’Œå…¨å±€ç»“æž„ï¼Œå¹¶æ ¹æ®å†…å®¹è‡ªé€‚åº”åœ°åˆ†é…æ¯”ç‰¹ï¼Œä»Žè€Œæé«˜åŽ‹ç¼©æ•ˆçŽ‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šHCFSSNetçš„æ•´ä½“æž¶æž„åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) CNNæ¨¡å—ï¼šç”¨äºŽæå–å›¾åƒçš„å±€éƒ¨é«˜é¢‘ç‰¹å¾ã€‚2) è§†è§‰é¢‘çŽ‡çŠ¶æ€ç©ºé—´ï¼ˆVFSSï¼‰å—ï¼šç”¨äºŽå»ºæ¨¡é•¿ç¨‹ä½Žé¢‘ä¿¡æ¯ï¼ŒVFSSå—ç”±å…¨å‘é‚»åŸŸçŠ¶æ€ç©ºé—´ï¼ˆVONSSï¼‰æ¨¡å—å’Œè‡ªé€‚åº”é¢‘çŽ‡è°ƒåˆ¶æ¨¡å—ï¼ˆAFMMï¼‰ç»„æˆã€‚3) é¢‘çŽ‡æ„ŸçŸ¥çš„Swin Transformeræ³¨æ„åŠ›æ¨¡å—ï¼ˆFSTAMï¼‰ï¼šç”¨äºŽé¢‘çŽ‡æ„ŸçŸ¥çš„è¾¹ä¿¡æ¯å»ºæ¨¡ï¼Œè¿›ä¸€æ­¥å‡å°‘ç†µæ¨¡åž‹ä¸­çš„å†—ä½™ã€‚

**å…³é”®åˆ›æ–°**ï¼šHCFSSNetçš„å…³é”®åˆ›æ–°åœ¨äºŽVFSSå—çš„è®¾è®¡ï¼Œå®ƒå°†VONSSæ¨¡å—å’ŒAFMMæ¨¡å—ç›¸ç»“åˆï¼Œå®žçŽ°äº†å¯¹å›¾åƒé¢‘çŽ‡ç‰¹å¾çš„è‡ªé€‚åº”å»ºæ¨¡ã€‚VONSSæ¨¡å—é€šè¿‡æ°´å¹³ã€åž‚ç›´å’Œå¯¹è§’æ‰«æç‰¹å¾ï¼Œæ•æ‰å›¾åƒçš„å…¨å±€ç»“æž„ä¿¡æ¯ã€‚AFMMæ¨¡å—åˆ™é€šè¿‡å¯¹ç¦»æ•£ä½™å¼¦å˜æ¢ï¼ˆDCTï¼‰é¢‘çŽ‡åˆ†é‡è¿›è¡Œå†…å®¹è‡ªé€‚åº”åŠ æƒï¼Œå®žçŽ°äº†æ›´æœ‰æ•ˆçš„æ¯”ç‰¹åˆ†é…ã€‚æ­¤å¤–ï¼ŒFSTAMæ¨¡å—é€šè¿‡å°†AFMMä¸ŽSwin Transformeré›†æˆï¼Œè¿›ä¸€æ­¥æé«˜äº†è¾¹ä¿¡æ¯å»ºæ¨¡çš„æ•ˆçŽ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šAFMMæ¨¡å—çš„å…³é”®è®¾è®¡åœ¨äºŽå†…å®¹è‡ªé€‚åº”çš„é¢‘çŽ‡æƒé‡è®¡ç®—ã€‚è¯¥æ¨¡å—é¦–å…ˆå¯¹è¾“å…¥ç‰¹å¾è¿›è¡ŒDCTå˜æ¢ï¼Œç„¶åŽæ ¹æ®è¾“å…¥å†…å®¹è®¡ç®—æ¯ä¸ªé¢‘çŽ‡åˆ†é‡çš„æƒé‡ã€‚è¿™äº›æƒé‡ç”¨äºŽè°ƒæ•´DCTç³»æ•°ï¼Œä»Žè€Œå®žçŽ°å¯¹é¢‘çŽ‡åˆ†é‡çš„è‡ªé€‚åº”è°ƒåˆ¶ã€‚VONSSæ¨¡å—é‡‡ç”¨äº†ä¸€ç§å…¨å‘æ‰«æç­–ç•¥ï¼Œé€šè¿‡æ°´å¹³ã€åž‚ç›´å’Œå¯¹è§’ä¸‰ä¸ªæ–¹å‘æ‰«æç‰¹å¾ï¼Œæ•æ‰å›¾åƒçš„å…¨å±€ç»“æž„ä¿¡æ¯ã€‚æŸå¤±å‡½æ•°æ–¹é¢ï¼Œé‡‡ç”¨äº†çŽ‡å¤±çœŸä¼˜åŒ–ç›®æ ‡ï¼Œå¹³è¡¡åŽ‹ç¼©çŽ‡å’Œå›¾åƒè´¨é‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒHCFSSNetåœ¨Kodakã€Tecnickå’ŒCLIC Professional Validationæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸ŽVTMé”šç‚¹ç›¸æ¯”ï¼ŒHCFSSNetåˆ†åˆ«é™ä½Žäº†18.06%ã€24.56%å’Œ22.44%çš„BDçŽ‡ã€‚æ­¤å¤–ï¼Œä¸Žæœ€è¿‘åŸºäºŽSSMçš„ç¼–è§£ç å™¨ï¼ˆå¦‚MambaICï¼‰ç›¸æ¯”ï¼ŒHCFSSNetå®žçŽ°äº†å…·æœ‰ç«žäº‰åŠ›çš„çŽ‡å¤±çœŸæ€§èƒ½ï¼ŒåŒæ—¶ä½¿ç”¨çš„å‚æ•°æ˜Žæ˜¾æ›´å°‘ï¼Œè¡¨æ˜Žè¯¥æ–¹æ³•åœ¨æ•ˆçŽ‡å’Œæ€§èƒ½æ–¹é¢éƒ½å…·æœ‰ä¼˜åŠ¿ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

HCFSSNetåœ¨å›¾åƒåŽ‹ç¼©é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºŽå›¾åƒå­˜å‚¨ã€å›¾åƒä¼ è¾“ã€è§†é¢‘ä¼šè®®ã€æµåª’ä½“æœåŠ¡ç­‰åœºæ™¯ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆé™ä½Žå›¾åƒçš„å­˜å‚¨ç©ºé—´å’Œä¼ è¾“å¸¦å®½ï¼Œæé«˜ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥æ‰©å±•åˆ°è§†é¢‘åŽ‹ç¼©é¢†åŸŸï¼Œä¸ºè§†é¢‘åº”ç”¨æä¾›æ›´é«˜æ•ˆçš„åŽ‹ç¼©æ–¹æ¡ˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Learned image compression (LIC) has recently benefited from Transformer based and state space model (SSM) based architectures. Convolutional neural networks (CNNs) effectively capture local high frequency details, whereas Transformers and SSMs provide strong long range modeling capabilities but may cause structural information loss or ignore frequency characteristics that are crucial for compression. In this work we propose HCFSSNet, a Hybrid Convolution and Frequency State Space Network for LIC. HCFSSNet uses CNNs to extract local high frequency structures and introduces a Vision Frequency State Space (VFSS) block that models long range low frequency information. The VFSS block combines an Omni directional Neighborhood State Space (VONSS) module, which scans features horizontally, vertically and diagonally, with an Adaptive Frequency Modulation Module (AFMM) that applies content adaptive weighting of discrete cosine transform frequency components for more efficient bit allocation. To further reduce redundancy in the entropy model, we integrate AFMM with a Swin Transformer to form a Frequency Swin Transformer Attention Module (FSTAM) for frequency aware side information modeling. Experiments on the Kodak, Tecnick and CLIC Professional Validation datasets show that HCFSSNet achieves competitive rate distortion performance compared with recent SSM based codecs such as MambaIC, while using significantly fewer parameters. On Kodak, Tecnick and CLIC, HCFSSNet reduces BD rate over the VTM anchor by 18.06, 24.56 and 22.44 percent, respectively, providing an efficient and interpretable hybrid architecture for future learned image compression systems.

