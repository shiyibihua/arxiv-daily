---
layout: default
title: Beluga: A CXL-Based Memory Architecture for Scalable and Efficient LLM KVCache Management
---

# Beluga: A CXL-Based Memory Architecture for Scalable and Efficient LLM KVCache Management

**arXiv**: [2511.20172v1](https://arxiv.org/abs/2511.20172) | [PDF](https://arxiv.org/pdf/2511.20172.pdf)

**ä½œè€…**: Xinjun Yang, Qingda Hu, Junru Li, Feifei Li, Yuqi Zhou, Yicong Zhu, Qiuru Lin, Jian Dai, Yang Kong, Jiayu Zhang, Guoqiang Xu, Qiang Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBeluga CXLå†…å­˜æž¶æž„ä»¥è§£å†³LLMæŽ¨ç†ä¸­KVCacheå†…å­˜ç“¶é¢ˆé—®é¢˜**

**å…³é”®è¯**: `CXLå†…å­˜æž¶æž„` `KVCacheç®¡ç†` `LLMæŽ¨ç†ä¼˜åŒ–` `GPUå†…å­˜æ‰©å±•` `ä½Žå»¶è¿Ÿè®¿é—®`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. LLMæ¨¡åž‹è§„æ¨¡æ‰©å¤§å’Œé•¿ä¸Šä¸‹æ–‡æŽ¨ç†éœ€æ±‚ä½¿GPUå†…å­˜æˆä¸ºç“¶é¢ˆï¼ŒHBMå®¹é‡æœ‰é™éœ€ä¾èµ–CPU DRAM
2. åŸºäºŽCXLæŠ€æœ¯æž„å»ºå…±äº«å†…å­˜æ± ï¼Œæ”¯æŒGPUå’ŒCPUç›´æŽ¥è®¿é—®ï¼Œé™ä½Žå»¶è¿Ÿå’ŒåŒæ­¥å¼€é”€
3. å®žéªŒæ˜¾ç¤ºåœ¨vLLMå¼•æ“Žä¸­TTFTé™ä½Ž89.6%ï¼Œåžåé‡æå‡7.35å€ï¼Œä¼˜äºŽRDMAæ–¹æ¡ˆ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The rapid increase in LLM model sizes and the growing demand for long-context inference have made memory a critical bottleneck in GPU-accelerated serving systems. Although high-bandwidth memory (HBM) on GPUs offers fast access, its limited capacity necessitates reliance on host memory (CPU DRAM) to support larger working sets such as the KVCache. However, the maximum DRAM capacity is constrained by the limited number of memory channels per CPU socket. To overcome this limitation, current systems often adopt RDMA-based disaggregated memory pools, which introduce significant challenges including high access latency, complex communication protocols, and synchronization overhead. Fortunately, the emerging CXL technology introduces new opportunities in KVCache design. In this paper, we propose Beluga, a novel memory architecture that enables GPUs and CPUs to access a shared, large-scale memory pool through CXL switches. By supporting native load/store access semantics over the CXL fabric, our design delivers near-local memory latency, while reducing programming complexity and minimizing synchronization overhead. We conduct a systematic characterization of a commercial CXL switch-based memory pool and propose a set of design guidelines. Based on Beluga, we design and implement Beluga-KVCache, a system tailored for managing the large-scale KVCache in LLM inference. Beluga-KVCache achieves an 89.6% reduction in Time-To-First-Token (TTFT) and 7.35x throughput improvement in the vLLM inference engine compared to RDMA-based solutions. To the best of our knowledge, Beluga is the first system that enables GPUs to directly access large-scale memory pools through CXL switches, marking a significant step toward low-latency, shared access to vast memory resources by GPUs.

