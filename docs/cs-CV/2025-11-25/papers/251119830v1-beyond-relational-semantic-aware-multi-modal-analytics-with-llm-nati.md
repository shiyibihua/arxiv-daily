---
layout: default
title: Beyond Relational: Semantic-Aware Multi-Modal Analytics with LLM-Native Query Optimization
---

# Beyond Relational: Semantic-Aware Multi-Modal Analytics with LLM-Native Query Optimization

**arXiv**: [2511.19830v1](https://arxiv.org/abs/2511.19830) | [PDF](https://arxiv.org/pdf/2511.19830.pdf)

**ä½œè€…**: Junhao Zhu, Lu Chen, Xiangyu Ke, Ziquan Fang, Tianyi Li, Yunjun Gao, Christian S. Jensen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNirvanaæ¡†æž¶ä»¥ä¼˜åŒ–å¤šæ¨¡æ€æ•°æ®åˆ†æžä¸­çš„è¯­ä¹‰æŸ¥è¯¢å¤„ç†**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ•°æ®åˆ†æž` `è¯­ä¹‰æŸ¥è¯¢ä¼˜åŒ–` `LLMé©±åŠ¨ç³»ç»Ÿ` `æŸ¥è¯¢è®¡åˆ’æœç´¢` `æˆæœ¬ä¼˜åŒ–` `è®¡ç®—é‡ç”¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿå…³ç³»æŸ¥è¯¢éš¾ä»¥æ•æ‰è¯­ä¹‰ï¼Œé™åˆ¶å¤šæ¨¡æ€åˆ†æžåº”ç”¨
2. ç»“åˆé€»è¾‘ä¼˜åŒ–å™¨ä¸Žç‰©ç†ä¼˜åŒ–å™¨ï¼Œæå‡LLMæŸ¥è¯¢æ•ˆçŽ‡
3. å®žéªŒæ˜¾ç¤ºè¿è¡Œæ—¶é—´å‡å°‘10%-85%ï¼Œæˆæœ¬å¹³å‡é™ä½Ž76%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-modal analytical processing has the potential to transform applications in e-commerce, healthcare, entertainment, and beyond. However, real-world adoption remains elusive due to the limited ability of traditional relational query operators to capture query semantics. The emergence of foundation models, particularly the large language models (LLMs), opens up new opportunities to develop flexible, semantic-aware data analytics systems that transcend the relational paradigm.
>   We present Nirvana, a multi-modal data analytics framework that incorporates programmable semantic operators while leveraging both logical and physical query optimization strategies, tailored for LLM-driven semantic query processing. Nirvana addresses two key challenges. First, it features an agentic logical optimizer that uses natural language-specified transformation rules and random-walk-based search to explore vast spaces of semantically equivalent query plans -- far beyond the capabilities of conventional optimizers. Second, it introduces a cost-aware physical optimizer that selects the most effective LLM backend for each operator using a novel improvement-score metric. To further enhance efficiency, Nirvana incorporates computation reuse and evaluation pushdown techniques guided by model capability hypotheses. Experimental evaluations on three real-world benchmarks demonstrate that Nirvana is able to reduce end-to-end runtime by 10%--85% and reduces system processing costs by 76% on average, outperforming state-of-the-art systems at both efficiency and scalability.

