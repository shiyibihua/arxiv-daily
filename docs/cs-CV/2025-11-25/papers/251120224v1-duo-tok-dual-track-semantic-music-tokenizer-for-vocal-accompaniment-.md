---
layout: default
title: DUO-TOK: Dual-Track Semantic Music Tokenizer for Vocal-Accompaniment Generation
---

# DUO-TOK: Dual-Track Semantic Music Tokenizer for Vocal-Accompaniment Generation

**arXiv**: [2511.20224v1](https://arxiv.org/abs/2511.20224) | [PDF](https://arxiv.org/pdf/2511.20224.pdf)

**ä½œè€…**: Rui Lin, Zhiyue Wu, Jiahe Le, Kangdi Wang, Weixiong Chen, Junyu Dai, Tao Jiang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDUO-TOKåŒè½¨è¯­ä¹‰éŸ³ä¹åˆ†è¯å™¨ï¼Œè§£å†³æ­Œè¯åˆ°æ­Œæ›²ç”Ÿæˆä¸­é‡å»ºè´¨é‡ä¸Žè¯­è¨€æ¨¡åž‹å¯å­¦ä¹ æ€§é—´çš„æƒè¡¡é—®é¢˜ã€‚**

**å…³é”®è¯**: `éŸ³ä¹åˆ†è¯å™¨` `åŒè½¨ç»“æž„` `è‡ªç›‘ç£å­¦ä¹ ` `æ½œåœ¨æ‰©æ•£æ¨¡åž‹` `æ­Œè¯åˆ°æ­Œæ›²ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰éŸ³ä¹ç¼–è§£ç å™¨åœ¨é‡å»ºä¿çœŸåº¦ä¸Žè¯­è¨€æ¨¡åž‹å‹å¥½æ€§é—´å­˜åœ¨æƒè¡¡ï¼Œä¸”ç¼ºä¹å¯¹å£°ä¹-ä¼´å¥åŒè½¨ç»“æž„çš„æ„ŸçŸ¥ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å››é˜¶æ®µè‡ªç›‘ç£å­¦ä¹ æµç¨‹ï¼ŒåŒ…æ‹¬é¢„è®­ç»ƒç¼–ç å™¨ã€è¡¨ç¤ºç¨³å®šä¸Žå› å­åŒ–ã€å­¦ä¹ åŒç æœ¬å’Œè®­ç»ƒæ½œåœ¨æ‰©æ•£è§£ç å™¨ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨0.75 kbpsä¸‹ï¼Œä¼˜åŒ–é‡å»º-ç”Ÿæˆå¸•ç´¯æ‰˜å‰æ²¿ï¼Œå®žçŽ°æœ€ä½³éŸ³ä¹æ ‡ç­¾APå’Œæœ€ä½Žè¯æ±‡å½’ä¸€åŒ–LMå›°æƒ‘åº¦ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Duo-Tok is a source-aware dual-codebook tokenizer for vocal-accompaniment music that targets the growing tension between reconstruction quality and language-model (LM) learnability in modern lyrics-to-song systems. Existing codecs either prioritize high-fidelity reconstruction with difficult-to-model acoustic tokens or compress aggressively into semantic tokens that are LM-friendly but lossy, and they rarely make the tokenizer itself aware of dual-track structure. Duo-Tok follows a four-stage, SSL-centered pipeline: we first pretrain a BEST-RQ-style encoder on large-scale audio, then stabilize and factorize the representation with Gaussian replacement noise and multi-task supervision, before freezing the encoder to learn SimVQ-based dual codebooks with hard routing for vocals and accompaniment, and finally training latent diffusion decoders on top of the discrete tokens. Duo-Tok at 0.75 kbps shifts the empirical reconstruction-generation Pareto frontier, achieving the best music-tagging AP and the lowest vocabulary-normalized LM perplexity among compared codecs while maintaining reconstruction quality comparable to state-of-the-art music tokenizers.

