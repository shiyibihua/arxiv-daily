---
layout: default
title: ACIT: Attention-Guided Cross-Modal Interaction Transformer for Pedestrian Crossing Intention Prediction
---

# ACIT: Attention-Guided Cross-Modal Interaction Transformer for Pedestrian Crossing Intention Prediction

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.20020" target="_blank" class="toolbar-btn">arXiv: 2511.20020v1</a>
    <a href="https://arxiv.org/pdf/2511.20020.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.20020v1" 
            onclick="toggleFavorite(this, '2511.20020v1', 'ACIT: Attention-Guided Cross-Modal Interaction Transformer for Pedestrian Crossing Intention Prediction')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yuanzhe Li, Steffen M√ºller

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-25

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ACITÊ®°ÂûãÔºåÂà©Áî®Ê≥®ÊÑèÂäõÊú∫Âà∂ÂíåË∑®Ê®°ÊÄÅ‰∫§‰∫íTransformerÊèêÂçáË°å‰∫∫ËøáË°óÊÑèÂõæÈ¢ÑÊµãÁ≤æÂ∫¶„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)** **ÊîØÊü±‰∫îÔºö‰∫§‰∫í‰∏éÂèçÂ∫î (Interaction & Reaction)**

**ÂÖ≥ÈîÆËØç**: `Ë°å‰∫∫ÊÑèÂõæÈ¢ÑÊµã` `Ë∑®Ê®°ÊÄÅ‰∫§‰∫í` `Ê≥®ÊÑèÂäõÊú∫Âà∂` `Transformer` `Ëá™Âä®È©æÈ©∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâË°å‰∫∫ÊÑèÂõæÈ¢ÑÊµãÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÊèêÂèñÂíåÊï¥ÂêàÊù•Ëá™‰∏çÂêåÁ±ªÂûãÊï∞ÊçÆÁöÑ‰∫íË°•‰ø°ÊÅØ„ÄÇ
2. ACITÊ®°ÂûãÈÄöËøáÊ≥®ÊÑèÂäõÊú∫Âà∂ÂºïÂØºË∑®Ê®°ÊÄÅÁâπÂæÅ‰∫§‰∫íÔºåÂπ∂Âà©Áî®TransformerÊçïËé∑Êó∂Â∫è‰æùËµñÂÖ≥Á≥ª„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåACITÂú®JAADÊï∞ÊçÆÈõÜ‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåËØÅÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊ≥®ÊÑèÂäõÊú∫Âà∂ÂºïÂØºÁöÑË∑®Ê®°ÊÄÅ‰∫§‰∫íTransformer (ACIT) Áî®‰∫éË°å‰∫∫ËøáË°óÊÑèÂõæÈ¢ÑÊµã„ÄÇACITÂà©Áî®ÂÖ≠ÁßçËßÜËßâÂíåËøêÂä®Ê®°ÊÄÅÊï∞ÊçÆÔºåÂπ∂Â∞ÜÂÆÉ‰ª¨ÂàÜ‰∏∫‰∏â‰∏™‰∫§‰∫íÂØπÔºö(1) ÂÖ®Â±ÄËØ≠‰πâÂú∞ÂõæÂíåÂÖ®Â±ÄÂÖâÊµÅÔºå(2) Â±ÄÈÉ®RGBÂõæÂÉèÂíåÂ±ÄÈÉ®ÂÖâÊµÅÔºå(3) Ëá™ËΩ¶ÈÄüÂ∫¶ÂíåË°å‰∫∫ËæπÁïåÊ°Ü„ÄÇÂú®ÊØè‰∏™ËßÜËßâ‰∫§‰∫íÂØπ‰∏≠ÔºåÂèåË∑ØÂæÑÊ≥®ÊÑèÂäõÊú∫Âà∂ÈÄöËøáÂÜÖÊ®°ÊÄÅËá™Ê≥®ÊÑèÂäõÂ¢ûÂº∫‰∏ªË¶ÅÊ®°ÊÄÅ‰∏≠ÁöÑÊòæËëóÂå∫ÂüüÔºåÂπ∂ÈÄöËøáÂÖâÊµÅÂºïÂØºÁöÑÊ≥®ÊÑèÂäõ‰øÉËøõ‰∏éËæÖÂä©Ê®°ÊÄÅÔºàÂç≥ÂÖâÊµÅÔºâÁöÑÊ∑±Â∫¶‰∫§‰∫í„ÄÇÂú®ËøêÂä®‰∫§‰∫íÂØπ‰∏≠ÔºåÈááÁî®Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÊù•Âª∫Ê®°Ë∑®Ê®°ÊÄÅÂä®ÊÄÅÔºå‰ªéËÄåÊúâÊïàÊèêÂèñ‰∫íË°•ÁöÑËøêÂä®ÁâπÂæÅ„ÄÇÈô§‰∫ÜÊàêÂØπ‰∫§‰∫í‰πãÂ§ñÔºåÂ§öÊ®°ÊÄÅÁâπÂæÅËûçÂêàÊ®°ÂùóËøõ‰∏ÄÊ≠•‰øÉËøõÊØè‰∏™Êó∂Èó¥Ê≠•ÁöÑË∑®Ê®°ÊÄÅ‰∫§‰∫í„ÄÇÊ≠§Â§ñÔºåÂºïÂÖ•Âü∫‰∫éTransformerÁöÑÊó∂Â∫èÁâπÂæÅËÅöÂêàÊ®°ÂùóÊù•ÊçïËé∑Â∫èÂàó‰æùËµñÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåACIT‰ºò‰∫éÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÔºåÂú®JAADbehÂíåJAADallÊï∞ÊçÆÈõÜ‰∏äÂàÜÂà´ÂÆûÁé∞‰∫Ü70%Âíå89%ÁöÑÂáÜÁ°ÆÁéá„ÄÇÊ≠§Â§ñÔºåËøòËøõË°å‰∫ÜÂπøÊ≥õÁöÑÊ∂àËûçÁ†îÁ©∂Ôºå‰ª•Á†îÁ©∂ACIT‰∏çÂêåÊ®°ÂùóÁöÑË¥°ÁåÆ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöË°å‰∫∫ËøáË°óÊÑèÂõæÈ¢ÑÊµãÊòØËá™Âä®È©æÈ©∂ÁöÑÂÖ≥ÈîÆ‰ªªÂä°ÔºåÊó®Âú®ÂáèÂ∞ëË°å‰∫∫Áõ∏ÂÖ≥ÁöÑ‰∫§ÈÄö‰∫ãÊïÖ„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàËûçÂêàÊù•Ëá™‰∏çÂêåÊ®°ÊÄÅÔºàÂ¶ÇËßÜËßâÂíåËøêÂä®ÔºâÁöÑ‰∫íË°•‰ø°ÊÅØÔºåÂØºËá¥È¢ÑÊµãÁ≤æÂ∫¶ÂèóÈôê„ÄÇÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇÂú∫ÊôØ‰∏ãÔºåÂ¶Ç‰ΩïÂáÜÁ°ÆÊçïÊçâË°å‰∫∫Ë°å‰∏∫ÁöÑÊó∂Â∫è‰æùËµñÊÄß‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöACITÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÊ≥®ÊÑèÂäõÊú∫Âà∂ÂºïÂØºË∑®Ê®°ÊÄÅÁâπÂæÅÁöÑ‰∫§‰∫íÔºåÂπ∂Âà©Áî®TransformerÊ®°ÂûãÊçïËé∑Êó∂Â∫è‰æùËµñÂÖ≥Á≥ª„ÄÇÈÄöËøáÂ∞ÜËßÜËßâÂíåËøêÂä®Ê®°ÊÄÅËøõË°åÈÖçÂØπÔºåÂπ∂ËÆæËÆ°Áõ∏Â∫îÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÊ®°ÂûãËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÊèêÂèñÂíåËûçÂêà‰∏çÂêåÊ®°ÊÄÅÁöÑ‰∫íË°•‰ø°ÊÅØ„ÄÇTransformerÊ®°ÂûãÂàôÁî®‰∫éÂª∫Ê®°Ë°å‰∫∫Ë°å‰∏∫ÁöÑÊó∂Â∫èÂä®ÊÄÅÔºå‰ªéËÄåÊèêÈ´òÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöACITÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) **Ë∑®Ê®°ÊÄÅ‰∫§‰∫íÊ®°Âùó**ÔºöÂ∞ÜÂÖ≠ÁßçÊ®°ÊÄÅÊï∞ÊçÆÂàÜ‰∏∫‰∏â‰∏™‰∫§‰∫íÂØπÔºåÂàÜÂà´ÊòØÂÖ®Â±ÄËØ≠‰πâÂú∞ÂõæÂíåÂÖ®Â±ÄÂÖâÊµÅ„ÄÅÂ±ÄÈÉ®RGBÂõæÂÉèÂíåÂ±ÄÈÉ®ÂÖâÊµÅ„ÄÅËá™ËΩ¶ÈÄüÂ∫¶ÂíåË°å‰∫∫ËæπÁïåÊ°Ü„ÄÇ2) **ÂèåË∑ØÂæÑÊ≥®ÊÑèÂäõÊú∫Âà∂**ÔºöÂú®ËßÜËßâ‰∫§‰∫íÂØπ‰∏≠ÔºåÂà©Áî®ÂèåË∑ØÂæÑÊ≥®ÊÑèÂäõÊú∫Âà∂Â¢ûÂº∫‰∏ªË¶ÅÊ®°ÊÄÅÁöÑÊòæËëóÂå∫ÂüüÔºåÂπ∂ÈÄöËøáÂÖâÊµÅÂºïÂØºÁöÑÊ≥®ÊÑèÂäõ‰øÉËøõ‰∏éËæÖÂä©Ê®°ÊÄÅÁöÑÊ∑±Â∫¶‰∫§‰∫í„ÄÇ3) **Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõ**ÔºöÂú®ËøêÂä®‰∫§‰∫íÂØπ‰∏≠ÔºåÈááÁî®Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÊù•Âª∫Ê®°Ë∑®Ê®°ÊÄÅÂä®ÊÄÅ„ÄÇ4) **Â§öÊ®°ÊÄÅÁâπÂæÅËûçÂêàÊ®°Âùó**ÔºöËøõ‰∏ÄÊ≠•‰øÉËøõÊØè‰∏™Êó∂Èó¥Ê≠•ÁöÑË∑®Ê®°ÊÄÅ‰∫§‰∫í„ÄÇ5) **TransformerÊó∂Â∫èÁâπÂæÅËÅöÂêàÊ®°Âùó**ÔºöÊçïËé∑Â∫èÂàó‰æùËµñÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöACITÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Ê≥®ÊÑèÂäõÂºïÂØºÁöÑË∑®Ê®°ÊÄÅ‰∫§‰∫íÊú∫Âà∂„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåACITËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÊèêÂèñÂíåËûçÂêà‰∏çÂêåÊ®°ÊÄÅÁöÑ‰∫íË°•‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇÊ≠§Â§ñÔºåACITËøòÂºïÂÖ•‰∫ÜTransformerÊ®°ÂûãÊù•ÊçïËé∑Ë°å‰∫∫Ë°å‰∏∫ÁöÑÊó∂Â∫è‰æùËµñÊÄßÔºåËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÈ¢ÑÊµãÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËßÜËßâ‰∫§‰∫íÂØπ‰∏≠ÔºåÂèåË∑ØÂæÑÊ≥®ÊÑèÂäõÊú∫Âà∂ÂåÖÂê´ÂÜÖÊ®°ÊÄÅËá™Ê≥®ÊÑèÂäõÂíåÂÖâÊµÅÂºïÂØºÁöÑÊ≥®ÊÑèÂäõ„ÄÇÂÜÖÊ®°ÊÄÅËá™Ê≥®ÊÑèÂäõÁî®‰∫éÂ¢ûÂº∫‰∏ªË¶ÅÊ®°ÊÄÅÁöÑÊòæËëóÂå∫ÂüüÔºåÂÖâÊµÅÂºïÂØºÁöÑÊ≥®ÊÑèÂäõÂàôÁî®‰∫é‰øÉËøõ‰∏éÂÖâÊµÅÊ®°ÊÄÅÁöÑ‰∫§‰∫í„ÄÇÂú®ËøêÂä®‰∫§‰∫íÂØπ‰∏≠ÔºåË∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÈááÁî®Ê†áÂáÜÁöÑTransformerÊ≥®ÊÑèÂäõÊú∫Âà∂„ÄÇTransformerÊó∂Â∫èÁâπÂæÅËÅöÂêàÊ®°ÂùóÈááÁî®Â§öÂ±ÇTransformerÁºñÁ†ÅÂô®ÁªìÊûÑÔºåÁî®‰∫éÊçïËé∑Êó∂Â∫è‰æùËµñÊÄß„ÄÇÊçüÂ§±ÂáΩÊï∞Êú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ACITÊ®°ÂûãÂú®JAADbehÊï∞ÊçÆÈõÜ‰∏äËææÂà∞‰∫Ü70%ÁöÑÂáÜÁ°ÆÁéáÔºåÂú®JAADallÊï∞ÊçÆÈõÜ‰∏äËææÂà∞‰∫Ü89%ÁöÑÂáÜÁ°ÆÁéáÔºåÊòæËëó‰ºò‰∫éÁé∞ÊúâÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇÊ∂àËûçÂÆûÈ™åË°®ÊòéÔºåÂêÑ‰∏™Ê®°ÂùóÈÉΩÂØπÊúÄÁªàÊÄßËÉΩÊúâË¥°ÁåÆÔºåÈ™åËØÅ‰∫ÜACITÊ®°ÂûãÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËá™Âä®È©æÈ©∂Á≥ªÁªüÔºåÊèêÈ´òËΩ¶ËæÜÂØπË°å‰∫∫ËøáË°óÊÑèÂõæÁöÑÈ¢ÑÊµãËÉΩÂäõÔºå‰ªéËÄåÂáèÂ∞ë‰∫§ÈÄö‰∫ãÊïÖ„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ï‰πüÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩÁõëÊéß„ÄÅÊú∫Âô®‰∫∫ÂØºËà™Á≠âÈ¢ÜÂüüÔºåÊèêÂçáÁ≥ªÁªüÂØπË°å‰∫∫Ë°å‰∏∫ÁöÑÁêÜËß£ÂíåÈ¢ÑÊµãËÉΩÂäõÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄºÂíåÂπøÈòîÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Predicting pedestrian crossing intention is crucial for autonomous vehicles to prevent pedestrian-related collisions. However, effectively extracting and integrating complementary cues from different types of data remains one of the major challenges. This paper proposes an attention-guided cross-modal interaction Transformer (ACIT) for pedestrian crossing intention prediction. ACIT leverages six visual and motion modalities, which are grouped into three interaction pairs: (1) Global semantic map and global optical flow, (2) Local RGB image and local optical flow, and (3) Ego-vehicle speed and pedestrian's bounding box. Within each visual interaction pair, a dual-path attention mechanism enhances salient regions within the primary modality through intra-modal self-attention and facilitates deep interactions with the auxiliary modality (i.e., optical flow) via optical flow-guided attention. Within the motion interaction pair, cross-modal attention is employed to model the cross-modal dynamics, enabling the effective extraction of complementary motion features. Beyond pairwise interactions, a multi-modal feature fusion module further facilitates cross-modal interactions at each time step. Furthermore, a Transformer-based temporal feature aggregation module is introduced to capture sequential dependencies. Experimental results demonstrate that ACIT outperforms state-of-the-art methods, achieving accuracy rates of 70% and 89% on the JAADbeh and JAADall datasets, respectively. Extensive ablation studies are further conducted to investigate the contribution of different modules of ACIT.

