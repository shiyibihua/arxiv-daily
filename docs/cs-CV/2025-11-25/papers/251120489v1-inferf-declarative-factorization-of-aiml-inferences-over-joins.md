---
layout: default
title: InferF: Declarative Factorization of AI/ML Inferences over Joins
---

# InferF: Declarative Factorization of AI/ML Inferences over Joins

**arXiv**: [2511.20489v1](https://arxiv.org/abs/2511.20489) | [PDF](https://arxiv.org/pdf/2511.20489.pdf)

**ä½œè€…**: Kanchan Chowdhury, Lixi Zhou, Lulu Xie, Xinwei Fu, Jia Zou

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInferFç³»ç»Ÿä»¥ä¼˜åŒ–å¤šè·¯è¿žæŽ¥ä¸Šçš„AI/MLæŽ¨ç†è®¡ç®—**

**å…³é”®è¯**: `å› å­åŒ–æœºå™¨å­¦ä¹ ` `å¤šè·¯è¿žæŽ¥æŽ¨ç†` `å£°æ˜Žå¼ç³»ç»Ÿ` `è®¡ç®—ä¼˜åŒ–` `æ•°æ®åº“å¼•æ“Žé›†æˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šè·¯è¿žæŽ¥ä¸­é‡å¤æ•°æ®å¯¼è‡´AI/MLæŽ¨ç†è®¡ç®—å†—ä½™ï¼ŒçŽ°æœ‰å› å­åŒ–æ–¹æ³•è®¨è®ºä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå£°æ˜Žå¼è¡¨è¾¾å¼ï¼Œå°†å› å­åŒ–è®¡ç®—ä¸‹æŽ¨åˆ°è¿žæŽ¥æ ‘èŠ‚ç‚¹ï¼Œæœ€å°åŒ–è®¡ç®—å’Œè¿žæŽ¥å¼€é”€ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žæ•°æ®é›†ä¸Šå®žçŽ°é«˜è¾¾11.3å€åŠ é€Ÿï¼Œå¹¶æ€»ç»“å› å­åŒ–MLçš„é€‚ç”¨æ¡ä»¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Real-world AI/ML workflows often apply inference computations to feature vectors joined from multiple datasets. To avoid the redundant AI/ML computations caused by repeated data records in the join's output, factorized ML has been proposed to decompose ML computations into sub-computations to be executed on each normalized dataset. However, there is insufficient discussion on how factorized ML could impact AI/ML inference over multi-way joins. To address the limitations, we propose a novel declarative InferF system, focusing on the factorization of arbitrary inference workflows represented as analyzable expressions over the multi-way joins. We formalize our problem to flexibly push down partial factorized computations to qualified nodes in the join tree to minimize the overall inference computation and join costs and propose two algorithms to resolve the problem: (1) a greedy algorithm based on a per-node cost function that estimates the influence on overall latency if a subset of factorized computations is pushed to a node, and (2) a genetic algorithm for iteratively enumerating and evaluating promising factorization plans. We implement InferF on Velox, an open-sourced database engine from Meta, evaluate it on real-world datasets, observed up to 11.3x speedups, and systematically summarized the factors that determine when factorized ML can benefit AI/ML inference workflows.

