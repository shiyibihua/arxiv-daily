---
layout: default
title: DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement Learning-Enhanced LLMs
---

# DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement Learning-Enhanced LLMs

**arXiv**: [2511.20468v1](https://arxiv.org/abs/2511.20468) | [PDF](https://arxiv.org/pdf/2511.20468.pdf)

**ä½œè€…**: Yuanhao Li, Mingshan Liu, Hongbo Wang, Yiding Zhang, Yifei Ma, Wei Tan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDRAFT-RLæ¡†æž¶ï¼Œé€šè¿‡å¤šä»£ç†è‰ç¨¿é“¾æŽ¨ç†å¢žå¼ºLLMsåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æ€§èƒ½**

**å…³é”®è¯**: `å¤šä»£ç†å¼ºåŒ–å­¦ä¹ ` `è‰ç¨¿é“¾æŽ¨ç†` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `å¤æ‚æŽ¨ç†ä»»åŠ¡` `å¥–åŠ±æ¨¡åž‹ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¤šä»£ç†åæ€æ¡†æž¶ä¾èµ–å•æ¬¡å“åº”ï¼ŒæŽ¨ç†æŽ¢ç´¢ç¼ºä¹ç»“æž„å¤šæ ·æ€§
2. DRAFT-RLé›†æˆè‰ç¨¿é“¾æŽ¨ç†ï¼Œä»£ç†ç”Ÿæˆå¤šè‰ç¨¿ï¼Œé€šè¿‡åŒä¼´è¯„ä¼°å’Œå¥–åŠ±æ¨¡åž‹é€‰æ‹©ä¼˜åŒ–ç­–ç•¥
3. åœ¨ä»£ç åˆæˆã€ç¬¦å·æ•°å­¦å’ŒçŸ¥è¯†é—®ç­”ä»»åŠ¡ä¸­ï¼Œå‡†ç¡®æ€§å’Œæ”¶æ•›é€Ÿåº¦æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Language Models (LLMs) have shown impressive capabilities in multi-step reasoning and problem-solving.Recent works introduce multi-agent reflection frameworks where multiple LLM agents critique and refine each other's outputs using reinforcement learning (RL). However, these approaches often rely on single-shot responses and lack structural diversity in reasoning exploration. In this paper, we propose DRAFT-RL, a novel framework that integrates Chain-of-Draft (CoD) reasoning into multi-agent RL training. Instead of generating single responses, each agent produces multiple drafts per query, which are then evaluated by peer agents and a learned reward model to identify the most promising trajectory. These selected drafts are used to refine future reasoning strategies through actor-critic learning.DRAFT-RL enables explicit multi-path exploration, peer-guided reflection, and reward-aligned selection, resulting in more robust and interpretable LLM agent behavior. We evaluate our method on complex reasoning tasks including code synthesis, symbolic math, and knowledge-intensive QA,demonstrating that DRAFT-RL outperforms existing reflective and RL-based agents by significant margins in both accuracy and convergence speed

