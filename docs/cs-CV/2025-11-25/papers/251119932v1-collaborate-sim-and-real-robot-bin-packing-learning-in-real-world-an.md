---
layout: default
title: Collaborate sim and real: Robot Bin Packing Learning in Real-world and Physical Engine
---

# Collaborate sim and real: Robot Bin Packing Learning in Real-world and Physical Engine

**arXiv**: [2511.19932v1](https://arxiv.org/abs/2511.19932) | [PDF](https://arxiv.org/pdf/2511.19932.pdf)

**ä½œè€…**: Lidi Zhang, Han Wu, Liyu Zhang, Ruofeng Liu, Haotian Wang, Chao Li, Desheng Zhang, Yunhuai Liu, Tian He

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ··åˆå¼ºåŒ–å­¦ä¹ æ¡†æž¶ä»¥è§£å†³æœºå™¨äººä¸‰ç»´è£…ç®±ä¸­çš„ä»¿çœŸä¸ŽçŽ°å®žå·®è·é—®é¢˜**

**å…³é”®è¯**: `ä¸‰ç»´è£…ç®±é—®é¢˜` `å¼ºåŒ–å­¦ä¹ ` `ä»¿çœŸåˆ°çŽ°å®žè¿ç§»` `é¢†åŸŸéšæœºåŒ–` `æœºå™¨äººéƒ¨ç½²`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°å®žè£…ç®±æ¶‰åŠè¿žç»­é‡åŠ›äº¤äº’ï¼ŒçŽ°æœ‰æ–¹æ³•ç®€åŒ–å¯¼è‡´ä¸ç¨³å®šéƒ¨ç½²ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆç‰©ç†ä»¿çœŸä¸ŽçœŸå®žæ•°æ®åé¦ˆï¼Œä½¿ç”¨é¢†åŸŸéšæœºåŒ–å’Œå¾®è°ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒæ˜¾ç¤ºå€’å¡ŒçŽ‡é™ä½Žï¼Œç‰©æµéƒ¨ç½²ä¸­å€’å¡Œå‡å°‘35%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The 3D bin packing problem, with its diverse industrial applications, has garnered significant research attention in recent years. Existing approaches typically model it as a discrete and static process, while real-world applications involve continuous gravity-driven interactions. This idealized simplification leads to infeasible deployments (e.g., unstable packing) in practice. Simulations with physical engine offer an opportunity to emulate continuous gravity effects, enabling the training of reinforcement learning (RL) agents to address such limitations and improve packing stability. However, a simulation-to-reality gap persists due to dynamic variations in physical properties of real-world objects, such as various friction coefficients, elasticity, and non-uniform weight distributions. To bridge this gap, we propose a hybrid RL framework that collaborates with physical simulation with real-world data feedback. Firstly, domain randomization is applied during simulation to expose agents to a spectrum of physical parameters, enhancing their generalization capability. Secondly, the RL agent is fine-tuned with real-world deployment feedback, further reducing collapse rates. Extensive experiments demonstrate that our method achieves lower collapse rates in both simulated and real-world scenarios. Large-scale deployments in logistics systems validate the practical effectiveness, with a 35\% reduction in packing collapse compared to baseline methods.

