---
layout: default
title: Image2Gcode: Image-to-G-code Generation for Additive Manufacturing Using Diffusion-Transformer Model
---

# Image2Gcode: Image-to-G-code Generation for Additive Manufacturing Using Diffusion-Transformer Model

**arXiv**: [2511.20636v1](https://arxiv.org/abs/2511.20636) | [PDF](https://arxiv.org/pdf/2511.20636.pdf)

**ä½œè€…**: Ziyue Wang, Yayati Jadhav, Peter Pak, Amir Barati Farimani

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºImage2Gcodeæ¡†æž¶ï¼Œç›´æŽ¥ä»Žå›¾åƒç”ŸæˆGä»£ç ä»¥åŠ é€Ÿå¢žæåˆ¶é€ è®¾è®¡æµç¨‹**

**å…³é”®è¯**: `å›¾åƒåˆ°Gä»£ç ç”Ÿæˆ` `æ‰©æ•£æ¦‚çŽ‡æ¨¡åž‹` `å¢žæåˆ¶é€ ` `ç«¯åˆ°ç«¯æ¡†æž¶` `è®¾è®¡è‡ªåŠ¨åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿåˆ¶é€ ä¾èµ–CADå»ºæ¨¡ï¼Œå¯¼è‡´è®¾è®¡è¿­ä»£ç¼“æ…¢ä¸”éš¾ä»¥æ‰©å±•
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ‰©æ•£-Transformeræ¨¡åž‹ä»Ž2Då›¾åƒç›´æŽ¥ç”Ÿæˆå¯æ‰§è¡ŒGä»£ç åºåˆ—
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¶ˆé™¤CADä¸­é—´æ­¥éª¤ï¼Œé™ä½Žåˆ¶é€ é—¨æ§›å¹¶åŠ é€ŸåŽŸåž‹åˆ¶ä½œ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Mechanical design and manufacturing workflows conventionally begin with conceptual design, followed by the creation of a computer-aided design (CAD) model and fabrication through material-extrusion (MEX) printing. This process requires converting CAD geometry into machine-readable G-code through slicing and path planning. While each step is well established, dependence on CAD modeling remains a major bottleneck: constructing object-specific 3D geometry is slow and poorly suited to rapid prototyping. Even minor design variations typically necessitate manual updates in CAD software, making iteration time-consuming and difficult to scale. To address this limitation, we introduce Image2Gcode, an end-to-end data-driven framework that bypasses the CAD stage and generates printer-ready G-code directly from images and part drawings. Instead of relying on an explicit 3D model, a hand-drawn or captured 2D image serves as the sole input. The framework first extracts slice-wise structural cues from the image and then employs a denoising diffusion probabilistic model (DDPM) over G-code sequences. Through iterative denoising, the model transforms Gaussian noise into executable print-move trajectories with corresponding extrusion parameters, establishing a direct mapping from visual input to native toolpaths. By producing structured G-code directly from 2D imagery, Image2Gcode eliminates the need for CAD or STL intermediates, lowering the entry barrier for additive manufacturing and accelerating the design-to-fabrication cycle. This approach supports on-demand prototyping from simple sketches or visual references and integrates with upstream 2D-to-3D reconstruction modules to enable an automated pipeline from concept to physical artifact. The result is a flexible, computationally efficient framework that advances accessibility in design iteration, repair workflows, and distributed manufacturing.

