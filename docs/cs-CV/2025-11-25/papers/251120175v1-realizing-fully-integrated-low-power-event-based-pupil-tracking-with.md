---
layout: default
title: Realizing Fully-Integrated, Low-Power, Event-Based Pupil Tracking with Neuromorphic Hardware
---

# Realizing Fully-Integrated, Low-Power, Event-Based Pupil Tracking with Neuromorphic Hardware

**arXiv**: [2511.20175v1](https://arxiv.org/abs/2511.20175) | [PDF](https://arxiv.org/pdf/2511.20175.pdf)

**ä½œè€…**: Federico Paredes-Valles, Yoshitaka Miyatani, Kirk Y. W. Scheper

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé›†æˆäº‹ä»¶æ„ŸçŸ¥ä¸Žç¥žç»å½¢æ€è®¡ç®—çš„ç©¿æˆ´å¼çž³å­”è¿½è¸ªç³»ç»Ÿï¼Œå®žçŽ°è¶…ä½ŽåŠŸè€—å®žæ—¶è·Ÿè¸ª**

**å…³é”®è¯**: `äº‹ä»¶è§†è§‰` `ç¥žç»å½¢æ€è®¡ç®—` `ç©¿æˆ´å¼ç³»ç»Ÿ` `çž³å­”è¿½è¸ª` `ä½ŽåŠŸè€—è®¾è®¡` `å®žæ—¶æŽ¨æ–­`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç©¿æˆ´å¼å¹³å°éš¾ä»¥å®žçŽ°é«˜é¢‘çŽ‡ã€ä½ŽåŠŸè€—çš„ç¨³å¥çœ¼åŠ¨è¿½è¸ª
2. é›†æˆäº‹ä»¶ä¼ æ„Ÿå™¨ä¸Žç¥žç»å½¢æ€èŠ¯ç‰‡ï¼Œé‡‡ç”¨é‡åŒ–ä¸ç¡®å®šæ€§çš„è„‰å†²ç¥žç»ç½‘ç»œ
3. åœ¨åŽŸåž‹ä¸Šå®žçŽ°100HzåŒçœ¼è¿½è¸ªï¼Œå¹³å‡åŠŸè€—ä½ŽäºŽ5mWæ¯çœ¼

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Eye tracking is fundamental to numerous applications, yet achieving robust, high-frequency tracking with ultra-low power consumption remains challenging for wearable platforms. While event-based vision sensors offer microsecond resolution and sparse data streams, they have lacked fully integrated, low-power processing solutions capable of real-time inference. In this work, we present the first battery-powered, wearable pupil-center-tracking system with complete on-device integration, combining event-based sensing and neuromorphic processing on the commercially available Speck2f system-on-chip with lightweight coordinate decoding on a low-power microcontroller. Our solution features a novel uncertainty-quantifying spiking neural network with gated temporal decoding, optimized for strict memory and bandwidth constraints, complemented by systematic deployment mechanisms that bridge the reality gap. We validate our system on a new multi-user dataset and demonstrate a wearable prototype with dual neuromorphic devices achieving robust binocular pupil tracking at 100 Hz with an average power consumption below 5 mW per eye. Our work demonstrates that end-to-end neuromorphic computing enables practical, always-on eye tracking for next-generation energy-efficient wearable systems.

