---
layout: default
title: DinoLizer: Learning from the Best for Generative Inpainting Localization
---

# DinoLizer: Learning from the Best for Generative Inpainting Localization

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.20722" target="_blank" class="toolbar-btn">arXiv: 2511.20722v1</a>
    <a href="https://arxiv.org/pdf/2511.20722.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.20722v1" 
            onclick="toggleFavorite(this, '2511.20722v1', 'DinoLizer: Learning from the Best for Generative Inpainting Localization')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Minh Thong Doi, Jan Butora, Vincent Itier, J√©r√©mie Boulanger, Patrick Bas

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-25

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**DinoLizerÔºöÂà©Áî®DINOv2Â≠¶‰π†ÁîüÊàêÂºèÂõæÂÉè‰øÆÂ§çÁØ°ÊîπÂå∫ÂüüÁöÑÂÆö‰Ωç**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ÂõæÂÉèÁØ°ÊîπÊ£ÄÊµã` `ÁîüÊàêÂºèÂõæÂÉè‰øÆÂ§ç` `DINOv2` `Vision Transformer` `Ëá™ÁõëÁù£Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁØ°ÊîπÊ£ÄÊµãÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂÆö‰ΩçÁîüÊàêÂºèÂõæÂÉè‰øÆÂ§ç‰∏≠ÁöÑÁØ°ÊîπÂå∫ÂüüÔºåÂ∞§ÂÖ∂ÊòØÂú®ËØ≠‰πâ‰∏ÄËá¥ÊÄßËæÉÂº∫ÁöÑÊÉÖÂÜµ‰∏ã„ÄÇ
2. DinoLizerÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑDINOv2Ê®°ÂûãÔºåÈÄöËøáÂæÆË∞ÉÁ∫øÊÄßÂàÜÁ±ªÂ§¥Ôºå‰∏ìÊ≥®‰∫éÊ£ÄÊµãËØ≠‰πâÂ±ÇÈù¢ÁöÑÁØ°ÊîπÔºåÂøΩÁï•ÈùûËØ≠‰πâÁºñËæë„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåDinoLizerÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂêéÂ§ÑÁêÜÊìç‰ΩúÂêéÔºåIoUÊèêÂçáÈ´òËææ12%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫DinoLizerÔºå‰∏Ä‰∏™Âü∫‰∫éDINOv2ÁöÑÊ®°ÂûãÔºåÁî®‰∫éÂÆö‰ΩçÁîüÊàêÂºèÂõæÂÉè‰øÆÂ§ç‰∏≠Ë¢´ÁØ°ÊîπÁöÑÂå∫Âüü„ÄÇËØ•ÊñπÊ≥ïÂü∫‰∫é‰∏Ä‰∏™È¢ÑËÆ≠ÁªÉÁöÑDINOv2Ê®°ÂûãÔºåËØ•Ê®°ÂûãÂú®B-FreeÊï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉ‰ª•Ê£ÄÊµãÂêàÊàêÂõæÂÉè„ÄÇÊàë‰ª¨Âú®Vision TransformerÁöÑpatchÂµåÂÖ•‰πã‰∏äÊ∑ªÂä†‰∏Ä‰∏™Á∫øÊÄßÂàÜÁ±ªÂ§¥Ôºå‰ª•$14	imes 14$ÁöÑpatchÂàÜËæ®ÁéáÈ¢ÑÊµãÁØ°Êîπ„ÄÇËØ•ÂàÜÁ±ªÂ§¥Ë¢´ËÆ≠ÁªÉ‰∏∫ÂÖ≥Ê≥®ËØ≠‰πâ‰∏äË¢´ÊîπÂèòÁöÑÂå∫ÂüüÔºåÂ∞ÜÈùûËØ≠‰πâÁºñËæëËßÜ‰∏∫ÂéüÂßãÂÜÖÂÆπÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇÁî±‰∫éViTÂè™Êé•ÂèóÂõ∫ÂÆöÂ§ßÂ∞èÁöÑËæìÂÖ•ÔºåÊàë‰ª¨‰ΩøÁî®ÊªëÂä®Á™óÂè£Á≠ñÁï•Êù•ËÅöÂêàÊõ¥Â§ßÂõæÂÉè‰∏äÁöÑÈ¢ÑÊµãÔºõÂØπÁîüÊàêÁöÑheatmapËøõË°åÂêéÂ§ÑÁêÜÔºå‰ª•ÁªÜÂåñ‰º∞ËÆ°ÁöÑ‰∫åÂÄºÁØ°Êîπmask„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåDinoLizerÂú®‰ªé‰∏çÂêåÁîüÊàêÊ®°ÂûãÂØºÂá∫ÁöÑÂêÑÁßç‰øÆÂ§çÊï∞ÊçÆÈõÜ‰∏äÔºåË∂ÖË∂ä‰∫ÜÊúÄÂÖàËøõÁöÑÂ±ÄÈÉ®ÁØ°ÊîπÊ£ÄÊµãÂô®„ÄÇÂÆÉÂØπÂ∏∏ËßÅÁöÑÂêéÂ§ÑÁêÜÊìç‰ΩúÔºàÂ¶ÇË∞ÉÊï¥Â§ßÂ∞è„ÄÅÊ∑ªÂä†Âô™Â£∞ÂíåJPEGÔºàÂèåÈáçÔºâÂéãÁº©Ôºâ‰øùÊåÅÈ≤ÅÊ£íÊÄß„ÄÇÂπ≥ÂùáËÄåË®ÄÔºåDinoLizerÂÆûÁé∞‰∫ÜÊØîÊ¨°‰ºòÊ®°ÂûãÈ´ò12%ÁöÑ‰∫§Âπ∂ÊØîÔºàIoUÔºâÔºåÂêéÂ§ÑÁêÜÂêéÂ¢ûÁõäÊõ¥Â§ß„ÄÇÊàë‰ª¨‰ΩøÁî®Áé∞ÊàêÁöÑDINOv2ËøõË°åÁöÑÂÆûÈ™åËØÅÊòé‰∫ÜVision TransformerÂú®ËØ•‰ªªÂä°‰∏≠ÁöÑÂº∫Â§ßË°®ÂæÅËÉΩÂäõ„ÄÇÊúÄÂêéÔºåÂ∞ÜDINOv2ÂèäÂÖ∂ÂêéÁªßËÄÖDINOv3Âú®deepfakeÂÆö‰Ωç‰∏≠ËøõË°åÊØîËæÉÁöÑÂπøÊ≥õÊ∂àËûçÁ†îÁ©∂ËØÅÂÆû‰∫ÜDinoLizerÁöÑ‰ºòË∂äÊÄß„ÄÇ‰ª£Á†ÅÂ∞ÜÂú®ËÆ∫ÊñáË¢´Êé•ÂèóÂêéÂÖ¨ÂºÄ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÁîüÊàêÂºèÂõæÂÉè‰øÆÂ§çÂêéÔºåÂ¶Ç‰ΩïÁ≤æÁ°ÆÂÆö‰ΩçË¢´ÁØ°ÊîπÂå∫ÂüüÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Èù¢ÂØπËØ≠‰πâ‰∏ÄËá¥ÊÄßËæÉÂº∫ÁöÑ‰øÆÂ§çÂõæÂÉèÊó∂ÔºåÈöæ‰ª•Âå∫ÂàÜÁúüÂÆûÂÜÖÂÆπÂíåÁîüÊàêÂÜÖÂÆπÔºåÂØºËá¥ÂÆö‰ΩçÁ≤æÂ∫¶‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑDINOv2Ê®°ÂûãÂº∫Â§ßÁöÑËßÜËßâË°®ÂæÅËÉΩÂäõÔºåÂπ∂Âú®Ê≠§Âü∫Á°Ä‰∏äËÆ≠ÁªÉ‰∏Ä‰∏™ÂàÜÁ±ªÂô®Ôºå‰∏ìÊ≥®‰∫éÊ£ÄÊµãÂõæÂÉè‰∏≠ËØ≠‰πâÂ±ÇÈù¢ÁöÑÂèòÂåñ„ÄÇÈÄöËøáÂøΩÁï•ÈùûËØ≠‰πâÁºñËæëÔºåÊ®°ÂûãÂèØ‰ª•Êõ¥ÂáÜÁ°ÆÂú∞ËØÜÂà´Âá∫Ë¢´ÁØ°ÊîπÁöÑÂå∫Âüü„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöDinoLizerÁöÑÊäÄÊúØÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) ‰ΩøÁî®Âú®B-FreeÊï∞ÊçÆÈõÜ‰∏äÈ¢ÑËÆ≠ÁªÉÁöÑDINOv2Ê®°ÂûãÊèêÂèñÂõæÂÉèÁâπÂæÅÔºõ2) Âú®Vision TransformerÁöÑpatchÂµåÂÖ•‰πã‰∏äÊ∑ªÂä†‰∏Ä‰∏™Á∫øÊÄßÂàÜÁ±ªÂ§¥Ôºõ3) ‰ΩøÁî®ÊªëÂä®Á™óÂè£Á≠ñÁï•Â§ÑÁêÜÂ§ßÂ∞∫ÂØ∏ÂõæÂÉèÔºåÁîüÊàêheatmapÔºõ4) ÂØπheatmapËøõË°åÂêéÂ§ÑÁêÜÔºåÂæóÂà∞ÊúÄÁªàÁöÑ‰∫åÂÄºÁØ°Êîπmask„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂà©Áî®DINOv2ÁöÑËá™ÁõëÁù£Â≠¶‰π†ËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂ≠¶‰π†Âà∞ÂõæÂÉèÁöÑÊ∑±Â±ÇËØ≠‰πâ‰ø°ÊÅØ„ÄÇÈÄöËøáÂæÆË∞ÉÁ∫øÊÄßÂàÜÁ±ªÂ§¥ÔºåÊ®°ÂûãËÉΩÂ§ü‰∏ìÊ≥®‰∫éÊ£ÄÊµãËØ≠‰πâÂ±ÇÈù¢ÁöÑÁØ°ÊîπÔºå‰ªéËÄåÊèêÈ´òÂÆö‰ΩçÁ≤æÂ∫¶„ÄÇÊ≠§Â§ñÔºåÊªëÂä®Á™óÂè£Á≠ñÁï•ÂíåÂêéÂ§ÑÁêÜÊ≠•È™§‰πüËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöDinoLizerÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®DINOv2‰Ωú‰∏∫ÁâπÂæÅÊèêÂèñÂô®Ôºõ2) Âú®ViTÁöÑpatchÂµåÂÖ•‰∏äÊ∑ªÂä†Á∫øÊÄßÂàÜÁ±ªÂ§¥Ôºå‰ª•$14	imes 14$ÁöÑpatchÂàÜËæ®ÁéáËøõË°åÈ¢ÑÊµãÔºõ3) ‰ΩøÁî®ÊªëÂä®Á™óÂè£Á≠ñÁï•Â§ÑÁêÜÂ§ßÂ∞∫ÂØ∏ÂõæÂÉèÔºõ4) ÈÄöËøáÂêéÂ§ÑÁêÜÊ≠•È™§ÔºàÊú™Áü•ÂÖ∑‰ΩìÁªÜËäÇÔºâÁªÜÂåñÁØ°Êîπmask„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

DinoLizerÂú®Â§ö‰∏™ÁîüÊàêÂºèÂõæÂÉè‰øÆÂ§çÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂπ≥ÂùáIoUÊØîÊ¨°‰ºòÊ®°ÂûãÈ´ò12%ÔºåÂπ∂‰∏îÂú®ÁªèËøáÂ∏∏ËßÅÁöÑÂêéÂ§ÑÁêÜÊìç‰ΩúÔºàÂ¶ÇÁº©Êîæ„ÄÅÂô™Â£∞Ê∑ªÂä†„ÄÅJPEGÂéãÁº©ÔºâÂêéÔºå‰ªçÁÑ∂‰øùÊåÅ‰∫ÜËæÉÂ•ΩÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÊ∂àËûçÂÆûÈ™åË°®ÊòéÔºåDINOv2‰ºò‰∫éÂÖ∂ÂêéÁªßËÄÖDINOv3Âú®deepfakeÂÆö‰Ωç‰ªªÂä°‰∏äÁöÑË°®Áé∞„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

DinoLizerÂèØÂ∫îÁî®‰∫éÊï∞Â≠óÂèñËØÅ„ÄÅÂõæÂÉèÁâàÊùÉ‰øùÊä§„ÄÅÊñ∞ÈóªÁúüÂÆûÊÄßÈ™åËØÅÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáËá™Âä®Ê£ÄÊµãÂõæÂÉè‰∏≠ÁöÑÁØ°ÊîπÂå∫ÂüüÔºåÂèØ‰ª•Â∏ÆÂä©ËØÜÂà´‰º™ÈÄ†ÂõæÂÉèÔºåÁª¥Êä§ÁΩëÁªú‰ø°ÊÅØÂÆâÂÖ®ÔºåÂπ∂‰∏∫Âè∏Ê≥ïÈâ¥ÂÆöÊèê‰æõÊäÄÊúØÊîØÊåÅ„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÈõÜÊàêÂà∞ÂõæÂÉèÁºñËæëËΩØ‰ª∂‰∏≠ÔºåËæÖÂä©Áî®Êà∑ËØÜÂà´ÊΩúÂú®ÁöÑÁØ°ÊîπÈ£éÈô©„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We introduce DinoLizer, a DINOv2-based model for localizing manipulated regions in generative inpainting. Our method builds on a DINOv2 model pretrained to detect synthetic images on the B-Free dataset. We add a linear classification head on top of the Vision Transformer's patch embeddings to predict manipulations at a $14\times 14$ patch resolution. The head is trained to focus on semantically altered regions, treating non-semantic edits as part of the original content. Because the ViT accepts only fixed-size inputs, we use a sliding-window strategy to aggregate predictions over larger images; the resulting heatmaps are post-processed to refine the estimated binary manipulation masks. Empirical results show that DinoLizer surpasses state-of-the-art local manipulation detectors on a range of inpainting datasets derived from different generative models. It remains robust to common post-processing operations such as resizing, noise addition, and JPEG (double) compression. On average, DinoLizer achieves a 12\% higher Intersection-over-Union (IoU) than the next best model, with even greater gains after post-processing. Our experiments with off-the-shelf DINOv2 demonstrate the strong representational power of Vision Transformers for this task. Finally, extensive ablation studies comparing DINOv2 and its successor, DINOv3, in deepfake localization confirm DinoLizer's superiority. The code will be publicly available upon acceptance of the paper.

