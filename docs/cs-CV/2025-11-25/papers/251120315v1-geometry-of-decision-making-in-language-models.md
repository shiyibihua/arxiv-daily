---
layout: default
title: Geometry of Decision Making in Language Models
---

# Geometry of Decision Making in Language Models

**arXiv**: [2511.20315v1](https://arxiv.org/abs/2511.20315) | [PDF](https://arxiv.org/pdf/2511.20315.pdf)

**ä½œè€…**: Abhinav Joshi, Divyanshu Bhatt, Ashutosh Modi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶è¯­è¨€æ¨¡åž‹å†…åœ¨ç»´åº¦å‡ ä½•ä»¥æ­ç¤ºå¤šé€‰é—®ç­”å†³ç­–è¿‡ç¨‹**

**å…³é”®è¯**: `è¯­è¨€æ¨¡åž‹` `å†…åœ¨ç»´åº¦` `å¤šé€‰é—®ç­”` `è¡¨ç¤ºå‡ ä½•` `å†³ç­–è¿‡ç¨‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè¯­è¨€æ¨¡åž‹å†…éƒ¨å†³ç­–è¿‡ç¨‹ä¸é€æ˜Žï¼Œå½±å“å¯è§£é‡Šæ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å†…åœ¨ç»´åº¦åˆ†æžéšè—è¡¨ç¤ºï¼Œèšç„¦å¤šé€‰é—®ç­”åœºæ™¯ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼š28ä¸ªæ¨¡åž‹æ˜¾ç¤ºIDæ¨¡å¼ï¼šæ—©æœŸä½Žç»´ã€ä¸­æœŸæ‰©å±•ã€åŽæœŸåŽ‹ç¼©ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Language Models (LLMs) show strong generalization across diverse tasks, yet the internal decision-making processes behind their predictions remain opaque. In this work, we study the geometry of hidden representations in LLMs through the lens of \textit{intrinsic dimension} (ID), focusing specifically on decision-making dynamics in a multiple-choice question answering (MCQA) setting. We perform a large-scale study, with 28 open-weight transformer models and estimate ID across layers using multiple estimators, while also quantifying per-layer performance on MCQA tasks. Our findings reveal a consistent ID pattern across models: early layers operate on low-dimensional manifolds, middle layers expand this space, and later layers compress it again, converging to decision-relevant representations. Together, these results suggest LLMs implicitly learn to project linguistic inputs onto structured, low-dimensional manifolds aligned with task-specific decisions, providing new geometric insights into how generalization and reasoning emerge in language models.

