---
layout: default
title: MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing
---

# MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.19963" target="_blank" class="toolbar-btn">arXiv: 2511.19963v1</a>
    <a href="https://arxiv.org/pdf/2511.19963.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.19963v1" 
            onclick="toggleFavorite(this, '2511.19963v1', 'MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Changho Choi, Minho Kim, Jinkyu Kim

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-25

**Â§áÊ≥®**: Code will be released in github

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**MambaEyeÔºöÂü∫‰∫éÂõ†ÊûúÂ∫èÂàóÂ§ÑÁêÜÁöÑÂ∞∫ÂØ∏Êó†ÂÖ≥ËßÜËßâÁºñÁ†ÅÂô®**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâÁºñÁ†ÅÂô®` `Mamba` `Áä∂ÊÄÅÁ©∫Èó¥Ê®°Âûã` `Âõ†ÊûúÂ∫èÂàóÂ§ÑÁêÜ` `Â∞∫ÂØ∏Êó†ÂÖ≥` `Áõ∏ÂØπÁßªÂä®ÂµåÂÖ•` `È´òÂàÜËæ®ÁéáÂõæÂÉè` `ÂõæÂÉèÂàÜÁ±ª`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜËßâÁºñÁ†ÅÂô®Èöæ‰ª•ÂÆûÁé∞ËæìÂÖ•Â∞∫ÂØ∏Êó†ÂÖ≥ÊÄßÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®‰∏çÂêåÂàÜËæ®ÁéáÂõæÂÉè‰∏äÁöÑÂ∫îÁî®„ÄÇ
2. MambaEyeÂà©Áî®ÂçïÂêëMamba2È™®Âπ≤ÁΩëÁªúÂíåÁõ∏ÂØπÁßªÂä®ÂµåÂÖ•ÔºåÂÆûÁé∞Âõ†ÊûúÂ∫èÂàóÂ§ÑÁêÜÂíåÂØπ‰ªªÊÑèÂàÜËæ®ÁéáÁöÑÈÄÇÂ∫îÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåMambaEyeÂú®ImageNet-1KÂàÜÁ±ª‰ªªÂä°‰∏≠ÔºåÈ´òÂàÜËæ®ÁéáÂõæÂÉè‰∏äË°®Áé∞Âá∫Âº∫Â§ßÁöÑÊÄßËÉΩÔºå‰∏î‰øùÊåÅÁ∫øÊÄßÂ§çÊùÇÂ∫¶„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂõ†ÊûúÂ∫èÂàóÁºñÁ†ÅÂô®MambaEyeÔºåÊó®Âú®Ëß£ÂÜ≥ËßÜËßâÁºñÁ†ÅÂô®ÂØπËæìÂÖ•Â∞∫ÂØ∏ÁöÑ‰æùËµñÈóÆÈ¢òÔºåËøôÊòØ‰∫∫Á±ªËßÜËßâÁöÑ‰∏Ä‰∏™Âü∫Êú¨ÁâπÂæÅ‰ΩÜÈïøÊúüÊú™Ë¢´Ëß£ÂÜ≥„ÄÇMambaEyeÂà©Áî®‰ΩéÂ§çÊùÇÂ∫¶ÂíåÂü∫‰∫éÂõ†ÊûúËøáÁ®ãÁöÑÁ∫ØMamba2È™®Âπ≤ÁΩëÁªú„ÄÇ‰∏é‰ª•ÂæÄÂü∫‰∫éMambaÁöÑÂèåÂêëËßÜËßâÁºñÁ†ÅÂô®‰∏çÂêåÔºåMambaEyeÈááÁî®‰∏•Ê†ºÁöÑÂçïÂêëÊñπÊ≥ïÔºå‰øùÁïô‰∫ÜÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÁöÑÂõ∫ÊúâÂõ†ÊûúÊÄßÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂú®ËæìÂÖ•Â∫èÂàóÁöÑ‰ªª‰ΩïÁÇπÁîüÊàêÈ¢ÑÊµã„ÄÇÊ†∏ÂøÉÂàõÊñ∞ÊòØÁõ∏ÂØπÁßªÂä®ÂµåÂÖ•ÔºåÂÆÉÁºñÁ†Å‰∫ÜËøûÁª≠ÂõæÂÉèÂùó‰πãÈó¥ÁöÑÁ©∫Èó¥‰ΩçÁßªÔºå‰∏∫Âπ≥Áßª‰∏çÂèòÊÄßÊèê‰æõ‰∫ÜÂº∫Â§ßÁöÑÂΩíÁ∫≥ÂÅèÁΩÆÔºåÂπ∂‰ΩøÊ®°ÂûãËÉΩÂ§üÈÄÇÂ∫î‰ªªÊÑèÂõæÂÉèÂàÜËæ®ÁéáÂíåÊâ´ÊèèÊ®°Âºè„ÄÇÊ≠§Â§ñÔºåÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂèóÊâ©Êï£ÂêØÂèëÁöÑÊçüÂ§±ÂáΩÊï∞ÔºåÊèê‰æõÂØÜÈõÜÁöÑ„ÄÅÈÄêÊ≠•ÁöÑÁõëÁù£ÔºåËÆ≠ÁªÉÊ®°ÂûãÂú®Êî∂ÈõÜÊõ¥Â§öËßÜËßâËØÅÊçÆÊó∂Âª∫Á´ãÁΩÆ‰ø°Â∫¶„ÄÇÂÆûÈ™åË°®ÊòéÔºåMambaEyeÂú®ÂêÑÁßçÂõæÂÉèÂàÜËæ®Áéá‰∏ãË°®Áé∞Âá∫Âº∫Â§ßÁöÑÊÄßËÉΩÔºåÂ∞§ÂÖ∂ÊòØÂú®ImageNet-1KÂàÜÁ±ª‰ªªÂä°‰∏≠ÔºåÂàÜËæ®ÁéáÈ´òËææ$1536^2$Êó∂„ÄÇÂêåÊó∂ÔºåÁõ∏ÂØπ‰∫éÂõæÂÉèÂùóÁöÑÊï∞ÈáèÔºå‰øùÊåÅ‰∫ÜÁ∫øÊÄßÁöÑÊó∂Èó¥ÂíåÂÜÖÂ≠òÂ§çÊùÇÂ∫¶„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜËßâÁºñÁ†ÅÂô®ÈÄöÂ∏∏ÂØπËæìÂÖ•ÂõæÂÉèÁöÑÂ∞∫ÂØ∏Êúâ‰∏•Ê†ºË¶ÅÊ±ÇÔºåÊó†Ê≥ïÂÉè‰∫∫Á±ªËßÜËßâ‰∏ÄÊ†∑ÁÅµÊ¥ªÂ§ÑÁêÜ‰ªªÊÑèÂàÜËæ®ÁéáÁöÑÂõæÂÉè„ÄÇËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®È´òÂàÜËæ®ÁéáÂõæÂÉèÂ§ÑÁêÜÊñπÈù¢ÔºåËÆ°ÁÆóÂ§çÊùÇÂ∫¶‰ºöÊòæËëóÂ¢ûÂä†„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMambaEyeÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ÂçïÂêëÁöÑMamba2Êû∂ÊûÑÔºåÁªìÂêàÁõ∏ÂØπÁßªÂä®ÂµåÂÖ•ÔºåÂÆûÁé∞ÂØπÂõæÂÉèÂùóÂ∫èÂàóÁöÑÂõ†ÊûúÂª∫Ê®°„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÊ®°ÂûãÂèØ‰ª•ÈÄêÊ≠•ÁßØÁ¥ØËßÜËßâ‰ø°ÊÅØÔºåÂπ∂Âú®‰ªªÊÑèÊó∂ÂàªÁîüÊàêÈ¢ÑÊµãÔºå‰ªéËÄåÊëÜËÑ±ÂØπÂõ∫ÂÆöËæìÂÖ•Â∞∫ÂØ∏ÁöÑ‰æùËµñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMambaEyeÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ≠•È™§Ôºö1) Â∞ÜËæìÂÖ•ÂõæÂÉèÂàÜÂâ≤ÊàêÂõæÂÉèÂùóÂ∫èÂàóÔºõ2) ‰ΩøÁî®Áõ∏ÂØπÁßªÂä®ÂµåÂÖ•ÁºñÁ†ÅÂõæÂÉèÂùó‰πãÈó¥ÁöÑÁ©∫Èó¥ÂÖ≥Á≥ªÔºõ3) Â∞ÜÁºñÁ†ÅÂêéÁöÑÂ∫èÂàóËæìÂÖ•Âà∞ÂçïÂêëMamba2È™®Âπ≤ÁΩëÁªú‰∏≠ËøõË°åÁâπÂæÅÊèêÂèñÔºõ4) ‰ΩøÁî®ÂàÜÁ±ªÂ§¥Âü∫‰∫éÊèêÂèñÁöÑÁâπÂæÅËøõË°åÈ¢ÑÊµã„ÄÇÂÖ≥ÈîÆÂú®‰∫éMamba2ÁöÑÂçïÂêëÊÄßÂíåÁõ∏ÂØπÁßªÂä®ÂµåÂÖ•ÁöÑÁ©∫Èó¥‰ø°ÊÅØÁºñÁ†Å„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMambaEyeÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ª•‰∏ã‰∏§ÁÇπÔºö‰∏ÄÊòØÈááÁî®‰∫ÜÂçïÂêëÁöÑMamba2Êû∂ÊûÑÔºå‰øùÁïô‰∫ÜÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÁöÑÂõ†ÊûúÊÄßÔºå‰ΩøÂÖ∂ËÉΩÂ§üËøõË°åÂ∫èÂàóÂåñÁöÑËßÜËßâ‰ø°ÊÅØÂ§ÑÁêÜÔºõ‰∫åÊòØÂºïÂÖ•‰∫ÜÁõ∏ÂØπÁßªÂä®ÂµåÂÖ•ÔºåÊúâÊïàÂú∞ÁºñÁ†Å‰∫ÜÂõæÂÉèÂùó‰πãÈó¥ÁöÑÁ©∫Èó¥ÂÖ≥Á≥ªÔºå‰∏∫Âπ≥Áßª‰∏çÂèòÊÄßÊèê‰æõ‰∫ÜÂº∫Â§ßÁöÑÂΩíÁ∫≥ÂÅèÁΩÆÔºåÂπ∂‰ΩøÊ®°ÂûãËÉΩÂ§üÈÄÇÂ∫î‰ªªÊÑèÂõæÂÉèÂàÜËæ®ÁéáÂíåÊâ´ÊèèÊ®°Âºè„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöMambaEyeÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®Áõ∏ÂØπÁßªÂä®ÂµåÂÖ•Êù•ÁºñÁ†ÅÂõæÂÉèÂùó‰πãÈó¥ÁöÑÁ©∫Èó¥‰ΩçÁßªÔºåÂÖ∑‰ΩìÂÆûÁé∞ÊñπÂºèÊú™Áü•Ôºõ2) ÈááÁî®ÂèóÊâ©Êï£ÂêØÂèëÁöÑÊçüÂ§±ÂáΩÊï∞ÔºåÊèê‰æõÂØÜÈõÜÁöÑ„ÄÅÈÄêÊ≠•ÁöÑÁõëÁù£ÔºåËÆ≠ÁªÉÊ®°ÂûãÂú®Êî∂ÈõÜÊõ¥Â§öËßÜËßâËØÅÊçÆÊó∂Âª∫Á´ãÁΩÆ‰ø°Â∫¶ÔºåÊçüÂ§±ÂáΩÊï∞ÁöÑÂÖ∑‰ΩìÂΩ¢ÂºèÊú™Áü•Ôºõ3) Mamba2È™®Âπ≤ÁΩëÁªúÁöÑÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MambaEyeÂú®ImageNet-1KÂàÜÁ±ª‰ªªÂä°‰∏≠ÔºåÂ∞§ÂÖ∂ÊòØÂú®È´òÂàÜËæ®ÁéáÔºàÂ¶Ç$1536^2$ÔºâÂõæÂÉè‰∏äË°®Áé∞Âá∫Âº∫Â§ßÁöÑÊÄßËÉΩ„ÄÇÁõ∏ËæÉ‰∫é‰º†ÁªüÁöÑËßÜËßâÁºñÁ†ÅÂô®ÔºåMambaEyeÂú®È´òÂàÜËæ®ÁéáÂõæÂÉèÂ§ÑÁêÜÊñπÈù¢ÂÖ∑ÊúâÊòæËëó‰ºòÂäøÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÁ∫øÊÄßÁöÑÊó∂Èó¥ÂíåÂÜÖÂ≠òÂ§çÊùÇÂ∫¶„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÊú™Âú®ÊëòË¶Å‰∏≠ÊòéÁ°ÆÁªôÂá∫ÔºåÈúÄË¶ÅÊü•ÈòÖËÆ∫ÊñáÂÖ®Êñá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MambaEyeÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÂú®È´òÂàÜËæ®ÁéáÂõæÂÉèËØÜÂà´„ÄÅÂåªÂ≠¶ÂõæÂÉèÂàÜÊûê„ÄÅÈÅ•ÊÑüÂõæÂÉèÂ§ÑÁêÜÁ≠âÈ¢ÜÂüü„ÄÇÂÖ∂Â∞∫ÂØ∏Êó†ÂÖ≥ÁöÑÁâπÊÄß‰ΩøÂÖ∂ËÉΩÂ§üÁÅµÊ¥ªÂ∫îÁî®‰∫éÂêÑÁßçÂú∫ÊôØÔºåÈôç‰Ωé‰∫ÜÂØπËæìÂÖ•ÂõæÂÉèÂ∞∫ÂØ∏ÁöÑÈôêÂà∂ÔºåÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊú™Êù•ÔºåMambaEyeÊúâÊúõÊàê‰∏∫‰∏ÄÁßçÈÄöÁî®ÁöÑËßÜËßâÁºñÁ†ÅÂô®Ôºå‰∏∫ÂêÑÁßçËßÜËßâ‰ªªÂä°Êèê‰æõÂº∫Â§ßÁöÑÊîØÊåÅ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Despite decades of progress, a truly input-size agnostic visual encoder-a fundamental characteristic of human vision-has remained elusive. We address this limitation by proposing \textbf{MambaEye}, a novel, causal sequential encoder that leverages the low complexity and causal-process based pure Mamba2 backbone. Unlike previous Mamba-based vision encoders that often employ bidirectional processing, our strictly unidirectional approach preserves the inherent causality of State Space Models, enabling the model to generate a prediction at any point in its input sequence. A core innovation is our use of relative move embedding, which encodes the spatial shift between consecutive patches, providing a strong inductive bias for translation invariance and making the model inherently adaptable to arbitrary image resolutions and scanning patterns. To achieve this, we introduce a novel diffusion-inspired loss function that provides dense, step-wise supervision, training the model to build confidence as it gathers more visual evidence. We demonstrate that MambaEye exhibits robust performance across a wide range of image resolutions, especially at higher resolutions such as $1536^2$ on the ImageNet-1K classification task. This feat is achieved while maintaining linear time and memory complexity relative to the number of patches.

