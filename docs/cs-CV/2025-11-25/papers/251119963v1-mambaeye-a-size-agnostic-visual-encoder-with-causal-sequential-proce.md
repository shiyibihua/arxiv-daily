---
layout: default
title: MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing
---

# MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing

**arXiv**: [2511.19963v1](https://arxiv.org/abs/2511.19963) | [PDF](https://arxiv.org/pdf/2511.19963.pdf)

**ä½œè€…**: Changho Choi, Minho Kim, Jinkyu Kim

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMambaEyeè§†è§‰ç¼–ç å™¨ï¼Œé€šè¿‡å› æžœåºåˆ—å¤„ç†å®žçŽ°è¾“å…¥å°ºå¯¸æ— å…³çš„å›¾åƒç¼–ç ã€‚**

**å…³é”®è¯**: `è§†è§‰ç¼–ç å™¨` `å› æžœåºåˆ—å¤„ç†` `è¾“å…¥å°ºå¯¸æ— å…³` `ç›¸å¯¹ç§»åŠ¨åµŒå…¥` `çº¿æ€§å¤æ‚åº¦` `å›¾åƒåˆ†ç±»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§†è§‰ç¼–ç å™¨éš¾ä»¥å®žçŽ°è¾“å…¥å°ºå¯¸æ— å…³ï¼Œé™åˆ¶äº†æ¨¡åž‹çµæ´»æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å•å‘å› æžœå¤„ç†å’Œç›¸å¯¹ç§»åŠ¨åµŒå…¥ï¼Œå¢žå¼ºå¹³ç§»ä¸å˜æ€§å’Œåˆ†è¾¨çŽ‡é€‚åº”æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ImageNet-1Kä¸Šé«˜åˆ†è¾¨çŽ‡è¡¨çŽ°ç¨³å¥ï¼Œä¿æŒçº¿æ€§å¤æ‚åº¦ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite decades of progress, a truly input-size agnostic visual encoder-a fundamental characteristic of human vision-has remained elusive. We address this limitation by proposing \textbf{MambaEye}, a novel, causal sequential encoder that leverages the low complexity and causal-process based pure Mamba2 backbone. Unlike previous Mamba-based vision encoders that often employ bidirectional processing, our strictly unidirectional approach preserves the inherent causality of State Space Models, enabling the model to generate a prediction at any point in its input sequence. A core innovation is our use of relative move embedding, which encodes the spatial shift between consecutive patches, providing a strong inductive bias for translation invariance and making the model inherently adaptable to arbitrary image resolutions and scanning patterns. To achieve this, we introduce a novel diffusion-inspired loss function that provides dense, step-wise supervision, training the model to build confidence as it gathers more visual evidence. We demonstrate that MambaEye exhibits robust performance across a wide range of image resolutions, especially at higher resolutions such as $1536^2$ on the ImageNet-1K classification task. This feat is achieved while maintaining linear time and memory complexity relative to the number of patches.

