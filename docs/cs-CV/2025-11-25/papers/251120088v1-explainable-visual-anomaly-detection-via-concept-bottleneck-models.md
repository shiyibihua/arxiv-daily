---
layout: default
title: Explainable Visual Anomaly Detection via Concept Bottleneck Models
---

# Explainable Visual Anomaly Detection via Concept Bottleneck Models

**arXiv**: [2511.20088v1](https://arxiv.org/abs/2511.20088) | [PDF](https://arxiv.org/pdf/2511.20088.pdf)

**ä½œè€…**: Arianna Stropeni, Valentina Zaccaria, Francesco Borsatti, Davide Dalle Pezze, Manuel Barusco, Gian Antonio Susto

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¦‚å¿µç“¶é¢ˆæ¨¡åž‹æ‰©å±•ä»¥è§£å†³è§†è§‰å¼‚å¸¸æ£€æµ‹ä¸­è§£é‡Šç¼ºä¹è¯­ä¹‰æ„ä¹‰çš„é—®é¢˜**

**å…³é”®è¯**: `è§†è§‰å¼‚å¸¸æ£€æµ‹` `æ¦‚å¿µç“¶é¢ˆæ¨¡åž‹` `å¯è§£é‡Šäººå·¥æ™ºèƒ½` `è¯­ä¹‰è§£é‡Š` `å¼‚å¸¸åˆæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§†è§‰å¼‚å¸¸æ£€æµ‹æ¨¡åž‹æä¾›è§†è§‰è§£é‡Šä½†ç¼ºä¹ç›´æŽ¥è¯­ä¹‰è§£é‡Šï¼Œå½±å“ç”¨æˆ·ç†è§£
2. æ–¹æ³•è¦ç‚¹ï¼šæ‰©å±•æ¦‚å¿µç“¶é¢ˆæ¨¡åž‹ï¼Œå­¦ä¹ æœ‰æ„ä¹‰æ¦‚å¿µä»¥ç”Ÿæˆäººç±»å¯è§£é‡Šçš„å¼‚å¸¸æè¿°
3. å®žéªŒæˆ–æ•ˆæžœï¼šCONVADæ–¹æ³•æ€§èƒ½ä¸Žç»å…¸æ–¹æ³•ç›¸å½“ï¼Œæä¾›æ›´ä¸°å¯Œæ¦‚å¿µé©±åŠ¨è§£é‡Šï¼Œå¢žå¼ºå¯è§£é‡Šæ€§å’Œä¿¡ä»»

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In recent years, Visual Anomaly Detection (VAD) has gained significant attention due to its ability to identify anomalous images using only normal images during training. Many VAD models work without supervision but are still able to provide visual explanations by highlighting the anomalous regions within an image. However, although these visual explanations can be helpful, they lack a direct and semantically meaningful interpretation for users. To address this limitation, we propose extending Concept Bottleneck Models (CBMs) to the VAD setting. By learning meaningful concepts, the network can provide human-interpretable descriptions of anomalies, offering a novel and more insightful way to explain them. Our contributions are threefold: (i) we develop a Concept Dataset to support research on CBMs for VAD; (ii) we improve the CBM architecture to generate both concept-based and visual explanations, bridging semantic and localization interpretability; and (iii) we introduce a pipeline for synthesizing artificial anomalies, preserving the VAD paradigm of minimizing dependence on rare anomalous samples. Our approach, Concept-Aware Visual Anomaly Detection (CONVAD), achieves performance comparable to classic VAD methods while providing richer, concept-driven explanations that enhance interpretability and trust in VAD systems.

