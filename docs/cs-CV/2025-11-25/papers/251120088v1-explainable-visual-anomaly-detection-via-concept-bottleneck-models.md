---
layout: default
title: Explainable Visual Anomaly Detection via Concept Bottleneck Models
---

# Explainable Visual Anomaly Detection via Concept Bottleneck Models

**arXiv**: [2511.20088v1](https://arxiv.org/abs/2511.20088) | [PDF](https://arxiv.org/pdf/2511.20088.pdf)

**ä½œè€…**: Arianna Stropeni, Valentina Zaccaria, Francesco Borsatti, Davide Dalle Pezze, Manuel Barusco, Gian Antonio Susto

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæ¦‚å¿µç“¶é¢ˆæ¨¡åž‹çš„å¯è§£é‡Šè§†è§‰å¼‚å¸¸æ£€æµ‹æ–¹æ³•CONVAD**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è§†è§‰å¼‚å¸¸æ£€æµ‹` `å¯è§£é‡Šæ€§` `æ¦‚å¿µç“¶é¢ˆæ¨¡åž‹` `å¼‚å¸¸è§£é‡Š` `äººå·¥å¼‚å¸¸åˆæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†è§‰å¼‚å¸¸æ£€æµ‹æ–¹æ³•ç¼ºä¹è¯­ä¹‰å±‚é¢çš„å¯è§£é‡Šæ€§ï¼Œéš¾ä»¥æä¾›å¯¹å¼‚å¸¸åŽŸå› çš„ç›´è§‚ç†è§£ã€‚
2. è®ºæ–‡æå‡ºCONVADï¼Œå°†æ¦‚å¿µç“¶é¢ˆæ¨¡åž‹å¼•å…¥è§†è§‰å¼‚å¸¸æ£€æµ‹ï¼Œå­¦ä¹ å¯è§£é‡Šçš„æ¦‚å¿µè¡¨ç¤ºï¼Œæä¾›æ¦‚å¿µé©±åŠ¨çš„å¼‚å¸¸è§£é‡Šã€‚
3. CONVADåœ¨æ€§èƒ½ä¸Šä¸Žä¼ ç»ŸVADæ–¹æ³•ç›¸å½“ï¼ŒåŒæ—¶æä¾›äº†æ›´ä¸°å¯Œçš„ã€åŸºäºŽæ¦‚å¿µçš„è§£é‡Šï¼Œæå‡äº†å¯è§£é‡Šæ€§å’Œä¿¡ä»»åº¦ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè§†è§‰å¼‚å¸¸æ£€æµ‹ï¼ˆVADï¼‰å› å…¶ä»…ä½¿ç”¨æ­£å¸¸å›¾åƒè¿›è¡Œè®­ç»ƒå³å¯è¯†åˆ«å¼‚å¸¸å›¾åƒçš„èƒ½åŠ›è€Œå¤‡å—å…³æ³¨ã€‚è®¸å¤šVADæ¨¡åž‹åœ¨æ— ç›‘ç£çš„æƒ…å†µä¸‹å·¥ä½œï¼Œä½†ä»èƒ½é€šè¿‡çªå‡ºæ˜¾ç¤ºå›¾åƒä¸­çš„å¼‚å¸¸åŒºåŸŸæ¥æä¾›è§†è§‰è§£é‡Šã€‚ç„¶è€Œï¼Œå°½ç®¡è¿™äº›è§†è§‰è§£é‡Šå¯èƒ½æœ‰æ‰€å¸®åŠ©ï¼Œä½†å®ƒä»¬ç¼ºä¹å¯¹ç”¨æˆ·è€Œè¨€ç›´æŽ¥ä¸”å…·æœ‰è¯­ä¹‰æ„ä¹‰çš„è§£é‡Šã€‚ä¸ºäº†è§£å†³è¿™ä¸ªå±€é™æ€§ï¼Œæˆ‘ä»¬å»ºè®®å°†æ¦‚å¿µç“¶é¢ˆæ¨¡åž‹ï¼ˆCBMï¼‰æ‰©å±•åˆ°VADè®¾ç½®ä¸­ã€‚é€šè¿‡å­¦ä¹ æœ‰æ„ä¹‰çš„æ¦‚å¿µï¼Œç½‘ç»œå¯ä»¥æä¾›äººç±»å¯è§£é‡Šçš„å¼‚å¸¸æè¿°ï¼Œä»Žè€Œæä¾›ä¸€ç§æ–°é¢–ä¸”æ›´å…·æ´žå¯ŸåŠ›çš„æ–¹å¼æ¥è§£é‡Šå®ƒä»¬ã€‚æˆ‘ä»¬çš„è´¡çŒ®æœ‰ä¸‰æ–¹é¢ï¼šï¼ˆiï¼‰æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªæ¦‚å¿µæ•°æ®é›†ï¼Œä»¥æ”¯æŒCBMåœ¨VADä¸­çš„ç ”ç©¶ï¼›ï¼ˆiiï¼‰æˆ‘ä»¬æ”¹è¿›äº†CBMæž¶æž„ï¼Œä»¥ç”ŸæˆåŸºäºŽæ¦‚å¿µçš„å’Œè§†è§‰çš„è§£é‡Šï¼Œä»Žè€Œå¼¥åˆè¯­ä¹‰å’Œå®šä½å¯è§£é‡Šæ€§ï¼›ï¼ˆiiiï¼‰æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åˆæˆäººå·¥å¼‚å¸¸çš„æµç¨‹ï¼Œä¿ç•™äº†VADèŒƒä¾‹ï¼Œå³æœ€å¤§é™åº¦åœ°å‡å°‘å¯¹ç½•è§å¼‚å¸¸æ ·æœ¬çš„ä¾èµ–ã€‚æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå³æ¦‚å¿µæ„ŸçŸ¥è§†è§‰å¼‚å¸¸æ£€æµ‹ï¼ˆCONVADï¼‰ï¼Œåœ¨æä¾›æ›´ä¸°å¯Œçš„ã€æ¦‚å¿µé©±åŠ¨çš„è§£é‡Šçš„åŒæ—¶ï¼Œå®žçŽ°äº†ä¸Žç»å…¸VADæ–¹æ³•ç›¸å½“çš„æ€§èƒ½ï¼Œä»Žè€Œå¢žå¼ºäº†VADç³»ç»Ÿçš„å¯è§£é‡Šæ€§å’Œä¿¡ä»»åº¦ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†è§‰å¼‚å¸¸æ£€æµ‹æ—¨åœ¨è¯†åˆ«ä¸Žè®­ç»ƒé›†ä¸­æ­£å¸¸æ•°æ®åˆ†å¸ƒä¸åŒçš„å›¾åƒæˆ–å›¾åƒåŒºåŸŸã€‚çŽ°æœ‰æ–¹æ³•è™½ç„¶èƒ½å¤Ÿå®šä½å¼‚å¸¸åŒºåŸŸï¼Œä½†ç¼ºä¹å¯¹å¼‚å¸¸åŽŸå› çš„è¯­ä¹‰è§£é‡Šï¼Œç”¨æˆ·éš¾ä»¥ç†è§£æ¨¡åž‹åˆ¤æ–­çš„ä¾æ®ã€‚è¿™é™åˆ¶äº†VADç³»ç»Ÿåœ¨å®‰å…¨å…³é”®é¢†åŸŸçš„åº”ç”¨ï¼Œå› ä¸ºç”¨æˆ·éœ€è¦ä¿¡ä»»å¹¶ç†è§£æ¨¡åž‹çš„å†³ç­–è¿‡ç¨‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ¦‚å¿µç“¶é¢ˆæ¨¡åž‹ï¼ˆCBMï¼‰å¼•å…¥VADä»»åŠ¡ã€‚CBMé€šè¿‡å­¦ä¹ ä¸€ç»„é¢„å®šä¹‰çš„ã€äººç±»å¯ç†è§£çš„æ¦‚å¿µæ¥è¡¨ç¤ºè¾“å…¥æ•°æ®ï¼Œä»Žè€Œå®žçŽ°æ¨¡åž‹å†³ç­–çš„å¯è§£é‡Šæ€§ã€‚åœ¨VADä¸­ï¼ŒCBMå¯ä»¥å­¦ä¹ æ­£å¸¸å›¾åƒçš„æ¦‚å¿µè¡¨ç¤ºï¼Œå¹¶åˆ©ç”¨è¿™äº›æ¦‚å¿µæ¥æ£€æµ‹å’Œè§£é‡Šå¼‚å¸¸ã€‚å¦‚æžœå›¾åƒä¸­æŸäº›æ¦‚å¿µçš„æ¿€æ´»ä¸Žæ­£å¸¸å›¾åƒçš„åˆ†å¸ƒæ˜¾è‘—ä¸åŒï¼Œåˆ™å¯ä»¥å°†å…¶åˆ¤å®šä¸ºå¼‚å¸¸ï¼Œå¹¶æ ¹æ®æ¿€æ´»å¼‚å¸¸çš„æ¦‚å¿µæ¥è§£é‡Šå¼‚å¸¸åŽŸå› ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šCONVADçš„æ•´ä½“æ¡†æž¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) **æ¦‚å¿µç¼–ç å™¨**ï¼šå°†è¾“å…¥å›¾åƒç¼–ç ä¸ºä¸€ç»„æ¦‚å¿µçš„æ¿€æ´»å€¼ã€‚2) **å¼‚å¸¸æ£€æµ‹å™¨**ï¼šåŸºäºŽæ¦‚å¿µæ¿€æ´»å€¼åˆ¤æ–­å›¾åƒæ˜¯å¦ä¸ºå¼‚å¸¸ã€‚3) **è§†è§‰è§£é‡Šå™¨**ï¼šç”Ÿæˆå¼‚å¸¸åŒºåŸŸçš„è§†è§‰è§£é‡Šï¼Œä¾‹å¦‚å¼‚å¸¸çƒ­å›¾ã€‚4) **æ¦‚å¿µæ•°æ®é›†**ï¼šç”¨äºŽè®­ç»ƒæ¦‚å¿µç¼–ç å™¨ï¼ŒåŒ…å«å¸¦æœ‰æ¦‚å¿µæ ‡æ³¨çš„å›¾åƒã€‚è®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§äººå·¥å¼‚å¸¸åˆæˆæµç¨‹ï¼Œç”¨äºŽåœ¨ç¼ºä¹çœŸå®žå¼‚å¸¸æ ·æœ¬çš„æƒ…å†µä¸‹è®­ç»ƒVADæ¨¡åž‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šCONVADçš„å…³é”®åˆ›æ–°åœ¨äºŽå°†æ¦‚å¿µç“¶é¢ˆæ¨¡åž‹åº”ç”¨äºŽè§†è§‰å¼‚å¸¸æ£€æµ‹ï¼Œä»Žè€Œå®žçŽ°äº†æ¦‚å¿µé©±åŠ¨çš„å¯è§£é‡Šæ€§ã€‚ä¸Žä¼ ç»Ÿçš„VADæ–¹æ³•ç›¸æ¯”ï¼ŒCONVADä¸ä»…å¯ä»¥å®šä½å¼‚å¸¸åŒºåŸŸï¼Œè¿˜å¯ä»¥æä¾›å¯¹å¼‚å¸¸åŽŸå› çš„è¯­ä¹‰è§£é‡Šï¼Œä¾‹å¦‚â€œè¯¥å›¾åƒè¢«åˆ¤å®šä¸ºå¼‚å¸¸ï¼Œå› ä¸ºç¼ºå°‘â€™è½¦è½®â€™æ¦‚å¿µâ€ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ä¸ªç”¨äºŽCBM-VADç ”ç©¶çš„æ¦‚å¿µæ•°æ®é›†å’Œä¸€ä¸ªäººå·¥å¼‚å¸¸åˆæˆæµç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šCONVADçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) **æ¦‚å¿µç¼–ç å™¨çš„é€‰æ‹©**ï¼šå¯ä»¥ä½¿ç”¨å„ç§ç¥žç»ç½‘ç»œæž¶æž„ï¼Œä¾‹å¦‚å·ç§¯ç¥žç»ç½‘ç»œæˆ–Transformerã€‚2) **æ¦‚å¿µæŸå¤±å‡½æ•°**ï¼šç”¨äºŽè®­ç»ƒæ¦‚å¿µç¼–ç å™¨ï¼Œé¼“åŠ±å…¶å­¦ä¹ æœ‰æ„ä¹‰çš„æ¦‚å¿µè¡¨ç¤ºã€‚3) **å¼‚å¸¸è¯„åˆ†å‡½æ•°**ï¼šåŸºäºŽæ¦‚å¿µæ¿€æ´»å€¼è®¡ç®—å›¾åƒçš„å¼‚å¸¸åˆ†æ•°ã€‚4) **äººå·¥å¼‚å¸¸åˆæˆç­–ç•¥**ï¼šç”¨äºŽç”Ÿæˆå…·æœ‰ä¸åŒç±»åž‹å¼‚å¸¸çš„äººå·¥å›¾åƒï¼Œä¾‹å¦‚æ·»åŠ å™ªå£°ã€é®æŒ¡æˆ–æ”¹å˜å›¾åƒçš„æŸäº›å±žæ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

CONVADåœ¨å¤šä¸ªè§†è§‰å¼‚å¸¸æ£€æµ‹æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æžœè¡¨æ˜Žï¼ŒCONVADåœ¨æä¾›æ›´ä¸°å¯Œçš„ã€æ¦‚å¿µé©±åŠ¨çš„è§£é‡Šçš„åŒæ—¶ï¼Œå®žçŽ°äº†ä¸Žç»å…¸VADæ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨MVTec ADæ•°æ®é›†ä¸Šï¼ŒCONVADçš„AUROCæŒ‡æ ‡ä¸Žä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ç•¥æœ‰ä¸‹é™ï¼Œä½†æä¾›äº†æ›´å…·å¯è§£é‡Šæ€§çš„å¼‚å¸¸è§£é‡Šã€‚æ­¤å¤–ï¼Œäººå·¥å¼‚å¸¸åˆæˆæµç¨‹æœ‰æ•ˆåœ°æé«˜äº†CONVADåœ¨ç¼ºä¹çœŸå®žå¼‚å¸¸æ ·æœ¬æ—¶çš„æ€§èƒ½ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

CONVADå¯åº”ç”¨äºŽå„ç§éœ€è¦å¯è§£é‡Šå¼‚å¸¸æ£€æµ‹çš„åœºæ™¯ï¼Œä¾‹å¦‚å·¥ä¸šè´¨æ£€ã€åŒ»ç–—å½±åƒåˆ†æžã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚åœ¨å·¥ä¸šè´¨æ£€ä¸­ï¼ŒCONVADå¯ä»¥æ£€æµ‹äº§å“ç¼ºé™·å¹¶è§£é‡Šç¼ºé™·åŽŸå› ï¼Œå¸®åŠ©å·¥ç¨‹å¸ˆæ”¹è¿›ç”Ÿäº§æµç¨‹ã€‚åœ¨åŒ»ç–—å½±åƒåˆ†æžä¸­ï¼ŒCONVADå¯ä»¥è¾…åŠ©åŒ»ç”Ÿè¯Šæ–­ç–¾ç—…å¹¶è§£é‡Šè¯Šæ–­ä¾æ®ï¼Œæé«˜è¯Šæ–­æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼ŒCONVADå¯ä»¥æ£€æµ‹å¼‚å¸¸äº¤é€šçŠ¶å†µå¹¶è§£é‡Šå¼‚å¸¸åŽŸå› ï¼Œæé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In recent years, Visual Anomaly Detection (VAD) has gained significant attention due to its ability to identify anomalous images using only normal images during training. Many VAD models work without supervision but are still able to provide visual explanations by highlighting the anomalous regions within an image. However, although these visual explanations can be helpful, they lack a direct and semantically meaningful interpretation for users. To address this limitation, we propose extending Concept Bottleneck Models (CBMs) to the VAD setting. By learning meaningful concepts, the network can provide human-interpretable descriptions of anomalies, offering a novel and more insightful way to explain them. Our contributions are threefold: (i) we develop a Concept Dataset to support research on CBMs for VAD; (ii) we improve the CBM architecture to generate both concept-based and visual explanations, bridging semantic and localization interpretability; and (iii) we introduce a pipeline for synthesizing artificial anomalies, preserving the VAD paradigm of minimizing dependence on rare anomalous samples. Our approach, Concept-Aware Visual Anomaly Detection (CONVAD), achieves performance comparable to classic VAD methods while providing richer, concept-driven explanations that enhance interpretability and trust in VAD systems.

