---
layout: default
title: VGGTFace: Topologically Consistent Facial Geometry Reconstruction in the Wild
---

# VGGTFace: Topologically Consistent Facial Geometry Reconstruction in the Wild

**arXiv**: [2511.20366v1](https://arxiv.org/abs/2511.20366) | [PDF](https://arxiv.org/pdf/2511.20366.pdf)

**ä½œè€…**: Xin Ming, Yuxuan Han, Tianyu Huang, Feng Xu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVGGTFaceä»¥ä»Žæ—¥å¸¸å¤šè§†è§’å›¾åƒè‡ªåŠ¨é‡å»ºæ‹“æ‰‘ä¸€è‡´çš„é¢éƒ¨å‡ ä½•**

**å…³é”®è¯**: `é¢éƒ¨å‡ ä½•é‡å»º` `æ‹“æ‰‘ä¸€è‡´æ€§` `3DåŸºç¡€æ¨¡åž‹` `å¤šè§†è§’å›¾åƒ` `æŸè°ƒæ•´`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•éœ€æ‰‹åŠ¨æ“ä½œã€æ³›åŒ–æ€§å·®æˆ–å—é™äºŽ3Då½¢å˜æ¨¡åž‹è¡¨è¾¾èƒ½åŠ›
2. ç»“åˆVGGTå’ŒPixel3DMMæ³¨å…¥æ‹“æ‰‘ä¿¡æ¯ï¼Œå¹¶é€šè¿‡æ‹“æ‰‘æ„ŸçŸ¥æŸè°ƒæ•´èžåˆç‚¹äº‘
3. åœ¨16è§†å›¾ä¸‹10ç§’å†…é«˜è´¨é‡é‡å»ºï¼ŒåŸºå‡†æµ‹è¯•å’Œé‡Žå¤–æ•°æ®æ³›åŒ–è¡¨çŽ°ä¼˜å¼‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reconstructing topologically consistent facial geometry is crucial for the digital avatar creation pipelines. Existing methods either require tedious manual efforts, lack generalization to in-the-wild data, or are constrained by the limited expressiveness of 3D Morphable Models. To address these limitations, we propose VGGTFace, an automatic approach that innovatively applies the 3D foundation model, \emph{i.e.} VGGT, for topologically consistent facial geometry reconstruction from in-the-wild multi-view images captured by everyday users. Our key insight is that, by leveraging VGGT, our method naturally inherits strong generalization ability and expressive power from its large-scale training and point map representation. However, it is unclear how to reconstruct a topologically consistent mesh from VGGT, as the topology information is missing in its prediction. To this end, we augment VGGT with Pixel3DMM for injecting topology information via pixel-aligned UV values. In this manner, we convert the pixel-aligned point map of VGGT to a point cloud with topology. Tailored to this point cloud with known topology, we propose a novel Topology-Aware Bundle Adjustment strategy to fuse them, where we construct a Laplacian energy for the Bundle Adjustment objective. Our method achieves high-quality reconstruction in 10 seconds for 16 views on a single NVIDIA RTX 4090. Experiments demonstrate state-of-the-art results on benchmarks and impressive generalization to in-the-wild data. Code is available at https://github.com/grignarder/vggtface.

