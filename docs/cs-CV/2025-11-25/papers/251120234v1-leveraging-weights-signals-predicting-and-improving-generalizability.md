---
layout: default
title: Leveraging weights signals - Predicting and improving generalizability in reinforcement learning
---

# Leveraging weights signals - Predicting and improving generalizability in reinforcement learning

**arXiv**: [2511.20234v1](https://arxiv.org/abs/2511.20234) | [PDF](https://arxiv.org/pdf/2511.20234.pdf)

**ä½œè€…**: Olivier Moulin, Vincent Francois-lavet, Paul Elbers, Mark Hoogendoorn

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæƒé‡ä¿¡å·é¢„æµ‹å’Œä¼˜åŒ–å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“æ³›åŒ–æ€§çš„æ–¹æ³•**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `æ³›åŒ–æ€§é¢„æµ‹` `PPOç®—æ³•` `ç¥žç»ç½‘ç»œæƒé‡` `è¿‡æ‹Ÿåˆé—®é¢˜` `æŸå¤±å‡½æ•°ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“æ˜“è¿‡æ‹Ÿåˆè®­ç»ƒçŽ¯å¢ƒï¼Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨ç¥žç»ç½‘ç»œå†…éƒ¨æƒé‡é¢„æµ‹æ³›åŒ–åˆ†æ•°ï¼Œå¹¶æ”¹è¿›PPOæŸå¤±å‡½æ•°ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ”¹è¿›ç‰ˆPPOç®—æ³•åœ¨å®žéªŒä¸­æå‡äº†æ™ºèƒ½ä½“çš„æ³›åŒ–æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generalizability of Reinforcement Learning (RL) agents (ability to perform on environments different from the ones they have been trained on) is a key problem as agents have the tendency to overfit to their training environments. In order to address this problem and offer a solution to increase the generalizability of RL agents, we introduce a new methodology to predict the generalizability score of RL agents based on the internal weights of the agent's neural networks. Using this prediction capability, we propose some changes in the Proximal Policy Optimization (PPO) loss function to boost the generalization score of the agents trained with this upgraded version. Experimental results demonstrate that our improved PPO algorithm yields agents with stronger generalizability compared to the original version.

