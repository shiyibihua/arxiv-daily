---
layout: default
title: MAPS: Preserving Vision-Language Representations via Module-Wise Proximity Scheduling for Better Vision-Language-Action Generalization
---

# MAPS: Preserving Vision-Language Representations via Module-Wise Proximity Scheduling for Better Vision-Language-Action Generalization

**arXiv**: [2511.19878v1](https://arxiv.org/abs/2511.19878) | [PDF](https://arxiv.org/pdf/2511.19878.pdf)

**ä½œè€…**: Chengyue Huang, Mellon M. Zhang, Robert Azarcon, Glen Chou, Zsolt Kira

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¨¡å—é‚»è¿‘è°ƒåº¦ä»¥åœ¨è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹ä¸­ä¿ç•™é¢„è®­ç»ƒè¡¨ç¤ºå¹¶æå‡æ³›åŒ–èƒ½åŠ›**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `å¾®è°ƒæ¡†æž¶` `æ¨¡å—é‚»è¿‘è°ƒåº¦` `æ³›åŒ–èƒ½åŠ›` `é¢„è®­ç»ƒè¡¨ç¤ºä¿ç•™`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹å¾®è°ƒæ˜“ç ´åé¢„è®­ç»ƒè¡¨ç¤ºï¼ŒæŸå®³æ³›åŒ–èƒ½åŠ›
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æ¨¡å—é‚»è¿‘è°ƒåº¦çº¿æ€§æ”¾æ¾çº¦æŸï¼Œå¹³è¡¡ç¨³å®šæ€§å’Œçµæ´»æ€§
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†å’ŒçœŸå®žå¹³å°ä¸Šæå‡æ€§èƒ½ï¼Œæœ€é«˜è¾¾30%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models inherit strong priors from pretrained Vision-Language Models (VLMs), but naive fine-tuning often disrupts these representations and harms generalization. Existing fixes -- freezing modules or applying uniform regularization -- either overconstrain adaptation or ignore the differing roles of VLA components. We present MAPS (Module-Wise Proximity Scheduling), the first robust fine-tuning framework for VLAs. Through systematic analysis, we uncover an empirical order in which proximity constraints should be relaxed to balance stability and flexibility. MAPS linearly schedules this relaxation, enabling visual encoders to stay close to their pretrained priors while action-oriented language layers adapt more freely. MAPS introduces no additional parameters or data, and can be seamlessly integrated into existing VLAs. Across MiniVLA-VQ, MiniVLA-OFT, OpenVLA-OFT, and challenging benchmarks such as SimplerEnv, CALVIN, LIBERO, as well as real-world evaluations on the Franka Emika Panda platform, MAPS consistently boosts both in-distribution and out-of-distribution performance (up to +30%). Our findings highlight empirically guided proximity to pretrained VLMs as a simple yet powerful principle for preserving broad generalization in VLM-to-VLA transfer.

