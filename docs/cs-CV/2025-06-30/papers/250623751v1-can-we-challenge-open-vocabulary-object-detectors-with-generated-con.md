---
layout: default
title: Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?
---

# Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23751" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23751v1</a>
  <a href="https://arxiv.org/pdf/2506.23751.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23751v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23751v1', 'Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Annika MÃ¼tze, Sadia Ilyas, Christian DÃ¶rpelkus, Matthias Rottmann

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨ç”Ÿæˆå†…å®¹æŒ‘æˆ˜å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨çš„å±€é™æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¼€æ”¾è¯æ±‡æ£€æµ‹` `åˆæˆæ•°æ®` `ç‰©ä½“æ£€æµ‹` `æ¨¡å‹æ³›åŒ–` `å®‰å…¨å…³é”®åº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨åœ¨çœŸå®åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶å±€é™æ€§å°šä¸æ˜ç¡®ï¼Œå°¤å…¶åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­ã€‚
2. æœ¬æ–‡æå‡ºåˆ©ç”¨åˆæˆç”Ÿæˆçš„æ•°æ®ï¼Œé€šè¿‡ç¨³å®šæ‰©æ•£æŠ€æœ¯å¡«å……ä¸å¯»å¸¸ç‰©ä½“ï¼Œä»¥ç³»ç»Ÿæ€§åœ°æŒ‘æˆ˜å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¼€æ”¾è¯æ±‡æ¨¡å‹åœ¨ç‰©ä½“ä½ç½®ä¸Šè¡¨ç°å‡ºå¼ºä¾èµ–æ€§ï¼Œå¡«å……æŠ€æœ¯èƒ½å¤Ÿæœ‰æ•ˆæŒ‘æˆ˜è¿™äº›æ¨¡å‹çš„æ£€æµ‹èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨å¦‚Grounding DINOåœ¨å¤šæ ·åŒ–æ•°æ®ä¸Šè®­ç»ƒï¼Œè¡¨ç°å‡ºè‰²ï¼Œä½†å…¶å±€é™æ€§å°šä¸æ˜ç¡®ï¼Œå°¤å…¶åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­ã€‚çœŸå®æ•°æ®æ— æ³•æä¾›è¶³å¤Ÿçš„æ§åˆ¶æ¥è¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œè€Œåˆæˆæ•°æ®åˆ™èƒ½ç³»ç»Ÿæ€§åœ°æ¢ç´¢æ¨¡å‹çš„èƒ½åŠ›è¾¹ç•Œã€‚æœ¬æ–‡è®¾è®¡äº†ä¸¤ä¸ªè‡ªåŠ¨åŒ–ç®¡é“ï¼Œåˆ©ç”¨ç¨³å®šæ‰©æ•£æŠ€æœ¯å¯¹ä¸å¯»å¸¸çš„ç‰©ä½“è¿›è¡Œå¡«å……ï¼Œå¹¶åœ¨åˆæˆæ•°æ®ä¸Šè¯„ä¼°å¤šç§å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨ï¼Œå‘ç°è¿™äº›æ¨¡å‹åœ¨ç‰©ä½“ä½ç½®ä¸Šè¡¨ç°å‡ºå¼ºä¾èµ–æ€§ï¼Œè€Œéç‰©ä½“è¯­ä¹‰ã€‚è¿™ä¸ºæŒ‘æˆ˜å¼€æ”¾è¯æ±‡æ¨¡å‹æä¾›äº†ç³»ç»Ÿæ€§çš„æ–¹æ³•ï¼Œå¹¶ä¸ºå¦‚ä½•æœ‰æ•ˆæ”¹è¿›è¿™äº›æ¨¡å‹æä¾›äº†å®è´µçš„è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨åœ¨åˆæˆç”Ÿæˆå†…å®¹ä¸‹çš„è¡¨ç°åŠå…¶å±€é™æ€§ã€‚ç°æœ‰æ–¹æ³•åœ¨çœŸå®æ•°æ®ä¸Šè¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›æ—¶ç¼ºä¹æ§åˆ¶ï¼Œå¯¼è‡´éš¾ä»¥å‘ç°æ¨¡å‹çš„æ½œåœ¨å¤±è´¥æ¨¡å¼ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åˆæˆç”Ÿæˆçš„æ•°æ®ï¼Œåˆ©ç”¨ç¨³å®šæ‰©æ•£æŠ€æœ¯å¯¹ä¸å¯»å¸¸çš„ç‰©ä½“è¿›è¡Œå¡«å……ï¼Œç³»ç»Ÿæ€§åœ°æŒ‘æˆ˜å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨çš„èƒ½åŠ›ã€‚æ­¤è®¾è®¡æ—¨åœ¨æ­ç¤ºæ¨¡å‹åœ¨ç‰¹å®šæ¡ä»¶ä¸‹çš„è¡¨ç°åŠå…¶å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶è®¾è®¡äº†ä¸¤ä¸ªè‡ªåŠ¨åŒ–ç®¡é“ï¼Œé¦–å…ˆä»WordNetå’ŒChatGPTä¸­é‡‡æ ·å¤šä¸ªåè¯ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„åˆæˆå›¾åƒï¼Œç„¶åå°†è¿™äº›å›¾åƒä¸å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨è¿›è¡Œæ¯”è¾ƒè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨åˆæˆç”Ÿæˆçš„æ•°æ®ç³»ç»Ÿæ€§åœ°æŒ‘æˆ˜å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨ï¼Œæ­ç¤ºå…¶å¯¹ç‰©ä½“ä½ç½®çš„å¼ºä¾èµ–æ€§ï¼Œè€Œéä»…ä»…ä¾èµ–ç‰©ä½“çš„è¯­ä¹‰ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†ç¨³å®šæ‰©æ•£æŠ€æœ¯è¿›è¡Œå›¾åƒå¡«å……ï¼Œç¡®ä¿ç”Ÿæˆçš„ç‰©ä½“å…·æœ‰é«˜è¯­ä¹‰å¤šæ ·æ€§ã€‚åŒæ—¶ï¼Œè¯„ä¼°äº†å¤šç§å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨ä¸ä¼ ç»Ÿæ£€æµ‹å™¨çš„æ€§èƒ½å·®å¼‚ï¼Œæä¾›äº†å…¨é¢çš„æ¯”è¾ƒåˆ†æã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨åœ¨åˆæˆç”Ÿæˆçš„å›¾åƒä¸Šè¡¨ç°å‡ºæ˜æ˜¾çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ç‰©ä½“ä½ç½®çš„ä¾èµ–æ€§æ–¹é¢ã€‚ç›¸æ¯”ä¼ ç»Ÿæ£€æµ‹å™¨ï¼Œå¼€æ”¾è¯æ±‡æ¨¡å‹åœ¨ç‰¹å®šæ¡ä»¶ä¸‹çš„æ£€æµ‹èƒ½åŠ›æ˜¾è‘—ä¸‹é™ï¼Œæä¾›äº†å¯¹æ¨¡å‹æ”¹è¿›çš„æ–¹å‘å’Œä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§å’Œæœºå™¨äººè§†è§‰ç­‰å®‰å…¨å…³é”®åœºæ™¯ã€‚é€šè¿‡è¯†åˆ«å’Œæ”¹è¿›å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨çš„å±€é™æ€§ï¼Œå¯ä»¥æé«˜è¿™äº›ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¯é æ€§å’Œå®‰å…¨æ€§ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Open-vocabulary object detectors such as Grounding DINO are trained on vast and diverse data, achieving remarkable performance on challenging datasets. Due to that, it is unclear where to find their limitations, which is of major concern when using in safety-critical applications. Real-world data does not provide sufficient control, required for a rigorous evaluation of model generalization. In contrast, synthetically generated data allows to systematically explore the boundaries of model competence/generalization. In this work, we address two research questions: 1) Can we challenge open-vocabulary object detectors with generated image content? 2) Can we find systematic failure modes of those models? To address these questions, we design two automated pipelines using stable diffusion to inpaint unusual objects with high diversity in semantics, by sampling multiple substantives from WordNet and ChatGPT. On the synthetically generated data, we evaluate and compare multiple open-vocabulary object detectors as well as a classical object detector. The synthetic data is derived from two real-world datasets, namely LostAndFound, a challenging out-of-distribution (OOD) detection benchmark, and the NuImages dataset. Our results indicate that inpainting can challenge open-vocabulary object detectors in terms of overlooking objects. Additionally, we find a strong dependence of open-vocabulary models on object location, rather than on object semantics. This provides a systematic approach to challenge open-vocabulary models and gives valuable insights on how data could be acquired to effectively improve these models.

