---
layout: default
title: VOCAL: Visual Odometry via ContrAstive Learning
---

# VOCAL: Visual Odometry via ContrAstive Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.00243" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.00243v1</a>
  <a href="https://arxiv.org/pdf/2507.00243.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.00243v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.00243v1', 'VOCAL: Visual Odometry via ContrAstive Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chi-Yao Huang, Zeel Bhatt, Yezhou Yang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVOCALæ¡†æ¶ä»¥è§£å†³è§†è§‰é‡Œç¨‹è®¡çš„å¯è§£é‡Šæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰é‡Œç¨‹è®¡` `å¯¹æ¯”å­¦ä¹ ` `è´å¶æ–¯æ¨æ–­` `ç‰¹å¾è¡¨ç¤º` `å¤šæ¨¡æ€æ•°æ®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å­¦ä¹ å‹è§†è§‰é‡Œç¨‹è®¡æ–¹æ³•å¾€å¾€ä¾èµ–äºåˆšæ€§å‡ ä½•å‡è®¾ï¼Œå¯¼è‡´å¯è§£é‡Šæ€§ä¸è¶³å’Œç†è®ºåŸºç¡€è–„å¼±ã€‚
2. æœ¬æ–‡æå‡ºçš„VOCALæ¡†æ¶å°†è§†è§‰é‡Œç¨‹è®¡è§†ä¸ºæ ‡ç­¾æ’åºé—®é¢˜ï¼Œé€šè¿‡è´å¶æ–¯æ¨æ–­å’Œè¡¨ç¤ºå­¦ä¹ ç›¸ç»“åˆï¼Œæå‡äº†ç‰¹å¾çš„å¯è§£é‡Šæ€§ã€‚
3. åœ¨KITTIæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒVOCALåœ¨å¯è§£é‡Šæ€§å’Œçµæ´»æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ¨åŠ¨äº†è§†è§‰é‡Œç¨‹è®¡çš„è¿›æ­¥ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰é‡Œç¨‹è®¡ï¼ˆVOï¼‰çš„çªç ´æ€§è¿›å±•åœ¨æœºå™¨äººé¢†åŸŸä¸­å‘æŒ¥äº†é‡è¦ä½œç”¨ï¼Œæå‡äº†ç°ä»£è‡ªä¸»ç³»ç»Ÿçš„ç›¸æœºçŠ¶æ€ä¼°è®¡ç²¾åº¦ã€‚ç„¶è€Œï¼Œè®¸å¤šåŸºäºå­¦ä¹ çš„VOæŠ€æœ¯ä¾èµ–äºåˆšæ€§å‡ ä½•å‡è®¾ï¼Œå¯¼è‡´å…¶å¯è§£é‡Šæ€§ä¸è¶³ä¸”ç¼ºä¹åšå®çš„ç†è®ºåŸºç¡€ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†VOCALï¼ˆé€šè¿‡å¯¹æ¯”å­¦ä¹ çš„è§†è§‰é‡Œç¨‹è®¡ï¼‰æ¡†æ¶ï¼Œå°†VOé‡æ–°æ„æƒ³ä¸ºæ ‡ç­¾æ’åºæŒ‘æˆ˜ã€‚é€šè¿‡å°†è´å¶æ–¯æ¨æ–­ä¸è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ç›¸ç»“åˆï¼ŒVOCALç»„ç»‡è§†è§‰ç‰¹å¾ä»¥åæ˜ ç›¸æœºçŠ¶æ€ã€‚æ’åºæœºåˆ¶ä¿ƒä½¿ç›¸ä¼¼çš„ç›¸æœºçŠ¶æ€åœ¨æ½œåœ¨ç©ºé—´ä¸­æ”¶æ•›ä¸ºä¸€è‡´ä¸”ç©ºé—´ä¸Šè¿è´¯çš„è¡¨ç¤ºï¼Œä»è€Œå¢å¼ºäº†å­¦ä¹ ç‰¹å¾çš„å¯è§£é‡Šæ€§ï¼Œå¹¶ç¡®ä¿ä¸å¤šæ¨¡æ€æ•°æ®æºçš„å…¼å®¹æ€§ã€‚å¯¹KITTIæ•°æ®é›†çš„å¹¿æ³›è¯„ä¼°æ˜¾ç¤ºï¼ŒVOCALåœ¨å¯è§£é‡Šæ€§å’Œçµæ´»æ€§æ–¹é¢çš„æå‡ï¼Œæ¨åŠ¨äº†VOå‘æ›´é€šç”¨å’Œå¯è§£é‡Šçš„ç©ºé—´æ™ºèƒ½å‘å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è§†è§‰é‡Œç¨‹è®¡æ–¹æ³•åœ¨å¯è§£é‡Šæ€§å’Œç†è®ºåŸºç¡€æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯é‚£äº›ä¾èµ–äºåˆšæ€§å‡ ä½•å‡è®¾çš„å­¦ä¹ å‹æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVOCALæ¡†æ¶å°†è§†è§‰é‡Œç¨‹è®¡é‡æ–°å®šä¹‰ä¸ºæ ‡ç­¾æ’åºé—®é¢˜ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ æœºåˆ¶æ¥ç»„ç»‡è§†è§‰ç‰¹å¾ï¼Œä½¿å¾—ç›¸ä¼¼çš„ç›¸æœºçŠ¶æ€åœ¨æ½œåœ¨ç©ºé—´ä¸­å½¢æˆä¸€è‡´çš„è¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVOCALçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç‰¹å¾æå–æ¨¡å—ã€è´å¶æ–¯æ¨æ–­æ¨¡å—å’Œæ’åºæœºåˆ¶ã€‚ç‰¹å¾æå–æ¨¡å—è´Ÿè´£ä»è¾“å…¥å›¾åƒä¸­æå–è§†è§‰ç‰¹å¾ï¼Œè´å¶æ–¯æ¨æ–­æ¨¡å—ç”¨äºå¤„ç†ä¸ç¡®å®šæ€§ï¼Œè€Œæ’åºæœºåˆ¶åˆ™ç¡®ä¿ç›¸ä¼¼çŠ¶æ€çš„ç‰¹å¾åœ¨æ½œåœ¨ç©ºé—´ä¸­èšé›†ã€‚

**å…³é”®åˆ›æ–°**ï¼šVOCALçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†è§†è§‰é‡Œç¨‹è®¡è§†ä¸ºæ ‡ç­¾æ’åºé—®é¢˜ï¼Œå¹¶é€šè¿‡å¯¹æ¯”å­¦ä¹ å¢å¼ºäº†ç‰¹å¾çš„å¯è§£é‡Šæ€§å’Œä¸€è‡´æ€§ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å‡ ä½•å‡è®¾æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œæä¾›äº†æ›´çµæ´»çš„æ¡†æ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒVOCALé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç‰¹å¾çš„æ’åºï¼ŒåŒæ—¶ä½¿ç”¨äº†æ·±åº¦ç¥ç»ç½‘ç»œæ¶æ„æ¥æå–å’Œè¡¨ç¤ºè§†è§‰ç‰¹å¾ï¼Œç¡®ä¿äº†æ¨¡å‹çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨KITTIæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVOCALæ¡†æ¶åœ¨å¯è§£é‡Šæ€§å’Œçµæ´»æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒéªŒè¯äº†å…¶åœ¨è§†è§‰é‡Œç¨‹è®¡ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VOCALæ¡†æ¶åœ¨è‡ªä¸»å¯¼èˆªã€å¢å¼ºç°å®å’Œæœºå™¨äººè§†è§‰ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶å¢å¼ºçš„å¯è§£é‡Šæ€§å’Œçµæ´»æ€§ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚ç¯å¢ƒä¸­çš„å¤šæ¨¡æ€æ•°æ®ï¼Œä»è€Œæå‡è‡ªä¸»ç³»ç»Ÿçš„æ™ºèƒ½æ°´å¹³å’Œå†³ç­–èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Breakthroughs in visual odometry (VO) have fundamentally reshaped the landscape of robotics, enabling ultra-precise camera state estimation that is crucial for modern autonomous systems. Despite these advances, many learning-based VO techniques rely on rigid geometric assumptions, which often fall short in interpretability and lack a solid theoretical basis within fully data-driven frameworks. To overcome these limitations, we introduce VOCAL (Visual Odometry via ContrAstive Learning), a novel framework that reimagines VO as a label ranking challenge. By integrating Bayesian inference with a representation learning framework, VOCAL organizes visual features to mirror camera states. The ranking mechanism compels similar camera states to converge into consistent and spatially coherent representations within the latent space. This strategic alignment not only bolsters the interpretability of the learned features but also ensures compatibility with multimodal data sources. Extensive evaluations on the KITTI dataset highlight VOCAL's enhanced interpretability and flexibility, pushing VO toward more general and explainable spatial intelligence.

