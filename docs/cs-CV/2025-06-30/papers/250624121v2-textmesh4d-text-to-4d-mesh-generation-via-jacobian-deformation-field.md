---
layout: default
title: TextMesh4D: Text-to-4D Mesh Generation via Jacobian Deformation Field
---

# TextMesh4D: Text-to-4D Mesh Generation via Jacobian Deformation Field

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.24121" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.24121v2</a>
  <a href="https://arxiv.org/pdf/2506.24121.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.24121v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.24121v2', 'TextMesh4D: Text-to-4D Mesh Generation via Jacobian Deformation Field')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sisi Dai, Xinxin Su, Ruizhen Hu, Kai Xu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30 (æ›´æ–°: 2025-12-16)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTextMesh4Dä»¥è§£å†³åŠ¨æ€3Dç½‘æ ¼ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `åŠ¨æ€ç½‘æ ¼ç”Ÿæˆ` `æ–‡æœ¬åˆ°4D` `Jacobianå˜å½¢åœº` `è¯­ä¹‰ä¸€è‡´æ€§` `è®¡ç®—æœºå›¾å½¢å­¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–‡æœ¬åˆ°4Dç”Ÿæˆæ–¹æ³•åœ¨å‡ ä½•ä¿çœŸåº¦å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æ»¡è¶³ç°ä»£è®¡ç®—æœºå›¾å½¢éœ€æ±‚ã€‚
2. æœ¬æ–‡æå‡ºTextMesh4Dæ¡†æ¶ï¼Œé€šè¿‡Jacobianå˜å½¢åœºå’Œå±€éƒ¨-å…¨å±€è¯­ä¹‰æ­£åˆ™åŒ–å™¨ï¼Œè§£å†³äº†ç½‘æ ¼ç”Ÿæˆä¸­çš„å˜å½¢çµæ´»æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒTextMesh4Dåœ¨æ—¶é—´ä¸€è‡´æ€§ã€ç»“æ„ä¿çœŸåº¦å’Œè§†è§‰çœŸå®æ„Ÿæ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¸”è®­ç»ƒæ•ˆç‡é«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŠ¨æ€3Dï¼ˆ4Dï¼‰å†…å®¹ç”Ÿæˆï¼Œå°¤å…¶æ˜¯æ–‡æœ¬åˆ°4Dçš„è½¬æ¢ï¼Œå› å…¶å›ºæœ‰çš„æ—¶ç©ºå¤æ‚æ€§è€Œé¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰çš„æ–‡æœ¬åˆ°4Dæ–¹æ³•é€šå¸¸é¿å…ç›´æ¥ç”Ÿæˆç½‘æ ¼ï¼Œè½¬è€Œé‡‡ç”¨NeRFæˆ–3DGSç­‰æ›¿ä»£è¡¨ç¤ºæ³•ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨å‡ ä½•ä¿çœŸåº¦ã€æ—¶é—´ä¼ªå½±å’Œä¸ç°ä»£è®¡ç®—æœºå›¾å½¢ç®¡é“çš„å…¼å®¹æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚æœ¬æ–‡æå‡ºçš„TextMesh4Dæ¡†æ¶é€šè¿‡å¼•å…¥Jacobianå˜å½¢åœºï¼ˆJDFï¼‰å’Œå±€éƒ¨-å…¨å±€è¯­ä¹‰æ­£åˆ™åŒ–å™¨ï¼ˆLGSRï¼‰ï¼Œç›´æ¥è§£å†³äº†è¿™äº›é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†æ—¶é—´ä¸€è‡´æ€§ã€ç»“æ„ä¿çœŸåº¦å’Œè§†è§‰çœŸå®æ„Ÿï¼ŒåŒæ—¶ä»…éœ€ä¸€å°24GBçš„GPUè¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºé«˜æ•ˆä¸”é«˜è´¨é‡çš„æ–‡æœ¬åˆ°4Dç½‘æ ¼ç”Ÿæˆå»ºç«‹äº†æ–°çš„åŸºå‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŠ¨æ€4Dç½‘æ ¼ç”Ÿæˆä¸­çš„å˜å½¢çµæ´»æ€§ä¸è¶³å’Œè¯­ä¹‰ä¸€è‡´æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å› æ‹“æ‰‘çº¦æŸè€Œéš¾ä»¥ç›´æ¥ç”Ÿæˆé«˜è´¨é‡ç½‘æ ¼ï¼Œå¯¼è‡´å‡ ä½•ä¿çœŸåº¦ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTextMesh4Dé€šè¿‡Jacobianå˜å½¢åœºå°†å˜å½¢å•å…ƒä»é¡¶ç‚¹è½¬ç§»åˆ°é¢ï¼Œåˆ©ç”¨æ¯ä¸ªé¢çš„Jacobianæ¥å»ºæ¨¡çµæ´»çš„å˜æ¢ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•çš„æ‹“æ‰‘é™åˆ¶ã€‚åŒæ—¶ï¼Œå±€éƒ¨-å…¨å±€è¯­ä¹‰æ­£åˆ™åŒ–å™¨ç¡®ä¿äº†åœ¨æ—¶é—´åºåˆ—ä¸­çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTextMesh4Dçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šJacobianå˜å½¢åœºæ¨¡å—å’Œå±€éƒ¨-å…¨å±€è¯­ä¹‰æ­£åˆ™åŒ–æ¨¡å—ã€‚å‰è€…è´Ÿè´£ç”ŸæˆåŠ¨æ€ç½‘æ ¼ï¼Œåè€…åˆ™ç¡®ä¿ç”Ÿæˆå†…å®¹çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºJacobianå˜å½¢åœºçš„å¼•å…¥ï¼Œä½¿å¾—å˜å½¢è¿‡ç¨‹ä¸å†å—é™äºç½‘æ ¼çš„æ‹“æ‰‘ç»“æ„ï¼Œä»è€Œå®ç°æ›´çµæ´»çš„åŠ¨æ€ç½‘æ ¼ç”Ÿæˆã€‚å±€éƒ¨-å…¨å±€è¯­ä¹‰æ­£åˆ™åŒ–å™¨åˆ™å¢å¼ºäº†ç”Ÿæˆå†…å®¹çš„è¯­ä¹‰è¿è´¯æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡å‡ ä½•ä¿çœŸåº¦å’Œè¯­ä¹‰ä¸€è‡´æ€§ï¼ŒåŒæ—¶ç½‘ç»œç»“æ„è®¾è®¡ä¸Šé‡‡ç”¨äº†æ·±åº¦å­¦ä¹ æ¡†æ¶ä»¥æé«˜ç”Ÿæˆæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒTextMesh4Dåœ¨æ—¶é—´ä¸€è‡´æ€§ã€ç»“æ„ä¿çœŸåº¦å’Œè§†è§‰çœŸå®æ„Ÿæ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œä¸”è®­ç»ƒä»…éœ€ä¸€å°24GB GPUã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘ã€åŠ¨ç”»åˆ¶ä½œå’ŒåŒ»å­¦æˆåƒç­‰ã€‚é€šè¿‡é«˜æ•ˆç”ŸæˆåŠ¨æ€4Dç½‘æ ¼ï¼Œèƒ½å¤Ÿä¸ºè¿™äº›é¢†åŸŸæä¾›æ›´çœŸå®çš„è§†è§‰ä½“éªŒå’Œäº¤äº’æ•ˆæœï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Dynamic 3D (4D) content generation, particularly text-to-4D, remains a challenging and under-explored problem due to its inherent spatiotemporal complexity. Existing text-to-4D methods typically avoid direct mesh generation due to inherent topological constraints, favoring alternative representations like NeRFs or 3DGS. However, these non-mesh approaches, suffer from insufficient geometric fidelity, temporal artifacts, and limited compatibility with modern computer graphics (CG) pipelines. In contrast, directly generating dynamic meshes faces two key challenges: i) deformation inflexibility, as traditional vertex-based optimization is constrained by meshes' explicitly encoded topology, and ii) semantic inconsistency, arising from stochastic noise in distilled priors.
>   In this paper, we introduce TextMesh4D, a pioneering framework for text-to-4D mesh generation that directly addresses these challenges. TextMesh4D features two core innovations: 1) the Jacobian Deformation Field (JDF), which shifts the deformation unit from vertices to faces, using per-face Jacobians to model flexible transformations free from topological constraints. 2) the Local-Global Semantic Regularizer (LGSR), which leverages the mesh's innate geometric properties to enforce semantic coherence both locally and globally across frames. Extensive experiments demonstrate that TextMesh4D achieves state-of-the-art performance in temporal consistency, structural fidelity, and visual realism, while requiring only a single 24GB GPU. Our work establishes a new benchmark for efficient and high-quality text-to-4D mesh generation. The code will be released to facilitate future research.

