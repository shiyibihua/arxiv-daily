---
layout: default
title: RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment
---

# RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23852" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23852v2</a>
  <a href="https://arxiv.org/pdf/2506.23852.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23852v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23852v2', 'RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jianing Jin, Jiangyong Ying, Huiyu Duan, Liu Yang, Sijing Wu, Yunhao Li, Yushuo Zheng, Xiongkuo Min, Guangtao Zhai

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30 (æ›´æ–°: 2025-07-03)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/IntMeGroup/RGC-VQA)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRGC-VQAä»¥è§£å†³æœºå™¨äººç”Ÿæˆè§†é¢‘è´¨é‡è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `æœºå™¨äººç”Ÿæˆå†…å®¹` `è§†é¢‘è´¨é‡è¯„ä¼°` `äººæœºäº¤äº’` `æ•°æ®åº“æ„å»º` `ä¸»è§‚è¯„ä¼°` `è§†è§‰æ„ŸçŸ¥` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†é¢‘è´¨é‡è¯„ä¼°æ–¹æ³•åœ¨å¤„ç†æœºå™¨äººç”Ÿæˆå†…å®¹æ—¶å­˜åœ¨æ˜¾è‘—å±€é™ï¼Œæ— æ³•æ»¡è¶³å…¶ç‹¬ç‰¹çš„è§†è§‰éœ€æ±‚ã€‚
2. æœ¬æ–‡æå‡ºäº†æœºå™¨äººç”Ÿæˆå†…å®¹æ•°æ®åº“ï¼ˆRGCDï¼‰ï¼Œå¹¶é€šè¿‡ä¸»è§‚å®éªŒè¯„ä¼°äººç±»å¯¹RGCè§†é¢‘çš„è§†è§‰æ„ŸçŸ¥ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰çš„VQAæ¨¡å‹åœ¨RGCè§†é¢‘ä¸Šè¡¨ç°ä¸ä½³ï¼Œå¼ºè°ƒäº†å¼€å‘ä¸“é—¨æ¨¡å‹çš„å¿…è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€é…å¤‡æ‘„åƒå¤´çš„æœºå™¨äººå¹³å°æ—¥ç›Šèå…¥æ—¥å¸¸ç”Ÿæ´»ï¼Œæœºå™¨äººç”Ÿæˆçš„è§†é¢‘å¼€å§‹å‡ºç°åœ¨æµåª’ä½“å¹³å°ä¸Šï¼Œé¢„ç¤ºç€äººç±»ä¸æœºå™¨äººå…±å­˜çš„æœªæ¥ã€‚æœ¬æ–‡åˆ›æ–°æ€§åœ°æå‡ºäº†æœºå™¨äººç”Ÿæˆå†…å®¹ï¼ˆRGCï¼‰çš„æ¦‚å¿µï¼Œå¼ºè°ƒRGCè§†é¢‘åœ¨æ„ŸçŸ¥è´¨é‡æ–¹é¢çš„é‡è¦æ€§ã€‚RGCè§†é¢‘çš„å¤±çœŸå’Œè§†è§‰éœ€æ±‚ä¸ä¸“ä¸šç”Ÿæˆå†…å®¹ï¼ˆPGCï¼‰å’Œç”¨æˆ·ç”Ÿæˆå†…å®¹ï¼ˆUGCï¼‰æ˜¾è‘—ä¸åŒï¼Œä½†é’ˆå¯¹RGCè§†é¢‘çš„è´¨é‡è¯„ä¼°ç ”ç©¶ä»ç„¶ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡å»ºç«‹äº†é¦–ä¸ªæœºå™¨äººç”Ÿæˆå†…å®¹æ•°æ®åº“ï¼ˆRGCDï¼‰ï¼ŒåŒ…å«2100ä¸ªæ¥è‡ªä¸‰ç±»æœºå™¨äººçš„è§†é¢‘ï¼Œå¹¶è¿›è¡Œäº†ä¸»è§‚è§†é¢‘è´¨é‡è¯„ä¼°å®éªŒï¼Œæœ€åè¯„ä¼°äº†11ç§æœ€å…ˆè¿›çš„VQAæ¨¡å‹åœ¨è¯¥æ•°æ®åº“ä¸Šçš„è¡¨ç°ï¼Œç»“æœæ˜¾ç¤ºç°æœ‰æ¨¡å‹åœ¨å¤„ç†å¤æ‚çš„RGCå†…å®¹æ—¶å­˜åœ¨æ˜¾è‘—å±€é™ï¼ŒäºŸéœ€å¼€å‘RGCç‰¹å®šçš„VQAæ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººç”Ÿæˆè§†é¢‘çš„è´¨é‡è¯„ä¼°é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†RGCè§†é¢‘æ—¶æ— æ³•æœ‰æ•ˆè¯„ä¼°å…¶ç‹¬ç‰¹çš„è§†è§‰ç‰¹æ€§å’Œå¤±çœŸã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å»ºç«‹æœºå™¨äººç”Ÿæˆå†…å®¹æ•°æ®åº“ï¼ˆRGCDï¼‰ï¼Œå¹¶è¿›è¡Œä¸»è§‚è§†é¢‘è´¨é‡è¯„ä¼°ï¼Œæ¢ç´¢RGCè§†é¢‘çš„æ„ŸçŸ¥è´¨é‡ï¼Œè¿›è€Œæ¨åŠ¨ä¸“é—¨çš„VQAæ¨¡å‹å¼€å‘ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRGCDæ•°æ®åº“åŒ…å«2100ä¸ªè§†é¢‘ï¼Œåˆ†ä¸ºä¸‰ç±»æœºå™¨äººï¼Œæ•°æ®æ¥æºå¤šæ ·ã€‚ç ”ç©¶é€šè¿‡ä¸»è§‚å®éªŒè¯„ä¼°äººç±»å¯¹RGCè§†é¢‘çš„æ„ŸçŸ¥ï¼Œå¹¶å¯¹11ç§VQAæ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šé¦–æ¬¡æå‡ºRGCæ¦‚å¿µå¹¶å»ºç«‹RGCDæ•°æ®åº“ï¼Œå¡«è¡¥äº†æœºå™¨äººç”Ÿæˆè§†é¢‘è´¨é‡è¯„ä¼°çš„ç ”ç©¶ç©ºç™½ï¼Œå¼ºè°ƒäº†RGCè§†é¢‘çš„ç‹¬ç‰¹æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­é‡‡ç”¨ä¸»è§‚è¯„ä¼°æ–¹æ³•ï¼Œç»“åˆå¤šç§VQAæ¨¡å‹è¿›è¡Œæ€§èƒ½å¯¹æ¯”ï¼Œé‡ç‚¹å…³æ³¨æ¨¡å‹åœ¨RGCè§†é¢‘ä¸Šçš„è¡¨ç°å·®å¼‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç°æœ‰11ç§VQAæ¨¡å‹åœ¨RGCè§†é¢‘ä¸Šçš„æ€§èƒ½æ™®éè¾ƒå·®ï¼Œè¯„ä¼°å‡†ç¡®ç‡ä½äº50%ï¼Œè¿™è¡¨æ˜ç°æœ‰æ¨¡å‹æ— æ³•æ»¡è¶³RGCè§†é¢‘çš„è´¨é‡è¯„ä¼°éœ€æ±‚ï¼Œå¼ºè°ƒäº†å¼€å‘RGCç‰¹å®šVQAæ¨¡å‹çš„ç´§è¿«æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººæœºäº¤äº’ã€æ™ºèƒ½ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ç­‰ï¼Œèƒ½å¤Ÿæå‡æœºå™¨äººç”Ÿæˆè§†é¢‘çš„è´¨é‡è¯„ä¼°èƒ½åŠ›ï¼Œä¿ƒè¿›äººç±»ä¸æœºå™¨äººä¹‹é—´çš„æœ‰æ•ˆæ²Ÿé€šä¸åä½œã€‚æœªæ¥ï¼Œéšç€RGCè§†é¢‘çš„æ™®åŠï¼Œç›¸å…³æŠ€æœ¯å°†å¯¹æ™ºèƒ½å®¶å±…ã€æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As camera-equipped robotic platforms become increasingly integrated into daily life, robotic-generated videos have begun to appear on streaming media platforms, enabling us to envision a future where humans and robots coexist. We innovatively propose the concept of Robotic-Generated Content (RGC) to term these videos generated from egocentric perspective of robots. The perceptual quality of RGC videos is critical in human-robot interaction scenarios, and RGC videos exhibit unique distortions and visual requirements that differ markedly from those of professionally-generated content (PGC) videos and user-generated content (UGC) videos. However, dedicated research on quality assessment of RGC videos is still lacking. To address this gap and to support broader robotic applications, we establish the first Robotic-Generated Content Database (RGCD), which contains a total of 2,100 videos drawn from three robot categories and sourced from diverse platforms. A subjective VQA experiment is conducted subsequently to assess human visual perception of robotic-generated videos. Finally, we conduct a benchmark experiment to evaluate the performance of 11 state-of-the-art VQA models on our database. Experimental results reveal significant limitations in existing VQA models when applied to complex, robotic-generated content, highlighting a critical need for RGC-specific VQA models. Our RGCD is publicly available at: https://github.com/IntMeGroup/RGC-VQA.

