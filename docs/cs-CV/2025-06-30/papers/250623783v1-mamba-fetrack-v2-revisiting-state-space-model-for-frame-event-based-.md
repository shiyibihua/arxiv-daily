---
layout: default
title: Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking
---

# Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23783" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23783v1</a>
  <a href="https://arxiv.org/pdf/2506.23783.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23783v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23783v1', 'Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shiao Wang, Ju Huang, Qingchuan Ma, Jinfeng Gao, Chunyi Xu, Xiao Wang, Lan Chen, Bo Jiang

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30

**å¤‡æ³¨**: Journal extension of Mamba-FETrack which was published on Pattern Recognition and Computer Vision (PRCV) 2024

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Event-AHU/Mamba_FETrack)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMamba-FETrack V2ä»¥è§£å†³å¤šæ¨¡æ€è§†è§‰ç›®æ ‡è·Ÿè¸ªæ•ˆç‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€è·Ÿè¸ª` `äº‹ä»¶ç›¸æœº` `è§†è§‰Mambaç½‘ç»œ` `ç‰¹å¾æå–` `ç›®æ ‡å®šä½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€è·Ÿè¸ªç®—æ³•ä¾èµ–å¤æ‚çš„è§†è§‰å˜æ¢å™¨ï¼Œå¯¼è‡´è®¡ç®—å¼€é”€å¤§ä¸”è·¨æ¨¡æ€äº¤äº’æ•ˆæœæœ‰é™ã€‚
2. æå‡ºMamba-FETrack V2æ¡†æ¶ï¼Œåˆ©ç”¨è½»é‡çº§æç¤ºç”Ÿæˆå™¨å’ŒVision Mambaç½‘ç»œå®ç°é«˜æ•ˆçš„ç‰¹å¾æå–ä¸èåˆã€‚
3. åœ¨å¤šä¸ªRGB-äº‹ä»¶è·Ÿè¸ªåŸºå‡†ä¸Šè¿›è¡Œå¹¿æ³›å®éªŒï¼Œç»“æœæ˜¾ç¤ºè¯¥æ¡†æ¶åœ¨æ€§èƒ½å’Œæ•ˆç‡ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå°†ä¼ ç»ŸRGBç›¸æœºä¸ç”Ÿç‰©å¯å‘çš„äº‹ä»¶ç›¸æœºç»“åˆç”¨äºç¨³å¥çš„ç›®æ ‡è·Ÿè¸ªå¼•èµ·äº†è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰çš„å¤šæ¨¡æ€è·Ÿè¸ªç®—æ³•è¿‡äºä¾èµ–é«˜å¤æ‚åº¦çš„è§†è§‰å˜æ¢å™¨æ¶æ„è¿›è¡Œç‰¹å¾æå–å’Œèåˆï¼Œè¿™ä¸ä»…å¯¼è‡´äº†æ˜¾è‘—çš„è®¡ç®—å¼€é”€ï¼Œè¿˜é™åˆ¶äº†è·¨æ¨¡æ€äº¤äº’çš„æœ‰æ•ˆæ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºçº¿æ€§å¤æ‚åº¦è§†è§‰Mambaç½‘ç»œçš„é«˜æ•ˆRGB-äº‹ä»¶ç›®æ ‡è·Ÿè¸ªæ¡†æ¶Mamba-FETrack V2ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªè½»é‡çº§çš„æç¤ºç”Ÿæˆå™¨ï¼Œåˆ©ç”¨æ¯ç§æ¨¡æ€çš„åµŒå…¥ç‰¹å¾å’Œå…±äº«æç¤ºæ± ï¼ŒåŠ¨æ€ç”Ÿæˆæ¨¡æ€ç‰¹å®šçš„å¯å­¦ä¹ æç¤ºå‘é‡ã€‚è¿™äº›æç¤ºä¸æ¨¡æ€ç‰¹å®šçš„åµŒå…¥ç‰¹å¾ä¸€èµ·è¾“å…¥åˆ°åŸºäºVision Mambaçš„FEMambaä¸»å¹²ç½‘ç»œä¸­ï¼Œä»è€Œä»¥ç»Ÿä¸€çš„æ–¹å¼ä¿ƒè¿›æç¤ºå¼•å¯¼çš„ç‰¹å¾æå–ã€è·¨æ¨¡æ€äº¤äº’å’Œèåˆã€‚æœ€åï¼Œèåˆåçš„è¡¨ç¤ºè¢«ä¼ é€’åˆ°è·Ÿè¸ªå¤´ä»¥å®ç°å‡†ç¡®çš„ç›®æ ‡å®šä½ã€‚å¤§é‡å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œæ‰€æå‡ºçš„è·Ÿè¸ªæ¡†æ¶åœ¨å¤šä¸ªRGB-äº‹ä»¶è·Ÿè¸ªåŸºå‡†ä¸Šè¡¨ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½å’Œæ•ˆç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€è§†è§‰ç›®æ ‡è·Ÿè¸ªç®—æ³•åœ¨è®¡ç®—å¤æ‚åº¦å’Œè·¨æ¨¡æ€äº¤äº’æ•ˆæœä¸Šçš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯é«˜å¤æ‚åº¦çš„è§†è§‰å˜æ¢å™¨æ¶æ„å¸¦æ¥çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§åŸºäºçº¿æ€§å¤æ‚åº¦çš„Vision Mambaç½‘ç»œï¼Œé€šè¿‡è®¾è®¡è½»é‡çº§çš„æç¤ºç”Ÿæˆå™¨ï¼ŒåŠ¨æ€ç”Ÿæˆæ¨¡æ€ç‰¹å®šçš„å¯å­¦ä¹ æç¤ºå‘é‡ï¼Œä»è€Œæé«˜ç‰¹å¾æå–å’Œèåˆçš„æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æç¤ºç”Ÿæˆå™¨ã€FEMambaä¸»å¹²ç½‘ç»œå’Œè·Ÿè¸ªå¤´ã€‚æç¤ºç”Ÿæˆå™¨ä»æ¯ç§æ¨¡æ€çš„åµŒå…¥ç‰¹å¾ä¸­æå–ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆé€‚åº”æ€§æç¤ºï¼Œéšåè¿™äº›æç¤ºä¸åµŒå…¥ç‰¹å¾ä¸€èµ·è¾“å…¥åˆ°ä¸»å¹²ç½‘ç»œè¿›è¡Œå¤„ç†ï¼Œæœ€åè¾“å‡ºç”¨äºç›®æ ‡å®šä½çš„èåˆè¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†è½»é‡çº§çš„æç¤ºç”Ÿæˆå™¨å’ŒåŸºäºVision Mambaçš„ç‰¹å¾æå–æœºåˆ¶ï¼Œä½¿å¾—è·¨æ¨¡æ€äº¤äº’å’Œç‰¹å¾èåˆåœ¨è®¡ç®—ä¸Šæ›´ä¸ºé«˜æ•ˆï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”æ˜¾è‘—é™ä½äº†å¤æ‚åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæç¤ºç”Ÿæˆå™¨åˆ©ç”¨å…±äº«æç¤ºæ± å’Œæ¨¡æ€ç‰¹å®šçš„åµŒå…¥ç‰¹å¾ï¼Œç¡®ä¿ç”Ÿæˆçš„æç¤ºå‘é‡èƒ½å¤Ÿæœ‰æ•ˆå¼•å¯¼ç‰¹å¾æå–ã€‚ç½‘ç»œç»“æ„é‡‡ç”¨äº†çº¿æ€§å¤æ‚åº¦çš„è®¾è®¡ï¼Œå‡å°‘äº†è®¡ç®—èµ„æºçš„æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒäº†è·Ÿè¸ªç²¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMamba-FETrack V2åœ¨çŸ­æœŸCOESOTæ•°æ®é›†å’Œé•¿æœŸFE108ã€FELT V2æ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œè·Ÿè¸ªç²¾åº¦æ˜¾è‘—é«˜äºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œä¸”è®¡ç®—æ•ˆç‡æå‡å¹…åº¦è¾¾åˆ°30%ä»¥ä¸Šï¼Œè¯æ˜äº†å…¶åœ¨å¤šæ¨¡æ€è·Ÿè¸ªä¸­çš„ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§å’Œæœºå™¨äººå¯¼èˆªç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„ç›®æ ‡è·Ÿè¸ªã€‚é€šè¿‡ç»“åˆRGBå’Œäº‹ä»¶ç›¸æœºçš„ä¼˜åŠ¿ï¼ŒMamba-FETrack V2æœ‰æœ›åœ¨å®æ—¶è·Ÿè¸ªä»»åŠ¡ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæå‡ç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³å’Œå“åº”èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Combining traditional RGB cameras with bio-inspired event cameras for robust object tracking has garnered increasing attention in recent years. However, most existing multimodal tracking algorithms depend heavily on high-complexity Vision Transformer architectures for feature extraction and fusion across modalities. This not only leads to substantial computational overhead but also limits the effectiveness of cross-modal interactions. In this paper, we propose an efficient RGB-Event object tracking framework based on the linear-complexity Vision Mamba network, termed Mamba-FETrack V2. Specifically, we first design a lightweight Prompt Generator that utilizes embedded features from each modality, together with a shared prompt pool, to dynamically generate modality-specific learnable prompt vectors. These prompts, along with the modality-specific embedded features, are then fed into a Vision Mamba-based FEMamba backbone, which facilitates prompt-guided feature extraction, cross-modal interaction, and fusion in a unified manner. Finally, the fused representations are passed to the tracking head for accurate target localization. Extensive experimental evaluations on multiple RGB-Event tracking benchmarks, including short-term COESOT dataset and long-term datasets, i.e., FE108 and FELT V2, demonstrate the superior performance and efficiency of the proposed tracking framework. The source code and pre-trained models will be released on https://github.com/Event-AHU/Mamba_FETrack

