---
layout: default
title: Explainable Adversarial-Robust Vision-Language-Action Model for Robotic Manipulation
---

# Explainable Adversarial-Robust Vision-Language-Action Model for Robotic Manipulation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.11865" target="_blank" class="toolbar-btn">arXiv: 2512.11865v1</a>
    <a href="https://arxiv.org/pdf/2512.11865.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.11865v1" 
            onclick="toggleFavorite(this, '2512.11865v1', 'Explainable Adversarial-Robust Vision-Language-Action Model for Robotic Manipulation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Ju-Young Kim, Ji-Hong Park, Myeongjun Kim, Gun-Woo Kim

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-05

**Â§áÊ≥®**: Accepted to MobieSec 2025 (poster session)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ÂèØËß£ÈáäÁöÑÂØπÊäóÈ≤ÅÊ£íËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÔºåÁî®‰∫éÊèêÂçáÊú∫Âô®‰∫∫Êìç‰ΩúÂú®Êô∫ËÉΩÂÜú‰∏ö‰∏≠ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Êìç‰Ωú` `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã` `ÂØπÊäóÈ≤ÅÊ£íÊÄß` `ÂèØËß£ÈáäÊÄß` `Êô∫ËÉΩÂÜú‰∏ö` `ÂÖâÂ∫¶Êâ∞Âä®` `Ëá™ÁÑ∂ËØ≠Ë®ÄËß£Èáä`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Êô∫ËÉΩÂÜú‰∏öÁ≥ªÁªü‰∏≠ÔºåÂü∫‰∫éRGBÁõ∏Êú∫ÁöÑËßÜËßâÊÑüÁü•ÂíåÊú∫Âô®‰∫∫Êìç‰ΩúÊòìÂèóÂÖâÁÖßÁ≠âÊâ∞Âä®ÂΩ±ÂìçÔºåÂØºËá¥ÂØπÊäóÊîªÂáª‰∏ãÁöÑÁ≥ªÁªüÂ§±Êïà„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Âü∫‰∫éOpenVLA-OFTÊ°ÜÊû∂ÁöÑËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÔºåÈõÜÊàêEvidence-3Ê®°ÂùóÊ£ÄÊµãÊâ∞Âä®Âπ∂ÁîüÊàêËá™ÁÑ∂ËØ≠Ë®ÄËß£Èáä„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•Ê®°ÂûãÊòæËëóÈôç‰Ωé‰∫ÜÂä®‰ΩúÈ¢ÑÊµãÁöÑL1ÊçüÂ§±ÔºåÊèêÂçá‰∫ÜÂú®ÂØπÊäóÁéØÂ¢É‰∏ãÁöÑÂä®‰ΩúÈ¢ÑÊµãÂáÜÁ°ÆÊÄßÂíåÂèØËß£ÈáäÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂèØËß£ÈáäÁöÑÂØπÊäóÈ≤ÅÊ£íËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÔºåËØ•Ê®°ÂûãÂü∫‰∫éOpenVLA-OFTÊ°ÜÊû∂ÔºåÊó®Âú®Ëß£ÂÜ≥Êô∫ËÉΩÂÜú‰∏ö‰∏≠‰æùËµñRGBÁõ∏Êú∫ÊÑüÁü•ÂíåÊú∫Âô®‰∫∫Êìç‰ΩúÁöÑÁ≥ªÁªüÊòìÂèóÂÖâÂ∫¶Êâ∞Âä®ÔºàÂ¶ÇËâ≤Ë∞É„ÄÅÂÖâÁÖßÂíåÂô™Â£∞ÂèòÂåñÔºâÂΩ±ÂìçÁöÑÈóÆÈ¢ò„ÄÇËØ•Ê®°ÂûãÈõÜÊàê‰∫Ü‰∏Ä‰∏™Evidence-3Ê®°ÂùóÔºåÁî®‰∫éÊ£ÄÊµãÂÖâÂ∫¶Êâ∞Âä®ÔºåÂπ∂ÁîüÊàêÂÖ≥‰∫éÂÖ∂ÂéüÂõ†ÂíåÂΩ±ÂìçÁöÑËá™ÁÑ∂ËØ≠Ë®ÄËß£Èáä„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰∏éÂü∫Á∫øÊ®°ÂûãÁõ∏ÊØîÔºåËØ•Ê®°ÂûãÂú®ÂΩìÂâçÂä®‰ΩúL1ÊçüÂ§±‰∏äÈôç‰Ωé‰∫Ü21.7%ÔºåÂú®ÂêéÁª≠Âä®‰ΩúL1ÊçüÂ§±‰∏äÈôç‰Ωé‰∫Ü18.4%ÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÂØπÊäóÊù°‰ª∂‰∏ãÂÖ∑ÊúâÊõ¥È´òÁöÑÂä®‰ΩúÈ¢ÑÊµãÂáÜÁ°ÆÊÄßÂíåÂèØËß£ÈáäÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊô∫ËÉΩÂÜú‰∏öÁ≥ªÁªü‰∏≠ÔºåÊú∫Âô®‰∫∫Êìç‰Ωú‰æùËµñRGBÁõ∏Êú∫ËøõË°åËßÜËßâÊÑüÁü•Ôºå‰ΩÜRGBÁõ∏Êú∫ÂÆπÊòìÂèóÂà∞ÂÖâÁÖß„ÄÅËâ≤Ë∞É„ÄÅÂô™Â£∞Á≠âÂÖâÂ∫¶Êâ∞Âä®ÁöÑÂΩ±Âìç„ÄÇËøô‰∫õÊâ∞Âä®‰ºöÂØºËá¥Á≥ªÁªüÂú®ÂØπÊäóÊîªÂáª‰∏ãÊÄßËÉΩÊòæËëó‰∏ãÈôçÔºåÁîöËá≥ÂÆåÂÖ®Â§±Êïà„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÊèêÈ´òËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÂú®ÂÖâÂ∫¶Êâ∞Âä®‰∏ãÁöÑÈ≤ÅÊ£íÊÄßÔºåÊòØÊú¨ÊñáË¶ÅËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèÂØπÊâ∞Âä®ÂéüÂõ†ÂíåÂΩ±ÂìçÁöÑËß£ÈáäËÉΩÂäõÔºåÈöæ‰ª•ËøõË°åÈíàÂØπÊÄßÁöÑÈò≤Âæ°„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™ÂèØËß£ÈáäÁöÑÂØπÊäóÈ≤ÅÊ£íËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÔºåÈÄöËøáÈõÜÊàêEvidence-3Ê®°ÂùóÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üÊ£ÄÊµãÂÖâÂ∫¶Êâ∞Âä®ÔºåÂπ∂ÁîüÊàêËá™ÁÑ∂ËØ≠Ë®ÄËß£ÈáäÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÂèØËß£ÈáäÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇËøôÁßçËÆæËÆ°ÂÖÅËÆ∏Ê®°Âûã‰∏ç‰ªÖËÉΩÂ§üÈ¢ÑÊµãÂä®‰ΩúÔºåËøòËÉΩÁêÜËß£Âπ∂Ëß£ÈáäÂÖ∂È¢ÑÊµãÁöÑÂéüÂõ†Ôºå‰ªéËÄåÊõ¥ÂÆπÊòìËøõË°åË∞ÉËØïÂíåÊîπËøõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê®°ÂûãÂü∫‰∫éOpenVLA-OFTÊ°ÜÊû∂ÊûÑÂª∫Ôºå‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÊ®°ÂùóÔºö1) ËßÜËßâÊÑüÁü•Ê®°ÂùóÔºöË¥üË¥£‰ªéRGBÂõæÂÉè‰∏≠ÊèêÂèñËßÜËßâÁâπÂæÅ„ÄÇ2) ËØ≠Ë®ÄÁêÜËß£Ê®°ÂùóÔºöË¥üË¥£ÁêÜËß£ËæìÂÖ•ÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÊåá‰ª§„ÄÇ3) Âä®‰ΩúÈ¢ÑÊµãÊ®°ÂùóÔºöË¥üË¥£Ê†πÊçÆËßÜËßâÁâπÂæÅÂíåËØ≠Ë®ÄÊåá‰ª§È¢ÑÊµãÊú∫Âô®‰∫∫ÁöÑÂä®‰Ωú„ÄÇ4) Evidence-3Ê®°ÂùóÔºöËøôÊòØËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞ÔºåË¥üË¥£Ê£ÄÊµãÂÖâÂ∫¶Êâ∞Âä®ÔºåÂπ∂ÁîüÊàêÂÖ≥‰∫éÂÖ∂ÂéüÂõ†ÂíåÂΩ±ÂìçÁöÑËá™ÁÑ∂ËØ≠Ë®ÄËß£Èáä„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÔºöËæìÂÖ•RGBÂõæÂÉèÂíåËá™ÁÑ∂ËØ≠Ë®ÄÊåá‰ª§ÔºåËßÜËßâÊÑüÁü•Ê®°ÂùóÂíåËØ≠Ë®ÄÁêÜËß£Ê®°ÂùóÂàÜÂà´ÊèêÂèñËßÜËßâÁâπÂæÅÂíåËØ≠Ë®ÄÁâπÂæÅÔºåÁÑ∂ÂêéÂ∞ÜËøô‰∫õÁâπÂæÅËæìÂÖ•Âà∞Âä®‰ΩúÈ¢ÑÊµãÊ®°ÂùóÂíåEvidence-3Ê®°Âùó‰∏≠ÔºåÂä®‰ΩúÈ¢ÑÊµãÊ®°ÂùóÈ¢ÑÊµãÊú∫Âô®‰∫∫ÁöÑÂä®‰ΩúÔºåEvidence-3Ê®°ÂùóÊ£ÄÊµãÂÖâÂ∫¶Êâ∞Âä®Âπ∂ÁîüÊàêËá™ÁÑ∂ËØ≠Ë®ÄËß£Èáä„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÈõÜÊàê‰∫ÜEvidence-3Ê®°ÂùóÔºåËØ•Ê®°ÂùóËÉΩÂ§üÊ£ÄÊµãÂÖâÂ∫¶Êâ∞Âä®ÔºåÂπ∂ÁîüÊàêÂÖ≥‰∫éÂÖ∂ÂéüÂõ†ÂíåÂΩ±ÂìçÁöÑËá™ÁÑ∂ËØ≠Ë®ÄËß£Èáä„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ï‰∏ç‰ªÖËÉΩÂ§üÊèêÈ´òÊ®°ÂûãÂú®ÂØπÊäóÊù°‰ª∂‰∏ãÁöÑÈ≤ÅÊ£íÊÄßÔºåËøòËÉΩÂ§üÊèêÈ´òÊ®°ÂûãÁöÑÂèØËß£ÈáäÊÄßÔºå‰ΩøÂæóÁî®Êà∑ËÉΩÂ§üÁêÜËß£Ê®°ÂûãÈ¢ÑÊµãÁöÑÂéüÂõ†Ôºå‰ªéËÄåÊõ¥ÂÆπÊòìËøõË°åË∞ÉËØïÂíåÊîπËøõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂÖ≥‰∫éEvidence-3Ê®°ÂùóÁöÑÂÖ∑‰ΩìËÆæËÆ°ÁªÜËäÇÊú™Áü•ÔºåÊëòË¶Å‰∏≠Ê≤°ÊúâËØ¶ÁªÜËØ¥Êòé„ÄÇ‰ΩÜÊòØÂèØ‰ª•Êé®ÊµãÔºåËØ•Ê®°ÂùóÂèØËÉΩ‰ΩøÁî®‰∫ÜÊüêÁßçÂΩ¢ÂºèÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂ÊàñÂõ†ÊûúÊé®ÁêÜÊ®°ÂûãÔºå‰ª•‰æøËÉΩÂ§üËØÜÂà´ÂÖâÂ∫¶Êâ∞Âä®ÔºåÂπ∂ÁîüÊàêÂÖ≥‰∫éÂÖ∂ÂéüÂõ†ÂíåÂΩ±ÂìçÁöÑËá™ÁÑ∂ËØ≠Ë®ÄËß£Èáä„ÄÇÊçüÂ§±ÂáΩÊï∞ÊñπÈù¢ÔºåËÆ∫Êñá‰ΩøÁî®‰∫ÜCurrent Action L1 lossÂíåNext Actions L1 lossÊù•ËØÑ‰º∞Âä®‰ΩúÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰∏éÂü∫Á∫øÊ®°ÂûãÁõ∏ÊØîÔºåËØ•Ê®°ÂûãÂú®ÂΩìÂâçÂä®‰ΩúL1ÊçüÂ§±‰∏äÈôç‰Ωé‰∫Ü21.7%ÔºåÂú®ÂêéÁª≠Âä®‰ΩúL1ÊçüÂ§±‰∏äÈôç‰Ωé‰∫Ü18.4%„ÄÇËøôË°®ÊòéËØ•Ê®°ÂûãÂú®ÂØπÊäóÊù°‰ª∂‰∏ãÂÖ∑ÊúâÊõ¥È´òÁöÑÂä®‰ΩúÈ¢ÑÊµãÂáÜÁ°ÆÊÄßÂíåÂèØËß£ÈáäÊÄßÔºåËÉΩÂ§üÊúâÊïàÂ∫îÂØπÂÖâÂ∫¶Êâ∞Âä®Â∏¶Êù•ÁöÑÊåëÊàòÔºåÊòæËëóÊèêÂçá‰∫ÜÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏ãÁöÑÊìç‰ΩúÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩÂÜú‰∏ö„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÁõëÊéßÁ≠âÈ¢ÜÂüü„ÄÇÂú®Êô∫ËÉΩÂÜú‰∏ö‰∏≠ÔºåÂèØ‰ª•ÊèêÈ´òÊú∫Âô®‰∫∫Êìç‰ΩúÂú®Â§çÊùÇÂÖâÁÖßÊù°‰ª∂‰∏ãÁöÑÁ®≥ÂÆöÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÂèØ‰ª•ÊèêÈ´òËΩ¶ËæÜÂú®ÊÅ∂Âä£Â§©Ê∞îÊù°‰ª∂‰∏ãÁöÑÊÑüÁü•ËÉΩÂäõ„ÄÇÂú®Êô∫ËÉΩÁõëÊéß‰∏≠ÔºåÂèØ‰ª•ÊèêÈ´òÁõëÊéßÁ≥ªÁªüÂú®ÂÖâÁÖßÂèòÂåñ‰∏ãÁöÑÂáÜÁ°ÆÊÄß„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÂú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®ÔºåÂπ∂ÊèêÈ´ò‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÁöÑÂèØÈù†ÊÄßÂíåÂÆâÂÖ®ÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Smart farming has emerged as a key technology for advancing modern agriculture through automation and intelligent control. However, systems relying on RGB cameras for perception and robotic manipulators for control, common in smart farming, are vulnerable to photometric perturbations such as hue, illumination, and noise changes, which can cause malfunction under adversarial attacks. To address this issue, we propose an explainable adversarial-robust Vision-Language-Action model based on the OpenVLA-OFT framework. The model integrates an Evidence-3 module that detects photometric perturbations and generates natural language explanations of their causes and effects. Experiments show that the proposed model reduces Current Action L1 loss by 21.7% and Next Actions L1 loss by 18.4% compared to the baseline, demonstrating improved action prediction accuracy and explainability under adversarial conditions.

