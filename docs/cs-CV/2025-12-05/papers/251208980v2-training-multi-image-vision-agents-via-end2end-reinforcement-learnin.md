---
layout: default
title: Training Multi-Image Vision Agents via End2End Reinforcement Learning
---

# Training Multi-Image Vision Agents via End2End Reinforcement Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.08980" target="_blank" class="toolbar-btn">arXiv: 2512.08980v2</a>
    <a href="https://arxiv.org/pdf/2512.08980.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.08980v2" 
            onclick="toggleFavorite(this, '2512.08980v2', 'Training Multi-Image Vision Agents via End2End Reinforcement Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Chengqi Dong, Chuhuai Yue, Hang He, Rongge Mao, Fenghe Tang, S Kevin Zhou, Zekun Xu, Xiaohan Wang, Jiajun Chai, Wei Lin, Guojun Yin

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-05 (Êõ¥Êñ∞: 2025-12-16)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫IMAgentÔºåÈÄöËøáÁ´ØÂà∞Á´ØÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÂ§öÂõæËßÜËßâAgentÔºåËß£ÂÜ≥Â§çÊùÇÂ§öÂõæQA‰ªªÂä°„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Â§öÂõæQA` `ËßÜËßâAgent` `Âº∫ÂåñÂ≠¶‰π†` `Â∑•ÂÖ∑‰ΩøÁî®` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éVLMÁöÑAgentÂú®Â∑•ÂÖ∑‰ΩøÁî®ÊñπÈù¢Â≠òÂú®Â±ÄÈôêÔºåÂ§ßÂ§ö‰ªÖÈôê‰∫éÂçïÂº†ÂõæÂÉèËæìÂÖ•ÔºåÈöæ‰ª•Â∫îÂØπÁúüÂÆû‰∏ñÁïåÁöÑÂ§öÂõæQA‰ªªÂä°„ÄÇ
2. IMAgentÈÄöËøáÁ´ØÂà∞Á´ØÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÔºåÂπ∂ÂºïÂÖ•Â§öAgentÁ≥ªÁªüÁîüÊàêÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂ§öÂõæQAÂØπÔºå‰ªéËÄåÊèêÂçáVLMÁöÑÂ∑•ÂÖ∑‰ΩøÁî®ËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåIMAgentÂú®Â§öÂõæQA‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÊèêÂçáÔºåÂêåÊó∂Âú®ÂçïÂõæÂü∫ÂáÜÊµãËØï‰∏≠‰øùÊåÅ‰∫ÜÁ´û‰∫âÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫IMAgentÔºå‰∏Ä‰∏™ÂºÄÊ∫êÁöÑËßÜËßâAgentÔºåÈÄöËøáÁ´ØÂà∞Á´ØÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÔºå‰∏ìÈó®Áî®‰∫éÂ§ÑÁêÜÂ§çÊùÇÁöÑÂ§öÂõæ‰ªªÂä°„ÄÇÂà©Áî®Â§öAgentÁ≥ªÁªüÔºåÁîüÊàêÂÖ∑ÊúâÊåëÊàòÊÄßÂíåËßÜËßâ‰∏∞ÂØåÊÄßÁöÑÂ§öÂõæQAÂØπÔºåÂÖÖÂàÜÊøÄÊ¥ªÂü∫Á°ÄVLMÁöÑÂ∑•ÂÖ∑‰ΩøÁî®ÊΩúÂäõ„ÄÇÈÄöËøá‰∫∫Â∑•È™åËØÅÔºåÊûÑÂª∫‰∫ÜÂåÖÂê´1‰∏á‰∏™Ê†∑Êú¨ÁöÑMIFG-QAÊï∞ÊçÆÈõÜÔºåÁî®‰∫éËÆ≠ÁªÉÂíåËØÑ‰º∞„ÄÇÈíàÂØπVLMÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÂèØËÉΩÂøΩÁï•ËßÜËßâËæìÂÖ•ÁöÑÈóÆÈ¢òÔºåÂºÄÂèë‰∫ÜËßÜËßâÂèçÊÄùÂíåÁ°ÆËÆ§Â∑•ÂÖ∑Ôºå‰ΩøÊ®°ÂûãËÉΩÂ§üÂú®Êé®ÁêÜËøáÁ®ã‰∏≠‰∏ªÂä®ÈáçÊñ∞ÂàÜÈÖçÂØπÂõæÂÉèÂÜÖÂÆπÁöÑÊ≥®ÊÑèÂäõ„ÄÇÂèóÁõä‰∫éÁ≤æÂøÉËÆæËÆ°ÁöÑÂä®‰ΩúËΩ®Ëøπ‰∏§Á∫ßÊé©Á†ÅÁ≠ñÁï•ÔºåIMAgentÈÄöËøáÁ∫ØÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÂÆûÁé∞‰∫ÜÁ®≥ÂÆöÁöÑÂ∑•ÂÖ∑‰ΩøÁî®Ë°å‰∏∫ÔºåÊó†ÈúÄÊòÇË¥µÁöÑÁõëÁù£ÂæÆË∞ÉÊï∞ÊçÆ„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåIMAgentÂú®Áé∞ÊúâÂçïÂõæÂü∫ÂáÜ‰∏ä‰øùÊåÅ‰∫ÜÂº∫Â§ßÁöÑÊÄßËÉΩÔºåÂπ∂Âú®ÊèêÂá∫ÁöÑÂ§öÂõæÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊîπËøõÔºåÂàÜÊûê‰∏∫Á†îÁ©∂Á§æÂå∫Êèê‰æõ‰∫ÜÂèØÊìç‰ΩúÁöÑËßÅËß£„ÄÇ‰ª£Á†ÅÂíåÊï∞ÊçÆÂç≥Â∞ÜÂèëÂ∏É„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâÁöÑAgentÂú®Â§ÑÁêÜÂ§öÂõæQA‰ªªÂä°Êó∂Â≠òÂú®‰∏çË∂≥Ôºå‰∏ªË¶ÅÂéüÂõ†ÊòØÂÆÉ‰ª¨ÈÄöÂ∏∏Âè™Êé•ÂèóÂçïÂº†ÂõæÂÉè‰Ωú‰∏∫ËæìÂÖ•ÔºåËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®ÈúÄË¶ÅÁªºÂêàÂ§öÂº†ÂõæÂÉè‰ø°ÊÅØÊâçËÉΩÂÆåÊàêÁöÑ‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®„ÄÇÁé∞ÊúâÁöÑÂºÄÊ∫êÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂà©Áî®VLMÁöÑÂ∑•ÂÖ∑‰ΩøÁî®ËÉΩÂäõÊù•Ëß£ÂÜ≥Â§çÊùÇÁöÑÂ§öÂõæÊé®ÁêÜÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÁ´ØÂà∞Á´ØÂº∫ÂåñÂ≠¶‰π†Êù•ËÆ≠ÁªÉ‰∏Ä‰∏™ËÉΩÂ§üÊúâÊïàÂà©Áî®Â§öÂº†ÂõæÂÉè‰ø°ÊÅØÁöÑËßÜËßâAgent„ÄÇÈÄöËøáËÆæËÆ°‰∏Ä‰∏™Â§öAgentÁ≥ªÁªüÊù•ÁîüÊàêÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂ§öÂõæQAÂØπÔºå‰ªéËÄåËÆ≠ÁªÉVLMÁöÑÂ∑•ÂÖ∑‰ΩøÁî®ËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫ÜËß£ÂÜ≥VLMÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÂèØËÉΩÂøΩÁï•ËßÜËßâËæìÂÖ•ÁöÑÈóÆÈ¢òÔºåÂºïÂÖ•‰∫ÜËßÜËßâÂèçÊÄùÂíåÁ°ÆËÆ§Â∑•ÂÖ∑Ôºå‰øÉ‰ΩøÊ®°ÂûãÊõ¥Âä†ÂÖ≥Ê≥®ÂõæÂÉèÂÜÖÂÆπ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöIMAgentÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Â§öAgentÊï∞ÊçÆÁîüÊàêÂô®ÔºöË¥üË¥£ÁîüÊàêÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂ§öÂõæQAÂØπÔºåÁî®‰∫éËÆ≠ÁªÉAgent„ÄÇ2) Âü∫‰∫éVLMÁöÑAgentÔºö‰Ωú‰∏∫Ê†∏ÂøÉÊé®ÁêÜÊ®°ÂùóÔºåË¥üË¥£Êé•Êî∂ÂõæÂÉèÂíåÈóÆÈ¢òÔºåÂπ∂ËæìÂá∫Á≠îÊ°à„ÄÇ3) ËßÜËßâÂèçÊÄùÂíåÁ°ÆËÆ§Â∑•ÂÖ∑ÔºöÁî®‰∫éÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÈáçÊñ∞ÂàÜÈÖçÂØπÂõæÂÉèÂÜÖÂÆπÁöÑÊ≥®ÊÑèÂäõ„ÄÇ4) Âº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÊ®°ÂùóÔºö‰ΩøÁî®Á≤æÂøÉËÆæËÆ°ÁöÑÂ•ñÂä±ÂáΩÊï∞ÂíåÂä®‰ΩúËΩ®ËøπÊé©Á†ÅÁ≠ñÁï•ÔºåËÆ≠ÁªÉAgentÁöÑÂ∑•ÂÖ∑‰ΩøÁî®ËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ª•‰∏ãÂá†‰∏™ÊñπÈù¢Ôºö1) ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫éÂ§öAgentÁ≥ªÁªüÁöÑÂ§öÂõæQAÊï∞ÊçÆÁîüÊàêÊñπÊ≥ïÔºåËÉΩÂ§üÁîüÊàêÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ2) ËÆæËÆ°‰∫ÜËßÜËßâÂèçÊÄùÂíåÁ°ÆËÆ§Â∑•ÂÖ∑ÔºåËß£ÂÜ≥‰∫ÜVLMÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÂèØËÉΩÂøΩÁï•ËßÜËßâËæìÂÖ•ÁöÑÈóÆÈ¢ò„ÄÇ3) ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âä®‰ΩúËΩ®Ëøπ‰∏§Á∫ßÊé©Á†ÅÁ≠ñÁï•Ôºå‰ΩøÂæóAgentËÉΩÂ§üÈÄöËøáÁ∫ØÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÂÆûÁé∞Á®≥ÂÆöÁöÑÂ∑•ÂÖ∑‰ΩøÁî®Ë°å‰∏∫ÔºåÊó†ÈúÄ‰æùËµñÊòÇË¥µÁöÑÁõëÁù£ÂæÆË∞ÉÊï∞ÊçÆ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Êï∞ÊçÆÁîüÊàêÊñπÈù¢ÔºåËÆæËÆ°‰∫Ü‰∏çÂêåÁöÑAgentËßíËâ≤ÔºåÂàÜÂà´Ë¥üË¥£ÁîüÊàêÈóÆÈ¢ò„ÄÅÈÄâÊã©ÂõæÂÉèÂíåÊèê‰æõÁ≠îÊ°àÔºå‰ªéËÄå‰øùËØÅÊï∞ÊçÆÁöÑÂ§öÊ†∑ÊÄßÂíåÊåëÊàòÊÄß„ÄÇÂú®Âº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÊñπÈù¢Ôºå‰ΩøÁî®‰∫ÜÁ®ÄÁñèÂ•ñÂä±ÂáΩÊï∞ÔºåÈºìÂä±AgentÈááÂèñÊ≠£Á°ÆÁöÑÂä®‰ΩúÂ∫èÂàó„ÄÇÂä®‰ΩúËΩ®Ëøπ‰∏§Á∫ßÊé©Á†ÅÁ≠ñÁï•ÈÄöËøáÈôêÂà∂AgentÂú®‰∏çÂêåÈò∂ÊÆµÂèØ‰ª•ÈááÂèñÁöÑÂä®‰ΩúÔºå‰ªéËÄåÊèêÈ´òËÆ≠ÁªÉÁöÑÁ®≥ÂÆöÊÄßÂíåÊïàÁéá„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞ÔºàÊú™Áü•Ôºâ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

IMAgentÂú®ÊèêÂá∫ÁöÑÂ§öÂõæÊï∞ÊçÆÈõÜMIFG-QA‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÂçïÂõæAgent„ÄÇÂêåÊó∂ÔºåIMAgentÂú®Áé∞ÊúâÁöÑÂçïÂõæÂü∫ÂáÜÊµãËØï‰∏≠‰øùÊåÅ‰∫ÜÁ´û‰∫âÂäõÔºåË°®ÊòéÂÖ∂ÂÖ∑ÊúâËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÈÄöËøáÊ∂àËûçÂÆûÈ™åÔºåÈ™åËØÅ‰∫ÜËßÜËßâÂèçÊÄùÂíåÁ°ÆËÆ§Â∑•ÂÖ∑‰ª•ÂèäÂä®‰ΩúËΩ®ËøπÊé©Á†ÅÁ≠ñÁï•ÁöÑÊúâÊïàÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÊèêÂçáÂπÖÂ∫¶Âú®ËÆ∫Êñá‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÂ±ïÁ§∫ÔºàÊú™Áü•Ôºâ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

IMAgentÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÊô∫ËÉΩÂÆ¢Êúç„ÄÅÂåªÂ≠¶ÂõæÂÉèËØäÊñ≠„ÄÅÈÅ•ÊÑüÂõæÂÉèÂàÜÊûêÁ≠âÈ¢ÜÂüü„ÄÇÂÆÉÂèØ‰ª•Â∏ÆÂä©Áî®Êà∑‰ªéÂ§öÂº†ÂõæÂÉè‰∏≠ÊèêÂèñÂÖ≥ÈîÆ‰ø°ÊÅØÔºåÂπ∂ËøõË°åÊ∑±ÂÖ•ÁöÑÊé®ÁêÜÂíåÂÜ≥Á≠ñ„ÄÇÊú™Êù•ÔºåIMAgentÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÂ§öÊ®°ÊÄÅ‰ªªÂä°‰∏≠Ôºå‰æãÂ¶ÇËßÜÈ¢ëÁêÜËß£„ÄÅÊú∫Âô®‰∫∫ÂØºËà™Á≠âÔºå‰∏∫‰∫∫Â∑•Êô∫ËÉΩÂ∫îÁî®Â∏¶Êù•Êõ¥Âº∫Â§ßÁöÑËÉΩÂäõ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent VLM-based agents aim to replicate OpenAI O3's ``thinking with images" via tool use, but most open-source methods limit input to a single image, falling short on real-world multi-image QA tasks. To address this, we propose IMAgent, an open-source vision agent trained via end-to-end reinforcement learning dedicated for complex multi-image tasks. By leveraging a multi-agent system, we generate challenging and visually-rich multi-image QA pairs to fully activate the tool-use potential of the base VLM. Through manual verification, we obtain MIFG-QA, comprising 10k samples for training and evaluation. With deeper reasoning steps, VLMs may increasingly ignore visual inputs. We therefore develop two specialized tools for visual reflection and confirmation, allowing the model to proactively reallocate its attention to image content during inference. Benefiting from our well-designed action-trajectory two-level mask strategy, IMAgent achieves stable tool use behavior via pure RL training without requiring costly supervised fine-tuning data. Extensive experiments demonstrate that IMAgent maintains strong performance on existing single-image benchmarks while achieving substantial improvements on our proposed multi-image dataset, with our analysis providing actionable insights for the research community. Codes and data will be released soon.

