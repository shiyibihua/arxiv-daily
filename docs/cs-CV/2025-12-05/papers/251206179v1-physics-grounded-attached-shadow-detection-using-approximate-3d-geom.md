---
layout: default
title: Physics-Grounded Attached Shadow Detection Using Approximate 3D Geometry and Light Direction
---

# Physics-Grounded Attached Shadow Detection Using Approximate 3D Geometry and Light Direction

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.06179" target="_blank" class="toolbar-btn">arXiv: 2512.06179v1</a>
    <a href="https://arxiv.org/pdf/2512.06179.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.06179v1" 
            onclick="toggleFavorite(this, '2512.06179v1', 'Physics-Grounded Attached Shadow Detection Using Approximate 3D Geometry and Light Direction')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Shilin Hu, Jingyi Xu, Sagnik Das, Dimitris Samaras, Hieu Le

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-05

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éËøë‰ºº3DÂá†‰ΩïÂíåÂÖâÁÖßÊñπÂêëÁöÑÁâ©ÁêÜÁ∫¶ÊùüÈò¥ÂΩ±Ê£ÄÊµãÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `‰æùÈôÑÈò¥ÂΩ±Ê£ÄÊµã` `ÊäïÂ∞ÑÈò¥ÂΩ±Ê£ÄÊµã` `ÂÖâÁÖß‰º∞ËÆ°` `Âá†‰ΩïÊé®ÁêÜ` `Èò¥ÂΩ±ÂàÜÂâ≤`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÈò¥ÂΩ±Ê£ÄÊµãÊñπÊ≥ï‰∏ªË¶ÅÂÖ≥Ê≥®ÊäïÂ∞ÑÈò¥ÂΩ±ÔºåÂøΩÁï•‰∫Ü‰æùÈôÑÈò¥ÂΩ±ÔºåÁº∫‰πèÈíàÂØπ‰æùÈôÑÈò¥ÂΩ±ÁöÑ‰∏ìÁî®Êï∞ÊçÆÈõÜÂíåÊ®°Âûã„ÄÇ
2. ËØ•ËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçËÅîÂêàÊ£ÄÊµãÊäïÂ∞ÑÈò¥ÂΩ±Âíå‰æùÈôÑÈò¥ÂΩ±ÁöÑÊ°ÜÊû∂ÔºåÈÄöËøáÂú∫ÊôØÂÖâÁÖßÂíåÂá†‰Ωï‰ΩìÁöÑÁõ∏‰∫íÂÖ≥Á≥ªËøõË°åÊé®ÁêÜ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÈÄöËøáËø≠‰ª£ÁöÑÂá†‰Ωï-ÂÖâÁÖßÊé®ÁêÜÔºåÊòæËëóÊèêÈ´ò‰∫Ü‰æùÈôÑÈò¥ÂΩ±ÁöÑÊ£ÄÊµãÊÄßËÉΩÔºåBERÈôç‰ΩéËá≥Â∞ë33%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçËÅîÂêàÊ£ÄÊµã‰æùÈôÑÈò¥ÂΩ±ÂíåÊäïÂ∞ÑÈò¥ÂΩ±ÁöÑÊ°ÜÊû∂ÔºåÈÄöËøáÊé®ÁêÜÂú∫ÊôØÂÖâÁÖßÂíåÂá†‰Ωï‰ΩìÁöÑÁõ∏‰∫íÂÖ≥Á≥ªÊù•ÂÆûÁé∞„ÄÇËØ•Á≥ªÁªüÂåÖÂê´‰∏Ä‰∏™Èò¥ÂΩ±Ê£ÄÊµãÊ®°ÂùóÔºåÂàÜÂà´È¢ÑÊµã‰∏§ÁßçÈò¥ÂΩ±Á±ªÂûãÔºå‰ª•Âèä‰∏Ä‰∏™ÂÖâÁÖß‰º∞ËÆ°Ê®°ÂùóÔºå‰ªéÊ£ÄÊµãÂà∞ÁöÑÈò¥ÂΩ±‰∏≠Êé®Êñ≠ÂÖâÁÖßÊñπÂêë„ÄÇ‰º∞ËÆ°ÁöÑÂÖâÁÖßÊñπÂêë‰∏éË°®Èù¢Ê≥ïÁ∫øÁõ∏ÁªìÂêàÔºåÂèØ‰ª•Êé®ÂØºÂá∫Âá†‰Ωï‰∏ÄËá¥ÁöÑÈÉ®ÂàÜÂú∞ÂõæÔºåËØÜÂà´ÂèØËÉΩÂèëÁîüËá™ÈÅÆÊå°ÁöÑÂå∫Âüü„ÄÇËØ•ÈÉ®ÂàÜÂú∞ÂõæË¢´ÂèçÈ¶à‰ª•ÁªÜÂåñÈò¥ÂΩ±È¢ÑÊµãÔºåÂΩ¢Êàê‰∏Ä‰∏™Èó≠ÁéØÊé®ÁêÜËøáÁ®ãÔºåËø≠‰ª£Âú∞ÊîπËøõÈò¥ÂΩ±ÂàÜÂâ≤ÂíåÂÖâÁÖß‰º∞ËÆ°„ÄÇ‰∏∫‰∫ÜËÆ≠ÁªÉËØ•ÊñπÊ≥ïÔºåÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÂåÖÂê´1458Âº†ÂõæÂÉèÁöÑÊï∞ÊçÆÈõÜÔºåÂàÜÂà´Ê†áÊ≥®‰∫ÜÊäïÂ∞ÑÈò¥ÂΩ±Âíå‰æùÈôÑÈò¥ÂΩ±Ôºå‰ªéËÄåËÉΩÂ§üÂØπ‰∏§ËÄÖËøõË°åËÆ≠ÁªÉÂíåÂÆöÈáèËØÑ‰º∞„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËøôÁßçËø≠‰ª£ÁöÑÂá†‰Ωï-ÂÖâÁÖßÊé®ÁêÜÊòæËëóÊèêÈ´ò‰∫Ü‰æùÈôÑÈò¥ÂΩ±ÁöÑÊ£ÄÊµãÔºåBERÈôç‰ΩéËá≥Â∞ë33%ÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÂº∫Â§ßÁöÑÂÆåÊï¥Èò¥ÂΩ±ÂíåÊäïÂ∞ÑÈò¥ÂΩ±ÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰æùÈôÑÈò¥ÂΩ±Ê£ÄÊµãÈóÆÈ¢ò„ÄÇÁé∞ÊúâÈò¥ÂΩ±Ê£ÄÊµãÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠‰∫éÊäïÂ∞ÑÈò¥ÂΩ±ÔºåÂøΩÁï•‰∫Ü‰æùÈôÑÈò¥ÂΩ±ÁöÑÈáçË¶ÅÊÄßÔºåÂπ∂‰∏îÁº∫‰πè‰∏ìÈó®Áî®‰∫é‰æùÈôÑÈò¥ÂΩ±Ê£ÄÊµãÁöÑÊï∞ÊçÆÈõÜÂíåÊ®°Âûã„ÄÇËøôÂØºËá¥Áé∞ÊúâÊñπÊ≥ïÂú®ÁêÜËß£Âú∫ÊôØ‰∏âÁª¥ÁªìÊûÑÂíåËøõË°åÊõ¥È´òÁ∫ßÁöÑÂú∫ÊôØÁêÜËß£ÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Âú∫ÊôØÁöÑÂá†‰Ωï‰ø°ÊÅØÂíåÂÖâÁÖß‰ø°ÊÅØ‰πãÈó¥ÁöÑÁõ∏‰∫íÂÖ≥Á≥ªÊù•ÊèêÈ´ò‰æùÈôÑÈò¥ÂΩ±ÁöÑÊ£ÄÊµãÁ≤æÂ∫¶„ÄÇÈÄöËøáËø≠‰ª£Âú∞‰º∞ËÆ°ÂÖâÁÖßÊñπÂêëÔºåÂπ∂ÁªìÂêàË°®Èù¢Ê≥ïÁ∫ø‰ø°ÊÅØÔºåÁîüÊàê‰∏Ä‰∏™Âá†‰Ωï‰∏ÄËá¥ÁöÑÈÉ®ÂàÜÂú∞ÂõæÔºåÁî®‰∫éÊåáÂØºÈò¥ÂΩ±Ê£ÄÊµãÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÂáÜÁ°ÆÁöÑ‰æùÈôÑÈò¥ÂΩ±ÂàÜÂâ≤„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ïÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈò¥ÂΩ±Ê£ÄÊµãÊ®°ÂùóÂíåÂÖâÁÖß‰º∞ËÆ°Ê®°Âùó„ÄÇÈò¥ÂΩ±Ê£ÄÊµãÊ®°ÂùóË¥üË¥£ÂàÜÂà´È¢ÑÊµãÊäïÂ∞ÑÈò¥ÂΩ±Âíå‰æùÈôÑÈò¥ÂΩ±„ÄÇÂÖâÁÖß‰º∞ËÆ°Ê®°Âùó‰ªéÊ£ÄÊµãÂà∞ÁöÑÈò¥ÂΩ±‰∏≠Êé®Êñ≠ÂÖâÁÖßÊñπÂêë„ÄÇ‰º∞ËÆ°ÁöÑÂÖâÁÖßÊñπÂêë‰∏éË°®Èù¢Ê≥ïÁ∫øÁªìÂêàÔºåÁîüÊàêÂá†‰Ωï‰∏ÄËá¥ÁöÑÈÉ®ÂàÜÂú∞Âõæ„ÄÇËØ•ÈÉ®ÂàÜÂú∞ÂõæË¢´ÂèçÈ¶àÂà∞Èò¥ÂΩ±Ê£ÄÊµãÊ®°ÂùóÔºåÁî®‰∫éÁªÜÂåñÈò¥ÂΩ±È¢ÑÊµãÔºåÂΩ¢Êàê‰∏Ä‰∏™Èó≠ÁéØÊé®ÁêÜËøáÁ®ã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂà©Áî®Âá†‰Ωï‰ø°ÊÅØÂíåÂÖâÁÖß‰ø°ÊÅØ‰πãÈó¥ÁöÑÁõ∏‰∫íÁ∫¶ÊùüÂÖ≥Á≥ªÔºåÈÄöËøáËø≠‰ª£Êé®ÁêÜÊù•ÊèêÈ´ò‰æùÈôÑÈò¥ÂΩ±ÁöÑÊ£ÄÊµãÁ≤æÂ∫¶„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ï‰∏ç‰ªÖËÄÉËôë‰∫ÜÈò¥ÂΩ±ÁöÑÂ§ñËßÇÁâπÂæÅÔºåËøòËÄÉËôë‰∫ÜÈò¥ÂΩ±‰∏éÂú∫ÊôØÂá†‰ΩïÁªìÊûÑ‰πãÈó¥ÁöÑÁâ©ÁêÜÂÖ≥Á≥ªÔºå‰ªéËÄåËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞Ê£ÄÊµã‰æùÈôÑÈò¥ÂΩ±„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËØ•ÊñπÊ≥ï‰ΩøÁî®‰∫Ü‰∏Ä‰∏™ÂåÖÂê´1458Âº†ÂõæÂÉèÁöÑÊï∞ÊçÆÈõÜËøõË°åËÆ≠ÁªÉÔºåËØ•Êï∞ÊçÆÈõÜÂàÜÂà´Ê†áÊ≥®‰∫ÜÊäïÂ∞ÑÈò¥ÂΩ±Âíå‰æùÈôÑÈò¥ÂΩ±„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÈúÄË¶ÅÂêåÊó∂ËÄÉËôëÊäïÂ∞ÑÈò¥ÂΩ±Âíå‰æùÈôÑÈò¥ÂΩ±ÁöÑÊ£ÄÊµãÁ≤æÂ∫¶Ôºå‰ª•ÂèäÂÖâÁÖß‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠Ê≤°ÊúâËØ¶ÁªÜÊèèËø∞ÔºåÂ±û‰∫éÊú™Áü•‰ø°ÊÅØ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®‰æùÈôÑÈò¥ÂΩ±Ê£ÄÊµãÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊèêÂçáÔºåBERÔºàË¥ùÂè∂ÊñØÈîôËØØÁéáÔºâÈôç‰Ωé‰∫ÜËá≥Â∞ë33%„ÄÇÂêåÊó∂ÔºåËØ•ÊñπÊ≥ïÂú®ÊäïÂ∞ÑÈò¥ÂΩ±ÂíåÂÆåÊï¥Èò¥ÂΩ±ÁöÑÊ£ÄÊµãÊñπÈù¢‰πü‰øùÊåÅ‰∫ÜËâØÂ•ΩÁöÑÊÄßËÉΩ„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåÈÄöËøáËø≠‰ª£ÁöÑÂá†‰Ωï-ÂÖâÁÖßÊé®ÁêÜÔºåÂèØ‰ª•ÊúâÊïàÂú∞ÊèêÈ´òÈò¥ÂΩ±Ê£ÄÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ËßÜËßâ„ÄÅËá™Âä®È©æÈ©∂„ÄÅ‰∏âÁª¥ÈáçÂª∫Á≠âÈ¢ÜÂüü„ÄÇÂáÜÁ°ÆÁöÑÈò¥ÂΩ±Ê£ÄÊµãËÉΩÂ§üÂ∏ÆÂä©Êú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÁêÜËß£Âë®Âõ¥ÁéØÂ¢ÉÔºåÊèêÈ´òËá™Âä®È©æÈ©∂Á≥ªÁªüÁöÑÂÆâÂÖ®ÊÄßÔºåÂπ∂ÊîπÂñÑ‰∏âÁª¥ÈáçÂª∫ÁöÑË¥®Èáè„ÄÇËØ•ÊñπÊ≥ïËøòÊúâÊΩúÂäõÂ∫îÁî®‰∫éÂõæÂÉèÁºñËæëÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüüÔºå‰æãÂ¶ÇÔºåÂèØ‰ª•Áî®‰∫éÂú®ÂõæÂÉè‰∏≠Ê∑ªÂä†Êàñ‰øÆÊîπÈò¥ÂΩ±Ôºå‰ª•Â¢ûÂº∫ÂõæÂÉèÁöÑÁúüÂÆûÊÑü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Attached shadows occur on the surface of the occluder where light cannot reach because of self-occlusion. They are crucial for defining the three-dimensional structure of objects and enhancing scene understanding. Yet existing shadow detection methods mainly target cast shadows, and there are no dedicated datasets or models for detecting attached shadows. To address this gap, we introduce a framework that jointly detects cast and attached shadows by reasoning about their mutual relationship with scene illumination and geometry. Our system consists of a shadow detection module that predicts both shadow types separately, and a light estimation module that infers the light direction from the detected shadows. The estimated light direction, combined with surface normals, allows us to derive a geometry-consistent partial map that identifies regions likely to be self-occluded. This partial map is then fed back to refine shadow predictions, forming a closed-loop reasoning process that iteratively improves both shadow segmentation and light estimation. In order to train our method, we have constructed a dataset of 1,458 images with separate annotations for cast and attached shadows, enabling training and quantitative evaluation of both. Experimental results demonstrate that this iterative geometry-illumination reasoning substantially improves the detection of attached shadows, with at least 33% BER reduction, while maintaining strong full and cast shadow performance.

