---
layout: default
title: IMTalker: Efficient Audio-driven Talking Face Generation with Implicit Motion Transfer
---

# IMTalker: Efficient Audio-driven Talking Face Generation with Implicit Motion Transfer

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.22167" target="_blank" class="toolbar-btn">arXiv: 2511.22167v1</a>
    <a href="https://arxiv.org/pdf/2511.22167.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.22167v1" 
            onclick="toggleFavorite(this, '2511.22167v1', 'IMTalker: Efficient Audio-driven Talking Face Generation with Implicit Motion Transfer')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Bo Chen, Tao Liu, Qi Chen, Xie Chen, Zilong Zheng

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-27

**Â§áÊ≥®**: 11 pages, 5 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**IMTalkerÔºöÂà©Áî®ÈöêÂºèËøêÂä®‰º†ÈÄíÂÆûÁé∞È´òÊïàÁöÑÈü≥È¢ëÈ©±Âä®ËØ¥ËØù‰∫∫ËÑ∏ÁîüÊàê**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)** **ÊîØÊü±‰∏ÉÔºöÂä®‰ΩúÈáçÂÆöÂêë (Motion Retargeting)**

**ÂÖ≥ÈîÆËØç**: `ËØ¥ËØù‰∫∫ËÑ∏ÁîüÊàê` `ÈöêÂºèËøêÂä®‰º†ÈÄí` `‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂` `Ë∫´‰ªΩ‰øùÊåÅ` `Èü≥È¢ëÈ©±Âä®`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËØ¥ËØù‰∫∫ËÑ∏ÁîüÊàêÊñπÊ≥ï‰æùËµñÂÖâÊµÅÂíåÂ±ÄÈÉ®Êâ≠Êõ≤ÔºåÈöæ‰ª•ÊçïÊçâÂÖ®Â±ÄËøêÂä®ÔºåÂØºËá¥Ë∫´‰ªΩ‰ø°ÊÅØ‰∏¢Â§±„ÄÇ
2. IMTalkerÈááÁî®‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂ÈöêÂºèÂª∫Ê®°ËøêÂä®Â∑ÆÂºÇÂíåË∫´‰ªΩÂØπÈΩêÔºåÂÆûÁé∞È≤ÅÊ£íÁöÑÂÖ®Â±ÄËøêÂä®Ê∏≤Êüì„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåIMTalkerÂú®ËøêÂä®Á≤æÂ∫¶„ÄÅË∫´‰ªΩ‰øùÊåÅÂíåÈü≥ÂîáÂêåÊ≠•ÊñπÈù¢‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÊïàÁéáÊõ¥È´ò„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫IMTalkerÁöÑÊñ∞Ê°ÜÊû∂ÔºåÁî®‰∫éÈ´òÊïà‰∏îÈ´ò‰øùÁúüÂú∞ÁîüÊàêËØ¥ËØù‰∫∫ËÑ∏„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÊòæÂºèÁöÑÂÖâÊµÅÂíåÂ±ÄÈÉ®Êâ≠Êõ≤ÔºåÈöæ‰ª•Âª∫Ê®°Â§çÊùÇÁöÑÂÖ®Â±ÄËøêÂä®ÔºåÂπ∂ÂØºËá¥Ë∫´‰ªΩÊºÇÁßª„ÄÇIMTalkerÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÁî®‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂Âèñ‰ª£‰º†ÁªüÁöÑÂü∫‰∫éÂÖâÊµÅÁöÑÊâ≠Êõ≤Ôºå‰ªéËÄåÂú®Áªü‰∏ÄÁöÑÊΩúÂú®Á©∫Èó¥‰∏≠ÈöêÂºèÂú∞Âª∫Ê®°ËøêÂä®Â∑ÆÂºÇÂíåË∫´‰ªΩÂØπÈΩêÔºåÂÆûÁé∞È≤ÅÊ£íÁöÑÂÖ®Â±ÄËøêÂä®Ê∏≤Êüì„ÄÇ‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•Âú®Ë∑®Ë∫´‰ªΩÈáçÊºî‰∏≠‰øùÊåÅËØ¥ËØù‰∫∫ÁöÑË∫´‰ªΩÔºåÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Ë∫´‰ªΩËá™ÈÄÇÂ∫îÊ®°ÂùóÔºåÂ∞ÜËøêÂä®ÊΩúÂú®ÂêëÈáèÊäïÂΩ±Âà∞‰∏™ÊÄßÂåñÁöÑÁ©∫Èó¥‰∏≠ÔºåÁ°Æ‰øùËøêÂä®ÂíåË∫´‰ªΩ‰πãÈó¥ÁöÑÊ∏ÖÊô∞Ëß£ËÄ¶„ÄÇÊ≠§Â§ñÔºå‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑÊµÅÂåπÈÖçËøêÂä®ÁîüÊàêÂô®‰ªéÈü≥È¢ë„ÄÅÂßøÂäøÂíåËßÜÁ∫øÁ∫øÁ¥¢‰∏≠‰∫ßÁîüÁîüÂä®‰∏îÂèØÊéßÁöÑÈöêÂºèËøêÂä®ÂêëÈáè„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåIMTalkerÂú®ËøêÂä®Á≤æÂ∫¶„ÄÅË∫´‰ªΩ‰øùÊåÅÂíåÈü≥È¢ë-Âò¥ÂîáÂêåÊ≠•ÊñπÈù¢Ë∂ÖË∂ä‰∫ÜÁé∞ÊúâÊñπÊ≥ïÔºå‰ª•ÂçìË∂äÁöÑÊïàÁéáÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑË¥®ÈáèÔºåÂú®RTX 4090 GPU‰∏äÔºåËßÜÈ¢ëÈ©±Âä®ÁîüÊàêÈÄüÂ∫¶‰∏∫40 FPSÔºåÈü≥È¢ëÈ©±Âä®ÁîüÊàêÈÄüÂ∫¶‰∏∫42 FPS„ÄÇÊàë‰ª¨Â∞ÜÂèëÂ∏ÉÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂíåÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºå‰ª•‰øÉËøõÂ∫îÁî®ÂíåÊú™Êù•ÁöÑÁ†îÁ©∂„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËØ¥ËØù‰∫∫ËÑ∏ÁîüÊàêÊó®Âú®‰ªéÂçïÂº†ÂõæÂÉèÂêàÊàêÈÄºÁúüÁöÑËØ¥ËØù‰∫∫ÂÉè„ÄÇÁé∞ÊúâÊñπÊ≥ï‰æùËµñÊòæÂºèÂÖâÊµÅÂíåÂ±ÄÈÉ®Êâ≠Êõ≤ÔºåÈöæ‰ª•Âª∫Ê®°Â§çÊùÇÁöÑÂÖ®Â±ÄËøêÂä®ÔºåÂØºËá¥Ë∫´‰ªΩÊºÇÁßªÔºåÁîüÊàêÊïàÊûú‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöIMTalkerÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØ‰ΩøÁî®‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂Êù•ÈöêÂºèÂú∞Âª∫Ê®°ËøêÂä®Â∑ÆÂºÇÂíåË∫´‰ªΩÂØπÈΩêÔºå‰ªéËÄåÈÅøÂÖç‰∫Ü‰º†ÁªüÊñπÊ≥ï‰∏≠ÊòæÂºèÂÖâÊµÅËÆ°ÁÆóÂíåÂ±ÄÈÉ®Êâ≠Êõ≤Â∏¶Êù•ÁöÑÈóÆÈ¢ò„ÄÇÈÄöËøáÂú®ÊΩúÂú®Á©∫Èó¥‰∏≠ËøõË°åÊìç‰ΩúÔºåËÉΩÂ§üÊõ¥Â•ΩÂú∞ÊçïÊçâÂÖ®Â±ÄËøêÂä®ÔºåÂπ∂‰øùÊåÅË∫´‰ªΩ‰ø°ÊÅØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöIMTalkerÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) ‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑÊµÅÂåπÈÖçËøêÂä®ÁîüÊàêÂô®ÔºåÁî®‰∫é‰ªéÈü≥È¢ë„ÄÅÂßøÂäøÂíåËßÜÁ∫øÁ∫øÁ¥¢‰∏≠ÁîüÊàêÈöêÂºèËøêÂä®ÂêëÈáèÔºõ2) ‰∏Ä‰∏™‰∫§ÂèâÊ≥®ÊÑèÂäõÊ®°ÂùóÔºåÁî®‰∫éÂú®Ê∫êÂõæÂÉèÂíåÈ©±Âä®‰ø°Âè∑‰πãÈó¥ËøõË°åËøêÂä®‰º†ÈÄíÂíåË∫´‰ªΩÂØπÈΩêÔºõ3) ‰∏Ä‰∏™Ë∫´‰ªΩËá™ÈÄÇÂ∫îÊ®°ÂùóÔºåÁî®‰∫éÂ∞ÜËøêÂä®ÊΩúÂú®ÂêëÈáèÊäïÂΩ±Âà∞‰∏™ÊÄßÂåñÁöÑÁ©∫Èó¥‰∏≠Ôºå‰ª•‰øùÊåÅËØ¥ËØù‰∫∫ÁöÑË∫´‰ªΩ„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÔºåÈ¶ñÂÖàÈÄöËøáËøêÂä®ÁîüÊàêÂô®ÂæóÂà∞ËøêÂä®‰ø°ÊÅØÔºåÁÑ∂ÂêéÈÄöËøá‰∫§ÂèâÊ≥®ÊÑèÂäõÂíåË∫´‰ªΩËá™ÈÄÇÂ∫îÊ®°ÂùóÂ∞ÜËøêÂä®‰ø°ÊÅØ‰º†ÈÄíÂà∞Ê∫êÂõæÂÉèÔºåÊúÄÁªàÁîüÊàêËØ¥ËØù‰∫∫ËÑ∏„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöIMTalkerÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ΩøÁî®‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂ËøõË°åÈöêÂºèËøêÂä®‰º†ÈÄíÔºåÂèñ‰ª£‰∫Ü‰º†ÁªüÊñπÊ≥ï‰∏≠Âü∫‰∫éÂÖâÊµÅÁöÑÊòæÂºèËøêÂä®‰º†ÈÄí„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊõ¥Â•ΩÂú∞ÊçïÊçâÂÖ®Â±ÄËøêÂä®ÔºåÂπ∂‰øùÊåÅË∫´‰ªΩ‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåË∫´‰ªΩËá™ÈÄÇÂ∫îÊ®°ÂùóÁöÑËÆæËÆ°‰πüÊúâÊïàÂú∞Ëß£ÂÜ≥‰∫ÜË∑®Ë∫´‰ªΩÈáçÊºî‰∏≠ÁöÑË∫´‰ªΩÊºÇÁßªÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËøêÂä®ÁîüÊàêÂô®ÈááÁî®ÊµÅÂåπÈÖçÊ®°ÂûãÔºåËÉΩÂ§üÁîüÊàêÁîüÂä®‰∏îÂèØÊéßÁöÑÈöêÂºèËøêÂä®ÂêëÈáè„ÄÇ‰∫§ÂèâÊ≥®ÊÑèÂäõÊ®°Âùó‰ΩøÁî®Â§öÂ§¥Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåËÉΩÂ§üÊçïÊçâ‰∏çÂêåÂ∞∫Â∫¶ÁöÑËøêÂä®‰ø°ÊÅØ„ÄÇË∫´‰ªΩËá™ÈÄÇÂ∫îÊ®°ÂùóÈÄöËøáÂ≠¶‰π†‰∏Ä‰∏™Êò†Â∞ÑÂáΩÊï∞ÔºåÂ∞ÜËøêÂä®ÊΩúÂú®ÂêëÈáèÊäïÂΩ±Âà∞‰∏™ÊÄßÂåñÁöÑÁ©∫Èó¥‰∏≠„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÈáçÂª∫ÊçüÂ§±„ÄÅÂØπÊäóÊçüÂ§±ÂíåË∫´‰ªΩ‰øùÊåÅÊçüÂ§±ÔºåÁî®‰∫é‰øùËØÅÁîüÊàêÂõæÂÉèÁöÑË¥®ÈáèÂíåË∫´‰ªΩ‰∏ÄËá¥ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

IMTalkerÂú®ËøêÂä®Á≤æÂ∫¶„ÄÅË∫´‰ªΩ‰øùÊåÅÂíåÈü≥È¢ë-Âò¥ÂîáÂêåÊ≠•ÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÂú®RTX 4090 GPU‰∏äÔºåËßÜÈ¢ëÈ©±Âä®ÁîüÊàêÈÄüÂ∫¶ËææÂà∞40 FPSÔºåÈü≥È¢ëÈ©±Âä®ÁîüÊàêÈÄüÂ∫¶ËææÂà∞42 FPSÔºåÂÆûÁé∞‰∫ÜÈ´òÊïàÁöÑËØ¥ËØù‰∫∫ËÑ∏ÁîüÊàê„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåIMTalkerËÉΩÂ§üÁîüÊàêÈ´òË¥®ÈáèÁöÑËØ¥ËØù‰∫∫ËÑ∏ÔºåÂêåÊó∂‰øùÊåÅËØ¥ËØù‰∫∫ÁöÑË∫´‰ªΩ‰ø°ÊÅØ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

IMTalkerÂèØÂ∫îÁî®‰∫éËôöÊãüÂΩ¢Ë±°ÁîüÊàê„ÄÅËßÜÈ¢ë‰ºöËÆÆ„ÄÅÁîµÂΩ±Âà∂‰Ωú„ÄÅÊ∏∏ÊàèÂºÄÂèëÁ≠âÈ¢ÜÂüü„ÄÇËØ•ÊäÄÊúØËÉΩÂ§üÁîüÊàêÈÄºÁúü‰∏îËá™ÁÑ∂ÁöÑËØ¥ËØù‰∫∫ËÑ∏ÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™åÔºåÈôç‰ΩéÂà∂‰ΩúÊàêÊú¨„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂ∫îÁî®‰∫é‰∏™ÊÄßÂåñÊïôËÇ≤„ÄÅÊô∫ËÉΩÂÆ¢ÊúçÁ≠âÈ¢ÜÂüüÔºåÂÆûÁé∞Êõ¥Êô∫ËÉΩÁöÑ‰∫∫Êú∫‰∫§‰∫í„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Talking face generation aims to synthesize realistic speaking portraits from a single image, yet existing methods often rely on explicit optical flow and local warping, which fail to model complex global motions and cause identity drift. We present IMTalker, a novel framework that achieves efficient and high-fidelity talking face generation through implicit motion transfer. The core idea is to replace traditional flow-based warping with a cross-attention mechanism that implicitly models motion discrepancy and identity alignment within a unified latent space, enabling robust global motion rendering. To further preserve speaker identity during cross-identity reenactment, we introduce an identity-adaptive module that projects motion latents into personalized spaces, ensuring clear disentanglement between motion and identity. In addition, a lightweight flow-matching motion generator produces vivid and controllable implicit motion vectors from audio, pose, and gaze cues. Extensive experiments demonstrate that IMTalker surpasses prior methods in motion accuracy, identity preservation, and audio-lip synchronization, achieving state-of-the-art quality with superior efficiency, operating at 40 FPS for video-driven and 42 FPS for audio-driven generation on an RTX 4090 GPU. We will release our code and pre-trained models to facilitate applications and future research.

