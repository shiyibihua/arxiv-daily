---
layout: default
title: DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action
---

# DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action

**arXiv**: [2511.22134v1](https://arxiv.org/abs/2511.22134) | [PDF](https://arxiv.org/pdf/2511.22134.pdf)

**ä½œè€…**: Zhen Fang, Zhuoyang Liu, Jiaming Liu, Hao Chen, Yu Zeng, Shiting Huang, Zehui Chen, Lin Chen, Shanghang Zhang, Feng Zhao

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-27

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://costaliya.github.io/DualVLA/)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DualVLAï¼šé€šè¿‡è§£è€¦æŽ¨ç†ä¸ŽåŠ¨ä½œï¼Œæž„å»ºå¯æ³›åŒ–çš„å…·èº«æ™ºèƒ½ä½“**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å…·èº«æ™ºèƒ½` `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `åŠ¨ä½œé€€åŒ–` `æ•°æ®å‰ªæž` `çŸ¥è¯†è’¸é¦` `å¤šæ¨¡æ€å­¦ä¹ ` `æœºå™¨äººæ“ä½œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VLAæ¨¡åž‹åœ¨èžåˆæŽ¨ç†èƒ½åŠ›æ—¶ï¼Œå¸¸å‡ºçŽ°åŠ¨ä½œæ€§èƒ½ä¸‹é™çš„â€œåŠ¨ä½œé€€åŒ–â€é—®é¢˜ï¼Œé™åˆ¶äº†é€šç”¨æ€§ã€‚
2. DualVLAé€šè¿‡åŒå±‚æ•°æ®å‰ªæžæ¶ˆé™¤å†—ä½™æŽ¨ç†ï¼Œå¹¶é‡‡ç”¨åŒæ•™å¸ˆè‡ªé€‚åº”è’¸é¦å¼ºåŒ–åŠ¨ä½œç”Ÿæˆï¼Œä¿æŒæŽ¨ç†èƒ½åŠ›ã€‚
3. DualVLAåœ¨SimplerEnvå’Œå¤šä¸ªå¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­è¡¨çŽ°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶åœ¨åŠ¨ä½œæ‰§è¡Œå’Œå¤šæ¨¡æ€ç†è§£ä¸Šçš„å¹³è¡¡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†æž„å»ºå…·æœ‰å¼ºå¤§æŽ¨ç†èƒ½åŠ›çš„å¯æ³›åŒ–è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹ï¼Œä¸€ç§å¸¸è§ç­–ç•¥æ˜¯é¦–å…ˆåœ¨æœºå™¨äººæ¼”ç¤ºæ•°æ®ä¸Šè®­ç»ƒä¸€ä¸ªä¸“å®¶VLAæ¨¡åž‹ï¼Œä»¥èŽ·å¾—å¯é çš„æ“ä½œæŠ€èƒ½ï¼Œç„¶åŽç»“åˆæ··åˆæ ‡æ³¨çš„æœºå™¨äººæ•°æ®å’Œå¤šæ¨¡æ€æ•°æ®ï¼Œä»¥æ¢å¤æ›´å¹¿æ³›çš„æŽ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œä¸Žå¾®è°ƒå‰çš„ä¸“å®¶æ¨¡åž‹ç›¸æ¯”ï¼Œç”±æ­¤äº§ç”Ÿçš„æŽ¨ç†VLAæ¨¡åž‹é€šå¸¸ä¼šå‡ºçŽ°åŠ¨ä½œæ€§èƒ½ä¸‹é™ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºåŠ¨ä½œé€€åŒ–çŽ°è±¡ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†DualVLAï¼Œå®ƒé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„åŽè®­ç»ƒæ¥å¢žå¼ºåŠ¨ä½œæ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒæŽ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬é¦–å…ˆå¼•å…¥äº†ä¸€ç§åŒå±‚æ•°æ®å‰ªæžæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ¶ˆé™¤äº†å†—ä½™çš„å…·èº«æŽ¨ç†ï¼Œé˜²æ­¢å…¶å¯¹åŠ¨ä½œå­¦ä¹ äº§ç”Ÿä¸åˆ©å½±å“ã€‚ä¸ºäº†è¿›ä¸€æ­¥åŠ å¼ºåŠ¨ä½œç”Ÿæˆï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åŒæ•™å¸ˆè‡ªé€‚åº”è’¸é¦ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ä¸ºä¸åŒçš„æ•°æ®åŸŸåˆ†é…ä¸åŒçš„ç›‘ç£ä¿¡å·ï¼ŒåŒæ—¶ä¿æŒæŽ¨ç†èƒ½åŠ›ã€‚ä¸ºäº†å¡«è¡¥é€šç”¨VLAçš„è¯„ä¼°ç©ºç™½ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†VLA Scoreï¼Œå®ƒå°†VLAèƒ½åŠ›è§£è€¦ä¸ºæŽ¨ç†ã€æ„å›¾ã€åŠ¨ä½œå’Œå¯¹é½ç»´åº¦ï¼Œä»¥ä¾¿è¿›è¡Œæ›´ç»†ç²’åº¦çš„è¯„ä¼°ã€‚å®žéªŒè¡¨æ˜Žï¼ŒDualVLAåœ¨SimplerEnvä¸­å®žçŽ°äº†61.0çš„å¹³å‡æˆåŠŸçŽ‡ï¼Œå¹¶åœ¨å…«ä¸ªç«žäº‰æ€§å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­å®žçŽ°äº†65.4çš„å¹³å‡åˆ†æ•°ï¼Œè¡¨æ˜Žåœ¨ç²¾ç¡®çš„åŠ¨ä½œæ‰§è¡Œå’Œå¤šæ¨¡æ€ç†è§£ä¹‹é—´å–å¾—äº†æ›´å¼ºçš„å¹³è¡¡ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³é€šç”¨è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹åœ¨èžåˆæŽ¨ç†èƒ½åŠ›æ—¶å‡ºçŽ°çš„â€œåŠ¨ä½œé€€åŒ–â€é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸å…ˆè®­ç»ƒä¸€ä¸ªæ“…é•¿åŠ¨ä½œçš„VLAæ¨¡åž‹ï¼Œç„¶åŽé€šè¿‡æ··åˆæ•°æ®è¿›è¡Œå¾®è°ƒä»¥æå‡æŽ¨ç†èƒ½åŠ›ï¼Œä½†å¾®è°ƒåŽåŠ¨ä½œæ€§èƒ½ä¼šæ˜¾è‘—ä¸‹é™ï¼Œé™åˆ¶äº†æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDualVLAçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨åŽè®­ç»ƒé˜¶æ®µï¼Œé€šè¿‡è§£è€¦æŽ¨ç†å’ŒåŠ¨ä½œçš„å­¦ä¹ è¿‡ç¨‹ï¼Œåœ¨ä¿æŒæŽ¨ç†èƒ½åŠ›çš„åŒæ—¶ï¼Œæå‡åŠ¨ä½œæ‰§è¡Œçš„ç²¾ç¡®æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡æ•°æ®å‰ªæžå‡å°‘æŽ¨ç†å¯¹åŠ¨ä½œå­¦ä¹ çš„å¹²æ‰°ï¼Œå¹¶é€šè¿‡è‡ªé€‚åº”è’¸é¦å¼ºåŒ–åŠ¨ä½œç”Ÿæˆã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šDualVLAåŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) é¢„è®­ç»ƒçš„VLAæ¨¡åž‹ï¼ˆä¸“å®¶æ¨¡åž‹ï¼‰ï¼›2) åŒå±‚æ•°æ®å‰ªæžæ¨¡å—ï¼Œç”¨äºŽåŽ»é™¤å†—ä½™çš„å…·èº«æŽ¨ç†æ•°æ®ï¼›3) åŒæ•™å¸ˆè‡ªé€‚åº”è’¸é¦æ¨¡å—ï¼Œåˆ©ç”¨ä¸“å®¶æ¨¡åž‹å’ŒæŽ¨ç†æ¨¡åž‹ä½œä¸ºæ•™å¸ˆï¼ŒæŒ‡å¯¼å­¦ç”Ÿæ¨¡åž‹å­¦ä¹ ï¼›4) VLA Scoreè¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºŽç»†ç²’åº¦è¯„ä¼°VLAæ¨¡åž‹çš„æŽ¨ç†ã€æ„å›¾ã€åŠ¨ä½œå’Œå¯¹é½èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šDualVLAçš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) æå‡ºäº†åŒå±‚æ•°æ®å‰ªæžæ–¹æ³•ï¼Œæœ‰æ•ˆå‡å°‘äº†æŽ¨ç†æ•°æ®å¯¹åŠ¨ä½œå­¦ä¹ çš„è´Ÿé¢å½±å“ï¼›2) è®¾è®¡äº†åŒæ•™å¸ˆè‡ªé€‚åº”è’¸é¦ç­–ç•¥ï¼Œèƒ½å¤Ÿæ ¹æ®æ•°æ®åŸŸçš„ä¸åŒï¼Œè‡ªé€‚åº”åœ°åˆ†é…ä¸åŒçš„ç›‘ç£ä¿¡å·ï¼Œä»Žè€Œåœ¨ä¿æŒæŽ¨ç†èƒ½åŠ›çš„åŒæ—¶ï¼Œæå‡åŠ¨ä½œæ‰§è¡Œçš„ç²¾åº¦ï¼›3) æå‡ºäº†VLA Scoreè¯„ä¼°æŒ‡æ ‡ï¼Œä¸ºé€šç”¨VLAæ¨¡åž‹çš„è¯„ä¼°æä¾›äº†ä¸€ç§æ›´ç»†ç²’åº¦çš„æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåŒå±‚æ•°æ®å‰ªæžçš„å…·ä½“å®žçŽ°æœªçŸ¥ï¼Œä½†å…¶ç›®æ ‡æ˜¯åŽ»é™¤å¯¹åŠ¨ä½œå­¦ä¹ æ— ç›Šçš„æŽ¨ç†æ•°æ®ã€‚åŒæ•™å¸ˆè‡ªé€‚åº”è’¸é¦ç­–ç•¥ä¸­ï¼Œå¦‚ä½•ç¡®å®šä¸åŒæ•°æ®åŸŸçš„ç›‘ç£ä¿¡å·åˆ†é…æ¯”ä¾‹æ˜¯å…³é”®è®¾è®¡ã€‚VLA Scoreè¯„ä¼°æŒ‡æ ‡çš„å…·ä½“è®¡ç®—æ–¹æ³•æœªçŸ¥ï¼Œä½†å…¶è€ƒè™‘äº†æŽ¨ç†ã€æ„å›¾ã€åŠ¨ä½œå’Œå¯¹é½å››ä¸ªç»´åº¦ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

DualVLAåœ¨SimplerEnvçŽ¯å¢ƒä¸­å–å¾—äº†61.0%çš„å¹³å‡æˆåŠŸçŽ‡ï¼Œç›¸è¾ƒäºŽåŸºçº¿æ¨¡åž‹æœ‰æ˜¾è‘—æå‡ã€‚åœ¨å…«ä¸ªç«žäº‰æ€§å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­ï¼ŒDualVLAèŽ·å¾—äº†65.4çš„å¹³å‡åˆ†æ•°ï¼Œè¡¨æ˜Žå…¶åœ¨å¤šæ¨¡æ€ç†è§£æ–¹é¢å…·æœ‰ä¼˜åŠ¿ã€‚è¿™äº›å®žéªŒç»“æžœéªŒè¯äº†DualVLAåœ¨åŠ¨ä½œæ‰§è¡Œå’Œå¤šæ¨¡æ€ç†è§£ä¹‹é—´çš„å¹³è¡¡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

DualVLAçš„ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½å®¶å±…ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡å…·èº«æ™ºèƒ½ä½“çš„é€šç”¨æ€§å’ŒåŠ¨ä½œæ‰§è¡Œèƒ½åŠ›ï¼Œå¯ä»¥ä½¿å…¶æ›´å¥½åœ°ç†è§£äººç±»æŒ‡ä»¤ï¼Œå®Œæˆå¤æ‚ä»»åŠ¡ï¼Œå¹¶ä¸ŽçŽ¯å¢ƒè¿›è¡Œæ›´æœ‰æ•ˆçš„äº¤äº’ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºŽæŽ¨åŠ¨äººæœºåä½œå’Œæ™ºèƒ½è‡ªåŠ¨åŒ–çš„å‘å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> To build a generalizable Vision-Language-Action (VLA) model with strong reasoning ability, a common strategy is to first train a specialist VLA on robot demonstrations to acquire reliable manipulation skills, and then incorporate mixed annotated robot data together with multimodal data to restore broader reasoning capabilities. However, we observe that the resulting reasoning VLA often suffers from degraded action performance compared to the specialist model before fine-tuning, a phenomenon we refer to as action degeneration. To address this issue, we propose DualVLA, which enhances action performance through carefully designed post-training while still preserving reasoning capability. We first introduce a dual-layer data pruning method that removes redundant embodied reasoning, preventing it from adversely influencing action learning. To further strengthen action generation, we design a dual-teacher adaptive distillation strategy that assigns different supervision signals to different data domains while maintaining reasoning ability. To fill the evaluation gap for generalist VLAs, we also propose VLA Score, which decouples VLA capability into reasoning, intention, action, and alignment dimensions for a more fine-grained assessment. Experiments show that DualVLA achieves an average success rate of 61.0 in SimplerEnv and an average score of 65.4 across eight competitive multimodal benchmarks, demonstrating a stronger balance between precise action execution and multimodal understanding. Project Website: https://costaliya.github.io/DualVLA/.

