---
layout: default
title: DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action
---

# DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.22134" target="_blank" class="toolbar-btn">arXiv: 2511.22134v1</a>
    <a href="https://arxiv.org/pdf/2511.22134.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.22134v1" 
            onclick="toggleFavorite(this, '2511.22134v1', 'DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Zhen Fang, Zhuoyang Liu, Jiaming Liu, Hao Chen, Yu Zeng, Shiting Huang, Zehui Chen, Lin Chen, Shanghang Zhang, Feng Zhao

**ÂàÜÁ±ª**: cs.CV, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-27

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://costaliya.github.io/DualVLA/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**DualVLAÔºöÈÄöËøáËß£ËÄ¶Êé®ÁêÜ‰∏éÂä®‰ΩúÔºåÊûÑÂª∫ÂèØÊ≥õÂåñÁöÑÂÖ∑Ë∫´Êô∫ËÉΩ‰Ωì**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `ÂÖ∑Ë∫´Êô∫ËÉΩ` `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã` `Âä®‰ΩúÈÄÄÂåñ` `Êï∞ÊçÆÂâ™Êûù` `Áü•ËØÜËí∏È¶è` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Êú∫Âô®‰∫∫Êìç‰Ωú`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLAÊ®°ÂûãÂú®ËûçÂêàÊé®ÁêÜËÉΩÂäõÊó∂ÔºåÂ∏∏Âá∫Áé∞Âä®‰ΩúÊÄßËÉΩ‰∏ãÈôçÁöÑ‚ÄúÂä®‰ΩúÈÄÄÂåñ‚ÄùÈóÆÈ¢òÔºåÈôêÂà∂‰∫ÜÈÄöÁî®ÊÄß„ÄÇ
2. DualVLAÈÄöËøáÂèåÂ±ÇÊï∞ÊçÆÂâ™ÊûùÊ∂àÈô§ÂÜó‰ΩôÊé®ÁêÜÔºåÂπ∂ÈááÁî®ÂèåÊïôÂ∏àËá™ÈÄÇÂ∫îËí∏È¶èÂº∫ÂåñÂä®‰ΩúÁîüÊàêÔºå‰øùÊåÅÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. DualVLAÂú®SimplerEnvÂíåÂ§ö‰∏™Â§öÊ®°ÊÄÅÂü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®Âä®‰ΩúÊâßË°åÂíåÂ§öÊ®°ÊÄÅÁêÜËß£‰∏äÁöÑÂπ≥Ë°°„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∏∫‰∫ÜÊûÑÂª∫ÂÖ∑ÊúâÂº∫Â§ßÊé®ÁêÜËÉΩÂäõÁöÑÂèØÊ≥õÂåñËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÔºàVLAÔºâÊ®°ÂûãÔºå‰∏ÄÁßçÂ∏∏ËßÅÁ≠ñÁï•ÊòØÈ¶ñÂÖàÂú®Êú∫Âô®‰∫∫ÊºîÁ§∫Êï∞ÊçÆ‰∏äËÆ≠ÁªÉ‰∏Ä‰∏™‰∏ìÂÆ∂VLAÊ®°ÂûãÔºå‰ª•Ëé∑ÂæóÂèØÈù†ÁöÑÊìç‰ΩúÊäÄËÉΩÔºåÁÑ∂ÂêéÁªìÂêàÊ∑∑ÂêàÊ†áÊ≥®ÁöÑÊú∫Âô®‰∫∫Êï∞ÊçÆÂíåÂ§öÊ®°ÊÄÅÊï∞ÊçÆÔºå‰ª•ÊÅ¢Â§çÊõ¥ÂπøÊ≥õÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊàë‰ª¨ËßÇÂØüÂà∞Ôºå‰∏éÂæÆË∞ÉÂâçÁöÑ‰∏ìÂÆ∂Ê®°ÂûãÁõ∏ÊØîÔºåÁî±Ê≠§‰∫ßÁîüÁöÑÊé®ÁêÜVLAÊ®°ÂûãÈÄöÂ∏∏‰ºöÂá∫Áé∞Âä®‰ΩúÊÄßËÉΩ‰∏ãÈôçÔºåÊàë‰ª¨Áß∞‰πã‰∏∫Âä®‰ΩúÈÄÄÂåñÁé∞Ë±°„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜDualVLAÔºåÂÆÉÈÄöËøáÁ≤æÂøÉËÆæËÆ°ÁöÑÂêéËÆ≠ÁªÉÊù•Â¢ûÂº∫Âä®‰ΩúÊÄßËÉΩÔºåÂêåÊó∂‰øùÊåÅÊé®ÁêÜËÉΩÂäõ„ÄÇÊàë‰ª¨È¶ñÂÖàÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂèåÂ±ÇÊï∞ÊçÆÂâ™ÊûùÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÊ∂àÈô§‰∫ÜÂÜó‰ΩôÁöÑÂÖ∑Ë∫´Êé®ÁêÜÔºåÈò≤Ê≠¢ÂÖ∂ÂØπÂä®‰ΩúÂ≠¶‰π†‰∫ßÁîü‰∏çÂà©ÂΩ±Âìç„ÄÇ‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•Âä†Âº∫Âä®‰ΩúÁîüÊàêÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏ÄÁßçÂèåÊïôÂ∏àËá™ÈÄÇÂ∫îËí∏È¶èÁ≠ñÁï•ÔºåËØ•Á≠ñÁï•‰∏∫‰∏çÂêåÁöÑÊï∞ÊçÆÂüüÂàÜÈÖç‰∏çÂêåÁöÑÁõëÁù£‰ø°Âè∑ÔºåÂêåÊó∂‰øùÊåÅÊé®ÁêÜËÉΩÂäõ„ÄÇ‰∏∫‰∫ÜÂ°´Ë°•ÈÄöÁî®VLAÁöÑËØÑ‰º∞Á©∫ÁôΩÔºåÊàë‰ª¨ËøòÊèêÂá∫‰∫ÜVLA ScoreÔºåÂÆÉÂ∞ÜVLAËÉΩÂäõËß£ËÄ¶‰∏∫Êé®ÁêÜ„ÄÅÊÑèÂõæ„ÄÅÂä®‰ΩúÂíåÂØπÈΩêÁª¥Â∫¶Ôºå‰ª•‰æøËøõË°åÊõ¥ÁªÜÁ≤íÂ∫¶ÁöÑËØÑ‰º∞„ÄÇÂÆûÈ™åË°®ÊòéÔºåDualVLAÂú®SimplerEnv‰∏≠ÂÆûÁé∞‰∫Ü61.0ÁöÑÂπ≥ÂùáÊàêÂäüÁéáÔºåÂπ∂Âú®ÂÖ´‰∏™Á´û‰∫âÊÄßÂ§öÊ®°ÊÄÅÂü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫Ü65.4ÁöÑÂπ≥ÂùáÂàÜÊï∞ÔºåË°®ÊòéÂú®Á≤æÁ°ÆÁöÑÂä®‰ΩúÊâßË°åÂíåÂ§öÊ®°ÊÄÅÁêÜËß£‰πãÈó¥ÂèñÂæó‰∫ÜÊõ¥Âº∫ÁöÑÂπ≥Ë°°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÈÄöÁî®ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÔºàVLAÔºâÊ®°ÂûãÂú®ËûçÂêàÊé®ÁêÜËÉΩÂäõÊó∂Âá∫Áé∞ÁöÑ‚ÄúÂä®‰ΩúÈÄÄÂåñ‚ÄùÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÂÖàËÆ≠ÁªÉ‰∏Ä‰∏™ÊìÖÈïøÂä®‰ΩúÁöÑVLAÊ®°ÂûãÔºåÁÑ∂ÂêéÈÄöËøáÊ∑∑ÂêàÊï∞ÊçÆËøõË°åÂæÆË∞É‰ª•ÊèêÂçáÊé®ÁêÜËÉΩÂäõÔºå‰ΩÜÂæÆË∞ÉÂêéÂä®‰ΩúÊÄßËÉΩ‰ºöÊòæËëó‰∏ãÈôçÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöDualVLAÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂú®ÂêéËÆ≠ÁªÉÈò∂ÊÆµÔºåÈÄöËøáËß£ËÄ¶Êé®ÁêÜÂíåÂä®‰ΩúÁöÑÂ≠¶‰π†ËøáÁ®ãÔºåÂú®‰øùÊåÅÊé®ÁêÜËÉΩÂäõÁöÑÂêåÊó∂ÔºåÊèêÂçáÂä®‰ΩúÊâßË°åÁöÑÁ≤æÁ°ÆÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈÄöËøáÊï∞ÊçÆÂâ™ÊûùÂáèÂ∞ëÊé®ÁêÜÂØπÂä®‰ΩúÂ≠¶‰π†ÁöÑÂπ≤Êâ∞ÔºåÂπ∂ÈÄöËøáËá™ÈÄÇÂ∫îËí∏È¶èÂº∫ÂåñÂä®‰ΩúÁîüÊàê„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöDualVLAÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) È¢ÑËÆ≠ÁªÉÁöÑVLAÊ®°ÂûãÔºà‰∏ìÂÆ∂Ê®°ÂûãÔºâÔºõ2) ÂèåÂ±ÇÊï∞ÊçÆÂâ™ÊûùÊ®°ÂùóÔºåÁî®‰∫éÂéªÈô§ÂÜó‰ΩôÁöÑÂÖ∑Ë∫´Êé®ÁêÜÊï∞ÊçÆÔºõ3) ÂèåÊïôÂ∏àËá™ÈÄÇÂ∫îËí∏È¶èÊ®°ÂùóÔºåÂà©Áî®‰∏ìÂÆ∂Ê®°ÂûãÂíåÊé®ÁêÜÊ®°Âûã‰Ωú‰∏∫ÊïôÂ∏àÔºåÊåáÂØºÂ≠¶ÁîüÊ®°ÂûãÂ≠¶‰π†Ôºõ4) VLA ScoreËØÑ‰º∞ÊåáÊ†áÔºåÁî®‰∫éÁªÜÁ≤íÂ∫¶ËØÑ‰º∞VLAÊ®°ÂûãÁöÑÊé®ÁêÜ„ÄÅÊÑèÂõæ„ÄÅÂä®‰ΩúÂíåÂØπÈΩêËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöDualVLAÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫ÜÂèåÂ±ÇÊï∞ÊçÆÂâ™ÊûùÊñπÊ≥ïÔºåÊúâÊïàÂáèÂ∞ë‰∫ÜÊé®ÁêÜÊï∞ÊçÆÂØπÂä®‰ΩúÂ≠¶‰π†ÁöÑË¥üÈù¢ÂΩ±ÂìçÔºõ2) ËÆæËÆ°‰∫ÜÂèåÊïôÂ∏àËá™ÈÄÇÂ∫îËí∏È¶èÁ≠ñÁï•ÔºåËÉΩÂ§üÊ†πÊçÆÊï∞ÊçÆÂüüÁöÑ‰∏çÂêåÔºåËá™ÈÄÇÂ∫îÂú∞ÂàÜÈÖç‰∏çÂêåÁöÑÁõëÁù£‰ø°Âè∑Ôºå‰ªéËÄåÂú®‰øùÊåÅÊé®ÁêÜËÉΩÂäõÁöÑÂêåÊó∂ÔºåÊèêÂçáÂä®‰ΩúÊâßË°åÁöÑÁ≤æÂ∫¶Ôºõ3) ÊèêÂá∫‰∫ÜVLA ScoreËØÑ‰º∞ÊåáÊ†áÔºå‰∏∫ÈÄöÁî®VLAÊ®°ÂûãÁöÑËØÑ‰º∞Êèê‰æõ‰∫Ü‰∏ÄÁßçÊõ¥ÁªÜÁ≤íÂ∫¶ÁöÑÊñπÊ≥ï„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂèåÂ±ÇÊï∞ÊçÆÂâ™ÊûùÁöÑÂÖ∑‰ΩìÂÆûÁé∞Êú™Áü•Ôºå‰ΩÜÂÖ∂ÁõÆÊ†áÊòØÂéªÈô§ÂØπÂä®‰ΩúÂ≠¶‰π†Êó†ÁõäÁöÑÊé®ÁêÜÊï∞ÊçÆ„ÄÇÂèåÊïôÂ∏àËá™ÈÄÇÂ∫îËí∏È¶èÁ≠ñÁï•‰∏≠ÔºåÂ¶Ç‰ΩïÁ°ÆÂÆö‰∏çÂêåÊï∞ÊçÆÂüüÁöÑÁõëÁù£‰ø°Âè∑ÂàÜÈÖçÊØî‰æãÊòØÂÖ≥ÈîÆËÆæËÆ°„ÄÇVLA ScoreËØÑ‰º∞ÊåáÊ†áÁöÑÂÖ∑‰ΩìËÆ°ÁÆóÊñπÊ≥ïÊú™Áü•Ôºå‰ΩÜÂÖ∂ËÄÉËôë‰∫ÜÊé®ÁêÜ„ÄÅÊÑèÂõæ„ÄÅÂä®‰ΩúÂíåÂØπÈΩêÂõõ‰∏™Áª¥Â∫¶„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

DualVLAÂú®SimplerEnvÁéØÂ¢É‰∏≠ÂèñÂæó‰∫Ü61.0%ÁöÑÂπ≥ÂùáÊàêÂäüÁéáÔºåÁõ∏ËæÉ‰∫éÂü∫Á∫øÊ®°ÂûãÊúâÊòæËëóÊèêÂçá„ÄÇÂú®ÂÖ´‰∏™Á´û‰∫âÊÄßÂ§öÊ®°ÊÄÅÂü∫ÂáÜÊµãËØï‰∏≠ÔºåDualVLAËé∑Âæó‰∫Ü65.4ÁöÑÂπ≥ÂùáÂàÜÊï∞ÔºåË°®ÊòéÂÖ∂Âú®Â§öÊ®°ÊÄÅÁêÜËß£ÊñπÈù¢ÂÖ∑Êúâ‰ºòÂäø„ÄÇËøô‰∫õÂÆûÈ™åÁªìÊûúÈ™åËØÅ‰∫ÜDualVLAÂú®Âä®‰ΩúÊâßË°åÂíåÂ§öÊ®°ÊÄÅÁêÜËß£‰πãÈó¥ÁöÑÂπ≥Ë°°„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

DualVLAÁöÑÁ†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÂÆ∂Â±ÖÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÂçáÂÖ∑Ë∫´Êô∫ËÉΩ‰ΩìÁöÑÈÄöÁî®ÊÄßÂíåÂä®‰ΩúÊâßË°åËÉΩÂäõÔºåÂèØ‰ª•‰ΩøÂÖ∂Êõ¥Â•ΩÂú∞ÁêÜËß£‰∫∫Á±ªÊåá‰ª§ÔºåÂÆåÊàêÂ§çÊùÇ‰ªªÂä°ÔºåÂπ∂‰∏éÁéØÂ¢ÉËøõË°åÊõ¥ÊúâÊïàÁöÑ‰∫§‰∫í„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÊé®Âä®‰∫∫Êú∫Âçè‰ΩúÂíåÊô∫ËÉΩËá™Âä®ÂåñÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> To build a generalizable Vision-Language-Action (VLA) model with strong reasoning ability, a common strategy is to first train a specialist VLA on robot demonstrations to acquire reliable manipulation skills, and then incorporate mixed annotated robot data together with multimodal data to restore broader reasoning capabilities. However, we observe that the resulting reasoning VLA often suffers from degraded action performance compared to the specialist model before fine-tuning, a phenomenon we refer to as action degeneration. To address this issue, we propose DualVLA, which enhances action performance through carefully designed post-training while still preserving reasoning capability. We first introduce a dual-layer data pruning method that removes redundant embodied reasoning, preventing it from adversely influencing action learning. To further strengthen action generation, we design a dual-teacher adaptive distillation strategy that assigns different supervision signals to different data domains while maintaining reasoning ability. To fill the evaluation gap for generalist VLAs, we also propose VLA Score, which decouples VLA capability into reasoning, intention, action, and alignment dimensions for a more fine-grained assessment. Experiments show that DualVLA achieves an average success rate of 61.0 in SimplerEnv and an average score of 65.4 across eight competitive multimodal benchmarks, demonstrating a stronger balance between precise action execution and multimodal understanding. Project Website: https://costaliya.github.io/DualVLA/.

