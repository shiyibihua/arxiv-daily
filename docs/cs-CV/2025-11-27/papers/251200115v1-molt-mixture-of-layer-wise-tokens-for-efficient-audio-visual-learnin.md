---
layout: default
title: MoLT: Mixture of Layer-Wise Tokens for Efficient Audio-Visual Learning
---

# MoLT: Mixture of Layer-Wise Tokens for Efficient Audio-Visual Learning

**arXiv**: [2512.00115v1](https://arxiv.org/abs/2512.00115) | [PDF](https://arxiv.org/pdf/2512.00115.pdf)

**ä½œè€…**: Kyeongha Rho, Hyeongkeun Lee, Jae Won Cho, Joon Son Chung

**åˆ†ç±»**: cs.SD, cs.CV, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-11-27

**å¤‡æ³¨**: 10 pages, 5 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMoLTï¼Œé€šè¿‡æ··åˆå±‚çº§Tokenå®žçŽ°é«˜æ•ˆçš„éŸ³è§†é¢‘å­¦ä¹ ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `éŸ³è§†é¢‘å­¦ä¹ ` `å¤šæ¨¡æ€èžåˆ` `Transformer` `è‡ªé€‚åº”å­¦ä¹ ` `å±‚çº§Token`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰éŸ³è§†é¢‘å­¦ä¹ æ–¹æ³•åœ¨Transformerçš„æ¯ä¸€å±‚è¿›è¡Œä¸²è¡Œè‡ªé€‚åº”ï¼Œè®¡ç®—é‡å¤§ï¼Œæ•ˆçŽ‡ä½Žã€‚
2. MoLTé€šè¿‡å¹¶è¡Œçš„è½»é‡çº§æ–¹æ¡ˆï¼Œä»…ä»ŽTransformerçš„åŽæœŸå±‚æå–å’Œèžåˆå±‚çº§Tokenï¼Œå®žçŽ°é«˜æ•ˆè‡ªé€‚åº”ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒMoLTåœ¨éŸ³è§†é¢‘é—®ç­”ã€åˆ†å‰²å’Œäº‹ä»¶å®šä½ç­‰ä»»åŠ¡ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒå‚æ•°å’Œå†…å­˜æ•ˆçŽ‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºæ··åˆå±‚çº§Tokenï¼ˆMoLTï¼‰çš„å‚æ•°å’Œå†…å­˜é«˜æ•ˆçš„éŸ³è§†é¢‘å­¦ä¹ è‡ªé€‚åº”æ¡†æž¶ã€‚MoLTçš„æ ¸å¿ƒæ€æƒ³æ˜¯ç”¨å¹¶è¡Œçš„è½»é‡çº§æ–¹æ¡ˆå–ä»£ä¼ ç»ŸTransformerä¸­è®¡ç®—é‡å¤§çš„ä¸²è¡Œè‡ªé€‚åº”ï¼Œè¯¥æ–¹æ¡ˆä»…ä»ŽåŽæœŸçš„Transformerå±‚æå–å’Œèžåˆå±‚çº§Tokenã€‚æˆ‘ä»¬é‡‡ç”¨ä¸¤ç§ç±»åž‹çš„é€‚é…å™¨ï¼Œå°†æ¨¡æ€ç‰¹å®šä¿¡æ¯å’Œè·¨æ¨¡æ€äº¤äº’æç‚¼æˆç´§å‡‘çš„æ½œåœ¨Tokenã€‚ç„¶åŽï¼ŒTokenèžåˆæ¨¡å—é€šè¿‡è€ƒè™‘å®ƒä»¬çš„ç›¸å¯¹é‡è¦æ€§æ¥åŠ¨æ€åœ°èžåˆè¿™äº›å±‚çº§Tokenã€‚ä¸ºäº†é˜²æ­¢æ½œåœ¨Tokençš„å†—ä½™ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒæœŸé—´å¯¹æ½œåœ¨Tokenåº”ç”¨æ­£äº¤æ­£åˆ™åŒ–ã€‚é€šè¿‡å¯¹é¢„è®­ç»ƒTransformerä¸­è‡ªé€‚åº”ä½ç½®çš„ç³»ç»Ÿåˆ†æžï¼Œæˆ‘ä»¬ä»…ä»ŽTransformerçš„åŽæœŸå±‚æå–æ½œåœ¨Tokenã€‚è¿™ç§ç­–ç•¥æ€§çš„è‡ªé€‚åº”æ–¹æ³•é¿å…äº†æ¥è‡ªæ˜“å¤±çš„æ—©æœŸå±‚ç‰¹å¾çš„è¯¯å·®ä¼ æ’­ï¼Œä»Žè€Œåœ¨ä¿æŒå‚æ•°å’Œå†…å­˜æ•ˆçŽ‡çš„åŒæ—¶ï¼Œæœ€å¤§åŒ–äº†è‡ªé€‚åº”æ€§èƒ½ã€‚é€šè¿‡å¤§é‡çš„å®žéªŒï¼Œæˆ‘ä»¬è¯æ˜Žäº†MoLTåœ¨å„ç§éŸ³è§†é¢‘åŸºå‡†æµ‹è¯•ä¸­ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼ŒåŒ…æ‹¬éŸ³è§†é¢‘é—®ç­”ã€éŸ³è§†é¢‘åˆ†å‰²å’ŒéŸ³è§†é¢‘äº‹ä»¶å®šä½ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰éŸ³è§†é¢‘å­¦ä¹ æ–¹æ³•é€šå¸¸åœ¨Transformerçš„æ¯ä¸€å±‚è¿›è¡Œä¸²è¡Œè‡ªé€‚åº”ï¼Œå¯¼è‡´è®¡ç®—é‡å¤§ã€å‚æ•°æ•ˆçŽ‡ä½Žï¼Œéš¾ä»¥éƒ¨ç½²åˆ°èµ„æºå—é™çš„è®¾å¤‡ä¸Šã€‚æ­¤å¤–ï¼Œæ—©æœŸå±‚çš„ç‰¹å¾å¯èƒ½ä¸ç¨³å®šï¼Œå®¹æ˜“å¯¼è‡´è¯¯å·®ä¼ æ’­ï¼Œå½±å“æœ€ç»ˆæ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMoLTçš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨ä¸€ç§å¹¶è¡Œçš„ã€è½»é‡çº§çš„è‡ªé€‚åº”æ–¹æ¡ˆï¼Œä»…ä»ŽTransformerçš„åŽæœŸå±‚æå–å’Œèžåˆå±‚çº§Tokenã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥é¿å…å¯¹æ¯ä¸€å±‚éƒ½è¿›è¡Œå¤æ‚çš„è®¡ç®—ï¼ŒåŒæ—¶åˆ©ç”¨åŽæœŸå±‚æ›´ç¨³å®šçš„ç‰¹å¾ï¼Œä»Žè€Œæé«˜æ•ˆçŽ‡å’Œæ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šMoLTçš„æ•´ä½“æž¶æž„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ¨¡æ€ç‰¹å®šé€‚é…å™¨ï¼šç”¨äºŽæå–éŸ³é¢‘å’Œè§†é¢‘æ¨¡æ€çš„ç‰¹å®šä¿¡æ¯ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºç´§å‡‘çš„æ½œåœ¨Tokenã€‚2) è·¨æ¨¡æ€äº¤äº’é€‚é…å™¨ï¼šç”¨äºŽæ•æ‰éŸ³é¢‘å’Œè§†é¢‘æ¨¡æ€ä¹‹é—´çš„äº¤äº’ä¿¡æ¯ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæ½œåœ¨Tokenã€‚3) Tokenèžåˆæ¨¡å—ï¼šç”¨äºŽåŠ¨æ€åœ°èžåˆæ¥è‡ªä¸åŒå±‚çš„æ½œåœ¨Tokenï¼Œè¯¥æ¨¡å—ä¼šæ ¹æ®Tokençš„ç›¸å¯¹é‡è¦æ€§è¿›è¡ŒåŠ æƒèžåˆã€‚4) æ­£äº¤æ­£åˆ™åŒ–ï¼šç”¨äºŽé˜²æ­¢æ½œåœ¨Tokençš„å†—ä½™ï¼Œæé«˜æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šMoLTçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶æ··åˆå±‚çº§Tokençš„æå–å’Œèžåˆæœºåˆ¶ã€‚ä¸Žä¼ ç»Ÿçš„ä¸²è¡Œè‡ªé€‚åº”æ–¹æ³•ä¸åŒï¼ŒMoLTé‡‡ç”¨å¹¶è¡Œçš„è½»é‡çº§æ–¹æ¡ˆï¼Œä»…ä»ŽTransformerçš„åŽæœŸå±‚æå–Tokenï¼Œä»Žè€Œæ˜¾è‘—é™ä½Žäº†è®¡ç®—å¤æ‚åº¦ã€‚æ­¤å¤–ï¼ŒTokenèžåˆæ¨¡å—èƒ½å¤ŸåŠ¨æ€åœ°è°ƒæ•´ä¸åŒå±‚Tokençš„æƒé‡ï¼Œä»Žè€Œæ›´å¥½åœ°åˆ©ç”¨ä¸åŒå±‚çš„ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šMoLTçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é€‚é…å™¨çš„ç±»åž‹å’Œæ•°é‡ï¼šè®ºæ–‡é‡‡ç”¨äº†ä¸¤ç§ç±»åž‹çš„é€‚é…å™¨ï¼Œåˆ†åˆ«ç”¨äºŽæå–æ¨¡æ€ç‰¹å®šä¿¡æ¯å’Œè·¨æ¨¡æ€äº¤äº’ä¿¡æ¯ã€‚2) Tokenèžåˆæ¨¡å—çš„æƒé‡è®¡ç®—æ–¹å¼ï¼šè®ºæ–‡é‡‡ç”¨äº†ä¸€ç§åŸºäºŽæ³¨æ„åŠ›çš„æœºåˆ¶æ¥è®¡ç®—Tokençš„æƒé‡ã€‚3) æ­£äº¤æ­£åˆ™åŒ–çš„å¼ºåº¦ï¼šè®ºæ–‡é€šè¿‡å®žéªŒç¡®å®šäº†æ­£äº¤æ­£åˆ™åŒ–çš„æœ€ä½³å¼ºåº¦ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒMoLTåœ¨éŸ³è§†é¢‘é—®ç­”ã€éŸ³è§†é¢‘åˆ†å‰²å’ŒéŸ³è§†é¢‘äº‹ä»¶å®šä½ç­‰ä»»åŠ¡ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨Audio-Visual Question Answeringä»»åŠ¡ä¸Šï¼ŒMoLTçš„æ€§èƒ½ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶ä¸”å‚æ•°é‡æ›´å°‘ã€‚è¿™äº›ç»“æžœè¯æ˜Žäº†MoLTçš„æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

MoLTå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚è§†é¢‘ä¼šè®®ä¸­çš„è¯­éŸ³å¢žå¼ºã€æ™ºèƒ½ç›‘æŽ§ä¸­çš„äº‹ä»¶æ£€æµ‹ã€ä»¥åŠè‡ªåŠ¨é©¾é©¶ä¸­çš„çŽ¯å¢ƒæ„ŸçŸ¥ã€‚è¯¥æ–¹æ³•å¯ä»¥éƒ¨ç½²åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šï¼Œå®žçŽ°é«˜æ•ˆçš„éŸ³è§†é¢‘å¤„ç†ï¼Œå…·æœ‰é‡è¦çš„å®žé™…åº”ç”¨ä»·å€¼å’Œå•†ä¸šæ½œåŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this paper, we propose Mixture of Layer-Wise Tokens (MoLT), a parameter- and memory-efficient adaptation framework for audio-visual learning. The key idea of MoLT is to replace conventional, computationally heavy sequential adaptation at every transformer layer with a parallel, lightweight scheme that extracts and fuses layer-wise tokens only from the late layers. We adopt two types of adapters to distill modality-specific information and cross-modal interaction into compact latent tokens in a layer-wise manner. A token fusion module then dynamically fuses these layer-wise tokens by taking into account their relative significance. To prevent the redundancy of latent tokens, we apply an orthogonality regularization between latent tokens during training. Through the systematic analysis of the position of adaptation in the pre-trained transformers, we extract latent tokens only from the late layers of the transformers. This strategic adaptation approach avoids error propagation from the volatile early-layer features, thereby maximizing the adaptation performance while maintaining parameter and memory efficiency. Through extensive experiments, we demonstrate that MoLT outperforms existing methods on diverse audio-visual benchmarks, including Audio-Visual Question Answering, Audio-Visual Segmentation, and Audio-Visual Event Localization.

