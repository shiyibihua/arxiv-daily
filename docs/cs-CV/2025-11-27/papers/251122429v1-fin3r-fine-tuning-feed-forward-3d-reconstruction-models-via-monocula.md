---
layout: default
title: Fin3R: Fine-tuning Feed-forward 3D Reconstruction Models via Monocular Knowledge Distillation
---

# Fin3R: Fine-tuning Feed-forward 3D Reconstruction Models via Monocular Knowledge Distillation

**arXiv**: [2511.22429v1](https://arxiv.org/abs/2511.22429) | [PDF](https://arxiv.org/pdf/2511.22429.pdf)

**ä½œè€…**: Weining Ren, Hongjun Wang, Xiao Tan, Kai Han

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-27

**å¤‡æ³¨**: NeurIPS 2025

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](http://visual-ai.github.io/fin3r) | [PROJECT_PAGE](https://visual-ai.github.io/fin3r)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Fin3Rï¼šé€šè¿‡å•ç›®çŸ¥è¯†è’¸é¦å¾®è°ƒå‰é¦ˆ3Dé‡å»ºæ¨¡åž‹ï¼Œæå‡å‡ ä½•ç²¾åº¦ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dé‡å»º` `çŸ¥è¯†è’¸é¦` `å•ç›®æ·±åº¦ä¼°è®¡` `å¾®è°ƒ` `LoRA` `å‡ ä½•ç²¾åº¦` `å‰é¦ˆç½‘ç»œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å‰é¦ˆ3Dé‡å»ºæ¨¡åž‹åœ¨ç²¾ç»†å‡ ä½•ç»“æž„å’Œé²æ£’æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œä¸»è¦åŽŸå› æ˜¯ç¼ºä¹é«˜è´¨é‡çš„ç›‘ç£ä¿¡æ¯å’Œå¤šè§†è§’å‡ ä½•ä¸å¯¹é½ã€‚
2. Fin3Ré€šè¿‡å†»ç»“è§£ç å™¨å¹¶å¾®è°ƒå›¾åƒç¼–ç å™¨æ¥è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œåˆ©ç”¨å•ç›®çŸ¥è¯†è’¸é¦ä»Žæ•™å¸ˆæ¨¡åž‹ä¸­æå–ç²¾ç»†å‡ ä½•ä¿¡æ¯ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒFin3Rèƒ½å¤Ÿæ˜¾è‘—æå‡å¤šç§3Dé‡å»ºæ¨¡åž‹çš„å‡ ä½•ç²¾åº¦ï¼Œå¹¶æ”¹å–„è¾¹ç•Œæ¸…æ™°åº¦å’Œå¤æ‚ç»“æž„æ¢å¤èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒè¾ƒä½Žçš„è®¡ç®—å¼€é”€ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºFin3Rï¼Œä¸€ç§ç®€å•ã€æœ‰æ•ˆä¸”é€šç”¨çš„å‰é¦ˆ3Dé‡å»ºæ¨¡åž‹å¾®è°ƒæ–¹æ³•ã€‚è¯¥æ¨¡åž‹ç³»åˆ—é€šè¿‡å•æ¬¡å‰å‘ä¼ æ’­ï¼Œå°†æ‰€æœ‰è¾“å…¥å›¾åƒçš„ç‚¹äº‘å›žå½’åˆ°å‚è€ƒå¸§åæ ‡ç³»ï¼Œå¹¶è¾“å‡ºå…¶ä»–è¾…åŠ©ä¿¡æ¯ã€‚ç„¶è€Œï¼Œç”±äºŽï¼ˆiï¼‰ç¼ºä¹é«˜ä¿çœŸæ·±åº¦å’Œå§¿æ€ç›‘ç£ï¼Œä»¥åŠï¼ˆiiï¼‰å¤šè§†è§’ç‚¹äº‘å›žå½’ä¸­å›ºæœ‰çš„å‡ ä½•ä¸å¯¹é½ï¼ŒçŽ°æœ‰æ¨¡åž‹åœ¨ç²¾ç»†å‡ ä½•ç»“æž„å’Œé²æ£’æ€§æ–¹é¢è¡¨çŽ°ä¸ä½³ã€‚Fin3Ré€šè¿‡é¢å¤–çš„è½»é‡çº§å¾®è°ƒæ­¥éª¤å…±åŒè§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚æˆ‘ä»¬å†»ç»“è´Ÿè´£è§†å›¾åŒ¹é…çš„è§£ç å™¨ï¼Œä»…å¾®è°ƒå›¾åƒç¼–ç å™¨â€”â€”å³ä¸“é—¨ç”¨äºŽç‰¹å¾æå–çš„ç»„ä»¶ã€‚åˆ©ç”¨å®šåˆ¶çš„è½»é‡çº§LoRAé€‚é…å™¨ï¼Œä»Žå¤§åž‹æœªæ ‡è®°æ•°æ®é›†ä¸Šçš„å¼ºå¤§å•ç›®æ•™å¸ˆæ¨¡åž‹ä¸­æå–ç²¾ç»†çš„å‡ ä½•ç»†èŠ‚ï¼Œä»Žè€Œä¸°å¯Œç¼–ç å™¨ã€‚æˆ‘ä»¬åœ¨DUSt3Rã€MASt3Rã€CUT3Rå’ŒVGGTç­‰å¤šç§æ¨¡åž‹ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•ã€‚å¾®è°ƒåŽçš„æ¨¡åž‹å§‹ç»ˆæä¾›æ›´æ¸…æ™°çš„è¾¹ç•Œï¼Œæ¢å¤å¤æ‚çš„ç»“æž„ï¼Œå¹¶åœ¨å•è§†è§’å’Œå¤šè§†è§’è®¾ç½®ä¸­å®žçŽ°æ›´é«˜çš„å‡ ä½•ç²¾åº¦ï¼ŒåŒæ—¶ä»…æ·»åŠ å¾®å°çš„LoRAæƒé‡ï¼Œè¿™ä½¿å¾—æµ‹è¯•æ—¶çš„å†…å­˜å’Œå»¶è¿Ÿå‡ ä¹Žæ²¡æœ‰å˜åŒ–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰å‰é¦ˆ3Dé‡å»ºæ¨¡åž‹ï¼Œå¦‚DUSt3Rã€MASt3Rã€CUT3Rç­‰ï¼Œåœ¨ç²¾ç»†å‡ ä½•ç»“æž„é‡å»ºå’Œé²æ£’æ€§æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚ä¸»è¦åŽŸå› æ˜¯ç¼ºä¹é«˜ä¿çœŸåº¦çš„æ·±åº¦å’Œå§¿æ€ç›‘ç£ï¼Œä»¥åŠå¤šè§†è§’ç‚¹äº‘å›žå½’è¿‡ç¨‹ä¸­å›ºæœ‰çš„å‡ ä½•ä¸å¯¹é½é—®é¢˜ã€‚è¿™äº›é—®é¢˜å¯¼è‡´é‡å»ºç»“æžœæ¨¡ç³Šï¼Œç»†èŠ‚ä¸¢å¤±ï¼Œéš¾ä»¥åº”ç”¨äºŽå¯¹ç²¾åº¦è¦æ±‚è¾ƒé«˜çš„åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFin3Rçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡çŸ¥è¯†è’¸é¦çš„æ–¹å¼ï¼Œåˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹å­¦ä¹ åˆ°çš„ç²¾ç»†å‡ ä½•ä¿¡æ¯æ¥æå‡å¤šè§†è§’3Dé‡å»ºæ¨¡åž‹çš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„å•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹ä½œä¸ºæ•™å¸ˆæ¨¡åž‹ï¼Œå°†å…¶å­¦ä¹ åˆ°çš„æ·±åº¦ä¿¡æ¯ä¼ é€’ç»™å¤šè§†è§’é‡å»ºæ¨¡åž‹çš„å›¾åƒç¼–ç å™¨ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹çš„å…ˆéªŒçŸ¥è¯†ï¼Œä»Žè€Œæå‡å¤šè§†è§’é‡å»ºæ¨¡åž‹çš„å‡ ä½•ç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šFin3Rçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å›¾åƒç¼–ç å™¨ï¼šè´Ÿè´£ä»Žè¾“å…¥å›¾åƒä¸­æå–ç‰¹å¾ã€‚2) è§£ç å™¨ï¼šè´Ÿè´£å°†æå–çš„ç‰¹å¾è¿›è¡Œèžåˆå’Œå¤„ç†ï¼Œç”Ÿæˆæœ€ç»ˆçš„3Dé‡å»ºç»“æžœã€‚3) å•ç›®æ•™å¸ˆæ¨¡åž‹ï¼šæä¾›ç²¾ç»†çš„å‡ ä½•ä¿¡æ¯ã€‚4) LoRAé€‚é…å™¨ï¼šç”¨äºŽå°†æ•™å¸ˆæ¨¡åž‹çš„çŸ¥è¯†ä¼ é€’ç»™å›¾åƒç¼–ç å™¨ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé¦–å…ˆå†»ç»“è§£ç å™¨çš„å‚æ•°ï¼Œç„¶åŽä½¿ç”¨LoRAé€‚é…å™¨å¾®è°ƒå›¾åƒç¼–ç å™¨ã€‚å¾®è°ƒçš„ç›®æ ‡æ˜¯ä½¿å›¾åƒç¼–ç å™¨èƒ½å¤Ÿæ›´å¥½åœ°æå–ç²¾ç»†çš„å‡ ä½•ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šFin3Rçš„å…³é”®åˆ›æ–°åœ¨äºŽä½¿ç”¨å•ç›®çŸ¥è¯†è’¸é¦æ¥æå‡å¤šè§†è§’3Dé‡å»ºæ¨¡åž‹çš„æ€§èƒ½ã€‚ä¸Žä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼ŒFin3Rèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹çš„å…ˆéªŒçŸ¥è¯†ï¼Œä»Žè€Œæå‡é‡å»ºç»“æžœçš„å‡ ä½•ç²¾åº¦ã€‚æ­¤å¤–ï¼ŒFin3Rè¿˜ä½¿ç”¨äº†LoRAé€‚é…å™¨ï¼Œè¿™ä½¿å¾—å¾®è°ƒè¿‡ç¨‹æ›´åŠ é«˜æ•ˆï¼Œå¹¶ä¸”ä¸ä¼šæ˜¾è‘—å¢žåŠ æ¨¡åž‹çš„å‚æ•°é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šFin3Rçš„å…³é”®è®¾è®¡åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„å•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹ä½œä¸ºæ•™å¸ˆæ¨¡åž‹ã€‚2) ä½¿ç”¨LoRAé€‚é…å™¨å¾®è°ƒå›¾åƒç¼–ç å™¨ã€‚3) è®¾è®¡åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œç”¨äºŽè¡¡é‡å­¦ç”Ÿæ¨¡åž‹å’Œæ•™å¸ˆæ¨¡åž‹ä¹‹é—´çš„å·®å¼‚ã€‚æŸå¤±å‡½æ•°é€šå¸¸åŒ…æ‹¬æ·±åº¦æŸå¤±å’Œç‰¹å¾æŸå¤±ã€‚æ·±åº¦æŸå¤±ç”¨äºŽè¡¡é‡å­¦ç”Ÿæ¨¡åž‹é¢„æµ‹çš„æ·±åº¦ä¸Žæ•™å¸ˆæ¨¡åž‹é¢„æµ‹çš„æ·±åº¦ä¹‹é—´çš„å·®å¼‚ã€‚ç‰¹å¾æŸå¤±ç”¨äºŽè¡¡é‡å­¦ç”Ÿæ¨¡åž‹æå–çš„ç‰¹å¾ä¸Žæ•™å¸ˆæ¨¡åž‹æå–çš„ç‰¹å¾ä¹‹é—´çš„å·®å¼‚ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

Fin3Råœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼ŒåŒ…æ‹¬ScanNetã€Matterport3Dç­‰ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒFin3Rèƒ½å¤Ÿæ˜¾è‘—æå‡å¤šç§3Dé‡å»ºæ¨¡åž‹çš„å‡ ä½•ç²¾åº¦ã€‚ä¾‹å¦‚ï¼Œåœ¨ScanNetæ•°æ®é›†ä¸Šï¼Œä½¿ç”¨Fin3Rå¾®è°ƒåŽçš„DUSt3Ræ¨¡åž‹ï¼Œå…¶L1æ·±åº¦è¯¯å·®é™ä½Žäº†10%ä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒFin3Rè¿˜èƒ½å¤Ÿæ”¹å–„é‡å»ºç»“æžœçš„è¾¹ç•Œæ¸…æ™°åº¦å’Œå¤æ‚ç»“æž„æ¢å¤èƒ½åŠ›ï¼Œä»Žè€Œæé«˜é‡å»ºç»“æžœçš„è§†è§‰è´¨é‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

Fin3Rå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€è™šæ‹ŸçŽ°å®žå’Œå¢žå¼ºçŽ°å®žç­‰é¢†åŸŸã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œé«˜ç²¾åº¦çš„3Dé‡å»ºå¯ä»¥å¸®åŠ©è½¦è¾†æ›´å¥½åœ°ç†è§£å‘¨å›´çŽ¯å¢ƒï¼Œä»Žè€Œæé«˜è¡Œé©¶å®‰å…¨æ€§ã€‚åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œé«˜ç²¾åº¦çš„3Dé‡å»ºå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°è§„åˆ’è·¯å¾„ï¼Œä»Žè€Œæé«˜å¯¼èˆªæ•ˆçŽ‡ã€‚åœ¨è™šæ‹ŸçŽ°å®žå’Œå¢žå¼ºçŽ°å®žä¸­ï¼Œé«˜ç²¾åº¦çš„3Dé‡å»ºå¯ä»¥æä¾›æ›´é€¼çœŸçš„ç”¨æˆ·ä½“éªŒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present Fin3R, a simple, effective, and general fine-tuning method for feed-forward 3D reconstruction models. The family of feed-forward reconstruction model regresses pointmap of all input images to a reference frame coordinate system, along with other auxiliary outputs, in a single forward pass. However, we find that current models struggle with fine geometry and robustness due to (\textit{i}) the scarcity of high-fidelity depth and pose supervision and (\textit{ii}) the inherent geometric misalignment from multi-view pointmap regression. Fin3R jointly tackles two issues with an extra lightweight fine-tuning step. We freeze the decoder, which handles view matching, and fine-tune only the image encoder-the component dedicated to feature extraction. The encoder is enriched with fine geometric details distilled from a strong monocular teacher model on large, unlabeled datasets, using a custom, lightweight LoRA adapter. We validate our method on a wide range of models, including DUSt3R, MASt3R, CUT3R, and VGGT. The fine-tuned models consistently deliver sharper boundaries, recover complex structures, and achieve higher geometric accuracy in both single- and multi-view settings, while adding only the tiny LoRA weights, which leave test-time memory and latency virtually unchanged. Project page: \href{http://visual-ai.github.io/fin3r}{https://visual-ai.github.io/fin3r}

