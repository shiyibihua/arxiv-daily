---
layout: default
title: Splat-SAP: Feed-Forward Gaussian Splatting for Human-Centered Scene with Scale-Aware Point Map Reconstruction
---

# Splat-SAP: Feed-Forward Gaussian Splatting for Human-Centered Scene with Scale-Aware Point Map Reconstruction

**arXiv**: [2511.22704v1](https://arxiv.org/abs/2511.22704) | [PDF](https://arxiv.org/pdf/2511.22704.pdf)

**ä½œè€…**: Boyao Zhou, Shunyuan Zheng, Zhanfeng Liao, Zihan Ma, Hanzhang Tu, Boning Liu, Yebin Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-27

**å¤‡æ³¨**: Accepted by AAAI 2026. Project page: https://yaourtb.github.io/Splat-SAP

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Splat-SAPï¼šé¢å‘ä»¥äººä¸ºä¸­å¿ƒçš„ç¨€ç–åœºæ™¯ï¼Œæå‡ºåŸºäºŽå°ºåº¦æ„ŸçŸ¥ç‚¹å›¾é‡å»ºçš„å‰é¦ˆé«˜æ–¯æº…å°„æ–¹æ³•**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `é«˜æ–¯æº…å°„` `è‡ªç”±è§†ç‚¹æ¸²æŸ“` `ç‚¹å›¾é‡å»º` `ç¨€ç–è§†å›¾` `ä»¥äººä¸ºä¸­å¿ƒåœºæ™¯`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŸºäºŽå¤šè§†å›¾ç«‹ä½“çš„feed-forwardé«˜æ–¯æº…å°„æ–¹æ³•ä¾èµ–äºŽè¾“å…¥è§†å›¾çš„å¤§é‡é‡å ï¼Œéš¾ä»¥å¤„ç†ç¨€ç–è§†å›¾åœºæ™¯ã€‚
2. Splat-SAPåˆ©ç”¨åƒç´ çº§ç‚¹å›¾é‡å»ºè¡¨ç¤ºå‡ ä½•ä¿¡æ¯ï¼Œå¯¹ç‹¬ç«‹è§†å›¾å»ºæ¨¡ï¼Œä»Žè€Œå¯¹å¤§ç¨€ç–åº¦å…·æœ‰é²æ£’æ€§ã€‚
3. è¯¥æ–¹æ³•é€šè¿‡ä¸¤é˜¶æ®µå­¦ä¹ ç­–ç•¥ï¼Œç»“åˆè‡ªç›‘ç£å’Œå…‰åº¦ç›‘ç£ï¼Œåœ¨ä»¥äººä¸ºä¸­å¿ƒçš„æ•°æ®é›†ä¸Šå®žçŽ°äº†é«˜è´¨é‡çš„è‡ªç”±è§†ç‚¹æ¸²æŸ“ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†Splat-SAPï¼Œä¸€ç§å‰é¦ˆæ–¹æ³•ï¼Œç”¨äºŽä»Žå…·æœ‰å¤§ç¨€ç–åº¦çš„åŒç›®ç›¸æœºæ¸²æŸ“ä»¥äººä¸ºä¸­å¿ƒçš„åœºæ™¯çš„æ–°è§†è§’ã€‚é«˜æ–¯æº…å°„åœ¨æ¸²æŸ“ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºå…¶æ½œåŠ›ï¼Œä½†é€šå¸¸éœ€è¦å¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä¼˜åŒ–ï¼Œå¹¶éœ€è¦å¯†é›†çš„è¾“å…¥è§†å›¾ã€‚è™½ç„¶æœ€è¿‘çš„ä¸€äº›æ–¹æ³•é€šè¿‡å¤šè§†å›¾ç«‹ä½“èŽ·å¾—çš„å‡ ä½•å…ˆéªŒå®žçŽ°äº†å‰é¦ˆé«˜æ–¯æº…å°„æ¸²æŸ“ï¼Œä½†è¿™äº›æ–¹æ³•ä»ç„¶éœ€è¦å¤§é‡é‡å çš„è¾“å…¥è§†å›¾æ¥å»ºç«‹å‡ ä½•å…ˆéªŒã€‚ä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬åˆ©ç”¨åƒç´ çº§çš„ç‚¹å›¾é‡å»ºæ¥è¡¨ç¤ºå‡ ä½•ï¼Œå› ä¸ºå®ƒå¯¹ç‹¬ç«‹è§†å›¾å»ºæ¨¡å…·æœ‰é²æ£’æ€§ï¼Œèƒ½å¤Ÿå¤„ç†å¤§çš„ç¨€ç–åº¦ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µçš„å­¦ä¹ ç­–ç•¥ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬é€šè¿‡è¿­ä»£çš„äº²å’ŒåŠ›å­¦ä¹ è¿‡ç¨‹å°†ç‚¹å›¾è½¬æ¢ä¸ºçœŸå®žç©ºé—´ï¼Œè¿™æœ‰åŠ©äºŽåŽç»­çš„ç›¸æœºæŽ§åˆ¶ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæˆ‘ä»¬å°†ä¸¤ä¸ªè¾“å…¥è§†å›¾çš„ç‚¹å›¾æŠ•å½±åˆ°ç›®æ ‡è§†å›¾å¹³é¢ä¸Šï¼Œå¹¶é€šè¿‡ç«‹ä½“åŒ¹é…æ¥ç»†åŒ–è¿™ç§å‡ ä½•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†é«˜æ–¯åŸºå…ƒé”šå®šåœ¨è¿™ä¸ªç»†åŒ–çš„å¹³é¢ä¸Šï¼Œä»¥ä¾¿æ¸²æŸ“é«˜è´¨é‡çš„å›¾åƒã€‚ä½œä¸ºä¸€ç§åº¦é‡è¡¨ç¤ºï¼Œç¬¬ä¸€é˜¶æ®µä¸­çš„å°ºåº¦æ„ŸçŸ¥ç‚¹å›¾ä»¥è‡ªç›‘ç£çš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€3Dç›‘ç£ï¼Œç¬¬äºŒé˜¶æ®µåˆ™ä»¥å…‰åº¦æŸå¤±è¿›è¡Œç›‘ç£ã€‚æˆ‘ä»¬æ”¶é›†äº†å¤šè§†å›¾ä»¥äººä¸ºä¸­å¿ƒçš„æ•°æ®ï¼Œå¹¶è¯æ˜Žæˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†ç‚¹å›¾é‡å»ºçš„ç¨³å®šæ€§å’Œè‡ªç”±è§†ç‚¹æ¸²æŸ“çš„è§†è§‰è´¨é‡ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»Žç¨€ç–åŒç›®ç›¸æœºè§†å›¾ä¸­ï¼Œé«˜è´¨é‡åœ°æ¸²æŸ“ä»¥äººä¸ºä¸­å¿ƒçš„åœºæ™¯çš„æ–°è§†è§’çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯é‚£äº›ä¾èµ–å¤šè§†å›¾ç«‹ä½“ï¼ˆMVSï¼‰æ¥å»ºç«‹å‡ ä½•å…ˆéªŒçš„æ–¹æ³•ï¼Œé€šå¸¸éœ€è¦è¾“å…¥è§†å›¾ä¹‹é—´æœ‰å¤§é‡çš„é‡å ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨ç¨€ç–è§†å›¾åœºæ™¯ä¸­çš„åº”ç”¨ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥åœ¨è§†å›¾ç¨€ç–çš„æƒ…å†µä¸‹å‡†ç¡®é‡å»ºå‡ ä½•ç»“æž„ï¼Œå¯¼è‡´æ¸²æŸ“è´¨é‡ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åƒç´ çº§çš„ç‚¹å›¾é‡å»ºæ¥è¡¨ç¤ºåœºæ™¯çš„å‡ ä½•ä¿¡æ¯ã€‚ä¸Žä¾èµ–è§†å›¾é—´é‡å çš„MVSæ–¹æ³•ä¸åŒï¼Œç‚¹å›¾é‡å»ºå¯¹æ¯ä¸ªè§†å›¾ç‹¬ç«‹å»ºæ¨¡ï¼Œå› æ­¤å¯¹è§†å›¾çš„ç¨€ç–æ€§å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ã€‚é€šè¿‡å°†ç‚¹å›¾è½¬æ¢ä¸ºçœŸå®žç©ºé—´ï¼Œå¹¶è¿›è¡Œç«‹ä½“åŒ¹é…ç»†åŒ–ï¼Œå¯ä»¥èŽ·å¾—æ›´å‡†ç¡®çš„å‡ ä½•ä¿¡æ¯ï¼Œä»Žè€Œå®žçŽ°é«˜è´¨é‡çš„æ¸²æŸ“ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šSplat-SAPé‡‡ç”¨ä¸¤é˜¶æ®µçš„å­¦ä¹ ç­–ç•¥ã€‚ç¬¬ä¸€é˜¶æ®µï¼Œé€šè¿‡è¿­ä»£çš„äº²å’ŒåŠ›å­¦ä¹ è¿‡ç¨‹å°†ç‚¹å›¾è½¬æ¢ä¸ºçœŸå®žç©ºé—´ï¼Œä¸ºåŽç»­çš„ç›¸æœºæŽ§åˆ¶æä¾›ä¾¿åˆ©ã€‚ç¬¬äºŒé˜¶æ®µï¼Œå°†ä¸¤ä¸ªè¾“å…¥è§†å›¾çš„ç‚¹å›¾æŠ•å½±åˆ°ç›®æ ‡è§†å›¾å¹³é¢ä¸Šï¼Œå¹¶é€šè¿‡ç«‹ä½“åŒ¹é…æ¥ç»†åŒ–å‡ ä½•ç»“æž„ã€‚æœ€åŽï¼Œå°†é«˜æ–¯åŸºå…ƒé”šå®šåœ¨è¿™ä¸ªç»†åŒ–çš„å¹³é¢ä¸Šï¼Œç”¨äºŽæ¸²æŸ“é«˜è´¨é‡çš„å›¾åƒã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ç‚¹å›¾é‡å»ºã€ç©ºé—´è½¬æ¢ã€ç«‹ä½“åŒ¹é…å’Œé«˜æ–¯æº…å°„æ¸²æŸ“å››ä¸ªä¸»è¦æ­¥éª¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽä½¿ç”¨å°ºåº¦æ„ŸçŸ¥çš„ç‚¹å›¾æ¥è¡¨ç¤ºå‡ ä½•ä¿¡æ¯ï¼Œå¹¶é‡‡ç”¨ä¸¤é˜¶æ®µçš„å­¦ä¹ ç­–ç•¥ã€‚å°ºåº¦æ„ŸçŸ¥çš„ç‚¹å›¾èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰åœºæ™¯çš„å‡ ä½•ç»†èŠ‚ï¼Œè€Œä¸¤é˜¶æ®µçš„å­¦ä¹ ç­–ç•¥åˆ™åˆ†åˆ«è´Ÿè´£ç‚¹å›¾çš„ç©ºé—´è½¬æ¢å’Œå‡ ä½•ç»†åŒ–ï¼Œä»Žè€Œæé«˜äº†é‡å»ºçš„å‡†ç¡®æ€§å’Œæ¸²æŸ“è´¨é‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨è‡ªç›‘ç£çš„æ–¹å¼è®­ç»ƒç¬¬ä¸€é˜¶æ®µçš„ç‚¹å›¾é‡å»ºï¼Œæ— éœ€3Dç›‘ç£æ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç¬¬ä¸€é˜¶æ®µï¼Œä½¿ç”¨è‡ªç›‘ç£æŸå¤±å‡½æ•°è®­ç»ƒå°ºåº¦æ„ŸçŸ¥çš„ç‚¹å›¾ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦ä¿è¯ç‚¹å›¾çš„å°ºåº¦ä¸€è‡´æ€§ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œä½¿ç”¨å…‰åº¦æŸå¤±å‡½æ•°ç›‘ç£å‡ ä½•ç»†åŒ–è¿‡ç¨‹ï¼Œç¡®ä¿æ¸²æŸ“ç»“æžœä¸Žç›®æ ‡è§†å›¾ä¸€è‡´ã€‚è¿­ä»£çš„äº²å’ŒåŠ›å­¦ä¹ è¿‡ç¨‹æ˜¯ç‚¹å›¾ç©ºé—´è½¬æ¢çš„å…³é”®ï¼Œå…¶å‚æ•°è®¾ç½®ä¼šå½±å“è½¬æ¢çš„å‡†ç¡®æ€§ã€‚é«˜æ–¯åŸºå…ƒçš„å‚æ•°åˆå§‹åŒ–å’Œä¼˜åŒ–ç­–ç•¥ä¹Ÿä¼šå½±å“æœ€ç»ˆçš„æ¸²æŸ“è´¨é‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è®ºæ–‡æ”¶é›†äº†å¤šè§†å›¾ä»¥äººä¸ºä¸­å¿ƒçš„æ•°æ®é›†ï¼Œå¹¶åœ¨è¯¥æ•°æ®é›†ä¸ŠéªŒè¯äº†Splat-SAPçš„æœ‰æ•ˆæ€§ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæé«˜ç‚¹å›¾é‡å»ºçš„ç¨³å®šæ€§å’Œè‡ªç”±è§†ç‚¹æ¸²æŸ“çš„è§†è§‰è´¨é‡ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSplat-SAPåœ¨ç¨€ç–è§†å›¾åœºæ™¯ä¸‹èƒ½å¤Ÿç”Ÿæˆæ›´å‡†ç¡®çš„å‡ ä½•ç»“æž„å’Œæ›´é«˜è´¨é‡çš„æ¸²æŸ“ç»“æžœã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®ï¼ˆä¾‹å¦‚PSNRã€SSIMç­‰ï¼‰å’Œå¯¹æ¯”åŸºçº¿éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

Splat-SAPå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬è™šæ‹ŸçŽ°å®žï¼ˆVRï¼‰ã€å¢žå¼ºçŽ°å®žï¼ˆARï¼‰ã€è‡ªç”±è§†ç‚¹è§†é¢‘ã€è¿œç¨‹å‘ˆçŽ°å’Œäººä½“é‡å»ºç­‰é¢†åŸŸã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿä»Žæœ‰é™çš„ç›¸æœºè§†å›¾ä¸­ç”Ÿæˆé«˜è´¨é‡çš„3Dåœºæ™¯è¡¨ç¤ºï¼Œä¸ºç”¨æˆ·æä¾›æ²‰æµ¸å¼çš„ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºŽäººæœºäº¤äº’ã€æ™ºèƒ½ç›‘æŽ§å’Œæœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present Splat-SAP, a feed-forward approach to render novel views of human-centered scenes from binocular cameras with large sparsity. Gaussian Splatting has shown its promising potential in rendering tasks, but it typically necessitates per-scene optimization with dense input views. Although some recent approaches achieve feed-forward Gaussian Splatting rendering through geometry priors obtained by multi-view stereo, such approaches still require largely overlapped input views to establish the geometry prior. To bridge this gap, we leverage pixel-wise point map reconstruction to represent geometry which is robust to large sparsity for its independent view modeling. In general, we propose a two-stage learning strategy. In stage 1, we transform the point map into real space via an iterative affinity learning process, which facilitates camera control in the following. In stage 2, we project point maps of two input views onto the target view plane and refine such geometry via stereo matching. Furthermore, we anchor Gaussian primitives on this refined plane in order to render high-quality images. As a metric representation, the scale-aware point map in stage 1 is trained in a self-supervised manner without 3D supervision and stage 2 is supervised with photo-metric loss. We collect multi-view human-centered data and demonstrate that our method improves both the stability of point map reconstruction and the visual quality of free-viewpoint rendering.

