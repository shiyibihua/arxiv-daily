---
layout: default
title: SparseWorld-TC: Trajectory-Conditioned Sparse Occupancy World Model
---

# SparseWorld-TC: Trajectory-Conditioned Sparse Occupancy World Model

**arXiv**: [2511.22039v1](https://arxiv.org/abs/2511.22039) | [PDF](https://arxiv.org/pdf/2511.22039.pdf)

**ä½œè€…**: Jiayuan Du, Yiming Zhao, Zhenglong Guo, Yong Pan, Wenbo Hou, Zhihui Hao, Kun Zhan, Qijun Chen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-27

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè½¨è¿¹æ¡ä»¶ä¸‹çš„ç¨€ç–Occupancy World Modelï¼Œç”¨äºŽæœªæ¥3Dåœºæ™¯Occupancyé¢„æµ‹ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `Occupancyé¢„æµ‹` `ç¨€ç–è¡¨å¾` `Transformer` `è‡ªåŠ¨é©¾é©¶` `åœºæ™¯ç†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–VAEç”Ÿæˆç¦»æ•£Occupancy tokensï¼Œé™åˆ¶äº†è¡¨å¾èƒ½åŠ›ï¼Œä¸”BEVæŠ•å½±å¼•å…¥äº†ç»“æž„é™åˆ¶ã€‚
2. è¯¥æ–¹æ³•é‡‡ç”¨ç¨€ç–Occupancyè¡¨å¾ï¼Œç»•è¿‡BEVæŠ•å½±ï¼Œç›´æŽ¥ä»Žå›¾åƒç‰¹å¾ç«¯åˆ°ç«¯é¢„æµ‹æœªæ¥Occupancyã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨nuScenesæ•°æ®é›†ä¸Šå®žçŽ°äº†SOTAæ€§èƒ½ï¼Œä¸”å¯¹æœªæ¥è½¨è¿¹æ¡ä»¶å…·æœ‰é²æ£’æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æž¶æž„ï¼Œç”¨äºŽè½¨è¿¹æ¡ä»¶ä¸‹çš„æœªæ¥3Dåœºæ™¯Occupancyé¢„æµ‹ã€‚ä¸Žä¾èµ–å˜åˆ†è‡ªç¼–ç å™¨(VAEs)ç”Ÿæˆç¦»æ•£Occupancy tokensçš„æ–¹æ³•ä¸åŒï¼ˆæ­¤ç±»æ–¹æ³•å›ºæœ‰åœ°é™åˆ¶äº†è¡¨å¾èƒ½åŠ›ï¼‰ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç›´æŽ¥ä»ŽåŽŸå§‹å›¾åƒç‰¹å¾ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼é¢„æµ‹å¤šå¸§æœªæ¥Occupancyã€‚å—åˆ°åŸºäºŽæ³¨æ„åŠ›æœºåˆ¶çš„Transformeræž¶æž„åœ¨GPTå’ŒVGGTç­‰åŸºç¡€è§†è§‰å’Œè¯­è¨€æ¨¡åž‹ä¸­å–å¾—çš„æˆåŠŸçš„å¯å‘ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§ç¨€ç–Occupancyè¡¨å¾ï¼Œå®ƒç»•è¿‡äº†ä¸­é—´çš„é¸Ÿçž°å›¾(BEV)æŠ•å½±åŠå…¶æ˜¾å¼çš„å‡ ä½•å…ˆéªŒã€‚è¿™ç§è®¾è®¡ä½¿å¾—Transformerèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•èŽ·æ—¶ç©ºä¾èµ–å…³ç³»ã€‚é€šè¿‡é¿å…ç¦»æ•£tokenizationçš„æœ‰é™å®¹é‡çº¦æŸå’ŒBEVè¡¨å¾çš„ç»“æž„é™åˆ¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨nuScenesåŸºå‡†æµ‹è¯•ä¸­å®žçŽ°äº†1-3ç§’Occupancyé¢„æµ‹çš„æœ€å…ˆè¿›æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼Œå®ƒå±•ç¤ºäº†å¼ºå¤§çš„åœºæ™¯åŠ¨æ€ç†è§£èƒ½åŠ›ï¼Œåœ¨ä»»æ„æœªæ¥è½¨è¿¹æ¡ä»¶ä¸‹å§‹ç»ˆæä¾›é«˜ç²¾åº¦ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰æ–¹æ³•åœ¨é¢„æµ‹æœªæ¥3Dåœºæ™¯Occupancyæ—¶ï¼Œé€šå¸¸ä¾èµ–äºŽå˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEsï¼‰æ¥ç”Ÿæˆç¦»æ•£çš„Occupancy tokensï¼Œè¿™ç§æ–¹æ³•çš„ç¼ºç‚¹åœ¨äºŽç¦»æ•£tokenizationé™åˆ¶äº†è¡¨å¾èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œä¸€äº›æ–¹æ³•ä½¿ç”¨é¸Ÿçž°å›¾ï¼ˆBEVï¼‰æŠ•å½±ï¼Œè™½ç„¶å¼•å…¥äº†å‡ ä½•å…ˆéªŒï¼Œä½†ä¹Ÿé™åˆ¶äº†æ¨¡åž‹å¯¹å¤æ‚æ—¶ç©ºå…³ç³»çš„å»ºæ¨¡èƒ½åŠ›ã€‚å› æ­¤ï¼Œå¦‚ä½•æ›´æœ‰æ•ˆåœ°è¡¨å¾å’Œé¢„æµ‹æœªæ¥åœºæ™¯çš„Occupancyæˆä¸ºä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨ä¸€ç§ç¨€ç–Occupancyè¡¨å¾ï¼Œå¹¶åˆ©ç”¨Transformeræž¶æž„ç›´æŽ¥ä»ŽåŽŸå§‹å›¾åƒç‰¹å¾é¢„æµ‹æœªæ¥Occupancyï¼Œä»Žè€Œé¿å…äº†ç¦»æ•£tokenizationçš„å®¹é‡é™åˆ¶å’ŒBEVæŠ•å½±çš„ç»“æž„é™åˆ¶ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡åž‹å¯ä»¥æ›´æœ‰æ•ˆåœ°å­¦ä¹ åœºæ™¯çš„æ—¶ç©ºåŠ¨æ€ï¼Œå¹¶å®žçŽ°æ›´å‡†ç¡®çš„æœªæ¥Occupancyé¢„æµ‹ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼šé¦–å…ˆï¼Œä»ŽåŽŸå§‹å›¾åƒä¸­æå–ç‰¹å¾ï¼›ç„¶åŽï¼Œåˆ©ç”¨Transformeræž¶æž„å¯¹è¿™äº›ç‰¹å¾è¿›è¡Œå¤„ç†ï¼Œä»¥å­¦ä¹ åœºæ™¯çš„æ—¶ç©ºä¾èµ–å…³ç³»ï¼›æœ€åŽï¼ŒåŸºäºŽå­¦ä¹ åˆ°çš„ç‰¹å¾ï¼Œé¢„æµ‹æœªæ¥å¤šå¸§çš„ç¨€ç–Occupancyã€‚è¯¥æ¡†æž¶é¿å…äº†ä¸­é—´çš„BEVæŠ•å½±æ­¥éª¤ï¼Œç›´æŽ¥åœ¨åŽŸå§‹å›¾åƒç‰¹å¾ä¸Šè¿›è¡Œæ“ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽé‡‡ç”¨äº†ç¨€ç–Occupancyè¡¨å¾ï¼Œå¹¶å°†å…¶ä¸ŽTransformeræž¶æž„ç›¸ç»“åˆã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•é¿å…äº†ç¦»æ•£tokenizationå’ŒBEVæŠ•å½±ï¼Œä»Žè€Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¡¨å¾å’Œé¢„æµ‹æœªæ¥åœºæ™¯çš„Occupancyã€‚è¿™ç§ç¨€ç–è¡¨å¾å…è®¸æ¨¡åž‹å…³æ³¨åœºæ™¯ä¸­æœ€é‡è¦çš„åŒºåŸŸï¼Œä»Žè€Œæé«˜äº†é¢„æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…·ä½“å®žçŽ°ä¸Šï¼Œè¯¥æ–¹æ³•ä½¿ç”¨äº†åŸºäºŽæ³¨æ„åŠ›æœºåˆ¶çš„Transformeræž¶æž„ï¼Œè¯¥æž¶æž„èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•èŽ·æ—¶ç©ºä¾èµ–å…³ç³»ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜è®¾è®¡äº†ä¸€ç§æŸå¤±å‡½æ•°ï¼Œç”¨äºŽè®­ç»ƒæ¨¡åž‹é¢„æµ‹æœªæ¥Occupancyã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æž„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨nuScenesåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰çš„æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨1-3ç§’çš„Occupancyé¢„æµ‹ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•å®žçŽ°äº†æ˜Žæ˜¾çš„æ€§èƒ½æå‡ï¼Œè¯æ˜Žäº†å…¶åœ¨åœºæ™¯åŠ¨æ€ç†è§£å’Œæœªæ¥é¢„æµ‹æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨ä»»æ„æœªæ¥è½¨è¿¹æ¡ä»¶ä¸‹éƒ½èƒ½ä¿æŒé«˜ç²¾åº¦ï¼Œä½“çŽ°äº†å…¶é²æ£’æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½ç›‘æŽ§ç­‰é¢†åŸŸã€‚é€šè¿‡é¢„æµ‹æœªæ¥åœºæ™¯çš„Occupancyï¼Œå¯ä»¥å¸®åŠ©è‡ªåŠ¨é©¾é©¶è½¦è¾†æ›´å¥½åœ°è§„åˆ’è¡Œé©¶è·¯å¾„ï¼Œæé«˜å®‰å…¨æ€§ï¼›æœºå™¨äººå¯ä»¥æ›´å¥½åœ°ç†è§£å‘¨å›´çŽ¯å¢ƒï¼Œä»Žè€Œå®žçŽ°æ›´æ™ºèƒ½çš„å¯¼èˆªï¼›æ™ºèƒ½ç›‘æŽ§ç³»ç»Ÿå¯ä»¥é¢„æµ‹æ½œåœ¨çš„å±é™©æƒ…å†µï¼Œä»Žè€Œæé«˜é¢„è­¦èƒ½åŠ›ã€‚è¯¥ç ”ç©¶å…·æœ‰é‡è¦çš„å®žé™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper introduces a novel architecture for trajectory-conditioned forecasting of future 3D scene occupancy. In contrast to methods that rely on variational autoencoders (VAEs) to generate discrete occupancy tokens, which inherently limit representational capacity, our approach predicts multi-frame future occupancy in an end-to-end manner directly from raw image features. Inspired by the success of attention-based transformer architectures in foundational vision and language models such as GPT and VGGT, we employ a sparse occupancy representation that bypasses the intermediate bird's eye view (BEV) projection and its explicit geometric priors. This design allows the transformer to capture spatiotemporal dependencies more effectively. By avoiding both the finite-capacity constraint of discrete tokenization and the structural limitations of BEV representations, our method achieves state-of-the-art performance on the nuScenes benchmark for 1-3 second occupancy forecasting, outperforming existing approaches by a significant margin. Furthermore, it demonstrates robust scene dynamics understanding, consistently delivering high accuracy under arbitrary future trajectory conditioning.

