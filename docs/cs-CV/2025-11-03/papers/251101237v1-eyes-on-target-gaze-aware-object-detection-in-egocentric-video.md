---
layout: default
title: Eyes on Target: Gaze-Aware Object Detection in Egocentric Video
---

# Eyes on Target: Gaze-Aware Object Detection in Egocentric Video

**arXiv**: [2511.01237v1](https://arxiv.org/abs/2511.01237) | [PDF](https://arxiv.org/pdf/2511.01237.pdf)

**ä½œè€…**: Vishakha Lall, Yisi Liu

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-03

**å¤‡æ³¨**: Accepted at RAAI 2025

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Eyes on Targetï¼šæå‡ºæ·±åº¦æ„ŸçŸ¥å’Œæ³¨è§†å¼•å¯¼çš„ç›®æ ‡æ£€æµ‹æ¡†æž¶ï¼Œç”¨äºŽä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘åˆ†æžã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æ³¨è§†é¢„æµ‹` `ç›®æ ‡æ£€æµ‹` `ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒè§†é¢‘` `è§†è§‰æ³¨æ„åŠ›` `Vision Transformer` `æ·±åº¦å­¦ä¹ ` `äººæœºäº¤äº’`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰ç›®æ ‡æ£€æµ‹æ–¹æ³•å¿½ç•¥äº†äººçœ¼æ³¨è§†ä¿¡æ¯ï¼Œåœ¨ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘ä¸­è¡¨çŽ°ä¸ä½³ã€‚
2. Eyes on Targetæ¡†æž¶å°†æ³¨è§†ä¿¡æ¯èžå…¥ViTçš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿æ¨¡åž‹å…³æ³¨äººçœ¼æ³¨è§†åŒºåŸŸã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡ä¼˜äºŽä¼ ç»Ÿæ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨æ¨¡æ‹ŸçŽ¯å¢ƒä¸­ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºâ€œEyes on Targetâ€çš„æ–°åž‹æ·±åº¦æ„ŸçŸ¥å’Œæ³¨è§†å¼•å¯¼çš„ç›®æ ‡æ£€æµ‹æ¡†æž¶ï¼Œä¸“ä¸ºä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘è®¾è®¡ã€‚è¯¥æ–¹æ³•å°†æ³¨è§†è¡ç”Ÿçš„ç‰¹å¾æ³¨å…¥åˆ°Vision Transformer (ViT)çš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œæœ‰æ•ˆåœ°å°†ç©ºé—´ç‰¹å¾é€‰æ‹©åå‘äºŽäººçœ¼å…³æ³¨çš„åŒºåŸŸã€‚ä¸Žä¼ ç»Ÿçš„ç›®æ ‡æ£€æµ‹å™¨å¹³ç­‰å¯¹å¾…æ‰€æœ‰åŒºåŸŸä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¼ºè°ƒè§‚å¯Ÿè€…ä¼˜å…ˆè€ƒè™‘çš„åŒºåŸŸï¼Œä»¥å¢žå¼ºç›®æ ‡æ£€æµ‹æ•ˆæžœã€‚æˆ‘ä»¬åœ¨ä¸€ä¸ªä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„æ¨¡æ‹Ÿå™¨æ•°æ®é›†ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•ï¼Œå…¶ä¸­äººç±»è§†è§‰æ³¨æ„åŠ›å¯¹äºŽä»»åŠ¡è¯„ä¼°è‡³å…³é‡è¦ï¼Œå±•ç¤ºäº†å…¶åœ¨è¯„ä¼°æ¨¡æ‹Ÿåœºæ™¯ä¸­äººç±»è¡¨çŽ°æ–¹é¢çš„æ½œåŠ›ã€‚é€šè¿‡å¤§é‡çš„å®žéªŒå’Œæ¶ˆèžç ”ç©¶ï¼Œæˆ‘ä»¬è¯„ä¼°äº†é›†æˆæ³¨è§†ä¿¡æ¯çš„æ¨¡åž‹çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜Žäº†åœ¨è‡ªå®šä¹‰æ¨¡æ‹Ÿå™¨æ•°æ®é›†å’Œå…¬å…±åŸºå‡†ï¼ˆåŒ…æ‹¬Ego4D Ego-Motionå’ŒEgo-CH-Gazeæ•°æ®é›†ï¼‰ä¸Šï¼Œæ£€æµ‹ç²¾åº¦ç›¸å¯¹äºŽä¸Žæ³¨è§†æ— å…³çš„åŸºçº¿å§‹ç»ˆæœ‰æ‰€æé«˜ã€‚ä¸ºäº†è§£é‡Šæ¨¡åž‹çš„è¡Œä¸ºï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§æ³¨è§†æ„ŸçŸ¥çš„æ³¨æ„åŠ›å¤´é‡è¦æ€§åº¦é‡ï¼Œæ­ç¤ºäº†æ³¨è§†çº¿ç´¢å¦‚ä½•è°ƒèŠ‚Transformerçš„æ³¨æ„åŠ›åŠ¨æ€ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„ç›®æ ‡æ£€æµ‹æ–¹æ³•é€šå¸¸å¹³ç­‰åœ°å¯¹å¾…å›¾åƒæˆ–è§†é¢‘ä¸­çš„æ‰€æœ‰åŒºåŸŸï¼Œè€Œå¿½ç•¥äº†äººç±»è§†è§‰æ³¨æ„åŠ›çš„é‡è¦æ€§ã€‚åœ¨ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘ä¸­ï¼Œäººç±»çš„æ³¨è§†ç‚¹å¾€å¾€é›†ä¸­åœ¨ä¸Žå½“å‰ä»»åŠ¡ç›¸å…³çš„å¯¹è±¡æˆ–åŒºåŸŸä¸Šã€‚å› æ­¤ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°åˆ©ç”¨äººç±»çš„æ³¨è§†ä¿¡æ¯æ¥æé«˜ç›®æ ‡æ£€æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEyes on Targetçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†äººç±»çš„æ³¨è§†ä¿¡æ¯ä½œä¸ºä¸€ç§å…ˆéªŒçŸ¥è¯†ï¼Œå¼•å¯¼ç›®æ ‡æ£€æµ‹æ¨¡åž‹æ›´åŠ å…³æ³¨äººçœ¼æ³¨è§†çš„åŒºåŸŸã€‚é€šè¿‡å°†æ³¨è§†è¡ç”Ÿçš„ç‰¹å¾èžå…¥åˆ°Vision Transformer (ViT)çš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œæ¨¡åž‹å¯ä»¥æ›´å¥½åœ°é€‰æ‹©ä¸Žä»»åŠ¡ç›¸å…³çš„ç©ºé—´ç‰¹å¾ï¼Œä»Žè€Œæé«˜ç›®æ ‡æ£€æµ‹çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šEyes on Targetæ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) æ³¨è§†ç‰¹å¾æå–æ¨¡å—ï¼šä»Žæ³¨è§†æ•°æ®ä¸­æå–æœ‰ç”¨çš„ç‰¹å¾ï¼Œä¾‹å¦‚æ³¨è§†ä½ç½®ã€æ³¨è§†æŒç»­æ—¶é—´ç­‰ã€‚2) æ·±åº¦æ„ŸçŸ¥æ¨¡å—ï¼šåˆ©ç”¨æ·±åº¦ä¿¡æ¯æ¥å¢žå¼ºå¯¹åœºæ™¯çš„ç†è§£ï¼Œå¹¶å¸®åŠ©æ¨¡åž‹æ›´å¥½åœ°å®šä½ç›®æ ‡ã€‚3) æ³¨è§†å¼•å¯¼çš„æ³¨æ„åŠ›æœºåˆ¶ï¼šå°†æ³¨è§†ç‰¹å¾å’Œæ·±åº¦ä¿¡æ¯æ³¨å…¥åˆ°ViTçš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œå¼•å¯¼æ¨¡åž‹å…³æ³¨äººçœ¼æ³¨è§†çš„åŒºåŸŸã€‚4) ç›®æ ‡æ£€æµ‹æ¨¡å—ï¼šåˆ©ç”¨ViTæå–çš„ç‰¹å¾è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå°†æ³¨è§†ä¿¡æ¯æœ‰æ•ˆåœ°èžå…¥åˆ°Vision Transformerçš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ã€‚ä¸Žä¼ ç»Ÿçš„æ³¨æ„åŠ›æœºåˆ¶ä¸åŒï¼Œè¯¥æ–¹æ³•ä¸ä»…ä»…å…³æ³¨å›¾åƒæˆ–è§†é¢‘æœ¬èº«çš„å†…å®¹ï¼Œè¿˜è€ƒè™‘äº†äººç±»çš„è§†è§‰æ³¨æ„åŠ›ï¼Œä»Žè€Œä½¿æ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£åœºæ™¯å¹¶æé«˜ç›®æ ‡æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†æ·±åº¦æ„ŸçŸ¥æ¨¡å—ï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡åž‹å¯¹ä¸‰ç»´åœºæ™¯çš„ç†è§£èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å…³é”®çš„è®¾è®¡åŒ…æ‹¬ï¼š1) å¦‚ä½•æœ‰æ•ˆåœ°æå–å’Œè¡¨ç¤ºæ³¨è§†ç‰¹å¾ï¼›2) å¦‚ä½•å°†æ³¨è§†ç‰¹å¾å’Œæ·±åº¦ä¿¡æ¯èžå…¥åˆ°ViTçš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼›3) å¦‚ä½•è®¾è®¡æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡åž‹çš„æ€§èƒ½ã€‚å…·ä½“çš„æŠ€æœ¯ç»†èŠ‚åŒ…æ‹¬æ³¨è§†ç‰¹å¾çš„ç¼–ç æ–¹å¼ã€æ³¨æ„åŠ›æœºåˆ¶çš„èžåˆç­–ç•¥ä»¥åŠæŸå¤±å‡½æ•°çš„é€‰æ‹©ç­‰ã€‚è®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§æ³¨è§†æ„ŸçŸ¥çš„æ³¨æ„åŠ›å¤´é‡è¦æ€§åº¦é‡ï¼Œç”¨äºŽè§£é‡Šæ¨¡åž‹è¡Œä¸ºã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒEyes on Targetæ¡†æž¶åœ¨è‡ªå®šä¹‰æ¨¡æ‹Ÿå™¨æ•°æ®é›†å’Œå…¬å…±åŸºå‡†ï¼ˆåŒ…æ‹¬Ego4D Ego-Motionå’ŒEgo-CH-Gazeæ•°æ®é›†ï¼‰ä¸Šï¼Œæ£€æµ‹ç²¾åº¦ç›¸å¯¹äºŽä¸Žæ³¨è§†æ— å…³çš„åŸºçº¿å§‹ç»ˆæœ‰æ‰€æé«˜ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨Ego4Dæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¯æ˜Žäº†å…¶æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽäººæœºäº¤äº’ã€æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½è¾…åŠ©é©¾é©¶ç­‰é¢†åŸŸã€‚é€šè¿‡ç†è§£äººç±»çš„è§†è§‰æ³¨æ„åŠ›ï¼Œæœºå™¨å¯ä»¥æ›´å¥½åœ°ä¸Žäººç±»è¿›è¡Œåä½œï¼Œæé«˜å·¥ä½œæ•ˆçŽ‡å’Œå®‰å…¨æ€§ã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½è¾…åŠ©é©¾é©¶ä¸­ï¼Œç³»ç»Ÿå¯ä»¥æ ¹æ®é©¾é©¶å‘˜çš„æ³¨è§†ç‚¹æ¥é¢„æµ‹å…¶è¡Œä¸ºï¼Œå¹¶åŠæ—¶å‘å‡ºè­¦å‘Šæˆ–é‡‡å–æŽªæ–½ï¼Œä»Žè€Œé¿å…äº¤é€šäº‹æ•…çš„å‘ç”Ÿã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Human gaze offers rich supervisory signals for understanding visual attention in complex visual environments. In this paper, we propose Eyes on Target, a novel depth-aware and gaze-guided object detection framework designed for egocentric videos. Our approach injects gaze-derived features into the attention mechanism of a Vision Transformer (ViT), effectively biasing spatial feature selection toward human-attended regions. Unlike traditional object detectors that treat all regions equally, our method emphasises viewer-prioritised areas to enhance object detection. We validate our method on an egocentric simulator dataset where human visual attention is critical for task assessment, illustrating its potential in evaluating human performance in simulation scenarios. We evaluate the effectiveness of our gaze-integrated model through extensive experiments and ablation studies, demonstrating consistent gains in detection accuracy over gaze-agnostic baselines on both the custom simulator dataset and public benchmarks, including Ego4D Ego-Motion and Ego-CH-Gaze datasets. To interpret model behaviour, we also introduce a gaze-aware attention head importance metric, revealing how gaze cues modulate transformer attention dynamics.

