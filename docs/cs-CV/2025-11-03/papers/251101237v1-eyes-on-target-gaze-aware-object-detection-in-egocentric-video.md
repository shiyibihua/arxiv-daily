---
layout: default
title: Eyes on Target: Gaze-Aware Object Detection in Egocentric Video
---

# Eyes on Target: Gaze-Aware Object Detection in Egocentric Video

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.01237" target="_blank" class="toolbar-btn">arXiv: 2511.01237v1</a>
    <a href="https://arxiv.org/pdf/2511.01237.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.01237v1" 
            onclick="toggleFavorite(this, '2511.01237v1', 'Eyes on Target: Gaze-Aware Object Detection in Egocentric Video')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Vishakha Lall, Yisi Liu

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-03

**Â§áÊ≥®**: Accepted at RAAI 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Eyes on TargetÔºöÊèêÂá∫Ê∑±Â∫¶ÊÑüÁü•ÂíåÊ≥®ËßÜÂºïÂØºÁöÑÁõÆÊ†áÊ£ÄÊµãÊ°ÜÊû∂ÔºåÁî®‰∫é‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜÈ¢ëÂàÜÊûê„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Ê≥®ËßÜÈ¢ÑÊµã` `ÁõÆÊ†áÊ£ÄÊµã` `‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉËßÜÈ¢ë` `ËßÜËßâÊ≥®ÊÑèÂäõ` `Vision Transformer` `Ê∑±Â∫¶Â≠¶‰π†` `‰∫∫Êú∫‰∫§‰∫í`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁõÆÊ†áÊ£ÄÊµãÊñπÊ≥ïÂøΩÁï•‰∫Ü‰∫∫ÁúºÊ≥®ËßÜ‰ø°ÊÅØÔºåÂú®‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜÈ¢ë‰∏≠Ë°®Áé∞‰∏ç‰Ω≥„ÄÇ
2. Eyes on TargetÊ°ÜÊû∂Â∞ÜÊ≥®ËßÜ‰ø°ÊÅØËûçÂÖ•ViTÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂Ôºå‰ΩøÊ®°ÂûãÂÖ≥Ê≥®‰∫∫ÁúºÊ≥®ËßÜÂå∫Âüü„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂùá‰ºò‰∫é‰º†ÁªüÊñπÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÂú®Ê®°ÊãüÁéØÂ¢É‰∏≠„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫‚ÄúEyes on Target‚ÄùÁöÑÊñ∞ÂûãÊ∑±Â∫¶ÊÑüÁü•ÂíåÊ≥®ËßÜÂºïÂØºÁöÑÁõÆÊ†áÊ£ÄÊµãÊ°ÜÊû∂Ôºå‰∏ì‰∏∫‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜÈ¢ëËÆæËÆ°„ÄÇËØ•ÊñπÊ≥ïÂ∞ÜÊ≥®ËßÜË°çÁîüÁöÑÁâπÂæÅÊ≥®ÂÖ•Âà∞Vision Transformer (ViT)ÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂‰∏≠ÔºåÊúâÊïàÂú∞Â∞ÜÁ©∫Èó¥ÁâπÂæÅÈÄâÊã©ÂÅèÂêë‰∫é‰∫∫ÁúºÂÖ≥Ê≥®ÁöÑÂå∫Âüü„ÄÇ‰∏é‰º†ÁªüÁöÑÁõÆÊ†áÊ£ÄÊµãÂô®Âπ≥Á≠âÂØπÂæÖÊâÄÊúâÂå∫Âüü‰∏çÂêåÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂº∫Ë∞ÉËßÇÂØüËÄÖ‰ºòÂÖàËÄÉËôëÁöÑÂå∫ÂüüÔºå‰ª•Â¢ûÂº∫ÁõÆÊ†áÊ£ÄÊµãÊïàÊûú„ÄÇÊàë‰ª¨Âú®‰∏Ä‰∏™‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑÊ®°ÊãüÂô®Êï∞ÊçÆÈõÜ‰∏äÈ™åËØÅ‰∫ÜËØ•ÊñπÊ≥ïÔºåÂÖ∂‰∏≠‰∫∫Á±ªËßÜËßâÊ≥®ÊÑèÂäõÂØπ‰∫é‰ªªÂä°ËØÑ‰º∞Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ËØÑ‰º∞Ê®°ÊãüÂú∫ÊôØ‰∏≠‰∫∫Á±ªË°®Áé∞ÊñπÈù¢ÁöÑÊΩúÂäõ„ÄÇÈÄöËøáÂ§ßÈáèÁöÑÂÆûÈ™åÂíåÊ∂àËûçÁ†îÁ©∂ÔºåÊàë‰ª¨ËØÑ‰º∞‰∫ÜÈõÜÊàêÊ≥®ËßÜ‰ø°ÊÅØÁöÑÊ®°ÂûãÁöÑÊúâÊïàÊÄßÔºåËØÅÊòé‰∫ÜÂú®Ëá™ÂÆö‰πâÊ®°ÊãüÂô®Êï∞ÊçÆÈõÜÂíåÂÖ¨ÂÖ±Âü∫ÂáÜÔºàÂåÖÊã¨Ego4D Ego-MotionÂíåEgo-CH-GazeÊï∞ÊçÆÈõÜÔºâ‰∏äÔºåÊ£ÄÊµãÁ≤æÂ∫¶Áõ∏ÂØπ‰∫é‰∏éÊ≥®ËßÜÊó†ÂÖ≥ÁöÑÂü∫Á∫øÂßãÁªàÊúâÊâÄÊèêÈ´ò„ÄÇ‰∏∫‰∫ÜËß£ÈáäÊ®°ÂûãÁöÑË°å‰∏∫ÔºåÊàë‰ª¨ËøòÂºïÂÖ•‰∫Ü‰∏ÄÁßçÊ≥®ËßÜÊÑüÁü•ÁöÑÊ≥®ÊÑèÂäõÂ§¥ÈáçË¶ÅÊÄßÂ∫¶ÈáèÔºåÊè≠Á§∫‰∫ÜÊ≥®ËßÜÁ∫øÁ¥¢Â¶Ç‰ΩïË∞ÉËäÇTransformerÁöÑÊ≥®ÊÑèÂäõÂä®ÊÄÅ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑÁõÆÊ†áÊ£ÄÊµãÊñπÊ≥ïÈÄöÂ∏∏Âπ≥Á≠âÂú∞ÂØπÂæÖÂõæÂÉèÊàñËßÜÈ¢ë‰∏≠ÁöÑÊâÄÊúâÂå∫ÂüüÔºåËÄåÂøΩÁï•‰∫Ü‰∫∫Á±ªËßÜËßâÊ≥®ÊÑèÂäõÁöÑÈáçË¶ÅÊÄß„ÄÇÂú®‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜÈ¢ë‰∏≠Ôºå‰∫∫Á±ªÁöÑÊ≥®ËßÜÁÇπÂæÄÂæÄÈõÜ‰∏≠Âú®‰∏éÂΩìÂâç‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÂØπË±°ÊàñÂå∫Âüü‰∏ä„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞Âà©Áî®‰∫∫Á±ªÁöÑÊ≥®ËßÜ‰ø°ÊÅØÊù•ÊèêÈ´òÁõÆÊ†áÊ£ÄÊµãÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöEyes on TargetÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞Ü‰∫∫Á±ªÁöÑÊ≥®ËßÜ‰ø°ÊÅØ‰Ωú‰∏∫‰∏ÄÁßçÂÖàÈ™åÁü•ËØÜÔºåÂºïÂØºÁõÆÊ†áÊ£ÄÊµãÊ®°ÂûãÊõ¥Âä†ÂÖ≥Ê≥®‰∫∫ÁúºÊ≥®ËßÜÁöÑÂå∫Âüü„ÄÇÈÄöËøáÂ∞ÜÊ≥®ËßÜË°çÁîüÁöÑÁâπÂæÅËûçÂÖ•Âà∞Vision Transformer (ViT)ÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂‰∏≠ÔºåÊ®°ÂûãÂèØ‰ª•Êõ¥Â•ΩÂú∞ÈÄâÊã©‰∏é‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÁ©∫Èó¥ÁâπÂæÅÔºå‰ªéËÄåÊèêÈ´òÁõÆÊ†áÊ£ÄÊµãÁöÑÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöEyes on TargetÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) Ê≥®ËßÜÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºö‰ªéÊ≥®ËßÜÊï∞ÊçÆ‰∏≠ÊèêÂèñÊúâÁî®ÁöÑÁâπÂæÅÔºå‰æãÂ¶ÇÊ≥®ËßÜ‰ΩçÁΩÆ„ÄÅÊ≥®ËßÜÊåÅÁª≠Êó∂Èó¥Á≠â„ÄÇ2) Ê∑±Â∫¶ÊÑüÁü•Ê®°ÂùóÔºöÂà©Áî®Ê∑±Â∫¶‰ø°ÊÅØÊù•Â¢ûÂº∫ÂØπÂú∫ÊôØÁöÑÁêÜËß£ÔºåÂπ∂Â∏ÆÂä©Ê®°ÂûãÊõ¥Â•ΩÂú∞ÂÆö‰ΩçÁõÆÊ†á„ÄÇ3) Ê≥®ËßÜÂºïÂØºÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºöÂ∞ÜÊ≥®ËßÜÁâπÂæÅÂíåÊ∑±Â∫¶‰ø°ÊÅØÊ≥®ÂÖ•Âà∞ViTÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂‰∏≠ÔºåÂºïÂØºÊ®°ÂûãÂÖ≥Ê≥®‰∫∫ÁúºÊ≥®ËßÜÁöÑÂå∫Âüü„ÄÇ4) ÁõÆÊ†áÊ£ÄÊµãÊ®°ÂùóÔºöÂà©Áî®ViTÊèêÂèñÁöÑÁâπÂæÅËøõË°åÁõÆÊ†áÊ£ÄÊµã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÊ≥®ËßÜ‰ø°ÊÅØÊúâÊïàÂú∞ËûçÂÖ•Âà∞Vision TransformerÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂‰∏≠„ÄÇ‰∏é‰º†ÁªüÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂‰∏çÂêåÔºåËØ•ÊñπÊ≥ï‰∏ç‰ªÖ‰ªÖÂÖ≥Ê≥®ÂõæÂÉèÊàñËßÜÈ¢ëÊú¨Ë∫´ÁöÑÂÜÖÂÆπÔºåËøòËÄÉËôë‰∫Ü‰∫∫Á±ªÁöÑËßÜËßâÊ≥®ÊÑèÂäõÔºå‰ªéËÄå‰ΩøÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£Âú∫ÊôØÂπ∂ÊèêÈ´òÁõÆÊ†áÊ£ÄÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇÊ≠§Â§ñÔºåÂºïÂÖ•‰∫ÜÊ∑±Â∫¶ÊÑüÁü•Ê®°ÂùóÔºåËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊ®°ÂûãÂØπ‰∏âÁª¥Âú∫ÊôØÁöÑÁêÜËß£ËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰∏≠ÂÖ≥ÈîÆÁöÑËÆæËÆ°ÂåÖÊã¨Ôºö1) Â¶Ç‰ΩïÊúâÊïàÂú∞ÊèêÂèñÂíåË°®Á§∫Ê≥®ËßÜÁâπÂæÅÔºõ2) Â¶Ç‰ΩïÂ∞ÜÊ≥®ËßÜÁâπÂæÅÂíåÊ∑±Â∫¶‰ø°ÊÅØËûçÂÖ•Âà∞ViTÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂‰∏≠Ôºõ3) Â¶Ç‰ΩïËÆæËÆ°ÊçüÂ§±ÂáΩÊï∞Êù•‰ºòÂåñÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇÂÖ∑‰ΩìÁöÑÊäÄÊúØÁªÜËäÇÂåÖÊã¨Ê≥®ËßÜÁâπÂæÅÁöÑÁºñÁ†ÅÊñπÂºè„ÄÅÊ≥®ÊÑèÂäõÊú∫Âà∂ÁöÑËûçÂêàÁ≠ñÁï•‰ª•ÂèäÊçüÂ§±ÂáΩÊï∞ÁöÑÈÄâÊã©Á≠â„ÄÇËÆ∫ÊñáËøòÊèêÂá∫‰∫Ü‰∏ÄÁßçÊ≥®ËßÜÊÑüÁü•ÁöÑÊ≥®ÊÑèÂäõÂ§¥ÈáçË¶ÅÊÄßÂ∫¶ÈáèÔºåÁî®‰∫éËß£ÈáäÊ®°ÂûãË°å‰∏∫„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEyes on TargetÊ°ÜÊû∂Âú®Ëá™ÂÆö‰πâÊ®°ÊãüÂô®Êï∞ÊçÆÈõÜÂíåÂÖ¨ÂÖ±Âü∫ÂáÜÔºàÂåÖÊã¨Ego4D Ego-MotionÂíåEgo-CH-GazeÊï∞ÊçÆÈõÜÔºâ‰∏äÔºåÊ£ÄÊµãÁ≤æÂ∫¶Áõ∏ÂØπ‰∫é‰∏éÊ≥®ËßÜÊó†ÂÖ≥ÁöÑÂü∫Á∫øÂßãÁªàÊúâÊâÄÊèêÈ´ò„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÂú®Ego4DÊï∞ÊçÆÈõÜ‰∏äÔºåËØ•ÊñπÊ≥ïÂú®ÁõÆÊ†áÊ£ÄÊµã‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåËØÅÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫é‰∫∫Êú∫‰∫§‰∫í„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÊô∫ËÉΩËæÖÂä©È©æÈ©∂Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÁêÜËß£‰∫∫Á±ªÁöÑËßÜËßâÊ≥®ÊÑèÂäõÔºåÊú∫Âô®ÂèØ‰ª•Êõ¥Â•ΩÂú∞‰∏é‰∫∫Á±ªËøõË°åÂçè‰ΩúÔºåÊèêÈ´òÂ∑•‰ΩúÊïàÁéáÂíåÂÆâÂÖ®ÊÄß„ÄÇ‰æãÂ¶ÇÔºåÂú®Êô∫ËÉΩËæÖÂä©È©æÈ©∂‰∏≠ÔºåÁ≥ªÁªüÂèØ‰ª•Ê†πÊçÆÈ©æÈ©∂ÂëòÁöÑÊ≥®ËßÜÁÇπÊù•È¢ÑÊµãÂÖ∂Ë°å‰∏∫ÔºåÂπ∂ÂèäÊó∂ÂèëÂá∫Ë≠¶ÂëäÊàñÈááÂèñÊé™ÊñΩÔºå‰ªéËÄåÈÅøÂÖç‰∫§ÈÄö‰∫ãÊïÖÁöÑÂèëÁîü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Human gaze offers rich supervisory signals for understanding visual attention in complex visual environments. In this paper, we propose Eyes on Target, a novel depth-aware and gaze-guided object detection framework designed for egocentric videos. Our approach injects gaze-derived features into the attention mechanism of a Vision Transformer (ViT), effectively biasing spatial feature selection toward human-attended regions. Unlike traditional object detectors that treat all regions equally, our method emphasises viewer-prioritised areas to enhance object detection. We validate our method on an egocentric simulator dataset where human visual attention is critical for task assessment, illustrating its potential in evaluating human performance in simulation scenarios. We evaluate the effectiveness of our gaze-integrated model through extensive experiments and ablation studies, demonstrating consistent gains in detection accuracy over gaze-agnostic baselines on both the custom simulator dataset and public benchmarks, including Ego4D Ego-Motion and Ego-CH-Gaze datasets. To interpret model behaviour, we also introduce a gaze-aware attention head importance metric, revealing how gaze cues modulate transformer attention dynamics.

