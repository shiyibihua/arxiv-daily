---
layout: default
title: EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced Supervised Fine-Tuning
---

# EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced Supervised Fine-Tuning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.05553" target="_blank" class="toolbar-btn">arXiv: 2511.05553v1</a>
    <a href="https://arxiv.org/pdf/2511.05553.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.05553v1" 
            onclick="toggleFavorite(this, '2511.05553v1', 'EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced Supervised Fine-Tuning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xinyan Cai, Shiguang Wu, Dafeng Chi, Yuzheng Zhuang, Xingyue Quan, Jianye Hao, Qiang Guan

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-03

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫EVLPÔºåÈÄöËøáÂº∫ÂåñÁõëÁù£ÂæÆË∞ÉÂ≠¶‰π†Áªü‰∏ÄÂÖ∑Ë∫´ËßÜËßâ-ËØ≠Ë®ÄËßÑÂàíÂô®ÔºåËß£ÂÜ≥ÈïøÁ®ãÊìç‰Ωú‰ªªÂä°‰∏≠ÁöÑÂ§öÊ®°ÊÄÅËßÑÂàíÈóÆÈ¢ò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `ÂÖ∑Ë∫´Êô∫ËÉΩ` `ËßÜËßâËØ≠Ë®ÄËßÑÂàí` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Âº∫ÂåñÂ≠¶‰π†` `ÈïøÁ®ãÊìç‰Ωú‰ªªÂä°`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Â§çÊùÇÂÖ∑Ë∫´ÈïøÁ®ãÊìç‰Ωú‰ªªÂä°‰∏≠ÔºåÁº∫‰πèÁªü‰∏ÄÁöÑÂ§öÊ®°ÊÄÅÁîüÊàêÊ°ÜÊû∂ÔºåÂØºËá¥ËØ≠Ë®ÄÊé®ÁêÜÂíåËßÜËßâÁ©∫Èó¥ÊÉ≥Ë±°ÁöÑÂçèÂêåÈõÜÊàê‰∏çË∂≥„ÄÇ
2. EVLPÈÄöËøáÁªü‰∏ÄÁöÑÂ§öÊ®°ÊÄÅÁîüÊàêÊ°ÜÊû∂ÔºåÂä®ÊÄÅÊÑüÁü•È¢ÑËÆ≠ÁªÉÂíåÂº∫ÂåñÁõëÁù£ÂæÆË∞ÉÔºåÂÆûÁé∞‰∫ÜËØ≠Ë®ÄÊé®ÁêÜÂíåËßÜËßâÁîüÊàêÁöÑËÅîÂêàÂª∫Ê®°„ÄÇ
3. ËØ•ÊñπÊ≥ïÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ÂØπÈΩêÊñáÊú¨Âä®‰ΩúÂíåÁîüÊàêÂõæÂÉèÁöÑÁ©∫Èó¥ÈÄªËæëÔºå‰ΩøÊ®°ÂûãÂÖ∑Â§áÁ©∫Èó¥ÊÑüÁü•ËÉΩÂäõÁöÑÂ§öÊ®°ÊÄÅËßÑÂàíËÉΩÂäõÔºåÊèêÂçá‰∫ÜÈïøÁ®ã‰ªªÂä°ÁöÑÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫EVLPÔºàEmbodied Vision-Language PlannerÔºâÁöÑÂàõÊñ∞Â§öÊ®°ÊÄÅÁªü‰∏ÄÁîüÊàêÊ°ÜÊû∂ÔºåÁî®‰∫éËÅîÂêàÂª∫Ê®°ËØ≠Ë®ÄÊé®ÁêÜÂíåËßÜËßâÁîüÊàêÔºå‰ªéËÄåÂÆûÁé∞ÈïøÁ®ã‰ªªÂä°ÁöÑÂ§öÊ®°ÊÄÅËßÑÂàí„ÄÇÁé∞ÊúâÊñπÊ≥ïÊú™ËÉΩÈááÁî®Áªü‰∏ÄÁöÑÁîüÊàêÊ°ÜÊû∂ËøõË°åÂ§öÊ®°ÊÄÅËßÑÂàíÔºåÂØºËá¥Â§öÊ®°ÊÄÅËßÑÂàí‰∏ç‰∏ÄËá¥„ÄÇEVLPÈÄöËøáÂä®ÊÄÅÈ¢ÑËÆ≠ÁªÉÂíåÂº∫ÂåñÂØπÈΩêÁöÑÊñ∞ÂûãËÆ≠ÁªÉÊµÅÁ®ãÊù•ÂÆûÁé∞Â§öÊ®°ÊÄÅËßÑÂàí„ÄÇÂÖ∂Ê†∏ÂøÉÂàõÊñ∞ÂåÖÊã¨ÔºöÁªü‰∏ÄÁöÑÂ§öÊ®°ÊÄÅÁîüÊàêÊ°ÜÊû∂ÔºåÈõÜÊàê‰∫ÜËØ≠‰πâ‰ø°ÊÅØÂíåÁ©∫Èó¥ÁâπÂæÅ‰ª•Êèê‰æõÂÖ®Èù¢ÁöÑËßÜËßâÊÑüÁü•ÔºåÂπ∂Áõ¥Êé•Â≠¶‰π†Á¶ªÊï£ÂõæÂÉèÁöÑËÅîÂêàÂàÜÂ∏É‰ª•ËøõË°åÂçïÊ≠•ËßÜËßâÂêàÊàêÔºõÂèåÂêëÂä®ÊÄÅÂØπÈΩêÁ≠ñÁï•ÔºåÈááÁî®ÈÄÜÂä®ÂäõÂ≠¶‰ªªÂä°ÂíåÊ≠£ÂêëÂä®ÂäõÂ≠¶‰ªªÂä°ÔºåÊúâÊïàÂä†Âº∫Áªü‰∏ÄÁâπÂæÅÁ©∫Èó¥ÂÜÖÁöÑÂ§öÊ®°ÊÄÅÁõ∏ÂÖ≥ÊÄßÔºõ‰ª•ÂèäÂº∫ÂåñÁõëÁù£ÂæÆË∞ÉÔºåÂú®Áªü‰∏ÄÁîüÊàêÁ©∫Èó¥‰∏≠ËøõË°åÂü∫‰∫éÊåá‰ª§ÁöÑÂæÆË∞ÉÊó∂ÔºåÊûÑÂª∫Âº∫ÂåñÊçüÂ§±‰ª•ÂØπÈΩêÊñáÊú¨Âä®‰ΩúÂíåÁîüÊàêÂõæÂÉè‰πãÈó¥ÁöÑÁ©∫Èó¥ÈÄªËæëÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üËé∑ÂæóÂÖ∑ÊúâÁ©∫Èó¥ÊÑüÁü•ËÉΩÂäõÁöÑÂ§öÊ®°ÊÄÅËßÑÂàíËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§çÊùÇÂÖ∑Ë∫´ÈïøÁ®ãÊìç‰Ωú‰ªªÂä°‰∏≠ÔºåÁé∞ÊúâÊñπÊ≥ïÊó†Ê≥ïÊúâÊïàÁªü‰∏ÄËØ≠Ë®ÄÊé®ÁêÜÂíåËßÜËßâÁ©∫Èó¥ÊÉ≥Ë±°ËøõË°åÂ§öÊ®°ÊÄÅËßÑÂàíÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈááÁî®ÂàÜÁ¶ªÁöÑÊ®°ÂùóËøõË°åËØ≠Ë®ÄÁêÜËß£ÂíåËßÜËßâÁîüÊàêÔºåÂØºËá¥‰∏§ËÄÖ‰πãÈó¥Áº∫‰πè‰∏ÄËá¥ÊÄßÔºåÈöæ‰ª•ËøõË°åÊúâÊïàÁöÑ‰ªªÂä°ÂàÜËß£ÂíåÊâßË°å„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊèêÂá∫‰∏Ä‰∏™Áªü‰∏ÄÁöÑÂ§öÊ®°ÊÄÅÁîüÊàêÊ°ÜÊû∂ÔºåÂ∞ÜËØ≠Ë®ÄÊé®ÁêÜÂíåËßÜËßâÁîüÊàêÊï¥ÂêàÂà∞‰∏Ä‰∏™Ê®°Âûã‰∏≠„ÄÇÈÄöËøáÂä®ÊÄÅÈ¢ÑËÆ≠ÁªÉÂíåÂº∫ÂåñÂØπÈΩêÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üÂ≠¶‰π†Âà∞ËØ≠Ë®ÄÂíåËßÜËßâ‰πãÈó¥ÁöÑÊ∑±Â±ÇÂÖ≥ËÅîÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÊúâÊïà„ÄÅÊõ¥ÂáÜÁ°ÆÁöÑÂ§öÊ®°ÊÄÅËßÑÂàí„ÄÇËøôÊ†∑ËÆæËÆ°ÁöÑÁõÆÁöÑÊòØ‰∏∫‰∫ÜÂÖãÊúçÁé∞ÊúâÊñπÊ≥ï‰∏≠Ê®°ÂùóÂàÜÁ¶ªÂ∏¶Êù•ÁöÑ‰∏ç‰∏ÄËá¥ÊÄßÈóÆÈ¢òÔºåÊèêÈ´òÊ®°ÂûãÂú®Â§çÊùÇ‰ªªÂä°‰∏≠ÁöÑË°®Áé∞„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöEVLPÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÁªÑÊàêÈÉ®ÂàÜÔºö1) Áªü‰∏ÄÁöÑÂ§öÊ®°ÊÄÅÁîüÊàêÊ°ÜÊû∂ÔºöËØ•Ê°ÜÊû∂ÈõÜÊàê‰∫ÜËØ≠‰πâ‰ø°ÊÅØÂíåÁ©∫Èó¥ÁâπÂæÅÔºåÁî®‰∫éÂÖ®Èù¢ÁöÑËßÜËßâÊÑüÁü•ÔºåÂπ∂Áõ¥Êé•Â≠¶‰π†Á¶ªÊï£ÂõæÂÉèÁöÑËÅîÂêàÂàÜÂ∏ÉÔºåÁî®‰∫éÂçïÊ≠•ËßÜËßâÂêàÊàê„ÄÇ2) Âä®ÊÄÅÊÑüÁü•È¢ÑËÆ≠ÁªÉÔºöÈááÁî®ÂèåÂêëÂä®ÊÄÅÂØπÈΩêÁ≠ñÁï•ÔºåÂåÖÊã¨ÈÄÜÂä®ÂäõÂ≠¶‰ªªÂä°ÂíåÊ≠£ÂêëÂä®ÂäõÂ≠¶‰ªªÂä°Ôºå‰ª•Âä†Âº∫Áªü‰∏ÄÁâπÂæÅÁ©∫Èó¥ÂÜÖÁöÑÂ§öÊ®°ÊÄÅÁõ∏ÂÖ≥ÊÄß„ÄÇ3) Âº∫ÂåñÁõëÁù£ÂæÆË∞ÉÔºöÂú®Áªü‰∏ÄÁîüÊàêÁ©∫Èó¥‰∏≠ËøõË°åÂü∫‰∫éÊåá‰ª§ÁöÑÂæÆË∞ÉÔºåÂπ∂ÊûÑÂª∫Âº∫ÂåñÊçüÂ§±Ôºå‰ª•ÂØπÈΩêÊñáÊú¨Âä®‰ΩúÂíåÁîüÊàêÂõæÂÉè‰πãÈó¥ÁöÑÁ©∫Èó¥ÈÄªËæë„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÂ§öÊ®°ÊÄÅÁîüÊàêÊ°ÜÊû∂ÔºåËÉΩÂ§üÂêåÊó∂Â§ÑÁêÜËØ≠Ë®ÄÂíåËßÜËßâ‰ø°ÊÅØÔºåÂπ∂Â≠¶‰π†ÂÆÉ‰ª¨‰πãÈó¥ÁöÑÂÖ≥ËÅî„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåEVLPÈÅøÂÖç‰∫ÜÊ®°ÂùóÂàÜÁ¶ªÂ∏¶Êù•ÁöÑ‰∏ç‰∏ÄËá¥ÊÄßÈóÆÈ¢òÔºåËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ËøõË°åÂ§öÊ®°ÊÄÅËßÑÂàí„ÄÇÊ≠§Â§ñÔºåÂä®ÊÄÅÊÑüÁü•È¢ÑËÆ≠ÁªÉÂíåÂº∫ÂåñÁõëÁù£ÂæÆË∞ÉËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Áªü‰∏ÄÁöÑÂ§öÊ®°ÊÄÅÁîüÊàêÊ°ÜÊû∂‰∏≠Ôºå‰ΩøÁî®‰∫ÜÂèØÂ≠¶‰π†ÁöÑË∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÁî®‰∫éÂçèË∞ÉËØ≠Ë®ÄÂíåËßÜËßâÂª∫Ê®°„ÄÇÂä®ÊÄÅÊÑüÁü•È¢ÑËÆ≠ÁªÉ‰∏≠ÁöÑÈÄÜÂä®ÂäõÂ≠¶‰ªªÂä°ÂíåÊ≠£ÂêëÂä®ÂäõÂ≠¶‰ªªÂä°ÔºåÊó®Âú®‰ªé‰∏çÂêåÊñπÂêëÂä†Âº∫Â§öÊ®°ÊÄÅÁõ∏ÂÖ≥ÊÄß„ÄÇÂº∫ÂåñÁõëÁù£ÂæÆË∞É‰∏≠ÁöÑÂº∫ÂåñÊçüÂ§±ÔºåÁî®‰∫éÂØπÈΩêÊñáÊú¨Âä®‰ΩúÂíåÁîüÊàêÂõæÂÉè‰πãÈó¥ÁöÑÁ©∫Èó¥ÈÄªËæëÔºåÂÖ∑‰ΩìÂΩ¢ÂºèÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÈÄöËøáÂÆûÈ™åÈ™åËØÅ‰∫ÜEVLPÁöÑÊúâÊïàÊÄßÔºåÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÊú™Áü•„ÄÇÂº∫ÂåñÁõëÁù£ÂæÆË∞ÉÊòæËëóÊèêÂçá‰∫ÜÊ®°ÂûãÂú®ÈïøÁ®ã‰ªªÂä°‰∏≠ÁöÑË°®Áé∞ÔºåË°®ÊòéEVLPËÉΩÂ§üÊúâÊïàÂú∞Â≠¶‰π†Âà∞ËØ≠Ë®ÄÂíåËßÜËßâ‰πãÈó¥ÁöÑÂÖ≥ËÅîÔºåÂπ∂ËøõË°åÂáÜÁ°ÆÁöÑÂ§öÊ®°ÊÄÅËßÑÂàí„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEVLPÂú®Â§öÊ®°ÊÄÅËßÑÂàí‰ªªÂä°‰∏ä‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂÖ∑‰ΩìÁöÑÊèêÂçáÂπÖÂ∫¶Êú™Áü•„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÅËá™Âä®È©æÈ©∂„ÄÅËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÔºåEVLPÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫ÁêÜËß£‰∫∫Á±ªÊåá‰ª§ÔºåÂπ∂ÁîüÊàêÁõ∏Â∫îÁöÑËßÜËßâÂõæÂÉèÂ∫èÂàóÔºå‰ªéËÄåÂÆåÊàêÂ§çÊùÇÁöÑ‰ªªÂä°„ÄÇÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåEVLPÂèØ‰ª•Áî®‰∫éÁêÜËß£‰∫§ÈÄöËßÑÂàôÂíåÂú∫ÊôØ‰ø°ÊÅØÔºåÂπ∂ÁîüÊàêÁõ∏Â∫îÁöÑÈ©æÈ©∂Á≠ñÁï•„ÄÇËØ•Á†îÁ©∂ÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÂπøÈòîÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In complex embodied long-horizon manipulation tasks, effective task decomposition and execution require synergistic integration of textual logical reasoning and visual-spatial imagination to ensure efficient and accurate operation. Current methods fail to adopt a unified generation framework for multimodal planning, lead to inconsistent in multimodal planning. To address this challenge, we present \textbf{EVLP (Embodied Vision-Language Planner)}, an innovative multimodal unified generation framework that jointly models linguistic reasoning and visual generation. Our approach achieves multimodal planning for long-horizon tasks through a novel training pipeline incorporating dynamic pretraining and reinforced alignment. Our core innovations consist of three key components: \textbf{1) Unified Multimodal Generation Framework}: For understanding, We integrate semantic information with spatial features to provide comprehensive visual perception. For generation, we directly learn the joint distribution of discrete images for one-step visual synthesis, enabling coordinated language-visual modeling through learnable cross-modal attention mechanisms. \textbf{2) Dynamic Perception Pretraining}: We propose a bidirectional dynamic alignment strategy employing inverse dynamics tasks and forward dynamics tasks, effectively strengthening multimodal correlations within a unified feature space. \textbf{3) Reinforced Supervised Fine-Tuning}: While conducting instruction-based fine-tuning in the unified generation space, we construct a reinforce loss to align the spatial logic between textual actions and generated images, enabling the model to acquire spatio-awared multimodal planning capabilities.

