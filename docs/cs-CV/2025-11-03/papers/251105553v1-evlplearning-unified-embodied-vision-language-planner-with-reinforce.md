---
layout: default
title: EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced Supervised Fine-Tuning
---

# EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced Supervised Fine-Tuning

**arXiv**: [2511.05553v1](https://arxiv.org/abs/2511.05553) | [PDF](https://arxiv.org/pdf/2511.05553.pdf)

**ä½œè€…**: Xinyan Cai, Shiguang Wu, Dafeng Chi, Yuzheng Zhuang, Xingyue Quan, Jianye Hao, Qiang Guan

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-03

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEVLPï¼Œé€šè¿‡å¼ºåŒ–ç›‘ç£å¾®è°ƒå­¦ä¹ ç»Ÿä¸€å…·èº«è§†è§‰-è¯­è¨€è§„åˆ’å™¨ï¼Œè§£å†³é•¿ç¨‹æ“ä½œä»»åŠ¡ä¸­çš„å¤šæ¨¡æ€è§„åˆ’é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å…·èº«æ™ºèƒ½` `è§†è§‰è¯­è¨€è§„åˆ’` `å¤šæ¨¡æ€å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `é•¿ç¨‹æ“ä½œä»»åŠ¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨å¤æ‚å…·èº«é•¿ç¨‹æ“ä½œä»»åŠ¡ä¸­ï¼Œç¼ºä¹ç»Ÿä¸€çš„å¤šæ¨¡æ€ç”Ÿæˆæ¡†æž¶ï¼Œå¯¼è‡´è¯­è¨€æŽ¨ç†å’Œè§†è§‰ç©ºé—´æƒ³è±¡çš„ååŒé›†æˆä¸è¶³ã€‚
2. EVLPé€šè¿‡ç»Ÿä¸€çš„å¤šæ¨¡æ€ç”Ÿæˆæ¡†æž¶ï¼ŒåŠ¨æ€æ„ŸçŸ¥é¢„è®­ç»ƒå’Œå¼ºåŒ–ç›‘ç£å¾®è°ƒï¼Œå®žçŽ°äº†è¯­è¨€æŽ¨ç†å’Œè§†è§‰ç”Ÿæˆçš„è”åˆå»ºæ¨¡ã€‚
3. è¯¥æ–¹æ³•é€šè¿‡å¼ºåŒ–å­¦ä¹ å¯¹é½æ–‡æœ¬åŠ¨ä½œå’Œç”Ÿæˆå›¾åƒçš„ç©ºé—´é€»è¾‘ï¼Œä½¿æ¨¡åž‹å…·å¤‡ç©ºé—´æ„ŸçŸ¥èƒ½åŠ›çš„å¤šæ¨¡æ€è§„åˆ’èƒ½åŠ›ï¼Œæå‡äº†é•¿ç¨‹ä»»åŠ¡çš„æ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºEVLPï¼ˆEmbodied Vision-Language Plannerï¼‰çš„åˆ›æ–°å¤šæ¨¡æ€ç»Ÿä¸€ç”Ÿæˆæ¡†æž¶ï¼Œç”¨äºŽè”åˆå»ºæ¨¡è¯­è¨€æŽ¨ç†å’Œè§†è§‰ç”Ÿæˆï¼Œä»Žè€Œå®žçŽ°é•¿ç¨‹ä»»åŠ¡çš„å¤šæ¨¡æ€è§„åˆ’ã€‚çŽ°æœ‰æ–¹æ³•æœªèƒ½é‡‡ç”¨ç»Ÿä¸€çš„ç”Ÿæˆæ¡†æž¶è¿›è¡Œå¤šæ¨¡æ€è§„åˆ’ï¼Œå¯¼è‡´å¤šæ¨¡æ€è§„åˆ’ä¸ä¸€è‡´ã€‚EVLPé€šè¿‡åŠ¨æ€é¢„è®­ç»ƒå’Œå¼ºåŒ–å¯¹é½çš„æ–°åž‹è®­ç»ƒæµç¨‹æ¥å®žçŽ°å¤šæ¨¡æ€è§„åˆ’ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼šç»Ÿä¸€çš„å¤šæ¨¡æ€ç”Ÿæˆæ¡†æž¶ï¼Œé›†æˆäº†è¯­ä¹‰ä¿¡æ¯å’Œç©ºé—´ç‰¹å¾ä»¥æä¾›å…¨é¢çš„è§†è§‰æ„ŸçŸ¥ï¼Œå¹¶ç›´æŽ¥å­¦ä¹ ç¦»æ•£å›¾åƒçš„è”åˆåˆ†å¸ƒä»¥è¿›è¡Œå•æ­¥è§†è§‰åˆæˆï¼›åŒå‘åŠ¨æ€å¯¹é½ç­–ç•¥ï¼Œé‡‡ç”¨é€†åŠ¨åŠ›å­¦ä»»åŠ¡å’Œæ­£å‘åŠ¨åŠ›å­¦ä»»åŠ¡ï¼Œæœ‰æ•ˆåŠ å¼ºç»Ÿä¸€ç‰¹å¾ç©ºé—´å†…çš„å¤šæ¨¡æ€ç›¸å…³æ€§ï¼›ä»¥åŠå¼ºåŒ–ç›‘ç£å¾®è°ƒï¼Œåœ¨ç»Ÿä¸€ç”Ÿæˆç©ºé—´ä¸­è¿›è¡ŒåŸºäºŽæŒ‡ä»¤çš„å¾®è°ƒæ—¶ï¼Œæž„å»ºå¼ºåŒ–æŸå¤±ä»¥å¯¹é½æ–‡æœ¬åŠ¨ä½œå’Œç”Ÿæˆå›¾åƒä¹‹é—´çš„ç©ºé—´é€»è¾‘ï¼Œä½¿æ¨¡åž‹èƒ½å¤ŸèŽ·å¾—å…·æœ‰ç©ºé—´æ„ŸçŸ¥èƒ½åŠ›çš„å¤šæ¨¡æ€è§„åˆ’èƒ½åŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤æ‚å…·èº«é•¿ç¨‹æ“ä½œä»»åŠ¡ä¸­ï¼ŒçŽ°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆç»Ÿä¸€è¯­è¨€æŽ¨ç†å’Œè§†è§‰ç©ºé—´æƒ³è±¡è¿›è¡Œå¤šæ¨¡æ€è§„åˆ’çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨åˆ†ç¦»çš„æ¨¡å—è¿›è¡Œè¯­è¨€ç†è§£å’Œè§†è§‰ç”Ÿæˆï¼Œå¯¼è‡´ä¸¤è€…ä¹‹é—´ç¼ºä¹ä¸€è‡´æ€§ï¼Œéš¾ä»¥è¿›è¡Œæœ‰æ•ˆçš„ä»»åŠ¡åˆ†è§£å’Œæ‰§è¡Œã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æå‡ºä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€ç”Ÿæˆæ¡†æž¶ï¼Œå°†è¯­è¨€æŽ¨ç†å’Œè§†è§‰ç”Ÿæˆæ•´åˆåˆ°ä¸€ä¸ªæ¨¡åž‹ä¸­ã€‚é€šè¿‡åŠ¨æ€é¢„è®­ç»ƒå’Œå¼ºåŒ–å¯¹é½ï¼Œä½¿æ¨¡åž‹èƒ½å¤Ÿå­¦ä¹ åˆ°è¯­è¨€å’Œè§†è§‰ä¹‹é—´çš„æ·±å±‚å…³è”ï¼Œä»Žè€Œå®žçŽ°æ›´æœ‰æ•ˆã€æ›´å‡†ç¡®çš„å¤šæ¨¡æ€è§„åˆ’ã€‚è¿™æ ·è®¾è®¡çš„ç›®çš„æ˜¯ä¸ºäº†å…‹æœçŽ°æœ‰æ–¹æ³•ä¸­æ¨¡å—åˆ†ç¦»å¸¦æ¥çš„ä¸ä¸€è‡´æ€§é—®é¢˜ï¼Œæé«˜æ¨¡åž‹åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨çŽ°ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šEVLPçš„æ•´ä½“æ¡†æž¶åŒ…å«ä¸‰ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼š1) ç»Ÿä¸€çš„å¤šæ¨¡æ€ç”Ÿæˆæ¡†æž¶ï¼šè¯¥æ¡†æž¶é›†æˆäº†è¯­ä¹‰ä¿¡æ¯å’Œç©ºé—´ç‰¹å¾ï¼Œç”¨äºŽå…¨é¢çš„è§†è§‰æ„ŸçŸ¥ï¼Œå¹¶ç›´æŽ¥å­¦ä¹ ç¦»æ•£å›¾åƒçš„è”åˆåˆ†å¸ƒï¼Œç”¨äºŽå•æ­¥è§†è§‰åˆæˆã€‚2) åŠ¨æ€æ„ŸçŸ¥é¢„è®­ç»ƒï¼šé‡‡ç”¨åŒå‘åŠ¨æ€å¯¹é½ç­–ç•¥ï¼ŒåŒ…æ‹¬é€†åŠ¨åŠ›å­¦ä»»åŠ¡å’Œæ­£å‘åŠ¨åŠ›å­¦ä»»åŠ¡ï¼Œä»¥åŠ å¼ºç»Ÿä¸€ç‰¹å¾ç©ºé—´å†…çš„å¤šæ¨¡æ€ç›¸å…³æ€§ã€‚3) å¼ºåŒ–ç›‘ç£å¾®è°ƒï¼šåœ¨ç»Ÿä¸€ç”Ÿæˆç©ºé—´ä¸­è¿›è¡ŒåŸºäºŽæŒ‡ä»¤çš„å¾®è°ƒï¼Œå¹¶æž„å»ºå¼ºåŒ–æŸå¤±ï¼Œä»¥å¯¹é½æ–‡æœ¬åŠ¨ä½œå’Œç”Ÿæˆå›¾åƒä¹‹é—´çš„ç©ºé—´é€»è¾‘ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€ç”Ÿæˆæ¡†æž¶ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†è¯­è¨€å’Œè§†è§‰ä¿¡æ¯ï¼Œå¹¶å­¦ä¹ å®ƒä»¬ä¹‹é—´çš„å…³è”ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒEVLPé¿å…äº†æ¨¡å—åˆ†ç¦»å¸¦æ¥çš„ä¸ä¸€è‡´æ€§é—®é¢˜ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¿›è¡Œå¤šæ¨¡æ€è§„åˆ’ã€‚æ­¤å¤–ï¼ŒåŠ¨æ€æ„ŸçŸ¥é¢„è®­ç»ƒå’Œå¼ºåŒ–ç›‘ç£å¾®è°ƒè¿›ä¸€æ­¥æå‡äº†æ¨¡åž‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç»Ÿä¸€çš„å¤šæ¨¡æ€ç”Ÿæˆæ¡†æž¶ä¸­ï¼Œä½¿ç”¨äº†å¯å­¦ä¹ çš„è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºŽåè°ƒè¯­è¨€å’Œè§†è§‰å»ºæ¨¡ã€‚åŠ¨æ€æ„ŸçŸ¥é¢„è®­ç»ƒä¸­çš„é€†åŠ¨åŠ›å­¦ä»»åŠ¡å’Œæ­£å‘åŠ¨åŠ›å­¦ä»»åŠ¡ï¼Œæ—¨åœ¨ä»Žä¸åŒæ–¹å‘åŠ å¼ºå¤šæ¨¡æ€ç›¸å…³æ€§ã€‚å¼ºåŒ–ç›‘ç£å¾®è°ƒä¸­çš„å¼ºåŒ–æŸå¤±ï¼Œç”¨äºŽå¯¹é½æ–‡æœ¬åŠ¨ä½œå’Œç”Ÿæˆå›¾åƒä¹‹é—´çš„ç©ºé—´é€»è¾‘ï¼Œå…·ä½“å½¢å¼æœªçŸ¥ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®žéªŒéªŒè¯äº†EVLPçš„æœ‰æ•ˆæ€§ï¼Œå…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªçŸ¥ã€‚å¼ºåŒ–ç›‘ç£å¾®è°ƒæ˜¾è‘—æå‡äº†æ¨¡åž‹åœ¨é•¿ç¨‹ä»»åŠ¡ä¸­çš„è¡¨çŽ°ï¼Œè¡¨æ˜ŽEVLPèƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ åˆ°è¯­è¨€å’Œè§†è§‰ä¹‹é—´çš„å…³è”ï¼Œå¹¶è¿›è¡Œå‡†ç¡®çš„å¤šæ¨¡æ€è§„åˆ’ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒEVLPåœ¨å¤šæ¨¡æ€è§„åˆ’ä»»åŠ¡ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå…·ä½“çš„æå‡å¹…åº¦æœªçŸ¥ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹ŸçŽ°å®žç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æœºå™¨äººæ“ä½œä¸­ï¼ŒEVLPå¯ä»¥å¸®åŠ©æœºå™¨äººç†è§£äººç±»æŒ‡ä»¤ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„è§†è§‰å›¾åƒåºåˆ—ï¼Œä»Žè€Œå®Œæˆå¤æ‚çš„ä»»åŠ¡ã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼ŒEVLPå¯ä»¥ç”¨äºŽç†è§£äº¤é€šè§„åˆ™å’Œåœºæ™¯ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„é©¾é©¶ç­–ç•¥ã€‚è¯¥ç ”ç©¶å…·æœ‰é‡è¦çš„å®žé™…ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In complex embodied long-horizon manipulation tasks, effective task decomposition and execution require synergistic integration of textual logical reasoning and visual-spatial imagination to ensure efficient and accurate operation. Current methods fail to adopt a unified generation framework for multimodal planning, lead to inconsistent in multimodal planning. To address this challenge, we present \textbf{EVLP (Embodied Vision-Language Planner)}, an innovative multimodal unified generation framework that jointly models linguistic reasoning and visual generation. Our approach achieves multimodal planning for long-horizon tasks through a novel training pipeline incorporating dynamic pretraining and reinforced alignment. Our core innovations consist of three key components: \textbf{1) Unified Multimodal Generation Framework}: For understanding, We integrate semantic information with spatial features to provide comprehensive visual perception. For generation, we directly learn the joint distribution of discrete images for one-step visual synthesis, enabling coordinated language-visual modeling through learnable cross-modal attention mechanisms. \textbf{2) Dynamic Perception Pretraining}: We propose a bidirectional dynamic alignment strategy employing inverse dynamics tasks and forward dynamics tasks, effectively strengthening multimodal correlations within a unified feature space. \textbf{3) Reinforced Supervised Fine-Tuning}: While conducting instruction-based fine-tuning in the unified generation space, we construct a reinforce loss to align the spatial logic between textual actions and generated images, enabling the model to acquire spatio-awared multimodal planning capabilities.

