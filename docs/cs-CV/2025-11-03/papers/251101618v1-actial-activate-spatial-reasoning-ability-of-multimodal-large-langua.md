---
layout: default
title: Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models
---

# Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models

**arXiv**: [2511.01618v1](https://arxiv.org/abs/2511.01618) | [PDF](https://arxiv.org/pdf/2511.01618.pdf)

**ä½œè€…**: Xiaoyu Zhan, Wenxuan Huang, Hao Sun, Xinyu Fu, Changfeng Ma, Shaosheng Cao, Bohan Jia, Shaohui Lin, Zhenfei Yin, Lei Bai, Wanli Ouyang, Yuanqi Li, Jie Guo, Yanwen Guo

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-11-03

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Actialï¼šé€šè¿‡è§†è§’å­¦ä¹ æ¿€æ´»å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹çš„ç©ºé—´æŽ¨ç†èƒ½åŠ›**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `ç©ºé—´æŽ¨ç†` `è§†è§’å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `æ•°æ®é›†` `è·¨è§†è§’ä¸€è‡´æ€§` `3Dåœºæ™¯ç†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰MLLMåœ¨3DæŽ¨ç†ä¸­ç¼ºä¹æœ‰æ•ˆçš„ç©ºé—´ä¿¡æ¯æ•æ‰ï¼Œå°¤å…¶åœ¨è·¨è§†è§’ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚
2. æå‡ºè§†è§’å­¦ä¹ ä»»åŠ¡å’ŒViewpoint-100Kæ•°æ®é›†ï¼Œé€šè¿‡ä¸¤é˜¶æ®µå¾®è°ƒç­–ç•¥æå‡ç©ºé—´æŽ¨ç†èƒ½åŠ›ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æ¿€æ´»MLLMçš„ç©ºé—´æŽ¨ç†èƒ½åŠ›ï¼Œæå‡äº†åŸŸå†…å’ŒåŸŸå¤–æŽ¨ç†ä»»åŠ¡çš„æ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹(MLLM)åœ¨2Dè§†è§‰ç†è§£æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œæ¿€å‘äº†äººä»¬å°†å…¶åº”ç”¨äºŽå¤æ‚3DæŽ¨ç†ä»»åŠ¡çš„å…´è¶£ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡åž‹æ˜¯å¦èƒ½æœ‰æ•ˆæ•æ‰åˆ°ç¨³å¥çš„çœŸå®žä¸–ç•Œæ€§èƒ½æ‰€éœ€çš„è¯¦ç»†ç©ºé—´ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯åœ¨ç²¾ç¡®3DæŽ¨ç†çš„å…³é”®è¦æ±‚â€”â€”è·¨è§†è§’ä¸€è‡´æ€§æ–¹é¢ï¼Œä»ç„¶ä¸æ¸…æ¥šã€‚è€ƒè™‘åˆ°è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†è§†è§’å­¦ä¹ ï¼Œè¿™æ˜¯ä¸€é¡¹æ—¨åœ¨è¯„ä¼°å’Œæé«˜MLLMç©ºé—´æŽ¨ç†èƒ½åŠ›çš„ä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºäº†Viewpoint-100Kæ•°æ®é›†ï¼ŒåŒ…å«10ä¸‡ä¸ªä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„å›¾åƒå¯¹ï¼Œå…·æœ‰ä¸åŒçš„è§†è§’å’Œç›¸åº”çš„é—®ç­”å¯¹ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨ä¸¤é˜¶æ®µå¾®è°ƒç­–ç•¥ï¼šé¦–å…ˆï¼Œé€šè¿‡åœ¨Viewpoint-100Kä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒ(SFT)ï¼Œå°†åŸºç¡€çŸ¥è¯†æ³¨å…¥åˆ°åŸºçº¿MLLMä¸­ï¼Œä»Žè€Œåœ¨å¤šä¸ªä»»åŠ¡ä¸­èŽ·å¾—æ˜¾è‘—æ”¹è¿›ï¼›å…¶æ¬¡ï¼Œé€šè¿‡åœ¨æ›´å¹¿æ³›çš„é—®é¢˜é›†ä¸Šä½¿ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)ç®—æ³•è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œå¢žå¼ºæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ··åˆå†·å¯åŠ¨åˆå§‹åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨åŒæ—¶å­¦ä¹ è§†è§’è¡¨ç¤ºå¹¶ä¿æŒè¿žè´¯çš„æŽ¨ç†æ€ç»´ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æ¿€æ´»äº†MLLMçš„ç©ºé—´æŽ¨ç†èƒ½åŠ›ï¼Œæé«˜äº†åœ¨åŸŸå†…å’ŒåŸŸå¤–æŽ¨ç†ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„å‘çŽ°å¼ºè°ƒäº†åœ¨MLLMä¸­å‘å±•åŸºç¡€ç©ºé—´æŠ€èƒ½çš„ä»·å€¼ï¼Œæ”¯æŒæœºå™¨äººã€è‡ªä¸»ç³»ç»Ÿå’Œ3Dåœºæ™¯ç†è§£æ–¹é¢çš„æœªæ¥è¿›å±•ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹åœ¨å¤„ç†éœ€è¦ç²¾ç»†ç©ºé—´æŽ¨ç†çš„ä»»åŠ¡æ—¶è¡¨çŽ°ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ç†è§£ä¸åŒè§†è§’ä¸‹çš„ç‰©ä½“å…³ç³»å’Œä¿æŒè·¨è§†è§’ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨å›°éš¾ã€‚è¿™é™åˆ¶äº†å®ƒä»¬åœ¨æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ç­‰éœ€è¦ç²¾ç¡®3Dåœºæ™¯ç†è§£é¢†åŸŸçš„åº”ç”¨ã€‚çŽ°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ•æ‰å’Œåˆ©ç”¨å›¾åƒä¸­çš„ç©ºé—´ä¿¡æ¯ï¼Œå¯¼è‡´æŽ¨ç†ç»“æžœä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡â€œè§†è§’å­¦ä¹ â€æ¥æå‡MLLMçš„ç©ºé—´æŽ¨ç†èƒ½åŠ›ã€‚å…·ä½“è€Œè¨€ï¼Œé€šè¿‡æž„å»ºåŒ…å«å¤§é‡ä¸åŒè§†è§’å›¾åƒå¯¹çš„æ•°æ®é›†ï¼Œå¹¶è®¾è®¡ç›¸åº”çš„é—®ç­”ä»»åŠ¡ï¼Œè®©æ¨¡åž‹å­¦ä¹ ä»Žä¸åŒè§†è§’è§‚å¯ŸåŒä¸€ç‰©ä½“æ—¶åº”è¯¥å…·å¤‡çš„ç†è§£èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨è®©æ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’ŒæŽ¨ç†3Dç©ºé—´ä¸­çš„ç‰©ä½“å…³ç³»ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1) ç›‘ç£å¾®è°ƒ(SFT)ï¼šåœ¨Viewpoint-100Kæ•°æ®é›†ä¸Šï¼Œä½¿ç”¨ç›‘ç£å­¦ä¹ çš„æ–¹å¼å¯¹MLLMè¿›è¡Œå¾®è°ƒï¼Œæ³¨å…¥åŸºç¡€çš„ç©ºé—´çŸ¥è¯†ã€‚2) å¼ºåŒ–å­¦ä¹ ï¼šä½¿ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)ç®—æ³•ï¼Œåœ¨æ›´å¹¿æ³›çš„é—®é¢˜é›†ä¸Šè¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œè¿›ä¸€æ­¥æå‡æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¿˜ä½¿ç”¨äº†æ··åˆå†·å¯åŠ¨åˆå§‹åŒ–æ–¹æ³•ï¼Œä»¥åŒæ—¶å­¦ä¹ è§†è§’è¡¨ç¤ºå¹¶ä¿æŒæŽ¨ç†è¿žè´¯æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†â€œè§†è§’å­¦ä¹ â€è¿™ä¸€æ¦‚å¿µï¼Œå¹¶è®¾è®¡äº†ç›¸åº”çš„Viewpoint-100Kæ•°æ®é›†å’Œä¸¤é˜¶æ®µå¾®è°ƒç­–ç•¥ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæœ‰æ•ˆåœ°æ¿€æ´»äº†MLLMçš„ç©ºé—´æŽ¨ç†èƒ½åŠ›ã€‚æ··åˆå†·å¯åŠ¨åˆå§‹åŒ–æ–¹æ³•ä¹Ÿæ˜¯ä¸€ä¸ªåˆ›æ–°ç‚¹ï¼Œå®ƒèƒ½å¤ŸåŒæ—¶å­¦ä¹ è§†è§’è¡¨ç¤ºå¹¶ä¿æŒæŽ¨ç†çš„è¿žè´¯æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šViewpoint-100Kæ•°æ®é›†åŒ…å«10ä¸‡ä¸ªä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„å›¾åƒå¯¹ï¼Œæ¯ä¸ªå›¾åƒå¯¹åŒ…å«ä¸åŒè§†è§’çš„åŒä¸€ç‰©ä½“å›¾åƒï¼Œå¹¶é…æœ‰ç›¸åº”çš„é—®ç­”å¯¹ã€‚ä¸¤é˜¶æ®µå¾®è°ƒç­–ç•¥ä¸­ï¼ŒSFTé˜¶æ®µä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ŒGRPOé˜¶æ®µä½¿ç”¨å¼ºåŒ–å­¦ä¹ å¥–åŠ±å‡½æ•°ã€‚æ··åˆå†·å¯åŠ¨åˆå§‹åŒ–æ–¹æ³•çš„å…·ä½“å®žçŽ°ç»†èŠ‚æœªçŸ¥ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæå‡ºçš„æ–¹æ³•æ˜¾è‘—æå‡äº†MLLMåœ¨ç©ºé—´æŽ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚åœ¨Viewpoint-100Kæ•°æ®é›†ä¸Šï¼Œæ€§èƒ½æå‡æ˜¾è‘—ã€‚åŒæ—¶ï¼Œè¯¥æ–¹æ³•åœ¨åŸŸå¤–æŽ¨ç†ä»»åŠ¡ä¸Šä¹Ÿè¡¨çŽ°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¯æ˜Žäº†å…¶æœ‰æ•ˆæ€§ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†çš„å±•ç¤ºã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯å¹¿æ³›åº”ç”¨äºŽæœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€3Dåœºæ™¯ç†è§£ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡MLLMçš„ç©ºé—´æŽ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥ä½¿æœºå™¨äººæ›´å¥½åœ°ç†è§£å‘¨å›´çŽ¯å¢ƒï¼Œä»Žè€Œå®žçŽ°æ›´æ™ºèƒ½çš„å¯¼èˆªå’Œæ“ä½œã€‚åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œå¯ä»¥æé«˜è½¦è¾†å¯¹å¤æ‚äº¤é€šåœºæ™¯çš„ç†è§£å’Œåˆ¤æ–­èƒ½åŠ›ï¼Œä»Žè€Œæå‡å®‰å…¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºŽè™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žç­‰é¢†åŸŸï¼Œæä¾›æ›´é€¼çœŸçš„ç”¨æˆ·ä½“éªŒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in Multimodal Large Language Models (MLLMs) have significantly improved 2D visual understanding, prompting interest in their application to complex 3D reasoning tasks. However, it remains unclear whether these models can effectively capture the detailed spatial information required for robust real-world performance, especially cross-view consistency, a key requirement for accurate 3D reasoning. Considering this issue, we introduce Viewpoint Learning, a task designed to evaluate and improve the spatial reasoning capabilities of MLLMs. We present the Viewpoint-100K dataset, consisting of 100K object-centric image pairs with diverse viewpoints and corresponding question-answer pairs. Our approach employs a two-stage fine-tuning strategy: first, foundational knowledge is injected to the baseline MLLM via Supervised Fine-Tuning (SFT) on Viewpoint-100K, resulting in significant improvements across multiple tasks; second, generalization is enhanced through Reinforcement Learning using the Group Relative Policy Optimization (GRPO) algorithm on a broader set of questions. Additionally, we introduce a hybrid cold-start initialization method designed to simultaneously learn viewpoint representations and maintain coherent reasoning thinking. Experimental results show that our approach significantly activates the spatial reasoning ability of MLLM, improving performance on both in-domain and out-of-domain reasoning tasks. Our findings highlight the value of developing foundational spatial skills in MLLMs, supporting future progress in robotics, autonomous systems, and 3D scene understanding.

