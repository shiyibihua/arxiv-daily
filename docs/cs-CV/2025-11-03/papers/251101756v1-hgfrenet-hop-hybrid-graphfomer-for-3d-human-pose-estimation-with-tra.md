---
layout: default
title: HGFreNet: Hop-hybrid GraphFomer for 3D Human Pose Estimation with Trajectory Consistency in Frequency Domain
---

# HGFreNet: Hop-hybrid GraphFomer for 3D Human Pose Estimation with Trajectory Consistency in Frequency Domain

**arXiv**: [2511.01756v1](https://arxiv.org/abs/2511.01756) | [PDF](https://arxiv.org/pdf/2511.01756.pdf)

**ä½œè€…**: Kai Zhai, Ziyan Huang, Qiang Nie, Xiang Li, Bo Ouyang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-03

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHGFreNetï¼Œåˆ©ç”¨Hop-hybrid GraphFomerè§£å†³å•ç›®è§†é¢‘3Däººä½“å§¿æ€ä¼°è®¡ä¸­çš„è½¨è¿¹ä¸ä¸€è‡´é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Däººä½“å§¿æ€ä¼°è®¡` `å•ç›®è§†é¢‘` `å›¾ç¥žç»ç½‘ç»œ` `Transformer` `é¢‘åŸŸåˆ†æž` `æ—¶ç©ºå»ºæ¨¡` `è½¨è¿¹ä¸€è‡´æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å•ç›®è§†é¢‘3Däººä½“å§¿æ€ä¼°è®¡æ˜“å—æ·±åº¦æ­§ä¹‰å’Œ2Dè¯¯å·®å½±å“ï¼Œå¯¼è‡´3Dè½¨è¿¹ä¸è¿žè´¯ï¼ŒçŽ°æœ‰æ–¹æ³•ç¼ºä¹å¯¹å…¨å±€æ—¶ç©ºç›¸å…³æ€§çš„æœ‰æ•ˆå»ºæ¨¡ã€‚
2. HGFreNeté€šè¿‡Hop-hybridå›¾æ³¨æ„åŠ›æ¨¡å—å’ŒTransformerç¼–ç å™¨ï¼Œæ•æ‰å…³èŠ‚çš„å…¨å±€æ—¶ç©ºç›¸å…³æ€§ï¼Œå¹¶åœ¨é¢‘åŸŸçº¦æŸè½¨è¿¹ä¸€è‡´æ€§ï¼Œæå‡å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§å’Œè¿žè´¯æ€§ã€‚
3. åœ¨Human3.6Må’ŒMPI-INF-3DHPæ•°æ®é›†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼ŒHGFreNetåœ¨ä½ç½®ç²¾åº¦å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢å‡è¶…è¶Šäº†çŽ°æœ‰æœ€ä½³æ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡é’ˆå¯¹å•ç›®è§†é¢‘ä¸­3Däººä½“å§¿æ€ä¼°è®¡çš„2D-to-3Då§¿æ€æå‡é—®é¢˜ï¼Œè¯¥é—®é¢˜é¢ä¸´æ·±åº¦æ¨¡ç³Šå’Œ2Då§¿æ€ä¼°è®¡è¯¯å·®å¯¼è‡´çš„3Dè½¨è¿¹ä¸ä¸€è‡´æ€§æŒ‘æˆ˜ã€‚çŽ°æœ‰æ–¹æ³•ä¸»è¦åœ¨æ—¶åŸŸé™åˆ¶æŠ–åŠ¨ï¼Œå¿½ç•¥äº†éª¨éª¼å…³èŠ‚è¿åŠ¨çš„å…¨å±€æ—¶ç©ºç›¸å…³æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„GraphFormeræž¶æž„HGFreNetï¼Œå®ƒç»“åˆäº†è·³è·ƒæ··åˆç‰¹å¾èšåˆå’Œé¢‘åŸŸä¸­çš„3Dè½¨è¿¹ä¸€è‡´æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè·³è·ƒæ··åˆå›¾æ³¨æ„åŠ›ï¼ˆHGAï¼‰æ¨¡å—å’Œä¸€ä¸ªTransformerç¼–ç å™¨æ¥å»ºæ¨¡å…¨å±€å…³èŠ‚æ—¶ç©ºç›¸å…³æ€§ã€‚HGAæ¨¡å—å°†éª¨éª¼å…³èŠ‚çš„æ‰€æœ‰kè·³é‚»å±…åˆ†ç»„åˆ°ä¸€ä¸ªæ··åˆç»„ä¸­ï¼Œä»¥æ‰©å¤§æ„Ÿå—é‡Žï¼Œå¹¶åº”ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥å‘çŽ°è¿™äº›ç»„çš„æ½œåœ¨ç›¸å…³æ€§ã€‚ç„¶åŽï¼Œæˆ‘ä»¬é€šè¿‡çº¦æŸé¢‘åŸŸä¸­çš„è½¨è¿¹ä¸€è‡´æ€§æ¥åˆ©ç”¨å…¨å±€æ—¶é—´ç›¸å…³æ€§ã€‚ä¸ºäº†ä¸ºè·¨å¸§çš„æ·±åº¦æŽ¨æ–­æä¾›3Dä¿¡æ¯å¹¶ä¿æŒæ—¶é—´ä¸Šçš„ä¸€è‡´æ€§ï¼Œåº”ç”¨åˆæ­¥ç½‘ç»œæ¥ä¼°è®¡3Då§¿æ€ã€‚åœ¨Human3.6Må’ŒMPI-INF-3DHPä¸¤ä¸ªæ ‡å‡†åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®žéªŒã€‚ç»“æžœè¡¨æ˜Žï¼Œæ‰€æå‡ºçš„HGFreNetåœ¨ä½ç½®ç²¾åº¦å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢å‡ä¼˜äºŽæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å•ç›®è§†é¢‘3Däººä½“å§¿æ€ä¼°è®¡ä¸­ï¼Œç”±äºŽ2Då§¿æ€ä¼°è®¡è¯¯å·®å’Œæ·±åº¦æ¨¡ç³Šæ€§å¯¼è‡´çš„3Dè½¨è¿¹ä¸ä¸€è‡´é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æ—¶åŸŸä¸Šçš„å¹³æ»‘ï¼Œä¾‹å¦‚é™åˆ¶ç›¸é‚»å¸§ä¹‹é—´çš„å·®å¼‚ï¼Œä½†å¿½ç•¥äº†éª¨éª¼å…³èŠ‚è¿åŠ¨çš„å…¨å±€æ—¶ç©ºç›¸å…³æ€§ï¼Œå¯¼è‡´ä¼°è®¡çš„3Då§¿æ€åºåˆ—å­˜åœ¨æŠ–åŠ¨å’Œä¸è¿žè´¯çŽ°è±¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨GraphFormeræž¶æž„ï¼Œç»“åˆè·³è·ƒæ··åˆå›¾æ³¨æ„åŠ›æœºåˆ¶å’Œé¢‘åŸŸçº¦æŸï¼ŒåŒæ—¶å»ºæ¨¡å…³èŠ‚çš„å…¨å±€æ—¶ç©ºç›¸å…³æ€§å’Œè½¨è¿¹çš„æ—¶é—´ä¸€è‡´æ€§ã€‚é€šè¿‡æ‰©å¤§æ„Ÿå—é‡Žå’Œåœ¨é¢‘åŸŸè¿›è¡Œçº¦æŸï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°æŠ‘åˆ¶å™ªå£°å’Œæé«˜ä¼°è®¡çš„ç¨³å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šHGFreNetçš„æ•´ä½“æž¶æž„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) 2Då§¿æ€è¾“å…¥ï¼›2) åˆå§‹3Då§¿æ€ä¼°è®¡ç½‘ç»œï¼ˆä¸ºåŽç»­æ¨¡å—æä¾›åˆæ­¥çš„3Dä¿¡æ¯ï¼‰ï¼›3) Hop-hybridå›¾æ³¨æ„åŠ›ï¼ˆHGAï¼‰æ¨¡å—ï¼Œç”¨äºŽèšåˆå…³èŠ‚çš„kè·³é‚»å±…ä¿¡æ¯ï¼›4) Transformerç¼–ç å™¨ï¼Œç”¨äºŽå»ºæ¨¡å…¨å±€æ—¶ç©ºç›¸å…³æ€§ï¼›5) é¢‘åŸŸè½¨è¿¹ä¸€è‡´æ€§çº¦æŸæ¨¡å—ï¼Œç”¨äºŽä¿è¯ä¼°è®¡çš„3Då§¿æ€åºåˆ—åœ¨æ—¶é—´ä¸Šçš„å¹³æ»‘æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽä»¥ä¸‹å‡ ç‚¹ï¼š1) æå‡ºäº†Hop-hybridå›¾æ³¨æ„åŠ›ï¼ˆHGAï¼‰æ¨¡å—ï¼Œé€šè¿‡å°†kè·³é‚»å±…åˆ†ç»„å¹¶åº”ç”¨æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ‰©å¤§äº†æ„Ÿå—é‡Žï¼Œæ›´å¥½åœ°æ•æ‰äº†å…³èŠ‚ä¹‹é—´çš„ç©ºé—´å…³ç³»ï¼›2) åœ¨é¢‘åŸŸä¸Šå¯¹3Dè½¨è¿¹è¿›è¡Œä¸€è‡´æ€§çº¦æŸï¼Œæœ‰æ•ˆåœ°æŠ‘åˆ¶äº†æ—¶é—´ä¸Šçš„æŠ–åŠ¨ï¼Œæé«˜äº†å§¿æ€ä¼°è®¡çš„ç¨³å®šæ€§ï¼›3) å°†å›¾ç¥žç»ç½‘ç»œå’ŒTransformerç»“åˆï¼Œå……åˆ†åˆ©ç”¨äº†å®ƒä»¬åœ¨å»ºæ¨¡ç©ºé—´å’Œæ—¶é—´ç›¸å…³æ€§æ–¹é¢çš„ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šHGAæ¨¡å—çš„å…³é”®è®¾è®¡åœ¨äºŽå¦‚ä½•é€‰æ‹©åˆé€‚çš„kå€¼ä»¥åŠå¦‚ä½•å®šä¹‰é‚»å±…ç»„ã€‚é¢‘åŸŸçº¦æŸçš„å…³é”®åœ¨äºŽé€‰æ‹©åˆé€‚çš„å˜æ¢æ–¹æ³•ï¼ˆä¾‹å¦‚ç¦»æ•£ä½™å¼¦å˜æ¢DCTï¼‰ä»¥åŠå¦‚ä½•è®¾è®¡æŸå¤±å‡½æ•°æ¥è¡¡é‡è½¨è¿¹çš„ä¸€è‡´æ€§ã€‚åˆæ­¥3Då§¿æ€ä¼°è®¡ç½‘ç»œå¯ä»¥ä½¿ç”¨çŽ°æœ‰çš„2D-to-3D liftingæ–¹æ³•ï¼Œä½†éœ€è¦ä¿è¯å…¶è¾“å‡ºçš„3Då§¿æ€å…·æœ‰ä¸€å®šçš„ç²¾åº¦ï¼Œä»¥ä¾¿ä¸ºåŽç»­æ¨¡å—æä¾›æœ‰ç”¨çš„ä¿¡æ¯ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

HGFreNetåœ¨Human3.6Må’ŒMPI-INF-3DHPæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨Human3.6Mæ•°æ®é›†ä¸Šï¼ŒHGFreNetåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šè¶…è¶Šäº†çŽ°æœ‰SOTAæ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨æ—¶é—´ä¸€è‡´æ€§æ–¹é¢æœ‰æ˜Žæ˜¾æ”¹å–„ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæ‰€æå‡ºçš„Hop-hybridå›¾æ³¨æ„åŠ›æ¨¡å—å’Œé¢‘åŸŸçº¦æŸèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜3Däººä½“å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽäººæœºäº¤äº’ã€åŠ¨ä½œæ•æ‰ã€è™šæ‹ŸçŽ°å®ž/å¢žå¼ºçŽ°å®žã€æ™ºèƒ½ç›‘æŽ§ã€è¿åŠ¨åˆ†æžç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜å•ç›®è§†é¢‘3Däººä½“å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ï¼Œå¯ä»¥ä¸ºè¿™äº›åº”ç”¨æä¾›æ›´å¯é çš„è¾“å…¥æ•°æ®ï¼Œä»Žè€Œæå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿæ€§èƒ½ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°æ›´å¤æ‚çš„åœºæ™¯ï¼Œä¾‹å¦‚å¤šäººäº¤äº’ã€é®æŒ¡æƒ…å†µç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> 2D-to-3D human pose lifting is a fundamental challenge for 3D human pose estimation in monocular video, where graph convolutional networks (GCNs) and attention mechanisms have proven to be inherently suitable for encoding the spatial-temporal correlations of skeletal joints. However, depth ambiguity and errors in 2D pose estimation lead to incoherence in the 3D trajectory. Previous studies have attempted to restrict jitters in the time domain, for instance, by constraining the differences between adjacent frames while neglecting the global spatial-temporal correlations of skeletal joint motion. To tackle this problem, we design HGFreNet, a novel GraphFormer architecture with hop-hybrid feature aggregation and 3D trajectory consistency in the frequency domain. Specifically, we propose a hop-hybrid graph attention (HGA) module and a Transformer encoder to model global joint spatial-temporal correlations. The HGA module groups all $k$-hop neighbors of a skeletal joint into a hybrid group to enlarge the receptive field and applies the attention mechanism to discover the latent correlations of these groups globally. We then exploit global temporal correlations by constraining trajectory consistency in the frequency domain. To provide 3D information for depth inference across frames and maintain coherence over time, a preliminary network is applied to estimate the 3D pose. Extensive experiments were conducted on two standard benchmark datasets: Human3.6M and MPI-INF-3DHP. The results demonstrate that the proposed HGFreNet outperforms state-of-the-art (SOTA) methods in terms of positional accuracy and temporal consistency.

