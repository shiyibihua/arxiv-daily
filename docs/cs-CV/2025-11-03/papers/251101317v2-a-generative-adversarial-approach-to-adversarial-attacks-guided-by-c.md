---
layout: default
title: A Generative Adversarial Approach to Adversarial Attacks Guided by Contrastive Language-Image Pre-trained Model
---

# A Generative Adversarial Approach to Adversarial Attacks Guided by Contrastive Language-Image Pre-trained Model

**arXiv**: [2511.01317v2](https://arxiv.org/abs/2511.01317) | [PDF](https://arxiv.org/pdf/2511.01317.pdf)

**ä½œè€…**: Sampriti Soor, Alik Pramanick, Jothiprakash K, Arijit Sur

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-03 (æ›´æ–°: 2025-11-16)

**å¤‡æ³¨**: 18 pages, 3 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå¯¹æ¯”è¯­è¨€-å›¾åƒé¢„è®­ç»ƒæ¨¡åž‹çš„ç”Ÿæˆå¯¹æŠ—æ”»å‡»æ–¹æ³•ï¼Œæå‡æ”»å‡»æ•ˆæžœä¸Žè§†è§‰ä¿çœŸåº¦ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å¯¹æŠ—æ”»å‡»` `ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ` `CLIPæ¨¡åž‹` `å¤šæ ‡ç­¾åˆ†ç±»` `è§†è§‰ä¿çœŸåº¦`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¯¹æŠ—æ”»å‡»æ–¹æ³•éš¾ä»¥åœ¨å¤šå¯¹è±¡åœºæ™¯ä¸‹ç”Ÿæˆæœ‰æ•ˆä¸”è§†è§‰ä¿çœŸåº¦é«˜çš„æ‰°åŠ¨ï¼Œå°¤å…¶æ˜¯åœ¨å¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ä¸­ã€‚
2. åˆ©ç”¨CLIPæ¨¡åž‹å¯¹é½æ–‡æœ¬å’Œå›¾åƒè¡¨ç¤ºçš„èƒ½åŠ›ï¼Œç»“åˆè‡ªç„¶è¯­è¨€è¯­ä¹‰å¼•å¯¼æŸå¤±ï¼Œç”Ÿæˆä¸ŽåŽŸå§‹å›¾åƒé«˜åº¦ç›¸ä¼¼çš„å¯¹æŠ—æ ·æœ¬ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨é»‘ç›’æ”»å‡»åœºæ™¯ä¸‹ï¼Œèƒ½è¾¾åˆ°ä¸ŽçŽ°æœ‰æŠ€æœ¯ç›¸å½“ç”šè‡³æ›´ä¼˜è¶Šçš„æ”»å‡»æ•ˆæžœï¼Œå¹¶ä¿æŒæ›´é«˜çš„è§†è§‰ä¿çœŸåº¦ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ·±åº¦å­¦ä¹ çš„å¿«é€Ÿå‘å±•å¸¦æ¥äº†å¼ºå¤§çš„æ¨¡åž‹ï¼Œå¯ä»¥å¤„ç†å„ç§ä»»åŠ¡ï¼Œå¦‚å›¾åƒè¯†åˆ«å’Œè¯­è¨€ç†è§£ã€‚ç„¶è€Œï¼Œå¯¹æŠ—æ”»å‡»ï¼Œä¸€ç§ä¸æ˜“å¯Ÿè§‰çš„ç¯¡æ”¹ï¼Œå¯èƒ½ä¼šæ¬ºéª—æ¨¡åž‹ï¼Œå¯¼è‡´ä¸å‡†ç¡®çš„é¢„æµ‹ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”Ÿæˆå¯¹æŠ—æ”»å‡»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨CLIPæ¨¡åž‹æ¥åˆ›å»ºé«˜æ•ˆä¸”è§†è§‰ä¸Šéš¾ä»¥å¯Ÿè§‰çš„å¯¹æŠ—æ‰°åŠ¨ã€‚CLIPæ¨¡åž‹å¯¹é½æ–‡æœ¬å’Œå›¾åƒè¡¨ç¤ºçš„èƒ½åŠ›æœ‰åŠ©äºŽå°†è‡ªç„¶è¯­è¨€è¯­ä¹‰ä¸Žå¼•å¯¼æŸå¤±ç›¸ç»“åˆï¼Œä»Žè€Œç”Ÿæˆä¸ŽåŽŸå§‹è¾“å…¥çœ‹èµ·æ¥ç›¸åŒçš„æœ‰æ•ˆå¯¹æŠ—æ ·æœ¬ã€‚è¿™ç§é›†æˆå…è®¸å¹¿æ³›çš„åœºæ™¯æ“ä½œï¼Œåœ¨å¤šå¯¹è±¡çŽ¯å¢ƒä¸­åˆ›å»ºä¸“é—¨è®¾è®¡ç”¨äºŽæ¬ºéª—å¤šæ ‡ç­¾åˆ†ç±»å™¨çš„æ‰°åŠ¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•é›†æˆäº†åŸºäºŽæ˜¾è‘—æ€§çš„è‡ªç¼–ç å™¨ï¼ˆSSAEï¼‰çš„é›†ä¸­æ‰°åŠ¨ç­–ç•¥å’Œç±»ä¼¼äºŽç”Ÿæˆå¯¹æŠ—å¤šå¯¹è±¡åœºæ™¯æ”»å‡»ï¼ˆGAMAï¼‰çš„éžç›¸ä¼¼æ–‡æœ¬åµŒå…¥ï¼Œä»Žè€Œäº§ç”Ÿæ—¢èƒ½æ¬ºéª—åˆ†ç±»æ¨¡åž‹åˆèƒ½ä¿æŒä¸ŽåŽŸå§‹å›¾åƒé«˜åº¦ç»“æž„ç›¸ä¼¼æ€§çš„æ‰°åŠ¨ã€‚è¯¥æ¨¡åž‹åœ¨å„ç§é»‘ç›’å—å®³è€…æ¨¡åž‹ä¸Šè¿›è¡Œäº†æµ‹è¯•ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•å…·æœ‰ç«žäº‰åŠ›ï¼Œåœ¨ä¿æŒæ›´é«˜è§†è§‰ä¿çœŸåº¦çš„åŒæ—¶ï¼Œå®žçŽ°äº†ä¸ŽçŽ°æœ‰æŠ€æœ¯ç›¸å½“æˆ–æ›´ä¼˜è¶Šçš„ç»“æžœã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¯¹æŠ—æ”»å‡»ä¸­ï¼ŒçŽ°æœ‰æ–¹æ³•åœ¨å¤šå¯¹è±¡åœºæ™¯ä¸‹ï¼Œå°¤å…¶æ˜¯åœ¨å¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬è§†è§‰ä¿çœŸåº¦ä½Žï¼Œæ”»å‡»æ•ˆæžœä¸ä½³çš„é—®é¢˜ã€‚çŽ°æœ‰çš„å¯¹æŠ—æ”»å‡»æ–¹æ³•é€šå¸¸éš¾ä»¥åœ¨ä¿æŒå›¾åƒè¯­ä¹‰å®Œæ•´æ€§çš„åŒæ—¶ï¼Œæœ‰æ•ˆåœ°æ¬ºéª—æ¨¡åž‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨CLIPæ¨¡åž‹å¯¹æ–‡æœ¬å’Œå›¾åƒçš„å¯¹é½èƒ½åŠ›ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€è¯­ä¹‰å¼•å¯¼å¯¹æŠ—æ‰°åŠ¨çš„ç”Ÿæˆï¼Œä»Žè€Œåœ¨ä¿æŒå›¾åƒè§†è§‰è´¨é‡çš„åŒæ—¶ï¼Œæé«˜å¯¹æŠ—æ”»å‡»çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡å°†å¯¹æŠ—æ ·æœ¬ä¸Žç›®æ ‡æ–‡æœ¬æè¿°å¯¹é½ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°æ¬ºéª—æ¨¡åž‹ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•é‡‡ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„æ¡†æž¶ï¼Œå…¶ä¸­ç”Ÿæˆå™¨è´Ÿè´£ç”Ÿæˆå¯¹æŠ—æ‰°åŠ¨ï¼Œåˆ¤åˆ«å™¨ï¼ˆæˆ–å—å®³è€…æ¨¡åž‹ï¼‰ç”¨äºŽè¯„ä¼°æ‰°åŠ¨çš„æœ‰æ•ˆæ€§ã€‚CLIPæ¨¡åž‹è¢«ç”¨äºŽæŒ‡å¯¼ç”Ÿæˆå™¨ç”Ÿæˆä¸Žç›®æ ‡æ–‡æœ¬æè¿°ç›¸ç¬¦çš„æ‰°åŠ¨ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1ï¼‰è¾“å…¥åŽŸå§‹å›¾åƒï¼›2ï¼‰ç”Ÿæˆå¯¹æŠ—æ‰°åŠ¨ï¼›3ï¼‰å°†æ‰°åŠ¨æ·»åŠ åˆ°åŽŸå§‹å›¾åƒï¼›4ï¼‰ä½¿ç”¨CLIPæ¨¡åž‹è®¡ç®—å¯¹æŠ—æ ·æœ¬ä¸Žç›®æ ‡æ–‡æœ¬æè¿°ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œå¹¶ä»¥æ­¤ä½œä¸ºæŸå¤±å‡½æ•°æŒ‡å¯¼ç”Ÿæˆå™¨è®­ç»ƒï¼›5ï¼‰è¯„ä¼°å¯¹æŠ—æ ·æœ¬åœ¨å—å®³è€…æ¨¡åž‹ä¸Šçš„æ”»å‡»æ•ˆæžœã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨äºŽå°†CLIPæ¨¡åž‹å¼•å…¥å¯¹æŠ—æ”»å‡»ä¸­ï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„æ–‡æœ¬-å›¾åƒå¯¹é½èƒ½åŠ›ï¼Œå®žçŽ°äº†è¯­ä¹‰å¼•å¯¼çš„å¯¹æŠ—æ‰°åŠ¨ç”Ÿæˆã€‚ä¸Žä¼ ç»Ÿçš„åŸºäºŽåƒç´ æ‰°åŠ¨çš„å¯¹æŠ—æ”»å‡»æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„æ‰°åŠ¨æ›´å…·æœ‰è¯­ä¹‰æ„ä¹‰ï¼Œä»Žè€Œæ›´å®¹æ˜“æ¬ºéª—æ¨¡åž‹ï¼ŒåŒæ—¶ä¿æŒæ›´é«˜çš„è§†è§‰ä¿çœŸåº¦ã€‚æ­¤å¤–ï¼Œç»“åˆäº†SSAEçš„é›†ä¸­æ‰°åŠ¨ç­–ç•¥å’ŒGAMAçš„éžç›¸ä¼¼æ–‡æœ¬åµŒå…¥ï¼Œè¿›ä¸€æ­¥æå‡äº†æ”»å‡»æ•ˆæžœã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ–¹æ³•ä½¿ç”¨äº†CLIPæ¨¡åž‹è®¡ç®—å¯¹æŠ—æ ·æœ¬ä¸Žç›®æ ‡æ–‡æœ¬æè¿°ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œå¹¶å°†å…¶ä½œä¸ºæŸå¤±å‡½æ•°çš„ä¸€éƒ¨åˆ†ã€‚æŸå¤±å‡½æ•°å¯èƒ½åŒ…æ‹¬ï¼š1ï¼‰CLIPç›¸ä¼¼åº¦æŸå¤±ï¼Œç”¨äºŽé¼“åŠ±å¯¹æŠ—æ ·æœ¬ä¸Žç›®æ ‡æ–‡æœ¬æè¿°å¯¹é½ï¼›2ï¼‰å›¾åƒç›¸ä¼¼åº¦æŸå¤±ï¼Œç”¨äºŽä¿æŒå¯¹æŠ—æ ·æœ¬ä¸ŽåŽŸå§‹å›¾åƒçš„è§†è§‰ç›¸ä¼¼æ€§ï¼›3ï¼‰å¯¹æŠ—æŸå¤±ï¼Œç”¨äºŽæœ€å¤§åŒ–å—å®³è€…æ¨¡åž‹çš„åˆ†ç±»é”™è¯¯çŽ‡ã€‚å…·ä½“çš„ç½‘ç»œç»“æž„å’Œå‚æ•°è®¾ç½®éœ€è¦æ ¹æ®å…·ä½“çš„å®žéªŒçŽ¯å¢ƒè¿›è¡Œè°ƒæ•´ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§é»‘ç›’å—å®³è€…æ¨¡åž‹ä¸Šè¡¨çŽ°å‡ºç«žäº‰åŠ›ï¼Œåœ¨æ”»å‡»æˆåŠŸçŽ‡æ–¹é¢ä¸ŽçŽ°æœ‰æŠ€æœ¯ç›¸å½“ç”šè‡³æ›´ä¼˜ï¼ŒåŒæ—¶æ˜¾è‘—æé«˜äº†å¯¹æŠ—æ ·æœ¬çš„è§†è§‰ä¿çœŸåº¦ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ï¼Œä½†æ€»ä½“è¶‹åŠ¿æ˜¯è¯¥æ–¹æ³•åœ¨ä¿æŒæ”»å‡»æ•ˆæžœçš„åŒæ—¶ï¼Œæå‡äº†è§†è§‰è´¨é‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæé«˜æ·±åº¦å­¦ä¹ æ¨¡åž‹çš„å®‰å…¨æ€§ï¼Œè¯„ä¼°æ¨¡åž‹åœ¨å¯¹æŠ—çŽ¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”¨äºŽç”Ÿæˆæ›´é€¼çœŸçš„å›¾åƒç¼–è¾‘å’Œå¢žå¼ºæ•ˆæžœï¼Œä¾‹å¦‚ï¼Œé€šè¿‡æŒ‡å®šæ–‡æœ¬æè¿°æ¥ä¿®æ”¹å›¾åƒå†…å®¹ã€‚åœ¨è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—å½±åƒåˆ†æžç­‰å®‰å…¨æ”¸å…³é¢†åŸŸï¼Œå¯¹æŠ—æ”»å‡»é˜²å¾¡æŠ€æœ¯è‡³å…³é‡è¦ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The rapid growth of deep learning has brought about powerful models that can handle various tasks, like identifying images and understanding language. However, adversarial attacks, an unnoticed alteration, can deceive models, leading to inaccurate predictions. In this paper, a generative adversarial attack method is proposed that uses the CLIP model to create highly effective and visually imperceptible adversarial perturbations. The CLIP model's ability to align text and image representation helps incorporate natural language semantics with a guided loss to generate effective adversarial examples that look identical to the original inputs. This integration allows extensive scene manipulation, creating perturbations in multi-object environments specifically designed to deceive multilabel classifiers. Our approach integrates the concentrated perturbation strategy from Saliency-based Auto-Encoder (SSAE) with the dissimilar text embeddings similar to Generative Adversarial Multi-Object Scene Attacks (GAMA), resulting in perturbations that both deceive classification models and maintain high structural similarity to the original images. The model was tested on various tasks across diverse black-box victim models. The experimental results show that our method performs competitively, achieving comparable or superior results to existing techniques, while preserving greater visual fidelity.

