---
layout: default
title: MoSa: Motion Generation with Scalable Autoregressive Modeling
---

# MoSa: Motion Generation with Scalable Autoregressive Modeling

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.01200" target="_blank" class="toolbar-btn">arXiv: 2511.01200v1</a>
    <a href="https://arxiv.org/pdf/2511.01200.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.01200v1" 
            onclick="toggleFavorite(this, '2511.01200v1', 'MoSa: Motion Generation with Scalable Autoregressive Modeling')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Mengyuan Liu, Sheng Yan, Yong Wang, Yingjie Li, Gui-Bin Bian, Hong Liu

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-03

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://mosa-web.github.io/MoSa-web)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**MoSaÔºöÂü∫‰∫éÂèØÊâ©Â±ïËá™ÂõûÂΩíÂª∫Ê®°ÁöÑËøêÂä®ÁîüÊàêÊ°ÜÊû∂ÔºåÊèêÂçáÊñáÊú¨È©±Âä®3D‰∫∫‰ΩìËøêÂä®ÁîüÊàêË¥®Èáè‰∏éÊïàÁéá„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `ÊñáÊú¨È©±Âä®ËøêÂä®ÁîüÊàê` `3D‰∫∫‰ΩìËøêÂä®` `ÂêëÈáèÈáèÂåñ` `Ëá™ÂõûÂΩíÂª∫Ê®°` `ÂàÜÂ±ÇÁîüÊàê` `Transformer` `ËøêÂä®ÁºñËæë`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñáÊú¨È©±Âä®3D‰∫∫‰ΩìËøêÂä®ÁîüÊàêÊñπÊ≥ïÂú®ÁîüÊàêË¥®ÈáèÂíåÊé®ÁêÜÊïàÁéá‰∏äÂ≠òÂú®ÊåëÊàòÔºåÈöæ‰ª•ÂÖºÈ°æ„ÄÇ
2. MoSaÈÄöËøáÂàÜÂ±ÇÊÆãÂ∑ÆÂêëÈáèÈáèÂåñÂíåÂèØÊâ©Â±ïËá™ÂõûÂΩíÂª∫Ê®°ÔºåÂÆûÁé∞‰∫ÜÁ≤óÂà∞Á≤æÁöÑËøêÂä®ÁîüÊàêÔºåÊèêÈ´ò‰∫ÜÁîüÊàêË¥®ÈáèÂíåÊïàÁéá„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåMoSaÂú®Motion-XÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜSOTAÁªìÊûúÔºåFIDÊòæËëóÈôç‰ΩéÔºåÊé®ÁêÜÈÄüÂ∫¶ÊèêÂçáÔºåÂπ∂ËÉΩÊ≥õÂåñÂà∞ËøêÂä®ÁºñËæë‰ªªÂä°„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫MoSaÁöÑÊñ∞ÂûãÂàÜÂ±ÇËøêÂä®ÁîüÊàêÊ°ÜÊû∂ÔºåÁî®‰∫éÊñáÊú¨È©±Âä®ÁöÑ3D‰∫∫‰ΩìËøêÂä®ÁîüÊàê„ÄÇMoSaÈÄöËøáÁ≤óÂà∞Á≤æÁöÑÂèØÊâ©Â±ïÁîüÊàêËøáÁ®ãÔºåÂ¢ûÂº∫‰∫ÜÂêëÈáèÈáèÂåñÂºïÂØºÁöÑÁîüÊàêTransformerÔºàVQ-GTÔºâËåÉÂºè„ÄÇMoSaÈõÜÊàê‰∫ÜÂ§öÂ∞∫Â∫¶Token‰øùÁïôÁ≠ñÁï•ÔºàMTPSÔºâÂà∞ÂàÜÂ±ÇÊÆãÂ∑ÆÂêëÈáèÈáèÂåñÂèòÂàÜËá™ÁºñÁ†ÅÂô®ÔºàRQ-VAEÔºâ‰∏≠„ÄÇMTPSÂú®ÊØè‰∏™ÂàÜÂ±ÇÈáèÂåñÂ±ÇÈááÁî®ÊèíÂÄºÔºåÊúâÊïàÂú∞‰øùÁïô‰∫ÜÁ≤óÂà∞Á≤æÁöÑÂ§öÂ∞∫Â∫¶token„ÄÇÁî±Ê≠§ÔºåÁîüÊàêTransformerÊîØÊåÅÂèØÊâ©Â±ïËá™ÂõûÂΩíÔºàSARÔºâÂª∫Ê®°ÔºåÈ¢ÑÊµãÂ∞∫Â∫¶tokenÔºåËÄåÈùû‰º†ÁªüÊñπÊ≥ï‰∏≠ÊØèÊ≠•‰ªÖÈ¢ÑÊµã‰∏Ä‰∏™token„ÄÇÂõ†Ê≠§ÔºåMoSa‰ªÖÈúÄ10Ê≠•Êé®ÁêÜÔºå‰∏éRQ-VAEÈáèÂåñÂ±ÇÊï∞ÂåπÈÖç„ÄÇ‰∏∫Ëß£ÂÜ≥È¢ëÁπÅÊèíÂÄºÂèØËÉΩÂØºËá¥ÁöÑÈáçÂª∫ÈÄÄÂåñÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫CAQ-VAEÔºå‰∏ÄÁßçËΩªÈáèÁ∫ß‰ΩÜÂØåÊúâË°®Áé∞ÂäõÁöÑÂç∑ÁßØ-Ê≥®ÊÑèÂäõÊ∑∑ÂêàVQ-VAE„ÄÇCAQ-VAEÂ¢ûÂº∫‰∫ÜÊÆãÂ∑ÆÂùóËÆæËÆ°ÔºåÂπ∂ËûçÂÖ•Ê≥®ÊÑèÂäõÊú∫Âà∂‰ª•Êõ¥Â•ΩÂú∞ÊçïÊçâÂÖ®Â±Ä‰æùËµñÂÖ≥Á≥ª„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåMoSaÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÁîüÊàêË¥®ÈáèÂíåÊïàÁéáÔºåÂú®‰øùÁúüÂ∫¶ÂíåÈÄüÂ∫¶ÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÂú®Motion-XÊï∞ÊçÆÈõÜ‰∏äÔºåMoSaÂÆûÁé∞‰∫Ü0.06ÁöÑFIDÔºàÁõ∏ÊØîMoMaskÁöÑ0.20ÔºâÔºåÂêåÊó∂ÂáèÂ∞ë‰∫Ü27%ÁöÑÊé®ÁêÜÊó∂Èó¥„ÄÇÊ≠§Â§ñÔºåMoSaÂèØ‰ª•ÂæàÂ•ΩÂú∞Ê≥õÂåñÂà∞ËøêÂä®ÁºñËæëÁ≠â‰∏ãÊ∏∏‰ªªÂä°ÔºåÊó†ÈúÄÈ¢ùÂ§ñÂæÆË∞É„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÊñáÊú¨È©±Âä®ÁöÑ3D‰∫∫‰ΩìËøêÂä®ÁîüÊàêÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÂ¶ÇÂü∫‰∫éVQ-GTÁöÑÊñπÊ≥ïÔºåÈÄöÂ∏∏ÈúÄË¶ÅËæÉÂ§öÁöÑÊé®ÁêÜÊ≠•È™§ÔºåÊïàÁéáËæÉ‰ΩéÔºåÂπ∂‰∏îÈöæ‰ª•Âú®ÁîüÊàêË¥®ÈáèÂíåÊé®ÁêÜÈÄüÂ∫¶‰πãÈó¥ÂèñÂæóÂπ≥Ë°°„ÄÇÈ¢ëÁπÅÁöÑÊèíÂÄºÊìç‰Ωú‰πüÂèØËÉΩÂØºËá¥ÈáçÂª∫Ë¥®Èáè‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMoSaÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂàÜÂ±ÇÈáèÂåñÂíåÂèØÊâ©Â±ïËá™ÂõûÂΩíÂª∫Ê®°ÔºåÂÆûÁé∞Á≤óÂà∞Á≤æÁöÑËøêÂä®ÁîüÊàê„ÄÇÈÄöËøáÂ§öÂ∞∫Â∫¶Token‰øùÁïôÁ≠ñÁï•ÔºàMTPSÔºâ‰øùÁïô‰∏çÂêåÂ∞∫Â∫¶ÁöÑËøêÂä®‰ø°ÊÅØÔºåÂπ∂Âà©Áî®ÂèØÊâ©Â±ïËá™ÂõûÂΩíÔºàSARÔºâÂª∫Ê®°‰∏ÄÊ¨°ÊÄßÈ¢ÑÊµãÂ§ö‰∏™Â∞∫Â∫¶ÁöÑtokenÔºå‰ªéËÄåÂáèÂ∞ëÊé®ÁêÜÊ≠•È™§ÔºåÊèêÈ´òÊïàÁéá„ÄÇÂêåÊó∂ÔºåÈááÁî®Âç∑ÁßØ-Ê≥®ÊÑèÂäõÊ∑∑ÂêàVQ-VAEÔºàCAQ-VAEÔºâÊù•ÊèêÂçáÈáçÂª∫Ë¥®Èáè„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMoSaÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨Ôºö1) ÂàÜÂ±ÇÊÆãÂ∑ÆÂêëÈáèÈáèÂåñÂèòÂàÜËá™ÁºñÁ†ÅÂô®ÔºàRQ-VAEÔºâÔºåÁî®‰∫éÂ∞ÜËøêÂä®Êï∞ÊçÆÁºñÁ†Å‰∏∫Á¶ªÊï£ÁöÑtokenÂ∫èÂàóÔºõ2) Â§öÂ∞∫Â∫¶Token‰øùÁïôÁ≠ñÁï•ÔºàMTPSÔºâÔºåÁî®‰∫éÂú®ÂàÜÂ±ÇÈáèÂåñËøáÁ®ã‰∏≠‰øùÁïô‰∏çÂêåÂ∞∫Â∫¶ÁöÑtokenÔºõ3) ÂèØÊâ©Â±ïËá™ÂõûÂΩíÔºàSARÔºâÂª∫Ê®°ÁöÑÁîüÊàêTransformerÔºåÁî®‰∫éÊ†πÊçÆÊñáÊú¨ÊèèËø∞ÁîüÊàêËøêÂä®tokenÂ∫èÂàóÔºõ4) Âç∑ÁßØ-Ê≥®ÊÑèÂäõÊ∑∑ÂêàVQ-VAEÔºàCAQ-VAEÔºâÔºåÁî®‰∫éÊèêÂçáÈáçÂª∫Ë¥®Èáè„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMoSaÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫ÜÂ§öÂ∞∫Â∫¶Token‰øùÁïôÁ≠ñÁï•ÔºàMTPSÔºâÔºåÈÄöËøáÊèíÂÄº‰øùÁïô‰∏çÂêåÂ∞∫Â∫¶ÁöÑËøêÂä®‰ø°ÊÅØÔºõ2) ÊèêÂá∫‰∫ÜÂèØÊâ©Â±ïËá™ÂõûÂΩíÔºàSARÔºâÂª∫Ê®°Ôºå‰∏ÄÊ¨°ÊÄßÈ¢ÑÊµãÂ§ö‰∏™Â∞∫Â∫¶ÁöÑtokenÔºåÂáèÂ∞ëÊé®ÁêÜÊ≠•È™§Ôºõ3) ÊèêÂá∫‰∫ÜÂç∑ÁßØ-Ê≥®ÊÑèÂäõÊ∑∑ÂêàVQ-VAEÔºàCAQ-VAEÔºâÔºåÈÄöËøáÂç∑ÁßØÂíåÊ≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÁªìÂêàÔºåÊèêÂçáÈáçÂª∫Ë¥®Èáè„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåMoSaËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®Â§öÂ∞∫Â∫¶‰ø°ÊÅØÔºåÂπ∂ÂáèÂ∞ëÊé®ÁêÜÊ≠•È™§Ôºå‰ªéËÄåÊèêÈ´òÁîüÊàêË¥®ÈáèÂíåÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöMTPSÂú®ÊØè‰∏™ÈáèÂåñÂ±Ç‰ΩøÁî®ÊèíÂÄºÊù•‰øùÁïôtokenÔºåÊèíÂÄºÊùÉÈáçÊòØÂèØÂ≠¶‰π†ÁöÑÂèÇÊï∞„ÄÇSARÂª∫Ê®°ÁöÑTransformer‰ΩøÁî®Â§öÂ§¥Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåÂπ∂Ê†πÊçÆÊñáÊú¨ÊèèËø∞È¢ÑÊµãÂ§ö‰∏™Â∞∫Â∫¶ÁöÑtoken„ÄÇCAQ-VAEÂú®ÊÆãÂ∑ÆÂùó‰∏≠ÂºïÂÖ•‰∫ÜÂç∑ÁßØÂíåÊ≥®ÊÑèÂäõÊú∫Âà∂Ôºå‰ª•Êõ¥Â•ΩÂú∞ÊçïÊçâÂ±ÄÈÉ®ÂíåÂÖ®Â±Ä‰æùËµñÂÖ≥Á≥ª„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÈáçÂª∫ÊçüÂ§±„ÄÅÈáèÂåñÊçüÂ§±ÂíåKLÊï£Â∫¶ÊçüÂ§±„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MoSaÂú®Motion-XÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåFIDÊåáÊ†á‰ªéMoMaskÁöÑ0.20Èôç‰ΩéÂà∞0.06ÔºåÊé®ÁêÜÊó∂Èó¥ÂáèÂ∞ë‰∫Ü27%„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMoSaÂú®ÁîüÊàêË¥®ÈáèÂíåÊïàÁéáÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂‰∏îÂÖ∑ÊúâËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂèØ‰ª•Â∫îÁî®‰∫éËøêÂä®ÁºñËæëÁ≠â‰∏ãÊ∏∏‰ªªÂä°„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MoSaÂú®ËôöÊãüÁé∞ÂÆû„ÄÅÊ∏∏ÊàèÂºÄÂèë„ÄÅÂä®ÁîªÂà∂‰Ωú„ÄÅ‰∫∫Êú∫‰∫§‰∫íÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Ê†πÊçÆÊñáÊú¨ÊèèËø∞Ëá™Âä®ÁîüÊàêÈÄºÁúüÁöÑ‰∫∫‰ΩìËøêÂä®Ôºå‰ªéËÄåÈôç‰ΩéËøêÂä®ÁîüÊàêÊàêÊú¨ÔºåÊèêÈ´òÂàõ‰ΩúÊïàÁéá„ÄÇÊ≠§Â§ñÔºåMoSaËøòÂèØ‰ª•Áî®‰∫éËøêÂä®ÁºñËæë„ÄÅÂä®‰ΩúÊçïÊçâÊï∞ÊçÆ‰øÆÂ§çÁ≠â‰ªªÂä°ÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄº„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We introduce MoSa, a novel hierarchical motion generation framework for text-driven 3D human motion generation that enhances the Vector Quantization-guided Generative Transformers (VQ-GT) paradigm through a coarse-to-fine scalable generation process. In MoSa, we propose a Multi-scale Token Preservation Strategy (MTPS) integrated into a hierarchical residual vector quantization variational autoencoder (RQ-VAE). MTPS employs interpolation at each hierarchical quantization to effectively retain coarse-to-fine multi-scale tokens. With this, the generative transformer supports Scalable Autoregressive (SAR) modeling, which predicts scale tokens, unlike traditional methods that predict only one token at each step. Consequently, MoSa requires only 10 inference steps, matching the number of RQ-VAE quantization layers. To address potential reconstruction degradation from frequent interpolation, we propose CAQ-VAE, a lightweight yet expressive convolution-attention hybrid VQ-VAE. CAQ-VAE enhances residual block design and incorporates attention mechanisms to better capture global dependencies. Extensive experiments show that MoSa achieves state-of-the-art generation quality and efficiency, outperforming prior methods in both fidelity and speed. On the Motion-X dataset, MoSa achieves an FID of 0.06 (versus MoMask's 0.20) while reducing inference time by 27 percent. Moreover, MoSa generalizes well to downstream tasks such as motion editing, requiring no additional fine-tuning. The code is available at https://mosa-web.github.io/MoSa-web

