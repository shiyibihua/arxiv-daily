---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-11-24
---

# cs.CVï¼ˆ2025-11-24ï¼‰

ğŸ“Š å…± **42** ç¯‡è®ºæ–‡
 | ğŸ”— **7** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (22 ğŸ”—5)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (7)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (6 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction" class="interest-badge">æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (3)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (2)</a>
<a href="#æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting" class="interest-badge">æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction-matching" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction & Matching) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (22 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251119294v1-densifybeforehand-lidar-assisted-content-aware-densification-for-eff.html">DensifyBeforehand: LiDAR-assisted Content-aware Densification for Efficient and Quality 3D Gaussian Splatting</a></td>
  <td>æå‡ºLiDARè¾…åŠ©çš„å†…å®¹æ„ŸçŸ¥ç¨ å¯†åŒ–æ–¹æ³•ï¼Œæå‡3Dé«˜æ–¯æº…å°„æ•ˆç‡ä¸è´¨é‡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19294v1" onclick="toggleFavorite(this, '2511.19294v1', 'DensifyBeforehand: LiDAR-assisted Content-aware Densification for Efficient and Quality 3D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251118873v1-neural-texture-splatting-expressive-3d-gaussian-splatting-for-view-s.html">Neural Texture Splatting: Expressive 3D Gaussian Splatting for View Synthesis, Geometry, and Dynamic Reconstruction</a></td>
  <td>æå‡ºç¥ç»çº¹ç†æº…å°„ï¼ˆNTSï¼‰ï¼Œæå‡3Dé«˜æ–¯æº…å°„åœ¨è§†å›¾åˆæˆã€å‡ ä½•åŠåŠ¨æ€é‡å»ºä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18873v1" onclick="toggleFavorite(this, '2511.18873v1', 'Neural Texture Splatting: Expressive 3D Gaussian Splatting for View Synthesis, Geometry, and Dynamic Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251119235v1-idsplat-instance-decomposed-3d-gaussian-splatting-for-driving-scenes.html">IDSplat: Instance-Decomposed 3D Gaussian Splatting for Driving Scenes</a></td>
  <td>IDSplatï¼šé¢å‘è‡ªåŠ¨é©¾é©¶åœºæ™¯çš„å®ä¾‹åˆ†è§£3Dé«˜æ–¯æº…å°„é‡å»º</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19235v1" onclick="toggleFavorite(this, '2511.19235v1', 'IDSplat: Instance-Decomposed 3D Gaussian Splatting for Driving Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251119202v1-nvgs-neural-visibility-for-occlusion-culling-in-3d-gaussian-splattin.html">NVGS: Neural Visibility for Occlusion Culling in 3D Gaussian Splatting</a></td>
  <td>æå‡ºåŸºäºç¥ç»å¯è§æ€§çš„3Dé«˜æ–¯æº…å°„é®æŒ¡å‰”é™¤æ–¹æ³•ï¼Œæå‡å¤æ‚åœºæ™¯æ¸²æŸ“æ•ˆç‡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19202v1" onclick="toggleFavorite(this, '2511.19202v1', 'NVGS: Neural Visibility for Occlusion Culling in 3D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251119527v1-maprf-weakly-supervised-online-hd-map-construction-via-nerf-guided-s.html">MapRF: Weakly Supervised Online HD Map Construction via NeRF-Guided Self-Training</a></td>
  <td>MapRFï¼šåŸºäºNeRFå¼•å¯¼è‡ªè®­ç»ƒçš„å¼±ç›‘ç£åœ¨çº¿é«˜æ¸…åœ°å›¾æ„å»º</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19527v1" onclick="toggleFavorite(this, '2511.19527v1', 'MapRF: Weakly Supervised Online HD Map Construction via NeRF-Guided Self-Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251118672v1-sphinx-efficiently-serving-novel-view-synthesis-using-regression-gui.html">Sphinx: Efficiently Serving Novel View Synthesis using Regression-Guided Selective Refinement</a></td>
  <td>Sphinxï¼šæå‡ºä¸€ç§åŸºäºå›å½’å¼•å¯¼é€‰æ‹©æ€§ä¼˜åŒ–çš„é«˜æ•ˆæ–°è§†è§’åˆæˆæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18672v1" onclick="toggleFavorite(this, '2511.18672v1', 'Sphinx: Efficiently Serving Novel View Synthesis using Regression-Guided Selective Refinement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251119172v1-metrogs-efficient-and-stable-reconstruction-of-geometrically-accurat.html">MetroGS: Efficient and Stable Reconstruction of Geometrically Accurate High-Fidelity Large-Scale Scenes</a></td>
  <td>MetroGSï¼šé«˜æ•ˆç¨³å®šåœ°é‡å»ºå‡ ä½•ç²¾ç¡®çš„é«˜ä¿çœŸå¤§è§„æ¨¡åœºæ™¯</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19172v1" onclick="toggleFavorite(this, '2511.19172v1', 'MetroGS: Efficient and Stable Reconstruction of Geometrically Accurate High-Fidelity Large-Scale Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251119105v1-graph-based-3d-human-pose-estimation-using-wifi-signals.html">Graph-based 3D Human Pose Estimation using WiFi Signals</a></td>
  <td>æå‡ºGraphPose-Fiï¼Œåˆ©ç”¨WiFiä¿¡å·å’Œå›¾ç¥ç»ç½‘ç»œè¿›è¡Œ3Däººä½“å§¿æ€ä¼°è®¡</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19105v1" onclick="toggleFavorite(this, '2511.19105v1', 'Graph-based 3D Human Pose Estimation using WiFi Signals')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251118851v1-robust-long-term-test-time-adaptation-for-3d-human-pose-estimation-t.html">Robust Long-term Test-Time Adaptation for 3D Human Pose Estimation through Motion Discretization</a></td>
  <td>æå‡ºåŸºäºè¿åŠ¨ç¦»æ•£åŒ–çš„é²æ£’é•¿æœŸæµ‹è¯•æ—¶è‡ªé€‚åº”3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18851v1" onclick="toggleFavorite(this, '2511.18851v1', 'Robust Long-term Test-Time Adaptation for 3D Human Pose Estimation through Motion Discretization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251119396v1-real-time-object-tracking-with-on-device-deep-learning-for-adaptive-.html">Real-Time Object Tracking with On-Device Deep Learning for Adaptive Beamforming in Dynamic Acoustic Environments</a></td>
  <td>æå‡ºä¸€ç§åŸºäºè®¾å¤‡ç«¯æ·±åº¦å­¦ä¹ çš„ç›®æ ‡è·Ÿè¸ªä¸æ³¢æŸæˆå½¢å®æ—¶åµŒå…¥å¼ç³»ç»Ÿ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19396v1" onclick="toggleFavorite(this, '2511.19396v1', 'Real-Time Object Tracking with On-Device Deep Learning for Adaptive Beamforming in Dynamic Acoustic Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251119542v1-proxy-free-gaussian-splats-deformation-with-splat-based-surface-esti.html">Proxy-Free Gaussian Splats Deformation with Splat-Based Surface Estimation</a></td>
  <td>æå‡ºæ— ä»£ç†é«˜æ–¯æ–‘ç‚¹å˜å½¢æ–¹æ³•ä»¥è§£å†³è¡¨é¢ä¿¡æ¯æ•æ‰ä¸è¶³é—®é¢˜</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19542v1" onclick="toggleFavorite(this, '2511.19542v1', 'Proxy-Free Gaussian Splats Deformation with Splat-Based Surface Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251119511v1-the-determinant-ratio-matrix-approach-to-solving-3d-matching-and-2d-.html">The Determinant Ratio Matrix Approach to Solving 3D Matching and 2D Orthographic Projection Alignment Tasks</a></td>
  <td>æå‡ºåŸºäºè¡Œåˆ—å¼æ¯”ç‡çŸ©é˜µï¼ˆDRaMï¼‰çš„EnPå’ŒOnPé—®é¢˜æ±‚è§£æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19511v1" onclick="toggleFavorite(this, '2511.19511v1', 'The Determinant Ratio Matrix Approach to Solving 3D Matching and 2D Orthographic Projection Alignment Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251119768v1-prune-then-plan-step-level-calibration-for-stable-frontier-explorati.html">Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering</a></td>
  <td>Prune-Then-Planï¼šé€šè¿‡æ­¥çº§æ ¡å‡†å®ç°å…·èº«é—®ç­”ä¸­ç¨³å®šçš„è¾¹ç•Œæ¢ç´¢</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19768v1" onclick="toggleFavorite(this, '2511.19768v1', 'Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251119760v1-a-storage-efficient-feature-for-3d-concrete-defect-segmentation-to-r.html">A Storage-Efficient Feature for 3D Concrete Defect Segmentation to Replace Normal Vector</a></td>
  <td>æå‡ºåŸºäºç›¸å¯¹è§’åº¦çš„3Dæ··å‡åœŸç¼ºé™·åˆ†å‰²ç‰¹å¾ï¼Œå®ç°å­˜å‚¨æ•ˆç‡æå‡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19760v1" onclick="toggleFavorite(this, '2511.19760v1', 'A Storage-Efficient Feature for 3D Concrete Defect Segmentation to Replace Normal Vector')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251119684v1-indego-a-dataset-of-industrial-scenarios-and-collaborative-work-for-.html">IndEgo: A Dataset of Industrial Scenarios and Collaborative Work for Egocentric Assistants</a></td>
  <td>IndEgoï¼šç”¨äºç¬¬ä¸€äººç§°è§†è§’å·¥ä¸šåŠ©æ‰‹åä½œä»»åŠ¡çš„å¤šæ¨¡æ€æ•°æ®é›†</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19684v1" onclick="toggleFavorite(this, '2511.19684v1', 'IndEgo: A Dataset of Industrial Scenarios and Collaborative Work for Egocentric Assistants')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251119149v1-from-pixels-to-posts-retrieval-augmented-fashion-captioning-and-hash.html">From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag Generation</a></td>
  <td>æå‡ºæ£€ç´¢å¢å¼ºçš„æ—¶å°šæè¿°ä¸æ ‡ç­¾ç”Ÿæˆæ¡†æ¶ï¼Œæå‡å±æ€§ä¿çœŸåº¦å’Œé¢†åŸŸæ³›åŒ–æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19149v1" onclick="toggleFavorite(this, '2511.19149v1', 'From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251119111v2-diffseg30k-a-multi-turn-diffusion-editing-benchmark-for-localized-ai.html">DiffSeg30k: A Multi-Turn Diffusion Editing Benchmark for Localized AIGC Detection</a></td>
  <td>DiffSeg30kï¼šç”¨äºAIGCç²¾ç»†åŒ–æ£€æµ‹çš„å¤šè½®æ‰©æ•£ç¼–è¾‘åŸºå‡†æ•°æ®é›†</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19111v2" onclick="toggleFavorite(this, '2511.19111v2', 'DiffSeg30k: A Multi-Turn Diffusion Editing Benchmark for Localized AIGC Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251119062v1-granular-computing-driven-sam-from-coarse-to-fine-guidance-for-promp.html">Granular Computing-driven SAM: From Coarse-to-Fine Guidance for Prompt-Free Segmentation</a></td>
  <td>æå‡ºåŸºäºç²’è®¡ç®—çš„Grc-SAMï¼Œå®ç°æ— æç¤ºå›¾åƒåˆ†å‰²çš„ç²—åˆ°ç»†ç²¾åº¦æå‡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19062v1" onclick="toggleFavorite(this, '2511.19062v1', 'Granular Computing-driven SAM: From Coarse-to-Fine Guidance for Prompt-Free Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251119526v1-perceptual-taxonomy-evaluating-and-guiding-hierarchical-scene-reason.html">Perceptual Taxonomy: Evaluating and Guiding Hierarchical Scene Reasoning in Vision-Language Models</a></td>
  <td>æå‡ºæ„ŸçŸ¥åˆ†ç±»æ³•ï¼Œç”¨äºè¯„ä¼°å’ŒæŒ‡å¯¼è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„åˆ†å±‚åœºæ™¯æ¨ç†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19526v1" onclick="toggleFavorite(this, '2511.19526v1', 'Perceptual Taxonomy: Evaluating and Guiding Hierarchical Scene Reasoning in Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251118806v1-tpg-inr-target-prior-guided-implicit-3d-ct-reconstruction-for-enhanc.html">TPG-INR: Target Prior-Guided Implicit 3D CT Reconstruction for Enhanced Sparse-view Imaging</a></td>
  <td>æå‡ºTPG-INRä»¥è§£å†³è¶…ç¨€è§†å›¾ä¸‹3D CTé‡å»ºç²¾åº¦ä¸è¶³é—®é¢˜</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18806v1" onclick="toggleFavorite(this, '2511.18806v1', 'TPG-INR: Target Prior-Guided Implicit 3D CT Reconstruction for Enhanced Sparse-view Imaging')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/251118801v1-partdiffuser-part-wise-3d-mesh-generation-via-discrete-diffusion.html">PartDiffuser: Part-wise 3D Mesh Generation via Discrete Diffusion</a></td>
  <td>PartDiffuserï¼šé€šè¿‡ç¦»æ•£æ‰©æ•£å®ç°åˆ†éƒ¨ä»¶çš„ä¸‰ç»´ç½‘æ ¼ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18801v1" onclick="toggleFavorite(this, '2511.18801v1', 'PartDiffuser: Part-wise 3D Mesh Generation via Discrete Diffusion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251118787v1-understanding-task-transfer-in-vision-language-models.html">Understanding Task Transfer in Vision-Language Models</a></td>
  <td>æå‡ºPerfection Gap Factorï¼Œç³»ç»Ÿç ”ç©¶è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„ä»»åŠ¡è¿ç§»ç°è±¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18787v1" onclick="toggleFavorite(this, '2511.18787v1', 'Understanding Task Transfer in Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (7 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>23</td>
  <td><a href="./papers/251118927v1-finextrol-controllable-motion-generation-via-fine-grained-text.html">FineXtrol: Controllable Motion Generation via Fine-Grained Text</a></td>
  <td>FineXtrolï¼šé€šè¿‡ç»†ç²’åº¦æ–‡æœ¬æ§åˆ¶å®ç°å¯æ§çš„è¿åŠ¨ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18927v1" onclick="toggleFavorite(this, '2511.18927v1', 'FineXtrol: Controllable Motion Generation via Fine-Grained Text')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/251119584v2-learning-massively-multitask-world-models-for-continuous-control.html">Learning Massively Multitask World Models for Continuous Control</a></td>
  <td>æå‡ºNewtï¼šä¸€ç§å¤§è§„æ¨¡å¤šä»»åŠ¡ä¸–ç•Œæ¨¡å‹ï¼Œç”¨äºè¿ç»­æ§åˆ¶ä»»åŠ¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19584v2" onclick="toggleFavorite(this, '2511.19584v2', 'Learning Massively Multitask World Models for Continuous Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/251119033v1-reexplore-improving-mllms-for-embodied-exploration-with-contextualiz.html">ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay</a></td>
  <td>ReEXploreï¼šåˆ©ç”¨æƒ…å¢ƒåŒ–å›é¡¾ç»éªŒå›æ”¾æ”¹è¿›MLLMåœ¨å…·èº«æ¢ç´¢ä¸­çš„æ€§èƒ½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19033v1" onclick="toggleFavorite(this, '2511.19033v1', 'ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/251119773v1-scaling-agentic-reinforcement-learning-for-tool-integrated-reasoning.html">Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs</a></td>
  <td>VISTA-Gymï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ æå‡è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å·¥å…·é›†æˆæ¨ç†æ–¹é¢çš„èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19773v1" onclick="toggleFavorite(this, '2511.19773v1', 'Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/251119524v1-videochat-m1-collaborative-policy-planning-for-video-understanding-v.html">VideoChat-M1: Collaborative Policy Planning for Video Understanding via Multi-Agent Reinforcement Learning</a></td>
  <td>æå‡ºVideoChat-M1ï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å®ç°è§†é¢‘ç†è§£çš„ååŒç­–ç•¥è§„åˆ’ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19524v1" onclick="toggleFavorite(this, '2511.19524v1', 'VideoChat-M1: Collaborative Policy Planning for Video Understanding via Multi-Agent Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/251119515v1-fewer-tokens-greater-scaling-self-adaptive-visual-bases-for-efficien.html">Fewer Tokens, Greater Scaling: Self-Adaptive Visual Bases for Efficient and Expansive Representation Learning</a></td>
  <td>æå‡ºè‡ªé€‚åº”è§†è§‰åŸºï¼Œå‡å°‘è§†è§‰Tokenæ•°é‡ï¼Œæå‡è§†è§‰è¡¨å¾å­¦ä¹ çš„æ•ˆç‡å’Œå¯æ‰©å±•æ€§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19515v1" onclick="toggleFavorite(this, '2511.19515v1', 'Fewer Tokens, Greater Scaling: Self-Adaptive Visual Bases for Efficient and Expansive Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/251118886v1-magicworld-interactive-geometry-driven-video-world-exploration.html">MagicWorld: Interactive Geometry-driven Video World Exploration</a></td>
  <td>MagicWorldï¼šæå‡ºå‡ ä½•å¼•å¯¼çš„äº¤äº’å¼è§†é¢‘ä¸–ç•Œæ¢ç´¢æ¨¡å‹ï¼Œæå‡åœºæ™¯ç¨³å®šæ€§å’Œè¿ç»­æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18886v1" onclick="toggleFavorite(this, '2511.18886v1', 'MagicWorld: Interactive Geometry-driven Video World Exploration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (6 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>30</td>
  <td><a href="./papers/251118993v1-auvire-audio-visual-speech-representation-reconstruction-for-deepfak.html">AuViRe: Audio-visual Speech Representation Reconstruction for Deepfake Temporal Localization</a></td>
  <td>æå‡ºAuViReï¼Œé€šè¿‡éŸ³è§†é¢‘è¯­éŸ³è¡¨å¾é‡å»ºå®ç°Deepfakeè§†é¢‘çš„æ—¶é—´å®šä½</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18993v1" onclick="toggleFavorite(this, '2511.18993v1', 'AuViRe: Audio-visual Speech Representation Reconstruction for Deepfake Temporal Localization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>31</td>
  <td><a href="./papers/251118983v1-umcl-unimodal-generated-multimodal-contrastive-learning-for-cross-co.html">UMCL: Unimodal-generated Multimodal Contrastive Learning for Cross-compression-rate Deepfake Detection</a></td>
  <td>æå‡ºUMCLæ¡†æ¶ï¼Œé€šè¿‡å•æ¨¡æ€ç”Ÿæˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ï¼Œè§£å†³è·¨å‹ç¼©ç‡æ·±åº¦ä¼ªé€ æ£€æµ‹éš¾é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18983v1" onclick="toggleFavorite(this, '2511.18983v1', 'UMCL: Unimodal-generated Multimodal Contrastive Learning for Cross-compression-rate Deepfake Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>32</td>
  <td><a href="./papers/251118729v2-guideflow-constraint-guided-flow-matching-for-planning-in-end-to-end.html">GuideFlow: Constraint-Guided Flow Matching for Planning in End-to-End Autonomous Driving</a></td>
  <td>GuideFlowï¼šä¸€ç§çº¦æŸå¼•å¯¼çš„Flow Matchingæ–¹æ³•ï¼Œç”¨äºç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶è§„åˆ’ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18729v2" onclick="toggleFavorite(this, '2511.18729v2', 'GuideFlow: Constraint-Guided Flow Matching for Planning in End-to-End Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>33</td>
  <td><a href="./papers/251119057v1-laa3d-a-benchmark-of-detecting-and-tracking-low-altitude-aircraft-in.html">LAA3D: A Benchmark of Detecting and Tracking Low-Altitude Aircraft in 3D Space</a></td>
  <td>LAA3Dï¼šæ„å»ºä½ç©ºé£è¡Œå™¨ä¸‰ç»´æ„ŸçŸ¥åŸºå‡†æ•°æ®é›†ä¸å•ç›®3Dæ£€æµ‹åŸºçº¿ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19057v1" onclick="toggleFavorite(this, '2511.19057v1', 'LAA3D: A Benchmark of Detecting and Tracking Low-Altitude Aircraft in 3D Space')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>34</td>
  <td><a href="./papers/251118960v2-ava-vla-improving-vision-language-action-models-with-active-visual-a.html">AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention</a></td>
  <td>AVA-VLAï¼šé€šè¿‡ä¸»åŠ¨è§†è§‰æ³¨æ„åŠ›æå‡è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨å…·èº«æ™ºèƒ½ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18960v2" onclick="toggleFavorite(this, '2511.18960v2', 'AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>35</td>
  <td><a href="./papers/251119436v1-vdc-agent-when-video-detailed-captioners-evolve-themselves-via-agent.html">VDC-Agent: When Video Detailed Captioners Evolve Themselves via Agentic Self-Reflection</a></td>
  <td>VDC-Agentï¼šé€šè¿‡Agentè‡ªåæ€è¿›åŒ–è§†é¢‘è¯¦ç»†æè¿°æ¨¡å‹ï¼Œæ— éœ€äººå·¥æ ‡æ³¨å’Œå¤§å‹æ•™å¸ˆæ¨¡å‹ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19436v1" onclick="toggleFavorite(this, '2511.19436v1', 'VDC-Agent: When Video Detailed Captioners Evolve Themselves via Agentic Self-Reflection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction">ğŸ”¬ æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>36</td>
  <td><a href="./papers/251118811v1-mitigating-long-tail-bias-in-hoi-detection-via-adaptive-diversity-ca.html">Mitigating Long-Tail Bias in HOI Detection via Adaptive Diversity Cache</a></td>
  <td>æå‡ºè‡ªé€‚åº”å¤šæ ·æ€§ç¼“å­˜æ¨¡å—ï¼Œæ— éœ€é¢å¤–è®­ç»ƒå³å¯ç¼“è§£HOIæ£€æµ‹ä¸­çš„é•¿å°¾åå·®ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18811v1" onclick="toggleFavorite(this, '2511.18811v1', 'Mitigating Long-Tail Bias in HOI Detection via Adaptive Diversity Cache')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>37</td>
  <td><a href="./papers/251119319v1-syncmv4d-synchronized-multi-view-joint-diffusion-of-appearance-and-m.html">SyncMV4D: Synchronized Multi-view Joint Diffusion of Appearance and Motion for Hand-Object Interaction Synthesis</a></td>
  <td>SyncMV4Dï¼šåŒæ­¥å¤šè§†è§’è”åˆæ‰©æ•£ç”Ÿæˆæ‰‹-ç‰©äº¤äº’è§†é¢‘ä¸4Dè¿åŠ¨</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19319v1" onclick="toggleFavorite(this, '2511.19319v1', 'SyncMV4D: Synchronized Multi-view Joint Diffusion of Appearance and Motion for Hand-Object Interaction Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>38</td>
  <td><a href="./papers/251118976v1-peregrine-one-shot-fine-tuning-for-fhe-inference-of-general-deep-cnn.html">Peregrine: One-Shot Fine-Tuning for FHE Inference of General Deep CNNs</a></td>
  <td>Peregrineï¼šç”¨äºé€šç”¨æ·±åº¦CNNçš„FHEæ¨ç†çš„å•æ¬¡å¾®è°ƒæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18976v1" onclick="toggleFavorite(this, '2511.18976v1', 'Peregrine: One-Shot Fine-Tuning for FHE Inference of General Deep CNNs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>39</td>
  <td><a href="./papers/251119217v1-realign-text-to-motion-generation-via-step-aware-reward-guided-align.html">ReAlign: Text-to-Motion Generation via Step-Aware Reward-Guided Alignment</a></td>
  <td>æå‡ºReAlignï¼Œé€šè¿‡æ­¥è¿›å¼å¥–åŠ±å¼•å¯¼å¯¹é½å®ç°é«˜è´¨é‡æ–‡æœ¬åˆ°åŠ¨ä½œç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19217v1" onclick="toggleFavorite(this, '2511.19217v1', 'ReAlign: Text-to-Motion Generation via Step-Aware Reward-Guided Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>40</td>
  <td><a href="./papers/251118775v1-rethinking-garment-conditioning-in-diffusion-based-virtual-try-on.html">Rethinking Garment Conditioning in Diffusion-based Virtual Try-On</a></td>
  <td>æå‡ºRe-CatVTONï¼Œé«˜æ•ˆå•UNetæ‰©æ•£æ¨¡å‹å®ç°é«˜æ€§èƒ½è™šæ‹Ÿè¯•ç©¿</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18775v1" onclick="toggleFavorite(this, '2511.18775v1', 'Rethinking Garment Conditioning in Diffusion-based Virtual Try-On')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting">ğŸ”¬ æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>41</td>
  <td><a href="./papers/251118766v1-unsupervised-multi-view-visual-anomaly-detection-via-progressive-hom.html">Unsupervised Multi-View Visual Anomaly Detection via Progressive Homography-Guided Alignment</a></td>
  <td>æå‡ºViewSense-ADï¼Œé€šè¿‡åŒæ„å˜æ¢å¼•å¯¼å¯¹é½å®ç°æ— ç›‘ç£å¤šè§†è§’å¼‚å¸¸æ£€æµ‹ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18766v1" onclick="toggleFavorite(this, '2511.18766v1', 'Unsupervised Multi-View Visual Anomaly Detection via Progressive Homography-Guided Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction-matching">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction & Matching) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>42</td>
  <td><a href="./papers/251119326v1-monomsk-monocular-3d-musculoskeletal-dynamics-estimation.html">MonoMSK: Monocular 3D Musculoskeletal Dynamics Estimation</a></td>
  <td>MonoMSKï¼šå•ç›®è§†é¢‘ä¸­åŸºäºç‰©ç†çš„3Däººä½“éª¨éª¼è‚Œè‚‰åŠ¨åŠ›å­¦ä¼°è®¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19326v1" onclick="toggleFavorite(this, '2511.19326v1', 'MonoMSK: Monocular 3D Musculoskeletal Dynamics Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)