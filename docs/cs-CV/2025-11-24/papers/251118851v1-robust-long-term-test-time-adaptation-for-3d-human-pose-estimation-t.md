---
layout: default
title: Robust Long-term Test-Time Adaptation for 3D Human Pose Estimation through Motion Discretization
---

# Robust Long-term Test-Time Adaptation for 3D Human Pose Estimation through Motion Discretization

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.18851" target="_blank" class="toolbar-btn">arXiv: 2511.18851v1</a>
    <a href="https://arxiv.org/pdf/2511.18851.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.18851v1" 
            onclick="toggleFavorite(this, '2511.18851v1', 'Robust Long-term Test-Time Adaptation for 3D Human Pose Estimation through Motion Discretization')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yilin Wen, Kechuan Dong, Yusuke Sugano

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-24

**Â§áÊ≥®**: Accepted by AAAI 2026, main track

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éËøêÂä®Á¶ªÊï£ÂåñÁöÑÈ≤ÅÊ£íÈïøÊúüÊµãËØïÊó∂Ëá™ÈÄÇÂ∫î3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°` `ÊµãËØïÊó∂Ëá™ÈÄÇÂ∫î` `ËøêÂä®Á¶ªÊï£Âåñ` `Êó†ÁõëÁù£Â≠¶‰π†` `ÈïøÊúüËßÜÈ¢ë` `ËØØÂ∑ÆÁ¥ØÁßØ` `Ëá™ÊàëÈáçÊîæ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Âú®Á∫øËá™ÈÄÇÂ∫îÁöÑ3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÊòìÂèóËØØÂ∑ÆÁ¥ØÁßØÂΩ±ÂìçÔºåÂØºËá¥ÊÄßËÉΩÈöèÊó∂Èó¥‰∏ãÈôç„ÄÇ
2. ÈÄöËøáËøêÂä®Á¶ªÊï£ÂåñÔºåÂà©Áî®Êó†ÁõëÁù£ËÅöÁ±ªÂæóÂà∞ÈîöÂÆöËøêÂä®ÔºåÂπ∂ÂºïÂÖ•ËΩØÈáçÁΩÆÊú∫Âà∂ÔºåÊèêÂçáÈ≤ÅÊ£íÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ï‰ºò‰∫éÁé∞ÊúâÂú®Á∫øÊµãËØïÊó∂Ëá™ÈÄÇÂ∫îÊñπÊ≥ïÔºåÈ™åËØÅ‰∫ÜËÆæËÆ°ÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÈÄöËøáËøêÂä®Á¶ªÊï£ÂåñÊù•Ëß£ÂÜ≥3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°‰∏≠Âú®Á∫øÊµãËØïÊó∂Ëá™ÈÄÇÂ∫îÁöÑËØØÂ∑ÆÁ¥ØÁßØÈóÆÈ¢ò„ÄÇËØ•ÊñπÊ≥ïÂà©Áî®ÊΩúÂú®ËøêÂä®Ë°®Á§∫Á©∫Èó¥‰∏≠ÁöÑÊó†ÁõëÁù£ËÅöÁ±ªÊù•Ëé∑Âæó‰∏ÄÁªÑÈîöÂÆöËøêÂä®ÔºåËøô‰∫õÈîöÂÆöËøêÂä®ÁöÑËßÑÂæãÊÄßÊúâÂä©‰∫éÁõëÁù£‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°Âô®ÔºåÂπ∂ÂÆûÁé∞ÊúâÊïàÁöÑËá™ÊàëÈáçÊîæ„ÄÇÊ≠§Â§ñÔºåÂºïÂÖ•‰∫Ü‰∏ÄÁßçÊúâÊïàÁöÑËΩØÈáçÁΩÆÊú∫Âà∂ÔºåÈÄöËøáÂú®ËøûÁª≠Ëá™ÈÄÇÂ∫îÊúüÈó¥Â∞ÜÂßøÊÄÅ‰º∞ËÆ°Âô®ÊÅ¢Â§çÂà∞ÂÖ∂ÊåáÊï∞ÁßªÂä®Âπ≥ÂùáÂÄºÊù•ÂÆûÁé∞„ÄÇÈÄöËøáÊåÅÁª≠ÈÄÇÂ∫îÂêå‰∏ÄÂØπË±°ÁöÑÂüüÂ§ñÊµÅÊµãËØïËßÜÈ¢ëÊù•Ê£ÄÊü•ÈïøÊúüÂú®Á∫øËá™ÈÄÇÂ∫îÔºå‰ªéËÄåÂèØ‰ª•Âú®Êï¥‰∏™ÊµÅËßÇÂØüËøáÁ®ã‰∏≠ÊçïËé∑‰∏ÄËá¥ÁöÑ‰∏™‰∫∫ÂΩ¢Áä∂ÂíåËøêÂä®ÁâπÂæÅ„ÄÇÈÄöËøáÂáèËΩªËØØÂ∑ÆÁ¥ØÁßØÔºåËØ•Ëß£ÂÜ≥ÊñπÊ°àËÉΩÂ§üÈ≤ÅÊ£íÂú∞Âà©Áî®Ëøô‰∫õ‰∏™‰∫∫ÁâπÂæÅÊù•ÊèêÈ´òÂáÜÁ°ÆÊÄß„ÄÇÂÆûÈ™åË°®ÊòéÔºåËØ•Ëß£ÂÜ≥ÊñπÊ°à‰ºò‰∫é‰ª•ÂâçÁöÑÂú®Á∫øÊµãËØïÊó∂Ëá™ÈÄÇÂ∫îÊñπÊ≥ïÔºåÂπ∂È™åËØÅ‰∫ÜËÆæËÆ°ÈÄâÊã©„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑÂú®Á∫øÊµãËØïÊó∂Ëá™ÈÄÇÂ∫îÊñπÊ≥ïÂú®3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°‰∏≠Èù¢‰∏¥ËØØÂ∑ÆÁ¥ØÁßØÁöÑÈóÆÈ¢ò„ÄÇÁî±‰∫éÊ®°ÂûãÂú®Êú™Ê†áËÆ∞ÁöÑÊµãËØïÊï∞ÊçÆ‰∏äËøõË°åËá™ÁõëÁù£Â≠¶‰π†Ôºå‰∏çÂÆåÁæéÁöÑÈ¢ÑÊµã‰ºöÈÄêÊ∏êÁ¥ØÁßØËØØÂ∑ÆÔºåÂØºËá¥ÈïøÊúüÊÄßËÉΩ‰∏ãÈôç„ÄÇÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜÈïøÊúüËßÜÈ¢ëÊµÅÊó∂ÔºåËøôÁßçËØØÂ∑ÆÁ¥ØÁßØ‰ºö‰∏•ÈáçÂΩ±ÂìçÂßøÊÄÅ‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáËøêÂä®Á¶ªÊï£ÂåñÊù•ÂºïÂÖ•ËøêÂä®ÁöÑËßÑÂæãÊÄßÔºå‰ªéËÄåÁ∫¶ÊùüÂßøÊÄÅ‰º∞ËÆ°Âô®ÁöÑÂ≠¶‰π†ËøáÁ®ãÔºåÂáèÂ∞ëËØØÂ∑ÆÁ¥ØÁßØ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈÄöËøáÊó†ÁõëÁù£ËÅöÁ±ªÂ∞ÜËøêÂä®Ë°®Á§∫Á©∫Èó¥ÂàíÂàÜ‰∏∫Ëã•Âπ≤‰∏™Á¶ªÊï£ÁöÑÈîöÂÆöËøêÂä®ÔºåÂà©Áî®Ëøô‰∫õÈîöÂÆöËøêÂä®Êù•ÁõëÁù£ÂßøÊÄÅ‰º∞ËÆ°Âô®ÁöÑËÆ≠ÁªÉ„ÄÇÊ≠§Â§ñÔºåÂºïÂÖ•ËΩØÈáçÁΩÆÊú∫Âà∂ÔºåÂÆöÊúüÂ∞ÜÂßøÊÄÅ‰º∞ËÆ°Âô®ÊÅ¢Â§çÂà∞ÂÖ∂ÂéÜÂè≤Áä∂ÊÄÅÔºå‰ª•Èò≤Ê≠¢Ê®°ÂûãËøáÂ∫¶ÈÄÇÂ∫îÂô™Â£∞Êï∞ÊçÆ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÂßøÊÄÅ‰º∞ËÆ°Âô®ÔºöÁî®‰∫é‰ªéËßÜÈ¢ëÂ∏ß‰∏≠‰º∞ËÆ°3D‰∫∫‰ΩìÂßøÊÄÅ„ÄÇ2) ËøêÂä®Ë°®Á§∫ÊèêÂèñÂô®ÔºöÁî®‰∫éÊèêÂèñËøûÁª≠Â∏ß‰πãÈó¥ÁöÑËøêÂä®Ë°®Á§∫„ÄÇ3) Êó†ÁõëÁù£ËÅöÁ±ªÊ®°ÂùóÔºöÁî®‰∫éÂ∞ÜËøêÂä®Ë°®Á§∫Á©∫Èó¥ÂàíÂàÜ‰∏∫Ëã•Âπ≤‰∏™Á∞áÔºåÊØè‰∏™Á∞á‰ª£Ë°®‰∏Ä‰∏™ÈîöÂÆöËøêÂä®„ÄÇ4) Ëá™ÊàëÈáçÊîæÊ®°ÂùóÔºöÂà©Áî®ÈîöÂÆöËøêÂä®Êù•ÁîüÊàê‰º™Ê†áÁ≠æÔºåÁî®‰∫éÁõëÁù£ÂßøÊÄÅ‰º∞ËÆ°Âô®ÁöÑËÆ≠ÁªÉ„ÄÇ5) ËΩØÈáçÁΩÆÊ®°ÂùóÔºöÂÆöÊúüÂ∞ÜÂßøÊÄÅ‰º∞ËÆ°Âô®ÊÅ¢Â§çÂà∞ÂÖ∂ÊåáÊï∞ÁßªÂä®Âπ≥ÂùáÂÄº„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂà©Áî®ËøêÂä®Á¶ªÊï£ÂåñÊù•ÂºïÂÖ•ËøêÂä®ÁöÑËßÑÂæãÊÄßÔºå‰ªéËÄåÁ∫¶ÊùüÂßøÊÄÅ‰º∞ËÆ°Âô®ÁöÑÂ≠¶‰π†ËøáÁ®ã„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ï‰∏çÈúÄË¶Å‰∫∫Â∑•Ê†áÊ≥®ÁöÑËøêÂä®Ê†áÁ≠æÔºåËÄåÊòØÈÄöËøáÊó†ÁõëÁù£ËÅöÁ±ªËá™Âä®Â≠¶‰π†ËøêÂä®Ê®°Âºè„ÄÇÊ≠§Â§ñÔºåËΩØÈáçÁΩÆÊú∫Âà∂ËÉΩÂ§üÊúâÊïàÂú∞Èò≤Ê≠¢Ê®°ÂûãËøáÂ∫¶ÈÄÇÂ∫îÂô™Â£∞Êï∞ÊçÆÔºåÊèêÈ´òÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËøêÂä®Ë°®Á§∫ÊèêÂèñÊñπÈù¢ÔºåÂèØ‰ª•‰ΩøÁî®‰æãÂ¶ÇÂÖâÊµÅ„ÄÅÈ™®È™ºËøêÂä®Á≠âÁâπÂæÅ„ÄÇÊó†ÁõëÁù£ËÅöÁ±ªÂèØ‰ª•‰ΩøÁî®K-meansÁ≠âÁÆóÊ≥ï„ÄÇËá™ÊàëÈáçÊîæÊ®°ÂùóÂèØ‰ª•ÈÄöËøáÂ∞ÜÈîöÂÆöËøêÂä®‰∏éÂßøÊÄÅ‰º∞ËÆ°Âô®ÁöÑËæìÂá∫ËøõË°åÊØîËæÉÔºåËÆ°ÁÆó‰∏ÄËá¥ÊÄßÊçüÂ§±„ÄÇËΩØÈáçÁΩÆÊ®°ÂùóÂèØ‰ª•ÈÄöËøáÊåáÊï∞ÁßªÂä®Âπ≥ÂùáÔºàEMAÔºâÊù•Áª¥Êä§ÂßøÊÄÅ‰º∞ËÆ°Âô®ÁöÑÂéÜÂè≤Áä∂ÊÄÅÔºåÂπ∂ÂÆöÊúüÂ∞ÜÂÖ∂ÊùÉÈáçÊÅ¢Â§çÂà∞EMAÂÄº„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®ÈïøÊúüÊµãËØïÊó∂Ëá™ÈÄÇÂ∫î‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÂáèÂ∞ëËØØÂ∑ÆÁ¥ØÁßØÔºåÊèêÈ´òÂßøÊÄÅ‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÈÉΩÂèñÂæó‰∫Üstate-of-the-artÁöÑÁªìÊûúÔºåÂπ∂‰∏îÂú®ÈïøÊúüËßÜÈ¢ëÊµÅ‰∏äÁöÑÊÄßËÉΩÊèêÂçáÂ∞§‰∏∫ÊòéÊòæ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËßÜÈ¢ëÁõëÊéß„ÄÅ‰∫∫Êú∫‰∫§‰∫í„ÄÅËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®ËßÜÈ¢ëÁõëÊéß‰∏≠ÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïÂØπÁõëÊéßËßÜÈ¢ë‰∏≠ÁöÑ‰∫∫‰ΩìÂßøÊÄÅËøõË°åÈïøÊúüË∑üË∏™ÂíåÂàÜÊûêÔºå‰ªéËÄåÂÆûÁé∞ÂºÇÂ∏∏Ë°å‰∏∫Ê£ÄÊµã„ÄÇÂú®‰∫∫Êú∫‰∫§‰∫í‰∏≠ÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïÂÆûÁé∞Êõ¥Ëá™ÁÑ∂„ÄÅÊõ¥ÂáÜÁ°ÆÁöÑ‰∫∫‰ΩìÂßøÊÄÅËØÜÂà´Ôºå‰ªéËÄåÊèêÈ´ò‰∫§‰∫í‰ΩìÈ™å„ÄÇÂú®ËôöÊãüÁé∞ÂÆû‰∏≠ÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïÂÆûÁé∞Êõ¥ÈÄºÁúüÁöÑ‰∫∫‰ΩìÂä®‰ΩúÊçïÊçâÔºå‰ªéËÄåÂ¢ûÂº∫Ê≤âÊµ∏ÊÑü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Online test-time adaptation addresses the train-test domain gap by adapting the model on unlabeled streaming test inputs before making the final prediction. However, online adaptation for 3D human pose estimation suffers from error accumulation when relying on self-supervision with imperfect predictions, leading to degraded performance over time. To mitigate this fundamental challenge, we propose a novel solution that highlights the use of motion discretization. Specifically, we employ unsupervised clustering in the latent motion representation space to derive a set of anchor motions, whose regularity aids in supervising the human pose estimator and enables efficient self-replay. Additionally, we introduce an effective and efficient soft-reset mechanism by reverting the pose estimator to its exponential moving average during continuous adaptation. We examine long-term online adaptation by continuously adapting to out-of-domain streaming test videos of the same individual, which allows for the capture of consistent personal shape and motion traits throughout the streaming observation. By mitigating error accumulation, our solution enables robust exploitation of these personal traits for enhanced accuracy. Experiments demonstrate that our solution outperforms previous online test-time adaptation methods and validate our design choices.

