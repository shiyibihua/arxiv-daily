---
layout: default
title: Ref-SAM3D: Bridging SAM3D with Text for Reference 3D Reconstruction
---

# Ref-SAM3D: Bridging SAM3D with Text for Reference 3D Reconstruction

**arXiv**: [2511.19426v1](https://arxiv.org/abs/2511.19426) | [PDF](https://arxiv.org/pdf/2511.19426.pdf)

**ä½œè€…**: Yun Zhou, Yaoting Wang, Guangquan Jie, Jinyu Liu, Henghui Ding

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRef-SAM3Dä»¥è§£å†³SAM3Dæ— æ³•åŸºäºŽæ–‡æœ¬æè¿°é‡å»ºç‰¹å®š3Då¯¹è±¡çš„é—®é¢˜**

**å…³é”®è¯**: `3Dé‡å»º` `æ–‡æœ¬å¼•å¯¼` `é›¶æ ·æœ¬å­¦ä¹ ` `å•è§†å›¾é‡å»º` `SAM3Dæ‰©å±•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šSAM3Dç¼ºä¹åŸºäºŽæ–‡æœ¬æè¿°é‡å»ºç‰¹å®š3Då¯¹è±¡çš„èƒ½åŠ›ï¼Œé™åˆ¶å®žé™…åº”ç”¨
2. æ–¹æ³•è¦ç‚¹ï¼šæ‰©å±•SAM3Dï¼Œå¼•å…¥æ–‡æœ¬æè¿°ä½œä¸ºå…ˆéªŒï¼Œå®žçŽ°å•RGBå›¾åƒçš„æ–‡æœ¬å¼•å¯¼3Dé‡å»º
3. å®žéªŒæˆ–æ•ˆæžœï¼šé›¶æ ·æœ¬é‡å»ºæ€§èƒ½ç«žäº‰ä¸”é«˜ä¿çœŸï¼Œä»…éœ€è‡ªç„¶è¯­è¨€å’Œå•2Dè§†å›¾

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> SAM3D has garnered widespread attention for its strong 3D object reconstruction capabilities. However, a key limitation remains: SAM3D cannot reconstruct specific objects referred to by textual descriptions, a capability that is essential for practical applications such as 3D editing, game development, and virtual environments. To address this gap, we introduce Ref-SAM3D, a simple yet effective extension to SAM3D that incorporates textual descriptions as a high-level prior, enabling text-guided 3D reconstruction from a single RGB image. Through extensive qualitative experiments, we show that Ref-SAM3D, guided only by natural language and a single 2D view, delivers competitive and high-fidelity zero-shot reconstruction performance. Our results demonstrate that Ref-SAM3D effectively bridges the gap between 2D visual cues and 3D geometric understanding, offering a more flexible and accessible paradigm for reference-guided 3D reconstruction. Code is available at: https://github.com/FudanCVL/Ref-SAM3D.

