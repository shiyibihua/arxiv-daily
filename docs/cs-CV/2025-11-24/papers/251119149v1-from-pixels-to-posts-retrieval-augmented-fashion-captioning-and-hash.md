---
layout: default
title: From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag Generation
---

# From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag Generation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.19149" target="_blank" class="toolbar-btn">arXiv: 2511.19149v1</a>
    <a href="https://arxiv.org/pdf/2511.19149.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.19149v1" 
            onclick="toggleFavorite(this, '2511.19149v1', 'From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag Generation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Moazzam Umer Gondal, Hamad Ul Qudous, Daniya Siddiqui, Asma Ahmad Farhan

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-24

**Â§áÊ≥®**: Submitted to Expert Systems with Applications

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Ê£ÄÁ¥¢Â¢ûÂº∫ÁöÑÊó∂Â∞öÊèèËø∞‰∏éÊ†áÁ≠æÁîüÊàêÊ°ÜÊû∂ÔºåÊèêÂçáÂ±ûÊÄß‰øùÁúüÂ∫¶ÂíåÈ¢ÜÂüüÊ≥õÂåñÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Êó∂Â∞öÂõæÂÉèÊèèËø∞` `Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê` `Â§öÊúçË£ÖÊ£ÄÊµã` `Â±ûÊÄßÊé®ÁêÜ` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ÊúçË£ÖÊ†áÁ≠æÁîüÊàê` `CLIP-FAISS` `È¢ÜÂüüÊ≥õÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁ´ØÂà∞Á´ØÊó∂Â∞öÂõæÂÉèÊèèËø∞Ê®°ÂûãÂú®Â±ûÊÄß‰øùÁúüÂ∫¶ÂíåÈ¢ÜÂüüÊ≥õÂåñÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÈöæ‰ª•ÂáÜÁ°ÆÊèèËø∞ÊúçË£ÖÁªÜËäÇÂíåÈ£éÊ†º„ÄÇ
2. ÊèêÂá∫‰∏ÄÁßçÊ£ÄÁ¥¢Â¢ûÂº∫Ê°ÜÊû∂ÔºåÂà©Áî®Â§öÊúçË£ÖÊ£ÄÊµã„ÄÅÂ±ûÊÄßÊé®ÁêÜÂíåLLMÊèêÁ§∫ÔºåÁîüÊàêÊõ¥ÂáÜÁ°Æ„ÄÅÊõ¥ÂÖ∑È£éÊ†ºÁöÑÊó∂Â∞öÊèèËø∞ÂíåÊ†áÁ≠æ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•Ê°ÜÊû∂Âú®Â±ûÊÄßË¶ÜÁõñÁéáÂíå‰∫ãÂÆûÂü∫Á°ÄÊñπÈù¢‰ºò‰∫éÂü∫Á∫øÊ®°ÂûãBLIPÔºåÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÊ≥õÂåñËÉΩÂäõÂíåÂèØÊâ©Â±ïÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊ£ÄÁ¥¢Â¢ûÂº∫Ê°ÜÊû∂ÔºåÁî®‰∫éËá™Âä®ÁîüÊàêÊó∂Â∞öÂõæÂÉèÁöÑÊèèËø∞ÂíåÊ†áÁ≠æ„ÄÇËØ•Ê°ÜÊû∂ÁªìÂêà‰∫ÜÂ§öÊúçË£ÖÊ£ÄÊµã„ÄÅÂ±ûÊÄßÊé®ÁêÜÂíåÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÊèêÁ§∫„ÄÇÊó®Âú®‰∏∫Êó∂Â∞öÂõæÂÉèÁîüÊàêËßÜËßâ‰∏äÊúâÂÖ≥ËÅî„ÄÅÊèèËø∞ÊÄßÂº∫‰∏îÈ£éÊ†ºÊúâË∂£ÁöÑÊñáÊú¨ÔºåÂÖãÊúç‰∫ÜÁ´ØÂà∞Á´ØÊèèËø∞Âô®Âú®Â±ûÊÄß‰øùÁúüÂ∫¶ÂíåÈ¢ÜÂüüÊ≥õÂåñÊñπÈù¢ÁöÑÂ±ÄÈôêÊÄß„ÄÇËØ•ÊµÅÁ®ãÁªìÂêà‰∫ÜÂü∫‰∫éYOLOÁöÑÊ£ÄÊµãÂô®ËøõË°åÂ§öÊúçË£ÖÂÆö‰ΩçÔºåk-meansËÅöÁ±ªÊèêÂèñ‰∏ªËâ≤Ë∞ÉÔºå‰ª•ÂèäÂü∫‰∫éÁªìÊûÑÂåñ‰∫ßÂìÅÁ¥¢ÂºïÁöÑCLIP-FAISSÊ£ÄÁ¥¢Ê®°ÂùóËøõË°åÈù¢ÊñôÂíåÊÄßÂà´Â±ûÊÄßÊé®Êñ≠„ÄÇËøô‰∫õÂ±ûÊÄß‰∏éÊ£ÄÁ¥¢Âà∞ÁöÑÈ£éÊ†ºÁ§∫‰æã‰∏ÄËµ∑ÔºåÂàõÂª∫‰∫Ü‰∏Ä‰∏™‰∫ãÂÆûËØÅÊçÆÂåÖÔºåÁî®‰∫éÂºïÂØºLLMÁîüÊàêÁ±ª‰ºº‰∫∫Á±ªÁöÑÊèèËø∞Âíå‰∏ä‰∏ãÊñá‰∏∞ÂØåÁöÑÊ†áÁ≠æ„ÄÇ‰ΩøÁî®ÂæÆË∞ÉÁöÑBLIPÊ®°Âûã‰Ωú‰∏∫ÊúâÁõëÁù£ÁöÑÂü∫Á∫øÊ®°ÂûãËøõË°åÊØîËæÉ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåYOLOÊ£ÄÊµãÂô®Âú®‰πù‰∏™ÊúçË£ÖÁ±ªÂà´‰∏≠Ëé∑Âæó‰∫Ü0.71ÁöÑÂπ≥ÂùáÁ≤æÂ∫¶ÂùáÂÄºÔºàmAP@0.5Ôºâ„ÄÇRAG-LLMÊµÅÁ®ãÁîüÊàê‰∫ÜÂØåÊúâË°®Áé∞ÂäõÁöÑÂ±ûÊÄßÂØπÈΩêÊèèËø∞ÔºåÂπ∂Âú®Ê†áÁ≠æÁîüÊàê‰∏≠ÂÆûÁé∞‰∫Ü0.80ÁöÑÂπ≥ÂùáÂ±ûÊÄßË¶ÜÁõñÁéáÔºåÂú®50%ÈòàÂÄº‰∏ãÂÆûÁé∞‰∫ÜÂÆåÂÖ®Ë¶ÜÁõñÔºåËÄåBLIPÊèê‰æõ‰∫ÜÊõ¥È´òÁöÑËØçÊ±áÈáçÂè†ÂíåÊõ¥‰ΩéÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊ£ÄÁ¥¢Â¢ûÂº∫ÊñπÊ≥ïË°®Áé∞Âá∫Êõ¥Â•ΩÁöÑ‰∫ãÂÆûÂü∫Á°Ä„ÄÅÊõ¥Â∞ëÁöÑÂπªËßâÔºåÂπ∂‰∏îÂú®ÂêÑÁßçÊúçË£ÖÈ¢ÜÂüüÂÖ∑ÊúâÂ∑®Â§ßÁöÑÂèØÊâ©Â±ïÈÉ®ÁΩ≤ÊΩúÂäõ„ÄÇËøô‰∫õÁªìÊûúËØÅÊòé‰∫ÜÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê‰Ωú‰∏∫‰∏ÄÁßçÊúâÊïà‰∏îÂèØËß£ÈáäÁöÑËåÉ‰æãÔºåÁî®‰∫éËá™Âä®ÂíåËßÜËßâÂü∫Á°ÄÁöÑÊó∂Â∞öÂÜÖÂÆπÁîüÊàê„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊó∂Â∞öÂõæÂÉèÊèèËø∞ÊñπÊ≥ïÔºåÁâπÂà´ÊòØÁ´ØÂà∞Á´ØÊ®°ÂûãÔºåÈöæ‰ª•‰øùËØÅÁîüÊàêÊèèËø∞ÁöÑÂ±ûÊÄßÂáÜÁ°ÆÊÄßÔºåÂπ∂‰∏îÂú®‰∏çÂêåÊúçË£ÖÈ¢ÜÂüüÊ≥õÂåñËÉΩÂäõËæÉÂº±„ÄÇËøô‰∫õÊ®°ÂûãÂÆπÊòì‰∫ßÁîüÂπªËßâÔºåÊó†Ê≥ïÂáÜÁ°ÆÊçïÊçâÂõæÂÉè‰∏≠ÊúçË£ÖÁöÑÁªÜËäÇÂíåÈ£éÊ†ºÁâπÂæÅ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÊ°ÜÊû∂ÔºåÈÄöËøáÊ£ÄÁ¥¢‰∏éÂõæÂÉèÁõ∏ÂÖ≥ÁöÑÂ±ûÊÄßÂíåÈ£éÊ†º‰ø°ÊÅØÔºå‰∏∫Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÊèê‰æõÊõ¥‰∏∞ÂØåÁöÑ‰∫ãÂÆû‰æùÊçÆÔºå‰ªéËÄåÂºïÂØºLLMÁîüÊàêÊõ¥ÂáÜÁ°Æ„ÄÅÊõ¥ÂÖ∑È£éÊ†ºÁöÑÊèèËø∞ÂíåÊ†áÁ≠æ„ÄÇËøôÁßçÊñπÊ≥ïÊó®Âú®ÂáèÂ∞ëÂπªËßâÔºåÊèêÈ´òÂ±ûÊÄß‰øùÁúüÂ∫¶ÔºåÂπ∂Â¢ûÂº∫È¢ÜÂüüÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂ÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) Âü∫‰∫éYOLOÁöÑÂ§öÊúçË£ÖÊ£ÄÊµãÂô®ÔºåÁî®‰∫éÂÆö‰ΩçÂõæÂÉè‰∏≠ÁöÑÂêÑ‰∏™ÊúçË£ÖÔºõ2) k-meansËÅöÁ±ªÔºåÁî®‰∫éÊèêÂèñÊúçË£ÖÁöÑ‰∏ªËâ≤Ë∞ÉÔºõ3) CLIP-FAISSÊ£ÄÁ¥¢Ê®°ÂùóÔºåÂü∫‰∫éÁªìÊûÑÂåñ‰∫ßÂìÅÁ¥¢ÂºïÊé®Êñ≠ÊúçË£ÖÁöÑÈù¢ÊñôÂíåÊÄßÂà´Â±ûÊÄßÔºõ4) LLMÔºåÁî®‰∫éÁîüÊàêÊèèËø∞ÂíåÊ†áÁ≠æÔºåÂÖ∂ËæìÂÖ•ÂåÖÊã¨Ê£ÄÊµãÂà∞ÁöÑÊúçË£Ö„ÄÅÊèêÂèñÁöÑÂ±ûÊÄßÂíåÊ£ÄÁ¥¢Âà∞ÁöÑÈ£éÊ†ºÁ§∫‰æã„ÄÇÊï¥‰∏™ÊµÅÁ®ãÈ¶ñÂÖàÂØπÂõæÂÉèËøõË°åÂàÜÊûêÔºåÊèêÂèñÁõ∏ÂÖ≥‰ø°ÊÅØÔºåÁÑ∂ÂêéÂ∞ÜËøô‰∫õ‰ø°ÊÅØ‰Ωú‰∏∫ÊèêÁ§∫ËæìÂÖ•LLMÔºåÊúÄÂêéÁî±LLMÁîüÊàêÊúÄÁªàÁöÑÊèèËø∞ÂíåÊ†áÁ≠æ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÂ∫îÁî®‰∫éÊó∂Â∞öÂõæÂÉèÊèèËø∞ÂíåÊ†áÁ≠æÁîüÊàê‰ªªÂä°„ÄÇÈÄöËøáÊ£ÄÁ¥¢‰∏éÂõæÂÉèÁõ∏ÂÖ≥ÁöÑÂ±ûÊÄßÂíåÈ£éÊ†º‰ø°ÊÅØÔºåËØ•ÊñπÊ≥ïËÉΩÂ§ü‰∏∫LLMÊèê‰æõÊõ¥‰∏∞ÂØåÁöÑ‰∫ãÂÆû‰æùÊçÆÔºå‰ªéËÄåÁîüÊàêÊõ¥ÂáÜÁ°Æ„ÄÅÊõ¥ÂÖ∑È£éÊ†ºÁöÑÊèèËø∞ÂíåÊ†áÁ≠æ„ÄÇ‰∏é‰º†ÁªüÁöÑÁ´ØÂà∞Á´ØÊ®°ÂûãÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÂ±ûÊÄß‰øùÁúüÂ∫¶„ÄÅÊõ¥Â∞ëÁöÑÂπªËßâÂíåÊõ¥Âº∫ÁöÑÈ¢ÜÂüüÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®CLIP-FAISSÊ£ÄÁ¥¢Ê®°Âùó‰∏≠ÔºåÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÁªìÊûÑÂåñÁöÑ‰∫ßÂìÅÁ¥¢ÂºïÔºåÁî®‰∫éÂ≠òÂÇ®ÊúçË£ÖÁöÑÂ±ûÊÄß‰ø°ÊÅØ„ÄÇÂú®LLMÊèêÁ§∫ÊñπÈù¢ÔºåËÆæËÆ°‰∫Ü‰∏Ä‰∏™ÊúâÊïàÁöÑ‰∫ãÂÆûËØÅÊçÆÂåÖÔºåÂåÖÊã¨Ê£ÄÊµãÂà∞ÁöÑÊúçË£Ö„ÄÅÊèêÂèñÁöÑÂ±ûÊÄßÂíåÊ£ÄÁ¥¢Âà∞ÁöÑÈ£éÊ†ºÁ§∫‰æã„ÄÇÊ≠§Â§ñÔºåËøòÂØπBLIPÊ®°ÂûãËøõË°å‰∫ÜÂæÆË∞ÉÔºå‰Ωú‰∏∫ÊúâÁõëÁù£ÁöÑÂü∫Á∫øÊ®°ÂûãËøõË°åÊØîËæÉ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Ê°ÜÊû∂Âú®‰πù‰∏™ÊúçË£ÖÁ±ªÂà´‰∏≠Ëé∑Âæó‰∫Ü0.71ÁöÑÂπ≥ÂùáÁ≤æÂ∫¶ÂùáÂÄºÔºàmAP@0.5Ôºâ„ÄÇRAG-LLMÊµÅÁ®ãÁîüÊàê‰∫ÜÂØåÊúâË°®Áé∞ÂäõÁöÑÂ±ûÊÄßÂØπÈΩêÊèèËø∞ÔºåÂπ∂Âú®Ê†áÁ≠æÁîüÊàê‰∏≠ÂÆûÁé∞‰∫Ü0.80ÁöÑÂπ≥ÂùáÂ±ûÊÄßË¶ÜÁõñÁéáÔºåÂú®50%ÈòàÂÄº‰∏ãÂÆûÁé∞‰∫ÜÂÆåÂÖ®Ë¶ÜÁõñ„ÄÇ‰∏éÂü∫Á∫øÊ®°ÂûãBLIPÁõ∏ÊØîÔºåËØ•Ê°ÜÊû∂ÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÂ±ûÊÄß‰øùÁúüÂ∫¶„ÄÅÊõ¥Â∞ëÁöÑÂπªËßâÂíåÊõ¥Âº∫ÁöÑÈ¢ÜÂüüÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÁîµÂïÜÂπ≥Âè∞„ÄÅÊó∂Â∞öÂçöÂÆ¢„ÄÅÁ§æ‰∫§Â™í‰ΩìÁ≠âÈ¢ÜÂüüÔºåËá™Âä®ÁîüÊàêÂïÜÂìÅÊèèËø∞ÂíåÊ†áÁ≠æÔºåÊèêÈ´òÂïÜÂìÅÊõùÂÖâÁéáÂíåÁî®Êà∑ÂèÇ‰∏éÂ∫¶„ÄÇÊ≠§Â§ñÔºåËØ•ÊäÄÊúØËøòÂèØÁî®‰∫éËæÖÂä©Êó∂Â∞öËÆæËÆ°Â∏àËøõË°åÈ£éÊ†ºÂàÜÊûêÂíåÁÅµÊÑüÊåñÊéòÔºå‰ª•Âèä‰∏∫Ê∂àË¥πËÄÖÊèê‰æõ‰∏™ÊÄßÂåñÁöÑÊó∂Â∞öÊé®Ëçê„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> This paper introduces the retrieval-augmented framework for automatic fashion caption and hashtag generation, combining multi-garment detection, attribute reasoning, and Large Language Model (LLM) prompting. The system aims to produce visually grounded, descriptive, and stylistically interesting text for fashion imagery, overcoming the limitations of end-to-end captioners that have problems with attribute fidelity and domain generalization. The pipeline combines a YOLO-based detector for multi-garment localization, k-means clustering for dominant color extraction, and a CLIP-FAISS retrieval module for fabric and gender attribute inference based on a structured product index. These attributes, together with retrieved style examples, create a factual evidence pack that is used to guide an LLM to generate human-like captions and contextually rich hashtags. A fine-tuned BLIP model is used as a supervised baseline model for comparison. Experimental results show that the YOLO detector is able to obtain a mean Average Precision (mAP@0.5) of 0.71 for nine categories of garments. The RAG-LLM pipeline generates expressive attribute-aligned captions and achieves mean attribute coverage of 0.80 with full coverage at the 50% threshold in hashtag generation, whereas BLIP gives higher lexical overlap and lower generalization. The retrieval-augmented approach exhibits better factual grounding, less hallucination, and great potential for scalable deployment in various clothing domains. These results demonstrate the use of retrieval-augmented generation as an effective and interpretable paradigm for automated and visually grounded fashion content generation.

