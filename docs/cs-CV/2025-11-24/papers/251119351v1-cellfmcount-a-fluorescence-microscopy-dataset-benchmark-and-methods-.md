---
layout: default
title: CellFMCount: A Fluorescence Microscopy Dataset, Benchmark, and Methods for Cell Counting
---

# CellFMCount: A Fluorescence Microscopy Dataset, Benchmark, and Methods for Cell Counting

**arXiv**: [2511.19351v1](https://arxiv.org/abs/2511.19351) | [PDF](https://arxiv.org/pdf/2511.19351.pdf)

**ä½œè€…**: Abdurahman Ali Mohammed, Catherine Fonder, Ying Wei, Wallapak Tavanapong, Donald S Sakaguchi, Qi Li, Surya K. Mallapragada

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCellFMCountæ•°æ®é›†ä¸ŽSAM-Counteræ–¹æ³•ä»¥è§£å†³è§å…‰æ˜¾å¾®é•œç»†èƒžè®¡æ•°éš¾é¢˜**

**å…³é”®è¯**: `ç»†èƒžè®¡æ•°` `è§å…‰æ˜¾å¾®é•œæ•°æ®é›†` `å¯†åº¦å›¾æ–¹æ³•` `SAMæ¨¡åž‹é€‚é…` `åŸºå‡†æµ‹è¯•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç»†èƒžè®¡æ•°åœ¨ç”Ÿç‰©åŒ»å­¦ä¸­å…³é”®ä½†æ‰‹åŠ¨è®¡æ•°è´¹æ—¶æ˜“é”™ï¼Œéœ€è‡ªåŠ¨åŒ–æ–¹æ³•
2. å¼•å…¥å¤§è§„æ¨¡æ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•ï¼Œå¹¶é€‚é…SAMæ¨¡åž‹ç”¨äºŽç»†èƒžè®¡æ•°
3. SAM-Counteræ–¹æ³•åœ¨æµ‹è¯•é›†ä¸ŠMAEä¸º22.12ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Accurate cell counting is essential in various biomedical research and clinical applications, including cancer diagnosis, stem cell research, and immunology. Manual counting is labor-intensive and error-prone, motivating automation through deep learning techniques. However, training reliable deep learning models requires large amounts of high-quality annotated data, which is difficult and time-consuming to produce manually. Consequently, existing cell-counting datasets are often limited, frequently containing fewer than $500$ images. In this work, we introduce a large-scale annotated dataset comprising $3{,}023$ images from immunocytochemistry experiments related to cellular differentiation, containing over $430{,}000$ manually annotated cell locations. The dataset presents significant challenges: high cell density, overlapping and morphologically diverse cells, a long-tailed distribution of cell count per image, and variation in staining protocols. We benchmark three categories of existing methods: regression-based, crowd-counting, and cell-counting techniques on a test set with cell counts ranging from $10$ to $2{,}126$ cells per image. We also evaluate how the Segment Anything Model (SAM) can be adapted for microscopy cell counting using only dot-annotated datasets. As a case study, we implement a density-map-based adaptation of SAM (SAM-Counter) and report a mean absolute error (MAE) of $22.12$, which outperforms existing approaches (second-best MAE of $27.46$). Our results underscore the value of the dataset and the benchmarking framework for driving progress in automated cell counting and provide a robust foundation for future research and development.

