---
layout: default
title: Are Image-to-Video Models Good Zero-Shot Image Editors?
---

# Are Image-to-Video Models Good Zero-Shot Image Editors?

**arXiv**: [2511.19435v1](https://arxiv.org/abs/2511.19435) | [PDF](https://arxiv.org/pdf/2511.19435.pdf)

**ä½œè€…**: Zechuan Zhang, Zhenyuan Chen, Zongxin Yang, Yi Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIF-Editæ¡†æž¶ï¼Œåˆ©ç”¨å›¾åƒåˆ°è§†é¢‘æ‰©æ•£æ¨¡åž‹å®žçŽ°é›¶æ ·æœ¬å›¾åƒç¼–è¾‘**

**å…³é”®è¯**: `å›¾åƒç¼–è¾‘` `è§†é¢‘æ‰©æ•£æ¨¡åž‹` `é›¶æ ·æœ¬å­¦ä¹ ` `æŽ¨ç†å¢žå¼º` `æ½œåœ¨å˜é‡åŽ‹ç¼©`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†é¢‘æ‰©æ•£æ¨¡åž‹åœ¨é›¶æ ·æœ¬å›¾åƒç¼–è¾‘ä¸­å­˜åœ¨æç¤ºé”™ä½ã€å†—ä½™æ—¶é—´æ½œåœ¨å˜é‡å’Œæ¨¡ç³ŠåŽæœŸå¸§é—®é¢˜
2. æ–¹æ³•è¦ç‚¹ï¼šåŒ…æ‹¬æ€ç»´é“¾æç¤ºå¢žå¼ºã€æ—¶é—´æ½œåœ¨å˜é‡ä¸¢å¼ƒå’Œè‡ªä¸€è‡´åŽç²¾ç‚¼æ­¥éª¤
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œåœ¨æŽ¨ç†ä»»åŠ¡ä¸Šè¡¨çŽ°ä¼˜å¼‚ï¼Œé€šç”¨ç¼–è¾‘ä»»åŠ¡ä¿æŒç«žäº‰åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large-scale video diffusion models show strong world simulation and temporal reasoning abilities, but their use as zero-shot image editors remains underexplored. We introduce IF-Edit, a tuning-free framework that repurposes pretrained image-to-video diffusion models for instruction-driven image editing. IF-Edit addresses three key challenges: prompt misalignment, redundant temporal latents, and blurry late-stage frames. It includes (1) a chain-of-thought prompt enhancement module that transforms static editing instructions into temporally grounded reasoning prompts; (2) a temporal latent dropout strategy that compresses frame latents after the expert-switch point, accelerating denoising while preserving semantic and temporal coherence; and (3) a self-consistent post-refinement step that sharpens late-stage frames using a short still-video trajectory. Experiments on four public benchmarks, covering non-rigid editing, physical and temporal reasoning, and general instruction edits, show that IF-Edit performs strongly on reasoning-centric tasks while remaining competitive on general-purpose edits. Our study provides a systematic view of video diffusion models as image editors and highlights a simple recipe for unified video-image generative reasoning.

