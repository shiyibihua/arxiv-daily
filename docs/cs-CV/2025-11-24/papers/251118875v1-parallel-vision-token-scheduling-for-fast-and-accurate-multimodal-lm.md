---
layout: default
title: Parallel Vision Token Scheduling for Fast and Accurate Multimodal LMMs Inference
---

# Parallel Vision Token Scheduling for Fast and Accurate Multimodal LMMs Inference

**arXiv**: [2511.18875v1](https://arxiv.org/abs/2511.18875) | [PDF](https://arxiv.org/pdf/2511.18875.pdf)

**ä½œè€…**: Wengyi Zhan, Mingbao Lin, Zhihang Lin, Rongrong Ji

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¹¶è¡Œè§†è§‰ä»¤ç‰Œè°ƒåº¦ä»¥åŠ é€Ÿå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹æŽ¨ç†**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `è§†è§‰ä»¤ç‰Œè°ƒåº¦` `æŽ¨ç†åŠ é€Ÿ` `è®¡ç®—å¤æ‚åº¦é™ä½Ž` `è®­ç»ƒæ— å…³æ–¹æ³•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹æŽ¨ç†å»¶è¿Ÿé«˜ï¼Œå› è‡ªæ³¨æ„åŠ›éšåºåˆ—é•¿åº¦å¹³æ–¹å¢žé•¿å’Œè§†è§‰ä»¤ç‰Œè¿‡å¤š
2. å°†è§†è§‰ä»¤ç‰Œåˆ†ä¸ºä¸»ä½“å’Œéžä¸»ä½“ç»„å¹¶è¡Œå¤„ç†ï¼Œè½¬ç§»è¯­ä¹‰åŽä¸¢å¼ƒéžä¸»ä½“è·¯å¾„ä»¥å‡å°‘è®¡ç®—
3. å®žéªŒæ˜¾ç¤ºå¯å‰ªæž88.9%è§†è§‰ä»¤ç‰Œï¼Œæ€§èƒ½æŸå¤±å°ï¼Œå®žçŽ°1.77å€åŠ é€Ÿå’Œ70%FLOPså‡å°‘

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) deliver impressive vision-language reasoning but suffer steep inference latency because self-attention scales quadratically with sequence length and thousands of visual tokens contributed by high-resolution images. Naively pruning less-informative visual tokens reduces this burden, yet indiscriminate removal can strip away contextual cues essential for background or fine-grained questions, undermining accuracy. In this paper, we present ParVTS (Parallel Vision Token Scheduling), a training-free scheduling framework that partitions visual tokens into subject and non-subject groups, processes them in parallel to transfer their semantics into question tokens, and discards the non-subject path mid-inference to reduce computation. This scheduling reduces computational complexity, requires no heuristics or additional modules, and is compatible with diverse existing MLLM architectures. Experiments across multiple MLLM backbones show that ParVTS prunes up to 88.9% of visual tokens with minimal performance drop, achieving 1.77x speedup and 70% FLOPs reduction.

