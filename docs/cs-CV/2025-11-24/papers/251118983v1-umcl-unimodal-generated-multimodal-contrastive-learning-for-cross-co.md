---
layout: default
title: UMCL: Unimodal-generated Multimodal Contrastive Learning for Cross-compression-rate Deepfake Detection
---

# UMCL: Unimodal-generated Multimodal Contrastive Learning for Cross-compression-rate Deepfake Detection

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.18983" target="_blank" class="toolbar-btn">arXiv: 2511.18983v1</a>
    <a href="https://arxiv.org/pdf/2511.18983.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.18983v1" 
            onclick="toggleFavorite(this, '2511.18983v1', 'UMCL: Unimodal-generated Multimodal Contrastive Learning for Cross-compression-rate Deepfake Detection')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Ching-Yi Lai, Chih-Yu Jian, Pei-Cheng Chuang, Chia-Ming Lee, Chih-Chung Hsu, Chiou-Ting Hsu, Chia-Wen Lin

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-24

**Â§áÊ≥®**: 24-page manuscript accepted to IJCV

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫UMCLÊ°ÜÊû∂ÔºåÈÄöËøáÂçïÊ®°ÊÄÅÁîüÊàêÂ§öÊ®°ÊÄÅÂØπÊØîÂ≠¶‰π†ÔºåËß£ÂÜ≥Ë∑®ÂéãÁº©ÁéáÊ∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµãÈöæÈ¢ò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ê∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµã` `Ë∑®ÂéãÁº©Áéá` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ÂØπÊØîÂ≠¶‰π†` `ÂçïÊ®°ÊÄÅÁîüÊàê` `‰∫≤ÂíåÂäõÂØπÈΩê` `ËßÜÈ¢ëÂéãÁº©`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂçïÊ®°ÊÄÅÊñπÊ≥ïÂú®Á§æ‰∫§Â™í‰ΩìÂéãÁº©‰∏ãÁâπÂæÅÈÄÄÂåñ‰∏•ÈáçÔºåÂ§öÊ®°ÊÄÅÊñπÊ≥ïÂàôÈù¢‰∏¥Êï∞ÊçÆÊî∂ÈõÜÊàêÊú¨È´òÊòÇÂíåÊ®°ÊÄÅË¥®Èáè‰∏ç‰∏ÄËá¥Á≠âÊåëÊàò„ÄÇ
2. UMCLÊ°ÜÊû∂Â∞ÜÂçïËßÜËßâÊ®°ÊÄÅËΩ¨Âåñ‰∏∫ÊäóÂéãÁº©ÁöÑrPPG‰ø°Âè∑„ÄÅÊó∂Èó¥Âú∞Ê†áÂä®ÊÄÅÂíåËØ≠‰πâÂµåÂÖ•ÔºåÂπ∂ÈÄöËøáÂØπÊØîÂ≠¶‰π†ÊòæÂºèÂØπÈΩêËøô‰∫õÁâπÂæÅ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåUMCLÂú®ÂêÑÁßçÂéãÁº©ÁéáÂíåÁØ°ÊîπÁ±ªÂûã‰∏ãÂùáË°®Áé∞Âá∫ÂçìË∂äÁöÑÊÄßËÉΩÔºåÂç≥‰ΩøÂçï‰∏™ÁâπÂæÅÈÄÄÂåñ‰πüËÉΩ‰øùÊåÅËæÉÈ´òÁöÑÊ£ÄÊµãÁ≤æÂ∫¶„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈíàÂØπÁ§æ‰∫§Â™í‰ΩìÂπ≥Âè∞ÂéãÁº©ÂØºËá¥Ê∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµãÊ®°ÂûãÊ≥õÂåñÊÄßÂíåÂèØÈù†ÊÄß‰∏ãÈôçÁöÑÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂçïÊ®°ÊÄÅÁîüÊàêÂ§öÊ®°ÊÄÅÂØπÊØîÂ≠¶‰π†ÔºàUMCLÔºâÊ°ÜÊû∂ÔºåÁî®‰∫éÈ≤ÅÊ£íÁöÑË∑®ÂéãÁº©ÁéáÔºàCCRÔºâÊ∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµã„ÄÇËØ•ÊñπÊ≥ïÂú®ËÆ≠ÁªÉÈò∂ÊÆµÂ∞ÜÂçïËßÜËßâÊ®°ÊÄÅËΩ¨Âåñ‰∏∫‰∏âÁßç‰∫íË°•ÁâπÂæÅÔºöÊäóÂéãÁº©ÁöÑrPPG‰ø°Âè∑„ÄÅÊó∂Èó¥Âú∞Ê†áÂä®ÊÄÅ‰ª•ÂèäÊù•Ëá™È¢ÑËÆ≠ÁªÉËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÁöÑËØ≠‰πâÂµåÂÖ•„ÄÇÈÄöËøá‰∫≤ÂíåÂäõÈ©±Âä®ÁöÑËØ≠‰πâÂØπÈΩêÔºàASAÔºâÁ≠ñÁï•ÊòæÂºèÂØπÈΩêËøô‰∫õÁâπÂæÅÔºåËØ•Á≠ñÁï•ÈÄöËøá‰∫≤ÂíåÂäõÁü©ÈòµÂª∫Ê®°Ê®°ÊÄÅÈó¥ÂÖ≥Á≥ªÔºåÂπ∂ÈÄöËøáÂØπÊØîÂ≠¶‰π†‰ºòÂåñÂÖ∂‰∏ÄËá¥ÊÄß„ÄÇÈöèÂêéÔºåË∑®Ë¥®ÈáèÁõ∏‰ººÊÄßÂ≠¶‰π†ÔºàCQSLÔºâÁ≠ñÁï•Â¢ûÂº∫‰∫ÜÁâπÂæÅÂú®‰∏çÂêåÂéãÁº©Áéá‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®ÂêÑÁßçÂéãÁº©ÁéáÂíåÁØ°ÊîπÁ±ªÂûã‰∏ãÂùáË°®Áé∞Âá∫ÂçìË∂äÁöÑÊÄßËÉΩÔºå‰∏∫È≤ÅÊ£íÁöÑÊ∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµãÂª∫Á´ã‰∫ÜÊñ∞ÁöÑÂü∫ÂáÜ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂç≥‰ΩøÂçï‰∏™ÁâπÂæÅÈÄÄÂåñÔºåËØ•ÊñπÊ≥ï‰πüËÉΩ‰øùÊåÅËæÉÈ´òÁöÑÊ£ÄÊµãÁ≤æÂ∫¶ÔºåÂêåÊó∂ÈÄöËøáÊòæÂºèÂØπÈΩêÊèê‰æõÂØπÁâπÂæÅÂÖ≥Á≥ªÁöÑÂèØËß£ÈáäÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊ∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµãÊñπÊ≥ïÂú®Èù¢ÂØπÁ§æ‰∫§Â™í‰ΩìÂπ≥Âè∞ÊôÆÈÅçÈááÁî®ÁöÑ‰∏çÂêåÂéãÁº©ÁéáÊó∂ÔºåÊ≥õÂåñËÉΩÂäõÊòæËëó‰∏ãÈôç„ÄÇÂçïÊ®°ÊÄÅÊñπÊ≥ïÂÆπÊòìÂèóÂà∞ÂéãÁº©‰º™ÂΩ±ÁöÑÂΩ±ÂìçÔºåÂØºËá¥ÁâπÂæÅË¥®Èáè‰∏ãÈôçÔºåËÄåÂ§öÊ®°ÊÄÅÊñπÊ≥ïÂàôÈúÄË¶ÅÂ§ßÈáèÊ†áÊ≥®Êï∞ÊçÆÔºå‰∏îÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Èöæ‰ª•‰øùËØÅÊâÄÊúâÊ®°ÊÄÅÁöÑË¥®ÈáèÂíåÂèØÁî®ÊÄß„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÂú®‰∏çÂêåÂéãÁº©Áéá‰∏ãÂÆûÁé∞È≤ÅÊ£í‰∏îÈ´òÊïàÁöÑÊ∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµãÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöUMCLÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØ‰ªéÂçï‰∏ÄÁöÑËßÜËßâÊ®°ÊÄÅÂá∫ÂèëÔºåÁîüÊàêÂ§ö‰∏™‰∫íË°•ÁöÑÊ®°ÊÄÅÁâπÂæÅÔºåÂπ∂ÈÄöËøáÂØπÊØîÂ≠¶‰π†ÁöÑÊñπÂºèÔºå‰ΩøËøô‰∫õÁâπÂæÅÂú®ËØ≠‰πâÁ©∫Èó¥‰∏≠ÂØπÈΩê„ÄÇËøôÊ†∑Âç≥‰ΩøÂéüÂßãËßÜËßâÊ®°ÊÄÅÂèóÂà∞ÂéãÁº©ÁöÑÂΩ±ÂìçÔºåÂÖ∂‰ªñÊ®°ÊÄÅÁâπÂæÅ‰ªçÁÑ∂ÂèØ‰ª•Êèê‰æõÊúâÊïàÁöÑ‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂêåÊó∂ÔºåÈÄöËøáË∑®Ë¥®ÈáèÁõ∏‰ººÊÄßÂ≠¶‰π†ÔºåËøõ‰∏ÄÊ≠•Â¢ûÂº∫Ê®°ÂûãÂú®‰∏çÂêåÂéãÁº©Áéá‰∏ãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöUMCLÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™Èò∂ÊÆµÔºöÁâπÂæÅÁîüÊàê‰∏éÂØπÈΩêÈò∂ÊÆµÂíåË∑®Ë¥®ÈáèÁõ∏‰ººÊÄßÂ≠¶‰π†Èò∂ÊÆµ„ÄÇÂú®ÁâπÂæÅÁîüÊàê‰∏éÂØπÈΩêÈò∂ÊÆµÔºåÈ¶ñÂÖà‰ªéËæìÂÖ•ÁöÑËßÜÈ¢ëÂ∏ß‰∏≠ÊèêÂèñ‰∏âÁßçÁâπÂæÅÔºörPPG‰ø°Âè∑„ÄÅÊó∂Èó¥Âú∞Ê†áÂä®ÊÄÅÂíåËØ≠‰πâÂµåÂÖ•„ÄÇÁÑ∂ÂêéÔºåÂà©Áî®‰∫≤ÂíåÂäõÈ©±Âä®ÁöÑËØ≠‰πâÂØπÈΩêÔºàASAÔºâÁ≠ñÁï•ÔºåÈÄöËøáÊûÑÂª∫‰∫≤ÂíåÂäõÁü©ÈòµÊù•Âª∫Ê®°Ê®°ÊÄÅÈó¥ÁöÑÂÖ≥Á≥ªÔºåÂπ∂‰ΩøÁî®ÂØπÊØîÂ≠¶‰π†Êù•‰ºòÂåñËøô‰∫õÂÖ≥Á≥ªÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂú®Ë∑®Ë¥®ÈáèÁõ∏‰ººÊÄßÂ≠¶‰π†Èò∂ÊÆµÔºåÈÄöËøáÂ≠¶‰π†‰∏çÂêåÂéãÁº©Áéá‰∏ãÁâπÂæÅÁöÑÁõ∏‰ººÊÄßÔºåÂ¢ûÂº∫Ê®°ÂûãÂØπÂéãÁº©‰º™ÂΩ±ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöUMCLÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂà©Áî®ÂçïÊ®°ÊÄÅÊï∞ÊçÆÁîüÊàêÂ§öÊ®°ÊÄÅÁâπÂæÅÔºåÂπ∂ÊòæÂºèÂú∞ÂØπÈΩêËøô‰∫õÁâπÂæÅ„ÄÇËøôÁßçÊñπÊ≥ïÈÅøÂÖç‰∫ÜÂ§öÊ®°ÊÄÅÊï∞ÊçÆÊî∂ÈõÜÁöÑÂõ∞ÈöæÔºåÂêåÊó∂Âà©Áî®‰∏çÂêåÁâπÂæÅÁöÑ‰∫íË°•ÊÄßÔºåÊèêÈ´ò‰∫ÜÊ®°ÂûãÂú®‰∏çÂêåÂéãÁº©Áéá‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºå‰∫≤ÂíåÂäõÈ©±Âä®ÁöÑËØ≠‰πâÂØπÈΩêÁ≠ñÁï•ËÉΩÂ§üÊúâÊïàÂú∞Âª∫Ê®°Ê®°ÊÄÅÈó¥ÁöÑÂÖ≥Á≥ªÔºåÂπ∂ÊèêÈ´òÁâπÂæÅÁöÑÂà§Âà´ËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÁâπÂæÅÊèêÂèñÊñπÈù¢ÔºårPPG‰ø°Âè∑ÊèêÂèñÈááÁî®È¢ÑËÆ≠ÁªÉÁöÑHRNetÊ®°ÂûãÔºåÊó∂Èó¥Âú∞Ê†áÂä®ÊÄÅÊèêÂèñÈááÁî®OpenPoseÔºåËØ≠‰πâÂµåÂÖ•ÊèêÂèñÈááÁî®CLIPÊ®°Âûã„ÄÇ‰∫≤ÂíåÂäõÁü©ÈòµÁöÑÊûÑÂª∫ÈááÁî®È´òÊñØÊ†∏ÂáΩÊï∞ÔºåÂØπÊØîÂ≠¶‰π†ÊçüÂ§±ÂáΩÊï∞ÈááÁî®InfoNCEÊçüÂ§±„ÄÇË∑®Ë¥®ÈáèÁõ∏‰ººÊÄßÂ≠¶‰π†ÈááÁî®Triplet LossÔºåÈÄöËøáÊúÄÂ∞èÂåñÁõ∏ÂêåËßÜÈ¢ëÂú®‰∏çÂêåÂéãÁº©Áéá‰∏ãÁöÑÁâπÂæÅË∑ùÁ¶ªÔºåÊúÄÂ§ßÂåñ‰∏çÂêåËßÜÈ¢ë‰πãÈó¥ÁöÑÁâπÂæÅË∑ùÁ¶ª„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåUMCLÂú®Ë∑®ÂéãÁº©ÁéáÊ∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµã‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºåÂú®ÁâπÂÆöÊï∞ÊçÆÈõÜ‰∏äÔºåUMCLÁöÑÊ£ÄÊµãÂáÜÁ°ÆÁéáÁõ∏ÊØîÁé∞ÊúâÊúÄ‰Ω≥ÊñπÊ≥ïÊèêÈ´ò‰∫Ü5%‰ª•‰∏ä„ÄÇÊ≠§Â§ñÔºåUMCLÂú®‰∏çÂêåÁ±ªÂûãÁöÑÊ∑±Â∫¶‰º™ÈÄ†ÊîªÂáª‰∏ãÂùáË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÈ≤ÅÊ£íÊÄßÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÊ∂àËûçÂÆûÈ™å‰πüÈ™åËØÅ‰∫ÜASAÂíåCQSLÁ≠ñÁï•ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

UMCLÊ°ÜÊû∂ÂèØÂ∫îÁî®‰∫éÁ§æ‰∫§Â™í‰ΩìÂπ≥Âè∞ÁöÑÂÜÖÂÆπÂÆ°Ê†∏ÔºåÊúâÊïàÊ£ÄÊµãÁªèËøáÂéãÁº©ÁöÑÊ∑±Â∫¶‰º™ÈÄ†ËßÜÈ¢ëÔºåÁª¥Êä§ÁΩëÁªú‰ø°ÊÅØÂÆâÂÖ®„ÄÇËØ•ÊäÄÊúØËøòÂèØÊâ©Â±ïÂà∞ÂÖ∂‰ªñÈúÄË¶ÅÂ§ÑÁêÜÂéãÁº©Êï∞ÊçÆÁöÑÂú∫ÊôØÔºåÂ¶ÇËßÜÈ¢ëÁõëÊéß„ÄÅËøúÁ®ãÂåªÁñóÁ≠âÔºåÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÂíåÂÆûÈôÖ‰ª∑ÂÄº„ÄÇÊú™Êù•ÔºåÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Á†îÁ©∂Â¶Ç‰ΩïÂ∞ÜUMCL‰∏éÂÖ∂‰ªñÈò≤Âæ°ÊäÄÊúØÁõ∏ÁªìÂêàÔºåÊûÑÂª∫Êõ¥Âº∫Â§ßÁöÑÊ∑±Â∫¶‰º™ÈÄ†Ê£ÄÊµãÁ≥ªÁªü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In deepfake detection, the varying degrees of compression employed by social media platforms pose significant challenges for model generalization and reliability. Although existing methods have progressed from single-modal to multimodal approaches, they face critical limitations: single-modal methods struggle with feature degradation under data compression in social media streaming, while multimodal approaches require expensive data collection and labeling and suffer from inconsistent modal quality or accessibility in real-world scenarios. To address these challenges, we propose a novel Unimodal-generated Multimodal Contrastive Learning (UMCL) framework for robust cross-compression-rate (CCR) deepfake detection. In the training stage, our approach transforms a single visual modality into three complementary features: compression-robust rPPG signals, temporal landmark dynamics, and semantic embeddings from pre-trained vision-language models. These features are explicitly aligned through an affinity-driven semantic alignment (ASA) strategy, which models inter-modal relationships through affinity matrices and optimizes their consistency through contrastive learning. Subsequently, our cross-quality similarity learning (CQSL) strategy enhances feature robustness across compression rates. Extensive experiments demonstrate that our method achieves superior performance across various compression rates and manipulation types, establishing a new benchmark for robust deepfake detection. Notably, our approach maintains high detection accuracy even when individual features degrade, while providing interpretable insights into feature relationships through explicit alignment.

