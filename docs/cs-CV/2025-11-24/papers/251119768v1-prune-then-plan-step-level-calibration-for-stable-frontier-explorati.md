---
layout: default
title: Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering
---

# Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.19768" target="_blank" class="toolbar-btn">arXiv: 2511.19768v1</a>
    <a href="https://arxiv.org/pdf/2511.19768.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.19768v1" 
            onclick="toggleFavorite(this, '2511.19768v1', 'Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Noah Frahm, Prakrut Patel, Yue Zhang, Shoubin Yu, Mohit Bansal, Roni Sengupta

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-24

**Â§áÊ≥®**: webpage: https://noahfrahm.github.io/Prune-Then-Plan-project-page/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Prune-Then-PlanÔºöÈÄöËøáÊ≠•Á∫ßÊ†°ÂáÜÂÆûÁé∞ÂÖ∑Ë∫´ÈóÆÁ≠î‰∏≠Á®≥ÂÆöÁöÑËæπÁïåÊé¢Á¥¢**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ÂÖ∑Ë∫´ÈóÆÁ≠î` `ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã` `Ê≠•Á∫ßÊ†°ÂáÜ` `ËæπÁïåÊé¢Á¥¢` `Êú∫Âô®‰∫∫ÂØºËà™`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂÖ∑Ë∫´ÈóÆÁ≠îÊô∫ËÉΩ‰ΩìÂú®Ê≠•Á∫ßÊé¢Á¥¢‰∏≠ÔºåËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂ∏∏Âõ†ËøáÂ∫¶Ëá™‰ø°ÂíåÈîôËØØÊ†°ÂáÜÂØºËá¥‰∏çÁ®≥ÂÆöÁßªÂä®„ÄÇ
2. Prune-Then-PlanÊ°ÜÊû∂ÈÄöËøáÂâ™Êûù‰∏çÂêàÁêÜÁöÑËæπÁïåÈÄâÊã©ÔºåÂπ∂Â∞ÜÂÜ≥Á≠ñÂßîÊâòÁªôÂü∫‰∫éË¶ÜÁõñÁéáÁöÑËßÑÂàíÂô®Êù•Á®≥ÂÆöÊé¢Á¥¢„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®ËßÜËßâÊé•Âú∞ÁöÑSPLÂíåLLM-MatchÊåáÊ†á‰∏äÂàÜÂà´ÂÆûÁé∞‰∫ÜÊòæËëóÊèêÂçáÔºåÂπ∂ÊèêÈ´ò‰∫ÜÂú∫ÊôØË¶ÜÁõñÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã(VLMs)ÈÄöËøá‰∏∫ÂºÄÊîæËØçÊ±áÊé®ÁêÜÊèê‰æõÂº∫Â§ßÁöÑËØ≠‰πâÂÖàÈ™åÔºåÊîπËøõ‰∫ÜÂÖ∑Ë∫´ÈóÆÁ≠î(EQA)Êô∫ËÉΩ‰Ωì„ÄÇÁÑ∂ËÄåÔºåÂΩìÁõ¥Êé•Áî®‰∫éÊ≠•Á∫ßÊé¢Á¥¢Êó∂ÔºåVLMsÂ∏∏Â∏∏Ë°®Áé∞Âá∫ËæπÁïåÊåØËç°ÔºåÂç≥Áî±ËøáÂ∫¶Ëá™‰ø°ÂíåÈîôËØØÊ†°ÂáÜÂØºËá¥ÁöÑ‰∏çÁ®≥ÂÆöÁöÑÊù•ÂõûÁßªÂä®Ôºå‰ªéËÄåÂØºËá¥‰ΩéÊïàÁöÑÂØºËà™ÂíåÈôç‰ΩéÁöÑÁ≠îÊ°àË¥®Èáè„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜPrune-Then-PlanÔºå‰∏Ä‰∏™ÁÆÄÂçïËÄåÊúâÊïàÁöÑÊ°ÜÊû∂ÔºåÈÄöËøáÊ≠•Á∫ßÊ†°ÂáÜÊù•Á®≥ÂÆöÊé¢Á¥¢„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ï‰∏ç‰ø°‰ªªÂéüÂßãVLMÂàÜÊï∞ÔºåËÄåÊòØ‰ΩøÁî®ÂèóHolm-BonferroniÂêØÂèëÁöÑÂâ™ÊûùÁ®ãÂ∫èÊù•Ââ™Èô§‰∏çÂêàÁêÜÁöÑËæπÁïåÈÄâÊã©ÔºåÁÑ∂ÂêéÂ∞ÜÊúÄÁªàÂÜ≥Á≠ñÂßîÊâòÁªôÂü∫‰∫éË¶ÜÁõñÁéáÁöÑËßÑÂàíÂô®„ÄÇËøôÁßçÂàÜÁ¶ªÈÄöËøá‰æùËµñ‰∫∫Á±ªÊ∞¥Âπ≥ÁöÑÂà§Êñ≠Êù•Ê†°ÂáÜVLMsÁöÑÊ≠•Á∫ßË°å‰∏∫ÔºåÂ∞ÜËøáÂ∫¶Ëá™‰ø°ÁöÑÈ¢ÑÊµãËΩ¨Âåñ‰∏∫‰øùÂÆàÁöÑ„ÄÅÂèØËß£ÈáäÁöÑË°åÂä®„ÄÇÈõÜÊàêÂà∞3D-Mem EQAÊ°ÜÊû∂‰∏≠ÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ËßÜËßâÊé•Âú∞ÁöÑSPLÂíåLLM-MatchÊåáÊ†á‰∏äÂàÜÂà´ÂÆûÁé∞‰∫ÜÈ´òËææ49%Âíå33%ÁöÑÁõ∏ÂØπÊîπËøõ„ÄÇÊÄªÁöÑÊù•ËØ¥ÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®OpenEQAÂíåEXPRESS-BenchÊï∞ÊçÆÈõÜ‰∏äÔºåÂú®Áõ∏ÂêåÁöÑÊé¢Á¥¢È¢ÑÁÆó‰∏ãÂÆûÁé∞‰∫ÜÊõ¥Â•ΩÁöÑÂú∫ÊôØË¶ÜÁõñ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂÖ∑Ë∫´ÈóÆÁ≠îÔºàEQAÔºâÊô∫ËÉΩ‰ΩìÂú®ËøõË°åÊ≠•Á∫ßÊé¢Á¥¢Êó∂ÔºåÁõ¥Êé•‰ΩøÁî®ËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâÁöÑÂéüÂßãÈ¢ÑÊµãÂàÜÊï∞ÔºåÂÆπÊòìÂèóÂà∞VLMËøáÂ∫¶Ëá™‰ø°ÂíåÈîôËØØÊ†°ÂáÜÁöÑÂΩ±ÂìçÔºåÂØºËá¥Êô∫ËÉΩ‰ΩìÂú®Êé¢Á¥¢ËøáÁ®ã‰∏≠Âá∫Áé∞‰∏çÁ®≥ÂÆöÁöÑÊù•ÂõûÁßªÂä®ÔºàËæπÁïåÊåØËç°ÔºâÔºåÈôç‰Ωé‰∫ÜÂØºËà™ÊïàÁéáÂíåÁ≠îÊ°àË¥®Èáè„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶Å‰∏ÄÁßçÊñπÊ≥ïÊù•Ê†°ÂáÜVLMÁöÑÊ≠•Á∫ßË°å‰∏∫Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Á®≥ÂÆöÂú∞ËøõË°åÊé¢Á¥¢„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜVLMÁöÑÈ¢ÑÊµãÁªìÊûúËøõË°åÊ†°ÂáÜÔºå‰ΩøÂÖ∂Êõ¥Âä†‰øùÂÆàÂíåÂèØ‰ø°„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈ¶ñÂÖà‰ΩøÁî®Ââ™ÊûùÁ≠ñÁï•ÂéªÈô§VLMÈ¢ÑÊµã‰∏≠‰∏çÂêàÁêÜÁöÑÈÄâÈ°πÔºåÁÑ∂ÂêéÂ∞ÜÊúÄÁªàÂÜ≥Á≠ñ‰∫§Áªô‰∏Ä‰∏™Âü∫‰∫éË¶ÜÁõñÁéáÁöÑËßÑÂàíÂô®„ÄÇËøôÁßç‚ÄúÂÖàÂâ™ÊûùÔºåÂêéËßÑÂàí‚ÄùÁöÑÁ≠ñÁï•ËÉΩÂ§üÊúâÊïàÂú∞ÊäëÂà∂VLMÁöÑËøáÂ∫¶Ëá™‰ø°ÔºåÂπ∂Âà©Áî®ËßÑÂàíÂô®Êù•‰øùËØÅÊé¢Á¥¢ÁöÑÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPrune-Then-PlanÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™Èò∂ÊÆµÔºöÂâ™ÊûùÈò∂ÊÆµÂíåËßÑÂàíÈò∂ÊÆµ„ÄÇÂú®Ââ™ÊûùÈò∂ÊÆµÔºå‰ΩøÁî®ÂèóHolm-BonferroniÂêØÂèëÁöÑÂâ™ÊûùÁ®ãÂ∫èÔºåÊ†πÊçÆVLMÁöÑÈ¢ÑÊµãÂàÜÊï∞ÔºåÂéªÈô§ÈÇ£‰∫õÁΩÆ‰ø°Â∫¶ËæÉ‰ΩéÊàñËÄÖ‰∏çÂêàÁêÜÁöÑËæπÁïåÈÄâÊã©„ÄÇÂú®ËßÑÂàíÈò∂ÊÆµÔºå‰ΩøÁî®‰∏Ä‰∏™Âü∫‰∫éË¶ÜÁõñÁéáÁöÑËßÑÂàíÂô®ÔºåÊ†πÊçÆÂâ©‰ΩôÁöÑËæπÁïåÈÄâÊã©ÔºåÈÄâÊã©ËÉΩÂ§üÊúÄÂ§ßÂåñÂú∫ÊôØË¶ÜÁõñÁéáÁöÑË°åÂä®„ÄÇÊï¥‰∏™Ê°ÜÊû∂ÈõÜÊàêÂà∞3D-Mem EQAÊ°ÜÊû∂‰∏≠„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÁÆÄÂçïËÄåÊúâÊïàÁöÑÊ≠•Á∫ßÊ†°ÂáÜÊ°ÜÊû∂ÔºåÈÄöËøáÂâ™ÊûùÂíåËßÑÂàíÁõ∏ÁªìÂêàÁöÑÊñπÂºèÔºåÊúâÊïàÂú∞Ëß£ÂÜ≥‰∫ÜVLMÂú®Ê≠•Á∫ßÊé¢Á¥¢‰∏≠ËøáÂ∫¶Ëá™‰ø°ÂíåÈîôËØØÊ†°ÂáÜÁöÑÈóÆÈ¢ò„ÄÇ‰∏éÁõ¥Êé•‰ΩøÁî®VLMÁöÑÂéüÂßãÈ¢ÑÊµãÂàÜÊï∞Áõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÁîüÊàêÊõ¥‰øùÂÆà„ÄÅÊõ¥ÂèØËß£ÈáäÁöÑË°åÂä®Ôºå‰ªéËÄåÊèêÈ´òÊé¢Á¥¢ÁöÑÁ®≥ÂÆöÊÄßÂíåÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂâ™ÊûùÈò∂ÊÆµÁöÑÂÖ≥ÈîÆÂú®‰∫éHolm-Bonferroni inspired pruning procedureÔºåÂÆÉÊ†πÊçÆVLMÁªôÂá∫ÁöÑÊØè‰∏™frontierÁöÑÁΩÆ‰ø°Â∫¶ÊâìÂàÜÔºåËøõË°åÊéíÂ∫èÔºåÁÑ∂Âêé‰æùÊ¨°ËøõË°åÂÅáËÆæÊ£ÄÈ™åÔºåÂ¶ÇÊûúÊüê‰∏™frontierÁöÑÁΩÆ‰ø°Â∫¶Ëøá‰ΩéÔºåÂàôÂ∞ÜÂÖ∂Ââ™Èô§„ÄÇËßÑÂàíÈò∂ÊÆµÁöÑÂÖ≥ÈîÆÂú®‰∫écoverage-based plannerÔºåÂÆÉÊ†πÊçÆÂâ©‰ΩôÁöÑfrontierÔºåÈÄâÊã©ËÉΩÂ§üÊúÄÂ§ßÂåñÂú∫ÊôØË¶ÜÁõñÁéáÁöÑË°åÂä®„ÄÇÂÖ∑‰ΩìÂÆûÁé∞‰∏≠Ôºå‰ΩøÁî®‰∫Ü3D-Mem EQAÊ°ÜÊû∂‰Ωú‰∏∫Âü∫Á°ÄÔºåÂπ∂ÂØπÂÖ∂‰∏≠ÁöÑÊé¢Á¥¢Á≠ñÁï•ËøõË°å‰∫ÜÊîπËøõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPrune-Then-PlanÊ°ÜÊû∂Âú®OpenEQAÂíåEXPRESS-BenchÊï∞ÊçÆÈõÜ‰∏äÔºåÂú®ËßÜËßâÊé•Âú∞ÁöÑSPLÊåáÊ†á‰∏äÂàÜÂà´ÂÆûÁé∞‰∫ÜÈ´òËææ49%ÁöÑÁõ∏ÂØπÊîπËøõÔºåÂú®LLM-MatchÊåáÊ†á‰∏äÂÆûÁé∞‰∫Ü33%ÁöÑÁõ∏ÂØπÊîπËøõ„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÂú®Áõ∏ÂêåÁöÑÊé¢Á¥¢È¢ÑÁÆó‰∏ãÔºåÂÆûÁé∞‰∫ÜÊõ¥Â•ΩÁöÑÂú∫ÊôØË¶ÜÁõñÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÊèêÈ´òÊé¢Á¥¢ÊïàÁéáÂíåÁ®≥ÂÆöÊÄßÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊ†°ÂáÜËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ≠•Á∫ßË°å‰∏∫ÔºåÂèØ‰ª•ÊèêÈ´òÊô∫ËÉΩ‰ΩìÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊé¢Á¥¢ÊïàÁéáÂíåÁ®≥ÂÆöÊÄßÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÂÆåÊàêÂêÑÁßç‰ªªÂä°Ôºå‰æãÂ¶ÇÊêúÁ¥¢ÁâπÂÆöÁâ©‰Ωì„ÄÅÂõûÁ≠îÈóÆÈ¢òÁ≠â„ÄÇËØ•ÊñπÊ≥ïÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÊúâÊúõÊé®Âä®Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large vision-language models (VLMs) have improved embodied question answering (EQA) agents by providing strong semantic priors for open-vocabulary reasoning. However, when used directly for step-level exploration, VLMs often exhibit frontier oscillations, unstable back-and-forth movements caused by overconfidence and miscalibration, leading to inefficient navigation and degraded answer quality. We propose Prune-Then-Plan, a simple and effective framework that stabilizes exploration through step-level calibration. Instead of trusting raw VLM scores, our method prunes implausible frontier choices using a Holm-Bonferroni inspired pruning procedure and then delegates final decisions to a coverage-based planner. This separation converts overconfident predictions into conservative, interpretable actions by relying on human-level judgments to calibrate the step-level behavior of VLMs. Integrated into the 3D-Mem EQA framework, our approach achieves relative improvements of up to 49% and 33% in visually grounded SPL and LLM-Match metrics respectively over baselines. Overall, our method achieves better scene coverage under equal exploration budgets on both OpenEQA and EXPRESS-Bench datasets.

