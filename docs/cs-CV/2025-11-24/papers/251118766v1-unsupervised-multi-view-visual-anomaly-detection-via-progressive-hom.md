---
layout: default
title: Unsupervised Multi-View Visual Anomaly Detection via Progressive Homography-Guided Alignment
---

# Unsupervised Multi-View Visual Anomaly Detection via Progressive Homography-Guided Alignment

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.18766" target="_blank" class="toolbar-btn">arXiv: 2511.18766v1</a>
    <a href="https://arxiv.org/pdf/2511.18766.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.18766v1" 
            onclick="toggleFavorite(this, '2511.18766v1', 'Unsupervised Multi-View Visual Anomaly Detection via Progressive Homography-Guided Alignment')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xintao Chen, Xiaohao Xu, Bozhong Zheng, Yun Liu, Yingna Wu

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-24

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ViewSense-ADÔºåÈÄöËøáÂêåÊûÑÂèòÊç¢ÂºïÂØºÂØπÈΩêÂÆûÁé∞Êó†ÁõëÁù£Â§öËßÜËßíÂºÇÂ∏∏Ê£ÄÊµã„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÉÔºöÂä®‰ΩúÈáçÂÆöÂêë (Motion Retargeting)**

**ÂÖ≥ÈîÆËØç**: `Â§öËßÜËßíÂ≠¶‰π†` `ÂºÇÂ∏∏Ê£ÄÊµã` `ÂêåÊûÑÂèòÊç¢` `Êâ©Êï£Ê®°Âûã` `Êó†ÁõëÁù£Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂçïËßÜËßíÂºÇÂ∏∏Ê£ÄÊµãÊñπÊ≥ïÊó†Ê≥ïÊúâÊïàÂ§ÑÁêÜÂ§öËßÜËßíÂõæÂÉè‰∏≠Âõ†ËßÜËßíÂèòÂåñ‰∫ßÁîüÁöÑË°®ËßÇÂ∑ÆÂºÇÔºåÂØºËá¥È´òËØØÊä•Áéá„ÄÇ
2. ViewSense-ADÈÄöËøáÂ§öËßÜËßíÂØπÈΩêÊ®°Âùó(MVAM)ÂíåËßÜËßíÂØπÈΩêÊΩúÂú®Êâ©Êï£Ê®°Âûã(VALDM)ÊòæÂºèÂª∫Ê®°Ë∑®ËßÜËßíÁöÑÂá†‰Ωï‰∏ÄËá¥ÊÄßÔºåÂ≠¶‰π†ËßÜËßí‰∏çÂèòÁâπÂæÅ„ÄÇ
3. Âú®RealIADÂíåMANTAÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåVSADÂú®ÂÉèÁ¥†„ÄÅËßÜËßíÂíåÊ†∑Êú¨Á∫ßÂà´ÁöÑÂºÇÂ∏∏Ê£ÄÊµã‰∏≠ÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊó†ÁõëÁù£Â§öËßÜËßíËßÜËßâÂºÇÂ∏∏Ê£ÄÊµãÊ°ÜÊû∂ViewSense-AD (VSAD)ÔºåÊó®Âú®Ëß£ÂÜ≥ËßÜËßíÂèòÂåñÂºïËµ∑ÁöÑËâØÊÄßÂ§ñËßÇÂ∑ÆÂºÇ‰∏éÁúüÂÆûÁº∫Èô∑Èöæ‰ª•Âå∫ÂàÜÁöÑÈóÆÈ¢ò„ÄÇVSADÈÄöËøáÊòæÂºèÂª∫Ê®°Ë∑®ËßÜËßíÁöÑÂá†‰Ωï‰∏ÄËá¥ÊÄßÊù•Â≠¶‰π†ËßÜËßí‰∏çÂèòÁöÑÁâπÂæÅË°®Á§∫„ÄÇÂÖ∂Ê†∏ÂøÉÊòØÂ§öËßÜËßíÂØπÈΩêÊ®°Âùó(MVAM)ÔºåËØ•Ê®°ÂùóÂà©Áî®ÂêåÊûÑÂèòÊç¢Êù•ÊäïÂΩ±ÂíåÂØπÈΩêÁõ∏ÈÇªËßÜËßí‰πãÈó¥ÁöÑÂØπÂ∫îÁâπÂæÅÂå∫Âüü„ÄÇMVAMË¢´ÈõÜÊàêÂà∞ËßÜËßíÂØπÈΩêÊΩúÂú®Êâ©Êï£Ê®°Âûã(VALDM)‰∏≠Ôºå‰ªéËÄåÂú®ÂéªÂô™ËøáÁ®ã‰∏≠ÂÆûÁé∞Ê∏êËøõÂºèÂ§öÈò∂ÊÆµÂØπÈΩêÔºå‰ΩøÊ®°ÂûãËÉΩÂ§ü‰ªéÁ≤óÂà∞ÁªÜÂú∞ÊûÑÂª∫ÂØπÁâ©‰ΩìË°®Èù¢ÁöÑËøûË¥ØÂíåÊï¥‰ΩìÁêÜËß£„ÄÇÊ≠§Â§ñÔºåËΩªÈáèÁ∫ßÁöÑËûçÂêàÁªÜÂåñÊ®°Âùó(FRM)Â¢ûÂº∫‰∫ÜÂØπÈΩêÁâπÂæÅÁöÑÂÖ®Â±Ä‰∏ÄËá¥ÊÄßÔºåÊäëÂà∂Âô™Â£∞Âπ∂ÊèêÈ´òÂà§Âà´ËÉΩÂäõ„ÄÇÈÄöËøáÊØîËæÉÊâ©Êï£Ê®°ÂûãÁöÑÂ§öÂ±ÇÊ¨°ÁâπÂæÅ‰∏éÂ≠¶‰π†Âà∞ÁöÑÊ≠£Â∏∏ÂéüÂûãËÆ∞ÂøÜÂ∫ìÊù•ËøõË°åÂºÇÂ∏∏Ê£ÄÊµã„ÄÇÂú®RealIADÂíåMANTAÊï∞ÊçÆÈõÜ‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåVSADËææÂà∞‰∫ÜÊñ∞ÁöÑstate-of-the-artÔºåÂú®ÂÉèÁ¥†„ÄÅËßÜËßíÂíåÊ†∑Êú¨Á∫ßÂà´ÁöÑËßÜËßâÂºÇÂ∏∏Ê£ÄÊµãÊñπÈù¢ÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåËØÅÊòé‰∫ÜÂÖ∂ÂØπÂ§ßËßÜËßíÂèòÂåñÂíåÂ§çÊùÇÁ∫πÁêÜÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Êó†ÁõëÁù£Â§öËßÜËßíËßÜËßâÂºÇÂ∏∏Ê£ÄÊµãÈóÆÈ¢òÔºåÂç≥Â¶Ç‰ΩïÂå∫ÂàÜÁî±‰∫éËßÜËßíÂèòÂåñÂºïËµ∑ÁöÑÊ≠£Â∏∏Â§ñËßÇÂèòÂåñÂíåÁúüÊ≠£ÁöÑÁº∫Èô∑„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Â∞ÜÂ§öËßÜËßíÂõæÂÉèËßÜ‰∏∫‰∏ÄÁªÑ‰∏çÁõ∏ÂÖ≥ÁöÑÂõæÂÉèÔºåÂøΩÁï•‰∫ÜËßÜËßí‰πãÈó¥ÁöÑÂá†‰ΩïÂÖ≥Á≥ªÔºåÂØºËá¥ÁâπÂæÅË°®Á§∫‰∏ç‰∏ÄËá¥Ôºå‰ªéËÄå‰∫ßÁîüËæÉÈ´òÁöÑËØØÊä•Áéá„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ËßÜËßíÈó¥ÁöÑÂá†‰Ωï‰∏ÄËá¥ÊÄßÊù•Â≠¶‰π†ËßÜËßí‰∏çÂèòÁöÑÁâπÂæÅË°®Á§∫„ÄÇÈÄöËøáÊòæÂºèÂú∞Âª∫Ê®°ÂíåÂØπÈΩê‰∏çÂêåËßÜËßí‰∏ãÁöÑÁâπÂæÅÔºåÂèØ‰ª•Ê∂àÈô§ËßÜËßíÂèòÂåñÂ∏¶Êù•ÁöÑÂΩ±ÂìçÔºå‰ªéËÄåÊõ¥ÂáÜÁ°ÆÂú∞Ê£ÄÊµãÂá∫ÁúüÊ≠£ÁöÑÂºÇÂ∏∏„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVSADÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏â‰∏™Ê®°ÂùóÔºöÂ§öËßÜËßíÂØπÈΩêÊ®°Âùó(MVAM)„ÄÅËßÜËßíÂØπÈΩêÊΩúÂú®Êâ©Êï£Ê®°Âûã(VALDM)ÂíåËûçÂêàÁªÜÂåñÊ®°Âùó(FRM)„ÄÇMVAMË¥üË¥£Âà©Áî®ÂêåÊûÑÂèòÊç¢ÂØπÈΩêÁõ∏ÈÇªËßÜËßíÁöÑÁâπÂæÅÔºõVALDMÂ∞ÜMVAMÈõÜÊàêÂà∞Êâ©Êï£Ê®°Âûã‰∏≠ÔºåÂÆûÁé∞Ê∏êËøõÂºèÁöÑÂ§öÈò∂ÊÆµÂØπÈΩêÔºõFRMÁî®‰∫éÂ¢ûÂº∫ÂØπÈΩêÁâπÂæÅÁöÑÂÖ®Â±Ä‰∏ÄËá¥ÊÄßÔºåÊäëÂà∂Âô™Â£∞„ÄÇÂºÇÂ∏∏Ê£ÄÊµãÈÄöËøáÊØîËæÉÊâ©Êï£Ê®°ÂûãÁöÑÂ§öÂ±ÇÊ¨°ÁâπÂæÅ‰∏éÊ≠£Â∏∏ÂéüÂûãËÆ∞ÂøÜÂ∫ìËøõË°å„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜMVAMÂíåVALDMÔºåÂ∞ÜÂêåÊûÑÂèòÊç¢ÂíåÊâ©Êï£Ê®°ÂûãÁõ∏ÁªìÂêàÔºåÂÆûÁé∞‰∫ÜÂ§öËßÜËßíÁâπÂæÅÁöÑÂØπÈΩêÂíåËûçÂêà„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞Ê∂àÈô§ËßÜËßíÂèòÂåñÁöÑÂΩ±ÂìçÔºåÂπ∂Â≠¶‰π†Âà∞Êõ¥Âä†È≤ÅÊ£íÁöÑÁâπÂæÅË°®Á§∫„ÄÇÊ≠§Â§ñÔºåFRMÊ®°ÂùóËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÁâπÂæÅÁöÑÂÖ®Â±Ä‰∏ÄËá¥ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöMVAM‰ΩøÁî®Ê∑±Â∫¶Â≠¶‰π†ÊñπÊ≥ï‰º∞ËÆ°Áõ∏ÈÇªËßÜËßí‰πãÈó¥ÁöÑÂêåÊûÑÁü©ÈòµÔºåÂπ∂Âà©Áî®ËØ•Áü©ÈòµÂØπÁâπÂæÅËøõË°åÂèòÊç¢ÂíåÂØπÈΩê„ÄÇVALDMÂú®Êâ©Êï£Ê®°ÂûãÁöÑÂéªÂô™ËøáÁ®ã‰∏≠ÈÄêÊ≠•ËøõË°åÁâπÂæÅÂØπÈΩêÔºå‰ªéËÄåÂÆûÁé∞‰ªéÁ≤óÂà∞ÁªÜÁöÑÂØπÈΩêÊïàÊûú„ÄÇFRMÈááÁî®ËΩªÈáèÁ∫ßÁöÑÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÁªìÊûÑÔºå‰ª•ÂáèÂ∞ëËÆ°ÁÆóÈáè„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÈáçÊûÑÊçüÂ§±„ÄÅÂØπÈΩêÊçüÂ§±ÂíåÂØπÊäóÊçüÂ§±Á≠âÔºåÁî®‰∫éËÆ≠ÁªÉÊ®°ÂûãÁöÑÂêÑ‰∏™Ê®°Âùó„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

VSADÂú®RealIADÂíåMANTAÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂú®ÂÉèÁ¥†Á∫ßÂà´„ÄÅËßÜËßíÁ∫ßÂà´ÂíåÊ†∑Êú¨Á∫ßÂà´ÁöÑÂºÇÂ∏∏Ê£ÄÊµã‰∏≠Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ‰æãÂ¶ÇÔºåÂú®RealIADÊï∞ÊçÆÈõÜ‰∏äÔºåVSADÁöÑF1-scoreÊØîÁé∞ÊúâÊúÄ‰Ω≥ÊñπÊ≥ïÊèêÈ´ò‰∫Ü5%‰ª•‰∏äÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®Â§çÊùÇÂú∫ÊôØ‰∏ãÁöÑÈ≤ÅÊ£íÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂ∑•‰∏öË¥®Ê£Ä„ÄÅÂÆâÈò≤ÁõëÊéß„ÄÅÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÊûêÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Â∑•‰∏öË¥®Ê£Ä‰∏≠ÔºåÂèØ‰ª•Âà©Áî®Â§öËßÜËßíÂõæÂÉèÊ£ÄÊµã‰∫ßÂìÅË°®Èù¢ÁöÑÁº∫Èô∑ÔºåÊèêÈ´òÊ£ÄÊµãÁ≤æÂ∫¶ÂíåÊïàÁéá„ÄÇÂú®ÂÆâÈò≤ÁõëÊéß‰∏≠ÔºåÂèØ‰ª•Âà©Áî®Â§öÊëÑÂÉèÂ§¥ÊçïÊçâÁöÑÂõæÂÉèËøõË°åÂºÇÂ∏∏Ë°å‰∏∫Ê£ÄÊµãÔºåÊèêÂçáÂÆâÂÖ®Èò≤ËåÉËÉΩÂäõ„ÄÇÂú®ÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÊûê‰∏≠ÔºåÂèØ‰ª•Âà©Áî®Â§öËßÜËßíÂåªÂ≠¶ÂõæÂÉèËæÖÂä©ÂåªÁîüËØäÊñ≠ÁñæÁóÖ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Unsupervised visual anomaly detection from multi-view images presents a significant challenge: distinguishing genuine defects from benign appearance variations caused by viewpoint changes. Existing methods, often designed for single-view inputs, treat multiple views as a disconnected set of images, leading to inconsistent feature representations and a high false-positive rate. To address this, we introduce ViewSense-AD (VSAD), a novel framework that learns viewpoint-invariant representations by explicitly modeling geometric consistency across views. At its core is our Multi-View Alignment Module (MVAM), which leverages homography to project and align corresponding feature regions between neighboring views. We integrate MVAM into a View-Align Latent Diffusion Model (VALDM), enabling progressive and multi-stage alignment during the denoising process. This allows the model to build a coherent and holistic understanding of the object's surface from coarse to fine scales. Furthermore, a lightweight Fusion Refiner Module (FRM) enhances the global consistency of the aligned features, suppressing noise and improving discriminative power. Anomaly detection is performed by comparing multi-level features from the diffusion model against a learned memory bank of normal prototypes. Extensive experiments on the challenging RealIAD and MANTA datasets demonstrate that VSAD sets a new state-of-the-art, significantly outperforming existing methods in pixel, view, and sample-level visual anomaly proving its robustness to large viewpoint shifts and complex textures.

