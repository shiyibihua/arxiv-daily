---
layout: default
title: Growing with the Generator: Self-paced GRPO for Video Generation
---

# Growing with the Generator: Self-paced GRPO for Video Generation

**arXiv**: [2511.19356v1](https://arxiv.org/abs/2511.19356) | [PDF](https://arxiv.org/pdf/2511.19356.pdf)

**ä½œè€…**: Rui Li, Yuanzhi Liang, Ziqi Ni, Haibing Huang, Chi Zhang, Xuelong Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªæ­¥GRPOä»¥è§£å†³è§†é¢‘ç”Ÿæˆä¸­é™æ€å¥–åŠ±æ¨¡åž‹å¯¼è‡´çš„åˆ†å¸ƒåå·®å’Œä¼˜åŒ–ä¸ç¨³å®šé—®é¢˜**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `å¼ºåŒ–å­¦ä¹ ` `å¥–åŠ±æ¨¡åž‹` `ç­–ç•¥ä¼˜åŒ–` `è‡ªæ­¥å­¦ä¹ ` `è¯­ä¹‰å¯¹é½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé™æ€å¥–åŠ±æ¨¡åž‹åœ¨è®­ç»ƒä¸­è¡Œä¸ºå›ºå®šï¼Œå¯¼è‡´åˆ†å¸ƒåå·®ã€å¥–åŠ±é¥±å’Œå’Œä¼˜åŒ–ä¸ç¨³å®š
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥æ¸è¿›å¥–åŠ±æœºåˆ¶ï¼Œéšç”Ÿæˆè´¨é‡æå‡ä»Žè§†è§‰ä¿çœŸåº¦è½¬å‘æ—¶é—´ä¸€è‡´æ€§å’Œè¯­ä¹‰å¯¹é½
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨VBenchä¸ŠéªŒè¯ï¼Œç›¸æ¯”é™æ€å¥–åŠ±GRPOï¼Œè§†è§‰è´¨é‡å’Œè¯­ä¹‰å¯¹é½å‡æå‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Group Relative Policy Optimization (GRPO) has emerged as a powerful reinforcement learning paradigm for post-training video generation models. However, existing GRPO pipelines rely on static, fixed-capacity reward models whose evaluation behavior is frozen during training. Such rigid rewards introduce distributional bias, saturate quickly as the generator improves, and ultimately limit the stability and effectiveness of reinforcement-based alignment. We propose Self-Paced GRPO, a competence-aware GRPO framework in which reward feedback co-evolves with the generator. Our method introduces a progressive reward mechanism that automatically shifts its emphasis from coarse visual fidelity to temporal coherence and fine-grained text-video semantic alignment as generation quality increases. This self-paced curriculum alleviates reward-policy mismatch, mitigates reward exploitation, and yields more stable optimization. Experiments on VBench across multiple video generation backbones demonstrate consistent improvements in both visual quality and semantic alignment over GRPO baselines with static rewards, validating the effectiveness and generality of Self-Paced GRPO.

