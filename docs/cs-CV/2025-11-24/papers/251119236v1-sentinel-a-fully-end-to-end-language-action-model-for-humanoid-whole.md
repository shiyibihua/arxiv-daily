---
layout: default
title: SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control
---

# SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control

**arXiv**: [2511.19236v1](https://arxiv.org/abs/2511.19236) | [PDF](https://arxiv.org/pdf/2511.19236.pdf)

**ä½œè€…**: Yuxuan Wang, Haobin Jiang, Shiqing Yao, Ziluo Ding, Zongqing Lu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSENTINELç«¯åˆ°ç«¯è¯­è¨€-åŠ¨ä½œæ¨¡åž‹ä»¥è§£å†³äººå½¢æœºå™¨äººå…¨èº«æŽ§åˆ¶ä¸­è¯­è¨€ä¸Žè¡Œä¸ºå¯¹é½é—®é¢˜**

**å…³é”®è¯**: `äººå½¢æœºå™¨äººæŽ§åˆ¶` `ç«¯åˆ°ç«¯å­¦ä¹ ` `è¯­è¨€-åŠ¨ä½œæ˜ å°„` `æµåŒ¹é…` `å…¨èº«æŽ§åˆ¶` `å¤šæ¨¡æ€æ‰©å±•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰ç³»ç»Ÿä¾èµ–é¥æ“ä½œæˆ–æ¨¡å—åŒ–ç®¡é“ï¼Œå¯¼è‡´è¯­è¨€ç†è§£ä¸Žç‰©ç†æ‰§è¡Œåˆ†ç¦»
2. æ¨¡åž‹ç›´æŽ¥æ˜ å°„è¯­è¨€å‘½ä»¤å’Œæœ¬ä½“æ„Ÿè§‰è¾“å…¥åˆ°ä½Žçº§åŠ¨ä½œï¼Œä½¿ç”¨æµåŒ¹é…ç”ŸæˆåŠ¨ä½œå—
3. åœ¨ä»¿çœŸå’ŒçœŸå®žéƒ¨ç½²ä¸­å±•ç¤ºå¼ºè¯­ä¹‰ç†è§£å’Œç¨³å®šæ‰§è¡Œï¼Œæ”¯æŒå¤šæ¨¡æ€æ‰©å±•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Existing humanoid control systems often rely on teleoperation or modular generation pipelines that separate language understanding from physical execution. However, the former is entirely human-driven, and the latter lacks tight alignment between language commands and physical behaviors. In this paper, we present SENTINEL, a fully end-to-end language-action model for humanoid whole-body control. We construct a large-scale dataset by tracking human motions in simulation using a pretrained whole body controller, combined with their text annotations. The model directly maps language commands and proprioceptive inputs to low-level actions without any intermediate representation. The model generates action chunks using flow matching, which can be subsequently refined by a residual action head for real-world deployment. Our method exhibits strong semantic understanding and stable execution on humanoid robots in both simulation and real-world deployment, and also supports multi-modal extensions by converting inputs into texts.

