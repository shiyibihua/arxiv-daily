---
layout: default
title: Dual-Granularity Semantic Prompting for Language Guidance Infrared Small Target Detection
---

# Dual-Granularity Semantic Prompting for Language Guidance Infrared Small Target Detection

**arXiv**: [2511.19306v1](https://arxiv.org/abs/2511.19306) | [PDF](https://arxiv.org/pdf/2511.19306.pdf)

**ä½œè€…**: Zixuan Wang, Haoran Sun, Jiaming Lu, Wenxuan Wang, Zhongling Huang, Dingwen Zhang, Xuelin Qian, Junwei Han

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDGSPNetä»¥è§£å†³çº¢å¤–å°ç›®æ ‡æ£€æµ‹ä¸­ç‰¹å¾è¡¨ç¤ºä¸è¶³å’ŒèƒŒæ™¯å¹²æ‰°é—®é¢˜**

**å…³é”®è¯**: `çº¢å¤–å°ç›®æ ‡æ£€æµ‹` `è¯­ä¹‰æç¤º` `è¯­è¨€å¼•å¯¼` `æ³¨æ„åŠ›æœºåˆ¶` `ç«¯åˆ°ç«¯æ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçº¢å¤–å°ç›®æ ‡æ£€æµ‹å› ç‰¹å¾è¡¨ç¤ºæœ‰é™å’ŒèƒŒæ™¯å¹²æ‰°ä¸¥é‡å¯¼è‡´æ€§èƒ½ä¸ä½³
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆåŒç²’åº¦è¯­ä¹‰æç¤ºï¼ŒåŒ…æ‹¬ç²—ç²’åº¦æ–‡æœ¬å…ˆéªŒå’Œç»†ç²’åº¦è§†è§‰åˆ°æ–‡æœ¬æ˜ å°„
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡æ£€æµ‹ç²¾åº¦ï¼Œè¾¾åˆ°æœ€å…ˆè¿›æ°´å¹³

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Infrared small target detection remains challenging due to limited feature representation and severe background interference, resulting in sub-optimal performance. While recent CLIP-inspired methods attempt to leverage textual guidance for detection, they are hindered by inaccurate text descriptions and reliance on manual annotations. To overcome these limitations, we propose DGSPNet, an end-to-end language prompt-driven framework. Our approach integrates dual-granularity semantic prompts: coarse-grained textual priors (e.g., 'infrared image', 'small target') and fine-grained personalized semantic descriptions derived through visual-to-textual mapping within the image space. This design not only facilitates learning fine-grained semantic information but also can inherently leverage language prompts during inference without relying on any annotation requirements. By fully leveraging the precision and conciseness of text descriptions, we further introduce a text-guide channel attention (TGCA) mechanism and text-guide spatial attention (TGSA) mechanism that enhances the model's sensitivity to potential targets across both low- and high-level feature spaces. Extensive experiments demonstrate that our method significantly improves detection accuracy and achieves state-of-the-art performance on three benchmark datasets.

