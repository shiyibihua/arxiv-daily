---
layout: default
title: PrismAudio: Decomposed Chain-of-Thoughts and Multi-dimensional Rewards for Video-to-Audio Generation
---

# PrismAudio: Decomposed Chain-of-Thoughts and Multi-dimensional Rewards for Video-to-Audio Generation

**arXiv**: [2511.18833v1](https://arxiv.org/abs/2511.18833) | [PDF](https://arxiv.org/pdf/2511.18833.pdf)

**ä½œè€…**: Huadai Liu, Kaicheng Luo, Wen Wang, Qian Chen, Peiwen Sun, Rongjie Huang, Xiangang Li, Jieping Ye, Wei Xue

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPrismAudioæ¡†æž¶ï¼Œé€šè¿‡åˆ†è§£æ€ç»´é“¾å’Œå¤šç»´å¥–åŠ±è§£å†³è§†é¢‘åˆ°éŸ³é¢‘ç”Ÿæˆçš„å®¢è§‚çº ç¼ é—®é¢˜ã€‚**

**å…³é”®è¯**: `è§†é¢‘åˆ°éŸ³é¢‘ç”Ÿæˆ` `å¼ºåŒ–å­¦ä¹ ` `æ€ç»´é“¾åˆ†è§£` `å¤šç»´å¥–åŠ±ä¼˜åŒ–` `AudioCanvasåŸºå‡†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•åœ¨è§†é¢‘åˆ°éŸ³é¢‘ç”Ÿæˆä¸­å­˜åœ¨å®¢è§‚çº ç¼ ï¼Œæ··æ·†å¤šä¸ªæ„ŸçŸ¥ç»´åº¦çš„ç›®æ ‡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥åˆ†è§£æ€ç»´é“¾å’Œå¯¹åº”å¥–åŠ±å‡½æ•°ï¼Œç»“åˆå¼ºåŒ–å­¦ä¹ è¿›è¡Œå¤šç»´ä¼˜åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨VGGSoundå’ŒAudioCanvasåŸºå‡†ä¸Šå®žçŽ°æ‰€æœ‰å››ä¸ªæ„ŸçŸ¥ç»´åº¦çš„æœ€å…ˆè¿›æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video-to-Audio (V2A) generation requires balancing four critical perceptual dimensions: semantic consistency, audio-visual temporal synchrony, aesthetic quality, and spatial accuracy; yet existing methods suffer from objective entanglement that conflates competing goals in single loss functions and lack human preference alignment. We introduce PrismAudio, the first framework to integrate Reinforcement Learning into V2A generation with specialized Chain-of-Thought (CoT) planning. Our approach decomposes monolithic reasoning into four specialized CoT modules (Semantic, Temporal, Aesthetic, and Spatial CoT), each paired with targeted reward functions. This CoT-reward correspondence enables multidimensional RL optimization that guides the model to jointly generate better reasoning across all perspectives, solving the objective entanglement problem while preserving interpretability. To make this optimization computationally practical, we propose Fast-GRPO, which employs hybrid ODE-SDE sampling that dramatically reduces the training overhead compared to existing GRPO implementations. We also introduce AudioCanvas, a rigorous benchmark that is more distributionally balanced and covers more realistically diverse and challenging scenarios than existing datasets, with 300 single-event classes and 501 multi-event samples. Experimental results demonstrate that PrismAudio achieves state-of-the-art performance across all four perceptual dimensions on both the in-domain VGGSound test set and out-of-domain AudioCanvas benchmark. The project page is available at https://PrismAudio-Project.github.io.

