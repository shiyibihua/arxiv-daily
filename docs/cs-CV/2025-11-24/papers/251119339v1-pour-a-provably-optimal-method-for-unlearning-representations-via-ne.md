---
layout: default
title: POUR: A Provably Optimal Method for Unlearning Representations via Neural Collapse
---

# POUR: A Provably Optimal Method for Unlearning Representations via Neural Collapse

**arXiv**: [2511.19339v1](https://arxiv.org/abs/2511.19339) | [PDF](https://arxiv.org/pdf/2511.19339.pdf)

**ä½œè€…**: Anjie Le, Can Peng, Yuyuan Liu, J. Alison Noble

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPOURæ–¹æ³•ä»¥åœ¨è®¡ç®—æœºè§†è§‰ä¸­å®žçŽ°è¡¨ç¤ºçº§åˆ«çš„å¯è¯æ˜Žæœ€ä¼˜é—å¿˜**

**å…³é”®è¯**: `æœºå™¨é—å¿˜` `è¡¨ç¤ºå­¦ä¹ ` `ç¥žç»å´©æºƒ` `å‡ ä½•æŠ•å½±` `è’¸é¦è®­ç»ƒ` `åˆ†ç±»æ€§èƒ½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰é—å¿˜æ–¹æ³•ä»…ä¿®æ”¹åˆ†ç±»å™¨ï¼Œå¯¼è‡´è¡¨ç¤ºå±‚é¢é—å¿˜ä¸å®Œæ•´ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽç¥žç»å´©æºƒç†è®ºï¼Œè®¾è®¡å‡ ä½•æŠ•å½±ç®—å­å®žçŽ°æœ€ä¼˜è¡¨ç¤ºé—å¿˜ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨CIFARå’ŒPathMNISTæ•°æ®é›†ä¸Šï¼ŒPOURåœ¨åˆ†ç±»å’Œè¡¨ç¤ºçº§åˆ«æŒ‡æ ‡ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In computer vision, machine unlearning aims to remove the influence of specific visual concepts or training images without retraining from scratch. Studies show that existing approaches often modify the classifier while leaving internal representations intact, resulting in incomplete forgetting. In this work, we extend the notion of unlearning to the representation level, deriving a three-term interplay between forgetting efficacy, retention fidelity, and class separation. Building on Neural Collapse theory, we show that the orthogonal projection of a simplex Equiangular Tight Frame (ETF) remains an ETF in a lower dimensional space, yielding a provably optimal forgetting operator. We further introduce the Representation Unlearning Score (RUS) to quantify representation-level forgetting and retention fidelity. Building on this, we introduce POUR (Provably Optimal Unlearning of Representations), a geometric projection method with closed-form (POUR-P) and a feature-level unlearning variant under a distillation scheme (POUR-D). Experiments on CIFAR-10/100 and PathMNIST demonstrate that POUR achieves effective unlearning while preserving retained knowledge, outperforming state-of-the-art unlearning methods on both classification-level and representation-level metrics.

