---
layout: default
title: Eevee: Towards Close-up High-resolution Video-based Virtual Try-on
---

# Eevee: Towards Close-up High-resolution Video-based Virtual Try-on

**arXiv**: [2511.18957v1](https://arxiv.org/abs/2511.18957) | [PDF](https://arxiv.org/pdf/2511.18957.pdf)

**ä½œè€…**: Jianhao Zeng, Yancheng Bai, Ruidong Chen, Xuanpu Zhang, Lei Sun, Dongyang Jin, Ryan Xu, Nannan Zhang, Dan Song, Xiangxiang Chu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé«˜åˆ†è¾¨çŽ‡è§†é¢‘è™šæ‹Ÿè¯•ç©¿æ•°æ®é›†ä¸ŽVGIDæŒ‡æ ‡ï¼Œä»¥æå‡æœè£…ç»†èŠ‚çœŸå®žæ€§ä¸Žä¸€è‡´æ€§ã€‚**

**å…³é”®è¯**: `è§†é¢‘è™šæ‹Ÿè¯•ç©¿` `é«˜åˆ†è¾¨çŽ‡æ•°æ®é›†` `æœè£…ä¸€è‡´æ€§è¯„ä¼°` `è¿‘æ™¯è§†é¢‘ç”Ÿæˆ` `çº¹ç†ç»†èŠ‚ä¿ç•™`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è™šæ‹Ÿè¯•ç©¿ä¾èµ–å•å¼ æœè£…å›¾åƒï¼Œæ— æ³•å‡†ç¡®æ•æ‰çº¹ç†ç»†èŠ‚ï¼Œä¸”ç¼ºä¹è¿‘æ™¯è§†é¢‘ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºåŒ…å«é«˜æ¸…å›¾åƒã€æ–‡æœ¬æè¿°åŠå…¨/è¿‘æ™¯è§†é¢‘çš„æ•°æ®é›†ï¼Œå¹¶è®¾è®¡VGIDæŒ‡æ ‡è¯„ä¼°ä¸€è‡´æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒéªŒè¯æ•°æ®é›†æå‡æ¨¡åž‹çº¹ç†æå–èƒ½åŠ›ï¼ŒåŸºå‡†æµ‹è¯•æ­ç¤ºçŽ°æœ‰æ–¹æ³•åœ¨ç»†èŠ‚ä¿ç•™ä¸Šçš„ä¸è¶³ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video virtual try-on technology provides a cost-effective solution for creating marketing videos in fashion e-commerce. However, its practical adoption is hindered by two critical limitations. First, the reliance on a single garment image as input in current virtual try-on datasets limits the accurate capture of realistic texture details. Second, most existing methods focus solely on generating full-shot virtual try-on videos, neglecting the business's demand for videos that also provide detailed close-ups. To address these challenges, we introduce a high-resolution dataset for video-based virtual try-on. This dataset offers two key features. First, it provides more detailed information on the garments, which includes high-fidelity images with detailed close-ups and textual descriptions; Second, it uniquely includes full-shot and close-up try-on videos of real human models. Furthermore, accurately assessing consistency becomes significantly more critical for the close-up videos, which demand high-fidelity preservation of garment details. To facilitate such fine-grained evaluation, we propose a new garment consistency metric VGID (Video Garment Inception Distance) that quantifies the preservation of both texture and structure. Our experiments validate these contributions. We demonstrate that by utilizing the detailed images from our dataset, existing video generation models can extract and incorporate texture features, significantly enhancing the realism and detail fidelity of virtual try-on results. Furthermore, we conduct a comprehensive benchmark of recent models. The benchmark effectively identifies the texture and structural preservation problems among current methods.

