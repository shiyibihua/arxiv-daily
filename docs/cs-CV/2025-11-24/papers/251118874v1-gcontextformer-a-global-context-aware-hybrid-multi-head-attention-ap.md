---
layout: default
title: GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction
---

# GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction

**arXiv**: [2511.18874v1](https://arxiv.org/abs/2511.18874) | [PDF](https://arxiv.org/pdf/2511.18874.pdf)

**ä½œè€…**: Yuzhi Chen, Yuanchang Xie, Lei Zhao, Pan Liu, Yajie Zou, Chen Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGContextFormerä»¥è§£å†³æ— åœ°å›¾å¤šæ¨¡æ€è½¨è¿¹é¢„æµ‹ä¸­çš„å…¨å±€ä¸Šä¸‹æ–‡ç¼ºå¤±é—®é¢˜**

**å…³é”®è¯**: `è½¨è¿¹é¢„æµ‹` `å¤šæ¨¡æ€å­¦ä¹ ` `æ³¨æ„åŠ›æœºåˆ¶` `å…¨å±€ä¸Šä¸‹æ–‡` `æ„å›¾å¯¹é½` `æ— åœ°å›¾é¢„æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ— åœ°å›¾æ–¹æ³•ç¼ºä¹å…¨å±€ä¸Šä¸‹æ–‡ï¼Œæ³¨æ„åŠ›æœºåˆ¶æ”¾å¤§ç›´çº¿æ¨¡å¼æŠ‘åˆ¶è¿‡æ¸¡æ¨¡å¼ï¼Œå¯¼è‡´è¿åŠ¨æ„å›¾é”™ä½
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å…¨å±€ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ··åˆæ³¨æ„åŠ›å’Œç¼©æ”¾åŠ æ³•èšåˆï¼Œå®žçŽ°æ„å›¾å¯¹é½çš„å¤šæ¨¡æ€é¢„æµ‹
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨TOD-VTæ•°æ®é›†ä¸Šè¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œåœ¨é«˜æ›²çŽ‡å’Œè¿‡æ¸¡åŒºè¡¨çŽ°æ›´ç¨³å¥

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal trajectory prediction generates multiple plausible future trajectories to address vehicle motion uncertainty from intention ambiguity and execution variability. However, HD map-dependent models suffer from costly data acquisition, delayed updates, and vulnerability to corrupted inputs, causing prediction failures. Map-free approaches lack global context, with pairwise attention over-amplifying straight patterns while suppressing transitional patterns, resulting in motion-intention misalignment. This paper proposes GContextFormer, a plug-and-play encoder-decoder architecture with global context-aware hybrid attention and scaled additive aggregation achieving intention-aligned multimodal prediction without map reliance. The Motion-Aware Encoder builds scene-level intention prior via bounded scaled additive aggregation over mode-embedded trajectory tokens and refines per-mode representations under shared global context, mitigating inter-mode suppression and promoting intention alignment. The Hierarchical Interaction Decoder decomposes social reasoning into dual-pathway cross-attention: a standard pathway ensures uniform geometric coverage over agent-mode pairs while a neighbor-context-enhanced pathway emphasizes salient interactions, with gating module mediating their contributions to maintain coverage-focus balance. Experiments on eight highway-ramp scenarios from TOD-VT dataset show GContextFormer outperforms state-of-the-art baselines. Compared to existing transformer models, GContextFormer achieves greater robustness and concentrated improvements in high-curvature and transition zones via spatial distributions. Interpretability is achieved through motion mode distinctions and neighbor context modulation exposing reasoning attribution. The modular architecture supports extensibility toward cross-domain multimodal reasoning tasks. Source: https://fenghy-chen.github.io/sources/.

