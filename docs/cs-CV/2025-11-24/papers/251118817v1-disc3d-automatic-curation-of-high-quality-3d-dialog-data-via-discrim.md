---
layout: default
title: Disc3D: Automatic Curation of High-Quality 3D Dialog Data via Discriminative Object Referring
---

# Disc3D: Automatic Curation of High-Quality 3D Dialog Data via Discriminative Object Referring

**arXiv**: [2511.18817v1](https://arxiv.org/abs/2511.18817) | [PDF](https://arxiv.org/pdf/2511.18817.pdf)

**ä½œè€…**: Siyuan Wei, Chunjie Wang, Xiao Liu, Xiaosheng Yan, Zhishan Zhou, Rui Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDisc3Dè‡ªåŠ¨ç®¡é“ä»¥è§£å†³3Då¤šæ¨¡æ€å¤§æ¨¡åž‹æ•°æ®ç¨€ç¼ºä¸Žæ­§ä¹‰é—®é¢˜**

**å…³é”®è¯**: `3Då¤šæ¨¡æ€å¤§æ¨¡åž‹` `è‡ªåŠ¨æ•°æ®ç”Ÿæˆ` `å¯¹è±¡æŒ‡ä»£æ¶ˆæ­§` `åœºæ™¯å›¾æž„å»º` `å¤šä»»åŠ¡å¯¹è¯åˆæˆ` `å¤§è§„æ¨¡æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼š3Då¤šæ¨¡æ€å¤§æ¨¡åž‹å› é«˜è´¨é‡å¯¹è¯æ•°æ®ç¨€ç¼ºå’Œè§†è§’ã€å¯¹è±¡æŒ‡ä»£æ­§ä¹‰è€Œè½åŽäºŽ2Dæ¨¡åž‹
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆè§„åˆ™çº¦æŸä¸Ž2D MLLMs/LLMsï¼Œè‡ªåŠ¨ç”Ÿæˆæ— æ­§ä¹‰ã€é«˜è´¨é‡3Dåœºæ™¯å¯¹è¯æ•°æ®
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å…¬å…±åŸºå‡†å’ŒDisc3D-QAä»»åŠ¡ä¸Šè®­ç»ƒæ¨¡åž‹ï¼Œå®žçŽ°ä¸€è‡´æ˜¾è‘—æ€§èƒ½æå‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> 3D Multi-modal Large Language Models (MLLMs) still lag behind their 2D peers, largely because large-scale, high-quality 3D scene-dialogue datasets remain scarce. Prior efforts hinge on expensive human annotation and leave two key ambiguities unresolved: viewpoint ambiguity, where spatial language presumes unknown camera poses, and object referring ambiguity, where non-exclusive descriptions blur the line between targets and distractors. We therefore present a fully automated pipeline that converts raw 3D scans into unambiguous, high-quality dialogue data at a fraction of the previous cost. By synergizing rule-based constraints with 2D MLLMs and LLMs, the pipeline enables controllable, scalable generation without human intervention. The pipeline comprises four stages: (1) meta-annotation collection harvesting object-, frame-, and scene-level captions, (2) scene graph construction with relation correction to capture proximal object relations, (3) discriminative object referring that generates exclusive and compact descriptions, and (4) multi-task data generation synthesizing diverse dialogues. Our pipeline systematically mitigates inherent flaws in source datasets and produces the final Disc3D dataset, over 2 million samples in 25K hybrid 3D scenes, spanning scene, view, and object captioning, visual grounding, and five object-centric QA tasks. Extensive experiments demonstrate that training with Disc3D yields consistent, significant improvements on both public benchmarks and our multifaceted Disc3D-QA tasks. Code, data, and models will be publicly available.

