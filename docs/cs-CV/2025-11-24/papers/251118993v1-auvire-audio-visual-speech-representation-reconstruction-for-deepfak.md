---
layout: default
title: AuViRe: Audio-visual Speech Representation Reconstruction for Deepfake Temporal Localization
---

# AuViRe: Audio-visual Speech Representation Reconstruction for Deepfake Temporal Localization

**arXiv**: [2511.18993v1](https://arxiv.org/abs/2511.18993) | [PDF](https://arxiv.org/pdf/2511.18993.pdf)

**ä½œè€…**: Christos Koutlis, Symeon Papadopoulos

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-24

**å¤‡æ³¨**: WACV 2026

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/mever-team/auvire)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAuViReï¼Œé€šè¿‡éŸ³è§†é¢‘è¯­éŸ³è¡¨å¾é‡å»ºå®žçŽ°Deepfakeè§†é¢‘çš„æ—¶é—´å®šä½**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `Deepfakeæ£€æµ‹` `æ—¶é—´å®šä½` `éŸ³è§†é¢‘èžåˆ` `è·¨æ¨¡æ€å­¦ä¹ ` `è¯­éŸ³è¡¨å¾é‡å»º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰Deepfakeæ£€æµ‹æ–¹æ³•åœ¨æ—¶é—´å®šä½æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥ç²¾ç¡®å®šä½ç¯¡æ”¹å‘ç”Ÿçš„æ—¶é—´ç‚¹ã€‚
2. AuViReé€šè¿‡è·¨æ¨¡æ€è¯­éŸ³è¡¨å¾é‡å»ºï¼Œæ”¾å¤§äº†ç¯¡æ”¹è§†é¢‘ç‰‡æ®µä¸­çš„å·®å¼‚ï¼Œä»Žè€Œæä¾›æ›´å¼ºçš„åˆ¤åˆ«æ€§ç‰¹å¾ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒAuViReåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æŠ€æœ¯ï¼Œå°¤å…¶åœ¨ç²¾ç¡®æ—¶é—´å®šä½æ–¹é¢ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€åˆæˆéŸ³è§†é¢‘å†…å®¹çš„å¿«é€Ÿå‘å±•ï¼Œç‰¹åˆ«æ˜¯ç”¨äºŽæ¶æ„æ“çºµçš„åœºæ™¯ï¼Œç¡®ä¿æ•°å­—åª’ä½“çš„å®Œæ•´æ€§è‡³å…³é‡è¦ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œå³éŸ³è§†é¢‘è¯­éŸ³è¡¨å¾é‡å»ºï¼ˆAuViReï¼‰ï¼Œç”¨äºŽDeepfakeè§†é¢‘çš„æ—¶é—´å®šä½ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åŸºäºŽä¸€ç§æ¨¡æ€ï¼ˆä¾‹å¦‚ï¼Œå”‡éƒ¨è¿åŠ¨ï¼‰é‡å»ºå¦ä¸€ç§æ¨¡æ€ï¼ˆä¾‹å¦‚ï¼ŒéŸ³é¢‘æ³¢å½¢ï¼‰çš„è¯­éŸ³è¡¨å¾ã€‚åœ¨è¢«ç¯¡æ”¹çš„è§†é¢‘ç‰‡æ®µä¸­ï¼Œè·¨æ¨¡æ€é‡å»ºæ›´å…·æŒ‘æˆ˜æ€§ï¼Œå¯¼è‡´å·®å¼‚è¢«æ”¾å¤§ï¼Œä»Žè€Œä¸ºç²¾ç¡®çš„æ—¶é—´ä¼ªé€ å®šä½æä¾›å¼ºå¤§çš„åˆ¤åˆ«çº¿ç´¢ã€‚AuViReåœ¨LAV-DFä¸Šè¶…è¿‡çŽ°æœ‰æŠ€æœ¯+8.9 AP@0.95ï¼Œåœ¨AV-Deepfake1Mä¸Šè¶…è¿‡+9.6 AP@0.5ï¼Œå¹¶åœ¨çœŸå®žåœºæ™¯å®žéªŒä¸­è¶…è¿‡+5.1 AUCã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³Deepfakeè§†é¢‘ä¸­æ—¶é—´å®šä½ä¸å‡†ç¡®çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸ä¾§é‡äºŽæ£€æµ‹è§†é¢‘æ˜¯å¦ä¸ºDeepfakeï¼Œä½†éš¾ä»¥ç²¾ç¡®å®šä½ç¯¡æ”¹å‘ç”Ÿçš„æ—¶é—´ç‚¹ï¼Œè¿™å¯¹äºŽå–è¯å’Œæº¯æºè‡³å…³é‡è¦ã€‚çŽ°æœ‰æ–¹æ³•åœ¨è·¨æ¨¡æ€ä¿¡æ¯åˆ©ç”¨æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæœªèƒ½å……åˆ†æŒ–æŽ˜éŸ³è§†é¢‘ä¹‹é—´çš„ä¸ä¸€è‡´æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨éŸ³è§†é¢‘è¯­éŸ³è¡¨å¾çš„è·¨æ¨¡æ€é‡å»ºã€‚æ­£å¸¸è§†é¢‘ä¸­ï¼ŒéŸ³é¢‘å’Œè§†è§‰ä¿¡æ¯é«˜åº¦ä¸€è‡´ï¼Œå¯ä»¥ç›¸äº’é¢„æµ‹ã€‚è€Œåœ¨Deepfakeè§†é¢‘ä¸­ï¼Œç”±äºŽç¯¡æ”¹ï¼ŒéŸ³è§†é¢‘ä¿¡æ¯ä¸å†ä¸€è‡´ï¼Œè·¨æ¨¡æ€é‡å»ºçš„è¯¯å·®ä¼šæ˜¾è‘—å¢žå¤§ã€‚é€šè¿‡æ£€æµ‹é‡å»ºè¯¯å·®çš„å˜åŒ–ï¼Œå¯ä»¥ç²¾ç¡®å®šä½ç¯¡æ”¹å‘ç”Ÿçš„æ—¶é—´ç‚¹ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šAuViReçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) éŸ³é¢‘ç‰¹å¾æå–æ¨¡å—ï¼Œç”¨äºŽæå–éŸ³é¢‘çš„è¯­éŸ³è¡¨å¾ï¼›2) è§†è§‰ç‰¹å¾æå–æ¨¡å—ï¼Œç”¨äºŽæå–å”‡éƒ¨è¿åŠ¨çš„è§†è§‰è¡¨å¾ï¼›3) è·¨æ¨¡æ€é‡å»ºæ¨¡å—ï¼ŒåŸºäºŽä¸€ç§æ¨¡æ€çš„è¡¨å¾é‡å»ºå¦ä¸€ç§æ¨¡æ€çš„è¡¨å¾ï¼›4) å·®å¼‚æ£€æµ‹æ¨¡å—ï¼Œè®¡ç®—é‡å»ºè¡¨å¾ä¸ŽåŽŸå§‹è¡¨å¾ä¹‹é—´çš„å·®å¼‚ï¼›5) æ—¶é—´å®šä½æ¨¡å—ï¼ŒåŸºäºŽå·®å¼‚çš„å˜åŒ–ï¼Œå®šä½ç¯¡æ”¹å‘ç”Ÿçš„æ—¶é—´ç‚¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šAuViReçš„å…³é”®åˆ›æ–°åœ¨äºŽåˆ©ç”¨è·¨æ¨¡æ€è¯­éŸ³è¡¨å¾é‡å»ºè¿›è¡ŒDeepfakeæ—¶é—´å®šä½ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒAuViReæ›´å…³æ³¨éŸ³è§†é¢‘ä¿¡æ¯çš„ä¸€è‡´æ€§ï¼Œé€šè¿‡é‡å»ºè¯¯å·®æ”¾å¤§ç¯¡æ”¹å¸¦æ¥çš„å·®å¼‚ï¼Œä»Žè€Œå®žçŽ°æ›´ç²¾ç¡®çš„æ—¶é—´å®šä½ã€‚æ­¤å¤–ï¼ŒAuViReæ— éœ€äººå·¥æ ‡æ³¨ç¯¡æ”¹æ—¶é—´ç‚¹ï¼Œå¯ä»¥è¿›è¡Œå¼±ç›‘ç£å­¦ä¹ ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨éŸ³é¢‘ç‰¹å¾æå–æ–¹é¢ï¼Œå¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒçš„è¯­éŸ³è¯†åˆ«æ¨¡åž‹æå–è¯­éŸ³è¡¨å¾ã€‚åœ¨è§†è§‰ç‰¹å¾æå–æ–¹é¢ï¼Œå¯ä»¥ä½¿ç”¨å”‡éƒ¨è¿åŠ¨è·Ÿè¸ªç®—æ³•æå–å”‡éƒ¨è¿åŠ¨çš„è§†è§‰è¡¨å¾ã€‚è·¨æ¨¡æ€é‡å»ºæ¨¡å—å¯ä»¥ä½¿ç”¨å¾ªçŽ¯ç¥žç»ç½‘ç»œï¼ˆRNNï¼‰æˆ–Transformerç­‰åºåˆ—æ¨¡åž‹ã€‚å·®å¼‚æ£€æµ‹æ¨¡å—å¯ä»¥ä½¿ç”¨å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰æˆ–ä½™å¼¦ç›¸ä¼¼åº¦ç­‰æŒ‡æ ‡ã€‚æ—¶é—´å®šä½æ¨¡å—å¯ä»¥ä½¿ç”¨æ»‘åŠ¨çª—å£æˆ–é˜ˆå€¼åˆ†å‰²ç­‰æ–¹æ³•ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

AuViReåœ¨LAV-DFæ•°æ®é›†ä¸Šå®žçŽ°äº†8.9%çš„AP@0.95æå‡ï¼Œåœ¨AV-Deepfake1Mæ•°æ®é›†ä¸Šå®žçŽ°äº†9.6%çš„AP@0.5æå‡ï¼Œå¹¶åœ¨çœŸå®žåœºæ™¯å®žéªŒä¸­å®žçŽ°äº†5.1%çš„AUCæå‡ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒAuViReåœ¨Deepfakeæ—¶é—´å®šä½æ–¹é¢æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æŠ€æœ¯ï¼Œå…·æœ‰å¾ˆå¼ºçš„å®žç”¨ä»·å€¼ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

AuViReå¯åº”ç”¨äºŽæ•°å­—åª’ä½“å–è¯ã€æ–°é—»çœŸå®žæ€§éªŒè¯ã€ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸ç­‰é¢†åŸŸã€‚é€šè¿‡ç²¾ç¡®å®šä½Deepfakeè§†é¢‘çš„ç¯¡æ”¹æ—¶é—´ç‚¹ï¼Œå¯ä»¥å¸®åŠ©è¯†åˆ«å’Œæº¯æºæ¶æ„ä¿¡æ¯ï¼Œç»´æŠ¤ç½‘ç»œå®‰å…¨å’Œä¿¡æ¯å®‰å…¨ã€‚è¯¥æŠ€æœ¯è¿˜æœ‰åŠ©äºŽæé«˜å…¬ä¼—å¯¹Deepfakeçš„è®¤çŸ¥ï¼Œå¢žå¼ºé˜²èŒƒæ„è¯†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> With the rapid advancement of sophisticated synthetic audio-visual content, e.g., for subtle malicious manipulations, ensuring the integrity of digital media has become paramount. This work presents a novel approach to temporal localization of deepfakes by leveraging Audio-Visual Speech Representation Reconstruction (AuViRe). Specifically, our approach reconstructs speech representations from one modality (e.g., lip movements) based on the other (e.g., audio waveform). Cross-modal reconstruction is significantly more challenging in manipulated video segments, leading to amplified discrepancies, thereby providing robust discriminative cues for precise temporal forgery localization. AuViRe outperforms the state of the art by +8.9 AP@0.95 on LAV-DF, +9.6 AP@0.5 on AV-Deepfake1M, and +5.1 AUC on an in-the-wild experiment. Code available at https://github.com/mever-team/auvire.

