---
layout: default
title: Dynamic Granularity Matters: Rethinking Vision Transformers Beyond Fixed Patch Splitting
---

# Dynamic Granularity Matters: Rethinking Vision Transformers Beyond Fixed Patch Splitting

**arXiv**: [2511.19021v1](https://arxiv.org/abs/2511.19021) | [PDF](https://arxiv.org/pdf/2511.19021.pdf)

**ä½œè€…**: Qiyang Yu, Yu Fang, Tianrui Li, Xuemei Cao, Yan Chen, Jianghao Li, Fan Min

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGrc-ViTä»¥åŠ¨æ€è°ƒæ•´è§†è§‰ç²’åº¦ï¼Œæå‡Vision Transformersçš„ç»†ç²’åº¦è¯†åˆ«ä¸Žè®¡ç®—æ•ˆçŽ‡**

**å…³é”®è¯**: `è§†è§‰Transformer` `åŠ¨æ€ç²’åº¦è°ƒæ•´` `ç»†ç²’åº¦è¯†åˆ«` `è®¡ç®—æ•ˆçŽ‡ä¼˜åŒ–` `æ³¨æ„åŠ›æœºåˆ¶` `å›¾åƒå¤æ‚åº¦è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. Vision Transformersåœ¨æ•æ‰å…¨å±€ä¾èµ–æ—¶ï¼Œéš¾ä»¥é«˜æ•ˆè¡¨ç¤ºç»†ç²’åº¦å±€éƒ¨ç»†èŠ‚ï¼Œä¸”çŽ°æœ‰å¤šå°ºåº¦æ–¹æ³•ä¾èµ–å›ºå®šè¡¥ä¸å¤§å°å¹¶å¼•å…¥å†—ä½™è®¡ç®—
2. Grc-ViTé€šè¿‡ç²—ç²’åº¦è¯„ä¼°æ¨¡å—åˆ†æžå›¾åƒå¤æ‚åº¦ï¼Œå¹¶åˆ©ç”¨ç»†ç²’åº¦ç²¾ç‚¼æ¨¡å—åŠ¨æ€è°ƒæ•´è¡¥ä¸å’Œçª—å£å¤§å°ï¼Œä¼˜åŒ–æ³¨æ„åŠ›è®¡ç®—
3. å®žéªŒè¡¨æ˜Žï¼ŒGrc-ViTåœ¨å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆçŽ‡é—´å®žçŽ°ä¼˜è¶Šå¹³è¡¡ï¼Œå¢žå¼ºç»†ç²’åº¦åˆ¤åˆ«èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision Transformers (ViTs) have demonstrated strong capabilities in capturing global dependencies but often struggle to efficiently represent fine-grained local details. Existing multi-scale approaches alleviate this issue by integrating hierarchical or hybrid features; however, they rely on fixed patch sizes and introduce redundant computation. To address these limitations, we propose Granularity-driven Vision Transformer (Grc-ViT), a dynamic coarse-to-fine framework that adaptively adjusts visual granularity based on image complexity. It comprises two key stages: (1) Coarse Granularity Evaluation module, which assesses visual complexity using edge density, entropy, and frequency-domain cues to estimate suitable patch and window sizes; (2) Fine-grained Refinement module, which refines attention computation according to the selected granularity, enabling efficient and precise feature learning. Two learnable parameters, Î± and \b{eta}, are optimized end-to-end to balance global reasoning and local perception. Comprehensive evaluations demonstrate that Grc-ViT enhances fine-grained discrimination while achieving a superior trade-off between accuracy and computational efficiency.

