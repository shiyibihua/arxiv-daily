---
layout: default
title: AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion
---

# AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion

**arXiv**: [2511.18857v1](https://arxiv.org/abs/2511.18857) | [PDF](https://arxiv.org/pdf/2511.18857.pdf)

**ä½œè€…**: Changsheng Luo, Yushi Wang, Wenhan Cai, Mingguo Zhao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAutoOdomè‡ªå›žå½’æœ¬ä½“æ„ŸçŸ¥é‡Œç¨‹è®¡ï¼Œè§£å†³è…¿å¼æœºå™¨äººåœ¨GPSç¼ºå¤±å’Œè§†è§‰é€€åŒ–çŽ¯å¢ƒä¸­çš„å®šä½é—®é¢˜**

**å…³é”®è¯**: `è…¿å¼æœºå™¨äººå®šä½` `è‡ªå›žå½’å­¦ä¹ ` `ä»¿çœŸåˆ°çŽ°å®žè¿ç§»` `æœ¬ä½“æ„ŸçŸ¥é‡Œç¨‹è®¡` `ä¸¤é˜¶æ®µè®­ç»ƒ` `ä¼ æ„Ÿå™¨æ¨¡æ€é€‰æ‹©`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿé‡Œç¨‹è®¡åœ¨GPSç¼ºå¤±å’Œè§†è§‰é€€åŒ–çŽ¯å¢ƒä¸­å¤±æ•ˆï¼ŒçŽ°æœ‰æ–¹æ³•å­˜åœ¨å»ºæ¨¡ä¸ç¡®å®šæ€§ã€ä»¿çœŸåˆ°çŽ°å®žå·®è·å’Œæ¼‚ç§»é—®é¢˜
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒï¼Œå…ˆä»¿çœŸå­¦ä¹ éžçº¿æ€§åŠ¨æ€å’ŒæŽ¥è§¦çŠ¶æ€ï¼Œå†è‡ªå›žå½’å¢žå¼ºä»¥å¼¥åˆä»¿çœŸåˆ°çŽ°å®žå·®è·
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Booster T1äººå½¢æœºå™¨äººä¸ŠéªŒè¯ï¼Œç»å¯¹è½¨è¿¹è¯¯å·®ç­‰æŒ‡æ ‡æ˜¾è‘—ä¼˜äºŽåŸºçº¿æ–¹æ³•ï¼Œæå‡è¾¾57.2%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Accurate proprioceptive odometry is fundamental for legged robot navigation in GPS-denied and visually degraded environments where conventional visual odometry systems fail. Current approaches face critical limitations: analytical filtering methods suffer from modeling uncertainties and cumulative drift, hybrid learning-filtering approaches remain constrained by their analytical components, while pure learning-based methods struggle with simulation-to-reality transfer and demand extensive real-world data collection. This paper introduces AutoOdom, a novel autoregressive proprioceptive odometry system that overcomes these challenges through an innovative two-stage training paradigm. Stage 1 employs large-scale simulation data to learn complex nonlinear dynamics and rapidly changing contact states inherent in legged locomotion, while Stage 2 introduces an autoregressive enhancement mechanism using limited real-world data to effectively bridge the sim-to-real gap. The key innovation lies in our autoregressive training approach, where the model learns from its own predictions to develop resilience against sensor noise and improve robustness in highly dynamic environments. Comprehensive experimental validation on the Booster T1 humanoid robot demonstrates that AutoOdom significantly outperforms state-of-the-art methods across all evaluation metrics, achieving 57.2% improvement in absolute trajectory error, 59.2% improvement in Umeyama-aligned error, and 36.2% improvement in relative pose error compared to the Legolas baseline. Extensive ablation studies provide critical insights into sensor modality selection and temporal modeling, revealing counterintuitive findings about IMU acceleration data and validating our systematic design choices for robust proprioceptive odometry in challenging locomotion scenarios.

