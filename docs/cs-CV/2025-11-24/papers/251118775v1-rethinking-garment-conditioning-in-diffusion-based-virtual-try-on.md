---
layout: default
title: Rethinking Garment Conditioning in Diffusion-based Virtual Try-On
---

# Rethinking Garment Conditioning in Diffusion-based Virtual Try-On

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.18775" target="_blank" class="toolbar-btn">arXiv: 2511.18775v1</a>
    <a href="https://arxiv.org/pdf/2511.18775.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.18775v1" 
            onclick="toggleFavorite(this, '2511.18775v1', 'Rethinking Garment Conditioning in Diffusion-based Virtual Try-On')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Kihyun Na, Jinyoung Choi, Injung Kim

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-24

**Â§áÊ≥®**: 15 pages (including references and supplementary material), 10 figures, 7 tables. Code and pretrained models will be released

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Re-CatVTONÔºåÈ´òÊïàÂçïUNetÊâ©Êï£Ê®°ÂûãÂÆûÁé∞È´òÊÄßËÉΩËôöÊãüËØïÁ©ø**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `ËôöÊãüËØïÁ©ø` `Êâ©Êï£Ê®°Âûã` `ÂçïUNet` `‰∏ä‰∏ãÊñáÁâπÂæÅÂ≠¶‰π†` `Êó†ÂàÜÁ±ªÂô®ÂºïÂØº` `ÂõæÂÉèÂêàÊàê` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑËôöÊãüËØïÁ©øÊñπÊ≥ïÔºåÁâπÂà´ÊòØÂèåUNetÁªìÊûÑÔºåËôΩÁÑ∂ÊïàÊûúÂ•ΩÔºå‰ΩÜËÆ°ÁÆóÂíåÂÜÖÂ≠òÂºÄÈîÄÂ∑®Â§ß„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Re-CatVTONÔºå‰∏Ä‰∏™È´òÊïàÁöÑÂçïUNetÊ®°ÂûãÔºåÈÄöËøá‰ºòÂåñ‰∏ä‰∏ãÊñáÁâπÂæÅÂ≠¶‰π†ÂíåÊîπËøõÂºïÂØºÁ≠ñÁï•ÔºåÊèêÂçáÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåRe-CatVTONÂú®FID„ÄÅKIDÂíåLPIPSÊåáÊ†á‰∏ä‰ºò‰∫éÁé∞ÊúâÂçïUNetÊ®°ÂûãÔºåÂπ∂Âú®ÊïàÁéá‰∏ä‰ºò‰∫éÂèåUNetÊ®°Âûã„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËôöÊãüËØïÁ©ø(VTON)Êó®Âú®ÂêàÊàêÁªôÂÆö‰∫∫Áâ©ÂõæÂÉèÂíåÊúçË£ÖÂõæÂÉèÊù°‰ª∂‰∏ãÔºå‰∫∫Áâ©Á©øÁùÄÁõÆÊ†áÊúçË£ÖÁöÑÂõæÂÉè„ÄÇÂü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑVTONÊ®°ÂûãÔºåÁâπÂà´ÊòØÈááÁî®ÂèåUNetÊû∂ÊûÑÁöÑÊ®°ÂûãÔºåÁõ∏ÊØîÂçïUNetÊ®°ÂûãÂ±ïÁé∞Âá∫Êõ¥È´òÁöÑÂõæÂÉè‰øùÁúüÂ∫¶Ôºå‰ΩÜÂÖ∂Â∫ûÂ§ßÁöÑÁªìÊûÑÂØºËá¥‰∫ÜÊòæËëóÁöÑËÆ°ÁÆóÂíåÂÜÖÂ≠òÂºÄÈîÄ„ÄÇÊú¨Á†îÁ©∂ÈÄöËøáÂèØËßÜÂåñÂàÜÊûêÂíåÁêÜËÆ∫ÂàÜÊûêÔºåÊé®ÂØº‰∫ÜÂÖ≥‰∫éÂ≠¶‰π†‰∏ä‰∏ãÊñáÁâπÂæÅ‰ª•Ë∞ÉËäÇÂéªÂô™ËøáÁ®ãÁöÑ‰∏â‰∏™ÂÅáËÆæ„ÄÇÂü∫‰∫éËøô‰∫õÂÅáËÆæÔºåÊàë‰ª¨ÂºÄÂèë‰∫ÜRe-CatVTONÔºå‰∏Ä‰∏™È´òÊïàÁöÑÂçïUNetÊ®°ÂûãÔºåÂÆûÁé∞‰∫ÜÈ´òÊÄßËÉΩ„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•ÈÄöËøáÂºïÂÖ•ÈíàÂØπVTONÁ©∫Èó¥ÊãºÊé•Êù°‰ª∂ÁöÑÊîπËøõÁöÑÊó†ÂàÜÁ±ªÂô®ÂºïÂØºÁ≠ñÁï•Ôºå‰ª•ÂèäÁõ¥Êé•Ê≥®ÂÖ•‰ªéÂπ≤ÂáÄÊúçË£ÖÊΩúÂú®ÂèòÈáèÂØºÂá∫ÁöÑÁúüÂÆûÊúçË£ÖÊΩúÂú®ÂèòÈáè‰ª•Èò≤Ê≠¢È¢ÑÊµãËØØÂ∑ÆÁ¥ØÁßØÔºåÊù•Â¢ûÂº∫Ê®°Âûã„ÄÇÊâÄÊèêÂá∫ÁöÑRe-CatVTONÁõ∏ÊØîÂÖ∂ÂâçË∫´(CatVTON)ÊòæËëóÊèêÈ´ò‰∫ÜÊÄßËÉΩÔºåÂπ∂‰∏îÊØîÈ´òÊÄßËÉΩÂèåUNetÊ®°ÂûãLeffaÈúÄË¶ÅÊõ¥Â∞ëÁöÑËÆ°ÁÆóÂíåÂÜÖÂ≠ò„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúË°®ÊòéÔºåFID„ÄÅKIDÂíåLPIPSÂàÜÊï∞ÊúâÊâÄÊèêÈ´òÔºåËÄåSSIMÁï•Êúâ‰∏ãÈôçÔºå‰∏∫ÂçïUNet VTONÊ®°ÂûãÂª∫Á´ã‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊïàÁéá-ÊÄßËÉΩÊùÉË°°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ËôöÊãüËØïÁ©ø‰ªªÂä°‰∏≠ÔºåÂü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑÂèåUNetÁªìÊûÑËÆ°ÁÆóÂíåÂÜÖÂ≠òÂºÄÈîÄËøáÂ§ßÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïËôΩÁÑ∂ËÉΩÁîüÊàêÈ´òË¥®ÈáèÁöÑËØïÁ©øÂõæÂÉèÔºå‰ΩÜÂÖ∂Â§çÊùÇÁöÑÁΩëÁªúÁªìÊûÑÈôêÂà∂‰∫ÜÂÖ∂Âú®ËµÑÊ∫êÂèóÈôêÂú∫ÊôØ‰∏ãÁöÑÂ∫îÁî®„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶ÅËÆæËÆ°‰∏ÄÁßçÊõ¥È´òÊïàÁöÑËôöÊãüËØïÁ©øÊ®°ÂûãÔºåÂú®‰øùËØÅÁîüÊàêË¥®ÈáèÁöÑÂêåÊó∂ÔºåÈôç‰ΩéËÆ°ÁÆóÊàêÊú¨„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÊ∑±ÂÖ•ÂàÜÊûê‰∏ä‰∏ãÊñáÁâπÂæÅÁöÑÂ≠¶‰π†ËøáÁ®ãÔºåÂπ∂Âü∫‰∫éÂàÜÊûêÁªìÊûúËÆæËÆ°Êõ¥ÊúâÊïàÁöÑÁΩëÁªúÁªìÊûÑÂíåËÆ≠ÁªÉÁ≠ñÁï•Ôºå‰ªéËÄåÂú®ÂçïUNetÁªìÊûÑ‰∏ãÂÆûÁé∞‰∏éÂèåUNetÁªìÊûÑÁõ∏Â™≤ÁæéÁöÑÊÄßËÉΩ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåËÆ∫ÊñáÊèêÂá∫‰∫ÜÂÖ≥‰∫é‰∏ä‰∏ãÊñáÁâπÂæÅÂ≠¶‰π†ÁöÑ‰∏â‰∏™ÂÅáËÆæÔºåÂπ∂Âü∫‰∫éËøô‰∫õÂÅáËÆæËÆæËÆ°‰∫ÜRe-CatVTONÊ®°Âûã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRe-CatVTONÂü∫‰∫éÂçïUNetÊû∂ÊûÑÔºåÊï¥‰ΩìÊµÅÁ®ãÂ¶Ç‰∏ãÔºöÈ¶ñÂÖàÔºåÂ∞Ü‰∫∫Áâ©ÂõæÂÉèÂíåÊúçË£ÖÂõæÂÉèËøõË°åÁ©∫Èó¥ÊãºÊé•Ôºå‰Ωú‰∏∫UNetÁöÑËæìÂÖ•„ÄÇÁÑ∂ÂêéÔºåUNetËøõË°åÂéªÂô™ËøáÁ®ãÔºåÈÄêÊ≠•ÁîüÊàêËØïÁ©øÂõæÂÉè„ÄÇ‰∏∫‰∫ÜÊèêÂçáÊÄßËÉΩÔºåËÆ∫ÊñáËøòÂºïÂÖ•‰∫ÜÊîπËøõÁöÑÊó†ÂàÜÁ±ªÂô®ÂºïÂØºÁ≠ñÁï•ÂíåÁõ¥Êé•Ê≥®ÂÖ•ÁúüÂÆûÊúçË£ÖÊΩúÂú®ÂèòÈáèÁöÑÊñπÊ≥ï„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞ÁÇπÂú®‰∫éÔºö1) Âü∫‰∫éÂèØËßÜÂåñÂíåÁêÜËÆ∫ÂàÜÊûêÔºåÊèêÂá∫‰∫ÜÂÖ≥‰∫é‰∏ä‰∏ãÊñáÁâπÂæÅÂ≠¶‰π†ÁöÑ‰∏â‰∏™ÂÅáËÆæ„ÄÇ2) Âü∫‰∫éËøô‰∫õÂÅáËÆæÔºåËÆæËÆ°‰∫ÜRe-CatVTONÊ®°ÂûãÔºåËØ•Ê®°ÂûãÂú®ÂçïUNetÁªìÊûÑ‰∏ãÂÆûÁé∞‰∫ÜÈ´òÊÄßËÉΩ„ÄÇ3) ÊèêÂá∫‰∫ÜÈíàÂØπVTONÁ©∫Èó¥ÊãºÊé•Êù°‰ª∂ÁöÑÊîπËøõÁöÑÊó†ÂàÜÁ±ªÂô®ÂºïÂØºÁ≠ñÁï•„ÄÇ4) ÊèêÂá∫‰∫ÜÁõ¥Êé•Ê≥®ÂÖ•ÁúüÂÆûÊúçË£ÖÊΩúÂú®ÂèòÈáèÁöÑÊñπÊ≥ïÔºå‰ª•Èò≤Ê≠¢È¢ÑÊµãËØØÂ∑ÆÁ¥ØÁßØ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ÁΩëÁªúÁªìÊûÑÔºöÈááÁî®ÂçïUNetÁªìÊûÑÔºåÂπ∂ÈíàÂØπVTON‰ªªÂä°ËøõË°å‰∫Ü‰ºòÂåñ„ÄÇ2) ÊçüÂ§±ÂáΩÊï∞ÔºöÈááÁî®Ê†áÂáÜÁöÑÊâ©Êï£Ê®°ÂûãÊçüÂ§±ÂáΩÊï∞„ÄÇ3) ËÆ≠ÁªÉÁ≠ñÁï•ÔºöÈááÁî®‰∫ÜÊîπËøõÁöÑÊó†ÂàÜÁ±ªÂô®ÂºïÂØºÁ≠ñÁï•ÂíåÁõ¥Êé•Ê≥®ÂÖ•ÁúüÂÆûÊúçË£ÖÊΩúÂú®ÂèòÈáèÁöÑÊñπÊ≥ï„ÄÇ4) ÂèÇÊï∞ËÆæÁΩÆÔºöÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞ÔºåËøôÈáå‰∏çÂÜçËµòËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Re-CatVTONÂú®ËôöÊãüËØïÁ©ø‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂú®FID„ÄÅKIDÂíåLPIPSÊåáÊ†á‰∏ä‰ºò‰∫éÂÖ∂ÂâçË∫´CatVTONÔºåÂπ∂‰∏îÂú®ËÆ°ÁÆóÊïàÁéá‰∏ä‰ºò‰∫éÈ´òÊÄßËÉΩÂèåUNetÊ®°ÂûãLeffa„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåRe-CatVTONÂú®‰øùËØÅSSIMÊåáÊ†áÁï•ÂæÆ‰∏ãÈôçÁöÑÊÉÖÂÜµ‰∏ãÔºåÊòæËëóÈôç‰Ωé‰∫ÜËÆ°ÁÆóÂíåÂÜÖÂ≠òÂºÄÈîÄÔºå‰∏∫ÂçïUNet VTONÊ®°ÂûãÂª∫Á´ã‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊïàÁéá-ÊÄßËÉΩÊùÉË°°„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂú®Á∫øË¥≠Áâ©„ÄÅËôöÊãüËØïË°£Èó¥Á≠âÈ¢ÜÂüüÔºåÂ∏ÆÂä©Áî®Êà∑Êõ¥Áõ¥ËßÇÂú∞‰∫ÜËß£ÊúçË£ÖÁöÑ‰∏äË∫´ÊïàÊûúÔºåÊèêÂçáË¥≠Áâ©‰ΩìÈ™å„ÄÇÊ≠§Â§ñÔºåËØ•ÊäÄÊúØËøòÂèØ‰ª•Â∫îÁî®‰∫éÊ∏∏Êàè„ÄÅÁ§æ‰∫§Â™í‰ΩìÁ≠âÈ¢ÜÂüüÔºå‰∏∫Áî®Êà∑Êèê‰æõ‰∏™ÊÄßÂåñÁöÑËôöÊãüÂΩ¢Ë±°ÂÆöÂà∂ÊúçÂä°„ÄÇÊú™Êù•ÔºåËØ•Á†îÁ©∂ÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞Êõ¥Â§çÊùÇÁöÑÊúçË£ÖÁ±ªÂûãÂíå‰∫∫‰ΩìÂßøÊÄÅÔºåÂÆûÁé∞Êõ¥ÈÄºÁúüÁöÑËôöÊãüËØïÁ©øÊïàÊûú„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Virtual Try-On (VTON) is the task of synthesizing an image of a person wearing a target garment, conditioned on a person image and a garment image. While diffusion-based VTON models featuring a Dual UNet architecture demonstrate superior fidelity compared to single UNet models, they incur substantial computational and memory overhead due to their heavy structure. In this study, through visualization analysis and theoretical analysis, we derived three hypotheses regarding the learning of context features to condition the denoising process. Based on these hypotheses, we developed Re-CatVTON, an efficient single UNet model that achieves high performance. We further enhance the model by introducing a modified classifier-free guidance strategy tailored for VTON's spatial concatenation conditioning, and by directly injecting the ground-truth garment latent derived from the clean garment latent to prevent the accumulation of prediction error. The proposed Re-CatVTON significantly improves performance compared to its predecessor (CatVTON) and requires less computation and memory than the high-performance Dual UNet model, Leffa. Our results demonstrate improved FID, KID, and LPIPS scores, with only a marginal decrease in SSIM, establishing a new efficiency-performance trade-off for single UNet VTON models.

