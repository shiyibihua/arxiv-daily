---
layout: default
title: GRIT-LP: Graph Transformer with Long-Range Skip Connection and Partitioned Spatial Graphs for Accurate Ice Layer Thickness Prediction
---

# GRIT-LP: Graph Transformer with Long-Range Skip Connection and Partitioned Spatial Graphs for Accurate Ice Layer Thickness Prediction

**arXiv**: [2511.18716v1](https://arxiv.org/abs/2511.18716) | [PDF](https://arxiv.org/pdf/2511.18716.pdf)

**ä½œè€…**: Zesheng Liu, Maryam Rahnemoonfar

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGRIT-LPå›¾å˜æ¢å™¨ï¼Œç»“åˆåˆ†åŒºç©ºé—´å›¾ä¸Žé•¿ç¨‹è·³è·ƒè¿žæŽ¥ï¼Œä»¥æå‡æžåœ°å†°å±‚åŽšåº¦é¢„æµ‹ç²¾åº¦**

**å…³é”®è¯**: `å›¾å˜æ¢å™¨` `å†°å±‚åŽšåº¦é¢„æµ‹` `é•¿ç¨‹è·³è·ƒè¿žæŽ¥` `åˆ†åŒºç©ºé—´å›¾` `æ—¶ç©ºæ¨¡å¼å»ºæ¨¡` `æžåœ°é›·è¾¾å›¾åƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå›¾å˜æ¢å™¨åœ¨æ·±åº¦å»ºæ¨¡ä¸­æ˜“å‡ºçŽ°è¿‡å¹³æ»‘å’Œé•¿ç¨‹ä¾èµ–å¼±åŒ–ï¼Œå½±å“å†°å±‚åŽšåº¦ä¼°è®¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åˆ†åŒºç©ºé—´å›¾æž„å»ºç­–ç•¥å’Œé•¿ç¨‹è·³è·ƒè¿žæŽ¥æœºåˆ¶ï¼Œå¢žå¼ºç©ºé—´ä¸€è‡´æ€§å’Œä¿¡æ¯æµåŠ¨ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ ¹å‡æ–¹è¯¯å·®ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•24.92%ï¼ŒéªŒè¯äº†æ¨¡åž‹åœ¨æ—¶ç©ºæ¨¡å¼å»ºæ¨¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Graph transformers have demonstrated remarkable capability on complex spatio-temporal tasks, yet their depth is often limited by oversmoothing and weak long-range dependency modeling. To address these challenges, we introduce GRIT-LP, a graph transformer explicitly designed for polar ice-layer thickness estimation from polar radar imagery. Accurately estimating ice layer thickness is critical for understanding snow accumulation, reconstructing past climate patterns and reducing uncertainties in projections of future ice sheet evolution and sea level rise. GRIT-LP combines an inductive geometric graph learning framework with self-attention mechanism, and introduces two major innovations that jointly address challenges in modeling the spatio-temporal patterns of ice layers: a partitioned spatial graph construction strategy that forms overlapping, fully connected local neighborhoods to preserve spatial coherence and suppress noise from irrelevant long-range links, and a long-range skip connection mechanism within the transformer that improves information flow and mitigates oversmoothing in deeper attention layers. We conducted extensive experiments, demonstrating that GRIT-LP outperforms current state-of-the-art methods with a 24.92\% improvement in root mean squared error. These results highlight the effectiveness of graph transformers in modeling spatiotemporal patterns by capturing both localized structural features and long-range dependencies across internal ice layers, and demonstrate their potential to advance data-driven understanding of cryospheric processes.

