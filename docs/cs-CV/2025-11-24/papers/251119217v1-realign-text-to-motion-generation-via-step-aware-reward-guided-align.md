---
layout: default
title: ReAlign: Text-to-Motion Generation via Step-Aware Reward-Guided Alignment
---

# ReAlign: Text-to-Motion Generation via Step-Aware Reward-Guided Alignment

**arXiv**: [2511.19217v1](https://arxiv.org/abs/2511.19217) | [PDF](https://arxiv.org/pdf/2511.19217.pdf)

**ä½œè€…**: Wanjiang Weng, Xiaofeng Tan, Junbo Wang, Guo-Sen Xie, Pan Zhou, Hongsong Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-24

**å¤‡æ³¨**: Accepted by AAAI 2026

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºReAlignï¼Œé€šè¿‡æ­¥è¿›å¼å¥–åŠ±å¼•å¯¼å¯¹é½å®žçŽ°é«˜è´¨é‡æ–‡æœ¬åˆ°åŠ¨ä½œç”Ÿæˆ**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°åŠ¨ä½œç”Ÿæˆ` `æ‰©æ•£æ¨¡åž‹` `å¥–åŠ±å¼•å¯¼` `å¯¹é½å­¦ä¹ ` `æ­¥è¿›å¼å¥–åŠ±æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ‰©æ•£æ¨¡åž‹åœ¨æ–‡æœ¬åˆ°åŠ¨ä½œç”Ÿæˆä¸­è¡¨çŽ°å‡ºæ½œåŠ›ï¼Œä½†æ–‡æœ¬å’ŒåŠ¨ä½œåˆ†å¸ƒçš„é”™ä½å¯¼è‡´è¯­ä¹‰ä¸ä¸€è‡´æˆ–ä½Žè´¨é‡çš„åŠ¨ä½œã€‚
2. ReAligné€šè¿‡æ­¥è¿›å¼å¥–åŠ±æ¨¡åž‹è¯„ä¼°å¯¹é½è´¨é‡ï¼Œå¹¶ä½¿ç”¨å¥–åŠ±å¼•å¯¼ç­–ç•¥ä¼˜åŒ–æ‰©æ•£è¿‡ç¨‹ï¼Œä»Žè€Œå®žçŽ°æ–‡æœ¬å’ŒåŠ¨ä½œçš„æ›´å¥½å¯¹é½ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒReAlignåœ¨æ–‡æœ¬-åŠ¨ä½œå¯¹é½å’ŒåŠ¨ä½œè´¨é‡æ–¹é¢æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œæå‡äº†ç”Ÿæˆæ•ˆæžœã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºå¥–åŠ±å¼•å¯¼é‡‡æ ·å¯¹é½ï¼ˆReAlignï¼‰çš„æ–¹æ³•ï¼Œç”¨äºŽè§£å†³æ–‡æœ¬åˆ°åŠ¨ä½œç”Ÿæˆä¸­ï¼Œæ‰©æ•£æ¨¡åž‹ä¸­æ–‡æœ¬å’ŒåŠ¨ä½œåˆ†å¸ƒä¸å¯¹é½çš„é—®é¢˜ã€‚ReAlignåŒ…å«ä¸€ä¸ªæ­¥è¿›å¼å¥–åŠ±æ¨¡åž‹ï¼Œç”¨äºŽè¯„ä¼°åŽ»å™ªé‡‡æ ·è¿‡ç¨‹ä¸­å¯¹é½è´¨é‡ï¼Œä»¥åŠä¸€ä¸ªå¥–åŠ±å¼•å¯¼ç­–ç•¥ï¼Œå¼•å¯¼æ‰©æ•£è¿‡ç¨‹æœç€æœ€ä½³å¯¹é½çš„åˆ†å¸ƒå‘å±•ã€‚è¯¥å¥–åŠ±æ¨¡åž‹é›†æˆäº†æ­¥è¿›å¼tokenï¼Œå¹¶ç»“åˆäº†ç”¨äºŽè¯­ä¹‰ä¸€è‡´æ€§çš„æ–‡æœ¬å¯¹é½æ¨¡å—å’Œç”¨äºŽçœŸå®žæ„Ÿçš„åŠ¨ä½œå¯¹é½æ¨¡å—ï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥ç»†åŒ–å™ªå£°åŠ¨ä½œï¼Œä»¥å¹³è¡¡æ¦‚çŽ‡å¯†åº¦å’Œå¯¹é½ã€‚åœ¨åŠ¨ä½œç”Ÿæˆå’Œæ£€ç´¢ä»»åŠ¡ä¸Šçš„å¤§é‡å®žéªŒè¡¨æ˜Žï¼Œä¸ŽçŽ°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†æ–‡æœ¬-åŠ¨ä½œå¯¹é½å’ŒåŠ¨ä½œè´¨é‡ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ–‡æœ¬åˆ°åŠ¨ä½œç”Ÿæˆæ—¨åœ¨æ ¹æ®ç»™å®šçš„æ–‡æœ¬æè¿°åˆæˆ3Däººä½“åŠ¨ä½œã€‚çŽ°æœ‰åŸºäºŽæ‰©æ•£æ¨¡åž‹çš„æ–¹æ³•è™½ç„¶èƒ½ç”Ÿæˆå¤šæ ·ä¸”é€¼çœŸçš„åŠ¨ä½œï¼Œä½†ç”±äºŽæ–‡æœ¬å’ŒåŠ¨ä½œåˆ†å¸ƒä¹‹é—´å­˜åœ¨ä¸å¯¹é½ï¼Œå¯¼è‡´ç”Ÿæˆçš„åŠ¨ä½œåœ¨è¯­ä¹‰ä¸Šä¸Žæ–‡æœ¬æè¿°ä¸ä¸€è‡´ï¼Œæˆ–è€…åŠ¨ä½œè´¨é‡ä¸é«˜ã€‚è¿™ç§ä¸å¯¹é½æ˜¯çŽ°æœ‰æ–¹æ³•çš„ä¸»è¦ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šReAlignçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨æ‰©æ•£æ¨¡åž‹çš„åŽ»å™ªé‡‡æ ·è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡ä¸€ä¸ªå¥–åŠ±æ¨¡åž‹æ¥è¯„ä¼°å½“å‰åŠ¨ä½œä¸Žæ–‡æœ¬æè¿°çš„å¯¹é½ç¨‹åº¦ï¼Œå¹¶æ ¹æ®è¿™ä¸ªå¥–åŠ±æ¥å¼•å¯¼é‡‡æ ·è¿‡ç¨‹ï¼Œä½¿å¾—ç”Ÿæˆçš„åŠ¨ä½œæœç€ä¸Žæ–‡æœ¬æè¿°æ›´å¯¹é½çš„æ–¹å‘å‘å±•ã€‚è¿™æ ·å¯ä»¥æœ‰æ•ˆåœ°ç¼©å°æ–‡æœ¬å’ŒåŠ¨ä½œåˆ†å¸ƒä¹‹é—´çš„å·®è·ï¼Œä»Žè€Œæé«˜ç”ŸæˆåŠ¨ä½œçš„è¯­ä¹‰ä¸€è‡´æ€§å’Œè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šReAlignä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šæ­¥è¿›å¼å¥–åŠ±æ¨¡åž‹å’Œå¥–åŠ±å¼•å¯¼ç­–ç•¥ã€‚æ­¥è¿›å¼å¥–åŠ±æ¨¡åž‹ç”¨äºŽè¯„ä¼°æ¯ä¸ªåŽ»å™ªæ­¥éª¤ä¸­åŠ¨ä½œä¸Žæ–‡æœ¬çš„å¯¹é½è´¨é‡ï¼Œå®ƒåŒ…å«æ–‡æœ¬å¯¹é½æ¨¡å—å’ŒåŠ¨ä½œå¯¹é½æ¨¡å—ï¼Œåˆ†åˆ«å…³æ³¨è¯­ä¹‰ä¸€è‡´æ€§å’ŒåŠ¨ä½œçœŸå®žæ„Ÿã€‚å¥–åŠ±å¼•å¯¼ç­–ç•¥åˆ™åˆ©ç”¨å¥–åŠ±æ¨¡åž‹æä¾›çš„ä¿¡å·ï¼Œè°ƒæ•´æ‰©æ•£è¿‡ç¨‹çš„é‡‡æ ·æ–¹å‘ï¼Œä½¿å¾—ç”Ÿæˆçš„åŠ¨ä½œåœ¨æ¯ä¸ªæ­¥éª¤éƒ½æœç€æ›´é«˜çš„å¥–åŠ±å€¼ï¼ˆå³æ›´å¥½çš„å¯¹é½ï¼‰å‘å±•ã€‚æ•´ä½“æµç¨‹æ˜¯åœ¨æ‰©æ•£æ¨¡åž‹çš„åŽ»å™ªè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸€æ­¥éƒ½ä½¿ç”¨å¥–åŠ±æ¨¡åž‹è¯„ä¼°å¯¹é½ç¨‹åº¦ï¼Œå¹¶æ ¹æ®å¥–åŠ±è°ƒæ•´é‡‡æ ·æ–¹å‘ï¼Œæœ€ç»ˆç”Ÿæˆä¸Žæ–‡æœ¬æè¿°é«˜åº¦å¯¹é½çš„åŠ¨ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šReAlignçš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†æ­¥è¿›å¼å¥–åŠ±æ¨¡åž‹å’Œå¥–åŠ±å¼•å¯¼ç­–ç•¥çš„ç»“åˆã€‚æ­¥è¿›å¼å¥–åŠ±æ¨¡åž‹èƒ½å¤Ÿæ›´ç²¾ç»†åœ°è¯„ä¼°æ¯ä¸ªåŽ»å™ªæ­¥éª¤ä¸­çš„å¯¹é½è´¨é‡ï¼Œè€Œå¥–åŠ±å¼•å¯¼ç­–ç•¥åˆ™èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨è¿™äº›è¯„ä¼°ç»“æžœæ¥ä¼˜åŒ–æ‰©æ•£è¿‡ç¨‹ã€‚è¿™ç§ç»“åˆä½¿å¾—ReAlignèƒ½å¤Ÿç”Ÿæˆæ›´é«˜è´¨é‡ã€è¯­ä¹‰æ›´ä¸€è‡´çš„åŠ¨ä½œã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒReAlignä¸æ˜¯ç®€å•åœ°è®­ç»ƒä¸€ä¸ªæ‰©æ•£æ¨¡åž‹ï¼Œè€Œæ˜¯é€šè¿‡åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­åŠ¨æ€åœ°è°ƒæ•´é‡‡æ ·æ–¹å‘æ¥ä¼˜åŒ–å¯¹é½ï¼Œè¿™æ˜¯ä¸€ç§æ›´æœ‰æ•ˆçš„æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šæ­¥è¿›å¼å¥–åŠ±æ¨¡åž‹åŒ…å«æ­¥è¿›å¼tokenï¼Œç”¨äºŽæ•æ‰ä¸åŒåŽ»å™ªæ­¥éª¤çš„ç‰¹å¾ã€‚æ–‡æœ¬å¯¹é½æ¨¡å—å’ŒåŠ¨ä½œå¯¹é½æ¨¡å—å¯ä»¥é‡‡ç”¨ä¸åŒçš„ç½‘ç»œç»“æž„ï¼Œä¾‹å¦‚Transformerå’Œè¿åŠ¨å­¦çº¦æŸç½‘ç»œã€‚å¥–åŠ±å¼•å¯¼ç­–ç•¥å¯ä»¥é‡‡ç”¨ä¸åŒçš„æ–¹æ³•ï¼Œä¾‹å¦‚æ¢¯åº¦ä¸Šå‡æˆ–é‡é‡‡æ ·ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦å¹³è¡¡æ¦‚çŽ‡å¯†åº¦å’Œå¯¹é½ç¨‹åº¦ï¼Œå¯ä»¥ä½¿ç”¨äº¤å‰ç†µæŸå¤±æˆ–å¯¹æ¯”æŸå¤±ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®éœ€è¦æ ¹æ®å®žéªŒç»“æžœè¿›è¡Œè°ƒæ•´ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒReAlignåœ¨HumanML3Då’ŒKIT-MLæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚åœ¨åŠ¨ä½œç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒReAlignåœ¨FIDå’ŒDiversityæŒ‡æ ‡ä¸Šå‡å–å¾—äº†æ˜¾è‘—æå‡ï¼Œè¡¨æ˜Žå…¶ç”Ÿæˆçš„åŠ¨ä½œè´¨é‡æ›´é«˜ã€å¤šæ ·æ€§æ›´ä¸°å¯Œã€‚åœ¨åŠ¨ä½œæ£€ç´¢ä»»åŠ¡ä¸­ï¼ŒReAlignåœ¨R@1å’ŒR@3æŒ‡æ ‡ä¸Šå‡å–å¾—äº†æ˜¾è‘—æå‡ï¼Œè¡¨æ˜Žå…¶èƒ½å¤Ÿæ›´å¥½åœ°å°†æ–‡æœ¬æè¿°ä¸Žç›¸åº”çš„åŠ¨ä½œåŒ¹é…èµ·æ¥ã€‚ä¾‹å¦‚ï¼Œåœ¨HumanML3Dæ•°æ®é›†ä¸Šï¼ŒReAlignçš„R@1æŒ‡æ ‡æ¯”çŽ°æœ‰æœ€ä½³æ–¹æ³•æé«˜äº†5%ä»¥ä¸Šã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

ReAlignåœ¨æ¸¸æˆã€ç”µå½±å’Œæœºå™¨äººç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚åœ¨æ¸¸æˆä¸­ï¼Œå®ƒå¯ä»¥ç”¨äºŽç”Ÿæˆè§’è‰²åŠ¨ç”»ï¼Œæé«˜æ¸¸æˆçš„çœŸå®žæ„Ÿå’Œäº’åŠ¨æ€§ã€‚åœ¨ç”µå½±åˆ¶ä½œä¸­ï¼Œå®ƒå¯ä»¥ç”¨äºŽç”Ÿæˆç‰¹æ•ˆåŠ¨ä½œï¼Œé™ä½Žåˆ¶ä½œæˆæœ¬ã€‚åœ¨æœºå™¨äººé¢†åŸŸï¼Œå®ƒå¯ä»¥ç”¨äºŽæŽ§åˆ¶æœºå™¨äººæ‰§è¡Œå¤æ‚çš„åŠ¨ä½œï¼Œæé«˜æœºå™¨äººçš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚æœªæ¥ï¼ŒReAlignå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–æ¨¡æ€çš„ç”Ÿæˆä»»åŠ¡ï¼Œä¾‹å¦‚æ–‡æœ¬åˆ°è¯­éŸ³ã€æ–‡æœ¬åˆ°å›¾åƒç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-to-motion generation, which synthesizes 3D human motions from text inputs, holds immense potential for applications in gaming, film, and robotics. Recently, diffusion-based methods have been shown to generate more diversity and realistic motion. However, there exists a misalignment between text and motion distributions in diffusion models, which leads to semantically inconsistent or low-quality motions. To address this limitation, we propose Reward-guided sampling Alignment (ReAlign), comprising a step-aware reward model to assess alignment quality during the denoising sampling and a reward-guided strategy that directs the diffusion process toward an optimally aligned distribution. This reward model integrates step-aware tokens and combines a text-aligned module for semantic consistency and a motion-aligned module for realism, refining noisy motions at each timestep to balance probability density and alignment. Extensive experiments of both motion generation and retrieval tasks demonstrate that our approach significantly improves text-motion alignment and motion quality compared to existing state-of-the-art methods.

