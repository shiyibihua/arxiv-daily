---
layout: default
title: Understanding, Accelerating, and Improving MeanFlow Training
---

# Understanding, Accelerating, and Improving MeanFlow Training

**arXiv**: [2511.19065v1](https://arxiv.org/abs/2511.19065) | [PDF](https://arxiv.org/pdf/2511.19065.pdf)

**ä½œè€…**: Jin-Young Kim, Hyojun Go, Lea Bogensperger, Julius Erbach, Nikolai Kalischek, Federico Tombari, Konrad Schindler, Dominik Narnhofer

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ”¹è¿›MeanFlowè®­ç»ƒæ–¹æ¡ˆä»¥åŠ é€Ÿæ”¶æ•›å¹¶æå‡å°‘æ­¥ç”Ÿæˆè´¨é‡**

**å…³é”®è¯**: `ç”Ÿæˆæ¨¡åž‹` `é€Ÿåº¦åœºå­¦ä¹ ` `è®­ç»ƒåŠ é€Ÿ` `å°‘æ­¥ç”Ÿæˆ` `å›¾åƒåˆæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åˆ†æžMeanFlowä¸­çž¬æ—¶ä¸Žå¹³å‡é€Ÿåº¦åœºäº¤äº’ï¼Œæ­ç¤ºå­¦ä¹ ä¾èµ–å…³ç³»ä¸Žé€€åŒ–æ¡ä»¶
2. è®¾è®¡è®­ç»ƒç­–ç•¥ï¼Œå…ˆåŠ é€Ÿçž¬æ—¶é€Ÿåº¦å½¢æˆï¼Œå†è½¬å‘é•¿é—´éš”å¹³å‡é€Ÿåº¦å­¦ä¹ 
3. å®žéªŒæ˜¾ç¤ºFIDé™è‡³2.87ï¼Œè®­ç»ƒæ—¶é—´ç¼©çŸ­2.5å€ï¼Œæˆ–ä½¿ç”¨æ›´å°éª¨å¹²ç½‘ç»œ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> MeanFlow promises high-quality generative modeling in few steps, by jointly learning instantaneous and average velocity fields. Yet, the underlying training dynamics remain unclear. We analyze the interaction between the two velocities and find: (i) well-established instantaneous velocity is a prerequisite for learning average velocity; (ii) learning of instantaneous velocity benefits from average velocity when the temporal gap is small, but degrades as the gap increases; and (iii) task-affinity analysis indicates that smooth learning of large-gap average velocities, essential for one-step generation, depends on the prior formation of accurate instantaneous and small-gap average velocities. Guided by these observations, we design an effective training scheme that accelerates the formation of instantaneous velocity, then shifts emphasis from short- to long-interval average velocity. Our enhanced MeanFlow training yields faster convergence and significantly better few-step generation: With the same DiT-XL backbone, our method reaches an impressive FID of 2.87 on 1-NFE ImageNet 256x256, compared to 3.43 for the conventional MeanFlow baseline. Alternatively, our method matches the performance of the MeanFlow baseline with 2.5x shorter training time, or with a smaller DiT-L backbone.

