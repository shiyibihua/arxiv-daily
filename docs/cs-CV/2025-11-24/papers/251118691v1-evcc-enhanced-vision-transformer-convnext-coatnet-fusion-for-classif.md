---
layout: default
title: EVCC: Enhanced Vision Transformer-ConvNeXt-CoAtNet Fusion for Classification
---

# EVCC: Enhanced Vision Transformer-ConvNeXt-CoAtNet Fusion for Classification

**arXiv**: [2511.18691v1](https://arxiv.org/abs/2511.18691) | [PDF](https://arxiv.org/pdf/2511.18691.pdf)

**ä½œè€…**: Kazi Reyazul Hasan, Md Nafiu Rahman, Wasif Jalal, Sadif Ahmed, Shahriar Raj, Mubasshira Musarrat, Muhammad Abdullah Adnan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEVCCèžåˆæž¶æž„ä»¥é«˜æ•ˆç»“åˆTransformerä¸ŽCNNï¼Œæå‡å›¾åƒåˆ†ç±»ç²¾åº¦å¹¶é™ä½Žè®¡ç®—æˆæœ¬ã€‚**

**å…³é”®è¯**: `å›¾åƒåˆ†ç±»` `æ··åˆæž¶æž„` `è‡ªé€‚åº”ä»¤ç‰Œå‰ªæž` `é—¨æŽ§äº¤å‰æ³¨æ„åŠ›` `å¤šä»»åŠ¡å­¦ä¹ ` `è®¡ç®—æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ··åˆè§†è§‰æž¶æž„è®¡ç®—æˆæœ¬é«˜ï¼Œéš¾ä»¥å¹³è¡¡ç²¾åº¦ä¸Žæ•ˆçŽ‡ã€‚
2. é›†æˆViTã€ConvNeXtå’ŒCoAtNetï¼Œé‡‡ç”¨è‡ªé€‚åº”ä»¤ç‰Œå‰ªæžå’Œé—¨æŽ§äº¤å‰æ³¨æ„åŠ›ã€‚
3. åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®žçŽ°SOTAç²¾åº¦ï¼ŒFLOPså‡å°‘25-35%ï¼Œæå‡è¾¾2ä¸ªç™¾åˆ†ç‚¹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Hybrid vision architectures combining Transformers and CNNs have significantly advanced image classification, but they usually do so at significant computational cost. We introduce EVCC (Enhanced Vision Transformer-ConvNeXt-CoAtNet), a novel multi-branch architecture integrating the Vision Transformer, lightweight ConvNeXt, and CoAtNet through key innovations: (1) adaptive token pruning with information preservation, (2) gated bidirectional cross-attention for enhanced feature refinement, (3) auxiliary classification heads for multi-task learning, and (4) a dynamic router gate employing context-aware confidence-driven weighting. Experiments across the CIFAR-100, Tobacco3482, CelebA, and Brain Cancer datasets demonstrate EVCC's superiority over powerful models like DeiT-Base, MaxViT-Base, and CrossViT-Base by consistently achieving state-of-the-art accuracy with improvements of up to 2 percentage points, while reducing FLOPs by 25 to 35%. Our adaptive architecture adjusts computational demands to deployment needs by dynamically reducing token count, efficiently balancing the accuracy-efficiency trade-off while combining global context, local details, and hierarchical features for real-world applications. The source code of our implementation is available at https://anonymous.4open.science/r/EVCC.

