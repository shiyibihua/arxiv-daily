---
layout: default
title: nnActive: A Framework for Evaluation of Active Learning in 3D Biomedical Segmentation
---

# nnActive: A Framework for Evaluation of Active Learning in 3D Biomedical Segmentation

**arXiv**: [2511.19183v1](https://arxiv.org/abs/2511.19183) | [PDF](https://arxiv.org/pdf/2511.19183.pdf)

**ä½œè€…**: Carsten T. LÃ¼th, Jeremias Traub, Kim-Celine Kahl, Till J. Bungert, Lukas Klein, Lars KrÃ¤mer, Paul F. Jaeger, Fabian Isensee, Klaus Maier-Hein

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºnnActiveæ¡†æž¶ä»¥è§£å†³3Dç”Ÿç‰©åŒ»å­¦åˆ†å‰²ä¸­ä¸»åŠ¨å­¦ä¹ è¯„ä¼°çš„ç¼ºé™·**

**å…³é”®è¯**: `ä¸»åŠ¨å­¦ä¹ ` `3Dç”Ÿç‰©åŒ»å­¦åˆ†å‰²` `nnU-Netæ‰©å±•` `æ ‡æ³¨æ•ˆçŽ‡` `éšæœºé‡‡æ ·ç­–ç•¥` `å¼€æºæ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼š3Dç”Ÿç‰©åŒ»å­¦åˆ†å‰²ä¾èµ–æ˜‚è´µæ ‡æ³¨ï¼Œä¸»åŠ¨å­¦ä¹ è¯„ä¼°å­˜åœ¨å››ä¸ªå¸¸è§ç¼ºé™·ï¼Œå¦‚æ•°æ®é›†é™åˆ¶å’ŒåŸºçº¿ä¸å½“ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šnnActiveæ‰©å±•nnU-Netï¼Œä½¿ç”¨éƒ¨åˆ†æ ‡æ³¨å’Œ3Dè¡¥ä¸æŸ¥è¯¢ï¼Œæ”¹è¿›éšæœºé‡‡æ ·ç­–ç•¥å’Œæ•ˆçŽ‡æŒ‡æ ‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å››ä¸ªæ•°æ®é›†ä¸Šï¼Œä¸»åŠ¨å­¦ä¹ ä¼˜äºŽæ ‡å‡†éšæœºé‡‡æ ·ï¼Œä½†æœªå¯é è¶…è¶Šæ”¹è¿›çš„éšæœºé‡‡æ ·ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Semantic segmentation is crucial for various biomedical applications, yet its reliance on large annotated datasets presents a bottleneck due to the high cost and specialized expertise required for manual labeling. Active Learning (AL) aims to mitigate this challenge by querying only the most informative samples, thereby reducing annotation effort. However, in the domain of 3D biomedical imaging, there is no consensus on whether AL consistently outperforms Random sampling. Four evaluation pitfalls hinder the current methodological assessment. These are (1) restriction to too few datasets and annotation budgets, (2) using 2D models on 3D images without partial annotations, (3) Random baseline not being adapted to the task, and (4) measuring annotation cost only in voxels. In this work, we introduce nnActive, an open-source AL framework that overcomes these pitfalls by (1) means of a large scale study spanning four biomedical imaging datasets and three label regimes, (2) extending nnU-Net by using partial annotations for training with 3D patch-based query selection, (3) proposing Foreground Aware Random sampling strategies tackling the foreground-background class imbalance of medical images and (4) propose the foreground efficiency metric, which captures the low annotation cost of background-regions. We reveal the following findings: (A) while all AL methods outperform standard Random sampling, none reliably surpasses an improved Foreground Aware Random sampling; (B) benefits of AL depend on task specific parameters; (C) Predictive Entropy is overall the best performing AL method, but likely requires the most annotation effort; (D) AL performance can be improved with more compute intensive design choices. As a holistic, open-source framework, nnActive can serve as a catalyst for research and application of AL in 3D biomedical imaging. Code is at: https://github.com/MIC-DKFZ/nnActive

