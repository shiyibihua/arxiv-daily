---
layout: default
title: DualGazeNet: A Biologically Inspired Dual-Gaze Query Network for Salient Object Detection
---

# DualGazeNet: A Biologically Inspired Dual-Gaze Query Network for Salient Object Detection

**arXiv**: [2511.18865v1](https://arxiv.org/abs/2511.18865) | [PDF](https://arxiv.org/pdf/2511.18865.pdf)

**ä½œè€…**: Yu Zhang, Haoan Ping, Yuchen Li, Zhenshan Bing, Fuchun Sun, Alois Knoll

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDualGazeNetä»¥ç®€åŒ–æ˜¾è‘—ç›®æ ‡æ£€æµ‹æž¶æž„å¹¶æå‡æ€§èƒ½**

**å…³é”®è¯**: `æ˜¾è‘—ç›®æ ‡æ£€æµ‹` `Transformeræž¶æž„` `ç”Ÿç‰©å¯å‘æ¨¡åž‹` `è®¡ç®—æ•ˆçŽ‡` `è·¨åŸŸæ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤æ‚SODæ–¹æ³•å¯¼è‡´ç‰¹å¾å†—ä½™å’Œæ€§èƒ½ç“¶é¢ˆ
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽTransformeræ¨¡æ‹Ÿäººç±»è§†è§‰åŒé€šè·¯å¤„ç†æœºåˆ¶
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†ä¸Šè¶…è¶Š25ç§æ–¹æ³•ï¼Œé€Ÿåº¦å’Œæ•ˆçŽ‡æ˜¾è‘—æå‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent salient object detection (SOD) methods aim to improve performance in four key directions: semantic enhancement, boundary refinement, auxiliary task supervision, and multi-modal fusion. In pursuit of continuous gains, these approaches have evolved toward increasingly sophisticated architectures with multi-stage pipelines, specialized fusion modules, edge-guided learning, and elaborate attention mechanisms. However, this complexity paradoxically introduces feature redundancy and cross-component interference that obscure salient cues, ultimately reaching performance bottlenecks. In contrast, human vision achieves efficient salient object identification without such architectural complexity. This contrast raises a fundamental question: can we design a biologically grounded yet architecturally simple SOD framework that dispenses with most of this engineering complexity, while achieving state-of-the-art accuracy, computational efficiency, and interpretability? In this work, we answer this question affirmatively by introducing DualGazeNet, a biologically inspired pure Transformer framework that models the dual biological principles of robust representation learning and magnocellular-parvocellular dual-pathway processing with cortical attention modulation in the human visual system. Extensive experiments on five RGB SOD benchmarks show that DualGazeNet consistently surpasses 25 state-of-the-art CNN- and Transformer-based methods. On average, DualGazeNet achieves about 60\% higher inference speed and 53.4\% fewer FLOPs than four Transformer-based baselines of similar capacity (VST++, MDSAM, Sam2unet, and BiRefNet). Moreover, DualGazeNet exhibits strong cross-domain generalization, achieving leading or highly competitive performance on camouflaged and underwater SOD benchmarks without relying on additional modalities.

