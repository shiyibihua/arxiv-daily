---
layout: default
title: IDEAL-M3D: Instance Diversity-Enriched Active Learning for Monocular 3D Detection
---

# IDEAL-M3D: Instance Diversity-Enriched Active Learning for Monocular 3D Detection

**arXiv**: [2511.19301v1](https://arxiv.org/abs/2511.19301) | [PDF](https://arxiv.org/pdf/2511.19301.pdf)

**ä½œè€…**: Johannes Meier, Florian GÃ¼nther, Riccardo Marin, Oussema Dhaouadi, Jacques Kaiser, Daniel Cremers

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIDEAL-M3Dä»¥è§£å†³å•ç›®3Dæ£€æµ‹ä¸­ä¸»åŠ¨å­¦ä¹ çš„å®žä¾‹å¤šæ ·æ€§å’Œæ ‡æ³¨æ•ˆçŽ‡é—®é¢˜**

**å…³é”®è¯**: `å•ç›®3Dæ£€æµ‹` `ä¸»åŠ¨å­¦ä¹ ` `å®žä¾‹å¤šæ ·æ€§` `æ ‡æ³¨æ•ˆçŽ‡` `æ·±åº¦ä¼°è®¡` `KITTIæ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ä¸»åŠ¨å­¦ä¹ æ–¹æ³•é€‰æ‹©æ•´å¼ å›¾åƒï¼Œæ•ˆçŽ‡ä½Žï¼Œä¸”åå‘æ·±åº¦æ¨¡ç³Šçš„è¿œè·ç¦»ç‰©ä½“
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å®žä¾‹çº§ç®¡é“ï¼Œé€šè¿‡å¼‚æž„éª¨å¹²ç½‘ç»œå’Œä»»åŠ¡æ— å…³ç‰¹å¾å¢žå¼ºå¤šæ ·æ€§
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨KITTIæ•°æ®é›†ä¸Šï¼Œä»…ç”¨60%æ ‡æ³¨è¾¾åˆ°ç›¸ä¼¼æˆ–æ›´é«˜AP3Dï¼ŒèŠ‚çœèµ„æº

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Monocular 3D detection relies on just a single camera and is therefore easy to deploy. Yet, achieving reliable 3D understanding from monocular images requires substantial annotation, and 3D labels are especially costly. To maximize performance under constrained labeling budgets, it is essential to prioritize annotating samples expected to deliver the largest performance gains. This prioritization is the focus of active learning. Curiously, we observed two significant limitations in active learning algorithms for 3D monocular object detection. First, previous approaches select entire images, which is inefficient, as non-informative instances contained in the same image also need to be labeled. Secondly, existing methods rely on uncertainty-based selection, which in monocular 3D object detection creates a bias toward depth ambiguity. Consequently, distant objects are selected, while nearby objects are overlooked.
>   To address these limitations, we propose IDEAL-M3D, the first instance-level pipeline for monocular 3D detection. For the first time, we demonstrate that an explicitly diverse, fast-to-train ensemble improves diversity-driven active learning for monocular 3D. We induce diversity with heterogeneous backbones and task-agnostic features, loss weight perturbation, and time-dependent bagging. IDEAL-M3D shows superior performance and significant resource savings: with just 60% of the annotations, we achieve similar or better AP3D on KITTI validation and test set results compared to training the same detector on the whole dataset.

