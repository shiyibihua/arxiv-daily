---
layout: default
title: FedPoisonTTP: A Threat Model and Poisoning Attack for Federated Test-Time Personalization
---

# FedPoisonTTP: A Threat Model and Poisoning Attack for Federated Test-Time Personalization

**arXiv**: [2511.19248v1](https://arxiv.org/abs/2511.19248) | [PDF](https://arxiv.org/pdf/2511.19248.pdf)

**ä½œè€…**: Md Akil Raihan Iftee, Syed Md. Ahnaf Hasan, Amin Ahsan Ali, AKM Mahbubur Rahman, Sajib Mistry, Aneesh Krishna

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFedPoisonTTPå¨èƒæ¨¡åž‹ä¸Žæ”»å‡»æ–¹æ³•ï¼Œä»¥è§£å†³è”é‚¦æµ‹è¯•æ—¶ä¸ªæ€§åŒ–ä¸­çš„å®‰å…¨é£Žé™©**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `æµ‹è¯•æ—¶ä¸ªæ€§åŒ–` `ä¸­æ¯’æ”»å‡»` `å¨èƒæ¨¡åž‹` `å¯¹æŠ—æ€§æ›´æ–°` `å®‰å…¨æ¼æ´ž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè”é‚¦æµ‹è¯•æ—¶ä¸ªæ€§åŒ–ä¸­ï¼Œæœ¬åœ°é€‚åº”æ˜“å—ä¸­æ¯’æ”»å‡»ï¼Œå¨èƒå…¨å±€ä¸Žå®¢æˆ·ç«¯æ€§èƒ½
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨ä»£ç†æ¨¡åž‹è’¸é¦å’Œç‰¹å¾ä¸€è‡´æ€§åˆæˆä¸­æ¯’è¾“å…¥ï¼Œä¼˜åŒ–æ”»å‡»ç›®æ ‡ä»¥è§„é¿è¿‡æ»¤
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨è§†è§‰åŸºå‡†æµ‹è¯•ä¸­ï¼Œä¸­æ¯’æ”»å‡»æ˜¾è‘—é™ä½Žæµ‹è¯•æ—¶æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Test-time personalization in federated learning enables models at clients to adjust online to local domain shifts, enhancing robustness and personalization in deployment. Yet, existing federated learning work largely overlooks the security risks that arise when local adaptation occurs at test time. Heterogeneous domain arrivals, diverse adaptation algorithms, and limited cross-client visibility create vulnerabilities where compromised participants can craft poisoned inputs and submit adversarial updates that undermine both global and per-client performance. To address this threat, we introduce FedPoisonTTP, a realistic grey-box attack framework that explores test-time data poisoning in the federated adaptation setting. FedPoisonTTP distills a surrogate model from adversarial queries, synthesizes in-distribution poisons using feature-consistency, and optimizes attack objectives to generate high-entropy or class-confident poisons that evade common adaptation filters. These poisons are injected during local adaptation and spread through collaborative updates, leading to broad degradation. Extensive experiments on corrupted vision benchmarks show that compromised participants can substantially diminish overall test-time performance.

