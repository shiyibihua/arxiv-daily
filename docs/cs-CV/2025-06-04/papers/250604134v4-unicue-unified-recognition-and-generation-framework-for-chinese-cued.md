---
layout: default
title: UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation
---

# UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04134" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.04134v4</a>
  <a href="https://arxiv.org/pdf/2506.04134.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04134v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04134v4', 'UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Jinting Wang, Shan Yang, Chenxing Li, Dong Yu, Li Liu

**ÂàÜÁ±ª**: cs.CV, cs.SD, eess.AS

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-04 (Êõ¥Êñ∞: 2025-11-11)

**Â§áÊ≥®**: 13 pages, 12 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫UniCUEÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥‰∏≠ÊñáÊâãËØ≠ËßÜÈ¢ëÂà∞ËØ≠Èü≥ÁîüÊàêÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÊâãËØ≠ËØÜÂà´` `ËßÜÈ¢ëÂà∞ËØ≠Èü≥ÁîüÊàê` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ËßÜËßâËØ≠‰πâÂØπÈΩê` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂ§ö‰æùËµñÊñáÊú¨‰Ωú‰∏∫‰∏≠‰ªãÔºåÂØºËá¥ÈîôËØØ‰º†Êí≠ÂíåÊó∂Èó¥Èîô‰ΩçÔºåÂΩ±ÂìçËØ≠Èü≥ÁîüÊàêÁöÑÂáÜÁ°ÆÊÄß„ÄÇ
2. UniCUEÊ°ÜÊû∂Áõ¥Êé•‰ªéCSËßÜÈ¢ëÁîüÊàêËØ≠Èü≥ÔºåÊï¥Âêà‰∫ÜÁêÜËß£‰ªªÂä°‰ª•Êèê‰æõËßÜËßâËØ≠‰πâÁ∫øÁ¥¢ÔºåÊèêÂçáÁîüÊàêÊïàÊûú„ÄÇ
3. Âú®ÊûÑÂª∫ÁöÑUniCUE-HIÊï∞ÊçÆÈõÜ‰∏äÔºåUniCUEÂú®Â§ö‰∏™ËØÑ‰º∞ÊåáÊ†á‰∏äË°®Áé∞‰ºòÂºÇÔºåËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÊ∞¥Âπ≥„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÊâãËØ≠ÔºàCued Speech, CSÔºâÈÄöËøáÊâãÂäøÁºñÁ†ÅÂ¢ûÂº∫ÂîáËØªËÉΩÂäõÔºå‰∏∫Âê¨Èöú‰∫∫Â£´Êèê‰æõËßÜËßâÈü≥Á¥†Á∫øÁ¥¢ÔºåÊîØÊåÅÁ≤æÁ°ÆÁöÑËØ≠Èü≥ÊÑüÁü•„ÄÇCSËßÜÈ¢ëÂà∞ËØ≠Èü≥ÁîüÊàêÔºàCSV2SÔºâ‰ªªÂä°Êó®Âú®Â∞ÜCSËßÜÈ¢ëËΩ¨Êç¢‰∏∫ÂèØÁêÜËß£ÁöÑËØ≠Èü≥‰ø°Âè∑„ÄÇÁé∞ÊúâÁ†îÁ©∂Â§öÈõÜ‰∏≠‰∫éCSËØÜÂà´ÔºàCSRÔºâÔºåÂ∞ÜËßÜÈ¢ëÂÜÖÂÆπËΩ¨ÂΩï‰∏∫ÊñáÊú¨ÔºåÂØºËá¥CSV2S‰æùËµñÊñáÊú¨‰Ωú‰∏∫‰∏≠‰ªãÔºåÂèØËÉΩÂºïÂèëÈîôËØØ‰º†Êí≠ÂíåÊó∂Èó¥Èîô‰Ωç„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫UniCUEÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™Áªü‰∏ÄÁöÑCSV2SÊ°ÜÊû∂ÔºåÁõ¥Êé•‰ªéCSËßÜÈ¢ëÁîüÊàêËØ≠Èü≥ÔºåÊó†ÈúÄ‰∏≠‰ªãÊñáÊú¨„ÄÇUniCUEÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÊï¥ÂêàÁêÜËß£‰ªªÂä°ÔºàCSRÔºâÔºåÊèê‰æõÁªÜÁ≤íÂ∫¶ÁöÑCSËßÜËßâËØ≠‰πâÁ∫øÁ¥¢‰ª•ÊåáÂØºËØ≠Èü≥ÁîüÊàêÔºåÂπ∂ÊûÑÂª∫‰∫ÜUniCUE-HIÊï∞ÊçÆÈõÜÔºåÂåÖÂê´11282‰∏™ËßÜÈ¢ëÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéUniCUEÂú®Â§ö‰∏™ËØÑ‰º∞ÊåáÊ†á‰∏äËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰∏≠ÊñáÊâãËØ≠ËßÜÈ¢ëÂà∞ËØ≠Èü≥ÁîüÊàêÔºàCSV2SÔºâ‰∏≠ÁöÑ‰∏≠‰ªãÊñáÊú¨‰æùËµñÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â∞ÜCSËßÜÈ¢ëËΩ¨Âåñ‰∏∫ËØ≠Èü≥Êó∂ÔºåÂ∏∏Â∏∏‰æùËµñ‰∫éÊñáÊú¨ËΩ¨ÂΩïÔºåÂØºËá¥ÈîôËØØ‰º†Êí≠ÂíåÊó∂Èó¥Èîô‰ΩçÔºåÂΩ±ÂìçÁîüÊàêÊïàÊûú„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöUniCUEÊ°ÜÊû∂ÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÁõ¥Êé•‰ªéCSËßÜÈ¢ëÁîüÊàêËØ≠Èü≥ÔºåÈÅøÂÖç‰∏≠‰ªãÊñáÊú¨ÁöÑ‰ΩøÁî®„ÄÇÈÄöËøáÊï¥ÂêàÁêÜËß£‰ªªÂä°ÔºàCSRÔºâÔºåUniCUEËÉΩÂ§üÊèê‰æõÁªÜÁ≤íÂ∫¶ÁöÑËßÜËßâËØ≠‰πâÁ∫øÁ¥¢Ôºå‰ªéËÄåÊåáÂØºËØ≠Èü≥ÁîüÊàêËøáÁ®ã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöUniCUEÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂßøÊÄÅÊÑüÁü•ËßÜËßâÂ§ÑÁêÜÂô®„ÄÅËØ≠‰πâÂØπÈΩêÊ±†ÂíåËßÜËßâÈü≥Á¥†ÈÄÇÈÖçÂô®„ÄÇËøô‰∫õÊ®°ÂùóÂÖ±ÂêåÂ∑•‰ΩúÔºåÂÆûÁé∞ËßÜËßâ‰ø°ÊÅØ‰∏éËØ≠Èü≥ÁîüÊàêÁöÑÊúâÊïàÂØπÊé•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöUniCUEÁöÑÊúÄÂ§ßÂàõÊñ∞Âú®‰∫éÂÖ∂Áªü‰∏ÄÁöÑÊû∂ÊûÑËÆæËÆ°ÔºåËÉΩÂ§üÂêåÊó∂Â§ÑÁêÜÁêÜËß£ÂíåÁîüÊàê‰ªªÂä°ÔºåÊèê‰æõÊõ¥‰∏∫Á≤æÂáÜÁöÑËßÜËßâËØ≠‰πâÊò†Â∞ÑÔºå‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåÂáèÂ∞ë‰∫Ü‰∏≠‰ªãÁéØËäÇÂ∏¶Êù•ÁöÑËØØÂ∑Æ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÊäÄÊúØÁªÜËäÇ‰∏äÔºåUniCUEÈááÁî®‰∫ÜÂ§öÂ±ÇÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÔºàCNNÔºâËøõË°åËßÜËßâÁâπÂæÅÊèêÂèñÔºåÁªìÂêàËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ËøõË°åËØ≠‰πâÂØπÈΩêÔºåÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°‰∏äÂàôËÄÉËôë‰∫ÜÁîüÊàêËØ≠Èü≥ÁöÑËá™ÁÑ∂ÊÄßÂíåÊµÅÁïÖÊÄßÔºåÁ°Æ‰øùÁîüÊàêÁªìÊûúÁöÑÈ´òË¥®Èáè„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®UniCUE-HIÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåUniCUEÂú®Â§ö‰∏™ËØÑ‰º∞ÊåáÊ†á‰∏äË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÂü∫Á∫øÊñπÊ≥ïÔºåÂÖ∑‰ΩìÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶ËææÂà∞10%‰ª•‰∏äÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®CSËßÜÈ¢ëÂà∞ËØ≠Èü≥ÁîüÊàê‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÂÖàËøõÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Âê¨Èöú‰∫∫Â£´ÁöÑËæÖÂä©Ê≤üÈÄöÂ∑•ÂÖ∑„ÄÅÊïôËÇ≤È¢ÜÂüüÁöÑËØ≠Èü≥ÁîüÊàêÁ≥ªÁªü‰ª•ÂèäÂ§öÊ®°ÊÄÅ‰∫§‰∫íÊäÄÊúØ„ÄÇÈÄöËøáÁõ¥Êé•ÁîüÊàêËØ≠Èü≥ÔºåUniCUEËÉΩÂ§üÊòæËëóÊèêÂçáÂê¨Èöú‰∫∫Â£´ÁöÑ‰∫§ÊµÅÊïàÁéáÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÁ§æ‰ºö‰ª∑ÂÄºÂíåÂÆûÈôÖÊÑè‰πâ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Cued Speech (CS) enhances lipreading via hand coding, offering visual phonemic cues that support precise speech perception for the hearing-impaired. The task of CS Video-to-Speech generation (CSV2S) aims to convert CS videos into intelligible speech signals. Most existing research focuses on CS Recognition (CSR), which transcribes video content into text. Consequently, a common solution for CSV2S is to integrate CSR with a text-to-speech (TTS) system. However, this pipeline relies on text as an intermediate medium, which may lead to error propagation and temporal misalignment between speech and CS video dynamics. In contrast, directly generating audio speech from CS video (direct CSV2S) often suffers from the inherent multimodal complexity and the limited availability of CS data. To address these challenges, we propose UniCUE, the first unified framework for CSV2S that directly generates speech from CS videos without relying on intermediate text. The core innovation of UniCUE lies in integrating an understanding task (CSR) that provides fine-grained CS visual-semantic cues to guide speech generation. Specifically, UniCUE incorporates a pose-aware visual processor, a semantic alignment pool that enables precise visual-semantic mapping, and a VisioPhonetic adapter to bridge the understanding and generation tasks within a unified architecture. To support this framework, we construct UniCUE-HI, a large-scale Mandarin CS dataset containing 11282 videos from 14 cuers, including both hearing-impaired and normal-hearing individuals. Extensive experiments on this dataset demonstrate that UniCUE achieves state-of-the-art performance across multiple evaluation metrics.

