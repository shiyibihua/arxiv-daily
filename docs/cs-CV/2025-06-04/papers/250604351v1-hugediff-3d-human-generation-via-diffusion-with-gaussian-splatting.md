---
layout: default
title: HuGeDiff: 3D Human Generation via Diffusion with Gaussian Splatting
---

# HuGeDiff: 3D Human Generation via Diffusion with Gaussian Splatting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04351" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04351v1</a>
  <a href="https://arxiv.org/pdf/2506.04351.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04351v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04351v1', 'HuGeDiff: 3D Human Generation via Diffusion with Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Maksym Ivashechkin, Oscar Mendez, Richard Bowden

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHuGeDiffä»¥è§£å†³3Däººç±»ç”Ÿæˆçš„æ§åˆ¶ä¸ç»†èŠ‚é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `3Däººç±»ç”Ÿæˆ` `æ‰©æ•£æ¨¡å‹` `å›¾åƒç”Ÿæˆ` `ç‚¹äº‘å¤„ç†` `è®¡ç®—æœºè§†è§‰` `è™šæ‹Ÿç°å®` `ç”Ÿæˆæ€§AI`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„3Däººç±»ç”Ÿæˆæ–¹æ³•åœ¨ç»†èŠ‚è¡¨ç°ã€çœŸå®æ„Ÿå’Œå¯æ§æ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨æ‰‹éƒ¨å’Œé¢éƒ¨çš„æ¸²æŸ“ä¸Šã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å¼±ç›‘ç£çš„ç”Ÿæˆç®¡é“ï¼Œé€šè¿‡å›¾åƒæ‰©æ•£æ¨¡å‹ç”Ÿæˆå¯æ§å±æ€§çš„å›¾åƒæ•°æ®é›†ï¼Œå¹¶å°†å…¶æ˜ å°„åˆ°3Dç‚¹äº‘ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œ3Däººç±»ç”Ÿæˆé€Ÿåº¦æå‡äº†å¤šä¸ªæ•°é‡çº§ï¼Œæ–‡æœ¬æç¤ºå¯¹é½åº¦å’Œæ¸²æŸ“è´¨é‡æ˜¾è‘—æ”¹å–„ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

3Däººç±»ç”Ÿæˆæ˜¯è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ä¸­çš„é‡è¦é—®é¢˜ï¼Œå°½ç®¡ç”Ÿæˆæ€§AIå’Œæ¸²æŸ“æ–¹æ³•å–å¾—äº†è¿›å±•ï¼Œä½†ä»æ–‡æœ¬æç¤ºç”Ÿæˆå‡†ç¡®çš„3Däººç±»ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç»†èŠ‚ã€æ‰‹éƒ¨å’Œé¢éƒ¨çš„å‡†ç¡®æ¸²æŸ“ã€äººç±»çœŸå®æ„ŸåŠå¤–è§‚å¯æ§æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¼±ç›‘ç£ç®¡é“ï¼Œé¦–å…ˆåˆ©ç”¨å…ˆè¿›çš„å›¾åƒæ‰©æ•£æ¨¡å‹ç”Ÿæˆå…·æœ‰å¯æ§å±æ€§çš„é€¼çœŸå›¾åƒæ•°æ®é›†ï¼Œæ¥ç€é‡‡ç”¨åŸºäºå˜æ¢å™¨çš„æ¶æ„é«˜æ•ˆæ˜ å°„å›¾åƒç‰¹å¾åˆ°3Dç‚¹äº‘ï¼Œæœ€åè®­ç»ƒä¸€ä¸ªåŸºäºç‚¹äº‘çš„æ‰©æ•£æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†3Däººç±»ç”Ÿæˆçš„é€Ÿåº¦ã€æ–‡æœ¬æç¤ºå¯¹é½åº¦ã€çœŸå®æ„Ÿå’Œæ¸²æŸ“è´¨é‡ã€‚ä»£ç å’Œæ•°æ®é›†å°†å…¬å¼€å‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»æ–‡æœ¬æç¤ºç”Ÿæˆé«˜è´¨é‡3Däººç±»æ¨¡å‹çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ç»†èŠ‚ã€çœŸå®æ„Ÿå’Œå¯æ§æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨æ‰‹éƒ¨å’Œé¢éƒ¨çš„è¡¨ç°ä¸Šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§å¼±ç›‘ç£çš„ç”Ÿæˆç®¡é“ï¼Œé¦–å…ˆç”Ÿæˆå…·æœ‰å¯æ§å±æ€§çš„é€¼çœŸå›¾åƒæ•°æ®é›†ï¼Œç„¶åé€šè¿‡å˜æ¢å™¨æ¶æ„å°†å›¾åƒç‰¹å¾æ˜ å°„åˆ°3Dç‚¹äº‘ï¼Œæœ€åè®­ç»ƒä¸€ä¸ªåŸºäºç‚¹äº‘çš„æ‰©æ•£æ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åˆ†ä¸ºä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä½¿ç”¨å›¾åƒæ‰©æ•£æ¨¡å‹ç”Ÿæˆå›¾åƒæ•°æ®é›†ï¼Œç¬¬äºŒé˜¶æ®µé€šè¿‡å˜æ¢å™¨æ¶æ„è¿›è¡Œç‰¹å¾æ˜ å°„ï¼Œç¬¬ä¸‰é˜¶æ®µè®­ç»ƒç‚¹äº‘æ‰©æ•£æ¨¡å‹ä»¥å®ç°æ–‡æœ¬æç¤ºçš„æ¡ä»¶ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºç»“åˆå›¾åƒæ‰©æ•£æ¨¡å‹ä¸ç‚¹äº‘ç”Ÿæˆçš„åŒé‡æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆçš„é€Ÿåº¦å’Œè´¨é‡ï¼Œå°¤å…¶æ˜¯åœ¨ç»†èŠ‚å’ŒçœŸå®æ„Ÿæ–¹é¢ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å…ˆè¿›çš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç”Ÿæˆè´¨é‡ï¼Œå¹¶åœ¨å˜æ¢å™¨æ¶æ„ä¸­å¼•å…¥äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®ï¼Œä»¥æé«˜ç‰¹å¾æ˜ å°„çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒHuGeDiffåœ¨3Däººç±»ç”Ÿæˆé€Ÿåº¦ä¸Šç›¸æ¯”ç°æœ‰æ–¹æ³•æå‡äº†å¤šä¸ªæ•°é‡çº§ï¼ŒåŒæ—¶åœ¨æ–‡æœ¬æç¤ºå¯¹é½åº¦å’Œæ¸²æŸ“è´¨é‡ä¸Šä¹Ÿæœ‰æ˜¾è‘—æ”¹å–„ï¼Œå±•ç¤ºäº†å…¶åœ¨ç”Ÿæˆæ€§AIé¢†åŸŸçš„å¼ºå¤§èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è®¡ç®—æœºè§†è§‰ã€è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡ç”Ÿæˆé«˜è´¨é‡çš„3Däººç±»æ¨¡å‹ï¼Œå¯ä»¥ä¸ºåŠ¨ç”»åˆ¶ä½œã€è™šæ‹Ÿè§’è‰²è®¾è®¡ä»¥åŠäººæœºäº¤äº’æä¾›æ›´çœŸå®çš„ä½“éªŒï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> 3D human generation is an important problem with a wide range of applications in computer vision and graphics. Despite recent progress in generative AI such as diffusion models or rendering methods like Neural Radiance Fields or Gaussian Splatting, controlling the generation of accurate 3D humans from text prompts remains an open challenge. Current methods struggle with fine detail, accurate rendering of hands and faces, human realism, and controlability over appearance. The lack of diversity, realism, and annotation in human image data also remains a challenge, hindering the development of a foundational 3D human model. We present a weakly supervised pipeline that tries to address these challenges. In the first step, we generate a photorealistic human image dataset with controllable attributes such as appearance, race, gender, etc using a state-of-the-art image diffusion model. Next, we propose an efficient mapping approach from image features to 3D point clouds using a transformer-based architecture. Finally, we close the loop by training a point-cloud diffusion model that is conditioned on the same text prompts used to generate the original samples. We demonstrate orders-of-magnitude speed-ups in 3D human generation compared to the state-of-the-art approaches, along with significantly improved text-prompt alignment, realism, and rendering quality. We will make the code and dataset available.

