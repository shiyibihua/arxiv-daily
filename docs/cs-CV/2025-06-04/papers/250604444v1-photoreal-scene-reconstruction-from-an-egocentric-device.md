---
layout: default
title: Photoreal Scene Reconstruction from an Egocentric Device
---

# Photoreal Scene Reconstruction from an Egocentric Device

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04444" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.04444v1</a>
  <a href="https://arxiv.org/pdf/2506.04444.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04444v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04444v1', 'Photoreal Scene Reconstruction from an Egocentric Device')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zhaoyang Lv, Maurizio Monge, Ka Chen, Yufeng Zhu, Michael Goesele, Jakob Engel, Zhao Dong, Richard Newcombe

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.GR, cs.HC, cs.MM

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-04

**Â§áÊ≥®**: Paper accepted to SIGGRAPH Conference Paper 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ËßÜËßâÊÉØÊÄßÊùüË∞ÉÊï¥‰ª•Ëß£ÂÜ≥ÊªöÂä®Âø´Èó®Áõ∏Êú∫ÈáçÂª∫ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±ÂÖ≠ÔºöËßÜÈ¢ëÊèêÂèñ‰∏éÂåπÈÖç (Video Extraction)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâÊÉØÊÄßÊµãÁ®ã` `ÊªöÂä®Âø´Èó®` `È´òÂä®ÊÄÅËåÉÂõ¥` `Âú∫ÊôØÈáçÂª∫` `Áâ©ÁêÜÂõæÂÉèÂΩ¢Êàê` `È´òÊñØÁÇπ‰∫ë` `Ëá™Êàë‰∏≠ÂøÉËÆæÂ§á`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®‰ΩøÁî®Ëá™Êàë‰∏≠ÂøÉËÆæÂ§áËøõË°åÂú∫ÊôØÈáçÂª∫Êó∂ÔºåÂæÄÂæÄÂøΩÁï•‰∫ÜÊªöÂä®Âø´Èó®Áõ∏Êú∫ÁöÑÊó∂Èó¥Êà≥ÂíåËøêÂä®Ê†°ÂáÜÔºåÂØºËá¥ÈáçÂª∫Á≤æÂ∫¶‰∏çË∂≥„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰ΩøÁî®ËßÜËßâÊÉØÊÄßÊùüË∞ÉÊï¥ÔºàVIBAÔºâÊù•Á≤æÁ°ÆÊ†°ÂáÜÊªöÂä®Âø´Èó®Áõ∏Êú∫ÁöÑÊó∂Èó¥Êà≥ÔºåÂπ∂ÁªìÂêàÁâ©ÁêÜÂõæÂÉèÂΩ¢ÊàêÊ®°Âûã‰ª•ÊîπÂñÑÈáçÂª∫ÊïàÊûú„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÈááÁî®VIBAÂêéPSNRÊèêÂçá‰∫Ü+1 dBÔºåÁªìÂêàÂõæÂÉèÂΩ¢ÊàêÊ®°ÂûãÂêéÂÜçÊèêÂçá+1 dBÔºåÈ™åËØÅ‰∫ÜÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÁ†îÁ©∂‰∫Ü‰ΩøÁî®Ëá™Êàë‰∏≠ÂøÉËÆæÂ§áËøõË°åÈ´òÂä®ÊÄÅËåÉÂõ¥Âú∫ÊôØÁöÑÁúüÂÆûÊÑüÈáçÂª∫ÊâÄÈù¢‰∏¥ÁöÑÊåëÊàò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÂÅáËÆæ‰ΩøÁî®ËÆæÂ§áÁöÑËßÜËßâÊÉØÊÄßÊµãÁ®ãÁ≥ªÁªü‰º∞ËÆ°ÁöÑÂ∏ßÈÄüÁéá6DoF‰ΩçÂßøÔºåËøôÂèØËÉΩÂøΩÁï•‰∫ÜÂÉèÁ¥†Á∫ßÈáçÂª∫ÊâÄÈúÄÁöÑÂÖ≥ÈîÆÁªÜËäÇ„ÄÇÁ†îÁ©∂ÊèêÂá∫‰∫Ü‰∏§È°πÈáçË¶ÅÂèëÁé∞ÔºöÈ¶ñÂÖàÔºå‰∏é‰∏ªÊµÅÂ∑•‰ΩúÂ∞ÜRGBÁõ∏Êú∫ËßÜ‰∏∫ÂÖ®Â±ÄÂø´Èó®Â∏ßÈÄüÁéáÁõ∏Êú∫‰∏çÂêåÔºåÂº∫Ë∞É‰∫ÜÈááÁî®ËßÜËßâÊÉØÊÄßÊùüË∞ÉÊï¥ÔºàVIBAÔºâÊù•Ê†°ÂáÜÊªöÂä®Âø´Èó®RGBÁõ∏Êú∫ÁöÑÁ≤æÁ°ÆÊó∂Èó¥Êà≥ÂíåËøêÂä®ÁöÑÈáçË¶ÅÊÄßÔºõÂÖ∂Ê¨°ÔºåÂ∞ÜÂü∫‰∫éÁâ©ÁêÜÂõæÂÉèÂΩ¢ÊàêÊ®°Âûã‰∏éÈ´òÊñØÁÇπ‰∫ëÁªìÂêàÔºåÊúâÊïàËß£ÂÜ≥‰∫ÜRGBÁõ∏Êú∫ÁöÑÊªöÂä®Âø´Èó®ÊïàÂ∫îÂèä‰º†ÊÑüÂô®ÊµãÈáèÁöÑÂä®ÊÄÅËåÉÂõ¥„ÄÇÈÄöËøáÂú®‰∏çÂêåÂÖâÁÖßÊù°‰ª∂‰∏ã‰ΩøÁî®ÂºÄÊîæÊ∫ê‰ª£Á†ÅÁöÑProject AriaËÆæÂ§áËøõË°åÂÖ®Èù¢ËØÑ‰º∞ÔºåÁªìÊûúÊòæÁ§∫ÂºïÂÖ•VIBAÂêéPSNRÊèêÂçá‰∫Ü+1 dBÔºåÁªìÂêàÂõæÂÉèÂΩ¢ÊàêÊ®°ÂûãÂêéÂèàÂ¢ûÂä†‰∫Ü+1 dB„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥‰ΩøÁî®Ëá™Êàë‰∏≠ÂøÉËÆæÂ§áËøõË°åÈ´òÂä®ÊÄÅËåÉÂõ¥Âú∫ÊôØÈáçÂª∫Êó∂ÔºåÊªöÂä®Âø´Èó®Áõ∏Êú∫ÁöÑÊó∂Èó¥Êà≥ÂíåËøêÂä®Ê†°ÂáÜ‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éËßÜËßâÊÉØÊÄßÊµãÁ®ãÁ≥ªÁªüÁöÑ‰ΩçÂßø‰º∞ËÆ°ÔºåÂØºËá¥ÈáçÂª∫Á≤æÂ∫¶‰∏çÈ´ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂºïÂÖ•ËßÜËßâÊÉØÊÄßÊùüË∞ÉÊï¥ÔºàVIBAÔºâÊù•Á≤æÁ°ÆÊ†°ÂáÜÊªöÂä®Âø´Èó®Áõ∏Êú∫ÁöÑÊó∂Èó¥Êà≥ÔºåÂπ∂ÁªìÂêàÁâ©ÁêÜÂõæÂÉèÂΩ¢ÊàêÊ®°ÂûãÔºå‰ª•Êõ¥Â•ΩÂú∞Â§ÑÁêÜ‰º†ÊÑüÂô®ÁâπÊÄßÔºåÁâπÂà´ÊòØÊªöÂä®Âø´Èó®ÊïàÂ∫î„ÄÇËøôÊ†∑ÁöÑËÆæËÆ°Á°Æ‰øù‰∫ÜÈáçÂª∫ËøáÁ®ã‰∏≠ÁöÑÂÉèÁ¥†Á∫ßÁ≤æÂ∫¶„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÈááÈõÜ„ÄÅVIBAÊ†°ÂáÜ„ÄÅÂõæÂÉèÂΩ¢ÊàêÊ®°ÂûãÂ∫îÁî®ÂíåÈáçÂª∫ËæìÂá∫Âõõ‰∏™‰∏ªË¶ÅÊ®°Âùó„ÄÇÈ¶ñÂÖàÔºåÈÄöËøáËá™Êàë‰∏≠ÂøÉËÆæÂ§áÈááÈõÜÊï∞ÊçÆÔºåÁÑ∂ÂêéÂ∫îÁî®VIBAËøõË°åÊó∂Èó¥Êà≥Ê†°ÂáÜÔºåÊé•ÁùÄÁªìÂêàÁâ©ÁêÜÂõæÂÉèÂΩ¢ÊàêÊ®°ÂûãËøõË°åÈáçÂª∫ÔºåÊúÄÂêéËæìÂá∫È´òË¥®ÈáèÁöÑÂú∫ÊôØÈáçÂª∫ÁªìÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÂ∞ÜËßÜËßâÊÉØÊÄßÊùüË∞ÉÊï¥‰∏éÁâ©ÁêÜÂõæÂÉèÂΩ¢ÊàêÊ®°ÂûãÁªìÂêàÔºåËß£ÂÜ≥‰∫ÜÊªöÂä®Âø´Èó®Áõ∏Êú∫Âú®Âä®ÊÄÅÂú∫ÊôØ‰∏ãÁöÑÈáçÂª∫ÈóÆÈ¢ò„ÄÇËøô‰∏ÄÊñπÊ≥ï‰∏é‰º†ÁªüÁöÑÂÖ®Â±ÄÂø´Èó®Áõ∏Êú∫Â§ÑÁêÜÊñπÂºèÊúâÊú¨Ë¥®Âå∫Âà´ÔºåËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞ÂèçÊò†‰º†ÊÑüÂô®ÁâπÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåVIBAÁöÑÂèÇÊï∞ËÆæÁΩÆÁªèËøáÁ≤æÁªÜË∞ÉÊï¥Ôºå‰ª•Á°Æ‰øùÊó∂Èó¥Êà≥ÁöÑÂáÜÁ°ÆÊÄßÔºõÁâ©ÁêÜÂõæÂÉèÂΩ¢ÊàêÊ®°ÂûãÂàôËÄÉËôë‰∫ÜRGBÁõ∏Êú∫ÁöÑÂä®ÊÄÅËåÉÂõ¥ÂíåÊªöÂä®Âø´Èó®ÊïàÂ∫îÔºåÁ°Æ‰øùÈáçÂª∫ÁªìÊûúÁöÑÁúüÂÆûÊÑüÂíåÁ≤æÁ°ÆÂ∫¶„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÈááÁî®ËßÜËßâÊÉØÊÄßÊùüË∞ÉÊï¥ÔºàVIBAÔºâÂêéÔºåPSNRÊèêÂçá‰∫Ü+1 dBÔºåÁªìÂêàÁâ©ÁêÜÂõæÂÉèÂΩ¢ÊàêÊ®°ÂûãÂêéÂÜçÊèêÂçá+1 dBÔºåÈ™åËØÅ‰∫ÜÊñπÊ≥ïÂú®‰∏çÂêåÂÖâÁÖßÊù°‰ª∂‰∏ãÁöÑÊúâÊïàÊÄß„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÁúüÂÆûÊÑüÂú∫ÊôØÈáçÂª∫‰∏≠ÂÖ∑ÊúâÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÂíåÊú∫Âô®‰∫∫ÂØºËà™Á≠âÂú∫ÊôØÔºåËÉΩÂ§ü‰∏∫Ëøô‰∫õÈ¢ÜÂüüÊèê‰æõÊõ¥È´òË¥®ÈáèÁöÑÁéØÂ¢ÉÈáçÂª∫ÊäÄÊúØ„ÄÇÈÄöËøáÊèêÈ´òÈáçÂª∫Á≤æÂ∫¶ÔºåÊú™Êù•ÂèØ‰ª•Âú®ÂÆûÊó∂Â∫îÁî®‰∏≠ÂÆûÁé∞Êõ¥Ëá™ÁÑ∂ÁöÑ‰∫§‰∫í‰ΩìÈ™åÔºåÊé®Âä®Áõ∏ÂÖ≥ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In this paper, we investigate the challenges associated with using egocentric devices to photorealistic reconstruct the scene in high dynamic range. Existing methodologies typically assume using frame-rate 6DoF pose estimated from the device's visual-inertial odometry system, which may neglect crucial details necessary for pixel-accurate reconstruction. This study presents two significant findings. Firstly, in contrast to mainstream work treating RGB camera as global shutter frame-rate camera, we emphasize the importance of employing visual-inertial bundle adjustment (VIBA) to calibrate the precise timestamps and movement of the rolling shutter RGB sensing camera in a high frequency trajectory format, which ensures an accurate calibration of the physical properties of the rolling-shutter camera. Secondly, we incorporate a physical image formation model based into Gaussian Splatting, which effectively addresses the sensor characteristics, including the rolling-shutter effect of RGB cameras and the dynamic ranges measured by sensors. Our proposed formulation is applicable to the widely-used variants of Gaussian Splats representation. We conduct a comprehensive evaluation of our pipeline using the open-source Project Aria device under diverse indoor and outdoor lighting conditions, and further validate it on a Meta Quest3 device. Across all experiments, we observe a consistent visual enhancement of +1 dB in PSNR by incorporating VIBA, with an additional +1 dB achieved through our proposed image formation model. Our complete implementation, evaluation datasets, and recording profile are available at http://www.projectaria.com/photoreal-reconstruction/

