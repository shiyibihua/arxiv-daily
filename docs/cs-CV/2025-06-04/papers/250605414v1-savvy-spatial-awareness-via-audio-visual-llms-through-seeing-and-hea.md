---
layout: default
title: SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing
---

# SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05414" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05414v1</a>
  <a href="https://arxiv.org/pdf/2506.05414.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05414v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05414v1', 'SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mingfei Chen, Zijun Cui, Xiulong Liu, Jinlin Xiang, Caleb Zheng, Jingyuan Li, Eli Shlizerman

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG, cs.MM, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04

**å¤‡æ³¨**: Project website with demo videos: https://zijuncui02.github.io/SAVVY/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSAVVYä»¥è§£å†³åŠ¨æ€3Dç©ºé—´æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŠ¨æ€3Dæ¨ç†` `å¤šæ¨¡æ€å­¦ä¹ ` `éŸ³è§†é¢‘ç†è§£` `ç©ºé—´éŸ³é¢‘` `è½¨è¿¹ä¼°è®¡` `å…¨å±€åœ°å›¾æ„å»º` `æ— è®­ç»ƒæ¨ç†` `åŸºå‡†æµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„éŸ³è§†é¢‘å¤§è¯­è¨€æ¨¡å‹åœ¨åŠ¨æ€3Dç©ºé—´æ¨ç†æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œä¸»è¦é›†ä¸­äºé™æ€æˆ–2Dåœºæ™¯ï¼Œç¼ºä¹å¯¹åŠ¨æ€ç¯å¢ƒçš„ç†è§£ã€‚
2. è®ºæ–‡æå‡ºSAVVYï¼Œä¸€ä¸ªæ— è®­ç»ƒçš„æ¨ç†ç®¡é“ï¼Œåˆ†ä¸ºè‡ªæˆ‘ä¸­å¿ƒç©ºé—´è½¨è¿¹ä¼°è®¡å’ŒåŠ¨æ€å…¨å±€åœ°å›¾æ„å»ºä¸¤ä¸ªé˜¶æ®µï¼Œæ—¨åœ¨æå‡åŠ¨æ€åœºæ™¯ä¸‹çš„ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒè¯æ˜ï¼ŒSAVVYæ˜¾è‘—æå‡äº†ç°æœ‰AV-LLMsçš„æ€§èƒ½ï¼Œè®¾å®šäº†æ–°çš„åŠ¨æ€3Dç©ºé—´æ¨ç†æ ‡å‡†ï¼Œæ¨åŠ¨äº†å¤šæ¨¡æ€ç†è§£çš„è¿›å±•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

3Dç©ºé—´æ¨ç†åœ¨åŠ¨æ€éŸ³è§†é¢‘ç¯å¢ƒä¸­æ˜¯äººç±»è®¤çŸ¥çš„åŸºçŸ³ï¼Œä½†ç°æœ‰çš„éŸ³è§†é¢‘å¤§è¯­è¨€æ¨¡å‹ï¼ˆAV-LLMsï¼‰å’ŒåŸºå‡†æµ‹è¯•ä¸»è¦é›†ä¸­åœ¨é™æ€æˆ–2Dåœºæ™¯ä¸Šï¼Œå°šæœªæ·±å…¥æ¢è®¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†SAVVY-Benchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªé’ˆå¯¹åŠ¨æ€åœºæ™¯ä¸­åŒæ­¥ç©ºé—´éŸ³é¢‘çš„3Dç©ºé—´æ¨ç†åŸºå‡†ã€‚SAVVY-BenchåŒ…å«æ•°åƒä¸ªæ¶‰åŠé™æ€å’Œç§»åŠ¨å¯¹è±¡çš„å…³ç³»ï¼Œè¦æ±‚ç²¾ç»†çš„æ—¶é—´å®šä½ã€ä¸€è‡´çš„3Då®šä½å’Œå¤šæ¨¡æ€æ³¨é‡Šã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†SAVVYï¼Œä¸€ä¸ªæ–°é¢–çš„æ— è®­ç»ƒæ¨ç†ç®¡é“ï¼Œåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯è‡ªæˆ‘ä¸­å¿ƒç©ºé—´è½¨è¿¹ä¼°è®¡ï¼Œåˆ©ç”¨AV-LLMsåŠå…¶ä»–éŸ³è§†é¢‘æ–¹æ³•è·Ÿè¸ªä¸æŸ¥è¯¢ç›¸å…³çš„å…³é”®å¯¹è±¡è½¨è¿¹ï¼›ç¬¬äºŒé˜¶æ®µæ˜¯åŠ¨æ€å…¨å±€åœ°å›¾æ„å»ºï¼Œå°†å¤šæ¨¡æ€æŸ¥è¯¢å¯¹è±¡è½¨è¿¹èšåˆå¹¶è½¬æ¢ä¸ºç»Ÿä¸€çš„åŠ¨æ€åœ°å›¾ã€‚é€šè¿‡æ„å»ºçš„åœ°å›¾ï¼Œæœ€ç»ˆQAç­”æ¡ˆé€šè¿‡åæ ‡å˜æ¢è·å¾—ï¼Œå®éªŒè¯æ˜SAVVYæ˜¾è‘—æå‡äº†ç°æœ‰AV-LLMsçš„æ€§èƒ½ï¼Œæ ‘ç«‹äº†æ–°çš„æ ‡å‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åŠ¨æ€éŸ³è§†é¢‘ç¯å¢ƒä¸­çš„3Dç©ºé—´æ¨ç†é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­äºé™æ€æˆ–2Dåœºæ™¯ï¼Œæ— æ³•æœ‰æ•ˆå¤„ç†åŠ¨æ€å¯¹è±¡å’Œç©ºé—´éŸ³é¢‘çš„å¤æ‚å…³ç³»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSAVVYçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ— è®­ç»ƒçš„æ¨ç†ç®¡é“ï¼Œåˆ©ç”¨éŸ³è§†é¢‘å¤§è¯­è¨€æ¨¡å‹å’Œå…¶ä»–éŸ³è§†é¢‘æ–¹æ³•ï¼Œç²¾ç¡®è·Ÿè¸ªä¸æŸ¥è¯¢ç›¸å…³çš„å¯¹è±¡è½¨è¿¹ï¼Œå¹¶æ„å»ºåŠ¨æ€å…¨å±€åœ°å›¾ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­è¿›è¡Œæœ‰æ•ˆçš„ç©ºé—´æ¨ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯è‡ªæˆ‘ä¸­å¿ƒç©ºé—´è½¨è¿¹ä¼°è®¡ï¼Œåˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯è·Ÿè¸ªå…³é”®å¯¹è±¡ï¼›ç¬¬äºŒé˜¶æ®µæ˜¯åŠ¨æ€å…¨å±€åœ°å›¾æ„å»ºï¼Œå°†è·Ÿè¸ªç»“æœæ•´åˆä¸ºç»Ÿä¸€çš„åŠ¨æ€åœ°å›¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†SAVVY-BenchåŸºå‡†å’Œæ— è®­ç»ƒçš„æ¨ç†ç®¡é“ï¼Œèƒ½å¤Ÿåœ¨åŠ¨æ€åœºæ™¯ä¸­è¿›è¡Œç²¾ç»†çš„ç©ºé—´æ¨ç†ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†å¯¹åŠ¨æ€å¯¹è±¡çš„ç†è§£èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šæ¨¡æ€æ³¨é‡Šå’Œç²¾ç»†çš„æ—¶é—´å®šä½æœºåˆ¶ï¼Œç¡®ä¿äº†å¯¹åŠ¨æ€åœºæ™¯ä¸­å¯¹è±¡çš„å‡†ç¡®è·Ÿè¸ªå’Œå®šä½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSAVVYåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†ç°æœ‰AV-LLMsçš„æ€§èƒ½ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œè®¾å®šäº†æ–°çš„åŠ¨æ€3Dç©ºé—´æ¨ç†æ ‡å‡†ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†é‡è¦å‚è€ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®å’Œè™šæ‹Ÿç°å®ç­‰ï¼Œèƒ½å¤Ÿæå‡ç³»ç»Ÿåœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­çš„ç†è§£å’Œå†³ç­–èƒ½åŠ›ã€‚æœªæ¥ï¼ŒSAVVYçš„æ¡†æ¶å¯èƒ½æ¨åŠ¨æ›´å¤šå¤šæ¨¡æ€å­¦ä¹ å’Œæ¨ç†æŠ€æœ¯çš„å‘å±•ï¼Œä¿ƒè¿›äººæœºäº¤äº’çš„æ™ºèƒ½åŒ–ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> 3D spatial reasoning in dynamic, audio-visual environments is a cornerstone of human cognition yet remains largely unexplored by existing Audio-Visual Large Language Models (AV-LLMs) and benchmarks, which predominantly focus on static or 2D scenes. We introduce SAVVY-Bench, the first benchmark for 3D spatial reasoning in dynamic scenes with synchronized spatial audio. SAVVY-Bench is comprised of thousands of relationships involving static and moving objects, and requires fine-grained temporal grounding, consistent 3D localization, and multi-modal annotation. To tackle this challenge, we propose SAVVY, a novel training-free reasoning pipeline that consists of two stages: (i) Egocentric Spatial Tracks Estimation, which leverages AV-LLMs as well as other audio-visual methods to track the trajectories of key objects related to the query using both visual and spatial audio cues, and (ii) Dynamic Global Map Construction, which aggregates multi-modal queried object trajectories and converts them into a unified global dynamic map. Using the constructed map, a final QA answer is obtained through a coordinate transformation that aligns the global map with the queried viewpoint. Empirical evaluation demonstrates that SAVVY substantially enhances performance of state-of-the-art AV-LLMs, setting a new standard and stage for approaching dynamic 3D spatial reasoning in AV-LLMs.

