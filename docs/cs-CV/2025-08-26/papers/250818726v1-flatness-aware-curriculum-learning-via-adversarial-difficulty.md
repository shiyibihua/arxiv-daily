---
layout: default
title: Flatness-aware Curriculum Learning via Adversarial Difficulty
---

# Flatness-aware Curriculum Learning via Adversarial Difficulty

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18726" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18726v1</a>
  <a href="https://arxiv.org/pdf/2508.18726.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18726v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18726v1', 'Flatness-aware Curriculum Learning via Adversarial Difficulty')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hiroaki Aizawa, Yoshikazu Hayashi

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26

**å¤‡æ³¨**: Accepted to BMVC2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯¹æŠ—æ€§éš¾åº¦åº¦é‡ä»¥è§£å†³è¯¾ç¨‹å­¦ä¹ ä¸å¹³å¦æœ€å°å€¼ç»“åˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è¯¾ç¨‹å­¦ä¹ ` `å¯¹æŠ—æ€§å­¦ä¹ ` `å¹³å¦æ€§æ„ŸçŸ¥` `æ·±åº¦å­¦ä¹ ` `æ¨¡å‹æ³›åŒ–` `å›¾åƒåˆ†ç±»` `ç»†ç²’åº¦è¯†åˆ«`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯¾ç¨‹å­¦ä¹ æ–¹æ³•åœ¨ç»“åˆå¹³å¦æ€§æ„ŸçŸ¥æœ€å°åŒ–æ—¶é¢ä¸´è¯„ä¼°æ ·æœ¬éš¾åº¦çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å¹³å¦åŒºåŸŸã€‚
2. æœ¬æ–‡æå‡ºå¯¹æŠ—æ€§éš¾åº¦åº¦é‡ï¼ˆADMï¼‰ï¼Œé€šè¿‡å¯¹æ¯”åŸå§‹æ ·æœ¬ä¸å¯¹æŠ—æ ·æœ¬çš„æŸå¤±å·®è·æ¥æœ‰æ•ˆè¯„ä¼°æ ·æœ¬éš¾åº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå‡ä¼˜äºä¼ ç»Ÿçš„è¯¾ç¨‹å­¦ä¹ å’ŒåŸºäºå¹³å¦æ€§çš„è®­ç»ƒç­–ç•¥ï¼Œæå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¥ç»ç½‘ç»œåœ¨ç»éªŒé£é™©æœ€å°åŒ–è®­ç»ƒä¸­å¸¸å¸¸é¢ä¸´è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨ç‰¹å®šæ ·æœ¬æˆ–é¢†åŸŸä¸Šï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›å·®ã€‚è¯¾ç¨‹å­¦ä¹ ï¼ˆCLï¼‰é€šè¿‡æ ¹æ®æ ·æœ¬éš¾åº¦é€‰æ‹©è®­ç»ƒæ ·æœ¬æ¥åº”å¯¹è¿™ä¸€é—®é¢˜ã€‚å¹³å¦æ€§æ„ŸçŸ¥æœ€å°åŒ–ï¼ˆSAMï¼‰æ–¹æ³•é€šè¿‡å¯»æ±‚å¹³å¦æœ€å°å€¼æ¥æé«˜æ¨¡å‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå°†CLä¸SAMç»“åˆå¹¶ä¸ç®€å•ï¼Œå› ä¸ºåœ¨å¹³å¦åŒºåŸŸï¼ŒæŸå¤±å€¼å’Œæ¢¯åº¦èŒƒæ•°é€šå¸¸è¾ƒå°ï¼Œéš¾ä»¥è¯„ä¼°æ ·æœ¬éš¾åº¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†å¯¹æŠ—æ€§éš¾åº¦åº¦é‡ï¼ˆADMï¼‰ï¼Œé€šè¿‡æµ‹é‡åŸå§‹æ ·æœ¬ä¸å¯¹æŠ—æ ·æœ¬ä¹‹é—´çš„å½’ä¸€åŒ–æŸå¤±å·®è·æ¥é‡åŒ–å¯¹æŠ—è„†å¼±æ€§ã€‚æˆ‘ä»¬å°†ADMä¸åŸºäºCLçš„SAMè®­ç»ƒç»“åˆï¼ŒåŠ¨æ€è¯„ä¼°æ ·æœ¬éš¾åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒåˆ†ç±»ã€ç»†ç²’åº¦è¯†åˆ«å’Œé¢†åŸŸæ³›åŒ–ä»»åŠ¡ä¸­ä¼˜äºç°æœ‰çš„è¯¾ç¨‹å­¦ä¹ å’Œå¹³å¦æ€§æ„ŸçŸ¥è®­ç»ƒç­–ç•¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è¯¾ç¨‹å­¦ä¹ ä¸å¹³å¦æ€§æ„ŸçŸ¥æœ€å°åŒ–ç»“åˆæ—¶ï¼Œæ ·æœ¬éš¾åº¦è¯„ä¼°å›°éš¾çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¹³å¦åŒºåŸŸæŸå¤±å€¼å’Œæ¢¯åº¦èŒƒæ•°å‡è¾ƒå°ï¼Œå¯¼è‡´éš¾ä»¥æœ‰æ•ˆé€‰æ‹©è®­ç»ƒæ ·æœ¬ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå¯¹æŠ—æ€§éš¾åº¦åº¦é‡ï¼ˆADMï¼‰ï¼Œé€šè¿‡æµ‹é‡åŸå§‹æ ·æœ¬ä¸å¯¹æŠ—æ ·æœ¬ä¹‹é—´çš„å½’ä¸€åŒ–æŸå¤±å·®è·ï¼Œæ¥é‡åŒ–æ ·æœ¬çš„å¯¹æŠ—è„†å¼±æ€§ï¼Œä»è€ŒåŠ¨æ€è¯„ä¼°æ ·æœ¬éš¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶ç»“åˆäº†è¯¾ç¨‹å­¦ä¹ å’ŒSAMï¼Œä¸»è¦åŒ…æ‹¬æ ·æœ¬éš¾åº¦è¯„ä¼°æ¨¡å—å’ŒåŸºäºADMçš„åŠ¨æ€è®­ç»ƒç­–ç•¥ã€‚é¦–å…ˆè®¡ç®—æ ·æœ¬çš„å¯¹æŠ—æŸå¤±ï¼Œç„¶åæ ¹æ®éš¾åº¦åŠ¨æ€è°ƒæ•´è®­ç»ƒæ ·æœ¬çš„é€‰æ‹©ã€‚

**å…³é”®åˆ›æ–°**ï¼šADMä½œä¸ºä¸€ç§æ–°çš„éš¾åº¦åº¦é‡æ–¹æ³•ï¼Œå…‹æœäº†ä¼ ç»ŸæŸå¤±å’Œæ¢¯åº¦åº¦é‡åœ¨å¹³å¦åŒºåŸŸå¤±æ•ˆçš„é—®é¢˜ï¼Œä¿æŒäº†ä¿¡æ¯çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡‡ç”¨äº†å¯¹æŠ—æ ·æœ¬çš„å½’ä¸€åŒ–æŸå¤±å·®è·ä½œä¸ºè¯„ä¼°æ ‡å‡†ï¼Œç¡®ä¿åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤ŸæŒç»­æœ‰æ•ˆåœ°è¯„ä¼°æ ·æœ¬éš¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ç›¸è¾ƒäºä¼ ç»Ÿè¯¾ç¨‹å­¦ä¹ å’ŒåŸºäºå¹³å¦æ€§çš„è®­ç»ƒç­–ç•¥ï¼Œå‡†ç¡®ç‡æå‡äº†çº¦5%ï¼Œåœ¨ç»†ç²’åº¦è¯†åˆ«å’Œé¢†åŸŸæ³›åŒ–ä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å›¾åƒåˆ†ç±»ã€ç»†ç²’åº¦è¯†åˆ«å’Œé¢†åŸŸæ³›åŒ–ç­‰ä»»åŠ¡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Neural networks trained by empirical risk minimization often suffer from overfitting, especially to specific samples or domains, which leads to poor generalization. Curriculum Learning (CL) addresses this issue by selecting training samples based on the difficulty. From the optimization perspective, methods such as Sharpness-Aware Minimization (SAM) improve robustness and generalization by seeking flat minima. However, combining CL with SAM is not straightforward. In flat regions, both the loss values and the gradient norms tend to become uniformly small, which makes it difficult to evaluate sample difficulty and design an effective curriculum. To overcome this problem, we propose the Adversarial Difficulty Measure (ADM), which quantifies adversarial vulnerability by leveraging the robustness properties of models trained toward flat minima. Unlike loss- or gradient-based measures, which become ineffective as training progresses into flatter regions, ADM remains informative by measuring the normalized loss gap between original and adversarial examples. We incorporate ADM into CL-based training with SAM to dynamically assess sample difficulty. We evaluated our approach on image classification tasks, fine-grained recognition, and domain generalization. The results demonstrate that our method preserves the strengths of both CL and SAM while outperforming existing curriculum-based and flatness-aware training strategies.

