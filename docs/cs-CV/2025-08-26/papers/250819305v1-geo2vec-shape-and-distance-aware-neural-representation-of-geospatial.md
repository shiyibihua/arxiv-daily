---
layout: default
title: Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities
---

# Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19305" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19305v1</a>
  <a href="https://arxiv.org/pdf/2508.19305.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19305v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19305v1', 'Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chen Chu, Cyrus Shahabi

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/chuchen2017/GeoNeuralRepresentation)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGeo2Vecä»¥è§£å†³åœ°ç†å®ä½“è¡¨ç¤ºå­¦ä¹ ä¸­çš„é«˜è®¡ç®—æˆæœ¬é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `åœ°ç†è¡¨ç¤ºå­¦ä¹ ` `æœ‰ç¬¦å·è·ç¦»åœº` `è‡ªé€‚åº”é‡‡æ ·` `ç¥ç»ç½‘ç»œ` `GeoAI` `åŸå¸‚åˆ†æ` `ç©ºé—´å…³ç³»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•è¦ä¹ˆä»…é’ˆå¯¹å•ä¸€åœ°ç†å®ä½“ç±»å‹ï¼Œè¦ä¹ˆé€šè¿‡åˆ†è§£å¼•å…¥é«˜è®¡ç®—æˆæœ¬ï¼Œä¸”ç¼ºä¹å‡ ä½•å¯¹é½ï¼Œå¯¼è‡´ç»†èŠ‚æ¨¡ç³Šã€‚
2. Geo2Vecé€šè¿‡è‡ªé€‚åº”é‡‡æ ·å’Œç¼–ç æœ‰ç¬¦å·è·ç¦»ï¼Œç›´æ¥åœ¨åŸå§‹ç©ºé—´ä¸­æ•æ‰å‡ ä½•å½¢çŠ¶ï¼Œé¿å…äº†åˆ†è§£å¸¦æ¥çš„å¤æ‚æ€§ã€‚
3. å®éªŒè¯æ˜ï¼ŒGeo2Vecåœ¨è¡¨ç¤ºå½¢çŠ¶å’Œä½ç½®ã€æ•æ‰ç©ºé—´å…³ç³»æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä¸”åœ¨å®é™…GeoAIåº”ç”¨ä¸­æ•ˆç‡æ›´é«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç©ºé—´è¡¨ç¤ºå­¦ä¹ å¯¹äºGeoAIåº”ç”¨è‡³å…³é‡è¦ï¼Œèƒ½å¤Ÿç¼–ç åœ°ç†å®ä½“çš„å½¢çŠ¶ã€ä½ç½®å’Œç©ºé—´å…³ç³»ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆé’ˆå¯¹å•ä¸€åœ°ç†å®ä½“ç±»å‹ï¼Œè¦ä¹ˆé€šè¿‡åˆ†è§£å®ä½“å¼•å…¥é«˜è®¡ç®—æˆæœ¬ï¼Œä¸”ç¼ºä¹å‡ ä½•å¯¹é½ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Geo2Vecï¼Œä¸€ç§ç›´æ¥åœ¨åŸå§‹ç©ºé—´ä¸­æ“ä½œçš„æ–°æ–¹æ³•ï¼Œçµæ„Ÿæ¥è‡ªæœ‰ç¬¦å·è·ç¦»åœºï¼ˆSDFï¼‰ã€‚Geo2Vecè‡ªé€‚åº”é‡‡æ ·ç‚¹å¹¶ç¼–ç å…¶æœ‰ç¬¦å·è·ç¦»ï¼Œæ•æ‰å‡ ä½•å½¢çŠ¶è€Œæ— éœ€åˆ†è§£ã€‚é€šè¿‡è®­ç»ƒç¥ç»ç½‘ç»œè¿‘ä¼¼SDFï¼ŒGeo2Vecä¸ºæ‰€æœ‰åœ°ç†å®ä½“ç±»å‹ç”Ÿæˆç´§å‡‘çš„å‡ ä½•æ„ŸçŸ¥ç»Ÿä¸€è¡¨ç¤ºã€‚å®éªŒè¯æ˜ï¼ŒGeo2Vecåœ¨å½¢çŠ¶å’Œä½ç½®è¡¨ç¤ºã€æ•æ‰æ‹“æ‰‘å’Œè·ç¦»å…³ç³»æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰åœ°ç†å®ä½“è¡¨ç¤ºå­¦ä¹ æ–¹æ³•åœ¨å¤„ç†å¤šç§åœ°ç†å®ä½“ç±»å‹æ—¶çš„é«˜è®¡ç®—æˆæœ¬å’Œå‡ ä½•å¯¹é½ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºåˆ†è§£å’Œå‚…é‡Œå¶å˜æ¢ï¼Œå¯¼è‡´ç»†èŠ‚ä¸¢å¤±å’Œè®¡ç®—æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGeo2Vecçš„æ ¸å¿ƒæ€æƒ³æ˜¯ç›´æ¥åœ¨åŸå§‹ç©ºé—´ä¸­æ“ä½œï¼Œåˆ©ç”¨æœ‰ç¬¦å·è·ç¦»åœºï¼ˆSDFï¼‰è¿›è¡Œè‡ªé€‚åº”é‡‡æ ·ï¼Œç¼–ç æ¯ä¸ªç‚¹çš„æœ‰ç¬¦å·è·ç¦»ï¼Œä»è€Œæ•æ‰å‡ ä½•ä¿¡æ¯è€Œæ— éœ€åˆ†è§£ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGeo2Vecçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è‡ªé€‚åº”é‡‡æ ·æ¨¡å—ã€SDFè¿‘ä¼¼ç¥ç»ç½‘ç»œå’Œæ—‹è½¬ä¸å˜ä½ç½®ç¼–ç ã€‚è‡ªé€‚åº”é‡‡æ ·æ¨¡å—æ ¹æ®å‡ ä½•ç‰¹å¾é€‰æ‹©é‡‡æ ·ç‚¹ï¼ŒSDFè¿‘ä¼¼ç½‘ç»œç”Ÿæˆç»Ÿä¸€çš„å‡ ä½•æ„ŸçŸ¥è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šGeo2Vecçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è‡ªé€‚åº”é‡‡æ ·å’Œæœ‰ç¬¦å·è·ç¦»ç¼–ç æ–¹æ³•ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„åˆ†è§£ç­–ç•¥å½¢æˆé²œæ˜å¯¹æ¯”ï¼Œä½¿å¾—å‡ ä½•ä¿¡æ¯çš„æ•æ‰æ›´åŠ ç²¾ç¡®å’Œé«˜æ•ˆã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒGeo2Vecé‡‡ç”¨æ—‹è½¬ä¸å˜çš„ä½ç½®ç¼–ç ï¼Œä»¥å»ºæ¨¡é«˜é¢‘ç©ºé—´å˜åŒ–ï¼Œå¹¶é€šè¿‡ç‰¹å®šçš„æŸå¤±å‡½æ•°ä¼˜åŒ–SDFè¿‘ä¼¼ç½‘ç»œï¼Œç¡®ä¿ç”Ÿæˆçš„è¡¨ç¤ºåœ¨å¤šç§GeoAIä»»åŠ¡ä¸­å…·æœ‰è‰¯å¥½çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGeo2Vecåœ¨å½¢çŠ¶å’Œä½ç½®è¡¨ç¤ºæ–¹é¢çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨æ•æ‰æ‹“æ‰‘å’Œè·ç¦»å…³ç³»æ–¹é¢ï¼Œæå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…GeoAIåº”ç”¨ä¸­çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Geo2Vecåœ¨åŸå¸‚åˆ†æã€ç¯å¢ƒç›‘æµ‹å’Œåœ°ç†ä¿¡æ¯ç³»ç»Ÿç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æä¾›é«˜æ•ˆä¸”å‡†ç¡®çš„åœ°ç†å®ä½“è¡¨ç¤ºï¼ŒGeo2Vecèƒ½å¤Ÿæå‡GeoAIæ¨¡å‹çš„æ€§èƒ½ï¼Œæ¨åŠ¨æ™ºèƒ½åŸå¸‚å’Œå¯æŒç»­å‘å±•ç­‰é¢†åŸŸçš„ç ”ç©¶ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Spatial representation learning is essential for GeoAI applications such as urban analytics, enabling the encoding of shapes, locations, and spatial relationships (topological and distance-based) of geo-entities like points, polylines, and polygons. Existing methods either target a single geo-entity type or, like Poly2Vec, decompose entities into simpler components to enable Fourier transformation, introducing high computational cost. Moreover, since the transformed space lacks geometric alignment, these methods rely on uniform, non-adaptive sampling, which blurs fine-grained features like edges and boundaries. To address these limitations, we introduce Geo2Vec, a novel method inspired by signed distance fields (SDF) that operates directly in the original space. Geo2Vec adaptively samples points and encodes their signed distances (positive outside, negative inside), capturing geometry without decomposition. A neural network trained to approximate the SDF produces compact, geometry-aware, and unified representations for all geo-entity types. Additionally, we propose a rotation-invariant positional encoding to model high-frequency spatial variations and construct a structured and robust embedding space for downstream GeoAI models. Empirical results show that Geo2Vec consistently outperforms existing methods in representing shape and location, capturing topological and distance relationships, and achieving greater efficiency in real-world GeoAI applications. Code and Data can be found at: https://github.com/chuchen2017/GeoNeuralRepresentation.

