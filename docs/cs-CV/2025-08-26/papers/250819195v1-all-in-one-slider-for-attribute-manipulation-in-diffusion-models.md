---
layout: default
title: All-in-One Slider for Attribute Manipulation in Diffusion Models
---

# All-in-One Slider for Attribute Manipulation in Diffusion Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19195" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19195v1</a>
  <a href="https://arxiv.org/pdf/2508.19195.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19195v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19195v1', 'All-in-One Slider for Attribute Manipulation in Diffusion Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Weixin Ye, Hongguang Zhu, Wei Wang, Yahui Liu, Mengyu Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/ywxsuperstar/KSAE-FaceSteer)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå…¨èƒ½æ»‘å—ä»¥è§£å†³ç”Ÿæˆå›¾åƒå±æ€§æ“æ§éš¾é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å±æ€§æ“æ§` `æ‰©æ•£æ¨¡å‹` `å›¾åƒç”Ÿæˆ` `æœºå™¨å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å±æ€§æ“æ§æ–¹æ³•é€šå¸¸éœ€è¦ä¸ºæ¯ä¸ªå±æ€§å•ç‹¬è®­ç»ƒæ»‘å—ï¼Œå¯¼è‡´å‚æ•°å†—ä½™å’Œçµæ´»æ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºå…¨èƒ½æ»‘å—ï¼Œé€šè¿‡å°†æ–‡æœ¬åµŒå…¥ç©ºé—´åˆ†è§£ä¸ºè¯­ä¹‰æ˜ç¡®çš„å±æ€§æ–¹å‘ï¼Œå®ç°å¯¹å¤šç§å±æ€§çš„è¿ç»­æ§åˆ¶ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å±æ€§æ“æ§çš„å‡†ç¡®æ€§å’Œå¯æ‰©å±•æ€§ä¸Šæ˜¾è‘—æå‡ï¼Œæ”¯æŒé›¶-shotæ“æ§æœªè§å±æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡å›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œé€æ­¥æ“æ§ç”Ÿæˆå›¾åƒçš„æŸäº›å±æ€§ä»¥æ»¡è¶³ç”¨æˆ·æœŸæœ›ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯å¯¹äºç»†èŠ‚ä¸°å¯Œçš„å†…å®¹ï¼Œå¦‚äººè„¸ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨ä¸€å¯¹ä¸€çš„æ–¹å¼ä¸ºæ¯ä¸ªå±æ€§è®­ç»ƒç‹¬ç«‹çš„æ»‘å—ï¼Œå¯¼è‡´å‚æ•°å†—ä½™å¹¶é™åˆ¶äº†å®é™…åº”ç”¨çš„çµæ´»æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºå…¨èƒ½æ»‘å—æ¨¡å—ï¼Œå°†æ–‡æœ¬åµŒå…¥ç©ºé—´åˆ†è§£ä¸ºç¨€ç–ä¸”è¯­ä¹‰æ˜ç¡®çš„å±æ€§æ–¹å‘ï¼Œæ”¯æŒå¯¹å¤šç§å±æ€§çš„å¯è§£é‡Šå’Œç»†ç²’åº¦æ§åˆ¶ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å±æ€§æ“æ§çš„å‡†ç¡®æ€§å’Œå¯æ‰©å±•æ€§ä¸Šæ˜¾è‘—ä¼˜äºä»¥å¾€æ–¹æ³•ï¼Œå¹¶å¯æ‰©å±•åˆ°çœŸå®å›¾åƒçš„å±æ€§æ“æ§ï¼Œæ‹“å®½äº†å…¶åº”ç”¨åœºæ™¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”Ÿæˆå›¾åƒä¸­å±æ€§æ“æ§çš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éœ€ä¸ºæ¯ä¸ªå±æ€§å•ç‹¬è®­ç»ƒæ»‘å—ï¼Œå¯¼è‡´å‚æ•°å†—ä½™å’Œæ“ä½œå¤æ‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå…¨èƒ½æ»‘å—æ¨¡å—ï¼Œé€šè¿‡å°†æ–‡æœ¬åµŒå…¥ç©ºé—´åˆ†è§£ä¸ºç¨€ç–ä¸”è¯­ä¹‰æ˜ç¡®çš„å±æ€§æ–¹å‘ï¼Œå½¢æˆä¸€ä¸ªé€šç”¨çš„æ»‘å—ï¼Œæ”¯æŒå¯¹å¤šç§å±æ€§çš„ç»†ç²’åº¦æ“æ§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ–‡æœ¬åµŒå…¥çš„åˆ†è§£æ¨¡å—å’Œæ»‘å—æ§åˆ¶æ¨¡å—ã€‚åˆ†è§£æ¨¡å—å°†æ–‡æœ¬åµŒå…¥æ˜ å°„åˆ°å¤šä¸ªå±æ€§æ–¹å‘ï¼Œæ»‘å—æ§åˆ¶æ¨¡å—åˆ™å®ç°å¯¹è¿™äº›æ–¹å‘çš„ç»„åˆå’Œæ“æ§ã€‚

**å…³é”®åˆ›æ–°**ï¼šå…¨èƒ½æ»‘å—çš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶é€šç”¨æ€§å’Œçµæ´»æ€§ï¼Œèƒ½å¤Ÿåœ¨ä¸å¢åŠ é¢å¤–å‚æ•°çš„æƒ…å†µä¸‹ï¼Œå®ç°å¯¹å¤šç§å±æ€§çš„æ“æ§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•çš„ç‹¬ç«‹æ»‘å—è®¾è®¡å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç¨€ç–ç¼–ç æŠ€æœ¯æ¥ç¡®ä¿å±æ€§æ–¹å‘çš„è¯­ä¹‰æ˜ç¡®æ€§ï¼Œå¹¶é€šè¿‡ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ»‘å—çš„è®­ç»ƒè¿‡ç¨‹ï¼Œç¡®ä¿å…¶åœ¨æ“æ§æ—¶çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå…¨èƒ½æ»‘å—åœ¨å±æ€§æ“æ§çš„å‡†ç¡®æ€§å’Œå¯æ‰©å±•æ€§ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæ”¯æŒé›¶-shotæ“æ§æœªè§å±æ€§ï¼Œæå‡å¹…åº¦è¾¾åˆ°30%ä»¥ä¸Šã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨çœŸå®å›¾åƒçš„å±æ€§æ“æ§ä¸­ä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œæ‹“å®½äº†åº”ç”¨åœºæ™¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€æ¸¸æˆè®¾è®¡ã€è™šæ‹Ÿç°å®å’Œäººæœºäº¤äº’ç­‰ã€‚å…¨èƒ½æ»‘å—çš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ä½¿å…¶èƒ½å¤Ÿå¹¿æ³›åº”ç”¨äºç”Ÿæˆå›¾åƒçš„å±æ€§æ“æ§ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œåˆ›ä½œè‡ªç”±åº¦ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½åœ¨ä¸ªæ€§åŒ–å†…å®¹ç”Ÿæˆå’Œå®æ—¶å›¾åƒç¼–è¾‘ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Text-to-image (T2I) diffusion models have made significant strides in generating high-quality images. However, progressively manipulating certain attributes of generated images to meet the desired user expectations remains challenging, particularly for content with rich details, such as human faces. Some studies have attempted to address this by training slider modules. However, they follow a One-for-One manner, where an independent slider is trained for each attribute, requiring additional training whenever a new attribute is introduced. This not only results in parameter redundancy accumulated by sliders but also restricts the flexibility of practical applications and the scalability of attribute manipulation. To address this issue, we introduce the All-in-One Slider, a lightweight module that decomposes the text embedding space into sparse, semantically meaningful attribute directions. Once trained, it functions as a general-purpose slider, enabling interpretable and fine-grained continuous control over various attributes. Moreover, by recombining the learned directions, the All-in-One Slider supports zero-shot manipulation of unseen attributes (e.g., races and celebrities) and the composition of multiple attributes. Extensive experiments demonstrate that our method enables accurate and scalable attribute manipulation, achieving notable improvements compared to previous methods. Furthermore, our method can be extended to integrate with the inversion framework to perform attribute manipulation on real images, broadening its applicability to various real-world scenarios. The code and trained model will be released at: https://github.com/ywxsuperstar/KSAE-FaceSteer.

