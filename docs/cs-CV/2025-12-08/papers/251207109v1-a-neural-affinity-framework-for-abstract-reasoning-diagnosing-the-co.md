---
layout: default
title: A Neural Affinity Framework for Abstract Reasoning: Diagnosing the Compositional Gap in Transformer Architectures via Procedural Task Taxonomy
---

# A Neural Affinity Framework for Abstract Reasoning: Diagnosing the Compositional Gap in Transformer Architectures via Procedural Task Taxonomy

**arXiv**: [2512.07109v1](https://arxiv.org/abs/2512.07109) | [PDF](https://arxiv.org/pdf/2512.07109.pdf)

**ä½œè€…**: Miguel Ingram, Arthur Joseph Merritt

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç¥žç»äº²å’ŒåŠ›æ¡†æž¶ä»¥è¯Šæ–­Transformeråœ¨æŠ½è±¡æŽ¨ç†ä»»åŠ¡ä¸­çš„ç»„åˆæ€§å·®è·**

**å…³é”®è¯**: `æŠ½è±¡æŽ¨ç†` `Transformeræž¶æž„` `ä»»åŠ¡åˆ†ç±»æ³•` `ç¥žç»äº²å’ŒåŠ›` `ç»„åˆæ€§å·®è·` `ARC-AGI-2`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šTransformeræž¶æž„åœ¨æŠ½è±¡æŽ¨ç†ä»»åŠ¡ä¸­å­˜åœ¨ç»„åˆæ€§å·®è·ï¼Œå¯¼è‡´å±€éƒ¨æ¨¡å¼å­¦ä¹ ä¸Žå…¨å±€åˆæˆèƒ½åŠ›ä¸åŒ¹é…
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽè§„åˆ™ä»£ç åˆ†æžæž„å»º9ç±»ä»»åŠ¡åˆ†ç±»æ³•ï¼Œç”¨äºŽè¯„ä¼°ä»»åŠ¡ä¸Žç¥žç»ç½‘ç»œçš„äº²å’ŒåŠ›
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ARC-AGI-2æµ‹è¯•é›†ä¸Šï¼Œ69.5%çš„ä»»åŠ¡æ˜¾ç¤ºé«˜å±€éƒ¨å‡†ç¡®çŽ‡ä½†ä½Žå…¨å±€å‡†ç¡®çŽ‡ï¼ŒéªŒè¯äº†ç¥žç»äº²å’ŒåŠ›å¤©èŠ±æ¿æ•ˆåº”

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Responding to Hodel et al.'s (2024) call for a formal definition of task relatedness in re-arc, we present the first 9-category taxonomy of all 400 tasks, validated at 97.5% accuracy via rule-based code analysis. We prove the taxonomy's visual coherence by training a CNN on raw grid pixels (95.24% accuracy on S3, 36.25% overall, 3.3x chance), then apply the taxonomy diagnostically to the original ARC-AGI-2 test set. Our curriculum analysis reveals 35.3% of tasks exhibit low neural affinity for Transformers--a distributional bias mirroring ARC-AGI-2. To probe this misalignment, we fine-tuned a 1.7M-parameter Transformer across 302 tasks, revealing a profound Compositional Gap: 210 of 302 tasks (69.5%) achieve >80% cell accuracy (local patterns) but <10% grid accuracy (global synthesis). This provides direct evidence for a Neural Affinity Ceiling Effect, where performance is bounded by architectural suitability, not curriculum. Applying our framework to Li et al.'s independent ViTARC study (400 specialists, 1M examples each) confirms its predictive power: Very Low affinity tasks achieve 51.9% versus 77.7% for High affinity (p<0.001), with a task at 0% despite massive data. The taxonomy enables precise diagnosis: low-affinity tasks (A2) hit hard ceilings, while high-affinity tasks (C1) reach 99.8%. These findings indicate that progress requires hybrid architectures with affinity-aligned modules. We release our validated taxonomy,

