---
layout: default
title: RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation
---

# RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation

**arXiv**: [2512.07273v1](https://arxiv.org/abs/2512.07273) | [PDF](https://arxiv.org/pdf/2512.07273.pdf)

**ä½œè€…**: Zhi Rao, Yucheng Zhou, Benjia Zhou, Yiqing Huang, Sergio Escalera, Jun Wan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRVLFæ¡†æž¶ä»¥è§£å†³æ— æ³¨é‡Šæ‰‹è¯­ç¿»è¯‘ä¸­çš„è¡¨ç¤ºä¸è¶³å’Œè¯­ä¹‰å¯¹é½é—®é¢˜**

**å…³é”®è¯**: `æ— æ³¨é‡Šæ‰‹è¯­ç¿»è¯‘` `è§†è§‰è¯­è¨€æ¨¡åž‹` `å¼ºåŒ–å­¦ä¹ ` `è¯­ä¹‰å¯¹é½` `GRPOä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ— æ³¨é‡Šæ‰‹è¯­ç¿»è¯‘å­˜åœ¨è§†è§‰è¡¨ç¤ºä¸è¶³å’Œå¥å­çº§è¯­ä¹‰é”™é…ï¼Œå½±å“ç¿»è¯‘è´¨é‡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆå¤§åž‹è§†è§‰è¯­è¨€æ¨¡åž‹ä¸Žå¼ºåŒ–å­¦ä¹ ï¼Œé€šè¿‡è¯­ä¹‰è¡¨ç¤ºå­¦ä¹ å’ŒGRPOä¼˜åŒ–æå‡ç¿»è¯‘æ€§èƒ½ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠBLEU-4åˆ†æ•°æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†GRPOä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Gloss-free sign language translation (SLT) is hindered by two key challenges: **inadequate sign representation** that fails to capture nuanced visual cues, and **sentence-level semantic misalignment** in current LLM-based methods, which limits translation quality. To address these issues, we propose a three-stage **r**einforcing **v**ision-**l**anguage **f**ramework (**RVLF**). We build a large vision-language model (LVLM) specifically designed for sign language, and then combine it with reinforcement learning (RL) to adaptively enhance translation performance. First, for a sufficient representation of sign language, RVLF introduces an effective semantic representation learning mechanism that fuses skeleton-based motion cues with semantically rich visual features extracted via DINOv2, followed by instruction tuning to obtain a strong SLT-SFT baseline. Then, to improve sentence-level semantic misalignment, we introduce a GRPO-based optimization strategy that fine-tunes the SLT-SFT model with a reward function combining translation fidelity (BLEU) and sentence completeness (ROUGE), yielding the optimized model termed SLT-GRPO. Our conceptually simple framework yields substantial gains under the gloss-free SLT setting without pre-training on any external large-scale sign language datasets, improving BLEU-4 scores by +5.1, +1.11, +1.4, and +1.61 on the CSL-Daily, PHOENIX-2014T, How2Sign, and OpenASL datasets, respectively. To the best of our knowledge, this is the first work to incorporate GRPO into SLT. Extensive experiments and ablation studies validate the effectiveness of GRPO-based optimization in enhancing both translation quality and semantic consistency.

