---
layout: default
title: MUSE: A Simple Yet Effective Multimodal Search-Based Framework for Lifelong User Interest Modeling
---

# MUSE: A Simple Yet Effective Multimodal Search-Based Framework for Lifelong User Interest Modeling

**arXiv**: [2512.07216v1](https://arxiv.org/abs/2512.07216) | [PDF](https://arxiv.org/pdf/2512.07216.pdf)

**ä½œè€…**: Bin Wu, Feifan Yang, Zhangming Chan, Yu-Ran Gu, Jiawei Feng, Chao Yi, Xiang-Rong Sheng, Han Zhu, Jian Xu, Mang Ye, Bo Zheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMUSEæ¡†æž¶ï¼Œé€šè¿‡ä¸¤é˜¶æ®µå¤šæ¨¡æ€æœç´¢è§£å†³æŽ¨èç³»ç»Ÿä¸­ç»ˆèº«ç”¨æˆ·å…´è¶£å»ºæ¨¡çš„æ³›åŒ–ä¸Žè¯­ä¹‰è¡¨è¾¾é—®é¢˜ã€‚**

**å…³é”®è¯**: `ç»ˆèº«ç”¨æˆ·å…´è¶£å»ºæ¨¡` `å¤šæ¨¡æ€æœç´¢` `æŽ¨èç³»ç»Ÿ` `è¡Œä¸ºåºåˆ—å»ºæ¨¡` `å·¥ä¸šéƒ¨ç½²`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•ä¾èµ–IDç‰¹å¾ï¼Œåœ¨é•¿å°¾ç‰©å“ä¸Šæ³›åŒ–å·®ä¸”è¯­ä¹‰è¡¨è¾¾æœ‰é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåœ¨GSUé˜¶æ®µä½¿ç”¨è½»é‡ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œåœ¨ESUé˜¶æ®µç»“åˆå¤šæ¨¡æ€åºåˆ—å»ºæ¨¡ä¸ŽID-å¤šæ¨¡æ€èžåˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šéƒ¨ç½²äºŽæ·˜å®å¹¿å‘Šç³»ç»Ÿï¼Œæ”¯æŒ10ä¸‡é•¿åº¦è¡Œä¸ºåºåˆ—å»ºæ¨¡ï¼Œæ˜¾è‘—æå‡æŒ‡æ ‡ä¸”åœ¨çº¿å»¶è¿Ÿå¯å¿½ç•¥ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Lifelong user interest modeling is crucial for industrial recommender systems, yet existing approaches rely predominantly on ID-based features, suffering from poor generalization on long-tail items and limited semantic expressiveness. While recent work explores multimodal representations for behavior retrieval in the General Search Unit (GSU), they often neglect multimodal integration in the fine-grained modeling stage -- the Exact Search Unit (ESU). In this work, we present a systematic analysis of how to effectively leverage multimodal signals across both stages of the two-stage lifelong modeling framework. Our key insight is that simplicity suffices in the GSU: lightweight cosine similarity with high-quality multimodal embeddings outperforms complex retrieval mechanisms. In contrast, the ESU demands richer multimodal sequence modeling and effective ID-multimodal fusion to unlock its full potential. Guided by these principles, we propose MUSE, a simple yet effective multimodal search-based framework. MUSE has been deployed in Taobao display advertising system, enabling 100K-length user behavior sequence modeling and delivering significant gains in top-line metrics with negligible online latency overhead. To foster community research, we share industrial deployment practices and open-source the first large-scale dataset featuring ultra-long behavior sequences paired with high-quality multimodal embeddings. Our code and data is available at https://taobao-mm.github.io.

