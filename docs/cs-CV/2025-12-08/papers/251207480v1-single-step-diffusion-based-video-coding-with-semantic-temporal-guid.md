---
layout: default
title: Single-step Diffusion-based Video Coding with Semantic-Temporal Guidance
---

# Single-step Diffusion-based Video Coding with Semantic-Temporal Guidance

**arXiv**: [2512.07480v1](https://arxiv.org/abs/2512.07480) | [PDF](https://arxiv.org/pdf/2512.07480.pdf)

**ä½œè€…**: Naifu Xue, Zhaoyang Jia, Jiahao Li, Bin Li, Zihan Zheng, Yuan Zhang, Yan Lu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºS2VCå•æ­¥æ‰©æ•£è§†é¢‘ç¼–ç å™¨ï¼Œç»“åˆè¯­ä¹‰ä¸Žæ—¶åºæŒ‡å¯¼ï¼Œåœ¨ä½Žç çŽ‡ä¸‹å®žçŽ°é«˜æ•ˆé«˜è´¨é‡è§†é¢‘åŽ‹ç¼©ã€‚**

**å…³é”®è¯**: `è§†é¢‘ç¼–ç ` `æ‰©æ•£æ¨¡åž‹` `è¯­ä¹‰æŒ‡å¯¼` `æ—¶åºä¸€è‡´æ€§` `ä½Žç çŽ‡åŽ‹ç¼©` `å•æ­¥ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿä¸Žç¥žç»è§†é¢‘ç¼–ç åœ¨ä½Žç çŽ‡ä¸‹æ„ŸçŸ¥è´¨é‡æå‡å›°éš¾ï¼ŒçŽ°æœ‰æ–¹æ³•å­˜åœ¨ç”Ÿæˆèƒ½åŠ›ä¸è¶³æˆ–é‡‡æ ·å¤æ‚åº¦é«˜çš„é—®é¢˜ã€‚
2. S2VCé‡‡ç”¨æ¡ä»¶ç¼–ç æ¡†æž¶ä¸Žå•æ­¥æ‰©æ•£ç”Ÿæˆå™¨ï¼Œå¼•å…¥ä¸Šä¸‹æ–‡è¯­ä¹‰æŒ‡å¯¼å’Œæ—¶åºä¸€è‡´æ€§æŒ‡å¯¼ï¼Œæå‡ç”ŸæˆçœŸå®žæ€§ä¸Žç¨³å®šæ€§ã€‚
3. å®žéªŒè¡¨æ˜ŽS2VCåœ¨æ„ŸçŸ¥è´¨é‡ä¸Šè¾¾åˆ°å…ˆè¿›æ°´å¹³ï¼Œç›¸æ¯”å…ˆå‰æ–¹æ³•å¹³å‡èŠ‚çœ52.73%ç çŽ‡ï¼ŒéªŒè¯å•æ­¥æ‰©æ•£åœ¨è§†é¢‘åŽ‹ç¼©ä¸­çš„é«˜æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While traditional and neural video codecs (NVCs) have achieved remarkable rate-distortion performance, improving perceptual quality at low bitrates remains challenging. Some NVCs incorporate perceptual or adversarial objectives but still suffer from artifacts due to limited generation capacity, whereas others leverage pretrained diffusion models to improve quality at the cost of heavy sampling complexity. To overcome these challenges, we propose S2VC, a Single-Step diffusion based Video Codec that integrates a conditional coding framework with an efficient single-step diffusion generator, enabling realistic reconstruction at low bitrates with reduced sampling cost. Recognizing the importance of semantic conditioning in single-step diffusion, we introduce Contextual Semantic Guidance to extract frame-adaptive semantics from buffered features. It replaces text captions with efficient, fine-grained conditioning, thereby improving generation realism. In addition, Temporal Consistency Guidance is incorporated into the diffusion U-Net to enforce temporal coherence across frames and ensure stable generation. Extensive experiments show that S2VC delivers state-of-the-art perceptual quality with an average 52.73% bitrate saving over prior perceptual methods, underscoring the promise of single-step diffusion for efficient, high-quality video compression.

