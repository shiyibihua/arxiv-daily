---
layout: default
title: START: Spatial and Textual Learning for Chart Understanding
---

# START: Spatial and Textual Learning for Chart Understanding

**arXiv**: [2512.07186v1](https://arxiv.org/abs/2512.07186) | [PDF](https://arxiv.org/pdf/2512.07186.pdf)

**ä½œè€…**: Zhuoming Liu, Xiaofeng Gao, Feiyang Niu, Qiaozi Gao, Liu Liu, Robinson Piramuthu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSTARTæ–¹æ³•ä»¥å¢žå¼ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹åœ¨å›¾è¡¨ç†è§£ä¸­çš„ç©ºé—´ä¸Žæ–‡æœ¬å­¦ä¹ èƒ½åŠ›**

**å…³é”®è¯**: `å›¾è¡¨ç†è§£` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `ç©ºé—´å­¦ä¹ ` `æ–‡æœ¬å­¦ä¹ ` `å›¾è¡¨å…ƒç´ å®šä½` `å›¾è¡¨åˆ°ä»£ç ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå›¾è¡¨ç»“åˆç»“æž„åŒ–è§†è§‰å¸ƒå±€ä¸Žåº•å±‚æ•°æ®è¡¨ç¤ºï¼Œéœ€åŒæ—¶ç†è§£ä¸¤è€…ä»¥å®žçŽ°ç²¾ç¡®æŽ¨ç†
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥å›¾è¡¨å…ƒç´ å®šä½å’Œå›¾è¡¨åˆ°ä»£ç ç”Ÿæˆï¼Œé€šè¿‡START-Datasetå’ŒCS-Benchæ”¯æŒå­¦ä¹ ä¸Žè¯„ä¼°
3. å®žéªŒæˆ–æ•ˆæžœï¼šSTARTåœ¨ä¸åŒæ¨¡åž‹è§„æ¨¡å’ŒåŸºå‡†ä¸Šä¼˜äºŽåŸºçº¿åŠå…ˆå‰æ–¹æ³•ï¼Œä»£ç ã€æ•°æ®å’Œæ¨¡åž‹å°†å…¬å¼€

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Chart understanding is crucial for deploying multimodal large language models (MLLMs) in real-world scenarios such as analyzing scientific papers and technical reports. Unlike natural images, charts pair a structured visual layout (spatial property) with an underlying data representation (textual property) -- grasping both is essential for precise, fine-grained chart reasoning. Motivated by this observation, we propose START, the Spatial and Textual learning for chART understanding. Specifically, we introduce (i) chart-element grounding and (ii) chart-to-code generation to strengthen an MLLM's understanding of both chart visual layout and data details. To facilitate spatial and textual learning, we propose the START-Dataset generated with a novel data-generation pipeline that first leverages an MLLM to translate real chart images into executable chart code, recovering the underlying data representation while preserving the visual distribution of real-world charts. We then evolve the code with a Large Language Model (LLM) to ascertain the positions of chart elements that capture the chart's visual structure, addressing challenges that existing methods cannot handle. To evaluate a model's ability to understand chart spatial structures, we propose the Chart Spatial understanding Benchmark (CS-Bench), filling a critical gap in comprehensive chart understanding evaluation. Leveraging spatial and textual learning, START delivers consistent gains across model sizes and benchmarks over the base models and surpasses prior state-of-the-art by a clear margin. Code, data and models will be publicly available.

