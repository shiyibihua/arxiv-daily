---
layout: default
title: When Large Language Models Do Not Work: Online Incivility Prediction through Graph Neural Networks
---

# When Large Language Models Do Not Work: Online Incivility Prediction through Graph Neural Networks

**arXiv**: [2512.07684v1](https://arxiv.org/abs/2512.07684) | [PDF](https://arxiv.org/pdf/2512.07684.pdf)

**ä½œè€…**: Zihan Chen, Lanyu Yu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå›¾ç¥žç»ç½‘ç»œçš„æ¡†æž¶ï¼Œä»¥è§£å†³åœ¨çº¿ç¤¾åŒºä¸æ–‡æ˜Žè¡Œä¸ºæ£€æµ‹ä¸­å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ä¸è¶³çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `åœ¨çº¿ä¸æ–‡æ˜Žè¡Œä¸ºæ£€æµ‹` `å›¾ç¥žç»ç½‘ç»œ` `æ–‡æœ¬ç›¸ä¼¼æ€§` `æ³¨æ„åŠ›æœºåˆ¶` `è¡Œä¸ºé¢„æµ‹` `è‹±è¯­ç»´åŸºç™¾ç§‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åœ¨çº¿ä¸æ–‡æ˜Žè¡Œä¸ºåœ¨æ•°å­—ç¤¾åŒºä¸­æ™®éå­˜åœ¨ï¼ŒçŽ°æœ‰æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ä¸Šå—é™ã€‚
2. æ¨¡åž‹å°†ç”¨æˆ·è¯„è®ºè¡¨ç¤ºä¸ºèŠ‚ç‚¹ï¼ŒåŸºäºŽæ–‡æœ¬ç›¸ä¼¼æ€§æž„å»ºè¾¹ï¼Œç»“åˆè¯­è¨€å†…å®¹å’Œå…³ç³»ç»“æž„å­¦ä¹ ã€‚
3. å®žéªŒæ˜¾ç¤ºï¼Œè¯¥æ¡†æž¶åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šä¼˜äºŽ12ä¸ªå¤§åž‹è¯­è¨€æ¨¡åž‹ï¼Œä¸”æŽ¨ç†æˆæœ¬æ˜¾è‘—é™ä½Žã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Online incivility has emerged as a widespread and persistent problem in digital communities, imposing substantial social and psychological burdens on users. Although many platforms attempt to curb incivility through moderation and automated detection, the performance of existing approaches often remains limited in both accuracy and efficiency. To address this challenge, we propose a Graph Neural Network (GNN) framework for detecting three types of uncivil behavior (i.e., toxicity, aggression, and personal attacks) within the English Wikipedia community. Our model represents each user comment as a node, with textual similarity between comments defining the edges, allowing the network to jointly learn from both linguistic content and relational structures among comments. We also introduce a dynamically adjusted attention mechanism that adaptively balances nodal and topological features during information aggregation. Empirical evaluations demonstrate that our proposed architecture outperforms 12 state-of-the-art Large Language Models (LLMs) across multiple metrics while requiring significantly lower inference cost. These findings highlight the crucial role of structural context in detecting online incivility and address the limitations of text-only LLM paradigms in behavioral prediction. All datasets and comparative outputs will be publicly available in our repository to support further research and reproducibility.

