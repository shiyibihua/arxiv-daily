---
layout: default
title: InterAgent: Physics-based Multi-agent Command Execution via Diffusion on Interaction Graphs
---

# InterAgent: Physics-based Multi-agent Command Execution via Diffusion on Interaction Graphs

**arXiv**: [2512.07410v1](https://arxiv.org/abs/2512.07410) | [PDF](https://arxiv.org/pdf/2512.07410.pdf)

**ä½œè€…**: Bin Li, Ruichi Zhang, Han Liang, Jingyan Zhang, Juze Zhang, Xin Chen, Lan Xu, Jingyi Yu, Jingya Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInterAgentæ¡†æž¶ï¼Œé€šè¿‡äº¤äº’å›¾æ‰©æ•£å®žçŽ°åŸºäºŽç‰©ç†çš„å¤šæ™ºèƒ½ä½“äººå½¢æŽ§åˆ¶**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“æŽ§åˆ¶` `ç‰©ç†æ¨¡æ‹Ÿ` `æ‰©æ•£æ¨¡åž‹` `äº¤äº’å›¾` `äººå½¢æœºå™¨äºº` `æ–‡æœ¬é©±åŠ¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•å¤šå±€é™äºŽå•æ™ºèƒ½ä½“åœºæ™¯ï¼Œç¼ºä¹ç‰©ç†åˆç†çš„å¤šæ™ºèƒ½ä½“äº¤äº’å»ºæ¨¡
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨è‡ªå›žå½’æ‰©æ•£å˜æ¢å™¨ä¸Žå¤šæµå—ï¼Œè§£è€¦æœ¬ä½“æ„ŸçŸ¥ã€å¤–æ„ŸçŸ¥å’ŒåŠ¨ä½œï¼Œå¹¶å¼•å…¥äº¤äº’å›¾å¤–æ„ŸçŸ¥è¡¨ç¤ºä¸Žç¨€ç–è¾¹æ³¨æ„åŠ›æœºåˆ¶
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å®žéªŒä¸­è¶…è¶Šå¤šä¸ªåŸºçº¿ï¼Œå®žçŽ°ä»Žæ–‡æœ¬æç¤ºç”Ÿæˆè¿žè´¯ã€ç‰©ç†åˆç†ä¸”è¯­ä¹‰å¿ å®žçš„è¡Œä¸º

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Humanoid agents are expected to emulate the complex coordination inherent in human social behaviors. However, existing methods are largely confined to single-agent scenarios, overlooking the physically plausible interplay essential for multi-agent interactions. To bridge this gap, we propose InterAgent, the first end-to-end framework for text-driven physics-based multi-agent humanoid control. At its core, we introduce an autoregressive diffusion transformer equipped with multi-stream blocks, which decouples proprioception, exteroception, and action to mitigate cross-modal interference while enabling synergistic coordination. We further propose a novel interaction graph exteroception representation that explicitly captures fine-grained joint-to-joint spatial dependencies to facilitate network learning. Additionally, within it we devise a sparse edge-based attention mechanism that dynamically prunes redundant connections and emphasizes critical inter-agent spatial relations, thereby enhancing the robustness of interaction modeling. Extensive experiments demonstrate that InterAgent consistently outperforms multiple strong baselines, achieving state-of-the-art performance. It enables producing coherent, physically plausible, and semantically faithful multi-agent behaviors from only text prompts. Our code and data will be released to facilitate future research.

