---
layout: default
title: AdLift: Lifting Adversarial Perturbations to Safeguard 3D Gaussian Splatting Assets Against Instruction-Driven Editing
---

# AdLift: Lifting Adversarial Perturbations to Safeguard 3D Gaussian Splatting Assets Against Instruction-Driven Editing

**arXiv**: [2512.07247v1](https://arxiv.org/abs/2512.07247) | [PDF](https://arxiv.org/pdf/2512.07247.pdf)

**ä½œè€…**: Ziming Hong, Tianyu Huang, Runnan Chen, Shanshan Ye, Mingming Gong, Bo Han, Tongliang Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAdLiftæ–¹æ³•ï¼Œé€šè¿‡æå‡2Då¯¹æŠ—æ‰°åŠ¨è‡³3Dé«˜æ–¯è¡¨ç¤ºï¼Œä¿æŠ¤3Dé«˜æ–¯æ³¼æº…èµ„äº§å…å—æŒ‡ä»¤é©±åŠ¨ç¼–è¾‘çš„å¨èƒã€‚**

**å…³é”®è¯**: `3Dé«˜æ–¯æ³¼æº…` `å¯¹æŠ—æ‰°åŠ¨` `æŒ‡ä»¤é©±åŠ¨ç¼–è¾‘` `èµ„äº§ä¿æŠ¤` `å¤šè§†è§’æ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼š3Dé«˜æ–¯æ³¼æº…èµ„äº§é¢ä¸´æŒ‡ä»¤é©±åŠ¨ç¼–è¾‘çš„æœªæŽˆæƒç¯¡æ”¹é£Žé™©ï¼ŒçŽ°æœ‰2Då¯¹æŠ—æ‰°åŠ¨æ–¹æ³•éš¾ä»¥ç›´æŽ¥åº”ç”¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨Lifted PGDä¼˜åŒ–ï¼Œé€šè¿‡æ¢¯åº¦æˆªæ–­å’Œå›¾åƒåˆ°é«˜æ–¯æ‹Ÿåˆï¼Œå°†ä¸¥æ ¼æœ‰ç•Œçš„2Dæ‰°åŠ¨æå‡ä¸º3Dé«˜æ–¯ä¿æŠ¤è¡¨ç¤ºã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šAdLiftåœ¨å®šæ€§å’Œå®šé‡å®žéªŒä¸­æœ‰æ•ˆæŠµå¾¡å…ˆè¿›æŒ‡ä»¤é©±åŠ¨ç¼–è¾‘ï¼Œå®žçŽ°å¤šè§†è§’ä¸€è‡´ä¿æŠ¤ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent studies have extended diffusion-based instruction-driven 2D image editing pipelines to 3D Gaussian Splatting (3DGS), enabling faithful manipulation of 3DGS assets and greatly advancing 3DGS content creation. However, it also exposes these assets to serious risks of unauthorized editing and malicious tampering. Although imperceptible adversarial perturbations against diffusion models have proven effective for protecting 2D images, applying them to 3DGS encounters two major challenges: view-generalizable protection and balancing invisibility with protection capability. In this work, we propose the first editing safeguard for 3DGS, termed AdLift, which prevents instruction-driven editing across arbitrary views and dimensions by lifting strictly bounded 2D adversarial perturbations into 3D Gaussian-represented safeguard. To ensure both adversarial perturbations effectiveness and invisibility, these safeguard Gaussians are progressively optimized across training views using a tailored Lifted PGD, which first conducts gradient truncation during back-propagation from the editing model at the rendered image and applies projected gradients to strictly constrain the image-level perturbation. Then, the resulting perturbation is backpropagated to the safeguard Gaussian parameters via an image-to-Gaussian fitting operation. We alternate between gradient truncation and image-to-Gaussian fitting, yielding consistent adversarial-based protection performance across different viewpoints and generalizes to novel views. Empirically, qualitative and quantitative results demonstrate that AdLift effectively protects against state-of-the-art instruction-driven 2D image and 3DGS editing.

