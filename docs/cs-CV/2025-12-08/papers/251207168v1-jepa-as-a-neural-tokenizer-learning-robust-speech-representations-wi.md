---
layout: default
title: JEPA as a Neural Tokenizer: Learning Robust Speech Representations with Density Adaptive Attention
---

# JEPA as a Neural Tokenizer: Learning Robust Speech Representations with Density Adaptive Attention

**arXiv**: [2512.07168v1](https://arxiv.org/abs/2512.07168) | [PDF](https://arxiv.org/pdf/2512.07168.pdf)

**ä½œè€…**: Georgios Ioannides, Christos Constantinou, Aman Chadha, Aaron Elkins, Linsey Pang, Ravid Shwartz-Ziv, Yann LeCun

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“åˆJEPAä¸Žå¯†åº¦è‡ªé€‚åº”æ³¨æ„åŠ›çš„ä¸¤é˜¶æ®µè‡ªç›‘ç£æ¡†æž¶ï¼Œç”¨äºŽå­¦ä¹ é²æ£’è¯­éŸ³è¡¨ç¤ºå’Œé«˜æ•ˆä»¤ç‰ŒåŒ–ã€‚**

**å…³é”®è¯**: `è‡ªç›‘ç£å­¦ä¹ ` `è¯­éŸ³è¡¨ç¤ºå­¦ä¹ ` `ç¥žç»éŸ³é¢‘ç¼–è§£ç ` `æ³¨æ„åŠ›æœºåˆ¶` `ä»¤ç‰ŒåŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœªçŸ¥ï¼Œä½†æ—¨åœ¨å­¦ä¹ é²æ£’è¯­éŸ³è¡¨ç¤ºä»¥æ”¯æŒé«˜æ•ˆåŽ‹ç¼©å’Œè¯­è¨€æ¨¡åž‹å‹å¥½æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç¬¬ä¸€é˜¶æ®µä½¿ç”¨JEPAä¸Žå¯†åº¦è‡ªé€‚åº”æ³¨æ„åŠ›è¿›è¡Œæ½œåœ¨ç©ºé—´æŽ©ç é¢„æµ‹ï¼Œç¬¬äºŒé˜¶æ®µåˆ©ç”¨FSQå’Œæ··åˆåŸºæ•°æ‰“åŒ…è¿›è¡Œä»¤ç‰ŒåŒ–ï¼Œç»“åˆHiFi-GANè§£ç å™¨é‡å»ºæ³¢å½¢ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¨¡åž‹åœ¨2.5 Hzä½Žå¸§çŽ‡ä¸‹å®žçŽ°è‡ªé€‚åº”æ—¶é—´ç‰¹å¾é€‰æ‹©å’Œåˆ†å±‚ç»“æž„å‘çŽ°ï¼Œä»¤ç‰Œé€ŸçŽ‡47.5 tokens/secï¼Œä¸ŽçŽ°æœ‰ç¥žç»éŸ³é¢‘ç¼–è§£ç å™¨ç«žäº‰ä¸”æ›´é«˜æ•ˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce a two-stage self-supervised framework that combines the Joint-Embedding Predictive Architecture (JEPA) with a Density Adaptive Attention Mechanism (DAAM) for learning robust speech representations. Stage~1 uses JEPA with DAAM to learn semantic audio features via masked prediction in latent space, fully decoupled from waveform reconstruction. Stage~2 leverages these representations for efficient tokenization using Finite Scalar Quantization (FSQ) and a mixed-radix packing scheme, followed by high-fidelity waveform reconstruction with a HiFi-GAN decoder. By integrating Gaussian mixture-based density-adaptive gating into the JEPA encoder, the model performs adaptive temporal feature selection and discovers hierarchical speech structure at a low frame rate of 2.5~Hz. The resulting tokens (47.5 tokens/sec) provide a reversible, highly compressed, and language-model-friendly representation that is competitive with, and often more efficient than, existing neural audio codecs.

