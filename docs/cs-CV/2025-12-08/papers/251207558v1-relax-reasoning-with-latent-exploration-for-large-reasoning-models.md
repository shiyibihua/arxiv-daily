---
layout: default
title: ReLaX: Reasoning with Latent Exploration for Large Reasoning Models
---

# ReLaX: Reasoning with Latent Exploration for Large Reasoning Models

**arXiv**: [2512.07558v1](https://arxiv.org/abs/2512.07558) | [PDF](https://arxiv.org/pdf/2512.07558.pdf)

**ä½œè€…**: Shimin Zhang, Xianwei Chen, Yufan Shen, Ziyuan Ye, Jibin Wu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºReLaXèŒƒå¼ï¼Œé€šè¿‡è°ƒæŽ§æ½œåœ¨åŠ¨æ€ä»¥è§£å†³å¤§åž‹æŽ¨ç†æ¨¡åž‹ä¸­çš„ç†µå´©æºƒé—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤§åž‹æŽ¨ç†æ¨¡åž‹` `å¼ºåŒ–å­¦ä¹ ` `æ½œåœ¨åŠ¨æ€åˆ†æž` `æŽ¢ç´¢ä¸Žåˆ©ç”¨å¹³è¡¡` `Koopmanç®—å­ç†è®º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šRLVRå¯¼è‡´ç†µå´©æºƒï¼Œå¼•å‘ç­–ç•¥æ—©ç†Ÿæ”¶æ•›å’Œæ€§èƒ½é¥±å’Œã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨Koopmanç®—å­ç†è®ºçº¿æ€§åŒ–æ½œåœ¨åŠ¨æ€ï¼Œå¼•å…¥DSDæŒ‡æ ‡é‡åŒ–æŽ¢ç´¢ï¼Œæå‡ºReLaXè°ƒæŽ§æŽ¢ç´¢ä¸Žåˆ©ç”¨ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šæ¨¡æ€å’Œçº¯æ–‡æœ¬æŽ¨ç†åŸºå‡†ä¸Šæ˜¾è‘—ç¼“è§£æ—©ç†Ÿæ”¶æ•›ï¼Œå®žçŽ°SOTAæ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated remarkable potential in enhancing the reasoning capability of Large Reasoning Models (LRMs). However, RLVR often leads to entropy collapse, resulting in premature policy convergence and performance saturation. While manipulating token-level entropy has proven effective for promoting policy exploration, we argue that the latent dynamics underlying token generation encode a far richer computational structure for steering policy optimization toward a more effective exploration-exploitation tradeoff. To enable tractable analysis and intervention of the latent dynamics of LRMs, we leverage Koopman operator theory to obtain a linearized representation of their hidden-state dynamics. This enables us to introduce Dynamic Spectral Dispersion (DSD), a new metric to quantify the heterogeneity of the model's latent dynamics, serving as a direct indicator of policy exploration. Building upon these foundations, we propose Reasoning with Latent eXploration (ReLaX), a paradigm that explicitly incorporates latent dynamics to regulate exploration and exploitation during policy optimization. Comprehensive experiments across a wide range of multimodal and text-only reasoning benchmarks show that ReLaX significantly mitigates premature convergence and consistently achieves state-of-the-art performance.

