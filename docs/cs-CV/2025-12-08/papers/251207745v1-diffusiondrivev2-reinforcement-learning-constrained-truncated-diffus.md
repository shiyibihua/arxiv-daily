---
layout: default
title: DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving
---

# DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving

**arXiv**: [2512.07745v1](https://arxiv.org/abs/2512.07745) | [PDF](https://arxiv.org/pdf/2512.07745.pdf)

**ä½œè€…**: Jialv Zou, Shaoyu Chen, Bencheng Liao, Zhiyu Zheng, Yuehao Song, Lefei Zhang, Qian Zhang, Wenyu Liu, Xinggang Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDiffusionDriveV2ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ çº¦æŸæˆªæ–­æ‰©æ•£æ¨¡åž‹ï¼Œè§£å†³ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ä¸­å¤šæ ·æ€§ä¸Žé«˜è´¨é‡è½¨è¿¹ç”Ÿæˆçš„å›°å¢ƒã€‚**

**å…³é”®è¯**: `ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶` `æ‰©æ•£æ¨¡åž‹` `å¼ºåŒ–å­¦ä¹ ` `è½¨è¿¹ç”Ÿæˆ` `æ¨¡å¼å´©æºƒ` `æˆªæ–­å»ºæ¨¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç”Ÿæˆæ‰©æ•£æ¨¡åž‹åœ¨ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ä¸­æ˜“å‡ºçŽ°æ¨¡å¼å´©æºƒï¼Œå¯¼è‡´ä¿å®ˆå’ŒåŒè´¨åŒ–è¡Œä¸ºï¼Œéš¾ä»¥å¹³è¡¡å¤šæ ·æ€§ä¸Žä¸€è‡´é«˜è´¨é‡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å°ºåº¦è‡ªé€‚åº”ä¹˜æ€§å™ªå£°ä¿ƒè¿›æŽ¢ç´¢ï¼Œç»“åˆé”šå†…GRPOå’Œé”šé—´æˆªæ–­GRPOç®¡ç†ä¼˜åŠ¿ä¼°è®¡ï¼Œé¿å…ä¸åŒæ„å›¾é—´ä¸å½“æ¯”è¾ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨NAVSIMæ•°æ®é›†ä¸Šå–å¾—é¢†å…ˆæ€§èƒ½ï¼ŒéªŒè¯äº†æ–¹æ³•åœ¨å¤šæ ·æ€§ä¸Žé«˜è´¨é‡é—´çš„ä¼˜åŒ–å¹³è¡¡ï¼Œä»£ç å°†å¼€æºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generative diffusion models for end-to-end autonomous driving often suffer from mode collapse, tending to generate conservative and homogeneous behaviors. While DiffusionDrive employs predefined anchors representing different driving intentions to partition the action space and generate diverse trajectories, its reliance on imitation learning lacks sufficient constraints, resulting in a dilemma between diversity and consistent high quality. In this work, we propose DiffusionDriveV2, which leverages reinforcement learning to both constrain low-quality modes and explore for superior trajectories. This significantly enhances the overall output quality while preserving the inherent multimodality of its core Gaussian Mixture Model. First, we use scale-adaptive multiplicative noise, ideal for trajectory planning, to promote broad exploration. Second, we employ intra-anchor GRPO to manage advantage estimation among samples generated from a single anchor, and inter-anchor truncated GRPO to incorporate a global perspective across different anchors, preventing improper advantage comparisons between distinct intentions (e.g., turning vs. going straight), which can lead to further mode collapse. DiffusionDriveV2 achieves 91.2 PDMS on the NAVSIM v1 dataset and 85.5 EPDMS on the NAVSIM v2 dataset in closed-loop evaluation with an aligned ResNet-34 backbone, setting a new record. Further experiments validate that our approach resolves the dilemma between diversity and consistent high quality for truncated diffusion models, achieving the best trade-off. Code and model will be available at https://github.com/hustvl/DiffusionDriveV2

