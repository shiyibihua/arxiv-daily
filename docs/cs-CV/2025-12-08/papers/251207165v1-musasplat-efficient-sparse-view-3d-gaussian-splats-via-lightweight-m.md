---
layout: default
title: MuSASplat: Efficient Sparse-View 3D Gaussian Splats via Lightweight Multi-Scale Adaptation
---

# MuSASplat: Efficient Sparse-View 3D Gaussian Splats via Lightweight Multi-Scale Adaptation

**arXiv**: [2512.07165v1](https://arxiv.org/abs/2512.07165) | [PDF](https://arxiv.org/pdf/2512.07165.pdf)

**ä½œè€…**: Muyu Xu, Fangneng Zhan, Xiaoqin Zhang, Ling Shao, Shijian Lu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMuSASplatæ¡†æž¶ï¼Œé€šè¿‡è½»é‡çº§å¤šå°ºåº¦é€‚é…å™¨é«˜æ•ˆè®­ç»ƒç¨€ç–è§†å›¾3Dé«˜æ–¯æº…å°„æ¨¡åž‹ã€‚**

**å…³é”®è¯**: `ç¨€ç–è§†å›¾3Dé‡å»º` `3Dé«˜æ–¯æº…å°„` `è½»é‡çº§å¾®è°ƒ` `å¤šå°ºåº¦é€‚é…å™¨` `ç‰¹å¾èžåˆèšåˆå™¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç¨€ç–è§†å›¾3Dé«˜æ–¯æº…å°„è®­ç»ƒè®¡ç®—æˆæœ¬é«˜ï¼ŒçŽ°æœ‰æ–¹æ³•ä¾èµ–å¤§æ¨¡åž‹å…¨å¾®è°ƒã€‚
2. å¼•å…¥è½»é‡çº§å¤šå°ºåº¦é€‚é…å™¨ï¼Œä»…å¾®è°ƒå°‘é‡å‚æ•°ï¼Œé™ä½ŽGPUå¼€é”€ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œåœ¨ä¿æŒæ¸²æŸ“è´¨é‡çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘å‚æ•°å’Œè®­ç»ƒèµ„æºéœ€æ±‚ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Sparse-view 3D Gaussian splatting seeks to render high-quality novel views of 3D scenes from a limited set of input images. While recent pose-free feed-forward methods leveraging pre-trained 3D priors have achieved impressive results, most of them rely on full fine-tuning of large Vision Transformer (ViT) backbones and incur substantial GPU costs. In this work, we introduce MuSASplat, a novel framework that dramatically reduces the computational burden of training pose-free feed-forward 3D Gaussian splats models with little compromise of rendering quality. Central to our approach is a lightweight Multi-Scale Adapter that enables efficient fine-tuning of ViT-based architectures with only a small fraction of training parameters. This design avoids the prohibitive GPU overhead associated with previous full-model adaptation techniques while maintaining high fidelity in novel view synthesis, even with very sparse input views. In addition, we introduce a Feature Fusion Aggregator that integrates features across input views effectively and efficiently. Unlike widely adopted memory banks, the Feature Fusion Aggregator ensures consistent geometric integration across input views and meanwhile mitigates the memory usage, training complexity, and computational costs significantly. Extensive experiments across diverse datasets show that MuSASplat achieves state-of-the-art rendering quality but has significantly reduced parameters and training resource requirements as compared with existing methods.

