---
layout: default
title: MultiMotion: Multi Subject Video Motion Transfer via Video Diffusion Transformer
---

# MultiMotion: Multi Subject Video Motion Transfer via Video Diffusion Transformer

**arXiv**: [2512.07500v1](https://arxiv.org/abs/2512.07500) | [PDF](https://arxiv.org/pdf/2512.07500.pdf)

**ä½œè€…**: Penghui Liu, Jiangshan Wang, Yutong Shen, Shanhui Mo, Chenyang Qi, Yue Ma

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMultiMotionæ¡†æž¶ï¼Œé€šè¿‡Maskaware Attention Motion Flowè§£å†³å¤šå¯¹è±¡è§†é¢‘è¿åŠ¨è½¬ç§»ä¸­çš„è¿åŠ¨çº ç¼ é—®é¢˜ã€‚**

**å…³é”®è¯**: `è§†é¢‘è¿åŠ¨è½¬ç§»` `æ‰©æ•£å˜æ¢å™¨` `å¤šå¯¹è±¡æŽ§åˆ¶` `è¿åŠ¨è§£ç¼ ` `åŸºå‡†æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šå¯¹è±¡è§†é¢‘è¿åŠ¨è½¬ç§»åœ¨Diffusion Transformerä¸­é¢ä¸´è¿åŠ¨çº ç¼ å’Œå¯¹è±¡çº§æŽ§åˆ¶ç¼ºå¤±çš„æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥Maskaware Attention Motion Flowï¼Œåˆ©ç”¨SAM2æŽ©ç åœ¨DiTæµç¨‹ä¸­æ˜¾å¼è§£ç¼ å’ŒæŽ§åˆ¶å¤šå¯¹è±¡è¿åŠ¨ç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæž„å»ºé¦–ä¸ªåŸºäºŽDiTçš„å¤šå¯¹è±¡è¿åŠ¨è½¬ç§»åŸºå‡†æ•°æ®é›†ï¼Œå®žçŽ°ç²¾ç¡®ã€è¯­ä¹‰å¯¹é½ä¸”æ—¶é—´ä¸€è‡´çš„è¿åŠ¨è½¬ç§»ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-object video motion transfer poses significant challenges for Diffusion Transformer (DiT) architectures due to inherent motion entanglement and lack of object-level control. We present MultiMotion, a novel unified framework that overcomes these limitations. Our core innovation is Maskaware Attention Motion Flow (AMF), which utilizes SAM2 masks to explicitly disentangle and control motion features for multiple objects within the DiT pipeline. Furthermore, we introduce RectPC, a high-order predictor-corrector solver for efficient and accurate sampling, particularly beneficial for multi-entity generation. To facilitate rigorous evaluation, we construct the first benchmark dataset specifically for DiT-based multi-object motion transfer. MultiMotion demonstrably achieves precise, semantically aligned, and temporally coherent motion transfer for multiple distinct objects, maintaining DiT's high quality and scalability. The code is in the supp.

