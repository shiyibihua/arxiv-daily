---
layout: default
title: Effective Attention-Guided Multi-Scale Medical Network for Skin Lesion Segmentation
---

# Effective Attention-Guided Multi-Scale Medical Network for Skin Lesion Segmentation

**arXiv**: [2512.07275v1](https://arxiv.org/abs/2512.07275) | [PDF](https://arxiv.org/pdf/2512.07275.pdf)

**ä½œè€…**: Siyu Wang, Hua Wang, Huiyu Li, Fan Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå¤šå°ºåº¦æ®‹å·®å’Œæ³¨æ„åŠ›æœºåˆ¶çš„ç¼–ç å™¨-è§£ç å™¨ç½‘ç»œï¼Œä»¥è§£å†³çš®è‚¤ç—…ç¶åˆ†å‰²ä¸­å½¢çŠ¶ä¸è§„åˆ™å’Œå¯¹æ¯”åº¦ä½Žçš„æŒ‘æˆ˜ã€‚**

**å…³é”®è¯**: `çš®è‚¤ç—…ç¶åˆ†å‰²` `å¤šå°ºåº¦ç‰¹å¾èžåˆ` `æ³¨æ„åŠ›æœºåˆ¶` `ç¼–ç å™¨-è§£ç å™¨ç½‘ç»œ` `åŒ»å­¦å›¾åƒå¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçš®è‚¤ç—…ç¶åˆ†å‰²é¢ä¸´ç—…ç¶å½¢çŠ¶ä¸è§„åˆ™å’Œå›¾åƒå¯¹æ¯”åº¦ä½Žçš„éš¾é¢˜ï¼Œå½±å“æ—©æœŸæ£€æµ‹å’Œè¯Šæ–­å‡†ç¡®æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥å¤šåˆ†è¾¨çŽ‡å¤šé€šé“èžåˆæ¨¡å—å’Œäº¤å‰æ··åˆæ³¨æ„åŠ›æ¨¡å—ï¼Œå¢žå¼ºç‰¹å¾æå–çš„æ·±åº¦å’Œçµæ´»æ€§ï¼Œå¹¶é€šè¿‡å¤–éƒ¨æ³¨æ„åŠ›æ¡¥è¡¥å¿ä¿¡æ¯æŸå¤±ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªçš®è‚¤ç—…ç¶æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæ¨¡åž‹åœ¨åˆ†å‰²å‡†ç¡®æ€§å’Œé²æ£’æ€§ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰åŸºäºŽTransformerå’Œå·ç§¯ç¥žç»ç½‘ç»œçš„æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In the field of healthcare, precise skin lesion segmentation is crucial for the early detection and accurate diagnosis of skin diseases. Despite significant advances in deep learning for image processing, existing methods have yet to effectively address the challenges of irregular lesion shapes and low contrast. To address these issues, this paper proposes an innovative encoder-decoder network architecture based on multi-scale residual structures, capable of extracting rich feature information from different receptive fields to effectively identify lesion areas. By introducing a Multi-Resolution Multi-Channel Fusion (MRCF) module, our method captures cross-scale features, enhancing the clarity and accuracy of the extracted information. Furthermore, we propose a Cross-Mix Attention Module (CMAM), which redefines the attention scope and dynamically calculates weights across multiple contexts, thus improving the flexibility and depth of feature capture and enabling deeper exploration of subtle features. To overcome the information loss caused by skip connections in traditional U-Net, an External Attention Bridge (EAB) is introduced, facilitating the effective utilization of information in the decoder and compensating for the loss during upsampling. Extensive experimental evaluations on several skin lesion segmentation datasets demonstrate that the proposed model significantly outperforms existing transformer and convolutional neural network-based models, showcasing exceptional segmentation accuracy and robustness.

