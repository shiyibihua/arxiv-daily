---
layout: default
title: HalluShift++: Bridging Language and Vision through Internal Representation Shifts for Hierarchical Hallucinations in MLLMs
---

# HalluShift++: Bridging Language and Vision through Internal Representation Shifts for Hierarchical Hallucinations in MLLMs

**arXiv**: [2512.07687v1](https://arxiv.org/abs/2512.07687) | [PDF](https://arxiv.org/pdf/2512.07687.pdf)

**ä½œè€…**: Sujoy Nath, Arkaprabha Basu, Sharanya Dasgupta, Swagatam Das

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHalluShift++æ–¹æ³•ï¼Œé€šè¿‡åˆ†æžå†…éƒ¨å±‚åŠ¨æ€æ£€æµ‹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ä¸­çš„å¹»è§‰é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `å¹»è§‰æ£€æµ‹` `å†…éƒ¨å±‚åˆ†æž` `è§†è§‰è¯­è¨€ç†è§£` `æ¨¡åž‹è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šMLLMsåœ¨è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­å¸¸äº§ç”Ÿä¸Žè§†è§‰å†…å®¹ä¸ä¸€è‡´çš„å¹»è§‰æè¿°ï¼ŒçŽ°æœ‰è¯„ä¼°æ–¹æ³•ä¾èµ–å¤–éƒ¨LLMè¯„ä¼°å™¨ï¼Œæ˜“å—å¹»è§‰å½±å“ä¸”é¢†åŸŸé€‚åº”æ€§å·®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå‡è®¾å¹»è§‰è¡¨çŽ°ä¸ºMLLMså†…éƒ¨å±‚åŠ¨æ€çš„å¯æµ‹é‡å¼‚å¸¸ï¼Œé€šè¿‡å±‚é—´åˆ†æžæ£€æµ‹è¿™äº›å¼‚å¸¸ï¼Œæ‰©å±•å¹»è§‰æ£€æµ‹è‡³å¤šæ¨¡æ€åœºæ™¯ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šHalluShift++æå‡äº†å¹»è§‰æ£€æµ‹çš„æ•ˆèƒ½ï¼Œä»£ç å·²å¼€æºï¼Œå…·ä½“æ•ˆæžœæœªçŸ¥ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in vision-language understanding tasks. While these models often produce linguistically coherent output, they often suffer from hallucinations, generating descriptions that are factually inconsistent with the visual content, potentially leading to adverse consequences. Therefore, the assessment of hallucinations in MLLM has become increasingly crucial in the model development process. Contemporary methodologies predominantly depend on external LLM evaluators, which are themselves susceptible to hallucinations and may present challenges in terms of domain adaptation. In this study, we propose the hypothesis that hallucination manifests as measurable irregularities within the internal layer dynamics of MLLMs, not merely due to distributional shifts but also in the context of layer-wise analysis of specific assumptions. By incorporating such modifications, \textsc{\textsc{HalluShift++}} broadens the efficacy of hallucination detection from text-based large language models (LLMs) to encompass multimodal scenarios. Our codebase is available at https://github.com/C0mRD/HalluShift_Plus.

