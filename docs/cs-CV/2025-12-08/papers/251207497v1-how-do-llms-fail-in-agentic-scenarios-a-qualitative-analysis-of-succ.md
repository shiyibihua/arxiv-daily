---
layout: default
title: How Do LLMs Fail In Agentic Scenarios? A Qualitative Analysis of Success and Failure Scenarios of Various LLMs in Agentic Simulations
---

# How Do LLMs Fail In Agentic Scenarios? A Qualitative Analysis of Success and Failure Scenarios of Various LLMs in Agentic Simulations

**arXiv**: [2512.07497v1](https://arxiv.org/abs/2512.07497) | [PDF](https://arxiv.org/pdf/2512.07497.pdf)

**ä½œè€…**: JV Roig

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ†æžå¤§è¯­è¨€æ¨¡åž‹åœ¨ä»£ç†åœºæ™¯ä¸­çš„å¤±è´¥æ¨¡å¼ï¼Œæ­ç¤ºç­–ç•¥ä¸Žå¯é æ€§å› ç´ **

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹ä»£ç†` `å·¥å…·ä½¿ç”¨å¤±è´¥åˆ†æž` `KAMIåŸºå‡†` `ç»†ç²’åº¦è¡Œä¸ºåˆ†æž` `å¼ºåŒ–å­¦ä¹ å¯é æ€§` `å¤±è´¥æ¨¡å¼åˆ†ç±»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç ”ç©¶å¤§è¯­è¨€æ¨¡åž‹ä½œä¸ºè‡ªä¸»ä»£ç†ä½¿ç”¨å·¥å…·æ—¶çš„å¤±è´¥æœºåˆ¶
2. é€šè¿‡KAMIåŸºå‡†å¯¹ä¸‰æ¬¾æ¨¡åž‹è¿›è¡Œç»†ç²’åº¦è¡Œä¸ºåˆ†æžï¼Œè¯†åˆ«æˆåŠŸç­–ç•¥ä¸Žå¤±è´¥æ¨¡å¼
3. å‘çŽ°æ¨¡åž‹è§„æ¨¡éžå”¯ä¸€å†³å®šå› ç´ ï¼Œå¼ºåŒ–å­¦ä¹ æå‡å¯é æ€§ï¼Œå¹¶å½’çº³å››ç§å¸¸è§å¤±è´¥ç±»åž‹

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We investigate how large language models (LLMs) fail when operating as autonomous agents with tool-use capabilities. Using the Kamiwaza Agentic Merit Index (KAMI) v0.1 benchmark, we analyze 900 execution traces from three representative models - Granite 4 Small, Llama 4 Maverick, and DeepSeek V3.1 - across filesystem, text extraction, CSV analysis, and SQL scenarios. Rather than focusing on aggregate scores, we perform fine-grained, per-trial behavioral analysis to surface the strategies that enable successful multi-step tool execution and the recurrent failure modes that undermine reliability. Our findings show that model scale alone does not predict agentic robustness: Llama 4 Maverick (400B) performs only marginally better than Granite 4 Small (32B) in some uncertainty-driven tasks, while DeepSeek V3.1's superior reliability derives primarily from post-training reinforcement learning rather than architecture or size. Across models, we identify four recurring failure archetypes: premature action without grounding, over-helpfulness that substitutes missing entities, vulnerability to distractor-induced context pollution, and fragile execution under load. These patterns highlight the need for agentic evaluation methods that emphasize interactive grounding, recovery behavior, and environment-aware adaptation, suggesting that reliable enterprise deployment requires not just stronger models but deliberate training and design choices that reinforce verification, constraint discovery, and adherence to source-of-truth data.

