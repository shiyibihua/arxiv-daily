---
layout: default
title: Complementary Learning Approach for Text Classification using Large Language Models
---

# Complementary Learning Approach for Text Classification using Large Language Models

**arXiv**: [2512.07583v1](https://arxiv.org/abs/2512.07583) | [PDF](https://arxiv.org/pdf/2512.07583.pdf)

**ä½œè€…**: Navid Asgari, Benjamin M. Cole

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºäº’è¡¥å­¦ä¹ æ–¹æ³•ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡åž‹è¿›è¡Œæˆæœ¬é«˜æ•ˆæ–‡æœ¬åˆ†ç±»ï¼Œè§£å†³äººæœºåä½œä¸­çš„å¼±ç‚¹ç®¡ç†é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ–‡æœ¬åˆ†ç±»` `å¤§è¯­è¨€æ¨¡åž‹` `äº’è¡¥å­¦ä¹ ` `äººæœºåä½œ` `å°‘æ ·æœ¬å­¦ä¹ ` `æº¯å› æŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•åœ¨å¤§è¯­è¨€æ¨¡åž‹åº”ç”¨ä¸­ï¼Œä»¥ä½Žæˆæœ¬æ–¹å¼ç®¡ç†å…¶å›ºæœ‰å¼±ç‚¹ï¼Œå¹¶æ•´åˆäººæœºä¼˜åŠ¿è¿›è¡Œæ–‡æœ¬åˆ†ç±»ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ€ç»´é“¾å’Œå°‘æ ·æœ¬å­¦ä¹ æç¤ºï¼Œå°†å®šæ€§ç ”ç©¶ä¸­çš„åˆä½œå›¢é˜Ÿæœ€ä½³å®žè·µæ‰©å±•åˆ°äººæœºå›¢é˜Ÿï¼Œæ”¯æŒæº¯å› æŽ¨ç†å’Œè‡ªç„¶è¯­è¨€äº¤äº’ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåº”ç”¨äºŽ1934ä»½åˆ¶è¯è”ç›Ÿæ–°é—»ç¨¿ï¼ˆ1990-2017ï¼‰ï¼Œæ¼”ç¤ºå¦‚ä½•åˆ†æžäººæœºè¯„åˆ†å·®å¼‚ï¼ŒéªŒè¯æ–¹æ³•çš„å®žç”¨æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this study, we propose a structured methodology that utilizes large language models (LLMs) in a cost-efficient and parsimonious manner, integrating the strengths of scholars and machines while offsetting their respective weaknesses. Our methodology, facilitated through a chain of thought and few-shot learning prompting from computer science, extends best practices for co-author teams in qualitative research to human-machine teams in quantitative research. This allows humans to utilize abductive reasoning and natural language to interrogate not just what the machine has done but also what the human has done. Our method highlights how scholars can manage inherent weaknesses OF LLMs using careful, low-cost techniques. We demonstrate how to use the methodology to interrogate human-machine rating discrepancies for a sample of 1,934 press releases announcing pharmaceutical alliances (1990-2017).

