---
layout: default
title: Generating Storytelling Images with Rich Chains-of-Reasoning
---

# Generating Storytelling Images with Rich Chains-of-Reasoning

**arXiv**: [2512.07198v1](https://arxiv.org/abs/2512.07198) | [PDF](https://arxiv.org/pdf/2512.07198.pdf)

**ä½œè€…**: Xiujie Song, Qi Jia, Shota Watanabe, Xiaoyi Pang, Ruijie Chen, Mengyue Wu, Kenny Q. Zhu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºStorytellingPainterä¸¤é˜¶æ®µæµæ°´çº¿ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡åž‹ä¸Žæ–‡ç”Ÿå›¾æ¨¡åž‹ç”Ÿæˆå¯Œå«æŽ¨ç†é“¾çš„æ•…äº‹å›¾åƒ**

**å…³é”®è¯**: `æ•…äº‹å›¾åƒç”Ÿæˆ` `æŽ¨ç†é“¾` `å¤§è¯­è¨€æ¨¡åž‹` `æ–‡ç”Ÿå›¾æ¨¡åž‹` `è¯„ä¼°æ¡†æž¶` `è½»é‡æ¨¡åž‹è®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ•…äº‹å›¾åƒè¯­ä¹‰å¤æ‚ä¸”ç¨€ç¼ºï¼Œç”Ÿæˆä»»åŠ¡å…·æŒ‘æˆ˜æ€§
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨LLMsè¿›è¡Œåˆ›æ„æŽ¨ç†ï¼ŒT2Iæ¨¡åž‹è§†è§‰åˆæˆï¼Œæž„å»ºä¸¤é˜¶æ®µç”Ÿæˆæµæ°´çº¿
3. å®žéªŒæˆ–æ•ˆæžœï¼šå¼€å‘è¯„ä¼°æ¡†æž¶éªŒè¯æ–¹æ³•å¯è¡Œæ€§ï¼Œè®­ç»ƒMini-Storytellersæ¨¡åž‹ç¼©å°å¼€æºä¸Žä¸“æœ‰LLMså·®è·

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> An image can convey a compelling story by presenting rich, logically connected visual clues. These connections form Chains-of-Reasoning (CoRs) within the image, enabling viewers to infer events, causal relationships, and other information, thereby understanding the underlying story. In this paper, we focus on these semantically rich images and define them as Storytelling Images. Such images have diverse applications beyond illustration creation and cognitive screening, leveraging their ability to convey multi-layered information visually and inspire active interpretation. However, due to their complex semantic nature, Storytelling Images are inherently challenging to create, and thus remain relatively scarce. To address this challenge, we introduce the Storytelling Image Generation task, which explores how generative AI models can be leveraged to create such images. Specifically, we propose a two-stage pipeline, StorytellingPainter, which combines the creative reasoning abilities of Large Language Models (LLMs) with the visual synthesis capabilities of Text-to-Image (T2I) models to generate Storytelling Images. Alongside this pipeline, we develop a dedicated evaluation framework comprising three main evaluators: a Semantic Complexity Evaluator, a KNN-based Diversity Evaluator and a Story-Image Alignment Evaluator. Given the critical role of story generation in the Storytelling Image Generation task and the performance disparity between open-source and proprietary LLMs, we further explore tailored training strategies to reduce this gap, resulting in a series of lightweight yet effective models named Mini-Storytellers. Experimental results demonstrate the feasibility and effectiveness of our approaches. The code is available at https://github.com/xiujiesong/StorytellingImageGeneration.

