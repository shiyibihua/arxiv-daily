---
layout: default
title: Dual-Stream Cross-Modal Representation Learning via Residual Semantic Decorrelation
---

# Dual-Stream Cross-Modal Representation Learning via Residual Semantic Decorrelation

**arXiv**: [2512.07568v1](https://arxiv.org/abs/2512.07568) | [PDF](https://arxiv.org/pdf/2512.07568.pdf)

**‰ΩúËÄÖ**: Xuecheng Li, Weikuan Jia, Alisher Kurbonaliev, Qurbonaliev Alisher, Khudzhamkulov Rustam, Ismoilov Shuhratjon, Eshmatov Javhariddin, Yuanjie Zheng

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ÂèåÊµÅÊÆãÂ∑ÆËØ≠‰πâÂéªÁõ∏ÂÖ≥ÁΩëÁªú‰ª•Ëß£ÂÜ≥Ë∑®Ê®°ÊÄÅÂ≠¶‰π†‰∏≠Ê®°ÊÄÅ‰∏ªÂØºÂíåÂÜó‰ΩôËÄ¶ÂêàÈóÆÈ¢ò**

**ÂÖ≥ÈîÆËØç**: `Ë∑®Ê®°ÊÄÅÂ≠¶‰π†` `ÊÆãÂ∑ÆÂàÜËß£` `ËØ≠‰πâÂéªÁõ∏ÂÖ≥` `ÂèåÊµÅÁΩëÁªú` `Ê®°ÊÄÅËß£ËÄ¶` `ÊïôËÇ≤È¢ÑÊµã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Ê†∏ÂøÉÈóÆÈ¢òÔºöË∑®Ê®°ÊÄÅÂ≠¶‰π†Â≠òÂú®Ê®°ÊÄÅ‰∏ªÂØº„ÄÅÂÜó‰Ωô‰ø°ÊÅØËÄ¶ÂêàÂíåËôöÂÅáÁõ∏ÂÖ≥ÊÄßÔºåÂΩ±ÂìçÊ≥õÂåñÂíåÂèØËß£ÈáäÊÄß
2. ÊñπÊ≥ïË¶ÅÁÇπÔºöÈÄöËøáÊÆãÂ∑ÆÂàÜËß£ÂíåËØ≠‰πâÂéªÁõ∏ÂÖ≥Á∫¶ÊùüÔºåÂàÜÁ¶ªÊ®°ÊÄÅÁâπÂÆö‰∏éÂÖ±‰∫´‰ø°ÊÅØÔºåÂπ∂Ê≠£ÂàôÂåñÂÖ±‰∫´Á©∫Èó¥
3. ÂÆûÈ™åÊàñÊïàÊûúÔºöÂú®‰∏§‰∏™Â§ßËßÑÊ®°ÊïôËÇ≤Âü∫ÂáÜ‰∏äÔºå‰ºò‰∫éÂçïÊ®°ÊÄÅ„ÄÅÊó©ÊúüËûçÂêà„ÄÅÊôöÊúüËûçÂêàÂíåÂçèÂêåÊ≥®ÊÑèÂäõÂü∫Á∫ø

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Cross-modal learning has become a fundamental paradigm for integrating heterogeneous information sources such as images, text, and structured attributes. However, multimodal representations often suffer from modality dominance, redundant information coupling, and spurious cross-modal correlations, leading to suboptimal generalization and limited interpretability. In particular, high-variance modalities tend to overshadow weaker but semantically important signals, while na√Øve fusion strategies entangle modality-shared and modality-specific factors in an uncontrolled manner. This makes it difficult to understand which modality actually drives a prediction and to maintain robustness when some modalities are noisy or missing. To address these challenges, we propose a Dual-Stream Residual Semantic Decorrelation Network (DSRSD-Net), a simple yet effective framework that disentangles modality-specific and modality-shared information through residual decomposition and explicit semantic decorrelation constraints. DSRSD-Net introduces: (1) a dual-stream representation learning module that separates intra-modal (private) and inter-modal (shared) latent factors via residual projection; (2) a residual semantic alignment head that maps shared factors from different modalities into a common space using a combination of contrastive and regression-style objectives; and (3) a decorrelation and orthogonality loss that regularizes the covariance structure of the shared space while enforcing orthogonality between shared and private streams, thereby suppressing cross-modal redundancy and preventing feature collapse. Experimental results on two large-scale educational benchmarks demonstrate that DSRSD-Net consistently improves next-step prediction and final outcome prediction over strong single-modality, early-fusion, late-fusion, and co-attention baselines.

