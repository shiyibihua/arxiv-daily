---
layout: default
title: Human Geometry Distribution for 3D Animation Generation
---

# Human Geometry Distribution for 3D Animation Generation

**arXiv**: [2512.07459v1](https://arxiv.org/abs/2512.07459) | [PDF](https://arxiv.org/pdf/2512.07459.pdf)

**ä½œè€…**: Xiangjun Tang, Biao Zhang, Peter Wonka

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽåˆ†å¸ƒè¡¨ç¤ºå’Œç”ŸæˆåŠ¨ç”»æ¨¡åž‹çš„ä¸¤é˜¶æ®µæ¡†æž¶ï¼Œä»¥è§£å†³æœ‰é™æ•°æ®ä¸‹äººä½“å‡ ä½•åŠ¨ç”»ç”Ÿæˆä¸­æœè£…åŠ¨æ€å»ºæ¨¡çš„æŒ‘æˆ˜ã€‚**

**å…³é”®è¯**: `äººä½“å‡ ä½•åŠ¨ç”»` `åˆ†å¸ƒè¡¨ç¤º` `ç”Ÿæˆæ¨¡åž‹` `æœè£…åŠ¨æ€å»ºæ¨¡` `æ½œåœ¨ç©ºé—´å­¦ä¹ ` `èº«ä»½æ¡ä»¶ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåœ¨æœ‰é™æ•°æ®ä¸‹ç”Ÿæˆå…·æœ‰è‡ªç„¶æœè£…åŠ¨æ€å’Œç²¾ç»†å‡ ä½•ç»†èŠ‚çš„äººä½“å‡ ä½•åŠ¨ç”»ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä¸¤é˜¶æ®µæ¡†æž¶ï¼Œç¬¬ä¸€é˜¶æ®µå­¦ä¹ ç´§å‡‘åˆ†å¸ƒè¡¨ç¤ºï¼Œç¬¬äºŒé˜¶æ®µåŸºäºŽèº«ä»½æ¡ä»¶ç”ŸæˆåŠ¨ç”»ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ½œåœ¨ç©ºé—´å’ŒåŠ¨ç”»æ¨¡åž‹ä¸Šå‡å–å¾—æœ€ä½³ç»“æžœï¼Œå¦‚Chamferè·ç¦»é™ä½Ž90%ï¼Œç”¨æˆ·ç ”ç©¶å¾—åˆ†æé«˜2.2å€ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generating realistic human geometry animations remains a challenging task, as it requires modeling natural clothing dynamics with fine-grained geometric details under limited data. To address these challenges, we propose two novel designs. First, we propose a compact distribution-based latent representation that enables efficient and high-quality geometry generation. We improve upon previous work by establishing a more uniform mapping between SMPL and avatar geometries. Second, we introduce a generative animation model that fully exploits the diversity of limited motion data. We focus on short-term transitions while maintaining long-term consistency through an identity-conditioned design. These two designs formulate our method as a two-stage framework: the first stage learns a latent space, while the second learns to generate animations within this latent space. We conducted experiments on both our latent space and animation model. We demonstrate that our latent space produces high-fidelity human geometry surpassing previous methods ($90\%$ lower Chamfer Dist.). The animation model synthesizes diverse animations with detailed and natural dynamics ($2.2 \times$ higher user study score), achieving the best results across all evaluation metrics.

