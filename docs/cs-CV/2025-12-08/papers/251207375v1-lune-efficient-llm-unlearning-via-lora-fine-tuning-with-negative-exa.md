---
layout: default
title: LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples
---

# LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples

**arXiv**: [2512.07375v1](https://arxiv.org/abs/2512.07375) | [PDF](https://arxiv.org/pdf/2512.07375.pdf)

**ä½œè€…**: Yezi Liu, Hanning Chen, Wenjun Huang, Yang Ni, Mohsen Imani

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLUNEæ¡†æž¶ï¼Œé€šè¿‡LoRAå¾®è°ƒä¸Žè´Ÿä¾‹å®žçŽ°é«˜æ•ˆLLMé—å¿˜ï¼Œä»¥è§£å†³éšç§ã€åè§å’ŒçŸ¥è¯†ä¿®æ­£é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹é—å¿˜` `LoRAå¾®è°ƒ` `è´Ÿä¾‹å­¦ä¹ ` `è®¡ç®—æ•ˆçŽ‡` `éšç§ä¿æŠ¤` `çŸ¥è¯†ä¿®æ­£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šLLMéš¾ä»¥ç§»é™¤ç‰¹å®šä¿¡æ¯ï¼Œä¼ ç»Ÿé—å¿˜æ–¹æ³•è®¡ç®—æˆæœ¬é«˜ï¼Œä¸é€‚ç”¨äºŽå®žé™…éƒ¨ç½²ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽLoRAçš„è½»é‡çº§æ¡†æž¶ï¼Œä»…æ›´æ–°ä½Žç§©é€‚é…å™¨ï¼Œå†»ç»“ä¸»å¹²ï¼Œé€šè¿‡è´Ÿä¾‹è¿›è¡Œé—å¿˜ï¼Œå®šä½ç¼–è¾‘å¹¶é¿å…å…¨å±€å˜åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šé¡¹äº‹å®žé—å¿˜ä»»åŠ¡ä¸­ï¼Œæ•ˆæžœä¸Žå…¨å¾®è°ƒå’Œè®°å¿†ç¼–è¾‘æ–¹æ³•ç›¸å½“ï¼Œè®¡ç®—æˆæœ¬é™ä½Žçº¦ä¸€ä¸ªæ•°é‡çº§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large language models (LLMs) possess vast knowledge acquired from extensive training corpora, but they often cannot remove specific pieces of information when needed, which makes it hard to handle privacy, bias mitigation, and knowledge correction. Traditional model unlearning approaches require computationally expensive fine-tuning or direct weight editing, making them impractical for real-world deployment. In this work, we introduce LoRA-based Unlearning with Negative Examples (LUNE), a lightweight framework that performs negative-only unlearning by updating only low-rank adapters while freezing the backbone, thereby localizing edits and avoiding disruptive global changes. Leveraging Low-Rank Adaptation (LoRA), LUNE targets intermediate representations to suppress (or replace) requested knowledge with an order-of-magnitude lower compute and memory than full fine-tuning or direct weight editing. Extensive experiments on multiple factual unlearning tasks show that LUNE: (I) achieves effectiveness comparable to full fine-tuning and memory-editing methods, and (II) reduces computational cost by about an order of magnitude.

