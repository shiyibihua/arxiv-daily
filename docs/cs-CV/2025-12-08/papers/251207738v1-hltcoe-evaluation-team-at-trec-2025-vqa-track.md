---
layout: default
title: HLTCOE Evaluation Team at TREC 2025: VQA Track
---

# HLTCOE Evaluation Team at TREC 2025: VQA Track

**arXiv**: [2512.07738v1](https://arxiv.org/abs/2512.07738) | [PDF](https://arxiv.org/pdf/2512.07738.pdf)

**ä½œè€…**: Dengjia Zhang, Charles Weng, Katherine Guerrerio, Yi Lu, Kenton Murray, Alexander Martin, Reno Kriz, Benjamin Van Durme

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽåˆ—è¡¨å­¦ä¹ æ¡†æž¶çš„è§†é¢‘é—®ç­”æ–¹æ³•ï¼Œé€šè¿‡å€™é€‰ç­”æ¡ˆé‡æŽ’åºæå‡è¯­ä¹‰ç²¾åº¦å’ŒæŽ’åºä¸€è‡´æ€§**

**å…³é”®è¯**: `è§†é¢‘é—®ç­”` `åˆ—è¡¨å­¦ä¹ ` `ç­”æ¡ˆé‡æŽ’åº` `å¤šæ¨¡æ€æ¨¡åž‹` `æ—¶åºæŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é’ˆå¯¹è§†é¢‘é—®ç­”çš„ç­”æ¡ˆç”Ÿæˆä»»åŠ¡ï¼Œæ ¸å¿ƒé—®é¢˜æ˜¯æå‡ç­”æ¡ˆçš„è¯­ä¹‰ç²¾åº¦å’ŒæŽ’åºç¨³å®šæ€§
2. æ–¹æ³•é‡‡ç”¨åˆ—è¡¨å­¦ä¹ æ¡†æž¶ï¼Œå…ˆç”±åŸºç¡€å¤šæ¨¡æ€æ¨¡åž‹ç”Ÿæˆå€™é€‰ç­”æ¡ˆï¼Œå†ç”¨å¸¦æŽ©ç æŒ‡é’ˆäº¤å‰ç†µæŸå¤±å’ŒæŽ’åºæƒé‡çš„æ¨¡åž‹è¿›è¡Œé‡æŽ’åº
3. å®žéªŒè¡¨æ˜Žè¯¥æ–¹æ³•åœ¨å‡†ç¡®æ€§å’ŒæŽ’åºç¨³å®šæ€§ä¸Šå–å¾—ä¸€è‡´æå‡ï¼Œå°¤å…¶åœ¨éœ€è¦æ—¶åºæŽ¨ç†å’Œè¯­ä¹‰æ¶ˆæ­§çš„é—®é¢˜ä¸Šæ•ˆæžœæ˜¾è‘—

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The HLTCOE Evaluation team participated in TREC VQA's Answer Generation (AG) task, for which we developed a listwise learning framework that aims to improve semantic precision and ranking consistency in answer generation. Given a video-question pair, a base multimodal model first generates multiple candidate answers, which are then reranked using a model trained with a novel Masked Pointer Cross-Entropy Loss with Rank Weights. This objective integrates pointer-based candidate selection, rank-dependent weighting, and masked cross-entropy under vocabulary restriction, enabling stable and interpretable listwise optimization. By bridging generative modeling with discriminative ranking, our method produces coherent, fine-grained answer lists. Experiments reveal consistent gains in accuracy and ranking stability, especially for questions requiring temporal reasoning and semantic disambiguation.

