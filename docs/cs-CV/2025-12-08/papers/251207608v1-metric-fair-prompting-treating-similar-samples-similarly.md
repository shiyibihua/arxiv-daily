---
layout: default
title: Metric-Fair Prompting: Treating Similar Samples Similarly
---

# Metric-Fair Prompting: Treating Similar Samples Similarly

**arXiv**: [2512.07608v1](https://arxiv.org/abs/2512.07608) | [PDF](https://arxiv.org/pdf/2512.07608.pdf)

**ä½œè€…**: Jing Wang, Jie Shen, Xing Niu, Tong Zhang, Jeremy Weiss

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåº¦é‡å…¬å¹³æç¤ºæ¡†æž¶ï¼Œä»¥æå‡å¤§åž‹è¯­è¨€æ¨¡åž‹åœ¨åŒ»å­¦å¤šé€‰é¢˜ä¸­çš„ä¸ªä½“å…¬å¹³æ€§å’Œå‡†ç¡®æ€§ã€‚**

**å…³é”®è¯**: `åº¦é‡å…¬å¹³æç¤º` `ä¸ªä½“å…¬å¹³æ€§` `åŒ»å­¦é—®ç­”` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `Lipschitzçº¦æŸ` `ç½®ä¿¡åº¦è¯„åˆ†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåœ¨åŒ»å­¦å¤šé€‰é¢˜ä¸­ï¼Œæ ‡å‡†æç¤ºå¯èƒ½å¿½ç•¥ç›¸ä¼¼é—®é¢˜é—´çš„å…¬å¹³æ€§ï¼Œå¯¼è‡´ä¸ä¸€è‡´å†³ç­–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽNLPåµŒå…¥è®¡ç®—é—®é¢˜ç›¸ä¼¼åº¦ï¼Œé€šè¿‡è”åˆå¤„ç†ç›¸ä¼¼é—®é¢˜å¯¹å¹¶æ–½åŠ Lipschitzçº¦æŸï¼Œç¡®ä¿ç›¸ä¼¼è¾“å…¥èŽ·å¾—ç›¸ä¼¼åˆ†æ•°ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨MedQAåŸºå‡†ä¸Šï¼Œè¯¥æ¡†æž¶ç›¸æ¯”æ ‡å‡†å•é¢˜æç¤ºæé«˜äº†æ€§èƒ½ï¼Œè¯æ˜Žå…¬å¹³å¼•å¯¼çš„ç½®ä¿¡åº¦æŽ¨ç†èƒ½å¢žå¼ºæ¨¡åž‹å‡†ç¡®æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce \emph{Metric-Fair Prompting}, a fairness-aware prompting framework that guides large language models (LLMs) to make decisions under metric-fairness constraints. In the application of multiple-choice medical question answering, each {(question, option)} pair is treated as a binary instance with label $+1$ (correct) or $-1$ (incorrect). To promote {individual fairness}~--~treating similar instances similarly~--~we compute question similarity using NLP embeddings and solve items in \emph{joint pairs of similar questions} rather than in isolation. The prompt enforces a global decision protocol: extract decisive clinical features, map each \((\text{question}, \text{option})\) to a score $f(x)$ that acts as confidence, and impose a Lipschitz-style constraint so that similar inputs receive similar scores and, hence, consistent outputs. Evaluated on the {MedQA (US)} benchmark, Metric-Fair Prompting is shown to improve performance over standard single-item prompting, demonstrating that fairness-guided, confidence-oriented reasoning can enhance LLM accuracy on high-stakes clinical multiple-choice questions.

