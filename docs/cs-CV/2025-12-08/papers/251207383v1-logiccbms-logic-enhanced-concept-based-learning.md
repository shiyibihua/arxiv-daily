---
layout: default
title: LogicCBMs: Logic-Enhanced Concept-Based Learning
---

# LogicCBMs: Logic-Enhanced Concept-Based Learning

**arXiv**: [2512.07383v1](https://arxiv.org/abs/2512.07383) | [PDF](https://arxiv.org/pdf/2512.07383.pdf)

**ä½œè€…**: Deepika SN Vemuri, Gautham Bellamkonda, Aditya Pola, Vineeth N Balasubramanian

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLogicCBMä»¥å¢žå¼ºæ¦‚å¿µç“¶é¢ˆæ¨¡åž‹ï¼Œé€šè¿‡é€»è¾‘æ¨¡å—æå‡è¡¨è¾¾åŠ›ä¸Žå¯è§£é‡Šæ€§ã€‚**

**å…³é”®è¯**: `æ¦‚å¿µç“¶é¢ˆæ¨¡åž‹` `é€»è¾‘å¢žå¼ºå­¦ä¹ ` `å¯è§£é‡Šäººå·¥æ™ºèƒ½` `å¯å¾®åˆ†é€»è¾‘` `æ¦‚å¿µå…³ç³»å»ºæ¨¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ¦‚å¿µç“¶é¢ˆæ¨¡åž‹çº¿æ€§ç»„åˆæ¦‚å¿µé™åˆ¶è¡¨è¾¾åŠ›ï¼Œéœ€è¶…è¶Šç®€å•åŠ æƒã€‚
2. å¼•å…¥å¯å¾®åˆ†é€»è¾‘æ¨¡å—è¿žæŽ¥æ¦‚å¿µï¼Œæ”¯æŒé€»è¾‘æ“ä½œä»¥æ•èŽ·æ¦‚å¿µé—´å…³ç³»ã€‚
3. å®žéªŒè¡¨æ˜Žæ¨¡åž‹åœ¨åŸºå‡†æ•°æ®é›†ä¸Šæé«˜å‡†ç¡®æ€§ï¼Œå¹¶ä¿æŒç«¯åˆ°ç«¯å¯å­¦ä¹ æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Concept Bottleneck Models (CBMs) provide a basis for semantic abstractions within a neural network architecture. Such models have primarily been seen through the lens of interpretability so far, wherein they offer transparency by inferring predictions as a linear combination of semantic concepts. However, a linear combination is inherently limiting. So we propose the enhancement of concept-based learning models through propositional logic. We introduce a logic module that is carefully designed to connect the learned concepts from CBMs through differentiable logic operations, such that our proposed LogicCBM can go beyond simple weighted combinations of concepts to leverage various logical operations to yield the final predictions, while maintaining end-to-end learnability. Composing concepts using a set of logic operators enables the model to capture inter-concept relations, while simultaneously improving the expressivity of the model in terms of logic operations. Our empirical studies on well-known benchmarks and synthetic datasets demonstrate that these models have better accuracy, perform effective interventions and are highly interpretable.

