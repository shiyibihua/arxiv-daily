---
layout: default
title: Decomposition Sampling for Efficient Region Annotations in Active Learning
---

# Decomposition Sampling for Efficient Region Annotations in Active Learning

**arXiv**: [2512.07606v1](https://arxiv.org/abs/2512.07606) | [PDF](https://arxiv.org/pdf/2512.07606.pdf)

**ä½œè€…**: Jingna Qiu, Frauke Wilm, Mathias Ã–ttl, Jonas Utz, Maja Schlereth, Moritz Schillinger, Marc Aubreville, Katharina Breininger

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆ†è§£é‡‡æ ·ä»¥æå‡å¯†é›†é¢„æµ‹ä»»åŠ¡ä¸­åŒºåŸŸæ ‡æ³¨æ•ˆçŽ‡**

**å…³é”®è¯**: `ä¸»åŠ¨å­¦ä¹ ` `å¯†é›†é¢„æµ‹` `åŒºåŸŸæ ‡æ³¨` `åˆ†è§£é‡‡æ ·` `åŒ»å­¦å½±åƒ` `å°‘æ•°ç±»é‡‡æ ·`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰åŒºåŸŸæ ‡æ³¨é€‰æ‹©æ–¹æ³•è®¡ç®—æˆæœ¬é«˜ã€ä¾èµ–ä¸ç¡®å®šæ€§é‡‡æ ·ä¸”åŒºåŸŸé€‰æ‹©ä¸ç›¸å…³
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡ä¼ªæ ‡ç­¾åˆ†è§£å›¾åƒä¸ºç±»ç‰¹å®šç»„ä»¶ï¼Œä»Žæ¯ç±»é‡‡æ ·åŒºåŸŸï¼Œç»“åˆç±»ç½®ä¿¡åº¦æŒ‡å¯¼
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ROIåˆ†ç±»ã€2Då’Œ3Dåˆ†å‰²ä¸­è¶…è¶ŠåŸºçº¿ï¼Œæå‡å°‘æ•°ç±»åŒºåŸŸé‡‡æ ·å’Œæ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Active learning improves annotation efficiency by selecting the most informative samples for annotation and model training. While most prior work has focused on selecting informative images for classification tasks, we investigate the more challenging setting of dense prediction, where annotations are more costly and time-intensive, especially in medical imaging. Region-level annotation has been shown to be more efficient than image-level annotation for these tasks. However, existing methods for representative annotation region selection suffer from high computational and memory costs, irrelevant region choices, and heavy reliance on uncertainty sampling. We propose decomposition sampling (DECOMP), a new active learning sampling strategy that addresses these limitations. It enhances annotation diversity by decomposing images into class-specific components using pseudo-labels and sampling regions from each class. Class-wise predictive confidence further guides the sampling process, ensuring that difficult classes receive additional annotations. Across ROI classification, 2-D segmentation, and 3-D segmentation, DECOMP consistently surpasses baseline methods by better sampling minority-class regions and boosting performance on these challenging classes. Code is in https://github.com/JingnaQiu/DECOMP.git.

