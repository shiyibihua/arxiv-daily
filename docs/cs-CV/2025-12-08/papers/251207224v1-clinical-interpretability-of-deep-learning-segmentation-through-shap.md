---
layout: default
title: Clinical Interpretability of Deep Learning Segmentation Through Shapley-Derived Agreement and Uncertainty Metrics
---

# Clinical Interpretability of Deep Learning Segmentation Through Shapley-Derived Agreement and Uncertainty Metrics

**arXiv**: [2512.07224v1](https://arxiv.org/abs/2512.07224) | [PDF](https://arxiv.org/pdf/2512.07224.pdf)

**ä½œè€…**: Tianyi Ren, Daniel Low, Pittra Jaengprajak, Juampablo Heras Rivera, Jacob Ruzevick, Mehmet Kurt

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽShapleyå€¼çš„åè®®ä¸Žä¸ç¡®å®šæ€§æŒ‡æ ‡ï¼Œä»¥æå‡åŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡åž‹çš„ä¸´åºŠå¯è§£é‡Šæ€§ã€‚**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒåˆ†å‰²` `å¯è§£é‡Šæ€§` `Shapleyå€¼` `ä¸´åºŠè¯„ä¼°` `ä¸ç¡®å®šæ€§é‡åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ·±åº¦å­¦ä¹ åˆ†å‰²æ¨¡åž‹åœ¨åŒ»å­¦å½±åƒä¸­ç¼ºä¹ä¸´åºŠå¯è§£é‡Šæ€§ï¼Œå½±å“ä¸´åºŠæŽ¥å—åº¦ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨å¯¹æ¯”çº§Shapleyå€¼æ‰°åŠ¨è¾“å…¥ï¼Œè¯„ä¼°ç‰¹å¾é‡è¦æ€§ï¼Œå¹¶è¡ç”Ÿåè®®ä¸Žä¸ç¡®å®šæ€§æŒ‡æ ‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨BraTS 2024æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œé«˜Diceåˆ†æ•°æ¡ˆä¾‹ä¸Žä¸´åºŠæŽ’ååè®®æ›´å¼ºï¼Œä¸ç¡®å®šæ€§æŒ‡æ ‡ä¸Žæ€§èƒ½è´Ÿç›¸å…³ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Segmentation is the identification of anatomical regions of interest, such as organs, tissue, and lesions, serving as a fundamental task in computer-aided diagnosis in medical imaging. Although deep learning models have achieved remarkable performance in medical image segmentation, the need for explainability remains critical for ensuring their acceptance and integration in clinical practice, despite the growing research attention in this area. Our approach explored the use of contrast-level Shapley values, a systematic perturbation of model inputs to assess feature importance. While other studies have investigated gradient-based techniques through identifying influential regions in imaging inputs, Shapley values offer a broader, clinically aligned approach, explaining how model performance is fairly attributed to certain imaging contrasts over others. Using the BraTS 2024 dataset, we generated rankings for Shapley values for four MRI contrasts across four model architectures. Two metrics were proposed from the Shapley ranking: agreement between model and ``clinician" imaging ranking, and uncertainty quantified through Shapley ranking variance across cross-validation folds. Higher-performing cases (Dice \textgreater0.6) showed significantly greater agreement with clinical rankings. Increased Shapley ranking variance correlated with decreased performance (U-Net: $r=-0.581$). These metrics provide clinically interpretable proxies for model reliability, helping clinicians better understand state-of-the-art segmentation models.

