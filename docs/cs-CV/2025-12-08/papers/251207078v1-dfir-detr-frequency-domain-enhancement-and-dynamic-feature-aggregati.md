---
layout: default
title: DFIR-DETR: Frequency Domain Enhancement and Dynamic Feature Aggregation for Cross-Scene Small Object Detection
---

# DFIR-DETR: Frequency Domain Enhancement and Dynamic Feature Aggregation for Cross-Scene Small Object Detection

**arXiv**: [2512.07078v1](https://arxiv.org/abs/2512.07078) | [PDF](https://arxiv.org/pdf/2512.07078.pdf)

**ä½œè€…**: Bo Gao, Jingcheng Tong, Xingsheng Chen, Han Yu, Zichen Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDFIR-DETRï¼Œç»“åˆé¢‘åŸŸå¢žå¼ºä¸ŽåŠ¨æ€ç‰¹å¾èšåˆï¼Œç”¨äºŽè·¨åœºæ™¯å°ç›®æ ‡æ£€æµ‹ã€‚**

**å…³é”®è¯**: `å°ç›®æ ‡æ£€æµ‹` `Transformeræ£€æµ‹å™¨` `é¢‘åŸŸå¤„ç†` `åŠ¨æ€ç‰¹å¾èšåˆ` `è½»é‡æ¨¡åž‹` `è·¨åœºæ™¯æ£€æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå°ç›®æ ‡ç‰¹å¾ç¨€ç–ã€èƒŒæ™¯æ‚ä¹±ã€å°ºåº¦å¤šå˜ï¼ŒçŽ°æœ‰Transformeræ£€æµ‹å™¨å­˜åœ¨ç‰¹å¾é€€åŒ–ã€é•¿ç¨‹ä¾èµ–ä¸è¶³å’Œç‰¹å¾å›¾è†¨èƒ€é—®é¢˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥DCFAæ¨¡å—é™ä½Žæ³¨æ„åŠ›å¤æ‚åº¦ï¼ŒDFPNæ¨¡å—é˜²æ­¢ç‰¹å¾è†¨èƒ€ï¼ŒFIRC3æ¨¡å—åœ¨é¢‘åŸŸå®žçŽ°å…¨å±€æ„Ÿå—é‡Žã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨NEU-DETå’ŒVisDroneæ•°æ®é›†ä¸Šè¾¾åˆ°SOTAï¼Œæ¨¡åž‹è½»é‡ï¼Œå‚æ•°11.7Mï¼ŒGFLOPs 41.2ï¼Œè·¨åœºæ™¯æ³›åŒ–èƒ½åŠ›å¼ºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Detecting small objects in UAV remote sensing images and identifying surface defects in industrial inspection remain difficult tasks. These applications face common obstacles: features are sparse and weak, backgrounds are cluttered, and object scales vary dramatically. Current transformer-based detectors, while powerful, struggle with three critical issues. First, features degrade severely as networks downsample progressively. Second, spatial convolutions cannot capture long-range dependencies effectively. Third, standard upsampling methods inflate feature maps unnecessarily.
>   We introduce DFIR-DETR to tackle these problems through dynamic feature aggregation combined with frequency-domain processing. Our architecture builds on three novel components. The DCFA module uses dynamic K-sparse attention, cutting complexity from O(N2) down to O(NK), and employs spatial gated linear units for better nonlinear modeling. The DFPN module applies amplitude-normalized upsampling to prevent feature inflation and uses dual-path shuffle convolution to retain spatial details across scales. The FIRC3 module operates in the frequency domain, achieving global receptive fields without sacrificing efficiency.
>   We tested our method extensively on NEU-DET and VisDrone datasets. Results show mAP50 scores of 92.9% and 51.6% respectively-both state-of-the-art. The model stays lightweight with just 11.7M parameters and 41.2 GFLOPs. Strong performance across two very different domains confirms that DFIR-DETR generalizes well and works effectively in resource-limited settings for cross-scene small object detection.

