---
layout: default
title: UniDiff: A Unified Diffusion Framework for Multimodal Time Series Forecasting
---

# UniDiff: A Unified Diffusion Framework for Multimodal Time Series Forecasting

**arXiv**: [2512.07184v1](https://arxiv.org/abs/2512.07184) | [PDF](https://arxiv.org/pdf/2512.07184.pdf)

**ä½œè€…**: Da Zhang, Bingyu Li, Zhuyuan Zhao, Junyu Gao, Feiping Nie, Xuelong Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUniDiffç»Ÿä¸€æ‰©æ•£æ¡†æž¶ä»¥è§£å†³å¤šæ¨¡æ€æ—¶é—´åºåˆ—é¢„æµ‹ä¸­å¼‚æž„ä¿¡æ¯èžåˆçš„æŒ‘æˆ˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ—¶é—´åºåˆ—é¢„æµ‹` `æ‰©æ•£æ¨¡åž‹` `å¼‚æž„ä¿¡æ¯èžåˆ` `äº¤å‰æ³¨æ„åŠ›æœºåˆ¶` `åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ‰©æ•£æ¨¡åž‹åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­å¤šå±€é™äºŽå•æ¨¡æ€æ•°å€¼åºåˆ—ï¼Œå¿½ç•¥æ–‡æœ¬å’Œæ—¶é—´æˆ³ç­‰å¼‚æž„è·¨æ¨¡æ€ä¿¡å·ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡ç»Ÿä¸€å¹¶è¡Œèžåˆæ¨¡å—ï¼Œä½¿ç”¨å•äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ä¸€æ­¥æ•´åˆæ—¶é—´æˆ³ç»“æž„ä¿¡æ¯å’Œæ–‡æœ¬è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼Œå¹¶å¼•å…¥å¤šæºæ¡ä»¶åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼æœºåˆ¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å…«ä¸ªé¢†åŸŸçš„çœŸå®žä¸–ç•ŒåŸºå‡†æ•°æ®é›†ä¸Šå¹¿æ³›å®žéªŒï¼ŒUniDiffå®žçŽ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> As multimodal data proliferates across diverse real-world applications, leveraging heterogeneous information such as texts and timestamps for accurate time series forecasting (TSF) has become a critical challenge. While diffusion models demonstrate exceptional performance in generation tasks, their application to TSF remains largely confined to modeling single-modality numerical sequences, overlooking the abundant cross-modal signals inherent in complex heterogeneous data. To address this gap, we propose UniDiff, a unified diffusion framework for multimodal time series forecasting. To process the numerical sequence, our framework first tokenizes the time series into patches, preserving local temporal dynamics by mapping each patch to an embedding space via a lightweight MLP. At its core lies a unified and parallel fusion module, where a single cross-attention mechanism adaptively weighs and integrates structural information from timestamps and semantic context from texts in one step, enabling a flexible and efficient interplay between modalities. Furthermore, we introduce a novel classifier-free guidance mechanism designed for multi-source conditioning, allowing for decoupled control over the guidance strength of textual and temporal information during inference, which significantly enhances model robustness. Extensive experiments on real-world benchmark datasets across eight domains demonstrate that the proposed UniDiff model achieves state-of-the-art performance.

