---
layout: default
title: IFFair: Influence Function-driven Sample Reweighting for Fair Classification
---

# IFFair: Influence Function-driven Sample Reweighting for Fair Classification

**arXiv**: [2512.07249v1](https://arxiv.org/abs/2512.07249) | [PDF](https://arxiv.org/pdf/2512.07249.pdf)

**ä½œè€…**: Jingran Yang, Min Zhang, Lingfeng Zhang, Zhaohui Wang, Yonggang Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIFFairæ–¹æ³•ï¼ŒåŸºäºŽå½±å“å‡½æ•°åŠ¨æ€è°ƒæ•´æ ·æœ¬æƒé‡ä»¥è§£å†³åˆ†ç±»ä¸­çš„å…¬å¹³æ€§é—®é¢˜ã€‚**

**å…³é”®è¯**: `å…¬å¹³åˆ†ç±»` `å½±å“å‡½æ•°` `æ ·æœ¬é‡åŠ æƒ` `é¢„å¤„ç†æ–¹æ³•` `æœºå™¨å­¦ä¹ å…¬å¹³æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨å­¦ä¹ ç®—æ³•å¯èƒ½å­¦ä¹ å¹¶åŠ å‰§æ ·æœ¬åè§ï¼Œå¯¼è‡´å¯¹å¼±åŠ¿ç¾¤ä½“çš„æ­§è§†æ€§å†³ç­–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨å½±å“å‡½æ•°è®¡ç®—è®­ç»ƒæ ·æœ¬å¯¹ä¸åŒç¾¤ä½“çš„å½±å“å·®å¼‚ï¼ŒåŠ¨æ€è°ƒæ•´æ ·æœ¬æƒé‡ï¼Œæ— éœ€ä¿®æ”¹ç½‘ç»œç»“æž„æˆ–æ•°æ®ç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªçœŸå®žæ•°æ®é›†ä¸ŠéªŒè¯ï¼ŒIFFairèƒ½ç¼“è§£å¤šç§å…¬å¹³æ€§æŒ‡æ ‡åè§ï¼Œå¹¶åœ¨æ•ˆç”¨ä¸Žå…¬å¹³æ€§é—´å–å¾—æ›´å¥½æƒè¡¡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Because machine learning has significantly improved efficiency and convenience in the society, it's increasingly used to assist or replace human decision-making. However, the data-based pattern makes related algorithms learn and even exacerbate potential bias in samples, resulting in discriminatory decisions against certain unprivileged groups, depriving them of the rights to equal treatment, thus damaging the social well-being and hindering the development of related applications. Therefore, we propose a pre-processing method IFFair based on the influence function. Compared with other fairness optimization approaches, IFFair only uses the influence disparity of training samples on different groups as a guidance to dynamically adjust the sample weights during training without modifying the network structure, data features and decision boundaries. To evaluate the validity of IFFair, we conduct experiments on multiple real-world datasets and metrics. The experimental results show that our approach mitigates bias of multiple accepted metrics in the classification setting, including demographic parity, equalized odds, equality of opportunity and error rate parity without conflicts. It also demonstrates that IFFair achieves better trade-off between multiple utility and fairness metrics compared with previous pre-processing methods.

