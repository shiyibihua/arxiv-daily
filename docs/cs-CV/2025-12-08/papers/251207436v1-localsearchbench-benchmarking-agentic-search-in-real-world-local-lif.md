---
layout: default
title: LocalSearchBench: Benchmarking Agentic Search in Real-World Local Life Services
---

# LocalSearchBench: Benchmarking Agentic Search in Real-World Local Life Services

**arXiv**: [2512.07436v1](https://arxiv.org/abs/2512.07436) | [PDF](https://arxiv.org/pdf/2512.07436.pdf)

**ä½œè€…**: Hang He, Chuhuai Yue, Chengqi Dong, Mingxue Tian, Zhenfeng Liu, Jiajun Chai, Xiaohan Wang, Yufei Zhang, Qun Liao, Guojun Yin, Wei Lin, Chengcheng Wan, Haiying Sun, Ting Su

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLocalSearchBenchåŸºå‡†ä»¥è¯„ä¼°æœ¬åœ°ç”Ÿæ´»æœåŠ¡ä¸­çš„æ™ºèƒ½æœç´¢ä»£ç†æ€§èƒ½**

**å…³é”®è¯**: `æ™ºèƒ½æœç´¢ä»£ç†` `æœ¬åœ°ç”Ÿæ´»æœåŠ¡` `å¤šè·³æŽ¨ç†` `åŸºå‡†æµ‹è¯•` `å¤§æŽ¨ç†æ¨¡åž‹` `åž‚ç›´é¢†åŸŸ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ™ºèƒ½æœç´¢ç ”ç©¶å¤šå…³æ³¨é€šç”¨ä¿¡æ¯æ£€ç´¢ï¼Œç¼ºä¹é’ˆå¯¹æœ¬åœ°ç”Ÿæ´»æœåŠ¡ç­‰åž‚ç›´é¢†åŸŸçš„åŸºå‡†ï¼Œè¯¥é¢†åŸŸæŸ¥è¯¢æ¨¡ç³Šä¸”éœ€å¤šè·³æŽ¨ç†ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºåŒ…å«15ä¸‡æ¡é«˜è´¨é‡æ¡ç›®çš„åŸºå‡†ï¼ŒåŸºäºŽçœŸå®žç”¨æˆ·æŸ¥è¯¢è®¾è®¡300ä¸ªå¤šè·³é—®ç­”ä»»åŠ¡ï¼Œå¹¶å¼€å‘ç»Ÿä¸€äº¤äº’çŽ¯å¢ƒLocalPlaygroundã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒæ˜¾ç¤ºï¼Œå³ä½¿æœ€å…ˆè¿›çš„å¤§æŽ¨ç†æ¨¡åž‹ï¼ˆå¦‚DeepSeek-V3.1ï¼‰åœ¨åŸºå‡†ä¸Šæ­£ç¡®çŽ‡ä»…34.34%ï¼Œå‡¸æ˜¾é¢†åŸŸç‰¹å®šè®­ç»ƒçš„å¿…è¦æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in large reasoning models (LRMs) have enabled agentic search systems to perform complex multi-step reasoning across multiple sources. However, most studies focus on general information retrieval and rarely explores vertical domains with unique challenges. In this work, we focus on local life services and introduce LocalSearchBench, which encompass diverse and complex business scenarios. Real-world queries in this domain are often ambiguous and require multi-hop reasoning across merchants and products, remaining challenging and not fully addressed. As the first comprehensive benchmark for agentic search in local life services, LocalSearchBench includes over 150,000 high-quality entries from various cities and business types. We construct 300 multi-hop QA tasks based on real user queries, challenging agents to understand questions and retrieve information in multiple steps. We also developed LocalPlayground, a unified environment integrating multiple tools for agent interaction. Experiments show that even state-of-the-art LRMs struggle on LocalSearchBench: the best model (DeepSeek-V3.1) achieves only 34.34% correctness, and most models have issues with completeness (average 77.33%) and faithfulness (average 61.99%). This highlights the need for specialized benchmarks and domain-specific agent training in local life services. Code, Benchmark, and Leaderboard are available at localsearchbench.github.io.

