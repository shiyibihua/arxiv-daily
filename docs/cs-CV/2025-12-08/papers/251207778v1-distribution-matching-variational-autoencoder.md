---
layout: default
title: Distribution Matching Variational AutoEncoder
---

# Distribution Matching Variational AutoEncoder

**arXiv**: [2512.07778v1](https://arxiv.org/abs/2512.07778) | [PDF](https://arxiv.org/pdf/2512.07778.pdf)

**ä½œè€…**: Sen Ye, Jianning Pei, Mengde Xu, Shuyang Gu, Chunyu Wang, Liwei Wang, Han Hu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆ†å¸ƒåŒ¹é…å˜åˆ†è‡ªç¼–ç å™¨ï¼Œé€šè¿‡æ˜¾å¼å¯¹é½æ½œåœ¨åˆ†å¸ƒä¸Žä»»æ„å‚è€ƒåˆ†å¸ƒæ¥ä¼˜åŒ–è§†è§‰ç”Ÿæˆå»ºæ¨¡ã€‚**

**å…³é”®è¯**: `å˜åˆ†è‡ªç¼–ç å™¨` `åˆ†å¸ƒåŒ¹é…` `æ½œåœ¨ç©ºé—´ä¼˜åŒ–` `è§†è§‰ç”Ÿæˆæ¨¡åž‹` `è‡ªç›‘ç£å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†è§‰ç”Ÿæˆæ¨¡åž‹ï¼ˆå¦‚VAEï¼‰çš„æ½œåœ¨åˆ†å¸ƒæœªæ˜¾å¼ä¼˜åŒ–ï¼Œä¸æ¸…æ¥šä½•ç§åˆ†å¸ƒæœ€é€‚åˆå»ºæ¨¡ã€‚
2. DMVAEé€šè¿‡åˆ†å¸ƒåŒ¹é…çº¦æŸï¼Œä½¿ç¼–ç å™¨æ½œåœ¨åˆ†å¸ƒä¸Žä»»æ„å‚è€ƒåˆ†å¸ƒï¼ˆå¦‚è‡ªç›‘ç£ç‰¹å¾åˆ†å¸ƒï¼‰å¯¹é½ã€‚
3. å®žéªŒå‘çŽ°è‡ªç›‘ç£ç‰¹å¾åˆ†å¸ƒèƒ½å¹³è¡¡é‡å»ºä¿çœŸåº¦ä¸Žå»ºæ¨¡æ•ˆçŽ‡ï¼Œåœ¨ImageNetä¸Šä»…ç”¨64è½®è®­ç»ƒè¾¾åˆ°gFID=3.2ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Most visual generative models compress images into a latent space before applying diffusion or autoregressive modelling. Yet, existing approaches such as VAEs and foundation model aligned encoders implicitly constrain the latent space without explicitly shaping its distribution, making it unclear which types of distributions are optimal for modeling. We introduce \textbf{Distribution-Matching VAE} (\textbf{DMVAE}), which explicitly aligns the encoder's latent distribution with an arbitrary reference distribution via a distribution matching constraint. This generalizes beyond the Gaussian prior of conventional VAEs, enabling alignment with distributions derived from self-supervised features, diffusion noise, or other prior distributions. With DMVAE, we can systematically investigate which latent distributions are more conducive to modeling, and we find that SSL-derived distributions provide an excellent balance between reconstruction fidelity and modeling efficiency, reaching gFID equals 3.2 on ImageNet with only 64 training epochs. Our results suggest that choosing a suitable latent distribution structure (achieved via distribution-level alignment), rather than relying on fixed priors, is key to bridging the gap between easy-to-model latents and high-fidelity image synthesis. Code is avaliable at https://github.com/sen-ye/dmvae.

