---
layout: default
title: KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models
---

# KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models

**arXiv**: [2512.07437v1](https://arxiv.org/abs/2512.07437) | [PDF](https://arxiv.org/pdf/2512.07437.pdf)

**ä½œè€…**: Chenwei Shi, Xueyu Luan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºKAN-Dreamerï¼Œå°†KANæž¶æž„é›†æˆåˆ°DreamerV3ä¸­ä½œä¸ºå‡½æ•°é€¼è¿‘å™¨è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚**

**å…³é”®è¯**: `åŸºäºŽæ¨¡åž‹çš„å¼ºåŒ–å­¦ä¹ ` `Kolmogorov-Arnoldç½‘ç»œ` `ä¸–ç•Œæ¨¡åž‹` `å‡½æ•°é€¼è¿‘` `æ ·æœ¬æ•ˆçŽ‡` `JAXå®žçŽ°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç ”ç©¶å°†Kolmogorov-Arnold Networksï¼ˆKANsï¼‰ä½œä¸ºMLPæ›¿ä»£å“é›†æˆåˆ°DreamerV3ä¸–ç•Œæ¨¡åž‹ä¸­ã€‚
2. åœ¨JAXæ¡†æž¶ä¸‹å®žçŽ°å‘é‡åŒ–ç‰ˆæœ¬ï¼Œç”¨KANå’ŒFastKANæ›¿æ¢ç‰¹å®šMLPå’Œå·ç§¯ç»„ä»¶ã€‚
3. åœ¨DeepMind Control Suiteä¸Šå®žéªŒï¼ŒFastKANåœ¨å¥–åŠ±å’Œç»§ç»­é¢„æµ‹å™¨ä¸Šæ€§èƒ½ä¸ŽMLPç›¸å½“ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> DreamerV3 is a state-of-the-art online model-based reinforcement learning (MBRL) algorithm known for remarkable sample efficiency. Concurrently, Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to Multi-Layer Perceptrons (MLPs), offering superior parameter efficiency and interpretability. To mitigate KANs' computational overhead, variants like FastKAN leverage Radial Basis Functions (RBFs) to accelerate inference. In this work, we investigate integrating KAN architectures into the DreamerV3 framework. We introduce KAN-Dreamer, replacing specific MLP and convolutional components of DreamerV3 with KAN and FastKAN layers. To ensure efficiency within the JAX-based World Model, we implement a tailored, fully vectorized version with simplified grid management. We structure our investigation into three subsystems: Visual Perception, Latent Prediction, and Behavior Learning. Empirical evaluations on the DeepMind Control Suite (walker_walk) analyze sample efficiency, training time, and asymptotic performance. Experimental results demonstrate that utilizing our adapted FastKAN as a drop-in replacement for the Reward and Continue predictors yields performance on par with the original MLP-based architecture, maintaining parity in both sample efficiency and training speed. This report serves as a preliminary study for future developments in KAN-based world models.

