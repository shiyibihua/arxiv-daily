---
layout: default
title: Persian-Phi: Efficient Cross-Lingual Adaptation of Compact LLMs via Curriculum Learning
---

# Persian-Phi: Efficient Cross-Lingual Adaptation of Compact LLMs via Curriculum Learning

**arXiv**: [2512.07454v1](https://arxiv.org/abs/2512.07454) | [PDF](https://arxiv.org/pdf/2512.07454.pdf)

**ä½œè€…**: Amir Mohammad Akhlaghi, Amirhossein Shabani, Mostafa Abdolmaleki, Saeed Reza Kheradpisheh

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPersian-Phiæ¨¡åž‹ï¼Œé€šè¿‡è¯¾ç¨‹å­¦ä¹ é«˜æ•ˆé€‚é…ä½Žèµ„æºæ³¢æ–¯è¯­ï¼ŒæŒ‘æˆ˜å¤§è§„æ¨¡å¤šè¯­è¨€æ¨¡åž‹å‡è®¾ã€‚**

**å…³é”®è¯**: `è·¨è¯­è¨€é€‚é…` `è¯¾ç¨‹å­¦ä¹ ` `å‚æ•°é«˜æ•ˆå¾®è°ƒ` `ä½Žèµ„æºè¯­è¨€` `æ³¢æ–¯è¯­æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä½Žèµ„æºè¯­è¨€è®­ç»ƒå¤§è¯­è¨€æ¨¡åž‹è®¡ç®—æˆæœ¬é«˜ï¼Œé˜»ç¢AIæ°‘ä¸»åŒ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨è¯¾ç¨‹å­¦ä¹ ï¼Œå…ˆåŒè¯­å™äº‹é¢„çƒ­å¯¹é½åµŒå…¥ï¼Œå†æŒç»­é¢„è®­ç»ƒå’ŒæŒ‡ä»¤è°ƒä¼˜ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¨¡åž‹åœ¨Open Persian LLM Leaderboardä¸Šå–å¾—ç«žäº‰æ€§ç»“æžœï¼Œæä¾›å¯æ‰©å±•æ¡†æž¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The democratization of AI is currently hindered by the immense computational costs required to train Large Language Models (LLMs) for low-resource languages. This paper presents Persian-Phi, a 3.8B parameter model that challenges the assumption that robust multilingual capabilities require massive model sizes or multilingual baselines. We demonstrate how Microsoft Phi-3 Mini -- originally a monolingual English model -- can be effectively adapted to Persian through a novel, resource-efficient curriculum learning pipeline. Our approach employs a unique "warm-up" stage using bilingual narratives (Tiny Stories) to align embeddings prior to heavy training, followed by continual pretraining and instruction tuning via Parameter-Efficient Fine-Tuning (PEFT). Despite its compact size, Persian-Phi achieves competitive results on Open Persian LLM Leaderboard in HuggingFace. Our findings provide a validated, scalable framework for extending the reach of state-of-the-art LLMs to underrepresented languages with minimal hardware resources. The Persian-Phi model is publicly available at https://huggingface.co/amirakhlaghiqqq/PersianPhi.

