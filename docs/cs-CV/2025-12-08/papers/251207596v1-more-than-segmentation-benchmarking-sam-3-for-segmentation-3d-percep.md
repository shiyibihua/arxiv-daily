---
layout: default
title: More than Segmentation: Benchmarking SAM 3 for Segmentation, 3D Perception, and Reconstruction in Robotic Surgery
---

# More than Segmentation: Benchmarking SAM 3 for Segmentation, 3D Perception, and Reconstruction in Robotic Surgery

**arXiv**: [2512.07596v1](https://arxiv.org/abs/2512.07596) | [PDF](https://arxiv.org/pdf/2512.07596.pdf)

**ä½œè€…**: Wenzhen Dong, Jieming Yu, Yiming Huang, Hongqiu Wang, Lei Zhu, Albert C. S. Chung, Hongliang Ren, Long Bai

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°SAM 3åœ¨æœºå™¨äººæ‰‹æœ¯ä¸­çš„åˆ†å‰²ã€3Dæ„ŸçŸ¥ä¸Žé‡å»ºæ€§èƒ½ï¼Œæ­ç¤ºå…¶åœ¨é›¶æ ·æœ¬åˆ†å‰²å’Œ3Dé‡å»ºæ–¹é¢çš„ä¼˜åŠ¿ä¸Žå±€é™ã€‚**

**å…³é”®è¯**: `é›¶æ ·æœ¬åˆ†å‰²` `3Dé‡å»º` `æœºå™¨äººæ‰‹æœ¯` `è¯­è¨€æç¤º` `åŠ¨æ€è§†é¢‘è·Ÿè¸ª` `å•ç›®æ·±åº¦ä¼°è®¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè¯„ä¼°SAM 3åœ¨æœºå™¨äººæ‰‹æœ¯åœºæ™¯ä¸‹çš„é›¶æ ·æœ¬åˆ†å‰²ã€åŠ¨æ€è§†é¢‘è·Ÿè¸ªå’Œ3Dé‡å»ºèƒ½åŠ›ï¼Œä»¥éªŒè¯å…¶å®žé™…åº”ç”¨æ½œåŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨ç‚¹ã€è¾¹ç•Œæ¡†å’Œè¯­è¨€æç¤ºè¿›è¡Œé›¶æ ·æœ¬åˆ†å‰²æµ‹è¯•ï¼Œå¹¶åŸºäºŽ2Då›¾åƒè¿›è¡Œ3Dè§£å‰–ç»“æž„é‡å»ºï¼Œç»“åˆå¤šä¸ªæ‰‹æœ¯æ•°æ®é›†è¿›è¡Œç»¼åˆè¯„ä¼°ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨MICCAI EndoVisåŸºå‡†ä¸Šï¼ŒSAM 3åœ¨ç©ºé—´æç¤ºä¸‹çš„å›¾åƒå’Œè§†é¢‘åˆ†å‰²ä¼˜äºŽå‰ä»£æ¨¡åž‹ï¼›é›¶æ ·æœ¬è¯„ä¼°æ˜¾ç¤ºå…¶åœ¨å•ç›®æ·±åº¦ä¼°è®¡å’Œ3Då™¨æ¢°é‡å»ºæ–¹é¢è¡¨çŽ°è‰¯å¥½ï¼Œä½†åœ¨å¤æ‚åŠ¨æ€åœºæ™¯ä¸­ä»æœ‰å±€é™ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The recent Segment Anything Model (SAM) 3 has introduced significant advancements over its predecessor, SAM 2, particularly with the integration of language-based segmentation and enhanced 3D perception capabilities. SAM 3 supports zero-shot segmentation across a wide range of prompts, including point, bounding box, and language-based prompts, allowing for more flexible and intuitive interactions with the model. In this empirical evaluation, we assess the performance of SAM 3 in robot-assisted surgery, benchmarking its zero-shot segmentation with point and bounding box prompts and exploring its effectiveness in dynamic video tracking, alongside its newly introduced language prompt segmentation. While language prompts show potential, their performance in the surgical domain is currently suboptimal, highlighting the need for further domain-specific training. Additionally, we investigate SAM 3's 3D reconstruction abilities, demonstrating its capacity to process surgical scene data and reconstruct 3D anatomical structures from 2D images. Through comprehensive testing on the MICCAI EndoVis 2017 and EndoVis 2018 benchmarks, SAM 3 shows clear improvements over SAM and SAM 2 in both image and video segmentation under spatial prompts, while zero-shot evaluations on SCARED, StereoMIS, and EndoNeRF indicate strong monocular depth estimation and realistic 3D instrument reconstruction, yet also reveal remaining limitations in complex, highly dynamic surgical scenes.

