---
layout: default
title: Zero-Shot Textual Explanations via Translating Decision-Critical Features
---

# Zero-Shot Textual Explanations via Translating Decision-Critical Features

**arXiv**: [2512.07245v1](https://arxiv.org/abs/2512.07245) | [PDF](https://arxiv.org/pdf/2512.07245.pdf)

**ä½œè€…**: Toshinori Yamauchi, Hiroshi Kera, Kazuhiko Kawamoto

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTEXTERæ–¹æ³•ï¼Œé€šè¿‡åˆ†ç¦»å†³ç­–å…³é”®ç‰¹å¾å®žçŽ°é›¶æ ·æœ¬æ–‡æœ¬è§£é‡Šï¼Œæå‡å›¾åƒåˆ†ç±»å™¨é€æ˜Žåº¦ã€‚**

**å…³é”®è¯**: `é›¶æ ·æœ¬æ–‡æœ¬è§£é‡Š` `å†³ç­–å…³é”®ç‰¹å¾` `å›¾åƒåˆ†ç±»å™¨é€æ˜Žåº¦` `CLIPç‰¹å¾æ˜ å°„` `ç¨€ç–è‡ªç¼–ç å™¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰é›¶æ ·æœ¬æ–¹æ³•ç”Ÿæˆæè¿°å¯è§å†…å®¹è€Œéžé¢„æµ‹é©±åŠ¨å› ç´ ï¼Œå¯¼è‡´è§£é‡Šä¸å¿ å®žã€‚
2. TEXTERè¯†åˆ«é¢„æµ‹è´¡çŒ®ç¥žç»å…ƒï¼Œå¼ºè°ƒå†³ç­–å…³é”®ç‰¹å¾ï¼Œæ˜ å°„åˆ°CLIPç©ºé—´æ£€ç´¢æ–‡æœ¬è§£é‡Šã€‚
3. å®žéªŒè¡¨æ˜ŽTEXTERæ¯”çŽ°æœ‰æ–¹æ³•ç”Ÿæˆæ›´å¿ å®žå’Œå¯è§£é‡Šçš„æ–‡æœ¬è§£é‡Šï¼Œä»£ç å°†å…¬å¼€ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Textual explanations make image classifier decisions transparent by describing the prediction rationale in natural language. Large vision-language models can generate captions but are designed for general visual understanding, not classifier-specific reasoning. Existing zero-shot explanation methods align global image features with language, producing descriptions of what is visible rather than what drives the prediction. We propose TEXTER, which overcomes this limitation by isolating decision-critical features before alignment. TEXTER identifies the neurons contributing to the prediction and emphasizes the features encoded in those neurons -- i.e., the decision-critical features. It then maps these emphasized features into the CLIP feature space to retrieve textual explanations that reflect the model's reasoning. A sparse autoencoder further improves interpretability, particularly for Transformer architectures. Extensive experiments show that TEXTER generates more faithful and interpretable explanations than existing methods. The code will be publicly released.

