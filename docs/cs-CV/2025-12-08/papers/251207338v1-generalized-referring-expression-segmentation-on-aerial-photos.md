---
layout: default
title: Generalized Referring Expression Segmentation on Aerial Photos
---

# Generalized Referring Expression Segmentation on Aerial Photos

**arXiv**: [2512.07338v1](https://arxiv.org/abs/2512.07338) | [PDF](https://arxiv.org/pdf/2512.07338.pdf)

**ä½œè€…**: LuÃ­s Marnoto, Alexandre Bernardino, Bruno Martins

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAerial-Dæ•°æ®é›†ä¸ŽRSRefSegæž¶æž„ï¼Œä»¥è§£å†³èˆªç©ºå½±åƒä¸­çš„æŒ‡ä»£è¡¨è¾¾åˆ†å‰²æŒ‘æˆ˜ã€‚**

**å…³é”®è¯**: `æŒ‡ä»£è¡¨è¾¾åˆ†å‰²` `èˆªç©ºå½±åƒ` `å¤§è§„æ¨¡æ•°æ®é›†` `LLMå¢žå¼º` `è¯­ä¹‰åˆ†å‰²` `åŽ†å²å½±åƒå¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šèˆªç©ºå½±åƒåˆ†è¾¨çŽ‡å¤šå˜ã€è‰²å½©ä¸ä¸€è‡´ã€ç›®æ ‡å°ä¸”å¯†é›†ï¼Œå¯¼è‡´æŒ‡ä»£è¡¨è¾¾åˆ†å‰²å›°éš¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºå¤§è§„æ¨¡Aerial-Dæ•°æ®é›†ï¼Œç»“åˆè§„åˆ™ç”Ÿæˆä¸ŽLLMå¢žå¼ºï¼Œå¹¶é‡‡ç”¨RSRefSegæž¶æž„è¿›è¡Œè®­ç»ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å½“ä»£åŸºå‡†ä¸Šè¡¨çŽ°ç«žäº‰æ€§ï¼Œå¯¹åŽ†å²å½±åƒçš„å•è‰²ã€è¤ªè‰²å’Œé¢—ç²’é€€åŒ–ä¿æŒé«˜ç²¾åº¦ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Referring expression segmentation is a fundamental task in computer vision that integrates natural language understanding with precise visual localization of target regions. Considering aerial imagery (e.g., modern aerial photos collected through drones, historical photos from aerial archives, high-resolution satellite imagery, etc.) presents unique challenges because spatial resolution varies widely across datasets, the use of color is not consistent, targets often shrink to only a few pixels, and scenes contain very high object densities and objects with partial occlusions. This work presents Aerial-D, a new large-scale referring expression segmentation dataset for aerial imagery, comprising 37,288 images with 1,522,523 referring expressions that cover 259,709 annotated targets, spanning across individual object instances, groups of instances, and semantic regions covering 21 distinct classes that range from vehicles and infrastructure to land coverage types. The dataset was constructed through a fully automatic pipeline that combines systematic rule-based expression generation with a Large Language Model (LLM) enhancement procedure that enriched both the linguistic variety and the focus on visual details within the referring expressions. Filters were additionally used to simulate historic imaging conditions for each scene. We adopted the RSRefSeg architecture, and trained models on Aerial-D together with prior aerial datasets, yielding unified instance and semantic segmentation from text for both modern and historical images. Results show that the combined training achieves competitive performance on contemporary benchmarks, while maintaining strong accuracy under monochrome, sepia, and grainy degradations that appear in archival aerial photography. The dataset, trained models, and complete software pipeline are publicly available at https://luispl77.github.io/aerial-d .

