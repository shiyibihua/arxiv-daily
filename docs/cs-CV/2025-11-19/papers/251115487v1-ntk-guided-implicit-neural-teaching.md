---
layout: default
title: NTK-Guided Implicit Neural Teaching
---

# NTK-Guided Implicit Neural Teaching

**arXiv**: [2511.15487v1](https://arxiv.org/abs/2511.15487) | [PDF](https://arxiv.org/pdf/2511.15487.pdf)

**ä½œè€…**: Chen Zhang, Wei Zuo, Bingyang Cheng, Yikun Wang, Wei-Bin Kou, Yik Chung WU, Ngai Wong

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNTKå¼•å¯¼éšå¼ç¥žç»æ•™å­¦ä»¥åŠ é€Ÿéšå¼ç¥žç»è¡¨ç¤ºè®­ç»ƒ**

**å…³é”®è¯**: `éšå¼ç¥žç»è¡¨ç¤º` `ç¥žç»æ­£åˆ‡æ ¸` `è®­ç»ƒåŠ é€Ÿ` `åæ ‡é‡‡æ ·` `å‡½æ•°é€¼è¿‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. éšå¼ç¥žç»è¡¨ç¤ºæ‹Ÿåˆé«˜åˆ†è¾¨çŽ‡ä¿¡å·æ—¶è®¡ç®—æˆæœ¬é«˜æ˜‚
2. åˆ©ç”¨ç¥žç»æ­£åˆ‡æ ¸åŠ¨æ€é€‰æ‹©åæ ‡ä»¥æœ€å¤§åŒ–å…¨å±€å‡½æ•°æ›´æ–°
3. å®žéªŒæ˜¾ç¤ºè®­ç»ƒæ—¶é—´å‡åŠä¸”ä¿æŒæˆ–æå‡è¡¨ç¤ºè´¨é‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Implicit Neural Representations (INRs) parameterize continuous signals via multilayer perceptrons (MLPs), enabling compact, resolution-independent modeling for tasks like image, audio, and 3D reconstruction. However, fitting high-resolution signals demands optimizing over millions of coordinates, incurring prohibitive computational costs. To address it, we propose NTK-Guided Implicit Neural Teaching (NINT), which accelerates training by dynamically selecting coordinates that maximize global functional updates. Leveraging the Neural Tangent Kernel (NTK), NINT scores examples by the norm of their NTK-augmented loss gradients, capturing both fitting errors and heterogeneous leverage (self-influence and cross-coordinate coupling). This dual consideration enables faster convergence compared to existing methods. Through extensive experiments, we demonstrate that NINT significantly reduces training time by nearly half while maintaining or improving representation quality, establishing state-of-the-art acceleration among recent sampling-based strategies.

