---
layout: default
title: Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models
---

# Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.15311" target="_blank" class="toolbar-btn">arXiv: 2511.15311v2</a>
    <a href="https://arxiv.org/pdf/2511.15311.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.15311v2" 
            onclick="toggleFavorite(this, '2511.15311v2', 'Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Mehran Tamjidi, Hamidreza Dastmalchi, Mohammadreza Alimoradijazi, Ali Cheraghian, Aijun An, Morteza Saberi

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-19 (Êõ¥Êñ∞: 2025-11-20)

**Â§áÊ≥®**: Accepted by AAAI 2026

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://mehran-tam.github.io/Uni-Adapter)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Uni-AdapterÔºå‰∏ÄÁßçÂÖçËÆ≠ÁªÉÁöÑ3DËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂú®Á∫øÊµãËØïÊó∂Ëá™ÈÄÇÂ∫îÊñπÊ≥ï„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `3DËßÜËßâ` `ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã` `ÊµãËØïÊó∂Ëá™ÈÄÇÂ∫î` `ÁÇπ‰∫ëÂ§ÑÁêÜ` `Âä®ÊÄÅÂéüÂûãÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3DËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÔºåÈù¢ÂØπÂô™Â£∞„ÄÅ‰∏çÂÆåÊï¥ÊàñÂàÜÂ∏ÉÂÅèÁßªÁöÑÊï∞ÊçÆÊó∂ÊÄßËÉΩ‰∏ãÈôç„ÄÇ
2. Uni-AdapterÈÄöËøáÂä®ÊÄÅÂéüÂûãÂ≠¶‰π†ÔºåÊûÑÂª∫Âπ∂Êõ¥Êñ∞Á±ªÁâπÂÆöÂéüÂûãÔºå‰ª•ÈÄÇÂ∫îÂºÇÊûÑÊï∞ÊçÆÂàÜÂ∏É„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåUni-AdapterÂú®Â§ö‰∏™3DÊï∞ÊçÆÈõÜ‰∏äÊòæËëóÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄßÔºåÊó†ÈúÄÈáçÊñ∞ËÆ≠ÁªÉ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

3DËßÜËßâ-ËØ≠Ë®ÄÂü∫Á°ÄÊ®°Âûã(VLFMs)Âú®ÂºÄÊîæ‰∏ñÁïåÁÇπ‰∫ëÂ§ÑÁêÜ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñÂíåÈõ∂Ê†∑Êú¨ËØÜÂà´ËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂú®Êï∞ÊçÆÂòàÊùÇ„ÄÅ‰∏çÂÆåÊï¥ÊàñÊù•Ëá™‰∏éËÆ≠ÁªÉÊï∞ÊçÆ‰∏çÂêåÂàÜÂ∏ÉÁöÑÂÆûÈôÖÂú∫ÊôØ‰∏≠ÔºåËøô‰∫õÊ®°ÂûãÁöÑÊÄßËÉΩÈÄöÂ∏∏‰∏ç‰Ω≥„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫Uni-AdapterÔºå‰∏ÄÁßçÂü∫‰∫éÂä®ÊÄÅÂéüÂûãÂ≠¶‰π†ÁöÑ3D VLFMsÊñ∞ÂûãÂÖçËÆ≠ÁªÉÂú®Á∫øÊµãËØïÊó∂Ëá™ÈÄÇÂ∫î(TTA)Á≠ñÁï•„ÄÇÊàë‰ª¨ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™3DÁºìÂ≠òÊù•Â≠òÂÇ®Á±ªÁâπÂÆöÁöÑËÅöÁ±ª‰∏≠ÂøÉ‰Ωú‰∏∫ÂéüÂûãÔºåËøô‰∫õÂéüÂûã‰∏çÊñ≠Êõ¥Êñ∞‰ª•ÊçïËé∑ÂºÇÊûÑÊï∞ÊçÆÂàÜÂ∏É‰∏≠ÁöÑÁ±ªÂÜÖÂèòÂºÇÊÄß„ÄÇËøô‰∫õÂä®ÊÄÅÂéüÂûã‰Ωú‰∏∫ÈÄöËøáÁõ∏‰ººÊÄßËØÑÂàÜËøõË°åÂü∫‰∫éÁºìÂ≠òÁöÑlogitËÆ°ÁÆóÁöÑÈîöÁÇπ„ÄÇÂêåÊó∂ÔºåÂü∫‰∫éÂõæÁöÑÊ†áÁ≠æÂπ≥ÊªëÊ®°ÂùóÊçïËé∑ÂéüÂûãÈó¥ÁöÑÁõ∏‰ººÊÄßÔºå‰ª•Â¢ûÂº∫Áõ∏‰ººÂéüÂûã‰πãÈó¥ÁöÑÊ†áÁ≠æ‰∏ÄËá¥ÊÄß„ÄÇÊúÄÂêéÔºåÊàë‰ª¨‰ΩøÁî®ÁÜµÂä†ÊùÉËÅöÂêàÊù•Áªü‰∏ÄÊù•Ëá™ÂéüÂßã3D VLFMÂíåÁ≤æÁÇºÁöÑ3DÁºìÂ≠òÁöÑÈ¢ÑÊµãÔºå‰ª•ÂÆûÁé∞ÂèØÈù†ÁöÑËá™ÈÄÇÂ∫î„ÄÇÊó†ÈúÄÈáçÊñ∞ËÆ≠ÁªÉÔºåUni-AdapterÊúâÊïàÂú∞ÁºìËß£‰∫ÜÂàÜÂ∏ÉÂÅèÁßªÔºåÂú®‰∏çÂêåÁöÑ3DÂü∫ÂáÜÊµãËØï‰∏≠ÔºåÈíàÂØπ‰∏çÂêåÁöÑ3D VLFMsÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂú®ModelNet-40C‰∏äÊèêÈ´ò‰∫Ü10.55%ÔºåÂú®ScanObjectNN-C‰∏äÊèêÈ´ò‰∫Ü8.26%ÔºåÂú®ShapeNet-C‰∏äÊèêÈ´ò‰∫Ü4.49%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥3DËßÜËßâ-ËØ≠Ë®ÄÂü∫Á°ÄÊ®°ÂûãÂú®ÊµãËØïÊó∂ÈÅáÂà∞ÂàÜÂ∏ÉÂÅèÁßªÈóÆÈ¢òÔºåÂç≥Ê®°ÂûãÂú®ËÆ≠ÁªÉÊï∞ÊçÆÂíåÂÆûÈôÖÂ∫îÁî®Êï∞ÊçÆ‰πãÈó¥Â≠òÂú®Â∑ÆÂºÇÊó∂ÊÄßËÉΩÊòæËëó‰∏ãÈôç„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÈáçÊñ∞ËÆ≠ÁªÉÊ®°ÂûãÊàñËøõË°åÂæÆË∞ÉÔºåËÆ°ÁÆóÊàêÊú¨È´òÊòÇ‰∏îÊïàÁéá‰Ωé‰∏ã„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÂú®‰∏çËøõË°åËÆ≠ÁªÉÁöÑÊÉÖÂÜµ‰∏ãÔºå‰ΩøÊ®°ÂûãÈÄÇÂ∫îÊñ∞ÁöÑÊï∞ÊçÆÂàÜÂ∏ÉÔºåÊòØÊú¨ÊñáË¶ÅËß£ÂÜ≥ÁöÑÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöUni-AdapterÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Âä®ÊÄÅÂéüÂûãÂ≠¶‰π†ÔºåÊûÑÂª∫‰∏Ä‰∏™ËÉΩÂ§üÊçïËé∑Á±ªÂÜÖÂèòÂºÇÊÄßÁöÑ3DÁºìÂ≠ò„ÄÇËØ•ÁºìÂ≠òÂ≠òÂÇ®Á±ªÁâπÂÆöÁöÑËÅöÁ±ª‰∏≠ÂøÉ‰Ωú‰∏∫ÂéüÂûãÔºåÂπ∂ÈöèÁùÄÊñ∞Êï∞ÊçÆÁöÑËæìÂÖ•‰∏çÊñ≠Êõ¥Êñ∞Ëøô‰∫õÂéüÂûã„ÄÇÈÄöËøáÂ∞ÜËæìÂÖ•Êï∞ÊçÆ‰∏éÁºìÂ≠ò‰∏≠ÁöÑÂéüÂûãËøõË°åÊØîËæÉÔºåÂèØ‰ª•ÂÆûÁé∞ÂØπÊ®°ÂûãÈ¢ÑÊµãÁªìÊûúÁöÑ‰øÆÊ≠£Ôºå‰ªéËÄåÈÄÇÂ∫îÊñ∞ÁöÑÊï∞ÊçÆÂàÜÂ∏É„ÄÇËøôÁßçÊñπÊ≥ïÊó†ÈúÄÈáçÊñ∞ËÆ≠ÁªÉÊ®°ÂûãÔºåÂÖ∑ÊúâÈ´òÊïàÊÄßÂíåÁÅµÊ¥ªÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöUni-AdapterÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) 3DÁºìÂ≠òÔºöÁî®‰∫éÂ≠òÂÇ®ÂíåÊõ¥Êñ∞Á±ªÁâπÂÆöÁöÑÂéüÂûã„ÄÇ2) Âü∫‰∫éÁºìÂ≠òÁöÑLogitËÆ°ÁÆóÔºöÈÄöËøáËÆ°ÁÆóËæìÂÖ•Êï∞ÊçÆ‰∏éÂéüÂûã‰πãÈó¥ÁöÑÁõ∏‰ººÊÄßÂæóÂàÜÔºåÁîüÊàêÊñ∞ÁöÑlogit„ÄÇ3) Âü∫‰∫éÂõæÁöÑÊ†áÁ≠æÂπ≥ÊªëÔºöÂà©Áî®ÂéüÂûã‰πãÈó¥ÁöÑÁõ∏‰ººÊÄßÔºåÂ¢ûÂº∫Ê†áÁ≠æ‰∏ÄËá¥ÊÄß„ÄÇÊúÄÂêéÔºåÈÄöËøáÁÜµÂä†ÊùÉËÅöÂêàÔºåÂ∞ÜÂéüÂßãÊ®°ÂûãÁöÑÈ¢ÑÊµãÁªìÊûúÂíåÁºìÂ≠òÁöÑÈ¢ÑÊµãÁªìÊûúËøõË°åËûçÂêàÔºåÂæóÂà∞ÊúÄÁªàÁöÑÈ¢ÑÊµãÁªìÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöUni-AdapterÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÂÖçËÆ≠ÁªÉÁöÑÂú®Á∫øÊµãËØïÊó∂Ëá™ÈÄÇÂ∫îÁ≠ñÁï•„ÄÇ‰∏é‰º†ÁªüÁöÑÈúÄË¶ÅÈáçÊñ∞ËÆ≠ÁªÉÊàñÂæÆË∞ÉÁöÑÊñπÊ≥ï‰∏çÂêåÔºåUni-AdapterÂèØ‰ª•Âú®ÊµãËØïÊó∂Âä®ÊÄÅÂú∞ÈÄÇÂ∫îÊñ∞ÁöÑÊï∞ÊçÆÂàÜÂ∏ÉÔºåÊó†ÈúÄ‰ªª‰ΩïËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇÊ≠§Â§ñÔºåÂä®ÊÄÅÂéüÂûãÂ≠¶‰π†ÂíåÂü∫‰∫éÂõæÁöÑÊ†áÁ≠æÂπ≥ÊªëÊ®°ÂùóËÉΩÂ§üÊúâÊïàÂú∞ÊçïËé∑Á±ªÂÜÖÂèòÂºÇÊÄßÂíåÁ±ªÈó¥ÂÖ≥Á≥ªÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**Ôºö3DÁºìÂ≠ò‰ΩøÁî®K-meansËÅöÁ±ªÁÆóÊ≥ïÊù•ÂàùÂßãÂåñÂíåÊõ¥Êñ∞ÂéüÂûã„ÄÇÁõ∏‰ººÊÄßËØÑÂàÜÈááÁî®‰ΩôÂº¶Áõ∏‰ººÂ∫¶„ÄÇÂü∫‰∫éÂõæÁöÑÊ†áÁ≠æÂπ≥ÊªëÊ®°Âùó‰ΩøÁî®KNNÂõæÊù•ÊûÑÂª∫ÂéüÂûã‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÁÜµÂä†ÊùÉËÅöÂêà‰ΩøÁî®È¢ÑÊµãÁªìÊûúÁöÑÁÜµÂÄºÊù•Á°ÆÂÆöÂéüÂßãÊ®°ÂûãÂíåÁºìÂ≠òÈ¢ÑÊµãÁªìÊûúÁöÑÊùÉÈáç„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÔºàÂ¶ÇK-meansÁöÑÁ∞áÊï∞„ÄÅKNNÂõæÁöÑÈÇªÂ±ÖÊï∞ÔºâÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰ΩìÊï∞ÊçÆÈõÜËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Uni-AdapterÂú®ModelNet-40C„ÄÅScanObjectNN-CÂíåShapeNet-CÁ≠âÂ§ö‰∏™3DÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÂú®ModelNet-40C‰∏äÔºåUni-AdapterÁöÑÊÄßËÉΩÊèêÂçá‰∫Ü10.55%ÔºõÂú®ScanObjectNN-C‰∏äÔºåÊÄßËÉΩÊèêÂçá‰∫Ü8.26%ÔºõÂú®ShapeNet-C‰∏äÔºåÊÄßËÉΩÊèêÂçá‰∫Ü4.49%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåUni-AdapterËÉΩÂ§üÊúâÊïàÂú∞ÁºìËß£ÂàÜÂ∏ÉÂÅèÁßªÈóÆÈ¢òÔºåÊèêÈ´òÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Uni-AdapterÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÂ§ÑÁêÜ3DÁÇπ‰∫ëÊï∞ÊçÆÁöÑÂú∫ÊôØÔºå‰æãÂ¶ÇËá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÂÆ§ÂÜÖÂú∫ÊôØÁêÜËß£„ÄÅ‰∏âÁª¥ÈáçÂª∫Á≠â„ÄÇËØ•ÊñπÊ≥ïËÉΩÂ§üÊèêÂçáÊ®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÈ≤ÅÊ£íÊÄßÂíåÂáÜÁ°ÆÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®Êï∞ÊçÆË¥®ÈáèËæÉÂ∑ÆÊàñÊï∞ÊçÆÂàÜÂ∏ÉÂèëÁîüÂèòÂåñÁöÑÊÉÖÂÜµ‰∏ã„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÊ®°ÊÄÅÁöÑÊï∞ÊçÆÔºå‰æãÂ¶ÇÂõæÂÉèÂíåÊñáÊú¨Ôºå‰ªéËÄåÂÆûÁé∞Êõ¥ÈÄöÁî®ÁöÑËá™ÈÄÇÂ∫îËÉΩÂäõ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> 3D Vision-Language Foundation Models (VLFMs) have shown strong generalization and zero-shot recognition capabilities in open-world point cloud processing tasks. However, these models often underperform in practical scenarios where data are noisy, incomplete, or drawn from a different distribution than the training data. To address this, we propose Uni-Adapter, a novel training-free online test-time adaptation (TTA) strategy for 3D VLFMs based on dynamic prototype learning. We define a 3D cache to store class-specific cluster centers as prototypes, which are continuously updated to capture intra-class variability in heterogeneous data distributions. These dynamic prototypes serve as anchors for cache-based logit computation via similarity scoring. Simultaneously, a graph-based label smoothing module captures inter-prototype similarities to enforce label consistency among similar prototypes. Finally, we unify predictions from the original 3D VLFM and the refined 3D cache using entropy-weighted aggregation for reliable adaptation. Without retraining, Uni-Adapter effectively mitigates distribution shifts, achieving state-of-the-art performance on diverse 3D benchmarks over different 3D VLFMs, improving ModelNet-40C by 10.55%, ScanObjectNN-C by 8.26%, and ShapeNet-C by 4.49% over the source 3D VLFMs. Project page: https://mehran-tam.github.io/Uni-Adapter

