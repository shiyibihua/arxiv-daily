---
layout: default
title: Evaluating Multimodal Large Language Models on Vertically Written Japanese Text
---

# Evaluating Multimodal Large Language Models on Vertically Written Japanese Text

**arXiv**: [2511.15059v1](https://arxiv.org/abs/2511.15059) | [PDF](https://arxiv.org/pdf/2511.15059.pdf)

**ä½œè€…**: Keito Sasagawa, Shuhei Kurita, Daisuke Kawahara

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹å¯¹ç«–æŽ’æ—¥æ–‡æ–‡æœ¬çš„é˜…è¯»èƒ½åŠ›ï¼Œå¹¶é€šè¿‡åˆæˆæ•°æ®é›†æå‡æ€§èƒ½**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `ç«–æŽ’æ—¥æ–‡æ–‡æœ¬` `OCRæ•°æ®é›†` `è§†è§‰æ–‡æ¡£ç†è§£` `æ¨¡åž‹å¾®è°ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰MLLMsåœ¨ç«–æŽ’æ—¥æ–‡æ–‡æœ¬ä¸Šè¡¨çŽ°å·®ï¼Œç¼ºä¹ä¸“é—¨ç ”ç©¶ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç”Ÿæˆåˆæˆæ—¥æ–‡OCRæ•°æ®é›†ï¼Œç”¨äºŽæ¨¡åž‹å¾®è°ƒå’Œè¯„ä¼°ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè®­ç»ƒåŽæ¨¡åž‹åœ¨ç«–æŽ’æ–‡æœ¬ä¸Šæ€§èƒ½æå‡ï¼Œæ•°æ®é›†å…¬å¼€ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) have seen rapid advances in recent years and are now being applied to visual document understanding tasks. They are expected to process a wide range of document images across languages, including Japanese. Understanding documents from images requires models to read what are written in them. Since some Japanese documents are written vertically, support for vertical writing is essential. However, research specifically focused on vertically written Japanese text remains limited. In this study, we evaluate the reading capability of existing MLLMs on vertically written Japanese text. First, we generate a synthetic Japanese OCR dataset by rendering Japanese texts into images, and use it for both model fine-tuning and evaluation. This dataset includes Japanese text in both horizontal and vertical writing. We also create an evaluation dataset sourced from the real-world document images containing vertically written Japanese text. Using these datasets, we demonstrate that the existing MLLMs perform worse on vertically written Japanese text than on horizontally written Japanese text. Furthermore, we show that training MLLMs on our synthesized Japanese OCR dataset results in improving the performance of models that previously could not handle vertical writing. The datasets and code are publicly available https://github.com/llm-jp/eval_vertical_ja.

