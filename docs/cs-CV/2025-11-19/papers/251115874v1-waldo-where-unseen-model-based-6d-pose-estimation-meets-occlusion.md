---
layout: default
title: WALDO: Where Unseen Model-based 6D Pose Estimation Meets Occlusion
---

# WALDO: Where Unseen Model-based 6D Pose Estimation Meets Occlusion

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.15874" target="_blank" class="toolbar-btn">arXiv: 2511.15874v1</a>
    <a href="https://arxiv.org/pdf/2511.15874.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.15874v1" 
            onclick="toggleFavorite(this, '2511.15874v1', 'WALDO: Where Unseen Model-based 6D Pose Estimation Meets Occlusion')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Sajjad Pakdamansavoji, Yintao Ma, Amir Rasouli, Tongtong Cao

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-19

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**WALDOÔºöÊèêÂá∫‰∏ÄÁßçÊñ∞È¢ñÁöÑÂü∫‰∫éÊ®°ÂûãÁöÑ6D‰ΩçÂßø‰º∞ËÆ°ÊñπÊ≥ïÔºåÊèêÂçáÈÅÆÊå°Âú∫ÊôØ‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `6D‰ΩçÂßø‰º∞ËÆ°` `ÈÅÆÊå°Â§ÑÁêÜ` `Ê®°ÂûãÈ©±Âä®` `Êú∫Âô®‰∫∫` `Â¢ûÂº∫Áé∞ÂÆû` `Âä®ÊÄÅÈááÊ†∑` `Â§öÂÅáËÆæÊé®ÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éÊ®°ÂûãÁöÑ6D‰ΩçÂßø‰º∞ËÆ°ÊñπÊ≥ïÂú®ÈÅÆÊå°Âú∫ÊôØ‰∏ãÔºåÁî±‰∫éÊó©ÊúüÈò∂ÊÆµÁöÑÊ£ÄÊµãÂíåÂàÜÂâ≤ËØØÂ∑ÆÔºåÂØºËá¥ÊÄßËÉΩÊòæËëó‰∏ãÈôç„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫WALDOÔºåÈÄöËøáÂä®ÊÄÅÈááÊ†∑„ÄÅÂ§öÂÅáËÆæÊé®ÁêÜ„ÄÅËø≠‰ª£ÁªÜÂåñÂíåÈÅÆÊå°Â¢ûÂº∫Á≠âÁ≠ñÁï•ÔºåÊèêÂçáÈÅÆÊå°Âú∫ÊôØ‰∏ãÁöÑ‰ΩçÂßø‰º∞ËÆ°È≤ÅÊ£íÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåWALDOÂú®ICBINÂíåBOPÊï∞ÊçÆÈõÜ‰∏äÂùáÂèñÂæó‰∫ÜÊòæËëóÁöÑÁ≤æÂ∫¶ÊèêÂçáÔºåÂπ∂ÊèêÈ´ò‰∫ÜÊé®ÁêÜÈÄüÂ∫¶„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Á≤æÁ°ÆÁöÑ6DÁâ©‰Ωì‰ΩçÂßø‰º∞ËÆ°ÂØπ‰∫éÊú∫Âô®‰∫∫„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÂíåÂú∫ÊôØÁêÜËß£Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÂØπ‰∫éÂ∑≤ËßÅËøáÁöÑÁâ©‰ΩìÔºåÈÄöËøáÈÄêÂØπË±°ÂæÆË∞ÉÈÄöÂ∏∏ÂèØ‰ª•ÂÆûÁé∞È´òÁ≤æÂ∫¶Ôºå‰ΩÜÊ≥õÂåñÂà∞Êú™ËßÅËøáÁöÑÁâ©‰Ωì‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåËøáÂéªÁöÑÊñπÊ≥ïÈÄöÂ∏∏ÂÅáËÆæÂú®ÊµãËØïÊó∂ÂèØ‰ª•ËÆøÈóÆCADÊ®°ÂûãÔºåÂπ∂‰∏îÈÄöÂ∏∏ÈÅµÂæ™‰∏Ä‰∏™Â§öÈò∂ÊÆµÊµÅÁ®ãÊù•‰º∞ËÆ°‰ΩçÂßøÔºöÊ£ÄÊµãÂíåÂàÜÂâ≤Áâ©‰ΩìÔºåÊèêÂá∫ÂàùÂßã‰ΩçÂßøÔºåÁÑ∂ÂêéÂØπÂÖ∂ËøõË°åÁªÜÂåñ„ÄÇÁÑ∂ËÄåÔºåÂú®ÈÅÆÊå°‰∏ãÔºåËøôÁßçÊµÅÁ®ãÁöÑÊó©ÊúüÈò∂ÊÆµÂÆπÊòìÂá∫ÈîôÔºåËøô‰∫õÈîôËØØ‰ºöÈÄöËøáÈ°∫Â∫èÂ§ÑÁêÜ‰º†Êí≠Ôºå‰ªéËÄåÈôç‰ΩéÊÄßËÉΩ„ÄÇ‰∏∫‰∫ÜÂº•Ë°•Ëøô‰∏™Áº∫ÁÇπÔºåÊàë‰ª¨ÂØπÂü∫‰∫éÊ®°ÂûãÁöÑ6D‰ΩçÂßø‰º∞ËÆ°ÊñπÊ≥ïÊèêÂá∫‰∫ÜÂõõ‰∏™Êñ∞ÁöÑÊâ©Â±ïÔºöÔºàiÔºâ‰∏ÄÁßçÂä®ÊÄÅÈùûÂùáÂåÄÂØÜÈõÜÈááÊ†∑Á≠ñÁï•ÔºåÂ∞ÜËÆ°ÁÆóÈõÜ‰∏≠Âú®ÂèØËßÅÂå∫ÂüüÔºåÂáèÂ∞ëÈÅÆÊå°ÂºïËµ∑ÁöÑËØØÂ∑ÆÔºõÔºàiiÔºâ‰∏ÄÁßçÂ§öÂÅáËÆæÊé®ÁêÜÊú∫Âà∂Ôºå‰øùÁïôÂá†‰∏™ÁΩÆ‰ø°Â∫¶ÊéíÂ∫èÁöÑ‰ΩçÂßøÂÄôÈÄâÔºåÂáèËΩªËÑÜÂº±ÁöÑÂçïË∑ØÂæÑÂ§±Ë¥•ÔºõÔºàiiiÔºâËø≠‰ª£ÁªÜÂåñÔºå‰ª•ÈÄêÊ≠•ÊèêÈ´ò‰ΩçÂßøÁ≤æÂ∫¶ÔºõÔºàivÔºâ‰∏ÄÁ≥ªÂàó‰ª•ÈÅÆÊå°‰∏∫‰∏≠ÂøÉÁöÑËÆ≠ÁªÉÊï∞ÊçÆÂ¢ûÂº∫Ôºå‰ª•Â¢ûÂº∫È≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊåâÂèØËßÅÊÄßÂä†ÊùÉÁöÑËØÑ‰º∞ÊåáÊ†áÔºåÁî®‰∫éÂú®ÈÅÆÊå°‰∏ãËøõË°åËØÑ‰º∞Ôºå‰ª•ÊúÄÂ§ßÈôêÂ∫¶Âú∞ÂáèÂ∞ëÁé∞ÊúâÂçèËÆÆ‰∏≠ÁöÑÂÅèÂ∑Æ„ÄÇÈÄöËøáÂπøÊ≥õÁöÑÂÆûËØÅËØÑ‰º∞ÔºåÊàë‰ª¨Ë°®ÊòéÊàë‰ª¨ÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ICBIN‰∏äÂÆûÁé∞‰∫ÜË∂ÖËøá5%ÁöÑÁ≤æÂ∫¶ÊèêÂçáÔºåÂú®BOPÊï∞ÊçÆÈõÜÂü∫ÂáÜ‰∏äÂÆûÁé∞‰∫ÜË∂ÖËøá2%ÁöÑÁ≤æÂ∫¶ÊèêÂçáÔºåÂêåÊó∂ÂÆûÁé∞‰∫ÜÂ§ßÁ∫¶3ÂÄçÁöÑÊé®ÁêÜÈÄüÂ∫¶„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Âú®Â≠òÂú®ÈÅÆÊå°ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂü∫‰∫éÊ®°ÂûãÁöÑ6D‰ΩçÂßø‰º∞ËÆ°Á≤æÂ∫¶‰∏ãÈôçÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÁ≤æÁ°ÆÁöÑÁâ©‰ΩìÊ£ÄÊµãÂíåÂàÜÂâ≤Ôºå‰ΩÜÂú®ÈÅÆÊå°ÁéØÂ¢É‰∏ãÔºåËøô‰∫õÊ≠•È™§ÂÆπÊòìÂá∫ÈîôÔºåÂØºËá¥ÂêéÁª≠ÁöÑ‰ΩçÂßø‰º∞ËÆ°ÊÄßËÉΩÂèóÂà∞‰∏•ÈáçÂΩ±Âìç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂáèÂ∞ëÂØπÂÆåÊï¥Áâ©‰Ωì‰ø°ÊÅØÁöÑ‰æùËµñÔºåÊõ¥Âä†ÂÖ≥Ê≥®ÂèØËßÅÂå∫ÂüüÁöÑ‰ø°ÊÅØÔºåÂπ∂ÈááÁî®Â§öÂÅáËÆæÊé®ÁêÜÊù•Â∫îÂØπ‰∏çÁ°ÆÂÆöÊÄß„ÄÇÈÄöËøáÂä®ÊÄÅÈááÊ†∑Á≠ñÁï•ÔºåÂ∞ÜËÆ°ÁÆóËµÑÊ∫êÈõÜ‰∏≠Âú®ÂèØËßÅÂå∫ÂüüÔºåÂáèÂ∞ëÈÅÆÊå°Â∏¶Êù•ÁöÑÂπ≤Êâ∞„ÄÇÂ§öÂÅáËÆæÊé®ÁêÜÂàô‰øùÁïôÂ§ö‰∏™ÂèØËÉΩÁöÑ‰ΩçÂßø‰º∞ËÆ°ÔºåÈÅøÂÖçÂõ†Êó©ÊúüÈîôËØØËÄåÂØºËá¥ÁöÑÂçïË∑ØÂæÑÂ§±Ë¥•„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöWALDOÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Âä®ÊÄÅÈùûÂùáÂåÄÂØÜÈõÜÈááÊ†∑ÔºöÊ†πÊçÆÂèØËßÅÊÄßÂØπÁâ©‰ΩìË°®Èù¢ËøõË°åÈááÊ†∑ÔºåÈõÜ‰∏≠ËÆ°ÁÆóËµÑÊ∫ê‰∫éÂèØËßÅÂå∫Âüü„ÄÇ2) Â§öÂÅáËÆæÊé®ÁêÜÔºöÁîüÊàêÂ§ö‰∏™ÂÄôÈÄâ‰ΩçÂßøÔºåÂπ∂Ê†πÊçÆÁΩÆ‰ø°Â∫¶ËøõË°åÊéíÂ∫è„ÄÇ3) Ëø≠‰ª£ÁªÜÂåñÔºöÈÄêÊ≠•‰ºòÂåñÂÄôÈÄâ‰ΩçÂßøÔºåÊèêÈ´òÁ≤æÂ∫¶„ÄÇ4) ÈÅÆÊå°Â¢ûÂº∫ÔºöÈÄöËøáÊ®°ÊãüÂêÑÁßçÈÅÆÊå°ÊÉÖÂÜµÊù•Â¢ûÂº∫Ê®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂä®ÊÄÅÈùûÂùáÂåÄÂØÜÈõÜÈááÊ†∑Á≠ñÁï•ÂíåÂ§öÂÅáËÆæÊé®ÁêÜÊú∫Âà∂„ÄÇÂä®ÊÄÅÈááÊ†∑ËÉΩÂ§üÊúâÊïàÂú∞ÂáèÂ∞ëÈÅÆÊå°Â∏¶Êù•ÁöÑÂπ≤Êâ∞ÔºåÊèêÈ´ò‰ΩçÂßø‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂ§öÂÅáËÆæÊé®ÁêÜÂàôËÉΩÂ§üÂ∫îÂØπ‰∏çÁ°ÆÂÆöÊÄßÔºåÈÅøÂÖçÂõ†Êó©ÊúüÈîôËØØËÄåÂØºËá¥ÁöÑÂçïË∑ØÂæÑÂ§±Ë¥•„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫ÁöÑÈÅÆÊå°ÊÑüÁü•ËØÑ‰º∞ÊåáÊ†á‰πüÊõ¥Âä†ÂêàÁêÜÂú∞ËØÑ‰º∞‰∫ÜÁÆóÊ≥ïÂú®ÈÅÆÊå°ÁéØÂ¢É‰∏ãÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂä®ÊÄÅÈááÊ†∑Á≠ñÁï•Ê†πÊçÆÁâ©‰ΩìÁöÑÂèØËßÅÊÄßÊ¶ÇÁéáÂàÜÂ∏ÉËøõË°åÈááÊ†∑ÔºåÂèØËßÅÊÄßÊ¶ÇÁéáÂèØ‰ª•ÈÄöËøáÊ∏≤ÊüìÊàñÂÖ∂‰ªñÊñπÊ≥ï‰º∞ËÆ°„ÄÇÂ§öÂÅáËÆæÊé®ÁêÜÈááÁî®ÁΩÆ‰ø°Â∫¶ÊéíÂ∫èÔºåÁΩÆ‰ø°Â∫¶ÂèØ‰ª•Âü∫‰∫éÊ∏≤ÊüìÁªìÊûú‰∏éËßÇÊµãÂõæÂÉèÁöÑÁõ∏‰ººÂ∫¶Êù•ËÆ°ÁÆó„ÄÇËø≠‰ª£ÁªÜÂåñÈááÁî®ICPÊàñÂÖ∂‰ªñ‰ºòÂåñÁÆóÊ≥ïÊù•ÈÄêÊ≠•ÊèêÈ´ò‰ΩçÂßøÁ≤æÂ∫¶„ÄÇÈÅÆÊå°Â¢ûÂº∫ÂàôÈÄöËøáÂú®ËÆ≠ÁªÉÂõæÂÉè‰∏≠ÈöèÊú∫Ê∑ªÂä†ÈÅÆÊå°Áâ©Êù•ÂÆûÁé∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåWALDOÂú®ICBINÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜË∂ÖËøá5%ÁöÑÁ≤æÂ∫¶ÊèêÂçáÔºåÂú®BOPÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜË∂ÖËøá2%ÁöÑÁ≤æÂ∫¶ÊèêÂçáÔºåÂêåÊó∂Êé®ÁêÜÈÄüÂ∫¶ÊèêÈ´ò‰∫ÜÁ∫¶3ÂÄç„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåWALDOÂú®ÈÅÆÊå°Âú∫ÊôØ‰∏ãÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÈ≤ÅÊ£íÊÄßÂíåÊõ¥È´òÁöÑÊïàÁéáÔºå‰ºò‰∫éÁé∞ÊúâÁöÑÂü∫‰∫éÊ®°ÂûãÁöÑ6D‰ΩçÂßø‰º∞ËÆ°ÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÅÂ¢ûÂº∫Áé∞ÂÆû„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüü„ÄÇÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÔºåÂáÜÁ°ÆÁöÑ6D‰ΩçÂßø‰º∞ËÆ°ÊòØÂÆûÁé∞Áâ©‰ΩìÊäìÂèñÂíåÊìç‰ΩúÁöÑÂü∫Á°Ä„ÄÇÂú®Â¢ûÂº∫Áé∞ÂÆû‰∏≠ÔºåÂèØ‰ª•Áî®‰∫éÂ∞ÜËôöÊãüÁâ©‰ΩìÁ≤æÁ°ÆÂú∞Âè†Âä†Âà∞ÁúüÂÆûÂú∫ÊôØ‰∏≠„ÄÇÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÂèØ‰ª•Áî®‰∫éÊÑüÁü•Âë®Âõ¥ÁéØÂ¢É‰∏≠ÁöÑÁâ©‰ΩìÔºåÂπ∂ËøõË°åÁ≤æÁ°ÆÁöÑÂÆö‰ΩçÂíåË∑üË∏™„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Accurate 6D object pose estimation is vital for robotics, augmented reality, and scene understanding. For seen objects, high accuracy is often attainable via per-object fine-tuning but generalizing to unseen objects remains a challenge. To address this problem, past arts assume access to CAD models at test time and typically follow a multi-stage pipeline to estimate poses: detect and segment the object, propose an initial pose, and then refine it. Under occlusion, however, the early-stage of such pipelines are prone to errors, which can propagate through the sequential processing, and consequently degrade the performance. To remedy this shortcoming, we propose four novel extensions to model-based 6D pose estimation methods: (i) a dynamic non-uniform dense sampling strategy that focuses computation on visible regions, reducing occlusion-induced errors; (ii) a multi-hypothesis inference mechanism that retains several confidence-ranked pose candidates, mitigating brittle single-path failures; (iii) iterative refinement to progressively improve pose accuracy; and (iv) series of occlusion-focused training augmentations that strengthen robustness and generalization. Furthermore, we propose a new weighted by visibility metric for evaluation under occlusion to minimize the bias in the existing protocols. Via extensive empirical evaluations, we show that our proposed approach achieves more than 5% improvement in accuracy on ICBIN and more than 2% on BOP dataset benchmarks, while achieving approximately 3 times faster inference.

