---
layout: default
title: Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation
---

# Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation

**arXiv**: [2511.15167v1](https://arxiv.org/abs/2511.15167) | [PDF](https://arxiv.org/pdf/2511.15167.pdf)

**ä½œè€…**: Jing Cao, Kui Jiang, Shenyi Li, Xiaocheng Feng, Yong Huang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-19

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªè¿›åŒ–å¯¹æ¯”å­¦ä¹ æ¡†æž¶SEC-Depthï¼Œæå‡æ¶åŠ£å¤©æ°”ä¸‹è‡ªç›‘ç£æ·±åº¦ä¼°è®¡çš„é²æ£’æ€§**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è‡ªç›‘ç£æ·±åº¦ä¼°è®¡` `é²æ£’æ€§` `å¯¹æ¯”å­¦ä¹ ` `æ¶åŠ£å¤©æ°”` `è‡ªè¿›åŒ–å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è‡ªç›‘ç£æ·±åº¦ä¼°è®¡æ–¹æ³•åœ¨æ¶åŠ£å¤©æ°”ä¸‹æ€§èƒ½å¤§å¹…ä¸‹é™ï¼ŒåŽŸå› æ˜¯èƒ½è§åº¦é™ä½Žå¯¼è‡´æ·±åº¦é¢„æµ‹å›°éš¾ã€‚
2. è®ºæ–‡æå‡ºè‡ªè¿›åŒ–å¯¹æ¯”å­¦ä¹ æ¡†æž¶SEC-Depthï¼Œåˆ©ç”¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸­é—´å‚æ•°æž„å»ºæ—¶é—´æ¼”åŒ–çš„æ½œåœ¨æ¨¡åž‹ï¼Œæå‡é²æ£’æ€§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•èƒ½æ— ç¼é›†æˆåˆ°å¤šç§åŸºçº¿æ¨¡åž‹ä¸­ï¼Œå¹¶åœ¨é›¶æ ·æœ¬è¯„ä¼°ä¸­æ˜¾è‘—æå‡æ¶åŠ£å¤©æ°”ä¸‹çš„æ·±åº¦ä¼°è®¡æ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªç›‘ç£æ·±åº¦ä¼°è®¡åœ¨è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººé¢†åŸŸå¤‡å—å…³æ³¨ã€‚ç„¶è€Œï¼ŒçŽ°æœ‰æ–¹æ³•åœ¨é›¨ã€é›¾ç­‰æ¶åŠ£å¤©æ°”æ¡ä»¶ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œèƒ½è§åº¦é™ä½Žä¸¥é‡å½±å“æ·±åº¦é¢„æµ‹ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªè¿›åŒ–å¯¹æ¯”å­¦ä¹ æ¡†æž¶ï¼Œç§°ä¸ºSEC-Depthï¼Œç”¨äºŽè‡ªç›‘ç£é²æ£’æ·±åº¦ä¼°è®¡ä»»åŠ¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆçš„ä¸­é—´å‚æ•°æ¥æž„å»ºæ—¶é—´æ¼”åŒ–çš„æ½œåœ¨æ¨¡åž‹ã€‚åˆ©ç”¨è¿™äº›æ¨¡åž‹ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§è‡ªè¿›åŒ–å¯¹æ¯”æ–¹æ¡ˆï¼Œä»¥å‡è½»åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹çš„æ€§èƒ½æŸå¤±ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é¦–å…ˆä¸ºæ·±åº¦ä¼°è®¡ä»»åŠ¡è®¾è®¡äº†ä¸€ç§æ½œåœ¨æ¨¡åž‹çš„åŠ¨æ€æ›´æ–°ç­–ç•¥ï¼Œä»¥æ•èŽ·è·¨è®­ç»ƒé˜¶æ®µçš„ä¼˜åŒ–çŠ¶æ€ã€‚ä¸ºäº†æœ‰æ•ˆåœ°åˆ©ç”¨æ½œåœ¨æ¨¡åž‹ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªè¿›åŒ–å¯¹æ¯”æŸå¤±ï¼ˆSECLï¼‰ï¼Œå°†åŽ†å²æ½œåœ¨æ¨¡åž‹çš„è¾“å‡ºè§†ä¸ºè´Ÿæ ·æœ¬ã€‚è¿™ç§æœºåˆ¶è‡ªé€‚åº”åœ°è°ƒæ•´å­¦ä¹ ç›®æ ‡ï¼ŒåŒæ—¶éšå¼åœ°æ„ŸçŸ¥å¤©æ°”é€€åŒ–ç¨‹åº¦ï¼Œå‡å°‘äº†æ‰‹åŠ¨å¹²é¢„çš„éœ€æ±‚ã€‚å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æ— ç¼é›†æˆåˆ°ä¸åŒçš„åŸºçº¿æ¨¡åž‹ä¸­ï¼Œå¹¶æ˜¾è‘—æé«˜é›¶æ ·æœ¬è¯„ä¼°çš„é²æ£’æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰è‡ªç›‘ç£æ·±åº¦ä¼°è®¡æ–¹æ³•åœ¨æ¶åŠ£å¤©æ°”ï¼ˆå¦‚é›¨ã€é›¾ï¼‰ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚è¿™äº›å¤©æ°”æ¡ä»¶é™ä½Žäº†å›¾åƒçš„èƒ½è§åº¦ï¼Œä½¿å¾—æ·±åº¦é¢„æµ‹å˜å¾—æ›´åŠ å›°éš¾ï¼Œä¸¥é‡å½±å“äº†è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººç­‰åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ¨¡åž‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„åŽ†å²çŠ¶æ€ï¼ˆå³ä¸­é—´å‚æ•°ï¼‰æž„å»ºä¸€ç³»åˆ—â€œæ½œåœ¨æ¨¡åž‹â€ï¼Œå¹¶å°†è¿™äº›æ½œåœ¨æ¨¡åž‹çš„è¾“å‡ºä½œä¸ºè´Ÿæ ·æœ¬ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ çš„æ–¹å¼ï¼Œæå‡æ¨¡åž‹åœ¨æ¶åŠ£å¤©æ°”ä¸‹çš„é²æ£’æ€§ã€‚è¿™ç§æ–¹æ³•æ¨¡æ‹Ÿäº†æ¨¡åž‹åœ¨ä¸åŒè®­ç»ƒé˜¶æ®µå¯¹æ¶åŠ£å¤©æ°”çš„é€‚åº”è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šSEC-Depthæ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªå…³é”®æ¨¡å—ï¼š1) åŠ¨æ€æ›´æ–°çš„æ½œåœ¨æ¨¡åž‹ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå®šæœŸä¿å­˜æ¨¡åž‹çš„ä¸­é—´å‚æ•°ï¼Œå½¢æˆä¸€ç³»åˆ—æ½œåœ¨æ¨¡åž‹ã€‚2) è‡ªè¿›åŒ–å¯¹æ¯”æŸå¤±ï¼ˆSECLï¼‰ï¼šå°†å½“å‰æ¨¡åž‹çš„è¾“å‡ºä¸ŽåŽ†å²æ½œåœ¨æ¨¡åž‹çš„è¾“å‡ºè¿›è¡Œå¯¹æ¯”ï¼Œæž„å»ºå¯¹æ¯”æŸå¤±ï¼Œä¿ƒä½¿æ¨¡åž‹å­¦ä¹ å¯¹æ¶åŠ£å¤©æ°”æ›´é²æ£’çš„ç‰¹å¾è¡¨ç¤ºã€‚3) é›†æˆåˆ°çŽ°æœ‰åŸºçº¿æ¨¡åž‹ï¼šSEC-Depthå¯ä»¥ä½œä¸ºä¸€ä¸ªæ¨¡å—ï¼Œæ— ç¼é›†æˆåˆ°çŽ°æœ‰çš„è‡ªç›‘ç£æ·±åº¦ä¼°è®¡æ¨¡åž‹ä¸­ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽåˆ©ç”¨æ¨¡åž‹è‡ªèº«çš„åŽ†å²çŠ¶æ€è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œè€Œä¸æ˜¯ä¾èµ–äºŽé¢å¤–çš„æ•°æ®å¢žå¼ºæˆ–é¢†åŸŸè‡ªé€‚åº”æŠ€æœ¯ã€‚é€šè¿‡è¿™ç§è‡ªè¿›åŒ–å¯¹æ¯”çš„æ–¹å¼ï¼Œæ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ åˆ°å¯¹æ¶åŠ£å¤©æ°”ä¸æ•æ„Ÿçš„ç‰¹å¾è¡¨ç¤ºï¼Œä»Žè€Œæå‡é²æ£’æ€§ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSEC-Depthä¸éœ€è¦æ‰‹åŠ¨å¹²é¢„æˆ–è°ƒæ•´å‚æ•°ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°æ„ŸçŸ¥å¤©æ°”é€€åŒ–ç¨‹åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼š1) æ½œåœ¨æ¨¡åž‹çš„åŠ¨æ€æ›´æ–°ç­–ç•¥ï¼šè®ºæ–‡è®¾è®¡äº†ä¸€ç§åŠ¨æ€æ›´æ–°ç­–ç•¥ï¼Œç”¨äºŽé€‰æ‹©åˆé€‚çš„ä¸­é—´å‚æ•°ä½œä¸ºæ½œåœ¨æ¨¡åž‹ã€‚2) è‡ªè¿›åŒ–å¯¹æ¯”æŸå¤±ï¼ˆSECLï¼‰ï¼šSECLçš„è®¾è®¡è€ƒè™‘äº†ä¸åŒæ½œåœ¨æ¨¡åž‹çš„è¾“å‡ºä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œå¹¶æ ¹æ®ç›¸ä¼¼æ€§è°ƒæ•´å¯¹æ¯”æŸå¤±çš„æƒé‡ã€‚3) æŸå¤±å‡½æ•°çš„æƒé‡ï¼šè®ºæ–‡å¯èƒ½ä½¿ç”¨äº†é¢å¤–çš„æƒé‡æ¥å¹³è¡¡SECLå’Œå…¶ä»–æŸå¤±å‡½æ•°ï¼ˆå¦‚å…‰åº¦ä¸€è‡´æ€§æŸå¤±ï¼‰ä¹‹é—´çš„è´¡çŒ®ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒSEC-Depthèƒ½å¤Ÿæ˜¾è‘—æå‡è‡ªç›‘ç£æ·±åº¦ä¼°è®¡æ¨¡åž‹åœ¨æ¶åŠ£å¤©æ°”ä¸‹çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨é›¶æ ·æœ¬è¯„ä¼°ä¸­ï¼ŒSEC-Depthèƒ½å¤Ÿå°†æ·±åº¦ä¼°è®¡çš„è¯¯å·®é™ä½ŽXX%ï¼ˆå…·ä½“æ•°å€¼éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ï¼‰ï¼Œå¹¶ä¸”èƒ½å¤Ÿä¸Žå¤šç§åŸºçº¿æ¨¡åž‹æ— ç¼é›†æˆï¼Œå±•çŽ°äº†è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯å¹¿æ³›åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€æ— äººæœºç­‰é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚å’Œæ¶åŠ£å¤©æ°”æ¡ä»¶ä¸‹ã€‚é€šè¿‡æé«˜æ·±åº¦ä¼°è®¡çš„é²æ£’æ€§ï¼Œå¯ä»¥å¢žå¼ºè¿™äº›ç³»ç»Ÿåœ¨å„ç§çŽ¯å¢ƒä¸‹çš„æ„ŸçŸ¥èƒ½åŠ›å’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–æ„ŸçŸ¥ä»»åŠ¡ï¼Œå¦‚è¯­ä¹‰åˆ†å‰²å’Œç›®æ ‡æ£€æµ‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Self-supervised depth estimation has gained significant attention in autonomous driving and robotics. However, existing methods exhibit substantial performance degradation under adverse weather conditions such as rain and fog, where reduced visibility critically impairs depth prediction. To address this issue, we propose a novel self-evolution contrastive learning framework called SEC-Depth for self-supervised robust depth estimation tasks. Our approach leverages intermediate parameters generated during training to construct temporally evolving latency models. Using these, we design a self-evolution contrastive scheme to mitigate performance loss under challenging conditions. Concretely, we first design a dynamic update strategy of latency models for the depth estimation task to capture optimization states across training stages. To effectively leverage latency models, we introduce a self-evolution contrastive Loss (SECL) that treats outputs from historical latency models as negative samples. This mechanism adaptively adjusts learning objectives while implicitly sensing weather degradation severity, reducing the needs for manual intervention. Experiments show that our method integrates seamlessly into diverse baseline models and significantly enhances robustness in zero-shot evaluations.

