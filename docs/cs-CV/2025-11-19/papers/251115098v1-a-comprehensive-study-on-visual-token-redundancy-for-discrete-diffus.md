---
layout: default
title: A Comprehensive Study on Visual Token Redundancy for Discrete Diffusion-based Multimodal Large Language Models
---

# A Comprehensive Study on Visual Token Redundancy for Discrete Diffusion-based Multimodal Large Language Models

**arXiv**: [2511.15098v1](https://arxiv.org/abs/2511.15098) | [PDF](https://arxiv.org/pdf/2511.15098.pdf)

**ä½œè€…**: Duo Li, Zuhao Yang, Xiaoqin Zhang, Ling Shao, Shijian Lu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶è§†è§‰ä»¤ç‰Œå†—ä½™ä»¥ä¼˜åŒ–ç¦»æ•£æ‰©æ•£å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹æ•ˆçŽ‡**

**å…³é”®è¯**: `ç¦»æ•£æ‰©æ•£æ¨¡åž‹` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `è§†è§‰ä»¤ç‰Œå†—ä½™` `å‰ªæžä¼˜åŒ–` `æŽ¨ç†åŠ é€Ÿ` `ä¿¡æ¯æŸå¤±æ¢å¤`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç¦»æ•£æ‰©æ•£MLLMsæŽ¨ç†æ—¶è®¡ç®—å¼€é”€å¤§ï¼Œå¿½è§†è§†è§‰ä»¤ç‰Œå†—ä½™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ†æžå†—ä½™æ¼”åŒ–ï¼ŒéªŒè¯å‰ªæžå¯¹ä¿¡æ¯æŸå¤±å’Œæ¢å¤çš„å½±å“ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå‘çŽ°ä¸åŒæž¶æž„å’Œä»»åŠ¡ä¸‹å†—ä½™ç‰¹æ€§ï¼Œæå‡ºé’ˆå¯¹æ€§åŠ é€Ÿç­–ç•¥ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Discrete diffusion-based multimodal large language models (dMLLMs) have emerged as a promising alternative to autoregressive MLLMs thanks to their advantages in parallel decoding and bidirectional context modeling, but most existing dMLLMs incur significant computational overhead during inference due to the full-sequence attention computation in each denoising step. Pioneer studies attempt to resolve this issue from a modality-agnostic perspective via key-value cache optimization or efficient sampling but most of them overlook modality-specific visual token redundancy. In this work, we conduct a comprehensive study on how visual token redundancy evolves with different dMLLM architectures and tasks and how visual token pruning affects dMLLM responses and efficiency. Specifically, our study reveals that visual redundancy emerges only in from-scratch dMLLMs while handling long-answer tasks. In addition, we validate that visual token pruning introduces non-negligible information loss in dMLLMs and only from-scratch dMLLMs can recover the lost information progressively during late denoising steps. Furthermore, our study shows that layer-skipping is promising for accelerating AR-to-diffusion dMLLMs, whereas progressive or late-step pruning is more effective for from-scratch dMLLMs. Overall, this work offers a new perspective on efficiency optimization for dMLLMs, greatly advancing their applicability across various multimodal understanding tasks.

