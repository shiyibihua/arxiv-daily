---
layout: default
title: Platform-Agnostic Reinforcement Learning Framework for Safe Exploration of Cluttered Environments with Graph Attention
---

# Platform-Agnostic Reinforcement Learning Framework for Safe Exploration of Cluttered Environments with Graph Attention

**arXiv**: [2511.15358v1](https://arxiv.org/abs/2511.15358) | [PDF](https://arxiv.org/pdf/2511.15358.pdf)

**ä½œè€…**: Gabriele Calzolari, Vidya Sumathy, Christoforos Kanellakis, George Nikolakopoulos

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¹³å°æ— å…³å¼ºåŒ–å­¦ä¹ æ¡†æž¶ï¼Œç»“åˆå›¾æ³¨æ„åŠ›å’Œå®‰å…¨è¿‡æ»¤å™¨ï¼Œå®žçŽ°æ‚ä¹±çŽ¯å¢ƒä¸­çš„å®‰å…¨é«˜æ•ˆæŽ¢ç´¢ã€‚**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å›¾ç¥žç»ç½‘ç»œ` `å®‰å…¨æŽ¢ç´¢` `å¹³å°æ— å…³æ¡†æž¶` `PPOç®—æ³•` `æ½œåœ¨åœºå¥–åŠ±`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‡ªä¸»æŽ¢ç´¢éšœç¢å¯†é›†ç©ºé—´éœ€å¹³è¡¡æ•ˆçŽ‡ä¸Žå®‰å…¨ï¼Œé¿å…ç¢°æ’žã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨PPOç®—æ³•è®­ç»ƒå›¾ç¥žç»ç½‘ç»œç­–ç•¥ï¼Œé›†æˆå®‰å…¨è¿‡æ»¤å™¨ä¿®æ­£ä¸å¯è¡ŒåŠ¨ä½œã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä»¿çœŸå’Œå®žéªŒå®¤çŽ¯å¢ƒä¸­éªŒè¯ï¼Œå®žçŽ°é«˜æ•ˆå®‰å…¨æŽ¢ç´¢ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Autonomous exploration of obstacle-rich spaces requires strategies that ensure efficiency while guaranteeing safety against collisions with obstacles. This paper investigates a novel platform-agnostic reinforcement learning framework that integrates a graph neural network-based policy for next-waypoint selection, with a safety filter ensuring safe mobility. Specifically, the neural network is trained using reinforcement learning through the Proximal Policy Optimization (PPO) algorithm to maximize exploration efficiency while minimizing safety filter interventions. Henceforth, when the policy proposes an infeasible action, the safety filter overrides it with the closest feasible alternative, ensuring consistent system behavior. In addition, this paper introduces a reward function shaped by a potential field that accounts for both the agent's proximity to unexplored regions and the expected information gain from reaching them. The proposed framework combines the adaptability of reinforcement learning-based exploration policies with the reliability provided by explicit safety mechanisms. This feature plays a key role in enabling the deployment of learning-based policies on robotic platforms operating in real-world environments. Extensive evaluations in both simulations and experiments performed in a lab environment demonstrate that the approach achieves efficient and safe exploration in cluttered spaces.

