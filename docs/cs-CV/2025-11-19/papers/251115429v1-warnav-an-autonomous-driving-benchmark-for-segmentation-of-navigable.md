---
layout: default
title: WarNav: An Autonomous Driving Benchmark for Segmentation of Navigable Zones in War Scenes
---

# WarNav: An Autonomous Driving Benchmark for Segmentation of Navigable Zones in War Scenes

**arXiv**: [2511.15429v1](https://arxiv.org/abs/2511.15429) | [PDF](https://arxiv.org/pdf/2511.15429.pdf)

**ä½œè€…**: Marc-Emmanuel Coupvent des Graviers, Hejer Ammar, Christophe Guettier, Yann Dumortier, Romaric Audigier

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWarNavæ•°æ®é›†ä»¥è§£å†³æˆ˜äº‰åœºæ™¯ä¸­è‡ªä¸»è½¦è¾†å¯¼èˆªåŒºåŸŸåˆ†å‰²é—®é¢˜**

**å…³é”®è¯**: `è¯­ä¹‰åˆ†å‰²` `è‡ªä¸»é©¾é©¶` `æˆ˜äº‰åœºæ™¯æ•°æ®é›†` `éžç»“æž„åŒ–çŽ¯å¢ƒ` `åŸºå‡†æµ‹è¯•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ•°æ®é›†æ— æ³•è¦†ç›–æˆ˜äº‰ç­‰é«˜é£Žé™©éžç»“æž„åŒ–çŽ¯å¢ƒï¼Œå¯¼è‡´è‡ªä¸»è½¦è¾†å¯¼èˆªæ¨¡åž‹é²æ£’æ€§ä¸è¶³
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå¼€æºDATTALIONå›¾åƒæž„å»ºçœŸå®žæ•°æ®é›†ï¼Œæ”¯æŒè¯­ä¹‰åˆ†å‰²æ¨¡åž‹å¼€å‘ä¸ŽåŸºå‡†æµ‹è¯•
3. å®žéªŒæˆ–æ•ˆæžœï¼šä½¿ç”¨åŸŽå¸‚åœºæ™¯é¢„è®­ç»ƒæ¨¡åž‹è¿›è¡ŒåŸºçº¿è¯„ä¼°ï¼Œåˆ†æžè®­ç»ƒæ•°æ®çŽ¯å¢ƒå½±å“ï¼ŒæŽ¢ç´¢æ— æ ‡æ³¨å›¾åƒå¯¼èˆªæ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce WarNav, a novel real-world dataset constructed from images of the open-source DATTALION repository, specifically tailored to enable the development and benchmarking of semantic segmentation models for autonomous ground vehicle navigation in unstructured, conflict-affected environments. This dataset addresses a critical gap between conventional urban driving resources and the unique operational scenarios encountered by unmanned systems in hazardous and damaged war-zones. We detail the methodological challenges encountered, ranging from data heterogeneity to ethical considerations, providing guidance for future efforts that target extreme operational contexts. To establish performance references, we report baseline results on WarNav using several state-of-the-art semantic segmentation models trained on structured urban scenes. We further analyse the impact of training data environments and propose a first step towards effective navigability in challenging environments with the constraint of having no annotation of the targeted images. Our goal is to foster impactful research that enhances the robustness and safety of autonomous vehicles in high-risk scenarios while being frugal in annotated data.

