---
layout: default
title: Insert In Style: A Zero-Shot Generative Framework for Harmonious Cross-Domain Object Composition
---

# Insert In Style: A Zero-Shot Generative Framework for Harmonious Cross-Domain Object Composition

**arXiv**: [2511.15197v1](https://arxiv.org/abs/2511.15197) | [PDF](https://arxiv.org/pdf/2511.15197.pdf)

**ä½œè€…**: Raghu Vamsi Chittersu, Yuvraj Singh Rathore, Pranav Adlinge, Kunal Swami

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé›¶æ ·æœ¬ç”Ÿæˆæ¡†æž¶Insert In Styleï¼Œè§£å†³çœŸå®žå¯¹è±¡æ’å…¥é£Žæ ¼åŒ–åŸŸæ—¶çš„å’Œè°ç»„åˆé—®é¢˜ã€‚**

**å…³é”®è¯**: `é›¶æ ·æœ¬ç”Ÿæˆ` `å¯¹è±¡ç»„åˆ` `é£Žæ ¼åŒ–åŸŸ` `è§£è€¦è¡¨ç¤º` `æŽ©ç æ³¨æ„åŠ›` `ç”Ÿæˆæ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•åœ¨çœŸå®žå¯¹è±¡æ’å…¥é£Žæ ¼åŒ–åŸŸæ—¶ï¼Œç¼ºä¹ç”Ÿæˆä¿çœŸåº¦æˆ–éœ€ä¸åˆ‡å®žé™…çš„åœ¨çº¿å¾®è°ƒã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å¤šé˜¶æ®µè®­ç»ƒåè®®å’ŒæŽ©ç æ³¨æ„åŠ›æž¶æž„ï¼Œå®žçŽ°èº«ä»½ã€é£Žæ ¼å’Œç»„åˆçš„è§£è€¦ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å…¬å…±åŸºå‡†ä¸Šå®žçŽ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œèº«ä»½å’Œé£Žæ ¼æŒ‡æ ‡æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reference-based object composition methods fail when inserting real-world objects into stylized domains. This under-explored problem is currently split between practical "blenders" that lack generative fidelity and "generators" that require impractical, per-subject online finetuning. In this work, we introduce Insert In Style, the first zero-shot generative framework that is both practical and high-fidelity. Our core contribution is a unified framework with two key innovations: (i) a novel multi-stage training protocol that disentangles representations for identity, style, and composition, and (ii) a specialized masked-attention architecture that surgically enforces this disentanglement during generation. This approach prevents the concept interference common in general-purpose, unified-attention models. Our framework is trained on a new 100k sample dataset, curated from a novel data pipeline. This pipeline couples large-scale generation with a rigorous, two-stage filtering process to ensure both high-fidelity semantic identity and style coherence. Unlike prior work, our model is truly zero-shot and requires no text prompts. We also introduce a new public benchmark for stylized composition. We demonstrate state-of-the-art performance, significantly outperforming existing methods on both identity and style metrics, a result strongly corroborated by user studies.

