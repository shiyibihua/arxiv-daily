---
layout: default
title: VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation
---

# VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation

**arXiv**: [2511.15200v1](https://arxiv.org/abs/2511.15200) | [PDF](https://arxiv.org/pdf/2511.15200.pdf)

**ä½œè€…**: Tairan He, Zi Wang, Haoru Xue, Qingwei Ben, Zhengyi Luo, Wenli Xiao, Ye Yuan, Xingye Da, Fernando CastaÃ±eda, Shankar Sastry, Changliu Liu, Guanya Shi, Linxi Fan, Yuke Zhu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVIRALè§†è§‰æ¨¡æ‹Ÿåˆ°çŽ°å®žæ¡†æž¶ï¼Œå®žçŽ°äººå½¢æœºå™¨äººé›¶æ ·æœ¬éƒ¨ç½²çš„è‡ªä¸»ç§»åŠ¨æ“ä½œ**

**å…³é”®è¯**: `äººå½¢æœºå™¨äºº` `æ¨¡æ‹Ÿåˆ°çŽ°å®ž` `è§†è§‰ç­–ç•¥` `å¸ˆç”Ÿè’¸é¦` `åŸŸéšæœºåŒ–` `ç§»åŠ¨æ“ä½œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šäººå½¢æœºå™¨äººç¼ºä¹è‡ªä¸»ç§»åŠ¨æ“ä½œæŠ€èƒ½ï¼Œé˜»ç¢çœŸå®žä¸–ç•Œéƒ¨ç½²ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å¸ˆç”Ÿè®¾è®¡ï¼Œç‰¹æƒå¼ºåŒ–å­¦ä¹ æ•™å¸ˆè’¸é¦è§†è§‰å­¦ç”Ÿç­–ç•¥ï¼Œç»“åˆå¤§è§„æ¨¡æ¨¡æ‹Ÿå’Œè§†è§‰åŸŸéšæœºåŒ–ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨Unitree G1äººå½¢æœºå™¨äººä¸Šå®žçŽ°è¿žç»­ç§»åŠ¨æ“ä½œï¼Œæ³›åŒ–æ€§å¼ºï¼Œæ— éœ€çœŸå®žä¸–ç•Œå¾®è°ƒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> A key barrier to the real-world deployment of humanoid robots is the lack of autonomous loco-manipulation skills. We introduce VIRAL, a visual sim-to-real framework that learns humanoid loco-manipulation entirely in simulation and deploys it zero-shot to real hardware. VIRAL follows a teacher-student design: a privileged RL teacher, operating on full state, learns long-horizon loco-manipulation using a delta action space and reference state initialization. A vision-based student policy is then distilled from the teacher via large-scale simulation with tiled rendering, trained with a mixture of online DAgger and behavior cloning. We find that compute scale is critical: scaling simulation to tens of GPUs (up to 64) makes both teacher and student training reliable, while low-compute regimes often fail. To bridge the sim-to-real gap, VIRAL combines large-scale visual domain randomization over lighting, materials, camera parameters, image quality, and sensor delays--with real-to-sim alignment of the dexterous hands and cameras. Deployed on a Unitree G1 humanoid, the resulting RGB-based policy performs continuous loco-manipulation for up to 54 cycles, generalizing to diverse spatial and appearance variations without any real-world fine-tuning, and approaching expert-level teleoperation performance. Extensive ablations dissect the key design choices required to make RGB-based humanoid loco-manipulation work in practice.

