---
layout: default
title: C2F-Space: Coarse-to-Fine Space Grounding for Spatial Instructions using Vision-Language Models
---

# C2F-Space: Coarse-to-Fine Space Grounding for Spatial Instructions using Vision-Language Models

**arXiv**: [2511.15333v1](https://arxiv.org/abs/2511.15333) | [PDF](https://arxiv.org/pdf/2511.15333.pdf)

**ä½œè€…**: Nayoung Oh, Dohyun Kim, Junhyeong Bang, Rohan Paul, Daehyung Park

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºC2F-Spaceæ¡†æž¶ä»¥è§£å†³ç©ºé—´æŒ‡ä»¤ä¸­å¤æ‚æŽ¨ç†ä¸Žç»†ç²’åº¦å®šä½é—®é¢˜**

**å…³é”®è¯**: `ç©ºé—´å®šä½` `è§†è§‰è¯­è¨€æ¨¡åž‹` `ç²—åˆ°ç»†æ¡†æž¶` `è¶…åƒç´ åŒ–` `æœºå™¨äººä»»åŠ¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿæ–¹æ³•éš¾ä»¥å¤„ç†ç©ºé—´æŒ‡ä»¤ä¸­çš„è·ç¦»ã€å‡ ä½•å’Œç‰©ä½“å…³ç³»æŽ¨ç†
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ç²—åˆ°ç»†ç­–ç•¥ï¼Œå…ˆä¼°è®¡ç²—ç•¥åŒºåŸŸå†é€šè¿‡è¶…åƒç´ åŒ–è¿›è¡Œå±€éƒ¨ç»†åŒ–
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ–°å»ºåŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºŽäº”ç§åŸºçº¿ï¼Œå¹¶éªŒè¯äº†æ¨¡å—æœ‰æ•ˆæ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Space grounding refers to localizing a set of spatial references described in natural language instructions. Traditional methods often fail to account for complex reasoning -- such as distance, geometry, and inter-object relationships -- while vision-language models (VLMs), despite strong reasoning abilities, struggle to produce a fine-grained region of outputs. To overcome these limitations, we propose C2F-Space, a novel coarse-to-fine space-grounding framework that (i) estimates an approximated yet spatially consistent region using a VLM, then (ii) refines the region to align with the local environment through superpixelization. For the coarse estimation, we design a grid-based visual-grounding prompt with a propose-validate strategy, maximizing VLM's spatial understanding and yielding physically and semantically valid canonical region (i.e., ellipses). For the refinement, we locally adapt the region to surrounding environment without over-relaxed to free space. We construct a new space-grounding benchmark and compare C2F-Space with five state-of-the-art baselines using success rate and intersection-over-union. Our C2F-Space significantly outperforms all baselines. Our ablation study confirms the effectiveness of each module in the two-step process and their synergistic effect of the combined framework. We finally demonstrate the applicability of C2F-Space to simulated robotic pick-and-place tasks.

