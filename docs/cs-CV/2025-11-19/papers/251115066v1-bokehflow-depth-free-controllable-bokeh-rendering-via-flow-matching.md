---
layout: default
title: BokehFlow: Depth-Free Controllable Bokeh Rendering via Flow Matching
---

# BokehFlow: Depth-Free Controllable Bokeh Rendering via Flow Matching

**arXiv**: [2511.15066v1](https://arxiv.org/abs/2511.15066) | [PDF](https://arxiv.org/pdf/2511.15066.pdf)

**ä½œè€…**: Yachuan Huang, Xianrui Luo, Qiwen Wang, Liao Shen, Jiaqi Li, Huiqiang Sun, Zihao Huang, Wei Jiang, Zhiguo Cao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBokehFlowæ¡†æž¶ï¼ŒåŸºäºŽæµåŒ¹é…å®žçŽ°æ— éœ€æ·±åº¦çš„å¯æŽ§æ•£æ™¯æ¸²æŸ“ã€‚**

**å…³é”®è¯**: `æ•£æ™¯æ¸²æŸ“` `æµåŒ¹é…` `å¯æŽ§ç”Ÿæˆ` `æ·±åº¦æ— å…³` `æ–‡æœ¬æŽ§åˆ¶` `å›¾åƒåˆæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰å¯æŽ§æ•£æ™¯æ¸²æŸ“æ–¹æ³•ä¾èµ–æ·±åº¦å›¾ï¼Œç¼ºä¹æ·±åº¦è¾“å…¥æ—¶éš¾ä»¥å®žçŽ°é«˜æ•ˆæŽ§åˆ¶ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æµåŒ¹é…å’Œäº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡æ–‡æœ¬æç¤ºæŽ§åˆ¶ç„¦ç‚¹åŒºåŸŸå’Œæ¨¡ç³Šå¼ºåº¦ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæ¸²æŸ“è´¨é‡å’Œæ•ˆçŽ‡ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå®žçŽ°é€¼çœŸæ•£æ™¯æ•ˆæžœã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Bokeh rendering simulates the shallow depth-of-field effect in photography, enhancing visual aesthetics and guiding viewer attention to regions of interest. Although recent approaches perform well, rendering controllable bokeh without additional depth inputs remains a significant challenge. Existing classical and neural controllable methods rely on accurate depth maps, while generative approaches often struggle with limited controllability and efficiency. In this paper, we propose BokehFlow, a depth-free framework for controllable bokeh rendering based on flow matching. BokehFlow directly synthesizes photorealistic bokeh effects from all-in-focus images, eliminating the need for depth inputs. It employs a cross-attention mechanism to enable semantic control over both focus regions and blur intensity via text prompts. To support training and evaluation, we collect and synthesize four datasets. Extensive experiments demonstrate that BokehFlow achieves visually compelling bokeh effects and offers precise control, outperforming existing depth-dependent and generative methods in both rendering quality and efficiency.

