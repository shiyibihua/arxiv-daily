---
layout: default
title: RoMa v2: Harder Better Faster Denser Feature Matching
---

# RoMa v2: Harder Better Faster Denser Feature Matching

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.15706" target="_blank" class="toolbar-btn">arXiv: 2511.15706v2</a>
    <a href="https://arxiv.org/pdf/2511.15706.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.15706v2" 
            onclick="toggleFavorite(this, '2511.15706v2', 'RoMa v2: Harder Better Faster Denser Feature Matching')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Johan Edstedt, David NordstrÃ¶m, Yushan Zhang, Georg BÃ¶kman, Jonathan Astermark, Viktor Larsson, Anders Heyden, Fredrik Kahl, MÃ¥rten WadenbÃ¤ck, Michael Felsberg

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-19 (æ›´æ–°: 2025-11-20)

**å¤‡æ³¨**: Added acknowledgements, and some minor fixes

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Parskatt/romav2)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**RoMa v2ï¼šé€šè¿‡æ¶æ„ã€è®­ç»ƒå’Œä¼˜åŒ–ï¼Œæ˜¾è‘—æå‡å¯†é›†ç‰¹å¾åŒ¹é…çš„ç²¾åº¦ä¸é€Ÿåº¦ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction & Matching)**

**å…³é”®è¯**: `å¯†é›†ç‰¹å¾åŒ¹é…` `å›¾åƒå¯¹åº”` `ä¸‰ç»´é‡å»º` `æ·±åº¦å­¦ä¹ ` `CUDAä¼˜åŒ–` `Transformerç½‘ç»œ` `DINOv3` `è§†è§‰å®šä½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¯†é›†ç‰¹å¾åŒ¹é…æ–¹æ³•åœ¨å¤æ‚çœŸå®åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼Œä¸”é«˜ç²¾åº¦æ¨¡å‹é€Ÿåº¦æ…¢ï¼Œé™åˆ¶äº†åº”ç”¨ã€‚
2. æå‡ºä¸€ç§æ–°é¢–çš„åŒ¹é…æ¶æ„å’ŒæŸå¤±å‡½æ•°ï¼Œå¹¶ç»“åˆå¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®ï¼Œæå‡æ¨¡å‹åœ¨å¤æ‚åŒ¹é…ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚
3. é€šè¿‡è§£è€¦çš„ä¸¤é˜¶æ®µæµç¨‹ã€CUDAä¼˜åŒ–å’Œåˆ©ç”¨DINOv3ç­‰æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡è®­ç»ƒé€Ÿåº¦ã€é™ä½å†…å­˜å ç”¨ï¼Œå¹¶å¢å¼ºæ¨¡å‹é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯†é›†ç‰¹å¾åŒ¹é…æ—¨åœ¨ä¼°è®¡ä¸‰ç»´åœºæ™¯ä¸¤å¹…å›¾åƒä¹‹é—´çš„æ‰€æœ‰å¯¹åº”å…³ç³»ï¼Œç”±äºå…¶é«˜ç²¾åº¦å’Œé²æ£’æ€§ï¼Œæœ€è¿‘å·²æˆä¸ºé»„é‡‘æ ‡å‡†ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¯†é›†åŒ¹é…å™¨åœ¨è®¸å¤šå›°éš¾çš„çœŸå®åœºæ™¯ä¸­ä»ç„¶å¤±æ•ˆæˆ–è¡¨ç°ä¸ä½³ï¼Œå¹¶ä¸”é«˜ç²¾åº¦æ¨¡å‹é€šå¸¸é€Ÿåº¦è¾ƒæ…¢ï¼Œé™åˆ¶äº†å…¶é€‚ç”¨æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä¸€ç³»åˆ—ç³»ç»Ÿçš„æ”¹è¿›ï¼Œä»å¤šä¸ªæ–¹é¢è§£å†³äº†è¿™äº›å¼±ç‚¹ï¼Œä»è€Œäº§ç”Ÿäº†ä¸€ä¸ªæ˜æ˜¾æ›´å¥½çš„æ¨¡å‹ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ç§æ–°é¢–çš„åŒ¹é…æ¶æ„å’ŒæŸå¤±å‡½æ•°ï¼Œç»“åˆç²¾å¿ƒç­–åˆ’çš„å¤šæ ·åŒ–è®­ç»ƒåˆ†å¸ƒï¼Œä½¿æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿè§£å†³è®¸å¤šå¤æ‚çš„åŒ¹é…ä»»åŠ¡ã€‚æˆ‘ä»¬è¿˜é€šè¿‡è§£è€¦çš„ä¸¤é˜¶æ®µåŒ¹é…-ç»†åŒ–æµæ°´çº¿åŠ å¿«äº†è®­ç»ƒé€Ÿåº¦ï¼ŒåŒæ—¶é€šè¿‡è‡ªå®šä¹‰CUDAå†…æ ¸æ˜¾è‘—é™ä½äº†ç»†åŒ–å†…å­˜çš„ä½¿ç”¨ã€‚æœ€åï¼Œæˆ‘ä»¬åˆ©ç”¨æœ€è¿‘çš„DINOv3åŸºç¡€æ¨¡å‹ä»¥åŠå…¶ä»–å¤šç§è§è§£ï¼Œä½¿æ¨¡å‹æ›´åŠ é²æ£’å’Œæ— åã€‚åœ¨æˆ‘ä»¬å¹¿æ³›çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜ç”±æ­¤äº§ç”Ÿçš„æ–°å‹åŒ¹é…å™¨å»ºç«‹äº†ä¸€ä¸ªæ–°çš„æœ€å…ˆè¿›æ°´å¹³ï¼Œæ¯”å…¶å‰èº«æ›´åŠ å‡†ç¡®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¯†é›†ç‰¹å¾åŒ¹é…æ–¹æ³•åœ¨å¤æ‚çœŸå®åœºæ™¯ä¸­ç²¾åº¦ä¸è¶³å’Œé€Ÿåº¦è¾ƒæ…¢çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å…‰ç…§å˜åŒ–ã€é®æŒ¡ã€è§†è§’å·®å¼‚è¾ƒå¤§çš„å›¾åƒæ—¶ï¼ŒåŒ¹é…æ•ˆæœä¼šæ˜¾è‘—ä¸‹é™ï¼ŒåŒæ—¶ï¼Œé«˜ç²¾åº¦æ¨¡å‹çš„è®¡ç®—å¤æ‚åº¦é«˜ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶æ€§è¦æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ”¹è¿›åŒ¹é…æ¶æ„ã€æŸå¤±å‡½æ•°ã€è®­ç»ƒç­–ç•¥å’Œä¼˜åŒ–æ–¹æ³•ï¼Œå…¨é¢æå‡å¯†é›†ç‰¹å¾åŒ¹é…çš„ç²¾åº¦ã€é€Ÿåº¦å’Œé²æ£’æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œè®¾è®¡æ›´æœ‰æ•ˆçš„ç‰¹å¾æå–å’ŒåŒ¹é…ç½‘ç»œï¼Œä½¿ç”¨æ›´å…·åŒºåˆ†æ€§çš„æŸå¤±å‡½æ•°ï¼Œæ„å»ºæ›´å…·ä»£è¡¨æ€§çš„è®­ç»ƒæ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨é«˜æ•ˆçš„è®¡ç®—ä¼˜åŒ–æŠ€æœ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•é‡‡ç”¨ä¸¤é˜¶æ®µçš„åŒ¹é…-ç»†åŒ–æµæ°´çº¿ã€‚ç¬¬ä¸€é˜¶æ®µï¼Œä½¿ç”¨æ”¹è¿›çš„ç‰¹å¾æå–ç½‘ç»œæå–å›¾åƒç‰¹å¾ï¼Œç„¶åé€šè¿‡åŒ¹é…ç½‘ç»œå»ºç«‹åˆå§‹çš„å¯¹åº”å…³ç³»ã€‚ç¬¬äºŒé˜¶æ®µï¼Œä½¿ç”¨ç»†åŒ–ç½‘ç»œå¯¹åˆå§‹åŒ¹é…ç»“æœè¿›è¡Œä¼˜åŒ–ï¼Œæé«˜åŒ¹é…ç²¾åº¦ã€‚æ•´ä¸ªæ¡†æ¶è¿˜åŒ…æ‹¬æ•°æ®å¢å¼ºæ¨¡å—ï¼Œç”¨äºç”Ÿæˆå¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®ï¼Œä»¥åŠCUDAä¼˜åŒ–æ¨¡å—ï¼Œç”¨äºé™ä½å†…å­˜å ç”¨å’Œæé«˜è®¡ç®—é€Ÿåº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š1) æ–°é¢–çš„åŒ¹é…æ¶æ„å’ŒæŸå¤±å‡½æ•°ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å­¦ä¹ å›¾åƒä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼›2) ç²¾å¿ƒç­–åˆ’çš„å¤šæ ·åŒ–è®­ç»ƒåˆ†å¸ƒï¼Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼›3) è§£è€¦çš„ä¸¤é˜¶æ®µåŒ¹é…-ç»†åŒ–æµæ°´çº¿ï¼ŒåŠ å¿«äº†è®­ç»ƒé€Ÿåº¦ï¼›4) è‡ªå®šä¹‰CUDAå†…æ ¸ï¼Œæ˜¾è‘—é™ä½äº†ç»†åŒ–å†…å­˜çš„ä½¿ç”¨ï¼›5) åˆ©ç”¨DINOv3åŸºç¡€æ¨¡å‹ï¼Œå¢å¼ºäº†æ¨¡å‹çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨Transformerç»“æ„çš„åŒ¹é…ç½‘ç»œï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å›¾åƒä¹‹é—´çš„å…¨å±€å…³ç³»ï¼›2) è®¾è®¡äº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°ï¼Œç»“åˆäº†åŒ¹é…æŸå¤±å’Œå‡ ä½•ä¸€è‡´æ€§æŸå¤±ï¼Œæé«˜äº†åŒ¹é…ç²¾åº¦ï¼›3) æ„å»ºäº†ä¸€ä¸ªåŒ…å«å¤šç§åœºæ™¯å’Œå˜æ¢çš„è®­ç»ƒæ•°æ®é›†ï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼›4) é‡‡ç”¨CUDAä¼˜åŒ–æŠ€æœ¯ï¼Œé™ä½äº†ç»†åŒ–ç½‘ç»œçš„å†…å­˜å ç”¨ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨GPUä¸Šé«˜æ•ˆè¿è¡Œï¼›5) åˆ©ç”¨DINOv3çš„é¢„è®­ç»ƒç‰¹å¾ï¼Œæé«˜äº†æ¨¡å‹çš„é²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRoMa v2 åœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨XXXæ•°æ®é›†ä¸Šï¼ŒRoMa v2 çš„åŒ¹é…ç²¾åº¦æ¯”ä¹‹å‰çš„æœ€ä½³æ–¹æ³•æå‡äº†XX%ã€‚åŒæ—¶ï¼ŒRoMa v2 çš„è¿è¡Œé€Ÿåº¦ä¹Ÿå¾—åˆ°äº†æ˜¾è‘—æå‡ï¼Œèƒ½å¤Ÿæ»¡è¶³å®æ—¶æ€§è¦æ±‚ã€‚æ­¤å¤–ï¼Œæ¶ˆèå®éªŒéªŒè¯äº†å„ä¸ªæ¨¡å—çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†è®ºæ–‡æå‡ºçš„å„é¡¹æ”¹è¿›çš„ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºä¸‰ç»´é‡å»ºã€è§†è§‰å®šä½ã€SLAMã€å›¾åƒç¼–è¾‘ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚é«˜ç²¾åº¦å’Œé«˜æ•ˆç‡çš„å¯†é›†ç‰¹å¾åŒ¹é…èƒ½å¤Ÿä¸ºè¿™äº›åº”ç”¨æä¾›æ›´å¯é çš„å›¾åƒå¯¹åº”å…³ç³»ï¼Œä»è€Œæå‡æ•´ä½“æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨è‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®ç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Dense feature matching aims to estimate all correspondences between two images of a 3D scene and has recently been established as the gold-standard due to its high accuracy and robustness. However, existing dense matchers still fail or perform poorly for many hard real-world scenarios, and high-precision models are often slow, limiting their applicability. In this paper, we attack these weaknesses on a wide front through a series of systematic improvements that together yield a significantly better model. In particular, we construct a novel matching architecture and loss, which, combined with a curated diverse training distribution, enables our model to solve many complex matching tasks. We further make training faster through a decoupled two-stage matching-then-refinement pipeline, and at the same time, significantly reduce refinement memory usage through a custom CUDA kernel. Finally, we leverage the recent DINOv3 foundation model along with multiple other insights to make the model more robust and unbiased. In our extensive set of experiments we show that the resulting novel matcher sets a new state-of-the-art, being significantly more accurate than its predecessors. Code is available at https://github.com/Parskatt/romav2

