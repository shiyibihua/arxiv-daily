---
layout: default
title: IPTQ-ViT: Post-Training Quantization of Non-linear Functions for Integer-only Vision Transformers
---

# IPTQ-ViT: Post-Training Quantization of Non-linear Functions for Integer-only Vision Transformers

**arXiv**: [2511.15369v1](https://arxiv.org/abs/2511.15369) | [PDF](https://arxiv.org/pdf/2511.15369.pdf)

**ä½œè€…**: Gihwan Kim, Jemin Lee, Hyungshin Kim

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIPTQ-ViTæ¡†æž¶ï¼Œå®žçŽ°æ— éœ€é‡è®­ç»ƒçš„æ•´æ•°åŒ–è§†è§‰Transformeré‡åŒ–**

**å…³é”®è¯**: `è§†è§‰Transformer` `åŽè®­ç»ƒé‡åŒ–` `æ•´æ•°æŽ¨ç†` `éžçº¿æ€§å‡½æ•°è¿‘ä¼¼` `å›¾åƒåˆ†ç±»` `ç›®æ ‡æ£€æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰PTQæ–¹æ³•æ— æ³•å®Œå…¨é‡åŒ–éžçº¿æ€§å‡½æ•°ï¼Œå¯¼è‡´æ•´æ•°æŽ¨ç†ä¸å®Œæ•´
2. å¼•å…¥å¤šé¡¹å¼GELUå’Œä½ç§»Softmaxè¿‘ä¼¼å‡½æ•°ï¼Œæå‡é‡åŒ–ç²¾åº¦
3. åœ¨å›¾åƒåˆ†ç±»å’Œæ£€æµ‹ä»»åŠ¡ä¸­ï¼Œç²¾åº¦ä¼˜äºŽå…¶ä»–PTQæ–¹æ³•ï¼ŒæŽ¥è¿‘QATæ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Previous Quantization-Aware Training (QAT) methods for vision transformers rely on expensive retraining to recover accuracy loss in non-linear layer quantization, limiting their use in resource-constrained environments. In contrast, existing Post-Training Quantization (PTQ) methods either partially quantize non-linear functions or adjust activation distributions to maintain accuracy but fail to achieve fully integer-only inference. In this paper, we introduce IPTQ-ViT, a novel PTQ framework for fully integer-only vision transformers without retraining. We present approximation functions: a polynomial-based GELU optimized for vision data and a bit-shifting-based Softmax designed to improve approximation accuracy in PTQ. In addition, we propose a unified metric integrating quantization sensitivity, perturbation, and computational cost to select the optimal approximation function per activation layer. IPTQ-ViT outperforms previous PTQ methods, achieving up to 6.44\%p (avg. 1.78\%p) top-1 accuracy improvement for image classification, 1.0 mAP for object detection. IPTQ-ViT outperforms partial floating-point PTQ methods under W8A8 and W4A8, and achieves accuracy and latency comparable to integer-only QAT methods. We plan to release our code https://github.com/gihwan-kim/IPTQ-ViT.git.

