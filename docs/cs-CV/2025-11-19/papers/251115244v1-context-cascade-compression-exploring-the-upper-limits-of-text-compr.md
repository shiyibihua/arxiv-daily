---
layout: default
title: Context Cascade Compression: Exploring the Upper Limits of Text Compression
---

# Context Cascade Compression: Exploring the Upper Limits of Text Compression

**arXiv**: [2511.15244v1](https://arxiv.org/abs/2511.15244) | [PDF](https://arxiv.org/pdf/2511.15244.pdf)

**ä½œè€…**: Fanfan Liu, Haibo Qiu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸Šä¸‹æ–‡çº§è”åŽ‹ç¼©ä»¥è§£å†³é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸­çš„è®¡ç®—ä¸Žå†…å­˜æŒ‘æˆ˜**

**å…³é”®è¯**: `æ–‡æœ¬åŽ‹ç¼©` `ä¸Šä¸‹æ–‡åŽ‹ç¼©` `çº§è”æ¨¡åž‹` `æ½œåœ¨ä»¤ç‰Œ` `è§£ç å‡†ç¡®çŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸­ç™¾ä¸‡çº§ä»¤ç‰Œè¾“å…¥å¯¼è‡´LLMè®¡ç®—ä¸Žå†…å­˜è´Ÿæ‹…é‡
2. çº§è”å¤§å°LLMè¿›è¡ŒåŽ‹ç¼©ä¸Žè§£ç ï¼Œå°æ¨¡åž‹åŽ‹ç¼©ä¸ºæ½œåœ¨ä»¤ç‰Œï¼Œå¤§æ¨¡åž‹è§£ç 
3. å®žéªŒæ˜¾ç¤º20å€åŽ‹ç¼©æ¯”ä¸‹è§£ç å‡†ç¡®çŽ‡è¾¾98%ï¼Œ40å€æ—¶ä¿æŒçº¦93%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Million-level token inputs in long-context tasks pose significant computational and memory challenges for Large Language Models (LLMs). Recently, DeepSeek-OCR conducted research into the feasibility of Contexts Optical Compression and achieved preliminary results. Inspired by this, we introduce Context Cascade Compression C3 to explore the upper limits of text compression. Our method cascades two LLMs of different sizes to handle the compression and decoding tasks. Specifically, a small LLM, acting as the first stage, performs text compression by condensing a long context into a set of latent tokens (e.g., 32 or 64 in length), achieving a high ratio of text tokens to latent tokens. A large LLM, as the second stage, then executes the decoding task on this compressed context. Experiments show that at a 20x compression ratio (where the number of text tokens is 20 times the number of latent tokens), our model achieves 98% decoding accuracy, compared to approximately 60% for DeepSeek-OCR. When we further increase the compression ratio to 40x, the accuracy is maintained at around 93%. This indicates that in the domain of context compression, C3 Compression demonstrates superior performance and feasibility over optical character compression. C3 uses a simpler, pure-text pipeline that ignores factors like layout, color, and information loss from a visual encoder. This also suggests a potential upper bound for compression ratios in future work on optical character compression, OCR, and related fields. Codes and model weights are publicly accessible at https://github.com/liufanfanlff/C3-Context-Cascade-Compression

