---
layout: default
title: Towards Unbiased Cross-Modal Representation Learning for Food Image-to-Recipe Retrieval
---

# Towards Unbiased Cross-Modal Representation Learning for Food Image-to-Recipe Retrieval

**arXiv**: [2511.15201v1](https://arxiv.org/abs/2511.15201) | [PDF](https://arxiv.org/pdf/2511.15201.pdf)

**ä½œè€…**: Qing Wang, Chong-Wah Ngo, Ee-Peng Lim

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå› æžœå¹²é¢„æ–¹æ³•ä»¥è§£å†³é£Ÿç‰©å›¾åƒ-é£Ÿè°±æ£€ç´¢ä¸­çš„è¡¨ç¤ºå­¦ä¹ åå·®é—®é¢˜**

**å…³é”®è¯**: `è·¨æ¨¡æ€æ£€ç´¢` `è¡¨ç¤ºå­¦ä¹ ` `å› æžœå¹²é¢„` `é£Ÿç‰©å›¾åƒ` `é£Ÿè°±æ£€ç´¢` `åå·®æ¶ˆé™¤`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•å°†é£Ÿè°±è§†ä¸ºå›¾åƒæè¿°ï¼Œå¿½ç•¥çƒ¹é¥ªå’Œæ‹æ‘„å› ç´ å¯¼è‡´çš„åå·®
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå› æžœç†è®ºå»ºæ¨¡åå·®ï¼Œä½¿ç”¨åŽé—¨è°ƒæ•´è¿›è¡Œå¹²é¢„ä»¥æ¶ˆé™¤åå·®
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Recipe1Mæ•°æ®é›†ä¸Šå®žçŽ°MedR=1ï¼Œå¹¶æŠ¥å‘Šæ–°SOTAæ£€ç´¢æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper addresses the challenges of learning representations for recipes and food images in the cross-modal retrieval problem. As the relationship between a recipe and its cooked dish is cause-and-effect, treating a recipe as a text source describing the visual appearance of a dish for learning representation, as the existing approaches, will create bias misleading image-and-recipe similarity judgment. Specifically, a food image may not equally capture every detail in a recipe, due to factors such as the cooking process, dish presentation, and image-capturing conditions. The current representation learning tends to capture dominant visual-text alignment while overlooking subtle variations that determine retrieval relevance. In this paper, we model such bias in cross-modal representation learning using causal theory. The causal view of this problem suggests ingredients as one of the confounder sources and a simple backdoor adjustment can alleviate the bias. By causal intervention, we reformulate the conventional model for food-to-recipe retrieval with an additional term to remove the potential bias in similarity judgment. Based on this theory-informed formulation, we empirically prove the oracle performance of retrieval on the Recipe1M dataset to be MedR=1 across the testing data sizes of 1K, 10K, and even 50K. We also propose a plug-and-play neural module, which is essentially a multi-label ingredient classifier for debiasing. New state-of-the-art search performances are reported on the Recipe1M dataset.

