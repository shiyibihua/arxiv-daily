---
layout: default
title: SIGMMA: Hierarchical Graph-Based Multi-Scale Multi-modal Contrastive Alignment of Histopathology Image and Spatial Transcriptome
---

# SIGMMA: Hierarchical Graph-Based Multi-Scale Multi-modal Contrastive Alignment of Histopathology Image and Spatial Transcriptome

**arXiv**: [2511.15464v1](https://arxiv.org/abs/2511.15464) | [PDF](https://arxiv.org/pdf/2511.15464.pdf)

**ä½œè€…**: Dabin Jeong, Amirhossein Vahidi, Ciro RamÃ­rez-SuÃ¡stegui, Marie Moullet, Kevin Ly, Mohammad Vali Sanian, Sebastian Birk, Yinshui Chang, Adam Boxall, Daniyal Jafree, Lloyd Steele, Vijaya Baskar MS, Muzlifah Haniffa, Mohammad Lotfollahi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSIGMMAæ¡†æž¶ä»¥è§£å†³ç»„ç»‡ç—…ç†å›¾åƒä¸Žç©ºé—´è½¬å½•ç»„å¤šå°ºåº¦å¯¹é½é—®é¢˜**

**å…³é”®è¯**: `è®¡ç®—ç—…ç†å­¦` `å¤šæ¨¡æ€å¯¹é½` `å›¾ç¥žç»ç½‘ç»œ` `å¯¹æ¯”å­¦ä¹ ` `ç©ºé—´è½¬å½•ç»„å­¦` `å¤šå°ºåº¦è¡¨ç¤º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨å•å°ºåº¦å¯¹é½HEå›¾åƒä¸ŽSTè°±ï¼Œå¿½ç•¥ç»†èƒžç»“æž„å±‚æ¬¡
2. SIGMMAé€šè¿‡å¤šå°ºåº¦å¯¹æ¯”å¯¹é½å’Œå›¾ç»“æž„å»ºæ¨¡ç»†èƒžäº¤äº’
3. å®žéªŒæ˜¾ç¤ºåœ¨åŸºå› é¢„æµ‹å’Œè·¨æ¨¡æ€æ£€ç´¢ä»»åŠ¡ä¸­æ€§èƒ½æ˜¾è‘—æå‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in computational pathology have leveraged vision-language models to learn joint representations of Hematoxylin and Eosin (HE) images with spatial transcriptomic (ST) profiles. However, existing approaches typically align HE tiles with their corresponding ST profiles at a single scale, overlooking fine-grained cellular structures and their spatial organization. To address this, we propose Sigmma, a multi-modal contrastive alignment framework for learning hierarchical representations of HE images and spatial transcriptome profiles across multiple scales. Sigmma introduces multi-scale contrastive alignment, ensuring that representations learned at different scales remain coherent across modalities. Furthermore, by representing cell interactions as a graph and integrating inter- and intra-subgraph relationships, our approach effectively captures cell-cell interactions, ranging from fine to coarse, within the tissue microenvironment. We demonstrate that Sigmm learns representations that better capture cross-modal correspondences, leading to an improvement of avg. 9.78\% in the gene-expression prediction task and avg. 26.93\% in the cross-modal retrieval task across datasets. We further show that it learns meaningful multi-tissue organization in downstream analyses.

