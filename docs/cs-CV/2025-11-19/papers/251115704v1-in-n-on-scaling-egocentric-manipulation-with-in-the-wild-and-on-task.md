---
layout: default
title: In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data
---

# In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data

**arXiv**: [2511.15704v1](https://arxiv.org/abs/2511.15704) | [PDF](https://arxiv.org/pdf/2511.15704.pdf)

**ä½œè€…**: Xiongyi Cai, Ri-Zhao Qiu, Geng Chen, Lai Wei, Isabella Liu, Tianshu Huang, Xuxin Cheng, Xiaolong Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIn-N-Onæ–¹æ³•ï¼Œåˆ©ç”¨é‡Žå¤–å’Œä»»åŠ¡æ•°æ®æ‰©å±•è‡ªæˆ‘ä¸­å¿ƒæ“ä½œç­–ç•¥å­¦ä¹ **

**å…³é”®è¯**: `è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘` `æ“ä½œç­–ç•¥å­¦ä¹ ` `æ•°æ®åˆ†ç±»` `æµåŒ¹é…` `é¢†åŸŸé€‚åº”` `è¯­è¨€æ¡ä»¶ç­–ç•¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‡ªæˆ‘ä¸­å¿ƒè§†é¢‘æ•°æ®å¼‚æž„æ€§é«˜ï¼ŒçŽ°æœ‰æ–¹æ³•æœªå……åˆ†åˆ©ç”¨å…¶æ½œåŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ†ç±»æ•°æ®ä¸ºé‡Žå¤–å’Œä»»åŠ¡åž‹ï¼Œæž„å»ºPHSDæ•°æ®é›†å¹¶è®­ç»ƒè¯­è¨€æ¡ä»¶æµåŒ¹é…ç­–ç•¥ã€‚
3. å®žéªŒæ•ˆæžœï¼šHuman0ç­–ç•¥å®žçŽ°è¯­è¨€æŒ‡ä»¤è·Ÿéšã€å°‘æ ·æœ¬å­¦ä¹ å’Œé²æ£’æ€§æå‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Egocentric videos are a valuable and scalable data source to learn manipulation policies. However, due to significant data heterogeneity, most existing approaches utilize human data for simple pre-training, which does not unlock its full potential. This paper first provides a scalable recipe for collecting and using egocentric data by categorizing human data into two categories: in-the-wild and on-task alongside with systematic analysis on how to use the data. We first curate a dataset, PHSD, which contains over 1,000 hours of diverse in-the-wild egocentric data and over 20 hours of on-task data directly aligned to the target manipulation tasks. This enables learning a large egocentric language-conditioned flow matching policy, Human0. With domain adaptation techniques, Human0 minimizes the gap between humans and humanoids. Empirically, we show Human0 achieves several novel properties from scaling human data, including language following of instructions from only human data, few-shot learning, and improved robustness using on-task data. Project website: https://xiongyicai.github.io/In-N-On/

