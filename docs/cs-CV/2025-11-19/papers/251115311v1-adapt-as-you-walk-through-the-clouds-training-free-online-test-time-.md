---
layout: default
title: Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models
---

# Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models

**arXiv**: [2511.15311v1](https://arxiv.org/abs/2511.15311) | [PDF](https://arxiv.org/pdf/2511.15311.pdf)

**ä½œè€…**: Mehran Tamjidi, Hamidreza Dastmalchi, Mohammadreza Alimoradijazi, Ali Cheraghian, Aijun An, Morteza Saberi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUni-Adapterä»¥è§£å†³3Dè§†è§‰è¯­è¨€åŸºç¡€æ¨¡åž‹åœ¨åˆ†å¸ƒåç§»ä¸‹çš„æ€§èƒ½ä¸‹é™é—®é¢˜**

**å…³é”®è¯**: `3Dè§†è§‰è¯­è¨€åŸºç¡€æ¨¡åž‹` `æµ‹è¯•æ—¶é€‚åº”` `åŠ¨æ€åŽŸåž‹å­¦ä¹ ` `å›¾æ ‡ç­¾å¹³æ»‘` `å…è®­ç»ƒé€‚åº”` `åˆ†å¸ƒåç§»ç¼“è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼š3Dè§†è§‰è¯­è¨€åŸºç¡€æ¨¡åž‹åœ¨å™ªå£°ã€ä¸å®Œæ•´æˆ–åˆ†å¸ƒå¤–æ•°æ®ä¸­æ€§èƒ½ä¸‹é™
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽåŠ¨æ€åŽŸåž‹å­¦ä¹ å’Œå›¾æ ‡ç­¾å¹³æ»‘ï¼Œå®žçŽ°å…è®­ç»ƒåœ¨çº¿æµ‹è¯•æ—¶é€‚åº”
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ª3DåŸºå‡†ä¸Šæ˜¾è‘—æå‡æ€§èƒ½ï¼Œå¦‚ModelNet-40Cæé«˜10.55%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> 3D Vision-Language Foundation Models (VLFMs) have shown strong generalization and zero-shot recognition capabilities in open-world point cloud processing tasks. However, these models often underperform in practical scenarios where data are noisy, incomplete, or drawn from a different distribution than the training data. To address this, we propose Uni-Adapter, a novel training-free online test-time adaptation (TTA) strategy for 3D VLFMs based on dynamic prototype learning. We define a 3D cache to store class-specific cluster centers as prototypes, which are continuously updated to capture intra-class variability in heterogeneous data distributions. These dynamic prototypes serve as anchors for cache-based logit computation via similarity scoring. Simultaneously, a graph-based label smoothing module captures inter-prototype similarities to enforce label consistency among similar prototypes. Finally, we unify predictions from the original 3D VLFM and the refined 3D cache using entropy-weighted aggregation for reliable adaptation. Without retraining, Uni-Adapter effectively mitigates distribution shifts, achieving state-of-the-art performance on diverse 3D benchmarks over different 3D VLFMs, improving ModelNet-40C by 10.55%, ScanObjectNN-C by 8.26%, and ShapeNet-C by 4.49% over the source 3D VLFMs.

