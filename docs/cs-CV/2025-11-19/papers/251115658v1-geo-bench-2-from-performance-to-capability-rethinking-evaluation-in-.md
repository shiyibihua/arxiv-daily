---
layout: default
title: GEO-Bench-2: From Performance to Capability, Rethinking Evaluation in Geospatial AI
---

# GEO-Bench-2: From Performance to Capability, Rethinking Evaluation in Geospatial AI

**arXiv**: [2511.15658v1](https://arxiv.org/abs/2511.15658) | [PDF](https://arxiv.org/pdf/2511.15658.pdf)

**ä½œè€…**: Naomi Simumba, Nils Lehmann, Paolo Fraccaro, Hamed Alemohammad, Geeth De Mel, Salman Khan, Manil Maskey, Nicolas Longepe, Xiao Xiang Zhu, Hannah Kerner, Juan Bernabe-Moreno, Alexander Lacoste

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGEO-Bench-2è¯„ä¼°æ¡†æž¶ä»¥è§£å†³åœ°ç†ç©ºé—´AIä¸­æ ‡å‡†åŒ–è¯„ä¼°ç¼ºå¤±é—®é¢˜**

**å…³é”®è¯**: `åœ°ç†ç©ºé—´åŸºç¡€æ¨¡åž‹` `æ ‡å‡†åŒ–è¯„ä¼°` `å¤šä»»åŠ¡åŸºå‡†` `èƒ½åŠ›åˆ†ç»„` `æ¨¡åž‹æ¯”è¾ƒ` `åœ°çƒè§‚æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåœ°ç†ç©ºé—´åŸºç¡€æ¨¡åž‹ç¼ºä¹ç»Ÿä¸€è¯„ä¼°æ ‡å‡†ï¼Œå½±å“å…¬å¹³æ¯”è¾ƒå’Œæ–¹æ³•åˆ›æ–°ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥èƒ½åŠ›åˆ†ç»„å’Œçµæ´»è¯„ä¼°åè®®ï¼Œè¦†ç›–å¤šä»»åŠ¡å’Œå¤šæ•°æ®é›†ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒæ˜¾ç¤ºæ— å•ä¸€æ¨¡åž‹ä¸»å¯¼æ‰€æœ‰ä»»åŠ¡ï¼Œå¼ºè°ƒä»»åŠ¡ç‰¹å®šæ¨¡åž‹é€‰æ‹©ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Geospatial Foundation Models (GeoFMs) are transforming Earth Observation (EO), but evaluation lacks standardized protocols. GEO-Bench-2 addresses this with a comprehensive framework spanning classification, segmentation, regression, object detection, and instance segmentation across 19 permissively-licensed datasets. We introduce ''capability'' groups to rank models on datasets that share common characteristics (e.g., resolution, bands, temporality). This enables users to identify which models excel in each capability and determine which areas need improvement in future work. To support both fair comparison and methodological innovation, we define a prescriptive yet flexible evaluation protocol. This not only ensures consistency in benchmarking but also facilitates research into model adaptation strategies, a key and open challenge in advancing GeoFMs for downstream tasks.
>   Our experiments show that no single model dominates across all tasks, confirming the specificity of the choices made during architecture design and pretraining. While models pretrained on natural images (ConvNext ImageNet, DINO V3) excel on high-resolution tasks, EO-specific models (TerraMind, Prithvi, and Clay) outperform them on multispectral applications such as agriculture and disaster response. These findings demonstrate that optimal model choice depends on task requirements, data modalities, and constraints. This shows that the goal of a single GeoFM model that performs well across all tasks remains open for future research. GEO-Bench-2 enables informed, reproducible GeoFM evaluation tailored to specific use cases. Code, data, and leaderboard for GEO-Bench-2 are publicly released under a permissive license.

