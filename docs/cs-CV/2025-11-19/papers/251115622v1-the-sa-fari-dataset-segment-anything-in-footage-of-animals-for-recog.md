---
layout: default
title: The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification
---

# The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification

**arXiv**: [2511.15622v1](https://arxiv.org/abs/2511.15622) | [PDF](https://arxiv.org/pdf/2511.15622.pdf)

**ä½œè€…**: Dante Francisco Wasmuht, Otto Brookes, Maximillian Schall, Pablo Palencia, Chris Beirne, Tilo Burghardt, Majid Mirmehdi, Hjalmar KÃ¼hl, Mimi Arandjelovic, Sam Pottie, Peter Bermant, Brandon Asheim, Yi Jin Toh, Adam Elzinga, Jason Holmberg, Andrew Whitworth, Eleanor Flatt, Laura Gustafson, Chaitanya Ryali, Yuan-Ting Hu, Baishan Guo, Andrew Westbury, Kate Saenko, Didac Suris

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSA-FARIæ•°æ®é›†ä»¥è§£å†³é‡Žç”ŸåŠ¨ç‰©å¤šåŠ¨ç‰©è¿½è¸ªåŸºå‡†ç¼ºå¤±é—®é¢˜**

**å…³é”®è¯**: `å¤šåŠ¨ç‰©è¿½è¸ª` `é‡Žç”ŸåŠ¨ç‰©æ•°æ®é›†` `åˆ†å‰²æŽ©ç ` `ç‰©ç§è¯†åˆ«` `åŸºå‡†æµ‹è¯•` `è®¡ç®—æœºè§†è§‰`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ•°æ®é›†è§„æ¨¡å°ã€ç‰©ç§å°‘ï¼Œç¼ºä¹æ—¶ç©ºå¤šæ ·æ€§ï¼Œæ— æ³•è®­ç»ƒé€šç”¨å¤šåŠ¨ç‰©è¿½è¸ªæ¨¡åž‹
2. SA-FARIåŒ…å«11,609ä¸ªè§†é¢‘ï¼Œè¦†ç›–99ä¸ªç‰©ç§ï¼Œæä¾›å¯†é›†è¾¹ç•Œæ¡†ã€åˆ†å‰²æŽ©ç å’Œç‰©ç§æ ‡æ³¨
3. ä½¿ç”¨SAM 3ç­‰æ¨¡åž‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œè¯„ä¼°ç‰©ç§ç‰¹å®šå’Œé€šç”¨åŠ¨ç‰©æç¤ºä¸‹çš„æ£€æµ‹ä¸Žè¿½è¸ªæ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Automated video analysis is critical for wildlife conservation. A foundational task in this domain is multi-animal tracking (MAT), which underpins applications such as individual re-identification and behavior recognition. However, existing datasets are limited in scale, constrained to a few species, or lack sufficient temporal and geographical diversity - leaving no suitable benchmark for training general-purpose MAT models applicable across wild animal populations. To address this, we introduce SA-FARI, the largest open-source MAT dataset for wild animals. It comprises 11,609 camera trap videos collected over approximately 10 years (2014-2024) from 741 locations across 4 continents, spanning 99 species categories. Each video is exhaustively annotated culminating in ~46 hours of densely annotated footage containing 16,224 masklet identities and 942,702 individual bounding boxes, segmentation masks, and species labels. Alongside the task-specific annotations, we publish anonymized camera trap locations for each video. Finally, we present comprehensive benchmarks on SA-FARI using state-of-the-art vision-language models for detection and tracking, including SAM 3, evaluated with both species-specific and generic animal prompts. We also compare against vision-only methods developed specifically for wildlife analysis. SA-FARI is the first large-scale dataset to combine high species diversity, multi-region coverage, and high-quality spatio-temporal annotations, offering a new foundation for advancing generalizable multianimal tracking in the wild. The dataset is available at $\href{https://www.conservationxlabs.com/sa-fari}{\text{conservationxlabs.com/SA-FARI}}$.

