---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-11-19
---

# cs.CVï¼ˆ2025-11-19ï¼‰

ğŸ“Š å…± **21** ç¯‡è®ºæ–‡
 | ğŸ”— **4** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (7 ğŸ”—3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (7)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (5)</a>
<a href="#æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction" class="interest-badge">æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction-matching" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction & Matching) (1 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (7 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251115102v1-gaussian-blending-rethinking-alpha-blending-in-3d-gaussian-splatting.html">Gaussian Blending: Rethinking Alpha Blending in 3D Gaussian Splatting</a></td>
  <td>æå‡ºé«˜æ–¯æ··åˆï¼šé‡æ–°æ€è€ƒ3Dé«˜æ–¯æº…å°„ä¸­çš„Alphaæ··åˆï¼Œæå‡æ–°è§†è§’åˆæˆè´¨é‡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15102v1" onclick="toggleFavorite(this, '2511.15102v1', 'Gaussian Blending: Rethinking Alpha Blending in 3D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251115874v1-waldo-where-unseen-model-based-6d-pose-estimation-meets-occlusion.html">WALDO: Where Unseen Model-based 6D Pose Estimation Meets Occlusion</a></td>
  <td>WALDOï¼šæå‡ºä¸€ç§æ–°é¢–çš„åŸºäºæ¨¡å‹çš„6Dä½å§¿ä¼°è®¡æ–¹æ³•ï¼Œæå‡é®æŒ¡åœºæ™¯ä¸‹çš„é²æ£’æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15874v1" onclick="toggleFavorite(this, '2511.15874v1', 'WALDO: Where Unseen Model-based 6D Pose Estimation Meets Occlusion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251115153v1-sceneedited-a-city-scale-benchmark-for-3d-hd-map-updating-via-image-.html">SceneEdited: A City-Scale Benchmark for 3D HD Map Updating via Image-Guided Change Detection</a></td>
  <td>SceneEditedï¼šæå‡ºåŸå¸‚çº§3Dé«˜æ¸…åœ°å›¾æ›´æ–°åŸºå‡†ï¼Œé€šè¿‡å›¾åƒå¼•å¯¼çš„å˜æ›´æ£€æµ‹ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15153v1" onclick="toggleFavorite(this, '2511.15153v1', 'SceneEdited: A City-Scale Benchmark for 3D HD Map Updating via Image-Guided Change Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251115567v1-computer-use-agents-as-judges-for-generative-user-interface.html">Computer-Use Agents as Judges for Generative User Interface</a></td>
  <td>æå‡ºCoder-CUAååŒæ¡†æ¶ï¼Œåˆ©ç”¨è®¡ç®—æœºä»£ç†è¾…åŠ©ä»£ç ç”ŸæˆGUIçš„è®¾è®¡ï¼Œæå‡ä»»åŠ¡è§£å†³èƒ½åŠ›ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15567v1" onclick="toggleFavorite(this, '2511.15567v1', 'Computer-Use Agents as Judges for Generative User Interface')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251115396v1-shelfocc-native-3d-supervision-beyond-lidar-for-vision-based-occupan.html">ShelfOcc: Native 3D Supervision beyond LiDAR for Vision-Based Occupancy Estimation</a></td>
  <td>ShelfOccï¼šæå‡ºä¸€ç§çº¯è§†è§‰çš„3Dä½“ç´ å æ®ä¼°è®¡æ–¹æ³•ï¼Œæ— éœ€æ¿€å…‰é›·è¾¾å³å¯å®ç°åŸç”Ÿ3Dç›‘ç£ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15396v1" onclick="toggleFavorite(this, '2511.15396v1', 'ShelfOcc: Native 3D Supervision beyond LiDAR for Vision-Based Occupancy Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251115311v2-adapt-as-you-walk-through-the-clouds-training-free-online-test-time-.html">Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models</a></td>
  <td>æå‡ºUni-Adapterï¼Œä¸€ç§å…è®­ç»ƒçš„3Dè§†è§‰-è¯­è¨€æ¨¡å‹åœ¨çº¿æµ‹è¯•æ—¶è‡ªé€‚åº”æ–¹æ³•ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15311v2" onclick="toggleFavorite(this, '2511.15311v2', 'Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251115090v1-bbox-docvqa-a-large-scale-bounding-box-grounded-dataset-for-enhancin.html">BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning in Document Visual Question Answer</a></td>
  <td>æå‡ºBBox DocVQAæ•°æ®é›†ï¼Œå¢å¼ºæ–‡æ¡£è§†è§‰é—®ç­”ä¸­ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15090v1" onclick="toggleFavorite(this, '2511.15090v1', 'BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning in Document Visual Question Answer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (7 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>8</td>
  <td><a href="./papers/251115308v1-text2loc-generalizing-3d-point-cloud-localization-from-natural-langu.html">Text2Loc++: Generalizing 3D Point Cloud Localization from Natural Language</a></td>
  <td>Text2Loc++ï¼šæå‡ºä¸€ç§åŸºäºè‡ªç„¶è¯­è¨€çš„é€šç”¨3Dç‚¹äº‘å®šä½æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15308v1" onclick="toggleFavorite(this, '2511.15308v1', 'Text2Loc++: Generalizing 3D Point Cloud Localization from Natural Language')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251115077v1-mambatrack3d-a-state-space-model-framework-for-lidar-based-object-tr.html">MambaTrack3D: A State Space Model Framework for LiDAR-Based Object Tracking under High Temporal Variation</a></td>
  <td>MambaTrack3Dï¼šåŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹çš„LiDARé«˜æ—¶é—´å˜åŒ–ç›®æ ‡è·Ÿè¸ªæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15077v1" onclick="toggleFavorite(this, '2511.15077v1', 'MambaTrack3D: A State Space Model Framework for LiDAR-Based Object Tracking under High Temporal Variation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251115167v1-learning-depth-from-past-selves-self-evolution-contrast-for-robust-d.html">Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation</a></td>
  <td>æå‡ºè‡ªè¿›åŒ–å¯¹æ¯”å­¦ä¹ æ¡†æ¶SEC-Depthï¼Œæå‡æ¶åŠ£å¤©æ°”ä¸‹è‡ªç›‘ç£æ·±åº¦ä¼°è®¡çš„é²æ£’æ€§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15167v1" onclick="toggleFavorite(this, '2511.15167v1', 'Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251115645v1-mambaio-global-coordinate-inertial-odometry-for-pedestrians-via-mult.html">MambaIO: Global-Coordinate Inertial Odometry for Pedestrians via Multi-Scale Frequency-Decoupled Modeling</a></td>
  <td>MambaIOï¼šé¢å‘è¡Œäººæƒ¯æ€§é‡Œç¨‹è®¡çš„å¤šå°ºåº¦è§£è€¦å»ºæ¨¡æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15645v1" onclick="toggleFavorite(this, '2511.15645v1', 'MambaIO: Global-Coordinate Inertial Odometry for Pedestrians via Multi-Scale Frequency-Decoupled Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251115256v1-grpo-rm-fine-tuning-representation-models-via-grpo-driven-reinforcem.html">GRPO-RM: Fine-Tuning Representation Models via GRPO-Driven Reinforcement Learning</a></td>
  <td>æå‡ºGRPO-RMï¼Œé€šè¿‡GRPOé©±åŠ¨çš„å¼ºåŒ–å­¦ä¹ å¾®è°ƒè¡¨å¾æ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15256v1" onclick="toggleFavorite(this, '2511.15256v1', 'GRPO-RM: Fine-Tuning Representation Models via GRPO-Driven Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251115201v1-towards-unbiased-cross-modal-representation-learning-for-food-image-.html">Towards Unbiased Cross-Modal Representation Learning for Food Image-to-Recipe Retrieval</a></td>
  <td>æå‡ºåŸºäºå› æœæ¨æ–­çš„è§£åæ–¹æ³•ï¼Œæå‡é£Ÿç‰©å›¾åƒ-èœè°±è·¨æ¨¡æ€æ£€ç´¢æ€§èƒ½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15201v1" onclick="toggleFavorite(this, '2511.15201v1', 'Towards Unbiased Cross-Modal Representation Learning for Food Image-to-Recipe Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251115066v1-bokehflow-depth-free-controllable-bokeh-rendering-via-flow-matching.html">BokehFlow: Depth-Free Controllable Bokeh Rendering via Flow Matching</a></td>
  <td>æå‡ºBokehFlowï¼Œä¸€ç§åŸºäºFlow Matchingçš„æ— æ·±åº¦ä¿¡æ¯å¯æ§ç„¦å¤–æˆåƒæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15066v1" onclick="toggleFavorite(this, '2511.15066v1', 'BokehFlow: Depth-Free Controllable Bokeh Rendering via Flow Matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>15</td>
  <td><a href="./papers/251115705v1-geovista-web-augmented-agentic-visual-reasoning-for-geolocalization.html">GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization</a></td>
  <td>æå‡ºGeoVistaï¼Œä¸€ä¸ªåŸºäºWebå¢å¼ºçš„Agenticè§†è§‰æ¨ç†æ¨¡å‹ï¼Œç”¨äºåœ°ç†å®šä½ä»»åŠ¡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15705v1" onclick="toggleFavorite(this, '2511.15705v1', 'GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251115884v1-box6d-zero-shot-category-level-6d-pose-estimation-of-warehouse-boxes.html">Box6D : Zero-shot Category-level 6D Pose Estimation of Warehouse Boxes</a></td>
  <td>Box6Dï¼šé¢å‘ä»“åº“ç®±ä½“çš„é›¶æ ·æœ¬ç±»åˆ«çº§6Dä½å§¿ä¼°è®¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15884v1" onclick="toggleFavorite(this, '2511.15884v1', 'Box6D : Zero-shot Category-level 6D Pose Estimation of Warehouse Boxes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251115580v3-comptrack-information-bottleneck-guided-low-rank-dynamic-token-compr.html">CompTrack: Information Bottleneck-Guided Low-Rank Dynamic Token Compression for Point Cloud Tracking</a></td>
  <td>CompTrackï¼šä¿¡æ¯ç“¶é¢ˆå¼•å¯¼çš„ä½ç§©åŠ¨æ€Tokenå‹ç¼©ï¼Œç”¨äºç‚¹äº‘å•ç›®æ ‡è·Ÿè¸ªã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15580v3" onclick="toggleFavorite(this, '2511.15580v3', 'CompTrack: Information Bottleneck-Guided Low-Rank Dynamic Token Compression for Point Cloud Tracking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251115351v2-octopus-agentic-multimodal-reasoning-with-six-capability-orchestrati.html">Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration</a></td>
  <td>Octopusï¼šåŸºäºå…­å¤§èƒ½åŠ›ç¼–æ’çš„Agenticå¤šæ¨¡æ€æ¨ç†æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15351v2" onclick="toggleFavorite(this, '2511.15351v2', 'Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251115322v1-adaptive-thresholding-pattern-for-fingerprint-forgery-detection.html">Adaptive thresholding pattern for fingerprint forgery detection</a></td>
  <td>æå‡ºåŸºäºè‡ªé€‚åº”é˜ˆå€¼æ¨¡å¼çš„æŒ‡çº¹ä¼ªé€ æ£€æµ‹ç®—æ³•ï¼Œæå‡æŠ—å¹²æ‰°èƒ½åŠ›ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15322v1" onclick="toggleFavorite(this, '2511.15322v1', 'Adaptive thresholding pattern for fingerprint forgery detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction">ğŸ”¬ æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>20</td>
  <td><a href="./papers/251115046v1-unihoi-unified-human-object-interaction-understanding-via-unified-to.html">UniHOI: Unified Human-Object Interaction Understanding via Unified Token Space</a></td>
  <td>UniHOIï¼šé€šè¿‡ç»Ÿä¸€Tokenç©ºé—´å®ç°ç»Ÿä¸€çš„äºº-ç‰©äº¤äº’ç†è§£</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15046v1" onclick="toggleFavorite(this, '2511.15046v1', 'UniHOI: Unified Human-Object Interaction Understanding via Unified Token Space')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction-matching">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction & Matching) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/251115706v2-roma-v2-harder-better-faster-denser-feature-matching.html">RoMa v2: Harder Better Faster Denser Feature Matching</a></td>
  <td>RoMa v2ï¼šé€šè¿‡æ¶æ„ã€è®­ç»ƒå’Œä¼˜åŒ–ï¼Œæ˜¾è‘—æå‡å¯†é›†ç‰¹å¾åŒ¹é…çš„ç²¾åº¦ä¸é€Ÿåº¦ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15706v2" onclick="toggleFavorite(this, '2511.15706v2', 'RoMa v2: Harder Better Faster Denser Feature Matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)