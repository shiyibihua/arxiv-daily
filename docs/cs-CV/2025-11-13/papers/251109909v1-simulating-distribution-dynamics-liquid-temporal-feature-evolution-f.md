---
layout: default
title: Simulating Distribution Dynamics: Liquid Temporal Feature Evolution for Single-Domain Generalized Object Detection
---

# Simulating Distribution Dynamics: Liquid Temporal Feature Evolution for Single-Domain Generalized Object Detection

**arXiv**: [2511.09909v1](https://arxiv.org/abs/2511.09909) | [PDF](https://arxiv.org/pdf/2511.09909.pdf)

**ä½œè€…**: Zihao Zhang, Yang Li, Aming Wu, Yahong Han

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¶²æ€æ—¶åºç‰¹å¾æ¼”åŒ–æ–¹æ³•ä»¥è§£å†³å•åŸŸæ³›åŒ–ç›®æ ‡æ£€æµ‹ä¸­çš„åŠ¨æ€åŸŸåç§»é—®é¢˜**

**å…³é”®è¯**: `å•åŸŸæ³›åŒ–ç›®æ ‡æ£€æµ‹` `æ—¶åºç‰¹å¾æ¼”åŒ–` `æ¶²æ€ç¥žç»ç½‘ç»œ` `åŠ¨æ€åŸŸåç§»` `é«˜æ–¯å™ªå£°æ³¨å…¥` `å¤šå°ºåº¦é«˜æ–¯æ¨¡ç³Š`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå•åŸŸæ³›åŒ–ç›®æ ‡æ£€æµ‹ä¸­ï¼Œç¦»æ•£æ•°æ®å¢žå¼ºæ— æ³•æ•æ‰è¿žç»­åŠ¨æ€åŸŸåç§»ï¼Œå¦‚å¤©æ°”å˜åŒ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥æ—¶åºå»ºæ¨¡å’Œæ¶²æ€ç¥žç»ç½‘ç»œï¼Œæ¨¡æ‹Ÿç‰¹å¾ä»ŽæºåŸŸåˆ°æ½œåœ¨åˆ†å¸ƒçš„æ¸è¿›æ¼”åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Diverse Weatherå’ŒReal-to-ArtåŸºå‡†ä¸Šæ˜¾è‘—æå‡æ³›åŒ–æ€§å’Œé²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this paper, we focus on Single-Domain Generalized Object Detection (Single-DGOD), aiming to transfer a detector trained on one source domain to multiple unknown domains. Existing methods for Single-DGOD typically rely on discrete data augmentation or static perturbation methods to expand data diversity, thereby mitigating the lack of access to target domain data. However, in real-world scenarios such as changes in weather or lighting conditions, domain shifts often occur continuously and gradually. Discrete augmentations and static perturbations fail to effectively capture the dynamic variation of feature distributions, thereby limiting the model's ability to perceive fine-grained cross-domain differences. To this end, we propose a new method, Liquid Temporal Feature Evolution, which simulates the progressive evolution of features from the source domain to simulated latent distributions by incorporating temporal modeling and liquid neural network-driven parameter adjustment. Specifically, we introduce controllable Gaussian noise injection and multi-scale Gaussian blurring to simulate initial feature perturbations, followed by temporal modeling and a liquid parameter adjustment mechanism to generate adaptive modulation parameters, enabling a smooth and continuous adaptation across domains. By capturing progressive cross-domain feature evolution and dynamically regulating adaptation paths, our method bridges the source-unknown domain distribution gap, significantly boosting generalization and robustness to unseen shifts. Significant performance improvements on the Diverse Weather dataset and Real-to-Art benchmark demonstrate the superiority of our method. Our code is available at https://github.com/2490o/LTFE.

