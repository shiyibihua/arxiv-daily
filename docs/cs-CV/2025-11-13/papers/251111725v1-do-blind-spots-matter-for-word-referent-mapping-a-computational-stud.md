---
layout: default
title: Do Blind Spots Matter for Word-Referent Mapping? A Computational Study with Infant Egocentric Video
---

# Do Blind Spots Matter for Word-Referent Mapping? A Computational Study with Infant Egocentric Video

**arXiv**: [2511.11725v1](https://arxiv.org/abs/2511.11725) | [PDF](https://arxiv.org/pdf/2511.11725.pdf)

**ä½œè€…**: Zekai Shi, Zhixi Cai, Kalin Stefanov

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-13

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽç›²ç‚¹æ„ŸçŸ¥çš„è‡ªç›‘ç£è§†è§‰è¡¨å¾å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºŽæå‡å©´å„¿è§†è§’è§†é¢‘ä¸­çš„è¯-ç‰©æ˜ å°„**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è¯-ç‰©æ˜ å°„` `å©´å„¿è§†è§’è§†é¢‘` `è‡ªç›‘ç£å­¦ä¹ ` `ç›²ç‚¹æ„ŸçŸ¥` `æŽ©ç è‡ªç¼–ç å™¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è¯-ç‰©æ˜ å°„æ–¹æ³•ç¼ºä¹ç”Ÿç‰©å­¦åˆç†æ€§ï¼Œé€šå¸¸é‡‡ç”¨éšæœºæŽ©ç ç­–ç•¥ï¼Œå¿½ç•¥äº†äººç±»è§†è§‰ç³»ç»Ÿçš„ç‰¹æ€§ã€‚
2. æå‡ºä¸€ç§åŸºäºŽç›²ç‚¹æ„ŸçŸ¥çš„æŽ©ç è‡ªç¼–ç å™¨ï¼Œæ¨¡æ‹Ÿäººè„‘å¡«è¡¥è§†è§‰ç›²åŒºçš„æ–¹å¼ï¼Œå­¦ä¹ æ›´é²æ£’çš„è§†è§‰è¡¨å¾ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨è¯-ç‰©æ˜ å°„ä»»åŠ¡ä¸­ï¼Œè‡³å°‘ä¸ŽéšæœºæŽ©ç ç­–ç•¥æ•ˆæžœç›¸å½“ï¼ŒéªŒè¯äº†ç”Ÿç‰©å­¦åˆç†æ€§æŽ©ç çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å„¿ç«¥é€šå¸¸åœ¨6åˆ°9ä¸ªæœˆå¤§æ—¶å¼€å§‹å­¦ä¹ ä»–ä»¬çš„ç¬¬ä¸€ä¸ªè¯ï¼Œå°†å£è¯­è¡¨è¾¾ä¸Žè§†è§‰å‚ç…§ç‰©è”ç³»èµ·æ¥ã€‚åœ¨æ²¡æœ‰å…ˆéªŒçŸ¥è¯†çš„æƒ…å†µä¸‹ï¼Œç¬¬ä¸€æ¬¡é‡åˆ°çš„è¯å¯ä»¥è¢«è§£é‡Šä¸ºæ— æ•°ç§æ–¹å¼ï¼›å®ƒå¯èƒ½æŒ‡çš„æ˜¯çŽ¯å¢ƒä¸­çš„ä»»ä½•ç‰©ä½“ã€å®ƒä»¬çš„ç»„æˆéƒ¨åˆ†æˆ–å±žæ€§ã€‚æœ¬æ–‡åˆ©ç”¨æ¥è‡ªä¸€ä¸ªå„¿ç«¥çš„çºµå‘ã€ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒä¸”ç”Ÿæ€æœ‰æ•ˆçš„æ•°æ®ï¼Œæå‡ºäº†ä¸€ç§è‡ªç›‘ç£å’Œç”Ÿç‰©å­¦ä¸Šåˆç†çš„ç­–ç•¥æ¥å­¦ä¹ å¼ºå¤§çš„è§†è§‰è¡¨å¾ã€‚æˆ‘ä»¬åŸºäºŽæŽ©ç è‡ªç¼–ç å™¨çš„è§†è§‰éª¨å¹²ç½‘ç»œç»“åˆäº†äººç±»çœ¼ç›ç›²ç‚¹çš„çŸ¥è¯†æ¥å®šä¹‰ä¸€ç§æ–°çš„æŽ©ç ç­–ç•¥ã€‚è¿™ç§æŽ©ç å’Œé‡å»ºæ–¹æ³•è¯•å›¾æ¨¡ä»¿äººè„‘å¡«è¡¥çœ¼ç›è§†é‡Žä¸­ç©ºç™½çš„æ–¹å¼ã€‚è¿™ä»£è¡¨äº†ä¸Žæ ‡å‡†éšæœºæŽ©ç ç­–ç•¥çš„é‡å¤§è½¬å˜ï¼Œæ ‡å‡†éšæœºæŽ©ç ç­–ç•¥å¾ˆéš¾ä»Žç”Ÿç‰©å­¦è§’åº¦è¯æ˜Žå…¶åˆç†æ€§ã€‚é¢„è®­ç»ƒçš„ç¼–ç å™¨è¢«ç”¨äºŽåŸºäºŽå¯¹æ¯”å­¦ä¹ çš„è§†é¢‘-æ–‡æœ¬æ¨¡åž‹ä¸­ï¼Œè¯¥æ¨¡åž‹èƒ½å¤ŸèŽ·å–è¯-ç‰©æ˜ å°„ã€‚å¹¿æ³›çš„è¯„ä¼°è¡¨æ˜Žï¼Œæ‰€æå‡ºçš„ç”Ÿç‰©å­¦ä¸Šåˆç†çš„æŽ©ç ç­–ç•¥è‡³å°‘ä¸ŽéšæœºæŽ©ç ä¸€æ ·æœ‰æ•ˆï¼Œå¯ä»¥ä»Žè·¨æƒ…å¢ƒå’Œæ—¶é—´æ‰©å±•çš„äº‹ä»¶ä¸­å­¦ä¹ è¯-ç‰©æ˜ å°„ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å©´å„¿å¦‚ä½•ä»Žè¿žç»­çš„ã€ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘ä¸­å­¦ä¹ è¯-ç‰©æ˜ å°„çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºŽéšæœºæŽ©ç ç­–ç•¥è¿›è¡Œè§†è§‰è¡¨å¾å­¦ä¹ ï¼Œè¿™ç§ç­–ç•¥ç¼ºä¹ç”Ÿç‰©å­¦ä¸Šçš„åˆç†æ€§ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨äººç±»è§†è§‰ç³»ç»Ÿçš„å…ˆéªŒçŸ¥è¯†ã€‚å› æ­¤ï¼Œå¦‚ä½•è®¾è®¡ä¸€ç§æ›´ç¬¦åˆç”Ÿç‰©å­¦åŽŸç†çš„è§†è§‰è¡¨å¾å­¦ä¹ æ–¹æ³•ï¼Œä»Žè€Œæå‡è¯-ç‰©æ˜ å°„çš„æ€§èƒ½ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ¨¡æ‹Ÿäººç±»è§†è§‰ç³»ç»Ÿä¸­çš„ç›²ç‚¹æœºåˆ¶ï¼Œè®¾è®¡ä¸€ç§åŸºäºŽç›²ç‚¹æ„ŸçŸ¥çš„æŽ©ç ç­–ç•¥ã€‚é€šè¿‡åœ¨è§†è§‰è¾“å…¥ä¸­å¼•å…¥ä¸Žäººç±»ç›²ç‚¹ç›¸ä¼¼çš„æŽ©ç ï¼Œå¹¶è®­ç»ƒæ¨¡åž‹é‡å»ºè¢«æŽ©ç›–çš„åŒºåŸŸï¼Œä»Žè€Œè¿«ä½¿æ¨¡åž‹å­¦ä¹ æ›´é²æ£’ã€æ›´å…·ç”Ÿç‰©å­¦æ„ä¹‰çš„è§†è§‰è¡¨å¾ã€‚è¿™ç§æ–¹æ³•çš„ç›®çš„æ˜¯è®©æ¨¡åž‹èƒ½å¤Ÿåƒäººè„‘ä¸€æ ·ï¼Œè‡ªåŠ¨å¡«è¡¥è§†è§‰ä¿¡æ¯ä¸­çš„ç¼ºå¤±éƒ¨åˆ†ï¼Œä»Žè€Œæ›´å¥½åœ°ç†è§£å‘¨å›´çŽ¯å¢ƒã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1) åŸºäºŽç›²ç‚¹æ„ŸçŸ¥çš„è‡ªç›‘ç£è§†è§‰è¡¨å¾å­¦ä¹ ï¼›2) åŸºäºŽå¯¹æ¯”å­¦ä¹ çš„è¯-ç‰©æ˜ å°„ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œä½¿ç”¨æŽ©ç è‡ªç¼–ç å™¨ï¼ˆMAEï¼‰ä½œä¸ºè§†è§‰éª¨å¹²ç½‘ç»œï¼Œå¹¶é‡‡ç”¨æå‡ºçš„ç›²ç‚¹æŽ©ç ç­–ç•¥è¿›è¡Œé¢„è®­ç»ƒã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œå°†é¢„è®­ç»ƒçš„è§†è§‰ç¼–ç å™¨ä¸Žæ–‡æœ¬ç¼–ç å™¨ç»“åˆï¼Œæž„å»ºä¸€ä¸ªå¯¹æ¯”å­¦ä¹ æ¨¡åž‹ï¼Œç”¨äºŽå­¦ä¹ è§†é¢‘ç‰‡æ®µå’Œå¯¹åº”è¯è¯­ä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽæå‡ºäº†åŸºäºŽç›²ç‚¹æ„ŸçŸ¥çš„æŽ©ç ç­–ç•¥ã€‚ä¸Žä¼ ç»Ÿçš„éšæœºæŽ©ç ç­–ç•¥ä¸åŒï¼Œè¯¥ç­–ç•¥æ¨¡æ‹Ÿäº†äººç±»è§†è§‰ç³»ç»Ÿä¸­çš„ç›²ç‚¹ï¼Œä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´ç¬¦åˆç”Ÿç‰©å­¦åŽŸç†çš„è§†è§‰è¡¨å¾ã€‚è¿™ç§æ–¹æ³•ä¸ä»…æé«˜äº†è§†è§‰è¡¨å¾çš„è´¨é‡ï¼Œè¿˜æœ‰åŠ©äºŽæå‡è¯-ç‰©æ˜ å°„çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç›²ç‚¹æŽ©ç ç­–ç•¥ä¸­ï¼Œè®ºæ–‡æ ¹æ®äººç±»çœ¼ç›çš„ç”Ÿç†ç»“æž„ï¼Œåœ¨å›¾åƒä¸­éšæœºé€‰æ‹©ä¸€ä¸ªåŒºåŸŸä½œä¸ºç›²ç‚¹ï¼Œå¹¶å°†å…¶æŽ©ç›–ã€‚æŽ©ç çš„å¤§å°å’Œä½ç½®å¯ä»¥æ ¹æ®å®žé™…æƒ…å†µè¿›è¡Œè°ƒæ•´ã€‚åœ¨æŸå¤±å‡½æ•°æ–¹é¢ï¼Œé‡‡ç”¨æ ‡å‡†çš„MAEé‡å»ºæŸå¤±ï¼Œå³æœ€å°åŒ–é‡å»ºå›¾åƒä¸ŽåŽŸå§‹å›¾åƒä¹‹é—´çš„å·®å¼‚ã€‚åœ¨å¯¹æ¯”å­¦ä¹ é˜¶æ®µï¼Œé‡‡ç”¨InfoNCEæŸå¤±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡åž‹å°†ç›¸ä¼¼çš„è§†é¢‘-æ–‡æœ¬å¯¹æ‹‰è¿‘ï¼Œå°†ä¸ç›¸ä¼¼çš„è§†é¢‘-æ–‡æœ¬å¯¹æŽ¨è¿œã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®žéªŒéªŒè¯äº†æå‡ºçš„ç›²ç‚¹æŽ©ç ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œåœ¨è¯-ç‰©æ˜ å°„ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•è‡³å°‘ä¸ŽéšæœºæŽ©ç ç­–ç•¥æ•ˆæžœç›¸å½“ï¼Œç”šè‡³åœ¨æŸäº›æƒ…å†µä¸‹ç•¥æœ‰æå‡ã€‚è¿™è¡¨æ˜Žï¼ŒåŸºäºŽç”Ÿç‰©å­¦åŽŸç†çš„æŽ©ç ç­–ç•¥èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ è§†è§‰è¡¨å¾ï¼Œå¹¶æå‡æ¨¡åž‹çš„æ€§èƒ½ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå¼€å‘æ›´æ™ºèƒ½çš„å„¿ç«¥æ—©æœŸæ•™è‚²æœºå™¨äººï¼Œå¸®åŠ©å„¿ç«¥æ›´å¥½åœ°å­¦ä¹ è¯­è¨€å’Œç†è§£ä¸–ç•Œã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æœºå™¨äººè§†è§‰ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸä¹Ÿå…·æœ‰æ½œåœ¨çš„åº”ç”¨ä»·å€¼ï¼Œå¯ä»¥æå‡æœºå™¨åœ¨å¤æ‚çŽ¯å¢ƒä¸‹çš„æ„ŸçŸ¥èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Typically, children start to learn their first words between 6 and 9 months, linking spoken utterances to their visual referents. Without prior knowledge, a word encountered for the first time can be interpreted in countless ways; it might refer to any of the objects in the environment, their components, or attributes. Using longitudinal, egocentric, and ecologically valid data from the experience of one child, in this work, we propose a self-supervised and biologically plausible strategy to learn strong visual representations. Our masked autoencoder-based visual backbone incorporates knowledge about the blind spot in human eyes to define a novel masking strategy. This mask and reconstruct approach attempts to mimic the way the human brain fills the gaps in the eyes' field of view. This represents a significant shift from standard random masking strategies, which are difficult to justify from a biological perspective. The pretrained encoder is utilized in a contrastive learning-based video-text model capable of acquiring word-referent mappings. Extensive evaluation suggests that the proposed biologically plausible masking strategy is at least as effective as random masking for learning word-referent mappings from cross-situational and temporally extended episodes.

