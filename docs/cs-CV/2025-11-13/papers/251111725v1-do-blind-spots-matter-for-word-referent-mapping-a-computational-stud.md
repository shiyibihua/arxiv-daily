---
layout: default
title: Do Blind Spots Matter for Word-Referent Mapping? A Computational Study with Infant Egocentric Video
---

# Do Blind Spots Matter for Word-Referent Mapping? A Computational Study with Infant Egocentric Video

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.11725" target="_blank" class="toolbar-btn">arXiv: 2511.11725v1</a>
    <a href="https://arxiv.org/pdf/2511.11725.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.11725v1" 
            onclick="toggleFavorite(this, '2511.11725v1', 'Do Blind Spots Matter for Word-Referent Mapping? A Computational Study with Infant Egocentric Video')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Zekai Shi, Zhixi Cai, Kalin Stefanov

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºç›²ç‚¹æ„ŸçŸ¥çš„è‡ªç›‘ç£è§†è§‰è¡¨å¾å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºæå‡å©´å„¿è§†è§’è§†é¢‘ä¸­çš„è¯-ç‰©æ˜ å°„**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è¯-ç‰©æ˜ å°„` `å©´å„¿è§†è§’è§†é¢‘` `è‡ªç›‘ç£å­¦ä¹ ` `ç›²ç‚¹æ„ŸçŸ¥` `æ©ç è‡ªç¼–ç å™¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯-ç‰©æ˜ å°„æ–¹æ³•ç¼ºä¹ç”Ÿç‰©å­¦åˆç†æ€§ï¼Œé€šå¸¸é‡‡ç”¨éšæœºæ©ç ç­–ç•¥ï¼Œå¿½ç•¥äº†äººç±»è§†è§‰ç³»ç»Ÿçš„ç‰¹æ€§ã€‚
2. æå‡ºä¸€ç§åŸºäºç›²ç‚¹æ„ŸçŸ¥çš„æ©ç è‡ªç¼–ç å™¨ï¼Œæ¨¡æ‹Ÿäººè„‘å¡«è¡¥è§†è§‰ç›²åŒºçš„æ–¹å¼ï¼Œå­¦ä¹ æ›´é²æ£’çš„è§†è§‰è¡¨å¾ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¯-ç‰©æ˜ å°„ä»»åŠ¡ä¸­ï¼Œè‡³å°‘ä¸éšæœºæ©ç ç­–ç•¥æ•ˆæœç›¸å½“ï¼ŒéªŒè¯äº†ç”Ÿç‰©å­¦åˆç†æ€§æ©ç çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å„¿ç«¥é€šå¸¸åœ¨6åˆ°9ä¸ªæœˆå¤§æ—¶å¼€å§‹å­¦ä¹ ä»–ä»¬çš„ç¬¬ä¸€ä¸ªè¯ï¼Œå°†å£è¯­è¡¨è¾¾ä¸è§†è§‰å‚ç…§ç‰©è”ç³»èµ·æ¥ã€‚åœ¨æ²¡æœ‰å…ˆéªŒçŸ¥è¯†çš„æƒ…å†µä¸‹ï¼Œç¬¬ä¸€æ¬¡é‡åˆ°çš„è¯å¯ä»¥è¢«è§£é‡Šä¸ºæ— æ•°ç§æ–¹å¼ï¼›å®ƒå¯èƒ½æŒ‡çš„æ˜¯ç¯å¢ƒä¸­çš„ä»»ä½•ç‰©ä½“ã€å®ƒä»¬çš„ç»„æˆéƒ¨åˆ†æˆ–å±æ€§ã€‚æœ¬æ–‡åˆ©ç”¨æ¥è‡ªä¸€ä¸ªå„¿ç«¥çš„çºµå‘ã€ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒä¸”ç”Ÿæ€æœ‰æ•ˆçš„æ•°æ®ï¼Œæå‡ºäº†ä¸€ç§è‡ªç›‘ç£å’Œç”Ÿç‰©å­¦ä¸Šåˆç†çš„ç­–ç•¥æ¥å­¦ä¹ å¼ºå¤§çš„è§†è§‰è¡¨å¾ã€‚æˆ‘ä»¬åŸºäºæ©ç è‡ªç¼–ç å™¨çš„è§†è§‰éª¨å¹²ç½‘ç»œç»“åˆäº†äººç±»çœ¼ç›ç›²ç‚¹çš„çŸ¥è¯†æ¥å®šä¹‰ä¸€ç§æ–°çš„æ©ç ç­–ç•¥ã€‚è¿™ç§æ©ç å’Œé‡å»ºæ–¹æ³•è¯•å›¾æ¨¡ä»¿äººè„‘å¡«è¡¥çœ¼ç›è§†é‡ä¸­ç©ºç™½çš„æ–¹å¼ã€‚è¿™ä»£è¡¨äº†ä¸æ ‡å‡†éšæœºæ©ç ç­–ç•¥çš„é‡å¤§è½¬å˜ï¼Œæ ‡å‡†éšæœºæ©ç ç­–ç•¥å¾ˆéš¾ä»ç”Ÿç‰©å­¦è§’åº¦è¯æ˜å…¶åˆç†æ€§ã€‚é¢„è®­ç»ƒçš„ç¼–ç å™¨è¢«ç”¨äºåŸºäºå¯¹æ¯”å­¦ä¹ çš„è§†é¢‘-æ–‡æœ¬æ¨¡å‹ä¸­ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿè·å–è¯-ç‰©æ˜ å°„ã€‚å¹¿æ³›çš„è¯„ä¼°è¡¨æ˜ï¼Œæ‰€æå‡ºçš„ç”Ÿç‰©å­¦ä¸Šåˆç†çš„æ©ç ç­–ç•¥è‡³å°‘ä¸éšæœºæ©ç ä¸€æ ·æœ‰æ•ˆï¼Œå¯ä»¥ä»è·¨æƒ…å¢ƒå’Œæ—¶é—´æ‰©å±•çš„äº‹ä»¶ä¸­å­¦ä¹ è¯-ç‰©æ˜ å°„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å©´å„¿å¦‚ä½•ä»è¿ç»­çš„ã€ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘ä¸­å­¦ä¹ è¯-ç‰©æ˜ å°„çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºéšæœºæ©ç ç­–ç•¥è¿›è¡Œè§†è§‰è¡¨å¾å­¦ä¹ ï¼Œè¿™ç§ç­–ç•¥ç¼ºä¹ç”Ÿç‰©å­¦ä¸Šçš„åˆç†æ€§ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨äººç±»è§†è§‰ç³»ç»Ÿçš„å…ˆéªŒçŸ¥è¯†ã€‚å› æ­¤ï¼Œå¦‚ä½•è®¾è®¡ä¸€ç§æ›´ç¬¦åˆç”Ÿç‰©å­¦åŸç†çš„è§†è§‰è¡¨å¾å­¦ä¹ æ–¹æ³•ï¼Œä»è€Œæå‡è¯-ç‰©æ˜ å°„çš„æ€§èƒ½ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ¨¡æ‹Ÿäººç±»è§†è§‰ç³»ç»Ÿä¸­çš„ç›²ç‚¹æœºåˆ¶ï¼Œè®¾è®¡ä¸€ç§åŸºäºç›²ç‚¹æ„ŸçŸ¥çš„æ©ç ç­–ç•¥ã€‚é€šè¿‡åœ¨è§†è§‰è¾“å…¥ä¸­å¼•å…¥ä¸äººç±»ç›²ç‚¹ç›¸ä¼¼çš„æ©ç ï¼Œå¹¶è®­ç»ƒæ¨¡å‹é‡å»ºè¢«æ©ç›–çš„åŒºåŸŸï¼Œä»è€Œè¿«ä½¿æ¨¡å‹å­¦ä¹ æ›´é²æ£’ã€æ›´å…·ç”Ÿç‰©å­¦æ„ä¹‰çš„è§†è§‰è¡¨å¾ã€‚è¿™ç§æ–¹æ³•çš„ç›®çš„æ˜¯è®©æ¨¡å‹èƒ½å¤Ÿåƒäººè„‘ä¸€æ ·ï¼Œè‡ªåŠ¨å¡«è¡¥è§†è§‰ä¿¡æ¯ä¸­çš„ç¼ºå¤±éƒ¨åˆ†ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£å‘¨å›´ç¯å¢ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1) åŸºäºç›²ç‚¹æ„ŸçŸ¥çš„è‡ªç›‘ç£è§†è§‰è¡¨å¾å­¦ä¹ ï¼›2) åŸºäºå¯¹æ¯”å­¦ä¹ çš„è¯-ç‰©æ˜ å°„ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œä½¿ç”¨æ©ç è‡ªç¼–ç å™¨ï¼ˆMAEï¼‰ä½œä¸ºè§†è§‰éª¨å¹²ç½‘ç»œï¼Œå¹¶é‡‡ç”¨æå‡ºçš„ç›²ç‚¹æ©ç ç­–ç•¥è¿›è¡Œé¢„è®­ç»ƒã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œå°†é¢„è®­ç»ƒçš„è§†è§‰ç¼–ç å™¨ä¸æ–‡æœ¬ç¼–ç å™¨ç»“åˆï¼Œæ„å»ºä¸€ä¸ªå¯¹æ¯”å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºå­¦ä¹ è§†é¢‘ç‰‡æ®µå’Œå¯¹åº”è¯è¯­ä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†åŸºäºç›²ç‚¹æ„ŸçŸ¥çš„æ©ç ç­–ç•¥ã€‚ä¸ä¼ ç»Ÿçš„éšæœºæ©ç ç­–ç•¥ä¸åŒï¼Œè¯¥ç­–ç•¥æ¨¡æ‹Ÿäº†äººç±»è§†è§‰ç³»ç»Ÿä¸­çš„ç›²ç‚¹ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´ç¬¦åˆç”Ÿç‰©å­¦åŸç†çš„è§†è§‰è¡¨å¾ã€‚è¿™ç§æ–¹æ³•ä¸ä»…æé«˜äº†è§†è§‰è¡¨å¾çš„è´¨é‡ï¼Œè¿˜æœ‰åŠ©äºæå‡è¯-ç‰©æ˜ å°„çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç›²ç‚¹æ©ç ç­–ç•¥ä¸­ï¼Œè®ºæ–‡æ ¹æ®äººç±»çœ¼ç›çš„ç”Ÿç†ç»“æ„ï¼Œåœ¨å›¾åƒä¸­éšæœºé€‰æ‹©ä¸€ä¸ªåŒºåŸŸä½œä¸ºç›²ç‚¹ï¼Œå¹¶å°†å…¶æ©ç›–ã€‚æ©ç çš„å¤§å°å’Œä½ç½®å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè¿›è¡Œè°ƒæ•´ã€‚åœ¨æŸå¤±å‡½æ•°æ–¹é¢ï¼Œé‡‡ç”¨æ ‡å‡†çš„MAEé‡å»ºæŸå¤±ï¼Œå³æœ€å°åŒ–é‡å»ºå›¾åƒä¸åŸå§‹å›¾åƒä¹‹é—´çš„å·®å¼‚ã€‚åœ¨å¯¹æ¯”å­¦ä¹ é˜¶æ®µï¼Œé‡‡ç”¨InfoNCEæŸå¤±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹å°†ç›¸ä¼¼çš„è§†é¢‘-æ–‡æœ¬å¯¹æ‹‰è¿‘ï¼Œå°†ä¸ç›¸ä¼¼çš„è§†é¢‘-æ–‡æœ¬å¯¹æ¨è¿œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®éªŒéªŒè¯äº†æå‡ºçš„ç›²ç‚¹æ©ç ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨è¯-ç‰©æ˜ å°„ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•è‡³å°‘ä¸éšæœºæ©ç ç­–ç•¥æ•ˆæœç›¸å½“ï¼Œç”šè‡³åœ¨æŸäº›æƒ…å†µä¸‹ç•¥æœ‰æå‡ã€‚è¿™è¡¨æ˜ï¼ŒåŸºäºç”Ÿç‰©å­¦åŸç†çš„æ©ç ç­–ç•¥èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ è§†è§‰è¡¨å¾ï¼Œå¹¶æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¼€å‘æ›´æ™ºèƒ½çš„å„¿ç«¥æ—©æœŸæ•™è‚²æœºå™¨äººï¼Œå¸®åŠ©å„¿ç«¥æ›´å¥½åœ°å­¦ä¹ è¯­è¨€å’Œç†è§£ä¸–ç•Œã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æœºå™¨äººè§†è§‰ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸä¹Ÿå…·æœ‰æ½œåœ¨çš„åº”ç”¨ä»·å€¼ï¼Œå¯ä»¥æå‡æœºå™¨åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æ„ŸçŸ¥èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Typically, children start to learn their first words between 6 and 9 months, linking spoken utterances to their visual referents. Without prior knowledge, a word encountered for the first time can be interpreted in countless ways; it might refer to any of the objects in the environment, their components, or attributes. Using longitudinal, egocentric, and ecologically valid data from the experience of one child, in this work, we propose a self-supervised and biologically plausible strategy to learn strong visual representations. Our masked autoencoder-based visual backbone incorporates knowledge about the blind spot in human eyes to define a novel masking strategy. This mask and reconstruct approach attempts to mimic the way the human brain fills the gaps in the eyes' field of view. This represents a significant shift from standard random masking strategies, which are difficult to justify from a biological perspective. The pretrained encoder is utilized in a contrastive learning-based video-text model capable of acquiring word-referent mappings. Extensive evaluation suggests that the proposed biologically plausible masking strategy is at least as effective as random masking for learning word-referent mappings from cross-situational and temporally extended episodes.

