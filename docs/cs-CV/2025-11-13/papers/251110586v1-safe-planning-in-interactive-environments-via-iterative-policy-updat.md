---
layout: default
title: Safe Planning in Interactive Environments via Iterative Policy Updates and Adversarially Robust Conformal Prediction
---

# Safe Planning in Interactive Environments via Iterative Policy Updates and Adversarially Robust Conformal Prediction

**arXiv**: [2511.10586v1](https://arxiv.org/abs/2511.10586) | [PDF](https://arxiv.org/pdf/2511.10586.pdf)

**ä½œè€…**: Omid Mirzaeedodangeh, Eliot Shekhtman, Nikolai Matni, Lars Lindemann

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¿­ä»£ç­–ç•¥æ›´æ–°ä¸Žå¯¹æŠ—é²æ£’å…±å½¢é¢„æµ‹æ¡†æž¶ï¼Œä»¥åœ¨äº¤äº’çŽ¯å¢ƒä¸­å®žçŽ°å®‰å…¨è§„åˆ’ã€‚**

**å…³é”®è¯**: `å®‰å…¨è§„åˆ’` `äº¤äº’çŽ¯å¢ƒ` `å…±å½¢é¢„æµ‹` `ç­–ç•¥æ›´æ–°` `åˆ†å¸ƒåç§»` `æ”¶æ•›åˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šäº¤äº’çŽ¯å¢ƒä¸­ç­–ç•¥æ›´æ–°å¯¼è‡´æ•°æ®åˆ†å¸ƒåç§»ï¼Œè¿åå…±å½¢é¢„æµ‹çš„äº¤æ¢æ€§å‡è®¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡ç­–ç•¥-è½¨è¿¹æ•æ„Ÿæ€§åˆ†æžè°ƒæ•´å…±å½¢é¢„æµ‹ç»“æžœï¼Œè·¨ç­–ç•¥æ›´æ–°è½¬ç§»å®‰å…¨ä¿è¯ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨äºŒç»´è½¦-è¡Œäººæ¡ˆä¾‹ä¸­å®žè¯å®‰å…¨ä¸Žæ”¶æ•›ä¿è¯ï¼ŒæœªçŸ¥æ˜¯å¦ä¼˜äºŽå…¶ä»–æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Safe planning of an autonomous agent in interactive environments -- such as the control of a self-driving vehicle among pedestrians and human-controlled vehicles -- poses a major challenge as the behavior of the environment is unknown and reactive to the behavior of the autonomous agent. This coupling gives rise to interaction-driven distribution shifts where the autonomous agent's control policy may change the environment's behavior, thereby invalidating safety guarantees in existing work. Indeed, recent works have used conformal prediction (CP) to generate distribution-free safety guarantees using observed data of the environment. However, CP's assumption on data exchangeability is violated in interactive settings due to a circular dependency where a control policy update changes the environment's behavior, and vice versa. To address this gap, we propose an iterative framework that robustly maintains safety guarantees across policy updates by quantifying the potential impact of a planned policy update on the environment's behavior. We realize this via adversarially robust CP where we perform a regular CP step in each episode using observed data under the current policy, but then transfer safety guarantees across policy updates by analytically adjusting the CP result to account for distribution shifts. This adjustment is performed based on a policy-to-trajectory sensitivity analysis, resulting in a safe, episodic open-loop planner. We further conduct a contraction analysis of the system providing conditions under which both the CP results and the policy updates are guaranteed to converge. We empirically demonstrate these safety and convergence guarantees on a two-dimensional car-pedestrian case study. To the best of our knowledge, these are the first results that provide valid safety guarantees in such interactive settings.

