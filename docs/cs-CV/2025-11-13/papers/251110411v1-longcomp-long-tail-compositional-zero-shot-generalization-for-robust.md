---
layout: default
title: LongComp: Long-Tail Compositional Zero-Shot Generalization for Robust Trajectory Prediction
---

# LongComp: Long-Tail Compositional Zero-Shot Generalization for Robust Trajectory Prediction

**arXiv**: [2511.10411v1](https://arxiv.org/abs/2511.10411) | [PDF](https://arxiv.org/pdf/2511.10411.pdf)

**ä½œè€…**: Benjamin Stoler, Jonathan Francis, Jean Oh

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé•¿å°¾ç»„åˆé›¶æ ·æœ¬æ³›åŒ–æ–¹æ³•ä»¥æå‡è‡ªåŠ¨é©¾é©¶è½¨è¿¹é¢„æµ‹çš„é²æ£’æ€§**

**å…³é”®è¯**: `è½¨è¿¹é¢„æµ‹` `ç»„åˆé›¶æ ·æœ¬å­¦ä¹ ` `é•¿å°¾åˆ†å¸ƒ` `è‡ªåŠ¨é©¾é©¶` `åˆ†å¸ƒå¤–æ³›åŒ–` `æ¨¡å—åŒ–ç½‘ç»œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‡ªåŠ¨é©¾é©¶è½¨è¿¹é¢„æµ‹åœ¨ç½•è§å®‰å…¨å…³é”®åœºæ™¯ä¸­ä¾èµ–çœŸå®žæ•°æ®ä¸è¶³ï¼Œå¯¼è‡´åˆ†å¸ƒå¤–æ³›åŒ–èƒ½åŠ›å·®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥å®‰å…¨åœºæ™¯å› å­åŒ–æ¡†æž¶å’Œä»»åŠ¡æ¨¡å—åŒ–é—¨æŽ§ç½‘ç»œï¼Œç»“åˆéš¾åº¦é¢„æµ‹å¤´ä¼˜åŒ–å†…éƒ¨è¡¨ç¤ºã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨é—­ä¸–ç•Œå’Œå¼€ä¸–ç•Œè®¾ç½®ä¸­ï¼Œåˆ†å¸ƒå¤–æ€§èƒ½å·®è·åˆ†åˆ«ä»Ž5.0%å’Œ14.7%é™è‡³2.8%å’Œ11.5%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Methods for trajectory prediction in Autonomous Driving must contend with rare, safety-critical scenarios that make reliance on real-world data collection alone infeasible. To assess robustness under such conditions, we propose new long-tail evaluation settings that repartition datasets to create challenging out-of-distribution (OOD) test sets. We first introduce a safety-informed scenario factorization framework, which disentangles scenarios into discrete ego and social contexts. Building on analogies to compositional zero-shot image-labeling in Computer Vision, we then hold out novel context combinations to construct challenging closed-world and open-world settings. This process induces OOD performance gaps in future motion prediction of 5.0% and 14.7% in closed-world and open-world settings, respectively, relative to in-distribution performance for a state-of-the-art baseline. To improve generalization, we extend task-modular gating networks to operate within trajectory prediction models, and develop an auxiliary, difficulty-prediction head to refine internal representations. Our strategies jointly reduce the OOD performance gaps to 2.8% and 11.5% in the two settings, respectively, while still improving in-distribution performance.

