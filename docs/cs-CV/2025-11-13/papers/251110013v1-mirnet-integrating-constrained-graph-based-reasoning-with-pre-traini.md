---
layout: default
title: MIRNet: Integrating Constrained Graph-Based Reasoning with Pre-training for Diagnostic Medical Imaging
---

# MIRNet: Integrating Constrained Graph-Based Reasoning with Pre-training for Diagnostic Medical Imaging

**arXiv**: [2511.10013v1](https://arxiv.org/abs/2511.10013) | [PDF](https://arxiv.org/pdf/2511.10013.pdf)

**ä½œè€…**: Shufeng Kong, Zijie Wang, Nuan Cui, Hao Tang, Yihan Meng, Yuanyuan Wei, Feifan Chen, Yingheng Wang, Zhuo Cai, Yaonan Wang, Yulong Zhang, Yuzheng Li, Zibin Zheng, Caihua Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMIRNetæ¡†æž¶ï¼Œç»“åˆè‡ªç›‘ç£é¢„è®­ç»ƒä¸Žå›¾æŽ¨ç†ï¼Œè§£å†³åŒ»å­¦å›¾åƒè¯Šæ–­ä¸­çš„æ ‡æ³¨ç¨€ç¼ºå’Œæ ‡ç­¾ä¸å¹³è¡¡é—®é¢˜ã€‚**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒè¯Šæ–­` `è‡ªç›‘ç£é¢„è®­ç»ƒ` `å›¾æ³¨æ„åŠ›ç½‘ç»œ` `çº¦æŸä¼˜åŒ–` `èˆŒåƒåˆ†æž` `æ ‡ç­¾ä¸å¹³è¡¡å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŒ»å­¦å›¾åƒæ ‡æ³¨ç¨€ç¼ºã€æ ‡ç­¾ä¸å¹³è¡¡å’Œä¸´åºŠåˆç†æ€§çº¦æŸï¼Œå°¤å…¶åœ¨èˆŒåƒè¯Šæ–­ä¸­ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨MAEè‡ªç›‘ç£é¢„è®­ç»ƒã€GATå»ºæ¨¡æ ‡ç­¾ç›¸å…³æ€§ã€çº¦æŸä¼˜åŒ–å’ŒASLæŸå¤±å¤„ç†ä¸å¹³è¡¡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨TongueAtlas-4Kæ•°æ®é›†ä¸ŠéªŒè¯ï¼Œè¾¾åˆ°å…ˆè¿›æ€§èƒ½ï¼Œå¯æ³›åŒ–è‡³å…¶ä»–åŒ»å­¦å›¾åƒä»»åŠ¡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Automated interpretation of medical images demands robust modeling of complex visual-semantic relationships while addressing annotation scarcity, label imbalance, and clinical plausibility constraints. We introduce MIRNet (Medical Image Reasoner Network), a novel framework that integrates self-supervised pre-training with constrained graph-based reasoning. Tongue image diagnosis is a particularly challenging domain that requires fine-grained visual and semantic understanding. Our approach leverages self-supervised masked autoencoder (MAE) to learn transferable visual representations from unlabeled data; employs graph attention networks (GAT) to model label correlations through expert-defined structured graphs; enforces clinical priors via constraint-aware optimization using KL divergence and regularization losses; and mitigates imbalance using asymmetric loss (ASL) and boosting ensembles. To address annotation scarcity, we also introduce TongueAtlas-4K, a comprehensive expert-curated benchmark comprising 4,000 images annotated with 22 diagnostic labels--representing the largest public dataset in tongue analysis. Validation shows our method achieves state-of-the-art performance. While optimized for tongue diagnosis, the framework readily generalizes to broader diagnostic medical imaging tasks.

