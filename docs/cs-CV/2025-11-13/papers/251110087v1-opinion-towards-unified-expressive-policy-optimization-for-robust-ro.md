---
layout: default
title: Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning
---

# Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning

**arXiv**: [2511.10087v1](https://arxiv.org/abs/2511.10087) | [PDF](https://arxiv.org/pdf/2511.10087.pdf)

**ä½œè€…**: Haidong Huang, Haiyue Zhu. Jiayu Song, Xixin Zhao, Yaohua Zhou, Jiayi Zhang, Yuze Zhai, Xiaocong Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUEPOç»Ÿä¸€ç”Ÿæˆæ¡†æž¶ä»¥è§£å†³æœºå™¨äººç¦»çº¿åˆ°åœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„æ¨¡æ€è¦†ç›–ä¸è¶³å’Œåˆ†å¸ƒåç§»é—®é¢˜**

**å…³é”®è¯**: `ç¦»çº¿åˆ°åœ¨çº¿å¼ºåŒ–å­¦ä¹ ` `æ‰©æ•£ç­–ç•¥` `åŠ¨æ€åˆ†æ­§æ­£åˆ™åŒ–` `æœºå™¨äººå­¦ä¹ ` `æ•°æ®å¢žå¼º` `æ³›åŒ–èƒ½åŠ›`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç¦»çº¿åˆ°åœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¸­æ¨¡æ€è¦†ç›–æœ‰é™å’Œåœ¨çº¿é€‚åº”æ—¶çš„åˆ†å¸ƒåç§»
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å¤šç§å­åŠ¨æ€æ„ŸçŸ¥æ‰©æ•£ç­–ç•¥å’ŒåŠ¨æ€åˆ†æ­§æ­£åˆ™åŒ–æœºåˆ¶
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨D4RLåŸºå‡†ä¸Šï¼Œè¿åŠ¨ä»»åŠ¡æå‡5.9%ï¼Œçµå·§æ“ä½œæå‡12.4%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Offline-to-online reinforcement learning (O2O-RL) has emerged as a promising paradigm for safe and efficient robotic policy deployment but suffers from two fundamental challenges: limited coverage of multimodal behaviors and distributional shifts during online adaptation. We propose UEPO, a unified generative framework inspired by large language model pretraining and fine-tuning strategies. Our contributions are threefold: (1) a multi-seed dynamics-aware diffusion policy that efficiently captures diverse modalities without training multiple models; (2) a dynamic divergence regularization mechanism that enforces physically meaningful policy diversity; and (3) a diffusion-based data augmentation module that enhances dynamics model generalization. On the D4RL benchmark, UEPO achieves +5.9\% absolute improvement over Uni-O4 on locomotion tasks and +12.4\% on dexterous manipulation, demonstrating strong generalization and scalability.

