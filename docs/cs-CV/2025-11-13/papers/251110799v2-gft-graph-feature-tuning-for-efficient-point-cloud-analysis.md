---
layout: default
title: GFT: Graph Feature Tuning for Efficient Point Cloud Analysis
---

# GFT: Graph Feature Tuning for Efficient Point Cloud Analysis

**arXiv**: [2511.10799v2](https://arxiv.org/abs/2511.10799) | [PDF](https://arxiv.org/pdf/2511.10799.pdf)

**ä½œè€…**: Manish Dhakal, Venkat R. Dasari, Rajshekhar Sunderraman, Yi Ding

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-13 (æ›´æ–°: 2025-12-01)

**å¤‡æ³¨**: Accepted to WACV 2026

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/manishdhakal/GFT)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå›¾ç‰¹å¾è°ƒä¼˜(GFT)æ–¹æ³•ï¼Œé«˜æ•ˆåˆ†æžç‚¹äº‘æ•°æ®å¹¶æ˜¾è‘—é™ä½Žå‚æ•°é‡ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `ç‚¹äº‘åˆ†æž` `å‚æ•°é«˜æ•ˆå¾®è°ƒ` `å›¾ç¥žç»ç½‘ç»œ` `Transformer` `ä¸‰ç»´é‡å»º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰é€šç”¨PEFTæ–¹æ³•åœ¨ç‚¹äº‘æ•°æ®ä¸Šè¡¨çŽ°æ¬¡ä¼˜ï¼Œä¸”å‚æ•°é‡ä»ç„¶è¾ƒé«˜ï¼Œé™åˆ¶äº†å…¶åœ¨èµ„æºå—é™åœºæ™¯çš„åº”ç”¨ã€‚
2. GFTé€šè¿‡è½»é‡çº§å›¾å·ç§¯ç½‘ç»œå­¦ä¹ åŠ¨æ€å›¾ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨è·³è·ƒè¿žæŽ¥å’Œé«˜æ•ˆäº¤å‰æ³¨æ„åŠ›æ¨¡å—ä¼ é€’åˆ°Transformeræ·±å±‚ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒGFTåœ¨å¯¹è±¡åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ä¸Šä¸ŽçŽ°æœ‰æ–¹æ³•æ€§èƒ½ç›¸å½“ï¼ŒåŒæ—¶æ˜¾è‘—å‡å°‘äº†å¯è®­ç»ƒå‚æ•°ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‚æ•°é«˜æ•ˆå¾®è°ƒ(PEFT)é€šè¿‡ä»…æ›´æ–°æ¨¡åž‹å‚æ•°çš„ä¸€å°éƒ¨åˆ†ï¼Œæ˜¾è‘—é™ä½Žäº†è®¡ç®—å’Œå†…å­˜æˆæœ¬ï¼Œä»Žè€Œèƒ½å¤Ÿä»¥æœ€å°çš„æ€§èƒ½æŸå¤±æ›´å¿«åœ°é€‚åº”æ–°ä»»åŠ¡ã€‚å…ˆå‰çš„ç ”ç©¶å·²ç»å¼•å…¥äº†ä¸ºç‚¹äº‘æ•°æ®é‡èº«å®šåˆ¶çš„PEFTï¼Œå› ä¸ºé€šç”¨æ–¹æ³•å¹¶éžæœ€ä¼˜ã€‚ä¸ºäº†è¿›ä¸€æ­¥å‡å°‘å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç‰¹å®šäºŽç‚¹äº‘çš„PEFTï¼Œç§°ä¸ºå›¾ç‰¹å¾è°ƒä¼˜(GFT)ï¼Œå®ƒä½¿ç”¨è½»é‡çº§å›¾å·ç§¯ç½‘ç»œä»ŽTransformerçš„åˆå§‹tokenizedè¾“å…¥ä¸­å­¦ä¹ åŠ¨æ€å›¾ï¼Œå¹¶é€šè¿‡è·³è·ƒè¿žæŽ¥å’Œé«˜æ•ˆçš„äº¤å‰æ³¨æ„åŠ›æ¨¡å—å°†è¿™äº›å›¾ç‰¹å¾ä¼ é€’åˆ°æ›´æ·±å±‚ã€‚åœ¨å¯¹è±¡åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ä¸Šçš„å¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒGFTåœ¨åŒä¸€é¢†åŸŸå†…è¿è¡Œï¼Œä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸åª²ç¾Žï¼ŒåŒæ—¶å‡å°‘äº†å¯è®­ç»ƒå‚æ•°ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç‚¹äº‘åˆ†æžä¸­ï¼ŒçŽ°æœ‰å‚æ•°é«˜æ•ˆå¾®è°ƒ(PEFT)æ–¹æ³•ä»ç„¶éœ€è¦è¾ƒå¤§å‚æ•°é‡çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•è™½ç„¶æ¯”å…¨å‚æ•°å¾®è°ƒå‡å°‘äº†å‚æ•°ï¼Œä½†åœ¨ç‚¹äº‘æ•°æ®ä¸Šä»æœ‰ä¼˜åŒ–ç©ºé—´ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„åœºæ™¯ä¸‹ï¼Œéœ€è¦è¿›ä¸€æ­¥é™ä½Žè®¡ç®—å’Œå­˜å‚¨æˆæœ¬ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å›¾ç¥žç»ç½‘ç»œ(GNN)å­¦ä¹ ç‚¹äº‘æ•°æ®çš„ç»“æž„ä¿¡æ¯ï¼Œå¹¶å°†è¿™äº›ç»“æž„ä¿¡æ¯ä½œä¸ºç‰¹å¾ä¼ é€’åˆ°Transformerçš„æ›´æ·±å±‚ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡åž‹å¯ä»¥æ›´å¥½åœ°åˆ©ç”¨ç‚¹äº‘çš„å†…åœ¨å…³ç³»ï¼Œä»Žè€Œåœ¨æ›´å°‘çš„å‚æ•°ä¸‹è¾¾åˆ°ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šGFTçš„æŠ€æœ¯æ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) è¾“å…¥ç‚¹äº‘ç»è¿‡Tokenizationå¤„ç†ï¼›2) è½»é‡çº§å›¾å·ç§¯ç½‘ç»œ(GCN)ä»Žåˆå§‹tokenizedè¾“å…¥ä¸­å­¦ä¹ åŠ¨æ€å›¾ç»“æž„ï¼›3) å›¾ç‰¹å¾é€šè¿‡è·³è·ƒè¿žæŽ¥ä¼ é€’åˆ°Transformerçš„æ›´æ·±å±‚ï¼›4) ä½¿ç”¨é«˜æ•ˆçš„äº¤å‰æ³¨æ„åŠ›æ¨¡å—èžåˆå›¾ç‰¹å¾å’ŒTransformerç‰¹å¾ã€‚æ•´ä½“æµç¨‹æ˜¯å…ˆæå–ç‚¹äº‘çš„å±€éƒ¨ç‰¹å¾ï¼Œç„¶åŽåˆ©ç”¨GCNå­¦ä¹ å…¨å±€ç»“æž„ä¿¡æ¯ï¼Œæœ€åŽå°†ç»“æž„ä¿¡æ¯èžå…¥åˆ°Transformerä¸­è¿›è¡Œåˆ†ç±»æˆ–åˆ†å‰²ã€‚

**å…³é”®åˆ›æ–°**ï¼šGFTçš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) æå‡ºäº†ä¸€ç§ç‰¹å®šäºŽç‚¹äº‘çš„PEFTæ–¹æ³•ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨ç‚¹äº‘çš„ç»“æž„ä¿¡æ¯ï¼›2) ä½¿ç”¨è½»é‡çº§GCNå­¦ä¹ åŠ¨æ€å›¾ç»“æž„ï¼Œé™ä½Žäº†è®¡ç®—å¤æ‚åº¦ï¼›3) é€šè¿‡è·³è·ƒè¿žæŽ¥å’Œé«˜æ•ˆäº¤å‰æ³¨æ„åŠ›æ¨¡å—ï¼Œæ›´å¥½åœ°èžåˆäº†å›¾ç‰¹å¾å’ŒTransformerç‰¹å¾ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒGFTåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘äº†å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šGFTçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) è½»é‡çº§GCNçš„ç»“æž„è®¾è®¡ï¼Œä¾‹å¦‚å±‚æ•°ã€å·ç§¯æ ¸å¤§å°ç­‰ï¼›2) è·³è·ƒè¿žæŽ¥çš„è¿žæŽ¥æ–¹å¼ï¼Œä¾‹å¦‚è¿žæŽ¥åˆ°å“ªäº›Transformerå±‚ï¼›3) äº¤å‰æ³¨æ„åŠ›æ¨¡å—çš„è®¾è®¡ï¼Œä¾‹å¦‚æ³¨æ„åŠ›å¤´çš„æ•°é‡ã€ç»´åº¦ç­‰ï¼›4) æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼Œä¾‹å¦‚æ˜¯å¦å¼•å…¥å›¾æ­£åˆ™åŒ–é¡¹ç­‰ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æž„éœ€è¦åœ¨å®žéªŒä¸­è¿›è¡Œè°ƒæ•´å’Œä¼˜åŒ–ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒGFTåœ¨å¯¹è±¡åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ä¸Šä¸ŽçŽ°æœ‰PEFTæ–¹æ³•æ€§èƒ½ç›¸å½“ï¼Œç”šè‡³ç•¥æœ‰æå‡ï¼ŒåŒæ—¶æ˜¾è‘—å‡å°‘äº†å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ã€‚å…·ä½“æ¥è¯´ï¼ŒGFTåœ¨ModelNet40æ•°æ®é›†ä¸Šçš„åˆ†ç±»ç²¾åº¦ä¸ŽçŽ°æœ‰æ–¹æ³•æŒå¹³ï¼Œä½†åœ¨ShapeNetæ•°æ®é›†ä¸Šçš„åˆ†å‰²ç²¾åº¦ç•¥æœ‰æå‡ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒGFTçš„å¯è®­ç»ƒå‚æ•°æ•°é‡æ¯”çŽ°æœ‰æ–¹æ³•å‡å°‘äº†çº¦30%-50%ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

GFTå¯åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€ä¸‰ç»´é‡å»ºã€å·¥ä¸šæ£€æµ‹ç­‰é¢†åŸŸã€‚é€šè¿‡å‡å°‘æ¨¡åž‹å‚æ•°é‡ï¼ŒGFTä½¿å¾—ç‚¹äº‘åˆ†æžæ¨¡åž‹æ›´å®¹æ˜“éƒ¨ç½²åˆ°èµ„æºå—é™çš„è®¾å¤‡ä¸Šï¼Œä¾‹å¦‚ç§»åŠ¨æœºå™¨äººã€æ— äººæœºç­‰ã€‚æœªæ¥ï¼ŒGFTå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–ä¸‰ç»´æ•°æ®å¤„ç†ä»»åŠ¡ï¼Œä¾‹å¦‚ç½‘æ ¼æ•°æ®åˆ†æžã€ä½“ç´ æ•°æ®åˆ†æžç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Parameter-efficient fine-tuning (PEFT) significantly reduces computational and memory costs by updating only a small subset of the model's parameters, enabling faster adaptation to new tasks with minimal loss in performance. Previous studies have introduced PEFTs tailored for point cloud data, as general approaches are suboptimal. To further reduce the number of trainable parameters, we propose a point-cloud-specific PEFT, termed Graph Features Tuning (GFT), which learns a dynamic graph from initial tokenized inputs of the transformer using a lightweight graph convolution network and passes these graph features to deeper layers via skip connections and efficient cross-attention modules. Extensive experiments on object classification and segmentation tasks show that GFT operates in the same domain, rivalling existing methods, while reducing the trainable parameters. Code is available at https://github.com/manishdhakal/GFT.

