---
layout: default
title: GFT: Graph Feature Tuning for Efficient Point Cloud Analysis
---

# GFT: Graph Feature Tuning for Efficient Point Cloud Analysis

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.10799" target="_blank" class="toolbar-btn">arXiv: 2511.10799v2</a>
    <a href="https://arxiv.org/pdf/2511.10799.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.10799v2" 
            onclick="toggleFavorite(this, '2511.10799v2', 'GFT: Graph Feature Tuning for Efficient Point Cloud Analysis')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Manish Dhakal, Venkat R. Dasari, Rajshekhar Sunderraman, Yi Ding

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-13 (æ›´æ–°: 2025-12-01)

**å¤‡æ³¨**: Accepted to WACV 2026

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/manishdhakal/GFT)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå›¾ç‰¹å¾è°ƒä¼˜(GFT)æ–¹æ³•ï¼Œé«˜æ•ˆåˆ†æç‚¹äº‘æ•°æ®å¹¶æ˜¾è‘—é™ä½å‚æ•°é‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `ç‚¹äº‘åˆ†æ` `å‚æ•°é«˜æ•ˆå¾®è°ƒ` `å›¾ç¥ç»ç½‘ç»œ` `Transformer` `ä¸‰ç»´é‡å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é€šç”¨PEFTæ–¹æ³•åœ¨ç‚¹äº‘æ•°æ®ä¸Šè¡¨ç°æ¬¡ä¼˜ï¼Œä¸”å‚æ•°é‡ä»ç„¶è¾ƒé«˜ï¼Œé™åˆ¶äº†å…¶åœ¨èµ„æºå—é™åœºæ™¯çš„åº”ç”¨ã€‚
2. GFTé€šè¿‡è½»é‡çº§å›¾å·ç§¯ç½‘ç»œå­¦ä¹ åŠ¨æ€å›¾ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨è·³è·ƒè¿æ¥å’Œé«˜æ•ˆäº¤å‰æ³¨æ„åŠ›æ¨¡å—ä¼ é€’åˆ°Transformeræ·±å±‚ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGFTåœ¨å¯¹è±¡åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ä¸Šä¸ç°æœ‰æ–¹æ³•æ€§èƒ½ç›¸å½“ï¼ŒåŒæ—¶æ˜¾è‘—å‡å°‘äº†å¯è®­ç»ƒå‚æ•°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‚æ•°é«˜æ•ˆå¾®è°ƒ(PEFT)é€šè¿‡ä»…æ›´æ–°æ¨¡å‹å‚æ•°çš„ä¸€å°éƒ¨åˆ†ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å’Œå†…å­˜æˆæœ¬ï¼Œä»è€Œèƒ½å¤Ÿä»¥æœ€å°çš„æ€§èƒ½æŸå¤±æ›´å¿«åœ°é€‚åº”æ–°ä»»åŠ¡ã€‚å…ˆå‰çš„ç ”ç©¶å·²ç»å¼•å…¥äº†ä¸ºç‚¹äº‘æ•°æ®é‡èº«å®šåˆ¶çš„PEFTï¼Œå› ä¸ºé€šç”¨æ–¹æ³•å¹¶éæœ€ä¼˜ã€‚ä¸ºäº†è¿›ä¸€æ­¥å‡å°‘å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç‰¹å®šäºç‚¹äº‘çš„PEFTï¼Œç§°ä¸ºå›¾ç‰¹å¾è°ƒä¼˜(GFT)ï¼Œå®ƒä½¿ç”¨è½»é‡çº§å›¾å·ç§¯ç½‘ç»œä»Transformerçš„åˆå§‹tokenizedè¾“å…¥ä¸­å­¦ä¹ åŠ¨æ€å›¾ï¼Œå¹¶é€šè¿‡è·³è·ƒè¿æ¥å’Œé«˜æ•ˆçš„äº¤å‰æ³¨æ„åŠ›æ¨¡å—å°†è¿™äº›å›¾ç‰¹å¾ä¼ é€’åˆ°æ›´æ·±å±‚ã€‚åœ¨å¯¹è±¡åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒGFTåœ¨åŒä¸€é¢†åŸŸå†…è¿è¡Œï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸åª²ç¾ï¼ŒåŒæ—¶å‡å°‘äº†å¯è®­ç»ƒå‚æ•°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç‚¹äº‘åˆ†æä¸­ï¼Œç°æœ‰å‚æ•°é«˜æ•ˆå¾®è°ƒ(PEFT)æ–¹æ³•ä»ç„¶éœ€è¦è¾ƒå¤§å‚æ•°é‡çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è™½ç„¶æ¯”å…¨å‚æ•°å¾®è°ƒå‡å°‘äº†å‚æ•°ï¼Œä½†åœ¨ç‚¹äº‘æ•°æ®ä¸Šä»æœ‰ä¼˜åŒ–ç©ºé—´ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„åœºæ™¯ä¸‹ï¼Œéœ€è¦è¿›ä¸€æ­¥é™ä½è®¡ç®—å’Œå­˜å‚¨æˆæœ¬ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å›¾ç¥ç»ç½‘ç»œ(GNN)å­¦ä¹ ç‚¹äº‘æ•°æ®çš„ç»“æ„ä¿¡æ¯ï¼Œå¹¶å°†è¿™äº›ç»“æ„ä¿¡æ¯ä½œä¸ºç‰¹å¾ä¼ é€’åˆ°Transformerçš„æ›´æ·±å±‚ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å¯ä»¥æ›´å¥½åœ°åˆ©ç”¨ç‚¹äº‘çš„å†…åœ¨å…³ç³»ï¼Œä»è€Œåœ¨æ›´å°‘çš„å‚æ•°ä¸‹è¾¾åˆ°ä¸ç°æœ‰æ–¹æ³•ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGFTçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) è¾“å…¥ç‚¹äº‘ç»è¿‡Tokenizationå¤„ç†ï¼›2) è½»é‡çº§å›¾å·ç§¯ç½‘ç»œ(GCN)ä»åˆå§‹tokenizedè¾“å…¥ä¸­å­¦ä¹ åŠ¨æ€å›¾ç»“æ„ï¼›3) å›¾ç‰¹å¾é€šè¿‡è·³è·ƒè¿æ¥ä¼ é€’åˆ°Transformerçš„æ›´æ·±å±‚ï¼›4) ä½¿ç”¨é«˜æ•ˆçš„äº¤å‰æ³¨æ„åŠ›æ¨¡å—èåˆå›¾ç‰¹å¾å’ŒTransformerç‰¹å¾ã€‚æ•´ä½“æµç¨‹æ˜¯å…ˆæå–ç‚¹äº‘çš„å±€éƒ¨ç‰¹å¾ï¼Œç„¶ååˆ©ç”¨GCNå­¦ä¹ å…¨å±€ç»“æ„ä¿¡æ¯ï¼Œæœ€åå°†ç»“æ„ä¿¡æ¯èå…¥åˆ°Transformerä¸­è¿›è¡Œåˆ†ç±»æˆ–åˆ†å‰²ã€‚

**å…³é”®åˆ›æ–°**ï¼šGFTçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§ç‰¹å®šäºç‚¹äº‘çš„PEFTæ–¹æ³•ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨ç‚¹äº‘çš„ç»“æ„ä¿¡æ¯ï¼›2) ä½¿ç”¨è½»é‡çº§GCNå­¦ä¹ åŠ¨æ€å›¾ç»“æ„ï¼Œé™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼›3) é€šè¿‡è·³è·ƒè¿æ¥å’Œé«˜æ•ˆäº¤å‰æ³¨æ„åŠ›æ¨¡å—ï¼Œæ›´å¥½åœ°èåˆäº†å›¾ç‰¹å¾å’ŒTransformerç‰¹å¾ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒGFTåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘äº†å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šGFTçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) è½»é‡çº§GCNçš„ç»“æ„è®¾è®¡ï¼Œä¾‹å¦‚å±‚æ•°ã€å·ç§¯æ ¸å¤§å°ç­‰ï¼›2) è·³è·ƒè¿æ¥çš„è¿æ¥æ–¹å¼ï¼Œä¾‹å¦‚è¿æ¥åˆ°å“ªäº›Transformerå±‚ï¼›3) äº¤å‰æ³¨æ„åŠ›æ¨¡å—çš„è®¾è®¡ï¼Œä¾‹å¦‚æ³¨æ„åŠ›å¤´çš„æ•°é‡ã€ç»´åº¦ç­‰ï¼›4) æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼Œä¾‹å¦‚æ˜¯å¦å¼•å…¥å›¾æ­£åˆ™åŒ–é¡¹ç­‰ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„éœ€è¦åœ¨å®éªŒä¸­è¿›è¡Œè°ƒæ•´å’Œä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGFTåœ¨å¯¹è±¡åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ä¸Šä¸ç°æœ‰PEFTæ–¹æ³•æ€§èƒ½ç›¸å½“ï¼Œç”šè‡³ç•¥æœ‰æå‡ï¼ŒåŒæ—¶æ˜¾è‘—å‡å°‘äº†å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ã€‚å…·ä½“æ¥è¯´ï¼ŒGFTåœ¨ModelNet40æ•°æ®é›†ä¸Šçš„åˆ†ç±»ç²¾åº¦ä¸ç°æœ‰æ–¹æ³•æŒå¹³ï¼Œä½†åœ¨ShapeNetæ•°æ®é›†ä¸Šçš„åˆ†å‰²ç²¾åº¦ç•¥æœ‰æå‡ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒGFTçš„å¯è®­ç»ƒå‚æ•°æ•°é‡æ¯”ç°æœ‰æ–¹æ³•å‡å°‘äº†çº¦30%-50%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GFTå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€ä¸‰ç»´é‡å»ºã€å·¥ä¸šæ£€æµ‹ç­‰é¢†åŸŸã€‚é€šè¿‡å‡å°‘æ¨¡å‹å‚æ•°é‡ï¼ŒGFTä½¿å¾—ç‚¹äº‘åˆ†ææ¨¡å‹æ›´å®¹æ˜“éƒ¨ç½²åˆ°èµ„æºå—é™çš„è®¾å¤‡ä¸Šï¼Œä¾‹å¦‚ç§»åŠ¨æœºå™¨äººã€æ— äººæœºç­‰ã€‚æœªæ¥ï¼ŒGFTå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–ä¸‰ç»´æ•°æ®å¤„ç†ä»»åŠ¡ï¼Œä¾‹å¦‚ç½‘æ ¼æ•°æ®åˆ†æã€ä½“ç´ æ•°æ®åˆ†æç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Parameter-efficient fine-tuning (PEFT) significantly reduces computational and memory costs by updating only a small subset of the model's parameters, enabling faster adaptation to new tasks with minimal loss in performance. Previous studies have introduced PEFTs tailored for point cloud data, as general approaches are suboptimal. To further reduce the number of trainable parameters, we propose a point-cloud-specific PEFT, termed Graph Features Tuning (GFT), which learns a dynamic graph from initial tokenized inputs of the transformer using a lightweight graph convolution network and passes these graph features to deeper layers via skip connections and efficient cross-attention modules. Extensive experiments on object classification and segmentation tasks show that GFT operates in the same domain, rivalling existing methods, while reducing the trainable parameters. Code is available at https://github.com/manishdhakal/GFT.

