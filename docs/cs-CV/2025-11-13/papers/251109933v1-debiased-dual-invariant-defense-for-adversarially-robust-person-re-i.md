---
layout: default
title: Debiased Dual-Invariant Defense for Adversarially Robust Person Re-Identification
---

# Debiased Dual-Invariant Defense for Adversarially Robust Person Re-Identification

**arXiv**: [2511.09933v1](https://arxiv.org/abs/2511.09933) | [PDF](https://arxiv.org/pdf/2511.09933.pdf)

**ä½œè€…**: Yuhang Zhou, Yanxiang Zhao, Zhongyun Hua, Zhipu Liu, Zhaoquan Gu, Qing Liao, Leo Yu Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŽ»ååŒä¸å˜é˜²å¾¡æ¡†æž¶ä»¥å¢žå¼ºè¡Œäººé‡è¯†åˆ«å¯¹æŠ—é²æ£’æ€§**

**å…³é”®è¯**: `è¡Œäººé‡è¯†åˆ«` `å¯¹æŠ—é˜²å¾¡` `åº¦é‡å­¦ä¹ ` `æ•°æ®å¹³è¡¡` `å¯¹æŠ—è®­ç»ƒ` `æ³›åŒ–èƒ½åŠ›`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè¡Œäººé‡è¯†åˆ«æ¨¡åž‹æ˜“å—å¯¹æŠ—æ”»å‡»ï¼ŒçŽ°æœ‰é˜²å¾¡æœªè§£å†³æ¨¡åž‹åè§å’Œå¤åˆæ³›åŒ–éœ€æ±‚ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ•°æ®å¹³è¡¡å’ŒåŒå¯¹æŠ—è‡ªå…ƒé˜²å¾¡ï¼Œç»“åˆæ‰©æ•£æ¨¡åž‹å’Œåº¦é‡å¯¹æŠ—è®­ç»ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒæ˜¾ç¤ºæ–¹æ³•æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰å…ˆè¿›é˜²å¾¡ï¼Œæå‡å¯¹æœªçŸ¥èº«ä»½å’Œæ”»å‡»ç±»åž‹çš„æ³›åŒ–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Person re-identification (ReID) is a fundamental task in many real-world applications such as pedestrian trajectory tracking. However, advanced deep learning-based ReID models are highly susceptible to adversarial attacks, where imperceptible perturbations to pedestrian images can cause entirely incorrect predictions, posing significant security threats. Although numerous adversarial defense strategies have been proposed for classification tasks, their extension to metric learning tasks such as person ReID remains relatively unexplored. Moreover, the several existing defenses for person ReID fail to address the inherent unique challenges of adversarially robust ReID. In this paper, we systematically identify the challenges of adversarial defense in person ReID into two key issues: model bias and composite generalization requirements. To address them, we propose a debiased dual-invariant defense framework composed of two main phases. In the data balancing phase, we mitigate model bias using a diffusion-model-based data resampling strategy that promotes fairness and diversity in training data. In the bi-adversarial self-meta defense phase, we introduce a novel metric adversarial training approach incorporating farthest negative extension softening to overcome the robustness degradation caused by the absence of classifier. Additionally, we introduce an adversarially-enhanced self-meta mechanism to achieve dual-generalization for both unseen identities and unseen attack types. Experiments demonstrate that our method significantly outperforms existing state-of-the-art defenses.

