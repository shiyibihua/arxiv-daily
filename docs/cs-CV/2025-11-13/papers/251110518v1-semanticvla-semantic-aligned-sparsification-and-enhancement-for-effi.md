---
layout: default
title: SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation
---

# SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.10518" target="_blank" class="toolbar-btn">arXiv: 2511.10518v1</a>
    <a href="https://arxiv.org/pdf/2511.10518.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.10518v1" 
            onclick="toggleFavorite(this, '2511.10518v1', 'SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Wei Li, Renshan Zhang, Rui Shao, Zhijian Fang, Kaiwen Zhou, Zhuotao Tian, Liqiang Nie

**ÂàÜÁ±ª**: cs.CV, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-13

**Â§áÊ≥®**: Accepted to AAAI 2026 (Oral), Project Page: https://github.com/JiuTian-VL/SemanticVLA

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/JiuTian-VL/SemanticVLA)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**SemanticVLAÔºöÈù¢ÂêëÈ´òÊïàÊú∫Âô®‰∫∫Êìç‰ΩúÁöÑËØ≠‰πâÂØπÈΩêÁ®ÄÁñèÂåñ‰∏éÂ¢ûÂº∫**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Êìç‰Ωú` `ËßÜËßâËØ≠Ë®ÄÂä®‰ΩúÊ®°Âûã` `ËØ≠‰πâÂØπÈΩê` `Á®ÄÁñèÂåñ` `ÁâπÂæÅËûçÂêà` `Ê∑±Â∫¶Â≠¶‰π†` `Êú∫Âô®‰∫∫ÊéßÂà∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLAÊ®°ÂûãÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠Â≠òÂú®ÊÑüÁü•ÂÜó‰ΩôÂíåÊåá‰ª§-ËßÜËßâÂØπÈΩê‰∏çË∂≥ÁöÑÈóÆÈ¢òÔºåÂØºËá¥ÊïàÁéá‰Ωé‰∏ãÂíåÊ≥õÂåñËÉΩÂäõÂº±„ÄÇ
2. SemanticVLAÈÄöËøáËØ≠‰πâÂØπÈΩêÁöÑÁ®ÄÁñèÂåñÂíåÂ¢ûÂº∫ÔºåÊúâÊïàÂáèÂ∞ëÂÜó‰Ωô‰ø°ÊÅØÔºåÂπ∂Â¢ûÂº∫ËØ≠‰πâ‰∏éÂä®‰ΩúÁöÑÂÖ≥ËÅîÔºåÊèêÂçáÊìç‰ΩúÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSemanticVLAÂú®LIBEROÂü∫ÂáÜÊµãËØï‰∏≠ÊòæËëóË∂ÖË∂äÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂Âú®ËÆ≠ÁªÉÂíåÊé®ÁêÜÊïàÁéá‰∏äÂùáÊúâÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãÂú®Êú∫Âô®‰∫∫Êìç‰ΩúÈ¢ÜÂüüÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜÂÆûÈôÖÈÉ®ÁΩ≤‰ªçÂèóÂà∞‰∏§‰∏™ÂÖ≥ÈîÆÈôêÂà∂ÁöÑÈòªÁ¢çÔºö1)ÊÑüÁü•ÂÜó‰ΩôÔºåÂç≥‰∏çÁõ∏ÂÖ≥ÁöÑËßÜËßâËæìÂÖ•Ë¢´‰ΩéÊïàÂ§ÑÁêÜÔºõ2)Ë°®Èù¢Êåá‰ª§-ËßÜËßâÂØπÈΩêÔºåÈòªÁ¢ç‰∫ÜÂä®‰ΩúÁöÑËØ≠‰πâÂü∫Á°Ä„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜSemanticVLAÔºå‰∏ÄÁßçÊñ∞È¢ñÁöÑVLAÊ°ÜÊû∂ÔºåÂÆÉÊâßË°åËØ≠‰πâÂØπÈΩêÁöÑÁ®ÄÁñèÂåñÂíåÂ¢ûÂº∫Ôºå‰ª•ÂÆûÁé∞È´òÊïàÁöÑÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºö1)‰∏∫‰∫ÜÂú®‰øùÊåÅËØ≠‰πâÂØπÈΩêÁöÑÂêåÊó∂Á®ÄÁñèÂåñÂÜó‰ΩôÊÑüÁü•ÔºåËØ≠‰πâÂºïÂØºÁöÑÂèåËßÜËßâ‰øÆÂâ™Âô®(SD-Pruner)ÊâßË°åÔºöÊåá‰ª§È©±Âä®ÁöÑ‰øÆÂâ™Âô®(ID-Pruner)ÊèêÂèñSigLIP‰∏≠ÁöÑÂÖ®Â±ÄÂä®‰ΩúÁ∫øÁ¥¢ÂíåÂ±ÄÈÉ®ËØ≠‰πâÈîöÁÇπÔºõÁ©∫Èó¥ËÅöÂêà‰øÆÂâ™Âô®(SA-Pruner)Â∞ÜÂá†‰Ωï‰∏∞ÂØåÁöÑÁâπÂæÅÂéãÁº©‰∏∫DINOv2‰∏≠ÁöÑ‰ªªÂä°Ëá™ÈÄÇÂ∫îtokens„ÄÇ2)‰∏∫‰∫ÜÂà©Áî®Á®ÄÁñèÂåñÁöÑÁâπÂæÅÂπ∂Â∞ÜËØ≠‰πâ‰∏éÁ©∫Èó¥Âá†‰ΩïÁõ∏ÁªìÂêàÔºåËØ≠‰πâ‰∫íË°•ÁöÑÂàÜÂ±ÇËûçÂêàÂô®(SH-Fuser)ËûçÂêàSigLIPÂíåDINOv2‰∏≠ÁöÑÂØÜÈõÜpatchesÂíåÁ®ÄÁñètokensÔºå‰ª•ÂÆûÁé∞ËøûË¥ØÁöÑË°®Á§∫„ÄÇ3)‰∏∫‰∫ÜÂ¢ûÂº∫‰ªéÊÑüÁü•Âà∞Âä®‰ΩúÁöÑËΩ¨Êç¢ÔºåËØ≠‰πâÊù°‰ª∂Âä®‰ΩúËÄ¶ÂêàÂô®(SA-Coupler)Âèñ‰ª£‰∫Ü‰º†ÁªüÁöÑËßÇÂØüÂà∞Ëá™Áî±Â∫¶(DoF)ÁöÑÊñπÊ≥ïÔºå‰ªéËÄå‰∏∫Êìç‰Ωú‰ªªÂä°‰∫ßÁîüÊõ¥È´òÊïàÂíåÂèØËß£ÈáäÁöÑË°å‰∏∫Âª∫Ê®°„ÄÇÂú®Ê®°ÊãüÂíåÁúüÂÆû‰∏ñÁïå‰ªªÂä°‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåSemanticVLAÂú®ÊÄßËÉΩÂíåÊïàÁéáÊñπÈù¢ÈÉΩÂàõÈÄ†‰∫ÜÊñ∞ÁöÑSOTA„ÄÇÂú®LIBEROÂü∫ÂáÜÊµãËØï‰∏≠ÔºåSemanticVLAÁöÑÊàêÂäüÁéáË∂ÖËøáOpenVLA 21.1%ÔºåÂêåÊó∂ËÆ≠ÁªÉÊàêÊú¨ÂíåÊé®ÁêÜÂª∂ËøüÂàÜÂà´Èôç‰Ωé‰∫Ü3.0ÂÄçÂíå2.7ÂÄç„ÄÇSemanticVLAÂ∑≤ÂºÄÊ∫êÔºåÂèØÂú®https://github.com/JiuTian-VL/SemanticVLAÂÖ¨ÂºÄËé∑Âèñ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâVLAÊ®°ÂûãÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠Èù¢‰∏¥ÁùÄ‰∏§‰∏™‰∏ªË¶ÅÈóÆÈ¢òÔºö‰∏ÄÊòØËßÜËßâÊÑüÁü•ÁöÑÂÜó‰ΩôÔºåÂç≥Ê®°ÂûãÈúÄË¶ÅÂ§ÑÁêÜÂ§ßÈáè‰∏éÂΩìÂâç‰ªªÂä°Êó†ÂÖ≥ÁöÑËßÜËßâ‰ø°ÊÅØÔºåÂØºËá¥ËÆ°ÁÆóËµÑÊ∫êÁöÑÊµ™Ë¥πÔºõ‰∫åÊòØÊåá‰ª§ÂíåËßÜËßâ‰ø°ÊÅØ‰πãÈó¥ÁöÑÂØπÈΩê‰∏çÂ§üÂÖÖÂàÜÔºå‰ΩøÂæóÊ®°ÂûãÈöæ‰ª•ÂáÜÁ°ÆÁêÜËß£Êåá‰ª§ÁöÑËØ≠‰πâÔºå‰ªéËÄåÂΩ±ÂìçÊìç‰ΩúÁöÑÁ≤æÂ∫¶ÂíåÊïàÁéá„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈááÁî®Á´ØÂà∞Á´ØÁöÑËÆ≠ÁªÉÊñπÂºèÔºåÁº∫‰πèÂØπËßÜËßâ‰ø°ÊÅØÁöÑÈÄâÊã©ÊÄßÂ§ÑÁêÜÂíåÂØπËØ≠‰πâ‰ø°ÊÅØÁöÑÊúâÊïàÂà©Áî®ÔºåÂØºËá¥Ê®°ÂûãÈöæ‰ª•Âú®Â§çÊùÇÁéØÂ¢É‰∏≠Ê≥õÂåñ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSemanticVLAÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáËØ≠‰πâÂØπÈΩêÁöÑÁ®ÄÁñèÂåñÂíåÂ¢ûÂº∫Êù•Ëß£ÂÜ≥‰∏äËø∞ÈóÆÈ¢ò„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈ¶ñÂÖàÈÄöËøáËØ≠‰πâÂºïÂØºÁöÑÂèåËßÜËßâ‰øÆÂâ™Âô®(SD-Pruner)Êù•ÂáèÂ∞ëËßÜËßâ‰ø°ÊÅØÁöÑÂÜó‰ΩôÔºåÂêåÊó∂‰øùÁïôÂÖ≥ÈîÆÁöÑËØ≠‰πâ‰ø°ÊÅØ„ÄÇÁÑ∂ÂêéÔºåÈÄöËøáËØ≠‰πâ‰∫íË°•ÁöÑÂàÜÂ±ÇËûçÂêàÂô®(SH-Fuser)Â∞ÜÁ®ÄÁñèÂåñÁöÑËßÜËßâÁâπÂæÅ‰∏éËØ≠‰πâ‰ø°ÊÅØËøõË°åËûçÂêàÔºå‰ªéËÄåÂæóÂà∞Êõ¥ÂÖ∑Ë°®ËææÂäõÁöÑË°®Á§∫„ÄÇÊúÄÂêéÔºåÈÄöËøáËØ≠‰πâÊù°‰ª∂Âä®‰ΩúËÄ¶ÂêàÂô®(SA-Coupler)Â∞ÜËûçÂêàÂêéÁöÑË°®Á§∫Êò†Â∞ÑÂà∞Âä®‰ΩúÁ©∫Èó¥Ôºå‰ªéËÄåÂÆûÁé∞È´òÊïàÁöÑÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSemanticVLAÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöSD-Pruner„ÄÅSH-FuserÂíåSA-Coupler„ÄÇSD-PrunerË¥üË¥£ÂØπËßÜËßâ‰ø°ÊÅØËøõË°åÁ®ÄÁñèÂåñÔºåÂåÖÊã¨ID-PrunerÂíåSA-Pruner‰∏§‰∏™Â≠êÊ®°ÂùóÔºåÂàÜÂà´‰ªéÊåá‰ª§ÂíåÁ©∫Èó¥Âá†‰ΩïÁöÑËßíÂ∫¶ËøõË°å‰øÆÂâ™„ÄÇSH-FuserË¥üË¥£Â∞ÜÁ®ÄÁñèÂåñÁöÑËßÜËßâÁâπÂæÅ‰∏éËØ≠‰πâ‰ø°ÊÅØËøõË°åËûçÂêàÔºåÈááÁî®ÂàÜÂ±ÇËûçÂêàÁöÑÊñπÂºèÔºåÈÄêÊ≠•Â∞Ü‰∏çÂêåÂ∞∫Â∫¶ÁöÑÁâπÂæÅËøõË°åÊï¥Âêà„ÄÇSA-CouplerË¥üË¥£Â∞ÜËûçÂêàÂêéÁöÑË°®Á§∫Êò†Â∞ÑÂà∞Âä®‰ΩúÁ©∫Èó¥ÔºåÈááÁî®ËØ≠‰πâÊù°‰ª∂ÁöÑÊñπÂºèÔºåÊ†πÊçÆ‰∏çÂêåÁöÑËØ≠‰πâ‰ø°ÊÅØÁîüÊàê‰∏çÂêåÁöÑÂä®‰Ωú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSemanticVLAÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜËØ≠‰πâÂØπÈΩêÁöÑÁ®ÄÁñèÂåñÂíåÂ¢ûÂº∫Á≠ñÁï•„ÄÇ‰º†ÁªüÁöÑVLAÊ®°ÂûãÈÄöÂ∏∏Áõ¥Êé•Â∞ÜÊâÄÊúâËßÜËßâ‰ø°ÊÅØËæìÂÖ•Âà∞Ê®°Âûã‰∏≠ÔºåËÄåSemanticVLAÂàôÈÄöËøáSD-PrunerÈÄâÊã©ÊÄßÂú∞‰øùÁïô‰∏éÂΩìÂâç‰ªªÂä°Áõ∏ÂÖ≥ÁöÑËßÜËßâ‰ø°ÊÅØÔºå‰ªéËÄåÂáèÂ∞ë‰∫ÜËÆ°ÁÆóËµÑÊ∫êÁöÑÊµ™Ë¥π„ÄÇÊ≠§Â§ñÔºåSemanticVLAËøòÈÄöËøáSH-FuserÂ∞ÜËßÜËßâÁâπÂæÅ‰∏éËØ≠‰πâ‰ø°ÊÅØËøõË°åËûçÂêàÔºå‰ªéËÄåÂ¢ûÂº∫‰∫ÜÊ®°ÂûãÂØπÊåá‰ª§ÁöÑÁêÜËß£ËÉΩÂäõ„ÄÇSA-CouplerÂàôÈÄöËøáËØ≠‰πâÊù°‰ª∂ÁöÑÊñπÂºèÔºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÊ†πÊçÆ‰∏çÂêåÁöÑËØ≠‰πâ‰ø°ÊÅØÁîüÊàê‰∏çÂêåÁöÑÂä®‰ΩúÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊìç‰ΩúÁöÑÁ≤æÂ∫¶ÂíåÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöSD-Pruner‰∏≠ÁöÑID-PrunerÂà©Áî®SigLIPÊ®°ÂûãÊèêÂèñÂÖ®Â±ÄÂä®‰ΩúÁ∫øÁ¥¢ÂíåÂ±ÄÈÉ®ËØ≠‰πâÈîöÁÇπÔºåSA-PrunerÂà©Áî®DINOv2Ê®°ÂûãÊèêÂèñÂá†‰Ωï‰∏∞ÂØåÁöÑÁâπÂæÅÔºåÂπ∂Â∞ÜËøô‰∫õÁâπÂæÅÂéãÁº©‰∏∫‰ªªÂä°Ëá™ÈÄÇÂ∫îÁöÑtokens„ÄÇSH-FuserÈááÁî®ÂàÜÂ±ÇËûçÂêàÁöÑÊñπÂºèÔºåÈÄêÊ≠•Â∞ÜSigLIPÂíåDINOv2ÁöÑÁâπÂæÅËøõË°åÊï¥Âêà„ÄÇSA-CouplerÈááÁî®ËØ≠‰πâÊù°‰ª∂ÁöÑÊñπÂºèÔºåÊ†πÊçÆ‰∏çÂêåÁöÑËØ≠‰πâ‰ø°ÊÅØÁîüÊàê‰∏çÂêåÁöÑÂä®‰Ωú„ÄÇÊçüÂ§±ÂáΩÊï∞ÊñπÈù¢ÔºåÈááÁî®‰∫ÜÊ†áÂáÜÁöÑ‰∫§ÂèâÁÜµÊçüÂ§±ÂáΩÊï∞ÂíåÂõûÂΩíÊçüÂ§±ÂáΩÊï∞ÔºåÁî®‰∫é‰ºòÂåñÊ®°ÂûãÁöÑÂèÇÊï∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SemanticVLAÂú®LIBEROÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÊàêÂäüÁéáË∂ÖËøáOpenVLA 21.1%ÔºåÂêåÊó∂ËÆ≠ÁªÉÊàêÊú¨ÂíåÊé®ÁêÜÂª∂ËøüÂàÜÂà´Èôç‰Ωé‰∫Ü3.0ÂÄçÂíå2.7ÂÄç„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåSemanticVLAÂú®ÊÄßËÉΩÂíåÊïàÁéáÊñπÈù¢ÈÉΩÂÖ∑ÊúâÊòæËëó‰ºòÂäøÔºå‰∏∫Êú∫Âô®‰∫∫Êìç‰ΩúÈ¢ÜÂüüÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÊñ∞ÁöÑÊÄùË∑Ø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SemanticVLAÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÂ∫îÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°ÔºåÂ¶ÇÁâ©‰ΩìÊäìÂèñ„ÄÅË£ÖÈÖç„ÄÅÂØºËà™Á≠â„ÄÇËØ•Á†îÁ©∂ÊàêÊûúÊúâÂä©‰∫éÊèêÈ´òÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊìç‰ΩúÊïàÁéáÂíåÁ≤æÂ∫¶ÔºåÈôç‰ΩéËÆ°ÁÆóÊàêÊú¨ÔºåÂπ∂‰∏∫Êú™Êù•ÁöÑÊú∫Âô®‰∫∫Êô∫ËÉΩÂåñÂèëÂ±ïÂ•†ÂÆöÂü∫Á°Ä„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Êé®ÂπøÂà∞ÂÖ∂‰ªñËßÜËßâ-ËØ≠Ë®Ä‰ªªÂä°‰∏≠ÔºåÂ¶ÇÂõæÂÉèÊèèËø∞„ÄÅËßÜËßâÈóÆÁ≠îÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-Language-Action (VLA) models have advanced in robotic manipulation, yet practical deployment remains hindered by two key limitations: 1) perceptual redundancy, where irrelevant visual inputs are processed inefficiently, and 2) superficial instruction-vision alignment, which hampers semantic grounding of actions. In this paper, we propose SemanticVLA, a novel VLA framework that performs Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation. Specifically: 1) To sparsify redundant perception while preserving semantic alignment, Semantic-guided Dual Visual Pruner (SD-Pruner) performs: Instruction-driven Pruner (ID-Pruner) extracts global action cues and local semantic anchors in SigLIP; Spatial-aggregation Pruner (SA-Pruner) compacts geometry-rich features into task-adaptive tokens in DINOv2. 2) To exploit sparsified features and integrate semantics with spatial geometry, Semantic-complementary Hierarchical Fuser (SH-Fuser) fuses dense patches and sparse tokens across SigLIP and DINOv2 for coherent representation. 3) To enhance the transformation from perception to action, Semantic-conditioned Action Coupler (SA-Coupler) replaces the conventional observation-to-DoF approach, yielding more efficient and interpretable behavior modeling for manipulation tasks. Extensive experiments on simulation and real-world tasks show that SemanticVLA sets a new SOTA in both performance and efficiency. SemanticVLA surpasses OpenVLA on LIBERO benchmark by 21.1% in success rate, while reducing training cost and inference latency by 3.0-fold and 2.7-fold.SemanticVLA is open-sourced and publicly available at https://github.com/JiuTian-VL/SemanticVLA

