---
layout: default
title: Adaptive Residual-Update Steering for Low-Overhead Hallucination Mitigation in Large Vision Language Models
---

# Adaptive Residual-Update Steering for Low-Overhead Hallucination Mitigation in Large Vision Language Models

**arXiv**: [2511.10292v1](https://arxiv.org/abs/2511.10292) | [PDF](https://arxiv.org/pdf/2511.10292.pdf)

**ä½œè€…**: Zhengtao Zou, Ya Gao, Jiarui Guan, Bin Li, Pekka Marttinen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRUDDERæ¡†æž¶ä»¥ä½Žå¼€é”€ç¼“è§£å¤§è§†è§‰è¯­è¨€æ¨¡åž‹ä¸­çš„ç‰©ä½“å¹»è§‰é—®é¢˜**

**å…³é”®è¯**: `å¤§è§†è§‰è¯­è¨€æ¨¡åž‹` `ç‰©ä½“å¹»è§‰ç¼“è§£` `ä½Žå¼€é”€æŽ¨ç†` `è‡ªé€‚åº”é—¨æŽ§` `è§†è§‰è¯æ®æå–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è§†è§‰è¯­è¨€æ¨¡åž‹å¸¸äº§ç”Ÿä¸Žè§†è§‰è¾“å…¥ä¸ä¸€è‡´çš„ç‰©ä½“å¹»è§‰ï¼Œå½±å“å¯é æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡CARDå‘é‡å’Œè‡ªé€‚åº”é—¨æŽ§ï¼Œåœ¨å•æ¬¡å‰å‘ä¼ æ’­ä¸­æ³¨å…¥è§†è§‰è¯æ®ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨POPEå’ŒCHAIRåŸºå‡†ä¸Šæ€§èƒ½åª²ç¾ŽSOTAï¼Œè®¡ç®—å»¶è¿Ÿå¯å¿½ç•¥ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Vision-Language Models (LVLMs) often suffer from object hallucination, generating text inconsistent with visual inputs, which can critically undermine their reliability. Existing inference-time interventions to mitigate this issue present a challenging trade-off: while methods that steer internal states or adjust output logits can be effective, they often incur substantial computational overhead, typically requiring extra forward passes. This efficiency bottleneck can limit their practicality for real-world, latency-sensitive deployments. In this work, we aim to address this trade-off with Residual-Update Directed DEcoding Regulation (RUDDER), a low-overhead framework that steers LVLMs towards visually-grounded generation. RUDDER is built on two key innovations: (1) Contextual Activation Residual Direction (CARD) vector, a per-sample visual evidence vector extracted from the residual update of a self-attention layer during a single, standard forward pass. (2) A Bayesian-inspired adaptive gate that performs token-wise injection, applying a corrective signal whose strength is conditioned on the model's deviation from the visual context. Extensive experiments on key hallucination benchmarks, including POPE and CHAIR, indicate that RUDDER achieves performance comparable to state-of-the-art methods while introducing negligible computational latency, validating RUDDER as a pragmatic and effective approach for improving LVLMs' reliability without a significant compromise on efficiency.

