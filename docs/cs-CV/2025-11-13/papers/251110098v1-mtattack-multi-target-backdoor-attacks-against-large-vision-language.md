---
layout: default
title: MTAttack: Multi-Target Backdoor Attacks against Large Vision-Language Models
---

# MTAttack: Multi-Target Backdoor Attacks against Large Vision-Language Models

**arXiv**: [2511.10098v1](https://arxiv.org/abs/2511.10098) | [PDF](https://arxiv.org/pdf/2511.10098.pdf)

**ä½œè€…**: Zihan Wang, Guansong Pang, Wenjun Miao, Jin Zheng, Xiao Bai

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMTAttackæ¡†æž¶ä»¥è§£å†³å¤§è§†è§‰è¯­è¨€æ¨¡åž‹ä¸­çš„å¤šç›®æ ‡åŽé—¨æ”»å‡»é—®é¢˜**

**å…³é”®è¯**: `å¤§è§†è§‰è¯­è¨€æ¨¡åž‹` `åŽé—¨æ”»å‡»` `å¤šç›®æ ‡æ”»å‡»` `è§¦å‘å™¨ä¼˜åŒ–` `ä»£ç†ç©ºé—´åˆ’åˆ†` `å®‰å…¨æ¼æ´ž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰åŽé—¨æ”»å‡»ä»…é’ˆå¯¹å•ä¸€ç›®æ ‡ï¼Œå¤šç›®æ ‡æ”»å‡»å› ç‰¹å¾å¹²æ‰°éš¾ä»¥å®žçŽ°å‡†ç¡®æ˜ å°„ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥ä»£ç†ç©ºé—´åˆ’åˆ†å’Œè§¦å‘å™¨åŽŸåž‹é”šå®šçº¦æŸï¼Œè”åˆä¼˜åŒ–å¤šä¸ªè§¦å‘å™¨ä»¥ç‹¬ç«‹æ˜ å°„åˆ°å”¯ä¸€ä»£ç†ç±»ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨åŸºå‡†æµ‹è¯•ä¸­å®žçŽ°é«˜æˆåŠŸçŽ‡ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶å±•ç¤ºè·¨æ•°æ®é›†æ³›åŒ–æ€§å’Œé˜²å¾¡é²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in Large Visual Language Models (LVLMs) have demonstrated impressive performance across various vision-language tasks by leveraging large-scale image-text pretraining and instruction tuning. However, the security vulnerabilities of LVLMs have become increasingly concerning, particularly their susceptibility to backdoor attacks. Existing backdoor attacks focus on single-target attacks, i.e., targeting a single malicious output associated with a specific trigger. In this work, we uncover multi-target backdoor attacks, where multiple independent triggers corresponding to different attack targets are added in a single pass of training, posing a greater threat to LVLMs in real-world applications. Executing such attacks in LVLMs is challenging since there can be many incorrect trigger-target mappings due to severe feature interference among different triggers. To address this challenge, we propose MTAttack, the first multi-target backdoor attack framework for enforcing accurate multiple trigger-target mappings in LVLMs. The core of MTAttack is a novel optimization method with two constraints, namely Proxy Space Partitioning constraint and Trigger Prototype Anchoring constraint. It jointly optimizes multiple triggers in the latent space, with each trigger independently mapping clean images to a unique proxy class while at the same time guaranteeing their separability. Experiments on popular benchmarks demonstrate a high success rate of MTAttack for multi-target attacks, substantially outperforming existing attack methods. Furthermore, our attack exhibits strong generalizability across datasets and robustness against backdoor defense strategies. These findings highlight the vulnerability of LVLMs to multi-target backdoor attacks and underscore the urgent need for mitigating such threats. Code is available at https://github.com/mala-lab/MTAttack.

