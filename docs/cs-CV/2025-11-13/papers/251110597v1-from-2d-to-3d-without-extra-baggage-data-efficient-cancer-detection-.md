---
layout: default
title: From 2D to 3D Without Extra Baggage: Data-Efficient Cancer Detection in Digital Breast Tomosynthesis
---

# From 2D to 3D Without Extra Baggage: Data-Efficient Cancer Detection in Digital Breast Tomosynthesis

**arXiv**: [2511.10597v1](https://arxiv.org/abs/2511.10597) | [PDF](https://arxiv.org/pdf/2511.10597.pdf)

**ä½œè€…**: Yen Nhi Truong Vu, Dan Guo, Sripad Joshi, Harshit Kumar, Jason Su, Thomas Paul Matthews

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºM&M-3Dæž¶æž„ï¼Œå®žçŽ°æ•°æ®é«˜æ•ˆ3DæŽ¨ç†ä»¥æ”¹è¿›æ•°å­—ä¹³è…ºæ–­å±‚åˆæˆç™Œç—‡æ£€æµ‹**

**å…³é”®è¯**: `æ•°å­—ä¹³è…ºæ–­å±‚åˆæˆ` `3DæŽ¨ç†` `æ•°æ®é«˜æ•ˆå­¦ä¹ ` `ç™Œç—‡æ£€æµ‹` `å‚æ•°è¿ç§»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ•°å­—ä¹³è…ºæ–­å±‚åˆæˆä¸­æ ‡æ³¨æ•°æ®ç¨€ç¼ºï¼ŒçŽ°æœ‰æ–¹æ³•ä¸¢å¼ƒä½“ç§¯ä¿¡æ¯æˆ–éœ€å¤§é‡æ•°æ®
2. æ–¹æ³•è¦ç‚¹ï¼šM&M-3Dé€šè¿‡æ··åˆ3Dç‰¹å¾ä¸Žåˆ‡ç‰‡ä¿¡æ¯å®žçŽ°å¯å­¦ä¹ 3DæŽ¨ç†ï¼Œæ— éœ€é¢å¤–å‚æ•°
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä½Žæ•°æ®ä¸‹ä¼˜äºŽåŸºçº¿æ–¹æ³•ï¼Œåˆ†ç±»å’Œå®šä½æ€§èƒ½æå‡2-54%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Digital Breast Tomosynthesis (DBT) enhances finding visibility for breast cancer detection by providing volumetric information that reduces the impact of overlapping tissues; however, limited annotated data has constrained the development of deep learning models for DBT. To address data scarcity, existing methods attempt to reuse 2D full-field digital mammography (FFDM) models by either flattening DBT volumes or processing slices individually, thus discarding volumetric information. Alternatively, 3D reasoning approaches introduce complex architectures that require more DBT training data. Tackling these drawbacks, we propose M&M-3D, an architecture that enables learnable 3D reasoning while remaining parameter-free relative to its FFDM counterpart, M&M. M&M-3D constructs malignancy-guided 3D features, and 3D reasoning is learned through repeatedly mixing these 3D features with slice-level information. This is achieved by modifying operations in M&M without adding parameters, thus enabling direct weight transfer from FFDM. Extensive experiments show that M&M-3D surpasses 2D projection and 3D slice-based methods by 11-54% for localization and 3-10% for classification. Additionally, M&M-3D outperforms complex 3D reasoning variants by 20-47% for localization and 2-10% for classification in the low-data regime, while matching their performance in high-data regime. On the popular BCS-DBT benchmark, M&M-3D outperforms previous top baseline by 4% for classification and 10% for localization.

