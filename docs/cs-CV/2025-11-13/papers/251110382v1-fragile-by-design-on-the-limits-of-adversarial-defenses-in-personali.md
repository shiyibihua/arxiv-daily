---
layout: default
title: Fragile by Design: On the Limits of Adversarial Defenses in Personalized Generation
---

# Fragile by Design: On the Limits of Adversarial Defenses in Personalized Generation

**arXiv**: [2511.10382v1](https://arxiv.org/abs/2511.10382) | [PDF](https://arxiv.org/pdf/2511.10382.pdf)

**ä½œè€…**: Zhen Chen, Yi Zhang, Xiangyu Yin, Chengxuan Qin, Xingyu Zhao, Xiaowei Huang, Wenjie Ruan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºä¸ªæ€§åŒ–ç”Ÿæˆä¸­å¯¹æŠ—é˜²å¾¡çš„è„†å¼±æ€§ï¼Œæå‡ºè¯„ä¼°æ¡†æž¶ä»¥æµ‹è¯•å‡€åŒ–å¨èƒã€‚**

**å…³é”®è¯**: `ä¸ªæ€§åŒ–ç”Ÿæˆ` `å¯¹æŠ—é˜²å¾¡` `éšç§ä¿æŠ¤` `å›¾åƒå‡€åŒ–` `èº«ä»½æ³„éœ²` `è¯„ä¼°æ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¸ªæ€§åŒ–AIåº”ç”¨å¦‚DreamBoothå­˜åœ¨é¢éƒ¨èº«ä»½æ³„éœ²éšç§é£Žé™©ï¼ŒçŽ°æœ‰é˜²å¾¡æœºåˆ¶æ˜“è¢«æ£€æµ‹å’Œç§»é™¤ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºAntiDB_Purifyæ¡†æž¶ï¼Œç³»ç»Ÿè¯„ä¼°é˜²å¾¡æ–¹æ³•åœ¨ä¼ ç»Ÿå›¾åƒè¿‡æ»¤å’Œå¯¹æŠ—å‡€åŒ–ä¸‹çš„æœ‰æ•ˆæ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç»“æžœæ˜¾ç¤ºå½“å‰é˜²å¾¡æ–¹æ³•åœ¨å‡€åŒ–å¨èƒä¸‹å‡å¤±æ•ˆï¼Œå¼ºè°ƒéœ€æ›´éšè”½å’Œé²æ£’çš„ä¿æŠ¤æŽªæ–½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Personalized AI applications such as DreamBooth enable the generation of customized content from user images, but also raise significant privacy concerns, particularly the risk of facial identity leakage. Recent defense mechanisms like Anti-DreamBooth attempt to mitigate this risk by injecting adversarial perturbations into user photos to prevent successful personalization. However, we identify two critical yet overlooked limitations of these methods. First, the adversarial examples often exhibit perceptible artifacts such as conspicuous patterns or stripes, making them easily detectable as manipulated content. Second, the perturbations are highly fragile, as even a simple, non-learned filter can effectively remove them, thereby restoring the model's ability to memorize and reproduce user identity. To investigate this vulnerability, we propose a novel evaluation framework, AntiDB_Purify, to systematically evaluate existing defenses under realistic purification threats, including both traditional image filters and adversarial purification. Results reveal that none of the current methods maintains their protective effectiveness under such threats. These findings highlight that current defenses offer a false sense of security and underscore the urgent need for more imperceptible and robust protections to safeguard user identity in personalized generation.

