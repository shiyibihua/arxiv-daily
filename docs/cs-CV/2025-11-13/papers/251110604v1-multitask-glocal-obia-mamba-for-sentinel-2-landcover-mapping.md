---
layout: default
title: Multitask GLocal OBIA-Mamba for Sentinel-2 Landcover Mapping
---

# Multitask GLocal OBIA-Mamba for Sentinel-2 Landcover Mapping

**arXiv**: [2511.10604v1](https://arxiv.org/abs/2511.10604) | [PDF](https://arxiv.org/pdf/2511.10604.pdf)

**ä½œè€…**: Zack Dewis, Yimin Zhu, Zhengsen Xu, Mabel Heffring, Saeid Taleghanidoozdoozan, Kaylee Xiao, Motasem Alkayid, Lincoln Linlin Xu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šä»»åŠ¡å…¨å±€-å±€éƒ¨OBIA-Mambaæ¨¡åž‹ä»¥å¢žå¼ºSentinel-2åœŸåœ°è¦†ç›–åˆ†ç±»**

**å…³é”®è¯**: `åœŸåœ°è¦†ç›–åˆ†ç±»` `å¤šä»»åŠ¡å­¦ä¹ ` `Mambaæ¨¡åž‹` `å¯¹è±¡å›¾åƒåˆ†æž` `å…¨å±€-å±€éƒ¨æž¶æž„` `Sentinel-2å½±åƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. Sentinel-2åœŸåœ°è¦†ç›–åˆ†ç±»é¢ä¸´ç©ºé—´å¼‚è´¨æ€§å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ç­‰æ•°æ®æŒ‘æˆ˜
2. è®¾è®¡OBIA-Mambaæ¨¡åž‹ä½¿ç”¨è¶…åƒç´ ä½œä¸ºMambaä»¤ç‰Œï¼Œå‡å°‘å†—ä½™è®¡ç®—å¹¶ä¿ç•™ç»†èŠ‚
3. åœ¨åŠ æ‹¿å¤§é˜¿å°”ä¼¯å¡”æµ‹è¯•ï¼Œç›¸æ¯”å…ˆè¿›æ–¹æ³•ï¼Œåˆ†ç±»ç²¾åº¦æ›´é«˜ã€ç»†èŠ‚æ›´ç²¾ç»†

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Although Sentinel-2 based land use and land cover (LULC) classification is critical for various environmental monitoring applications, it is a very difficult task due to some key data challenges (e.g., spatial heterogeneity, context information, signature ambiguity). This paper presents a novel Multitask Glocal OBIA-Mamba (MSOM) for enhanced Sentinel-2 classification with the following contributions. First, an object-based image analysis (OBIA) Mamba model (OBIA-Mamba) is designed to reduce redundant computation without compromising fine-grained details by using superpixels as Mamba tokens. Second, a global-local (GLocal) dual-branch convolutional neural network (CNN)-mamba architecture is designed to jointly model local spatial detail and global contextual information. Third, a multitask optimization framework is designed to employ dual loss functions to balance local precision with global consistency. The proposed approach is tested on Sentinel-2 imagery in Alberta, Canada, in comparison with several advanced classification approaches, and the results demonstrate that the proposed approach achieves higher classification accuracy and finer details that the other state-of-the-art methods.

