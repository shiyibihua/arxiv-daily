---
layout: default
title: HCC-3D: Hierarchical Compensatory Compression for 98% 3D Token Reduction in Vision-Language Models
---

# HCC-3D: Hierarchical Compensatory Compression for 98% 3D Token Reduction in Vision-Language Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.09883" target="_blank" class="toolbar-btn">arXiv: 2511.09883v1</a>
    <a href="https://arxiv.org/pdf/2511.09883.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.09883v1" 
            onclick="toggleFavorite(this, '2511.09883v1', 'HCC-3D: Hierarchical Compensatory Compression for 98% 3D Token Reduction in Vision-Language Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Liheng Zhang, Jin Wang, Hui Li, Bingfeng Zhang, Weifeng Liu

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-13

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫HCC-3DÔºåÈÄöËøáÂàÜÂ±ÇË°•ÂÅøÂéãÁº©ÂÆûÁé∞3DËßÜËßâËØ≠Ë®ÄÊ®°Âûã‰∏≠98%ÁöÑTokenÁº©Âáè**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `3DËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `ÁÇπ‰∫ëÂ§ÑÁêÜ` `TokenÂéãÁº©` `ÂàÜÂ±ÇÂéãÁº©` `Ëá™ÈÄÇÂ∫îÁªÜËäÇÊåñÊéò`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3D-VLMsÁõ¥Êé•Â§ÑÁêÜÂ§ßÈáè3D tokensÂØºËá¥ËÆ°ÁÆóÊàêÊú¨È´òÊòÇÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®Ôºå‰∫üÈúÄÈ´òÊïàÁöÑ3D tokenÂéãÁº©ÊñπÊ≥ï„ÄÇ
2. HCC-3DÈÄöËøáÂÖ®Â±ÄÁªìÊûÑÂéãÁº©‰øùÁïôÊï¥‰ΩìÁªìÊûÑ‰ø°ÊÅØÔºåÂπ∂Âà©Áî®Ëá™ÈÄÇÂ∫îÁªÜËäÇÊåñÊéòË°•ÂÅøÂéãÁº©ËøáÁ®ã‰∏≠ÁöÑ‰ø°ÊÅØÊçüÂ§±„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåHCC-3DÂÆûÁé∞‰∫Ü98%ÁöÑtokenÂéãÁº©ÁéáÔºåÂπ∂Âú®Â§ö‰∏™‰ªªÂä°‰∏äÂèñÂæó‰∫Üstate-of-the-artÁöÑÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫ÂàÜÂ±ÇË°•ÂÅøÂéãÁº©ÔºàHCC-3DÔºâÁöÑÊñπÊ≥ïÔºåÊó®Âú®È´òÊïàÂéãÁº©3DËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàVLMsÔºâ‰∏≠ÁöÑ3D tokensÔºåÂêåÊó∂‰øùÁïôÂÖ≥ÈîÆÁªÜËäÇ‰ø°ÊÅØ„ÄÇÁé∞Êúâ3D-VLMsÁõ¥Êé•Â∞Ü3DÁÇπ‰∫ëÂµåÂÖ•Âà∞3D tokens‰∏≠ÔºåËÆ°ÁÆóÊàêÊú¨È´òÊòÇÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®„ÄÇHCC-3DÈ¶ñÂÖàÈááÁî®ÂÖ®Â±ÄÁªìÊûÑÂéãÁº©ÔºàGSCÔºâÔºåËÆæËÆ°ÂÖ®Â±ÄÊü•ËØ¢Â∞ÜÊâÄÊúâ3D tokensÂéãÁº©‰∏∫Â∞ëÈáèÂÖ≥ÈîÆtokensÔºå‰øùÁïôÊï¥‰ΩìÁªìÊûÑ‰ø°ÊÅØ„ÄÇÁÑ∂ÂêéÔºå‰∏∫‰∫ÜË°•ÂÅøGSC‰∏≠ÁöÑ‰ø°ÊÅØÊçüÂ§±ÔºåËøõ‰∏ÄÊ≠•ÊèêÂá∫Ëá™ÈÄÇÂ∫îÁªÜËäÇÊåñÊéòÔºàADMÔºâÊ®°ÂùóÔºåÈÄöËøá‰∫íË°•ËØÑÂàÜÈÄâÊã©ÊÄßÂú∞ÈáçÊñ∞ÂéãÁº©ÊòæËëó‰ΩÜÊú™ÂÖÖÂàÜÂÖ≥Ê≥®ÁöÑÁâπÂæÅ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåHCC-3D‰∏ç‰ªÖÂÆûÁé∞‰∫ÜÊûÅÈ´òÁöÑÂéãÁº©ÁéáÔºàÁ∫¶98%ÔºâÔºåËÄå‰∏îËææÂà∞‰∫ÜÊñ∞ÁöÑstate-of-the-artÊÄßËÉΩÔºåÂú®ÊïàÁéáÂíåÊÄßËÉΩ‰∏äÂùáÊúâÊòæËëóÊèêÂçá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞Êúâ3DËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÁõ¥Êé•Â∞Ü3DÁÇπ‰∫ëËΩ¨Êç¢‰∏∫Â§ßÈáèÁöÑ3D tokensÔºåÁÑ∂ÂêéËæìÂÖ•Âà∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâ‰∏≠ËøõË°åÂ§ÑÁêÜ„ÄÇËøôÁßçÊñπÊ≥ïËÆ°ÁÆóÊàêÊú¨ÈùûÂ∏∏È´òÔºå‰∏•ÈáçÈôêÂà∂‰∫Ü3D-VLMsÁöÑÂ∫îÁî®„ÄÇ‰∏ªË¶ÅÁöÑÁóõÁÇπÂú®‰∫éLLMÈúÄË¶ÅÂ§ÑÁêÜÂ§ßÈáèÁöÑ3D tokensÔºåÂØºËá¥ËÆ°ÁÆóÁì∂È¢à„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂàÜÂ±ÇÂéãÁº©ÁöÑÊñπÂºèÔºåÂú®Â∞ΩÂèØËÉΩ‰øùÁïôÂÖ≥ÈîÆ‰ø°ÊÅØÁöÑÂâçÊèê‰∏ãÔºåÂ§ßÂπÖÂ∫¶ÂáèÂ∞ë3D tokensÁöÑÊï∞Èáè„ÄÇÈ¶ñÂÖàËøõË°åÂÖ®Â±ÄÁªìÊûÑÂéãÁº©Ôºå‰øùÁïôÊï¥‰ΩìÁöÑÁªìÊûÑ‰ø°ÊÅØÔºõÁÑ∂ÂêéÔºåÈíàÂØπÂéãÁº©ËøáÁ®ã‰∏≠ÂèØËÉΩ‰∏¢Â§±ÁöÑÁªÜËäÇ‰ø°ÊÅØÔºåËøõË°åËá™ÈÄÇÂ∫îÁöÑÁªÜËäÇÊåñÊéòÂíåË°•ÂÅø„ÄÇËøôÊ†∑Êó¢ËÉΩÈôç‰ΩéËÆ°ÁÆóÈáèÔºåÂèàËÉΩ‰øùËØÅÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöHCC-3DÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂÖ®Â±ÄÁªìÊûÑÂéãÁº©ÔºàGSCÔºâÂíåËá™ÈÄÇÂ∫îÁªÜËäÇÊåñÊéòÔºàADMÔºâ„ÄÇGSCÊ®°Âùó‰ΩøÁî®ÂÖ®Â±ÄÊü•ËØ¢Êù•ÂéãÁº©ÊâÄÊúâ3D tokensÔºåÊèêÂèñÂ∞ëÈáèÂÖ≥ÈîÆtokensÔºå‰øùÁïôÊï¥‰ΩìÁªìÊûÑ‰ø°ÊÅØ„ÄÇADMÊ®°ÂùóÂàôÈÄöËøá‰∫íË°•ËØÑÂàÜÊú∫Âà∂ÔºåÈÄâÊã©ÊÄßÂú∞ÈáçÊñ∞ÂéãÁº©ÊòæËëó‰ΩÜÊú™Ë¢´ÂÖÖÂàÜÂÖ≥Ê≥®ÁöÑÁâπÂæÅÔºå‰ª•Ë°•ÂÅøGSC‰∏≠ÂèØËÉΩ‰∏¢Â§±ÁöÑÁªÜËäÇ‰ø°ÊÅØ„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØÂÖàËøõË°åÂÖ®Â±ÄÂéãÁº©ÔºåÂÜçËøõË°åÂ±ÄÈÉ®ÁªÜËäÇË°•ÂÅøÔºå‰ªéËÄåÂÆûÁé∞È´òÊïàÁöÑtokenÂéãÁº©„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂàÜÂ±ÇË°•ÂÅøÂéãÁº©ÁöÑÁ≠ñÁï•„ÄÇ‰º†ÁªüÁöÑÂéãÁº©ÊñπÊ≥ïÂæÄÂæÄ‰ºöÈÄ†Êàê‰ø°ÊÅØÊçüÂ§±ÔºåËÄåHCC-3DÈÄöËøáÂÖ®Â±ÄÁªìÊûÑÂéãÁº©ÂíåËá™ÈÄÇÂ∫îÁªÜËäÇÊåñÊéòÁõ∏ÁªìÂêàÔºåËÉΩÂ§üÂú®Â§ßÂπÖÂ∫¶ÂéãÁº©tokensÁöÑÂêåÊó∂ÔºåÂ∞ΩÂèØËÉΩÂú∞‰øùÁïôÂÖ≥ÈîÆ‰ø°ÊÅØ„ÄÇËøôÁßçÂàÜÂ±ÇË°•ÂÅøÁöÑÁ≠ñÁï•ÊòØ‰∏éÁé∞ÊúâÊñπÊ≥ïÊúÄÊú¨Ë¥®ÁöÑÂå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöGSCÊ®°Âùó‰∏≠ÔºåÂÖ®Â±ÄÊü•ËØ¢ÁöÑËÆæËÆ°Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÈúÄË¶ÅËÉΩÂ§üÊúâÊïàÂú∞ÊèêÂèñÂÖ®Â±ÄÁªìÊûÑ‰ø°ÊÅØ„ÄÇADMÊ®°Âùó‰∏≠Ôºå‰∫íË°•ËØÑÂàÜÊú∫Âà∂ÁöÑËÆæËÆ°ÈúÄË¶ÅËÉΩÂ§üÂáÜÁ°ÆÂú∞ËØÜÂà´Âá∫ÊòæËëó‰ΩÜÊú™Ë¢´ÂÖÖÂàÜÂÖ≥Ê≥®ÁöÑÁâπÂæÅ„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÊçüÂ§±ÂáΩÊï∞ÁªÜËäÇËÆ∫Êñá‰∏≠Êú™ÊòéÁ°ÆÁªôÂá∫ÔºåÂ±û‰∫éÊú™Áü•‰ø°ÊÅØ„ÄÇÊé®ÊµãÂèØËÉΩ‰ΩøÁî®‰∫ÜÊ≥®ÊÑèÂäõÊú∫Âà∂Áõ∏ÂÖ≥ÁöÑÁΩëÁªúÁªìÊûÑÔºåÊçüÂ§±ÂáΩÊï∞ÂèØËÉΩÂåÖÂê´ÈáçÂª∫ÊçüÂ§±ÂíåÂØπÊØîÊçüÂ§±Á≠â„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

HCC-3DÂÆûÁé∞‰∫ÜÈ´òËææ98%ÁöÑ3D tokenÂéãÁº©ÁéáÔºåÊòæËëóÈôç‰Ωé‰∫ÜËÆ°ÁÆóÊàêÊú¨„ÄÇÂêåÊó∂ÔºåÂú®Â§ö‰∏™3DËßÜËßâËØ≠Ë®Ä‰ªªÂä°‰∏äÂèñÂæó‰∫Üstate-of-the-artÁöÑÊÄßËÉΩÔºåË°®ÊòéËØ•ÊñπÊ≥ïÂú®ÊïàÁéáÂíåÊÄßËÉΩ‰∏äÂùáÊúâÊòæËëóÊèêÂçá„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÂú®ÊëòË¶Å‰∏≠Êú™ÁªôÂá∫ÔºåÂ±û‰∫éÊú™Áü•‰ø°ÊÅØ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

HCC-3DÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÂú®Ëá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅ‰∏âÁª¥Âú∫ÊôØÁêÜËß£Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÈôç‰Ωé3D-VLMsÁöÑËÆ°ÁÆóÊàêÊú¨ÔºåÂèØ‰ª•‰ΩøÂÖ∂Êõ¥ÂÆπÊòìÈÉ®ÁΩ≤Âú®ËµÑÊ∫êÂèóÈôêÁöÑËÆæÂ§á‰∏äÔºå‰ªéËÄåÂä†ÈÄüËøô‰∫õÊäÄÊúØÁöÑËêΩÂú∞ÂíåÂ∫îÁî®„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Â∫îÁî®‰∫éÂÖ∂‰ªñÈúÄË¶ÅÂ§ÑÁêÜÂ§ßÈáètokensÁöÑÂ§öÊ®°ÊÄÅ‰ªªÂä°‰∏≠ÔºåÂÖ∑Êúâ‰∏ÄÂÆöÁöÑÈÄöÁî®ÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> 3D understanding has drawn significant attention recently, leveraging Vision-Language Models (VLMs) to enable multi-modal reasoning between point cloud and text data. Current 3D-VLMs directly embed the 3D point clouds into 3D tokens, following large 2D-VLMs with powerful reasoning capabilities. However, this framework has a great computational cost limiting its application, where we identify that the bottleneck lies in processing all 3D tokens in the Large Language Model (LLM) part. This raises the question: how can we reduce the computational overhead introduced by 3D tokens while preserving the integrity of their essential information? To address this question, we introduce Hierarchical Compensatory Compression (HCC-3D) to efficiently compress 3D tokens while maintaining critical detail retention. Specifically, we first propose a global structure compression (GSC), in which we design global queries to compress all 3D tokens into a few key tokens while keeping overall structural information. Then, to compensate for the information loss in GSC, we further propose an adaptive detail mining (ADM) module that selectively recompresses salient but under-attended features through complementary scoring. Extensive experiments demonstrate that HCC-3D not only achieves extreme compression ratios (approximately 98%) compared to previous 3D-VLMs, but also achieves new state-of-the-art performance, showing the great improvements on both efficiency and performance.

