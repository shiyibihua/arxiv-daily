---
layout: default
title: AdaptViG: Adaptive Vision GNN with Exponential Decay Gating
---

# AdaptViG: Adaptive Vision GNN with Exponential Decay Gating

**arXiv**: [2511.09942v1](https://arxiv.org/abs/2511.09942) | [PDF](https://arxiv.org/pdf/2511.09942.pdf)

**ä½œè€…**: Mustafa Munir, Md Mostafijur Rahman, Radu Marculescu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAdaptViGè‡ªé€‚åº”è§†è§‰å›¾ç¥žç»ç½‘ç»œï¼Œé€šè¿‡æŒ‡æ•°è¡°å‡é—¨æŽ§è§£å†³å›¾æž„å»ºè®¡ç®—æ•ˆçŽ‡é—®é¢˜**

**å…³é”®è¯**: `è§†è§‰å›¾ç¥žç»ç½‘ç»œ` `è‡ªé€‚åº”å›¾å·ç§¯` `æŒ‡æ•°è¡°å‡é—¨æŽ§` `è®¡ç®—æ•ˆçŽ‡ä¼˜åŒ–` `æ··åˆç­–ç•¥` `ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†è§‰å›¾ç¥žç»ç½‘ç»œå›¾æž„å»ºé˜¶æ®µè®¡ç®—é‡å¤§ï¼Œå½±å“æ¨¡åž‹æ•ˆçŽ‡
2. å¼•å…¥è‡ªé€‚åº”å›¾å·ç§¯ï¼Œç»“åˆé™æ€è½´å‘æ”¯æž¶å’ŒåŠ¨æ€æŒ‡æ•°è¡°å‡é—¨æŽ§æœºåˆ¶
3. åœ¨ImageNetè¾¾82.6%å‡†ç¡®çŽ‡ï¼Œå‚æ•°å’Œè®¡ç®—é‡å¤§å¹…å‡å°‘ï¼Œä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½é¢†å…ˆ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision Graph Neural Networks (ViGs) offer a new direction for advancements in vision architectures. While powerful, ViGs often face substantial computational challenges stemming from their graph construction phase, which can hinder their efficiency. To address this issue we propose AdaptViG, an efficient and powerful hybrid Vision GNN that introduces a novel graph construction mechanism called Adaptive Graph Convolution. This mechanism builds upon a highly efficient static axial scaffold and a dynamic, content-aware gating strategy called Exponential Decay Gating. This gating mechanism selectively weighs long-range connections based on feature similarity. Furthermore, AdaptViG employs a hybrid strategy, utilizing our efficient gating mechanism in the early stages and a full Global Attention block in the final stage for maximum feature aggregation. Our method achieves a new state-of-the-art trade-off between accuracy and efficiency among Vision GNNs. For instance, our AdaptViG-M achieves 82.6% top-1 accuracy, outperforming ViG-B by 0.3% while using 80% fewer parameters and 84% fewer GMACs. On downstream tasks, AdaptViG-M obtains 45.8 mIoU, 44.8 APbox, and 41.1 APmask, surpassing the much larger EfficientFormer-L7 by 0.7 mIoU, 2.2 APbox, and 2.1 APmask, respectively, with 78% fewer parameters.

