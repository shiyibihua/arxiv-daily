---
layout: default
title: Difference Vector Equalization for Robust Fine-tuning of Vision-Language Models
---

# Difference Vector Equalization for Robust Fine-tuning of Vision-Language Models

**arXiv**: [2511.09973v1](https://arxiv.org/abs/2511.09973) | [PDF](https://arxiv.org/pdf/2511.09973.pdf)

**ä½œè€…**: Satoshi Suzuki, Shin'ya Yamaguchi, Shoichiro Takeda, Taiga Yamane, Naoki Makishima, Naotaka Kawata, Mana Ihori, Tomohiro Tanaka, Shota Orihashi, Ryo Masumura

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå·®å¼‚å‘é‡å‡è¡¡åŒ–ä»¥åœ¨å¾®è°ƒä¸­ä¿æŒè§†è§‰è¯­è¨€æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡åž‹` `é²æ£’å¾®è°ƒ` `å‡ ä½•ç»“æž„ä¿æŒ` `å·®å¼‚å‘é‡å‡è¡¡åŒ–` `é›¶æ ·æœ¬å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¾®è°ƒæ–¹æ³•æ‰­æ›²åµŒå…¥å‡ ä½•ç»“æž„ï¼Œé™åˆ¶åˆ†å¸ƒå¤–å’Œé›¶æ ·æœ¬æ€§èƒ½
2. é€šè¿‡çº¦æŸå·®å¼‚å‘é‡ç›¸ç­‰æ¥å…¨å±€å’Œå±€éƒ¨ä¿æŒå‡ ä½•ç»“æž„
3. å®žéªŒæ˜¾ç¤ºåœ¨åˆ†å¸ƒå†…ã€åˆ†å¸ƒå¤–å’Œé›¶æ ·æœ¬æŒ‡æ ‡ä¸Šå–å¾—å¼ºç»“æžœ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Contrastive pre-trained vision-language models, such as CLIP, demonstrate strong generalization abilities in zero-shot classification by leveraging embeddings extracted from image and text encoders. This paper aims to robustly fine-tune these vision-language models on in-distribution (ID) data without compromising their generalization abilities in out-of-distribution (OOD) and zero-shot settings. Current robust fine-tuning methods tackle this challenge by reusing contrastive learning, which was used in pre-training, for fine-tuning. However, we found that these methods distort the geometric structure of the embeddings, which plays a crucial role in the generalization of vision-language models, resulting in limited OOD and zero-shot performance. To address this, we propose Difference Vector Equalization (DiVE), which preserves the geometric structure during fine-tuning. The idea behind DiVE is to constrain difference vectors, each of which is obtained by subtracting the embeddings extracted from the pre-trained and fine-tuning models for the same data sample. By constraining the difference vectors to be equal across various data samples, we effectively preserve the geometric structure. Therefore, we introduce two losses: average vector loss (AVL) and pairwise vector loss (PVL). AVL preserves the geometric structure globally by constraining difference vectors to be equal to their weighted average. PVL preserves the geometric structure locally by ensuring a consistent multimodal alignment. Our experiments demonstrate that DiVE effectively preserves the geometric structure, achieving strong results across ID, OOD, and zero-shot metrics.

