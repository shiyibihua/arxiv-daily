---
layout: default
title: SPOT: Sparsification with Attention Dynamics via Token Relevance in Vision Transformers
---

# SPOT: Sparsification with Attention Dynamics via Token Relevance in Vision Transformers

**arXiv**: [2511.10488v1](https://arxiv.org/abs/2511.10488) | [PDF](https://arxiv.org/pdf/2511.10488.pdf)

**ä½œè€…**: Oded Schlesinger, Amirhossein Farzam, J. Matias Di Martino, Guillermo Sapiro

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSPOTæ¡†æž¶ä»¥è§£å†³è§†è§‰Transformerè®¡ç®—æ•ˆçŽ‡ä½Žçš„é—®é¢˜**

**å…³é”®è¯**: `è§†è§‰Transformer` `tokenç¨€ç–åŒ–` `æ³¨æ„åŠ›æœºåˆ¶` `è®¡ç®—æ•ˆçŽ‡` `æ¨¡åž‹ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†è§‰Transformerè®¡ç®—éœ€æ±‚éštokenæ•°äºŒæ¬¡å¢žé•¿ï¼Œæ•ˆçŽ‡ä½Žä¸‹
2. SPOTåˆ©ç”¨tokenåµŒå…¥å’Œæ³¨æ„åŠ›åŠ¨æ€æ—©æœŸæ£€æµ‹å†—ä½™token
3. å®žéªŒæ˜¾ç¤ºæ•ˆçŽ‡æå‡è¾¾40%ï¼ŒåŒæ—¶ä¿æŒæˆ–æé«˜å‡†ç¡®çŽ‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While Vision Transformers (ViT) have demonstrated remarkable performance across diverse tasks, their computational demands are substantial, scaling quadratically with the number of processed tokens. Compact attention representations, reflecting token interaction distributions, can guide early detection and reduction of less salient tokens prior to attention computation. Motivated by this, we present SParsification with attentiOn dynamics via Token relevance (SPOT), a framework for early detection of redundant tokens within ViTs that leverages token embeddings, interactions, and attention dynamics across layers to infer token importance, resulting in a more context-aware and interpretable relevance detection process. SPOT informs token sparsification and facilitates the elimination of such tokens, improving computational efficiency without sacrificing performance. SPOT employs computationally lightweight predictors that can be plugged into various ViT architectures and learn to derive effective input-specific token prioritization across layers. Its versatile design supports a range of performance levels adaptable to varying resource constraints. Empirical evaluations demonstrate significant efficiency gains of up to 40% compared to standard ViTs, while maintaining or even improving accuracy. Code and models are available at https://github.com/odedsc/SPOT .

