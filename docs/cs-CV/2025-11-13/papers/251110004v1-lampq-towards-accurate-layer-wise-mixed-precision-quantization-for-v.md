---
layout: default
title: LampQ: Towards Accurate Layer-wise Mixed Precision Quantization for Vision Transformers
---

# LampQ: Towards Accurate Layer-wise Mixed Precision Quantization for Vision Transformers

**arXiv**: [2511.10004v1](https://arxiv.org/abs/2511.10004) | [PDF](https://arxiv.org/pdf/2511.10004.pdf)

**ä½œè€…**: Minjun Kim, Jaeri Lee, Jongjin Kim, Jeongin Yun, Yongmo Kwon, U Kang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLampQæ–¹æ³•ä»¥è§£å†³Vision Transformeræ··åˆç²¾åº¦é‡åŒ–ä¸­çš„ç²’åº¦ç²—ã€åº¦é‡ä¸åŒ¹é…å’Œä½åˆ†é…é—®é¢˜**

**å…³é”®è¯**: `Vision Transformeré‡åŒ–` `æ··åˆç²¾åº¦é‡åŒ–` `å±‚çº§åˆ«é‡åŒ–` `Fisherä¿¡æ¯åº¦é‡` `æ•´æ•°çº¿æ€§è§„åˆ’` `é›¶æ ·æœ¬é‡åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰ViTé‡åŒ–æ–¹æ³•é‡‡ç”¨å‡åŒ€ç²¾åº¦ï¼Œå¿½ç•¥ç»„ä»¶å¯¹é‡åŒ–çš„æ•æ„Ÿåº¦å·®å¼‚
2. LampQé‡‡ç”¨å±‚çº§é‡åŒ–ã€ç±»åž‹æ„ŸçŸ¥Fisheråº¦é‡å’Œæ•´æ•°çº¿æ€§è§„åˆ’ä¼˜åŒ–ä½å®½åˆ†é…
3. å®žéªŒæ˜¾ç¤ºLampQåœ¨å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ç­‰ä»»åŠ¡ä¸­å®žçŽ°å…ˆè¿›é‡åŒ–æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> How can we accurately quantize a pre-trained Vision Transformer model? Quantization algorithms compress Vision Transformers (ViTs) into low-bit formats, reducing memory and computation demands with minimal accuracy degradation. However, existing methods rely on uniform precision, ignoring the diverse sensitivity of ViT components to quantization. Metric-based Mixed Precision Quantization (MPQ) is a promising alternative, but previous MPQ methods for ViTs suffer from three major limitations: 1) coarse granularity, 2) mismatch in metric scale across component types, and 3) quantization-unaware bit allocation. In this paper, we propose LampQ (Layer-wise Mixed Precision Quantization for Vision Transformers), an accurate metric-based MPQ method for ViTs to overcome these limitations. LampQ performs layer-wise quantization to achieve both fine-grained control and efficient acceleration, incorporating a type-aware Fisher-based metric to measure sensitivity. Then, LampQ assigns bit-widths optimally through integer linear programming and further updates them iteratively. Extensive experiments show that LampQ provides the state-of-the-art performance in quantizing ViTs pre-trained on various tasks such as image classification, object detection, and zero-shot quantization.

