---
layout: default
title: Learning to Pose Problems: Reasoning-Driven and Solver-Adaptive Data Synthesis for Large Reasoning Models
---

# Learning to Pose Problems: Reasoning-Driven and Solver-Adaptive Data Synthesis for Large Reasoning Models

**arXiv**: [2511.09907v1](https://arxiv.org/abs/2511.09907) | [PDF](https://arxiv.org/pdf/2511.09907.pdf)

**ä½œè€…**: Yongxian Wei, Yilin Zhao, Li Shen, Xinrui Chen, Runxi Cheng, Sinan Du, Hao Yu, Gang Liu, Jiahong Yan, Chun Yuan, Dian Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæŽ¨ç†é©±åŠ¨å’Œæ±‚è§£å™¨è‡ªé€‚åº”çš„æ•°æ®åˆæˆæ–¹æ³•ï¼Œä»¥æå‡å¤§åž‹æŽ¨ç†æ¨¡åž‹çš„è®­ç»ƒæ•ˆæžœã€‚**

**å…³é”®è¯**: `æ•°æ®åˆæˆ` `æŽ¨ç†æ¨¡åž‹` `é—®é¢˜ç”Ÿæˆ` `è‡ªé€‚åº”éš¾åº¦` `æ¨¡åž‹è®­ç»ƒ` `æ€§èƒ½æå‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ•°æ®åˆæˆæ–¹æ³•å¿½è§†æ±‚è§£å™¨èƒ½åŠ›ï¼Œç”Ÿæˆä½Žä»·å€¼é—®é¢˜æˆ–ä¾èµ–å¤æ‚æµç¨‹å¹³è¡¡éš¾åº¦ã€‚
2. æ–¹æ³•é€šè¿‡æŽ¨ç†æ¨¡åž‹è§„åˆ’é—®é¢˜æ–¹å‘ï¼Œå¹¶åŸºäºŽæ±‚è§£å™¨åé¦ˆè‡ªé€‚åº”è°ƒæ•´é—®é¢˜éš¾åº¦ã€‚
3. åœ¨10ä¸ªåŸºå‡†æµ‹è¯•ä¸­å¹³å‡æå‡2.5%ï¼Œå¹¶æ”¯æŒè¯­è¨€å’Œè§†è§‰è¯­è¨€æ¨¡åž‹çš„æ³›åŒ–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Data synthesis for training large reasoning models offers a scalable alternative to limited, human-curated datasets, enabling the creation of high-quality data. However, existing approaches face several challenges: (i) indiscriminate generation that ignores the solver's ability and yields low-value problems, or reliance on complex data pipelines to balance problem difficulty; and (ii) a lack of reasoning in problem generation, leading to shallow problem variants. In this paper, we develop a problem generator that reasons explicitly to plan problem directions before synthesis and adapts difficulty to the solver's ability. Specifically, we construct related problem pairs and augment them with intermediate problem-design CoT produced by a reasoning model. These data bootstrap problem-design strategies from the generator. Then, we treat the solver's feedback on synthetic problems as a reward signal, enabling the generator to calibrate difficulty and produce complementary problems near the edge of the solver's competence. Extensive experiments on 10 mathematical and general reasoning benchmarks show that our method achieves an average improvement of 2.5% and generalizes to both language and vision-language models. Moreover, a solver trained on the synthesized data provides improved rewards for continued generator training, enabling co-evolution and yielding a further 0.7% performance gain. Our code will be made publicly available here.

