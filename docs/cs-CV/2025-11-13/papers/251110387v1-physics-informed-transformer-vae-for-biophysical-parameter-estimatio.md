---
layout: default
title: Physics informed Transformer-VAE for biophysical parameter estimation: PROSAIL model inversion in Sentinel-2 imagery
---

# Physics informed Transformer-VAE for biophysical parameter estimation: PROSAIL model inversion in Sentinel-2 imagery

**arXiv**: [2511.10387v1](https://arxiv.org/abs/2511.10387) | [PDF](https://arxiv.org/pdf/2511.10387.pdf)

**ä½œè€…**: Prince Mensah, Pelumi Victor Aderinto, Ibrahim Salihu Yusuf, Arnu Pretorius

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç‰©ç†ä¿¡æ¯Transformer-VAEä»¥ä»ŽSentinel-2å½±åƒåæ¼”PROSAILæ¨¡åž‹ï¼Œä¼°è®¡æ¤è¢«ç”Ÿç‰©ç‰©ç†å‚æ•°ã€‚**

**å…³é”®è¯**: `æ¤è¢«å‚æ•°åæ¼”` `ç‰©ç†ä¿¡æ¯æ·±åº¦å­¦ä¹ ` `PROSAILæ¨¡åž‹` `Sentinel-2å½±åƒ` `è‡ªç›‘ç£å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä»Žå«æ˜Ÿå½±åƒå‡†ç¡®åæ¼”æ¤è¢«ç”Ÿç‰©ç‰©ç†å˜é‡ï¼Œç”¨äºŽç”Ÿæ€ç³»ç»Ÿç›‘æµ‹å’Œå†œä¸šç®¡ç†ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆTransformer-VAEä¸ŽPROSAILæ¨¡åž‹ä½œä¸ºå¯å¾®åˆ†ç‰©ç†è§£ç å™¨ï¼Œä»…ç”¨æ¨¡æ‹Ÿæ•°æ®è®­ç»ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žæ•°æ®é›†ä¸Šä¼°è®¡LAIå’ŒCCCï¼Œæ€§èƒ½åª²ç¾Žä½¿ç”¨çœŸå®žå½±åƒçš„å…ˆè¿›æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Accurate retrieval of vegetation biophysical variables from satellite imagery is crucial for ecosystem monitoring and agricultural management. In this work, we propose a physics-informed Transformer-VAE architecture to invert the PROSAIL radiative transfer model for simultaneous estimation of key canopy parameters from Sentinel-2 data. Unlike previous hybrid approaches that require real satellite images for self-supevised training. Our model is trained exclusively on simulated data, yet achieves performance on par with state-of-the-art methods that utilize real imagery. The Transformer-VAE incorporates the PROSAIL model as a differentiable physical decoder, ensuring that inferred latent variables correspond to physically plausible leaf and canopy properties. We demonstrate retrieval of leaf area index (LAI) and canopy chlorophyll content (CCC) on real-world field datasets (FRM4Veg and BelSAR) with accuracy comparable to models trained with real Sentinel-2 data. Our method requires no in-situ labels or calibration on real images, offering a cost-effective and self-supervised solution for global vegetation monitoring. The proposed approach illustrates how integrating physical models with advanced deep networks can improve the inversion of RTMs, opening new prospects for large-scale, physically-constrained remote sensing of vegetation traits.

