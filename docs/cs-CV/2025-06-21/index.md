---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-06-21
---

# cs.CVï¼ˆ2025-06-21ï¼‰

ğŸ“Š å…± **2** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250617561v1-vla-os-structuring-and-dissecting-planning-representations-and-parad.html">VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models</a></td>
  <td>æå‡ºVLA-OSä»¥ç³»ç»ŸåŒ–è§„åˆ’è¡¨ç¤ºå’ŒèŒƒå¼åœ¨è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ä¸­çš„åº”ç”¨</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous hand</span> <span class="paper-tag">vision-language-action</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17561v1" data-paper-url="./papers/250617561v1-vla-os-structuring-and-dissecting-planning-representations-and-parad.html" onclick="toggleFavorite(this, '2506.17561v1', 'VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>2</td>
  <td><a href="./papers/250617545v1-scene-r1-video-grounded-large-language-models-for-3d-scene-reasoning.html">Scene-R1: Video-Grounded Large Language Models for 3D Scene Reasoning without 3D Annotations</a></td>
  <td>æå‡ºScene-R1ä»¥è§£å†³æ— 3Dæ ‡æ³¨çš„3Dåœºæ™¯æ¨ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">scene understanding</span> <span class="paper-tag">open-vocabulary</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17545v1" data-paper-url="./papers/250617545v1-scene-r1-video-grounded-large-language-models-for-3d-scene-reasoning.html" onclick="toggleFavorite(this, '2506.17545v1', 'Scene-R1: Video-Grounded Large Language Models for 3D Scene Reasoning without 3D Annotations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)