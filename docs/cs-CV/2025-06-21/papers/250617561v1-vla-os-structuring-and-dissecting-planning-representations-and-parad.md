---
layout: default
title: VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models
---

# VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17561" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17561v1</a>
  <a href="https://arxiv.org/pdf/2506.17561.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17561v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17561v1', 'VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chongkai Gao, Zixuan Liu, Zhenghao Chi, Junshan Huang, Xin Fei, Yiwen Hou, Yuxuan Zhang, Yudi Lin, Zhirui Fang, Zeyu Jiang, Lin Shao

**åˆ†ç±»**: cs.CV, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-21

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVLA-OSä»¥ç³»ç»ŸåŒ–è§„åˆ’è¡¨ç¤ºå’ŒèŒƒå¼åœ¨è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ä¸­çš„åº”ç”¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `ä»»åŠ¡è§„åˆ’` `å¤šæ¨¡æ€å­¦ä¹ ` `æœºå™¨äººæ“ä½œ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLAæ¨¡å‹åœ¨ç½‘ç»œæ¶æ„å’Œè®­ç»ƒæ•°æ®æºä¸Šå·®å¼‚æ˜¾è‘—ï¼Œéš¾ä»¥è¯†åˆ«æ€§èƒ½æå‡çš„å…·ä½“æ¥æºã€‚
2. æœ¬æ–‡æå‡ºVLA-OSï¼Œç»Ÿä¸€çš„VLAæ¶æ„ç³»åˆ—ï¼Œæ”¯æŒå¤šç§ä»»åŠ¡è§„åˆ’èŒƒå¼ï¼Œæ—¨åœ¨ç³»ç»Ÿæ€§ç ”ç©¶ä¸åŒè§„åˆ’è¡¨ç¤ºçš„å½±å“ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè§†è§‰åŸºç¡€çš„è§„åˆ’è¡¨ç¤ºä¼˜äºè¯­è¨€åŸºç¡€çš„è¡¨ç¤ºï¼Œåˆ†å±‚VLAèŒƒå¼åœ¨å¤šé¡¹æ€§èƒ½æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜è¶Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹çš„ç ”ç©¶å·²ä»ç«¯åˆ°ç«¯çš„åŠ¨ä½œç”ŸæˆèŒƒå¼è½¬å‘åŒ…å«ä»»åŠ¡è§„åˆ’å’ŒåŠ¨ä½œç”Ÿæˆçš„ç®¡é“ï¼Œæ˜¾ç¤ºå‡ºåœ¨å¤æ‚é•¿æ—¶é—´æ“ä½œä»»åŠ¡ä¸Šçš„æ€§èƒ½æå‡ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨ç½‘ç»œæ¶æ„ã€è§„åˆ’èŒƒå¼ã€è¡¨ç¤ºå’Œè®­ç»ƒæ•°æ®æºä¸Šå·®å¼‚æ˜¾è‘—ï¼Œå¯¼è‡´ç ”ç©¶è€…éš¾ä»¥è¯†åˆ«æ€§èƒ½æå‡çš„å…·ä½“æ¥æºã€‚ä¸ºç³»ç»Ÿæ€§åœ°ç ”ç©¶ä¸åŒè§„åˆ’èŒƒå¼å’Œè¡¨ç¤ºçš„å½±å“ï¼Œæœ¬æ–‡æå‡ºäº†VLA-OSï¼Œä¸€ä¸ªç»Ÿä¸€çš„VLAæ¶æ„ç³»åˆ—ï¼Œèƒ½å¤Ÿæ”¯æŒå¤šç§ä»»åŠ¡è§„åˆ’èŒƒå¼ï¼Œå¹¶è®¾è®¡äº†ä¸€å¥—å…¨é¢çš„æ§åˆ¶å®éªŒï¼Œæ¶µç›–å¤šç§ç‰©ä½“ç±»åˆ«ã€è§†è§‰æ¨¡æ€ã€ç¯å¢ƒå’Œæœ«ç«¯æ‰§è¡Œå™¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè§†è§‰åŸºç¡€çš„è§„åˆ’è¡¨ç¤ºé€šå¸¸ä¼˜äºè¯­è¨€åŸºç¡€çš„è¡¨ç¤ºï¼Œè€Œåˆ†å±‚VLAèŒƒå¼åœ¨ä»»åŠ¡æ€§èƒ½ã€é¢„è®­ç»ƒã€æ³›åŒ–èƒ½åŠ›ã€å¯æ‰©å±•æ€§å’ŒæŒç»­å­¦ä¹ èƒ½åŠ›ä¸Šé€šå¸¸è¡¨ç°ä¼˜è¶Šï¼Œå°½ç®¡è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦è¾ƒæ…¢ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨è§„åˆ’è¡¨ç¤ºå’ŒèŒƒå¼ä¸Šçš„ä¸ä¸€è‡´æ€§ï¼Œå¯¼è‡´æ€§èƒ½æå‡æ¥æºä¸æ˜ç¡®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç½‘ç»œæ¶æ„ã€è§„åˆ’èŒƒå¼å’Œè®­ç»ƒæ•°æ®æºä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå½±å“äº†ç ”ç©¶çš„ç³»ç»Ÿæ€§å’Œå¯é‡å¤æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºVLA-OSæ¶æ„ï¼Œé€šè¿‡ç»Ÿä¸€çš„è®¾è®¡æ¥æ”¯æŒå¤šç§ä»»åŠ¡è§„åˆ’èŒƒå¼ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°ä¸åŒè§„åˆ’è¡¨ç¤ºçš„æ•ˆæœï¼Œæ—¨åœ¨æ¶ˆé™¤ç½‘ç»œæ¶æ„å’Œè®­ç»ƒæ•°æ®å¯¹ç»“æœçš„å¹²æ‰°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVLA-OSæ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆè¿›è¡Œä»»åŠ¡è§„åˆ’ï¼Œç„¶åç”ŸæˆåŠ¨ä½œã€‚å®éªŒè®¾è®¡æ¶µç›–å¤šç§ç‰©ä½“ç±»åˆ«ï¼ˆåˆšæ€§å’Œå¯å˜å½¢ï¼‰ã€è§†è§‰æ¨¡æ€ï¼ˆ2Då’Œ3Dï¼‰ã€ç¯å¢ƒï¼ˆä»¿çœŸå’Œç°å®ï¼‰åŠæœ«ç«¯æ‰§è¡Œå™¨ï¼ˆå¤¹æŒå™¨å’Œçµå·§æ‰‹ï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†åˆ†å±‚VLAèŒƒå¼ï¼Œè¯¥èŒƒå¼åœ¨ä»»åŠ¡æ€§èƒ½ã€é¢„è®­ç»ƒã€æ³›åŒ–èƒ½åŠ›ã€å¯æ‰©å±•æ€§å’ŒæŒç»­å­¦ä¹ èƒ½åŠ›ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œä¸”èƒ½å¤Ÿç³»ç»Ÿæ€§åœ°æ¯”è¾ƒä¸åŒè§„åˆ’è¡¨ç¤ºçš„æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†è§†è§‰åŸºç¡€çš„è§„åˆ’è¡¨ç¤ºï¼Œè®¾ç½®äº†å¤šç§å®éªŒæ¡ä»¶ä»¥è¯„ä¼°ä¸åŒè§„åˆ’èŒƒå¼çš„æ€§èƒ½ï¼Œå…³æ³¨è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦çš„æƒè¡¡ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒä¸­è¿›è¡Œäº†ä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè§†è§‰åŸºç¡€çš„è§„åˆ’è¡¨ç¤ºåœ¨å¤šé¡¹ä»»åŠ¡ä¸­ä¼˜äºè¯­è¨€åŸºç¡€çš„è¡¨ç¤ºï¼Œåˆ†å±‚VLAèŒƒå¼åœ¨ä»»åŠ¡æ€§èƒ½ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œå°¤å…¶åœ¨é¢„è®­ç»ƒå’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢ï¼Œæå‡å¹…åº¦æ˜¾è‘—ï¼Œå°½ç®¡è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦è¾ƒæ…¢ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ“ä½œã€è‡ªåŠ¨åŒ–åˆ¶é€ å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æ”¹è¿›è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„è§„åˆ’èƒ½åŠ›ï¼Œèƒ½å¤Ÿæå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è‡ªä¸»æ“ä½œèƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent studies on Vision-Language-Action (VLA) models have shifted from the end-to-end action-generation paradigm toward a pipeline involving task planning followed by action generation, demonstrating improved performance on various complex, long-horizon manipulation tasks. However, existing approaches vary significantly in terms of network architectures, planning paradigms, representations, and training data sources, making it challenging for researchers to identify the precise sources of performance gains and components to be further improved. To systematically investigate the impacts of different planning paradigms and representations isolating from network architectures and training data, in this paper, we introduce VLA-OS, a unified VLA architecture series capable of various task planning paradigms, and design a comprehensive suite of controlled experiments across diverse object categories (rigid and deformable), visual modalities (2D and 3D), environments (simulation and real-world), and end-effectors (grippers and dexterous hands). Our results demonstrate that: 1) visually grounded planning representations are generally better than language planning representations; 2) the Hierarchical-VLA paradigm generally achieves superior or comparable performance than other paradigms on task performance, pretraining, generalization ability, scalability, and continual learning ability, albeit at the cost of slower training and inference speeds.

