---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-09-17
---

# cs.CVï¼ˆ2025-09-17ï¼‰

ğŸ“Š å…± **5** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (4 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250915241v1-m-pace-mother-child-framework-for-multimodal-compliance.html">M-PACE: Mother Child Framework for Multimodal Compliance</a></td>
  <td>M-PACEï¼šç”¨äºå¤šæ¨¡æ€åˆè§„æ€§çš„æ¯å­æ¡†æ¶ï¼Œæ˜¾è‘—é™ä½æ¨ç†æˆæœ¬ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15241v1" data-paper-url="./papers/250915241v1-m-pace-mother-child-framework-for-multimodal-compliance.html" onclick="toggleFavorite(this, '2509.15241v1', 'M-PACE: Mother Child Framework for Multimodal Compliance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250918174v1-baseer-a-vision-language-model-for-arabic-document-to-markdown-ocr.html">Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR</a></td>
  <td>Baseerï¼šé¢å‘é˜¿æ‹‰ä¼¯è¯­æ–‡æ¡£OCRçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œåˆ·æ–°SOTA</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.18174v1" data-paper-url="./papers/250918174v1-baseer-a-vision-language-model-for-arabic-document-to-markdown-ocr.html" onclick="toggleFavorite(this, '2509.18174v1', 'Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250915235v5-vispec-accelerating-vision-language-models-with-vision-aware-specula.html">ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding</a></td>
  <td>ViSpecï¼šåˆ©ç”¨è§†è§‰æ„ŸçŸ¥æ¨æµ‹è§£ç åŠ é€Ÿè§†è§‰-è¯­è¨€æ¨¡å‹æ¨ç†</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15235v5" data-paper-url="./papers/250915235v5-vispec-accelerating-vision-language-models-with-vision-aware-specula.html" onclick="toggleFavorite(this, '2509.15235v5', 'ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250914199v2-dense-video-understanding-with-gated-residual-tokenization.html">Dense Video Understanding with Gated Residual Tokenization</a></td>
  <td>æå‡ºé—¨æ§æ®‹å·®TokenåŒ–ï¼ˆGRTï¼‰æ¡†æ¶ï¼Œå®ç°é«˜æ•ˆé«˜å¸§ç‡è§†é¢‘ç†è§£ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14199v2" data-paper-url="./papers/250914199v2-dense-video-understanding-with-gated-residual-tokenization.html" onclick="toggleFavorite(this, '2509.14199v2', 'Dense Video Understanding with Gated Residual Tokenization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>5</td>
  <td><a href="./papers/250913605v1-a-generalization-of-clap-from-3d-localization-to-image-processing-a-.html">A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms</a></td>
  <td>CLAPç®—æ³•æ³›åŒ–ï¼šä»3Då®šä½åˆ°å›¾åƒæ‹¼æ¥ï¼Œå¹¶æ­ç¤ºå…¶ä¸RANSACå’ŒHoughå˜æ¢çš„è”ç³»</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13605v1" data-paper-url="./papers/250913605v1-a-generalization-of-clap-from-3d-localization-to-image-processing-a-.html" onclick="toggleFavorite(this, '2509.13605v1', 'A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)