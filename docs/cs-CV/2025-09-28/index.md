---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-09-28
---

# cs.CVï¼ˆ2025-09-28ï¼‰

ğŸ“Š å…± **5** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (2)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250923612v1-interactmove-text-controlled-human-object-interaction-generation-in-.html">InteractMove: Text-Controlled Human-Object Interaction Generation in 3D Scenes with Movable Objects</a></td>
  <td>InteractMoveï¼šæå‡ºä¸€ç§æ–‡æœ¬æ§åˆ¶çš„3Dåœºæ™¯ä¸­å¯ç§»åŠ¨ç‰©ä½“äººæœºäº¤äº’ç”Ÿæˆæ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">affordance</span> <span class="paper-tag">physically plausible</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23612v1" data-paper-url="./papers/250923612v1-interactmove-text-controlled-human-object-interaction-generation-in-.html" onclick="toggleFavorite(this, '2509.23612v1', 'InteractMove: Text-Controlled Human-Object Interaction Generation in 3D Scenes with Movable Objects')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250923555v1-from-fields-to-splats-a-cross-domain-survey-of-real-time-neural-scen.html">From Fields to Splats: A Cross-Domain Survey of Real-Time Neural Scene Representations</a></td>
  <td>ç»¼è¿°ï¼šå®æ—¶ç¥ç»åœºæ™¯è¡¨ç¤ºï¼Œä»NeRFåˆ°3Dé«˜æ–¯æº…å°„åœ¨å¤šé¢†åŸŸçš„åº”ç”¨ä¸å‘å±•</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">teleoperation</span> <span class="paper-tag">3D gaussian splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23555v1" data-paper-url="./papers/250923555v1-from-fields-to-splats-a-cross-domain-survey-of-real-time-neural-scen.html" onclick="toggleFavorite(this, '2509.23555v1', 'From Fields to Splats: A Cross-Domain Survey of Real-Time Neural Scene Representations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>3</td>
  <td><a href="./papers/250923541v1-ovseg3r-learn-open-vocabulary-instance-segmentation-from-2d-via-3d-r.html">OVSeg3R: Learn Open-vocabulary Instance Segmentation from 2D via 3D Reconstruction</a></td>
  <td>OVSeg3Rï¼šé€šè¿‡3Dé‡å»ºä»2Då­¦ä¹ å¼€æ”¾è¯æ±‡å®ä¾‹åˆ†å‰²</td>
  <td class="tags-cell"><span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23541v1" data-paper-url="./papers/250923541v1-ovseg3r-learn-open-vocabulary-instance-segmentation-from-2d-via-3d-r.html" onclick="toggleFavorite(this, '2509.23541v1', 'OVSeg3R: Learn Open-vocabulary Instance Segmentation from 2D via 3D Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>4</td>
  <td><a href="./papers/250923608v1-flowlut-efficient-image-enhancement-via-differentiable-luts-and-iter.html">FlowLUT: Efficient Image Enhancement via Differentiable LUTs and Iterative Flow Matching</a></td>
  <td>æå‡ºFlowLUTä»¥è§£å†³å›¾åƒå¢å¼ºä¸­çš„æ•ˆç‡ä¸è¡¨ç°èƒ½åŠ›æƒè¡¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">flow matching</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23608v1" data-paper-url="./papers/250923608v1-flowlut-efficient-image-enhancement-via-differentiable-luts-and-iter.html" onclick="toggleFavorite(this, '2509.23608v1', 'FlowLUT: Efficient Image Enhancement via Differentiable LUTs and Iterative Flow Matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>5</td>
  <td><a href="./papers/250923594v1-stolenlora-exploring-lora-extraction-attacks-via-synthetic-data.html">StolenLoRA: Exploring LoRA Extraction Attacks via Synthetic Data</a></td>
  <td>æå‡ºStolenLoRAï¼Œåˆ©ç”¨åˆæˆæ•°æ®å®ç°å¯¹LoRAé€‚é…æ¨¡å‹çš„æå–æ”»å‡»ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23594v1" data-paper-url="./papers/250923594v1-stolenlora-exploring-lora-extraction-attacks-via-synthetic-data.html" onclick="toggleFavorite(this, '2509.23594v1', 'StolenLoRA: Exploring LoRA Extraction Attacks via Synthetic Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)