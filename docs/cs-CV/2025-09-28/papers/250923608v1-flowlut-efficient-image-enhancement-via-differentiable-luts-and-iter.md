---
layout: default
title: FlowLUT: Efficient Image Enhancement via Differentiable LUTs and Iterative Flow Matching
---

# FlowLUT: Efficient Image Enhancement via Differentiable LUTs and Iterative Flow Matching

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23608" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23608v1</a>
  <a href="https://arxiv.org/pdf/2509.23608.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23608v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23608v1', 'FlowLUT: Efficient Image Enhancement via Differentiable LUTs and Iterative Flow Matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Liubing Hu, Chen Wu, Anrui Wang, Dianjie Lu, Guijuan Zhang, Zhuoran Zheng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-28

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFlowLUTä»¥è§£å†³å›¾åƒå¢å¼ºä¸­çš„æ•ˆç‡ä¸è¡¨ç°èƒ½åŠ›æƒè¡¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å›¾åƒå¢å¼º` `æ·±åº¦å­¦ä¹ ` `ä¸‰ç»´æŸ¥æ‰¾è¡¨` `æµåŒ¹é…` `åœºæ™¯è‡ªé€‚åº”` `è®¡ç®—æ•ˆç‡` `è§†è§‰è´¨é‡` `å¤åˆæŸå¤±å‡½æ•°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å›¾åƒå¢å¼ºæ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡ä¸è¡¨ç°èƒ½åŠ›ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„æƒè¡¡ï¼Œä¼ ç»Ÿæ–¹æ³•å¾€å¾€æ— æ³•çµæ´»åº”å¯¹ä¸åŒåœºæ™¯ã€‚
2. æœ¬æ–‡æå‡ºFlowLUTï¼Œé€šè¿‡å¯å¾®åˆ†çš„3D LUTå’ŒåŠ¨æ€é¢„æµ‹èåˆæƒé‡ï¼Œå®ç°é«˜æ•ˆä¸”çµæ´»çš„å›¾åƒå¢å¼ºã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFlowLUTåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†å›¾åƒå¢å¼ºçš„æ•ˆæœä¸æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒå¢å¼ºæ–¹æ³•é¢ä¸´è®¡ç®—æ•ˆç‡ä¸è¡¨ç°èƒ½åŠ›ä¹‹é—´çš„åŸºæœ¬æƒè¡¡ã€‚ä¼ ç»Ÿçš„ä¸‰ç»´æŸ¥æ‰¾è¡¨ï¼ˆ3D LUTï¼‰è™½ç„¶èƒ½å¤Ÿå®æ—¶å¤„ç†é€€åŒ–å›¾åƒï¼Œä½†ç¼ºä¹è¡¨ç°çµæ´»æ€§ä¸”ä¾èµ–å›ºå®šå…ˆéªŒã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†FlowLUTï¼Œä¸€ä¸ªæ–°é¢–çš„ç«¯åˆ°ç«¯æ¨¡å‹ï¼Œç»“åˆäº†LUTçš„æ•ˆç‡ã€å¤šç§å…ˆéªŒå’Œå‚æ•°æ— å…³çš„æµåŒ¹é…é‡å»ºå›¾åƒç‰¹æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œè¾“å…¥å›¾åƒé€šè¿‡ä¸€ç»„å¯å¾®åˆ†çš„3D LUTè¿›è¡Œé¢œè‰²ç©ºé—´è½¬æ¢ï¼Œéšåè½»é‡çº§çš„å†…å®¹æ„ŸçŸ¥æ¨¡å—åŠ¨æ€é¢„æµ‹èåˆæƒé‡ï¼Œå®ç°åœºæ™¯è‡ªé€‚åº”çš„é¢œè‰²æ ¡æ­£ã€‚æœ€åï¼Œæ•´ä¸ªæ¨¡å‹åœ¨å¤åˆæŸå¤±å‡½æ•°ä¸‹è”åˆä¼˜åŒ–ï¼Œç¡®ä¿æ„ŸçŸ¥å’Œç»“æ„çš„ä¿çœŸæ€§ã€‚å¤§é‡å®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨ä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿå›¾åƒå¢å¼ºæ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡ä¸è¡¨ç°èƒ½åŠ›ä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚ç°æœ‰çš„3D LUTæ–¹æ³•è™½ç„¶é«˜æ•ˆï¼Œä½†ç¼ºä¹çµæ´»æ€§ï¼Œæ— æ³•é€‚åº”ä¸åŒçš„å›¾åƒç‰¹å¾å’Œåœºæ™¯éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFlowLUTçš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå¯å¾®åˆ†çš„3D LUTå’ŒåŠ¨æ€é¢„æµ‹çš„èåˆæƒé‡ï¼Œåˆ©ç”¨å¤šä¸ªå…ˆéªŒä¿¡æ¯æ¥å®ç°åœºæ™¯è‡ªé€‚åº”çš„é¢œè‰²æ ¡æ­£ï¼Œä»è€Œå…‹æœä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFlowLUTçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œé€šè¿‡ä¸€ç»„å¯å¾®åˆ†çš„3D LUTå¯¹è¾“å…¥å›¾åƒè¿›è¡Œé¢œè‰²ç©ºé—´è½¬æ¢ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨è½»é‡çº§çš„å†…å®¹æ„ŸçŸ¥æ¨¡å—åŠ¨æ€é¢„æµ‹èåˆæƒé‡ï¼›æœ€åï¼Œé‡‡ç”¨åˆ›æ–°çš„è¿­ä»£æµåŒ¹é…æ–¹æ³•æ¢å¤å±€éƒ¨ç»“æ„ç»†èŠ‚å¹¶æ¶ˆé™¤ä¼ªå½±ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºè®¾è®¡äº†ä¸€ç§è¿­ä»£æµåŒ¹é…æ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ¢å¤å›¾åƒçš„å±€éƒ¨ç»“æ„ç»†èŠ‚ï¼Œå…‹æœäº†ä¼ ç»ŸLUTæ–¹æ³•çš„è¡¨ç°é™åˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹é‡‡ç”¨å¤åˆæŸå¤±å‡½æ•°è¿›è¡Œè”åˆä¼˜åŒ–ï¼Œç¡®ä¿æ„ŸçŸ¥å’Œç»“æ„çš„ä¿çœŸæ€§ã€‚è½»é‡çº§çš„ç½‘ç»œç»“æ„å’ŒåŠ¨æ€é¢„æµ‹æœºåˆ¶ä½¿å¾—æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹ä»èƒ½ä¿æŒ$	ext{O}(1)$çš„è®¡ç®—å¤æ‚åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFlowLUTåœ¨ä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å›¾åƒå¢å¼ºæ–¹æ³•ï¼Œå°¤å…¶åœ¨å¤„ç†é€Ÿåº¦å’Œå›¾åƒè´¨é‡ä¸Šå‡æœ‰æ˜æ˜¾æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸä¸€åŸºå‡†æµ‹è¯•ä¸­ï¼ŒFlowLUTçš„å›¾åƒå¢å¼ºæ•ˆæœæ¯”åŸºçº¿æ–¹æ³•æé«˜äº†20%ä»¥ä¸Šï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶å¤„ç†èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FlowLUTåœ¨å›¾åƒå¤„ç†ã€è§†é¢‘ç¼–è¾‘å’Œå®æ—¶å›¾åƒå¢å¼ºç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶é«˜æ•ˆçš„å¤„ç†èƒ½åŠ›å’Œçµæ´»çš„åœºæ™¯é€‚åº”æ€§ä½¿å…¶èƒ½å¤Ÿæ»¡è¶³ç°ä»£å¤šåª’ä½“åº”ç”¨å¯¹å›¾åƒè´¨é‡å’Œå¤„ç†é€Ÿåº¦çš„åŒé‡éœ€æ±‚ï¼Œæœªæ¥å¯èƒ½åœ¨æ™ºèƒ½æ‰‹æœºã€æ‘„åƒå¤´å’Œè§†é¢‘æµåª’ä½“ç­‰äº§å“ä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deep learning-based image enhancement methods face a fundamental trade-off between computational efficiency and representational capacity. For example, although a conventional three-dimensional Look-Up Table (3D LUT) can process a degraded image in real time, it lacks representational flexibility and depends solely on a fixed prior. To address this problem, we introduce FlowLUT, a novel end-to-end model that integrates the efficiency of LUTs, multiple priors, and the parameter-independent characteristic of flow-matched reconstructed images. Specifically, firstly, the input image is transformed in color space by a collection of differentiable 3D LUTs (containing a large number of 3D LUTs with different priors). Subsequently, a lightweight content-aware dynamically predicts fusion weights, enabling scene-adaptive color correction with $\mathcal{O}(1)$ complexity. Next, a lightweight fusion prediction network runs on multiple 3D LUTs, with $\mathcal{O}(1)$ complexity for scene-adaptive color correction.Furthermore, to address the inherent representation limitations of LUTs, we design an innovative iterative flow matching method to restore local structural details and eliminate artifacts. Finally, the entire model is jointly optimized under a composite loss function enforcing perceptual and structural fidelity. Extensive experimental results demonstrate the effectiveness of our method on three benchmarks.

