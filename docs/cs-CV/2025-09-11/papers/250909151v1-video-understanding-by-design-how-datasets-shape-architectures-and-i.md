---
layout: default
title: Video Understanding by Design: How Datasets Shape Architectures and Insights
---

# Video Understanding by Design: How Datasets Shape Architectures and Insights

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09151" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09151v1</a>
  <a href="https://arxiv.org/pdf/2509.09151.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09151v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09151v1', 'Video Understanding by Design: How Datasets Shape Architectures and Insights')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lei Wang, Piotr Koniusz, Yongsheng Gao

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11

**å¤‡æ³¨**: Research report

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ä»æ•°æ®é›†è§†è§’è§£è¯»è§†é¢‘ç†è§£ï¼šæ­ç¤ºæ•°æ®é›†å¦‚ä½•å¡‘é€ æ¨¡å‹æ¶æ„ä¸æ´è§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘ç†è§£` `æ•°æ®é›†é©±åŠ¨` `æ¨¡å‹æ¶æ„` `å½’çº³åç½®` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘ç†è§£ç»¼è¿°ä¾§é‡æ¨¡å‹åˆ†ç±»ï¼Œå¿½ç•¥äº†æ•°æ®é›†å¯¹æ¨¡å‹æ¶æ„æ¼”å˜çš„å½±å“ã€‚
2. æœ¬ç ”ç©¶ä»æ•°æ®é›†è§’åº¦å‡ºå‘ï¼Œåˆ†æè¿åŠ¨å¤æ‚æ€§ç­‰å› ç´ å¦‚ä½•å½±å“æ¨¡å‹è®¾è®¡ã€‚
3. é€šè¿‡ç»Ÿä¸€æ•°æ®é›†ã€å½’çº³åç½®å’Œæ¶æ„ï¼Œä¸ºé€šç”¨è§†é¢‘ç†è§£æä¾›æŒ‡å¯¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†é¢‘ç†è§£é¢†åŸŸå‘å±•è¿…é€Ÿï¼Œè¿™å¾—ç›Šäºæ—¥ç›Šå¤æ‚çš„æ•°æ®é›†å’Œå¼ºå¤§çš„æ¨¡å‹æ¶æ„ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç»¼è¿°å¤§å¤šæŒ‰ä»»åŠ¡æˆ–æ¨¡å‹å®¶æ—å¯¹æ¨¡å‹è¿›è¡Œåˆ†ç±»ï¼Œå¿½ç•¥äº†æ•°æ®é›†é€šè¿‡ç»“æ„æ€§å‹åŠ›å¼•å¯¼æ¶æ„æ¼”å˜çš„è¿‡ç¨‹ã€‚æœ¬ç»¼è¿°é¦–æ¬¡é‡‡ç”¨æ•°æ®é›†é©±åŠ¨çš„è§†è§’ï¼Œå±•ç¤ºäº†è¿åŠ¨å¤æ‚æ€§ã€æ—¶é—´è·¨åº¦ã€åˆ†å±‚ç»„åˆå’Œå¤šæ¨¡æ€ä¸°å¯Œæ€§å¦‚ä½•æ–½åŠ å½’çº³åç½®ï¼Œè€Œæ¨¡å‹åº”è¯¥å¯¹è¿™äº›å½’çº³åç½®è¿›è¡Œç¼–ç ã€‚æˆ‘ä»¬å°†ä»åŒæµç½‘ç»œå’Œ3D CNNåˆ°åºåˆ—æ¨¡å‹ã€Transformeræ¨¡å‹å’Œå¤šæ¨¡æ€åŸºç¡€æ¨¡å‹çš„é‡Œç¨‹ç¢‘å¼è¿›å±•ï¼Œé‡æ–°è§£é‡Šä¸ºå¯¹è¿™äº›æ•°æ®é›†é©±åŠ¨å‹åŠ›çš„å…·ä½“å“åº”ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬ä¸ºæ¨¡å‹è®¾è®¡ä¸æ•°æ®é›†ä¸å˜æ€§å¯¹é½ï¼ŒåŒæ—¶å¹³è¡¡å¯æ‰©å±•æ€§å’Œä»»åŠ¡éœ€æ±‚ï¼Œæä¾›äº†å®ç”¨çš„æŒ‡å¯¼ã€‚é€šè¿‡å°†æ•°æ®é›†ã€å½’çº³åç½®å’Œæ¶æ„ç»Ÿä¸€åˆ°ä¸€ä¸ªè¿è´¯çš„æ¡†æ¶ä¸­ï¼Œæœ¬ç»¼è¿°ä¸ºæ¨è¿›é€šç”¨è§†é¢‘ç†è§£æä¾›äº†å…¨é¢çš„å›é¡¾å’Œè§„èŒƒæ€§çš„è·¯çº¿å›¾ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è§†é¢‘ç†è§£ç»¼è¿°ä¸»è¦å…³æ³¨æ¨¡å‹æ¶æ„çš„åˆ†ç±»å’Œæ€§èƒ½æ¯”è¾ƒï¼Œè€Œå¿½ç•¥äº†æ•°æ®é›†æœ¬èº«å¯¹æ¨¡å‹è®¾è®¡çš„å½±å“ã€‚ä¸åŒçš„è§†é¢‘æ•°æ®é›†åœ¨è¿åŠ¨å¤æ‚æ€§ã€æ—¶é—´è·¨åº¦ã€å¤šæ¨¡æ€ä¿¡æ¯ç­‰æ–¹é¢å­˜åœ¨å·®å¼‚ï¼Œè¿™äº›å·®å¼‚ä¼šå¯¹æ¨¡å‹çš„é€‰æ‹©å’Œè®¾è®¡äº§ç”Ÿé‡è¦çš„å½±å“ã€‚å› æ­¤ï¼Œéœ€è¦ä»æ•°æ®é›†çš„è§’åº¦æ¥ç†è§£è§†é¢‘ç†è§£æ¨¡å‹çš„å‘å±•å†ç¨‹ï¼Œå¹¶æŒ‡å¯¼æœªæ¥çš„æ¨¡å‹è®¾è®¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ä»æ•°æ®é›†çš„ç‰¹æ€§å‡ºå‘ï¼Œåˆ†æè¿™äº›ç‰¹æ€§å¦‚ä½•å¯¹æ¨¡å‹æ¶æ„äº§ç”Ÿâ€œå‹åŠ›â€ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹çš„è®¾è®¡ã€‚å…·ä½“æ¥è¯´ï¼Œè®ºæ–‡å…³æ³¨å››ä¸ªå…³é”®çš„æ•°æ®é›†ç‰¹æ€§ï¼šè¿åŠ¨å¤æ‚æ€§ã€æ—¶é—´è·¨åº¦ã€åˆ†å±‚ç»„åˆå’Œå¤šæ¨¡æ€ä¸°å¯Œæ€§ã€‚è¿™äº›ç‰¹æ€§å†³å®šäº†æ¨¡å‹éœ€è¦å…·å¤‡ä»€ä¹ˆæ ·çš„å½’çº³åç½®ï¼Œæ‰èƒ½æœ‰æ•ˆåœ°å¤„ç†è§†é¢‘æ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡æ„å»ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œå°†æ•°æ®é›†ã€å½’çº³åç½®å’Œæ¨¡å‹æ¶æ„è”ç³»èµ·æ¥ã€‚é¦–å…ˆï¼Œè®ºæ–‡åˆ†æäº†ä¸åŒè§†é¢‘æ•°æ®é›†çš„ç‰¹æ€§ï¼Œå¹¶å°†å…¶å½’çº³ä¸ºä¸Šè¿°å››ä¸ªå…³é”®ç»´åº¦ã€‚ç„¶åï¼Œè®ºæ–‡è®¨è®ºäº†è¿™äº›ç‰¹æ€§å¦‚ä½•å½±å“æ¨¡å‹çš„å½’çº³åç½®ï¼Œä¾‹å¦‚ï¼Œå¤„ç†é•¿æ—¶åºä¾èµ–éœ€è¦æ¨¡å‹å…·å¤‡è®°å¿†èƒ½åŠ›ï¼Œå¤„ç†å¤šæ¨¡æ€ä¿¡æ¯éœ€è¦æ¨¡å‹å…·å¤‡èåˆèƒ½åŠ›ã€‚æœ€åï¼Œè®ºæ–‡å›é¡¾äº†è§†é¢‘ç†è§£é¢†åŸŸçš„é‡è¦æ¨¡å‹ï¼Œå¹¶å°†å…¶è§†ä¸ºå¯¹æ•°æ®é›†â€œå‹åŠ›â€çš„å“åº”ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬è®ºæ–‡æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ä¸ªæ•°æ®é›†é©±åŠ¨çš„è§†é¢‘ç†è§£æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„æ¨¡å‹é©±åŠ¨æ–¹æ³•ä¸åŒï¼Œè¯¥æ¡†æ¶å¼ºè°ƒæ•°æ®é›†å¯¹æ¨¡å‹è®¾è®¡çš„å½±å“ï¼Œå¹¶æä¾›äº†ä¸€ç§æ–°çš„è§†è§’æ¥ç†è§£è§†é¢‘ç†è§£æ¨¡å‹çš„å‘å±•å†ç¨‹ã€‚è¿™ç§è§†è§’æœ‰åŠ©äºç ”ç©¶è€…æ›´å¥½åœ°é€‰æ‹©å’Œè®¾è®¡æ¨¡å‹ï¼Œä»¥é€‚åº”ä¸åŒçš„è§†é¢‘æ•°æ®é›†ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡å¹¶æ²¡æœ‰æå‡ºå…·ä½“çš„æ¨¡å‹æ¶æ„æˆ–ç®—æ³•ï¼Œè€Œæ˜¯æä¾›äº†ä¸€ä¸ªåˆ†ææ¡†æ¶ã€‚è¯¥æ¡†æ¶å¯ä»¥ç”¨äºåˆ†æç°æœ‰æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥ç”¨äºæŒ‡å¯¼æœªæ¥çš„æ¨¡å‹è®¾è®¡ã€‚ä¾‹å¦‚ï¼Œå½“å¤„ç†ä¸€ä¸ªåŒ…å«å¤æ‚è¿åŠ¨çš„è§†é¢‘æ•°æ®é›†æ—¶ï¼Œç ”ç©¶è€…åº”è¯¥é€‰æ‹©æˆ–è®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰è¿åŠ¨ä¿¡æ¯çš„æ¨¡å‹ã€‚å½“å¤„ç†ä¸€ä¸ªåŒ…å«å¤šæ¨¡æ€ä¿¡æ¯çš„è§†é¢‘æ•°æ®é›†æ—¶ï¼Œç ”ç©¶è€…åº”è¯¥é€‰æ‹©æˆ–è®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿæœ‰æ•ˆèåˆå¤šæ¨¡æ€ä¿¡æ¯çš„æ¨¡å‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºæå‡ºäº†æ•°æ®é›†é©±åŠ¨çš„è§†é¢‘ç†è§£æ¡†æ¶ï¼Œå¹¶ä»¥æ­¤é‡æ–°è§£è¯»äº†è§†é¢‘ç†è§£é¢†åŸŸçš„é‡è¦æ¨¡å‹ã€‚é€šè¿‡åˆ†ææ•°æ®é›†çš„è¿åŠ¨å¤æ‚æ€§ã€æ—¶é—´è·¨åº¦ã€åˆ†å±‚ç»„åˆå’Œå¤šæ¨¡æ€ä¸°å¯Œæ€§ç­‰ç‰¹æ€§ï¼Œæ­ç¤ºäº†æ•°æ®é›†å¦‚ä½•å¡‘é€ æ¨¡å‹æ¶æ„ã€‚è¯¥æ¡†æ¶ä¸ºæ¨¡å‹è®¾è®¡æä¾›äº†æ–°çš„è§†è§’å’ŒæŒ‡å¯¼ï¼Œæœ‰åŠ©äºç ”ç©¶è€…æ›´å¥½åœ°é€‰æ‹©å’Œè®¾è®¡æ¨¡å‹ä»¥é€‚åº”ä¸åŒçš„è§†é¢‘æ•°æ®é›†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè§†é¢‘å†…å®¹åˆ†æã€æ™ºèƒ½ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ã€äººæœºäº¤äº’ç­‰é¢†åŸŸã€‚é€šè¿‡ç†è§£æ•°æ®é›†ç‰¹æ€§ä¸æ¨¡å‹æ¶æ„ä¹‹é—´çš„å…³ç³»ï¼Œå¯ä»¥ä¸ºç‰¹å®šåº”ç”¨åœºæ™¯é€‰æ‹©æˆ–è®¾è®¡æ›´åˆé€‚çš„è§†é¢‘ç†è§£æ¨¡å‹ï¼Œæå‡ç³»ç»Ÿæ€§èƒ½å’Œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æ€è·¯å¯æ¨å¹¿åˆ°å…¶ä»–å¤šåª’ä½“æ•°æ®ç†è§£ä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Video understanding has advanced rapidly, fueled by increasingly complex datasets and powerful architectures. Yet existing surveys largely classify models by task or family, overlooking the structural pressures through which datasets guide architectural evolution. This survey is the first to adopt a dataset-driven perspective, showing how motion complexity, temporal span, hierarchical composition, and multimodal richness impose inductive biases that models should encode. We reinterpret milestones, from two-stream and 3D CNNs to sequential, transformer, and multimodal foundation models, as concrete responses to these dataset-driven pressures. Building on this synthesis, we offer practical guidance for aligning model design with dataset invariances while balancing scalability and task demands. By unifying datasets, inductive biases, and architectures into a coherent framework, this survey provides both a comprehensive retrospective and a prescriptive roadmap for advancing general-purpose video understanding.

