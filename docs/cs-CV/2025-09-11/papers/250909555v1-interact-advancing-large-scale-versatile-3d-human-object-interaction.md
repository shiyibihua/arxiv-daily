---
layout: default
title: InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation
---

# InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09555" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09555v1</a>
  <a href="https://arxiv.org/pdf/2509.09555.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09555v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09555v1', 'InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sirui Xu, Dongting Li, Yucheng Zhang, Xiyan Xu, Qi Long, Ziyin Wang, Yunzhi Lu, Shuchang Dong, Hezi Jiang, Akshat Gupta, Yu-Xiong Wang, Liang-Yan Gui

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11

**å¤‡æ³¨**: CVPR 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/wzyabcas/InterAct)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**InterActï¼šæå‡ºå¤§è§„æ¨¡é€šç”¨3Däºº-ç‰©äº¤äº’ç”Ÿæˆæ•°æ®é›†ä¸æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `äºº-ç‰©äº¤äº’` `3Dç”Ÿæˆ` `æ•°æ®é›†` `åŠ¨ä½œæ•æ‰` `æ•°æ®å¢å¼º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰HOIæ•°æ®é›†è§„æ¨¡å°ã€è´¨é‡ä½ï¼Œå­˜åœ¨ä¼ªå½±å’Œæ ‡æ³¨ä¸è¶³ï¼Œé™åˆ¶äº†3Däºº-ç‰©äº¤äº’ç”Ÿæˆæ¨¡å‹çš„å‘å±•ã€‚
2. InterActé€šè¿‡æ•´åˆå¤šæºæ•°æ®ã€ä¼˜åŒ–æ•°æ®è´¨é‡å’Œåˆ©ç”¨æ¥è§¦ä¸å˜æ€§è¿›è¡Œæ•°æ®å¢å¼ºï¼Œæ„å»ºäº†å¤§è§„æ¨¡é«˜è´¨é‡çš„HOIæ•°æ®é›†ã€‚
3. è®ºæ–‡å®šä¹‰äº†å…­ä¸ªHOIç”Ÿæˆä»»åŠ¡ï¼Œå¹¶æå‡ºäº†ç»Ÿä¸€çš„ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨InterActæ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼ŒéªŒè¯äº†æ•°æ®é›†çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”±äºæ•°æ®é›†çš„é™åˆ¶ï¼Œå»ºæ¨¡å’Œç”ŸæˆåŠ¨æ€3Däºº-ç‰©äº¤äº’ï¼ˆHOIï¼‰ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç°æœ‰çš„æ•°æ®é›†é€šå¸¸ç¼ºä¹å¹¿æ³›ã€é«˜è´¨é‡çš„è¿åŠ¨å’Œæ ‡æ³¨ï¼Œå¹¶ä¸”å­˜åœ¨æ¥è§¦ç©¿é€ã€æ¼‚æµ®å’Œä¸æ­£ç¡®çš„æ‰‹éƒ¨è¿åŠ¨ç­‰ä¼ªå½±ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†InterActï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„3D HOIåŸºå‡†ï¼Œå…·æœ‰æ•°æ®é›†å’Œæ–¹æ³•ä¸Šçš„è¿›æ­¥ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ•´åˆå’Œæ ‡å‡†åŒ–äº†æ¥è‡ªä¸åŒæ¥æºçš„21.81å°æ—¶çš„HOIæ•°æ®ï¼Œå¹¶ç”¨è¯¦ç»†çš„æ–‡æœ¬æ³¨é‡Šä¸°å¯Œäº†å®ƒã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡å‡å°‘ä¼ªå½±å’Œçº æ­£æ‰‹éƒ¨è¿åŠ¨æ¥æé«˜æ•°æ®è´¨é‡ã€‚åˆ©ç”¨æ¥è§¦ä¸å˜æ€§åŸåˆ™ï¼Œæˆ‘ä»¬åœ¨ä¿æŒäºº-ç‰©å…³ç³»çš„åŒæ—¶å¼•å…¥è¿åŠ¨å˜åŒ–ï¼Œå°†æ•°æ®é›†æ‰©å±•åˆ°30.70å°æ—¶ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬å®šä¹‰äº†å…­ä¸ªåŸºå‡†æµ‹è¯•ä»»åŠ¡ï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªç»Ÿä¸€çš„HOIç”Ÿæˆå»ºæ¨¡è§†è§’ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å¤§é‡çš„å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„æ•°æ®é›†ä½œä¸ºæ¨è¿›3Däºº-ç‰©äº¤äº’ç”Ÿæˆçš„åŸºç¡€èµ„æºçš„æ•ˆç”¨ã€‚ä¸ºäº†æ”¯æŒè¯¥é¢†åŸŸçš„æŒç»­ç ”ç©¶ï¼Œè¯¥æ•°æ®é›†å¯åœ¨https://github.com/wzyabcas/InterActå…¬å¼€è·å–ï¼Œå¹¶å°†å¾—åˆ°ç§¯æç»´æŠ¤ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰3Däºº-ç‰©äº¤äº’ï¼ˆHOIï¼‰æ•°æ®é›†è§„æ¨¡æœ‰é™ï¼Œæ•°æ®è´¨é‡ä¸é«˜ï¼Œå­˜åœ¨æ¥è§¦ç©¿é€ã€æ¼‚æµ®ç­‰ä¼ªå½±ï¼Œæ‰‹éƒ¨åŠ¨ä½œä¸å‡†ç¡®ï¼Œç¼ºä¹è¯¦ç»†çš„æ–‡æœ¬æ ‡æ³¨ã€‚è¿™äº›é—®é¢˜ä¸¥é‡é˜»ç¢äº†HOIç”Ÿæˆæ¨¡å‹çš„å‘å±•ï¼Œä½¿å…¶éš¾ä»¥å­¦ä¹ åˆ°çœŸå®ã€è‡ªç„¶çš„äº¤äº’æ¨¡å¼ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„HOIæ•°æ®é›†ï¼Œå¹¶æå‡ºä¸€ä¸ªç»Ÿä¸€çš„ç”Ÿæˆæ¨¡å‹ã€‚é€šè¿‡æ•´åˆå¤šæºæ•°æ®ï¼Œåˆ©ç”¨ä¼˜åŒ–æ¡†æ¶å‡å°‘ä¼ªå½±ï¼Œå¹¶åˆ©ç”¨æ¥è§¦ä¸å˜æ€§è¿›è¡Œæ•°æ®å¢å¼ºï¼Œä»è€Œæé«˜æ•°æ®é›†çš„è§„æ¨¡å’Œè´¨é‡ã€‚åŒæ—¶ï¼Œè®¾è®¡ä¸€ä¸ªç»Ÿä¸€çš„ç”Ÿæˆæ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†ä¸åŒçš„HOIç”Ÿæˆä»»åŠ¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šInterActçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼šæ•°æ®æ”¶é›†ä¸æ•´åˆã€æ•°æ®ä¼˜åŒ–ä¸å¢å¼ºã€HOIç”Ÿæˆæ¨¡å‹ã€‚é¦–å…ˆï¼Œä»å¤šä¸ªæ¥æºæ”¶é›†HOIæ•°æ®ï¼Œå¹¶è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ã€‚ç„¶åï¼Œåˆ©ç”¨ä¼˜åŒ–æ¡†æ¶å‡å°‘ä¼ªå½±ï¼Œå¹¶åˆ©ç”¨æ¥è§¦ä¸å˜æ€§è¿›è¡Œæ•°æ®å¢å¼ºã€‚æœ€åï¼Œæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„HOIç”Ÿæˆæ¨¡å‹ï¼Œç”¨äºå¤„ç†ä¸åŒçš„HOIç”Ÿæˆä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºï¼š1) æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„HOIæ•°æ®é›†InterActï¼Œè§£å†³äº†ç°æœ‰æ•°æ®é›†è§„æ¨¡å°ã€è´¨é‡ä½çš„é—®é¢˜ã€‚2) æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ä¼˜åŒ–æ¡†æ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘HOIæ•°æ®ä¸­çš„ä¼ªå½±ã€‚3) åˆ©ç”¨æ¥è§¦ä¸å˜æ€§è¿›è¡Œæ•°æ®å¢å¼ºï¼Œåœ¨ä¿æŒäºº-ç‰©å…³ç³»çš„åŒæ—¶å¼•å…¥è¿åŠ¨å˜åŒ–ï¼Œè¿›ä¸€æ­¥æ‰©å¤§äº†æ•°æ®é›†çš„è§„æ¨¡ã€‚4) æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„HOIç”Ÿæˆæ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†ä¸åŒçš„HOIç”Ÿæˆä»»åŠ¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®ä¼˜åŒ–é˜¶æ®µï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ä¸ªåŸºäºä¼˜åŒ–çš„æ¡†æ¶ï¼Œé€šè¿‡æœ€å°åŒ–æ¥è§¦ç©¿é€ã€æ¼‚æµ®ç­‰ä¼ªå½±çš„èƒ½é‡å‡½æ•°æ¥æé«˜æ•°æ®è´¨é‡ã€‚åœ¨æ•°æ®å¢å¼ºé˜¶æ®µï¼Œè®ºæ–‡åˆ©ç”¨æ¥è§¦ä¸å˜æ€§åŸåˆ™ï¼Œåœ¨ä¿æŒäºº-ç‰©æ¥è§¦å…³ç³»çš„åŒæ—¶ï¼Œå¯¹äººä½“è¿åŠ¨è¿›è¡Œå¾®è°ƒï¼Œä»è€Œç”Ÿæˆæ–°çš„HOIæ•°æ®ã€‚åœ¨HOIç”Ÿæˆæ¨¡å‹ä¸­ï¼Œè®ºæ–‡é‡‡ç”¨Transformeræ¶æ„ï¼Œå¹¶è®¾è®¡äº†ä¸“é—¨çš„æŸå¤±å‡½æ•°æ¥é¼“åŠ±ç”ŸæˆçœŸå®ã€è‡ªç„¶çš„HOIåºåˆ—ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

InterActæ•°æ®é›†åŒ…å«21.81å°æ—¶çš„åŸå§‹HOIæ•°æ®ï¼Œç»è¿‡ä¼˜åŒ–å’Œå¢å¼ºåè¾¾åˆ°30.70å°æ—¶ã€‚åœ¨å…­ä¸ªHOIç”Ÿæˆä»»åŠ¡ä¸Šï¼Œè®ºæ–‡æå‡ºçš„ç»Ÿä¸€ç”Ÿæˆæ¨¡å‹å‡å–å¾—äº†SOTAæ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†InterActæ•°æ®é›†çš„æœ‰æ•ˆæ€§å’Œæ¨¡å‹çš„ä¼˜è¶Šæ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

InterActæ•°æ®é›†å’Œç›¸å…³æŠ€æœ¯å¯å¹¿æ³›åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€æ¸¸æˆå¼€å‘ã€æœºå™¨äººæ§åˆ¶ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºç”Ÿæˆé€¼çœŸçš„äººä¸è™šæ‹Ÿç‰©ä½“çš„äº¤äº’åŠ¨ç”»ï¼Œæé«˜VR/ARä½“éªŒçš„æ²‰æµ¸æ„Ÿï¼›å¯ä»¥ç”¨äºè®­ç»ƒæœºå™¨äººå­¦ä¹ å¦‚ä½•ä¸ç‰©ä½“è¿›è¡Œäº¤äº’ï¼Œä»è€Œå®ç°æ›´æ™ºèƒ½çš„æœºå™¨äººæ§åˆ¶ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While large-scale human motion capture datasets have advanced human motion generation, modeling and generating dynamic 3D human-object interactions (HOIs) remain challenging due to dataset limitations. Existing datasets often lack extensive, high-quality motion and annotation and exhibit artifacts such as contact penetration, floating, and incorrect hand motions. To address these issues, we introduce InterAct, a large-scale 3D HOI benchmark featuring dataset and methodological advancements. First, we consolidate and standardize 21.81 hours of HOI data from diverse sources, enriching it with detailed textual annotations. Second, we propose a unified optimization framework to enhance data quality by reducing artifacts and correcting hand motions. Leveraging the principle of contact invariance, we maintain human-object relationships while introducing motion variations, expanding the dataset to 30.70 hours. Third, we define six benchmarking tasks and develop a unified HOI generative modeling perspective, achieving state-of-the-art performance. Extensive experiments validate the utility of our dataset as a foundational resource for advancing 3D human-object interaction generation. To support continued research in this area, the dataset is publicly available at https://github.com/wzyabcas/InterAct, and will be actively maintained.

