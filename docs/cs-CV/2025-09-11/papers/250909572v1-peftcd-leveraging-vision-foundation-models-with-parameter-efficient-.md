---
layout: default
title: PeftCD: Leveraging Vision Foundation Models with Parameter-Efficient Fine-Tuning for Remote Sensing Change Detection
---

# PeftCD: Leveraging Vision Foundation Models with Parameter-Efficient Fine-Tuning for Remote Sensing Change Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09572" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.09572v1</a>
  <a href="https://arxiv.org/pdf/2509.09572.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09572v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09572v1', 'PeftCD: Leveraging Vision Foundation Models with Parameter-Efficient Fine-Tuning for Remote Sensing Change Detection')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Sijun Dong, Yuxuan Hu, LiBo Wang, Geng Chen, Xiaoliang Meng

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-11

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/dyzy41/PeftCD)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**PeftCDÔºöÂà©Áî®ÂèÇÊï∞È´òÊïàÂæÆË∞ÉÁöÑËßÜËßâÂü∫Á°ÄÊ®°ÂûãËøõË°åÈÅ•ÊÑüÂèòÂåñÊ£ÄÊµã**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÈÅ•ÊÑüÂèòÂåñÊ£ÄÊµã` `ËßÜËßâÂü∫Á°ÄÊ®°Âûã` `ÂèÇÊï∞È´òÊïàÂæÆË∞É` `SiameseÁΩëÁªú` `LoRA` `Adapter` `‰º™ÂèòÂåñÊäëÂà∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ÈÅ•ÊÑüÂèòÂåñÊ£ÄÊµãÈù¢‰∏¥‰º™ÂèòÂåñÂπ≤Êâ∞„ÄÅÊ†áÊ≥®Êï∞ÊçÆ‰∏çË∂≥ÂíåË∑®È¢ÜÂüüÊ≥õÂåñÊÄßÂ∑ÆÁ≠âÊåëÊàò„ÄÇ
2. PeftCDÂà©Áî®ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÔºåÈÄöËøáÂèÇÊï∞È´òÊïàÂæÆË∞ÉÔºåÂÆûÁé∞Âø´ÈÄüÈÄÇÂ∫îÁâπÂÆöÈÅ•ÊÑüÂèòÂåñÊ£ÄÊµã‰ªªÂä°„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåPeftCDÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äËææÂà∞SOTAÔºåÊúâÊïàÊäëÂà∂‰º™ÂèòÂåñÔºåËæπÁïåÂàíÂàÜÊõ¥Á≤æÁ°Æ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∏∫‰∫ÜËß£ÂÜ≥Â§öÊó∂Áõ∏ÂíåÂ§öÊ∫êÈÅ•ÊÑüÂõæÂÉè‰∏≠‰º™ÂèòÂåñÊôÆÈÅç„ÄÅÊ†áËÆ∞Ê†∑Êú¨Á®ÄÁº∫‰ª•ÂèäË∑®ÂüüÊ≥õÂåñÂõ∞ÈöæÁöÑÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜPeftCDÔºåËøôÊòØ‰∏Ä‰∏™Âª∫Á´ãÂú®ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÔºàVFMsÔºâ‰πã‰∏äÔºåÂπ∂ÈááÁî®ÂèÇÊï∞È´òÊïàÂæÆË∞ÉÔºàPEFTÔºâÁöÑÂèòÂåñÊ£ÄÊµãÊ°ÜÊû∂„ÄÇPeftCDÁöÑÊ†∏ÂøÉÊòØÈááÁî®‰∏Ä‰∏™Ê∫êËá™VFMÁöÑÊùÉÈáçÂÖ±‰∫´SiameseÁºñÁ†ÅÂô®ÔºåÂÖ∂‰∏≠Êó†ÁºùÈõÜÊàê‰∫ÜLoRAÂíåAdapterÊ®°Âùó„ÄÇËøôÁßçËÆæËÆ°ÈÄöËøá‰ªÖËÆ≠ÁªÉÊúÄÂ∞ëÊï∞ÈáèÁöÑÈôÑÂä†ÂèÇÊï∞Êù•ÂÆûÁé∞È´òÊïàÁöÑ‰ªªÂä°ÈÄÇÂ∫î„ÄÇ‰∏∫‰∫ÜÂÖÖÂàÜÈáäÊîæVFMÁöÑÊΩúÂäõÔºåÊàë‰ª¨Á†îÁ©∂‰∫Ü‰∏§‰∏™È¢ÜÂÖàÁöÑÈ™®Âπ≤ÁΩëÁªúÔºö‰ª•Âº∫Â§ßÁöÑÂàÜÂâ≤ÂÖàÈ™åËÄåÈóªÂêçÁöÑSegment Anything Model v2ÔºàSAM2ÔºâÂíåÊúÄÂÖàËøõÁöÑËá™ÁõëÁù£Ë°®Á§∫Â≠¶‰π†Âô®DINOv3„ÄÇËØ•Ê°ÜÊû∂Áî±‰∏Ä‰∏™Á≤æÂøÉËÆæËÆ°ÁöÑËΩªÈáèÁ∫ßËß£Á†ÅÂô®Ë°•ÂÖÖÔºåÁ°Æ‰øùÈáçÁÇπ‰ªçÁÑ∂ÊîæÂú®Êù•Ëá™È™®Âπ≤ÁΩëÁªúÁöÑÂº∫Â§ßÁâπÂæÅË°®Á§∫‰∏ä„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåPeftCDÂú®Â§ö‰∏™ÂÖ¨ÂÖ±Êï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂåÖÊã¨SYSU-CDÔºàIoU 73.81%Ôºâ„ÄÅWHUCDÔºà92.05%Ôºâ„ÄÅMSRSCDÔºà64.07%Ôºâ„ÄÅMLCDÔºà76.89%Ôºâ„ÄÅCDDÔºà97.01%Ôºâ„ÄÅS2LookingÔºà52.25%ÔºâÂíåLEVIR-CDÔºà85.62%ÔºâÔºåÂÖ∑ÊúâÊòæËëóÁ≤æÁ°ÆÁöÑËæπÁïåÊèèÁªòÂíåÂØπ‰º™ÂèòÂåñÁöÑÂº∫Â§ßÊäëÂà∂„ÄÇÊÄª‰πãÔºåPeftCDÂú®ÂáÜÁ°ÆÊÄß„ÄÅÊïàÁéáÂíåÊ≥õÂåñÊÄß‰πãÈó¥ÂÆûÁé∞‰∫ÜÊúÄ‰Ω≥Âπ≥Ë°°„ÄÇÂÆÉ‰∏∫Â∞ÜÂ§ßËßÑÊ®°VFMÂ∫îÁî®‰∫éÂÆûÈôÖÈÅ•ÊÑüÂèòÂåñÊ£ÄÊµãÂ∫îÁî®Êèê‰æõ‰∫Ü‰∏Ä‰∏™Âº∫Â§ß‰∏îÂèØÊâ©Â±ïÁöÑËåÉ‰æã„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÈÅ•ÊÑüÂèòÂåñÊ£ÄÊµãÊó®Âú®ËØÜÂà´‰∏çÂêåÊó∂Èó¥Ëé∑ÂèñÁöÑÂêå‰∏ÄÂå∫ÂüüÈÅ•ÊÑüÂõæÂÉè‰πãÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÊ†áÊ≥®Êï∞ÊçÆËøõË°åËÆ≠ÁªÉÔºå‰∏îÂÆπÊòìÂèóÂà∞‰º™ÂèòÂåñÁöÑÂΩ±ÂìçÔºåÊ≥õÂåñËÉΩÂäõÊúâÈôê„ÄÇÊ≠§Â§ñÔºåÁõ¥Êé•ÂæÆË∞ÉÂ§ßÂûãËßÜËßâÊ®°ÂûãÊàêÊú¨È´òÊòÇÔºåÊïàÁéá‰Ωé‰∏ã„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöPeftCDÁöÑÊ†∏ÂøÉÂú®‰∫éÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑËßÜËßâÂü∫Á°ÄÊ®°ÂûãÔºàVFMsÔºâÁöÑÂº∫Â§ßÁâπÂæÅÊèêÂèñËÉΩÂäõÔºåÂπ∂ÈÄöËøáÂèÇÊï∞È´òÊïàÂæÆË∞ÉÔºàPEFTÔºâÊñπÊ≥ïÔºå‰ªÖËÆ≠ÁªÉÂ∞ëÈáèÂèÇÊï∞Âç≥ÂèØÈÄÇÂ∫îÁâπÂÆöÁöÑÂèòÂåñÊ£ÄÊµã‰ªªÂä°„ÄÇËøôÁßçÊñπÊ≥ïÊó¢ËÉΩÂà©Áî®VFMÁöÑÈÄöÁî®Áü•ËØÜÔºåÂèàËÉΩÈÅøÂÖç‰ªéÂ§¥ËÆ≠ÁªÉÊàñÂÖ®ÂèÇÊï∞ÂæÆË∞ÉÂ∏¶Êù•ÁöÑÈ´òÊàêÊú¨ÂíåËøáÊãüÂêàÈ£éÈô©„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPeftCDÈááÁî®SiameseÁΩëÁªúÁªìÊûÑÔºåÂåÖÂê´‰∏§‰∏™ÂÖ±‰∫´ÊùÉÈáçÁöÑÁºñÁ†ÅÂô®ÔºåÂàÜÂà´Â§ÑÁêÜ‰∏çÂêåÊó∂Áõ∏ÁöÑÈÅ•ÊÑüÂõæÂÉè„ÄÇÁºñÁ†ÅÂô®Âü∫‰∫éVFMÔºàÂ¶ÇSAM2ÊàñDINOv3ÔºâÔºåÂπ∂ÈõÜÊàêLoRAÊàñAdapterÊ®°ÂùóËøõË°åÂèÇÊï∞È´òÊïàÂæÆË∞É„ÄÇÁºñÁ†ÅÂô®ÊèêÂèñÁöÑÁâπÂæÅÁªèËøáËΩªÈáèÁ∫ßËß£Á†ÅÂô®ËøõË°åËûçÂêàÂíåÂ§ÑÁêÜÔºåÊúÄÁªàËæìÂá∫ÂèòÂåñÊ£ÄÊµãÁªìÊûú„ÄÇÊï¥‰ΩìÊµÅÁ®ãÂåÖÊã¨ÔºöÂõæÂÉèËæìÂÖ• -> VFMÁºñÁ†ÅÂô®ÔºàLoRA/AdapterÂæÆË∞ÉÔºâ -> ÁâπÂæÅÊèêÂèñ -> ËΩªÈáèÁ∫ßËß£Á†ÅÂô® -> ÂèòÂåñÊ£ÄÊµãÁªìÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöPeftCDÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÂèÇÊï∞È´òÊïàÂæÆË∞ÉÊäÄÊúØ‰∏éËßÜËßâÂü∫Á°ÄÊ®°ÂûãÁõ∏ÁªìÂêàÔºåÁî®‰∫éÈÅ•ÊÑüÂèòÂåñÊ£ÄÊµã„ÄÇÈÄöËøáLoRAÊàñAdapterÁ≠âPEFTÊñπÊ≥ïÔºå‰ªÖÈúÄËÆ≠ÁªÉÂ∞ëÈáèÂèÇÊï∞Âç≥ÂèØÂÆûÁé∞ÂØπVFMÁöÑÊúâÊïàÈÄÇÂ∫îÔºåÊòæËëóÈôç‰Ωé‰∫ÜËÆ°ÁÆóÊàêÊú¨ÂíåÂ≠òÂÇ®ÈúÄÊ±ÇÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜËæÉÈ´òÁöÑÊ£ÄÊµãÁ≤æÂ∫¶„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÂØπ‰º™ÂèòÂåñÁöÑÊäëÂà∂ËÉΩÂäõÊõ¥Âº∫ÔºåÊ≥õÂåñÊÄßËÉΩÊõ¥Â•Ω„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöPeftCDÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ÈÄâÊã©ÂêàÈÄÇÁöÑVFM‰Ωú‰∏∫È™®Âπ≤ÁΩëÁªúÔºåÂ¶ÇSAM2ÊàñDINOv3ÔºåÂà©Áî®ÂÖ∂Âº∫Â§ßÁöÑÁâπÂæÅÊèêÂèñËÉΩÂäõÔºõ2) ÈõÜÊàêLoRAÊàñAdapterÊ®°ÂùóÔºåÂÆûÁé∞ÂèÇÊï∞È´òÊïàÂæÆË∞ÉÔºõ3) ËÆæËÆ°ËΩªÈáèÁ∫ßËß£Á†ÅÂô®ÔºåÈÅøÂÖçÂºïÂÖ•ËøáÂ§öÂèÇÊï∞Ôºå‰øùÊåÅÊ®°ÂûãÁöÑÁÆÄÊ¥ÅÊÄßÔºõ4) ÈááÁî®ÂêàÈÄÇÁöÑÊçüÂ§±ÂáΩÊï∞ÔºåÂ¶Ç‰∫§ÂèâÁÜµÊçüÂ§±ÊàñDiceÊçüÂ§±Ôºå‰ºòÂåñÂèòÂåñÊ£ÄÊµãÁªìÊûú„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

PeftCDÂú®Â§ö‰∏™ÂÖ¨ÂºÄÈÅ•ÊÑüÂèòÂåñÊ£ÄÊµãÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜSOTAÊÄßËÉΩÔºå‰æãÂ¶ÇÂú®SYSU-CD‰∏äIoUËææÂà∞73.81%ÔºåÂú®WHUCD‰∏äËææÂà∞92.05%ÔºåÂú®CDD‰∏äËææÂà∞97.01%„ÄÇÁõ∏ËæÉ‰∫é‰º†ÁªüÊñπÊ≥ïÔºåPeftCDÂú®Á≤æÂ∫¶„ÄÅÊïàÁéáÂíåÊ≥õÂåñÊÄßÊñπÈù¢ÂùáÊúâÊòæËëóÊèêÂçáÔºåÂ∞§ÂÖ∂Âú®ÊäëÂà∂‰º™ÂèòÂåñÂíåÁ≤æÁ°ÆËæπÁïåÊèèÁªòÊñπÈù¢Ë°®Áé∞Á™ÅÂá∫„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

PeftCDÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÂüéÂ∏ÇËßÑÂàí„ÄÅÁÅæÂÆ≥ÁõëÊµã„ÄÅÁéØÂ¢ÉËØÑ‰º∞„ÄÅÂÜú‰∏öÁÆ°ÁêÜÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÂø´ÈÄüÂáÜÁ°ÆÂú∞Ê£ÄÊµãÂú∞Ë°®ÂèòÂåñÔºå‰∏∫ÂÜ≥Á≠ñËÄÖÊèê‰æõÂèäÊó∂ÊúâÊïàÁöÑ‰ø°ÊÅØÊîØÊåÅÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄºÂíåÁ§æ‰ºöÁªèÊµéÊïàÁõä„ÄÇÊú™Êù•ÂèØËøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞Êõ¥Â§öÁ±ªÂûãÁöÑÈÅ•ÊÑüÊï∞ÊçÆÂíåÊõ¥Â§çÊùÇÁöÑÂú∫ÊôØÔºå‰æãÂ¶Ç‰∏âÁª¥ÂèòÂåñÊ£ÄÊµãÂíåÂ§öÊ®°ÊÄÅÊï∞ÊçÆËûçÂêà„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> To tackle the prevalence of pseudo changes, the scarcity of labeled samples, and the difficulty of cross-domain generalization in multi-temporal and multi-source remote sensing imagery, we propose PeftCD, a change detection framework built upon Vision Foundation Models (VFMs) with Parameter-Efficient Fine-Tuning (PEFT). At its core, PeftCD employs a weight-sharing Siamese encoder derived from a VFM, into which LoRA and Adapter modules are seamlessly integrated. This design enables highly efficient task adaptation by training only a minimal set of additional parameters. To fully unlock the potential of VFMs, we investigate two leading backbones: the Segment Anything Model v2 (SAM2), renowned for its strong segmentation priors, and DINOv3, a state-of-the-art self-supervised representation learner. The framework is complemented by a deliberately lightweight decoder, ensuring the focus remains on the powerful feature representations from the backbones. Extensive experiments demonstrate that PeftCD achieves state-of-the-art performance across multiple public datasets, including SYSU-CD (IoU 73.81%), WHUCD (92.05%), MSRSCD (64.07%), MLCD (76.89%), CDD (97.01%), S2Looking (52.25%) and LEVIR-CD (85.62%), with notably precise boundary delineation and strong suppression of pseudo-changes. In summary, PeftCD presents an optimal balance of accuracy, efficiency, and generalization. It offers a powerful and scalable paradigm for adapting large-scale VFMs to real-world remote sensing change detection applications. The code and pretrained models will be released at https://github.com/dyzy41/PeftCD.

