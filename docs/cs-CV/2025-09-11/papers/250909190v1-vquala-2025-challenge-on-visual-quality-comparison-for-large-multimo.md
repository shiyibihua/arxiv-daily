---
layout: default
title: VQualA 2025 Challenge on Visual Quality Comparison for Large Multimodal Models: Methods and Results
---

# VQualA 2025 Challenge on Visual Quality Comparison for Large Multimodal Models: Methods and Results

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09190" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09190v1</a>
  <a href="https://arxiv.org/pdf/2509.09190.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09190v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09190v1', 'VQualA 2025 Challenge on Visual Quality Comparison for Large Multimodal Models: Methods and Results')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hanwei Zhu, Haoning Wu, Zicheng Zhang, Lingyu Zhu, Yixuan Li, Peilin Chen, Shiqi Wang, Chris Wei Zhou, Linhan Cao, Wei Sun, Xiangyang Zhu, Weixia Zhang, Yucheng Zhu, Jing Liu, Dandan Zhu, Guangtao Zhai, Xiongkuo Min, Zhichao Zhang, Xinyue Li, Shubo Xu, Anh Dao, Yifan Li, Hongyuan Yu, Jiaojiao Yi, Yiding Tian, Yupeng Wu, Feiran Sun, Lijuan Liao, Song Jiang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11

**å¤‡æ³¨**: ICCV VQualA Workshop 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VQualA 2025æŒ‘æˆ˜èµ›ï¼šè¯„ä¼°å¹¶æå‡å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨è§†è§‰è´¨é‡æ¯”è¾ƒæ–¹é¢çš„èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è´¨é‡è¯„ä¼°` `å¤§å‹å¤šæ¨¡æ€æ¨¡å‹` `è§†è§‰è´¨é‡æ¯”è¾ƒ` `åŸºå‡†æ•°æ®é›†` `æŒ‡ä»¤è°ƒæ•´`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LMMåœ¨è§†è§‰è´¨é‡æ¯”è¾ƒæ–¹é¢ç¼ºä¹ç»†ç²’åº¦å’Œå¼€æ”¾åŸŸçš„è¯„ä¼°åŸºå‡†ï¼Œé™åˆ¶äº†å…¶åœ¨è¯¥é¢†åŸŸçš„åº”ç”¨ã€‚
2. VQualA 2025æŒ‘æˆ˜èµ›æ„å»ºäº†åŒ…å«å¤šç§è§†è§‰è´¨é‡æ¯”è¾ƒä»»åŠ¡çš„æ–°åŸºå‡†ï¼Œæ—¨åœ¨å…¨é¢è¯„ä¼°LMMçš„è´¨é‡åˆ¤æ–­èƒ½åŠ›ã€‚
3. æŒ‘æˆ˜èµ›å¸å¼•äº†çº¦100åå‚ä¸è€…ï¼Œç»“æœè¡¨æ˜æŒ‡ä»¤è°ƒæ•´çš„LMMåœ¨è´¨é‡è¯„ä¼°æ–¹é¢å±•ç°å‡ºæ½œåŠ›ï¼Œä½†ä»æœ‰æå‡ç©ºé—´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ€»ç»“äº†ä½œä¸ºICCV 2025è§†è§‰è´¨é‡è¯„ä¼°ç ”è®¨ä¼šä¸€éƒ¨åˆ†çš„VQualA 2025å¤§å‹å¤šæ¨¡æ€æ¨¡å‹è§†è§‰è´¨é‡æ¯”è¾ƒæŒ‘æˆ˜èµ›ã€‚è¯¥æŒ‘æˆ˜èµ›æ—¨åœ¨è¯„ä¼°å’Œæå‡æœ€å…ˆè¿›çš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨æ‰§è¡Œå…³äºå¤šä¸ªå›¾åƒä¹‹é—´è§†è§‰è´¨é‡å·®å¼‚çš„å¼€æ”¾å¼å’Œè¯¦ç»†æ¨ç†æ–¹é¢çš„èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæ¯”èµ›å¼•å…¥äº†ä¸€ä¸ªæ–°é¢–çš„åŸºå‡†ï¼ŒåŒ…å«æ•°åƒä¸ªç”±ç²—åˆ°ç»†ç²’åº¦çš„è§†è§‰è´¨é‡æ¯”è¾ƒä»»åŠ¡ï¼Œæ¶µç›–å•ä¸ªå›¾åƒã€å›¾åƒå¯¹å’Œå¤šå›¾åƒç»„ã€‚æ¯ä¸ªä»»åŠ¡éƒ½è¦æ±‚æ¨¡å‹æä¾›å‡†ç¡®çš„è´¨é‡åˆ¤æ–­ã€‚æ¯”èµ›å¼ºè°ƒæ•´ä½“è¯„ä¼°åè®®ï¼ŒåŒ…æ‹¬åŸºäº2AFCçš„äºŒå…ƒåå¥½å’Œå¤šé¡¹é€‰æ‹©é¢˜ï¼ˆMCQsï¼‰ã€‚å¤§çº¦100åå‚ä¸è€…æäº¤äº†å‚èµ›ä½œå“ï¼Œå…¶ä¸­äº”ä¸ªæ¨¡å‹å±•ç¤ºäº†æŒ‡ä»¤è°ƒæ•´LMMsåœ¨è´¨é‡è¯„ä¼°æ–¹é¢çš„æ–°å…´èƒ½åŠ›ã€‚è¿™é¡¹æŒ‘æˆ˜æ ‡å¿—ç€æœç€å¼€æ”¾åŸŸè§†è§‰è´¨é‡æ¨ç†å’Œæ¯”è¾ƒè¿ˆå‡ºçš„é‡è¦ä¸€æ­¥ï¼Œå¹¶ä¸ºæœªæ¥å¯è§£é‡Šå’Œäººç±»å¯¹é½çš„è´¨é‡è¯„ä¼°ç³»ç»Ÿçš„ç ”ç©¶æä¾›äº†å‚¬åŒ–å‰‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨è§†è§‰è´¨é‡æ¯”è¾ƒä»»åŠ¡ä¸­ç¼ºä¹æœ‰æ•ˆè¯„ä¼°å’Œæå‡çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¼€æ”¾åŸŸå’Œç»†ç²’åº¦è§†è§‰è´¨é‡æ¯”è¾ƒæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œç¼ºä¹ç»Ÿä¸€çš„åŸºå‡†å’Œè¯„ä¼°åè®®ï¼Œéš¾ä»¥å…¨é¢è¡¡é‡LMMçš„æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«å¤šç§è§†è§‰è´¨é‡æ¯”è¾ƒä»»åŠ¡çš„æ–°åŸºå‡†ï¼Œå¹¶è®¾è®¡ç›¸åº”çš„è¯„ä¼°åè®®ï¼Œæ¥ä¿ƒè¿›LMMåœ¨è§†è§‰è´¨é‡æ¯”è¾ƒæ–¹é¢çš„ç ”ç©¶ã€‚è¯¥åŸºå‡†æ¶µç›–äº†å•å¼ å›¾åƒã€å›¾åƒå¯¹å’Œå¤šå¼ å›¾åƒç»„çš„æ¯”è¾ƒï¼Œå¹¶è¦æ±‚æ¨¡å‹æä¾›å‡†ç¡®çš„è´¨é‡åˆ¤æ–­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVQualA 2025æŒ‘æˆ˜èµ›çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) æ„å»ºåŒ…å«æ•°åƒä¸ªè§†è§‰è´¨é‡æ¯”è¾ƒä»»åŠ¡çš„æ–°åŸºå‡†ï¼›2) è®¾è®¡åŸºäº2AFCçš„äºŒå…ƒåå¥½å’Œå¤šé¡¹é€‰æ‹©é¢˜ï¼ˆMCQsï¼‰çš„è¯„ä¼°åè®®ï¼›3) ç»„ç»‡æ¯”èµ›ï¼Œå¸å¼•ç ”ç©¶äººå‘˜æäº¤LMMæ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼›4) åˆ†ææ¯”èµ›ç»“æœï¼Œæ€»ç»“LMMåœ¨è§†è§‰è´¨é‡æ¯”è¾ƒæ–¹é¢çš„ä¼˜åŠ¿å’Œä¸è¶³ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªæ–°é¢–çš„ã€ç”±ç²—åˆ°ç»†ç²’åº¦çš„è§†è§‰è´¨é‡æ¯”è¾ƒåŸºå‡†ï¼Œè¯¥åŸºå‡†æ¶µç›–äº†å¤šç§ç±»å‹çš„è§†è§‰è´¨é‡æ¯”è¾ƒä»»åŠ¡ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°LMMçš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†åŸºäº2AFCå’ŒMCQsçš„è¯„ä¼°åè®®ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¡¡é‡LMMçš„è´¨é‡åˆ¤æ–­èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåŸºå‡†æ•°æ®é›†åŒ…å«å•å¼ å›¾åƒã€å›¾åƒå¯¹å’Œå¤šå¼ å›¾åƒç»„çš„æ¯”è¾ƒä»»åŠ¡ï¼Œæ¶µç›–äº†å¤šç§è§†è§‰è´¨é‡å±æ€§ï¼Œå¦‚æ¸…æ™°åº¦ã€å¯¹æ¯”åº¦ã€è‰²å½©ç­‰ã€‚è¯„ä¼°åè®®é‡‡ç”¨2AFCå’ŒMCQsä¸¤ç§å½¢å¼ï¼Œèƒ½å¤Ÿä»ä¸åŒè§’åº¦è¯„ä¼°LMMçš„æ€§èƒ½ã€‚æ¯”èµ›é¼“åŠ±å‚ä¸è€…ä½¿ç”¨å„ç§LMMæ¨¡å‹ï¼Œå¹¶æ ¹æ®è¯„ä¼°ç»“æœè¿›è¡Œæ’åã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VQualA 2025æŒ‘æˆ˜èµ›å¸å¼•äº†çº¦100åå‚ä¸è€…ï¼Œæäº¤äº†å¤šç§LMMæ¨¡å‹ã€‚ç»“æœè¡¨æ˜ï¼Œç»è¿‡æŒ‡ä»¤è°ƒæ•´çš„LMMåœ¨è§†è§‰è´¨é‡æ¯”è¾ƒæ–¹é¢å±•ç°å‡ºæ½œåŠ›ï¼Œä½†ä»æœ‰æå‡ç©ºé—´ã€‚ä¾‹å¦‚ï¼Œéƒ¨åˆ†æ¨¡å‹åœ¨2AFCä»»åŠ¡ä¸­å–å¾—äº†è¾ƒå¥½çš„ç»“æœï¼Œä½†åœ¨MCQsä»»åŠ¡ä¸­è¡¨ç°ç›¸å¯¹è¾ƒå¼±ï¼Œè¡¨æ˜LMMåœ¨ç»†ç²’åº¦è§†è§‰è´¨é‡æ¨ç†æ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå›¾åƒ/è§†é¢‘è´¨é‡è¯„ä¼°ã€å›¾åƒå¢å¼ºã€å›¾åƒä¿®å¤ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡LMMåœ¨è§†è§‰è´¨é‡æ¯”è¾ƒæ–¹é¢çš„èƒ½åŠ›ï¼Œå¯ä»¥å¼€å‘æ›´æ™ºèƒ½çš„å›¾åƒå¤„ç†ç®—æ³•ï¼Œæé«˜ç”¨æˆ·ä½“éªŒï¼Œå¹¶ä¸ºå†…å®¹åˆ›ä½œå’Œç¼–è¾‘æä¾›æ›´æœ‰æ•ˆçš„å·¥å…·ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æœ‰æœ›æ¨åŠ¨å¯è§£é‡Šå’Œäººç±»å¯¹é½çš„è´¨é‡è¯„ä¼°ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents a summary of the VQualA 2025 Challenge on Visual Quality Comparison for Large Multimodal Models (LMMs), hosted as part of the ICCV 2025 Workshop on Visual Quality Assessment. The challenge aims to evaluate and enhance the ability of state-of-the-art LMMs to perform open-ended and detailed reasoning about visual quality differences across multiple images. To this end, the competition introduces a novel benchmark comprising thousands of coarse-to-fine grained visual quality comparison tasks, spanning single images, pairs, and multi-image groups. Each task requires models to provide accurate quality judgments. The competition emphasizes holistic evaluation protocols, including 2AFC-based binary preference and multi-choice questions (MCQs). Around 100 participants submitted entries, with five models demonstrating the emerging capabilities of instruction-tuned LMMs on quality assessment. This challenge marks a significant step toward open-domain visual quality reasoning and comparison and serves as a catalyst for future research on interpretable and human-aligned quality evaluation systems.

