---
layout: default
title: SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models
---

# SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09090" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09090v1</a>
  <a href="https://arxiv.org/pdf/2509.09090.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09090v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09090v1', 'SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hengyu Fang, Yijiang Liu, Yuan Du, Li Du, Huanrui Yang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11

**å¤‡æ³¨**: 12 pages, 9 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSQAP-VLAæ¡†æ¶ï¼ŒååŒé‡åŒ–ä¸å‰ªæåŠ é€Ÿé«˜æ€§èƒ½è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹æ¨ç†ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹` `æ¨¡å‹å‹ç¼©` `é‡åŒ–` `å‰ªæ` `æ¨ç†åŠ é€Ÿ` `å…·èº«æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. VLAæ¨¡å‹è®¡ç®—å’Œå†…å­˜å¼€é”€å·¨å¤§ï¼Œé™åˆ¶äº†å…¶åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„éƒ¨ç½²ã€‚
2. SQAP-VLAé€šè¿‡ååŒè®¾è®¡é‡åŒ–å’Œtokenå‰ªææµç¨‹ï¼Œå…‹æœäº†äºŒè€…ä¸å…¼å®¹çš„é—®é¢˜ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSQAP-VLAåœ¨åŠ é€Ÿæ¨ç†çš„åŒæ—¶ï¼Œè¿˜èƒ½æå‡VLAæ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹åœ¨å…·èº«æ™ºèƒ½æ–¹é¢å±•ç°äº†å‰æ‰€æœªæœ‰çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬å·¨å¤§çš„è®¡ç®—å’Œå†…å­˜æˆæœ¬é˜»ç¢äº†å®ƒä»¬çš„å®é™…éƒ¨ç½²ã€‚ç°æœ‰çš„VLAå‹ç¼©å’ŒåŠ é€Ÿæ–¹æ³•é€šå¸¸ä»¥ä¸´æ—¶çš„æ–¹å¼è¿›è¡Œé‡åŒ–æˆ–tokenå‰ªæï¼Œä½†ç”±äºè§‚å¯Ÿåˆ°çš„ä¸å…¼å®¹æ€§ï¼Œæ— æ³•åŒæ—¶å®ç°ä¸¤è€…ä»¥å®ç°æ•´ä½“æ•ˆç‡çš„æå‡ã€‚æœ¬æ–‡ä»‹ç»äº†SQAP-VLAï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç»“æ„åŒ–çš„ã€å…è®­ç»ƒçš„VLAæ¨ç†åŠ é€Ÿæ¡†æ¶ï¼Œå®ƒåŒæ—¶å®ç°äº†æœ€å…ˆè¿›çš„é‡åŒ–å’Œtokenå‰ªæã€‚æˆ‘ä»¬é€šè¿‡å…±åŒè®¾è®¡é‡åŒ–å’Œtokenå‰ªææµç¨‹æ¥å…‹æœè¿™ç§ä¸å…¼å®¹æ€§ï¼Œå…¶ä¸­æˆ‘ä»¬æå‡ºäº†æ–°çš„é‡åŒ–æ„ŸçŸ¥tokenå‰ªææ ‡å‡†ï¼Œè¯¥æ ‡å‡†é€‚ç”¨äºæ¿€è¿›é‡åŒ–çš„æ¨¡å‹ï¼ŒåŒæ—¶æ”¹è¿›äº†é‡åŒ–å™¨çš„è®¾è®¡ä»¥æé«˜å‰ªææ•ˆæœã€‚å½“åº”ç”¨äºæ ‡å‡†VLAæ¨¡å‹æ—¶ï¼ŒSQAP-VLAåœ¨è®¡ç®—æ•ˆç‡å’Œæ¨ç†é€Ÿåº¦æ–¹é¢äº§ç”Ÿäº†æ˜¾è‘—çš„å¢ç›Šï¼ŒåŒæ—¶æˆåŠŸåœ°ä¿æŒäº†æ ¸å¿ƒæ¨¡å‹æ€§èƒ½ï¼Œä¸åŸå§‹æ¨¡å‹ç›¸æ¯”ï¼Œå®ç°äº†1.93å€çš„åŠ é€Ÿå’Œé«˜è¾¾4.5%çš„å¹³å‡æˆåŠŸç‡æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰VLAæ¨¡å‹è®¡ç®—é‡å’Œå†…å­˜å ç”¨è¿‡å¤§ï¼Œéš¾ä»¥éƒ¨ç½²ã€‚ç°æœ‰çš„é‡åŒ–å’Œtokenå‰ªææ–¹æ³•å•ç‹¬ä½¿ç”¨æ—¶æ•ˆæœæœ‰é™ï¼ŒåŒæ—¶ä½¿ç”¨æ—¶ä¼šäº§ç”Ÿä¸å…¼å®¹é—®é¢˜ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤ŸåŒæ—¶æœ‰æ•ˆåˆ©ç”¨é‡åŒ–å’Œå‰ªæçš„VLAæ¨¡å‹å‹ç¼©æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSQAP-VLAçš„æ ¸å¿ƒæ€è·¯æ˜¯ååŒè®¾è®¡é‡åŒ–å’Œtokenå‰ªææµç¨‹ï¼Œè§£å†³äºŒè€…ä¹‹é—´çš„ä¸å…¼å®¹æ€§ã€‚é€šè¿‡æå‡ºé‡åŒ–æ„ŸçŸ¥çš„tokenå‰ªææ ‡å‡†ï¼Œä½¿å¾—å‰ªæè¿‡ç¨‹èƒ½å¤Ÿé€‚åº”é‡åŒ–åçš„æ¨¡å‹ï¼ŒåŒæ—¶æ”¹è¿›é‡åŒ–å™¨çš„è®¾è®¡ï¼Œæå‡å‰ªæçš„æœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSQAP-VLAæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šé‡åŒ–é˜¶æ®µå’Œå‰ªæé˜¶æ®µã€‚åœ¨é‡åŒ–é˜¶æ®µï¼Œå¯¹æ¨¡å‹å‚æ•°è¿›è¡Œé‡åŒ–ï¼Œé™ä½æ¨¡å‹å¤§å°å’Œè®¡ç®—å¤æ‚åº¦ã€‚åœ¨å‰ªæé˜¶æ®µï¼Œæ ¹æ®é‡åŒ–æ„ŸçŸ¥çš„tokenå‰ªææ ‡å‡†ï¼Œç§»é™¤ä¸é‡è¦çš„tokenï¼Œè¿›ä¸€æ­¥é™ä½è®¡ç®—é‡ã€‚è¿™ä¸¤ä¸ªé˜¶æ®µååŒå·¥ä½œï¼Œå…±åŒæå‡æ¨¡å‹çš„æ•ˆç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šSQAP-VLAçš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†é‡åŒ–æ„ŸçŸ¥çš„tokenå‰ªææ ‡å‡†ã€‚è¯¥æ ‡å‡†è€ƒè™‘äº†é‡åŒ–å¯¹tokené‡è¦æ€§çš„å½±å“ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°tokençš„é‡è¦æ€§ï¼Œä»è€Œå®ç°æ›´æœ‰æ•ˆçš„å‰ªæã€‚æ­¤å¤–ï¼ŒSQAP-VLAè¿˜æ”¹è¿›äº†é‡åŒ–å™¨çš„è®¾è®¡ï¼Œä½¿å…¶æ›´é€‚åˆä¸å‰ªæç»“åˆä½¿ç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šé‡åŒ–æ„ŸçŸ¥tokenå‰ªææ ‡å‡†çš„è®¾è®¡æ˜¯å…³é”®ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ ‡å‡†å¯èƒ½ç»“åˆäº†é‡åŒ–åçš„å‚æ•°å€¼ã€tokençš„æ¿€æ´»å€¼ä»¥åŠå…¶ä»–ç›¸å…³ä¿¡æ¯ï¼Œä»¥è¯„ä¼°tokençš„é‡è¦æ€§ã€‚é‡åŒ–å™¨çš„è®¾è®¡å¯èƒ½é‡‡ç”¨äº†ç‰¹å®šçš„é‡åŒ–ç­–ç•¥ï¼Œä¾‹å¦‚è®­ç»ƒåé‡åŒ–æˆ–é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼Œä»¥æœ€å°åŒ–é‡åŒ–è¯¯å·®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SQAP-VLAåœ¨æ ‡å‡†VLAæ¨¡å‹ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŸå§‹æ¨¡å‹ç›¸æ¯”ï¼ŒSQAP-VLAå®ç°äº†1.93å€çš„æ¨ç†é€Ÿåº¦æå‡ï¼Œå¹¶ä¸”å¹³å‡æˆåŠŸç‡æå‡äº†é«˜è¾¾4.5%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒSQAP-VLAæ˜¯ä¸€ç§æœ‰æ•ˆçš„VLAæ¨¡å‹å‹ç¼©å’ŒåŠ é€Ÿæ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SQAP-VLAæ¡†æ¶å¯åº”ç”¨äºå„ç§éœ€è¦é«˜æ€§èƒ½å’Œä½åŠŸè€—çš„å…·èº«æ™ºèƒ½åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½å®¶å±…ã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚é€šè¿‡å‹ç¼©VLAæ¨¡å‹ï¼Œå¯ä»¥åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²å¤æ‚çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œä»»åŠ¡ï¼Œæé«˜ç³»ç»Ÿçš„å“åº”é€Ÿåº¦å’Œç”¨æˆ·ä½“éªŒã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæ¨åŠ¨å…·èº«æ™ºèƒ½æŠ€æœ¯åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models exhibit unprecedented capabilities for embodied intelligence. However, their extensive computational and memory costs hinder their practical deployment. Existing VLA compression and acceleration approaches conduct quantization or token pruning in an ad-hoc manner but fail to enable both for a holistic efficiency improvement due to an observed incompatibility. This work introduces SQAP-VLA, the first structured, training-free VLA inference acceleration framework that simultaneously enables state-of-the-art quantization and token pruning. We overcome the incompatibility by co-designing the quantization and token pruning pipeline, where we propose new quantization-aware token pruning criteria that work on an aggressively quantized model while improving the quantizer design to enhance pruning effectiveness. When applied to standard VLA models, SQAP-VLA yields significant gains in computational efficiency and inference speed while successfully preserving core model performance, achieving a $\times$1.93 speedup and up to a 4.5\% average success rate enhancement compared to the original model.

