---
layout: default
title: ALL-PET: A Low-resource and Low-shot PET Foundation Model in Projection Domain
---

# ALL-PET: A Low-resource and Low-shot PET Foundation Model in Projection Domain

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09130" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09130v2</a>
  <a href="https://arxiv.org/pdf/2509.09130.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09130v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09130v2', 'ALL-PET: A Low-resource and Low-shot PET Foundation Model in Projection Domain')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Bin Huang, Kang Chen, Bingxuan Li, Huafeng Liu, Qiegen Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11 (æ›´æ–°: 2025-09-16)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ALL-PETï¼šä¸€ç§ä½èµ„æºã€ä½æ ·æœ¬çš„æŠ•å½±åŸŸPETåŸºç¡€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `PETæˆåƒ` `åŸºç¡€æ¨¡å‹` `ä½èµ„æºå­¦ä¹ ` `æ½œåœ¨æ‰©æ•£æ¨¡å‹` `æ­£å¼¦å›¾` `æ•°æ®å¢å¼º` `åŒ»å­¦å½±åƒ` `å‡ ä½•çº¦æŸ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰PETæˆåƒåŸºç¡€æ¨¡å‹å—é™äºæ ‡æ³¨æ•°æ®ç¨€ç¼ºå’Œè®¡ç®—èµ„æºä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆæ„å»ºã€‚
2. ALL-PETé€šè¿‡åœ¨æŠ•å½±åŸŸåˆ©ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œç»“åˆRadonæ©ç å¢å¼ºç­‰ç­–ç•¥ï¼Œå®ç°ä½èµ„æºä¸‹çš„é«˜æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒALL-PETä»…éœ€å°‘é‡æ ·æœ¬å³å¯ç”Ÿæˆé«˜è´¨é‡æ­£å¼¦å›¾ï¼Œå¹¶åœ¨å¤šç§PETæˆåƒä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ„å»ºå¤§è§„æ¨¡PETæˆåƒåŸºç¡€æ¨¡å‹é¢ä¸´ç€æ ‡æ³¨æ•°æ®æœ‰é™å’Œè®¡ç®—èµ„æºä¸è¶³çš„æŒ‘æˆ˜ã€‚ä¸ºäº†å…‹æœæ•°æ®ç¨€ç¼ºå’Œæ•ˆç‡é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ALL-PETï¼Œä¸€ç§ç›´æ¥åœ¨æŠ•å½±åŸŸæ“ä½œçš„ä½èµ„æºã€ä½æ ·æœ¬PETåŸºç¡€æ¨¡å‹ã€‚ALL-PETåˆ©ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ï¼Œå¹¶å…·æœ‰ä¸‰ä¸ªå…³é”®åˆ›æ–°ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§Radonæ©ç å¢å¼ºç­–ç•¥ï¼ˆRMASï¼‰ï¼Œé€šè¿‡å°†éšæœºå›¾åƒåŸŸæ©ç æŠ•å½±åˆ°æ­£å¼¦å›¾ç©ºé—´ï¼Œç”Ÿæˆè¶…è¿‡20ä¸‡ä¸ªç»“æ„å¤šæ ·çš„è®­ç»ƒæ ·æœ¬ï¼Œä»è€Œä»¥æœ€å°‘çš„æ•°æ®æ˜¾è‘—æé«˜æ³›åŒ–èƒ½åŠ›ã€‚è¿™é€šè¿‡åŠ¨æ€å¤šæ©ç ï¼ˆDMMï¼‰æœºåˆ¶è¿›è¡Œæ‰©å±•ï¼Œè¯¥æœºåˆ¶æ”¹å˜æ©ç æ•°é‡å’Œåˆ†å¸ƒï¼Œåœ¨ä¸å¢åŠ æ¨¡å‹å¤æ‚æ€§çš„æƒ…å†µä¸‹å¢å¼ºæ•°æ®å¤šæ ·æ€§ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å®æ–½æ­£/è´Ÿæ©ç çº¦æŸä»¥åµŒå…¥ä¸¥æ ¼çš„å‡ ä½•ä¸€è‡´æ€§ï¼Œå‡å°‘å‚æ•°è´Ÿæ‹…ï¼ŒåŒæ—¶ä¿æŒç”Ÿæˆè´¨é‡ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬å¼•å…¥é€æ˜åŒ»å­¦æ³¨æ„åŠ›ï¼ˆTMAï¼‰ï¼Œä¸€ç§æ— å‚æ•°ã€å‡ ä½•é©±åŠ¨çš„æœºåˆ¶ï¼Œå¢å¼ºåŸå§‹æŠ•å½±æ•°æ®ä¸­ä¸ç—…ç¶ç›¸å…³çš„åŒºåŸŸã€‚ç—…ç¶èšç„¦çš„æ³¨æ„åŠ›å›¾ä»ç²—åˆ†å‰²ä¸­å¯¼å‡ºï¼Œè¦†ç›–é«˜ä»£è°¢å’Œä½ä»£è°¢åŒºåŸŸï¼Œå¹¶æŠ•å½±åˆ°æ­£å¼¦å›¾ç©ºé—´ä»¥å®ç°ç‰©ç†ä¸€è‡´çš„æŒ‡å¯¼ã€‚è¯¥ç³»ç»Ÿæ”¯æŒä¸´åºŠåŒ»ç”Ÿå®šä¹‰çš„ROIè°ƒæ•´ï¼Œç¡®ä¿ä¸PETé‡‡é›†ç‰©ç†å¯¹é½çš„çµæ´»ã€å¯è§£é‡Šå’Œä»»åŠ¡è‡ªé€‚åº”çš„å¼ºè°ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒALL-PETä»…ä½¿ç”¨500ä¸ªæ ·æœ¬å³å¯å®ç°é«˜è´¨é‡çš„æ­£å¼¦å›¾ç”Ÿæˆï¼Œå…¶æ€§èƒ½ä¸åœ¨æ›´å¤§çš„æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ç›¸å½“ã€‚ALL-PETå¯æ¨å¹¿åˆ°åŒ…æ‹¬ä½å‰‚é‡é‡å»ºã€è¡°å‡æ ¡æ­£ã€å»¶è¿Ÿå¸§é¢„æµ‹å’Œç¤ºè¸ªå‰‚åˆ†ç¦»ç­‰ä»»åŠ¡ï¼Œå¹¶åœ¨ä½äº24GBçš„å†…å­˜ä½¿ç”¨æƒ…å†µä¸‹é«˜æ•ˆè¿è¡Œã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šPETæˆåƒåŸºç¡€æ¨¡å‹çš„æ„å»ºé¢ä¸´æ•°æ®é‡ä¸è¶³å’Œè®¡ç®—èµ„æºæœ‰é™çš„åŒé‡æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä¸”è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…ä¸´åºŠåº”ç”¨ä¸­çš„æ¨å¹¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šALL-PETçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨æŠ•å½±åŸŸï¼ˆæ­£å¼¦å›¾ç©ºé—´ï¼‰ç›´æ¥è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œå¹¶åˆ©ç”¨æ•°æ®å¢å¼ºå’Œå‡ ä½•çº¦æŸæ¥å…‹æœæ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚é€šè¿‡åœ¨æ­£å¼¦å›¾ç©ºé—´è¿›è¡Œæ“ä½œï¼Œå¯ä»¥æ›´å¥½åœ°åˆ©ç”¨PETæˆåƒçš„ç‰©ç†ç‰¹æ€§ï¼Œå¹¶å‡å°‘å¯¹å¤§é‡å›¾åƒåŸŸæ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šALL-PETåŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) Radonæ©ç å¢å¼ºç­–ç•¥ï¼ˆRMASï¼‰å’ŒåŠ¨æ€å¤šæ©ç ï¼ˆDMMï¼‰ç”¨äºç”Ÿæˆå¤§é‡ç»“æ„å¤šæ ·çš„è®­ç»ƒæ ·æœ¬ï¼›2) æ­£/è´Ÿæ©ç çº¦æŸç”¨äºåµŒå…¥å‡ ä½•ä¸€è‡´æ€§ï¼›3) é€æ˜åŒ»å­¦æ³¨æ„åŠ›ï¼ˆTMAï¼‰æœºåˆ¶ç”¨äºå¢å¼ºç—…ç¶ç›¸å…³åŒºåŸŸçš„å…³æ³¨ã€‚æ•´ä½“æµç¨‹ä¸ºï¼šé¦–å…ˆåˆ©ç”¨RMASå’ŒDMMè¿›è¡Œæ•°æ®å¢å¼ºï¼Œç„¶åå°†å¢å¼ºåçš„æ•°æ®è¾“å…¥åˆ°LDMä¸­è¿›è¡Œè®­ç»ƒï¼ŒåŒæ—¶æ–½åŠ æ­£/è´Ÿæ©ç çº¦æŸï¼Œæœ€ååˆ©ç”¨TMAæœºåˆ¶å¼•å¯¼æ¨¡å‹å…³æ³¨ç—…ç¶åŒºåŸŸã€‚

**å…³é”®åˆ›æ–°**ï¼šALL-PETçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œå³Radonæ©ç å¢å¼ºç­–ç•¥ï¼ˆRMASï¼‰ï¼Œå¯ä»¥åœ¨æ•°æ®é‡æå°‘çš„æƒ…å†µä¸‹ç”Ÿæˆå¤§é‡ç»“æ„å¤šæ ·çš„è®­ç»ƒæ ·æœ¬ï¼›2) å¼•å…¥äº†é€æ˜åŒ»å­¦æ³¨æ„åŠ›ï¼ˆTMAï¼‰æœºåˆ¶ï¼Œå¯ä»¥åœ¨ä¸å¢åŠ æ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹ï¼Œå¼•å¯¼æ¨¡å‹å…³æ³¨ç—…ç¶åŒºåŸŸï¼Œæé«˜ç”Ÿæˆè´¨é‡ï¼›3) é€šè¿‡æ­£/è´Ÿæ©ç çº¦æŸï¼ŒåµŒå…¥äº†ä¸¥æ ¼çš„å‡ ä½•ä¸€è‡´æ€§ï¼Œå‡å°‘äº†å‚æ•°è´Ÿæ‹…ã€‚

**å…³é”®è®¾è®¡**ï¼šRMASé€šè¿‡å°†éšæœºå›¾åƒåŸŸæ©ç æŠ•å½±åˆ°æ­£å¼¦å›¾ç©ºé—´æ¥ç”Ÿæˆè®­ç»ƒæ ·æœ¬ã€‚DMMåŠ¨æ€è°ƒæ•´æ©ç çš„æ•°é‡å’Œåˆ†å¸ƒï¼Œä»¥å¢åŠ æ•°æ®å¤šæ ·æ€§ã€‚æ­£/è´Ÿæ©ç çº¦æŸé€šè¿‡é™åˆ¶ç”Ÿæˆç»“æœä¸­æ­£è´Ÿåƒç´ çš„åˆ†å¸ƒæ¥ä¿è¯å‡ ä½•ä¸€è‡´æ€§ã€‚TMAåˆ©ç”¨ç²—åˆ†å‰²ç»“æœç”Ÿæˆæ³¨æ„åŠ›å›¾ï¼Œå¹¶å°†å…¶æŠ•å½±åˆ°æ­£å¼¦å›¾ç©ºé—´ï¼Œä»¥å¼•å¯¼æ¨¡å‹å…³æ³¨ç—…ç¶åŒºåŸŸã€‚TMAæ˜¯æ— å‚æ•°çš„ï¼Œå¹¶ä¸”æ”¯æŒä¸´åºŠåŒ»ç”Ÿå®šä¹‰çš„ROIè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ALL-PETä»…ä½¿ç”¨500ä¸ªæ ·æœ¬å³å¯å®ç°é«˜è´¨é‡çš„æ­£å¼¦å›¾ç”Ÿæˆï¼Œå…¶æ€§èƒ½ä¸åœ¨æ›´å¤§çš„æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ç›¸å½“ã€‚è¯¥æ¨¡å‹åœ¨ä½å‰‚é‡é‡å»ºã€è¡°å‡æ ¡æ­£ã€å»¶è¿Ÿå¸§é¢„æµ‹å’Œç¤ºè¸ªå‰‚åˆ†ç¦»ç­‰ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸”å†…å­˜å ç”¨ä½äº24GBï¼Œå…·æœ‰å¾ˆé«˜çš„å®ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ALL-PETåœ¨PETæˆåƒé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬ä½å‰‚é‡PETé‡å»ºã€è¡°å‡æ ¡æ­£ã€åŠ¨æ€PETæˆåƒçš„å»¶è¿Ÿå¸§é¢„æµ‹ä»¥åŠPETç¤ºè¸ªå‰‚åˆ†ç¦»ç­‰ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿé™ä½å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œå‡å°‘è®¡ç®—èµ„æºéœ€æ±‚ï¼ŒåŠ é€ŸPETæˆåƒæŠ€æœ¯çš„ä¸´åºŠè½¬åŒ–ï¼Œå¹¶æœ‰æœ›æå‡ç–¾ç—…è¯Šæ–­çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Building large-scale foundation model for PET imaging is hindered by limited access to labeled data and insufficient computational resources. To overcome data scarcity and efficiency limitations, we propose ALL-PET, a low-resource, low-shot PET foundation model operating directly in projection domain. ALL-PET leverages a latent diffusion model (LDM) with three key innovations. First, we design a Radon mask augmentation strategy (RMAS) that generates over 200,000 structurally diverse training samples by projecting randomized image-domain masks into sinogram space, significantly improving generalization with minimal data. This is extended by a dynamic multi-mask (DMM) mechanism that varies mask quantity and distribution, enhancing data diversity without added model complexity. Second, we implement positive/negative mask constraints to embed strict geometric consistency, reducing parameter burden while preserving generation quality. Third, we introduce transparent medical attention (TMA), a parameter-free, geometry-driven mechanism that enhances lesion-related regions in raw projection data. Lesion-focused attention maps are derived from coarse segmentation, covering both hypermetabolic and hypometabolic areas, and projected into sinogram space for physically consistent guidance. The system supports clinician-defined ROI adjustments, ensuring flexible, interpretable, and task-adaptive emphasis aligned with PET acquisition physics. Experimental results show that ALL-PET achieves high-quality sinogram generation using only 500 samples, with performance comparable to models trained on larger datasets. ALL-PET generalizes across tasks including low-dose reconstruction, attenuation correction, delayed-frame prediction, and tracer separation, operating efficiently with memory use under 24GB.

