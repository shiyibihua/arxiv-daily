---
layout: default
title: DATE: Dynamic Absolute Time Enhancement for Long Video Understanding
---

# DATE: Dynamic Absolute Time Enhancement for Long Video Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09263" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09263v1</a>
  <a href="https://arxiv.org/pdf/2509.09263.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09263v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09263v1', 'DATE: Dynamic Absolute Time Enhancement for Long Video Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chao Yuan, Yang Yang, Yehui Yang, Zach Cheng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDATEæ¡†æ¶ï¼Œé€šè¿‡åŠ¨æ€ç»å¯¹æ—¶é—´å¢å¼ºæå‡MLLMåœ¨é•¿è§†é¢‘ç†è§£ä¸­çš„æ—¶åºæ¨ç†èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿è§†é¢‘ç†è§£` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `æ—¶é—´åºåˆ—å»ºæ¨¡` `è§†é¢‘å†…å®¹åˆ†æ` `äº‹ä»¶å®šä½` `æ—¶é—´æˆ³æ³¨å…¥` `è¯­ä¹‰å¼•å¯¼é‡‡æ ·`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰MLLMåœ¨é•¿è§†é¢‘ç†è§£ä¸­ï¼Œé‡‡ç”¨å‡åŒ€é‡‡æ ·å’Œéšå¼ä½ç½®ç¼–ç ï¼Œéš¾ä»¥æ•æ‰é•¿ç¨‹æ—¶åºä¾èµ–ï¼Œå¯¼è‡´ä¿¡æ¯æŸå¤±ã€‚
2. DATEæ¡†æ¶é€šè¿‡æ—¶é—´æˆ³æ³¨å…¥æœºåˆ¶å’Œè¯­ä¹‰å¼•å¯¼çš„æ—¶åºæ„ŸçŸ¥ç›¸ä¼¼æ€§é‡‡æ ·ï¼Œå¢å¼ºæ¨¡å‹å¯¹ç»å¯¹æ—¶é—´çš„ç†è§£ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDATEåœ¨å°æ—¶çº§è§†é¢‘åŸºå‡†æµ‹è¯•ä¸­ï¼Œæ˜¾è‘—æå‡äº†ç»å¯¹æ—¶é—´ç†è§£å’Œå…³é”®äº‹ä»¶å®šä½çš„æ€§èƒ½ï¼Œç”šè‡³è¶…è¶Šäº†æ›´å¤§çš„æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é•¿è§†é¢‘ç†è§£æ˜¯å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)é¢ä¸´çš„ä¸€é¡¹åŸºç¡€æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ç²¾ç¡®æ—¶åºæ¨ç†å’Œäº‹ä»¶å®šä½çš„ä»»åŠ¡ä¸­ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨å‡åŒ€å¸§é‡‡æ ·ï¼Œå¹¶ä¾èµ–éšå¼ä½ç½®ç¼–ç æ¥å»ºæ¨¡æ—¶é—´é¡ºåºï¼Œä½†è¿™äº›æ–¹æ³•éš¾ä»¥å¤„ç†é•¿ç¨‹ä¾èµ–ï¼Œå¯¼è‡´å…³é”®ä¿¡æ¯ä¸¢å¤±å’Œæ—¶åºç†è§£èƒ½åŠ›ä¸‹é™ã€‚æœ¬æ–‡æå‡ºäº†åŠ¨æ€ç»å¯¹æ—¶é—´å¢å¼º(DATE)æ¡†æ¶ï¼Œé€šè¿‡æ—¶é—´æˆ³æ³¨å…¥æœºåˆ¶(TIM)å’Œè¯­ä¹‰å¼•å¯¼çš„æ—¶åºæ„ŸçŸ¥ç›¸ä¼¼æ€§é‡‡æ ·(TASS)ç­–ç•¥æ¥å¢å¼ºMLLMçš„æ—¶åºæ„ŸçŸ¥èƒ½åŠ›ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å°†è§†é¢‘å¸§åµŒå…¥ä¸æ–‡æœ¬æ—¶é—´æˆ³tokenäº¤é”™ï¼Œæ„å»ºè¿ç»­çš„æ—¶é—´å‚è€ƒç³»ç»Ÿã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†è§†é¢‘é‡‡æ ·é—®é¢˜é‡æ–°å®šä¹‰ä¸ºè§†è§‰-è¯­è¨€æ£€ç´¢ä»»åŠ¡ï¼Œå¹¶å¼•å…¥ä¸¤é˜¶æ®µç®—æ³•ï¼Œç¡®ä¿è¯­ä¹‰ç›¸å…³æ€§å’Œæ—¶é—´è¦†ç›–ç‡ï¼šå°†æ¯ä¸ªæŸ¥è¯¢ä¸°å¯Œä¸ºæè¿°æ€§æ ‡é¢˜ï¼Œä»¥æ›´å¥½åœ°ä¸è§†è§‰ç‰¹å¾å¯¹é½ï¼Œå¹¶ä½¿ç”¨ç›¸ä¼¼æ€§é©±åŠ¨çš„æ—¶åºæ­£åˆ™åŒ–è´ªå©ªç­–ç•¥é‡‡æ ·å…³é”®äº‹ä»¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç»å¯¹æ—¶é—´ç†è§£å’Œå…³é”®äº‹ä»¶å®šä½æ–¹é¢å–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼Œåœ¨å°æ—¶çº§è§†é¢‘åŸºå‡†æµ‹è¯•ä¸­ï¼Œåœ¨7Bå’Œ72Bæ¨¡å‹ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬çš„7Bæ¨¡å‹åœ¨æŸäº›åŸºå‡†æµ‹è¯•ä¸­ç”šè‡³è¶…è¿‡äº†è®¸å¤š72Bæ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•åœ¨å¤„ç†é•¿è§†é¢‘æ—¶ï¼Œç”±äºå‡åŒ€é‡‡æ ·å’Œéšå¼ä½ç½®ç¼–ç çš„å±€é™æ€§ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰è§†é¢‘ä¸­çš„é•¿ç¨‹æ—¶åºä¾èµ–å…³ç³»ï¼Œå¯¼è‡´å…³é”®ä¿¡æ¯ä¸¢å¤±ï¼Œå½±å“æ¨¡å‹å¯¹è§†é¢‘å†…å®¹çš„æ—¶åºç†è§£å’Œäº‹ä»¶å®šä½èƒ½åŠ›ã€‚å°¤å…¶æ˜¯åœ¨éœ€è¦ç²¾ç¡®æ—¶é—´æ¨ç†çš„ä»»åŠ¡ä¸­ï¼Œè¿™ç§ç¼ºé™·æ›´ä¸ºæ˜æ˜¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDATEæ¡†æ¶çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ˜¾å¼åœ°æ³¨å…¥æ—¶é—´ä¿¡æ¯ï¼Œå¹¶ç»“åˆè¯­ä¹‰ä¿¡æ¯æŒ‡å¯¼é‡‡æ ·ï¼Œæ¥å¢å¼ºæ¨¡å‹å¯¹è§†é¢‘æ—¶åºçš„æ„ŸçŸ¥èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡æ—¶é—´æˆ³æ³¨å…¥æœºåˆ¶ï¼Œå°†æ—¶é—´ä¿¡æ¯ä¸è§†é¢‘å¸§åµŒå…¥äº¤é”™ï¼Œæ„å»ºè¿ç»­çš„æ—¶é—´å‚è€ƒç³»ï¼›åŒæ—¶ï¼Œåˆ©ç”¨è¯­ä¹‰ä¿¡æ¯æŒ‡å¯¼å…³é”®å¸§çš„é‡‡æ ·ï¼Œç¡®ä¿é‡‡æ ·çš„å¸§æ—¢å…·æœ‰è¯­ä¹‰ç›¸å…³æ€§ï¼Œåˆèƒ½è¦†ç›–è§†é¢‘çš„å…³é”®äº‹ä»¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDATEæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šæ—¶é—´æˆ³æ³¨å…¥æœºåˆ¶(TIM)å’Œè¯­ä¹‰å¼•å¯¼çš„æ—¶åºæ„ŸçŸ¥ç›¸ä¼¼æ€§é‡‡æ ·(TASS)ã€‚TIMè´Ÿè´£å°†æ—¶é—´æˆ³ä¿¡æ¯åµŒå…¥åˆ°è§†é¢‘å¸§åºåˆ—ä¸­ï¼Œå½¢æˆæ—¶é—´æ„ŸçŸ¥çš„è§†é¢‘è¡¨ç¤ºã€‚TASSåˆ™å°†è§†é¢‘é‡‡æ ·é—®é¢˜è½¬åŒ–ä¸ºè§†è§‰-è¯­è¨€æ£€ç´¢é—®é¢˜ï¼Œé€šè¿‡ä¸¤é˜¶æ®µç®—æ³•ï¼Œé¦–å…ˆåˆ©ç”¨è¯­ä¹‰ä¿¡æ¯ä¸°å¯ŒæŸ¥è¯¢ï¼Œç„¶åä½¿ç”¨ç›¸ä¼¼æ€§é©±åŠ¨çš„æ—¶åºæ­£åˆ™åŒ–è´ªå©ªç­–ç•¥é€‰æ‹©å…³é”®å¸§ã€‚æ•´ä¸ªæ¡†æ¶æ—¨åœ¨æå‡æ¨¡å‹å¯¹é•¿è§†é¢‘çš„æ—¶åºç†è§£èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šDATEæ¡†æ¶çš„å…³é”®åˆ›æ–°åœ¨äºæ˜¾å¼åœ°å°†æ—¶é—´ä¿¡æ¯æ³¨å…¥åˆ°è§†é¢‘è¡¨ç¤ºä¸­ï¼Œå¹¶ç»“åˆè¯­ä¹‰ä¿¡æ¯æŒ‡å¯¼é‡‡æ ·è¿‡ç¨‹ã€‚ä¸ä¼ ç»Ÿçš„éšå¼ä½ç½®ç¼–ç æ–¹æ³•ç›¸æ¯”ï¼ŒDATEèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•æ‰é•¿è§†é¢‘ä¸­çš„æ—¶åºä¾èµ–å…³ç³»ï¼Œæå‡æ¨¡å‹å¯¹ç»å¯¹æ—¶é—´çš„ç†è§£èƒ½åŠ›ã€‚åŒæ—¶ï¼Œå°†è§†é¢‘é‡‡æ ·é—®é¢˜è½¬åŒ–ä¸ºè§†è§‰-è¯­è¨€æ£€ç´¢é—®é¢˜ï¼Œä¸ºå…³é”®å¸§çš„é€‰æ‹©æä¾›äº†æ–°çš„æ€è·¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ—¶é—´æˆ³æ³¨å…¥æœºåˆ¶ä¸­ï¼Œæ—¶é—´æˆ³tokençš„é€‰æ‹©å’ŒåµŒå…¥æ–¹å¼æ˜¯å…³é”®ã€‚è®ºæ–‡ä¸­å…·ä½“çš„æ—¶é—´æˆ³tokenå½¢å¼å’ŒåµŒå…¥æ–¹å¼æœªçŸ¥ã€‚åœ¨TASSä¸­ï¼Œä¸¤é˜¶æ®µé‡‡æ ·ç®—æ³•çš„è®¾è®¡è‡³å…³é‡è¦ï¼Œç¬¬ä¸€é˜¶æ®µé€šè¿‡è¯­ä¹‰ä¿¡æ¯ä¸°å¯ŒæŸ¥è¯¢ï¼Œç¬¬äºŒé˜¶æ®µä½¿ç”¨ç›¸ä¼¼æ€§é©±åŠ¨çš„æ—¶åºæ­£åˆ™åŒ–è´ªå©ªç­–ç•¥é€‰æ‹©å…³é”®å¸§ï¼Œå…·ä½“çš„ç›¸ä¼¼æ€§åº¦é‡æ–¹å¼å’Œæ—¶åºæ­£åˆ™åŒ–ç­–ç•¥æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DATEæ¡†æ¶åœ¨å°æ—¶çº§è§†é¢‘åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œåœ¨ç»å¯¹æ—¶é—´ç†è§£å’Œå…³é”®äº‹ä»¶å®šä½æ–¹é¢å‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒDATEæ¡†æ¶çš„7Bæ¨¡å‹åœ¨æŸäº›åŸºå‡†æµ‹è¯•ä¸­ç”šè‡³è¶…è¶Šäº†è®¸å¤š72Bæ¨¡å‹ï¼Œè¡¨æ˜è¯¥æ–¹æ³•åœ¨æå‡æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œå…·æœ‰è‰¯å¥½çš„å‚æ•°æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DATEæ¡†æ¶åœ¨é•¿è§†é¢‘ç†è§£é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚è§†é¢‘å†…å®¹åˆ†æã€æ™ºèƒ½ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ã€åœ¨çº¿æ•™è‚²ç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹å¯¹è§†é¢‘æ—¶åºçš„ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥å®ç°æ›´ç²¾ç¡®çš„äº‹ä»¶æ£€æµ‹ã€è¡Œä¸ºè¯†åˆ«å’Œè§†é¢‘æ‘˜è¦ç”Ÿæˆï¼Œä»è€Œæé«˜ç›¸å…³åº”ç”¨çš„æ™ºèƒ½åŒ–æ°´å¹³å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åº”ç”¨äºæ›´å¤æ‚çš„è§†é¢‘åˆ†æä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Long video understanding remains a fundamental challenge for multimodal large language models (MLLMs), particularly in tasks requiring precise temporal reasoning and event localization. Existing approaches typically adopt uniform frame sampling and rely on implicit position encodings to model temporal order. However, these methods struggle with long-range dependencies, leading to critical information loss and degraded temporal comprehension. In this paper, we propose Dynamic Absolute Time Enhancement (DATE) that enhances temporal awareness in MLLMs through the Timestamp Injection Mechanism (TIM) and a semantically guided Temporal-Aware Similarity Sampling (TASS) strategy. Specifically, we interleave video frame embeddings with textual timestamp tokens to construct a continuous temporal reference system. We further reformulate the video sampling problem as a vision-language retrieval task and introduce a two-stage algorithm to ensure both semantic relevance and temporal coverage: enriching each query into a descriptive caption to better align with the vision feature, and sampling key event with a similarity-driven temporally regularized greedy strategy. Our method achieves remarkable improvements w.r.t. absolute time understanding and key event localization, resulting in state-of-the-art performance among 7B and 72B models on hour-long video benchmarks. Particularly, our 7B model even exceeds many 72B models on some benchmarks.

