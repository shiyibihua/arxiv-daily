---
layout: default
title: Locality-aware Concept Bottleneck Model
---

# Locality-aware Concept Bottleneck Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14562" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.14562v1</a>
  <a href="https://arxiv.org/pdf/2508.14562.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14562v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14562v1', 'Locality-aware Concept Bottleneck Model')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Sujin Jeon, Hyundo Lee, Eungseo Kim, Sanghack Lee, Byoung-Tak Zhang, Inwoo Hwang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-20

**Â§áÊ≥®**: 34 pages, 25 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Â±ÄÈÉ®ÊÑüÁü•Ê¶ÇÂøµÁì∂È¢àÊ®°Âûã‰ª•Ëß£ÂÜ≥Ê¶ÇÂøµÂÆö‰ΩçÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Ê¶ÇÂøµÁì∂È¢àÊ®°Âûã` `ÂéüÂûãÂ≠¶‰π†` `Á©∫Èó¥ÂÆö‰Ωç` `ËÆ°ÁÆóÊú∫ËßÜËßâ` `ÂõæÂÉèÂàÜÁ±ª` `ÁõÆÊ†áÊ£ÄÊµã` `ÂèØËß£ÈáäÊÄßAI`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÊó†Ê†áÁ≠æÊ¶ÇÂøµÁì∂È¢àÊ®°ÂûãÂú®Ê¶ÇÂøµÂÆö‰Ωç‰∏äÂ≠òÂú®‰∏çË∂≥ÔºåÂ∏∏Â∏∏ÂÖ≥Ê≥®‰∏éÊ¶ÇÂøµÊó†ÂÖ≥ÁöÑËßÜËßâÂå∫Âüü„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑÂ±ÄÈÉ®ÊÑüÁü•Ê¶ÇÂøµÁì∂È¢àÊ®°ÂûãÈÄöËøáÂéüÂûãÂ≠¶‰π†Á°Æ‰øùÊ¶ÇÂøµÁöÑÁ©∫Èó¥ÂÆö‰ΩçÂáÜÁ°ÆÊÄßÔºåÂà©Áî®Âü∫Á°ÄÊ®°ÂûãÁöÑ‰ø°ÊÅØ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåLCBMÂú®Ê¶ÇÂøµËØÜÂà´ÂíåÂÆö‰ΩçÊñπÈù¢Ë°®Áé∞‰ºòÂºÇÔºåÂàÜÁ±ªÊÄßËÉΩ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÂΩì„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ê¶ÇÂøµÁì∂È¢àÊ®°ÂûãÔºàCBMsÔºâÊòØ‰∏ÄÁßçÂü∫‰∫é‰∫∫Á±ªÂèØÁêÜËß£ËßÜËßâÁ∫øÁ¥¢ËøõË°åÈ¢ÑÊµãÁöÑÂèØËß£ÈáäÊ®°Âûã„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÊó†Ê†áÁ≠æCBMsÂú®Ê¶ÇÂøµÂÆö‰Ωç‰∏äÂ≠òÂú®‰∏çË∂≥ÔºåÂ∏∏Â∏∏ÂÖ≥Ê≥®‰∏éÊ¶ÇÂøµÊó†ÂÖ≥ÁöÑÂå∫Âüü„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜÂ±ÄÈÉ®ÊÑüÁü•Ê¶ÇÂøµÁì∂È¢àÊ®°ÂûãÔºàLCBMÔºâÔºåËØ•Ê®°ÂûãÂà©Áî®Âü∫Á°ÄÊ®°ÂûãÁöÑ‰∏∞ÂØå‰ø°ÊÅØÂπ∂ÈááÁî®ÂéüÂûãÂ≠¶‰π†Ôºå‰ª•Á°Æ‰øùÊ¶ÇÂøµÁöÑÂáÜÁ°ÆÁ©∫Èó¥ÂÆö‰Ωç„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÊàë‰ª¨‰∏∫ÊØè‰∏™Ê¶ÇÂøµÂàÜÈÖç‰∏Ä‰∏™ÂéüÂûãÔºå‰øÉËøõÂÖ∂‰ª£Ë°®ËØ•Ê¶ÇÂøµÁöÑÂÖ∏ÂûãÂõæÂÉèÁâπÂæÅ„ÄÇÈÄöËøáÈºìÂä±ÂéüÂûãÁºñÁ†ÅÁõ∏‰ººÁöÑÂ±ÄÈÉ®Âå∫ÂüüÔºåÂà©Áî®Âü∫Á°ÄÊ®°ÂûãÁ°Æ‰øùÊØè‰∏™ÂéüÂûã‰∏éÂÖ∂Áõ∏ÂÖ≥Ê¶ÇÂøµÁöÑÁõ∏ÂÖ≥ÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåLCBMÊúâÊïàËØÜÂà´ÂõæÂÉè‰∏≠ÁöÑÊ¶ÇÂøµÔºåÂπ∂Âú®‰øùÊåÅÂàÜÁ±ªÊÄßËÉΩÁöÑÂêåÊó∂ÊîπÂñÑ‰∫ÜÂÆö‰ΩçÊïàÊûú„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÊó†Ê†áÁ≠æÊ¶ÇÂøµÁì∂È¢àÊ®°ÂûãÂú®ÂõæÂÉè‰∏≠Ê¶ÇÂøµÂÆö‰Ωç‰∏çÂáÜÁ°ÆÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂ∏∏Â∏∏Êó†Ê≥ïÊúâÊïàÂÖ≥Ê≥®‰∏éÊ¶ÇÂøµÁõ∏ÂÖ≥ÁöÑÂå∫ÂüüÔºåÂØºËá¥È¢ÑÊµãÁªìÊûú‰∏çÁêÜÊÉ≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫Â±ÄÈÉ®ÊÑüÁü•Ê¶ÇÂøµÁì∂È¢àÊ®°ÂûãÔºàLCBMÔºâÔºåÈÄöËøá‰∏∫ÊØè‰∏™Ê¶ÇÂøµÂàÜÈÖç‰∏Ä‰∏™ÂéüÂûãÔºåÁ°Æ‰øùÂéüÂûãËÉΩÂ§üÂáÜÁ°Æ‰ª£Ë°®ËØ•Ê¶ÇÂøµÁöÑÁâπÂæÅÔºå‰ªéËÄåÊîπÂñÑÊ¶ÇÂøµÁöÑÁ©∫Èó¥ÂÆö‰Ωç„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöLCBMÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨ÂéüÂûãÂ≠¶‰π†Ê®°ÂùóÂíåÊ¶ÇÂøµËØÜÂà´Ê®°Âùó„ÄÇÂéüÂûãÂ≠¶‰π†Ê®°ÂùóË¥üË¥£Â≠¶‰π†ÊØè‰∏™Ê¶ÇÂøµÁöÑÂéüÂûãÔºåÊ¶ÇÂøµËØÜÂà´Ê®°ÂùóÂàôÂà©Áî®Ëøô‰∫õÂéüÂûãÊù•Á°ÆÂÆöÂõæÂÉè‰∏≠Ê¶ÇÂøµÁöÑÂ≠òÂú®ÂèäÂÖ∂‰ΩçÁΩÆ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÈÄöËøáÂéüÂûãÂ≠¶‰π†Á°Æ‰øùÊ¶ÇÂøµÁöÑÁ©∫Èó¥ÂÆö‰ΩçÂáÜÁ°ÆÊÄßÔºå‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåLCBMËÉΩÂ§üÊõ¥Â•ΩÂú∞ÂÖ≥Ê≥®‰∏éÊ¶ÇÂøµÁõ∏ÂÖ≥ÁöÑÂ±ÄÈÉ®Âå∫Âüü„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÂéüÂûãÁöÑÂ≠¶‰π†ÈÄöËøáÈºìÂä±ÂÖ∂ÁºñÁ†ÅÁõ∏‰ººÁöÑÂ±ÄÈÉ®Âå∫ÂüüÊù•ÂÆûÁé∞ÔºåÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°‰∏äËÄÉËôë‰∫ÜÂéüÂûã‰∏éÊ¶ÇÂøµÁöÑÁõ∏ÂÖ≥ÊÄßÔºåÁ°Æ‰øùÊØè‰∏™ÂéüÂûãËÉΩÂ§üÊúâÊïà‰ª£Ë°®ÂÖ∂ÂØπÂ∫îÁöÑÊ¶ÇÂøµ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåLCBMÂú®Ê¶ÇÂøµËØÜÂà´ÂíåÂÆö‰ΩçÊñπÈù¢Ë°®Áé∞‰ºòÂºÇÔºåÁõ∏ËæÉ‰∫éÂü∫Á∫øÊ®°ÂûãÔºåÂÆö‰ΩçÁ≤æÂ∫¶ÊèêÂçáÊòæËëóÔºåÂêåÊó∂‰øùÊåÅ‰∫Ü‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÂΩìÁöÑÂàÜÁ±ªÊÄßËÉΩ„ÄÇËøô‰∏ÄÊàêÊûúÂ±ïÁ§∫‰∫ÜÊ®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊΩúÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ËÆ°ÁÆóÊú∫ËßÜËßâ‰∏≠ÁöÑÂõæÂÉèÂàÜÁ±ª„ÄÅÁõÆÊ†áÊ£ÄÊµãÂíåÂú∫ÊôØÁêÜËß£Á≠â‰ªªÂä°„ÄÇÈÄöËøáÊèêÈ´òÊ¶ÇÂøµÁöÑÁ©∫Èó¥ÂÆö‰ΩçËÉΩÂäõÔºåLCBMÂèØ‰ª•Âú®Ëá™Âä®È©æÈ©∂„ÄÅÂåªÁñóÂΩ±ÂÉèÂàÜÊûêÁ≠âÈ¢ÜÂüüÊèê‰æõÊõ¥‰∏∫ÂáÜÁ°ÆÁöÑÂÜ≥Á≠ñÊîØÊåÅÔºåÊú™Êù•ÂèØËÉΩÂØπÊô∫ËÉΩÁ≥ªÁªüÁöÑÂèØËß£ÈáäÊÄßÂíåÂèØÈù†ÊÄß‰∫ßÁîüÁßØÊûÅÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Concept bottleneck models (CBMs) are inherently interpretable models that make predictions based on human-understandable visual cues, referred to as concepts. As obtaining dense concept annotations with human labeling is demanding and costly, recent approaches utilize foundation models to determine the concepts existing in the images. However, such label-free CBMs often fail to localize concepts in relevant regions, attending to visually unrelated regions when predicting concept presence. To this end, we propose a framework, coined Locality-aware Concept Bottleneck Model (LCBM), which utilizes rich information from foundation models and adopts prototype learning to ensure accurate spatial localization of the concepts. Specifically, we assign one prototype to each concept, promoted to represent a prototypical image feature of that concept. These prototypes are learned by encouraging them to encode similar local regions, leveraging foundation models to assure the relevance of each prototype to its associated concept. Then we use the prototypes to facilitate the learning process of identifying the proper local region from which each concept should be predicted. Experimental results demonstrate that LCBM effectively identifies present concepts in the images and exhibits improved localization while maintaining comparable classification performance.

