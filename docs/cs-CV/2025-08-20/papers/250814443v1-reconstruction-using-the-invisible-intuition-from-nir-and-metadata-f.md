---
layout: default
title: Reconstruction Using the Invisible: Intuition from NIR and Metadata for Enhanced 3D Gaussian Splatting
---

# Reconstruction Using the Invisible: Intuition from NIR and Metadata for Enhanced 3D Gaussian Splatting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14443" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14443v1</a>
  <a href="https://arxiv.org/pdf/2508.14443.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14443v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14443v1', 'Reconstruction Using the Invisible: Intuition from NIR and Metadata for Enhanced 3D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Gyusam Chang, Tuan-Anh Vu, Vivek Alumootil, Harris Song, Deanna Pham, Sangpil Kim, M. Khalid Jawed

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/StructuresComp/3D-Reconstruction-NIR)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNIRSplatä»¥è§£å†³å†œä¸šåœºæ™¯ä¸‹3Dé‡å»ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dé‡å»º` `è¿‘çº¢å¤–å›¾åƒ` `å¤šæ¨¡æ€æ•°æ®` `å†œä¸šåº”ç”¨` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„3Dé‡å»ºæ–¹æ³•åœ¨å†œä¸šåœºæ™¯ä¸­é¢ä¸´ä¸å‡åŒ€ç…§æ˜å’Œé®æŒ¡ç­‰æŒ‘æˆ˜ï¼Œå¯¼è‡´é‡å»ºæ•ˆæœä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºNIRSplatï¼Œé€šè¿‡ç»“åˆè¿‘çº¢å¤–æ•°æ®å’Œæ–‡æœ¬å…ƒæ•°æ®ï¼Œå¢å¼ºäº†3Dé‡å»ºçš„é²æ£’æ€§å’Œæ¤ç‰©å­¦ç†è§£ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒNIRSplatåœ¨å¤æ‚å†œä¸šç¯å¢ƒä¸­æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæå‡äº†é‡å»ºç²¾åº¦å’Œæ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡3Dé«˜æ–¯ç‚¹äº‘æŠ€æœ¯ï¼ˆ3DGSï¼‰è¿…é€Ÿå‘å±•ï¼Œä½†å…¶åœ¨å†œä¸šä¸­çš„åº”ç”¨ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚å†œä¸šåœºæ™¯é¢ä¸´ç€ä¸å‡åŒ€ç…§æ˜ã€é®æŒ¡å’Œæœ‰é™è§†é‡ç­‰ç‹¬ç‰¹æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†NIRPlantï¼Œä¸€ä¸ªåŒ…å«è¿‘çº¢å¤–ï¼ˆNIRï¼‰å›¾åƒã€RGBå›¾åƒã€æ–‡æœ¬å…ƒæ•°æ®ã€æ·±åº¦å’ŒLiDARæ•°æ®çš„å¤šæ¨¡æ€æ•°æ®é›†ï¼Œæ—¨åœ¨å¢å¼º3Dé‡å»ºçš„é²æ£’æ€§ã€‚é€šè¿‡æ•´åˆNIRæ•°æ®ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æä¾›äº†è¶…è¶Šå¯è§å…‰è°±çš„æ¤ç‰©å­¦æ´å¯Ÿã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ©ç”¨åŸºäºæ¤è¢«æŒ‡æ•°ï¼ˆå¦‚NDVIã€NDWIå’Œå¶ç»¿ç´ æŒ‡æ•°ï¼‰æå–çš„æ–‡æœ¬å…ƒæ•°æ®ï¼Œæ˜¾è‘—ä¸°å¯Œäº†å¯¹å¤æ‚å†œä¸šç¯å¢ƒçš„ç†è§£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNIRSplatåœ¨æŒ‘æˆ˜æ€§å†œä¸šåœºæ™¯ä¸­ä¼˜äºç°æœ‰çš„æ ‡å¿—æ€§æ–¹æ³•ï¼Œå¦‚3DGSã€CoR-GSå’ŒInstantSplatã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å†œä¸šåœºæ™¯ä¸‹3Dé‡å»ºçš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ä¸å‡åŒ€ç…§æ˜å’Œé®æŒ¡æƒ…å†µä¸‹è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´é‡å»ºæ•ˆæœä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºNIRSplatï¼Œé€šè¿‡æ•´åˆè¿‘çº¢å¤–ï¼ˆNIRï¼‰å›¾åƒå’Œæ–‡æœ¬å…ƒæ•°æ®ï¼Œå¢å¼ºäº†é‡å»ºçš„é²æ£’æ€§ï¼Œå¹¶æä¾›äº†è¶…è¶Šå¯è§å…‰è°±çš„æ¤ç‰©å­¦æ´å¯Ÿã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šNIRSplatçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ç‰¹å¾æå–å’Œé‡å»ºæ¨¡å—ã€‚æ•°æ®é¢„å¤„ç†é˜¶æ®µæ•´åˆNIRå’ŒRGBå›¾åƒï¼Œç‰¹å¾æå–é˜¶æ®µä½¿ç”¨è·¨æ³¨æ„åŠ›æœºåˆ¶ï¼Œé‡å»ºæ¨¡å—åˆ™åŸºäº3Dç‚¹çš„ä½ç½®ä¿¡æ¯è¿›è¡Œé«˜æ•ˆé‡å»ºã€‚

**å…³é”®åˆ›æ–°**ï¼šNIRSplatçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†è·¨æ³¨æ„åŠ›æœºåˆ¶ä¸3Dç‚¹ä½ç½®ç¼–ç çš„ç»“åˆï¼Œæä¾›äº†å¼ºå¤§çš„å‡ ä½•å…ˆéªŒï¼Œæ˜¾è‘—æå‡äº†é‡å»ºç²¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å¤šæ¨¡æ€èåˆç­–ç•¥ï¼Œåˆ©ç”¨æ¤è¢«æŒ‡æ•°ç”Ÿæˆçš„æ–‡æœ¬å…ƒæ•°æ®æ¥ä¸°å¯Œä¸Šä¸‹æ–‡ç†è§£ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸­ä¼˜åŒ–äº†æŸå¤±å‡½æ•°ä»¥é€‚åº”å†œä¸šåœºæ™¯çš„ç‰¹æ®Šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒNIRSplatåœ¨å¤æ‚å†œä¸šåœºæ™¯ä¸­çš„é‡å»ºç²¾åº¦æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå°¤å…¶åœ¨å¤„ç†é®æŒ¡å’Œä¸å‡åŒ€ç…§æ˜æ—¶ï¼Œé‡å»ºæ•ˆæœæå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç²¾å‡†å†œä¸šã€æ¤ç‰©ç›‘æµ‹å’Œç¯å¢ƒç›‘æµ‹ç­‰ã€‚é€šè¿‡æé«˜3Dé‡å»ºçš„å‡†ç¡®æ€§ï¼ŒNIRSplatèƒ½å¤Ÿä¸ºå†œä¸šç”Ÿäº§æä¾›æ›´ä¸ºç²¾å‡†çš„æ•°æ®æ”¯æŒï¼Œä¿ƒè¿›æ™ºèƒ½å†œä¸šçš„å‘å±•ï¼Œæœªæ¥å¯èƒ½å¯¹å†œä¸šç®¡ç†å’Œå†³ç­–äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While 3D Gaussian Splatting (3DGS) has rapidly advanced, its application in agriculture remains underexplored. Agricultural scenes present unique challenges for 3D reconstruction methods, particularly due to uneven illumination, occlusions, and a limited field of view. To address these limitations, we introduce \textbf{NIRPlant}, a novel multimodal dataset encompassing Near-Infrared (NIR) imagery, RGB imagery, textual metadata, Depth, and LiDAR data collected under varied indoor and outdoor lighting conditions. By integrating NIR data, our approach enhances robustness and provides crucial botanical insights that extend beyond the visible spectrum. Additionally, we leverage text-based metadata derived from vegetation indices, such as NDVI, NDWI, and the chlorophyll index, which significantly enriches the contextual understanding of complex agricultural environments. To fully exploit these modalities, we propose \textbf{NIRSplat}, an effective multimodal Gaussian splatting architecture employing a cross-attention mechanism combined with 3D point-based positional encoding, providing robust geometric priors. Comprehensive experiments demonstrate that \textbf{NIRSplat} outperforms existing landmark methods, including 3DGS, CoR-GS, and InstantSplat, highlighting its effectiveness in challenging agricultural scenarios. The code and dataset are publicly available at: https://github.com/StructuresComp/3D-Reconstruction-NIR

