---
layout: default
title: Seeing Further on the Shoulders of Giants: Knowledge Inheritance for Vision Foundation Models
---

# Seeing Further on the Shoulders of Giants: Knowledge Inheritance for Vision Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14707" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14707v2</a>
  <a href="https://arxiv.org/pdf/2508.14707.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14707v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14707v2', 'Seeing Further on the Shoulders of Giants: Knowledge Inheritance for Vision Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiabo Huang, Chen Chen, Lingjuan Lyu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20 (æ›´æ–°: 2025-09-15)

**å¤‡æ³¨**: Technical report

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºçŸ¥è¯†ç»§æ‰¿æ–¹æ³•ä»¥æå‡è§†è§‰åŸºç¡€æ¨¡å‹çš„æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰åŸºç¡€æ¨¡å‹` `çŸ¥è¯†ç»§æ‰¿` `æ¨¡å‹é©±åŠ¨æ–¹æ³•` `çŸ¥è¯†è½¬ç§»` `é€‚é…æ¨¡å—` `è®¡ç®—æœºè§†è§‰` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰åŸºç¡€æ¨¡å‹ä¸»è¦ä¾èµ–å¤§é‡é«˜è´¨é‡æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¯¼è‡´è®¸å¤šæœºæ„é¢ä¸´æ•°æ®å’Œè®¡ç®—èµ„æºçš„ç“¶é¢ˆã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¨¡å‹é©±åŠ¨æ–¹æ³•ï¼Œé€šè¿‡è”åˆçŸ¥è¯†è½¬ç§»å’Œä¿ç•™ï¼Œè§£å†³äº†ä¸åŒé¢„è®­ç»ƒæ¨¡å‹ä¹‹é—´çš„çŸ¥è¯†è½¬ç§»ä¸å¹³è¡¡é—®é¢˜ã€‚
3. å¤§é‡å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„VFMåœ¨å¤šä¸ªè§†è§‰ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„æ•°æ®é©±åŠ¨æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMï¼‰ä¸»è¦ä¾èµ–æ•°æ®é©±åŠ¨çš„æ–¹æ³•è¿›è¡Œå¼€å‘ï¼Œè¿™äº›æ–¹æ³•éœ€è¦å¤§é‡é«˜è´¨é‡æ ‡æ³¨æ•°æ®ï¼Œç»™ç¼ºä¹å¤§è§„æ¨¡æ•°æ®å’Œé«˜ç«¯GPUçš„æœºæ„å¸¦æ¥äº†ç“¶é¢ˆã€‚å°½ç®¡è®¸å¤šå¼€æºè§†è§‰æ¨¡å‹å·²åœ¨ç‰¹å®šé¢†åŸŸæ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œèƒ½å¤Ÿæç‚¼å’Œè¡¨ç¤ºå¯è½¬ç§»çš„æ ¸å¿ƒçŸ¥è¯†ï¼Œä½†åœ¨æ¨åŠ¨é€šç”¨VFMçš„å‘å±•æ–¹é¢ä»æœªå¾—åˆ°å……åˆ†åˆ©ç”¨ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡è”åˆçŸ¥è¯†è½¬ç§»å’Œä¿ç•™çš„æ¨¡å‹é©±åŠ¨æ–¹æ³•ï¼Œç»Ÿä¸€å¤šä¸ªé¢„è®­ç»ƒæ•™å¸ˆæ¨¡å‹äºå…±äº«æ½œåœ¨ç©ºé—´ï¼Œä»¥ç¼“è§£å› åˆ†å¸ƒå·®å¼‚å¯¼è‡´çš„â€œå¤±è¡¡è½¬ç§»â€é—®é¢˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§çŸ¥è¯†ä¿ç•™ç­–ç•¥ï¼Œä»¥é€šç”¨æ•™å¸ˆä½œä¸ºçŸ¥è¯†åº“ï¼Œé€šè¿‡é€‚é…æ¨¡å—æ•´åˆå…¶ä»–ç‰¹å®šä»»åŠ¡æ•™å¸ˆçš„çŸ¥è¯†ã€‚é€šè¿‡ç»Ÿä¸€å’Œèšåˆç°æœ‰æ¨¡å‹ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¼ºå¤§çš„VFMï¼Œèƒ½å¤Ÿåœ¨æ— éœ€å¤§é‡æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ç»§æ‰¿æ•™å¸ˆçš„ä¸“ä¸šçŸ¥è¯†ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„VFMåœ¨å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰å’Œå®ä¾‹åˆ†å‰²ç­‰å››ä¸ªåŸºç¡€è§†è§‰ä»»åŠ¡ä¸Šè¶…è¶Šäº†ç°æœ‰çš„æ•°æ®é©±åŠ¨æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰åŸºç¡€æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹å¤§é‡é«˜è´¨é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œç°æœ‰æ–¹æ³•åœ¨çŸ¥è¯†è½¬ç§»æ—¶å­˜åœ¨åˆ†å¸ƒå·®å¼‚å¯¼è‡´çš„å¤±è¡¡è½¬ç§»é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å°†å¤šä¸ªé¢„è®­ç»ƒæ•™å¸ˆæ¨¡å‹ç»Ÿä¸€åˆ°ä¸€ä¸ªå…±äº«æ½œåœ¨ç©ºé—´ä¸­ï¼Œç»“åˆçŸ¥è¯†ä¿ç•™ç­–ç•¥ï¼Œåˆ©ç”¨é€šç”¨æ•™å¸ˆä½œä¸ºçŸ¥è¯†åº“ï¼Œæ•´åˆç‰¹å®šä»»åŠ¡æ•™å¸ˆçš„çŸ¥è¯†ï¼Œä»è€Œæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªé¢„è®­ç»ƒæ•™å¸ˆæ¨¡å‹çš„èšåˆã€å…±äº«æ½œåœ¨ç©ºé—´çš„æ„å»ºä»¥åŠé€‚é…æ¨¡å—çš„è®¾è®¡ã€‚é¦–å…ˆï¼Œåˆ©ç”¨å…±äº«æ½œåœ¨ç©ºé—´å¯¹æ•™å¸ˆæ¨¡å‹è¿›è¡Œç»Ÿä¸€ï¼Œç„¶åé€šè¿‡é€‚é…æ¨¡å—å°†ç‰¹å®šä»»åŠ¡çŸ¥è¯†æ•´åˆåˆ°é€šç”¨æ¨¡å‹ä¸­ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†çŸ¥è¯†è½¬ç§»ä¸ä¿ç•™çš„è”åˆæ–¹æ³•ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•ä¸­ç”±äºæ¨¡å‹åˆ†å¸ƒå·®å¼‚å¯¼è‡´çš„çŸ¥è¯†è½¬ç§»ä¸å¹³è¡¡é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†é€‚é…æ¨¡å—æ¥å®ç°çŸ¥è¯†çš„æ•´åˆï¼Œè®¾ç½®äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡ä¸åŒæ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†è´¡çŒ®ï¼ŒåŒæ—¶ä¼˜åŒ–äº†ç½‘ç»œç»“æ„ä»¥æé«˜æ¨¡å‹çš„å­¦ä¹ æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„VFMåœ¨å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²å’Œå®ä¾‹åˆ†å‰²ç­‰å››ä¸ªåŸºç¡€è§†è§‰ä»»åŠ¡ä¸Šå‡è¶…è¶Šäº†ç°æœ‰çš„æ•°æ®é©±åŠ¨æ¨¡å‹ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ä¸­çš„å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²ç­‰ä»»åŠ¡ï¼Œèƒ½å¤Ÿä¸ºèµ„æºæœ‰é™çš„æœºæ„æä¾›ä¸€ç§é«˜æ•ˆçš„æ¨¡å‹è®­ç»ƒæ–¹æ¡ˆã€‚é€šè¿‡çŸ¥è¯†ç»§æ‰¿ï¼Œç ”ç©¶æˆæœæœ‰æœ›åœ¨å¤šä¸ªè§†è§‰åº”ç”¨ä¸­å®ç°æ›´å¥½çš„æ€§èƒ½ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision foundation models (VFMs) are predominantly developed using data-centric methods. These methods require training on vast amounts of data usually with high-quality labels, which poses a bottleneck for most institutions that lack both large-scale data and high-end GPUs. On the other hand, many open-source vision models have been pretrained on domain-specific data, enabling them to distill and represent core knowledge in a form that is transferable across diverse applications. Even though these models are highly valuable assets, they remain largely under-explored in empowering the development of a general-purpose VFM. In this paper, we present a new model-driven approach for training VFMs through joint knowledge transfer and preservation. Our method unifies multiple pre-trained teacher models in a shared latent space to mitigate the ``imbalanced transfer'' issue caused by their distributional gaps. Besides, we introduce a knowledge preservation strategy to take a general-purpose teacher as a knowledge base for integrating knowledge from the remaining purpose-specific teachers using an adapter module. By unifying and aggregating existing models, we build a powerful VFM to inherit teachers' expertise without needing to train on a large amount of labeled data. Our model not only provides generalizable visual features, but also inherently supports multiple downstream tasks. Extensive experiments demonstrate that our VFM outperforms existing data-centric models across four fundamental vision tasks, including image classification, object detection, semantic and instance segmentation.

