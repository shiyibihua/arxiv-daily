---
layout: default
title: Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels
---

# Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17437" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.17437v2</a>
  <a href="https://arxiv.org/pdf/2508.17437.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17437v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17437v2', 'Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Long Le, Ryan Lucas, Chen Wang, Chuhao Chen, Dinesh Jayaraman, Eric Eaton, Lingjie Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20 (æ›´æ–°: 2025-08-26)

**å¤‡æ³¨**: Website: https://pixie-3d.github.io/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPIXIEä»¥è§£å†³3Dåœºæ™¯ç‰©ç†å±æ€§æ¨æ–­é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `3Dç‰©ç†æ¨æ–­` `ç¥ç»ç½‘ç»œ` `ç›‘ç£å­¦ä¹ ` `è™šæ‹Ÿç°å®` `æ•°æ®é›†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¾èµ–é€åœºæ™¯ä¼˜åŒ–ï¼Œå¯¼è‡´æ¨æ–­é€Ÿåº¦æ…¢ä¸”ç¼ºä¹é€šç”¨æ€§ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚
2. PIXIEé€šè¿‡è®­ç»ƒä¸€ä¸ªå¯æ³›åŒ–çš„ç¥ç»ç½‘ç»œï¼Œåˆ©ç”¨ç›‘ç£å­¦ä¹ ä»å¤šä¸ªåœºæ™¯ä¸­æå–3Dè§†è§‰ç‰¹å¾ï¼Œå¿«é€Ÿæ¨æ–­ç‰©ç†å±æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPIXIEåœ¨æ€§èƒ½ä¸Šæ¯”ä¼ ç»Ÿæ–¹æ³•æå‡äº†1.46-4.39å€ï¼Œå¹¶ä¸”æ¨æ–­é€Ÿåº¦æ˜¾è‘—åŠ å¿«ï¼Œå…·å¤‡è‰¯å¥½çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»è§†è§‰ä¿¡æ¯æ¨æ–­3Dåœºæ™¯çš„ç‰©ç†å±æ€§æ˜¯åˆ›å»ºäº¤äº’å¼å’ŒçœŸå®è™šæ‹Ÿä¸–ç•Œçš„å…³é”®ä»»åŠ¡ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºç¼“æ…¢çš„é€åœºæ™¯ä¼˜åŒ–ï¼Œé™åˆ¶äº†å…¶é€šç”¨æ€§å’Œåº”ç”¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†PIXIEï¼Œä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œé€šè¿‡ç›‘ç£æŸå¤±è®­ç»ƒä¸€ä¸ªå¯æ³›åŒ–çš„ç¥ç»ç½‘ç»œï¼Œä»å¤šä¸ªåœºæ™¯ä¸­é¢„æµ‹ç‰©ç†å±æ€§ã€‚è®­ç»ƒå®Œæˆåï¼Œè¯¥å‰é¦ˆç½‘ç»œèƒ½å¤Ÿå¿«é€Ÿæ¨æ–­åˆç†çš„ææ–™åœºï¼Œå¹¶ç»“åˆå­¦ä¹ åˆ°çš„é™æ€åœºæ™¯è¡¨ç¤ºï¼ˆå¦‚é«˜æ–¯æ•£ç‚¹ï¼‰ï¼Œå®ç°å¤–åŠ›ä¸‹çš„çœŸå®ç‰©ç†æ¨¡æ‹Ÿã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æ”¶é›†äº†PIXIEVERSEï¼Œè¿™æ˜¯å·²çŸ¥æœ€å¤§çš„é…å¯¹3Dèµ„äº§å’Œç‰©ç†ææ–™æ³¨é‡Šæ•°æ®é›†ä¹‹ä¸€ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒPIXIEåœ¨æ€§èƒ½ä¸Šæ¯”æµ‹è¯•æ—¶ä¼˜åŒ–æ–¹æ³•æé«˜äº†1.46-4.39å€ï¼Œå¹¶ä¸”é€Ÿåº¦æå‡äº†å‡ ä¸ªæ•°é‡çº§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»è§†è§‰ä¿¡æ¯æ¨æ–­3Dåœºæ™¯ç‰©ç†å±æ€§çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•å› ä¾èµ–é€åœºæ™¯ä¼˜åŒ–è€Œå¯¼è‡´é€Ÿåº¦æ…¢ã€é€šç”¨æ€§å·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPIXIEçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç›‘ç£å­¦ä¹ è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œä½¿å…¶èƒ½å¤Ÿä»å¤šä¸ªåœºæ™¯ä¸­æå–3Dè§†è§‰ç‰¹å¾å¹¶é¢„æµ‹ç‰©ç†å±æ€§ï¼Œä»è€Œå®ç°å¿«é€Ÿæ¨æ–­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPIXIEçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€ç¥ç»ç½‘ç»œè®­ç»ƒå’Œæ¨æ–­ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ”¶é›†åŒ…å«3Dèµ„äº§å’Œç‰©ç†å±æ€§çš„é…å¯¹æ•°æ®é›†ï¼›ç„¶åï¼Œä½¿ç”¨è¿™äº›æ•°æ®è®­ç»ƒç¥ç»ç½‘ç»œï¼›æœ€åï¼Œåˆ©ç”¨è®­ç»ƒå¥½çš„ç½‘ç»œè¿›è¡Œå¿«é€Ÿæ¨æ–­ã€‚

**å…³é”®åˆ›æ–°**ï¼šPIXIEçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è®­ç»ƒçš„ç¥ç»ç½‘ç»œèƒ½å¤Ÿåœ¨æœªè§è¿‡çš„çœŸå®åœºæ™¯ä¸­è¿›è¡Œé›¶æ ·æœ¬æ³›åŒ–ï¼Œå°½ç®¡ä»…åœ¨åˆæˆæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¿™ä¸€ç‰¹æ€§æ˜¾è‘—æå‡äº†æ¨¡å‹çš„é€‚ç”¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒPIXIEä½¿ç”¨äº†é¢„è®­ç»ƒçš„è§†è§‰ç‰¹å¾ï¼ˆå¦‚CLIPï¼‰ï¼Œå¹¶ç»“åˆäº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨æ¨æ–­æ—¶çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPIXIEåœ¨æ€§èƒ½ä¸Šæ¯”ä¼ ç»Ÿçš„æµ‹è¯•æ—¶ä¼˜åŒ–æ–¹æ³•æé«˜äº†1.46-4.39å€ï¼Œä¸”æ¨æ–­é€Ÿåº¦æ˜¾è‘—åŠ å¿«ï¼Œè¾¾åˆ°æ•°ä¸ªæ•°é‡çº§çš„æå‡ã€‚è¿™ä¸€æˆæœå±•ç¤ºäº†PIXIEåœ¨å¤„ç†å¤æ‚3Dåœºæ™¯ç‰©ç†å±æ€§æ¨æ–­ä»»åŠ¡ä¸­çš„å“è¶Šèƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘å’Œæœºå™¨äººæ§åˆ¶ç­‰ã€‚é€šè¿‡å¿«é€Ÿå‡†ç¡®åœ°æ¨æ–­ç‰©ç†å±æ€§ï¼ŒPIXIEå¯ä»¥å¸®åŠ©å¼€å‘è€…åˆ›å»ºæ›´ä¸ºçœŸå®çš„è™šæ‹Ÿç¯å¢ƒï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•çš„é€šç”¨æ€§ä½¿å…¶åœ¨å¤šç§åœºæ™¯ä¸‹å‡å…·å¤‡åº”ç”¨ä»·å€¼ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Inferring the physical properties of 3D scenes from visual information is a critical yet challenging task for creating interactive and realistic virtual worlds. While humans intuitively grasp material characteristics such as elasticity or stiffness, existing methods often rely on slow, per-scene optimization, limiting their generalizability and application. To address this problem, we introduce PIXIE, a novel method that trains a generalizable neural network to predict physical properties across multiple scenes from 3D visual features purely using supervised losses. Once trained, our feed-forward network can perform fast inference of plausible material fields, which coupled with a learned static scene representation like Gaussian Splatting enables realistic physics simulation under external forces. To facilitate this research, we also collected PIXIEVERSE, one of the largest known datasets of paired 3D assets and physic material annotations. Extensive evaluations demonstrate that PIXIE is about 1.46-4.39x better and orders of magnitude faster than test-time optimization methods. By leveraging pretrained visual features like CLIP, our method can also zero-shot generalize to real-world scenes despite only ever been trained on synthetic data. https://pixie-3d.github.io/

