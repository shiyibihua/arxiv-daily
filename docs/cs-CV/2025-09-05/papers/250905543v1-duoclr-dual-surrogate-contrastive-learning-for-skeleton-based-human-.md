---
layout: default
title: DuoCLR: Dual-Surrogate Contrastive Learning for Skeleton-based Human Action Segmentation
---

# DuoCLR: Dual-Surrogate Contrastive Learning for Skeleton-based Human Action Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05543" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05543v1</a>
  <a href="https://arxiv.org/pdf/2509.05543.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05543v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05543v1', 'DuoCLR: Dual-Surrogate Contrastive Learning for Skeleton-based Human Action Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haitao Tian, Pierre Payeur

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

**å¤‡æ³¨**: ICCV 2025 accepted paper

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DuoCLRï¼šé€šè¿‡åŒä»£ç†å¯¹æ¯”å­¦ä¹ å¢å¼ºéª¨éª¼åŠ¨ä½œåˆ†å‰²**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `éª¨éª¼åŠ¨ä½œåˆ†å‰²` `å¯¹æ¯”å­¦ä¹ ` `è¡¨ç¤ºå­¦ä¹ ` `æ•°æ®å¢å¼º` `å¤šå°ºåº¦ç‰¹å¾` `äººä½“è¡Œä¸ºåˆ†æ` `æ—¶ç©ºå›¾å·ç§¯ç½‘ç»œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŠ¨ä½œè¯†åˆ«æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨å¤šå°ºåº¦ä¿¡æ¯å’Œè·¨åºåˆ—å˜åŒ–ï¼Œé™åˆ¶äº†åŠ¨ä½œåˆ†å‰²çš„æ€§èƒ½ã€‚
2. æå‡ºDuoCLRæ¡†æ¶ï¼Œé€šè¿‡Shuffle and Warpæ•°æ®å¢å¼ºç­–ç•¥å’ŒåŒä»£ç†å¯¹æ¯”å­¦ä¹ ï¼Œå­¦ä¹ æ›´é²æ£’çš„å¤šå°ºåº¦ç‰¹å¾è¡¨ç¤ºã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDuoCLRåœ¨å¤šç±»å’Œå¤šæ ‡ç­¾åŠ¨ä½œåˆ†å‰²ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§å¯¹æ¯”è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ä½¿ç”¨è£å‰ªè¿‡çš„ï¼ˆå•åŠ¨ä½œï¼‰éª¨éª¼åºåˆ—è¿›è¡Œé¢„è®­ç»ƒï¼Œæ¥å¢å¼ºäººä½“åŠ¨ä½œåˆ†å‰²ã€‚ä¸ä¹‹å‰é’ˆå¯¹åŠ¨ä½œè¯†åˆ«ä¸”åŸºäºå­¤ç«‹åºåˆ—è¡¨ç¤ºçš„è¡¨ç¤ºå­¦ä¹ å·¥ä½œä¸åŒï¼Œè¯¥æ¡†æ¶ä¾§é‡äºåˆ©ç”¨å¤šå°ºåº¦è¡¨ç¤ºä»¥åŠè·¨åºåˆ—å˜åŒ–ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œå®ƒæå‡ºäº†ä¸€ç§æ–°é¢–çš„æ•°æ®å¢å¼ºç­–ç•¥â€œShuffle and Warpâ€ï¼Œè¯¥ç­–ç•¥åˆ©ç”¨äº†å„ç§å¤šåŠ¨ä½œæ’åˆ—ã€‚åè€…æœ‰æ•ˆåœ°è¾…åŠ©äº†å¯¹æ¯”å­¦ä¹ ä¸­å¼•å…¥çš„ä¸¤ä¸ªä»£ç†ä»»åŠ¡ï¼šè·¨æ’åˆ—å¯¹æ¯”(CPC)å’Œç›¸å¯¹é¡ºåºæ¨ç†(ROR)ã€‚åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼ŒCPCé€šè¿‡å¯¹æ¯”ä¸åŒæ’åˆ—ä¸­ç›¸åŒåŠ¨ä½œç±»åˆ«çš„è¡¨ç¤ºæ¥å­¦ä¹ ç±»å†…ç›¸ä¼¼æ€§ï¼Œè€ŒRORé€šè¿‡é¢„æµ‹ä¸¤ä¸ªæ’åˆ—ä¹‹é—´çš„ç›¸å¯¹æ˜ å°„æ¥æ¨ç†ç±»é—´ä¸Šä¸‹æ–‡ã€‚è¿™äº›ä»»åŠ¡å…±åŒä½¿åŒä»£ç†å¯¹æ¯”å­¦ä¹ (DuoCLR)ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ é’ˆå¯¹åŠ¨ä½œåˆ†å‰²ä¼˜åŒ–çš„å¤šå°ºåº¦ç‰¹å¾è¡¨ç¤ºã€‚åœ¨å®éªŒä¸­ï¼ŒDuoCLRåœ¨è£å‰ªåçš„éª¨éª¼æ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶åœ¨æœªè£å‰ªçš„æ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œåœ¨å¤šç±»å’Œå¤šæ ‡ç­¾åŠ¨ä½œåˆ†å‰²ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºä¼˜äºæœ€å…ˆè¿›æ°´å¹³çš„æ˜¾è‘—æå‡ã€‚æœ€åï¼Œè¿›è¡Œäº†æ¶ˆèç ”ç©¶ï¼Œä»¥è¯„ä¼°æ‰€æå‡ºæ–¹æ³•çš„æ¯ä¸ªç»„æˆéƒ¨åˆ†çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºéª¨éª¼çš„åŠ¨ä½œåˆ†å‰²æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ä¾èµ–äºè¡¨ç¤ºå­¦ä¹ çš„æ–¹æ³•ï¼Œé€šå¸¸é’ˆå¯¹åŠ¨ä½œè¯†åˆ«ä»»åŠ¡è®¾è®¡ï¼Œå¿½ç•¥äº†åŠ¨ä½œåˆ†å‰²å¯¹å¤šå°ºåº¦ä¿¡æ¯å’Œè·¨åºåˆ—ä¸Šä¸‹æ–‡çš„ç‰¹æ®Šéœ€æ±‚ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨ä¸åŒåŠ¨ä½œæ’åˆ—ä¸­çš„ä¿¡æ¯ï¼Œå¯¼è‡´åˆ†å‰²æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¯¹æ¯”å­¦ä¹ ï¼Œé€šè¿‡è®¾è®¡ä¸¤ä¸ªä»£ç†ä»»åŠ¡ï¼ˆè·¨æ’åˆ—å¯¹æ¯”CPCå’Œç›¸å¯¹é¡ºåºæ¨ç†RORï¼‰æ¥å­¦ä¹ å¯¹åŠ¨ä½œåˆ†å‰²æ›´æœ‰ç”¨çš„ç‰¹å¾è¡¨ç¤ºã€‚é€šè¿‡Shuffle and Warpæ•°æ®å¢å¼ºç­–ç•¥ï¼Œç”Ÿæˆä¸åŒçš„åŠ¨ä½œæ’åˆ—ï¼Œå¹¶åˆ©ç”¨è¿™äº›æ’åˆ—æ¥è®­ç»ƒç½‘ç»œåŒºåˆ†ç›¸åŒåŠ¨ä½œçš„ä¸åŒæ’åˆ—å’Œä¸åŒåŠ¨ä½œä¹‹é—´çš„ç›¸å¯¹é¡ºåºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDuoCLRæ¡†æ¶åŒ…å«æ•°æ®å¢å¼ºæ¨¡å—ã€ç‰¹å¾æå–æ¨¡å—å’Œå¯¹æ¯”å­¦ä¹ æ¨¡å—ã€‚é¦–å…ˆï¼Œä½¿ç”¨Shuffle and Warpç­–ç•¥å¯¹è¾“å…¥éª¨éª¼åºåˆ—è¿›è¡Œæ•°æ®å¢å¼ºï¼Œç”Ÿæˆä¸åŒçš„åŠ¨ä½œæ’åˆ—ã€‚ç„¶åï¼Œä½¿ç”¨ç‰¹å¾æå–æ¨¡å—ï¼ˆä¾‹å¦‚ï¼Œæ—¶ç©ºå›¾å·ç§¯ç½‘ç»œï¼‰æå–å¤šå°ºåº¦ç‰¹å¾è¡¨ç¤ºã€‚æœ€åï¼Œé€šè¿‡CPCå’ŒRORä¸¤ä¸ªä»£ç†ä»»åŠ¡è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºã€‚CPCä»»åŠ¡æ—¨åœ¨æ‹‰è¿‘ç›¸åŒåŠ¨ä½œç±»åˆ«çš„ä¸åŒæ’åˆ—çš„è¡¨ç¤ºï¼ŒRORä»»åŠ¡æ—¨åœ¨é¢„æµ‹ä¸åŒåŠ¨ä½œæ’åˆ—ä¹‹é—´çš„ç›¸å¯¹é¡ºåºã€‚

**å…³é”®åˆ›æ–°**ï¼šDuoCLRçš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†åŒä»£ç†å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŒæ—¶åˆ©ç”¨è·¨æ’åˆ—å¯¹æ¯”å’Œç›¸å¯¹é¡ºåºæ¨ç†æ¥å­¦ä¹ ç‰¹å¾è¡¨ç¤ºã€‚Shuffle and Warpæ•°æ®å¢å¼ºç­–ç•¥èƒ½å¤Ÿç”Ÿæˆå¤šæ ·åŒ–çš„åŠ¨ä½œæ’åˆ—ï¼Œä¸ºå¯¹æ¯”å­¦ä¹ æä¾›äº†ä¸°å¯Œçš„è®­ç»ƒæ ·æœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šShuffle and Warpæ•°æ®å¢å¼ºç­–ç•¥é€šè¿‡éšæœºæ‰“ä¹±å’Œæ—¶é—´æ‰­æ›²æ“ä½œç”Ÿæˆä¸åŒçš„åŠ¨ä½œæ’åˆ—ã€‚CPCä»»åŠ¡ä½¿ç”¨InfoNCEæŸå¤±å‡½æ•°ï¼Œé¼“åŠ±ç›¸åŒåŠ¨ä½œç±»åˆ«çš„ä¸åŒæ’åˆ—çš„è¡¨ç¤ºå°½å¯èƒ½æ¥è¿‘ã€‚RORä»»åŠ¡é€šè¿‡é¢„æµ‹ä¸¤ä¸ªæ’åˆ—ä¹‹é—´çš„ç›¸å¯¹æ˜ å°„å…³ç³»æ¥å­¦ä¹ ç±»é—´ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚å…·ä½“å®ç°ç»†èŠ‚åŒ…æ‹¬æŸå¤±å‡½æ•°çš„æƒé‡ã€ç½‘ç»œç»“æ„çš„å‚æ•°é€‰æ‹©ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DuoCLRåœ¨æœªè£å‰ªçš„éª¨éª¼åŠ¨ä½œåˆ†å‰²æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨å¤šç±»åŠ¨ä½œåˆ†å‰²ä»»åŠ¡ä¸­ï¼ŒDuoCLRçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæå‡å¹…åº¦è¾¾åˆ°æ˜¾è‘—æ°´å¹³ã€‚åœ¨å¤šæ ‡ç­¾åŠ¨ä½œåˆ†å‰²ä»»åŠ¡ä¸­ï¼ŒDuoCLRåŒæ ·å–å¾—äº†ä¼˜å¼‚çš„æˆç»©ï¼Œè¯æ˜äº†å…¶åœ¨å¤æ‚åœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ã€‚æ¶ˆèå®éªŒéªŒè¯äº†Shuffle and Warpæ•°æ®å¢å¼ºç­–ç•¥ä»¥åŠCPCå’ŒRORä¸¤ä¸ªä»£ç†ä»»åŠ¡çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DuoCLRæ¡†æ¶åœ¨äººä½“åŠ¨ä½œåˆ†å‰²é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚è§†é¢‘ç›‘æ§ã€äººæœºäº¤äº’ã€åº·å¤è®­ç»ƒç­‰ã€‚é€šè¿‡å‡†ç¡®åˆ†å‰²äººä½“åŠ¨ä½œï¼Œå¯ä»¥å®ç°å¼‚å¸¸è¡Œä¸ºæ£€æµ‹ã€æ‰‹åŠ¿è¯†åˆ«ã€è¿åŠ¨è¯„ä¼°ç­‰åŠŸèƒ½ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œæ½œåœ¨çš„ç¤¾ä¼šå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this paper, a contrastive representation learning framework is proposed to enhance human action segmentation via pre-training using trimmed (single action) skeleton sequences. Unlike previous representation learning works that are tailored for action recognition and that build upon isolated sequence-wise representations, the proposed framework focuses on exploiting multi-scale representations in conjunction with cross-sequence variations. More specifically, it proposes a novel data augmentation strategy, 'Shuffle and Warp', which exploits diverse multi-action permutations. The latter effectively assists two surrogate tasks that are introduced in contrastive learning: Cross Permutation Contrasting (CPC) and Relative Order Reasoning (ROR). In optimization, CPC learns intra-class similarities by contrasting representations of the same action class across different permutations, while ROR reasons about inter-class contexts by predicting relative mapping between two permutations. Together, these tasks enable a Dual-Surrogate Contrastive Learning (DuoCLR) network to learn multi-scale feature representations optimized for action segmentation. In experiments, DuoCLR is pre-trained on a trimmed skeleton dataset and evaluated on an untrimmed dataset where it demonstrates a significant boost over state-the-art comparatives in both multi-class and multi-label action segmentation tasks. Lastly, ablation studies are conducted to evaluate the effectiveness of each component of the proposed approach.

