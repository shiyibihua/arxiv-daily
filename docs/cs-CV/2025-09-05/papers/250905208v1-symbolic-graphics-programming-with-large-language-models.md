---
layout: default
title: Symbolic Graphics Programming with Large Language Models
---

# Symbolic Graphics Programming with Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05208" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05208v1</a>
  <a href="https://arxiv.org/pdf/2509.05208.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05208v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05208v1', 'Symbolic Graphics Programming with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yamei Chen, Haoquan Zhang, Yangyi Huang, Zeju Qiu, Kaipeng Zhang, Yandong Wen, Weiyang Liu

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

**å¤‡æ³¨**: Technical report (32 pages, 12 figures, project page: https://spherelab.ai/SGP-Gen/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¡†æ¶ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆç²¾ç¡®å¯æ§SVGå›¾åƒçš„èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¬¦å·å›¾å½¢ç¼–ç¨‹` `å¤§è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `SVGç”Ÿæˆ` `è·¨æ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨ç¨‹åºåˆæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ç”Ÿæˆå¯æ¸²æŸ“ä¸ºç²¾ç¡®è§†è§‰å†…å®¹çš„ç¬¦å·å›¾å½¢ç¨‹åºï¼ˆSGPï¼‰æ–¹é¢çš„èƒ½åŠ›ä»æœ‰å¾…æ¢ç´¢ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œå¯éªŒè¯å¥–åŠ±çš„æ–¹æ³•ï¼Œåˆ©ç”¨æ ¼å¼æœ‰æ•ˆæ€§é—¨å’Œè·¨æ¨¡æ€å¥–åŠ±æ¥æå‡LLMç”ŸæˆSGPçš„èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åº”ç”¨äºQwen-2.5-7Båï¼Œæ˜¾è‘—æé«˜äº†SVGç”Ÿæˆè´¨é‡å’Œè¯­ä¹‰ï¼Œè¾¾åˆ°äº†ä¸å‰æ²¿ç³»ç»Ÿç›¸å½“çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†ç¬¦å·å›¾å½¢ç¼–ç¨‹ï¼Œæ—¨åœ¨ä»è‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆå¯æ¸²æŸ“ä¸ºç²¾ç¡®è§†è§‰å†…å®¹çš„ç¬¦å·å›¾å½¢ç¨‹åºï¼ˆSGPï¼‰ã€‚è¯¥ä»»åŠ¡é€šè¿‡æç¤ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆç”±SGPæ¸²æŸ“çš„å›¾åƒï¼Œä»è€Œè€ƒå¯ŸLLMå¯¹è§†è§‰ä¸–ç•Œçš„ç†è§£ã€‚æœ¬æ–‡ä¸“æ³¨äºå¯ç¼©æ”¾çŸ¢é‡å›¾å½¢ï¼ˆSVGï¼‰ã€‚é¦–å…ˆï¼Œè¯„ä¼°äº†LLMç”ŸæˆSGPçš„èƒ½åŠ›ï¼Œä¸ºæ­¤å¼•å…¥äº†SGP-GenBenchï¼Œä¸€ä¸ªæ¶µç›–å¯¹è±¡ä¿çœŸåº¦ã€åœºæ™¯ä¿çœŸåº¦å’Œç»„åˆæ€§ï¼ˆå±æ€§ç»‘å®šã€ç©ºé—´å…³ç³»ã€æ•°å€¼èƒ½åŠ›ï¼‰çš„ç»¼åˆåŸºå‡†ã€‚å®éªŒè¡¨æ˜ï¼Œå‰æ²¿ä¸“æœ‰æ¨¡å‹æ˜¾è‘—ä¼˜äºå¼€æºæ¨¡å‹ï¼Œä¸”æ€§èƒ½ä¸é€šç”¨ç¼–ç èƒ½åŠ›å¯†åˆ‡ç›¸å…³ã€‚é’ˆå¯¹è¿™ä¸€å·®è·ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œå¯éªŒè¯å¥–åŠ±çš„æ–¹æ³•ï¼Œå…¶ä¸­æ ¼å¼æœ‰æ•ˆæ€§é—¨ç¡®ä¿SVGå¯æ¸²æŸ“ï¼Œè·¨æ¨¡æ€å¥–åŠ±é€šè¿‡å¼ºå¤§çš„è§†è§‰ç¼–ç å™¨ï¼ˆä¾‹å¦‚ï¼ŒSigLIPç”¨äºæ–‡æœ¬-å›¾åƒï¼ŒDINOç”¨äºå›¾åƒ-å›¾åƒï¼‰å¯¹é½æ–‡æœ¬å’Œæ¸²æŸ“å›¾åƒã€‚åº”ç”¨äºQwen-2.5-7Båï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†SVGç”Ÿæˆè´¨é‡å’Œè¯­ä¹‰ï¼Œè¾¾åˆ°äº†ä¸å‰æ²¿ç³»ç»Ÿç›¸å½“çš„æ€§èƒ½ã€‚è¿›ä¸€æ­¥åˆ†æäº†è®­ç»ƒåŠ¨æ€ï¼Œè¡¨æ˜RLè¯±å¯¼äº†ï¼ˆiï¼‰å°†å¯¹è±¡æ›´ç²¾ç»†åœ°åˆ†è§£ä¸ºå¯æ§çš„åŸºå…ƒï¼Œä»¥åŠï¼ˆiiï¼‰æ”¹å–„åœºæ™¯è¿è´¯æ€§çš„ä¸Šä¸‹æ–‡ç»†èŠ‚ã€‚ç»“æœè¡¨æ˜ï¼Œç¬¦å·å›¾å½¢ç¼–ç¨‹ä¸ºè·¨æ¨¡æ€åŸºç¡€æä¾›äº†ç²¾ç¡®ä¸”å¯è§£é‡Šçš„è§†è§’ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç”Ÿæˆç¬¦å·å›¾å½¢ç¨‹åºï¼ˆSGPï¼‰æ–¹é¢çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯ç”Ÿæˆå¯æ¸²æŸ“ä¸ºç²¾ç¡®è§†è§‰å†…å®¹çš„SVGå›¾åƒã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥ä¿è¯ç”ŸæˆSVGçš„è´¨é‡å’Œè¯­ä¹‰å‡†ç¡®æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹è±¡ä¿çœŸåº¦ã€åœºæ™¯ä¿çœŸåº¦å’Œç»„åˆæ€§æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¥è®­ç»ƒLLMï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆæ›´å‡†ç¡®ã€æ›´ç¬¦åˆè¯­ä¹‰çš„SVGä»£ç ã€‚é€šè¿‡å¼•å…¥å¯éªŒè¯å¥–åŠ±æœºåˆ¶ï¼Œç¡®ä¿ç”Ÿæˆçš„SVGæ ¼å¼æœ‰æ•ˆä¸”å†…å®¹ä¸ç»™å®šçš„æ–‡æœ¬æè¿°ä¸€è‡´ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨å¼¥åˆLLMçš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ä¸è§†è§‰å†…å®¹ç”Ÿæˆä¹‹é—´çš„å·®è·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) LLMï¼ˆä¾‹å¦‚Qwen-2.5-7Bï¼‰ä½œä¸ºSVGä»£ç ç”Ÿæˆå™¨ï¼›2) æ ¼å¼æœ‰æ•ˆæ€§é—¨ï¼Œç”¨äºéªŒè¯ç”Ÿæˆçš„SVGä»£ç æ˜¯å¦å¯æ¸²æŸ“ï¼›3) è·¨æ¨¡æ€å¥–åŠ±æ¨¡å—ï¼Œåˆ©ç”¨è§†è§‰ç¼–ç å™¨ï¼ˆSigLIPå’ŒDINOï¼‰è®¡ç®—æ–‡æœ¬æè¿°ä¸æ¸²æŸ“å›¾åƒä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œä½œä¸ºRLçš„å¥–åŠ±ä¿¡å·ï¼›4) å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå…·ä½“ç®—æ³•æœªçŸ¥ï¼‰ï¼Œç”¨äºä¼˜åŒ–LLMçš„ç”Ÿæˆç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ç›¸ç»“åˆï¼Œç”¨äºè®­ç»ƒLLMç”ŸæˆSVGä»£ç ã€‚è¿™ç§æ–¹æ³•ä¸ä»…ä¿è¯äº†ç”ŸæˆSVGçš„æ ¼å¼æœ‰æ•ˆæ€§ï¼Œè¿˜é€šè¿‡è·¨æ¨¡æ€å¥–åŠ±ç¡®ä¿äº†ç”Ÿæˆå†…å®¹ä¸æ–‡æœ¬æè¿°çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚ä¸ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼ŒRLèƒ½å¤Ÿæ›´å¥½åœ°æ¢ç´¢SVGä»£ç çš„ç”Ÿæˆç©ºé—´ï¼Œä»è€Œç”Ÿæˆæ›´å¤æ‚ã€æ›´å‡†ç¡®çš„å›¾åƒã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨SigLIPä½œä¸ºæ–‡æœ¬-å›¾åƒç¼–ç å™¨ï¼Œç”¨äºè®¡ç®—æ–‡æœ¬æè¿°ä¸æ¸²æŸ“å›¾åƒä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼›2) ä½¿ç”¨DINOä½œä¸ºå›¾åƒ-å›¾åƒç¼–ç å™¨ï¼Œç”¨äºè¯„ä¼°ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œä¸€è‡´æ€§ï¼›3) è®¾è®¡åˆé€‚çš„å¥–åŠ±å‡½æ•°ï¼Œå¹³è¡¡æ ¼å¼æœ‰æ•ˆæ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§ï¼›4) å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„å…·ä½“é€‰æ‹©å’Œå‚æ•°è°ƒæ•´ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå°†è¯¥æ–¹æ³•åº”ç”¨äºQwen-2.5-7Båï¼ŒSVGç”Ÿæˆè´¨é‡å’Œè¯­ä¹‰æ˜¾è‘—æé«˜ï¼Œè¾¾åˆ°äº†ä¸å‰æ²¿ä¸“æœ‰æ¨¡å‹ç›¸å½“çš„æ€§èƒ½æ°´å¹³ã€‚é€šè¿‡åˆ†æè®­ç»ƒåŠ¨æ€ï¼Œå‘ç°å¼ºåŒ–å­¦ä¹ èƒ½å¤Ÿä¿ƒä½¿LLMå°†å¯¹è±¡åˆ†è§£ä¸ºæ›´ç²¾ç»†çš„å¯æ§åŸºå…ƒï¼Œå¹¶ç”Ÿæˆæ”¹å–„åœºæ™¯è¿è´¯æ€§çš„ä¸Šä¸‹æ–‡ç»†èŠ‚ã€‚å…·ä½“æ€§èƒ½æå‡æ•°æ®æœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå›¾åƒç”Ÿæˆã€è®¡ç®—æœºè¾…åŠ©è®¾è®¡ã€è§†è§‰å†…å®¹åˆ›ä½œç­‰é¢†åŸŸã€‚é€šè¿‡è‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆé«˜è´¨é‡çš„çŸ¢é‡å›¾å½¢ï¼Œå¯ä»¥é™ä½è®¾è®¡é—¨æ§›ï¼Œæé«˜åˆ›ä½œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºè‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰é¢†åŸŸï¼Œå®ç°æ›´æ™ºèƒ½ã€æ›´ä¾¿æ·çš„è§†è§‰å†…å®¹äº¤äº’ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) excel at program synthesis, yet their ability to produce symbolic graphics programs (SGPs) that render into precise visual content remains underexplored. We study symbolic graphics programming, where the goal is to generate an SGP from a natural-language description. This task also serves as a lens into how LLMs understand the visual world by prompting them to generate images rendered from SGPs. Among various SGPs, our paper sticks to scalable vector graphics (SVGs). We begin by examining the extent to which LLMs can generate SGPs. To this end, we introduce SGP-GenBench, a comprehensive benchmark covering object fidelity, scene fidelity, and compositionality (attribute binding, spatial relations, numeracy). On SGP-GenBench, we discover that frontier proprietary models substantially outperform open-source models, and performance correlates well with general coding capabilities. Motivated by this gap, we aim to improve LLMs' ability to generate SGPs. We propose a reinforcement learning (RL) with verifiable rewards approach, where a format-validity gate ensures renderable SVG, and a cross-modal reward aligns text and the rendered image via strong vision encoders (e.g., SigLIP for text-image and DINO for image-image). Applied to Qwen-2.5-7B, our method substantially improves SVG generation quality and semantics, achieving performance on par with frontier systems. We further analyze training dynamics, showing that RL induces (i) finer decomposition of objects into controllable primitives and (ii) contextual details that improve scene coherence. Our results demonstrate that symbolic graphics programming offers a precise and interpretable lens on cross-modal grounding.

