---
layout: default
title: FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph
---

# FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04772" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04772v1</a>
  <a href="https://arxiv.org/pdf/2509.04772.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04772v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04772v1', 'FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhangding Liu, Neda Mohammadi, John E. Taylor

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**FloodVisionï¼šç»“åˆè§†è§‰è¯­è¨€æ¨¡å‹ä¸é¢†åŸŸçŸ¥è¯†å›¾è°±çš„åŸå¸‚æ´ªæ°´æ·±åº¦ä¼°è®¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `æ´ªæ°´æ·±åº¦ä¼°è®¡` `è§†è§‰è¯­è¨€æ¨¡å‹` `é¢†åŸŸçŸ¥è¯†å›¾è°±` `é›¶æ ·æœ¬å­¦ä¹ ` `åŸå¸‚é˜²æ´ª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ´ªæ°´æ£€æµ‹æ–¹æ³•ä¾èµ–å›ºå®šç›®æ ‡æ£€æµ‹å™¨å’Œç‰¹å®šä»»åŠ¡è®­ç»ƒï¼Œå¯¼è‡´ç²¾åº¦å—é™ä¸”æ³›åŒ–èƒ½åŠ›å·®ï¼Œéš¾ä»¥é€‚åº”å¤šæ ·åŒ–çš„æ´ªæ°´åœºæ™¯ã€‚
2. FloodVisionåˆ©ç”¨GPT-4oçš„è¯­ä¹‰æ¨ç†èƒ½åŠ›ï¼Œç»“åˆé¢†åŸŸçŸ¥è¯†å›¾è°±ä¸­åŸå¸‚å¯¹è±¡çš„å°ºå¯¸ä¿¡æ¯ï¼Œå®ç°é›¶æ ·æœ¬çš„æ´ªæ°´æ·±åº¦ä¼°è®¡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒFloodVisionåœ¨æ´ªæ°´æ·±åº¦ä¼°è®¡ä¸Šä¼˜äºGPT-4oåŸºçº¿å’Œä¼ ç»ŸCNNæ–¹æ³•ï¼Œä¸”å…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§å’Œå®æ—¶æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºFloodVisionï¼Œä¸€ä¸ªé›¶æ ·æœ¬æ¡†æ¶ï¼Œç”¨äºå‡†ç¡®ä¼°è®¡åŸå¸‚æ´ªæ°´æ·±åº¦ï¼Œè¿™å¯¹é“è·¯é€šè¡Œå’Œåº”æ€¥å“åº”è‡³å…³é‡è¦ã€‚è¯¥æ¡†æ¶ç»“åˆäº†åŸºç¡€è§†è§‰è¯­è¨€æ¨¡å‹GPT-4oçš„è¯­ä¹‰æ¨ç†èƒ½åŠ›å’Œç»“æ„åŒ–çš„é¢†åŸŸçŸ¥è¯†å›¾è°±ã€‚çŸ¥è¯†å›¾è°±ç¼–ç äº†è½¦è¾†ã€äººå‘˜å’ŒåŸºç¡€è®¾æ–½ç­‰å¸¸è§åŸå¸‚ç‰©ä½“çš„æ ‡å‡†å°ºå¯¸ï¼Œä½¿æ¨¡å‹æ¨ç†ä¸ç‰©ç†ç°å®ç›¸ç»“åˆã€‚FloodVisionåŠ¨æ€è¯†åˆ«RGBå›¾åƒä¸­çš„å¯è§å‚è€ƒå¯¹è±¡ï¼Œä»çŸ¥è¯†å›¾è°±æ£€ç´¢éªŒè¯çš„é«˜åº¦ä»¥å‡å°‘å¹»è§‰ï¼Œä¼°è®¡æ·¹æ²¡æ¯”ä¾‹ï¼Œå¹¶åº”ç”¨ç»Ÿè®¡å¼‚å¸¸å€¼è¿‡æ»¤æ¥è®¡ç®—æœ€ç»ˆæ·±åº¦å€¼ã€‚åœ¨MyCoast New Yorkçš„110å¼ ä¼—åŒ…å›¾åƒä¸Šè¯„ä¼°ï¼ŒFloodVisionå®ç°äº†8.17å˜ç±³çš„å¹³å‡ç»å¯¹è¯¯å·®ï¼Œæ¯”GPT-4oåŸºçº¿é™ä½äº†10.28å˜ç±³ï¼Œé™ä½å¹…åº¦ä¸º20.5%ï¼Œè¶…è¿‡äº†å…ˆå‰çš„åŸºäºCNNçš„æ–¹æ³•ã€‚è¯¥ç³»ç»Ÿåœ¨ä¸åŒåœºæ™¯ä¸­å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶èƒ½è¿‘å®æ—¶è¿è¡Œï¼Œé€‚åˆæœªæ¥é›†æˆåˆ°æ•°å­—å­ªç”Ÿå¹³å°å’Œå…¬æ°‘æŠ¥å‘Šåº”ç”¨ç¨‹åºä¸­ï¼Œä»¥æé«˜æ™ºæ…§åŸå¸‚çš„æ´ªæ°´éŸ§æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŸå¸‚ç¯å¢ƒä¸­å‡†ç¡®ä¼°è®¡æ´ªæ°´æ·±åº¦çš„é—®é¢˜ã€‚ç°æœ‰åŸºäºè®¡ç®—æœºè§†è§‰çš„æ´ªæ°´æ£€æµ‹æ–¹æ³•ä¾èµ–äºå›ºå®šç›®æ ‡æ£€æµ‹å™¨å’Œç‰¹å®šä»»åŠ¡çš„è®­ç»ƒæ•°æ®ï¼Œå¯¼è‡´æ¨¡å‹åœ¨é¢å¯¹ä¸åŒåœºæ™¯æ—¶æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œå¹¶ä¸”ç²¾åº¦æœ‰é™ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿè·¨åœºæ™¯æ³›åŒ–ä¸”ç²¾åº¦æ›´é«˜çš„æ´ªæ°´æ·±åº¦ä¼°è®¡æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-4oï¼‰çš„è¯­ä¹‰ç†è§£èƒ½åŠ›å’Œé¢†åŸŸçŸ¥è¯†å›¾è°±æä¾›çš„ç»“æ„åŒ–çŸ¥è¯†ã€‚é€šè¿‡è®©æ¨¡å‹ç†è§£å›¾åƒä¸­çš„åœºæ™¯ï¼Œå¹¶ç»“åˆçŸ¥è¯†å›¾è°±ä¸­å¸¸è§ç‰©ä½“çš„å°ºå¯¸ä¿¡æ¯ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°æ¨æ–­å‡ºæ´ªæ°´æ·±åº¦ï¼Œè€Œæ— éœ€é’ˆå¯¹ç‰¹å®šåœºæ™¯è¿›è¡Œè®­ç»ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFloodVisionæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **å›¾åƒè¾“å…¥ä¸å¯¹è±¡è¯†åˆ«**ï¼šè¾“å…¥RGBå›¾åƒï¼Œåˆ©ç”¨GPT-4oè¯†åˆ«å›¾åƒä¸­å¯è§çš„å‚è€ƒå¯¹è±¡ï¼ˆå¦‚è½¦è¾†ã€è¡Œäººã€å»ºç­‘ç‰©ç­‰ï¼‰ã€‚2) **çŸ¥è¯†å›¾è°±æ£€ç´¢**ï¼šä»é¢„å…ˆæ„å»ºçš„é¢†åŸŸçŸ¥è¯†å›¾è°±ä¸­æ£€ç´¢è¯†åˆ«å‡ºçš„å‚è€ƒå¯¹è±¡çš„æ ‡å‡†å°ºå¯¸ä¿¡æ¯ã€‚çŸ¥è¯†å›¾è°±ç”¨äºæä¾›ç‰©ç†ä¸–ç•Œçš„å…ˆéªŒçŸ¥è¯†ï¼Œå‡å°‘æ¨¡å‹å¹»è§‰ã€‚3) **æ·¹æ²¡æ¯”ä¾‹ä¼°è®¡**ï¼šæ ¹æ®å‚è€ƒå¯¹è±¡åœ¨å›¾åƒä¸­çš„å¯è§éƒ¨åˆ†ï¼Œä¼°è®¡å…¶è¢«æ·¹æ²¡çš„æ¯”ä¾‹ã€‚4) **æ·±åº¦è®¡ç®—ä¸å¼‚å¸¸å€¼è¿‡æ»¤**ï¼šç»“åˆå‚è€ƒå¯¹è±¡çš„å°ºå¯¸ä¿¡æ¯å’Œæ·¹æ²¡æ¯”ä¾‹ï¼Œè®¡ç®—æ´ªæ°´æ·±åº¦ã€‚åº”ç”¨ç»Ÿè®¡å¼‚å¸¸å€¼è¿‡æ»¤æ–¹æ³•ï¼Œå»é™¤ä¸åˆç†çš„æ·±åº¦ä¼°è®¡å€¼ï¼Œå¾—åˆ°æœ€ç»ˆçš„æ´ªæ°´æ·±åº¦ä¼°è®¡ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ä¸é¢†åŸŸçŸ¥è¯†å›¾è°±ç›¸ç»“åˆï¼Œå®ç°é›¶æ ·æœ¬çš„æ´ªæ°´æ·±åº¦ä¼°è®¡ã€‚ä¸ä¼ ç»Ÿçš„ä¾èµ–äºç‰¹å®šæ•°æ®é›†è®­ç»ƒçš„æ–¹æ³•ä¸åŒï¼ŒFloodVisionèƒ½å¤Ÿåˆ©ç”¨GPT-4oçš„é€šç”¨è¯­ä¹‰ç†è§£èƒ½åŠ›å’ŒçŸ¥è¯†å›¾è°±æä¾›çš„ç»“æ„åŒ–çŸ¥è¯†ï¼Œä»è€Œåœ¨ä¸åŒåœºæ™¯ä¸‹å®ç°æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šçŸ¥è¯†å›¾è°±çš„è®¾è®¡æ˜¯å…³é”®ã€‚çŸ¥è¯†å›¾è°±éœ€è¦åŒ…å«å¸¸è§åŸå¸‚å¯¹è±¡çš„æ ‡å‡†å°ºå¯¸ä¿¡æ¯ï¼Œå¹¶ä¸”éœ€è¦ä¿è¯ä¿¡æ¯çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œå¼‚å¸¸å€¼è¿‡æ»¤ç®—æ³•çš„é€‰æ‹©ä¹Ÿä¼šå½±å“æœ€ç»ˆçš„æ·±åº¦ä¼°è®¡ç²¾åº¦ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†ç»Ÿè®¡å¼‚å¸¸å€¼è¿‡æ»¤æ–¹æ³•ï¼Œä½†ä¹Ÿå¯ä»¥å°è¯•å…¶ä»–æ›´å¤æ‚çš„å¼‚å¸¸å€¼æ£€æµ‹ç®—æ³•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

FloodVisionåœ¨MyCoast New Yorkçš„110å¼ ä¼—åŒ…å›¾åƒä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®ç°äº†8.17å˜ç±³çš„å¹³å‡ç»å¯¹è¯¯å·®ã€‚ç›¸æ¯”äºGPT-4oåŸºçº¿ï¼ŒFloodVisionçš„è¯¯å·®é™ä½äº†10.28å˜ç±³ï¼Œé™å¹…è¾¾20.5%ã€‚æ­¤å¤–ï¼ŒFloodVisionçš„æ€§èƒ½ä¹Ÿä¼˜äºå…ˆå‰çš„åŸºäºCNNçš„æ´ªæ°´æ·±åº¦ä¼°è®¡æ–¹æ³•ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æ³›åŒ–æ€§å’Œç²¾åº¦æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FloodVisionå¯åº”ç”¨äºæ™ºæ…§åŸå¸‚å»ºè®¾ä¸­çš„æ´ªæ°´ç›‘æµ‹å’Œé¢„è­¦ç³»ç»Ÿã€‚å®ƒå¯ä»¥é›†æˆåˆ°æ•°å­—å­ªç”Ÿå¹³å°å’Œå…¬æ°‘æŠ¥å‘Šåº”ç”¨ç¨‹åºä¸­ï¼Œä¸ºåº”æ€¥å“åº”æä¾›åŠæ—¶çš„æ´ªæ°´æ·±åº¦ä¿¡æ¯ï¼Œå¸®åŠ©åˆ¶å®šåˆç†çš„ç–æ•£è®¡åˆ’ï¼Œå‡å°‘æ´ªæ°´é€ æˆçš„æŸå¤±ã€‚è¯¥æŠ€æœ¯è¿˜å¯ç”¨äºè¯„ä¼°åŸå¸‚åŸºç¡€è®¾æ–½çš„æŠ—æ´ªèƒ½åŠ›ï¼Œä¸ºåŸå¸‚è§„åˆ’æä¾›å†³ç­–æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Timely and accurate floodwater depth estimation is critical for road accessibility and emergency response. While recent computer vision methods have enabled flood detection, they suffer from both accuracy limitations and poor generalization due to dependence on fixed object detectors and task-specific training. To enable accurate depth estimation that can generalize across diverse flood scenarios, this paper presents FloodVision, a zero-shot framework that combines the semantic reasoning abilities of the foundation vision-language model GPT-4o with a structured domain knowledge graph. The knowledge graph encodes canonical real-world dimensions for common urban objects including vehicles, people, and infrastructure elements to ground the model's reasoning in physical reality. FloodVision dynamically identifies visible reference objects in RGB images, retrieves verified heights from the knowledge graph to mitigate hallucination, estimates submergence ratios, and applies statistical outlier filtering to compute final depth values. Evaluated on 110 crowdsourced images from MyCoast New York, FloodVision achieves a mean absolute error of 8.17 cm, reducing the GPT-4o baseline 10.28 cm by 20.5% and surpassing prior CNN-based methods. The system generalizes well across varying scenes and operates in near real-time, making it suitable for future integration into digital twin platforms and citizen-reporting apps for smart city flood resilience.

