---
layout: default
title: PropVG: End-to-End Proposal-Driven Visual Grounding with Multi-Granularity Discrimination
---

# PropVG: End-to-End Proposal-Driven Visual Grounding with Multi-Granularity Discrimination

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04833" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04833v1</a>
  <a href="https://arxiv.org/pdf/2509.04833.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04833v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04833v1', 'PropVG: End-to-End Proposal-Driven Visual Grounding with Multi-Granularity Discrimination')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ming Dai, Wenxuan Cheng, Jiedong Zhuang, Jiang-jiang Liu, Hongshen Zhao, Zhenhua Feng, Wankou Yang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

**å¤‡æ³¨**: ICCV2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Dmmm1997/PropVG)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PropVGï¼šæå‡ºç«¯åˆ°ç«¯çš„åŸºäºæè®®çš„è§†è§‰å®šä½æ¡†æ¶ï¼Œæå‡å¤æ‚åœºæ™¯ä¸‹çš„ç›®æ ‡è¯†åˆ«èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰å®šä½` `ç«¯åˆ°ç«¯å­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `å¤šç²’åº¦åˆ¤åˆ«` `ç›®æ ‡æ£€æµ‹` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰å®šä½æ–¹æ³•è¿‡åº¦ä¾èµ–ç›®æ ‡ç›‘ç£ï¼Œå¿½ç•¥äº†å‰æ™¯ç›®æ ‡çš„æ½œåœ¨ä»·å€¼ï¼Œä¸”ç¼ºä¹å¤šç²’åº¦åˆ¤åˆ«èƒ½åŠ›ã€‚
2. PropVGæ¡†æ¶é€šè¿‡æ— ç¼é›†æˆå‰æ™¯æè®®ç”Ÿæˆä¸å‚è€ƒå¯¹è±¡ç†è§£ï¼Œå¹¶å¼•å…¥å¯¹æ¯”å­¦ä¹ å’Œå¤šç²’åº¦åˆ¤åˆ«æ¨¡å—æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒPropVGè¡¨ç°å‡ºæ˜¾è‘—çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†å…¶åœ¨è§†è§‰å®šä½ä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰å®šä½é¢†åŸŸçš„æœ€æ–°è¿›å±•å·²é€æ¸ä»ä¼ ç»Ÿçš„åŸºäºæè®®çš„ä¸¤é˜¶æ®µæ¡†æ¶è½¬å‘ç«¯åˆ°ç«¯çš„ç›´æ¥å‚è€ƒèŒƒå¼ï¼Œå› ä¸ºå‰è€…æ•ˆç‡è¾ƒä½ä¸”è®¡ç®—å¤æ‚åº¦é«˜ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä»…ä¾èµ–äºè¢«å‚è€ƒçš„ç›®æ ‡è¿›è¡Œç›‘ç£ï¼Œå¿½ç•¥äº†æ½œåœ¨çš„å‰æ™¯ç›®æ ‡çš„ç›Šå¤„ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸æœªèƒ½æ•´åˆå¤šç²’åº¦åˆ¤åˆ«ï¼Œè¿™å¯¹äºå¤æ‚åœºæ™¯ä¸­ç¨³å¥çš„ç›®æ ‡è¯†åˆ«è‡³å…³é‡è¦ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†PropVGï¼Œè¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„åŸºäºæè®®çš„æ¡†æ¶ï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªæ— ç¼åœ°å°†å‰æ™¯å¯¹è±¡æè®®ç”Ÿæˆä¸å‚è€ƒå¯¹è±¡ç†è§£ç›¸ç»“åˆï¼Œè€Œæ— éœ€é¢å¤–çš„æ£€æµ‹å™¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºäºå¯¹æ¯”çš„å‚è€ƒè¯„åˆ†ï¼ˆCRSï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—åœ¨å¥å­å’Œå•è¯çº§åˆ«é‡‡ç”¨å¯¹æ¯”å­¦ä¹ ï¼Œä»¥å¢å¼ºç†è§£å’ŒåŒºåˆ†å‚è€ƒå¯¹è±¡çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå¤šç²’åº¦ç›®æ ‡åˆ¤åˆ«ï¼ˆMTDï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—èåˆäº†å¯¹è±¡çº§å’Œè¯­ä¹‰çº§ä¿¡æ¯ï¼Œä»¥æé«˜å¯¹ç¼ºå¤±ç›®æ ‡çš„è¯†åˆ«ã€‚åœ¨gRefCOCOï¼ˆGREC/GRESï¼‰ã€Ref-ZOMã€R-RefCOCOå’ŒRefCOCOï¼ˆREC/RESï¼‰åŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†PropVGçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†è§‰å®šä½æ—¨åœ¨æ ¹æ®ç»™å®šçš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œåœ¨å›¾åƒä¸­å®šä½åˆ°å¯¹åº”çš„ç›®æ ‡å¯¹è±¡ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ç«¯åˆ°ç«¯çš„æ–¹æ³•ï¼Œè™½ç„¶é¿å…äº†ä¸¤é˜¶æ®µæ¡†æ¶çš„ä½æ•ˆï¼Œä½†è¿‡åº¦ä¾èµ–äºè¢«å‚è€ƒçš„ç›®æ ‡è¿›è¡Œç›‘ç£ï¼Œå¿½ç•¥äº†å›¾åƒä¸­å…¶ä»–æ½œåœ¨å‰æ™¯ç›®æ ‡çš„ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œåœ¨å¤æ‚åœºæ™¯ä¸‹ï¼Œç°æœ‰æ–¹æ³•ç¼ºä¹è¶³å¤Ÿçš„å¤šç²’åº¦åˆ¤åˆ«èƒ½åŠ›ï¼Œéš¾ä»¥å‡†ç¡®è¯†åˆ«ç›®æ ‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPropVGçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å‰æ™¯å¯¹è±¡æè®®ç”Ÿæˆä¸å‚è€ƒå¯¹è±¡ç†è§£æ— ç¼é›†æˆåˆ°ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¡†æ¶ä¸­ã€‚é€šè¿‡åˆ©ç”¨å‰æ™¯æè®®ï¼Œæ¨¡å‹å¯ä»¥åŒæ—¶å…³æ³¨è¢«å‚è€ƒçš„ç›®æ ‡ä»¥åŠå…¶ä»–æ½œåœ¨çš„ç›®æ ‡ï¼Œä»è€Œè·å¾—æ›´å…¨é¢çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¼•å…¥å¯¹æ¯”å­¦ä¹ å’Œå¤šç²’åº¦åˆ¤åˆ«æ¨¡å—ï¼Œæ¨¡å‹å¯ä»¥æ›´å¥½åœ°ç†è§£è¯­è¨€æè¿°ï¼Œå¹¶åŒºåˆ†ä¸åŒçš„ç›®æ ‡å¯¹è±¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPropVGæ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šå‰æ™¯å¯¹è±¡æè®®ç”Ÿæˆæ¨¡å—ã€åŸºäºå¯¹æ¯”çš„å‚è€ƒè¯„åˆ†ï¼ˆCRSï¼‰æ¨¡å—å’Œå¤šç²’åº¦ç›®æ ‡åˆ¤åˆ«ï¼ˆMTDï¼‰æ¨¡å—ã€‚é¦–å…ˆï¼Œå‰æ™¯å¯¹è±¡æè®®ç”Ÿæˆæ¨¡å—è´Ÿè´£ç”Ÿæˆå›¾åƒä¸­æ½œåœ¨çš„ç›®æ ‡å¯¹è±¡æè®®ã€‚ç„¶åï¼ŒCRSæ¨¡å—åˆ©ç”¨å¯¹æ¯”å­¦ä¹ ï¼Œåœ¨å¥å­å’Œå•è¯çº§åˆ«å­¦ä¹ è¯­è¨€æè¿°å’Œè§†è§‰æè®®ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œä»è€Œä¸ºæ¯ä¸ªæè®®æ‰“åˆ†ã€‚æœ€åï¼ŒMTDæ¨¡å—èåˆå¯¹è±¡çº§å’Œè¯­ä¹‰çº§ä¿¡æ¯ï¼Œè¿›ä¸€æ­¥æé«˜å¯¹ç›®æ ‡çš„è¯†åˆ«èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯å¯¹äºç¼ºå¤±ç›®æ ‡çš„è¯†åˆ«ã€‚

**å…³é”®åˆ›æ–°**ï¼šPropVGçš„å…³é”®åˆ›æ–°åœ¨äºä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š1) é¦–æ¬¡å°†å‰æ™¯å¯¹è±¡æè®®ç”Ÿæˆä¸å‚è€ƒå¯¹è±¡ç†è§£æ— ç¼é›†æˆåˆ°ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¡†æ¶ä¸­ï¼Œé¿å…äº†ä¼ ç»Ÿä¸¤é˜¶æ®µæ¡†æ¶çš„ä½æ•ˆã€‚2) æå‡ºäº†åŸºäºå¯¹æ¯”çš„å‚è€ƒè¯„åˆ†ï¼ˆCRSï¼‰æ¨¡å—ï¼Œåˆ©ç”¨å¯¹æ¯”å­¦ä¹ å¢å¼ºäº†æ¨¡å‹ç†è§£å’ŒåŒºåˆ†å‚è€ƒå¯¹è±¡çš„èƒ½åŠ›ã€‚3) è®¾è®¡äº†å¤šç²’åº¦ç›®æ ‡åˆ¤åˆ«ï¼ˆMTDï¼‰æ¨¡å—ï¼Œèåˆäº†å¯¹è±¡çº§å’Œè¯­ä¹‰çº§ä¿¡æ¯ï¼Œæé«˜äº†å¯¹ç›®æ ‡çš„è¯†åˆ«èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯å¯¹äºç¼ºå¤±ç›®æ ‡çš„è¯†åˆ«ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒPropVGèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨å›¾åƒä¸­çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¹¶å…·æœ‰æ›´å¼ºçš„åˆ¤åˆ«èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨CRSæ¨¡å—ä¸­ï¼Œé‡‡ç”¨äº†å¥å­çº§åˆ«å’Œå•è¯çº§åˆ«çš„å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œä»¥å­¦ä¹ è¯­è¨€æè¿°å’Œè§†è§‰æè®®ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚åœ¨MTDæ¨¡å—ä¸­ï¼Œèåˆäº†å¯¹è±¡çº§åˆ«çš„è§†è§‰ç‰¹å¾å’Œè¯­ä¹‰çº§åˆ«çš„å±æ€§ç‰¹å¾ï¼Œä»¥æé«˜å¯¹ç›®æ ‡çš„è¯†åˆ«èƒ½åŠ›ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼Œä»£ç å·²å¼€æºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PropVGåœ¨gRefCOCOã€Ref-ZOMã€R-RefCOCOå’ŒRefCOCOç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨RefCOCOæ•°æ®é›†ä¸Šï¼ŒPropVGçš„å‡†ç¡®ç‡è¶…è¿‡äº†ç°æœ‰æœ€ä½³æ–¹æ³•X%ï¼Œè¯æ˜äº†å…¶åœ¨è§†è§‰å®šä½ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPropVGèƒ½å¤Ÿæ›´å‡†ç¡®åœ°ç†è§£è¯­è¨€æè¿°ï¼Œå¹¶å®šä½åˆ°å›¾åƒä¸­çš„ç›®æ ‡å¯¹è±¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PropVGåœ¨è§†è§‰å®šä½é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å›¾åƒæœç´¢ã€äººæœºäº¤äº’ã€æœºå™¨äººå¯¼èˆªç­‰ã€‚é€šè¿‡ç†è§£è‡ªç„¶è¯­è¨€æè¿°å¹¶å®šä½å›¾åƒä¸­çš„ç›®æ ‡å¯¹è±¡ï¼ŒPropVGå¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´æ–¹ä¾¿åœ°è·å–æ‰€éœ€ä¿¡æ¯ï¼Œå¹¶ä¸ºæœºå™¨äººæä¾›æ›´å‡†ç¡®çš„ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ã€‚æœªæ¥ï¼ŒPropVGå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°è§†é¢‘å®šä½ã€ä¸‰ç»´åœºæ™¯ç†è§£ç­‰æ›´å¤æ‚çš„ä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in visual grounding have largely shifted away from traditional proposal-based two-stage frameworks due to their inefficiency and high computational complexity, favoring end-to-end direct reference paradigms. However, these methods rely exclusively on the referred target for supervision, overlooking the potential benefits of prominent prospective targets. Moreover, existing approaches often fail to incorporate multi-granularity discrimination, which is crucial for robust object identification in complex scenarios. To address these limitations, we propose PropVG, an end-to-end proposal-based framework that, to the best of our knowledge, is the first to seamlessly integrate foreground object proposal generation with referential object comprehension without requiring additional detectors. Furthermore, we introduce a Contrastive-based Refer Scoring (CRS) module, which employs contrastive learning at both sentence and word levels to enhance the capability in understanding and distinguishing referred objects. Additionally, we design a Multi-granularity Target Discrimination (MTD) module that fuses object- and semantic-level information to improve the recognition of absent targets. Extensive experiments on gRefCOCO (GREC/GRES), Ref-ZOM, R-RefCOCO, and RefCOCO (REC/RES) benchmarks demonstrate the effectiveness of PropVG. The codes and models are available at https://github.com/Dmmm1997/PropVG.

