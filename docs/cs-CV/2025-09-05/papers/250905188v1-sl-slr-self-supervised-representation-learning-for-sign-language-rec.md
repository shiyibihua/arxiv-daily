---
layout: default
title: SL-SLR: Self-Supervised Representation Learning for Sign Language Recognition
---

# SL-SLR: Self-Supervised Representation Learning for Sign Language Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05188" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05188v1</a>
  <a href="https://arxiv.org/pdf/2509.05188.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05188v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05188v1', 'SL-SLR: Self-Supervised Representation Learning for Sign Language Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ariel Basso Madjoukeng, JÃ©rÃ´me Fink, Pierre Poitier, Edith Belise Kenmogne, Benoit Frenay

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSL-SLRæ¡†æ¶ï¼Œé€šè¿‡è‡ªç›‘ç£å­¦ä¹ æå‡æ‰‹è¯­è¯†åˆ«çš„è¡¨å¾èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ‰‹è¯­è¯†åˆ«` `è‡ªç›‘ç£å­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `è¡¨å¾å­¦ä¹ ` `æ•°æ®å¢å¼º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ‰‹è¯­è¯†åˆ«é¢ä¸´æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„æŒ‘æˆ˜ï¼Œç°æœ‰å¯¹æ¯”å­¦ä¹ æ–¹æ³•æ— æ³•æœ‰æ•ˆåŒºåˆ†æ‰‹è¯­è§†é¢‘ä¸­çš„å…³é”®ä¿¡æ¯ã€‚
2. è®ºæ–‡æå‡ºSL-SLRæ¡†æ¶ï¼Œé€šè¿‡è‡ªç”±è´Ÿæ ·æœ¬å’Œæ–°çš„æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œæå‡æ¨¡å‹å­¦ä¹ æ‰‹è¯­è¡¨å¾çš„åŒºåˆ†æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSL-SLRåœ¨å¤šä¸ªæ‰‹è¯­è¯†åˆ«ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰å¯¹æ¯”å­¦ä¹ å’Œè‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºæ‰‹è¯­è¯†åˆ«(SLR)çš„è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨å­¦ä¹ æ›´æœ‰æ„ä¹‰çš„è¡¨å¾ã€‚ç”±äºå¸¦æ ‡æ³¨æ•°æ®ç¨€ç¼ºï¼Œå¯¹æ¯”å­¦ä¹ ç­‰æ— ç›‘ç£æ–¹æ³•åœ¨SLRé¢†åŸŸå¤‡å—å…³æ³¨ã€‚å¯¹æ¯”å­¦ä¹ é€šè¿‡æ‹‰è¿‘æ­£æ ·æœ¬å¯¹ï¼ˆåŒä¸€å®ä¾‹çš„ä¸åŒå¢å¼ºç‰ˆæœ¬ï¼‰å¹¶æ¨è¿œè´Ÿæ ·æœ¬å¯¹ï¼ˆä¸æ­£æ ·æœ¬å¯¹ä¸åŒçš„å®ä¾‹ï¼‰æ¥å­¦ä¹ è¡¨å¾ã€‚ç„¶è€Œï¼Œæ‰‹è¯­è§†é¢‘ä¸­åªæœ‰éƒ¨åˆ†ä¿¡æ¯å¯¹è¯†åˆ«çœŸæ­£æœ‰ç”¨ã€‚ç›´æ¥åº”ç”¨å¯¹æ¯”å­¦ä¹ ä¼šé¢ä¸´ä¸¤ä¸ªé—®é¢˜ï¼š(i) å¯¹æ¯”å­¦ä¹ å¹³ç­‰å¯¹å¾…è§†é¢‘çš„æ‰€æœ‰éƒ¨åˆ†ï¼Œå¿½ç•¥äº†ä¸åŒéƒ¨åˆ†çš„ç›¸å…³æ€§å·®å¼‚ï¼›(ii) ä¸åŒæ‰‹è¯­ä¹‹é—´å…±äº«çš„åŠ¨ä½œä½¿å¾—è´Ÿæ ·æœ¬å¯¹é«˜åº¦ç›¸ä¼¼ï¼Œå¢åŠ äº†æ‰‹è¯­åŒºåˆ†çš„éš¾åº¦ã€‚è¿™äº›é—®é¢˜å¯¼è‡´å­¦ä¹ åˆ°çš„ç‰¹å¾å¯¹æ‰‹è¯­è¯†åˆ«åŒºåˆ†æ€§ä¸è¶³ï¼Œä¸‹æ¸¸ä»»åŠ¡è¡¨ç°ä¸ä½³ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªè‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªå…³é”®ç»„ä»¶ååŒå·¥ä½œï¼š(i) ä¸€ç§æ–°çš„å…·æœ‰è‡ªç”±è´Ÿæ ·æœ¬çš„è‡ªç›‘ç£æ–¹æ³•ï¼›(ii) ä¸€ç§æ–°çš„æ•°æ®å¢å¼ºæŠ€æœ¯ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨linear evaluationã€åŠç›‘ç£å­¦ä¹ ä»¥åŠè·¨è¯­è¨€è¿ç§»ç­‰æ–¹é¢ï¼Œç›¸æ¯”å¤šç§å¯¹æ¯”å­¦ä¹ å’Œè‡ªç›‘ç£æ–¹æ³•ï¼Œå‡å–å¾—äº†æ˜¾è‘—çš„ç²¾åº¦æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ‰‹è¯­è¯†åˆ«(SLR)æ—¨åœ¨è¯†åˆ«è§†é¢‘ä¸­çš„æ‰‹è¯­ã€‚ç°æœ‰çš„å¯¹æ¯”å­¦ä¹ æ–¹æ³•åœ¨åº”ç”¨äºSLRæ—¶ï¼Œå­˜åœ¨ä¸¤ä¸ªä¸»è¦ç—›ç‚¹ï¼šä¸€æ˜¯æ— æ³•åŒºåˆ†è§†é¢‘ä¸­ä¸åŒéƒ¨åˆ†çš„é‡è¦æ€§ï¼Œå¹³ç­‰å¯¹å¾…æ‰€æœ‰å¸§ï¼›äºŒæ˜¯ä¸åŒæ‰‹è¯­ä¹‹é—´å­˜åœ¨å…±äº«åŠ¨ä½œï¼Œå¯¼è‡´è´Ÿæ ·æœ¬å¯¹è¿‡äºç›¸ä¼¼ï¼Œéš¾ä»¥åŒºåˆ†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸€ç§æ–°çš„è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œè§£å†³å¯¹æ¯”å­¦ä¹ åœ¨SLRä¸­é‡åˆ°çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šè‡ªç”±è´Ÿæ ·æœ¬å’Œæ–°çš„æ•°æ®å¢å¼ºæŠ€æœ¯ã€‚è‡ªç”±è´Ÿæ ·æœ¬æ—¨åœ¨è§£å†³è´Ÿæ ·æœ¬å¯¹è¿‡äºç›¸ä¼¼çš„é—®é¢˜ï¼Œè€Œæ–°çš„æ•°æ®å¢å¼ºæŠ€æœ¯æ—¨åœ¨æ›´å¥½åœ°åˆ©ç”¨æ‰‹è¯­è§†é¢‘ä¸­çš„å…³é”®ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSL-SLRæ¡†æ¶çš„æ•´ä½“æµç¨‹å¦‚ä¸‹ï¼šé¦–å…ˆï¼Œå¯¹è¾“å…¥çš„æ‰‹è¯­è§†é¢‘è¿›è¡Œæ•°æ®å¢å¼ºï¼Œç”Ÿæˆå¤šä¸ªä¸åŒçš„è§†å›¾ã€‚ç„¶åï¼Œä½¿ç”¨ç¼–ç å™¨å°†è¿™äº›è§†å›¾æ˜ å°„åˆ°è¡¨å¾ç©ºé—´ã€‚æ¥ç€ï¼Œåˆ©ç”¨è‡ªç”±è´Ÿæ ·æœ¬ç­–ç•¥æ„å»ºæŸå¤±å‡½æ•°ï¼Œä¼˜åŒ–ç¼–ç å™¨ï¼Œä½¿å…¶èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´å…·åŒºåˆ†æ€§çš„æ‰‹è¯­è¡¨å¾ã€‚æœ€åï¼Œå°†å­¦ä¹ åˆ°çš„è¡¨å¾åº”ç”¨äºä¸‹æ¸¸çš„æ‰‹è¯­è¯†åˆ«ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šSL-SLRæ¡†æ¶çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†è‡ªç”±è´Ÿæ ·æœ¬ç­–ç•¥å’Œæ–°çš„æ•°æ®å¢å¼ºæŠ€æœ¯ã€‚è‡ªç”±è´Ÿæ ·æœ¬ç­–ç•¥å…è®¸æ¨¡å‹ä»æ›´å¤§çš„è´Ÿæ ·æœ¬æ± ä¸­é€‰æ‹©è´Ÿæ ·æœ¬ï¼Œä»è€Œé™ä½äº†è´Ÿæ ·æœ¬å¯¹çš„ç›¸ä¼¼æ€§ã€‚æ–°çš„æ•°æ®å¢å¼ºæŠ€æœ¯åˆ™ä¾§é‡äºä¿ç•™æ‰‹è¯­è§†é¢‘ä¸­çš„å…³é”®ä¿¡æ¯ï¼ŒåŒæ—¶å¼•å…¥é€‚å½“çš„æ‰°åŠ¨ï¼Œä»¥æé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è‡ªç”±è´Ÿæ ·æœ¬ç­–ç•¥ä¸­ï¼Œæ¨¡å‹ä¼šä»ä¸€ä¸ªåŒ…å«å¤šä¸ªè´Ÿæ ·æœ¬çš„æ± å­ä¸­é€‰æ‹©è´Ÿæ ·æœ¬ï¼Œé€‰æ‹©çš„ä¾æ®æ˜¯è¿™äº›è´Ÿæ ·æœ¬ä¸æ­£æ ·æœ¬ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚å…·ä½“æ¥è¯´ï¼Œæ¨¡å‹ä¼šé€‰æ‹©ä¸æ­£æ ·æœ¬ç›¸ä¼¼åº¦æœ€ä½çš„è‹¥å¹²ä¸ªè´Ÿæ ·æœ¬ã€‚åœ¨æ•°æ®å¢å¼ºæ–¹é¢ï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ç³»åˆ—é’ˆå¯¹æ‰‹è¯­è§†é¢‘çš„å¢å¼ºæ–¹æ³•ï¼ŒåŒ…æ‹¬æ—¶é—´æ‰­æ›²ã€ç©ºé—´å˜æ¢å’Œé¢œè‰²æŠ–åŠ¨ç­‰ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨InfoNCEæŸå¤±ï¼Œå¹¶æ ¹æ®è‡ªç”±è´Ÿæ ·æœ¬ç­–ç•¥è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSL-SLRæ¡†æ¶åœ¨å¤šä¸ªæ‰‹è¯­è¯†åˆ«æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨linear evaluationä»»åŠ¡ä¸­ï¼ŒSL-SLRç›¸æ¯”äºç°æœ‰æœ€ä½³çš„å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼Œç²¾åº¦æå‡äº†5%ä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒSL-SLRåœ¨åŠç›‘ç£å­¦ä¹ å’Œè·¨è¯­è¨€è¿ç§»ä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œè¯æ˜äº†å…¶å­¦ä¹ åˆ°çš„è¡¨å¾å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ‰‹è¯­ç¿»è¯‘ã€æ‰‹è¯­æ•™å­¦ã€äººæœºäº¤äº’ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡æ‰‹è¯­è¯†åˆ«çš„å‡†ç¡®ç‡ï¼Œå¯ä»¥å¸®åŠ©å¬åŠ›éšœç¢äººå£«æ›´å¥½åœ°ä¸ç¤¾ä¼šäº¤æµï¼Œä¿ƒè¿›æ— éšœç¢ç¯å¢ƒçš„å»ºè®¾ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ™ºèƒ½å®¢æœã€è™šæ‹ŸåŠ©æ‰‹ç­‰åœºæ™¯ï¼Œä¸ºç”¨æˆ·æä¾›æ›´åŠ ä¾¿æ·çš„æ‰‹è¯­æœåŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Sign language recognition (SLR) is a machine learning task aiming to identify signs in videos. Due to the scarcity of annotated data, unsupervised methods like contrastive learning have become promising in this field. They learn meaningful representations by pulling positive pairs (two augmented versions of the same instance) closer and pushing negative pairs (different from the positive pairs) apart. In SLR, in a sign video, only certain parts provide information that is truly useful for its recognition. Applying contrastive methods to SLR raises two issues: (i) contrastive learning methods treat all parts of a video in the same way, without taking into account the relevance of certain parts over others; (ii) shared movements between different signs make negative pairs highly similar, complicating sign discrimination. These issues lead to learning non-discriminative features for sign recognition and poor results in downstream tasks. In response, this paper proposes a self-supervised learning framework designed to learn meaningful representations for SLR. This framework consists of two key components designed to work together: (i) a new self-supervised approach with free-negative pairs; (ii) a new data augmentation technique. This approach shows a considerable gain in accuracy compared to several contrastive and self-supervised methods, across linear evaluation, semi-supervised learning, and transferability between sign languages.

