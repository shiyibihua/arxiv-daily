---
layout: default
title: Constructing and Interpreting Digital Twin Representations for Visual Reasoning via Reinforcement Learning
---

# Constructing and Interpreting Digital Twin Representations for Visual Reasoning via Reinforcement Learning

**arXiv**: [2511.12365v1](https://arxiv.org/abs/2511.12365) | [PDF](https://arxiv.org/pdf/2511.12365.pdf)

**ä½œè€…**: Yiqing Shen, Mathias Unberath

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-15

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå¼ºåŒ–å­¦ä¹ çš„DT-R1æ¡†æž¶ï¼Œåˆ©ç”¨æ•°å­—å­ªç”Ÿè¡¨ç¤ºç»Ÿä¸€è§£å†³è§†è§‰æŽ¨ç†ä»»åŠ¡ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰æŽ¨ç†` `æ•°å­—å­ªç”Ÿ` `å¼ºåŒ–å­¦ä¹ ` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `å¤šæ¨¡æ€å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†è§‰æŽ¨ç†æ–¹æ³•ä¾èµ–äºŽç‰¹å®šä»»åŠ¡çš„ç›‘ç£å¾®è°ƒï¼Œç¼ºä¹ç»Ÿä¸€æ€§å’Œè·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚
2. DT-R1åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¤§åž‹è¯­è¨€æ¨¡åž‹æž„å»ºè§†è§‰è¾“å…¥çš„æ•°å­—å­ªç”Ÿè¡¨ç¤ºï¼Œå®žçŽ°ç»Ÿä¸€çš„è§†è§‰æŽ¨ç†ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒDT-R1åœ¨å…­ä¸ªè§†è§‰æŽ¨ç†åŸºå‡†æµ‹è¯•ä¸­å§‹ç»ˆä¼˜äºŽæœ€å…ˆè¿›çš„ç‰¹å®šä»»åŠ¡æ¨¡åž‹ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰æŽ¨ç†éœ€è¦æ¨¡åž‹ç†è§£å›¾åƒå’Œè§†é¢‘ï¼Œå¹¶å¯¹å„ç§è¾“å‡ºæ ¼å¼ï¼ˆä»Žåƒç´ çº§åˆ†å‰²æŽ©ç åˆ°è‡ªç„¶è¯­è¨€æè¿°ï¼‰çš„éšå¼æ–‡æœ¬æŸ¥è¯¢åšå‡ºå“åº”ã€‚çŽ°æœ‰æ–¹æ³•ä¾èµ–äºŽé’ˆå¯¹ç‰¹å®šä»»åŠ¡æž¶æž„çš„ç›‘ç£å¾®è°ƒã€‚ä¾‹å¦‚ï¼ŒæŽ¨ç†åˆ†å‰²ã€å®šä½ã€æ‘˜è¦å’Œè§†è§‰é—®ç­”éƒ½éœ€è¦ä¸åŒçš„æ¨¡åž‹è®¾è®¡å’Œè®­ç»ƒï¼Œè¿™é˜»ç¢äº†ç»Ÿä¸€çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶é™åˆ¶äº†è·¨ä»»åŠ¡å’Œè·¨æ¨¡æ€çš„æ³›åŒ–ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†DT-R1ï¼Œä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ¡†æž¶ï¼Œå®ƒè®­ç»ƒå¤§åž‹è¯­è¨€æ¨¡åž‹æ¥æž„å»ºå¤æ‚å¤šæ¨¡æ€è§†è§‰è¾“å…¥çš„æ•°å­—å­ªç”Ÿè¡¨ç¤ºï¼Œç„¶åŽåŸºäºŽè¿™äº›é«˜çº§è¡¨ç¤ºè¿›è¡ŒæŽ¨ç†ï¼Œä½œä¸ºè§†è§‰æŽ¨ç†çš„ç»Ÿä¸€æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨GRPOè®­ç»ƒDT-R1ï¼Œå¹¶ä½¿ç”¨ä¸€ç§æ–°é¢–çš„å¥–åŠ±ï¼Œè¯¥å¥–åŠ±éªŒè¯ç»“æž„å®Œæ•´æ€§å’Œè¾“å‡ºå‡†ç¡®æ€§ã€‚åœ¨æ¶µç›–ä¸¤ç§æ¨¡æ€å’Œå››ç§ä»»åŠ¡ç±»åž‹çš„å…­ä¸ªè§†è§‰æŽ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œçš„è¯„ä¼°è¡¨æ˜Žï¼ŒDT-R1å§‹ç»ˆä¼˜äºŽæœ€å…ˆè¿›çš„ç‰¹å®šä»»åŠ¡æ¨¡åž‹ã€‚DT-R1å¼€è¾Ÿäº†ä¸€ä¸ªæ–°çš„æ–¹å‘ï¼Œå³è§†è§‰æŽ¨ç†æºäºŽä½¿ç”¨æ•°å­—å­ªç”Ÿè¡¨ç¤ºçš„å¼ºåŒ–å­¦ä¹ ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰è§†è§‰æŽ¨ç†æ–¹æ³•é’ˆå¯¹ä¸åŒä»»åŠ¡ï¼ˆå¦‚åˆ†å‰²ã€å®šä½ã€é—®ç­”ç­‰ï¼‰éœ€è¦è®¾è®¡ä¸åŒçš„æ¨¡åž‹æž¶æž„å’Œè®­ç»ƒæµç¨‹ï¼Œå¯¼è‡´æ¨¡åž‹éš¾ä»¥æ³›åŒ–åˆ°æ–°çš„ä»»åŠ¡å’Œæ¨¡æ€ä¸Šã€‚è¿™äº›æ–¹æ³•ç¼ºä¹ä¸€ä¸ªç»Ÿä¸€çš„è¡¨ç¤ºå­¦ä¹ æ¡†æž¶ï¼Œæ— æ³•æœ‰æ•ˆåœ°åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯è¿›è¡ŒæŽ¨ç†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸€ä¸ªå¤§åž‹è¯­è¨€æ¨¡åž‹ï¼Œä½¿å…¶èƒ½å¤Ÿå°†å¤æ‚çš„è§†è§‰è¾“å…¥è½¬åŒ–ä¸ºä¸€ç§é«˜å±‚æ¬¡çš„â€œæ•°å­—å­ªç”Ÿâ€è¡¨ç¤ºã€‚è¿™ç§è¡¨ç¤ºèƒ½å¤Ÿæ•æ‰è§†è§‰åœºæ™¯çš„å…³é”®ç»“æž„å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œä»Žè€Œä¸ºåŽç»­çš„æŽ¨ç†ä»»åŠ¡æä¾›ä¸€ä¸ªç»Ÿä¸€çš„åŸºç¡€ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œæ¨¡åž‹å¯ä»¥å­¦ä¹ å¦‚ä½•æž„å»ºæ—¢èƒ½ä¿æŒç»“æž„å®Œæ•´æ€§åˆèƒ½ä¿è¯è¾“å‡ºå‡†ç¡®æ€§çš„æ•°å­—å­ªç”Ÿè¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šDT-R1æ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªå…³é”®æ¨¡å—ï¼š1) è§†è§‰è¾“å…¥ç¼–ç å™¨ï¼šå°†å›¾åƒæˆ–è§†é¢‘ç­‰è§†è§‰è¾“å…¥ç¼–ç æˆç‰¹å¾å‘é‡ã€‚2) å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰ï¼šä½œä¸ºæ™ºèƒ½ä½“ï¼Œè´Ÿè´£æ ¹æ®è§†è§‰ç‰¹å¾é€æ­¥æž„å»ºæ•°å­—å­ªç”Ÿè¡¨ç¤ºã€‚3) å¼ºåŒ–å­¦ä¹ çŽ¯å¢ƒï¼šå®šä¹‰äº†æ™ºèƒ½ä½“çš„åŠ¨ä½œç©ºé—´ï¼ˆä¾‹å¦‚ï¼Œæ·»åŠ ã€ä¿®æ”¹æ•°å­—å­ªç”Ÿè¡¨ç¤ºçš„èŠ‚ç‚¹å’Œå…³ç³»ï¼‰å’ŒçŠ¶æ€ç©ºé—´ï¼ˆä¾‹å¦‚ï¼Œå½“å‰çš„æ•°å­—å­ªç”Ÿè¡¨ç¤ºå’Œè§†è§‰ç‰¹å¾ï¼‰ã€‚4) å¥–åŠ±å‡½æ•°ï¼šç”¨äºŽè¯„ä¼°æ™ºèƒ½ä½“æž„å»ºçš„æ•°å­—å­ªç”Ÿè¡¨ç¤ºçš„è´¨é‡ï¼ŒåŒ…æ‹¬ç»“æž„å®Œæ•´æ€§å’Œè¾“å‡ºå‡†ç¡®æ€§ã€‚æ¡†æž¶ä½¿ç”¨GRPOï¼ˆGradient Ratio Policy Optimizationï¼‰ç®—æ³•è¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽæå‡ºäº†ä½¿ç”¨æ•°å­—å­ªç”Ÿè¡¨ç¤ºä½œä¸ºç»Ÿä¸€çš„è§†è§‰æŽ¨ç†æ¡†æž¶ã€‚ä¸Žä»¥å¾€é’ˆå¯¹ç‰¹å®šä»»åŠ¡è®¾è®¡æ¨¡åž‹ä¸åŒï¼ŒDT-R1é€šè¿‡å­¦ä¹ æž„å»ºé«˜å±‚æ¬¡çš„åœºæ™¯è¡¨ç¤ºï¼Œå®žçŽ°äº†è·¨ä»»åŠ¡å’Œè·¨æ¨¡æ€çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒLLMæ¥æž„å»ºæ•°å­—å­ªç”Ÿè¡¨ç¤ºä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ï¼Œä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿè‡ªé€‚åº”åœ°å­¦ä¹ å¦‚ä½•æœ‰æ•ˆåœ°è¡¨ç¤ºè§†è§‰ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šå¥–åŠ±å‡½æ•°çš„è®¾è®¡æ˜¯å…³é”®ã€‚è®ºæ–‡è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„å¥–åŠ±å‡½æ•°ï¼Œå®ƒåŒæ—¶è€ƒè™‘äº†æ•°å­—å­ªç”Ÿè¡¨ç¤ºçš„ç»“æž„å®Œæ•´æ€§å’Œè¾“å‡ºå‡†ç¡®æ€§ã€‚ç»“æž„å®Œæ•´æ€§å¥–åŠ±é¼“åŠ±æ™ºèƒ½ä½“æž„å»ºç¬¦åˆè§†è§‰åœºæ™¯ç»“æž„çš„è¡¨ç¤ºï¼Œä¾‹å¦‚ï¼Œä¿æŒå¯¹è±¡ä¹‹é—´çš„ç©ºé—´å…³ç³»ã€‚è¾“å‡ºå‡†ç¡®æ€§å¥–åŠ±åˆ™æ ¹æ®ä¸‹æ¸¸æŽ¨ç†ä»»åŠ¡çš„æ€§èƒ½æ¥è¯„ä¼°è¡¨ç¤ºçš„è´¨é‡ï¼Œä¾‹å¦‚ï¼Œåœ¨è§†è§‰é—®ç­”ä»»åŠ¡ä¸­ï¼Œå¥–åŠ±æ™ºèƒ½ä½“ç”Ÿæˆèƒ½å¤Ÿæ­£ç¡®å›žç­”é—®é¢˜çš„è¡¨ç¤ºã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æž„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜Žï¼Œå±žäºŽæœªçŸ¥ä¿¡æ¯ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

DT-R1åœ¨å…­ä¸ªè§†è§‰æŽ¨ç†åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œæ¶µç›–äº†ä¸¤ç§æ¨¡æ€ï¼ˆå›¾åƒå’Œè§†é¢‘ï¼‰å’Œå››ç§ä»»åŠ¡ç±»åž‹ï¼ˆåˆ†å‰²ã€å®šä½ã€æ‘˜è¦å’Œé—®ç­”ï¼‰ã€‚ä¸Žæœ€å…ˆè¿›çš„ç‰¹å®šä»»åŠ¡æ¨¡åž‹ç›¸æ¯”ï¼ŒDT-R1åœ¨æ‰€æœ‰åŸºå‡†æµ‹è¯•ä¸­éƒ½å–å¾—äº†æ›´å¥½çš„ç»“æžœï¼Œè¯æ˜Žäº†å…¶æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†ç»™å‡ºï¼Œå±žäºŽæœªçŸ¥ä¿¡æ¯ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

DT-R1æ¡†æž¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æŽ§ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å‘¨å›´çŽ¯å¢ƒï¼Œä»Žè€Œå®žçŽ°æ›´æ™ºèƒ½çš„å¯¼èˆªå’Œäº¤äº’ã€‚åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼ŒDT-R1å¯ä»¥ç”¨äºŽæž„å»ºè½¦è¾†å‘¨å›´çŽ¯å¢ƒçš„æ•°å­—å­ªç”Ÿæ¨¡åž‹ï¼Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚åœ¨æ™ºèƒ½ç›‘æŽ§é¢†åŸŸï¼ŒDT-R1å¯ä»¥ç”¨äºŽåˆ†æžç›‘æŽ§è§†é¢‘ï¼Œè‡ªåŠ¨è¯†åˆ«å¼‚å¸¸äº‹ä»¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Visual reasoning may require models to interpret images and videos and respond to implicit text queries across diverse output formats, from pixel-level segmentation masks to natural language descriptions. Existing approaches rely on supervised fine-tuning with task-specific architectures. For example, reasoning segmentation, grounding, summarization, and visual question answering each demand distinct model designs and training, preventing unified solutions and limiting cross-task and cross-modality generalization. Hence, we propose DT-R1, a reinforcement learning framework that trains large language models to construct digital twin representations of complex multi-modal visual inputs and then reason over these high-level representations as a unified approach to visual reasoning. Specifically, we train DT-R1 using GRPO with a novel reward that validates both structural integrity and output accuracy. Evaluations in six visual reasoning benchmarks, covering two modalities and four task types, demonstrate that DT-R1 consistently achieves improvements over state-of-the-art task-specific models. DT-R1 opens a new direction where visual reasoning emerges from reinforcement learning with digital twin representations.

