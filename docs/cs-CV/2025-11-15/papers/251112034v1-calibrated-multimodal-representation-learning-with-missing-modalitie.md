---
layout: default
title: Calibrated Multimodal Representation Learning with Missing Modalities
---

# Calibrated Multimodal Representation Learning with Missing Modalities

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.12034" target="_blank" class="toolbar-btn">arXiv: 2511.12034v1</a>
    <a href="https://arxiv.org/pdf/2511.12034.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.12034v1" 
            onclick="toggleFavorite(this, '2511.12034v1', 'Calibrated Multimodal Representation Learning with Missing Modalities')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xiaohao Liu, Xiaobo Xia, Jiaheng Wei, Shuo Yang, Xiu Su, See-Kiong Ng, Tat-Seng Chua

**ÂàÜÁ±ª**: cs.CV, cs.LG, cs.MM

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-15

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫CalMRLÔºåÈÄöËøáÊ†°ÂáÜ‰∏çÂÆåÊï¥ÂØπÈΩêËß£ÂÜ≥Áº∫Â§±Ê®°ÊÄÅ‰∏ãÁöÑÂ§öÊ®°ÊÄÅË°®ÂæÅÂ≠¶‰π†ÈóÆÈ¢ò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Áº∫Â§±Ê®°ÊÄÅ` `Ë°®ÂæÅÂ≠¶‰π†` `ÈîöÁÇπÂÅèÁßª` `Êï∞ÊçÆË°•ÂÖ®`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Â§öÊ®°ÊÄÅË°®ÂæÅÂ≠¶‰π†‰∏≠Ë¶ÅÊ±ÇÊâÄÊúâÊ®°ÊÄÅÂÆåÊï¥ÔºåÊó†Ê≥ïÊúâÊïàÂà©Áî®ÂåÖÂê´Áº∫Â§±Ê®°ÊÄÅÁöÑÂ∏∏ËßÅÊï∞ÊçÆÈõÜ„ÄÇ
2. CalMRLÈÄöËøáÂª∫Ê®°Áº∫Â§±Ê®°ÊÄÅÁöÑË°®ÂæÅË°•ÂÖ®ÔºåÊ†°ÂáÜ‰∏çÂÆåÊï¥ÂØπÈΩêÔºåÁºìËß£Áî±Áº∫Â§±Ê®°ÊÄÅÂØºËá¥ÁöÑÈîöÁÇπÂÅèÁßªÈóÆÈ¢ò„ÄÇ
3. CalMRLÈááÁî®ÂèåÊ≠•Â≠¶‰π†ÊñπÊ≥ïÔºåÂπ∂Êé®ÂØºÂá∫ÂÖ±‰∫´ÊΩúÂú®ÂèòÈáèÂêéÈ™åÂàÜÂ∏ÉÁöÑÈó≠ÂºèËß£ÔºåÂÆûÈ™åËØÅÊòéÂÖ∂‰ºòË∂äÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅË°®ÂæÅÂ≠¶‰π†ÈÄöËøáÂ∞Ü‰∏çÂêåÊ®°ÊÄÅÂØπÈΩêÂà∞Áªü‰∏ÄÁöÑÊΩúÂú®Á©∫Èó¥Êù•ÂçèË∞ÉÂÆÉ‰ª¨„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∞Ü‰º†ÁªüÁöÑË∑®Ê®°ÊÄÅÂØπÈΩêÊé®ÂπøÂà∞‰∫ßÁîüÂ¢ûÂº∫ÁöÑÂ§öÊ®°ÊÄÅÂçèÂêå‰ΩúÁî®Ôºå‰ΩÜËøôË¶ÅÊ±ÇÊâÄÊúâÊ®°ÊÄÅÈÉΩÂ≠òÂú®‰∫é‰∏Ä‰∏™ÂÖ±ÂêåÁöÑÂÆû‰æã‰∏≠ÔºåËøô‰ΩøÂæóÂà©Áî®ÊôÆÈÅçÂ≠òÂú®ÁöÑÂÖ∑ÊúâÁº∫Â§±Ê®°ÊÄÅÁöÑÊï∞ÊçÆÈõÜÂÖ∑ÊúâÊåëÊàòÊÄß„ÄÇÊàë‰ª¨‰ªéÈîöÁÇπÂÅèÁßªÁöÑËßíÂ∫¶Êèê‰æõ‰∫ÜÂØπËøô‰∏™ÈóÆÈ¢òÁöÑÁêÜËÆ∫ËßÅËß£„ÄÇËßÇÂØüÂà∞ÁöÑÊ®°ÊÄÅ‰∏é‰∏Ä‰∏™Â±ÄÈÉ®ÈîöÁÇπÂØπÈΩêÔºåÂΩìÊâÄÊúâÊ®°ÊÄÅÈÉΩÂ≠òÂú®Êó∂ÔºåËØ•Â±ÄÈÉ®ÈîöÁÇπ‰ºöÂÅèÁ¶ªÊúÄ‰ºòÈîöÁÇπÔºå‰ªéËÄåÂØºËá¥‰∏çÂèØÈÅøÂÖçÁöÑÂÅèÁßª„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜCalMRLÁî®‰∫éÂ§öÊ®°ÊÄÅË°®ÂæÅÂ≠¶‰π†Ôºå‰ª•Ê†°ÂáÜÁî±Áº∫Â§±Ê®°ÊÄÅÂºïËµ∑ÁöÑ‰∏çÂÆåÊï¥ÂØπÈΩê„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåCalMRLÂà©Áî®ÂÖàÈ™åÁü•ËØÜÂíåÊ®°ÊÄÅ‰πãÈó¥ÁöÑÂÜÖÂú®ËÅîÁ≥ªÊù•Âª∫Ê®°Áº∫Â§±Ê®°ÊÄÅÂú®Ë°®ÂæÅÂ±ÇÈù¢ÁöÑË°•ÂÖ®„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥‰ºòÂåñÂõ∞Â¢ÉÔºåÊàë‰ª¨ÈááÁî®‰∫Ü‰∏ÄÁßçÂèåÊ≠•Â≠¶‰π†ÊñπÊ≥ïÔºåÂπ∂ÂÖ∑ÊúâÂÖ±‰∫´ÊΩúÂú®ÂèòÈáèÂêéÈ™åÂàÜÂ∏ÉÁöÑÈó≠ÂºèËß£„ÄÇÊàë‰ª¨ÈÄöËøáÁêÜËÆ∫ÊåáÂØºÈ™åËØÅ‰∫ÜÂÆÉÂØπÈîöÁÇπÂÅèÁßªÁöÑÁºìËß£ÂíåÊî∂ÊïõÊÄß„ÄÇÈÄöËøáÂ∞ÜÊ†°ÂáÜÂêéÁöÑÂØπÈΩê‰∏éÁé∞ÊúâÁöÑÂÖàËøõÊñπÊ≥ïÁõ∏ÁªìÂêàÔºåÊàë‰ª¨‰∏∫Âê∏Êî∂ÂéüÊú¨Êó†Ê≥ïËé∑ÂæóÁöÑÂ≠òÂú®Áº∫Â§±Ê®°ÊÄÅÁöÑÊï∞ÊçÆÊèê‰æõ‰∫ÜÊñ∞ÁöÑÁÅµÊ¥ªÊÄß„ÄÇÂπøÊ≥õÁöÑÂÆûÈ™åÂíåÂÖ®Èù¢ÁöÑÂàÜÊûêËØÅÊòé‰∫ÜCalMRLÁöÑ‰ºòË∂äÊÄß„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†Å„ÄÅÊ®°ÂûãÊ£ÄÊü•ÁÇπÂíåËØÑ‰º∞ÂéüÂßãÊï∞ÊçÆÂ∞ÜÂÖ¨ÂºÄÊèê‰æõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅË°®ÂæÅÂ≠¶‰π†‰∏≠ÔºåÁî±‰∫éÊï∞ÊçÆÈõÜ‰∏≠ÊôÆÈÅçÂ≠òÂú®Áº∫Â§±Ê®°ÊÄÅÔºåÂØºËá¥Áé∞ÊúâÊñπÊ≥ïÊó†Ê≥ïÊúâÊïàÂà©Áî®Ëøô‰∫õÊï∞ÊçÆÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÂÅáËÆæÊâÄÊúâÊ®°ÊÄÅÈÉΩÂ≠òÂú®ÔºåËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÈÄÇÁî®ÊÄß„ÄÇÁº∫Â§±Ê®°ÊÄÅ‰ºöÂØºËá¥Â≠¶‰π†Âà∞ÁöÑË°®ÂæÅ‰∏éÂÆåÊï¥Ê®°ÊÄÅ‰∏ãÁöÑÊúÄ‰ºòË°®ÂæÅ‰∫ßÁîüÂÅèÂ∑ÆÔºåÂç≥‚ÄúÈîöÁÇπÂÅèÁßª‚Äù„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÊ†°ÂáÜ‰∏çÂÆåÊï¥ÂØπÈΩêÊù•ÁºìËß£ÈîöÁÇπÂÅèÁßª„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåCalMRLÂà©Áî®Â∑≤ÊúâÁöÑÊ®°ÊÄÅ‰ø°ÊÅØÂíåÊ®°ÊÄÅ‰πãÈó¥ÁöÑÂÜÖÂú®ËÅîÁ≥ªÔºåÂØπÁº∫Â§±ÁöÑÊ®°ÊÄÅËøõË°åË°®ÂæÅÂ±ÇÈù¢ÁöÑË°•ÂÖ®„ÄÇÈÄöËøáË°•ÂÖ®Áº∫Â§±Ê®°ÊÄÅÁöÑË°®ÂæÅÔºåÂèØ‰ª•Êõ¥ÂáÜÁ°ÆÂú∞‰º∞ËÆ°ÂÖ±‰∫´ÁöÑÊΩúÂú®Á©∫Èó¥Ôºå‰ªéËÄåÂáèÂ∞ëÈîöÁÇπÂÅèÁßª„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCalMRLÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ≠•È™§Ôºö1) Âà©Áî®Â∑≤ÊúâÁöÑÊ®°ÊÄÅÊï∞ÊçÆÂ≠¶‰π†ÂêÑ‰∏™Ê®°ÊÄÅÁöÑË°®ÂæÅÔºõ2) Âà©Áî®Ê®°ÊÄÅ‰πãÈó¥ÁöÑÂÖàÈ™åÁü•ËØÜÂíåÂÜÖÂú®ËÅîÁ≥ªÔºåÂØπÁº∫Â§±ÁöÑÊ®°ÊÄÅËøõË°åË°®ÂæÅË°•ÂÖ®Ôºõ3) Â∞ÜË°•ÂÖ®ÂêéÁöÑË°®ÂæÅ‰∏éÂ∑≤ÊúâÁöÑÊ®°ÊÄÅË°®ÂæÅËøõË°åÂØπÈΩêÔºåÂ≠¶‰π†ÂÖ±‰∫´ÁöÑÊΩúÂú®Á©∫Èó¥Ôºõ4) Âà©Áî®Â≠¶‰π†Âà∞ÁöÑÂÖ±‰∫´ÊΩúÂú®Á©∫Èó¥ËøõË°å‰∏ãÊ∏∏‰ªªÂä°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöCalMRLÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÆÉËÉΩÂ§üÊòæÂºèÂú∞Âª∫Ê®°Áº∫Â§±Ê®°ÊÄÅÁöÑË°®ÂæÅÔºåÂπ∂Âà©Áî®Ëøô‰∫õË°•ÂÖ®ÁöÑË°®ÂæÅÊù•Ê†°ÂáÜ‰∏çÂÆåÊï¥ÂØπÈΩê„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåCalMRL‰∏çÈúÄË¶ÅÊâÄÊúâÊ®°ÊÄÅÈÉΩÂ≠òÂú®ÔºåÂõ†Ê≠§ÂèØ‰ª•Êõ¥ÊúâÊïàÂú∞Âà©Áî®ÂåÖÂê´Áº∫Â§±Ê®°ÊÄÅÁöÑÊï∞ÊçÆÈõÜ„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÂèåÊ≠•Â≠¶‰π†ÊñπÊ≥ïÔºåÂπ∂Êé®ÂØºÂá∫‰∫ÜÂÖ±‰∫´ÊΩúÂú®ÂèòÈáèÂêéÈ™åÂàÜÂ∏ÉÁöÑÈó≠ÂºèËß£Ôºå‰ªéËÄåËß£ÂÜ≥‰∫Ü‰ºòÂåñÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöCalMRLÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®Ëá™ÁºñÁ†ÅÂô®Â≠¶‰π†ÂêÑ‰∏™Ê®°ÊÄÅÁöÑË°®ÂæÅÔºõ2) ‰ΩøÁî®ÂèòÂàÜÊé®Êñ≠ÂØπÁº∫Â§±Ê®°ÊÄÅËøõË°åË°®ÂæÅË°•ÂÖ®Ôºõ3) ‰ΩøÁî®ÂØπÊØîÂ≠¶‰π†ÊçüÂ§±ÂáΩÊï∞Êù•ÂØπÈΩê‰∏çÂêåÊ®°ÊÄÅÁöÑË°®ÂæÅÔºõ4) ‰ΩøÁî®ÂèåÊ≠•Â≠¶‰π†ÊñπÊ≥ïÊù•‰ºòÂåñÊ®°ÂûãÂèÇÊï∞„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÁ¨¨‰∏ÄÊ≠•Âõ∫ÂÆöÁºñÁ†ÅÂô®Ôºå‰ºòÂåñÂèòÂàÜÊé®Êñ≠Ê®°ÂûãÔºåÁ¨¨‰∫åÊ≠•Âõ∫ÂÆöÂèòÂàÜÊé®Êñ≠Ê®°ÂûãÔºå‰ºòÂåñÁºñÁ†ÅÂô®ÂíåÂØπÊØîÂ≠¶‰π†ÊçüÂ§±ÂáΩÊï∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCalMRLÂú®Â§ö‰∏™Â§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºåÂú®ÂåÖÂê´Áº∫Â§±Ê®°ÊÄÅÁöÑÂõæÂÉèÊèèËø∞ÁîüÊàê‰ªªÂä°‰∏≠ÔºåCalMRLÁõ∏ÊØî‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂú®CIDErÊåáÊ†á‰∏äÊèêÂçá‰∫ÜË∂ÖËøá5%„ÄÇÊ≠§Â§ñÔºåÂÆûÈ™åËøòÈ™åËØÅ‰∫ÜCalMRLËÉΩÂ§üÊúâÊïàÁºìËß£ÈîöÁÇπÂÅèÁßªÔºåÂπ∂ÂÖ∑ÊúâËâØÂ•ΩÁöÑÊî∂ÊïõÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

CalMRLÂèØÂ∫îÁî®‰∫éÂêÑÁßçÂ§öÊ®°ÊÄÅÂ≠¶‰π†‰ªªÂä°Ôºå‰æãÂ¶ÇÂõæÂÉèÊèèËø∞ÁîüÊàê„ÄÅËßÜÈ¢ëÁêÜËß£„ÄÅË∑®Ê®°ÊÄÅÊ£ÄÁ¥¢Á≠â„ÄÇÁâπÂà´ÊòØÂú®ÂåªÁñóËØäÊñ≠„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüüÔºåÊï∞ÊçÆÈõÜ‰∏≠ÁªèÂ∏∏Â≠òÂú®Áº∫Â§±Ê®°ÊÄÅÁöÑÊÉÖÂÜµÔºåCalMRLËÉΩÂ§üÊúâÊïàÂà©Áî®Ëøô‰∫õÊï∞ÊçÆÔºåÊèêÈ´òÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÈ≤ÅÊ£íÊÄß„ÄÇËØ•Á†îÁ©∂‰∏∫Â§ÑÁêÜÁº∫Â§±Ê®°ÊÄÅÈóÆÈ¢òÊèê‰æõ‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊÄùË∑ØÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊΩúÂú®ÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal representation learning harmonizes distinct modalities by aligning them into a unified latent space. Recent research generalizes traditional cross-modal alignment to produce enhanced multimodal synergy but requires all modalities to be present for a common instance, making it challenging to utilize prevalent datasets with missing modalities. We provide theoretical insights into this issue from an anchor shift perspective. Observed modalities are aligned with a local anchor that deviates from the optimal one when all modalities are present, resulting in an inevitable shift. To address this, we propose CalMRL for multimodal representation learning to calibrate incomplete alignments caused by missing modalities. Specifically, CalMRL leverages the priors and the inherent connections among modalities to model the imputation for the missing ones at the representation level. To resolve the optimization dilemma, we employ a bi-step learning method with the closed-form solution of the posterior distribution of shared latents. We validate its mitigation of anchor shift and convergence with theoretical guidance. By equipping the calibrated alignment with the existing advanced method, we offer new flexibility to absorb data with missing modalities, which is originally unattainable. Extensive experiments and comprehensive analyses demonstrate the superiority of CalMRL. Our code, model checkpoints, and evaluation raw data will be publicly available.

