---
layout: default
title: MovSemCL: Movement-Semantics Contrastive Learning for Trajectory Similarity
---

# MovSemCL: Movement-Semantics Contrastive Learning for Trajectory Similarity

**arXiv**: [2511.12061v1](https://arxiv.org/abs/2511.12061) | [PDF](https://arxiv.org/pdf/2511.12061.pdf)

**ä½œè€…**: Zhichen Lai, Hua Lu, Huan Li, Jialiang Li, Christian S. Jensen

**åˆ†ç±»**: cs.CV, cs.AI, cs.DB

**å‘å¸ƒæ—¥æœŸ**: 2025-11-15

**å¤‡æ³¨**: 8 pages, 6 figures; accepted by AAAI 2026 as an Oral paper

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMovSemCLæ¡†æž¶ï¼Œé€šè¿‡è¿åŠ¨è¯­ä¹‰å¯¹æ¯”å­¦ä¹ æå‡è½¨è¿¹ç›¸ä¼¼åº¦è®¡ç®—æ€§èƒ½ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è½¨è¿¹ç›¸ä¼¼åº¦` `å¯¹æ¯”å­¦ä¹ ` `è¿åŠ¨è¯­ä¹‰` `æ³¨æ„åŠ›æœºåˆ¶` `æ•°æ®å¢žå¼º` `è½¨è¿¹èšç±»` `å¼‚å¸¸æ£€æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è½¨è¿¹ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•åœ¨è½¨è¿¹è¯­ä¹‰å»ºæ¨¡ã€è®¡ç®—æ•ˆçŽ‡å’Œæ•°æ®å¢žå¼ºç­–ç•¥ä¸Šå­˜åœ¨ä¸è¶³ã€‚
2. MovSemCLé€šè¿‡è¿åŠ¨è¯­ä¹‰ç‰¹å¾æå–ã€åˆ†å±‚æ³¨æ„åŠ›ç¼–ç å’Œæ›²çŽ‡å¼•å¯¼å¢žå¼ºæ¥æå‡è½¨è¿¹ç›¸ä¼¼åº¦è®¡ç®—ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒMovSemCLåœ¨ç›¸ä¼¼åº¦æœç´¢å’Œå¯å‘å¼è¿‘ä¼¼ä»»åŠ¡ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶é™ä½Žäº†æŽ¨ç†å»¶è¿Ÿã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è½¨è¿¹ç›¸ä¼¼åº¦è®¡ç®—æ˜¯èšç±»ã€é¢„æµ‹å’Œå¼‚å¸¸æ£€æµ‹ç­‰ä»»åŠ¡çš„åŸºç¡€ã€‚ç„¶è€Œï¼ŒçŽ°æœ‰çš„åŸºäºŽå­¦ä¹ çš„æ–¹æ³•å­˜åœ¨ä¸‰ä¸ªä¸»è¦é™åˆ¶ï¼š(1) è½¨è¿¹è¯­ä¹‰å’Œå±‚æ¬¡ç»“æž„å»ºæ¨¡ä¸è¶³ï¼Œç¼ºä¹è¿åŠ¨åŠ¨æ€æå–å’Œå¤šå°ºåº¦ç»“æž„è¡¨ç¤ºï¼›(2) ç”±äºŽé€ç‚¹ç¼–ç å¯¼è‡´è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼›(3) ä½¿ç”¨ç‰©ç†ä¸Šä¸åˆç†çš„å¢žå¼ºæ–¹å¼ï¼Œæ‰­æ›²äº†è½¨è¿¹è¯­ä¹‰ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†MovSemCLï¼Œä¸€ä¸ªç”¨äºŽè½¨è¿¹ç›¸ä¼¼åº¦è®¡ç®—çš„è¿åŠ¨è¯­ä¹‰å¯¹æ¯”å­¦ä¹ æ¡†æž¶ã€‚MovSemCLé¦–å…ˆå°†åŽŸå§‹GPSè½¨è¿¹è½¬æ¢ä¸ºè¿åŠ¨è¯­ä¹‰ç‰¹å¾ï¼Œç„¶åŽå°†å…¶åˆ†å‰²æˆpatchesã€‚æŽ¥ä¸‹æ¥ï¼ŒMovSemCLé‡‡ç”¨patchå†…å’Œpatché—´çš„æ³¨æ„åŠ›æœºåˆ¶æ¥ç¼–ç å±€éƒ¨å’Œå…¨å±€è½¨è¿¹æ¨¡å¼ï¼Œä»Žè€Œå®žçŽ°é«˜æ•ˆçš„åˆ†å±‚è¡¨ç¤ºå¹¶é™ä½Žè®¡ç®—æˆæœ¬ã€‚æ­¤å¤–ï¼ŒMovSemCLåŒ…å«ä¸€ç§æ›²çŽ‡å¼•å¯¼çš„å¢žå¼ºç­–ç•¥ï¼Œè¯¥ç­–ç•¥ä¿ç•™ä¿¡æ¯ä¸°å¯Œçš„ç‰‡æ®µï¼ˆä¾‹å¦‚ï¼Œè½¬å¼¯å’Œäº¤å‰å£ï¼‰å¹¶å±è”½å†—ä½™ç‰‡æ®µï¼Œä»Žè€Œç”Ÿæˆç‰©ç†ä¸Šåˆç†çš„å¢žå¼ºè§†å›¾ã€‚åœ¨çœŸå®žä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼ŒMovSemCLèƒ½å¤Ÿä¼˜äºŽæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨ç›¸ä¼¼åº¦æœç´¢ä»»åŠ¡ä¸­å®žçŽ°æŽ¥è¿‘ç†æƒ³å€¼1çš„å¹³å‡æŽ’åï¼Œå¹¶åœ¨å¯å‘å¼è¿‘ä¼¼æ–¹é¢æé«˜é«˜è¾¾20.3%ï¼ŒåŒæ—¶å°†æŽ¨ç†å»¶è¿Ÿé™ä½Žé«˜è¾¾43.4%ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰åŸºäºŽå­¦ä¹ çš„è½¨è¿¹ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•ï¼Œæ— æ³•å……åˆ†å»ºæ¨¡è½¨è¿¹çš„è¿åŠ¨è¯­ä¹‰å’Œå±‚æ¬¡ç»“æž„ï¼Œå¯¼è‡´ç›¸ä¼¼åº¦è®¡ç®—ç²¾åº¦ä¸é«˜ã€‚åŒæ—¶ï¼Œé€ç‚¹ç¼–ç æ–¹å¼è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œä¸”æ•°æ®å¢žå¼ºæ–¹æ³•ä¸åˆç†ï¼Œä¼šæ‰­æ›²è½¨è¿¹çš„çœŸå®žè¯­ä¹‰ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿæœ‰æ•ˆæå–è½¨è¿¹è¯­ä¹‰ã€é™ä½Žè®¡ç®—æˆæœ¬å¹¶è¿›è¡Œåˆç†æ•°æ®å¢žå¼ºçš„è½¨è¿¹ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMovSemCLçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è¿åŠ¨è¯­ä¹‰ç‰¹å¾æå–ï¼Œå°†åŽŸå§‹GPSè½¨è¿¹è½¬æ¢ä¸ºæ›´å…·è¡¨è¾¾åŠ›çš„ç‰¹å¾è¡¨ç¤ºã€‚ç„¶åŽï¼Œåˆ©ç”¨åˆ†å±‚æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¯¹è½¨è¿¹çš„å±€éƒ¨å’Œå…¨å±€æ¨¡å¼è¿›è¡Œç¼–ç ï¼Œä»Žè€Œå®žçŽ°é«˜æ•ˆçš„å±‚æ¬¡åŒ–è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œé‡‡ç”¨æ›²çŽ‡å¼•å¯¼çš„æ•°æ®å¢žå¼ºç­–ç•¥ï¼Œä¿ç•™è½¨è¿¹ä¸­çš„å…³é”®ä¿¡æ¯ï¼Œå¹¶å±è”½å†—ä½™ä¿¡æ¯ï¼Œç”Ÿæˆç‰©ç†ä¸Šåˆç†çš„å¢žå¼ºè§†å›¾ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šMovSemCLæ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) è¿åŠ¨è¯­ä¹‰ç‰¹å¾æå–ï¼šå°†åŽŸå§‹GPSè½¨è¿¹è½¬æ¢ä¸ºè¿åŠ¨è¯­ä¹‰ç‰¹å¾ã€‚2) è½¨è¿¹åˆ†å—ï¼šå°†è½¨è¿¹åˆ†å‰²æˆpatchesã€‚3) åˆ†å±‚æ³¨æ„åŠ›ç¼–ç ï¼šåˆ©ç”¨patchå†…å’Œpatché—´çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¯¹å±€éƒ¨å’Œå…¨å±€è½¨è¿¹æ¨¡å¼è¿›è¡Œç¼–ç ã€‚4) æ›²çŽ‡å¼•å¯¼æ•°æ®å¢žå¼ºï¼šæ ¹æ®è½¨è¿¹çš„æ›²çŽ‡ï¼Œä¿ç•™ä¿¡æ¯ä¸°å¯Œçš„ç‰‡æ®µï¼Œå¹¶å±è”½å†—ä½™ç‰‡æ®µã€‚5) å¯¹æ¯”å­¦ä¹ ï¼šé€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œå­¦ä¹ è½¨è¿¹çš„ç›¸ä¼¼åº¦è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šMovSemCLçš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) æå‡ºäº†è¿åŠ¨è¯­ä¹‰ç‰¹å¾ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°è¡¨è¾¾è½¨è¿¹çš„è¿åŠ¨ä¿¡æ¯ã€‚2) é‡‡ç”¨äº†åˆ†å±‚æ³¨æ„åŠ›æœºåˆ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°ç¼–ç è½¨è¿¹çš„å±€éƒ¨å’Œå…¨å±€æ¨¡å¼ã€‚3) è®¾è®¡äº†æ›²çŽ‡å¼•å¯¼çš„æ•°æ®å¢žå¼ºç­–ç•¥ï¼Œèƒ½å¤Ÿç”Ÿæˆç‰©ç†ä¸Šåˆç†çš„å¢žå¼ºè§†å›¾ã€‚

**å…³é”®è®¾è®¡**ï¼šMovSemCLçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) è¿åŠ¨è¯­ä¹‰ç‰¹å¾çš„å…·ä½“è®¡ç®—æ–¹æ³•ï¼Œä¾‹å¦‚é€Ÿåº¦ã€åŠ é€Ÿåº¦ã€æ–¹å‘ç­‰ã€‚2) patchçš„å¤§å°å’Œæ•°é‡ã€‚3) æ³¨æ„åŠ›æœºåˆ¶çš„å…·ä½“å®žçŽ°æ–¹å¼ï¼Œä¾‹å¦‚Transformerã€‚4) æ›²çŽ‡çš„è®¡ç®—æ–¹æ³•å’Œé˜ˆå€¼è®¾å®šã€‚5) å¯¹æ¯”å­¦ä¹ çš„æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚InfoNCEã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒMovSemCLåœ¨çœŸå®žä¸–ç•Œæ•°æ®é›†ä¸Šä¼˜äºŽæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨ç›¸ä¼¼åº¦æœç´¢ä»»åŠ¡ä¸­å®žçŽ°äº†æŽ¥è¿‘ç†æƒ³å€¼1çš„å¹³å‡æŽ’åï¼Œå¹¶åœ¨å¯å‘å¼è¿‘ä¼¼æ–¹é¢æé«˜äº†é«˜è¾¾20.3%ï¼ŒåŒæ—¶å°†æŽ¨ç†å»¶è¿Ÿé™ä½Žäº†é«˜è¾¾43.4%ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒMovSemCLèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜è½¨è¿¹ç›¸ä¼¼åº¦è®¡ç®—çš„ç²¾åº¦å’Œæ•ˆçŽ‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

MovSemCLå¯åº”ç”¨äºŽè½¨è¿¹èšç±»ã€è½¨è¿¹é¢„æµ‹ã€å¼‚å¸¸è½¨è¿¹æ£€æµ‹ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨äº¤é€šç®¡ç†ä¸­ï¼Œå¯ä»¥åˆ©ç”¨MovSemCLå¯¹è½¦è¾†è½¨è¿¹è¿›è¡Œèšç±»ï¼Œä»Žè€Œåˆ†æžäº¤é€šæ¨¡å¼ï¼›åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥åˆ©ç”¨MovSemCLé¢„æµ‹è½¦è¾†çš„æœªæ¥è½¨è¿¹ï¼Œä»Žè€Œæé«˜é©¾é©¶å®‰å…¨æ€§ï¼›åœ¨é‡‘èžé£ŽæŽ§ä¸­ï¼Œå¯ä»¥åˆ©ç”¨MovSemCLæ£€æµ‹å¼‚å¸¸äº¤æ˜“è½¨è¿¹ï¼Œä»Žè€Œé˜²æ­¢æ¬ºè¯ˆè¡Œä¸ºã€‚è¯¥ç ”ç©¶å…·æœ‰é‡è¦çš„å®žé™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Trajectory similarity computation is fundamental functionality that is used for, e.g., clustering, prediction, and anomaly detection. However, existing learning-based methods exhibit three key limitations: (1) insufficient modeling of trajectory semantics and hierarchy, lacking both movement dynamics extraction and multi-scale structural representation; (2) high computational costs due to point-wise encoding; and (3) use of physically implausible augmentations that distort trajectory semantics. To address these issues, we propose MovSemCL, a movement-semantics contrastive learning framework for trajectory similarity computation. MovSemCL first transforms raw GPS trajectories into movement-semantics features and then segments them into patches. Next, MovSemCL employs intra- and inter-patch attentions to encode local as well as global trajectory patterns, enabling efficient hierarchical representation and reducing computational costs. Moreover, MovSemCL includes a curvature-guided augmentation strategy that preserves informative segments (e.g., turns and intersections) and masks redundant ones, generating physically plausible augmented views. Experiments on real-world datasets show that MovSemCL is capable of outperforming state-of-the-art methods, achieving mean ranks close to the ideal value of 1 at similarity search tasks and improvements by up to 20.3% at heuristic approximation, while reducing inference latency by up to 43.4%.

