---
layout: default
title: AttackVLA: Benchmarking Adversarial and Backdoor Attacks on Vision-Language-Action Models
---

# AttackVLA: Benchmarking Adversarial and Backdoor Attacks on Vision-Language-Action Models

**arXiv**: [2511.12149v1](https://arxiv.org/abs/2511.12149) | [PDF](https://arxiv.org/pdf/2511.12149.pdf)

**ä½œè€…**: Jiayu Li, Yunhan Zhao, Xiang Zheng, Zonghuan Xu, Yige Li, Xingjun Ma, Yu-Gang Jiang

**åˆ†ç±»**: cs.CR, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-15

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**AttackVLAæå‡ºç»Ÿä¸€æ¡†æž¶ï¼Œè¯„ä¼°å¹¶æå‡è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹çš„å¯¹æŠ—é²æ£’æ€§ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `å¯¹æŠ—æ”»å‡»` `åŽé—¨æ”»å‡»` `æœºå™¨äººå®‰å…¨` `å…·èº«æ™ºèƒ½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VLAæ¨¡åž‹æ”»å‡»æ–¹æ³•ç¼ºä¹ç»Ÿä¸€è¯„ä¼°æ¡†æž¶ï¼Œä¸”çœŸå®žåœºæ™¯éªŒè¯ä¸è¶³ï¼Œå¯¼è‡´æ”»å‡»æ•ˆæžœä¸æ˜Žç¡®ã€‚
2. AttackVLAæ¡†æž¶ç»Ÿä¸€æ•°æ®æž„å»ºã€æ¨¡åž‹è®­ç»ƒå’ŒæŽ¨ç†æµç¨‹ï¼Œå¹¶æå‡ºBackdoorVLAå®žçŽ°ç²¾å‡†é•¿ç¨‹åŠ¨ä½œåºåˆ—æ”»å‡»ã€‚
3. BackdoorVLAåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žæœºå™¨äººçŽ¯å¢ƒä¸­å–å¾—äº†å¹³å‡58.4%çš„ç›®æ ‡æ”»å‡»æˆåŠŸçŽ‡ï¼Œéƒ¨åˆ†ä»»åŠ¡è¾¾åˆ°100%ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹ä½¿æœºå™¨äººèƒ½å¤Ÿç†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤å¹¶æ‰§è¡Œå„ç§ä»»åŠ¡ï¼Œä½†å…¶æ„ŸçŸ¥ã€è¯­è¨€å’ŒæŽ§åˆ¶çš„é›†æˆå¼•å…¥äº†æ–°çš„å®‰å…¨æ¼æ´žã€‚å°½ç®¡äººä»¬å¯¹æ”»å‡»æ­¤ç±»æ¨¡åž‹çš„å…´è¶£æ—¥ç›Šæµ“åŽšï¼Œä½†ç”±äºŽç¼ºä¹ç»Ÿä¸€çš„è¯„ä¼°æ¡†æž¶ï¼ŒçŽ°æœ‰æŠ€æœ¯çš„æœ‰æ•ˆæ€§ä»ä¸æ¸…æ¥šã€‚ä¸€ä¸ªä¸»è¦é—®é¢˜æ˜¯ï¼ŒVLAæž¶æž„ä¹‹é—´åŠ¨ä½œæ ‡è®°å™¨çš„å·®å¼‚é˜»ç¢äº†å¯é‡å¤æ€§å’Œå…¬å¹³æ¯”è¾ƒã€‚æ›´é‡è¦çš„æ˜¯ï¼Œå¤§å¤šæ•°çŽ°æœ‰æ”»å‡»å°šæœªåœ¨çœŸå®žåœºæ™¯ä¸­å¾—åˆ°éªŒè¯ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†AttackVLAï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ŽVLAå¼€å‘ç”Ÿå‘½å‘¨æœŸä¿æŒä¸€è‡´çš„ç»Ÿä¸€æ¡†æž¶ï¼Œæ¶µç›–æ•°æ®æž„å»ºã€æ¨¡åž‹è®­ç»ƒå’ŒæŽ¨ç†ã€‚åœ¨è¯¥æ¡†æž¶å†…ï¼Œæˆ‘ä»¬å®žæ–½äº†ä¸€å¥—å¹¿æ³›çš„æ”»å‡»ï¼ŒåŒ…æ‹¬æ‰€æœ‰çŽ°æœ‰çš„é’ˆå¯¹VLAçš„æ”»å‡»å’Œå¤šä¸ªæœ€åˆä¸ºè§†è§‰-è¯­è¨€æ¨¡åž‹å¼€å‘çš„æ”¹ç¼–æ”»å‡»ï¼Œå¹¶åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žçŽ¯å¢ƒä¸­å¯¹å…¶è¿›è¡Œè¯„ä¼°ã€‚æˆ‘ä»¬å¯¹çŽ°æœ‰æ”»å‡»çš„åˆ†æžæ­ç¤ºäº†ä¸€ä¸ªå…³é”®å·®è·ï¼šå½“å‰çš„æ–¹æ³•å€¾å‘äºŽå¯¼è‡´æ— ç›®æ ‡å¤±è´¥æˆ–é™æ€åŠ¨ä½œçŠ¶æ€ï¼Œä½¿å¾—é©±åŠ¨VLAæ‰§è¡Œç²¾ç¡®çš„é•¿ç¨‹åŠ¨ä½œåºåˆ—çš„æœ‰ç›®æ ‡æ”»å‡»åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæœªè¢«æŽ¢ç´¢ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†BackdoorVLAï¼Œè¿™æ˜¯ä¸€ç§æœ‰ç›®æ ‡çš„åŽé—¨æ”»å‡»ï¼Œå®ƒè¿«ä½¿VLAåœ¨å‡ºçŽ°è§¦å‘å™¨æ—¶æ‰§è¡Œæ”»å‡»è€…æŒ‡å®šçš„é•¿ç¨‹åŠ¨ä½œåºåˆ—ã€‚æˆ‘ä»¬åœ¨æ¨¡æ‹ŸåŸºå‡†å’ŒçœŸå®žæœºå™¨äººçŽ¯å¢ƒä¸­è¯„ä¼°äº†BackdoorVLAï¼Œå¹³å‡ç›®æ ‡æˆåŠŸçŽ‡ä¸º58.4%ï¼Œåœ¨é€‰å®šçš„ä»»åŠ¡ä¸­è¾¾åˆ°100%ã€‚æˆ‘ä»¬çš„å·¥ä½œæä¾›äº†ä¸€ä¸ªç”¨äºŽè¯„ä¼°VLAæ¼æ´žçš„æ ‡å‡†æ¡†æž¶ï¼Œå¹¶å±•ç¤ºäº†ç²¾ç¡®å¯¹æŠ—æ“çºµçš„æ½œåŠ›ï¼Œä»Žè€ŒæŽ¨åŠ¨äº†å¯¹ä¿æŠ¤åŸºäºŽVLAçš„å…·èº«ç³»ç»Ÿçš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹çš„å®‰å…¨æ€§è¯„ä¼°ç¼ºä¹ç»Ÿä¸€çš„æ ‡å‡†å’Œæ¡†æž¶ï¼Œå¯¼è‡´ä¸åŒæ”»å‡»æ–¹æ³•éš¾ä»¥æ¯”è¾ƒã€‚æ­¤å¤–ï¼ŒçŽ°æœ‰æ”»å‡»æ–¹æ³•ä¸»è¦é›†ä¸­äºŽæ— ç›®æ ‡æ”»å‡»æˆ–è¯±å¯¼é™æ€åŠ¨ä½œï¼Œæ— æ³•å®žçŽ°ç²¾ç¡®æŽ§åˆ¶VLAæ‰§è¡Œç‰¹å®šé•¿ç¨‹åŠ¨ä½œåºåˆ—çš„æœ‰ç›®æ ‡æ”»å‡»ã€‚çœŸå®žåœºæ™¯çš„éªŒè¯ä¹Ÿç›¸å¯¹ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAttackVLAçš„æ ¸å¿ƒæ€è·¯æ˜¯æž„å»ºä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ¡†æž¶ï¼Œæ¶µç›–VLAå¼€å‘çš„æ•´ä¸ªç”Ÿå‘½å‘¨æœŸï¼ŒåŒ…æ‹¬æ•°æ®æž„å»ºã€æ¨¡åž‹è®­ç»ƒå’ŒæŽ¨ç†ã€‚é€šè¿‡åœ¨è¯¥æ¡†æž¶ä¸‹å®žçŽ°å’Œè¯„ä¼°å„ç§æ”»å‡»æ–¹æ³•ï¼Œå¯ä»¥æ›´å…¨é¢åœ°äº†è§£VLAæ¨¡åž‹çš„è„†å¼±æ€§ã€‚é’ˆå¯¹æœ‰ç›®æ ‡æ”»å‡»çš„ä¸è¶³ï¼Œæå‡ºäº†BackdoorVLAï¼Œé€šè¿‡åŽé—¨è§¦å‘æœºåˆ¶ï¼Œå®žçŽ°å¯¹VLAè¡Œä¸ºçš„ç²¾ç¡®æŽ§åˆ¶ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šAttackVLAæ¡†æž¶åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šæ•°æ®æž„å»ºé˜¶æ®µï¼Œç”¨äºŽç”ŸæˆåŒ…å«å¯¹æŠ—æ ·æœ¬å’ŒåŽé—¨è§¦å‘æ ·æœ¬çš„æ•°æ®é›†ï¼›æ¨¡åž‹è®­ç»ƒé˜¶æ®µï¼Œç”¨äºŽè®­ç»ƒæˆ–å¾®è°ƒVLAæ¨¡åž‹ï¼›æŽ¨ç†é˜¶æ®µï¼Œç”¨äºŽè¯„ä¼°å„ç§æ”»å‡»æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žçŽ¯å¢ƒä¸­çš„æ•ˆæžœã€‚BackdoorVLAä½œä¸ºæ¡†æž¶å†…çš„ä¸€ç§æ”»å‡»æ–¹æ³•ï¼Œé€šè¿‡åœ¨è®­ç»ƒæ•°æ®ä¸­æ’å…¥å¸¦æœ‰ç‰¹å®šè§¦å‘å™¨çš„æ ·æœ¬ï¼Œä½¿æ¨¡åž‹åœ¨æ£€æµ‹åˆ°è§¦å‘å™¨æ—¶æ‰§è¡Œé¢„å®šä¹‰çš„åŠ¨ä½œåºåˆ—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽBackdoorVLAï¼Œå®ƒæ˜¯ä¸€ç§æœ‰ç›®æ ‡çš„åŽé—¨æ”»å‡»ï¼Œèƒ½å¤Ÿç²¾ç¡®æŽ§åˆ¶VLAæ‰§è¡Œæ”»å‡»è€…æŒ‡å®šçš„é•¿ç¨‹åŠ¨ä½œåºåˆ—ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æ— ç›®æ ‡æ”»å‡»æˆ–é™æ€åŠ¨ä½œè¯±å¯¼ä¸åŒï¼ŒBackdoorVLAå®žçŽ°äº†å¯¹VLAè¡Œä¸ºçš„ç²¾ç»†åŒ–æ“çºµï¼Œä»Žè€Œæ­ç¤ºäº†VLAæ¨¡åž‹æ›´æ·±å±‚æ¬¡çš„å®‰å…¨é£Žé™©ã€‚

**å…³é”®è®¾è®¡**ï¼šBackdoorVLAçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é€‰æ‹©åˆé€‚çš„è§¦å‘å™¨ï¼Œä½¿å…¶åœ¨çœŸå®žçŽ¯å¢ƒä¸­ä¸æ˜“è¢«å¯Ÿè§‰ï¼›2) è®¾è®¡æœ‰æ•ˆçš„åŽé—¨è®­ç»ƒç­–ç•¥ï¼Œç¡®ä¿æ¨¡åž‹åœ¨æ£€æµ‹åˆ°è§¦å‘å™¨æ—¶èƒ½å¤Ÿå‡†ç¡®æ‰§è¡Œç›®æ ‡åŠ¨ä½œåºåˆ—ï¼›3) é’ˆå¯¹ä¸åŒçš„VLAæž¶æž„ï¼Œè°ƒæ•´åŽé—¨æ³¨å…¥æ–¹å¼ï¼Œä»¥ä¿è¯æ”»å‡»çš„æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦å¹³è¡¡æ­£å¸¸ä»»åŠ¡çš„æ€§èƒ½å’ŒåŽé—¨æ”»å‡»çš„æˆåŠŸçŽ‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

AttackVLAæ¡†æž¶æˆåŠŸå®žçŽ°äº†å¯¹VLAæ¨¡åž‹çš„å¤šç§æ”»å‡»ï¼Œå¹¶æ­ç¤ºäº†çŽ°æœ‰æ”»å‡»æ–¹æ³•çš„å±€é™æ€§ã€‚BackdoorVLAåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žæœºå™¨äººçŽ¯å¢ƒä¸­å–å¾—äº†æ˜¾è‘—çš„æ”»å‡»æ•ˆæžœï¼Œå¹³å‡ç›®æ ‡æˆåŠŸçŽ‡ä¸º58.4%ï¼Œåœ¨ç‰¹å®šä»»åŠ¡ä¸­ç”šè‡³è¾¾åˆ°äº†100%ã€‚è¿™äº›å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒVLAæ¨¡åž‹é¢ä¸´ç€ä¸¥é‡çš„å®‰å…¨å¨èƒï¼Œéœ€è¦è¿›ä¸€æ­¥ç ”ç©¶å’Œå¼€å‘æœ‰æ•ˆçš„é˜²å¾¡æ–¹æ³•ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽè¯„ä¼°å’Œæå‡å„ç§åŸºäºŽVLAçš„å…·èº«æ™ºèƒ½ç³»ç»Ÿçš„å®‰å…¨æ€§ï¼Œä¾‹å¦‚æœåŠ¡æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶æ±½è½¦å’Œæ™ºèƒ½å®¶å±…è®¾å¤‡ã€‚é€šè¿‡AttackVLAæ¡†æž¶ï¼Œå¯ä»¥ç³»ç»Ÿåœ°è¯†åˆ«VLAæ¨¡åž‹çš„æ½œåœ¨æ¼æ´žï¼Œå¹¶å¼€å‘ç›¸åº”çš„é˜²å¾¡æœºåˆ¶ï¼Œä»Žè€Œæé«˜è¿™äº›ç³»ç»Ÿåœ¨çœŸå®žä¸–ç•Œä¸­çš„å¯é æ€§å’Œå®‰å…¨æ€§ï¼Œé¿å…æ¶æ„æ”»å‡»é€ æˆçš„æ½œåœ¨å±å®³ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models enable robots to interpret natural-language instructions and perform diverse tasks, yet their integration of perception, language, and control introduces new safety vulnerabilities. Despite growing interest in attacking such models, the effectiveness of existing techniques remains unclear due to the absence of a unified evaluation framework. One major issue is that differences in action tokenizers across VLA architectures hinder reproducibility and fair comparison. More importantly, most existing attacks have not been validated in real-world scenarios. To address these challenges, we propose AttackVLA, a unified framework that aligns with the VLA development lifecycle, covering data construction, model training, and inference. Within this framework, we implement a broad suite of attacks, including all existing attacks targeting VLAs and multiple adapted attacks originally developed for vision-language models, and evaluate them in both simulation and real-world settings. Our analysis of existing attacks reveals a critical gap: current methods tend to induce untargeted failures or static action states, leaving targeted attacks that drive VLAs to perform precise long-horizon action sequences largely unexplored. To fill this gap, we introduce BackdoorVLA, a targeted backdoor attack that compels a VLA to execute an attacker-specified long-horizon action sequence whenever a trigger is present. We evaluate BackdoorVLA in both simulated benchmarks and real-world robotic settings, achieving an average targeted success rate of 58.4% and reaching 100% on selected tasks. Our work provides a standardized framework for evaluating VLA vulnerabilities and demonstrates the potential for precise adversarial manipulation, motivating further research on securing VLA-based embodied systems.

