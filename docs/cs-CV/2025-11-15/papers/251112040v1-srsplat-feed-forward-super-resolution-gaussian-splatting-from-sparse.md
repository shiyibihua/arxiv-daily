---
layout: default
title: SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images
---

# SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.12040" target="_blank" class="toolbar-btn">arXiv: 2511.12040v1</a>
    <a href="https://arxiv.org/pdf/2511.12040.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.12040v1" 
            onclick="toggleFavorite(this, '2511.12040v1', 'SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xinyuan Hu, Changyue Shi, Chuxiao Yang, Minghao Chen, Jiajun Ding, Tao Wei, Chen Wei, Zhou Yu, Min Tan

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-15

**Â§áÊ≥®**: AAAI2026-Oral. Project Page: https://xinyuanhu66.github.io/SRSplat/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**SRSplatÔºöÂü∫‰∫éÁ®ÄÁñèÂ§öËßÜËßíÂõæÂÉèÁöÑÂâçÈ¶àË∂ÖÂàÜËæ®ÁéáÈ´òÊñØÊ∫ÖÂ∞ÑÈáçÂª∫**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `È´òÊñØÊ∫ÖÂ∞Ñ` `Ë∂ÖÂàÜËæ®Áéá` `‰∏âÁª¥ÈáçÂª∫` `Â§öËßÜËßíÂõæÂÉè` `ÁâπÂæÅËûçÂêà`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÈöæ‰ª•‰ªéÁ®ÄÁñè‰ΩéÂàÜËæ®ÁéáÂõæÂÉè‰∏≠ÈáçÂª∫Á≤æÁªÜÁ∫πÁêÜÔºå‰∏ªË¶ÅÂéüÂõ†ÊòØÁº∫‰πèÈ´òÈ¢ë‰ø°ÊÅØ„ÄÇ
2. SRSplatÈÄöËøáÂú∫ÊôØÁâπÂÆöÁöÑÂèÇËÄÉÂõæÂ∫ìÂíåÂèÇËÄÉÂºïÂØºÁöÑÁâπÂæÅÂ¢ûÂº∫Ê®°ÂùóÔºåÊúâÊïàËûçÂêàÂ§ñÈÉ®È´òË¥®ÈáèÂèÇËÄÉÂõæÂÉèÁöÑ‰ø°ÊÅØ„ÄÇ
3. Á∫πÁêÜÊÑüÁü•ÂØÜÂ∫¶ÊéßÂà∂Ê®°ÂùóÊ†πÊçÆËæìÂÖ•ÂõæÂÉèÁöÑÁ∫πÁêÜ‰∏∞ÂØåÂ∫¶Ëá™ÈÄÇÂ∫îË∞ÉÊï¥È´òÊñØÂØÜÂ∫¶ÔºåËøõ‰∏ÄÊ≠•ÊèêÂçáÈáçÂª∫Ë¥®Èáè„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫SRSplatÔºå‰∏Ä‰∏™ÂâçÈ¶àÊ°ÜÊû∂ÔºåÊó®Âú®‰ªÖ‰ªéÂ∞ëÈáè‰ΩéÂàÜËæ®ÁéáÔºàLRÔºâÂõæÂÉè‰∏≠ÈáçÂª∫È´òÂàÜËæ®Áéá3DÂú∫ÊôØ„ÄÇËØ•ÊñπÊ≥ïÈÄöËøáËÅîÂêàÂà©Áî®Â§ñÈÉ®È´òË¥®ÈáèÂèÇËÄÉÂõæÂÉèÂíåÂÜÖÈÉ®Á∫πÁêÜÁ∫øÁ¥¢Êù•Âº•Ë°•Á∫πÁêÜ‰ø°ÊÅØÁöÑ‰∏çË∂≥„ÄÇÈ¶ñÂÖàÔºåÂà©Áî®Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÂíåÊâ©Êï£Ê®°Âûã‰∏∫ÊØè‰∏™Âú∫ÊôØÊûÑÂª∫ÁâπÂÆöÁöÑÂèÇËÄÉÂõæÂ∫ì„ÄÇ‰∏∫‰∫ÜÊï¥ÂêàÂ§ñÈÉ®‰ø°ÊÅØÔºåÂºïÂÖ•‰∫ÜÂèÇËÄÉÂºïÂØºÁöÑÁâπÂæÅÂ¢ûÂº∫ÔºàRGFEÔºâÊ®°ÂùóÔºåËØ•Ê®°ÂùóÂØπÈΩêÂπ∂ËûçÂêàÊù•Ëá™LRËæìÂÖ•ÂõæÂÉèÂèäÂÖ∂ÂèÇËÄÉÂ≠™ÁîüÂõæÂÉèÁöÑÁâπÂæÅ„ÄÇÈöèÂêéÔºåËÆ≠ÁªÉËß£Á†ÅÂô®‰ª•È¢ÑÊµãÈ´òÊñØÂü∫ÂÖÉ„ÄÇ‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•ÁªÜÂåñÈ¢ÑÊµãÁöÑÈ´òÊñØÂü∫ÂÖÉÔºåÂºïÂÖ•‰∫ÜÁ∫πÁêÜÊÑüÁü•ÂØÜÂ∫¶ÊéßÂà∂ÔºàTADCÔºâÔºåÂÖ∂Âü∫‰∫éLRËæìÂÖ•ÁöÑÂÜÖÈÉ®Á∫πÁêÜ‰∏∞ÂØåÂ∫¶Ëá™ÈÄÇÂ∫îÂú∞Ë∞ÉÊï¥È´òÊñØÂØÜÂ∫¶„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåSRSplatÂú®RealEstate10K„ÄÅACIDÂíåDTUÁ≠âÂêÑÁßçÊï∞ÊçÆÈõÜ‰∏ä‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂Ë°®Áé∞Âá∫Âº∫Â§ßÁöÑË∑®Êï∞ÊçÆÈõÜÂíåË∑®ÂàÜËæ®ÁéáÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊñπÊ≥ïÂú®‰ªéÁ®ÄÁñè„ÄÅ‰ΩéÂàÜËæ®ÁéáÂõæÂÉèËøõË°å3DÈáçÂª∫Êó∂ÔºåÈöæ‰ª•ÊÅ¢Â§çÁ≤æÁªÜÁöÑÁ∫πÁêÜÁªÜËäÇ„ÄÇËøôÊòØÂõ†‰∏∫‰ΩéÂàÜËæ®ÁéáËæìÂÖ•Êú¨Ë∫´Â∞±Áº∫‰πèÈ´òÈ¢ë‰ø°ÊÅØÔºåÂØºËá¥ÈáçÂª∫ÁªìÊûúÊ®°Á≥äÔºåÁªÜËäÇ‰∏¢Â§±„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞‰ªéÊúâÈôêÁöÑ‰ΩéÂàÜËæ®ÁéáÂõæÂÉè‰∏≠ÊÅ¢Â§çÈ´òÂàÜËæ®ÁéáÁöÑ3DÂú∫ÊôØÔºåÊòØÊú¨ÊñáË¶ÅËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Â§ñÈÉ®È´òË¥®ÈáèÁöÑÂèÇËÄÉÂõæÂÉèÊù•Âº•Ë°•‰ΩéÂàÜËæ®ÁéáËæìÂÖ•‰∏≠Áº∫Â§±ÁöÑÁ∫πÁêÜ‰ø°ÊÅØ„ÄÇÂêåÊó∂ÔºåÁªìÂêàËæìÂÖ•ÂõæÂÉèËá™Ë∫´ÁöÑÁ∫πÁêÜÁ∫øÁ¥¢ÔºåÂÖ±ÂêåÊåáÂØºÈ´òÊñØÂü∫ÂÖÉÁöÑÈ¢ÑÊµãÂíå‰ºòÂåñ„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÂèØ‰ª•ÊúâÊïàÂú∞ÊèêÂçáÈáçÂª∫ÁªìÊûúÁöÑË¥®ÈáèÂíåÁªÜËäÇ‰∏∞ÂØåÂ∫¶„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSRSplatÁöÑÊï¥‰ΩìÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) **ÂèÇËÄÉÂõæÂ∫ìÊûÑÂª∫**ÔºöÂà©Áî®Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂíåÊâ©Êï£Ê®°ÂûãÔºå‰∏∫ÊØè‰∏™Âú∫ÊôØÁîüÊàê‰∏ÄÁªÑÈ´òË¥®ÈáèÁöÑÂèÇËÄÉÂõæÂÉè„ÄÇ2) **ÂèÇËÄÉÂºïÂØºÁöÑÁâπÂæÅÂ¢ûÂº∫ÔºàRGFEÔºâ**ÔºöÂ∞Ü‰ΩéÂàÜËæ®ÁéáËæìÂÖ•ÂõæÂÉèÂíåÂØπÂ∫îÁöÑÂèÇËÄÉÂõæÂÉèËøõË°åÁâπÂæÅÂØπÈΩêÂíåËûçÂêàÔºå‰ªéËÄåÂ∞ÜÂ§ñÈÉ®‰ø°ÊÅØÂºïÂÖ•Âà∞ÈáçÂª∫ËøáÁ®ã‰∏≠„ÄÇ3) **È´òÊñØÂü∫ÂÖÉÈ¢ÑÊµã**Ôºö‰ΩøÁî®Ëß£Á†ÅÂô®‰ªéËûçÂêàÂêéÁöÑÁâπÂæÅ‰∏≠È¢ÑÊµãÈ´òÊñØÂü∫ÂÖÉÁöÑÂèÇÊï∞„ÄÇ4) **Á∫πÁêÜÊÑüÁü•ÂØÜÂ∫¶ÊéßÂà∂ÔºàTADCÔºâ**ÔºöÊ†πÊçÆËæìÂÖ•ÂõæÂÉèÁöÑÁ∫πÁêÜ‰∏∞ÂØåÂ∫¶ÔºåËá™ÈÄÇÂ∫îÂú∞Ë∞ÉÊï¥È´òÊñØÂØÜÂ∫¶ÔºåËøõ‰∏ÄÊ≠•‰ºòÂåñÈáçÂª∫ÁªìÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSRSplatÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂà©Áî®Â§ñÈÉ®ÂèÇËÄÉÂõæÂÉèÊù•Â¢ûÂº∫‰ΩéÂàÜËæ®ÁéáÂõæÂÉèÈáçÂª∫ÁöÑÊñπÊ≥ïÔºåÊúâÊïàÂú∞Âº•Ë°•‰∫ÜËæìÂÖ•‰ø°ÊÅØÁöÑ‰∏çË∂≥„ÄÇ2) ÂºïÂÖ•‰∫ÜÁ∫πÁêÜÊÑüÁü•ÂØÜÂ∫¶ÊéßÂà∂Ê®°ÂùóÔºåËÉΩÂ§üÊ†πÊçÆËæìÂÖ•ÂõæÂÉèÁöÑÁ∫πÁêÜ‰ø°ÊÅØËá™ÈÄÇÂ∫îÂú∞Ë∞ÉÊï¥È´òÊñØÂØÜÂ∫¶Ôºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÈáçÂª∫Âú∫ÊôØÁöÑÁªÜËäÇ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåSRSplatËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®Â§ñÈÉ®‰ø°ÊÅØÂíåÂÜÖÈÉ®Á∫øÁ¥¢Ôºå‰ªéËÄåËé∑ÂæóÊõ¥È´òË¥®ÈáèÁöÑÈáçÂª∫ÁªìÊûú„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèÇËÄÉÂºïÂØºÁöÑÁâπÂæÅÂ¢ûÂº∫Ê®°Âùó‰∏≠Ôºå‰ΩøÁî®‰∫ÜÊ≥®ÊÑèÂäõÊú∫Âà∂Êù•ÂÆûÁé∞ÁâπÂæÅÂØπÈΩêÂíåËûçÂêà„ÄÇÁ∫πÁêÜÊÑüÁü•ÂØÜÂ∫¶ÊéßÂà∂Ê®°ÂùóÈÄöËøáËÆ°ÁÆóËæìÂÖ•ÂõæÂÉèÁöÑÊ¢ØÂ∫¶Êù•‰º∞ËÆ°Á∫πÁêÜ‰∏∞ÂØåÂ∫¶ÔºåÂπ∂Ê†πÊçÆÁ∫πÁêÜ‰∏∞ÂØåÂ∫¶Ë∞ÉÊï¥È´òÊñØÂØÜÂ∫¶„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÈáçÂª∫ÊçüÂ§±„ÄÅÊ≠£ÂàôÂåñÊçüÂ§±Á≠âÔºåÁî®‰∫é‰ºòÂåñÈ´òÊñØÂü∫ÂÖÉÁöÑÂèÇÊï∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SRSplatÂú®RealEstate10K„ÄÅACIDÂíåDTUÁ≠âÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºåÂú®RealEstate10KÊï∞ÊçÆÈõÜ‰∏äÔºåSRSplatÁöÑPSNRÊåáÊ†áÊØîÁé∞ÊúâÊñπÊ≥ïÊèêÈ´ò‰∫ÜX%ÔºåSSIMÊåáÊ†áÊèêÈ´ò‰∫ÜY%„ÄÇÊ≠§Â§ñÔºåSRSplatËøòË°®Áé∞Âá∫Âº∫Â§ßÁöÑË∑®Êï∞ÊçÆÈõÜÂíåË∑®ÂàÜËæ®ÁéáÊ≥õÂåñËÉΩÂäõÔºåË°®ÊòéÂÖ∂ÂÖ∑ÊúâËâØÂ•ΩÁöÑÈ≤ÅÊ£íÊÄßÂíåÂÆûÁî®ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SRSplatÂú®Ëá™Âä®È©æÈ©∂„ÄÅÂÖ∑Ë∫´Êô∫ËÉΩÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ‰æãÂ¶ÇÔºåÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÂèØ‰ª•Âà©Áî®ËΩ¶ËΩΩÊëÑÂÉèÂ§¥ÊãçÊëÑÁöÑ‰ΩéÂàÜËæ®ÁéáÂõæÂÉèÈáçÂª∫È´òÂàÜËæ®ÁéáÁöÑ3DÁéØÂ¢ÉÂú∞ÂõæÔºå‰ªéËÄåÊèêÈ´òËΩ¶ËæÜÁöÑÊÑüÁü•ËÉΩÂäõÂíåÂÆâÂÖ®ÊÄß„ÄÇÂú®ÂÖ∑Ë∫´Êô∫ËÉΩ‰∏≠ÔºåÂèØ‰ª•Âà©Áî®Êú∫Âô®‰∫∫ÊãçÊëÑÁöÑÂõæÂÉèÈáçÂª∫È´òÂàÜËæ®ÁéáÁöÑ3DÂú∫ÊôØÔºå‰ªéËÄåÂ∏ÆÂä©Êú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÊìç‰ΩúÁéØÂ¢É„ÄÇËØ•Á†îÁ©∂ÁöÑÊàêÊûúÊúâÂä©‰∫éÊé®Âä®Ëøô‰∫õÈ¢ÜÂüüÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Feed-forward 3D reconstruction from sparse, low-resolution (LR) images is a crucial capability for real-world applications, such as autonomous driving and embodied AI. However, existing methods often fail to recover fine texture details. This limitation stems from the inherent lack of high-frequency information in LR inputs. To address this, we propose \textbf{SRSplat}, a feed-forward framework that reconstructs high-resolution 3D scenes from only a few LR views. Our main insight is to compensate for the deficiency of texture information by jointly leveraging external high-quality reference images and internal texture cues. We first construct a scene-specific reference gallery, generated for each scene using Multimodal Large Language Models (MLLMs) and diffusion models. To integrate this external information, we introduce the \textit{Reference-Guided Feature Enhancement (RGFE)} module, which aligns and fuses features from the LR input images and their reference twin image. Subsequently, we train a decoder to predict the Gaussian primitives using the multi-view fused feature obtained from \textit{RGFE}. To further refine predicted Gaussian primitives, we introduce \textit{Texture-Aware Density Control (TADC)}, which adaptively adjusts Gaussian density based on the internal texture richness of the LR inputs. Extensive experiments demonstrate that our SRSplat outperforms existing methods on various datasets, including RealEstate10K, ACID, and DTU, and exhibits strong cross-dataset and cross-resolution generalization capabilities.

