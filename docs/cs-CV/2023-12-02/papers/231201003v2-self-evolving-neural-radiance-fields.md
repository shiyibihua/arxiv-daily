---
layout: default
title: Self-Evolving Neural Radiance Fields
---

# Self-Evolving Neural Radiance Fields

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.01003" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.01003v2</a>
  <a href="https://arxiv.org/pdf/2312.01003.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.01003v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.01003v2', 'Self-Evolving Neural Radiance Fields')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jaewoo Jung, Jisang Han, Jiwon Kang, Seongchan Kim, Min-Seop Kwak, Seungryong Kim

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2023-12-02 (æ›´æ–°: 2023-12-05)

**å¤‡æ³¨**: 34 pages, 21 figures Our project page can be found at : https://ku-cvlab.github.io/SE-NeRF/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªè¿›åŒ–ç¥ç»è¾å°„åœº(SE-NeRF)ï¼Œè§£å†³ç¨€ç–è§†è§’ä¸‹NeRFè¿‡æ‹Ÿåˆé—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ç¥ç»è¾å°„åœº` `NeRF` `novel view synthesis` `few-shot learning` `è‡ªè®­ç»ƒ` `çŸ¥è¯†è’¸é¦` `ä¸‰ç»´é‡å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰NeRFæ–¹æ³•åœ¨ç¨€ç–è§†è§’ä¸‹æ˜“è¿‡æ‹Ÿåˆï¼Œä»…é æ­£åˆ™åŒ–éš¾ä»¥ä¿è¯æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚
2. SE-NeRFé‡‡ç”¨æ•™å¸ˆ-å­¦ç”Ÿè‡ªè®­ç»ƒæ¡†æ¶ï¼Œåˆ©ç”¨æ•™å¸ˆæ¨¡å‹ç”Ÿæˆçš„ä¼ªæ ‡ç­¾æŒ‡å¯¼å­¦ç”Ÿæ¨¡å‹å­¦ä¹ æ›´é²æ£’çš„åœºæ™¯è¡¨ç¤ºã€‚
3. é€šè¿‡å¯é æ€§ä¼°è®¡åŒºåˆ†å°„çº¿ï¼Œå¹¶é‡‡ç”¨ä¸åŒçš„è’¸é¦ç­–ç•¥ï¼ŒSE-NeRFåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„ç»“æœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¥ç»è¾å°„åœº(NeRF)åœ¨ novel view synthesis å’Œ 3D é‡å»ºæ–¹é¢è¡¨ç°å‡ºè‰²ã€‚ç„¶è€Œï¼Œå®ƒä»ç„¶éœ€è¦å¤§é‡é«˜è´¨é‡å›¾åƒï¼Œé™åˆ¶äº†å…¶åœ¨ç°å®åœºæ™¯ä¸­çš„åº”ç”¨ã€‚ä¸ºäº†å…‹æœè¿™ä¸€é™åˆ¶ï¼Œæœ€è¿‘çš„å·¥ä½œé›†ä¸­åœ¨ä½¿ç”¨ç¨€ç–è§†è§’è®­ç»ƒ NeRFï¼Œå¹¶æ–½åŠ é¢å¤–çš„æ­£åˆ™åŒ–ï¼Œé€šå¸¸ç§°ä¸º few-shot NeRFã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œç”±äºä»»åŠ¡çš„æ¬ çº¦æŸæ€§è´¨ï¼Œä»…ä½¿ç”¨é¢å¤–çš„æ­£åˆ™åŒ–ä¸è¶³ä»¥é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆç¨€ç–è§†è§’ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåä¸ºè‡ªè¿›åŒ–ç¥ç»è¾å°„åœº(SE-NeRF)çš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†è‡ªè®­ç»ƒåº”ç”¨äº NeRF ä»¥è§£å†³è¿™äº›é—®é¢˜ã€‚æˆ‘ä»¬å°† few-shot NeRF è½¬åŒ–ä¸ºæ•™å¸ˆ-å­¦ç”Ÿæ¡†æ¶ï¼Œé€šè¿‡ä½¿ç”¨ä»æ•™å¸ˆç”Ÿæˆçš„é¢å¤–ä¼ªæ ‡ç­¾è®­ç»ƒå­¦ç”Ÿï¼Œæ¥å¼•å¯¼ç½‘ç»œå­¦ä¹ æ›´é²æ£’çš„åœºæ™¯è¡¨ç¤ºã€‚é€šè¿‡ä½¿ç”¨æˆ‘ä»¬æ–°é¢–çš„å¯é æ€§ä¼°è®¡æ–¹æ³•è·å¾—çš„å¯é å’Œä¸å¯é å°„çº¿çš„ä¸åŒè’¸é¦æ–¹æ¡ˆæ¥æç‚¼å°„çº¿çº§ä¼ªæ ‡ç­¾ï¼Œæˆ‘ä»¬ä½¿ NeRF èƒ½å¤Ÿå­¦ä¹ æ›´å‡†ç¡®å’Œé²æ£’çš„ 3D åœºæ™¯å‡ ä½•ã€‚æˆ‘ä»¬å±•ç¤ºå¹¶è¯„ä¼°äº†å°†æˆ‘ä»¬çš„è‡ªè®­ç»ƒæ¡†æ¶åº”ç”¨äºç°æœ‰æ¨¡å‹å¯ä»¥æé«˜æ¸²æŸ“å›¾åƒçš„è´¨é‡ï¼Œå¹¶åœ¨å¤šä¸ªè®¾ç½®ä¸­å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨ç¨€ç–è§†è§’ä¸‹è®­ç»ƒç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ—¶ï¼Œæ¨¡å‹å®¹æ˜“è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚ç°æœ‰çš„few-shot NeRFæ–¹æ³•é€šå¸¸ä¾èµ–äºé¢å¤–çš„æ­£åˆ™åŒ–æ¥çº¦æŸæ¨¡å‹ï¼Œä½†ç”±äºä»»åŠ¡æœ¬èº«çš„æ¬ çº¦æŸæ€§ï¼Œå•çº¯çš„æ­£åˆ™åŒ–ä¸è¶³ä»¥é˜²æ­¢æ¨¡å‹è®°ä½æœ‰é™çš„è®­ç»ƒè§†è§’ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›å·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è‡ªè®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡æ•™å¸ˆ-å­¦ç”Ÿæ¨¡å‹ä¹‹é—´çš„çŸ¥è¯†è’¸é¦ï¼Œæé«˜NeRFåœ¨ç¨€ç–è§†è§’ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æ•™å¸ˆæ¨¡å‹ç”Ÿæˆä¼ªæ ‡ç­¾ï¼ŒæŒ‡å¯¼å­¦ç”Ÿæ¨¡å‹å­¦ä¹ ï¼Œä»è€Œé¿å…å­¦ç”Ÿæ¨¡å‹ç›´æ¥è¿‡æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSE-NeRFçš„æ•´ä½“æ¡†æ¶æ˜¯ä¸€ä¸ªæ•™å¸ˆ-å­¦ç”Ÿæ¨¡å‹ã€‚é¦–å…ˆï¼Œä½¿ç”¨åŸå§‹çš„ç¨€ç–è§†è§’å›¾åƒè®­ç»ƒæ•™å¸ˆNeRFæ¨¡å‹ã€‚ç„¶åï¼Œæ•™å¸ˆæ¨¡å‹ç”Ÿæˆå°„çº¿çº§åˆ«çš„ä¼ªæ ‡ç­¾ï¼ˆé¢œè‰²å’Œå¯†åº¦ï¼‰ã€‚æ¥ä¸‹æ¥ï¼Œå¼•å…¥å¯é æ€§ä¼°è®¡æ¨¡å—ï¼Œåˆ¤æ–­å“ªäº›å°„çº¿çš„ä¼ªæ ‡ç­¾æ˜¯å¯é çš„ï¼Œå“ªäº›æ˜¯ä¸å¯é çš„ã€‚æœ€åï¼Œä½¿ç”¨ä¸åŒçš„è’¸é¦ç­–ç•¥ï¼Œå°†æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†ä¼ é€’ç»™å­¦ç”ŸNeRFæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªè‡ªè¿›åŒ–çš„NeRFè®­ç»ƒæ¡†æ¶ï¼Œå¹¶è®¾è®¡äº†å¯é æ€§ä¼°è®¡æ¨¡å—å’Œå·®å¼‚åŒ–çš„è’¸é¦ç­–ç•¥ã€‚é€šè¿‡è‡ªè®­ç»ƒï¼Œæ¨¡å‹èƒ½å¤Ÿä»è‡ªèº«çš„é¢„æµ‹ä¸­å­¦ä¹ ï¼Œä»è€Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚å¯é æ€§ä¼°è®¡æ¨¡å—èƒ½å¤ŸåŒºåˆ†å¯é å’Œä¸å¯é çš„å°„çº¿ï¼Œé¿å…äº†ä¸å¯é çš„ä¼ªæ ‡ç­¾å¯¹å­¦ç”Ÿæ¨¡å‹çš„è´Ÿé¢å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šSE-NeRFçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ•™å¸ˆå’Œå­¦ç”Ÿæ¨¡å‹é‡‡ç”¨ç›¸åŒçš„NeRFç»“æ„ï¼›2) å¯é æ€§ä¼°è®¡æ¨¡å—åŸºäºå°„çº¿çš„ä¸ç¡®å®šæ€§è¿›è¡Œåˆ¤æ–­ï¼Œä¾‹å¦‚æ–¹å·®æˆ–ç†µï¼›3) å¯¹äºå¯é çš„å°„çº¿ï¼Œä½¿ç”¨L1æˆ–L2æŸå¤±è¿›è¡Œè’¸é¦ï¼›4) å¯¹äºä¸å¯é çš„å°„çº¿ï¼Œä½¿ç”¨æ›´å®½æ¾çš„æŸå¤±å‡½æ•°æˆ–å¿½ç•¥å®ƒä»¬ï¼›5) æŸå¤±å‡½æ•°åŒ…æ‹¬é‡å»ºæŸå¤±ã€æ­£åˆ™åŒ–æŸå¤±å’Œè’¸é¦æŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SE-NeRFåœ¨å¤šä¸ªfew-shot NeRF benchmarkæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼ŒSE-NeRFæ˜¾è‘—æé«˜äº†æ¸²æŸ“å›¾åƒçš„è´¨é‡ï¼Œå¹¶åœ¨PSNRã€SSIMå’ŒLPIPSç­‰æŒ‡æ ‡ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›æ•°æ®é›†ä¸Šï¼ŒSE-NeRFç›¸æ¯”äºä¹‹å‰çš„æœ€ä½³æ–¹æ³•ï¼ŒPSNRæå‡äº†1-2dBã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SE-NeRFå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®/å¢å¼ºç°å®ç­‰é¢†åŸŸã€‚åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œé€šå¸¸éš¾ä»¥è·å–å¤§é‡é«˜è´¨é‡çš„å›¾åƒæ•°æ®ï¼Œè€ŒSE-NeRFèƒ½å¤Ÿåœ¨ç¨€ç–è§†è§’ä¸‹å®ç°é«˜è´¨é‡çš„3Dé‡å»ºå’Œnovel view synthesisï¼Œé™ä½äº†æ•°æ®é‡‡é›†æˆæœ¬ï¼Œæé«˜äº†ç³»ç»Ÿçš„å®ç”¨æ€§ã€‚è¯¥æ–¹æ³•è¿˜æœ‰æ½œåŠ›åº”ç”¨äºåŒ»å­¦å½±åƒé‡å»ºã€æ–‡ç‰©æ•°å­—åŒ–ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently, neural radiance field (NeRF) has shown remarkable performance in novel view synthesis and 3D reconstruction. However, it still requires abundant high-quality images, limiting its applicability in real-world scenarios. To overcome this limitation, recent works have focused on training NeRF only with sparse viewpoints by giving additional regularizations, often called few-shot NeRF. We observe that due to the under-constrained nature of the task, solely using additional regularization is not enough to prevent the model from overfitting to sparse viewpoints. In this paper, we propose a novel framework, dubbed Self-Evolving Neural Radiance Fields (SE-NeRF), that applies a self-training framework to NeRF to address these problems. We formulate few-shot NeRF into a teacher-student framework to guide the network to learn a more robust representation of the scene by training the student with additional pseudo labels generated from the teacher. By distilling ray-level pseudo labels using distinct distillation schemes for reliable and unreliable rays obtained with our novel reliability estimation method, we enable NeRF to learn a more accurate and robust geometry of the 3D scene. We show and evaluate that applying our self-training framework to existing models improves the quality of the rendered images and achieves state-of-the-art performance in multiple settings.

