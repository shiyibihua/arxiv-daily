---
layout: default
title: DPHMs: Diffusion Parametric Head Models for Depth-based Tracking
---

# DPHMs: Diffusion Parametric Head Models for Depth-based Tracking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.01068" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.01068v2</a>
  <a href="https://arxiv.org/pdf/2312.01068.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.01068v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.01068v2', 'DPHMs: Diffusion Parametric Head Models for Depth-based Tracking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiapeng Tang, Angela Dai, Yinyu Nie, Lev Markhasin, Justus Thies, Matthias Niessner

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2023-12-02 (æ›´æ–°: 2024-04-08)

**å¤‡æ³¨**: CVPR 2024; homepage: https://tangjiapeng.github.io/projects/DPHMs/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ‰©æ•£å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹çš„æ·±åº¦è·Ÿè¸ªæ–¹æ³•ï¼Œæå‡å•ç›®æ·±åº¦åºåˆ—å¤´éƒ¨é‡å»ºä¸è·Ÿè¸ªçš„é²æ£’æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¤´éƒ¨é‡å»º` `é¢éƒ¨è·Ÿè¸ª` `æ‰©æ•£æ¨¡å‹` `å‚æ•°åŒ–æ¨¡å‹` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä½“ç´ å¤´éƒ¨æ¨¡å‹åœ¨å•ç›®æ·±åº¦åºåˆ—ä¸‹ï¼Œæ˜“å—å™ªå£°å’Œé®æŒ¡å½±å“ï¼Œå¯¼è‡´å¤´éƒ¨é‡å»ºå’Œè·Ÿè¸ªæ•ˆæœä¸ä½³ã€‚
2. åˆ©ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹å­¦ä¹ å¤´éƒ¨å½¢çŠ¶çš„å…ˆéªŒçŸ¥è¯†ï¼Œçº¦æŸèº«ä»½å’Œè¡¨æƒ…ä»£ç ï¼Œä»è€Œæ­£åˆ™åŒ–å¤´éƒ¨é‡å»ºå’Œè·Ÿè¸ªè¿‡ç¨‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤´éƒ¨èº«ä»½é‡å»ºå’Œè¡¨æƒ…è·Ÿè¸ªæ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚è¡¨æƒ…å’Œå¿«é€Ÿè¿åŠ¨åœºæ™¯ä¸‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ‰©æ•£å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹ï¼ˆDPHMsï¼‰ï¼Œè¯¥ç”Ÿæˆæ¨¡å‹èƒ½å¤Ÿä»å•ç›®æ·±åº¦åºåˆ—ä¸­å®ç°é²æ£’çš„ä½“ç´ å¤´éƒ¨é‡å»ºå’Œè·Ÿè¸ªã€‚å°½ç®¡è¯¸å¦‚NPHMsç­‰æœ€æ–°çš„ä½“ç´ å¤´éƒ¨æ¨¡å‹åœ¨è¡¨ç¤ºé«˜ä¿çœŸå¤´éƒ¨å‡ ä½•ç»“æ„æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†ä»çœŸå®ä¸–ç•Œçš„å•è§†è§’æ·±åº¦åºåˆ—ä¸­è·Ÿè¸ªå’Œé‡å»ºå¤´éƒ¨ä»ç„¶æå…·æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå¯¹éƒ¨åˆ†å’Œå™ªå£°è§‚æµ‹çš„æ‹Ÿåˆå—åˆ°çº¦æŸä¸è¶³ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ½œåœ¨æ‰©æ•£çš„å…ˆéªŒï¼Œä»¥æ­£åˆ™åŒ–ä½“ç´ å¤´éƒ¨é‡å»ºå’Œè·Ÿè¸ªã€‚è¿™ç§åŸºäºå…ˆéªŒçš„æ­£åˆ™åŒ–å™¨æœ‰æ•ˆåœ°çº¦æŸäº†èº«ä»½å’Œè¡¨æƒ…ä»£ç ï¼Œä½¿å…¶ä½äºè¡¨ç¤ºåˆç†å¤´éƒ¨å½¢çŠ¶çš„åº•å±‚æ½œåœ¨æµå½¢ä¸Šã€‚ä¸ºäº†è¯„ä¼°åŸºäºæ‰©æ•£çš„å…ˆéªŒçš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬æ”¶é›†äº†ä¸€ä¸ªåŒ…å«å„ç§å¤æ‚é¢éƒ¨è¡¨æƒ…è¿åŠ¨å’Œå¿«é€Ÿè¿‡æ¸¡çš„å•ç›®Kinectåºåˆ—æ•°æ®é›†ã€‚æˆ‘ä»¬å°†æˆ‘ä»¬çš„æ–¹æ³•ä¸æœ€å…ˆè¿›çš„è·Ÿè¸ªæ–¹æ³•è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶è¯æ˜äº†æ”¹è¿›çš„å¤´éƒ¨èº«ä»½é‡å»ºä»¥åŠé²æ£’çš„è¡¨æƒ…è·Ÿè¸ªã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»å•ç›®æ·±åº¦åºåˆ—ä¸­è¿›è¡Œé²æ£’çš„å¤´éƒ¨é‡å»ºå’Œè·Ÿè¸ªé—®é¢˜ã€‚ç°æœ‰çš„ä½“ç´ å¤´éƒ¨æ¨¡å‹ï¼Œå¦‚NPHMsï¼Œè™½ç„¶èƒ½å¤Ÿè¾ƒå¥½åœ°è¡¨ç¤ºå¤´éƒ¨å‡ ä½•ç»“æ„ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œç”±äºå•ç›®æ·±åº¦åºåˆ—å­˜åœ¨å™ªå£°ã€é®æŒ¡ä»¥åŠè§†è§’é™åˆ¶ç­‰é—®é¢˜ï¼Œç›´æ¥æ‹Ÿåˆè¿™äº›æ¨¡å‹ä¼šå¯¼è‡´é‡å»ºç»“æœä¸å‡†ç¡®ï¼Œè·Ÿè¸ªæ•ˆæœä¸ä½³ã€‚ç°æœ‰çš„æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„æ­£åˆ™åŒ–æ‰‹æ®µï¼Œå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜è§£ï¼Œå¯¼è‡´èº«ä»½ä¿¡æ¯ä¸¢å¤±å’Œè¡¨æƒ…è·Ÿè¸ªä¸ç¨³å®šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ‰©æ•£æ¨¡å‹å­¦ä¹ åˆ°çš„å¤´éƒ¨å½¢çŠ¶å…ˆéªŒçŸ¥è¯†æ¥çº¦æŸå¤´éƒ¨é‡å»ºå’Œè·Ÿè¸ªè¿‡ç¨‹ã€‚æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„å¤´éƒ¨å½¢çŠ¶ï¼Œå¹¶ä¸”å¯ä»¥å­¦ä¹ åˆ°å¤´éƒ¨å½¢çŠ¶çš„æ½œåœ¨æµå½¢ã€‚é€šè¿‡å°†èº«ä»½å’Œè¡¨æƒ…ä»£ç çº¦æŸåœ¨è¿™ä¸ªæ½œåœ¨æµå½¢ä¸Šï¼Œå¯ä»¥æœ‰æ•ˆåœ°é¿å…é‡å»ºç»“æœåç¦»çœŸå®å¤´éƒ¨å½¢çŠ¶ï¼Œä»è€Œæé«˜é‡å»ºå’Œè·Ÿè¸ªçš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDPHMsçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1ï¼‰æ·±åº¦å›¾è¾“å…¥ï¼šæ¥æ”¶å•ç›®æ·±åº¦åºåˆ—ä½œä¸ºè¾“å…¥ã€‚2ï¼‰å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹ï¼šä½¿ç”¨å‚æ•°åŒ–çš„å¤´éƒ¨æ¨¡å‹ï¼ˆå¦‚NPHMsï¼‰è¡¨ç¤ºå¤´éƒ¨å½¢çŠ¶ã€‚3ï¼‰æ‰©æ•£å…ˆéªŒï¼šåˆ©ç”¨æ‰©æ•£æ¨¡å‹å­¦ä¹ å¤´éƒ¨å½¢çŠ¶çš„æ½œåœ¨ç©ºé—´ï¼Œå¹¶ä½œä¸ºå…ˆéªŒçŸ¥è¯†ã€‚4ï¼‰ä¼˜åŒ–è¿‡ç¨‹ï¼šé€šè¿‡ä¼˜åŒ–èº«ä»½ä»£ç ã€è¡¨æƒ…ä»£ç ç­‰å‚æ•°ï¼Œå°†å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹æ‹Ÿåˆåˆ°è¾“å…¥çš„æ·±åº¦å›¾ï¼ŒåŒæ—¶åˆ©ç”¨æ‰©æ•£å…ˆéªŒè¿›è¡Œæ­£åˆ™åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†æ‰©æ•£æ¨¡å‹å¼•å…¥åˆ°å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹çš„é‡å»ºå’Œè·Ÿè¸ªè¿‡ç¨‹ä¸­ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹å­¦ä¹ åˆ°çš„å¤´éƒ¨å½¢çŠ¶å…ˆéªŒçŸ¥è¯†æ¥çº¦æŸè§£ç©ºé—´ã€‚ä¸ä¼ ç»Ÿçš„æ­£åˆ™åŒ–æ–¹æ³•ç›¸æ¯”ï¼Œæ‰©æ•£å…ˆéªŒèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å¤´éƒ¨å½¢çŠ¶çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ï¼Œä»è€Œæé«˜é‡å»ºå’Œè·Ÿè¸ªçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œè®ºæ–‡ä½¿ç”¨äº†ä»¥ä¸‹å…³é”®è®¾è®¡ï¼š1ï¼‰æŸå¤±å‡½æ•°ï¼šåŒ…æ‹¬æ·±åº¦å›¾é‡å»ºæŸå¤±ã€æ‰©æ•£å…ˆéªŒæŸå¤±ç­‰ã€‚æ·±åº¦å›¾é‡å»ºæŸå¤±ç”¨äºä¿è¯é‡å»ºç»“æœä¸è¾“å…¥æ·±åº¦å›¾çš„ä¸€è‡´æ€§ï¼Œæ‰©æ•£å…ˆéªŒæŸå¤±ç”¨äºçº¦æŸèº«ä»½å’Œè¡¨æƒ…ä»£ç ä½äºæ‰©æ•£æ¨¡å‹å­¦ä¹ åˆ°çš„æ½œåœ¨æµå½¢ä¸Šã€‚2ï¼‰ä¼˜åŒ–ç®—æ³•ï¼šä½¿ç”¨Adamç­‰ä¼˜åŒ–ç®—æ³•æ¥æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼Œä»è€Œå¾—åˆ°æœ€ä¼˜çš„èº«ä»½ä»£ç å’Œè¡¨æƒ…ä»£ç ã€‚3ï¼‰æ‰©æ•£æ¨¡å‹è®­ç»ƒï¼šä½¿ç”¨å¤§é‡çš„å¤´éƒ¨æ‰«ææ•°æ®è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿå­¦ä¹ åˆ°é«˜è´¨é‡çš„å¤´éƒ¨å½¢çŠ¶å…ˆéªŒçŸ¥è¯†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDPHMsåœ¨å¤´éƒ¨èº«ä»½é‡å»ºå’Œè¡¨æƒ…è·Ÿè¸ªæ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚åœ¨ä½œè€…æ”¶é›†çš„å•ç›®Kinectæ•°æ®é›†ä¸Šï¼ŒDPHMsèƒ½å¤Ÿæ›´å‡†ç¡®åœ°é‡å»ºå¤´éƒ¨å½¢çŠ¶ï¼Œå¹¶èƒ½å¤Ÿé²æ£’åœ°è·Ÿè¸ªå¤æ‚çš„é¢éƒ¨è¡¨æƒ…è¿åŠ¨å’Œå¿«é€Ÿè¿‡æ¸¡ã€‚ä¸state-of-the-artæ–¹æ³•ç›¸æ¯”ï¼ŒDPHMsåœ¨é‡å»ºç²¾åº¦å’Œè·Ÿè¸ªç¨³å®šæ€§æ–¹é¢å‡æœ‰æ˜æ˜¾æå‡ï¼Œå°¤å…¶æ˜¯åœ¨å™ªå£°å’Œé®æŒ¡ä¸¥é‡çš„æƒ…å†µä¸‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€äººæœºäº¤äº’ã€åŠ¨ç”»åˆ¶ä½œç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨VR/ARåº”ç”¨ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•å®ç°æ›´é€¼çœŸçš„è™šæ‹ŸåŒ–èº«åˆ›å»ºå’Œå®æ—¶é¢éƒ¨è¡¨æƒ…è·Ÿè¸ªï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚åœ¨äººæœºäº¤äº’é¢†åŸŸï¼Œå¯ä»¥ç”¨äºå®ç°æ›´è‡ªç„¶å’Œæµç•…çš„é¢éƒ¨è¡¨æƒ…è¯†åˆ«å’Œç†è§£ï¼Œä»è€Œæ”¹å–„äººæœºäº¤äº’çš„æ•ˆç‡å’Œèˆ’é€‚åº¦ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ç”¨äºå®‰å…¨ç›‘æ§å’Œèº«ä»½è¯†åˆ«ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce Diffusion Parametric Head Models (DPHMs), a generative model that enables robust volumetric head reconstruction and tracking from monocular depth sequences. While recent volumetric head models, such as NPHMs, can now excel in representing high-fidelity head geometries, tracking and reconstructing heads from real-world single-view depth sequences remains very challenging, as the fitting to partial and noisy observations is underconstrained. To tackle these challenges, we propose a latent diffusion-based prior to regularize volumetric head reconstruction and tracking. This prior-based regularizer effectively constrains the identity and expression codes to lie on the underlying latent manifold which represents plausible head shapes. To evaluate the effectiveness of the diffusion-based prior, we collect a dataset of monocular Kinect sequences consisting of various complex facial expression motions and rapid transitions. We compare our method to state-of-the-art tracking methods and demonstrate improved head identity reconstruction as well as robust expression tracking.

