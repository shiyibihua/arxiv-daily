---
layout: default
title: RobustCalib: Robust Lidar-Camera Extrinsic Calibration with Consistency Learning
---

# RobustCalib: Robust Lidar-Camera Extrinsic Calibration with Consistency Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.01085" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.01085v1</a>
  <a href="https://arxiv.org/pdf/2312.01085.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.01085v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.01085v1', 'RobustCalib: Robust Lidar-Camera Extrinsic Calibration with Consistency Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuang Xu, Sifan Zhou, Zhi Tian, Jizhou Ma, Qiong Nie, Xiangxiang Chu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2023-12-02

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRobustCalibï¼Œé€šè¿‡ä¸€è‡´æ€§å­¦ä¹ å®ç°é²æ£’çš„æ¿€å…‰é›·è¾¾-ç›¸æœºå¤–å‚æ ‡å®š**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `æ¿€å…‰é›·è¾¾ç›¸æœºæ ‡å®š` `å¤–å‚ä¼°è®¡` `ä¸€è‡´æ€§å­¦ä¹ ` `è‡ªåŠ¨é©¾é©¶` `æœºå™¨äººæ„ŸçŸ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿæ¿€å…‰é›·è¾¾-ç›¸æœºå¤–å‚æ ‡å®šæ–¹æ³•ä¾èµ–ç¦»çº¿ç›®æ ‡å’Œäººå·¥å¹²é¢„ï¼Œå­¦ä¹ æ–¹æ³•åˆ™ä¾èµ–è¿­ä»£ä¼˜åŒ–ï¼Œé™åˆ¶äº†å…¶æ³›åŒ–æ€§å’Œè½¦è½½ç³»ç»Ÿåº”ç”¨ã€‚
2. RobustCalibé€šè¿‡ä¸€è‡´æ€§å­¦ä¹ å®ç°éšå¼é‡æ ‡å®šï¼Œå¼•å…¥å¤–è§‚ä¸€è‡´æ€§æŸå¤±å’Œå‡ ä½•ä¸€è‡´æ€§æŸå¤±ï¼Œæœ€å°åŒ–æ¿€å…‰é›·è¾¾æŠ•å½±ç‚¹ä¸é¢„æµ‹å±æ€§çš„ä¸ä¸€è‡´æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒæ•°æ®é›†ä¸Šå®ç°äº†å‡†ç¡®è€Œé²æ£’çš„æ€§èƒ½ï¼Œä»£ç å’Œæ¨¡å‹å°†ä¼šå¼€æºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œä»¥é²æ£’ã€è‡ªåŠ¨å’Œå•æ¬¡çš„æ–¹å¼è§£å†³æ¿€å…‰é›·è¾¾-ç›¸æœºå¤–å‚æ ‡å®šé—®é¢˜ã€‚è¯¥æ–¹æ³•ä¸ç›´æ¥ä¼˜åŒ–å¤–å‚ï¼Œè€Œæ˜¯åˆ©ç”¨æ¿€å…‰é›·è¾¾å’Œç›¸æœºä¹‹é—´çš„ä¸€è‡´æ€§å­¦ä¹ æ¥å®ç°éšå¼é‡æ ‡å®šã€‚å…·ä½“è€Œè¨€ï¼Œå¼•å…¥äº†å¤–è§‚ä¸€è‡´æ€§æŸå¤±å’Œå‡ ä½•ä¸€è‡´æ€§æŸå¤±ï¼Œä»¥æœ€å°åŒ–æŠ•å½±æ¿€å…‰é›·è¾¾ç‚¹çš„å±æ€§ï¼ˆä¾‹å¦‚ï¼Œå¼ºåº¦å’Œæ·±åº¦ï¼‰ä¸é¢„æµ‹å±æ€§ä¹‹é—´çš„ä¸ä¸€è‡´æ€§ã€‚è¿™ç§è®¾è®¡ä¸ä»…å¢å¼ºäº†å¯¹å„ç§åœºæ™¯çš„é€‚åº”æ€§ï¼Œè€Œä¸”åœ¨æ¨ç†è¿‡ç¨‹ä¸­å®ç°äº†ç®€å•é«˜æ•ˆçš„å…¬å¼åŒ–ã€‚åœ¨ä¸åŒæ•°æ®é›†ä¸Šè¿›è¡Œäº†å…¨é¢çš„å®éªŒï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•å®ç°äº†å‡†ç¡®è€Œé²æ£’çš„æ€§èƒ½ã€‚ä¸ºäº†ä¿ƒè¿›è¯¥é¢†åŸŸè¿›ä¸€æ­¥çš„ç ”ç©¶å’Œå¼€å‘ï¼Œæˆ‘ä»¬å°†å‘å¸ƒæˆ‘ä»¬çš„æ¨¡å‹å’Œä»£ç ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ¿€å…‰é›·è¾¾å’Œç›¸æœºå¤–å‚æ ‡å®šæ˜¯è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººæ„ŸçŸ¥ä¸­çš„å…³é”®é—®é¢˜ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºç‰¹å®šçš„æ ‡å®šç‰©å’Œäººå·¥æ“ä½œï¼Œæ•ˆç‡ä½ä¸”éš¾ä»¥è‡ªåŠ¨åŒ–ã€‚åŸºäºå­¦ä¹ çš„æ–¹æ³•é€šå¸¸éœ€è¦è¿­ä»£ä¼˜åŒ–ï¼Œè®¡ç®—æˆæœ¬é«˜ï¼Œæ³›åŒ–èƒ½åŠ›å—é™ï¼Œéš¾ä»¥æ»¡è¶³è½¦è½½ç³»ç»Ÿçš„å®æ—¶æ€§è¦æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRobustCalibçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å­¦ä¹ æ¿€å…‰é›·è¾¾å’Œç›¸æœºæ•°æ®ä¹‹é—´çš„ä¸€è‡´æ€§æ¥éšå¼åœ°è¿›è¡Œå¤–å‚æ ‡å®šï¼Œé¿å…äº†ç›´æ¥ä¼˜åŒ–å¤–å‚çš„å¤æ‚è¿‡ç¨‹ã€‚é€šè¿‡æœ€å°åŒ–æ¿€å…‰é›·è¾¾æŠ•å½±ç‚¹å’Œç›¸æœºå›¾åƒä¹‹é—´çš„ä¸ä¸€è‡´æ€§ï¼Œç½‘ç»œå¯ä»¥å­¦ä¹ åˆ°æ­£ç¡®çš„å¤–å‚ï¼Œä»è€Œå®ç°é²æ£’çš„æ ‡å®šã€‚è¿™ç§æ–¹æ³•æ— éœ€è¿­ä»£ä¼˜åŒ–ï¼Œå¯ä»¥å•æ¬¡å®Œæˆæ ‡å®šã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRobustCalibçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ•°æ®è¾“å…¥ï¼šè¾“å…¥æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®å’Œç›¸æœºå›¾åƒæ•°æ®ã€‚2) ç‰¹å¾æå–ï¼šåˆ†åˆ«æå–æ¿€å…‰é›·è¾¾ç‚¹äº‘å’Œç›¸æœºå›¾åƒçš„ç‰¹å¾ã€‚3) æŠ•å½±å˜æ¢ï¼šå°†æ¿€å…‰é›·è¾¾ç‚¹äº‘æŠ•å½±åˆ°ç›¸æœºå›¾åƒå¹³é¢ã€‚4) ä¸€è‡´æ€§å­¦ä¹ ï¼šé€šè¿‡å¤–è§‚ä¸€è‡´æ€§æŸå¤±å’Œå‡ ä½•ä¸€è‡´æ€§æŸå¤±æ¥å­¦ä¹ æ¿€å…‰é›·è¾¾å’Œç›¸æœºæ•°æ®ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚5) å¤–å‚ä¼°è®¡ï¼šåŸºäºå­¦ä¹ åˆ°çš„ä¸€è‡´æ€§ï¼Œéšå¼åœ°ä¼°è®¡æ¿€å…‰é›·è¾¾å’Œç›¸æœºä¹‹é—´çš„å¤–å‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šRobustCalibçš„å…³é”®åˆ›æ–°åœ¨äºä½¿ç”¨ä¸€è‡´æ€§å­¦ä¹ æ¥éšå¼åœ°è¿›è¡Œå¤–å‚æ ‡å®šã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›´æ¥ä¼˜åŒ–å¤–å‚ä¸åŒï¼ŒRobustCalibé€šè¿‡å­¦ä¹ æ¿€å…‰é›·è¾¾å’Œç›¸æœºæ•°æ®ä¹‹é—´çš„ä¸€è‡´æ€§æ¥é—´æ¥ä¼°è®¡å¤–å‚ã€‚è¿™ç§æ–¹æ³•å…·æœ‰æ›´é«˜çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”å¯ä»¥å•æ¬¡å®Œæˆæ ‡å®šã€‚

**å…³é”®è®¾è®¡**ï¼šRobustCalibçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¤–è§‚ä¸€è‡´æ€§æŸå¤±ï¼šç”¨äºæœ€å°åŒ–æ¿€å…‰é›·è¾¾æŠ•å½±ç‚¹çš„å¼ºåº¦ä¸ç›¸æœºå›¾åƒå¯¹åº”åŒºåŸŸçš„é¢œè‰²ä¹‹é—´çš„å·®å¼‚ã€‚2) å‡ ä½•ä¸€è‡´æ€§æŸå¤±ï¼šç”¨äºæœ€å°åŒ–æ¿€å…‰é›·è¾¾æŠ•å½±ç‚¹çš„æ·±åº¦ä¸ç›¸æœºå›¾åƒå¯¹åº”åŒºåŸŸçš„é¢„æµ‹æ·±åº¦ä¹‹é—´çš„å·®å¼‚ã€‚3) ç½‘ç»œç»“æ„ï¼šé‡‡ç”¨æ·±åº¦ç¥ç»ç½‘ç»œæ¥æå–æ¿€å…‰é›·è¾¾ç‚¹äº‘å’Œç›¸æœºå›¾åƒçš„ç‰¹å¾ï¼Œå¹¶å­¦ä¹ å®ƒä»¬ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

RobustCalibåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜å…¶æ€§èƒ½ä¼˜äºç°æœ‰çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿå®ç°å‡†ç¡®è€Œé²æ£’çš„æ¿€å…‰é›·è¾¾-ç›¸æœºå¤–å‚æ ‡å®šï¼Œå¹¶ä¸”å¯ä»¥å•æ¬¡å®Œæˆæ ‡å®šï¼Œæ— éœ€è¿­ä»£ä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œå¯ä»¥é€‚åº”ä¸åŒçš„åœºæ™¯å’Œä¼ æ„Ÿå™¨é…ç½®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RobustCalibå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€ä¸‰ç»´é‡å»ºç­‰é¢†åŸŸã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œç²¾ç¡®çš„æ¿€å…‰é›·è¾¾-ç›¸æœºå¤–å‚æ ‡å®šæ˜¯ç¯å¢ƒæ„ŸçŸ¥çš„å…³é”®ï¼Œå¯ä»¥æé«˜è½¦è¾†å¯¹å‘¨å›´ç¯å¢ƒçš„ç†è§£èƒ½åŠ›ï¼Œä»è€Œæå‡é©¾é©¶å®‰å…¨æ€§ã€‚åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œå¯ä»¥å¸®åŠ©æœºå™¨äººå‡†ç¡®åœ°å®šä½è‡ªèº«ä½ç½®å’Œæ„å»ºå‘¨å›´ç¯å¢ƒåœ°å›¾ã€‚åœ¨ä¸‰ç»´é‡å»ºä¸­ï¼Œå¯ä»¥æé«˜é‡å»ºç²¾åº¦å’Œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current traditional methods for LiDAR-camera extrinsics estimation depend on offline targets and human efforts, while learning-based approaches resort to iterative refinement for calibration results, posing constraints on their generalization and application in on-board systems. In this paper, we propose a novel approach to address the extrinsic calibration problem in a robust, automatic, and single-shot manner. Instead of directly optimizing extrinsics, we leverage the consistency learning between LiDAR and camera to implement implicit re-calibartion. Specially, we introduce an appearance-consistency loss and a geometric-consistency loss to minimizing the inconsitency between the attrbutes (e.g., intensity and depth) of projected LiDAR points and the predicted ones. This design not only enhances adaptability to various scenarios but also enables a simple and efficient formulation during inference. We conduct comprehensive experiments on different datasets, and the results demonstrate that our method achieves accurate and robust performance. To promote further research and development in this area, we will release our model and code.

