---
layout: default
title: HERO: Hierarchical Extrapolation and Refresh for Efficient World Models
---

# HERO: Hierarchical Extrapolation and Refresh for Efficient World Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17588" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.17588v1</a>
  <a href="https://arxiv.org/pdf/2508.17588.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17588v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17588v1', 'HERO: Hierarchical Extrapolation and Refresh for Efficient World Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Quanjian Song, Xinyu Wang, Donghao Zhou, Jingyu Lin, Cunjian Chen, Yue Ma, Xiu Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25

**å¤‡æ³¨**: 12 pages in total

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHEROæ¡†æ¶ä»¥è§£å†³ä¸–ç•Œæ¨¡å‹æ¨ç†æ•ˆç‡ä½ä¸‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ä¸–ç•Œæ¨¡å‹` `æ‰©æ•£æ¨¡å‹` `æ¨ç†åŠ é€Ÿ` `åˆ†å±‚ç­–ç•¥` `ç‰¹å¾è€¦åˆ` `è™šæ‹Ÿç¯å¢ƒ` `ç”Ÿæˆæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç”Ÿæˆé©±åŠ¨ä¸–ç•Œæ¨¡å‹åœ¨æ¨ç†æ—¶é€Ÿåº¦è¾ƒæ…¢ï¼Œä¸»è¦ç”±äºæ‰©æ•£æ¨¡å‹çš„è¿­ä»£è®¡ç®—ç‰¹æ€§ã€‚
2. HEROæ¡†æ¶é€šè¿‡åˆ†å±‚ç­–ç•¥åŠ é€Ÿæ¨ç†ï¼Œæµ…å±‚é‡‡ç”¨è¡¥ä¸åˆ·æ–°æœºåˆ¶ï¼Œæ·±å±‚åˆ™ä½¿ç”¨çº¿æ€§å¤–æ¨æ–¹æ¡ˆã€‚
3. å®éªŒè¡¨æ˜ï¼ŒHEROå®ç°äº†1.73å€çš„é€Ÿåº¦æå‡ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒé«˜çš„ç”Ÿæˆè´¨é‡ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”Ÿæˆé©±åŠ¨çš„ä¸–ç•Œæ¨¡å‹èƒ½å¤Ÿåˆ›å»ºæ²‰æµ¸å¼è™šæ‹Ÿç¯å¢ƒï¼Œä½†ç”±äºæ‰©æ•£æ¨¡å‹çš„è¿­ä»£ç‰¹æ€§ï¼Œæ¨ç†é€Ÿåº¦è¾ƒæ…¢ã€‚å°½ç®¡è¿‘æœŸçš„ç ”ç©¶æå‡äº†æ‰©æ•£æ¨¡å‹çš„æ•ˆç‡ï¼Œä½†ç›´æ¥å°†è¿™äº›æŠ€æœ¯åº”ç”¨äºä¸–ç•Œæ¨¡å‹æ—¶ï¼Œå¸¸å¸¸ä¼šå¯¼è‡´è´¨é‡ä¸‹é™ã€‚æœ¬æ–‡æå‡ºäº†HEROï¼Œä¸€ä¸ªæ— éœ€è®­ç»ƒçš„åˆ†å±‚åŠ é€Ÿæ¡†æ¶ï¼Œæ—¨åœ¨æé«˜ä¸–ç•Œæ¨¡å‹çš„æ¨ç†æ•ˆç‡ã€‚HEROé€šè¿‡è¯†åˆ«ç‰¹å¾è€¦åˆç°è±¡ï¼Œé‡‡ç”¨åˆ†å±‚ç­–ç•¥åŠ é€Ÿæ¨ç†ï¼Œå…·ä½“åŒ…æ‹¬åœ¨æµ…å±‚ä½¿ç”¨è¡¥ä¸åˆ·æ–°æœºåˆ¶å’Œåœ¨æ·±å±‚ä½¿ç”¨çº¿æ€§å¤–æ¨æ–¹æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHEROå®ç°äº†1.73å€çš„é€Ÿåº¦æå‡ï¼Œä¸”è´¨é‡ä¸‹é™æå°ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„æ‰©æ•£åŠ é€Ÿæ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”Ÿæˆé©±åŠ¨ä¸–ç•Œæ¨¡å‹æ¨ç†æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚ç°æœ‰çš„æ‰©æ•£æ¨¡å‹åœ¨æ¨ç†æ—¶éœ€è¦å¤šæ¬¡è¿­ä»£è®¡ç®—ï¼Œå¯¼è‡´é€Ÿåº¦ç¼“æ…¢ï¼Œä¸”ç›´æ¥åº”ç”¨æ–°æŠ€æœ¯å¯èƒ½å¯¼è‡´ç”Ÿæˆè´¨é‡ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHEROæ¡†æ¶çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åˆ†å±‚ç­–ç•¥æ¥åŠ é€Ÿæ¨ç†è¿‡ç¨‹ã€‚é€šè¿‡è¯†åˆ«ç‰¹å¾è€¦åˆç°è±¡ï¼Œæµ…å±‚ç‰¹å¾å…·æœ‰é«˜æ—¶é—´å˜å¼‚æ€§ï¼Œè€Œæ·±å±‚ç‰¹å¾åˆ™æ›´ç¨³å®šï¼Œå› æ­¤å¯ä»¥é‡‡ç”¨ä¸åŒçš„åŠ é€Ÿç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHEROæ¡†æ¶åˆ†ä¸ºä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šåœ¨æµ…å±‚ï¼Œä½¿ç”¨è¡¥ä¸åˆ·æ–°æœºåˆ¶é«˜æ•ˆé€‰æ‹©éœ€è¦é‡æ–°è®¡ç®—çš„tokenï¼›åœ¨æ·±å±‚ï¼Œé‡‡ç”¨çº¿æ€§å¤–æ¨æ–¹æ¡ˆç›´æ¥ä¼°è®¡ä¸­é—´ç‰¹å¾ï¼Œä»è€Œé¿å…æ³¨æ„åŠ›æ¨¡å—å’Œå‰é¦ˆç½‘ç»œçš„è®¡ç®—ã€‚

**å…³é”®åˆ›æ–°**ï¼šHEROçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è®­ç»ƒæ— å…³çš„åˆ†å±‚åŠ é€Ÿç­–ç•¥ï¼Œç‰¹åˆ«æ˜¯åœ¨æµ…å±‚å’Œæ·±å±‚é‡‡ç”¨ä¸åŒçš„å¤„ç†æœºåˆ¶ï¼Œæ˜¾è‘—æé«˜äº†æ¨ç†é€Ÿåº¦è€Œä¸æŸå¤±ç”Ÿæˆè´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æµ…å±‚ï¼ŒHEROå®ç°äº†è¡¥ä¸é‡‡æ ·å’Œé¢‘ç‡æ„ŸçŸ¥è·Ÿè¸ªï¼Œé¿å…äº†é¢å¤–çš„åº¦é‡è®¡ç®—ï¼Œå¹¶ä¸FlashAttentionå…¼å®¹ï¼›åœ¨æ·±å±‚ï¼Œçº¿æ€§å¤–æ¨æ–¹æ¡ˆç›´æ¥ä¼°è®¡ç‰¹å¾ï¼Œå®Œå…¨ç»•è¿‡äº†æ³¨æ„åŠ›æ¨¡å—å’Œå‰é¦ˆç½‘ç»œçš„è®¡ç®—ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHEROæ¡†æ¶åœ¨æ¨ç†é€Ÿåº¦ä¸Šå®ç°äº†1.73å€çš„æå‡ï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆè´¨é‡çš„ç¨³å®šæ€§ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„æ‰©æ•£åŠ é€Ÿæ–¹æ³•ã€‚è¿™ä¸€æˆæœä¸ºç”Ÿæˆæ¨¡å‹çš„å®é™…åº”ç”¨æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

HEROæ¡†æ¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘å’Œè‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ç”Ÿæˆæ¨¡å‹çš„æ¨ç†æ•ˆç‡ï¼Œè¿›è€Œæ”¹å–„ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿå“åº”é€Ÿåº¦ã€‚æœªæ¥ï¼ŒHEROå¯èƒ½ä¼šæ¨åŠ¨æ›´é«˜æ•ˆçš„ä¸–ç•Œæ¨¡å‹è®¾è®¡ï¼Œä¿ƒè¿›æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generation-driven world models create immersive virtual environments but suffer slow inference due to the iterative nature of diffusion models. While recent advances have improved diffusion model efficiency, directly applying these techniques to world models introduces limitations such as quality degradation. In this paper, we present HERO, a training-free hierarchical acceleration framework tailored for efficient world models. Owing to the multi-modal nature of world models, we identify a feature coupling phenomenon, wherein shallow layers exhibit high temporal variability, while deeper layers yield more stable feature representations. Motivated by this, HERO adopts hierarchical strategies to accelerate inference: (i) In shallow layers, a patch-wise refresh mechanism efficiently selects tokens for recomputation. With patch-wise sampling and frequency-aware tracking, it avoids extra metric computation and remain compatible with FlashAttention. (ii) In deeper layers, a linear extrapolation scheme directly estimates intermediate features. This completely bypasses the computations in attention modules and feed-forward networks. Our experiments show that HERO achieves a 1.73$\times$ speedup with minimal quality degradation, significantly outperforming existing diffusion acceleration methods.

