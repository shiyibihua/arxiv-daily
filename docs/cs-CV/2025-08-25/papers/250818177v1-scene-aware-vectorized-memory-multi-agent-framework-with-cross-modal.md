---
layout: default
title: Scene-Aware Vectorized Memory Multi-Agent Framework with Cross-Modal Differentiated Quantization VLMs for Visually Impaired Assistance
---

# Scene-Aware Vectorized Memory Multi-Agent Framework with Cross-Modal Differentiated Quantization VLMs for Visually Impaired Assistance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18177" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18177v1</a>
  <a href="https://arxiv.org/pdf/2508.18177.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18177v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18177v1', 'Scene-Aware Vectorized Memory Multi-Agent Framework with Cross-Modal Differentiated Quantization VLMs for Visually Impaired Assistance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiangxiang Wang, Xuanyu Wang, YiJia Luo, Yongbin Yu, Manping Fan, Jingtao Zhang, Liyong Ren

**åˆ†ç±»**: cs.CV, cs.LG, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25

**å¤‡æ³¨**: 28 pages,9 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè·¨æ¨¡æ€å·®å¼‚åŒ–é‡åŒ–æ¡†æ¶ä»¥è§£å†³è§†è§‰éšœç¢è¾…åŠ©é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰éšœç¢è¾…åŠ©` `è·¨æ¨¡æ€é‡åŒ–` `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `åœºæ™¯æ„ŸçŸ¥` `å®æ—¶å¯¼èˆª` `æ–‡æœ¬è¯†åˆ«` `è®¡ç®—æ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è§†è§‰éšœç¢è¾…åŠ©é¢†åŸŸé¢ä¸´å†…å­˜éœ€æ±‚é«˜å’Œå“åº”é€Ÿåº¦æ…¢çš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å…¶å®ç”¨æ€§ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§è·¨æ¨¡æ€å·®å¼‚åŒ–é‡åŒ–æ¡†æ¶å’Œåœºæ™¯æ„ŸçŸ¥å‘é‡åŒ–è®°å¿†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä»¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨å’Œæå‡å“åº”é€Ÿåº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡åŒ–åçš„æ¨¡å‹åœ¨æ€§èƒ½ä¸Šä»…æœ‰å¾®å°ä¸‹é™ï¼ŒåŒæ—¶åœ¨å“åº”æ—¶é—´ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæå‡äº†ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŒé‡æŠ€æœ¯åˆ›æ–°æ¡†æ¶ï¼ŒåŒ…æ‹¬é’ˆå¯¹è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„è·¨æ¨¡æ€å·®å¼‚åŒ–é‡åŒ–æ¡†æ¶å’Œç”¨äºè§†è§‰éšœç¢è¾…åŠ©çš„åœºæ™¯æ„ŸçŸ¥å‘é‡åŒ–è®°å¿†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚è¯¥æ¨¡å—åŒ–æ¡†æ¶é€šè¿‡å®æ–½å·®å¼‚åŒ–å¤„ç†ç­–ç•¥ï¼Œæœ‰æ•ˆå°†å†…å­˜éœ€æ±‚ä»38GBé™ä½è‡³16GBï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½ã€‚å¤šæ™ºèƒ½ä½“æ¶æ„ç»“åˆäº†åœºæ™¯åˆ†ç±»ã€å‘é‡åŒ–è®°å¿†å’Œå¤šæ¨¡æ€äº¤äº’ï¼Œèƒ½å¤ŸæŒä¹…å­˜å‚¨å’Œé«˜æ•ˆæ£€ç´¢åœºæ™¯è®°å¿†ã€‚é€šè¿‡æ„ŸçŸ¥-è®°å¿†-æ¨ç†å·¥ä½œæµï¼Œç³»ç»Ÿæä¾›è¶…å‡ºå½“å‰è§†é‡çš„ç¯å¢ƒä¿¡æ¯ã€‚å®éªŒè¡¨æ˜ï¼Œé‡åŒ–åçš„19Bå‚æ•°æ¨¡å‹åœ¨MMBenchä¸Šä»…æœ‰2.05%çš„æ€§èƒ½ä¸‹é™ï¼Œå¹¶åœ¨OCR-VQAä¸Šä¿æŒ63.7çš„å‡†ç¡®ç‡ï¼Œè¶…è¶Šäº†å†…å­˜éœ€æ±‚ç›¸å½“çš„å°å‹æ¨¡å‹ã€‚è¯¥ç³»ç»Ÿåœ¨åœºæ™¯åˆ†æåˆ°åˆå§‹è¯­éŸ³è¾“å‡ºçš„å“åº”å»¶è¿Ÿä¿æŒåœ¨2.83-3.52ç§’ä¹‹é—´ï¼Œæ˜¾è‘—å¿«äºéæµå¼æ–¹æ³•ã€‚æ­¤ç ”ç©¶æ¨åŠ¨äº†è®¡ç®—æ•ˆç‡å’Œè¾…åŠ©æŠ€æœ¯çš„å‘å±•ï¼Œä¸ºè§†è§‰éšœç¢ç”¨æˆ·æä¾›å…¨é¢çš„å®æ—¶åœºæ™¯æ„ŸçŸ¥ã€æ–‡æœ¬è¯†åˆ«å’Œå¯¼èˆªæ”¯æŒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è§†è§‰éšœç¢è¾…åŠ©æŠ€æœ¯ä¸­å†…å­˜éœ€æ±‚è¿‡é«˜å’Œå“åº”é€Ÿåº¦ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡å†…å­˜ï¼Œå¯¼è‡´è®¾å¤‡ä¸ä¾¿æºå¸¦ï¼ŒåŒæ—¶å“åº”æ—¶é—´è¾ƒé•¿ï¼Œå½±å“ç”¨æˆ·ä½“éªŒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è·¨æ¨¡æ€å·®å¼‚åŒ–é‡åŒ–å’Œåœºæ™¯æ„ŸçŸ¥å‘é‡åŒ–è®°å¿†çš„ç»“åˆï¼Œæ¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨å¹¶æé«˜ç³»ç»Ÿçš„å“åº”é€Ÿåº¦ã€‚é€šè¿‡è¿™ç§è®¾è®¡ï¼Œç³»ç»Ÿèƒ½å¤Ÿåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½å†…å­˜éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè·¨æ¨¡æ€å·®å¼‚åŒ–é‡åŒ–æ¡†æ¶å’Œåœºæ™¯æ„ŸçŸ¥å‘é‡åŒ–è®°å¿†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚å‰è€…è´Ÿè´£ä¼˜åŒ–è§†è§‰-è¯­è¨€æ¨¡å‹çš„å†…å­˜ä½¿ç”¨ï¼Œåè€…åˆ™é€šè¿‡å¤šæ™ºèƒ½ä½“åä½œå®ç°å¯¹ç¯å¢ƒä¿¡æ¯çš„æ„ŸçŸ¥å’Œè®°å¿†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†è·¨æ¨¡æ€å·®å¼‚åŒ–é‡åŒ–ç­–ç•¥ï¼Œä½¿å¾—æ¨¡å‹åœ¨å¤§å¹…å‡å°‘å†…å­˜éœ€æ±‚çš„åŒæ—¶ï¼Œæ€§èƒ½æŸå¤±æå°ã€‚è¿™ä¸€åˆ›æ–°ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå…¶å¤„ç†ç­–ç•¥çš„çµæ´»æ€§å’Œé«˜æ•ˆæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæ¨¡å‹çš„å‚æ•°é‡ä¸º19Bï¼Œç»è¿‡é‡åŒ–å¤„ç†åï¼Œå†…å­˜éœ€æ±‚ä»38GBé™ä½è‡³16GBã€‚æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿åœ¨é™ä½å†…å­˜çš„åŒæ—¶ï¼Œä¿æŒæ¨¡å‹çš„å‡†ç¡®æ€§å’Œå“åº”é€Ÿåº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡åŒ–åçš„19Bå‚æ•°æ¨¡å‹åœ¨MMBenchä¸Šä»…æœ‰2.05%çš„æ€§èƒ½ä¸‹é™ï¼ŒOCR-VQAçš„å‡†ç¡®ç‡ä¸º63.7ï¼Œæ¥è¿‘åŸå§‹æ¨¡å‹çš„64.9ã€‚åŒæ—¶ï¼Œè¯¥ç³»ç»Ÿçš„å“åº”å»¶è¿Ÿåœ¨2.83-3.52ç§’ä¹‹é—´ï¼Œæ˜¾è‘—å¿«äºä¼ ç»Ÿéæµå¼æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½è¾…åŠ©è®¾å¤‡ã€å¯¼èˆªç³»ç»Ÿå’Œç¯å¢ƒæ„ŸçŸ¥æŠ€æœ¯ï¼Œå°¤å…¶é€‚ç”¨äºè§†è§‰éšœç¢äººå£«çš„æ—¥å¸¸ç”Ÿæ´»ã€‚é€šè¿‡æä¾›å®æ—¶çš„åœºæ™¯ä¿¡æ¯å’Œæ–‡æœ¬è¯†åˆ«ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ç”¨æˆ·çš„ç‹¬ç«‹æ€§å’Œç”Ÿæ´»è´¨é‡ï¼Œæœªæ¥å¯èƒ½åœ¨æ›´å¹¿æ³›çš„è¾…åŠ©æŠ€æœ¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This study proposes the dual technological innovation framework, including a cross-modal differ entiated quantization framework for vision-language models (VLMs) and a scene-aware vectorized
>   memory multi-agent system for visually impaired assistance. The modular framework was developed
>   implementing differentiated processing strategies, effectively reducing memory requirements from
>   38GB to 16GB while maintaining model performance. The multi-agent architecture combines
>   scene classification, vectorized memory, and multimodal interaction, enabling persistent storage
>   and efficient retrieval of scene memories. Through perception-memory-reasoning workflows, the
>   system provides environmental information beyond the current view using historical memories.
>   Experiments show the quantized 19B-parameter model only experiences a 2.05% performance drop
>   on MMBench and maintains 63.7 accuracy on OCR-VQA (original: 64.9), outperforming smaller
>   models with equivalent memory requirements like the Molmo-7B series. The system maintains
>   response latency between 2.83-3.52 seconds from scene analysis to initial speech output, substantially
>   faster than non-streaming methods. This research advances computational efficiency and assistive
>   technology, offering visually impaired users comprehensive real-time assistance in scene perception,
>   text recognition, and navigation.

