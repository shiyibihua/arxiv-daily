---
layout: default
title: TinyGiantVLM: A Lightweight Vision-Language Architecture for Spatial Reasoning under Resource Constraints
---

# TinyGiantVLM: A Lightweight Vision-Language Architecture for Spatial Reasoning under Resource Constraints

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17595" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.17595v1</a>
  <a href="https://arxiv.org/pdf/2508.17595.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17595v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17595v1', 'TinyGiantVLM: A Lightweight Vision-Language Architecture for Spatial Reasoning under Resource Constraints')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Vinh-Thuan Ly, Hoang M. Truong, Xuan-Huong Nguyen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25

**å¤‡æ³¨**: Accepted for presentation at the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops, 2025

**æœŸåˆŠ**: IEEE/CVF International Conference on Computer Vision (ICCV) Workshops, Hawaii, 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTinyGiantVLMä»¥è§£å†³å·¥ä¸šç¯å¢ƒä¸­çš„ç©ºé—´æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç©ºé—´æ¨ç†` `è§†è§‰-è¯­è¨€æ¨¡å‹` `æ··åˆä¸“å®¶` `å·¥ä¸šåº”ç”¨` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨ç†è§£ä¸‰ç»´å¸ƒå±€å’Œç‰©ä½“æ’åˆ—æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œéš¾ä»¥åº”å¯¹å¤æ‚çš„å·¥ä¸šç¯å¢ƒã€‚
2. TinyGiantVLMé€šè¿‡æ¨¡å—åŒ–è®¾è®¡å’Œæ··åˆä¸“å®¶èåˆæ¨¡å—ï¼Œæœ‰æ•ˆå¤„ç†é«˜æ¨¡æ€è¾“å…¥ï¼Œæå‡ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚
3. åœ¨AI City Challenge 2025ä¸­ï¼Œ64Må‚æ•°çš„åŸºç¡€æ¨¡å‹å–å¾—ç¬¬5åï¼Œå¾—åˆ†66.8861ï¼Œå±•ç¤ºäº†å…¶åœ¨ç©ºé—´æ¨ç†ä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ä»“å‚¨è§„æ¨¡ç¯å¢ƒä¸­ï¼Œç»†ç²’åº¦ç©ºé—´å…³ç³»æ¨ç†å¯¹ç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰æ„æˆäº†é‡å¤§æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ç†è§£ä¸‰ç»´å¸ƒå±€ã€ç‰©ä½“æ’åˆ—å’Œå¤šæ¨¡æ€çº¿ç´¢æ–¹é¢ã€‚æœ¬æ–‡æå‡ºäº†TinyGiantVLMï¼Œä¸€ä¸ªè½»é‡çº§å’Œæ¨¡å—åŒ–çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œä¸“ä¸ºç‰©ç†ç©ºé—´æ¨ç†è€Œè®¾è®¡ï¼ŒåŒºåˆ«äºå¤æ‚ç‰©æµåœºæ™¯ä¸­çš„ä¼ ç»Ÿåœ°ç†æ¨ç†ã€‚è¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰éª¨å¹²ç½‘ç»œï¼Œä»RGBå’Œæ·±åº¦æ¨¡æ€ä¸­ç¼–ç å…¨å±€å’ŒåŒºåŸŸçº§ç‰¹å¾ã€‚ä¸ºæœ‰æ•ˆå¤„ç†é«˜æ¨¡æ€è¾“å…¥å’Œå¤šæ ·åŒ–é—®é¢˜ç±»å‹ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ··åˆä¸“å®¶ï¼ˆMoEï¼‰èåˆæ¨¡å—ï¼ŒåŠ¨æ€ç»„åˆç©ºé—´è¡¨ç¤ºä»¥æ”¯æŒä¸‹æ¸¸æ¨ç†ä»»åŠ¡å¹¶æé«˜æ”¶æ•›æ€§ã€‚ç»è¿‡ä¸¤é˜¶æ®µè®­ç»ƒï¼Œæ¨¡å‹åœ¨AI City Challenge 2025çš„ç¬¬ä¸‰è½¨é“è¯„ä¼°ä¸­å–å¾—äº†ç¬¬5åçš„æˆç»©ï¼Œæ˜¾ç¤ºå‡ºåœ¨å·¥ä¸šç¯å¢ƒä¸­è§†è§‰æ„ŸçŸ¥ä¸ç©ºé—´ç†è§£çš„å¼ºå¤§è¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨ä»“å‚¨è§„æ¨¡ç¯å¢ƒä¸­è¿›è¡Œç»†ç²’åº¦ç©ºé—´æ¨ç†çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä¸‰ç»´å¸ƒå±€å’Œç‰©ä½“æ’åˆ—æ–¹é¢è¡¨ç°ä¸è¶³ï¼Œéš¾ä»¥é€‚åº”å¤æ‚çš„å·¥ä¸šåœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTinyGiantVLMé‡‡ç”¨è½»é‡çº§å’Œæ¨¡å—åŒ–çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œç»“åˆæ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å—ï¼ŒåŠ¨æ€èåˆç©ºé—´è¡¨ç¤ºï¼Œä»¥æ”¯æŒå¤šæ ·åŒ–çš„æ¨ç†ä»»åŠ¡ï¼Œæå‡æ¨¡å‹çš„æ”¶æ•›æ€§å’Œæ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µç”Ÿæˆè‡ªç”±å½¢å¼çš„ç­”æ¡ˆä»¥å¢å¼ºç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œç¬¬äºŒé˜¶æ®µä½¿ç”¨æ ‡å‡†åŒ–ç­”æ¡ˆè¿›è¡Œè¯„ä¼°ã€‚æ•´ä½“æ¶æ„åŒ…æ‹¬é¢„è®­ç»ƒçš„è§†è§‰éª¨å¹²ç½‘ç»œå’ŒMoEèåˆæ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†æ··åˆä¸“å®¶æ¨¡å—ï¼Œèƒ½å¤ŸåŠ¨æ€ç»„åˆä¸åŒçš„ç©ºé—´è¡¨ç¤ºï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰æ›´é«˜çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹å‚æ•°è®¾ç½®ä¸º64Må’Œ80Mï¼Œåè€…å…·æœ‰æ‰©å±•çš„MoEå®¹é‡ï¼Œé‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œç½‘ç»œç»“æ„ç»è¿‡ç²¾å¿ƒè®¾è®¡ä»¥é€‚åº”å¤šæ¨¡æ€è¾“å…¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨AI City Challenge 2025ä¸­ï¼ŒTinyGiantVLMçš„64Må‚æ•°åŸºç¡€æ¨¡å‹å–å¾—äº†ç¬¬5åï¼Œå¾—åˆ†66.8861ï¼Œæ˜¾ç¤ºå‡ºåœ¨å¤æ‚ç©ºé—´æ¨ç†ä»»åŠ¡ä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚80Må‚æ•°çš„å˜ä½“è¿›ä¸€æ­¥æå‡äº†æ€§èƒ½ï¼Œå±•ç¤ºäº†æ··åˆä¸“å®¶æ¨¡å—çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TinyGiantVLMçš„ç ”ç©¶æˆæœåœ¨ç‰©æµã€ä»“å‚¨ç®¡ç†å’Œæ™ºèƒ½åˆ¶é€ ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿä¼˜åŒ–ç‰©ä½“å¸ƒå±€ã€æå‡è‡ªåŠ¨åŒ–æ°´å¹³ï¼Œå¹¶ä¸ºæ™ºèƒ½æœºå™¨äººæä¾›æ›´å¥½çš„ç¯å¢ƒç†è§£èƒ½åŠ›ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨å·¥ä¸š4.0çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reasoning about fine-grained spatial relationships in warehouse-scale environments poses a significant challenge for existing vision-language models (VLMs), which often struggle to comprehend 3D layouts, object arrangements, and multimodal cues in real-world industrial settings. In this paper, we present TinyGiantVLM, a lightweight and modular two-stage framework designed for physical spatial reasoning, distinguishing itself from traditional geographic reasoning in complex logistics scenes. Our approach encodes both global and region-level features from RGB and depth modalities using pretrained visual backbones. To effectively handle the complexity of high-modality inputs and diverse question types, we incorporate a Mixture-of-Experts (MoE) fusion module, which dynamically combines spatial representations to support downstream reasoning tasks and improve convergence. Training is conducted in a two-phase strategy: the first phase focuses on generating free-form answers to enhance spatial reasoning ability, while the second phase uses normalized answers for evaluation. Evaluated on Track 3 of the AI City Challenge 2025, our 64M-parameter base model achieved 5th place on the leaderboard with a score of 66.8861, demonstrating strong performance in bridging visual perception and spatial understanding in industrial environments. We further present an 80M-parameter variant with expanded MoE capacity, which demonstrates improved performance on spatial reasoning tasks.

