---
layout: default
title: Propose and Rectify: A Forensics-Driven MLLM Framework for Image Manipulation Localization
---

# Propose and Rectify: A Forensics-Driven MLLM Framework for Image Manipulation Localization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17976" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.17976v1</a>
  <a href="https://arxiv.org/pdf/2508.17976.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17976v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17976v1', 'Propose and Rectify: A Forensics-Driven MLLM Framework for Image Manipulation Localization')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Keyang Zhang, Chenqi Kong, Hui Liu, Bo Ding, Xinghao Jiang, Haoliang Li

**ÂàÜÁ±ª**: cs.CV, eess.IV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-25

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Propose-RectifyÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥ÂõæÂÉèÁØ°ÊîπÂÆö‰ΩçÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂõæÂÉèÁØ°Êîπ` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `ÂèñËØÅÂàÜÊûê` `ËØ≠‰πâÊé®ÁêÜ` `Â¢ûÂº∫ÂàÜÂâ≤` `È≤ÅÊ£íÊÄß` `ÂÆö‰ΩçÁ≤æÂ∫¶`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®Ê£ÄÊµãÂõæÂÉèÁØ°ÊîπÊó∂ÔºåÈöæ‰ª•ÊçïÊçâÁªÜÂæÆÁöÑ‰ΩéÁ∫ßÂèñËØÅÁâπÂæÅÔºåÂØºËá¥ÂÆö‰ΩçÁ≤æÂ∫¶‰∏çË∂≥„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑPropose-RectifyÊ°ÜÊû∂ÁªìÂêà‰∫ÜËØ≠‰πâÊé®ÁêÜ‰∏éÂèñËØÅÂàÜÊûêÔºåÈÄöËøá‰∏§‰∏™Èò∂ÊÆµÂÆûÁé∞ÁØ°ÊîπÂå∫ÂüüÁöÑÂàùÊ≠•ÂÆö‰Ωç‰∏é‰øÆÊ≠£„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåËØ•Ê°ÜÊû∂Âú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äËææÂà∞ÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÊòæËëóÊèêÂçá‰∫ÜÊ£ÄÊµãÂáÜÁ°ÆÊÄßÂíåÂÆö‰ΩçÁ≤æÂ∫¶„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÂõæÂÉèÁØ°ÊîπÊäÄÊúØÁöÑÊó•ÁõäÂ§çÊùÇÔºåËø´ÂàáÈúÄË¶ÅÂèØÈù†ÁöÑÂèñËØÅËß£ÂÜ≥ÊñπÊ°àÔºåÊó¢ËÉΩÊ£ÄÊµã‰øÆÊîπÂèàËÉΩÁ≤æÁ°ÆÂÆö‰ΩçÁØ°ÊîπÂå∫Âüü„ÄÇËøëÊúüÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÂú®‰∏ä‰∏ãÊñáÊÑüÁü•Ê£ÄÊµãÊñπÈù¢Â±ïÁé∞Âá∫ÊΩúÂäõÔºå‰ΩÜÂú®ÊçïÊçâÁªÜÂæÆÁöÑ‰ΩéÁ∫ßÂèñËØÅÁâπÂæÅÊñπÈù¢‰ªçÊòæ‰∏çË∂≥„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑPropose-RectifyÊ°ÜÊû∂ÔºåÊúâÊïàÂú∞Â∞ÜËØ≠‰πâÊé®ÁêÜ‰∏éÂèñËØÅÁâπÂÆöÂàÜÊûêÁªìÂêà„ÄÇÂú®ÊèêËÆÆÈò∂ÊÆµÔºåÂà©Áî®ÈÄÇÂ∫îÂèñËØÅÁöÑLLaVAÊ®°ÂûãÁîüÊàêÂàùÊ≠•ÁöÑÁØ°ÊîπÂàÜÊûêÂíåÂèØÁñëÂå∫ÂüüÁöÑÂàùÊ≠•ÂÆö‰Ωç„ÄÇÂú®‰øÆÊ≠£Èò∂ÊÆµÔºåÂºïÂÖ•ÂèñËØÅ‰øÆÊ≠£Ê®°ÂùóÔºåÈÄöËøáÂ§öÂ∞∫Â∫¶ÂèñËØÅÁâπÂæÅÂàÜÊûêÁ≥ªÁªüÂú∞È™åËØÅÂíå‰ºòÂåñËøô‰∫õÂàùÊ≠•ÊèêËÆÆ„ÄÇÊ≠§Â§ñÔºåÂ¢ûÂº∫ÂàÜÂâ≤Ê®°ÂùóÂ∞ÜÂÖ≥ÈîÆÂèñËØÅÁ∫øÁ¥¢ËûçÂÖ•SAMÁöÑÁºñÁ†ÅÂõæÂÉèÂµåÂÖ•‰∏≠Ôºå‰ªéËÄåÂÖãÊúçÂõ∫ÊúâÁöÑËØ≠‰πâÂÅèÂ∑ÆÔºåÂÆûÁé∞ÂØπÁØ°ÊîπÂå∫ÂüüÁöÑÁ≤æÁ°ÆÂàíÂàÜ„ÄÇÈÄöËøáÂ∞ÜÂÖàËøõÁöÑÂ§öÊ®°ÊÄÅÊé®ÁêÜ‰∏éÊàêÁÜüÁöÑÂèñËØÅÊñπÊ≥ïÁõ∏ÁªìÂêàÔºåÁ°Æ‰øùÂàùÊ≠•ËØ≠‰πâÊèêËÆÆÈÄöËøáÂÖ∑‰ΩìÁöÑÊäÄÊúØËØÅÊçÆÂæóÂà∞Á≥ªÁªüÈ™åËØÅÂíåÂ¢ûÂº∫Ôºå‰ªéËÄåÂÆûÁé∞ÂÖ®Èù¢ÁöÑÊ£ÄÊµãÂáÜÁ°ÆÊÄßÂíåÂÆö‰ΩçÁ≤æÂ∫¶„ÄÇÂ§ßÈáèÂÆûÈ™åÈ™åËØÅË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Â§öÊ†∑ÂåñÊï∞ÊçÆÈõÜ‰∏äË°®Áé∞Âá∫Ëâ≤ÔºåÂÖ∑ÊúâÂçìË∂äÁöÑÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÂõæÂÉèÁØ°ÊîπÁöÑÊ£ÄÊµã‰∏éÂÆö‰ΩçÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ÊçïÊçâ‰ΩéÁ∫ßÂèñËØÅÁâπÂæÅÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÂØºËá¥ÂÆö‰ΩçÁ≤æÂ∫¶‰∏çÈ´ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫ÁöÑPropose-RectifyÊ°ÜÊû∂ÈÄöËøáÁªìÂêàËØ≠‰πâÊé®ÁêÜ‰∏éÂèñËØÅÂàÜÊûêÔºåÂàÜ‰∏∫ÊèêËÆÆÂíå‰øÆÊ≠£‰∏§‰∏™Èò∂ÊÆµÔºåÁ≥ªÁªüÊÄßÂú∞È™åËØÅÂíå‰ºòÂåñÁØ°ÊîπÂå∫ÂüüÁöÑÂÆö‰Ωç„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊ°ÜÊû∂ÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºöÊèêËÆÆÈò∂ÊÆµ‰ΩøÁî®LLaVAÊ®°ÂûãÁîüÊàêÂàùÊ≠•ÂàÜÊûêÔºå‰øÆÊ≠£Èò∂ÊÆµÈÄöËøáÂèñËØÅ‰øÆÊ≠£Ê®°ÂùóËøõË°åÂ§öÂ∞∫Â∫¶ÁâπÂæÅÂàÜÊûêÔºåÊúÄÂêéÈÄöËøáÂ¢ûÂº∫ÂàÜÂâ≤Ê®°ÂùóÂÆûÁé∞Á≤æÁ°ÆÂàíÂàÜ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÂ∞ÜËØ≠‰πâÊé®ÁêÜ‰∏éÂèñËØÅÁâπÂæÅÂàÜÊûêÁõ∏ÁªìÂêàÔºåÁ°Æ‰øùÂàùÊ≠•ÊèêËÆÆÈÄöËøáÂÖ∑‰ΩìÊäÄÊúØËØÅÊçÆÂæóÂà∞È™åËØÅÂíåÂ¢ûÂº∫ÔºåËøô‰∏ÄÊñπÊ≥ï‰∏éÁé∞ÊúâÊäÄÊúØÊúâÊú¨Ë¥®Âå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÂ§öÂ∞∫Â∫¶ÁâπÂæÅÂàÜÊûêÂíåÂ¢ûÂº∫ÂàÜÂâ≤Ê®°ÂùóÔºåÂÖ≥ÈîÆÂèÇÊï∞ËÆæÁΩÆÂíåÊçüÂ§±ÂáΩÊï∞ÁªèËøáÁ≤æÂøÉË∞ÉÊï¥Ôºå‰ª•Á°Æ‰øùÊ®°ÂûãÂú®‰∏çÂêåÊï∞ÊçÆÈõÜ‰∏äÁöÑÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPropose-RectifyÊ°ÜÊû∂Âú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÊ£ÄÊµãÂáÜÁ°ÆÁéáÊèêÂçá‰∫ÜXX%ÔºåÂÆö‰ΩçÁ≤æÂ∫¶ÊèêÈ´ò‰∫ÜYY%ÔºåÂ±ïÁé∞Âá∫ÂçìË∂äÁöÑÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÂü∫Á∫øÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êï∞Â≠óÂèñËØÅ„ÄÅÁ§æ‰∫§Â™í‰ΩìÂÜÖÂÆπÂÆ°Ê†∏ÂíåÊñ∞ÈóªÁúüÂÆûÊÄßÈ™åËØÅÁ≠â„ÄÇÈöèÁùÄÂõæÂÉèÁØ°ÊîπÊäÄÊúØÁöÑ‰∏çÊñ≠ÂèëÂ±ïÔºåÂáÜÁ°ÆÁöÑÁØ°ÊîπÊ£ÄÊµã‰∏éÂÆö‰ΩçÂ∞ÜÂØπÁª¥Êä§‰ø°ÊÅØÁöÑÁúüÂÆûÊÄßÂíåÂÆâÂÖ®ÊÄß‰∫ßÁîüÈáçË¶ÅÂΩ±ÂìçÔºåÂÖ∑ÊúâÂπøÊ≥õÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The increasing sophistication of image manipulation techniques demands robust forensic solutions that can both reliably detect alterations and precisely localize tampered regions. Recent Multimodal Large Language Models (MLLMs) show promise by leveraging world knowledge and semantic understanding for context-aware detection, yet they struggle with perceiving subtle, low-level forensic artifacts crucial for accurate manipulation localization. This paper presents a novel Propose-Rectify framework that effectively bridges semantic reasoning with forensic-specific analysis. In the proposal stage, our approach utilizes a forensic-adapted LLaVA model to generate initial manipulation analysis and preliminary localization of suspicious regions based on semantic understanding and contextual reasoning. In the rectification stage, we introduce a Forensics Rectification Module that systematically validates and refines these initial proposals through multi-scale forensic feature analysis, integrating technical evidence from several specialized filters. Additionally, we present an Enhanced Segmentation Module that incorporates critical forensic cues into SAM's encoded image embeddings, thereby overcoming inherent semantic biases to achieve precise delineation of manipulated regions. By synergistically combining advanced multimodal reasoning with established forensic methodologies, our framework ensures that initial semantic proposals are systematically validated and enhanced through concrete technical evidence, resulting in comprehensive detection accuracy and localization precision. Extensive experimental validation demonstrates state-of-the-art performance across diverse datasets with exceptional robustness and generalization capabilities.

