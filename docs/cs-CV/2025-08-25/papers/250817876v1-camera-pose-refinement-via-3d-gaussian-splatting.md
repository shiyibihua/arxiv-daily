---
layout: default
title: Camera Pose Refinement via 3D Gaussian Splatting
---

# Camera Pose Refinement via 3D Gaussian Splatting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17876" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.17876v1</a>
  <a href="https://arxiv.org/pdf/2508.17876.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17876v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17876v1', 'Camera Pose Refinement via 3D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lulu Hao, Lipu Zhou, Zhenzhong Wei, Xu Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGS-SMCä»¥è§£å†³ç›¸æœºå§¿æ€ç²¾ç¡®åº¦ä¸è¶³çš„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ç›¸æœºå§¿æ€ç²¾åŒ–` `3Dé«˜æ–¯ç‚¹äº‘` `è®¡ç®—æœºè§†è§‰` `è¿­ä»£ä¼˜åŒ–` `å‡ ä½•çº¦æŸ` `ç‰¹å¾æå–` `æœºå™¨äººå¯¼èˆª` `å¢å¼ºç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç›¸æœºå§¿æ€ç²¾åŒ–æ–¹æ³•ä¾èµ–äº2D-3Då¯¹åº”å…³ç³»ï¼Œå¯¼è‡´åœ¨ä¸åŒåœºæ™¯ä¸­éœ€é‡å»ºæˆ–é‡æ–°è®­ç»ƒï¼Œæ•ˆç‡ä½ä¸‹ã€‚
2. æœ¬æ–‡æå‡ºGS-SMCæ¡†æ¶ï¼Œåˆ©ç”¨3Dé«˜æ–¯ç‚¹äº‘è¿›è¡Œç›¸æœºå§¿æ€ç²¾åŒ–ï¼Œé¿å…äº†é¢å¤–è®­ç»ƒï¼Œé€‚åº”æ€§å¼ºã€‚
3. åœ¨7-Sceneså’Œå‰‘æ¡¥åœ°æ ‡æ•°æ®é›†ä¸Šï¼ŒGS-SMCåˆ†åˆ«å®ç°äº†53.3%å’Œ56.9%çš„å¹³ç§»å’Œæ—‹è½¬è¯¯å·®å‡å°‘ï¼Œæ•ˆæœæ˜¾è‘—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›¸æœºå§¿æ€ç²¾ç¡®åŒ–æ—¨åœ¨æé«˜3Dè®¡ç®—æœºè§†è§‰ä¸­åˆå§‹å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚å¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¾èµ–äº2D-3Då¯¹åº”å…³ç³»ï¼Œéœ€é’ˆå¯¹ä¸åŒæè¿°ç¬¦é‡å»ºåœºæ™¯æˆ–é‡æ–°è®­ç»ƒç½‘ç»œã€‚è™½ç„¶ä¸€äº›æ–°æ–¹æ³•é€šè¿‡ç‰¹å¾ç›¸ä¼¼æ€§æ¨æ–­å§¿æ€ï¼Œä½†ç¼ºä¹å‡ ä½•çº¦æŸå¯¼è‡´å‡†ç¡®æ€§ä¸è¶³ã€‚ä¸ºå…‹æœè¿™äº›é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç›¸æœºå§¿æ€ç²¾åŒ–æ¡†æ¶GS-SMCï¼Œåˆ©ç”¨3Dé«˜æ–¯ç‚¹äº‘ï¼ˆ3DGSï¼‰è¿›è¡Œä¼˜åŒ–ã€‚è¯¥æ–¹æ³•å¯ç›´æ¥åº”ç”¨äºå¤šç§åœºæ™¯ï¼Œæ— éœ€é¢å¤–è®­ç»ƒï¼Œé‡‡ç”¨è¿­ä»£ä¼˜åŒ–æ–¹æ³•ï¼Œé€šè¿‡æŸ¥è¯¢å›¾åƒä¸å¤šä¸ªæ¸²æŸ“å›¾åƒä¹‹é—´çš„æå‡ ä½•çº¦æŸæ¥ç²¾åŒ–ç›¸æœºå§¿æ€ã€‚å¤§é‡å®éªŒè¯æ˜ï¼ŒGS-SMCåœ¨7-Sceneså’Œå‰‘æ¡¥åœ°æ ‡æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåˆ†åˆ«å®ç°äº†53.3%å’Œ56.9%çš„ä¸­ä½å¹³ç§»å’Œæ—‹è½¬è¯¯å·®å‡å°‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ç›¸æœºå§¿æ€ç²¾åŒ–æ–¹æ³•åœ¨ä¸åŒåœºæ™¯ä¸­éœ€é‡å»ºæˆ–é‡æ–°è®­ç»ƒçš„é—®é¢˜ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œå‡†ç¡®æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºGS-SMCæ¡†æ¶ï¼Œåˆ©ç”¨3Dé«˜æ–¯ç‚¹äº‘ï¼ˆ3DGSï¼‰è¿›è¡Œç›¸æœºå§¿æ€ç²¾åŒ–ï¼Œé€šè¿‡è¿­ä»£ä¼˜åŒ–æ–¹æ³•ç»“åˆæå‡ ä½•çº¦æŸï¼Œæå‡å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGS-SMCæ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨ç°æœ‰çš„3DGSæ¨¡å‹æ¸²æŸ“æ–°è§†å›¾ï¼›å…¶æ¬¡ï¼Œé€šè¿‡æŸ¥è¯¢å›¾åƒä¸å¤šä¸ªæ¸²æŸ“å›¾åƒä¹‹é—´çš„æå‡ ä½•çº¦æŸè¿›è¡Œå§¿æ€ä¼˜åŒ–ï¼›æœ€åï¼Œçµæ´»é€‰æ‹©ç‰¹å¾æå–å™¨å’ŒåŒ¹é…å™¨ä»¥å»ºç«‹çº¦æŸã€‚

**å…³é”®åˆ›æ–°**ï¼šGS-SMCçš„åˆ›æ–°åœ¨äºåˆ©ç”¨3DGSæ¨¡å‹è¿›è¡Œç›¸æœºå§¿æ€ç²¾åŒ–ï¼Œé¿å…äº†å¯¹æ¯ä¸ªåœºæ™¯çš„é‡æ–°è®­ç»ƒï¼Œæ˜¾è‘—æé«˜äº†æ–¹æ³•çš„é€‚åº”æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†è¿­ä»£ä¼˜åŒ–ç®—æ³•ï¼Œç»“åˆäº†å¤šç§ç‰¹å¾æå–å™¨å’ŒåŒ¹é…å™¨çš„çµæ´»é€‰æ‹©ï¼Œç¡®ä¿äº†å‡ ä½•çº¦æŸçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

GS-SMCåœ¨7-Sceneså’Œå‰‘æ¡¥åœ°æ ‡æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œåˆ†åˆ«å®ç°äº†53.3%å’Œ56.9%çš„ä¸­ä½å¹³ç§»è¯¯å·®å‡å°‘ï¼Œä»¥åŠ40.7%å’Œ53.2%çš„ä¸­ä½æ—‹è½¬è¯¯å·®å‡å°‘ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨3Dè®¡ç®—æœºè§†è§‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æœºå™¨äººå¯¼èˆªã€å¢å¼ºç°å®å’Œè™šæ‹Ÿç°å®ç­‰åœºæ™¯ä¸­ã€‚é€šè¿‡æé«˜ç›¸æœºå§¿æ€çš„ç²¾ç¡®åº¦ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è¿™äº›åº”ç”¨çš„æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯æ‰©å±•åˆ°æ›´å¤šå¤æ‚åœºæ™¯å’ŒåŠ¨æ€ç¯å¢ƒä¸­ï¼Œè¿›ä¸€æ­¥æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Camera pose refinement aims at improving the accuracy of initial pose estimation for applications in 3D computer vision. Most refinement approaches rely on 2D-3D correspondences with specific descriptors or dedicated networks, requiring reconstructing the scene again for a different descriptor or fully retraining the network for each scene. Some recent methods instead infer pose from feature similarity, but their lack of geometry constraints results in less accuracy. To overcome these limitations, we propose a novel camera pose refinement framework leveraging 3D Gaussian Splatting (3DGS), referred to as GS-SMC. Given the widespread usage of 3DGS, our method can employ an existing 3DGS model to render novel views, providing a lightweight solution that can be directly applied to diverse scenes without additional training or fine-tuning. Specifically, we introduce an iterative optimization approach, which refines the camera pose using epipolar geometric constraints among the query and multiple rendered images. Our method allows flexibly choosing feature extractors and matchers to establish these constraints. Extensive empirical evaluations on the 7-Scenes and the Cambridge Landmarks datasets demonstrate that our method outperforms state-of-the-art camera pose refinement approaches, achieving 53.3% and 56.9% reductions in median translation and rotation errors on 7-Scenes, and 40.7% and 53.2% on Cambridge.

