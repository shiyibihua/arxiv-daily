---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-08-16
---

# cs.CVï¼ˆ2025-08-16ï¼‰

ğŸ“Š å…± **3** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250812081v2-vimorag-video-based-retrieval-augmented-3d-motion-generation-for-mot.html">VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion Language Models</a></td>
  <td>æå‡ºVimoRAGä»¥è§£å†³è¿åŠ¨è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">DPO</span> <span class="paper-tag">motion generation</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.12081v2" data-paper-url="./papers/250812081v2-vimorag-video-based-retrieval-augmented-3d-motion-generation-for-mot.html" onclick="toggleFavorite(this, '2508.12081v2', 'VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>2</td>
  <td><a href="./papers/250811886v1-evtp-ivs-effective-visual-token-pruning-for-unifying-instruction-vis.html">EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models</a></td>
  <td>æå‡ºEVTP-IVSä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­çš„è§†è§‰åˆ†å‰²æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11886v1" data-paper-url="./papers/250811886v1-evtp-ivs-effective-visual-token-pruning-for-unifying-instruction-vis.html" onclick="toggleFavorite(this, '2508.11886v1', 'EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>3</td>
  <td><a href="./papers/250811950v1-dynamicpose-real-time-and-robust-6d-object-pose-tracking-for-fast-mo.html">DynamicPose: Real-time and Robust 6D Object Pose Tracking for Fast-Moving Cameras and Objects</a></td>
  <td>æå‡ºDynamicPoseä»¥è§£å†³å¿«é€Ÿç§»åŠ¨ç›¸æœºå’Œç‰©ä½“çš„6Då§¿æ€è·Ÿè¸ªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">VIO</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11950v1" data-paper-url="./papers/250811950v1-dynamicpose-real-time-and-robust-6d-object-pose-tracking-for-fast-mo.html" onclick="toggleFavorite(this, '2508.11950v1', 'DynamicPose: Real-time and Robust 6D Object Pose Tracking for Fast-Moving Cameras and Objects')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)