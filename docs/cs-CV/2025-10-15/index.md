---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€»ï¼ˆwith DeepSeekï¼‰ - cs.CV - 2025-10-15
---

# cs.CVï¼ˆ2025-10-15ï¼‰

ğŸ“Š å…± **119** ç¯‡è®ºæ–‡


| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 1 | [PhysMaster: Mastering Physical Representation for Video Generation via Reinforcement Learning](./papers/251013809v1-physmaster-mastering-physical-representation-for-video-generation-vi.html) | æå‡ºPhysMasteré€šè¿‡å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‰©ç†è¡¨ç¤ºï¼Œä»¥å¢å¼ºè§†é¢‘ç”Ÿæˆçš„ç‰©ç†åˆç†æ€§ |  |
| 2 | [VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models](./papers/251013808v1-viscop-visual-probing-for-video-domain-adaptation-of-vision-language.html) | æå‡ºVisCoPæ–¹æ³•ï¼Œé€šè¿‡è§†è§‰æ¢é’ˆå®ç°è§†è§‰è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆè§†é¢‘é¢†åŸŸé€‚åº” |  |
| 3 | [Generative Universal Verifier as Multimodal Meta-Reasoner](./papers/251013804v1-generative-universal-verifier-as-multimodal-meta-reasoner.html) | æå‡ºç”Ÿæˆå¼é€šç”¨éªŒè¯å™¨ä½œä¸ºå¤šæ¨¡æ€å…ƒæ¨ç†å™¨ï¼Œå¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹çš„å¯é åæ€ä¸ä¼˜åŒ–èƒ½åŠ›ã€‚ |  |
| 4 | [Trace Anything: Representing Any Video in 4D via Trajectory Fields](./papers/251013802v1-trace-anything-representing-any-video-in-4d-via-trajectory-fields.html) | æå‡ºè½¨è¿¹åœºè¡¨ç¤ºæ³•ï¼Œé€šè¿‡å•æ¬¡å‰é¦ˆé¢„æµ‹è§†é¢‘åƒç´ è½¨è¿¹ï¼Œæå‡åŠ¨æ€å»ºæ¨¡æ•ˆç‡ã€‚ |  |
| 5 | [Reasoning in Space via Grounding in the World](./papers/251013800v1-reasoning-in-space-via-grounding-in-the-world.html) | æå‡ºGS-Reasonerä»¥è§£å†³3Dè§†è§‰å®šä½ä¸ç©ºé—´æ¨ç†çš„èåˆé—®é¢˜ |  |
| 6 | [The Mechanistic Emergence of Symbol Grounding in Language Models](./papers/251013796v1-the-mechanistic-emergence-of-symbol-grounding-in-language-models.html) | æå‡ºå—æ§è¯„ä¼°æ¡†æ¶ä»¥æ­ç¤ºè¯­è¨€æ¨¡å‹ä¸­ç¬¦å·æ¥åœ°çš„æ¶Œç°æœºåˆ¶ |  |
| 7 | [Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs](./papers/251013795v1-bee-a-high-quality-corpus-and-full-stack-suite-to-unlock-advanced-fu.html) | æå‡ºé«˜è´¨é‡æ•°æ®é›†ä¸å…¨æ ˆå·¥å…·å¥—ä»¶ä»¥æå‡å…¨å¼€æ”¾å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½ |  |
| 8 | [MimicKit: A Reinforcement Learning Framework for Motion Imitation and Control](./papers/251013794v1-mimickit-a-reinforcement-learning-framework-for-motion-imitation-and.html) | æå‡ºMimicKitæ¡†æ¶ï¼Œç”¨äºè¿åŠ¨æ¨¡ä»¿ä¸æ§åˆ¶ï¼Œæ”¯æŒè®¡ç®—æœºå›¾å½¢å’Œæœºå™¨äººç ”ç©¶ã€‚ |  |
| 9 | [NoisePrints: Distortion-Free Watermarks for Authorship in Private Diffusion Models](./papers/251013793v1-noiseprints-distortion-free-watermarks-for-authorship-in-private-dif.html) | æå‡ºNoisePrintsæ°´å°æ–¹æ¡ˆï¼Œåˆ©ç”¨éšæœºç§å­åœ¨ç§æœ‰æ‰©æ•£æ¨¡å‹ä¸­å®ç°æ— å¤±çœŸä½œè€…è®¤è¯ |  |
| 10 | [Adaptive Visual Conditioning for Semantic Consistency in Diffusion-Based Story Continuation](./papers/251013787v1-adaptive-visual-conditioning-for-semantic-consistency-in-diffusion-b.html) | æå‡ºè‡ªé€‚åº”è§†è§‰æ¡ä»¶æ¡†æ¶ä»¥è§£å†³æ‰©æ•£æ•…äº‹å»¶ç»­ä¸­çš„è¯­ä¹‰ä¸€è‡´æ€§é—®é¢˜ |  |
| 11 | [InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy](./papers/251013778v1-internvla-m1-a-spatially-guided-vision-language-action-framework-for.html) | æå‡ºInternVLA-M1æ¡†æ¶ï¼Œé€šè¿‡ç©ºé—´å¼•å¯¼è®­ç»ƒæå‡é€šç”¨æœºå™¨äººæŒ‡ä»¤è·Ÿéšèƒ½åŠ› |  |
| 12 | [UrbanFusion: Stochastic Multimodal Fusion for Contrastive Learning of Robust Spatial Representations](./papers/251013774v1-urbanfusion-stochastic-multimodal-fusion-for-contrastive-learning-of.html) | æå‡ºUrbanFusionæ¨¡å‹ï¼Œé€šè¿‡éšæœºå¤šæ¨¡æ€èåˆå­¦ä¹ ç¨³å¥ç©ºé—´è¡¨ç¤ºä»¥é¢„æµ‹åŸå¸‚ç°è±¡ |  |
| 13 | [Scaling Vision Transformers for Functional MRI with Flat Maps](./papers/251013768v1-scaling-vision-transformers-for-functional-mri-with-flat-maps.html) | æå‡ºåŸºäºæ‰å¹³å›¾çš„è§†è§‰å˜æ¢å™¨ï¼Œç”¨äºåŠŸèƒ½ç£å…±æŒ¯æˆåƒè§†é¢‘åˆ†æ |  |
| 14 | [Uni-MMMU: A Massive Multi-discipline Multimodal Unified Benchmark](./papers/251013759v1-uni-mmmu-a-massive-multi-discipline-multimodal-unified-benchmark.html) | æå‡ºUni-MMMUåŸºå‡†ä»¥è¯„ä¼°å¤šé¢†åŸŸå¤šæ¨¡æ€ç»Ÿä¸€æ¨¡å‹çš„ç”Ÿæˆä¸ç†è§£åŒå‘ååŒ |  |
| 15 | [RECODE: Reasoning Through Code Generation for Visual Question Answering](./papers/251013756v1-recode-reasoning-through-code-generation-for-visual-question-answeri.html) | æå‡ºRECODEæ¡†æ¶ï¼Œé€šè¿‡ä»£ç ç”Ÿæˆè§£å†³å¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨å›¾è¡¨æ¨ç†ä¸­çš„éªŒè¯é—®é¢˜ |  |
| 16 | [InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue](./papers/251013747v1-interactiveomni-a-unified-omni-modal-model-for-audio-visual-multi-tu.html) | æå‡ºInteractiveOmniç»Ÿä¸€å…¨æ¨¡æ€æ¨¡å‹ï¼Œç”¨äºéŸ³é¢‘-è§†è§‰å¤šè½®å¯¹è¯ï¼Œå®ç°è½»é‡çº§æ™ºèƒ½äº¤äº’ã€‚ |  |
| 17 | [UniCalli: A Unified Diffusion Framework for Column-Level Generation and Recognition of Chinese Calligraphy](./papers/251013745v1-unicalli-a-unified-diffusion-framework-for-column-level-generation-a.html) | æå‡ºUniCalliç»Ÿä¸€æ‰©æ•£æ¡†æ¶ï¼Œè§£å†³ä¸­æ–‡ä¹¦æ³•åˆ—çº§ç”Ÿæˆä¸è¯†åˆ«é—®é¢˜ |  |
| 18 | [Multi-Scale High-Resolution Logarithmic Grapher Module for Efficient Vision GNNs](./papers/251013740v1-multi-scale-high-resolution-logarithmic-grapher-module-for-efficient.html) | æå‡ºLogViGæ¨¡å‹ï¼Œé€šè¿‡LSGCå›¾æ„å»ºæ–¹æ³•æå‡è§†è§‰å›¾ç¥ç»ç½‘ç»œæ•ˆç‡ä¸æ€§èƒ½ã€‚ |  |
| 19 | [Cyclic Self-Supervised Diffusion for Ultra Low-field to High-field MRI Synthesis](./papers/251013735v1-cyclic-self-supervised-diffusion-for-ultra-low-field-to-high-field-m.html) | æå‡ºå¾ªç¯è‡ªç›‘ç£æ‰©æ•£æ¡†æ¶ä»¥è§£å†³ä½åœºåˆ°é«˜åœºMRIåˆæˆä¸­çš„è§£å‰–ä¿çœŸåº¦é—®é¢˜ |  |
| 20 | [LiFMCR: Dataset and Benchmark for Light Field Multi-Camera Registration](./papers/251013729v1-lifmcr-dataset-and-benchmark-for-light-field-multi-camera-registrati.html) | æå‡ºLiFMCRæ•°æ®é›†ä¸åŸºå‡†ä»¥è§£å†³å¤šç›¸æœºå…‰åœºæ³¨å†Œé—®é¢˜ |  |
| 21 | [NExT-OMNI: Towards Any-to-Any Omnimodal Foundation Models with Discrete Flow Matching](./papers/251013721v1-next-omni-towards-any-to-any-omnimodal-foundation-models-with-discre.html) | æå‡ºNExT-OMNIæ¨¡å‹ï¼Œé€šè¿‡ç¦»æ•£æµåŒ¹é…å®ç°ä»»æ„æ¨¡æ€é—´ç†è§£ä¸ç”Ÿæˆ |  |
| 22 | [Circle of Willis Centerline Graphs: A Dataset and Baseline Algorithm](./papers/251013720v1-circle-of-willis-centerline-graphs-a-dataset-and-baseline-algorithm.html) | æå‡ºåŸºäºU-Netå’ŒA*ç®—æ³•çš„åŸºçº¿æ–¹æ³•ï¼Œç”¨äºä»è„‘åŠ¨è„‰å›¾åƒä¸­æå–ä¸­å¿ƒçº¿å›¾ï¼Œä»¥è§£å†³å¤æ‚å‡ ä½•ä¸‹çš„å¯é ä¸­å¿ƒçº¿æå–é—®é¢˜ã€‚ |  |
| 23 | [Dedelayed: Deleting remote inference delay via on-device correction](./papers/251013714v1-dedelayed-deleting-remote-inference-delay-via-on-device-correction.html) | æå‡ºDedelayedæ–¹æ³•ï¼Œé€šè¿‡æœ¬åœ°æ ¡æ­£ç¼“è§£è¿œç¨‹æ¨ç†å»¶è¿Ÿï¼Œå®ç°å®æ—¶è¾“å‡ºã€‚ |  |
| 24 | [Simplicial Embeddings Improve Sample Efficiency in Actor-Critic Agents](./papers/251013704v1-simplicial-embeddings-improve-sample-efficiency-in-actor-critic-agen.html) | æå‡ºå•çº¯å½¢åµŒå…¥ä»¥æå‡æ¼”å‘˜-è¯„è®ºå®¶æ–¹æ³•çš„æ ·æœ¬æ•ˆç‡ |  |
| 25 | [MVCustom: Multi-View Customized Diffusion via Geometric Latent Rendering and Completion](./papers/251013702v1-mvcustom-multi-view-customized-diffusion-via-geometric-latent-render.html) | æå‡ºMVCustomæ¡†æ¶ä»¥è§£å†³å¤šè§†è§’ç”Ÿæˆä¸å®šåˆ¶åŒ–ç»Ÿä¸€é—®é¢˜ |  |
| 26 | [Risk-adaptive Activation Steering for Safe Multimodal Large Language Models](./papers/251013698v1-risk-adaptive-activation-steering-for-safe-multimodal-large-language.html) | æå‡ºé£é™©è‡ªé€‚åº”æ¿€æ´»å¼•å¯¼ä»¥è§£å†³å¤šæ¨¡æ€å¤§æ¨¡å‹çš„å®‰å…¨å¯¹é½é—®é¢˜ |  |
| 27 | [Hierarchical Discrete Lattice Assembly: An Approach for the Digital Fabrication of Scalable Macroscale Structures](./papers/251013686v1-hierarchical-discrete-lattice-assembly-an-approach-for-the-digital-f.html) | æå‡ºåˆ†å±‚ç¦»æ•£æ™¶æ ¼ç»„è£…æ–¹æ³•ï¼Œä»¥è§£å†³å¤§è§„æ¨¡ç»“æ„æ•°å­—åˆ¶é€ ä¸­çš„å¤æ‚æ€§ä¸å¯é æ€§é—®é¢˜ã€‚ |  |
| 28 | [Generating healthy counterfactuals with denoising diffusion bridge models](./papers/251013684v1-generating-healthy-counterfactuals-with-denoising-diffusion-bridge-m.html) | æå‡ºåŸºäºå»å™ªæ‰©æ•£æ¡¥æ¨¡å‹çš„å¥åº·åäº‹å®ç”Ÿæˆæ–¹æ³•ï¼Œä»¥æ”¹è¿›åŒ»å­¦å›¾åƒå¼‚å¸¸æ£€æµ‹ã€‚ |  |
| 29 | [FlashWorld: High-quality 3D Scene Generation within Seconds](./papers/251013678v1-flashworld-high-quality-3d-scene-generation-within-seconds.html) | æå‡ºFlashWorldä»¥å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡3Dåœºæ™¯ï¼Œä»å•å›¾æˆ–æ–‡æœ¬æç¤ºåœ¨ç§’çº§å®Œæˆ |  |
| 30 | [Seeing and Knowing in the Wild: Open-domain Visual Entity Recognition with Large-scale Knowledge Graphs via Contrastive Learning](./papers/251013675v1-seeing-and-knowing-in-the-wild-open-domain-visual-entity-recognition.html) | æå‡ºçŸ¥è¯†å¼•å¯¼å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œè§£å†³å¼€æ”¾åŸŸè§†è§‰å®ä½“è¯†åˆ«ä¸­çš„é›¶æ ·æœ¬å’Œé•¿å°¾é—®é¢˜ã€‚ |  |
| 31 | [NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results](./papers/251013670v1-ntire-2025-challenge-on-low-light-image-enhancement-methods-and-resu.html) | ç»¼è¿°NTIRE 2025ä½å…‰å›¾åƒå¢å¼ºæŒ‘æˆ˜çš„æ–¹æ³•ä¸ç»“æœï¼Œè¯„ä¼°å…ˆè¿›ç½‘ç»œæ€§èƒ½ã€‚ |  |
| 32 | [CanvasMAR: Improving Masked Autoregressive Video Generation With Canvas](./papers/251013669v1-canvasmar-improving-masked-autoregressive-video-generation-with-canv.html) | æå‡ºCanvasMARä»¥è§£å†³è§†é¢‘æ©ç è‡ªå›å½’ç”Ÿæˆä¸­çš„æ…¢å¯åŠ¨å’Œè¯¯å·®ç´¯ç§¯é—®é¢˜ |  |
| 33 | [OmniGaze: Reward-inspired Generalizable Gaze Estimation In The Wild](./papers/251013660v1-omnigaze-reward-inspired-generalizable-gaze-estimation-in-the-wild.html) | æå‡ºOmniGazeåŠç›‘ç£æ¡†æ¶ï¼Œåˆ©ç”¨æœªæ ‡è®°æ•°æ®æå‡3Dè§†çº¿ä¼°è®¡çš„è·¨åŸŸæ³›åŒ–èƒ½åŠ› |  |
| 34 | [On Your Own: Pro-level Autonomous Drone Racing in Uninstrumented Arenas](./papers/251013644v1-on-your-own-pro-level-autonomous-drone-racing-in-uninstrumented-aren.html) | æå‡ºè‡ªä¸»æ— äººæœºç«é€Ÿç³»ç»Ÿï¼Œåœ¨æ— å¤–éƒ¨è¿½è¸ªç¯å¢ƒä¸­åŒ¹é…ä¸“ä¸šé£è¡Œå‘˜æ€§èƒ½ |  |
| 35 | [Towards Adversarial Robustness and Uncertainty Quantification in DINOv2-based Few-Shot Anomaly Detection](./papers/251013643v1-towards-adversarial-robustness-and-uncertainty-quantification-in-din.html) | è¯„ä¼°DINOv2å°æ ·æœ¬å¼‚å¸¸æ£€æµ‹çš„å¯¹æŠ—é²æ£’æ€§å’Œä¸ç¡®å®šæ€§é‡åŒ–ï¼Œæå‡ºåå¤„ç†æ ¡å‡†åŸºçº¿ |  |
| 36 | [Challenges, Advances, and Evaluation Metrics in Medical Image Enhancement: A Systematic Literature Review](./papers/251013638v1-challenges-advances-and-evaluation-metrics-in-medical-image-enhancem.html) | ç³»ç»Ÿç»¼è¿°åŒ»å­¦å›¾åƒå¢å¼ºçš„æŒ‘æˆ˜ã€è¿›å±•ä¸è¯„ä¼°æŒ‡æ ‡ï¼ŒåŸºäº39é¡¹ç ”ç©¶åˆ†æã€‚ |  |
| 37 | [AVAR-Net: A Lightweight Audio-Visual Anomaly Recognition Framework with a Benchmark Dataset](./papers/251013630v1-avar-net-a-lightweight-audio-visual-anomaly-recognition-framework-wi.html) | æå‡ºAVAR-Netè½»é‡çº§éŸ³è§†é¢‘å¼‚å¸¸è¯†åˆ«æ¡†æ¶ï¼Œè§£å†³è§†è§‰å•æ¨¡æ€åœ¨æ¶åŠ£æ¡ä»¶ä¸‹çš„ä¸å¯é é—®é¢˜ã€‚ |  |
| 38 | [LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models](./papers/251013626v1-libero-plus-in-depth-robustness-analysis-of-vision-language-action-m.html) | åˆ†æè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨ä¸ƒç»´æ‰°åŠ¨ä¸‹çš„é²æ£’æ€§å¼±ç‚¹ |  |
| 39 | [A Modular Object Detection System for Humanoid Robots Using YOLO](./papers/251013625v1-a-modular-object-detection-system-for-humanoid-robots-using-yolo.html) | æå‡ºåŸºäºYOLOv9çš„æ¨¡å—åŒ–ç‰©ä½“æ£€æµ‹ç³»ç»Ÿï¼Œç”¨äºäººå½¢æœºå™¨äººè§†è§‰ä»»åŠ¡ã€‚ |  |
| 40 | [Fusion Meets Diverse Conditions: A High-diversity Benchmark and Baseline for UAV-based Multimodal Object Detection with Condition Cues](./papers/251013620v1-fusion-meets-diverse-conditions-a-high-diversity-benchmark-and-basel.html) | æå‡ºPCDFæ–¹æ³•ä»¥è§£å†³æ— äººæœºå¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹åœ¨å¤šæ ·æ¡ä»¶ä¸‹çš„è‡ªé€‚åº”èåˆé—®é¢˜ |  |
| 41 | [Characterizing Lidar Point-Cloud Adversities Using a Vector Field Visualization](./papers/251013619v1-characterizing-lidar-point-cloud-adversities-using-a-vector-field-vi.html) | æå‡ºå‘é‡åœºå¯è§†åŒ–æ–¹æ³•ä»¥è¾…åŠ©ç¦»çº¿åˆ†ææ¿€å…‰é›·è¾¾ç‚¹äº‘é…å‡†ä¸­çš„é€†å¢ƒæ¨¡å¼ |  |
| 42 | [Efficient Force and Stiffness Prediction in Robotic Produce Handling with a Piezoresistive Pressure Sensor](./papers/251013616v1-efficient-force-and-stiffness-prediction-in-robotic-produce-handling.html) | æå‡ºåŸºäºå‹é˜»å‹åŠ›ä¼ æ„Ÿå™¨çš„åŠ›ä¸åˆšåº¦é¢„æµ‹æ–¹æ³•ï¼Œç”¨äºæœºå™¨äººæŠ“å–å†œäº§å“ |  |
| 43 | [PlanarMesh: Building Compact 3D Meshes from LiDAR using Incremental Adaptive Resolution Reconstruction](./papers/251013599v1-planarmesh-building-compact-3d-meshes-from-lidar-using-incremental-a.html) | æå‡ºPlanarMeshç³»ç»Ÿï¼Œé€šè¿‡è‡ªé€‚åº”åˆ†è¾¨ç‡é‡å»ºå®ç°ç´§å‡‘å®æ—¶3D LiDARå»ºå›¾ |  |
| 44 | [Active Tactile Exploration for Rigid Body Pose and Shape Estimation](./papers/251013595v1-active-tactile-exploration-for-rigid-body-pose-and-shape-estimation.html) | æå‡ºä¸»åŠ¨è§¦è§‰æ¢ç´¢æ¡†æ¶ï¼Œä½¿ç”¨è§¦è§‰æ•°æ®é«˜æ•ˆä¼°è®¡åˆšä½“å§¿æ€ä¸å½¢çŠ¶ |  |
| 45 | [Development of an Intuitive GUI for Non-Expert Teleoperation of Humanoid Robots](./papers/251013594v1-development-of-an-intuitive-gui-for-non-expert-teleoperation-of-huma.html) | å¼€å‘ç›´è§‚GUIä»¥ç®€åŒ–éä¸“å®¶å¯¹äººå½¢æœºå™¨äººçš„é¥æ“ä½œ |  |
| 46 | [XD-RCDepth: Lightweight Radar-Camera Depth Estimation with Explainability-Aligned and Distribution-Aware Distillation](./papers/251013565v1-xd-rcdepth-lightweight-radar-camera-depth-estimation-with-explainabi.html) | æå‡ºXD-RCDepthè½»é‡é›·è¾¾-ç›¸æœºæ·±åº¦ä¼°è®¡æ–¹æ³•ï¼Œé€šè¿‡å¯è§£é‡Šæ€§å¯¹é½å’Œåˆ†å¸ƒæ„ŸçŸ¥è’¸é¦æå‡æ€§èƒ½ã€‚ |  |
| 47 | [An efficient approach with theoretical guarantees to simultaneously reconstruct activity and attenuation sinogram for TOF-PET](./papers/251013562v1-an-efficient-approach-with-theoretical-guarantees-to-simultaneously-.html) | æå‡ºåŸºäºæœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„æ¨¡å‹ï¼Œä»TOF-PETå‘å°„æ•°æ®åŒæ—¶é‡å»ºæ´»æ€§å’Œè¡°å‡æ­£å¼¦å›¾ |  |
| 48 | [Modeling Cultural Bias in Facial Expression Recognition with Adaptive Agents](./papers/251013557v1-modeling-cultural-bias-in-facial-expression-recognition-with-adaptiv.html) | æå‡ºåŸºäºè‡ªé€‚åº”ä»£ç†çš„æµå¼åŸºå‡†ï¼Œé‡åŒ–æ–‡åŒ–åè§ä¸æ¨¡ç³Šå¯¹è¡¨æƒ…è¯†åˆ«é²æ£’æ€§çš„å½±å“ |  |
| 49 | [Hoecken-D Hand: A Novel Robotic Hand for Linear Parallel Pinching and Self-Adaptive Grasping](./papers/251013553v1-hoecken-d-hand-a-novel-robotic-hand-for-linear-parallel-pinching-and.html) | æå‡ºHoecken-Dæ‰‹çˆªï¼Œç»“åˆæ”¹è¿›Hoeckenè¿æ†ä¸å·®åŠ¨å¼¹ç°§æœºåˆ¶ï¼Œå®ç°çº¿æ€§å¹³è¡Œå¤¹æŒå’Œè‡ªé€‚åº”æŠ“å–ã€‚ |  |
| 50 | [Accelerated Feature Detectors for Visual SLAM: A Comparative Study of FPGA vs GPU](./papers/251013546v1-accelerated-feature-detectors-for-visual-slam-a-comparative-study-of.html) | æ¯”è¾ƒFPGAä¸GPUåœ¨è§†è§‰SLAMä¸­åŠ é€Ÿç‰¹å¾æ£€æµ‹çš„æ€§èƒ½ä¸èƒ½æ•ˆ |  |
| 51 | [Learning Neural Parametric 3D Breast Shape Models for Metrical Surface Reconstruction From Monocular RGB Videos](./papers/251013540v1-learning-neural-parametric-3d-breast-shape-models-for-metrical-surfa.html) | æå‡ºå±€éƒ¨éšå¼ç¥ç»å‚æ•°3Dä¹³æˆ¿å½¢çŠ¶æ¨¡å‹ï¼Œç”¨äºä»å•ç›®RGBè§†é¢‘é‡å»ºåº¦é‡å‡†ç¡®è¡¨é¢ |  |
| 52 | [A Novel Robot Hand with Hoeckens Linkages and Soft Phalanges for Scooping and Self-Adaptive Grasping in Environmental Constraints](./papers/251013535v1-a-novel-robot-hand-with-hoeckens-linkages-and-soft-phalanges-for-sco.html) | æå‡ºHockens-Aæœºæ¢°æ‰‹ä»¥åœ¨ç¯å¢ƒçº¦æŸä¸‹å®ç°è‡ªé€‚åº”æŠ“å– |  |
| 53 | [High Semantic Features for the Continual Learning of Complex Emotions: a Lightweight Solution](./papers/251013534v1-high-semantic-features-for-the-continual-learning-of-complex-emotion.html) | æå‡ºåŸºäºåŠ¨ä½œå•å…ƒçš„é«˜è¯­ä¹‰ç‰¹å¾æ–¹æ³•ï¼Œä»¥è½»é‡æ¨¡å‹è§£å†³å¤æ‚æƒ…æ„Ÿè¯†åˆ«çš„æŒç»­å­¦ä¹ é—®é¢˜ã€‚ |  |
| 54 | [UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning](./papers/251013515v1-unime-v2-mllm-as-a-judge-for-universal-multimodal-embedding-learning.html) | æå‡ºUniME-V2æ¨¡å‹ï¼Œåˆ©ç”¨MLLMä½œä¸ºè¯„åˆ¤è€…å¢å¼ºå¤šæ¨¡æ€åµŒå…¥å­¦ä¹ ï¼Œè§£å†³è¯­ä¹‰å·®å¼‚æ•æ‰å’Œè´Ÿæ ·æœ¬å¤šæ ·æ€§é—®é¢˜ã€‚ |  |
| 55 | [ExpressNet-MoE: A Hybrid Deep Neural Network for Emotion Recognition](./papers/251013493v1-expressnet-moe-a-hybrid-deep-neural-network-for-emotion-recognition.html) | æå‡ºExpressNet-MoEæ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ä»¥è§£å†³é¢éƒ¨æƒ…æ„Ÿè¯†åˆ«ä¸­çš„æ³›åŒ–ä¸é€‚åº”æ€§é—®é¢˜ |  |
| 56 | [Bridge the Gap: Enhancing Quadruped Locomotion with Vertical Ground Perturbations](./papers/251013488v1-bridge-the-gap-enhancing-quadruped-locomotion-with-vertical-ground-p.html) | æå‡ºåœ¨æŒ¯è¡æ¡¥ä¸Šè®­ç»ƒå››è¶³æœºå™¨äººä»¥å¢å¼ºå‚ç›´åœ°é¢æ‰°åŠ¨ä¸‹çš„è¿åŠ¨é²æ£’æ€§ |  |
| 57 | [Through the Lens of Doubt: Robust and Efficient Uncertainty Estimation for Visual Place Recognition](./papers/251013464v1-through-the-lens-of-doubt-robust-and-efficient-uncertainty-estimatio.html) | æå‡ºä¸‰ç§å…è®­ç»ƒä¸ç¡®å®šæ€§æŒ‡æ ‡ä»¥æå‡è§†è§‰åœ°ç‚¹è¯†åˆ«çš„é²æ£’æ€§ |  |
| 58 | [Physics-Informed Neural Network Modeling of Vehicle Collision Dynamics in Precision Immobilization Technique Maneuvers](./papers/251013461v1-physics-informed-neural-network-modeling-of-vehicle-collision-dynami.html) | æå‡ºåŒç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œæ¡†æ¶ä»¥è§£å†³è½¦è¾†ç¢°æ’åŠ¨åŠ›å­¦é¢„æµ‹ä¸­çš„æ•ˆç‡ä¸ç²¾åº¦æƒè¡¡é—®é¢˜ |  |
| 59 | [VIST3A: Text-to-3D by Stitching a Multi-view Reconstruction Network to a Video Generator](./papers/251013454v1-vist3a-text-to-3d-by-stitching-a-multi-view-reconstruction-network-t.html) | æå‡ºVIST3Aæ¡†æ¶ï¼Œé€šè¿‡ç¼åˆæ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆå™¨ä¸3Dé‡å»ºç½‘ç»œå®ç°æ–‡æœ¬åˆ°3Dç”Ÿæˆ |  |
| 60 | [Near-Infrared Hyperspectral Imaging Applications in Food Analysis -- Improving Algorithms and Methodologies](./papers/251013452v1-near-infrared-hyperspectral-imaging-applications-in-food-analysis-im.html) | æ”¹è¿›è¿‘çº¢å¤–é«˜å…‰è°±æˆåƒç®—æ³•ï¼Œæå‡é£Ÿå“è´¨é‡åˆ†ææ€§èƒ½ |  |
| 61 | [Real-Time Knee Angle Prediction Using EMG and Kinematic Data with an Attention-Based CNN-LSTM Network and Transfer Learning Across Multiple Datasets](./papers/251013443v1-real-time-knee-angle-prediction-using-emg-and-kinematic-data-with-an.html) | æå‡ºåŸºäºæ³¨æ„åŠ›CNN-LSTMå’Œè¿ç§»å­¦ä¹ çš„æ¡†æ¶ï¼Œç”¨äºå®æ—¶è†å…³èŠ‚è§’åº¦é¢„æµ‹ï¼Œé€‚åº”å¤šæ•°æ®é›†å’Œåº·å¤åœºæ™¯ã€‚ |  |
| 62 | [Steerable Conditional Diffusion for Domain Adaptation in PET Image Reconstruction](./papers/251013441v1-steerable-conditional-diffusion-for-domain-adaptation-in-pet-image-r.html) | æå‡ºå¯å¼•å¯¼æ¡ä»¶æ‰©æ•£æ–¹æ³•ä»¥è§£å†³PETå›¾åƒé‡å»ºä¸­çš„åŸŸé€‚åº”é—®é¢˜ |  |
| 63 | [Beyond Pixels: A Differentiable Pipeline for Probing Neuronal Selectivity in 3D](./papers/251013433v1-beyond-pixels-a-differentiable-pipeline-for-probing-neuronal-selecti.html) | æå‡ºå¯å¾®åˆ†æ¸²æŸ“ç®¡é“ä»¥åœ¨3Dä¸­æ¢ç´¢ç¥ç»å…ƒé€‰æ‹©æ€§ |  |
| 64 | [CoDS: Enhancing Collaborative Perception in Heterogeneous Scenarios via Domain Separation](./papers/251013432v1-cods-enhancing-collaborative-perception-in-heterogeneous-scenarios-v.html) | æå‡ºCoDSæ–¹æ³•ï¼Œé€šè¿‡åŸŸåˆ†ç¦»è§£å†³å¼‚æ„åœºæ™¯ä¸­çš„åä½œæ„ŸçŸ¥ç‰¹å¾å·®å¼‚é—®é¢˜ |  |
| 65 | [Ultra High-Resolution Image Inpainting with Patch-Based Content Consistency Adapter](./papers/251013419v1-ultra-high-resolution-image-inpainting-with-patch-based-content-cons.html) | æå‡ºPatch-Adapteræ¡†æ¶ä»¥è§£å†³è¶…é«˜åˆ†è¾¨ç‡å›¾åƒä¿®å¤ä¸­çš„å†…å®¹ä¸€è‡´æ€§å’Œæç¤ºå¯¹é½é—®é¢˜ |  |
| 66 | [Reinforcement Learning Meets Masked Generative Models: Mask-GRPO for Text-to-Image Generation](./papers/251013418v1-reinforcement-learning-meets-masked-generative-models-mask-grpo-for-.html) | æå‡ºMask-GRPOä»¥å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ©ç ç”Ÿæˆæ¨¡å‹ç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ |  |
| 67 | [Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models](./papers/251013394v1-spatial-dise-a-unified-benchmark-for-evaluating-spatial-reasoning-in.html) | æå‡ºSpatial-DISEåŸºå‡†ä»¥è¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹çš„ç©ºé—´æ¨ç†èƒ½åŠ› |  |
| 68 | [Generalizing WiFi Gesture Recognition via Large-Model-Aware Semantic Distillation and Alignment](./papers/251013390v1-generalizing-wifi-gesture-recognition-via-large-model-aware-semantic.html) | æå‡ºGLSDAæ¡†æ¶ä»¥å¢å¼ºWiFiæ‰‹åŠ¿è¯†åˆ«çš„æ³›åŒ–èƒ½åŠ›å’Œè¯­ä¹‰è¡¨è¾¾ã€‚ |  |
| 69 | [Leveraging 2D Priors and SDF Guidance for Dynamic Urban Scene Rendering](./papers/251013381v1-leveraging-2d-priors-and-sdf-guidance-for-dynamic-urban-scene-render.html) | æå‡ºç»“åˆ2Då…ˆéªŒä¸SDFçš„3Dé«˜æ–¯æ³¼æº…æ–¹æ³•ï¼Œæå‡åŠ¨æ€åŸå¸‚åœºæ™¯æ¸²æŸ“ç²¾åº¦ |  |
| 70 | [DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning](./papers/251013375v1-depthvla-enhancing-vision-language-action-models-with-depth-aware-sp.html) | æå‡ºDepthVLAä»¥å¢å¼ºè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„ç©ºé—´æ¨ç†èƒ½åŠ› |  |
| 71 | [A New Perspective on Transformers in Online Reinforcement Learning for Continuous Control](./papers/251013367v1-a-new-perspective-on-transformers-in-online-reinforcement-learning-f.html) | æå‡ºTransformeræ¶æ„ä¸è®­ç»ƒç­–ç•¥ï¼Œç”¨äºåœ¨çº¿æ— æ¨¡å‹å¼ºåŒ–å­¦ä¹ çš„è¿ç»­æ§åˆ¶ä»»åŠ¡ã€‚ |  |
| 72 | [Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity](./papers/251013364v1-language-as-a-label-zero-shot-multimodal-classification-of-everyday-.html) | ç ”ç©¶æç¤ºè®¾è®¡å¯¹é›¶æ ·æœ¬å¤šæ¨¡æ€åˆ†ç±»çš„å½±å“ï¼Œå‘ç°ç®€å•æç¤ºåœ¨æ•°æ®ç¨€ç¼ºä¸‹è¡¨ç°æ›´ä¼˜ã€‚ |  |
| 73 | [Improving Visual Recommendation on E-commerce Platforms Using Vision-Language Models](./papers/251013359v1-improving-visual-recommendation-on-e-commerce-platforms-using-vision.html) | æå‡ºåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„è§†è§‰æ¨èæ–¹æ³•ï¼Œä»¥æå‡ç”µå•†å¹³å°äº§å“å‘ç°æ•ˆç‡ã€‚ |  |
| 74 | [Adversarial Fine-tuning in Offline-to-Online Reinforcement Learning for Robust Robot Control](./papers/251013358v1-adversarial-fine-tuning-in-offline-to-online-reinforcement-learning-.html) | æå‡ºå¯¹æŠ—æ€§å¾®è°ƒæ¡†æ¶ä»¥å¢å¼ºç¦»çº¿å¼ºåŒ–å­¦ä¹ åœ¨æœºå™¨äººæ§åˆ¶ä¸­çš„é²æ£’æ€§ |  |
| 75 | [MODUR: A Modular Dual-reconfigurable Robot](./papers/251013356v1-modur-a-modular-dual-reconfigurable-robot.html) | æå‡ºMODURæ¨¡å—åŒ–åŒå¯é‡æ„æœºå™¨äººï¼Œé›†æˆæ¨¡å—é—´å’Œæ¨¡å—å†…é‡æ„ä»¥å¢å¼ºé€‚åº”æ€§ã€‚ |  |
| 76 | [No-Reference Rendered Video Quality Assessment: Dataset and Metrics](./papers/251013349v1-no-reference-rendered-video-quality-assessment-dataset-and-metrics.html) | æå‡ºæ— å‚è€ƒæ¸²æŸ“è§†é¢‘è´¨é‡è¯„ä¼°æ•°æ®é›†ä¸æŒ‡æ ‡ï¼Œä»¥è§£å†³æ¸²æŸ“è§†é¢‘ä¸­æ—¶é—´ä¼ªå½±é—®é¢˜ã€‚ |  |
| 77 | [Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models](./papers/251013331v1-group-wise-optimization-for-self-extensible-codebooks-in-vector-quan.html) | æå‡ºGroup-VQä»¥è§£å†³VQæ¨¡å‹ç æœ¬å´©æºƒé—®é¢˜ï¼Œæå‡é‡å»ºè´¨é‡ä¸ç æœ¬çµæ´»æ€§ã€‚ |  |
| 78 | [DEF-YOLO: Leveraging YOLO for Concealed Weapon Detection in Thermal Imagin](./papers/251013326v1-def-yolo-leveraging-yolo-for-concealed-weapon-detection-in-thermal-i.html) | æå‡ºDEF-YOLOä¸TICWæ•°æ®é›†ä»¥è§£å†³çƒ­æˆåƒéšè”½æ­¦å™¨æ£€æµ‹é—®é¢˜ |  |
| 79 | [Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation](./papers/251013324v1-tactile-conditioned-diffusion-policy-for-force-aware-robotic-manipul.html) | æå‡ºFARMæ¡†æ¶ï¼Œé€šè¿‡è§¦è§‰æ¡ä»¶æ‰©æ•£ç­–ç•¥è§£å†³æ¥è§¦ä¸°å¯Œæ“ä½œä¸­çš„åŠ›æ§åˆ¶é—®é¢˜ã€‚ |  |
| 80 | [Removing Cost Volumes from Optical Flow Estimators](./papers/251013317v1-removing-cost-volumes-from-optical-flow-estimators.html) | æå‡ºè®­ç»ƒç­–ç•¥ä»¥ç§»é™¤å…‰æµä¼°è®¡å™¨ä¸­çš„ä»£ä»·ä½“ç§¯ï¼Œæå‡æ¨ç†é€Ÿåº¦ä¸å†…å­˜æ•ˆç‡ã€‚ |  |
| 81 | [Visual Interestingness Decoded: How GPT-4o Mirrors Human Interests](./papers/251013316v1-visual-interestingness-decoded-how-gpt-4o-mirrors-human-interests.html) | æ¢ç´¢GPT-4oåœ¨è§†è§‰æœ‰è¶£æ€§è¯„ä¼°ä¸­ä¸äººç±»çš„éƒ¨åˆ†å¯¹é½ï¼Œç”¨äºå›¾åƒå¯¹æ ‡æ³¨å’ŒçŸ¥è¯†è’¸é¦ã€‚ |  |
| 82 | [Self-Augmented Visual Contrastive Decoding](./papers/251013315v1-self-augmented-visual-contrastive-decoding.html) | æå‡ºè‡ªå¢å¼ºè§†è§‰å¯¹æ¯”è§£ç ç­–ç•¥ï¼Œä»¥è§£å†³å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹å¹»è§‰é—®é¢˜ |  |
| 83 | [InstantSfM: Fully Sparse and Parallel Structure-from-Motion](./papers/251013310v1-instantsfm-fully-sparse-and-parallel-structure-from-motion.html) | æå‡ºå…¨ç¨€ç–å¹¶è¡ŒSfMæ–¹æ³•ä»¥åŠ é€Ÿå¤§è§„æ¨¡åœºæ™¯é‡å»º |  |
| 84 | [Novel Class Discovery for Point Cloud Segmentation via Joint Learning of Causal Representation and Reasoning](./papers/251013307v1-novel-class-discovery-for-point-cloud-segmentation-via-joint-learnin.html) | æå‡ºè”åˆå­¦ä¹ å› æœè¡¨ç¤ºä¸æ¨ç†æ–¹æ³•ä»¥è§£å†³ç‚¹äº‘åˆ†å‰²ä¸­çš„æ–°ç±»å‘ç°é—®é¢˜ |  |
| 85 | [Automated document processing system for government agencies using DBNET++ and BART models](./papers/251013303v1-automated-document-processing-system-for-government-agencies-using-d.html) | æå‡ºåŸºäºDBNet++å’ŒBARTçš„è‡ªåŠ¨æ–‡æ¡£åˆ†ç±»ç³»ç»Ÿï¼Œç”¨äºæ”¿åºœæœºæ„å¤„ç†å¤šæºå›¾åƒæ–‡æ¡£ã€‚ |  |
| 86 | [DAMM-LOAM: Degeneracy Aware Multi-Metric LiDAR Odometry and Mapping](./papers/251013287v1-damm-loam-degeneracy-aware-multi-metric-lidar-odometry-and-mapping.html) | æå‡ºDAMM-LOAMä»¥è§£å†³LiDAR SLAMåœ¨ç¨€ç–ç‰¹å¾å’Œé‡å¤ç»“æ„ç¯å¢ƒä¸­çš„ä½å§¿ä¼°è®¡é€€åŒ–é—®é¢˜ |  |
| 87 | [ALOHA2 Robot Kitchen Application Scenario Reproduction Report](./papers/251013284v1-aloha2-robot-kitchen-application-scenario-reproduction-report.html) | å¢å¼ºALOHA2æœºå™¨äººï¼Œæå‡å¨æˆ¿åœºæ™¯ä¸­çš„æ€§èƒ½å’Œäººä½“å·¥å­¦è®¾è®¡ |  |
| 88 | [Universal Image Restoration Pre-training via Masked Degradation Classification](./papers/251013282v1-universal-image-restoration-pre-training-via-masked-degradation-clas.html) | æå‡ºMaskDCPTé¢„è®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡æ©ç é€€åŒ–åˆ†ç±»å®ç°é€šç”¨å›¾åƒæ¢å¤ã€‚ |  |
| 89 | [MMLongCite: A Benchmark for Evaluating Fidelity of Long-Context Vision-Language Models](./papers/251013276v1-mmlongcite-a-benchmark-for-evaluating-fidelity-of-long-context-visio.html) | æå‡ºMMLongCiteåŸºå‡†ä»¥è¯„ä¼°é•¿ä¸Šä¸‹æ–‡è§†è§‰è¯­è¨€æ¨¡å‹çš„å¿ å®æ€§ |  |
| 90 | [End-to-End Multi-Modal Diffusion Mamba](./papers/251013253v1-end-to-end-multi-modal-diffusion-mamba.html) | æå‡ºå¤šæ¨¡æ€æ‰©æ•£Mambaä»¥ç»Ÿä¸€å¤šæ¨¡æ€å¤„ç†ï¼Œæå‡é«˜ç»´æ•°æ®ç”Ÿæˆæ€§èƒ½ã€‚ |  |
| 91 | [Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs](./papers/251013251v1-map-the-flow-revealing-hidden-pathways-of-information-in-videollms.html) | æ­ç¤ºVideoLLMsä¿¡æ¯æµæœºåˆ¶ä»¥æå‡è§†é¢‘é—®ç­”æ€§èƒ½ä¸å¯è§£é‡Šæ€§ |  |
| 92 | [Real-Time Crowd Counting for Embedded Systems with Lightweight Architecture](./papers/251013250v1-real-time-crowd-counting-for-embedded-systems-with-lightweight-archi.html) | æå‡ºè½»é‡çº§æ¶æ„å®ç°åµŒå…¥å¼ç³»ç»Ÿä¸Šçš„è¶…å®æ—¶äººç¾¤è®¡æ•°ï¼Œå…¼é¡¾é€Ÿåº¦ä¸ç²¾åº¦ |  |
| 93 | [CymbaDiff: Structured Spatial Diffusion for Sketch-based 3D Semantic Urban Scene Generation](./papers/251013245v1-cymbadiff-structured-spatial-diffusion-for-sketch-based-3d-semantic-.html) | æå‡ºCymbaDiffä»¥å¢å¼ºæˆ·å¤–3Dè¯­ä¹‰åœºæ™¯ç”Ÿæˆçš„ç©ºé—´ä¸€è‡´æ€§ |  |
| 94 | [FlyAwareV2: A Multimodal Cross-Domain UAV Dataset for Urban Scene Understanding](./papers/251013243v1-flyawarev2-a-multimodal-cross-domain-uav-dataset-for-urban-scene-und.html) | æå‡ºFlyAwareV2å¤šæ¨¡æ€æ— äººæœºæ•°æ®é›†ä»¥è§£å†³åŸå¸‚åœºæ™¯ç†è§£ä¸­æ•°æ®æ”¶é›†å›°éš¾é—®é¢˜ |  |
| 95 | [Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models](./papers/251013237v1-model-agnostic-adversarial-attack-and-defense-for-vision-language-ac.html) | æå‡ºæ¨¡å‹æ— å…³çš„å¯¹æŠ—æ”»å‡»EDPAä¸é˜²å¾¡ç­–ç•¥ï¼Œæå‡è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„é²æ£’æ€§ã€‚ |  |
| 96 | [EPIPTrack: Rethinking Prompt Modeling with Explicit and Implicit Prompts for Multi-Object Tracking](./papers/251013235v1-epiptrack-rethinking-prompt-modeling-with-explicit-and-implicit-prom.html) | æå‡ºEPIPTrackæ¡†æ¶ï¼Œåˆ©ç”¨æ˜¾å¼å’Œéšå¼æç¤ºè§£å†³å¤šç›®æ ‡è·Ÿè¸ªä¸­è¯­ä¹‰æç¤ºé€‚åº”æ€§ä¸è¶³é—®é¢˜ã€‚ |  |
| 97 | [UniVector: Unified Vector Extraction via Instance-Geometry Interaction](./papers/251013234v1-univector-unified-vector-extraction-via-instance-geometry-interactio.html) | æå‡ºUniVectoræ¡†æ¶ï¼Œé€šè¿‡å®ä¾‹-å‡ ä½•äº¤äº’ç»Ÿä¸€æå–å¤šç§å‘é‡ç±»å‹ |  |
| 98 | [What "Not" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging](./papers/251013232v1-what-not-to-detect-negation-aware-vlms-via-structured-reasoning-and-.html) | æå‡ºNegToMeå’ŒCoVANDä»¥è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¦å®šç†è§£ä¸­çš„è‚¯å®šåè§é—®é¢˜ |  |
| 99 | [Sample-Centric Multi-Task Learning for Detection and Segmentation of Industrial Surface Defects](./papers/251013226v1-sample-centric-multi-task-learning-for-detection-and-segmentation-of.html) | æå‡ºæ ·æœ¬ä¸­å¿ƒå¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ä»¥è§£å†³å·¥ä¸šè¡¨é¢ç¼ºé™·æ£€æµ‹ä¸­çš„æ ·æœ¬çº§å†³ç­–ä¸ç¨³å®šé—®é¢˜ |  |
| 100 | [Prompt-based Adaptation in Large-scale Vision Models: A Survey](./papers/251013219v1-prompt-based-adaptation-in-large-scale-vision-models-a-survey.html) | æå‡ºæç¤ºé€‚åº”ç»Ÿä¸€æ¡†æ¶ï¼Œç³»ç»Ÿåˆ†ç±»è§†è§‰æ¨¡å‹è½»é‡è°ƒä¼˜æ–¹æ³•ã€‚ |  |
| 101 | [MimicParts: Part-aware Style Injection for Speech-Driven 3D Motion Generation](./papers/251013208v1-mimicparts-part-aware-style-injection-for-speech-driven-3d-motion-ge.html) | æå‡ºMimicPartsæ¡†æ¶ä»¥è§£å†³è¯­éŸ³é©±åŠ¨3Dè¿åŠ¨ç”Ÿæˆä¸­çš„é£æ ¼å¤šæ ·æ€§å’ŒåŒºåŸŸå·®å¼‚é—®é¢˜ |  |
| 102 | [Paper Copilot: Tracking the Evolution of Peer Review in AI Conferences](./papers/251013201v1-paper-copilot-tracking-the-evolution-of-peer-review-in-ai-conference.html) | æå‡ºPaper Copilotç³»ç»Ÿä»¥è§£å†³AIä¼šè®®åŒè¡Œè¯„å®¡çš„é€æ˜åº¦å’Œå¯è¿½æº¯æ€§é—®é¢˜ |  |
| 103 | [Complementary Information Guided Occupancy Prediction via Multi-Level Representation Fusion](./papers/251013198v1-complementary-information-guided-occupancy-prediction-via-multi-leve.html) | æå‡ºCIGOccæ¡†æ¶ï¼Œé€šè¿‡å¤šçº§è¡¨ç¤ºèåˆæå‡è‡ªåŠ¨é©¾é©¶ä¸­åŸºäºç›¸æœºçš„3Då ç”¨é¢„æµ‹æ€§èƒ½ã€‚ |  |
| 104 | [STT-GS: Sample-Then-Transmit Edge Gaussian Splatting with Joint Client Selection and Power Control](./papers/251013186v1-stt-gs-sample-then-transmit-edge-gaussian-splatting-with-joint-clien.html) | æå‡ºSTT-GSç­–ç•¥ï¼Œé€šè¿‡è”åˆå®¢æˆ·ç«¯é€‰æ‹©ä¸åŠŸç‡æ§åˆ¶ä¼˜åŒ–è¾¹ç¼˜é«˜æ–¯æ³¼æº…åœºæ™¯é‡å»ºè´¨é‡ |  |
| 105 | [DP-TTA: Test-time Adaptation for Transient Electromagnetic Signal Denoising via Dictionary-driven Prior Regularization](./papers/251013160v1-dp-tta-test-time-adaptation-for-transient-electromagnetic-signal-den.html) | æå‡ºDP-TTAæ–¹æ³•ï¼Œé€šè¿‡å­—å…¸é©±åŠ¨å…ˆéªŒæ­£åˆ™åŒ–æå‡ç¬å˜ç”µç£ä¿¡å·å»å™ªçš„æµ‹è¯•æ—¶é€‚åº”æ€§ |  |
| 106 | [Foveation Improves Payload Capacity in Steganography](./papers/251013151v1-foveation-improves-payload-capacity-in-steganography.html) | æå‡ºåŸºäºæ³¨è§†ç‚¹æ¸²æŸ“çš„éšå†™æ–¹æ³•ï¼Œæå‡è§†è§‰åª’ä½“ä¸­æœ‰æ•ˆè½½è·å®¹é‡ã€‚ |  |
| 107 | [RoboHiMan: A Hierarchical Evaluation Paradigm for Compositional Generalization in Long-Horizon Manipulation](./papers/251013149v1-robohiman-a-hierarchical-evaluation-paradigm-for-compositional-gener.html) | æå‡ºRoboHiManåˆ†å±‚è¯„ä¼°èŒƒå¼ä»¥è§£å†³é•¿è§†é‡æ“ä½œä¸­çš„ç»„åˆæ³›åŒ–é—®é¢˜ |  |
| 108 | [Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN](./papers/251013137v1-real-time-sign-language-to-text-translation-using-deep-learning-a-co.html) | æ¯”è¾ƒ3D CNNä¸LSTMåœ¨å®æ—¶ç¾å›½æ‰‹è¯­è¯†åˆ«ä¸­çš„æ€§èƒ½ï¼Œå¼ºè°ƒç²¾åº¦ä¸æ•ˆç‡æƒè¡¡ã€‚ |  |
| 109 | [OS-HGAdapter: Open Semantic Hypergraph Adapter for Large Language Models Assisted Entropy-Enhanced Image-Text Alignment](./papers/251013131v1-os-hgadapter-open-semantic-hypergraph-adapter-for-large-language-mod.html) | æå‡ºOS-HGAdapterï¼Œåˆ©ç”¨LLMå¢å¼ºæ–‡æœ¬ç†µå’Œè¶…å›¾é€‚é…å™¨è§£å†³å›¾æ–‡å¯¹é½ä¸å¹³è¡¡é—®é¢˜ |  |
| 110 | [Safe Driving in Occluded Environments](./papers/251013114v1-safe-driving-in-occluded-environments.html) | æå‡ºæ¦‚ç‡å®‰å…¨è¯ä¹¦ä»¥è§£å†³é®æŒ¡ç¯å¢ƒä¸­çš„æ½œåœ¨é£é™©é—®é¢˜ |  |
| 111 | [VPREG: An Optimal Control Formulation for Diffeomorphic Image Registration Based on the Variational Principle Grid Generation Method](./papers/251013109v1-vpreg-an-optimal-control-formulation-for-diffeomorphic-image-registr.html) | æå‡ºVPregæ–¹æ³•ä»¥ä¼˜åŒ–è„‘å›¾åƒé…å‡†ï¼Œç¡®ä¿å˜æ¢å¯é€†ä¸”æ— æŠ˜å ã€‚ |  |
| 112 | [DriveCritic: Towards Context-Aware, Human-Aligned Evaluation for Autonomous Driving with Vision-Language Models](./papers/251013108v1-drivecritic-towards-context-aware-human-aligned-evaluation-for-auton.html) | æå‡ºDriveCriticæ¡†æ¶ï¼Œé€šè¿‡è§†è§‰è¯­è¨€æ¨¡å‹å®ç°ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è‡ªåŠ¨é©¾é©¶è¯„ä¼°ï¼Œä»¥å¯¹é½äººç±»åå¥½ã€‚ |  |
| 113 | [EgoSocial: Benchmarking Proactive Intervention Ability of Omnimodal LLMs via Egocentric Social Interaction Perception](./papers/251013105v1-egosocial-benchmarking-proactive-intervention-ability-of-omnimodal-l.html) | æå‡ºEgoSocialåŸºå‡†ä¸EgoSoDæ–¹æ³•ä»¥æå‡AR/VRä¸­AIçš„ä¸»åŠ¨å¹²é¢„èƒ½åŠ› |  |
| 114 | [Edit-Your-Interest: Efficient Video Editing via Feature Most-Similar Propagation](./papers/251013084v1-edit-your-interest-efficient-video-editing-via-feature-most-similar-.html) | æå‡ºEdit-Your-Interestæ–¹æ³•ä»¥é«˜æ•ˆå®ç°é›¶æ ·æœ¬è§†é¢‘ç¼–è¾‘ |  |
| 115 | [Counting Hallucinations in Diffusion Models](./papers/251013080v1-counting-hallucinations-in-diffusion-models.html) | æå‡ºè®¡æ•°å¹»è§‰é‡åŒ–æ–¹æ³•ä»¥è§£å†³æ‰©æ•£æ¨¡å‹ç”Ÿæˆé”™è¯¯å¯¹è±¡æ•°é‡é—®é¢˜ |  |
| 116 | [Unsupervised Domain Adaptation via Content Alignment for Hippocampus Segmentation](./papers/251013075v1-unsupervised-domain-adaptation-via-content-alignment-for-hippocampus.html) | æå‡ºåŸºäºå†…å®¹å¯¹é½çš„æ— ç›‘ç£åŸŸé€‚åº”æ¡†æ¶ï¼Œç”¨äºè·¨åŸŸæµ·é©¬ä½“åˆ†å‰² |  |
| 117 | [Direction-aware multi-scale gradient loss for infrared and visible image fusion](./papers/251013067v1-direction-aware-multi-scale-gradient-loss-for-infrared-and-visible-i.html) | æå‡ºæ–¹å‘æ„ŸçŸ¥å¤šå°ºåº¦æ¢¯åº¦æŸå¤±ä»¥æå‡çº¢å¤–ä¸å¯è§å…‰å›¾åƒèåˆçš„è¾¹ç¼˜ä¿çœŸåº¦ |  |
| 118 | [True Self-Supervised Novel View Synthesis is Transferable](./papers/251013063v1-true-self-supervised-novel-view-synthesis-is-transferable.html) | æå‡ºXFactorå®ç°å¯è½¬ç§»è‡ªç›‘ç£æ–°è§†è§’åˆæˆï¼Œæ— éœ€å‡ ä½•å…ˆéªŒã€‚ |  |
| 119 | [VLA-0: Building State-of-the-Art VLAs with Zero Modification](./papers/251013054v1-vla-0-building-state-of-the-art-vlas-with-zero-modification.html) | æå‡ºVLA-0æ–¹æ³•ï¼Œä»¥æ–‡æœ¬è¡¨ç¤ºåŠ¨ä½œæ„å»ºé«˜æ€§èƒ½è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹ã€‚ |  |

[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)