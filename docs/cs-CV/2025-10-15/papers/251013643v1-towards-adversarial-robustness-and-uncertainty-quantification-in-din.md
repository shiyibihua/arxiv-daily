---
layout: default
title: Towards Adversarial Robustness and Uncertainty Quantification in DINOv2-based Few-Shot Anomaly Detection
---

# Towards Adversarial Robustness and Uncertainty Quantification in DINOv2-based Few-Shot Anomaly Detection

**arXiv**: [2510.13643v1](https://arxiv.org/abs/2510.13643) | [PDF](https://arxiv.org/pdf/2510.13643.pdf)

**ä½œè€…**: Akib Mohammed Khan, Bartosz Krawczyk

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°DINOv2å°æ ·æœ¬å¼‚å¸¸æ£€æµ‹çš„å¯¹æŠ—é²æ£’æ€§å’Œä¸ç¡®å®šæ€§é‡åŒ–ï¼Œæå‡ºåŽå¤„ç†æ ¡å‡†åŸºçº¿**

**å…³é”®è¯**: `å¼‚å¸¸æ£€æµ‹` `å¯¹æŠ—æ”»å‡»` `ä¸ç¡®å®šæ€§é‡åŒ–` `DINOv2æ¨¡åž‹` `å°æ ·æœ¬å­¦ä¹ ` `æ¨¡åž‹æ ¡å‡†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šDINOv2åŸºç¡€æ¨¡åž‹åœ¨å¼‚å¸¸æ£€æµ‹ä¸­æ˜“å—å¯¹æŠ—æ”»å‡»ä¸”ä¸ç¡®å®šæ€§æ ¡å‡†ä¸è¶³
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å†»ç»“DINOv2ç‰¹å¾é™„åŠ çº¿æ€§å¤´è¿›è¡Œç™½ç›’æ”»å‡»ï¼Œå¹¶åº”ç”¨Plattç¼©æ”¾æ ¡å‡†å¼‚å¸¸åˆ†æ•°
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨MVTec-ADå’ŒVisAæ•°æ®é›†ä¸Šï¼ŒFGSMæ”»å‡»å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œæ ¡å‡†åŽç†µå¢žåŠ å¹¶é™ä½Žæ ¡å‡†è¯¯å·®

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Foundation models such as DINOv2 have shown strong performance in few-shot
> anomaly detection, yet two key questions remain unexamined: (i) how susceptible
> are these detectors to adversarial perturbations; and (ii) how well do their
> anomaly scores reflect calibrated uncertainty? Building on AnomalyDINO, a
> training-free deep nearest-neighbor detector over DINOv2 features, we present
> one of the first systematic studies of adversarial attacks and uncertainty
> estimation in this setting. To enable white-box gradient attacks while
> preserving test-time behavior, we attach a lightweight linear head to frozen
> DINOv2 features only for crafting perturbations. Using this heuristic, we
> evaluate the impact of FGSM across the MVTec-AD and VisA datasets and observe
> consistent drops in F1, AUROC, AP, and G-mean, indicating that imperceptible
> perturbations can flip nearest-neighbor relations in feature space to induce
> confident misclassification. Complementing robustness, we probe reliability and
> find that raw anomaly scores are poorly calibrated, revealing a gap between
> confidence and correctness that limits safety-critical use. As a simple, strong
> baseline toward trustworthiness, we apply post-hoc Platt scaling to the anomaly
> scores for uncertainty estimation. The resulting calibrated posteriors yield
> significantly higher predictive entropy on adversarially perturbed inputs than
> on clean ones, enabling a practical flagging mechanism for attack detection
> while reducing calibration error (ECE). Our findings surface concrete
> vulnerabilities in DINOv2-based few-shot anomaly detectors and establish an
> evaluation protocol and baseline for robust, uncertainty-aware anomaly
> detection. We argue that adversarial robustness and principled uncertainty
> quantification are not optional add-ons but essential capabilities if anomaly
> detection systems are to be trustworthy and ready for real-world deployment.

