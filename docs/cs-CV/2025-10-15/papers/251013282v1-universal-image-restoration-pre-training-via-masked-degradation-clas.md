---
layout: default
title: Universal Image Restoration Pre-training via Masked Degradation Classification
---

# Universal Image Restoration Pre-training via Masked Degradation Classification

**arXiv**: [2510.13282v1](https://arxiv.org/abs/2510.13282) | [PDF](https://arxiv.org/pdf/2510.13282.pdf)

**ä½œè€…**: JiaKui Hu, Zhengjian Yao, Lujia Jin, Yinghao Chen, Yanye Lu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMaskDCPTé¢„è®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡æŽ©ç é€€åŒ–åˆ†ç±»å®žçŽ°é€šç”¨å›¾åƒæ¢å¤ã€‚**

**å…³é”®è¯**: `å›¾åƒæ¢å¤é¢„è®­ç»ƒ` `æŽ©ç é€€åŒ–åˆ†ç±»` `åŒè§£ç å™¨æž¶æž„` `é€šç”¨å›¾åƒæ¢å¤` `UIR-2.5Mæ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå›¾åƒæ¢å¤ä¸­é€€åŒ–ç±»åž‹åˆ†ç±»ä¸Žé«˜è´¨é‡é‡å»ºçš„è”åˆå­¦ä¹ ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨ç¼–ç å™¨å’ŒåŒè§£ç å™¨ï¼Œç»“åˆæŽ©ç å›¾åƒå»ºæ¨¡ä¸Žå¯¹æ¯”å­¦ä¹ ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨PSNRä¸Šæå‡è‡³å°‘3.77 dBï¼Œæ³›åŒ–è‡³æœªçŸ¥é€€åŒ–ç±»åž‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This study introduces a Masked Degradation Classification Pre-Training method
> (MaskDCPT), designed to facilitate the classification of degradation types in
> input images, leading to comprehensive image restoration pre-training. Unlike
> conventional pre-training methods, MaskDCPT uses the degradation type of the
> image as an extremely weak supervision, while simultaneously leveraging the
> image reconstruction to enhance performance and robustness. MaskDCPT includes
> an encoder and two decoders: the encoder extracts features from the masked
> low-quality input image. The classification decoder uses these features to
> identify the degradation type, whereas the reconstruction decoder aims to
> reconstruct a corresponding high-quality image. This design allows the
> pre-training to benefit from both masked image modeling and contrastive
> learning, resulting in a generalized representation suited for restoration
> tasks. Benefit from the straightforward yet potent MaskDCPT, the pre-trained
> encoder can be used to address universal image restoration and achieve
> outstanding performance. Implementing MaskDCPT significantly improves
> performance for both convolution neural networks (CNNs) and Transformers, with
> a minimum increase in PSNR of 3.77 dB in the 5D all-in-one restoration task and
> a 34.8% reduction in PIQE compared to baseline in real-world degradation
> scenarios. It also emergences strong generalization to previously unseen
> degradation types and levels. In addition, we curate and release the UIR-2.5M
> dataset, which includes 2.5 million paired restoration samples across 19
> degradation types and over 200 degradation levels, incorporating both synthetic
> and real-world data. The dataset, source code, and models are available at
> https://github.com/MILab-PKU/MaskDCPT.

