---
layout: default
title: OmniGaze: Reward-inspired Generalizable Gaze Estimation In The Wild
---

# OmniGaze: Reward-inspired Generalizable Gaze Estimation In The Wild

**arXiv**: [2510.13660v1](https://arxiv.org/abs/2510.13660) | [PDF](https://arxiv.org/pdf/2510.13660.pdf)

**ä½œè€…**: Hongyu Qu, Jianan Wei, Xiangbo Shu, Yazhou Yao, Wenguan Wang, Jinhui Tang

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmniGazeåŠç›‘ç£æ¡†æ¶ï¼Œåˆ©ç”¨æœªæ ‡è®°æ•°æ®æå‡3Dè§†çº¿ä¼°è®¡çš„è·¨åŸŸæ³›åŒ–èƒ½åŠ›**

**å…³é”®è¯**: `3Dè§†çº¿ä¼°è®¡` `åŠç›‘ç£å­¦ä¹ ` `ä¼ªæ ‡ç­¾ç­–ç•¥` `å¥–åŠ±æ¨¡å‹` `è·¨åŸŸæ³›åŒ–` `é›¶æ ·æœ¬å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼š3Dè§†çº¿ä¼°è®¡æ–¹æ³•å› æ ‡æ³¨æ•°æ®ç¨€ç¼ºå’Œå¤šæ ·æ€§ä¸è¶³ï¼Œéš¾ä»¥æ³›åŒ–åˆ°ä¸åŒæ•°æ®åŸŸ
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä¼ªæ ‡ç­¾ç­–ç•¥ï¼Œç»“åˆå¥–åŠ±æ¨¡å‹è¯„ä¼°ä¼ªæ ‡ç­¾å¯é æ€§ï¼Œèåˆè§†è§‰åµŒå…¥å’Œè¯­ä¹‰çº¿ç´¢
3. å®éªŒæˆ–æ•ˆæœï¼šåœ¨äº”ä¸ªæ•°æ®é›†ä¸Šå®ç°SOTAæ€§èƒ½ï¼Œå¹¶åœ¨å››ä¸ªæœªè§æ•°æ®é›†ä¸Šå±•ç¤ºé›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current 3D gaze estimation methods struggle to generalize across diverse data
> domains, primarily due to i) the scarcity of annotated datasets, and ii) the
> insufficient diversity of labeled data. In this work, we present OmniGaze, a
> semi-supervised framework for 3D gaze estimation, which utilizes large-scale
> unlabeled data collected from diverse and unconstrained real-world environments
> to mitigate domain bias and generalize gaze estimation in the wild. First, we
> build a diverse collection of unlabeled facial images, varying in facial
> appearances, background environments, illumination conditions, head poses, and
> eye occlusions. In order to leverage unlabeled data spanning a broader
> distribution, OmniGaze adopts a standard pseudo-labeling strategy and devises a
> reward model to assess the reliability of pseudo labels. Beyond pseudo labels
> as 3D direction vectors, the reward model also incorporates visual embeddings
> extracted by an off-the-shelf visual encoder and semantic cues from gaze
> perspective generated by prompting a Multimodal Large Language Model to compute
> confidence scores. Then, these scores are utilized to select high-quality
> pseudo labels and weight them for loss computation. Extensive experiments
> demonstrate that OmniGaze achieves state-of-the-art performance on five
> datasets under both in-domain and cross-domain settings. Furthermore, we also
> evaluate the efficacy of OmniGaze as a scalable data engine for gaze
> estimation, which exhibits robust zero-shot generalization on four unseen
> datasets.

