---
layout: default
title: A New Perspective on Transformers in Online Reinforcement Learning for Continuous Control
---

# A New Perspective on Transformers in Online Reinforcement Learning for Continuous Control

**arXiv**: [2510.13367v1](https://arxiv.org/abs/2510.13367) | [PDF](https://arxiv.org/pdf/2510.13367.pdf)

**ä½œè€…**: Nikita Kachaev, Daniil Zelezetsky, Egor Cherepanov, Alexey K. Kovelev, Aleksandr I. Panov

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTransformeræž¶æž„ä¸Žè®­ç»ƒç­–ç•¥ï¼Œç”¨äºŽåœ¨çº¿æ— æ¨¡åž‹å¼ºåŒ–å­¦ä¹ çš„è¿žç»­æŽ§åˆ¶ä»»åŠ¡ã€‚**

**å…³é”®è¯**: `åœ¨çº¿å¼ºåŒ–å­¦ä¹ ` `Transformeræž¶æž„` `è¿žç»­æŽ§åˆ¶` `æ¨¡åž‹è®¾è®¡ç­–ç•¥` `åºåˆ—æ•°æ®å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šTransformeråœ¨åœ¨çº¿æ— æ¨¡åž‹å¼ºåŒ–å­¦ä¹ ä¸­åº”ç”¨ä¸è¶³ï¼Œå› å¯¹è®­ç»ƒè®¾ç½®å’Œæ¨¡åž‹è®¾è®¡æ•æ„Ÿã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç ”ç©¶è¾“å…¥æ¡ä»¶ã€ç»„ä»¶å…±äº«å’Œåºåˆ—æ•°æ®åˆ‡ç‰‡ç­‰å…³é”®è®¾è®¡é—®é¢˜ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å®Œå…¨å’Œéƒ¨åˆ†å¯è§‚æµ‹ä»»åŠ¡ä¸­å®žçŽ°ç«žäº‰æ€§èƒ½ï¼Œé€‚ç”¨äºŽå‘é‡å’Œå›¾åƒè®¾ç½®ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite their effectiveness and popularity in offline or model-based
> reinforcement learning (RL), transformers remain underexplored in online
> model-free RL due to their sensitivity to training setups and model design
> decisions such as how to structure the policy and value networks, share
> components, or handle temporal information. In this paper, we show that
> transformers can be strong baselines for continuous control in online
> model-free RL. We investigate key design questions: how to condition inputs,
> share components between actor and critic, and slice sequential data for
> training. Our experiments reveal stable architectural and training strategies
> enabling competitive performance across fully and partially observable tasks,
> and in both vector- and image-based settings. These findings offer practical
> guidance for applying transformers in online RL.

