---
layout: default
title: Edit-Your-Interest: Efficient Video Editing via Feature Most-Similar Propagation
---

# Edit-Your-Interest: Efficient Video Editing via Feature Most-Similar Propagation

**arXiv**: [2510.13084v1](https://arxiv.org/abs/2510.13084) | [PDF](https://arxiv.org/pdf/2510.13084.pdf)

**ä½œè€…**: Yi Zuo, Zitao Wang, Lingling Li, Xu Liu, Fang Liu, Licheng Jiao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEdit-Your-Interestæ–¹æ³•ä»¥é«˜æ•ˆå®žçŽ°é›¶æ ·æœ¬è§†é¢‘ç¼–è¾‘**

**å…³é”®è¯**: `è§†é¢‘ç¼–è¾‘` `æ‰©æ•£æ¨¡åž‹` `ç‰¹å¾ä¼ æ’­` `æ—¶ç©ºä¸€è‡´æ€§` `é›¶æ ·æœ¬å­¦ä¹ ` `è®¡ç®—æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†é¢‘ç¼–è¾‘æ–¹æ³•è®¡ç®—å¼€é”€é«˜ã€å†…å­˜æ¶ˆè€—å¤§ï¼Œä¸”æ˜“äº§ç”Ÿæ—¶é—´ä¸ä¸€è‡´æ€§å’Œä¼ªå½±
2. å¼•å…¥æ—¶ç©ºç‰¹å¾è®°å¿†åº“å’Œç‰¹å¾æœ€ç›¸ä¼¼ä¼ æ’­ï¼Œç¼“å­˜å¹¶ä¼ æ’­å…³é”®ç‰¹å¾ä»¥æå‡æ•ˆçŽ‡ä¸Žä¸€è‡´æ€§
3. å®žéªŒè¡¨æ˜Žè¯¥æ–¹æ³•åœ¨æ•ˆçŽ‡å’Œè§†è§‰ä¿çœŸåº¦ä¸Šä¼˜äºŽçŽ°æœ‰å…ˆè¿›æ–¹æ³•ï¼ŒéªŒè¯å…¶æœ‰æ•ˆæ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-to-image (T2I) diffusion models have recently demonstrated significant
> progress in video editing.
>   However, existing video editing methods are severely limited by their high
> computational overhead and memory consumption.
>   Furthermore, these approaches often sacrifice visual fidelity, leading to
> undesirable temporal inconsistencies and artifacts such as blurring and
> pronounced mosaic-like patterns.
>   We propose Edit-Your-Interest, a lightweight, text-driven, zero-shot video
> editing method.
>   Edit-Your-Interest introduces a spatio-temporal feature memory to cache
> features from previous frames, significantly reducing computational overhead
> compared to full-sequence spatio-temporal modeling approaches.
>   Specifically, we first introduce a Spatio-Temporal Feature Memory bank (SFM),
> which is designed to efficiently cache and retain the crucial image tokens
> processed by spatial attention.
>   Second, we propose the Feature Most-Similar Propagation (FMP) method. FMP
> propagates the most relevant tokens from previous frames to subsequent ones,
> preserving temporal consistency.
>   Finally, we introduce an SFM update algorithm that continuously refreshes the
> cached features, ensuring their long-term relevance and effectiveness
> throughout the video sequence.
>   Furthermore, we leverage cross-attention maps to automatically extract masks
> for the instances of interest.
>   These masks are seamlessly integrated into the diffusion denoising process,
> enabling fine-grained control over target objects and allowing
> Edit-Your-Interest to perform highly accurate edits while robustly preserving
> the background integrity.
>   Extensive experiments decisively demonstrate that the proposed
> Edit-Your-Interest outperforms state-of-the-art methods in both efficiency and
> visual fidelity, validating its superior effectiveness and practicality.

