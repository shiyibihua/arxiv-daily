---
layout: default
title: No-Reference Rendered Video Quality Assessment: Dataset and Metrics
---

# No-Reference Rendered Video Quality Assessment: Dataset and Metrics

**arXiv**: [2510.13349v1](https://arxiv.org/abs/2510.13349) | [PDF](https://arxiv.org/pdf/2510.13349.pdf)

**ä½œè€…**: Sipeng Yang, Jiayu Ji, Qingchuan Zhu, Zhiyao Yang, Xiaogang Jin

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ— å‚è€ƒæ¸²æŸ“è§†é¢‘è´¨é‡è¯„ä¼°æ•°æ®é›†ä¸æŒ‡æ ‡ï¼Œä»¥è§£å†³æ¸²æŸ“è§†é¢‘ä¸­æ—¶é—´ä¼ªå½±é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ— å‚è€ƒè§†é¢‘è´¨é‡è¯„ä¼°` `æ¸²æŸ“è§†é¢‘` `æ—¶é—´ä¼ªå½±` `ä¸»è§‚è´¨é‡æ ‡æ³¨` `å®æ—¶æ¸²æŸ“` `è¶…é‡‡æ ·æ–¹æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ— å‚è€ƒè§†é¢‘è´¨é‡è¯„ä¼°æ–¹æ³•å¯¹ç›¸æœºè§†é¢‘æœ‰åï¼Œä¸é€‚ç”¨äºæ¸²æŸ“è§†é¢‘ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ„å»ºå¤§è§„æ¨¡æ¸²æŸ“è§†é¢‘æ•°æ®é›†ï¼Œå¹¶è®¾è®¡ç»“åˆå›¾åƒè´¨é‡å’Œæ—¶é—´ç¨³å®šæ€§çš„è¯„ä¼°æŒ‡æ ‡ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šæ–°æŒ‡æ ‡åœ¨æ¸²æŸ“è§†é¢‘ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶ç”¨äºè¶…é‡‡æ ·å’Œå¸§ç”Ÿæˆç­–ç•¥è¯„ä¼°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Quality assessment of videos is crucial for many computer graphics
> applications, including video games, virtual reality, and augmented reality,
> where visual performance has a significant impact on user experience. When test
> videos cannot be perfectly aligned with references or when references are
> unavailable, the significance of no-reference video quality assessment (NR-VQA)
> methods is undeniable. However, existing NR-VQA datasets and metrics are
> primarily focused on camera-captured videos; applying them directly to rendered
> videos would result in biased predictions, as rendered videos are more prone to
> temporal artifacts. To address this, we present a large rendering-oriented
> video dataset with subjective quality annotations, as well as a designed NR-VQA
> metric specific to rendered videos. The proposed dataset includes a wide range
> of 3D scenes and rendering settings, with quality scores annotated for various
> display types to better reflect real-world application scenarios. Building on
> this dataset, we calibrate our NR-VQA metric to assess rendered video quality
> by looking at both image quality and temporal stability. We compare our metric
> to existing NR-VQA metrics, demonstrating its superior performance on rendered
> videos. Finally, we demonstrate that our metric can be used to benchmark
> supersampling methods and assess frame generation strategies in real-time
> rendering.

