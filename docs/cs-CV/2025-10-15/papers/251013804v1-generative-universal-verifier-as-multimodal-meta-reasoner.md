---
layout: default
title: Generative Universal Verifier as Multimodal Meta-Reasoner
---

# Generative Universal Verifier as Multimodal Meta-Reasoner

**arXiv**: [2510.13804v1](https://arxiv.org/abs/2510.13804) | [PDF](https://arxiv.org/pdf/2510.13804.pdf)

**ä½œè€…**: Xinchen Zhang, Xiaoying Zhang, Youbin Wu, Yanbin Cao, Renrui Zhang, Ruihang Chu, Ling Yang, Yujiu Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç”Ÿæˆå¼é€šç”¨éªŒè¯å™¨ä½œä¸ºå¤šæ¨¡æ€å…ƒæŽ¨ç†å™¨ï¼Œå¢žå¼ºè§†è§‰è¯­è¨€æ¨¡åž‹çš„å¯é åæ€ä¸Žä¼˜åŒ–èƒ½åŠ›ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€æŽ¨ç†` `è§†è§‰éªŒè¯` `ç”Ÿæˆå¼æ¨¡åž‹` `æµ‹è¯•æ—¶ä¼˜åŒ–` `åŸºå‡†è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†è§‰è¯­è¨€æ¨¡åž‹åœ¨è§†è§‰éªŒè¯ä»»åŠ¡ä¸­è¡¨çŽ°ä¸ä½³ï¼Œä¸Žäººç±»èƒ½åŠ›å­˜åœ¨æ˜¾è‘—å·®è·ã€‚
2. æž„å»ºViVerBenchåŸºå‡†å¹¶è®­ç»ƒOmniVerifier-7Bï¼Œå®žçŽ°é€šç”¨è§†è§‰éªŒè¯ï¼Œæå‡åŸºå‡†æ€§èƒ½8.3%ã€‚
3. æå‡ºOmniVerifier-TTSæµ‹è¯•æ—¶æ‰©å±•èŒƒå¼ï¼Œåœ¨å¤šä¸ªåŸºå‡†ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œæå‡ç”Ÿæˆèƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce Generative Universal Verifier, a novel concept and plugin
> designed for next-generation multimodal reasoning in vision-language models and
> unified multimodal models, providing the fundamental capability of reflection
> and refinement on visual outcomes during the reasoning and generation process.
> This work makes three main contributions: (1) We build ViVerBench, a
> comprehensive benchmark spanning 16 categories of critical tasks for evaluating
> visual outcomes in multimodal reasoning. Results show that existing VLMs
> consistently underperform across these tasks, underscoring a substantial gap
> from human-level capability in reliable visual verification. (2) We design two
> automated pipelines to construct large-scale visual verification data and train
> OmniVerifier-7B, the first omni-capable generative verifier trained for
> universal visual verification and achieves notable gains on ViVerBench(+8.3).
> Through training, we identify three atomic capabilities in visual verification
> and demonstrate how they generalize and interact synergistically. (3) We
> propose OmniVerifier-TTS, a sequential test-time scaling paradigm that
> leverages the universal verifier to bridge image generation and editing within
> unified models, enhancing the upper bound of generative ability through
> iterative fine-grained optimization. Beyond generation, we extend universal
> verifier to broader world-modeling interleaved reasoning scenarios.
> Empirically, OmniVerifier-TTS achieves improvements on T2I-ReasonBench(+3.7),
> and GenEval++(+4.3), outperforming existing parallel test-time scaling methods,
> such as Best-of-N. By endowing multimodal reasoning with reliable visual
> verification, OmniVerifier advances both reliable reflection during generation
> and scalable test-time refinement, marking a step toward more trustworthy and
> controllable next-generation reasoning systems.

