---
layout: default
title: CoDS: Enhancing Collaborative Perception in Heterogeneous Scenarios via Domain Separation
---

# CoDS: Enhancing Collaborative Perception in Heterogeneous Scenarios via Domain Separation

**arXiv**: [2510.13432v1](https://arxiv.org/abs/2510.13432) | [PDF](https://arxiv.org/pdf/2510.13432.pdf)

**ä½œè€…**: Yushan Han, Hui Zhang, Honglei Zhang, Chuntao Ding, Yuanzhouhan Cao, Yidong Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoDSæ–¹æ³•ï¼Œé€šè¿‡åŸŸåˆ†ç¦»è§£å†³å¼‚æž„åœºæ™¯ä¸­çš„åä½œæ„ŸçŸ¥ç‰¹å¾å·®å¼‚é—®é¢˜**

**å…³é”®è¯**: `åä½œæ„ŸçŸ¥` `åŸŸåˆ†ç¦»` `ç‰¹å¾å¯¹é½` `å¼‚æž„åœºæ™¯` `æŽ¨ç†æ•ˆçŽ‡` `è‡ªåŠ¨é©¾é©¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¼‚æž„åœºæ™¯ä¸­ç‰¹å¾å¯¹é½æ˜“å—å™ªå£°å½±å“ï¼Œä¸”çŽ°æœ‰æ–¹æ³•æŽ¨ç†æ•ˆçŽ‡ä½Ž
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨è½»é‡çº§ç©ºé—´é€šé“è°ƒæ•´å™¨å’ŒåŸŸåˆ†ç¦»æ¨¡å—è¿›è¡Œç‰¹å¾å¯¹é½
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¼‚æž„åœºæ™¯ä¸­æœ‰æ•ˆç¼“è§£ç‰¹å¾å·®å¼‚ï¼Œå¹³è¡¡æ£€æµ‹ç²¾åº¦ä¸ŽæŽ¨ç†æ•ˆçŽ‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Collaborative perception has been proven to improve individual perception in
> autonomous driving through multi-agent interaction. Nevertheless, most methods
> often assume identical encoders for all agents, which does not hold true when
> these models are deployed in real-world applications. To realize collaborative
> perception in actual heterogeneous scenarios, existing methods usually align
> neighbor features to those of the ego vehicle, which is vulnerable to noise
> from domain gaps and thus fails to address feature discrepancies effectively.
> Moreover, they adopt transformer-based modules for domain adaptation, which
> causes the model inference inefficiency on mobile devices. To tackle these
> issues, we propose CoDS, a Collaborative perception method that leverages
> Domain Separation to address feature discrepancies in heterogeneous scenarios.
> The CoDS employs two feature alignment modules, i.e., Lightweight
> Spatial-Channel Resizer (LSCR) and Distribution Alignment via Domain Separation
> (DADS). Besides, it utilizes the Domain Alignment Mutual Information (DAMI)
> loss to ensure effective feature alignment. Specifically, the LSCR aligns the
> neighbor feature across spatial and channel dimensions using a lightweight
> convolutional layer. Subsequently, the DADS mitigates feature distribution
> discrepancy with encoder-specific and encoder-agnostic domain separation
> modules. The former removes domain-dependent information and the latter
> captures task-related information. During training, the DAMI loss maximizes the
> mutual information between aligned heterogeneous features to enhance the domain
> separation process. The CoDS employs a fully convolutional architecture, which
> ensures high inference efficiency. Extensive experiments demonstrate that the
> CoDS effectively mitigates feature discrepancies in heterogeneous scenarios and
> achieves a trade-off between detection accuracy and inference efficiency.

