---
layout: default
title: Reinforcement Learning Meets Masked Generative Models: Mask-GRPO for Text-to-Image Generation
---

# Reinforcement Learning Meets Masked Generative Models: Mask-GRPO for Text-to-Image Generation

**arXiv**: [2510.13418v1](https://arxiv.org/abs/2510.13418) | [PDF](https://arxiv.org/pdf/2510.13418.pdf)

**ä½œè€…**: Yifu Luo, Xinhao Hu, Keyu Fan, Haoyuan Sun, Zeyu Chen, Bo Xia, Tiantian Zhang, Yongzhe Chang, Xueqian Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMask-GRPOä»¥å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æŽ©ç ç”Ÿæˆæ¨¡åž‹ç”¨äºŽæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `å¼ºåŒ–å­¦ä¹ ` `æŽ©ç ç”Ÿæˆæ¨¡åž‹` `ç­–ç•¥ä¼˜åŒ–` `å¤šæ­¥å†³ç­–` `åå¥½å¯¹é½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•å¿½ç•¥æŽ©ç ç”Ÿæˆæ¨¡åž‹ï¼Œä»…é’ˆå¯¹æ‰©æ•£æˆ–è‡ªå›žå½’æ¨¡åž‹
2. é‡æ–°å®šä¹‰è½¬ç§»æ¦‚çŽ‡ï¼Œå°†åŽ»æŽ©ç è¿‡ç¨‹å»ºæ¨¡ä¸ºå¤šæ­¥å†³ç­–é—®é¢˜
3. åœ¨æ ‡å‡†åŸºå‡†å’Œåå¥½å¯¹é½ä¸Šè¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œæå‡åŸºç¡€æ¨¡åž‹æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reinforcement learning (RL) has garnered increasing attention in
> text-to-image (T2I) generation. However, most existing RL approaches are
> tailored to either diffusion models or autoregressive models, overlooking an
> important alternative: masked generative models. In this work, we propose
> Mask-GRPO, the first method to incorporate Group Relative Policy Optimization
> (GRPO)-based RL into this overlooked paradigm. Our core insight is to redefine
> the transition probability, which is different from current approaches, and
> formulate the unmasking process as a multi-step decision-making problem. To
> further enhance our method, we explore several useful strategies, including
> removing the KL constraint, applying the reduction strategy, and filtering out
> low-quality samples. Using Mask-GRPO, we improve a base model, Show-o, with
> substantial improvements on standard T2I benchmarks and preference alignment,
> outperforming existing state-of-the-art approaches. The code is available on
> https://github.com/xingzhejun/Mask-GRPO

