---
layout: default
title: Leveraging 2D Priors and SDF Guidance for Dynamic Urban Scene Rendering
---

# Leveraging 2D Priors and SDF Guidance for Dynamic Urban Scene Rendering

**arXiv**: [2510.13381v1](https://arxiv.org/abs/2510.13381) | [PDF](https://arxiv.org/pdf/2510.13381.pdf)

**ä½œè€…**: Siddharth Tourani, Jayaram Reddy, Akash Kumbar, Satyajit Tourani, Nishant Goyal, Madhava Krishna, N. Dinesh Reddy, Muhammad Haris Khan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“åˆ2Då…ˆéªŒä¸ŽSDFçš„3Dé«˜æ–¯æ³¼æº…æ–¹æ³•ï¼Œæå‡åŠ¨æ€åŸŽå¸‚åœºæ™¯æ¸²æŸ“ç²¾åº¦**

**å…³é”®è¯**: `åŠ¨æ€åœºæ™¯æ¸²æŸ“` `3Dé«˜æ–¯æ³¼æº…` `ç¬¦å·è·ç¦»å‡½æ•°` `åŸŽå¸‚åœºæ™¯é‡å»º` `åœºæ™¯ç¼–è¾‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŠ¨æ€åŸŽå¸‚åœºæ™¯æ¸²æŸ“éœ€LiDARå’Œ3Dè¿åŠ¨æ ‡æ³¨ï¼Œä¾èµ–æ€§å¼ºã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆSDFä¸Ž3Dé«˜æ–¯æ³¼æº…ï¼Œåˆ©ç”¨æ·±åº¦å’Œç‚¹è·Ÿè¸ªå…ˆéªŒä¼˜åŒ–å‡ ä½•ä¸Žå˜å½¢ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ— LiDARæ—¶æ¸²æŸ“æŒ‡æ ‡é¢†å…ˆï¼Œç»“åˆLiDARå¯å¢žå¼ºé‡å»ºä¸Žç¼–è¾‘èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Dynamic scene rendering and reconstruction play a crucial role in computer
> vision and augmented reality. Recent methods based on 3D Gaussian Splatting
> (3DGS), have enabled accurate modeling of dynamic urban scenes, but for urban
> scenes they require both camera and LiDAR data, ground-truth 3D segmentations
> and motion data in the form of tracklets or pre-defined object templates such
> as SMPL. In this work, we explore whether a combination of 2D object agnostic
> priors in the form of depth and point tracking coupled with a signed distance
> function (SDF) representation for dynamic objects can be used to relax some of
> these requirements. We present a novel approach that integrates Signed Distance
> Functions (SDFs) with 3D Gaussian Splatting (3DGS) to create a more robust
> object representation by harnessing the strengths of both methods. Our unified
> optimization framework enhances the geometric accuracy of 3D Gaussian splatting
> and improves deformation modeling within the SDF, resulting in a more adaptable
> and precise representation. We demonstrate that our method achieves
> state-of-the-art performance in rendering metrics even without LiDAR data on
> urban scenes. When incorporating LiDAR, our approach improved further in
> reconstructing and generating novel views across diverse object categories,
> without ground-truth 3D motion annotation. Additionally, our method enables
> various scene editing tasks, including scene decomposition, and scene
> composition.

