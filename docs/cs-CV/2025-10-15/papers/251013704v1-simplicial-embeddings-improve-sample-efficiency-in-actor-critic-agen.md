---
layout: default
title: Simplicial Embeddings Improve Sample Efficiency in Actor-Critic Agents
---

# Simplicial Embeddings Improve Sample Efficiency in Actor-Critic Agents

**arXiv**: [2510.13704v1](https://arxiv.org/abs/2510.13704) | [PDF](https://arxiv.org/pdf/2510.13704.pdf)

**ä½œè€…**: Johan Obando-Ceron, Walter Mayor, Samuel Lavoie, Scott Fujimoto, Aaron Courville, Pablo Samuel Castro

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå•çº¯å½¢åµŒå…¥ä»¥æå‡æ¼”å‘˜-è¯„è®ºå®¶æ–¹æ³•çš„æ ·æœ¬æ•ˆç‡**

**å…³é”®è¯**: `å•çº¯å½¢åµŒå…¥` `æ¼”å‘˜-è¯„è®ºå®¶æ–¹æ³•` `æ ·æœ¬æ•ˆç‡` `å¼ºåŒ–å­¦ä¹ ` `å‡ ä½•å½’çº³åç½®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é—®é¢˜ï¼šå¤§è§„æ¨¡å¹¶è¡ŒåŒ–è®­ç»ƒä»éœ€è¦å¤§é‡ç¯å¢ƒäº¤äº’æ‰èƒ½è¾¾åˆ°æ€§èƒ½ç›®æ ‡
2. æ–¹æ³•ï¼šå¼•å…¥å•çº¯å½¢åµŒå…¥ï¼Œçº¦æŸåµŒå…¥ä¸ºå•çº¯å½¢ç»“æ„ï¼Œæä¾›å‡ ä½•å½’çº³åç½®
3. æ•ˆæœï¼šåœ¨å¤šç§ç¯å¢ƒä¸­æé«˜æ ·æœ¬æ•ˆç‡å’Œæœ€ç»ˆæ€§èƒ½ï¼Œä¸æŸå¤±è¿è¡Œé€Ÿåº¦

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent works have proposed accelerating the wall-clock training time of
> actor-critic methods via the use of large-scale environment parallelization;
> unfortunately, these can sometimes still require large number of environment
> interactions to achieve a desired level of performance. Noting that
> well-structured representations can improve the generalization and sample
> efficiency of deep reinforcement learning (RL) agents, we propose the use of
> simplicial embeddings: lightweight representation layers that constrain
> embeddings to simplicial structures. This geometric inductive bias results in
> sparse and discrete features that stabilize critic bootstrapping and strengthen
> policy gradients. When applied to FastTD3, FastSAC, and PPO, simplicial
> embeddings consistently improve sample efficiency and final performance across
> a variety of continuous- and discrete-control environments, without any loss in
> runtime speed.

