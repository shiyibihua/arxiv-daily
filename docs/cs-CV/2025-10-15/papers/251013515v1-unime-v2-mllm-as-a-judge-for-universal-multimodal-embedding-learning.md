---
layout: default
title: UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning
---

# UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning

**arXiv**: [2510.13515v1](https://arxiv.org/abs/2510.13515) | [PDF](https://arxiv.org/pdf/2510.13515.pdf)

**ä½œè€…**: Tiancheng Gu, Kaicheng Yang, Kaichen Zhang, Xiang An, Ziyong Feng, Yueyi Zhang, Weidong Cai, Jiankang Deng, Lidong Bing

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUniME-V2æ¨¡åž‹ï¼Œåˆ©ç”¨MLLMä½œä¸ºè¯„åˆ¤è€…å¢žå¼ºå¤šæ¨¡æ€åµŒå…¥å­¦ä¹ ï¼Œè§£å†³è¯­ä¹‰å·®å¼‚æ•æ‰å’Œè´Ÿæ ·æœ¬å¤šæ ·æ€§é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€åµŒå…¥å­¦ä¹ ` `ç¡¬è´Ÿæ ·æœ¬æŒ–æŽ˜` `MLLMè¯„åˆ¤æœºåˆ¶` `è¯­ä¹‰åŒ¹é…åˆ†æ•°` `é‡æŽ’åºæ¨¡åž‹` `æ£€ç´¢ä»»åŠ¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•éš¾ä»¥æ•æ‰å€™é€‰é—´ç»†å¾®è¯­ä¹‰å·®å¼‚ï¼Œä¸”è´Ÿæ ·æœ¬ç¼ºä¹å¤šæ ·æ€§ï¼Œå¯¼è‡´åµŒå…¥åˆ¤åˆ«èƒ½åŠ›æœ‰é™ã€‚
2. å¼•å…¥MLLM-as-a-Judgeæœºåˆ¶ï¼Œè¯„ä¼°æŸ¥è¯¢-å€™é€‰å¯¹è¯­ä¹‰å¯¹é½ï¼Œç”Ÿæˆè½¯åŒ¹é…åˆ†æ•°ç”¨äºŽç¡¬è´Ÿæ ·æœ¬æŒ–æŽ˜å’Œè½¯æ ‡ç­¾å¯¹é½ã€‚
3. åœ¨MMEBåŸºå‡†å’Œå¤šä¸ªæ£€ç´¢ä»»åŠ¡ä¸Šå®žéªŒï¼Œå¹³å‡æ€§èƒ½è¾¾åˆ°æœ€å…ˆè¿›æ°´å¹³ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Universal multimodal embedding models are foundational to various tasks.
> Existing approaches typically employ in-batch negative mining by measuring the
> similarity of query-candidate pairs. However, these methods often struggle to
> capture subtle semantic differences among candidates and lack diversity in
> negative samples. Moreover, the embeddings exhibit limited discriminative
> ability in distinguishing false and hard negatives. In this paper, we leverage
> the advanced understanding capabilities of MLLMs to enhance representation
> learning and present a novel Universal Multimodal Embedding (UniME-V2) model.
> Our approach first constructs a potential hard negative set through global
> retrieval. We then introduce the MLLM-as-a-Judge mechanism, which utilizes
> MLLMs to assess the semantic alignment of query-candidate pairs and generate
> soft semantic matching scores. These scores serve as a foundation for hard
> negative mining, mitigating the impact of false negatives and enabling the
> identification of diverse, high-quality hard negatives. Furthermore, the
> semantic matching scores are used as soft labels to mitigate the rigid
> one-to-one mapping constraint. By aligning the similarity matrix with the soft
> semantic matching score matrix, the model learns semantic distinctions among
> candidates, significantly enhancing its discriminative capacity. To further
> improve performance, we propose UniME-V2-Reranker, a reranking model trained on
> our mined hard negatives through a joint pairwise and listwise optimization
> approach. We conduct comprehensive experiments on the MMEB benchmark and
> multiple retrieval tasks, demonstrating that our method achieves
> state-of-the-art performance on average across all tasks.

