---
layout: default
title: OS-HGAdapter: Open Semantic Hypergraph Adapter for Large Language Models Assisted Entropy-Enhanced Image-Text Alignment
---

# OS-HGAdapter: Open Semantic Hypergraph Adapter for Large Language Models Assisted Entropy-Enhanced Image-Text Alignment

**arXiv**: [2510.13131v1](https://arxiv.org/abs/2510.13131) | [PDF](https://arxiv.org/pdf/2510.13131.pdf)

**ä½œè€…**: Rongjun Chen, Chengsi Yao, Jinchang Ren, Xianxian Zeng, Peixian Wang, Jun Yuan, Jiawen Li, Huimin Zhao, Xu Lu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOS-HGAdapterï¼Œåˆ©ç”¨LLMå¢žå¼ºæ–‡æœ¬ç†µå’Œè¶…å›¾é€‚é…å™¨è§£å†³å›¾æ–‡å¯¹é½ä¸å¹³è¡¡é—®é¢˜**

**å…³é”®è¯**: `å›¾æ–‡å¯¹é½` `è·¨æ¨¡æ€æ£€ç´¢` `ä¿¡æ¯ç†µå¢žå¼º` `è¶…å›¾é€‚é…å™¨` `å¤§è¯­è¨€æ¨¡åž‹` `è¯­ä¹‰åŒ¹é…`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå›¾æ–‡æ¨¡æ€ä¿¡æ¯ç†µå·®å¼‚å¯¼è‡´è·¨æ¨¡æ€æ£€ç´¢ä¸å¹³è¡¡ï¼Œå½±å“è¯­ä¹‰å¯¹é½æ€§èƒ½ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡LLMæç¤ºæ¨¡æ¿å¢žå¼ºæ–‡æœ¬å¤šä¹‰æ€§ï¼Œä½¿ç”¨è¶…å›¾é€‚é…å™¨æž„å»ºå¤šè¾¹è¿žæŽ¥çº æ­£åŒ¹é…é”™è¯¯ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨Flickr30Kå’ŒMS-COCOåŸºå‡†ä¸Šï¼Œå›¾æ–‡æ£€ç´¢æ€§èƒ½æ˜¾è‘—æå‡ï¼Œè¾¾åˆ°æ–°SOTAã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-image alignment constitutes a foundational challenge in multimedia
> content understanding, where effective modeling of cross-modal semantic
> correspondences critically enhances retrieval system performance through joint
> embedding space optimization. Given the inherent difference in information
> entropy between texts and images, conventional approaches often show an
> imbalance in the mutual retrieval of these two modalities. To address this
> particular challenge, we propose to use the open semantic knowledge of Large
> Language Model (LLM) to fill for the entropy gap and reproduce the alignment
> ability of humans in these tasks. Our entropy-enhancing alignment is achieved
> through a two-step process: 1) a new prompt template that does not rely on
> explicit knowledge in the task domain is designed to use LLM to enhance the
> polysemy description of the text modality. By analogy, the information entropy
> of the text modality relative to the visual modality is increased; 2) A
> hypergraph adapter is used to construct multilateral connections between the
> text and image modalities, which can correct the positive and negative matching
> errors for synonymous semantics in the same fixed embedding space, whilst
> reducing the noise caused by open semantic entropy by mapping the reduced
> dimensions back to the original dimensions. Comprehensive evaluations on the
> Flickr30K and MS-COCO benchmarks validate the superiority of our Open Semantic
> Hypergraph Adapter (OS-HGAdapter), showcasing 16.8\% (text-to-image) and 40.1\%
> (image-to-text) cross-modal retrieval gains over existing methods while
> establishing new state-of-the-art performance in semantic alignment tasks.

