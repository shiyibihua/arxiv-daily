---
layout: default
title: MMLongCite: A Benchmark for Evaluating Fidelity of Long-Context Vision-Language Models
---

# MMLongCite: A Benchmark for Evaluating Fidelity of Long-Context Vision-Language Models

**arXiv**: [2510.13276v1](https://arxiv.org/abs/2510.13276) | [PDF](https://arxiv.org/pdf/2510.13276.pdf)

**ä½œè€…**: Keyan Zhou, Zecheng Tang, Lingfeng Ming, Guanghao Zhou, Qiguang Chen, Dan Qiao, Zheming Yang, Libo Qin, Minghui Qiu, Juntao Li, Min Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMMLongCiteåŸºå‡†ä»¥è¯„ä¼°é•¿ä¸Šä¸‹æ–‡è§†è§‰è¯­è¨€æ¨¡åž‹çš„å¿ å®žæ€§**

**å…³é”®è¯**: `é•¿ä¸Šä¸‹æ–‡è¯„ä¼°` `è§†è§‰è¯­è¨€æ¨¡åž‹` `å¤šæ¨¡æ€åŸºå‡†` `å¿ å®žæ€§åˆ†æž` `ä¸Šä¸‹æ–‡é•¿åº¦å½±å“`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé•¿ä¸Šä¸‹æ–‡çª—å£ä¸ä¿è¯æœ‰æ•ˆåˆ©ç”¨ï¼Œå½±å“å¤šæ¨¡æ€åº”ç”¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºæ¶µç›–å¤šæ¨¡æ€å’Œé•¿åº¦åŒºé—´çš„ç»¼åˆåŸºå‡†ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè¯„ä¼°æ˜¾ç¤ºæ¨¡åž‹å¿ å®žæ€§æœ‰é™ï¼Œåˆ†æžé•¿åº¦å’Œå†…å®¹ä½ç½®å½±å“ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The rapid advancement of large vision language models (LVLMs) has led to a
> significant expansion of their context windows. However, an extended context
> window does not guarantee the effective utilization of the context, posing a
> critical challenge for real-world applications. Current evaluations of such
> long-context faithfulness are predominantly focused on the text-only domain,
> while multimodal assessments remain limited to short contexts. To bridge this
> gap, we introduce MMLongCite, a comprehensive benchmark designed to evaluate
> the fidelity of LVLMs in long-context scenarios. MMLongCite comprises 8
> distinct tasks spanning 6 context length intervals and incorporates diverse
> modalities, including text, images, and videos. Our evaluation of
> state-of-the-art LVLMs reveals their limited faithfulness in handling long
> multimodal contexts. Furthermore, we provide an in-depth analysis of how
> context length and the position of crucial content affect the faithfulness of
> these models.

