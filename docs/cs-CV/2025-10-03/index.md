---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-10-03
---

# cs.CVï¼ˆ2025-10-03ï¼‰

ğŸ“Š å…± **30** ç¯‡è®ºæ–‡
 | ğŸ”— **5** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (12 ğŸ”—3)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (5)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (5 ğŸ”—1)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ğŸ”—1)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
<a href="#æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting" class="interest-badge">æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (12 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251003555v1-gas-mil-group-aggregative-selection-multi-instance-learning-for-ense.html">GAS-MIL: Group-Aggregative Selection Multi-Instance Learning for Ensemble of Foundation Models in Digital Pathology Image Analysis</a></td>
  <td>æå‡ºGAS-MILæ¡†æ¶ï¼Œç”¨äºæ•°å­—ç—…ç†å›¾åƒåˆ†æä¸­é›†æˆå¤šä¸ªé¢„è®­ç»ƒæ¨¡å‹ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03555v1" onclick="toggleFavorite(this, '2510.03555v1', 'GAS-MIL: Group-Aggregative Selection Multi-Instance Learning for Ensemble of Foundation Models in Digital Pathology Image Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251002922v1-multimodal-carotid-risk-stratification-with-large-vision-language-mo.html">Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights</a></td>
  <td>åˆ©ç”¨å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œå¤šæ¨¡æ€é¢ˆåŠ¨è„‰é£é™©åˆ†å±‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02922v1" onclick="toggleFavorite(this, '2510.02922v1', 'Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251002876v1-elmf4eggq-ensemble-learning-with-multimodal-feature-fusion-for-non-d.html">ELMF4EggQ: Ensemble Learning with Multimodal Feature Fusion for Non-Destructive Egg Quality Assessment</a></td>
  <td>ELMF4EggQï¼šå¤šæ¨¡æ€ç‰¹å¾èåˆçš„é›†æˆå­¦ä¹ ç”¨äºé¸¡è›‹æ— æŸè´¨é‡è¯„ä¼°</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02876v1" onclick="toggleFavorite(this, '2510.02876v1', 'ELMF4EggQ: Ensemble Learning with Multimodal Feature Fusion for Non-Destructive Egg Quality Assessment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251002789v1-align-your-query-representation-alignment-for-multimodality-medical-.html">Align Your Query: Representation Alignment for Multimodality Medical Object Detection</a></td>
  <td>æå‡ºå¤šæ¨¡æ€ä¸Šä¸‹æ–‡æ³¨æ„åŠ›æœºåˆ¶ä»¥è§£å†³åŒ»å­¦ç›®æ ‡æ£€æµ‹ä¸­çš„è¡¨ç¤ºå¯¹é½é—®é¢˜</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02789v1" onclick="toggleFavorite(this, '2510.02789v1', 'Align Your Query: Representation Alignment for Multimodality Medical Object Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251002987v1-tit-score-evaluating-long-prompt-based-text-to-image-alignment-via-t.html">TIT-Score: Evaluating Long-Prompt Based Text-to-Image Alignment via Text-to-Image-to-Text Consistency</a></td>
  <td>æå‡ºTIT-Scoreï¼Œé€šè¿‡æ–‡æœ¬-å›¾åƒ-æ–‡æœ¬ä¸€è‡´æ€§è¯„ä¼°é•¿æ–‡æœ¬æç¤ºä¸‹çš„æ–‡å›¾å¯¹é½è´¨é‡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02987v1" onclick="toggleFavorite(this, '2510.02987v1', 'TIT-Score: Evaluating Long-Prompt Based Text-to-Image Alignment via Text-to-Image-to-Text Consistency')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251002912v2-dont-just-chase-highlighted-tokens-in-mllms-revisiting-visual-holist.html">Don't Just Chase "Highlighted Tokens" in MLLMs: Revisiting Visual Holistic Context Retention</a></td>
  <td>HoloVï¼šä¸€ç§è§†è§‰tokenå‰ªææ¡†æ¶ï¼Œé€šè¿‡å…¨å±€ä¸Šä¸‹æ–‡ä¿ç•™æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ•ˆç‡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02912v2" onclick="toggleFavorite(this, '2510.02912v2', 'Don&#39;t Just Chase &quot;Highlighted Tokens&quot; in MLLMs: Revisiting Visual Holistic Context Retention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251002778v1-adard-key-adaptive-relevance-diversity-keyframe-sampling-for-long-fo.html">AdaRD-key: Adaptive Relevance-Diversity Keyframe Sampling for Long-form Video understanding</a></td>
  <td>æå‡ºAdaRD-Keyï¼Œç”¨äºæŸ¥è¯¢é©±åŠ¨çš„é•¿è§†é¢‘å…³é”®å¸§è‡ªé€‚åº”é‡‡æ ·ï¼Œæå‡è§†é¢‘ç†è§£æ€§èƒ½ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02778v1" onclick="toggleFavorite(this, '2510.02778v1', 'AdaRD-key: Adaptive Relevance-Diversity Keyframe Sampling for Long-form Video understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251003540v1-domain-generalization-for-semantic-segmentation-a-survey.html">Domain Generalization for Semantic Segmentation: A Survey</a></td>
  <td>é¢†åŸŸæ³›åŒ–è¯­ä¹‰åˆ†å‰²ç»¼è¿°ï¼šåˆ†ææ–¹æ³•ä¸æ€§èƒ½ï¼Œå¼ºè°ƒåŸºç¡€æ¨¡å‹çš„å½±å“</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03540v1" onclick="toggleFavorite(this, '2510.03540v1', 'Domain Generalization for Semantic Segmentation: A Survey')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251003441v1-spatial-vilt-enhancing-visual-spatial-reasoning-through-multi-task-l.html">Spatial-ViLT: Enhancing Visual Spatial Reasoning through Multi-Task Learning</a></td>
  <td>Spatial-ViLTé€šè¿‡å¤šä»»åŠ¡å­¦ä¹ å¢å¼ºè§†è§‰ç©ºé—´æ¨ç†èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03441v1" onclick="toggleFavorite(this, '2510.03441v1', 'Spatial-ViLT: Enhancing Visual Spatial Reasoning through Multi-Task Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251003376v1-visual-language-model-as-a-judge-for-object-detection-in-industrial-.html">Visual Language Model as a Judge for Object Detection in Industrial Diagrams</a></td>
  <td>æå‡ºåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„å·¥ä¸šå›¾çº¸å¯¹è±¡æ£€æµ‹è´¨é‡è¯„ä¼°æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03376v1" onclick="toggleFavorite(this, '2510.03376v1', 'Visual Language Model as a Judge for Object Detection in Industrial Diagrams')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251002994v1-towards-scalable-and-consistent-3d-editing.html">Towards Scalable and Consistent 3D Editing</a></td>
  <td>æå‡º3DEditFormerï¼Œå®ç°å¯æ‰©å±•ä¸”ä¸€è‡´çš„3Dç¼–è¾‘ï¼Œå¹¶æ„å»ºå¤§è§„æ¨¡æ•°æ®é›†3DEditVerseã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02994v1" onclick="toggleFavorite(this, '2510.02994v1', 'Towards Scalable and Consistent 3D Editing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251002780v1-reasoning-riddles-how-explainability-reveals-cognitive-limits-in-vis.html">Reasoning Riddles: How Explainability Reveals Cognitive Limits in Vision-Language Models</a></td>
  <td>é€šè¿‡å¯è§£é‡Šæ€§åˆ†ææ­ç¤ºè§†è§‰-è¯­è¨€æ¨¡å‹åœ¨è°œé¢˜æ¨ç†ä¸­çš„è®¤çŸ¥å±€é™</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02780v1" onclick="toggleFavorite(this, '2510.02780v1', 'Reasoning Riddles: How Explainability Reveals Cognitive Limits in Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/251002732v1-from-tokens-to-nodes-semantic-guided-motion-control-for-dynamic-3d-g.html">From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting</a></td>
  <td>æå‡ºè¯­ä¹‰å¼•å¯¼çš„åŠ¨æ€3Dé«˜æ–¯æº…å°„è¿åŠ¨æ§åˆ¶æ–¹æ³•ï¼Œè§£å†³å•ç›®è§†é¢‘åŠ¨æ€é‡å»ºä¸­çš„æ§åˆ¶ç‚¹åˆ†é…éš¾é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02732v1" onclick="toggleFavorite(this, '2510.02732v1', 'From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251008589v1-beyond-cnns-efficient-fine-tuning-of-multi-modal-llms-for-object-det.html">Beyond CNNs: Efficient Fine-Tuning of Multi-Modal LLMs for Object Detection on Low-Data Regimes</a></td>
  <td>åˆ©ç”¨å¤šæ¨¡æ€LLMé«˜æ•ˆå¾®è°ƒï¼Œè§£å†³ä½æ•°æ®é‡ä¸‹çš„ç›®æ ‡æ£€æµ‹é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.08589v1" onclick="toggleFavorite(this, '2510.08589v1', 'Beyond CNNs: Efficient Fine-Tuning of Multi-Modal LLMs for Object Detection on Low-Data Regimes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251003163v3-rogr-relightable-3d-objects-using-generative-relighting.html">ROGR: Relightable 3D Objects using Generative Relighting</a></td>
  <td>ROGRï¼šåˆ©ç”¨ç”Ÿæˆå¼å…‰ç…§é‡æ„å¯é‡æ–°å…‰ç…§çš„3Dç‰©ä½“æ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03163v3" onclick="toggleFavorite(this, '2510.03163v3', 'ROGR: Relightable 3D Objects using Generative Relighting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251002691v2-fsfsplatter-build-surface-and-novel-views-with-sparse-views-within-2.html">FSFSplatter: Build Surface and Novel Views with Sparse-Views within 2min</a></td>
  <td>FSFSplatterï¼šæå‡ºå¿«é€Ÿè¡¨é¢é‡å»ºæ–¹æ³•ï¼Œä»…ç”¨ç¨€ç–è§†å›¾åœ¨2åˆ†é’Ÿå†…æ„å»ºåœºæ™¯ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02691v2" onclick="toggleFavorite(this, '2510.02691v2', 'FSFSplatter: Build Surface and Novel Views with Sparse-Views within 2min')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251003224v1-test-time-defense-against-adversarial-attacks-via-stochastic-resonan.html">Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles</a></td>
  <td>æå‡ºåŸºäºæ½œç©ºé—´é›†æˆçš„éšæœºå…±æŒ¯å¯¹æŠ—æ”»å‡»é˜²å¾¡æ–¹æ³•ï¼Œæ— éœ€è®­ç»ƒä¸”é€‚ç”¨å¤šç§ä»»åŠ¡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03224v1" onclick="toggleFavorite(this, '2510.03224v1', 'Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>18</td>
  <td><a href="./papers/251003232v1-leaml-label-efficient-adaptation-to-out-of-distribution-visual-tasks.html">LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models</a></td>
  <td>LEAMLï¼šé¢å‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œå®ç°æ ‡ç­¾é«˜æ•ˆçš„é¢†åŸŸå¤–è§†è§‰ä»»åŠ¡è‡ªé€‚åº”</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03232v1" onclick="toggleFavorite(this, '2510.03232v1', 'LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251002909v1-training-free-out-of-distribution-segmentation-with-foundation-model.html">Training-Free Out-Of-Distribution Segmentation With Foundation Models</a></td>
  <td>æå‡ºä¸€ç§å…è®­ç»ƒçš„å¼‚å¸¸åˆ†å‰²æ–¹æ³•ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡ŒåŸŸå¤–æ£€æµ‹ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02909v1" onclick="toggleFavorite(this, '2510.02909v1', 'Training-Free Out-Of-Distribution Segmentation With Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251002745v2-retrv-r1-a-reasoning-driven-mllm-framework-for-universal-and-efficie.html">Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval</a></td>
  <td>æå‡ºRetrv-R1ï¼Œä¸€ç§åŸºäºæ¨ç†é©±åŠ¨çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œç”¨äºé€šç”¨ä¸”é«˜æ•ˆçš„å¤šæ¨¡æ€æ£€ç´¢ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02745v2" onclick="toggleFavorite(this, '2510.02745v2', 'Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/251003455v1-pearl-pathway-enhanced-representation-learning-for-gene-and-pathway-.html">PEaRL: Pathway-Enhanced Representation Learning for Gene and Pathway Expression Prediction from Histology</a></td>
  <td>PEaRLï¼šé€šè¿‡é€šè·¯å¢å¼ºè¡¨ç¤ºå­¦ä¹ ï¼Œä»ç»„ç»‡å­¦å›¾åƒé¢„æµ‹åŸºå› å’Œé€šè·¯è¡¨è¾¾</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03455v1" onclick="toggleFavorite(this, '2510.03455v1', 'PEaRL: Pathway-Enhanced Representation Learning for Gene and Pathway Expression Prediction from Histology')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251002654v1-smart-grpo-smartly-sampling-noise-for-efficient-rl-of-flow-matching-.html">Smart-GRPO: Smartly Sampling Noise for Efficient RL of Flow-Matching Models</a></td>
  <td>Smart-GRPOï¼šä¼˜åŒ–å™ªå£°é‡‡æ ·ï¼Œæå‡Flow-Matchingæ¨¡å‹å¼ºåŒ–å­¦ä¹ æ•ˆç‡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02654v1" onclick="toggleFavorite(this, '2510.02654v1', 'Smart-GRPO: Smartly Sampling Noise for Efficient RL of Flow-Matching Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>23</td>
  <td><a href="./papers/251003104v1-geometry-meets-vision-revisiting-pretrained-semantics-in-distilled-f.html">Geometry Meets Vision: Revisiting Pretrained Semantics in Distilled Fields</a></td>
  <td>ç ”ç©¶å‡ ä½•ä¿¡æ¯åœ¨ç¥ç»è¾å°„åœºè¯­ä¹‰è’¸é¦ä¸­çš„ä½œç”¨ï¼Œå¹¶æå‡ºSPINEæ¡†æ¶å®ç°æ— åˆå§‹çŒœæµ‹çš„è¾å°„åœºåæ¼”ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03104v1" onclick="toggleFavorite(this, '2510.03104v1', 'Geometry Meets Vision: Revisiting Pretrained Semantics in Distilled Fields')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/251003545v1-sketchplan-diffusion-based-drone-planning-from-human-sketches.html">SketchPlan: Diffusion Based Drone Planning From Human Sketches</a></td>
  <td>SketchPlanï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„æ— äººæœºè§„åˆ’ï¼Œä»äººç±»è‰å›¾ç”Ÿæˆé£è¡Œè·¯å¾„</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03545v1" onclick="toggleFavorite(this, '2510.03545v1', 'SketchPlan: Diffusion Based Drone Planning From Human Sketches')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/251003135v2-mask2iv-interaction-centric-video-generation-via-mask-trajectories.html">Mask2IV: Interaction-Centric Video Generation via Mask Trajectories</a></td>
  <td>Mask2IVï¼šé€šè¿‡Maskè½¨è¿¹å®ç°äº¤äº’ä¸­å¿ƒè§†é¢‘ç”Ÿæˆï¼Œæ— éœ€å¯†é›†Maskæ ‡æ³¨ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03135v2" onclick="toggleFavorite(this, '2510.03135v2', 'Mask2IV: Interaction-Centric Video Generation via Mask Trajectories')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/251003550v2-streaming-drag-oriented-interactive-video-manipulation-drag-anything.html">Streaming Drag-Oriented Interactive Video Manipulation: Drag Anything, Anytime!</a></td>
  <td>æå‡ºDragStreamï¼Œå®ç°åŸºäºæ‹–æ‹½çš„æµå¼äº¤äº’è§†é¢‘ç¼–è¾‘ï¼Œæ”¯æŒä»»æ„å¯¹è±¡ã€ä»»æ„æ—¶åˆ»çš„ç²¾ç»†æ§åˆ¶ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03550v2" onclick="toggleFavorite(this, '2510.03550v2', 'Streaming Drag-Oriented Interactive Video Manipulation: Drag Anything, Anytime!')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/251002790v1-maskcd-mitigating-lvlm-hallucinations-by-image-head-masked-contrasti.html">MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding</a></td>
  <td>æå‡ºMaskCDï¼Œé€šè¿‡å›¾åƒå¤´æ©ç å¯¹æ¯”è§£ç ç¼“è§£LVLMå¹»è§‰é—®é¢˜</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02790v1" onclick="toggleFavorite(this, '2510.02790v1', 'MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>28</td>
  <td><a href="./papers/251002722v1-mogic-boosting-motion-generation-via-intention-understanding-and-vis.html">MoGIC: Boosting Motion Generation via Intention Understanding and Visual Context</a></td>
  <td>MoGICï¼šé€šè¿‡æ„å›¾ç†è§£å’Œè§†è§‰ä¸Šä¸‹æ–‡å¢å¼ºè¿åŠ¨ç”Ÿæˆ</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02722v1" onclick="toggleFavorite(this, '2510.02722v1', 'MoGIC: Boosting Motion Generation via Intention Understanding and Visual Context')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>29</td>
  <td><a href="./papers/251003152v1-reemark-reeb-graphs-for-simulating-patterns-of-life-in-spatiotempora.html">ReeMark: Reeb Graphs for Simulating Patterns of Life in Spatiotemporal Trajectories</a></td>
  <td>æå‡ºReeMarkï¼Œåˆ©ç”¨Reebå›¾æ¨¡æ‹Ÿæ—¶ç©ºè½¨è¿¹ä¸­çš„ç”Ÿæ´»æ¨¡å¼ï¼Œç”¨äºåŸå¸‚è§„åˆ’ç­‰ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03152v1" onclick="toggleFavorite(this, '2510.03152v1', 'ReeMark: Reeb Graphs for Simulating Patterns of Life in Spatiotemporal Trajectories')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting">ğŸ”¬ æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>30</td>
  <td><a href="./papers/251003110v1-geocomplete-geometry-aware-diffusion-for-reference-driven-image-comp.html">GeoComplete: Geometry-Aware Diffusion for Reference-Driven Image Completion</a></td>
  <td>GeoCompleteï¼šæå‡ºå‡ ä½•æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå‚è€ƒå›¾åƒé©±åŠ¨çš„å›¾åƒè¡¥å…¨ï¼Œæ˜¾è‘—æå‡å‡ ä½•ä¸€è‡´æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.03110v1" onclick="toggleFavorite(this, '2510.03110v1', 'GeoComplete: Geometry-Aware Diffusion for Reference-Driven Image Completion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)