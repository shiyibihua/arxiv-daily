---
layout: default
title: LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA
---

# LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10026" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.10026v3</a>
  <a href="https://arxiv.org/pdf/2509.10026.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10026v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10026v3', 'LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Jing Huang, Zhiya Tan, Shutao Gong, Fanwei Zeng, Joey Tianyi Zhou, Changtao Miao, Huazhe Tan, Weibin Yao, Jianshu Li

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-12 (Êõ¥Êñ∞: 2025-10-10)

**Â§áÊ≥®**: 12 Pages, 12 Figures, 3 Tables

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/HJNVR/LaV-CoT)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫LaV-CoTÊ°ÜÊû∂ÔºåÈÄöËøáÂ§öÊñπÈù¢Â•ñÂä±‰ºòÂåñÔºåËß£ÂÜ≥ÁúüÂÆû‰∏ñÁïåÂ§öËØ≠Ë®ÄVQAÈóÆÈ¢ò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öËØ≠Ë®ÄËßÜËßâÈóÆÁ≠î` `ÊÄùÁª¥Èìæ` `Â§öÊ®°ÊÄÅÊé®ÁêÜ` `Â•ñÂä±‰ºòÂåñ` `ËØ≠Ë®ÄÊÑüÁü•` `Êï∞ÊçÆÁîüÊàê` `Á≠ñÁï•‰ºòÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâmVQAÊñπÊ≥ï‰∏ªË¶Å‰æùËµñÊñáÊú¨CoTÔºåÁº∫‰πèÂØπÂ§öËØ≠Ë®ÄÂ§öÊ®°ÊÄÅÊé®ÁêÜÁöÑÊúâÊïàÊîØÊåÅÔºåÈôêÂà∂‰∫ÜÂÆûÈôÖÂ∫îÁî®„ÄÇ
2. LaV-CoTÊèêÂá∫ËØ≠Ë®ÄÊÑüÁü•ÁöÑËßÜËßâCoTÊ°ÜÊû∂ÔºåÂåÖÂê´Â§öÈò∂ÊÆµÊé®ÁêÜÊµÅÁ®ãÂíåÂ§öÊñπÈù¢Â•ñÂä±‰ºòÂåñÔºåÊèêÂçáÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåLaV-CoTÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÊ®°ÂûãÔºåÂπ∂Âú®ÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆ‰∏äÈ™åËØÅ‰∫ÜÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÂ§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàVLMsÔºâÁöÑÂèëÂ±ïÔºåÂÆÉ‰ª¨Âú®Â§öËØ≠Ë®ÄËßÜËßâÈóÆÁ≠îÔºàmVQAÔºâÊñπÈù¢ÁöÑËÉΩÂäõÂæóÂà∞‰∫ÜÊòæËëóÊèêÈ´ò„ÄÇÊÄùÁª¥ÈìæÔºàCoTÔºâÊé®ÁêÜÂ∑≤Ë¢´ËØÅÊòéÂèØ‰ª•Â¢ûÂº∫ÂèØËß£ÈáäÊÄßÂíåÂ§çÊùÇÊé®ÁêÜ„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∞Áé∞ÊúâÊñπÊ≥ï‰∏ªË¶Å‰æùËµñ‰∫éÊñáÊú¨CoTÔºåÂπ∂‰∏îÂØπÂ§öËØ≠Ë®ÄÂ§öÊ®°ÊÄÅÊé®ÁêÜÁöÑÊîØÊåÅÊúâÈôêÔºå‰ªéËÄåÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÈÉ®ÁΩ≤„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜLaV-CoTÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™ÂÖ∑ÊúâÂ§öÊñπÈù¢Â•ñÂä±‰ºòÂåñÁöÑËØ≠Ë®ÄÊÑüÁü•ËßÜËßâCoTÊ°ÜÊû∂„ÄÇLaV-CoTÂåÖÂê´‰∏Ä‰∏™ÂèØËß£ÈáäÁöÑÂ§öÈò∂ÊÆµÊé®ÁêÜÊµÅÁ®ãÔºåÂåÖÊã¨Â∏¶ÊúâËæπÁïåÊ°ÜÁöÑÊñáÊú¨ÊëòË¶Å„ÄÅËØ≠Ë®ÄËØÜÂà´„ÄÅÁ©∫Èó¥ÂØπË±°Á∫ßÊèèËø∞ÂíåÈÄêÊ≠•ÈÄªËæëÊé®ÁêÜ„ÄÇÈÅµÂæ™Ê≠§Êé®ÁêÜÊµÅÁ®ãÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏ÄÁßçËá™Âä®Êï∞ÊçÆÁÆ°ÁêÜÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÈÄöËøáËø≠‰ª£ÁîüÊàê„ÄÅÊ†°Ê≠£ÂíåÁªÜÂåñÊù•ÁîüÊàêÂ§öËØ≠Ë®ÄCoTÊ≥®ÈáäÔºå‰ªéËÄåÂÆûÁé∞ÂèØÊâ©Â±ïÁöÑÈ´òË¥®ÈáèËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ‰∏∫‰∫ÜÊèêÈ´òÊé®ÁêÜÂíåÊ≥õÂåñËÉΩÂäõÔºåLaV-CoTÈááÁî®‰∫Ü‰∏ÄÁßç‰∏§Èò∂ÊÆµËÆ≠ÁªÉËåÉ‰æãÔºåÂ∞ÜÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâ‰∏éËØ≠Ë®ÄÊÑüÁü•ÁªÑÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâÁõ∏ÁªìÂêàÔºåÂπ∂‰ª•ÂèØÈ™åËØÅÁöÑÂ§öÊñπÈù¢Â•ñÂä±ÔºàÂåÖÊã¨ËØ≠Ë®Ä‰∏ÄËá¥ÊÄß„ÄÅÁªìÊûÑÂáÜÁ°ÆÊÄßÂíåËØ≠‰πâÂØπÈΩêÔºâ‰∏∫ÊåáÂØº„ÄÇÂú®ÂåÖÊã¨MMMB„ÄÅMultilingual MMBenchÂíåMTVQAÂú®ÂÜÖÁöÑÂÖ¨ÂÖ±Êï∞ÊçÆÈõÜ‰∏äÁöÑÂ§ßÈáèËØÑ‰º∞Ë°®ÊòéÔºåLaV-CoTÁöÑÂáÜÁ°ÆÁéáÊØîÁ±ª‰ººËßÑÊ®°ÁöÑÂºÄÊ∫êÂü∫Á∫øÊèêÈ´ò‰∫ÜÈ´òËææ~9.5%ÔºåÁîöËá≥Ë∂ÖËøá‰∫ÜËßÑÊ®°Â§ß2ÂÄçÁöÑÊ®°ÂûãÁ∫¶~2.6%„ÄÇÊ≠§Â§ñÔºåLaV-CoTÁöÑÊÄßËÉΩ‰ºò‰∫éGPT-4o-0513ÂíåGemini-2.5-flashÁ≠âÂÖàËøõÁöÑ‰∏ìÊúâÊ®°Âûã„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•ËøõË°å‰∫ÜÂú®Á∫øA/BÊµãËØïÔºå‰ª•È™åËØÅÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆ‰∏äÁöÑÊúâÊïàÊÄßÔºåÁ™ÅÂá∫‰∫ÜÂÖ∂Âú®Â∑•‰∏öÈÉ®ÁΩ≤‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂèØÂú®‰ª•‰∏ãÈìæÊé•Ëé∑ÂæóÔºöhttps://github.com/HJNVR/LaV-CoT

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÁúüÂÆû‰∏ñÁïåÂ§öËØ≠Ë®ÄËßÜËßâÈóÆÁ≠îÔºàmVQAÔºâÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶Å‰æùËµñ‰∫éÊñáÊú¨ÊÄùÁª¥ÈìæÔºàCoTÔºâÔºåÁº∫‰πèÂØπÂ§öËØ≠Ë®ÄÂíåÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÁöÑÊúâÊïàÂà©Áî®ÔºåÂØºËá¥Êé®ÁêÜËÉΩÂäõ‰∏çË∂≥ÔºåÈöæ‰ª•ÈÄÇÂ∫îÂ§çÊùÇÂú∫ÊôØ„ÄÇÊ≠§Â§ñÔºåÁº∫‰πèÈ´òË¥®ÈáèÁöÑÂ§öËØ≠Ë®ÄCoTÊï∞ÊçÆ‰πüÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöLaV-CoTÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™ËØ≠Ë®ÄÊÑüÁü•ÁöÑËßÜËßâCoTÊ°ÜÊû∂ÔºåÈÄöËøáÂ§öÈò∂ÊÆµÊé®ÁêÜÊµÅÁ®ãÂíåÂ§öÊñπÈù¢Â•ñÂä±‰ºòÂåñÔºåÂ¢ûÂº∫Ê®°ÂûãÁöÑÂ§öËØ≠Ë®ÄÂ§öÊ®°ÊÄÅÊé®ÁêÜËÉΩÂäõ„ÄÇËØ•ÊñπÊ≥ïÊòæÂºèÂú∞ËÄÉËôë‰∫ÜËØ≠Ë®Ä‰ø°ÊÅØÔºåÂπ∂Âà©Áî®ËßÜËßâ‰ø°ÊÅØËæÖÂä©Êé®ÁêÜÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÂáÜÁ°ÆÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöLaV-CoTÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) **ÊñáÊú¨ÊëòË¶Å‰∏éËæπÁïåÊ°ÜÔºàBBoxÔºâ**ÔºöÊèêÂèñÂõæÂÉèÁõ∏ÂÖ≥ÊñáÊú¨‰ø°ÊÅØÂíåÁõÆÊ†á‰ΩçÁΩÆ„ÄÇ2) **ËØ≠Ë®ÄËØÜÂà´**ÔºöÁ°ÆÂÆöËæìÂÖ•ÈóÆÈ¢òÁöÑËØ≠Ë®Ä„ÄÇ3) **Á©∫Èó¥ÂØπË±°Á∫ßÊèèËø∞**ÔºöÁîüÊàêÂõæÂÉè‰∏≠ÂØπË±°ÁöÑËØ¶ÁªÜÊèèËø∞„ÄÇ4) **ÈÄêÊ≠•ÈÄªËæëÊé®ÁêÜ**ÔºöÂü∫‰∫é‰ª•‰∏ä‰ø°ÊÅØËøõË°åÈÄêÊ≠•Êé®ÁêÜÔºåÊúÄÁªàÂæóÂá∫Á≠îÊ°à„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòËÆæËÆ°‰∫ÜËá™Âä®Êï∞ÊçÆÁîüÊàêÊñπÊ≥ïÔºåËø≠‰ª£ÁîüÊàê„ÄÅÊ†°Ê≠£ÂíåÁªÜÂåñÂ§öËØ≠Ë®ÄCoTÊï∞ÊçÆ„ÄÇËÆ≠ÁªÉËøáÁ®ãÂàÜ‰∏∫‰∏§‰∏™Èò∂ÊÆµÔºöÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâÂíåËØ≠Ë®ÄÊÑüÁü•ÁªÑÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöLaV-CoTÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫ÜËØ≠Ë®ÄÊÑüÁü•ÁöÑËßÜËßâCoTÊ°ÜÊû∂ÔºåÊòæÂºèÂú∞ËÄÉËôë‰∫ÜËØ≠Ë®Ä‰ø°ÊÅØ„ÄÇ2) ËÆæËÆ°‰∫ÜÂ§öÈò∂ÊÆµÊé®ÁêÜÊµÅÁ®ãÔºåÂ∞ÜÂ§çÊùÇÊé®ÁêÜËøáÁ®ãÂàÜËß£‰∏∫Â§ö‰∏™ÂèØËß£ÈáäÁöÑÊ≠•È™§„ÄÇ3) ÊèêÂá∫‰∫ÜÂ§öÊñπÈù¢Â•ñÂä±‰ºòÂåñÊñπÊ≥ïÔºåÂà©Áî®ËØ≠Ë®Ä‰∏ÄËá¥ÊÄß„ÄÅÁªìÊûÑÂáÜÁ°ÆÊÄßÂíåËØ≠‰πâÂØπÈΩêÁ≠âÊåáÊ†áÊåáÂØºÊ®°ÂûãËÆ≠ÁªÉ„ÄÇ4) ÊèêÂá∫‰∫ÜËá™Âä®Êï∞ÊçÆÁîüÊàêÊñπÊ≥ïÔºåËß£ÂÜ≥‰∫ÜÂ§öËØ≠Ë®ÄCoTÊï∞ÊçÆÁ®ÄÁº∫ÁöÑÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆ≠ÁªÉÈò∂ÊÆµÔºå‰ΩøÁî®‰∫ÜËØ≠Ë®ÄÊÑüÁü•ÁªÑÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâÔºåËØ•ÊñπÊ≥ïÊ†πÊçÆËØ≠Ë®ÄÁ±ªÂûãÂØπÊ†∑Êú¨ËøõË°åÂàÜÁªÑÔºåÂπ∂‰ΩøÁî®Áõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÁÆóÊ≥ïËøõË°åËÆ≠ÁªÉÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÂ§öÊñπÈù¢Â•ñÂä±ÂáΩÊï∞ÁªºÂêàËÄÉËôë‰∫ÜËØ≠Ë®Ä‰∏ÄËá¥ÊÄß„ÄÅÁªìÊûÑÂáÜÁ°ÆÊÄßÂíåËØ≠‰πâÂØπÈΩêÁ≠âÂõ†Á¥†Ôºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÊåáÂØºÊ®°ÂûãÂ≠¶‰π†„ÄÇËá™Âä®Êï∞ÊçÆÁîüÊàêÊñπÊ≥ïÈÄöËøáËø≠‰ª£ÁîüÊàê„ÄÅÊ†°Ê≠£ÂíåÁªÜÂåñÔºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑË¥®ÈáèÂíåÂ§öÊ†∑ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

LaV-CoTÂú®MMMB„ÄÅMultilingual MMBenchÂíåMTVQAÁ≠âÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÁõ∏ÊØîÂêåÁ≠âËßÑÊ®°ÁöÑÂºÄÊ∫êÊ®°ÂûãÔºåÂáÜÁ°ÆÁéáÊèêÂçáÈ´òËææ9.5%ÔºåÁîöËá≥Ë∂ÖË∂ä‰∫ÜËßÑÊ®°ÊòØÂÖ∂‰∏§ÂÄçÁöÑÊ®°Âûã2.6%„ÄÇÊ≠§Â§ñÔºåLaV-CoTÁöÑÊÄßËÉΩ‰ºò‰∫éGPT-4o-0513ÂíåGemini-2.5-flashÁ≠âÂÖàËøõÁöÑ‰∏ìÊúâÊ®°Âûã„ÄÇÂú®Á∫øA/BÊµãËØï‰πüÈ™åËØÅ‰∫ÜËØ•ÊñπÊ≥ïÂú®ÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆ‰∏äÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

LaV-CoTÊ°ÜÊû∂ÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩÂÆ¢Êúç„ÄÅÊïôËÇ≤ËæÖÂä©„ÄÅË∑®Â¢ÉÁîµÂïÜÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Êô∫ËÉΩÂÆ¢Êúç‰∏≠ÔºåÂèØ‰ª•Â∏ÆÂä©Áî®Êà∑ÁêÜËß£Â§öËØ≠Ë®ÄÁöÑÂïÜÂìÅ‰ø°ÊÅØÂíå‰ΩøÁî®ËØ¥ÊòéÔºõÂú®ÊïôËÇ≤ËæÖÂä©‰∏≠ÔºåÂèØ‰ª•Â∏ÆÂä©Â≠¶ÁîüÁêÜËß£Â§öËØ≠Ë®ÄÁöÑÊïôÊùêÂíåÂ≠¶‰π†ËµÑÊñô„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÊèêÂçáÂ§öËØ≠Ë®ÄÁéØÂ¢É‰∏ã‰∫∫Êú∫‰∫§‰∫íÁöÑÊô∫ËÉΩÂåñÊ∞¥Âπ≥ÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄºÂíåÂπøÈòîÁöÑÂèëÂ±ïÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> As large vision language models (VLMs) advance, their capabilities in multilingual visual question answering (mVQA) have significantly improved. Chain-of-thought (CoT) reasoning has been proven to enhance interpretability and complex reasoning. However, most existing approaches rely primarily on textual CoT and provide limited support for multilingual multimodal reasoning, constraining their deployment in real-world applications. To address this gap, we introduce LaV-CoT, the first Language-aware Visual CoT framework with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable multi-stage reasoning pipeline consisting of Text Summary with Bounding Box (BBox), Language Identification, Spatial Object-level Captioning, and Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an automated data curation method that generates multilingual CoT annotations through iterative generation, correction, and refinement, enabling scalable and high-quality training data. To improve reasoning and generalization, LaV-CoT adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT) with Language-aware Group Relative Policy Optimization (GRPO), guided by verifiable multi-aspect rewards including language consistency, structural accuracy, and semantic alignment. Extensive evaluations on public datasets including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up to ~9.5% accuracy improvements over open-source baselines of similar size and even surpasses models with 2$\times$ larger scales by ~2.6%. Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513 and Gemini-2.5-flash. We further conducted an online A/B test to validate our method on real-world data, highlighting its effectiveness for industrial deployment. Our code is available at this link: https://github.com/HJNVR/LaV-CoT

