---
layout: default
title: Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence
---

# Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence

**arXiv**: [2510.20470v1](https://arxiv.org/abs/2510.20470) | [PDF](https://arxiv.org/pdf/2510.20470.pdf)

**ä½œè€…**: Kun Ouyang, Yuanxin Liu, Linli Yao, Yishuo Cai, Hao Zhou, Jie Zhou, Fandong Meng, Xu Sun

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºConanæ¡†æž¶ä»¥è§£å†³å¤šæ­¥è§†é¢‘æŽ¨ç†ä¸­çš„è¯æ®å®šä½ä¸Žå¹»è§‰é—®é¢˜**

**å…³é”®è¯**: `å¤šæ­¥è§†é¢‘æŽ¨ç†` `è¯æ®æŽ¥åœ°` `å¼ºåŒ–å­¦ä¹ ` `é•¿è§†é¢‘ç†è§£` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `æ¸è¿›å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹åœ¨å¤šæ­¥è§†é¢‘æŽ¨ç†ä¸­æ˜“äº§ç”ŸæœªæŽ¥åœ°æˆ–å¹»è§‰ç»“è®º
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºConan-91Kæ•°æ®é›†å¹¶é‡‡ç”¨å¤šé˜¶æ®µæ¸è¿›å†·å¯åŠ¨ä¸ŽAIRå¼ºåŒ–å­¦ä¹ æ¡†æž¶
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å…­ä¸ªåŸºå‡†ä¸Šå¹³å‡å‡†ç¡®çŽ‡è¶…åŸºçº¿10%ï¼Œå®žçŽ°SOTAæ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video reasoning, which requires multi-step deduction across frames, remains a
> major challenge for multimodal large language models (MLLMs). While
> reinforcement learning (RL)-based methods enhance reasoning capabilities, they
> often rely on text-only chains that yield ungrounded or hallucinated
> conclusions. Conversely, frame-retrieval approaches introduce visual grounding
> but still struggle with inaccurate evidence localization. To address these
> challenges, we present Conan, a framework for evidence-grounded multi-step
> video reasoning. Conan identifies contextual and evidence frames, reasons over
> cross-frame clues, and adaptively decides when to conclude or explore further.
> To achieve this, we (1) construct Conan-91K, a large-scale dataset of
> automatically generated reasoning traces that includes frame identification,
> evidence reasoning, and action decision, and (2) design a multi-stage
> progressive cold-start strategy combined with an
> Identification-Reasoning-Action (AIR) RLVR training framework to jointly
> enhance multi-step visual reasoning. Extensive experiments on six multi-step
> reasoning benchmarks demonstrate that Conan surpasses the baseline
> Qwen2.5-VL-7B-Instruct by an average of over 10% in accuracy, achieving
> state-of-the-art performance. Furthermore, Conan generalizes effectively to
> long-video understanding tasks, validating its strong scalability and
> robustness.

