---
layout: default
title: A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization
---

# A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization

**arXiv**: [2510.20291v1](https://arxiv.org/abs/2510.20291) | [PDF](https://arxiv.org/pdf/2510.20291.pdf)

**ä½œè€…**: LinFeng Li, Jian Zhao, Zepeng Yang, Yuhang Song, Bojun Lin, Tianle Zhang, Yuchen Yuan, Chi Zhang, Xuelong Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå‚æ•°é«˜æ•ˆä¸“å®¶æ··åˆæ¡†æž¶ï¼Œè§£å†³è·¨æ¨¡æ€å¼‚æž„å¹³å°åœ°ç†å®šä½é—®é¢˜ã€‚**

**å…³é”®è¯**: `è·¨æ¨¡æ€æ£€ç´¢` `ä¸“å®¶æ··åˆæ¡†æž¶` `åœ°ç†å®šä½` `é¢†åŸŸå¯¹é½` `å¼‚æž„å¹³å°` `å›¾åƒæ£€ç´¢`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè·¨å¹³å°å¼‚æž„æ€§å’Œé¢†åŸŸå·®è·é˜»ç¢è‡ªç„¶è¯­è¨€æŸ¥è¯¢ä¸Žåœ°ç†å›¾åƒæ£€ç´¢ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨é¢†åŸŸå¯¹é½é¢„å¤„ç†å’Œä¸“å®¶æ··åˆæ¡†æž¶ï¼Œå¢žå¼ºè¯­ä¹‰ä¸Žè§†è§‰å¯¹é½ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨RoboSense 2025ç«žèµ›ä¸­æŽ’åç¬¬ä¸€ï¼ŒéªŒè¯äº†é²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present a winning solution to RoboSense 2025 Track 4: Cross-Modal Drone
> Navigation. The task retrieves the most relevant geo-referenced image from a
> large multi-platform corpus (satellite/drone/ground) given a natural-language
> query. Two obstacles are severe inter-platform heterogeneity and a domain gap
> between generic training descriptions and platform-specific test queries. We
> mitigate these with a domain-aligned preprocessing pipeline and a
> Mixture-of-Experts (MoE) framework: (i) platform-wise partitioning, satellite
> augmentation, and removal of orientation words; (ii) an LLM-based caption
> refinement pipeline to align textual semantics with the distinct visual
> characteristics of each platform. Using BGE-M3 (text) and EVA-CLIP (image), we
> train three platform experts using a progressive two-stage, hard-negative
> mining strategy to enhance discriminative power, and fuse their scores at
> inference. The system tops the official leaderboard, demonstrating robust
> cross-modal geo-localization under heterogeneous viewpoints.

