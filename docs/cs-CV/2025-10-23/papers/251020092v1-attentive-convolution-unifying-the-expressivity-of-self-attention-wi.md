---
layout: default
title: Attentive Convolution: Unifying the Expressivity of Self-Attention with Convolutional Efficiency
---

# Attentive Convolution: Unifying the Expressivity of Self-Attention with Convolutional Efficiency

**arXiv**: [2510.20092v1](https://arxiv.org/abs/2510.20092) | [PDF](https://arxiv.org/pdf/2510.20092.pdf)

**ä½œè€…**: Hao Yu, Haoyu Chen, Yan Jiang, Wei Peng, Zhaodong Sun, Samuel Kaski, Guoying Zhao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAttentive Convolutionä»¥ç»Ÿä¸€è‡ªæ³¨æ„åŠ›çš„è¡¨è¾¾åŠ›ä¸Žå·ç§¯çš„æ•ˆçŽ‡**

**å…³é”®è¯**: `è‡ªæ³¨æ„åŠ›æœºåˆ¶` `å·ç§¯ç¥žç»ç½‘ç»œ` `å›¾åƒåˆ†ç±»` `æ‰©æ•£æ¨¡åž‹` `è®¡ç®—æ•ˆçŽ‡` `è‡ªé€‚åº”è·¯ç”±`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è‡ªæ³¨æ„åŠ›è¡¨è¾¾åŠ›å¼ºä½†å¤æ‚åº¦é«˜ï¼Œå·ç§¯æ•ˆçŽ‡é«˜ä½†æ€§èƒ½å­˜åœ¨å·®è·
2. å¼•å…¥è‡ªé€‚åº”è·¯ç”±å’Œä¾§å‘æŠ‘åˆ¶åŽŸåˆ™ï¼Œè®¾è®¡ATConvå·ç§¯ç®—å­
3. åœ¨ImageNetåˆ†ç±»å’Œæ‰©æ•£ç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒATConvè¶…è¶Šè‡ªæ³¨æ„åŠ›æœºåˆ¶

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Self-attention (SA) has become the cornerstone of modern vision backbones for
> its powerful expressivity over traditional Convolutions (Conv). However, its
> quadratic complexity remains a critical bottleneck for practical applications.
> Given that Conv offers linear complexity and strong visual priors, continuing
> efforts have been made to promote the renaissance of Conv. However, a
> persistent performance chasm remains, highlighting that these modernizations
> have not yet captured the intrinsic expressivity that defines SA. In this
> paper, we re-examine the design of the CNNs, directed by a key question: what
> principles give SA its edge over Conv? As a result, we reveal two fundamental
> insights that challenge the long-standing design intuitions in prior research
> (e.g., Receptive field). The two findings are: (1) \textit{Adaptive routing}:
> SA dynamically regulates positional information flow according to semantic
> content, whereas Conv employs static kernels uniformly across all positions.
> (2) \textit{Lateral inhibition}: SA induces score competition among token
> weighting, effectively suppressing redundancy and sharpening representations,
> whereas Conv filters lack such inhibitory dynamics and exhibit considerable
> redundancy. Based on this, we propose \textit{Attentive Convolution} (ATConv),
> a principled reformulation of the convolutional operator that intrinsically
> injects these principles. Interestingly, with only $3\times3$ kernels, ATConv
> consistently outperforms various SA mechanisms in fundamental vision tasks.
> Building on ATConv, we introduce AttNet, a CNN family that can attain
> \textbf{84.4\%} ImageNet-1K Top-1 accuracy with only 27M parameters. In
> diffusion-based image generation, replacing all SA with the proposed $3\times
> 3$ ATConv in SiT-XL/2 reduces ImageNet FID by 0.15 in 400k steps with faster
> sampling. Code is available at: github.com/price112/Attentive-Convolution.

