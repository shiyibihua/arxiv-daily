---
layout: default
title: PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding
---

# PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding

**arXiv**: [2510.20155v1](https://arxiv.org/abs/2510.20155) | [PDF](https://arxiv.org/pdf/2510.20155.pdf)

**ä½œè€…**: Penghao Wang, Yiyang He, Xin Lv, Yukai Zhou, Lan Xu, Jingyi Yu, Jiayuan Gu

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPartNeXtæ•°æ®é›†ä»¥è§£å†³3Dç»†ç²’åº¦å’Œå±‚æ¬¡åŒ–éƒ¨ä»¶ç†è§£çš„å¯æ‰©å±•æ€§å’Œå¯ç”¨æ€§é—®é¢˜**

**å…³é”®è¯**: `3Déƒ¨ä»¶ç†è§£` `ç»†ç²’åº¦åˆ†å‰²` `å±‚æ¬¡åŒ–æ ‡æ³¨` `çº¹ç†3Dæ•°æ®é›†` `éƒ¨ä»¶é—®ç­”åŸºå‡†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ•°æ®é›†ä¾èµ–æ— çº¹ç†å‡ ä½•å’Œä¸“å®¶æ ‡æ³¨ï¼Œé™åˆ¶3Déƒ¨ä»¶ç†è§£çš„æ‰©å±•
2. PartNeXtåŒ…å«2.3ä¸‡é«˜è´¨é‡çº¹ç†3Dæ¨¡å‹ï¼Œæ ‡æ³¨50ç±»ç»†ç²’åº¦å±‚æ¬¡åŒ–éƒ¨ä»¶
3. åŸºå‡†æµ‹è¯•æ˜¾ç¤ºåœ¨éƒ¨ä»¶åˆ†å‰²å’Œ3Déƒ¨ä»¶é—®ç­”ä»»åŠ¡ä¸­æå‡æ€§èƒ½ï¼Œè®­ç»ƒPoint-SAMä¼˜äºPartNet

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Understanding objects at the level of their constituent parts is fundamental
> to advancing computer vision, graphics, and robotics. While datasets like
> PartNet have driven progress in 3D part understanding, their reliance on
> untextured geometries and expert-dependent annotation limits scalability and
> usability. We introduce PartNeXt, a next-generation dataset addressing these
> gaps with over 23,000 high-quality, textured 3D models annotated with
> fine-grained, hierarchical part labels across 50 categories. We benchmark
> PartNeXt on two tasks: (1) class-agnostic part segmentation, where
> state-of-the-art methods (e.g., PartField, SAMPart3D) struggle with
> fine-grained and leaf-level parts, and (2) 3D part-centric question answering,
> a new benchmark for 3D-LLMs that reveals significant gaps in open-vocabulary
> part grounding. Additionally, training Point-SAM on PartNeXt yields substantial
> gains over PartNet, underscoring the dataset's superior quality and diversity.
> By combining scalable annotation, texture-aware labels, and multi-task
> evaluation, PartNeXt opens new avenues for research in structured 3D
> understanding.

