---
layout: default
title: COS3D: Collaborative Open-Vocabulary 3D Segmentation
---

# COS3D: Collaborative Open-Vocabulary 3D Segmentation

**arXiv**: [2510.20238v1](https://arxiv.org/abs/2510.20238) | [PDF](https://arxiv.org/pdf/2510.20238.pdf)

**ä½œè€…**: Runsong Zhu, Ka-Hei Hui, Zhengzhe Liu, Qianyi Wu, Weiliang Tang, Shi Qiu, Pheng-Ann Heng, Chi-Wing Fu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCOS3Dåä½œæ¡†æž¶ä»¥è§£å†³å¼€æ”¾è¯æ±‡3Dåˆ†å‰²ä¸­çš„è¯­è¨€ä¸Žåˆ†å‰²èžåˆé—®é¢˜**

**å…³é”®è¯**: `å¼€æ”¾è¯æ±‡3Dåˆ†å‰²` `åä½œåœº` `å®žä¾‹åœº` `è¯­è¨€åœº` `ä¸¤é˜¶æ®µè®­ç»ƒ` `è‡ªé€‚åº”æç¤ºä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•ä¾èµ–å•ä¸€è¯­è¨€åœºæˆ–é¢„è®¡ç®—åˆ†å‰²ï¼Œå¯¼è‡´åˆ†å‰²è´¨é‡å·®å’Œè¯¯å·®ç´¯ç§¯ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥åä½œåœºæ¦‚å¿µï¼Œç»“åˆå®žä¾‹åœºå’Œè¯­è¨€åœºï¼Œé€šè¿‡ç‰¹å¾æ˜ å°„å’Œä¸¤é˜¶æ®µè®­ç»ƒä¼˜åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨çŽ°é¢†å…ˆï¼Œæ”¯æŒå›¾åƒåˆ†å‰²ã€å±‚æ¬¡åˆ†å‰²å’Œæœºå™¨äººåº”ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Open-vocabulary 3D segmentation is a fundamental yet challenging task,
> requiring a mutual understanding of both segmentation and language. However,
> existing Gaussian-splatting-based methods rely either on a single 3D language
> field, leading to inferior segmentation, or on pre-computed class-agnostic
> segmentations, suffering from error accumulation. To address these limitations,
> we present COS3D, a new collaborative prompt-segmentation framework that
> contributes to effectively integrating complementary language and segmentation
> cues throughout its entire pipeline. We first introduce the new concept of
> collaborative field, comprising an instance field and a language field, as the
> cornerstone for collaboration. During training, to effectively construct the
> collaborative field, our key idea is to capture the intrinsic relationship
> between the instance field and language field, through a novel
> instance-to-language feature mapping and designing an efficient two-stage
> training strategy. During inference, to bridge distinct characteristics of the
> two fields, we further design an adaptive language-to-instance prompt
> refinement, promoting high-quality prompt-segmentation inference. Extensive
> experiments not only demonstrate COS3D's leading performance over existing
> methods on two widely-used benchmarks but also show its high potential to
> various applications,~\ie, novel image-based 3D segmentation, hierarchical
> segmentation, and robotics. The code is publicly available at
> \href{https://github.com/Runsong123/COS3D}{https://github.com/Runsong123/COS3D}.

