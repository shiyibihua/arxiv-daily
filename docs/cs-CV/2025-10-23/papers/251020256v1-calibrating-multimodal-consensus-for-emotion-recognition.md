---
layout: default
title: Calibrating Multimodal Consensus for Emotion Recognition
---

# Calibrating Multimodal Consensus for Emotion Recognition

**arXiv**: [2510.20256v1](https://arxiv.org/abs/2510.20256) | [PDF](https://arxiv.org/pdf/2510.20256.pdf)

**ä½œè€…**: Guowei Zhong, Junjie Li, Huaiyu Zhu, Ruohong Huan, Yun Pan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ ¡å‡†å¤šæ¨¡æ€å…±è¯†æ¨¡åž‹ä»¥è§£å†³å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«ä¸­çš„è¯­ä¹‰ä¸ä¸€è‡´å’Œæ–‡æœ¬ä¸»å¯¼é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«` `è¯­ä¹‰ä¸ä¸€è‡´` `æ–‡æœ¬ä¸»å¯¼` `è‡ªç›‘ç£å­¦ä¹ ` `å¤šæ¨¡æ€èžåˆ` `ä¼ªæ ‡ç­¾ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«ä¸­å­˜åœ¨è·¨æ¨¡æ€è¯­ä¹‰ä¸ä¸€è‡´å’Œæ–‡æœ¬ä¸»å¯¼å¯¼è‡´çš„å‡†ç¡®çŽ‡ä¸‹é™
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥ä¼ªæ ‡ç­¾ç”Ÿæˆæ¨¡å—è¿›è¡Œè‡ªç›‘ç£é¢„è®­ç»ƒï¼Œå¹¶ä½¿ç”¨å‚æ•°æ— å…³èžåˆæ¨¡å—å’Œå¤šæ¨¡æ€å…±è¯†è·¯ç”±å™¨è¿›è¡Œå¾®è°ƒ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ€§èƒ½è¾¾åˆ°æˆ–è¶…è¶Šå…ˆè¿›æ–¹æ³•ï¼Œå¹¶åœ¨è¯­ä¹‰ä¸ä¸€è‡´åœºæ™¯ä¸­è¡¨çŽ°çªå‡º

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In recent years, Multimodal Emotion Recognition (MER) has made substantial
> progress. Nevertheless, most existing approaches neglect the semantic
> inconsistencies that may arise across modalities, such as conflicting emotional
> cues between text and visual inputs. Besides, current methods are often
> dominated by the text modality due to its strong representational capacity,
> which can compromise recognition accuracy. To address these challenges, we
> propose a model termed Calibrated Multimodal Consensus (CMC). CMC introduces a
> Pseudo Label Generation Module (PLGM) to produce pseudo unimodal labels,
> enabling unimodal pretraining in a self-supervised fashion. It then employs a
> Parameter-free Fusion Module (PFM) and a Multimodal Consensus Router (MCR) for
> multimodal finetuning, thereby mitigating text dominance and guiding the fusion
> process toward a more reliable consensus. Experimental results demonstrate that
> CMC achieves performance on par with or superior to state-of-the-art methods
> across four datasets, CH-SIMS, CH-SIMS v2, CMU-MOSI, and CMU-MOSEI, and
> exhibits notable advantages in scenarios with semantic inconsistencies on
> CH-SIMS and CH-SIMS v2. The implementation of this work is publicly accessible
> at https://github.com/gw-zhong/CMC.

