---
layout: default
title: Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis
---

# Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis

**arXiv**: [2510.20531v1](https://arxiv.org/abs/2510.20531) | [PDF](https://arxiv.org/pdf/2510.20531.pdf)

**ä½œè€…**: Lixiong Qin, Yang Zhang, Mei Wang, Jiani Hu, Weihong Deng, Weiran Xu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFake-in-Facextæ¡†æž¶ä»¥è§£å†³ç»†ç²’åº¦å¯è§£é‡ŠDeepFakeåˆ†æžé—®é¢˜**

**å…³é”®è¯**: `å¯è§£é‡ŠDeepFakeåˆ†æž` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `ç»†ç²’åº¦æ³¨é‡Š` `Artifact-Grounding Explanation` `é¢éƒ¨å›¾åƒæ¦‚å¿µæ ‘` `å¤šä»»åŠ¡å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰æ–¹æ³•ç¼ºä¹ç»†ç²’åº¦æ„ŸçŸ¥ï¼Œæ•°æ®æ³¨é‡Šä¸å¯é ä¸”ç²—ç²’åº¦ï¼Œæ¨¡åž‹æ— æ³•è¿žæŽ¥æ–‡æœ¬è§£é‡Šä¸Žè§†è§‰è¯æ®
2. å®šä¹‰é¢éƒ¨å›¾åƒæ¦‚å¿µæ ‘ï¼Œæž„å»ºFiFa-Annotatoræ•°æ®æ³¨é‡Šç®¡é“ï¼Œæ”¯æŒArtifact-Grounding Explanationä»»åŠ¡
3. FiFa-MLLMå¤šä»»åŠ¡å­¦ä¹ æž¶æž„åœ¨AGEä»»åŠ¡ä¸Šè¶…è¶ŠåŸºçº¿ï¼Œåœ¨çŽ°æœ‰XDFAæ•°æ®é›†ä¸Šè¾¾åˆ°SOTAæ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The advancement of Multimodal Large Language Models (MLLMs) has bridged the
> gap between vision and language tasks, enabling the implementation of
> Explainable DeepFake Analysis (XDFA). However, current methods suffer from a
> lack of fine-grained awareness: the description of artifacts in data annotation
> is unreliable and coarse-grained, and the models fail to support the output of
> connections between textual forgery explanations and the visual evidence of
> artifacts, as well as the input of queries for arbitrary facial regions. As a
> result, their responses are not sufficiently grounded in Face Visual Context
> (Facext). To address this limitation, we propose the Fake-in-Facext (FiFa)
> framework, with contributions focusing on data annotation and model
> construction. We first define a Facial Image Concept Tree (FICT) to divide
> facial images into fine-grained regional concepts, thereby obtaining a more
> reliable data annotation pipeline, FiFa-Annotator, for forgery explanation.
> Based on this dedicated data annotation, we introduce a novel
> Artifact-Grounding Explanation (AGE) task, which generates textual forgery
> explanations interleaved with segmentation masks of manipulated artifacts. We
> propose a unified multi-task learning architecture, FiFa-MLLM, to
> simultaneously support abundant multimodal inputs and outputs for fine-grained
> Explainable DeepFake Analysis. With multiple auxiliary supervision tasks,
> FiFa-MLLM can outperform strong baselines on the AGE task and achieve SOTA
> performance on existing XDFA datasets. The code and data will be made
> open-source at https://github.com/lxq1000/Fake-in-Facext.

