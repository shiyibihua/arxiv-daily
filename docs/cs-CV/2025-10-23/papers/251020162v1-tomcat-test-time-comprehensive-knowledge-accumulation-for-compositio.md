---
layout: default
title: TOMCAT: Test-time Comprehensive Knowledge Accumulation for Compositional Zero-Shot Learning
---

# TOMCAT: Test-time Comprehensive Knowledge Accumulation for Compositional Zero-Shot Learning

**arXiv**: [2510.20162v1](https://arxiv.org/abs/2510.20162) | [PDF](https://arxiv.org/pdf/2510.20162.pdf)

**ä½œè€…**: Xudong Yan, Songhe Feng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTOMCATæ–¹æ³•ï¼Œé€šè¿‡æµ‹è¯•æ—¶çŸ¥è¯†ç§¯ç´¯è§£å†³ç»„åˆé›¶æ ·æœ¬å­¦ä¹ ä¸­çš„åˆ†å¸ƒåç§»é—®é¢˜**

**å…³é”®è¯**: `ç»„åˆé›¶æ ·æœ¬å­¦ä¹ ` `æµ‹è¯•æ—¶é€‚åº”` `å¤šæ¨¡æ€åŽŸåž‹` `åˆ†å¸ƒåç§»` `åŠ¨æ€ä¼˜å…ˆçº§é˜Ÿåˆ—` `å¤šæ¨¡æ€å¯¹é½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæµ‹è¯•æ—¶æ ‡ç­¾ç©ºé—´åˆ†å¸ƒåç§»å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼ŒæºäºŽæœªè§å±žæ€§-å¯¹è±¡ç»„åˆ
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨æ— ç›‘ç£æ•°æ®ç§¯ç´¯å¤šæ¨¡æ€çŸ¥è¯†ï¼Œè‡ªé€‚åº”æ›´æ–°åŽŸåž‹å¹¶å¼•å…¥åŠ¨æ€ä¼˜å…ˆçº§é˜Ÿåˆ—
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®žçŽ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œæ”¯æŒé—­ä¸–ç•Œå’Œå¼€ä¸–ç•Œè®¾ç½®

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Compositional Zero-Shot Learning (CZSL) aims to recognize novel
> attribute-object compositions based on the knowledge learned from seen ones.
> Existing methods suffer from performance degradation caused by the distribution
> shift of label space at test time, which stems from the inclusion of unseen
> compositions recombined from attributes and objects. To overcome the challenge,
> we propose a novel approach that accumulates comprehensive knowledge in both
> textual and visual modalities from unsupervised data to update multimodal
> prototypes at test time. Building on this, we further design an adaptive update
> weight to control the degree of prototype adjustment, enabling the model to
> flexibly adapt to distribution shift during testing. Moreover, a dynamic
> priority queue is introduced that stores high-confidence images to acquire
> visual knowledge from historical images for inference. Considering the semantic
> consistency of multimodal knowledge, we align textual and visual prototypes by
> multimodal collaborative representation learning. Extensive experiments
> indicate that our approach achieves state-of-the-art performance on four
> benchmark datasets under both closed-world and open-world settings. Code will
> be available at https://github.com/xud-yan/TOMCAT .

