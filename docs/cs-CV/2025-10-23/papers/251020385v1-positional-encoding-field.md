---
layout: default
title: Positional Encoding Field
---

# Positional Encoding Field

**arXiv**: [2510.20385v1](https://arxiv.org/abs/2510.20385) | [PDF](https://arxiv.org/pdf/2510.20385.pdf)

**ä½œè€…**: Yunpeng Bai, Haoxiang Li, Qixing Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä½ç½®ç¼–ç åœºä»¥å¢žå¼ºæ‰©æ•£å˜æ¢å™¨åœ¨3Dç©ºé—´å»ºæ¨¡å’Œå›¾åƒç”Ÿæˆä¸­çš„æ€§èƒ½**

**å…³é”®è¯**: `æ‰©æ•£å˜æ¢å™¨` `ä½ç½®ç¼–ç ` `3Då»ºæ¨¡` `æ–°è§†è§’åˆæˆ` `å›¾åƒç¼–è¾‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‰©æ•£å˜æ¢å™¨ä¸­ä½ç½®ç¼–ç å¯¹ç©ºé—´ä¸€è‡´æ€§çš„ä¸»å¯¼ä½œç”¨æœªè¢«å……åˆ†æŽ¢ç´¢ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ‰©å±•ä½ç½®ç¼–ç è‡³3Dåœºï¼Œå¼•å…¥æ·±åº¦æ„ŸçŸ¥å’Œåˆ†å±‚ç¼–ç ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å•å›¾åƒæ–°è§†è§’åˆæˆä¸­å®žçŽ°æœ€ä¼˜æ€§èƒ½ï¼Œå¹¶æŽ¨å¹¿è‡³å¯æŽ§å›¾åƒç¼–è¾‘ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Diffusion Transformers (DiTs) have emerged as the dominant architecture for
> visual generation, powering state-of-the-art image and video models. By
> representing images as patch tokens with positional encodings (PEs), DiTs
> combine Transformer scalability with spatial and temporal inductive biases. In
> this work, we revisit how DiTs organize visual content and discover that patch
> tokens exhibit a surprising degree of independence: even when PEs are
> perturbed, DiTs still produce globally coherent outputs, indicating that
> spatial coherence is primarily governed by PEs. Motivated by this finding, we
> introduce the Positional Encoding Field (PE-Field), which extends positional
> encodings from the 2D plane to a structured 3D field. PE-Field incorporates
> depth-aware encodings for volumetric reasoning and hierarchical encodings for
> fine-grained sub-patch control, enabling DiTs to model geometry directly in 3D
> space. Our PE-Field-augmented DiT achieves state-of-the-art performance on
> single-image novel view synthesis and generalizes to controllable spatial image
> editing.

