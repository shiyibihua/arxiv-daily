---
layout: default
title: BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models
---

# BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models

**arXiv**: [2510.20095v1](https://arxiv.org/abs/2510.20095) | [PDF](https://arxiv.org/pdf/2510.20095.pdf)

**ä½œè€…**: Ziheng Zhang, Xinyue Ma, Arpita Chowdhury, Elizabeth G. Campolongo, Matthew J. Thompson, Net Zhang, Samuel Stevens, Hilmar Lapp, Tanya Berger-Wolf, Yu Su, Wei-Lun Chao, Jianyang Gu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBIOCAPæ¨¡åž‹ï¼Œåˆ©ç”¨åˆæˆæè¿°å¢žå¼ºç”Ÿç‰©å¤šæ¨¡æ€åŸºç¡€æ¨¡åž‹æ€§èƒ½**

**å…³é”®è¯**: `ç”Ÿç‰©å¤šæ¨¡æ€åŸºç¡€æ¨¡åž‹` `åˆæˆæè¿°ç”Ÿæˆ` `ç‰©ç§åˆ†ç±»` `æ–‡æœ¬-å›¾åƒæ£€ç´¢` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `ç”Ÿç‰©å›¾åƒåˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç”Ÿç‰©å›¾åƒç¼ºä¹å¤§è§„æ¨¡å®žä¾‹ç‰¹å¼‚æ€§æè¿°ï¼Œé™åˆ¶å¤šæ¨¡æ€ç›‘ç£åº”ç”¨
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ç”Ÿæˆåˆæˆæè¿°ï¼Œç»“åˆç»´åŸºç™¾ç§‘è§†è§‰ä¿¡æ¯
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¨¡åž‹åœ¨ç‰©ç§åˆ†ç±»å’Œæ–‡æœ¬-å›¾åƒæ£€ç´¢ä¸­è¡¨çŽ°ä¼˜å¼‚ï¼ŒéªŒè¯æè¿°ä»·å€¼

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This work investigates descriptive captions as an additional source of
> supervision for biological multimodal foundation models. Images and captions
> can be viewed as complementary samples from the latent morphospace of a
> species, each capturing certain biological traits. Incorporating captions
> during training encourages alignment with this shared latent structure,
> emphasizing potentially diagnostic characters while suppressing spurious
> correlations. The main challenge, however, lies in obtaining faithful,
> instance-specific captions at scale. This requirement has limited the
> utilization of natural language supervision in organismal biology compared with
> many other scientific domains. We complement this gap by generating synthetic
> captions with multimodal large language models (MLLMs), guided by
> Wikipedia-derived visual information and taxon-tailored format examples. These
> domain-specific contexts help reduce hallucination and yield accurate,
> instance-based descriptive captions. Using these captions, we train BIOCAP
> (i.e., BIOCLIP with Captions), a biological foundation model that captures rich
> semantics and achieves strong performance in species classification and
> text-image retrieval. These results demonstrate the value of descriptive
> captions beyond labels in bridging biological images with multimodal foundation
> models.

