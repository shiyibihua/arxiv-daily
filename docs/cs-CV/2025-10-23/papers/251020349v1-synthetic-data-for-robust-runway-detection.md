---
layout: default
title: Synthetic Data for Robust Runway Detection
---

# Synthetic Data for Robust Runway Detection

**arXiv**: [2510.20349v1](https://arxiv.org/abs/2510.20349) | [PDF](https://arxiv.org/pdf/2510.20349.pdf)

**ä½œè€…**: Estelle Chigot, Dennis G. Wilson, Meriem Ghrib, Fabrice Jimenez, Thomas Oberlin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽé£žè¡Œæ¨¡æ‹Ÿå™¨çš„åˆæˆæ•°æ®æ–¹æ³•ä»¥å¢žå¼ºè·‘é“æ£€æµ‹åœ¨è‡ªä¸»ç€é™†ä¸­çš„é²æ£’æ€§**

**å…³é”®è¯**: `åˆæˆæ•°æ®ç”Ÿæˆ` `è·‘é“æ£€æµ‹` `è‡ªä¸»ç€é™†ç³»ç»Ÿ` `åŸŸé€‚åº”` `é²æ£’æ€§è¯„ä¼°` `é£žè¡Œæ¨¡æ‹Ÿå™¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå…³é”®åº”ç”¨ä¸­çœŸå®žæ•°æ®æ”¶é›†æˆæœ¬é«˜ä¸”éš¾ä»¥è¦†ç›–æ‰€æœ‰æ¡ä»¶ï¼Œå¦‚å¤œé—´åœºæ™¯ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å•†ä¸šé£žè¡Œæ¨¡æ‹Ÿå™¨ç”Ÿæˆåˆæˆå›¾åƒï¼Œç»“åˆå°‘é‡çœŸå®žå›¾åƒè¿›è¡Œè®­ç»ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ ‡å‡†æ£€æµ‹æ¨¡åž‹å®žçŽ°å‡†ç¡®é¢„æµ‹ï¼Œå¹¶é€šè¿‡å®šåˆ¶åŸŸé€‚åº”ç­–ç•¥æå‡å¯¹æœªçŸ¥æ¡ä»¶çš„é²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deep vision models are now mature enough to be integrated in industrial and
> possibly critical applications such as autonomous navigation. Yet, data
> collection and labeling to train such models requires too much efforts and
> costs for a single company or product. This drawback is more significant in
> critical applications, where training data must include all possible conditions
> including rare scenarios. In this perspective, generating synthetic images is
> an appealing solution, since it allows a cheap yet reliable covering of all the
> conditions and environments, if the impact of the synthetic-to-real
> distribution shift is mitigated. In this article, we consider the case of
> runway detection that is a critical part in autonomous landing systems
> developed by aircraft manufacturers. We propose an image generation approach
> based on a commercial flight simulator that complements a few annotated real
> images. By controlling the image generation and the integration of real and
> synthetic data, we show that standard object detection models can achieve
> accurate prediction. We also evaluate their robustness with respect to adverse
> conditions, in our case nighttime images, that were not represented in the real
> data, and show the interest of using a customized domain adaptation strategy.

