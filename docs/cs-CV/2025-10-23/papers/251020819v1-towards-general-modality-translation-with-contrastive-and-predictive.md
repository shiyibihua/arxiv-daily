---
layout: default
title: Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge
---

# Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge

**arXiv**: [2510.20819v1](https://arxiv.org/abs/2510.20819) | [PDF](https://arxiv.org/pdf/2510.20819.pdf)

**ä½œè€…**: Nimrod Berman, Omkar Joglekar, Eitan Kosman, Dotan Di Castro, Omri Azencot

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ½œåœ¨åŽ»å™ªæ‰©æ•£æ¡¥æ¨¡åž‹ä»¥è§£å†³è·¨æ¨¡æ€ç¿»è¯‘çš„é€šç”¨æ€§é—®é¢˜**

**å…³é”®è¯**: `è·¨æ¨¡æ€ç¿»è¯‘` `æ‰©æ•£æ¨¡åž‹` `æ½œåœ¨ç©ºé—´å­¦ä¹ ` `å¯¹æ¯”å¯¹é½` `å™ªå£°é¢„æµ‹` `å¤šæ¨¡æ€ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–å…±äº«ç»´åº¦ç­‰å‡è®¾ï¼Œé™åˆ¶è·¨æ¨¡æ€ç¿»è¯‘çš„é€šç”¨æ€§ã€‚
2. åœ¨å…±äº«æ½œåœ¨ç©ºé—´å­¦ä¹ æ¡¥æŽ¥ï¼Œå¼•å…¥å¯¹æ¯”å¯¹é½å’Œé¢„æµ‹æŸå¤±æå‡è¯­ä¹‰ä¸€è‡´æ€§ã€‚
3. åœ¨å¤šç§ä»»åŠ¡å¦‚å¤šè§†å›¾åˆ°3Dç”Ÿæˆä¸­è¡¨çŽ°ä¼˜å¼‚ï¼ŒéªŒè¯æ¡†æž¶æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in generative modeling have positioned diffusion models as
> state-of-the-art tools for sampling from complex data distributions. While
> these models have shown remarkable success across single-modality domains such
> as images and audio, extending their capabilities to Modality Translation (MT),
> translating information across different sensory modalities, remains an open
> challenge. Existing approaches often rely on restrictive assumptions, including
> shared dimensionality, Gaussian source priors, and modality-specific
> architectures, which limit their generality and theoretical grounding. In this
> work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a
> general-purpose framework for modality translation based on a latent-variable
> extension of Denoising Diffusion Bridge Models. By operating in a shared latent
> space, our method learns a bridge between arbitrary modalities without
> requiring aligned dimensions. We introduce a contrastive alignment loss to
> enforce semantic consistency between paired samples and design a
> domain-agnostic encoder-decoder architecture tailored for noise prediction in
> latent space. Additionally, we propose a predictive loss to guide training
> toward accurate cross-domain translation and explore several training
> strategies to improve stability. Our approach supports arbitrary modality pairs
> and performs strongly on diverse MT tasks, including multi-view to 3D shape
> generation, image super-resolution, and multi-view scene synthesis.
> Comprehensive experiments and ablations validate the effectiveness of our
> framework, establishing a new strong baseline in general modality translation.
> For more information, see our project page:
> https://sites.google.com/view/lddbm/home.

