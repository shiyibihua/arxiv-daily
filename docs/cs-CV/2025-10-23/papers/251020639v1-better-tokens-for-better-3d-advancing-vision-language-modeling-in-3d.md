---
layout: default
title: Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging
---

# Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging

**arXiv**: [2510.20639v1](https://arxiv.org/abs/2510.20639) | [PDF](https://arxiv.org/pdf/2510.20639.pdf)

**ä½œè€…**: Ibrahim Ethem Hamamci, Sezgin Er, Suprosanna Shit, Hadrien Reynaud, Dong Yang, Pengfei Guo, Marc Edgar, Daguang Xu, Bernhard Kainz, Bjoern Menze

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBTB3Dæ–¹æ³•ä»¥è§£å†³3DåŒ»å­¦å½±åƒä¸­é«˜åˆ†è¾¨çŽ‡é•¿åºåˆ—çš„è§†è§‰-è¯­è¨€å»ºæ¨¡é—®é¢˜**

**å…³é”®è¯**: `3DåŒ»å­¦å½±åƒ` `è§†è§‰-è¯­è¨€å»ºæ¨¡` `ä½“ç§¯æ ‡è®°åŒ–` `å› æžœå·ç§¯` `æŠ¥å‘Šç”Ÿæˆ` `æ–‡æœ¬åˆ°å›¾åƒåˆæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå½“å‰æ–¹æ³•åœ¨é«˜åˆ†è¾¨çŽ‡é•¿åºåˆ—3DåŒ»å­¦å½±åƒä¸­ï¼Œè§†è§‰ç¼–ç å™¨ä¸Žä¸´åºŠè¯­è¨€ä¸åŒ¹é…ï¼Œä¸”åˆ‡ç‰‡çº§æ ‡è®°åŒ–æ¨¡ç³Šç²¾ç»†è§£å‰–ç»“æž„
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å› æžœå·ç§¯ç¼–ç å™¨-è§£ç å™¨ï¼Œç»Ÿä¸€2Då’Œ3Dè®­ç»ƒæŽ¨ç†ï¼Œç”Ÿæˆç´§å‡‘çš„é¢‘çŽ‡æ„ŸçŸ¥ä½“ç§¯æ ‡è®°
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æŠ¥å‘Šç”Ÿæˆå’Œæ–‡æœ¬åˆ°CTåˆæˆä»»åŠ¡ä¸­ï¼Œæ˜¾è‘—æå‡BLEUåˆ†æ•°ã€ä¸´åºŠF1ï¼Œå¹¶å¤§å¹…é™ä½ŽFIDå’ŒFVD

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent progress in vision-language modeling for 3D medical imaging has been
> fueled by large-scale computed tomography (CT) corpora with paired free-text
> reports, stronger architectures, and powerful pretrained models. This has
> enabled applications such as automated report generation and text-conditioned
> 3D image synthesis. Yet, current approaches struggle with high-resolution,
> long-sequence volumes: contrastive pretraining often yields vision encoders
> that are misaligned with clinical language, and slice-wise tokenization blurs
> fine anatomy, reducing diagnostic performance on downstream tasks. We introduce
> BTB3D (Better Tokens for Better 3D), a causal convolutional encoder-decoder
> that unifies 2D and 3D training and inference while producing compact,
> frequency-aware volumetric tokens. A three-stage training curriculum enables
> (i) local reconstruction, (ii) overlapping-window tiling, and (iii)
> long-context decoder refinement, during which the model learns from short slice
> excerpts yet generalizes to scans exceeding 300 slices without additional
> memory overhead. BTB3D sets a new state-of-the-art on two key tasks: it
> improves BLEU scores and increases clinical F1 by 40% over CT2Rep, CT-CHAT, and
> Merlin for report generation; and it reduces FID by 75% and halves FVD compared
> to GenerateCT and MedSyn for text-to-CT synthesis, producing anatomically
> consistent 512*512*241 volumes. These results confirm that precise
> three-dimensional tokenization, rather than larger language backbones alone, is
> essential for scalable vision-language modeling in 3D medical imaging. The
> codebase is available at: https://github.com/ibrahimethemhamamci/BTB3D

