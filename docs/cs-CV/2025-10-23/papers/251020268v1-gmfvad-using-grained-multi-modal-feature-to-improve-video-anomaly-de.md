---
layout: default
title: GMFVAD: Using Grained Multi-modal Feature to Improve Video Anomaly Detection
---

# GMFVAD: Using Grained Multi-modal Feature to Improve Video Anomaly Detection

**arXiv**: [2510.20268v1](https://arxiv.org/abs/2510.20268) | [PDF](https://arxiv.org/pdf/2510.20268.pdf)

**ä½œè€…**: Guangyu Dai, Dong Chen, Siliang Tang, Yueting Zhuang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGMFVADæ–¹æ³•ï¼Œé€šè¿‡ç»†ç²’åº¦å¤šæ¨¡æ€ç‰¹å¾å‡å°‘å†—ä½™ä¿¡æ¯ä»¥æ”¹è¿›è§†é¢‘å¼‚å¸¸æ£€æµ‹**

**å…³é”®è¯**: `è§†é¢‘å¼‚å¸¸æ£€æµ‹` `å¤šæ¨¡æ€ç‰¹å¾` `ç‰¹å¾å†—ä½™å‡å°‘` `ç»†ç²’åº¦ç‰¹å¾` `æ–‡æœ¬ç‰¹å¾å¢žå¼º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§†é¢‘å¼‚å¸¸æ£€æµ‹æ–¹æ³•åœ¨å¼•å…¥å¤šæ¨¡æ€ä¿¡æ¯æ—¶å­˜åœ¨ç‰¹å¾å†—ä½™ï¼Œå½±å“æ£€æµ‹å‡†ç¡®æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽè§†é¢‘ç‰‡æ®µç”Ÿæˆç»†ç²’åº¦å¤šæ¨¡æ€ç‰¹å¾ï¼Œç»“åˆæ–‡æœ¬ç‰¹å¾å¢žå¼ºè§†è§‰ç‰¹å¾ï¼Œå‡å°‘å†—ä½™ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å››ä¸ªä¸»è¦æ•°æ®é›†ä¸Šè¾¾åˆ°å…ˆè¿›æ€§èƒ½ï¼Œæ¶ˆèžå®žéªŒéªŒè¯å†—ä½™å‡å°‘å¸¦æ¥æ”¹è¿›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video anomaly detection (VAD) is a challenging task that detects anomalous
> frames in continuous surveillance videos. Most previous work utilizes the
> spatio-temporal correlation of visual features to distinguish whether there are
> abnormalities in video snippets. Recently, some works attempt to introduce
> multi-modal information, like text feature, to enhance the results of video
> anomaly detection. However, these works merely incorporate text features into
> video snippets in a coarse manner, overlooking the significant amount of
> redundant information that may exist within the video snippets. Therefore, we
> propose to leverage the diversity among multi-modal information to further
> refine the extracted features, reducing the redundancy in visual features, and
> we propose Grained Multi-modal Feature for Video Anomaly Detection (GMFVAD).
> Specifically, we generate more grained multi-modal feature based on the video
> snippet, which summarizes the main content, and text features based on the
> captions of original video will be introduced to further enhance the visual
> features of highlighted portions. Experiments show that the proposed GMFVAD
> achieves state-of-the-art performance on four mainly datasets. Ablation
> experiments also validate that the improvement of GMFVAD is due to the
> reduction of redundant information.

