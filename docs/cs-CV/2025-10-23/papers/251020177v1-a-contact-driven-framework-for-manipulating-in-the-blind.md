---
layout: default
title: A Contact-Driven Framework for Manipulating in the Blind
---

# A Contact-Driven Framework for Manipulating in the Blind

**arXiv**: [2510.20177v1](https://arxiv.org/abs/2510.20177) | [PDF](https://arxiv.org/pdf/2510.20177.pdf)

**ä½œè€…**: Muhammad Suhail Saleem, Lai Yuan, Maxim Likhachev

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæŽ¥è§¦åé¦ˆä¸Žç»“æž„å…ˆéªŒçš„ç›²æ“ä½œæ¡†æž¶ï¼Œä»¥åœ¨è§†è§‰å—é™çŽ¯å¢ƒä¸­å®žçŽ°é²æ£’æœºå™¨äººæ“ä½œã€‚**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `æŽ¥è§¦åé¦ˆ` `å ç”¨ä¼°è®¡` `è¿åŠ¨è§„åˆ’` `ç»“æž„å…ˆéªŒ` `ç›²æ“ä½œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨äººåœ¨è§†è§‰ä¸è¶³çŽ¯å¢ƒä¸­æ“ä½œï¼Œéœ€ä¾èµ–æŽ¥è§¦åé¦ˆé¿å…ç¢°æ’žå¹¶å®Œæˆä»»åŠ¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ•´åˆæŽ¥è§¦æ£€æµ‹ã€å ç”¨ä¼°è®¡å’Œè§„åˆ’æ¨¡å—ï¼Œåˆ©ç”¨ç»“æž„å…ˆéªŒé¢„æµ‹æœªçŸ¥åŒºåŸŸã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žä»»åŠ¡ä¸­éªŒè¯ï¼Œä»»åŠ¡å®Œæˆæ—¶é—´å‡å°‘è¾¾2å€ï¼Œæ¨¡å—è´¡çŒ®å¾—åˆ°ç¡®è®¤ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Robots often face manipulation tasks in environments where vision is
> inadequate due to clutter, occlusions, or poor lighting--for example, reaching
> a shutoff valve at the back of a sink cabinet or locating a light switch above
> a crowded shelf. In such settings, robots, much like humans, must rely on
> contact feedback to distinguish free from occupied space and navigate around
> obstacles. Many of these environments often exhibit strong structural
> priors--for instance, pipes often span across sink cabinets--that can be
> exploited to anticipate unseen structure and avoid unnecessary collisions. We
> present a theoretically complete and empirically efficient framework for
> manipulation in the blind that integrates contact feedback with structural
> priors to enable robust operation in unknown environments. The framework
> comprises three tightly coupled components: (i) a contact detection and
> localization module that utilizes joint torque sensing with a contact particle
> filter to detect and localize contacts, (ii) an occupancy estimation module
> that uses the history of contact observations to build a partial occupancy map
> of the workspace and extrapolate it into unexplored regions with learned
> predictors, and (iii) a planning module that accounts for the fact that contact
> localization estimates and occupancy predictions can be noisy, computing paths
> that avoid collisions and complete tasks efficiently without eliminating
> feasible solutions. We evaluate the system in simulation and in the real world
> on a UR10e manipulator across two domestic tasks--(i) manipulating a valve
> under a kitchen sink surrounded by pipes and (ii) retrieving a target object
> from a cluttered shelf. Results show that the framework reliably solves these
> tasks, achieving up to a 2x reduction in task completion time compared to
> baselines, with ablations confirming the contribution of each module.

