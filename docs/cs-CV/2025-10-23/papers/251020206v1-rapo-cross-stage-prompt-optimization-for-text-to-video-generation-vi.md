---
layout: default
title: RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling
---

# RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling

**arXiv**: [2510.20206v1](https://arxiv.org/abs/2510.20206) | [PDF](https://arxiv.org/pdf/2510.20206.pdf)

**ä½œè€…**: Bingjie Gao, Qianli Ma, Xiaoxue Wu, Shuai Yang, Guanzhou Lan, Haonan Zhao, Jiaxuan Chen, Qingyang Liu, Yu Qiao, Xinyuan Chen, Yaohui Wang, Li Niu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRAPO++æ¡†æž¶ä»¥ä¼˜åŒ–æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆçš„æç¤ºè®¾è®¡**

**å…³é”®è¯**: `æç¤ºä¼˜åŒ–` `æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆ` `æ•°æ®å¯¹é½` `æµ‹è¯•æ—¶ç¼©æ”¾` `LLMå¾®è°ƒ` `è·¨é˜¶æ®µæ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç”¨æˆ·æç¤ºçŸ­å°ä¸”ä¸Žè®­ç»ƒæ•°æ®ä¸åŒ¹é…ï¼Œé™åˆ¶æ‰©æ•£æ¨¡åž‹ç”Ÿæˆæ½œåŠ›ã€‚
2. æ–¹æ³•åŒ…æ‹¬æ•°æ®å¯¹é½ä¼˜åŒ–ã€æµ‹è¯•æ—¶è¿­ä»£ç¼©æ”¾å’ŒLLMå¾®è°ƒï¼Œæ— éœ€ä¿®æ”¹ç”Ÿæˆä¸»å¹²ã€‚
3. å®žéªŒåœ¨å¤šä¸ªæ¨¡åž‹å’ŒåŸºå‡†ä¸Šæ˜¾ç¤ºè¯­ä¹‰å¯¹é½ã€ç»„åˆæŽ¨ç†ç­‰æŒ‡æ ‡æ˜¾è‘—æå‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Prompt design plays a crucial role in text-to-video (T2V) generation, yet
> user-provided prompts are often short, unstructured, and misaligned with
> training data, limiting the generative potential of diffusion-based T2V models.
> We present \textbf{RAPO++}, a cross-stage prompt optimization framework that
> unifies training-data--aligned refinement, test-time iterative scaling, and
> large language model (LLM) fine-tuning to substantially improve T2V generation
> without modifying the underlying generative backbone. In \textbf{Stage 1},
> Retrieval-Augmented Prompt Optimization (RAPO) enriches user prompts with
> semantically relevant modifiers retrieved from a relation graph and refactors
> them to match training distributions, enhancing compositionality and
> multi-object fidelity. \textbf{Stage 2} introduces Sample-Specific Prompt
> Optimization (SSPO), a closed-loop mechanism that iteratively refines prompts
> using multi-source feedback -- including semantic alignment, spatial fidelity,
> temporal coherence, and task-specific signals such as optical flow -- yielding
> progressively improved video generation quality. \textbf{Stage 3} leverages
> optimized prompt pairs from SSPO to fine-tune the rewriter LLM, internalizing
> task-specific optimization patterns and enabling efficient, high-quality prompt
> generation even before inference. Extensive experiments across five
> state-of-the-art T2V models and five benchmarks demonstrate that RAPO++
> achieves significant gains in semantic alignment, compositional reasoning,
> temporal stability, and physical plausibility, outperforming existing methods
> by large margins. Our results highlight RAPO++ as a model-agnostic,
> cost-efficient, and scalable solution that sets a new standard for prompt
> optimization in T2V generation. The code is available at
> https://github.com/Vchitect/RAPO.

