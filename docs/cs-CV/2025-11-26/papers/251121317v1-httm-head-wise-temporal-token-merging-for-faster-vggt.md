---
layout: default
title: HTTM: Head-wise Temporal Token Merging for Faster VGGT
---

# HTTM: Head-wise Temporal Token Merging for Faster VGGT

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.21317" target="_blank" class="toolbar-btn">arXiv: 2511.21317v1</a>
    <a href="https://arxiv.org/pdf/2511.21317.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.21317v1" 
            onclick="toggleFavorite(this, '2511.21317v1', 'HTTM: Head-wise Temporal Token Merging for Faster VGGT')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Weitian Wang, Lukas Meiner, Rai Shubham, Cecilia De La Parra, Akash Kumar

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-26

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Â§¥ÈÉ®ÂàÜÊó∂Â∫èTokenÂêàÂπ∂(HTTM)Âä†ÈÄüVGGTÔºåÁî®‰∫éÂø´ÈÄü3DÂú∫ÊôØÈáçÂª∫**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `3DÂú∫ÊôØÈáçÂª∫` `Transformer` `Ê®°ÂûãÂä†ÈÄü` `TokenÂêàÂπ∂` `Â§öÂ§¥Ê≥®ÊÑèÂäõ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. VGGTÂú®3DÂú∫ÊôØÈáçÂª∫‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂÖ®Â±ÄÊ≥®ÊÑèÂäõÊú∫Âà∂ÂØºËá¥ÈïøÂ∫èÂàóËæìÂÖ•Êó∂ËÆ°ÁÆóÈáèÂ∑®Â§ßÔºåÊàê‰∏∫ÊÄßËÉΩÁì∂È¢à„ÄÇ
2. HTTMÈÄöËøáÂú®Â§öÂ§¥Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÂ§¥ÈÉ®Á≤íÂ∫¶‰∏äËøõË°åtokenÂêàÂπ∂Ôºå‰øùÁïô‰∫ÜÁâπÂæÅtokenÁöÑÁã¨ÁâπÊÄßÔºåÊèêÂçá‰∫ÜÊ®°ÂûãË°®ÂæÅËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåHTTMÂú®GPU‰∏äÂÆûÁé∞‰∫ÜÈ´òËææ7ÂÄçÁöÑÂä†ÈÄüÔºåÂêåÊó∂ÊÄßËÉΩ‰∏ãÈôçÂèØÂøΩÁï•‰∏çËÆ°ÔºåÊòæËëóÊèêÂçá‰∫ÜVGGTÁöÑÊïàÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâÂá†‰ΩïÂü∫Á°ÄTransformer (VGGT) Âú®3DÂú∫ÊôØÈáçÂª∫ÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºåÂÆÉÊòØÁ¨¨‰∏Ä‰∏™Áõ¥Êé•‰∏ÄÊ¨°ÊÄßËÅîÂêàÊé®Êñ≠ÊâÄÊúâÂÖ≥ÈîÆ3DÂ±ûÊÄßÔºàÁõ∏Êú∫ÂßøÊÄÅ„ÄÅÊ∑±Â∫¶ÂíåÂØÜÈõÜÂá†‰ΩïÔºâÁöÑÊ®°Âûã„ÄÇÁÑ∂ËÄåÔºåËøôÁßçËÅîÂêàÊé®Êñ≠Êú∫Âà∂ÈúÄË¶ÅÂÖ®Â±ÄÊ≥®ÊÑèÂäõÂ±ÇÔºåÂØπÊù•Ëá™ÊâÄÊúâËßÜËßíÁöÑtokenÊâßË°åÂÖ®ËøûÊé•Ê≥®ÊÑèÂäõËÆ°ÁÆó„ÄÇÂØπ‰∫éÂÖ∑ÊúâÈïøÂ∫èÂàóËæìÂÖ•ÁöÑÂ§ßÂûãÂú∫ÊôØÈáçÂª∫ÔºåËøô‰ºöÂØºËá¥ÊòæËëóÁöÑÂª∂ËøüÁì∂È¢à„ÄÇÊú¨ÊñáÊèêÂá∫Â§¥ÈÉ®ÂàÜÊó∂Â∫èÂêàÂπ∂ÔºàHTTMÔºâÔºå‰∏ÄÁßçÂÖçËÆ≠ÁªÉÁöÑ3D tokenÂêàÂπ∂ÊñπÊ≥ïÔºåÁî®‰∫éÂä†ÈÄüVGGT„ÄÇÁé∞ÊúâÁöÑÂêàÂπ∂ÊäÄÊúØÂú®‰∏çÂêåÁöÑÊ≥®ÊÑèÂäõÂ§¥‰∏≠Áªü‰∏ÄÂêàÂπ∂tokenÔºåÂØºËá¥Â±ÇËæìÂá∫‰∏≠Âá∫Áé∞Áõ∏ÂêåÁöÑtokenÔºåËøôÈòªÁ¢ç‰∫ÜÊ®°ÂûãÁöÑË°®ÂæÅËÉΩÂäõ„ÄÇHTTMÈÄöËøáÂ§öÂ§¥Á≤íÂ∫¶ÂêàÂπ∂tokenÊù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºå‰ªéËÄåÂú®Â§¥ÈÉ®ËøûÊé•Âêé‰øùÊåÅÁâπÂæÅtokenÁöÑÂîØ‰∏ÄÊÄß„ÄÇÊ≠§Â§ñÔºå‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËøô‰ΩøÂæóHTTMËÉΩÂ§üÂà©Áî®Âú®Â§¥ÈÉ®Â±ÇÈù¢ËßÇÂØüÂà∞ÁöÑÁ©∫Èó¥Â±ÄÈÉ®ÊÄßÂíåÊó∂Èó¥ÂØπÂ∫îÊÄßÔºå‰ª•Êõ¥‰ΩéÁöÑÂêàÂπ∂ÊàêÊú¨ÂÆûÁé∞Êõ¥È´òÁöÑÂêàÂπ∂Áéá„ÄÇÂõ†Ê≠§ÔºåHTTMÂú®Âü∫‰∫éGPUÁöÑÊé®ÁêÜ‰∏≠ÂÆûÁé∞‰∫ÜÈ´òËææ7ÂÄçÁöÑÂä†ÈÄüÔºåËÄåÊÄßËÉΩ‰∏ãÈôçÂèØÂøΩÁï•‰∏çËÆ°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöVGGTÂú®3DÂú∫ÊôØÈáçÂª∫‰∏≠ÈúÄË¶ÅÂØπÊâÄÊúâËßÜËßíÁöÑtokenËøõË°åÂÖ®Â±ÄÊ≥®ÊÑèÂäõËÆ°ÁÆóÔºåËøôÂú®Â§ÑÁêÜÈïøÂ∫èÂàóËæìÂÖ•ÁöÑÂ§ßÂûãÂú∫ÊôØÊó∂‰ºö‰∫ßÁîüÂ∑®Â§ßÁöÑËÆ°ÁÆóÈáèÔºåÂØºËá¥Êé®ÁêÜÈÄüÂ∫¶ÊÖ¢ÔºåÊàê‰∏∫ÊÄßËÉΩÁì∂È¢à„ÄÇÁé∞ÊúâÁöÑtokenÂêàÂπ∂ÊñπÊ≥ïÈÄöÂ∏∏Âú®‰∏çÂêåÊ≥®ÊÑèÂäõÂ§¥‰∏≠Áªü‰∏ÄÂêàÂπ∂tokenÔºåÂØºËá¥‰ø°ÊÅØÂÜó‰ΩôÔºåÈôç‰Ωé‰∫ÜÊ®°ÂûãÁöÑË°®ÂæÅËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöHTTMÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂú®Â§öÂ§¥Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÂ§¥ÈÉ®Á≤íÂ∫¶‰∏äËøõË°åtokenÂêàÂπ∂ÔºåËÄå‰∏çÊòØÂÉèÁé∞ÊúâÊñπÊ≥ïÈÇ£Ê†∑Âú®ÊâÄÊúâÂ§¥ÈÉ®Áªü‰∏ÄÂêàÂπ∂„ÄÇËøôÊ†∑ÂèØ‰ª•‰øùÁïôÊØè‰∏™Â§¥ÈÉ®Â≠¶‰π†Âà∞ÁöÑÁã¨ÁâπÁâπÂæÅÔºåÈÅøÂÖç‰ø°ÊÅØÂÜó‰ΩôÔºå‰ªéËÄåÂú®ÂáèÂ∞ëËÆ°ÁÆóÈáèÁöÑÂêåÊó∂‰øùÊåÅÊ®°ÂûãÁöÑË°®ÂæÅËÉΩÂäõ„ÄÇÂêåÊó∂ÔºåHTTMÂà©Áî®Â§¥ÈÉ®Â±ÇÈù¢ÁöÑÁ©∫Èó¥Â±ÄÈÉ®ÊÄßÂíåÊó∂Èó¥ÂØπÂ∫îÊÄßÔºåÂÆûÁé∞Êõ¥È´òÁöÑÂêàÂπ∂ÁéáÂíåÊõ¥‰ΩéÁöÑÂêàÂπ∂ÊàêÊú¨„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöHTTM‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÊ≠•È™§ÔºöÈ¶ñÂÖàÔºåÂ∞ÜËæìÂÖ•tokenÊåâÁÖßÊó∂Èó¥È°∫Â∫èÂàÜÁªÑ„ÄÇÁÑ∂ÂêéÔºåÂØπ‰∫éÊØè‰∏™Êó∂Èó¥Ê≠•ÁöÑtokenÔºåÂ∞ÜÂÖ∂ËæìÂÖ•Âà∞Â§öÂ§¥Ê≥®ÊÑèÂäõÂ±Ç„ÄÇÂú®ÊØè‰∏™Ê≥®ÊÑèÂäõÂ§¥‰∏≠ÔºåHTTMÊ†πÊçÆ‰∏ÄÂÆöÁöÑÁ≠ñÁï•Ôºà‰æãÂ¶ÇÔºåÂü∫‰∫éÁõ∏‰ººÂ∫¶ÊàñÈáçË¶ÅÊÄßÔºâÈÄâÊã©ÈúÄË¶Å‰øùÁïôÁöÑtokenÔºåÂπ∂ÂêàÂπ∂ÂÖ∂‰ΩôÁöÑtoken„ÄÇÊúÄÂêéÔºåÂ∞ÜÊâÄÊúâÂ§¥ÈÉ®ÁöÑËæìÂá∫ËøûÊé•Ëµ∑Êù•Ôºå‰Ωú‰∏∫‰∏ã‰∏ÄÂ±ÇÁöÑËæìÂÖ•„ÄÇÊï¥‰∏™ËøáÁ®ãÊó†ÈúÄËÆ≠ÁªÉÔºåÂèØ‰ª•Áõ¥Êé•Â∫îÁî®‰∫éÈ¢ÑËÆ≠ÁªÉÁöÑVGGTÊ®°Âûã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöHTTMÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂÖ∂Â§¥ÈÉ®ÂàÜÊó∂Â∫èÂêàÂπ∂Á≠ñÁï•„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÂú®ÊâÄÊúâÂ§¥ÈÉ®Áªü‰∏ÄÂêàÂπ∂token‰∏çÂêåÔºåHTTMÂú®ÊØè‰∏™Â§¥ÈÉ®Áã¨Á´ãÂú∞ËøõË°åtokenÂêàÂπ∂Ôºå‰øùÁïô‰∫ÜÊØè‰∏™Â§¥ÈÉ®Â≠¶‰π†Âà∞ÁöÑÁã¨ÁâπÁâπÂæÅÔºåÈÅøÂÖç‰∫Ü‰ø°ÊÅØÂÜó‰Ωô„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÂáèÂ∞ëËÆ°ÁÆóÈáèÔºåÂêåÊó∂‰øùÊåÅÊ®°ÂûãÁöÑË°®ÂæÅËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöHTTMÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Âü∫‰∫éÁõ∏‰ººÂ∫¶ÊàñÈáçË¶ÅÊÄßÁöÑtokenÈÄâÊã©Á≠ñÁï•ÔºåÁî®‰∫éÁ°ÆÂÆöÂì™‰∫õtokenÈúÄË¶Å‰øùÁïôÔºåÂì™‰∫õtokenÂèØ‰ª•ÂêàÂπ∂Ôºõ2) Â§öÂ§¥Á≤íÂ∫¶ÁöÑÂêàÂπ∂Êìç‰ΩúÔºåÁ°Æ‰øùÊØè‰∏™Â§¥ÈÉ®ÁöÑ‰ø°ÊÅØËÉΩÂ§üË¢´ÂÖÖÂàÜÂà©Áî®Ôºõ3) ÂÖçËÆ≠ÁªÉÁöÑËÆæËÆ°Ôºå‰ΩøÂæóHTTMÂèØ‰ª•Áõ¥Êé•Â∫îÁî®‰∫éÈ¢ÑËÆ≠ÁªÉÁöÑVGGTÊ®°ÂûãÔºåÊó†ÈúÄÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉÊàêÊú¨„ÄÇÂÖ∑‰ΩìÁöÑÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ïÂíåÈáçË¶ÅÊÄßËØÑ‰º∞ÊåáÊ†áÂèØ‰ª•Ê†πÊçÆÂÆûÈôÖÂ∫îÁî®Âú∫ÊôØËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåHTTMÂú®GPU‰∏äÂÆûÁé∞‰∫ÜÈ´òËææ7ÂÄçÁöÑÂä†ÈÄüÔºåÂêåÊó∂ÊÄßËÉΩ‰∏ãÈôçÂèØÂøΩÁï•‰∏çËÆ°„ÄÇËøôÊÑèÂë≥ÁùÄÂú®‰øùÊåÅÈáçÂª∫Ë¥®ÈáèÁöÑÂâçÊèê‰∏ãÔºåVGGTÁöÑÊé®ÁêÜÈÄüÂ∫¶ÂæóÂà∞‰∫ÜÊòæËëóÊèêÂçá„ÄÇÊ≠§Â§ñÔºåHTTMÁöÑÂÖçËÆ≠ÁªÉÁâπÊÄß‰ΩøÂÖ∂ËÉΩÂ§üÁõ¥Êé•Â∫îÁî®‰∫éÈ¢ÑËÆ≠ÁªÉÁöÑVGGTÊ®°ÂûãÔºåÊó†ÈúÄÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉÊàêÊú¨ÔºåÂÖ∑ÊúâÂæàÂº∫ÁöÑÂÆûÁî®ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

HTTMÂä†ÈÄüVGGTÁöÑÊñπÊ≥ïÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÈúÄË¶ÅÂø´ÈÄü3DÂú∫ÊôØÈáçÂª∫ÁöÑÈ¢ÜÂüüÔºå‰æãÂ¶ÇËá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠â„ÄÇÈÄöËøáÈôç‰ΩéËÆ°ÁÆóÊàêÊú¨ÂíåÂª∂ËøüÔºåHTTM‰ΩøÂæóVGGTËÉΩÂ§üÂ§ÑÁêÜÊõ¥Â§ßËßÑÊ®°ÁöÑÂú∫ÊôØÂíåÊõ¥ÈïøÁöÑËæìÂÖ•Â∫èÂàóÔºå‰ªéËÄåÊèêÈ´òËøô‰∫õÂ∫îÁî®ÁöÑÂÆûÊó∂ÊÄßÂíåÂÆûÁî®ÊÄß„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÂü∫‰∫éTransformerÁöÑ3DËßÜËßâ‰ªªÂä°‰∏≠„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The Visual Geometry Grounded Transformer (VGGT) marks a significant leap forward in 3D scene reconstruction, as it is the first model that directly infers all key 3D attributes (camera poses, depths, and dense geometry) jointly in one pass. However, this joint inference mechanism requires global attention layers that perform all-to-all attention computation on tokens from all views. For reconstruction of large scenes with long-sequence inputs, this causes a significant latency bottleneck. In this paper, we propose head-wise temporal merging (HTTM), a training-free 3D token merging method for accelerating VGGT. Existing merging techniques merge tokens uniformly across different attention heads, resulting in identical tokens in the layers' output, which hinders the model's representational ability. HTTM tackles this problem by merging tokens in multi-head granularity, which preserves the uniqueness of feature tokens after head concatenation. Additionally, this enables HTTM to leverage the spatial locality and temporal correspondence observed at the head level to achieve higher merging ratios with lower merging costs compared to existing methods. Thus, HTTM achieves up to 7x acceleration with negligible performance drops in a GPU-based inference.

