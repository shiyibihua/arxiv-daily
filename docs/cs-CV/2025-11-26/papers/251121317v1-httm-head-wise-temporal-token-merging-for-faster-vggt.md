---
layout: default
title: HTTM: Head-wise Temporal Token Merging for Faster VGGT
---

# HTTM: Head-wise Temporal Token Merging for Faster VGGT

**arXiv**: [2511.21317v1](https://arxiv.org/abs/2511.21317) | [PDF](https://arxiv.org/pdf/2511.21317.pdf)

**ä½œè€…**: Weitian Wang, Lukas Meiner, Rai Shubham, Cecilia De La Parra, Akash Kumar

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-26

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤´éƒ¨åˆ†æ—¶åºTokenåˆå¹¶(HTTM)åŠ é€ŸVGGTï¼Œç”¨äºŽå¿«é€Ÿ3Dåœºæ™¯é‡å»º**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dåœºæ™¯é‡å»º` `Transformer` `æ¨¡åž‹åŠ é€Ÿ` `Tokenåˆå¹¶` `å¤šå¤´æ³¨æ„åŠ›`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. VGGTåœ¨3Dåœºæ™¯é‡å»ºä¸­è¡¨çŽ°å‡ºè‰²ï¼Œä½†å…¨å±€æ³¨æ„åŠ›æœºåˆ¶å¯¼è‡´é•¿åºåˆ—è¾“å…¥æ—¶è®¡ç®—é‡å·¨å¤§ï¼Œæˆä¸ºæ€§èƒ½ç“¶é¢ˆã€‚
2. HTTMé€šè¿‡åœ¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„å¤´éƒ¨ç²’åº¦ä¸Šè¿›è¡Œtokenåˆå¹¶ï¼Œä¿ç•™äº†ç‰¹å¾tokençš„ç‹¬ç‰¹æ€§ï¼Œæå‡äº†æ¨¡åž‹è¡¨å¾èƒ½åŠ›ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒHTTMåœ¨GPUä¸Šå®žçŽ°äº†é«˜è¾¾7å€çš„åŠ é€Ÿï¼ŒåŒæ—¶æ€§èƒ½ä¸‹é™å¯å¿½ç•¥ä¸è®¡ï¼Œæ˜¾è‘—æå‡äº†VGGTçš„æ•ˆçŽ‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰å‡ ä½•åŸºç¡€Transformer (VGGT) åœ¨3Dåœºæ™¯é‡å»ºæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªç›´æŽ¥ä¸€æ¬¡æ€§è”åˆæŽ¨æ–­æ‰€æœ‰å…³é”®3Då±žæ€§ï¼ˆç›¸æœºå§¿æ€ã€æ·±åº¦å’Œå¯†é›†å‡ ä½•ï¼‰çš„æ¨¡åž‹ã€‚ç„¶è€Œï¼Œè¿™ç§è”åˆæŽ¨æ–­æœºåˆ¶éœ€è¦å…¨å±€æ³¨æ„åŠ›å±‚ï¼Œå¯¹æ¥è‡ªæ‰€æœ‰è§†è§’çš„tokenæ‰§è¡Œå…¨è¿žæŽ¥æ³¨æ„åŠ›è®¡ç®—ã€‚å¯¹äºŽå…·æœ‰é•¿åºåˆ—è¾“å…¥çš„å¤§åž‹åœºæ™¯é‡å»ºï¼Œè¿™ä¼šå¯¼è‡´æ˜¾è‘—çš„å»¶è¿Ÿç“¶é¢ˆã€‚æœ¬æ–‡æå‡ºå¤´éƒ¨åˆ†æ—¶åºåˆå¹¶ï¼ˆHTTMï¼‰ï¼Œä¸€ç§å…è®­ç»ƒçš„3D tokenåˆå¹¶æ–¹æ³•ï¼Œç”¨äºŽåŠ é€ŸVGGTã€‚çŽ°æœ‰çš„åˆå¹¶æŠ€æœ¯åœ¨ä¸åŒçš„æ³¨æ„åŠ›å¤´ä¸­ç»Ÿä¸€åˆå¹¶tokenï¼Œå¯¼è‡´å±‚è¾“å‡ºä¸­å‡ºçŽ°ç›¸åŒçš„tokenï¼Œè¿™é˜»ç¢äº†æ¨¡åž‹çš„è¡¨å¾èƒ½åŠ›ã€‚HTTMé€šè¿‡å¤šå¤´ç²’åº¦åˆå¹¶tokenæ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä»Žè€Œåœ¨å¤´éƒ¨è¿žæŽ¥åŽä¿æŒç‰¹å¾tokençš„å”¯ä¸€æ€§ã€‚æ­¤å¤–ï¼Œä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¿™ä½¿å¾—HTTMèƒ½å¤Ÿåˆ©ç”¨åœ¨å¤´éƒ¨å±‚é¢è§‚å¯Ÿåˆ°çš„ç©ºé—´å±€éƒ¨æ€§å’Œæ—¶é—´å¯¹åº”æ€§ï¼Œä»¥æ›´ä½Žçš„åˆå¹¶æˆæœ¬å®žçŽ°æ›´é«˜çš„åˆå¹¶çŽ‡ã€‚å› æ­¤ï¼ŒHTTMåœ¨åŸºäºŽGPUçš„æŽ¨ç†ä¸­å®žçŽ°äº†é«˜è¾¾7å€çš„åŠ é€Ÿï¼Œè€Œæ€§èƒ½ä¸‹é™å¯å¿½ç•¥ä¸è®¡ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šVGGTåœ¨3Dåœºæ™¯é‡å»ºä¸­éœ€è¦å¯¹æ‰€æœ‰è§†è§’çš„tokenè¿›è¡Œå…¨å±€æ³¨æ„åŠ›è®¡ç®—ï¼Œè¿™åœ¨å¤„ç†é•¿åºåˆ—è¾“å…¥çš„å¤§åž‹åœºæ™¯æ—¶ä¼šäº§ç”Ÿå·¨å¤§çš„è®¡ç®—é‡ï¼Œå¯¼è‡´æŽ¨ç†é€Ÿåº¦æ…¢ï¼Œæˆä¸ºæ€§èƒ½ç“¶é¢ˆã€‚çŽ°æœ‰çš„tokenåˆå¹¶æ–¹æ³•é€šå¸¸åœ¨ä¸åŒæ³¨æ„åŠ›å¤´ä¸­ç»Ÿä¸€åˆå¹¶tokenï¼Œå¯¼è‡´ä¿¡æ¯å†—ä½™ï¼Œé™ä½Žäº†æ¨¡åž‹çš„è¡¨å¾èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHTTMçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„å¤´éƒ¨ç²’åº¦ä¸Šè¿›è¡Œtokenåˆå¹¶ï¼Œè€Œä¸æ˜¯åƒçŽ°æœ‰æ–¹æ³•é‚£æ ·åœ¨æ‰€æœ‰å¤´éƒ¨ç»Ÿä¸€åˆå¹¶ã€‚è¿™æ ·å¯ä»¥ä¿ç•™æ¯ä¸ªå¤´éƒ¨å­¦ä¹ åˆ°çš„ç‹¬ç‰¹ç‰¹å¾ï¼Œé¿å…ä¿¡æ¯å†—ä½™ï¼Œä»Žè€Œåœ¨å‡å°‘è®¡ç®—é‡çš„åŒæ—¶ä¿æŒæ¨¡åž‹çš„è¡¨å¾èƒ½åŠ›ã€‚åŒæ—¶ï¼ŒHTTMåˆ©ç”¨å¤´éƒ¨å±‚é¢çš„ç©ºé—´å±€éƒ¨æ€§å’Œæ—¶é—´å¯¹åº”æ€§ï¼Œå®žçŽ°æ›´é«˜çš„åˆå¹¶çŽ‡å’Œæ›´ä½Žçš„åˆå¹¶æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šHTTMä¸»è¦åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼šé¦–å…ˆï¼Œå°†è¾“å…¥tokenæŒ‰ç…§æ—¶é—´é¡ºåºåˆ†ç»„ã€‚ç„¶åŽï¼Œå¯¹äºŽæ¯ä¸ªæ—¶é—´æ­¥çš„tokenï¼Œå°†å…¶è¾“å…¥åˆ°å¤šå¤´æ³¨æ„åŠ›å±‚ã€‚åœ¨æ¯ä¸ªæ³¨æ„åŠ›å¤´ä¸­ï¼ŒHTTMæ ¹æ®ä¸€å®šçš„ç­–ç•¥ï¼ˆä¾‹å¦‚ï¼ŒåŸºäºŽç›¸ä¼¼åº¦æˆ–é‡è¦æ€§ï¼‰é€‰æ‹©éœ€è¦ä¿ç•™çš„tokenï¼Œå¹¶åˆå¹¶å…¶ä½™çš„tokenã€‚æœ€åŽï¼Œå°†æ‰€æœ‰å¤´éƒ¨çš„è¾“å‡ºè¿žæŽ¥èµ·æ¥ï¼Œä½œä¸ºä¸‹ä¸€å±‚çš„è¾“å…¥ã€‚æ•´ä¸ªè¿‡ç¨‹æ— éœ€è®­ç»ƒï¼Œå¯ä»¥ç›´æŽ¥åº”ç”¨äºŽé¢„è®­ç»ƒçš„VGGTæ¨¡åž‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šHTTMæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽå…¶å¤´éƒ¨åˆ†æ—¶åºåˆå¹¶ç­–ç•¥ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•åœ¨æ‰€æœ‰å¤´éƒ¨ç»Ÿä¸€åˆå¹¶tokenä¸åŒï¼ŒHTTMåœ¨æ¯ä¸ªå¤´éƒ¨ç‹¬ç«‹åœ°è¿›è¡Œtokenåˆå¹¶ï¼Œä¿ç•™äº†æ¯ä¸ªå¤´éƒ¨å­¦ä¹ åˆ°çš„ç‹¬ç‰¹ç‰¹å¾ï¼Œé¿å…äº†ä¿¡æ¯å†—ä½™ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å‡å°‘è®¡ç®—é‡ï¼ŒåŒæ—¶ä¿æŒæ¨¡åž‹çš„è¡¨å¾èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šHTTMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) åŸºäºŽç›¸ä¼¼åº¦æˆ–é‡è¦æ€§çš„tokené€‰æ‹©ç­–ç•¥ï¼Œç”¨äºŽç¡®å®šå“ªäº›tokenéœ€è¦ä¿ç•™ï¼Œå“ªäº›tokenå¯ä»¥åˆå¹¶ï¼›2) å¤šå¤´ç²’åº¦çš„åˆå¹¶æ“ä½œï¼Œç¡®ä¿æ¯ä¸ªå¤´éƒ¨çš„ä¿¡æ¯èƒ½å¤Ÿè¢«å……åˆ†åˆ©ç”¨ï¼›3) å…è®­ç»ƒçš„è®¾è®¡ï¼Œä½¿å¾—HTTMå¯ä»¥ç›´æŽ¥åº”ç”¨äºŽé¢„è®­ç»ƒçš„VGGTæ¨¡åž‹ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒæˆæœ¬ã€‚å…·ä½“çš„ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•å’Œé‡è¦æ€§è¯„ä¼°æŒ‡æ ‡å¯ä»¥æ ¹æ®å®žé™…åº”ç”¨åœºæ™¯è¿›è¡Œè°ƒæ•´ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒHTTMåœ¨GPUä¸Šå®žçŽ°äº†é«˜è¾¾7å€çš„åŠ é€Ÿï¼ŒåŒæ—¶æ€§èƒ½ä¸‹é™å¯å¿½ç•¥ä¸è®¡ã€‚è¿™æ„å‘³ç€åœ¨ä¿æŒé‡å»ºè´¨é‡çš„å‰æä¸‹ï¼ŒVGGTçš„æŽ¨ç†é€Ÿåº¦å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚æ­¤å¤–ï¼ŒHTTMçš„å…è®­ç»ƒç‰¹æ€§ä½¿å…¶èƒ½å¤Ÿç›´æŽ¥åº”ç”¨äºŽé¢„è®­ç»ƒçš„VGGTæ¨¡åž‹ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒæˆæœ¬ï¼Œå…·æœ‰å¾ˆå¼ºçš„å®žç”¨æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

HTTMåŠ é€ŸVGGTçš„æ–¹æ³•å¯å¹¿æ³›åº”ç”¨äºŽéœ€è¦å¿«é€Ÿ3Dåœºæ™¯é‡å»ºçš„é¢†åŸŸï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€è™šæ‹ŸçŽ°å®žå’Œå¢žå¼ºçŽ°å®žç­‰ã€‚é€šè¿‡é™ä½Žè®¡ç®—æˆæœ¬å’Œå»¶è¿Ÿï¼ŒHTTMä½¿å¾—VGGTèƒ½å¤Ÿå¤„ç†æ›´å¤§è§„æ¨¡çš„åœºæ™¯å’Œæ›´é•¿çš„è¾“å…¥åºåˆ—ï¼Œä»Žè€Œæé«˜è¿™äº›åº”ç”¨çš„å®žæ—¶æ€§å’Œå®žç”¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–åŸºäºŽTransformerçš„3Dè§†è§‰ä»»åŠ¡ä¸­ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The Visual Geometry Grounded Transformer (VGGT) marks a significant leap forward in 3D scene reconstruction, as it is the first model that directly infers all key 3D attributes (camera poses, depths, and dense geometry) jointly in one pass. However, this joint inference mechanism requires global attention layers that perform all-to-all attention computation on tokens from all views. For reconstruction of large scenes with long-sequence inputs, this causes a significant latency bottleneck. In this paper, we propose head-wise temporal merging (HTTM), a training-free 3D token merging method for accelerating VGGT. Existing merging techniques merge tokens uniformly across different attention heads, resulting in identical tokens in the layers' output, which hinders the model's representational ability. HTTM tackles this problem by merging tokens in multi-head granularity, which preserves the uniqueness of feature tokens after head concatenation. Additionally, this enables HTTM to leverage the spatial locality and temporal correspondence observed at the head level to achieve higher merging ratios with lower merging costs compared to existing methods. Thus, HTTM achieves up to 7x acceleration with negligible performance drops in a GPU-based inference.

