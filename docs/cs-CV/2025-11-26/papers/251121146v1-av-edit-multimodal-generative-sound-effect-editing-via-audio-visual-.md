---
layout: default
title: AV-Edit: Multimodal Generative Sound Effect Editing via Audio-Visual Semantic Joint Control
---

# AV-Edit: Multimodal Generative Sound Effect Editing via Audio-Visual Semantic Joint Control

**arXiv**: [2511.21146v1](https://arxiv.org/abs/2511.21146) | [PDF](https://arxiv.org/pdf/2511.21146.pdf)

**ä½œè€…**: Xinyue Guo, Xiaoran Yang, Lipan Zhang, Jianxuan Yang, Zhao Wang, Jian Luan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAV-Editæ¡†æž¶ï¼Œé€šè¿‡éŸ³è§†é¢‘è¯­ä¹‰è”åˆæŽ§åˆ¶å®žçŽ°è§†é¢‘ä¸­éŸ³æ•ˆçš„ç»†ç²’åº¦ç¼–è¾‘**

**å…³é”®è¯**: `éŸ³æ•ˆç¼–è¾‘` `å¤šæ¨¡æ€ç”Ÿæˆ` `éŸ³è§†é¢‘è¯­ä¹‰å¯¹é½` `æ‰©æ•£å˜æ¢å™¨` `å¯¹æ¯”å­¦ä¹ ` `è§†é¢‘éŸ³é¢‘æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰éŸ³æ•ˆç¼–è¾‘æ–¹æ³•ä¾èµ–ä½Žå±‚ä¿¡å·å¤„ç†æˆ–ç²—ç²’åº¦æ–‡æœ¬æç¤ºï¼Œçµæ´»æ€§å·®ä¸”éŸ³é¢‘è´¨é‡ä¸ä½³
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å¯¹æ¯”éŸ³è§†é¢‘æŽ©ç è‡ªç¼–ç å™¨é¢„è®­ç»ƒï¼Œç»“åˆå¤šæ¨¡æ€æ‰©æ•£å˜æ¢å™¨è¿›è¡ŒéŸ³æ•ˆç§»é™¤ä¸Žç”Ÿæˆ
3. å®žéªŒæˆ–æ•ˆæžœï¼šæž„å»ºä¸“ç”¨æ•°æ®é›†è¯„ä¼°ï¼Œç”Ÿæˆé«˜è´¨é‡éŸ³é¢‘ï¼Œåœ¨éŸ³æ•ˆç¼–è¾‘é¢†åŸŸè¾¾åˆ°å…ˆè¿›æ°´å¹³

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Sound effect editing-modifying audio by adding, removing, or replacing elements-remains constrained by existing approaches that rely solely on low-level signal processing or coarse text prompts, often resulting in limited flexibility and suboptimal audio quality. To address this, we propose AV-Edit, a generative sound effect editing framework that enables fine-grained editing of existing audio tracks in videos by jointly leveraging visual, audio, and text semantics. Specifically, the proposed method employs a specially designed contrastive audio-visual masking autoencoder (CAV-MAE-Edit) for multimodal pre-training, learning aligned cross-modal representations. These representations are then used to train an editorial Multimodal Diffusion Transformer (MM-DiT) capable of removing visually irrelevant sounds and generating missing audio elements consistent with video content through a correlation-based feature gating training strategy. Furthermore, we construct a dedicated video-based sound editing dataset as an evaluation benchmark. Experiments demonstrate that the proposed AV-Edit generates high-quality audio with precise modifications based on visual content, achieving state-of-the-art performance in the field of sound effect editing and exhibiting strong competitiveness in the domain of audio generation.

