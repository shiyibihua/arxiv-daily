---
layout: default
title: Progress by Pieces: Test-Time Scaling for Autoregressive Image Generation
---

# Progress by Pieces: Test-Time Scaling for Autoregressive Image Generation

**arXiv**: [2511.21185v1](https://arxiv.org/abs/2511.21185) | [PDF](https://arxiv.org/pdf/2511.21185.pdf)

**ä½œè€…**: Joonhyung Park, Hyeongwon Jang, Joowon Kim, Eunho Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGridARæ¡†æž¶ä»¥ä¼˜åŒ–è§†è§‰è‡ªå›žå½’æ¨¡åž‹çš„æµ‹è¯•æ—¶æ‰©å±•ç”Ÿæˆè´¨é‡**

**å…³é”®è¯**: `è§†è§‰è‡ªå›žå½’æ¨¡åž‹` `æµ‹è¯•æ—¶æ‰©å±•` `å›¾åƒç”Ÿæˆ` `ç½‘æ ¼åˆ’åˆ†ç”Ÿæˆ` `æç¤ºé‡æž„` `å›¾åƒç¼–è¾‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæµ‹è¯•æ—¶æ‰©å±•ç­–ç•¥åœ¨è§†è§‰è‡ªå›žå½’æ¨¡åž‹ä¸­æ•ˆçŽ‡ä½Žï¼Œå› å…¨ç”»å¸ƒè§£ç ç¼ºä¹è“å›¾ä¸”é”™è¯¯è½¨è¿¹æ¶ˆè€—è®¡ç®—èµ„æº
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ç½‘æ ¼åˆ’åˆ†æ¸è¿›ç”Ÿæˆï¼Œæ—©æœŸå‰ªæžä¸å¯è¡Œå€™é€‰ï¼Œå¹¶åˆ©ç”¨å¸ƒå±€æŒ‡å®šæç¤ºé‡æž„æŒ‡å¯¼åŽç»­è§£ç 
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨N=4æ—¶ä¼˜äºŽBest-of-N(N=8)ï¼ŒT2I-CompBench++ä¸Šæå‡14.4%ï¼Œæˆæœ¬é™ä½Ž25.6%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent visual autoregressive (AR) models have shown promising capabilities in text-to-image generation, operating in a manner similar to large language models. While test-time computation scaling has brought remarkable success in enabling reasoning-enhanced outputs for challenging natural language tasks, its adaptation to visual AR models remains unexplored and poses unique challenges. Naively applying test-time scaling strategies such as Best-of-N can be suboptimal: they consume full-length computation on erroneous generation trajectories, while the raster-scan decoding scheme lacks a blueprint of the entire canvas, limiting scaling benefits as only a few prompt-aligned candidates are generated. To address these, we introduce GridAR, a test-time scaling framework designed to elicit the best possible results from visual AR models. GridAR employs a grid-partitioned progressive generation scheme in which multiple partial candidates for the same position are generated within a canvas, infeasible ones are pruned early, and viable ones are fixed as anchors to guide subsequent decoding. Coupled with this, we present a layout-specified prompt reformulation strategy that inspects partial views to infer a feasible layout for satisfying the prompt. The reformulated prompt then guides subsequent image generation to mitigate the blueprint deficiency. Together, GridAR achieves higher-quality results under limited test-time scaling: with N=4, it even outperforms Best-of-N (N=8) by 14.4% on T2I-CompBench++ while reducing cost by 25.6%. It also generalizes to autoregressive image editing, showing comparable edit quality and a 13.9% gain in semantic preservation on PIE-Bench over larger-N baselines.

