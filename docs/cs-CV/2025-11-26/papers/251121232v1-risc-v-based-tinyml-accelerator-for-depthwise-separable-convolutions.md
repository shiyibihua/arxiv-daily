---
layout: default
title: RISC-V Based TinyML Accelerator for Depthwise Separable Convolutions in Edge AI
---

# RISC-V Based TinyML Accelerator for Depthwise Separable Convolutions in Edge AI

**arXiv**: [2511.21232v1](https://arxiv.org/abs/2511.21232) | [PDF](https://arxiv.org/pdf/2511.21232.pdf)

**ä½œè€…**: Muhammed Yildirim, Ozcan Ozturk

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRISC-Vèžåˆåƒç´ æ•°æ®æµåŠ é€Ÿå™¨ä»¥è§£å†³è¾¹ç¼˜AIä¸­æ·±åº¦å¯åˆ†ç¦»å·ç§¯çš„å†…å­˜å¢™é—®é¢˜**

**å…³é”®è¯**: `è¾¹ç¼˜AIåŠ é€Ÿå™¨` `æ·±åº¦å¯åˆ†ç¦»å·ç§¯` `RISC-Vå¤„ç†å™¨` `æ•°æ®æµä¼˜åŒ–` `å†…å­˜å¢™ç¼“è§£` `TinyMLç¡¬ä»¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ·±åº¦å¯åˆ†ç¦»å·ç§¯é€å±‚æ‰§è¡Œå¯¼è‡´ä¸­é—´ç‰¹å¾å›¾ä¼ è¾“èƒ½è€—é«˜ã€å»¶è¿Ÿå¤§
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨èžåˆåƒç´ æ•°æ®æµï¼Œæ— ä¸­é—´ç¼“å†²ï¼Œé€šè¿‡æµæ°´çº¿å®Œæˆæ‰€æœ‰é˜¶æ®µè®¡ç®—
3. å®žéªŒæˆ–æ•ˆæžœï¼šFPGAå®žçŽ°59.3å€åŠ é€Ÿï¼ŒASICåˆæˆæ˜¾ç¤ºå°é¢ç§¯ä½ŽåŠŸè€—

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The increasing demand for on-device intelligence in Edge AI and TinyML applications requires the efficient execution of modern Convolutional Neural Networks (CNNs). While lightweight architectures like MobileNetV2 employ Depthwise Separable Convolutions (DSC) to reduce computational complexity, their multi-stage design introduces a critical performance bottleneck inherent to layer-by-layer execution: the high energy and latency cost of transferring intermediate feature maps to either large on-chip buffers or off-chip DRAM. To address this memory wall, this paper introduces a novel hardware accelerator architecture that utilizes a fused pixel-wise dataflow. Implemented as a Custom Function Unit (CFU) for a RISC-V processor, our architecture eliminates the need for intermediate buffers entirely, reducing the data movement up to 87\% compared to conventional layer-by-layer execution. It computes a single output pixel to completion across all DSC stages-expansion, depthwise convolution, and projection-by streaming data through a tightly-coupled pipeline without writing to memory. Evaluated on a Xilinx Artix-7 FPGA, our design achieves a speedup of up to 59.3x over the baseline software execution on the RISC-V core. Furthermore, ASIC synthesis projects a compact 0.284 mm$^2$ footprint with 910 mW power at 2 GHz in 28 nm, and a 1.20 mm$^2$ footprint with 233 mW power at 300 MHz in 40 nm. This work confirms the feasibility of a zero-buffer dataflow within a TinyML resource envelope, offering a novel and effective strategy for overcoming the memory wall in edge AI accelerators.

