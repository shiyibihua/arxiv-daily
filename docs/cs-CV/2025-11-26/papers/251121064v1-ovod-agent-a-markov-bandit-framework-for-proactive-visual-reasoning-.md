---
layout: default
title: OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection
---

# OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection

**arXiv**: [2511.21064v1](https://arxiv.org/abs/2511.21064) | [PDF](https://arxiv.org/pdf/2511.21064.pdf)

**ä½œè€…**: Chujie Wang, Jianyu Lu, Zhiyuan Luo, Xi Chen, Chu He

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOVOD-Agentæ¡†æž¶ï¼Œé€šè¿‡ä¸»åŠ¨è§†è§‰æŽ¨ç†ä¸Žè‡ªè¿›åŒ–æ£€æµ‹è§£å†³å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹çš„æ³›åŒ–é—®é¢˜**

**å…³é”®è¯**: `å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹` `å¼±é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹` `BanditæŽ¢ç´¢` `è§†è§‰æŽ¨ç†é“¾` `è‡ªè¿›åŒ–æ£€æµ‹` `å¥–åŠ±æ¨¡åž‹ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹åœ¨æŽ¨ç†æ—¶ä¾èµ–å›ºå®šç±»åˆ«åï¼Œå¯¼è‡´å¤šæ¨¡æ€è®­ç»ƒä¸Žå•æ¨¡æ€æŽ¨ç†é—´å­˜åœ¨å·®è·
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå¼±é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹å»ºæ¨¡è§†è§‰ä¸Šä¸‹æ–‡ï¼Œç»“åˆBanditæ¨¡å—æŽ¢ç´¢ä¸ç¡®å®šåŒºåŸŸå¹¶ä¼˜åŒ–å¥–åŠ±æ¨¡åž‹
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨COCOå’ŒLVISæ•°æ®é›†ä¸ŠéªŒè¯ï¼Œå¯¹ç¨€æœ‰ç±»åˆ«æ£€æµ‹æ•ˆæžœæå‡æ˜¾è‘—ï¼Œå…¼å®¹å¤šç§OVODéª¨å¹²ç½‘ç»œ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Open-Vocabulary Object Detection (OVOD) aims to enable detectors to generalize across categories by leveraging semantic information. Although existing methods are pretrained on large vision-language datasets, their inference is still limited to fixed category names, creating a gap between multimodal training and unimodal inference. Previous work has shown that improving textual representation can significantly enhance OVOD performance, indicating that the textual space is still underexplored. To this end, we propose OVOD-Agent, which transforms passive category matching into proactive visual reasoning and self-evolving detection. Inspired by the Chain-of-Thought (CoT) paradigm, OVOD-Agent extends the textual optimization process into an interpretable Visual-CoT with explicit actions. OVOD's lightweight nature makes LLM-based management unsuitable; instead, we model visual context transitions as a Weakly Markovian Decision Process (w-MDP) over eight state spaces, which naturally represents the agent's state, memory, and interaction dynamics. A Bandit module generates exploration signals under limited supervision, helping the agent focus on uncertain regions and adapt its detection policy. We further integrate Markov transition matrices with Bandit trajectories for self-supervised Reward Model (RM) optimization, forming a closed loop from Bandit exploration to RM learning. Experiments on COCO and LVIS show that OVOD-Agent provides consistent improvements across OVOD backbones, particularly on rare categories, confirming the effectiveness of the proposed framework.

