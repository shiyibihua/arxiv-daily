---
layout: default
title: RosettaSpeech: Zero-Shot Speech-to-Speech Translation from Monolingual Data
---

# RosettaSpeech: Zero-Shot Speech-to-Speech Translation from Monolingual Data

**arXiv**: [2511.20974v1](https://arxiv.org/abs/2511.20974) | [PDF](https://arxiv.org/pdf/2511.20974.pdf)

**ä½œè€…**: Zhisheng Zheng, Xiaohang Sun, Tuan Dinh, Abhishek Yanamandra, Abhinav Jain, Zhu Liu, Sunil Hadap, Vimal Bhat, Manoj Aggarwal, Gerard Medioni, David Harwath

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRosettaSpeechæ¡†æž¶ï¼Œåˆ©ç”¨å•è¯­æ•°æ®å’Œæœºå™¨ç¿»è¯‘å®žçŽ°é›¶æ ·æœ¬è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘ã€‚**

**å…³é”®è¯**: `è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘` `é›¶æ ·æœ¬å­¦ä¹ ` `å•è¯­æ•°æ®è®­ç»ƒ` `æœºå™¨ç¿»è¯‘ç›‘ç£` `ç«¯åˆ°ç«¯æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¹³è¡Œè¯­éŸ³è¯­æ–™ç¨€ç¼ºï¼Œé˜»ç¢è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘å‘å±•ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®­ç»ƒæ—¶ä½¿ç”¨æ–‡æœ¬ä½œä¸ºæ¡¥æ¢ï¼ŒæŽ¨ç†æ—¶ç«¯åˆ°ç«¯ç›´æŽ¥ç¿»è¯‘è¯­éŸ³ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨CVSS-Cæµ‹è¯•é›†ä¸Šï¼Œå¾·è¯­åˆ°è‹±è¯­ASR-BLEUè¾¾25.17ï¼Œæ€§èƒ½é¢†å…ˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The scarcity of parallel speech corpora critically hampers speech-to-speech translation (S2ST), often forcing reliance on complex, multi-stage pipelines. This paper introduces RosettaSpeech, a novel and simplified framework for zero-shot S2ST that is trained on monolingual speech-text data augmented by machine translation supervision. While our method leverages the linguistic knowledge inherent in text-based NMT models, it strictly eliminates the need for parallel speech-to-speech pairs. Our model uniquely uses text as an intermediate bridge during training but functions as a direct, end-to-end speech-to-speech model at inference. This streamlined approach achieves state-of-the-art results on standard benchmarks. For instance, on the CVSS-C test set, RosettaSpeech outperforms leading systems, achieving an ASR-BLEU score of 25.17 for German-to-English and 29.86 for Spanish-to-English-relative gains of over 27% and 14%, respectively. Furthermore, we demonstrate that a single model can deliver strong many-to-one translation performance (FR/ES/DE -> EN). We also provide a foundational analysis of how training data scaling impacts model performance. By prioritizing reliance on abundant parallel text rather than difficult-to-acquire parallel speech, RosettaSpeech offers a scalable path to creating high-quality, speaker-preserving S2ST for a much broader array of languages.

