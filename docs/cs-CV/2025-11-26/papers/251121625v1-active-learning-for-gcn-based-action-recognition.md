---
layout: default
title: Active Learning for GCN-based Action Recognition
---

# Active Learning for GCN-based Action Recognition

**arXiv**: [2511.21625v1](https://arxiv.org/abs/2511.21625) | [PDF](https://arxiv.org/pdf/2511.21625.pdf)

**ä½œè€…**: Hichem Sahbi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ ‡ç­¾é«˜æ•ˆGCNæ¨¡åž‹ï¼Œé€šè¿‡ä¸»åŠ¨å­¦ä¹ è§£å†³éª¨æž¶åŠ¨ä½œè¯†åˆ«ä¸­æ ‡æ³¨æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚**

**å…³é”®è¯**: `ä¸»åŠ¨å­¦ä¹ ` `å›¾å·ç§¯ç½‘ç»œ` `éª¨æž¶åŠ¨ä½œè¯†åˆ«` `æ ‡ç­¾æ•ˆçŽ‡` `å¯¹æŠ—ç­–ç•¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šGCNåœ¨éª¨æž¶åŠ¨ä½œè¯†åˆ«ä¸­ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œä½†å®žé™…åœºæ™¯ä¸­æ•°æ®ç¨€ç¼ºã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼€å‘å¯¹æŠ—æ€§é‡‡é›†å‡½æ•°é€‰æ‹©ä¿¡æ¯æ ·æœ¬ï¼Œå¹¶å¼•å…¥åŒå‘ç¨³å®šGCNæž¶æž„ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œæ¨¡åž‹ç›¸æ¯”å…ˆå‰å·¥ä½œå®žçŽ°æ˜¾è‘—æ€§èƒ½æå‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite the notable success of graph convolutional networks (GCNs) in skeleton-based action recognition, their performance often depends on large volumes of labeled data, which are frequently scarce in practical settings. To address this limitation, we propose a novel label-efficient GCN model. Our work makes two primary contributions. First, we develop a novel acquisition function that employs an adversarial strategy to identify a compact set of informative exemplars for labeling. This selection process balances representativeness, diversity, and uncertainty. Second, we introduce bidirectional and stable GCN architectures. These enhanced networks facilitate a more effective mapping between the ambient and latent data spaces, enabling a better understanding of the learned exemplar distribution. Extensive evaluations on two challenging skeleton-based action recognition benchmarks reveal significant improvements achieved by our label-efficient GCNs compared to prior work.

