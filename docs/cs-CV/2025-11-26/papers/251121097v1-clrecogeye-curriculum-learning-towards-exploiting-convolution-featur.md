---
layout: default
title: CLRecogEye : Curriculum Learning towards exploiting convolution features for Dynamic Iris Recognition
---

# CLRecogEye : Curriculum Learning towards exploiting convolution features for Dynamic Iris Recognition

**arXiv**: [2511.21097v1](https://arxiv.org/abs/2511.21097) | [PDF](https://arxiv.org/pdf/2511.21097.pdf)

**ä½œè€…**: Geetanjali Sharma, Gaurav Jaswal, Aditya Nigam, Raghavendra Ramachandra

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-26

**å¤‡æ³¨**: 12 Pages, 3 figures, ISVC conference 2025

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/GeetanjaliGTZ/CLRecogEye)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCLRecogEyeï¼Œåˆ©ç”¨å·ç§¯ç‰¹å¾å’Œè¯¾ç¨‹å­¦ä¹ æå‡åŠ¨æ€è™¹è†œè¯†åˆ«çš„é²æ£’æ€§ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è™¹è†œè¯†åˆ«` `3Då·ç§¯ç¥žç»ç½‘ç»œ` `è¯¾ç¨‹å­¦ä¹ ` `æ—¶ç©ºç‰¹å¾` `åº¦é‡å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è™¹è†œè¯†åˆ«æ–¹æ³•åœ¨æ—‹è½¬ã€å°ºåº¦å˜åŒ–ã€åå°„å’Œæ¨¡ç³Šç­‰å› ç´ å½±å“ä¸‹ï¼Œé²æ£’æ€§é¢ä¸´æŒ‘æˆ˜ï¼Œä¸”ç¼ºä¹å¯¹è™¹è†œæ—¶ç©ºç»“æž„çš„æœ‰æ•ˆåˆ©ç”¨ã€‚
2. CLRecogEyeé€šè¿‡å°†è™¹è†œå›¾åƒåˆ†å‰²æˆåºåˆ—ï¼Œè¾“å…¥3D-CNNå­¦ä¹ æ—¶ç©ºç‰¹å¾ï¼Œå¹¶é‡‡ç”¨è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œå¢žå¼ºç‰¹å¾çš„åŒºåˆ†æ€§ã€‚
3. è¯¥æ–¹æ³•é€šè¿‡ç«¯åˆ°ç«¯è®­ç»ƒï¼Œä½¿ç”¨tripletå’ŒArcFaceæŸå¤±ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹å®žçŽ°äº†é²æ£’çš„è™¹è†œè®¤è¯ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è™¹è†œè®¤è¯ç®—æ³•åœ¨è¯†åˆ«æ€§èƒ½æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½¿å…¶åœ¨è¾¹å¢ƒæŽ§åˆ¶ã€å…¬æ°‘èº«ä»½è¯†åˆ«ã€åˆ‘äº‹è°ƒæŸ¥å’Œå•†ä¸šç³»ç»Ÿç­‰å®žé™…åº”ç”¨ä¸­æžå…·å‰æ™¯ã€‚ç„¶è€Œï¼Œæ—‹è½¬ã€å°ºåº¦ã€é•œé¢åå°„å’Œæ•£ç„¦æ¨¡ç³Šç­‰å˜åŒ–ä»ç„¶å¯¹å…¶é²æ£’æ€§æž„æˆæŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œå¤§å¤šæ•°çŽ°æœ‰æ–¹æ³•ä¾èµ–äºŽç›´æŽ¥çš„ç‚¹å¯¹ç‚¹æ¯”è¾ƒï¼Œé€šå¸¸ä½¿ç”¨ä½™å¼¦æˆ–L2è·ç¦»ï¼Œè€Œæ²¡æœ‰æœ‰æ•ˆåœ°åˆ©ç”¨è™¹è†œæ¨¡å¼çš„æ—¶ç©ºç»“æž„ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é€šç”¨çš„åŒ¹é…æµç¨‹ï¼Œè¯¥æµç¨‹å­¦ä¹ è™¹è†œç‰¹å¾çš„ä¸°å¯Œæ—¶ç©ºè¡¨ç¤ºã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆæ²¿ä¸€ä¸ªç»´åº¦åˆ†å‰²æ¯ä¸ªè™¹è†œå›¾åƒï¼Œç”Ÿæˆä¸€ç³»åˆ—å­å›¾åƒï¼Œä½œä¸º3D-CNNçš„è¾“å…¥ï¼Œä½¿ç½‘ç»œèƒ½å¤Ÿæ•èŽ·ç©ºé—´å’Œæ—¶ç©ºçº¿ç´¢ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¢žå¼ºæ—¶ç©ºç‰¹å¾åŠ¨æ€çš„å»ºæ¨¡ï¼Œæˆ‘ä»¬ä»¥è¯¾ç¨‹å­¦ä¹ çš„æ–¹å¼è®­ç»ƒæ¨¡åž‹ã€‚è¿™ç§è®¾è®¡å…è®¸ç½‘ç»œå°†æ—¶é—´ä¾èµ–æ€§ç›´æŽ¥åµŒå…¥åˆ°ç‰¹å¾ç©ºé—´ä¸­ï¼Œä»Žè€Œæé«˜æ·±åº¦åº¦é‡åŸŸä¸­çš„å¯åŒºåˆ†æ€§ã€‚è¯¥æ¡†æž¶ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼é€šè¿‡ triplet å’Œ ArcFace æŸå¤±è¿›è¡Œè¯¾ç¨‹å­¦ä¹ è®­ç»ƒï¼Œå³ä½¿é¢ä¸´æ—‹è½¬ã€å°ºåº¦ã€åå°„å’Œæ¨¡ç³Šç­‰æŒ‘æˆ˜ï¼Œä¹Ÿèƒ½å¼ºåˆ¶æ‰§è¡Œé«˜åº¦å¯åŒºåˆ†çš„åµŒå…¥ã€‚è¿™ç§è®¾è®¡ä¸ºè™¹è†œè®¤è¯æä¾›äº†ä¸€ç§é²æ£’ä¸”é€šç”¨çš„è§£å†³æ–¹æ¡ˆã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰è™¹è†œè¯†åˆ«æ–¹æ³•å¯¹å›¾åƒè´¨é‡æ•æ„Ÿï¼Œåœ¨æ—‹è½¬ã€å°ºåº¦å˜åŒ–ã€åå°„å’Œæ¨¡ç³Šç­‰å› ç´ å½±å“ä¸‹ï¼Œè¯†åˆ«ç²¾åº¦ä¼šæ˜¾è‘—ä¸‹é™ã€‚æ­¤å¤–ï¼Œä¼ ç»Ÿæ–¹æ³•é€šå¸¸é‡‡ç”¨ç‚¹å¯¹ç‚¹çš„ç‰¹å¾æ¯”è¾ƒï¼Œå¿½ç•¥äº†è™¹è†œçº¹ç†çš„æ—¶ç©ºç»“æž„ä¿¡æ¯ï¼Œå¯¼è‡´åŒºåˆ†èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCLRecogEyeçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨3Då·ç§¯ç¥žç»ç½‘ç»œï¼ˆ3D-CNNï¼‰æå–è™¹è†œå›¾åƒçš„æ—¶ç©ºç‰¹å¾ï¼Œå¹¶é€šè¿‡è¯¾ç¨‹å­¦ä¹ ï¼ˆCurriculum Learningï¼‰ç­–ç•¥ï¼Œé€æ­¥æå‡æ¨¡åž‹å¯¹å¤æ‚è™¹è†œå›¾åƒçš„è¯†åˆ«èƒ½åŠ›ã€‚é€šè¿‡å°†è™¹è†œå›¾åƒåˆ†å‰²æˆåºåˆ—ï¼Œ3D-CNNèƒ½å¤Ÿæ•æ‰è™¹è†œçº¹ç†åœ¨ç©ºé—´å’Œæ—¶é—´ä¸Šçš„åŠ¨æ€å˜åŒ–ï¼Œä»Žè€Œæé«˜ç‰¹å¾çš„åŒºåˆ†æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šCLRecogEyeæ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) è™¹è†œå›¾åƒé¢„å¤„ç†ï¼šå¯¹è™¹è†œå›¾åƒè¿›è¡Œåˆ†å‰²å’Œå½’ä¸€åŒ–å¤„ç†ã€‚2) å›¾åƒåºåˆ—ç”Ÿæˆï¼šå°†è™¹è†œå›¾åƒæ²¿ä¸€ä¸ªç»´åº¦åˆ†å‰²æˆä¸€ç³»åˆ—å­å›¾åƒï¼Œå½¢æˆå›¾åƒåºåˆ—ã€‚3) 3D-CNNç‰¹å¾æå–ï¼šä½¿ç”¨3D-CNNç½‘ç»œæå–å›¾åƒåºåˆ—çš„æ—¶ç©ºç‰¹å¾ã€‚4) è¯¾ç¨‹å­¦ä¹ è®­ç»ƒï¼šé‡‡ç”¨è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œä»Žç®€å•åˆ°å¤æ‚é€æ­¥è®­ç»ƒæ¨¡åž‹ã€‚5) åº¦é‡å­¦ä¹ ï¼šä½¿ç”¨Triplet Losså’ŒArcFace Lossè¿›è¡Œåº¦é‡å­¦ä¹ ï¼Œä¼˜åŒ–ç‰¹å¾åµŒå…¥ç©ºé—´ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„ä¸»è¦åˆ›æ–°ç‚¹åœ¨äºŽï¼š1) å¼•å…¥3D-CNNæ¥æå–è™¹è†œå›¾åƒçš„æ—¶ç©ºç‰¹å¾ï¼Œæœ‰æ•ˆåˆ©ç”¨äº†è™¹è†œçº¹ç†çš„åŠ¨æ€ä¿¡æ¯ã€‚2) é‡‡ç”¨è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œé€æ­¥æå‡æ¨¡åž‹å¯¹å¤æ‚è™¹è†œå›¾åƒçš„è¯†åˆ«èƒ½åŠ›ï¼Œé¿å…äº†æ¨¡åž‹åœ¨è®­ç»ƒåˆæœŸé™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚3) å°†3D-CNNä¸Žè¯¾ç¨‹å­¦ä¹ ç›¸ç»“åˆï¼Œä¸ºè™¹è†œè¯†åˆ«æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æž„æ–¹é¢ï¼Œé‡‡ç”¨äº†3Då·ç§¯å±‚æ¥æ•æ‰æ—¶ç©ºä¿¡æ¯ã€‚åœ¨æŸå¤±å‡½æ•°æ–¹é¢ï¼ŒåŒæ—¶ä½¿ç”¨äº†Triplet Losså’ŒArcFace Lossï¼ŒTriplet Lossç”¨äºŽæ‹‰è¿‘åŒç±»æ ·æœ¬çš„è·ç¦»ï¼ŒæŽ¨è¿œå¼‚ç±»æ ·æœ¬çš„è·ç¦»ï¼ŒArcFace Lossåˆ™é€šè¿‡åœ¨è§’åº¦ç©ºé—´ä¸Šå¢žåŠ ç±»é—´è·ç¦»ï¼Œè¿›ä¸€æ­¥æé«˜ç‰¹å¾çš„åŒºåˆ†æ€§ã€‚è¯¾ç¨‹å­¦ä¹ ç­–ç•¥çš„å…·ä½“å®žçŽ°æ–¹å¼æ˜¯ï¼šé¦–å…ˆä½¿ç”¨é«˜è´¨é‡çš„è™¹è†œå›¾åƒè¿›è¡Œè®­ç»ƒï¼Œç„¶åŽé€æ­¥å¢žåŠ ä½Žè´¨é‡å›¾åƒçš„æ¯”ä¾‹ï¼Œä»Žè€Œä½¿æ¨¡åž‹é€æ¸é€‚åº”å„ç§å¤æ‚çš„è™¹è†œå›¾åƒã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºŽ3D-CNNå’Œè¯¾ç¨‹å­¦ä¹ çš„è™¹è†œè¯†åˆ«æ–¹æ³•ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚é€šè¿‡å®žéªŒéªŒè¯ï¼Œè¯¥æ–¹æ³•åœ¨æ—‹è½¬ã€å°ºåº¦å˜åŒ–ã€åå°„å’Œæ¨¡ç³Šç­‰å› ç´ å½±å“ä¸‹ï¼Œä»ç„¶èƒ½å¤Ÿä¿æŒè¾ƒé«˜çš„è¯†åˆ«ç²¾åº¦ï¼Œè¡¨æ˜Žå…¶å…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†æ‘˜è¦å¼ºè°ƒäº†å…¶åœ¨æ·±åº¦åº¦é‡åŸŸä¸­æé«˜äº†å¯åŒºåˆ†æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§éœ€è¦é«˜å®‰å…¨æ€§çš„èº«ä»½è®¤è¯åœºæ™¯ï¼Œå¦‚è¾¹å¢ƒå®‰å…¨æŽ§åˆ¶ã€å…¬æ°‘èº«ä»½è¯†åˆ«ã€é‡‘èžæ”¯ä»˜ç³»ç»Ÿã€é—¨ç¦ç³»ç»Ÿç­‰ã€‚é€šè¿‡æé«˜è™¹è†œè¯†åˆ«çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ï¼Œå¯ä»¥æœ‰æ•ˆé˜²æ­¢èº«ä»½æ¬ºè¯ˆå’Œéžæ³•å…¥ä¾µï¼Œä¿éšœç¤¾ä¼šå®‰å…¨å’Œä¸ªäººè´¢äº§å®‰å…¨ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ä¸Žç§»åŠ¨è®¾å¤‡é›†æˆï¼Œå®žçŽ°ä¾¿æ·çš„ç§»åŠ¨è™¹è†œè®¤è¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Iris authentication algorithms have achieved impressive recognition performance, making them highly promising for real-world applications such as border control, citizen identification, and both criminal investigations and commercial systems. However, their robustness is still challenged by variations in rotation, scale, specular reflections, and defocus blur. In addition, most existing approaches rely on straightforward point-to-point comparisons, typically using cosine or L2 distance, without effectively leveraging the spatio-spatial-temporal structure of iris patterns. To address these limitations, we propose a novel and generalized matching pipeline that learns rich spatio-spatial-temporal representations of iris features. Our approach first splits each iris image along one dimension, generating a sequence of sub-images that serve as input to a 3D-CNN, enabling the network to capture both spatial and spatio-spatial-temporal cues. To further enhance the modeling of spatio-spatial-temporal feature dynamics, we train the model in curriculum manner. This design allows the network to embed temporal dependencies directly into the feature space, improving discriminability in the deep metric domain. The framework is trained end-to-end with triplet and ArcFace loss in a curriculum manner, enforcing highly discriminative embeddings despite challenges like rotation, scale, reflections, and blur. This design yields a robust and generalizable solution for iris authentication.Github code: https://github.com/GeetanjaliGTZ/CLRecogEye

