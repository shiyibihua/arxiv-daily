---
layout: default
title: Pessimistic Verification for Open Ended Math Questions
---

# Pessimistic Verification for Open Ended Math Questions

**arXiv**: [2511.21522v1](https://arxiv.org/abs/2511.21522) | [PDF](https://arxiv.org/pdf/2511.21522.pdf)

**ä½œè€…**: Yanxing Huang, Zihan Tang, Zejin Lin, Peng Li, Yang Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ‚²è§‚éªŒè¯æ–¹æ³•ä»¥æå‡å¼€æ”¾æ•°å­¦é—®é¢˜éªŒè¯æ€§èƒ½**

**å…³é”®è¯**: `æ‚²è§‚éªŒè¯` `æ•°å­¦é—®é¢˜éªŒè¯` `é”™è¯¯æ£€æµ‹` `å¹¶è¡ŒéªŒè¯` `è¯­è¨€æ¨¡åž‹å¯é æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰éªŒè¯æ–¹æ³•åœ¨é”™è¯¯æ£€æµ‹èƒ½åŠ›ä¸Šå­˜åœ¨å±€é™ï¼Œå½±å“å¼€æ”¾æ•°å­¦é—®é¢˜éªŒè¯æ•ˆæžœã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡å¤šå¹¶è¡ŒéªŒè¯æµç¨‹ï¼Œä»»ä¸€éªŒè¯æŠ¥å‘Šé”™è¯¯å³åˆ¤å®šè¯æ˜Žé”™è¯¯ï¼Œæå‡å‡†ç¡®æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°å­¦åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡æ€§èƒ½ï¼Œä¸”è®¡ç®—èµ„æºæ¶ˆè€—ä½Žï¼Œä¼˜äºŽæ‰©å±•é•¿é“¾æ€ç»´ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The key limitation of the verification performance lies in the ability of error detection. With this intuition we designed several variants of pessimistic verification, which are simple workflows that could significantly improve the verification of open-ended math questions. In pessimistic verification we construct multiple parallel verifications for the same proof, and the proof is deemed incorrect if any one of them reports an error. This simple technique significantly improves the performance across many math verification benchmarks without incurring substantial computational resources. Its token efficiency even surpassed extended long-CoT in test-time scaling. Our case studies further indicate that the majority of false negatives in stronger models are actually caused by annotation errors in the original dataset, so our method's performance is in fact underestimated. Self-verification for mathematical problems can effectively improve the reliability and performance of language model outputs, and it also plays a critical role in enabling long-horizon mathematical tasks. We believe that research on pessimistic verification will help enhance the mathematical capabilities of language models across a wide range of tasks.

