---
layout: default
title: Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation
---

# Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation

**arXiv**: [2511.21517v1](https://arxiv.org/abs/2511.21517) | [PDF](https://arxiv.org/pdf/2511.21517.pdf)

**ä½œè€…**: Lina Conti, Dennis Fucci, Marco Gaido, Matteo Negri, Guillaume Wisniewski, Luisa Bentivogli

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºè¯­éŸ³ç¿»è¯‘ä¸­åŸºäºŽå£°å­¦ä¸Žä»£è¯æœºåˆ¶è§£å†³æ€§åˆ«åè§é—®é¢˜**

**å…³é”®è¯**: `è¯­éŸ³ç¿»è¯‘` `æ€§åˆ«åè§` `å£°å­¦ç‰¹å¾` `ä»£è¯æœºåˆ¶` `æ¨¡åž‹å¯è§£é‡Šæ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè¯­éŸ³ç¿»è¯‘ä¸­å£°å­¦çº¿ç´¢å¯èƒ½å¯¼è‡´æ€§åˆ«è¯¯åˆ¤ï¼Œå°¤å…¶åœ¨è¯­æ³•æ€§åˆ«è¯­è¨€ä¸­ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ†æžè®­ç»ƒæ•°æ®ã€å†…éƒ¨è¯­è¨€æ¨¡åž‹åè§å’Œå£°å­¦ä¿¡æ¯äº¤äº’æœºåˆ¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå‘çŽ°æ¨¡åž‹åˆ©ç”¨ç¬¬ä¸€äººç§°ä»£è¯é“¾æŽ¥æ€§åˆ«ä¿¡æ¯ï¼Œæé«˜å‡†ç¡®æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Unlike text, speech conveys information about the speaker, such as gender, through acoustic cues like pitch. This gives rise to modality-specific bias concerns. For example, in speech translation (ST), when translating from languages with notional gender, such as English, into languages where gender-ambiguous terms referring to the speaker are assigned grammatical gender, the speaker's vocal characteristics may play a role in gender assignment. This risks misgendering speakers, whether through masculine defaults or vocal-based assumptions. Yet, how ST models make these decisions remains poorly understood. We investigate the mechanisms ST models use to assign gender to speaker-referring terms across three language pairs (en-es/fr/it), examining how training data patterns, internal language model (ILM) biases, and acoustic information interact. We find that models do not simply replicate term-specific gender associations from training data, but learn broader patterns of masculine prevalence. While the ILM exhibits strong masculine bias, models can override these preferences based on acoustic input. Using contrastive feature attribution on spectrograms, we reveal that the model with higher gender accuracy relies on a previously unknown mechanism: using first-person pronouns to link gendered terms back to the speaker, accessing gender information distributed across the frequency spectrum rather than concentrated in pitch.

