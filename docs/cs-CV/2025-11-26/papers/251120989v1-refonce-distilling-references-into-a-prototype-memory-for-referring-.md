---
layout: default
title: RefOnce: Distilling References into a Prototype Memory for Referring Camouflaged Object Detection
---

# RefOnce: Distilling References into a Prototype Memory for Referring Camouflaged Object Detection

**arXiv**: [2511.20989v1](https://arxiv.org/abs/2511.20989) | [PDF](https://arxiv.org/pdf/2511.20989.pdf)

**ä½œè€…**: Yu-Huan Wu, Zi-Xuan Zhu, Yan Wang, Liangli Zhen, Deng-Ping Fan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRefOnceæ¡†æž¶ï¼Œé€šè¿‡è’¸é¦å‚è€ƒå›¾åƒåˆ°åŽŸåž‹å†…å­˜ï¼Œå®žçŽ°æ— æµ‹è¯•æ—¶å‚è€ƒçš„ä¼ªè£…ç›®æ ‡æ£€æµ‹ã€‚**

**å…³é”®è¯**: `ä¼ªè£…ç›®æ ‡æ£€æµ‹` `åŽŸåž‹è’¸é¦` `å‚è€ƒå›¾åƒ` `åŒå‘æ³¨æ„åŠ›å¯¹é½` `æ— æµ‹è¯•å‚è€ƒ` `ç±»åˆ«åŽŸåž‹å†…å­˜`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰Ref-CODç³»ç»Ÿéœ€æµ‹è¯•æ—¶å‚è€ƒå›¾åƒï¼Œå¯¼è‡´éƒ¨ç½²å›°éš¾å’Œå»¶è¿Ÿã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®­ç»ƒæ—¶è’¸é¦å‚è€ƒåˆ°ç±»åˆ«åŽŸåž‹ï¼ŒæŽ¨ç†æ—¶é€šè¿‡æŸ¥è¯¢æ¡ä»¶æ··åˆç”Ÿæˆå‚è€ƒå‘é‡ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨R2C7KåŸºå‡†ä¸Šè¡¨çŽ°ç«žäº‰æˆ–ä¼˜äºŽæœ€æ–°æ–¹æ³•ï¼Œä»£ç å·²å¼€æºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Referring Camouflaged Object Detection (Ref-COD) segments specified camouflaged objects in a scene by leveraging a small set of referring images. Though effective, current systems adopt a dual-branch design that requires reference images at test time, which limits deployability and adds latency and data-collection burden. We introduce a Ref-COD framework that distills references into a class-prototype memory during training and synthesizes a reference vector at inference via a query-conditioned mixture of prototypes. Concretely, we maintain an EMA-updated prototype per category and predict mixture weights from the query to produce a guidance vector without any test-time references. To bridge the representation gap between reference statistics and camouflaged query features, we propose a bidirectional attention alignment module that adapts both the query features and the class representation. Thus, our approach yields a simple, efficient path to Ref-COD without mandatory references. We evaluate the proposed method on the large-scale R2C7K benchmark. Extensive experiments demonstrate competitive or superior performance of the proposed method compared with recent state-of-the-arts. Code is available at https://github.com/yuhuan-wu/RefOnce.

