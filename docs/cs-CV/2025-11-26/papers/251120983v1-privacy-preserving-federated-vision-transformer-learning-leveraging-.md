---
layout: default
title: Privacy-Preserving Federated Vision Transformer Learning Leveraging Lightweight Homomorphic Encryption in Medical AI
---

# Privacy-Preserving Federated Vision Transformer Learning Leveraging Lightweight Homomorphic Encryption in Medical AI

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.20983" target="_blank" class="toolbar-btn">arXiv: 2511.20983v1</a>
    <a href="https://arxiv.org/pdf/2511.20983.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.20983v1" 
            onclick="toggleFavorite(this, '2511.20983v1', 'Privacy-Preserving Federated Vision Transformer Learning Leveraging Lightweight Homomorphic Encryption in Medical AI')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Al Amin, Kamrul Hasan, Liang Hong, Sharif Ullah

**ÂàÜÁ±ª**: cs.CV, cs.CR

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-26

**Â§áÊ≥®**: 7 pages, 4 figures

**ÊúüÂàä**: IEEE ICNC2026

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂêåÊÄÅÂä†ÂØÜÁöÑËÅîÈÇ¶Vision TransformerÂ≠¶‰π†Ê°ÜÊû∂Ôºå‰øùÊä§ÂåªÁñóAI‰∏≠ÁöÑÊÇ£ËÄÖÈöêÁßÅ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫îÔºö‰∫§‰∫í‰∏éÂèçÂ∫î (Interaction & Reaction)**

**ÂÖ≥ÈîÆËØç**: `ËÅîÈÇ¶Â≠¶‰π†` `ÂêåÊÄÅÂä†ÂØÜ` `Vision Transformer` `ÈöêÁßÅ‰øùÊä§` `ÂåªÁñóAI` `ÁªÑÁªáÁóÖÁêÜÂ≠¶` `Ê®°ÂûãÂèçÊºîÊîªÂáª`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰º†ÁªüËÅîÈÇ¶Â≠¶‰π†‰∏≠ÁöÑÊ®°ÂûãÊ¢ØÂ∫¶ÊòìÂèóÈáçÂª∫ÊîªÂáªÔºåÂèØËÉΩÊö¥Èú≤ÊïèÊÑüÂåªÁñó‰ø°ÊÅØÔºåHIPAAÁ≠âÊ≥ïËßÑÁ¶ÅÊ≠¢Áõ¥Êé•ÂÖ±‰∫´ÊÇ£ËÄÖÊï∞ÊçÆ„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßçÁªìÂêàVision Transformers (ViT) ÂíåÂêåÊÄÅÂä†ÂØÜ (HE) ÁöÑËÅîÈÇ¶Â≠¶‰π†Ê°ÜÊû∂Ôºå‰øùÊä§Â§öÊú∫ÊûÑÁªÑÁªáÁóÖÁêÜÂ≠¶ÂàÜÁ±ª‰∏≠ÁöÑÈöêÁßÅ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®‰øùËØÅÈöêÁßÅÁöÑÂêåÊó∂ÔºåÂÆûÁé∞‰∫ÜÈÄö‰ø°ÈáèÁöÑÊòæËëóÂáèÂ∞ëÔºåÂπ∂Âú®Âä†ÂØÜÂüüÂíåÊú™Âä†ÂØÜÂüüÂùáÂèñÂæó‰∫ÜËæÉÈ´òÁöÑÂàÜÁ±ªÁ≤æÂ∫¶„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßç‰øùÊä§ÈöêÁßÅÁöÑËÅîÈÇ¶Â≠¶‰π†Ê°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂ÁªìÂêà‰∫ÜVision Transformers (ViT) ÂíåÂêåÊÄÅÂä†ÂØÜ (HE)ÔºåÁî®‰∫éÂÆâÂÖ®ÁöÑÂ§öÊú∫ÊûÑÁªÑÁªáÁóÖÁêÜÂ≠¶ÂàÜÁ±ª„ÄÇËØ•ÊñπÊ≥ïÂà©Áî®ViTÁöÑCLS token‰Ωú‰∏∫Á¥ßÂáëÁöÑ768Áª¥ÁâπÂæÅË°®Á§∫ÔºåÁî®‰∫éÂÆâÂÖ®ËÅöÂêàÔºåÂπ∂Âú®‰º†ËæìÂà∞ÊúçÂä°Âô®‰πãÂâç‰ΩøÁî®CKKSÂêåÊÄÅÂä†ÂØÜÂØπËøô‰∫õtokenËøõË°åÂä†ÂØÜ„ÄÇÂÆûÈ™åË°®ÊòéÔºå‰∏éÊ¢ØÂ∫¶Âä†ÂØÜÁõ∏ÊØîÔºåÂä†ÂØÜCLS tokenÂÆûÁé∞‰∫Ü30ÂÄçÁöÑÈÄö‰ø°ÂáèÂ∞ëÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÂº∫Â§ßÁöÑÈöêÁßÅ‰øùËØÅ„ÄÇÂú®ËÇ∫ÁôåÁªÑÁªáÁóÖÁêÜÂ≠¶ÂàÜÁ±ªÁöÑ‰∏âÂÆ¢Êà∑Á´ØËÅîÈÇ¶ËÆæÁΩÆ‰∏≠ÔºåÊ¢ØÂ∫¶ÈùûÂ∏∏ÂÆπÊòìÂèóÂà∞Ê®°ÂûãÂèçÊºîÊîªÂáªÔºàPSNRÔºö52.26 dBÔºåSSIMÔºö0.999ÔºåNMIÔºö0.741ÔºâÔºå‰ªéËÄåÂèØ‰ª•ÂÆûÁé∞Ëøë‰πéÂÆåÁæéÁöÑÂõæÂÉèÈáçÂª∫„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÊâÄÊèêÂá∫ÁöÑCLS‰øùÊä§ÁöÑHEÊñπÊ≥ïÂèØ‰ª•Èò≤Ê≠¢Ê≠§Á±ªÊîªÂáªÔºåÂêåÊó∂ÂèØ‰ª•Áõ¥Êé•Âú®ÂØÜÊñá‰∏äËøõË°åÂä†ÂØÜÊé®ÁêÜÔºåÊØèÊ¨°ËÅöÂêàËΩÆÊ¨°‰ªÖÈúÄË¶Å326 KBÁöÑÂä†ÂØÜÊï∞ÊçÆ‰º†Ëæì„ÄÇËØ•Ê°ÜÊû∂Âú®Êú™Âä†ÂØÜÂüü‰∏≠ÂÆûÁé∞‰∫Ü96.12ÔºÖÁöÑÂÖ®Â±ÄÂàÜÁ±ªÁ≤æÂ∫¶ÔºåÂú®Âä†ÂØÜÂüü‰∏≠ÂÆûÁé∞‰∫Ü90.02ÔºÖÁöÑÂÖ®Â±ÄÂàÜÁ±ªÁ≤æÂ∫¶„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Âú®ÂåªÁñóAIÈ¢ÜÂüüÔºåÂà©Áî®ËÅîÈÇ¶Â≠¶‰π†ËøõË°åÂ§öÊú∫ÊûÑÂçè‰ΩúËÆ≠ÁªÉÊó∂ÔºåÂ¶Ç‰Ωï‰øùÊä§ÊÇ£ËÄÖÈöêÁßÅÁöÑÈóÆÈ¢ò„ÄÇ‰º†ÁªüÁöÑËÅîÈÇ¶Â≠¶‰π†ËôΩÁÑ∂ÈÅøÂÖç‰∫ÜÁõ¥Êé•ÂÖ±‰∫´ÂéüÂßãÊï∞ÊçÆÔºå‰ΩÜÊ®°ÂûãÊ¢ØÂ∫¶‰ªçÁÑ∂Â≠òÂú®Ë¢´ÊîªÂáªËÄÖÂà©Áî®ËøõË°åÊï∞ÊçÆÈáçÂª∫ÁöÑÈ£éÈô©ÔºåËøô‰ΩøÂæóÂú®ÂåªÁñóÂú∫ÊôØ‰∏ãÁöÑÂ∫îÁî®ÂèóÂà∞ÈôêÂà∂„ÄÇÁé∞ÊúâÊñπÊ≥ïÁöÑÁóõÁÇπÂú®‰∫éÔºåÂ¶Ç‰ΩïÂú®‰øùËØÅÊ®°ÂûãÊÄßËÉΩÁöÑÂêåÊó∂ÔºåÊèê‰æõÊõ¥Âº∫ÁöÑÈöêÁßÅ‰øùÊä§„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Vision Transformer (ViT) ÁöÑCLS token‰Ωú‰∏∫‰∏ÄÁßçÁ¥ßÂáëÁöÑÁâπÂæÅË°®Á§∫ÔºåÂπ∂‰ΩøÁî®ÂêåÊÄÅÂä†ÂØÜ (HE) ÂØπÂÖ∂ËøõË°åÂä†ÂØÜÔºå‰ªéËÄåÂú®ËÅîÈÇ¶Â≠¶‰π†ËøáÁ®ã‰∏≠‰øùÊä§ÈöêÁßÅ„ÄÇCLS tokenÂåÖÂê´‰∫ÜÂõæÂÉèÁöÑÂÖ®Â±Ä‰ø°ÊÅØÔºåÂêåÊó∂Áª¥Â∫¶ËæÉ‰ΩéÔºåÈÄÇÂêàËøõË°åÂä†ÂØÜ„ÄÇÈÄöËøáÂØπCLS tokenËøõË°åÂêåÊÄÅÂä†ÂØÜÔºåÂèØ‰ª•Âú®ÊúçÂä°Âô®Á´ØËøõË°åÂä†ÂØÜÊï∞ÊçÆÁöÑËÅöÂêàÂíåËÆ°ÁÆóÔºåËÄåÊó†ÈúÄËß£ÂØÜÔºå‰ªéËÄåÈò≤Ê≠¢‰∫ÜÊ¢ØÂ∫¶Ê≥ÑÈú≤„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) ÂÆ¢Êà∑Á´Ø‰ΩøÁî®Êú¨Âú∞Êï∞ÊçÆËÆ≠ÁªÉViTÊ®°ÂûãÔºåÊèêÂèñCLS tokenÔºõ2) ÂÆ¢Êà∑Á´Ø‰ΩøÁî®CKKSÂêåÊÄÅÂä†ÂØÜÁÆóÊ≥ïÂØπCLS tokenËøõË°åÂä†ÂØÜÔºõ3) ÂÆ¢Êà∑Á´ØÂ∞ÜÂä†ÂØÜÂêéÁöÑCLS tokenÂèëÈÄÅÂà∞ÊúçÂä°Âô®Ôºõ4) ÊúçÂä°Âô®ÂØπÂä†ÂØÜÁöÑCLS tokenËøõË°åËÅöÂêàÔºõ5) ÊúçÂä°Âô®Â∞ÜËÅöÂêàÂêéÁöÑÂä†ÂØÜCLS tokenÂèëÈÄÅÂõûÂÆ¢Êà∑Á´ØÔºõ6) ÂÆ¢Êà∑Á´ØÂØπÂä†ÂØÜÁöÑCLS tokenËøõË°åËß£ÂØÜÔºåÂπ∂Êõ¥Êñ∞Êú¨Âú∞Ê®°Âûã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÔºåÂ∞ÜViTÁöÑCLS token‰∏éÂêåÊÄÅÂä†ÂØÜÁõ∏ÁªìÂêàÔºåÁî®‰∫éËÅîÈÇ¶Â≠¶‰π†‰∏≠ÁöÑÈöêÁßÅ‰øùÊä§„ÄÇ‰∏éÁõ¥Êé•Âä†ÂØÜÊ¢ØÂ∫¶Áõ∏ÊØîÔºåÂä†ÂØÜCLS tokenÂèØ‰ª•ÊòæËëóÂáèÂ∞ëÈÄö‰ø°ÈáèÔºåÂêåÊó∂‰øùÊåÅËæÉÂº∫ÁöÑÈöêÁßÅ‰øùÊä§ËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÊîØÊåÅÂú®Âä†ÂØÜÂüüËøõË°åÊé®ÁêÜÔºåËøõ‰∏ÄÊ≠•Â¢ûÂº∫‰∫ÜÈöêÁßÅÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰ΩøÁî®‰∫ÜCKKSÂêåÊÄÅÂä†ÂØÜÁÆóÊ≥ïÔºåËØ•ÁÆóÊ≥ïÂÖÅËÆ∏Âú®Âä†ÂØÜÊï∞ÊçÆ‰∏äËøõË°åËøë‰ººËÆ°ÁÆó„ÄÇCLS tokenÁöÑÁª¥Â∫¶‰∏∫768Áª¥„ÄÇÂÆûÈ™å‰∏≠‰ΩøÁî®‰∫Ü‰∏â‰∏™ÂÆ¢Êà∑Á´ØËøõË°åËÅîÈÇ¶Â≠¶‰π†„ÄÇÊçüÂ§±ÂáΩÊï∞‰ΩøÁî®‰∫Ü‰∫§ÂèâÁÜµÊçüÂ§±ÂáΩÊï∞„ÄÇViTÊ®°ÂûãÁöÑÂÖ∑‰ΩìÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÊú™Âú®ÊëòË¶Å‰∏≠ËØ¶ÁªÜËØ¥ÊòéÔºåÈúÄË¶ÅÂèÇËÄÉËÆ∫ÊñáÂÖ®Êñá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁõ¥Êé•‰ΩøÁî®Ê¢ØÂ∫¶ËøõË°åËÅîÈÇ¶Â≠¶‰π†ÂÆπÊòìÂèóÂà∞Ê®°ÂûãÂèçÊºîÊîªÂáªÔºåÂõæÂÉèÈáçÂª∫ÊïàÊûúÊé•ËøëÂÆåÁæéÔºàPSNR: 52.26 dB, SSIM: 0.999, NMI: 0.741Ôºâ„ÄÇËÄåÊèêÂá∫ÁöÑCLS‰øùÊä§ÁöÑHEÊñπÊ≥ïÂèØ‰ª•ÊúâÊïàÈò≤Ê≠¢Ê≠§Á±ªÊîªÂáªÔºåÂêåÊó∂ÊØèÊ¨°ËÅöÂêàËΩÆÊ¨°‰ªÖÈúÄ‰º†Ëæì326 KBÁöÑÂä†ÂØÜÊï∞ÊçÆÔºåÂπ∂Âú®Êú™Âä†ÂØÜÂüüÂíåÂä†ÂØÜÂüüÂàÜÂà´ÂÆûÁé∞‰∫Ü96.12%Âíå90.02%ÁöÑÂÖ®Â±ÄÂàÜÁ±ªÁ≤æÂ∫¶„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂåªÁñóÂΩ±ÂÉèÂàÜÊûê„ÄÅÂü∫Âõ†ÁªÑÂ≠¶Á≠âÈ¢ÜÂüüÔºåÂÆûÁé∞Â§öÂÆ∂ÂåªÁñóÊú∫ÊûÑÂú®‰øùÊä§ÊÇ£ËÄÖÈöêÁßÅÁöÑÂâçÊèê‰∏ãËøõË°åÂçè‰ΩúÁ†îÁ©∂ÔºåÊèêÂçáÁñæÁóÖËØäÊñ≠ÂíåÊ≤ªÁñóÊ∞¥Âπ≥„ÄÇËØ•ÊñπÊ≥ïËøòÂèØÊé®ÂπøÂà∞ÂÖ∂‰ªñÂØπÊï∞ÊçÆÈöêÁßÅÊúâËæÉÈ´òË¶ÅÊ±ÇÁöÑËÅîÈÇ¶Â≠¶‰π†Âú∫ÊôØÔºå‰æãÂ¶ÇÈáëËûçÈ£éÊéß„ÄÅÊô∫ËÉΩÂà∂ÈÄ†Á≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Collaborative machine learning across healthcare institutions promises improved diagnostic accuracy by leveraging diverse datasets, yet privacy regulations such as HIPAA prohibit direct patient data sharing. While federated learning (FL) enables decentralized training without raw data exchange, recent studies show that model gradients in conventional FL remain vulnerable to reconstruction attacks, potentially exposing sensitive medical information. This paper presents a privacy-preserving federated learning framework combining Vision Transformers (ViT) with homomorphic encryption (HE) for secure multi-institutional histopathology classification. The approach leverages the ViT CLS token as a compact 768-dimensional feature representation for secure aggregation, encrypting these tokens using CKKS homomorphic encryption before transmission to the server. We demonstrate that encrypting CLS tokens achieves a 30-fold communication reduction compared to gradient encryption while maintaining strong privacy guarantees. Through evaluation on a three-client federated setup for lung cancer histopathology classification, we show that gradients are highly susceptible to model inversion attacks (PSNR: 52.26 dB, SSIM: 0.999, NMI: 0.741), enabling near-perfect image reconstruction. In contrast, the proposed CLS-protected HE approach prevents such attacks while enabling encrypted inference directly on ciphertexts, requiring only 326 KB of encrypted data transmission per aggregation round. The framework achieves 96.12 percent global classification accuracy in the unencrypted domain and 90.02 percent in the encrypted domain.

