---
layout: default
title: Privacy-Preserving Federated Vision Transformer Learning Leveraging Lightweight Homomorphic Encryption in Medical AI
---

# Privacy-Preserving Federated Vision Transformer Learning Leveraging Lightweight Homomorphic Encryption in Medical AI

**arXiv**: [2511.20983v1](https://arxiv.org/abs/2511.20983) | [PDF](https://arxiv.org/pdf/2511.20983.pdf)

**ä½œè€…**: Al Amin, Kamrul Hasan, Liang Hong, Sharif Ullah

**åˆ†ç±»**: cs.CV, cs.CR

**å‘å¸ƒæ—¥æœŸ**: 2025-11-26

**å¤‡æ³¨**: 7 pages, 4 figures

**æœŸåˆŠ**: IEEE ICNC2026

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽåŒæ€åŠ å¯†çš„è”é‚¦Vision Transformerå­¦ä¹ æ¡†æž¶ï¼Œä¿æŠ¤åŒ»ç–—AIä¸­çš„æ‚£è€…éšç§ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸Žååº” (Interaction & Reaction)**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `åŒæ€åŠ å¯†` `Vision Transformer` `éšç§ä¿æŠ¤` `åŒ»ç–—AI` `ç»„ç»‡ç—…ç†å­¦` `æ¨¡åž‹åæ¼”æ”»å‡»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿè”é‚¦å­¦ä¹ ä¸­çš„æ¨¡åž‹æ¢¯åº¦æ˜“å—é‡å»ºæ”»å‡»ï¼Œå¯èƒ½æš´éœ²æ•æ„ŸåŒ»ç–—ä¿¡æ¯ï¼ŒHIPAAç­‰æ³•è§„ç¦æ­¢ç›´æŽ¥å…±äº«æ‚£è€…æ•°æ®ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§ç»“åˆVision Transformers (ViT) å’ŒåŒæ€åŠ å¯† (HE) çš„è”é‚¦å­¦ä¹ æ¡†æž¶ï¼Œä¿æŠ¤å¤šæœºæž„ç»„ç»‡ç—…ç†å­¦åˆ†ç±»ä¸­çš„éšç§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨ä¿è¯éšç§çš„åŒæ—¶ï¼Œå®žçŽ°äº†é€šä¿¡é‡çš„æ˜¾è‘—å‡å°‘ï¼Œå¹¶åœ¨åŠ å¯†åŸŸå’ŒæœªåŠ å¯†åŸŸå‡å–å¾—äº†è¾ƒé«˜çš„åˆ†ç±»ç²¾åº¦ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ä¿æŠ¤éšç§çš„è”é‚¦å­¦ä¹ æ¡†æž¶ï¼Œè¯¥æ¡†æž¶ç»“åˆäº†Vision Transformers (ViT) å’ŒåŒæ€åŠ å¯† (HE)ï¼Œç”¨äºŽå®‰å…¨çš„å¤šæœºæž„ç»„ç»‡ç—…ç†å­¦åˆ†ç±»ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ViTçš„CLS tokenä½œä¸ºç´§å‡‘çš„768ç»´ç‰¹å¾è¡¨ç¤ºï¼Œç”¨äºŽå®‰å…¨èšåˆï¼Œå¹¶åœ¨ä¼ è¾“åˆ°æœåŠ¡å™¨ä¹‹å‰ä½¿ç”¨CKKSåŒæ€åŠ å¯†å¯¹è¿™äº›tokenè¿›è¡ŒåŠ å¯†ã€‚å®žéªŒè¡¨æ˜Žï¼Œä¸Žæ¢¯åº¦åŠ å¯†ç›¸æ¯”ï¼ŒåŠ å¯†CLS tokenå®žçŽ°äº†30å€çš„é€šä¿¡å‡å°‘ï¼ŒåŒæ—¶ä¿æŒäº†å¼ºå¤§çš„éšç§ä¿è¯ã€‚åœ¨è‚ºç™Œç»„ç»‡ç—…ç†å­¦åˆ†ç±»çš„ä¸‰å®¢æˆ·ç«¯è”é‚¦è®¾ç½®ä¸­ï¼Œæ¢¯åº¦éžå¸¸å®¹æ˜“å—åˆ°æ¨¡åž‹åæ¼”æ”»å‡»ï¼ˆPSNRï¼š52.26 dBï¼ŒSSIMï¼š0.999ï¼ŒNMIï¼š0.741ï¼‰ï¼Œä»Žè€Œå¯ä»¥å®žçŽ°è¿‘ä¹Žå®Œç¾Žçš„å›¾åƒé‡å»ºã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ‰€æå‡ºçš„CLSä¿æŠ¤çš„HEæ–¹æ³•å¯ä»¥é˜²æ­¢æ­¤ç±»æ”»å‡»ï¼ŒåŒæ—¶å¯ä»¥ç›´æŽ¥åœ¨å¯†æ–‡ä¸Šè¿›è¡ŒåŠ å¯†æŽ¨ç†ï¼Œæ¯æ¬¡èšåˆè½®æ¬¡ä»…éœ€è¦326 KBçš„åŠ å¯†æ•°æ®ä¼ è¾“ã€‚è¯¥æ¡†æž¶åœ¨æœªåŠ å¯†åŸŸä¸­å®žçŽ°äº†96.12ï¼…çš„å…¨å±€åˆ†ç±»ç²¾åº¦ï¼Œåœ¨åŠ å¯†åŸŸä¸­å®žçŽ°äº†90.02ï¼…çš„å…¨å±€åˆ†ç±»ç²¾åº¦ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨åŒ»ç–—AIé¢†åŸŸï¼Œåˆ©ç”¨è”é‚¦å­¦ä¹ è¿›è¡Œå¤šæœºæž„åä½œè®­ç»ƒæ—¶ï¼Œå¦‚ä½•ä¿æŠ¤æ‚£è€…éšç§çš„é—®é¢˜ã€‚ä¼ ç»Ÿçš„è”é‚¦å­¦ä¹ è™½ç„¶é¿å…äº†ç›´æŽ¥å…±äº«åŽŸå§‹æ•°æ®ï¼Œä½†æ¨¡åž‹æ¢¯åº¦ä»ç„¶å­˜åœ¨è¢«æ”»å‡»è€…åˆ©ç”¨è¿›è¡Œæ•°æ®é‡å»ºçš„é£Žé™©ï¼Œè¿™ä½¿å¾—åœ¨åŒ»ç–—åœºæ™¯ä¸‹çš„åº”ç”¨å—åˆ°é™åˆ¶ã€‚çŽ°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºŽï¼Œå¦‚ä½•åœ¨ä¿è¯æ¨¡åž‹æ€§èƒ½çš„åŒæ—¶ï¼Œæä¾›æ›´å¼ºçš„éšç§ä¿æŠ¤ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Vision Transformer (ViT) çš„CLS tokenä½œä¸ºä¸€ç§ç´§å‡‘çš„ç‰¹å¾è¡¨ç¤ºï¼Œå¹¶ä½¿ç”¨åŒæ€åŠ å¯† (HE) å¯¹å…¶è¿›è¡ŒåŠ å¯†ï¼Œä»Žè€Œåœ¨è”é‚¦å­¦ä¹ è¿‡ç¨‹ä¸­ä¿æŠ¤éšç§ã€‚CLS tokenåŒ…å«äº†å›¾åƒçš„å…¨å±€ä¿¡æ¯ï¼ŒåŒæ—¶ç»´åº¦è¾ƒä½Žï¼Œé€‚åˆè¿›è¡ŒåŠ å¯†ã€‚é€šè¿‡å¯¹CLS tokenè¿›è¡ŒåŒæ€åŠ å¯†ï¼Œå¯ä»¥åœ¨æœåŠ¡å™¨ç«¯è¿›è¡ŒåŠ å¯†æ•°æ®çš„èšåˆå’Œè®¡ç®—ï¼Œè€Œæ— éœ€è§£å¯†ï¼Œä»Žè€Œé˜²æ­¢äº†æ¢¯åº¦æ³„éœ²ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) å®¢æˆ·ç«¯ä½¿ç”¨æœ¬åœ°æ•°æ®è®­ç»ƒViTæ¨¡åž‹ï¼Œæå–CLS tokenï¼›2) å®¢æˆ·ç«¯ä½¿ç”¨CKKSåŒæ€åŠ å¯†ç®—æ³•å¯¹CLS tokenè¿›è¡ŒåŠ å¯†ï¼›3) å®¢æˆ·ç«¯å°†åŠ å¯†åŽçš„CLS tokenå‘é€åˆ°æœåŠ¡å™¨ï¼›4) æœåŠ¡å™¨å¯¹åŠ å¯†çš„CLS tokenè¿›è¡Œèšåˆï¼›5) æœåŠ¡å™¨å°†èšåˆåŽçš„åŠ å¯†CLS tokenå‘é€å›žå®¢æˆ·ç«¯ï¼›6) å®¢æˆ·ç«¯å¯¹åŠ å¯†çš„CLS tokenè¿›è¡Œè§£å¯†ï¼Œå¹¶æ›´æ–°æœ¬åœ°æ¨¡åž‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽï¼Œå°†ViTçš„CLS tokenä¸ŽåŒæ€åŠ å¯†ç›¸ç»“åˆï¼Œç”¨äºŽè”é‚¦å­¦ä¹ ä¸­çš„éšç§ä¿æŠ¤ã€‚ä¸Žç›´æŽ¥åŠ å¯†æ¢¯åº¦ç›¸æ¯”ï¼ŒåŠ å¯†CLS tokenå¯ä»¥æ˜¾è‘—å‡å°‘é€šä¿¡é‡ï¼ŒåŒæ—¶ä¿æŒè¾ƒå¼ºçš„éšç§ä¿æŠ¤èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•æ”¯æŒåœ¨åŠ å¯†åŸŸè¿›è¡ŒæŽ¨ç†ï¼Œè¿›ä¸€æ­¥å¢žå¼ºäº†éšç§æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä½¿ç”¨äº†CKKSåŒæ€åŠ å¯†ç®—æ³•ï¼Œè¯¥ç®—æ³•å…è®¸åœ¨åŠ å¯†æ•°æ®ä¸Šè¿›è¡Œè¿‘ä¼¼è®¡ç®—ã€‚CLS tokençš„ç»´åº¦ä¸º768ç»´ã€‚å®žéªŒä¸­ä½¿ç”¨äº†ä¸‰ä¸ªå®¢æˆ·ç«¯è¿›è¡Œè”é‚¦å­¦ä¹ ã€‚æŸå¤±å‡½æ•°ä½¿ç”¨äº†äº¤å‰ç†µæŸå¤±å‡½æ•°ã€‚ViTæ¨¡åž‹çš„å…·ä½“ç»“æž„å’Œå‚æ•°è®¾ç½®æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜Žï¼Œéœ€è¦å‚è€ƒè®ºæ–‡å…¨æ–‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œç›´æŽ¥ä½¿ç”¨æ¢¯åº¦è¿›è¡Œè”é‚¦å­¦ä¹ å®¹æ˜“å—åˆ°æ¨¡åž‹åæ¼”æ”»å‡»ï¼Œå›¾åƒé‡å»ºæ•ˆæžœæŽ¥è¿‘å®Œç¾Žï¼ˆPSNR: 52.26 dB, SSIM: 0.999, NMI: 0.741ï¼‰ã€‚è€Œæå‡ºçš„CLSä¿æŠ¤çš„HEæ–¹æ³•å¯ä»¥æœ‰æ•ˆé˜²æ­¢æ­¤ç±»æ”»å‡»ï¼ŒåŒæ—¶æ¯æ¬¡èšåˆè½®æ¬¡ä»…éœ€ä¼ è¾“326 KBçš„åŠ å¯†æ•°æ®ï¼Œå¹¶åœ¨æœªåŠ å¯†åŸŸå’ŒåŠ å¯†åŸŸåˆ†åˆ«å®žçŽ°äº†96.12%å’Œ90.02%çš„å…¨å±€åˆ†ç±»ç²¾åº¦ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽåŒ»ç–—å½±åƒåˆ†æžã€åŸºå› ç»„å­¦ç­‰é¢†åŸŸï¼Œå®žçŽ°å¤šå®¶åŒ»ç–—æœºæž„åœ¨ä¿æŠ¤æ‚£è€…éšç§çš„å‰æä¸‹è¿›è¡Œåä½œç ”ç©¶ï¼Œæå‡ç–¾ç—…è¯Šæ–­å’Œæ²»ç–—æ°´å¹³ã€‚è¯¥æ–¹æ³•è¿˜å¯æŽ¨å¹¿åˆ°å…¶ä»–å¯¹æ•°æ®éšç§æœ‰è¾ƒé«˜è¦æ±‚çš„è”é‚¦å­¦ä¹ åœºæ™¯ï¼Œä¾‹å¦‚é‡‘èžé£ŽæŽ§ã€æ™ºèƒ½åˆ¶é€ ç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Collaborative machine learning across healthcare institutions promises improved diagnostic accuracy by leveraging diverse datasets, yet privacy regulations such as HIPAA prohibit direct patient data sharing. While federated learning (FL) enables decentralized training without raw data exchange, recent studies show that model gradients in conventional FL remain vulnerable to reconstruction attacks, potentially exposing sensitive medical information. This paper presents a privacy-preserving federated learning framework combining Vision Transformers (ViT) with homomorphic encryption (HE) for secure multi-institutional histopathology classification. The approach leverages the ViT CLS token as a compact 768-dimensional feature representation for secure aggregation, encrypting these tokens using CKKS homomorphic encryption before transmission to the server. We demonstrate that encrypting CLS tokens achieves a 30-fold communication reduction compared to gradient encryption while maintaining strong privacy guarantees. Through evaluation on a three-client federated setup for lung cancer histopathology classification, we show that gradients are highly susceptible to model inversion attacks (PSNR: 52.26 dB, SSIM: 0.999, NMI: 0.741), enabling near-perfect image reconstruction. In contrast, the proposed CLS-protected HE approach prevents such attacks while enabling encrypted inference directly on ciphertexts, requiring only 326 KB of encrypted data transmission per aggregation round. The framework achieves 96.12 percent global classification accuracy in the unencrypted domain and 90.02 percent in the encrypted domain.

