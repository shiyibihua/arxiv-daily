---
layout: default
title: Endo-G$^{2}$T: Geometry-Guided & Temporally Aware Time-Embedded 4DGS For Endoscopic Scenes
---

# Endo-G$^{2}$T: Geometry-Guided & Temporally Aware Time-Embedded 4DGS For Endoscopic Scenes

**arXiv**: [2511.21367v1](https://arxiv.org/abs/2511.21367) | [PDF](https://arxiv.org/pdf/2511.21367.pdf)

**ä½œè€…**: Yangle Liu, Fengze Li, Kan Liu, Jieming Ma

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEndo-GÂ²Tæ–¹æ³•ä»¥è§£å†³å†…çª¥é•œåœºæ™¯ä¸­å‡ ä½•æ¼‚ç§»ä¸Žæ—¶é—´ä¸€è‡´æ€§é—®é¢˜**

**å…³é”®è¯**: `4Dé«˜æ–¯æº…å°„` `å‡ ä½•å¼•å¯¼è®­ç»ƒ` `æ—¶é—´ä¸€è‡´æ€§` `å†…çª¥é•œé‡å»º` `å•ç›®æ·±åº¦ä¼°è®¡` `å…³é”®å¸§ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å†…çª¥é•œè§†é¢‘å­˜åœ¨å¼ºè§†è§’ä¾èµ–æ•ˆåº”ï¼Œçº¯å…‰åº¦ç›‘ç£æ˜“å¯¼è‡´å‡ ä½•æ¼‚ç§»
2. é‡‡ç”¨å‡ ä½•å¼•å¯¼å…ˆéªŒè’¸é¦å’Œæ—¶é—´åµŒå…¥é«˜æ–¯åœºï¼Œæå‡å‡ ä½•å‡†ç¡®æ€§ä¸Žæ—¶é—´ä¸€è‡´æ€§
3. åœ¨EndoNeRFå’ŒStereoMIS-P1æ•°æ®é›†ä¸Šå®žçŽ°å•ç›®é‡å»ºæœ€ä¼˜ç»“æžœ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Endoscopic (endo) video exhibits strong view-dependent effects such as specularities, wet reflections, and occlusions. Pure photometric supervision misaligns with geometry and triggers early geometric drift, where erroneous shapes are reinforced during densification and become hard to correct. We ask how to anchor geometry early for 4D Gaussian splatting (4DGS) while maintaining temporal consistency and efficiency in dynamic endoscopic scenes. Thus, we present Endo-G$^{2}$T, a geometry-guided and temporally aware training scheme for time-embedded 4DGS. First, geo-guided prior distillation converts confidence-gated monocular depth into supervision with scale-invariant depth and depth-gradient losses, using a warm-up-to-cap schedule to inject priors softly and avoid early overfitting. Second, a time-embedded Gaussian field represents dynamics in XYZT with a rotor-like rotation parameterization, yielding temporally coherent geometry with lightweight regularization that favors smooth motion and crisp opacity boundaries. Third, keyframe-constrained streaming improves efficiency and long-horizon stability through keyframe-focused optimization under a max-points budget, while non-keyframes advance with lightweight updates. Across EndoNeRF and StereoMIS-P1 datasets, Endo-G$^{2}$T achieves state-of-the-art results among monocular reconstruction baselines.

