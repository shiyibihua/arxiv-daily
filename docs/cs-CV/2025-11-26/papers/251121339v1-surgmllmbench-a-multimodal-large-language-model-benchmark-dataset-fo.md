---
layout: default
title: SurgMLLMBench: A Multimodal Large Language Model Benchmark Dataset for Surgical Scene Understanding
---

# SurgMLLMBench: A Multimodal Large Language Model Benchmark Dataset for Surgical Scene Understanding

**arXiv**: [2511.21339v1](https://arxiv.org/abs/2511.21339) | [PDF](https://arxiv.org/pdf/2511.21339.pdf)

**ä½œè€…**: Tae-Min Choi, Tae Kyeong Jeong, Garam Kim, Jaemin Lee, Yeongyoon Koh, In Cheul Choi, Jae-Ho Chung, Jong Woong Park, Juyoun Park

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSurgMLLMBenchåŸºå‡†ä»¥è§£å†³æ‰‹æœ¯åœºæ™¯ç†è§£ä¸­å¤šæ¨¡æ€LLMè¯„ä¼°ä¸ä¸€è‡´é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `æ‰‹æœ¯åœºæ™¯ç†è§£` `åƒç´ çº§åˆ†å‰²` `è§†è§‰é—®ç­”åŸºå‡†` `è·¨åŸŸæ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ‰‹æœ¯æ•°æ®é›†å¤šä¸ºVQAæ ¼å¼ï¼Œåˆ†ç±»ä¸ç»Ÿä¸€ä¸”ç¼ºä¹åƒç´ çº§åˆ†å‰²ï¼Œé™åˆ¶å¤šæ¨¡æ€LLMè¯„ä¼°
2. é›†æˆåƒç´ çº§åˆ†å‰²æŽ©ç å’Œç»“æž„åŒ–VQAæ³¨é‡Šï¼Œè¦†ç›–è…¹è…”é•œã€æœºå™¨äººè¾…åŠ©å’Œæ˜¾å¾®æ‰‹æœ¯é¢†åŸŸ
3. å®žéªŒæ˜¾ç¤ºå•ä¸€æ¨¡åž‹åœ¨è·¨åŸŸè¯„ä¼°ä¸­è¡¨çŽ°ä¸€è‡´ï¼Œå¹¶èƒ½æ³›åŒ–åˆ°æœªçŸ¥æ•°æ®é›†

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in multimodal large language models (LLMs) have highlighted their potential for medical and surgical applications. However, existing surgical datasets predominantly adopt a Visual Question Answering (VQA) format with heterogeneous taxonomies and lack support for pixel-level segmentation, limiting consistent evaluation and applicability. We present SurgMLLMBench, a unified multimodal benchmark explicitly designed for developing and evaluating interactive multimodal LLMs for surgical scene understanding, including the newly collected Micro-surgical Artificial Vascular anastomosIS (MAVIS) dataset. It integrates pixel-level instrument segmentation masks and structured VQA annotations across laparoscopic, robot-assisted, and micro-surgical domains under a unified taxonomy, enabling comprehensive evaluation beyond traditional VQA tasks and richer visual-conversational interactions. Extensive baseline experiments show that a single model trained on SurgMLLMBench achieves consistent performance across domains and generalizes effectively to unseen datasets. SurgMLLMBench will be publicly released as a robust resource to advance multimodal surgical AI research, supporting reproducible evaluation and development of interactive surgical reasoning models.

