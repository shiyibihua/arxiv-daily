---
layout: default
title: Do Reasoning Vision-Language Models Inversely Scale in Test-Time Compute? A Distractor-centric Empirical Analysis
---

# Do Reasoning Vision-Language Models Inversely Scale in Test-Time Compute? A Distractor-centric Empirical Analysis

**arXiv**: [2511.21397v1](https://arxiv.org/abs/2511.21397) | [PDF](https://arxiv.org/pdf/2511.21397.pdf)

**ä½œè€…**: Jiyun Bae, Hyunjong Ok, Sangwoo Mo, Jaeho Lee

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIdisæ•°æ®é›†åˆ†æžè§†è§‰å¹²æ‰°ç‰©å¯¹å¤šæ¨¡æ€æŽ¨ç†æ¨¡åž‹çš„å½±å“ï¼Œæ­ç¤ºé€†ç¼©æ”¾çŽ°è±¡ã€‚**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡åž‹` `å¹²æ‰°ç‰©åˆ†æž` `é€†ç¼©æ”¾çŽ°è±¡` `è§†è§‰é—®ç­”æ•°æ®é›†` `æŽ¨ç†é•¿åº¦` `åè§ç¼“è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§‰å¹²æ‰°ç‰©å¦‚ä½•å½±å“å¤šæ¨¡æ€æ¨¡åž‹åœ¨æµ‹è¯•æ—¶çš„æŽ¨ç†ç¼©æ”¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºIdisæ•°æ®é›†ï¼Œç³»ç»Ÿå˜åŒ–è¯­ä¹‰ã€æ•°å€¼å’Œç©ºé—´ç»´åº¦çš„å¹²æ‰°ç‰©ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè§†è§‰å¹²æ‰°ç‰©é™ä½Žå‡†ç¡®çŽ‡ä½†ä¸å¢žåŠ æŽ¨ç†é•¿åº¦ï¼Œæå‡ºæç¤ºç­–ç•¥ç¼“è§£åè§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> How does irrelevant information (i.e., distractors) affect test-time scaling in vision-language models (VLMs)? Prior studies on language models have reported an inverse scaling effect, where textual distractors lead to longer but less effective reasoning. To investigate whether similar phenomena occur in multimodal settings, we introduce Idis (Images with distractors), a visual question-answering dataset that systematically varies distractors along semantic, numerical, and spatial dimensions. Our analyses reveal that visual distractors differ fundamentally from textual ones: although inverse scaling persists, adding visual distractors reduces accuracy without increasing reasoning length. We further show that tracking attribute counts within reasoning traces provides key insights into how distractors, reasoning length, and accuracy interact. Finally, we demonstrate that these trends extend to established visual bias benchmarks such as Waterbirds, and we propose a simple prompting strategy to mitigate bias-driven predictions in reasoning models.

