---
layout: default
title: Generating Separated Singing Vocals Using a Diffusion Model Conditioned on Music Mixtures
---

# Generating Separated Singing Vocals Using a Diffusion Model Conditioned on Music Mixtures

**arXiv**: [2511.21342v1](https://arxiv.org/abs/2511.21342) | [PDF](https://arxiv.org/pdf/2511.21342.pdf)

**ä½œè€…**: GenÃ­s Plaja-Roglans, Yun-Ning Hung, Xavier Serra, Igor Pereira

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæ‰©æ•£æ¨¡åž‹çš„æ­Œå£°åˆ†ç¦»æ–¹æ³•ï¼Œä»¥ä»ŽéŸ³ä¹æ··åˆä¸­ç”Ÿæˆçº¯å‡€äººå£°ã€‚**

**å…³é”®è¯**: `æ­Œå£°åˆ†ç¦»` `æ‰©æ•£æ¨¡åž‹` `æ¡ä»¶ç”Ÿæˆ` `éŸ³ä¹åˆ†æž` `è¿­ä»£é‡‡æ ·`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä»ŽçœŸå®žéŸ³ä¹å½•éŸ³ä¸­åˆ†ç¦»äººå£°ï¼Œæ”¯æŒéŸ³ä¹åˆ†æžå’Œå®žè·µã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ‰©æ•£æ¨¡åž‹ï¼Œä»¥éŸ³ä¹æ··åˆä¸ºæ¡ä»¶ç”Ÿæˆç‹¬å”±äººå£°ï¼Œæå‡çµæ´»æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨è¡¥å……æ•°æ®è®­ç»ƒä¸‹ï¼Œè¾¾åˆ°ä¸Žéžç”ŸæˆåŸºçº¿ç«žäº‰çš„ç›®æ ‡åˆ†æ•°ï¼Œæ”¯æŒè´¨é‡-æ•ˆçŽ‡æƒè¡¡æŽ§åˆ¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Separating the individual elements in a musical mixture is an essential process for music analysis and practice. While this is generally addressed using neural networks optimized to mask or transform the time-frequency representation of a mixture to extract the target sources, the flexibility and generalization capabilities of generative diffusion models are giving rise to a novel class of solutions for this complicated task. In this work, we explore singing voice separation from real music recordings using a diffusion model which is trained to generate the solo vocals conditioned on the corresponding mixture. Our approach improves upon prior generative systems and achieves competitive objective scores against non-generative baselines when trained with supplementary data. The iterative nature of diffusion sampling enables the user to control the quality-efficiency trade-off, and also refine the output when needed. We present an ablation study of the sampling algorithm, highlighting the effects of the user-configurable parameters.

