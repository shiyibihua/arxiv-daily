---
layout: default
title: DiverseVAR: Balancing Diversity and Quality of Next-Scale Visual Autoregressive Models
---

# DiverseVAR: Balancing Diversity and Quality of Next-Scale Visual Autoregressive Models

**arXiv**: [2511.21415v1](https://arxiv.org/abs/2511.21415) | [PDF](https://arxiv.org/pdf/2511.21415.pdf)

**ä½œè€…**: Mingue Park, Prin Phunyaphibarn, Phillip Y. Lee, Minhyuk Sung

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDiverseVARæ¡†æž¶ä»¥è§£å†³è§†è§‰è‡ªå›žå½’æ¨¡åž‹åœ¨æµ‹è¯•æ—¶å¤šæ ·æ€§ä¸è¶³çš„é—®é¢˜**

**å…³é”®è¯**: `è§†è§‰è‡ªå›žå½’æ¨¡åž‹` `å¤šæ ·æ€§å¢žå¼º` `æ–‡æœ¬åµŒå…¥å™ªå£°` `å°ºåº¦æ—…è¡Œç²¾ç‚¼` `å›¾åƒç”Ÿæˆ` `å¤šå°ºåº¦è‡ªç¼–ç å™¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šVARæ¨¡åž‹åœ¨å›¾åƒç”Ÿæˆä¸­å¤šæ ·æ€§ä½Žï¼Œå¸¸å¯¹ç®€å•æç¤ºç”Ÿæˆç›¸ä¼¼å›¾åƒ
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆæ–‡æœ¬åµŒå…¥å™ªå£°æ³¨å…¥å’Œå°ºåº¦æ—…è¡Œæ½œåœ¨ç²¾ç‚¼ï¼Œå¹³è¡¡å¤šæ ·æ€§ä¸Žè´¨é‡
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ˜¾è‘—æå‡å¤šæ ·æ€§ï¼Œæœ€å°åŒ–è´¨é‡æŸå¤±ï¼Œå®žçŽ°å¤šæ ·æ€§-è´¨é‡å¸•ç´¯æ‰˜å‰æ²¿

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce DiverseVAR, a framework that enhances the diversity of text-conditioned visual autoregressive models (VAR) at test time without requiring retraining, fine-tuning, or substantial computational overhead. While VAR models have recently emerged as strong competitors to diffusion and flow models for image generation, they suffer from a critical limitation in diversity, often producing nearly identical images even for simple prompts. This issue has largely gone unnoticed amid the predominant focus on image quality. We address this limitation at test time in two stages. First, inspired by diversity enhancement techniques in diffusion models, we propose injecting noise into the text embedding. This introduces a trade-off between diversity and image quality: as diversity increases, the image quality sharply declines. To preserve quality, we propose scale-travel: a novel latent refinement technique inspired by time-travel strategies in diffusion models. Specifically, we use a multi-scale autoencoder to extract coarse-scale tokens that enable us to resume generation at intermediate stages. Extensive experiments show that combining text-embedding noise injection with our scale-travel refinement significantly enhances diversity while minimizing image-quality degradation, achieving a new Pareto frontier in the diversity-quality trade-off.

