---
layout: default
title: MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning
---

# MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning

**arXiv**: [2511.21460v1](https://arxiv.org/abs/2511.21460) | [PDF](https://arxiv.org/pdf/2511.21460.pdf)

**ä½œè€…**: Junjian Wang, Lidan Zhao, Xi Sheryl Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMADRAå¤šæ™ºèƒ½ä½“è¾©è®ºæ¡†æž¶ä»¥è§£å†³å…·èº«AIä»»åŠ¡è§„åˆ’ä¸­çš„å®‰å…¨é£Žé™©é—®é¢˜**

**å…³é”®è¯**: `å…·èº«AI` `å¤šæ™ºèƒ½ä½“è¾©è®º` `é£Žé™©æ„ŸçŸ¥è§„åˆ’` `å®‰å…¨è¯„ä¼°` `è®­ç»ƒå…è´¹æ¡†æž¶` `åŸºå‡†æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•å­˜åœ¨è®¡ç®—æˆæœ¬é«˜æˆ–è¿‡åº¦æ‹’ç»å®‰å…¨æŒ‡ä»¤çš„é—®é¢˜
2. é‡‡ç”¨å¤šæ™ºèƒ½ä½“è¾©è®ºå’Œå…±è¯†æŠ•ç¥¨ï¼Œæ— éœ€è®­ç»ƒå³å¯æå‡å®‰å…¨è¯„ä¼°
3. åœ¨AI2-THORå’ŒVirtualHomeå®žéªŒä¸­ï¼Œæ‹’ç»90%ä»¥ä¸Šå±é™©ä»»åŠ¡ä¸”å®‰å…¨ä»»åŠ¡æ‹’ç»çŽ‡ä½Ž

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Ensuring the safety of embodied AI agents during task planning is critical for real-world deployment, especially in household environments where dangerous instructions pose significant risks. Existing methods often suffer from either high computational costs due to preference alignment training or over-rejection when using single-agent safety prompts. To address these limitations, we propose MADRA, a training-free Multi-Agent Debate Risk Assessment framework that leverages collective reasoning to enhance safety awareness without sacrificing task performance. MADRA employs multiple LLM-based agents to debate the safety of a given instruction, guided by a critical evaluator that scores responses based on logical soundness, risk identification, evidence quality, and clarity. Through iterative deliberation and consensus voting, MADRA significantly reduces false rejections while maintaining high sensitivity to dangerous tasks. Additionally, we introduce a hierarchical cognitive collaborative planning framework that integrates safety, memory, planning, and self-evolution mechanisms to improve task success rates through continuous learning. We also contribute SafeAware-VH, a benchmark dataset for safety-aware task planning in VirtualHome, containing 800 annotated instructions. Extensive experiments on AI2-THOR and VirtualHome demonstrate that our approach achieves over 90% rejection of unsafe tasks while ensuring that safe-task rejection is low, outperforming existing methods in both safety and execution efficiency. Our work provides a scalable, model-agnostic solution for building trustworthy embodied agents.

