---
layout: default
title: BotaCLIP: Contrastive Learning for Botany-Aware Representation of Earth Observation Data
---

# BotaCLIP: Contrastive Learning for Botany-Aware Representation of Earth Observation Data

**arXiv**: [2511.21194v1](https://arxiv.org/abs/2511.21194) | [PDF](https://arxiv.org/pdf/2511.21194.pdf)

**‰ΩúËÄÖ**: Selene Cerna, Sara Si-Moussi, Wilfried Thuiller, Hadrien Hendrikx, Vincent Miele

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫BotaCLIPÊ°ÜÊû∂ÔºåÈÄöËøáÂØπÊØîÂ≠¶‰π†Â∞ÜÊ§çÁâ©Â≠¶Áü•ËØÜÊ≥®ÂÖ•Âú∞ÁêÉËßÇÊµãÊ®°ÂûãÔºåÊèêÂçáÁîüÊÄÅ‰ªªÂä°ÊÄßËÉΩ„ÄÇ**

**ÂÖ≥ÈîÆËØç**: `ÂØπÊØîÂ≠¶‰π†` `Â§öÊ®°ÊÄÅË°®Á§∫` `Âú∞ÁêÉËßÇÊµãÊï∞ÊçÆ` `Ê§çÁâ©Â≠¶ÈÄÇÂ∫î` `ÁîüÊÄÅÂª∫Ê®°` `ËΩªÈáèÊ°ÜÊû∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Ê†∏ÂøÉÈóÆÈ¢òÔºöÈ¢ÑËÆ≠ÁªÉÂü∫Á°ÄÊ®°ÂûãÁº∫‰πèÈ¢ÜÂüüÁü•ËØÜÔºåÈöæ‰ª•ÈÄÇÂ∫îÁîüÊÄÅÊï∞ÊçÆÁ®ÄÁº∫Âú∫ÊôØ„ÄÇ
2. ÊñπÊ≥ïË¶ÅÁÇπÔºöËΩªÈáèÂ§öÊ®°ÊÄÅÂØπÊØîÊ°ÜÊû∂ÔºåÂØπÈΩêÈ´òÂàÜËæ®ÁéáËà™ÊãçÂõæÂÉè‰∏éÊ§çÁâ©Ë∞ÉÊü•Êï∞ÊçÆÔºåÈò≤Ê≠¢ÁÅæÈöæÊÄßÈÅóÂøò„ÄÇ
3. ÂÆûÈ™åÊïàÊûúÔºöÂú®Ê§çÁâ©Â≠òÂú®È¢ÑÊµãÁ≠â‰ªªÂä°‰∏≠ÔºåÊÄßËÉΩ‰ºò‰∫éDOFAÂíåÁõëÁù£Âü∫Á∫øÊ®°Âûã„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Foundation models have demonstrated a remarkable ability to learn rich, transferable representations across diverse modalities such as images, text, and audio. In modern machine learning pipelines, these representations often replace raw data as the primary input for downstream tasks. In this paper, we address the challenge of adapting a pre-trained foundation model to inject domain-specific knowledge, without retraining from scratch or incurring significant computational costs. To this end, we introduce BotaCLIP, a lightweight multimodal contrastive framework that adapts a pre-trained Earth Observation foundation model (DOFA) by aligning high-resolution aerial imagery with botanical relev√©s. Unlike generic embeddings, BotaCLIP internalizes ecological structure through contrastive learning with a regularization strategy that mitigates catastrophic forgetting. Once trained, the resulting embeddings serve as transferable representations for downstream predictors. Motivated by real-world applications in biodiversity modeling, we evaluated BotaCLIP representations in three ecological tasks: plant presence prediction, butterfly occurrence modeling, and soil trophic group abundance estimation. The results showed consistent improvements over those derived from DOFA and supervised baselines. More broadly, this work illustrates how domain-aware adaptation of foundation models can inject expert knowledge into data-scarce settings, enabling frugal representation learning.

