---
layout: default
title: Canvas-to-Image: Compositional Image Generation with Multimodal Controls
---

# Canvas-to-Image: Compositional Image Generation with Multimodal Controls

**arXiv**: [2511.21691v1](https://arxiv.org/abs/2511.21691) | [PDF](https://arxiv.org/pdf/2511.21691.pdf)

**ä½œè€…**: Yusuf Dalva, Guocheng Gordon Qian, Maya Goldenberg, Tsai-Shien Chen, Kfir Aberman, Sergey Tulyakov, Pinar Yanardag, Kuan-Chieh Jackson Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCanvas-to-Imageæ¡†æž¶ä»¥è§£å†³å¤šæ¨¡æ€æŽ§åˆ¶å›¾åƒç”Ÿæˆä¸­çš„å¿ å®žæ€§é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€æŽ§åˆ¶` `å›¾åƒç”Ÿæˆ` `æ‰©æ•£æ¨¡åž‹` `ç”»å¸ƒç¼–ç ` `å¤šä»»åŠ¡è®­ç»ƒ` `å¿ å®žæ€§è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‰©æ•£æ¨¡åž‹éš¾ä»¥åŒæ—¶å¤„ç†æ–‡æœ¬ã€å‚è€ƒã€ç©ºé—´ç­‰å¤šæ¨¡æ€æŽ§åˆ¶ï¼Œå¯¼è‡´ç”Ÿæˆå›¾åƒä¸å¿ å®ž
2. æ–¹æ³•è¦ç‚¹ï¼šå°†å¼‚è´¨æŽ§åˆ¶ç¼–ç ä¸ºå•ä¸€ç”»å¸ƒå›¾åƒï¼Œé€šè¿‡å¤šä»»åŠ¡è®­ç»ƒå®žçŽ°ç»Ÿä¸€æŽ¨ç†
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šäººç»„åˆã€å§¿æ€æŽ§åˆ¶ç­‰åŸºå‡†ä¸Šï¼Œèº«ä»½ä¿æŒå’ŒæŽ§åˆ¶ä¾ä»Žæ€§æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While modern diffusion models excel at generating high-quality and diverse images, they still struggle with high-fidelity compositional and multimodal control, particularly when users simultaneously specify text prompts, subject references, spatial arrangements, pose constraints, and layout annotations. We introduce Canvas-to-Image, a unified framework that consolidates these heterogeneous controls into a single canvas interface, enabling users to generate images that faithfully reflect their intent. Our key idea is to encode diverse control signals into a single composite canvas image that the model can directly interpret for integrated visual-spatial reasoning. We further curate a suite of multi-task datasets and propose a Multi-Task Canvas Training strategy that optimizes the diffusion model to jointly understand and integrate heterogeneous controls into text-to-image generation within a unified learning paradigm. This joint training enables Canvas-to-Image to reason across multiple control modalities rather than relying on task-specific heuristics, and it generalizes well to multi-control scenarios during inference. Extensive experiments show that Canvas-to-Image significantly outperforms state-of-the-art methods in identity preservation and control adherence across challenging benchmarks, including multi-person composition, pose-controlled composition, layout-constrained generation, and multi-control generation.

