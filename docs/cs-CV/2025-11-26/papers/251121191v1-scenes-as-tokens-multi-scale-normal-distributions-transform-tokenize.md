---
layout: default
title: Scenes as Tokens: Multi-Scale Normal Distributions Transform Tokenizer for General 3D Vision-Language Understanding
---

# Scenes as Tokens: Multi-Scale Normal Distributions Transform Tokenizer for General 3D Vision-Language Understanding

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.21191" target="_blank" class="toolbar-btn">arXiv: 2511.21191v1</a>
    <a href="https://arxiv.org/pdf/2511.21191.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.21191v1" 
            onclick="toggleFavorite(this, '2511.21191v1', 'Scenes as Tokens: Multi-Scale Normal Distributions Transform Tokenizer for General 3D Vision-Language Understanding')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yutao Tang, Cheng Zhao, Gaurav Mittal, Rohith Kukkala, Rama Chellappa, Cheng Peng, Mei Chen

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-26

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫NDTokenizer3DÔºåÁî®‰∫éÈÄöÁî®3DËßÜËßâ-ËØ≠Ë®ÄÁêÜËß£ÁöÑÂ§öÂ∞∫Â∫¶NDT Tokenizer**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `3DËßÜËßâ-ËØ≠Ë®ÄÁêÜËß£` `Âú∫ÊôØtokenÂåñ` `Â§öÂ∞∫Â∫¶NDT` `ÁÇπ‰∫ëÂ§ÑÁêÜ` `‰∫∫Êú∫‰∫§‰∫í` `3DÂú∫ÊôØÁêÜËß£` `Transformer` `LLM`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3DËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂú®Â∞Ü3DÂú∫ÊôØtokenÂåñ‰∏∫Êï¥‰ΩìÂú∫ÊôØtokensÔºåÂπ∂Â∞ÜÂÖ∂Â∫îÁî®‰∫éÂêÑÁßç3DÁêÜËß£‰ªªÂä°ÊñπÈù¢Â≠òÂú®ÊåëÊàò„ÄÇ
2. NDTokenizer3DÈÄöËøáÂ§öÂ∞∫Â∫¶Ê≠£ÊÄÅÂàÜÂ∏ÉÂèòÊç¢(NDT)Ë°®Á§∫ÂíåÂ§öÂ∞∫Â∫¶NDTËß£Á†ÅÂô®(MSDec)ÂÆûÁé∞È´òÊïàÁöÑ3DÂú∫ÊôØtokenÂåñÂíåÁêÜËß£„ÄÇ
3. NDTokenizer3DÂú®3D Referring Segmentation„ÄÅ3D Visual Question AnsweringÂíå3D Dense CaptioningÁ≠â‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫NDTokenizer3DÁöÑÈÄöÁî®3DËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã(VLM)ÔºåÊó®Âú®ÊèêÂçá3DÂú∫ÊôØÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇËØ•Ê®°ÂûãÈÄöËøáÂ∞Ü3DÂú∫ÊôØÊúâÊïàÂú∞tokenÂåñ‰∏∫Êï¥‰ΩìÂú∫ÊôØtokensÔºåÂπ∂Âà©Áî®Ëøô‰∫õtokensÊù•Â§ÑÁêÜÂêÑÁßç3DÁêÜËß£‰ªªÂä°Ôºå‰ªéËÄåËá™ÁÑ∂Âú∞ÊîØÊåÅ‰∫∫Êú∫‰∫§‰∫íÔºåÂπ∂Â∞ÜËØ≠Ë®ÄÂ±ÇÈù¢ÁöÑÊé®ÁêÜ‰∏é3DÁ©∫Èó¥ÁêÜËß£ËÅîÁ≥ªËµ∑Êù•„ÄÇNDTokenizer3DÁöÑÊ†∏ÂøÉÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑ‰∏âÈò∂ÊÆµÂú∫ÊôØtokenÂåñÊµÅÁ®ãÔºåÂÆÉÂü∫‰∫éÂ§öÂ∞∫Â∫¶Ê≠£ÊÄÅÂàÜÂ∏ÉÂèòÊç¢(NDT)Ë°®Á§∫ÔºåÂπ∂ÁªìÂêà‰∫ÜÂ§öÂ∞∫Â∫¶NDTËß£Á†ÅÂô®(MSDec)„ÄÇËØ•Ê®°ÂûãÈ¶ñÂÖà‰ªéÂéüÂßãÈ´òÂàÜËæ®ÁéáÁÇπ‰∫ëÊûÑÂª∫Â§öÂ∞∫Â∫¶NDTË°®Á§∫Ôºå‰øùÁïôÂÖ®Â±Ä‰∏ä‰∏ãÊñáÂíåÁ≤æÁªÜÁöÑÂá†‰ΩïÁªÜËäÇ„ÄÇÁÑ∂ÂêéÔºåMSDecÈÄêÊ≠•ËûçÂêàË∑®Â∞∫Â∫¶NDTÁâπÂæÅÔºåÁîüÊàêÂèØ‰æõLLMÁ´ØÁÇπ‰ΩøÁî®ÁöÑÊï¥‰ΩìÂú∫ÊôØtokens„ÄÇÊ≠§Â§ñÔºåMSDecËøòË¢´ÈáçÊñ∞Áî®‰Ωú‰∫∫Êú∫‰∫§‰∫íÊèêÁ§∫ÔºàÁÇπ„ÄÅÊ°Ü„ÄÅÊé©Á†ÅÔºâÂíåÂàÜÂâ≤Êé©Á†ÅËß£Á†ÅÁöÑÈÄöÁî®Êé•Âè£Ôºå‰ªéËÄåÂ∞ÜÂêÑÁßç3DÂú∫ÊôØÁêÜËß£‰ªªÂä°Áªü‰∏ÄÂú®‰∏Ä‰∏™Êû∂ÊûÑ‰∏≠„ÄÇËøôÁßçÁ¥ßÂáëËÄåÁªü‰∏ÄÁöÑËÆæËÆ°‰ΩøNDTokenizer3DÊàê‰∏∫‰∏Ä‰∏™Á≤æÁªÜÁöÑ„ÄÅÈÄöÁî®ÁöÑ3D VLMÔºåÂú®3D Referring Segmentation„ÄÅ3D Visual Question AnsweringÂíå3D Dense CaptioningÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊîπËøõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞Êúâ3DËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÈöæ‰ª•ÊúâÊïàÂú∞Â∞Ü3DÂú∫ÊôØtokenÂåñ‰∏∫Êï¥‰ΩìÁöÑ„ÄÅÂèØÁî®‰∫éÂ§öÁßç‰ªªÂä°ÁöÑÂú∫ÊôØtokens„ÄÇËøôÈôêÂà∂‰∫ÜÊ®°ÂûãÂú®3DÂú∫ÊôØÁêÜËß£ÂíåÊé®ÁêÜÊñπÈù¢ÁöÑËÉΩÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÁªìÂêàËØ≠Ë®Ä‰ø°ÊÅØËøõË°å‰∫§‰∫íÂíåÁêÜËß£ÁöÑÂú∫ÊôØ‰∏≠„ÄÇÁé∞ÊúâÊñπÊ≥ïÂèØËÉΩÊó†Ê≥ïÂêåÊó∂ÊçïÊçâÂÖ®Â±Ä‰∏ä‰∏ãÊñáÂíåÁ≤æÁªÜÂá†‰ΩïÁªÜËäÇÔºåÊàñËÄÖÁº∫‰πèÁªü‰∏ÄÁöÑÊ°ÜÊû∂Êù•Â§ÑÁêÜ‰∏çÂêåÁ±ªÂûãÁöÑ3DÁêÜËß£‰ªªÂä°„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Â§öÂ∞∫Â∫¶Ê≠£ÊÄÅÂàÜÂ∏ÉÂèòÊç¢(NDT)Êù•Ë°®Á§∫3DÂú∫ÊôØÔºåÂπ∂ËÆæËÆ°‰∏Ä‰∏™Â§öÂ∞∫Â∫¶NDTËß£Á†ÅÂô®(MSDec)Êù•ÁîüÊàêÂú∫ÊôØtokens„ÄÇNDTËÉΩÂ§üÊúâÊïàÂú∞Ë°®Á§∫ÁÇπ‰∫ëÁöÑÊ¶ÇÁéáÂàÜÂ∏ÉÔºå‰ªéËÄå‰øùÁïôÂá†‰Ωï‰ø°ÊÅØÂíå‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇMSDecÂàôÈÄöËøáËûçÂêà‰∏çÂêåÂ∞∫Â∫¶ÁöÑNDTÁâπÂæÅÔºåÁîüÊàêÂÖ∑ÊúâÂÖ®Â±Ä‰∏ÄËá¥ÊÄßÂíåÂ±ÄÈÉ®ÁªÜËäÇÁöÑÂú∫ÊôØtokensÔºåËøô‰∫õtokensÂèØ‰ª•Ë¢´LLMÁ≠âÊ®°ÂûãÁõ¥Êé•‰ΩøÁî®„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöNDTokenizer3DÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) Â§öÂ∞∫Â∫¶NDTË°®Á§∫ÔºöÂ∞ÜÂéüÂßãÁÇπ‰∫ëËΩ¨Êç¢‰∏∫Â§öÂ∞∫Â∫¶ÁöÑNDTË°®Á§∫ÔºåÊçïÊçâ‰∏çÂêåÂ∞∫Â∫¶ÁöÑÂá†‰Ωï‰ø°ÊÅØ„ÄÇ2) Â§öÂ∞∫Â∫¶NDTËß£Á†ÅÂô®(MSDec)ÔºöÈÄêÊ≠•ËûçÂêàË∑®Â∞∫Â∫¶ÁöÑNDTÁâπÂæÅÔºåÁîüÊàêÊï¥‰ΩìÂú∫ÊôØtokens„ÄÇ3) ‰ªªÂä°ÁâπÂÆöÊ®°ÂùóÔºöÂà©Áî®ÁîüÊàêÁöÑÂú∫ÊôØtokensËøõË°åÂêÑÁßç3DÁêÜËß£‰ªªÂä°ÔºåÂ¶Ç3D Referring Segmentation„ÄÅ3D Visual Question AnsweringÂíå3D Dense Captioning„ÄÇMSDecËøòË¢´Áî®‰Ωú‰∫∫Êú∫‰∫§‰∫íÊèêÁ§∫ÂíåÂàÜÂâ≤Êé©Á†ÅËß£Á†ÅÁöÑÈÄöÁî®Êé•Âè£„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÊèêÂá∫‰∫ÜÂü∫‰∫éÂ§öÂ∞∫Â∫¶NDTÁöÑÂú∫ÊôØtokenÂåñÊñπÊ≥ï„ÄÇ‰∏éÁõ¥Êé•Â§ÑÁêÜÂéüÂßãÁÇπ‰∫ëÊàñ‰ΩøÁî®‰ΩìÁ¥†ÂåñÁ≠âÊñπÊ≥ïÁõ∏ÊØîÔºåNDTËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Ë°®Á§∫ÁÇπ‰∫ëÁöÑÂá†‰Ωï‰ø°ÊÅØÂíåÊ¶ÇÁéáÂàÜÂ∏ÉÔºå‰ªéËÄåÁîüÊàêÊõ¥ÂÖ∑‰ø°ÊÅØÈáèÁöÑÂú∫ÊôØtokens„ÄÇÊ≠§Â§ñÔºåMSDecÁöÑËÆæËÆ°‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂêåÊó∂ÊçïÊçâÂÖ®Â±Ä‰∏ä‰∏ãÊñáÂíåÂ±ÄÈÉ®ÁªÜËäÇÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÂú∫ÊôØÁêÜËß£ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂ§öÂ∞∫Â∫¶NDTË°®Á§∫ÈÄöËøáË∞ÉÊï¥NDTÁöÑÂ∞∫Â∫¶ÂèÇÊï∞Êù•ÊçïÊçâ‰∏çÂêåÂ∞∫Â∫¶ÁöÑÂá†‰Ωï‰ø°ÊÅØ„ÄÇMSDecÈááÁî®ÈÄêÊ≠•ËûçÂêàÁöÑÊñπÂºèÔºåÂ∞Ü‰∏çÂêåÂ∞∫Â∫¶ÁöÑNDTÁâπÂæÅËøõË°åËûçÂêàÔºå‰ªéËÄåÁîüÊàêÊúÄÁªàÁöÑÂú∫ÊôØtokens„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰ΩìÁöÑ‰ªªÂä°ËøõË°åË∞ÉÊï¥Ôºå‰æãÂ¶ÇÔºåÂú®3D Referring Segmentation‰ªªÂä°‰∏≠ÔºåÂèØ‰ª•‰ΩøÁî®‰∫§ÂèâÁÜµÊçüÂ§±ÂáΩÊï∞Êù•‰ºòÂåñÂàÜÂâ≤ÁªìÊûú„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

NDTokenizer3DÂú®Â§ö‰∏™3DËßÜËßâ-ËØ≠Ë®ÄÁêÜËß£‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºåÂú®3D Referring Segmentation‰ªªÂä°‰∏≠ÔºåËØ•Ê®°ÂûãÁõ∏ÊØîÁé∞ÊúâÊñπÊ≥ïÂèñÂæó‰∫ÜX%ÁöÑÊèêÂçáÔºàÂÖ∑‰ΩìÊï∞ÊçÆËØ∑ÂèÇËÄÉÂéüËÆ∫ÊñáÔºâ„ÄÇÊ≠§Â§ñÔºåËØ•Ê®°ÂûãÂú®3D Visual Question AnsweringÂíå3D Dense Captioning‰ªªÂä°‰∏ä‰πüË°®Áé∞Âá∫Ëâ≤ÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÈÄöÁî®3DÂú∫ÊôØÁêÜËß£ÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÁªìÂêàËßÜËßâÂíåËØ≠Ë®Ä‰ø°ÊÅØÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£Âë®Âõ¥ÁéØÂ¢ÉÔºåÂπ∂‰∏é‰∫∫Á±ªËøõË°åÊõ¥Ëá™ÁÑ∂ÁöÑ‰∫§‰∫í„ÄÇ‰æãÂ¶ÇÔºåÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÊ®°ÂûãÂèØ‰ª•ÁêÜËß£‚ÄúÁ∫¢Ëâ≤ÁöÑËΩ¶ÂÅúÂú®Ë∑ØËæπ‚ÄùÁ≠âÊåá‰ª§Ôºå‰ªéËÄåÂÅöÂá∫Êõ¥ÂêàÁêÜÁöÑÂÜ≥Á≠ñ„ÄÇÂú®ËôöÊãüÁé∞ÂÆû‰∏≠ÔºåÊ®°ÂûãÂèØ‰ª•Ê†πÊçÆÁî®Êà∑ÁöÑËØ≠Ë®ÄÊèèËø∞ÁîüÊàêÁõ∏Â∫îÁöÑ3DÂú∫ÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent advances in 3D vision-language models (VLMs) highlight a strong potential for 3D scene understanding and reasoning. However, effectively tokenizing 3D scenes into holistic scene tokens, and leveraging these tokens across diverse 3D understanding tasks, remain highly challenging. We present NDTokenizer3D, a generalist 3D VLM that performs a wide range of 3D scene understanding tasks while naturally supporting human interactions, thereby bridging language-level reasoning with 3D spatial understanding. The core of our approach is a novel three-stage scene tokenization pipeline built upon a Multi-Scale Normal Distributions Transform (NDT) representation, paired with a Multi-Scale NDT Decoder (MSDec). Specifically, NDTokenizer3D first constructs a multi-scale NDT representation from raw high-resolution point clouds, preserving both global context and fine-grained geometric details. Next, the MSDec progressively fuses cross-scale NDT features, producing holistic scene tokens consumable by LLM endpoints. Beyond tokenization, MSDec is repurposed as a general interface for human-interactive prompting (points, boxes, masks) and segmentation-mask decoding, unifying diverse 3D scene understanding tasks within a single architecture. With this compact and unified design, NDTokenizer3D offers a fine-grained, general-purpose 3D VLM, achieving remarkable improvements in 3D Referring Segmentation, 3D Visual Question Answering, and 3D Dense Captioning.

