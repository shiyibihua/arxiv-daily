---
layout: default
title: Scenes as Tokens: Multi-Scale Normal Distributions Transform Tokenizer for General 3D Vision-Language Understanding
---

# Scenes as Tokens: Multi-Scale Normal Distributions Transform Tokenizer for General 3D Vision-Language Understanding

**arXiv**: [2511.21191v1](https://arxiv.org/abs/2511.21191) | [PDF](https://arxiv.org/pdf/2511.21191.pdf)

**ä½œè€…**: Yutao Tang, Cheng Zhao, Gaurav Mittal, Rohith Kukkala, Rama Chellappa, Cheng Peng, Mei Chen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-26

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNDTokenizer3Dï¼Œç”¨äºŽé€šç”¨3Dè§†è§‰-è¯­è¨€ç†è§£çš„å¤šå°ºåº¦NDT Tokenizer**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dè§†è§‰-è¯­è¨€ç†è§£` `åœºæ™¯tokenåŒ–` `å¤šå°ºåº¦NDT` `ç‚¹äº‘å¤„ç†` `äººæœºäº¤äº’` `3Dåœºæ™¯ç†è§£` `Transformer` `LLM`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰3Dè§†è§‰-è¯­è¨€æ¨¡åž‹åœ¨å°†3Dåœºæ™¯tokenåŒ–ä¸ºæ•´ä½“åœºæ™¯tokensï¼Œå¹¶å°†å…¶åº”ç”¨äºŽå„ç§3Dç†è§£ä»»åŠ¡æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚
2. NDTokenizer3Dé€šè¿‡å¤šå°ºåº¦æ­£æ€åˆ†å¸ƒå˜æ¢(NDT)è¡¨ç¤ºå’Œå¤šå°ºåº¦NDTè§£ç å™¨(MSDec)å®žçŽ°é«˜æ•ˆçš„3Dåœºæ™¯tokenåŒ–å’Œç†è§£ã€‚
3. NDTokenizer3Dåœ¨3D Referring Segmentationã€3D Visual Question Answeringå’Œ3D Dense Captioningç­‰ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºNDTokenizer3Dçš„é€šç”¨3Dè§†è§‰-è¯­è¨€æ¨¡åž‹(VLM)ï¼Œæ—¨åœ¨æå‡3Dåœºæ™¯ç†è§£å’ŒæŽ¨ç†èƒ½åŠ›ã€‚è¯¥æ¨¡åž‹é€šè¿‡å°†3Dåœºæ™¯æœ‰æ•ˆåœ°tokenåŒ–ä¸ºæ•´ä½“åœºæ™¯tokensï¼Œå¹¶åˆ©ç”¨è¿™äº›tokensæ¥å¤„ç†å„ç§3Dç†è§£ä»»åŠ¡ï¼Œä»Žè€Œè‡ªç„¶åœ°æ”¯æŒäººæœºäº¤äº’ï¼Œå¹¶å°†è¯­è¨€å±‚é¢çš„æŽ¨ç†ä¸Ž3Dç©ºé—´ç†è§£è”ç³»èµ·æ¥ã€‚NDTokenizer3Dçš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªæ–°é¢–çš„ä¸‰é˜¶æ®µåœºæ™¯tokenåŒ–æµç¨‹ï¼Œå®ƒåŸºäºŽå¤šå°ºåº¦æ­£æ€åˆ†å¸ƒå˜æ¢(NDT)è¡¨ç¤ºï¼Œå¹¶ç»“åˆäº†å¤šå°ºåº¦NDTè§£ç å™¨(MSDec)ã€‚è¯¥æ¨¡åž‹é¦–å…ˆä»ŽåŽŸå§‹é«˜åˆ†è¾¨çŽ‡ç‚¹äº‘æž„å»ºå¤šå°ºåº¦NDTè¡¨ç¤ºï¼Œä¿ç•™å…¨å±€ä¸Šä¸‹æ–‡å’Œç²¾ç»†çš„å‡ ä½•ç»†èŠ‚ã€‚ç„¶åŽï¼ŒMSDecé€æ­¥èžåˆè·¨å°ºåº¦NDTç‰¹å¾ï¼Œç”Ÿæˆå¯ä¾›LLMç«¯ç‚¹ä½¿ç”¨çš„æ•´ä½“åœºæ™¯tokensã€‚æ­¤å¤–ï¼ŒMSDecè¿˜è¢«é‡æ–°ç”¨ä½œäººæœºäº¤äº’æç¤ºï¼ˆç‚¹ã€æ¡†ã€æŽ©ç ï¼‰å’Œåˆ†å‰²æŽ©ç è§£ç çš„é€šç”¨æŽ¥å£ï¼Œä»Žè€Œå°†å„ç§3Dåœºæ™¯ç†è§£ä»»åŠ¡ç»Ÿä¸€åœ¨ä¸€ä¸ªæž¶æž„ä¸­ã€‚è¿™ç§ç´§å‡‘è€Œç»Ÿä¸€çš„è®¾è®¡ä½¿NDTokenizer3Dæˆä¸ºä¸€ä¸ªç²¾ç»†çš„ã€é€šç”¨çš„3D VLMï¼Œåœ¨3D Referring Segmentationã€3D Visual Question Answeringå’Œ3D Dense Captioningæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰3Dè§†è§‰-è¯­è¨€æ¨¡åž‹éš¾ä»¥æœ‰æ•ˆåœ°å°†3Dåœºæ™¯tokenåŒ–ä¸ºæ•´ä½“çš„ã€å¯ç”¨äºŽå¤šç§ä»»åŠ¡çš„åœºæ™¯tokensã€‚è¿™é™åˆ¶äº†æ¨¡åž‹åœ¨3Dåœºæ™¯ç†è§£å’ŒæŽ¨ç†æ–¹é¢çš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ç»“åˆè¯­è¨€ä¿¡æ¯è¿›è¡Œäº¤äº’å’Œç†è§£çš„åœºæ™¯ä¸­ã€‚çŽ°æœ‰æ–¹æ³•å¯èƒ½æ— æ³•åŒæ—¶æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡å’Œç²¾ç»†å‡ ä½•ç»†èŠ‚ï¼Œæˆ–è€…ç¼ºä¹ç»Ÿä¸€çš„æ¡†æž¶æ¥å¤„ç†ä¸åŒç±»åž‹çš„3Dç†è§£ä»»åŠ¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šå°ºåº¦æ­£æ€åˆ†å¸ƒå˜æ¢(NDT)æ¥è¡¨ç¤º3Dåœºæ™¯ï¼Œå¹¶è®¾è®¡ä¸€ä¸ªå¤šå°ºåº¦NDTè§£ç å™¨(MSDec)æ¥ç”Ÿæˆåœºæ™¯tokensã€‚NDTèƒ½å¤Ÿæœ‰æ•ˆåœ°è¡¨ç¤ºç‚¹äº‘çš„æ¦‚çŽ‡åˆ†å¸ƒï¼Œä»Žè€Œä¿ç•™å‡ ä½•ä¿¡æ¯å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚MSDecåˆ™é€šè¿‡èžåˆä¸åŒå°ºåº¦çš„NDTç‰¹å¾ï¼Œç”Ÿæˆå…·æœ‰å…¨å±€ä¸€è‡´æ€§å’Œå±€éƒ¨ç»†èŠ‚çš„åœºæ™¯tokensï¼Œè¿™äº›tokenså¯ä»¥è¢«LLMç­‰æ¨¡åž‹ç›´æŽ¥ä½¿ç”¨ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šNDTokenizer3DåŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1) å¤šå°ºåº¦NDTè¡¨ç¤ºï¼šå°†åŽŸå§‹ç‚¹äº‘è½¬æ¢ä¸ºå¤šå°ºåº¦çš„NDTè¡¨ç¤ºï¼Œæ•æ‰ä¸åŒå°ºåº¦çš„å‡ ä½•ä¿¡æ¯ã€‚2) å¤šå°ºåº¦NDTè§£ç å™¨(MSDec)ï¼šé€æ­¥èžåˆè·¨å°ºåº¦çš„NDTç‰¹å¾ï¼Œç”Ÿæˆæ•´ä½“åœºæ™¯tokensã€‚3) ä»»åŠ¡ç‰¹å®šæ¨¡å—ï¼šåˆ©ç”¨ç”Ÿæˆçš„åœºæ™¯tokensè¿›è¡Œå„ç§3Dç†è§£ä»»åŠ¡ï¼Œå¦‚3D Referring Segmentationã€3D Visual Question Answeringå’Œ3D Dense Captioningã€‚MSDecè¿˜è¢«ç”¨ä½œäººæœºäº¤äº’æç¤ºå’Œåˆ†å‰²æŽ©ç è§£ç çš„é€šç”¨æŽ¥å£ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽæå‡ºäº†åŸºäºŽå¤šå°ºåº¦NDTçš„åœºæ™¯tokenåŒ–æ–¹æ³•ã€‚ä¸Žç›´æŽ¥å¤„ç†åŽŸå§‹ç‚¹äº‘æˆ–ä½¿ç”¨ä½“ç´ åŒ–ç­‰æ–¹æ³•ç›¸æ¯”ï¼ŒNDTèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¡¨ç¤ºç‚¹äº‘çš„å‡ ä½•ä¿¡æ¯å’Œæ¦‚çŽ‡åˆ†å¸ƒï¼Œä»Žè€Œç”Ÿæˆæ›´å…·ä¿¡æ¯é‡çš„åœºæ™¯tokensã€‚æ­¤å¤–ï¼ŒMSDecçš„è®¾è®¡ä½¿å¾—æ¨¡åž‹èƒ½å¤ŸåŒæ—¶æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡å’Œå±€éƒ¨ç»†èŠ‚ï¼Œä»Žè€Œæé«˜äº†åœºæ™¯ç†è§£çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå¤šå°ºåº¦NDTè¡¨ç¤ºé€šè¿‡è°ƒæ•´NDTçš„å°ºåº¦å‚æ•°æ¥æ•æ‰ä¸åŒå°ºåº¦çš„å‡ ä½•ä¿¡æ¯ã€‚MSDecé‡‡ç”¨é€æ­¥èžåˆçš„æ–¹å¼ï¼Œå°†ä¸åŒå°ºåº¦çš„NDTç‰¹å¾è¿›è¡Œèžåˆï¼Œä»Žè€Œç”Ÿæˆæœ€ç»ˆçš„åœºæ™¯tokensã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦æ ¹æ®å…·ä½“çš„ä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼Œä¾‹å¦‚ï¼Œåœ¨3D Referring Segmentationä»»åŠ¡ä¸­ï¼Œå¯ä»¥ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥ä¼˜åŒ–åˆ†å‰²ç»“æžœã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

NDTokenizer3Dåœ¨å¤šä¸ª3Dè§†è§‰-è¯­è¨€ç†è§£ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨3D Referring Segmentationä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡åž‹ç›¸æ¯”çŽ°æœ‰æ–¹æ³•å–å¾—äº†X%çš„æå‡ï¼ˆå…·ä½“æ•°æ®è¯·å‚è€ƒåŽŸè®ºæ–‡ï¼‰ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡åž‹åœ¨3D Visual Question Answeringå’Œ3D Dense Captioningä»»åŠ¡ä¸Šä¹Ÿè¡¨çŽ°å‡ºè‰²ï¼Œè¯æ˜Žäº†å…¶åœ¨é€šç”¨3Dåœºæ™¯ç†è§£æ–¹é¢çš„èƒ½åŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žç­‰é¢†åŸŸã€‚é€šè¿‡ç»“åˆè§†è§‰å’Œè¯­è¨€ä¿¡æ¯ï¼Œæœºå™¨äººå¯ä»¥æ›´å¥½åœ°ç†è§£å‘¨å›´çŽ¯å¢ƒï¼Œå¹¶ä¸Žäººç±»è¿›è¡Œæ›´è‡ªç„¶çš„äº¤äº’ã€‚ä¾‹å¦‚ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œæ¨¡åž‹å¯ä»¥ç†è§£â€œçº¢è‰²çš„è½¦åœåœ¨è·¯è¾¹â€ç­‰æŒ‡ä»¤ï¼Œä»Žè€Œåšå‡ºæ›´åˆç†çš„å†³ç­–ã€‚åœ¨è™šæ‹ŸçŽ°å®žä¸­ï¼Œæ¨¡åž‹å¯ä»¥æ ¹æ®ç”¨æˆ·çš„è¯­è¨€æè¿°ç”Ÿæˆç›¸åº”çš„3Dåœºæ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in 3D vision-language models (VLMs) highlight a strong potential for 3D scene understanding and reasoning. However, effectively tokenizing 3D scenes into holistic scene tokens, and leveraging these tokens across diverse 3D understanding tasks, remain highly challenging. We present NDTokenizer3D, a generalist 3D VLM that performs a wide range of 3D scene understanding tasks while naturally supporting human interactions, thereby bridging language-level reasoning with 3D spatial understanding. The core of our approach is a novel three-stage scene tokenization pipeline built upon a Multi-Scale Normal Distributions Transform (NDT) representation, paired with a Multi-Scale NDT Decoder (MSDec). Specifically, NDTokenizer3D first constructs a multi-scale NDT representation from raw high-resolution point clouds, preserving both global context and fine-grained geometric details. Next, the MSDec progressively fuses cross-scale NDT features, producing holistic scene tokens consumable by LLM endpoints. Beyond tokenization, MSDec is repurposed as a general interface for human-interactive prompting (points, boxes, masks) and segmentation-mask decoding, unifying diverse 3D scene understanding tasks within a single architecture. With this compact and unified design, NDTokenizer3D offers a fine-grained, general-purpose 3D VLM, achieving remarkable improvements in 3D Referring Segmentation, 3D Visual Question Answering, and 3D Dense Captioning.

