---
layout: default
title: PathReasoning: A multimodal reasoning agent for query-based ROI navigation on whole-slide images
---

# PathReasoning: A multimodal reasoning agent for query-based ROI navigation on whole-slide images

**arXiv**: [2511.21902v1](https://arxiv.org/abs/2511.21902) | [PDF](https://arxiv.org/pdf/2511.21902.pdf)

**ä½œè€…**: Kunpeng Zhang, Hanwen Xu, Sheng Wang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-26

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PathReasoningï¼šä¸€ç§ç”¨äºŽå…¨åˆ‡ç‰‡å›¾åƒä¸ŠåŸºäºŽæŸ¥è¯¢çš„ROIå¯¼èˆªçš„å¤šæ¨¡æ€æŽ¨ç†Agent**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å…¨åˆ‡ç‰‡å›¾åƒ` `ROIå¯¼èˆª` `å¤šæ¨¡æ€æŽ¨ç†` `æ•°å­—ç—…ç†å­¦` `è‚¿ç˜¤å¾®çŽ¯å¢ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å…¨åˆ‡ç‰‡å›¾åƒå·¨å¤§ï¼Œäººå·¥å¯¼èˆªè€—æ—¶ï¼ŒçŽ°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„é—®é¢˜å¼•å¯¼å’ŒæŽ¨ç†æœºåˆ¶ã€‚
2. PathReasoningé€šè¿‡å¤šè½®æŽ¨ç†å’Œè‡ªæˆ‘åæ€ï¼Œé€æ­¥å¼•å¯¼æ¨¡åž‹å…³æ³¨è¯Šæ–­ç›¸å…³åŒºåŸŸï¼Œæž„å»ºå¯è§£é‡Šçš„æŽ¨ç†é“¾ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒPathReasoningåœ¨ROIé€‰æ‹©å’ŒæŠ¥å‘Šç”Ÿæˆæ–¹é¢æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼ŒAUROCæœ€é«˜æå‡6.7%ï¼ŒæŠ¥å‘Šå‡†ç¡®çŽ‡æå‡10%ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»Žå…¨åˆ‡ç‰‡å›¾åƒ(WSI)ä¸­è§£è¯»è‚¿ç˜¤å¾®çŽ¯å¢ƒå¯¹äºŽç™Œç—‡çš„è¯Šæ–­ã€é¢„åŽå’Œæ²»ç–—ååº”è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè¿™äº›é«˜è¾¾æ•°åäº¿åƒç´ çš„å›¾åƒåœ¨æä¾›å…¨é¢ç™Œç—‡å›¾æ™¯çš„åŒæ—¶ï¼Œå…¶å·¨å¤§çš„å°ºå¯¸ä¹Ÿä½¿å¾—å¯¼èˆªåˆ°ç›¸åº”åŒºåŸŸä»¥æ”¯æŒå„ç§ä¸´åºŠæ£€æŸ¥å˜å¾—å…·æœ‰æŒ‘æˆ˜æ€§å’Œè€—æ—¶ã€‚å—ç—…ç†å­¦å®¶åœ¨WSIä¸Šç»“åˆé‡‡æ ·ã€æŽ¨ç†å’Œè‡ªæˆ‘åæ€è¿›è¡Œå¯¼èˆªçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†â€œPathReasoningâ€ï¼Œè¿™æ˜¯ä¸€ç§å¤šæ¨¡æ€æŽ¨ç†Agentï¼Œé€šè¿‡å¤šè½®æŽ¨ç†å’Œæ”¹è¿›åœ¨WSIä¸­è¿­ä»£å¯¼èˆªã€‚å…·ä½“æ¥è¯´ï¼ŒPathReasoningä»Žéšæœºé‡‡æ ·çš„å€™é€‰åŒºåŸŸå¼€å§‹ï¼Œé€šè¿‡è‡ªæˆ‘åæ€æ¥å›žé¡¾å½“å‰çš„é€‰æ‹©ï¼ŒæŽ¨ç†è§†è§‰è§‚å¯Ÿå’Œä¸´åºŠé—®é¢˜ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œå¹¶é€šè¿‡æå‡ºæ–°çš„æŽ¢ç´¢åŒºåŸŸæ¥ç»“æŸã€‚åœ¨å¤šè½®è¿­ä»£ä¸­ï¼ŒPathReasoningæž„å»ºäº†ä¸€ä¸ªæŽ¨ç†é“¾ï¼Œé€æ­¥å°†æ³¨æ„åŠ›å¼•å¯¼åˆ°å…·æœ‰è¯Šæ–­ç›¸å…³æ€§çš„åŒºåŸŸã€‚PathReasoningå°†æ¯ä¸ªå…¨åˆ‡ç‰‡å›¾åƒè½¬æ¢ä¸ºä¸€ç³»åˆ—é—®é¢˜å¼•å¯¼çš„è§†å›¾ï¼Œä½¿æ¨¡åž‹èƒ½å¤Ÿåœ¨å›ºå®šæ­¥æ•°å†…æœ‰æ•ˆåœ°æ‰¾åˆ°ä¿¡æ¯ä¸°å¯Œçš„ROIï¼Œè€Œæ— éœ€å¯†é›†çš„åƒç´ çº§æ³¨é‡Šã€‚PathReasoningåœ¨äºšåž‹åˆ†æžå’Œçºµå‘åˆ†æžä»»åŠ¡ä¸­ï¼Œæ˜¾è‘—ä¼˜äºŽå¼ºå¤§çš„ROIé€‰æ‹©æ–¹æ³•ï¼ŒAUROCåˆ†åˆ«æé«˜äº†6.7%å’Œ3.1%ã€‚é«˜è´¨é‡çš„ROIè¿›ä¸€æ­¥æ”¯æŒäº†ä¹³è…ºç™Œçš„å‡†ç¡®æŠ¥å‘Šç”Ÿæˆï¼Œåœ¨å‡†ç¡®æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºŽæ ‡å‡†GPT-4o 10%ã€‚PathReasoningä¼˜å…ˆè€ƒè™‘ç‰¹å®šé—®é¢˜çš„åŒºåŸŸå¹¶æž„å»ºå¯è§£é‡Šçš„æŽ¨ç†é“¾ï¼Œä»Žè€Œæ”¯æŒæ•°å­—ç—…ç†å­¦ä¸­çš„é«˜æ•ˆåˆ‡ç‰‡å®¡æŸ¥ã€ä¸€è‡´çš„è¯Šæ–­è§£é‡Šã€å…¨é¢çš„æŠ¥å‘Šå’Œè¯æ®å¯è¿½æº¯æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå…¨åˆ‡ç‰‡å›¾åƒï¼ˆWSIï¼‰å°ºå¯¸å·¨å¤§ï¼Œäººå·¥å¯¼èˆªè€—æ—¶ä¸”å®¹æ˜“å‡ºé”™ã€‚çŽ°æœ‰çš„ROIé€‰æ‹©æ–¹æ³•é€šå¸¸ç¼ºä¹æœ‰æ•ˆçš„é—®é¢˜å¼•å¯¼å’ŒæŽ¨ç†æœºåˆ¶ï¼Œéš¾ä»¥å¿«é€Ÿå‡†ç¡®åœ°å®šä½åˆ°å…·æœ‰è¯Šæ–­ä»·å€¼çš„åŒºåŸŸã€‚è¿™é˜»ç¢äº†å¯¹è‚¿ç˜¤å¾®çŽ¯å¢ƒçš„æ·±å…¥ç†è§£å’Œä¸´åºŠåº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPathReasoningçš„æ ¸å¿ƒæ€è·¯æ˜¯æ¨¡æ‹Ÿç—…ç†å­¦å®¶çš„è¯Šæ–­è¿‡ç¨‹ï¼Œé€šè¿‡è¿­ä»£çš„é‡‡æ ·ã€æŽ¨ç†å’Œè‡ªæˆ‘åæ€ï¼Œé€æ­¥ç¼©å°æœç´¢èŒƒå›´ï¼Œæœ€ç»ˆå®šä½åˆ°ä¸Žä¸´åºŠé—®é¢˜ç›¸å…³çš„ROIã€‚è¿™ç§æ–¹æ³•å°†å…¨å±€æœç´¢é—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªåºåˆ—å†³ç­–é—®é¢˜ï¼Œåˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯è¿›è¡ŒæŽ¨ç†ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šPathReasoningåŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) å€™é€‰åŒºåŸŸé‡‡æ ·ï¼šä»ŽWSIä¸­éšæœºé‡‡æ ·å€™é€‰ROIï¼›2) è‡ªæˆ‘åæ€ï¼šè¯„ä¼°å½“å‰é€‰æ‹©çš„ROIçš„è´¨é‡ï¼›3) å¤šæ¨¡æ€æŽ¨ç†ï¼šç»“åˆè§†è§‰ä¿¡æ¯å’Œä¸´åºŠé—®é¢˜ï¼ŒæŽ¨ç†ROIä¸Žé—®é¢˜çš„ç›¸å…³æ€§ï¼›4) åŒºåŸŸæè®®ï¼šåŸºäºŽæŽ¨ç†ç»“æžœï¼Œæå‡ºæ–°çš„æŽ¢ç´¢åŒºåŸŸã€‚æ•´ä¸ªæµç¨‹è¿­ä»£è¿›è¡Œï¼Œç›´åˆ°è¾¾åˆ°é¢„è®¾çš„æ­¥æ•°æˆ–æ»¡è¶³åœæ­¢æ¡ä»¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šPathReasoningçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶å¤šæ¨¡æ€æŽ¨ç†å’Œè¿­ä»£æ”¹è¿›æœºåˆ¶ã€‚å®ƒä¸ä»…åˆ©ç”¨è§†è§‰ä¿¡æ¯ï¼Œè¿˜ç»“åˆäº†ä¸´åºŠé—®é¢˜ï¼Œä»Žè€Œå®žçŽ°äº†é—®é¢˜å¼•å¯¼çš„ROIå¯¼èˆªã€‚æ­¤å¤–ï¼Œé€šè¿‡è‡ªæˆ‘åæ€å’Œè¿­ä»£æ”¹è¿›ï¼ŒPathReasoningèƒ½å¤Ÿé€æ­¥æé«˜ROIçš„è´¨é‡ï¼Œå¹¶æž„å»ºå¯è§£é‡Šçš„æŽ¨ç†é“¾ã€‚

**å…³é”®è®¾è®¡**ï¼šPathReasoningçš„å…·ä½“å®žçŽ°ç»†èŠ‚åŒ…æ‹¬ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰æ¨¡åž‹æå–ROIçš„ç‰¹å¾ï¼›ä½¿ç”¨è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡åž‹è§£æžä¸´åºŠé—®é¢˜ï¼›è®¾è®¡ä¸€ä¸ªæŽ¨ç†æ¨¡å—ï¼Œå°†è§†è§‰ç‰¹å¾å’Œé—®é¢˜è¡¨ç¤ºæ˜ å°„åˆ°ROIçš„ç›¸å…³æ€§å¾—åˆ†ï¼›ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–ç›‘ç£å­¦ä¹ æ–¹æ³•è®­ç»ƒæ¨¡åž‹ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆåœ°è¿›è¡Œè‡ªæˆ‘åæ€å’ŒåŒºåŸŸæè®®ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦è€ƒè™‘ROIçš„è´¨é‡ã€ä¸Žé—®é¢˜çš„ç›¸å…³æ€§ä»¥åŠæŽ¨ç†é“¾çš„å¯è§£é‡Šæ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

PathReasoningåœ¨äºšåž‹åˆ†æžå’Œçºµå‘åˆ†æžä»»åŠ¡ä¸­ï¼ŒAUROCåˆ†åˆ«æé«˜äº†6.7%å’Œ3.1%ï¼Œæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰çš„ROIé€‰æ‹©æ–¹æ³•ã€‚åœ¨ä¹³è…ºç™ŒæŠ¥å‘Šç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒPathReasoningçš„å‡†ç¡®æ€§æ¯”GPT-4oæé«˜äº†10%ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒPathReasoningèƒ½å¤Ÿæœ‰æ•ˆåœ°å®šä½åˆ°å…·æœ‰è¯Šæ–­ä»·å€¼çš„ROIï¼Œå¹¶ç”Ÿæˆæ›´å‡†ç¡®çš„æŠ¥å‘Šã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

PathReasoningå¯åº”ç”¨äºŽæ•°å­—ç—…ç†å­¦é¢†åŸŸï¼Œè¾…åŠ©ç—…ç†å­¦å®¶è¿›è¡Œå…¨åˆ‡ç‰‡å›¾åƒçš„å¿«é€Ÿå®¡æŸ¥å’Œè¯Šæ–­ã€‚å®ƒå¯ä»¥æé«˜è¯Šæ–­æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ï¼Œå‡å°‘äººä¸ºè¯¯å·®ï¼Œå¹¶ä¸ºä¸´åºŠå†³ç­–æä¾›æ›´å¯é çš„ä¾æ®ã€‚æ­¤å¤–ï¼ŒPathReasoningè¿˜å¯ä»¥ç”¨äºŽè¯ç‰©ç ”å‘ã€ç”Ÿç‰©æ ‡å¿—ç‰©å‘çŽ°ç­‰é¢†åŸŸï¼ŒåŠ é€Ÿç™Œç—‡ç ”ç©¶çš„è¿›å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deciphering tumor microenvironment from Whole Slide Images (WSIs) is intriguing as it is key to cancer diagnosis, prognosis and treatment response. While these gigapixel images on one hand offer a comprehensive portrait of cancer, on the other hand, the extremely large size, as much as more than 10 billion pixels, make it challenging and time-consuming to navigate to corresponding regions to support diverse clinical inspection. Inspired by pathologists who conducted navigation on WSIs with a combination of sampling, reasoning and self-reflection, we proposed "PathReasoning", a multi-modal reasoning agent that iteratively navigates across WSIs through multiple rounds of reasoning and refinements. Specifically, starting with randomly sampled candidate regions, PathReasoning reviews current selections with self-reflection, reasoning over the correspondence between visual observations and clinical questions, and concludes by proposing new regions to explore. Across rounds, PathReasoning builds a reasoning chain that gradually directs attention to diagnostically relevant areas. PathReasoning turns each whole slide into a sequence of question-guided views, allowing the model to efficiently find informative ROIs within a fixed number of steps, without the need for dense pixel-level annotations. PathReasoning can substantially outperform strong ROI-selection approaches by 6.7% and 3.1% of AUROC on subtyping and longitudinal analysis tasks. The high-quality ROIs further support accurate report generation on breast cancer, significantly outperforming the standard GPT-4o by 10% in accuracy. PathReasoning prioritizes question-specific regions and constructs interpretable reasoning chains, supporting efficient slide review, consistent diagnostic interpretations, comprehensive reporting, and evidence traceability in digital pathology.

