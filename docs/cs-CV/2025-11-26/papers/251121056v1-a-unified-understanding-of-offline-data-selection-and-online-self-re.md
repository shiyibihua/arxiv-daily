---
layout: default
title: A Unified Understanding of Offline Data Selection and Online Self-refining Generation for Post-training LLMs
---

# A Unified Understanding of Offline Data Selection and Online Self-refining Generation for Post-training LLMs

**arXiv**: [2511.21056v1](https://arxiv.org/abs/2511.21056) | [PDF](https://arxiv.org/pdf/2511.21056.pdf)

**ä½œè€…**: Quan Xiao, Tianyi Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒå±‚æ•°æ®é€‰æ‹©ä¸Žåœ¨çº¿è‡ªä¼˜åŒ–ç”Ÿæˆæ¡†æž¶ï¼Œä»¥æå‡åŽè®­ç»ƒå¤§è¯­è¨€æ¨¡åž‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹åŽè®­ç»ƒ` `ç¦»çº¿æ•°æ®é€‰æ‹©` `åœ¨çº¿è‡ªä¼˜åŒ–ç”Ÿæˆ` `åŒå±‚ä¼˜åŒ–` `æ¨¡åž‹å¾®è°ƒ` `æ•°æ®æƒé‡å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç¦»çº¿æ•°æ®é€‰æ‹©å’Œåœ¨çº¿è‡ªä¼˜åŒ–ç”Ÿæˆå¦‚ä½•ç»Ÿä¸€ä¼˜åŒ–ä»¥æå‡å¤§è¯­è¨€æ¨¡åž‹åœ¨ä¸‹æ¸¸ä»»åŠ¡çš„æ•°æ®è´¨é‡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åŒå±‚æ•°æ®é€‰æ‹©ä¼˜åŒ–ç¦»çº¿æ•°æ®ï¼Œå¹¶å°†åœ¨çº¿è‡ªä¼˜åŒ–è§†ä¸ºæ¨¡åž‹é€‚åº”æ­¥éª¤ï¼Œå­¦ä¹ æ•°æ®æƒé‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨è´¨é‡å¢žå¼ºå’Œå®‰å…¨æ„ŸçŸ¥å¾®è°ƒå®žéªŒä¸­éªŒè¯äº†æ€§èƒ½æå‡ï¼Œä¼˜äºŽæœªè¿‡æ»¤åŸºçº¿ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Offline data selection and online self-refining generation, which enhance the data quality, are crucial steps in adapting large language models (LLMs) to specific downstream tasks. We tackle offline data selection and online self-refining generations through an optimization perspective. Specifically, bilevel data selection is used for offline data selection with respect to the validation dataset, and we treat online self-refining generation as a model adaptation step of selecting the model trained on current responses that best fits the validation data. Our framework offers a unified understanding of offline data selection and self-refining generation by assigning a learned data weight to each question and response, either explicitly or implicitly. For the first time, we theoretically demonstrate the effectiveness of the bilevel data selection framework and demonstrate its performance gains over unfiltered direct mixing baselines. By combining offline data with validation-weighted online generations, our method enhances fine-tuning performance. Experiments on quality enhancement and safety-aware LLM fine-tuning validate its effectiveness.

