---
layout: default
title: On the Limits of Innate Planning in Large Language Models
---

# On the Limits of Innate Planning in Large Language Models

**arXiv**: [2511.21591v1](https://arxiv.org/abs/2511.21591) | [PDF](https://arxiv.org/pdf/2511.21591.pdf)

**ä½œè€…**: Charles Schepanowski, Charles Ling

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§è¯­è¨€æ¨¡åž‹åœ¨8-puzzleä»»åŠ¡ä¸­çš„å†…åœ¨è§„åˆ’èƒ½åŠ›ï¼Œæ­ç¤ºå…¶çŠ¶æ€è·Ÿè¸ªä¸Žå¯å‘å¼è§„åˆ’ç¼ºé™·**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹` `è§„åˆ’èƒ½åŠ›` `çŠ¶æ€è·Ÿè¸ª` `8-puzzleä»»åŠ¡` `æç¤ºç­–ç•¥` `å¯å‘å¼è§„åˆ’`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è¯­è¨€æ¨¡åž‹åœ¨æ— å¤–éƒ¨å·¥å…·ä¸‹çš„è§„åˆ’ä¸ŽçŠ¶æ€æŽ¨ç†èƒ½åŠ›å­˜åœ¨æ˜¾è‘—å±€é™
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨8-puzzleä»»åŠ¡ï¼Œæµ‹è¯•å¤šç§æç¤ºç­–ç•¥ä¸Žåé¦ˆæœºåˆ¶ï¼Œåˆ†æžæ¨¡åž‹è¡Œä¸º
3. å®žéªŒæˆ–æ•ˆæžœï¼šåé¦ˆæå‡éƒ¨åˆ†æˆåŠŸçŽ‡ï¼Œä½†æ¨¡åž‹æ— æ³•åœ¨éªŒè¯å™¨è¾…åŠ©ä¸‹è§£å†³ä»»ä½•è°œé¢˜

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large language models (LLMs) achieve impressive results on many benchmarks, yet their capacity for planning and stateful reasoning remains unclear. We study these abilities directly, without code execution or other tools, using the 8-puzzle: a classic task that requires state tracking and goal-directed planning while allowing precise, step-by-step evaluation. Four models are tested under common prompting conditions (Zero-Shot, Chain-of-Thought, Algorithm-of-Thought) and with tiered corrective feedback. Feedback improves success rates for some model-prompt combinations, but many successful runs are long, computationally expensive, and indirect. We then examine the models with an external move validator that provides only valid moves. Despite this level of assistance, none of the models solve any puzzles in this setting. Qualitative analysis reveals two dominant deficits across all models: (1) brittle internal state representations, leading to frequent invalid moves, and (2) weak heuristic planning, with models entering loops or selecting actions that do not reduce the distance to the goal state. These findings indicate that, in the absence of external tools such as code interpreters, current LLMs have substantial limitations in planning and that further progress may require mechanisms for maintaining explicit state and performing structured search.

