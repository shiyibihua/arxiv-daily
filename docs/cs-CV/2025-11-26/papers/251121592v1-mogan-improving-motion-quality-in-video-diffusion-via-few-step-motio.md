---
layout: default
title: MoGAN: Improving Motion Quality in Video Diffusion via Few-Step Motion Adversarial Post-Training
---

# MoGAN: Improving Motion Quality in Video Diffusion via Few-Step Motion Adversarial Post-Training

**arXiv**: [2511.21592v1](https://arxiv.org/abs/2511.21592) | [PDF](https://arxiv.org/pdf/2511.21592.pdf)

**ä½œè€…**: Haotian Xue, Qi Chen, Zhonghao Wang, Xun Huang, Eli Shechtman, Jinrong Xie, Yongxin Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMoGANåŽè®­ç»ƒæ¡†æž¶ä»¥æå‡è§†é¢‘æ‰©æ•£æ¨¡åž‹ä¸­çš„è¿åŠ¨è´¨é‡**

**å…³é”®è¯**: `è§†é¢‘æ‰©æ•£æ¨¡åž‹` `è¿åŠ¨è´¨é‡æå‡` `åŽè®­ç»ƒæ¡†æž¶` `å…‰æµåˆ¤åˆ«å™¨` `åˆ†å¸ƒåŒ¹é…æ­£åˆ™åŒ–` `è’¸é¦è®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†é¢‘æ‰©æ•£æ¨¡åž‹å­˜åœ¨è¿åŠ¨ä¸è¿žè´¯ã€æŠ–åŠ¨å’ŒåŠ¨æ€ä¸çœŸå®žé—®é¢˜ï¼Œç¼ºä¹æ—¶é—´ä¸€è‡´æ€§ç›‘ç£
2. æ–¹æ³•åŸºäºŽ3æ­¥è’¸é¦æ¨¡åž‹ï¼Œè®­ç»ƒå…‰æµåˆ¤åˆ«å™¨åŒºåˆ†çœŸå®žä¸Žç”Ÿæˆè¿åŠ¨ï¼Œå¹¶æ·»åŠ åˆ†å¸ƒåŒ¹é…æ­£åˆ™åŒ–
3. å®žéªŒæ˜¾ç¤ºåœ¨VBenchå’ŒVideoJAM-Benchä¸Šè¿åŠ¨åˆ†æ•°æ˜¾è‘—æå‡ï¼Œäººç±»ç ”ç©¶åå¥½MoGANè¿åŠ¨è´¨é‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video diffusion models achieve strong frame-level fidelity but still struggle with motion coherence, dynamics and realism, often producing jitter, ghosting, or implausible dynamics. A key limitation is that the standard denoising MSE objective provides no direct supervision on temporal consistency, allowing models to achieve low loss while still generating poor motion. We propose MoGAN, a motion-centric post-training framework that improves motion realism without reward models or human preference data. Built atop a 3-step distilled video diffusion model, we train a DiT-based optical-flow discriminator to differentiate real from generated motion, combined with a distribution-matching regularizer to preserve visual fidelity. With experiments on Wan2.1-T2V-1.3B, MoGAN substantially improves motion quality across benchmarks. On VBench, MoGAN boosts motion score by +7.3% over the 50-step teacher and +13.3% over the 3-step DMD model. On VideoJAM-Bench, MoGAN improves motion score by +7.4% over the teacher and +8.8% over DMD, while maintaining comparable or even better aesthetic and image-quality scores. A human study further confirms that MoGAN is preferred for motion quality (52% vs. 38% for the teacher; 56% vs. 29% for DMD). Overall, MoGAN delivers significantly more realistic motion without sacrificing visual fidelity or efficiency, offering a practical path toward fast, high-quality video generation. Project webpage is: https://xavihart.github.io/mogan.

