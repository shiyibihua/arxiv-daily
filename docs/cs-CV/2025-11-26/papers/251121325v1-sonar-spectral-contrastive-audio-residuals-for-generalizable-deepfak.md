---
layout: default
title: SONAR: Spectral-Contrastive Audio Residuals for Generalizable Deepfake Detection
---

# SONAR: Spectral-Contrastive Audio Residuals for Generalizable Deepfake Detection

**arXiv**: [2511.21325v1](https://arxiv.org/abs/2511.21325) | [PDF](https://arxiv.org/pdf/2511.21325.pdf)

**ä½œè€…**: Ido Nitzan HIdekel, Gal lifshitz, Khen Cohen, Dan Raviv

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSONARæ¡†æž¶ä»¥è§£å†³æ·±åº¦ä¼ªé€ éŸ³é¢‘æ£€æµ‹çš„æ³›åŒ–æ€§é—®é¢˜**

**å…³é”®è¯**: `æ·±åº¦ä¼ªé€ æ£€æµ‹` `éŸ³é¢‘ä¿¡å·å¤„ç†` `é¢‘è°±å¯¹æ¯”å­¦ä¹ ` `é«˜é¢‘æ®‹å·®` `æ³›åŒ–æ€§æå‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç¥žç»ç½‘ç»œé¢‘è°±åå·®å¯¼è‡´é«˜é¢‘ä¼ªå½±æœªè¢«å……åˆ†åˆ©ç”¨ï¼Œå½±å“æ£€æµ‹å™¨æ³›åŒ–
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡é¢‘çŽ‡å¼•å¯¼æ¡†æž¶åˆ†ç¦»éŸ³é¢‘ä¿¡å·ï¼Œç»“åˆå¯¹æ¯”å­¦ä¹ ä¼˜åŒ–å†³ç­–è¾¹ç•Œ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ASVspoof 2021ç­‰åŸºå‡†ä¸Šè¾¾åˆ°SOTAï¼Œæ”¶æ•›é€Ÿåº¦æå‡å››å€

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deepfake (DF) audio detectors still struggle to generalize to out of distribution inputs. A central reason is spectral bias, the tendency of neural networks to learn low-frequency structure before high-frequency (HF) details, which both causes DF generators to leave HF artifacts and leaves those same artifacts under-exploited by common detectors. To address this gap, we propose Spectral-cONtrastive Audio Residuals (SONAR), a frequency-guided framework that explicitly disentangles an audio signal into complementary representations. An XLSR encoder captures the dominant low-frequency content, while the same cloned path, preceded by learnable SRM, value-constrained high-pass filters, distills faint HF residuals. Frequency cross-attention reunites the two views for long- and short-range frequency dependencies, and a frequency-aware Jensen-Shannon contrastive loss pulls real content-noise pairs together while pushing fake embeddings apart, accelerating optimization and sharpening decision boundaries. Evaluated on the ASVspoof 2021 and in-the-wild benchmarks, SONAR attains state-of-the-art performance and converges four times faster than strong baselines. By elevating faint high-frequency residuals to first-class learning signals, SONAR unveils a fully data-driven, frequency-guided contrastive framework that splits the latent space into two disjoint manifolds: natural-HF for genuine audio and distorted-HF for synthetic audio, thereby sharpening decision boundaries. Because the scheme operates purely at the representation level, it is architecture-agnostic and, in future work, can be seamlessly integrated into any model or modality where subtle high-frequency cues are decisive.

