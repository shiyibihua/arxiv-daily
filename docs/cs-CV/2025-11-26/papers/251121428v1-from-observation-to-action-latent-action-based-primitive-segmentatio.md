---
layout: default
title: From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings
---

# From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings

**arXiv**: [2511.21428v1](https://arxiv.org/abs/2511.21428) | [PDF](https://arxiv.org/pdf/2511.21428.pdf)

**ä½œè€…**: Jiajie Zhang, SÃ¶ren Schwertfeger, Alexander Kleiner

**åˆ†ç±»**: cs.CV, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-26

**å¤‡æ³¨**: 10 pages, 5 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽéšå¼åŠ¨ä½œåŽŸè¯­åˆ†å‰²çš„VLAé¢„è®­ç»ƒæ–¹æ³•ï¼Œç”¨äºŽå·¥ä¸šåœºæ™¯**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `VLAé¢„è®­ç»ƒ` `æ— ç›‘ç£å­¦ä¹ ` `åŠ¨ä½œåˆ†å‰²` `å·¥ä¸šæœºå™¨äºº` `å…·èº«æ™ºèƒ½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨å·¥ä¸šè§†é¢‘ä¸­å¤§é‡æœªæ ‡æ³¨çš„äººå·¥æ“ä½œæ•°æ®ï¼Œé˜»ç¢äº†VLAæ¨¡åž‹åœ¨å·¥ä¸šé¢†åŸŸçš„åº”ç”¨ã€‚
2. æå‡ºä¸€ç§æ— ç›‘ç£å­¦ä¹ æ¡†æž¶ï¼Œé€šè¿‡è¿åŠ¨æ ‡è®°å™¨å’Œéšå¼åŠ¨ä½œèƒ½é‡åº¦é‡ï¼Œè‡ªåŠ¨å‘çŽ°å¹¶åˆ†å‰²è§†é¢‘ä¸­çš„åŠ¨ä½œåŽŸè¯­ã€‚
3. åœ¨å…¬å…±æ•°æ®é›†å’Œå·¥ä¸šæ•°æ®é›†ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜Žå…¶èƒ½å¤Ÿæå–è¯­ä¹‰è¿žè´¯çš„åŠ¨ä½œåŽŸè¯­ï¼Œé€‚ç”¨äºŽVLAé¢„è®­ç»ƒã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ— ç›‘ç£æ¡†æž¶ï¼Œæ—¨åœ¨ä»Žè¿žç»­çš„å·¥ä¸šè§†é¢‘æµä¸­æŒ–æŽ˜å¤§é‡æœªæ ‡æ³¨çš„äººå·¥æ¼”ç¤ºæ•°æ®ï¼Œç”¨äºŽè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹çš„é¢„è®­ç»ƒã€‚è¯¥æ–¹æ³•é¦–å…ˆè®­ç»ƒä¸€ä¸ªè½»é‡çº§çš„è¿åŠ¨æ ‡è®°å™¨æ¥ç¼–ç è¿åŠ¨åŠ¨æ€ï¼Œç„¶åŽåˆ©ç”¨ä¸€ä¸ªæ— ç›‘ç£çš„åŠ¨ä½œåˆ†å‰²å™¨ï¼Œè¯¥åˆ†å‰²å™¨åˆ©ç”¨äº†ä¸€ç§æ–°çš„â€œéšå¼åŠ¨ä½œèƒ½é‡â€åº¦é‡æ¥å‘çŽ°å’Œåˆ†å‰²è¯­ä¹‰è¿žè´¯çš„åŠ¨ä½œåŽŸè¯­ã€‚è¯¥æµç¨‹è¾“å‡ºåˆ†å‰²åŽçš„è§†é¢‘ç‰‡æ®µåŠå…¶å¯¹åº”çš„éšå¼åŠ¨ä½œåºåˆ—ï¼Œä¸ºVLAé¢„è®­ç»ƒæä¾›ç›´æŽ¥é€‚ç”¨çš„ç»“æž„åŒ–æ•°æ®ã€‚åœ¨å…¬å…±åŸºå‡†å’Œä¸€ä¸ªä¸“æœ‰çš„ç”µæœºè£…é…æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜Žï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ†å‰²äººç±»åœ¨å·¥ä½œç«™æ‰§è¡Œçš„å…³é”®ä»»åŠ¡ã€‚é€šè¿‡è§†è§‰-è¯­è¨€æ¨¡åž‹è¿›è¡Œçš„è¿›ä¸€æ­¥èšç±»å’Œå®šé‡è¯„ä¼°è¯å®žäº†æ‰€å‘çŽ°çš„åŠ¨ä½œåŽŸè¯­çš„è¯­ä¹‰è¿žè´¯æ€§ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå…¨è‡ªåŠ¨ç«¯åˆ°ç«¯ç³»ç»Ÿï¼Œç”¨äºŽä»Žéžç»“æž„åŒ–å·¥ä¸šè§†é¢‘ä¸­æå–å’Œç»„ç»‡VLAé¢„è®­ç»ƒæ•°æ®ï¼Œä¸ºåˆ¶é€ ä¸šä¸­å…·èº«äººå·¥æ™ºèƒ½çš„é›†æˆæä¾›äº†ä¸€ç§å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•ä»Žæµ·é‡æœªæ ‡æ³¨çš„å·¥ä¸šè§†é¢‘æ•°æ®ä¸­æå–æœ‰ç”¨çš„ä¿¡æ¯ï¼Œç”¨äºŽè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹çš„é¢„è®­ç»ƒã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦äººå·¥æ ‡æ³¨ï¼Œæˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥æ‰©å±•ã€‚æ­¤å¤–ï¼Œå·¥ä¸šè§†é¢‘é€šå¸¸æ˜¯è¿žç»­çš„ï¼Œç¼ºä¹æ˜Žç¡®çš„åŠ¨ä½œè¾¹ç•Œï¼Œä½¿å¾—è‡ªåŠ¨åˆ†å‰²å’Œç†è§£å˜å¾—å›°éš¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ— ç›‘ç£å­¦ä¹ çš„æ–¹å¼ï¼Œè‡ªåŠ¨å‘çŽ°å’Œåˆ†å‰²è§†é¢‘ä¸­çš„åŠ¨ä½œåŽŸè¯­ã€‚é¦–å…ˆï¼Œåˆ©ç”¨è¿åŠ¨æ ‡è®°å™¨å­¦ä¹ è§†é¢‘ä¸­çš„è¿åŠ¨æ¨¡å¼ï¼Œç„¶åŽåŸºäºŽè¿™äº›è¿åŠ¨æ¨¡å¼ï¼Œä½¿ç”¨ä¸€ç§æ–°çš„â€œéšå¼åŠ¨ä½œèƒ½é‡â€åº¦é‡æ¥ç¡®å®šåŠ¨ä½œçš„è¾¹ç•Œã€‚è¿™ç§æ–¹æ³•é¿å…äº†äººå·¥æ ‡æ³¨çš„éœ€è¦ï¼Œå¹¶ä¸”èƒ½å¤Ÿå¤„ç†è¿žç»­çš„è§†é¢‘æµã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä¸ªæ¡†æž¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè¿åŠ¨æ ‡è®°å™¨å’ŒåŠ¨ä½œåˆ†å‰²å™¨ã€‚è¿åŠ¨æ ‡è®°å™¨è´Ÿè´£å°†è§†é¢‘å¸§ç¼–ç æˆè¿åŠ¨tokenï¼Œæ•æ‰è§†é¢‘ä¸­çš„è¿åŠ¨ä¿¡æ¯ã€‚åŠ¨ä½œåˆ†å‰²å™¨åˆ™åˆ©ç”¨è¿™äº›è¿åŠ¨tokenï¼Œé€šè¿‡è®¡ç®—â€œéšå¼åŠ¨ä½œèƒ½é‡â€æ¥ç¡®å®šåŠ¨ä½œçš„è¾¹ç•Œï¼Œå¹¶å°†è§†é¢‘åˆ†å‰²æˆä¸€ç³»åˆ—åŠ¨ä½œåŽŸè¯­ã€‚æœ€åŽï¼Œå°†åˆ†å‰²åŽçš„è§†é¢‘ç‰‡æ®µå’Œå¯¹åº”çš„éšå¼åŠ¨ä½œåºåˆ—ä½œä¸ºVLAæ¨¡åž‹çš„é¢„è®­ç»ƒæ•°æ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†â€œéšå¼åŠ¨ä½œèƒ½é‡â€è¿™ä¸€æ¦‚å¿µï¼Œå¹¶å°†å…¶ç”¨äºŽæ— ç›‘ç£çš„åŠ¨ä½œåˆ†å‰²ã€‚ä¸Žä¼ ç»Ÿçš„åŸºäºŽæ‰‹å·¥ç‰¹å¾æˆ–ç›‘ç£å­¦ä¹ çš„åŠ¨ä½œåˆ†å‰²æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ è§†é¢‘ä¸­çš„è¿åŠ¨æ¨¡å¼ï¼Œå¹¶æ ¹æ®è¿™äº›æ¨¡å¼æ¥ç¡®å®šåŠ¨ä½œçš„è¾¹ç•Œã€‚è¿™ç§æ–¹æ³•æ›´åŠ çµæ´»ï¼Œèƒ½å¤Ÿé€‚åº”ä¸åŒçš„å·¥ä¸šåœºæ™¯ã€‚

**å…³é”®è®¾è®¡**ï¼šè¿åŠ¨æ ‡è®°å™¨å¯ä»¥ä½¿ç”¨å„ç§çŽ°æœ‰çš„è§†é¢‘ç¼–ç å™¨ï¼Œä¾‹å¦‚TimeSformerã€‚éšå¼åŠ¨ä½œèƒ½é‡çš„è®¡ç®—æ–¹å¼æ˜¯åŸºäºŽè¿åŠ¨tokenä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œç›¸ä¼¼åº¦è¶Šé«˜ï¼Œè¡¨ç¤ºè¯¥ç‰‡æ®µå±žäºŽåŒä¸€ä¸ªåŠ¨ä½œçš„å¯èƒ½æ€§è¶Šå¤§ã€‚åŠ¨ä½œåˆ†å‰²å™¨å¯ä»¥ä½¿ç”¨åŠ¨æ€è§„åˆ’ç®—æ³•æ¥å¯»æ‰¾æœ€ä¼˜çš„åˆ†å‰²æ–¹æ¡ˆã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦è€ƒè™‘åˆ†å‰²çš„å‡†ç¡®æ€§å’ŒåŠ¨ä½œåŽŸè¯­çš„è¯­ä¹‰è¿žè´¯æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨å…¬å…±åŸºå‡†å’Œä¸€ä¸ªä¸“æœ‰çš„ç”µæœºè£…é…æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ†å‰²äººç±»åœ¨å·¥ä½œç«™æ‰§è¡Œçš„å…³é”®ä»»åŠ¡ï¼Œå¹¶ä¸”æ‰€å‘çŽ°çš„åŠ¨ä½œåŽŸè¯­å…·æœ‰è‰¯å¥½çš„è¯­ä¹‰è¿žè´¯æ€§ã€‚é€šè¿‡ä¸Žè§†è§‰-è¯­è¨€æ¨¡åž‹è¿›è¡Œçš„å®šé‡è¯„ä¼°ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•æå–çš„åŠ¨ä½œåŽŸè¯­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºVLAæ¨¡åž‹çš„é¢„è®­ç»ƒæä¾›äº†é«˜è´¨é‡çš„æ•°æ®ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯å¹¿æ³›åº”ç”¨äºŽå·¥ä¸šè‡ªåŠ¨åŒ–é¢†åŸŸï¼Œä¾‹å¦‚æœºå™¨äººæ“ä½œã€è´¨é‡æ£€æµ‹ã€è®¾å¤‡ç»´æŠ¤ç­‰ã€‚é€šè¿‡VLAæ¨¡åž‹ï¼Œæœºå™¨äººå¯ä»¥ç†è§£äººç±»çš„æ“ä½œæŒ‡ä»¤ï¼Œå¹¶è‡ªä¸»å®Œæˆå¤æ‚çš„ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºŽåˆ†æžå·¥äººçš„æ“ä½œè¡Œä¸ºï¼Œæé«˜ç”Ÿäº§æ•ˆçŽ‡å’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æŽ¨åŠ¨åˆ¶é€ ä¸šå‘æ™ºèƒ½åŒ–ã€æŸ”æ€§åŒ–æ–¹å‘å‘å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present a novel unsupervised framework to unlock vast unlabeled human demonstration data from continuous industrial video streams for Vision-Language-Action (VLA) model pre-training. Our method first trains a lightweight motion tokenizer to encode motion dynamics, then employs an unsupervised action segmenter leveraging a novel "Latent Action Energy" metric to discover and segment semantically coherent action primitives. The pipeline outputs both segmented video clips and their corresponding latent action sequences, providing structured data directly suitable for VLA pre-training. Evaluations on public benchmarks and a proprietary electric motor assembly dataset demonstrate effective segmentation of key tasks performed by humans at workstations. Further clustering and quantitative assessment via a Vision-Language Model confirm the semantic coherence of the discovered action primitives. To our knowledge, this is the first fully automated end-to-end system for extracting and organizing VLA pre-training data from unstructured industrial videos, offering a scalable solution for embodied AI integration in manufacturing.

