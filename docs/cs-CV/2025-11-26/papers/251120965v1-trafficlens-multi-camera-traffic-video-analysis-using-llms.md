---
layout: default
title: TrafficLens: Multi-Camera Traffic Video Analysis Using LLMs
---

# TrafficLens: Multi-Camera Traffic Video Analysis Using LLMs

**arXiv**: [2511.20965v1](https://arxiv.org/abs/2511.20965) | [PDF](https://arxiv.org/pdf/2511.20965.pdf)

**ä½œè€…**: Md Adnan Arefeen, Biplob Debnath, Srimat Chakradhar

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTrafficLensç®—æ³•ä»¥è§£å†³å¤šæ‘„åƒå¤´äº¤é€šè§†é¢‘åˆ†æžæ•ˆçŽ‡é—®é¢˜**

**å…³é”®è¯**: `å¤šæ‘„åƒå¤´è§†é¢‘åˆ†æž` `äº¤é€šç›‘æŽ§` `è§†è§‰è¯­è¨€æ¨¡åž‹` `åºåˆ—å¤„ç†` `å¯¹è±¡ç›¸ä¼¼æ€§æ£€æµ‹` `æ•ˆçŽ‡ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ‘„åƒå¤´äº¤é€šè§†é¢‘æ•°æ®é‡å¤§ï¼Œè§†é¢‘è½¬æ–‡æœ¬è¿‡ç¨‹è€—æ—¶ï¼Œå½±å“å®žæ—¶åˆ†æžã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åºåˆ—åŒ–VLMå¤„ç†ï¼Œåˆ©ç”¨æ‘„åƒå¤´é‡å åŒºåŸŸå’Œå¯¹è±¡ç›¸ä¼¼æ€§æ£€æµ‹å‡å°‘å†—ä½™ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šçœŸå®žæ•°æ®é›†æµ‹è¯•æ˜¾ç¤ºï¼Œè½¬æ¢æ—¶é—´å‡å°‘é«˜è¾¾4å€ï¼Œä¿¡æ¯å‡†ç¡®æ€§ä¿æŒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Traffic cameras are essential in urban areas, playing a crucial role in intelligent transportation systems. Multiple cameras at intersections enhance law enforcement capabilities, traffic management, and pedestrian safety. However, efficiently managing and analyzing multi-camera feeds poses challenges due to the vast amount of data. Analyzing such huge video data requires advanced analytical tools. While Large Language Models (LLMs) like ChatGPT, equipped with retrieval-augmented generation (RAG) systems, excel in text-based tasks, integrating them into traffic video analysis demands converting video data into text using a Vision-Language Model (VLM), which is time-consuming and delays the timely utilization of traffic videos for generating insights and investigating incidents. To address these challenges, we propose TrafficLens, a tailored algorithm for multi-camera traffic intersections. TrafficLens employs a sequential approach, utilizing overlapping coverage areas of cameras. It iteratively applies VLMs with varying token limits, using previous outputs as prompts for subsequent cameras, enabling rapid generation of detailed textual descriptions while reducing processing time. Additionally, TrafficLens intelligently bypasses redundant VLM invocations through an object-level similarity detector. Experimental results with real-world datasets demonstrate that TrafficLens reduces video-to-text conversion time by up to $4\times$ while maintaining information accuracy.

