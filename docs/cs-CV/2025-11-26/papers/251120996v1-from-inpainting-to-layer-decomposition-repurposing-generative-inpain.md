---
layout: default
title: From Inpainting to Layer Decomposition: Repurposing Generative Inpainting Models for Image Layer Decomposition
---

# From Inpainting to Layer Decomposition: Repurposing Generative Inpainting Models for Image Layer Decomposition

**arXiv**: [2511.20996v1](https://arxiv.org/abs/2511.20996) | [PDF](https://arxiv.org/pdf/2511.20996.pdf)

**ä½œè€…**: Jingxi Chen, Yixiao Zhang, Xiaoye Qian, Zongxia Li, Cornelia Fermuller, Caren Chen, Yiannis Aloimonos

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæ‰©æ•£ä¿®å¤æ¨¡åž‹çš„å›¾åƒå±‚åˆ†è§£æ–¹æ³•ï¼Œç”¨äºŽç‹¬ç«‹ç¼–è¾‘å›¾åƒå…ƒç´ ã€‚**

**å…³é”®è¯**: `å›¾åƒå±‚åˆ†è§£` `æ‰©æ•£æ¨¡åž‹` `ä¿®å¤ä»»åŠ¡` `å¤šæ¨¡æ€èžåˆ` `åˆæˆæ•°æ®é›†` `å›¾åƒç¼–è¾‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå•å›¾åƒå±‚åˆ†è§£å› æ–¹æ³•å’Œæ•°æ®æœ‰é™è€Œå…·æŒ‘æˆ˜æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè½»é‡å¾®è°ƒæ‰©æ•£ä¿®å¤æ¨¡åž‹ï¼Œå¼•å…¥å¤šæ¨¡æ€ä¸Šä¸‹æ–‡èžåˆæ¨¡å—ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åˆæˆæ•°æ®é›†ä¸Šè®­ç»ƒï¼Œå®žçŽ°ä¼˜è¶Šçš„å¯¹è±¡ç§»é™¤å’Œé®æŒ¡æ¢å¤æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Images can be viewed as layered compositions, foreground objects over background, with potential occlusions. This layered representation enables independent editing of elements, offering greater flexibility for content creation. Despite the progress in large generative models, decomposing a single image into layers remains challenging due to limited methods and data. We observe a strong connection between layer decomposition and in/outpainting tasks, and propose adapting a diffusion-based inpainting model for layer decomposition using lightweight finetuning. To further preserve detail in the latent space, we introduce a novel multi-modal context fusion module with linear attention complexity. Our model is trained purely on a synthetic dataset constructed from open-source assets and achieves superior performance in object removal and occlusion recovery, unlocking new possibilities in downstream editing and creative applications.

