---
layout: default
title: When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models
---

# When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models

**arXiv**: [2511.21192v2](https://arxiv.org/abs/2511.21192) | [PDF](https://arxiv.org/pdf/2511.21192.pdf)

**ä½œè€…**: Hui Lu, Yi Yu, Yiming Yang, Chenyu Yi, Qixin Zhang, Bingquan Shen, Alex C. Kot, Xudong Jiang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-26 (æ›´æ–°: 2025-11-30)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUPA-RFASä»¥è§£å†³VLAæ¨¡åž‹çš„é€šç”¨å¯è½¬ç§»æ”»å‡»é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å¯¹æŠ—æ”»å‡»` `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `è¡¥ä¸æ”»å‡»` `è·¨æ¨¡åž‹è½¬ç§»` `é²æ£’æ€§å¢žå¼º` `ä¿¡æ¯å¯¹æ¯”æŸå¤±` `æœºå™¨äººè§†è§‰` `å®‰å…¨æ€§ç ”ç©¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰çš„å¯¹æŠ—æ”»å‡»æ–¹æ³•é€šå¸¸é’ˆå¯¹ç‰¹å®šæ¨¡åž‹ï¼Œç¼ºä¹é€šç”¨æ€§å’Œå¯è½¬ç§»æ€§ï¼Œå¯¼è‡´åœ¨é»‘ç®±çŽ¯å¢ƒä¸­æ•ˆæžœä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºUPA-RFASæ¡†æž¶ï¼Œé€šè¿‡å…±äº«ç‰¹å¾ç©ºé—´å­¦ä¹ ç‰©ç†è¡¥ä¸ï¼Œå¢žå¼ºè·¨æ¨¡åž‹çš„è½¬ç§»èƒ½åŠ›ï¼Œè§£å†³äº†çŽ°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚
3. å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒUPA-RFASåœ¨ä¸åŒVLAæ¨¡åž‹å’Œä»»åŠ¡ä¸­å‡èƒ½æœ‰æ•ˆè½¬ç§»ï¼Œå±•ç¤ºäº†å…¶åœ¨å®žé™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹æ˜“å—å¯¹æŠ—æ”»å‡»çš„å½±å“ï¼Œä½†çŽ°æœ‰çš„é€šç”¨å’Œå¯è½¬ç§»æ”»å‡»ç ”ç©¶ä»ç„¶ä¸è¶³ã€‚å¤§å¤šæ•°çŽ°æœ‰çš„æ”»å‡»æ–¹æ³•è¿‡æ‹ŸåˆäºŽå•ä¸€æ¨¡åž‹ï¼Œæ— æ³•åœ¨é»‘ç®±è®¾ç½®ä¸­æœ‰æ•ˆå·¥ä½œã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç³»ç»Ÿæ€§ç ”ç©¶ï¼Œé’ˆå¯¹VLAé©±åŠ¨çš„æœºå™¨äººåœ¨æœªçŸ¥æž¶æž„ã€å¾®è°ƒå˜ä½“å’Œä»¿çœŸåˆ°çŽ°å®žçš„è½¬å˜ä¸‹ï¼Œæå‡ºäº†é€šç”¨å¯è½¬ç§»çš„å¯¹æŠ—è¡¥ä¸æ”»å‡»ã€‚æˆ‘ä»¬å¼•å…¥äº†UPA-RFASï¼ˆé€šè¿‡é²æ£’ç‰¹å¾ã€æ³¨æ„åŠ›å’Œè¯­ä¹‰çš„é€šç”¨è¡¥ä¸æ”»å‡»ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€æ¡†æž¶ï¼Œæ—¨åœ¨å­¦ä¹ ä¸€ä¸ªå…±äº«ç‰¹å¾ç©ºé—´ä¸­çš„ç‰©ç†è¡¥ä¸ï¼ŒåŒæ—¶ä¿ƒè¿›è·¨æ¨¡åž‹çš„è½¬ç§»ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒUPA-RFASåœ¨å¤šç§VLAæ¨¡åž‹ã€æ“ä½œå¥—ä»¶å’Œç‰©ç†æ‰§è¡Œä¸­è¡¨çŽ°å‡ºä¸€è‡´çš„è½¬ç§»èƒ½åŠ›ï¼Œæ­ç¤ºäº†åŸºäºŽè¡¥ä¸çš„æ”»å‡»è¡¨é¢ï¼Œå¹¶ä¸ºæœªæ¥çš„é˜²å¾¡å»ºç«‹äº†å¼ºæœ‰åŠ›çš„åŸºçº¿ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹åœ¨é¢å¯¹å¯¹æŠ—æ”»å‡»æ—¶çš„è„†å¼±æ€§ï¼Œå°¤å…¶æ˜¯çŽ°æœ‰æ–¹æ³•åœ¨é»‘ç®±è®¾ç½®ä¸­çš„é€šç”¨æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šUPA-RFASæ¡†æž¶é€šè¿‡åœ¨å…±äº«ç‰¹å¾ç©ºé—´ä¸­å­¦ä¹ ä¸€ä¸ªç‰©ç†è¡¥ä¸ï¼Œç»“åˆå¤šç§æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç­–ç•¥ï¼Œä¿ƒè¿›è¡¥ä¸çš„è·¨æ¨¡åž‹è½¬ç§»ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šUPA-RFASåŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šç‰¹å¾ç©ºé—´ç›®æ ‡ã€é²æ£’æ€§å¢žå¼ºçš„ä¸¤é˜¶æ®µæœ€å°-æœ€å¤§ç¨‹åºï¼Œä»¥åŠVLAç‰¹å®šçš„æŸå¤±å‡½æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºŽå¼•å…¥äº†è¡¥ä¸æ³¨æ„åŠ›ä¸»å¯¼å’Œè¡¥ä¸è¯­ä¹‰ä¸å¯¹é½çš„æŸå¤±å‡½æ•°ï¼Œä½¿å¾—è¡¥ä¸åœ¨ä¸åŒæ¨¡åž‹é—´çš„è½¬ç§»èƒ½åŠ›æ˜¾è‘—å¢žå¼ºã€‚

**å…³é”®è®¾è®¡**ï¼šé‡‡ç”¨$	ext{l}_1$åå·®å…ˆéªŒå’Œä¿¡æ¯å¯¹æ¯”æŸå¤±ï¼ˆInfoNCEï¼‰æ¥è¯±å¯¼å¯è½¬ç§»çš„è¡¨ç¤ºå˜åŒ–ï¼ŒåŒæ—¶åœ¨ä¸¤é˜¶æ®µä¼˜åŒ–ä¸­ï¼Œå†…å¾ªçŽ¯å­¦ä¹ ä¸å¯è§çš„æ ·æœ¬æ‰°åŠ¨ï¼Œå¤–å¾ªçŽ¯åˆ™é’ˆå¯¹å¼ºåŒ–çš„é‚»åŸŸä¼˜åŒ–é€šç”¨è¡¥ä¸ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒUPA-RFASåœ¨å¤šç§VLAæ¨¡åž‹ä¸Šå‡èƒ½å®žçŽ°æœ‰æ•ˆçš„è¡¥ä¸è½¬ç§»ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒä»»åŠ¡å’Œè§†è§’ä¸‹ï¼Œè¡¨çŽ°å‡ºä¸€è‡´æ€§å’Œå¼ºå¤§çš„æ”»å‡»èƒ½åŠ›ï¼Œä¸ºæœªæ¥çš„é˜²å¾¡ç ”ç©¶æä¾›äº†é‡è¦åŸºçº¿ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººè§†è§‰ã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æŽ§ç­‰ï¼Œèƒ½å¤Ÿæé«˜è¿™äº›ç³»ç»Ÿåœ¨é¢å¯¹å¯¹æŠ—æ”»å‡»æ—¶çš„é²æ£’æ€§ã€‚é€šè¿‡å»ºç«‹å¼ºæœ‰åŠ›çš„æ”»å‡»åŸºçº¿ï¼Œæœªæ¥çš„é˜²å¾¡æœºåˆ¶å¯ä»¥æ›´æœ‰æ•ˆåœ°é’ˆå¯¹è¿™äº›æ”»å‡»è¿›è¡Œä¼˜åŒ–ï¼Œæå‡æ•´ä½“å®‰å…¨æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models are vulnerable to adversarial attacks, yet universal and transferable attacks remain underexplored, as most existing patches overfit to a single model and fail in black-box settings. To address this gap, we present a systematic study of universal, transferable adversarial patches against VLA-driven robots under unknown architectures, finetuned variants, and sim-to-real shifts. We introduce UPA-RFAS (Universal Patch Attack via Robust Feature, Attention, and Semantics), a unified framework that learns a single physical patch in a shared feature space while promoting cross-model transfer. UPA-RFAS combines (i) a feature-space objective with an $\ell_1$ deviation prior and repulsive InfoNCE loss to induce transferable representation shifts, (ii) a robustness-augmented two-phase min-max procedure where an inner loop learns invisible sample-wise perturbations and an outer loop optimizes the universal patch against this hardened neighborhood, and (iii) two VLA-specific losses: Patch Attention Dominance to hijack text$\to$vision attention and Patch Semantic Misalignment to induce image-text mismatch without labels. Experiments across diverse VLA models, manipulation suites, and physical executions show that UPA-RFAS consistently transfers across models, tasks, and viewpoints, exposing a practical patch-based attack surface and establishing a strong baseline for future defenses.

