---
layout: default
title: Merge and Bound: Direct Manipulations on Weights for Class Incremental Learning
---

# Merge and Bound: Direct Manipulations on Weights for Class Incremental Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.21490" target="_blank" class="toolbar-btn">arXiv: 2511.21490v1</a>
    <a href="https://arxiv.org/pdf/2511.21490.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.21490v1" 
            onclick="toggleFavorite(this, '2511.21490v1', 'Merge and Bound: Direct Manipulations on Weights for Class Incremental Learning')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Taehoon Kim, Donghwan Jang, Bohyung Han

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMerge-and-Boundæ–¹æ³•ï¼Œé€šè¿‡æƒé‡ç©ºé—´æ“ä½œè§£å†³ç±»å¢é‡å­¦ä¹ ä¸­çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `ç±»å¢é‡å­¦ä¹ ` `ç¾éš¾æ€§é—å¿˜` `æƒé‡åˆå¹¶` `æœ‰ç•Œæ›´æ–°` `æŒç»­å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç±»å¢é‡å­¦ä¹ é¢ä¸´ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œå³å­¦ä¹ æ–°ç±»æ—¶ä¼šå¿˜è®°æ—§ç±»çŸ¥è¯†ã€‚
2. M&Bæ–¹æ³•é€šè¿‡ä»»åŠ¡é—´å’Œä»»åŠ¡å†…æƒé‡åˆå¹¶ï¼Œå¹¶åœ¨æƒé‡æ›´æ–°æ—¶è¿›è¡Œçº¦æŸï¼Œä¿ç•™æ—§çŸ¥è¯†å¹¶å­¦ä¹ æ–°çŸ¥è¯†ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒM&Bæ–¹æ³•åœ¨æ ‡å‡†CILåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæœ‰æ•ˆç¼“è§£äº†ç¾éš¾æ€§é—å¿˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºMerge-and-Bound (M&B) çš„æ–°å‹è®­ç»ƒæ–¹æ³•ï¼Œç”¨äºç±»å¢é‡å­¦ä¹  (CIL)ã€‚è¯¥æ–¹æ³•ç›´æ¥åœ¨å‚æ•°ç©ºé—´ä¸­æ“ä½œæ¨¡å‹æƒé‡ä»¥è¿›è¡Œä¼˜åŒ–ã€‚æˆ‘ä»¬çš„ç®—æ³•æ¶‰åŠä¸¤ç§ç±»å‹çš„æƒé‡åˆå¹¶ï¼šä»»åŠ¡é—´æƒé‡åˆå¹¶å’Œä»»åŠ¡å†…æƒé‡åˆå¹¶ã€‚ä»»åŠ¡é—´æƒé‡åˆå¹¶é€šè¿‡å¹³å‡å…ˆå‰æ‰€æœ‰é˜¶æ®µçš„æ¨¡å‹æƒé‡æ¥ç»Ÿä¸€å…ˆå‰çš„æ¨¡å‹ã€‚å¦ä¸€æ–¹é¢ï¼Œä»»åŠ¡å†…æƒé‡åˆå¹¶é€šè¿‡ç»„åˆå½“å‰é˜¶æ®µçš„æ¨¡å‹å‚æ•°æ¥ä¿ƒè¿›å½“å‰ä»»åŠ¡çš„å­¦ä¹ ã€‚ä¸ºäº†å®ç°å¯é çš„æƒé‡åˆå¹¶ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æœ‰ç•Œæ›´æ–°æŠ€æœ¯ï¼Œæ—¨åœ¨ä»¥æœ€å°çš„ç´¯ç§¯æ›´æ–°ä¼˜åŒ–ç›®æ ‡æ¨¡å‹ï¼Œå¹¶ä¿ç•™å…ˆå‰ä»»åŠ¡çš„çŸ¥è¯†ï¼›è¯¥ç­–ç•¥è¡¨æ˜ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åœ¨æ—§æ¨¡å‹é™„è¿‘è·å¾—æ–°æ¨¡å‹ï¼Œä»è€Œå‡å°‘ç¾éš¾æ€§é—å¿˜ã€‚M&B å¯ä»¥æ— ç¼é›†æˆåˆ°ç°æœ‰çš„ CIL æ–¹æ³•ä¸­ï¼Œè€Œæ— éœ€ä¿®æ”¹æ¶æ„ç»„ä»¶æˆ–ä¿®æ”¹å­¦ä¹ ç›®æ ‡ã€‚æˆ‘ä»¬åœ¨æ ‡å‡† CIL åŸºå‡†ä¸Šå¹¿æ³›è¯„ä¼°äº†æˆ‘ä»¬çš„ç®—æ³•ï¼Œå¹¶è¯æ˜äº†ä¸æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”çš„å“è¶Šæ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç±»å¢é‡å­¦ä¹ ï¼ˆCILï¼‰æ—¨åœ¨ä½¿æ¨¡å‹èƒ½å¤Ÿé€æ­¥å­¦ä¹ æ–°çš„ç±»åˆ«ï¼Œè€Œä¸ä¼šå¿˜è®°ä¹‹å‰å­¦ä¹ è¿‡çš„ç±»åˆ«ã€‚ç°æœ‰çš„CILæ–¹æ³•é€šå¸¸é¢ä¸´â€œç¾éš¾æ€§é—å¿˜â€çš„é—®é¢˜ï¼Œå³åœ¨å­¦ä¹ æ–°ä»»åŠ¡æ—¶ï¼Œæ¨¡å‹ä¼šæ˜¾è‘—é™ä½åœ¨å…ˆå‰ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚ç°æœ‰çš„æ–¹æ³•é€šå¸¸éœ€è¦å¤æ‚çš„æ¶æ„ä¿®æ”¹æˆ–æŸå¤±å‡½æ•°è®¾è®¡ï¼Œé™åˆ¶äº†å…¶é€šç”¨æ€§å’Œæ˜“ç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šM&Bçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç›´æ¥æ“ä½œæ¨¡å‹æƒé‡æ¥ä¼˜åŒ–æ¨¡å‹ï¼Œä»è€Œé¿å…ç¾éš¾æ€§é—å¿˜ã€‚å®ƒé€šè¿‡åˆå¹¶ä¸åŒä»»åŠ¡çš„æ¨¡å‹æƒé‡ï¼Œä»¥åŠçº¦æŸæƒé‡æ›´æ–°çš„å¹…åº¦ï¼Œæ¥åœ¨å­¦ä¹ æ–°çŸ¥è¯†çš„åŒæ—¶ä¿ç•™æ—§çŸ¥è¯†ã€‚è¿™ç§æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºè®¤ä¸ºå¯ä»¥é€šè¿‡åœ¨å‚æ•°ç©ºé—´ä¸­æ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„ç‚¹ï¼Œä½¿å¾—æ¨¡å‹æ—¢èƒ½é€‚åº”æ–°ä»»åŠ¡ï¼Œåˆèƒ½ä¿æŒå¯¹æ—§ä»»åŠ¡çš„è®°å¿†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šM&Bç®—æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1. **ä»»åŠ¡é—´æƒé‡åˆå¹¶**ï¼šå°†ä¹‹å‰æ‰€æœ‰ä»»åŠ¡çš„æ¨¡å‹æƒé‡è¿›è¡Œå¹³å‡ï¼Œå¾—åˆ°ä¸€ä¸ªç»Ÿä¸€çš„å…ˆå‰çŸ¥è¯†æ¨¡å‹ã€‚2. **ä»»åŠ¡å†…æƒé‡åˆå¹¶**ï¼šåœ¨å½“å‰ä»»åŠ¡çš„å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œå¯¹æ¨¡å‹å‚æ•°è¿›è¡Œåˆå¹¶ï¼Œä»¥ä¿ƒè¿›å½“å‰ä»»åŠ¡çš„å­¦ä¹ ã€‚3. **æœ‰ç•Œæ›´æ–°**ï¼šåœ¨æ›´æ–°æ¨¡å‹æƒé‡æ—¶ï¼Œé™åˆ¶æ›´æ–°çš„å¹…åº¦ï¼Œä»¥é˜²æ­¢æ¨¡å‹è¿‡åº¦åç¦»å…ˆå‰ä»»åŠ¡çš„çŸ¥è¯†ã€‚è¿™ä¸ªè¿‡ç¨‹å¯ä»¥è¿­ä»£è¿›è¡Œï¼Œç›´åˆ°æ¨¡å‹æ”¶æ•›ã€‚

**å…³é”®åˆ›æ–°**ï¼šM&Bçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç›´æ¥åœ¨æƒé‡ç©ºé—´è¿›è¡Œæ“ä½œï¼Œè€Œä¸æ˜¯åƒä¼ ç»Ÿæ–¹æ³•é‚£æ ·ä¿®æ”¹ç½‘ç»œç»“æ„æˆ–æŸå¤±å‡½æ•°ã€‚é€šè¿‡ä»»åŠ¡é—´å’Œä»»åŠ¡å†…æƒé‡åˆå¹¶ï¼Œä»¥åŠæœ‰ç•Œæ›´æ–°ï¼ŒM&Bèƒ½å¤Ÿåœ¨å­¦ä¹ æ–°çŸ¥è¯†çš„åŒæ—¶æœ‰æ•ˆåœ°ä¿ç•™æ—§çŸ¥è¯†ï¼Œä»è€Œç¼“è§£ç¾éš¾æ€§é—å¿˜ã€‚è¿™ç§æ–¹æ³•çš„å¦ä¸€ä¸ªä¼˜ç‚¹æ˜¯å®ƒå¯ä»¥å¾ˆå®¹æ˜“åœ°é›†æˆåˆ°ç°æœ‰çš„CILæ–¹æ³•ä¸­ï¼Œè€Œæ— éœ€è¿›è¡Œå¤§é‡çš„ä¿®æ”¹ã€‚

**å…³é”®è®¾è®¡**ï¼šM&Bçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1. **æƒé‡åˆå¹¶ç­–ç•¥**ï¼šä»»åŠ¡é—´æƒé‡åˆå¹¶é‡‡ç”¨ç®€å•çš„å¹³å‡ç­–ç•¥ï¼Œä»»åŠ¡å†…æƒé‡åˆå¹¶çš„å…·ä½“æ–¹æ³•æœªçŸ¥ï¼Œå¯èƒ½ä¾èµ–äºå…·ä½“ä»»åŠ¡ã€‚2. **æœ‰ç•Œæ›´æ–°çš„å®ç°**ï¼šå…·ä½“å¦‚ä½•å®ç°æœ‰ç•Œæ›´æ–°æœªçŸ¥ï¼Œå¯èƒ½æ¶‰åŠåˆ°å¯¹æƒé‡æ›´æ–°å¹…åº¦çš„è£å‰ªæˆ–æ­£åˆ™åŒ–ã€‚3. **è¶…å‚æ•°è®¾ç½®**ï¼šæƒé‡åˆå¹¶çš„æ¯”ä¾‹ã€æœ‰ç•Œæ›´æ–°çš„å¹…åº¦ç­‰è¶…å‚æ•°çš„é€‰æ‹©å¯¹æ¨¡å‹çš„æ€§èƒ½æœ‰é‡è¦å½±å“ï¼Œä½†è®ºæ–‡ä¸­æœªæåŠå…·ä½“è®¾ç½®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡åœ¨æ ‡å‡†CILåŸºå‡†æµ‹è¯•ä¸­éªŒè¯äº†M&Bæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼ŒM&Bæ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šä¼˜äºç°æœ‰çš„CILæ–¹æ³•ã€‚å…·ä½“çš„æ€§èƒ½æå‡å¹…åº¦æœªçŸ¥ï¼Œä½†æ‘˜è¦ä¸­æ˜ç¡®æŒ‡å‡ºM&Bæ–¹æ³•è¡¨ç°å‡ºâ€œå“è¶Šæ€§èƒ½â€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

M&Bæ–¹æ³•å¯åº”ç”¨äºéœ€è¦æŒç»­å­¦ä¹ æ–°çŸ¥è¯†çš„åœºæ™¯ï¼Œå¦‚æ™ºèƒ½å®¢æœã€è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ç­‰ã€‚è¿™äº›åœºæ™¯ä¸­ï¼Œæ¨¡å‹éœ€è¦ä¸æ–­é€‚åº”æ–°çš„æ•°æ®å’Œä»»åŠ¡ï¼ŒåŒæ—¶ä¿æŒå¯¹å…ˆå‰çŸ¥è¯†çš„è®°å¿†ã€‚M&Bæ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆç¼“è§£ç¾éš¾æ€§é—å¿˜ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present a novel training approach, named Merge-and-Bound (M&B) for Class Incremental Learning (CIL), which directly manipulates model weights in the parameter space for optimization. Our algorithm involves two types of weight merging: inter-task weight merging and intra-task weight merging. Inter-task weight merging unifies previous models by averaging the weights of models from all previous stages. On the other hand, intra-task weight merging facilitates the learning of current task by combining the model parameters within current stage. For reliable weight merging, we also propose a bounded update technique that aims to optimize the target model with minimal cumulative updates and preserve knowledge from previous tasks; this strategy reveals that it is possible to effectively obtain new models near old ones, reducing catastrophic forgetting. M&B is seamlessly integrated into existing CIL methods without modifying architecture components or revising learning objectives. We extensively evaluate our algorithm on standard CIL benchmarks and demonstrate superior performance compared to state-of-the-art methods.

