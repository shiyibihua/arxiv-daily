---
layout: default
title: Prune4Web: DOM Tree Pruning Programming for Web Agent
---

# Prune4Web: DOM Tree Pruning Programming for Web Agent

**arXiv**: [2511.21398v1](https://arxiv.org/abs/2511.21398) | [PDF](https://arxiv.org/pdf/2511.21398.pdf)

**ä½œè€…**: Jiayuan Zhang, Kaiquan Chen, Zhihao Lu, Enshen Zhou, Qian Yu, Jing Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPrune4Webä»¥è§£å†³ç½‘é¡µè‡ªåŠ¨åŒ–ä¸­DOMæ ‘è¿‡å¤§å¯¼è‡´çš„æ•ˆçŽ‡ä¸Žç²¾åº¦é—®é¢˜**

**å…³é”®è¯**: `ç½‘é¡µè‡ªåŠ¨åŒ–` `DOMæ ‘å‰ªæž` `ç¨‹åºåŒ–è¿‡æ»¤` `å¤§è¯­è¨€æ¨¡åž‹` `åŠ¨ä½œå®šä½` `æ•°æ®æ ‡æ³¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç½‘é¡µDOMç»“æž„åºžå¤§ï¼ˆ1ä¸‡è‡³10ä¸‡ä»¤ç‰Œï¼‰ï¼ŒçŽ°æœ‰æ–¹æ³•æ˜“ä¸¢å¤±å…³é”®ä¿¡æ¯æˆ–æ•ˆçŽ‡ä½Žä¸‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šLLMç”ŸæˆPythonè„šæœ¬åŠ¨æ€è¿‡æ»¤DOMå…ƒç´ ï¼Œå®žçŽ°ç¨‹åºåŒ–å‰ªæžï¼Œå‡å°‘å€™é€‰å…ƒç´ 25-50å€ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨ä½Žå±‚å®šä½ä»»åŠ¡ä¸­ï¼Œå‡†ç¡®çŽ‡ä»Ž46.8%æå‡è‡³88.28%ï¼Œè¾¾åˆ°å…ˆè¿›æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Web automation employs intelligent agents to execute high-level tasks by mimicking human interactions with web interfaces. Despite the capabilities of recent Large Language Model (LLM)-based web agents, navigating complex, real-world webpages efficiently remains a significant hurdle due to the prohibitively large size of Document Object Model (DOM) structures, often ranging from 10,000 to 100,000 tokens. Existing strategies typically rely on crude DOM truncation -- risking the loss of critical information -- or employ inefficient heuristics and separate ranking models, failing to achieve an optimal balance between precision and scalability. To address these challenges, we introduce Prune4Web, a novel paradigm that shifts DOM processing from resource-intensive LLM reading to efficient programmatic pruning. Central to our approach is DOM Tree Pruning Programming, where an LLM generates executable Python scoring scripts to dynamically filter DOM elements based on semantic cues from decomposed sub-tasks. This mechanism eliminates the need for LLMs to ingest raw, massive DOMs, instead delegating traversal and scoring to lightweight, interpretable programs. This methodology achieves a 25x to 50x reduction in candidate elements for grounding, thereby facilitating precise action localization while mitigating attention dilution. Furthermore, we propose a specialized data annotation pipeline and a two-turn dialogue training strategy that jointly optimizes the Planner, Programmatic Filter, and Grounder within a unified framework. Extensive experiments demonstrate state-of-the-art performance. Notably, on our low-level grounding task, Prune4Web dramatically improves accuracy from 46.8% to 88.28%, underscoring its efficacy in real-world web automation.

