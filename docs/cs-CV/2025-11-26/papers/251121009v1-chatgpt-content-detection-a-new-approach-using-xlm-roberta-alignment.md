---
layout: default
title: ChatGpt Content detection: A new approach using xlm-roberta alignment
---

# ChatGpt Content detection: A new approach using xlm-roberta alignment

**arXiv**: [2511.21009v1](https://arxiv.org/abs/2511.21009) | [PDF](https://arxiv.org/pdf/2511.21009.pdf)

**ä½œè€…**: Md Tasnin Tanvir, Dr Santanu Kumar Dash, Ishan Shahnan, Nafis Fuad, Tanvir Rahman, Abdullah Al Faisal, Asadullah Al Mamun

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽXLM-RoBERTaçš„AIç”Ÿæˆæ–‡æœ¬æ£€æµ‹æ–¹æ³•ä»¥åº”å¯¹ChatGPTå†…å®¹è¯†åˆ«æŒ‘æˆ˜**

**å…³é”®è¯**: `AIç”Ÿæˆæ–‡æœ¬æ£€æµ‹` `XLM-RoBERTaæ¨¡åž‹` `å¤šè¯­è¨€Transformer` `å›°æƒ‘åº¦ç‰¹å¾` `æ³¨æ„åŠ›æœºåˆ¶` `å­¦æœ¯è¯šä¿¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŒºåˆ†AIç”Ÿæˆä¸Žäººç±»æ’°å†™æ–‡æœ¬ï¼ŒåŒ…æ‹¬AIæ”¹å†™å†…å®¹ï¼Œä»¥ç»´æŠ¤å­¦æœ¯è¯šä¿¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨XLM-RoBERTaæ¨¡åž‹ï¼Œç»“åˆå›°æƒ‘åº¦ã€è¯­ä¹‰å’Œå¯è¯»æ€§ç‰¹å¾è¿›è¡Œæ£€æµ‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¨¡åž‹åœ¨å¤šç§æ–‡æœ¬ç±»åž‹ä¸­è¡¨çŽ°é«˜å‡†ç¡®çŽ‡ï¼Œç‰¹å¾åˆ†æžæ­ç¤ºå›°æƒ‘åº¦å’Œæ³¨æ„åŠ›ç‰¹å¾å…³é”®ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The challenge of separating AI-generated text from human-authored content is becoming more urgent as generative AI technologies like ChatGPT become more widely available. In this work, we address this issue by looking at both the detection of content that has been entirely generated by AI and the identification of human text that has been reworded by AI. In our work, a comprehensive methodology to detect AI- generated text using XLM-RoBERTa, a state-of-the-art multilingual transformer model. Our approach includes rigorous preprocessing, and feature extraction involving perplexity, semantic, and readability features. We fine-tuned the XLM-RoBERTa model on a balanced dataset of human and AI-generated texts and evaluated its performance. The model demonstrated high accuracy and robust performance across various text genres. Additionally, we conducted feature analysis to understand the model's decision-making process, revealing that perplexity and attention-based features are critical in differentiating between human and AI-generated texts. Our findings offer a valuable tool for maintaining academic integrity and contribute to the broader field of AI ethics by promoting transparency and accountability in AI systems. Future research directions include exploring other advanced models and expanding the dataset to enhance the model's generalizability.

