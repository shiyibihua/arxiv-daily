---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-11-26
---

# cs.CVï¼ˆ2025-11-26ï¼‰

ğŸ“Š å…± **28** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (10 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (8 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (5)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (3)</a>
<a href="#æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction" class="interest-badge">æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1)</a>
<a href="#æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting" class="interest-badge">æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (10 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251200086v1-multi-modal-on-device-learning-for-monocular-depth-estimation-on-ult.html">Multi-modal On-Device Learning for Monocular Depth Estimation on Ultra-low-power MCUs</a></td>
  <td>æå‡ºä¸€ç§å¤šæ¨¡æ€ç‰‡ä¸Šå­¦ä¹ æ–¹æ³•ï¼Œç”¨äºè¶…ä½åŠŸè€—MCUä¸Šçš„å•ç›®æ·±åº¦ä¼°è®¡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00086v1" onclick="toggleFavorite(this, '2512.00086v1', 'Multi-modal On-Device Learning for Monocular Depth Estimation on Ultra-low-power MCUs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251121265v1-unlocking-zero-shot-potential-of-semi-dense-image-matching-via-gauss.html">Unlocking Zero-shot Potential of Semi-dense Image Matching via Gaussian Splatting</a></td>
  <td>MatchGSï¼šåˆ©ç”¨é«˜æ–¯æº…å°„è§£é”åŠç¨ å¯†å›¾åƒåŒ¹é…çš„é›¶æ ·æœ¬æ½œåŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21265v1" onclick="toggleFavorite(this, '2511.21265v1', 'Unlocking Zero-shot Potential of Semi-dense Image Matching via Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251121317v1-httm-head-wise-temporal-token-merging-for-faster-vggt.html">HTTM: Head-wise Temporal Token Merging for Faster VGGT</a></td>
  <td>æå‡ºå¤´éƒ¨åˆ†æ—¶åºTokenåˆå¹¶(HTTM)åŠ é€ŸVGGTï¼Œç”¨äºå¿«é€Ÿ3Dåœºæ™¯é‡å»º</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21317v1" onclick="toggleFavorite(this, '2511.21317v1', 'HTTM: Head-wise Temporal Token Merging for Faster VGGT')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251121902v1-pathreasoning-a-multimodal-reasoning-agent-for-query-based-roi-navig.html">PathReasoning: A multimodal reasoning agent for query-based ROI navigation on whole-slide images</a></td>
  <td>PathReasoningï¼šä¸€ç§ç”¨äºå…¨åˆ‡ç‰‡å›¾åƒä¸ŠåŸºäºæŸ¥è¯¢çš„ROIå¯¼èˆªçš„å¤šæ¨¡æ€æ¨ç†Agent</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21902v1" onclick="toggleFavorite(this, '2511.21902v1', 'PathReasoning: A multimodal reasoning agent for query-based ROI navigation on whole-slide images')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251121339v1-surgmllmbench-a-multimodal-large-language-model-benchmark-dataset-fo.html">SurgMLLMBench: A Multimodal Large Language Model Benchmark Dataset for Surgical Scene Understanding</a></td>
  <td>SurgMLLMBenchï¼šç”¨äºæ‰‹æœ¯åœºæ™¯ç†è§£çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åŸºå‡†æ•°æ®é›†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21339v1" onclick="toggleFavorite(this, '2511.21339v1', 'SurgMLLMBench: A Multimodal Large Language Model Benchmark Dataset for Surgical Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251121367v1-endo-g2t-geometry-guided-temporally-aware-time-embedded-4dgs-for-end.html">Endo-G$^{2}$T: Geometry-Guided & Temporally Aware Time-Embedded 4DGS For Endoscopic Scenes</a></td>
  <td>Endo-GÂ²Tï¼šé’ˆå¯¹å†…çª¥é•œåœºæ™¯ï¼Œæå‡ºå‡ ä½•å¼•å¯¼å’Œæ—¶åºæ„ŸçŸ¥çš„æ—¶åºåµŒå…¥4Dé«˜æ–¯æº…å°„æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21367v1" onclick="toggleFavorite(this, '2511.21367v1', 'Endo-G$^{2}$T: Geometry-Guided & Temporally Aware Time-Embedded 4DGS For Endoscopic Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251121191v1-scenes-as-tokens-multi-scale-normal-distributions-transform-tokenize.html">Scenes as Tokens: Multi-Scale Normal Distributions Transform Tokenizer for General 3D Vision-Language Understanding</a></td>
  <td>æå‡ºNDTokenizer3Dï¼Œç”¨äºé€šç”¨3Dè§†è§‰-è¯­è¨€ç†è§£çš„å¤šå°ºåº¦NDT Tokenizer</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21191v1" onclick="toggleFavorite(this, '2511.21191v1', 'Scenes as Tokens: Multi-Scale Normal Distributions Transform Tokenizer for General 3D Vision-Language Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251121113v1-faithfusion-harmonizing-reconstruction-and-generation-via-pixel-wise.html">FaithFusion: Harmonizing Reconstruction and Generation via Pixel-wise Information Gain</a></td>
  <td>FaithFusionï¼šæå‡ºåŸºäºåƒç´ çº§ä¿¡æ¯å¢ç›Šçš„3DGS-æ‰©æ•£èåˆæ¡†æ¶ï¼Œè§£å†³å¯æ§é©¾é©¶åœºæ™¯é‡å»ºä¸ç”Ÿæˆé—®é¢˜ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21113v1" onclick="toggleFavorite(this, '2511.21113v1', 'FaithFusion: Harmonizing Reconstruction and Generation via Pixel-wise Information Gain')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251121945v1-amodalgen3d-generative-amodal-3d-object-reconstruction-from-sparse-u.html">AmodalGen3D: Generative Amodal 3D Object Reconstruction from Sparse Unposed Views</a></td>
  <td>æå‡ºAmodalGen3Dä»¥è§£å†³ç¨€ç–è§†è§’ä¸‹çš„3Dç‰©ä½“é‡å»ºé—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21945v1" onclick="toggleFavorite(this, '2511.21945v1', 'AmodalGen3D: Generative Amodal 3D Object Reconstruction from Sparse Unposed Views')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251121592v1-mogan-improving-motion-quality-in-video-diffusion-via-few-step-motio.html">MoGAN: Improving Motion Quality in Video Diffusion via Few-Step Motion Adversarial Post-Training</a></td>
  <td>MoGANï¼šé€šè¿‡å°‘é‡æ­¥æ•°çš„è¿åŠ¨å¯¹æŠ—åè®­ç»ƒæå‡è§†é¢‘æ‰©æ•£æ¨¡å‹çš„è¿åŠ¨è´¨é‡</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21592v1" onclick="toggleFavorite(this, '2511.21592v1', 'MoGAN: Improving Motion Quality in Video Diffusion via Few-Step Motion Adversarial Post-Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (8 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>11</td>
  <td><a href="./papers/251121105v1-scaling-foundation-models-for-radar-scene-understanding.html">Scaling Foundation Models for Radar Scene Understanding</a></td>
  <td>æå‡ºRadarFMé›·è¾¾åŸºç¡€æ¨¡å‹ï¼Œé€šè¿‡ç»“æ„åŒ–ç©ºé—´è¯­è¨€ç›‘ç£å®ç°åœºæ™¯ç†è§£ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21105v1" onclick="toggleFavorite(this, '2511.21105v1', 'Scaling Foundation Models for Radar Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251121574v1-multimodal-robust-prompt-distillation-for-3d-point-cloud-models.html">Multimodal Robust Prompt Distillation for 3D Point Cloud Models</a></td>
  <td>æå‡ºå¤šæ¨¡æ€é²æ£’Promptè’¸é¦æ¡†æ¶ï¼Œæå‡3Dç‚¹äº‘æ¨¡å‹åœ¨å¯¹æŠ—æ”»å‡»ä¸‹çš„é²æ£’æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21574v1" onclick="toggleFavorite(this, '2511.21574v1', 'Multimodal Robust Prompt Distillation for 3D Point Cloud Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251121298v1-pathmamba-a-hybrid-mamba-transformer-for-topologically-coherent-road.html">PathMamba: A Hybrid Mamba-Transformer for Topologically Coherent Road Segmentation in Satellite Imagery</a></td>
  <td>æå‡ºPathMambaï¼Œç”¨äºå«æ˜Ÿå›¾åƒä¸­æ‹“æ‰‘è¿ç»­çš„é“è·¯åˆ†å‰²</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21298v1" onclick="toggleFavorite(this, '2511.21298v1', 'PathMamba: A Hybrid Mamba-Transformer for Topologically Coherent Road Segmentation in Satellite Imagery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251121194v1-botaclip-contrastive-learning-for-botany-aware-representation-of-ear.html">BotaCLIP: Contrastive Learning for Botany-Aware Representation of Earth Observation Data</a></td>
  <td>BotaCLIPï¼šé€šè¿‡å¯¹æ¯”å­¦ä¹ å®ç°åœ°çƒè§‚æµ‹æ•°æ®çš„æ¤ç‰©å­¦æ„ŸçŸ¥è¡¨å¾</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21194v1" onclick="toggleFavorite(this, '2511.21194v1', 'BotaCLIP: Contrastive Learning for Botany-Aware Representation of Earth Observation Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251121097v1-clrecogeye-curriculum-learning-towards-exploiting-convolution-featur.html">CLRecogEye : Curriculum Learning towards exploiting convolution features for Dynamic Iris Recognition</a></td>
  <td>æå‡ºCLRecogEyeï¼Œåˆ©ç”¨å·ç§¯ç‰¹å¾å’Œè¯¾ç¨‹å­¦ä¹ æå‡åŠ¨æ€è™¹è†œè¯†åˆ«çš„é²æ£’æ€§ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21097v1" onclick="toggleFavorite(this, '2511.21097v1', 'CLRecogEye : Curriculum Learning towards exploiting convolution features for Dynamic Iris Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251121029v1-flowerdance-meanflow-for-efficient-and-refined-3d-dance-generation.html">FlowerDance: MeanFlow for Efficient and Refined 3D Dance Generation</a></td>
  <td>FlowerDanceï¼šç»“åˆMeanFlowçš„é«˜æ•ˆç²¾ç»†3Dèˆè¹ˆç”Ÿæˆæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21029v1" onclick="toggleFavorite(this, '2511.21029v1', 'FlowerDance: MeanFlow for Efficient and Refined 3D Dance Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251121681v1-seeing-without-pixels-perception-from-camera-trajectories.html">Seeing without Pixels: Perception from Camera Trajectories</a></td>
  <td>ä»…å‡­ç›¸æœºè½¨è¿¹æ„ŸçŸ¥è§†é¢‘å†…å®¹ï¼šæå‡ºCamFormerå¯¹æ¯”å­¦ä¹ æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21681v1" onclick="toggleFavorite(this, '2511.21681v1', 'Seeing without Pixels: Perception from Camera Trajectories')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251121422v1-e-m3rf-an-equivariant-multimodal-3d-re-assembly-framework.html">E-M3RF: An Equivariant Multimodal 3D Re-assembly Framework</a></td>
  <td>æå‡ºE-M3RFï¼Œä¸€ç§ç”¨äºå¤šæ¨¡æ€3Dé‡ç»„çš„ç­‰å˜æ¡†æ¶ï¼Œæå‡å‡ ä½•é‡å»ºç²¾åº¦ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21422v1" onclick="toggleFavorite(this, '2511.21422v1', 'E-M3RF: An Equivariant Multimodal 3D Re-assembly Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>19</td>
  <td><a href="./papers/251121365v1-pff-net-patch-feature-fitting-for-point-cloud-normal-estimation.html">PFF-Net: Patch Feature Fitting for Point Cloud Normal Estimation</a></td>
  <td>æå‡ºPFF-Netï¼Œé€šè¿‡å¤šå°ºåº¦patchç‰¹å¾æ‹Ÿåˆå®ç°é²æ£’çš„ç‚¹äº‘æ³•å‘é‡ä¼°è®¡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21365v1" onclick="toggleFavorite(this, '2511.21365v1', 'PFF-Net: Patch Feature Fitting for Point Cloud Normal Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251121237v2-3-tracer-a-tri-level-temporal-aware-framework-for-audio-forgery-dete.html">3-Tracer: A Tri-level Temporal-Aware Framework for Audio Forgery Detection and Localization</a></td>
  <td>æå‡ºT3-Tracerï¼Œç”¨äºéŸ³é¢‘ç¯¡æ”¹æ£€æµ‹ä¸å®šä½ï¼Œå®ç°å¸§ã€æ®µã€éŸ³é¢‘ä¸‰å±‚æ—¶åºåˆ†æã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21237v2" onclick="toggleFavorite(this, '2511.21237v2', '3-Tracer: A Tri-level Temporal-Aware Framework for Audio Forgery Detection and Localization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/251121490v1-merge-and-bound-direct-manipulations-on-weights-for-class-incrementa.html">Merge and Bound: Direct Manipulations on Weights for Class Incremental Learning</a></td>
  <td>æå‡ºMerge-and-Boundæ–¹æ³•ï¼Œé€šè¿‡æƒé‡ç©ºé—´æ“ä½œè§£å†³ç±»å¢é‡å­¦ä¹ ä¸­çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21490v1" onclick="toggleFavorite(this, '2511.21490v1', 'Merge and Bound: Direct Manipulations on Weights for Class Incremental Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251121192v2-when-robots-obey-the-patch-universal-transferable-patch-attacks-on-v.html">When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models</a></td>
  <td>æå‡ºUPA-RFASä»¥è§£å†³VLAæ¨¡å‹çš„é€šç”¨å¯è½¬ç§»æ”»å‡»é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21192v2" onclick="toggleFavorite(this, '2511.21192v2', 'When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/251121978v1-pat3d-physics-augmented-text-to-3d-scene-generation.html">PAT3D: Physics-Augmented Text-to-3D Scene Generation</a></td>
  <td>PAT3Dï¼šé¦–ä¸ªç‰©ç†å¢å¼ºçš„æ–‡æœ¬åˆ°3Dåœºæ™¯ç”Ÿæˆæ¡†æ¶ï¼Œå®ç°é€¼çœŸã€å¯äº¤äº’çš„åœºæ™¯åˆ›å»ºã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21978v1" onclick="toggleFavorite(this, '2511.21978v1', 'PAT3D: Physics-Augmented Text-to-3D Scene Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>24</td>
  <td><a href="./papers/251121579v2-harmony-harmonizing-audio-and-video-generation-through-cross-task-sy.html">Harmony: Harmonizing Audio and Video Generation through Cross-Task Synergy</a></td>
  <td>Harmonyï¼šé€šè¿‡è·¨ä»»åŠ¡ååŒå®ç°éŸ³è§†é¢‘ç”Ÿæˆå’Œè°ç»Ÿä¸€</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21579v2" onclick="toggleFavorite(this, '2511.21579v2', 'Harmony: Harmonizing Audio and Video Generation through Cross-Task Synergy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/251121428v1-from-observation-to-action-latent-action-based-primitive-segmentatio.html">From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings</a></td>
  <td>æå‡ºåŸºäºéšå¼åŠ¨ä½œåŸè¯­åˆ†å‰²çš„VLAé¢„è®­ç»ƒæ–¹æ³•ï¼Œç”¨äºå·¥ä¸šåœºæ™¯</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21428v1" onclick="toggleFavorite(this, '2511.21428v1', 'From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/251121051v1-muse-manipulating-unified-framework-for-synthesizing-emotions-in-ima.html">MUSE: Manipulating Unified Framework for Synthesizing Emotions in Images via Test-Time Optimization</a></td>
  <td>MUSEï¼šæå‡ºç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡æµ‹è¯•æ—¶ä¼˜åŒ–å®ç°å›¾åƒæƒ…æ„Ÿçš„ç”Ÿæˆä¸ç¼–è¾‘</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21051v1" onclick="toggleFavorite(this, '2511.21051v1', 'MUSE: Manipulating Unified Framework for Synthesizing Emotions in Images via Test-Time Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction">ğŸ”¬ æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>27</td>
  <td><a href="./papers/251120983v1-privacy-preserving-federated-vision-transformer-learning-leveraging-.html">Privacy-Preserving Federated Vision Transformer Learning Leveraging Lightweight Homomorphic Encryption in Medical AI</a></td>
  <td>æå‡ºåŸºäºåŒæ€åŠ å¯†çš„è”é‚¦Vision Transformerå­¦ä¹ æ¡†æ¶ï¼Œä¿æŠ¤åŒ»ç–—AIä¸­çš„æ‚£è€…éšç§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.20983v1" onclick="toggleFavorite(this, '2511.20983v1', 'Privacy-Preserving Federated Vision Transformer Learning Leveraging Lightweight Homomorphic Encryption in Medical AI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting">ğŸ”¬ æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>28</td>
  <td><a href="./papers/251121098v1-pygmalion-effect-in-vision-image-to-clay-translation-for-reflective-.html">Pygmalion Effect in Vision: Image-to-Clay Translation for Reflective Geometry Reconstruction</a></td>
  <td>æå‡ºåŸºäºå›¾åƒåˆ°é»åœŸè½¬æ¢çš„Pygmalionæ•ˆåº”ï¼Œç”¨äºåå°„å‡ ä½•ä½“é‡å»º</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.21098v1" onclick="toggleFavorite(this, '2511.21098v1', 'Pygmalion Effect in Vision: Image-to-Clay Translation for Reflective Geometry Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)