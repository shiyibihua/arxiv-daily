---
layout: default
title: Fix False Transparency by Noise Guided Splatting
---

# Fix False Transparency by Noise Guided Splatting

**arXiv**: [2510.15736v1](https://arxiv.org/abs/2510.15736) | [PDF](https://arxiv.org/pdf/2510.15736.pdf)

**ä½œè€…**: Aly El Hakie, Yiren Lu, Yu Yin, Michael Jenkins, Yehe Liu

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå™ªå£°å¼•å¯¼æº…å°„ä»¥è§£å†³3Dé«˜æ–¯æº…å°„ä¸­çš„è™šå‡é€æ˜é—®é¢˜**

**å…³é”®è¯**: `3Dé«˜æ–¯æº…å°„` `è™šå‡é€æ˜` `å™ªå£°å¼•å¯¼ä¼˜åŒ–` `è¡¨é¢ä¸é€æ˜åº¦` `äº¤äº’å¼æŸ¥çœ‹` `é‡å»ºè¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼š3Dé«˜æ–¯æº…å°„ä¼˜åŒ–ä¸­ç¼ºä¹è¡¨é¢ä¸é€æ˜åº¦çº¦æŸï¼Œå¯¼è‡´ä¸é€æ˜ç‰©ä½“å‡ºç°è™šå‡é€æ˜
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æ³¨å…¥ä¸é€æ˜å™ªå£°é«˜æ–¯ï¼Œé¼“åŠ±è¡¨é¢é«˜æ–¯é‡‡ç”¨æ›´é«˜ä¸é€æ˜åº¦
3. å®éªŒæˆ–æ•ˆæœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—å‡å°‘è™šå‡é€æ˜ï¼Œä¿æŒæ ‡å‡†æ¸²æŸ“æŒ‡æ ‡ç«äº‰åŠ›

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Opaque objects reconstructed by 3DGS often exhibit a falsely transparent
> surface, leading to inconsistent background and internal patterns under camera
> motion in interactive viewing. This issue stems from the ill-posed optimization
> in 3DGS. During training, background and foreground Gaussians are blended via
> alpha-compositing and optimized solely against the input RGB images using a
> photometric loss. As this process lacks an explicit constraint on surface
> opacity, the optimization may incorrectly assign transparency to opaque
> regions, resulting in view-inconsistent and falsely transparent. This issue is
> difficult to detect in standard evaluation settings but becomes particularly
> evident in object-centric reconstructions under interactive viewing. Although
> other causes of view-inconsistency have been explored recently, false
> transparency has not been explicitly identified. To the best of our knowledge,
> we are the first to identify, characterize, and develop solutions for this
> artifact, an underreported artifact in 3DGS. Our strategy, NGS, encourages
> surface Gaussians to adopt higher opacity by injecting opaque noise Gaussians
> in the object volume during training, requiring only minimal modifications to
> the existing splatting process. To quantitatively evaluate false transparency
> in static renderings, we propose a transmittance-based metric that measures the
> severity of this artifact. In addition, we introduce a customized, high-quality
> object-centric scan dataset exhibiting pronounced transparency issues, and we
> augment popular existing datasets with complementary infill noise specifically
> designed to assess the robustness of 3D reconstruction methods to false
> transparency. Experiments across multiple datasets show that NGS substantially
> reduces false transparency while maintaining competitive performance on
> standard rendering metrics, demonstrating its overall effectiveness.

