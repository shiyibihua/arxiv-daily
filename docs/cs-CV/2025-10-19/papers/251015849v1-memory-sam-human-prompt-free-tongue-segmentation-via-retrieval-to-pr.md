---
layout: default
title: Memory-SAM: Human-Prompt-Free Tongue Segmentation via Retrieval-to-Prompt
---

# Memory-SAM: Human-Prompt-Free Tongue Segmentation via Retrieval-to-Prompt

**arXiv**: [2510.15849v1](https://arxiv.org/abs/2510.15849) | [PDF](https://arxiv.org/pdf/2510.15849.pdf)

**ä½œè€…**: Joongwon Chae, Lihui Luo, Xi Yuan, Dongmei Yu, Zhenglin Chen, Lian Zhang, Peiwu Qin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMemory-SAMä»¥è‡ªåŠ¨åˆ†å‰²èˆŒè±¡ï¼Œæ— éœ€äººå·¥æç¤ºæˆ–è®­ç»ƒ**

**å…³é”®è¯**: `èˆŒåˆ†å‰²` `æ£€ç´¢åˆ°æç¤º` `è®­ç»ƒè‡ªç”±æ–¹æ³•` `DINOv3ç‰¹å¾` `FAISSæ£€ç´¢` `SAM2æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šèˆŒåˆ†å‰²éœ€å¤§é‡æ ‡æ³¨æ•°æ®ï¼ŒSAMæ¨¡åž‹ä¾èµ–äººå·¥æç¤ºã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æ£€ç´¢å…ˆä¾‹ç”Ÿæˆç‚¹æç¤ºï¼ŒæŒ‡å¯¼SAM2è‡ªåŠ¨åˆ†å‰²ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨æ··åˆæµ‹è¯•é›†ä¸ŠmIoUè¾¾0.9863ï¼Œä¼˜äºŽåŸºçº¿æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Accurate tongue segmentation is crucial for reliable TCM analysis. Supervised
> models require large annotated datasets, while SAM-family models remain
> prompt-driven. We present Memory-SAM, a training-free, human-prompt-free
> pipeline that automatically generates effective prompts from a small memory of
> prior cases via dense DINOv3 features and FAISS retrieval. Given a query image,
> mask-constrained correspondences to the retrieved exemplar are distilled into
> foreground/background point prompts that guide SAM2 without manual clicks or
> model fine-tuning. We evaluate on 600 expert-annotated images (300 controlled,
> 300 in-the-wild). On the mixed test split, Memory-SAM achieves mIoU 0.9863,
> surpassing FCN (0.8188) and a detector-to-box SAM baseline (0.1839). On
> controlled data, ceiling effects above 0.98 make small differences less
> meaningful given annotation variability, while our method shows clear gains
> under real-world conditions. Results indicate that retrieval-to-prompt enables
> data-efficient, robust segmentation of irregular boundaries in tongue imaging.
> The code is publicly available at https://github.com/jw-chae/memory-sam.

