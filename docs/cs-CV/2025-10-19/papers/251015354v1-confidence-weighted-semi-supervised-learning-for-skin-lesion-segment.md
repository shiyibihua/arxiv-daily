---
layout: default
title: Confidence-Weighted Semi-Supervised Learning for Skin Lesion Segmentation Using Hybrid CNN-Transformer Networks
---

# Confidence-Weighted Semi-Supervised Learning for Skin Lesion Segmentation Using Hybrid CNN-Transformer Networks

**arXiv**: [2510.15354v1](https://arxiv.org/abs/2510.15354) | [PDF](https://arxiv.org/pdf/2510.15354.pdf)

**ä½œè€…**: Saqib Qamar

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMIRA-UåŠç›‘ç£æ¡†æž¶ï¼Œç»“åˆä¸ç¡®å®šæ€§ä¼ªæ ‡ç­¾å’Œæ··åˆCNN-Transformerç½‘ç»œï¼Œä»¥è§£å†³çš®è‚¤ç—…å˜åˆ†å‰²ä¸­æ ‡æ³¨æ•°æ®ä¸è¶³çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `çš®è‚¤ç—…å˜åˆ†å‰²` `åŠç›‘ç£å­¦ä¹ ` `CNN-Transformeræ··åˆç½‘ç»œ` `ä¸ç¡®å®šæ€§ä¼ªæ ‡ç­¾` `å¸ˆç”Ÿæ¨¡åž‹` `åŒ»å­¦å›¾åƒåˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçš®è‚¤ç—…å˜è‡ªåŠ¨åˆ†å‰²å› æ ‡æ³¨æ•°æ®æœ‰é™è€Œå…·æŒ‘æˆ˜æ€§ï¼Œå½±å“æ—©æœŸçš®è‚¤ç™Œæ£€æµ‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä¸ç¡®å®šæ€§æ„ŸçŸ¥å¸ˆç”Ÿä¼ªæ ‡ç­¾å’ŒUå½¢CNN-Transformeræž¶æž„ï¼Œæå‡ä¼ªæ ‡ç­¾è´¨é‡å’Œè¾¹ç•Œåˆ†å‰²ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ISIC-2016å’ŒPH2æ•°æ®é›†ä¸Šï¼Œä»…ç”¨50%æ ‡æ³¨æ•°æ®ï¼ŒDSCè¾¾0.9153ï¼ŒIoUè¾¾0.8552ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Automated skin lesion segmentation through dermoscopic analysis is essential
> for early skin cancer detection, yet remains challenging due to limited
> annotated training data. We present MIRA-U, a semi-supervised framework that
> combines uncertainty-aware teacher-student pseudo-labeling with a hybrid
> CNN-Transformer architecture. Our approach employs a teacher network
> pre-trained via masked image modeling to generate confidence-weighted soft
> pseudo-labels, which guide a U-shaped CNN-Transformer student network featuring
> cross-attention skip connections. This design enhances pseudo-label quality and
> boundary delineation, surpassing reconstruction-based and CNN-only baselines,
> particularly in low-annotation regimes. Extensive evaluation on ISIC-2016 and
> PH2 datasets demonstrates superior performance, achieving a Dice Similarity
> Coefficient (DSC) of 0.9153 and Intersection over Union (IoU) of 0.8552 using
> only 50% labeled data. Code is publicly available on GitHub.

