---
layout: default
title: ClapperText: A Benchmark for Text Recognition in Low-Resource Archival Documents
---

# ClapperText: A Benchmark for Text Recognition in Low-Resource Archival Documents

**arXiv**: [2510.15557v1](https://arxiv.org/abs/2510.15557) | [PDF](https://arxiv.org/pdf/2510.15557.pdf)

**ä½œè€…**: Tingyu Lin, Marco Peer, Florian Kleber, Robert Sablatnig

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºClapperTextåŸºå‡†æ•°æ®é›†ï¼Œç”¨äºŽä½Žèµ„æºæ¡£æ¡ˆæ–‡æ¡£ä¸­çš„æ–‡æœ¬è¯†åˆ«ã€‚**

**å…³é”®è¯**: `æ–‡æœ¬è¯†åˆ«åŸºå‡†` `ä½Žèµ„æºæ¡£æ¡ˆæ–‡æ¡£` `æ‰‹å†™æ–‡æœ¬è¯†åˆ«` `è§†è§‰é€€åŒ–å¤„ç†` `å°‘æ ·æœ¬å­¦ä¹ ` `æ—‹è½¬è¾¹ç•Œæ¡†æ ‡æ³¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§£å†³è§†è§‰é€€åŒ–ã€ä½Žèµ„æºæ¡£æ¡ˆæ–‡æ¡£ä¸­æ‰‹å†™å’Œå°åˆ·æ–‡æœ¬è¯†åˆ«çš„æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽäºŒæˆ˜æ¡£æ¡ˆè§†é¢‘æž„å»ºæ•°æ®é›†ï¼Œæä¾›æ—‹è½¬è¾¹ç•Œæ¡†å’Œè¯­ä¹‰ç±»åˆ«æ ‡æ³¨ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å°‘é‡è®­ç»ƒæ•°æ®ä¸‹å¾®è°ƒæ¨¡åž‹æ˜¾è‘—æå‡æ€§èƒ½ï¼Œæ”¯æŒå°‘æ ·æœ¬å­¦ä¹ ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper presents ClapperText, a benchmark dataset for handwritten and
> printed text recognition in visually degraded and low-resource settings. The
> dataset is derived from 127 World War II-era archival video segments containing
> clapperboards that record structured production metadata such as date,
> location, and camera-operator identity. ClapperText includes 9,813 annotated
> frames and 94,573 word-level text instances, 67% of which are handwritten and
> 1,566 are partially occluded. Each instance includes transcription, semantic
> category, text type, and occlusion status, with annotations available as
> rotated bounding boxes represented as 4-point polygons to support spatially
> precise OCR applications. Recognizing clapperboard text poses significant
> challenges, including motion blur, handwriting variation, exposure
> fluctuations, and cluttered backgrounds, mirroring broader challenges in
> historical document analysis where structured content appears in degraded,
> non-standard forms. We provide both full-frame annotations and cropped word
> images to support downstream tasks. Using a consistent per-video evaluation
> protocol, we benchmark six representative recognition and seven detection
> models under zero-shot and fine-tuned conditions. Despite the small training
> set (18 videos), fine-tuning leads to substantial performance gains,
> highlighting ClapperText's suitability for few-shot learning scenarios. The
> dataset offers a realistic and culturally grounded resource for advancing
> robust OCR and document understanding in low-resource archival contexts. The
> dataset and evaluation code are available at
> https://github.com/linty5/ClapperText.

