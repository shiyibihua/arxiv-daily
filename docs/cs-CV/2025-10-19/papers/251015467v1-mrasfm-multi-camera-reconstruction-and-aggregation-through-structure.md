---
layout: default
title: MRASfM: Multi-Camera Reconstruction and Aggregation through Structure-from-Motion in Driving Scenes
---

# MRASfM: Multi-Camera Reconstruction and Aggregation through Structure-from-Motion in Driving Scenes

**arXiv**: [2510.15467v1](https://arxiv.org/abs/2510.15467) | [PDF](https://arxiv.org/pdf/2510.15467.pdf)

**ä½œè€…**: Lingfeng Xuan, Chang Nie, Yiqing Xu, Zhe Liu, Yanzi Miao, Hesheng Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMRASfMæ¡†æž¶ä»¥è§£å†³é©¾é©¶åœºæ™¯ä¸­å¤šç›¸æœºSfMçš„å¯é æ€§ã€ç²¾åº¦å’Œæ•ˆçŽ‡é—®é¢˜**

**å…³é”®è¯**: `å¤šç›¸æœºé‡å»º` `ç»“æž„ä»Žè¿åŠ¨` `é©¾é©¶åœºæ™¯` `æ†ç»‘è°ƒæ•´` `è·¯é¢é‡å»º` `å§¿æ€ä¼°è®¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šç›¸æœºç³»ç»Ÿåœ¨é©¾é©¶åœºæ™¯ä¸­SfMåº”ç”¨å­˜åœ¨å§¿æ€ä¼°è®¡ä¸å¯é ã€è·¯é¢é‡å»ºå¼‚å¸¸ç‚¹å¤šå’Œæ•ˆçŽ‡ä½Ž
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨å›ºå®šç›¸æœºå…³ç³»å¢žå¼ºå§¿æ€ä¼°è®¡ï¼Œå¹³é¢æ¨¡åž‹åŽ»é™¤è·¯é¢é”™è¯¯ç‚¹ï¼Œæ†ç»‘è°ƒæ•´ä¼˜åŒ–æ•ˆçŽ‡
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨nuScenesæ•°æ®é›†ä¸Šå®žçŽ°0.124ç»å¯¹å§¿æ€è¯¯å·®ï¼ŒéªŒè¯æ³›åŒ–æ€§å’Œé²æ£’æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Structure from Motion (SfM) estimates camera poses and reconstructs point
> clouds, forming a foundation for various tasks. However, applying SfM to
> driving scenes captured by multi-camera systems presents significant
> difficulties, including unreliable pose estimation, excessive outliers in road
> surface reconstruction, and low reconstruction efficiency. To address these
> limitations, we propose a Multi-camera Reconstruction and Aggregation
> Structure-from-Motion (MRASfM) framework specifically designed for driving
> scenes. MRASfM enhances the reliability of camera pose estimation by leveraging
> the fixed spatial relationships within the multi-camera system during the
> registration process. To improve the quality of road surface reconstruction,
> our framework employs a plane model to effectively remove erroneous points from
> the triangulated road surface. Moreover, treating the multi-camera set as a
> single unit in Bundle Adjustment (BA) helps reduce optimization variables to
> boost efficiency. In addition, MRASfM achieves multi-scene aggregation through
> scene association and assembly modules in a coarse-to-fine fashion. We deployed
> multi-camera systems on actual vehicles to validate the generalizability of
> MRASfM across various scenes and its robustness in challenging conditions
> through real-world applications. Furthermore, large-scale validation results on
> public datasets show the state-of-the-art performance of MRASfM, achieving
> 0.124 absolute pose error on the nuScenes dataset.

