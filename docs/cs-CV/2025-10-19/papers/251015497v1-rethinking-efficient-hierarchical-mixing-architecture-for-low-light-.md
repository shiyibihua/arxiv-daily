---
layout: default
title: Rethinking Efficient Hierarchical Mixing Architecture for Low-light RAW Image Enhancement
---

# Rethinking Efficient Hierarchical Mixing Architecture for Low-light RAW Image Enhancement

**arXiv**: [2510.15497v1](https://arxiv.org/abs/2510.15497) | [PDF](https://arxiv.org/pdf/2510.15497.pdf)

**ä½œè€…**: Xianmin Chen, Peiliang Huang, Longfei Han, Dingwen Zhang, Junwei Han

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHiMAæž¶æž„ä»¥é«˜æ•ˆå¢žå¼ºä½Žå…‰RAWå›¾åƒ**

**å…³é”®è¯**: `ä½Žå…‰å›¾åƒå¢žå¼º` `RAWå›¾åƒå¤„ç†` `åˆ†å±‚æ··åˆæž¶æž„` `Transformeræ¨¡å—` `Mambaæ¨¡å—` `å¤šå…ˆéªŒèžåˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä½Žå…‰RAWå›¾åƒå¢žå¼ºéœ€å¹³è¡¡é«˜è´¨é‡ä¸Žé«˜æ•ˆçŽ‡ï¼ŒçŽ°æœ‰æ–¹æ³•å­˜åœ¨å±€é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆTransformerå’ŒMambaæ¨¡å—ï¼Œå¼•å…¥LoDAå’ŒMPFæå‡å±€éƒ¨é€‚åº”ä¸Žç»†èŠ‚ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šä¼˜äºŽSOTAï¼Œå‚æ•°æ›´å°‘ï¼Œæ€§èƒ½æ›´ä¼˜ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Low-light RAW image enhancement remains a challenging task. Although numerous
> deep learning based approaches have been proposed, they still suffer from
> inherent limitations. A key challenge is how to simultaneously achieve strong
> enhancement quality and high efficiency. In this paper, we rethink the
> architecture for efficient low-light image signal processing (ISP) and
> introduce a Hierarchical Mixing Architecture (HiMA). HiMA leverages the
> complementary strengths of Transformer and Mamba modules to handle features at
> large and small scales, respectively, thereby improving efficiency while
> avoiding the ambiguities observed in prior two-stage frameworks. To further
> address uneven illumination with strong local variations, we propose Local
> Distribution Adjustment (LoDA), which adaptively aligns feature distributions
> across different local regions. In addition, to fully exploit the denoised
> outputs from the first stage, we design a Multi-prior Fusion (MPF) module that
> integrates spatial and frequency-domain priors for detail enhancement.
> Extensive experiments on multiple public datasets demonstrate that our method
> outperforms state-of-the-art approaches, achieving superior performance with
> fewer parameters. Code will be released at https://github.com/Cynicarlos/HiMA.

