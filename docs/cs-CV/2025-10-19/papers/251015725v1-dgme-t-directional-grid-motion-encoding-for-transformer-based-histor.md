---
layout: default
title: DGME-T: Directional Grid Motion Encoding for Transformer-Based Historical Camera Movement Classification
---

# DGME-T: Directional Grid Motion Encoding for Transformer-Based Historical Camera Movement Classification

**arXiv**: [2510.15725v1](https://arxiv.org/abs/2510.15725) | [PDF](https://arxiv.org/pdf/2510.15725.pdf)

**ä½œè€…**: Tingyu Lin, Armin Dadras, Florian Kleber, Robert Sablatnig

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDGME-Tæ–¹æ³•ï¼Œé€šè¿‡æ–¹å‘æ€§ç½‘æ ¼è¿åŠ¨ç¼–ç å¢žå¼ºTransformerï¼Œæå‡åŽ†å²å½±ç‰‡ç›¸æœºè¿åŠ¨åˆ†ç±»é²æ£’æ€§**

**å…³é”®è¯**: `ç›¸æœºè¿åŠ¨åˆ†ç±»` `Transformeræ¨¡åž‹` `å…‰æµç¼–ç ` `åŽ†å²å½±ç‰‡åˆ†æž` `è·¨åŸŸå­¦ä¹ ` `é²æ£’æ€§å¢žå¼º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå½“ä»£ç›¸æœºè¿åŠ¨åˆ†ç±»æ¨¡åž‹åœ¨å™ªå£°ã€ä½Žå¯¹æ¯”åº¦åŽ†å²å½±ç‰‡ä¸Šæ€§èƒ½ä¸‹é™
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå…‰æµæå–æ–¹å‘æ€§ç½‘æ ¼è¿åŠ¨ç¼–ç ï¼Œé€šè¿‡å¯å­¦ä¹ å½’ä¸€åŒ–èžåˆå±‚é›†æˆåˆ°Video Swin Transformer
3. å®žéªŒæ•ˆæžœï¼šåœ¨çŽ°ä»£å’ŒåŽ†å²æ•°æ®é›†ä¸Šå‡†ç¡®çŽ‡å’Œå®F1åˆ†æ•°å‡æ˜¾è‘—æå‡ï¼Œè·¨åŸŸå¾®è°ƒè¿›ä¸€æ­¥æ”¹å–„æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Camera movement classification (CMC) models trained on contemporary,
> high-quality footage often degrade when applied to archival film, where noise,
> missing frames, and low contrast obscure motion cues. We bridge this gap by
> assembling a unified benchmark that consolidates two modern corpora into four
> canonical classes and restructures the HISTORIAN collection into five balanced
> categories. Building on this benchmark, we introduce DGME-T, a lightweight
> extension to the Video Swin Transformer that injects directional grid motion
> encoding, derived from optical flow, via a learnable and normalised late-fusion
> layer. DGME-T raises the backbone's top-1 accuracy from 81.78% to 86.14% and
> its macro F1 from 82.08% to 87.81% on modern clips, while still improving the
> demanding World-War-II footage from 83.43% to 84.62% accuracy and from 81.72%
> to 82.63% macro F1. A cross-domain study further shows that an intermediate
> fine-tuning stage on modern data increases historical performance by more than
> five percentage points. These results demonstrate that structured motion priors
> and transformer representations are complementary and that even a small,
> carefully calibrated motion head can substantially enhance robustness in
> degraded film analysis. Related resources are available at
> https://github.com/linty5/DGME-T.

