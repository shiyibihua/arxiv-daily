---
layout: default
title: 3DPR: Single Image 3D Portrait Relight using Generative Priors
---

# 3DPR: Single Image 3D Portrait Relight using Generative Priors

**arXiv**: [2510.15846v1](https://arxiv.org/abs/2510.15846) | [PDF](https://arxiv.org/pdf/2510.15846.pdf)

**ä½œè€…**: Pramod Rao, Abhimitra Meka, Xilong Zhou, Gereon Fox, Mallikarjun B R, Fangneng Zhan, Tim Weyrich, Bernd Bickel, Hanspeter Pfister, Wojciech Matusik, Thabo Beeler, Mohamed Elgharib, Marc Habermann, Christian Theobalt

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡º3DPRæ–¹æ³•ï¼Œåˆ©ç”¨ç”Ÿæˆå…ˆéªŒä»Žå•å¼ è‚–åƒå›¾åƒå®žçŽ°é«˜è´¨é‡3Dé‡å…‰ç…§**

**å…³é”®è¯**: `3Dè‚–åƒé‡å…‰ç…§` `ç”Ÿæˆå…ˆéªŒ` `å…‰é˜¶æ®µæ•°æ®é›†` `åå°„ç½‘ç»œ` `å›¾åƒåµŒå…¥` `çŽ¯å¢ƒé‡å…‰ç…§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå•å¼ è‚–åƒå›¾åƒé‡å…‰ç…§æ˜¯æ¬ çº¦æŸé—®é¢˜ï¼Œä¼ ç»Ÿæ–¹æ³•å—é™äºŽå‡ ä½•ã€æè´¨å’Œå…‰ç…§åˆ†è§£çš„å‡è®¾
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆç”Ÿæˆå¤´éƒ¨æ¨¡åž‹çš„å‡ ä½•å…ˆéªŒå’Œå…‰é˜¶æ®µæ•°æ®è®­ç»ƒçš„åå°„ç½‘ç»œï¼Œåˆæˆé«˜ä¿çœŸOLATå›¾åƒ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨èº«ä»½ä¿æŒå’Œå…‰ç…§æ•ˆæžœï¼ˆå¦‚é•œé¢åå°„ã€è‡ªé˜´å½±ï¼‰ä¸Šä¼˜äºŽå…ˆå‰æ–¹æ³•ï¼Œæ”¯æŒç‰©ç†å‡†ç¡®çŽ¯å¢ƒé‡å…‰ç…§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Rendering novel, relit views of a human head, given a monocular portrait
> image as input, is an inherently underconstrained problem. The traditional
> graphics solution is to explicitly decompose the input image into geometry,
> material and lighting via differentiable rendering; but this is constrained by
> the multiple assumptions and approximations of the underlying models and
> parameterizations of these scene components. We propose 3DPR, an image-based
> relighting model that leverages generative priors learnt from multi-view
> One-Light-at-A-Time (OLAT) images captured in a light stage. We introduce a new
> diverse and large-scale multi-view 4K OLAT dataset of 139 subjects to learn a
> high-quality prior over the distribution of high-frequency face reflectance. We
> leverage the latent space of a pre-trained generative head model that provides
> a rich prior over face geometry learnt from in-the-wild image datasets. The
> input portrait is first embedded in the latent manifold of such a model through
> an encoder-based inversion process. Then a novel triplane-based reflectance
> network trained on our lightstage data is used to synthesize high-fidelity OLAT
> images to enable image-based relighting. Our reflectance network operates in
> the latent space of the generative head model, crucially enabling a relatively
> small number of lightstage images to train the reflectance model. Combining the
> generated OLATs according to a given HDRI environment maps yields physically
> accurate environmental relighting results. Through quantitative and qualitative
> evaluations, we demonstrate that 3DPR outperforms previous methods,
> particularly in preserving identity and in capturing lighting effects such as
> specularities, self-shadows, and subsurface scattering. Project Page:
> https://vcai.mpi-inf.mpg.de/projects/3dpr/

