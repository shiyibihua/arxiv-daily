---
layout: default
title: SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization
---

# SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization

**arXiv**: [2510.15775v1](https://arxiv.org/abs/2510.15775) | [PDF](https://arxiv.org/pdf/2510.15775.pdf)

**ä½œè€…**: Gai Zhang, Xinfeng Zhang, Lv Tang, Hongyu An, Li Zhang, Qingming Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSANRä»¥è§£å†³å…‰åœºå›¾åƒåŽ‹ç¼©ä¸­çš„åœºæ™¯å»ºæ¨¡ä¸ŽçŽ‡å¤±çœŸä¼˜åŒ–é—®é¢˜**

**å…³é”®è¯**: `å…‰åœºå›¾åƒåŽ‹ç¼©` `ç¥žç»è¡¨ç¤º` `åœºæ™¯å»ºæ¨¡` `çŽ‡å¤±çœŸä¼˜åŒ–` `é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå…‰åœºå›¾åƒé«˜ç»´æ•°æ®å¯¼è‡´åŽ‹ç¼©æ•ˆçŽ‡ä½Žï¼ŒçŽ°æœ‰æ–¹æ³•å¿½ç•¥åœºæ™¯ç»“æž„å»ºæ¨¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥åˆ†å±‚åœºæ™¯å»ºæ¨¡å—ï¼Œç»“åˆç†µçº¦æŸé‡åŒ–æ„ŸçŸ¥è®­ç»ƒå®žçŽ°ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨çŽ‡å¤±çœŸæ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æŠ€æœ¯ï¼ŒBD-rateèŠ‚çœè¾¾65.62%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Light field images capture multi-view scene information and play a crucial
> role in 3D scene reconstruction. However, their high-dimensional nature results
> in enormous data volumes, posing a significant challenge for efficient
> compression in practical storage and transmission scenarios. Although neural
> representation-based methods have shown promise in light field image
> compression, most approaches rely on direct coordinate-to-pixel mapping through
> implicit neural representation (INR), often neglecting the explicit modeling of
> scene structure. Moreover, they typically lack end-to-end rate-distortion
> optimization, limiting their compression efficiency. To address these
> limitations, we propose SANR, a Scene-Aware Neural Representation framework for
> light field image compression with end-to-end rate-distortion optimization. For
> scene awareness, SANR introduces a hierarchical scene modeling block that
> leverages multi-scale latent codes to capture intrinsic scene structures,
> thereby reducing the information gap between INR input coordinates and the
> target light field image. From a compression perspective, SANR is the first to
> incorporate entropy-constrained quantization-aware training (QAT) into neural
> representation-based light field image compression, enabling end-to-end
> rate-distortion optimization. Extensive experiment results demonstrate that
> SANR significantly outperforms state-of-the-art techniques regarding
> rate-distortion performance with a 65.62\% BD-rate saving against HEVC.

