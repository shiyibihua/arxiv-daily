---
layout: default
title: ERNet: Efficient Non-Rigid Registration Network for Point Sequences
---

# ERNet: Efficient Non-Rigid Registration Network for Point Sequences

**arXiv**: [2510.15800v1](https://arxiv.org/abs/2510.15800) | [PDF](https://arxiv.org/pdf/2510.15800.pdf)

**ä½œè€…**: Guangzhao He, Yuxi Xiao, Zhen Xu, Xiaowei Zhou, Sida Peng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºERNetä»¥é«˜æ•ˆè§£å†³ç‚¹åºåˆ—éžåˆšæ€§é…å‡†ä¸­çš„å±€éƒ¨æœ€å°å€¼å’Œè¯¯å·®ç´¯ç§¯é—®é¢˜**

**å…³é”®è¯**: `ç‚¹äº‘é…å‡†` `éžåˆšæ€§å˜å½¢` `åºåˆ—å¤„ç†` `å˜å½¢å›¾é¢„æµ‹` `æ»‘åŠ¨çª—å£ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šéžåˆšæ€§é…å‡†ä¸­å±€éƒ¨æœ€å°å€¼å’Œé•¿åºåˆ—è¯¯å·®ç´¯ç§¯é˜»ç¢å‡†ç¡®å˜å½¢ä¼°è®¡
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä¸¤é˜¶æ®µç®¡é“é¢„æµ‹å˜å½¢å›¾ï¼Œå…ˆç²—ä¼°èŠ‚ç‚¹å†æ»‘åŠ¨çª—å£ç²¾ç‚¼è½¨è¿¹
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨DeformingThings4Då’ŒD-FAUSTæ•°æ®é›†ä¸Šä¼˜äºŽSOTAï¼Œé€Ÿåº¦æå‡4å€ä»¥ä¸Š

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Registering an object shape to a sequence of point clouds undergoing
> non-rigid deformation is a long-standing challenge. The key difficulties stem
> from two factors: (i) the presence of local minima due to the non-convexity of
> registration objectives, especially under noisy or partial inputs, which
> hinders accurate and robust deformation estimation, and (ii) error accumulation
> over long sequences, leading to tracking failures. To address these challenges,
> we introduce to adopt a scalable data-driven approach and propose ERNet, an
> efficient feed-forward model trained on large deformation datasets. It is
> designed to handle noisy and partial inputs while effectively leveraging
> temporal information for accurate and consistent sequential registration. The
> key to our design is predicting a sequence of deformation graphs through a
> two-stage pipeline, which first estimates frame-wise coarse graph nodes for
> robust initialization, before refining their trajectories over time in a
> sliding-window fashion. Extensive experiments show that our proposed approach
> (i) outperforms previous state-of-the-art on both the DeformingThings4D and
> D-FAUST datasets, and (ii) achieves more than 4x speedup compared to the
> previous best, offering significant efficiency improvement.

