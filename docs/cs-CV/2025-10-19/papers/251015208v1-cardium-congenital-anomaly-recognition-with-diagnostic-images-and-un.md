---
layout: default
title: CARDIUM: Congenital Anomaly Recognition with Diagnostic Images and Unified Medical records
---

# CARDIUM: Congenital Anomaly Recognition with Diagnostic Images and Unified Medical records

**arXiv**: [2510.15208v1](https://arxiv.org/abs/2510.15208) | [PDF](https://arxiv.org/pdf/2510.15208.pdf)

**ä½œè€…**: Daniela Vega, Hannah V. Ceballos, Javier S. Vera, Santiago Rodriguez, Alejandra Perez, Angela Castillo, Maria Escobar, Dario LondoÃ±o, Luis A. Sarmiento, Camila I. Castro, Nadiezhda Rodriguez, Juan C. BriceÃ±o, Pablo ArbelÃ¡ez

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCARDIUMæ•°æ®é›†ä¸Žå¤šæ¨¡æ€Transformeræž¶æž„ï¼Œä»¥æå‡äº§å‰å…ˆå¤©æ€§å¿ƒè„ç—…æ£€æµ‹æ€§èƒ½ã€‚**

**å…³é”®è¯**: `å…ˆå¤©æ€§å¿ƒè„ç—…æ£€æµ‹` `å¤šæ¨¡æ€æ•°æ®é›†` `Transformeræž¶æž„` `è·¨æ³¨æ„åŠ›æœºåˆ¶` `äº§å‰è¯Šæ–­` `åŒ»å­¦å½±åƒåˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šäº§å‰å…ˆå¤©æ€§å¿ƒè„ç—…è¯Šæ–­æ•°æ®ç¨€ç¼ºã€ä¸å¹³è¡¡ï¼Œä¸”ç¼ºä¹å¤šæ¨¡æ€æ•´åˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºé¦–ä¸ªå…¬å¼€å¤šæ¨¡æ€æ•°æ®é›†ï¼Œèžåˆè¶…å£°å›¾åƒä¸Žä¸´åºŠè®°å½•ï¼Œé‡‡ç”¨è·¨æ³¨æ„åŠ›æœºåˆ¶èžåˆç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CARDIUMæ•°æ®é›†ä¸Šï¼Œå¤šæ¨¡æ€æ–¹æ³•æ¯”å•æ¨¡æ€æå‡11%å’Œ50%ï¼ŒF1å¾—åˆ†è¾¾79.8Â±4.8%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Prenatal diagnosis of Congenital Heart Diseases (CHDs) holds great potential
> for Artificial Intelligence (AI)-driven solutions. However, collecting
> high-quality diagnostic data remains difficult due to the rarity of these
> conditions, resulting in imbalanced and low-quality datasets that hinder model
> performance. Moreover, no public efforts have been made to integrate multiple
> sources of information, such as imaging and clinical data, further limiting the
> ability of AI models to support and enhance clinical decision-making. To
> overcome these challenges, we introduce the Congenital Anomaly Recognition with
> Diagnostic Images and Unified Medical records (CARDIUM) dataset, the first
> publicly available multimodal dataset consolidating fetal ultrasound and
> echocardiographic images along with maternal clinical records for prenatal CHD
> detection. Furthermore, we propose a robust multimodal transformer architecture
> that incorporates a cross-attention mechanism to fuse feature representations
> from image and tabular data, improving CHD detection by 11% and 50% over image
> and tabular single-modality approaches, respectively, and achieving an F1 score
> of 79.8 $\pm$ 4.8% in the CARDIUM dataset. We will publicly release our dataset
> and code to encourage further research on this unexplored field. Our dataset
> and code are available at https://github.com/BCVUniandes/Cardium, and at the
> project website https://bcv-uniandes.github.io/CardiumPage/

