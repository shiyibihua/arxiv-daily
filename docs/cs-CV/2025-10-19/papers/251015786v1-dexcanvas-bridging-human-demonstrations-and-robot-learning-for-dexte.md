---
layout: default
title: DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation
---

# DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation

**arXiv**: [2510.15786v1](https://arxiv.org/abs/2510.15786) | [PDF](https://arxiv.org/pdf/2510.15786.pdf)

**ä½œè€…**: Xinyue Xu, Jieqiang Sun, Jing, Dai, Siyuan Chen, Lanjie Ma, Ke Sun, Bin Zhao, Jianbo Yuan, Yiwen Lu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDexCanvasæ•°æ®é›†ï¼Œæ¡¥æŽ¥äººç±»æ¼”ç¤ºä¸Žæœºå™¨äººå­¦ä¹ ï¼Œç”¨äºŽçµå·§æ“ä½œä»»åŠ¡ã€‚**

**å…³é”®è¯**: `çµå·§æ“ä½œæ•°æ®é›†` `äººç±»æ¼”ç¤ºå­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ æŽ§åˆ¶` `å¤šæ¨¡æ€æ•°æ®` `æŽ¥è§¦åŠ›æŽ¨æ–­`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨äººçµå·§æ“ä½œç¼ºä¹å¤§è§„æ¨¡ã€ç³»ç»ŸåŒ–çš„äººç±»æ¼”ç¤ºæ•°æ®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºæ··åˆçœŸå®ž-åˆæˆæ•°æ®é›†ï¼Œç»“åˆå¤šæ¨¡æ€æ•°æ®å’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ•°æ®é›†æ”¯æŒç­–ç•¥è®­ç»ƒï¼Œé‡çŽ°äººç±»åŠ¨ä½œå¹¶æŽ¨æ–­æŽ¥è§¦åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present DexCanvas, a large-scale hybrid real-synthetic human manipulation
> dataset containing 7,000 hours of dexterous hand-object interactions seeded
> from 70 hours of real human demonstrations, organized across 21 fundamental
> manipulation types based on the Cutkosky taxonomy. Each entry combines
> synchronized multi-view RGB-D, high-precision mocap with MANO hand parameters,
> and per-frame contact points with physically consistent force profiles. Our
> real-to-sim pipeline uses reinforcement learning to train policies that control
> an actuated MANO hand in physics simulation, reproducing human demonstrations
> while discovering the underlying contact forces that generate the observed
> object motion. DexCanvas is the first manipulation dataset to combine
> large-scale real demonstrations, systematic skill coverage based on established
> taxonomies, and physics-validated contact annotations. The dataset can
> facilitate research in robotic manipulation learning, contact-rich control, and
> skill transfer across different hand morphologies.

