---
layout: default
title: Towards Label-Free Brain Tumor Segmentation: Unsupervised Learning with Multimodal MRI
---

# Towards Label-Free Brain Tumor Segmentation: Unsupervised Learning with Multimodal MRI

**arXiv**: [2510.15684v1](https://arxiv.org/abs/2510.15684) | [PDF](https://arxiv.org/pdf/2510.15684.pdf)

**ä½œè€…**: Gerard Comas-Quiles, Carles Garcia-Cabrera, Julia Dietlmeier, Noel E. O'Connor, Ferran Marques

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€è§†è§‰å˜æ¢å™¨è‡ªç¼–ç å™¨ï¼Œç”¨äºŽæ— ç›‘ç£è„‘è‚¿ç˜¤åˆ†å‰²ä»¥è§£å†³æ ‡æ³¨æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚**

**å…³é”®è¯**: `æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹` `è„‘è‚¿ç˜¤åˆ†å‰²` `å¤šæ¨¡æ€MRI` `è§†è§‰å˜æ¢å™¨` `é‡å»ºè¯¯å·®å›¾` `æ ‡ç­¾é«˜æ•ˆå·¥å…·`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè„‘è‚¿ç˜¤åˆ†å‰²ä¸­æ ‡æ³¨æ•°æ®æœ‰é™ã€æ˜‚è´µæˆ–ä¸ä¸€è‡´ï¼Œé™åˆ¶ç›‘ç£å­¦ä¹ å¯æ‰©å±•æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å¥åº·è„‘MRIè®­ç»ƒè‡ªç¼–ç å™¨ï¼Œé€šè¿‡é‡å»ºè¯¯å·®å›¾æ£€æµ‹è‚¿ç˜¤ï¼Œå¹¶èžåˆå¤šæ¨¡æ€MRIåºåˆ—ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨BraTS-GoATæ•°æ®é›†ä¸Šï¼ŒDiceç³»æ•°è¾¾0.437ï¼ˆå…¨è‚¿ç˜¤ï¼‰ï¼Œæ£€æµ‹çŽ‡89.4%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Unsupervised anomaly detection (UAD) presents a complementary alternative to
> supervised learning for brain tumor segmentation in magnetic resonance imaging
> (MRI), particularly when annotated datasets are limited, costly, or
> inconsistent. In this work, we propose a novel Multimodal Vision Transformer
> Autoencoder (MViT-AE) trained exclusively on healthy brain MRIs to detect and
> localize tumors via reconstruction-based error maps. This unsupervised paradigm
> enables segmentation without reliance on manual labels, addressing a key
> scalability bottleneck in neuroimaging workflows. Our method is evaluated in
> the BraTS-GoAT 2025 Lighthouse dataset, which includes various types of tumors
> such as gliomas, meningiomas, and pediatric brain tumors. To enhance
> performance, we introduce a multimodal early-late fusion strategy that
> leverages complementary information across multiple MRI sequences, and a
> post-processing pipeline that integrates the Segment Anything Model (SAM) to
> refine predicted tumor contours. Despite the known challenges of UAD,
> particularly in detecting small or non-enhancing lesions, our method achieves
> clinically meaningful tumor localization, with lesion-wise Dice Similarity
> Coefficient of 0.437 (Whole Tumor), 0.316 (Tumor Core), and 0.350 (Enhancing
> Tumor) on the test set, and an anomaly Detection Rate of 89.4% on the
> validation set. These findings highlight the potential of transformer-based
> unsupervised models to serve as scalable, label-efficient tools for
> neuro-oncological imaging.

