---
layout: default
title: "PanoGrounder: Bridging 2D and 3D with Panoramic Scene Representations for VLM-based 3D Visual Grounding"
---

# PanoGrounder: Bridging 2D and 3D with Panoramic Scene Representations for VLM-based 3D Visual Grounding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.20907" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.20907v1</a>
  <a href="https://arxiv.org/pdf/2512.20907.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.20907v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.20907v1', 'PanoGrounder: Bridging 2D and 3D with Panoramic Scene Representations for VLM-based 3D Visual Grounding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Seongmin Jung, Seongho Choi, Gunwoo Jeon, Minsu Cho, Jongwoo Lim

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-24

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PanoGrounderï¼šåˆ©ç”¨å…¨æ™¯åœºæ™¯è¡¨ç¤ºæ¡¥æ¥2Då’Œ3Dï¼Œå®ç°åŸºäºVLMçš„3Dè§†è§‰å®šä½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dè§†è§‰å®šä½` `å…¨æ™¯åœºæ™¯è¡¨ç¤º` `è§†è§‰-è¯­è¨€æ¨¡å‹` `è·¨æ¨¡æ€å­¦ä¹ ` `æœºå™¨äººæŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dè§†è§‰å®šä½æ–¹æ³•ä¾èµ–å¤§é‡3Dè§†è§‰-è¯­è¨€æ•°æ®ï¼Œä¸”æ¨¡å‹æ¨ç†èƒ½åŠ›å¼±äºå…ˆè¿›çš„VLMï¼Œæ³›åŒ–æ€§å—é™ã€‚
2. PanoGrounderåˆ©ç”¨å…¨æ™¯å›¾ä½œä¸º2Då’Œ3Dçš„æ¡¥æ¢ï¼Œç»“åˆé¢„è®­ç»ƒVLMï¼Œæå‡è§†è§‰-è¯­è¨€æ¨ç†èƒ½åŠ›å’Œæ³›åŒ–æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒPanoGrounderåœ¨ScanReferå’ŒNr3Dæ•°æ®é›†ä¸Šå–å¾—äº†SOTAç»“æœï¼Œå¹¶å¯¹æœªè§è¿‡çš„3Dæ•°æ®è¡¨ç°å‡ºæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

3Dè§†è§‰å®šä½ï¼ˆ3DVGï¼‰æ˜¯è§†è§‰-è¯­è¨€æ„ŸçŸ¥åˆ°æœºå™¨äººæŠ€æœ¯çš„å…³é”®æ¡¥æ¢ï¼Œå®ƒéœ€è¦è¯­è¨€ç†è§£å’Œ3Dåœºæ™¯æ¨ç†èƒ½åŠ›ã€‚ä¼ ç»Ÿçš„ç›‘ç£æ¨¡å‹åˆ©ç”¨æ˜¾å¼çš„3Då‡ ä½•ä¿¡æ¯ï¼Œä½†ç”±äº3Dè§†è§‰-è¯­è¨€æ•°æ®é›†çš„ç¨€ç¼ºä»¥åŠä¸ç°ä»£è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ç›¸æ¯”æœ‰é™çš„æ¨ç†èƒ½åŠ›ï¼Œå…¶æ³›åŒ–èƒ½åŠ›å—åˆ°é™åˆ¶ã€‚æˆ‘ä»¬æå‡ºäº†PanoGrounderï¼Œä¸€ä¸ªé€šç”¨çš„3DVGæ¡†æ¶ï¼Œå®ƒå°†å¤šæ¨¡æ€å…¨æ™¯è¡¨ç¤ºä¸é¢„è®­ç»ƒçš„2D VLMç›¸ç»“åˆï¼Œä»¥å®ç°å¼ºå¤§çš„è§†è§‰-è¯­è¨€æ¨ç†ã€‚å…¨æ™¯æ¸²æŸ“å›¾ï¼Œè¾…ä»¥3Dè¯­ä¹‰å’Œå‡ ä½•ç‰¹å¾ï¼Œä½œä¸º2Då’Œ3Dä¹‹é—´çš„ä¸­é—´è¡¨ç¤ºï¼Œå¹¶æä¾›ä¸¤ä¸ªä¸»è¦ä¼˜åŠ¿ï¼šï¼ˆiï¼‰å®ƒä»¬å¯ä»¥é€šè¿‡æœ€å°çš„é€‚é…ç›´æ¥è¾“å…¥åˆ°VLMä¸­ï¼Œä»¥åŠï¼ˆiiï¼‰ç”±äºå…¶360åº¦è§†é‡ï¼Œå®ƒä»¬ä¿ç•™äº†é•¿ç¨‹å¯¹è±¡åˆ°å¯¹è±¡çš„å…³ç³»ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªä¸‰é˜¶æ®µæµç¨‹ï¼Œè¯¥æµç¨‹è€ƒè™‘åœºæ™¯å¸ƒå±€å’Œå‡ ä½•å½¢çŠ¶æ¥æ”¾ç½®ä¸€ç»„ç´§å‡‘çš„å…¨æ™¯è§†ç‚¹ï¼Œä½¿ç”¨VLMåœ¨æ¯ä¸ªå…¨æ™¯æ¸²æŸ“å›¾ä¸Šå®šä½æ–‡æœ¬æŸ¥è¯¢ï¼Œå¹¶é€šè¿‡æå‡å°†æ¯ä¸ªè§†ç‚¹çš„é¢„æµ‹èåˆä¸ºå•ä¸ª3Dè¾¹ç•Œæ¡†ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ScanReferå’ŒNr3Dä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶å±•ç¤ºäº†å¯¹æœªè§è¿‡çš„3Dæ•°æ®é›†å’Œæ–‡æœ¬é‡Šä¹‰çš„å“è¶Šæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼š3Dè§†è§‰å®šä½æ—¨åœ¨æ ¹æ®ç»™å®šçš„æ–‡æœ¬æè¿°ï¼Œåœ¨3Dåœºæ™¯ä¸­å®šä½ç›®æ ‡ç‰©ä½“ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå¤§é‡çš„3Dè§†è§‰-è¯­è¨€æ ‡æ³¨æ•°æ®ï¼Œå¹¶ä¸”æ¨¡å‹çš„è§†è§‰-è¯­è¨€æ¨ç†èƒ½åŠ›ç›¸å¯¹è¾ƒå¼±ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥é€‚åº”æ–°çš„åœºæ™¯å’Œæ–‡æœ¬æè¿°æ–¹å¼ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPanoGrounderçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å…¨æ™¯å›¾ä½œä¸º2Då’Œ3Dåœºæ™¯ä¹‹é—´çš„æ¡¥æ¢ã€‚é€šè¿‡å°†3Dåœºæ™¯æ¸²æŸ“æˆå¤šä¸ªå…¨æ™¯å›¾ï¼Œå¹¶ç»“åˆ3Dè¯­ä¹‰å’Œå‡ ä½•ä¿¡æ¯ï¼Œå¯ä»¥å……åˆ†åˆ©ç”¨é¢„è®­ç»ƒçš„2D VLMå¼ºå¤§çš„è§†è§‰-è¯­è¨€æ¨ç†èƒ½åŠ›ã€‚å…¨æ™¯å›¾çš„360åº¦è§†é‡ä¹Ÿæœ‰åŠ©äºæ•æ‰åœºæ™¯ä¸­ç‰©ä½“ä¹‹é—´çš„é•¿ç¨‹å…³ç³»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPanoGrounderåŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1) å…¨æ™¯è§†ç‚¹é€‰æ‹©ï¼šæ ¹æ®åœºæ™¯å¸ƒå±€å’Œå‡ ä½•ä¿¡æ¯ï¼Œé€‰æ‹©ä¸€ç»„ç´§å‡‘çš„å…¨æ™¯è§†ç‚¹ã€‚2) åŸºäºVLMçš„å…¨æ™¯å›¾å®šä½ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„2D VLMåœ¨æ¯ä¸ªå…¨æ™¯å›¾ä¸Šå®šä½æ–‡æœ¬æŸ¥è¯¢æ‰€æŒ‡ä»£çš„ç‰©ä½“ã€‚3) 3Dè¾¹ç•Œæ¡†èåˆï¼šå°†æ¯ä¸ªè§†ç‚¹çš„é¢„æµ‹ç»“æœé€šè¿‡æå‡æ“ä½œèåˆä¸ºå•ä¸ª3Dè¾¹ç•Œæ¡†ã€‚

**å…³é”®åˆ›æ–°**ï¼šPanoGrounderçš„å…³é”®åˆ›æ–°åœ¨äºä½¿ç”¨å…¨æ™¯å›¾ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œæ¡¥æ¥äº†2Då’Œ3Dåœºæ™¯ï¼Œä»è€Œèƒ½å¤Ÿå……åˆ†åˆ©ç”¨é¢„è®­ç»ƒçš„2D VLMçš„å¼ºå¤§èƒ½åŠ›ã€‚ä¸ç›´æ¥åœ¨3Dæ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥æ˜¾è‘—æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šå…¨æ™¯è§†ç‚¹çš„é€‰æ‹©ç­–ç•¥è€ƒè™‘äº†åœºæ™¯çš„å‡ ä½•ä¿¡æ¯ï¼Œä»¥ç¡®ä¿æ¯ä¸ªè§†ç‚¹éƒ½èƒ½è¦†ç›–åœºæ™¯ä¸­çš„å…³é”®åŒºåŸŸã€‚åœ¨å…¨æ™¯å›¾å®šä½é˜¶æ®µï¼Œä½¿ç”¨äº†é¢„è®­ç»ƒçš„CLIPæ¨¡å‹è¿›è¡Œè§†è§‰-è¯­è¨€åŒ¹é…ã€‚åœ¨3Dè¾¹ç•Œæ¡†èåˆé˜¶æ®µï¼Œä½¿ç”¨äº†åŠ æƒå¹³å‡çš„æ–¹æ³•ï¼Œæ ¹æ®æ¯ä¸ªè§†ç‚¹çš„ç½®ä¿¡åº¦å¯¹é¢„æµ‹ç»“æœè¿›è¡ŒåŠ æƒã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.20907v1/fig/hook.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.20907v1/fig/pipeline.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.20907v1/fig/adapter.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

PanoGrounderåœ¨ScanReferå’ŒNr3Dæ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„ç»“æœï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„3Dè§†è§‰å®šä½æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æœªè§è¿‡çš„3Dæ•°æ®é›†å’Œæ–‡æœ¬é‡Šä¹‰ä¸Šè¡¨ç°å‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåˆ©ç”¨å…¨æ™¯å›¾ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œå¯ä»¥æœ‰æ•ˆæå‡3Dè§†è§‰å®šä½çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PanoGrounderåœ¨æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½å®¶å±…ã€å¢å¼ºç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œæœºå™¨äººå¯ä»¥æ ¹æ®ç”¨æˆ·çš„è¯­éŸ³æŒ‡ä»¤ï¼Œåœ¨å¤æ‚çš„å®¤å†…ç¯å¢ƒä¸­å®šä½å¹¶æŠ“å–ç›®æ ‡ç‰©ä½“ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæå‡æœºå™¨äººä¸äººç±»çš„äº¤äº’èƒ½åŠ›ï¼Œå¹¶ä¿ƒè¿›æœºå™¨äººæŠ€æœ¯åœ¨å®é™…ç”Ÿæ´»ä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> 3D Visual Grounding (3DVG) is a critical bridge from vision-language perception to robotics, requiring both language understanding and 3D scene reasoning. Traditional supervised models leverage explicit 3D geometry but exhibit limited generalization, owing to the scarcity of 3D vision-language datasets and the limited reasoning capabilities compared to modern vision-language models (VLMs). We propose PanoGrounder, a generalizable 3DVG framework that couples multi-modal panoramic representation with pretrained 2D VLMs for strong vision-language reasoning. Panoramic renderings, augmented with 3D semantic and geometric features, serve as an intermediate representation between 2D and 3D, and offer two major benefits: (i) they can be directly fed to VLMs with minimal adaptation and (ii) they retain long-range object-to-object relations thanks to their 360-degree field of view. We devise a three-stage pipeline that places a compact set of panoramic viewpoints considering the scene layout and geometry, grounds a text query on each panoramic rendering with a VLM, and fuses per-view predictions into a single 3D bounding box via lifting. Our approach achieves state-of-the-art results on ScanRefer and Nr3D, and demonstrates superior generalization to unseen 3D datasets and text rephrasings.

