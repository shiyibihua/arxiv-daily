---
layout: default
title: "TICON: A Slide-Level Tile Contextualizer for Histopathology Representation Learning"
---

# TICON: A Slide-Level Tile Contextualizer for Histopathology Representation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.21331" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.21331v1</a>
  <a href="https://arxiv.org/pdf/2512.21331.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.21331v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.21331v1', 'TICON: A Slide-Level Tile Contextualizer for Histopathology Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Varun Belagali, Saarthak Kapse, Pierre Marza, Srijan Das, Zilinghan Li, SofiÃ¨ne Boutaj, Pushpak Pati, Srikar Yellapragada, Tarak Nath Nandi, Ravi K Madduri, Joel Saltz, Prateek Prasanna, Stergios Christodoulidis Maria Vakalopoulou, Dimitris Samaras

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-24

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**TICONï¼šä¸€ç§ç”¨äºç»„ç»‡ç—…ç†å­¦è¡¨å¾å­¦ä¹ çš„åˆ‡ç‰‡çº§ä¸Šä¸‹æ–‡å»ºæ¨¡æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç»„ç»‡ç—…ç†å­¦` `å…¨åˆ‡ç‰‡å›¾åƒ` `è¡¨å¾å­¦ä¹ ` `Transformer` `ä¸Šä¸‹æ–‡å»ºæ¨¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹WSIä¸­åˆ‡ç‰‡é—´ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æœ‰æ•ˆå»ºæ¨¡ï¼Œé™åˆ¶äº†ç—…ç†å›¾åƒåˆ†æçš„æ€§èƒ½ã€‚
2. TICONé€šè¿‡Transformeræ¶æ„ï¼Œå¯¹åˆ‡ç‰‡è¡¨å¾è¿›è¡Œä¸Šä¸‹æ–‡å»ºæ¨¡ï¼Œä»è€Œæ•è·åˆ‡ç‰‡é—´çš„ä¾èµ–å…³ç³»å’Œå…¨å±€ä¿¡æ¯ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒTICONåœ¨å¤šä¸ªåˆ‡ç‰‡å’ŒWSIçº§åˆ«çš„ç—…ç†å›¾åƒåˆ†æä»»åŠ¡ä¸Šï¼Œå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§å‹å…¨åˆ‡ç‰‡å›¾åƒ(WSI)ä¸­ï¼Œå°åˆ‡ç‰‡çš„åˆ¤è¯»é€šå¸¸éœ€è¦æ›´å¤§çš„å›¾åƒä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬æå‡ºäº†TICONï¼Œä¸€ç§åŸºäºTransformerçš„åˆ‡ç‰‡è¡¨å¾ä¸Šä¸‹æ–‡å»ºæ¨¡å™¨ï¼Œä¸ºè®¡ç®—ç—…ç†å­¦ä¸­çš„â€œä»»ä½•â€åº”ç”¨ç”Ÿæˆä¸°å¯Œçš„ã€ä¸Šä¸‹æ–‡ç›¸å…³çš„åµŒå…¥ã€‚æ ‡å‡†çš„åŸºäºåˆ‡ç‰‡ç¼–ç å™¨çš„æµç¨‹ï¼Œæå–çš„åˆ‡ç‰‡åµŒå…¥ç¼ºä¹ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ— æ³•å¯¹å±€éƒ¨å’Œå…¨å±€ä»»åŠ¡è‡³å…³é‡è¦çš„åˆ‡ç‰‡çº§ä¿¡æ¯è¿›è¡Œå»ºæ¨¡ã€‚æ­¤å¤–ï¼Œä¸åŒçš„åˆ‡ç‰‡ç¼–ç å™¨æ“…é•¿ä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å‹æ¥å¯¹æ¥è‡ªâ€œä»»ä½•â€åˆ‡ç‰‡çº§åŸºç¡€æ¨¡å‹çš„åµŒå…¥è¿›è¡Œä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚TICONé€šè¿‡ä¸€ä¸ªå…±äº«çš„ç¼–ç å™¨æ¥æ»¡è¶³è¿™ä¸€éœ€æ±‚ï¼Œè¯¥ç¼–ç å™¨ä½¿ç”¨æ©ç å»ºæ¨¡ç›®æ ‡è¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥åŒæ—¶ç»Ÿä¸€å’Œä¸Šä¸‹æ–‡å»ºæ¨¡æ¥è‡ªä¸åŒåˆ‡ç‰‡çº§ç—…ç†å­¦åŸºç¡€æ¨¡å‹çš„è¡¨å¾ã€‚å®éªŒè¡¨æ˜ï¼ŒTICONä¸Šä¸‹æ–‡åµŒå…¥æ˜¾è‘—æé«˜äº†å„ç§ä»»åŠ¡çš„æ€§èƒ½ï¼Œåœ¨åˆ‡ç‰‡çº§åŸºå‡†(HEST-Benchã€THUNDERã€CATCH)å’Œåˆ‡ç‰‡çº§åŸºå‡†(Patho-Bench)ä¸Šå»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›ç»“æœã€‚æœ€åï¼Œæˆ‘ä»¬ä»…ä½¿ç”¨1.1ä¸‡å¼ WSIåœ¨TICONä¸Šé¢„è®­ç»ƒäº†ä¸€ä¸ªèšåˆå™¨ï¼Œå½¢æˆäº†ä¸€ä¸ªåˆ‡ç‰‡çº§åŸºç¡€æ¨¡å‹ï¼Œå…¶æ€§èƒ½ä¼˜äºä½¿ç”¨é«˜è¾¾35ä¸‡å¼ WSIé¢„è®­ç»ƒçš„æœ€å…ˆè¿›çš„åˆ‡ç‰‡çº§åŸºç¡€æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºåˆ‡ç‰‡ç¼–ç å™¨çš„ç—…ç†å›¾åƒåˆ†ææ–¹æ³•ï¼Œé€šå¸¸å°†åˆ‡ç‰‡ä»å…¶åŸå§‹WSIä¸Šä¸‹æ–‡ä¸­å‰¥ç¦»ï¼Œå¯¼è‡´æ— æ³•æœ‰æ•ˆåˆ©ç”¨åˆ‡ç‰‡é—´çš„ç©ºé—´å…³ç³»å’Œå…¨å±€ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œä¸åŒçš„åˆ‡ç‰‡ç¼–ç å™¨é€‚ç”¨äºä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡ï¼Œç¼ºä¹ä¸€ä¸ªé€šç”¨çš„ä¸Šä¸‹æ–‡å»ºæ¨¡æ¡†æ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTICONçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Transformeræ¶æ„å¯¹åˆ‡ç‰‡è¡¨å¾è¿›è¡Œä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚é€šè¿‡å°†åˆ‡ç‰‡è¡¨å¾è§†ä¸ºåºåˆ—ï¼Œå¹¶åˆ©ç”¨Transformerçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ŒTICONèƒ½å¤Ÿæ•è·åˆ‡ç‰‡é—´çš„ä¾èµ–å…³ç³»ï¼Œä»è€Œç”Ÿæˆæ›´å…·ä¿¡æ¯é‡çš„ä¸Šä¸‹æ–‡åµŒå…¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTICONçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šåˆ‡ç‰‡ç¼–ç å™¨ã€Transformerä¸Šä¸‹æ–‡å»ºæ¨¡å™¨å’Œä¸‹æ¸¸ä»»åŠ¡é€‚é…å™¨ã€‚é¦–å…ˆï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„åˆ‡ç‰‡ç¼–ç å™¨æå–æ¯ä¸ªåˆ‡ç‰‡çš„è¡¨å¾ã€‚ç„¶åï¼Œå°†è¿™äº›è¡¨å¾è¾“å…¥åˆ°Transformerä¸Šä¸‹æ–‡å»ºæ¨¡å™¨ä¸­ï¼Œä»¥ç”Ÿæˆä¸Šä¸‹æ–‡åµŒå…¥ã€‚æœ€åï¼Œå°†ä¸Šä¸‹æ–‡åµŒå…¥è¾“å…¥åˆ°ä¸‹æ¸¸ä»»åŠ¡é€‚é…å™¨ä¸­ï¼Œä»¥å®Œæˆç‰¹å®šçš„ç—…ç†å›¾åƒåˆ†æä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šTICONçš„å…³é”®åˆ›æ–°åœ¨äºå…¶Transformerä¸Šä¸‹æ–‡å»ºæ¨¡å™¨ã€‚è¯¥æ¨¡å—èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•è·åˆ‡ç‰‡é—´çš„ä¾èµ–å…³ç³»ï¼Œä»è€Œç”Ÿæˆæ›´å…·ä¿¡æ¯é‡çš„ä¸Šä¸‹æ–‡åµŒå…¥ã€‚æ­¤å¤–ï¼ŒTICONé‡‡ç”¨äº†ä¸€ç§æ©ç å»ºæ¨¡ç›®æ ‡è¿›è¡Œé¢„è®­ç»ƒï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´é²æ£’çš„è¡¨å¾ã€‚

**å…³é”®è®¾è®¡**ï¼šTICONä½¿ç”¨æ ‡å‡†çš„Transformeræ¶æ„ä½œä¸ºä¸Šä¸‹æ–‡å»ºæ¨¡å™¨ã€‚ä¸ºäº†æé«˜è®­ç»ƒæ•ˆç‡ï¼ŒTICONé‡‡ç”¨äº†ç›¸å¯¹ä½ç½®ç¼–ç ã€‚æ­¤å¤–ï¼ŒTICONä½¿ç”¨AdamWä¼˜åŒ–å™¨è¿›è¡Œè®­ç»ƒï¼Œå¹¶é‡‡ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡ç­–ç•¥ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.21331v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.21331v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.21331v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

TICONåœ¨å¤šä¸ªç—…ç†å›¾åƒåˆ†æåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨HEST-Benchã€THUNDERå’ŒCATCHç­‰åˆ‡ç‰‡çº§åŸºå‡†æµ‹è¯•ä¸­ï¼ŒTICONå‡å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚æ­¤å¤–ï¼ŒTICONåœ¨Patho-Benchåˆ‡ç‰‡çº§åŸºå‡†æµ‹è¯•ä¸­ä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œç”šè‡³è¶…è¶Šäº†ä½¿ç”¨æ›´å¤§è§„æ¨¡æ•°æ®é›†é¢„è®­ç»ƒçš„æ¨¡å‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TICONå¯å¹¿æ³›åº”ç”¨äºè®¡ç®—ç—…ç†å­¦é¢†åŸŸï¼Œä¾‹å¦‚è‚¿ç˜¤äºšå‹åˆ†ç±»ã€æ·‹å·´ç»“è½¬ç§»æ£€æµ‹ã€å…ç–«ç»„åŒ–è¯„åˆ†ç­‰ã€‚é€šè¿‡æä¾›æ›´å…·ä¸Šä¸‹æ–‡ä¿¡æ¯çš„åˆ‡ç‰‡è¡¨å¾ï¼ŒTICONèƒ½å¤Ÿæé«˜ç—…ç†å›¾åƒåˆ†æçš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œè¾…åŠ©ç—…ç†åŒ»ç”Ÿè¿›è¡Œè¯Šæ–­å’Œæ²»ç–—å†³ç­–ï¼Œå…·æœ‰é‡è¦çš„ä¸´åºŠåº”ç”¨ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The interpretation of small tiles in large whole slide images (WSI) often needs a larger image context. We introduce TICON, a transformer-based tile representation contextualizer that produces rich, contextualized embeddings for ''any'' application in computational pathology. Standard tile encoder-based pipelines, which extract embeddings of tiles stripped from their context, fail to model the rich slide-level information essential for both local and global tasks. Furthermore, different tile-encoders excel at different downstream tasks. Therefore, a unified model is needed to contextualize embeddings derived from ''any'' tile-level foundation model. TICON addresses this need with a single, shared encoder, pretrained using a masked modeling objective to simultaneously unify and contextualize representations from diverse tile-level pathology foundation models. Our experiments demonstrate that TICON-contextualized embeddings significantly improve performance across many different tasks, establishing new state-of-the-art results on tile-level benchmarks (i.e., HEST-Bench, THUNDER, CATCH) and slide-level benchmarks (i.e., Patho-Bench). Finally, we pretrain an aggregator on TICON to form a slide-level foundation model, using only 11K WSIs, outperforming SoTA slide-level foundation models pretrained with up to 350K WSIs.

