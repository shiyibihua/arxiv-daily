---
layout: default
title: EasyARC: Evaluating Vision Language Models on True Visual Reasoning
---

# EasyARC: Evaluating Vision Language Models on True Visual Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11595" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11595v1</a>
  <a href="https://arxiv.org/pdf/2506.11595.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11595v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11595v1', 'EasyARC: Evaluating Vision Language Models on True Visual Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mert Unsal, Aylin Akkus

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

**å¤‡æ³¨**: CVPR2025 Workshop on Test-time Scaling for Computer Vision

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEasyARCä»¥è§£å†³å¤šæ¨¡æ€è§†è§‰æ¨ç†è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨ç†` `è§†è§‰-è¯­è¨€æ¨¡å‹` `ç¨‹åºç”Ÿæˆ` `è‡ªæˆ‘çº æ­£` `åŸºå‡†æµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸»è¦é›†ä¸­åœ¨è§†è§‰æå–ä¸æ–‡æœ¬æ¨ç†çš„ç»“åˆï¼Œç¼ºä¹å¯¹å¤æ‚è§†è§‰ä¸è¯­è¨€äº¤äº’çš„çœŸå®æ¨ç†è¯„ä¼°ã€‚
2. æœ¬æ–‡æå‡ºEasyARCï¼Œä¸€ä¸ªç¨‹åºç”Ÿæˆçš„è§†è§‰-è¯­è¨€åŸºå‡†ï¼Œè¦æ±‚å¤šå›¾åƒã€å¤šæ­¥éª¤æ¨ç†ï¼Œå¹¶å…·å¤‡è‡ªæˆ‘çº æ­£èƒ½åŠ›ã€‚
3. é€šè¿‡å¯¹æœ€å…ˆè¿›çš„è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œåˆ†æå…¶å¤±è´¥æ¨¡å¼ï¼ŒEasyARCä¸ºçœŸå®æ¨ç†è¯„ä¼°è®¾å®šäº†æ–°æ ‡å‡†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºè¿‘æœŸè¯­è¨€æ¨ç†æ¨¡å‹çš„è¿›å±•ï¼Œæœ¬æ–‡æ¢è®¨äº†æ•´åˆè§†è§‰ä¸æ–‡æœ¬çš„å¤šæ¨¡æ€æ¨ç†ã€‚ç°æœ‰çš„å¤šæ¨¡æ€åŸºå‡†ä¸»è¦æµ‹è¯•è§†è§‰æå–ä¸æ–‡æœ¬æ¨ç†çš„ç»“åˆï¼Œç¼ºä¹æ›´å¤æ‚çš„è§†è§‰ä¸è¯­è¨€ä¹‹é—´çš„çœŸå®æ¨ç†ã€‚å—ARCæŒ‘æˆ˜çš„å¯å‘ï¼Œæˆ‘ä»¬å¼•å…¥äº†EasyARCï¼Œè¿™æ˜¯ä¸€ä¸ªéœ€è¦å¤šå›¾åƒã€å¤šæ­¥éª¤æ¨ç†å’Œè‡ªæˆ‘çº æ­£çš„è§†è§‰-è¯­è¨€åŸºå‡†ã€‚EasyARCæ˜¯ç¨‹åºç”Ÿæˆçš„ï¼Œå®Œå…¨å¯éªŒè¯ä¸”å¯æ‰©å±•ï¼Œé€‚åˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç®¡é“ã€‚ç”Ÿæˆå™¨ç»“åˆäº†é€æ­¥éš¾åº¦çº§åˆ«ï¼Œä½¿å¾—åœ¨ä»»åŠ¡ç±»å‹å’Œå¤æ‚æ€§ä¸Šè¿›è¡Œç»“æ„åŒ–è¯„ä¼°æˆä¸ºå¯èƒ½ã€‚æˆ‘ä»¬å¯¹æœ€å…ˆè¿›çš„è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œå¹¶åˆ†æäº†å®ƒä»¬çš„å¤±è´¥æ¨¡å¼ã€‚æˆ‘ä»¬è®¤ä¸ºEasyARCä¸ºè¯„ä¼°çœŸå®æ¨ç†å’Œæµ‹è¯•æ—¶æ‰©å±•èƒ½åŠ›è®¾å®šäº†æ–°çš„æ ‡å‡†ï¼Œå¹¶å¼€æºäº†æˆ‘ä»¬çš„åŸºå‡†æ•°æ®é›†å’Œè¯„ä¼°ä»£ç ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€åŸºå‡†åœ¨çœŸå®è§†è§‰æ¨ç†è¯„ä¼°æ–¹é¢çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•å¤šé›†ä¸­äºç®€å•çš„è§†è§‰æå–ä¸æ–‡æœ¬æ¨ç†çš„ç»“åˆï¼Œç¼ºä¹å¯¹å¤æ‚äº¤äº’çš„è€ƒé‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEasyARCé€šè¿‡å¼•å…¥å¤šå›¾åƒå’Œå¤šæ­¥éª¤æ¨ç†çš„è¦æ±‚ï¼Œç»“åˆè‡ªæˆ‘çº æ­£æœºåˆ¶ï¼Œæä¾›äº†ä¸€ä¸ªæ›´å…·æŒ‘æˆ˜æ€§çš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨æ¨åŠ¨è§†è§‰-è¯­è¨€æ¨¡å‹çš„çœŸå®æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEasyARCçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç”Ÿæˆå™¨å’Œè¯„ä¼°æ¨¡å—ã€‚ç”Ÿæˆå™¨è´Ÿè´£åˆ›å»ºå¤šæ ·åŒ–çš„ä»»åŠ¡åœºæ™¯ï¼Œè¯„ä¼°æ¨¡å—åˆ™ç”¨äºæµ‹è¯•æ¨¡å‹åœ¨è¿™äº›åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚ç”Ÿæˆå™¨è®¾è®¡äº†é€æ­¥å¢åŠ éš¾åº¦çš„ä»»åŠ¡ï¼Œä»¥ä¾¿è¿›è¡Œç»“æ„åŒ–è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šEasyARCçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ç¨‹åºç”Ÿæˆçš„ç‰¹æ€§å’Œè‡ªæˆ‘çº æ­£æœºåˆ¶ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„é™æ€è¯„ä¼°æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚é€šè¿‡åŠ¨æ€ç”Ÿæˆä»»åŠ¡ï¼ŒEasyARCèƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡è¿‡ç¨‹ä¸­ï¼ŒEasyARCé‡‡ç”¨äº†å¤šå±‚æ¬¡çš„éš¾åº¦è®¾ç½®ï¼Œç¡®ä¿æ¨¡å‹åœ¨ä¸åŒå¤æ‚æ€§ä»»åŠ¡ä¸­çš„è¡¨ç°å¾—åˆ°å…¨é¢è¯„ä¼°ã€‚æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„çš„é€‰æ‹©ä¹Ÿç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥é€‚åº”å¤šæ¨¡æ€è¾“å…¥çš„ç‰¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒEasyARCå¯¹å¤šç§æœ€å…ˆè¿›çš„è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œç»“æœæ˜¾ç¤ºè¿™äº›æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚é€šè¿‡å¼•å…¥å¤šæ­¥éª¤æ¨ç†å’Œè‡ªæˆ‘çº æ­£æœºåˆ¶ï¼ŒEasyARCèƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EasyARCçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€è‡ªåŠ¨å›¾åƒæè¿°ç”Ÿæˆä»¥åŠäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡è§†è§‰-è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼ŒEasyARCèƒ½å¤Ÿæ¨åŠ¨æ›´æ™ºèƒ½çš„å¤šæ¨¡æ€åº”ç”¨çš„å‘å±•ï¼Œæœªæ¥å¯èƒ½åœ¨æ•™è‚²ã€åŒ»ç–—å’Œå¨±ä¹ç­‰è¡Œä¸šäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Building on recent advances in language-based reasoning models, we explore multimodal reasoning that integrates vision and text. Existing multimodal benchmarks primarily test visual extraction combined with text-based reasoning, lacking true visual reasoning with more complex interactions between vision and language. Inspired by the ARC challenge, we introduce EasyARC, a vision-language benchmark requiring multi-image, multi-step reasoning, and self-correction. EasyARC is procedurally generated, fully verifiable, and scalable, making it ideal for reinforcement learning (RL) pipelines. The generators incorporate progressive difficulty levels, enabling structured evaluation across task types and complexities. We benchmark state-of-the-art vision-language models and analyze their failure modes. We argue that EasyARC sets a new standard for evaluating true reasoning and test-time scaling capabilities in vision-language models. We open-source our benchmark dataset and evaluation code.

