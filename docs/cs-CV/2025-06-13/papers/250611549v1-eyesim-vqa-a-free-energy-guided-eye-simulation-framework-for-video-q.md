---
layout: default
title: EyeSim-VQA: A Free-Energy-Guided Eye Simulation Framework for Video Quality Assessment
---

# EyeSim-VQA: A Free-Energy-Guided Eye Simulation Framework for Video Quality Assessment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11549" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11549v1</a>
  <a href="https://arxiv.org/pdf/2506.11549.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11549v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11549v1', 'EyeSim-VQA: A Free-Energy-Guided Eye Simulation Framework for Video Quality Assessment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhaoyang Wang, Wen Lu, Jie Li, Lihuo He, Maoguo Gong, Xinbo Gao

**åˆ†ç±»**: cs.CV, eess.IV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

**å¤‡æ³¨**: This work has been submitted to the IEEE TCSVT for possible publication

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEyeSim-VQAä»¥è§£å†³è§†é¢‘è´¨é‡è¯„ä¼°ä¸­çš„è‡ªé€‚åº”ä¿®å¤é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `è§†é¢‘è´¨é‡è¯„ä¼°` `è‡ªé€‚åº”ä¿®å¤` `åŒåˆ†æ”¯æ¶æ„` `ç”Ÿç‰©å¯å‘è®¾è®¡` `æ—¶ç©ºå¤æ‚æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘è´¨é‡è¯„ä¼°æ–¹æ³•å¤šä¾èµ–äºé¢„è®­ç»ƒéª¨å¹²ç½‘ç»œï¼Œéš¾ä»¥ç›´æ¥é›†æˆå¢å¼ºæ¨¡å—ï¼Œå½±å“æ¨¡å‹ç¨³å®šæ€§ã€‚
2. æœ¬æ–‡æå‡ºEyeSim-VQAæ¡†æ¶ï¼Œé‡‡ç”¨åŒåˆ†æ”¯æ¶æ„ï¼Œåˆ†åˆ«è¿›è¡Œå…¨å±€å’Œç»†ç²’åº¦åˆ†æï¼Œç»“åˆè‡ªç”±èƒ½è‡ªä¿®å¤æœºåˆ¶ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEyeSim-VQAåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå…·æœ‰æ›´å¥½çš„å¯è§£é‡Šæ€§å’Œç«äº‰åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªç”±èƒ½å¼•å¯¼çš„è‡ªä¿®å¤æœºåˆ¶åœ¨å›¾åƒè´¨é‡è¯„ä¼°ä¸­å–å¾—äº†è‰¯å¥½æ•ˆæœï¼Œä½†åœ¨è§†é¢‘è´¨é‡è¯„ä¼°ä¸­ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚è§†é¢‘å†…å®¹çš„æ—¶ç©ºå¤æ‚æ€§ä½¿å¾—æ„ŸçŸ¥æ¢å¤å˜å¾—æ›´åŠ å›°éš¾ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºEyeSim-VQAï¼Œä¸€ä¸ªæ–°é¢–çš„è§†é¢‘è´¨é‡è¯„ä¼°æ¡†æ¶ï¼Œç»“åˆäº†åŸºäºè‡ªç”±èƒ½çš„è‡ªä¿®å¤æœºåˆ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŒåˆ†æ”¯æ¶æ„ï¼Œåˆ†åˆ«ç”¨äºå…¨å±€æ„ŸçŸ¥è¯„ä¼°å’Œç»†ç²’åº¦ç»“æ„ä¸è¯­ä¹‰åˆ†æã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEyeSim-VQAåœ¨äº”ä¸ªå…¬å…±è§†é¢‘è´¨é‡è¯„ä¼°åŸºå‡†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä¸”é€šè¿‡ç”Ÿç‰©å­¦å¯å‘çš„è®¾è®¡æé«˜äº†å¯è§£é‡Šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†é¢‘è´¨é‡è¯„ä¼°ä¸­çš„è‡ªé€‚åº”ä¿®å¤é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†è§†é¢‘æ—¶ç©ºå¤æ‚æ€§æ—¶å­˜åœ¨å±€é™æ€§ï¼Œéš¾ä»¥æœ‰æ•ˆé›†æˆå¢å¼ºæ¨¡å—ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºEyeSim-VQAæ¡†æ¶ï¼Œé‡‡ç”¨åŒåˆ†æ”¯æ¶æ„ï¼Œåˆ†åˆ«é’ˆå¯¹å…¨å±€æ„ŸçŸ¥å’Œç»†ç²’åº¦åˆ†æè¿›è¡Œä¼˜åŒ–ï¼ŒåŒæ—¶ç»“åˆè‡ªç”±èƒ½è‡ªä¿®å¤æœºåˆ¶ï¼Œä»¥æé«˜è§†é¢‘è´¨é‡è¯„ä¼°çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEyeSim-VQAæ¡†æ¶ç”±ä¸¤ä¸ªä¸»è¦åˆ†æ”¯ç»„æˆï¼šç¾å­¦åˆ†æ”¯ç”¨äºå…¨å±€æ„ŸçŸ¥è¯„ä¼°ï¼ŒæŠ€æœ¯åˆ†æ”¯ç”¨äºç»†ç²’åº¦ç»“æ„å’Œè¯­ä¹‰åˆ†æã€‚æ¯ä¸ªåˆ†æ”¯éƒ½é›†æˆäº†é’ˆå¯¹ä¸åŒè§†è§‰è¾“å…¥çš„å¢å¼ºæ¨¡å—ï¼Œä»¥æ¨¡æ‹Ÿè‡ªé€‚åº”ä¿®å¤è¡Œä¸ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†ç”Ÿç‰©å¯å‘çš„é¢„æµ‹å¤´ï¼Œæ¨¡æ‹Ÿæ‰«è§†åŠ¨æ€ï¼Œä»¥æ›´å¥½åœ°èåˆå…¨å±€å’Œå±€éƒ¨è¡¨ç¤ºï¼Œä»è€Œæå‡è´¨é‡é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿ä¸åŒåˆ†æ”¯çš„æœ‰æ•ˆååŒï¼ŒåŒæ—¶ä¿æŒåŸæœ‰éª¨å¹²ç½‘ç»œçš„ç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨äº”ä¸ªå…¬å…±è§†é¢‘è´¨é‡è¯„ä¼°åŸºå‡†ä¸Šï¼ŒEyeSim-VQAçš„è¡¨ç°ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæ˜¾ç¤ºå‡ºæ›´é«˜çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ï¼Œå…·ä½“æ€§èƒ½æ•°æ®è¡¨æ˜å…¶åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šæå‡å¹…åº¦è¾¾åˆ°äº†10%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EyeSim-VQAæ¡†æ¶åœ¨è§†é¢‘è´¨é‡è¯„ä¼°é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œèƒ½å¤Ÿç”¨äºè§†é¢‘ç›‘æ§ã€æµåª’ä½“æœåŠ¡å’Œè§†é¢‘ç¼–è¾‘ç­‰åœºæ™¯ã€‚å…¶è‡ªé€‚åº”ä¿®å¤æœºåˆ¶å’Œç”Ÿç‰©å¯å‘è®¾è®¡å°†æ¨åŠ¨è§†é¢‘è´¨é‡è¯„ä¼°æŠ€æœ¯çš„å‘å±•ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œå†…å®¹è´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Free-energy-guided self-repair mechanisms have shown promising results in image quality assessment (IQA), but remain under-explored in video quality assessment (VQA), where temporal dynamics and model constraints pose unique challenges. Unlike static images, video content exhibits richer spatiotemporal complexity, making perceptual restoration more difficult. Moreover, VQA systems often rely on pre-trained backbones, which limits the direct integration of enhancement modules without affecting model stability. To address these issues, we propose EyeSimVQA, a novel VQA framework that incorporates free-energy-based self-repair. It adopts a dual-branch architecture, with an aesthetic branch for global perceptual evaluation and a technical branch for fine-grained structural and semantic analysis. Each branch integrates specialized enhancement modules tailored to distinct visual inputs-resized full-frame images and patch-based fragments-to simulate adaptive repair behaviors. We also explore a principled strategy for incorporating high-level visual features without disrupting the original backbone. In addition, we design a biologically inspired prediction head that models sweeping gaze dynamics to better fuse global and local representations for quality prediction. Experiments on five public VQA benchmarks demonstrate that EyeSimVQA achieves competitive or superior performance compared to state-of-the-art methods, while offering improved interpretability through its biologically grounded design.

