---
layout: default
title: CLIP Meets Diffusion: A Synergistic Approach to Anomaly Detection
---

# CLIP Meets Diffusion: A Synergistic Approach to Anomaly Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11772" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11772v3</a>
  <a href="https://arxiv.org/pdf/2506.11772.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11772v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11772v3', 'CLIP Meets Diffusion: A Synergistic Approach to Anomaly Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Byeongchan Lee, John Won, Seunghyun Lee, Jinwoo Shin

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13 (æ›´æ–°: 2025-11-05)

**å¤‡æ³¨**: Accepted at TMLR 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCLIPFUSIONä»¥è§£å†³å¼‚å¸¸æ£€æµ‹ä¸­çš„å¤šæ¨¡æ€èåˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼‚å¸¸æ£€æµ‹` `å¤šæ¨¡æ€èåˆ` `ç”Ÿæˆæ¨¡å‹` `åˆ¤åˆ«æ¨¡å‹` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•åœ¨å®šä¹‰å¼‚å¸¸æ—¶å­˜åœ¨æ¨¡ç³Šæ€§ï¼Œä¸”å¼‚å¸¸ç±»å‹å¤šæ ·ï¼Œå¯¼è‡´æ£€æµ‹æ•ˆæœä¸ä½³ã€‚
2. CLIPFUSIONç»“åˆäº†åˆ¤åˆ«æ€§å’Œç”Ÿæˆæ€§æ¨¡å‹ï¼Œåˆ©ç”¨CLIPæ•æ‰å…¨å±€ç‰¹å¾ï¼Œæ‰©æ•£æ¨¡å‹æ•æ‰å±€éƒ¨ç»†èŠ‚ï¼Œå½¢æˆäº’è¡¥ã€‚
3. åœ¨MVTec-ADå’ŒVisAæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCLIPFUSIONåœ¨å¼‚å¸¸åˆ†å‰²å’Œåˆ†ç±»ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼‚å¸¸æ£€æµ‹æ˜¯ä¸€ä¸ªå¤æ‚çš„é—®é¢˜ï¼Œå› å…¶å®šä¹‰æ¨¡ç³Šã€å¼‚å¸¸ç±»å‹å¤šæ ·ï¼ˆå¦‚å±€éƒ¨å’Œå…¨å±€ç¼ºé™·ï¼‰ä»¥åŠè®­ç»ƒæ•°æ®ç¨€ç¼ºè€Œå˜å¾—æ›´åŠ å›°éš¾ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†CLIPFUSIONæ–¹æ³•ï¼Œç»“åˆäº†åˆ¤åˆ«æ€§å’Œç”Ÿæˆæ€§åŸºç¡€æ¨¡å‹ã€‚å…·ä½“è€Œè¨€ï¼ŒåŸºäºCLIPçš„åˆ¤åˆ«æ¨¡å‹æ“…é•¿æ•æ‰å…¨å±€ç‰¹å¾ï¼Œè€ŒåŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹åˆ™æœ‰æ•ˆæ•æ‰å±€éƒ¨ç»†èŠ‚ï¼Œå½¢æˆäº†ä¸€ç§ååŒäº’è¡¥çš„æ–¹æ³•ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§åˆ©ç”¨äº¤å‰æ³¨æ„åŠ›å›¾å’Œä»æ‰©æ•£æ¨¡å‹æå–çš„ç‰¹å¾å›¾è¿›è¡Œå¼‚å¸¸æ£€æµ‹çš„æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCLIPFUSIONåœ¨åŸºå‡†æ•°æ®é›†ï¼ˆMVTec-AD, VisAï¼‰ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†å¼‚å¸¸åˆ†å‰²å’Œåˆ†ç±»çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¼‚å¸¸æ£€æµ‹ä¸­çš„å¤šæ ·æ€§å’Œæ•°æ®ç¨€ç¼ºæ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆæ•æ‰åˆ°å…¨å±€å’Œå±€éƒ¨ç‰¹å¾ï¼Œå¯¼è‡´æ£€æµ‹æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCLIPFUSIONé€šè¿‡ç»“åˆåˆ¤åˆ«æ€§å’Œç”Ÿæˆæ€§æ¨¡å‹ï¼Œåˆ©ç”¨CLIPæ¨¡å‹æå–å…¨å±€ç‰¹å¾ï¼ŒåŒæ—¶é€šè¿‡æ‰©æ•£æ¨¡å‹æ•æ‰å±€éƒ¨ç»†èŠ‚ï¼Œä»è€Œå®ç°æ›´å…¨é¢çš„å¼‚å¸¸æ£€æµ‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€ä¸ªåŸºäºCLIPçš„åˆ¤åˆ«æ¨¡å‹ç”¨äºå…¨å±€ç‰¹å¾æå–ï¼Œå¦ä¸€ä¸ªåŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹ç”¨äºå±€éƒ¨ç»†èŠ‚æ•æ‰ã€‚æ­¤å¤–ï¼Œäº¤å‰æ³¨æ„åŠ›å›¾å’Œç‰¹å¾å›¾çš„ç»“åˆç”¨äºå¢å¼ºå¼‚å¸¸æ£€æµ‹çš„æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šCLIPFUSIONçš„åˆ›æ–°åœ¨äºå°†å¤šæ¨¡æ€æ¨¡å‹çš„ä¼˜åŠ¿ç»“åˆèµ·æ¥ï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„ååŒæ£€æµ‹æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•åœ¨å¤„ç†å¤æ‚çš„å¼‚å¸¸æ£€æµ‹ä»»åŠ¡æ—¶ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰åˆ°ä¸åŒå±‚æ¬¡çš„ç‰¹å¾ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡å…¨å±€å’Œå±€éƒ¨ç‰¹å¾çš„å­¦ä¹ ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥æé«˜æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡å’Œæ£€æµ‹å‡†ç¡®æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œæ¶æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨MVTec-ADå’ŒVisAæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCLIPFUSIONåœ¨å¼‚å¸¸åˆ†å‰²å’Œåˆ†ç±»ä»»åŠ¡ä¸­å‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°10%ä»¥ä¸Šï¼Œè¯æ˜äº†å…¶åœ¨å¼‚å¸¸æ£€æµ‹é¢†åŸŸçš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å·¥ä¸šç¼ºé™·æ£€æµ‹ã€åŒ»ç–—å½±åƒåˆ†æä»¥åŠå®‰å…¨ç›‘æ§ç­‰ã€‚é€šè¿‡æé«˜å¼‚å¸¸æ£€æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼ŒCLIPFUSIONèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æ˜¾è‘—é™ä½è¯¯æŠ¥ç‡ï¼Œæå‡ç”Ÿäº§å’Œå®‰å…¨ç®¡ç†çš„æ™ºèƒ½åŒ–æ°´å¹³ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Anomaly detection is a complex problem due to the ambiguity in defining anomalies, the diversity of anomaly types (e.g., local and global defect), and the scarcity of training data. As such, it necessitates a comprehensive model capable of capturing both low-level and high-level features, even with limited data. To address this, we propose CLIPFUSION, a method that leverages both discriminative and generative foundation models. Specifically, the CLIP-based discriminative model excels at capturing global features, while the diffusion-based generative model effectively captures local details, creating a synergistic and complementary approach. Notably, we introduce a methodology for utilizing cross-attention maps and feature maps extracted from diffusion models specifically for anomaly detection. Experimental results on benchmark datasets (MVTec-AD, VisA) demonstrate that CLIPFUSION consistently outperforms baseline methods, achieving outstanding performance in both anomaly segmentation and classification. We believe that our method underscores the effectiveness of multi-modal and multi-model fusion in tackling the multifaceted challenges of anomaly detection, providing a scalable solution for real-world applications.

