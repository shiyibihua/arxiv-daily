---
layout: default
title: Stop learning it all to mitigate visual hallucination, Focus on the hallucination target
---

# Stop learning it all to mitigate visual hallucination, Focus on the hallucination target

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11417" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11417v1</a>
  <a href="https://arxiv.org/pdf/2506.11417.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11417v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11417v1', 'Stop learning it all to mitigate visual hallucination, Focus on the hallucination target')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dokyoon Yoon, Youngsook Song, Woomyong Park

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

**å¤‡æ³¨**: Accepted to CVPR 2025

**æœŸåˆŠ**: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåå¥½å­¦ä¹ æ–¹æ³•ä»¥ç¼“è§£å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„è§†è§‰å¹»è§‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è§†è§‰å¹»è§‰` `åå¥½å­¦ä¹ ` `ä¿¡æ¯è¿‡æ»¤` `æ¨¡å‹å¯é æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸­å¸¸å¸¸äº§ç”Ÿå¹»è§‰ï¼Œå¯¼è‡´ç”Ÿæˆä¸è¾“å…¥å›¾åƒä¸ç¬¦çš„ä¿¡æ¯ï¼Œå½±å“æ¨¡å‹çš„å¯é æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åå¥½å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡ä¸“æ³¨äºå¹»è§‰å‘ç”Ÿçš„ç›®æ ‡åŒºåŸŸæ¥å‡è½»å¹»è§‰ç°è±¡ï¼Œä»è€Œæé«˜æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªè§†è§‰å¹»è§‰ä»»åŠ¡ä¸­æœ‰æ•ˆé™ä½äº†å¹»è§‰å‘ç”Ÿç‡ï¼Œæå‡äº†æ¨¡å‹çš„æ•´ä½“æ€§èƒ½å’Œå¯é æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸­å¸¸å¸¸é­é‡å¹»è§‰é—®é¢˜ï¼Œå³ç”Ÿæˆè¾“å…¥å›¾åƒä¸­ä¸å­˜åœ¨çš„ç‰©ä½“ä¿¡æ¯ã€‚è¿™ç§å¹»è§‰ä¸¥é‡å½±å“äº†æ¨¡å‹åœ¨éœ€è¦å‡†ç¡®ç‰©ä½“è¯†åˆ«çš„å®é™…åº”ç”¨ä¸­çš„å¯é æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åå¥½å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡å…³æ³¨å¹»è§‰å‘ç”Ÿçš„ç‰¹å®šåŒºåŸŸæ¥å‡è½»å¹»è§‰ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«å¹»è§‰å“åº”ã€æ­£ç¡®å“åº”å’Œç›®æ ‡ä¿¡æ¯çš„æ•°æ®é›†ã€‚é€šè¿‡å°†åå¥½å­¦ä¹ æ–¹æ³•åº”ç”¨äºè¿™äº›ç‰¹å®šç›®æ ‡ï¼Œæ¨¡å‹èƒ½å¤Ÿè¿‡æ»¤æ‰æ— å…³ä¿¡å·ï¼Œä¸“æ³¨äºçº æ­£å¹»è§‰ï¼Œä»è€Œç”Ÿæˆæ›´çœŸå®çš„å“åº”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆå‡å°‘äº†å¤šé¡¹è§†è§‰å¹»è§‰ä»»åŠ¡ä¸­çš„å¹»è§‰ç°è±¡ï¼Œæé«˜äº†MLLMsçš„å¯é æ€§å’Œæ€§èƒ½ï¼Œè€Œä¸å½±å“æ•´ä½“è¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸­äº§ç”Ÿå¹»è§‰çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè¯†åˆ«å’Œçº æ­£è¿™äº›å¹»è§‰ï¼Œå¯¼è‡´ç”Ÿæˆä¸å‡†ç¡®çš„ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§åå¥½å­¦ä¹ æ–¹æ³•ï¼Œä¸“æ³¨äºå¹»è§‰å‘ç”Ÿçš„ç‰¹å®šåŒºåŸŸï¼Œé€šè¿‡è¿‡æ»¤æ— å…³ä¿¡å·æ¥æé«˜æ¨¡å‹çš„å“åº”å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€åå¥½å­¦ä¹ æ¨¡å‹è®­ç»ƒå’Œå“åº”ç”Ÿæˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é›†ä¸­åŒ…å«å¹»è§‰å“åº”ã€æ­£ç¡®å“åº”åŠç›®æ ‡ä¿¡æ¯ï¼Œä»¥ä¾¿æ¨¡å‹è¿›è¡Œé’ˆå¯¹æ€§å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡åå¥½å­¦ä¹ æ–¹æ³•èšç„¦äºå¹»è§‰ç›®æ ‡åŒºåŸŸï¼ŒåŒºåˆ«äºä¼ ç»Ÿæ–¹æ³•çš„å…¨é¢å­¦ä¹ ç­–ç•¥ï¼Œä»è€Œæœ‰æ•ˆå‡å°‘å¹»è§‰ç°è±¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¼ºè°ƒç›®æ ‡åŒºåŸŸçš„å­¦ä¹ ï¼ŒåŒæ—¶è®¾è®¡äº†é€‚åº”æ€§å‚æ•°è®¾ç½®ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨å¹»è§‰çº æ­£ä¸­çš„è¡¨ç°ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°èšç„¦äºç›¸å…³ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨è¯¥åå¥½å­¦ä¹ æ–¹æ³•åï¼Œæ¨¡å‹åœ¨å¤šä¸ªè§†è§‰å¹»è§‰ä»»åŠ¡ä¸­çš„å¹»è§‰å‘ç”Ÿç‡æ˜¾è‘—é™ä½ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒåŒæ—¶ä¿æŒäº†æ•´ä½“æ€§èƒ½çš„ç¨³å®šæ€§ã€‚è¿™ä¸€ç»“æœéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—å½±åƒåˆ†æç­‰éœ€è¦é«˜å‡†ç¡®åº¦ç‰©ä½“è¯†åˆ«çš„åœºæ™¯ã€‚é€šè¿‡æé«˜å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å¯é æ€§ï¼Œèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æä¾›æ›´ä¸ºå‡†ç¡®çš„ä¿¡æ¯ï¼Œä»è€Œå¢å¼ºç”¨æˆ·ä½“éªŒå’Œä¿¡ä»»åº¦ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨åŠ¨æ›´å¹¿æ³›çš„å¤šæ¨¡æ€å­¦ä¹ ç ”ç©¶ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) frequently suffer from hallucination issues, generating information about objects that are not present in input images during vision-language tasks. These hallucinations particularly undermine model reliability in practical applications requiring accurate object identification. To address this challenge, we propose \mymethod,\ a preference learning approach that mitigates hallucinations by focusing on targeted areas where they occur. To implement this, we build a dataset containing hallucinated responses, correct responses, and target information (i.e., objects present in the images and the corresponding chunk positions in responses affected by hallucinations). By applying a preference learning method restricted to these specific targets, the model can filter out irrelevant signals and focus on correcting hallucinations. This allows the model to produce more factual responses by concentrating solely on relevant information. Experimental results demonstrate that \mymethod\ effectively reduces hallucinations across multiple vision hallucination tasks, improving the reliability and performance of MLLMs without diminishing overall performance.

