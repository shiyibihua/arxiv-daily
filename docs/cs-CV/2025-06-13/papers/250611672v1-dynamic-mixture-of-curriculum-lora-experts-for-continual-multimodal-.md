---
layout: default
title: Dynamic Mixture of Curriculum LoRA Experts for Continual Multimodal Instruction Tuning
---

# Dynamic Mixture of Curriculum LoRA Experts for Continual Multimodal Instruction Tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11672" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.11672v1</a>
  <a href="https://arxiv.org/pdf/2506.11672.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11672v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11672v1', 'Dynamic Mixture of Curriculum LoRA Experts for Continual Multimodal Instruction Tuning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Chendi Ge, Xin Wang, Zeyang Zhang, Hong Chen, Jiapei Fan, Longtao Huang, Hui Xue, Wenwu Zhu

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-13

**Â§áÊ≥®**: Accepted by ICML 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âä®ÊÄÅÊ∑∑ÂêàËØæÁ®ãLoRA‰∏ìÂÆ∂‰ª•Ëß£ÂÜ≥ÊåÅÁª≠Â§öÊ®°ÊÄÅÊåá‰ª§Ë∞É‰ºòÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÊåá‰ª§Ë∞É‰ºò` `ÊåÅÁª≠Â≠¶‰π†` `Âä®ÊÄÅÊû∂ÊûÑ` `LoRA‰∏ìÂÆ∂` `Ê®°ÊÄÅ‰∏çÂπ≥Ë°°` `‰ªªÂä°ÈÄÇÂ∫îÊÄß` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÈááÁî®Âõ∫ÂÆöÊû∂ÊûÑÔºåÈöæ‰ª•ÈÄÇÂ∫îÊñ∞‰ªªÂä°ÔºåÈù¢‰∏¥‰ªªÂä°Êû∂ÊûÑÂÜ≤Á™ÅÂíåÊ®°ÊÄÅ‰∏çÂπ≥Ë°°ÁöÑÊåëÊàò„ÄÇ
2. ÊèêÂá∫Âä®ÊÄÅÊ∑∑ÂêàËØæÁ®ãLoRA‰∏ìÂÆ∂ÔºàD-MoLEÔºâÊñπÊ≥ïÔºåÈÄöËøáÂä®ÊÄÅÂàÜÈÖçLoRA‰∏ìÂÆ∂ÂíåË∞ÉÊï¥Êõ¥Êñ∞ÊØî‰æãÊù•Ëß£ÂÜ≥‰∏äËø∞ÈóÆÈ¢ò„ÄÇ
3. D-MoLEÂú®Â§öÈ°πÂÆûÈ™å‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÂπ≥ÂùáÊèêÂçá15%ÔºåÊòØÈ¶ñÊ¨°‰ªéÊû∂ÊûÑËßíÂ∫¶Á†îÁ©∂Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊåÅÁª≠Â≠¶‰π†„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÊåÅÁª≠ÁöÑÂ§öÊ®°ÊÄÅÊåá‰ª§Ë∞É‰ºòÂØπ‰∫éÈÄÇÂ∫î‰∏çÊñ≠ÂèòÂåñÁöÑ‰ªªÂä°Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈááÁî®Âõ∫ÂÆöÊû∂ÊûÑÔºåÈöæ‰ª•ÈÄÇÂ∫îÊñ∞‰ªªÂä°„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂú®ÂèÇÊï∞È¢ÑÁÆó‰∏ãÂä®ÊÄÅÊºîÂåñÊû∂ÊûÑÁöÑÊñπÊ≥ïÔºåËß£ÂÜ≥‰∫Ü‰ªªÂä°Êû∂ÊûÑÂÜ≤Á™ÅÂíåÊ®°ÊÄÅ‰∏çÂπ≥Ë°°‰∏§‰∏™ÊåëÊàò„ÄÇÊàë‰ª¨ÊèêÂá∫ÁöÑÂä®ÊÄÅÊ∑∑ÂêàËØæÁ®ãLoRA‰∏ìÂÆ∂ÔºàD-MoLEÔºâÊñπÊ≥ïÔºåËÉΩÂ§üËá™Âä®ÊºîÂåñÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊû∂ÊûÑÔºå‰ª•ÊåÅÁª≠ÈÄÇÂ∫îÊñ∞‰ªªÂä°ÔºåÂêåÊó∂‰øùÁïôÂ∑≤Â≠¶Áü•ËØÜ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåD-MoLEÂú®ÊÄßËÉΩ‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÂü∫Á∫øÔºåÂπ≥ÂùáÊèêÂçá15%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÊåÅÁª≠Â§öÊ®°ÊÄÅÊåá‰ª§Ë∞É‰ºò‰∏≠ÁöÑÊû∂ÊûÑÈÄÇÂ∫îÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÁî±‰∫éÂõ∫ÂÆöÊû∂ÊûÑÔºåÊó†Ê≥ïÊúâÊïàÂ∫îÂØπ‰∏çÂêå‰ªªÂä°ÁöÑÈúÄÊ±ÇÔºåÂØºËá¥‰ªªÂä°Êû∂ÊûÑÂÜ≤Á™ÅÂíåÊ®°ÊÄÅ‰∏çÂπ≥Ë°°„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫Âä®ÊÄÅÊ∑∑ÂêàËØæÁ®ãLoRA‰∏ìÂÆ∂ÔºàD-MoLEÔºâÊñπÊ≥ïÔºåÈÄöËøáÂä®ÊÄÅÂàÜÈÖçLoRA‰∏ìÂÆ∂ÂíåË∞ÉÊï¥Êõ¥Êñ∞ÊØî‰æãÔºåÁÅµÊ¥ªÈÄÇÂ∫îÊñ∞‰ªªÂä°ÔºåÂêåÊó∂‰øùÁïôÂ∑≤ÊúâÁü•ËØÜ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöD-MoLEÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Âä®ÊÄÅÂ±ÇÁ∫ß‰∏ìÂÆ∂ÂàÜÈÖçÂô®ÂíåÂü∫‰∫éÊ¢ØÂ∫¶ÁöÑË∑®Ê®°ÊÄÅÊåÅÁª≠ËØæÁ®ã„ÄÇÂä®ÊÄÅÂ±ÇÁ∫ß‰∏ìÂÆ∂ÂàÜÈÖçÂô®Ë¥üË¥£Âú®‰∏çÂêåÂ±Ç‰πãÈó¥ÂàÜÈÖçLoRA‰∏ìÂÆ∂ÔºåËÄåË∑®Ê®°ÊÄÅÊåÅÁª≠ËØæÁ®ãÂàôÊ†πÊçÆÊ®°ÊÄÅÈöæÂ∫¶Ë∞ÉÊï¥ÂêÑÊ®°ÂùóÁöÑÊõ¥Êñ∞ÊØî‰æã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöD-MoLEÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂Âä®ÊÄÅÊû∂ÊûÑÊºîÂåñËÉΩÂäõÔºåËÉΩÂ§üÂú®ÂèÇÊï∞È¢ÑÁÆóÂÜÖËá™Âä®ÈÄÇÂ∫îÊñ∞‰ªªÂä°ÔºåËß£ÂÜ≥‰∫Ü‰º†ÁªüÊñπÊ≥ïÁöÑÈùôÊÄÅÈôêÂà∂„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÂä®ÊÄÅÂ±ÇÁ∫ß‰∏ìÂÆ∂ÂàÜÈÖçÊú∫Âà∂ÂíåÂü∫‰∫é‰ªªÂä°ÈöæÂ∫¶ÁöÑÊõ¥Êñ∞ÊØî‰æãË∞ÉÊï¥ÔºåÁ°Æ‰øù‰∫ÜÂú®‰∏çÂêåÊ®°ÊÄÅÈó¥ÁöÑÁü•ËØÜÂÖ±‰∫´ÂíåÊõ¥Êñ∞Âπ≥Ë°°„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

D-MoLEÂú®Â§öÈ°πÂÆûÈ™å‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂπ≥ÂùáÊèêÂçá15%Áõ∏ËæÉ‰∫éÊúÄ‰Ω≥Âü∫Á∫øÔºåÊòæÁ§∫Âá∫ÂÖ∂Âú®ÊåÅÁª≠Â≠¶‰π†ÂíåÂ§öÊ®°ÊÄÅÊåá‰ª§Ë∞É‰ºò‰∏≠ÁöÑÊòæËëó‰ºòÂäø„ÄÇËøô‰∏ÄÁªìÊûúË°®ÊòéÔºåD-MoLEÂú®Ëß£ÂÜ≥‰ªªÂä°Êû∂ÊûÑÂÜ≤Á™ÅÂíåÊ®°ÊÄÅ‰∏çÂπ≥Ë°°ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÁâπÂà´ÊòØÂú®ÈúÄË¶ÅÂø´ÈÄüÈÄÇÂ∫îÊñ∞‰ªªÂä°ÁöÑÂ§öÊ®°ÊÄÅÁ≥ªÁªü‰∏≠ÔºåÂ¶ÇÊô∫ËÉΩÂä©Êâã„ÄÅËá™Âä®È©æÈ©∂Âíå‰∫∫Êú∫‰∫§‰∫íÁ≠âÈ¢ÜÂüü„ÄÇD-MoLEÁöÑÂä®ÊÄÅÊû∂ÊûÑÊºîÂåñËÉΩÂäõÂ∞ÜÊé®Âä®Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÁÅµÊ¥ªÊÄßÂíåÊïàÁéáÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™å„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Continual multimodal instruction tuning is crucial for adapting Multimodal Large Language Models (MLLMs) to evolving tasks. However, most existing methods adopt a fixed architecture, struggling with adapting to new tasks due to static model capacity. We propose to evolve the architecture under parameter budgets for dynamic task adaptation, which remains unexplored and imposes two challenges: 1) task architecture conflict, where different tasks require varying layer-wise adaptations, and 2) modality imbalance, where different tasks rely unevenly on modalities, leading to unbalanced updates. To address these challenges, we propose a novel Dynamic Mixture of Curriculum LoRA Experts (D-MoLE) method, which automatically evolves MLLM's architecture with controlled parameter budgets to continually adapt to new tasks while retaining previously learned knowledge. Specifically, we propose a dynamic layer-wise expert allocator, which automatically allocates LoRA experts across layers to resolve architecture conflicts, and routes instructions layer-wisely to facilitate knowledge sharing among experts. Then, we propose a gradient-based inter-modal continual curriculum, which adjusts the update ratio of each module in MLLM based on the difficulty of each modality within the task to alleviate the modality imbalance problem. Extensive experiments show that D-MoLE significantly outperforms state-of-the-art baselines, achieving a 15% average improvement over the best baseline. To the best of our knowledge, this is the first study of continual learning for MLLMs from an architectural perspective.

