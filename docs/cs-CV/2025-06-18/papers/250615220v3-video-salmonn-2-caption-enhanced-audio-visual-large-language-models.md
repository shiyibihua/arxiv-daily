---
layout: default
title: video-SALMONN 2: Caption-Enhanced Audio-Visual Large Language Models
---

# video-SALMONN 2: Caption-Enhanced Audio-Visual Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15220" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15220v3</a>
  <a href="https://arxiv.org/pdf/2506.15220.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15220v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15220v3', 'video-SALMONN 2: Caption-Enhanced Audio-Visual Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Changli Tang, Yixuan Li, Yudong Yang, Jimin Zhuang, Guangzhi Sun, Wei Li, Zejun Ma, Chao Zhang

**åˆ†ç±»**: cs.CV, cs.CL, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18 (æ›´æ–°: 2025-09-26)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/bytedance/video-SALMONN-2)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºvideo-SALMONN 2ä»¥è§£å†³è§†é¢‘æè¿°ä¸é—®ç­”é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éŸ³è§†é¢‘ç†è§£` `å¤šè½®ä¼˜åŒ–` `å­—å¹•ç”Ÿæˆ` `é—®ç­”ç³»ç»Ÿ` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„éŸ³è§†é¢‘ç†è§£æ¨¡å‹åœ¨è§†é¢‘æè¿°å’Œé—®ç­”ä»»åŠ¡ä¸­å­˜åœ¨å‡†ç¡®æ€§å’Œç»†èŠ‚ä¸è¶³çš„é—®é¢˜ã€‚
2. è®ºæ–‡æå‡ºçš„å¤šè½®ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆMrDPOï¼‰æ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€æ›´æ–°å‚è€ƒç­–ç•¥ï¼Œæå‡äº†å­—å¹•çš„è´¨é‡å’Œå‡†ç¡®æ€§ã€‚
3. åœ¨å¤šä¸ªéŸ³è§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•ä¸­ï¼Œ3Bå’Œ7Bæ¨¡å‹è¾¾åˆ°äº†SOTAç»“æœï¼Œ72Bæ¨¡å‹è¶…è¶Šäº†æ‰€æœ‰å…¶ä»–å¼€æºç³»ç»Ÿã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†video-SALMONN 2ï¼Œè¿™æ˜¯ä¸€ç³»åˆ—éŸ³è§†é¢‘å¤§è¯­è¨€æ¨¡å‹ï¼Œåœ¨è§†é¢‘æè¿°å’Œé—®ç­”ï¼ˆQAï¼‰ä»»åŠ¡ä¸­åˆ›é€ äº†æ–°çš„æœ€å…ˆè¿›ï¼ˆSOTAï¼‰ç»“æœã€‚æˆ‘ä»¬çš„æ ¸å¿ƒè´¡çŒ®æ˜¯å¤šè½®ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆMrDPOï¼‰ï¼Œç»“åˆäº†ä¸€ä¸ªå…±åŒå¥–åŠ±å®Œæ•´æ€§å’Œäº‹å®å‡†ç¡®æ€§çš„å­—å¹•è´¨é‡ç›®æ ‡ã€‚ä¸å›ºå®šå‚è€ƒç­–ç•¥çš„æ ‡å‡†DPOä¸åŒï¼ŒMrDPOé€šè¿‡ä»æœ€æ–°åå¥½è®­ç»ƒçš„è½»é‡é€‚é…å™¨ä¸­é‡æ–°åˆå§‹åŒ–å‚è€ƒï¼Œå®šæœŸåˆ·æ–°å‚è€ƒï¼Œé¿å…äº†å‚è€ƒè¿‡æ—¶çš„é—®é¢˜ï¼Œä¿ƒè¿›äº†æŒç»­æ”¹è¿›ã€‚è¯¥ç­–ç•¥ç”Ÿæˆçš„å­—å¹•åœ¨ç»†èŠ‚å’Œå‡†ç¡®æ€§ä¸Šå§‹ç»ˆä¼˜äºGPT-4oå’ŒGemini-1.5 Proç­‰ä¸“æœ‰ç³»ç»Ÿã€‚æˆ‘ä»¬è¿›ä¸€æ­¥åˆ©ç”¨è¯¥æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘å­—å¹•è¯­æ–™åº“ï¼Œä»¥ä¾¿å¯¹æ–°æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒï¼Œè¶…è¶Šäº†å­—å¹•ç”Ÿæˆçš„å¥½å¤„ï¼Œåœ¨å¤æ‚è§†é¢‘é—®ç­”ä»»åŠ¡ä¸Šä¹Ÿè¡¨ç°å‡ºè‰²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰éŸ³è§†é¢‘ç†è§£æ¨¡å‹åœ¨è§†é¢‘æè¿°å’Œé—®ç­”ä»»åŠ¡ä¸­å‡†ç¡®æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–å›ºå®šçš„å‚è€ƒç­–ç•¥ï¼Œå¯¼è‡´ç”Ÿæˆçš„å­—å¹•ç¼ºä¹ç»†èŠ‚å’Œå‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„å¤šè½®ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆMrDPOï¼‰æ–¹æ³•ï¼Œé€šè¿‡å®šæœŸæ›´æ–°å‚è€ƒç­–ç•¥ï¼Œé¿å…äº†å‚è€ƒè¿‡æ—¶çš„é—®é¢˜ï¼Œä»è€Œæå‡äº†å­—å¹•çš„è´¨é‡ã€‚è¯¥æ–¹æ³•ç»“åˆäº†å­—å¹•è´¨é‡ç›®æ ‡ï¼Œå¥–åŠ±å®Œæ•´æ€§å’Œäº‹å®å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆæ˜¯éŸ³è§†é¢‘æ•°æ®çš„è¾“å…¥å¤„ç†ï¼Œç„¶åæ˜¯é€šè¿‡MrDPOè¿›è¡Œåå¥½ä¼˜åŒ–ï¼Œæœ€åç”Ÿæˆé«˜è´¨é‡çš„å­—å¹•ã€‚æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨è½»é‡é€‚é…å™¨åŠ¨æ€æ›´æ–°å‚è€ƒç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹æ˜¯MrDPOçš„å¼•å…¥ï¼Œå®ƒä¸ä¼ ç»Ÿçš„å›ºå®šå‚è€ƒç­–ç•¥DPOæ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œèƒ½å¤Ÿå®ç°æŒç»­çš„æ€§èƒ½æå‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œæ¨¡å‹ä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡å®Œæ•´æ€§å’Œå‡†ç¡®æ€§ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†è½»é‡é€‚é…å™¨ï¼Œä»¥ä¾¿äºåŠ¨æ€æ›´æ–°å‚è€ƒç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼Œ3Bå’Œ7Bæ¨¡å‹åœ¨å¤šä¸ªéŸ³è§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•ï¼ˆå¦‚Video-MMEã€WorldSenseç­‰ï¼‰ä¸­è¾¾åˆ°äº†æ–°çš„æœ€å…ˆè¿›ç»“æœï¼Œ72Bæ¨¡å‹çš„æ€§èƒ½è¶…è¶Šäº†æ‰€æœ‰å…¶ä»–å¼€æºç³»ç»Ÿï¼Œå±•ç¤ºäº†æ˜¾è‘—çš„æå‡å¹…åº¦ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚è§†é¢‘é—®ç­”ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è§†é¢‘å†…å®¹ç”Ÿæˆã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œå¤šæ¨¡æ€ä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æå‡è§†é¢‘ç†è§£çš„å‡†ç¡®æ€§å’Œç»†èŠ‚ï¼Œvideo-SALMONN 2èƒ½å¤Ÿä¸ºæ•™è‚²ã€å¨±ä¹å’Œä¿¡æ¯æœåŠ¡ç­‰è¡Œä¸šå¸¦æ¥å®é™…ä»·å€¼ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´æ™ºèƒ½çš„å¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present video-SALMONN 2, a family of audio-visual large language models that set new state-of-the-art (SOTA) results in video description and question answering (QA). Our core contribution is multi-round direct preference optimisation (MrDPO), paired with a caption-quality objective that jointly rewards completeness and factual accuracy. Unlike standard DPO with a fixed reference policy, MrDPO periodically refreshes the reference by bootstrapping from a newly re-initialised lightweight adapter trained on the latest preferences, avoiding reference staleness and enabling continual improvement. This strategy produces captions that are consistently more detailed and accurate than those from proprietary systems such as GPT-4o and Gemini-1.5 Pro. We further distil these gains by using our model to generate a high-quality video-caption corpus for supervised fine-tuning of new models, transferring benefits beyond captioning to strong performance on complex video-QA tasks. Across widely used audio-visual and visual-only understanding benchmarks (including Video-MME, WorldSense, AVUT, Video-Holmes, DailyOmni, MLVU, and LVBench), our 3B and 7B models achieve SOTA results at comparable scales, while the 72B model surpasses all other open-source systems. Our source code, models, and data are released at \href{https://github.com/bytedance/video-SALMONN-2}{https://github.com/bytedance/video-SALMONN-2}.

