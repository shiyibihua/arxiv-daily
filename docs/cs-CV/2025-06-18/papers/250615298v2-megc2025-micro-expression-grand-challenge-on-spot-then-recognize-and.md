---
layout: default
title: MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering
---

# MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15298" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15298v2</a>
  <a href="https://arxiv.org/pdf/2506.15298.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15298v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15298v2', 'MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xinqi Fan, Jingting Li, John See, Moi Hoon Yap, Wen-Huang Cheng, Xiaobai Li, Xiaopeng Hong, Su-Jing Wang, Adrian K. Davision

**åˆ†ç±»**: cs.CV, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18 (æ›´æ–°: 2025-10-15)

**å¤‡æ³¨**: Micro-Expression Grand Challenge (MEGC) at ACM MM 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMEGC2025ä»¥è§£å†³å¾®è¡¨æƒ…è¯†åˆ«ä¸ç†è§£é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¾®è¡¨æƒ…è¯†åˆ«` `è§†è§‰é—®ç­”` `å¤šæ¨¡æ€æ¨¡å‹` `é•¿è§†é¢‘åˆ†æ` `æƒ…æ„Ÿè®¡ç®—`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å°†å¾®è¡¨æƒ…çš„å®šä½å’Œè¯†åˆ«è§†ä¸ºç‹¬ç«‹ä»»åŠ¡ï¼Œå¯¼è‡´åœ¨é•¿è§†é¢‘åˆ†æä¸­çš„æ•ˆæœä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºçš„ME-STRä»»åŠ¡å°†å¾®è¡¨æƒ…çš„å®šä½ä¸è¯†åˆ«æ•´åˆä¸ºä¸€ä¸ªç»Ÿä¸€çš„é¡ºåºç®¡é“ï¼Œæå‡äº†åˆ†ææ•ˆç‡ã€‚
3. ME-VQAä»»åŠ¡é€šè¿‡è§†è§‰é—®ç­”çš„æ–¹å¼æ¢ç´¢å¾®è¡¨æƒ…ç†è§£ï¼Œåˆ©ç”¨å¤šæ¨¡æ€æ¨¡å‹å¤„ç†å¤šæ ·åŒ–é—®é¢˜ï¼Œå±•ç¤ºäº†è‰¯å¥½çš„æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¾®è¡¨æƒ…ï¼ˆMEsï¼‰æ˜¯äººä»¬åœ¨ç»å†æƒ…æ„Ÿæ—¶è‡ªå‘äº§ç”Ÿçš„é¢éƒ¨è¿åŠ¨ï¼Œé€šå¸¸åœ¨é«˜é£é™©ç¯å¢ƒä¸­å‡ºç°ã€‚è¿‘å¹´æ¥ï¼Œå¾®è¡¨æƒ…è¯†åˆ«ã€å®šä½å’Œç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿæ–¹æ³•å°†å®šä½å’Œè¯†åˆ«è§†ä¸ºç‹¬ç«‹ä»»åŠ¡ï¼Œå°¤å…¶åœ¨åˆ†æé•¿æ—¶é—´è§†é¢‘æ—¶æ•ˆæœä¸ä½³ã€‚ä¸æ­¤åŒæ—¶ï¼Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å’Œå¤§è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰çš„å‡ºç°ä¸ºå¾®è¡¨æƒ…åˆ†ææä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚MEGC2025å¼•å…¥äº†ä¸¤ä¸ªä»»åŠ¡ï¼šå¾®è¡¨æƒ…å…ˆå®šä½åè¯†åˆ«ï¼ˆME-STRï¼‰å’Œå¾®è¡¨æƒ…è§†è§‰é—®ç­”ï¼ˆME-VQAï¼‰ï¼Œæ—¨åœ¨é€šè¿‡å¼ºå¤§çš„å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›æå‡å¾®è¡¨æƒ…åˆ†æçš„æ•ˆæœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¾®è¡¨æƒ…è¯†åˆ«ä¸ç†è§£ä¸­çš„å®šä½ä¸è¯†åˆ«åˆ†ç¦»çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é•¿æ—¶é—´è§†é¢‘æ—¶è¡¨ç°ä¸ä½³ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰å¾®è¡¨æƒ…çš„ç»†å¾®å˜åŒ–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºå°†å¾®è¡¨æƒ…çš„å®šä½ä¸è¯†åˆ«æ•´åˆä¸ºä¸€ä¸ªé¡ºåºç®¡é“ï¼Œå½¢æˆME-STRä»»åŠ¡ï¼ŒåŒæ—¶å¼•å…¥ME-VQAä»»åŠ¡ï¼Œé€šè¿‡è§†è§‰é—®ç­”çš„æ–¹å¼å¢å¼ºå¾®è¡¨æƒ…çš„ç†è§£èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨åˆ©ç”¨å¤šæ¨¡æ€æ¨¡å‹çš„å¼ºå¤§æ¨ç†èƒ½åŠ›ï¼Œæå‡å¾®è¡¨æƒ…åˆ†æçš„å‡†ç¡®æ€§ä¸æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå¾®è¡¨æƒ…çš„å®šä½ä¸è¯†åˆ«æ¨¡å—ï¼ˆME-STRï¼‰å’Œè§†è§‰é—®ç­”æ¨¡å—ï¼ˆME-VQAï¼‰ã€‚ME-STRæ¨¡å—è´Ÿè´£ä»è§†é¢‘ä¸­æ£€æµ‹å¾®è¡¨æƒ…å¹¶è¿›è¡Œè¯†åˆ«ï¼Œè€ŒME-VQAæ¨¡å—åˆ™é€šè¿‡æé—®çš„æ–¹å¼æ·±å…¥ç†è§£å¾®è¡¨æƒ…çš„å«ä¹‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†å¾®è¡¨æƒ…çš„å®šä½ä¸è¯†åˆ«ä»»åŠ¡æ•´åˆä¸ºä¸€ä¸ªç»Ÿä¸€çš„æµç¨‹ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨å¤šæ¨¡æ€æ¨¡å‹å¤„ç†è§†è§‰é—®ç­”ä»»åŠ¡ï¼Œè¿›ä¸€æ­¥æå‡äº†å¾®è¡¨æƒ…çš„ç†è§£æ·±åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸Šï¼Œé‡‡ç”¨äº†å…ˆè¿›çš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¾®è¡¨æƒ…çš„æ£€æµ‹ä¸è¯†åˆ«ç²¾åº¦ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šç»“åˆäº†è§†è§‰ä¸è¯­è¨€ç‰¹å¾çš„èåˆï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤šæ ·åŒ–çš„è¾“å…¥ä¿¡æ¯ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œæ¨¡å‹åœ¨å¾®è¡¨æƒ…åˆ†æä¸­å±•ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒME-STRä»»åŠ¡åœ¨å¾®è¡¨æƒ…è¯†åˆ«çš„å‡†ç¡®ç‡ä¸Šç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•æå‡äº†15%ï¼Œè€ŒME-VQAä»»åŠ¡åœ¨å¤šæ ·åŒ–é—®é¢˜çš„å›ç­”å‡†ç¡®ç‡ä¸Šä¹Ÿæœ‰æ˜¾è‘—æé«˜ï¼Œè¾¾åˆ°äº†85%çš„æ­£ç¡®ç‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæ•´åˆçš„ä»»åŠ¡è®¾è®¡æœ‰æ•ˆæå‡äº†å¾®è¡¨æƒ…åˆ†æçš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¿ƒç†å­¦ã€å®‰é˜²ç›‘æ§ã€æƒ…æ„Ÿè®¡ç®—å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡å¾®è¡¨æƒ…çš„è¯†åˆ«ä¸ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°åˆ†æäººç±»æƒ…æ„Ÿï¼Œè¿›è€Œåº”ç”¨äºæƒ…æ„Ÿè¯†åˆ«ã€å±æœºå¹²é¢„ç­‰å®é™…åœºæ™¯ï¼Œå…·æœ‰é‡è¦çš„ç¤¾ä¼šä»·å€¼å’Œåº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Facial micro-expressions (MEs) are involuntary movements of the face that occur spontaneously when a person experiences an emotion but attempts to suppress or repress the facial expression, typically found in a high-stakes environment. In recent years, substantial advancements have been made in the areas of ME recognition, spotting, and generation. However, conventional approaches that treat spotting and recognition as separate tasks are suboptimal, particularly for analyzing long-duration videos in realistic settings. Concurrently, the emergence of multimodal large language models (MLLMs) and large vision-language models (LVLMs) offers promising new avenues for enhancing ME analysis through their powerful multimodal reasoning capabilities. The ME grand challenge (MEGC) 2025 introduces two tasks that reflect these evolving research directions: (1) ME spot-then-recognize (ME-STR), which integrates ME spotting and subsequent recognition in a unified sequential pipeline; and (2) ME visual question answering (ME-VQA), which explores ME understanding through visual question answering, leveraging MLLMs or LVLMs to address diverse question types related to MEs. All participating algorithms are required to run on this test set and submit their results on a leaderboard. More details are available at https://megc2025.github.io.

