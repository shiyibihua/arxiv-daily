---
layout: default
title: DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder
---

# DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15218" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15218v1</a>
  <a href="https://arxiv.org/pdf/2506.15218.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15218v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15218v1', 'DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dan He, Weisheng Li, Guofen Wang, Yuping Huang, Shiqiang Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18

**å¤‡æ³¨**: This paper has been accepted by IEEE Transactions on Multimedia (TMM) in March 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/HeDan-11/DM-FNet)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDM-FNetä»¥è§£å†³å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆè´¨é‡ä¸è¶³çš„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆ` `æ‰©æ•£æ¨¡å‹` `UNet` `å›¾åƒé‡å»º` `ç‰¹å¾äº¤äº’` `åŒ»å­¦å½±åƒå­¦` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆæ–¹æ³•åœ¨ç»†èŠ‚ç‰¹å¾æ•æ‰å’Œè·¨æ¨¡æ€ç‰¹å¾äº¤äº’æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´èåˆå›¾åƒè´¨é‡ä¸ç†æƒ³ã€‚
2. æœ¬ç ”ç©¶æå‡ºDM-FNetï¼Œé€šè¿‡ä¸¤é˜¶æ®µæ‰©æ•£æ¨¡å‹è®­ç»ƒUNetè¿›è¡Œå›¾åƒé‡å»ºï¼Œå¢å¼ºç‰¹å¾è¡¨ç¤ºèƒ½åŠ›ï¼Œæå‡èåˆæ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDM-FNetåœ¨å¤šä¸ªåŒ»å­¦å›¾åƒç±»å‹ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œèåˆå›¾åƒåœ¨äº®åº¦ã€çº¹ç†å’Œè¾¹ç¼˜æ¸…æ™°åº¦ç­‰æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆï¼ˆMMIFï¼‰æå–å¤šæºå›¾åƒä¸­æœ€æœ‰æ„ä¹‰çš„ä¿¡æ¯ï¼Œä»è€Œå®ç°æ›´å…¨é¢å’Œå‡†ç¡®çš„è¯Šæ–­ã€‚é«˜è´¨é‡çš„èåˆç»“æœéœ€è¦åœ¨äº®åº¦ã€é¢œè‰²ã€å¯¹æ¯”åº¦å’Œç»†èŠ‚ä¹‹é—´è¿›è¡Œç²¾ç¡®å¹³è¡¡ï¼Œä»¥ç¡®ä¿èåˆå›¾åƒæœ‰æ•ˆå±•ç¤ºç›¸å…³çš„è§£å‰–ç»“æ„å¹¶åæ˜ ç»„ç»‡çš„åŠŸèƒ½çŠ¶æ€ã€‚ç„¶è€Œï¼Œç°æœ‰MMIFæ–¹æ³•åœ¨å¸¸è§„è®­ç»ƒä¸­æ•æ‰ç»†èŠ‚ç‰¹å¾çš„èƒ½åŠ›æœ‰é™ï¼Œä¸”è·¨æ¨¡æ€ç‰¹å¾äº¤äº’ä¸è¶³ï¼Œå¯¼è‡´èåˆå›¾åƒè´¨é‡ä¸ç†æƒ³ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„ä¸¤é˜¶æ®µèåˆç½‘ç»œDM-FNetï¼Œæ—¨åœ¨å®ç°ç»Ÿä¸€çš„MMIFã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§åŒ»å­¦å›¾åƒç±»å‹ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œèåˆå›¾åƒä¿æŒé€‚å½“çš„äº®åº¦ã€ä¸°å¯Œçš„çº¹ç†å’Œæ¸…æ™°çš„è¾¹ç¼˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆï¼ˆMMIFï¼‰ä¸­å­˜åœ¨çš„ç»†èŠ‚ç‰¹å¾æ•æ‰ä¸è¶³å’Œè·¨æ¨¡æ€ç‰¹å¾äº¤äº’ä¸å……åˆ†çš„é—®é¢˜ï¼Œå¯¼è‡´èåˆå›¾åƒè´¨é‡ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºDM-FNetï¼Œé€šè¿‡ä¸¤é˜¶æ®µçš„æ‰©æ•£æ¨¡å‹è®­ç»ƒï¼Œé¦–å…ˆé‡å»ºå›¾åƒä»¥æ•æ‰ç»†èŠ‚ä¿¡æ¯ï¼Œç„¶ååœ¨èåˆé˜¶æ®µå¢å¼ºç‰¹å¾è¯†åˆ«èƒ½åŠ›ï¼Œä»è€Œå®ç°é«˜è´¨é‡çš„å›¾åƒèåˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDM-FNetçš„æ•´ä½“æ¶æ„åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä½¿ç”¨æ‰©æ•£è¿‡ç¨‹è®­ç»ƒUNetè¿›è¡Œå›¾åƒé‡å»ºï¼Œç¬¬äºŒé˜¶æ®µå°†ä¸åŒæ­¥éª¤çš„å™ªå£°å›¾åƒè¾“å…¥èåˆç½‘ç»œï¼Œç»“åˆä¸‰ä¸ªå…³é”®èåˆæ¨¡å—è‡ªé€‚åº”å¤„ç†ä¸åŒæ¨¡æ€çš„åŒ»å­¦å›¾åƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„åˆ›æ–°ç‚¹åœ¨äºç»“åˆæ‰©æ•£æ¨¡å‹ä¸UNetæ¶æ„ï¼Œåˆ©ç”¨é€æ­¥å»å™ªçš„æ–¹å¼æ•æ‰å¤šå±‚æ¬¡ç‰¹å¾ï¼Œå¹¶é€šè¿‡èåˆç½‘ç»œå¢å¼ºç‰¹å¾äº¤äº’èƒ½åŠ›ï¼Œæ˜¾è‘—æå‡äº†èåˆå›¾åƒçš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†æ··åˆæŸå¤±å‡½æ•°ä»¥åè°ƒèåˆå›¾åƒçš„äº®åº¦ã€é¢œè‰²ã€å¯¹æ¯”åº¦å’Œç»†èŠ‚ï¼ŒåŒæ—¶é›†æˆäº†ä¸‰ä¸ªå…³é”®èåˆæ¨¡å—ï¼Œä»¥é€‚åº”ä¸åŒæ¨¡æ€çš„åŒ»å­¦å›¾åƒå¤„ç†éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDM-FNetåœ¨å¤šä¸ªåŒ»å­¦å›¾åƒç±»å‹ä¸Šçš„å®¢è§‚è¯„ä¼°æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œèåˆå›¾åƒåœ¨äº®åº¦ã€æ”¾å°„æ€§ç¤ºè¸ªå‰‚åˆ†å¸ƒã€çº¹ç†ä¸°å¯Œåº¦å’Œè¾¹ç¼˜æ¸…æ™°åº¦ç­‰æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨åŒ»å­¦å½±åƒå­¦é¢†åŸŸï¼Œå¯ä»¥ç”¨äºæé«˜ä¸åŒæ¨¡æ€åŒ»å­¦å›¾åƒçš„èåˆè´¨é‡ï¼Œä»è€Œè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œæ›´å‡†ç¡®çš„è¯Šæ–­å’Œæ²»ç–—å†³ç­–ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•ä¹Ÿå¯èƒ½æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸï¼Œå¦‚å¤šæ¨¡æ€æ•°æ®åˆ†æå’Œè®¡ç®—æœºè§†è§‰ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal medical image fusion (MMIF) extracts the most meaningful information from multiple source images, enabling a more comprehensive and accurate diagnosis. Achieving high-quality fusion results requires a careful balance of brightness, color, contrast, and detail; this ensures that the fused images effectively display relevant anatomical structures and reflect the functional status of the tissues. However, existing MMIF methods have limited capacity to capture detailed features during conventional training and suffer from insufficient cross-modal feature interaction, leading to suboptimal fused image quality. To address these issues, this study proposes a two-stage diffusion model-based fusion network (DM-FNet) to achieve unified MMIF. In Stage I, a diffusion process trains UNet for image reconstruction. UNet captures detailed information through progressive denoising and represents multilevel data, providing a rich set of feature representations for the subsequent fusion network. In Stage II, noisy images at various steps are input into the fusion network to enhance the model's feature recognition capability. Three key fusion modules are also integrated to process medical images from different modalities adaptively. Ultimately, the robust network structure and a hybrid loss function are integrated to harmonize the fused image's brightness, color, contrast, and detail, enhancing its quality and information density. The experimental results across various medical image types demonstrate that the proposed method performs exceptionally well regarding objective evaluation metrics. The fused image preserves appropriate brightness, a comprehensive distribution of radioactive tracers, rich textures, and clear edges. The code is available at https://github.com/HeDan-11/DM-FNet.

