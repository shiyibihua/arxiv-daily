---
layout: default
title: GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects
---

# GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15483" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15483v1</a>
  <a href="https://arxiv.org/pdf/2506.15483.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15483v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15483v1', 'GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shujia Li, Haiyu Zhang, Xinyuan Chen, Yaohui Wang, Yutong Ban

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGenHOIä»¥è§£å†³4Däººæœºäº¤äº’åˆæˆä¸­çš„ç‰©ä½“æ³›åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `4Däººæœºäº¤äº’` `æ–‡æœ¬é©±åŠ¨åˆæˆ` `æ‰©æ•£æ¨¡å‹` `ç¨€ç–å…³é”®å¸§` `æ³›åŒ–èƒ½åŠ›` `é«˜ä¿çœŸç”Ÿæˆ` `æ¥è§¦æ¨¡å¼` `è™šæ‹Ÿç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨4Däººæœºäº¤äº’åˆæˆä¸­é¢ä¸´æ•°æ®é›†ç¨€ç¼ºçš„é—®é¢˜ï¼Œé™åˆ¶äº†å¯¹æœªè§ç‰©ä½“çš„æ³›åŒ–èƒ½åŠ›ã€‚
2. è®ºæ–‡æå‡ºçš„GenHOIæ¡†æ¶é€šè¿‡Object-AnchorNetå’ŒContact-Aware Diffusion Modelå®ç°å¯¹æœªè§ç‰©ä½“çš„æ³›åŒ–å’Œé«˜ä¿çœŸ4D HOIåºåˆ—åˆæˆã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGenHOIåœ¨OMOMOå’Œ3D-FUTUREæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œç”Ÿæˆè´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡æ‰©æ•£æ¨¡å‹å’Œå¤§è§„æ¨¡è¿åŠ¨æ•°æ®é›†æ¨åŠ¨äº†æ–‡æœ¬é©±åŠ¨çš„äººç±»è¿åŠ¨åˆæˆï¼Œä½†å°†è¿™äº›è¿›å±•æ‰©å±•åˆ°4Däººæœºäº¤äº’ï¼ˆHOIï¼‰ä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦æ˜¯ç”±äºç¼ºä¹å¤§è§„æ¨¡4D HOIæ•°æ®é›†ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†GenHOIï¼Œä¸€ä¸ªæ–°é¢–çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œæ—¨åœ¨å®ç°ä¸¤ä¸ªå…³é”®ç›®æ ‡ï¼š1ï¼‰å¯¹æœªè§ç‰©ä½“çš„æ³›åŒ–ï¼Œ2ï¼‰åˆæˆé«˜ä¿çœŸ4D HOIåºåˆ—ã€‚åœ¨æ¡†æ¶çš„åˆå§‹é˜¶æ®µï¼Œæˆ‘ä»¬é‡‡ç”¨Object-AnchorNeté‡å»ºæœªè§ç‰©ä½“çš„ç¨€ç–3D HOIå…³é”®å¸§ï¼Œä»…ä»3D HOIæ•°æ®é›†ä¸­å­¦ä¹ ï¼Œä»è€Œå‡è½»å¯¹å¤§è§„æ¨¡4D HOIæ•°æ®é›†çš„ä¾èµ–ã€‚éšåï¼Œæˆ‘ä»¬åœ¨ç¬¬äºŒé˜¶æ®µå¼•å…¥Contact-Aware Diffusion Modelï¼ˆContactDMï¼‰ï¼Œä»¥æ— ç¼æ’å€¼ç¨€ç–3D HOIå…³é”®å¸§ä¸ºå¯†é›†çš„æ—¶é—´ä¸€è‡´çš„4D HOIåºåˆ—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬åœ¨å…¬å¼€çš„OMOMOå’Œ3D-FUTUREæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå±•ç¤ºäº†å¯¹æœªè§ç‰©ä½“çš„å¼ºæ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶å®ç°äº†é«˜ä¿çœŸçš„4D HOIç”Ÿæˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³4Däººæœºäº¤äº’åˆæˆä¸­çš„ç‰©ä½“æ³›åŒ–é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–äºå¤§è§„æ¨¡4D HOIæ•°æ®é›†ï¼Œé™åˆ¶äº†å¯¹æœªè§ç‰©ä½“çš„é€‚åº”èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„GenHOIæ¡†æ¶é€šè¿‡ä¸¤é˜¶æ®µçš„æ–¹æ³•ï¼Œé¦–å…ˆåˆ©ç”¨Object-AnchorNetä»3D HOIæ•°æ®é›†ä¸­é‡å»ºç¨€ç–çš„3Då…³é”®å¸§ï¼Œç„¶åé€šè¿‡Contact-Aware Diffusion Modelå°†å…¶æ’å€¼ä¸ºé«˜ä¿çœŸçš„4D HOIåºåˆ—ï¼Œä»è€Œå‡è½»å¯¹å¤§è§„æ¨¡4Dæ•°æ®é›†çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGenHOIæ¡†æ¶åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä½¿ç”¨Object-AnchorNeté‡å»ºç¨€ç–3D HOIå…³é”®å¸§ï¼Œç¬¬äºŒé˜¶æ®µé€šè¿‡Contact-Aware Diffusion Modelå°†è¿™äº›å…³é”®å¸§æ’å€¼ä¸ºå¯†é›†çš„4D HOIåºåˆ—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†Contact-Aware Encoderå’ŒContact-Aware HOI Attentionï¼Œè¿™äº›æ¨¡å—èƒ½å¤Ÿæå–äººæœºæ¥è§¦æ¨¡å¼å¹¶æœ‰æ•ˆæ•´åˆæ¥è§¦ä¿¡å·ï¼Œä»è€Œæå‡ç”Ÿæˆåºåˆ—çš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒContact-Aware Encoderç”¨äºæ•æ‰æ¥è§¦æ¨¡å¼ï¼ŒContact-Aware HOI Attentionåˆ™ç”¨äºå°†æ¥è§¦ä¿¡å·èå…¥æ‰©æ•£æ¨¡å‹ä¸­ï¼Œç¡®ä¿ç”Ÿæˆçš„4D HOIåºåˆ—åœ¨æ—¶é—´ä¸Šå…·æœ‰ä¸€è‡´æ€§å’Œé«˜ä¿çœŸåº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGenHOIåœ¨OMOMOå’Œ3D-FUTUREæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œç”Ÿæˆçš„4D HOIåºåˆ—åœ¨è´¨é‡å’Œæ³›åŒ–èƒ½åŠ›ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘å’Œäººæœºåä½œç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿä¸ºè¿™äº›é¢†åŸŸæä¾›æ›´ä¸ºçœŸå®å’Œè‡ªç„¶çš„äººæœºäº¤äº’ä½“éªŒã€‚æœªæ¥ï¼ŒGenHOIå¯èƒ½æ¨åŠ¨4Däººæœºäº¤äº’æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼Œä¿ƒè¿›ç›¸å…³åº”ç”¨çš„æ™®åŠä¸åˆ›æ–°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While diffusion models and large-scale motion datasets have advanced text-driven human motion synthesis, extending these advances to 4D human-object interaction (HOI) remains challenging, mainly due to the limited availability of large-scale 4D HOI datasets. In our study, we introduce GenHOI, a novel two-stage framework aimed at achieving two key objectives: 1) generalization to unseen objects and 2) the synthesis of high-fidelity 4D HOI sequences. In the initial stage of our framework, we employ an Object-AnchorNet to reconstruct sparse 3D HOI keyframes for unseen objects, learning solely from 3D HOI datasets, thereby mitigating the dependence on large-scale 4D HOI datasets. Subsequently, we introduce a Contact-Aware Diffusion Model (ContactDM) in the second stage to seamlessly interpolate sparse 3D HOI keyframes into densely temporally coherent 4D HOI sequences. To enhance the quality of generated 4D HOI sequences, we propose a novel Contact-Aware Encoder within ContactDM to extract human-object contact patterns and a novel Contact-Aware HOI Attention to effectively integrate the contact signals into diffusion models. Experimental results show that we achieve state-of-the-art results on the publicly available OMOMO and 3D-FUTURE datasets, demonstrating strong generalization abilities to unseen objects, while enabling high-fidelity 4D HOI generation.

