---
layout: default
title: Weakly-supervised VLM-guided Partial Contrastive Learning for Visual Language Navigation
---

# Weakly-supervised VLM-guided Partial Contrastive Learning for Visual Language Navigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15757" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15757v1</a>
  <a href="https://arxiv.org/pdf/2506.15757.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15757v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15757v1', 'Weakly-supervised VLM-guided Partial Contrastive Learning for Visual Language Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ruoyu Wang, Tong Yu, Junda Wu, Yao Liu, Julian McAuley, Lina Yao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¼±ç›‘ç£éƒ¨åˆ†å¯¹æ¯”å­¦ä¹ ä»¥è§£å†³è§†è§‰è¯­è¨€å¯¼èˆªä¸­çš„åŠ¨æ€è§†è§’é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€å¯¼èˆª` `å¼±ç›‘ç£å­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `åŠ¨æ€è§†è§’` `é¢„è®­ç»ƒæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰è¯­è¨€å¯¼èˆªæ–¹æ³•ä¾èµ–äºé¢„è®­ç»ƒæ¨¡å‹ï¼Œéš¾ä»¥å¤„ç†åŠ¨æ€è§†è§’ï¼Œä¸”æœªå¾®è°ƒçš„æ¨¡å‹æ€§èƒ½å—é™ã€‚
2. æœ¬æ–‡æå‡ºå¼±ç›‘ç£éƒ¨åˆ†å¯¹æ¯”å­¦ä¹ ï¼ˆWPCLï¼‰ï¼Œé€šè¿‡æ•´åˆé¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹çŸ¥è¯†ï¼Œæå‡æ™ºèƒ½ä½“åœ¨åŠ¨æ€è§†è§’ä¸‹çš„ç‰©ä½“è¯†åˆ«èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWPCLåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†åŸºçº¿æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰æ˜¯ä½“ç°äººå·¥æ™ºèƒ½çš„åŸºæœ¬ä»»åŠ¡ï¼Œæ—¨åœ¨ä½¿æ™ºèƒ½ä½“æ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤åœ¨å¤æ‚ç¯å¢ƒä¸­å¯¼èˆªã€‚ç°æœ‰æ–¹æ³•é¢ä¸´ä¸€äº›æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ä¾èµ–äºé¢„è®­ç»ƒçš„è§†è§‰æ¨¡å‹ï¼Œéš¾ä»¥å¤„ç†VLNåœºæ™¯ä¸­çš„åŠ¨æ€è§†è§’ï¼›ä½¿ç”¨æœªå¾®è°ƒçš„é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹æˆ–è§†è§‰è¯­è¨€æ¨¡å‹æ—¶ï¼Œæ€§èƒ½å—é™äºç¼ºä¹VLNé¢†åŸŸçŸ¥è¯†ï¼›å¾®è°ƒæ¨¡å‹è™½ç„¶èƒ½æé«˜ç»“æœï¼Œä½†è®¡ç®—æˆæœ¬è¾ƒé«˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†å¼±ç›‘ç£éƒ¨åˆ†å¯¹æ¯”å­¦ä¹ ï¼ˆWPCLï¼‰ï¼Œè¯¥æ–¹æ³•é€šè¿‡æœ‰æ•ˆæ•´åˆé¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹çŸ¥è¯†ï¼Œå¢å¼ºæ™ºèƒ½ä½“åœ¨åŠ¨æ€è§†è§’ä¸‹è¯†åˆ«ç‰©ä½“çš„èƒ½åŠ›ï¼Œè€Œæ— éœ€å¯¹è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWPCLåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºåŸºçº¿æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€å¯¼èˆªä¸­æ™ºèƒ½ä½“åœ¨åŠ¨æ€è§†è§’ä¸‹ç‰©ä½“è¯†åˆ«çš„å›°éš¾ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºé¢„è®­ç»ƒæ¨¡å‹ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹åŠ¨æ€ç¯å¢ƒçš„å˜åŒ–ï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„å¼±ç›‘ç£éƒ¨åˆ†å¯¹æ¯”å­¦ä¹ ï¼ˆWPCLï¼‰æ–¹æ³•é€šè¿‡ä¸éœ€è¦å¾®è°ƒçš„æ–¹å¼ï¼Œæ•´åˆé¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†ï¼Œä»è€Œå¢å¼ºæ™ºèƒ½ä½“çš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œæå‡å…¶å¯¹ç¯å¢ƒçº¿ç´¢çš„è§£è¯»å’Œå“åº”èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šWPCLçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ç‰¹å¾æå–ã€å¯¹æ¯”å­¦ä¹ æ¨¡å—å’Œå†³ç­–æ¨¡å—ã€‚é¦–å…ˆï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹æå–ç‰¹å¾ï¼Œç„¶åé€šè¿‡å¯¹æ¯”å­¦ä¹ å¢å¼ºç‰¹å¾çš„åŒºåˆ†æ€§ï¼Œæœ€åå°†æå–çš„ç‰¹å¾ç”¨äºå¯¼èˆªå†³ç­–ã€‚

**å…³é”®åˆ›æ–°**ï¼šWPCLçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶å¼±ç›‘ç£å­¦ä¹ ç­–ç•¥ï¼Œèƒ½å¤Ÿåœ¨ä¸è¿›è¡Œæ¨¡å‹å¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„çŸ¥è¯†è¿›è¡Œæœ‰æ•ˆçš„ç‰©ä½“è¯†åˆ«ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ä¾èµ–äºå¾®è°ƒçš„ç­–ç•¥å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒWPCLé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å¯¹æ¯”å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šç»“åˆäº†è§†è§‰å’Œè¯­è¨€ç‰¹å¾çš„èåˆï¼Œç¡®ä¿äº†æ¨¡å‹åœ¨åŠ¨æ€è§†è§’ä¸‹çš„é²æ£’æ€§å’Œæ•ˆç‡ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†è¯´æ˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒWPCLåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºä¼ ç»ŸåŸºçº¿æ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°10%ä»¥ä¸Šï¼ŒéªŒè¯äº†å…¶åœ¨è§†è§‰è¯­è¨€å¯¼èˆªä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€æœºå™¨äººå¯¼èˆªå’Œå¢å¼ºç°å®ç­‰åœºæ™¯ã€‚åœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œæ™ºèƒ½ä½“éœ€è¦æ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤åœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œè‡ªä¸»å¯¼èˆªï¼ŒWPCLæ–¹æ³•çš„æå‡ºå°†æ˜¾è‘—æå‡å…¶åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›å’Œæ•ˆç‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual Language Navigation (VLN) is a fundamental task within the field of Embodied AI, focusing on the ability of agents to navigate complex environments based on natural language instructions. Despite the progress made by existing methods, these methods often present some common challenges. First, they rely on pre-trained backbone models for visual perception, which struggle with the dynamic viewpoints in VLN scenarios. Second, the performance is limited when using pre-trained LLMs or VLMs without fine-tuning, due to the absence of VLN domain knowledge. Third, while fine-tuning LLMs and VLMs can improve results, their computational costs are higher than those without fine-tuning. To address these limitations, we propose Weakly-supervised Partial Contrastive Learning (WPCL), a method that enhances an agent's ability to identify objects from dynamic viewpoints in VLN scenarios by effectively integrating pre-trained VLM knowledge into the perception process, without requiring VLM fine-tuning. Our method enhances the agent's ability to interpret and respond to environmental cues while ensuring computational efficiency. Experimental results have shown that our method outperforms the baseline methods on multiple benchmarks, which validate the effectiveness, robustness and generalizability of our method.

