---
layout: default
title: Segment Any 3D Gaussians
---

# Segment Any 3D Gaussians

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00860" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00860v3</a>
  <a href="https://arxiv.org/pdf/2312.00860.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00860v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00860v3', 'Segment Any 3D Gaussians')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiazhong Cen, Jiemin Fang, Chen Yang, Lingxi Xie, Xiaopeng Zhang, Wei Shen, Qi Tian

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01 (æ›´æ–°: 2025-02-05)

**å¤‡æ³¨**: AAAI-25. Project page: https://jumpat.github.io/SAGA

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSAGAæ–¹æ³•ä»¥å®ç°é«˜æ•ˆçš„3Dé«˜æ–¯åˆ†å‰²**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `3Dåˆ†å‰²` `é«˜æ–¯ç‚¹äº‘` `æç¤ºåˆ†å‰²` `å°ºåº¦æ„ŸçŸ¥` `å¯¹æ¯”å­¦ä¹ ` `å®æ—¶å¤„ç†` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„3Dåˆ†å‰²æ–¹æ³•åœ¨å¤„ç†å¤šç²’åº¦ä¿¡æ¯æ—¶å­˜åœ¨æ¨¡ç³Šæ€§ï¼Œéš¾ä»¥å®ç°é«˜æ•ˆä¸”å‡†ç¡®çš„åˆ†å‰²ã€‚
2. SAGAé€šè¿‡å¼•å…¥å°ºåº¦é—¨æ§äº²å’Œç‰¹å¾å’Œå°ºåº¦æ„ŸçŸ¥å¯¹æ¯”è®­ç»ƒç­–ç•¥ï¼Œèƒ½å¤Ÿå¿«é€Ÿä¸”å‡†ç¡®åœ°è¿›è¡Œ3Dé«˜æ–¯åˆ†å‰²ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSAGAåœ¨åˆ†å‰²è´¨é‡å’Œé€Ÿåº¦ä¸Šå‡ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œè¾¾åˆ°äº†å®æ—¶å¤„ç†çš„èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†SAGAï¼ˆSegment Any 3D GAussiansï¼‰ï¼Œä¸€ç§åŸºäº3Dé«˜æ–¯ç‚¹äº‘çš„é«˜æ•ˆ3Dæç¤ºåˆ†å‰²æ–¹æ³•ã€‚SAGAèƒ½å¤Ÿåœ¨4æ¯«ç§’å†…æ ¹æ®è¾“å…¥çš„2Dè§†è§‰æç¤ºå¯¹ç›¸åº”çš„3Dç›®æ ‡è¿›è¡Œåˆ†å‰²ã€‚å…¶æ ¸å¿ƒåœ¨äºä¸ºæ¯ä¸ª3Dé«˜æ–¯é™„åŠ ä¸€ä¸ªå°ºåº¦é—¨æ§äº²å’Œç‰¹å¾ï¼Œä»¥å®ç°å¤šç²’åº¦åˆ†å‰²ã€‚å…·ä½“è€Œè¨€ï¼Œæå‡ºäº†ä¸€ç§å°ºåº¦æ„ŸçŸ¥å¯¹æ¯”è®­ç»ƒç­–ç•¥æ¥å­¦ä¹ å°ºåº¦é—¨æ§äº²å’Œç‰¹å¾ï¼Œæ—¢æç‚¼äº†Segment Anything Modelï¼ˆSAMï¼‰ä»2Dæ©è†œä¸­è·å¾—çš„åˆ†å‰²èƒ½åŠ›ï¼Œåˆé€šè¿‡è½¯å°ºåº¦é—¨æ§æœºåˆ¶å¤„ç†3Dåˆ†å‰²ä¸­çš„å¤šç²’åº¦æ¨¡ç³Šæ€§ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒSAGAåœ¨å®æ—¶å¤šç²’åº¦åˆ†å‰²æ–¹é¢çš„è´¨é‡å¯ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸åª²ç¾ã€‚ä½œä¸ºé¦–ä¸ªè§£å†³3D-GSä¸­å¯æç¤ºåˆ†å‰²é—®é¢˜çš„æ–¹æ³•ä¹‹ä¸€ï¼ŒSAGAçš„ç®€å•æ€§å’Œæœ‰æ•ˆæ€§ä¸ºè¯¥é¢†åŸŸçš„æœªæ¥å‘å±•é“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰3Dåˆ†å‰²æ–¹æ³•åœ¨å¤šç²’åº¦ä¿¡æ¯å¤„ç†ä¸­çš„æ¨¡ç³Šæ€§å’Œæ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•å¿«é€Ÿé€‚åº”ä¸åŒå°ºåº¦çš„åˆ†å‰²éœ€æ±‚ï¼Œå¯¼è‡´åˆ†å‰²ç»“æœä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSAGAçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥å°ºåº¦é—¨æ§äº²å’Œç‰¹å¾ï¼Œä½¿æ¯ä¸ª3Dé«˜æ–¯å…·å¤‡å¤šç²’åº¦åˆ†å‰²èƒ½åŠ›ã€‚é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œæç‚¼å‡ºæœ‰æ•ˆçš„ç‰¹å¾è¡¨ç¤ºï¼Œä»è€Œæå‡åˆ†å‰²çš„å‡†ç¡®æ€§å’Œé€Ÿåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSAGAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥2Dè§†è§‰æç¤ºã€å°ºåº¦é—¨æ§äº²å’Œç‰¹å¾çš„ç”Ÿæˆã€å°ºåº¦æ„ŸçŸ¥å¯¹æ¯”è®­ç»ƒå’Œæœ€ç»ˆçš„3Dåˆ†å‰²è¾“å‡ºã€‚æ¯ä¸ªæ¨¡å—ç›¸äº’é…åˆï¼Œå½¢æˆé«˜æ•ˆçš„åˆ†å‰²æµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šSAGAçš„ä¸»è¦åˆ›æ–°åœ¨äºå°ºåº¦é—¨æ§äº²å’Œç‰¹å¾çš„å¼•å…¥åŠå…¶å­¦ä¹ ç­–ç•¥ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¤šç²’åº¦åˆ†å‰²ä¸­çš„ä¸è¶³ã€‚è¿™ä¸€è®¾è®¡ä½¿å¾—SAGAåœ¨å¤„ç†ä¸åŒå°ºåº¦çš„3Då¯¹è±¡æ—¶è¡¨ç°å‡ºè‰²ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒSAGAé‡‡ç”¨äº†è½¯å°ºåº¦é—¨æ§æœºåˆ¶ï¼Œé€šè¿‡è°ƒæ•´ç‰¹å¾é€šé“çš„å¹…åº¦æ¥é€‚åº”æŒ‡å®šçš„3Dç‰©ç†å°ºåº¦ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šç»“åˆäº†å¯¹æ¯”æŸå¤±ï¼Œä»¥å¢å¼ºç‰¹å¾å­¦ä¹ çš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSAGAåœ¨3Dåˆ†å‰²ä»»åŠ¡ä¸­å®ç°äº†é«˜è¾¾200å¸§æ¯ç§’çš„å¤„ç†é€Ÿåº¦ï¼Œåˆ†å‰²è´¨é‡ä¸å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“ï¼Œæ˜¾ç¤ºå‡ºåœ¨å®æ—¶å¤šç²’åº¦åˆ†å‰²ä¸­çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SAGAæ–¹æ³•åœ¨è®¡ç®—æœºè§†è§‰ã€æœºå™¨äººå¯¼èˆªã€å¢å¼ºç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶é«˜æ•ˆçš„3Dåˆ†å‰²èƒ½åŠ›å¯ä»¥ç”¨äºå®æ—¶åœºæ™¯ç†è§£ã€ç‰©ä½“è¯†åˆ«å’Œäº¤äº’å¼åº”ç”¨ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥å’Œå®é™…åº”ç”¨çš„è½åœ°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents SAGA (Segment Any 3D GAussians), a highly efficient 3D promptable segmentation method based on 3D Gaussian Splatting (3D-GS). Given 2D visual prompts as input, SAGA can segment the corresponding 3D target represented by 3D Gaussians within 4 ms. This is achieved by attaching an scale-gated affinity feature to each 3D Gaussian to endow it a new property towards multi-granularity segmentation. Specifically, a scale-aware contrastive training strategy is proposed for the scale-gated affinity feature learning. It 1) distills the segmentation capability of the Segment Anything Model (SAM) from 2D masks into the affinity features and 2) employs a soft scale gate mechanism to deal with multi-granularity ambiguity in 3D segmentation through adjusting the magnitude of each feature channel according to a specified 3D physical scale. Evaluations demonstrate that SAGA achieves real-time multi-granularity segmentation with quality comparable to state-of-the-art methods. As one of the first methods addressing promptable segmentation in 3D-GS, the simplicity and effectiveness of SAGA pave the way for future advancements in this field. Our code will be released.

