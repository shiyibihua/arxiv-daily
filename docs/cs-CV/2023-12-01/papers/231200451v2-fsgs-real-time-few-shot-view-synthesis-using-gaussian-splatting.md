---
layout: default
title: FSGS: Real-Time Few-shot View Synthesis using Gaussian Splatting
---

# FSGS: Real-Time Few-shot View Synthesis using Gaussian Splatting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00451" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00451v2</a>
  <a href="https://arxiv.org/pdf/2312.00451.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00451v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00451v2', 'FSGS: Real-Time Few-shot View Synthesis using Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zehao Zhu, Zhiwen Fan, Yifan Jiang, Zhangyang Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01 (æ›´æ–°: 2024-06-16)

**å¤‡æ³¨**: Project page: https://zehaozhu.github.io/FSGS/

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://zehaozhu.github.io/FSGS/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFSGSæ¡†æ¶ä»¥å®ç°å®æ—¶å°‘æ ·æœ¬è§†å›¾åˆæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å°‘æ ·æœ¬å­¦ä¹ ` `è§†å›¾åˆæˆ` `é«˜æ–¯æ•£å°„` `å®æ—¶æ¸²æŸ“` `ä¸‰ç»´é‡å»º` `æ·±åº¦ä¼°è®¡` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºNeRFçš„å°‘æ ·æœ¬è§†å›¾åˆæˆæ–¹æ³•åœ¨å‡†ç¡®æ€§ä¸æ•ˆç‡ä¹‹é—´å­˜åœ¨æƒè¡¡ï¼Œéš¾ä»¥å®ç°å®æ—¶æ¸²æŸ“ã€‚
2. æœ¬æ–‡æå‡ºçš„FSGSæ¡†æ¶åˆ©ç”¨3Dé«˜æ–¯æ•£å°„æŠ€æœ¯ï¼Œèƒ½å¤Ÿåœ¨ä»…æœ‰ä¸‰å¹…è®­ç»ƒè§†å›¾çš„æƒ…å†µä¸‹å®ç°é«˜æ•ˆä¸”é€¼çœŸçš„è§†å›¾åˆæˆã€‚
3. FSGSåœ¨å¤šç§æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§å’Œæ¸²æŸ“æ•ˆç‡ï¼Œæ˜¾è‘—æå‡äº†æ–°è§†å›¾çš„è´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»æœ‰é™è§‚å¯Ÿä¸­åˆæˆæ–°è§†å›¾ä»ç„¶æ˜¯ä¸€ä¸ªé‡è¦ä¸”æŒä¹…çš„ä»»åŠ¡ã€‚ç„¶è€Œï¼Œç°æœ‰åŸºäºNeRFçš„å°‘æ ·æœ¬è§†å›¾åˆæˆåœ¨è·å–å‡†ç¡®çš„3Dè¡¨ç¤ºæ—¶å¾€å¾€æ•ˆç‡è¾ƒä½ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº3Dé«˜æ–¯æ•£å°„çš„å°‘æ ·æœ¬è§†å›¾åˆæˆæ¡†æ¶FSGSï¼Œèƒ½å¤Ÿä»¥è‡³å¤šä¸‰å¹…è®­ç»ƒè§†å›¾å®ç°å®æ—¶ä¸”é€¼çœŸçš„è§†å›¾åˆæˆã€‚è¯¥æ–¹æ³•é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„é«˜æ–¯åæ± åŒ–è¿‡ç¨‹å¤„ç†æå…¶ç¨€ç–çš„åˆå§‹åŒ–SfMç‚¹ï¼Œè¿­ä»£åœ°åœ¨æœ€å…·ä»£è¡¨æ€§çš„ä½ç½®å‘¨å›´åˆ†å¸ƒæ–°é«˜æ–¯ï¼Œéšåå¡«å……ç©ºç™½åŒºåŸŸçš„å±€éƒ¨ç»†èŠ‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨é«˜æ–¯ä¼˜åŒ–è¿‡ç¨‹ä¸­é›†æˆäº†å¤§è§„æ¨¡é¢„è®­ç»ƒçš„å•ç›®æ·±åº¦ä¼°è®¡å™¨ï¼Œåˆ©ç”¨åœ¨çº¿å¢å¼ºè§†å›¾å¼•å¯¼å‡ ä½•ä¼˜åŒ–æœå‘æœ€ä½³è§£ã€‚FSGSèƒ½å¤Ÿä»æœ‰é™è¾“å…¥è§†è§’è§‚å¯Ÿåˆ°çš„ç¨€ç–ç‚¹å¼€å§‹ï¼Œå‡†ç¡®æ‰©å±•åˆ°æœªè§åŒºåŸŸï¼Œå…¨é¢è¦†ç›–åœºæ™¯å¹¶æå‡æ–°è§†å›¾çš„æ¸²æŸ“è´¨é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»æœ‰é™è§‚å¯Ÿä¸­åˆæˆæ–°è§†å›¾çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å‡†ç¡®æ€§ä¸æ•ˆç‡ä¹‹é—´å­˜åœ¨å¦¥åï¼Œéš¾ä»¥å®ç°å®æ—¶åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFSGSæ¡†æ¶é€šè¿‡3Dé«˜æ–¯æ•£å°„æŠ€æœ¯ï¼Œå¤„ç†ç¨€ç–çš„åˆå§‹åŒ–SfMç‚¹ï¼Œå¹¶é€šè¿‡é«˜æ–¯åæ± åŒ–è¿‡ç¨‹é€æ­¥å¡«å……ç©ºç™½åŒºåŸŸï¼Œä»è€Œå®ç°é«˜æ•ˆçš„è§†å›¾åˆæˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬é«˜æ–¯åˆ†å¸ƒåˆå§‹åŒ–ã€è¿­ä»£é«˜æ–¯åˆ†å¸ƒæ›´æ–°å’Œé›†æˆå•ç›®æ·±åº¦ä¼°è®¡å™¨ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼Œå½¢æˆä¸€ä¸ªé—­ç¯ä¼˜åŒ–è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šFSGSçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºé«˜æ–¯åæ± åŒ–è¿‡ç¨‹å’Œä¸å•ç›®æ·±åº¦ä¼°è®¡å™¨çš„ç»“åˆï¼Œä½¿å¾—åœ¨æå°‘è®­ç»ƒè§†å›¾çš„æƒ…å†µä¸‹ä»èƒ½å®ç°é«˜è´¨é‡çš„è§†å›¾åˆæˆã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨é«˜æ–¯åˆ†å¸ƒçš„å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†è‡ªé€‚åº”æ›´æ–°ç­–ç•¥ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šç»“åˆäº†å‡ ä½•çº¦æŸä¸å›¾åƒé‡å»ºæŸå¤±ï¼Œç¡®ä¿äº†åˆæˆè§†å›¾çš„å‡†ç¡®æ€§ä¸çœŸå®æ„Ÿã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

FSGSåœ¨LLFFã€Mip-NeRF360å’ŒBlenderç­‰å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå‡†ç¡®æ€§å’Œæ¸²æŸ“æ•ˆç‡å‡æœ‰æ˜¾è‘—æå‡ã€‚å…·ä½“è€Œè¨€ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼ŒFSGSåœ¨æ¸²æŸ“è´¨é‡ä¸Šæå‡äº†çº¦20%ï¼Œå¹¶ä¸”åœ¨å¤„ç†é€Ÿåº¦ä¸Šè¾¾åˆ°äº†å®æ—¶æ°´å¹³ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FSGSæ¡†æ¶åœ¨è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ä»¥åŠæ¸¸æˆå¼€å‘ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶å®æ—¶åˆæˆèƒ½åŠ›èƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´åŠ æ²‰æµ¸å¼çš„ä½“éªŒï¼ŒåŒæ—¶åœ¨å½±è§†åˆ¶ä½œä¸­ä¹Ÿèƒ½æ˜¾è‘—æé«˜åœºæ™¯æ¸²æŸ“çš„æ•ˆç‡ä¸è´¨é‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½æ¨åŠ¨æ›´å¤šåŸºäºè§†è§‰çš„äº¤äº’åº”ç”¨çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Novel view synthesis from limited observations remains an important and persistent task. However, high efficiency in existing NeRF-based few-shot view synthesis is often compromised to obtain an accurate 3D representation. To address this challenge, we propose a few-shot view synthesis framework based on 3D Gaussian Splatting that enables real-time and photo-realistic view synthesis with as few as three training views. The proposed method, dubbed FSGS, handles the extremely sparse initialized SfM points with a thoughtfully designed Gaussian Unpooling process. Our method iteratively distributes new Gaussians around the most representative locations, subsequently infilling local details in vacant areas. We also integrate a large-scale pre-trained monocular depth estimator within the Gaussians optimization process, leveraging online augmented views to guide the geometric optimization towards an optimal solution. Starting from sparse points observed from limited input viewpoints, our FSGS can accurately grow into unseen regions, comprehensively covering the scene and boosting the rendering quality of novel views. Overall, FSGS achieves state-of-the-art performance in both accuracy and rendering efficiency across diverse datasets, including LLFF, Mip-NeRF360, and Blender. Project website: https://zehaozhu.github.io/FSGS/.

