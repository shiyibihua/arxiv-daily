---
layout: default
title: Enhancing Diffusion Models with 3D Perspective Geometry Constraints
---

# Enhancing Diffusion Models with 3D Perspective Geometry Constraints

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00944" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00944v1</a>
  <a href="https://arxiv.org/pdf/2312.00944.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00944v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00944v1', 'Enhancing Diffusion Models with 3D Perspective Geometry Constraints')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rishi Upadhyay, Howard Zhang, Yunhao Ba, Ethan Yang, Blake Gella, Sicheng Jiang, Alex Wong, Achuta Kadambi

**åˆ†ç±»**: cs.CV, cs.GR

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01

**å¤‡æ³¨**: Project Webpage: http://visual.ee.ucla.edu/diffusionperspective.htm/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå‡ ä½•çº¦æŸä»¥å¢å¼ºæ‰©æ•£æ¨¡å‹çš„é€è§†å‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡å‹` `å‡ ä½•çº¦æŸ` `é€è§†å‡†ç¡®æ€§` `å›¾åƒç”Ÿæˆ` `æ·±åº¦ä¼°è®¡` `è®¡ç®—æœºè§†è§‰` `ç”Ÿæˆæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ—¶æœªèƒ½æœ‰æ•ˆéµå¾ªçº¿æ€§é€è§†åŸåˆ™ï¼Œå¯¼è‡´ç”Ÿæˆå›¾åƒçš„é€è§†å‡†ç¡®æ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å‡ ä½•çº¦æŸï¼Œé€šè¿‡åœ¨ç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥é€è§†å‡†ç¡®æ€§çº¦æŸï¼Œæ¥æ”¹å–„ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œåº”ç”¨è¯¥çº¦æŸçš„æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒçš„çœŸå®æ„Ÿå’Œä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œå°¤å…¶åœ¨æ·±åº¦ä¼°è®¡ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡é€è§†åœ¨è‰ºæœ¯ä¸­æ˜¯ä¸€ä¸ªç ”ç©¶å¹¿æ³›çš„è¯é¢˜ï¼Œä½†åœ¨å›¾åƒåˆæˆä¸­é€šå¸¸è¢«å¿½è§†ã€‚è¿‘å¹´æ¥çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ—¶å¹¶æœªæ˜ç¡®è¦æ±‚é€è§†å‡†ç¡®æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å‡ ä½•çº¦æŸï¼Œæ—¨åœ¨è®­ç»ƒç”Ÿæˆæ¨¡å‹æ—¶å¼ºåˆ¶æ‰§è¡Œé€è§†å‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåº”ç”¨è¯¥çº¦æŸè®­ç»ƒçš„æ¨¡å‹è¾“å‡ºå›¾åƒæ›´ä¸ºçœŸå®ï¼Œå¹¶ä¸”åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°æ›´ä½³ã€‚ä¸»è§‚è¯„ä¼°æ˜¾ç¤ºï¼Œä½¿ç”¨è¯¥çº¦æŸçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„å›¾åƒåœ¨70%çš„æƒ…å†µä¸‹ä¼˜äºStable Diffusion V2æ¨¡å‹ã€‚ç»è¿‡å¾®è°ƒçš„å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹åœ¨KITTIæµ‹è¯•é›†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—æå‡ï¼ŒRMSEå’ŒSqRelåˆ†åˆ«æé«˜äº†7.03%å’Œ19.3%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ½œåœ¨æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­é€è§†å‡†ç¡®æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåœ°å°†é€è§†åŸåˆ™èå…¥ç”Ÿæˆè¿‡ç¨‹ï¼Œå¯¼è‡´ç”Ÿæˆå›¾åƒçš„è´¨é‡å’ŒçœŸå®æ„Ÿä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§å‡ ä½•çº¦æŸï¼Œå¼ºåˆ¶ç”Ÿæˆæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éµå¾ªé€è§†å‡†ç¡®æ€§ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æå‡ç”Ÿæˆå›¾åƒçš„çœŸå®æ„Ÿï¼Œå¹¶æ”¹å–„åç»­ä»»åŠ¡çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¼•å…¥å‡ ä½•çº¦æŸçš„ç”Ÿæˆæ¨¡å‹è®­ç»ƒæµç¨‹ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€å‡ ä½•çº¦æŸçš„å®šä¹‰ä¸å®ç°ã€æ¨¡å‹è®­ç»ƒåŠè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥å‡ ä½•çº¦æŸä»¥å¢å¼ºé€è§†å‡†ç¡®æ€§ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºå¼ºè°ƒäº†é€è§†åŸåˆ™åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­çš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°ä¸­åŠ å…¥é€è§†ç›¸å…³çš„çº¦æŸé¡¹ï¼Œè°ƒæ•´ç½‘ç»œç»“æ„ä»¥é€‚åº”å‡ ä½•çº¦æŸçš„å®ç°ï¼Œç¡®ä¿ç”Ÿæˆå›¾åƒåœ¨é€è§†æ–¹é¢çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨å‡ ä½•çº¦æŸè®­ç»ƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„å›¾åƒåœ¨70%çš„ä¸»è§‚è¯„ä¼°ä¸­ä¼˜äºStable Diffusion V2æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç»è¿‡å¾®è°ƒçš„å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹åœ¨KITTIæµ‹è¯•é›†ä¸Šï¼ŒRMSEå’ŒSqRelåˆ†åˆ«æé«˜äº†7.03%å’Œ19.3%ï¼Œå±•ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰ã€‚é€šè¿‡æé«˜ç”Ÿæˆå›¾åƒçš„é€è§†å‡†ç¡®æ€§ï¼Œå¯ä»¥åœ¨è‰ºæœ¯åˆ›ä½œã€æ¸¸æˆè®¾è®¡å’Œè‡ªåŠ¨é©¾é©¶ç­‰å¤šä¸ªé¢†åŸŸå®ç°æ›´é«˜çš„çœŸå®æ„Ÿå’Œç”¨æˆ·ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While perspective is a well-studied topic in art, it is generally taken for granted in images. However, for the recent wave of high-quality image synthesis methods such as latent diffusion models, perspective accuracy is not an explicit requirement. Since these methods are capable of outputting a wide gamut of possible images, it is difficult for these synthesized images to adhere to the principles of linear perspective. We introduce a novel geometric constraint in the training process of generative models to enforce perspective accuracy. We show that outputs of models trained with this constraint both appear more realistic and improve performance of downstream models trained on generated images. Subjective human trials show that images generated with latent diffusion models trained with our constraint are preferred over images from the Stable Diffusion V2 model 70% of the time. SOTA monocular depth estimation models such as DPT and PixelFormer, fine-tuned on our images, outperform the original models trained on real images by up to 7.03% in RMSE and 19.3% in SqRel on the KITTI test set for zero-shot transfer.

