---
layout: default
title: ASCD: Attention-Steerable Contrastive Decoding for Reducing Hallucination in MLLM
---

# ASCD: Attention-Steerable Contrastive Decoding for Reducing Hallucination in MLLM

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.14766" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.14766v2</a>
  <a href="https://arxiv.org/pdf/2506.14766.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.14766v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.14766v2', 'ASCD: Attention-Steerable Contrastive Decoding for Reducing Hallucination in MLLM')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yujun Wang, Aniri, Jinhe Bi, Soeren Pirk, Yunpu Ma

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-17 (æ›´æ–°: 2025-10-19)

**å¤‡æ³¨**: 14 pages, 8 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºASCDä»¥å‡å°‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å¹»è§‰ç°è±¡` `å¯¹æ¯”è§£ç ` `æ³¨æ„åŠ›æœºåˆ¶` `ç”Ÿæˆæ¨¡å‹` `è§†è§‰ç†è§£` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†è§†è§‰ä¿¡æ¯æ—¶ï¼Œå¸¸å¸¸ä¼šå—åˆ°è™šå‡çº¿ç´¢çš„å½±å“ï¼Œå¯¼è‡´ç”Ÿæˆä¸å‡†ç¡®çš„å†…å®¹ã€‚
2. æœ¬æ–‡æå‡ºçš„æ³¨æ„åŠ›å¯å¼•å¯¼å¯¹æ¯”è§£ç ï¼ˆASCDï¼‰æ–¹æ³•ï¼Œé€šè¿‡å¼•å¯¼æ³¨æ„åŠ›åˆ†æ•°æ¥å‡å°‘å¹»è§‰ç°è±¡ï¼Œç»“åˆæ­£å‘å’Œè´Ÿå‘å¼•å¯¼ç­–ç•¥ã€‚
3. ASCDåœ¨äº”ä¸ªMLLMéª¨å¹²å’Œä¸‰ç§è§£ç æ–¹æ¡ˆä¸Šï¼Œå‡å°‘äº†å¹»è§‰ç°è±¡æœ€å¤š38.2%ï¼ŒåŒæ—¶åœ¨æ ‡å‡†VQAåŸºå‡†ä¸Šæé«˜äº†å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å¸¸å¸¸å› è¿‡åº¦ä¾èµ–è™šå‡è§†è§‰çº¿ç´¢è€Œäº§ç”Ÿå¹»è§‰ã€‚ä»¥å¾€çš„è§£å†³æ–¹æ¡ˆå¦‚è§†è§‰å’ŒæŒ‡ä»¤å¯¹æ¯”è§£ç ï¼ˆVCD, ICDï¼‰è™½ç„¶æœ‰æ‰€æ”¹å–„ï¼Œä½†å…¶æœºåˆ¶ä»ä¸æ˜ç¡®ã€‚æœ¬æ–‡é¦–æ¬¡å®è¯è¡¨æ˜ï¼Œè¿™äº›æ–¹æ³•çš„æ”¹è¿›ä¸è·¨æ¨¡æ€æ³¨æ„åŠ›çš„é‡æ–°åˆ†é…ç³»ç»Ÿæ€§ç›¸å…³ã€‚åŸºäºæ­¤ï¼Œæå‡ºäº†æ³¨æ„åŠ›å¯å¼•å¯¼å¯¹æ¯”è§£ç ï¼ˆASCDï¼‰ï¼Œè¯¥æ–¹æ³•ç›´æ¥åœ¨è§£ç è¿‡ç¨‹ä¸­å¼•å¯¼æ³¨æ„åŠ›åˆ†æ•°ã€‚ASCDç»“åˆäº†æ­£å‘å¼•å¯¼å’Œè´Ÿå‘å¼•å¯¼ï¼Œå‰è€…å¢å¼ºäº†æ¨¡å‹å†…éƒ¨ç¨³å®šä¸”è·¨é¢†åŸŸé²æ£’çš„æ–‡æœ¬ä¸­å¿ƒå¤´éƒ¨ï¼Œåè€…åˆ™æŠ‘åˆ¶äº†å®æ—¶è¯†åˆ«çš„å…³é”®è§†è§‰æ ‡è®°ã€‚è¯¥æ–¹æ³•åœ¨è¿è¡Œæ—¶å’Œå†…å­˜å¼€é”€ä¸Šå‡ ä¹æ²¡æœ‰å½±å“ï¼Œå¹¶ä¸”æ— éœ€é¢å¤–è®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒASCDåœ¨å¤šä¸ªMLLMéª¨å¹²å’Œè§£ç æ–¹æ¡ˆä¸Šï¼Œå‡å°‘äº†POPEã€CHAIRå’ŒMMHal-Benchä¸Šçš„å¹»è§‰ç°è±¡ï¼Œæå‡äº†æ ‡å‡†VQAåŸºå‡†çš„å‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å› è™šå‡è§†è§‰çº¿ç´¢è€Œäº§ç”Ÿçš„å¹»è§‰é—®é¢˜ã€‚ç°æœ‰çš„è§£å†³æ–¹æ¡ˆå¦‚VCDå’ŒICDè™½ç„¶æœ‰æ‰€æ”¹å–„ï¼Œä½†å…¶æœºåˆ¶ä¸å¤Ÿé€æ˜ï¼Œéš¾ä»¥ç†è§£å…¶æ•ˆæœæ¥æºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„ASCDæ–¹æ³•é€šè¿‡ç›´æ¥å¼•å¯¼è§£ç è¿‡ç¨‹ä¸­çš„æ³¨æ„åŠ›åˆ†æ•°ï¼Œæ¥å‡å°‘å¹»è§‰ç°è±¡ã€‚è¯¥æ–¹æ³•ç»“åˆäº†æ­£å‘å¼•å¯¼ï¼ˆå¢å¼ºæ–‡æœ¬ä¸­å¿ƒå¤´éƒ¨ï¼‰å’Œè´Ÿå‘å¼•å¯¼ï¼ˆæŠ‘åˆ¶å…³é”®è§†è§‰æ ‡è®°ï¼‰ï¼Œä»è€Œå®ç°æ›´å‡†ç¡®çš„å¤šæ¨¡æ€ç”Ÿæˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šASCDçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæ­£å‘å¼•å¯¼æ¨¡å—å’Œè´Ÿå‘å¼•å¯¼æ¨¡å—ã€‚æ­£å‘å¼•å¯¼æ¨¡å—è‡ªåŠ¨æŒ–æ˜å¹¶æ”¾å¤§æ–‡æœ¬ä¸­å¿ƒçš„æ³¨æ„åŠ›å¤´ï¼Œè€Œè´Ÿå‘å¼•å¯¼æ¨¡å—åˆ™å®æ—¶è¯†åˆ«å¹¶æŠ‘åˆ¶ä¸å¿…è¦çš„è§†è§‰æ ‡è®°ã€‚

**å…³é”®åˆ›æ–°**ï¼šASCDçš„åˆ›æ–°åœ¨äºå…¶æ³¨æ„åŠ›å¼•å¯¼æœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨è§£ç è¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´æ³¨æ„åŠ›åˆ†æ•°ï¼ŒåŒºåˆ«äºä»¥å¾€é™æ€çš„å¯¹æ¯”è§£ç æ–¹æ³•ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸå’Œä»»åŠ¡ä¸­éƒ½èƒ½ä¿æŒé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šASCDåœ¨å®ç°è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†è½»é‡çº§çš„å‚æ•°è®¾ç½®ï¼Œç¡®ä¿åœ¨è¿è¡Œæ—¶å’Œå†…å­˜å¼€é”€ä¸Šå‡ ä¹æ²¡æœ‰å½±å“ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦é¢å¤–çš„è®­ç»ƒï¼Œä¾¿äºåœ¨ç°æœ‰æ¨¡å‹ä¸Šç›´æ¥åº”ç”¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ASCDåœ¨äº”ä¸ªä¸åŒçš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹éª¨å¹²å’Œä¸‰ç§è§£ç æ–¹æ¡ˆä¸Šè¡¨ç°å‡ºè‰²ï¼Œå‡å°‘å¹»è§‰ç°è±¡æœ€å¤šè¾¾åˆ°38.2%ã€‚åŒæ—¶ï¼Œè¯¥æ–¹æ³•åœ¨æ ‡å‡†VQAåŸºå‡†æµ‹è¯•ä¸­æé«˜äº†å‡†ç¡®æ€§ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šæ¨¡æ€ç”Ÿæˆä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šæ¨¡æ€ç”Ÿæˆä»»åŠ¡ï¼Œå¦‚å›¾åƒæè¿°ã€è§†é¢‘ç†è§£å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡å‡å°‘å¹»è§‰ç°è±¡ï¼ŒASCDèƒ½å¤Ÿæå‡ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šå½±å“å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„è®¾è®¡å’Œåº”ç”¨ï¼Œæ¨åŠ¨æ›´å®‰å…¨å’Œå¯é çš„AIç³»ç»Ÿå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) frequently hallucinate by over-committing to spurious visual cues. Prior remedies-Visual and Instruction Contrastive Decoding (VCD, ICD)-mitigate this issue, yet the mechanism remains opaque. We first empirically show that their improvements systematically coincide with redistributions of cross-modal attention. Building on this insight, we propose Attention-Steerable Contrastive Decoding (ASCD), which directly steers the attention scores during decoding. ASCD combines (i) positive steering, which amplifies automatically mined text-centric heads-stable within a model and robust across domains-with (ii) negative steering, which dampens on-the-fly identified critical visual tokens. The method incurs negligible runtime and memory overhead and requires no additional training. Across five MLLM backbones and three decoding schemes, ASCD reduces hallucination on POPE, CHAIR, and MMHal-Bench by up to 38.2 percent while improving accuracy on standard VQA benchmarks, including MMMU, MM-VET, ScienceQA, TextVQA, and GQA. These results position attention steering as a simple, model-agnostic, and principled route to safer, more faithful multimodal generation.

