---
layout: default
title: Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection
---

# Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.14473" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.14473v2</a>
  <a href="https://arxiv.org/pdf/2506.14473.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.14473v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.14473v2', 'Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhijing Wan, Zhixiang Wang, Zheng Wang, Xin Xu, Shin'ichi Satoh

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-17 (æ›´æ–°: 2025-06-27)

**å¤‡æ³¨**: 18 pages, 10 figures, accepted by ICML 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRAM-APLä»¥è§£å†³ç»†ç²’åº¦ä¸€-shotå­é›†é€‰æ‹©é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸€-shotå­¦ä¹ ` `å­é›†é€‰æ‹©` `åŸºç¡€æ¨¡å‹` `ç»†ç²’åº¦åˆ†ç±»` `ä¿¡æ¯æå–å™¨` `æ·±åº¦å­¦ä¹ ` `æ•°æ®é€‰æ‹©` `ä¼ªç±»æ ‡ç­¾`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä¸€-shotå­é›†é€‰æ‹©æ–¹æ³•ä¾èµ–äºä¼ ç»Ÿçš„ä¿¡æ¯æå–å™¨ï¼Œå­˜åœ¨æ•°æ®é›†ä¾èµ–æ€§ï¼Œé™åˆ¶äº†å…¶é€šç”¨æ€§å’Œé€‚åº”æ€§ã€‚
2. æœ¬æ–‡æå‡ºRAM-APLæ–¹æ³•ï¼Œåˆ©ç”¨å¤šä¸ªåŸºç¡€æ¨¡å‹çš„äº’è¡¥ä¼˜åŠ¿ï¼Œæ—¨åœ¨æå‡ç»†ç²’åº¦å›¾åƒæ•°æ®é›†çš„å­é›†é€‰æ‹©æ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRAM-APLåœ¨å¤šä¸ªç»†ç²’åº¦æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æ˜¾è‘—æå‡äº†é€‰æ‹©å‡†ç¡®ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸€-shotå­é›†é€‰æ‹©ä½œä¸ºä¸€ç§æœ‰æ•ˆå·¥å…·ï¼Œé€šè¿‡ä¿¡æ¯æå–å™¨ï¼ˆIEï¼‰è¯†åˆ«ä¿¡æ¯ä¸°å¯Œçš„æ•°æ®å­é›†ï¼Œä»è€Œé™ä½æ·±åº¦å­¦ä¹ è®­ç»ƒæˆæœ¬ã€‚ä¼ ç»Ÿçš„IEé€šå¸¸åœ¨ç›®æ ‡æ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå› æ­¤å…·æœ‰æ•°æ®é›†ä¾èµ–æ€§ã€‚åŸºç¡€æ¨¡å‹ï¼ˆFMï¼‰æä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¯èƒ½ç¼“è§£è¿™ä¸€é™åˆ¶ã€‚æœ¬æ–‡æ¢è®¨äº†ä¸¤ä¸ªå…³é”®é—®é¢˜ï¼š1ï¼‰åŸºäºFMçš„å­é›†é€‰æ‹©æ˜¯å¦èƒ½åœ¨å¤šæ ·åŒ–æ•°æ®é›†ä¸Šè¶…è¶Šä¼ ç»ŸIEæ–¹æ³•ï¼Ÿ2ï¼‰æ‰€æœ‰FMåœ¨å­é›†é€‰æ‹©ä¸­è¡¨ç°æ˜¯å¦ç›¸åŒï¼Ÿå®éªŒç»“æœè¡¨æ˜ï¼ŒFMåœ¨ç»†ç²’åº¦æ•°æ®é›†ä¸Šå§‹ç»ˆä¼˜äºä¼ ç»ŸIEï¼Œè€Œåœ¨å¸¦æœ‰å™ªå£°æ ‡ç­¾çš„ç²—ç²’åº¦æ•°æ®é›†ä¸Šå…¶ä¼˜åŠ¿å‡å¼±ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†RAM-APLï¼ˆä¼ªç±»æ ‡ç­¾çš„å¹³å‡å‡†ç¡®ç‡æ’åï¼‰ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨å¤šä¸ªFMçš„äº’è¡¥ä¼˜åŠ¿æ¥å¢å¼ºå­é›†é€‰æ‹©ï¼Œåœ¨Oxford-IIIT Petã€Food-101å’ŒCaltech-UCSD Birds-200-2011ç­‰ç»†ç²’åº¦æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿä¿¡æ¯æå–å™¨åœ¨ä¸€-shotå­é›†é€‰æ‹©ä¸­çš„æ•°æ®é›†ä¾èµ–æ€§é—®é¢˜ï¼Œå¯¼è‡´å…¶åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¸ä¸€è‡´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥åŸºç¡€æ¨¡å‹ï¼ˆFMï¼‰ï¼Œåˆ©ç”¨å…¶åœ¨å¤šæ ·åŒ–æ•°æ®é›†ä¸Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œç»“åˆå¤šä¸ªFMçš„ä¼˜åŠ¿ï¼Œæå‡ºRAM-APLæ–¹æ³•ä»¥æå‡ç»†ç²’åº¦å›¾åƒæ•°æ®é›†çš„å­é›†é€‰æ‹©æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ–¹æ³•åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€FMç‰¹å¾æå–ã€ä¼ªç±»æ ‡ç­¾ç”Ÿæˆå’ŒåŸºäºæ’åçš„å­é›†é€‰æ‹©å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆå¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œç„¶åä½¿ç”¨å¤šä¸ªFMæå–ç‰¹å¾ï¼Œæ¥ç€ç”Ÿæˆä¼ªç±»æ ‡ç­¾ï¼Œæœ€åé€šè¿‡æ’åç®—æ³•é€‰æ‹©æœ€ä¼˜å­é›†ã€‚

**å…³é”®åˆ›æ–°**ï¼šRAM-APLæ–¹æ³•çš„åˆ›æ–°åœ¨äºåˆ©ç”¨å¤šä¸ªFMçš„äº’è¡¥ç‰¹æ€§ï¼Œå…‹æœäº†å•ä¸€IEæ–¹æ³•çš„å±€é™æ€§ï¼Œå°¤å…¶åœ¨ç»†ç²’åº¦æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒRAM-APLé‡‡ç”¨äº†å¤šç§FMçš„ç»„åˆç­–ç•¥ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸ºä¼˜åŒ–ä¼ªç±»æ ‡ç­¾çš„å‡†ç¡®ç‡ï¼Œç½‘ç»œç»“æ„åˆ™åŸºäºç°æœ‰çš„å…ˆè¿›FMæ¶æ„è¿›è¡Œè°ƒæ•´ï¼Œä»¥é€‚åº”ç»†ç²’åº¦å›¾åƒçš„ç‰¹å¾æå–éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRAM-APLåœ¨ç»†ç²’åº¦æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…·ä½“åœ¨Oxford-IIIT Petæ•°æ®é›†ä¸Šæå‡äº†é€‰æ‹©å‡†ç¡®ç‡è¾¾5.2%ï¼Œåœ¨Food-101å’ŒCaltech-UCSD Birds-200-2011ä¸Šä¹Ÿå‡è¡¨ç°å‡ºæ˜¾è‘—çš„ä¼˜åŠ¿ï¼Œç›¸è¾ƒäºä¼ ç»ŸIEæ–¹æ³•æœ‰æ˜æ˜¾æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å›¾åƒåˆ†ç±»ã€ç‰©ä½“æ£€æµ‹å’Œæ•°æ®é€‰æ‹©ç­‰ä»»åŠ¡ï¼Œå°¤å…¶åœ¨éœ€è¦é«˜æ•ˆæ•°æ®åˆ©ç”¨çš„åœºæ™¯ä¸­å…·æœ‰å®é™…ä»·å€¼ã€‚æœªæ¥ï¼ŒRAM-APLæ–¹æ³•å¯æ‰©å±•è‡³å…¶ä»–é¢†åŸŸï¼Œå¦‚è‡ªç„¶è¯­è¨€å¤„ç†å’ŒéŸ³é¢‘åˆ†æï¼Œæ¨åŠ¨å¤šæ¨¡æ€å­¦ä¹ çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> One-shot subset selection serves as an effective tool to reduce deep learning training costs by identifying an informative data subset based on the information extracted by an information extractor (IE). Traditional IEs, typically pre-trained on the target dataset, are inherently dataset-dependent. Foundation models (FMs) offer a promising alternative, potentially mitigating this limitation. This work investigates two key questions: (1) Can FM-based subset selection outperform traditional IE-based methods across diverse datasets? (2) Do all FMs perform equally well as IEs for subset selection? Extensive experiments uncovered surprising insights: FMs consistently outperform traditional IEs on fine-grained datasets, whereas their advantage diminishes on coarse-grained datasets with noisy labels. Motivated by these finding, we propose RAM-APL (RAnking Mean-Accuracy of Pseudo-class Labels), a method tailored for fine-grained image datasets. RAM-APL leverages multiple FMs to enhance subset selection by exploiting their complementary strengths. Our approach achieves state-of-the-art performance on fine-grained datasets, including Oxford-IIIT Pet, Food-101, and Caltech-UCSD Birds-200-2011.

