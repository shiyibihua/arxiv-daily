---
layout: default
title: SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks
---

# SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.14512" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.14512v3</a>
  <a href="https://arxiv.org/pdf/2506.14512.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.14512v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.14512v3', 'SIRI-Bench: Challenging VLMs\' Spatial Intelligence through Complex Reasoning Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zijian Song, Xiaoxin Lin, Qiuming Huang, Guangrun Wang, Liang Lin

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-17 (æ›´æ–°: 2025-10-17)

**å¤‡æ³¨**: 20 pages, 11 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSIRI-Benchä»¥è¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹çš„ç©ºé—´æ™ºèƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `ç©ºé—´æ™ºèƒ½` `å¤æ‚æ¨ç†` `åŸºå‡†æµ‹è¯•` `3Dåœºæ™¯ç”Ÿæˆ` `è‡ªåŠ¨åŒ–æ•°æ®åˆæˆ` `ç»“æ„æ¨ç†` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ç©ºé—´æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°ä¸è¶³ï¼Œç¼ºä¹ç³»ç»Ÿæ€§çš„è¯„ä¼°åŸºå‡†ã€‚
2. æœ¬æ–‡æå‡ºSIRI-Benchï¼Œé€šè¿‡9000ä¸ªè§†é¢‘-é—®é¢˜-ç­”æ¡ˆä¸‰å…ƒç»„è¯„ä¼°VLMsçš„ç»“æ„ç©ºé—´æ™ºèƒ½ï¼Œç»“åˆç©ºé—´ç†è§£ä¸ç»“æ„æ¨ç†ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰æœ€å…ˆè¿›çš„VLMsåœ¨SIRI-Benchä¸Šé¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ï¼Œå¼ºè°ƒäº†ç»“æ„ç©ºé—´æ¨ç†çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šå–å¾—äº†å¿«é€Ÿè¿›å±•ï¼Œè€Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨çœŸå®ä¸–ç•Œäº¤äº’ä¸­å¯¹ç©ºé—´æ™ºèƒ½çš„éœ€æ±‚å´æœªå¾—åˆ°ç³»ç»Ÿç ”ç©¶ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡æå‡ºäº†SIRI-Benchï¼Œä¸€ä¸ªæ—¨åœ¨é€šè¿‡ç©ºé—´åŸºç¡€æ¨ç†ä»»åŠ¡è¯„ä¼°VLMsç»“æ„ç©ºé—´æ™ºèƒ½çš„åŸºå‡†ã€‚SIRI-BenchåŒ…å«9000ä¸ªè§†é¢‘-é—®é¢˜-ç­”æ¡ˆä¸‰å…ƒç»„ï¼Œæ¯ä¸ªé—®é¢˜éƒ½åµŒå…¥åœ¨é€¼çœŸçš„3Dåœºæ™¯ä¸­ã€‚è¯¥åŸºå‡†çš„è®¾è®¡è¦æ±‚è§£å†³æ¯ä¸ªé—®é¢˜æ—¶å¿…é¡»å…·å¤‡ç©ºé—´ç†è§£å’Œç»“æ„æ¨ç†èƒ½åŠ›ã€‚ä¸ºä¿ƒè¿›å¤§è§„æ¨¡æ•°æ®åˆæˆï¼Œæœ¬æ–‡å¼€å‘äº†ä¸€ä¸ªè‡ªåŠ¨åœºæ™¯åˆ›å»ºå¼•æ“ï¼Œåˆ©ç”¨åä½œçš„LLMä»£ç†å°†æŠ½è±¡æ•°å­¦é—®é¢˜è½¬åŒ–ä¸ºçœŸå®çš„3Dåœºæ™¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰æœ€å…ˆè¿›çš„VLMsåœ¨SIRI-Benchä¸Šè¡¨ç°ä¸ä½³ï¼Œå‡¸æ˜¾äº†ç»“æ„ç©ºé—´æ¨ç†çš„æŒ‘æˆ˜ã€‚å¸Œæœ›æœ¬ç ”ç©¶èƒ½å¼•èµ·ç ”ç©¶è€…å¯¹ç©ºé—´åŸºç¡€æ¨ç†çš„å…³æ³¨ï¼Œæ¨åŠ¨VLMsåœ¨è§†è§‰é—®é¢˜è§£å†³æ–¹é¢çš„è¿›å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ç©ºé—´æ¨ç†ä»»åŠ¡ä¸­çš„è¯„ä¼°ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè¡¡é‡å…¶ç©ºé—´æ™ºèƒ½èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®¾è®¡SIRI-BenchåŸºå‡†ï¼Œç»“åˆç©ºé—´åŸºç¡€æ¨ç†ä»»åŠ¡ï¼Œè¦æ±‚æ¨¡å‹å…·å¤‡ç©ºé—´ç†è§£ä¸ç»“æ„æ¨ç†èƒ½åŠ›ï¼Œä»¥å…¨é¢è¯„ä¼°VLMsçš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSIRI-Benchçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®ç”Ÿæˆæ¨¡å—å’Œè¯„ä¼°æ¨¡å—ã€‚æ•°æ®ç”Ÿæˆæ¨¡å—åˆ©ç”¨è‡ªåŠ¨åœºæ™¯åˆ›å»ºå¼•æ“ç”Ÿæˆ3Dåœºæ™¯ï¼Œè¯„ä¼°æ¨¡å—åˆ™é€šè¿‡é—®é¢˜-ç­”æ¡ˆå¯¹æ¥æµ‹è¯•æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼€å‘äº†è‡ªåŠ¨åœºæ™¯åˆ›å»ºå¼•æ“ï¼Œåˆ©ç”¨åä½œçš„LLMä»£ç†å°†æŠ½è±¡é—®é¢˜è½¬åŒ–ä¸ºçœŸå®åœºæ™¯ï¼Œè¿™ä¸€æ–¹æ³•åœ¨ç°æœ‰ç ”ç©¶ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®åˆæˆè¿‡ç¨‹ä¸­ï¼Œè®¾ç½®äº†å¤šç§å‚æ•°ä»¥ç¡®ä¿ç”Ÿæˆåœºæ™¯çš„çœŸå®æ€§å’Œå¤æ‚æ€§ï¼ŒåŒæ—¶é‡‡ç”¨äº†é€‚åˆç©ºé—´æ¨ç†çš„æŸå¤±å‡½æ•°ï¼Œä»¥æé«˜æ¨¡å‹çš„å­¦ä¹ æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰æœ€å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨SIRI-Benchä¸Šè¡¨ç°ä¸ä½³ï¼Œæ•´ä½“å‡†ç¡®ç‡æ˜¾è‘—ä½äºé¢„æœŸï¼Œå¼ºè°ƒäº†ç»“æ„ç©ºé—´æ¨ç†çš„å¤æ‚æ€§å’ŒæŒ‘æˆ˜æ€§ã€‚è¿™ä¸€å‘ç°ä¸ºæœªæ¥çš„ç ”ç©¶æŒ‡æ˜äº†æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ç­‰ï¼Œèƒ½å¤Ÿæå‡è¿™äº›é¢†åŸŸä¸­æ¨¡å‹çš„ç©ºé—´ç†è§£ä¸æ¨ç†èƒ½åŠ›ã€‚æœªæ¥ï¼ŒSIRI-Benchå¯èƒ½æˆä¸ºè¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹çš„é‡è¦æ ‡å‡†ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have undergone rapid progress, largely attributed to reinforcement learning on complex reasoning tasks. In contrast, while spatial intelligence is fundamental for Vision-Language Models (VLMs) in real-world interaction, the systematic study of their complex spatial reasoning remains underexplored. To bridge this gap, we introduce SIRI-Bench, a benchmark designed to evaluate VLMs' structural spatial intelligence through spatial-grounded reasoning tasks. SIRI-Bench comprises 9,000 video-question-answer triplets, where each problem is embedded in a realistic 3D scene. The benchmark is carefully designed so that solving each problem requires both spatial comprehension and structural reasoning. To facilitate large-scale data synthesis, we develop an Automatic Scene Creation Engine that employs collaborative LLM agents to translate abstract mathematical problems into faithful 3D scenes. Experimental results reveal that state-of-the-art VLMs struggle significantly on SIRI-Bench, underscoring the challenge of structural spatial reasoning. We hope that our study will bring researchers' attention to spatially grounded reasoning and advance VLMs in visual problem-solving.

