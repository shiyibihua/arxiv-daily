---
layout: default
title: Leader360V: The Large-scale, Real-world 360 Video Dataset for Multi-task Learning in Diverse Environment
---

# Leader360V: The Large-scale, Real-world 360 Video Dataset for Multi-task Learning in Diverse Environment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.14271" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.14271v1</a>
  <a href="https://arxiv.org/pdf/2506.14271.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.14271v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.14271v1', 'Leader360V: The Large-scale, Real-world 360 Video Dataset for Multi-task Learning in Diverse Environment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Weiming Zhang, Dingwen Xiao, Aobotao Dai, Yexin Liu, Tianbo Pan, Shiqi Wen, Lei Chen, Lin Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-17

**å¤‡æ³¨**: 23 pages, 16 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLeader360Vä»¥è§£å†³360è§†é¢‘æ•°æ®é›†ç¼ºä¹çš„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `360è§†é¢‘ç†è§£` `å®ä¾‹åˆ†å‰²` `è‡ªåŠ¨æ ‡æ³¨` `å¤šä»»åŠ¡å­¦ä¹ ` `çœŸå®ä¸–ç•Œæ•°æ®é›†` `æœºå™¨äººè§†è§‰` `è¯­ä¹‰åˆ†å‰²`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é¢ä¸´ç¼ºä¹å¤§è§„æ¨¡ã€æ ‡æ³¨çœŸå®ä¸–ç•Œ360è§†é¢‘æ•°æ®é›†çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´360åœºæ™¯ç†è§£ä»»åŠ¡å—é™ã€‚
2. æœ¬æ–‡æå‡ºLeader360Væ•°æ®é›†ï¼Œå¹¶è®¾è®¡äº†è‡ªåŠ¨æ ‡æ³¨ç®¡é“ï¼Œç»“åˆ2Dåˆ†å‰²å™¨å’Œå¤§å‹è¯­è¨€æ¨¡å‹ä»¥æé«˜æ ‡æ³¨æ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLeader360Væ˜¾è‘—æå‡äº†360è§†é¢‘åˆ†å‰²å’Œè·Ÿè¸ªæ¨¡å‹çš„æ€§èƒ½ï¼Œæ¨åŠ¨äº†360åœºæ™¯ç†è§£çš„å‘å±•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

360è§†é¢‘æ•æ‰äº†å®Œæ•´çš„å‘¨å›´åœºæ™¯ï¼Œå…·æœ‰360X180çš„è¶…å¤§è§†é‡ã€‚è¿™ä½¿å¾—360åœºæ™¯ç†è§£ä»»åŠ¡ï¼ˆå¦‚åˆ†å‰²å’Œè·Ÿè¸ªï¼‰åœ¨è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººç­‰åº”ç”¨ä¸­è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºç¡€æ¨¡å‹é¢ä¸´ç¼ºä¹å¤§è§„æ¨¡æ ‡æ³¨çœŸå®ä¸–ç•Œæ•°æ®é›†çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡ä»‹ç»äº†Leader360Vï¼Œè¿™æ˜¯é¦–ä¸ªå¤§è§„æ¨¡æ ‡æ³¨çš„çœŸå®ä¸–ç•Œ360è§†é¢‘æ•°æ®é›†ï¼Œä¸“æ³¨äºå®ä¾‹åˆ†å‰²å’Œè·Ÿè¸ªã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§è‡ªåŠ¨æ ‡æ³¨ç®¡é“ï¼Œç»“åˆé¢„è®­ç»ƒçš„2Dåˆ†å‰²å™¨å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ˜¾è‘—æé«˜äº†æ ‡æ³¨æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒLeader360Væ˜¾è‘—æå‡äº†360è§†é¢‘åˆ†å‰²å’Œè·Ÿè¸ªæ¨¡å‹çš„æ€§èƒ½ï¼Œä¸ºæ›´å¯æ‰©å±•çš„360åœºæ™¯ç†è§£å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³360è§†é¢‘æ•°æ®é›†ç¼ºä¹çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æ ‡æ³¨çœŸå®ä¸–ç•Œæ•°æ®é›†æ—¶é¢ä¸´é«˜æˆæœ¬å’Œå¤æ‚æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æåœ°åŒºåŸŸçš„ä¸¥é‡å¤±çœŸå’Œå†…å®¹ä¸è¿ç»­æ€§æ–¹é¢ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§è‡ªåŠ¨æ ‡æ³¨ç®¡é“ï¼Œé€šè¿‡åè°ƒé¢„è®­ç»ƒçš„2Dåˆ†å‰²å™¨å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ¥æé«˜æ ‡æ³¨çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚è¯¥ç®¡é“åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼Œæ—¨åœ¨å‡å°‘äººå·¥å¹²é¢„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬åˆå§‹æ ‡æ³¨é˜¶æ®µã€è‡ªåŠ¨ä¿®æ­£æ ‡æ³¨é˜¶æ®µå’Œäººå·¥ä¿®è®¢é˜¶æ®µã€‚åˆå§‹æ ‡æ³¨é˜¶æ®µå¼•å…¥äº†è¯­ä¹‰å’Œå¤±çœŸæ„ŸçŸ¥çš„ç»†åŒ–æ¨¡å—ï¼Œåç»­é˜¶æ®µåˆ™é€šè¿‡å†æ¬¡åº”ç”¨SDRæˆ–å¤„ç†æ°´å¹³è¾¹ç•Œé™„è¿‘çš„ä¸è¿ç»­æ€§æ¥ä¿®æ­£ç¼ºå¤±åŒºåŸŸã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºç»“åˆäº†å¤šç§2Dåˆ†å‰²å™¨çš„ç‰©ä½“æ©ç ææ¡ˆä¸å¤§å‹è¯­è¨€æ¨¡å‹éªŒè¯çš„è¯­ä¹‰æ ‡ç­¾ï¼Œä»è€Œç”Ÿæˆå¤±çœŸæ„ŸçŸ¥çš„æ©ç ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å•ä¸€æ ‡æ³¨æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åˆå§‹æ ‡æ³¨é˜¶æ®µï¼Œä½¿ç”¨äº†SAM2ç”Ÿæˆå¤±çœŸæ„ŸçŸ¥æ©ç çš„æ©ç æç¤ºï¼›åœ¨è‡ªåŠ¨ä¿®æ­£é˜¶æ®µï¼Œé‡‡ç”¨äº†SDRæŠ€æœ¯æ¥å¤„ç†ç¼ºå¤±åŒºåŸŸï¼Œç¡®ä¿æ ‡æ³¨çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLeader360Våœ¨360è§†é¢‘åˆ†å‰²å’Œè·Ÿè¸ªä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•è¡¨ç°å‡ºæ›´å¥½çš„æ•ˆæœï¼ŒéªŒè¯äº†è‡ªåŠ¨æ ‡æ³¨ç®¡é“çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Leader360Væ•°æ®é›†çš„æå‡ºä¸ºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººç­‰é¢†åŸŸçš„360åœºæ™¯ç†è§£æä¾›äº†é‡è¦çš„æ•°æ®æ”¯æŒã€‚é€šè¿‡é«˜æ•ˆçš„æ ‡æ³¨ç®¡é“ï¼Œç ”ç©¶è€…å¯ä»¥æ›´å¿«é€Ÿåœ°è·å–é«˜è´¨é‡çš„æ ‡æ³¨æ•°æ®ï¼Œä»è€Œæ¨åŠ¨ç›¸å…³ç®—æ³•çš„å‘å±•å’Œåº”ç”¨ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> 360 video captures the complete surrounding scenes with the ultra-large field of view of 360X180. This makes 360 scene understanding tasks, eg, segmentation and tracking, crucial for appications, such as autonomous driving, robotics. With the recent emergence of foundation models, the community is, however, impeded by the lack of large-scale, labelled real-world datasets. This is caused by the inherent spherical properties, eg, severe distortion in polar regions, and content discontinuities, rendering the annotation costly yet complex. This paper introduces Leader360V, the first large-scale, labeled real-world 360 video datasets for instance segmentation and tracking. Our datasets enjoy high scene diversity, ranging from indoor and urban settings to natural and dynamic outdoor scenes. To automate annotation, we design an automatic labeling pipeline, which subtly coordinates pre-trained 2D segmentors and large language models to facilitate the labeling. The pipeline operates in three novel stages. Specifically, in the Initial Annotation Phase, we introduce a Semantic- and Distortion-aware Refinement module, which combines object mask proposals from multiple 2D segmentors with LLM-verified semantic labels. These are then converted into mask prompts to guide SAM2 in generating distortion-aware masks for subsequent frames. In the Auto-Refine Annotation Phase, missing or incomplete regions are corrected either by applying the SDR again or resolving the discontinuities near the horizontal borders. The Manual Revision Phase finally incorporates LLMs and human annotators to further refine and validate the annotations. Extensive user studies and evaluations demonstrate the effectiveness of our labeling pipeline. Meanwhile, experiments confirm that Leader360V significantly enhances model performance for 360 video segmentation and tracking, paving the way for more scalable 360 scene understanding.

