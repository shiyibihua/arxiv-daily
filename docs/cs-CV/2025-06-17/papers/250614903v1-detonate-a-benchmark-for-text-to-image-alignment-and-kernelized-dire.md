---
layout: default
title: DETONATE: A Benchmark for Text-to-Image Alignment and Kernelized Direct Preference Optimization
---

# DETONATE: A Benchmark for Text-to-Image Alignment and Kernelized Direct Preference Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.14903" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.14903v1</a>
  <a href="https://arxiv.org/pdf/2506.14903.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.14903v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.14903v1', 'DETONATE: A Benchmark for Text-to-Image Alignment and Kernelized Direct Preference Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Renjith Prasad, Abhilekh Borah, Hasnat Md Abdullah, Chathurangi Shyalika, Gurpreet Singh, Ritvik Garimella, Rajarshi Roy, Harshul Surana, Nasrin Imanpour, Suranjana Trivedy, Amit Sheth, Amitava Das

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-17

**å¤‡æ³¨**: 59 pages, 10 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDETONATEåŸºå‡†ä»¥ä¼˜åŒ–æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒ` `å¯¹é½ä¼˜åŒ–` `ç¤¾ä¼šåè§` `æ·±åº¦å­¦ä¹ ` `ç”Ÿæˆæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹åœ¨å¯¹é½ç”¨æˆ·æ„å›¾ä¸ç”Ÿæˆå›¾åƒä¹‹é—´å­˜åœ¨æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å®‰å…¨æ€§å’Œå…¬å¹³æ€§æ–¹é¢ã€‚
2. è®ºæ–‡æå‡ºDPO-Kernelsï¼Œé€šè¿‡æ··åˆæŸå¤±ã€æ ¸åŒ–è¡¨ç¤ºå’Œå‘æ•£é€‰æ‹©ä¸‰æ–¹é¢å¢å¼ºT2Iæ¨¡å‹çš„å¯¹é½èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDPO-Kernelsåœ¨æ³›åŒ–èƒ½åŠ›ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¸”é€šè¿‡AQIæ­ç¤ºäº†æ½œåœ¨çš„å®‰å…¨éšæ‚£ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯¹é½æ˜¯æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ¨¡å‹çš„å…³é”®ï¼Œç¡®ä¿ç”Ÿæˆçš„å›¾åƒå¿ å®æ•æ‰ç”¨æˆ·æ„å›¾ï¼ŒåŒæ—¶ç»´æŠ¤å®‰å…¨æ€§å’Œå…¬å¹³æ€§ã€‚æœ¬æ–‡å¼•å…¥äº†DPO-Kernelsï¼Œå¢å¼ºäº†T2Iæ¨¡å‹çš„å¯¹é½èƒ½åŠ›ï¼Œä¸»è¦é€šè¿‡ä¸‰æ–¹é¢çš„åˆ›æ–°ï¼šæ··åˆæŸå¤±ã€æ ¸åŒ–è¡¨ç¤ºå’Œå‘æ•£é€‰æ‹©ã€‚DETONATEæ˜¯é¦–ä¸ªå¤§è§„æ¨¡åŸºå‡†ï¼ŒåŒ…å«çº¦10ä¸‡å¯¹ç»è¿‡ç­–åˆ’çš„å›¾åƒå¯¹ï¼Œæ¶µç›–ç§æ—ã€æ€§åˆ«å’Œæ®‹ç–¾ç­‰ç¤¾ä¼šåè§ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†å¯¹é½è´¨é‡æŒ‡æ•°ï¼ˆAQIï¼‰ï¼Œé‡åŒ–å®‰å…¨/ä¸å®‰å…¨å›¾åƒæ¿€æ´»çš„æ½œåœ¨ç©ºé—´å¯åˆ†ç¦»æ€§ã€‚å®éªŒè¯æ˜ï¼ŒDPO-Kernelsé€šè¿‡é‡å°¾è‡ªæˆ‘æ­£åˆ™åŒ–ï¼ˆHT-SRï¼‰ä¿æŒå¼ºå¤§çš„æ³›åŒ–ç•Œé™ã€‚DETONATEåŠå®Œæ•´ä»£ç å·²å…¬å¼€å‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ—¶å¯¹ç”¨æˆ·æ„å›¾çš„å¯¹é½é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å®‰å…¨æ€§å’Œå…¬å¹³æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºDPO-Kernelsï¼Œé€šè¿‡å¼•å…¥æ··åˆæŸå¤±ã€æ ¸åŒ–è¡¨ç¤ºå’Œå¤šç§å‘æ•£é€‰æ‹©ï¼Œæå‡æ¨¡å‹çš„å¯¹é½èƒ½åŠ›å’Œç¨³å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ··åˆæŸå¤±æ¨¡å—ã€æ ¸åŒ–è¡¨ç¤ºæ¨¡å—å’Œå‘æ•£é€‰æ‹©æ¨¡å—ï¼Œåˆ†åˆ«è´Ÿè´£ä¼˜åŒ–ç›®æ ‡ã€ç‰¹å¾è½¬æ¢å’Œæ­£åˆ™åŒ–é€‰æ‹©ã€‚

**å…³é”®åˆ›æ–°**ï¼šDPO-Kernelsæ˜¯å¯¹DPOçš„æ‰©å±•ï¼Œç»“åˆäº†å¤šç§æŸå¤±å‡½æ•°å’Œæ ¸å‡½æ•°ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¯¹é½ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šé‡‡ç”¨äº†æ··åˆæŸå¤±å‡½æ•°ï¼Œç»“åˆäº†åŸºäºåµŒå…¥çš„ç›®æ ‡ä¸ä¼ ç»Ÿæ¦‚ç‡æŸå¤±ï¼›ä½¿ç”¨RBFã€Polynomialå’ŒWaveletæ ¸è¿›è¡Œç‰¹å¾è½¬æ¢ï¼›å¼•å…¥Wassersteinå’ŒR'enyiå‘æ•£ä»¥å¢å¼ºç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDPO-Kernelsåœ¨å¯¹é½ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæ³›åŒ–èƒ½åŠ›å¼ºï¼Œä¸”AQIæŒ‡æ ‡æ­ç¤ºäº†æ½œåœ¨çš„å®‰å…¨éšæ‚£ï¼Œæä¾›äº†æ–°çš„è¯„ä¼°è§†è§’ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªè¯¦ç»†æŠ«éœ²ï¼Œå¾…è¿›ä¸€æ­¥ç ”ç©¶éªŒè¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”Ÿæˆè‰ºæœ¯ã€å¹¿å‘Šè®¾è®¡å’Œç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆç­‰ã€‚é€šè¿‡ä¼˜åŒ–æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„å¯¹é½èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°æ»¡è¶³ç”¨æˆ·éœ€æ±‚ï¼Œå‡å°‘ç”Ÿæˆå†…å®¹ä¸­çš„åè§å’Œä¸å®‰å…¨å› ç´ ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œç¤¾ä¼šè´£ä»»æ„Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Alignment is crucial for text-to-image (T2I) models to ensure that generated images faithfully capture user intent while maintaining safety and fairness. Direct Preference Optimization (DPO), prominent in large language models (LLMs), is extending its influence to T2I systems. This paper introduces DPO-Kernels for T2I models, a novel extension enhancing alignment across three dimensions: (i) Hybrid Loss, integrating embedding-based objectives with traditional probability-based loss for improved optimization; (ii) Kernelized Representations, employing Radial Basis Function (RBF), Polynomial, and Wavelet kernels for richer feature transformations and better separation between safe and unsafe inputs; and (iii) Divergence Selection, expanding beyond DPO's default Kullback-Leibler (KL) regularizer by incorporating Wasserstein and R'enyi divergences for enhanced stability and robustness. We introduce DETONATE, the first large-scale benchmark of its kind, comprising approximately 100K curated image pairs categorized as chosen and rejected. DETONATE encapsulates three axes of social bias and discrimination: Race, Gender, and Disability. Prompts are sourced from hate speech datasets, with images generated by leading T2I models including Stable Diffusion 3.5 Large, Stable Diffusion XL, and Midjourney. Additionally, we propose the Alignment Quality Index (AQI), a novel geometric measure quantifying latent-space separability of safe/unsafe image activations, revealing hidden vulnerabilities. Empirically, we demonstrate that DPO-Kernels maintain strong generalization bounds via Heavy-Tailed Self-Regularization (HT-SR). DETONATE and complete code are publicly released.

