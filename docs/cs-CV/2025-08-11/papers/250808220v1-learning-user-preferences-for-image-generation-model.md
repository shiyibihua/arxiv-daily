---
layout: default
title: Learning User Preferences for Image Generation Model
---

# Learning User Preferences for Image Generation Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08220" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08220v1</a>
  <a href="https://arxiv.org/pdf/2508.08220.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08220v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08220v1', 'Learning User Preferences for Image Generation Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenyi Mo, Ying Ba, Tianyu Zhang, Yalong Bai, Biye Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„ç”¨æˆ·åå¥½å­¦ä¹ æ–¹æ³•ä»¥æå‡å›¾åƒç”Ÿæˆè´¨é‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç”¨æˆ·åå¥½å­¦ä¹ ` `å›¾åƒç”Ÿæˆ` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å¯¹æ¯”æŸå¤±` `ä¸ªæ€§åŒ–æ¨è`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºä¸€èˆ¬äººç±»åå¥½æˆ–å‡è®¾é™æ€ç”¨æˆ·æ¡£æ¡ˆï¼Œå¿½è§†äº†ä¸ªä½“å·®å¼‚å’ŒåŠ¨æ€æ€§ã€‚
2. æœ¬æ–‡æå‡ºåŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ–¹æ³•ï¼Œé€šè¿‡å¯¹æ¯”åå¥½æŸå¤±å’Œå¯å­¦ä¹ åå¥½æ ‡è®°æ¥å­¦ä¹ ä¸ªæ€§åŒ–ç”¨æˆ·åå¥½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨åå¥½é¢„æµ‹å‡†ç¡®æ€§ä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œæœ‰æ•ˆè¯†åˆ«ç›¸ä¼¼ç”¨æˆ·å¹¶æä¾›ç²¾å‡†çš„å›¾åƒç”ŸæˆæŒ‡å¯¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”¨æˆ·åå¥½é¢„æµ‹éœ€è¦å…¨é¢å‡†ç¡®åœ°ç†è§£ä¸ªä½“çš„å“å‘³ï¼ŒåŒ…æ‹¬è¡¨é¢å±æ€§ï¼ˆå¦‚é¢œè‰²å’Œé£æ ¼ï¼‰å’Œæ›´æ·±å±‚æ¬¡çš„å†…å®¹ç›¸å…³æ–¹é¢ï¼ˆå¦‚ä¸»é¢˜å’Œæ„å›¾ï¼‰ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºä¸€èˆ¬äººç±»åå¥½æˆ–å‡è®¾é™æ€ç”¨æˆ·æ¡£æ¡ˆï¼Œå¿½è§†äº†ä¸ªä½“å·®å¼‚å’Œä¸ªäººå“å‘³çš„åŠ¨æ€å¤šé¢æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ–¹æ³•ï¼Œå¼•å…¥å¯¹æ¯”åå¥½æŸå¤±å’Œå¯å­¦ä¹ çš„åå¥½æ ‡è®°ï¼Œä»å†å²äº¤äº’ä¸­å­¦ä¹ ä¸ªæ€§åŒ–ç”¨æˆ·åå¥½ã€‚å¯¹æ¯”åå¥½æŸå¤±æ—¨åœ¨æœ‰æ•ˆåŒºåˆ†ç”¨æˆ·çš„â€œå–œæ¬¢â€å’Œâ€œä¸å–œæ¬¢â€ï¼Œè€Œå¯å­¦ä¹ çš„åå¥½æ ‡è®°åˆ™æ•æ‰ç°æœ‰ç”¨æˆ·ä¹‹é—´çš„å…±åŒå…´è¶£è¡¨ç¤ºï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ¿€æ´»ç‰¹å®šç¾¤ä½“çš„åå¥½ï¼Œå¹¶å¢å¼ºç›¸ä¼¼ç”¨æˆ·ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨åå¥½é¢„æµ‹å‡†ç¡®æ€§ä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œæœ‰æ•ˆè¯†åˆ«å…·æœ‰ç›¸ä¼¼ç¾å­¦å€¾å‘çš„ç”¨æˆ·ï¼Œå¹¶ä¸ºç”Ÿæˆç¬¦åˆä¸ªä½“å“å‘³çš„å›¾åƒæä¾›æ›´ç²¾ç¡®çš„æŒ‡å¯¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”¨æˆ·åå¥½é¢„æµ‹ä¸­çš„ä¸ªä½“å·®å¼‚å’ŒåŠ¨æ€æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†äº†ç”¨æˆ·çš„å¤šæ ·åŒ–éœ€æ±‚ï¼Œå¯¼è‡´ç”Ÿæˆç»“æœä¸å¤Ÿä¸ªæ€§åŒ–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥å¯¹æ¯”åå¥½æŸå¤±å’Œå¯å­¦ä¹ çš„åå¥½æ ‡è®°ï¼Œæœ¬æ–‡çš„æ–¹æ³•èƒ½å¤Ÿä»ç”¨æˆ·çš„å†å²äº¤äº’ä¸­æå–ä¸ªæ€§åŒ–çš„åå¥½ä¿¡æ¯ï¼Œä»è€Œæ›´å¥½åœ°é€‚åº”ç”¨æˆ·çš„å˜åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€ç”¨æˆ·åå¥½å»ºæ¨¡å’Œå›¾åƒç”Ÿæˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡å†å²äº¤äº’æ•°æ®æ”¶é›†ç”¨æˆ·åå¥½ï¼Œç„¶ååˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œåå¥½å»ºæ¨¡ï¼Œæœ€åç”Ÿæˆç¬¦åˆç”¨æˆ·åå¥½çš„å›¾åƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥å¯¹æ¯”åå¥½æŸå¤±å’Œå¯å­¦ä¹ çš„åå¥½æ ‡è®°ï¼Œè¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†ç”¨æˆ·çš„â€œå–œæ¬¢â€å’Œâ€œä¸å–œæ¬¢â€ï¼Œå¹¶æ•æ‰ç”¨æˆ·ä¹‹é—´çš„å…±åŒå…´è¶£ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¿™ç§è®¾è®¡èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ç”¨æˆ·çš„ä¸ªæ€§åŒ–éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°ä¸­ï¼Œé‡‡ç”¨å¯¹æ¯”æŸå¤±æ¥ä¼˜åŒ–ç”¨æˆ·åå¥½çš„åŒºåˆ†èƒ½åŠ›ï¼›å¯å­¦ä¹ çš„åå¥½æ ‡è®°åˆ™é€šè¿‡è®­ç»ƒå¾—åˆ°ï¼Œèƒ½å¤ŸåŠ¨æ€è°ƒæ•´ä»¥é€‚åº”ä¸åŒç”¨æˆ·çš„éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æ¨¡å‹åœ¨åå¥½é¢„æµ‹å‡†ç¡®æ€§ä¸Šè¶…è¶Šäº†å¤šç§åŸºçº¿æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°15%ä»¥ä¸Šï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å‡ºå…·æœ‰ç›¸ä¼¼ç¾å­¦å€¾å‘çš„ç”¨æˆ·ï¼Œä¸ºä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆæä¾›äº†æ›´ä¸ºç²¾å‡†çš„æŒ‡å¯¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆã€ç¤¾äº¤åª’ä½“å†…å®¹æ¨èä»¥åŠåœ¨çº¿è‰ºæœ¯åˆ›ä½œå¹³å°ç­‰ã€‚é€šè¿‡æ›´å‡†ç¡®åœ°ç†è§£ç”¨æˆ·åå¥½ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæå‡ç”¨æˆ·ä½“éªŒï¼Œå¢åŠ ç”¨æˆ·ç²˜æ€§ï¼Œå¹¶ä¸ºåˆ›ä½œè€…æä¾›æ›´å…·é’ˆå¯¹æ€§çš„åˆ›ä½œæŒ‡å¯¼ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> User preference prediction requires a comprehensive and accurate understanding of individual tastes. This includes both surface-level attributes, such as color and style, and deeper content-related aspects, such as themes and composition. However, existing methods typically rely on general human preferences or assume static user profiles, often neglecting individual variability and the dynamic, multifaceted nature of personal taste. To address these limitations, we propose an approach built upon Multimodal Large Language Models, introducing contrastive preference loss and preference tokens to learn personalized user preferences from historical interactions. The contrastive preference loss is designed to effectively distinguish between user ''likes'' and ''dislikes'', while the learnable preference tokens capture shared interest representations among existing users, enabling the model to activate group-specific preferences and enhance consistency across similar users. Extensive experiments demonstrate our model outperforms other methods in preference prediction accuracy, effectively identifying users with similar aesthetic inclinations and providing more precise guidance for generating images that align with individual tastes. The project page is \texttt{https://learn-user-pref.github.io/}.

