---
layout: default
title: VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models
---

# VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08521" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.08521v1</a>
  <a href="https://arxiv.org/pdf/2508.08521.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08521v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08521v1', 'VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Mansi Phute, Ravikumar Balakrishnan

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-11

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫VISOR‰ª•Ëß£ÂÜ≥ËßÜËßâËæìÂÖ•ÂºïÂØºËæìÂá∫ÈáçÂÆöÂêëÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `Ë°å‰∏∫ÊéßÂà∂` `ËæìÂá∫ÈáçÂÆöÂêë` `Â§öÊ®°ÊÄÅÊ®°Âûã` `ÂÆâÂÖ®ÊÄß` `ÂºïÂØºÂõæÂÉè` `ÊøÄÊ¥ªÊ®°Âºè`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑË°å‰∏∫ÊéßÂà∂ÊñπÊ≥ïÂ¶ÇÁ≥ªÁªüÊèêÁ§∫ÊòìË¢´Ê£ÄÊµã‰∏îÊïàÊûú‰∏ç‰Ω≥Ôºå‰∏îÂü∫‰∫éÊøÄÊ¥ªÁöÑÂºïÂØºÂêëÈáèÈúÄË¶ÅÂØπÊ®°ÂûãÂÜÖÈÉ®ËøõË°å‰æµÂÖ•ÂºèËÆøÈóÆÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®„ÄÇ
2. Êú¨ÊñáÊèêÂá∫VISORÔºåÈÄöËøá‰ºòÂåñËßÜËßâËæìÂÖ•ÂÆûÁé∞Â§çÊùÇÁöÑË°å‰∏∫ÊéßÂà∂ÔºåËÉΩÂ§üÂú®‰∏çÊé•Ëß¶Ê®°ÂûãÂÜÖÈÉ®ÁöÑÊÉÖÂÜµ‰∏ãËøõË°åÊúâÊïàÁöÑËæìÂá∫ÈáçÂÆöÂêë„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVISORÂú®Â§ö‰∏™‰ªªÂä°‰∏äË°®Áé∞‰ºòÂºÇÔºåÂ∞§ÂÖ∂Âú®Ë¥üÂêëÂºïÂØº‰∏äÊïàÊûúÊòæËëóÔºåÊèê‰æõ‰∫ÜÊØî‰º†ÁªüÊñπÊ≥ïÊõ¥Âº∫ÁöÑÊéßÂà∂ËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàVLMsÔºâÂú®Â§öÁßçÂ∫îÁî®‰∏≠Êó•ÁõäÊôÆÂèäÔºåÂÆâÂÖ®ÊÄßÂíåË°å‰∏∫ÊéßÂà∂ÈóÆÈ¢òÂèòÂæóÂ∞§‰∏∫ÈáçË¶Å„ÄÇÁé∞ÊúâÁöÑË°å‰∏∫ÊéßÂà∂ÊñπÊ≥ïÔºåÂ¶ÇÁ≥ªÁªüÊèêÁ§∫ÔºåÂÆπÊòìË¢´Ê£ÄÊµã‰∏îÊïàÊûúÊúâÈôêÔºåËÄåÂü∫‰∫éÊøÄÊ¥ªÁöÑÂºïÂØºÂêëÈáèÈúÄË¶ÅÂØπÊ®°ÂûãÂÜÖÈÉ®ËøõË°å‰æµÂÖ•ÂºèËÆøÈóÆÔºå‰∏çÈÄÇÂêàAPIÊúçÂä°ÂíåÈó≠Ê∫êÈÉ®ÁΩ≤„ÄÇÊú¨ÊñáÊèêÂá∫VISORÔºàÂü∫‰∫éËßÜËßâËæìÂÖ•ÁöÑËæìÂá∫ÈáçÂÆöÂêëÂºïÂØºÔºâÔºåÈÄöËøá‰ºòÂåñËßÜËßâËæìÂÖ•ÂÆûÁé∞Â§çÊùÇÁöÑË°å‰∏∫ÊéßÂà∂„ÄÇVISORÈÄöËøáÂà∂‰ΩúÈÄöÁî®ÂºïÂØºÂõæÂÉèËØ±ÂØºÁõÆÊ†áÊøÄÊ¥ªÊ®°ÂºèÔºåËÉΩÂ§üÂú®ÊâÄÊúâVLMÊúçÂä°Ê®°Âºè‰∏≠ËøõË°åÂÆûÁî®ÈÉ®ÁΩ≤ÔºåÂπ∂‰∏îÁõ∏ËæÉ‰∫éÊòæÂºèÊñáÊú¨Êåá‰ª§Êõ¥‰∏∫ÈöêËîΩ„ÄÇÊàë‰ª¨Âú®LLaVA-1.5-7B‰∏äÈ™åËØÅ‰∫ÜVISORÂú®ÊãíÁªù„ÄÅË∞ÑÂ™öÂíåÁîüÂ≠òÊú¨ËÉΩ‰∏â‰∏™ÂÖ≥ÈîÆÂØπÈΩê‰ªªÂä°‰∏äÁöÑË°®Áé∞„ÄÇÂçï‰∏™150KBÁöÑÂºïÂØºÂõæÂÉèÂú®Ê≠£ÂêëË°å‰∏∫ËΩ¨Âèò‰∏ä‰∏éÂºïÂØºÂêëÈáèÁöÑË°®Áé∞Áõ∏Â∑Æ‰ªÖ1-2%ÔºåËÄåÂú®Ë¥üÂêëÂºïÂØº‰∏äÂàôÊòæËëóË∂ÖËøáÔºåÂºïÂØºÊïàÊûúËææÂà∞Âü∫Á∫øÁöÑ25%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®Ë°å‰∏∫ÊéßÂà∂ÂíåËæìÂá∫ÈáçÂÆöÂêëÊñπÈù¢ÁöÑ‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÁé∞ÊúâÊñπÊ≥ïÁöÑÂèØÊ£ÄÊµãÊÄßÂíåÂØπÊ®°ÂûãÂÜÖÈÉ®ÁöÑ‰æµÂÖ•ÂºèË¶ÅÊ±Ç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVISORÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøá‰ºòÂåñËßÜËßâËæìÂÖ•ÔºåÂà∂‰ΩúÈÄöÁî®ÂºïÂØºÂõæÂÉèÊù•ËØ±ÂØºÁõÆÊ†áÊøÄÊ¥ªÊ®°ÂºèÔºå‰ªéËÄåÂÆûÁé∞Â§çÊùÇÁöÑË°å‰∏∫ÊéßÂà∂ÔºåËÄåÊó†ÈúÄÁõ¥Êé•ËÆøÈóÆÊ®°ÂûãÂÜÖÈÉ®„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVISORÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöËßÜËßâËæìÂÖ•ÁîüÊàêÊ®°Âùó„ÄÅÊøÄÊ¥ªÊ®°ÂºèËØ±ÂØºÊ®°ÂùóÂíåË°å‰∏∫ÊéßÂà∂Ê®°Âùó„ÄÇËßÜËßâËæìÂÖ•ÁîüÊàêÊ®°ÂùóË¥üË¥£ÂàõÂª∫ÂºïÂØºÂõæÂÉèÔºåÊøÄÊ¥ªÊ®°ÂºèËØ±ÂØºÊ®°ÂùóÁî®‰∫éÂàÜÊûêÂíå‰ºòÂåñÊøÄÊ¥ªÊ®°ÂºèÔºåË°å‰∏∫ÊéßÂà∂Ê®°ÂùóÂàôÂÆûÁé∞ËæìÂá∫ÈáçÂÆöÂêë„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVISORÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÈÄöËøáËßÜËßâËæìÂÖ•ÂÆûÁé∞Ë°å‰∏∫ÊéßÂà∂ÁöÑËÉΩÂäõÔºåÈÅøÂÖç‰∫Ü‰º†ÁªüÊñπÊ≥ïÁöÑ‰æµÂÖ•ÂºèËÆøÈóÆÈúÄÊ±ÇÔºåÂπ∂‰∏îÂú®ÈöêËîΩÊÄß‰∏ä‰ºò‰∫éÊñáÊú¨Êåá‰ª§„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåVISOR‰ΩøÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞Êù•‰ºòÂåñÂºïÂØºÂõæÂÉèÁöÑÁîüÊàêÔºåÂêåÊó∂Á°Æ‰øùÂÖ∂Âú®‰∏çÂêå‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÂºïÂØºÂõæÂÉèÁöÑÂ§ßÂ∞èÂíåÂ§çÊùÇÂ∫¶ÁªèËøáÁ≤æÂøÉË∞ÉÊï¥Ôºå‰ª•Á°Æ‰øùÂú®‰øùÊåÅÈ´òÊïàÊÄßÁöÑÂêåÊó∂‰∏çÂΩ±ÂìçÊ®°ÂûãÁöÑÊï¥‰ΩìÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåVISORÂú®Ê≠£ÂêëË°å‰∏∫ËΩ¨Âèò‰∏ä‰∏éÂºïÂØºÂêëÈáèÁöÑË°®Áé∞Áõ∏Â∑Æ‰ªÖ1-2%ÔºåËÄåÂú®Ë¥üÂêëÂºïÂØº‰∏äÂàôÊòæËëóË∂ÖËøáÔºåÂºïÂØºÊïàÊûúËææÂà∞Âü∫Á∫øÁöÑ25%„ÄÇ‰∏é‰º†ÁªüÁöÑÁ≥ªÁªüÊèêÁ§∫ÊñπÊ≥ïÁõ∏ÊØîÔºåVISORÊèê‰æõ‰∫ÜÊõ¥Âº∫ÁöÑÂèåÂêëÊéßÂà∂ËÉΩÂäõÔºåÂêåÊó∂Âú®14,000‰∏™Êó†ÂÖ≥MMLU‰ªªÂä°‰∏ä‰øùÊåÅ‰∫Ü99.9%ÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

VISORÁöÑÁ†îÁ©∂ÊàêÊûúÂú®Â§ö‰∏™È¢ÜÂüüÂÖ∑ÊúâÊΩúÂú®Â∫îÁî®‰ª∑ÂÄºÔºåÂåÖÊã¨ÂÆâÂÖ®ÊÄßÂ¢ûÂº∫„ÄÅÁî®Êà∑Ë°å‰∏∫ÂºïÂØºÂíå‰∫∫Êú∫‰∫§‰∫íÁ≠â„ÄÇÈÄöËøá‰ºòÂåñËßÜËßâËæìÂÖ•ÔºåVISORËÉΩÂ§üÂú®‰∏çÂπ≤Êâ∞Ê®°ÂûãÂÜÖÈÉ®ÁöÑÊÉÖÂÜµ‰∏ãÂÆûÁé∞ÊúâÊïàÁöÑË°å‰∏∫ÊéßÂà∂ÔºåÈÄÇÁî®‰∫éAPIÊúçÂä°ÂíåÈó≠Ê∫êÈÉ®ÁΩ≤ÁöÑÂú∫ÊôØ„ÄÇÊú™Êù•ÔºåVISORÂèØËÉΩ‰ºöÊé®Âä®Â§öÊ®°ÊÄÅÊ®°ÂûãÊéßÂà∂ÁöÑÁ†îÁ©∂ËøõÂ±ïÔºåÂπ∂‰øÉ‰ΩøÁõ∏ÂÖ≥Èò≤Âæ°Êú∫Âà∂ÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision Language Models (VLMs) are increasingly being used in a broad range of applications, bringing their security and behavioral control to the forefront. While existing approaches for behavioral control or output redirection, like system prompting in VLMs, are easily detectable and often ineffective, activation-based steering vectors require invasive runtime access to model internals--incompatible with API-based services and closed-source deployments. We introduce VISOR (Visual Input-based Steering for Output Redirection), a novel method that achieves sophisticated behavioral control through optimized visual inputs alone. By crafting universal steering images that induce target activation patterns, VISOR enables practical deployment across all VLM serving modalities while remaining imperceptible compared to explicit textual instructions. We validate VISOR on LLaVA-1.5-7B across three critical alignment tasks: refusal, sycophancy and survival instinct. A single 150KB steering image matches steering vector performance within 1-2% for positive behavioral shifts while dramatically exceeding it for negative steering--achieving up to 25% shifts from baseline compared to steering vectors' modest changes. Unlike system prompting (3-4% shifts), VISOR provides robust bidirectional control while maintaining 99.9% performance on 14,000 unrelated MMLU tasks. Beyond eliminating runtime overhead and model access requirements, VISOR exposes a critical security vulnerability: adversaries can achieve sophisticated behavioral manipulation through visual channels alone, bypassing text-based defenses. Our work fundamentally re-imagines multimodal model control and highlights the urgent need for defenses against visual steering attacks.

