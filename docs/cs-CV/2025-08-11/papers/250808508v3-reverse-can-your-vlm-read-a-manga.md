---
layout: default
title: Re:Verse -- Can Your VLM Read a Manga?
---

# Re:Verse -- Can Your VLM Read a Manga?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08508" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08508v3</a>
  <a href="https://arxiv.org/pdf/2508.08508.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08508v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08508v3', 'Re:Verse -- Can Your VLM Read a Manga?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aaditya Baranwal, Madhav Kataria, Naitik Agrawal, Yogesh S Rawat, Shruti Vyas

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11 (æ›´æ–°: 2025-08-18)

**å¤‡æ³¨**: Accepted (oral) at ICCV (AISTORY Workshop) 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–°è¯„ä¼°æ¡†æ¶ä»¥è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æ¼«ç”»å™äº‹ç†è§£ä¸­çš„ä¸è¶³**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `æ¼«ç”»å™äº‹ç†è§£` `å¤šæ¨¡æ€è¯„ä¼°` `å› æœæ¨ç†` `è·¨é¢æ¿è¿è´¯æ€§` `æ·±åº¦å­¦ä¹ ` `å™äº‹æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ç†è§£æ¼«ç”»å™äº‹æ—¶ï¼Œç¼ºä¹å¯¹æ—¶é—´å› æœå…³ç³»å’Œè·¨é¢æ¿è¿è´¯æ€§çš„å¤„ç†èƒ½åŠ›ï¼Œå¯¼è‡´å™äº‹ç†è§£ä¸å®Œæ•´ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œç»“åˆå¤šæ¨¡æ€æ³¨é‡Šå’Œæ£€ç´¢å¢å¼ºè¯„ä¼°ï¼Œç³»ç»Ÿæ€§åœ°åˆ†æVLMsåœ¨å™äº‹ç†è§£ä¸­çš„ä¸è¶³ã€‚
3. é€šè¿‡å¯¹ã€ŠRe:Zeroã€‹æ¼«ç”»çš„11ç« 308ä¸ªé¢æ¿è¿›è¡Œè¯„ä¼°ï¼Œå‘ç°å½“å‰æ¨¡å‹åœ¨éçº¿æ€§å™äº‹å’Œå› æœæ¨ç†æ–¹é¢è¡¨ç°ä¸ä½³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å¤„ç†é¡ºåºè§†è§‰å™äº‹æ—¶ï¼Œè¡¨é¢è¯†åˆ«ä¸æ·±å±‚å™äº‹æ¨ç†ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®è·ã€‚é€šè¿‡å¯¹æ¼«ç”»å™äº‹ç†è§£çš„æ·±å…¥ç ”ç©¶ï¼Œæˆ‘ä»¬å‘ç°å°½ç®¡å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨å•ä¸ªé¢æ¿çš„è§£è¯»ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ—¶é—´å› æœå…³ç³»å’Œè·¨é¢æ¿è¿è´¯æ€§æ–¹é¢å­˜åœ¨ç³»ç»Ÿæ€§ç¼ºé™·ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œç»“åˆç»†ç²’åº¦å¤šæ¨¡æ€æ³¨é‡Šã€è·¨æ¨¡æ€åµŒå…¥åˆ†æå’Œæ£€ç´¢å¢å¼ºè¯„ä¼°ï¼Œç³»ç»Ÿæ€§åœ°è¡¨å¾è¿™äº›å±€é™æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºè¯„ä¼°å™äº‹æ™ºèƒ½å¥ å®šäº†åŸºç¡€ï¼Œå¹¶æä¾›äº†å¯¹æ·±åº¦é¡ºåºç†è§£ç¦»æ•£è§†è§‰å™äº‹èƒ½åŠ›çš„å¯è¡Œè§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æ¼«ç”»å™äº‹ç†è§£ä¸­çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯åœ¨æ—¶é—´å› æœå…³ç³»å’Œè·¨é¢æ¿è¿è´¯æ€§æ–¹é¢çš„ç¼ºé™·ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚å™äº‹æ—¶è¡¨ç°ä¸ä½³ï¼Œæ— æ³•å®ç°çœŸæ­£çš„æ•…äº‹çº§æ™ºèƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯é€šè¿‡å¼•å…¥ä¸€ç§æ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œç»“åˆç»†ç²’åº¦çš„å¤šæ¨¡æ€æ³¨é‡Šå’Œè·¨æ¨¡æ€åˆ†æï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°å’Œç†è§£VLMsçš„å™äº‹èƒ½åŠ›ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æ­ç¤ºæ¨¡å‹åœ¨å™äº‹ç†è§£ä¸­çš„æ ¹æœ¬ç¼ºé™·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) ä¸¥è°¨çš„æ³¨é‡Šåè®®ï¼Œå°†è§†è§‰å…ƒç´ ä¸å™äº‹ç»“æ„ç›¸è¿æ¥ï¼›2) å¤šç§æ¨ç†èŒƒå¼çš„ç»¼åˆè¯„ä¼°ï¼ŒåŒ…æ‹¬ç›´æ¥æ¨ç†å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼›3) è·¨æ¨¡æ€ç›¸ä¼¼æ€§åˆ†æï¼Œæ­ç¤ºå½“å‰VLMsçš„è”åˆè¡¨ç¤ºä¸­çš„åŸºæœ¬ä¸åŒ¹é…ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§ç³»ç»ŸåŒ–çš„è¯„ä¼°æ–¹æ³•ï¼Œèƒ½å¤Ÿæ·±å…¥åˆ†æVLMsåœ¨å™äº‹ç†è§£ä¸­çš„è¡¨ç°ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´ä¸ºå…¨é¢çš„è¯„ä¼°è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†ç²¾ç»†çš„æ³¨é‡Šæ ‡å‡†ï¼Œç»“åˆäº†å¤šæ¨¡æ€æ•°æ®çš„å¯¹é½ï¼Œå¹¶åœ¨è¯„ä¼°è¿‡ç¨‹ä¸­ä½¿ç”¨äº†å¤šç§æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å¤æ‚çš„å™äº‹ç»“æ„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨é•¿ç¯‡å™äº‹ç†è§£ä¸­è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨éçº¿æ€§å™äº‹å’Œå› æœæ¨ç†æ–¹é¢ã€‚é€šè¿‡æ–°è¯„ä¼°æ¡†æ¶çš„åº”ç”¨ï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨308ä¸ªé¢æ¿ä¸Šçš„ç³»ç»Ÿæ€§ç¼ºé™·ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†é‡è¦çš„æ”¹è¿›æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ¼«ç”»ã€åŠ¨ç”»å’Œæ¸¸æˆç­‰è§†è§‰å™äº‹å†…å®¹çš„è‡ªåŠ¨ç†è§£ä¸ç”Ÿæˆã€‚é€šè¿‡æ”¹è¿›è§†è§‰è¯­è¨€æ¨¡å‹çš„å™äº‹ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥æå‡ç›¸å…³é¢†åŸŸçš„å†…å®¹åˆ›ä½œã€æ¨èç³»ç»Ÿå’Œç”¨æˆ·äº¤äº’ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current Vision Language Models (VLMs) demonstrate a critical gap between surface-level recognition and deep narrative reasoning when processing sequential visual storytelling. Through a comprehensive investigation of manga narrative understanding, we reveal that while recent large multimodal models excel at individual panel interpretation, they systematically fail at temporal causality and cross-panel cohesion, core requirements for coherent story comprehension. We introduce a novel evaluation framework that combines fine-grained multimodal annotation, cross-modal embedding analysis, and retrieval-augmented assessment to systematically characterize these limitations.
>   Our methodology includes (i) a rigorous annotation protocol linking visual elements to narrative structure through aligned light novel text, (ii) comprehensive evaluation across multiple reasoning paradigms, including direct inference and retrieval-augmented generation, and (iii) cross-modal similarity analysis revealing fundamental misalignments in current VLMs' joint representations. Applying this framework to Re:Zero manga across 11 chapters with 308 annotated panels, we conduct the first systematic study of long-form narrative understanding in VLMs through three core evaluation axes: generative storytelling, contextual dialogue grounding, and temporal reasoning. Our findings demonstrate that current models lack genuine story-level intelligence, struggling particularly with non-linear narratives, character consistency, and causal inference across extended sequences. This work establishes both the foundation and practical methodology for evaluating narrative intelligence, while providing actionable insights into the capability of deep sequential understanding of Discrete Visual Narratives beyond basic recognition in Multimodal Models.
>   Project Page: https://re-verse.vercel.app

