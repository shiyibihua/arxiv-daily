---
layout: default
title: GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking
---

# GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08117" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08117v1</a>
  <a href="https://arxiv.org/pdf/2508.08117.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08117v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08117v1', 'GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xudong Han, Pengcheng Fang, Yueying Tian, Jianhui Yu, Xiaohao Cai, Daniel Roggen, Philip Birch

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGRASPTrackä»¥è§£å†³å•ç›®è§†é¢‘ä¸­çš„å¤šç›®æ ‡è·Ÿè¸ªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¤šç›®æ ‡è·Ÿè¸ª` `å•ç›®æ·±åº¦ä¼°è®¡` `å®ä¾‹åˆ†å‰²` `3Dç‚¹äº‘` `å¡å°”æ›¼æ»¤æ³¢` `è¿åŠ¨æ–¹å‘ä¸€è‡´æ€§` `é®æŒ¡å¤„ç†` `æ·±åº¦æ„ŸçŸ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºæ£€æµ‹çš„å¤šç›®æ ‡è·Ÿè¸ªæ–¹æ³•åœ¨å¤„ç†é®æŒ¡å’Œæ·±åº¦æ¨¡ç³Šæ—¶è¡¨ç°ä¸ä½³ï¼Œç¼ºä¹å‡ ä½•æ„è¯†ã€‚
2. GRASPTracké€šè¿‡ç»“åˆå•ç›®æ·±åº¦ä¼°è®¡å’Œå®ä¾‹åˆ†å‰²ï¼Œç”Ÿæˆ3Dç‚¹äº‘ä»¥è¿›è¡Œå‡ ä½•æ¨ç†ï¼Œå¹¶å¼•å…¥æ·±åº¦æ„ŸçŸ¥å™ªå£°è¡¥å¿ä»¥å¢å¼ºè·Ÿè¸ªé²æ£’æ€§ã€‚
3. åœ¨MOT17ã€MOT20å’ŒDanceTrackåŸºå‡†æµ‹è¯•ä¸Šï¼ŒGRASPTrackæ˜¾è‘—æé«˜äº†è·Ÿè¸ªæ€§èƒ½ï¼Œå°¤å…¶åœ¨å¤æ‚åœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å•ç›®è§†é¢‘ä¸­çš„å¤šç›®æ ‡è·Ÿè¸ªï¼ˆMOTï¼‰é¢ä¸´é®æŒ¡å’Œæ·±åº¦æ¨¡ç³Šç­‰æŒ‘æˆ˜ï¼Œä¼ ç»Ÿçš„åŸºäºæ£€æµ‹çš„è·Ÿè¸ªæ–¹æ³•éš¾ä»¥è§£å†³è¿™äº›é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†GRASPTrackï¼Œä¸€ä¸ªæ–°é¢–çš„æ·±åº¦æ„ŸçŸ¥MOTæ¡†æ¶ï¼Œç»“åˆå•ç›®æ·±åº¦ä¼°è®¡å’Œå®ä¾‹åˆ†å‰²ï¼Œç”Ÿæˆé«˜ä¿çœŸ3Dç‚¹äº‘ï¼Œä»è€Œå®ç°æ˜ç¡®çš„3Då‡ ä½•æ¨ç†ã€‚é€šè¿‡ä½“ç´ åŒ–è¿™äº›ç‚¹äº‘ï¼Œæœ¬æ–‡å®ç°äº†ç²¾ç¡®çš„ä½“ç´ åŸºç¡€3Däº¤å¹¶æ¯”ï¼ˆIoUï¼‰ä»¥è¿›è¡Œç©ºé—´å…³è”ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†æ·±åº¦æ„ŸçŸ¥è‡ªé€‚åº”å™ªå£°è¡¥å¿ï¼ŒåŠ¨æ€è°ƒæ•´å¡å°”æ›¼æ»¤æ³¢å™¨çš„è¿‡ç¨‹å™ªå£°ï¼Œä»¥æé«˜çŠ¶æ€ä¼°è®¡çš„å¯é æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGRASPTrackåœ¨MOT17ã€MOT20å’ŒDanceTrackåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æå‡äº†å¤æ‚åœºæ™¯ä¸­çš„è·Ÿè¸ªé²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å•ç›®è§†é¢‘ä¸­çš„å¤šç›®æ ‡è·Ÿè¸ªé—®é¢˜ï¼Œå°¤å…¶æ˜¯é®æŒ¡å’Œæ·±åº¦æ¨¡ç³Šå¸¦æ¥çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„åŸºäºæ£€æµ‹çš„æ–¹æ³•åœ¨è¿™äº›æƒ…å†µä¸‹å¾€å¾€æ— æ³•æœ‰æ•ˆè·Ÿè¸ªç›®æ ‡ï¼Œå¯¼è‡´è·Ÿè¸ªç²¾åº¦ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGRASPTrackçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å•ç›®æ·±åº¦ä¼°è®¡ä¸å®ä¾‹åˆ†å‰²ç›¸ç»“åˆï¼Œç”Ÿæˆé«˜ä¿çœŸçš„3Dç‚¹äº‘ï¼Œä»¥å®ç°æ›´å‡†ç¡®çš„å‡ ä½•æ¨ç†ã€‚è¿™ç§è®¾è®¡ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿåœ¨å¤æ‚åœºæ™¯ä¸­æ›´å¥½åœ°ç†è§£ç›®æ ‡ä¹‹é—´çš„ç©ºé—´å…³ç³»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGRASPTrackçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯å•ç›®æ·±åº¦ä¼°è®¡å’Œå®ä¾‹åˆ†å‰²æ¨¡å—ï¼Œç”Ÿæˆ2Dæ£€æµ‹çš„3Dç‚¹äº‘ï¼›å…¶æ¬¡æ˜¯ä½“ç´ åŒ–æ¨¡å—ï¼Œå°†3Dç‚¹äº‘è½¬æ¢ä¸ºä½“ç´ ï¼Œä»¥ä¾¿è¿›è¡Œç©ºé—´å…³è”ï¼›æœ€åæ˜¯è·Ÿè¸ªæ¨¡å—ï¼Œç»“åˆæ·±åº¦æ„ŸçŸ¥è‡ªé€‚åº”å™ªå£°è¡¥å¿å’Œè¿åŠ¨æ–¹å‘ä¸€è‡´æ€§æ¥æé«˜è·Ÿè¸ªçš„é²æ£’æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†æ·±åº¦æ„ŸçŸ¥è‡ªé€‚åº”å™ªå£°è¡¥å¿å’Œæ·±åº¦å¢å¼ºè§‚å¯Ÿä¸­å¿ƒåŠ¨é‡ã€‚è¿™äº›æ–¹æ³•ä½¿å¾—è·Ÿè¸ªç³»ç»Ÿèƒ½å¤ŸåŠ¨æ€è°ƒæ•´å™ªå£°æ°´å¹³ï¼Œå¹¶åœ¨3Dç©ºé—´ä¸­ä¿æŒè¿åŠ¨æ–¹å‘çš„ä¸€è‡´æ€§ï¼Œä»è€Œæ˜¾è‘—æå‡äº†è·Ÿè¸ªçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæœ¬æ–‡é‡‡ç”¨äº†åŠ¨æ€è°ƒæ•´çš„å¡å°”æ›¼æ»¤æ³¢å™¨è¿‡ç¨‹å™ªå£°ï¼Œå¹¶è®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–3Dç‚¹äº‘çš„ç”Ÿæˆå’Œä½“ç´ åŒ–è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œç½‘ç»œç»“æ„ä¸Šç»“åˆäº†æ·±åº¦ä¼°è®¡å’Œå®ä¾‹åˆ†å‰²çš„æœ€æ–°æŠ€æœ¯ï¼Œä»¥ç¡®ä¿é«˜æ•ˆçš„ç‰¹å¾æå–å’Œå¤„ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨MOT17ã€MOT20å’ŒDanceTrackåŸºå‡†æµ‹è¯•ä¸­ï¼ŒGRASPTrackçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚åœºæ™¯ä¸‹çš„è·Ÿè¸ªé²æ£’æ€§å¾—åˆ°äº†æ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®è¡¨æ˜ï¼Œè·Ÿè¸ªç²¾åº¦æå‡å¹…åº¦è¾¾åˆ°XX%ï¼Œåœ¨é®æŒ¡å’Œå¤æ‚è¿åŠ¨æ¨¡å¼ä¸‹è¡¨ç°å°¤ä¸ºçªå‡ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GRASPTrackçš„ç ”ç©¶æˆæœåœ¨è‡ªåŠ¨é©¾é©¶ã€è§†é¢‘ç›‘æ§å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜å¤šç›®æ ‡è·Ÿè¸ªçš„é²æ£’æ€§ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­æ›´å‡†ç¡®åœ°è¯†åˆ«å’Œè·Ÿè¸ªå¤šä¸ªç›®æ ‡ï¼Œè¿›è€Œæå‡ç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³å’Œå®ç”¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨å®æ—¶è·Ÿè¸ªå’Œåˆ†æä¸­å‘æŒ¥æ›´å¤§ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multi-object tracking (MOT) in monocular videos is fundamentally challenged by occlusions and depth ambiguity, issues that conventional tracking-by-detection (TBD) methods struggle to resolve owing to a lack of geometric awareness. To address these limitations, we introduce GRASPTrack, a novel depth-aware MOT framework that integrates monocular depth estimation and instance segmentation into a standard TBD pipeline to generate high-fidelity 3D point clouds from 2D detections, thereby enabling explicit 3D geometric reasoning. These 3D point clouds are then voxelized to enable a precise and robust Voxel-Based 3D Intersection-over-Union (IoU) for spatial association. To further enhance tracking robustness, our approach incorporates Depth-aware Adaptive Noise Compensation, which dynamically adjusts the Kalman filter process noise based on occlusion severity for more reliable state estimation. Additionally, we propose a Depth-enhanced Observation-Centric Momentum, which extends the motion direction consistency from the image plane into 3D space to improve motion-based association cues, particularly for objects with complex trajectories. Extensive experiments on the MOT17, MOT20, and DanceTrack benchmarks demonstrate that our method achieves competitive performance, significantly improving tracking robustness in complex scenes with frequent occlusions and intricate motion patterns.

