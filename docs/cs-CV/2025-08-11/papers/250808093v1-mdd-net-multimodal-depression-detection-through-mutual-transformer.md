---
layout: default
title: MDD-Net: Multimodal Depression Detection through Mutual Transformer
---

# MDD-Net: Multimodal Depression Detection through Mutual Transformer

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08093" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08093v1</a>
  <a href="https://arxiv.org/pdf/2508.08093.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08093v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08093v1', 'MDD-Net: Multimodal Depression Detection through Mutual Transformer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Md Rezwanul Haque, Md. Milon Islam, S M Taslim Uddin Raju, Hamdi Altaheri, Lobna Nassar, Fakhri Karray

**åˆ†ç±»**: cs.CV, cs.LG, cs.MM, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11

**å¤‡æ³¨**: Accepted for the 2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC), Vienna, Austria

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/rezwanh001/Multimodal-Depression-Detection)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMDD-Netä»¥è§£å†³å¤šæ¨¡æ€æŠ‘éƒæ£€æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æŠ‘éƒæ£€æµ‹` `äº’å˜æ¢å™¨` `å£°å­¦ç‰¹å¾æå–` `è§†è§‰ç‰¹å¾æå–` `æ·±åº¦å­¦ä¹ ` `å¿ƒç†å¥åº·` `ç¤¾äº¤åª’ä½“åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æŠ‘éƒæ£€æµ‹æ–¹æ³•å¾€å¾€ä¾èµ–å•ä¸€æ¨¡æ€ï¼Œéš¾ä»¥å…¨é¢æ•æ‰æƒ…æ„ŸçŠ¶æ€ï¼Œå¯¼è‡´æ£€æµ‹æ•ˆæœä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºçš„MDD-Netç»“åˆå£°å­¦å’Œè§†è§‰æ•°æ®ï¼Œé€šè¿‡äº’å˜æ¢å™¨é«˜æ•ˆæå–å’Œèåˆå¤šæ¨¡æ€ç‰¹å¾ï¼Œæå‡æŠ‘éƒæ£€æµ‹çš„å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMDD-Netåœ¨F1åˆ†æ•°ä¸Šæ¯”ç°æœ‰æŠ€æœ¯æé«˜äº†17.37%ï¼ŒéªŒè¯äº†å…¶åœ¨æŠ‘éƒæ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŠ‘éƒç—‡æ˜¯ä¸€ç§ä¸¥é‡å½±å“ä¸ªäººæƒ…æ„Ÿå’Œèº«ä½“å¥åº·çš„å¿ƒç†å¥åº·é—®é¢˜ã€‚åˆ©ç”¨ç¤¾äº¤åª’ä½“å¹³å°æ”¶é›†æ•°æ®çš„ç®€å•æ€§å¼•èµ·äº†äººä»¬å¯¹å¿ƒç†å¥åº·ç ”ç©¶çš„å…³æ³¨ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€æŠ‘éƒæ£€æµ‹ç½‘ç»œï¼ˆMDD-Netï¼‰ï¼Œåˆ©ç”¨ä»ç¤¾äº¤åª’ä½“ç½‘ç»œè·å–çš„å£°å­¦å’Œè§†è§‰æ•°æ®ï¼Œé€šè¿‡äº’å˜æ¢å™¨æœ‰æ•ˆæå–å’Œèåˆå¤šæ¨¡æ€ç‰¹å¾ï¼Œä»¥å®ç°é«˜æ•ˆçš„æŠ‘éƒæ£€æµ‹ã€‚MDD-Netç”±å››ä¸ªæ ¸å¿ƒæ¨¡å—ç»„æˆï¼šå£°å­¦ç‰¹å¾æå–æ¨¡å—ã€è§†è§‰ç‰¹å¾æå–æ¨¡å—ã€äº’å˜æ¢å™¨å’Œæ£€æµ‹å±‚ã€‚é€šè¿‡å¯¹å¤šæ¨¡æ€D-Vlogæ•°æ®é›†çš„å¹¿æ³›å®éªŒï¼Œç»“æœè¡¨æ˜è¯¥ç½‘ç»œåœ¨F1åˆ†æ•°ä¸Šè¶…è¿‡äº†ç°æœ‰æŠ€æœ¯17.37%ï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæŠ‘éƒç—‡çš„æ£€æµ‹é€šå¸¸ä¾èµ–äºå•ä¸€æ¨¡æ€æ•°æ®ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¯¼è‡´æ£€æµ‹å‡†ç¡®æ€§ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚æƒ…æ„ŸçŠ¶æ€æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMDD-Neté€šè¿‡ç»“åˆå£°å­¦å’Œè§†è§‰æ•°æ®ï¼Œåˆ©ç”¨äº’å˜æ¢å™¨æå–å’Œèåˆå¤šæ¨¡æ€ç‰¹å¾ï¼Œä»è€Œæé«˜æŠ‘éƒæ£€æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚è¯¥è®¾è®¡æ—¨åœ¨å……åˆ†åˆ©ç”¨ä¸åŒæ¨¡æ€çš„ä¿¡æ¯äº’è¡¥æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMDD-Netçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å››ä¸ªä¸»è¦æ¨¡å—ï¼šå£°å­¦ç‰¹å¾æå–æ¨¡å—ç”¨äºæå–ç›¸å…³å£°å­¦å±æ€§ï¼›è§†è§‰ç‰¹å¾æå–æ¨¡å—ç”¨äºæå–æ˜¾è‘—çš„é«˜å±‚æ¨¡å¼ï¼›äº’å˜æ¢å™¨ç”¨äºè®¡ç®—ç”Ÿæˆç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§å¹¶èåˆå¤šæ¨¡æ€ç‰¹å¾ï¼›æ£€æµ‹å±‚ç”¨äºåŸºäºèåˆç‰¹å¾è¡¨ç¤ºè¿›è¡ŒæŠ‘éƒæ£€æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šMDD-Netçš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº’å˜æ¢å™¨ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°è®¡ç®—å’Œèåˆæ¥è‡ªä¸åŒæ¨¡æ€çš„ç‰¹å¾ï¼Œæ˜¾è‘—æå‡äº†æŠ‘éƒæ£€æµ‹çš„æ€§èƒ½ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨ç‰¹å¾èåˆä¸Šå…·æœ‰æ›´é«˜çš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œè®¾è®¡ä¸­ï¼Œå£°å­¦å’Œè§†è§‰ç‰¹å¾æå–æ¨¡å—é‡‡ç”¨äº†æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œäº’å˜æ¢å™¨çš„ç»“æ„ç»è¿‡ä¼˜åŒ–ä»¥æé«˜ç‰¹å¾èåˆçš„æ•ˆç‡ã€‚æŸå¤±å‡½æ•°è®¾è®¡ä¸ºé€‚åº”å¤šæ¨¡æ€æ•°æ®çš„ç‰¹æ€§ï¼Œç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMDD-Netåœ¨F1åˆ†æ•°ä¸Šæ¯”ç°æœ‰æŠ€æœ¯æé«˜äº†17.37%ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å¤šæ¨¡æ€æŠ‘éƒæ£€æµ‹ä¸­çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚è¿™ä¸€æˆæœä¸ä»…éªŒè¯äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œä¹Ÿä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¿ƒç†å¥åº·ç›‘æµ‹ã€ç¤¾äº¤åª’ä½“æƒ…æ„Ÿåˆ†æä»¥åŠæ™ºèƒ½å¥åº·ç®¡ç†ç³»ç»Ÿã€‚é€šè¿‡å®æ—¶ç›‘æµ‹ç”¨æˆ·çš„æƒ…æ„ŸçŠ¶æ€ï¼ŒMDD-Netå¯ä»¥ä¸ºå¿ƒç†å¥åº·å¹²é¢„æä¾›æ•°æ®æ”¯æŒï¼Œå¸®åŠ©ä¸“ä¸šäººå£«åˆ¶å®šä¸ªæ€§åŒ–çš„æ²»ç–—æ–¹æ¡ˆï¼Œå…·æœ‰é‡è¦çš„ç¤¾ä¼šä»·å€¼å’Œå®é™…æ„ä¹‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Depression is a major mental health condition that severely impacts the emotional and physical well-being of individuals. The simple nature of data collection from social media platforms has attracted significant interest in properly utilizing this information for mental health research. A Multimodal Depression Detection Network (MDD-Net), utilizing acoustic and visual data obtained from social media networks, is proposed in this work where mutual transformers are exploited to efficiently extract and fuse multimodal features for efficient depression detection. The MDD-Net consists of four core modules: an acoustic feature extraction module for retrieving relevant acoustic attributes, a visual feature extraction module for extracting significant high-level patterns, a mutual transformer for computing the correlations among the generated features and fusing these features from multiple modalities, and a detection layer for detecting depression using the fused feature representations. The extensive experiments are performed using the multimodal D-Vlog dataset, and the findings reveal that the developed multimodal depression detection network surpasses the state-of-the-art by up to 17.37% for F1-Score, demonstrating the greater performance of the proposed system. The source code is accessible at https://github.com/rezwanh001/Multimodal-Depression-Detection.

