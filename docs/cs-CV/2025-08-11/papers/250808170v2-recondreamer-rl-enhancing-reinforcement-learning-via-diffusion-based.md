---
layout: default
title: ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction
---

# ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08170" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.08170v2</a>
  <a href="https://arxiv.org/pdf/2508.08170.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08170v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08170v2', 'ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Chaojun Ni, Guosheng Zhao, Xiaofeng Wang, Zheng Zhu, Wenkang Qin, Xinze Chen, Guanghong Jia, Guan Huang, Wenjun Mei

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-11 (Êõ¥Êñ∞: 2025-08-21)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ReconDreamer-RL‰ª•Ëß£ÂÜ≥‰ªøÁúü‰∏éÁé∞ÂÆû‰πãÈó¥ÁöÑÂ∑ÆË∑ùÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `Âº∫ÂåñÂ≠¶‰π†` `Ëá™Âä®È©æÈ©∂` `Âú∫ÊôØÈáçÂª∫` `ËßÜÈ¢ëÊâ©Êï£` `‰ªøÁúüÊäÄÊúØ` `Êï∞ÊçÆÂàÜÂ∏É` `Â§çÊùÇÂú∫ÊôØÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑËá™Âä®È©æÈ©∂‰ªøÁúüÊñπÊ≥ïÂú®ÁúüÂÆû‰∏ñÁïåÊù°‰ª∂‰∏ãË°®Áé∞‰∏ç‰Ω≥ÔºåÂØºËá¥‰ªøÁúü‰∏éÁé∞ÂÆû‰πãÈó¥Â≠òÂú®ÊòæËëóÂ∑ÆË∑ù„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ReconDreamer-RLÊ°ÜÊû∂ÔºåÁªìÂêàËßÜÈ¢ëÊâ©Êï£ÂÖàÈ™åÂíåËøêÂä®Â≠¶Ê®°ÂûãÔºåÈáçÂª∫ÁúüÂÆûÈ©æÈ©∂Âú∫ÊôØ‰ª•ÊîπÂñÑÂº∫ÂåñÂ≠¶‰π†ÊïàÊûú„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåReconDreamer-RLÂú®Ëá™Âä®È©æÈ©∂ËÆ≠ÁªÉ‰∏≠‰ºò‰∫éÊ®°‰ªøÂ≠¶‰π†ÊñπÊ≥ïÔºåÁ¢∞ÊíûÁéáÈôç‰Ωé‰∫Ü5ÂÄçÔºåÊòæËëóÊèêÂçá‰∫ÜËÆ≠ÁªÉÊïàÊûú„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÂº∫ÂåñÂ≠¶‰π†Âú®Èó≠ÁéØ‰ªøÁúü‰∏≠ËÆ≠ÁªÉÁ´ØÂà∞Á´ØËá™Âä®È©æÈ©∂Ê®°ÂûãÁöÑÂÖ≥Ê≥®Â∫¶Êó•ÁõäÂ¢ûÂä†ÔºåÁé∞ÊúâÁöÑ‰ªøÁúüÁéØÂ¢É‰∏éÁúüÂÆû‰∏ñÁïåÊù°‰ª∂‰πãÈó¥Â≠òÂú®ÊòæËëóÂ∑ÆË∑ùÔºåÂΩ¢Êàê‰∫ÜËæÉÂ§ßÁöÑ‰ªøÁúüÂà∞Áé∞ÂÆûÔºàsim2realÔºâÂ∑ÆË∑ù„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜReconDreamer-RLÊ°ÜÊû∂ÔºåÈÄöËøáÂ∞ÜËßÜÈ¢ëÊâ©Êï£ÂÖàÈ™åËûçÂÖ•Âú∫ÊôØÈáçÂª∫ÔºåÂ¢ûÂº∫Âº∫ÂåñÂ≠¶‰π†ÁöÑÊïàÊûú„ÄÇËØ•Ê°ÜÊû∂ÂºïÂÖ•‰∫ÜReconSimulatorÔºåÁªìÂêàËßÜÈ¢ëÊâ©Êï£ÂÖàÈ™åËøõË°åÂ§ñËßÇÂª∫Ê®°ÔºåÂπ∂ÁªìÂêàËøêÂä®Â≠¶Ê®°ÂûãËøõË°åÁâ©ÁêÜÂª∫Ê®°Ôºå‰ªéÁúüÂÆûÊï∞ÊçÆ‰∏≠ÈáçÂª∫È©æÈ©∂Âú∫ÊôØ„ÄÇÊ≠§Â§ñÔºåÂä®ÊÄÅÂØπÊäó‰ª£ÁêÜÔºàDAAÔºâËÉΩÂ§üËá™‰∏ªÁîüÊàêÂ§çÊùÇ‰∫§ÈÄöÂú∫ÊôØÔºåÊúÄÂêéÔºåË°®‰∫≤ËΩ®ËøπÁîüÊàêÂô®ÔºàCTGÔºâËß£ÂÜ≥‰∫ÜËÆ≠ÁªÉÊï∞ÊçÆÂàÜÂ∏ÉÂÅèÂêëÁÆÄÂçïÁõ¥Á∫øËøêÂä®ÁöÑÈóÆÈ¢ò„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåReconDreamer-RLÂú®Á´ØÂà∞Á´ØËá™Âä®È©æÈ©∂ËÆ≠ÁªÉ‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÁ¢∞ÊíûÁéáÈôç‰Ωé‰∫Ü5ÂÄç„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâËá™Âä®È©æÈ©∂‰ªøÁúüÊñπÊ≥ïÂú®ÁúüÂÆû‰∏ñÁïåÊù°‰ª∂‰∏ãÁöÑ‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØ‰ªøÁúü‰∏éÁé∞ÂÆû‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºåÂØºËá¥Èöæ‰ª•ÁîüÊàêÈ´òË¥®ÈáèÁöÑ‰º†ÊÑüÂô®Êï∞ÊçÆ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÂºïÂÖ•ËßÜÈ¢ëÊâ©Êï£ÂÖàÈ™åËøõË°åÂú∫ÊôØÈáçÂª∫ÔºåÁªìÂêàËøêÂä®Â≠¶Ê®°Âûã‰ª•ÂÆûÁé∞Êõ¥ÁúüÂÆûÁöÑÁâ©ÁêÜÊ®°ÊãüÔºå‰ªéËÄåÁº©Â∞è‰ªøÁúü‰∏éÁé∞ÂÆû‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöReconDreamer-RLÊ°ÜÊû∂ÂåÖÊã¨ReconSimulator„ÄÅÂä®ÊÄÅÂØπÊäó‰ª£ÁêÜÔºàDAAÔºâÂíåË°®‰∫≤ËΩ®ËøπÁîüÊàêÂô®ÔºàCTGÔºâ„ÄÇReconSimulatorË¥üË¥£Âú∫ÊôØÈáçÂª∫ÔºåDAAÁîüÊàêÂ§çÊùÇ‰∫§ÈÄöÂú∫ÊôØÔºåCTGÂàôË∞ÉÊï¥ËÆ≠ÁªÉÊï∞ÊçÆÂàÜÂ∏É„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÂ∞ÜËßÜÈ¢ëÊâ©Êï£ÂÖàÈ™å‰∏éËøêÂä®Â≠¶Ê®°ÂûãÁªìÂêàÔºåËÉΩÂ§üÂú®ÁúüÂÆûÊï∞ÊçÆÂü∫Á°Ä‰∏äÈáçÂª∫È©æÈ©∂Âú∫ÊôØÔºåËß£ÂÜ≥‰∫Ü‰º†ÁªüÊñπÊ≥ïÂú®Êñ∞ËΩ®ËøπÊàñÂ§çÊùÇÂú∫ÊôØ‰∏ãÁöÑÂ±ÄÈôêÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåReconSimulatorÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•‰ºòÂåñÂú∫ÊôØÈáçÂª∫Ë¥®ÈáèÔºåDAAÈÄöËøáË∞ÉÊï¥Âë®Âõ¥ËΩ¶ËæÜËΩ®ËøπÁîüÊàêÂ§çÊùÇÂú∫ÊôØÔºåCTGÂàôÈÄöËøáÁîüÊàêÂ§öÊ†∑ÂåñÁöÑËÆ≠ÁªÉÊï∞ÊçÆÊù•Ëß£ÂÜ≥Êï∞ÊçÆÂàÜÂ∏ÉÂÅèÂ∑ÆÈóÆÈ¢ò„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåReconDreamer-RLÂú®Á´ØÂà∞Á´ØËá™Âä®È©æÈ©∂ËÆ≠ÁªÉ‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÁõ∏ËæÉ‰∫éÊ®°‰ªøÂ≠¶‰π†ÊñπÊ≥ïÔºåÁ¢∞ÊíûÁéáÈôç‰Ωé‰∫Ü5ÂÄçÔºåÊòæËëóÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÂÆâÂÖ®ÊÄß‰∏éÂèØÈù†ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™Âä®È©æÈ©∂Á≥ªÁªüÁöÑÂºÄÂèë‰∏éÊµãËØïÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇ‰∫§ÈÄöÂú∫ÊôØ‰∏ãÁöÑÂÆâÂÖ®ÊÄßËØÑ‰º∞‰∏é‰ºòÂåñ„ÄÇÈÄöËøáÊèêÈ´ò‰ªøÁúüÁéØÂ¢ÉÁöÑÁúüÂÆûÊÄßÔºåËÉΩÂ§üÊúâÊïàÊèêÂçáËá™Âä®È©æÈ©∂Ê®°ÂûãÂú®ÁúüÂÆû‰∏ñÁïå‰∏≠ÁöÑË°®Áé∞ÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Reinforcement learning for training end-to-end autonomous driving models in closed-loop simulations is gaining growing attention. However, most simulation environments differ significantly from real-world conditions, creating a substantial simulation-to-reality (sim2real) gap. To bridge this gap, some approaches utilize scene reconstruction techniques to create photorealistic environments as a simulator. While this improves realistic sensor simulation, these methods are inherently constrained by the distribution of the training data, making it difficult to render high-quality sensor data for novel trajectories or corner case scenarios. Therefore, we propose ReconDreamer-RL, a framework designed to integrate video diffusion priors into scene reconstruction to aid reinforcement learning, thereby enhancing end-to-end autonomous driving training. Specifically, in ReconDreamer-RL, we introduce ReconSimulator, which combines the video diffusion prior for appearance modeling and incorporates a kinematic model for physical modeling, thereby reconstructing driving scenarios from real-world data. This narrows the sim2real gap for closed-loop evaluation and reinforcement learning. To cover more corner-case scenarios, we introduce the Dynamic Adversary Agent (DAA), which adjusts the trajectories of surrounding vehicles relative to the ego vehicle, autonomously generating corner-case traffic scenarios (e.g., cut-in). Finally, the Cousin Trajectory Generator (CTG) is proposed to address the issue of training data distribution, which is often biased toward simple straight-line movements. Experiments show that ReconDreamer-RL improves end-to-end autonomous driving training, outperforming imitation learning methods with a 5x reduction in the Collision Ratio.

