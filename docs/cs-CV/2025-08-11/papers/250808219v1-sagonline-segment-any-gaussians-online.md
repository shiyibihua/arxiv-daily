---
layout: default
title: SAGOnline: Segment Any Gaussians Online
---

# SAGOnline: Segment Any Gaussians Online

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08219" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08219v1</a>
  <a href="https://arxiv.org/pdf/2508.08219.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08219v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08219v1', 'SAGOnline: Segment Any Gaussians Online')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wentao Sun, Quanyun Wu, Hanqing Xu, Kyle Gao, Zhengsen Xu, Yiping Chen, Dedong Zhang, Lingfei Ma, John S. Zelek, Jonathan Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11

**å¤‡æ³¨**: 19 pages, 10 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSAGOnlineä»¥è§£å†³é«˜æ•ˆ3Dåˆ†å‰²é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dåˆ†å‰²` `é«˜æ–¯è¡¨ç¤º` `å®æ—¶å¤„ç†` `è§†é¢‘åŸºç¡€æ¨¡å‹` `å¤šç‰©ä½“è·Ÿè¸ª` `å¢å¼ºç°å®` `è™šæ‹Ÿç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dåˆ†å‰²æ–¹æ³•è®¡ç®—æˆæœ¬é«˜ï¼Œç©ºé—´æ¨ç†èƒ½åŠ›æœ‰é™ï¼Œæ— æ³•åŒæ—¶è·Ÿè¸ªå¤šä¸ªç‰©ä½“ã€‚
2. æå‡ºSAGOnlineæ¡†æ¶ï¼Œç»“åˆè§†é¢‘åŸºç¡€æ¨¡å‹å®ç°2Dæ©ç ä¼ æ’­ï¼Œå¹¶é€šè¿‡GPUåŠ é€Ÿç”Ÿæˆ3Dæ©ç ã€‚
3. åœ¨NVOSå’ŒSpin-NeRFåŸºå‡†æµ‹è¯•ä¸­ï¼ŒSAGOnlineåˆ†åˆ«å–å¾—92.7%å’Œ95.2%çš„mIoUï¼Œæ¨ç†é€Ÿåº¦æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

3Dé«˜æ–¯ç‚¹äº‘è¡¨ç¤ºï¼ˆ3DGSï¼‰åœ¨æ˜ç¡®çš„3Dåœºæ™¯è¡¨ç¤ºä¸­å±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†å®ç°é«˜æ•ˆä¸”ä¸€è‡´çš„3Dåˆ†å‰²ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨è®¡ç®—æˆæœ¬é«˜ã€3Dç©ºé—´æ¨ç†èƒ½åŠ›æœ‰é™ä»¥åŠæ— æ³•åŒæ—¶è·Ÿè¸ªå¤šä¸ªç‰©ä½“ç­‰é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§è½»é‡çº§çš„é›¶æ ·æœ¬æ¡†æ¶SAGOnlineï¼Œæ—¨åœ¨å®æ—¶è¿›è¡Œé«˜æ–¯åœºæ™¯çš„3Dåˆ†å‰²ã€‚é€šè¿‡ä¸¤ä¸ªå…³é”®åˆ›æ–°ï¼ŒSAGOnlineæœ‰æ•ˆè§£å†³äº†è¿™äº›é—®é¢˜ï¼šä¸€æ˜¯é‡‡ç”¨è§£è€¦ç­–ç•¥ï¼Œç»“åˆè§†é¢‘åŸºç¡€æ¨¡å‹ï¼ˆå¦‚SAM2ï¼‰å®ç°åˆæˆè§†å›¾é—´ä¸€è‡´çš„2Dæ©ç ä¼ æ’­ï¼›äºŒæ˜¯å¼€å‘äº†GPUåŠ é€Ÿçš„3Dæ©ç ç”Ÿæˆå’Œé«˜æ–¯çº§å®ä¾‹æ ‡è®°ç®—æ³•ï¼Œä¸º3DåŸè¯­åˆ†é…å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œä»è€Œå®ç°æ— æŸçš„å¤šç‰©ä½“è·Ÿè¸ªå’Œåˆ†å‰²ã€‚SAGOnlineåœ¨NVOSå’ŒSpin-NeRFåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ¨ç†é€Ÿåº¦æ¯”ç°æœ‰æ–¹æ³•å¿«15è‡³1500å€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é«˜æ•ˆä¸”ä¸€è‡´çš„3Dåˆ†å‰²é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è®¡ç®—æˆæœ¬ã€ç©ºé—´æ¨ç†å’Œå¤šç‰©ä½“è·Ÿè¸ªæ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSAGOnlineé€šè¿‡è§£è€¦ç­–ç•¥å’ŒGPUåŠ é€ŸæŠ€æœ¯ï¼Œç»“åˆè§†é¢‘åŸºç¡€æ¨¡å‹ï¼Œå®ç°é«˜æ•ˆçš„3Dåˆ†å‰²å’Œè·Ÿè¸ªã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿåœ¨å®æ—¶åœºæ™¯ä¸­å¤„ç†å¤æ‚çš„3Dæ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSAGOnlineçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€æ˜¯åŸºäºè§†é¢‘åŸºç¡€æ¨¡å‹çš„2Dæ©ç ä¼ æ’­ï¼ŒäºŒæ˜¯GPUåŠ é€Ÿçš„3Dæ©ç ç”Ÿæˆä¸å®ä¾‹æ ‡è®°ã€‚è¿™ä¸¤ä¸ªæ¨¡å—ååŒå·¥ä½œï¼Œå®ç°äº†é«˜æ•ˆçš„3Dåˆ†å‰²ã€‚

**å…³é”®åˆ›æ–°**ï¼šSAGOnlineçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†è§†é¢‘åŸºç¡€æ¨¡å‹æœ‰æ•ˆé€‚åº”äº3Dåœºæ™¯ï¼Œå¹¶å®ç°é«˜æ–¯åŸè¯­çš„æ˜¾å¼æ ‡è®°ï¼Œæ”¯æŒåŒæ—¶çš„åˆ†å‰²ä¸è·Ÿè¸ªã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€å¤„ç†æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒSAGOnlineé‡‡ç”¨äº†é«˜æ•ˆçš„GPUè®¡ç®—èµ„æºï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šæ³¨é‡å¤šç‰©ä½“çš„æ— æŸè·Ÿè¸ªï¼Œç½‘ç»œç»“æ„åˆ™é€šè¿‡è§£è€¦è®¾è®¡æå‡äº†å¤„ç†é€Ÿåº¦å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SAGOnlineåœ¨NVOSå’ŒSpin-NeRFåŸºå‡†æµ‹è¯•ä¸­åˆ†åˆ«å–å¾—92.7%å’Œ95.2%çš„mIoUï¼Œæ¨ç†é€Ÿåº¦è¾¾åˆ°27æ¯«ç§’æ¯å¸§ï¼Œç›¸è¾ƒäºFeature3DGSã€OmniSeg3D-gså’ŒSA3Dæå‡äº†15è‡³1500å€ï¼Œå±•ç°å‡ºå“è¶Šçš„æ€§èƒ½å’Œæ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SAGOnlineçš„ç ”ç©¶æˆæœåœ¨å¢å¼ºç°å®ï¼ˆARï¼‰ã€è™šæ‹Ÿç°å®ï¼ˆVRï¼‰å’Œæœºå™¨äººç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡å®æ—¶çš„3Dåœºæ™¯ç†è§£å’Œåˆ†å‰²ï¼Œèƒ½å¤Ÿæå‡äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæ™ºèƒ½åŒ–æ°´å¹³ï¼Œä¸ºæœªæ¥çš„æ™ºèƒ½ç³»ç»Ÿæä¾›æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> 3D Gaussian Splatting (3DGS) has emerged as a powerful paradigm for explicit 3D scene representation, yet achieving efficient and consistent 3D segmentation remains challenging. Current methods suffer from prohibitive computational costs, limited 3D spatial reasoning, and an inability to track multiple objects simultaneously. We present Segment Any Gaussians Online (SAGOnline), a lightweight and zero-shot framework for real-time 3D segmentation in Gaussian scenes that addresses these limitations through two key innovations: (1) a decoupled strategy that integrates video foundation models (e.g., SAM2) for view-consistent 2D mask propagation across synthesized views; and (2) a GPU-accelerated 3D mask generation and Gaussian-level instance labeling algorithm that assigns unique identifiers to 3D primitives, enabling lossless multi-object tracking and segmentation across views. SAGOnline achieves state-of-the-art performance on NVOS (92.7% mIoU) and Spin-NeRF (95.2% mIoU) benchmarks, outperforming Feature3DGS, OmniSeg3D-gs, and SA3D by 15--1500 times in inference speed (27 ms/frame). Qualitative results demonstrate robust multi-object segmentation and tracking in complex scenes. Our contributions include: (i) a lightweight and zero-shot framework for 3D segmentation in Gaussian scenes, (ii) explicit labeling of Gaussian primitives enabling simultaneous segmentation and tracking, and (iii) the effective adaptation of 2D video foundation models to the 3D domain. This work allows real-time rendering and 3D scene understanding, paving the way for practical AR/VR and robotic applications.

