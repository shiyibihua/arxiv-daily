---
layout: default
title: Trans-defense: Transformer-based Denoiser for Adversarial Defense with Spatial-Frequency Domain Representation
---

# Trans-defense: Transformer-based Denoiser for Adversarial Defense with Spatial-Frequency Domain Representation

**arXiv**: [2510.27245v1](https://arxiv.org/abs/2510.27245) | [PDF](https://arxiv.org/pdf/2510.27245.pdf)

**ä½œè€…**: Alik Pramanick, Mayank Bansal, Utkarsh Srivastava, Suklav Ghosh, Arijit Sur

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºTransformerçš„ç©ºé—´-é¢‘ç‡åŸŸå»å™ªæ–¹æ³•ä»¥é˜²å¾¡å›¾åƒå¯¹æŠ—æ”»å‡»**

**å…³é”®è¯**: `å¯¹æŠ—é˜²å¾¡` `å›¾åƒå»å™ª` `Transformer` `ç©ºé—´-é¢‘ç‡åŸŸ` `ç¦»æ•£å°æ³¢å˜æ¢` `æ·±åº¦ç¥ç»ç½‘ç»œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ·±åº¦ç¥ç»ç½‘ç»œæ˜“å—å¯¹æŠ—æ”»å‡»ï¼Œé™åˆ¶å…¶åœ¨å®‰å…¨å…³é”®ç³»ç»Ÿä¸­çš„åº”ç”¨
2. é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒï¼šå…ˆè®­ç»ƒå»å™ªç½‘ç»œï¼Œå†è®­ç»ƒåˆ†ç±»å™¨ï¼›ç»“åˆç©ºé—´å’Œé¢‘ç‡åŸŸç‰¹å¾
3. åœ¨MNISTç­‰æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡åˆ†ç±»å‡†ç¡®ç‡ï¼Œä¼˜äºç°æœ‰å»å™ªå’Œå¯¹æŠ—è®­ç»ƒæ–¹æ³•

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In recent times, deep neural networks (DNNs) have been successfully adopted
> for various applications. Despite their notable achievements, it has become
> evident that DNNs are vulnerable to sophisticated adversarial attacks,
> restricting their applications in security-critical systems. In this paper, we
> present two-phase training methods to tackle the attack: first, training the
> denoising network, and second, the deep classifier model. We propose a novel
> denoising strategy that integrates both spatial and frequency domain approaches
> to defend against adversarial attacks on images. Our analysis reveals that
> high-frequency components of attacked images are more severely corrupted
> compared to their lower-frequency counterparts. To address this, we leverage
> Discrete Wavelet Transform (DWT) for frequency analysis and develop a denoising
> network that combines spatial image features with wavelets through a
> transformer layer. Next, we retrain the classifier using the denoised images,
> which enhances the classifier's robustness against adversarial attacks.
> Experimental results across the MNIST, CIFAR-10, and Fashion-MNIST datasets
> reveal that the proposed method remarkably elevates classification accuracy,
> substantially exceeding the performance by utilizing a denoising network and
> adversarial training approaches. The code is available at
> https://github.com/Mayank94/Trans-Defense.

