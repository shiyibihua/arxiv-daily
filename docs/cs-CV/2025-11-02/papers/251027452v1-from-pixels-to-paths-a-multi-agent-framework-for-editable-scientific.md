---
layout: default
title: From Pixels to Paths: A Multi-Agent Framework for Editable Scientific Illustration
---

# From Pixels to Paths: A Multi-Agent Framework for Editable Scientific Illustration

**arXiv**: [2510.27452v1](https://arxiv.org/abs/2510.27452) | [PDF](https://arxiv.org/pdf/2510.27452.pdf)

**ä½œè€…**: Jianwen Sun, Fanrui Zhang, Yukang Feng, Chuanhao Li, Zizhen Li, Jiaxin Ai, Yifan Chang, Yu Dai, Kaipeng Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVisPainterå¤šæ™ºèƒ½ä½“æ¡†æž¶ä»¥è§£å†³ç§‘å­¦æ’å›¾çš„å…ƒç´ çº§ç¼–è¾‘é—®é¢˜**

**å…³é”®è¯**: `ç§‘å­¦æ’å›¾ç”Ÿæˆ` `å¤šæ™ºèƒ½ä½“æ¡†æž¶` `çŸ¢é‡å›¾å½¢ç¼–è¾‘` `è§†è§‰è¯­è¨€æ¨¡åž‹è¯„ä¼°` `å…ƒç´ çº§æŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ç”Ÿæˆæ¨¡åž‹ç¼ºä¹è¯­ä¹‰ç»“æž„ï¼Œä»£ç æ–¹æ³•ç¼–è¾‘ç¹çï¼Œæ— æ³•é«˜æ•ˆè¿­ä»£ä¿®æ”¹ç§‘å­¦æ’å›¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å¤šæ™ºèƒ½ä½“åä½œï¼ŒåŒ…æ‹¬Managerã€Designerå’ŒToolboxæ¨¡å—ï¼Œç”Ÿæˆå¯ç¼–è¾‘çŸ¢é‡å›¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå¼•å…¥VisBenchåŸºå‡†è¿›è¡Œä¸ƒç»´è¯„ä¼°ï¼ŒéªŒè¯æž¶æž„åˆç†æ€§å’Œæ¨¡åž‹èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Scientific illustrations demand both high information density and
> post-editability. However, current generative models have two major
> limitations: Frist, image generation models output rasterized images lacking
> semantic structure, making it impossible to access, edit, or rearrange
> independent visual components in the images. Second, code-based generation
> methods (TikZ or SVG), although providing element-level control, force users
> into the cumbersome cycle of "writing-compiling-reviewing" and lack the
> intuitiveness of manipulation. Neither of these two approaches can well meet
> the needs for efficiency, intuitiveness, and iterative modification in
> scientific creation. To bridge this gap, we introduce VisPainter, a multi-agent
> framework for scientific illustration built upon the model context protocol.
> VisPainter orchestrates three specialized modules-a Manager, a Designer, and a
> Toolbox-to collaboratively produce diagrams compatible with standard vector
> graphics software. This modular, role-based design allows each element to be
> explicitly represented and manipulated, enabling true element-level control and
> any element can be added and modified later. To systematically evaluate the
> quality of scientific illustrations, we introduce VisBench, a benchmark with
> seven-dimensional evaluation metrics. It assesses high-information-density
> scientific illustrations from four aspects: content, layout, visual perception,
> and interaction cost. To this end, we conducted extensive ablation experiments
> to verify the rationality of our architecture and the reliability of our
> evaluation methods. Finally, we evaluated various vision-language models,
> presenting fair and credible model rankings along with detailed comparisons of
> their respective capabilities. Additionally, we isolated and quantified the
> impacts of role division, step control,and description on the quality of
> illustrations.

