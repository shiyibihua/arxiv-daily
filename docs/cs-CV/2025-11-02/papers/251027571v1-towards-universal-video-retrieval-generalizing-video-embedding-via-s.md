---
layout: default
title: Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum
---

# Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum

**arXiv**: [2510.27571v1](https://arxiv.org/abs/2510.27571) | [PDF](https://arxiv.org/pdf/2510.27571.pdf)

**ä½œè€…**: Zhuoning Guo, Mingxin Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Xiaowen Chu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€šç”¨è§†é¢‘æ£€ç´¢æ¡†æž¶ï¼Œé€šè¿‡å¤šæ¨¡æ€é‡‘å­—å¡”è¯¾ç¨‹è®­ç»ƒè§£å†³æ³›åŒ–èƒ½åŠ›ä¸è¶³é—®é¢˜**

**å…³é”®è¯**: `é€šç”¨è§†é¢‘æ£€ç´¢` `å¤šæ¨¡æ€åµŒå…¥` `è¯¾ç¨‹å­¦ä¹ ` `é›¶æ ·æœ¬æ³›åŒ–` `åŸºå‡†è®¾è®¡` `æ•°æ®åˆæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§†é¢‘æ£€ç´¢åŸºå‡†ç‹­çª„ï¼ŒæŠ‘åˆ¶å¤šç»´åº¦æ³›åŒ–èƒ½åŠ›ï¼Œç¼ºä¹è¯Šæ–­æ€§è¯„ä¼°
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡UVRBåŸºå‡†ã€åˆæˆå¤§è§„æ¨¡æ•°æ®ã€å¼•å…¥æ¨¡æ€é‡‘å­—å¡”è¯¾ç¨‹è®­ç»ƒGVEæ¨¡åž‹
3. å®žéªŒæˆ–æ•ˆæžœï¼šGVEåœ¨UVRBä¸Šå®žçŽ°é›¶æ ·æœ¬æ³›åŒ–SOTAï¼Œæ­ç¤ºæµè¡ŒåŸºå‡†é¢„æµ‹èƒ½åŠ›å·®

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The prevailing video retrieval paradigm is structurally misaligned, as narrow
> benchmarks incentivize correspondingly limited data and single-task training.
> Therefore, universal capability is suppressed due to the absence of a
> diagnostic evaluation that defines and demands multi-dimensional
> generalization. To break this cycle, we introduce a framework built on the
> co-design of evaluation, data, and modeling. First, we establish the Universal
> Video Retrieval Benchmark (UVRB), a suite of 16 datasets designed not only to
> measure performance but also to diagnose critical capability gaps across tasks
> and domains. Second, guided by UVRB's diagnostics, we introduce a scalable
> synthesis workflow that generates 1.55 million high-quality pairs to populate
> the semantic space required for universality. Finally, we devise the Modality
> Pyramid, a curriculum that trains our General Video Embedder (GVE) by
> explicitly leveraging the latent interconnections within our diverse data.
> Extensive experiments show GVE achieves state-of-the-art zero-shot
> generalization on UVRB. In particular, our analysis reveals that popular
> benchmarks are poor predictors of general ability and that partially relevant
> retrieval is a dominant but overlooked scenario. Overall, our co-designed
> framework provides a practical path to escape the limited scope and advance
> toward truly universal video retrieval.

