---
layout: default
title: Referee: Reference-aware Audiovisual Deepfake Detection
---

# Referee: Reference-aware Audiovisual Deepfake Detection

**arXiv**: [2510.27475v1](https://arxiv.org/abs/2510.27475) | [PDF](https://arxiv.org/pdf/2510.27475.pdf)

**ä½œè€…**: Hyemin Boo, Eunsang Lee, Jiyoung Lee

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRefereeæ–¹æ³•ï¼Œåˆ©ç”¨å•æ ·æœ¬å‚è€ƒæ£€æµ‹æœªçŸ¥è§†å¬æ·±åº¦ä¼ªé€ ã€‚**

**å…³é”®è¯**: `è§†å¬æ·±åº¦ä¼ªé€ æ£€æµ‹` `å‚è€ƒæ„ŸçŸ¥æ–¹æ³•` `è·¨æ¨¡æ€èº«ä»½éªŒè¯` `å•æ ·æœ¬å­¦ä¹ ` `æ³›åŒ–æ€§èƒ½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§†å¬æ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹æ³•éš¾ä»¥æ³›åŒ–åˆ°æœªè§ä¼ªé€ å†…å®¹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å‚è€ƒå†…å®¹åŒ¹é…èº«ä»½æŸ¥è¯¢ï¼Œè”åˆæŽ¨ç†è§†å¬åŒæ­¥ä¸Žèº«ä»½ä¸€è‡´æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨è·¨æ•°æ®é›†å’Œè·¨è¯­è¨€è¯„ä¼°ä¸­è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Since deepfakes generated by advanced generative models have rapidly posed
> serious threats, existing audiovisual deepfake detection approaches struggle to
> generalize to unseen forgeries. We propose a novel reference-aware audiovisual
> deepfake detection method, called Referee. Speaker-specific cues from only
> one-shot examples are leveraged to detect manipulations beyond spatiotemporal
> artifacts. By matching and aligning identity-related queries from reference and
> target content into cross-modal features, Referee jointly reasons about
> audiovisual synchrony and identity consistency. Extensive experiments on
> FakeAVCeleb, FaceForensics++, and KoDF demonstrate that Referee achieves
> state-of-the-art performance on cross-dataset and cross-language evaluation
> protocols. Experimental results highlight the importance of cross-modal
> identity verification for future deepfake detection. The code is available at
> https://github.com/ewha-mmai/referee.

