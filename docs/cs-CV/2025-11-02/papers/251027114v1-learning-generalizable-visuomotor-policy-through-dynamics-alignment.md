---
layout: default
title: Learning Generalizable Visuomotor Policy through Dynamics-Alignment
---

# Learning Generalizable Visuomotor Policy through Dynamics-Alignment

**arXiv**: [2510.27114v1](https://arxiv.org/abs/2510.27114) | [PDF](https://arxiv.org/pdf/2510.27114.pdf)

**ä½œè€…**: Dohyeok Lee, Jung Min Lee, Munkyung Kim, Seokhun Ju, Jin Woo Koo, Kyungjae Lee, Dohyeong Kim, TaeHyun Cho, Jungwoo Lee

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŠ¨æ€å¯¹é½æµåŒ¹é…ç­–ç•¥ä»¥æå‡æœºå™¨äººè§†è§‰è¿åŠ¨ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›**

**å…³é”®è¯**: `æœºå™¨äººå­¦ä¹ ` `è¡Œä¸ºå…‹éš†` `åŠ¨æ€é¢„æµ‹` `ç­–ç•¥å­¦ä¹ ` `æ³›åŒ–èƒ½åŠ›` `è§†è§‰è¿åŠ¨ç­–ç•¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è¡Œä¸ºå…‹éš†æ–¹æ³•æ³›åŒ–æ€§å·®ï¼Œå—é™äºŽä¸“å®¶æ¼”ç¤ºæ•°æ®ä¸è¶³
2. é›†æˆåŠ¨æ€é¢„æµ‹ä¸Žç­–ç•¥å­¦ä¹ ï¼Œé€šè¿‡ç›¸äº’åé¦ˆå®žçŽ°è‡ªæ ¡æ­£
3. åœ¨çœŸå®žæœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼Œæ³›åŒ–æ€§èƒ½ä¼˜äºŽåŸºçº¿ï¼Œå¯¹è§†è§‰å¹²æ‰°å’Œå…‰ç…§å˜åŒ–é²æ£’

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Behavior cloning methods for robot learning suffer from poor generalization
> due to limited data support beyond expert demonstrations. Recent approaches
> leveraging video prediction models have shown promising results by learning
> rich spatiotemporal representations from large-scale datasets. However, these
> models learn action-agnostic dynamics that cannot distinguish between different
> control inputs, limiting their utility for precise manipulation tasks and
> requiring large pretraining datasets. We propose a Dynamics-Aligned Flow
> Matching Policy (DAP) that integrates dynamics prediction into policy learning.
> Our method introduces a novel architecture where policy and dynamics models
> provide mutual corrective feedback during action generation, enabling
> self-correction and improved generalization. Empirical validation demonstrates
> generalization performance superior to baseline methods on real-world robotic
> manipulation tasks, showing particular robustness in OOD scenarios including
> visual distractions and lighting variations.

