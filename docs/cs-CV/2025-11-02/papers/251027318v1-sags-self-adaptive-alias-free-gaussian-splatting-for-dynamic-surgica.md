---
layout: default
title: SAGS: Self-Adaptive Alias-Free Gaussian Splatting for Dynamic Surgical Endoscopic Reconstruction
---

# SAGS: Self-Adaptive Alias-Free Gaussian Splatting for Dynamic Surgical Endoscopic Reconstruction

**arXiv**: [2510.27318v1](https://arxiv.org/abs/2510.27318) | [PDF](https://arxiv.org/pdf/2510.27318.pdf)

**ä½œè€…**: Wenfeng Huang, Xiangyun Liao, Yinling Qian, Hao Liu, Yongming Yang, Wenjing Jia, Qiong Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªé€‚åº”æ€§æ— æ··å é«˜æ–¯æº…å°„æ¡†æž¶ä»¥è§£å†³åŠ¨æ€å†…çª¥é•œé‡å»ºä¸­çš„æ··å å’Œä¼ªå½±é—®é¢˜**

**å…³é”®è¯**: `åŠ¨æ€å†…çª¥é•œé‡å»º` `é«˜æ–¯æº…å°„` `æ— æ··å æ¸²æŸ“` `å˜å½¢ç»„ç»‡å»ºæ¨¡` `4Då˜å½¢è§£ç å™¨` `æ‰‹æœ¯å¯è§†åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŠ¨æ€å†…çª¥é•œé‡å»ºä¸­ç»„ç»‡è¿åŠ¨å¯¼è‡´æ··å å’Œä¼ªå½±ï¼Œé™ä½Žå¯è§†åŒ–è´¨é‡
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥æ³¨æ„åŠ›é©±åŠ¨åŠ¨æ€åŠ æƒ4Då˜å½¢è§£ç å™¨ï¼Œç»“åˆ3Då¹³æ»‘å’Œ2D Mipæ»¤æ³¢å™¨
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨EndoNeRFå’ŒSCAREDåŸºå‡†ä¸Šï¼ŒPSNRã€SSIMå’ŒLPIPSæŒ‡æ ‡ä¼˜äºŽçŽ°æœ‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Surgical reconstruction of dynamic tissues from endoscopic videos is a
> crucial technology in robot-assisted surgery. The development of Neural
> Radiance Fields (NeRFs) has greatly advanced deformable tissue reconstruction,
> achieving high-quality results from video and image sequences. However,
> reconstructing deformable endoscopic scenes remains challenging due to aliasing
> and artifacts caused by tissue movement, which can significantly degrade
> visualization quality. The introduction of 3D Gaussian Splatting (3DGS) has
> improved reconstruction efficiency by enabling a faster rendering pipeline.
> Nevertheless, existing 3DGS methods often prioritize rendering speed while
> neglecting these critical issues. To address these challenges, we propose SAGS,
> a self-adaptive alias-free Gaussian splatting framework. We introduce an
> attention-driven, dynamically weighted 4D deformation decoder, leveraging 3D
> smoothing filters and 2D Mip filters to mitigate artifacts in deformable tissue
> reconstruction and better capture the fine details of tissue movement.
> Experimental results on two public benchmarks, EndoNeRF and SCARED, demonstrate
> that our method achieves superior performance in all metrics of PSNR, SSIM, and
> LPIPS compared to the state of the art while also delivering better
> visualization quality.

