---
layout: default
title: C-LEAD: Contrastive Learning for Enhanced Adversarial Defense
---

# C-LEAD: Contrastive Learning for Enhanced Adversarial Defense

**arXiv**: [2510.27249v1](https://arxiv.org/abs/2510.27249) | [PDF](https://arxiv.org/pdf/2510.27249.pdf)

**ä½œè€…**: Suklav Ghosh, Sonal Kumar, Arijit Sur

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¯¹æ¯”å­¦ä¹ çš„å¯¹æŠ—é˜²å¾¡æ–¹æ³•ä»¥å¢å¼ºæ·±åº¦ç¥ç»ç½‘ç»œé²æ£’æ€§**

**å…³é”®è¯**: `å¯¹æŠ—é˜²å¾¡` `å¯¹æ¯”å­¦ä¹ ` `æ·±åº¦ç¥ç»ç½‘ç»œ` `é²æ£’æ€§` `å›¾åƒåˆ†ç±»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ·±åº¦ç¥ç»ç½‘ç»œæ˜“å—å¯¹æŠ—æ”»å‡»å½±å“ï¼Œå¯¼è‡´è¾“å…¥å¾®å°æ‰°åŠ¨æ—¶é¢„æµ‹é”™è¯¯
2. åˆ©ç”¨å¯¹æ¯”æŸå¤±å‡½æ•°è®­ç»ƒæ¨¡å‹ï¼Œç»“åˆå¹²å‡€ä¸å¯¹æŠ—æ‰°åŠ¨å›¾åƒå­¦ä¹ é²æ£’è¡¨ç¤º
3. å®éªŒæ˜¾ç¤ºæ¨¡å‹å¯¹å¤šç§å¯¹æŠ—æ‰°åŠ¨é²æ£’æ€§æ˜¾è‘—æå‡ï¼Œç‰¹å¾æ›´å…·ä¿¡æ¯æ€§å’Œå¼¹æ€§

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deep neural networks (DNNs) have achieved remarkable success in computer
> vision tasks such as image classification, segmentation, and object detection.
> However, they are vulnerable to adversarial attacks, which can cause incorrect
> predictions with small perturbations in input images. Addressing this issue is
> crucial for deploying robust deep-learning systems. This paper presents a novel
> approach that utilizes contrastive learning for adversarial defense, a
> previously unexplored area. Our method leverages the contrastive loss function
> to enhance the robustness of classification models by training them with both
> clean and adversarially perturbed images. By optimizing the model's parameters
> alongside the perturbations, our approach enables the network to learn robust
> representations that are less susceptible to adversarial attacks. Experimental
> results show significant improvements in the model's robustness against various
> types of adversarial perturbations. This suggests that contrastive loss helps
> extract more informative and resilient features, contributing to the field of
> adversarial robustness in deep learning.

