---
layout: default
title: A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis
---

# A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.00962" target="_blank" class="toolbar-btn">arXiv: 2511.00962v1</a>
    <a href="https://arxiv.org/pdf/2511.00962.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.00962v1" 
            onclick="toggleFavorite(this, '2511.00962v1', 'A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Dongheng Lin, Mengxue Qu, Kunyang Han, Jianbo Jiao, Xiaojie Jin, Yunchao Wei

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-02

**Â§áÊ≥®**: NeurIPS 2025 poster

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://rathgrith.github.io/Unified_Frame_VAA/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Áªü‰∏ÄÊé®ÁêÜÊ°ÜÊû∂ÔºåÂÆûÁé∞Èõ∂Ê†∑Êú¨ËßÜÈ¢ëÂºÇÂ∏∏‰∫ã‰ª∂ÁöÑÊï¥‰ΩìÂàÜÊûê**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÂºÇÂ∏∏Ê£ÄÊµã` `Èõ∂Ê†∑Êú¨Â≠¶‰π†` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `ÊèêÁ§∫Â≠¶‰π†` `‰ªªÂä°Èìæ` `ÂèØËß£ÈáäÊÄß` `ËßÜÈ¢ëÁêÜËß£`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëÂºÇÂ∏∏Ê£ÄÊµãÊñπÊ≥ïÁº∫‰πèÂØπÂºÇÂ∏∏ÂéüÂõ†ÁöÑËß£ÈáäÔºå‰∏îÂèØËß£ÈáäÊÄßÊñπÊ≥ï‰æùËµñÊï∞ÊçÆÂíåÁâπÂÆö‰ªªÂä°„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Áªü‰∏ÄÊé®ÁêÜÊ°ÜÊû∂ÔºåÈÄöËøáÈìæÂºèÊµãËØïÊó∂Êé®ÁêÜËøûÊé•Êó∂Èó¥Ê£ÄÊµã„ÄÅÁ©∫Èó¥ÂÆö‰ΩçÂíåÊñáÊú¨Ëß£Èáä‰ªªÂä°„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Èõ∂Ê†∑Êú¨ËÆæÁΩÆ‰∏ãÔºåÂú®ËßÜÈ¢ëÂºÇÂ∏∏Ê£ÄÊµã„ÄÅÂÆö‰ΩçÂíåËß£Èáä‰ªªÂä°‰∏äÂùáÂèñÂæóÈ¢ÜÂÖàÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂΩìÂâçËßÜÈ¢ëÂºÇÂ∏∏Ê£ÄÊµãÁ†îÁ©∂Â§öÂ±ÄÈôê‰∫éÂ∏ßÁ∫ßÂà´ÔºåÁº∫‰πèÂØπÂºÇÂ∏∏ÂéüÂõ†ÁöÑÊ∑±ÂÖ•ÁêÜËß£ÔºåÈÄöÂ∏∏‰ªÖËæìÂá∫Â∏ßÁ∫ßÂà´ÁöÑÂºÇÂ∏∏ÂàÜÊï∞ÔºåÁº∫Â∞ëÁ©∫Èó¥ÊàñËØ≠‰πâ‰ø°ÊÅØ„ÄÇËøëÊúüÁöÑËßÜÈ¢ëÂºÇÂ∏∏ÂÆö‰ΩçÂíåÁêÜËß£ÊñπÊ≥ïËôΩÁÑ∂ÊèêÈ´ò‰∫ÜÂèØËß£ÈáäÊÄßÔºå‰ΩÜ‰ªçÁÑ∂‰æùËµñÊï∞ÊçÆÂíåÁâπÂÆö‰ªªÂä°„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁªü‰∏ÄÁöÑÊé®ÁêÜÊ°ÜÊû∂ÔºåÂº•Âêà‰∫ÜÊó∂Èó¥Ê£ÄÊµã„ÄÅÁ©∫Èó¥ÂÆö‰ΩçÂíåÊñáÊú¨Ëß£Èáä‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇËØ•ÊñπÊ≥ïÂü∫‰∫éÈìæÂºèÊµãËØïÊó∂Êé®ÁêÜËøáÁ®ãÔºå‰æùÊ¨°ËøûÊé•Ëøô‰∫õ‰ªªÂä°Ôºå‰ªéËÄåÂÆûÁé∞Êó†ÈúÄÈ¢ùÂ§ñËÆ≠ÁªÉÁöÑÊï¥‰ΩìÈõ∂Ê†∑Êú¨ÂºÇÂ∏∏ÂàÜÊûê„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåËØ•ÊñπÊ≥ïÂà©Áî®‰ªªÂä°ÂÜÖÊé®ÁêÜÊù•‰ºòÂåñÊó∂Èó¥Ê£ÄÊµãÔºåÂπ∂Âà©Áî®‰ªªÂä°Èó¥ÈìæÊé•ËøõË°åÁ©∫Èó¥ÂíåËØ≠‰πâÁêÜËß£Ôºå‰ªéËÄåÂú®ÂÆåÂÖ®Èõ∂Ê†∑Êú¨ÁöÑÊÉÖÂÜµ‰∏ãÊèêÈ´òÂèØËß£ÈáäÊÄßÂíåÊ≥õÂåñÊÄß„ÄÇÂú®Ê≤°Êúâ‰ªª‰ΩïÈ¢ùÂ§ñÊï∞ÊçÆÊàñÊ¢ØÂ∫¶ÁöÑÊÉÖÂÜµ‰∏ãÔºåËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™ËßÜÈ¢ëÂºÇÂ∏∏Ê£ÄÊµã„ÄÅÂÆö‰ΩçÂíåËß£ÈáäÂü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÈõ∂Ê†∑Êú¨ÊÄßËÉΩ„ÄÇÁªìÊûúË°®ÊòéÔºåÈÄöËøáÁ≤æÂøÉËÆæËÆ°ÁöÑÊèêÁ§∫Âíå‰ªªÂä°ÈìæÔºåÂèØ‰ª•ÈáäÊîæÂü∫Á°ÄÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ªéËÄåÂú®ÂÆåÂÖ®Èõ∂Ê†∑Êú¨ÁöÑÊÉÖÂÜµ‰∏ãÂÆûÁé∞ÂÆûÁî®‰∏îÂèØËß£ÈáäÁöÑËßÜÈ¢ëÂºÇÂ∏∏ÂàÜÊûê„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜÈ¢ëÂºÇÂ∏∏ÂàÜÊûêÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠Âú®Â∏ßÁ∫ßÂà´ÁöÑÂºÇÂ∏∏Ê£ÄÊµãÔºåÁº∫‰πèÂØπÂºÇÂ∏∏‰∫ã‰ª∂ÂéüÂõ†ÁöÑÊ∑±ÂÖ•ÁêÜËß£ÔºåÂèØËß£ÈáäÊÄßÂ∑Æ„ÄÇÂç≥‰ΩøÊòØÂºÇÂ∏∏ÂÆö‰ΩçÂíåÁêÜËß£ÊñπÊ≥ïÔºå‰πüÈ´òÂ∫¶‰æùËµñËÆ≠ÁªÉÊï∞ÊçÆÂíåÁâπÂÆö‰ªªÂä°ÔºåÊ≥õÂåñËÉΩÂäõÊúâÈôê„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÂÆûÁé∞Êó†ÈúÄÈ¢ùÂ§ñËÆ≠ÁªÉÔºåÂç≥ÂèØËøõË°åÊó∂Èó¥Ê£ÄÊµã„ÄÅÁ©∫Èó¥ÂÆö‰ΩçÂíåËØ≠‰πâËß£ÈáäÁöÑÊï¥‰ΩìËßÜÈ¢ëÂºÇÂ∏∏ÂàÜÊûêÔºåÊòØ‰∏Ä‰∏™‰∫üÂæÖËß£ÂÜ≥ÁöÑÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàÂ¶ÇCLIPÔºâÁöÑÂº∫Â§ßÊé®ÁêÜËÉΩÂäõÔºåÈÄöËøáÁ≤æÂøÉËÆæËÆ°ÁöÑÊèêÁ§∫ÔºàPromptÔºâÂíå‰ªªÂä°ÈìæÔºàTask ChainingÔºâÔºåÂ∞ÜÊó∂Èó¥Ê£ÄÊµã„ÄÅÁ©∫Èó¥ÂÆö‰ΩçÂíåÊñáÊú¨Ëß£Èáä‰∏â‰∏™‰ªªÂä°‰∏≤ËÅîËµ∑Êù•„ÄÇÈÄöËøá‰ªªÂä°Èó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®ÔºåÂÆûÁé∞ÂØπËßÜÈ¢ëÂºÇÂ∏∏‰∫ã‰ª∂ÁöÑÊï¥‰ΩìÁêÜËß£ÔºåËÄåÊó†ÈúÄÈíàÂØπÁâπÂÆöÊï∞ÊçÆÈõÜËøõË°åËÆ≠ÁªÉ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) **Êó∂Èó¥Ê£ÄÊµã**ÔºöÂà©Áî®È¢ÑËÆ≠ÁªÉÊ®°ÂûãÊèêÂèñËßÜÈ¢ëÂ∏ßÁöÑÁâπÂæÅÔºåÂπ∂ÈÄöËøáËÆæËÆ°ÁöÑPromptËøõË°åÊó∂Èó¥ÂºÇÂ∏∏Ê£ÄÊµã„ÄÇ2) **Á©∫Èó¥ÂÆö‰Ωç**ÔºöÂü∫‰∫éÊó∂Èó¥Ê£ÄÊµãÁöÑÁªìÊûúÔºåÂà©Áî®PromptÂºïÂØºÊ®°ÂûãÂÆö‰ΩçÂºÇÂ∏∏Âå∫Âüü„ÄÇ3) **ÊñáÊú¨Ëß£Èáä**ÔºöÊ†πÊçÆÊó∂Èó¥ÂíåÁ©∫Èó¥‰ø°ÊÅØÔºåÁîüÊàêÂØπÂºÇÂ∏∏‰∫ã‰ª∂ÁöÑÊñáÊú¨ÊèèËø∞„ÄÇËøô‰∏â‰∏™Èò∂ÊÆµÈÄöËøá‰ªªÂä°Èìæ‰æùÊ¨°ËøûÊé•ÔºåÂâç‰∏Ä‰∏™‰ªªÂä°ÁöÑËæìÂá∫‰Ωú‰∏∫Âêé‰∏Ä‰∏™‰ªªÂä°ÁöÑËæìÂÖ•Ôºå‰ªéËÄåÂÆûÁé∞Êï¥‰ΩìÁöÑÂºÇÂ∏∏ÂàÜÊûê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊé®ÁêÜÊ°ÜÊû∂ÔºåÈÄöËøá‰ªªÂä°ÈìæÂ∞ÜÊó∂Èó¥Ê£ÄÊµã„ÄÅÁ©∫Èó¥ÂÆö‰ΩçÂíåÊñáÊú¨Ëß£Èáä‰∏â‰∏™‰ªªÂä°Êï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÂÆûÁé∞‰∫ÜÈõ∂Ê†∑Êú¨ÁöÑÊï¥‰ΩìËßÜÈ¢ëÂºÇÂ∏∏ÂàÜÊûê„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÊó†ÈúÄ‰ªª‰ΩïÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉÊï∞ÊçÆÊàñÊ¢ØÂ∫¶ÔºåÂç≥ÂèØÂÆûÁé∞ÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Á≤æÂøÉËÆæËÆ°ÁöÑPromptÔºöÈíàÂØπÊØè‰∏™‰ªªÂä°ÔºåËÆæËÆ°‰∫ÜÁâπÂÆöÁöÑPromptÔºå‰ª•ÂºïÂØºÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÊé®ÁêÜ„ÄÇ2) ‰ªªÂä°ÈìæÔºöÈÄöËøá‰ªªÂä°ÈìæÂ∞Ü‰∏â‰∏™‰ªªÂä°‰æùÊ¨°ËøûÊé•ÔºåÂÆûÁé∞‰ªªÂä°Èó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®„ÄÇ3) Èõ∂Ê†∑Êú¨ËÆæÁΩÆÔºöÊï¥‰∏™Ê°ÜÊû∂Âú®Èõ∂Ê†∑Êú¨ËÆæÁΩÆ‰∏ãËøõË°åËØÑ‰º∞ÔºåÈ™åËØÅ‰∫ÜÂÖ∂Ê≥õÂåñËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™ËßÜÈ¢ëÂºÇÂ∏∏Ê£ÄÊµã„ÄÅÂÆö‰ΩçÂíåËß£ÈáäÂü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÈõ∂Ê†∑Êú¨ÊÄßËÉΩÔºåÊó†ÈúÄ‰ªª‰ΩïÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉÊï∞ÊçÆÊàñÊ¢ØÂ∫¶„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÈÄöËøáÁ≤æÂøÉËÆæËÆ°ÁöÑÊèêÁ§∫Âíå‰ªªÂä°ÈìæÔºåÂèØ‰ª•ÊúâÊïàÂà©Áî®È¢ÑËÆ≠ÁªÉÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂÆûÁé∞ÂÆûÁî®‰∏îÂèØËß£ÈáäÁöÑËßÜÈ¢ëÂºÇÂ∏∏ÂàÜÊûê„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫ø‰ø°ÊÅØËØ∑ÂèÇËÄÉÂéüÊñá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩÁõëÊéß„ÄÅÂ∑•‰∏öÂÆâÂÖ®„ÄÅÂåªÁñóËØäÊñ≠Á≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Êô∫ËÉΩÁõëÊéß‰∏≠ÔºåÂèØ‰ª•Ëá™Âä®Ê£ÄÊµãÂºÇÂ∏∏Ë°å‰∏∫Âπ∂ÁîüÊàêÊä•ÂëäÔºõÂú®Â∑•‰∏öÂÆâÂÖ®‰∏≠ÔºåÂèØ‰ª•Ê£ÄÊµãÁîü‰∫ßÁ∫ø‰∏äÁöÑÂºÇÂ∏∏Êìç‰ΩúÔºõÂú®ÂåªÁñóËØäÊñ≠‰∏≠ÔºåÂèØ‰ª•ËæÖÂä©ÂåªÁîüËØÜÂà´ÂåªÂ≠¶ÂΩ±ÂÉè‰∏≠ÁöÑÂºÇÂ∏∏Âå∫Âüü„ÄÇËØ•Á†îÁ©∂ÊúâÊúõÊé®Âä®ËßÜÈ¢ëÂºÇÂ∏∏ÂàÜÊûêÊäÄÊúØÂú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®ÔºåÊèêÈ´òÂÆâÂÖ®ÊÄßÂíåÊïàÁéá„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Most video-anomaly research stops at frame-wise detection, offering little insight into why an event is abnormal, typically outputting only frame-wise anomaly scores without spatial or semantic context. Recent video anomaly localization and video anomaly understanding methods improve explainability but remain data-dependent and task-specific. We propose a unified reasoning framework that bridges the gap between temporal detection, spatial localization, and textual explanation. Our approach is built upon a chained test-time reasoning process that sequentially connects these tasks, enabling holistic zero-shot anomaly analysis without any additional training. Specifically, our approach leverages intra-task reasoning to refine temporal detections and inter-task chaining for spatial and semantic understanding, yielding improved interpretability and generalization in a fully zero-shot manner. Without any additional data or gradients, our method achieves state-of-the-art zero-shot performance across multiple video anomaly detection, localization, and explanation benchmarks. The results demonstrate that careful prompt design with task-wise chaining can unlock the reasoning power of foundation models, enabling practical, interpretable video anomaly analysis in a fully zero-shot manner. Project Page: https://rathgrith.github.io/Unified_Frame_VAA/.

