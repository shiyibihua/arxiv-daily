---
layout: default
title: A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis
---

# A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis

**arXiv**: [2511.00962v1](https://arxiv.org/abs/2511.00962) | [PDF](https://arxiv.org/pdf/2511.00962.pdf)

**ä½œè€…**: Dongheng Lin, Mengxue Qu, Kunyang Han, Jianbo Jiao, Xiaojie Jin, Yunchao Wei

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-02

**å¤‡æ³¨**: NeurIPS 2025 poster

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://rathgrith.github.io/Unified_Frame_VAA/)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€æŽ¨ç†æ¡†æž¶ï¼Œå®žçŽ°é›¶æ ·æœ¬è§†é¢‘å¼‚å¸¸äº‹ä»¶çš„æ•´ä½“åˆ†æž**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è§†é¢‘å¼‚å¸¸æ£€æµ‹` `é›¶æ ·æœ¬å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡åž‹` `æç¤ºå­¦ä¹ ` `ä»»åŠ¡é“¾` `å¯è§£é‡Šæ€§` `è§†é¢‘ç†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†é¢‘å¼‚å¸¸æ£€æµ‹æ–¹æ³•ç¼ºä¹å¯¹å¼‚å¸¸åŽŸå› çš„è§£é‡Šï¼Œä¸”å¯è§£é‡Šæ€§æ–¹æ³•ä¾èµ–æ•°æ®å’Œç‰¹å®šä»»åŠ¡ã€‚
2. è®ºæ–‡æå‡ºç»Ÿä¸€æŽ¨ç†æ¡†æž¶ï¼Œé€šè¿‡é“¾å¼æµ‹è¯•æ—¶æŽ¨ç†è¿žæŽ¥æ—¶é—´æ£€æµ‹ã€ç©ºé—´å®šä½å’Œæ–‡æœ¬è§£é‡Šä»»åŠ¡ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹ï¼Œåœ¨è§†é¢‘å¼‚å¸¸æ£€æµ‹ã€å®šä½å’Œè§£é‡Šä»»åŠ¡ä¸Šå‡å–å¾—é¢†å…ˆæ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰è§†é¢‘å¼‚å¸¸æ£€æµ‹ç ”ç©¶å¤šå±€é™äºŽå¸§çº§åˆ«ï¼Œç¼ºä¹å¯¹å¼‚å¸¸åŽŸå› çš„æ·±å…¥ç†è§£ï¼Œé€šå¸¸ä»…è¾“å‡ºå¸§çº§åˆ«çš„å¼‚å¸¸åˆ†æ•°ï¼Œç¼ºå°‘ç©ºé—´æˆ–è¯­ä¹‰ä¿¡æ¯ã€‚è¿‘æœŸçš„è§†é¢‘å¼‚å¸¸å®šä½å’Œç†è§£æ–¹æ³•è™½ç„¶æé«˜äº†å¯è§£é‡Šæ€§ï¼Œä½†ä»ç„¶ä¾èµ–æ•°æ®å’Œç‰¹å®šä»»åŠ¡ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„æŽ¨ç†æ¡†æž¶ï¼Œå¼¥åˆäº†æ—¶é—´æ£€æµ‹ã€ç©ºé—´å®šä½å’Œæ–‡æœ¬è§£é‡Šä¹‹é—´çš„å·®è·ã€‚è¯¥æ–¹æ³•åŸºäºŽé“¾å¼æµ‹è¯•æ—¶æŽ¨ç†è¿‡ç¨‹ï¼Œä¾æ¬¡è¿žæŽ¥è¿™äº›ä»»åŠ¡ï¼Œä»Žè€Œå®žçŽ°æ— éœ€é¢å¤–è®­ç»ƒçš„æ•´ä½“é›¶æ ·æœ¬å¼‚å¸¸åˆ†æžã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ä»»åŠ¡å†…æŽ¨ç†æ¥ä¼˜åŒ–æ—¶é—´æ£€æµ‹ï¼Œå¹¶åˆ©ç”¨ä»»åŠ¡é—´é“¾æŽ¥è¿›è¡Œç©ºé—´å’Œè¯­ä¹‰ç†è§£ï¼Œä»Žè€Œåœ¨å®Œå…¨é›¶æ ·æœ¬çš„æƒ…å†µä¸‹æé«˜å¯è§£é‡Šæ€§å’Œæ³›åŒ–æ€§ã€‚åœ¨æ²¡æœ‰ä»»ä½•é¢å¤–æ•°æ®æˆ–æ¢¯åº¦çš„æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªè§†é¢‘å¼‚å¸¸æ£€æµ‹ã€å®šä½å’Œè§£é‡ŠåŸºå‡†æµ‹è¯•ä¸­å®žçŽ°äº†æœ€å…ˆè¿›çš„é›¶æ ·æœ¬æ€§èƒ½ã€‚ç»“æžœè¡¨æ˜Žï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºå’Œä»»åŠ¡é“¾ï¼Œå¯ä»¥é‡Šæ”¾åŸºç¡€æ¨¡åž‹çš„æŽ¨ç†èƒ½åŠ›ï¼Œä»Žè€Œåœ¨å®Œå…¨é›¶æ ·æœ¬çš„æƒ…å†µä¸‹å®žçŽ°å®žç”¨ä¸”å¯è§£é‡Šçš„è§†é¢‘å¼‚å¸¸åˆ†æžã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰è§†é¢‘å¼‚å¸¸åˆ†æžæ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å¸§çº§åˆ«çš„å¼‚å¸¸æ£€æµ‹ï¼Œç¼ºä¹å¯¹å¼‚å¸¸äº‹ä»¶åŽŸå› çš„æ·±å…¥ç†è§£ï¼Œå¯è§£é‡Šæ€§å·®ã€‚å³ä½¿æ˜¯å¼‚å¸¸å®šä½å’Œç†è§£æ–¹æ³•ï¼Œä¹Ÿé«˜åº¦ä¾èµ–è®­ç»ƒæ•°æ®å’Œç‰¹å®šä»»åŠ¡ï¼Œæ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚å› æ­¤ï¼Œå¦‚ä½•å®žçŽ°æ— éœ€é¢å¤–è®­ç»ƒï¼Œå³å¯è¿›è¡Œæ—¶é—´æ£€æµ‹ã€ç©ºé—´å®šä½å’Œè¯­ä¹‰è§£é‡Šçš„æ•´ä½“è§†é¢‘å¼‚å¸¸åˆ†æžï¼Œæ˜¯ä¸€ä¸ªäºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡åž‹ï¼ˆå¦‚CLIPï¼‰çš„å¼ºå¤§æŽ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºï¼ˆPromptï¼‰å’Œä»»åŠ¡é“¾ï¼ˆTask Chainingï¼‰ï¼Œå°†æ—¶é—´æ£€æµ‹ã€ç©ºé—´å®šä½å’Œæ–‡æœ¬è§£é‡Šä¸‰ä¸ªä»»åŠ¡ä¸²è”èµ·æ¥ã€‚é€šè¿‡ä»»åŠ¡é—´çš„ç›¸äº’ä½œç”¨ï¼Œå®žçŽ°å¯¹è§†é¢‘å¼‚å¸¸äº‹ä»¶çš„æ•´ä½“ç†è§£ï¼Œè€Œæ— éœ€é’ˆå¯¹ç‰¹å®šæ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ¡†æž¶åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1) **æ—¶é—´æ£€æµ‹**ï¼šåˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹æå–è§†é¢‘å¸§çš„ç‰¹å¾ï¼Œå¹¶é€šè¿‡è®¾è®¡çš„Promptè¿›è¡Œæ—¶é—´å¼‚å¸¸æ£€æµ‹ã€‚2) **ç©ºé—´å®šä½**ï¼šåŸºäºŽæ—¶é—´æ£€æµ‹çš„ç»“æžœï¼Œåˆ©ç”¨Promptå¼•å¯¼æ¨¡åž‹å®šä½å¼‚å¸¸åŒºåŸŸã€‚3) **æ–‡æœ¬è§£é‡Š**ï¼šæ ¹æ®æ—¶é—´å’Œç©ºé—´ä¿¡æ¯ï¼Œç”Ÿæˆå¯¹å¼‚å¸¸äº‹ä»¶çš„æ–‡æœ¬æè¿°ã€‚è¿™ä¸‰ä¸ªé˜¶æ®µé€šè¿‡ä»»åŠ¡é“¾ä¾æ¬¡è¿žæŽ¥ï¼Œå‰ä¸€ä¸ªä»»åŠ¡çš„è¾“å‡ºä½œä¸ºåŽä¸€ä¸ªä»»åŠ¡çš„è¾“å…¥ï¼Œä»Žè€Œå®žçŽ°æ•´ä½“çš„å¼‚å¸¸åˆ†æžã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æŽ¨ç†æ¡†æž¶ï¼Œé€šè¿‡ä»»åŠ¡é“¾å°†æ—¶é—´æ£€æµ‹ã€ç©ºé—´å®šä½å’Œæ–‡æœ¬è§£é‡Šä¸‰ä¸ªä»»åŠ¡æ•´åˆåœ¨ä¸€èµ·ï¼Œå®žçŽ°äº†é›¶æ ·æœ¬çš„æ•´ä½“è§†é¢‘å¼‚å¸¸åˆ†æžã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ— éœ€ä»»ä½•é¢å¤–çš„è®­ç»ƒæ•°æ®æˆ–æ¢¯åº¦ï¼Œå³å¯å®žçŽ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç²¾å¿ƒè®¾è®¡çš„Promptï¼šé’ˆå¯¹æ¯ä¸ªä»»åŠ¡ï¼Œè®¾è®¡äº†ç‰¹å®šçš„Promptï¼Œä»¥å¼•å¯¼é¢„è®­ç»ƒæ¨¡åž‹è¿›è¡ŒæŽ¨ç†ã€‚2) ä»»åŠ¡é“¾ï¼šé€šè¿‡ä»»åŠ¡é“¾å°†ä¸‰ä¸ªä»»åŠ¡ä¾æ¬¡è¿žæŽ¥ï¼Œå®žçŽ°ä»»åŠ¡é—´çš„ç›¸äº’ä½œç”¨ã€‚3) é›¶æ ·æœ¬è®¾ç½®ï¼šæ•´ä¸ªæ¡†æž¶åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹è¿›è¡Œè¯„ä¼°ï¼ŒéªŒè¯äº†å…¶æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨å¤šä¸ªè§†é¢‘å¼‚å¸¸æ£€æµ‹ã€å®šä½å’Œè§£é‡ŠåŸºå‡†æµ‹è¯•ä¸­å®žçŽ°äº†æœ€å…ˆè¿›çš„é›¶æ ·æœ¬æ€§èƒ½ï¼Œæ— éœ€ä»»ä½•é¢å¤–çš„è®­ç»ƒæ•°æ®æˆ–æ¢¯åº¦ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºå’Œä»»åŠ¡é“¾ï¼Œå¯ä»¥æœ‰æ•ˆåˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹çš„æŽ¨ç†èƒ½åŠ›ï¼Œå®žçŽ°å®žç”¨ä¸”å¯è§£é‡Šçš„è§†é¢‘å¼‚å¸¸åˆ†æžã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿ä¿¡æ¯è¯·å‚è€ƒåŽŸæ–‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæ™ºèƒ½ç›‘æŽ§ã€å·¥ä¸šå®‰å…¨ã€åŒ»ç–—è¯Šæ–­ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½ç›‘æŽ§ä¸­ï¼Œå¯ä»¥è‡ªåŠ¨æ£€æµ‹å¼‚å¸¸è¡Œä¸ºå¹¶ç”ŸæˆæŠ¥å‘Šï¼›åœ¨å·¥ä¸šå®‰å…¨ä¸­ï¼Œå¯ä»¥æ£€æµ‹ç”Ÿäº§çº¿ä¸Šçš„å¼‚å¸¸æ“ä½œï¼›åœ¨åŒ»ç–—è¯Šæ–­ä¸­ï¼Œå¯ä»¥è¾…åŠ©åŒ»ç”Ÿè¯†åˆ«åŒ»å­¦å½±åƒä¸­çš„å¼‚å¸¸åŒºåŸŸã€‚è¯¥ç ”ç©¶æœ‰æœ›æŽ¨åŠ¨è§†é¢‘å¼‚å¸¸åˆ†æžæŠ€æœ¯åœ¨å®žé™…åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œæé«˜å®‰å…¨æ€§å’Œæ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Most video-anomaly research stops at frame-wise detection, offering little insight into why an event is abnormal, typically outputting only frame-wise anomaly scores without spatial or semantic context. Recent video anomaly localization and video anomaly understanding methods improve explainability but remain data-dependent and task-specific. We propose a unified reasoning framework that bridges the gap between temporal detection, spatial localization, and textual explanation. Our approach is built upon a chained test-time reasoning process that sequentially connects these tasks, enabling holistic zero-shot anomaly analysis without any additional training. Specifically, our approach leverages intra-task reasoning to refine temporal detections and inter-task chaining for spatial and semantic understanding, yielding improved interpretability and generalization in a fully zero-shot manner. Without any additional data or gradients, our method achieves state-of-the-art zero-shot performance across multiple video anomaly detection, localization, and explanation benchmarks. The results demonstrate that careful prompt design with task-wise chaining can unlock the reasoning power of foundation models, enabling practical, interpretable video anomaly analysis in a fully zero-shot manner. Project Page: https://rathgrith.github.io/Unified_Frame_VAA/.

