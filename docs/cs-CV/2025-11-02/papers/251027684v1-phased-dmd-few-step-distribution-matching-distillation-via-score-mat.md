---
layout: default
title: Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals
---

# Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals

**arXiv**: [2510.27684v1](https://arxiv.org/abs/2510.27684) | [PDF](https://arxiv.org/pdf/2510.27684.pdf)

**ä½œè€…**: Xiangyu Fan, Zesong Qiu, Zhuguanyu Wu, Fanzhou Wang, Zhiqian Lin, Tianxiang Ren, Dahua Lin, Ruihao Gong, Lei Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPhased DMDå¤šæ­¥è’¸é¦æ¡†æž¶ï¼Œé€šè¿‡å­åŒºé—´åˆ†æ•°åŒ¹é…è§£å†³å¤æ‚ç”Ÿæˆä»»åŠ¡ä¸­çš„æ¨¡åž‹å®¹é‡é™åˆ¶é—®é¢˜ã€‚**

**å…³é”®è¯**: `åˆ†å¸ƒåŒ¹é…è’¸é¦` `å¤šæ­¥è’¸é¦` `åˆ†æ•°åŒ¹é…` `æ¨¡åž‹å®¹é‡` `ç”Ÿæˆå¤šæ ·æ€§` `SNRå­åŒºé—´`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¸€æ­¥è’¸é¦æ¨¡åž‹åœ¨å¤æ‚ç”Ÿæˆä»»åŠ¡ä¸­æ€§èƒ½ä¸è¶³ï¼Œå¤šæ­¥è’¸é¦å­˜åœ¨å†…å­˜å’Œè®¡ç®—æ•ˆçŽ‡é—®é¢˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†SNRèŒƒå›´åˆ’åˆ†ä¸ºå­åŒºé—´ï¼Œç»“åˆMoEè¿›è¡Œæ¸è¿›åˆ†å¸ƒåŒ¹é…å’Œåˆ†æ•°åŒ¹é…ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨å›¾åƒå’Œè§†é¢‘ç”Ÿæˆæ¨¡åž‹è’¸é¦ä¸­ï¼Œä¼˜äºŽDMDï¼Œä¿æŒè¾“å‡ºå¤šæ ·æ€§å’Œå…³é”®ç”Ÿæˆèƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Distribution Matching Distillation (DMD) distills score-based generative
> models into efficient one-step generators, without requiring a one-to-one
> correspondence with the sampling trajectories of their teachers. However,
> limited model capacity causes one-step distilled models underperform on complex
> generative tasks, e.g., synthesizing intricate object motions in text-to-video
> generation. Directly extending DMD to multi-step distillation increases memory
> usage and computational depth, leading to instability and reduced efficiency.
> While prior works propose stochastic gradient truncation as a potential
> solution, we observe that it substantially reduces the generation diversity of
> multi-step distilled models, bringing it down to the level of their one-step
> counterparts. To address these limitations, we propose Phased DMD, a multi-step
> distillation framework that bridges the idea of phase-wise distillation with
> Mixture-of-Experts (MoE), reducing learning difficulty while enhancing model
> capacity. Phased DMD is built upon two key ideas: progressive distribution
> matching and score matching within subintervals. First, our model divides the
> SNR range into subintervals, progressively refining the model to higher SNR
> levels, to better capture complex distributions. Next, to ensure the training
> objective within each subinterval is accurate, we have conducted rigorous
> mathematical derivations. We validate Phased DMD by distilling state-of-the-art
> image and video generation models, including Qwen-Image (20B parameters) and
> Wan2.2 (28B parameters). Experimental results demonstrate that Phased DMD
> preserves output diversity better than DMD while retaining key generative
> capabilities. We will release our code and models.

