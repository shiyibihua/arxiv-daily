---
layout: default
title: PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting
---

# PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting

**arXiv**: [2510.27680v1](https://arxiv.org/abs/2510.27680) | [PDF](https://arxiv.org/pdf/2510.27680.pdf)

**ä½œè€…**: Danyal Maqbool, Changhee Lee, Zachary Huemann, Samuel D. Church, Matthew E. Larson, Scott B. Perlman, Tomas A. Romero, Joshua D. Warner, Meghan Lubner, Xin Tie, Jameson Merkow, Junjie Hu, Steve Y. Cho, Tyler J. Bradshaw

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPETAR-4Bæ¨¡åž‹ï¼Œç»“åˆPET/CTä¸Žç—…ç¶è½®å»“ï¼Œç”Ÿæˆå±€éƒ¨åŒ–PETè‡ªåŠ¨æŠ¥å‘Šã€‚**

**å…³é”®è¯**: `3DåŒ»å­¦å½±åƒ` `è§†è§‰è¯­è¨€æ¨¡åž‹` `PET/CTæŠ¥å‘Šç”Ÿæˆ` `ç—…ç¶åˆ†å‰²` `å¤šæ¨¡æ€æŽ¨ç†` `è‡ªåŠ¨åŒ–è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼š3D PET/CTæ•°æ®å¤§ã€ç—…ç¶å°ä¸”åˆ†æ•£ï¼ŒæŠ¥å‘Šå†—é•¿ï¼ŒçŽ°æœ‰è§†è§‰è¯­è¨€æ¨¡åž‹å¤šé™äºŽ2Dã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºå¤§è§„æ¨¡æ•°æ®é›†ï¼Œé›†æˆPETã€CTå’Œç—…ç¶è½®å»“ï¼Œå®žçŽ°ç©ºé—´æŽ¥åœ°æŠ¥å‘Šç”Ÿæˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè‡ªåŠ¨å’Œäººå·¥è¯„ä¼°æ˜¾ç¤ºï¼ŒPETARæ˜¾è‘—æå‡æŠ¥å‘Šè´¨é‡ï¼ŒæŽ¨è¿›3DåŒ»å­¦è§†è§‰è¯­è¨€ç†è§£ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in vision-language models (VLMs) have enabled impressive
> multimodal reasoning, yet most medical applications remain limited to 2D
> imaging. In this work, we extend VLMs to 3D positron emission tomography and
> computed tomography (PET/CT), a domain characterized by large volumetric data,
> small and dispersed lesions, and lengthy radiology reports. We introduce a
> large-scale dataset comprising over 11,000 lesion-level descriptions paired
> with 3D segmentations from more than 5,000 PET/CT exams, extracted via a hybrid
> rule-based and large language model (LLM) pipeline. Building upon this dataset,
> we propose PETAR-4B, a 3D mask-aware vision-language model that integrates PET,
> CT, and lesion contours for spatially grounded report generation. PETAR bridges
> global contextual reasoning with fine-grained lesion awareness, producing
> clinically coherent and localized findings. Comprehensive automated and human
> evaluations demonstrate that PETAR substantially improves PET/CT report
> generation quality, advancing 3D medical vision-language understanding.

