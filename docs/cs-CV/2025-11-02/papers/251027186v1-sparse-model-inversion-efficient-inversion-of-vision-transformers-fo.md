---
layout: default
title: Sparse Model Inversion: Efficient Inversion of Vision Transformers for Data-Free Applications
---

# Sparse Model Inversion: Efficient Inversion of Vision Transformers for Data-Free Applications

**arXiv**: [2510.27186v1](https://arxiv.org/abs/2510.27186) | [PDF](https://arxiv.org/pdf/2510.27186.pdf)

**ä½œè€…**: Zixuan Hu, Yongxian Wei, Li Shen, Zhenyi Wang, Lei Li, Chun Yuan, Dacheng Tao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç¨€ç–æ¨¡åž‹åæ¼”ä»¥é«˜æ•ˆåæ¼”è§†è§‰å˜æ¢å™¨ï¼Œç”¨äºŽæ•°æ®ç¼ºå¤±åº”ç”¨**

**å…³é”®è¯**: `æ¨¡åž‹åæ¼”` `è§†è§‰å˜æ¢å™¨` `ç¨€ç–ä¼˜åŒ–` `æ•°æ®ç¼ºå¤±åº”ç”¨` `é«˜æ•ˆè®¡ç®—`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¯†é›†åæ¼”æ–¹æ³•æ•ˆçŽ‡ä½Žï¼Œå› åæ¼”å™ªå£°èƒŒæ™¯å’Œè™šå‡ç›¸å…³æ€§
2. é€‰æ‹©æ€§åæ¼”è¯­ä¹‰å‰æ™¯ï¼Œé¿å…èƒŒæ™¯å’Œè™šå‡ç›¸å…³ï¼Œæ— éœ€ä¿®æ”¹åŽŸæŸå¤±å‡½æ•°
3. å®žéªŒæ˜¾ç¤ºåŠ é€Ÿè¾¾3.79å€ï¼Œä¿æŒæˆ–æå‡æ•°æ®ç¼ºå¤±é‡åŒ–å’ŒçŸ¥è¯†è¿ç§»æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Model inversion, which aims to reconstruct the original training data from
> pre-trained discriminative models, is especially useful when the original
> training data is unavailable due to privacy, usage rights, or size constraints.
> However, existing dense inversion methods attempt to reconstruct the entire
> image area, making them extremely inefficient when inverting high-resolution
> images from large-scale Vision Transformers (ViTs). We further identify two
> underlying causes of this inefficiency: the redundant inversion of noisy
> backgrounds and the unintended inversion of spurious correlations--a phenomenon
> we term "hallucination" in model inversion. To address these limitations, we
> propose a novel sparse model inversion strategy, as a plug-and-play extension
> to speed up existing dense inversion methods with no need for modifying their
> original loss functions. Specifically, we selectively invert semantic
> foregrounds while stopping the inversion of noisy backgrounds and potential
> spurious correlations. Through both theoretical and empirical studies, we
> validate the efficacy of our approach in achieving significant inversion
> acceleration (up to 3.79 faster) while maintaining comparable or even enhanced
> downstream performance in data-free model quantization and data-free knowledge
> transfer. Code is available at https://github.com/Egg-Hu/SMI.

