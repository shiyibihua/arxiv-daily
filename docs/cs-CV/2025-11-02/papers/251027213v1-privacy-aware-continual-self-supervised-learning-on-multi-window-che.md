---
layout: default
title: Privacy-Aware Continual Self-Supervised Learning on Multi-Window Chest Computed Tomography for Domain-Shift Robustness
---

# Privacy-Aware Continual Self-Supervised Learning on Multi-Window Chest Computed Tomography for Domain-Shift Robustness

**arXiv**: [2510.27213v1](https://arxiv.org/abs/2510.27213) | [PDF](https://arxiv.org/pdf/2510.27213.pdf)

**ä½œè€…**: Ren Tasai, Guang Li, Ren Togo, Takahiro Ogawa, Kenji Hirata, Minghui Tang, Takaaki Yoshimura, Hiroyuki Sugimori, Noriko Nishioka, Yukie Shimizu, Kohsuke Kudo, Miki Haseyama

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéšç§æ„ŸçŸ¥æŒç»­è‡ªç›‘ç£å­¦ä¹ æ¡†æž¶ï¼Œä»¥å¢žå¼ºå¤šçª—å£èƒ¸éƒ¨CTçš„åŸŸåç§»é²æ£’æ€§ã€‚**

**å…³é”®è¯**: `æŒç»­è‡ªç›‘ç£å­¦ä¹ ` `åŸŸåç§»é²æ£’æ€§` `éšç§ä¿æŠ¤` `ç‰¹å¾è’¸é¦` `èƒ¸éƒ¨CTå›¾åƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŒ»ç–—å›¾åƒè¯Šæ–­ä¸­åŸŸåç§»å’Œæ•°æ®éšç§é™åˆ¶æ¨¡åž‹æ³›åŒ–èƒ½åŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆæ½œåœ¨å›žæ”¾å’Œç‰¹å¾è’¸é¦ï¼Œç¼“è§£ç¾éš¾æ€§é—å¿˜å¹¶ä¿æŠ¤éšç§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨èƒ¸éƒ¨CTå¤šçª—å£è®¾ç½®ä¸‹éªŒè¯ï¼Œæ€§èƒ½ä¼˜äºŽå…¶ä»–æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We propose a novel continual self-supervised learning (CSSL) framework for
> simultaneously learning diverse features from multi-window-obtained chest
> computed tomography (CT) images and ensuring data privacy. Achieving a robust
> and highly generalizable model in medical image diagnosis is challenging,
> mainly because of issues, such as the scarcity of large-scale, accurately
> annotated datasets and domain shifts inherent to dynamic healthcare
> environments. Specifically, in chest CT, these domain shifts often arise from
> differences in window settings, which are optimized for distinct clinical
> purposes. Previous CSSL frameworks often mitigated domain shift by reusing past
> data, a typically impractical approach owing to privacy constraints. Our
> approach addresses these challenges by effectively capturing the relationship
> between previously learned knowledge and new information across different
> training stages through continual pretraining on unlabeled images.
> Specifically, by incorporating a latent replay-based mechanism into CSSL, our
> method mitigates catastrophic forgetting due to domain shifts during continual
> pretraining while ensuring data privacy. Additionally, we introduce a feature
> distillation technique that integrates Wasserstein distance-based knowledge
> distillation (WKD) and batch-knowledge ensemble (BKE), enhancing the ability of
> the model to learn meaningful, domain-shift-robust representations. Finally, we
> validate our approach using chest CT images obtained across two different
> window settings, demonstrating superior performance compared with other
> approaches.

