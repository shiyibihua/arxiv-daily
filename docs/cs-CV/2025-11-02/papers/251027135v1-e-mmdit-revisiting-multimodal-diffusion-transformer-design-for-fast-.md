---
layout: default
title: E-MMDiT: Revisiting Multimodal Diffusion Transformer Design for Fast Image Synthesis under Limited Resources
---

# E-MMDiT: Revisiting Multimodal Diffusion Transformer Design for Fast Image Synthesis under Limited Resources

**arXiv**: [2510.27135v1](https://arxiv.org/abs/2510.27135) | [PDF](https://arxiv.org/pdf/2510.27135.pdf)

**ä½œè€…**: Tong Shen, Jingai Yu, Dong Zhou, Dong Li, Emad Barsoum

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºE-MMDiTä»¥åœ¨æœ‰é™èµ„æºä¸‹å®žçŽ°å¿«é€Ÿå›¾åƒåˆæˆ**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ‰©æ•£æ¨¡åž‹` `ä»¤ç‰ŒåŽ‹ç¼©` `è½»é‡çº§æž¶æž„` `å¿«é€Ÿå›¾åƒåˆæˆ` `æœ‰é™èµ„æºè®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‰©æ•£æ¨¡åž‹è®­ç»ƒèµ„æºéœ€æ±‚é«˜ã€å»¶è¿Ÿå¤§ï¼Œéš¾ä»¥åœ¨æœ‰é™è®¡ç®—æ¡ä»¶ä¸‹éƒ¨ç½²ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä»¤ç‰ŒåŽ‹ç¼©ã€ä½ç½®å¼ºåŒ–å’Œäº¤æ›¿å­åŒºåŸŸæ³¨æ„åŠ›ï¼Œé™ä½Žè®¡ç®—æˆæœ¬ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨512pxç”Ÿæˆä»»åŠ¡ä¸­ï¼Œä½¿ç”¨25Mæ•°æ®è®­ç»ƒ1.5å¤©ï¼ŒGenEvalå¾—åˆ†0.66ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Diffusion models have shown strong capabilities in generating high-quality
> images from text prompts. However, these models often require large-scale
> training data and significant computational resources to train, or suffer from
> heavy structure with high latency. To this end, we propose Efficient Multimodal
> Diffusion Transformer (E-MMDiT), an efficient and lightweight multimodal
> diffusion model with only 304M parameters for fast image synthesis requiring
> low training resources. We provide an easily reproducible baseline with
> competitive results. Our model for 512px generation, trained with only 25M
> public data in 1.5 days on a single node of 8 AMD MI300X GPUs, achieves 0.66 on
> GenEval and easily reaches to 0.72 with some post-training techniques such as
> GRPO. Our design philosophy centers on token reduction as the computational
> cost scales significantly with the token count. We adopt a highly compressive
> visual tokenizer to produce a more compact representation and propose a novel
> multi-path compression module for further compression of tokens. To enhance our
> design, we introduce Position Reinforcement, which strengthens positional
> information to maintain spatial coherence, and Alternating Subregion Attention
> (ASA), which performs attention within subregions to further reduce
> computational cost. In addition, we propose AdaLN-affine, an efficient
> lightweight module for computing modulation parameters in transformer blocks.
> Our code is available at https://github.com/AMD-AGI/Nitro-E and we hope E-MMDiT
> serves as a strong and practical baseline for future research and contributes
> to democratization of generative AI models.

