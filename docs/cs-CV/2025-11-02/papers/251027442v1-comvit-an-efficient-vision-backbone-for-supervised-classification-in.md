---
layout: default
title: CoMViT: An Efficient Vision Backbone for Supervised Classification in Medical Imaging
---

# CoMViT: An Efficient Vision Backbone for Supervised Classification in Medical Imaging

**arXiv**: [2510.27442v1](https://arxiv.org/abs/2510.27442) | [PDF](https://arxiv.org/pdf/2510.27442.pdf)

**ä½œè€…**: Aon Safdar, Mohamed Saadeldin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoMViTä»¥è§£å†³åŒ»å­¦å½±åƒä¸­ViTè®¡ç®—é«˜å’Œè¿‡æ‹Ÿåˆé—®é¢˜**

**å…³é”®è¯**: `åŒ»å­¦å½±åƒåˆ†ç±»` `è§†è§‰Transformer` `è½»é‡æ¨¡åž‹` `æ³›åŒ–èƒ½åŠ›` `è®¡ç®—æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ViTåœ¨åŒ»å­¦å½±åƒä¸­è®¡ç®—éœ€æ±‚é«˜ä¸”æ˜“åœ¨å°æ•°æ®é›†è¿‡æ‹Ÿåˆ
2. é›†æˆå·ç§¯åˆ†è¯å™¨ã€å¯¹è§’æŽ©ç ç­‰æŠ€æœ¯ä¼˜åŒ–æž¶æž„
3. åœ¨12ä¸ªMedMNISTæ•°æ®é›†ä¸Šæ€§èƒ½ç¨³å¥ï¼Œå‚æ•°ä»…çº¦4.5M

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision Transformers (ViTs) have demonstrated strong potential in medical
> imaging; however, their high computational demands and tendency to overfit on
> small datasets limit their applicability in real-world clinical scenarios. In
> this paper, we present CoMViT, a compact and generalizable Vision Transformer
> architecture optimized for resource-constrained medical image analysis. CoMViT
> integrates a convolutional tokenizer, diagonal masking, dynamic temperature
> scaling, and pooling-based sequence aggregation to improve performance and
> generalization. Through systematic architectural optimization, CoMViT achieves
> robust performance across twelve MedMNIST datasets while maintaining a
> lightweight design with only ~4.5M parameters. It matches or outperforms deeper
> CNN and ViT variants, offering up to 5-20x parameter reduction without
> sacrificing accuracy. Qualitative Grad-CAM analyses show that CoMViT
> consistently attends to clinically relevant regions despite its compact size.
> These results highlight the potential of principled ViT redesign for developing
> efficient and interpretable models in low-resource medical imaging settings.

