---
layout: default
title: Mitigating Semantic Collapse in Partially Relevant Video Retrieval
---

# Mitigating Semantic Collapse in Partially Relevant Video Retrieval

**arXiv**: [2510.27432v1](https://arxiv.org/abs/2510.27432) | [PDF](https://arxiv.org/pdf/2510.27432.pdf)

**ä½œè€…**: WonJun Moon, MinSeok Jung, Gilhan Park, Tae-Young Kim, Cheol-Ho Cho, Woojin Jun, Jae-Pil Heo

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–‡æœ¬ç›¸å…³ä¿ç•™å­¦ä¹ å’Œè·¨åˆ†æ”¯è§†é¢‘å¯¹é½æ–¹æ³•ï¼Œä»¥ç¼“è§£éƒ¨åˆ†ç›¸å…³è§†é¢‘æ£€ç´¢ä¸­çš„è¯­ä¹‰åç¼©é—®é¢˜ã€‚**

**å…³é”®è¯**: `éƒ¨åˆ†ç›¸å…³è§†é¢‘æ£€ç´¢` `è¯­ä¹‰åç¼©` `æ–‡æœ¬ç›¸å…³ä¿ç•™å­¦ä¹ ` `è·¨åˆ†æ”¯è§†é¢‘å¯¹é½` `å±‚æ¬¡è§†é¢‘è¡¨ç¤º` `å¯¹æ¯”å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•å¿½ç•¥è§†é¢‘å†…å’Œè·¨è§†é¢‘çš„è¯­ä¹‰å˜åŒ–ï¼Œå¯¼è‡´åµŒå…¥ç©ºé—´è¯­ä¹‰åç¼©ï¼Œé™åˆ¶æ£€ç´¢æ€§èƒ½ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥æ–‡æœ¬ç›¸å…³ä¿ç•™å­¦ä¹ ä¿æŒæŸ¥è¯¢è¯­ä¹‰å…³ç³»ï¼Œå¹¶ä½¿ç”¨è·¨åˆ†æ”¯è§†é¢‘å¯¹é½è§£è€¦å±‚æ¬¡è§†é¢‘è¡¨ç¤ºã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨PRVRåŸºå‡†æµ‹è¯•ä¸­ï¼Œæ¡†æž¶æœ‰æ•ˆé˜²æ­¢è¯­ä¹‰åç¼©ï¼Œæ˜¾è‘—æå‡æ£€ç´¢å‡†ç¡®çŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Partially Relevant Video Retrieval (PRVR) seeks videos where only part of the
> content matches a text query. Existing methods treat every annotated text-video
> pair as a positive and all others as negatives, ignoring the rich semantic
> variation both within a single video and across different videos. Consequently,
> embeddings of both queries and their corresponding video-clip segments for
> distinct events within the same video collapse together, while embeddings of
> semantically similar queries and segments from different videos are driven
> apart. This limits retrieval performance when videos contain multiple, diverse
> events. This paper addresses the aforementioned problems, termed as semantic
> collapse, in both the text and video embedding spaces. We first introduce Text
> Correlation Preservation Learning, which preserves the semantic relationships
> encoded by the foundation model across text queries. To address collapse in
> video embeddings, we propose Cross-Branch Video Alignment (CBVA), a contrastive
> alignment method that disentangles hierarchical video representations across
> temporal scales. Subsequently, we introduce order-preserving token merging and
> adaptive CBVA to enhance alignment by producing video segments that are
> internally coherent yet mutually distinctive. Extensive experiments on PRVR
> benchmarks demonstrate that our framework effectively prevents semantic
> collapse and substantially improves retrieval accuracy.

