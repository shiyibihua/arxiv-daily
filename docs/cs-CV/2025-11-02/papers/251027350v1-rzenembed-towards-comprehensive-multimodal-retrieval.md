---
layout: default
title: RzenEmbed: Towards Comprehensive Multimodal Retrieval
---

# RzenEmbed: Towards Comprehensive Multimodal Retrieval

**arXiv**: [2510.27350v1](https://arxiv.org/abs/2510.27350) | [PDF](https://arxiv.org/pdf/2510.27350.pdf)

**ä½œè€…**: Weijian Jian, Yajun Zhang, Dawei Liang, Chunyu Xie, Yixiao He, Dawei Leng, Yuhui Yin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRzenEmbedç»Ÿä¸€æ¡†æž¶ä»¥è§£å†³å¤šæ¨¡æ€æ£€ç´¢ä¸­è§†é¢‘å’Œè§†è§‰æ–‡æ¡£æ”¯æŒä¸è¶³çš„é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ£€ç´¢` `ç»Ÿä¸€åµŒå…¥å­¦ä¹ ` `ä¸¤é˜¶æ®µè®­ç»ƒ` `æ”¹è¿›InfoNCEæŸå¤±` `è§†é¢‘æ£€ç´¢` `è§†è§‰æ–‡æ¡£æ£€ç´¢`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰CLIPæ¡†æž¶ä¸»è¦é’ˆå¯¹è‡ªç„¶å›¾åƒï¼Œç¼ºä¹å¯¹è§†é¢‘å’Œè§†è§‰æ–‡æ¡£ç­‰æ¨¡æ€çš„å…¨é¢æ”¯æŒ
2. é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼ŒåŒ…æ‹¬åŸºç¡€æ£€ç´¢å’Œæ”¹è¿›çš„InfoNCEæŸå¤±ä»¥å¢žå¼ºåˆ¤åˆ«èƒ½åŠ›
3. åœ¨MMEBåŸºå‡†ä¸Šå®žçŽ°æ–°SOTAï¼Œå°¤å…¶åœ¨è§†é¢‘å’Œè§†è§‰æ–‡æ¡£æ£€ç´¢ä»»åŠ¡ä¸­è¡¨çŽ°ä¼˜å¼‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The rapid advancement of Multimodal Large Language Models (MLLMs) has
> extended CLIP-based frameworks to produce powerful, universal embeddings for
> retrieval tasks. However, existing methods primarily focus on natural images,
> offering limited support for other crucial visual modalities such as videos and
> visual documents. To bridge this gap, we introduce RzenEmbed, a unified
> framework to learn embeddings across a diverse set of modalities, including
> text, images, videos, and visual documents. We employ a novel two-stage
> training strategy to learn discriminative representations. The first stage
> focuses on foundational text and multimodal retrieval. In the second stage, we
> introduce an improved InfoNCE loss, incorporating two key enhancements.
> Firstly, a hardness-weighted mechanism guides the model to prioritize
> challenging samples by assigning them higher weights within each batch.
> Secondly, we implement an approach to mitigate the impact of false negatives
> and alleviate data noise. This strategy not only enhances the model's
> discriminative power but also improves its instruction-following capabilities.
> We further boost performance with learnable temperature parameter and model
> souping. RzenEmbed sets a new state-of-the-art on the MMEB benchmark. It not
> only achieves the best overall score but also outperforms all prior work on the
> challenging video and visual document retrieval tasks. Our models are available
> in https://huggingface.co/qihoo360/RzenEmbed.

