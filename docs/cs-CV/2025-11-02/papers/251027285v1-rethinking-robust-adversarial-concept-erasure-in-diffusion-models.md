---
layout: default
title: Rethinking Robust Adversarial Concept Erasure in Diffusion Models
---

# Rethinking Robust Adversarial Concept Erasure in Diffusion Models

**arXiv**: [2510.27285v1](https://arxiv.org/abs/2510.27285) | [PDF](https://arxiv.org/pdf/2510.27285.pdf)

**ä½œè€…**: Qinghong Yin, Yu Tian, Yue Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºS-GRACEæ–¹æ³•ä»¥è§£å†³æ‰©æ•£æ¨¡åž‹ä¸­æ¦‚å¿µæ“¦é™¤çš„é²æ£’æ€§é—®é¢˜**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹` `æ¦‚å¿µæ“¦é™¤` `å¯¹æŠ—è®­ç»ƒ` `è¯­ä¹‰æŒ‡å¯¼` `é²æ£’æ€§ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨å¯¹æŠ—è®­ç»ƒä¸­å¿½è§†æ¦‚å¿µè¯­ä¹‰ï¼Œå¯¼è‡´æ¦‚å¿µç©ºé—´è¦†ç›–ä¸è¶³æˆ–å¹²æ‰°å…¶ä»–æ¦‚å¿µ
2. S-GRACEåˆ©ç”¨è¯­ä¹‰æŒ‡å¯¼ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼Œæå‡æ¦‚å¿µæ“¦é™¤çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§
3. å®žéªŒæ˜¾ç¤ºS-GRACEæ“¦é™¤æ€§èƒ½æå‡26%ï¼Œéžç›®æ ‡æ¦‚å¿µä¿ç•™æ›´å¥½ï¼Œè®­ç»ƒæ—¶é—´å‡å°‘90%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Concept erasure aims to selectively unlearning undesirable content in
> diffusion models (DMs) to reduce the risk of sensitive content generation. As a
> novel paradigm in concept erasure, most existing methods employ adversarial
> training to identify and suppress target concepts, thus reducing the likelihood
> of sensitive outputs. However, these methods often neglect the specificity of
> adversarial training in DMs, resulting in only partial mitigation. In this
> work, we investigate and quantify this specificity from the perspective of
> concept space, i.e., can adversarial samples truly fit the target concept
> space? We observe that existing methods neglect the role of conceptual
> semantics when generating adversarial samples, resulting in ineffective fitting
> of concept spaces. This oversight leads to the following issues: 1) when there
> are few adversarial samples, they fail to comprehensively cover the object
> concept; 2) conversely, they will disrupt other target concept spaces.
> Motivated by the analysis of these findings, we introduce S-GRACE
> (Semantics-Guided Robust Adversarial Concept Erasure), which grace leveraging
> semantic guidance within the concept space to generate adversarial samples and
> perform erasure training. Experiments conducted with seven state-of-the-art
> methods and three adversarial prompt generation strategies across various DM
> unlearning scenarios demonstrate that S-GRACE significantly improves erasure
> performance 26%, better preserves non-target concepts, and reduces training
> time by 90%. Our code is available at https://github.com/Qhong-522/S-GRACE.

