---
layout: default
title: Image Hashing via Cross-View Code Alignment in the Age of Foundation Models
---

# Image Hashing via Cross-View Code Alignment in the Age of Foundation Models

**arXiv**: [2510.27584v1](https://arxiv.org/abs/2510.27584) | [PDF](https://arxiv.org/pdf/2510.27584.pdf)

**ä½œè€…**: Ilyass Moummad, Kawtar Zaher, HervÃ© GoÃ«au, Alexis Joly

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCroVCAæ–¹æ³•ï¼Œé€šè¿‡è·¨è§†å›¾ä»£ç å¯¹é½å®žçŽ°é«˜æ•ˆå›¾åƒå“ˆå¸Œæ£€ç´¢**

**å…³é”®è¯**: `å›¾åƒå“ˆå¸Œ` `è·¨è§†å›¾å¯¹é½` `ç¼–ç çŽ‡æœ€å¤§åŒ–` `è½»é‡ç½‘ç»œ` `é«˜æ•ˆæ£€ç´¢` `åŸºç¡€æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŸºç¡€æ¨¡åž‹åµŒå…¥é«˜ç»´ï¼Œæœ€è¿‘é‚»æœç´¢è®¡ç®—æˆæœ¬é«˜ï¼ŒçŽ°æœ‰å“ˆå¸Œæ–¹æ³•å¤æ‚ä¸”è®­ç»ƒæ…¢ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å•ä¸€äºŒå…ƒäº¤å‰ç†µæŸå¤±å¯¹é½è¯­ä¹‰è§†å›¾ï¼Œç¼–ç çŽ‡æœ€å¤§åŒ–é˜²æ­¢ä»£ç å´©æºƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†ä¸Šå®žçŽ°SOTAï¼Œ16ä½å“ˆå¸Œè®­ç»ƒä»…éœ€æ•°åˆ†é’Ÿï¼Œæ•ˆçŽ‡é«˜ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Efficient large-scale retrieval requires representations that are both
> compact and discriminative. Foundation models provide powerful visual and
> multimodal embeddings, but nearest neighbor search in these high-dimensional
> spaces is computationally expensive. Hashing offers an efficient alternative by
> enabling fast Hamming distance search with binary codes, yet existing
> approaches often rely on complex pipelines, multi-term objectives, designs
> specialized for a single learning paradigm, and long training times. We
> introduce CroVCA (Cross-View Code Alignment), a simple and unified principle
> for learning binary codes that remain consistent across semantically aligned
> views. A single binary cross-entropy loss enforces alignment, while coding-rate
> maximization serves as an anti-collapse regularizer to promote balanced and
> diverse codes. To implement this, we design HashCoder, a lightweight MLP
> hashing network with a final batch normalization layer to enforce balanced
> codes. HashCoder can be used as a probing head on frozen embeddings or to adapt
> encoders efficiently via LoRA fine-tuning. Across benchmarks, CroVCA achieves
> state-of-the-art results in just 5 training epochs. At 16 bits, it particularly
> well-for instance, unsupervised hashing on COCO completes in under 2 minutes
> and supervised hashing on ImageNet100 in about 3 minutes on a single GPU. These
> results highlight CroVCA's efficiency, adaptability, and broad applicability.

