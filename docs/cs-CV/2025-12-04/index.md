---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-12-04
---

# cs.CVï¼ˆ2025-12-04ï¼‰

ğŸ“Š å…± **29** ç¯‡è®ºæ–‡
 | ğŸ”— **8** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (15 ğŸ”—4)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (6 ğŸ”—3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (3 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (15 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251205259v1-age-inclusive-3d-human-mesh-recovery-for-action-preserving-data-anon.html">Age-Inclusive 3D Human Mesh Recovery for Action-Preserving Data Anonymization</a></td>
  <td>æå‡ºAionHMRæ¡†æ¶ï¼Œå®ç°å¹´é¾„åŒ…å®¹çš„3Däººä½“ç½‘æ ¼é‡å»ºï¼Œç”¨äºä¿æŠ¤éšç§çš„æ•°æ®åŒ¿ååŒ–ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05259v1" onclick="toggleFavorite(this, '2512.05259v1', 'Age-Inclusive 3D Human Mesh Recovery for Action-Preserving Data Anonymization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251204815v1-robustsplat-decoupling-densification-dynamics-and-illumination-for-i.html">RobustSplat++: Decoupling Densification, Dynamics, and Illumination for In-the-Wild 3DGS</a></td>
  <td>RobustSplat++ï¼šè§£è€¦3DGSçš„ç¨ å¯†åŒ–ã€åŠ¨æ€å’Œå…‰ç…§ï¼Œå®ç°é‡å¤–åœºæ™¯é²æ£’å»ºæ¨¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04815v1" onclick="toggleFavorite(this, '2512.04815v1', 'RobustSplat++: Decoupling Densification, Dynamics, and Illumination for In-the-Wild 3DGS')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251204542v1-gaussian-entropy-fields-driving-adaptive-sparsity-in-3d-gaussian-opt.html">Gaussian Entropy Fields: Driving Adaptive Sparsity in 3D Gaussian Optimization</a></td>
  <td>æå‡ºé«˜æ–¯ç†µåœºä»¥é©±åŠ¨3Dé«˜æ–¯ä¼˜åŒ–ä¸­çš„è‡ªé€‚åº”ç¨€ç–æ€§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04542v1" onclick="toggleFavorite(this, '2512.04542v1', 'Gaussian Entropy Fields: Driving Adaptive Sparsity in 3D Gaussian Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251204358v1-mafnetmulti-frequency-adaptive-fusion-network-for-real-time-stereo-m.html">MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching</a></td>
  <td>æå‡ºMAFNetï¼Œé€šè¿‡å¤šé¢‘è‡ªé€‚åº”èåˆç½‘ç»œå®ç°å®æ—¶é«˜ç²¾åº¦ç«‹ä½“åŒ¹é…</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04358v1" onclick="toggleFavorite(this, '2512.04358v1', 'MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251204939v1-litevggt-boosting-vanilla-vggt-via-geometry-aware-cached-token-mergi.html">LiteVGGT: Boosting Vanilla VGGT via Geometry-aware Cached Token Merging</a></td>
  <td>LiteVGGTï¼šé€šè¿‡å‡ ä½•æ„ŸçŸ¥ç¼“å­˜Tokenåˆå¹¶åŠ é€ŸVGGTï¼Œå®ç°å¤§è§„æ¨¡åœºæ™¯é«˜æ•ˆ3Dé‡å»ºã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04939v1" onclick="toggleFavorite(this, '2512.04939v1', 'LiteVGGT: Boosting Vanilla VGGT via Geometry-aware Cached Token Merging')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251204890v3-equivariant-symmetry-aware-head-pose-estimation-for-fetal-mri.html">Equivariant symmetry-aware head pose estimation for fetal MRI</a></td>
  <td>æå‡ºE(3)-Poseï¼Œè§£å†³èƒå„¿MRIä¸­å¯¹ç§°æ„ŸçŸ¥çš„å¤´éƒ¨å§¿æ€ä¼°è®¡é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04890v3" onclick="toggleFavorite(this, '2512.04890v3', 'Equivariant symmetry-aware head pose estimation for fetal MRI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251204862v1-contact-aware-refinement-of-human-pose-pseudo-ground-truth-via-bioim.html">Contact-Aware Refinement of Human Pose Pseudo-Ground Truth via Bioimpedance Sensing</a></td>
  <td>æå‡ºBioTUCHï¼Œç»“åˆç”Ÿç‰©é˜»æŠ—æ„ŸçŸ¥ä¼˜åŒ–è‡ªæ¥è§¦åœºæ™¯ä¸‹çš„äººä½“å§¿æ€ä¼ªæ ‡ç­¾ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04862v1" onclick="toggleFavorite(this, '2512.04862v1', 'Contact-Aware Refinement of Human Pose Pseudo-Ground Truth via Bioimpedance Sensing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251205113v2-splannequin-freezing-monocular-mannequin-challenge-footage-with-dual.html">Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting</a></td>
  <td>Splannequinï¼šåˆ©ç”¨åŒé‡æ£€æµ‹ Splatting å†»ç»“å•ç›®äººä½“é›•å¡‘æŒ‘æˆ˜è§†é¢‘</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05113v2" onclick="toggleFavorite(this, '2512.05113v2', 'Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251205060v1-4dlangvggt-4d-language-visual-geometry-grounded-transformer.html">4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer</a></td>
  <td>æå‡º4DLangVGGTï¼Œç”¨äºé«˜æ•ˆä¸”å¯æ³›åŒ–çš„4Dè¯­è¨€-è§†è§‰å‡ ä½•å¯¹é½</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05060v1" onclick="toggleFavorite(this, '2512.05060v1', '4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251205115v2-light-x-generative-4d-video-rendering-with-camera-and-illumination-c.html">Light-X: Generative 4D Video Rendering with Camera and Illumination Control</a></td>
  <td>Light-Xï¼šæå‡ºå¯æ§ç›¸æœºä¸å…‰ç…§çš„ç”Ÿæˆå¼4Dè§†é¢‘æ¸²æŸ“æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05115v2" onclick="toggleFavorite(this, '2512.05115v2', 'Light-X: Generative 4D Video Rendering with Camera and Illumination Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251204996v1-a-dynamic-memory-assignment-strategy-for-dilation-based-icp-algorith.html">A dynamic memory assignment strategy for dilation-based ICP algorithm on embedded GPUs</a></td>
  <td>é’ˆå¯¹åµŒå…¥å¼GPUï¼Œæå‡ºåŠ¨æ€å†…å­˜åˆ†é…ç­–ç•¥ä¼˜åŒ–VANICPç‚¹äº‘é…å‡†ç®—æ³•ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04996v1" onclick="toggleFavorite(this, '2512.04996v1', 'A dynamic memory assignment strategy for dilation-based ICP algorithm on embedded GPUs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251204943v1-towards-adaptive-fusion-of-multimodal-deep-networks-for-human-action.html">Towards Adaptive Fusion of Multimodal Deep Networks for Human Action Recognition</a></td>
  <td>æå‡ºåŸºäºé—¨æ§æœºåˆ¶çš„å¤šæ¨¡æ€è‡ªé€‚åº”èåˆç½‘ç»œï¼Œæå‡äººç±»è¡Œä¸ºè¯†åˆ«ç²¾åº¦</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04943v1" onclick="toggleFavorite(this, '2512.04943v1', 'Towards Adaptive Fusion of Multimodal Deep Networks for Human Action Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251204888v2-you-only-train-once-yoto-a-retraining-free-object-detection-framewor.html">You Only Train Once (YOTO): A Retraining-Free Object Detection Framework</a></td>
  <td>æå‡ºYOTOæ¡†æ¶ï¼Œè§£å†³ç›®æ ‡æ£€æµ‹ä¸­å…é‡è®­ç»ƒçš„æ–°å“å¢é‡å­¦ä¹ é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04888v2" onclick="toggleFavorite(this, '2512.04888v2', 'You Only Train Once (YOTO): A Retraining-Free Object Detection Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251204619v1-denoise-to-track-harnessing-video-diffusion-priors-for-robust-corres.html">Denoise to Track: Harnessing Video Diffusion Priors for Robust Correspondence</a></td>
  <td>æå‡ºHeFTï¼Œåˆ©ç”¨è§†é¢‘æ‰©æ•£å…ˆéªŒå®ç°é²æ£’çš„é›¶æ ·æœ¬ç‚¹è·Ÿè¸ª</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04619v1" onclick="toggleFavorite(this, '2512.04619v1', 'Denoise to Track: Harnessing Video Diffusion Priors for Robust Correspondence')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251204599v1-malicious-image-analysis-via-vision-language-segmentation-fusion-det.html">Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot</a></td>
  <td>æå‡ºåŸºäºè§†è§‰-è¯­è¨€åˆ†å‰²èåˆçš„æ¶æ„å›¾åƒåˆ†ææ–¹æ³•ï¼Œå®ç°ä¸€æ­¥åˆ°ä½çš„å†…å®¹æ£€æµ‹ã€å…ƒç´ è¯†åˆ«å’Œå®šä½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04599v1" onclick="toggleFavorite(this, '2512.04599v1', 'Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (6 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>16</td>
  <td><a href="./papers/251204537v1-x-humanoid-robotize-human-videos-to-generate-humanoid-videos-at-scal.html">X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale</a></td>
  <td>X-Humanoidï¼šé€šè¿‡æœºå™¨äººåŒ–äººç±»è§†é¢‘å¤§è§„æ¨¡ç”Ÿæˆç±»äººæœºå™¨äººè§†é¢‘</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04537v1" onclick="toggleFavorite(this, '2512.04537v1', 'X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251204425v1-explainable-parkinsons-disease-gait-recognition-using-multimodal-rgb.html">Explainable Parkinsons Disease Gait Recognition Using Multimodal RGB-D Fusion and Large Language Models</a></td>
  <td>æå‡ºåŸºäºRGB-Dèåˆå’ŒLLMçš„å¯è§£é‡Šå¸•é‡‘æ£®æ­¥æ€è¯†åˆ«æ¡†æ¶</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04425v1" onclick="toggleFavorite(this, '2512.04425v1', 'Explainable Parkinsons Disease Gait Recognition Using Multimodal RGB-D Fusion and Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251204952v2-faster-toward-efficient-autoregressive-vision-language-action-modeli.html">FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization</a></td>
  <td>FASTerï¼šé€šè¿‡ç¥ç»åŠ¨ä½œæ ‡è®°åŒ–å®ç°é«˜æ•ˆçš„è‡ªå›å½’è§†è§‰-è¯­è¨€-åŠ¨ä½œå»ºæ¨¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04952v2" onclick="toggleFavorite(this, '2512.04952v2', 'FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251205079v1-object-reconstruction-under-occlusion-with-generative-priors-and-con.html">Object Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints</a></td>
  <td>æå‡ºåŸºäºç”Ÿæˆå…ˆéªŒå’Œæ¥è§¦çº¦æŸçš„ç‰©ä½“é®æŒ¡é‡å»ºæ–¹æ³•ï¼Œæå‡æœºå™¨äººæ“ä½œæ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05079v1" onclick="toggleFavorite(this, '2512.05079v1', 'Object Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251205076v1-bullettime-decoupled-control-of-time-and-camera-pose-for-video-gener.html">BulletTime: Decoupled Control of Time and Camera Pose for Video Generation</a></td>
  <td>BulletTimeï¼šè§£è€¦æ—¶é—´å’Œç›¸æœºå§¿æ€æ§åˆ¶çš„è§†é¢‘ç”Ÿæˆæ¡†æ¶</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05076v1" onclick="toggleFavorite(this, '2512.05076v1', 'BulletTime: Decoupled Control of Time and Camera Pose for Video Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/251204686v2-towards-cross-view-point-correspondence-in-vision-language-models.html">Towards Cross-View Point Correspondence in Vision-Language Models</a></td>
  <td>æå‡ºCrossPoint-Benchå’ŒCroPondæ¨¡å‹ï¼Œè§£å†³è§†è§‰è¯­è¨€æ¨¡å‹ä¸­è·¨è§†è§’ç‚¹å¯¹åº”éš¾é¢˜ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04686v2" onclick="toggleFavorite(this, '2512.04686v2', 'Towards Cross-View Point Correspondence in Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>22</td>
  <td><a href="./papers/251204970v1-stable-single-pixel-contrastive-learning-for-semantic-and-geometric-.html">Stable Single-Pixel Contrastive Learning for Semantic and Geometric Tasks</a></td>
  <td>æå‡ºç¨³å®šå•åƒç´ å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºè¯­ä¹‰å’Œå‡ ä½•ä»»åŠ¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04970v1" onclick="toggleFavorite(this, '2512.04970v1', 'Stable Single-Pixel Contrastive Learning for Semantic and Geometric Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/251204511v1-dugi-mae-improving-infrared-mask-autoencoders-via-dual-domain-guidan.html">DuGI-MAE: Improving Infrared Mask Autoencoders via Dual-Domain Guidance</a></td>
  <td>DuGI-MAEï¼šé€šè¿‡åŒåŸŸå¼•å¯¼æ”¹è¿›çº¢å¤–å›¾åƒæ©ç è‡ªç¼–ç å™¨æ€§èƒ½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04511v1" onclick="toggleFavorite(this, '2512.04511v1', 'DuGI-MAE: Improving Infrared Mask Autoencoders via Dual-Domain Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/251205172v1-semore-vlm-guided-enhanced-semantic-motion-representations-for-visua.html">Semore: VLM-guided Enhanced Semantic Motion Representations for Visual Reinforcement Learning</a></td>
  <td>Semoreï¼šVLMå¼•å¯¼çš„å¢å¼ºè¯­ä¹‰è¿åŠ¨è¡¨å¾ç”¨äºè§†è§‰å¼ºåŒ–å­¦ä¹ </td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05172v1" onclick="toggleFavorite(this, '2512.05172v1', 'Semore: VLM-guided Enhanced Semantic Motion Representations for Visual Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/251204904v1-reflexflow-rethinking-learning-objective-for-exposure-bias-alleviati.html">ReflexFlow: Rethinking Learning Objective for Exposure Bias Alleviation in Flow Matching</a></td>
  <td>ReflexFlowï¼šé€šè¿‡åæ€å¼ä¼˜åŒ–Flow Matchingå­¦ä¹ ç›®æ ‡ï¼Œç¼“è§£ç”Ÿæˆæ¨¡å‹çš„æš´éœ²åå·®</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04904v1" onclick="toggleFavorite(this, '2512.04904v1', 'ReflexFlow: Rethinking Learning Objective for Exposure Bias Alleviation in Flow Matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/251204395v1-fourier-attentive-representation-learning-a-fourier-guided-framework.html">Fourier-Attentive Representation Learning: A Fourier-Guided Framework for Few-Shot Generalization in Vision-Language Models</a></td>
  <td>æå‡ºFARLæ¡†æ¶ï¼Œåˆ©ç”¨å‚…é‡Œå¶åˆ†æè§£è€¦è§†è§‰è¡¨å¾ï¼Œæå‡è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04395v1" onclick="toggleFavorite(this, '2512.04395v1', 'Fourier-Attentive Representation Learning: A Fourier-Guided Framework for Few-Shot Generalization in Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>27</td>
  <td><a href="./papers/251204499v1-back-to-basics-motion-representation-matters-for-human-motion-genera.html">Back to Basics: Motion Representation Matters for Human Motion Generation Using Diffusion Model</a></td>
  <td>ç ”ç©¶è¿åŠ¨æ‰©æ•£æ¨¡å‹ä¸­è¿åŠ¨è¡¨å¾å¯¹äººä½“è¿åŠ¨ç”Ÿæˆçš„å½±å“ï¼Œå¹¶æå‡ºä¼˜åŒ–å»ºè®®ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04499v1" onclick="toggleFavorite(this, '2512.04499v1', 'Back to Basics: Motion Representation Matters for Human Motion Generation Using Diffusion Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/251204487v1-controllable-long-term-motion-generation-with-extended-joint-targets.html">Controllable Long-term Motion Generation with Extended Joint Targets</a></td>
  <td>COMETï¼šåŸºäºTransformerçš„å®æ—¶å¯æ§é•¿æ—¶ç¨‹äººä½“è¿åŠ¨ç”Ÿæˆæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04487v1" onclick="toggleFavorite(this, '2512.04487v1', 'Controllable Long-term Motion Generation with Extended Joint Targets')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/251205044v1-joint-3d-geometry-reconstruction-and-motion-generation-for-4d-synthe.html">Joint 3D Geometry Reconstruction and Motion Generation for 4D Synthesis from a Single Image</a></td>
  <td>æå‡ºMoRe4Dï¼Œè”åˆè¿›è¡Œ3Då‡ ä½•é‡å»ºå’Œè¿åŠ¨ç”Ÿæˆï¼Œä»å•å¼ å›¾åƒåˆæˆ4Dåœºæ™¯ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05044v1" onclick="toggleFavorite(this, '2512.05044v1', 'Joint 3D Geometry Reconstruction and Motion Generation for 4D Synthesis from a Single Image')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)