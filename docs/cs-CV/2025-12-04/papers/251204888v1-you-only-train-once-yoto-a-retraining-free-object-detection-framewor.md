---
layout: default
title: You Only Train Once (YOTO): A Retraining-Free Object Detection Framework
---

# You Only Train Once (YOTO): A Retraining-Free Object Detection Framework

**arXiv**: [2512.04888v1](https://arxiv.org/abs/2512.04888) | [PDF](https://arxiv.org/pdf/2512.04888.pdf)

**ä½œè€…**: Priyanto Hidayatullah, Nurjannah Syakrani, Yudi Widhiyasana, Muhammad Rizqi Sholahuddin, Refdinal Tubagus, Zahri Al Adzani Hidayat, Hanri Fajar Ramadhan, Dafa Alfarizki Pratama, Farhan Muhammad Yasin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºYOTOæ¡†æž¶ä»¥è§£å†³é›¶å”®åœºæ™¯ä¸­ç›®æ ‡æ£€æµ‹çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œæ— éœ€é‡è®­ç»ƒå³å¯æ·»åŠ æ–°äº§å“ã€‚**

**å…³é”®è¯**: `ç›®æ ‡æ£€æµ‹` `ç¾éš¾æ€§é—å¿˜` `é›¶å”®åº”ç”¨` `è¾¹ç¼˜è®¡ç®—` `å‘é‡æ•°æ®åº“` `åº¦é‡å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç›®æ ‡æ£€æµ‹é¢ä¸´ç¾éš¾æ€§é—å¿˜ï¼Œæ·»åŠ æ–°äº§å“éœ€é‡è®­ç»ƒå…¨éƒ¨æ•°æ®ï¼Œå¢žåŠ æˆæœ¬å’Œæ—¶é—´ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆYOLO11nå®šä½ã€DeITç‰¹å¾æå–å’Œä»£ç†é”šç‚¹æŸå¤±ï¼Œé€šè¿‡ä½™å¼¦ç›¸ä¼¼åº¦åœ¨å‘é‡æ•°æ®åº“ä¸­åˆ†ç±»ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨140äº§å“é›¶å”®æ¡ˆä¾‹ä¸­ï¼Œå‡†ç¡®çŽ‡è‰¯å¥½ï¼Œè®­ç»ƒæ•ˆçŽ‡æå‡è¿‘3å€ï¼ŒæŽ¨ç†æ—¶é—´580ms/å›¾åƒäºŽè¾¹ç¼˜è®¾å¤‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Object detection constitutes the primary task within the domain of computer vision. It is utilized in numerous domains. Nonetheless, object detection continues to encounter the issue of catastrophic forgetting. The model must be retrained whenever new products are introduced, utilizing not only the new products dataset but also the entirety of the previous dataset. The outcome is obvious: increasing model training expenses and significant time consumption. In numerous sectors, particularly retail checkout, the frequent introduction of new products presents a great challenge. This study introduces You Only Train Once (YOTO), a methodology designed to address the issue of catastrophic forgetting by integrating YOLO11n for object localization with DeIT and Proxy Anchor Loss for feature extraction and metric learning. For classification, we utilize cosine similarity between the embedding features of the target product and those in the Qdrant vector database. In a case study conducted in a retail store with 140 products, the experimental results demonstrate that our proposed framework achieves encouraging accuracy, whether for detecting new or existing products. Furthermore, without retraining, the training duration difference is significant. We achieve almost 3 times the training time efficiency compared to classical object detection approaches. This efficiency escalates as additional new products are added to the product database. The average inference time is 580 ms per image containing multiple products, on an edge device, validating the proposed framework's feasibility for practical use.

