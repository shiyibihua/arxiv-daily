---
layout: default
title: RRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS
---

# RRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS

**arXiv**: [2512.04552v1](https://arxiv.org/abs/2512.04552) | [PDF](https://arxiv.org/pdf/2512.04552.pdf)

**ä½œè€…**: Cong Wang, Changfeng Gao, Yang Xiang, Zhihao Du, Keyu An, Han Zhao, Qian Chen, Xiangang Li, Yingming Gao, Ya Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRRPOæ¡†æž¶ä»¥è§£å†³åŸºäºŽLLMçš„æƒ…æ„ŸTTSä¸­çš„å¥–åŠ±é»‘å®¢é—®é¢˜**

**å…³é”®è¯**: `æƒ…æ„Ÿæ–‡æœ¬è½¬è¯­éŸ³` `ç¨³å¥å¥–åŠ±æ¨¡åž‹` `å¯å¾®å¼ºåŒ–å­¦ä¹ ` `å¥–åŠ±é»‘å®¢ç¼“è§£` `æ··åˆæ­£åˆ™åŒ–` `è·¨è¯­è¨€æ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¯å¾®å¼ºåŒ–å­¦ä¹ æ¡†æž¶æ˜“å—å¥–åŠ±é»‘å®¢å½±å“ï¼Œå¯¼è‡´å£°å­¦ä¼ªå½±å’Œæ„ŸçŸ¥è´¨é‡ä¸‹é™
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ··åˆæ­£åˆ™åŒ–æ–¹æ¡ˆå¼€å‘ç¨³å¥å¥–åŠ±æ¨¡åž‹ï¼Œä½¿å¥–åŠ±ä¿¡å·æ›´å¯é åœ°å¯¹é½äººç±»æ„ŸçŸ¥
3. å®žéªŒæˆ–æ•ˆæžœï¼šä¸»è§‚è¯„ä¼°æ˜¾ç¤ºRRPOæ˜¾è‘—æå‡æƒ…æ„Ÿè¡¨è¾¾åŠ›å’Œè‡ªç„¶åº¦ï¼Œå¹¶å±•ç¤ºè·¨è¯­è¨€æ³›åŒ–èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Differentiable reinforcement learning (RL) frameworks like DiffRO offer a powerful approach for controllable text-to-speech (TTS), but are vulnerable to reward hacking, particularly for nuanced tasks like emotion control. The policy model can exploit a vanilla Reward Model (RM) by generating acoustic artifacts to achieve spurious rewards, but at the cost of degrading perceptual quality. To address this, we propose Robust Reward Policy Optimization (RRPO), a novel framework that employs a hybrid regularization scheme. This scheme develops a robust RM whose reward signal is more reliably aligned with human perception, compelling the policy to abandon detrimental shortcuts and instead learn the complex features of genuine emotions. Our ablation study confirms the enhanced robustness of our RM, as evidenced by its strong cross-lingual generalization. The subjective evaluation demonstrates that this robust RM effectively mitigates reward hacking, leading to significant improvements in both emotional expressiveness and naturalness over all baselines. Demo page: https://lrwinr.github.io/RRPO-CosyVoice.

