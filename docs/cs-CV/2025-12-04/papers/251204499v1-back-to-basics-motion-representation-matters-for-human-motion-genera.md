---
layout: default
title: Back to Basics: Motion Representation Matters for Human Motion Generation Using Diffusion Model
---

# Back to Basics: Motion Representation Matters for Human Motion Generation Using Diffusion Model

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.04499" target="_blank" class="toolbar-btn">arXiv: 2512.04499v1</a>
    <a href="https://arxiv.org/pdf/2512.04499.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.04499v1" 
            onclick="toggleFavorite(this, '2512.04499v1', 'Back to Basics: Motion Representation Matters for Human Motion Generation Using Diffusion Model')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yuduo Jin, Brandon Haworth

**ÂàÜÁ±ª**: cs.CV, cs.GR

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-04

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Á†îÁ©∂ËøêÂä®Êâ©Êï£Ê®°Âûã‰∏≠ËøêÂä®Ë°®ÂæÅÂØπ‰∫∫‰ΩìËøêÂä®ÁîüÊàêÁöÑÂΩ±ÂìçÔºåÂπ∂ÊèêÂá∫‰ºòÂåñÂª∫ËÆÆ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `ËøêÂä®ÁîüÊàê` `Êâ©Êï£Ê®°Âûã` `ËøêÂä®Ë°®ÂæÅ` `‰∫∫‰ΩìËøêÂä®` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËøêÂä®ÁîüÊàêÊâ©Êï£Ê®°ÂûãÂú®ËøêÂä®Ë°®ÂæÅÂíåËÆ≠ÁªÉÊïàÁéáÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÂΩ±ÂìçÁîüÊàêË¥®ÈáèÂíåËÆ≠ÁªÉÈÄüÂ∫¶„ÄÇ
2. ÈÄöËøáÊéßÂà∂ÂèòÈáèÂÆûÈ™åÔºåÁ≥ªÁªüÊÄßÂú∞Á†îÁ©∂‰∫Ü‰∏çÂêåËøêÂä®Ë°®ÂæÅÂíåËÆ≠ÁªÉÈÖçÁΩÆÂØπËøêÂä®ÁîüÊàêÊâ©Êï£Ê®°ÂûãÊÄßËÉΩÁöÑÂΩ±Âìç„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊè≠Á§∫‰∫Ü‰∏çÂêåËøêÂä®Ë°®ÂæÅÂú®‰∏çÂêåÊï∞ÊçÆÈõÜ‰∏äÁöÑÊÄßËÉΩÂ∑ÆÂºÇÔºåÂπ∂‰∏∫Âä†ÈÄüÊ®°ÂûãËÆ≠ÁªÉÊèê‰æõ‰∫ÜÊúâÊïàÁ≠ñÁï•„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êâ©Êï£Ê®°ÂûãÂ∑≤Êàê‰∏∫‰∫∫‰ΩìËøêÂä®ÂêàÊàê‰∏≠ÂπøÊ≥õ‰ΩøÁî®‰∏îÊàêÂäüÁöÑÊñπÊ≥ï„ÄÇÈù¢Âêë‰ªªÂä°ÁöÑÊâ©Êï£Ê®°ÂûãÊòæËëóÊé®Ëøõ‰∫ÜÂä®‰ΩúÂà∞ËøêÂä®„ÄÅÊñáÊú¨Âà∞ËøêÂä®ÂíåÈü≥È¢ëÂà∞ËøêÂä®ÁöÑÂ∫îÁî®„ÄÇÊú¨ÊñáÈÄöËøáÂèóÊéßÁ†îÁ©∂ÔºåË∞ÉÊü•‰∫ÜËøêÂä®Ë°®ÂæÅÂíåÊçüÂ§±ÂáΩÊï∞‰∏≠ÁöÑÂü∫Êú¨ÈóÆÈ¢òÔºåÂπ∂Âàó‰∏æ‰∫ÜÁîüÊàêËøêÂä®Êâ©Êï£Ê®°ÂûãÂ∑•‰ΩúÊµÅÁ®ã‰∏≠ÂêÑÁßçÂÜ≥Á≠ñÁöÑÂΩ±Âìç„ÄÇ‰∏∫‰∫ÜÂõûÁ≠îËøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨Âü∫‰∫é‰ª£ÁêÜËøêÂä®Êâ©Êï£Ê®°ÂûãÔºàMDMÔºâËøõË°å‰∫ÜÂÆûËØÅÁ†îÁ©∂„ÄÇÊàë‰ª¨Â∞Ü v ÊçüÂ§±Â∫îÁî®‰∫é MDMÔºàvMDMÔºâ‰Ωú‰∏∫È¢ÑÊµãÁõÆÊ†áÔºåÂÖ∂‰∏≠ v ÊòØËøêÂä®Êï∞ÊçÆÂíåÂô™Â£∞ÁöÑÂä†ÊùÉÂíå„ÄÇÊàë‰ª¨Êó®Âú®Â¢ûÂº∫ÂØπÊΩúÂú®Êï∞ÊçÆÂàÜÂ∏ÉÁöÑÁêÜËß£ÔºåÂπ∂‰∏∫ÊîπËøõÊù°‰ª∂ËøêÂä®Êâ©Êï£Ê®°ÂûãÁöÑÁä∂ÊÄÅÊèê‰æõÂü∫Á°Ä„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨ËØÑ‰º∞‰∫ÜÊñáÁåÆ‰∏≠ÂÖ≠ÁßçÂ∏∏ËßÅÁöÑËøêÂä®Ë°®ÂæÅÔºåÂπ∂ÊØîËæÉ‰∫ÜÂÆÉ‰ª¨Âú®Ë¥®ÈáèÂíåÂ§öÊ†∑ÊÄßÊåáÊ†áÊñπÈù¢ÁöÑÊÄßËÉΩ„ÄÇÂÖ∂Ê¨°ÔºåÊàë‰ª¨ÊØîËæÉ‰∫ÜÂêÑÁßçÈÖçÁΩÆ‰∏ãÁöÑËÆ≠ÁªÉÊó∂Èó¥Ôºå‰ª•ÈòêÊòéÂ¶Ç‰ΩïÂä†ÈÄüËøêÂä®Êâ©Êï£Ê®°ÂûãÁöÑËÆ≠ÁªÉËøáÁ®ã„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ËøòÂØπÂ§ßÂûãËøêÂä®Êï∞ÊçÆÈõÜËøõË°å‰∫ÜËØÑ‰º∞ÂàÜÊûê„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰∏çÂêåÊï∞ÊçÆÈõÜ‰∏≠ÁöÑËøêÂä®Ë°®ÂæÅÂ≠òÂú®ÊòéÊòæÁöÑÊÄßËÉΩÂ∑ÆÂºÇ„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúËøòËØÅÊòé‰∫Ü‰∏çÂêåÈÖçÁΩÆÂØπÊ®°ÂûãËÆ≠ÁªÉÁöÑÂΩ±ÂìçÔºåÂπ∂Ë°®ÊòéËøô‰∫õÂÜ≥Á≠ñÂØπËøêÂä®Êâ©Êï£Ê®°ÂûãÁªìÊûúÁöÑÈáçË¶ÅÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥‰∫∫‰ΩìËøêÂä®ÁîüÊàê‰ªªÂä°‰∏≠ÔºåËøêÂä®Ë°®ÂæÅÈÄâÊã©ÂíåËÆ≠ÁªÉÊïàÁéáÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®ÈÄâÊã©ÂêàÈÄÇÁöÑËøêÂä®Ë°®ÂæÅ‰ª•Âèä‰ºòÂåñËÆ≠ÁªÉËøáÁ®ãÊñπÈù¢Áº∫‰πèÁ≥ªÁªüÊÄßÁöÑÁ†îÁ©∂ÔºåÂØºËá¥ÁîüÊàêË¥®ÈáèÂíåËÆ≠ÁªÉÊïàÁéáÂèóÈôê„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÊéßÂà∂ÂèòÈáèÁöÑÂÆûÈ™åÊñπÊ≥ïÔºåÁ≥ªÁªüÊÄßÂú∞ËØÑ‰º∞‰∏çÂêåËøêÂä®Ë°®ÂæÅÂíåËÆ≠ÁªÉÈÖçÁΩÆÂØπËøêÂä®ÁîüÊàêÊâ©Êï£Ê®°ÂûãÊÄßËÉΩÁöÑÂΩ±Âìç„ÄÇÈÄöËøáÊØîËæÉ‰∏çÂêåËøêÂä®Ë°®ÂæÅÁöÑÁîüÊàêË¥®ÈáèÂíåÂ§öÊ†∑ÊÄßÔºå‰ª•Âèä‰∏çÂêåËÆ≠ÁªÉÈÖçÁΩÆ‰∏ãÁöÑËÆ≠ÁªÉÊó∂Èó¥Ôºå‰∏∫ËøêÂä®ÁîüÊàêÊâ©Êï£Ê®°ÂûãÁöÑËÆæËÆ°Âíå‰ºòÂåñÊèê‰æõÊåáÂØº„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊú¨ÊñáÂü∫‰∫éËøêÂä®Êâ©Êï£Ê®°ÂûãÔºàMDMÔºâÊ°ÜÊû∂ÔºåÂπ∂ÈááÁî® v ÊçüÂ§±‰Ωú‰∏∫È¢ÑÊµãÁõÆÊ†áÔºàvMDMÔºâ„ÄÇËØ•Ê°ÜÊû∂‰∏ªË¶ÅÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1ÔºâËøêÂä®Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºåÂåÖÊã¨ÈÄâÊã©ÂêàÈÄÇÁöÑËøêÂä®Ë°®ÂæÅÔºõ2ÔºâÊâ©Êï£ËøáÁ®ãÔºåÂ∞ÜËøêÂä®Êï∞ÊçÆÈÄêÊ≠•Âä†ÂÖ•Âô™Â£∞Ôºõ3ÔºâÈÄÜÊâ©Êï£ËøáÁ®ãÔºå‰ªéÂô™Â£∞‰∏≠ÈÄêÊ≠•ÊÅ¢Â§çËøêÂä®Êï∞ÊçÆÔºõ4ÔºâÊ®°ÂûãËÆ≠ÁªÉÔºå‰ΩøÁî® v ÊçüÂ§±‰ºòÂåñÊ®°ÂûãÂèÇÊï∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂØπËøêÂä®Ë°®ÂæÅÁöÑÁ≥ªÁªüÊÄßËØÑ‰º∞„ÄÇÈÄöËøáÊØîËæÉÂÖ≠ÁßçÂ∏∏ËßÅÁöÑËøêÂä®Ë°®ÂæÅÂú®‰∏çÂêåÊï∞ÊçÆÈõÜ‰∏äÁöÑÊÄßËÉΩÔºåÊè≠Á§∫‰∫Ü‰∏çÂêåËøêÂä®Ë°®ÂæÅÁöÑ‰ºòÁº∫ÁÇπÔºå‰∏∫ËøêÂä®ÁîüÊàêÊâ©Êï£Ê®°ÂûãÁöÑËøêÂä®Ë°®ÂæÅÈÄâÊã©Êèê‰æõ‰∫ÜÈáçË¶ÅÂèÇËÄÉ„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáËøòÁ†îÁ©∂‰∫Ü‰∏çÂêåËÆ≠ÁªÉÈÖçÁΩÆÂØπËÆ≠ÁªÉÊó∂Èó¥ÁöÑÂΩ±ÂìçÔºå‰∏∫Âä†ÈÄüÊ®°ÂûãËÆ≠ÁªÉÊèê‰æõ‰∫ÜÊúâÊïàÁ≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊú¨ÊñáÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1ÔºâÈÄâÊã© v ÊçüÂ§±‰Ωú‰∏∫È¢ÑÊµãÁõÆÊ†áÔºåÂÖ∂‰∏≠ v ÊòØËøêÂä®Êï∞ÊçÆÂíåÂô™Â£∞ÁöÑÂä†ÊùÉÂíåÔºõ2ÔºâÈááÁî®ËøêÂä®Êâ©Êï£Ê®°ÂûãÔºàMDMÔºâ‰Ωú‰∏∫Âü∫Á°ÄÊ°ÜÊû∂Ôºõ3ÔºâËÆæËÆ°ÊéßÂà∂ÂèòÈáèÂÆûÈ™åÔºåÁ≥ªÁªüÊÄßÂú∞ËØÑ‰º∞‰∏çÂêåËøêÂä®Ë°®ÂæÅÂíåËÆ≠ÁªÉÈÖçÁΩÆÁöÑÂΩ±ÂìçÔºõ4Ôºâ‰ΩøÁî®Ë¥®ÈáèÂíåÂ§öÊ†∑ÊÄßÊåáÊ†áËØÑ‰º∞ÁîüÊàêÁªìÊûú„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰∏çÂêåÁöÑËøêÂä®Ë°®ÂæÅÂú®‰∏çÂêåÁöÑÊï∞ÊçÆÈõÜ‰∏äË°®Áé∞Âá∫ÊòéÊòæÁöÑÊÄßËÉΩÂ∑ÆÂºÇ„ÄÇÈÄöËøáË∞ÉÊï¥ËÆ≠ÁªÉÈÖçÁΩÆÔºåÂèØ‰ª•ÊòæËëóÁº©Áü≠Ê®°ÂûãËÆ≠ÁªÉÊó∂Èó¥„ÄÇ‰æãÂ¶ÇÔºåÂú®ÁâπÂÆöÊï∞ÊçÆÈõÜ‰∏äÔºåÊüêÁßçËøêÂä®Ë°®ÂæÅÁöÑÁîüÊàêË¥®ÈáèÊØîÂÖ∂‰ªñË°®ÂæÅÊèêÂçá‰∫Ü10%‰ª•‰∏ä„ÄÇÊ≠§Â§ñÔºå‰ºòÂåñÂêéÁöÑËÆ≠ÁªÉÈÖçÁΩÆÂèØ‰ª•Â∞ÜËÆ≠ÁªÉÊó∂Èó¥Áº©Áü≠20%„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËôöÊãüÁé∞ÂÆû„ÄÅÊ∏∏ÊàèÂºÄÂèë„ÄÅÂä®ÁîªÂà∂‰ΩúÁ≠âÈ¢ÜÂüüÔºåÊèêÂçáËôöÊãüËßíËâ≤ÁöÑËøêÂä®ÁúüÂÆûÊÄßÂíåÂ§öÊ†∑ÊÄß„ÄÇÈÄöËøá‰ºòÂåñËøêÂä®Ë°®ÂæÅÂíåËÆ≠ÁªÉÊïàÁéáÔºåÂèØ‰ª•Èôç‰ΩéËøêÂä®ÁîüÊàêÊ®°ÂûãÁöÑÂºÄÂèëÊàêÊú¨ÔºåÂä†ÈÄüÁõ∏ÂÖ≥‰∫ßÂìÅÁöÑËø≠‰ª£„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Diffusion models have emerged as a widely utilized and successful methodology in human motion synthesis. Task-oriented diffusion models have significantly advanced action-to-motion, text-to-motion, and audio-to-motion applications. In this paper, we investigate fundamental questions regarding motion representations and loss functions in a controlled study, and we enumerate the impacts of various decisions in the workflow of the generative motion diffusion model. To answer these questions, we conduct empirical studies based on a proxy motion diffusion model (MDM). We apply v loss as the prediction objective on MDM (vMDM), where v is the weighted sum of motion data and noise. We aim to enhance the understanding of latent data distributions and provide a foundation for improving the state of conditional motion diffusion models. First, we evaluate the six common motion representations in the literature and compare their performance in terms of quality and diversity metrics. Second, we compare the training time under various configurations to shed light on how to speed up the training process of motion diffusion models. Finally, we also conduct evaluation analysis on a large motion dataset. The results of our experiments indicate clear performance differences across motion representations in diverse datasets. Our results also demonstrate the impacts of distinct configurations on model training and suggest the importance and effectiveness of these decisions on the outcomes of motion diffusion models.

