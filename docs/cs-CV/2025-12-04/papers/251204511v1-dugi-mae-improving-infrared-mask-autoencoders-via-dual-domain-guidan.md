---
layout: default
title: DuGI-MAE: Improving Infrared Mask Autoencoders via Dual-Domain Guidance
---

# DuGI-MAE: Improving Infrared Mask Autoencoders via Dual-Domain Guidance

**arXiv**: [2512.04511v1](https://arxiv.org/abs/2512.04511) | [PDF](https://arxiv.org/pdf/2512.04511.pdf)

**ä½œè€…**: Yinghui Xing, Xiaoting Su, Shizhou Zhang, Donghao Chu, Di Xu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDuGI-MAEï¼Œé€šè¿‡åŒåŸŸå¼•å¯¼æ”¹è¿›çº¢å¤–æŽ©ç è‡ªç¼–ç å™¨ä»¥æå‡çº¢å¤–å›¾åƒç†è§£æ€§èƒ½**

**å…³é”®è¯**: `çº¢å¤–å›¾åƒå¤„ç†` `æŽ©ç è‡ªç¼–ç å™¨` `åŒåŸŸå¼•å¯¼` `è‡ªç›‘ç£å­¦ä¹ ` `åŸºç¡€æ¨¡åž‹` `å™ªå£°è¿‡æ»¤`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é’ˆå¯¹çº¢å¤–å›¾åƒç‰¹æ€§ï¼ŒçŽ°æœ‰åŸºç¡€æ¨¡åž‹åœ¨çº¢å¤–ä»»åŠ¡ä¸­è¡¨çŽ°ä¸ä½³ï¼Œå­˜åœ¨ä¿¡æ¯ä¸¢å¤±ã€å…¨å±€å…³è”ä¸è¶³å’Œéžå‡åŒ€å™ªå£°é—®é¢˜
2. è®¾è®¡åŸºäºŽç†µçš„ç¡®å®šæ€§æŽ©ç ç­–ç•¥å’ŒåŒåŸŸå¼•å¯¼æ¨¡å—ï¼Œå¢žå¼ºä¿¡æ¯ä¿ç•™å¹¶å¤„ç†å™ªå£°ï¼Œæž„å»ºInf-590Kæ•°æ®é›†è¿›è¡Œé¢„è®­ç»ƒ
3. åœ¨çº¢å¤–ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²å’Œå°ç›®æ ‡æ£€æµ‹ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­éªŒè¯äº†æ–¹æ³•çš„ä¼˜è¶Šæ€§å’Œæ³›åŒ–èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Infrared imaging plays a critical role in low-light and adverse weather conditions. However, due to the distinct characteristics of infrared images, existing foundation models such as Masked Autoencoder (MAE) trained on visible data perform suboptimal in infrared image interpretation tasks. To bridge this gap, an infrared foundation model known as InfMAE was developed and pre-trained on large-scale infrared datasets. Despite its effectiveness, InfMAE still faces several limitations, including the omission of informative tokens, insufficient modeling of global associations, and neglect of non-uniform noise. In this paper, we propose a Dual-domain Guided Infrared foundation model based on MAE (DuGI-MAE). First, we design a deterministic masking strategy based on token entropy, preserving only high-entropy tokens for reconstruction to enhance informativeness. Next, we introduce a Dual-Domain Guidance (DDG) module, which simultaneously captures global token relationships and adaptively filters non-uniform background noise commonly present in infrared imagery. To facilitate large-scale pretraining, we construct Inf-590K, a comprehensive infrared image dataset encompassing diverse scenes, various target types, and multiple spatial resolutions. Pretrained on Inf-590K, DuGI-MAE demonstrates strong generalization capabilities across various downstream tasks, including infrared object detection, semantic segmentation, and small target detection. Experimental results validate the superiority of the proposed method over both supervised and self-supervised comparison methods. Our code is available in the supplementary material.

