---
layout: default
title: Prompt2Craft: Generating Functional Craft Assemblies with LLMs
---

# Prompt2Craft: Generating Functional Craft Assemblies with LLMs

**arXiv**: [2512.04568v1](https://arxiv.org/abs/2512.04568) | [PDF](https://arxiv.org/pdf/2512.04568.pdf)

**ä½œè€…**: Vitor Hideyo Isume, Takuya Kiyokawa, Natsuki Yamanobe, Yukiyasu Domae, Weiwei Wan, Kensuke Harada

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPrompt2Craftæ–¹æ³•ï¼Œåˆ©ç”¨LLMsç”ŸæˆåŠŸèƒ½æ€§æ‰‹å·¥ç»„è£…ï¼Œè§£å†³æœºå™¨äººåŸºäºŽå¯ç”¨ç‰©ä½“ç»„è£…ç›®æ ‡å¯¹è±¡çš„ä»»åŠ¡ã€‚**

**å…³é”®è¯**: `æœºå™¨äººç»„è£…` `ç›®æ ‡è¡¨ç¤º` `æŽ©ç åˆ†å‰²` `æ¨¡æ¿æ£€ç´¢` `å½¢çŠ¶ç®€åŒ–` `æ¯”ä¾‹åŒ¹é…`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨äººå¦‚ä½•ä»Žå¯ç”¨ç‰©ä½“ä¸­é€‰å–å­é›†ï¼Œç»„è£…æˆç›®æ ‡å¯¹è±¡çš„å‡†ç¡®è¡¨ç¤ºï¼Œç‰©ä½“ä¸ç›´æŽ¥å¯¹åº”ç›®æ ‡éƒ¨ä»¶ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æŽ©ç åˆ†å‰²ç½‘ç»œè¯†åˆ«å¯è§éƒ¨åˆ†ï¼Œæ£€ç´¢æ¨¡æ¿ç½‘æ ¼ï¼Œç®€åŒ–å½¢çŠ¶ï¼Œè®¾è®¡æœç´¢ç®—æ³•åŒ¹é…å±€éƒ¨å’Œå…¨å±€æ¯”ä¾‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä¸¤ç§åœºæ™¯ä¸­ä¸ŽåŸºçº¿æ–¹æ³•ç»“æžœç›¸å½“ï¼Œå¹¶åœ¨çœŸå®žåœºæ™¯ä¸­å±•ç¤ºå®šæ€§ç»“æžœã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Inspired by traditional handmade crafts, where a person improvises assemblies based on the available objects, we formally introduce the Craft Assembly Task. It is a robotic assembly task that involves building an accurate representation of a given target object using the available objects, which do not directly correspond to its parts. In this work, we focus on selecting the subset of available objects for the final craft, when the given input is an RGB image of the target in the wild. We use a mask segmentation neural network to identify visible parts, followed by retrieving labeled template meshes. These meshes undergo pose optimization to determine the most suitable template. Then, we propose to simplify the parts of the transformed template mesh to primitive shapes like cuboids or cylinders. Finally, we design a search algorithm to find correspondences in the scene based on local and global proportions. We develop baselines for comparison that consider all possible combinations, and choose the highest scoring combination for common metrics used in foreground maps and mask accuracy. Our approach achieves comparable results to the baselines for two different scenes, and we show qualitative results for an implementation in a real-world scenario.

