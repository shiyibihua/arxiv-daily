---
layout: default
title: WiFi-based Cross-Domain Gesture Recognition Using Attention Mechanism
---

# WiFi-based Cross-Domain Gesture Recognition Using Attention Mechanism

**arXiv**: [2512.04521v1](https://arxiv.org/abs/2512.04521) | [PDF](https://arxiv.org/pdf/2512.04521.pdf)

**ä½œè€…**: Ruijing Liu, Cunhua Pan, Jiaming Zeng, Hong Ren, Kezhi Wang, Lei Kong, Jiangzhou Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæ³¨æ„åŠ›æœºåˆ¶çš„WiFiè·¨åŸŸæ‰‹åŠ¿è¯†åˆ«ç½‘ç»œï¼Œä»¥è§£å†³çŽ°æœ‰æ–¹æ³•åœ¨æœªè®­ç»ƒçŽ¯å¢ƒä¸­æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `WiFiæ‰‹åŠ¿è¯†åˆ«` `è·¨åŸŸè¯†åˆ«` `æ³¨æ„åŠ›æœºåˆ¶` `å¤šæ™®å‹’é¢‘è°±` `ResNet18` `Widar3æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰WiFiæ‰‹åŠ¿è¯†åˆ«æ–¹æ³•åœ¨è·¨åŸŸï¼ˆæœªè®­ç»ƒçŽ¯å¢ƒï¼‰ä¸­æ€§èƒ½ä¸è¶³ï¼Œç¼ºä¹æ³›åŒ–èƒ½åŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä»ŽCSIæå–å¤šæ™®å‹’é¢‘è°±ç”Ÿæˆèžåˆå›¾åƒï¼Œç»“åˆå¤šè¯­ä¹‰ç©ºé—´æ³¨æ„åŠ›å’Œè‡ªæ³¨æ„åŠ›é€šé“æœºåˆ¶æž„å»ºç½‘ç»œï¼Œæå–åŸŸæ— å…³ç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Widar3æ•°æ®é›†ä¸Šï¼ŒåŸŸå†…å‡†ç¡®çŽ‡è¾¾99.72%ï¼Œè·¨åŸŸè¯†åˆ«è¾¾97.61%ï¼Œä¼˜äºŽçŽ°æœ‰æœ€ä½³æ–¹æ¡ˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While fulfilling communication tasks, wireless signals can also be used to sense the environment. Among various types of sensing media, WiFi signals offer advantages such as widespread availability, low hardware cost, and strong robustness to environmental conditions like light, temperature, and humidity. By analyzing Wi-Fi signals in the environment, it is possible to capture dynamic changes of the human body and accomplish sensing applications such as gesture recognition. Although many existing gesture sensing solutions perform well in-domain but lack cross-domain capabilities (i.e., recognition performance in untrained environments). To address this, we extract Doppler spectra from the channel state information (CSI) received by all receivers and concatenate each Doppler spectrum along the same time axis to generate fused images with multi-angle information as input features. Furthermore, inspired by the convolutional block attention module (CBAM), we propose a gesture recognition network that integrates a multi-semantic spatial attention mechanism with a self-attention-based channel mechanism. This network constructs attention maps to quantify the spatiotemporal features of gestures in images, enabling the extraction of key domain-independent features. Additionally, ResNet18 is employed as the backbone network to further capture deep-level features. To validate the network performance, we evaluate the proposed network on the public Widar3 dataset, and the results show that it not only maintains high in-domain accuracy of 99.72%, but also achieves high performance in cross-domain recognition of 97.61%, significantly outperforming existing best solutions.

