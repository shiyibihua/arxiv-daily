---
layout: default
title: Sequential Enumeration in Large Language Models
---

# Sequential Enumeration in Large Language Models

**arXiv**: [2512.04727v1](https://arxiv.org/abs/2512.04727) | [PDF](https://arxiv.org/pdf/2512.04727.pdf)

**ä½œè€…**: Kuinan Hou, Marco Zorzi, Alberto Testolin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æŽ¢ç©¶å¤§è¯­è¨€æ¨¡åž‹åœ¨åºåˆ—æžšä¸¾ä»»åŠ¡ä¸­çš„è®¡æ•°èƒ½åŠ›ä¸Žå±€é™æ€§**

**å…³é”®è¯**: `åºåˆ—æžšä¸¾` `å¤§è¯­è¨€æ¨¡åž‹` `è®¡æ•°èƒ½åŠ›` `æ€ç»´é“¾` `ç¥žç»ç¬¦å·å·®è·` `ç¦»æ•£ç¬¦å·å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è¯­è¨€æ¨¡åž‹èƒ½å¦ç³»ç»Ÿæ€§åœ°è®¡æ•°å’Œç”Ÿæˆç¦»æ•£ç¬¦å·åºåˆ—ï¼Œä»¥å¼¥åˆç¥žç»ä¸Žç¬¦å·æ–¹æ³•çš„å·®è·ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæµ‹è¯•äº”ç§å…ˆè¿›å¤§è¯­è¨€æ¨¡åž‹ï¼Œé€šè¿‡ä¸åŒæç¤ºæŒ‡ä»¤æŽ¢ç´¢æ€ç»´é“¾åœ¨è®¡æ•°ç­–ç•¥è‡ªå‘æ¶ŒçŽ°ä¸­çš„ä½œç”¨ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¨¡åž‹åœ¨æ˜Žç¡®æç¤ºä¸‹å¯è®¡æ•°ï¼Œä½†æ— æ³•è‡ªå‘è¿›è¡Œï¼Œè®¡æ•°èƒ½åŠ›æœªéšè§„æ¨¡æ‰©å±•è€Œç¨³å¥æå‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reliably counting and generating sequences of items remain a significant challenge for neural networks, including Large Language Models (LLMs). Indeed, although this capability is readily handled by rule-based symbolic systems based on serial computation, learning to systematically deploy counting procedures is difficult for neural models, which should acquire these skills through learning. Previous research has demonstrated that recurrent architectures can only approximately track and enumerate sequences of events, and it remains unclear whether modern deep learning systems, including LLMs, can deploy systematic counting procedures over sequences of discrete symbols. This paper aims to fill this gap by investigating the sequential enumeration abilities of five state-of-the-art LLMs, including proprietary, open-source, and reasoning models. We probe LLMs in sequential naming and production tasks involving lists of letters and words, adopting a variety of prompting instructions to explore the role of chain-of-thought in the spontaneous emerging of counting strategies. We also evaluate open-source models with the same architecture but increasing size to see whether the mastering of counting principles follows scaling laws, and we analyze the embedding dynamics during sequential enumeration to investigate the emergent encoding of numerosity. We find that some LLMs are indeed capable of deploying counting procedures when explicitly prompted to do so, but none of them spontaneously engage in counting when simply asked to enumerate the number of items in a sequence. Our results suggest that, despite their impressive emergent abilities, LLMs cannot yet robustly and systematically deploy counting procedures, highlighting a persistent gap between neural and symbolic approaches to compositional generalization.

