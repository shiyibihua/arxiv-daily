---
layout: default
title: BiTAgent: A Task-Aware Modular Framework for Bidirectional Coupling between Multimodal Large Language Models and World Models
---

# BiTAgent: A Task-Aware Modular Framework for Bidirectional Coupling between Multimodal Large Language Models and World Models

**arXiv**: [2512.04513v1](https://arxiv.org/abs/2512.04513) | [PDF](https://arxiv.org/pdf/2512.04513.pdf)

**ä½œè€…**: Yu-Wei Zhan, Xin Wang, Pengzhe Mao, Tongtong Feng, Ren Wang, Wenwu Zhu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBiTAgentæ¡†æž¶ï¼Œé€šè¿‡åŒå‘è€¦åˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ä¸Žä¸–ç•Œæ¨¡åž‹ï¼Œè§£å†³å¼€æ”¾ä¸–ç•Œå…·èº«æ™ºèƒ½ä¸­çš„è¯­ä¹‰ä¸ŽåŠ¨æ€å¯¹é½æŒ‘æˆ˜ã€‚**

**å…³é”®è¯**: `å…·èº«æ™ºèƒ½` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `ä¸–ç•Œæ¨¡åž‹` `åŒå‘è€¦åˆ` `ä»»åŠ¡æ„ŸçŸ¥å­¦ä¹ ` `è·¨çŽ¯å¢ƒæ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ä¸Žä¸–ç•Œæ¨¡åž‹ç»“åˆæ—¶ï¼Œè¯­ä¹‰æ„å›¾ä¸ŽåŠ¨æ€çŠ¶æ€è¡¨ç¤ºéš¾ä»¥ç´§å¯†è€¦åˆï¼Œä¸”ç¼ºä¹ä»»åŠ¡æ„ŸçŸ¥çš„é€‚åº”æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡å‰å‘è·¯å¾„æ³¨å…¥è¯­ä¹‰æŒ‡å¯¼æƒ³è±¡ï¼ŒåŽå‘è·¯å¾„é€šè¿‡å¯†é›†æ–‡æœ¬æ¡ä»¶å¥–åŠ±ä¼˜åŒ–è¯­ä¹‰ç©ºé—´ï¼Œå®žçŽ°åŒå‘äº¤äº’ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä»»åŠ¡å’Œè·¨çŽ¯å¢ƒè®¾ç½®ä¸­ï¼Œè¡¨çŽ°å‡ºä¼˜äºŽåŸºçº¿çš„ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼ŒæŽ¨åŠ¨å¼€æ”¾ä¸–ç•Œå…·èº«å­¦ä¹ ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Building generalist embodied agents requires a unified system that can interpret multimodal goals, model environment dynamics, and execute reliable actions across diverse real-world tasks. Multimodal large language models (MLLMs) offer strong semantic priors and cross-modal generalization, while world models (WMs) provide actionable latent dynamics for prediction and control. Their combination holds promise for open-ended embodied intelligence, yet introduces two key challenges: (1) establishing a tight coupling between the semantic intent from MLLMs and the dynamic state representations within the WM's latent space, and (2) achieving task-aware adaptability that supports multi-task learning and cross-environment generalization. To address these limitations, we propose BiTAgent, a task-aware dynamic joint framework that enables bidirectional coupling between MLLMs and WMs. BiTAgent establishes two complementary pathways: a forward path that injects MLLM representations into the WM's latent space for semantically guided imagination, and a backward path where WM-generated feedback refines the MLLM's semantic space via dense text-conditioned rewards. This bidirectional interaction is realized through three synergistic components: Task-Aware Dynamic Joint Learning, Task-Aware Behavior Learning, and MLLM-WM Joint Optimization, which together harmonize semantic reasoning and dynamic prediction. Extensive experiments across multi-task and cross-environment settings demonstrate superior stability and generalization over state-of-the-art baselines, marking a step toward open-ended embodied learning.

