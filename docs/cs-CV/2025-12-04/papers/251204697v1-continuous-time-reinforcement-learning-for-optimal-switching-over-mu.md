---
layout: default
title: Continuous-time reinforcement learning for optimal switching over multiple regimes
---

# Continuous-time reinforcement learning for optimal switching over multiple regimes

**arXiv**: [2512.04697v1](https://arxiv.org/abs/2512.04697) | [PDF](https://arxiv.org/pdf/2512.04697.pdf)

**ä½œè€…**: Yijie Huang, Mengge Li, Xiang Yu, Zhou Zhou

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¿žç»­æ—¶é—´å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œè§£å†³å¤šåˆ¶åº¦æœ€ä¼˜åˆ‡æ¢é—®é¢˜**

**å…³é”®è¯**: `è¿žç»­æ—¶é—´å¼ºåŒ–å­¦ä¹ ` `æœ€ä¼˜åˆ‡æ¢` `ç†µæ­£åˆ™åŒ–` `HJBæ–¹ç¨‹` `ç­–ç•¥è¿­ä»£` `ç¥žç»ç½‘ç»œç®—æ³•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç ”ç©¶å¤šåˆ¶åº¦æœ€ä¼˜åˆ‡æ¢çš„è¿žç»­æ—¶é—´å¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œé‡‡ç”¨ç†µæ­£åˆ™åŒ–æŽ¢ç´¢æ€§æ¡†æž¶
2. å»ºç«‹HJBæ–¹ç¨‹ç³»ç»Ÿé€‚å®šæ€§ï¼Œåˆ†æžç­–ç•¥è¿­ä»£æ”¶æ•›æ€§ï¼Œå¹¶è®¾è®¡åŸºäºŽéž…è¡¨å¾çš„RLç®—æ³•
3. æ•°å€¼å®žéªŒç»“åˆç¥žç»ç½‘ç»œéªŒè¯ç®—æ³•æœ‰æ•ˆæ€§ï¼Œå±•ç¤ºæ¸©åº¦å‚æ•°è¶‹é›¶æ—¶å€¼å‡½æ•°æ”¶æ•›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper studies the continuous-time reinforcement learning (RL) for optimal switching problems across multiple regimes. We consider a type of exploratory formulation under entropy regularization where the agent randomizes both the timing of switches and the selection of regimes through the generator matrix of an associated continuous-time finite-state Markov chain. We establish the well-posedness of the associated system of Hamilton-Jacobi-Bellman (HJB) equations and provide a characterization of the optimal policy. The policy improvement and the convergence of the policy iterations are rigorously established by analyzing the system of equations. We also show the convergence of the value function in the exploratory formulation towards the value function in the classical formulation as the temperature parameter vanishes. Finally, a reinforcement learning algorithm is devised and implemented by invoking the policy evaluation based on the martingale characterization. Our numerical examples with the aid of neural networks illustrate the effectiveness of the proposed RL algorithm.

