---
layout: default
title: Executable Governance for AI: Translating Policies into Rules Using LLMs
---

# Executable Governance for AI: Translating Policies into Rules Using LLMs

**arXiv**: [2512.04408v1](https://arxiv.org/abs/2512.04408) | [PDF](https://arxiv.org/pdf/2512.04408.pdf)

**ä½œè€…**: Gautam Varma Datla, Anudeep Vurity, Tejaswani Dash, Tazeem Ahmad, Mohd Adnan, Saima Rafi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPolicy-to-Testsæ¡†æž¶ï¼Œåˆ©ç”¨LLMså°†è‡ªç„¶è¯­è¨€AIæ”¿ç­–è½¬æ¢ä¸ºå¯æ‰§è¡Œè§„åˆ™ä»¥è§£å†³æ‰‹åŠ¨è½¬æ¢çš„ä½Žæ•ˆé—®é¢˜ã€‚**

**å…³é”®è¯**: `AIæ”¿ç­–æ‰§è¡Œ` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¯æ‰§è¡Œè§„åˆ™ç”Ÿæˆ` `LLMåº”ç”¨` `å®‰å…¨è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šAIæ”¿ç­–æŒ‡å—å¤šä¸ºæ–‡æœ¬ï¼Œæ‰‹åŠ¨è½¬æ¢ä¸ºå¯æ‰§è¡Œè§„åˆ™ç¼“æ…¢ã€æ˜“é”™ä¸”éš¾ä»¥æ‰©å±•ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼€å‘P2Tæ¡†æž¶ï¼Œé€šè¿‡LLMså’Œé¢†åŸŸç‰¹å®šè¯­è¨€å°†æ”¿ç­–æ–‡æ¡£æ ‡å‡†åŒ–ä¸ºæœºå™¨å¯è¯»è§„åˆ™ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šç§æ”¿ç­–ä¸Šæµ‹è¯•ï¼ŒAIç”Ÿæˆè§„åˆ™æŽ¥è¿‘äººç±»åŸºå‡†ï¼Œå¹¶åœ¨ç”Ÿæˆä»£ç†ä¸­éªŒè¯å®‰å…¨å½±å“ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> AI policy guidance is predominantly written as prose, which practitioners must first convert into executable rules before frameworks can evaluate or enforce them. This manual step is slow, error-prone, difficult to scale, and often delays the use of safeguards in real-world deployments. To address this gap, we present Policy-to-Tests (P2T), a framework that converts natural-language policy documents into normalized, machine-readable rules. The framework comprises a pipeline and a compact domain-specific language (DSL) that encodes hazards, scope, conditions, exceptions, and required evidence, yielding a canonical representation of extracted rules. To test the framework beyond a single policy, we apply it across general frameworks, sector guidance, and enterprise standards, extracting obligation-bearing clauses and converting them into executable rules. These AI-generated rules closely match strong human baselines on span-level and rule-level metrics, with robust inter-annotator agreement on the gold set. To evaluate downstream behavioral and safety impact, we add HIPAA-derived safeguards to a generative agent and compare it with an otherwise identical agent without guardrails. An LLM-based judge, aligned with gold-standard criteria, measures violation rates and robustness to obfuscated and compositional prompts. Detailed results are provided in the appendix. We release the codebase, DSL, prompts, and rule sets as open-source resources to enable reproducible evaluation.

