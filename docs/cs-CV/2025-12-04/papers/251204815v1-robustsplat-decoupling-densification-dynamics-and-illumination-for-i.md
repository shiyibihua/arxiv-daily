---
layout: default
title: RobustSplat++: Decoupling Densification, Dynamics, and Illumination for In-the-Wild 3DGS
---

# RobustSplat++: Decoupling Densification, Dynamics, and Illumination for In-the-Wild 3DGS

**arXiv**: [2512.04815v1](https://arxiv.org/abs/2512.04815) | [PDF](https://arxiv.org/pdf/2512.04815.pdf)

**ä½œè€…**: Chuanyu Fu, Guanying Chen, Yuqi Zhang, Kunbin Yao, Yuan Xiong, Chuan Huang, Shuguang Cui, Yasuyuki Matsushita, Xiaochun Cao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRobustSplat++ä»¥è§£å†³é‡Žå¤–åœºæ™¯ä¸­3Dé«˜æ–¯æ³¼æº…çš„çž¬æ€å¯¹è±¡å’Œå…‰ç…§å¹²æ‰°é—®é¢˜**

**å…³é”®è¯**: `3Dé«˜æ–¯æ³¼æº…` `é‡Žå¤–åœºæ™¯å»ºæ¨¡` `çž¬æ€å¯¹è±¡å¤„ç†` `å…‰ç…§å˜åŒ–é²æ£’æ€§` `å»¶è¿Ÿé«˜æ–¯å¢žé•¿` `æŽ©ç å¼•å¯¼`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰3DGSæ–¹æ³•åœ¨é‡Žå¤–åœºæ™¯ä¸­å› çž¬æ€å¯¹è±¡å’Œå…‰ç…§å˜åŒ–å¯¼è‡´æ¸²æŸ“ä¼ªå½±ï¼Œé«˜æ–¯è‡´å¯†åŒ–è¿‡ç¨‹åŠ å‰§äº†è¿™ä¸€é—®é¢˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å»¶è¿Ÿé«˜æ–¯å¢žé•¿ç­–ç•¥ä¼˜å…ˆä¼˜åŒ–é™æ€ç»“æž„ï¼Œç»“åˆå°ºåº¦çº§è”æŽ©ç å¼•å¯¼å®žçŽ°ä»Žä½Žåˆ°é«˜åˆ†è¾¨çŽ‡çš„å¯é çž¬æ€æŽ©ç ä¼°è®¡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæŒ‘æˆ˜æ€§æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæ–¹æ³•ä¼˜äºŽçŽ°æœ‰æŠ€æœ¯ï¼Œå±•çŽ°å‡ºé²æ£’æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> 3D Gaussian Splatting (3DGS) has gained significant attention for its real-time, photo-realistic rendering in novel-view synthesis and 3D modeling. However, existing methods struggle with accurately modeling in-the-wild scenes affected by transient objects and illuminations, leading to artifacts in the rendered images. We identify that the Gaussian densification process, while enhancing scene detail capture, unintentionally contributes to these artifacts by growing additional Gaussians that model transient disturbances and illumination variations. To address this, we propose RobustSplat++, a robust solution based on several critical designs. First, we introduce a delayed Gaussian growth strategy that prioritizes optimizing static scene structure before allowing Gaussian splitting/cloning, mitigating overfitting to transient objects in early optimization. Second, we design a scale-cascaded mask bootstrapping approach that first leverages lower-resolution feature similarity supervision for reliable initial transient mask estimation, taking advantage of its stronger semantic consistency and robustness to noise, and then progresses to high-resolution supervision to achieve more precise mask prediction. Third, we incorporate the delayed Gaussian growth strategy and mask bootstrapping with appearance modeling to handling in-the-wild scenes including transients and illuminations. Extensive experiments on multiple challenging datasets show that our method outperforms existing methods, clearly demonstrating the robustness and effectiveness of our method.

