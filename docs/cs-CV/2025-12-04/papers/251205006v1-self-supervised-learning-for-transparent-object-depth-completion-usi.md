---
layout: default
title: Self-Supervised Learning for Transparent Object Depth Completion Using Depth from Non-Transparent Objects
---

# Self-Supervised Learning for Transparent Object Depth Completion Using Depth from Non-Transparent Objects

**arXiv**: [2512.05006v1](https://arxiv.org/abs/2512.05006) | [PDF](https://arxiv.org/pdf/2512.05006.pdf)

**ä½œè€…**: Xianghui Fan, Zhaoyu Chen, Mengyang Pan, Anping Deng, Hang Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªç›‘ç£æ·±åº¦è¡¥å…¨æ–¹æ³•ï¼Œåˆ©ç”¨éžé€æ˜Žç‰©ä½“æ·±åº¦æ¨¡æ‹Ÿé€æ˜Žç‰©ä½“æ·±åº¦ç¼ºå¤±ä»¥è§£å†³æ ‡æ³¨æˆæœ¬é«˜é—®é¢˜**

**å…³é”®è¯**: `é€æ˜Žç‰©ä½“æ„ŸçŸ¥` `æ·±åº¦è¡¥å…¨` `è‡ªç›‘ç£å­¦ä¹ ` `æ·±åº¦ä¼ æ„Ÿå™¨` `æ¨¡æ‹Ÿè®­ç»ƒ` `å°æ ·æœ¬å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé€æ˜Žç‰©ä½“å› å…‰æŠ˜å°„åå°„å¯¼è‡´æ·±åº¦ä¼ æ„Ÿå™¨éš¾ä»¥æ„ŸçŸ¥ï¼Œä¼ ç»Ÿç›‘ç£æ–¹æ³•ä¾èµ–æ˜‚è´µæ ‡æ³¨æ•°æ®
2. æ–¹æ³•è¦ç‚¹ï¼šåœ¨éžé€æ˜ŽåŒºåŸŸæ¨¡æ‹Ÿé€æ˜Žç‰©ä½“æ·±åº¦ç¼ºå¤±ï¼Œä½¿ç”¨åŽŸå§‹æ·±åº¦å›¾ä½œä¸ºè‡ªç›‘ç£çœŸå€¼è®­ç»ƒç½‘ç»œ
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ–¹æ³•æ€§èƒ½æŽ¥è¿‘ç›‘ç£æ–¹æ³•ï¼Œå°æ ·æœ¬ä¸‹é¢„è®­ç»ƒå¯æå‡æ¨¡åž‹æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The perception of transparent objects is one of the well-known challenges in computer vision. Conventional depth sensors have difficulty in sensing the depth of transparent objects due to refraction and reflection of light. Previous research has typically train a neural network to complete the depth acquired by the sensor, and this method can quickly and accurately acquire accurate depth maps of transparent objects. However, previous training relies on a large amount of annotation data for supervision, and the labeling of depth maps is costly. To tackle this challenge, we propose a new self-supervised method for training depth completion networks. Our method simulates the depth deficits of transparent objects within non-transparent regions and utilizes the original depth map as ground truth for supervision. Experiments demonstrate that our method achieves performance comparable to supervised approach, and pre-training with our method can improve the model performance when the training samples are small.

