---
layout: default
title: Towards Ethical Multi-Agent Systems of Large Language Models: A Mechanistic Interpretability Perspective
---

# Towards Ethical Multi-Agent Systems of Large Language Models: A Mechanistic Interpretability Perspective

**arXiv**: [2512.04691v1](https://arxiv.org/abs/2512.04691) | [PDF](https://arxiv.org/pdf/2512.04691.pdf)

**ä½œè€…**: Jae Hee Lee, Anne Lauscher, Stefano V. Albrecht

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæœºåˆ¶å¯è§£é‡Šæ€§çš„ç ”ç©¶è®®ç¨‹ï¼Œä»¥è§£å†³å¤§è¯­è¨€æ¨¡åž‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„ä¼¦ç†æŒ‘æˆ˜**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `ä¼¦ç†è¡Œä¸ºè¯„ä¼°` `æœºåˆ¶å¯è§£é‡Šæ€§` `å‚æ•°é«˜æ•ˆå¯¹é½` `å¤šæ™ºèƒ½ä½“äº¤äº’`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è¯­è¨€æ¨¡åž‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å¢žå¼ºèƒ½åŠ›çš„åŒæ—¶ï¼Œå¼•å‘æ˜¾è‘—çš„ä¼¦ç†è¡Œä¸ºæŒ‘æˆ˜
2. æ–¹æ³•è¦ç‚¹ï¼šä»Žæœºåˆ¶å¯è§£é‡Šæ€§è§†è§’ï¼Œå¼€å‘è¯„ä¼°æ¡†æž¶ã€é˜æ˜Žå†…éƒ¨æœºåˆ¶ã€å®žæ–½å‚æ•°é«˜æ•ˆå¯¹é½æŠ€æœ¯
3. å®žéªŒæˆ–æ•ˆæžœï¼šæœªçŸ¥ï¼Œæœ¬æ–‡ä¸ºç«‹åœºè®ºæ–‡ï¼Œä¸»è¦æ¦‚è¿°ç ”ç©¶è®®ç¨‹è€Œéžå…·ä½“å®žéªŒ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large language models (LLMs) have been widely deployed in various applications, often functioning as autonomous agents that interact with each other in multi-agent systems. While these systems have shown promise in enhancing capabilities and enabling complex tasks, they also pose significant ethical challenges. This position paper outlines a research agenda aimed at ensuring the ethical behavior of multi-agent systems of LLMs (MALMs) from the perspective of mechanistic interpretability. We identify three key research challenges: (i) developing comprehensive evaluation frameworks to assess ethical behavior at individual, interactional, and systemic levels; (ii) elucidating the internal mechanisms that give rise to emergent behaviors through mechanistic interpretability; and (iii) implementing targeted parameter-efficient alignment techniques to steer MALMs towards ethical behaviors without compromising their performance.

