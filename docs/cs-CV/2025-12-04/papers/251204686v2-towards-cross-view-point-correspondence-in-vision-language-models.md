---
layout: default
title: Towards Cross-View Point Correspondence in Vision-Language Models
---

# Towards Cross-View Point Correspondence in Vision-Language Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.04686" target="_blank" class="toolbar-btn">arXiv: 2512.04686v2</a>
    <a href="https://arxiv.org/pdf/2512.04686.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.04686v2" 
            onclick="toggleFavorite(this, '2512.04686v2', 'Towards Cross-View Point Correspondence in Vision-Language Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yipu Wang, Yuheng Ji, Yuyang Liu, Enshen Zhou, Ziqiang Yang, Yuxuan Tian, Ziheng Qin, Yue Liu, Huajie Tan, Cheng Chi, Zhiyuan Ma, Daniel Dajun Zeng, Xiaolong Zheng

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-04 (Êõ¥Êñ∞: 2025-12-07)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/WangYipu2002/CrossPoint)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫CrossPoint-BenchÂíåCroPondÊ®°ÂûãÔºåËß£ÂÜ≥ËßÜËßâËØ≠Ë®ÄÊ®°Âûã‰∏≠Ë∑®ËßÜËßíÁÇπÂØπÂ∫îÈöæÈ¢ò„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `Ë∑®ËßÜËßíÂØπÂ∫î` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `ÁÇπÂØπÂ∫î` `Âü∫ÂáÜÊµãËØï` `Êï∞ÊçÆÈõÜ` `ÂÖ∑Ë∫´Êô∫ËÉΩ` `Êú∫Âô®‰∫∫ÂØºËà™`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®Ë∑®ËßÜËßíÁÇπÂØπÂ∫îÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÂú®Á≤æÁ°ÆÁÇπÁ∫ßÂØπÂ∫î‰∏äÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®ÂÖ∑Ë∫´Êô∫ËÉΩ‰∏≠ÁöÑÂ∫îÁî®„ÄÇ
2. ÊèêÂá∫CrossPoint-BenchÂü∫ÂáÜÊµãËØïÂíåCrossPoint-378KÊï∞ÊçÆÈõÜÔºåÂπ∂ËÆæËÆ°CroPondÊ®°ÂûãÔºå‰ª•ÊèêÂçáÊ®°ÂûãÂú®Ë∑®ËßÜËßíÁÇπÂØπÂ∫î‰ªªÂä°‰∏äÁöÑÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCroPondÊ®°ÂûãÂú®CrossPoint-Bench‰∏äË∂ÖË∂ä‰∫ÜGemini-2.5-ProÔºåÂáÜÁ°ÆÁéáÊèêÂçá‰∫Ü39.7%ÔºåÊòæËëóÊèêÈ´ò‰∫ÜË∑®ËßÜËßíÁÇπÂØπÂ∫îÁöÑÁ≤æÂ∫¶„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ë∑®ËßÜËßíÂØπÂ∫îÊòØÁ©∫Èó¥ÁêÜËß£ÂíåÂÖ∑Ë∫´Êô∫ËÉΩÁöÑ‰∏ÄÈ°πÂü∫Êú¨ËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåËßÜËßâËØ≠Ë®ÄÊ®°Âûã(VLMs)Âú®ËøôÊñπÈù¢‰ªçÊúâ‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂÆûÁé∞Á≤æÁ°ÆÁöÑÁÇπÁ∫ßÂØπÂ∫îÊñπÈù¢ÔºåËøôÂØπ‰∫éÁ≤æÁ°ÆÁöÑ‰∫§‰∫íËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜË∑®ËßÜËßíÁÇπÂØπÂ∫î(CVPC)‰ªªÂä°ÂíåCrossPoint-BenchÔºåËøôÊòØ‰∏Ä‰∏™ÁªºÂêàÊÄßÁöÑÂü∫ÂáÜÔºåÂÖ∂ÂàÜÂ±ÇËÆæËÆ°ÁÅµÊÑüÊù•Ê∫ê‰∫é‰∫∫Á±ª‚ÄúÊÑüÁü•‚Äù„ÄÅ‚ÄúÊé®ÁêÜ‚ÄùÂíå‚ÄúÂØπÂ∫î‚ÄùÁöÑËÆ§Áü•ËøáÁ®ã„ÄÇÊàë‰ª¨ÁöÑËØÑ‰º∞Ë°®ÊòéÔºåÊúÄÂÖàËøõÁöÑÊ®°Âûã(‰æãÂ¶ÇÔºåGemini-2.5-Pro)‰ªçÁÑ∂ËøúËøúËêΩÂêé‰∫é‰∫∫Á±ªÔºåÊÄª‰ΩìÂáÜÁ°ÆÁéáÂ∑ÆË∑ùË∂ÖËøá54.65%ÔºåËøôÊö¥Èú≤‰∫Ü‰ªéÁ≤óÁ≤íÂ∫¶Âà§Êñ≠Âà∞ÁªÜÁ≤íÂ∫¶ÂùêÊ†áÈ¢ÑÊµãÁöÑÊåëÊàò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊûÑÂª∫‰∫ÜCrossPoint-378KÊï∞ÊçÆÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´900‰∏™Âú∫ÊôØ‰∏≠378K‰∏™ÈóÆÁ≠îÂØπÔºåÈáçÁÇπÂÖ≥Ê≥®ÂèØÊìç‰ΩúÁöÑÂå∫ÂüüÔºåÊõ¥Â•ΩÂú∞ÂèçÊò†‰∫ÜÁé∞ÂÆû‰∏ñÁïåÁöÑÊìç‰ΩúÂíå‰∫§‰∫íÂú∫ÊôØ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÂú®CrossPoint-378KÊï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉÁöÑCroPond„ÄÇÊàë‰ª¨ÁöÑCroPondÂú®CrossPoint-Bench‰∏äÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂáÜÁ°ÆÁéáË∂ÖËøáGemini-2.5-Pro 39.7%ÔºåËøô‰∏∫Êé®ËøõÊú™Êù•Ë∑®ËßÜËßíÂØπÂ∫îÂ∑•‰ΩúÂ•†ÂÆö‰∫ÜÂü∫Á°Ä„ÄÇËØ•Âü∫ÂáÜ„ÄÅÊï∞ÊçÆÈõÜÂíåÊ®°ÂûãÂ∑≤Âú®https://github.com/WangYipu2002/CrossPointÂÖ¨ÂºÄÂèëÂ∏É„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®Ë∑®ËßÜËßíÂú∫ÊôØ‰∏ãÔºåÈöæ‰ª•Âª∫Á´ãÁ≤æÁ°ÆÁÇπÂØπÂ∫îÂÖ≥Á≥ªÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Âè™ËÉΩËøõË°åÁ≤óÁ≤íÂ∫¶ÁöÑÂà§Êñ≠ÔºåÊó†Ê≥ïÂáÜÁ°ÆÈ¢ÑÊµãÁõÆÊ†áÁÇπÂú®‰∏çÂêåËßÜËßí‰∏ãÁöÑÂùêÊ†áÔºåËøôÈôêÂà∂‰∫ÜÂÖ∂Âú®ÈúÄË¶ÅÁ≤æÁªÜÊìç‰ΩúÁöÑÂÖ∑Ë∫´Êô∫ËÉΩ‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™Êõ¥ÂÖ∑ÊåëÊàòÊÄßÁöÑÂü∫ÂáÜÊµãËØïCrossPoint-BenchÂíå‰∏Ä‰∏™Â§ßËßÑÊ®°Êï∞ÊçÆÈõÜCrossPoint-378KÔºåÂπ∂Âú®Ê≠§Âü∫Á°Ä‰∏äËÆ≠ÁªÉ‰∏Ä‰∏™‰∏ìÈó®ÁöÑÊ®°ÂûãCroPond„ÄÇÈÄöËøáÊõ¥ÁªÜÁ≤íÂ∫¶ÁöÑÊï∞ÊçÆÂíåÊõ¥ÊúâÊïàÁöÑËÆ≠ÁªÉÊñπÊ≥ïÔºåÊèêÂçáÊ®°ÂûãÂú®Ë∑®ËßÜËßíÁÇπÂØπÂ∫î‰ªªÂä°‰∏äÁöÑÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÈÉ®ÂàÜÔºö1) CrossPoint-BenchÂü∫ÂáÜÊµãËØïÔºåÁî®‰∫éËØÑ‰º∞Ê®°ÂûãÂú®Ë∑®ËßÜËßíÁÇπÂØπÂ∫î‰ªªÂä°‰∏äÁöÑÊÄßËÉΩÔºõ2) CrossPoint-378KÊï∞ÊçÆÈõÜÔºåÂåÖÂê´Â§ßÈáè‰∏çÂêåËßÜËßí‰∏ãÁöÑÈóÆÁ≠îÂØπÔºåÁî®‰∫éËÆ≠ÁªÉÊ®°ÂûãÔºõ3) CroPondÊ®°ÂûãÔºåÂü∫‰∫éËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÊû∂ÊûÑÔºåÈÄöËøáÂú®CrossPoint-378KÊï∞ÊçÆÈõÜ‰∏äËøõË°åËÆ≠ÁªÉÔºåÊèêÂçáË∑®ËßÜËßíÁÇπÂØπÂ∫îÁöÑËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫ÜCrossPoint-BenchÂü∫ÂáÜÊµãËØïÔºåËØ•Âü∫ÂáÜÊµãËØïÊõ¥ÂÖ∑ÊåëÊàòÊÄßÔºåËÉΩÂ§üÊõ¥ÂÖ®Èù¢Âú∞ËØÑ‰º∞Ê®°ÂûãÂú®Ë∑®ËßÜËßíÁÇπÂØπÂ∫î‰ªªÂä°‰∏äÁöÑÊÄßËÉΩÔºõ2) ÊûÑÂª∫‰∫ÜCrossPoint-378KÊï∞ÊçÆÈõÜÔºåËØ•Êï∞ÊçÆÈõÜÂåÖÂê´Â§ßÈáèÈ´òË¥®ÈáèÁöÑÈóÆÁ≠îÂØπÔºåËÉΩÂ§üÊúâÊïàÊèêÂçáÊ®°ÂûãÁöÑËÆ≠ÁªÉÊïàÊûúÔºõ3) ÊèêÂá∫‰∫ÜCroPondÊ®°ÂûãÔºåËØ•Ê®°ÂûãÂú®CrossPoint-Bench‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöCrossPoint-BenchÂü∫ÂáÜÊµãËØïÈááÁî®ÂàÜÂ±ÇËÆæËÆ°ÔºåÊ®°Êãü‰∫∫Á±ªÁöÑËÆ§Áü•ËøáÁ®ãÔºåÂåÖÂê´‚ÄúÊÑüÁü•‚Äù„ÄÅ‚ÄúÊé®ÁêÜ‚ÄùÂíå‚ÄúÂØπÂ∫î‚Äù‰∏â‰∏™Èò∂ÊÆµ„ÄÇCrossPoint-378KÊï∞ÊçÆÈõÜÈáçÁÇπÂÖ≥Ê≥®ÂèØÊìç‰ΩúÁöÑÂå∫ÂüüÔºåÊõ¥Â•ΩÂú∞ÂèçÊò†‰∫ÜÁé∞ÂÆû‰∏ñÁïåÁöÑÊìç‰ΩúÂíå‰∫§‰∫íÂú∫ÊôØ„ÄÇCroPondÊ®°ÂûãÁöÑÂÖ∑‰ΩìÁΩëÁªúÁªìÊûÑÂíåÊçüÂ§±ÂáΩÊï∞Á≠âÊäÄÊúØÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠Êú™ËØ¶ÁªÜËØ¥ÊòéÔºåÂ±û‰∫éÊú™Áü•‰ø°ÊÅØ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

CroPondÊ®°ÂûãÂú®CrossPoint-BenchÂü∫ÂáÜÊµãËØï‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂáÜÁ°ÆÁéáË∂ÖËøá‰∫ÜGemini-2.5-Pro 39.7%„ÄÇËøô‰∏ÄÁªìÊûúË°®ÊòéÔºåÈÄöËøáÊûÑÂª∫Êõ¥ÂÖ∑ÊåëÊàòÊÄßÁöÑÂü∫ÂáÜÊµãËØïÂíåÊõ¥Â§ßËßÑÊ®°ÁöÑÊï∞ÊçÆÈõÜÔºåÂπ∂Âú®Ê≠§Âü∫Á°Ä‰∏äËøõË°åÈíàÂØπÊÄßÁöÑÊ®°ÂûãËÆ≠ÁªÉÔºåÂèØ‰ª•ÊúâÊïàÊèêÂçáËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®Ë∑®ËßÜËßíÁÇπÂØπÂ∫î‰ªªÂä°‰∏äÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÁâ©‰ΩìÊäìÂèñ„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÂçáËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®Ë∑®ËßÜËßíÁÇπÂØπÂ∫îÊñπÈù¢ÁöÑËÉΩÂäõÔºåÂèØ‰ª•‰ΩøÊú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÁêÜËß£Âë®Âõ¥ÁéØÂ¢ÉÔºåÂπ∂ËøõË°åÊõ¥Á≤æÁ°ÆÁöÑÊìç‰Ωú„ÄÇ‰æãÂ¶ÇÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Ê†πÊçÆÁî®Êà∑ÁöÑÊåá‰ª§ÔºåÂú®‰∏çÂêåËßÜËßí‰∏ãÂáÜÁ°ÆÊâæÂà∞ÁõÆÊ†áÁâ©‰ΩìÂπ∂ËøõË°åÊäìÂèñÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Êô∫ËÉΩÁöÑ‰∫∫Êú∫‰∫§‰∫í„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Cross-view correspondence is a fundamental capability for spatial understanding and embodied AI. However, it is still far from being realized in Vision-Language Models (VLMs), especially in achieving precise point-level correspondence, which is crucial for precise affordance interaction. So we propose the Cross-View Point Correspondence (CVPC) task and CrossPoint-Bench, a comprehensive benchmark with hierarchical design, inspired by the human cognitive process of "perceive", "reason", and "correspond". Our evaluation shows the state-of-the-art models (e.g., Gemini-2.5-Pro) still fall far behind humans, with a gap of over 54.65% in overall accuracy, exposing a challenge in transitioning from coarse-grained judgement to fine-grained coordinate prediction. To address this problem, we construct CrossPoint-378K, a dataset with 378K question-answering pairs across 900 scenes, focused on actionable affordance regions that better reflect real-world manipulation and interaction scenarios. Furthermore, we propose CroPond that trained on the CrossPoint-378K dataset. Our CroPond achieves state-of-the-art performance on CrossPoint-Bench, surpassing Gemini-2.5-Pro by 39.7% accuracy, which offers a foundation for advancing future work on cross-view correspondence. The benchmark, dataset, and model are publicly available at https://github.com/WangYipu2002/CrossPoint.

