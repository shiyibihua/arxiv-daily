---
layout: default
title: Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot
---

# Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot

**arXiv**: [2512.04599v1](https://arxiv.org/abs/2512.04599) | [PDF](https://arxiv.org/pdf/2512.04599.pdf)

**ä½œè€…**: Sheng Hang, Chaoxiang He, Hongsheng Hu, Hanqing Hu, Bin Benjamin Zhu, Shi-Feng Sun, Dawu Gu, Shuo Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé›¶æ¬¡å­¦ä¹ è§†è§‰-è¯­è¨€åˆ†å‰²èžåˆæ–¹æ³•ï¼Œå®žçŽ°æ¶æ„å›¾åƒæ£€æµ‹ã€å…ƒç´ è¯†åˆ«ä¸Žå®šä½ä¸€ä½“åŒ–**

**å…³é”®è¯**: `æ¶æ„å›¾åƒæ£€æµ‹` `è§†è§‰-è¯­è¨€èžåˆ` `é›¶æ¬¡å­¦ä¹ ` `åƒç´ çº§å®šä½` `å¯¹æŠ—é²æ£’æ€§` `å¼€æ”¾è¯æ±‡æç¤º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ¶æ„å›¾åƒæ£€æµ‹éœ€è¶…è¶Šå›¾åƒçº§æ ‡ç­¾ï¼Œå®žçŽ°å…ƒç´ çº§è¯†åˆ«ä¸Žåƒç´ çº§å®šä½
2. æ–¹æ³•è¦ç‚¹ï¼šèžåˆåŸºç¡€åˆ†å‰²æ¨¡åž‹ä¸Žè§†è§‰è¯­è¨€æ¨¡åž‹ï¼Œé€šè¿‡å¼€æ”¾è¯æ±‡æç¤ºè¯„åˆ†å¹¶åŠ æƒèžåˆç”Ÿæˆæ¶æ„å¯¹è±¡å›¾
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨790å¼ å›¾åƒæ•°æ®é›†ä¸Šè¾¾åˆ°85.8%å…ƒç´ çº§å¬å›žçŽ‡ï¼Œå¯¹æŠ—æ”»å‡»ä¸‹æ€§èƒ½ä¸‹é™ä¸è¶…è¿‡10%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Detecting illicit visual content demands more than image-level NSFW flags; moderators must also know what objects make an image illegal and where those objects occur. We introduce a zero-shot pipeline that simultaneously (i) detects if an image contains harmful content, (ii) identifies each critical element involved, and (iii) localizes those elements with pixel-accurate masks - all in one pass. The system first applies foundation segmentation model (SAM) to generate candidate object masks and refines them into larger independent regions. Each region is scored for malicious relevance by a vision-language model using open-vocabulary prompts; these scores weight a fusion step that produces a consolidated malicious object map. An ensemble across multiple segmenters hardens the pipeline against adaptive attacks that target any single segmentation method. Evaluated on a newly-annotated 790-image dataset spanning drug, sexual, violent and extremist content, our method attains 85.8% element-level recall, 78.1% precision and a 92.1% segment-success rate - exceeding direct zero-shot VLM localization by 27.4% recall at comparable precision. Against PGD adversarial perturbations crafted to break SAM and VLM, our method's precision and recall decreased by no more than 10%, demonstrating high robustness against attacks. The full pipeline processes an image in seconds, plugs seamlessly into existing VLM workflows, and constitutes the first practical tool for fine-grained, explainable malicious-image moderation.

