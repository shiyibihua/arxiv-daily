---
layout: default
title: HTR-ConvText: Leveraging Convolution and Textual Information for Handwritten Text Recognition
---

# HTR-ConvText: Leveraging Convolution and Textual Information for Handwritten Text Recognition

**arXiv**: [2512.05021v1](https://arxiv.org/abs/2512.05021) | [PDF](https://arxiv.org/pdf/2512.05021.pdf)

**ä½œè€…**: Pham Thach Thanh Truc, Dang Hoai Nam, Huynh Tong Dang Khoa, Vo Nguyen Le Duy

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHTR-ConvTextæ¨¡åž‹ï¼Œç»“åˆå·ç§¯ä¸Žæ–‡æœ¬ä¿¡æ¯ä»¥æå‡æ‰‹å†™æ–‡æœ¬è¯†åˆ«çš„æ³›åŒ–èƒ½åŠ›ã€‚**

**å…³é”®è¯**: `æ‰‹å†™æ–‡æœ¬è¯†åˆ«` `å·ç§¯ç¥žç»ç½‘ç»œ` `MobileViT` `ä¸Šä¸‹æ–‡ç¼–ç ` `æœ‰é™æ•°æ®æ³›åŒ–` `åºåˆ—å»ºæ¨¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‰‹å†™æ–‡æœ¬è¯†åˆ«é¢ä¸´æ•°æ®æœ‰é™ã€ä¹¦å†™é£Žæ ¼å¤šæ ·å’Œå¤æ‚å˜éŸ³ç¬¦å·çš„æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆæ®‹å·®CNNä¸ŽMobileViTæå–ç‰¹å¾ï¼Œå¹¶å¼•å…¥ConvTextç¼–ç å™¨ç»“åˆå…¨å±€ä¸Šä¸‹æ–‡ä¸Žå±€éƒ¨ç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨IAMç­‰æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œåœ¨æœ‰é™æ ·æœ¬å’Œé«˜å¤šæ ·æ€§åœºæ™¯ä¸‹æ€§èƒ½ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Handwritten Text Recognition remains challenging due to the limited data, high writing style variance, and scripts with complex diacritics. Existing approaches, though partially address these issues, often struggle to generalize without massive synthetic data. To address these challenges, we propose HTR-ConvText, a model designed to capture fine-grained, stroke-level local features while preserving global contextual dependencies. In the feature extraction stage, we integrate a residual Convolutional Neural Network backbone with a MobileViT with Positional Encoding block. This enables the model to both capture structural patterns and learn subtle writing details. We then introduce the ConvText encoder, a hybrid architecture combining global context and local features within a hierarchical structure that reduces sequence length for improved efficiency. Additionally, an auxiliary module injects textual context to mitigate the weakness of Connectionist Temporal Classification. Evaluations on IAM, READ2016, LAM and HANDS-VNOnDB demonstrate that our approach achieves improved performance and better generalization compared to existing methods, especially in scenarios with limited training samples and high handwriting diversity.

