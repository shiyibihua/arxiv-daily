---
layout: default
title: OmniScaleSR: Unleashing Scale-Controlled Diffusion Prior for Faithful and Realistic Arbitrary-Scale Image Super-Resolution
---

# OmniScaleSR: Unleashing Scale-Controlled Diffusion Prior for Faithful and Realistic Arbitrary-Scale Image Super-Resolution

**arXiv**: [2512.04699v1](https://arxiv.org/abs/2512.04699) | [PDF](https://arxiv.org/pdf/2512.04699.pdf)

**ä½œè€…**: Xinning Chai, Zhengxue Cheng, Yuhong Zhang, Hengsheng Zhang, Yingsheng Qin, Yucai Yang, Rong Xie, Li Song

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmniScaleSRä»¥è§£å†³ä»»æ„å°ºåº¦è¶…åˆ†è¾¨çŽ‡ä¸­çœŸå®žæ€§ä¸Žä¿çœŸåº¦å¹³è¡¡é—®é¢˜**

**å…³é”®è¯**: `ä»»æ„å°ºåº¦è¶…åˆ†è¾¨çŽ‡` `æ‰©æ•£æ¨¡åž‹` `å°ºåº¦æŽ§åˆ¶` `çœŸå®žæ€§å¢žå¼º` `ä¿çœŸåº¦ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ä»»æ„å°ºåº¦è¶…åˆ†è¾¨çŽ‡æ–¹æ³•åœ¨è¶…é«˜å°ºåº¦ä¸‹æ˜“äº§ç”Ÿè¿‡åº¦å¹»è§‰æˆ–æ¨¡ç³Šè¾“å‡ºï¼Œç¼ºä¹æ˜¾å¼å°ºåº¦æŽ§åˆ¶ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥æ˜¾å¼æ‰©æ•£åŽŸç”Ÿå°ºåº¦æŽ§åˆ¶æœºåˆ¶ï¼Œç»“åˆéšå¼å°ºåº¦é€‚åº”ï¼Œå®žçŽ°å°ºåº¦ä¸Žå†…å®¹æ„ŸçŸ¥çš„æ‰©æ•£è¿‡ç¨‹è°ƒåˆ¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŒä¸‰æ¬¡é™è´¨åŸºå‡†å’ŒçœŸå®žæ•°æ®é›†ä¸Šï¼Œè¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨æ”¾å¤§å€æ•°å¤§æ—¶è¡¨çŽ°ä¼˜å¼‚ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Arbitrary-scale super-resolution (ASSR) overcomes the limitation of traditional super-resolution (SR) methods that operate only at fixed scales (e.g., 4x), enabling a single model to handle arbitrary magnification. Most existing ASSR approaches rely on implicit neural representation (INR), but its regression-driven feature extraction and aggregation intrinsically limit the ability to synthesize fine details, leading to low realism. Recent diffusion-based realistic image super-resolution (Real-ISR) models leverage powerful pre-trained diffusion priors and show impressive results at the 4x setting. We observe that they can also achieve ASSR because the diffusion prior implicitly adapts to scale by encouraging high-realism generation. However, without explicit scale control, the diffusion process cannot be properly adjusted for different magnification levels, resulting in excessive hallucination or blurry outputs, especially under ultra-high scales. To address these issues, we propose OmniScaleSR, a diffusion-based realistic arbitrary-scale SR framework designed to achieve both high fidelity and high realism. We introduce explicit, diffusion-native scale control mechanisms that work synergistically with implicit scale adaptation, enabling scale-aware and content-aware modulation of the diffusion process. In addition, we incorporate multi-domain fidelity enhancement designs to further improve reconstruction accuracy. Extensive experiments on bicubic degradation benchmarks and real-world datasets show that OmniScaleSR surpasses state-of-the-art methods in both fidelity and perceptual realism, with particularly strong performance at large magnification factors. Code will be released at https://github.com/chaixinning/OmniScaleSR.

