---
layout: default
title: VideoSSM: Autoregressive Long Video Generation with Hybrid State-Space Memory
---

# VideoSSM: Autoregressive Long Video Generation with Hybrid State-Space Memory

**arXiv**: [2512.04519v1](https://arxiv.org/abs/2512.04519) | [PDF](https://arxiv.org/pdf/2512.04519.pdf)

**ä½œè€…**: Yifei Yu, Xiaoshan Wu, Xinting Hu, Tao Hu, Yangtian Sun, Xiaoyang Lyu, Bo Wang, Lin Ma, Yuewen Ma, Zhongrui Wang, Xiaojuan Qi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVideoSSMï¼Œç»“åˆè‡ªå›žå½’æ‰©æ•£ä¸Žæ··åˆçŠ¶æ€ç©ºé—´è®°å¿†ï¼Œä»¥è§£å†³é•¿è§†é¢‘ç”Ÿæˆä¸­çš„ç´¯ç§¯è¯¯å·®å’Œä¸€è‡´æ€§æŒ‘æˆ˜ã€‚**

**å…³é”®è¯**: `é•¿è§†é¢‘ç”Ÿæˆ` `è‡ªå›žå½’æ‰©æ•£` `çŠ¶æ€ç©ºé—´æ¨¡åž‹` `æ··åˆè®°å¿†` `æ—¶é—´ä¸€è‡´æ€§` `äº¤äº’æŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‡ªå›žå½’é•¿è§†é¢‘ç”Ÿæˆé¢ä¸´ç´¯ç§¯è¯¯å·®ã€è¿åŠ¨æ¼‚ç§»å’Œå†…å®¹é‡å¤ï¼Œå¯¼è‡´åˆ†é’Ÿçº§ä¸€è‡´æ€§å·®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ··åˆçŠ¶æ€ç©ºé—´è®°å¿†ï¼Œå…¨å±€SSMå­˜å‚¨åœºæ™¯åŠ¨æ€ï¼Œå±€éƒ¨ä¸Šä¸‹æ–‡çª—å£æä¾›è¿åŠ¨ç»†èŠ‚ï¼Œç¡®ä¿çº¿æ€§æ—¶é—´æ‰©å±•ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨é•¿çŸ­èŒƒå›´åŸºå‡†æµ‹è¯•ä¸­ï¼Œå®žçŽ°æœ€ä½³æ—¶é—´ä¸€è‡´æ€§å’Œè¿åŠ¨ç¨³å®šæ€§ï¼Œæ”¯æŒäº¤äº’å¼æç¤ºæŽ§åˆ¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Autoregressive (AR) diffusion enables streaming, interactive long-video generation by producing frames causally, yet maintaining coherence over minute-scale horizons remains challenging due to accumulated errors, motion drift, and content repetition. We approach this problem from a memory perspective, treating video synthesis as a recurrent dynamical process that requires coordinated short- and long-term context. We propose VideoSSM, a Long Video Model that unifies AR diffusion with a hybrid state-space memory. The state-space model (SSM) serves as an evolving global memory of scene dynamics across the entire sequence, while a context window provides local memory for motion cues and fine details. This hybrid design preserves global consistency without frozen, repetitive patterns, supports prompt-adaptive interaction, and scales in linear time with sequence length. Experiments on short- and long-range benchmarks demonstrate state-of-the-art temporal consistency and motion stability among autoregressive video generator especially at minute-scale horizons, enabling content diversity and interactive prompt-based control, thereby establishing a scalable, memory-aware framework for long video generation.

