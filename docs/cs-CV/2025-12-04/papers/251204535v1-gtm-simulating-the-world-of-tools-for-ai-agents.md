---
layout: default
title: GTM: Simulating the World of Tools for AI Agents
---

# GTM: Simulating the World of Tools for AI Agents

**arXiv**: [2512.04535v1](https://arxiv.org/abs/2512.04535) | [PDF](https://arxiv.org/pdf/2512.04535.pdf)

**ä½œè€…**: Zhenzhen Ren, Xinpeng Zhang, Zhenxing Qian, Yan Gao, Yu Shi, Shuxin Zheng, Jiyan He

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€šç”¨å·¥å…·æ¨¡åž‹GTMï¼Œä»¥æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œè§£å†³LLMä»£ç†è®­ç»ƒæˆæœ¬é«˜çš„é—®é¢˜**

**å…³é”®è¯**: `å·¥å…·æ¨¡æ‹Ÿ` `LLMä»£ç†è®­ç»ƒ` `ä¸Šä¸‹æ–‡æ„ŸçŸ¥å“åº”ç”Ÿæˆ` `å¤šé¢†åŸŸå·¥å…·` `å¼ºåŒ–å­¦ä¹ ` `æˆæœ¬ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šLLMä»£ç†ç›´æŽ¥äº¤äº’å·¥å…·è®­ç»ƒæˆæœ¬é«˜ã€é€Ÿåº¦æ…¢ä¸”ç»´æŠ¤å¼€é”€å¤§
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡CARGç®¡é“åˆæˆå¤šé¢†åŸŸæ•°æ®ï¼Œè®­ç»ƒGTMä½œä¸ºé€šç”¨å·¥å…·æ¨¡æ‹Ÿå™¨
3. å®žéªŒæˆ–æ•ˆæžœï¼šGTMè¾“å‡ºè´¨é‡é«˜ã€æ¨¡æ‹Ÿé€Ÿåº¦å¿«ï¼Œåœ¨å¼ºåŒ–å­¦ä¹ åœºæ™¯ä¸­è¡¨çŽ°ä¼˜å¼‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The integration of external tools is pivotal for empowering Large Language Model (LLM) agents with real-world capabilities. However, training these agents through direct, continuous interaction with diverse tools is often prohibitively expensive, slow, and introduces additional development and maintenance overhead. To address this challenge, we introduce the Generalist Tool Model (GTM), a 1.5-billion-parameter model that learns to act as a universal tool simulator. With only prompt-level configuration, GTM accesses tool functionalities along with input arguments and generates outputs that faithfully mimic real tool execution, providing a fast and cost-effective solution that eliminates development overhead. To build GTM, we propose the Context-Aware Response Generation (CARG) pipeline, which synthesizes comprehensive training data covering over 20,000 tools across 300 domains including physics, medicine, robotics, and finance. Through this pipeline, GTM learns to produce not only syntactically correct outputs but also logically coherent and contextually appropriate responses. Experiments demonstrate that GTM produces high-quality outputs with strong consistency and reliability. Besides when used in real reinforcement learning scenarios for agent training, GTM exhibits significantly faster simulation speed compared to real tools while maintaining comparable output quality, along with remarkable generalization and domain adaptability. Our results establish GTM as a foundational component for developing future AI agents, enabling efficient and scalable training of tool-augmented systems.

