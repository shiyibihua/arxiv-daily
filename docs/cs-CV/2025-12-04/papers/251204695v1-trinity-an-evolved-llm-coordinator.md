---
layout: default
title: TRINITY: An Evolved LLM Coordinator
---

# TRINITY: An Evolved LLM Coordinator

**arXiv**: [2512.04695v1](https://arxiv.org/abs/2512.04695) | [PDF](https://arxiv.org/pdf/2512.04695.pdf)

**ä½œè€…**: Jinglue Xu, Qi Sun, Peter Schwendeman, Stefan Nielsen, Edoardo Cetin, Yujin Tang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè½»é‡çº§åè°ƒå™¨Trinityï¼Œé€šè¿‡è¿›åŒ–ç­–ç•¥ä¼˜åŒ–å¤šLLMåä½œä»¥è§£å†³æ¨¡åž‹èžåˆéš¾é¢˜ã€‚**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹åè°ƒ` `è¿›åŒ–ç­–ç•¥ä¼˜åŒ–` `å¤šæ¨¡åž‹åä½œ` `è½»é‡çº§æž¶æž„` `ä»»åŠ¡åˆ†é…`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæƒé‡èžåˆå—é™äºŽæž¶æž„ä¸åŒ¹é…å’Œå°é—­APIï¼Œéš¾ä»¥æœ‰æ•ˆç»“åˆå¤šæ ·åŸºç¡€æ¨¡åž‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨çº¦0.6Bå‚æ•°ç´§å‡‘æ¨¡åž‹å’Œçº¦10Kå‚æ•°è½»é‡å¤´ï¼Œé€šè¿‡è¿›åŒ–ç­–ç•¥åˆ†é…Thinkerã€Workerã€Verifierè§’è‰²ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨ç¼–ç ã€æ•°å­¦ã€æŽ¨ç†ç­‰ä»»åŠ¡ä¸Šè¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼ŒLiveCodeBenchå¾—åˆ†86.2%ï¼Œæ³›åŒ–èƒ½åŠ›å¼ºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Combining diverse foundation models is promising, but weight-merging is limited by mismatched architectures and closed APIs. Trinity addresses this with a lightweight coordinator that orchestrates collaboration among large language models (LLMs). The coordinator, comprising a compact language model (approximately $0.6$B parameters) and a lightweight head (approximately $10$K parameters), is optimized with an evolutionary strategy for efficient and adaptive delegation. Trinity processes queries over multiple turns, where at each turn the coordinator assigns one of three roles (Thinker, Worker, or Verifier) to a selected LLM, effectively offloading complex skill acquisition from the coordinator itself. Experiments show that Trinity consistently outperforms individual models and existing methods across coding, math, reasoning, and domain knowledge tasks, and generalizes robustly to out-of-distribution tasks. On standard benchmarks, Trinity achieves state-of-the-art results, including a score of 86.2% on LiveCodeBench. Theoretical and empirical analyses identify two main factors behind this performance: (1) the coordinator's hidden-state representations provide rich contextualization of inputs, and (2) under high dimensionality and strict budget constraints, the separable Covariance Matrix Adaptation Evolution Strategy offers advantages over reinforcement learning, imitation learning, and random search by exploiting potential block-epsilon-separability.

