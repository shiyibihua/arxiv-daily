---
layout: default
title: GovBench: Benchmarking LLM Agents for Real-World Data Governance Workflows
---

# GovBench: Benchmarking LLM Agents for Real-World Data Governance Workflows

**arXiv**: [2512.04416v1](https://arxiv.org/abs/2512.04416) | [PDF](https://arxiv.org/pdf/2512.04416.pdf)

**ä½œè€…**: Zhou Liu, Zhaoyang Han, Guochen Yan, Hao Liang, Bohan Zeng, Xing Chen, Yuanfeng Song, Wentao Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGovBenchåŸºå‡†ä¸ŽDataGovAgentæ¡†æž¶ï¼Œä»¥è¯„ä¼°å’Œæå‡LLMåœ¨çœŸå®žæ•°æ®æ²»ç†å·¥ä½œæµä¸­çš„è‡ªåŠ¨åŒ–èƒ½åŠ›**

**å…³é”®è¯**: `æ•°æ®æ²»ç†åŸºå‡†` `LLMæ™ºèƒ½ä½“` `å·¥ä½œæµè‡ªåŠ¨åŒ–` `çº¦æŸè§„åˆ’` `æ£€ç´¢å¢žå¼ºç”Ÿæˆ` `æ²™ç›’è°ƒè¯•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŸºå‡†éš¾ä»¥è¯„ä¼°æ•°æ®æ²»ç†ç‰¹æœ‰çš„æ•°æ®æ­£ç¡®æ€§ä¸Žè´¨é‡ä¿éšœæŒ‘æˆ˜
2. GovBenchåŸºäºŽçœŸå®žæ¡ˆä¾‹æ•°æ®ï¼Œé‡‡ç”¨åå‘ç›®æ ‡æ–¹æ³•åˆæˆå™ªå£°ï¼Œè¯„ä¼°ç«¯åˆ°ç«¯å¯é æ€§
3. DataGovAgenté‡‡ç”¨è§„åˆ’-æ‰§è¡Œ-è¯„ä¼°æž¶æž„ï¼Œæ˜¾è‘—æå‡å¤æ‚ä»»åŠ¡å¾—åˆ†å¹¶å‡å°‘è°ƒè¯•è¿­ä»£

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Data governance ensures data quality, security, and compliance through policies and standards, a critical foundation for scaling modern AI development. Recently, large language models (LLMs) have emerged as a promising solution for automating data governance by translating user intent into executable transformation code. However, existing benchmarks for automated data science often emphasize snippet-level coding or high-level analytics, failing to capture the unique challenge of data governance: ensuring the correctness and quality of the data itself. To bridge this gap, we introduce GovBench, a benchmark featuring 150 diverse tasks grounded in real-world scenarios, built on data from actual cases. GovBench employs a novel "reversed-objective" methodology to synthesize realistic noise and utilizes rigorous metrics to assess end-to-end pipeline reliability. Our analysis on GovBench reveals that current models struggle with complex, multi-step workflows and lack robust error-correction mechanisms. Consequently, we propose DataGovAgent, a framework utilizing a Planner-Executor-Evaluator architecture that integrates constraint-based planning, retrieval-augmented generation, and sandboxed feedback-driven debugging. Experimental results show that DataGovAgent significantly boosts the Average Task Score (ATS) on complex tasks from 39.7 to 54.9 and reduces debugging iterations by over 77.9 percent compared to general-purpose baselines.

