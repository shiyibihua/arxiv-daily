---
layout: default
title: Amortized Inference of Multi-Modal Posteriors using Likelihood-Weighted Normalizing Flows
---

# Amortized Inference of Multi-Modal Posteriors using Likelihood-Weighted Normalizing Flows

**arXiv**: [2512.04954v1](https://arxiv.org/abs/2512.04954) | [PDF](https://arxiv.org/pdf/2512.04954.pdf)

**ä½œè€…**: Rajneil Baruah

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽä¼¼ç„¶åŠ æƒå½’ä¸€åŒ–æµçš„æ‘Šé”€åŽéªŒä¼°è®¡æ–¹æ³•ï¼Œä»¥è§£å†³é«˜ç»´é€†é—®é¢˜ä¸­å¤šæ¨¡æ€åŽéªŒæŽ¨æ–­çš„æŒ‘æˆ˜ã€‚**

**å…³é”®è¯**: `å½’ä¸€åŒ–æµ` `æ‘Šé”€æŽ¨æ–­` `å¤šæ¨¡æ€åŽéªŒ` `ä¼¼ç„¶åŠ æƒé‡‡æ ·` `é«˜æ–¯æ··åˆæ¨¡åž‹` `é«˜ç»´é€†é—®é¢˜`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé«˜ç»´é€†é—®é¢˜ä¸­ç†è®ºå‚æ•°çš„åŽéªŒæŽ¨æ–­ï¼Œä¼ ç»Ÿæ–¹æ³•ä¾èµ–åŽéªŒè®­ç»ƒæ ·æœ¬ä¸”éš¾ä»¥å¤„ç†å¤šæ¨¡æ€åˆ†å¸ƒã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨ä¼¼ç„¶åŠ æƒé‡è¦æ€§é‡‡æ ·è®­ç»ƒå½’ä¸€åŒ–æµï¼Œå®žçŽ°æ‘Šé”€åŽéªŒä¼°è®¡ï¼Œæ— éœ€åŽéªŒæ ·æœ¬ï¼›å¼•å…¥é«˜æ–¯æ··åˆæ¨¡åž‹åˆå§‹åŒ–ä»¥åŒ¹é…ç›®æ ‡æ¨¡æ€åŸºæ•°ï¼Œæ”¹å–„å¤šæ¨¡æ€æ•èŽ·ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨2Då’Œ3Då¤šæ¨¡æ€åŸºå‡†ä»»åŠ¡ä¸­éªŒè¯æ–¹æ³•æœ‰æ•ˆæ€§ï¼Œé€šè¿‡è·ç¦»å’Œæ•£åº¦åº¦é‡æ˜¾ç¤ºé‡å»ºä¿çœŸåº¦æ˜¾è‘—æå‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present a novel technique for amortized posterior estimation using Normalizing Flows trained with likelihood-weighted importance sampling. This approach allows for the efficient inference of theoretical parameters in high-dimensional inverse problems without the need for posterior training samples. We implement the method on multi-modal benchmark tasks in 2D and 3D to check for the efficacy. A critical observation of our study is the impact of the topology of the base distributions on the modelled posteriors. We find that standard unimodal base distributions fail to capture disconnected support, resulting in spurious probability bridges between modes. We demonstrate that initializing the flow with a Gaussian Mixture Model that matches the cardinality of the target modes significantly improves reconstruction fidelity, as measured by some distance and divergence metrics.

