---
layout: default
title: Hardware-aware Neural Architecture Search of Early Exiting Networks on Edge Accelerators
---

# Hardware-aware Neural Architecture Search of Early Exiting Networks on Edge Accelerators

**arXiv**: [2512.04705v1](https://arxiv.org/abs/2512.04705) | [PDF](https://arxiv.org/pdf/2512.04705.pdf)

**ä½œè€…**: Alaa Zniber, Arne Symons, Ouassim Karrakchou, Marian Verhelst, Mounir Ghogho

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç¡¬ä»¶æ„ŸçŸ¥ç¥žç»æž¶æž„æœç´¢æ¡†æž¶ï¼Œä¼˜åŒ–è¾¹ç¼˜åŠ é€Ÿå™¨ä¸Šçš„æ—©æœŸé€€å‡ºç½‘ç»œè®¾è®¡**

**å…³é”®è¯**: `ç¥žç»æž¶æž„æœç´¢` `æ—©æœŸé€€å‡ºç½‘ç»œ` `è¾¹ç¼˜è®¡ç®—` `ç¡¬ä»¶æ„ŸçŸ¥ä¼˜åŒ–` `é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè¾¹ç¼˜éƒ¨ç½²ä¸­ï¼Œæ—©æœŸé€€å‡ºç½‘ç»œå—ç¡¬ä»¶å¼‚æž„æ€§å’Œé‡åŒ–çº¦æŸå½±å“ï¼Œè‡ªåŠ¨ä¼˜åŒ–ç ”ç©¶ä¸è¶³
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆé‡åŒ–å’Œç¡¬ä»¶èµ„æºåˆ†é…ï¼Œç³»ç»Ÿæœç´¢ç½‘ç»œéª¨å¹²ä¸­çš„æ—©æœŸé€€å‡ºç‚¹ä½ç½®
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CIFAR-10æ•°æ®é›†ä¸Šï¼Œå‘çŽ°æž¶æž„å¯å‡å°‘è¶…50%è®¡ç®—æˆæœ¬ï¼Œæå‡è¾¹ç¼˜çŽ¯å¢ƒé€‚åº”æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Advancements in high-performance computing and cloud technologies have enabled the development of increasingly sophisticated Deep Learning (DL) models. However, the growing demand for embedded intelligence at the edge imposes stringent computational and energy constraints, challenging the deployment of these large-scale models. Early Exiting Neural Networks (EENN) have emerged as a promising solution, allowing dynamic termination of inference based on input complexity to enhance efficiency. Despite their potential, EENN performance is highly influenced by the heterogeneity of edge accelerators and the constraints imposed by quantization, affecting accuracy, energy efficiency, and latency. Yet, research on the automatic optimization of EENN design for edge hardware remains limited. To bridge this gap, we propose a hardware-aware Neural Architecture Search (NAS) framework that systematically integrates the effects of quantization and hardware resource allocation to optimize the placement of early exit points within a network backbone. Experimental results on the CIFAR-10 dataset demonstrate that our NAS framework can discover architectures that achieve over a 50\% reduction in computational costs compared to conventional static networks, making them more suitable for deployment in resource-constrained edge environments.

