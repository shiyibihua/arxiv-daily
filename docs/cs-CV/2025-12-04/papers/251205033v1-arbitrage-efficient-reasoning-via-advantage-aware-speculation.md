---
layout: default
title: Arbitrage: Efficient Reasoning via Advantage-Aware Speculation
---

# Arbitrage: Efficient Reasoning via Advantage-Aware Speculation

**arXiv**: [2512.05033v1](https://arxiv.org/abs/2512.05033) | [PDF](https://arxiv.org/pdf/2512.05033.pdf)

**ä½œè€…**: Monishwaran Maheswaran, Rishabh Tiwari, Yuezhou Hu, Kerem Dilmen, Coleman Hooper, Haocheng Xi, Nicholas Lee, Mehrdad Farajtabar, Michael W. Mahoney, Kurt Keutzer, Amir Gholami

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºArbitrageæ¡†æž¶ï¼Œé€šè¿‡åŠ¨æ€è·¯ç”±æå‡æŽ¨ç†ä»»åŠ¡ä¸­æ­¥çº§æŽ¨æµ‹è§£ç çš„æ•ˆçŽ‡**

**å…³é”®è¯**: `æŽ¨æµ‹è§£ç ` `æŽ¨ç†åŠ é€Ÿ` `åŠ¨æ€è·¯ç”±` `æ­¥çº§éªŒè¯` `å¤§è¯­è¨€æ¨¡åž‹` `æ•ˆçŽ‡ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»ŸæŽ¨æµ‹è§£ç åœ¨æŽ¨ç†ä»»åŠ¡ä¸­å› è¯­ä¹‰ç­‰æ•ˆæ­¥éª¤çš„ä»¤ç‰Œä¸åŒ¹é…å¯¼è‡´æ•ˆçŽ‡ä½Žä¸‹
2. Arbitrageä½¿ç”¨è½»é‡çº§è·¯ç”±å™¨åŠ¨æ€é€‰æ‹©è‰ç¨¿æˆ–ç›®æ ‡æ¨¡åž‹ç”Ÿæˆæ­¥éª¤ï¼Œä¼˜åŒ–æ•ˆçŽ‡-å‡†ç¡®æ€§æƒè¡¡
3. åœ¨æ•°å­¦æŽ¨ç†åŸºå‡†æµ‹è¯•ä¸­ï¼ŒArbitrageå‡å°‘æŽ¨ç†å»¶è¿Ÿçº¦2å€ï¼Œä¿æŒå‡†ç¡®æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Modern Large Language Models achieve impressive reasoning capabilities with long Chain of Thoughts, but they incur substantial computational cost during inference, and this motivates techniques to improve the performance-cost ratio. Among these techniques, Speculative Decoding accelerates inference by employing a fast but inaccurate draft model to autoregressively propose tokens, which are then verified in parallel by a more capable target model. However, due to unnecessary rejections caused by token mismatches in semantically equivalent steps, traditional token-level Speculative Decoding struggles in reasoning tasks. Although recent works have shifted to step-level semantic verification, which improve efficiency by accepting or rejecting entire reasoning steps, existing step-level methods still regenerate many rejected steps with little improvement, wasting valuable target compute. To address this challenge, we propose Arbitrage, a novel step-level speculative generation framework that routes generation dynamically based on the relative advantage between draft and target models. Instead of applying a fixed acceptance threshold, Arbitrage uses a lightweight router trained to predict when the target model is likely to produce a meaningfully better step. This routing approximates an ideal Arbitrage Oracle that always chooses the higher-quality step, achieving near-optimal efficiency-accuracy trade-offs. Across multiple mathematical reasoning benchmarks, Arbitrage consistently surpasses prior step-level Speculative Decoding baselines, reducing inference latency by up to $\sim2\times$ at matched accuracy.

