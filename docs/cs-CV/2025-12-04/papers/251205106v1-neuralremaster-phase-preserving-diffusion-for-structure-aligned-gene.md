---
layout: default
title: NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation
---

# NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation

**arXiv**: [2512.05106v1](https://arxiv.org/abs/2512.05106) | [PDF](https://arxiv.org/pdf/2512.05106.pdf)

**ä½œè€…**: Yu Zeng, Charles Ochoa, Mingyuan Zhou, Vishal M. Patel, Vitor Guizilini, Rowan McAllister

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç›¸ä½ä¿æŒæ‰©æ•£ä»¥è§£å†³æ ‡å‡†æ‰©æ•£ç ´åç©ºé—´ç»“æž„çš„é—®é¢˜ï¼Œé€‚ç”¨äºŽç»“æž„å¯¹é½ç”Ÿæˆä»»åŠ¡ã€‚**

**å…³é”®è¯**: `ç›¸ä½ä¿æŒæ‰©æ•£` `ç»“æž„å¯¹é½ç”Ÿæˆ` `å›¾åƒåˆ°å›¾åƒç¿»è¯‘` `è§†é¢‘ç”Ÿæˆ` `é¢‘çŽ‡é€‰æ‹©æ€§å™ªå£°` `æ¨¡æ‹Ÿåˆ°çœŸå®žå¢žå¼º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ‡å‡†æ‰©æ•£ä½¿ç”¨é«˜æ–¯å™ªå£°ç ´åç›¸ä½ï¼Œå¯¼è‡´ç©ºé—´ç»“æž„ä¸¢å¤±ï¼Œä¸é€‚åˆå‡ ä½•ä¸€è‡´æ€§ä»»åŠ¡ã€‚
2. å¼•å…¥ç›¸ä½ä¿æŒæ‰©æ•£ï¼Œä¿ç•™è¾“å…¥ç›¸ä½å¹¶éšæœºåŒ–å¹…åº¦ï¼Œæ— éœ€ä¿®æ”¹æž¶æž„æˆ–å¢žåŠ å‚æ•°ã€‚
3. æå‡ºé¢‘çŽ‡é€‰æ‹©æ€§ç»“æž„åŒ–å™ªå£°ï¼Œé€šè¿‡å•ä¸€é¢‘çŽ‡æˆªæ­¢å‚æ•°æŽ§åˆ¶ç»“æž„åˆšæ€§ï¼Œå®žéªŒæ˜¾ç¤ºåœ¨CARLAæ¨¡æ‹Ÿå™¨ä¸­æå‡è§„åˆ’å™¨æ€§èƒ½50%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Standard diffusion corrupts data using Gaussian noise whose Fourier coefficients have random magnitudes and random phases. While effective for unconditional or text-to-image generation, corrupting phase components destroys spatial structure, making it ill-suited for tasks requiring geometric consistency, such as re-rendering, simulation enhancement, and image-to-image translation. We introduce Phase-Preserving Diffusion Ï†-PD, a model-agnostic reformulation of the diffusion process that preserves input phase while randomizing magnitude, enabling structure-aligned generation without architectural changes or additional parameters. We further propose Frequency-Selective Structured (FSS) noise, which provides continuous control over structural rigidity via a single frequency-cutoff parameter. Ï†-PD adds no inference-time cost and is compatible with any diffusion model for images or videos. Across photorealistic and stylized re-rendering, as well as sim-to-real enhancement for driving planners, Ï†-PD produces controllable, spatially aligned results. When applied to the CARLA simulator, Ï†-PD improves CARLA-to-Waymo planner performance by 50\%. The method is complementary to existing conditioning approaches and broadly applicable to image-to-image and video-to-video generation. Videos, additional examples, and code are available on our \href{https://yuzeng-at-tri.github.io/ppd-page/}{project page}.

