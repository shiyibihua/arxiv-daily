---
layout: default
title: TARDis: Time Attenuated Representation Disentanglement for Incomplete Multi-Modal Tumor Segmentation and Classification
---

# TARDis: Time Attenuated Representation Disentanglement for Incomplete Multi-Modal Tumor Segmentation and Classification

**arXiv**: [2512.04576v1](https://arxiv.org/abs/2512.04576) | [PDF](https://arxiv.org/pdf/2512.04576.pdf)

**ä½œè€…**: Zishuo Wan, Qinqin Kang, Yi Huang, Yun Bian, Dawei Ding, Ke Yan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTARDisæ¡†æž¶ï¼Œé€šè¿‡æ—¶é—´è¡°å‡è¡¨ç¤ºè§£è€¦è§£å†³ä¸å®Œæ•´å¤šæ¨¡æ€è‚¿ç˜¤åˆ†å‰²ä¸Žåˆ†ç±»é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€åŒ»å­¦å½±åƒ` `è¡¨ç¤ºè§£è€¦` `æ—¶é—´è¡°å‡æ›²çº¿` `è‚¿ç˜¤åˆ†å‰²` `æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨` `ç¼ºå¤±æ¨¡æ€å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šCTå¤šæœŸç›¸æ‰«æä¸­ç¼ºå¤±æ¨¡æ€å¿½ç•¥è¡€æµåŠ¨åŠ›å­¦æ—¶é—´è¿žç»­æ€§ï¼Œå½±å“è‚¿ç˜¤åˆ†å‰²ä¸Žè¯Šæ–­ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†ç¼ºå¤±æ¨¡æ€è§†ä¸ºæ—¶é—´è¡°å‡æ›²çº¿ä¸Šçš„ç¼ºå¤±ç‚¹ï¼Œè§£è€¦ç‰¹å¾ä¸ºé™æ€è§£å‰–å’ŒåŠ¨æ€çŒæ³¨æˆåˆ†ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ç§æœ‰å’Œå…¬å…±æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œåœ¨æžç«¯æ•°æ®ç¨€ç–åœºæ™¯ä¸‹ä¿æŒç¨³å¥æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Tumor segmentation and diagnosis in contrast-enhanced Computed Tomography (CT) rely heavily on the physiological dynamics of contrast agents. However, obtaining a complete multi-phase series is often clinically unfeasible due to radiation concerns or scanning limitations, leading to the "missing modality" problem. Existing deep learning approaches typically treat missing phases as absent independent channels, ignoring the inherent temporal continuity of hemodynamics. In this work, we propose Time Attenuated Representation Disentanglement (TARDis), a novel physics-aware framework that redefines missing modalities as missing sample points on a continuous Time-Attenuation Curve. TARDis explicitly disentangles the latent feature space into a time-invariant static component (anatomy) and a time-dependent dynamic component (perfusion). We achieve this via a dual-path architecture: a quantization-based path using a learnable embedding dictionary to extract consistent anatomical structures, and a probabilistic path using a Conditional Variational Autoencoder to model dynamic enhancement conditioned on the estimated scan time. This design allows the network to hallucinate missing hemodynamic features by sampling from the learned latent distribution. Extensive experiments on a large-scale private abdominal CT dataset (2,282 cases) and two public datasets demonstrate that TARDis significantly outperforms state-of-the-art incomplete modality frameworks. Notably, our method maintains robust diagnostic performance even in extreme data-sparsity scenarios, highlighting its potential for reducing radiation exposure while maintaining diagnostic precision.

