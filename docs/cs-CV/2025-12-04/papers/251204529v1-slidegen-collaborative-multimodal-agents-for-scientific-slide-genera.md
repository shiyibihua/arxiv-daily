---
layout: default
title: SlideGen: Collaborative Multimodal Agents for Scientific Slide Generation
---

# SlideGen: Collaborative Multimodal Agents for Scientific Slide Generation

**arXiv**: [2512.04529v1](https://arxiv.org/abs/2512.04529) | [PDF](https://arxiv.org/pdf/2512.04529.pdf)

**ä½œè€…**: Xin Liang, Xiang Zhang, Yiwei Xu, Siqi Sun, Chenyu You

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSlideGenæ¡†æž¶ï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“åä½œè§£å†³ç§‘å­¦è®ºæ–‡åˆ°æ¼”ç¤ºæ–‡ç¨¿çš„ç”Ÿæˆé—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€æŽ¨ç†` `æ™ºèƒ½ä½“åä½œ` `å¹»ç¯ç‰‡ç”Ÿæˆ` `è§†è§‰è§„åˆ’` `æ–‡æ¡£ç†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•å¿½è§†è§†è§‰è§„åˆ’ï¼Œéš¾ä»¥ç”Ÿæˆé«˜è´¨é‡å­¦æœ¯å¹»ç¯ç‰‡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ¨¡å—åŒ–å¤šæ™ºèƒ½ä½“æ¡†æž¶ï¼ŒååŒå¤„ç†æ–‡æ¡£ç»“æž„ä¸Žè§†è§‰è®¾è®¡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒSlideGenåœ¨è§†è§‰è´¨é‡ã€å†…å®¹å¿ å®žåº¦å’Œå¯è¯»æ€§ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generating academic slides from scientific papers is a challenging multimodal reasoning task that requires both long context understanding and deliberate visual planning. Existing approaches largely reduce it to text only summarization, overlooking the visual component and design intensive nature of slide creation. In this paper we introduce SlideGen, an agentic, modular, and visual in the loop framework for scientific paper to slide generation. SlideGen orchestrates a group of vision language agents that reason collaboratively over the document structure and semantics, producing editable PPTX slides with logical flow and compelling visual presentation. By integrating coordinated outlining, mapping, arrangement, note synthesis, and iterative refinement, our system consistently delivers slides of expert level quality. Across diverse benchmarks and strong baselines, SlideGen outperforms existing methods in visual quality, content faithfulness, and readability, positioning it as the new state of the art in automated slide generation. Our work establishes a foundation for design aware multimodal slide generation, demonstrating how agentic collaboration can bridge understanding and presentation in complex multimodal reasoning tasks.

