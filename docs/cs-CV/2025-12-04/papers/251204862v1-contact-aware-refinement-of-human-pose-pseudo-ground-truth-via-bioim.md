---
layout: default
title: Contact-Aware Refinement of Human Pose Pseudo-Ground Truth via Bioimpedance Sensing
---

# Contact-Aware Refinement of Human Pose Pseudo-Ground Truth via Bioimpedance Sensing

**arXiv**: [2512.04862v1](https://arxiv.org/abs/2512.04862) | [PDF](https://arxiv.org/pdf/2512.04862.pdf)

**ä½œè€…**: Maria-Paola Forte, Nikos Athanasiou, Giulia Ballardini, Jan Ulrich Bartels, Katherine J. Kuchenbecker, Michael J. Black

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBioTUCHæ¡†æž¶ï¼Œç»“åˆç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿä¼˜åŒ–è‡ªæŽ¥è§¦åœºæ™¯ä¸‹çš„3Däººä½“å§¿æ€ä¼°è®¡**

**å…³é”®è¯**: `3Däººä½“å§¿æ€ä¼°è®¡` `ç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿ` `è‡ªæŽ¥è§¦ä¼˜åŒ–` `å§¿æ€é‡å»º` `å¤šæ¨¡æ€æ•°æ®èžåˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†é¢‘å§¿æ€ä¼°è®¡åœ¨è‡ªæŽ¥è§¦åœºæ™¯ï¼ˆå¦‚æ‰‹è§¦è„¸ï¼‰ä¸­å¸¸ä¸å‡†ç¡®ï¼Œç¼ºä¹çœŸå®žæŽ¥è§¦æ•°æ®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨ç”Ÿç‰©é˜»æŠ—ä¼ æ„Ÿæµ‹é‡çš®è‚¤æŽ¥è§¦ï¼Œé€šè¿‡æŽ¥è§¦æ„ŸçŸ¥ä¼˜åŒ–åˆå§‹åŒ–å§¿æ€ï¼Œæœ€å°åŒ–é‡æŠ•å½±è¯¯å·®å’Œåå·®ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŒæ­¥æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œå¹³å‡é‡å»ºç²¾åº¦æå‡11.7%ï¼Œå¹¶å¼€å‘å¾®åž‹ä¼ æ„Ÿå™¨ç”¨äºŽå¤§è§„æ¨¡æ•°æ®æ”¶é›†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Capturing accurate 3D human pose in the wild would provide valuable data for training pose estimation and motion generation methods. While video-based estimation approaches have become increasingly accurate, they often fail in common scenarios involving self-contact, such as a hand touching the face. In contrast, wearable bioimpedance sensing can cheaply and unobtrusively measure ground-truth skin-to-skin contact. Consequently, we propose a novel framework that combines visual pose estimators with bioimpedance sensing to capture the 3D pose of people by taking self-contact into account. Our method, BioTUCH, initializes the pose using an off-the-shelf estimator and introduces contact-aware pose optimization during measured self-contact: reprojection error and deviations from the input estimate are minimized while enforcing vertex proximity constraints. We validate our approach using a new dataset of synchronized RGB video, bioimpedance measurements, and 3D motion capture. Testing with three input pose estimators, we demonstrate an average of 11.7% improvement in reconstruction accuracy. We also present a miniature wearable bioimpedance sensor that enables efficient large-scale collection of contact-aware training data for improving pose estimation and generation using BioTUCH. Code and data are available at biotuch.is.tue.mpg.de

