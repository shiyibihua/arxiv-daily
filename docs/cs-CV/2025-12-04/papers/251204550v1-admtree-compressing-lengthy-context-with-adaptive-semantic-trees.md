---
layout: default
title: AdmTree: Compressing Lengthy Context with Adaptive Semantic Trees
---

# AdmTree: Compressing Lengthy Context with Adaptive Semantic Trees

**arXiv**: [2512.04550v1](https://arxiv.org/abs/2512.04550) | [PDF](https://arxiv.org/pdf/2512.04550.pdf)

**ä½œè€…**: Yangning Li, Shaoshen Chen, Yinghui Li, Yankai Chen, Hai-Tao Zheng, Hui Wang, Wenhao Jiang, Philip S. Yu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAdmTreeè‡ªé€‚åº”è¯­ä¹‰æ ‘æ¡†æž¶ä»¥åŽ‹ç¼©é•¿ä¸Šä¸‹æ–‡ï¼Œæå‡LLMå¤„ç†æ•ˆçŽ‡ä¸Žè¯­ä¹‰ä¿çœŸåº¦ã€‚**

**å…³é”®è¯**: `é•¿ä¸Šä¸‹æ–‡åŽ‹ç¼©` `è‡ªé€‚åº”è¯­ä¹‰æ ‘` `è½»é‡èšåˆæœºåˆ¶` `ä½ç½®åå·®ç¼“è§£` `è¯­ä¹‰ä¿çœŸåº¦` `åˆ†å±‚æŠ½è±¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‡ªæ³¨æ„åŠ›äºŒæ¬¡å¤æ‚åº¦é™åˆ¶LLMå¤„ç†é•¿ä¸Šä¸‹æ–‡ï¼ŒçŽ°æœ‰æ–¹æ³•åœ¨ç»†èŠ‚ä¿ç•™ã€ä½ç½®åå·®æˆ–é•¿ç¨‹ä¾èµ–æ•èŽ·ä¸Šä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽä¿¡æ¯å¯†åº¦åŠ¨æ€åˆ†æ®µï¼Œä½¿ç”¨gistä»¤ç‰Œæž„å»ºè¯­ä¹‰äºŒå‰æ ‘ï¼Œè½»é‡èšåˆæœºåˆ¶ä¸Žå†»ç»“ä¸»å¹²LLMå®žçŽ°é«˜æ•ˆåˆ†å±‚æŠ½è±¡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæœªçŸ¥ï¼Œä½†æ¡†æž¶æ—¨åœ¨ä¿ç•™ç»†ç²’åº¦ç»†èŠ‚ä¸Žå…¨å±€è¯­ä¹‰è¿žè´¯æ€§ï¼ŒåŠ¨æ€é€‚åº”å†…å®¹ä»¥ç¨³å¥ä¿ç•™è¯­ä¹‰ä¿¡æ¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The quadratic complexity of self-attention constrains Large Language Models (LLMs) in processing long contexts, a capability essential for many advanced applications. Context compression aims to alleviate this computational bottleneck while retaining critical semantic information. However, existing approaches often fall short: explicit methods may compromise local detail, whereas implicit methods can suffer from positional biases, information degradation, or an inability to capture long-range semantic dependencies. We propose AdmTree, a novel framework for adaptive, hierarchical context compression with a central focus on preserving high semantic fidelity while maintaining efficiency. AdmTree dynamically segments input based on information density, utilizing gist tokens to summarize variable-length segments as the leaves of a semantic binary tree. This structure, together with a lightweight aggregation mechanism and a frozen backbone LLM (thereby minimizing new trainable parameters), enables efficient hierarchical abstraction of the context. By preserving fine-grained details alongside global semantic coherence, mitigating positional bias, and dynamically adapting to content, AdmTree robustly retains the semantic information of long contexts.

