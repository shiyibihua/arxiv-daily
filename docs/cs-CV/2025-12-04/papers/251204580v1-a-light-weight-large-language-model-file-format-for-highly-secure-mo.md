---
layout: default
title: A Light-Weight Large Language Model File Format for Highly-Secure Model Distribution
---

# A Light-Weight Large Language Model File Format for Highly-Secure Model Distribution

**arXiv**: [2512.04580v1](https://arxiv.org/abs/2512.04580) | [PDF](https://arxiv.org/pdf/2512.04580.pdf)

**ä½œè€…**: Huifeng Zhu, Shijie Li, Qinfeng Li, Yier Jin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCryptoTensorsæ ¼å¼ä»¥è§£å†³å¤§è¯­è¨€æ¨¡åž‹åœ¨éƒ¨ç½²å’Œåˆ†å‘ä¸­çš„å®‰å…¨ä¿å¯†é—®é¢˜**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹å®‰å…¨` `æ¨¡åž‹åˆ†å‘æ ¼å¼` `å¼ é‡åŠ å¯†` `è®¿é—®æŽ§åˆ¶` `è½»é‡çº§éƒ¨ç½²`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ¨¡åž‹æ ¼å¼ç¼ºä¹å¯¹æœºå¯†æ€§ã€è®¿é—®æŽ§åˆ¶æˆ–å¯ä¿¡ç¡¬ä»¶é›†æˆçš„å†…ç½®æ”¯æŒï¼Œå¯¼è‡´æ¨¡åž‹æƒé‡ä¿æŠ¤ä¸è¶³
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽSafetensorsæ‰©å±•ï¼Œå¼•å…¥å¼ é‡çº§åŠ å¯†å’ŒåµŒå…¥å¼è®¿é—®æŽ§åˆ¶ç­–ç•¥ï¼Œæ”¯æŒé€æ˜Žè§£å¯†å’Œè‡ªåŠ¨å¯†é’¥ç®¡ç†
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žçŽ°æ¦‚å¿µéªŒè¯åº“ï¼Œåœ¨åºåˆ—åŒ–å’Œè¿è¡Œæ—¶åœºæ™¯ä¸­åŸºå‡†æµ‹è¯•ï¼ŒéªŒè¯ä¸ŽHugging Face Transformerså’ŒvLLMç­‰æ¡†æž¶çš„å…¼å®¹æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> To enhance the performance of large language models (LLMs) in various domain-specific applications, sensitive data such as healthcare, law, and finance are being used to privately customize or fine-tune these models. Such privately adapted LLMs are regarded as either personal privacy assets or corporate intellectual property. Therefore, protecting model weights and maintaining strict confidentiality during deployment and distribution have become critically important. However, existing model formats and deployment frameworks provide little to no built-in support for confidentiality, access control, or secure integration with trusted hardware. Current methods for securing model deployment either rely on computationally expensive cryptographic techniques or tightly controlled private infrastructure. Although these approaches can be effective in specific scenarios, they are difficult and costly for widespread deployment.
>   In this paper, we introduce CryptoTensors, a secure and format-compatible file structure for confidential LLM distribution. Built as an extension to the widely adopted Safetensors format, CryptoTensors incorporates tensor-level encryption and embedded access control policies, while preserving critical features such as lazy loading and partial deserialization. It enables transparent decryption and automated key management, supporting flexible licensing and secure model execution with minimal overhead. We implement a proof-of-concept library, benchmark its performance across serialization and runtime scenarios, and validate its compatibility with existing inference frameworks, including Hugging Face Transformers and vLLM. Our results highlight CryptoTensors as a light-weight, efficient, and developer-friendly solution for safeguarding LLM weights in real-world and widespread deployments.

