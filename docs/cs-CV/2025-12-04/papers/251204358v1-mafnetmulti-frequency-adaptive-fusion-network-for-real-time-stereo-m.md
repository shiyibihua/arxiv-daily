---
layout: default
title: MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching
---

# MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching

**arXiv**: [2512.04358v1](https://arxiv.org/abs/2512.04358) | [PDF](https://arxiv.org/pdf/2512.04358.pdf)

**ä½œè€…**: Ao Xu, Rujin Zhao, Xiong Xu, Boceng Huang, Yujia Jia, Hongfeng Long, Fuxuan Chen, Zilong Cao, Fangyuan Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMAFNetå¤šé¢‘è‡ªé€‚åº”èžåˆç½‘ç»œï¼Œä»¥é«˜æ•ˆ2Då·ç§¯å®žçŽ°å®žæ—¶ç«‹ä½“åŒ¹é…ï¼Œå¹³è¡¡ç²¾åº¦ä¸Žé€Ÿåº¦ã€‚**

**å…³é”®è¯**: `ç«‹ä½“åŒ¹é…` `å®žæ—¶è®¡ç®—` `é¢‘åŸŸæ»¤æ³¢` `æ³¨æ„åŠ›æœºåˆ¶` `2Då·ç§¯` `ç§»åŠ¨è®¾å¤‡éƒ¨ç½²`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰ç«‹ä½“åŒ¹é…ç½‘ç»œåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šå®žæ—¶æ€§å·®ï¼Œå› 3Då·ç§¯è®¡ç®—å¼€é”€å¤§æˆ–è¿­ä»£ä¼˜åŒ–ç¼ºä¹éžå±€éƒ¨ä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚
2. MAFNetè®¾è®¡è‡ªé€‚åº”é¢‘åŸŸæ»¤æ³¢æ³¨æ„åŠ›æ¨¡å—ï¼Œåˆ†è§£æˆæœ¬ä½“ç§¯ä¸ºé«˜ä½Žé¢‘éƒ¨åˆ†ï¼Œå¹¶åŸºäºŽLinformerä½Žç§©æ³¨æ„åŠ›èžåˆä¿¡æ¯ã€‚
3. åœ¨Scene Flowå’ŒKITTI 2015æ•°æ®é›†ä¸Šï¼ŒMAFNetä¼˜äºŽçŽ°æœ‰å®žæ—¶æ–¹æ³•ï¼Œå±•çŽ°ç²¾åº¦ä¸Žå®žæ—¶æ€§èƒ½çš„è‰¯å¥½å¹³è¡¡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Existing stereo matching networks typically rely on either cost-volume construction based on 3D convolutions or deformation methods based on iterative optimization. The former incurs significant computational overhead during cost aggregation, whereas the latter often lacks the ability to model non-local contextual information. These methods exhibit poor compatibility on resource-constrained mobile devices, limiting their deployment in real-time applications. To address this, we propose a Multi-frequency Adaptive Fusion Network (MAFNet), which can produce high-quality disparity maps using only efficient 2D convolutions. Specifically, we design an adaptive frequency-domain filtering attention module that decomposes the full cost volume into high-frequency and low-frequency volumes, performing frequency-aware feature aggregation separately. Subsequently, we introduce a Linformer-based low-rank attention mechanism to adaptively fuse high- and low-frequency information, yielding more robust disparity estimation. Extensive experiments demonstrate that the proposed MAFNet significantly outperforms existing real-time methods on public datasets such as Scene Flow and KITTI 2015, showing a favorable balance between accuracy and real-time performance.

