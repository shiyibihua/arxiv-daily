---
layout: default
title: David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?
---

# David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?

**arXiv**: [2512.05073v1](https://arxiv.org/abs/2512.05073) | [PDF](https://arxiv.org/pdf/2512.05073.pdf)

**ä½œè€…**: Shashwat Shankar, Subhranshu Pandey, Innocent Dengkhw Mochahari, Bhabesh Mali, Animesh Basak Chowdhury, Sukanta Bhattacharjee, Chandan Karfa

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“åˆä»£ç†AIæ¡†æž¶çš„å°æ¨¡åž‹æ–¹æ³•ï¼Œåœ¨ç¡¬ä»¶è®¾è®¡ä»»åŠ¡ä¸­ä»¥ä½Žæˆæœ¬å®žçŽ°æŽ¥è¿‘å¤§æ¨¡åž‹æ€§èƒ½**

**å…³é”®è¯**: `ç¡¬ä»¶è®¾è®¡` `å°è¯­è¨€æ¨¡åž‹` `ä»£ç†AIæ¡†æž¶` `ä»»åŠ¡åˆ†è§£` `è¿­ä»£åé¦ˆ` `æˆæœ¬æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è¯­è¨€æ¨¡åž‹æŽ¨ç†æˆæœ¬é«˜ï¼Œç¡¬ä»¶è®¾è®¡é¢†åŸŸéœ€é«˜æ•ˆæ›¿ä»£æ–¹æ¡ˆ
2. æ–¹æ³•è¦ç‚¹ï¼šå°æ¨¡åž‹ç»“åˆä»£ç†AIæ¡†æž¶ï¼Œé€šè¿‡ä»»åŠ¡åˆ†è§£ã€è¿­ä»£åé¦ˆå’Œä¿®æ­£æå‡æ€§èƒ½
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨NVIDIA CVDPåŸºå‡†æµ‹è¯•ä¸­ï¼Œå°æ¨¡åž‹ä»£ç†å·¥ä½œæµå®žçŽ°ä½Žæˆæœ¬è¿‘LLMæ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Language Model(LLM) inference demands massive compute and energy, making domain-specific tasks expensive and unsustainable. As foundation models keep scaling, we ask: Is bigger always better for hardware design? Our work tests this by evaluating Small Language Models coupled with a curated agentic AI framework on NVIDIA's Comprehensive Verilog Design Problems(CVDP) benchmark. Results show that agentic workflows: through task decomposition, iterative feedback, and correction - not only unlock near-LLM performance at a fraction of the cost but also create learning opportunities for agents, paving the way for efficient, adaptive solutions in complex design tasks.

