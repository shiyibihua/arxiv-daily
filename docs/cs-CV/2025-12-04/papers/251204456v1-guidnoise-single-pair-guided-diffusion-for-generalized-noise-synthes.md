---
layout: default
title: GuidNoise: Single-Pair Guided Diffusion for Generalized Noise Synthesis
---

# GuidNoise: Single-Pair Guided Diffusion for Generalized Noise Synthesis

**arXiv**: [2512.04456v1](https://arxiv.org/abs/2512.04456) | [PDF](https://arxiv.org/pdf/2512.04456.pdf)

**ä½œè€…**: Changjin Kim, HyeokJun Lee, YoungJoon Yoo

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGuidNoiseï¼Œåˆ©ç”¨å•å¯¹å›¾åƒå¼•å¯¼æ‰©æ•£æ¨¡åž‹å®žçŽ°å¹¿ä¹‰å™ªå£°åˆæˆï¼Œä»¥è§£å†³çœŸå®žå™ªå£°æ•°æ®èŽ·å–æˆæœ¬é«˜çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `å™ªå£°åˆæˆ` `æ‰©æ•£æ¨¡åž‹` `å›¾åƒåŽ»å™ª` `æ•°æ®å¢žå¼º` `å•å¯¹å¼•å¯¼` `å¹¿ä¹‰å™ªå£°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰å™ªå£°åˆæˆæ–¹æ³•ä¾èµ–ç›¸æœºå…ƒæ•°æ®å’Œå¤§é‡å™ªå£°-å¹²å‡€å›¾åƒå¯¹ï¼Œæ³›åŒ–èƒ½åŠ›æœ‰é™ä¸”æ•°æ®èŽ·å–æˆæœ¬é«˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥GuidNoiseï¼ŒåŸºäºŽå•å¯¹å›¾åƒå¼•å¯¼ï¼Œé‡‡ç”¨GAFMå’Œå™ªå£°æ„ŸçŸ¥ç»†åŒ–æŸå¤±ä¼˜åŒ–æ‰©æ•£æ¨¡åž‹ï¼Œæ— éœ€é¢å¤–å…ƒæ•°æ®ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šGuidNoiseèƒ½åˆæˆé«˜è´¨é‡å™ªå£°å›¾åƒï¼Œå¢žå¼ºè®­ç»ƒæ•°æ®ï¼Œæå‡åŽ»å™ªæ€§èƒ½ï¼Œå°¤å…¶åœ¨è½»é‡æ¨¡åž‹å’Œæœ‰é™æ•°æ®åœºæ™¯ä¸‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent image denoising methods have leveraged generative modeling for real noise synthesis to address the costly acquisition of real-world noisy data. However, these generative models typically require camera metadata and extensive target-specific noisy-clean image pairs, often showing limited generalization between settings. In this paper, to mitigate the prerequisites, we propose a Single-Pair Guided Diffusion for generalized noise synthesis GuidNoise, which uses a single noisy/clean pair as the guidance, often easily obtained by itself within a training set. To train GuidNoise, which generates synthetic noisy images from the guidance, we introduce a guidance-aware affine feature modification (GAFM) and a noise-aware refine loss to leverage the inherent potential of diffusion models. This loss function refines the diffusion model's backward process, making the model more adept at generating realistic noise distributions. The GuidNoise synthesizes high-quality noisy images under diverse noise environments without additional metadata during both training and inference. Additionally, GuidNoise enables the efficient generation of noisy-clean image pairs at inference time, making synthetic noise readily applicable for augmenting training data. This self-augmentation significantly improves denoising performance, especially in practical scenarios with lightweight models and limited training data. The code is available at https://github.com/chjinny/GuidNoise.

