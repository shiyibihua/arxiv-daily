---
layout: default
title: Provable FDR Control for Deep Feature Selection: Deep MLPs and Beyond
---

# Provable FDR Control for Deep Feature Selection: Deep MLPs and Beyond

**arXiv**: [2512.04696v1](https://arxiv.org/abs/2512.04696) | [PDF](https://arxiv.org/pdf/2512.04696.pdf)

**ä½œè€…**: Kazuma Sawaya

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæ·±åº¦ç¥žç»ç½‘ç»œçš„çµæ´»ç‰¹å¾é€‰æ‹©æ¡†æž¶ï¼Œåœ¨å¹¿ä¹‰æ·±åº¦å­¦ä¹ è®¾ç½®ä¸­è¿‘ä¼¼æŽ§åˆ¶å‡å‘çŽ°çŽ‡ã€‚**

**å…³é”®è¯**: `ç‰¹å¾é€‰æ‹©` `å‡å‘çŽ°çŽ‡æŽ§åˆ¶` `æ·±åº¦å­¦ä¹ ` `æ¸è¿‘åˆ†æž` `ç¥žç»ç½‘ç»œæž¶æž„`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåœ¨æ·±åº¦å­¦ä¹ ä¸­å®žçŽ°ç‰¹å¾é€‰æ‹©çš„ç†è®ºå‡å‘çŽ°çŽ‡æŽ§åˆ¶ï¼Œä»¥è¡¡é‡ç±»åž‹Ié”™è¯¯ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€‚ç”¨äºŽé¦–å±‚å…¨è¿žæŽ¥çš„ç½‘ç»œï¼Œæ”¯æŒå¤šç§æž¶æž„å’Œè®­ç»ƒè¿‡ç¨‹ï¼ŒåŸºäºŽå¤šç´¢å¼•æ•°æ®ç”Ÿæˆæ¨¡åž‹å’Œæ¸è¿‘åˆ†æžã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ•°å€¼å®žéªŒéªŒè¯ç†è®ºå‘çŽ°ï¼Œä½†å‡è®¾è®¾è®¡çŸ©é˜µçš„å³æ­£äº¤ä¸å˜æ€§ä½œä¸ºç†è®ºé™åˆ¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We develop a flexible feature selection framework based on deep neural networks that approximately controls the false discovery rate (FDR), a measure of Type-I error. The method applies to architectures whose first layer is fully connected. From the second layer onward, it accommodates multilayer perceptrons (MLPs) of arbitrary width and depth, convolutional and recurrent networks, attention mechanisms, residual connections, and dropout. The procedure also accommodates stochastic gradient descent with data-independent initializations and learning rates. To the best of our knowledge, this is the first work to provide a theoretical guarantee of FDR control for feature selection within such a general deep learning setting.
>   Our analysis is built upon a multi-index data-generating model and an asymptotic regime in which the feature dimension $n$ diverges faster than the latent dimension $q^{*}$, while the sample size, the number of training iterations, the network depth, and hidden layer widths are left unrestricted. Under this setting, we show that each coordinate of the gradient-based feature-importance vector admits a marginal normal approximation, thereby supporting the validity of asymptotic FDR control. As a theoretical limitation, we assume $\mathbf{B}$-right orthogonal invariance of the design matrix, and we discuss broader generalizations. We also present numerical experiments that underscore the theoretical findings.

