---
layout: default
title: Towards Adaptive Fusion of Multimodal Deep Networks for Human Action Recognition
---

# Towards Adaptive Fusion of Multimodal Deep Networks for Human Action Recognition

**arXiv**: [2512.04943v1](https://arxiv.org/abs/2512.04943) | [PDF](https://arxiv.org/pdf/2512.04943.pdf)

**ä½œè€…**: Novanto Yudistira

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽé—¨æŽ§æœºåˆ¶çš„è‡ªé€‚åº”å¤šæ¨¡æ€èžåˆæ–¹æ³•ï¼Œä»¥æå‡äººç±»åŠ¨ä½œè¯†åˆ«çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§**

**å…³é”®è¯**: `å¤šæ¨¡æ€èžåˆ` `é—¨æŽ§æœºåˆ¶` `äººç±»åŠ¨ä½œè¯†åˆ«` `è‡ªé€‚åº”åŠ æƒ` `æ·±åº¦å­¦ä¹ ` `åŠ¨ä½œæ£€æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿå•æ¨¡æ€æ–¹æ³•åœ¨äººç±»åŠ¨ä½œè¯†åˆ«ä¸­å—é™äºŽä¿¡æ¯å•ä¸€ï¼Œéš¾ä»¥å…¨é¢æ•æ‰åŠ¨ä½œç‰¹å¾
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨é—¨æŽ§æœºåˆ¶è‡ªé€‚åº”èžåˆRGBã€å…‰æµã€éŸ³é¢‘å’Œæ·±åº¦ç­‰å¤šæ¨¡æ€ä¿¡æ¯ï¼Œé€‰æ‹©æ€§æ•´åˆå…³é”®ç‰¹å¾
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŸºå‡†æ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œåœ¨åŠ¨ä½œè¯†åˆ«ã€æš´åŠ›åŠ¨ä½œæ£€æµ‹ç­‰ä»»åŠ¡ä¸­å±•çŽ°å‡ºä¼˜äºŽå•æ¨¡æ€æ–¹æ³•çš„æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This study introduces a pioneering methodology for human action recognition by harnessing deep neural network techniques and adaptive fusion strategies across multiple modalities, including RGB, optical flows, audio, and depth information. Employing gating mechanisms for multimodal fusion, we aim to surpass limitations inherent in traditional unimodal recognition methods while exploring novel possibilities for diverse applications. Through an exhaustive investigation of gating mechanisms and adaptive weighting-based fusion architectures, our methodology enables the selective integration of relevant information from various modalities, thereby bolstering both accuracy and robustness in action recognition tasks. We meticulously examine various gated fusion strategies to pinpoint the most effective approach for multimodal action recognition, showcasing its superiority over conventional unimodal methods. Gating mechanisms facilitate the extraction of pivotal features, resulting in a more holistic representation of actions and substantial enhancements in recognition performance. Our evaluations across human action recognition, violence action detection, and multiple self-supervised learning tasks on benchmark datasets demonstrate promising advancements in accuracy. The significance of this research lies in its potential to revolutionize action recognition systems across diverse fields. The fusion of multimodal information promises sophisticated applications in surveillance and human-computer interaction, especially in contexts related to active assisted living.

