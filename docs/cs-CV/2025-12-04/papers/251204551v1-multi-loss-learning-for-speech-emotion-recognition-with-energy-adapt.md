---
layout: default
title: Multi-Loss Learning for Speech Emotion Recognition with Energy-Adaptive Mixup and Frame-Level Attention
---

# Multi-Loss Learning for Speech Emotion Recognition with Energy-Adaptive Mixup and Frame-Level Attention

**arXiv**: [2512.04551v1](https://arxiv.org/abs/2512.04551) | [PDF](https://arxiv.org/pdf/2512.04551.pdf)

**ä½œè€…**: Cong Wang, Yizhong Geng, Yuhua Wen, Qifei Li, Yingming Gao, Ruimin Wang, Chunfeng Wang, Hao Li, Ya Li, Wei Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæŸå¤±å­¦ä¹ æ¡†æž¶ï¼Œé›†æˆèƒ½é‡è‡ªé€‚åº”æ··åˆä¸Žå¸§çº§æ³¨æ„åŠ›ï¼Œä»¥æå‡è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«æ€§èƒ½ã€‚**

**å…³é”®è¯**: `è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«` `å¤šæŸå¤±å­¦ä¹ ` `æ•°æ®å¢žå¼º` `æ³¨æ„åŠ›æœºåˆ¶` `ç‰¹å¾æå–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«é¢ä¸´æƒ…æ„Ÿå¤æ‚æ€§å’Œæ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨èƒ½é‡è‡ªé€‚åº”æ··åˆå¢žå¼ºæ•°æ®å¤šæ ·æ€§ï¼Œç»“åˆå¸§çº§æ³¨æ„åŠ›æ¨¡å—ä¼˜åŒ–ç‰¹å¾æå–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å››ä¸ªå¸¸ç”¨æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œå®žçŽ°å…ˆè¿›æ€§èƒ½ï¼Œæ˜¾ç¤ºæ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Speech emotion recognition (SER) is an important technology in human-computer interaction. However, achieving high performance is challenging due to emotional complexity and scarce annotated data. To tackle these challenges, we propose a multi-loss learning (MLL) framework integrating an energy-adaptive mixup (EAM) method and a frame-level attention module (FLAM). The EAM method leverages SNR-based augmentation to generate diverse speech samples capturing subtle emotional variations. FLAM enhances frame-level feature extraction for multi-frame emotional cues. Our MLL strategy combines Kullback-Leibler divergence, focal, center, and supervised contrastive loss to optimize learning, address class imbalance, and improve feature separability. We evaluate our method on four widely used SER datasets: IEMOCAP, MSP-IMPROV, RAVDESS, and SAVEE. The results demonstrate our method achieves state-of-the-art performance, suggesting its effectiveness and robustness.

