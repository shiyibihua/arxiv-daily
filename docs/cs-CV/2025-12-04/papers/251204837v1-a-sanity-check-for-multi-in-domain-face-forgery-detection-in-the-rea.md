---
layout: default
title: A Sanity Check for Multi-In-Domain Face Forgery Detection in the Real World
---

# A Sanity Check for Multi-In-Domain Face Forgery Detection in the Real World

**arXiv**: [2512.04837v1](https://arxiv.org/abs/2512.04837) | [PDF](https://arxiv.org/pdf/2512.04837.pdf)

**ä½œè€…**: Jikang Cheng, Renye Yan, Zhiyuan Yan, Yaozhong Gan, Xueyi Zhang, Zhongyuan Wang, Wei Peng, Ling Liang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDevDetæ¡†æž¶ä»¥è§£å†³å¤šåŸŸäººè„¸ä¼ªé€ æ£€æµ‹ä¸­åŸŸå·®å¼‚ä¸»å¯¼ç‰¹å¾ç©ºé—´çš„é—®é¢˜**

**å…³é”®è¯**: `äººè„¸ä¼ªé€ æ£€æµ‹` `å¤šåŸŸå­¦ä¹ ` `ç‰¹å¾ç©ºé—´ä¼˜åŒ–` `æ¨¡åž‹æ³›åŒ–` `çœŸå®žä¸–ç•Œåº”ç”¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨è®­ç»ƒæ•°æ®æœ‰é™æ—¶éš¾ä»¥æ³›åŒ–è‡³å®Œå…¨æœªè§çš„å˜åŒ–ï¼Œå¤šåŸŸè®­ç»ƒè™½å¯è¡Œä½†åŸŸå·®å¼‚æŽ©ç›–çœŸä¼ªå·®å¼‚
2. æå‡ºæ¨¡åž‹æ— å…³æ¡†æž¶DevDetï¼ŒåŒ…å«FFDevå’ŒDAFTï¼Œæ”¾å¤§çœŸä¼ªå·®å¼‚ä½¿å…¶ä¸»å¯¼ç‰¹å¾ç©ºé—´
3. å®žéªŒæ˜¾ç¤ºåœ¨MID-FFDåœºæ™¯ä¸‹æå‡çœŸä¼ªé¢„æµ‹èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒå¯¹æœªè§æ•°æ®çš„æ³›åŒ–èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Existing methods for deepfake detection aim to develop generalizable detectors. Although "generalizable" is the ultimate target once and for all, with limited training forgeries and domains, it appears idealistic to expect generalization that covers entirely unseen variations, especially given the diversity of real-world deepfakes. Therefore, introducing large-scale multi-domain data for training can be feasible and important for real-world applications. However, within such a multi-domain scenario, the differences between multiple domains, rather than the subtle real/fake distinctions, dominate the feature space. As a result, despite detectors being able to relatively separate real and fake within each domain (i.e., high AUC), they struggle with single-image real/fake judgments in domain-unspecified conditions (i.e., low ACC). In this paper, we first define a new research paradigm named Multi-In-Domain Face Forgery Detection (MID-FFD), which includes sufficient volumes of real-fake domains for training. Then, the detector should provide definitive real-fake judgments to the domain-unspecified inputs, which simulate the frame-by-frame independent detection scenario in the real world. Meanwhile, to address the domain-dominant issue, we propose a model-agnostic framework termed DevDet (Developer for Detector) to amplify real/fake differences and make them dominant in the feature space. DevDet consists of a Face Forgery Developer (FFDev) and a Dose-Adaptive detector Fine-Tuning strategy (DAFT). Experiments demonstrate our superiority in predicting real-fake under the MID-FFD scenario while maintaining original generalization ability to unseen data.

