---
layout: default
title: Measuring the Unspoken: A Disentanglement Model and Benchmark for Psychological Analysis in the Wild
---

# Measuring the Unspoken: A Disentanglement Model and Benchmark for Psychological Analysis in the Wild

**arXiv**: [2512.04728v1](https://arxiv.org/abs/2512.04728) | [PDF](https://arxiv.org/pdf/2512.04728.pdf)

**ä½œè€…**: Yigui Feng, Qinglin Wang, Haotian Mo, Yang Liu, Ke Liu, Gencheng Liu, Xinhai Chen, Siqi Shen, Songzhu Mei, Jie Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMINDæ¨¡åž‹å’ŒPRISMåŸºå‡†ï¼Œè§£å†³é‡Žå¤–å¯¹è¯ä¸­è§†è§‰-è¯­è¨€æ¨¡åž‹çš„è¡¨è¾¾-æƒ…æ„Ÿæ­§ä¹‰å’Œè¯„ä¼°éš¾é¢˜ã€‚**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€æ¨¡åž‹` `å¿ƒç†åˆ†æž` `è§£è€¦å­¦ä¹ ` `å¾®è¡¨æƒ…æ£€æµ‹` `è¯„ä¼°åŸºå‡†` `é‡Žå¤–å¯¹è¯`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§†è§‰-è¯­è¨€æ¨¡åž‹åœ¨é‡Žå¤–å¯¹è¯ä¸­æ— æ³•å¤„ç†è¡¨è¾¾-æƒ…æ„Ÿæ­§ä¹‰ï¼Œä¸”ç¼ºä¹å¯éªŒè¯çš„è¯„ä¼°æŒ‡æ ‡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥MINDæ¨¡åž‹ï¼Œé€šè¿‡çŠ¶æ€åˆ¤æ–­æ¨¡å—æŠ‘åˆ¶æ­§ä¹‰å”‡éƒ¨ç‰¹å¾ï¼Œå®žçŽ°è§†è§‰è§£è€¦ï¼›æž„å»ºConvoInsight-DBæ•°æ®é›†å’ŒPRISMè¯„ä¼°æ¡†æž¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨PRISMåŸºå‡†ä¸Šï¼ŒMINDæ˜¾è‘—ä¼˜äºŽåŸºçº¿ï¼Œå¾®è¡¨æƒ…æ£€æµ‹æå‡86.95%ï¼Œæ¶ˆèžç ”ç©¶ç¡®è®¤çŠ¶æ€åˆ¤æ–­æ¨¡å—æ˜¯å…³é”®ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generative psychological analysis of in-the-wild conversations faces two fundamental challenges: (1) existing Vision-Language Models (VLMs) fail to resolve Articulatory-Affective Ambiguity, where visual patterns of speech mimic emotional expressions; and (2) progress is stifled by a lack of verifiable evaluation metrics capable of assessing visual grounding and reasoning depth. We propose a complete ecosystem to address these twin challenges. First, we introduce Multilevel Insight Network for Disentanglement(MIND), a novel hierarchical visual encoder that introduces a Status Judgment module to algorithmically suppress ambiguous lip features based on their temporal feature variance, achieving explicit visual disentanglement. Second, we construct ConvoInsight-DB, a new large-scale dataset with expert annotations for micro-expressions and deep psychological inference. Third, Third, we designed the Mental Reasoning Insight Rating Metric (PRISM), an automated dimensional framework that uses expert-guided LLM to measure the multidimensional performance of large mental vision models. On our PRISM benchmark, MIND significantly outperforms all baselines, achieving a +86.95% gain in micro-expression detection over prior SOTA. Ablation studies confirm that our Status Judgment disentanglement module is the most critical component for this performance leap. Our code has been opened.

