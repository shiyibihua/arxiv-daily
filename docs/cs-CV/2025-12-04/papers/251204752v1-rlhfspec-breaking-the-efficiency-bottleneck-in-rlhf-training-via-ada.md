---
layout: default
title: RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting
---

# RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting

**arXiv**: [2512.04752v1](https://arxiv.org/abs/2512.04752) | [PDF](https://arxiv.org/pdf/2512.04752.pdf)

**ä½œè€…**: Siqi Wang, Hailong Yang, Junjie Zhu, Xuezhu Wang, Yufan Xu, Depei Qian

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRLHFSpecç³»ç»Ÿï¼Œé€šè¿‡è‡ªé€‚åº”æŽ¨æµ‹è§£ç åŠ é€ŸRLHFè®­ç»ƒä¸­çš„ç”Ÿæˆé˜¶æ®µç“¶é¢ˆ**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆ` `æŽ¨æµ‹è§£ç ` `è‡ªé€‚åº”ç­–ç•¥` `GPUèµ„æºä¼˜åŒ–` `å¤§è¯­è¨€æ¨¡åž‹å¾®è°ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. RLHFè®­ç»ƒä¸­ç”Ÿæˆé˜¶æ®µæ˜¯æ•ˆçŽ‡ç“¶é¢ˆï¼Œéœ€ä¼˜åŒ–ä»¥æå‡æ•´ä½“æ‰§è¡Œé€Ÿåº¦
2. é›†æˆæŽ¨æµ‹è§£ç å¹¶é‡‡ç”¨è‡ªé€‚åº”ç­–ç•¥é€‰æ‹©ï¼Œç»“åˆæ ·æœ¬é‡åˆ†é…ä»¥å……åˆ†åˆ©ç”¨GPUèµ„æº
3. å®žéªŒæ˜¾ç¤ºåœ¨ç”Ÿæˆé˜¶æ®µå®žçŽ°æ›´é«˜åžåé‡ï¼Œæ˜¾è‘—åŠ é€Ÿæ•´ä¸ªRLHFæ‰§è¡Œè¿‡ç¨‹

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reinforcement Learning from Human Feedback (RLHF) is an important fine-tuning technique for large language models (LLMs) and comprises three stages: generation, inference, and training. The generation stage generates samples that are then used to infer learnable experiences for training. We observe that the generation stage is the bottleneck of the entire execution process and consider it a key point for optimization. Specifically, we realize the first attempt to integrate speculative decoding into the RLHF generation stage and propose RLHFSpec, an RLHF system that accelerates generation execution with adaptive speculative decoding and sample reallocation. To fully exploit the performance potential provided by speculative decoding, especially dealing with the dynamic workload of the generation stage, RLHFSpec proposes a workload-aware drafting strategy selection mechanism, which selects the near-optimal strategy by jointly considering the verification cost and the number of accepted tokens. Moreover, RLHFSpec also proposes sample reallocation to fully utilize the GPU resources, and optimizes it with an efficient sample migration mechanism. The experimental results show that the RLHFSpec can achieve higher throughput in the generation stage compared to state-of-the-art works. Moreover, due to the effective alleviation of the generation bottleneck, RLHFSpec also shows significant performance speedup in the entire RLHF execution.

