---
layout: default
title: Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems
---

# Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems

**arXiv**: [2512.04895v1](https://arxiv.org/abs/2512.04895) | [PDF](https://arxiv.org/pdf/2512.04895.pdf)

**ä½œè€…**: M Zeeshan, Saud Satti

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºChameleonè‡ªé€‚åº”å¯¹æŠ—æ¡†æž¶ä»¥è§£å†³å¤šæ¨¡æ€AIç³»ç»Ÿä¸­åŸºäºŽç¼©æ”¾çš„è§†è§‰æç¤ºæ³¨å…¥æ¼æ´ž**

**å…³é”®è¯**: `å¤šæ¨¡æ€AIå®‰å…¨` `è§†è§‰æç¤ºæ³¨å…¥` `è‡ªé€‚åº”å¯¹æŠ—æ”»å‡»` `å›¾åƒç¼©æ”¾æ¼æ´ž` `ä»£ç†ä¼˜åŒ–æœºåˆ¶` `é˜²å¾¡æœºåˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€AIç³»ç»Ÿä¾èµ–å›¾åƒç¼©æ”¾é¢„å¤„ç†ï¼Œæ˜“è¢«æ¶æ„è§†è§‰æç¤ºåˆ©ç”¨ï¼Œå½¢æˆå®‰å…¨æ¼æ´žã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åŸºäºŽä»£ç†çš„è¿­ä»£ä¼˜åŒ–æœºåˆ¶ï¼ŒåŠ¨æ€è°ƒæ•´å›¾åƒæ‰°åŠ¨ï¼Œé€‚åº”å®žæ—¶æ¨¡åž‹åé¦ˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Gemini 2.5 Flashæ¨¡åž‹ä¸Šæ”»å‡»æˆåŠŸçŽ‡84.5%ï¼Œæ˜¾è‘—ä¼˜äºŽé™æ€åŸºçº¿ï¼Œé™ä½Žå¤šæ­¥ä»»åŠ¡å†³ç­–å‡†ç¡®çŽ‡è¶…45%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal Artificial Intelligence (AI) systems, particularly Vision-Language Models (VLMs), have become integral to critical applications ranging from autonomous decision-making to automated document processing. As these systems scale, they rely heavily on preprocessing pipelines to handle diverse inputs efficiently. However, this dependency on standard preprocessing operations, specifically image downscaling, creates a significant yet often overlooked security vulnerability. While intended for computational optimization, scaling algorithms can be exploited to conceal malicious visual prompts that are invisible to human observers but become active semantic instructions once processed by the model. Current adversarial strategies remain largely static, failing to account for the dynamic nature of modern agentic workflows. To address this gap, we propose Chameleon, a novel, adaptive adversarial framework designed to expose and exploit scaling vulnerabilities in production VLMs. Unlike traditional static attacks, Chameleon employs an iterative, agent-based optimization mechanism that dynamically refines image perturbations based on the target model's real-time feedback. This allows the framework to craft highly robust adversarial examples that survive standard downscaling operations to hijack downstream execution. We evaluate Chameleon against Gemini 2.5 Flash model. Our experiments demonstrate that Chameleon achieves an Attack Success Rate (ASR) of 84.5% across varying scaling factors, significantly outperforming static baseline attacks which average only 32.1%. Furthermore, we show that these attacks effectively compromise agentic pipelines, reducing decision-making accuracy by over 45% in multi-step tasks. Finally, we discuss the implications of these vulnerabilities and propose multi-scale consistency checks as a necessary defense mechanism.

