---
layout: default
title: Hoi! -- A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation
---

# Hoi! -- A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation

**arXiv**: [2512.04884v1](https://arxiv.org/abs/2512.04884) | [PDF](https://arxiv.org/pdf/2512.04884.pdf)

**ä½œè€…**: Tim Engelbracht, RenÃ© ZurbrÃ¼gg, Matteo Wohlrapp, Martin BÃ¼chner, Abhinav Valada, Marc Pollefeys, Hermann Blum, Zuria Bauer

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHoi!æ•°æ®é›†ä»¥æ”¯æŒåŸºäºŽåŠ›æ„ŸçŸ¥çš„å¤šè§†è§’å…³èŠ‚æ“ä½œç ”ç©¶**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ•°æ®é›†` `å…³èŠ‚æ“ä½œ` `åŠ›æ„ŸçŸ¥` `è·¨è§†è§’å­¦ä¹ ` `äº¤äº’ç†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç¼ºä¹è€¦åˆè§†è§‰ã€åŠ¨ä½œä¸ŽåŠ›æ„ŸçŸ¥çš„å¤šæ¨¡æ€æ•°æ®é›†ï¼Œé™åˆ¶äº¤äº’ç†è§£ç ”ç©¶
2. æ–¹æ³•è¦ç‚¹ï¼šæ”¶é›†3048ä¸ªåºåˆ—ï¼Œæ¶µç›–381ä¸ªå…³èŠ‚ç‰©ä½“ï¼Œæä¾›å››ç§æ“ä½œè§†è§’ä¸ŽåŒæ­¥åŠ›/è§¦è§‰æ•°æ®
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ”¯æŒè·¨è§†è§’æ–¹æ³•è¯„ä¼°ï¼Œä¿ƒè¿›åŠ›æ„ŸçŸ¥ç­‰æœªå……åˆ†æŽ¢ç´¢æ¨¡æ€çš„ç ”ç©¶

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present a dataset for force-grounded, cross-view articulated manipulation that couples what is seen with what is done and what is felt during real human interaction. The dataset contains 3048 sequences across 381 articulated objects in 38 environments. Each object is operated under four embodiments - (i) human hand, (ii) human hand with a wrist-mounted camera, (iii) handheld UMI gripper, and (iv) a custom Hoi! gripper - where the tool embodiment provides synchronized end-effector forces and tactile sensing. Our dataset offers a holistic view of interaction understanding from video, enabling researchers to evaluate how well methods transfer between human and robotic viewpoints, but also investigate underexplored modalities such as force sensing and prediction.

