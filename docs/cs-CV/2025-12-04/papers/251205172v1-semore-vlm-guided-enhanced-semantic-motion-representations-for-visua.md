---
layout: default
title: Semore: VLM-guided Enhanced Semantic Motion Representations for Visual Reinforcement Learning
---

# Semore: VLM-guided Enhanced Semantic Motion Representations for Visual Reinforcement Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.05172" target="_blank" class="toolbar-btn">arXiv: 2512.05172v1</a>
    <a href="https://arxiv.org/pdf/2512.05172.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.05172v1" 
            onclick="toggleFavorite(this, '2512.05172v1', 'Semore: VLM-guided Enhanced Semantic Motion Representations for Visual Reinforcement Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Wentao Wang, Chunyang Liu, Kehua Sheng, Bo Zhang, Yan Wang

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-04

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**SemoreÔºöVLMÂºïÂØºÁöÑÂ¢ûÂº∫ËØ≠‰πâËøêÂä®Ë°®ÂæÅÁî®‰∫éËßÜËßâÂº∫ÂåñÂ≠¶‰π†**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâÂº∫ÂåñÂ≠¶‰π†` `ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã` `ËØ≠‰πâË°®ÂæÅ` `ËøêÂä®Ë°®ÂæÅ` `ÂèåË∑ØÂæÑÁΩëÁªú`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éLLMÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂú®ËßÜËßâË°®ÂæÅÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄßÔºåÊó†Ê≥ïÂÖÖÂàÜÂà©Áî®ËßÜËßâ‰ø°ÊÅØ„ÄÇ
2. SemoreÊ°ÜÊû∂Âà©Áî®VLMÊèêÂèñËØ≠‰πâÂíåËøêÂä®Ë°®ÂæÅÔºåÂπ∂ÈÄöËøáÂèåË∑ØÂæÑÈ™®Âπ≤ÁΩëÁªúËøõË°åËûçÂêàÔºåÊèêÂçáË°®ÂæÅËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSemoreÂú®VLMÁöÑÊåáÂØº‰∏ãÔºåÂ±ïÁé∞Âá∫ÊØîÁé∞ÊúâÊñπÊ≥ïÊõ¥È´òÊïàÂíåËá™ÈÄÇÂ∫îÁöÑËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã(LLM)ÂíåËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã(VLM)ÁöÑÊó•ÁõäÂèëÂ±ï‰∏∫ÊèêÈ´òÂº∫ÂåñÂ≠¶‰π†(RL)ÁöÑÊúâÊïàÊÄßÂºÄËæü‰∫ÜÈÅìË∑Ø„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÂü∫‰∫éLLMÁöÑRLÊñπÊ≥ïÈÄöÂ∏∏‰æßÈáç‰∫éÊéßÂà∂Á≠ñÁï•ÁöÑÊåáÂØºÔºåÂπ∂Èù¢‰∏¥È™®Âπ≤ÁΩëÁªúË°®ÂæÅËÉΩÂäõÊúâÈôêÁöÑÊåëÊàò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂü∫‰∫éVLMÁöÑËßÜËßâÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂‚Äî‚ÄîÂ¢ûÂº∫ËØ≠‰πâËøêÂä®Ë°®ÂæÅ(Semore)ÔºåÂÆÉÂèØ‰ª•ÈÄöËøáRGBÊµÅÁöÑÂèåË∑ØÂæÑÈ™®Âπ≤ÁΩëÁªúÂêåÊó∂ÊèêÂèñËØ≠‰πâÂíåËøêÂä®Ë°®ÂæÅ„ÄÇSemoreÂà©Áî®ÂÖ∑ÊúâÂ∏∏ËØÜÁü•ËØÜÁöÑVLM‰ªéËßÇÂØü‰∏≠Ê£ÄÁ¥¢ÂÖ≥ÈîÆ‰ø°ÊÅØÔºåÂêåÊó∂‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑclipÊù•ÂÆûÁé∞ÊñáÊú¨-ÂõæÂÉèÂØπÈΩêÔºå‰ªéËÄåÂ∞Üground-truthË°®ÂæÅÂµåÂÖ•Âà∞È™®Âπ≤ÁΩëÁªú‰∏≠„ÄÇ‰∏∫‰∫ÜÊúâÊïàÂú∞ËûçÂêàËØ≠‰πâÂíåËøêÂä®Ë°®ÂæÅ‰ª•ËøõË°åÂÜ≥Á≠ñÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÈááÁî®‰∫Ü‰∏ÄÁßçÂçïÁã¨ÁõëÁù£ÁöÑÊñπÊ≥ïÔºå‰ª•ÂêåÊó∂ÊåáÂØºËØ≠‰πâÂíåËøêÂä®ÁöÑÊèêÂèñÔºåÂêåÊó∂ÂÖÅËÆ∏ÂÆÉ‰ª¨Ëá™ÂèëÂú∞‰∫§‰∫í„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åË°®ÊòéÔºåÂú®ÁâπÂæÅÂ±ÇÈù¢ÁöÑVLMÊåáÂØº‰∏ãÔºå‰∏éÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïË°®Áé∞Âá∫È´òÊïàÂíåËá™ÈÄÇÂ∫îÁöÑËÉΩÂäõ„ÄÇÊâÄÊúâ‰ª£Á†ÅÂùáÂ∑≤ÂèëÂ∏É„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éLLMÁöÑËßÜËßâÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåÂÖ∂È™®Âπ≤ÁΩëÁªúÁöÑË°®ÂæÅËÉΩÂäõ‰∏çË∂≥ÔºåÊó†Ê≥ïÂÖÖÂàÜÊèêÂèñÂíåÂà©Áî®ËßÜËßâ‰ø°ÊÅØ‰∏≠ÁöÑËØ≠‰πâÂíåËøêÂä®‰ø°ÊÅØÔºå‰ªéËÄåÈôêÂà∂‰∫ÜÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÁöÑÊÄßËÉΩ„ÄÇËøô‰∫õÊñπÊ≥ïÈÄöÂ∏∏‰æßÈáç‰∫éÂà©Áî®LLMÊåáÂØºÊéßÂà∂Á≠ñÁï•ÔºåËÄåÂøΩÁï•‰∫ÜËßÜËßâË°®ÂæÅÁöÑÈáçË¶ÅÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSemoreÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®VLMÁöÑÂº∫Â§ßËØ≠‰πâÁêÜËß£ËÉΩÂäõÔºåÁªìÂêàRGBÊµÅ‰∏≠ÁöÑËøêÂä®‰ø°ÊÅØÔºåÊûÑÂª∫Â¢ûÂº∫ÁöÑËØ≠‰πâËøêÂä®Ë°®ÂæÅ„ÄÇÈÄöËøáVLM‰ªéËßÇÂØü‰∏≠ÊèêÂèñÂÖ≥ÈîÆËØ≠‰πâ‰ø°ÊÅØÔºåÂπ∂‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑCLIPÊ®°ÂûãÂÆûÁé∞ÊñáÊú¨-ÂõæÂÉèÂØπÈΩêÔºåÂ∞Üground-truthË°®ÂæÅÂµåÂÖ•Âà∞È™®Âπ≤ÁΩëÁªú‰∏≠Ôºå‰ªéËÄåÊèêÂçáËßÜËßâË°®ÂæÅÁöÑË¥®Èáè„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSemoreÈááÁî®ÂèåË∑ØÂæÑÈ™®Âπ≤ÁΩëÁªúÔºåÂàÜÂà´ÊèêÂèñËØ≠‰πâÂíåËøêÂä®Ë°®ÂæÅ„ÄÇ‰∏ÄÊù°Ë∑ØÂæÑÂ§ÑÁêÜRGBÂõæÂÉèÔºåÂà©Áî®VLMÊèêÂèñËØ≠‰πâ‰ø°ÊÅØÔºõÂè¶‰∏ÄÊù°Ë∑ØÂæÑÂ§ÑÁêÜRGBÊµÅÔºåÊèêÂèñËøêÂä®‰ø°ÊÅØ„ÄÇÁÑ∂ÂêéÔºåÈÄöËøáÂçïÁã¨ÁõëÁù£ÁöÑÊñπÂºèÔºåÂêåÊó∂ÊåáÂØºËØ≠‰πâÂíåËøêÂä®‰ø°ÊÅØÁöÑÊèêÂèñÔºåÂπ∂ÂÖÅËÆ∏ÂÆÉ‰ª¨Ëá™ÂèëÂú∞‰∫§‰∫í„ÄÇÊúÄÂêéÔºåÂ∞ÜËûçÂêàÂêéÁöÑË°®ÂæÅÁî®‰∫éÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÁöÑÂÜ≥Á≠ñ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSemoreÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂà©Áî®VLMÂú®ÁâπÂæÅÂ±ÇÈù¢ÊåáÂØºËßÜËßâË°®ÂæÅÁöÑÂ≠¶‰π†„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ï‰∏çÂêåÔºåSemore‰∏çÊòØÁõ¥Êé•Âà©Áî®LLMÁîüÊàêÊéßÂà∂Á≠ñÁï•ÔºåËÄåÊòØÂà©Áî®VLMÂ¢ûÂº∫ËßÜËßâË°®ÂæÅÔºå‰ªéËÄåÊèêÂçáÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÂèåË∑ØÂæÑÈ™®Âπ≤ÁΩëÁªúÂíåÂçïÁã¨ÁõëÁù£ÁöÑÊñπÂºè‰πü‰∏∫ËØ≠‰πâÂíåËøêÂä®‰ø°ÊÅØÁöÑÊúâÊïàËûçÂêàÊèê‰æõ‰∫Ü‰øùÈöú„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöSemoreÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑCLIPÊ®°ÂûãËøõË°åÊñáÊú¨-ÂõæÂÉèÂØπÈΩêÔºåÂ∞ÜVLMÊèêÂèñÁöÑËØ≠‰πâ‰ø°ÊÅØ‰∏éËßÜËßâ‰ø°ÊÅØÂØπÈΩêÔºõ2) ÈááÁî®ÂçïÁã¨ÁõëÁù£ÁöÑÊñπÂºèÔºåÂàÜÂà´ÊåáÂØºËØ≠‰πâÂíåËøêÂä®‰ø°ÊÅØÁöÑÊèêÂèñÔºåÈÅøÂÖç‰ø°ÊÅØ‰πãÈó¥ÁöÑÂπ≤Êâ∞Ôºõ3) ËÆæËÆ°ÂèåË∑ØÂæÑÈ™®Âπ≤ÁΩëÁªúÔºåÂàÜÂà´Â§ÑÁêÜRGBÂõæÂÉèÂíåRGBÊµÅÔºåÊèêÂèñËØ≠‰πâÂíåËøêÂä®‰ø°ÊÅØ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSemoreÂú®Â§ö‰∏™ËßÜËßâÂº∫ÂåñÂ≠¶‰π†‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰∏éÁé∞ÊúâÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåSemoreÂú®Êüê‰∫õ‰ªªÂä°‰∏äÂèñÂæó‰∫ÜË∂ÖËøá10%ÁöÑÊÄßËÉΩÊèêÂçáÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ËßÜËßâË°®ÂæÅÂ≠¶‰π†ÊñπÈù¢ÁöÑÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇ‰ª£Á†ÅÂ∑≤ÂºÄÊ∫ê„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SemoreÊ°ÜÊû∂ÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅËßÜËßâÊÑüÁü•ÁöÑÊú∫Âô®‰∫∫‰ªªÂä°Ôºå‰æãÂ¶ÇËá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÁâ©‰ΩìÊäìÂèñÁ≠â„ÄÇÈÄöËøáÂ¢ûÂº∫ËßÜËßâË°®ÂæÅÔºåSemoreÂèØ‰ª•ÊèêÈ´òÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊÑüÁü•ËÉΩÂäõÂíåÂÜ≥Á≠ñËÉΩÂäõÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÂÆâÂÖ®„ÄÅÊõ¥È´òÊïàÁöÑËá™Âä®Âåñ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The growing exploration of Large Language Models (LLM) and Vision-Language Models (VLM) has opened avenues for enhancing the effectiveness of reinforcement learning (RL). However, existing LLM-based RL methods often focus on the guidance of control policy and encounter the challenge of limited representations of the backbone networks. To tackle this problem, we introduce Enhanced Semantic Motion Representations (Semore), a new VLM-based framework for visual RL, which can simultaneously extract semantic and motion representations through a dual-path backbone from the RGB flows. Semore utilizes VLM with common-sense knowledge to retrieve key information from observations, while using the pre-trained clip to achieve the text-image alignment, thereby embedding the ground-truth representations into the backbone. To efficiently fuse semantic and motion representations for decision-making, our method adopts a separately supervised approach to simultaneously guide the extraction of semantics and motion, while allowing them to interact spontaneously. Extensive experiments demonstrate that, under the guidance of VLM at the feature level, our method exhibits efficient and adaptive ability compared to state-of-art methods. All codes are released.

