---
layout: default
title: Language Models as Semantic Teachers: Post-Training Alignment for Medical Audio Understanding
---

# Language Models as Semantic Teachers: Post-Training Alignment for Medical Audio Understanding

**arXiv**: [2512.04847v1](https://arxiv.org/abs/2512.04847) | [PDF](https://arxiv.org/pdf/2512.04847.pdf)

**ä½œè€…**: Tsai-Ning Wang, Lin-Lin Chen, Neil Zeghidour, Aaqib Saeed

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAcuLaæ¡†æž¶ï¼Œé€šè¿‡éŸ³é¢‘-è¯­è¨€å¯¹é½å¢žå¼ºåŒ»å­¦éŸ³é¢‘æ¨¡åž‹çš„ä¸´åºŠè¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚**

**å…³é”®è¯**: `åŒ»å­¦éŸ³é¢‘ç†è§£` `éŸ³é¢‘-è¯­è¨€å¯¹é½` `åŽè®­ç»ƒæ¡†æž¶` `è¯­ä¹‰æ•™å¸ˆ` `ä¸´åºŠæŠ¥å‘Šç”Ÿæˆ` `å¯¹æ¯”å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é¢„è®­ç»ƒéŸ³é¢‘æ¨¡åž‹èƒ½æ£€æµ‹å¬è¯Šå£°éŸ³çš„å£°å­¦æ¨¡å¼ï¼Œä½†ç¼ºä¹ä¸´åºŠæ„ä¹‰ç†è§£ï¼Œé™åˆ¶è¯Šæ–­åº”ç”¨ã€‚
2. AcuLaåˆ©ç”¨åŒ»å­¦è¯­è¨€æ¨¡åž‹ä½œä¸ºè¯­ä¹‰æ•™å¸ˆï¼Œé€šè¿‡è¡¨ç¤ºçº§å¯¹æ¯”å’Œè‡ªç›‘ç£å­¦ä¹ å¯¹é½éŸ³é¢‘ç¼–ç å™¨ã€‚
3. åœ¨18ä¸ªå¿ƒè‚ºä»»åŠ¡ä¸Šå®žçŽ°SOTAï¼Œå¹³å‡AUROCä»Ž0.68æå‡è‡³0.79ï¼ŒCOVID-19å’³å—½æ£€æµ‹AUROCä»Ž0.55æå‡è‡³0.89ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Pre-trained audio models excel at detecting acoustic patterns in auscultation sounds but often fail to grasp their clinical significance, limiting their use and performance in diagnostic tasks. To bridge this gap, we introduce AcuLa (Audio-Clinical Understanding via Language Alignment), a lightweight post-training framework that instills semantic understanding into any audio encoder by aligning it with a medical language model, which acts as a "semantic teacher." To enable alignment at scale, we construct a large-scale dataset by leveraging off-the-shelf large language models to translate the rich, structured metadata accompanying existing audio recordings into coherent clinical reports. Our alignment strategy combines a representation-level contrastive objective with a self-supervised modeling, ensuring that the model learns clinical semantics while preserving fine-grained temporal cues. AcuLa achieves state-of-the-art results across 18 diverse cardio-respiratory tasks from 10 different datasets, improving the mean AUROC on classification benchmarks from 0.68 to 0.79 and, on the most challenging COVID-19 cough detection task, boosting the AUROC from 0.55 to 0.89. Our work demonstrates that this audio-language alignment transforms purely acoustic models into clinically-aware diagnostic tools, establishing a novel paradigm for enhancing physiological understanding in audio-based health monitoring.

