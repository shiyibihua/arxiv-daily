---
layout: default
title: MT-Depth: Multi-task Instance feature analysis for the Depth Completion
---

# MT-Depth: Multi-task Instance feature analysis for the Depth Completion

**arXiv**: [2512.04734v1](https://arxiv.org/abs/2512.04734) | [PDF](https://arxiv.org/pdf/2512.04734.pdf)

**ä½œè€…**: Abdul Haseeb Nizamani, Dandi Zhou, Xinhai Sun

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMT-Depthæ¡†æž¶ï¼Œé€šè¿‡å®žä¾‹æ„ŸçŸ¥å¼•å¯¼æ·±åº¦è¡¥å…¨ï¼Œæå‡ç¨€ç–æ·±åº¦æ•°æ®åœ¨è‡ªåŠ¨é©¾é©¶ç­‰åœºæ™¯ä¸‹çš„ç²¾åº¦ã€‚**

**å…³é”®è¯**: `æ·±åº¦è¡¥å…¨` `å®žä¾‹æ„ŸçŸ¥` `è·¨æ³¨æ„åŠ›èžåˆ` `è‡ªåŠ¨é©¾é©¶` `ç¨€ç–æ·±åº¦æ•°æ®` `å¯¹è±¡è¾¹ç•Œä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ·±åº¦è¡¥å…¨æ–¹æ³•ä¾èµ–è¯­ä¹‰åˆ†å‰²ï¼Œå¿½ç•¥å¯¹è±¡çº§ç†è§£ï¼Œå¯¼è‡´è¾¹ç•Œå’Œé®æŒ¡åŒºåŸŸç²¾åº¦ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆYOLO V11å®žä¾‹åˆ†å‰²ã€U-Netæ·±åº¦è¡¥å…¨ã€è·¨æ³¨æ„åŠ›èžåˆå’Œæ³¨æ„åŠ›å¼•å¯¼é¢„æµ‹å¤´ï¼Œåˆ©ç”¨äºŒå€¼å®žä¾‹æŽ©ç ä½œä¸ºç©ºé—´å…ˆéªŒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Virtual KITTI 2æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œç›¸æ¯”åŸºçº¿é™ä½ŽRMSEï¼Œä¿æŒç«žäº‰æ€§MAEï¼Œæœ‰æ•ˆæå‡å¯¹è±¡è¾¹ç•Œå’Œè–„ç»“æž„å¤„çš„æ·±åº¦å‡†ç¡®æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Depth completion plays a vital role in 3D perception systems, especially in scenarios where sparse depth data must be densified for tasks such as autonomous driving, robotics, and augmented reality. While many existing approaches rely on semantic segmentation to guide depth completion, they often overlook the benefits of object-level understanding. In this work, we introduce an instance-aware depth completion framework that explicitly integrates binary instance masks as spatial priors to refine depth predictions. Our model combines four main components: a frozen YOLO V11 instance segmentation branch, a U-Net-based depth completion backbone, a cross-attention fusion module, and an attention-guided prediction head. The instance segmentation branch generates per-image foreground masks that guide the depth branch via cross-attention, allowing the network to focus on object-centric regions during refinement. We validate our method on the Virtual KITTI 2 dataset, showing that it achieves lower RMSE compared to both a U-Net-only baseline and previous semantic-guided methods, while maintaining competitive MAE. Qualitative and quantitative results demonstrate that the proposed model effectively enhances depth accuracy near object boundaries, occlusions, and thin structures. Our findings suggest that incorporating instance-aware cues offers a promising direction for improving depth completion without relying on dense semantic labels.

