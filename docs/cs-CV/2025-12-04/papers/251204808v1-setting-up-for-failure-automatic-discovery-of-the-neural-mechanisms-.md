---
layout: default
title: Setting up for failure: automatic discovery of the neural mechanisms of cognitive errors
---

# Setting up for failure: automatic discovery of the neural mechanisms of cognitive errors

**arXiv**: [2512.04808v1](https://arxiv.org/abs/2512.04808) | [PDF](https://arxiv.org/pdf/2512.04808.pdf)

**ä½œè€…**: Puria Radmard, Paul M. Bays, MÃ¡tÃ© Lengyel

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªåŠ¨å‘çŽ°è®¤çŸ¥é”™è¯¯ç¥žç»æœºåˆ¶çš„æ–¹æ³•ï¼Œé€šè¿‡è®­ç»ƒRNNæ¨¡æ‹Ÿè¡Œä¸ºæ•°æ®**

**å…³é”®è¯**: `è®¤çŸ¥é”™è¯¯æœºåˆ¶` `å¾ªçŽ¯ç¥žç»ç½‘ç»œè®­ç»ƒ` `è¡Œä¸ºæ•°æ®æ¨¡æ‹Ÿ` `æ‰©æ•£æ¨¡åž‹` `è§†è§‰å·¥ä½œè®°å¿†` `ç¥žç»æœºåˆ¶å‘çŽ°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»ŸRNNå»ºæ¨¡è®¤çŸ¥æœºåˆ¶ä¾èµ–äººå·¥è¿­ä»£ï¼Œæ•ˆçŽ‡ä½Žä¸”å¯å‘å¼
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨éžå‚æ•°ç”Ÿæˆæ¨¡åž‹ç”Ÿæˆæ›¿ä»£æ•°æ®ï¼Œç»“åˆæ‰©æ•£æ¨¡åž‹è®­ç»ƒRNNæ¨¡æ‹Ÿè¡Œä¸º
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨è§†è§‰å·¥ä½œè®°å¿†ä»»åŠ¡ä¸­ï¼ŒRNNåŠ¨æ€åŒ¹é…çŒ•çŒ´ç¥žç»æ•°æ®ï¼Œé¢„æµ‹äº¤æ¢é”™è¯¯æœºåˆ¶

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Discovering the neural mechanisms underpinning cognition is one of the grand challenges of neuroscience. However, previous approaches for building models of RNN dynamics that explain behaviour required iterative refinement of architectures and/or optimisation objectives, resulting in a piecemeal, and mostly heuristic, human-in-the-loop process. Here, we offer an alternative approach that automates the discovery of viable RNN mechanisms by explicitly training RNNs to reproduce behaviour, including the same characteristic errors and suboptimalities, that humans and animals produce in a cognitive task. Achieving this required two main innovations. First, as the amount of behavioural data that can be collected in experiments is often too limited to train RNNs, we use a non-parametric generative model of behavioural responses to produce surrogate data for training RNNs. Second, to capture all relevant statistical aspects of the data, we developed a novel diffusion model-based approach for training RNNs. To showcase the potential of our approach, we chose a visual working memory task as our test-bed, as behaviour in this task is well known to produce response distributions that are patently multimodal (due to swap errors). The resulting network dynamics correctly qualitative features of macaque neural data. Importantly, these results were not possible to obtain with more traditional approaches, i.e., when only a limited set of behavioural signatures (rather than the full richness of behavioural response distributions) were fitted, or when RNNs were trained for task optimality (instead of reproducing behaviour). Our approach also yields novel predictions about the mechanism of swap errors, which can be readily tested in experiments. These results suggest that fitting RNNs to rich patterns of behaviour provides a powerful way to automatically discover mechanisms of important cognitive functions.

