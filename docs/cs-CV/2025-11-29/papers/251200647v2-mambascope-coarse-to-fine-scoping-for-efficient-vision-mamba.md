---
layout: default
title: MambaScope: Coarse-to-Fine Scoping for Efficient Vision Mamba
---

# MambaScope: Coarse-to-Fine Scoping for Efficient Vision Mamba

**arXiv**: [2512.00647v2](https://arxiv.org/abs/2512.00647) | [PDF](https://arxiv.org/pdf/2512.00647.pdf)

**ä½œè€…**: Shanhui Liu, Rui Xu, Yunke Wang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-29 (æ›´æ–°: 2025-12-03)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MambaScopeï¼šç”¨äºŽé«˜æ•ˆVision Mambaçš„ç²—åˆ°ç»†è‡ªé€‚åº”æŽ¨ç†æ¡†æž¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `Vision Mamba` `é«˜æ•ˆæŽ¨ç†` `è‡ªé€‚åº”è®¡ç®—` `åŠ¨æ€åˆ†è¾¨çŽ‡` `è§†è§‰ä»»åŠ¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰Vision Mambaçš„tokenç¼©å‡æ–¹æ³•ä¼šå› ä¸¢å¼ƒæˆ–åŽ‹ç¼©tokenè¡¨ç¤ºè€Œå¯¼è‡´ä¿¡æ¯æŸå¤±ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†ä¸åŒå¤æ‚åº¦çš„å›¾åƒæ—¶ã€‚
2. MambaScopeé€šè¿‡ç²—ç²’åº¦æŽ¨ç†å¿«é€Ÿå¤„ç†ç®€å•å›¾åƒï¼Œä»…å¯¹å¤æ‚åŒºåŸŸè¿›è¡Œç»†ç²’åº¦å¤„ç†ï¼Œä»Žè€Œè‡ªé€‚åº”åœ°åˆ†é…è®¡ç®—èµ„æºã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒMambaScopeåœ¨å¤šç§è§†è§‰ä»»åŠ¡ä¸­ï¼Œç›¸æ¯”åŸºçº¿Vision Mambaå’ŒçŽ°æœ‰tokenç¼©å‡æŠ€æœ¯ï¼Œå®žçŽ°äº†æ›´é«˜çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Vision Mambaä½œä¸ºVision Transformerçš„ä¸€ç§æœ‰å‰æ™¯ä¸”é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆå·²ç»å‡ºçŽ°ï¼Œä½†å…¶æ•ˆçŽ‡ä»ç„¶å—åˆ°è¾“å…¥tokenæ•°é‡çš„æ ¹æœ¬é™åˆ¶ã€‚çŽ°æœ‰çš„tokenç¼©å‡æ–¹æ³•é€šå¸¸é‡‡ç”¨tokenå‰ªæžæˆ–åˆå¹¶æ¥å‡å°‘è®¡ç®—é‡ã€‚ç„¶è€Œï¼Œå®ƒä»¬å›ºæœ‰åœ°å¯¼è‡´ä¿¡æ¯ä¸¢å¤±ï¼Œå› ä¸ºå®ƒä»¬ä¸¢å¼ƒæˆ–åŽ‹ç¼©tokenè¡¨ç¤ºã€‚å½“ç›¸åŒçš„ç»†ç²’åº¦tokenå¤„ç†è¢«ç»Ÿä¸€åº”ç”¨äºŽæ‰€æœ‰å›¾åƒæ—¶ï¼Œæ— è®ºè§†è§‰å¤æ‚æ€§å¦‚ä½•ï¼Œè¿™ä¸ªé—®é¢˜éƒ½ä¼šè¿›ä¸€æ­¥åŠ å‰§ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°å¹¶éžæ‰€æœ‰è¾“å…¥éƒ½éœ€è¦ç»†ç²’åº¦å¤„ç†ï¼šç®€å•çš„å›¾åƒå¯ä»¥åœ¨ç²—åˆ†è¾¨çŽ‡ä¸‹æœ‰æ•ˆåœ°å¤„ç†ï¼Œè€Œåªæœ‰å¤æ‚çš„å›¾åƒæ‰éœ€è¦ç»†åŒ–ã€‚åŸºäºŽè¿™ç§æ´žå¯Ÿï¼Œæˆ‘ä»¬æå‡ºäº†MambaScopeï¼Œä¸€ç§ç”¨äºŽé«˜æ•ˆVision MambaæŽ¨ç†çš„è‡ªé€‚åº”æ¡†æž¶ã€‚MambaScopeé¦–å…ˆé€šè¿‡å°†è¾“å…¥å›¾åƒåˆ’åˆ†ä¸ºå¤§patchæ¥æ‰§è¡Œç²—ç²’åº¦æŽ¨ç†ï¼Œä»Žè€Œæ˜¾è‘—å‡å°‘tokené•¿åº¦å’Œè®¡ç®—é‡ã€‚å½“æ¨¡åž‹çš„é¢„æµ‹ç½®ä¿¡åº¦è¾ƒä½Žæ—¶ï¼Œé€‰æ‹©çš„åŒºåŸŸä»¥æ›´ç²¾ç»†çš„åˆ†è¾¨çŽ‡é‡æ–°å¤„ç†ï¼Œä»¥æœ€å°çš„é¢å¤–æˆæœ¬æ¢å¤å¿…è¦çš„è§†è§‰ç»†èŠ‚ã€‚è¿™ç§åŠ¨æ€åˆ†è¾¨çŽ‡åˆ†é…ç­–ç•¥å…è®¸MambaScopeæ ¹æ®å›¾åƒå¤æ‚æ€§è‡ªé€‚åº”åœ°åˆ†é…è®¡ç®—é‡ï¼Œä»Žè€Œåœ¨ä¸å½±å“å‡†ç¡®æ€§çš„æƒ…å†µä¸‹å®žçŽ°é«˜æ•ˆå¤„ç†ã€‚è·¨å„ç§è§†è§‰ä»»åŠ¡çš„å®žéªŒè¡¨æ˜Žï¼ŒMambaScopeåœ¨å‡†ç¡®æ€§å’Œæ•ˆçŽ‡æ–¹é¢å‡ä¼˜äºŽåŸºçº¿Vision Mambaå’Œæœ€å…ˆè¿›çš„tokenç¼©å‡æŠ€æœ¯ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³Vision Mambaåœ¨å¤„ç†ä¸åŒå¤æ‚åº¦çš„å›¾åƒæ—¶ï¼Œè®¡ç®—èµ„æºåˆ†é…ä¸å‡çš„é—®é¢˜ã€‚çŽ°æœ‰tokenç¼©å‡æ–¹æ³•ï¼Œå¦‚å‰ªæžå’Œåˆå¹¶ï¼Œä¼šä¸å¯é¿å…åœ°é€ æˆä¿¡æ¯æŸå¤±ï¼Œå¹¶ä¸”æ— æ³•æ ¹æ®å›¾åƒå†…å®¹è‡ªé€‚åº”åœ°è°ƒæ•´è®¡ç®—é‡ï¼Œå¯¼è‡´æ•ˆçŽ‡ç“¶é¢ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€æƒ³æ˜¯æ ¹æ®å›¾åƒçš„è§†è§‰å¤æ‚æ€§ï¼ŒåŠ¨æ€åœ°è°ƒæ•´æŽ¨ç†çš„åˆ†è¾¨çŽ‡ã€‚å¯¹äºŽç®€å•çš„å›¾åƒï¼Œé‡‡ç”¨ç²—ç²’åº¦çš„æŽ¨ç†æ–¹å¼ï¼Œå‡å°‘tokenæ•°é‡ï¼Œé™ä½Žè®¡ç®—æˆæœ¬ï¼›å¯¹äºŽå¤æ‚çš„å›¾åƒï¼Œåˆ™åœ¨éœ€è¦ç²¾ç»†ä¿¡æ¯çš„åŒºåŸŸé‡‡ç”¨ç»†ç²’åº¦çš„æŽ¨ç†æ–¹å¼ï¼Œä»¥ä¿è¯å‡†ç¡®æ€§ã€‚è¿™ç§è‡ªé€‚åº”çš„ç­–ç•¥å¯ä»¥åœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜è®¡ç®—æ•ˆçŽ‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šMambaScopeæ¡†æž¶ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šç²—ç²’åº¦æŽ¨ç†é˜¶æ®µå’Œç»†ç²’åº¦æŽ¨ç†é˜¶æ®µã€‚åœ¨ç²—ç²’åº¦æŽ¨ç†é˜¶æ®µï¼Œè¾“å…¥å›¾åƒè¢«åˆ’åˆ†ä¸ºè¾ƒå¤§çš„patchï¼Œå‡å°‘tokenæ•°é‡ï¼Œå¹¶ä½¿ç”¨Vision Mambaè¿›è¡Œåˆæ­¥é¢„æµ‹ã€‚å¦‚æžœæ¨¡åž‹çš„é¢„æµ‹ç½®ä¿¡åº¦è¾ƒä½Žï¼Œåˆ™è¿›å…¥ç»†ç²’åº¦æŽ¨ç†é˜¶æ®µã€‚åœ¨ç»†ç²’åº¦æŽ¨ç†é˜¶æ®µï¼Œé€‰æ‹©ç½®ä¿¡åº¦è¾ƒä½Žçš„åŒºåŸŸï¼Œä»¥æ›´ç²¾ç»†çš„åˆ†è¾¨çŽ‡é‡æ–°å¤„ç†ï¼Œä»Žè€Œæ¢å¤å¿…è¦çš„è§†è§‰ç»†èŠ‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šMambaScopeçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶åŠ¨æ€åˆ†è¾¨çŽ‡åˆ†é…ç­–ç•¥ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ä¸åŒï¼ŒMambaScopeä¸æ˜¯å¯¹æ‰€æœ‰å›¾åƒéƒ½é‡‡ç”¨ç›¸åŒçš„å¤„ç†æ–¹å¼ï¼Œè€Œæ˜¯æ ¹æ®å›¾åƒçš„å¤æ‚æ€§è‡ªé€‚åº”åœ°è°ƒæ•´è®¡ç®—é‡ã€‚è¿™ç§ç­–ç•¥å¯ä»¥åœ¨ä¿è¯å‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œæ˜¾è‘—æé«˜è®¡ç®—æ•ˆçŽ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šMambaScopeçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é¢„æµ‹ç½®ä¿¡åº¦ä½œä¸ºé€‰æ‹©éœ€è¦ç»†ç²’åº¦å¤„ç†åŒºåŸŸçš„æŒ‡æ ‡ï¼›2) é‡‡ç”¨ç²—åˆ°ç»†çš„åˆ†è¾¨çŽ‡ç­–ç•¥ï¼Œå…ˆè¿›è¡Œç²—ç²’åº¦æŽ¨ç†ï¼Œå†æ ¹æ®éœ€è¦è¿›è¡Œç»†ç²’åº¦æŽ¨ç†ï¼›3) æ¡†æž¶å¯ä»¥çµæ´»åœ°ä¸Žä¸åŒçš„Vision Mambaæ¨¡åž‹ç»“åˆä½¿ç”¨ï¼Œå…·æœ‰è¾ƒå¼ºçš„é€šç”¨æ€§ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªæ˜Žç¡®æåŠï¼Œå±žäºŽæœªçŸ¥ä¿¡æ¯ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒMambaScopeåœ¨å¤šä¸ªè§†è§‰ä»»åŠ¡ä¸Šå‡ä¼˜äºŽåŸºçº¿Vision Mambaå’ŒçŽ°æœ‰çš„tokenç¼©å‡æŠ€æœ¯ã€‚å…·ä½“æ€§èƒ½æ•°æ®åœ¨æ‘˜è¦ä¸­æœ‰æ‰€æåŠï¼Œä½†æœªç»™å‡ºå…·ä½“æ•°å€¼ã€‚æ€»ä½“è€Œè¨€ï¼ŒMambaScopeåœ¨ä¿è¯æˆ–æå‡å‡†ç¡®çŽ‡çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½Žäº†è®¡ç®—æˆæœ¬ï¼ŒéªŒè¯äº†å…¶é«˜æ•ˆæ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

MambaScopeå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²è§†è§‰æ¨¡åž‹ï¼Œå¦‚ç§»åŠ¨è®¾å¤‡å’ŒåµŒå…¥å¼ç³»ç»Ÿã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºŽå®žæ—¶è§†é¢‘åˆ†æžã€è‡ªåŠ¨é©¾é©¶ç­‰éœ€è¦é«˜æ•ˆæŽ¨ç†çš„åœºæ™¯ï¼Œé™ä½Žè®¡ç®—æˆæœ¬ï¼Œæé«˜å“åº”é€Ÿåº¦ã€‚æœªæ¥ï¼ŒMambaScopeçš„è‡ªé€‚åº”æŽ¨ç†æ€æƒ³å¯ä»¥æŽ¨å¹¿åˆ°å…¶ä»–è§†è§‰æ¨¡åž‹å’Œä»»åŠ¡ä¸­ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision Mamba has emerged as a promising and efficient alternative to Vision Transformers, yet its efficiency remains fundamentally constrained by the number of input tokens. Existing token reduction approaches typically adopt token pruning or merging to reduce computation. However, they inherently lead to information loss as they discard or compress token representations. This problem is further exacerbated when the same fine-grained token processing is uniformly applied across all images regardless of visual complexity. We observe that not all inputs require fine-grained processing: simple images can be effectively handled at a coarse resolution, while only complex ones require refinement. Based on this insight, we propose MambaScope, an adaptive framework for efficient inference for Vision Mamba. MambaScope first performs coarse-grained inference by dividing the input image into large patches, significantly reducing token length and computation. When the model's prediction confidence is low, selected regions are re-processed at a finer resolution to recover essential visual details with minimal additional cost. This dynamic resolution assignment strategy allows MambaScope to allocate computation adaptively according to image complexity, achieving efficient processing without compromising accuracy. Experiments across various vision tasks demonstrate that MambaScope outperforms both the baseline Vision Mamba and state-of-the-art token reduction techniques in terms of accuracy and efficiency.

