---
layout: default
title: Describe Anything Anywhere At Any Moment
---

# Describe Anything Anywhere At Any Moment

**arXiv**: [2512.00565v1](https://arxiv.org/abs/2512.00565) | [PDF](https://arxiv.org/pdf/2512.00565.pdf)

**ä½œè€…**: Nicolas Gorlo, Lukas Schmid, Luca Carlone

**åˆ†ç±»**: cs.CV, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-29

**å¤‡æ³¨**: 14 pages, 5 figures, 6 tables

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDAAAMæ¡†æž¶ï¼Œå®žçŽ°å¤§è§„æ¨¡åœºæ™¯ä¸‹ä»»æ„æ—¶ç©ºä½ç½®çš„å®žæ—¶è¯­ä¹‰æè¿°ä¸ŽæŽ¨ç†ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `4Dåœºæ™¯ç†è§£` `æ—¶ç©ºè®°å¿†` `åœºæ™¯å›¾` `è¯­ä¹‰æè¿°` `æœºå™¨äººå¯¼èˆª`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆä¸°å¯Œçš„å¼€æ”¾è¯æ±‡æè¿°æ—¶ï¼Œéš¾ä»¥å…¼é¡¾3Dåœºæ™¯ä¸­å®žæ—¶æ€§èƒ½ï¼Œé¢ä¸´ä¸¤éš¾ã€‚
2. DAAAMé€šè¿‡ä¼˜åŒ–çš„å‰ç«¯ä»Žå±€éƒ¨å­—å¹•æ¨¡åž‹æŽ¨æ–­è¯­ä¹‰æè¿°ï¼Œå¹¶æž„å»ºåˆ†å±‚4Dåœºæ™¯å›¾ï¼Œå®žçŽ°é«˜æ•ˆæ—¶ç©ºè®°å¿†ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒDAAAMåœ¨æ—¶ç©ºé—®ç­”å’Œä»»åŠ¡æ‰§è¡Œæ–¹é¢å‡ä¼˜äºŽçŽ°æœ‰æŠ€æœ¯ï¼Œå¹¶åœ¨OC-NaVQAä¸Šæ˜¾è‘—æå‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºâ€œDescribe Anything, Anywhere, at Any Moment (DAAAM)â€çš„æ–°åž‹æ—¶ç©ºè®°å¿†æ¡†æž¶ï¼Œç”¨äºŽå¤§è§„æ¨¡å’Œå®žæ—¶çš„4Dåœºæ™¯ç†è§£ã€‚DAAAMå¼•å…¥äº†ä¸€ç§åŸºäºŽä¼˜åŒ–çš„å‰ç«¯ï¼Œåˆ©ç”¨å±€éƒ¨å­—å¹•æ¨¡åž‹ï¼ˆå¦‚Describe Anything Model (DAM)ï¼‰æŽ¨æ–­è¯¦ç»†çš„è¯­ä¹‰æè¿°ï¼Œå¹¶é€šè¿‡æ‰¹é‡å¤„ç†å°†åœ¨çº¿å¤„ç†çš„æŽ¨ç†é€Ÿåº¦æé«˜äº†ä¸€ä¸ªæ•°é‡çº§ã€‚å®ƒåˆ©ç”¨è¿™ç§è¯­ä¹‰ç†è§£æ¥æž„å»ºä¸€ä¸ªåˆ†å±‚çš„4Dåœºæ™¯å›¾ï¼ˆSGï¼‰ï¼Œè¯¥åœºæ™¯å›¾ä½œä¸ºä¸€ä¸ªæœ‰æ•ˆçš„å…¨å±€ç©ºé—´å’Œæ—¶é—´ä¸€è‡´çš„è®°å¿†è¡¨ç¤ºã€‚DAAAMæž„å»ºå…·æœ‰è¯¦ç»†çš„ã€å‡ ä½•å¯¹é½çš„æè¿°çš„4D SGï¼ŒåŒæ—¶ä¿æŒå®žæ—¶æ€§èƒ½ã€‚æˆ‘ä»¬å±•ç¤ºäº†DAAAMçš„4D SGä¸Žç”¨äºŽæŽ¨ç†å’ŒæŽ¨ç†çš„å·¥å…·è°ƒç”¨ä»£ç†è‰¯å¥½åœ°æŽ¥å£ã€‚æˆ‘ä»¬åœ¨NaVQAåŸºå‡†æµ‹è¯•ä¸­å¯¹æ—¶ç©ºé—®ç­”çš„å¤æ‚ä»»åŠ¡è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨SG3DåŸºå‡†æµ‹è¯•ä¸­å¯¹é¡ºåºä»»åŠ¡æŽ¥åœ°çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥ç­–åˆ’äº†ä¸€ä¸ªæ‰©å±•çš„OC-NaVQAåŸºå‡†æµ‹è¯•ï¼Œç”¨äºŽå¤§è§„æ¨¡å’Œé•¿æ—¶é—´è¯„ä¼°ã€‚DAAAMåœ¨è¿™ä¸¤é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æžœï¼Œåˆ†åˆ«å°†OC-NaVQAé—®é¢˜çš„å‡†ç¡®çŽ‡æé«˜äº†53.6%ï¼Œä½ç½®è¯¯å·®æé«˜äº†21.9%ï¼Œæ—¶é—´è¯¯å·®æé«˜äº†21.6%ï¼ŒSG3Dä»»åŠ¡çš„å‡†ç¡®çŽ‡æé«˜äº†27.8%ã€‚æˆ‘ä»¬å¼€æºå‘å¸ƒäº†æˆ‘ä»¬çš„æ•°æ®å’Œä»£ç ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§è§„æ¨¡çŽ¯å¢ƒä¸­ï¼Œå¦‚ä½•å®žæ—¶åœ°å¯¹ä»»æ„æ—¶ç©ºä½ç½®è¿›è¡Œè¯¦ç»†çš„è¯­ä¹‰æè¿°å’Œç†è§£çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆå¼€æ”¾è¯æ±‡æè¿°æ—¶ï¼Œéœ€è¦æ¶ˆè€—å¤§é‡çš„è®¡ç®—èµ„æºï¼Œéš¾ä»¥æ»¡è¶³å®žæ—¶æ€§è¦æ±‚ï¼Œå°¤å…¶æ˜¯åœ¨3Dåœºæ™¯ä¸­è¿›è¡Œ grounding æ—¶ï¼Œæ€§èƒ½ä¼šæ˜¾è‘—ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å±€éƒ¨captioningæ¨¡åž‹ï¼ˆå¦‚DAMï¼‰ç”Ÿæˆè¯¦ç»†çš„è¯­ä¹‰æè¿°ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–çš„å‰ç«¯è¿›è¡Œæ‰¹é‡å¤„ç†ï¼Œä»Žè€ŒåŠ é€ŸæŽ¨ç†è¿‡ç¨‹ã€‚åŒæ—¶ï¼Œæž„å»ºä¸€ä¸ªåˆ†å±‚çš„4Dåœºæ™¯å›¾ï¼ˆSGï¼‰ï¼Œä½œä¸ºå…¨å±€ç©ºé—´å’Œæ—¶é—´ä¸€è‡´çš„è®°å¿†è¡¨ç¤ºï¼Œç”¨äºŽå­˜å‚¨å’Œæ£€ç´¢åœºæ™¯ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šDAAAMæ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) å±€éƒ¨captioningæ¨¡åž‹ï¼ˆå¦‚DAMï¼‰ï¼šç”¨äºŽç”Ÿæˆåœºæ™¯ä¸­ç‰©ä½“çš„è¯­ä¹‰æè¿°ã€‚2) ä¼˜åŒ–å‰ç«¯ï¼šé€šè¿‡æ‰¹é‡å¤„ç†åŠ é€Ÿè¯­ä¹‰æè¿°çš„æŽ¨ç†è¿‡ç¨‹ã€‚3) 4Dåœºæ™¯å›¾æž„å»ºæ¨¡å—ï¼šå°†è¯­ä¹‰æè¿°å’Œå‡ ä½•ä¿¡æ¯æ•´åˆåˆ°4Dåœºæ™¯å›¾ä¸­ï¼Œæž„å»ºå…¨å±€ä¸€è‡´çš„åœºæ™¯è¡¨ç¤ºã€‚4) å·¥å…·è°ƒç”¨ä»£ç†ï¼šåˆ©ç”¨4Dåœºæ™¯å›¾è¿›è¡ŒæŽ¨ç†å’Œå†³ç­–ï¼Œå®Œæˆå„ç§ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šDAAAMçš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) æå‡ºäº†ä¸€ç§åŸºäºŽä¼˜åŒ–çš„å‰ç«¯ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜å±€éƒ¨captioningæ¨¡åž‹çš„æŽ¨ç†é€Ÿåº¦ï¼Œä½¿å…¶èƒ½å¤Ÿæ»¡è¶³å®žæ—¶æ€§è¦æ±‚ã€‚2) æž„å»ºäº†ä¸€ä¸ªåˆ†å±‚çš„4Dåœºæ™¯å›¾ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å­˜å‚¨å’Œæ£€ç´¢åœºæ™¯ä¿¡æ¯ï¼Œå¹¶æ”¯æŒå¤æ‚çš„æ—¶ç©ºæŽ¨ç†ä»»åŠ¡ã€‚

**å…³é”®è®¾è®¡**ï¼šDAAAMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä¼˜åŒ–å‰ç«¯çš„æ‰¹é‡å¤„ç†ç­–ç•¥ï¼Œå¦‚ä½•é€‰æ‹©åˆé€‚çš„batch sizeï¼Œä»¥å¹³è¡¡æŽ¨ç†é€Ÿåº¦å’Œå†…å­˜æ¶ˆè€—ã€‚2) 4Dåœºæ™¯å›¾çš„æž„å»ºæ–¹å¼ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°æ•´åˆè¯­ä¹‰ä¿¡æ¯å’Œå‡ ä½•ä¿¡æ¯ï¼Œå¹¶æ”¯æŒé«˜æ•ˆçš„æŸ¥è¯¢æ“ä½œã€‚3) å·¥å…·è°ƒç”¨ä»£ç†çš„è®¾è®¡ï¼Œå¦‚ä½•åˆ©ç”¨4Dåœºæ™¯å›¾è¿›è¡ŒæŽ¨ç†å’Œå†³ç­–ï¼Œå®Œæˆå„ç§ä»»åŠ¡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

DAAAMåœ¨NaVQAå’ŒSG3DåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨OC-NaVQAä¸Šï¼ŒDAAAMçš„é—®é¢˜å‡†ç¡®çŽ‡æé«˜äº†53.6%ï¼Œä½ç½®è¯¯å·®é™ä½Žäº†21.9%ï¼Œæ—¶é—´è¯¯å·®é™ä½Žäº†21.6%ã€‚åœ¨SG3Dä¸Šï¼ŒDAAAMçš„ä»»åŠ¡æ‰§è¡Œå‡†ç¡®çŽ‡æé«˜äº†27.8%ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒDAAAMèƒ½å¤Ÿæœ‰æ•ˆåœ°è¿›è¡Œæ—¶ç©ºæŽ¨ç†å’Œä»»åŠ¡æ‰§è¡Œã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

DAAAMæ¡†æž¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚å¢žå¼ºçŽ°å®žã€æœºå™¨äººè‡ªä¸»å¯¼èˆªã€æ™ºèƒ½å®¶å±…ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å‘¨å›´çŽ¯å¢ƒï¼Œå¹¶æ ¹æ®ç”¨æˆ·çš„æŒ‡ä»¤æ‰§è¡Œå„ç§ä»»åŠ¡ã€‚æ­¤å¤–ï¼ŒDAAAMè¿˜å¯ä»¥ç”¨äºŽæž„å»ºè™šæ‹ŸçŽ°å®žåœºæ™¯ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›æ›´åŠ æ²‰æµ¸å¼çš„ä½“éªŒã€‚æœªæ¥ï¼ŒDAAAMæœ‰æœ›æˆä¸ºä¸‹ä¸€ä»£æ™ºèƒ½ç³»ç»Ÿçš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Computer vision and robotics applications ranging from augmented reality to robot autonomy in large-scale environments require spatio-temporal memory frameworks that capture both geometric structure for accurate language-grounding as well as semantic detail. Existing methods face a tradeoff, where producing rich open-vocabulary descriptions comes at the expense of real-time performance when these descriptions have to be grounded in 3D. To address these challenges, we propose Describe Anything, Anywhere, at Any Moment (DAAAM), a novel spatio-temporal memory framework for large-scale and real-time 4D scene understanding. DAAAM introduces a novel optimization-based frontend to infer detailed semantic descriptions from localized captioning models, such as the Describe Anything Model (DAM), leveraging batch processing to speed up inference by an order of magnitude for online processing. It leverages such semantic understanding to build a hierarchical 4D scene graph (SG), which acts as an effective globally spatially and temporally consistent memory representation. DAAAM constructs 4D SGs with detailed, geometrically grounded descriptions while maintaining real-time performance. We show that DAAAM's 4D SG interfaces well with a tool-calling agent for inference and reasoning.
>   We thoroughly evaluate DAAAM in the complex task of spatio-temporal question answering on the NaVQA benchmark and show its generalization capabilities for sequential task grounding on the SG3D benchmark. We further curate an extended OC-NaVQA benchmark for large-scale and long-time evaluations. DAAAM achieves state-of-the-art results in both tasks, improving OC-NaVQA question accuracy by 53.6%, position errors by 21.9%, temporal errors by 21.6%, and SG3D task grounding accuracy by 27.8% over the most competitive baselines, respectively. We release our data and code open-source.

