---
layout: default
title: Describe Anything Anywhere At Any Moment
---

# Describe Anything Anywhere At Any Moment

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.00565" target="_blank" class="toolbar-btn">arXiv: 2512.00565v1</a>
    <a href="https://arxiv.org/pdf/2512.00565.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.00565v1" 
            onclick="toggleFavorite(this, '2512.00565v1', 'Describe Anything Anywhere At Any Moment')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Nicolas Gorlo, Lukas Schmid, Luca Carlone

**åˆ†ç±»**: cs.CV, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-29

**å¤‡æ³¨**: 14 pages, 5 figures, 6 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDAAAMæ¡†æ¶ï¼Œå®ç°å¤§è§„æ¨¡åœºæ™¯ä¸‹ä»»æ„æ—¶ç©ºä½ç½®çš„å®æ—¶è¯­ä¹‰æè¿°ä¸æ¨ç†ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `4Dåœºæ™¯ç†è§£` `æ—¶ç©ºè®°å¿†` `åœºæ™¯å›¾` `è¯­ä¹‰æè¿°` `æœºå™¨äººå¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆä¸°å¯Œçš„å¼€æ”¾è¯æ±‡æè¿°æ—¶ï¼Œéš¾ä»¥å…¼é¡¾3Dåœºæ™¯ä¸­å®æ—¶æ€§èƒ½ï¼Œé¢ä¸´ä¸¤éš¾ã€‚
2. DAAAMé€šè¿‡ä¼˜åŒ–çš„å‰ç«¯ä»å±€éƒ¨å­—å¹•æ¨¡å‹æ¨æ–­è¯­ä¹‰æè¿°ï¼Œå¹¶æ„å»ºåˆ†å±‚4Dåœºæ™¯å›¾ï¼Œå®ç°é«˜æ•ˆæ—¶ç©ºè®°å¿†ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDAAAMåœ¨æ—¶ç©ºé—®ç­”å’Œä»»åŠ¡æ‰§è¡Œæ–¹é¢å‡ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå¹¶åœ¨OC-NaVQAä¸Šæ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºâ€œDescribe Anything, Anywhere, at Any Moment (DAAAM)â€çš„æ–°å‹æ—¶ç©ºè®°å¿†æ¡†æ¶ï¼Œç”¨äºå¤§è§„æ¨¡å’Œå®æ—¶çš„4Dåœºæ™¯ç†è§£ã€‚DAAAMå¼•å…¥äº†ä¸€ç§åŸºäºä¼˜åŒ–çš„å‰ç«¯ï¼Œåˆ©ç”¨å±€éƒ¨å­—å¹•æ¨¡å‹ï¼ˆå¦‚Describe Anything Model (DAM)ï¼‰æ¨æ–­è¯¦ç»†çš„è¯­ä¹‰æè¿°ï¼Œå¹¶é€šè¿‡æ‰¹é‡å¤„ç†å°†åœ¨çº¿å¤„ç†çš„æ¨ç†é€Ÿåº¦æé«˜äº†ä¸€ä¸ªæ•°é‡çº§ã€‚å®ƒåˆ©ç”¨è¿™ç§è¯­ä¹‰ç†è§£æ¥æ„å»ºä¸€ä¸ªåˆ†å±‚çš„4Dåœºæ™¯å›¾ï¼ˆSGï¼‰ï¼Œè¯¥åœºæ™¯å›¾ä½œä¸ºä¸€ä¸ªæœ‰æ•ˆçš„å…¨å±€ç©ºé—´å’Œæ—¶é—´ä¸€è‡´çš„è®°å¿†è¡¨ç¤ºã€‚DAAAMæ„å»ºå…·æœ‰è¯¦ç»†çš„ã€å‡ ä½•å¯¹é½çš„æè¿°çš„4D SGï¼ŒåŒæ—¶ä¿æŒå®æ—¶æ€§èƒ½ã€‚æˆ‘ä»¬å±•ç¤ºäº†DAAAMçš„4D SGä¸ç”¨äºæ¨ç†å’Œæ¨ç†çš„å·¥å…·è°ƒç”¨ä»£ç†è‰¯å¥½åœ°æ¥å£ã€‚æˆ‘ä»¬åœ¨NaVQAåŸºå‡†æµ‹è¯•ä¸­å¯¹æ—¶ç©ºé—®ç­”çš„å¤æ‚ä»»åŠ¡è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨SG3DåŸºå‡†æµ‹è¯•ä¸­å¯¹é¡ºåºä»»åŠ¡æ¥åœ°çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥ç­–åˆ’äº†ä¸€ä¸ªæ‰©å±•çš„OC-NaVQAåŸºå‡†æµ‹è¯•ï¼Œç”¨äºå¤§è§„æ¨¡å’Œé•¿æ—¶é—´è¯„ä¼°ã€‚DAAAMåœ¨è¿™ä¸¤é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œåˆ†åˆ«å°†OC-NaVQAé—®é¢˜çš„å‡†ç¡®ç‡æé«˜äº†53.6%ï¼Œä½ç½®è¯¯å·®æé«˜äº†21.9%ï¼Œæ—¶é—´è¯¯å·®æé«˜äº†21.6%ï¼ŒSG3Dä»»åŠ¡çš„å‡†ç¡®ç‡æé«˜äº†27.8%ã€‚æˆ‘ä»¬å¼€æºå‘å¸ƒäº†æˆ‘ä»¬çš„æ•°æ®å’Œä»£ç ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§è§„æ¨¡ç¯å¢ƒä¸­ï¼Œå¦‚ä½•å®æ—¶åœ°å¯¹ä»»æ„æ—¶ç©ºä½ç½®è¿›è¡Œè¯¦ç»†çš„è¯­ä¹‰æè¿°å’Œç†è§£çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆå¼€æ”¾è¯æ±‡æè¿°æ—¶ï¼Œéœ€è¦æ¶ˆè€—å¤§é‡çš„è®¡ç®—èµ„æºï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶æ€§è¦æ±‚ï¼Œå°¤å…¶æ˜¯åœ¨3Dåœºæ™¯ä¸­è¿›è¡Œ grounding æ—¶ï¼Œæ€§èƒ½ä¼šæ˜¾è‘—ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å±€éƒ¨captioningæ¨¡å‹ï¼ˆå¦‚DAMï¼‰ç”Ÿæˆè¯¦ç»†çš„è¯­ä¹‰æè¿°ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–çš„å‰ç«¯è¿›è¡Œæ‰¹é‡å¤„ç†ï¼Œä»è€ŒåŠ é€Ÿæ¨ç†è¿‡ç¨‹ã€‚åŒæ—¶ï¼Œæ„å»ºä¸€ä¸ªåˆ†å±‚çš„4Dåœºæ™¯å›¾ï¼ˆSGï¼‰ï¼Œä½œä¸ºå…¨å±€ç©ºé—´å’Œæ—¶é—´ä¸€è‡´çš„è®°å¿†è¡¨ç¤ºï¼Œç”¨äºå­˜å‚¨å’Œæ£€ç´¢åœºæ™¯ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDAAAMæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) å±€éƒ¨captioningæ¨¡å‹ï¼ˆå¦‚DAMï¼‰ï¼šç”¨äºç”Ÿæˆåœºæ™¯ä¸­ç‰©ä½“çš„è¯­ä¹‰æè¿°ã€‚2) ä¼˜åŒ–å‰ç«¯ï¼šé€šè¿‡æ‰¹é‡å¤„ç†åŠ é€Ÿè¯­ä¹‰æè¿°çš„æ¨ç†è¿‡ç¨‹ã€‚3) 4Dåœºæ™¯å›¾æ„å»ºæ¨¡å—ï¼šå°†è¯­ä¹‰æè¿°å’Œå‡ ä½•ä¿¡æ¯æ•´åˆåˆ°4Dåœºæ™¯å›¾ä¸­ï¼Œæ„å»ºå…¨å±€ä¸€è‡´çš„åœºæ™¯è¡¨ç¤ºã€‚4) å·¥å…·è°ƒç”¨ä»£ç†ï¼šåˆ©ç”¨4Dåœºæ™¯å›¾è¿›è¡Œæ¨ç†å’Œå†³ç­–ï¼Œå®Œæˆå„ç§ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šDAAAMçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§åŸºäºä¼˜åŒ–çš„å‰ç«¯ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜å±€éƒ¨captioningæ¨¡å‹çš„æ¨ç†é€Ÿåº¦ï¼Œä½¿å…¶èƒ½å¤Ÿæ»¡è¶³å®æ—¶æ€§è¦æ±‚ã€‚2) æ„å»ºäº†ä¸€ä¸ªåˆ†å±‚çš„4Dåœºæ™¯å›¾ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å­˜å‚¨å’Œæ£€ç´¢åœºæ™¯ä¿¡æ¯ï¼Œå¹¶æ”¯æŒå¤æ‚çš„æ—¶ç©ºæ¨ç†ä»»åŠ¡ã€‚

**å…³é”®è®¾è®¡**ï¼šDAAAMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä¼˜åŒ–å‰ç«¯çš„æ‰¹é‡å¤„ç†ç­–ç•¥ï¼Œå¦‚ä½•é€‰æ‹©åˆé€‚çš„batch sizeï¼Œä»¥å¹³è¡¡æ¨ç†é€Ÿåº¦å’Œå†…å­˜æ¶ˆè€—ã€‚2) 4Dåœºæ™¯å›¾çš„æ„å»ºæ–¹å¼ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°æ•´åˆè¯­ä¹‰ä¿¡æ¯å’Œå‡ ä½•ä¿¡æ¯ï¼Œå¹¶æ”¯æŒé«˜æ•ˆçš„æŸ¥è¯¢æ“ä½œã€‚3) å·¥å…·è°ƒç”¨ä»£ç†çš„è®¾è®¡ï¼Œå¦‚ä½•åˆ©ç”¨4Dåœºæ™¯å›¾è¿›è¡Œæ¨ç†å’Œå†³ç­–ï¼Œå®Œæˆå„ç§ä»»åŠ¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DAAAMåœ¨NaVQAå’ŒSG3DåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨OC-NaVQAä¸Šï¼ŒDAAAMçš„é—®é¢˜å‡†ç¡®ç‡æé«˜äº†53.6%ï¼Œä½ç½®è¯¯å·®é™ä½äº†21.9%ï¼Œæ—¶é—´è¯¯å·®é™ä½äº†21.6%ã€‚åœ¨SG3Dä¸Šï¼ŒDAAAMçš„ä»»åŠ¡æ‰§è¡Œå‡†ç¡®ç‡æé«˜äº†27.8%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒDAAAMèƒ½å¤Ÿæœ‰æ•ˆåœ°è¿›è¡Œæ—¶ç©ºæ¨ç†å’Œä»»åŠ¡æ‰§è¡Œã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DAAAMæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚å¢å¼ºç°å®ã€æœºå™¨äººè‡ªä¸»å¯¼èˆªã€æ™ºèƒ½å®¶å±…ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å‘¨å›´ç¯å¢ƒï¼Œå¹¶æ ¹æ®ç”¨æˆ·çš„æŒ‡ä»¤æ‰§è¡Œå„ç§ä»»åŠ¡ã€‚æ­¤å¤–ï¼ŒDAAAMè¿˜å¯ä»¥ç”¨äºæ„å»ºè™šæ‹Ÿç°å®åœºæ™¯ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›æ›´åŠ æ²‰æµ¸å¼çš„ä½“éªŒã€‚æœªæ¥ï¼ŒDAAAMæœ‰æœ›æˆä¸ºä¸‹ä¸€ä»£æ™ºèƒ½ç³»ç»Ÿçš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Computer vision and robotics applications ranging from augmented reality to robot autonomy in large-scale environments require spatio-temporal memory frameworks that capture both geometric structure for accurate language-grounding as well as semantic detail. Existing methods face a tradeoff, where producing rich open-vocabulary descriptions comes at the expense of real-time performance when these descriptions have to be grounded in 3D. To address these challenges, we propose Describe Anything, Anywhere, at Any Moment (DAAAM), a novel spatio-temporal memory framework for large-scale and real-time 4D scene understanding. DAAAM introduces a novel optimization-based frontend to infer detailed semantic descriptions from localized captioning models, such as the Describe Anything Model (DAM), leveraging batch processing to speed up inference by an order of magnitude for online processing. It leverages such semantic understanding to build a hierarchical 4D scene graph (SG), which acts as an effective globally spatially and temporally consistent memory representation. DAAAM constructs 4D SGs with detailed, geometrically grounded descriptions while maintaining real-time performance. We show that DAAAM's 4D SG interfaces well with a tool-calling agent for inference and reasoning.
>   We thoroughly evaluate DAAAM in the complex task of spatio-temporal question answering on the NaVQA benchmark and show its generalization capabilities for sequential task grounding on the SG3D benchmark. We further curate an extended OC-NaVQA benchmark for large-scale and long-time evaluations. DAAAM achieves state-of-the-art results in both tasks, improving OC-NaVQA question accuracy by 53.6%, position errors by 21.9%, temporal errors by 21.6%, and SG3D task grounding accuracy by 27.8% over the most competitive baselines, respectively. We release our data and code open-source.

