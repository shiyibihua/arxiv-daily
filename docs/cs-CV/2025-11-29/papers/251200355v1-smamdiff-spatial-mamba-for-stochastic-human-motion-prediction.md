---
layout: default
title: SMamDiff: Spatial Mamba for Stochastic Human Motion Prediction
---

# SMamDiff: Spatial Mamba for Stochastic Human Motion Prediction

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.00355" target="_blank" class="toolbar-btn">arXiv: 2512.00355v1</a>
    <a href="https://arxiv.org/pdf/2512.00355.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.00355v1" 
            onclick="toggleFavorite(this, '2512.00355v1', 'SMamDiff: Spatial Mamba for Stochastic Human Motion Prediction')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Junqiao Fan, Pengfei Liu, Haocong Rao

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-29

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SMamDiffÔºå‰∏ÄÁßçÂü∫‰∫éÁ©∫Èó¥MambaÁöÑÂçïÈò∂ÊÆµÊâ©Êï£Ê®°ÂûãÔºåÁî®‰∫éÈöèÊú∫‰∫∫‰ΩìËøêÂä®È¢ÑÊµã„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `‰∫∫‰ΩìËøêÂä®È¢ÑÊµã` `Êâ©Êï£Ê®°Âûã` `Á©∫Èó¥Mamba` `Êó∂Á©∫ËøûË¥ØÊÄß` `ÊÆãÂ∑ÆDCT` `ÂçïÈò∂ÊÆµÊ®°Âûã` `ËæπÁºòËÆ°ÁÆó`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâHMPÊñπÊ≥ïÈöæ‰ª•ÂÖºÈ°æÈ¢ÑÊµãÁªìÊûúÁöÑÂáÜÁ°ÆÊÄß„ÄÅÂ§öÊ†∑ÊÄßÂíåËøêÂä®Â≠¶ÂêàÁêÜÊÄßÔºå‰∏îÂ§öÈò∂ÊÆµÊâ©Êï£Ê®°ÂûãËÆ°ÁÆóÊàêÊú¨È´òÊòÇÔºå‰∏çÂà©‰∫éËæπÁºòÈÉ®ÁΩ≤„ÄÇ
2. SMamDiffÈÄöËøáÊÆãÂ∑ÆDCTÁºñÁ†ÅÊèêÂèñÈ´òÈ¢ëËøêÂä®‰ø°ÊÅØÔºåÂπ∂Âà©Áî®Á©∫Èó¥MambaÊ®°ÂùóÂª∫Ê®°ÂÖ≥ËäÇÈó¥ÁöÑÈïøÁ®ã‰æùËµñÂÖ≥Á≥ªÔºå‰ªéËÄåÊèêÂçáÊó∂Á©∫ËøûË¥ØÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåSMamDiffÂú®ÂçïÈò∂ÊÆµÊ¶ÇÁéáHMPÊñπÊ≥ï‰∏≠ÂèñÂæó‰∫ÜSOTAÁªìÊûúÔºåÂπ∂Âú®Âª∂ËøüÂíåÂÜÖÂ≠òÂç†Áî®ÊñπÈù¢‰ºò‰∫éÂ§öÈò∂ÊÆµÊâ©Êï£Ê®°Âûã„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÊô∫ËÉΩÂÆ§ÂÜÖ‰º†ÊÑüÂíåÊúçÂä°Êú∫Âô®‰∫∫ÁöÑÂπøÊ≥õÈÉ®ÁΩ≤Ôºå‰∫∫‰ΩìËøêÂä®È¢ÑÊµãÔºàHMPÔºâÂØπ‰∫éÂÆâÂÖ®„ÄÅ‰∏ªÂä®ÁöÑËæÖÂä©Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåËÆ∏Â§öÁé∞ÊúâÁöÑHMPÊñπÊ≥ïË¶Å‰πà‰∫ßÁîüÂçï‰∏ÄÁöÑ„ÄÅÁ°ÆÂÆöÊÄßÁöÑÈ¢ÑÊµãÔºåÂøΩÁï•‰∫Ü‰∏çÁ°ÆÂÆöÊÄßÔºåË¶Å‰πà‰æùËµñ‰∫éÁâ∫Áâ≤ËøêÂä®Â≠¶ÂêàÁêÜÊÄßÁöÑÊ¶ÇÁéáÊ®°Âûã„ÄÇÊâ©Êï£Ê®°ÂûãÊîπÂñÑ‰∫ÜÂáÜÁ°ÆÊÄß-Â§öÊ†∑ÊÄßÁöÑÊùÉË°°Ôºå‰ΩÜÈÄöÂ∏∏‰æùËµñ‰∫éÂ§öÈò∂ÊÆµÊµÅÁ®ãÔºåËøôÂØπ‰∫éËæπÁºòÈÉ®ÁΩ≤Êù•ËØ¥ÊàêÊú¨È´òÊòÇ„ÄÇËøôÈ°πÂ∑•‰Ωú‰æßÈáç‰∫éÂ¶Ç‰ΩïÂú®Áî®‰∫éHMPÁöÑÂçïÈò∂ÊÆµÊâ©Êï£Ê®°Âûã‰∏≠Á°Æ‰øùÊó∂Á©∫ËøûË¥ØÊÄß„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫ÜSMamDiffÔºå‰∏ÄÁßçÂü∫‰∫éÁ©∫Èó¥MambaÁöÑÊâ©Êï£Ê®°ÂûãÔºåÂÖ∑Êúâ‰∏§‰∏™Êñ∞È¢ñÁöÑËÆæËÆ°ÔºöÔºàiÔºâ‰∏ÄÁßçÊÆãÂ∑Æ-DCTËøêÂä®ÁºñÁ†ÅÔºåÂú®Êó∂Èó¥DCT‰πãÂâçÂáèÂéªÊúÄÂêéËßÇÂØüÂà∞ÁöÑÂßøÂäøÔºåÂáèÂ∞ë‰∫ÜÁ¨¨‰∏Ä‰∏™DCÂàÜÈáèÔºàf=0ÔºâÁöÑ‰∏ªÂØºÂú∞‰ΩçÔºåÂπ∂Á™ÅÂá∫‰∫Ü‰ø°ÊÅØÈáèÊõ¥Â§ßÁöÑÈ´òÈ¢ëÁ∫øÁ¥¢ÔºåÂõ†Ê≠§Ê®°ÂûãÂ≠¶‰π†ÂÖ≥ËäÇÂ¶Ç‰ΩïÁßªÂä®ËÄå‰∏çÊòØÂÆÉ‰ª¨Âú®Âì™ÈáåÔºõÔºàiiÔºâ‰∏Ä‰∏™ÁÅ´Êü¥‰∫∫ÁªòÂà∂Á©∫Èó¥MambaÊ®°ÂùóÔºå‰ª•ÊúâÂ∫èÁöÑ„ÄÅÈÄêÂÖ≥ËäÇÁöÑÊñπÂºèÂ§ÑÁêÜÂÖ≥ËäÇÔºå‰ΩøÂêéÈù¢ÁöÑÂÖ≥ËäÇ‰ª•ÂâçÈù¢ÁöÑÂÖ≥ËäÇ‰∏∫Êù°‰ª∂Ôºå‰ª•ËØ±ÂØºÈïøÁ®ã„ÄÅË∑®ÂÖ≥ËäÇÁöÑ‰æùËµñÂÖ≥Á≥ª„ÄÇÂú®Human3.6MÂíåHumanEva‰∏äÔºåËøô‰∫õËøûË¥ØÊÄßÊú∫Âà∂Âú®ÂçïÈò∂ÊÆµÊ¶ÇÁéáHMPÊñπÊ≥ï‰∏≠Êèê‰æõ‰∫ÜÊúÄÂÖàËøõÁöÑÁªìÊûúÔºåÂêåÊó∂ÊØîÂ§öÈò∂ÊÆµÊâ©Êï£Âü∫Á∫ø‰ΩøÁî®Êõ¥Â∞ëÁöÑÂª∂ËøüÂíåÂÜÖÂ≠ò„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**Ôºö‰∫∫‰ΩìËøêÂä®È¢ÑÊµãÔºàHMPÔºâÊó®Âú®Ê†πÊçÆËøáÂéª‰∏ÄÊÆµÊó∂Èó¥ÁöÑ‰∫∫‰ΩìËøêÂä®ËΩ®ËøπÔºåÈ¢ÑÊµãÊú™Êù•‰∏ÄÊÆµÊó∂Èó¥ÁöÑËøêÂä®ËΩ®Ëøπ„ÄÇÁé∞ÊúâÊñπÊ≥ïÁöÑÁóõÁÇπÂú®‰∫éÔºåÁ°ÆÂÆöÊÄßÊ®°ÂûãÂøΩÁï•‰∫ÜËøêÂä®ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÔºåÊ¶ÇÁéáÊ®°ÂûãÂèàÈöæ‰ª•‰øùËØÅËøêÂä®ÁöÑÂêàÁêÜÊÄßÔºåËÄåÂ§öÈò∂ÊÆµÊâ©Êï£Ê®°ÂûãËÆ°ÁÆóÂºÄÈîÄÂ§ßÔºåÈöæ‰ª•ÈÉ®ÁΩ≤Âú®ËæπÁºòËÆæÂ§á‰∏ä„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂú®ÂçïÈò∂ÊÆµÊâ©Êï£Ê®°Âûã‰∏≠ÔºåÈÄöËøáÁ≤æÂ∑ßÁöÑËÆæËÆ°Êù•‰øùËØÅÊó∂Á©∫ËøûË¥ØÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈÄöËøáÊÆãÂ∑ÆDCTÁºñÁ†ÅÔºå‰ΩøÊ®°ÂûãÂÖ≥Ê≥®ÂÖ≥ËäÇÁöÑËøêÂä®Ê®°ÂºèËÄåÈùûÁªùÂØπ‰ΩçÁΩÆÔºõÈÄöËøáÁ©∫Èó¥MambaÊ®°ÂùóÔºåÂª∫Ê®°ÂÖ≥ËäÇÈó¥ÁöÑÈïøÁ®ã‰æùËµñÂÖ≥Á≥ªÔºå‰øùËØÅËøêÂä®ÁöÑÂçèË∞ÉÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSMamDiffÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÊòØ‰∏Ä‰∏™ÂçïÈò∂ÊÆµÊâ©Êï£Ê®°Âûã„ÄÇÈ¶ñÂÖàÔºå‰ΩøÁî®ÊÆãÂ∑ÆDCTÁºñÁ†ÅÂØπËæìÂÖ•ÁöÑ‰∫∫‰ΩìËøêÂä®Êï∞ÊçÆËøõË°åÂ§ÑÁêÜÔºåÊèêÂèñËøêÂä®ÁâπÂæÅ„ÄÇÁÑ∂ÂêéÔºåÂ∞ÜËøô‰∫õÁâπÂæÅËæìÂÖ•Âà∞Âü∫‰∫éÁ©∫Èó¥MambaÁöÑÊâ©Êï£Ê®°Âûã‰∏≠ÔºåËØ•Ê®°ÂûãÈÄêÊ≠•ÂéªÂô™ÔºåÊúÄÁªàÁîüÊàêÈ¢ÑÊµãÁöÑËøêÂä®ËΩ®Ëøπ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰∏§‰∏™ÊñπÈù¢Ôºö‰∏ÄÊòØÊÆãÂ∑ÆDCTËøêÂä®ÁºñÁ†ÅÔºåÂÆÉËÉΩÂ§üÊúâÊïàÊèêÂèñÈ´òÈ¢ëËøêÂä®‰ø°ÊÅØÔºåÂáèÂ∞ë‰ΩéÈ¢ëÂàÜÈáèÁöÑÂπ≤Êâ∞Ôºõ‰∫åÊòØÁ©∫Èó¥MambaÊ®°ÂùóÔºåÂÆÉËÉΩÂ§ü‰ª•ÊúâÂ∫èÁöÑÊñπÂºèÂ§ÑÁêÜÂÖ≥ËäÇÔºåÂπ∂Âª∫Ê®°ÂÖ≥ËäÇÈó¥ÁöÑÈïøÁ®ã‰æùËµñÂÖ≥Á≥ª„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊÆãÂ∑ÆDCTÁºñÁ†ÅÁöÑÂÖ≥ÈîÆÂú®‰∫éÂÖàÂáèÂéªÊúÄÂêé‰∏Ä‰∏™ËßÇÊµãÂà∞ÁöÑÂßøÂäøÔºåÂÜçËøõË°åDCTÂèòÊç¢ÔºåËøôÊ†∑ÂèØ‰ª•Á™ÅÂá∫ËøêÂä®ÁöÑÂèòÂåñ‰ø°ÊÅØ„ÄÇÁ©∫Èó¥MambaÊ®°ÂùóÁöÑÂÖ≥ÈîÆÂú®‰∫éÊåâÁÖßÁÅ´Êü¥‰∫∫È™®Êû∂ÁöÑÈ°∫Â∫èÂ§ÑÁêÜÂÖ≥ËäÇÔºå‰ΩøÂæóÂêéÈù¢ÁöÑÂÖ≥ËäÇÂèØ‰ª•‰æùËµñ‰∫éÂâçÈù¢ÁöÑÂÖ≥ËäÇÁöÑ‰ø°ÊÅØ„ÄÇÊçüÂ§±ÂáΩÊï∞ÈááÁî®Ê†áÂáÜÁöÑÊâ©Êï£Ê®°ÂûãÊçüÂ§±ÂáΩÊï∞Ôºå‰æãÂ¶ÇL2ÊçüÂ§±ÊàñHuberÊçüÂ§±„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SMamDiffÂú®Human3.6MÂíåHumanEvaÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜSOTAÁªìÊûúÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂçïÈò∂ÊÆµÊ¶ÇÁéáHMPÊñπÊ≥ï‰∏≠„ÄÇ‰∏éÂ§öÈò∂ÊÆµÊâ©Êï£Ê®°ÂûãÁõ∏ÊØîÔºåSMamDiffÂú®‰øùËØÅÊÄßËÉΩÁöÑÂêåÊó∂ÔºåÊòæËëóÈôç‰Ωé‰∫ÜÂª∂ËøüÂíåÂÜÖÂ≠òÂç†Áî®ÔºåÊõ¥ÈÄÇÂêàËæπÁºòÈÉ®ÁΩ≤„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÔºà‰æãÂ¶ÇÔºåÈ¢ÑÊµãËØØÂ∑ÆÁöÑÈôç‰ΩéÁôæÂàÜÊØîÔºâÂú®ËÆ∫Êñá‰∏≠ÁªôÂá∫„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩÂÆ∂Â±Ö„ÄÅÊúçÂä°Êú∫Âô®‰∫∫„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Êô∫ËÉΩÂÆ∂Â±Ö‰∏≠ÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•È¢ÑÊµãÁî®Êà∑ÁöÑËøêÂä®ËΩ®ËøπÔºå‰ªéËÄåÊèêÂâçÂáÜÂ§áÂ•ΩÊâÄÈúÄÁâ©ÂìÅÊàñË∞ÉÊï¥ÁéØÂ¢ÉËÆæÁΩÆ„ÄÇÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÁ≥ªÁªüÂèØ‰ª•È¢ÑÊµãË°å‰∫∫ÁöÑËøêÂä®ËΩ®ËøπÔºå‰ªéËÄåÂÅöÂá∫Êõ¥ÂÆâÂÖ®ÁöÑÂÜ≥Á≠ñ„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÊèêÂçá‰∫∫Êú∫‰∫§‰∫íÁöÑÂÆâÂÖ®ÊÄß„ÄÅÊïàÁéáÂíåËàíÈÄÇÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> With intelligent room-side sensing and service robots widely deployed, human motion prediction (HMP) is essential for safe, proactive assistance. However, many existing HMP methods either produce a single, deterministic forecast that ignores uncertainty or rely on probabilistic models that sacrifice kinematic plausibility. Diffusion models improve the accuracy-diversity trade-off but often depend on multi-stage pipelines that are costly for edge deployment. This work focuses on how to ensure spatial-temporal coherence within a single-stage diffusion model for HMP. We introduce SMamDiff, a Spatial Mamba-based Diffusion model with two novel designs: (i) a residual-DCT motion encoding that subtracts the last observed pose before a temporal DCT, reducing the first DC component ($f=0$) dominance and highlighting informative higher-frequency cues so the model learns how joints move rather than where they are; and (ii) a stickman-drawing spatial-mamba module that processes joints in an ordered, joint-by-joint manner, making later joints condition on earlier ones to induce long-range, cross-joint dependencies. On Human3.6M and HumanEva, these coherence mechanisms deliver state-of-the-art results among single-stage probabilistic HMP methods while using less latency and memory than multi-stage diffusion baselines.

