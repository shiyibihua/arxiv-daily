---
layout: default
title: SimVecVis: A Dataset for Enhancing MLLMs in Visualization Understanding
---

# SimVecVis: A Dataset for Enhancing MLLMs in Visualization Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21319" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21319v3</a>
  <a href="https://arxiv.org/pdf/2506.21319.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21319v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21319v3', 'SimVecVis: A Dataset for Enhancing MLLMs in Visualization Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Can Liu, Chunlin Da, Xiaoxiao Long, Yuxiao Yang, Yu Zhang, Yong Wang

**åˆ†ç±»**: cs.HC, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26 (æ›´æ–°: 2025-07-02)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/VIDA-Lab/SimVecVis)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSimVecä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¯è§†åŒ–ç†è§£ä¸­çš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å¯è§†åŒ–ç†è§£` `æ•°æ®é›†æ„å»º` `å›¾è¡¨å…ƒç´ ç¼–ç ` `é—®ç­”ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¯è§†åŒ–ç†è§£æ–¹é¢å­˜åœ¨è§£ç æ•°æ®ä¸è§†è§‰æ˜ å°„çš„èƒ½åŠ›ä¸è¶³ï¼Œå¯¼è‡´ç»“æ„åŒ–ä¿¡æ¯æå–å›°éš¾ã€‚
2. æœ¬æ–‡æå‡ºäº†SimVecï¼Œä¸€ç§æ–°é¢–çš„ç®€åŒ–å‘é‡æ ¼å¼ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç¼–ç å›¾è¡¨å…ƒç´ ï¼Œå¹¶æ„å»ºäº†SimVecVisæ•°æ®é›†ä»¥æå‡MLLMsçš„å¯è§†åŒ–ç†è§£èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨SimVecViså¾®è°ƒçš„MLLMsåœ¨æ•°æ®ä¸­å¿ƒé—®ç­”ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨ç©ºé—´æ„ŸçŸ¥èƒ½åŠ›æ–¹é¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è‡ªç„¶å›¾åƒç†è§£æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¯è§†åŒ–ç†è§£ä¸Šå­˜åœ¨å›°éš¾ï¼Œä¸»è¦ç”±äºæ— æ³•è§£ç æ•°æ®ä¸è§†è§‰ä¹‹é—´çš„æ˜ å°„å…³ç³»ä»¥åŠæå–ç»“æ„åŒ–ä¿¡æ¯ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç®€åŒ–å‘é‡æ ¼å¼SimVecï¼Œç”¨äºç¼–ç å›¾è¡¨å…ƒç´ ï¼Œå¦‚æ ‡è®°ç±»å‹ã€ä½ç½®å’Œå¤§å°ã€‚é€šè¿‡ä½¿ç”¨SimVecæ ¼å¼é‡å»ºå›¾è¡¨ä¿¡æ¯ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚éšåï¼Œæ„å»ºäº†æ–°çš„å¯è§†åŒ–æ•°æ®é›†SimVecVisï¼Œä»¥æå‡MLLMsåœ¨å¯è§†åŒ–ç†è§£ä¸­çš„æ€§èƒ½ï¼Œè¯¥æ•°æ®é›†åŒ…æ‹¬å›¾è¡¨çš„ä½å›¾å›¾åƒã€SimVecè¡¨ç¤ºä»¥åŠç›¸åº”çš„æ•°æ®ä¸­å¿ƒé—®ç­”å¯¹å’Œè§£é‡Šæ€§æ€ç»´é“¾æè¿°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨SimVecViså¾®è°ƒçš„æœ€å…ˆè¿›MLLMsï¼ˆå¦‚MiniCPMå’ŒQwen-VLï¼‰åœ¨æ•°æ®ä¸­å¿ƒé—®ç­”ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¯è§†åŒ–ç†è§£ä¸­çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯å…¶åœ¨è§£ç æ•°æ®ä¸è§†è§‰ä¹‹é—´çš„æ˜ å°„å…³ç³»åŠæå–ç»“æ„åŒ–ä¿¡æ¯æ–¹é¢çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å›¾è¡¨ä¿¡æ¯æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆæ•æ‰å’Œç†è§£å›¾è¡¨çš„å…³é”®å…ƒç´ ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„SimVecæ ¼å¼é€šè¿‡ç®€åŒ–å›¾è¡¨å…ƒç´ çš„ç¼–ç ï¼Œå¸®åŠ©MLLMsæ›´å¥½åœ°ç†è§£å’Œé‡å»ºå›¾è¡¨ä¿¡æ¯ã€‚è¯¥æ ¼å¼ä¸“æ³¨äºæ ‡è®°ç±»å‹ã€ä½ç½®å’Œå¤§å°ç­‰å…³é”®å±æ€§ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´ç›´è§‚åœ°å¤„ç†å¯è§†åŒ–æ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯å›¾è¡¨çš„ä½å›¾å›¾åƒè¾“å…¥ï¼Œå…¶æ¬¡æ˜¯SimVecæ ¼å¼çš„å›¾è¡¨å…ƒç´ ç¼–ç ï¼Œæœ€åæ˜¯åŸºäºæ•°æ®ä¸­å¿ƒé—®ç­”çš„æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°ã€‚é€šè¿‡è¿™äº›æ¨¡å—çš„ååŒå·¥ä½œï¼Œæå‡äº†æ¨¡å‹çš„å¯è§†åŒ–ç†è§£èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šSimVecæ ¼å¼çš„æå‡ºæ˜¯æœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°ï¼Œå®ƒä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå…¶ç®€åŒ–å’Œç»“æ„åŒ–çš„ç¼–ç æ–¹å¼ï¼Œä½¿å¾—MLLMsèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†å’Œç†è§£å›¾è¡¨ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†ä¸åŒçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨æ•°æ®ä¸­å¿ƒé—®ç­”ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„è®¾è®¡ä¹Ÿç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥é€‚åº”SimVecæ ¼å¼çš„è¾“å…¥ç‰¹å¾ã€‚å®éªŒä¸­ä½¿ç”¨çš„æœ€å…ˆè¿›æ¨¡å‹å¦‚MiniCPMå’ŒQwen-VLï¼Œå‡åœ¨æ­¤æ¡†æ¶ä¸‹è¿›è¡Œäº†å¾®è°ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨SimVecViså¾®è°ƒçš„MiniCPMæ¨¡å‹åœ¨æ•°æ®ä¸­å¿ƒé—®ç­”ä»»åŠ¡ä¸­æ€§èƒ½æ˜¾è‘—æå‡ï¼Œå°¤å…¶åœ¨ç©ºé—´æ„ŸçŸ¥èƒ½åŠ›æ–¹é¢ï¼Œè¾ƒåŸºçº¿æ¨¡å‹æå‡å¹…åº¦è¾¾åˆ°XX%ã€‚è¿™ä¸€ç»“æœéªŒè¯äº†SimVecæ ¼å¼åœ¨å¯è§†åŒ–ç†è§£ä¸­çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•°æ®å¯è§†åŒ–åˆ†æã€æ•™è‚²é¢†åŸŸçš„å›¾è¡¨ç†è§£ä»¥åŠå•†ä¸šæ™ºèƒ½ä¸­çš„æ•°æ®å‘ˆç°ã€‚é€šè¿‡æå‡MLLMsåœ¨å¯è§†åŒ–ç†è§£æ–¹é¢çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ä»å¤æ‚æ•°æ®ä¸­æå–æœ‰ä»·å€¼çš„ä¿¡æ¯ï¼Œè¿›è€Œä¿ƒè¿›å†³ç­–è¿‡ç¨‹çš„ä¼˜åŒ–ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨æ›´å¤šé¢†åŸŸä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œæ¨åŠ¨æ™ºèƒ½æ•°æ®åˆ†æçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current multimodal large language models (MLLMs), while effective in natural image understanding, struggle with visualization understanding due to their inability to decode the data-to-visual mapping and extract structured information. To address these challenges, we propose SimVec, a novel simplified vector format that encodes chart elements such as mark type, position, and size. The effectiveness of SimVec is demonstrated by using MLLMs to reconstruct chart information from SimVec formats. Then, we build a new visualization dataset, SimVecVis, to enhance the performance of MLLMs in visualization understanding, which consists of three key dimensions: bitmap images of charts, their SimVec representations, and corresponding data-centric question-answering (QA) pairs with explanatory chain-of-thought (CoT) descriptions. We finetune state-of-the-art MLLMs (e.g., MiniCPM and Qwen-VL), using SimVecVis with different dataset dimensions. The experimental results show that it leads to substantial performance improvements of MLLMs with good spatial perception capabilities (e.g., MiniCPM) in data-centric QA tasks. Our dataset and source code are available at: https://github.com/VIDA-Lab/SimVecVis.

