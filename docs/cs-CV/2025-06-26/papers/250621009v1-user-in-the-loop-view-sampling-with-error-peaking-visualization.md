---
layout: default
title: User-in-the-Loop View Sampling with Error Peaking Visualization
---

# User-in-the-Loop View Sampling with Error Peaking Visualization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21009" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21009v1</a>
  <a href="https://arxiv.org/pdf/2506.21009.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21009v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21009v1', 'User-in-the-Loop View Sampling with Error Peaking Visualization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ayaka Yasunaga, Hideo Saito, Shohei Mori

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

**å¤‡æ³¨**: Accepted at IEEE ICIP 2025, Project Page: https://mediated-reality.github.io/projects/yasunaga_icip25/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºç”¨æˆ·åé¦ˆçš„è§†å›¾é‡‡æ ·æ–¹æ³•ä»¥è§£å†³ARæ•°æ®æ”¶é›†æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¢å¼ºç°å®` `è§†å›¾åˆæˆ` `æ•°æ®æ”¶é›†` `å…‰åœºé‡å»º` `ç”¨æˆ·ä½“éªŒ` `é”™è¯¯å¯è§†åŒ–` `3Dæ³¨é‡Š`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ARæ•°æ®æ”¶é›†æ–¹æ³•ä¾èµ–ç”¨æˆ·è¿›è¡Œ3Dæ³¨é‡Šï¼Œå¯¼è‡´å¿ƒç†è´Ÿæ‹…å¤§ä¸”é™åˆ¶äº†æ•è·åŒºåŸŸã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡å±€éƒ¨é‡å»ºå…‰åœºå’Œé”™è¯¯å¯è§†åŒ–æ¥ç®€åŒ–æ•°æ®æ”¶é›†è¿‡ç¨‹ï¼Œé™ä½ç”¨æˆ·çš„æ“ä½œéš¾åº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨é”™è¯¯å³°å€¼å¯è§†åŒ–çš„æ–¹æ³•åœ¨æ ·æœ¬æ•°é‡å‡å°‘çš„æƒ…å†µä¸‹ï¼Œä»èƒ½è·å¾—æ»¡æ„çš„åˆæˆæ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¢å¼ºç°å®ï¼ˆARï¼‰ä¸ºæ–°è§†å›¾åˆæˆæä¾›äº†å¯è§†åŒ–ç¼ºå¤±è§†å›¾æ ·æœ¬çš„æ–¹æ³•ã€‚ç°æœ‰æ–¹æ³•è¦æ±‚ç”¨æˆ·é€šè¿‡å¯¹é½ARæ˜¾ç¤ºæ¥æ‹æ‘„å›¾åƒï¼Œå¯¼è‡´æ•°æ®æ”¶é›†ä»»åŠ¡å¿ƒç†è´Ÿæ‹…è¾ƒé‡ï¼Œå¹¶é™åˆ¶äº†æ•è·åŒºåŸŸã€‚ä¸ºäº†è§£æ”¾ç”¨æˆ·çš„3Dæ³¨é‡Šå’Œæœ‰é™çš„åœºæ™¯æ¢ç´¢ï¼Œæœ¬æ–‡æå‡ºä½¿ç”¨å±€éƒ¨é‡å»ºçš„å…‰åœºå¹¶å¯è§†åŒ–éœ€è¦é€šè¿‡æ’å…¥æ–°è§†å›¾æ¥æ¶ˆé™¤çš„é”™è¯¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé”™è¯¯å³°å€¼å¯è§†åŒ–æ–¹æ³•å¯¹ç”¨æˆ·çš„å¹²æ‰°è¾ƒå°ï¼Œå‡å°‘äº†æœ€ç»ˆç»“æœçš„å¤±æœ›æ„Ÿï¼Œå¹¶åœ¨ç§»åŠ¨è§†å›¾åˆæˆç³»ç»Ÿä¸­ä»¥æ›´å°‘çš„è§†å›¾æ ·æœ¬è·å¾—äº†ä»¤äººæ»¡æ„çš„æ•ˆæœã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†è¯¥æ–¹æ³•å¯¹è¾ƒå¤§åœºæ™¯çš„è¾å°„åœºé‡å»ºçš„è´¡çŒ®ï¼Œä¾‹å¦‚3Dé«˜æ–¯å–·æº…ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ARæ•°æ®æ”¶é›†æ–¹æ³•çš„å¿ƒç†è´Ÿæ‹…å’Œæ•è·åŒºåŸŸé™åˆ¶é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è¦æ±‚ç”¨æˆ·è¿›è¡Œå¤æ‚çš„3Dæ³¨é‡Šï¼Œå¯¼è‡´ç”¨æˆ·ä½“éªŒä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡å±€éƒ¨é‡å»ºçš„å…‰åœºå’Œé”™è¯¯å¯è§†åŒ–æ¥ç®€åŒ–æ•°æ®æ”¶é›†è¿‡ç¨‹ï¼Œç”¨æˆ·åªéœ€å…³æ³¨éœ€è¦æ’å…¥æ–°è§†å›¾çš„ä½ç½®ï¼Œä»è€Œé™ä½æ“ä½œéš¾åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å±€éƒ¨å…‰åœºé‡å»ºæ¨¡å—å’Œé”™è¯¯å¯è§†åŒ–æ¨¡å—ã€‚é¦–å…ˆé‡å»ºå±€éƒ¨å…‰åœºï¼Œç„¶åé€šè¿‡å¯è§†åŒ–æŠ€æœ¯å±•ç¤ºéœ€è¦æ’å…¥æ–°è§†å›¾çš„ä½ç½®ï¼ŒæŒ‡å¯¼ç”¨æˆ·è¿›è¡Œæ‹æ‘„ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé”™è¯¯å³°å€¼å¯è§†åŒ–æ–¹æ³•ï¼Œå®ƒæ˜¾è‘—å‡å°‘äº†ç”¨æˆ·çš„å¹²æ‰°å’Œå¤±æœ›æ„Ÿï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œç”¨æˆ·ä½“éªŒå¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œæœ¬æ–‡è®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å…‰åœºé‡å»ºæ•ˆæœï¼Œå¹¶é‡‡ç”¨äº†é€‚åº”æ€§è§†å›¾é€‰æ‹©ç­–ç•¥ï¼Œä»¥ç¡®ä¿ç”¨æˆ·åœ¨æ‹æ‘„æ—¶èƒ½å¤Ÿè·å¾—æœ€ä½³çš„è§†å›¾æ ·æœ¬ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨é”™è¯¯å³°å€¼å¯è§†åŒ–çš„æ–¹æ³•åœ¨æ ·æœ¬æ•°é‡å‡å°‘çš„æƒ…å†µä¸‹ï¼Œç”¨æˆ·æ»¡æ„åº¦æ˜¾è‘—æé«˜ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæœ€ç»ˆåˆæˆæ•ˆæœçš„å¤±æœ›æ„Ÿé™ä½ï¼Œç”¨æˆ·åœ¨è¾ƒå°çš„æ•è·åŒºåŸŸå†…ä»èƒ½è·å¾—é«˜è´¨é‡çš„è§†å›¾åˆæˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨å¢å¼ºç°å®ã€è™šæ‹Ÿç°å®å’Œè®¡ç®—æœºè§†è§‰ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡ç®€åŒ–æ•°æ®æ”¶é›†è¿‡ç¨‹ï¼Œèƒ½å¤Ÿæé«˜ç”¨æˆ·ä½“éªŒï¼Œä¿ƒè¿›æ›´å¤§è§„æ¨¡çš„åœºæ™¯é‡å»ºå’Œåˆæˆï¼Œæœªæ¥å¯èƒ½åœ¨æ¸¸æˆã€æ•™è‚²å’ŒåŒ»ç–—ç­‰å¤šä¸ªè¡Œä¸šä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Augmented reality (AR) provides ways to visualize missing view samples for novel view synthesis. Existing approaches present 3D annotations for new view samples and task users with taking images by aligning the AR display. This data collection task is known to be mentally demanding and limits capture areas to pre-defined small areas due to the ideal but restrictive underlying sampling theory. To free users from 3D annotations and limited scene exploration, we propose using locally reconstructed light fields and visualizing errors to be removed by inserting new views. Our results show that the error-peaking visualization is less invasive, reduces disappointment in final results, and is satisfactory with fewer view samples in our mobile view synthesis system. We also show that our approach can contribute to recent radiance field reconstruction for larger scenes, such as 3D Gaussian splatting.

