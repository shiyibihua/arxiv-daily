---
layout: default
title: Evidence-based diagnostic reasoning with multi-agent copilot for human pathology
---

# Evidence-based diagnostic reasoning with multi-agent copilot for human pathology

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20964" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20964v1</a>
  <a href="https://arxiv.org/pdf/2506.20964.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20964v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20964v1', 'Evidence-based diagnostic reasoning with multi-agent copilot for human pathology')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chengkuan Chen, Luca L. Weishaupt, Drew F. K. Williamson, Richard J. Chen, Tong Ding, Bowen Chen, Anurag Vaidya, Long Phi Le, Guillaume Jaume, Ming Y. Lu, Faisal Mahmood

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPathChat+ä»¥è§£å†³ç—…ç†å­¦è¯Šæ–­æ¨ç†ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è®¡ç®—ç—…ç†å­¦` `è‡ªä¸»è¯Šæ–­æ¨ç†` `å…¨åˆ‡ç‰‡æˆåƒ` `äººå·¥æ™ºèƒ½` `ç—…ç†ç‰¹å®šæŒ‡ä»¤` `å›¾åƒåˆ†æ` `å·®å¼‚è¯Šæ–­`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è®¡ç®—ç—…ç†å­¦æ¨¡å‹ä¸»è¦é›†ä¸­äºå›¾åƒåˆ†æï¼Œç¼ºä¹å¯¹è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œæ–‡æœ¬èƒŒæ™¯çš„æ•´åˆï¼Œå¯¼è‡´è¯Šæ–­æ¨ç†èƒ½åŠ›ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†PathChat+ï¼Œä¸€ä¸ªä¸“ä¸ºç—…ç†å­¦è®¾è®¡çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†ä¸°å¯Œçš„ç—…ç†ç‰¹å®šæŒ‡ä»¤å’Œé—®ç­”æ•°æ®ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒPathChat+åœ¨å¤šä¸ªç—…ç†åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—è¶…è¶Šäº†ä¹‹å‰çš„æ¨¡å‹ï¼Œå¹¶åœ¨å¼€æ”¾å¼å·®å¼‚è¯Šæ–­ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç—…ç†å­¦æ­£åœ¨ç»å†ç”±å…¨åˆ‡ç‰‡æˆåƒå’Œäººå·¥æ™ºèƒ½é©±åŠ¨çš„å¿«é€Ÿæ•°å­—åŒ–è½¬å‹ã€‚å°½ç®¡åŸºäºæ·±åº¦å­¦ä¹ çš„è®¡ç®—ç—…ç†å­¦å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†ä¼ ç»Ÿæ¨¡å‹ä¸»è¦é›†ä¸­äºå›¾åƒåˆ†æï¼Œæœªèƒ½æ•´åˆè‡ªç„¶è¯­è¨€æŒ‡ä»¤æˆ–ä¸°å¯Œçš„æ–‡æœ¬èƒŒæ™¯ã€‚å½“å‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨è®¡ç®—ç—…ç†å­¦ä¸­é¢ä¸´è®­ç»ƒæ•°æ®ä¸è¶³ã€å¯¹å¤šå›¾åƒç†è§£æ”¯æŒä¸è¶³åŠç¼ºä¹è‡ªä¸»è¯Šæ–­æ¨ç†èƒ½åŠ›ç­‰é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†PathChat+ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºäººç±»ç—…ç†å­¦è®¾è®¡çš„æ–°å‹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œç»è¿‡è¶…è¿‡100ä¸‡ä¸ªå¤šæ ·åŒ–çš„ç—…ç†ç‰¹å®šæŒ‡ä»¤æ ·æœ¬å’Œè¿‘550ä¸‡ä¸ªé—®ç­”è½®æ¬¡çš„è®­ç»ƒã€‚å¹¿æ³›çš„è¯„ä¼°æ˜¾ç¤ºï¼ŒPathChat+åœ¨å¤šä¸ªç—…ç†åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºä¹‹å‰çš„PathChatåŠ©æ‰‹ï¼Œä»¥åŠå…¶ä»–æœ€å…ˆè¿›çš„é€šç”¨å’Œç—…ç†ç‰¹å®šæ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†SlideSeekï¼Œä¸€ä¸ªåˆ©ç”¨PathChat+è¿›è¡Œè‡ªä¸»è¯„ä¼°çš„å¤šä»£ç†AIç³»ç»Ÿï¼Œèƒ½å¤Ÿé€šè¿‡è¿­ä»£çš„åˆ†å±‚è¯Šæ–­æ¨ç†é«˜æ•ˆå¤„ç†åƒå…†åƒç´ çš„å…¨åˆ‡ç‰‡å›¾åƒï¼Œå¹¶åœ¨å¼€æ”¾å¼çš„å·®å¼‚è¯Šæ–­åŸºå‡†DDxBenchä¸Šè¾¾åˆ°é«˜å‡†ç¡®ç‡ï¼ŒåŒæ—¶ç”Ÿæˆå¯è§†åŒ–çš„ã€æ˜“äºç†è§£çš„æ€»ç»“æŠ¥å‘Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è®¡ç®—ç—…ç†å­¦æ¨¡å‹åœ¨å›¾åƒåˆ†æä¸è‡ªç„¶è¯­è¨€å¤„ç†ç»“åˆæ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨è‡ªä¸»è¯Šæ–­æ¨ç†èƒ½åŠ›ä¸Šçš„ç¼ºå¤±ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„PathChat+é€šè¿‡æ•´åˆä¸°å¯Œçš„ç—…ç†ç‰¹å®šæŒ‡ä»¤å’Œé—®ç­”æ•°æ®ï¼Œå¢å¼ºäº†æ¨¡å‹çš„å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ï¼Œä»è€Œæå‡äº†è¯Šæ–­æ¨ç†çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPathChat+çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ¨ç†æ¨¡å—ã€‚æ•°æ®é¢„å¤„ç†é˜¶æ®µè´Ÿè´£æ”¶é›†å’Œæ•´ç†ç—…ç†ç‰¹å®šçš„æŒ‡ä»¤å’Œé—®ç­”æ•°æ®ï¼Œæ¨¡å‹è®­ç»ƒé˜¶æ®µåˆ™ä½¿ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯è¿›è¡Œè®­ç»ƒï¼Œæ¨ç†æ¨¡å—åˆ™åˆ©ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œå®é™…çš„ç—…ç†å›¾åƒåˆ†æå’Œè¯Šæ–­æ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šPathChat+çš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§å’Œä¸°å¯Œæ€§ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ç—…ç†å­¦çš„ç‰¹å®šæŒ‡ä»¤æ ·æœ¬å’Œé—®ç­”è½®æ¬¡ï¼Œè¿™ä½¿å¾—æ¨¡å‹åœ¨å¤„ç†å¤æ‚çš„ç—…ç†å›¾åƒæ—¶å…·å¤‡æ›´å¼ºçš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¤šæ¨¡æ€æ•°æ®çš„èåˆæ•ˆæœï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”å¤§è§„æ¨¡ç—…ç†å›¾åƒçš„å¤„ç†éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPathChat+åœ¨å¤šä¸ªç—…ç†åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºä¹‹å‰çš„PathChatåŠ©æ‰‹ï¼Œä¸”åœ¨å¼€æ”¾å¼å·®å¼‚è¯Šæ–­åŸºå‡†DDxBenchä¸Šè¾¾åˆ°äº†é«˜å‡†ç¡®ç‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤„ç†å¤æ‚ç—…ç†å›¾åƒæ—¶çš„å“è¶Šæ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¸´åºŠç—…ç†è¯Šæ–­ã€åŒ»å­¦æ•™è‚²å’Œç—…ç†å›¾åƒåˆ†æç­‰ã€‚PathChat+å’ŒSlideSeekçš„ç»“åˆå¯ä»¥æé«˜ç—…ç†å­¦è¯Šæ–­çš„è‡ªåŠ¨åŒ–æ°´å¹³ï¼Œå‡å°‘äººä¸ºé”™è¯¯ï¼Œæå‡è¯Šæ–­æ•ˆç‡ï¼Œæœªæ¥å¯èƒ½åœ¨åŒ»ç–—è¡Œä¸šäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Pathology is experiencing rapid digital transformation driven by whole-slide imaging and artificial intelligence (AI). While deep learning-based computational pathology has achieved notable success, traditional models primarily focus on image analysis without integrating natural language instruction or rich, text-based context. Current multimodal large language models (MLLMs) in computational pathology face limitations, including insufficient training data, inadequate support and evaluation for multi-image understanding, and a lack of autonomous, diagnostic reasoning capabilities. To address these limitations, we introduce PathChat+, a new MLLM specifically designed for human pathology, trained on over 1 million diverse, pathology-specific instruction samples and nearly 5.5 million question answer turns. Extensive evaluations across diverse pathology benchmarks demonstrated that PathChat+ substantially outperforms the prior PathChat copilot, as well as both state-of-the-art (SOTA) general-purpose and other pathology-specific models. Furthermore, we present SlideSeek, a reasoning-enabled multi-agent AI system leveraging PathChat+ to autonomously evaluate gigapixel whole-slide images (WSIs) through iterative, hierarchical diagnostic reasoning, reaching high accuracy on DDxBench, a challenging open-ended differential diagnosis benchmark, while also capable of generating visually grounded, humanly-interpretable summary reports.

