---
layout: default
title: G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation
---

# G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21514" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21514v3</a>
  <a href="https://arxiv.org/pdf/2506.21514.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21514v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21514v3', 'G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mohammed Rakib, Arunkumar Bagavathi

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26 (æ›´æ–°: 2025-10-17)

**å¤‡æ³¨**: Accepted at ICCV 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/rAIson-Lab/G2D)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGÂ²Dä»¥è§£å†³å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„æ¨¡æ€ä¸å¹³è¡¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `çŸ¥è¯†è’¸é¦` `æ¨¡æ€ä¼˜å…ˆçº§` `ç‰¹å¾è¡¨ç¤º` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•å¸¸å¸¸å—åˆ°æ¨¡æ€ä¸å¹³è¡¡çš„å½±å“ï¼Œå¯¼è‡´æŸäº›æ¨¡æ€ä¸»å¯¼ä¼˜åŒ–è¿‡ç¨‹ï¼Œå¼±æ¨¡æ€æœªè¢«å……åˆ†åˆ©ç”¨ã€‚
2. æœ¬æ–‡æå‡ºäº†GÂ²Dæ¡†æ¶ï¼Œé€šè¿‡è‡ªå®šä¹‰æŸå¤±å‡½æ•°å’ŒåŠ¨æ€æ¨¡æ€ä¼˜å…ˆçº§æŠ€æœ¯ï¼Œä¼˜åŒ–å¤šæ¨¡æ€æ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒGÂ²Dåœ¨å¤šä¸ªçœŸå®æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†å¼±æ¨¡æ€çš„è¡¨ç°ï¼Œå¹¶åœ¨åˆ†ç±»å’Œå›å½’ä»»åŠ¡ä¸­è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å­¦ä¹ æ—¨åœ¨åˆ©ç”¨ä¸åŒæ•°æ®æ¨¡æ€çš„ä¿¡æ¯ä»¥å®ç°æ›´å…¨é¢çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„å¤šæ¨¡æ€æ¨¡å‹å¸¸å¸¸é¢ä¸´æ¨¡æ€ä¸å¹³è¡¡çš„é—®é¢˜ï¼Œå¯¼è‡´æŸäº›æ¨¡æ€ä¸»å¯¼æ¨¡å‹ä¼˜åŒ–ï¼Œä»è€Œé€ æˆç‰¹å¾è¡¨ç¤ºçš„æ¬¡ä¼˜å’Œå¼±æ¨¡æ€çš„æœªå……åˆ†åˆ©ç”¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†æ¢¯åº¦å¼•å¯¼è’¸é¦ï¼ˆGÂ²Dï¼‰ï¼Œä¸€ç§çŸ¥è¯†è’¸é¦æ¡†æ¶ï¼Œé€šè¿‡è‡ªå®šä¹‰æŸå¤±å‡½æ•°èåˆå•æ¨¡æ€å’Œå¤šæ¨¡æ€ç›®æ ‡ã€‚æ­¤å¤–ï¼ŒGÂ²Dè¿˜åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å¼•å…¥äº†åŠ¨æ€é¡ºåºæ¨¡æ€ä¼˜å…ˆçº§ï¼ˆSMPï¼‰æŠ€æœ¯ï¼Œä»¥ç¡®ä¿æ¯ä¸ªæ¨¡æ€åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å‘æŒ¥ä¸»å¯¼ä½œç”¨ï¼Œé¿å…å¼ºæ¨¡æ€é®è”½å¼±æ¨¡æ€ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸ŠéªŒè¯äº†GÂ²Dï¼Œç»“æœè¡¨æ˜å…¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¢å¼ºäº†å¼±æ¨¡æ€çš„é‡è¦æ€§ï¼Œå¹¶åœ¨åˆ†ç±»å’Œå›å½’ä»»åŠ¡ä¸­è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„æ¨¡æ€ä¸å¹³è¡¡é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€å¯¼è‡´æŸäº›æ¨¡æ€ä¸»å¯¼æ¨¡å‹ä¼˜åŒ–ï¼Œé€ æˆç‰¹å¾è¡¨ç¤ºçš„æ¬¡ä¼˜å’Œå¼±æ¨¡æ€çš„æœªå……åˆ†åˆ©ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGÂ²Dé€šè¿‡å¼•å…¥æ¢¯åº¦å¼•å¯¼è’¸é¦å’ŒåŠ¨æ€æ¨¡æ€ä¼˜å…ˆçº§ï¼Œç¡®ä¿æ¯ä¸ªæ¨¡æ€åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­éƒ½æœ‰æœºä¼šä¸»å¯¼ï¼Œä»è€Œæå‡å¼±æ¨¡æ€çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGÂ²Dçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè‡ªå®šä¹‰æŸå¤±å‡½æ•°æ¨¡å—ï¼Œèåˆå•æ¨¡æ€å’Œå¤šæ¨¡æ€ç›®æ ‡ï¼›åŠ¨æ€æ¨¡æ€ä¼˜å…ˆçº§æ¨¡å—ï¼Œç¡®ä¿æ¨¡æ€åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­çš„åŠ¨æ€è°ƒæ•´ã€‚

**å…³é”®åˆ›æ–°**ï¼šGÂ²Dçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºç»“åˆäº†æ¢¯åº¦å¼•å¯¼è’¸é¦å’ŒåŠ¨æ€æ¨¡æ€ä¼˜å…ˆçº§æŠ€æœ¯ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„é™æ€æ¨¡æ€å¤„ç†æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼ŒGÂ²Dé‡‡ç”¨äº†èåˆå•æ¨¡æ€å’Œå¤šæ¨¡æ€ç›®æ ‡çš„è‡ªå®šä¹‰æŸå¤±å‡½æ•°ï¼Œç¡®ä¿ä¸åŒæ¨¡æ€çš„ç‰¹å¾èƒ½å¤Ÿå¾—åˆ°å¹³è¡¡åˆ©ç”¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGÂ²Dåœ¨åˆ†ç±»å’Œå›å½’ä»»åŠ¡ä¸­æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨å¼±æ¨¡æ€çš„è¡¨ç°ä¸Šï¼Œæå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æã€è§†é¢‘ç†è§£å’ŒåŒ»ç–—å½±åƒåˆ†æç­‰ã€‚é€šè¿‡æå‡å¼±æ¨¡æ€çš„è¡¨ç°ï¼ŒGÂ²Då¯ä»¥åœ¨å®é™…åº”ç”¨ä¸­å®ç°æ›´å…¨é¢çš„å†³ç­–æ”¯æŒï¼Œæœªæ¥å¯èƒ½å¯¹å¤šæ¨¡æ€å­¦ä¹ é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal learning aims to leverage information from diverse data modalities to achieve more comprehensive performance. However, conventional multimodal models often suffer from modality imbalance, where one or a few modalities dominate model optimization, leading to suboptimal feature representation and underutilization of weak modalities. To address this challenge, we introduce Gradient-Guided Distillation (G$^{2}$D), a knowledge distillation framework that optimizes the multimodal model with a custom-built loss function that fuses both unimodal and multimodal objectives. G$^{2}$D further incorporates a dynamic sequential modality prioritization (SMP) technique in the learning process to ensure each modality leads the learning process, avoiding the pitfall of stronger modalities overshadowing weaker ones. We validate G$^{2}$D on multiple real-world datasets and show that G$^{2}$D amplifies the significance of weak modalities while training and outperforms state-of-the-art methods in classification and regression tasks. Our code is available at https://github.com/rAIson-Lab/G2D.

