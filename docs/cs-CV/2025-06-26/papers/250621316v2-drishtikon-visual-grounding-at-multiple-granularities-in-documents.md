---
layout: default
title: DRISHTIKON: Visual Grounding at Multiple Granularities in Documents
---

# DRISHTIKON: Visual Grounding at Multiple Granularities in Documents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21316" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21316v2</a>
  <a href="https://arxiv.org/pdf/2506.21316.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21316v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21316v2', 'DRISHTIKON: Visual Grounding at Multiple Granularities in Documents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Badri Vishal Kasuba, Parag Chaudhuri, Ganesh Ramakrishnan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26 (æ›´æ–°: 2025-07-16)

**å¤‡æ³¨**: Work in Progress

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDRISHTIKONä»¥è§£å†³æ–‡æ¡£å›¾åƒä¸­çš„è§†è§‰å®šä½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰å®šä½` `æ–‡æ¡£æ™ºèƒ½` `å¤šè¯­è¨€å¤„ç†` `è§†è§‰é—®ç­”` `åŒºåŸŸåŒ¹é…ç®—æ³•` `å¤šç²’åº¦åˆ†æ` `å¤§å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰é—®ç­”ç³»ç»Ÿåœ¨å¤„ç†å¤æ‚çš„å¤šè¯­è¨€æ–‡æ¡£æ—¶ï¼Œé¢ä¸´ç€è§†è§‰å®šä½å‡†ç¡®æ€§ä¸è¶³çš„é—®é¢˜ã€‚
2. DRISHTIKONæ¡†æ¶é€šè¿‡ç»“åˆå¤šè¯­è¨€OCRå’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨å¤šç²’åº¦çš„åŒºåŸŸåŒ¹é…ç®—æ³•æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDRISHTIKONåœ¨å®šä½å‡†ç¡®æ€§ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ï¼Œå°¤å…¶åœ¨è¡Œçº§ç²’åº¦ä¸Šè¡¨ç°æœ€ä½³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰å®šä½åœ¨æ–‡æœ¬ä¸°å¯Œçš„æ–‡æ¡£å›¾åƒä¸­æ˜¯ä¸€ä¸ªå…³é”®ä½†å°šæœªå……åˆ†æ¢ç´¢çš„æŒ‘æˆ˜ï¼Œå°¤å…¶åœ¨æ–‡æ¡£æ™ºèƒ½å’Œè§†è§‰é—®ç­”ç³»ç»Ÿä¸­ã€‚æœ¬æ–‡æå‡ºäº†DRISHTIKONï¼Œä¸€ä¸ªå¤šç²’åº¦å’Œå¤šå—çš„è§†è§‰å®šä½æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºå¤æ‚å¤šè¯­è¨€æ–‡æ¡£çš„å¯è§£é‡Šæ€§å’Œä¿¡ä»»åº¦ã€‚è¯¥æ–¹æ³•ç»“åˆäº†å¤šè¯­è¨€OCRã€å¤§å‹è¯­è¨€æ¨¡å‹å’Œä¸€ç§æ–°é¢–çš„åŒºåŸŸåŒ¹é…ç®—æ³•ï¼Œä»¥åœ¨å—ã€è¡Œã€è¯å’Œç‚¹çº§åˆ«å®šä½ç­”æ¡ˆèŒƒå›´ã€‚æˆ‘ä»¬å¼•å…¥äº†å¤šç²’åº¦è§†è§‰å®šä½åŸºå‡†ï¼ˆMGVGï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç»è¿‡äººå·¥æ ‡æ³¨çš„å¤šæ ·åŒ–æµ‹è¯•é›†ï¼Œæ¶µç›–æ¥è‡ªå„ä¸ªé¢†åŸŸçš„é€šçŸ¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®šä½å‡†ç¡®æ€§ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ï¼Œè¡Œçº§ç²’åº¦åœ¨ç²¾åº¦å’Œå¬å›ç‡ä¹‹é—´æä¾›äº†æœ€ä½³å¹³è¡¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ–‡æœ¬ä¸°å¯Œçš„æ–‡æ¡£å›¾åƒä¸­çš„è§†è§‰å®šä½é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤šè¯­è¨€å’Œå¤æ‚æ–‡æ¡£çš„å¤„ç†ä¸Šå­˜åœ¨å‡†ç¡®æ€§ä¸è¶³çš„ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDRISHTIKONé€šè¿‡å¤šç²’åº¦å’Œå¤šå—çš„è§†è§‰å®šä½æ¡†æ¶ï¼Œç»“åˆå¤šè¯­è¨€OCRå’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè®¾è®¡äº†ä¸€ç§æ–°é¢–çš„åŒºåŸŸåŒ¹é…ç®—æ³•ï¼Œä»¥æé«˜å®šä½çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆè¿›è¡Œå¤šè¯­è¨€OCRå¤„ç†ï¼Œç„¶ååˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œè¯­ä¹‰ç†è§£ï¼Œæœ€åé€šè¿‡åŒºåŸŸåŒ¹é…ç®—æ³•å®ç°å¤šç²’åº¦çš„è§†è§‰å®šä½ï¼Œæ¶µç›–å—ã€è¡Œã€è¯å’Œç‚¹çº§åˆ«ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†å¤šç²’åº¦è§†è§‰å®šä½åŸºå‡†ï¼ˆMGVGï¼‰ï¼Œå¹¶é€šè¿‡ç»“æ„åŒ–çš„å¯¹é½æ–¹æ³•æ˜¾è‘—æé«˜äº†å®šä½çš„å‡†ç¡®æ€§ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚çš„æ–‡æ¡£ç»“æ„ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†ç²¾ç»†åŒ–çš„äººå·¥æ ‡æ³¨æ•°æ®é›†ï¼Œè®¾è®¡äº†é€‚åº”å¤šç²’åº¦å®šä½çš„æŸå¤±å‡½æ•°ï¼Œå¹¶ä¼˜åŒ–äº†ç½‘ç»œç»“æ„ä»¥æ”¯æŒå¤šå—å’Œå¤šè¡Œæ¨ç†ã€‚è¯¥è®¾è®¡ç¡®ä¿äº†æ¨¡å‹åœ¨ä¸åŒç²’åº¦ä¸‹çš„æœ‰æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDRISHTIKONåœ¨è§†è§‰å®šä½å‡†ç¡®æ€§ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ï¼Œè¡Œçº§ç²’åº¦çš„å®šä½ç²¾åº¦å’Œå¬å›ç‡ä¹‹é—´çš„å¹³è¡¡æœ€ä½³ã€‚ä¸é¢†å…ˆçš„è§†è§‰è¯­è¨€æ¨¡å‹ç›¸æ¯”ï¼ŒDRISHTIKONåœ¨ç²¾ç¡®å®šä½æ–¹é¢è¡¨ç°å‡ºæ˜æ˜¾ä¼˜åŠ¿ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶ç»“æ„åŒ–å¯¹é½æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DRISHTIKONçš„ç ”ç©¶æˆæœåœ¨æ–‡æ¡£æ™ºèƒ½å’Œè§†è§‰é—®ç­”ç³»ç»Ÿä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œèƒ½å¤Ÿæå‡å¤šè¯­è¨€æ–‡æ¡£çš„ç†è§£å’Œå¤„ç†èƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯ä»¥åº”ç”¨äºæ³•å¾‹ã€åŒ»ç–—å’Œæ•™è‚²ç­‰é¢†åŸŸï¼Œå¸®åŠ©ç”¨æˆ·æ›´é«˜æ•ˆåœ°è·å–å’Œç†è§£ä¿¡æ¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual grounding in text-rich document images is a critical yet underexplored challenge for Document Intelligence and Visual Question Answering (VQA) systems. We present DRISHTIKON, a multi-granular and multi-block visual grounding framework designed to enhance interpretability and trust in VQA for complex, multilingual documents. Our approach integrates multilingual OCR, large language models, and a novel region matching algorithm to localize answer spans at the block, line, word, and point levels. We introduce the Multi-Granular Visual Grounding (MGVG) benchmark, a curated test set of diverse circular notifications from various sectors, each manually annotated with fine-grained, human-verified labels across multiple granularities. Extensive experiments show that our method achieves state-of-the-art grounding accuracy, with line-level granularity providing the best balance between precision and recall. Ablation studies further highlight the benefits of multi-block and multi-line reasoning. Comparative evaluations reveal that leading vision-language models struggle with precise localization, underscoring the effectiveness of our structured, alignment-based approach. Our findings pave the way for more robust and interpretable document understanding systems in real-world, text-centric scenarios with multi-granular grounding support. Code and dataset are made available for future research.

