---
layout: default
title: Hierarchical Sub-action Tree for Continuous Sign Language Recognition
---

# Hierarchical Sub-action Tree for Continuous Sign Language Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20947" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20947v1</a>
  <a href="https://arxiv.org/pdf/2506.20947.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20947v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20947v1', 'Hierarchical Sub-action Tree for Continuous Sign Language Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dejie Yang, Zhu Xu, Xinjie Gao, Yang Liu

**åˆ†ç±»**: cs.CV, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

**æœŸåˆŠ**: ICME 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå±‚æ¬¡å­åŠ¨ä½œæ ‘ä»¥è§£å†³è¿ç»­æ‰‹è¯­è¯†åˆ«ä¸­çš„æ•°æ®ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¿ç»­æ‰‹è¯­è¯†åˆ«` `å±‚æ¬¡å­åŠ¨ä½œæ ‘` `å¤šæ¨¡æ€å¯¹é½` `è§†è§‰ä¿¡æ¯æå–` `æ–‡æœ¬ä¿¡æ¯åˆ©ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¿ç»­æ‰‹è¯­è¯†åˆ«æ–¹æ³•é¢ä¸´æ•°æ®é›†ä¸è¶³å’Œæ ‡æ³¨ä¸ç²¾ç¡®çš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚
2. æœ¬æ–‡æå‡ºçš„HST-CSLRé€šè¿‡æ„å»ºå±‚æ¬¡å­åŠ¨ä½œæ ‘ï¼Œæœ‰æ•ˆç»“åˆäº†æ–‡æœ¬å’Œè§†è§‰ä¿¡æ¯ï¼Œæå‡äº†å¯¹é½æ•ˆæœã€‚
3. åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHST-CSLRåœ¨è¯†åˆ«å‡†ç¡®ç‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿ç»­æ‰‹è¯­è¯†åˆ«ï¼ˆCSLRï¼‰æ—¨åœ¨å°†æœªå‰ªè¾‘çš„è§†é¢‘è½¬å½•ä¸ºæ–‡æœ¬è¯æ±‡ã€‚è¿‘æœŸç ”ç©¶è¡¨æ˜ï¼Œç¼ºä¹å¤§è§„æ¨¡æ•°æ®é›†å’Œç²¾ç¡®æ ‡æ³¨å·²æˆä¸ºCSLRçš„ç“¶é¢ˆã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œéƒ¨åˆ†ç ”ç©¶å¼€å‘äº†è·¨æ¨¡æ€è§£å†³æ–¹æ¡ˆä»¥å¯¹é½è§†è§‰å’Œæ–‡æœ¬æ¨¡æ€ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ä»…ä»è¯æ±‡ä¸­æå–æ–‡æœ¬ç‰¹å¾ï¼Œè€Œæœªå……åˆ†åˆ©ç”¨å…¶çŸ¥è¯†ã€‚æœ¬æ–‡æå‡ºäº†å±‚æ¬¡å­åŠ¨ä½œæ ‘ï¼ˆHSTï¼‰ï¼Œç§°ä¸ºHST-CSLRï¼Œä»¥é«˜æ•ˆç»“åˆè¯æ±‡çŸ¥è¯†ä¸è§†è§‰è¡¨ç¤ºå­¦ä¹ ã€‚é€šè¿‡ç»“åˆæ¥è‡ªå¤§å‹è¯­è¨€æ¨¡å‹çš„ç‰¹å®šè¯æ±‡çŸ¥è¯†ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ›´æœ‰æ•ˆåœ°åˆ©ç”¨æ–‡æœ¬ä¿¡æ¯ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªHSTç”¨äºæ–‡æœ¬ä¿¡æ¯è¡¨ç¤ºï¼Œé€æ­¥å¯¹é½è§†è§‰å’Œæ–‡æœ¬æ¨¡æ€ï¼Œå¹¶åˆ©ç”¨æ ‘ç»“æ„é™ä½è®¡ç®—å¤æ‚åº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ–½åŠ äº†å¯¹æ¯”å¯¹é½å¢å¼ºï¼Œä»¥ç¼©å°ä¸¤ç§æ¨¡æ€ä¹‹é—´çš„å·®è·ã€‚åœ¨å››ä¸ªæ•°æ®é›†ï¼ˆPHOENIX-2014ã€PHOENIX-2014Tã€CSL-Dailyå’Œæ‰‹è¯­æ‰‹åŠ¿ï¼‰ä¸Šçš„å®éªŒè¡¨æ˜äº†HST-CSLRçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è¿ç»­æ‰‹è¯­è¯†åˆ«ä¸­çš„æ•°æ®ä¸è¶³å’Œæ ‡æ³¨ä¸ç²¾ç¡®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸æ— æ³•å……åˆ†åˆ©ç”¨æ–‡æœ¬ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHST-CSLRçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºå±‚æ¬¡å­åŠ¨ä½œæ ‘ï¼Œå°†è§†è§‰ä¿¡æ¯ä¸æ–‡æœ¬ä¿¡æ¯é€æ­¥å¯¹é½ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°åˆ©ç”¨è¯æ±‡çŸ¥è¯†ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨æå‡æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›å’Œè¯†åˆ«å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHST-CSLRçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ–‡æœ¬ä¿¡æ¯çš„å±‚æ¬¡è¡¨ç¤ºã€è§†è§‰ç‰¹å¾æå–å’Œå¯¹é½æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹æå–æ–‡æœ¬ç‰¹å¾ï¼Œç„¶ååˆ©ç”¨å±‚æ¬¡å­åŠ¨ä½œæ ‘è¿›è¡Œç»“æ„åŒ–è¡¨ç¤ºï¼Œæœ€åé€šè¿‡å¯¹æ¯”å­¦ä¹ å¢å¼ºè§†è§‰ä¸æ–‡æœ¬çš„å¯¹é½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥å±‚æ¬¡å­åŠ¨ä½œæ ‘ç»“æ„ï¼Œä½¿å¾—æ–‡æœ¬ä¿¡æ¯çš„è¡¨ç¤ºæ›´åŠ çµæ´»ä¸”é«˜æ•ˆï¼ŒåŒæ—¶é€šè¿‡å¯¹æ¯”å¯¹é½å¢å¼ºæŠ€æœ¯ç¼©å°äº†è§†è§‰ä¸æ–‡æœ¬æ¨¡æ€ä¹‹é—´çš„å·®è·ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„ç›´æ¥ç‰¹å¾æå–æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¯¹é½æ•ˆæœï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†å¤šå±‚æ¬¡çš„ç‰¹å¾æå–æ¨¡å—ï¼Œä»¥æé«˜æ¨¡å‹å¯¹å¤æ‚æ‰‹è¯­çš„è¯†åˆ«èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨PHOENIX-2014ã€PHOENIX-2014Tã€CSL-Dailyå’Œæ‰‹è¯­æ‰‹åŠ¿ç­‰å››ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHST-CSLRåœ¨è¯†åˆ«å‡†ç¡®ç‡ä¸Šè¾ƒåŸºçº¿æ–¹æ³•æå‡äº†æ˜¾è‘—çš„ç™¾åˆ†æ¯”ï¼ŒéªŒè¯äº†å…¶åœ¨è¿ç»­æ‰‹è¯­è¯†åˆ«ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æ‰‹è¯­ç¿»è¯‘ã€æ— éšœç¢äº¤æµå’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡è¿ç»­æ‰‹è¯­è¯†åˆ«çš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æœåŠ¡äºå¬éšœäººå£«ï¼Œä¿ƒè¿›ç¤¾ä¼šçš„åŒ…å®¹æ€§ã€‚æ­¤å¤–ï¼Œæœªæ¥å¯å°†è¯¥æ–¹æ³•æ‰©å±•è‡³å…¶ä»–å¤šæ¨¡æ€å­¦ä¹ ä»»åŠ¡ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Continuous sign language recognition (CSLR) aims to transcribe untrimmed videos into glosses, which are typically textual words. Recent studies indicate that the lack of large datasets and precise annotations has become a bottleneck for CSLR due to insufficient training data. To address this, some works have developed cross-modal solutions to align visual and textual modalities. However, they typically extract textual features from glosses without fully utilizing their knowledge. In this paper, we propose the Hierarchical Sub-action Tree (HST), termed HST-CSLR, to efficiently combine gloss knowledge with visual representation learning. By incorporating gloss-specific knowledge from large language models, our approach leverages textual information more effectively. Specifically, we construct an HST for textual information representation, aligning visual and textual modalities step-by-step and benefiting from the tree structure to reduce computational complexity. Additionally, we impose a contrastive alignment enhancement to bridge the gap between the two modalities. Experiments on four datasets (PHOENIX-2014, PHOENIX-2014T, CSL-Daily, and Sign Language Gesture) demonstrate the effectiveness of our HST-CSLR.

