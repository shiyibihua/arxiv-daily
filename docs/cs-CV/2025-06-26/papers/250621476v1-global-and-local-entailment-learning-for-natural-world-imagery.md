---
layout: default
title: Global and Local Entailment Learning for Natural World Imagery
---

# Global and Local Entailment Learning for Natural World Imagery

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21476" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21476v1</a>
  <a href="https://arxiv.org/pdf/2506.21476.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21476v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21476v1', 'Global and Local Entailment Learning for Natural World Imagery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Srikumar Sastry, Aayush Dhakal, Eric Xing, Subash Khanal, Nathan Jacobs

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

**å¤‡æ³¨**: Accepted at ICCV 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://vishu26.github.io/RCME/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRadial Cross-Modal Embeddingsä»¥è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨ç†å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡å‹` `å±‚æ¬¡ç»“æ„` `å¤šæ¨¡æ€å­¦ä¹ ` `ç”Ÿç‰©åˆ†ç±»` `åµŒå…¥æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ¨ç†å­¦ä¹ æ–¹æ³•æœªèƒ½æœ‰æ•ˆå»ºæ¨¡æ¨ç†çš„ä¼ é€’æ€§ï¼Œå¯¼è‡´è¯­ä¹‰è¡¨ç¤ºä¸­çš„é¡ºåºå…³ç³»ç¼ºå¤±ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºRCMEæ¡†æ¶ï¼Œé€šè¿‡ä¼˜åŒ–æ¦‚å¿µçš„ååºå…³ç³»ï¼Œæ˜¾å¼å»ºæ¨¡æ¨ç†çš„ä¼ é€’æ€§ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šåœ¨å±‚æ¬¡ç‰©ç§åˆ†ç±»å’Œæ£€ç´¢ä»»åŠ¡ä¸­ï¼Œæ‰€ææ¨¡å‹æ˜¾è‘—è¶…è¶Šç°æœ‰æœ€å…ˆè¿›æ¨¡å‹ï¼Œå±•ç¤ºäº†æ›´å¥½çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨è§†è§‰è¯­è¨€æ¨¡å‹ä¸­ï¼Œå­¦ä¹ æ•°æ®çš„å±‚æ¬¡ç»“æ„æ˜¯ä¸€é¡¹é‡å¤§æŒ‘æˆ˜ã€‚ä»¥å¾€çš„ç ”ç©¶é€šè¿‡æ¨ç†å­¦ä¹ æ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œä½†æœªèƒ½æ˜ç¡®å»ºæ¨¡æ¨ç†çš„ä¼ é€’æ€§ï¼Œå¯¼è‡´è¯­ä¹‰ä¸é¡ºåºå…³ç³»çš„ç¼ºå¤±ã€‚æœ¬æ–‡æå‡ºäº†Radial Cross-Modal Embeddingsï¼ˆRCMEï¼‰æ¡†æ¶ï¼Œèƒ½å¤Ÿæ˜¾å¼å»ºæ¨¡ä¼ é€’æ€§çº¦æŸçš„æ¨ç†ã€‚è¯¥æ¡†æ¶ä¼˜åŒ–è§†è§‰è¯­è¨€æ¨¡å‹ä¸­æ¦‚å¿µçš„ååºå…³ç³»ï¼Œè¿›è€Œå¼€å‘å‡ºä¸€ç§èƒ½å¤Ÿè¡¨ç¤ºç”Ÿå‘½æ ‘å±‚æ¬¡ç»“æ„çš„å±‚æ¬¡åŒ–è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æœ€å…ˆè¿›æ¨¡å‹ç›¸æ¯”ï¼Œæ‰€ææ¨¡å‹åœ¨å±‚æ¬¡ç‰©ç§åˆ†ç±»å’Œæ£€ç´¢ä»»åŠ¡ä¸Šè¡¨ç°å‡ºæ˜¾è‘—æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹ä¸­æ¨ç†å­¦ä¹ çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯æœªèƒ½æœ‰æ•ˆå»ºæ¨¡æ¨ç†çš„ä¼ é€’æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å±‚æ¬¡ç»“æ„æ—¶ï¼Œå¾€å¾€å¿½è§†äº†è¯­ä¹‰ä¸é¡ºåºä¹‹é—´çš„å…³ç³»ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„RCMEæ¡†æ¶é€šè¿‡ä¼˜åŒ–æ¦‚å¿µçš„ååºå…³ç³»ï¼Œæ˜¾å¼åœ°å»ºæ¨¡æ¨ç†çš„ä¼ é€’æ€§ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œè¡¨ç¤ºæ•°æ®çš„å±‚æ¬¡ç»“æ„ï¼Œä»è€Œæå‡è§†è§‰è¯­è¨€ä»»åŠ¡çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRCMEæ¡†æ¶åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆæ˜¯æ•°æ®é¢„å¤„ç†æ¨¡å—ï¼Œæ¥ç€æ˜¯ä¼ é€’æ€§çº¦æŸçš„å»ºæ¨¡æ¨¡å—ï¼Œæœ€åæ˜¯ä¼˜åŒ–æ¨¡å—ã€‚æ•´ä¸ªæµç¨‹é€šè¿‡å¼•å…¥ååºå…³ç³»ï¼Œç¡®ä¿æ¨¡å‹åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­èƒ½å¤Ÿæ•æ‰åˆ°å±‚æ¬¡ç»“æ„çš„å¤æ‚æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ˜¾å¼å»ºæ¨¡æ¨ç†çš„ä¼ é€’æ€§ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„éšå¼å»ºæ¨¡æ–¹å¼å½¢æˆé²œæ˜å¯¹æ¯”ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å‡†ç¡®åœ°åæ˜ æ¦‚å¿µä¹‹é—´çš„å±‚æ¬¡å…³ç³»ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ååºå…³ç³»ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†æ–°çš„åµŒå…¥å±‚ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹å±‚æ¬¡ç»“æ„çš„å­¦ä¹ èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ¨¡å‹åœ¨å±‚æ¬¡ç‰©ç§åˆ†ç±»ä»»åŠ¡ä¸­ç›¸è¾ƒäºç°æœ‰æœ€å…ˆè¿›æ¨¡å‹æå‡äº†çº¦15%çš„å‡†ç¡®ç‡ï¼Œåœ¨å±‚æ¬¡æ£€ç´¢ä»»åŠ¡ä¸­ä¹Ÿå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†RCMEæ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”Ÿç‰©åˆ†ç±»ã€å›¾åƒæ£€ç´¢å’Œå¤šæ¨¡æ€å­¦ä¹ ç­‰ã€‚é€šè¿‡æ›´å¥½åœ°ç†è§£è§†è§‰å’Œè¯­è¨€ä¹‹é—´çš„å…³ç³»ï¼ŒRCMEæ¡†æ¶å¯ä»¥åœ¨æ•™è‚²ã€ç§‘ç ”å’Œå•†ä¸šç­‰å¤šä¸ªé¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Learning the hierarchical structure of data in vision-language models is a significant challenge. Previous works have attempted to address this challenge by employing entailment learning. However, these approaches fail to model the transitive nature of entailment explicitly, which establishes the relationship between order and semantics within a representation space. In this work, we introduce Radial Cross-Modal Embeddings (RCME), a framework that enables the explicit modeling of transitivity-enforced entailment. Our proposed framework optimizes for the partial order of concepts within vision-language models. By leveraging our framework, we develop a hierarchical vision-language foundation model capable of representing the hierarchy in the Tree of Life. Our experiments on hierarchical species classification and hierarchical retrieval tasks demonstrate the enhanced performance of our models compared to the existing state-of-the-art models. Our code and models are open-sourced at https://vishu26.github.io/RCME/index.html.

