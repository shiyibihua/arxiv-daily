---
layout: default
title: ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing
---

# ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21448" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21448v3</a>
  <a href="https://arxiv.org/pdf/2506.21448.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21448v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21448v3', 'ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Huadai Liu, Kaicheng Luo, Jialei Wang, Wen Wang, Qian Chen, Zhou Zhao, Wei Xue

**åˆ†ç±»**: eess.AS, cs.CV, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26 (æ›´æ–°: 2025-11-05)

**å¤‡æ³¨**: Accepted by NeurIPS 2025 Main

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºThinkSoundæ¡†æ¶ä»¥è§£å†³è§†é¢‘éŸ³é¢‘ç”Ÿæˆä¸­çš„é«˜ä¿çœŸæŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘éŸ³é¢‘ç”Ÿæˆ` `é“¾å¼æ€ç»´æ¨ç†` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `éŸ³æ•ˆè®¾è®¡` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†é¢‘åˆ°éŸ³é¢‘ç”Ÿæˆæ–¹æ³•åœ¨é«˜ä¿çœŸéŸ³é¢‘ç”Ÿæˆä¸Šå­˜åœ¨æŒ‘æˆ˜ï¼Œéš¾ä»¥çœŸå®æ•æ‰è§†è§‰å†…å®¹çš„ç»†å¾®å·®åˆ«ã€‚
2. æœ¬æ–‡æå‡ºçš„ThinkSoundæ¡†æ¶é€šè¿‡é“¾å¼æ€ç»´æ¨ç†ï¼Œåˆ†é˜¶æ®µå®ç°éŸ³é¢‘çš„ç”Ÿæˆä¸ç¼–è¾‘ï¼Œå¢å¼ºäº†ç”¨æˆ·äº¤äº’ä½“éªŒã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒThinkSoundåœ¨éŸ³é¢‘æŒ‡æ ‡å’Œé“¾å¼æ€ç»´æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨Movie Gen AudioåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡ç«¯åˆ°ç«¯çš„è§†é¢‘åˆ°éŸ³é¢‘ç”ŸæˆæŠ€æœ¯å·²æ˜¾è‘—æå‡ï¼Œä½†é«˜ä¿çœŸéŸ³é¢‘çš„ç”Ÿæˆä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨æ•æ‰è§†è§‰å†…å®¹ç»†å¾®å·®åˆ«æ–¹é¢ã€‚æœ¬æ–‡æå‡ºäº†ThinkSoundï¼Œä¸€ä¸ªåˆ©ç”¨é“¾å¼æ€ç»´æ¨ç†çš„æ¡†æ¶ï¼Œæ”¯æŒè§†é¢‘çš„é€æ­¥ã€äº¤äº’å¼éŸ³é¢‘ç”Ÿæˆä¸ç¼–è¾‘ã€‚è¯¥æ–¹æ³•å°†è¿‡ç¨‹åˆ†ä¸ºä¸‰ä¸ªäº’è¡¥é˜¶æ®µï¼šåŸºç¡€éŸ³æ•ˆç”Ÿæˆã€äº¤äº’å¼å¯¹è±¡ä¸­å¿ƒç²¾ç»†åŒ–å’ŒåŸºäºè‡ªç„¶è¯­è¨€æŒ‡ä»¤çš„ç›®æ ‡ç¼–è¾‘ã€‚æ¯ä¸ªé˜¶æ®µéƒ½é€šè¿‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸Šä¸‹æ–‡å¯¹é½çš„é“¾å¼æ€ç»´æ¨ç†ï¼ŒæŒ‡å¯¼ç»Ÿä¸€çš„éŸ³é¢‘åŸºç¡€æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†AudioCoTï¼Œä¸€ä¸ªå…·æœ‰ç»“æ„åŒ–æ¨ç†æ³¨é‡Šçš„ç»¼åˆæ•°æ®é›†ï¼Œå»ºç«‹è§†è§‰å†…å®¹ã€æ–‡æœ¬æè¿°ä¸å£°éŸ³åˆæˆä¹‹é—´çš„è”ç³»ã€‚å®éªŒè¡¨æ˜ï¼ŒThinkSoundåœ¨è§†é¢‘åˆ°éŸ³é¢‘ç”Ÿæˆæ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†é¢‘åˆ°éŸ³é¢‘ç”Ÿæˆä¸­é«˜ä¿çœŸéŸ³é¢‘çš„ç”Ÿæˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ•æ‰è§†è§‰å†…å®¹çš„ç»†å¾®å·®åˆ«å’Œå¤æ‚çš„éŸ³é¢‘ç¯å¢ƒæ–¹é¢å­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šThinkSoundæ¡†æ¶åˆ©ç”¨é“¾å¼æ€ç»´æ¨ç†ï¼Œåˆ†é˜¶æ®µå®ç°éŸ³é¢‘ç”Ÿæˆä¸ç¼–è¾‘ï¼Œé€šè¿‡ç”¨æˆ·äº¤äº’æå‡ç”Ÿæˆè´¨é‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åˆ†ä¸ºä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šåŸºç¡€éŸ³æ•ˆç”Ÿæˆã€äº¤äº’å¼å¯¹è±¡ä¸­å¿ƒç²¾ç»†åŒ–å’ŒåŸºäºè‡ªç„¶è¯­è¨€çš„ç›®æ ‡ç¼–è¾‘ã€‚æ¯ä¸ªé˜¶æ®µéƒ½ä¾èµ–äºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„ä¸Šä¸‹æ–‡å¯¹é½æ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥é“¾å¼æ€ç»´æ¨ç†ï¼Œå…è®¸é€æ­¥ç”Ÿæˆå’Œç¼–è¾‘éŸ³é¢‘ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œç”¨æˆ·äº¤äº’çš„çµæ´»æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œæ¡†æ¶é‡‡ç”¨äº†ç»“æ„åŒ–æ¨ç†æ³¨é‡Šçš„æ•°æ®é›†AudioCoTï¼Œç¡®ä¿è§†è§‰å†…å®¹ã€æ–‡æœ¬æè¿°ä¸éŸ³é¢‘åˆæˆä¹‹é—´çš„æœ‰æ•ˆè¿æ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒThinkSoundåœ¨è§†é¢‘åˆ°éŸ³é¢‘ç”Ÿæˆä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨éŸ³é¢‘è´¨é‡å’Œé“¾å¼æ€ç»´æ¨ç†æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå°¤å…¶åœ¨Movie Gen AudioåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°çªå‡ºï¼Œæå‡å¹…åº¦æ˜¾è‘—ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ThinkSoundæ¡†æ¶åœ¨å½±è§†åˆ¶ä½œã€æ¸¸æˆéŸ³æ•ˆè®¾è®¡å’Œè™šæ‹Ÿç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æä¾›é«˜ä¿çœŸéŸ³é¢‘ç”Ÿæˆä¸ç¼–è¾‘èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡åˆ›ä½œæ•ˆç‡å’ŒéŸ³é¢‘è´¨é‡ï¼Œæ¨åŠ¨ç›¸å…³è¡Œä¸šçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While end-to-end video-to-audio generation has greatly improved, producing high-fidelity audio that authentically captures the nuances of visual content remains challenging. Like professionals in the creative industries, this generation requires sophisticated reasoning about items such as visual dynamics, acoustic environments, and temporal relationships. We present ThinkSound, a novel framework that leverages Chain-of-Thought (CoT) reasoning to enable stepwise, interactive audio generation and editing for videos. Our approach decomposes the process into three complementary stages: foundational foley generation that creates semantically coherent soundscapes, interactive object-centric refinement through precise user interactions, and targeted editing guided by natural language instructions. At each stage, a multimodal large language model generates contextually aligned CoT reasoning that guides a unified audio foundation model. Furthermore, we introduce AudioCoT, a comprehensive dataset with structured reasoning annotations that establishes connections between visual content, textual descriptions, and sound synthesis. Experiments demonstrate that ThinkSound achieves state-of-the-art performance in video-to-audio generation across both audio metrics and CoT metrics, and excels in the out-of-distribution Movie Gen Audio benchmark. The project page is available at https://ThinkSound-Project.github.io.

