---
layout: default
title: EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for Efficient Egocentric Perception
---

# EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for Efficient Egocentric Perception

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21080" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21080v1</a>
  <a href="https://arxiv.org/pdf/2506.21080.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21080v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21080v1', 'EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for Efficient Egocentric Perception')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sanjoy Chowdhury, Subrata Biswas, Sayan Nag, Tushar Nagarajan, Calvin Murdock, Ishwarya Ananthabhotla, Yijun Qian, Vamsi Krishna Ithapu, Dinesh Manocha, Ruohan Gao

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

**å¤‡æ³¨**: Accepted at ICCV 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEgoAdaptä»¥è§£å†³å¤šæ¨¡æ€è‡ªæˆ‘æ„ŸçŸ¥çš„é«˜è®¡ç®—æˆæœ¬é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `è‡ªæˆ‘ä¸­å¿ƒæ„ŸçŸ¥` `å¤šæ¨¡æ€å­¦ä¹ ` `è’¸é¦è®­ç»ƒ` `ç­–ç•¥å­¦ä¹ ` `é«˜æ•ˆæ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€è‡ªæˆ‘ä¸­å¿ƒæ„ŸçŸ¥æ¨¡å‹åœ¨æ€§èƒ½ä¸Šè™½æœ‰çªç ´ï¼Œä½†è®¡ç®—æˆæœ¬é«˜ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„éƒ¨ç½²ã€‚
2. EgoAdaptæ¡†æ¶é€šè¿‡è‡ªé€‚åº”è·¨æ¨¡æ€è’¸é¦å’Œç­–ç•¥å­¦ä¹ ï¼Œæå‡äº†ä¸åŒè‡ªæˆ‘ä¸­å¿ƒæ„ŸçŸ¥ä»»åŠ¡çš„æ¨ç†æ•ˆç‡ã€‚
3. åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼ŒEgoAdaptæ˜¾è‘—é™ä½äº†è®¡ç®—èµ„æºæ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒæˆ–è¶…è¶Šäº†ç°æœ‰æ¨¡å‹çš„æ€§èƒ½è¡¨ç°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°ä»£æ„ŸçŸ¥æ¨¡å‹ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹å¤šæ„ŸçŸ¥è‡ªæˆ‘ä¸­å¿ƒä»»åŠ¡çš„æ¨¡å‹ï¼Œè™½ç„¶å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½ï¼Œä½†é€šå¸¸ä¼´éšé«˜æ˜‚çš„è®¡ç®—æˆæœ¬ã€‚è¿™äº›é«˜éœ€æ±‚åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­éƒ¨ç½²æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºEgoAdaptæ¡†æ¶ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°è¿›è¡Œè·¨æ¨¡æ€è’¸é¦å’Œç­–ç•¥å­¦ä¹ ï¼Œä»¥å®ç°ä¸åŒè‡ªæˆ‘ä¸­å¿ƒæ„ŸçŸ¥ä»»åŠ¡çš„é«˜æ•ˆæ¨ç†ï¼ŒåŒ…æ‹¬è‡ªæˆ‘ä¸­å¿ƒåŠ¨ä½œè¯†åˆ«ã€ä¸»åŠ¨è¯´è¯è€…å®šä½å’Œè¡Œä¸ºé¢„æµ‹ã€‚æˆ‘ä»¬æå‡ºçš„ç­–ç•¥æ¨¡å—èƒ½å¤Ÿé€‚åº”ä»»åŠ¡ç‰¹å®šçš„åŠ¨ä½œç©ºé—´ï¼Œå…·æœ‰å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨EPIC-Kitchensã€EasyComå’ŒAria Everyday Activitiesç­‰ä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„è‡ªæˆ‘ä¸­å¿ƒæ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†æ•ˆç‡ï¼ŒGMACså‡å°‘äº†é«˜è¾¾89.09%ï¼Œå‚æ•°å‡å°‘äº†82.02%ï¼Œèƒ½é‡å‡å°‘äº†9.6å€ï¼ŒåŒæ—¶åœ¨è®¸å¤šæƒ…å†µä¸‹ä¸å¯¹åº”çš„æœ€å…ˆè¿›æ¨¡å‹çš„æ€§èƒ½æŒå¹³æˆ–è¶…è¶Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€è‡ªæˆ‘ä¸­å¿ƒæ„ŸçŸ¥ä»»åŠ¡ä¸­çš„é«˜è®¡ç®—æˆæœ¬é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ€§èƒ½ä¸Šè™½ç„¶è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„åº”ç”¨å—åˆ°é™åˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEgoAdaptæ¡†æ¶é€šè¿‡è‡ªé€‚åº”çš„è·¨æ¨¡æ€è’¸é¦å’Œç­–ç•¥å­¦ä¹ ï¼Œä¼˜åŒ–äº†ä¸åŒä»»åŠ¡çš„æ¨ç†è¿‡ç¨‹ï¼Œæ—¨åœ¨æé«˜æ•ˆç‡å¹¶é™ä½è®¡ç®—èµ„æºæ¶ˆè€—ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEgoAdaptçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è·¨æ¨¡æ€è’¸é¦æ¨¡å—å’Œç­–ç•¥å­¦ä¹ æ¨¡å—ã€‚è·¨æ¨¡æ€è’¸é¦æ¨¡å—è´Ÿè´£ä»ä¸åŒæ„ŸçŸ¥æ¨¡æ€ä¸­æå–ä¿¡æ¯ï¼Œè€Œç­–ç•¥å­¦ä¹ æ¨¡å—åˆ™æ ¹æ®ä»»åŠ¡ç‰¹å®šçš„åŠ¨ä½œç©ºé—´è¿›è¡Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šEgoAdaptçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è‡ªé€‚åº”æ€§ï¼Œèƒ½å¤Ÿæ ¹æ®ä¸åŒä»»åŠ¡çš„éœ€æ±‚è°ƒæ•´ç­–ç•¥æ¨¡å—ï¼Œæ˜¾è‘—æé«˜äº†æ¨ç†æ•ˆç‡å’Œèµ„æºåˆ©ç”¨ç‡ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œå…¶åœ¨å¤šæ¨¡æ€èåˆå’Œç­–ç•¥ä¼˜åŒ–æ–¹é¢å…·æœ‰æœ¬è´¨çš„åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒEgoAdapté‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡ä¸åŒæ¨¡æ€çš„ä¿¡æ¯è’¸é¦ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šå¼•å…¥äº†å¯è°ƒèŠ‚çš„å‚æ•°è®¾ç½®ï¼Œä»¥é€‚åº”ä¸åŒä»»åŠ¡çš„éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEgoAdaptåœ¨EPIC-Kitchensã€EasyComå’ŒAria Everyday Activitiesæ•°æ®é›†ä¸Šï¼ŒGMACså‡å°‘é«˜è¾¾89.09%ï¼Œå‚æ•°å‡å°‘82.02%ï¼Œèƒ½é‡æ¶ˆè€—é™ä½9.6å€ï¼ŒåŒæ—¶åœ¨æ€§èƒ½ä¸Šä¸æœ€å…ˆè¿›æ¨¡å‹æŒå¹³æˆ–è¶…è¶Šï¼Œå±•ç°å‡ºæ˜¾è‘—çš„æ•ˆç‡æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EgoAdaptæ¡†æ¶åœ¨å¤šä¸ªè‡ªæˆ‘ä¸­å¿ƒæ„ŸçŸ¥ä»»åŠ¡ä¸­å±•ç°å‡ºé«˜æ•ˆçš„æ¨ç†èƒ½åŠ›ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶å¯ç”¨äºæ™ºèƒ½å®¶å±…ã€æœºå™¨äººå¯¼èˆªã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸï¼Œèƒ½å¤Ÿåœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­å®ç°é«˜æ•ˆçš„æ„ŸçŸ¥ä¸å†³ç­–ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å®é™…åº”ç”¨ä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Modern perception models, particularly those designed for multisensory egocentric tasks, have achieved remarkable performance but often come with substantial computational costs. These high demands pose challenges for real-world deployment, especially in resource-constrained environments. In this paper, we introduce EgoAdapt, a framework that adaptively performs cross-modal distillation and policy learning to enable efficient inference across different egocentric perception tasks, including egocentric action recognition, active speaker localization, and behavior anticipation. Our proposed policy module is adaptable to task-specific action spaces, making it broadly applicable. Experimental results on three challenging egocentric datasets EPIC-Kitchens, EasyCom, and Aria Everyday Activities demonstrate that our method significantly enhances efficiency, reducing GMACs by up to 89.09%, parameters up to 82.02%, and energy up to 9.6x, while still on-par and in many cases outperforming, the performance of corresponding state-of-the-art models.

