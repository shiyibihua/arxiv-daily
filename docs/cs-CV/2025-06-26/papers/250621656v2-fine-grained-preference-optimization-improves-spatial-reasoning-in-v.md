---
layout: default
title: Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs
---

# Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21656" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21656v2</a>
  <a href="https://arxiv.org/pdf/2506.21656.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21656v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21656v2', 'Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yifan Shen, Yuanzhe Liu, Jingyuan Zhu, Xu Cao, Xiaofeng Zhang, Yixiao He, Wenming Ye, James Matthew Rehg, Ismini Lourentzou

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26 (æ›´æ–°: 2025-10-26)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSpatialReasoner-R1ä»¥è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹çš„ç©ºé—´æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `ç©ºé—´æ¨ç†` `å¤šæ¨¡å‹è’™ç‰¹å¡æ´›æ ‘æœç´¢` `ç»†ç²’åº¦ä¼˜åŒ–` `é€»è¾‘æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ç»†ç²’åº¦ç©ºé—´æ¨ç†æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚é€»è¾‘å’Œç©ºé—´å¯¹é½ä»»åŠ¡ä¸­ã€‚
2. æœ¬æ–‡æå‡ºäº†SpatialReasoner-R1æ¨¡å‹ï¼Œç»“åˆå¤šæ¨¡å‹è’™ç‰¹å¡æ´›æ ‘æœç´¢å’Œç»†ç²’åº¦ç›´æ¥åå¥½ä¼˜åŒ–ï¼Œä»¥æå‡ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒfDPOåœ¨ç©ºé—´è´¨é‡å’Œæ•°é‡ä»»åŠ¡ä¸Šåˆ†åˆ«æå‡4.1%å’Œ9.0%ï¼Œå¹¶åœ¨SPATIALRGPT-Benchä¸Šåˆ›ä¸‹æ–°çºªå½•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨ç»†ç²’åº¦ç©ºé—´æ¨ç†æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤šæ­¥é€»è¾‘å’Œç²¾ç¡®ç©ºé—´å¯¹é½æ—¶ã€‚æœ¬æ–‡æå‡ºäº†SpatialReasoner-R1ï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³è¿™äº›å±€é™æ€§çš„è§†è§‰è¯­è¨€æ¨ç†æ¨¡å‹ã€‚ä¸ºæ„å»ºé«˜è´¨é‡çš„ç©ºé—´æ¨ç†ç›‘ç£ï¼Œè®¾è®¡äº†å¤šæ¨¡å‹è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆM3CTSï¼‰æ–¹æ³•ï¼Œç”Ÿæˆå¤šæ ·ä¸”é€»è¾‘ä¸€è‡´çš„é•¿é“¾æ€ç»´æ¨ç†è½¨è¿¹ã€‚æ­¤å¤–ï¼Œæå‡ºäº†ç»†ç²’åº¦ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆfDPOï¼‰ï¼Œå¼•å…¥äº†é’ˆå¯¹æè¿°æ€§åŸºç¡€å’Œé€»è¾‘æ¨ç†çš„æ®µç‰¹å®šåå¥½ç²’åº¦ï¼Œé€šè¿‡ç©ºé—´å¥–åŠ±æœºåˆ¶è¯„ä¼°å€™é€‰å“åº”çš„è§†è§‰ä¸€è‡´æ€§ã€ç©ºé—´åŸºç¡€å’Œé€»è¾‘è¿è´¯æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒfDPOåœ¨ç©ºé—´è´¨é‡ä»»åŠ¡ä¸Šå¹³å‡æå‡4.1%ï¼Œåœ¨ç©ºé—´æ•°é‡ä»»åŠ¡ä¸Šæå‡9.0%ã€‚ä½¿ç”¨fDPOè®­ç»ƒçš„SpatialReasoner-R1åœ¨SPATIALRGPT-Benchä¸Šè®¾å®šäº†æ–°çš„çŠ¶æ€-of-the-artï¼ˆSoTAï¼‰ï¼Œåœ¨å¹³å‡å‡†ç¡®ç‡ä¸Šè¶…è¶Šæœ€å¼ºåŸºçº¿9.8%ï¼ŒåŒæ—¶åœ¨ä¸€èˆ¬è§†è§‰è¯­è¨€ä»»åŠ¡ä¸Šä¿æŒç«äº‰åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå½“å‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ç»†ç²’åº¦ç©ºé—´æ¨ç†æ—¶ï¼Œå¸¸å¸¸é¢ä¸´å¤šæ­¥é€»è¾‘æ¨ç†å’Œç©ºé—´å¯¹é½çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´æ¨ç†ç»“æœä¸å¤Ÿå‡†ç¡®å’Œä¸€è‡´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºSpatialReasoner-R1ï¼Œé€šè¿‡å¼•å…¥å¤šæ¨¡å‹è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆM3CTSï¼‰å’Œç»†ç²’åº¦ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆfDPOï¼‰ï¼Œä»¥ç”Ÿæˆé€»è¾‘ä¸€è‡´çš„æ¨ç†è½¨è¿¹å¹¶ä¼˜åŒ–æ¨¡å‹çš„ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šM3CTSç”¨äºç”Ÿæˆå¤šæ ·çš„æ¨ç†è½¨è¿¹ï¼ŒfDPOåˆ™é€šè¿‡ç©ºé—´å¥–åŠ±æœºåˆ¶å¯¹æ¨¡å‹è¿›è¡Œç»†ç²’åº¦ä¼˜åŒ–ï¼Œç¡®ä¿è¾“å‡ºçš„è§†è§‰ä¸€è‡´æ€§å’Œé€»è¾‘è¿è´¯æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†ç»†ç²’åº¦çš„åå¥½ä¼˜åŒ–æœºåˆ¶ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒçš„ç©ºé—´æ¨ç†ä»»åŠ¡ä¸­æ ¹æ®å…·ä½“æ®µè½çš„éœ€æ±‚è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œæ˜¾è‘—æå‡äº†æ¨ç†çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒM3CTSç”Ÿæˆçš„æ¨ç†è½¨è¿¹å…·æœ‰å¤šæ ·æ€§å’Œé€»è¾‘ä¸€è‡´æ€§ï¼ŒfDPOåˆ™é€šè¿‡è®¾å®šç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå¥–åŠ±æœºåˆ¶ï¼Œç¡®ä¿æ¨¡å‹åœ¨è¯„ä¼°å€™é€‰å“åº”æ—¶èƒ½å¤Ÿå……åˆ†è€ƒè™‘è§†è§‰å’Œé€»è¾‘å› ç´ ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„çš„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒfDPOåœ¨ç©ºé—´è´¨é‡ä»»åŠ¡ä¸Šå¹³å‡æå‡4.1%ï¼Œåœ¨ç©ºé—´æ•°é‡ä»»åŠ¡ä¸Šæå‡9.0%ã€‚ä½¿ç”¨fDPOè®­ç»ƒçš„SpatialReasoner-R1åœ¨SPATIALRGPT-Benchä¸Šåˆ›ä¸‹æ–°çš„SoTAï¼Œå¹³å‡å‡†ç¡®ç‡è¶…è¶Šæœ€å¼ºåŸºçº¿9.8%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªç­‰éœ€è¦å¤æ‚ç©ºé—´æ¨ç†çš„åœºæ™¯ã€‚é€šè¿‡æå‡è§†è§‰è¯­è¨€æ¨¡å‹çš„ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥æ˜¾è‘—æ”¹å–„äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œå‡†ç¡®æ€§ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å®é™…åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current Vision-Language Models (VLMs) struggle with fine-grained spatial reasoning, particularly when multi-step logic and precise spatial alignment are required. In this work, we introduce SpatialReasoner-R1, a vision-language reasoning model designed to address these limitations. To construct high-quality supervision for spatial reasoning, we design a Multi-Model Monte Carlo Tree Search (M3CTS) method that generates diverse, logically consistent Long Chain-of-Thought (LongCoT) reasoning trajectories. In addition, we propose fine-grained Direct Preference Optimization (fDPO), which introduces segment-specific preference granularity for descriptive grounding and logical reasoning, guided by a spatial reward mechanism that evaluates candidate responses based on visual consistency, spatial grounding, and logical coherence. Experimental results demonstrate that fDPO achieves an average improvement of 4.1% over standard DPO across spatial quality tasks, and a 9.0% gain in spatial quantity tasks. SpatialReasoner-R1, trained with fDPO, sets a new SoTA on SPATIALRGPT-Bench, outperforming the strongest baseline by 9.8% in average accuracy, while maintaining competitive performance on general vision-language tasks.

