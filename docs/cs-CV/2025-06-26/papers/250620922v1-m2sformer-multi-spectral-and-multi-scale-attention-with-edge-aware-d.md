---
layout: default
title: M2SFormer: Multi-Spectral and Multi-Scale Attention with Edge-Aware Difficulty Guidance for Image Forgery Localization
---

# M2SFormer: Multi-Spectral and Multi-Scale Attention with Edge-Aware Difficulty Guidance for Image Forgery Localization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20922" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20922v1</a>
  <a href="https://arxiv.org/pdf/2506.20922.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20922v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20922v1', 'M2SFormer: Multi-Spectral and Multi-Scale Attention with Edge-Aware Difficulty Guidance for Image Forgery Localization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ju-Hyeon Nam, Dong-Hyun Moon, Sang-Chul Lee

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

**å¤‡æ³¨**: Accepted in International Conference on Computer Vision (ICCV) 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºM2SFormerä»¥è§£å†³å›¾åƒä¼ªé€ å®šä½ä¸­çš„ç»†èŠ‚æŸå¤±é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å›¾åƒä¼ªé€ ` `æ·±åº¦å­¦ä¹ ` `Transformer` `å¤šå°ºåº¦æ³¨æ„åŠ›` `å›¾åƒå¤„ç†` `æ•°å­—å–è¯` `ä¼ªé€ æ£€æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨å›¾åƒä¼ªé€ å®šä½ä¸­å­˜åœ¨è®¡ç®—å¼€é”€å¤§å’Œè¡¨ç¤ºèƒ½åŠ›æœ‰é™çš„é—®é¢˜ï¼Œå°¤å…¶å¯¹äºç»†å¾®ç¯¡æ”¹çš„å¤„ç†ã€‚
2. M2SFormeré€šè¿‡ç»Ÿä¸€å¤šé¢‘ç‡å’Œå¤šå°ºåº¦çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç»“åˆå…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæå‡äº†ä¼ªé€ ä¼ªå½±çš„æ•æ‰èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒM2SFormeråœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ç°æœ‰æ¨¡å‹ï¼Œå°¤å…¶åœ¨æœªè§é¢†åŸŸçš„æ£€æµ‹å’Œå®šä½èƒ½åŠ›ä¸Šæœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å›¾åƒç¼–è¾‘æŠ€æœ¯çš„è¿…é€Ÿå‘å±•ï¼Œæ•°å­—å›¾åƒçš„åˆ›æ–°åº”ç”¨ä¸æ¶æ„æ“æ§å¹¶å­˜ã€‚å°½ç®¡åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•åœ¨åƒç´ çº§ä¼ªé€ å®šä½ä¸­å–å¾—äº†é«˜å‡†ç¡®ç‡ï¼Œä½†åœ¨è®¡ç®—å¼€é”€å’Œè¡¨ç¤ºèƒ½åŠ›æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯å¯¹äºç»†å¾®æˆ–å¤æ‚çš„ç¯¡æ”¹ã€‚æœ¬æ–‡æå‡ºäº†M2SFormerï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„åŸºäºTransformerçš„ç¼–ç å™¨æ¡†æ¶ï¼Œæ—¨åœ¨å…‹æœè¿™äº›æŒ‘æˆ˜ã€‚M2SFormeré€šè¿‡åœ¨è·³è·ƒè¿æ¥ä¸­ç»Ÿä¸€å¤šé¢‘ç‡å’Œå¤šå°ºåº¦æ³¨æ„åŠ›ï¼Œåˆ©ç”¨å…¨å±€ä¸Šä¸‹æ–‡æ›´å¥½åœ°æ•æ‰å¤šæ ·çš„ä¼ªé€ ä¼ªå½±ã€‚æ­¤å¤–ï¼Œæ¡†æ¶é€šè¿‡åˆ©ç”¨å…¨å±€å…ˆéªŒå›¾å’Œæ›²ç‡åº¦é‡æ¥å¼•å¯¼éš¾åº¦å¼•å¯¼æ³¨æ„åŠ›æ¨¡å—ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°ä¿ç•™ç»†å¾®çš„æ“æ§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒM2SFormeråœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ¨¡å‹ï¼Œåœ¨æœªè§é¢†åŸŸä¸­æ£€æµ‹å’Œå®šä½ä¼ªé€ çš„æ³›åŒ–èƒ½åŠ›æ›´å¼ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å›¾åƒä¼ªé€ å®šä½ä¸­ç»†èŠ‚æŸå¤±å’Œè®¡ç®—å¼€é”€å¤§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚æˆ–ç»†å¾®ç¯¡æ”¹æ—¶è¡¨ç°ä¸ä½³ï¼Œéš¾ä»¥æœ‰æ•ˆæ•æ‰ä¼ªé€ ç‰¹å¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šM2SFormeré€šè¿‡åœ¨è·³è·ƒè¿æ¥ä¸­æ•´åˆå¤šé¢‘ç‡å’Œå¤šå°ºåº¦çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œåˆ©ç”¨å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å¢å¼ºä¼ªé€ ç‰¹å¾çš„æ•æ‰èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨å…¨å±€å…ˆéªŒå›¾å’Œæ›²ç‡åº¦é‡æ¥å¼•å¯¼æ³¨æ„åŠ›æ¨¡å—ï¼Œæœ‰æ•ˆä¿ç•™ç»†å¾®æ“æ§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šM2SFormerçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆæ˜¯å¤šé¢‘ç‡å’Œå¤šå°ºåº¦çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç„¶åæ˜¯å…¨å±€å…ˆéªŒå›¾çš„ç”Ÿæˆï¼Œæœ€åæ˜¯éš¾åº¦å¼•å¯¼çš„æ³¨æ„åŠ›æ¨¡å—ã€‚è¿™äº›æ¨¡å—ååŒå·¥ä½œï¼Œä»¥æå‡ä¼ªé€ å®šä½çš„ç²¾åº¦å’Œæ•ˆç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šM2SFormerçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†å¤šé¢‘ç‡å’Œå¤šå°ºåº¦æ³¨æ„åŠ›æœºåˆ¶ç»“åˆåœ¨ä¸€èµ·ï¼Œå¹¶é€šè¿‡å…¨å±€å…ˆéªŒå›¾å¼•å¯¼æ³¨æ„åŠ›æ¨¡å—ï¼Œä»è€Œæœ‰æ•ˆè§£å†³äº†ç»†èŠ‚æŸå¤±çš„é—®é¢˜ã€‚è¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿæ–¹æ³•çš„åˆ†ç¦»å¤„ç†æ–¹å¼å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼ŒM2SFormeré‡‡ç”¨äº†Transformerç¼–ç å™¨æ¶æ„ï¼Œç»“åˆäº†è·³è·ƒè¿æ¥å’Œå…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œè€ƒè™‘äº†ç»†èŠ‚ä¿ç•™å’Œä¼ªé€ å®šä½çš„ç»¼åˆæ•ˆæœï¼Œä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œè¶…å‚æ•°è°ƒä¼˜åœ¨å®éªŒä¸­è¿›è¡Œäº†è¯¦ç»†æ¢è®¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒM2SFormeråœ¨ä¼ªé€ æ£€æµ‹å’Œå®šä½ä»»åŠ¡ä¸­è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›æ¨¡å‹ï¼Œå°¤å…¶åœ¨æœªè§é¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›ä¸Šæå‡æ˜¾è‘—ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°äº†XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

M2SFormeråœ¨å›¾åƒä¼ªé€ æ£€æµ‹å’Œå®šä½é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶é€‚ç”¨äºæ•°å­—å–è¯ã€ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸å’Œæ–°é—»çœŸå®æ€§éªŒè¯ç­‰åœºæ™¯ã€‚éšç€å›¾åƒç¼–è¾‘æŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼Œè¯¥ç ”ç©¶çš„æˆæœå°†ä¸ºæ‰“å‡»æ¶æ„æ“æ§æä¾›æœ‰æ•ˆå·¥å…·ï¼Œæå‡å…¬ä¼—å¯¹æ•°å­—å†…å®¹çš„ä¿¡ä»»åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Image editing techniques have rapidly advanced, facilitating both innovative use cases and malicious manipulation of digital images. Deep learning-based methods have recently achieved high accuracy in pixel-level forgery localization, yet they frequently struggle with computational overhead and limited representation power, particularly for subtle or complex tampering. In this paper, we propose M2SFormer, a novel Transformer encoder-based framework designed to overcome these challenges. Unlike approaches that process spatial and frequency cues separately, M2SFormer unifies multi-frequency and multi-scale attentions in the skip connection, harnessing global context to better capture diverse forgery artifacts. Additionally, our framework addresses the loss of fine detail during upsampling by utilizing a global prior map, a curvature metric indicating the difficulty of forgery localization, which then guides a difficulty-guided attention module to preserve subtle manipulations more effectively. Extensive experiments on multiple benchmark datasets demonstrate that M2SFormer outperforms existing state-of-the-art models, offering superior generalization in detecting and localizing forgeries across unseen domains.

