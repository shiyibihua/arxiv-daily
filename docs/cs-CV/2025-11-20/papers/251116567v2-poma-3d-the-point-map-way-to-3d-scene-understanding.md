---
layout: default
title: POMA-3D: The Point Map Way to 3D Scene Understanding
---

# POMA-3D: The Point Map Way to 3D Scene Understanding

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.16567" target="_blank" class="toolbar-btn">arXiv: 2511.16567v2</a>
    <a href="https://arxiv.org/pdf/2511.16567.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.16567v2" 
            onclick="toggleFavorite(this, '2511.16567v2', 'POMA-3D: The Point Map Way to 3D Scene Understanding')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Ye Mao, Weixun Luo, Ranran Huang, Junpeng Jing, Krystian Mikolajczyk

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-20 (Êõ¥Êñ∞: 2025-11-21)

**Â§áÊ≥®**: 11 pages, 6 tables, 5 figures

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://matchlab-imperial.github.io/poma3d/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**POMA-3DÔºöÊèêÂá∫Âü∫‰∫éÁÇπÂõæÁöÑËá™ÁõëÁù£3DÂú∫ÊôØÁêÜËß£Ê®°ÂûãÔºåÊèêÂçáÂ§öÈ°π‰∏ãÊ∏∏‰ªªÂä°ÊÄßËÉΩ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `3DÂú∫ÊôØÁêÜËß£` `ÁÇπÂõæË°®Á§∫` `Ëá™ÁõëÁù£Â≠¶‰π†` `È¢ÑËÆ≠ÁªÉÊ®°Âûã` `Âá†‰ΩïË°®Á§∫`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3DË°®Á§∫Â≠¶‰π†Áº∫‰πèÊúâÊïàÁöÑÈ¢ÑËÆ≠ÁªÉÊñπÊ≥ïÂíåÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÊÄßËÉΩ„ÄÇ
2. POMA-3DÂà©Áî®ÁÇπÂõæÂ∞Ü3D‰ø°ÊÅØÁºñÁ†Å‰∏∫2DÁªìÊûÑÔºåÂπ∂ËÆæËÆ°ËßÜËßíÂØπÈΩêÁ≠ñÁï•ÂíåËÅîÂêàÂµåÂÖ•È¢ÑÊµãÊû∂ÊûÑ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåPOMA-3DÂú®3DÈóÆÁ≠î„ÄÅÂØºËà™Á≠â‰ªªÂä°‰∏äË°®Áé∞Âá∫Ëâ≤ÔºåÈ™åËØÅ‰∫ÜÂÖ∂‰Ωú‰∏∫ÈÄöÁî®3DÈ™®Âπ≤ÁΩëÁªúÁöÑÊΩúÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫POMA-3DÔºåÈ¶ñ‰∏™‰ªéÁÇπÂõæÂ≠¶‰π†ÁöÑËá™ÁõëÁù£3DË°®Á§∫Ê®°Âûã„ÄÇÁÇπÂõæÂú®ÁªìÊûÑÂåñÁöÑ2DÁΩëÊ†º‰∏äÁºñÁ†ÅÊòæÂºèÁöÑ3DÂùêÊ†áÔºå‰øùÁïôÂÖ®Â±Ä3DÂá†‰Ωï‰ø°ÊÅØÔºåÂêåÊó∂ÂÖºÂÆπ2DÂü∫Á°ÄÊ®°ÂûãÁöÑËæìÂÖ•Ê†ºÂºè„ÄÇ‰∏∫‰∫ÜÂ∞Ü‰∏∞ÂØåÁöÑ2DÂÖàÈ™åÁü•ËØÜËøÅÁßªÂà∞POMA-3D‰∏≠ÔºåËÆæËÆ°‰∫Ü‰∏ÄÁßçËßÜËßíÂà∞Âú∫ÊôØÁöÑÂØπÈΩêÁ≠ñÁï•„ÄÇÊ≠§Â§ñÔºåÁî±‰∫éÁÇπÂõæÁõ∏ÂØπ‰∫éËßÑËåÉÁ©∫Èó¥ÊòØËßÜËßíÁõ∏ÂÖ≥ÁöÑÔºåÊàë‰ª¨ÂºïÂÖ•POMA-JEPAÔºå‰∏ÄÁßçËÅîÂêàÂµåÂÖ•-È¢ÑÊµãÊû∂ÊûÑÔºåÁî®‰∫éÂú®Â§ö‰∏™ËßÜËßí‰∏äÂº∫Âà∂ÊâßË°åÂá†‰Ωï‰∏ÄËá¥ÁöÑÁÇπÂõæÁâπÂæÅ„ÄÇÂêåÊó∂ÔºåÊàë‰ª¨ÊûÑÂª∫‰∫ÜScenePointÊï∞ÊçÆÈõÜÔºåÂåÖÂê´6.5K‰∏™ÊàøÈó¥Á∫ßRGB-DÂú∫ÊôØÂíå1M‰∏™2DÂõæÂÉèÂú∫ÊôØÔºå‰ª•‰øÉËøõÂ§ßËßÑÊ®°POMA-3DÈ¢ÑËÆ≠ÁªÉ„ÄÇÂÆûÈ™åË°®ÊòéÔºåPOMA-3DÂèØ‰ª•‰Ωú‰∏∫‰∏ìÂÆ∂ÂíåÈÄöÁî®3DÁêÜËß£ÁöÑÂº∫Â§ßÈ™®Âπ≤ÁΩëÁªúÔºåÂπ∂ËÉΩÊèêÂçáÂåÖÊã¨3DÈóÆÁ≠î„ÄÅÂÖ∑Ë∫´ÂØºËà™„ÄÅÂú∫ÊôØÊ£ÄÁ¥¢ÂíåÂÖ∑Ë∫´ÂÆö‰ΩçÁ≠âÂ§öÁßç‰ªªÂä°ÁöÑÊÄßËÉΩÔºåÊâÄÊúâËøô‰∫õÈÉΩ‰ªÖ‰ΩøÁî®Âá†‰ΩïËæìÂÖ•ÔºàÂç≥3DÂùêÊ†áÔºâ„ÄÇÊÄªËÄåË®Ä‰πãÔºåPOMA-3DÊé¢Á¥¢‰∫Ü‰∏ÄÁßçÂü∫‰∫éÁÇπÂõæÁöÑ3DÂú∫ÊôØÁêÜËß£ÊñπÊ≥ïÔºåËß£ÂÜ≥‰∫Ü3DË°®Á§∫Â≠¶‰π†‰∏≠È¢ÑËÆ≠ÁªÉÂÖàÈ™åÁü•ËØÜÂåÆ‰πèÂíåÊï∞ÊçÆÊúâÈôêÁöÑÈóÆÈ¢ò„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑ3DÂú∫ÊôØÁêÜËß£ÊñπÊ≥ïÈù¢‰∏¥ÁùÄ‰∏§‰∏™‰∏ªË¶ÅÈóÆÈ¢òÔºö‰∏ÄÊòØÁº∫‰πèÊúâÊïàÁöÑÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºåÂØºËá¥Ê®°ÂûãÈúÄË¶Å‰ªéÂ§¥ÂºÄÂßãÂ≠¶‰π†ÔºåÊïàÁéá‰Ωé‰∏ãÔºõ‰∫åÊòØ3DÊï∞ÊçÆÁöÑËé∑ÂèñÊàêÊú¨È´òÊòÇÔºåÂØºËá¥ËÆ≠ÁªÉÊï∞ÊçÆ‰∏çË∂≥ÔºåÊ®°ÂûãÊ≥õÂåñËÉΩÂäõÂèóÈôê„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÂà©Áî®ÊúâÈôêÁöÑ3DÊï∞ÊçÆÔºåÂ≠¶‰π†Âà∞ÈÄöÁî®ÁöÑ„ÄÅÂèØËøÅÁßªÁöÑ3DË°®Á§∫ÔºåÊòØÂΩìÂâç3DÂú∫ÊôØÁêÜËß£È¢ÜÂüüÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöPOMA-3DÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞Ü3DÁÇπ‰∫ëÊï∞ÊçÆËΩ¨Êç¢‰∏∫2DÁÇπÂõæË°®Á§∫Ôºå‰ªéËÄåËÉΩÂ§üÂà©Áî®Âú®2DÂõæÂÉèÈ¢ÜÂüüÈ¢ÑËÆ≠ÁªÉÁöÑÂº∫Â§ßÊ®°Âûã„ÄÇÈÄöËøáÂ∞Ü3DÂùêÊ†áÊò†Â∞ÑÂà∞2DÁΩëÊ†º‰∏äÔºå‰øùÁïô‰∫Ü3DÂú∫ÊôØÁöÑÂá†‰Ωï‰ø°ÊÅØÔºåÂêåÊó∂‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂà©Áî®2DÂç∑ÁßØÁ•ûÁªèÁΩëÁªúËøõË°åÁâπÂæÅÊèêÂèñ„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫ÜËß£ÂÜ≥ÁÇπÂõæÁöÑËßÜËßí‰æùËµñÊÄßÈóÆÈ¢òÔºåËÆ∫ÊñáÊèêÂá∫‰∫ÜËßÜËßíÂØπÈΩêÁ≠ñÁï•ÂíåËÅîÂêàÂµåÂÖ•È¢ÑÊµãÊû∂ÊûÑÔºå‰ª•‰øùËØÅÊ®°ÂûãÂ≠¶‰π†Âà∞ÁöÑÁâπÂæÅÂÖ∑ÊúâËßÜËßí‰∏çÂèòÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPOMA-3DÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÈÉ®ÂàÜÔºöÁÇπÂõæÁîüÊàê„ÄÅÁâπÂæÅÊèêÂèñÂíåËÅîÂêàÂµåÂÖ•È¢ÑÊµã„ÄÇÈ¶ñÂÖàÔºåÂ∞Ü3DÁÇπ‰∫ëÊï∞ÊçÆÊäïÂΩ±Âà∞Â§ö‰∏™ËßÜËßíÔºåÁîüÊàêÂØπÂ∫îÁöÑÁÇπÂõæ„ÄÇÁÑ∂ÂêéÔºå‰ΩøÁî®2DÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÔºà‰æãÂ¶ÇÔºåVision TransformerÔºâ‰ªéÁÇπÂõæ‰∏≠ÊèêÂèñÁâπÂæÅ„ÄÇÊúÄÂêéÔºåÈÄöËøáPOMA-JEPAÊû∂ÊûÑÔºåÂà©Áî®Â§ö‰∏™ËßÜËßíÁöÑÁÇπÂõæÁâπÂæÅËøõË°åËÅîÂêàÂµåÂÖ•È¢ÑÊµãÔºå‰ªéËÄåÂ≠¶‰π†Âà∞ÂÖ∑ÊúâËßÜËßí‰∏çÂèòÊÄßÁöÑ3DË°®Á§∫„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöPOMA-3DÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ª•‰∏ãÂá†ÁÇπÔºö‰∏ÄÊòØÊèêÂá∫‰∫ÜÁÇπÂõæË°®Á§∫ÔºåÂ∞Ü3DÊï∞ÊçÆËΩ¨Êç¢‰∏∫2DÁªìÊûÑÔºå‰ªéËÄåËÉΩÂ§üÂà©Áî®2DÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºõ‰∫åÊòØËÆæËÆ°‰∫ÜËßÜËßíÂØπÈΩêÁ≠ñÁï•ÂíåPOMA-JEPAÊû∂ÊûÑÔºåËß£ÂÜ≥‰∫ÜÁÇπÂõæÁöÑËßÜËßí‰æùËµñÊÄßÈóÆÈ¢òÔºõ‰∏âÊòØÊûÑÂª∫‰∫ÜÂ§ßËßÑÊ®°ÁöÑScenePointÊï∞ÊçÆÈõÜÔºå‰∏∫3DË°®Á§∫Â≠¶‰π†Êèê‰æõ‰∫ÜÂÖÖË∂≥ÁöÑËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåPOMA-3DËÉΩÂ§üÂ≠¶‰π†Âà∞Êõ¥ÈÄöÁî®ÁöÑ„ÄÅÂèØËøÅÁßªÁöÑ3DË°®Á§∫Ôºå‰ªéËÄåÂú®ÂêÑÁßç‰∏ãÊ∏∏‰ªªÂä°‰∏äÂèñÂæóÊõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÁÇπÂõæÁîüÊàêËøáÁ®ã‰∏≠ÔºåÈúÄË¶ÅÈÄâÊã©ÂêàÈÄÇÁöÑÊäïÂΩ±ÊñπÂºèÂíåÂàÜËæ®ÁéáÔºå‰ª•‰øùËØÅÁÇπÂõæËÉΩÂ§üÊúâÊïàÂú∞‰øùÁïô3DÂá†‰Ωï‰ø°ÊÅØ„ÄÇÂú®POMA-JEPAÊû∂ÊûÑ‰∏≠Ôºå‰ΩøÁî®‰∫ÜInfoNCEÊçüÂ§±ÂáΩÊï∞Êù•ËÆ≠ÁªÉÊ®°ÂûãÔºåÈºìÂä±Ê®°ÂûãÂ≠¶‰π†Âà∞ÂÖ∑ÊúâËßÜËßí‰∏çÂèòÊÄßÁöÑÁâπÂæÅ„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÊé¢Á¥¢‰∫Ü‰∏çÂêåÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÔºå‰ª•‰ºòÂåñÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPOMA-3DÂú®3DÈóÆÁ≠î„ÄÅÂÖ∑Ë∫´ÂØºËà™„ÄÅÂú∫ÊôØÊ£ÄÁ¥¢ÂíåÂÖ∑Ë∫´ÂÆö‰ΩçÁ≠âÂ§ö‰∏™‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºåÂú®3DÈóÆÁ≠î‰ªªÂä°‰∏≠ÔºåPOMA-3DÁõ∏ÊØî‰∫éÁé∞ÊúâÊñπÊ≥ïÂèñÂæó‰∫ÜË∂ÖËøá5%ÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÊ≠§Â§ñÔºåPOMA-3DÂú®ScenePointÊï∞ÊçÆÈõÜ‰∏äÁöÑÈ¢ÑËÆ≠ÁªÉËÉΩÂ§üÊúâÊïàÂú∞ÊèêÂçáÊ®°ÂûãÂú®ÂÖ∂‰ªñÊï∞ÊçÆÈõÜ‰∏äÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

POMA-3DÂú®Êú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÊèêÂçáÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊÑüÁü•ËÉΩÂäõÔºåÂ∏ÆÂä©Ëá™Âä®È©æÈ©∂ËΩ¶ËæÜÊõ¥Â•ΩÂú∞ÁêÜËß£Âë®Âõ¥ÁéØÂ¢ÉÔºåÂπ∂‰∏∫ËôöÊãüÁé∞ÂÆûÂ∫îÁî®Êèê‰æõÊõ¥ÈÄºÁúüÁöÑ3DÂú∫ÊôØË°®Á§∫„ÄÇÊ≠§Â§ñÔºåPOMA-3DËøòÂèØ‰ª•Áî®‰∫é3DÂú∫ÊôØÊ£ÄÁ¥¢„ÄÅ3DÈóÆÁ≠îÁ≠â‰ªªÂä°Ôºå‰∏∫Áî®Êà∑Êèê‰æõÊõ¥Êô∫ËÉΩÂåñÁöÑÊúçÂä°„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In this paper, we introduce POMA-3D, the first self-supervised 3D representation model learned from point maps. Point maps encode explicit 3D coordinates on a structured 2D grid, preserving global 3D geometry while remaining compatible with the input format of 2D foundation models. To transfer rich 2D priors into POMA-3D, a view-to-scene alignment strategy is designed. Moreover, as point maps are view-dependent with respect to a canonical space, we introduce POMA-JEPA, a joint embedding-predictive architecture that enforces geometrically consistent point map features across multiple views. Additionally, we introduce ScenePoint, a point map dataset constructed from 6.5K room-level RGB-D scenes and 1M 2D image scenes to facilitate large-scale POMA-3D pretraining. Experiments show that POMA-3D serves as a strong backbone for both specialist and generalist 3D understanding. It benefits diverse tasks, including 3D question answering, embodied navigation, scene retrieval, and embodied localization, all achieved using only geometric inputs (i.e., 3D coordinates). Overall, our POMA-3D explores a point map way to 3D scene understanding, addressing the scarcity of pretrained priors and limited data in 3D representation learning. Project Page: https://matchlab-imperial.github.io/poma3d/

