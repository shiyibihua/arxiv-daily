---
layout: default
title: InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy
---

# InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy

**arXiv**: [2511.16651v1](https://arxiv.org/abs/2511.16651) | [PDF](https://arxiv.org/pdf/2511.16651.pdf)

**ä½œè€…**: Yang Tian, Yuyin Yang, Yiman Xie, Zetao Cai, Xu Shi, Ning Gao, Hangxu Liu, Xuekun Jiang, Zherui Qiu, Feng Yuan, Yaping Li, Ping Wang, Junhao Cai, Jia Zeng, Hao Dong, Jiangmiao Pang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInternData-A1åˆæˆæ•°æ®é›†ï¼Œç”¨äºŽé¢„è®­ç»ƒé€šç”¨ç­–ç•¥æ¨¡åž‹ï¼ŒåŒ¹é…çœŸå®žæ•°æ®æ€§èƒ½ã€‚**

**å…³é”®è¯**: `åˆæˆæ•°æ®ç”Ÿæˆ` `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡åž‹` `æœºå™¨äººé¢„è®­ç»ƒ` `é›¶æ ·æœ¬è¿ç§»` `ä»¿çœŸåˆ°çœŸå®ž` `é•¿æ—¶ç¨‹æŠ€èƒ½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåˆæˆæ•°æ®åœ¨VLAæ¨¡åž‹é¢„è®­ç»ƒä¸­æœªè¾¾å¤§è§„æ¨¡çœŸå®žæ•°æ®æ•ˆæžœã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºå¤§è§„æ¨¡åˆæˆæ•°æ®é›†ï¼Œæ”¯æŒå¤šæŠ€èƒ½ã€ä»»åŠ¡å’Œåœºæ™¯çš„è‡ªä¸»ç”Ÿæˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¨¡åž‹åœ¨ä»¿çœŸå’ŒçœŸå®žä»»åŠ¡ä¸­åŒ¹é…Ï€_0ï¼Œå®žçŽ°é›¶æ ·æœ¬è¿ç§»ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent works explore how real and synthetic data contribute to Vision-Language-Action (VLA) models' generalization. While current VLA models have shown the strong effectiveness of large-scale real-robot pre-training, synthetic data has not previously demonstrated comparable capability at scale. This paper provides the first evidence that synthetic data alone can match the performance of the strongest $Ï€$-dataset in pre-training a VLA model, revealing the substantial value of large-scale simulation. The resulting model also exhibits surprisingly zero-shot sim-to-real transfer on several challenging tasks. Our synthetic dataset, InternData-A1, contains over 630k trajectories and 7,433 hours across 4 embodiments, 18 skills, 70 tasks, and 227 scenes, covering rigid, articulated, deformable, and fluid-object manipulation. It is generated through a highly autonomous, fully decoupled, and compositional simulation pipeline that enables long-horizon skill composition, flexible task assembly, and heterogeneous embodiments with minimal manual tuning. Using the same architecture as $Ï€_0$, we pre-train a model entirely on InternData-A1 and find that it matches the official $Ï€_0$ across 49 simulation tasks, 5 real-world tasks, and 4 long-horizon dexterous tasks. We release the dataset and will open-source the generation pipeline to broaden access to large-scale robotic data and to lower the barrier to scalable data creation for embodied AI research.

