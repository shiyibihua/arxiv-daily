---
layout: default
title: PairHuman: A High-Fidelity Photographic Dataset for Customized Dual-Person Generation
---

# PairHuman: A High-Fidelity Photographic Dataset for Customized Dual-Person Generation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.16712" target="_blank" class="toolbar-btn">arXiv: 2511.16712v2</a>
    <a href="https://arxiv.org/pdf/2511.16712.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.16712v2" 
            onclick="toggleFavorite(this, '2511.16712v2', 'PairHuman: A High-Fidelity Photographic Dataset for Customized Dual-Person Generation')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Ting Pan, Ye Wang, Peiguang Jing, Rui Ma, Zili Yi, Yu Liu

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-20 (æ›´æ–°: 2025-11-24)

**å¤‡æ³¨**: 46 pages, 31 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/annaoooo/PairHuman)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPairHumanæ•°æ®é›†ï¼Œç”¨äºé«˜è´¨é‡å®šåˆ¶åŒäººè‚–åƒç”Ÿæˆï¼Œå¹¶æå‡ºDHumanDiffåŸºçº¿æ¨¡å‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `åŒäººè‚–åƒç”Ÿæˆ` `æ‰©æ•£æ¨¡å‹` `ä¸ªæ€§åŒ–å®šåˆ¶` `æ•°æ®é›†` `é¢éƒ¨ä¸€è‡´æ€§` `å›¾åƒç”Ÿæˆ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é«˜è´¨é‡åŒäººè‚–åƒå®šåˆ¶å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†ç¼ºä¹åŸºå‡†æ•°æ®é›†é˜»ç¢äº†ç›¸å…³ç ”ç©¶ã€‚
2. æå‡ºPairHumanæ•°æ®é›†ï¼ŒåŒ…å«å¤šæ ·åœºæ™¯å’Œä¸°å¯Œå…ƒæ•°æ®ï¼Œå¹¶è®¾è®¡DHumanDiffåŸºçº¿æ¨¡å‹ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒPairHumanæ•°æ®é›†å’ŒDHumanDiffæ¨¡å‹èƒ½ç”Ÿæˆé«˜è´¨é‡ã€ä¸ªæ€§åŒ–çš„åŒäººè‚–åƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†PairHumanæ•°æ®é›†ï¼Œè¿™æ˜¯é¦–ä¸ªä¸“ä¸ºç”Ÿæˆæ»¡è¶³é«˜æ‘„å½±æ ‡å‡†çš„åŒäººè‚–åƒè€Œè®¾è®¡çš„å¤§è§„æ¨¡åŸºå‡†æ•°æ®é›†ã€‚PairHumanæ•°æ®é›†åŒ…å«è¶…è¿‡10ä¸‡å¼ å›¾åƒï¼Œæ•æ‰äº†å„ç§åœºæ™¯ã€æœè£…å’ŒåŒäººäº’åŠ¨ï¼Œä»¥åŠä¸°å¯Œçš„å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬è¯¦ç»†çš„å›¾åƒæè¿°ã€äººç‰©å®šä½ã€äººä½“å…³é”®ç‚¹å’Œå±æ€§æ ‡ç­¾ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜ä»‹ç»äº†DHumanDiffï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºåŒäººè‚–åƒç”Ÿæˆè€Œè®¾è®¡çš„åŸºçº¿æ¨¡å‹ï¼Œå®ƒå…·æœ‰å¢å¼ºçš„é¢éƒ¨ä¸€è‡´æ€§ï¼Œå¹¶åŒæ—¶å¹³è¡¡äº†ä¸ªæ€§åŒ–äººç‰©ç”Ÿæˆå’Œè¯­ä¹‰é©±åŠ¨çš„åœºæ™¯åˆ›å»ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ•°æ®é›†å’Œæ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜åº¦å®šåˆ¶çš„è‚–åƒï¼Œå…·æœ‰å“è¶Šçš„è§†è§‰è´¨é‡ï¼Œå¹¶èƒ½æ»¡è¶³äººç±»çš„åå¥½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•åœ¨åŒäººè‚–åƒç”Ÿæˆä¸­ï¼Œéš¾ä»¥å…¼é¡¾äººç‰©ä¸ªæ€§åŒ–å®šåˆ¶å’Œåœºæ™¯çš„è¯­ä¹‰ä¸€è‡´æ€§ï¼Œå°¤å…¶ç¼ºä¹é«˜è´¨é‡ã€å¤§è§„æ¨¡çš„æ•°æ®é›†æ”¯æŒï¼Œå¯¼è‡´ç”Ÿæˆæ•ˆæœä¸ä½³ï¼Œé¢éƒ¨ä¸€è‡´æ€§éš¾ä»¥ä¿è¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„PairHumanæ•°æ®é›†ï¼Œä¸ºåŒäººè‚–åƒç”Ÿæˆæä¾›æ•°æ®åŸºç¡€ã€‚åŒæ—¶ï¼Œè®¾è®¡DHumanDiffæ¨¡å‹ï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­æ˜¾å¼åœ°è€ƒè™‘é¢éƒ¨ä¸€è‡´æ€§ï¼Œå¹¶å¹³è¡¡äººç‰©ä¸ªæ€§åŒ–å’Œåœºæ™¯è¯­ä¹‰ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDHumanDiffæ¨¡å‹åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å›¾åƒç¼–ç å™¨ï¼šæå–è¾“å…¥å›¾åƒçš„ç‰¹å¾è¡¨ç¤ºï¼›2) äººç‰©ç‰¹å¾èåˆæ¨¡å—ï¼šèåˆä¸¤ä¸ªäººç‰©çš„ä¸ªæ€§åŒ–ç‰¹å¾ï¼Œå¹¶ä¿æŒé¢éƒ¨ä¸€è‡´æ€§ï¼›3) åœºæ™¯ç”Ÿæˆæ¨¡å—ï¼šæ ¹æ®è¯­ä¹‰ä¿¡æ¯ç”Ÿæˆä¸äººç‰©ç›¸åè°ƒçš„èƒŒæ™¯åœºæ™¯ï¼›4) æ‰©æ•£æ¨¡å‹è§£ç å™¨ï¼šå°†èåˆçš„äººç‰©ç‰¹å¾å’Œåœºæ™¯ä¿¡æ¯è§£ç ä¸ºæœ€ç»ˆçš„åŒäººè‚–åƒã€‚

**å…³é”®åˆ›æ–°**ï¼š1) PairHumanæ•°æ®é›†ï¼šå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„åŒäººè‚–åƒæ•°æ®é›†ï¼ŒåŒ…å«ä¸°å¯Œçš„å…ƒæ•°æ®ï¼›2) DHumanDiffæ¨¡å‹ï¼šä¸“é—¨ä¸ºåŒäººè‚–åƒç”Ÿæˆè®¾è®¡çš„æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡äººç‰©ç‰¹å¾èåˆæ¨¡å—å¢å¼ºé¢éƒ¨ä¸€è‡´æ€§ï¼Œå¹¶å¹³è¡¡äººç‰©ä¸ªæ€§åŒ–å’Œåœºæ™¯è¯­ä¹‰ä¿¡æ¯ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDHumanDiffæ›´å…³æ³¨åŒäººè‚–åƒçš„æ•´ä½“åè°ƒæ€§å’Œé¢éƒ¨ç»†èŠ‚ã€‚

**å…³é”®è®¾è®¡**ï¼š1) äººç‰©ç‰¹å¾èåˆæ¨¡å—ï¼šé‡‡ç”¨æ³¨æ„åŠ›æœºåˆ¶ï¼Œå­¦ä¹ ä¸åŒäººç‰©ç‰¹å¾ä¹‹é—´çš„å…³è”æ€§ï¼Œå¹¶ä¿æŒé¢éƒ¨å…³é”®ç‚¹çš„å¯¹é½ï¼›2) æŸå¤±å‡½æ•°ï¼šé™¤äº†æ ‡å‡†çš„æ‰©æ•£æ¨¡å‹æŸå¤±å¤–ï¼Œè¿˜å¼•å…¥äº†é¢éƒ¨ä¸€è‡´æ€§æŸå¤±ï¼Œé¼“åŠ±ç”Ÿæˆå…·æœ‰ç›¸ä¼¼é¢éƒ¨ç‰¹å¾çš„åŒäººè‚–åƒï¼›3) æ•°æ®å¢å¼ºï¼šé‡‡ç”¨å¤šç§æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œå¦‚éšæœºè£å‰ªã€æ—‹è½¬å’Œé¢œè‰²æŠ–åŠ¨ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDHumanDiffæ¨¡å‹åœ¨PairHumanæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDHumanDiffç”Ÿæˆçš„åŒäººè‚–åƒåœ¨é¢éƒ¨ä¸€è‡´æ€§ã€äººç‰©ä¸ªæ€§åŒ–å’Œåœºæ™¯è¯­ä¹‰ä¸€è‡´æ€§æ–¹é¢å‡æœ‰æ˜æ˜¾æ”¹å–„ã€‚ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œç”¨æˆ·æ›´åå¥½DHumanDiffç”Ÿæˆçš„è‚–åƒï¼Œè®¤ä¸ºå…¶è§†è§‰è´¨é‡æ›´é«˜ï¼Œæ›´ç¬¦åˆä¸ªäººåå¥½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PairHumanæ•°æ®é›†å’ŒDHumanDiffæ¨¡å‹åœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚ï¼šæƒ…æ„Ÿè®°å¿†çš„ä¿å­˜ã€å©šç¤¼æ‘„å½±çš„è§„åˆ’ã€è™šæ‹Ÿå½¢è±¡çš„åˆ›å»ºã€ä»¥åŠä¸ªæ€§åŒ–å®šåˆ¶çš„è‰ºæœ¯åˆ›ä½œã€‚è¯¥ç ”ç©¶æˆæœèƒ½å¤Ÿæå‡åŒäººè‚–åƒç”Ÿæˆçš„è´¨é‡å’Œæ•ˆç‡ï¼Œä¸ºç”¨æˆ·æä¾›æ›´åŠ ä¾¿æ·å’Œä¸ªæ€§åŒ–çš„æœåŠ¡ï¼Œå¹¶æ¨åŠ¨ç›¸å…³äº§ä¸šçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Personalized dual-person portrait customization has considerable potential applications, such as preserving emotional memories and facilitating wedding photography planning. However, the absence of a benchmark dataset hinders the pursuit of high-quality customization in dual-person portrait generation. In this paper, we propose the PairHuman dataset, which is the first large-scale benchmark dataset specifically designed for generating dual-person portraits that meet high photographic standards. The PairHuman dataset contains more than 100K images that capture a variety of scenes, attire, and dual-person interactions, along with rich metadata, including detailed image descriptions, person localization, human keypoints, and attribute tags. We also introduce DHumanDiff, which is a baseline specifically crafted for dual-person portrait generation that features enhanced facial consistency and simultaneously balances in personalized person generation and semantic-driven scene creation. Finally, the experimental results demonstrate that our dataset and method produce highly customized portraits with superior visual quality that are tailored to human preferences. Our dataset is publicly available at https://github.com/annaoooo/PairHuman.

