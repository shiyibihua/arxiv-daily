---
layout: default
title: SAM 3: Segment Anything with Concepts
---

# SAM 3: Segment Anything with Concepts

**arXiv**: [2511.16719v1](https://arxiv.org/abs/2511.16719) | [PDF](https://arxiv.org/pdf/2511.16719.pdf)

**ä½œè€…**: Nicolas Carion, Laura Gustafson, Yuan-Ting Hu, Shoubhik Debnath, Ronghang Hu, Didac Suris, Chaitanya Ryali, Kalyan Vasudev Alwala, Haitham Khedr, Andrew Huang, Jie Lei, Tengyu Ma, Baishan Guo, Arpit Kalla, Markus Marks, Joseph Greer, Meng Wang, Peize Sun, Roman RÃ¤dle, Triantafyllos Afouras, Effrosyni Mavroudi, Katherine Xu, Tsung-Han Wu, Yu Zhou, Liliane Momeni, Rishi Hazra, Shuangrui Ding, Sagar Vaze, Francois Porcher, Feng Li, Siyuan Li, Aishwarya Kamath, Ho Kei Cheng, Piotr DollÃ¡r, Nikhila Ravi, Kate Saenko, Pengchuan Zhang, Christoph Feichtenhofer

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-20

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SAM 3ï¼šåŸºäºŽæ¦‚å¿µæç¤ºçš„å›¾åƒå’Œè§†é¢‘é€šç”¨åˆ†å‰²æ¨¡åž‹**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å›¾åƒåˆ†å‰²` `è§†é¢‘åˆ†å‰²` `æ¦‚å¿µæç¤º` `ç›®æ ‡æ£€æµ‹` `ç›®æ ‡è·Ÿè¸ª`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åˆ†å‰²æ¨¡åž‹åœ¨å¤„ç†å¤æ‚åœºæ™¯å’Œæ¦‚å¿µæç¤ºæ—¶å­˜åœ¨æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚
2. SAM 3é€šè¿‡å¼•å…¥æ¦‚å¿µæç¤ºï¼Œå¹¶ç»“åˆå›¾åƒçº§æ£€æµ‹å™¨å’Œè§†é¢‘è·Ÿè¸ªå™¨ï¼Œå®žçŽ°äº†æ›´ç²¾ç¡®çš„å¯¹è±¡åˆ†å‰²å’Œè·Ÿè¸ªã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒSAM 3åœ¨å›¾åƒå’Œè§†é¢‘PCSä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œç²¾åº¦æé«˜äº†ä¸€å€ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†Segment Anything Model (SAM) 3ï¼Œä¸€ä¸ªç»Ÿä¸€çš„æ¨¡åž‹ï¼Œèƒ½å¤ŸåŸºäºŽæ¦‚å¿µæç¤ºåœ¨å›¾åƒå’Œè§†é¢‘ä¸­æ£€æµ‹ã€åˆ†å‰²å’Œè·Ÿè¸ªå¯¹è±¡ã€‚æ¦‚å¿µæç¤ºè¢«å®šä¹‰ä¸ºç®€çŸ­çš„åè¯çŸ­è¯­ï¼ˆä¾‹å¦‚ï¼Œâ€œé»„è‰²æ ¡è½¦â€ï¼‰ã€å›¾åƒç¤ºä¾‹æˆ–ä¸¤è€…çš„ç»„åˆã€‚å¯æç¤ºçš„æ¦‚å¿µåˆ†å‰²ï¼ˆPCSï¼‰æŽ¥å—è¿™äº›æç¤ºï¼Œå¹¶è¿”å›žæ‰€æœ‰åŒ¹é…å¯¹è±¡å®žä¾‹çš„åˆ†å‰²æŽ©ç å’Œå”¯ä¸€èº«ä»½æ ‡è¯†ã€‚ä¸ºäº†æŽ¨è¿›PCSï¼Œæˆ‘ä»¬æž„å»ºäº†ä¸€ä¸ªå¯æ‰©å±•çš„æ•°æ®å¼•æ“Žï¼Œç”Ÿæˆäº†ä¸€ä¸ªé«˜è´¨é‡çš„æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å›¾åƒå’Œè§†é¢‘ä¸­400ä¸‡ä¸ªç‹¬ç‰¹çš„æ¦‚å¿µæ ‡ç­¾ï¼ŒåŒ…æ‹¬éš¾è´Ÿä¾‹ã€‚æˆ‘ä»¬çš„æ¨¡åž‹ç”±å›¾åƒçº§æ£€æµ‹å™¨å’ŒåŸºäºŽå†…å­˜çš„è§†é¢‘è·Ÿè¸ªå™¨ç»„æˆï¼Œå®ƒä»¬å…±äº«ä¸€ä¸ªéª¨å¹²ç½‘ç»œã€‚è¯†åˆ«å’Œå®šä½é€šè¿‡å­˜åœ¨å¤´è§£è€¦ï¼Œä»Žè€Œæé«˜äº†æ£€æµ‹ç²¾åº¦ã€‚SAM 3åœ¨å›¾åƒå’Œè§†é¢‘PCSä¸­çš„ç²¾åº¦æ˜¯çŽ°æœ‰ç³»ç»Ÿçš„ä¸¤å€ï¼Œå¹¶æé«˜äº†å…ˆå‰SAMåœ¨è§†è§‰åˆ†å‰²ä»»åŠ¡ä¸Šçš„èƒ½åŠ›ã€‚æˆ‘ä»¬å¼€æºäº†SAM 3ä»¥åŠæˆ‘ä»¬æ–°çš„ç”¨äºŽå¯æç¤ºæ¦‚å¿µåˆ†å‰²çš„Segment Anything with Concepts (SA-Co)åŸºå‡†ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰åˆ†å‰²æ¨¡åž‹éš¾ä»¥æ ¹æ®ç”¨æˆ·æä¾›çš„æ¦‚å¿µæ€§æç¤ºï¼ˆä¾‹å¦‚â€œæŸç§ç±»åž‹çš„ç‰©ä½“â€ï¼‰è¿›è¡Œç²¾ç¡®åˆ†å‰²ï¼Œå°¤å…¶æ˜¯åœ¨è§†é¢‘ä¸­è¿›è¡Œè·Ÿè¸ªæ—¶ï¼ŒæŒ‘æˆ˜æ›´å¤§ã€‚ä¹‹å‰çš„SAMæ¨¡åž‹è™½ç„¶å¼ºå¤§ï¼Œä½†åœ¨å¤„ç†æ¦‚å¿µæç¤ºå’Œè§†é¢‘åˆ†å‰²æ–¹é¢ä»æœ‰æå‡ç©ºé—´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSAM 3çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ¦‚å¿µæç¤ºï¼ˆæ–‡æœ¬æˆ–å›¾åƒï¼‰æ¥å¼•å¯¼åˆ†å‰²è¿‡ç¨‹ï¼Œå¹¶ç»“åˆå›¾åƒæ£€æµ‹å’Œè§†é¢‘è·Ÿè¸ªæŠ€æœ¯ï¼Œå®žçŽ°å¯¹å›¾åƒå’Œè§†é¢‘ä¸­ç‰¹å®šæ¦‚å¿µå¯¹è±¡çš„ç²¾ç¡®åˆ†å‰²å’Œè·Ÿè¸ªã€‚é€šè¿‡è§£è€¦è¯†åˆ«å’Œå®šä½ï¼Œå¹¶å¼•å…¥å­˜åœ¨å¤´ï¼Œæå‡æ£€æµ‹ç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šSAM 3åŒ…å«ä¸€ä¸ªå›¾åƒçº§æ£€æµ‹å™¨å’Œä¸€ä¸ªåŸºäºŽå†…å­˜çš„è§†é¢‘è·Ÿè¸ªå™¨ï¼Œä¸¤è€…å…±äº«ä¸€ä¸ªéª¨å¹²ç½‘ç»œã€‚å›¾åƒçº§æ£€æµ‹å™¨è´Ÿè´£æ£€æµ‹å›¾åƒä¸­çš„å¯¹è±¡ï¼Œå¹¶æ ¹æ®æ¦‚å¿µæç¤ºç”Ÿæˆåˆ†å‰²æŽ©ç ã€‚è§†é¢‘è·Ÿè¸ªå™¨åˆ™åˆ©ç”¨å†…å­˜æœºåˆ¶ï¼Œåœ¨è§†é¢‘å¸§ä¹‹é—´è·Ÿè¸ªå¯¹è±¡çš„èº«ä»½å’Œä½ç½®ã€‚å­˜åœ¨å¤´ç”¨äºŽåˆ¤æ–­å¯¹è±¡æ˜¯å¦å­˜åœ¨ï¼Œä»Žè€Œæé«˜æ£€æµ‹ç²¾åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šSAM 3çš„å…³é”®åˆ›æ–°åœ¨äºŽå¼•å…¥äº†æ¦‚å¿µæç¤ºä½œä¸ºåˆ†å‰²çš„å¼•å¯¼ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡åž‹æ¡†æž¶ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†å›¾åƒå’Œè§†é¢‘çš„åˆ†å‰²ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œé€šè¿‡è§£è€¦è¯†åˆ«å’Œå®šä½ï¼Œå¹¶å¼•å…¥å­˜åœ¨å¤´ï¼Œæé«˜äº†æ£€æµ‹ç²¾åº¦ã€‚å¤§è§„æ¨¡çš„æ¦‚å¿µæ ‡ç­¾æ•°æ®é›†ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„è´¡çŒ®ã€‚

**å…³é”®è®¾è®¡**ï¼šSAM 3ä½¿ç”¨äº†Transformerä½œä¸ºéª¨å¹²ç½‘ç»œï¼Œå¹¶è®¾è®¡äº†ä¸“é—¨çš„æŸå¤±å‡½æ•°æ¥è®­ç»ƒæ¨¡åž‹ã€‚æ¦‚å¿µæç¤ºè¢«ç¼–ç æˆå‘é‡ï¼Œå¹¶ç”¨äºŽæŒ‡å¯¼åˆ†å‰²è¿‡ç¨‹ã€‚è§†é¢‘è·Ÿè¸ªå™¨ä½¿ç”¨äº†å†…å­˜æœºåˆ¶æ¥å­˜å‚¨å’Œæ›´æ–°å¯¹è±¡çš„ç‰¹å¾ï¼Œä»Žè€Œå®žçŽ°å¯¹å¯¹è±¡çš„é•¿æœŸè·Ÿè¸ªã€‚å­˜åœ¨å¤´æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»å™¨ï¼Œç”¨äºŽåˆ¤æ–­å¯¹è±¡æ˜¯å¦å­˜åœ¨ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

SAM 3åœ¨å›¾åƒå’Œè§†é¢‘PCSä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç²¾åº¦æ˜¯çŽ°æœ‰ç³»ç»Ÿçš„ä¸¤å€ã€‚è¯¥æ¨¡åž‹åœ¨SA-CoåŸºå‡†æµ‹è¯•ä¸­è¡¨çŽ°å‡ºè‰²ï¼Œè¯æ˜Žäº†å…¶åœ¨å¯æç¤ºæ¦‚å¿µåˆ†å‰²æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚æ­¤å¤–ï¼ŒSAM 3è¿˜æé«˜äº†å…ˆå‰SAMåœ¨è§†è§‰åˆ†å‰²ä»»åŠ¡ä¸Šçš„èƒ½åŠ›ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶é€šç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

SAM 3åœ¨è‡ªåŠ¨é©¾é©¶ã€è§†é¢‘ç›‘æŽ§ã€åŒ»å­¦å›¾åƒåˆ†æžç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥åˆ©ç”¨SAM 3è¯†åˆ«å’Œè·Ÿè¸ªé“è·¯ä¸Šçš„è½¦è¾†ã€è¡Œäººç­‰ç›®æ ‡ã€‚åœ¨åŒ»å­¦å›¾åƒåˆ†æžä¸­ï¼Œå¯ä»¥ç”¨äºŽåˆ†å‰²å’Œè·Ÿè¸ªè‚¿ç˜¤ç­‰ç—…ç¶ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºŽæå‡è®¡ç®—æœºè§†è§‰ç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³ï¼Œå®žçŽ°æ›´ç²¾ç¡®ã€æ›´é«˜æ•ˆçš„å›¾åƒå’Œè§†é¢‘åˆ†æžã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present Segment Anything Model (SAM) 3, a unified model that detects, segments, and tracks objects in images and videos based on concept prompts, which we define as either short noun phrases (e.g., "yellow school bus"), image exemplars, or a combination of both. Promptable Concept Segmentation (PCS) takes such prompts and returns segmentation masks and unique identities for all matching object instances. To advance PCS, we build a scalable data engine that produces a high-quality dataset with 4M unique concept labels, including hard negatives, across images and videos. Our model consists of an image-level detector and a memory-based video tracker that share a single backbone. Recognition and localization are decoupled with a presence head, which boosts detection accuracy. SAM 3 doubles the accuracy of existing systems in both image and video PCS, and improves previous SAM capabilities on visual segmentation tasks. We open source SAM 3 along with our new Segment Anything with Concepts (SA-Co) benchmark for promptable concept segmentation.

