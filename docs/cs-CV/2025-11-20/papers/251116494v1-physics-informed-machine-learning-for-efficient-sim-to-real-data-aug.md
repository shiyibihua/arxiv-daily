---
layout: default
title: Physics-Informed Machine Learning for Efficient Sim-to-Real Data Augmentation in Micro-Object Pose Estimation
---

# Physics-Informed Machine Learning for Efficient Sim-to-Real Data Augmentation in Micro-Object Pose Estimation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.16494" target="_blank" class="toolbar-btn">arXiv: 2511.16494v1</a>
    <a href="https://arxiv.org/pdf/2511.16494.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.16494v1" 
            onclick="toggleFavorite(this, '2511.16494v1', 'Physics-Informed Machine Learning for Efficient Sim-to-Real Data Augmentation in Micro-Object Pose Estimation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Zongcai Tan, Lan Wei, Dandan Zhang

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-20

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Áâ©ÁêÜ‰ø°ÊÅØGANÔºåÁî®‰∫éÂæÆÂûãÁâ©‰Ωì‰ΩçÂßø‰º∞ËÆ°ÁöÑÈ´òÊïàSim-to-RealÊï∞ÊçÆÂ¢ûÂº∫**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Áâ©ÁêÜ‰ø°ÊÅØÊú∫Âô®Â≠¶‰π†` `Sim-to-Real` `Êï∞ÊçÆÂ¢ûÂº∫` `ÁîüÊàêÂØπÊäóÁΩëÁªú` `ÂæÆÂûãÊú∫Âô®‰∫∫` `‰ΩçÂßø‰º∞ËÆ°` `Ê≥¢Âä®ÂÖâÂ≠¶` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂæÆÂûãÊú∫Âô®‰∫∫‰ΩçÂßø‰º∞ËÆ°ÊñπÊ≥ï‰æùËµñÂ§ßÈáèÈ´òË¥®ÈáèÊòæÂæÆÂõæÂÉèÊï∞ÊçÆÔºåËé∑ÂèñÊàêÊú¨È´òÊòÇÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®„ÄÇ
2. ÊèêÂá∫‰∏ÄÁßçÁâ©ÁêÜ‰ø°ÊÅØGANÔºåÁªìÂêàÊ≥¢Âä®ÂÖâÂ≠¶Ê∏≤ÊüìÂíåÊ∑±Â∫¶ÂØπÈΩêÔºåÁîüÊàêÈ´ò‰øùÁúüÂêàÊàêÂõæÂÉèÔºåÁî®‰∫éSim-to-RealÊï∞ÊçÆÂ¢ûÂº∫„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÊòæËëóÊèêÂçáÂêàÊàêÂõæÂÉèË¥®ÈáèÂíå‰ΩçÂßø‰º∞ËÆ°Á≤æÂ∫¶ÔºåÂπ∂ÂÖ∑Â§áËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõÔºåÊó†ÈúÄÈ¢ùÂ§ñËÆ≠ÁªÉ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÁâ©ÁêÜ‰ø°ÊÅØÊ∑±Â∫¶ÁîüÊàêÂ≠¶‰π†Ê°ÜÊû∂ÔºåÈ¶ñÊ¨°Â∞ÜÂü∫‰∫éÊ≥¢Âä®ÂÖâÂ≠¶ÁöÑÁâ©ÁêÜÊ∏≤ÊüìÂíåÊ∑±Â∫¶ÂØπÈΩêÈõÜÊàêÂà∞ÁîüÊàêÂØπÊäóÁΩëÁªú(GAN)‰∏≠Ôºå‰ªéËÄåÈ´òÊïàÂú∞ÂêàÊàêÁî®‰∫éÂæÆÂûãÊú∫Âô®‰∫∫‰ΩçÂßø‰º∞ËÆ°ÁöÑÈ´ò‰øùÁúüÊòæÂæÆÈïúÂõæÂÉè„ÄÇ‰∏éÁ∫ØÁ≤πÁöÑAIÈ©±Âä®ÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÂ∞ÜÁªìÊûÑÁõ∏‰ººÊÄßÊåáÊï∞(SSIM)ÊèêÈ´ò‰∫Ü35.6%ÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÂÆûÊó∂Ê∏≤ÊüìÈÄüÂ∫¶(0.022Áßí/Â∏ß)„ÄÇÂú®ÂêàÊàêÊï∞ÊçÆ‰∏äËÆ≠ÁªÉÁöÑ‰ΩçÂßø‰º∞ËÆ°Âô®(CNN backbone)ËææÂà∞‰∫Ü93.9%/91.9% (pitch/roll)ÁöÑÂáÜÁ°ÆÁéáÔºå‰ªÖÊØîÂÆåÂÖ®Âú®ÁúüÂÆûÊï∞ÊçÆ‰∏äËÆ≠ÁªÉÁöÑ‰º∞ËÆ°Âô®‰Ωé5.0%/5.4% (pitch/roll)„ÄÇÊ≠§Â§ñÔºåËØ•Ê°ÜÊû∂ÂèØ‰ª•Êé®ÂπøÂà∞Êú™ËßÅËøáÁöÑÂßøÂäøÔºå‰ªéËÄå‰∏∫Êñ∞ÁöÑÂæÆÂûãÊú∫Âô®‰∫∫ÈÖçÁΩÆÂÆûÁé∞Êï∞ÊçÆÂ¢ûÂº∫ÂíåÈ≤ÅÊ£íÁöÑ‰ΩçÂßø‰º∞ËÆ°ÔºåËÄåÊó†ÈúÄÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂæÆÂûãÊú∫Âô®‰∫∫‰ΩçÂßø‰º∞ËÆ°‰∏≠ÔºåÁúüÂÆûÊòæÂæÆÂõæÂÉèÊï∞ÊçÆÈöæ‰ª•Ëé∑Âèñ‰∏îÊ†áÊ≥®ÊàêÊú¨È´òÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÂáÜÁ°ÆÊ®°ÊãüÂ§çÊùÇÁöÑÂÖâÂ≠¶ÊòæÂæÆÁé∞Ë±°ÔºåÂØºËá¥ÂêàÊàêÂõæÂÉèË¥®Èáè‰∏çÈ´òÔºåÂΩ±Âìç‰ΩçÂßø‰º∞ËÆ°ÁöÑÁ≤æÂ∫¶ÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÁâ©ÁêÜÊ®°ÂûãÔºàÊ≥¢Âä®ÂÖâÂ≠¶ÔºâËûçÂÖ•Âà∞Ê∑±Â∫¶ÁîüÊàêÊ®°ÂûãÔºàGANÔºâ‰∏≠ÔºåÂà©Áî®Áâ©ÁêÜÊ®°ÂûãÊåáÂØºÂõæÂÉèÁîüÊàêËøáÁ®ãÔºå‰ªéËÄåÁîüÊàêÊõ¥ÈÄºÁúüÁöÑÊòæÂæÆÂõæÂÉè„ÄÇÈÄöËøáSim-to-RealÁöÑÊï∞ÊçÆÂ¢ûÂº∫ÔºåÊèêÂçá‰ΩçÂßø‰º∞ËÆ°Ê®°ÂûãÂú®ÁúüÂÆûÊï∞ÊçÆ‰∏äÁöÑÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÊòØ‰∏Ä‰∏™Âü∫‰∫éGANÁöÑÁîüÊàêÊ®°ÂûãÔºåÂåÖÂê´ÁîüÊàêÂô®ÂíåÂà§Âà´Âô®„ÄÇÁîüÊàêÂô®Ë¥üË¥£Ê†πÊçÆËæìÂÖ•ÁöÑ‰ΩçÂßøÂèÇÊï∞ÂíåÁâ©ÁêÜÊ®°ÂûãÁîüÊàêÂêàÊàêÂõæÂÉèÔºåÂà§Âà´Âô®Ë¥üË¥£Âå∫ÂàÜÂêàÊàêÂõæÂÉèÂíåÁúüÂÆûÂõæÂÉè„ÄÇÊ≠§Â§ñÔºåÊ°ÜÊû∂ËøòÂºïÂÖ•‰∫ÜÊ∑±Â∫¶ÂØπÈΩêÊ®°ÂùóÔºåÁî®‰∫éÊ†°Ê≠£ÂêàÊàêÂõæÂÉèÁöÑÊ∑±Â∫¶‰ø°ÊÅØÔºå‰ΩøÂÖ∂Êõ¥Á¨¶ÂêàÁúüÂÆûÊòæÂæÆÂõæÂÉèÁöÑÁâπÁÇπ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÊ≥¢Âä®ÂÖâÂ≠¶Ê®°ÂûãÈõÜÊàêÂà∞GAN‰∏≠ÔºåÂÆûÁé∞‰∫ÜÁâ©ÁêÜ‰ø°ÊÅØÈ©±Âä®ÁöÑÂõæÂÉèÁîüÊàê„ÄÇ‰∏é‰º†ÁªüÁöÑÁ∫ØÊï∞ÊçÆÈ©±Âä®ÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊõ¥Â•ΩÂú∞Ê®°ÊãüÂ§çÊùÇÁöÑÂÖâÂ≠¶ÊòæÂæÆÁé∞Ë±°ÔºåÁîüÊàêÊõ¥È´òË¥®ÈáèÁöÑÂêàÊàêÂõæÂÉè„ÄÇÂêåÊó∂ÔºåÊ∑±Â∫¶ÂØπÈΩêÊ®°ÂùóÁöÑÂºïÂÖ•Ëøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÂêàÊàêÂõæÂÉèÁöÑÁúüÂÆûÊÑü„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÁîüÊàêÂô®ÁΩëÁªúÁªìÊûÑÈááÁî®U-NetÔºåÂà§Âà´Âô®ÁΩëÁªúÁªìÊûÑÈááÁî®PatchGAN„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨GANÊçüÂ§±„ÄÅÁâ©ÁêÜÊ®°ÂûãÊçüÂ§±ÂíåÊ∑±Â∫¶ÂØπÈΩêÊçüÂ§±„ÄÇÁâ©ÁêÜÊ®°ÂûãÊçüÂ§±Áî®‰∫éÁ∫¶ÊùüÁîüÊàêÂõæÂÉèÁ¨¶ÂêàÊ≥¢Âä®ÂÖâÂ≠¶ËßÑÂæã„ÄÇÊ∑±Â∫¶ÂØπÈΩêÊçüÂ§±Áî®‰∫éÁ∫¶ÊùüÂêàÊàêÂõæÂÉèÁöÑÊ∑±Â∫¶‰ø°ÊÅØ‰∏éÁúüÂÆûÂõæÂÉè‰∏ÄËá¥„ÄÇËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÈááÁî®ÂØπÊäóËÆ≠ÁªÉÁöÑÊñπÂºè‰ºòÂåñÁîüÊàêÂô®ÂíåÂà§Âà´Âô®„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÁîüÊàêÁöÑÂêàÊàêÂõæÂÉèÂú®ÁªìÊûÑÁõ∏‰ººÊÄßÊåáÊï∞(SSIM)‰∏äÊØîÁ∫ØAIÈ©±Âä®ÊñπÊ≥ïÊèêÈ´ò‰∫Ü35.6%ÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÂÆûÊó∂Ê∏≤ÊüìÈÄüÂ∫¶(0.022Áßí/Â∏ß)„ÄÇ‰ΩøÁî®ÂêàÊàêÊï∞ÊçÆËÆ≠ÁªÉÁöÑ‰ΩçÂßø‰º∞ËÆ°Âô®Âú®pitch/roll‰∏äÁöÑÂáÜÁ°ÆÁéáÂàÜÂà´ËææÂà∞93.9%/91.9%Ôºå‰ªÖÊØîÂú®ÁúüÂÆûÊï∞ÊçÆ‰∏äËÆ≠ÁªÉÁöÑ‰º∞ËÆ°Âô®‰Ωé5.0%/5.4%„ÄÇËØ•Ê°ÜÊû∂ËøòÂ±ïÁé∞Âá∫ËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõÔºåËÉΩÂ§üÂ§ÑÁêÜÊú™ËßÅËøáÁöÑÂßøÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂÖâÂ≠¶ÂæÆÂûãÊú∫Âô®‰∫∫ÁöÑÁ≤æÁ°ÆË∑üË∏™„ÄÅËá™‰∏ªÁîüÁâ©Â≠¶Á†îÁ©∂„ÄÅÈ´òÁ≤æÂ∫¶ÂæÆÊìç‰ΩúÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÈôç‰ΩéÂØπÁúüÂÆûÊï∞ÊçÆÁöÑ‰æùËµñÔºåÂèØ‰ª•Âä†ÈÄüÂæÆÂûãÊú∫Âô®‰∫∫ÊäÄÊúØÁöÑÁ†îÂèëÂíåÂ∫îÁî®ÔºåÂπ∂‰∏∫Áõ∏ÂÖ≥È¢ÜÂüüÁöÑËá™Âä®ÂåñÂíåÊô∫ËÉΩÂåñÊèê‰æõÊúâÂäõÊîØÊåÅ„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÊé®ÂπøÂà∞ÂÖ∂‰ªñÈúÄË¶ÅSim-to-RealÊï∞ÊçÆÂ¢ûÂº∫ÁöÑËßÜËßâ‰ªªÂä°‰∏≠„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Precise pose estimation of optical microrobots is essential for enabling high-precision object tracking and autonomous biological studies. However, current methods rely heavily on large, high-quality microscope image datasets, which are difficult and costly to acquire due to the complexity of microrobot fabrication and the labour-intensive labelling. Digital twin systems offer a promising path for sim-to-real data augmentation, yet existing techniques struggle to replicate complex optical microscopy phenomena, such as diffraction artifacts and depth-dependent imaging.This work proposes a novel physics-informed deep generative learning framework that, for the first time, integrates wave optics-based physical rendering and depth alignment into a generative adversarial network (GAN), to synthesise high-fidelity microscope images for microrobot pose estimation efficiently. Our method improves the structural similarity index (SSIM) by 35.6% compared to purely AI-driven methods, while maintaining real-time rendering speeds (0.022 s/frame).The pose estimator (CNN backbone) trained on our synthetic data achieves 93.9%/91.9% (pitch/roll) accuracy, just 5.0%/5.4% (pitch/roll) below that of an estimator trained exclusively on real data. Furthermore, our framework generalises to unseen poses, enabling data augmentation and robust pose estimation for novel microrobot configurations without additional training data.

