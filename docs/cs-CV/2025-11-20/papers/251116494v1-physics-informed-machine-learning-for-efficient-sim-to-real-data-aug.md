---
layout: default
title: Physics-Informed Machine Learning for Efficient Sim-to-Real Data Augmentation in Micro-Object Pose Estimation
---

# Physics-Informed Machine Learning for Efficient Sim-to-Real Data Augmentation in Micro-Object Pose Estimation

**arXiv**: [2511.16494v1](https://arxiv.org/abs/2511.16494) | [PDF](https://arxiv.org/pdf/2511.16494.pdf)

**ä½œè€…**: Zongcai Tan, Lan Wei, Dandan Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç‰©ç†ä¿¡æ¯ç”Ÿæˆå¯¹æŠ—ç½‘ç»œä»¥é«˜æ•ˆå¢žå¼ºå¾®ç‰©ä½“å§¿æ€ä¼°è®¡çš„æ¨¡æ‹Ÿåˆ°çœŸå®žæ•°æ®**

**å…³é”®è¯**: `ç‰©ç†ä¿¡æ¯æœºå™¨å­¦ä¹ ` `æ¨¡æ‹Ÿåˆ°çœŸå®žæ•°æ®å¢žå¼º` `å¾®ç‰©ä½“å§¿æ€ä¼°è®¡` `ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ` `æ³¢å…‰å­¦æ¸²æŸ“`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¾®ç‰©ä½“å§¿æ€ä¼°è®¡ä¾èµ–é«˜è´¨é‡æ˜¾å¾®é•œå›¾åƒï¼Œä½†æ•°æ®èŽ·å–å›°éš¾ä¸”æˆæœ¬é«˜
2. é›†æˆæ³¢å…‰å­¦ç‰©ç†æ¸²æŸ“å’Œæ·±åº¦å¯¹é½åˆ°GANï¼Œåˆæˆé«˜ä¿çœŸå›¾åƒ
3. åˆæˆæ•°æ®è®­ç»ƒçš„å§¿æ€ä¼°è®¡å™¨ç²¾åº¦æŽ¥è¿‘çœŸå®žæ•°æ®ï¼Œæ³›åŒ–åˆ°æœªçŸ¥å§¿æ€

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Precise pose estimation of optical microrobots is essential for enabling high-precision object tracking and autonomous biological studies. However, current methods rely heavily on large, high-quality microscope image datasets, which are difficult and costly to acquire due to the complexity of microrobot fabrication and the labour-intensive labelling. Digital twin systems offer a promising path for sim-to-real data augmentation, yet existing techniques struggle to replicate complex optical microscopy phenomena, such as diffraction artifacts and depth-dependent imaging.This work proposes a novel physics-informed deep generative learning framework that, for the first time, integrates wave optics-based physical rendering and depth alignment into a generative adversarial network (GAN), to synthesise high-fidelity microscope images for microrobot pose estimation efficiently. Our method improves the structural similarity index (SSIM) by 35.6% compared to purely AI-driven methods, while maintaining real-time rendering speeds (0.022 s/frame).The pose estimator (CNN backbone) trained on our synthetic data achieves 93.9%/91.9% (pitch/roll) accuracy, just 5.0%/5.4% (pitch/roll) below that of an estimator trained exclusively on real data. Furthermore, our framework generalises to unseen poses, enabling data augmentation and robust pose estimation for novel microrobot configurations without additional training data.

