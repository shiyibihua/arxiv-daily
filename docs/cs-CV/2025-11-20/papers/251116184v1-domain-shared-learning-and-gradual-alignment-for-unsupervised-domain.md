---
layout: default
title: Domain-Shared Learning and Gradual Alignment for Unsupervised Domain Adaptation Visible-Infrared Person Re-Identification
---

# Domain-Shared Learning and Gradual Alignment for Unsupervised Domain Adaptation Visible-Infrared Person Re-Identification

**arXiv**: [2511.16184v1](https://arxiv.org/abs/2511.16184) | [PDF](https://arxiv.org/pdf/2511.16184.pdf)

**ä½œè€…**: Nianchang Huang, Yi Xu, Ruida Xi, Ruida Xi, Qiang Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDSLGAæ¨¡åž‹ä»¥è§£å†³æ— ç›‘ç£åŸŸè‡ªé€‚åº”å¯è§å…‰-çº¢å¤–è¡Œäººé‡è¯†åˆ«ä¸­çš„æ¨¡æ€å·®å¼‚é—®é¢˜**

**å…³é”®è¯**: `æ— ç›‘ç£åŸŸè‡ªé€‚åº”` `å¯è§å…‰-çº¢å¤–è¡Œäººé‡è¯†åˆ«` `æ¨¡æ€å·®å¼‚å¯¹é½` `ä¸¤é˜¶æ®µå­¦ä¹ ` `è·¨æ¨¡æ€å¯¹é½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¯è§å…‰ä¸Žçº¢å¤–æ•°æ®é—´å­˜åœ¨åŸŸé—´å’ŒåŸŸå†…æ¨¡æ€å·®å¼‚ï¼Œå½±å“æ¨¡åž‹æ³›åŒ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä¸¤é˜¶æ®µç­–ç•¥ï¼Œå…ˆé¢„è®­ç»ƒå…±äº«ä¿¡æ¯ï¼Œå†é€æ­¥å¯¹é½è·¨æ¨¡æ€æ•°æ®ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šç§è®¾ç½®ä¸‹æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰åŸŸè‡ªé€‚åº”æ–¹æ³•ï¼Œç”šè‡³éƒ¨åˆ†ç›‘ç£æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recently, Visible-Infrared person Re-Identification (VI-ReID) has achieved remarkable performance on public datasets. However, due to the discrepancies between public datasets and real-world data, most existing VI-ReID algorithms struggle in real-life applications. To address this, we take the initiative to investigate Unsupervised Domain Adaptation Visible-Infrared person Re-Identification (UDA-VI-ReID), aiming to transfer the knowledge learned from the public data to real-world data without compromising accuracy and requiring the annotation of new samples. Specifically, we first analyze two basic challenges in UDA-VI-ReID, i.e., inter-domain modality discrepancies and intra-domain modality discrepancies. Then, we design a novel two-stage model, i.e., Domain-Shared Learning and Gradual Alignment (DSLGA), to handle these discrepancies. In the first pre-training stage, DSLGA introduces a Domain-Shared Learning Strategy (DSLS) to mitigate ineffective pre-training caused by inter-domain modality discrepancies via exploiting shared information between the source and target domains. While, in the second fine-tuning stage, DSLGA designs a Gradual Alignment Strategy (GAS) to handle the cross-modality alignment challenges between visible and infrared data caused by the large intra-domain modality discrepancies through a cluster-to-holistic alignment way. Finally, a new UDA-VI-ReID testing method i.e., CMDA-XD, is constructed for training and testing different UDA-VI-ReID models. A large amount of experiments demonstrate that our method significantly outperforms existing domain adaptation methods for VI-ReID and even some supervised methods under various settings.

