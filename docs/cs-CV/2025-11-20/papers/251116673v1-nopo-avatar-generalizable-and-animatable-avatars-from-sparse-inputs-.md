---
layout: default
title: NoPo-Avatar: Generalizable and Animatable Avatars from Sparse Inputs without Human Poses
---

# NoPo-Avatar: Generalizable and Animatable Avatars from Sparse Inputs without Human Poses

**arXiv**: [2511.16673v1](https://arxiv.org/abs/2511.16673) | [PDF](https://arxiv.org/pdf/2511.16673.pdf)

**ä½œè€…**: Jing Wen, Alexander G. Schwing, Shenlong Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNoPo-Avatarä»Žç¨€ç–å›¾åƒé‡å»ºå¯åŠ¨ç”»3Däººä½“åŒ–èº«ï¼Œæ— éœ€äººä½“å§¿æ€è¾“å…¥**

**å…³é”®è¯**: `3Däººä½“é‡å»º` `å¯åŠ¨ç”»åŒ–èº«` `ç¨€ç–å›¾åƒè¾“å…¥` `å§¿æ€æ— å…³æ–¹æ³•` `é²æ£’æ€§æå‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä»Žå•å¼ æˆ–ç¨€ç–å›¾åƒé‡å»ºå¯åŠ¨ç”»3Däººä½“åŒ–èº«ï¼Œä¾èµ–å§¿æ€è¾“å…¥æ˜“å—å™ªå£°å½±å“
2. æ–¹æ³•è¦ç‚¹ï¼šä»…ä½¿ç”¨å›¾åƒè¾“å…¥ï¼Œæ¶ˆé™¤æµ‹è¯•æ—¶å¯¹äººä½“å§¿æ€çš„ä¾èµ–ï¼Œæå‡é²æ£’æ€§
3. å®žéªŒæ•ˆæžœï¼šåœ¨THuman2.0ç­‰æ•°æ®é›†ä¸Šï¼Œæ— å§¿æ€è¾“å…¥æ—¶ä¼˜äºŽåŸºçº¿ï¼Œæœ‰å§¿æ€æ—¶ç»“æžœç›¸å½“

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We tackle the task of recovering an animatable 3D human avatar from a single or a sparse set of images. For this task, beyond a set of images, many prior state-of-the-art methods use accurate "ground-truth" camera poses and human poses as input to guide reconstruction at test-time. We show that pose-dependent reconstruction degrades results significantly if pose estimates are noisy. To overcome this, we introduce NoPo-Avatar, which reconstructs avatars solely from images, without any pose input. By removing the dependence of test-time reconstruction on human poses, NoPo-Avatar is not affected by noisy human pose estimates, making it more widely applicable. Experiments on challenging THuman2.0, XHuman, and HuGe100K data show that NoPo-Avatar outperforms existing baselines in practical settings (without ground-truth poses) and delivers comparable results in lab settings (with ground-truth poses).

