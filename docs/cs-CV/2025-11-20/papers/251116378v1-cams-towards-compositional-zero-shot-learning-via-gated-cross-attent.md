---
layout: default
title: CAMS: Towards Compositional Zero-Shot Learning via Gated Cross-Attention and Multi-Space Disentanglement
---

# CAMS: Towards Compositional Zero-Shot Learning via Gated Cross-Attention and Multi-Space Disentanglement

**arXiv**: [2511.16378v1](https://arxiv.org/abs/2511.16378) | [PDF](https://arxiv.org/pdf/2511.16378.pdf)

**ä½œè€…**: Pan Yang, Cheng Deng, Jing Yang, Han Zhao, Yun Liu, Yuling Chen, Xiaoli Ruan, Yanping Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCAMSæ–¹æ³•ï¼Œé€šè¿‡é—¨æŽ§äº¤å‰æ³¨æ„åŠ›å’Œå¤šç©ºé—´è§£è€¦æ”¹è¿›ç»„åˆé›¶æ ·æœ¬å­¦ä¹ ã€‚**

**å…³é”®è¯**: `ç»„åˆé›¶æ ·æœ¬å­¦ä¹ ` `é—¨æŽ§äº¤å‰æ³¨æ„åŠ›` `å¤šç©ºé—´è§£è€¦` `è¯­ä¹‰ç‰¹å¾æå–` `CLIPæ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç»„åˆé›¶æ ·æœ¬å­¦ä¹ ä¸­ï¼Œå…¨å±€è¯­ä¹‰è¡¨ç¤ºèƒ½åŠ›æœ‰é™ï¼Œéš¾ä»¥å®Œå…¨è§£è€¦å±žæ€§å’Œå¯¹è±¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨é—¨æŽ§äº¤å‰æ³¨æ„åŠ›æå–ç»†ç²’åº¦è¯­ä¹‰ç‰¹å¾ï¼Œå¹¶åœ¨å¤šç©ºé—´è¿›è¡Œè¯­ä¹‰è§£è€¦ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨MIT-Statesç­‰åŸºå‡†æµ‹è¯•ä¸­ï¼Œé—­é›†å’Œå¼€é›†è®¾ç½®ä¸‹å‡è¾¾åˆ°æœ€ä¼˜æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Compositional zero-shot learning (CZSL) aims to learn the concepts of attributes and objects in seen compositions and to recognize their unseen compositions. Most Contrastive Language-Image Pre-training (CLIP)-based CZSL methods focus on disentangling attributes and objects by leveraging the global semantic representation obtained from the image encoder. However, this representation has limited representational capacity and do not allow for complete disentanglement of the two. To this end, we propose CAMS, which aims to extract semantic features from visual features and perform semantic disentanglement in multidimensional spaces, thereby improving generalization over unseen attribute-object compositions. Specifically, CAMS designs a Gated Cross-Attention that captures fine-grained semantic features from the high-level image encoding blocks of CLIP through a set of latent units, while adaptively suppressing background and other irrelevant information. Subsequently, it conducts Multi-Space Disentanglement to achieve disentanglement of attribute and object semantics. Experiments on three popular benchmarks (MIT-States, UT-Zappos, and C-GQA) demonstrate that CAMS achieves state-of-the-art performance in both closed-world and open-world settings. The code is available at https://github.com/ybyangjing/CAMS.

