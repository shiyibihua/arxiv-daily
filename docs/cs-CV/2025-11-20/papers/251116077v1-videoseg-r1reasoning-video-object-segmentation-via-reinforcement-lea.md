---
layout: default
title: VideoSeg-R1:Reasoning Video Object Segmentation via Reinforcement Learning
---

# VideoSeg-R1:Reasoning Video Object Segmentation via Reinforcement Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.16077" target="_blank" class="toolbar-btn">arXiv: 2511.16077v1</a>
    <a href="https://arxiv.org/pdf/2511.16077.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.16077v1" 
            onclick="toggleFavorite(this, '2511.16077v1', 'VideoSeg-R1:Reasoning Video Object Segmentation via Reinforcement Learning')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Zishan Xu, Yifu Guo, Yuquan Lu, Fengyu Yang, Junxin Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-20

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/euyis1019/VideoSeg-R1)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVideoSeg-R1ï¼Œé¦–ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„è§†é¢‘æ¨ç†åˆ†å‰²æ¡†æ¶ï¼Œæå‡å¤æ‚åœºæ™¯æ³›åŒ–æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†é¢‘æ¨ç†åˆ†å‰²` `å¼ºåŒ–å­¦ä¹ ` `è§†é¢‘ç†è§£` `ç›®æ ‡åˆ†å‰²` `æ˜¾å¼æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿè§†é¢‘æ¨ç†åˆ†å‰²æ–¹æ³•ä¾èµ–æœ‰ç›‘ç£å¾®è°ƒï¼Œæ³›åŒ–æ€§å—é™ï¼Œç¼ºä¹æ˜¾å¼æ¨ç†ã€‚
2. VideoSeg-R1é‡‡ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œè§£è€¦æŒ‡ä»£å›¾åƒåˆ†å‰²å’Œæ©ç ä¼ æ’­ï¼Œå®ç°æ˜¾å¼æ¨ç†ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVideoSeg-R1åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°SOTAï¼Œæå‡å¤æ‚åœºæ™¯æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºVideoSeg-R1ï¼Œé¦–ä¸ªå°†å¼ºåŒ–å­¦ä¹ å¼•å…¥è§†é¢‘æ¨ç†åˆ†å‰²çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨è§£è€¦æ¶æ„ï¼Œå°†ä»»åŠ¡åˆ†è§£ä¸ºè”åˆæŒ‡ä»£å›¾åƒåˆ†å‰²å’Œè§†é¢‘æ©ç ä¼ æ’­ã€‚å®ƒåŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼šï¼ˆ1ï¼‰åˆ†å±‚æ–‡æœ¬å¼•å¯¼çš„å¸§é‡‡æ ·å™¨ï¼Œæ¨¡æ‹Ÿäººç±»æ³¨æ„åŠ›ï¼›ï¼ˆ2ï¼‰æ¨ç†æ¨¡å‹ï¼Œäº§ç”Ÿç©ºé—´çº¿ç´¢ä»¥åŠæ˜¾å¼æ¨ç†é“¾ï¼›ï¼ˆ3ï¼‰ä½¿ç”¨SAM2å’ŒXMemçš„åˆ†å‰²-ä¼ æ’­é˜¶æ®µã€‚ä¸€ç§ä»»åŠ¡éš¾åº¦æ„ŸçŸ¥æœºåˆ¶è‡ªé€‚åº”åœ°æ§åˆ¶æ¨ç†é•¿åº¦ï¼Œä»¥è·å¾—æ›´å¥½çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡è¯„ä¼°è¡¨æ˜ï¼ŒVideoSeg-R1åœ¨å¤æ‚çš„è§†é¢‘æ¨ç†å’Œåˆ†å‰²ä»»åŠ¡ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä»£ç å°†åœ¨https://github.com/euyis1019/VideoSeg-R1ä¸Šå…¬å¼€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†é¢‘æ¨ç†åˆ†å‰²æ–¹æ³•ä¸»è¦ä¾èµ–äºæœ‰ç›‘ç£çš„å¾®è°ƒï¼Œè¿™å¯¼è‡´æ¨¡å‹åœ¨é¢å¯¹åˆ†å¸ƒå¤–ï¼ˆout-of-distributionï¼‰çš„åœºæ™¯æ—¶æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ç¼ºä¹æ˜¾å¼çš„æ¨ç†è¿‡ç¨‹ï¼Œéš¾ä»¥è§£é‡Šæ¨¡å‹çš„å†³ç­–ä¾æ®ã€‚å› æ­¤ï¼Œå¦‚ä½•æé«˜æ¨¡å‹åœ¨å¤æ‚è§†é¢‘åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä½¿å…¶å…·å¤‡å¯è§£é‡Šçš„æ¨ç†èƒ½åŠ›ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVideoSeg-R1çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è§†é¢‘æ¨ç†åˆ†å‰²ä»»åŠ¡å»ºæ¨¡ä¸ºä¸€ä¸ªå¼ºåŒ–å­¦ä¹ é—®é¢˜ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°å¦‚ä½•åœ¨è§†é¢‘ä¸­è¿›è¡Œæœ‰æ•ˆçš„æ¨ç†ï¼Œå¹¶ç”Ÿæˆå‡†ç¡®çš„åˆ†å‰²æ©ç ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚åŒæ—¶ï¼Œæ˜¾å¼çš„æ¨ç†é“¾ä½¿å¾—æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹æ›´åŠ é€æ˜å’Œå¯è§£é‡Šã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVideoSeg-R1çš„æ•´ä½“æ¶æ„åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šï¼ˆ1ï¼‰**åˆ†å±‚æ–‡æœ¬å¼•å¯¼çš„å¸§é‡‡æ ·å™¨**ï¼šè¯¥æ¨¡å—æ¨¡æ‹Ÿäººç±»çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ ¹æ®æ–‡æœ¬æè¿°é€‰æ‹©è§†é¢‘ä¸­ç›¸å…³çš„å¸§ï¼Œä»¥å‡å°‘è®¡ç®—è´Ÿæ‹…å¹¶æé«˜æ¨ç†æ•ˆç‡ã€‚ï¼ˆ2ï¼‰**æ¨ç†æ¨¡å‹**ï¼šè¯¥æ¨¡å—åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç”Ÿæˆç©ºé—´çº¿ç´¢å’Œæ˜¾å¼æ¨ç†é“¾ï¼ŒæŒ‡å¯¼åç»­çš„åˆ†å‰²è¿‡ç¨‹ã€‚ï¼ˆ3ï¼‰**åˆ†å‰²-ä¼ æ’­é˜¶æ®µ**ï¼šè¯¥æ¨¡å—åˆ©ç”¨SAM2å’ŒXMemç­‰å…ˆè¿›çš„åˆ†å‰²æ¨¡å‹ï¼Œæ ¹æ®æ¨ç†æ¨¡å‹æä¾›çš„çº¿ç´¢ï¼Œç”Ÿæˆæœ€ç»ˆçš„åˆ†å‰²æ©ç ï¼Œå¹¶å°†å…¶ä¼ æ’­åˆ°æ•´ä¸ªè§†é¢‘åºåˆ—ã€‚

**å…³é”®åˆ›æ–°**ï¼šVideoSeg-R1æœ€å…³é”®çš„åˆ›æ–°åœ¨äºå°†å¼ºåŒ–å­¦ä¹ å¼•å…¥è§†é¢‘æ¨ç†åˆ†å‰²ä»»åŠ¡ã€‚ä¸ä¼ ç»Ÿçš„æœ‰ç›‘ç£æ–¹æ³•ä¸åŒï¼ŒVideoSeg-R1é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿè‡ªä¸»åœ°å­¦ä¹ æ¨ç†ç­–ç•¥ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚æ­¤å¤–ï¼Œæ˜¾å¼çš„æ¨ç†é“¾ä½¿å¾—æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹æ›´åŠ é€æ˜å’Œå¯è§£é‡Šï¼Œè¿™å¯¹äºå®é™…åº”ç”¨éå¸¸é‡è¦ã€‚

**å…³é”®è®¾è®¡**ï¼šVideoSeg-R1çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) **ä»»åŠ¡éš¾åº¦æ„ŸçŸ¥æœºåˆ¶**ï¼šè¯¥æœºåˆ¶æ ¹æ®è§†é¢‘çš„å¤æ‚ç¨‹åº¦è‡ªé€‚åº”åœ°è°ƒæ•´æ¨ç†é•¿åº¦ï¼Œä»¥åœ¨æ•ˆç‡å’Œå‡†ç¡®æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚(2) **åˆ†å±‚æ–‡æœ¬å¼•å¯¼çš„å¸§é‡‡æ ·å™¨**ï¼šé€šè¿‡åˆ†å±‚é‡‡æ ·ï¼Œæ¨¡å‹å¯ä»¥æ›´æœ‰æ•ˆåœ°é€‰æ‹©ä¸æ–‡æœ¬æè¿°ç›¸å…³çš„å¸§ï¼Œä»è€Œæé«˜æ¨ç†çš„å‡†ç¡®æ€§ã€‚(3) **å¼ºåŒ–å­¦ä¹ å¥–åŠ±å‡½æ•°**ï¼šå¥–åŠ±å‡½æ•°çš„è®¾è®¡è‡³å…³é‡è¦ï¼Œå®ƒç›´æ¥å½±å“æ¨¡å‹çš„å­¦ä¹ æ•ˆæœã€‚è®ºæ–‡ä¸­å¯èƒ½é‡‡ç”¨äº†åŸºäºåˆ†å‰²å‡†ç¡®ç‡å’Œæ¨ç†æ•ˆç‡çš„å¥–åŠ±å‡½æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VideoSeg-R1åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å¤æ‚è§†é¢‘æ¨ç†å’Œåˆ†å‰²ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥å¼ºåŒ–å­¦ä¹ å’Œæ˜¾å¼æ¨ç†é“¾ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VideoSeg-R1åœ¨è§†é¢‘ç¼–è¾‘ã€æ™ºèƒ½ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œåœ¨è§†é¢‘ç¼–è¾‘ä¸­ï¼Œå¯ä»¥æ ¹æ®æ–‡æœ¬æè¿°è‡ªåŠ¨åˆ†å‰²è§†é¢‘ä¸­çš„ç›®æ ‡å¯¹è±¡ï¼Œæ–¹ä¾¿ç”¨æˆ·è¿›è¡Œç¼–è¾‘å’Œç‰¹æ•ˆå¤„ç†ã€‚åœ¨æ™ºèƒ½ç›‘æ§ä¸­ï¼Œå¯ä»¥è‡ªåŠ¨è¯†åˆ«å’Œè·Ÿè¸ªè§†é¢‘ä¸­çš„å¯ç–‘ç›®æ ‡ï¼Œæé«˜ç›‘æ§æ•ˆç‡ã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥å‡†ç¡®åˆ†å‰²é“è·¯ä¸Šçš„è½¦è¾†ã€è¡Œäººç­‰ç›®æ ‡ï¼Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Traditional video reasoning segmentation methods rely on supervised fine-tuning, which limits generalization to out-of-distribution scenarios and lacks explicit reasoning. To address this, we propose \textbf{VideoSeg-R1}, the first framework to introduce reinforcement learning into video reasoning segmentation. It adopts a decoupled architecture that formulates the task as joint referring image segmentation and video mask propagation. It comprises three stages: (1) A hierarchical text-guided frame sampler to emulate human attention; (2) A reasoning model that produces spatial cues along with explicit reasoning chains; and (3) A segmentation-propagation stage using SAM2 and XMem. A task difficulty-aware mechanism adaptively controls reasoning length for better efficiency and accuracy. Extensive evaluations on multiple benchmarks demonstrate that VideoSeg-R1 achieves state-of-the-art performance in complex video reasoning and segmentation tasks. The code will be publicly available at https://github.com/euyis1019/VideoSeg-R1.

