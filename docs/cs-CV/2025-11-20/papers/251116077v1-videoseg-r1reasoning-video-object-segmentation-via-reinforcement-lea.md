---
layout: default
title: VideoSeg-R1:Reasoning Video Object Segmentation via Reinforcement Learning
---

# VideoSeg-R1:Reasoning Video Object Segmentation via Reinforcement Learning

**arXiv**: [2511.16077v1](https://arxiv.org/abs/2511.16077) | [PDF](https://arxiv.org/pdf/2511.16077.pdf)

**ä½œè€…**: Zishan Xu, Yifu Guo, Yuquan Lu, Fengyu Yang, Junxin Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-20

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/euyis1019/VideoSeg-R1)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVideoSeg-R1ï¼Œé¦–ä¸ªåŸºäºŽå¼ºåŒ–å­¦ä¹ çš„è§†é¢‘æŽ¨ç†åˆ†å‰²æ¡†æž¶ï¼Œæå‡å¤æ‚åœºæ™¯æ³›åŒ–æ€§ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è§†é¢‘æŽ¨ç†åˆ†å‰²` `å¼ºåŒ–å­¦ä¹ ` `è§†é¢‘ç†è§£` `ç›®æ ‡åˆ†å‰²` `æ˜¾å¼æŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿè§†é¢‘æŽ¨ç†åˆ†å‰²æ–¹æ³•ä¾èµ–æœ‰ç›‘ç£å¾®è°ƒï¼Œæ³›åŒ–æ€§å—é™ï¼Œç¼ºä¹æ˜¾å¼æŽ¨ç†ã€‚
2. VideoSeg-R1é‡‡ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œè§£è€¦æŒ‡ä»£å›¾åƒåˆ†å‰²å’ŒæŽ©ç ä¼ æ’­ï¼Œå®žçŽ°æ˜¾å¼æŽ¨ç†ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒVideoSeg-R1åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°SOTAï¼Œæå‡å¤æ‚åœºæ™¯æ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºVideoSeg-R1ï¼Œé¦–ä¸ªå°†å¼ºåŒ–å­¦ä¹ å¼•å…¥è§†é¢‘æŽ¨ç†åˆ†å‰²çš„æ¡†æž¶ã€‚è¯¥æ¡†æž¶é‡‡ç”¨è§£è€¦æž¶æž„ï¼Œå°†ä»»åŠ¡åˆ†è§£ä¸ºè”åˆæŒ‡ä»£å›¾åƒåˆ†å‰²å’Œè§†é¢‘æŽ©ç ä¼ æ’­ã€‚å®ƒåŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼šï¼ˆ1ï¼‰åˆ†å±‚æ–‡æœ¬å¼•å¯¼çš„å¸§é‡‡æ ·å™¨ï¼Œæ¨¡æ‹Ÿäººç±»æ³¨æ„åŠ›ï¼›ï¼ˆ2ï¼‰æŽ¨ç†æ¨¡åž‹ï¼Œäº§ç”Ÿç©ºé—´çº¿ç´¢ä»¥åŠæ˜¾å¼æŽ¨ç†é“¾ï¼›ï¼ˆ3ï¼‰ä½¿ç”¨SAM2å’ŒXMemçš„åˆ†å‰²-ä¼ æ’­é˜¶æ®µã€‚ä¸€ç§ä»»åŠ¡éš¾åº¦æ„ŸçŸ¥æœºåˆ¶è‡ªé€‚åº”åœ°æŽ§åˆ¶æŽ¨ç†é•¿åº¦ï¼Œä»¥èŽ·å¾—æ›´å¥½çš„æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡è¯„ä¼°è¡¨æ˜Žï¼ŒVideoSeg-R1åœ¨å¤æ‚çš„è§†é¢‘æŽ¨ç†å’Œåˆ†å‰²ä»»åŠ¡ä¸­å®žçŽ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä»£ç å°†åœ¨https://github.com/euyis1019/VideoSeg-R1ä¸Šå…¬å¼€ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰è§†é¢‘æŽ¨ç†åˆ†å‰²æ–¹æ³•ä¸»è¦ä¾èµ–äºŽæœ‰ç›‘ç£çš„å¾®è°ƒï¼Œè¿™å¯¼è‡´æ¨¡åž‹åœ¨é¢å¯¹åˆ†å¸ƒå¤–ï¼ˆout-of-distributionï¼‰çš„åœºæ™¯æ—¶æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ç¼ºä¹æ˜¾å¼çš„æŽ¨ç†è¿‡ç¨‹ï¼Œéš¾ä»¥è§£é‡Šæ¨¡åž‹çš„å†³ç­–ä¾æ®ã€‚å› æ­¤ï¼Œå¦‚ä½•æé«˜æ¨¡åž‹åœ¨å¤æ‚è§†é¢‘åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä½¿å…¶å…·å¤‡å¯è§£é‡Šçš„æŽ¨ç†èƒ½åŠ›ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVideoSeg-R1çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è§†é¢‘æŽ¨ç†åˆ†å‰²ä»»åŠ¡å»ºæ¨¡ä¸ºä¸€ä¸ªå¼ºåŒ–å­¦ä¹ é—®é¢˜ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œæ¨¡åž‹å¯ä»¥å­¦ä¹ åˆ°å¦‚ä½•åœ¨è§†é¢‘ä¸­è¿›è¡Œæœ‰æ•ˆçš„æŽ¨ç†ï¼Œå¹¶ç”Ÿæˆå‡†ç¡®çš„åˆ†å‰²æŽ©ç ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œæé«˜äº†æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ã€‚åŒæ—¶ï¼Œæ˜¾å¼çš„æŽ¨ç†é“¾ä½¿å¾—æ¨¡åž‹çš„å†³ç­–è¿‡ç¨‹æ›´åŠ é€æ˜Žå’Œå¯è§£é‡Šã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šVideoSeg-R1çš„æ•´ä½“æž¶æž„åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šï¼ˆ1ï¼‰**åˆ†å±‚æ–‡æœ¬å¼•å¯¼çš„å¸§é‡‡æ ·å™¨**ï¼šè¯¥æ¨¡å—æ¨¡æ‹Ÿäººç±»çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ ¹æ®æ–‡æœ¬æè¿°é€‰æ‹©è§†é¢‘ä¸­ç›¸å…³çš„å¸§ï¼Œä»¥å‡å°‘è®¡ç®—è´Ÿæ‹…å¹¶æé«˜æŽ¨ç†æ•ˆçŽ‡ã€‚ï¼ˆ2ï¼‰**æŽ¨ç†æ¨¡åž‹**ï¼šè¯¥æ¨¡å—åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç”Ÿæˆç©ºé—´çº¿ç´¢å’Œæ˜¾å¼æŽ¨ç†é“¾ï¼ŒæŒ‡å¯¼åŽç»­çš„åˆ†å‰²è¿‡ç¨‹ã€‚ï¼ˆ3ï¼‰**åˆ†å‰²-ä¼ æ’­é˜¶æ®µ**ï¼šè¯¥æ¨¡å—åˆ©ç”¨SAM2å’ŒXMemç­‰å…ˆè¿›çš„åˆ†å‰²æ¨¡åž‹ï¼Œæ ¹æ®æŽ¨ç†æ¨¡åž‹æä¾›çš„çº¿ç´¢ï¼Œç”Ÿæˆæœ€ç»ˆçš„åˆ†å‰²æŽ©ç ï¼Œå¹¶å°†å…¶ä¼ æ’­åˆ°æ•´ä¸ªè§†é¢‘åºåˆ—ã€‚

**å…³é”®åˆ›æ–°**ï¼šVideoSeg-R1æœ€å…³é”®çš„åˆ›æ–°åœ¨äºŽå°†å¼ºåŒ–å­¦ä¹ å¼•å…¥è§†é¢‘æŽ¨ç†åˆ†å‰²ä»»åŠ¡ã€‚ä¸Žä¼ ç»Ÿçš„æœ‰ç›‘ç£æ–¹æ³•ä¸åŒï¼ŒVideoSeg-R1é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¨¡åž‹ï¼Œä½¿å…¶èƒ½å¤Ÿè‡ªä¸»åœ°å­¦ä¹ æŽ¨ç†ç­–ç•¥ï¼Œä»Žè€Œæé«˜æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚æ­¤å¤–ï¼Œæ˜¾å¼çš„æŽ¨ç†é“¾ä½¿å¾—æ¨¡åž‹çš„å†³ç­–è¿‡ç¨‹æ›´åŠ é€æ˜Žå’Œå¯è§£é‡Šï¼Œè¿™å¯¹äºŽå®žé™…åº”ç”¨éžå¸¸é‡è¦ã€‚

**å…³é”®è®¾è®¡**ï¼šVideoSeg-R1çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) **ä»»åŠ¡éš¾åº¦æ„ŸçŸ¥æœºåˆ¶**ï¼šè¯¥æœºåˆ¶æ ¹æ®è§†é¢‘çš„å¤æ‚ç¨‹åº¦è‡ªé€‚åº”åœ°è°ƒæ•´æŽ¨ç†é•¿åº¦ï¼Œä»¥åœ¨æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚(2) **åˆ†å±‚æ–‡æœ¬å¼•å¯¼çš„å¸§é‡‡æ ·å™¨**ï¼šé€šè¿‡åˆ†å±‚é‡‡æ ·ï¼Œæ¨¡åž‹å¯ä»¥æ›´æœ‰æ•ˆåœ°é€‰æ‹©ä¸Žæ–‡æœ¬æè¿°ç›¸å…³çš„å¸§ï¼Œä»Žè€Œæé«˜æŽ¨ç†çš„å‡†ç¡®æ€§ã€‚(3) **å¼ºåŒ–å­¦ä¹ å¥–åŠ±å‡½æ•°**ï¼šå¥–åŠ±å‡½æ•°çš„è®¾è®¡è‡³å…³é‡è¦ï¼Œå®ƒç›´æŽ¥å½±å“æ¨¡åž‹çš„å­¦ä¹ æ•ˆæžœã€‚è®ºæ–‡ä¸­å¯èƒ½é‡‡ç”¨äº†åŸºäºŽåˆ†å‰²å‡†ç¡®çŽ‡å’ŒæŽ¨ç†æ•ˆçŽ‡çš„å¥–åŠ±å‡½æ•°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

VideoSeg-R1åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œè¯æ˜Žäº†å…¶åœ¨å¤æ‚è§†é¢‘æŽ¨ç†å’Œåˆ†å‰²ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥å¼ºåŒ–å­¦ä¹ å’Œæ˜¾å¼æŽ¨ç†é“¾ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›å’Œå¯è§£é‡Šæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

VideoSeg-R1åœ¨è§†é¢‘ç¼–è¾‘ã€æ™ºèƒ½ç›‘æŽ§ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œåœ¨è§†é¢‘ç¼–è¾‘ä¸­ï¼Œå¯ä»¥æ ¹æ®æ–‡æœ¬æè¿°è‡ªåŠ¨åˆ†å‰²è§†é¢‘ä¸­çš„ç›®æ ‡å¯¹è±¡ï¼Œæ–¹ä¾¿ç”¨æˆ·è¿›è¡Œç¼–è¾‘å’Œç‰¹æ•ˆå¤„ç†ã€‚åœ¨æ™ºèƒ½ç›‘æŽ§ä¸­ï¼Œå¯ä»¥è‡ªåŠ¨è¯†åˆ«å’Œè·Ÿè¸ªè§†é¢‘ä¸­çš„å¯ç–‘ç›®æ ‡ï¼Œæé«˜ç›‘æŽ§æ•ˆçŽ‡ã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥å‡†ç¡®åˆ†å‰²é“è·¯ä¸Šçš„è½¦è¾†ã€è¡Œäººç­‰ç›®æ ‡ï¼Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Traditional video reasoning segmentation methods rely on supervised fine-tuning, which limits generalization to out-of-distribution scenarios and lacks explicit reasoning. To address this, we propose \textbf{VideoSeg-R1}, the first framework to introduce reinforcement learning into video reasoning segmentation. It adopts a decoupled architecture that formulates the task as joint referring image segmentation and video mask propagation. It comprises three stages: (1) A hierarchical text-guided frame sampler to emulate human attention; (2) A reasoning model that produces spatial cues along with explicit reasoning chains; and (3) A segmentation-propagation stage using SAM2 and XMem. A task difficulty-aware mechanism adaptively controls reasoning length for better efficiency and accuracy. Extensive evaluations on multiple benchmarks demonstrate that VideoSeg-R1 achieves state-of-the-art performance in complex video reasoning and segmentation tasks. The code will be publicly available at https://github.com/euyis1019/VideoSeg-R1.

