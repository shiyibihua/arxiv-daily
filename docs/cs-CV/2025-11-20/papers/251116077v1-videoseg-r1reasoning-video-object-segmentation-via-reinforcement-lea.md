---
layout: default
title: VideoSeg-R1:Reasoning Video Object Segmentation via Reinforcement Learning
---

# VideoSeg-R1:Reasoning Video Object Segmentation via Reinforcement Learning

**arXiv**: [2511.16077v1](https://arxiv.org/abs/2511.16077) | [PDF](https://arxiv.org/pdf/2511.16077.pdf)

**ä½œè€…**: Zishan Xu, Yifu Guo, Yuquan Lu, Fengyu Yang, Junxin Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVideoSeg-R1æ¡†æž¶ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è§£å†³è§†é¢‘æŽ¨ç†åˆ†å‰²çš„æ³›åŒ–ä¸Žæ˜¾å¼æŽ¨ç†é—®é¢˜ã€‚**

**å…³é”®è¯**: `è§†é¢‘æŽ¨ç†åˆ†å‰²` `å¼ºåŒ–å­¦ä¹ ` `è§£è€¦æž¶æž„` `æ˜¾å¼æŽ¨ç†é“¾` `è‡ªé€‚åº”æŽ¨ç†é•¿åº¦`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿæ–¹æ³•ä¾èµ–ç›‘ç£å¾®è°ƒï¼Œæ³›åŒ–èƒ½åŠ›å·®ä¸”ç¼ºä¹æ˜¾å¼æŽ¨ç†ã€‚
2. é‡‡ç”¨è§£è€¦æž¶æž„ï¼Œç»“åˆæ–‡æœ¬å¼•å¯¼é‡‡æ ·ã€æŽ¨ç†é“¾ç”Ÿæˆå’Œåˆ†å‰²ä¼ æ’­ã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®žçŽ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œä»£ç å°†å¼€æºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Traditional video reasoning segmentation methods rely on supervised fine-tuning, which limits generalization to out-of-distribution scenarios and lacks explicit reasoning. To address this, we propose \textbf{VideoSeg-R1}, the first framework to introduce reinforcement learning into video reasoning segmentation. It adopts a decoupled architecture that formulates the task as joint referring image segmentation and video mask propagation. It comprises three stages: (1) A hierarchical text-guided frame sampler to emulate human attention; (2) A reasoning model that produces spatial cues along with explicit reasoning chains; and (3) A segmentation-propagation stage using SAM2 and XMem. A task difficulty-aware mechanism adaptively controls reasoning length for better efficiency and accuracy. Extensive evaluations on multiple benchmarks demonstrate that VideoSeg-R1 achieves state-of-the-art performance in complex video reasoning and segmentation tasks. The code will be publicly available at https://github.com/euyis1019/VideoSeg-R1.

