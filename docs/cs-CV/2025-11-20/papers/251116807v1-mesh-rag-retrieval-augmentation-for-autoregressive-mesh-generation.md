---
layout: default
title: Mesh RAG: Retrieval Augmentation for Autoregressive Mesh Generation
---

# Mesh RAG: Retrieval Augmentation for Autoregressive Mesh Generation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.16807" target="_blank" class="toolbar-btn">arXiv: 2511.16807v1</a>
    <a href="https://arxiv.org/pdf/2511.16807.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.16807v1" 
            onclick="toggleFavorite(this, '2511.16807v1', 'Mesh RAG: Retrieval Augmentation for Autoregressive Mesh Generation')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Xiatao Sun, Chen Liang, Qian Wang, Daniel Rakita

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Mesh RAGï¼šç”¨äºè‡ªå›å½’ç½‘æ ¼ç”Ÿæˆçš„æ£€ç´¢å¢å¼ºæ¡†æ¶ï¼Œæå‡è´¨é‡ä¸é€Ÿåº¦ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `ç½‘æ ¼ç”Ÿæˆ` `è‡ªå›å½’æ¨¡å‹` `æ£€ç´¢å¢å¼º` `ç‚¹äº‘å¤„ç†` `ä¸‰ç»´é‡å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªå›å½’ç½‘æ ¼ç”Ÿæˆæ¨¡å‹ä¾èµ–æ›´å¤§çš„æ¨¡å‹æˆ–æ›´é•¿çš„åºåˆ—æ¥æé«˜è´¨é‡ï¼Œå¯¼è‡´ç”Ÿæˆæ—¶é—´è¿‡é•¿ï¼Œå­˜åœ¨è´¨é‡ä¸é€Ÿåº¦çš„ä¸¥é‡æƒè¡¡ã€‚
2. Mesh RAGé€šè¿‡æ£€ç´¢ã€ç”Ÿæˆå’Œé›†æˆç½‘æ ¼ç»„ä»¶æ¥å¢å¼ºç”Ÿæˆè¿‡ç¨‹ï¼Œè§£è€¦äº†ç”Ÿæˆè¿‡ç¨‹çš„é¡ºåºä¾èµ–æ€§ï¼Œå®ç°äº†é«˜æ•ˆçš„å¹¶è¡Œæ¨ç†ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMesh RAGæ˜¾è‘—æé«˜äº†ç½‘æ ¼è´¨é‡ï¼ŒåŠ å¿«äº†ç”Ÿæˆé€Ÿåº¦ï¼Œå¹¶æ”¯æŒå¢é‡ç¼–è¾‘ï¼Œä¸”æ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºMesh RAGï¼Œä¸€ä¸ªæ–°é¢–çš„ã€å…è®­ç»ƒçš„ã€å³æ’å³ç”¨çš„è‡ªå›å½’ç½‘æ ¼ç”Ÿæˆæ¨¡å‹æ¡†æ¶ã€‚å—è¯­è¨€æ¨¡å‹RAGçš„å¯å‘ï¼Œè¯¥æ–¹æ³•é€šè¿‡åˆ©ç”¨ç‚¹äº‘åˆ†å‰²ã€ç©ºé—´å˜æ¢å’Œç‚¹äº‘é…å‡†æ¥æ£€ç´¢ã€ç”Ÿæˆå’Œé›†æˆç½‘æ ¼ç»„ä»¶ï¼Œä»è€Œå¢å¼ºç”Ÿæˆè¿‡ç¨‹ã€‚è¿™ç§åŸºäºæ£€ç´¢çš„æ–¹æ³•å°†ç”Ÿæˆä¸ä¸¥æ ¼çš„é¡ºåºä¾èµ–æ€§è§£è€¦ï¼Œä»è€Œä¿ƒè¿›é«˜æ•ˆä¸”å¯å¹¶è¡ŒåŒ–çš„æ¨ç†ã€‚å®éªŒè¯æ˜Mesh RAGåœ¨å„ç§åŸºç¡€è‡ªå›å½’ç½‘æ ¼ç”Ÿæˆæ¨¡å‹ä¸­å…·æœ‰å¹¿æ³›çš„é€‚ç”¨æ€§ï¼Œä¸é¡ºåºéƒ¨ä»¶é¢„æµ‹ç›¸æ¯”ï¼Œå®ƒæ˜¾è‘—æé«˜äº†ç½‘æ ¼è´¨é‡ï¼ŒåŠ å¿«äº†ç”Ÿæˆé€Ÿåº¦ï¼Œå¹¶å®ç°äº†å¢é‡ç¼–è¾‘ï¼Œæ‰€æœ‰è¿™äº›éƒ½ä¸éœ€è¦æ¨¡å‹é‡æ–°è®­ç»ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è‡ªå›å½’ç½‘æ ¼ç”Ÿæˆä¸­è´¨é‡ä¸é€Ÿåº¦çš„æƒè¡¡é—®é¢˜ï¼Œä»¥åŠé¡ºåºç”Ÿæˆå¸¦æ¥çš„å¢é‡ç¼–è¾‘å›°éš¾ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºæ‰©å¤§æ¨¡å‹è§„æ¨¡æˆ–å¢åŠ åºåˆ—é•¿åº¦æ¥æå‡è´¨é‡ï¼Œå¯¼è‡´ç”Ÿæˆé€Ÿåº¦æ˜¾è‘—ä¸‹é™ï¼Œå¹¶ä¸”éš¾ä»¥è¿›è¡Œå±€éƒ¨ä¿®æ”¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯å€Ÿé‰´è¯­è¨€æ¨¡å‹ä¸­çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ€æƒ³ï¼Œé€šè¿‡æ£€ç´¢å·²æœ‰çš„ç½‘æ ¼éƒ¨ä»¶æ¥è¾…åŠ©ç”Ÿæˆè¿‡ç¨‹ï¼Œé¿å…å®Œå…¨ä¾èµ–è‡ªå›å½’æ¨¡å‹çš„é¡ºåºé¢„æµ‹ã€‚è¿™æ ·å¯ä»¥å°†ç”Ÿæˆè¿‡ç¨‹è§£è€¦ï¼Œå®ç°å¹¶è¡ŒåŒ–ï¼Œä»è€Œæé«˜ç”Ÿæˆé€Ÿåº¦å’Œæ”¯æŒå¢é‡ç¼–è¾‘ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMesh RAGæ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼šæ£€ç´¢é˜¶æ®µã€ç”Ÿæˆé˜¶æ®µå’Œé›†æˆé˜¶æ®µã€‚åœ¨æ£€ç´¢é˜¶æ®µï¼Œåˆ©ç”¨ç‚¹äº‘åˆ†å‰²ã€ç©ºé—´å˜æ¢å’Œç‚¹äº‘é…å‡†ç­‰æŠ€æœ¯ï¼Œä»å·²æœ‰çš„ç½‘æ ¼éƒ¨ä»¶åº“ä¸­æ£€ç´¢å‡ºä¸å½“å‰éœ€è¦ç”Ÿæˆçš„éƒ¨ä»¶ç›¸ä¼¼çš„éƒ¨ä»¶ã€‚åœ¨ç”Ÿæˆé˜¶æ®µï¼Œåˆ©ç”¨æ£€ç´¢åˆ°çš„éƒ¨ä»¶ä½œä¸ºå…ˆéªŒä¿¡æ¯ï¼ŒæŒ‡å¯¼è‡ªå›å½’æ¨¡å‹ç”Ÿæˆæ–°çš„ç½‘æ ¼éƒ¨ä»¶ã€‚åœ¨é›†æˆé˜¶æ®µï¼Œå°†ç”Ÿæˆçš„ç½‘æ ¼éƒ¨ä»¶ä¸å·²æœ‰çš„ç½‘æ ¼è¿›è¡Œèåˆï¼Œå½¢æˆæœ€ç»ˆçš„å®Œæ•´ç½‘æ ¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†æ£€ç´¢å¢å¼ºçš„æ€æƒ³å¼•å…¥åˆ°è‡ªå›å½’ç½‘æ ¼ç”Ÿæˆä¸­ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿè‡ªå›å½’æ¨¡å‹çš„é¡ºåºä¾èµ–æ€§ï¼Œå®ç°äº†å¹¶è¡ŒåŒ–ç”Ÿæˆå’Œå¢é‡ç¼–è¾‘ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMesh RAGæ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œå³å¯æ˜¾è‘—æé«˜ç”Ÿæˆè´¨é‡å’Œé€Ÿåº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šMesh RAGçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ç‚¹äº‘åˆ†å‰²æŠ€æœ¯å°†ç½‘æ ¼åˆ†è§£ä¸ºéƒ¨ä»¶ï¼›2) ä½¿ç”¨ç©ºé—´å˜æ¢å’Œç‚¹äº‘é…å‡†æŠ€æœ¯è¿›è¡Œéƒ¨ä»¶æ£€ç´¢ï¼›3) ä½¿ç”¨æ£€ç´¢åˆ°çš„éƒ¨ä»¶ä½œä¸ºå…ˆéªŒä¿¡æ¯ï¼ŒæŒ‡å¯¼è‡ªå›å½’æ¨¡å‹ç”Ÿæˆæ–°çš„éƒ¨ä»¶ï¼›4) è®¾è®¡åˆé€‚çš„èåˆç­–ç•¥ï¼Œå°†ç”Ÿæˆçš„éƒ¨ä»¶ä¸å·²æœ‰ç½‘æ ¼è¿›è¡Œæ— ç¼é›†æˆã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰ç»†èŠ‚å–å†³äºæ‰€ä½¿ç”¨çš„åŸºç¡€è‡ªå›å½’ç½‘æ ¼ç”Ÿæˆæ¨¡å‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMesh RAGåœ¨å¤šä¸ªè‡ªå›å½’ç½‘æ ¼ç”Ÿæˆæ¨¡å‹ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸é¡ºåºéƒ¨ä»¶é¢„æµ‹ç›¸æ¯”ï¼ŒMesh RAGæ˜¾è‘—æé«˜äº†ç½‘æ ¼è´¨é‡ï¼ŒåŠ å¿«äº†ç”Ÿæˆé€Ÿåº¦ï¼Œå¹¶å®ç°äº†å¢é‡ç¼–è¾‘ï¼Œä¸”æ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®ï¼ˆä¾‹å¦‚ï¼Œåœ¨ç‰¹å®šæŒ‡æ ‡ä¸Šçš„æå‡å¹…åº¦ï¼‰åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†çš„å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Mesh RAGåœ¨å·¥ä¸šè®¾è®¡ã€æ¸¸æˆå¼€å‘ã€ä»¿çœŸå’Œæœºå™¨äººç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥åŠ é€Ÿ3Dæ¨¡å‹çš„åˆ›å»ºè¿‡ç¨‹ï¼Œé™ä½äººå·¥æˆæœ¬ï¼Œå¹¶æé«˜æ¨¡å‹çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚æ­¤å¤–ï¼ŒMesh RAGçš„å¢é‡ç¼–è¾‘èƒ½åŠ›ä½¿å¾—ç”¨æˆ·å¯ä»¥æ–¹ä¾¿åœ°å¯¹ç°æœ‰æ¨¡å‹è¿›è¡Œä¿®æ”¹å’Œå®šåˆ¶ï¼Œæ»¡è¶³ä¸ªæ€§åŒ–éœ€æ±‚ã€‚æœªæ¥ï¼ŒMesh RAGæœ‰æœ›æˆä¸º3Då†…å®¹åˆ›ä½œçš„é‡è¦å·¥å…·ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> 3D meshes are a critical building block for applications ranging from industrial design and gaming to simulation and robotics. Traditionally, meshes are crafted manually by artists, a process that is time-intensive and difficult to scale. To automate and accelerate this asset creation, autoregressive models have emerged as a powerful paradigm for artistic mesh generation. However, current methods to enhance quality typically rely on larger models or longer sequences that result in longer generation time, and their inherent sequential nature imposes a severe quality-speed trade-off. This sequential dependency also significantly complicates incremental editing. To overcome these limitations, we propose Mesh RAG, a novel, training-free, plug-and-play framework for autoregressive mesh generation models. Inspired by RAG for language models, our approach augments the generation process by leveraging point cloud segmentation, spatial transformation, and point cloud registration to retrieve, generate, and integrate mesh components. This retrieval-based approach decouples generation from its strict sequential dependency, facilitating efficient and parallelizable inference. We demonstrate the wide applicability of Mesh RAG across various foundational autoregressive mesh generation models, showing it significantly enhances mesh quality, accelerates generation speed compared to sequential part prediction, and enables incremental editing, all without model retraining.

