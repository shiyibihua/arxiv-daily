---
layout: default
title: Solving Spatial Supersensing Without Spatial Supersensing
---

# Solving Spatial Supersensing Without Spatial Supersensing

**arXiv**: [2511.16655v1](https://arxiv.org/abs/2511.16655) | [PDF](https://arxiv.org/pdf/2511.16655.pdf)

**ä½œè€…**: Vishaal Udandarao, Shyamgopal Karthik, Surabhi S. Nath, Andreas Hochlehnert, Matthias Bethge, Ameya Prabhu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ†æžCambrian-SåŸºå‡†ä¸ŽæŽ¨ç†æ–¹æ³•ï¼Œæ­ç¤ºå…¶æœªå¯é æµ‹é‡ç©ºé—´è¶…æ„ŸçŸ¥**

**å…³é”®è¯**: `ç©ºé—´è¶…æ„ŸçŸ¥` `è§†é¢‘åŸºå‡†è¯„ä¼°` `æŽ¨ç†æ–¹æ³•åˆ†æž` `æ·å¾„å¯å‘å¼` `é•¿è§†é¢‘ç†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå½“å‰VSI-SuperåŸºå‡†å¯èƒ½æ— æ³•æœ‰æ•ˆè¯„ä¼°ç©ºé—´è¶…æ„ŸçŸ¥èƒ½åŠ›
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºNoSenseåŸºçº¿ï¼Œä»…ç”¨è¯è¢‹æ¨¡åž‹è§£å†³VSRï¼›è®¾è®¡VSC-Repeatæ‰°åŠ¨æµ‹è¯•
3. å®žéªŒæˆ–æ•ˆæžœï¼šNoSenseåœ¨VSRè¾¾95%å‡†ç¡®çŽ‡ï¼›VSC-Repeatä½¿Cambrian-Så‡†ç¡®çŽ‡é™è‡³0%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Cambrian-S aims to take the first steps towards improving video world models with spatial supersensing by introducing (i) two benchmarks, VSI-Super-Recall (VSR) and VSI-Super-Counting (VSC), and (ii) bespoke predictive sensing inference strategies tailored to each benchmark. In this work, we conduct a critical analysis of Cambrian-S across both these fronts. First, we introduce a simple baseline, NoSense, which discards almost all temporal structure and uses only a bag-of-words SigLIP model, yet near-perfectly solves VSR, achieving 95% accuracy even on 4-hour videos. This shows benchmarks like VSR can be nearly solved without spatial cognition, world modeling or spatial supersensing. Second, we hypothesize that the tailored inference methods proposed by Cambrian-S likely exploit shortcut heuristics in the benchmark. We illustrate this with a simple sanity check on the VSC benchmark, called VSC-Repeat: We concatenate each video with itself 1-5 times, which does not change the number of unique objects. However, this simple perturbation entirely collapses the mean relative accuracy of Cambrian-S from 42% to 0%. A system that performs spatial supersensing and integrates information across experiences should recognize views of the same scene and keep object-count predictions unchanged; instead, Cambrian-S inference algorithm relies largely on a shortcut in the VSC benchmark that rooms are never revisited. Taken together, our findings suggest that (i) current VSI-Super benchmarks do not yet reliably measure spatial supersensing, and (ii) predictive-sensing inference recipes used by Cambrian-S improve performance by inadvertently exploiting shortcuts rather than from robust spatial supersensing. We include the response from the Cambrian-S authors (in Appendix A) to provide a balanced perspective alongside our claims. We release our code at: https://github.com/bethgelab/supersanity

