---
layout: default
title: LiSTAR: Ray-Centric World Models for 4D LiDAR Sequences in Autonomous Driving
---

# LiSTAR: Ray-Centric World Models for 4D LiDAR Sequences in Autonomous Driving

**arXiv**: [2511.16049v1](https://arxiv.org/abs/2511.16049) | [PDF](https://arxiv.org/pdf/2511.16049.pdf)

**ä½œè€…**: Pei Liu, Songtao Wang, Lang Zhang, Xingyue Peng, Yuandong Lyu, Jiaxin Deng, Songxin Lu, Weiliang Ma, Xueyang Zhang, Yifei Zhan, XianPeng Lang, Jun Ma

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLiSTARæ¨¡åž‹ä»¥è§£å†³è‡ªåŠ¨é©¾é©¶ä¸­4D LiDARæ•°æ®åˆæˆæŒ‘æˆ˜**

**å…³é”®è¯**: `4D LiDARåˆæˆ` `ç”Ÿæˆä¸–ç•Œæ¨¡åž‹` `å°„çº¿ä¸­å¿ƒå˜æ¢å™¨` `è‡ªåŠ¨é©¾é©¶æ¨¡æ‹Ÿ` `å¯æŽ§ç”Ÿæˆ` `æ—¶ç©ºæ³¨æ„åŠ›`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼š4D LiDARæ•°æ®åˆæˆå› çƒå½¢å‡ ä½•ã€æ—¶é—´ç¨€ç–æ€§å’ŒåŠ¨æ€åœºæ™¯å¤æ‚æ€§è€Œå›°éš¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ··åˆæŸ±é¢-çƒé¢è¡¨ç¤ºå’Œå°„çº¿ä¸­å¿ƒå˜æ¢å™¨ï¼Œæå‡æ•°æ®ä¿çœŸåº¦å’Œæ—¶é—´ä¸€è‡´æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨é‡å»ºã€é¢„æµ‹å’Œç”Ÿæˆä»»åŠ¡ä¸­è¡¨çŽ°ä¼˜å¼‚ï¼ŒMMDé™ä½Ž76%ï¼ŒIoUæé«˜32%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Synthesizing high-fidelity and controllable 4D LiDAR data is crucial for creating scalable simulation environments for autonomous driving. This task is inherently challenging due to the sensor's unique spherical geometry, the temporal sparsity of point clouds, and the complexity of dynamic scenes. To address these challenges, we present LiSTAR, a novel generative world model that operates directly on the sensor's native geometry. LiSTAR introduces a Hybrid-Cylindrical-Spherical (HCS) representation to preserve data fidelity by mitigating quantization artifacts common in Cartesian grids. To capture complex dynamics from sparse temporal data, it utilizes a Spatio-Temporal Attention with Ray-Centric Transformer (START) that explicitly models feature evolution along individual sensor rays for robust temporal coherence. Furthermore, for controllable synthesis, we propose a novel 4D point cloud-aligned voxel layout for conditioning and a corresponding discrete Masked Generative START (MaskSTART) framework, which learns a compact, tokenized representation of the scene, enabling efficient, high-resolution, and layout-guided compositional generation. Comprehensive experiments validate LiSTAR's state-of-the-art performance across 4D LiDAR reconstruction, prediction, and conditional generation, with substantial quantitative gains: reducing generation MMD by a massive 76%, improving reconstruction IoU by 32%, and lowering prediction L1 Med by 50%. This level of performance provides a powerful new foundation for creating realistic and controllable autonomous systems simulations. Project link: https://ocean-luna.github.io/LiSTAR.gitub.io.

