---
layout: default
title: Crossmodal learning for Crop Canopy Trait Estimation
---

# Crossmodal learning for Crop Canopy Trait Estimation

**arXiv**: [2511.16031v1](https://arxiv.org/abs/2511.16031) | [PDF](https://arxiv.org/pdf/2511.16031.pdf)

**ä½œè€…**: Timilehin T. Ayanlade, Anirudha Powadi, Talukder Z. Jubery, Baskar Ganapathysubramanian, Soumik Sarkar

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè·¨æ¨¡æ€å­¦ä¹ ç­–ç•¥ï¼Œåˆ©ç”¨å«æ˜Ÿå›¾åƒç”Ÿæˆæ— äººæœºçº§ç»†èŠ‚ä»¥ä¼°è®¡ä½œç‰©å† å±‚æ€§çŠ¶**

**å…³é”®è¯**: `è·¨æ¨¡æ€å­¦ä¹ ` `ä½œç‰©å† å±‚æ€§çŠ¶ä¼°è®¡` `å«æ˜Ÿå›¾åƒå¢žå¼º` `æ— äººæœºå›¾åƒ` `å†œä¸šç›‘æµ‹` `å…‰è°±ç©ºé—´å¯¹åº”`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å«æ˜Ÿå›¾åƒç©ºé—´åˆ†è¾¨çŽ‡ä½Žï¼Œé™åˆ¶å…¶åœ¨å¾®åœ°å—ç®¡ç†å†œä¸šä¸­çš„åº”ç”¨
2. æ–¹æ³•å­¦ä¹ å«æ˜Ÿä¸Žæ— äººæœºå›¾åƒé—´çš„ç²¾ç»†å…‰è°±ç©ºé—´å¯¹åº”å…³ç³»
3. ç”Ÿæˆå›¾åƒåœ¨äº§é‡å’Œæ°®é¢„æµ‹ä»»åŠ¡ä¸­ä¼˜äºŽçœŸå®žå«æ˜Ÿå›¾åƒ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in plant phenotyping have driven widespread adoption of multi sensor platforms for collecting crop canopy reflectance data. This includes the collection of heterogeneous data across multiple platforms, with Unmanned Aerial Vehicles (UAV) seeing significant usage due to their high performance in crop monitoring, forecasting, and prediction tasks. Similarly, satellite missions have been shown to be effective for agriculturally relevant tasks. In contrast to UAVs, such missions are bound to the limitation of spatial resolution, which hinders their effectiveness for modern farming systems focused on micro-plot management. In this work, we propose a cross modal learning strategy that enriches high-resolution satellite imagery with UAV level visual detail for crop canopy trait estimation. Using a dataset of approximately co registered satellite UAV image pairs collected from replicated plots of 84 hybrid maize varieties across five distinct locations in the U.S. Corn Belt, we train a model that learns fine grained spectral spatial correspondences between sensing modalities. Results show that the generated UAV-like representations from satellite inputs consistently outperform real satellite imagery on multiple downstream tasks, including yield and nitrogen prediction, demonstrating the potential of cross-modal correspondence learning to bridge the gap between satellite and UAV sensing in agricultural monitoring.

