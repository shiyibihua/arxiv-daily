---
layout: default
title: SwiTrack: Tri-State Switch for Cross-Modal Object Tracking
---

# SwiTrack: Tri-State Switch for Cross-Modal Object Tracking

**arXiv**: [2511.16227v1](https://arxiv.org/abs/2511.16227) | [PDF](https://arxiv.org/pdf/2511.16227.pdf)

**ä½œè€…**: Boyue Xu, Ruichao Hou, Tongwei Ren, Dongming Zhou, Gangshan Wu, Jinde Cao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSwiTrackä¸‰æ€åˆ‡æ¢æ¡†æž¶ä»¥è§£å†³è·¨æ¨¡æ€ç›®æ ‡è·Ÿè¸ªä¸­çš„ç‰¹å¾æå–ä¸è¶³å’Œæ¼‚ç§»é—®é¢˜**

**å…³é”®è¯**: `è·¨æ¨¡æ€ç›®æ ‡è·Ÿè¸ª` `RGB-NIRè·Ÿè¸ª` `ä¸‰æ€åˆ‡æ¢æ¡†æž¶` `ç‰¹å¾æ ¡å‡†` `è½¨è¿¹é¢„æµ‹` `åŠ¨æ€æ¨¡æ¿é‡å»º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•åœ¨RGB-NIRè·¨æ¨¡æ€è·Ÿè¸ªä¸­éš¾ä»¥æå–æ¨¡æ€ç‰¹æœ‰ç‰¹å¾ï¼Œæ˜“å¯¼è‡´ç›®æ ‡æ¼‚ç§»
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä¸‰æµæž¶æž„ï¼ŒåŒ…æ‹¬è§†è§‰ç¼–ç å™¨ã€NIRé—¨æŽ§é€‚é…å™¨å’Œä¸€è‡´æ€§è½¨è¿¹é¢„æµ‹æ¨¡å—
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŸºå‡†æµ‹è¯•ä¸­ç²¾åº¦å’ŒæˆåŠŸçŽ‡åˆ†åˆ«æå‡7.2%å’Œ4.3%ï¼Œå®žæ—¶è·Ÿè¸ªè¾¾65å¸§/ç§’

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Cross-modal object tracking (CMOT) is an emerging task that maintains target consistency while the video stream switches between different modalities, with only one modality available in each frame, mostly focusing on RGB-Near Infrared (RGB-NIR) tracking. Existing methods typically connect parallel RGB and NIR branches to a shared backbone, which limits the comprehensive extraction of distinctive modality-specific features and fails to address the issue of object drift, especially in the presence of unreliable inputs. In this paper, we propose SwiTrack, a novel state-switching framework that redefines CMOT through the deployment of three specialized streams. Specifically, RGB frames are processed by the visual encoder, while NIR frames undergo refinement via a NIR gated adapter coupled with the visual encoder to progressively calibrate shared latent space features, thereby yielding more robust cross-modal representations. For invalid modalities, a consistency trajectory prediction module leverages spatio-temporal cues to estimate target movement, ensuring robust tracking and mitigating drift. Additionally, we incorporate dynamic template reconstruction to iteratively update template features and employ a similarity alignment loss to reinforce feature consistency. Experimental results on the latest benchmarks demonstrate that our tracker achieves state-of-the-art performance, boosting precision rate and success rate gains by 7.2\% and 4.3\%, respectively, while maintaining real-time tracking at 65 frames per second. Code and models are available at https://github.com/xuboyue1999/SwiTrack.git.

