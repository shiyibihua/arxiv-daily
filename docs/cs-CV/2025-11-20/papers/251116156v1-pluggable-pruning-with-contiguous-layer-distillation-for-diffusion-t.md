---
layout: default
title: Pluggable Pruning with Contiguous Layer Distillation for Diffusion Transformers
---

# Pluggable Pruning with Contiguous Layer Distillation for Diffusion Transformers

**arXiv**: [2511.16156v1](https://arxiv.org/abs/2511.16156) | [PDF](https://arxiv.org/pdf/2511.16156.pdf)

**ä½œè€…**: Jian Ma, Qirong Peng, Xujie Zhu, Peixing Xie, Chen Chen, Haonan Lu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯æ’æ‹”å‰ªæžä¸Žè¿žç»­å±‚è’¸é¦æ–¹æ³•ï¼Œä»¥åŽ‹ç¼©æ‰©æ•£å˜æ¢å™¨å‚æ•°å¹¶ä¿æŒå›¾åƒç”Ÿæˆè´¨é‡ã€‚**

**å…³é”®è¯**: `æ‰©æ•£å˜æ¢å™¨` `ç»“æž„åŒ–å‰ªæž` `çŸ¥è¯†è’¸é¦` `å›¾åƒç”Ÿæˆ` `æ¨¡åž‹åŽ‹ç¼©` `èµ„æºä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ‰©æ•£å˜æ¢å™¨å‚æ•°é‡å¤§ï¼Œè®¡ç®—æˆæœ¬é«˜ï¼Œé˜»ç¢èµ„æºå—é™éƒ¨ç½²ã€‚
2. é€šè¿‡çº¿æ€§æŽ¢æµ‹å’Œç›¸ä¼¼åº¦è¶‹åŠ¿åˆ†æžè¯†åˆ«å†—ä½™å±‚ï¼Œç»“åˆäº¤æ›¿è’¸é¦å®žçŽ°æ·±åº¦å’Œå®½åº¦å‰ªæžã€‚
3. å®žéªŒæ˜¾ç¤ºå‚æ•°å‡å°‘50%ï¼Œå…³é”®æŒ‡æ ‡é€€åŒ–å°äºŽ3%ï¼Œä»£ç å¼€æºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Diffusion Transformers (DiTs) have shown exceptional performance in image generation, yet their large parameter counts incur high computational costs, impeding deployment in resource-constrained settings. To address this, we propose Pluggable Pruning with Contiguous Layer Distillation (PPCL), a flexible structured pruning framework specifically designed for DiT architectures. First, we identify redundant layer intervals through a linear probing mechanism combined with the first-order differential trend analysis of similarity metrics. Subsequently, we propose a plug-and-play teacher-student alternating distillation scheme tailored to integrate depth-wise and width-wise pruning within a single training phase. This distillation framework enables flexible knowledge transfer across diverse pruning ratios, eliminating the need for per-configuration retraining. Extensive experiments on multiple Multi-Modal Diffusion Transformer architecture models demonstrate that PPCL achieves a 50\% reduction in parameter count compared to the full model, with less than 3\% degradation in key objective metrics. Notably, our method maintains high-quality image generation capabilities while achieving higher compression ratios, rendering it well-suited for resource-constrained environments. The open-source code, checkpoints for PPCL can be found at the following link: https://github.com/OPPO-Mente-Lab/Qwen-Image-Pruning.

