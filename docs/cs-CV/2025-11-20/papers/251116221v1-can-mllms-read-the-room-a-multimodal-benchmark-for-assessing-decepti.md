---
layout: default
title: Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions
---

# Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions

**arXiv**: [2511.16221v1](https://arxiv.org/abs/2511.16221) | [PDF](https://arxiv.org/pdf/2511.16221.pdf)

**ä½œè€…**: Caixin Kang, Yifei Huang, Liangyang Ouyang, Mingfang Zhang, Ruicong Liu, Yoichi Sato

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-11-20

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMIDAåŸºå‡†æµ‹è¯•ï¼Œè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹åœ¨å¤šäººç¤¾äº¤äº’åŠ¨ä¸­è¯†åˆ«æ¬ºéª—çš„èƒ½åŠ›ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸Žååº” (Interaction & Reaction)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `æ¬ºéª—æ£€æµ‹` `ç¤¾äº¤æŽ¨ç†` `å¤§è¯­è¨€æ¨¡åž‹` `äººæœºäº¤äº’`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰MLLMåœ¨å¤æ‚ç¤¾äº¤äº’åŠ¨ä¸­è¯†åˆ«æ¬ºéª—çš„èƒ½åŠ›ä¸è¶³ï¼Œç¼ºä¹â€œè¯»æ‡‚æ°”æ°›â€çš„æ ¸å¿ƒäººç±»æ™ºèƒ½ã€‚
2. æå‡ºMIDAä»»åŠ¡å’Œæ•°æ®é›†ï¼Œå¹¶è®¾è®¡SoCoTæŽ¨ç†ç®¡é“å’ŒDSEMæ¨¡å—ï¼Œæå‡æ¨¡åž‹ç¤¾äº¤æŽ¨ç†èƒ½åŠ›ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œå³ä½¿æ˜¯GPT-4oç­‰å¼ºå¤§æ¨¡åž‹ä¹Ÿéš¾ä»¥å¯é åŒºåˆ†çœŸå‡ï¼ŒSoCoTå’ŒDSEMèƒ½æœ‰æ•ˆæå‡æ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡æœ€å…ˆè¿›çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ï¼ˆMLLMsï¼‰å…·æœ‰å…ˆè¿›çš„æŽ¨ç†èƒ½åŠ›ï¼Œä½†å®ƒä»¬æ˜Žæ˜¾ç¼ºä¹äººç±»æ™ºèƒ½çš„ä¸€ä¸ªæ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼šå³â€œè¯»æ‡‚æ°”æ°›â€å¹¶è¯„ä¼°å¤æ‚ç¤¾äº¤äº’åŠ¨ä¸­æ¬ºéª—è¡Œä¸ºçš„èƒ½åŠ›ã€‚ä¸ºäº†ä¸¥æ ¼é‡åŒ–è¿™ç§ç¼ºé™·ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€é¡¹æ–°ä»»åŠ¡ï¼Œå³å¤šæ¨¡æ€äº’åŠ¨æ¬ºéª—è¯„ä¼°ï¼ˆMIDAï¼‰ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ–°çš„å¤šæ¨¡æ€æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æä¾›åŒæ­¥çš„è§†é¢‘å’Œæ–‡æœ¬ï¼Œä»¥åŠæ¯ä¸ªé™ˆè¿°çš„å¯éªŒè¯çš„çœŸå®žæ ‡ç­¾ã€‚æˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªå…¨é¢çš„åŸºå‡†ï¼Œè¯„ä¼°äº†12ä¸ªæœ€å…ˆè¿›çš„å¼€æºå’Œé—­æºMLLMï¼Œæ­ç¤ºäº†ä¸€ä¸ªæ˜¾è‘—çš„æ€§èƒ½å·®è·ï¼šå³ä½¿æ˜¯åƒGPT-4oè¿™æ ·å¼ºå¤§çš„æ¨¡åž‹ä¹Ÿéš¾ä»¥å¯é åœ°åŒºåˆ†çœŸå‡ã€‚æˆ‘ä»¬å¯¹å¤±è´¥æ¨¡å¼çš„åˆ†æžè¡¨æ˜Žï¼Œè¿™äº›æ¨¡åž‹æœªèƒ½æœ‰æ•ˆåœ°å°†è¯­è¨€ä¸Žå¤šæ¨¡æ€ç¤¾äº¤çº¿ç´¢è”ç³»èµ·æ¥ï¼Œå¹¶ä¸”ç¼ºä¹å¯¹ä»–äººæ‰€çŸ¥ã€æ‰€ä¿¡æˆ–æ‰€æƒ³è¿›è¡Œå»ºæ¨¡çš„èƒ½åŠ›ï¼Œçªæ˜¾äº†è¿«åˆ‡éœ€è¦æ–°çš„æ–¹æ³•æ¥æž„å»ºæ›´å…·æ´žå¯ŸåŠ›å’Œå€¼å¾—ä¿¡èµ–çš„AIç³»ç»Ÿã€‚ä¸ºäº†å‘å‰è¿ˆè¿›ä¸€æ­¥ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç¤¾ä¼šé“¾å¼æ€è€ƒï¼ˆSoCoTï¼‰æŽ¨ç†ç®¡é“å’Œä¸€ä¸ªåŠ¨æ€ç¤¾ä¼šè®¤çŸ¥è®°å¿†ï¼ˆDSEMï¼‰æ¨¡å—ã€‚æˆ‘ä»¬çš„æ¡†æž¶åœ¨è¿™ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šäº§ç”Ÿäº†æ€§èƒ½æå‡ï¼Œå±•ç¤ºäº†ä¸€æ¡æœ‰å¸Œæœ›çš„æ–°é€”å¾„ï¼Œå¯ä»¥æž„å»ºèƒ½å¤Ÿè¿›è¡ŒçœŸæ­£ç±»äººç¤¾äº¤æŽ¨ç†çš„MLLMã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ–¹ç¤¾äº¤äº’åŠ¨åœºæ™¯ä¸‹ï¼Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ï¼ˆMLLMsï¼‰éš¾ä»¥å‡†ç¡®è¯†åˆ«æ¬ºéª—è¡Œä¸ºçš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ç¼ºä¹å¯¹å¤æ‚ç¤¾äº¤çº¿ç´¢çš„æœ‰æ•ˆåˆ©ç”¨ï¼Œæ— æ³•å‡†ç¡®å»ºæ¨¡å‚ä¸Žè€…çš„çŸ¥è¯†ã€ä¿¡å¿µå’Œæ„å›¾ï¼Œå¯¼è‡´åœ¨æ¬ºéª—è¯†åˆ«ä»»åŠ¡ä¸­è¡¨çŽ°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¢žå¼ºMLLMså¯¹å¤šæ¨¡æ€ç¤¾äº¤çº¿ç´¢çš„æ„ŸçŸ¥å’ŒæŽ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œæ¨¡æ‹Ÿç¤¾äº¤äº’åŠ¨ä¸­çš„å¤æ‚åŠ¨æ€ã€‚é€šè¿‡å¼•å…¥ç¤¾ä¼šé“¾å¼æ€è€ƒï¼ˆSoCoTï¼‰æŽ¨ç†ç®¡é“å’ŒåŠ¨æ€ç¤¾ä¼šè®¤çŸ¥è®°å¿†ï¼ˆDSEMï¼‰æ¨¡å—ï¼Œæ¨¡åž‹èƒ½å¤Ÿé€æ­¥æŽ¨ç†å¹¶è®°å¿†å…³é”®çš„ç¤¾äº¤ä¿¡æ¯ï¼Œä»Žè€Œæé«˜æ¬ºéª—è¯†åˆ«çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¤šæ¨¡æ€è¾“å…¥ç¼–ç å™¨ï¼šç”¨äºŽå¤„ç†è§†é¢‘å’Œæ–‡æœ¬è¾“å…¥ï¼Œæå–ç›¸å…³çš„ç‰¹å¾è¡¨ç¤ºã€‚2) ç¤¾ä¼šé“¾å¼æ€è€ƒï¼ˆSoCoTï¼‰æŽ¨ç†ç®¡é“ï¼šå¼•å¯¼æ¨¡åž‹é€æ­¥æŽ¨ç†ç¤¾äº¤äº’åŠ¨ä¸­çš„å…³é”®ä¿¡æ¯ï¼Œä¾‹å¦‚å‚ä¸Žè€…çš„æ„å›¾ã€ä¿¡å¿µå’ŒçŸ¥è¯†ã€‚3) åŠ¨æ€ç¤¾ä¼šè®¤çŸ¥è®°å¿†ï¼ˆDSEMï¼‰æ¨¡å—ï¼šç”¨äºŽå­˜å‚¨å’Œæ›´æ–°ç¤¾äº¤äº’åŠ¨ä¸­çš„å…³é”®ä¿¡æ¯ï¼Œä¾‹å¦‚å‚ä¸Žè€…çš„å…³ç³»ã€åŽ†å²è¡Œä¸ºå’Œå½“å‰çŠ¶æ€ã€‚4) æ¬ºéª—æ£€æµ‹æ¨¡å—ï¼šåŸºäºŽç¼–ç åŽçš„ç‰¹å¾å’ŒæŽ¨ç†ç»“æžœï¼Œåˆ¤æ–­æ¯ä¸ªé™ˆè¿°çš„çœŸå‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ç¤¾ä¼šé“¾å¼æ€è€ƒï¼ˆSoCoTï¼‰æŽ¨ç†ç®¡é“å’ŒåŠ¨æ€ç¤¾ä¼šè®¤çŸ¥è®°å¿†ï¼ˆDSEMï¼‰æ¨¡å—ã€‚SoCoTé€šè¿‡å¼•å¯¼æ¨¡åž‹é€æ­¥æŽ¨ç†ï¼Œæ¨¡æ‹Ÿäº†äººç±»åœ¨ç¤¾äº¤äº’åŠ¨ä¸­çš„æ€è€ƒè¿‡ç¨‹ã€‚DSEMåˆ™å…è®¸æ¨¡åž‹åŠ¨æ€åœ°å­˜å‚¨å’Œæ›´æ–°ç¤¾äº¤ä¿¡æ¯ï¼Œä»Žè€Œæ›´å¥½åœ°ç†è§£ç¤¾äº¤äº’åŠ¨ä¸­çš„å¤æ‚åŠ¨æ€ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ›´æ³¨é‡å¯¹ç¤¾äº¤çº¿ç´¢çš„å»ºæ¨¡å’ŒæŽ¨ç†ï¼Œè€Œéžä»…ä»…ä¾èµ–äºŽè¡¨é¢çš„è¯­è¨€ç‰¹å¾ã€‚

**å…³é”®è®¾è®¡**ï¼šSoCoTæŽ¨ç†ç®¡é“çš„è®¾è®¡åŒ…æ‹¬å¤šä¸ªæŽ¨ç†æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤éƒ½æ—¨åœ¨æå–ç‰¹å®šçš„ç¤¾äº¤ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œç¬¬ä¸€ä¸ªæ­¥éª¤å¯èƒ½å…³æ³¨å‚ä¸Žè€…çš„æ„å›¾ï¼Œç¬¬äºŒä¸ªæ­¥éª¤å¯èƒ½å…³æ³¨å‚ä¸Žè€…çš„ä¿¡å¿µã€‚DSEMæ¨¡å—çš„è®¾è®¡åŒ…æ‹¬ä¸€ä¸ªè®°å¿†å•å…ƒå’Œä¸€ä¸ªæ›´æ–°æœºåˆ¶ã€‚è®°å¿†å•å…ƒç”¨äºŽå­˜å‚¨ç¤¾äº¤ä¿¡æ¯ï¼Œæ›´æ–°æœºåˆ¶ç”¨äºŽæ ¹æ®æ–°çš„ä¿¡æ¯æ›´æ–°è®°å¿†å•å…ƒã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡åŒ…æ‹¬ä¸€ä¸ªæ¬ºéª—æ£€æµ‹æŸå¤±å’Œä¸€ä¸ªæŽ¨ç†ä¸€è‡´æ€§æŸå¤±ã€‚æ¬ºéª—æ£€æµ‹æŸå¤±ç”¨äºŽè®­ç»ƒæ¨¡åž‹è¯†åˆ«æ¬ºéª—è¡Œä¸ºï¼ŒæŽ¨ç†ä¸€è‡´æ€§æŸå¤±ç”¨äºŽé¼“åŠ±æ¨¡åž‹è¿›è¡Œä¸€è‡´çš„æŽ¨ç†ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæå‡ºçš„SoCoTæŽ¨ç†ç®¡é“å’ŒDSEMæ¨¡å—èƒ½å¤Ÿæ˜¾è‘—æå‡MLLMsåœ¨MIDAåŸºå‡†ä¸Šçš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨GPT-4oæ¨¡åž‹ä¸Šï¼Œä½¿ç”¨SoCoTå’ŒDSEMåŽï¼Œæ¬ºéª—è¯†åˆ«å‡†ç¡®çŽ‡æå‡äº†çº¦5%-10%ã€‚æ­¤å¤–ï¼Œå®žéªŒè¿˜åˆ†æžäº†æ¨¡åž‹çš„å¤±è´¥æ¨¡å¼ï¼Œæ­ç¤ºäº†çŽ°æœ‰MLLMsåœ¨å¤„ç†å¤æ‚ç¤¾äº¤çº¿ç´¢æ–¹é¢çš„ä¸è¶³ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæ™ºèƒ½å®¢æœã€åœ¨çº¿ä¼šè®®ã€ç¤¾äº¤åª’ä½“ç›‘æŽ§ç­‰é¢†åŸŸï¼Œå¸®åŠ©è¯†åˆ«è™šå‡ä¿¡æ¯ã€æ¬ºè¯ˆè¡Œä¸ºå’Œæ¶æ„æ”»å‡»ã€‚é€šè¿‡æå‡AIç³»ç»Ÿåœ¨ç¤¾äº¤äº’åŠ¨ä¸­çš„æ„ŸçŸ¥å’ŒæŽ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥æž„å»ºæ›´å€¼å¾—ä¿¡èµ–å’Œå®‰å…¨çš„AIåº”ç”¨ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ä¸­çš„äººæœºäº¤äº’ï¼Œä»¥åŠåŒ»ç–—è¯Šæ–­ä¸­çš„æƒ…æ„Ÿåˆ†æžã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite their advanced reasoning capabilities, state-of-the-art Multimodal Large Language Models (MLLMs) demonstrably lack a core component of human intelligence: the ability to `read the room' and assess deception in complex social interactions. To rigorously quantify this failure, we introduce a new task, Multimodal Interactive Deception Assessment (MIDA), and present a novel multimodal dataset providing synchronized video and text with verifiable ground-truth labels for every statement. We establish a comprehensive benchmark evaluating 12 state-of-the-art open- and closed-source MLLMs, revealing a significant performance gap: even powerful models like GPT-4o struggle to distinguish truth from falsehood reliably. Our analysis of failure modes indicates that these models fail to effectively ground language in multimodal social cues and lack the ability to model what others know, believe, or intend, highlighting the urgent need for novel approaches to building more perceptive and trustworthy AI systems. To take a step forward, we design a Social Chain-of-Thought (SoCoT) reasoning pipeline and a Dynamic Social Epistemic Memory (DSEM) module. Our framework yields performance improvement on this challenging task, demonstrating a promising new path toward building MLLMs capable of genuine human-like social reasoning.

