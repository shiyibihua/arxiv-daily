---
layout: default
title: DynaMimicGen: A Data Generation Framework for Robot Learning of Dynamic Tasks
---

# DynaMimicGen: A Data Generation Framework for Robot Learning of Dynamic Tasks

**arXiv**: [2511.16223v1](https://arxiv.org/abs/2511.16223) | [PDF](https://arxiv.org/pdf/2511.16223.pdf)

**ä½œè€…**: Vincenzo Pomponi, Paolo Franceschi, Stefano Baraldo, Loris Roveda, Oliver Avram, Luca Maria Gambardella, Anna Valente

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDynaMimicGenæ¡†æž¶ä»¥è§£å†³åŠ¨æ€çŽ¯å¢ƒä¸­æœºå™¨äººå­¦ä¹ æ•°æ®ç¨€ç¼ºé—®é¢˜**

**å…³é”®è¯**: `æœºå™¨äººå­¦ä¹ ` `åŠ¨æ€ä»»åŠ¡` `æ•°æ®ç”Ÿæˆ` `æ¨¡ä»¿å­¦ä¹ ` `è½¨è¿¹ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŠ¨æ€çŽ¯å¢ƒä¸‹æœºå™¨äººå­¦ä¹ éœ€å¤§é‡æ•°æ®ï¼Œäººå·¥æ”¶é›†è€—æ—¶ä¸”ä¸å®žç”¨
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå°‘é‡æ¼”ç¤ºï¼Œåˆ†å‰²ä»»åŠ¡å¹¶ä½¿ç”¨åŠ¨æ€è¿åŠ¨åŸºå…ƒç”Ÿæˆé€‚åº”åŠ¨æ€å˜åŒ–çš„è½¨è¿¹
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨é•¿æ—¶ç¨‹å’ŒæŽ¥è§¦ä¸°å¯Œä»»åŠ¡ä¸­ï¼Œè®­ç»ƒä»£ç†åœ¨åŠ¨æ€å˜åŒ–ä¸‹è¡¨çŽ°ä¼˜å¼‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Learning robust manipulation policies typically requires large and diverse datasets, the collection of which is time-consuming, labor-intensive, and often impractical for dynamic environments. In this work, we introduce DynaMimicGen (D-MG), a scalable dataset generation framework that enables policy training from minimal human supervision while uniquely supporting dynamic task settings. Given only a few human demonstrations, D-MG first segments the demonstrations into meaningful sub-tasks, then leverages Dynamic Movement Primitives (DMPs) to adapt and generalize the demonstrated behaviors to novel and dynamically changing environments. Improving prior methods that rely on static assumptions or simplistic trajectory interpolation, D-MG produces smooth, realistic, and task-consistent Cartesian trajectories that adapt in real time to changes in object poses, robot states, or scene geometry during task execution. Our method supports different scenarios - including scene layouts, object instances, and robot configurations - making it suitable for both static and highly dynamic manipulation tasks. We show that robot agents trained via imitation learning on D-MG-generated data achieve strong performance across long-horizon and contact-rich benchmarks, including tasks like cube stacking and placing mugs in drawers, even under unpredictable environment changes. By eliminating the need for extensive human demonstrations and enabling generalization in dynamic settings, D-MG offers a powerful and efficient alternative to manual data collection, paving the way toward scalable, autonomous robot learning.

