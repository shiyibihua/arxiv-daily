---
layout: default
title: Graph Neural Networks for Surgical Scene Segmentation
---

# Graph Neural Networks for Surgical Scene Segmentation

**arXiv**: [2511.16430v1](https://arxiv.org/abs/2511.16430) | [PDF](https://arxiv.org/pdf/2511.16430.pdf)

**ä½œè€…**: Yihan Li, Nikhil Churamani, Maria Robu, Imanol Luengo, Danail Stoyanov

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå›¾ç¥žç»ç½‘ç»œæ–¹æ³•ä»¥æå‡æ‰‹æœ¯åœºæ™¯åˆ†å‰²çš„å‡†ç¡®æ€§å’Œè§£å‰–ä¸€è‡´æ€§**

**å…³é”®è¯**: `å›¾ç¥žç»ç½‘ç»œ` `æ‰‹æœ¯åœºæ™¯åˆ†å‰²` `Vision Transformer` `é•¿ç¨‹ä¾èµ–å»ºæ¨¡` `è§£å‰–ä¸€è‡´æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ·±åº¦å­¦ä¹ æ¨¡åž‹åœ¨é®æŒ¡ã€é•¿ç¨‹ä¾èµ–å’Œç²¾ç»†å‡ ä½•ç»“æž„åˆ†å‰²ä¸­è¡¨çŽ°ä¸ä½³
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆVision Transformerç¼–ç å™¨å’Œå›¾ç¥žç»ç½‘ç»œï¼Œå»ºæ¨¡è§£å‰–åŒºåŸŸç©ºé—´å…³ç³»
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŸºå‡†æµ‹è¯•ä¸­mIoUå’ŒmDiceåˆ†åˆ«æå‡7-8%å’Œ6%ï¼Œæ”¹å–„ç¨€æœ‰ç»“æž„åˆ†å‰²

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Purpose: Accurate identification of hepatocystic anatomy is critical to preventing surgical complications during laparoscopic cholecystectomy. Deep learning models often struggle with occlusions, long-range dependencies, and capturing the fine-scale geometry of rare structures. This work addresses these challenges by introducing graph-based segmentation approaches that enhance spatial and semantic understanding in surgical scene analyses.
>   Methods: We propose two segmentation models integrating Vision Transformer (ViT) feature encoders with Graph Neural Networks (GNNs) to explicitly model spatial relationships between anatomical regions. (1) A static k Nearest Neighbours (k-NN) graph with a Graph Convolutional Network with Initial Residual and Identity Mapping (GCNII) enables stable long-range information propagation. (2) A dynamic Differentiable Graph Generator (DGG) with a Graph Attention Network (GAT) supports adaptive topology learning. Both models are evaluated on the Endoscapes-Seg50 and CholecSeg8k benchmarks.
>   Results: The proposed approaches achieve up to 7-8% improvement in Mean Intersection over Union (mIoU) and 6% improvement in Mean Dice (mDice) scores over state-of-the-art baselines. It produces anatomically coherent predictions, particularly on thin, rare and safety-critical structures.
>   Conclusion: The proposed graph-based segmentation methods enhance both performance and anatomical consistency in surgical scene segmentation. By combining ViT-based global context with graph-based relational reasoning, the models improve interpretability and reliability, paving the way for safer laparoscopic and robot-assisted surgery through a precise identification of critical anatomical features.

