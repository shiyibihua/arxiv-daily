---
layout: default
title: When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models
---

# When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models

**arXiv**: [2511.16203v3](https://arxiv.org/abs/2511.16203) | [PDF](https://arxiv.org/pdf/2511.16203.pdf)

**ä½œè€…**: Yuping Yan, Yuhan Xie, Yixin Zhang, Lingjuan Lyu, Handing Wang, Yaochu Jin

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-20 (æ›´æ–°: 2025-12-11)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VLA-Foolï¼šé’ˆå¯¹å…·èº«è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹çš„å¤šæ¨¡æ€å¯¹æŠ—æ”»å‡»ç ”ç©¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `å¯¹æŠ—æ”»å‡»` `å¤šæ¨¡æ€å­¦ä¹ ` `å…·èº«æ™ºèƒ½` `é²æ£’æ€§` `è·¨æ¨¡æ€å¯¹é½` `è¯­ä¹‰ç©ºé—´`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VLAæ¨¡åž‹å¯¹æŠ—é²æ£’æ€§ç ”ç©¶ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤šæ¨¡æ€å’Œé»‘ç›’åœºæ™¯ä¸‹ï¼Œå¿½ç•¥äº†è·¨æ¨¡æ€è¯­ä¹‰å¯¹é½çš„é‡è¦æ€§ã€‚
2. è®ºæ–‡æå‡ºVLA-Foolæ¡†æž¶ï¼Œé€šè¿‡æ–‡æœ¬ã€è§†è§‰æ‰°åŠ¨å’Œè·¨æ¨¡æ€é”™ä½æ”»å‡»ï¼Œè¯„ä¼°VLAæ¨¡åž‹åœ¨å¯¹æŠ—çŽ¯å¢ƒä¸‹çš„æ€§èƒ½ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œå³ä½¿æ˜¯è½»å¾®çš„å¤šæ¨¡æ€æ‰°åŠ¨ä¹Ÿä¼šå¯¼è‡´VLAæ¨¡åž‹è¡Œä¸ºå‡ºçŽ°æ˜¾è‘—åå·®ï¼Œæ­ç¤ºäº†å…¶è„†å¼±æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹(VLA)åœ¨å…·èº«çŽ¯å¢ƒä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿé€šè¿‡ç»Ÿä¸€çš„å¤šæ¨¡æ€ç†è§£è¿›è¡Œæ„ŸçŸ¥ã€æŽ¨ç†å’Œè¡ŒåŠ¨ã€‚å°½ç®¡å®ƒä»¬çš„èƒ½åŠ›ä»¤äººå°è±¡æ·±åˆ»ï¼Œä½†è¿™äº›ç³»ç»Ÿåœ¨çŽ°å®žçš„å¤šæ¨¡æ€å’Œé»‘ç›’æ¡ä»¶ä¸‹çš„å¯¹æŠ—é²æ£’æ€§ä»æœªå¾—åˆ°å……åˆ†æŽ¢ç´¢ã€‚çŽ°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å•æ¨¡æ€æ‰°åŠ¨ï¼Œå¿½ç•¥äº†ä»Žæ ¹æœ¬ä¸Šå½±å“å…·èº«æŽ¨ç†å’Œå†³ç­–çš„è·¨æ¨¡æ€é”™ä½ã€‚æœ¬æ–‡æå‡ºäº†VLA-Foolï¼Œä¸€é¡¹é’ˆå¯¹å…·èº«VLAæ¨¡åž‹åœ¨ç™½ç›’å’Œé»‘ç›’è®¾ç½®ä¸‹å¤šæ¨¡æ€å¯¹æŠ—é²æ£’æ€§çš„å…¨é¢ç ”ç©¶ã€‚VLA-Foolç»Ÿä¸€äº†ä¸‰ä¸ªå±‚æ¬¡çš„å¤šæ¨¡æ€å¯¹æŠ—æ”»å‡»ï¼š(1)é€šè¿‡åŸºäºŽæ¢¯åº¦å’ŒåŸºäºŽæç¤ºçš„æ“çºµè¿›è¡Œæ–‡æœ¬æ‰°åŠ¨ï¼Œ(2)é€šè¿‡è¡¥ä¸å’Œå™ªå£°å¤±çœŸè¿›è¡Œè§†è§‰æ‰°åŠ¨ï¼Œ(3)æœ‰æ„ç ´åæ„ŸçŸ¥å’ŒæŒ‡ä»¤ä¹‹é—´è¯­ä¹‰å¯¹åº”å…³ç³»çš„è·¨æ¨¡æ€é”™ä½æ”»å‡»ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å°†VLAæ„ŸçŸ¥çš„è¯­ä¹‰ç©ºé—´æ•´åˆåˆ°è¯­è¨€æç¤ºä¸­ï¼Œå¼€å‘äº†ç¬¬ä¸€ä¸ªè‡ªåŠ¨ç”Ÿæˆå’Œè¯­ä¹‰å¼•å¯¼çš„æç¤ºæ¡†æž¶ã€‚ä½¿ç”¨å¾®è°ƒçš„OpenVLAæ¨¡åž‹åœ¨LIBEROåŸºå‡†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œå³ä½¿æ˜¯è½»å¾®çš„å¤šæ¨¡æ€æ‰°åŠ¨ä¹Ÿä¼šå¯¼è‡´æ˜¾è‘—çš„è¡Œä¸ºåå·®ï¼Œè¯æ˜Žäº†å…·èº«å¤šæ¨¡æ€å¯¹é½çš„è„†å¼±æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹ï¼ˆVLAï¼‰åœ¨å¯¹æŠ—æ”»å‡»ä¸‹çš„è„†å¼±æ€§é—®é¢˜ã€‚çŽ°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­äºŽå•æ¨¡æ€çš„æ‰°åŠ¨ï¼Œå¿½ç•¥äº†å¤šæ¨¡æ€ä¿¡æ¯ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ï¼Œè¿™å¯¹äºŽVLAæ¨¡åž‹åœ¨å…·èº«çŽ¯å¢ƒä¸­çš„æŽ¨ç†å’Œå†³ç­–è‡³å…³é‡è¦ã€‚å› æ­¤ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°è¯„ä¼°å’Œæå‡VLAæ¨¡åž‹åœ¨å¤šæ¨¡æ€å¯¹æŠ—æ”»å‡»ä¸‹çš„é²æ£’æ€§æ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æž„å»ºä¸€ä¸ªå…¨é¢çš„å¤šæ¨¡æ€å¯¹æŠ—æ”»å‡»æ¡†æž¶VLA-Foolï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°VLAæ¨¡åž‹åœ¨ä¸åŒç±»åž‹çš„æ”»å‡»ä¸‹çš„æ€§èƒ½ã€‚è¯¥æ¡†æž¶ä¸ä»…è€ƒè™‘äº†å•æ¨¡æ€çš„æ‰°åŠ¨ï¼ˆæ–‡æœ¬å’Œè§†è§‰ï¼‰ï¼Œè¿˜ç‰¹åˆ«å…³æ³¨äº†è·¨æ¨¡æ€çš„è¯­ä¹‰é”™ä½æ”»å‡»ï¼Œæ—¨åœ¨æ¨¡æ‹ŸçœŸå®žä¸–ç•Œä¸­å¯èƒ½å‡ºçŽ°çš„å„ç§å¯¹æŠ—åœºæ™¯ã€‚é€šè¿‡åˆ†æžæ¨¡åž‹åœ¨è¿™äº›æ”»å‡»ä¸‹çš„è¡¨çŽ°ï¼Œå¯ä»¥æ·±å…¥äº†è§£VLAæ¨¡åž‹çš„å¼±ç‚¹ï¼Œå¹¶ä¸ºåŽç»­çš„é²æ£’æ€§æå‡æä¾›æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šVLA-Foolæ¡†æž¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ–‡æœ¬æ‰°åŠ¨æ¨¡å—ã€è§†è§‰æ‰°åŠ¨æ¨¡å—å’Œè·¨æ¨¡æ€é”™ä½æ”»å‡»æ¨¡å—ã€‚æ–‡æœ¬æ‰°åŠ¨æ¨¡å—é€šè¿‡æ¢¯åº¦å’Œæç¤ºå·¥ç¨‹æ–¹æ³•ç”Ÿæˆå¯¹æŠ—æ€§æ–‡æœ¬æŒ‡ä»¤ã€‚è§†è§‰æ‰°åŠ¨æ¨¡å—åˆ™é€šè¿‡æ·»åŠ è¡¥ä¸æˆ–å™ªå£°æ¥å¹²æ‰°è§†è§‰è¾“å…¥ã€‚è·¨æ¨¡æ€é”™ä½æ”»å‡»æ¨¡å—æ—¨åœ¨ç ´åè§†è§‰å’Œè¯­è¨€ä¿¡æ¯ä¹‹é—´çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æž¶è¿˜å¼•å…¥äº†ä¸€ä¸ªVLAæ„ŸçŸ¥çš„è¯­ä¹‰ç©ºé—´ï¼Œç”¨äºŽæŒ‡å¯¼æç¤ºçš„ç”Ÿæˆï¼Œä»Žè€Œæé«˜æ”»å‡»çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€å¯¹æŠ—æ”»å‡»æ¡†æž¶ï¼Œè¯¥æ¡†æž¶ä¸ä»…è€ƒè™‘äº†å•æ¨¡æ€çš„æ‰°åŠ¨ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œå¼•å…¥äº†è·¨æ¨¡æ€é”™ä½æ”»å‡»çš„æ¦‚å¿µã€‚è¿™ç§æ”»å‡»æ–¹å¼èƒ½å¤Ÿæ›´çœŸå®žåœ°æ¨¡æ‹ŸçŽ°å®žä¸–ç•Œä¸­å¯èƒ½å‡ºçŽ°çš„å¯¹æŠ—åœºæ™¯ï¼Œä»Žè€Œæ›´æœ‰æ•ˆåœ°è¯„ä¼°VLAæ¨¡åž‹çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼ŒVLAæ„ŸçŸ¥çš„è¯­ä¹‰ç©ºé—´å’Œè‡ªåŠ¨æç¤ºç”Ÿæˆæ¡†æž¶ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ç‚¹ï¼Œèƒ½å¤Ÿæé«˜æ”»å‡»çš„æ•ˆçŽ‡å’Œæ•ˆæžœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ–‡æœ¬æ‰°åŠ¨æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†åŸºäºŽæ¢¯åº¦çš„æ–¹æ³•æ¥å¯»æ‰¾å¯¹æ¨¡åž‹å½±å“æœ€å¤§çš„è¯è¯­è¿›è¡Œæ›¿æ¢ã€‚åœ¨è§†è§‰æ‰°åŠ¨æ¨¡å—ä¸­ï¼Œé‡‡ç”¨äº†patchæ”»å‡»å’Œnoiseæ”»å‡»ä¸¤ç§æ–¹å¼ã€‚åœ¨è·¨æ¨¡æ€é”™ä½æ”»å‡»æ¨¡å—ä¸­ï¼Œé€šè¿‡æ›¿æ¢ä¸Žè§†è§‰ä¿¡æ¯ä¸ç›¸å…³çš„æ–‡æœ¬æè¿°æ¥ç ´åè¯­ä¹‰ä¸€è‡´æ€§ã€‚VLAæ„ŸçŸ¥çš„è¯­ä¹‰ç©ºé—´åˆ™é€šè¿‡åˆ†æžVLAæ¨¡åž‹çš„å†…éƒ¨è¡¨ç¤ºæ¥æž„å»ºï¼Œç”¨äºŽæŒ‡å¯¼æç¤ºçš„ç”Ÿæˆï¼Œç¡®ä¿ç”Ÿæˆçš„æç¤ºèƒ½å¤Ÿæœ‰æ•ˆåœ°æ¬ºéª—æ¨¡åž‹ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œå³ä½¿æ˜¯å¾®å°çš„å¤šæ¨¡æ€æ‰°åŠ¨ä¹Ÿèƒ½æ˜¾è‘—é™ä½ŽOpenVLAæ¨¡åž‹åœ¨LIBEROåŸºå‡†ä¸Šçš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œè·¨æ¨¡æ€é”™ä½æ”»å‡»å¯¼è‡´æ¨¡åž‹æˆåŠŸçŽ‡ä¸‹é™è¶…è¿‡30%ã€‚VLA-Foolæ¡†æž¶èƒ½å¤Ÿæœ‰æ•ˆåœ°è¯„ä¼°VLAæ¨¡åž‹çš„é²æ£’æ€§ï¼Œå¹¶æ­ç¤ºå…¶åœ¨å¤šæ¨¡æ€å¯¹æŠ—æ”»å‡»ä¸‹çš„è„†å¼±æ€§ï¼Œä¸ºåŽç»­çš„é˜²å¾¡ç ”ç©¶æä¾›äº†é‡è¦å‚è€ƒã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæå‡æœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„å¯é æ€§å’Œå®‰å…¨æ€§ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½å®¶å±…å’Œå·¥ä¸šæœºå™¨äººç­‰é¢†åŸŸã€‚é€šè¿‡å¢žå¼ºVLAæ¨¡åž‹å¯¹å¯¹æŠ—æ”»å‡»çš„é²æ£’æ€§ï¼Œå¯ä»¥å‡å°‘å› æ¶æ„æ”»å‡»æˆ–çŽ¯å¢ƒå¹²æ‰°å¯¼è‡´çš„æ„å¤–è¡Œä¸ºï¼Œæé«˜ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå®‰å…¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿæœ‰åŠ©äºŽå¼€å‘æ›´å®‰å…¨çš„AIç³»ç»Ÿï¼Œé˜²æ­¢å…¶è¢«æ¶æ„åˆ©ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language-Action models (VLAs) have recently demonstrated remarkable progress in embodied environments, enabling robots to perceive, reason, and act through unified multimodal understanding. Despite their impressive capabilities, the adversarial robustness of these systems remains largely unexplored, especially under realistic multimodal and black-box conditions. Existing studies mainly focus on single-modality perturbations and overlook the cross-modal misalignment that fundamentally affects embodied reasoning and decision-making. In this paper, we introduce VLA-Fool, a comprehensive study of multimodal adversarial robustness in embodied VLA models under both white-box and black-box settings. VLA-Fool unifies three levels of multimodal adversarial attacks: (1) textual perturbations through gradient-based and prompt-based manipulations, (2) visual perturbations via patch and noise distortions, and (3) cross-modal misalignment attacks that intentionally disrupt the semantic correspondence between perception and instruction. We further incorporate a VLA-aware semantic space into linguistic prompts, developing the first automatically crafted and semantically guided prompting framework. Experiments on the LIBERO benchmark using a fine-tuned OpenVLA model reveal that even minor multimodal perturbations can cause significant behavioral deviations, demonstrating the fragility of embodied multimodal alignment.

