---
layout: default
title: PSTF-AttControl: Per-Subject-Tuning-Free Personalized Image Generation with Controllable Face Attributes
---

# PSTF-AttControl: Per-Subject-Tuning-Free Personalized Image Generation with Controllable Face Attributes

**arXiv**: [2510.25084v1](https://arxiv.org/abs/2510.25084) | [PDF](https://arxiv.org/pdf/2510.25084.pdf)

**ä½œè€…**: Xiang liu, Zhaoxiang Liu, Huan Hu, Zipeng Wang, Ping Chen, Zezhou Chen, Kai Wang, Shiguo Lian

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPSTF-AttControlæ–¹æ³•ï¼Œå®žçŽ°å…è°ƒä¼˜ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆä¸Žå¯æŽ§é¢éƒ¨å±žæ€§ã€‚**

**å…³é”®è¯**: `ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆ` `é¢éƒ¨å±žæ€§æŽ§åˆ¶` `å…è°ƒä¼˜æ–¹æ³•` `StyleGAN2` `äººè„¸è¯†åˆ«` `UNetæž¶æž„`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•éš¾ä»¥åœ¨å…è°ƒä¼˜ä¸‹ç²¾ç¡®æŽ§åˆ¶é¢éƒ¨å±žæ€§ï¼Œé™åˆ¶ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆã€‚
2. ä½¿ç”¨äººè„¸è¯†åˆ«æ¨¡åž‹æå–èº«ä»½ç‰¹å¾ï¼Œç»“åˆTriplet-Decoupled Cross-Attentionæ¨¡å—åˆ†ç¦»èº«ä»½ä¸Žå±žæ€§ã€‚
3. åœ¨FFHQæ•°æ®é›†ä¸Šè®­ç»ƒï¼Œç”Ÿæˆå›¾åƒä¿ç•™èº«ä»½å¹¶æŽ§åˆ¶å±žæ€§ï¼Œæ— éœ€é¢å¤–è°ƒä¼˜ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advancements in personalized image generation have significantly
> improved facial identity preservation, particularly in fields such as
> entertainment and social media. However, existing methods still struggle to
> achieve precise control over facial attributes in a per-subject-tuning-free
> (PSTF) way. Tuning-based techniques like PreciseControl have shown promise by
> providing fine-grained control over facial features, but they often require
> extensive technical expertise and additional training data, limiting their
> accessibility. In contrast, PSTF approaches simplify the process by enabling
> image generation from a single facial input, but they lack precise control over
> facial attributes. In this paper, we introduce a novel, PSTF method that
> enables both precise control over facial attributes and high-fidelity
> preservation of facial identity. Our approach utilizes a face recognition model
> to extract facial identity features, which are then mapped into the $W^+$
> latent space of StyleGAN2 using the e4e encoder. We further enhance the model
> with a Triplet-Decoupled Cross-Attention module, which integrates facial
> identity, attribute features, and text embeddings into the UNet architecture,
> ensuring clean separation of identity and attribute information. Trained on the
> FFHQ dataset, our method allows for the generation of personalized images with
> fine-grained control over facial attributes, while without requiring additional
> fine-tuning or training data for individual identities. We demonstrate that our
> approach successfully balances personalization with precise facial attribute
> control, offering a more efficient and user-friendly solution for high-quality,
> adaptable facial image synthesis. The code is publicly available at
> https://github.com/UnicomAI/PSTF-AttControl.

