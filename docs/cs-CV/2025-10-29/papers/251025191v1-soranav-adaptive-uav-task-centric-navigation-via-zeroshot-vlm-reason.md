---
layout: default
title: SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning
---

# SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning

**arXiv**: [2510.25191v1](https://arxiv.org/abs/2510.25191) | [PDF](https://arxiv.org/pdf/2510.25191.pdf)

**ä½œè€…**: Hongyu Song, Rishabh Dev Yadav, Cheng Guo, Wei Pan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSoraNavæ¡†æž¶ï¼Œé€šè¿‡é›¶æ ·æœ¬VLMæŽ¨ç†ä¸Žå‡ ä½•æ„ŸçŸ¥å†³ç­–ï¼Œæå‡UAVåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„å¯¼èˆªæ€§èƒ½ã€‚**

**å…³é”®è¯**: `æ— äººæœºå¯¼èˆª` `è§†è§‰è¯­è¨€æ¨¡åž‹` `é›¶æ ·æœ¬æŽ¨ç†` `å‡ ä½•æ„ŸçŸ¥å†³ç­–` `æ··åˆåˆ‡æ¢ç­–ç•¥` `æ•°å­—å­ªç”Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰VLNæ–¹æ³•éš¾ä»¥æ³›åŒ–åˆ°UAVçš„3Dç©ºé—´æŽ¨ç†ä»»åŠ¡ï¼Œç¼ºä¹ç©ºé—´åŸºç¡€ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆé›¶æ ·æœ¬VLMæŽ¨ç†ä¸Žå‡ ä½•å…ˆéªŒï¼Œé‡‡ç”¨æ··åˆåˆ‡æ¢ç­–ç•¥ä¼˜åŒ–å¯¼èˆªå†³ç­–ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨2.5Då’Œ3Dåœºæ™¯ä¸­ï¼ŒæˆåŠŸçŽ‡å’Œè·¯å¾„é•¿åº¦åŠ æƒæˆåŠŸçŽ‡æ˜¾è‘—æå‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Interpreting visual observations and natural language instructions for
> complex task execution remains a key challenge in robotics and AI. Despite
> recent advances, language-driven navigation is still difficult, particularly
> for UAVs in small-scale 3D environments. Existing Vision-Language Navigation
> (VLN) approaches are mostly designed for ground robots and struggle to
> generalize to aerial tasks that require full 3D spatial reasoning. The
> emergence of large Vision-Language Models (VLMs), such as GPT and Claude,
> enables zero-shot semantic reasoning from visual and textual inputs. However,
> these models lack spatial grounding and are not directly applicable to
> navigation. To address these limitations, SoraNav is introduced, an adaptive
> UAV navigation framework that integrates zero-shot VLM reasoning with
> geometry-aware decision-making. Geometric priors are incorporated into image
> annotations to constrain the VLM action space and improve decision quality. A
> hybrid switching strategy leverages navigation history to alternate between VLM
> reasoning and geometry-based exploration, mitigating dead-ends and redundant
> revisits. A PX4-based hardware-software platform, comprising both a digital
> twin and a physical micro-UAV, enables reproducible evaluation. Experimental
> results show that in 2.5D scenarios, our method improves Success Rate (SR) by
> 25.7% and Success weighted by Path Length (SPL) by 17%. In 3D scenarios, it
> improves SR by 29.5% and SPL by 18.5% relative to the baseline.

