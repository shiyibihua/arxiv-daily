---
layout: default
title: Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning
---

# Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning

**arXiv**: [2510.25405v1](https://arxiv.org/abs/2510.25405) | [PDF](https://arxiv.org/pdf/2510.25405.pdf)

**ä½œè€…**: Kei Ikemura, Yifei Dong, David Blanco-Mulero, Alberta Longhini, Li Chen, Florian T. Pokorny

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåº”åŠ›å¼•å¯¼å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå®žçŽ°æ¨¡æ‹Ÿåˆ°çœŸå®žä¸–ç•Œä¸­å¯¹æ˜“å˜å½¢å’Œæ˜“ç¢Žç‰©ä½“çš„è½»æŸ”æ“ä½œ**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `å¼ºåŒ–å­¦ä¹ ` `æ¨¡æ‹Ÿåˆ°çœŸå®žè¿ç§»` `åº”åŠ›å¼•å¯¼` `æ˜“ç¢Žç‰©ä½“` `è¯¾ç¨‹å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨äººæ“ä½œæ˜“å˜å½¢å’Œæ˜“ç¢Žç‰©ä½“æ—¶ï¼Œåº”åŠ›è¿‡å¤§æ˜“å¯¼è‡´ä¸å¯é€†æŸä¼¤ï¼ŒçŽ°æœ‰æ–¹æ³•ä¾èµ–ç²¾ç¡®æ¨¡åž‹æˆ–ä¸“ç”¨è®¾å¤‡ï¼Œæ³›åŒ–æ€§å·®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åŸºäºŽè§†è§‰çš„å¼ºåŒ–å­¦ä¹ ï¼Œå¼•å…¥åº”åŠ›æƒ©ç½šå¥–åŠ±ï¼Œç»“åˆç¦»çº¿æ¼”ç¤ºå’Œä»Žåˆšæ€§ä»£ç†åˆ°æ˜“å˜å½¢ç‰©ä½“çš„è¯¾ç¨‹å­¦ä¹ ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žä¸–ç•Œè¯„ä¼°ä¸­ï¼Œé›¶æ ·æœ¬è¿ç§»ç­–ç•¥é™ä½Žåº”åŠ›36.5%ï¼Œå®žçŽ°ä»»åŠ¡ç›®æ ‡å¹¶å±•ç¤ºè½»æŸ”æ“ä½œè¡Œä¸ºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Robotic manipulation of deformable and fragile objects presents significant
> challenges, as excessive stress can lead to irreversible damage to the object.
> While existing solutions rely on accurate object models or specialized sensors
> and grippers, this adds complexity and often lacks generalization. To address
> this problem, we present a vision-based reinforcement learning approach that
> incorporates a stress-penalized reward to discourage damage to the object
> explicitly. In addition, to bootstrap learning, we incorporate offline
> demonstrations as well as a designed curriculum progressing from rigid proxies
> to deformables. We evaluate the proposed method in both simulated and
> real-world scenarios, showing that the policy learned in simulation can be
> transferred to the real world in a zero-shot manner, performing tasks such as
> picking up and pushing tofu. Our results show that the learned policies exhibit
> a damage-aware, gentle manipulation behavior, demonstrating their effectiveness
> by decreasing the stress applied to fragile objects by 36.5% while achieving
> the task goals, compared to vanilla RL policies.

