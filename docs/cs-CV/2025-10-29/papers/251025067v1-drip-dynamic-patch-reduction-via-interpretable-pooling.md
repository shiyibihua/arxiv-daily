---
layout: default
title: DRIP: Dynamic patch Reduction via Interpretable Pooling
---

# DRIP: Dynamic patch Reduction via Interpretable Pooling

**arXiv**: [2510.25067v1](https://arxiv.org/abs/2510.25067) | [PDF](https://arxiv.org/pdf/2510.25067.pdf)

**ä½œè€…**: Yusen Peng, Sachin Kumar

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDRIPæ–¹æ³•ä»¥é™ä½Žè§†è§‰è¯­è¨€æ¨¡åž‹é¢„è®­ç»ƒè®¡ç®—æˆæœ¬**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡åž‹` `åŠ¨æ€ä»¤ç‰Œåˆå¹¶` `è®¡ç®—æ•ˆçŽ‡ä¼˜åŒ–` `å¯¹æ¯”é¢„è®­ç»ƒ` `å›¾åƒåˆ†ç±»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡åž‹é¢„è®­ç»ƒè®¡ç®—æˆæœ¬é«˜ï¼Œé˜»ç¢ä»Žå¤´è®­ç»ƒã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å¯è§£é‡Šæ± åŒ–åŠ¨æ€åˆå¹¶è§†è§‰ç¼–ç å™¨æ·±å±‚ä»¤ç‰Œï¼Œé€‚åº”è¾“å…¥å›¾åƒã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨ImageNetå’ŒCLIPé¢„è®­ç»ƒä¸­æ˜¾è‘—å‡å°‘GFLOPï¼Œä¿æŒæ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recently, the advances in vision-language models, including contrastive
> pretraining and instruction tuning, have greatly pushed the frontier of
> multimodal AI. However, owing to the large-scale and hence expensive
> pretraining, the efficiency concern has discouraged researchers from attempting
> to pretrain a vision language model from scratch. In this work, we propose
> Dynamic patch Reduction via Interpretable Pooling (DRIP), which adapts to the
> input images and dynamically merges tokens in the deeper layers of a visual
> encoder. Our results on both ImageNet training from scratch and CLIP
> contrastive pretraining demonstrate a significant GFLOP reduction while
> maintaining comparable classification/zero-shot performance. To further
> validate our proposed method, we conduct continual pretraining on a large
> biology dataset, extending its impact into scientific domains.

