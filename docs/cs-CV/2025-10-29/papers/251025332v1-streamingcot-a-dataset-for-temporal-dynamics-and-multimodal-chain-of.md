---
layout: default
title: StreamingCoT: A Dataset for Temporal Dynamics and Multimodal Chain-of-Thought Reasoning in Streaming VideoQA
---

# StreamingCoT: A Dataset for Temporal Dynamics and Multimodal Chain-of-Thought Reasoning in Streaming VideoQA

**arXiv**: [2510.25332v1](https://arxiv.org/abs/2510.25332) | [PDF](https://arxiv.org/pdf/2510.25332.pdf)

**ä½œè€…**: Yuhang Hu, Zhenyu Yang, Shihan Wang, Shengsheng Qian, Bin Wen, Fan Yang, Tingting Gao, Changsheng Xu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºStreamingCoTæ•°æ®é›†ä»¥è§£å†³æµè§†é¢‘é—®ç­”ä¸­åŠ¨æ€æŽ¨ç†å’Œè§£é‡Šæ€§ä¸è¶³çš„é—®é¢˜**

**å…³é”®è¯**: `æµè§†é¢‘é—®ç­”` `å¤šæ¨¡æ€æŽ¨ç†` `æ—¶é—´åŠ¨æ€ç†è§£` `é“¾å¼æ€ç»´` `æ•°æ®é›†æž„å»º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰VideoQAæ•°æ®é›†ç¼ºä¹åŠ¨æ€ç­”æ¡ˆæ ‡æ³¨å’Œæ˜¾å¼æŽ¨ç†è¿‡ç¨‹ï¼Œé™åˆ¶æ¨¡åž‹å¯¹æ—¶é—´æ¼”åŒ–çš„ç†è§£
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºåŠ¨æ€åˆ†å±‚æ ‡æ³¨æž¶æž„ï¼Œç”Ÿæˆæ¯ç§’æè¿°å’Œè¯­ä¹‰æ®µï¼Œå¹¶æå–åŸºäºŽå¯¹è±¡çŠ¶æ€è½¬æ¢çš„æŽ¨ç†é“¾
3. å®žéªŒæˆ–æ•ˆæžœï¼šæœªçŸ¥ï¼Œä½†æ•°æ®é›†ä¸ºæµè§†é¢‘ç†è§£ã€å¤æ‚æŽ¨ç†å’Œå¤šæ¨¡æ€æŽ¨æ–­ç ”ç©¶æä¾›åŸºç¡€

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The rapid growth of streaming video applications demands multimodal models
> with enhanced capabilities for temporal dynamics understanding and complex
> reasoning. However, current Video Question Answering (VideoQA) datasets suffer
> from two critical limitations: 1) Static annotation mechanisms fail to capture
> the evolving nature of answers in temporal video streams, and 2) The absence of
> explicit reasoning process annotations restricts model interpretability and
> logical deduction capabilities. To address these challenges, We introduce
> StreamingCoT, the first dataset explicitly designed for temporally evolving
> reasoning in streaming VideoQA and multimodal Chain-of-Thought (CoT) tasks. Our
> framework first establishes a dynamic hierarchical annotation architecture that
> generates per-second dense descriptions and constructs temporally-dependent
> semantic segments through similarity fusion, paired with question-answer sets
> constrained by temporal evolution patterns. We further propose an explicit
> reasoning chain generation paradigm that extracts spatiotemporal objects via
> keyframe semantic alignment, derives object state transition-based reasoning
> paths using large language models, and ensures logical coherence through
> human-verified validation. This dataset establishes a foundation for advancing
> research in streaming video understanding, complex temporal reasoning, and
> multimodal inference. Our StreamingCoT and its construction toolkit can be
> accessed at https://github.com/Fleeting-hyh/StreamingCoT.

