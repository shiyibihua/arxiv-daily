---
layout: default
title: GaTector+: A Unified Head-free Framework for Gaze Object and Gaze Following Prediction
---

# GaTector+: A Unified Head-free Framework for Gaze Object and Gaze Following Prediction

**arXiv**: [2510.25301v1](https://arxiv.org/abs/2510.25301) | [PDF](https://arxiv.org/pdf/2510.25301.pdf)

**ä½œè€…**: Yang Jin, Guangyu Guo, Binglu Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGaTector+ç»Ÿä¸€æ¡†æž¶ï¼Œè§£å†³æ³¨è§†å¯¹è±¡æ£€æµ‹ä¸Žæ³¨è§†è·Ÿéšä»»åŠ¡ä¸­ä¾èµ–å¤´éƒ¨å…ˆéªŒçŸ¥è¯†çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ³¨è§†å¯¹è±¡æ£€æµ‹` `æ³¨è§†è·Ÿéš` `ç»Ÿä¸€æ¡†æž¶` `å¤´éƒ¨æ£€æµ‹` `æ³¨æ„åŠ›æœºåˆ¶` `è¯„ä¼°æŒ‡æ ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•ä¾èµ–å¤´éƒ¨å…ˆéªŒçŸ¥è¯†ï¼Œéœ€è¾…åŠ©ç½‘ç»œæå–å¤´éƒ¨ä½ç½®ï¼Œé™åˆ¶ç³»ç»Ÿè”åˆä¼˜åŒ–ä¸Žå®žé™…åº”ç”¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ‰©å±•ç‰¹å®š-é€šç”¨-ç‰¹å®šç‰¹å¾æå–å™¨ï¼Œç»“åˆå¤´éƒ¨æ£€æµ‹åˆ†æ”¯å’ŒåŸºäºŽå¤´éƒ¨çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ¶ˆé™¤æŽ¨ç†æ—¶å¯¹å¤´éƒ¨å…ˆéªŒçš„ä¾èµ–ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸ŠéªŒè¯æ¨¡åž‹åœ¨æ³¨è§†å¯¹è±¡æ£€æµ‹å’Œæ³¨è§†è·Ÿéšä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Gaze object detection and gaze following are fundamental tasks for
> interpreting human gaze behavior or intent. However, most previous methods
> usually solve these two tasks separately, and their prediction of gaze objects
> and gaze following typically depend on head-related prior knowledge during both
> the training phase and real-world deployment. This dependency necessitates an
> auxiliary network to extract head location, thus precluding joint optimization
> across the entire system and constraining the practical applicability. To this
> end, we propose GaTector+, a unified framework for gaze object detection and
> gaze following, which eliminates the dependence on the head-related priors
> during inference. Specifically, GaTector+ uses an expanded
> specific-general-specific feature extractor that leverages a shared backbone,
> which extracts general features for gaze following and object detection using
> the shared backbone while using specific blocks before and after the shared
> backbone to better consider the specificity of each sub-task. To obtain
> head-related knowledge without prior information, we first embed a head
> detection branch to predict the head of each person. Then, before regressing
> the gaze point, a head-based attention mechanism is proposed to fuse the sense
> feature and gaze feature with the help of head location. Since the
> suboptimization of the gaze point heatmap leads to the performance bottleneck,
> we propose an attention supervision mechanism to accelerate the learning of the
> gaze heatmap. Finally, we propose a novel evaluation metric, mean Similarity
> over Candidates (mSoC), for gaze object detection, which is more sensitive to
> variations between bounding boxes. The experimental results on multiple
> benchmark datasets demonstrate the effectiveness of our model in both gaze
> object detection and gaze following tasks.

