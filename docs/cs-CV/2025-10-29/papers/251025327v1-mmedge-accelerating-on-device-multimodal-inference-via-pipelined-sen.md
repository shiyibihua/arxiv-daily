---
layout: default
title: MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding
---

# MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding

**arXiv**: [2510.25327v1](https://arxiv.org/abs/2510.25327) | [PDF](https://arxiv.org/pdf/2510.25327.pdf)

**ä½œè€…**: Runxi Huang, Mingxuan Yu, Mingyu Tsoi, Xiaomin Ouyang

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMMEdgeæ¡†æ¶ï¼Œé€šè¿‡æµæ°´çº¿æ„ŸçŸ¥ä¸ç¼–ç åŠ é€Ÿè¾¹ç¼˜è®¾å¤‡å¤šæ¨¡æ€æ¨ç†ã€‚**

**å…³é”®è¯**: `è¾¹ç¼˜è®¡ç®—` `å¤šæ¨¡æ€æ¨ç†` `æµæ°´çº¿å¤„ç†` `è‡ªé€‚åº”ä¼˜åŒ–` `å®æ—¶ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè¾¹ç¼˜è®¾å¤‡å¤šæ¨¡æ€æ¨ç†ä¸­æ„ŸçŸ¥åŠ¨æ€ä¸æ¨¡å‹æ‰§è¡Œç´§è€¦åˆï¼Œå¿½ç•¥æ¨¡æ€é—´ä¾èµ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ†è§£æ¨ç†ä¸ºç»†ç²’åº¦å•å…ƒï¼Œå¼•å…¥æ—¶é—´èšåˆæ¨¡å—å’Œè‡ªé€‚åº”ä¼˜åŒ–æœºåˆ¶ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šåœ¨æ— äººæœºæµ‹è¯•ä¸­æ˜¾è‘—é™ä½å»¶è¿Ÿï¼Œä¿æŒé«˜ä»»åŠ¡å‡†ç¡®æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Real-time multimodal inference on resource-constrained edge devices is
> essential for applications such as autonomous driving, human-computer
> interaction, and mobile health. However, prior work often overlooks the tight
> coupling between sensing dynamics and model execution, as well as the complex
> inter-modality dependencies. In this paper, we propose MMEdge, an new on-device
> multi-modal inference framework based on pipelined sensing and encoding.
> Instead of waiting for complete sensor inputs, MMEdge decomposes the entire
> inference process into a sequence of fine-grained sensing and encoding units,
> allowing computation to proceed incrementally as data arrive. MMEdge also
> introduces a lightweight but effective temporal aggregation module that
> captures rich temporal dynamics across different pipelined units to maintain
> accuracy performance. Such pipelined design also opens up opportunities for
> fine-grained cross-modal optimization and early decision-making during
> inference. To further enhance system performance under resource variability and
> input data complexity, MMEdge incorporates an adaptive multimodal configuration
> optimizer that dynamically selects optimal sensing and model configurations for
> each modality under latency constraints, and a cross-modal speculative skipping
> mechanism that bypasses future units of slower modalities when early
> predictions reach sufficient confidence. We evaluate MMEdge using two public
> multimodal datasets and deploy it on a real-world unmanned aerial vehicle
> (UAV)-based multimodal testbed. The results show that MMEdge significantly
> reduces end-to-end latency while maintaining high task accuracy across various
> system and data dynamics.

