---
layout: default
title: Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation
---

# Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation

**arXiv**: [2510.25279v1](https://arxiv.org/abs/2510.25279) | [PDF](https://arxiv.org/pdf/2510.25279.pdf)

**ä½œè€…**: Yuyang Huang, Yabo Chen, Junyu Zhou, Wenrui Dai, Xiaopeng Zhang, Junni Zou, Hongkai Xiong, Qi Tian

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ‰©æ•£é©±åŠ¨æ¸è¿›ç›®æ ‡æ“çºµæ¡†æž¶ä»¥è§£å†³æºè‡ªç”±åŸŸé€‚åº”ä¸­çš„å¤§åŸŸå·®å¼‚é—®é¢˜**

**å…³é”®è¯**: `æºè‡ªç”±åŸŸé€‚åº”` `æ‰©æ•£æ¨¡åž‹` `ä¼ªæ ‡ç­¾ç”Ÿæˆ` `æ¸è¿›ç»†åŒ–` `åŸŸå·®å¼‚å‡å°‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æºè‡ªç”±åŸŸé€‚åº”é¢ä¸´å¤§åŸŸå·®å¼‚å¯¼è‡´ä¼ªæ ‡ç­¾ä¸å¯é å’Œç”Ÿæˆæ–¹æ³•æ€§èƒ½ä¸‹é™çš„æ ¸å¿ƒé—®é¢˜
2. æ–¹æ³•åŒ…æ‹¬åŸºäºŽä¼ªæ ‡ç­¾å¯é æ€§åˆ’åˆ†æ ·æœ¬é›†ã€ä½¿ç”¨æ½œåœ¨æ‰©æ•£æ¨¡åž‹è¿›è¡Œè¯­ä¹‰è½¬æ¢å’Œæ¸è¿›ç»†åŒ–æœºåˆ¶
3. å®žéªŒåœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®žçŽ°SOTAæ€§èƒ½ï¼Œå¤§åŸŸå·®å¼‚åœºæ™¯ä¸‹æ€§èƒ½æå‡é«˜è¾¾18.6%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Source-free domain adaptation (SFDA) is a challenging task that tackles
> domain shifts using only a pre-trained source model and unlabeled target data.
> Existing SFDA methods are restricted by the fundamental limitation of
> source-target domain discrepancy. Non-generation SFDA methods suffer from
> unreliable pseudo-labels in challenging scenarios with large domain
> discrepancies, while generation-based SFDA methods are evidently degraded due
> to enlarged domain discrepancies in creating pseudo-source data. To address
> this limitation, we propose a novel generation-based framework named
> Diffusion-Driven Progressive Target Manipulation (DPTM) that leverages
> unlabeled target data as references to reliably generate and progressively
> refine a pseudo-target domain for SFDA. Specifically, we divide the target
> samples into a trust set and a non-trust set based on the reliability of
> pseudo-labels to sufficiently and reliably exploit their information. For
> samples from the non-trust set, we develop a manipulation strategy to
> semantically transform them into the newly assigned categories, while
> simultaneously maintaining them in the target distribution via a latent
> diffusion model. Furthermore, we design a progressive refinement mechanism that
> progressively reduces the domain discrepancy between the pseudo-target domain
> and the real target domain via iterative refinement. Experimental results
> demonstrate that DPTM outperforms existing methods by a large margin and
> achieves state-of-the-art performance on four prevailing SFDA benchmark
> datasets with different scales. Remarkably, DPTM can significantly enhance the
> performance by up to 18.6% in scenarios with large source-target gaps.

