---
layout: default
title: Transformers in Medicine: Improving Vision-Language Alignment for Medical Image Captioning
---

# Transformers in Medicine: Improving Vision-Language Alignment for Medical Image Captioning

**arXiv**: [2510.25164v1](https://arxiv.org/abs/2510.25164) | [PDF](https://arxiv.org/pdf/2510.25164.pdf)

**ä½œè€…**: Yogesh Thakku Suresh, Vishwajeet Shivaji Hogale, Luca-Alexandru Zamfira, Anandavardhana Hegde

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽTransformerçš„å¤šæ¨¡æ€æ¡†æž¶ï¼Œä»¥æ”¹è¿›åŒ»å­¦MRIå›¾åƒæè¿°ä¸­çš„è§†è§‰-è¯­è¨€å¯¹é½ã€‚**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒæè¿°` `è§†è§‰-è¯­è¨€å¯¹é½` `Transformeræž¶æž„` `MRIå›¾åƒåˆ†æž` `å¯¹æ¯”å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŒ»å­¦MRIå›¾åƒæè¿°ä¸­è§†è§‰ä¸Žæ–‡æœ¬è¯­ä¹‰å¯¹é½ä¸è¶³ï¼Œå½±å“ä¸´åºŠç›¸å…³æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆDEiT-Smallè§†è§‰Transformerã€MediCareBERTå’ŒLSTMè§£ç å™¨ï¼Œä½¿ç”¨æ··åˆæŸå¤±å’Œå¯¹æ¯”æŽ¨ç†ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨MultiCaReæ•°æ®é›†ä¸ŠéªŒè¯ï¼Œä¸“æ³¨è„‘éƒ¨MRIæå‡æè¿°å‡†ç¡®æ€§å’Œè¯­ä¹‰å¯¹é½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present a transformer-based multimodal framework for generating clinically
> relevant captions for MRI scans. Our system combines a DEiT-Small vision
> transformer as an image encoder, MediCareBERT for caption embedding, and a
> custom LSTM-based decoder. The architecture is designed to semantically align
> image and textual embeddings, using hybrid cosine-MSE loss and contrastive
> inference via vector similarity. We benchmark our method on the MultiCaRe
> dataset, comparing performance on filtered brain-only MRIs versus general MRI
> images against state-of-the-art medical image captioning methods including
> BLIP, R2GenGPT, and recent transformer-based approaches. Results show that
> focusing on domain-specific data improves caption accuracy and semantic
> alignment. Our work proposes a scalable, interpretable solution for automated
> medical image reporting.

