---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-10-29
---

# cs.CVï¼ˆ2025-10-29ï¼‰

ğŸ“Š å…± **16** ç¯‡è®ºæ–‡
 | ğŸ”— **5** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (6 ğŸ”—3)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (3)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (2 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction" class="interest-badge">æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (6 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251025327v5-mmedge-accelerating-on-device-multimodal-inference-via-pipelined-sen.html">MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding</a></td>
  <td>MMEdgeï¼šé€šè¿‡æµæ°´çº¿å¼æ„ŸçŸ¥ä¸ç¼–ç åŠ é€Ÿè®¾å¤‡ç«¯å¤šæ¨¡æ€æ¨ç†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25327v5" onclick="toggleFavorite(this, '2510.25327v5', 'MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251025175v1-test-time-adaptive-object-detection-with-foundation-model.html">Test-Time Adaptive Object Detection with Foundation Model</a></td>
  <td>æå‡ºåŸºäºåŸºç¡€æ¨¡å‹çš„æµ‹è¯•æ—¶è‡ªé€‚åº”ç›®æ ‡æ£€æµ‹æ–¹æ³•ä»¥è§£å†³æºæ•°æ®ä¾èµ–é—®é¢˜</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25175v1" onclick="toggleFavorite(this, '2510.25175v1', 'Test-Time Adaptive Object Detection with Foundation Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251026027v1-enhancing-temporal-understanding-in-video-llms-through-stacked-tempo.html">Enhancing Temporal Understanding in Video-LLMs through Stacked Temporal Attention in Vision Encoders</a></td>
  <td>æå‡ºSTAVEï¼Œé€šè¿‡åœ¨è§†è§‰ç¼–ç å™¨ä¸­å †å æ—¶é—´æ³¨æ„åŠ›å¢å¼ºVideo-LLMçš„æ—¶é—´ç†è§£èƒ½åŠ›</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26027v1" onclick="toggleFavorite(this, '2510.26027v1', 'Enhancing Temporal Understanding in Video-LLMs through Stacked Temporal Attention in Vision Encoders')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251100073v1-habitat-and-land-cover-change-detection-in-alpine-protected-areas-a-.html">Habitat and Land Cover Change Detection in Alpine Protected Areas: A Comparison of AI Architectures</a></td>
  <td>å¯¹æ¯”AIæ¶æ„ï¼Œè§£å†³é«˜å±±ä¿æŠ¤åŒºç”Ÿå¢ƒå’ŒåœŸåœ°è¦†ç›–å˜åŒ–æ£€æµ‹éš¾é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.00073v1" onclick="toggleFavorite(this, '2511.00073v1', 'Habitat and Land Cover Change Detection in Alpine Protected Areas: A Comparison of AI Architectures')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251026006v1-cave-detecting-and-explaining-commonsense-anomalies-in-visual-enviro.html">CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments</a></td>
  <td>CAVEï¼šæå‡ºç”¨äºæ£€æµ‹å’Œè§£é‡Šè§†è§‰ç¯å¢ƒä¸­å¸¸è¯†å¼‚å¸¸çš„åŸºå‡†æ•°æ®é›†ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26006v1" onclick="toggleFavorite(this, '2510.26006v1', 'CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251025238v2-vadb-a-large-scale-video-aesthetic-database-with-professional-and-mu.html">VADB: A Large-Scale Video Aesthetic Database with Professional and Multi-Dimensional Annotations</a></td>
  <td>æå‡ºVADBæ•°æ®åº“ä¸VADB-Netæ¡†æ¶ä»¥è§£å†³è§†é¢‘ç¾å­¦è¯„ä¼°é—®é¢˜</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25238v2" onclick="toggleFavorite(this, '2510.25238v2', 'VADB: A Large-Scale Video Aesthetic Database with Professional and Multi-Dimensional Annotations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>7</td>
  <td><a href="./papers/251025173v2-d2gs-dense-depth-regularization-for-lidar-free-urban-scene-reconstru.html">D$^2$GS: Dense Depth Regularization for LiDAR-free Urban Scene Reconstruction</a></td>
  <td>æå‡ºD$^2$GSä»¥è§£å†³æ— LiDARåŸå¸‚åœºæ™¯é‡å»ºé—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25173v2" onclick="toggleFavorite(this, '2510.25173v2', 'D$^2$GS: Dense Depth Regularization for LiDAR-free Urban Scene Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251025263v2-langhops-language-grounded-hierarchical-open-vocabulary-part-segment.html">LangHOPS: Language Grounded Hierarchical Open-Vocabulary Part Segmentation</a></td>
  <td>LangHOPSï¼šæå‡ºä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å¼€æ”¾è¯æ±‡åˆ†å±‚éƒ¨ä»¶åˆ†å‰²æ¡†æ¶ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25263v2" onclick="toggleFavorite(this, '2510.25263v2', 'LangHOPS: Language Grounded Hierarchical Open-Vocabulary Part Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251025463v1-spade-sparsity-adaptive-depth-estimator-for-zero-shot-real-time-mono.html">SPADE: Sparsity Adaptive Depth Estimator for Zero-Shot, Real-Time, Monocular Depth Estimation in Underwater Environments</a></td>
  <td>SPADEï¼šä¸€ç§æ°´ä¸‹é›¶æ ·æœ¬ã€å®æ—¶ã€å•ç›®æ·±åº¦ä¼°è®¡çš„ç¨€ç–è‡ªé€‚åº”æ·±åº¦ä¼°è®¡å™¨</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25463v1" onclick="toggleFavorite(this, '2510.25463v1', 'SPADE: Sparsity Adaptive Depth Estimator for Zero-Shot, Real-Time, Monocular Depth Estimation in Underwater Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>10</td>
  <td><a href="./papers/251025332v1-streamingcot-a-dataset-for-temporal-dynamics-and-multimodal-chain-of.html">StreamingCoT: A Dataset for Temporal Dynamics and Multimodal Chain-of-Thought Reasoning in Streaming VideoQA</a></td>
  <td>æå‡ºStreamingCoTæ•°æ®é›†ï¼Œç”¨äºæµè§†é¢‘é—®ç­”ä¸­çš„æ—¶åºåŠ¨æ€ç†è§£å’Œå¤šæ¨¡æ€æ€ç»´é“¾æ¨ç†ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25332v1" onclick="toggleFavorite(this, '2510.25332v1', 'StreamingCoT: A Dataset for Temporal Dynamics and Multimodal Chain-of-Thought Reasoning in Streaming VideoQA')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251025345v1-informative-sample-selection-model-for-skeleton-based-action-recogni.html">Informative Sample Selection Model for Skeleton-based Action Recognition with Limited Training Samples</a></td>
  <td>æå‡ºåŸºäºMDPçš„éª¨éª¼åŠ¨ä½œè¯†åˆ«ä¿¡æ¯æ ·æœ¬é€‰æ‹©æ¨¡å‹ï¼Œæå‡æœ‰é™æ ·æœ¬ä¸‹çš„è¯†åˆ«ç²¾åº¦ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25345v1" onclick="toggleFavorite(this, '2510.25345v1', 'Informative Sample Selection Model for Skeleton-based Action Recognition with Limited Training Samples')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>12</td>
  <td><a href="./papers/251025257v1-rt-detrv4-painlessly-furthering-real-time-object-detection-with-visi.html">RT-DETRv4: Painlessly Furthering Real-Time Object Detection with Vision Foundation Models</a></td>
  <td>RT-DETRv4ï¼šåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹ï¼Œæ— ç—›æå‡å®æ—¶ç›®æ ‡æ£€æµ‹æ€§èƒ½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25257v1" onclick="toggleFavorite(this, '2510.25257v1', 'RT-DETRv4: Painlessly Furthering Real-Time Object Detection with Vision Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251026001v2-larger-hausdorff-dimension-in-scanning-pattern-facilitates-mamba-bas.html">Larger Hausdorff Dimension in Scanning Pattern Facilitates Mamba-Based Methods in Low-Light Image Enhancement</a></td>
  <td>æå‡ºåŸºäºHilbertæ‰«æMambaçš„ä½å…‰å›¾åƒå¢å¼ºæ–¹æ³•ï¼Œæå‡ç»†èŠ‚è¡¨ç°</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26001v2" onclick="toggleFavorite(this, '2510.26001v2', 'Larger Hausdorff Dimension in Scanning Pattern Facilitates Mamba-Based Methods in Low-Light Image Enhancement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>14</td>
  <td><a href="./papers/251025760v2-multimodal-spatial-reasoning-in-the-large-model-era-a-survey-and-ben.html">Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks</a></td>
  <td>ç»¼è¿°å¤šæ¨¡æ€ç©ºé—´æ¨ç†å¤§æ¨¡å‹ï¼Œå¹¶æ„å»ºå¼€æ”¾åŸºå‡†è¯„æµ‹</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25760v2" onclick="toggleFavorite(this, '2510.25760v2', 'Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction">ğŸ”¬ æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>15</td>
  <td><a href="./papers/251025976v1-brain-it-image-reconstruction-from-fmri-via-brain-interaction-transf.html">Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer</a></td>
  <td>æå‡ºBrain-ITï¼Œé€šè¿‡è„‘äº¤äº’Transformerå®ç°åŸºäºfMRIçš„å›¾åƒé‡å»ºï¼Œæå‡é‡å»ºå›¾åƒçš„çœŸå®æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25976v1" onclick="toggleFavorite(this, '2510.25976v1', 'Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>16</td>
  <td><a href="./papers/251025279v1-diffusion-driven-progressive-target-manipulation-for-source-free-dom.html">Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation</a></td>
  <td>æå‡ºæ‰©æ•£é©±åŠ¨çš„æ¸è¿›å¼ç›®æ ‡åŸŸæ“æ§æ–¹æ³•ï¼Œè§£å†³æ— æºåŸŸè‡ªé€‚åº”ä¸­çš„åŸŸå·®å¼‚é—®é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25279v1" onclick="toggleFavorite(this, '2510.25279v1', 'Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)