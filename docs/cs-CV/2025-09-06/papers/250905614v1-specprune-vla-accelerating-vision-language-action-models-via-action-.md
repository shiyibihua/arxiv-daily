---
layout: default
title: SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning
---

# SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05614" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05614v1</a>
  <a href="https://arxiv.org/pdf/2509.05614.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05614v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05614v1', 'SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hanzhen Wang, Jiaming Xu, Jiayi Pan, Yongkang Zhou, Guohao Dai

**åˆ†ç±»**: cs.CV, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-06

**å¤‡æ³¨**: 8pages, 10 figures,

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SpecPrune-VLAï¼šé€šè¿‡åŠ¨ä½œæ„ŸçŸ¥è‡ªé€‚åº”æ¨æµ‹å‰ªæåŠ é€Ÿè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹` `æ¨¡å‹å‰ªæ` `åŠ¨ä½œæ„ŸçŸ¥` `æ¨¡å‹åŠ é€Ÿ` `æœºå™¨äºº` `æ¨ç†ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLAæ¨¡å‹å‰ªææ–¹æ³•ä»…ä¾èµ–å½“å‰åŠ¨ä½œçš„å±€éƒ¨ä¿¡æ¯ï¼Œå¿½ç•¥äº†å…¨å±€ä¸Šä¸‹æ–‡ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™å’ŒåŠ é€Ÿæ•ˆæœä¸ä½³ã€‚
2. SpecPrune-VLAåˆ©ç”¨å…¨å±€å†å²å’Œå±€éƒ¨ä¸Šä¸‹æ–‡è¿›è¡Œtokené€‰æ‹©ï¼Œé€šè¿‡ä¸¤çº§å‰ªæå’ŒåŠ¨ä½œæ„ŸçŸ¥æ§åˆ¶å®ç°æ›´æ™ºèƒ½çš„å‰ªæã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSpecPrune-VLAåœ¨ä¿æŒæˆåŠŸç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†VLAæ¨¡å‹çš„æ¨ç†é€Ÿåº¦ï¼Œåœ¨A800å’Œ3090ä¸Šåˆ†åˆ«åŠ é€Ÿ1.46å€å’Œ1.57å€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºSpecPrune-VLAï¼Œä¸€ç§ç”¨äºåŠ é€Ÿè§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹çš„è®­ç»ƒæ— å…³æ–¹æ³•ã€‚ç°æœ‰å‰ªææ–¹æ³•ä»…åˆ©ç”¨å½“å‰åŠ¨ä½œçš„å±€éƒ¨ä¿¡æ¯è¿›è¡Œtokenå‰ªæï¼Œå¿½ç•¥äº†æ¥è‡ªå…ˆå‰åŠ¨ä½œçš„å…¨å±€ä¸Šä¸‹æ–‡ï¼Œå¯¼è‡´æˆåŠŸç‡æ˜¾è‘—ä¸‹é™å’ŒåŠ é€Ÿæ•ˆæœå—é™ã€‚SpecPrune-VLAåˆ©ç”¨å±€éƒ¨å’Œå…¨å±€ä¿¡æ¯è¿›è¡Œæ›´æ™ºèƒ½çš„tokené€‰æ‹©ï¼ŒåŒ…å«ä¸¤çº§å‰ªæå’Œå¯å‘å¼æ§åˆ¶ï¼šï¼ˆ1ï¼‰åŠ¨ä½œçº§åˆ«çš„é™æ€å‰ªæï¼šä½¿ç”¨å…¨å±€å†å²å’Œå±€éƒ¨ä¸Šä¸‹æ–‡å‡å°‘æ¯ä¸ªåŠ¨ä½œçš„è§†è§‰tokenï¼›ï¼ˆ2ï¼‰å±‚çº§åˆ«çš„åŠ¨æ€å‰ªæï¼šåŸºäºå±‚ç‰¹å®šçš„é‡è¦æ€§å‰ªææ¯å±‚çš„tokenï¼›ï¼ˆ3ï¼‰è½»é‡çº§çš„åŠ¨ä½œæ„ŸçŸ¥æ§åˆ¶å™¨ï¼šå°†åŠ¨ä½œåˆ†ç±»ä¸ºç²—ç²’åº¦/ç»†ç²’åº¦ï¼Œå¹¶è°ƒæ•´å‰ªæå¼ºåº¦ï¼Œå› ä¸ºç»†ç²’åº¦åŠ¨ä½œå¯¹å‰ªææ›´æ•æ„Ÿã€‚åœ¨LIBEROä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSpecPrune-VLAåœ¨NVIDIA A800ä¸Šå®ç°äº†1.46å€çš„åŠ é€Ÿï¼Œåœ¨NVIDIA GeForce RTX 3090ä¸Šå®ç°äº†1.57å€çš„åŠ é€Ÿï¼Œä¸OpenVLA-OFTç›¸æ¯”ï¼ŒæˆåŠŸç‡æŸå¤±å¯å¿½ç•¥ä¸è®¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šVLAæ¨¡å‹è®¡ç®—é‡å¤§ï¼Œæ¨ç†é€Ÿåº¦æ…¢ã€‚ç°æœ‰å‰ªææ–¹æ³•åœ¨VLAæ¨¡å‹ä¸Šåº”ç”¨æ—¶ï¼Œä»…è€ƒè™‘å½“å‰åŠ¨ä½œçš„å±€éƒ¨ä¿¡æ¯ï¼Œå¿½ç•¥äº†å†å²åŠ¨ä½œçš„å…¨å±€ä¸Šä¸‹æ–‡ï¼Œå¯¼è‡´å‰ªæåæ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œæ— æ³•æœ‰æ•ˆåŠ é€Ÿã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šåˆ©ç”¨è¿ç»­åŠ¨ä½œä¹‹é—´çš„é«˜åº¦ç›¸ä¼¼æ€§ï¼Œç»“åˆå½“å‰åŠ¨ä½œçš„å±€éƒ¨ä¿¡æ¯å’Œå†å²åŠ¨ä½œçš„å…¨å±€ä¸Šä¸‹æ–‡ï¼Œè¿›è¡Œæ›´æ™ºèƒ½çš„tokené€‰æ‹©å’Œå‰ªæï¼Œä»è€Œåœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œæé«˜æ¨ç†é€Ÿåº¦ã€‚æ ¸å¿ƒåœ¨äºåŠ¨ä½œæ„ŸçŸ¥çš„å‰ªæç­–ç•¥ï¼Œæ ¹æ®åŠ¨ä½œçš„ç²’åº¦è°ƒæ•´å‰ªæçš„æ¿€è¿›ç¨‹åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSpecPrune-VLAåŒ…å«ä¸‰ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼šåŠ¨ä½œçº§åˆ«çš„é™æ€å‰ªæã€å±‚çº§åˆ«çš„åŠ¨æ€å‰ªæå’Œè½»é‡çº§çš„åŠ¨ä½œæ„ŸçŸ¥æ§åˆ¶å™¨ã€‚é™æ€å‰ªæåœ¨åŠ¨ä½œå±‚é¢å‡å°‘è§†è§‰tokenæ•°é‡ï¼ŒåŠ¨æ€å‰ªæåœ¨å±‚å±‚é¢æ ¹æ®é‡è¦æ€§å‰ªætokenï¼ŒåŠ¨ä½œæ„ŸçŸ¥æ§åˆ¶å™¨æ ¹æ®åŠ¨ä½œç²’åº¦è°ƒæ•´å‰ªæå¼ºåº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šSpecPrune-VLAçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) ç»“åˆå…¨å±€å†å²å’Œå±€éƒ¨ä¸Šä¸‹æ–‡è¿›è¡Œå‰ªæï¼›2) æå‡ºä¸¤çº§å‰ªæç­–ç•¥ï¼Œåˆ†åˆ«åœ¨åŠ¨ä½œçº§åˆ«å’Œå±‚çº§åˆ«è¿›è¡Œå‰ªæï¼›3) è®¾è®¡è½»é‡çº§çš„åŠ¨ä½œæ„ŸçŸ¥æ§åˆ¶å™¨ï¼Œæ ¹æ®åŠ¨ä½œç²’åº¦åŠ¨æ€è°ƒæ•´å‰ªæå¼ºåº¦ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSpecPrune-VLAèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¹³è¡¡æ¨¡å‹æ€§èƒ½å’Œæ¨ç†é€Ÿåº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåŠ¨ä½œæ„ŸçŸ¥æ§åˆ¶å™¨å°†åŠ¨ä½œåˆ†ä¸ºç²—ç²’åº¦å’Œç»†ç²’åº¦ï¼Œç»†ç²’åº¦åŠ¨ä½œå¯¹å‰ªææ›´æ•æ„Ÿï¼Œå› æ­¤é™ä½å‰ªææ¯”ä¾‹ã€‚é™æ€å‰ªæå’ŒåŠ¨æ€å‰ªæçš„å…·ä½“æ¯”ä¾‹é€šè¿‡å®éªŒç¡®å®šã€‚æŸå¤±å‡½æ•°ä¿æŒä¸å˜ï¼Œå› ä¸ºSpecPrune-VLAæ˜¯ä¸€ç§è®­ç»ƒæ— å…³çš„æ–¹æ³•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SpecPrune-VLAåœ¨LIBEROæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„åŠ é€Ÿæ•ˆæœï¼Œåœ¨NVIDIA A800ä¸Šå®ç°äº†1.46å€çš„åŠ é€Ÿï¼Œåœ¨NVIDIA GeForce RTX 3090ä¸Šå®ç°äº†1.57å€çš„åŠ é€Ÿï¼Œä¸OpenVLA-OFTç›¸æ¯”ï¼ŒæˆåŠŸç‡æŸå¤±å¯å¿½ç•¥ä¸è®¡ã€‚è¿™è¡¨æ˜SpecPrune-VLAèƒ½å¤Ÿåœ¨ä¿æŒæ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œæœ‰æ•ˆæé«˜VLAæ¨¡å‹çš„æ¨ç†é€Ÿåº¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SpecPrune-VLAå¯åº”ç”¨äºå„ç§éœ€è¦å®æ—¶å“åº”çš„æœºå™¨äººä»»åŠ¡ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½åˆ¶é€ å’Œå®¶åº­æœåŠ¡æœºå™¨äººã€‚é€šè¿‡åŠ é€ŸVLAæ¨¡å‹çš„æ¨ç†é€Ÿåº¦ï¼Œå¯ä»¥æé«˜æœºå™¨äººçš„å†³ç­–æ•ˆç‡å’Œäº¤äº’èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å¤æ‚å¤šå˜çš„ç¯å¢ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Pruning accelerates compute-bound models by reducing computation. Recently applied to Vision-Language-Action (VLA) models, existing methods prune tokens using only local info from current action, ignoring global context from prior actions, causing >20% success rate drop and limited speedup. We observe high similarity across consecutive actions and propose leveraging both local (current) and global (past) info for smarter token selection. We introduce SpecPrune-VLA, a training-free method with two-level pruning and heuristic control: (1) Static pruning at action level: uses global history and local context to reduce visual tokens per action; (2) Dynamic pruning at layer level: prunes tokens per layer based on layer-specific importance; (3) Lightweight action-aware controller: classifies actions as coarse/fine-grained (by speed), adjusting pruning aggressiveness since fine-grained actions are pruning-sensitive. Experiments on LIBERO show SpecPrune-VLA achieves 1.46 times speedup on NVIDIA A800 and 1.57 times on NVIDIA GeForce RTX 3090 vs. OpenVLA-OFT, with negligible success rate loss.

