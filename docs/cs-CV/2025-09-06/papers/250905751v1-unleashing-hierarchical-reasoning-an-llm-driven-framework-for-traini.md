---
layout: default
title: Unleashing Hierarchical Reasoning: An LLM-Driven Framework for Training-Free Referring Video Object Segmentation
---

# Unleashing Hierarchical Reasoning: An LLM-Driven Framework for Training-Free Referring Video Object Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05751" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05751v1</a>
  <a href="https://arxiv.org/pdf/2509.05751.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05751v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05751v1', 'Unleashing Hierarchical Reasoning: An LLM-Driven Framework for Training-Free Referring Video Object Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Bingrui Zhao, Lin Yuanbo Wu, Xiangtian Fan, Deyin Liu, Lu Zhang, Ruyi He, Jialie Shen, Ximing Li

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPARSE-VOSä»¥è§£å†³åŠ¨æ€è§†é¢‘ç‰©ä½“åˆ†å‰²ä¸­çš„è¯­è¨€ä¸è§†è§‰å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼•ç”¨è§†é¢‘ç‰©ä½“åˆ†å‰²` `å¤§å‹è¯­è¨€æ¨¡å‹` `å±‚æ¬¡åŒ–æ¨ç†` `æ—¶ç©ºå®šä½` `æ— è®­ç»ƒæ¡†æ¶` `è¯­ä¹‰è§£æ` `ç›®æ ‡è¯†åˆ«`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¼•ç”¨è§†é¢‘ç‰©ä½“åˆ†å‰²æ–¹æ³•åœ¨å¤„ç†åŠ¨æ€è§†é¢‘æ—¶ï¼Œéš¾ä»¥æœ‰æ•ˆå¯¹é½è¯­è¨€æè¿°ä¸è§†è§‰å†…å®¹ï¼Œå°¤å…¶æ˜¯å½“ç›®æ ‡å¯¹è±¡å¤–è§‚ç›¸ä¼¼æ—¶ã€‚
2. æœ¬æ–‡æå‡ºçš„PARSE-VOSæ¡†æ¶é€šè¿‡è§£æè¯­è¨€æŸ¥è¯¢å¹¶ç»“åˆæ—¶ç©ºä¿¡æ¯ï¼Œå®ç°äº†å±‚æ¬¡åŒ–çš„ç²—åˆ°ç»†æ¨ç†ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•çš„è®­ç»ƒä¾èµ–ã€‚
3. PARSE-VOSåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºè‰²ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾ç¤ºäº†å…¶åœ¨å¼•ç”¨è§†é¢‘ç‰©ä½“åˆ†å‰²ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼•ç”¨è§†é¢‘ç‰©ä½“åˆ†å‰²ï¼ˆRVOSï¼‰æ—¨åœ¨æ ¹æ®è¯­è¨€æè¿°å¯¹è§†é¢‘ä¸­çš„ç›®æ ‡å¯¹è±¡è¿›è¡Œåˆ†å‰²ã€‚ä¸»è¦æŒ‘æˆ˜åœ¨äºå°†é™æ€æ–‡æœ¬ä¸åŠ¨æ€è§†è§‰å†…å®¹å¯¹é½ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹è±¡å¤–è§‚ç›¸ä¼¼ä½†è¿åŠ¨å’Œå§¿æ€ä¸ä¸€è‡´çš„æƒ…å†µä¸‹ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–æ•´ä½“çš„è§†è§‰-è¯­è¨€èåˆï¼Œéš¾ä»¥å¤„ç†å¤æ‚çš„ç»„åˆæè¿°ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ— è®­ç»ƒæ¡†æ¶PARSE-VOSï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®ç°æ–‡æœ¬ä¸è§†é¢‘é¢†åŸŸçš„å±‚æ¬¡åŒ–ç²—åˆ°ç»†æ¨ç†ã€‚è¯¥æ–¹æ³•é¦–å…ˆå°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è§£æä¸ºç»“æ„åŒ–è¯­ä¹‰å‘½ä»¤ï¼Œç„¶åå¼•å…¥æ—¶ç©ºå®šä½æ¨¡å—ç”Ÿæˆæ‰€æœ‰æ½œåœ¨ç›®æ ‡å¯¹è±¡çš„å€™é€‰è½¨è¿¹ï¼Œæœ€åé€šè¿‡ä¸¤é˜¶æ®µæ¨ç†è¿‡ç¨‹é€‰æ‹©æ­£ç¡®ç›®æ ‡ï¼Œæœ€ç»ˆè¾“å‡ºå‡†ç¡®çš„åˆ†å‰²æ©è†œã€‚PARSE-VOSåœ¨Ref-YouTube-VOSã€Ref-DAVIS17å’ŒMeViSä¸‰ä¸ªä¸»è¦åŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯å¼•ç”¨è§†é¢‘ç‰©ä½“åˆ†å‰²ï¼ˆRVOSï¼‰ä¸­çš„è¯­è¨€ä¸è§†è§‰å¯¹é½é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚æè¿°æ—¶è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹è±¡å¤–è§‚ç›¸ä¼¼ä¸”è¿åŠ¨ä¸ä¸€è‡´çš„æƒ…å†µä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPARSE-VOSæ¡†æ¶çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œå±‚æ¬¡åŒ–æ¨ç†ï¼Œé¦–å…ˆå°†è¯­è¨€æŸ¥è¯¢è§£æä¸ºç»“æ„åŒ–å‘½ä»¤ï¼Œç„¶åé€šè¿‡æ—¶ç©ºå®šä½æ¨¡å—ç”Ÿæˆå€™é€‰è½¨è¿¹ï¼Œæœ€åé€šè¿‡ä¸¤é˜¶æ®µæ¨ç†é€‰æ‹©æ­£ç¡®ç›®æ ‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1ï¼‰è¯­è¨€è§£ææ¨¡å—ï¼Œå°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºç»“æ„åŒ–è¯­ä¹‰å‘½ä»¤ï¼›2ï¼‰æ—¶ç©ºå®šä½æ¨¡å—ï¼Œç”Ÿæˆæ‰€æœ‰æ½œåœ¨ç›®æ ‡å¯¹è±¡çš„å€™é€‰è½¨è¿¹ï¼›3ï¼‰å±‚æ¬¡åŒ–è¯†åˆ«æ¨¡å—ï¼Œé€šè¿‡ç²—ç²’åº¦è¿åŠ¨æ¨ç†å’Œç»†ç²’åº¦å§¿æ€éªŒè¯è¿›è¡Œç›®æ ‡é€‰æ‹©ã€‚

**å…³é”®åˆ›æ–°**ï¼šPARSE-VOSçš„å…³é”®åˆ›æ–°åœ¨äºå…¶æ— è®­ç»ƒçš„è®¾è®¡ï¼Œåˆ©ç”¨LLMsè¿›è¡Œæ¨ç†ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•å¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–ï¼Œä¸”é€šè¿‡å±‚æ¬¡åŒ–æ¨ç†æé«˜äº†å¯¹å¤æ‚æè¿°çš„å¤„ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæ—¶ç©ºå®šä½æ¨¡å—çš„å‚æ•°è®¾ç½®å’Œè¯­ä¹‰è§£æçš„å‡†ç¡®æ€§è‡³å…³é‡è¦ï¼Œæ­¤å¤–ï¼Œå±‚æ¬¡åŒ–è¯†åˆ«æ¨¡å—çš„ä¸¤é˜¶æ®µæ¨ç†è¿‡ç¨‹ç¡®ä¿äº†åœ¨å­˜åœ¨æ­§ä¹‰æ—¶èƒ½å¤Ÿè¿›è¡Œæœ‰æ•ˆçš„ç»†åŒ–éªŒè¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PARSE-VOSåœ¨Ref-YouTube-VOSã€Ref-DAVIS17å’ŒMeViSä¸‰ä¸ªåŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨Ref-YouTube-VOSä¸Šæé«˜äº†5.2%çš„mIoUï¼Œç›¸è¾ƒäºç°æœ‰æœ€ä½³æ–¹æ³•å…·æœ‰æ˜¾è‘—æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚è§†é¢‘åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è§†é¢‘ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½å®¶å±…ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­å®ç°å¯¹ç›®æ ‡å¯¹è±¡çš„ç²¾ç¡®è¯†åˆ«ä¸åˆ†å‰²ï¼Œæå‡ç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨å¤šæ¨¡æ€äº¤äº’å’Œäººæœºåä½œä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Referring Video Object Segmentation (RVOS) aims to segment an object of interest throughout a video based on a language description. The prominent challenge lies in aligning static text with dynamic visual content, particularly when objects exhibiting similar appearances with inconsistent motion and poses. However, current methods often rely on a holistic visual-language fusion that struggles with complex, compositional descriptions. In this paper, we propose \textbf{PARSE-VOS}, a novel, training-free framework powered by Large Language Models (LLMs), for a hierarchical, coarse-to-fine reasoning across text and video domains. Our approach begins by parsing the natural language query into structured semantic commands. Next, we introduce a spatio-temporal grounding module that generates all candidate trajectories for all potential target objects, guided by the parsed semantics. Finally, a hierarchical identification module select the correct target through a two-stage reasoning process: it first performs coarse-grained motion reasoning with an LLM to narrow down candidates; if ambiguity remains, a fine-grained pose verification stage is conditionally triggered to disambiguate. The final output is an accurate segmentation mask for the target object. \textbf{PARSE-VOS} achieved state-of-the-art performance on three major benchmarks: Ref-YouTube-VOS, Ref-DAVIS17, and MeViS.

