---
layout: default
title: Language-guided Recursive Spatiotemporal Graph Modeling for Video Summarization
---

# Language-guided Recursive Spatiotemporal Graph Modeling for Video Summarization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05604" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05604v1</a>
  <a href="https://arxiv.org/pdf/2509.05604.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05604v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05604v1', 'Language-guided Recursive Spatiotemporal Graph Modeling for Video Summarization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jungin Park, Jiyoung Lee, Kwanghoon Sohn

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-06

**å¤‡æ³¨**: Accepted to IJCV, 29 pages, 14 figures, 11 tables

**DOI**: [10.1007/s11263-025-02577-2](https://doi.org/10.1007/s11263-025-02577-2)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/park-jungin/videograph)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè¯­è¨€å¼•å¯¼çš„é€’å½’æ—¶ç©ºå›¾ç½‘ç»œVideoGraphï¼Œç”¨äºè§†é¢‘æ‘˜è¦ä»»åŠ¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `è§†é¢‘æ‘˜è¦` `æ—¶ç©ºå›¾ç½‘ç»œ` `è¯­è¨€å¼•å¯¼` `å›¾å·ç§¯ç½‘ç»œ` `é€’å½’ç¥ç»ç½‘ç»œ` `è§†é¢‘ç†è§£` `å…³é”®å¸§æå–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘æ‘˜è¦æ–¹æ³•ä¾§é‡äºå¸§é—´çš„æ—¶é—´å…³ç³»ï¼Œå¿½ç•¥äº†ç»†ç²’åº¦è§†è§‰å®ä½“ï¼ˆå¦‚å¯¹è±¡ï¼‰ä¸è§†é¢‘å†…å®¹çš„ç›¸å…³æ€§ã€‚
2. VideoGraphé€šè¿‡æ„å»ºé€’å½’æ—¶ç©ºå›¾ç½‘ç»œï¼Œå°†å¯¹è±¡å’Œå¸§åˆ†åˆ«å»ºæ¨¡ä¸ºç©ºé—´å›¾å’Œæ—¶é—´å›¾çš„èŠ‚ç‚¹ï¼Œå¹¶èå…¥è¯­è¨€ä¿¡æ¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒVideoGraphåœ¨é€šç”¨å’ŒæŸ¥è¯¢èšç„¦è§†é¢‘æ‘˜è¦ä»»åŠ¡ä¸Šï¼Œå‡å–å¾—äº†ä¼˜äºç°æœ‰æŠ€æœ¯æ°´å¹³çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¯­è¨€å¼•å¯¼çš„æ—¶ç©ºå›¾å»ºæ¨¡æ–¹æ³•ç”¨äºè§†é¢‘æ‘˜è¦ï¼Œæ—¨åœ¨é€‰æ‹©å…·æœ‰è§†è§‰å¤šæ ·æ€§å¹¶èƒ½ä»£è¡¨è§†é¢‘æ•´ä½“æ•…äº‹çš„å…³é”®å¸§ã€‚ç°æœ‰æ–¹æ³•ä¾§é‡äºé€šè¿‡æ—¶é—´å»ºæ¨¡æ¥å»ºç«‹å¸§ä¹‹é—´çš„å…¨å±€äº’è¿æ€§ã€‚ç„¶è€Œï¼Œç»†ç²’åº¦çš„è§†è§‰å®ä½“ï¼ˆå¦‚å¯¹è±¡ï¼‰ä¹Ÿä¸è§†é¢‘çš„ä¸»è¦å†…å®¹é«˜åº¦ç›¸å…³ã€‚æ­¤å¤–ï¼Œæœ€è¿‘ç ”ç©¶çš„è¯­è¨€å¼•å¯¼è§†é¢‘æ‘˜è¦éœ€è¦å¯¹å¤æ‚çš„çœŸå®ä¸–ç•Œè§†é¢‘è¿›è¡Œå…¨é¢çš„è¯­è¨€ç†è§£ã€‚ä¸ºäº†è€ƒè™‘æ‰€æœ‰å¯¹è±¡ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼Œæœ¬æ–‡å°†è§†é¢‘æ‘˜è¦è§†ä¸ºä¸€ä¸ªè¯­è¨€å¼•å¯¼çš„æ—¶ç©ºå›¾å»ºæ¨¡é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†é€’å½’æ—¶ç©ºå›¾ç½‘ç»œï¼Œç§°ä¸ºVideoGraphï¼Œå®ƒå°†å¯¹è±¡å’Œå¸§åˆ†åˆ«è¡¨ç¤ºä¸ºç©ºé—´å›¾å’Œæ—¶é—´å›¾çš„èŠ‚ç‚¹ã€‚æ¯ä¸ªå›¾ä¸­çš„èŠ‚ç‚¹é€šè¿‡å›¾è¾¹è¿æ¥å’Œèšåˆï¼Œè¡¨ç¤ºèŠ‚ç‚¹ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ã€‚ä¸ºäº†é˜²æ­¢è¾¹ä»…æ ¹æ®è§†è§‰ç›¸ä¼¼æ€§é…ç½®ï¼Œæˆ‘ä»¬å°†ä»è§†é¢‘ä¸­æå–çš„è¯­è¨€æŸ¥è¯¢èå…¥åˆ°å›¾èŠ‚ç‚¹è¡¨ç¤ºä¸­ï¼Œä½¿å…¶åŒ…å«è¯­ä¹‰çŸ¥è¯†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨é€’å½’ç­–ç•¥æ¥ç»†åŒ–åˆå§‹å›¾ï¼Œå¹¶æ­£ç¡®åœ°å°†æ¯ä¸ªå¸§èŠ‚ç‚¹åˆ†ç±»ä¸ºå…³é”®å¸§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVideoGraphåœ¨æœ‰ç›‘ç£å’Œæ— ç›‘ç£çš„é€šç”¨å’ŒæŸ¥è¯¢èšç„¦è§†é¢‘æ‘˜è¦çš„å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­éƒ½å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä»£ç å·²å¼€æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†é¢‘æ‘˜è¦æ—¨åœ¨ä»è§†é¢‘ä¸­é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„å…³é”®å¸§ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å¸§ä¹‹é—´çš„æ—¶é—´å…³ç³»ï¼Œå¿½ç•¥äº†è§†é¢‘ä¸­ç»†ç²’åº¦å¯¹è±¡ä¹‹é—´çš„è¯­ä¹‰å…³è”ï¼Œä»¥åŠè¯­è¨€ä¿¡æ¯å¯¹è§†é¢‘ç†è§£çš„æŒ‡å¯¼ä½œç”¨ã€‚è¿™å¯¼è‡´ç”Ÿæˆçš„æ‘˜è¦å¯èƒ½ç¼ºä¹å¯¹è§†é¢‘å†…å®¹æ·±å±‚æ¬¡çš„ç†è§£å’Œè¡¨è¾¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è§†é¢‘æ‘˜è¦é—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªè¯­è¨€å¼•å¯¼çš„æ—¶ç©ºå›¾å»ºæ¨¡é—®é¢˜ã€‚é€šè¿‡æ„å»ºæ—¶ç©ºå›¾ï¼Œæ˜¾å¼åœ°å»ºæ¨¡è§†é¢‘ä¸­å¯¹è±¡å’Œå¸§ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶åˆ©ç”¨è¯­è¨€ä¿¡æ¯æ¥æŒ‡å¯¼å›¾çš„æ„å»ºå’Œæ¨ç†ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£è§†é¢‘å†…å®¹å¹¶é€‰æ‹©å…³é”®å¸§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVideoGraphçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ç‰¹å¾æå–æ¨¡å—ï¼šæå–è§†é¢‘å¸§çš„è§†è§‰ç‰¹å¾å’Œå¯¹è±¡çš„è§†è§‰ç‰¹å¾ã€‚2) è¯­è¨€æŸ¥è¯¢æ¨¡å—ï¼šä»è§†é¢‘æè¿°æˆ–ç”¨æˆ·æŸ¥è¯¢ä¸­æå–è¯­è¨€ç‰¹å¾ã€‚3) æ—¶ç©ºå›¾æ„å»ºæ¨¡å—ï¼šæ„å»ºç©ºé—´å›¾ï¼ˆå¯¹è±¡ä¹‹é—´çš„å…³ç³»ï¼‰å’Œæ—¶é—´å›¾ï¼ˆå¸§ä¹‹é—´çš„å…³ç³»ï¼‰ã€‚4) å›¾æ¨ç†æ¨¡å—ï¼šåˆ©ç”¨å›¾ç¥ç»ç½‘ç»œåœ¨æ—¶ç©ºå›¾ä¸Šè¿›è¡Œæ¨ç†ï¼Œèåˆè§†è§‰å’Œè¯­è¨€ä¿¡æ¯ã€‚5) é€’å½’ç»†åŒ–æ¨¡å—ï¼šé€šè¿‡é€’å½’çš„æ–¹å¼ä¸æ–­ç»†åŒ–å›¾ç»“æ„å’ŒèŠ‚ç‚¹è¡¨ç¤ºï¼Œæé«˜å…³é”®å¸§åˆ†ç±»çš„å‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†é€’å½’æ—¶ç©ºå›¾ç½‘ç»œVideoGraphï¼Œèƒ½å¤ŸåŒæ—¶å»ºæ¨¡è§†é¢‘ä¸­çš„å¯¹è±¡å’Œå¸§ä¹‹é—´çš„å…³ç³»ã€‚2) å°†è¯­è¨€ä¿¡æ¯èå…¥åˆ°å›¾èŠ‚ç‚¹è¡¨ç¤ºä¸­ï¼Œä»è€Œåˆ©ç”¨è¯­è¨€ä¿¡æ¯æ¥æŒ‡å¯¼å›¾çš„æ„å»ºå’Œæ¨ç†ã€‚3) é‡‡ç”¨é€’å½’ç­–ç•¥æ¥ç»†åŒ–å›¾ç»“æ„å’ŒèŠ‚ç‚¹è¡¨ç¤ºï¼Œæé«˜å…³é”®å¸§åˆ†ç±»çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ—¶ç©ºå›¾æ„å»ºæ–¹é¢ï¼Œä½¿ç”¨äº†GCNï¼ˆå›¾å·ç§¯ç½‘ç»œï¼‰æ¥èšåˆèŠ‚ç‚¹ä¿¡æ¯ã€‚è¯­è¨€ä¿¡æ¯çš„èå…¥æ–¹å¼æ˜¯å°†è¯­è¨€ç‰¹å¾ä¸è§†è§‰ç‰¹å¾è¿›è¡Œèåˆï¼Œä½œä¸ºå›¾èŠ‚ç‚¹çš„åˆå§‹è¡¨ç¤ºã€‚é€’å½’ç»†åŒ–æ¨¡å—é€šè¿‡å¤šå±‚GCNæ¥å®ç°ï¼Œæ¯ä¸€å±‚GCNéƒ½å¯¹å›¾ç»“æ„å’ŒèŠ‚ç‚¹è¡¨ç¤ºè¿›è¡Œæ›´æ–°ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬å…³é”®å¸§åˆ†ç±»æŸå¤±å’Œå›¾ç»“æ„æ­£åˆ™åŒ–æŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VideoGraphåœ¨TVSumã€SumMeã€YouTubeç­‰å¤šä¸ªè§†é¢‘æ‘˜è¦åŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨TVSumæ•°æ®é›†ä¸Šï¼ŒVideoGraphçš„F-scoreæ¯”ä¹‹å‰çš„æœ€ä½³æ–¹æ³•æé«˜äº†çº¦2-3ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æœ‰ç›‘ç£å’Œæ— ç›‘ç£ä¸¤ç§æ¨¡å¼ä¸‹å‡è¡¨ç°å‡ºè‰²ï¼Œè¯æ˜äº†å…¶æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè§†é¢‘ç›‘æ§æ‘˜è¦ã€æ–°é—»è§†é¢‘æ‘˜è¦ã€ç”µå½±é¢„å‘Šç‰‡ç”Ÿæˆã€æ•™è‚²è§†é¢‘å†…å®¹æå–ç­‰é¢†åŸŸã€‚é€šè¿‡è‡ªåŠ¨æå–è§†é¢‘çš„å…³é”®ä¿¡æ¯ï¼Œå¯ä»¥èŠ‚çœå¤§é‡çš„äººå·¥æ ‡æ³¨æˆæœ¬ï¼Œæé«˜è§†é¢‘å†…å®¹ç†è§£å’Œæ£€ç´¢çš„æ•ˆç‡ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›æ›´ä¾¿æ·çš„è§†é¢‘æµè§ˆä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–è§†é¢‘ç†è§£ä»»åŠ¡ï¼Œå¦‚è§†é¢‘é—®ç­”ã€è§†é¢‘æè¿°ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Video summarization aims to select keyframes that are visually diverse and can represent the whole story of a given video. Previous approaches have focused on global interlinkability between frames in a video by temporal modeling. However, fine-grained visual entities, such as objects, are also highly related to the main content of the video. Moreover, language-guided video summarization, which has recently been studied, requires a comprehensive linguistic understanding of complex real-world videos. To consider how all the objects are semantically related to each other, this paper regards video summarization as a language-guided spatiotemporal graph modeling problem. We present recursive spatiotemporal graph networks, called VideoGraph, which formulate the objects and frames as nodes of the spatial and temporal graphs, respectively. The nodes in each graph are connected and aggregated with graph edges, representing the semantic relationships between the nodes. To prevent the edges from being configured with visual similarity, we incorporate language queries derived from the video into the graph node representations, enabling them to contain semantic knowledge. In addition, we adopt a recursive strategy to refine initial graphs and correctly classify each frame node as a keyframe. In our experiments, VideoGraph achieves state-of-the-art performance on several benchmarks for generic and query-focused video summarization in both supervised and unsupervised manners. The code is available at https://github.com/park-jungin/videograph.

