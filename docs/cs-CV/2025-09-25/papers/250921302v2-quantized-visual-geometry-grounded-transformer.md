---
layout: default
title: Quantized Visual Geometry Grounded Transformer
---

# Quantized Visual Geometry Grounded Transformer

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21302" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21302v2</a>
  <a href="https://arxiv.org/pdf/2509.21302.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21302v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21302v2', 'Quantized Visual Geometry Grounded Transformer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Weilun Feng, Haotong Qin, Mingqiang Wu, Chuanguang Yang, Yuqi Li, Xiangqi Li, Zhulin An, Libo Huang, Yulun Zhang, Michele Magno, Yongjun Xu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25 (æ›´æ–°: 2025-09-30)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/wlfeng0509/QuantVGGT)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºQuantVGGTï¼Œè§£å†³VGGTé‡åŒ–éš¾é¢˜ï¼Œå®ç°èµ„æºå—é™åœºæ™¯ä¸‹çš„é«˜æ•ˆ3Dé‡å»ºã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `3Dé‡å»º` `æ¨¡å‹é‡åŒ–` `è§†è§‰å‡ ä½•å¼•å¯¼Transformer` `åè®­ç»ƒé‡åŒ–` `é‡å°¾åˆ†å¸ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VGGTæ¨¡å‹è®¡ç®—å’Œå†…å­˜æˆæœ¬é«˜æ˜‚ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„åœºæ™¯ä¸­éƒ¨ç½²ï¼Œåè®­ç»ƒé‡åŒ–(PTQ)åœ¨VGGTä¸Šçš„åº”ç”¨é¢ä¸´é‡å°¾æ¿€æ´»åˆ†å¸ƒå’Œæ ¡å‡†æ ·æœ¬é€‰æ‹©ä¸ç¨³å®šçš„æŒ‘æˆ˜ã€‚
2. QuantVGGTé€šè¿‡åŒé‡å¹³æ»‘ç»†ç²’åº¦é‡åŒ–ç¼“è§£é‡å°¾åˆ†å¸ƒå’Œé€šé“é—´æ–¹å·®ï¼Œå¹¶åˆ©ç”¨å™ªå£°è¿‡æ»¤å¤šæ ·æ€§é‡‡æ ·ç¡®ä¿ç¨³å®šçš„é‡åŒ–èŒƒå›´ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œ4ä½QuantVGGTåœ¨ä¿æŒè¾ƒé«˜é‡å»ºç²¾åº¦çš„åŒæ—¶ï¼Œå®ç°äº†3.7å€çš„å†…å­˜å‡å°‘å’Œ2.5å€çš„åŠ é€Ÿï¼Œä¼˜äºç°æœ‰é‡åŒ–æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰å‡ ä½•å¼•å¯¼Transformer (VGGT) ç­‰åŸºäºå­¦ä¹ çš„3Dé‡å»ºæ¨¡å‹ï¼Œå—ç›Šäºå¤§è§„æ¨¡Transformerï¼Œå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå…¶å·¨å¤§çš„è®¡ç®—å’Œå†…å­˜æˆæœ¬ä¸¥é‡é˜»ç¢äº†å®é™…éƒ¨ç½²ã€‚åè®­ç»ƒé‡åŒ– (PTQ) å·²æˆä¸ºå‹ç¼©å’ŒåŠ é€Ÿæ¨¡å‹çš„å¸¸ç”¨æ–¹æ³•ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬é€šè¿‡å®éªŒè§‚å¯Ÿåˆ°ï¼Œåœ¨å‹ç¼©åäº¿çº§VGGTæ—¶ï¼ŒPTQé¢ä¸´ç€ç‹¬ç‰¹çš„éšœç¢ï¼šæ•°æ®æ— å…³çš„ç‰¹æ®Štokenå¯¼è‡´é‡å°¾æ¿€æ´»åˆ†å¸ƒï¼Œè€Œ3Dæ•°æ®çš„å¤šè§†è§’ç‰¹æ€§ä½¿å¾—æ ¡å‡†æ ·æœ¬çš„é€‰æ‹©éå¸¸ä¸ç¨³å®šã€‚æœ¬æ–‡æå‡ºäº†ç¬¬ä¸€ä¸ªé’ˆå¯¹VGGTçš„é‡åŒ–æ¡†æ¶ï¼Œå³QuantVGGTã€‚è¿™ä¸»è¦ä¾èµ–äºä¸¤é¡¹æŠ€æœ¯è´¡çŒ®ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥äº†åŒé‡å¹³æ»‘ç»†ç²’åº¦é‡åŒ–ï¼Œå®ƒé›†æˆäº†é¢„å…¨å±€Hadamardæ—‹è½¬å’Œåå±€éƒ¨é€šé“å¹³æ»‘ï¼Œä»¥ç¨³å¥åœ°å‡è½»é‡å°¾åˆ†å¸ƒå’Œé€šé“é—´æ–¹å·®ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬è®¾è®¡äº†å™ªå£°è¿‡æ»¤å¤šæ ·æ€§é‡‡æ ·ï¼Œé€šè¿‡æ·±å±‚ç»Ÿè®¡ä¿¡æ¯è¿‡æ»¤å¼‚å¸¸å€¼ï¼Œå¹¶æ„å»ºå¸§æ„ŸçŸ¥å¤šæ ·æ€§æ ¡å‡†é›†ç¾¤ï¼Œä»¥ç¡®ä¿ç¨³å®šçš„é‡åŒ–èŒƒå›´ã€‚ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒQuantVGGTåœ¨ä¸åŒçš„åŸºå‡†å’Œä½å®½ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå¤§å¤§è¶…è¿‡äº†ä»¥å‰æœ€å…ˆè¿›çš„é€šç”¨é‡åŒ–æ–¹æ³•ã€‚æˆ‘ä»¬å¼ºè°ƒï¼Œæˆ‘ä»¬çš„4ä½QuantVGGTå¯ä»¥åœ¨å®é™…ç¡¬ä»¶æ¨ç†ä¸­å®ç°3.7å€çš„å†…å­˜å‡å°‘å’Œ2.5å€çš„åŠ é€Ÿï¼ŒåŒæ—¶ä¿æŒé‡å»ºç²¾åº¦é«˜äºå…¶å…¨ç²¾åº¦ç‰ˆæœ¬çš„98%ã€‚è¿™è¯æ˜äº†QuantVGGTåœ¨èµ„æºå—é™åœºæ™¯ä¸­çš„å·¨å¤§ä¼˜åŠ¿å’Œå®ç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºTransformerçš„3Dé‡å»ºæ¨¡å‹ï¼ˆå¦‚VGGTï¼‰å‚æ•°é‡å·¨å¤§ï¼Œè®¡ç®—å¤æ‚åº¦é«˜ï¼Œéš¾ä»¥éƒ¨ç½²åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šã€‚ç›´æ¥åº”ç”¨åè®­ç»ƒé‡åŒ–ï¼ˆPTQï¼‰æ–¹æ³•å‹ç¼©VGGTæ—¶ï¼Œä¼šé‡åˆ°ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯æ•°æ®æ— å…³çš„ç‰¹æ®Štokenå¯¼è‡´æ¿€æ´»å€¼å‘ˆç°é‡å°¾åˆ†å¸ƒï¼Œå½±å“é‡åŒ–ç²¾åº¦ï¼›äºŒæ˜¯å¤šè§†è§’3Dæ•°æ®ä½¿å¾—æ ¡å‡†æ ·æœ¬çš„é€‰æ‹©ä¸ç¨³å®šï¼Œå¯¼è‡´é‡åŒ–èŒƒå›´åå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šQuantVGGTçš„æ ¸å¿ƒæ€è·¯æ˜¯é’ˆå¯¹VGGTçš„ç‰¹æ€§ï¼Œè®¾è®¡ä¸“é—¨çš„é‡åŒ–ç­–ç•¥ï¼Œä»¥è§£å†³PTQåœ¨VGGTä¸Šé‡åˆ°çš„é‡å°¾æ¿€æ´»åˆ†å¸ƒå’Œæ ¡å‡†æ ·æœ¬é€‰æ‹©ä¸ç¨³å®šçš„é—®é¢˜ã€‚é€šè¿‡åŒé‡å¹³æ»‘ç»†ç²’åº¦é‡åŒ–æ¥å¤„ç†é‡å°¾åˆ†å¸ƒï¼Œå¹¶é€šè¿‡å™ªå£°è¿‡æ»¤å¤šæ ·æ€§é‡‡æ ·æ¥ç¨³å®šæ ¡å‡†æ ·æœ¬çš„é€‰æ‹©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šQuantVGGTçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šåŒé‡å¹³æ»‘ç»†ç²’åº¦é‡åŒ–å’Œå™ªå£°è¿‡æ»¤å¤šæ ·æ€§é‡‡æ ·ã€‚é¦–å…ˆï¼Œå¯¹VGGTæ¨¡å‹è¿›è¡Œé¢„å…¨å±€Hadamardæ—‹è½¬ï¼Œç„¶åè¿›è¡Œé‡åŒ–ï¼Œä¹‹åè¿›è¡Œåå±€éƒ¨é€šé“å¹³æ»‘ã€‚åŒæ—¶ï¼Œåˆ©ç”¨å™ªå£°è¿‡æ»¤å¤šæ ·æ€§é‡‡æ ·æ–¹æ³•é€‰æ‹©åˆé€‚çš„æ ¡å‡†æ•°æ®é›†ï¼Œç”¨äºç¡®å®šé‡åŒ–å‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šQuantVGGTçš„å…³é”®åˆ›æ–°åœ¨äºé’ˆå¯¹VGGTçš„ç‰¹æ€§ï¼Œæå‡ºäº†åŒé‡å¹³æ»‘ç»†ç²’åº¦é‡åŒ–å’Œå™ªå£°è¿‡æ»¤å¤šæ ·æ€§é‡‡æ ·ä¸¤ç§æŠ€æœ¯ã€‚åŒé‡å¹³æ»‘ç»†ç²’åº¦é‡åŒ–é€šè¿‡é¢„å…¨å±€Hadamardæ—‹è½¬å’Œåå±€éƒ¨é€šé“å¹³æ»‘ï¼Œæœ‰æ•ˆç¼“è§£äº†é‡å°¾æ¿€æ´»åˆ†å¸ƒå’Œé€šé“é—´æ–¹å·®ï¼Œæé«˜äº†é‡åŒ–ç²¾åº¦ã€‚å™ªå£°è¿‡æ»¤å¤šæ ·æ€§é‡‡æ ·é€šè¿‡æ·±å±‚ç»Ÿè®¡ä¿¡æ¯è¿‡æ»¤å¼‚å¸¸å€¼ï¼Œå¹¶æ„å»ºå¸§æ„ŸçŸ¥å¤šæ ·æ€§æ ¡å‡†é›†ç¾¤ï¼Œç¡®ä¿äº†é‡åŒ–èŒƒå›´çš„ç¨³å®šã€‚

**å…³é”®è®¾è®¡**ï¼šåŒé‡å¹³æ»‘ç»†ç²’åº¦é‡åŒ–ä¸­ï¼ŒHadamardæ—‹è½¬æ˜¯ä¸€ç§æ­£äº¤å˜æ¢ï¼Œç”¨äºé™ä½é€šé“é—´çš„ç›¸å…³æ€§ï¼Œä»è€Œç¼“è§£é‡å°¾åˆ†å¸ƒã€‚åå±€éƒ¨é€šé“å¹³æ»‘åˆ™é€šè¿‡å¯¹é‡åŒ–åçš„æ¿€æ´»å€¼è¿›è¡Œå¹³æ»‘å¤„ç†ï¼Œè¿›ä¸€æ­¥é™ä½é‡åŒ–è¯¯å·®ã€‚å™ªå£°è¿‡æ»¤å¤šæ ·æ€§é‡‡æ ·ä¸­ï¼Œæ·±å±‚ç»Ÿè®¡ä¿¡æ¯ç”¨äºè¯†åˆ«å’Œè¿‡æ»¤å¼‚å¸¸å€¼ï¼Œå¸§æ„ŸçŸ¥å¤šæ ·æ€§æ ¡å‡†é›†ç¾¤åˆ™ä¿è¯äº†æ ¡å‡†æ ·æœ¬çš„å¤šæ ·æ€§å’Œä»£è¡¨æ€§ã€‚å…·ä½“çš„é‡åŒ–ä½å®½é€‰æ‹©å’Œå‚æ•°è®¾ç½®éœ€è¦æ ¹æ®å®é™…åº”ç”¨åœºæ™¯è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

QuantVGGTåœ¨å¤šä¸ª3Dé‡å»ºåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†state-of-the-artçš„ç»“æœï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„é€šç”¨é‡åŒ–æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯åœ¨4ä½é‡åŒ–ä¸‹ï¼ŒQuantVGGTå®ç°äº†3.7å€çš„å†…å­˜å‡å°‘å’Œ2.5å€çš„åŠ é€Ÿï¼ŒåŒæ—¶ä¿æŒäº†é‡å»ºç²¾åº¦é«˜äºå…¨ç²¾åº¦æ¨¡å‹çš„98%ã€‚è¿™äº›ç»“æœè¡¨æ˜QuantVGGTåœ¨å®é™…ç¡¬ä»¶ä¸Šçš„é«˜æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

QuantVGGTåœ¨èµ„æºå—é™çš„åœºæ™¯ä¸‹å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚ç§»åŠ¨è®¾å¤‡ä¸Šçš„3Dé‡å»ºã€æœºå™¨äººå¯¼èˆªã€å¢å¼ºç°å®ç­‰ã€‚é€šè¿‡é™ä½æ¨¡å‹çš„è®¡ç®—å’Œå†…å­˜éœ€æ±‚ï¼ŒQuantVGGTä½¿å¾—è¿™äº›åº”ç”¨èƒ½å¤Ÿåœ¨ä½åŠŸè€—ã€ä½æˆæœ¬çš„ç¡¬ä»¶å¹³å°ä¸Šè¿è¡Œï¼ŒåŠ é€Ÿäº†3Dé‡å»ºæŠ€æœ¯çš„æ™®åŠå’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Learning-based 3D reconstruction models, represented by Visual Geometry Grounded Transformers (VGGTs), have made remarkable progress with the use of large-scale transformers. Their prohibitive computational and memory costs severely hinder real-world deployment. Post-Training Quantization (PTQ) has become a common practice for compressing and accelerating models. However, we empirically observe that PTQ faces unique obstacles when compressing billion-scale VGGTs: the data-independent special tokens induce heavy-tailed activation distributions, while the multi-view nature of 3D data makes calibration sample selection highly unstable. This paper proposes the first Quantization framework for VGGTs, namely QuantVGGT. This mainly relies on two technical contributions: First, we introduce Dual-Smoothed Fine-Grained Quantization, which integrates pre-global Hadamard rotation and post-local channel smoothing to mitigate heavy-tailed distributions and inter-channel variance robustly. Second, we design Noise-Filtered Diverse Sampling, which filters outliers via deep-layer statistics and constructs frame-aware diverse calibration clusters to ensure stable quantization ranges. Comprehensive experiments demonstrate that QuantVGGT achieves the state-of-the-art results across different benchmarks and bit-width, surpassing the previous state-of-the-art generic quantization method with a great margin. We highlight that our 4-bit QuantVGGT can deliver a 3.7$\times$ memory reduction and 2.5$\times$ acceleration in real-hardware inference, while maintaining reconstruction accuracy above 98\% of its full-precision counterpart. This demonstrates the vast advantages and practicality of QuantVGGT in resource-constrained scenarios. Our code is released in https://github.com/wlfeng0509/QuantVGGT.

