---
layout: default
title: MORPH: PDE Foundation Models with Arbitrary Data Modality
---

# MORPH: PDE Foundation Models with Arbitrary Data Modality

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21670" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21670v3</a>
  <a href="https://arxiv.org/pdf/2509.21670.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21670v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21670v3', 'MORPH: PDE Foundation Models with Arbitrary Data Modality')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mahindra Singh Rautela, Alexander Most, Siddharth Mansingh, Bradley C. Love, Ayan Biswas, Diane Oyen, Earl Lawrence

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG, physics.comp-ph

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25 (æ›´æ–°: 2025-12-04)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/lanl/MORPH)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMORPHæ¨¡å‹ä»¥å¤„ç†å¤šæ¨¡æ€åå¾®åˆ†æ–¹ç¨‹æ•°æ®**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åå¾®åˆ†æ–¹ç¨‹` `å¤šæ¨¡æ€å­¦ä¹ ` `å·ç§¯è§†è§‰å˜æ¢å™¨` `è‡ªå›å½’æ¨¡å‹` `ç§‘å­¦æœºå™¨å­¦ä¹ ` `æ•°æ®é©±åŠ¨` `è¿ç§»å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¼‚æ„å’Œå¤šæ¨¡æ€çš„åå¾®åˆ†æ–¹ç¨‹æ•°æ®æ—¶ï¼Œé¢ä¸´è®¡ç®—æ•ˆç‡ä½å’Œä¿¡æ¯ä¼ é€’ä¸å……åˆ†çš„æŒ‘æˆ˜ã€‚
2. MORPHæ¨¡å‹é€šè¿‡å·ç§¯è§†è§‰å˜æ¢å™¨æ¶æ„ï¼Œç»“åˆç»„ä»¶å·ç§¯å’Œäº¤å‰æ³¨æ„åŠ›ç­‰æŠ€æœ¯ï¼Œæœ‰æ•ˆæ•æ‰å±€éƒ¨äº¤äº’å’Œä¸åŒç‰©ç†åœºä¹‹é—´çš„ä¿¡æ¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒMORPHåœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­è¶…è¶Šäº†å¼ºåŸºçº¿å’Œæœ€æ–°çš„å…ˆè¿›æ¨¡å‹ï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šçš„è¿ç§»å­¦ä¹ èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†MORPHï¼Œè¿™æ˜¯ä¸€ç§æ¨¡æ€æ— å…³çš„è‡ªå›å½’åŸºç¡€æ¨¡å‹ï¼Œä¸“é—¨ç”¨äºåå¾®åˆ†æ–¹ç¨‹ï¼ˆPDEï¼‰ã€‚MORPHåŸºäºå·ç§¯è§†è§‰å˜æ¢å™¨éª¨å¹²ç½‘ç»œï¼Œèƒ½å¤Ÿæ— ç¼å¤„ç†ä¸åŒåˆ†è¾¨ç‡çš„å¼‚æ„æ—¶ç©ºæ•°æ®é›†ï¼ŒåŒ…æ‹¬1Dåˆ°3Dçš„å¤šç§æ•°æ®æ¨¡æ€ï¼Œä»¥åŠæ··åˆæ ‡é‡å’Œå‘é‡æˆåˆ†çš„å¤šä¸ªåœºã€‚è¯¥æ¶æ„ç»“åˆäº†ç»„ä»¶å·ç§¯ã€åœºé—´äº¤å‰æ³¨æ„åŠ›å’Œè½´å‘æ³¨æ„åŠ›ç­‰æŠ€æœ¯ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—è´Ÿæ‹…ï¼ŒåŒæ—¶ä¿æŒäº†è¡¨è¾¾èƒ½åŠ›ã€‚é€šè¿‡åœ¨å¤šæ ·åŒ–çš„PDEæ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼ŒMORPHåœ¨å¤šä¸ªä¸‹æ¸¸é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ä»å¤´è®­ç»ƒçš„æ¨¡å‹ï¼Œå±•ç¤ºäº†å…¶åœ¨ç§‘å­¦è§‚å¯Ÿçš„å¼‚æ„å’Œå¤šæ¨¡æ€å­¦ä¹ ä¸­çš„çµæ´»æ€§å’Œå¼ºå¤§èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨å¤„ç†å¼‚æ„å’Œå¤šæ¨¡æ€åå¾®åˆ†æ–¹ç¨‹ï¼ˆPDEï¼‰æ•°æ®æ—¶ï¼Œç°æœ‰æ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡å’Œä¿¡æ¯ä¼ é€’æ–¹é¢çš„ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMORPHæ¨¡å‹é‡‡ç”¨å·ç§¯è§†è§‰å˜æ¢å™¨æ¶æ„ï¼Œè®¾è®¡äº†ç»„ä»¶å·ç§¯å’Œäº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥æœ‰æ•ˆæ•æ‰å±€éƒ¨äº¤äº’å’Œä¸åŒç‰©ç†åœºä¹‹é—´çš„ä¿¡æ¯ä¼ æ’­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMORPHçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç»„ä»¶å·ç§¯æ¨¡å—ã€åœºé—´äº¤å‰æ³¨æ„åŠ›æ¨¡å—å’Œè½´å‘æ³¨æ„åŠ›æ¨¡å—ï¼Œèƒ½å¤Ÿå¤„ç†ä¸åŒåˆ†è¾¨ç‡å’Œæ¨¡æ€çš„æ•°æ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šMORPHçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æ¨¡æ€æ— å…³æ€§å’Œè‡ªå›å½’ç‰¹æ€§ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†æ ‡é‡å’Œå‘é‡æ•°æ®ï¼Œå¹¶é€šè¿‡è½´å‘æ³¨æ„åŠ›é™ä½è®¡ç®—å¤æ‚åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹é‡‡ç”¨äº†ä½ç§©é€‚é…å™¨ï¼ˆLoRAï¼‰è¿›è¡Œå‚æ•°é«˜æ•ˆçš„å¾®è°ƒï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šè€ƒè™‘äº†å¤šæ¨¡æ€æ•°æ®çš„ç‰¹æ€§ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å¤šæ ·åŒ–æ•°æ®é›†ä¸Šçš„æœ‰æ•ˆå­¦ä¹ ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡çš„è¯„ä¼°ä¸­ï¼ŒMORPHæ¨¡å‹çš„è¡¨ç°è¶…è¶Šäº†ä»å¤´è®­ç»ƒçš„æ¨¡å‹ï¼Œä¸”åœ¨ä¸å¼ºåŸºçº¿å’Œæœ€æ–°æ¨¡å‹çš„æ¯”è¾ƒä¸­ï¼Œå±•ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†å…¶åœ¨ç§‘å­¦æœºå™¨å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MORPHæ¨¡å‹åœ¨ç§‘å­¦è®¡ç®—ã€æ°”å€™æ¨¡æ‹Ÿã€æµä½“åŠ¨åŠ›å­¦ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶çµæ´»çš„æ¶æ„èƒ½å¤Ÿå¤„ç†å¤æ‚çš„ç‰©ç†ç°è±¡ï¼Œä¸ºç§‘å­¦æœºå™¨å­¦ä¹ æä¾›äº†æ–°çš„æ€è·¯ï¼Œæ¨åŠ¨äº†æ•°æ®é©±åŠ¨çš„ç§‘å­¦ç ”ç©¶è¿›å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce MORPH, a modality-agnostic, autoregressive foundation model for partial differential equations (PDEs). MORPH is built on a convolutional vision transformer backbone that seamlessly handles heterogeneous spatiotemporal datasets of varying data modality (1D--3D) at different resolutions, and multiple fields with mixed scalar and vector components. The architecture combines (i) component-wise convolution, which jointly processes scalar and vector channels to capture local interactions, (ii) inter-field cross-attention, which models and selectively propagates information between different physical fields, (iii) axial attentions, which factorize full spatiotemporal self-attention along individual spatial and temporal axes to reduce computational burden while retaining expressivity. We pretrain multiple model variants on a diverse collection of heterogeneous PDE datasets and evaluate transfer to a range of downstream prediction tasks. Using both full-model fine-tuning and parameter-efficient low-rank adapters (LoRA), MORPH outperforms models trained from scratch. Across extensive evaluations, MORPH matches or surpasses strong baselines and recent state-of-the-art models. Collectively, these capabilities present a flexible and powerful backbone for learning from the heterogeneous and multimodal nature of scientific observations, charting a path toward scalable and data-efficient scientific machine learning. The source code, datasets, and models are publicly available at https://github.com/lanl/MORPH.

