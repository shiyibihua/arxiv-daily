---
layout: default
title: VideoJudge: Bootstrapping Enables Scalable Supervision of MLLM-as-a-Judge for Video Understanding
---

# VideoJudge: Bootstrapping Enables Scalable Supervision of MLLM-as-a-Judge for Video Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21451" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21451v1</a>
  <a href="https://arxiv.org/pdf/2509.21451.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21451v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21451v1', 'VideoJudge: Bootstrapping Enables Scalable Supervision of MLLM-as-a-Judge for Video Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Abdul Waheed, Zhen Wu, Dareen Alharthi, Seungone Kim, Bhiksha Raj

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25

**å¤‡æ³¨**: Work in progress

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VideoJudgeï¼šé€šè¿‡è‡ªä¸¾æ³•å®ç°MLLMä½œä¸ºè§†é¢‘ç†è§£è¯„åˆ¤å™¨çš„å¯æ‰©å±•ç›‘ç£**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘ç†è§£` `å¤šæ¨¡æ€å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªä¸¾å­¦ä¹ ` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘ç†è§£æ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚BLEUï¼‰æ— æ³•å‡†ç¡®åæ˜ äººç±»çš„ç»†å¾®åˆ¤æ–­ï¼Œäººå·¥è¯„ä¼°æˆæœ¬é«˜æ˜‚ã€‚
2. VideoJudgeé€šè¿‡ç”Ÿæˆå™¨å’Œè¯„ä¼°å™¨ä¹‹é—´çš„è‡ªä¸¾æ–¹æ³•ï¼Œè®­ç»ƒä¸“é—¨ç”¨äºè§†é¢‘ç†è§£è¯„ä¼°çš„MLLMè¯„åˆ¤å™¨ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVideoJudge-7Båœ¨å¤šä¸ªå…ƒè¯„ä¼°åŸºå‡†ä¸Šä¼˜äºæ›´å¤§çš„MLLMè¯„åˆ¤å™¨åŸºçº¿ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç²¾ç¡®è¯„ä¼°è§†é¢‘ç†è§£æ¨¡å‹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼šå¸¸ç”¨çš„æŒ‡æ ‡å¦‚BLEUã€ROUGEå’ŒBERTScoreæ— æ³•æ•æ‰äººç±»åˆ¤æ–­çš„ç»†å¾®ä¹‹å¤„ï¼Œè€Œé€šè¿‡äººå·¥è¯„ä¼°è·å¾—æ­¤ç±»åˆ¤æ–­çš„æˆæœ¬å¾ˆé«˜ã€‚æœ€è¿‘çš„å·¥ä½œæ¢ç´¢äº†ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æˆ–å¤šæ¨¡æ€LLMï¼ˆMLLMï¼‰ä½œä¸ºè¯„ä¼°å™¨ï¼Œä½†å®ƒä»¬åœ¨è§†é¢‘ç†è§£ä¸­çš„æ‰©å±•ä»ç„¶ç›¸å¯¹æœªè¢«æ¢ç´¢ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†VideoJudgeï¼Œä¸€ä¸ª3Bå’Œ7Bå¤§å°çš„MLLMè¯„åˆ¤å™¨ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°è§†é¢‘ç†è§£æ¨¡å‹çš„è¾“å‡ºï¼ˆå³ï¼Œä»¥è§†é¢‘ä¸ºæ¡ä»¶çš„æ–‡æœ¬å“åº”ï¼‰ã€‚ä¸ºäº†è®­ç»ƒVideoJudgeï¼Œæˆ‘ä»¬çš„æ–¹æ³•å»ºç«‹åœ¨ç”Ÿæˆå™¨å’Œè¯„ä¼°å™¨ä¹‹é—´çš„ç›¸äº’ä½œç”¨ä¸Šï¼šæç¤ºç”Ÿæˆå™¨äº§ç”Ÿä»¥ç›®æ ‡è¯„çº§ä¸ºæ¡ä»¶çš„å“åº”ï¼Œå¹¶ä¸¢å¼ƒä¸è¯„ä¼°å™¨çš„è¯„çº§ä¸åŒ¹é…çš„å“åº”ã€‚åœ¨å››ä¸ªå…ƒè¯„ä¼°åŸºå‡†ä¸­çš„ä¸‰ä¸ªä¸Šï¼ŒVideoJudge-7Bä¼˜äºæ›´å¤§çš„MLLMè¯„åˆ¤å™¨åŸºçº¿ï¼Œå¦‚Qwen2.5-VLï¼ˆ32Bå’Œ72Bï¼‰ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬å‘ç°LLMè¯„åˆ¤å™¨ï¼ˆQwen3ï¼‰æ¨¡å‹çš„æ€§èƒ½æ¯”MLLMè¯„åˆ¤å™¨ï¼ˆQwen2.5-VLï¼‰æ›´å·®ï¼Œå¹¶ä¸”é•¿é“¾å¼æ€ç»´æ¨ç†å¹¶æ²¡æœ‰æé«˜æ€§èƒ½ï¼Œè¿™è¡¨æ˜æä¾›è§†é¢‘è¾“å…¥å¯¹äºè¯„ä¼°è§†é¢‘ç†è§£ä»»åŠ¡è‡³å…³é‡è¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†é¢‘ç†è§£æ¨¡å‹è¯„ä¼°ä¸å‡†ç¡®ä¸”æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚ç°æœ‰è¯„ä¼°æ–¹æ³•ï¼Œå¦‚BLEUã€ROUGEç­‰ï¼Œæ— æ³•æ•æ‰äººç±»åˆ¤æ–­çš„ç»†å¾®å·®åˆ«ã€‚äººå·¥è¯„ä¼°è™½ç„¶å‡†ç¡®ï¼Œä½†è€—æ—¶è€—åŠ›ï¼Œéš¾ä»¥å¤§è§„æ¨¡åº”ç”¨ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿè‡ªåŠ¨ã€å‡†ç¡®ä¸”é«˜æ•ˆåœ°è¯„ä¼°è§†é¢‘ç†è§£æ¨¡å‹çš„æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ä½œä¸ºè¯„åˆ¤å™¨ï¼Œå¹¶é‡‡ç”¨è‡ªä¸¾æ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚é€šè¿‡ç”Ÿæˆå™¨ç”Ÿæˆå¸¦æœ‰ç›®æ ‡è¯„åˆ†çš„å“åº”ï¼Œç„¶åç”±MLLMè¯„åˆ¤å™¨è¿›è¡Œè¯„ä¼°ï¼Œä¸åŒ¹é…çš„å“åº”å°†è¢«ä¸¢å¼ƒã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°è®­ç»ƒMLLMè¯„åˆ¤å™¨ï¼Œä½¿å…¶èƒ½å¤Ÿå‡†ç¡®åœ°è¯„ä¼°è§†é¢‘ç†è§£æ¨¡å‹çš„è¾“å‡ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVideoJudgeçš„è®­ç»ƒæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç”Ÿæˆå™¨å’Œè¯„ä¼°å™¨ã€‚ç”Ÿæˆå™¨è´Ÿè´£æ ¹æ®ç»™å®šçš„è§†é¢‘å’Œç›®æ ‡è¯„åˆ†ç”Ÿæˆæ–‡æœ¬å“åº”ã€‚è¯„ä¼°å™¨æ˜¯ä¸€ä¸ªMLLMï¼Œè´Ÿè´£è¯„ä¼°ç”Ÿæˆå™¨ç”Ÿæˆçš„å“åº”ä¸ç›®æ ‡è¯„åˆ†æ˜¯å¦ä¸€è‡´ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç”Ÿæˆå™¨å’Œè¯„ä¼°å™¨ç›¸äº’ä½œç”¨ï¼Œä¸æ–­ä¼˜åŒ–å„è‡ªçš„æ€§èƒ½ã€‚å…·ä½“æµç¨‹å¦‚ä¸‹ï¼š1) ç»™å®šè§†é¢‘å’Œç›®æ ‡è¯„åˆ†ï¼Œç”Ÿæˆå™¨ç”Ÿæˆæ–‡æœ¬å“åº”ï¼›2) è¯„ä¼°å™¨è¯„ä¼°ç”Ÿæˆçš„å“åº”ä¸ç›®æ ‡è¯„åˆ†æ˜¯å¦ä¸€è‡´ï¼›3) å¦‚æœä¸€è‡´ï¼Œåˆ™ä¿ç•™è¯¥æ ·æœ¬ï¼›å¦åˆ™ï¼Œä¸¢å¼ƒè¯¥æ ·æœ¬ï¼›4) ä½¿ç”¨ä¿ç•™çš„æ ·æœ¬è®­ç»ƒç”Ÿæˆå™¨å’Œè¯„ä¼°å™¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†åŸºäºè‡ªä¸¾æ³•çš„MLLMè¯„åˆ¤å™¨è®­ç»ƒæ–¹æ³•ã€‚è¯¥æ–¹æ³•æ— éœ€å¤§é‡äººå·¥æ ‡æ³¨æ•°æ®ï¼Œå³å¯è®­ç»ƒå‡ºèƒ½å¤Ÿå‡†ç¡®è¯„ä¼°è§†é¢‘ç†è§£æ¨¡å‹çš„MLLMè¯„åˆ¤å™¨ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å‘ç°ï¼Œå¯¹äºè§†é¢‘ç†è§£ä»»åŠ¡çš„è¯„ä¼°ï¼ŒMLLMè¯„åˆ¤å™¨çš„æ€§èƒ½ä¼˜äºLLMè¯„åˆ¤å™¨ï¼Œå¹¶ä¸”é•¿é“¾å¼æ€ç»´æ¨ç†å¹¶æ²¡æœ‰æ˜¾è‘—æé«˜æ€§èƒ½ï¼Œè¿™è¡¨æ˜æä¾›è§†é¢‘è¾“å…¥å¯¹äºè¯„ä¼°è‡³å…³é‡è¦ã€‚

**å…³é”®è®¾è®¡**ï¼šVideoJudgeä½¿ç”¨äº†3Bå’Œ7Bä¸¤ç§å°ºå¯¸çš„MLLMä½œä¸ºè¯„ä¼°å™¨ã€‚ç”Ÿæˆå™¨å¯ä»¥ä½¿ç”¨å„ç§è§†é¢‘ç†è§£æ¨¡å‹ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥é‡‡ç”¨é¢„è®­ç»ƒçš„è§†é¢‘ç¼–ç å™¨å’Œæ–‡æœ¬è§£ç å™¨ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯ä»¥ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç”Ÿæˆå™¨å’Œè¯„ä¼°å™¨çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¿˜å¯ä»¥é‡‡ç”¨å„ç§æ­£åˆ™åŒ–æŠ€æœ¯æ¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVideoJudge-7Båœ¨å››ä¸ªå…ƒè¯„ä¼°åŸºå‡†ä¸­çš„ä¸‰ä¸ªä¸Šä¼˜äºæ›´å¤§çš„MLLMè¯„åˆ¤å™¨åŸºçº¿ï¼Œå¦‚Qwen2.5-VLï¼ˆ32Bå’Œ72Bï¼‰ã€‚è¿™è¡¨æ˜ï¼Œé€šè¿‡è‡ªä¸¾æ³•è®­ç»ƒçš„VideoJudgeèƒ½å¤Ÿæœ‰æ•ˆåœ°è¯„ä¼°è§†é¢‘ç†è§£æ¨¡å‹çš„è¾“å‡ºï¼Œå¹¶ä¸”å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜å‘ç°ï¼ŒLLMè¯„åˆ¤å™¨ï¼ˆQwen3ï¼‰çš„æ€§èƒ½ä¸å¦‚MLLMè¯„åˆ¤å™¨ï¼ˆQwen2.5-VLï¼‰ï¼Œè¡¨æ˜è§†é¢‘è¾“å…¥å¯¹äºè¯„ä¼°è§†é¢‘ç†è§£ä»»åŠ¡è‡³å…³é‡è¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VideoJudgeå¯åº”ç”¨äºè§†é¢‘ç†è§£æ¨¡å‹çš„è‡ªåŠ¨è¯„ä¼°å’Œæ€§èƒ½ç›‘æ§ï¼ŒåŠ é€Ÿæ¨¡å‹å¼€å‘è¿­ä»£è¿‡ç¨‹ã€‚å®ƒè¿˜å¯ç”¨äºæ„å»ºè‡ªåŠ¨åŒ–çš„è§†é¢‘å†…å®¹å®¡æ ¸ç³»ç»Ÿï¼Œæé«˜å®¡æ ¸æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯åº”ç”¨äºæ•™è‚²é¢†åŸŸï¼Œè‡ªåŠ¨è¯„ä¼°å­¦ç”Ÿå¯¹è§†é¢‘å†…å®¹çš„ç†è§£ç¨‹åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Precisely evaluating video understanding models remains challenging: commonly used metrics such as BLEU, ROUGE, and BERTScore fail to capture the fineness of human judgment, while obtaining such judgments through manual evaluation is costly. Recent work has explored using large language models (LLMs) or multimodal LLMs (MLLMs) as evaluators, but their extension to video understanding remains relatively unexplored. In this work, we introduce VideoJudge, a 3B and 7B-sized MLLM judge specialized to evaluate outputs from video understanding models (\textit{i.e.}, text responses conditioned on videos). To train VideoJudge, our recipe builds on the interplay between a generator and an evaluator: the generator is prompted to produce responses conditioned on a target rating, and responses not matching the evaluator's rating are discarded. Across three out of four meta-evaluation benchmarks, VideoJudge-7B outperforms larger MLLM judge baselines such as Qwen2.5-VL (32B and 72B). Notably, we find that LLM judges (Qwen3) models perform worse than MLLM judges (Qwen2.5-VL) and long chain-of-thought reasoning does not improve performance, indicating that providing video inputs is crucial for evaluation of video understanding tasks.

