---
layout: default
title: Dense Semantic Matching with VGGT Prior
---

# Dense Semantic Matching with VGGT Prior

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21263" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21263v1</a>
  <a href="https://arxiv.org/pdf/2509.21263.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21263v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21263v1', 'Dense Semantic Matching with VGGT Prior')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Songlin Yang, Tianyi Wei, Yushi Lan, Zeqi Xiao, Anyi Rao, Xingang Pan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºVGGTå…ˆéªŒçš„ç¨ å¯†è¯­ä¹‰åŒ¹é…æ–¹æ³•ï¼Œæå‡å‡ ä½•æ„ŸçŸ¥å’ŒåŒ¹é…å¯é æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­ä¹‰åŒ¹é…` `ç¨ å¯†å¯¹åº”` `å‡ ä½•å…ˆéªŒ` `VGGT` `å¾ªç¯ä¸€è‡´æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­ä¹‰åŒ¹é…æ–¹æ³•ä¾èµ–2Dç‰¹å¾ï¼Œéš¾ä»¥å¤„ç†å¯¹ç§°ç»“æ„ï¼Œæ³›åŒ–æ€§ä¸è¶³ï¼Œä¸”å¿½ç•¥äº†è·¨å›¾ä¸å¯è§æ€§å’Œæµå½¢ä¿æŒã€‚
2. è®ºæ–‡åˆ©ç”¨3Då‡ ä½•åŸºç¡€æ¨¡å‹VGGTçš„å‡ ä½•æ„ŸçŸ¥èƒ½åŠ›ï¼Œé€šè¿‡é‡ç”¨å’Œå¾®è°ƒVGGTç‰¹å¾ï¼Œå¹¶æ·»åŠ è¯­ä¹‰å¤´ï¼Œå®ç°æ›´å¯é çš„åŒ¹é…ã€‚
3. é€šè¿‡å¾ªç¯ä¸€è‡´æ€§è®­ç»ƒã€åˆæˆæ•°æ®å¢å¼ºå’Œæ¸è¿›å¼è®­ç»ƒï¼Œå…‹æœäº†æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œå®éªŒè¡¨æ˜è¯¥æ–¹æ³•ä¼˜äºç°æœ‰åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯­ä¹‰åŒ¹é…æ—¨åœ¨å»ºç«‹åŒä¸€ç±»åˆ«å®ä¾‹ä¹‹é—´çš„åƒç´ çº§å¯¹åº”å…³ç³»ï¼Œæ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„ä¸€é¡¹åŸºæœ¬ä»»åŠ¡ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªå±€é™æ€§ï¼šï¼ˆiï¼‰å‡ ä½•æ­§ä¹‰ï¼šå®ƒä»¬ä¾èµ–äº2DåŸºç¡€æ¨¡å‹ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼ŒStable Diffusionã€DINOï¼‰ï¼Œé€šå¸¸æ— æ³•æ¶ˆé™¤å¯¹ç§°ç»“æ„çš„æ­§ä¹‰ï¼Œéœ€è¦é¢å¤–çš„å¾®è°ƒï¼Œä¸”ç¼ºä¹æ³›åŒ–æ€§ï¼›ï¼ˆiiï¼‰æœ€è¿‘é‚»è§„åˆ™ï¼šå®ƒä»¬çš„åƒç´ çº§åŒ¹é…å¿½ç•¥äº†è·¨å›¾åƒçš„ä¸å¯è§æ€§ï¼Œå¹¶å¿½ç•¥äº†æµå½¢ä¿æŒã€‚è¿™äº›æŒ‘æˆ˜éœ€è¦å…·æœ‰å‡ ä½•æ„ŸçŸ¥çš„åƒç´ æè¿°ç¬¦å’Œæ•´ä½“ç¨ å¯†å¯¹åº”æœºåˆ¶ã€‚å—3Då‡ ä½•åŸºç¡€æ¨¡å‹æœ€æ–°è¿›å±•çš„å¯å‘ï¼Œæˆ‘ä»¬è½¬å‘VGGTï¼Œå®ƒæä¾›äº†ä¸è¿™äº›éœ€æ±‚éå¸¸å»åˆçš„å‡ ä½•åŸºç¡€ç‰¹å¾å’Œæ•´ä½“ç¨ å¯†åŒ¹é…èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç›´æ¥è¿ç§»VGGTå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå®ƒæœ€åˆæ˜¯ä¸ºå•ä¸ªå®ä¾‹çš„è·¨è§†è§’å‡ ä½•åŒ¹é…è€Œè®¾è®¡çš„ï¼Œä¸è·¨å®ä¾‹è¯­ä¹‰åŒ¹é…ä¸ä¸€è‡´ï¼Œå¹¶ä¸”å—åˆ°ç¨ å¯†è¯­ä¹‰æ ‡æ³¨ç¨€ç¼ºçš„é˜»ç¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ï¼ˆiï¼‰é€šè¿‡é‡ç”¨æ—©æœŸç‰¹å¾é˜¶æ®µã€å¾®è°ƒåæœŸç‰¹å¾é˜¶æ®µä»¥åŠæ·»åŠ ç”¨äºåŒå‘å¯¹åº”çš„è¯­ä¹‰å¤´æ¥ä¿ç•™VGGTçš„å†…åœ¨ä¼˜åŠ¿ï¼›ï¼ˆiiï¼‰é€šè¿‡å¾ªç¯ä¸€è‡´æ€§è®­ç»ƒç­–ç•¥ã€åˆæˆæ•°æ®å¢å¼ºä»¥åŠå…·æœ‰æ··å ä¼ªå½±ç¼“è§£çš„æ¸è¿›å¼è®­ç»ƒæ–¹æ¡ˆï¼Œä½¿VGGTé€‚åº”æ•°æ®ç¨€ç¼ºæƒ…å†µä¸‹çš„è¯­ä¹‰åŒ¹é…åœºæ™¯ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†å“è¶Šçš„å‡ ä½•æ„ŸçŸ¥ã€åŒ¹é…å¯é æ€§å’Œæµå½¢ä¿æŒï¼Œä¼˜äºå…ˆå‰çš„åŸºçº¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è·¨å®ä¾‹çš„ç¨ å¯†è¯­ä¹‰åŒ¹é…é—®é¢˜ï¼Œå³åœ¨ä¸¤å¼ åŒ…å«ç›¸åŒç±»åˆ«ç‰©ä½“çš„å›¾åƒä¸­ï¼Œæ‰¾åˆ°åƒç´ çº§åˆ«çš„å¯¹åº”å…³ç³»ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äº2Då›¾åƒç‰¹å¾ï¼Œåœ¨å¤„ç†å…·æœ‰å¯¹ç§°ç»“æ„çš„ç‰©ä½“æ—¶å®¹æ˜“äº§ç”Ÿæ­§ä¹‰ï¼Œå¹¶ä¸”å¿½ç•¥äº†å›¾åƒä¹‹é—´çš„é®æŒ¡å…³ç³»ï¼Œå¯¼è‡´åŒ¹é…ç²¾åº¦ä¸é«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨3Då‡ ä½•å…ˆéªŒçŸ¥è¯†æ¥æŒ‡å¯¼è¯­ä¹‰åŒ¹é…ã€‚å…·ä½“æ¥è¯´ï¼Œè®ºæ–‡å€Ÿé‰´äº†VGGTæ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæå–å…·æœ‰å‡ ä½•ä¿¡æ¯çš„ç‰¹å¾ï¼Œä»è€Œæ›´å¥½åœ°å¤„ç†å¯¹ç§°æ€§å’Œé®æŒ¡é—®é¢˜ã€‚åŒæ—¶ï¼Œè®ºæ–‡é€šè¿‡ç‰¹å®šçš„è®­ç»ƒç­–ç•¥ï¼Œå°†VGGTæ¨¡å‹é€‚é…åˆ°è¯­ä¹‰åŒ¹é…ä»»åŠ¡ä¸­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1) ç‰¹å¾æå–ï¼šåˆ©ç”¨VGGTçš„æ—©æœŸå±‚æå–å‡ ä½•ç‰¹å¾ï¼Œå¹¶å¾®è°ƒVGGTçš„åæœŸå±‚ä»¥é€‚åº”è¯­ä¹‰åŒ¹é…ä»»åŠ¡ã€‚2) è¯­ä¹‰å¤´ï¼šæ·»åŠ ä¸€ä¸ªè¯­ä¹‰å¤´ï¼Œç”¨äºé¢„æµ‹åƒç´ çº§åˆ«çš„å¯¹åº”å…³ç³»ã€‚3) è®­ç»ƒç­–ç•¥ï¼šé‡‡ç”¨å¾ªç¯ä¸€è‡´æ€§è®­ç»ƒã€åˆæˆæ•°æ®å¢å¼ºå’Œæ¸è¿›å¼è®­ç»ƒç­‰ç­–ç•¥ï¼Œä»¥å…‹æœæ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œå¹¶æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†3Då‡ ä½•å…ˆéªŒçŸ¥è¯†å¼•å…¥åˆ°è¯­ä¹‰åŒ¹é…ä»»åŠ¡ä¸­ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¯¹ç§°æ€§å’Œé®æŒ¡é—®é¢˜ï¼Œä»è€Œæé«˜åŒ¹é…ç²¾åº¦ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ç³»åˆ—æœ‰æ•ˆçš„è®­ç»ƒç­–ç•¥ï¼Œä»¥å…‹æœæ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç‰¹å¾æå–é˜¶æ®µï¼Œè®ºæ–‡é‡ç”¨äº†VGGTçš„æ—©æœŸå±‚ï¼Œå¹¶å¾®è°ƒäº†VGGTçš„åæœŸå±‚ã€‚è¿™æ ·åšæ—¢ä¿ç•™äº†VGGTçš„å‡ ä½•æ„ŸçŸ¥èƒ½åŠ›ï¼Œåˆä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”è¯­ä¹‰åŒ¹é…ä»»åŠ¡ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œè®ºæ–‡é‡‡ç”¨äº†å¾ªç¯ä¸€è‡´æ€§æŸå¤±ï¼Œä»¥ä¿è¯åŒ¹é…ç»“æœçš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ä½¿ç”¨äº†åˆæˆæ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œä»¥å¢åŠ è®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä¾‹å¦‚ï¼Œåœ¨XXXæ•°æ®é›†ä¸Šï¼ŒåŒ¹é…ç²¾åº¦æé«˜äº†X%ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¯¹ç§°æ€§å’Œé®æŒ¡é—®é¢˜ï¼Œä»è€Œæé«˜äº†åŒ¹é…çš„å¯é æ€§å’Œå‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå›¾åƒç¼–è¾‘ã€ä¸‰ç»´é‡å»ºã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾åƒç¼–è¾‘ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯­ä¹‰åŒ¹é…æŠ€æœ¯å°†ä¸€ä¸ªç‰©ä½“ä»ä¸€å¼ å›¾åƒå¤åˆ¶åˆ°å¦ä¸€å¼ å›¾åƒä¸­ã€‚åœ¨ä¸‰ç»´é‡å»ºä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯­ä¹‰åŒ¹é…æŠ€æœ¯å»ºç«‹ä¸åŒè§†è§’å›¾åƒä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œä»è€Œé‡å»ºå‡ºç‰©ä½“çš„ä¸‰ç»´æ¨¡å‹ã€‚åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯­ä¹‰åŒ¹é…æŠ€æœ¯è¯†åˆ«ç¯å¢ƒä¸­çš„ç‰©ä½“ï¼Œå¹¶è¿›è¡Œå®šä½å’Œå¯¼èˆªã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Semantic matching aims to establish pixel-level correspondences between instances of the same category and represents a fundamental task in computer vision. Existing approaches suffer from two limitations: (i) Geometric Ambiguity: Their reliance on 2D foundation model features (e.g., Stable Diffusion, DINO) often fails to disambiguate symmetric structures, requiring extra fine-tuning yet lacking generalization; (ii) Nearest-Neighbor Rule: Their pixel-wise matching ignores cross-image invisibility and neglects manifold preservation. These challenges call for geometry-aware pixel descriptors and holistic dense correspondence mechanisms. Inspired by recent advances in 3D geometric foundation models, we turn to VGGT, which provides geometry-grounded features and holistic dense matching capabilities well aligned with these needs. However, directly transferring VGGT is challenging, as it was originally designed for geometry matching within cross views of a single instance, misaligned with cross-instance semantic matching, and further hindered by the scarcity of dense semantic annotations. To address this, we propose an approach that (i) retains VGGT's intrinsic strengths by reusing early feature stages, fine-tuning later ones, and adding a semantic head for bidirectional correspondences; and (ii) adapts VGGT to the semantic matching scenario under data scarcity through cycle-consistent training strategy, synthetic data augmentation, and progressive training recipe with aliasing artifact mitigation. Extensive experiments demonstrate that our approach achieves superior geometry awareness, matching reliability, and manifold preservation, outperforming previous baselines.

