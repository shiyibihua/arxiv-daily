---
layout: default
title: "RGBT-Ground Benchmark: Visual Grounding Beyond RGB in Complex Real-World Scenarios"
---

# RGBT-Ground Benchmark: Visual Grounding Beyond RGB in Complex Real-World Scenarios

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.24561" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.24561v1</a>
  <a href="https://arxiv.org/pdf/2512.24561.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.24561v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.24561v1', 'RGBT-Ground Benchmark: Visual Grounding Beyond RGB in Complex Real-World Scenarios')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tianyi Zhao, Jiawen Xi, Linhui Xiao, Junnan Li, Xue Yang, Maoxun Yuan, Xingxing Wei

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-31

**å¤‡æ³¨**: 27pages, 9figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRGBT-GroundåŸºå‡†ï¼Œç”¨äºè¯„ä¼°å¤æ‚åœºæ™¯ä¸‹RGB-Tå›¾åƒçš„è§†è§‰å®šä½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰å®šä½` `å¤šæ¨¡æ€èåˆ` `RGB-Tå›¾åƒ` `çœŸå®åœºæ™¯` `é²æ£’æ€§` `æ·±åº¦å­¦ä¹ ` `æ•°æ®é›†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰å®šä½åŸºå‡†æ•°æ®é›†ç¼ºä¹çœŸå®åœºæ™¯çš„å¤æ‚æ€§ï¼Œéš¾ä»¥è¯„ä¼°æ¨¡å‹åœ¨å…‰ç…§å˜åŒ–ã€æ¶åŠ£å¤©æ°”ç­‰æ¡ä»¶ä¸‹çš„é²æ£’æ€§ã€‚
2. æå‡ºRGBT-Groundæ•°æ®é›†ï¼ŒåŒ…å«RGBå’Œçƒ­çº¢å¤–å›¾åƒå¯¹ï¼Œä»¥åŠé«˜è´¨é‡çš„æŒ‡ä»£è¡¨è¾¾å¼å’Œç»†ç²’åº¦æ ‡æ³¨ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„å®šä½èƒ½åŠ›ã€‚
3. æå‡ºRGBT-VGNetï¼Œä¸€ä¸ªèåˆRGBå’Œçƒ­çº¢å¤–ä¿¡æ¯çš„è§†è§‰å®šä½åŸºçº¿æ¨¡å‹ï¼Œå¹¶åœ¨RGBT-Groundæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰å®šä½ï¼ˆVGï¼‰æ—¨åœ¨æ ¹æ®è‡ªç„¶è¯­è¨€è¡¨è¾¾å¼å®šä½å›¾åƒä¸­çš„ç‰¹å®šå¯¹è±¡ï¼Œæ˜¯è§†è§‰è¯­è¨€ç†è§£ä¸­çš„ä¸€é¡¹åŸºæœ¬ä»»åŠ¡ã€‚ç„¶è€Œï¼Œç°æœ‰çš„VGåŸºå‡†ä¸»è¦æ¥è‡ªåœ¨å¹²å‡€ç¯å¢ƒä¸‹æ”¶é›†çš„æ•°æ®é›†ï¼Œå¦‚COCOï¼Œåœºæ™¯å¤šæ ·æ€§æœ‰é™ã€‚å› æ­¤ï¼Œå®ƒä»¬æ— æ³•åæ˜ çœŸå®ä¸–ç•Œæ¡ä»¶çš„å¤æ‚æ€§ï¼Œå¦‚å…‰ç…§ã€å¤©æ°”ç­‰å˜åŒ–ï¼Œè€Œè¿™äº›å¯¹äºè¯„ä¼°æ¨¡å‹åœ¨å®‰å…¨å…³é”®åº”ç”¨ä¸­çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›è‡³å…³é‡è¦ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†RGBT-Groundï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸ºå¤æ‚çœŸå®ä¸–ç•Œåœºæ™¯æ„å»ºçš„å¤§è§„æ¨¡è§†è§‰å®šä½åŸºå‡†ã€‚å®ƒç”±ç©ºé—´å¯¹é½çš„RGBå’Œçƒ­çº¢å¤–ï¼ˆTIRï¼‰å›¾åƒå¯¹ç»„æˆï¼Œå…·æœ‰é«˜è´¨é‡çš„æŒ‡ä»£è¡¨è¾¾å¼ã€ç›¸åº”çš„å¯¹è±¡è¾¹ç•Œæ¡†ä»¥åŠåœºæ™¯ã€ç¯å¢ƒå’Œå¯¹è±¡çº§åˆ«çš„ç»†ç²’åº¦æ³¨é‡Šã€‚è¯¥åŸºå‡†èƒ½å¤Ÿè¿›è¡Œå…¨é¢è¯„ä¼°ï¼Œå¹¶ä¿ƒè¿›åœ¨å¤šæ ·åŒ–å’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹å¯¹é²æ£’å®šä½çš„ç ”ç©¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªç»Ÿä¸€çš„è§†è§‰å®šä½æ¡†æ¶ï¼Œæ”¯æŒå•æ¨¡æ€ï¼ˆRGBæˆ–TIRï¼‰å’Œå¤šæ¨¡æ€ï¼ˆRGB-TIRï¼‰è§†è§‰è¾“å…¥ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†RGBT-VGNetï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„åŸºçº¿ï¼Œç”¨äºèåˆäº’è¡¥çš„è§†è§‰æ¨¡æ€ä»¥å®ç°é²æ£’å®šä½ã€‚æˆ‘ä»¬å¯¹RGBT-Groundä¸Šçš„ç°æœ‰æ–¹æ³•è¿›è¡Œäº†å¹¿æ³›çš„è°ƒæ•´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„RGBT-VGNetæ˜¾è‘—ä¼˜äºè¿™äº›è°ƒæ•´åçš„æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨å¤œé—´å’Œè¿œè·ç¦»åœºæ™¯ä¸­ã€‚æ‰€æœ‰èµ„æºå°†å…¬å¼€å‘å¸ƒï¼Œä»¥ä¿ƒè¿›æœªæ¥å¯¹å¤æ‚çœŸå®ä¸–ç•Œç¯å¢ƒä¸­é²æ£’è§†è§‰å®šä½çš„ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è§†è§‰å®šä½ï¼ˆVisual Grounding, VGï¼‰æ–¹æ³•å’Œæ•°æ®é›†ä¸»è¦é›†ä¸­åœ¨æ¡ä»¶è‰¯å¥½çš„åœºæ™¯ä¸‹ï¼Œä¾‹å¦‚COCOã€‚ç„¶è€Œï¼Œåœ¨çœŸå®çš„å¤æ‚åœºæ™¯ä¸­ï¼Œå…‰ç…§å˜åŒ–ã€æ¶åŠ£å¤©æ°”ç­‰å› ç´ ä¼šå¯¹è§†è§‰å®šä½çš„æ€§èƒ½äº§ç”Ÿæ˜¾è‘—å½±å“ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ä¸ªèƒ½å¤Ÿåæ˜ çœŸå®ä¸–ç•Œå¤æ‚æ€§çš„æ•°æ®é›†ï¼Œä»¥åŠèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯ï¼ˆå¦‚RGBå’Œçƒ­çº¢å¤–å›¾åƒï¼‰çš„è§†è§‰å®šä½æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå¤§è§„æ¨¡çš„RGBTæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«RGBå’Œçƒ­çº¢å¤–å›¾åƒå¯¹ï¼Œä»¥åŠå¯¹åº”çš„è‡ªç„¶è¯­è¨€æè¿°å’Œç›®æ ‡è¾¹ç•Œæ¡†æ ‡æ³¨ã€‚åŒæ—¶ï¼Œæå‡ºä¸€ä¸ªèƒ½å¤Ÿæœ‰æ•ˆèåˆRGBå’Œçƒ­çº¢å¤–ä¿¡æ¯çš„è§†è§‰å®šä½æ¨¡å‹RGBT-VGNetã€‚é€šè¿‡å¤šæ¨¡æ€ä¿¡æ¯çš„äº’è¡¥ï¼Œæé«˜æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRGBT-VGNetçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ç‰¹å¾æå–æ¨¡å—ï¼šåˆ†åˆ«æå–RGBå’Œçƒ­çº¢å¤–å›¾åƒçš„è§†è§‰ç‰¹å¾ã€‚2) æ–‡æœ¬ç‰¹å¾æå–æ¨¡å—ï¼šæå–è‡ªç„¶è¯­è¨€æè¿°çš„æ–‡æœ¬ç‰¹å¾ã€‚3) å¤šæ¨¡æ€èåˆæ¨¡å—ï¼šå°†è§†è§‰ç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾è¿›è¡Œèåˆã€‚4) å®šä½æ¨¡å—ï¼šæ ¹æ®èåˆåçš„ç‰¹å¾ï¼Œé¢„æµ‹ç›®æ ‡å¯¹è±¡çš„è¾¹ç•Œæ¡†ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æ„å»ºäº†RGBT-Groundæ•°æ®é›†ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå¤§è§„æ¨¡çš„RGBTè§†è§‰å®šä½æ•°æ®é›†ï¼ŒåŒ…å«ä¸°å¯Œçš„åœºæ™¯å’Œç¯å¢ƒä¿¡æ¯ã€‚2) æå‡ºäº†RGBT-VGNetæ¨¡å‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆèåˆRGBå’Œçƒ­çº¢å¤–ä¿¡æ¯ï¼Œæé«˜æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„é²æ£’æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒRGBT-VGNetèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯çš„äº’è¡¥æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šRGBT-VGNetçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰æ¨¡å‹ï¼ˆå¦‚ResNetï¼‰æå–RGBå’Œçƒ­çº¢å¤–å›¾åƒçš„è§†è§‰ç‰¹å¾ã€‚2) ä½¿ç”¨Transformeræ¨¡å‹æå–è‡ªç„¶è¯­è¨€æè¿°çš„æ–‡æœ¬ç‰¹å¾ã€‚3) ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶å°†è§†è§‰ç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾è¿›è¡Œèåˆï¼Œä»è€Œæ›´å¥½åœ°å…³æ³¨ä¸ç›®æ ‡å¯¹è±¡ç›¸å…³çš„åŒºåŸŸã€‚4) ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°å’ŒIoUæŸå¤±å‡½æ•°æ¥è®­ç»ƒæ¨¡å‹ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.24561v1/x2.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.24561v1/x3.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.24561v1/x4.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRGBT-VGNetåœ¨RGBT-Groundæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„è§†è§‰å®šä½æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨å¤œé—´å’Œè¿œè·ç¦»åœºæ™¯ä¸­ã€‚ä¾‹å¦‚ï¼Œåœ¨å¤œé—´åœºæ™¯ä¸­ï¼ŒRGBT-VGNetçš„æ€§èƒ½æå‡äº†10%ä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒRGBT-VGNetåœ¨é•¿è·ç¦»åœºæ™¯ä¸­ä¹Ÿå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†å…¶åœ¨å¤æ‚åœºæ™¯ä¸‹çš„é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æ§ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚åœ¨è¿™äº›åº”ç”¨ä¸­ï¼Œè§†è§‰å®šä½çš„é²æ£’æ€§è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨å…‰ç…§ä¸è¶³ã€æ¶åŠ£å¤©æ°”ç­‰å¤æ‚ç¯å¢ƒä¸‹ã€‚RGBT-Groundæ•°æ®é›†å’ŒRGBT-VGNetæ¨¡å‹ä¸ºè¿™äº›åº”ç”¨æä¾›äº†æœ‰åŠ›çš„æ”¯æŒï¼Œæœ‰åŠ©äºæé«˜ç³»ç»Ÿçš„å¯é æ€§å’Œå®‰å…¨æ€§ï¼Œæœªæ¥å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤šæ¨¡æ€çš„æ•°æ®èåˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual Grounding (VG) aims to localize specific objects in an image according to natural language expressions, serving as a fundamental task in vision-language understanding. However, existing VG benchmarks are mostly derived from datasets collected under clean environments, such as COCO, where scene diversity is limited. Consequently, they fail to reflect the complexity of real-world conditions, such as changes in illumination, weather, etc., that are critical to evaluating model robustness and generalization in safety-critical applications. To address these limitations, we present RGBT-Ground, the first large-scale visual grounding benchmark built for complex real-world scenarios. It consists of spatially aligned RGB and Thermal infrared (TIR) image pairs with high-quality referring expressions, corresponding object bounding boxes, and fine-grained annotations at the scene, environment, and object levels. This benchmark enables comprehensive evaluation and facilitates the study of robust grounding under diverse and challenging conditions. Furthermore, we establish a unified visual grounding framework that supports both uni-modal (RGB or TIR) and multi-modal (RGB-TIR) visual inputs. Based on it, we propose RGBT-VGNet, a simple yet effective baseline for fusing complementary visual modalities to achieve robust grounding. We conduct extensive adaptations to the existing methods on RGBT-Ground. Experimental results show that our proposed RGBT-VGNet significantly outperforms these adapted methods, particularly in nighttime and long-distance scenarios. All resources will be publicly released to promote future research on robust visual grounding in complex real-world environments.

