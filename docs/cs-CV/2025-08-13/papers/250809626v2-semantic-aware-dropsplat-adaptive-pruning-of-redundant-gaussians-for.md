---
layout: default
title: Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation
---

# Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09626" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09626v2</a>
  <a href="https://arxiv.org/pdf/2508.09626.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09626v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09626v2', 'Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xu Tang, Junan Jia, Yijing Wang, Jingjing Ma, Xiangrong Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13 (æ›´æ–°: 2025-08-14)

**å¤‡æ³¨**: 9 pages, 4 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSAD-Splatä»¥è§£å†³3Dèˆªç©ºå›¾åƒè¯­ä¹‰åˆ†å‰²ä¸­çš„æ¨¡ç³Šæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dè¯­ä¹‰åˆ†å‰²` `é«˜æ–¯ç‚¹ä¸¢å¼ƒ` `èˆªç©ºå›¾åƒå¤„ç†` `è¯­ä¹‰ç½®ä¿¡åº¦` `ç¨€ç–æœºåˆ¶` `ä¼ªæ ‡ç­¾ç”Ÿæˆ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†èˆªç©ºå›¾åƒæ—¶ï¼Œé¢ä¸´å°ºåº¦å˜åŒ–å’Œç»“æ„é®æŒ¡å¯¼è‡´çš„è¯­ä¹‰æ¨¡ç³Šæ€§é—®é¢˜ï¼Œå½±å“åˆ†å‰²æ•ˆæœã€‚
2. è®ºæ–‡æå‡ºçš„SAD-Splatæ–¹æ³•é€šè¿‡é«˜æ–¯ç‚¹ä¸¢å¼ƒæ¨¡å—ï¼Œç»“åˆè¯­ä¹‰ç½®ä¿¡åº¦å’Œå¯å­¦ä¹ ç¨€ç–æœºåˆ¶ï¼Œæœ‰æ•ˆå»é™¤å†—ä½™ç‚¹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSAD-Splatåœ¨åˆ†å‰²å‡†ç¡®æ€§å’Œè¡¨ç¤ºç´§å‡‘æ€§ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œæä¾›äº†é«˜æ•ˆçš„3Dåœºæ™¯ç†è§£æ–¹æ¡ˆã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨3Dèˆªç©ºåœºæ™¯è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­ï¼Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥åº”å¯¹èˆªç©ºå›¾åƒä¸­çš„å°ºåº¦å˜åŒ–å’Œç»“æ„é®æŒ¡æ‰€å¯¼è‡´çš„è¯­ä¹‰æ¨¡ç³Šæ€§ï¼Œä»è€Œé™åˆ¶äº†åˆ†å‰²çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„3D-AVS-SSæ–¹æ³•ï¼Œå‘½åä¸ºSAD-Splatã€‚è¯¥æ–¹æ³•å¼•å…¥äº†é«˜æ–¯ç‚¹ä¸¢å¼ƒæ¨¡å—ï¼Œç»“åˆè¯­ä¹‰ç½®ä¿¡åº¦ä¼°è®¡å’ŒåŸºäºHard Concreteåˆ†å¸ƒçš„å¯å­¦ä¹ ç¨€ç–æœºåˆ¶ï¼Œæœ‰æ•ˆæ¶ˆé™¤å†—ä½™å’Œè¯­ä¹‰æ¨¡ç³Šçš„é«˜æ–¯ç‚¹ï¼Œæå‡äº†åˆ†å‰²æ€§èƒ½å’Œè¡¨ç¤ºç´§å‡‘æ€§ã€‚æ­¤å¤–ï¼ŒSAD-Splatè¿˜åŒ…å«é«˜ç½®ä¿¡åº¦ä¼ªæ ‡ç­¾ç”Ÿæˆç®¡é“ï¼Œåˆ©ç”¨2DåŸºç¡€æ¨¡å‹å¢å¼ºç›‘ç£ï¼Œè¿›ä¸€æ­¥æé«˜åˆ†å‰²å‡†ç¡®æ€§ã€‚ä¸ºäº†æ¨åŠ¨è¯¥é¢†åŸŸçš„ç ”ç©¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æ•°æ®é›†ï¼š3D Aerial Semantic (3D-AS)ï¼Œæ¶µç›–å¤šæ ·çš„çœŸå®ä¸–ç•Œèˆªç©ºåœºæ™¯åŠç¨€ç–æ ‡æ³¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSAD-Splatåœ¨åˆ†å‰²å‡†ç¡®æ€§å’Œè¡¨ç¤ºç´§å‡‘æ€§ä¹‹é—´å®ç°äº†è‰¯å¥½çš„å¹³è¡¡ï¼Œä¸º3Dèˆªç©ºåœºæ™¯ç†è§£æä¾›äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³3Dèˆªç©ºå›¾åƒè¯­ä¹‰åˆ†å‰²ä¸­çš„è¯­ä¹‰æ¨¡ç³Šæ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å°ºåº¦å˜åŒ–å’Œç»“æ„é®æŒ¡æ—¶è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´åˆ†å‰²å‡†ç¡®æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSAD-Splatæ–¹æ³•çš„æ ¸å¿ƒåœ¨äºå¼•å…¥é«˜æ–¯ç‚¹ä¸¢å¼ƒæ¨¡å—ï¼Œé€šè¿‡ç»“åˆè¯­ä¹‰ç½®ä¿¡åº¦ä¼°è®¡ä¸å¯å­¦ä¹ çš„ç¨€ç–æœºåˆ¶ï¼Œä¸»åŠ¨æ¶ˆé™¤å†—ä½™å’Œæ¨¡ç³Šçš„é«˜æ–¯ç‚¹ï¼Œä»è€Œæé«˜åˆ†å‰²æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬é«˜æ–¯ç‚¹ä¸¢å¼ƒæ¨¡å—å’Œé«˜ç½®ä¿¡åº¦ä¼ªæ ‡ç­¾ç”Ÿæˆç®¡é“ã€‚é«˜æ–¯ç‚¹ä¸¢å¼ƒæ¨¡å—è´Ÿè´£å¤„ç†å†—ä½™ç‚¹ï¼Œè€Œä¼ªæ ‡ç­¾ç”Ÿæˆç®¡é“åˆ™åˆ©ç”¨2DåŸºç¡€æ¨¡å‹å¢å¼ºç›‘ç£ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé«˜æ–¯ç‚¹ä¸¢å¼ƒæ¨¡å—çš„è®¾è®¡ï¼Œå®ƒé€šè¿‡Hard Concreteåˆ†å¸ƒå®ç°äº†å¯¹å†—ä½™ç‚¹çš„æœ‰æ•ˆå»é™¤ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†åˆ†å‰²çš„å‡†ç¡®æ€§å’Œè¡¨ç¤ºçš„ç´§å‡‘æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–è¯­ä¹‰ç½®ä¿¡åº¦ä¼°è®¡ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§çš„ç¨€ç–æœºåˆ¶ï¼Œä»¥ç¡®ä¿é«˜æ–¯ç‚¹çš„æœ‰æ•ˆæ€§å’Œå¿…è¦æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSAD-Splatåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œåˆ†å‰²å‡†ç¡®æ€§æå‡äº†XX%ï¼Œè¡¨ç¤ºç´§å‡‘æ€§ä¹Ÿå¾—åˆ°äº†æ˜¾è‘—æ”¹å–„ï¼Œå±•ç¤ºäº†å…¶åœ¨3Dèˆªç©ºåœºæ™¯ç†è§£ä¸­çš„æœ‰æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æ— äººæœºç›‘æµ‹ã€åŸå¸‚è§„åˆ’ã€ç¯å¢ƒç›‘æµ‹ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡3Dèˆªç©ºå›¾åƒçš„è¯­ä¹‰åˆ†å‰²èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°æ”¯æŒæ™ºèƒ½äº¤é€šã€ç¾å®³å“åº”ç­‰å®é™…åœºæ™¯çš„å†³ç­–ä¸åˆ†æï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In the task of 3D Aerial-view Scene Semantic Segmentation (3D-AVS-SS), traditional methods struggle to address semantic ambiguity caused by scale variations and structural occlusions in aerial images. This limits their segmentation accuracy and consistency. To tackle these challenges, we propose a novel 3D-AVS-SS approach named SAD-Splat. Our method introduces a Gaussian point drop module, which integrates semantic confidence estimation with a learnable sparsity mechanism based on the Hard Concrete distribution. This module effectively eliminates redundant and semantically ambiguous Gaussian points, enhancing both segmentation performance and representation compactness. Furthermore, SAD-Splat incorporates a high-confidence pseudo-label generation pipeline. It leverages 2D foundation models to enhance supervision when ground-truth labels are limited, thereby further improving segmentation accuracy. To advance research in this domain, we introduce a challenging benchmark dataset: 3D Aerial Semantic (3D-AS), which encompasses diverse real-world aerial scenes with sparse annotations. Experimental results demonstrate that SAD-Splat achieves an excellent balance between segmentation accuracy and representation compactness. It offers an efficient and scalable solution for 3D aerial scene understanding.

