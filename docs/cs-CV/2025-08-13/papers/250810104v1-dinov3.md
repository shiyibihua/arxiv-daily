---
layout: default
title: DINOv3
---

# DINOv3

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.10104" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.10104v1</a>
  <a href="https://arxiv.org/pdf/2508.10104.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.10104v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.10104v1', 'DINOv3')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Oriane SimÃ©oni, Huy V. Vo, Maximilian Seitzer, Federico Baldassarre, Maxime Oquab, Cijo Jose, Vasil Khalidov, Marc Szafraniec, Seungeun Yi, MichaÃ«l Ramamonjisoa, Francisco Massa, Daniel Haziza, Luca Wehrstedt, Jianyuan Wang, TimothÃ©e Darcet, ThÃ©o Moutakanni, Leonel Sentana, Claire Roberts, Andrea Vedaldi, Jamie Tolan, John Brandt, Camille Couprie, Julien Mairal, HervÃ© JÃ©gou, Patrick Labatut, Piotr Bojanowski

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDINOv3ä»¥è§£å†³è‡ªç›‘ç£å­¦ä¹ ä¸­çš„ç‰¹å¾å›¾é€€åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªç›‘ç£å­¦ä¹ ` `ç‰¹å¾å›¾é€€åŒ–` `Gramé”šå®š` `è§†è§‰ä»»åŠ¡` `æ¨¡å‹ä¼˜åŒ–` `æ•°æ®å‡†å¤‡` `åå¤„ç†ç­–ç•¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨é•¿æ—¶é—´è®­ç»ƒä¸­é¢ä¸´ç‰¹å¾å›¾é€€åŒ–çš„é—®é¢˜ï¼Œå½±å“æ¨¡å‹æ€§èƒ½ã€‚
2. DINOv3é€šè¿‡Gramé”šå®šæ–¹æ³•è§£å†³ç‰¹å¾å›¾é€€åŒ–ï¼ŒåŒæ—¶ä¼˜åŒ–æ•°æ®é›†å’Œæ¨¡å‹è§„æ¨¡ï¼Œæå‡è®­ç»ƒæ•ˆæœã€‚
3. DINOv3åœ¨å¤šä¸ªè§†è§‰ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰è‡ªç›‘ç£å’Œå¼±ç›‘ç£æ¨¡å‹ï¼Œå±•ç¤ºäº†å…¶å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªç›‘ç£å­¦ä¹ æœ‰æœ›æ¶ˆé™¤æ‰‹åŠ¨æ•°æ®æ ‡æ³¨çš„éœ€æ±‚ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿè½»æ¾æ‰©å±•åˆ°å¤§è§„æ¨¡æ•°æ®é›†å’Œæ›´å¤§æ¶æ„ã€‚DINOv3é€šè¿‡ç®€å•è€Œæœ‰æ•ˆçš„ç­–ç•¥ï¼Œæ ‡å¿—ç€å®ç°è¿™ä¸€æ„¿æ™¯çš„é‡è¦é‡Œç¨‹ç¢‘ã€‚é¦–å…ˆï¼Œé€šè¿‡ç²¾å¿ƒçš„æ•°æ®å‡†å¤‡ã€è®¾è®¡å’Œä¼˜åŒ–ï¼Œå……åˆ†åˆ©ç”¨æ•°æ®é›†å’Œæ¨¡å‹è§„æ¨¡çš„ä¼˜åŠ¿ã€‚å…¶æ¬¡ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•â€”â€”Gramé”šå®šï¼Œæœ‰æ•ˆè§£å†³äº†åœ¨é•¿æ—¶é—´è®­ç»ƒè¿‡ç¨‹ä¸­å¯†é›†ç‰¹å¾å›¾é€€åŒ–çš„é—®é¢˜ã€‚æœ€åï¼Œåº”ç”¨åå¤„ç†ç­–ç•¥è¿›ä¸€æ­¥å¢å¼ºæ¨¡å‹åœ¨åˆ†è¾¨ç‡ã€æ¨¡å‹å¤§å°å’Œæ–‡æœ¬å¯¹é½æ–¹é¢çš„çµæ´»æ€§ã€‚DINOv3å±•ç¤ºäº†åœ¨æ— éœ€å¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿåœ¨å¹¿æ³›è®¾ç½®ä¸­è¶…è¶Šä¸“ä¸šåŒ–çš„æœ€å…ˆè¿›æŠ€æœ¯ï¼Œç”Ÿæˆé«˜è´¨é‡çš„å¯†é›†ç‰¹å¾ï¼Œåœ¨å„ç§è§†è§‰ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—è¶…è¶Šäº†ä¹‹å‰çš„è‡ªç›‘ç£å’Œå¼±ç›‘ç£åŸºç¡€æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šDINOv3æ—¨åœ¨è§£å†³è‡ªç›‘ç£å­¦ä¹ ä¸­å¯†é›†ç‰¹å¾å›¾åœ¨é•¿æ—¶é—´è®­ç»ƒè¿‡ç¨‹ä¸­é€€åŒ–çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†æ—¶ï¼Œå¾€å¾€æ— æ³•ä¿æŒç‰¹å¾å›¾çš„è´¨é‡ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDINOv3çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡Gramé”šå®šæ–¹æ³•æ¥ç¨³å®šç‰¹å¾å›¾ï¼ŒåŒæ—¶ç»“åˆæ•°æ®é›†å’Œæ¨¡å‹è§„æ¨¡çš„ä¼˜åŒ–ï¼Œæå‡æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å¤šç§ä»»åŠ¡ä¸­ä¿æŒé«˜æ•ˆçš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDINOv3çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€æ¨¡å‹è®¾è®¡ã€Gramé”šå®šæ–¹æ³•çš„åº”ç”¨ä»¥åŠåå¤„ç†ç­–ç•¥ã€‚æ•°æ®å‡†å¤‡é˜¶æ®µç¡®ä¿æ•°æ®çš„å¤šæ ·æ€§å’Œè´¨é‡ï¼Œæ¨¡å‹è®¾è®¡åˆ™å…³æ³¨äºæ¶æ„çš„çµæ´»æ€§å’Œæ‰©å±•æ€§ã€‚Gramé”šå®šæ–¹æ³•ç”¨äºè§£å†³ç‰¹å¾å›¾é€€åŒ–ï¼Œåå¤„ç†ç­–ç•¥è¿›ä¸€æ­¥å¢å¼ºæ¨¡å‹çš„é€‚åº”æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šDINOv3çš„å…³é”®åˆ›æ–°åœ¨äºGramé”šå®šæ–¹æ³•çš„æå‡ºï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆè§£å†³äº†ç‰¹å¾å›¾åœ¨é•¿æ—¶é—´è®­ç»ƒä¸­çš„é€€åŒ–é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚è¿™ä¸€åˆ›æ–°ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´ä¸ºæœ‰æ•ˆçš„ç‰¹å¾ä¿æŒæœºåˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨DINOv3ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç‰¹å¾å›¾çš„è´¨é‡ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ç²¾å¿ƒè®¾è®¡ï¼Œä»¥æ”¯æŒå¤§è§„æ¨¡æ•°æ®é›†çš„è®­ç»ƒã€‚æ­¤å¤–ï¼Œåå¤„ç†ç­–ç•¥çš„å¼•å…¥ä½¿å¾—æ¨¡å‹åœ¨ä¸åŒåˆ†è¾¨ç‡å’Œæ–‡æœ¬å¯¹é½æ–¹é¢å…·å¤‡æ›´é«˜çš„çµæ´»æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DINOv3åœ¨å¤šä¸ªè§†è§‰ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç”Ÿæˆçš„é«˜è´¨é‡å¯†é›†ç‰¹å¾åœ¨å„é¡¹æŒ‡æ ‡ä¸Šæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„è‡ªç›‘ç£å’Œå¼±ç›‘ç£æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›ä»»åŠ¡ä¸­ï¼ŒDINOv3çš„æ€§èƒ½æå‡å¹…åº¦è¶…è¿‡äº†10%ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¼ºå¤§èƒ½åŠ›å’Œçµæ´»æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DINOv3çš„ç ”ç©¶æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸï¼Œå¦‚å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œå›¾åƒç”Ÿæˆç­‰ä»»åŠ¡ä¸­ã€‚å…¶è‡ªç›‘ç£å­¦ä¹ çš„ç‰¹æ€§ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨ç¼ºä¹æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œä¾ç„¶ä¿æŒé«˜æ•ˆçš„å­¦ä¹ èƒ½åŠ›ï¼Œé€‚ç”¨äºèµ„æºå—é™çš„åœºæ™¯ã€‚æœªæ¥ï¼ŒDINOv3å¯èƒ½æ¨åŠ¨æ›´å¤šé¢†åŸŸçš„è‡ªåŠ¨åŒ–å’Œæ™ºèƒ½åŒ–å‘å±•ï¼Œé™ä½å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Self-supervised learning holds the promise of eliminating the need for manual data annotation, enabling models to scale effortlessly to massive datasets and larger architectures. By not being tailored to specific tasks or domains, this training paradigm has the potential to learn visual representations from diverse sources, ranging from natural to aerial images -- using a single algorithm. This technical report introduces DINOv3, a major milestone toward realizing this vision by leveraging simple yet effective strategies. First, we leverage the benefit of scaling both dataset and model size by careful data preparation, design, and optimization. Second, we introduce a new method called Gram anchoring, which effectively addresses the known yet unsolved issue of dense feature maps degrading during long training schedules. Finally, we apply post-hoc strategies that further enhance our models' flexibility with respect to resolution, model size, and alignment with text. As a result, we present a versatile vision foundation model that outperforms the specialized state of the art across a broad range of settings, without fine-tuning. DINOv3 produces high-quality dense features that achieve outstanding performance on various vision tasks, significantly surpassing previous self- and weakly-supervised foundation models. We also share the DINOv3 suite of vision models, designed to advance the state of the art on a wide spectrum of tasks and data by providing scalable solutions for diverse resource constraints and deployment scenarios.

