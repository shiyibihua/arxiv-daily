---
layout: default
title: Physical Autoregressive Model for Robotic Manipulation without Action Pretraining
---

# Physical Autoregressive Model for Robotic Manipulation without Action Pretraining

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09822" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09822v4</a>
  <a href="https://arxiv.org/pdf/2508.09822.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09822v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09822v4', 'Physical Autoregressive Model for Robotic Manipulation without Action Pretraining')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zijian Song, Sihan Qin, Tianshui Chen, Liang Lin, Guangrun Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13 (æ›´æ–°: 2025-09-08)

**å¤‡æ³¨**: 16 pages, 6 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://hcplab-sysu.github.io/PhysicalAutoregressiveModel/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç‰©ç†è‡ªå›å½’æ¨¡å‹ä»¥è§£å†³æœºå™¨äººæ“ä½œæ•°æ®ç¨€ç¼ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `ç‰©ç†è‡ªå›å½’æ¨¡å‹` `æœºå™¨äººæ“ä½œ` `è§†é¢‘é¢„æµ‹` `åŠ¨ä½œè½¨è¿¹` `æ•°æ®ç¨€ç¼º` `è‡ªå›å½’ç”Ÿæˆ` `ä¸–ç•ŒçŸ¥è¯†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æœºå™¨äººæ“ä½œä¸­é¢ä¸´æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨ç¼ºä¹åŠ¨ä½œé¢„è®­ç»ƒçš„æƒ…å†µä¸‹ã€‚
2. æœ¬æ–‡æå‡ºçš„ç‰©ç†è‡ªå›å½’æ¨¡å‹ï¼ˆPARï¼‰é€šè¿‡ç»“åˆå¸§å’ŒåŠ¨ä½œçš„ç‰©ç†æ ‡è®°ï¼Œåˆ©ç”¨è§†é¢‘é¢„è®­ç»ƒçš„ä¸–ç•ŒçŸ¥è¯†æ¥ç†è§£ç‰©ç†åŠ¨æ€ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPARåœ¨PushCubeä»»åŠ¡ä¸Šå–å¾—100%æˆåŠŸç‡ï¼Œå¹¶åœ¨å…¶ä»–ä»»åŠ¡ä¸Šä¸åŠ¨ä½œé¢„è®­ç»ƒåŸºçº¿ç›¸å½“ï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šçš„é¢„æµ‹èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”±äºæ“ä½œæ•°æ®çš„ç¨€ç¼ºï¼Œç ”ç©¶è€…ä»¬å¼€å§‹åˆ©ç”¨å…¶ä»–æ¨¡æ€çš„é¢„è®­ç»ƒå¤§æ¨¡å‹æ¥è¾…åŠ©æœºå™¨äººæŠ€æœ¯ã€‚æœ¬æ–‡åŸºäºè‡ªå›å½’è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œæå‡ºäº†ä¸€ç§ç‰©ç†è‡ªå›å½’æ¨¡å‹ï¼ˆPARï¼‰ï¼Œé€šè¿‡ç‰©ç†æ ‡è®°å°†å¸§å’ŒåŠ¨ä½œç»“åˆï¼Œè¡¨ç¤ºæœºå™¨äººä¸ç¯å¢ƒçš„è”åˆæ¼”å˜ã€‚PARåˆ©ç”¨è§†é¢‘é¢„è®­ç»ƒä¸­åµŒå…¥çš„ä¸–ç•ŒçŸ¥è¯†æ¥ç†è§£ç‰©ç†åŠ¨æ€ï¼Œæ— éœ€åŠ¨ä½œé¢„è®­ç»ƒï¼Œä»è€Œå®ç°å‡†ç¡®çš„è§†é¢‘é¢„æµ‹å’Œä¸€è‡´çš„åŠ¨ä½œè½¨è¿¹ã€‚æ­¤å¤–ï¼ŒPARé‡‡ç”¨åŸºäºDiTçš„å»æ ‡è®°å™¨ï¼Œå°†å¸§å’ŒåŠ¨ä½œå»ºæ¨¡ä¸ºè¿ç»­æ ‡è®°ï¼Œå‡è½»é‡åŒ–è¯¯å·®å¹¶ä¿ƒè¿›ç›¸äº’å¢å¼ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPARåœ¨ManiSkillåŸºå‡†æµ‹è¯•ä¸­ï¼Œåœ¨PushCubeä»»åŠ¡ä¸Šå®ç°äº†100%çš„æˆåŠŸç‡ï¼Œå¹¶åœ¨å…¶ä»–ä»»åŠ¡ä¸Šä¸åŠ¨ä½œé¢„è®­ç»ƒåŸºçº¿çš„æ€§èƒ½ç›¸åŒ¹é…ï¼Œå‡†ç¡®é¢„æµ‹æœªæ¥è§†é¢‘å¹¶ç´§å¯†å¯¹é½åŠ¨ä½œè½¨è¿¹ã€‚è¿™äº›å‘ç°ä¸ºé€šè¿‡è‡ªå›å½’è§†é¢‘é¢„è®­ç»ƒè½¬ç§»ä¸–ç•ŒçŸ¥è¯†åˆ°æœºå™¨äººæ“ä½œæä¾›äº†æœ‰å¸Œæœ›çš„æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæ“ä½œä¸­æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨ç¼ºä¹åŠ¨ä½œé¢„è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥å‡†ç¡®é¢„æµ‹ç‰©ç†åŠ¨æ€å’Œç”Ÿæˆä¸€è‡´çš„åŠ¨ä½œè½¨è¿¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºç‰©ç†è‡ªå›å½’æ¨¡å‹ï¼ˆPARï¼‰ï¼Œé€šè¿‡ç‰©ç†æ ‡è®°å°†å¸§å’ŒåŠ¨ä½œç»“åˆï¼Œåˆ©ç”¨è§†é¢‘é¢„è®­ç»ƒä¸­åµŒå…¥çš„ä¸–ç•ŒçŸ¥è¯†æ¥ç†è§£ç‰©ç†åŠ¨æ€ï¼Œä»è€Œå®ç°å‡†ç¡®çš„è§†é¢‘é¢„æµ‹å’Œä¸€è‡´çš„åŠ¨ä½œè½¨è¿¹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPARçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç‰©ç†æ ‡è®°çš„ç”Ÿæˆã€åŸºäºDiTçš„å»æ ‡è®°å™¨ã€å› æœæ©ç ã€é€†å‘è¿åŠ¨å­¦å’ŒKV-cacheæœºåˆ¶ç­‰æ¨¡å—ï¼Œå½¢æˆä¸€ä¸ªé«˜æ•ˆçš„è®­ç»ƒå’Œé¢„æµ‹æµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šPARçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºæ— éœ€åŠ¨ä½œé¢„è®­ç»ƒå³å¯ç†è§£ç‰©ç†åŠ¨æ€ï¼ŒåŒæ—¶é€šè¿‡å°†å¸§å’ŒåŠ¨ä½œå»ºæ¨¡ä¸ºè¿ç»­æ ‡è®°ï¼Œå‡è½»äº†é‡åŒ–è¯¯å·®ï¼Œæå‡äº†æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒPARé‡‡ç”¨äº†å› æœæ©ç ä»¥ç¡®ä¿æ—¶é—´åºåˆ—çš„å› æœæ€§ï¼Œç»“åˆé€†å‘è¿åŠ¨å­¦ä¼˜åŒ–åŠ¨ä½œç”Ÿæˆï¼Œå¹¶é€šè¿‡å¹¶è¡Œè®­ç»ƒå’ŒKV-cacheæœºåˆ¶æå‡äº†æ€§èƒ½å’Œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PARåœ¨ManiSkillåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œåœ¨PushCubeä»»åŠ¡ä¸Šå®ç°äº†100%çš„æˆåŠŸç‡ï¼Œå¹¶åœ¨å…¶ä»–ä»»åŠ¡ä¸­ä¸åŠ¨ä½œé¢„è®­ç»ƒåŸºçº¿çš„æ€§èƒ½ç›¸åŒ¹é…ï¼Œå±•ç¤ºäº†å…¶åœ¨è§†é¢‘é¢„æµ‹å’ŒåŠ¨ä½œè½¨è¿¹ä¸€è‡´æ€§æ–¹é¢çš„æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æœºå™¨äººã€è‡ªåŠ¨åŒ–ç”Ÿäº§çº¿å’Œäººæœºäº¤äº’ç­‰åœºæ™¯ã€‚é€šè¿‡æœ‰æ•ˆåœ°è½¬ç§»ä¸–ç•ŒçŸ¥è¯†ï¼ŒPARèƒ½å¤Ÿæå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œèƒ½åŠ›ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The scarcity of manipulation data has motivated the use of pretrained large models from other modalities in robotics. In this work, we build upon autoregressive video generation models to propose a Physical Autoregressive Model (PAR), where physical tokens combine frames and actions to represent the joint evolution of the robot and its environment. PAR leverages the world knowledge embedded in video pretraining to understand physical dynamics without requiring action pretraining, enabling accurate video prediction and consistent action trajectories. It also adopts a DiT-based de-tokenizer to model frames and actions as continuous tokens, mitigating quantization errors and facilitating mutual enhancement. Furthermore, we incorporate a causal mask with inverse kinematics, parallel training, and the KV-cache mechanism to further improve performance and efficiency. Experiments on the ManiSkill benchmark show that PAR achieves a 100\% success rate on the PushCube task, matches the performance of action-pretrained baselines on other tasks, and accurately predicts future videos with tightly aligned action trajectories. These findings underscore a promising direction for robotic manipulation by transferring world knowledge from autoregressive video pretraining. The project page is here: https://hcplab-sysu.github.io/PhysicalAutoregressiveModel/

