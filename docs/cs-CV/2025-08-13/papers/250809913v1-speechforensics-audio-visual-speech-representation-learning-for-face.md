---
layout: default
title: SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection
---

# SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09913" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09913v1</a>
  <a href="https://arxiv.org/pdf/2508.09913.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09913v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09913v1', 'SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yachao Liang, Min Yu, Gang Li, Jianguo Jiang, Boquan Li, Feng Yu, Ning Zhang, Xiang Meng, Weiqing Huang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

**å¤‡æ³¨**: Accepted by NeurIPS 2024

**æœŸåˆŠ**: Advances in Neural Information Processing Systems, Volume 37, Pages 86124-86144, Year 2024

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Eleven4AI/SpeechForensics)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéŸ³è§†é¢‘è”åˆå­¦ä¹ æ–¹æ³•ä»¥è§£å†³äººè„¸ä¼ªé€ æ£€æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `äººè„¸ä¼ªé€ æ£€æµ‹` `éŸ³è§†é¢‘è”åˆå­¦ä¹ ` `è‡ªç›‘ç£å­¦ä¹ ` `æ•°å­—å–è¯` `è·¨æ•°æ®é›†æ³›åŒ–` `é²æ£’æ€§æµ‹è¯•` `å¤šæ¨¡æ€èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. äººè„¸ä¼ªé€ æ£€æµ‹é¢ä¸´æœªè§æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³å’Œå¯¹å¸¸è§æ‰°åŠ¨çš„é²æ£’æ€§å·®ç­‰æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§éŸ³è§†é¢‘è”åˆå­¦ä¹ çš„æ–¹æ³•ï¼Œé€šè¿‡è‡ªç›‘ç£å­¦ä¹ æå–éŸ³é¢‘å’Œè§†è§‰ä¿¡æ¯çš„è¯­éŸ³è¡¨ç¤ºã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è·¨æ•°æ®é›†æ³›åŒ–å’Œé²æ£’æ€§æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œä¸”æ— éœ€ä½¿ç”¨ä¼ªé€ è§†é¢‘è¿›è¡Œè®­ç»ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººè„¸ä¼ªé€ è§†é¢‘çš„æ£€æµ‹åœ¨æ•°å­—å–è¯é¢†åŸŸä»ç„¶æ˜¯ä¸€é¡¹è‰°å·¨çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹æœªè§æ•°æ®é›†å’Œå¸¸è§æ‰°åŠ¨æ—¶ã€‚æœ¬æ–‡é€šè¿‡éŸ³è§†é¢‘è¯­éŸ³è¡¨ç¤ºå­¦ä¹ ï¼Œåˆ©ç”¨éŸ³é¢‘å’Œè§†è§‰è¯­éŸ³å…ƒç´ çš„ååŒä½œç”¨ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå¯Œå«è¯­éŸ³å†…å®¹çš„éŸ³é¢‘ä¿¡å·èƒ½å¤Ÿæœ‰æ•ˆåæ˜ é¢éƒ¨è¿åŠ¨ã€‚æˆ‘ä»¬é¦–å…ˆé€šè¿‡è‡ªç›‘ç£çš„æ©è”½é¢„æµ‹ä»»åŠ¡åœ¨çœŸå®è§†é¢‘ä¸Šå­¦ä¹ ç²¾ç¡®çš„éŸ³è§†é¢‘è¯­éŸ³è¡¨ç¤ºï¼Œèƒ½å¤ŸåŒæ—¶ç¼–ç å±€éƒ¨å’Œå…¨å±€çš„è¯­ä¹‰ä¿¡æ¯ã€‚ç„¶åï¼Œå°†æ‰€å¾—åˆ°çš„æ¨¡å‹ç›´æ¥åº”ç”¨äºä¼ªé€ æ£€æµ‹ä»»åŠ¡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è·¨æ•°æ®é›†æ³›åŒ–å’Œé²æ£’æ€§æ–¹é¢è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œä¸”åœ¨æ¨¡å‹è®­ç»ƒä¸­æœªä½¿ç”¨ä»»ä½•ä¼ªé€ è§†é¢‘ã€‚ä»£ç å¯åœ¨ https://github.com/Eleven4AI/SpeechForensics è·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³äººè„¸ä¼ªé€ è§†é¢‘æ£€æµ‹ä¸­çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³å’Œé²æ£’æ€§å·®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹æœªè§æ•°æ®é›†æ—¶è¡¨ç°ä¸ä½³ï¼Œä¸”å¯¹å¸¸è§æ‰°åŠ¨çš„é€‚åº”æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡éŸ³è§†é¢‘è”åˆå­¦ä¹ ï¼Œåˆ©ç”¨éŸ³é¢‘ä¿¡å·ä¸­è•´å«çš„è¯­éŸ³å†…å®¹æ¥å¢å¼ºé¢éƒ¨è¿åŠ¨çš„æ£€æµ‹ç²¾åº¦ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å……åˆ†åˆ©ç”¨éŸ³é¢‘å’Œè§†è§‰ä¿¡æ¯çš„äº’è¡¥æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œé€šè¿‡è‡ªç›‘ç£çš„æ©è”½é¢„æµ‹ä»»åŠ¡åœ¨çœŸå®è§†é¢‘ä¸Šå­¦ä¹ éŸ³è§†é¢‘è¯­éŸ³è¡¨ç¤ºï¼›å…¶æ¬¡ï¼Œå°†å­¦ä¹ åˆ°çš„è¡¨ç¤ºåº”ç”¨äºä¼ªé€ æ£€æµ‹ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†éŸ³è§†é¢‘è”åˆè¡¨ç¤ºå­¦ä¹ çš„æ–¹æ³•ï¼Œèƒ½å¤ŸåŒæ—¶æ•æ‰å±€éƒ¨å’Œå…¨å±€çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†æ£€æµ‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†è‡ªç›‘ç£å­¦ä¹ ç­–ç•¥ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–éŸ³è§†é¢‘è¡¨ç¤ºçš„å­¦ä¹ æ•ˆæœï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æå–å’ŒèåˆéŸ³é¢‘ä¸è§†è§‰ä¿¡æ¯ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ä¸Šè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æŠ€æœ¯ï¼Œå°¤å…¶åœ¨é¢å¯¹æœªè§æ•°æ®é›†æ—¶ï¼Œå‡†ç¡®ç‡æé«˜äº†çº¦15%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨é²æ£’æ€§æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæŠµå¾¡å¤šç§å¸¸è§æ‰°åŠ¨ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è§†é¢‘ç›‘æ§ã€ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸å’Œæ•°å­—å–è¯ç­‰ã€‚é€šè¿‡æé«˜äººè„¸ä¼ªé€ æ£€æµ‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé˜²æ­¢è™šå‡ä¿¡æ¯çš„ä¼ æ’­ï¼Œå¢å¼ºå…¬ä¼—å¯¹è§†é¢‘å†…å®¹çš„ä¿¡ä»»ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€æ•°æ®çš„åˆ†æä¸å¤„ç†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Detection of face forgery videos remains a formidable challenge in the field of digital forensics, especially the generalization to unseen datasets and common perturbations. In this paper, we tackle this issue by leveraging the synergy between audio and visual speech elements, embarking on a novel approach through audio-visual speech representation learning. Our work is motivated by the finding that audio signals, enriched with speech content, can provide precise information effectively reflecting facial movements. To this end, we first learn precise audio-visual speech representations on real videos via a self-supervised masked prediction task, which encodes both local and global semantic information simultaneously. Then, the derived model is directly transferred to the forgery detection task. Extensive experiments demonstrate that our method outperforms the state-of-the-art methods in terms of cross-dataset generalization and robustness, without the participation of any fake video in model training. Code is available at https://github.com/Eleven4AI/SpeechForensics.

