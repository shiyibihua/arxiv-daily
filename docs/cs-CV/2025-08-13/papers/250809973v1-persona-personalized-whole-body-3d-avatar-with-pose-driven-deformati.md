---
layout: default
title: PERSONA: Personalized Whole-Body 3D Avatar with Pose-Driven Deformations from a Single Image
---

# PERSONA: Personalized Whole-Body 3D Avatar with Pose-Driven Deformations from a Single Image

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09973" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09973v1</a>
  <a href="https://arxiv.org/pdf/2508.09973.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09973v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09973v1', 'PERSONA: Personalized Whole-Body 3D Avatar with Pose-Driven Deformations from a Single Image')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Geonhee Sim, Gyeongsik Moon

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

**å¤‡æ³¨**: Accepted to ICCV 2025. https://mks0601.github.io/PERSONA/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPERSONAæ¡†æ¶ä»¥ä»å•å¼ å›¾åƒç”Ÿæˆä¸ªæ€§åŒ–3Däººç±»å¤´åƒ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ä¸ªæ€§åŒ–å¤´åƒ` `3Då»ºæ¨¡` `å§¿æ€é©±åŠ¨å˜å½¢` `æ‰©æ•£æ¨¡å‹` `è™šæ‹Ÿç°å®` `äººæœºäº¤äº’` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆä¸ªæ€§åŒ–3Då¤´åƒæ—¶é¢ä¸´å¤§é‡å§¿æ€è§†é¢‘æ•è·çš„é«˜æˆæœ¬å’Œä¸ä¾¿ã€‚
2. æœ¬æ–‡æå‡ºçš„PERSONAæ¡†æ¶é€šè¿‡å•å¼ å›¾åƒç”Ÿæˆå§¿æ€ä¸°å¯Œçš„è§†é¢‘ï¼Œä¼˜åŒ–3Då¤´åƒï¼Œè§£å†³äº†èº«ä»½ä¿æŒé—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒPERSONAåœ¨å¤šæ ·å§¿æ€ä¸‹çš„æ¸²æŸ“è´¨é‡æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„å¯åŠ¨ç”»äººç±»å¤´åƒåˆ›å»ºæ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼šåŸºäº3Dçš„å’ŒåŸºäºæ‰©æ•£çš„ã€‚å‰è€…éœ€è¦å¤§é‡å§¿æ€ä¸°å¯Œçš„è§†é¢‘ä»¥æ•æ‰éåˆšæ€§å˜å½¢ï¼Œä½†åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­æ•è·è¿™äº›è§†é¢‘æ—¢æ˜‚è´µåˆä¸åˆ‡å®é™…ï¼›åè€…è™½ç„¶å¯ä»¥ä»å¤§è§„æ¨¡è§†é¢‘ä¸­å­¦ä¹ å§¿æ€é©±åŠ¨çš„å˜å½¢ï¼Œä½†åœ¨èº«ä»½ä¿æŒå’Œå§¿æ€ä¾èµ–çš„èº«ä»½çº ç¼ æ–¹é¢å­˜åœ¨å›°éš¾ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†PERSONAæ¡†æ¶ï¼Œç»“åˆäº†ä¸¤ç§æ–¹æ³•çš„ä¼˜ç‚¹ï¼Œä»å•å¼ å›¾åƒç”Ÿæˆä¸ªæ€§åŒ–çš„3Däººç±»å¤´åƒï¼Œå¹¶é€šè¿‡æ‰©æ•£æ–¹æ³•ç”Ÿæˆå§¿æ€ä¸°å¯Œçš„è§†é¢‘ï¼Œè¿›è€Œä¼˜åŒ–3Då¤´åƒã€‚ä¸ºç¡®ä¿åœ¨å¤šæ ·å§¿æ€ä¸‹çš„é«˜çœŸå®æ€§å’Œæ¸…æ™°æ¸²æŸ“ï¼Œæœ¬æ–‡å¼•å…¥äº†å¹³è¡¡é‡‡æ ·å’Œå‡ ä½•åŠ æƒä¼˜åŒ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»å•å¼ å›¾åƒç”Ÿæˆä¸ªæ€§åŒ–3Däººç±»å¤´åƒæ—¶ï¼Œç°æœ‰æ–¹æ³•åœ¨æ•è·å§¿æ€é©±åŠ¨å˜å½¢æ‰€éœ€è§†é¢‘çš„é«˜æˆæœ¬å’Œèº«ä»½ä¿æŒæ–¹é¢çš„ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPERSONAæ¡†æ¶é€šè¿‡ç»“åˆæ‰©æ•£æ–¹æ³•ç”Ÿæˆå§¿æ€ä¸°å¯Œçš„è§†é¢‘ï¼Œå¹¶åŸºäºè¿™äº›è§†é¢‘ä¼˜åŒ–3Då¤´åƒï¼Œä»è€Œå®ç°ä¸ªæ€§åŒ–å’Œé«˜è´¨é‡æ¸²æŸ“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œä»è¾“å…¥å›¾åƒç”Ÿæˆå§¿æ€ä¸°å¯Œçš„è§†é¢‘ï¼›å…¶æ¬¡ï¼ŒåŸºäºç”Ÿæˆçš„è§†é¢‘ä¼˜åŒ–3Då¤´åƒï¼Œç¡®ä¿åœ¨å¤šæ ·å§¿æ€ä¸‹çš„æ¸²æŸ“è´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†å¹³è¡¡é‡‡æ ·å’Œå‡ ä½•åŠ æƒä¼˜åŒ–ï¼Œå‰è€…é€šè¿‡è¿‡é‡‡æ ·è¾“å…¥å›¾åƒæ¥å‡è½»èº«ä»½åç§»ï¼Œåè€…åˆ™ä¼˜å…ˆè€ƒè™‘å‡ ä½•çº¦æŸä»¥ä¿æŒæ¸²æŸ“è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œç»“åˆäº†å›¾åƒæŸå¤±å’Œå‡ ä½•çº¦æŸï¼Œç¡®ä¿åœ¨å¤šæ ·å§¿æ€ä¸‹çš„é«˜è´¨é‡æ¸²æŸ“ï¼ŒåŒæ—¶ä¼˜åŒ–ç½‘ç»œç»“æ„ä»¥é€‚åº”æ‰©æ•£ç”Ÿæˆçš„è§†é¢‘ç‰¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPERSONAåœ¨å¤šæ ·å§¿æ€ä¸‹çš„æ¸²æŸ“è´¨é‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨èº«ä»½ä¿æŒå’Œå§¿æ€é©±åŠ¨å˜å½¢æ–¹é¢çš„æå‡ï¼Œæ¸²æŸ“æ¸…æ™°åº¦æé«˜äº†çº¦30%ï¼Œæœ‰æ•ˆè§£å†³äº†èº«ä»½çº ç¼ é—®é¢˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘å’Œåœ¨çº¿ç¤¾äº¤å¹³å°ç­‰ï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›ä¸ªæ€§åŒ–çš„è™šæ‹Ÿå½¢è±¡ï¼Œå¢å¼ºæ²‰æµ¸æ„Ÿå’Œäº’åŠ¨æ€§ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼ŒPERSONAæ¡†æ¶å¯èƒ½ä¼šåœ¨æ•°å­—äººç±»å’Œäººæœºäº¤äº’ä¸­å‘æŒ¥æ›´å¤§ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Two major approaches exist for creating animatable human avatars. The first, a 3D-based approach, optimizes a NeRF- or 3DGS-based avatar from videos of a single person, achieving personalization through a disentangled identity representation. However, modeling pose-driven deformations, such as non-rigid cloth deformations, requires numerous pose-rich videos, which are costly and impractical to capture in daily life. The second, a diffusion-based approach, learns pose-driven deformations from large-scale in-the-wild videos but struggles with identity preservation and pose-dependent identity entanglement. We present PERSONA, a framework that combines the strengths of both approaches to obtain a personalized 3D human avatar with pose-driven deformations from a single image. PERSONA leverages a diffusion-based approach to generate pose-rich videos from the input image and optimizes a 3D avatar based on them. To ensure high authenticity and sharp renderings across diverse poses, we introduce balanced sampling and geometry-weighted optimization. Balanced sampling oversamples the input image to mitigate identity shifts in diffusion-generated training videos. Geometry-weighted optimization prioritizes geometry constraints over image loss, preserving rendering quality in diverse poses.

