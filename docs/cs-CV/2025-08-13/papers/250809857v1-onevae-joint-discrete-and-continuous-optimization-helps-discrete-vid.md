---
layout: default
title: OneVAE: Joint Discrete and Continuous Optimization Helps Discrete Video VAE Train Better
---

# OneVAE: Joint Discrete and Continuous Optimization Helps Discrete Video VAE Train Better

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09857" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09857v1</a>
  <a href="https://arxiv.org/pdf/2508.09857.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09857v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09857v1', 'OneVAE: Joint Discrete and Continuous Optimization Helps Discrete Video VAE Train Better')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yupeng Zhou, Zhen Li, Ziheng Ouyang, Yuming Chen, Ruoyi Du, Daquan Zhou, Bin Fu, Yihao Liu, Peng Gao, Ming-Ming Cheng, Qibin Hou

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOneVAEä»¥è§£å†³ç¦»æ•£è§†é¢‘VAEè®­ç»ƒä¸ç¨³å®šé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `ç¦»æ•£è§†é¢‘VAE` `è¿ç»­VAE` `å¤šæ¨¡æ€å­¦ä¹ ` `é‡å»ºè´¨é‡` `è”åˆä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¦»æ•£è§†é¢‘VAEåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å­˜åœ¨ä¸ç¨³å®šæ€§ã€é•¿è®­ç»ƒæ—¶é—´å’Œé‡å»ºè´¨é‡ä¸‹é™ç­‰é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºçš„OneVAEé€šè¿‡å¼•å…¥è¿ç»­VAEçš„å…ˆéªŒçŸ¥è¯†ï¼Œç»“åˆå¤šæ ‡è®°é‡åŒ–æœºåˆ¶å’Œå¼ºåŒ–é¦–å¸§é‡å»ºï¼Œæå‡äº†ç¦»æ•£è§†é¢‘VAEçš„è®­ç»ƒæ•ˆæœã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒOneVAEåœ¨æ”¶æ•›é€Ÿåº¦å’Œé‡å»ºè´¨é‡ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ç¦»æ•£è§†é¢‘VAEï¼Œè¾¾åˆ°äº†æ›´é«˜çš„PSNRå€¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°†è§†é¢‘ç¼–ç ä¸ºç¦»æ•£æ ‡è®°å¯ä»¥ä¸æ–‡æœ¬æ ‡è®°å¯¹é½ï¼Œä»è€Œä¿ƒè¿›ç®€æ´ç»Ÿä¸€çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç¦»æ•£è§†é¢‘å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é¢ä¸´ä¸ç¨³å®šã€è®­ç»ƒæ—¶é—´é•¿å’Œé‡å»ºè´¨é‡ä¸‹é™ç­‰é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºOneVAEçš„æ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨è¿ç»­VAEçš„å…ˆéªŒçŸ¥è¯†ï¼Œæ˜¾è‘—åŠ å¿«äº†æ”¶æ•›é€Ÿåº¦å¹¶æé«˜äº†æ€§èƒ½ã€‚åŒæ—¶ï¼Œæå‡ºäº†å¤šæ ‡è®°é‡åŒ–æœºåˆ¶å’Œå¼ºåŒ–é¦–å¸§é‡å»ºçš„ç»“æ„æ”¹è¿›ï¼Œè¿›ä¸€æ­¥æå‡äº†é‡å»ºè´¨é‡ã€‚OneVAEé¦–æ¬¡åœ¨å•ä¸€ç½‘ç»œä¸­å®ç°äº†ç¦»æ•£å’Œè¿ç»­è¡¨ç¤ºçš„ç»Ÿä¸€ä¼˜åŒ–ï¼Œå±•ç°å‡ºç«äº‰åŠ›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç¦»æ•£è§†é¢‘å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é¢ä¸´çš„ç¨³å®šæ€§å·®ã€è®­ç»ƒæ—¶é—´é•¿å’Œé‡å»ºè´¨é‡ä½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è§†é¢‘æ•°æ®æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆåˆ©ç”¨è¿ç»­è¡¨ç¤ºçš„ä¼˜åŠ¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOneVAEçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¼•å…¥è¿ç»­VAEçš„å…ˆéªŒçŸ¥è¯†æ¥å¢å¼ºç¦»æ•£è§†é¢‘VAEçš„è®­ç»ƒæ•ˆæœï¼Œä»è€Œå®ç°æ›´å¿«çš„æ”¶æ•›å’Œæ›´é«˜çš„é‡å»ºè´¨é‡ã€‚é€šè¿‡é‡æ–°æ€è€ƒç¦»æ•£ä¸è¿ç»­è¡¨ç¤ºä¹‹é—´çš„å†…åœ¨è”ç³»ï¼Œæå‡ºäº†ä¸€ç§è”åˆä¼˜åŒ–æ–¹æ¡ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOneVAEçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆæ˜¯å¤šæ ‡è®°é‡åŒ–æœºåˆ¶ï¼Œç”¨äºæå‡é‡å»ºè´¨é‡ï¼›å…¶æ¬¡æ˜¯å¼ºåŒ–é¦–å¸§é‡å»ºï¼Œä»¥ä¾¿åç»­å¸§èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨é¦–å¸§ä¿¡æ¯ï¼›æœ€åæ˜¯è”åˆç¦»æ•£-è¿ç»­ä¼˜åŒ–æ–¹æ¡ˆï¼Œç»Ÿä¸€äº†ä¸¤ç§è¡¨ç¤ºæ–¹å¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šOneVAEçš„ä¸»è¦åˆ›æ–°åœ¨äºé¦–æ¬¡å®ç°äº†ç¦»æ•£å’Œè¿ç»­è¡¨ç¤ºçš„ç»Ÿä¸€ä¼˜åŒ–ï¼Œæ˜¾è‘—æé«˜äº†è®­ç»ƒæ•ˆç‡å’Œé‡å»ºè´¨é‡ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒOneVAEåœ¨æ”¶æ•›é€Ÿåº¦ä¸Šå¿«äº†æ•°å€ï¼Œä¸”åœ¨æ€§èƒ½ä¸Šè¡¨ç°å‡ºè‰²ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒOneVAEé‡‡ç”¨äº†å¤šæ ‡è®°é‡åŒ–æœºåˆ¶ï¼Œä¼˜åŒ–äº†æ½œåœ¨ç»´åº¦ï¼Œå¹¶è®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¼ºåŒ–é¦–å¸§é‡å»ºï¼Œç¡®ä¿åœ¨é«˜å‹ç¼©æ¯”ä¸‹ä»èƒ½ä¿æŒè‰¯å¥½çš„é‡å»ºæ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOneVAEåœ¨PSNRæŒ‡æ ‡ä¸Šæå‡äº†è¿‘1 dBï¼Œå¹¶ä¸”æ”¶æ•›é€Ÿåº¦æ¯”ä»å¤´å¼€å§‹è®­ç»ƒå¿«æ•°å€ã€‚è¿™è¡¨æ˜è¯¥æ–¹æ³•åœ¨ç¦»æ•£è§†é¢‘VAEçš„è®­ç»ƒå’Œé‡å»ºè´¨é‡ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè§£å†³ç°æœ‰æ–¹æ³•çš„ä¸è¶³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

OneVAEçš„ç ”ç©¶æˆæœåœ¨å¤šæ¨¡æ€å­¦ä¹ ã€è§†é¢‘ç†è§£å’Œç”Ÿæˆç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜ç¦»æ•£è§†é¢‘VAEçš„è®­ç»ƒæ•ˆç‡å’Œé‡å»ºè´¨é‡ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä¸ºè§†é¢‘å†…å®¹ç”Ÿæˆã€è§†é¢‘æ‘˜è¦å’Œè§†é¢‘æ£€ç´¢ç­‰ä»»åŠ¡æä¾›æ›´å¼ºå¤§çš„æŠ€æœ¯æ”¯æŒï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Encoding videos into discrete tokens could align with text tokens to facilitate concise and unified multi-modal LLMs, yet introducing significant spatiotemporal compression compared to continuous video representation. Previous discrete video VAEs experienced unstable training, long training time, and degraded reconstruction quality. Given the easier training and superior performance of continuous VAEs, an intuitive idea is to enhance discrete video VAEs by leveraging continuous VAEs. After rethinking the intrinsic link between discrete and continuous representations, we found that FSQ could effectively preserve pre-trained continuous VAE priors compared to other quantization methods. By leveraging continuous VAE priors, it converges several times faster than training from scratch and achieves superior performance at convergence. Meanwhile, two structural improvements are proposed. First, inspired by how continuous VAEs enhance reconstruction via enlarged latent dimensions, we introduce a multi-token quantization mechanism, which achieves nearly a 1 dB improvement in PSNR without compromising the token compression ratio. Second, to tackle reconstruction challenges in high-compression video VAEs, we strengthen first-frame reconstruction, enabling the causal VAE to leverage this information in subsequent frames and markedly improving the performance of 4 x 16 x 16 discrete VAEs. Furthermore, we propose a joint discrete-continuous optimization scheme that unifies the two paradigms and, for the first time, achieves competitive performance on both continuous and discrete representations within a single network. We name our method OneVAE to reflect this connection.

