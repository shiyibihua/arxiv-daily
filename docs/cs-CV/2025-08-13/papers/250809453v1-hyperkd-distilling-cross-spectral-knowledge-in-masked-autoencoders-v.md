---
layout: default
title: HyperKD: Distilling Cross-Spectral Knowledge in Masked Autoencoders via Inverse Domain Shift with Spatial-Aware Masking and Specialized Loss
---

# HyperKD: Distilling Cross-Spectral Knowledge in Masked Autoencoders via Inverse Domain Shift with Spatial-Aware Masking and Specialized Loss

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09453" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09453v1</a>
  <a href="https://arxiv.org/pdf/2508.09453.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09453v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09453v1', 'HyperKD: Distilling Cross-Spectral Knowledge in Masked Autoencoders via Inverse Domain Shift with Spatial-Aware Masking and Specialized Loss')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Abdul Matin, Tanjim Bin Faruk, Shrideep Pallickara, Sangmi Lee Pallickara

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHyperKDä»¥è§£å†³é«˜å…‰è°±é¥æ„Ÿä¸­çš„çŸ¥è¯†è’¸é¦é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é«˜å…‰è°±é¥æ„Ÿ` `çŸ¥è¯†è’¸é¦` `é€†åŸŸé€‚åº”` `ç‰¹å¾å¯¹é½` `ç©ºé—´ç‰¹å¾æ©è”½` `åŸºç¡€æ¨¡å‹` `é¥æ„Ÿåˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çŸ¥è¯†è’¸é¦æ–¹æ³•åœ¨é«˜å…‰è°±é¥æ„Ÿä¸­é¢ä¸´å…‰è°±å·®å¼‚å’Œè§‚æµ‹æ•°æ®ç¨€ç¼ºçš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†åŸºç¡€æ¨¡å‹çš„æœ‰æ•ˆåº”ç”¨ã€‚
2. HyperKDé€šè¿‡é€†å‘çŸ¥è¯†è½¬ç§»ï¼Œåˆ©ç”¨ç®€å•çš„æ•™å¸ˆæ¨¡å‹æŒ‡å¯¼å¤æ‚çš„å­¦ç”Ÿæ¨¡å‹ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„çŸ¥è¯†è’¸é¦æ¡†æ¶ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒHyperKDåœ¨MAEçš„è¡¨ç¤ºå­¦ä¹ ä¸Šæ˜¾è‘—æå‡äº†é‡å»ºç²¾åº¦ï¼Œå¹¶åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€åŸºç¡€æ¨¡å‹çš„æ™®åŠï¼Œåˆ©ç”¨å¤§è§„æ¨¡æ— æ ‡ç­¾æ•°æ®é›†è¿›è¡Œé¢„è®­ç»ƒå·²æˆä¸ºåˆ›å»ºå¯é€‚åº”å’Œå¯é‡ç”¨æ¶æ„çš„æœ‰æ•ˆæ–¹æ³•ã€‚ç„¶è€Œï¼Œç›´æ¥åº”ç”¨äºé«˜å…‰è°±é¥æ„Ÿé¢ä¸´å…‰è°±å·®å¼‚å’Œè§‚æµ‹ç¨€ç¼ºçš„æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºHyperKDï¼Œä¸€ä¸ªæ–°é¢–çš„çŸ¥è¯†è’¸é¦æ¡†æ¶ï¼Œèƒ½å¤Ÿå°†æ•™å¸ˆæ¨¡å‹çš„å­¦ä¹ è¡¨ç¤ºæœ‰æ•ˆè½¬ç§»åˆ°å­¦ç”Ÿæ¨¡å‹ä¸­ï¼Œä¿ƒè¿›é«˜å…‰è°±å›¾åƒçš„åŸºç¡€æ¨¡å‹å¼€å‘ã€‚HyperKDé€šè¿‡å¼•å…¥åŸºäºç‰¹å¾çš„ç­–ç•¥ï¼Œè§£å†³äº†å…‰è°±é—´éš™çš„é€†åŸŸé€‚åº”é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†MAEçš„è¡¨ç¤ºå­¦ä¹ æ•ˆæœï¼Œå¹¶åœ¨åœŸåœ°è¦†ç›–åˆ†ç±»ã€ä½œç‰©ç±»å‹è¯†åˆ«å’ŒåœŸå£¤æœ‰æœºç¢³é¢„æµ‹ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´å¼ºçš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é«˜å…‰è°±é¥æ„Ÿä¸­çŸ¥è¯†è’¸é¦çš„é€†åŸŸé€‚åº”é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å…‰è°±å·®å¼‚å’Œæ•°æ®ç¨€ç¼ºæƒ…å†µä¸‹éš¾ä»¥æœ‰æ•ˆè¿ç§»çŸ¥è¯†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHyperKDé€šè¿‡å¼•å…¥ç®€å•æ•™å¸ˆæ¨¡å‹æŒ‡å¯¼å¤æ‚å­¦ç”Ÿæ¨¡å‹ï¼Œé‡‡ç”¨é€†å‘çŸ¥è¯†è½¬ç§»çš„æ–¹å¼ï¼Œå…‹æœäº†å…‰è°±é—´éš™å¸¦æ¥çš„æŒ‘æˆ˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHyperKDåŸºäºMasked Autoencoderæ„å»ºï¼Œä¸»è¦åŒ…æ‹¬ç‰¹å¾å¯¹é½ã€ç©ºé—´ç‰¹å¾å¼•å¯¼æ©è”½å’Œé’ˆå¯¹é«˜å…‰è°±å›¾åƒçš„å¢å¼ºæŸå¤±å‡½æ•°ç­‰æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šHyperKDçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶é€†å‘çŸ¥è¯†è½¬ç§»æœºåˆ¶å’Œç‰¹å¾åŸºç¡€ç­–ç•¥ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„çŸ¥è¯†è’¸é¦æ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å…‰è°±åŸŸé—´éš™ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒHyperKDé‡‡ç”¨äº†å…‰è°±èŒƒå›´åŸºç¡€çš„é€šé“å¯¹é½æŠ€æœ¯ï¼Œç»“åˆç©ºé—´ç‰¹å¾å¼•å¯¼çš„æ©è”½ç­–ç•¥ï¼Œå¹¶è®¾è®¡äº†é€‚ç”¨äºé«˜å…‰è°±å›¾åƒçš„æŸå¤±å‡½æ•°ï¼Œä»¥æé«˜æ¨¡å‹çš„å­¦ä¹ æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHyperKDåœ¨MAEçš„è¡¨ç¤ºå­¦ä¹ ä¸Šæ˜¾è‘—æé«˜äº†é‡å»ºç²¾åº¦ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼ŒåœŸåœ°è¦†ç›–åˆ†ç±»ä»»åŠ¡çš„å‡†ç¡®ç‡æå‡äº†X%ï¼Œä½œç‰©ç±»å‹è¯†åˆ«ä»»åŠ¡çš„F1åˆ†æ•°æå‡äº†Y%ï¼Œå±•ç°äº†çŸ¥è¯†è’¸é¦æ¡†æ¶åœ¨é«˜å…‰è°±å›¾åƒåˆ†æä¸­çš„å·¨å¤§æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

HyperKDçš„ç ”ç©¶æˆæœåœ¨é«˜å…‰è°±é¥æ„Ÿé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡åœŸåœ°è¦†ç›–åˆ†ç±»ã€ä½œç‰©ç±»å‹è¯†åˆ«å’ŒåœŸå£¤æœ‰æœºç¢³é¢„æµ‹ç­‰ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚è¿™ä¸€æ¡†æ¶ä¸ºé¥æ„Ÿåˆ†ææä¾›äº†æ–°çš„æ€è·¯ï¼Œæœªæ¥å¯è¿›ä¸€æ­¥æ¨å¹¿è‡³å…¶ä»–é¢†åŸŸçš„å¤šæ¨¡æ€æ•°æ®å¤„ç†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The proliferation of foundation models, pretrained on large-scale unlabeled datasets, has emerged as an effective approach in creating adaptable and reusable architectures that can be leveraged for various downstream tasks using satellite observations. However, their direct application to hyperspectral remote sensing remains challenging due to inherent spectral disparities and the scarcity of available observations. In this work, we present HyperKD, a novel knowledge distillation framework that enables transferring learned representations from a teacher model into a student model for effective development of a foundation model on hyperspectral images. Unlike typical knowledge distillation frameworks, which use a complex teacher to guide a simpler student, HyperKD enables an inverse form of knowledge transfer across different types of spectral data, guided by a simpler teacher model. Building upon a Masked Autoencoder, HyperKD distills knowledge from the Prithvi foundational model into a student tailored for EnMAP hyperspectral imagery. HyperKD addresses the inverse domain adaptation problem with spectral gaps by introducing a feature-based strategy that includes spectral range-based channel alignment, spatial feature-guided masking, and an enhanced loss function tailored for hyperspectral images. HyperKD bridges the substantial spectral domain gap, enabling the effective use of pretrained foundation models for geospatial applications. Extensive experiments show that HyperKD significantly improves representation learning in MAEs, leading to enhanced reconstruction fidelity and more robust performance on downstream tasks such as land cover classification, crop type identification, and soil organic carbon prediction, underpinning the potential of knowledge distillation frameworks in remote sensing analytics with hyperspectral imagery.

