---
layout: default
title: Parametric Gaussian Human Model: Generalizable Prior for Efficient and Realistic Human Avatar Modeling
---

# Parametric Gaussian Human Model: Generalizable Prior for Efficient and Realistic Human Avatar Modeling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.06645" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.06645v1</a>
  <a href="https://arxiv.org/pdf/2506.06645.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.06645v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.06645v1', 'Parametric Gaussian Human Model: Generalizable Prior for Efficient and Realistic Human Avatar Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Cheng Peng, Jingxiang Sun, Yushuo Chen, Zhaoqi Su, Zhuo Su, Yebin Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-07

**å¤‡æ³¨**: Project Page: https://pengc02.github.io/pghm/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå‚æ•°åŒ–é«˜æ–¯äººæ¨¡å‹ä»¥è§£å†³å•ç›®è§†é¢‘å¤´åƒé‡å»ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `é«˜æ–¯æ¨¡å‹` `äººç±»å¤´åƒ` `å•ç›®è§†é¢‘` `è™šæ‹Ÿç°å®` `å¢å¼ºç°å®` `å¤´åƒé‡å»º` `æ·±åº¦å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ä¸ªä½“ä¼˜åŒ–ä¸Šè€—æ—¶è¾ƒé•¿ï¼Œå¹¶ä¸”åœ¨ç¨€ç–å•ç›®è¾“å…¥ä¸‹æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. æå‡ºçš„PGHMæ¡†æ¶é€šè¿‡å¼•å…¥äººç±»å…ˆéªŒçŸ¥è¯†ï¼Œå®ç°äº†é«˜æ•ˆçš„å•ç›®è§†é¢‘å¤´åƒé‡å»ºã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPGHMåœ¨æ•ˆç‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæ¯ä¸ªä¸»ä½“ä»…éœ€çº¦20åˆ†é’Ÿå³å¯ç”Ÿæˆé«˜è´¨é‡å¤´åƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é€¼çœŸä¸”å¯åŠ¨ç”»çš„äººç±»å¤´åƒæ˜¯è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€è¿œç¨‹å‘ˆç°å’Œæ•°å­—å¨±ä¹çš„å…³é”®ã€‚å°½ç®¡3Dé«˜æ–¯ç‚¹äº‘æŠ€æœ¯åœ¨æ¸²æŸ“è´¨é‡å’Œæ•ˆç‡ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•ä»é¢ä¸´ä¸ªä½“ä¼˜åŒ–è€—æ—¶å’Œåœ¨ç¨€ç–å•ç›®è¾“å…¥ä¸‹æ³›åŒ–èƒ½åŠ›å·®ç­‰æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†å‚æ•°åŒ–é«˜æ–¯äººæ¨¡å‹ï¼ˆPGHMï¼‰ï¼Œè¯¥æ¡†æ¶å°†äººç±»å…ˆéªŒçŸ¥è¯†æ•´åˆåˆ°3Dé«˜æ–¯ç‚¹äº‘ä¸­ï¼Œå®ç°äº†ä»å•ç›®è§†é¢‘å¿«é€Ÿé«˜ä¿çœŸå¤´åƒé‡å»ºã€‚PGHMå¼•å…¥äº†ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šUVå¯¹é½çš„æ½œåœ¨èº«ä»½å›¾å’Œè§£è€¦çš„å¤šå¤´U-Netï¼Œèƒ½å¤Ÿåœ¨å¤æ‚å§¿æ€å’Œè§†è§’ä¸‹ä¿æŒæ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶æ— éœ€å¤šè§†è§’æ•æ‰æˆ–é•¿æ—¶é—´ä¼˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼ŒPGHMçš„æ•ˆç‡æ˜¾è‘—é«˜äºä»å¤´ä¼˜åŒ–çš„æ–¹æ³•ï¼Œæ¯ä¸ªä¸»ä½“ä»…éœ€çº¦20åˆ†é’Ÿå³å¯ç”Ÿæˆè§†è§‰è´¨é‡ç›¸å½“çš„å¤´åƒï¼Œå±•ç¤ºäº†å…¶åœ¨ç°å®å•ç›®å¤´åƒåˆ›å»ºä¸­çš„å®é™…åº”ç”¨æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»å•ç›®è§†é¢‘ä¸­é«˜æ•ˆé‡å»ºé€¼çœŸå¤´åƒçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä¸ªä½“ä¼˜åŒ–ä¸Šè€—æ—¶è¾ƒé•¿ï¼Œå¹¶ä¸”åœ¨ç¨€ç–å•ç›®è¾“å…¥ä¸‹çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPGHMæ¡†æ¶é€šè¿‡å¼•å…¥UVå¯¹é½çš„æ½œåœ¨èº«ä»½å›¾å’Œè§£è€¦çš„å¤šå¤´U-Netï¼Œæ•´åˆäººç±»å…ˆéªŒçŸ¥è¯†ï¼Œä»è€Œå®ç°å¿«é€Ÿä¸”é«˜ä¿çœŸçš„å¤´åƒé‡å»ºã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—åœ¨å¤æ‚å§¿æ€å’Œè§†è§’ä¸‹ä»èƒ½ä¿æŒè‰¯å¥½çš„æ¸²æŸ“è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPGHMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šUVå¯¹é½çš„æ½œåœ¨èº«ä»½å›¾ç”¨äºç¼–ç ä¸ªä½“å‡ ä½•å’Œå¤–è§‚ä¿¡æ¯ï¼Œè§£è€¦çš„å¤šå¤´U-Netç”¨äºé¢„æµ‹é«˜æ–¯å±æ€§ã€‚è¯¥æ¡†æ¶é€šè¿‡æ¡ä»¶è§£ç å™¨åˆ†è§£é™æ€ã€å§¿æ€ä¾èµ–å’Œè§†è§’ä¾èµ–çš„ç»„ä»¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šPGHMçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶å°†äººç±»å…ˆéªŒçŸ¥è¯†ä¸3Dé«˜æ–¯ç‚¹äº‘æŠ€æœ¯ç»“åˆï¼Œæ˜¾è‘—æé«˜äº†å¤´åƒé‡å»ºçš„æ•ˆç‡å’Œè´¨é‡ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå‡å°‘äº†å¯¹å¤šè§†è§’æ•æ‰å’Œé•¿æ—¶é—´ä¼˜åŒ–çš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒUVå¯¹é½çš„æ½œåœ¨èº«ä»½å›¾è¢«ç”¨ä½œå¯å­¦ä¹ çš„ç‰¹å¾å¼ é‡ï¼Œè§£è€¦çš„å¤šå¤´U-Neté€šè¿‡æ¡ä»¶è§£ç å™¨æ¥é¢„æµ‹é«˜æ–¯å±æ€§ï¼Œç¡®ä¿åœ¨ä¸åŒå§¿æ€å’Œè§†è§’ä¸‹çš„æ¸²æŸ“è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPGHMåœ¨å¤´åƒç”Ÿæˆæ•ˆç‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ä»å¤´ä¼˜åŒ–æ–¹æ³•ï¼Œæ¯ä¸ªä¸»ä½“ä»…éœ€çº¦20åˆ†é’Ÿå³å¯ç”Ÿæˆè§†è§‰è´¨é‡ç›¸å½“çš„å¤´åƒï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€è¿œç¨‹å‘ˆç°å’Œæ•°å­—å¨±ä¹ç­‰ã€‚é€šè¿‡æä¾›é«˜æ•ˆä¸”é«˜ä¿çœŸçš„äººç±»å¤´åƒé‡å»ºï¼ŒPGHMå¯ä»¥åœ¨æ¸¸æˆã€å½±è§†åˆ¶ä½œå’Œåœ¨çº¿ç¤¾äº¤ç­‰å¤šä¸ªåœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œäº¤äº’è´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Photorealistic and animatable human avatars are a key enabler for virtual/augmented reality, telepresence, and digital entertainment. While recent advances in 3D Gaussian Splatting (3DGS) have greatly improved rendering quality and efficiency, existing methods still face fundamental challenges, including time-consuming per-subject optimization and poor generalization under sparse monocular inputs. In this work, we present the Parametric Gaussian Human Model (PGHM), a generalizable and efficient framework that integrates human priors into 3DGS for fast and high-fidelity avatar reconstruction from monocular videos. PGHM introduces two core components: (1) a UV-aligned latent identity map that compactly encodes subject-specific geometry and appearance into a learnable feature tensor; and (2) a disentangled Multi-Head U-Net that predicts Gaussian attributes by decomposing static, pose-dependent, and view-dependent components via conditioned decoders. This design enables robust rendering quality under challenging poses and viewpoints, while allowing efficient subject adaptation without requiring multi-view capture or long optimization time. Experiments show that PGHM is significantly more efficient than optimization-from-scratch methods, requiring only approximately 20 minutes per subject to produce avatars with comparable visual quality, thereby demonstrating its practical applicability for real-world monocular avatar creation.

