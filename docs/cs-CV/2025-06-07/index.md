---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-06-07
---

# cs.CVï¼ˆ2025-06-07ï¼‰

ğŸ“Š å…± **5** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (4 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250606645v1-parametric-gaussian-human-model-generalizable-prior-for-efficient-an.html">Parametric Gaussian Human Model: Generalizable Prior for Efficient and Realistic Human Avatar Modeling</a></td>
  <td>æå‡ºå‚æ•°åŒ–é«˜æ–¯äººæ¨¡å‹ä»¥è§£å†³å•ç›®è§†é¢‘å¤´åƒé‡å»ºé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">3DGS</span> <span class="paper-tag">gaussian splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06645v1" data-paper-url="./papers/250606645v1-parametric-gaussian-human-model-generalizable-prior-for-efficient-an.html" onclick="toggleFavorite(this, '2506.06645v1', 'Parametric Gaussian Human Model: Generalizable Prior for Efficient and Realistic Human Avatar Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250606631v2-physlab-a-benchmark-dataset-for-multi-granularity-visual-parsing-of-.html">PhysLab: A Benchmark Dataset for Multi-Granularity Visual Parsing of Physics Experiments</a></td>
  <td>æå‡ºPhysLabæ•°æ®é›†ä»¥è§£å†³ç‰©ç†å®éªŒè§†è§‰è§£æçš„å¤šç²’åº¦é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">scene understanding</span> <span class="paper-tag">human-object interaction</span> <span class="paper-tag">HOI</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06631v2" data-paper-url="./papers/250606631v2-physlab-a-benchmark-dataset-for-multi-granularity-visual-parsing-of-.html" onclick="toggleFavorite(this, '2506.06631v2', 'PhysLab: A Benchmark Dataset for Multi-Granularity Visual Parsing of Physics Experiments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250606643v2-dark-channel-assisted-depth-from-defocus-from-a-single-image.html">Dark Channel-Assisted Depth-from-Defocus from a Single Image</a></td>
  <td>æå‡ºåŸºäºæš—é€šé“çš„å•å¹…å›¾åƒæ·±åº¦ä¼°è®¡æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">depth estimation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06643v2" data-paper-url="./papers/250606643v2-dark-channel-assisted-depth-from-defocus-from-a-single-image.html" onclick="toggleFavorite(this, '2506.06643v2', 'Dark Channel-Assisted Depth-from-Defocus from a Single Image')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250606596v1-ev-layersegnet-self-supervised-motion-segmentation-using-event-camer.html">EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras</a></td>
  <td>æå‡ºEV-LayerSegNetä»¥è§£å†³äº‹ä»¶ç›¸æœºè¿åŠ¨åˆ†å‰²é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">optical flow</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06596v1" data-paper-url="./papers/250606596v1-ev-layersegnet-self-supervised-motion-segmentation-using-event-camer.html" onclick="toggleFavorite(this, '2506.06596v1', 'EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>5</td>
  <td><a href="./papers/250606602v1-zero-shot-composed-image-retrieval.html">Zero Shot Composed Image Retrieval</a></td>
  <td>æå‡ºåŸºäºBLIP-2çš„é›¶-shotå¤åˆå›¾åƒæ£€ç´¢æ–¹æ³•ä»¥æå‡æ£€ç´¢æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">DPO</span> <span class="paper-tag">direct preference optimization</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06602v1" data-paper-url="./papers/250606602v1-zero-shot-composed-image-retrieval.html" onclick="toggleFavorite(this, '2506.06602v1', 'Zero Shot Composed Image Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)