---
layout: default
title: A Unified Low-level Foundation Model for Enhancing Pathology Image Quality
---

# A Unified Low-level Foundation Model for Enhancing Pathology Image Quality

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01071" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01071v1</a>
  <a href="https://arxiv.org/pdf/2509.01071.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01071v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01071v1', 'A Unified Low-level Foundation Model for Enhancing Pathology Image Quality')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziyi Liu, Zhe Xu, Jiabo Ma, Wenqaing Li, Junlin Hou, Fuxiang Huang, Xi Wang, Ronald Cheong Kin Chan, Terence Tsz Wai Wong, Hao Chen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€ä½çº§ç—…ç†åŸºç¡€æ¨¡å‹ä»¥å¢å¼ºç—…ç†å›¾åƒè´¨é‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç—…ç†å›¾åƒå¤„ç†` `å›¾åƒå¢å¼º` `æ·±åº¦å­¦ä¹ ` `åŸºç¡€æ¨¡å‹` `å¤šä»»åŠ¡å­¦ä¹ ` `å›¾åƒæ¢å¤` `è™šæ‹ŸæŸ“è‰²`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å¤šé’ˆå¯¹å•ä¸€é—®é¢˜ï¼Œå¦‚å»å™ªæˆ–è¶…åˆ†è¾¨ç‡ï¼Œç¼ºä¹å¤„ç†å¤šç§ä½çº§è§†è§‰æŒ‘æˆ˜çš„é€šç”¨æ€§ï¼Œå¯¼è‡´å®é™…åº”ç”¨ä¸­çš„å±€é™æ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„ä½çº§ç—…ç†åŸºç¡€æ¨¡å‹ï¼ˆLPFMï¼‰é€šè¿‡å•ä¸€æ¶æ„åŒæ—¶å¤„ç†è¶…åˆ†è¾¨ç‡ã€å»æ¨¡ç³Šå’Œå»å™ªå£°ç­‰ä»»åŠ¡ï¼Œå…·æœ‰é«˜åº¦é€‚åº”æ€§ã€‚
3. åœ¨87,810å¹…å…¨åˆ‡ç‰‡å›¾åƒçš„å®éªŒä¸­ï¼ŒLPFMåœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒPSNRå’ŒSSIMå‡æœ‰æ˜¾è‘—æ”¹å–„ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºç¡€æ¨¡å‹åœ¨è®¡ç®—ç—…ç†å­¦ä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†ä½çº§å›¾åƒå¢å¼ºçš„å…³é”®æŒ‘æˆ˜ä»æœªå¾—åˆ°æœ‰æ•ˆè§£å†³ã€‚ç°å®ä¸­çš„ç—…ç†å›¾åƒå¸¸å› åˆ¶ç‰‡å·¥è‰ºã€æŸ“è‰²å˜å¼‚å’Œæˆåƒé™åˆ¶ç­‰åŸå› å—åˆ°å™ªå£°ã€æ¨¡ç³Šå’Œä½åˆ†è¾¨ç‡ç­‰é€€åŒ–å½±å“ã€‚ç°æœ‰æ–¹æ³•å¤šé’ˆå¯¹å•ä¸€é—®é¢˜ï¼Œç¼ºä¹å¤„ç†å¤šæ ·ä½çº§è§†è§‰æŒ‘æˆ˜çš„é€šç”¨æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†é¦–ä¸ªç»Ÿä¸€çš„ä½çº§ç—…ç†åŸºç¡€æ¨¡å‹ï¼ˆLPFMï¼‰ï¼Œèƒ½å¤Ÿé€šè¿‡å•ä¸€æ¶æ„æå‡å›¾åƒè´¨é‡ï¼Œæ¶µç›–è¶…åˆ†è¾¨ç‡ã€å»æ¨¡ç³Šã€å»å™ªå£°ç­‰æ¢å¤ä»»åŠ¡ï¼Œä»¥åŠè™šæ‹ŸæŸ“è‰²ç­‰å›¾åƒè½¬æ¢ä»»åŠ¡ã€‚è¯¥æ¨¡å‹é€šè¿‡å¯¹1.9äº¿æœªæ ‡è®°ç—…ç†å›¾åƒè¿›è¡Œå¯¹æ¯”é¢„è®­ç»ƒï¼Œå­¦ä¹ å¯è½¬ç§»çš„ã€æŸ“è‰²ä¸å˜çš„ç‰¹å¾è¡¨ç¤ºï¼Œç¡®ä¿å¯¹é€€åŒ–æ¨¡å¼çš„ç¨³å¥è¯†åˆ«ã€‚ç»è¿‡åœ¨87,810å¹…å…¨åˆ‡ç‰‡å›¾åƒä¸Šè®­ç»ƒï¼ŒLPFMåœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸­ï¼ˆ56/66ï¼‰æ˜¾ç¤ºå‡ºç»Ÿè®¡æ˜¾è‘—çš„æ”¹è¿›ï¼Œå›¾åƒæ¢å¤çš„å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰æå‡10-15%ï¼Œè™šæ‹ŸæŸ“è‰²çš„ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆSSIMï¼‰æå‡12-18%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç—…ç†å›¾åƒåœ¨å®é™…åº”ç”¨ä¸­å› åˆ¶ç‰‡å·¥è‰ºå’Œæˆåƒé™åˆ¶è€Œå¯¼è‡´çš„å™ªå£°ã€æ¨¡ç³Šå’Œä½åˆ†è¾¨ç‡ç­‰ä½çº§å›¾åƒè´¨é‡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€é’ˆå¯¹å•ä¸€é—®é¢˜ï¼Œç¼ºä¹é€šç”¨æ€§ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹å¤šæ ·çš„ä½çº§è§†è§‰æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„ä½çº§ç—…ç†åŸºç¡€æ¨¡å‹ï¼ˆLPFMï¼‰é€šè¿‡ç»Ÿä¸€çš„æ¶æ„ï¼Œç»“åˆå¯¹æ¯”é¢„è®­ç»ƒçš„ç¼–ç å™¨ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†å¤šç§å›¾åƒæ¢å¤å’Œè½¬æ¢ä»»åŠ¡ï¼Œæå‡å›¾åƒè´¨é‡ã€‚è¯¥æ¨¡å‹çš„è®¾è®¡æ—¨åœ¨å®ç°ä»»åŠ¡é—´çš„å¯è½¬ç§»æ€§å’Œé€‚åº”æ€§ï¼Œç¡®ä¿åœ¨ä¸åŒä»»åŠ¡ä¸­å‡èƒ½è·å¾—ä¼˜å¼‚è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLPFMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªå¯¹æ¯”é¢„è®­ç»ƒçš„ç¼–ç å™¨å’Œä¸€ä¸ªç»Ÿä¸€çš„æ¡ä»¶æ‰©æ•£è¿‡ç¨‹ã€‚ç¼–ç å™¨ä»190ç™¾ä¸‡æœªæ ‡è®°çš„ç—…ç†å›¾åƒä¸­å­¦ä¹ ç‰¹å¾è¡¨ç¤ºï¼Œè€Œæ¡ä»¶æ‰©æ•£è¿‡ç¨‹åˆ™é€šè¿‡æ–‡æœ¬æç¤ºåŠ¨æ€é€‚åº”ç‰¹å®šä»»åŠ¡ï¼Œç¡®ä¿è¾“å‡ºè´¨é‡çš„ç²¾ç¡®æ§åˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šLPFMçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶ç»Ÿä¸€æ€§å’Œé€‚åº”æ€§ï¼Œèƒ½å¤Ÿåœ¨å•ä¸€æ¨¡å‹ä¸­å¤„ç†å¤šç§ä½çº§è§†è§‰ä»»åŠ¡ï¼Œä¸ç°æœ‰æ–¹æ³•çš„ä»»åŠ¡ç‰¹å®šè®¾è®¡å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹çš„è®­ç»ƒä½¿ç”¨äº†87,810å¹…å…¨åˆ‡ç‰‡å›¾åƒï¼Œæ¶µç›–34ç§ç»„ç»‡ç±»å‹å’Œ5ç§æŸ“è‰²åè®®ã€‚æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿åœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸­å®ç°æœ€ä½³æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLPFMåœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸­ï¼ˆ56/66ï¼‰å‡æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå›¾åƒæ¢å¤çš„å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰æå‡10-15%ï¼Œè™šæ‹ŸæŸ“è‰²çš„ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆSSIMï¼‰æå‡12-18%ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨ç—…ç†å›¾åƒå¤„ç†ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»å­¦å›¾åƒå¤„ç†ã€ç—…ç†è¯Šæ–­å’Œç”Ÿç‰©åŒ»å­¦ç ”ç©¶ç­‰ã€‚é€šè¿‡æå‡ç—…ç†å›¾åƒçš„è´¨é‡ï¼ŒLPFMèƒ½å¤Ÿå¸®åŠ©ç—…ç†å­¦å®¶æ›´å‡†ç¡®åœ°è¿›è¡Œè¯Šæ–­ï¼Œå‡å°‘å› å›¾åƒè´¨é‡é—®é¢˜å¯¼è‡´çš„è¯¯è¯Šé£é™©ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Foundation models have revolutionized computational pathology by achieving remarkable success in high-level diagnostic tasks, yet the critical challenge of low-level image enhancement remains largely unaddressed. Real-world pathology images frequently suffer from degradations such as noise, blur, and low resolution due to slide preparation artifacts, staining variability, and imaging constraints, while the reliance on physical staining introduces significant costs, delays, and inconsistency. Although existing methods target individual problems like denoising or super-resolution, their task-specific designs lack the versatility to handle the diverse low-level vision challenges encountered in practice. To bridge this gap, we propose the first unified Low-level Pathology Foundation Model (LPFM), capable of enhancing image quality in restoration tasks, including super-resolution, deblurring, and denoising, as well as facilitating image translation tasks like virtual staining (H&E and special stains), all through a single adaptable architecture. Our approach introduces a contrastive pre-trained encoder that learns transferable, stain-invariant feature representations from 190 million unlabeled pathology images, enabling robust identification of degradation patterns. A unified conditional diffusion process dynamically adapts to specific tasks via textual prompts, ensuring precise control over output quality. Trained on a curated dataset of 87,810 whole slied images (WSIs) across 34 tissue types and 5 staining protocols, LPFM demonstrates statistically significant improvements (p<0.01) over state-of-the-art methods in most tasks (56/66), achieving Peak Signal-to-Noise Ratio (PSNR) gains of 10-15% for image restoration and Structural Similarity Index Measure (SSIM) improvements of 12-18% for virtual staining.

