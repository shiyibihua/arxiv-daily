---
layout: default
title: Do Video Language Models Really Know Where to Look? Diagnosing Attention Failures in Video Language Models
---

# Do Video Language Models Really Know Where to Look? Diagnosing Attention Failures in Video Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01167" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01167v1</a>
  <a href="https://arxiv.org/pdf/2509.01167.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01167v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01167v1', 'Do Video Language Models Really Know Where to Look? Diagnosing Attention Failures in Video Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hyunjong Ok, Jaeho Lee

**åˆ†ç±»**: cs.CV, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01

**å¤‡æ³¨**: preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯Šæ–­è§†é¢‘è¯­è¨€æ¨¡å‹æ³¨æ„åŠ›å¤±æ•ˆé—®é¢˜ï¼Œæ­ç¤ºå…³é”®å¸§é€‰æ‹©çš„å±€é™æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘è¯­è¨€æ¨¡å‹` `å…³é”®å¸§é€‰æ‹©` `æ³¨æ„åŠ›æœºåˆ¶` `å¤šæ¨¡æ€å­¦ä¹ ` `è§†é¢‘ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘è¯­è¨€æ¨¡å‹ä¾èµ–è§†è§‰-è¯­è¨€ç¼–ç å™¨è¿›è¡Œå…³é”®å¸§é‡‡æ ·ï¼Œä½†å…¶æœ‰æ•ˆæ€§æœªç»éªŒè¯ã€‚
2. è®ºæ–‡é€šè¿‡å®éªŒè¯Šæ–­ç°æœ‰è§†è§‰ç¼–ç å™¨åœ¨å…³é”®å¸§é€‰æ‹©ä¸Šçš„ä¸è¶³ï¼Œæ­ç¤ºæ³¨æ„åŠ›æœºåˆ¶çš„å¤±æ•ˆã€‚
3. ç ”ç©¶è¡¨æ˜ï¼Œéœ€è¦å¼€å‘æ›´æœ‰æ•ˆçš„å…³é”®å¸§è¯†åˆ«æŠ€æœ¯ï¼Œä»¥æå‡è§†é¢‘è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨è§†é¢‘ç†è§£ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ä¸ºäº†é¿å…å¤„ç†æ‰€æœ‰å¸§å¸¦æ¥çš„å·¨å¤§è®¡ç®—æˆæœ¬ï¼Œè¿™äº›æ¨¡å‹é€šå¸¸ä¾èµ–äºç”±è§†è§‰-è¯­è¨€ç¼–ç å™¨ï¼ˆä¾‹å¦‚ï¼ŒSigLIPï¼‰å¼•å¯¼çš„å…³é”®å¸§é‡‡æ ·æ–¹æ³•ã€‚ç„¶è€Œï¼Œè¿™äº›ç¼–ç å™¨æ˜¯å¦èƒ½å¤ŸçœŸæ­£è¯†åˆ«å‡ºä¿¡æ¯é‡æœ€å¤§çš„å¸§ä»ç„¶ä¸æ¸…æ¥šã€‚æœ¬æ–‡é€šè¿‡å¤šä¸ªç»éªŒæ€§è¯æ®è¡¨æ˜ï¼Œæµè¡Œçš„è§†è§‰ç¼–ç å™¨åœ¨è¯†åˆ« MLLM åº”è¯¥å…³æ³¨è§†é¢‘å†…éƒ¨å“ªäº›éƒ¨åˆ†ä»¥é€‚å½“å¤„ç†ç»™å®šçš„æ–‡æœ¬æŸ¥è¯¢æ–¹é¢å­˜åœ¨ä¸¥é‡ä¸è¶³ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå¼€å‘æ›´å¥½çš„å…³é”®å¸§è¯†åˆ«æŠ€æœ¯å¯¹äºé«˜æ•ˆçš„è§†é¢‘ MLLM æ¥è¯´å¯èƒ½æ˜¯å¿…è¦çš„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è§†é¢‘è¯­è¨€æ¨¡å‹ä¸ºäº†é™ä½è®¡ç®—æˆæœ¬ï¼Œé€šå¸¸é‡‡ç”¨åŸºäºè§†è§‰-è¯­è¨€ç¼–ç å™¨çš„å…³é”®å¸§é‡‡æ ·æ–¹æ³•ã€‚ç„¶è€Œï¼Œè¿™äº›ç¼–ç å™¨åœ¨é€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„å…³é”®å¸§æ—¶å¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œå¯¼è‡´æ¨¡å‹æ— æ³•æœ‰æ•ˆç†è§£è§†é¢‘å†…å®¹ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºï¼Œå…³é”®å¸§çš„é€‰æ‹©å¯èƒ½å¹¶éçœŸæ­£åŸºäºå¯¹è§†é¢‘å†…å®¹å’Œæ–‡æœ¬æŸ¥è¯¢çš„æ·±å…¥ç†è§£ï¼Œè€Œæ˜¯ä¾èµ–äºä¸€äº›å¯å‘å¼è§„åˆ™æˆ–ç®€å•çš„è§†è§‰ç‰¹å¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è®¾è®¡ä¸€ç³»åˆ—è¯Šæ–­å®éªŒï¼Œæ¥è¯„ä¼°ç°æœ‰è§†è§‰-è¯­è¨€ç¼–ç å™¨åœ¨å…³é”®å¸§é€‰æ‹©ä¸Šçš„èƒ½åŠ›ã€‚é€šè¿‡åˆ†ææ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸‹çš„è¡¨ç°ï¼Œæ­ç¤ºå…¶åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸Šçš„ä¸è¶³ï¼Œä»è€ŒéªŒè¯å…³é”®å¸§é€‰æ‹©æ–¹æ³•å­˜åœ¨å±€é™æ€§ã€‚è¿™ç§è¯Šæ–­æ–¹æ³•èƒ½å¤Ÿå¸®åŠ©ç ”ç©¶äººå‘˜æ›´å¥½åœ°ç†è§£æ¨¡å‹çš„è¡Œä¸ºï¼Œå¹¶ä¸ºæ”¹è¿›å…³é”®å¸§é€‰æ‹©ç­–ç•¥æä¾›æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡ä¸»è¦é€šè¿‡å®éªŒåˆ†ææ¥è¯Šæ–­ç°æœ‰æ¨¡å‹çš„ä¸è¶³ï¼Œå¹¶æ²¡æœ‰æå‡ºæ–°çš„æ¨¡å‹æ¶æ„ã€‚å…¶æŠ€æœ¯æ¡†æ¶å¯ä»¥æ¦‚æ‹¬ä¸ºï¼š1) é€‰æ‹©å…·æœ‰ä»£è¡¨æ€§çš„è§†é¢‘è¯­è¨€æ¨¡å‹å’Œè§†è§‰-è¯­è¨€ç¼–ç å™¨ï¼›2) è®¾è®¡ä¸€ç³»åˆ—é’ˆå¯¹æ€§çš„æµ‹è¯•ç”¨ä¾‹ï¼Œæ¶µç›–ä¸åŒçš„è§†é¢‘å†…å®¹å’Œæ–‡æœ¬æŸ¥è¯¢ï¼›3) åˆ†ææ¨¡å‹åœ¨è¿™äº›æµ‹è¯•ç”¨ä¾‹ä¸Šçš„è¡¨ç°ï¼Œè¯„ä¼°å…¶å…³é”®å¸§é€‰æ‹©çš„æœ‰æ•ˆæ€§ï¼›4) æ€»ç»“å®éªŒç»“æœï¼Œæ­ç¤ºæ¨¡å‹åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸Šçš„ä¸è¶³ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå…¶è¯Šæ–­æ–¹æ³•ï¼Œå®ƒæä¾›äº†ä¸€ç§ç³»ç»Ÿæ€§çš„æ–¹å¼æ¥è¯„ä¼°è§†é¢‘è¯­è¨€æ¨¡å‹åœ¨å…³é”®å¸§é€‰æ‹©ä¸Šçš„èƒ½åŠ›ã€‚é€šè¿‡è¿™ç§è¯Šæ–­ï¼Œç ”ç©¶äººå‘˜å¯ä»¥æ›´æ¸…æ™°åœ°äº†è§£æ¨¡å‹çš„ä¼˜ç‚¹å’Œä¸è¶³ï¼Œä»è€Œä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›æŒ‡å¯¼ã€‚ä¸ä»¥å¾€çš„ç ”ç©¶ä¸åŒï¼Œè¯¥è®ºæ–‡å¹¶æ²¡æœ‰ç›´æ¥æå‡ºæ–°çš„æ¨¡å‹æˆ–ç®—æ³•ï¼Œè€Œæ˜¯ä¸“æ³¨äºåˆ†æç°æœ‰æ¨¡å‹çš„è¡Œä¸ºï¼Œå¹¶æ­ç¤ºå…¶æ½œåœ¨çš„é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åœ¨äºæµ‹è¯•ç”¨ä¾‹çš„è®¾è®¡ï¼Œè¿™äº›ç”¨ä¾‹éœ€è¦èƒ½å¤Ÿæœ‰æ•ˆåœ°è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸‹çš„å…³é”®å¸§é€‰æ‹©èƒ½åŠ›ã€‚å…·ä½“çš„æµ‹è¯•ç”¨ä¾‹è®¾è®¡ç»†èŠ‚æœªçŸ¥ï¼Œä½†å¯ä»¥æ¨æµ‹å…¶ä¼šæ¶µç›–ä¸åŒçš„è§†é¢‘å†…å®¹ï¼ˆä¾‹å¦‚ï¼ŒåŠ¨ä½œã€åœºæ™¯ã€å¯¹è±¡ï¼‰å’Œæ–‡æœ¬æŸ¥è¯¢ï¼ˆä¾‹å¦‚ï¼Œæè¿°ã€é—®é¢˜ã€æŒ‡ä»¤ï¼‰ã€‚æ­¤å¤–ï¼Œè®ºæ–‡å¯èƒ½è¿˜ä¼šå…³æ³¨ä¸€äº›å…³é”®çš„å‚æ•°è®¾ç½®ï¼Œä¾‹å¦‚ï¼Œå…³é”®å¸§çš„æ•°é‡ã€é‡‡æ ·é¢‘ç‡ç­‰ï¼Œä»¥è¯„ä¼°è¿™äº›å‚æ•°å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®éªŒè¯æ˜ï¼Œç°æœ‰çš„è§†è§‰ç¼–ç å™¨åœ¨è¯†åˆ«è§†é¢‘ä¸­å…³é”®å¸§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•å‡†ç¡®æ•æ‰ä¸æ–‡æœ¬æŸ¥è¯¢ç›¸å…³çš„ä¿¡æ¯ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ”¹è¿›å…³é”®å¸§è¯†åˆ«æŠ€æœ¯å¯¹äºæå‡è§†é¢‘è¯­è¨€æ¨¡å‹çš„æ€§èƒ½è‡³å…³é‡è¦ã€‚è¯¥ç ”ç©¶ä¸ºæœªæ¥è§†é¢‘è¯­è¨€æ¨¡å‹çš„ç ”ç©¶æ–¹å‘æä¾›äº†æœ‰ä»·å€¼çš„æŒ‡å¯¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè§†é¢‘å†…å®¹ç†è§£ã€æ™ºèƒ½ç›‘æ§ã€è§†é¢‘æ£€ç´¢ã€è§†é¢‘æ‘˜è¦ç­‰é¢†åŸŸã€‚é€šè¿‡æ”¹è¿›å…³é”®å¸§é€‰æ‹©æŠ€æœ¯ï¼Œå¯ä»¥æå‡è§†é¢‘è¯­è¨€æ¨¡å‹åœ¨è¿™äº›åº”ç”¨ä¸­çš„æ€§èƒ½å’Œæ•ˆç‡ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥æ¢ç´¢æ›´æœ‰æ•ˆçš„æ³¨æ„åŠ›æœºåˆ¶å’Œå…³é”®å¸§é€‰æ‹©ç­–ç•¥ï¼Œä»è€Œå®ç°æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„è§†é¢‘ç†è§£ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in multimodal large language models (MLLMs) have led to much progress in video understanding tasks. To avoid the heavy computational cost of processing all frames, these models typically rely on keyframe sampling methods guided by vision-language encoders (\textit{e.g.,} SigLIP). However, it remains unclear whether such encoders can truly identify the most informative frames. In this work, we provide several empirical pieces of evidence revealing that popular vision encoders critically suffer from their limited capability to identify where the MLLM should look inside the video to handle the given textual query appropriately. Our findings suggest that the development of better keyframe identification techniques may be necessary for efficient video MLLMs.

