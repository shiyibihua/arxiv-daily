---
layout: default
title: Exploring Task-Solving Paradigm for Generalized Cross-Domain Face Anti-Spoofing via Reinforcement Fine-Tuning
---

# Exploring Task-Solving Paradigm for Generalized Cross-Domain Face Anti-Spoofing via Reinforcement Fine-Tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21895" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21895v1</a>
  <a href="https://arxiv.org/pdf/2506.21895.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21895v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21895v1', 'Exploring Task-Solving Paradigm for Generalized Cross-Domain Face Anti-Spoofing via Reinforcement Fine-Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fangling Jiang, Qi Li, Weining Wang, Gang Wang, Bing Liu, Zhenan Sun

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å¾®è°ƒçš„è·¨åŸŸäººè„¸åæ¬ºè¯ˆæ–¹æ³•ä»¥è§£å†³æ³›åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äººè„¸åæ¬ºè¯ˆ` `å¼ºåŒ–å­¦ä¹ ` `è·¨åŸŸæ³›åŒ–` `å¤šæ¨¡æ€å­¦ä¹ ` `å¯è§£é‡Šæ€§` `ä¼˜åŒ–ç­–ç•¥` `å†³ç­–è§„åˆ™`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„äººè„¸åæ¬ºè¯ˆæ–¹æ³•æ™®éå­˜åœ¨å¯¹è®­ç»ƒæ•°æ®çš„è¿‡åº¦è®°å¿†ï¼Œå¯¼è‡´åœ¨é¢å¯¹æœªçŸ¥æ”»å‡»æ—¶æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å¾®è°ƒçš„åæ¬ºè¯ˆæ–¹æ³•ï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è‡ªä¸»å­¦ä¹ è§£å†³ä»»åŠ¡ï¼Œé¿å…äº†å¯¹æ•°æ®æ¨¡å¼çš„å•ä¸€ä¾èµ–ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è·¨åŸŸäººè„¸åæ¬ºè¯ˆä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹å¤šæ ·åŒ–çš„æœªçŸ¥æ”»å‡»ç±»å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæ–°å‹å±•ç¤ºæ”»å‡»çš„å‡ºç°å¼•èµ·äº†äººè„¸åæ¬ºè¯ˆé¢†åŸŸçš„å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºè®­ç»ƒé›†ä¸­çš„æ•°æ®æ¨¡å¼ï¼Œå¯¼è‡´åœ¨ä¸åŒåœºæ™¯ä¸‹å¯¹æœªçŸ¥æ”»å‡»ç±»å‹çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ï¼Œä¸”å¯è§£é‡Šæ€§æœ‰é™ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å¾®è°ƒçš„äººè„¸åæ¬ºè¯ˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ¿€å‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿè‡ªä¸»æ€è€ƒå’Œå­¦ä¹ å¦‚ä½•è§£å†³åæ¬ºè¯ˆä»»åŠ¡ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–äºå¯¹çœŸå®æ€§æ¨¡å¼çš„è®°å¿†ã€‚é€šè¿‡è®¾è®¡å¯éªŒè¯çš„ç±»åˆ«ä¸€è‡´å¥–åŠ±å’Œæ¨ç†ä¸€è‡´å¥–åŠ±ï¼Œå¹¶é‡‡ç”¨åŸºäºGRPOçš„ä¼˜åŒ–ç­–ç•¥ï¼Œå¼•å¯¼æ¨¡å‹ä»å¤šä¸ªè§’åº¦æ¢ç´¢æ¨ç†ç­–ç•¥ä»¥æœ€å¤§åŒ–é¢„æœŸå¥–åŠ±ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è·¨åŸŸæ³›åŒ–æ€§èƒ½ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æœªçŸ¥æ”»å‡»ç±»å‹ï¼ŒåŒæ—¶æä¾›å¯è§£é‡Šçš„çœŸå®æ€§å†³ç­–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰åæ¬ºè¯ˆæ–¹æ³•åœ¨é¢å¯¹æœªçŸ¥æ”»å‡»ç±»å‹æ—¶çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºè®­ç»ƒé›†çš„è®°å¿†ï¼Œå¯¼è‡´åœ¨æ–°åœºæ™¯ä¸­çš„è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡å¼ºåŒ–å¾®è°ƒçš„æ–¹æ³•ï¼Œæ¿€å‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿè‡ªä¸»æ¢ç´¢å’Œå­¦ä¹ åæ¬ºè¯ˆä»»åŠ¡çš„è§£å†³ç­–ç•¥ï¼Œè€Œä¸æ˜¯ä»…ä¾èµ–äºè®°å¿†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¥–åŠ±è®¾è®¡æ¨¡å—å’Œä¼˜åŒ–ç­–ç•¥æ¨¡å—ã€‚å¥–åŠ±è®¾è®¡æ¨¡å—ä¸­åŒ…å«å¯éªŒè¯çš„ç±»åˆ«ä¸€è‡´å¥–åŠ±å’Œæ¨ç†ä¸€è‡´å¥–åŠ±ï¼Œä¼˜åŒ–ç­–ç•¥æ¨¡å—é‡‡ç”¨GRPOç­–ç•¥å¼•å¯¼æ¨¡å‹æ¢ç´¢å¤šæ ·çš„æ¨ç†ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡å¼ºåŒ–å­¦ä¹ çš„æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨å¤šç§è§†è§’ä¸‹è¿›è¡Œæ¨ç†æ¢ç´¢ï¼Œä»è€Œæå–å‡ºé«˜åº¦å¯æ³›åŒ–çš„å†³ç­–è§„åˆ™ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•çš„è®°å¿†æ€§æœ¬è´¨åŒºåˆ«æ˜æ˜¾ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œè®¾è®¡äº†ç‰¹å®šçš„å¥–åŠ±å‡½æ•°ä»¥å¼•å¯¼æ¨¡å‹å­¦ä¹ ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šé‡‡ç”¨äº†é€‚åˆå¤šæ¨¡æ€æ•°æ®å¤„ç†çš„æ¶æ„ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ•´åˆä¸åŒç±»å‹çš„ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨è·¨åŸŸäººè„¸åæ¬ºè¯ˆä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œèƒ½å¤Ÿåœ¨æœªè§ç›®æ ‡åŸŸä¸­å¯¹å¤šç§æœªçŸ¥æ”»å‡»ç±»å‹è¿›è¡Œæœ‰æ•ˆè¯†åˆ«ï¼Œæ˜¾è‘—æé«˜äº†æ³›åŒ–èƒ½åŠ›ï¼Œå…·ä½“æå‡å¹…åº¦è¶…è¿‡äº†ç°æœ‰åŸºçº¿æ–¹æ³•çš„20%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èå®‰å…¨ã€èº«ä»½éªŒè¯å’Œæ™ºèƒ½ç›‘æ§ç­‰åœºæ™¯ã€‚é€šè¿‡æé«˜äººè„¸åæ¬ºè¯ˆç³»ç»Ÿçš„æ³›åŒ–èƒ½åŠ›ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æ–°å‹æ”»å‡»ï¼Œæå‡å®‰å…¨æ€§å’Œç”¨æˆ·ä¿¡ä»»åº¦ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently the emergence of novel presentation attacks has drawn increasing attention to face anti-spoofing. However, existing methods tend to memorize data patterns from the training set, resulting in poor generalization to unknown attack types across different scenarios and limited interpretability. To address these challenges, this paper presents a reinforcement fine-tuning-based face anti-spoofing method that stimulates the capabilities of multimodal large language models to think and learn how to solve the anti-spoofing task itself, rather than relying on the memorization of authenticity patterns. We design verifiable class consistent reward and reasoning consistent reward, and employ a GRPO-based optimization strategy to guide the model in exploring reasoning policies from multiple perspectives to maximize expected rewards. As a result, through iterative trial-and-error learning while retaining only high-reward trajectories, the model distills highly generalizable decision-making rules from the extensive solution space to effectively address cross-domain face anti-spoofing tasks. Extensive experimental results demonstrate that our method achieves state-of-the-art cross-domain generalization performance. It generalizes well to diverse unknown attack types in unseen target domains while providing interpretable reasoning for its authenticity decisions without requiring labor-intensive textual annotations for training.

