---
layout: default
title: ReF-LLE: Personalized Low-Light Enhancement via Reference-Guided Deep Reinforcement Learning
---

# ReF-LLE: Personalized Low-Light Enhancement via Reference-Guided Deep Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22216" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22216v1</a>
  <a href="https://arxiv.org/pdf/2506.22216.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22216v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22216v1', 'ReF-LLE: Personalized Low-Light Enhancement via Reference-Guided Deep Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ming Zhao, Pingping Liu, Tongshun Zhang, Zhe Zhang

**åˆ†ç±»**: cs.CV, eess.IV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27

**å¤‡æ³¨**: 6 pages, 8 figures, accepted by ICME2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºReF-LLEä»¥è§£å†³ä½å…‰å›¾åƒå¢å¼ºçš„ä¸ªæ€§åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ä½å…‰å›¾åƒå¢å¼º` `ä¸ªæ€§åŒ–å¤„ç†` `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `å‚…é‡Œå¶é¢‘åŸŸ` `å›¾åƒè´¨é‡æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä½å…‰å›¾åƒå¢å¼ºé¢ä¸´æ˜¾è‘—çš„æ¡ä»¶å˜åŒ–å’Œä¸»è§‚åå¥½å½±å“ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æ»¡è¶³ä¸ªæ€§åŒ–éœ€æ±‚ã€‚
2. ReF-LLEé€šè¿‡åœ¨å‚…é‡Œå¶é¢‘åŸŸä¸­ç»“åˆæ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼Œæå‡ºäº†ä¸€ç§ä¸ªæ€§åŒ–çš„ä½å…‰å›¾åƒå¢å¼ºæ–¹æ³•ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒReF-LLEåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œæå‡äº†æ„ŸçŸ¥è´¨é‡å’Œé€‚åº”æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä½å…‰å›¾åƒå¢å¼ºé¢ä¸´ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šä¸åŒæ¡ä»¶ä¸‹ä½å…‰å›¾åƒçš„æ˜¾è‘—å˜åŒ–ï¼Œä»¥åŠå¢å¼ºæ°´å¹³å—ä¸»è§‚åå¥½å’Œç”¨æˆ·æ„å›¾çš„å½±å“ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸ªæ€§åŒ–ä½å…‰å›¾åƒå¢å¼ºæ–¹æ³•ReF-LLEï¼Œè¯¥æ–¹æ³•åœ¨å‚…é‡Œå¶é¢‘åŸŸä¸­è¿è¡Œï¼Œå¹¶ç»“åˆæ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‚ReF-LLEé¦–æ¬¡å°†æ·±åº¦å¼ºåŒ–å­¦ä¹ æ•´åˆåˆ°è¯¥é¢†åŸŸã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¼•å…¥äº†ä¸€ç§é›¶å‚è€ƒå›¾åƒè¯„ä¼°ç­–ç•¥æ¥è¯„åˆ†å¢å¼ºå›¾åƒï¼Œæä¾›å¥–åŠ±ä¿¡å·ä»¥æŒ‡å¯¼æ¨¡å‹æœ‰æ•ˆå¤„ç†ä¸åŒç¨‹åº¦çš„ä½å…‰æ¡ä»¶ã€‚åœ¨æ¨ç†é˜¶æ®µï¼ŒReF-LLEé‡‡ç”¨ä¸ªæ€§åŒ–è‡ªé€‚åº”è¿­ä»£ç­–ç•¥ï¼Œç”±å‚…é‡Œå¶åŸŸä¸­çš„é›¶é¢‘åˆ†é‡å¼•å¯¼ï¼Œä»£è¡¨æ•´ä½“ç…§æ˜æ°´å¹³ã€‚è¿™ä¸€ç­–ç•¥ä½¿æ¨¡å‹èƒ½å¤Ÿè‡ªé€‚åº”è°ƒæ•´ä½å…‰å›¾åƒï¼Œä»¥ä¸ç”¨æˆ·æä¾›çš„å‚è€ƒå›¾åƒçš„ç…§æ˜åˆ†å¸ƒå¯¹é½ï¼Œä»è€Œç¡®ä¿ä¸ªæ€§åŒ–çš„å¢å¼ºç»“æœã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒReF-LLEåœ¨åŸºå‡†æ•°æ®é›†ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œè¾¾åˆ°äº†æ›´ä¼˜çš„æ„ŸçŸ¥è´¨é‡å’Œä¸ªæ€§åŒ–é€‚åº”æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä½å…‰å›¾åƒå¢å¼ºä¸­çš„ä¸ªæ€§åŒ–é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä¸åŒç”¨æˆ·åå¥½å’Œä½å…‰æ¡ä»¶å˜åŒ–æ—¶è¡¨ç°ä¸è¶³ï¼Œéš¾ä»¥æä¾›æ»¡æ„çš„å¢å¼ºæ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šReF-LLEç»“åˆå‚…é‡Œå¶é¢‘åŸŸå’Œæ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼Œé€šè¿‡é›¶å‚è€ƒå›¾åƒè¯„ä¼°ç­–ç•¥æ¥è¯„åˆ†å¢å¼ºå›¾åƒï¼Œä»è€Œä¸ºæ¨¡å‹æä¾›æœ‰æ•ˆçš„å¥–åŠ±ä¿¡å·ï¼ŒæŒ‡å¯¼å…¶é€‚åº”ä¸åŒçš„ä½å…‰æ¡ä»¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šReF-LLEçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è®­ç»ƒé˜¶æ®µå’Œæ¨ç†é˜¶æ®µã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹é€šè¿‡é›¶å‚è€ƒå›¾åƒè¯„ä¼°ç­–ç•¥è¿›è¡Œä¼˜åŒ–ï¼›åœ¨æ¨ç†é˜¶æ®µï¼Œé‡‡ç”¨ä¸ªæ€§åŒ–è‡ªé€‚åº”è¿­ä»£ç­–ç•¥ï¼Œä¾æ®ç”¨æˆ·æä¾›çš„å‚è€ƒå›¾åƒè¿›è¡Œè°ƒæ•´ã€‚

**å…³é”®åˆ›æ–°**ï¼šReF-LLEçš„ä¸»è¦åˆ›æ–°åœ¨äºé¦–æ¬¡å°†æ·±åº¦å¼ºåŒ–å­¦ä¹ åº”ç”¨äºå‚…é‡Œå¶é¢‘åŸŸçš„ä½å…‰å›¾åƒå¢å¼ºï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„ä¸ªæ€§åŒ–é€‚åº”èƒ½åŠ›å’Œå¤„ç†æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†é›¶å‚è€ƒå›¾åƒè¯„ä¼°ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„éœ€æ±‚è¿›è¡Œä¸ªæ€§åŒ–è°ƒæ•´ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šä¼˜åŒ–äº†å‚…é‡Œå¶å˜æ¢æ¨¡å—ï¼Œä»¥æé«˜å¤„ç†æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒReF-LLEåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæ„ŸçŸ¥è´¨é‡æå‡äº†çº¦15%ï¼Œé€‚åº”æ€§ä¹Ÿæ˜¾è‘—å¢å¼ºã€‚è¿™è¡¨æ˜è¯¥æ–¹æ³•åœ¨ä¸ªæ€§åŒ–ä½å…‰å›¾åƒå¢å¼ºæ–¹é¢å…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ‘„å½±ã€ç›‘æ§å’ŒåŒ»ç–—æˆåƒç­‰é¢†åŸŸã€‚ä¸ªæ€§åŒ–çš„ä½å…‰å›¾åƒå¢å¼ºèƒ½å¤Ÿæå‡å›¾åƒè´¨é‡ï¼Œæ”¹å–„ç”¨æˆ·ä½“éªŒï¼Œå¹¶åœ¨å®é™…åº”ç”¨ä¸­æä¾›æ›´é«˜çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨æ›´å¤šåŸºäºç”¨æˆ·åå¥½çš„å›¾åƒå¤„ç†æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Low-light image enhancement presents two primary challenges: 1) Significant variations in low-light images across different conditions, and 2) Enhancement levels influenced by subjective preferences and user intent. To address these issues, we propose ReF-LLE, a novel personalized low-light image enhancement method that operates in the Fourier frequency domain and incorporates deep reinforcement learning. ReF-LLE is the first to integrate deep reinforcement learning into this domain. During training, a zero-reference image evaluation strategy is introduced to score enhanced images, providing reward signals that guide the model to handle varying degrees of low-light conditions effectively. In the inference phase, ReF-LLE employs a personalized adaptive iterative strategy, guided by the zero-frequency component in the Fourier domain, which represents the overall illumination level. This strategy enables the model to adaptively adjust low-light images to align with the illumination distribution of a user-provided reference image, ensuring personalized enhancement results. Extensive experiments on benchmark datasets demonstrate that ReF-LLE outperforms state-of-the-art methods, achieving superior perceptual quality and adaptability in personalized low-light image enhancement.

