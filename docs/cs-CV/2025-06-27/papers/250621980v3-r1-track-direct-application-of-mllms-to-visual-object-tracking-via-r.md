---
layout: default
title: R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning
---

# R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21980" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.21980v3</a>
  <a href="https://arxiv.org/pdf/2506.21980.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21980v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21980v3', 'R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Biao Wang, Wenwen Li, Jiawei Ge

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-27 (Êõ¥Êñ∞: 2025-07-22)

**Â§áÊ≥®**: 7 pages, 2 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫R1-Track‰ª•Ëß£ÂÜ≥ËßÜËßâÁõÆÊ†áË∑üË∏™‰∏≠ÁöÑÊ®°ÊùøÂåπÈÖçÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâÁõÆÊ†áË∑üË∏™` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `Âº∫ÂåñÂ≠¶‰π†` `Ê®°ÊùøÂåπÈÖç` `Ê®°ÂûãÂæÆË∞É`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑËßÜËßâÁõÆÊ†áË∑üË∏™ÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÊ®°ÊùøÂåπÈÖçÔºåÁº∫‰πèÁÅµÊ¥ªÊÄß‰∏îÈúÄË¶ÅÂ§ßÈáèÊ†áÊ≥®Êï∞ÊçÆËøõË°åËÆ≠ÁªÉ„ÄÇ
2. Êú¨ÊñáÊèêÂá∫R1-TrackÔºåÈÄöËøáÂæÆË∞ÉQwen2.5-VLÊ®°ÂûãÔºåÁªìÂêàGRPOÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåËß£ÂÜ≥‰∫ÜÊ®°ÊùøÂåπÈÖçÁöÑ‰∏çË∂≥„ÄÇ
3. R1-TrackÂú®GOT-10kÂü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÊîØÊåÅÈÄöËøáËæπÁïåÊ°ÜÊàñÊñáÊú¨ÊèèËø∞ËøõË°åÁÅµÊ¥ªÂàùÂßãÂåñ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâÂçïÁõÆÊ†áË∑üË∏™Êó®Âú®Ê†πÊçÆÁ¨¨‰∏ÄÂ∏ß‰∏≠ÁöÑÂàùÂßãÁä∂ÊÄÅÔºåÂú®ÂêéÁª≠ËßÜÈ¢ëÂ∏ß‰∏≠ÊåÅÁª≠ÂÆö‰ΩçÂíå‰º∞ËÆ°ÁõÆÊ†áÁöÑÂ∞∫Â∫¶„ÄÇ‰º†ÁªüÊñπÊ≥ïÈÄöÂ∏∏Â∞ÜÂÖ∂ËßÜ‰∏∫Ê®°ÊùøÂåπÈÖçÈóÆÈ¢òÔºåÁªèÂéÜ‰∫ÜÁõ∏ÂÖ≥Êª§Ê≥¢Âô®„ÄÅÂèåÊµÅÁΩëÁªúÂíåÂçïÊµÅÁΩëÁªúÁ≠âÂ§ö‰∏™Èò∂ÊÆµÔºåÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ï„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÊòéÁ°ÆÁöÑÂàÜÁ±ªÂíåÂõûÂΩíÂª∫Ê®°Ôºå‰æùËµñ‰∫éÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÁöÑÁõëÁù£ËÆ≠ÁªÉÔºåÂπ∂‰∏î‰ªÖÈôê‰∫éÂçï‰∏ÄÁöÑË∑üË∏™‰ªªÂä°ÔºåÁº∫‰πèÁÅµÊ¥ªÊÄß„ÄÇËøëÂπ¥Êù•ÔºåÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâËøÖÈÄüÂèëÂ±ïÔºåÂºÄÊ∫êÊ®°ÂûãÂ¶ÇQwen2.5-VLÂú®Âü∫Á°ÄËÉΩÂäõ‰∏äË°®Áé∞Âá∫Ëâ≤ÔºåÊøÄÂèë‰∫ÜÂ∞ÜÂÖ∂Áõ¥Êé•Â∫îÁî®‰∫éËßÜËßâË∑üË∏™ÁöÑÂÖ¥Ë∂£„ÄÇÊú¨ÊñáÊèêÂá∫ÁöÑR1-TrackÊ®°ÂûãÈÄöËøáÂØπQwen2.5-VLËøõË°åÂæÆË∞ÉÔºåÈááÁî®Âü∫‰∫éËßÑÂàôÁöÑÂ•ñÂä±ÂáΩÊï∞ÂíåÁæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåÂú®GOT-10kÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ËßÜËßâÁõÆÊ†áË∑üË∏™‰∏≠ÁöÑÊ®°ÊùøÂåπÈÖçÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ÁÅµÊ¥ªÊÄßÂíåÊï∞ÊçÆ‰æùËµñÊÄßÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®Âú∫ÊôØ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫R1-TrackÊ®°ÂûãÔºåÈÄöËøáÂæÆË∞ÉQwen2.5-VLÔºåÂà©Áî®Âº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÊù•‰ºòÂåñË∑üË∏™ÊÄßËÉΩÔºåÊó®Âú®ÂÖãÊúç‰º†ÁªüÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöR1-TrackÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ„ÄÅÊ®°ÂûãÂæÆË∞ÉÂíåË∑üË∏™Èò∂ÊÆµ„ÄÇÈ¶ñÂÖàÔºåÂà©Áî®Â∞èËßÑÊ®°Êï∞ÊçÆÈõÜËøõË°åÊ®°ÂûãÁöÑÂæÆË∞ÉÔºåÁÑ∂ÂêéÈÄöËøáÂº∫ÂåñÂ≠¶‰π†‰ºòÂåñË∑üË∏™Á≠ñÁï•ÔºåÊúÄÂêéÂú®ËßÜÈ¢ëÂ∏ß‰∏≠ËøõË°åÁõÆÊ†áÂÆö‰ΩçÂíåÂ∞∫Â∫¶‰º∞ËÆ°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöR1-TrackÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂ∞ÜÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁõ¥Êé•Â∫îÁî®‰∫éËßÜËßâË∑üË∏™‰ªªÂä°ÔºåÁ™ÅÁ†¥‰∫Ü‰º†ÁªüÊñπÊ≥ïÂØπÊ®°ÊùøÂåπÈÖçÁöÑ‰æùËµñÔºåÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÁÅµÊ¥ªÊÄßÂíåÈÄÇÂ∫îÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãÂæÆË∞ÉËøáÁ®ã‰∏≠ÔºåÈááÁî®‰∫ÜÂü∫‰∫éËßÑÂàôÁöÑÂ•ñÂä±ÂáΩÊï∞ÔºåÂπ∂‰ΩøÁî®Áæ§‰ΩìÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÔºàGRPOÔºâÊñπÊ≥ïÔºåÁ°Æ‰øùÊ®°ÂûãÂú®Â∞èËßÑÊ®°Êï∞ÊçÆÈõÜ‰∏äÊúâÊïàÂ≠¶‰π†Ë∑üË∏™Á≠ñÁï•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®GOT-10kÂü∫ÂáÜÊµãËØï‰∏≠ÔºåR1-TrackÊ®°ÂûãË°®Áé∞Âá∫Ëâ≤ÔºåÁõ∏ËæÉ‰∫é‰º†ÁªüÊñπÊ≥ïÔºåË∑üË∏™Á≤æÂ∫¶ÊòæËëóÊèêÂçáÔºåÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÂ∞öÊú™ÂÖ¨ÂºÄÔºå‰ΩÜÂÆûÈ™åÁªìÊûúË°®ÊòéÂÖ∂Âú®Â§öÁßçË∑üË∏™Âú∫ÊôØ‰∏≠ÂùáËÉΩ‰øùÊåÅÈ´òÊïàÁ®≥ÂÆöÁöÑË°®Áé∞„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

R1-TrackÊ®°ÂûãÂú®ËßÜÈ¢ëÁõëÊéß„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊó†‰∫∫Êú∫Ë∑üË∏™Á≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÂÖ∂ÁÅµÊ¥ªÁöÑÂàùÂßãÂåñÊñπÂºèÂíå‰ºòÁßÄÁöÑË∑üË∏™ÊÄßËÉΩÔºå‰ΩøÂÖ∂ËÉΩÂ§üÈÄÇÂ∫îÂ§öÁßçÂ§çÊùÇÂú∫ÊôØÔºåÊèêÂçáÁõÆÊ†áË∑üË∏™ÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéá„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Visual single object tracking aims to continuously localize and estimate the scale of a target in subsequent video frames, given only its initial state in the first frame. This task has traditionally been framed as a template matching problem, evolving through major phases including correlation filters, two-stream networks, and one-stream networks with significant progress achieved. However, these methods typically require explicit classification and regression modeling, depend on supervised training with large-scale datasets, and are limited to the single task of tracking, lacking flexibility. In recent years, multi-modal large language models (MLLMs) have advanced rapidly. Open-source models like Qwen2.5-VL, a flagship MLLMs with strong foundational capabilities, demonstrate excellent performance in grounding tasks. This has spurred interest in applying such models directly to visual tracking. However, experiments reveal that Qwen2.5-VL struggles with template matching between image pairs (i.e., tracking tasks). Inspired by deepseek-R1, we fine-tuned Qwen2.5-VL using the group relative policy optimization (GRPO) reinforcement learning method on a small-scale dataset with a rule-based reward function. The resulting model, R1-Track, achieved notable performance on the GOT-10k benchmark. R1-Track supports flexible initialization via bounding boxes or text descriptions while retaining most of the original model's general capabilities. And we further discuss potential improvements for R1-Track. This rough technical report summarizes our findings as of May 2025.

