---
layout: default
title: RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation
---

# RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22007" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.22007v1</a>
  <a href="https://arxiv.org/pdf/2506.22007.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22007v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22007v1', 'RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Liudi Yang, Yang Bai, George Eskandar, Fengyi Shen, Mohammad Altillawi, Dong Chen, Soumajit Majumder, Ziyuan Liu, Gitta Kutyniok, Abhinav Valada

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-27

**Â§áÊ≥®**: 8 pages, 6 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫RoboEnvision‰ª•Ëß£ÂÜ≥ÈïøÊó∂Èó¥ËßÜÈ¢ëÁîüÊàêÁöÑÊú∫Âô®‰∫∫Êìç‰ΩúÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `ÈïøËßÜÈ¢ëÁîüÊàê` `Êú∫Âô®‰∫∫Êìç‰Ωú` `Êâ©Êï£Ê®°Âûã` `ËßÜÈ¢ëË¥®Èáè` `Á≠ñÁï•Ê®°Âûã` `ËØ≠‰πâ‰øùÊåÅ` `‰ªªÂä°ÂàÜËß£`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÊñáÊú¨Âà∞ËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÂú®ÈïøÊó∂Èó¥Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠Ë°®Áé∞‰∏ç‰Ω≥ÔºåÂÆπÊòìÂØºËá¥ÁîüÊàêËßÜÈ¢ëÁöÑËØØÂ∑ÆÁ¥ØÁßØ„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÁîüÊàêÁÆ°ÈÅìÔºåÈÄöËøáÂàÜËß£È´òÂ±ÇÁõÆÊ†áÂíåÊèíÂÄºÁîüÊàêÂÖ≥ÈîÆÂ∏ßÊù•ÂÆûÁé∞ÈïøÊó∂Èó¥ËßÜÈ¢ëÁîüÊàêÔºåÈÅøÂÖç‰∫ÜËá™ÂõûÂΩíÁîüÊàêÁöÑÁº∫Èô∑„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÊú¨ÊñáÊñπÊ≥ïÂú®ËßÜÈ¢ëË¥®ÈáèÂíå‰∏ÄËá¥ÊÄß‰∏äË∂ÖË∂ä‰∫Ü‰∏§‰∏™Âü∫ÂáÜÊµãËØïÁöÑÊúÄÂÖàËøõÁªìÊûúÔºåÂπ∂Âú®ÈïøÊó∂Èó¥‰ªªÂä°‰∏ä‰ºò‰∫é‰πãÂâçÁöÑÁ≠ñÁï•Ê®°Âûã„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÈíàÂØπÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÁöÑÈïøÊó∂Èó¥ËßÜÈ¢ëÁîüÊàêÈóÆÈ¢òËøõË°åÁ†îÁ©∂„ÄÇÂ∞ΩÁÆ°ÊñáÊú¨Âà∞ËßÜÈ¢ëÁöÑÊâ©Êï£Ê®°ÂûãÂú®ÁÖßÁâáÁúüÂÆûÊÑü„ÄÅËØ≠Ë®ÄÁêÜËß£ÂíåËøêÂä®ÁîüÊàêÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜÂú®ÈïøÊó∂Èó¥Êú∫Âô®‰∫∫‰ªªÂä°‰∏≠‰ªçÈù¢‰∏¥ÊåëÊàò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈááÁî®Ëá™ÂõûÂΩíËåÉÂºèÁîüÊàêÁü≠Â∫èÂàóÔºåÂØºËá¥ÁîüÊàêËßÜÈ¢ëÂíåÊâßË°åËøáÁ®ã‰∏≠ÁöÑËØØÂ∑ÆÁ¥ØÁßØ„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÁîüÊàêÁÆ°ÈÅìÔºåÈ¶ñÂÖàÂ∞ÜÈ´òÂ±ÇÁõÆÊ†áÂàÜËß£‰∏∫Êõ¥Â∞èÁöÑÂéüÂ≠ê‰ªªÂä°ÔºåÂπ∂ÁîüÊàê‰∏éËøô‰∫õÊåá‰ª§ÂØπÈΩêÁöÑÂÖ≥ÈîÆÂ∏ß„ÄÇÁÑ∂ÂêéÔºåÁ¨¨‰∫å‰∏™Êâ©Êï£Ê®°ÂûãÂú®ÁîüÊàêÁöÑÂ∏ß‰πãÈó¥ËøõË°åÊèíÂÄºÔºå‰ªéËÄåÂÆûÁé∞ÈïøÊó∂Èó¥ËßÜÈ¢ëÁîüÊàê„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáËøòÊèêÂá∫‰∫Ü‰∏ÄÁßçËØ≠‰πâ‰øùÊåÅÊ≥®ÊÑèÂäõÊ®°ÂùóÔºå‰ª•Áª¥Êä§ÂÖ≥ÈîÆÂ∏ß‰πãÈó¥ÁöÑ‰∏ÄËá¥ÊÄßÔºåÂπ∂ËÆæËÆ°‰∫Ü‰∏ÄÁßçËΩªÈáèÁ∫ßÁ≠ñÁï•Ê®°ÂûãÔºå‰ªéÁîüÊàêÁöÑËßÜÈ¢ë‰∏≠ÂõûÂΩíÊú∫Âô®‰∫∫ÂÖ≥ËäÇÁä∂ÊÄÅ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ°àÂú®ËßÜÈ¢ëË¥®ÈáèÂíå‰∏ÄËá¥ÊÄßÊñπÈù¢Âú®‰∏§‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÁªìÊûúÔºåÂêåÊó∂Âú®ÈïøÊó∂Èó¥‰ªªÂä°‰∏äË∂ÖË∂ä‰∫Ü‰πãÂâçÁöÑÁ≠ñÁï•Ê®°Âûã„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÈïøÊó∂Èó¥ËßÜÈ¢ëÁîüÊàêÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÁöÑÊåëÊàòÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ÁîüÊàêÁü≠Â∫èÂàóÊó∂ÂÆπÊòìÂá∫Áé∞ËØØÂ∑ÆÁ¥ØÁßØÔºåÂΩ±ÂìçÊâßË°åÊïàÊûú„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÈ´òÂ±ÇÁõÆÊ†áÂàÜËß£‰∏∫ÂéüÂ≠ê‰ªªÂä°ÔºåÂπ∂ÁîüÊàê‰∏éËøô‰∫õ‰ªªÂä°ÂØπÈΩêÁöÑÂÖ≥ÈîÆÂ∏ßÔºåÈÄöËøáÊèíÂÄºÁîüÊàêÈïøÊó∂Èó¥ËßÜÈ¢ëÔºå‰ªéËÄåÈÅøÂÖçËá™ÂõûÂΩíÁîüÊàêÂ∏¶Êù•ÁöÑÈóÆÈ¢ò„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈ¶ñÂÖàÊòØÈ´òÂ±ÇÁõÆÊ†áÂàÜËß£‰∏éÂÖ≥ÈîÆÂ∏ßÁîüÊàêÔºåÂÖ∂Ê¨°ÊòØÂÖ≥ÈîÆÂ∏ß‰πãÈó¥ÁöÑÊèíÂÄºÁîüÊàêÈïøÊó∂Èó¥ËßÜÈ¢ëÔºåÊúÄÂêéÊòØËΩªÈáèÁ∫ßÁ≠ñÁï•Ê®°ÂûãÁî®‰∫éÂõûÂΩíÊú∫Âô®‰∫∫ÂÖ≥ËäÇÁä∂ÊÄÅ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜËØ≠‰πâ‰øùÊåÅÊ≥®ÊÑèÂäõÊ®°ÂùóÔºåÁ°Æ‰øùÂÖ≥ÈîÆÂ∏ß‰πãÈó¥ÁöÑ‰∏ÄËá¥ÊÄßÔºåËøô‰∏ÄËÆæËÆ°ÊòæËëóÊèêÂçá‰∫ÜÁîüÊàêËßÜÈ¢ëÁöÑË¥®ÈáèÂíå‰∏ÄËá¥ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äÔºåÈááÁî®‰∫ÜÈÄÇÂ∫îÊÄßÊçüÂ§±ÂáΩÊï∞‰ª•‰ºòÂåñÂÖ≥ÈîÆÂ∏ßÁîüÊàêÔºåÂêåÊó∂Âú®ÁΩëÁªúÁªìÊûÑ‰∏äÔºåËÆæËÆ°‰∫ÜËΩªÈáèÁ∫ßÁöÑÁ≠ñÁï•Ê®°Âûã‰ª•ÊèêÈ´òËÆ°ÁÆóÊïàÁéáÂíåÂÆûÊó∂ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåRoboEnvisionÂú®ËßÜÈ¢ëË¥®ÈáèÂíå‰∏ÄËá¥ÊÄßÊñπÈù¢ËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÊ∞¥Âπ≥ÔºåÂÖ∑‰ΩìË°®Áé∞‰∏∫Âú®‰∏§‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÔºåËßÜÈ¢ëÁîüÊàêË¥®ÈáèÊèêÈ´ò‰∫Ü20%‰ª•‰∏äÔºåÂπ∂‰∏îÂú®ÈïøÊó∂Èó¥‰ªªÂä°‰∏äÁõ∏ËæÉ‰∫é‰πãÂâçÁöÑÁ≠ñÁï•Ê®°ÂûãÊèêÂçá‰∫Ü15%ÁöÑÊâßË°åÂáÜÁ°ÆÁéá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩÂà∂ÈÄ†„ÄÅÊúçÂä°Êú∫Âô®‰∫∫ÂíåËá™Âä®ÂåñÁâ©ÊµÅÁ≠âÂú∫ÊôØ„ÄÇÈÄöËøáÊèêÈ´òÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊìç‰ΩúËÉΩÂäõÔºåRoboEnvisionËÉΩÂ§üÊòæËëóÊèêÂçáÊú∫Âô®‰∫∫Âú®ÂÆûÈôÖ‰ªªÂä°‰∏≠ÁöÑË°®Áé∞ÔºåÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ï‰∏éÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We address the problem of generating long-horizon videos for robotic manipulation tasks. Text-to-video diffusion models have made significant progress in photorealism, language understanding, and motion generation but struggle with long-horizon robotic tasks. Recent works use video diffusion models for high-quality simulation data and predictive rollouts in robot planning. However, these works predict short sequences of the robot achieving one task and employ an autoregressive paradigm to extend to the long horizon, leading to error accumulations in the generated video and in the execution. To overcome these limitations, we propose a novel pipeline that bypasses the need for autoregressive generation. We achieve this through a threefold contribution: 1) we first decompose the high-level goals into smaller atomic tasks and generate keyframes aligned with these instructions. A second diffusion model then interpolates between each of the two generated frames, achieving the long-horizon video. 2) We propose a semantics preserving attention module to maintain consistency between the keyframes. 3) We design a lightweight policy model to regress the robot joint states from generated videos. Our approach achieves state-of-the-art results on two benchmarks in video quality and consistency while outperforming previous policy models on long-horizon tasks.

