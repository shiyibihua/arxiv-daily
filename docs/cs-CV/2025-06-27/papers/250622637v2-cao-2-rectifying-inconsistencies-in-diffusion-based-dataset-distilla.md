---
layout: default
title: CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation
---

# CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22637" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22637v2</a>
  <a href="https://arxiv.org/pdf/2506.22637.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22637v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22637v2', 'CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haoxuan Wang, Zhenghao Zhao, Junyi Wu, Yuzhang Shang, Gaowen Liu, Yan Yan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27 (æ›´æ–°: 2025-07-09)

**å¤‡æ³¨**: ICCV 2025. Code is available at https://github.com/hatchetProject/CaO2

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCaO$_2$ä»¥è§£å†³æ‰©æ•£æ¨¡å‹æ•°æ®è’¸é¦ä¸­çš„ä¸ä¸€è‡´æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡å‹` `æ•°æ®è’¸é¦` `æ¡ä»¶æ„ŸçŸ¥ä¼˜åŒ–` `ç›®æ ‡å¼•å¯¼é‡‡æ ·` `è®¡ç®—æœºè§†è§‰` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ‰©æ•£æ¨¡å‹æ•°æ®è’¸é¦æ–¹æ³•å­˜åœ¨ç›®æ ‡ä¸ä¸€è‡´æ€§å’Œæ¡ä»¶ä¸ä¸€è‡´æ€§ï¼Œå¯¼è‡´ç”Ÿæˆå›¾åƒä¸è¯„ä¼°ç›®æ ‡ä¸åŒ¹é…ã€‚
2. æœ¬æ–‡æå‡ºçš„CaO$_2$æ¡†æ¶é€šè¿‡æ¡ä»¶æ„ŸçŸ¥ä¼˜åŒ–å’Œç›®æ ‡å¼•å¯¼é‡‡æ ·ï¼Œè§£å†³äº†è’¸é¦è¿‡ç¨‹ä¸­çš„ä¸ä¸€è‡´æ€§é—®é¢˜ã€‚
3. CaO$_2$åœ¨ImageNetåŠå…¶å­é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå¹³å‡æå‡äº†2.3%çš„å‡†ç¡®ç‡ï¼Œè¶…è¶Šäº†æœ€ä½³åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ€è¿‘æ‰©æ•£æ¨¡å‹åœ¨æ•°æ®é›†è’¸é¦ä¸­çš„åº”ç”¨å±•ç°äº†åœ¨åˆ›å»ºç´§å‡‘çš„æ›¿ä»£æ•°æ®é›†æ–¹é¢çš„æ½œåŠ›ï¼Œè¾ƒä¼ ç»Ÿçš„ä¼˜åŒ–æ–¹æ³•å…·æœ‰æ›´é«˜çš„æ•ˆç‡å’Œæ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ‰©æ•£æ¨¡å‹æ•°æ®è’¸é¦æ–¹æ³•å¿½è§†äº†è¯„ä¼°è¿‡ç¨‹ï¼Œå¹¶åœ¨è’¸é¦è¿‡ç¨‹ä¸­å­˜åœ¨ä¸¤ç§å…³é”®ä¸ä¸€è‡´æ€§ï¼šç›®æ ‡ä¸ä¸€è‡´æ€§å’Œæ¡ä»¶ä¸ä¸€è‡´æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†æ¡ä»¶æ„ŸçŸ¥ä¼˜åŒ–ä¸ç›®æ ‡å¼•å¯¼é‡‡æ ·ï¼ˆCaO$_2$ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼Œæ—¨åœ¨å°†è’¸é¦è¿‡ç¨‹ä¸è¯„ä¼°ç›®æ ‡å¯¹é½ã€‚CaO$_2$åœ¨ImageNetåŠå…¶å­é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹³å‡æé«˜äº†2.3%çš„å‡†ç¡®ç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ‰©æ•£æ¨¡å‹æ•°æ®è’¸é¦ä¸­çš„ç›®æ ‡ä¸ä¸€è‡´æ€§å’Œæ¡ä»¶ä¸ä¸€è‡´æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è’¸é¦è¿‡ç¨‹ä¸­æœªèƒ½æœ‰æ•ˆå¯¹é½ç”Ÿæˆå›¾åƒä¸è¯„ä¼°ç›®æ ‡ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCaO$_2$æ¡†æ¶é€šè¿‡å¼•å…¥æ¡ä»¶æ„ŸçŸ¥ä¼˜åŒ–ä¸ç›®æ ‡å¼•å¯¼é‡‡æ ·ï¼Œç¡®ä¿è’¸é¦è¿‡ç¨‹ä¸è¯„ä¼°ç›®æ ‡ä¸€è‡´ï¼Œä»è€Œæé«˜ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µé‡‡ç”¨æ¦‚ç‡å¼•å¯¼çš„æ ·æœ¬é€‰æ‹©ç®¡é“ï¼Œç¬¬äºŒé˜¶æ®µåˆ™å¯¹ç›¸åº”çš„æ½œåœ¨è¡¨ç¤ºè¿›è¡Œç²¾ç»†åŒ–å¤„ç†ï¼Œä»¥æé«˜æ¡ä»¶ä¼¼ç„¶æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šCaO$_2$çš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ä¸¤é˜¶æ®µçš„ä¼˜åŒ–ç­–ç•¥ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡æ¡ä»¶æ„ŸçŸ¥ä¼˜åŒ–æ¥è§£å†³ç°æœ‰æ–¹æ³•ä¸­çš„ä¸ä¸€è‡´æ€§é—®é¢˜ï¼Œè¿™åœ¨ä¼ ç»Ÿçš„å•é˜¶æ®µæ–¹æ³•ä¸­å¹¶æœªå®ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ ·æœ¬é€‰æ‹©è¿‡ç¨‹ä¸­ï¼ŒCaO$_2$ä½¿ç”¨æ¦‚ç‡ä¿¡æ¯æ¥æŒ‡å¯¼æ ·æœ¬çš„é€‰æ‹©ï¼ŒåŒæ—¶åœ¨æ½œåœ¨è¡¨ç¤ºçš„ç²¾ç»†åŒ–é˜¶æ®µï¼Œé‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¡ä»¶ä¼¼ç„¶æ€§ï¼Œç¡®ä¿ç”Ÿæˆå›¾åƒä¸æ¡ä»¶çš„ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CaO$_2$åœ¨ImageNetåŠå…¶å­é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹³å‡æé«˜äº†2.3%çš„å‡†ç¡®ç‡ï¼Œè¶…è¶Šäº†ç°æœ‰æœ€ä½³åŸºçº¿ã€‚è¿™ä¸€ç»“æœå±•ç¤ºäº†å…¶åœ¨æ•°æ®è’¸é¦é¢†åŸŸçš„æœ‰æ•ˆæ€§å’Œåˆ›æ–°æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ä¸­çš„å›¾åƒç”Ÿæˆã€æ•°æ®é›†ä¼˜åŒ–ä»¥åŠæœºå™¨å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒã€‚é€šè¿‡æä¾›æ›´é«˜æ•ˆçš„æ•°æ®è’¸é¦æ–¹æ³•ï¼ŒCaO$_2$èƒ½å¤Ÿåœ¨å¤§è§„æ¨¡æ•°æ®é›†çš„å¤„ç†ä¸Šæ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The recent introduction of diffusion models in dataset distillation has shown promising potential in creating compact surrogate datasets for large, high-resolution target datasets, offering improved efficiency and performance over traditional bi-level/uni-level optimization methods. However, current diffusion-based dataset distillation approaches overlook the evaluation process and exhibit two critical inconsistencies in the distillation process: (1) Objective Inconsistency, where the distillation process diverges from the evaluation objective, and (2) Condition Inconsistency, leading to mismatches between generated images and their corresponding conditions. To resolve these issues, we introduce Condition-aware Optimization with Objective-guided Sampling (CaO$_2$), a two-stage diffusion-based framework that aligns the distillation process with the evaluation objective. The first stage employs a probability-informed sample selection pipeline, while the second stage refines the corresponding latent representations to improve conditional likelihood. CaO$_2$ achieves state-of-the-art performance on ImageNet and its subsets, surpassing the best-performing baselines by an average of 2.3% accuracy.

