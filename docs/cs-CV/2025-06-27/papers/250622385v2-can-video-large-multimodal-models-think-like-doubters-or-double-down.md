---
layout: default
title: Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment
---

# Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22385" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22385v2</a>
  <a href="https://arxiv.org/pdf/2506.22385.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22385v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22385v2', 'Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yue Zhang, Jilei Sun, Yunhui Guo, Vibhav Gogate

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27 (æ›´æ–°: 2025-10-07)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯å¦å®šè§†é¢‘è•´å«ä»»åŠ¡ä»¥æå‡è§†é¢‘å¤šæ¨¡æ€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘ç†è§£` `å¤šæ¨¡æ€æ¨¡å‹` `åŠ¨æ€æ¨ç†` `åäº‹å®æ€ç»´` `ç”Ÿæˆä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†é¢‘å¤šæ¨¡æ€æ¨¡å‹åœ¨é¢å¯¹æ–°ä¿¡æ¯æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆæ›´æ–°å…¶æ¨ç†ï¼Œå¯¼è‡´æ¨ç†ç»“æœçš„å±€é™æ€§ã€‚
2. æœ¬æ–‡æå‡ºå¯å¦å®šè§†é¢‘è•´å«ï¼ˆDVidEï¼‰ä»»åŠ¡ï¼Œè¦æ±‚æ¨¡å‹åœ¨æ–°è¯æ®å‡ºç°æ—¶ï¼ŒåŠ¨æ€è°ƒæ•´å…¶æ¨ç†ç»“æœï¼Œå¢å¼ºæ¨ç†çš„é€‚åº”æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨åŠ¨æ€æ¨ç†èƒ½åŠ›ä¸Šæ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†åäº‹å®æ€ç»´å’Œç”Ÿæˆæ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†é¢‘å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆVLMMsï¼‰åœ¨ç†è§£è§†é¢‘å†…å®¹æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨æŠ½è±¡å’Œé€‚åº”æ€§æ¨ç†æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡å¼•å…¥äº†å¯å¦å®šè§†é¢‘è•´å«ï¼ˆDVidEï¼‰ä»»åŠ¡ï¼Œè¦æ±‚æ¨¡å‹æ ¹æ®æ–°è¯æ®ä¸æ–­æ›´æ–°æ¨ç†ã€‚æ¨¡å‹éœ€åˆ¤æ–­æ–°ä¿¡æ¯æ˜¯åŠ å¼ºè¿˜æ˜¯å‰Šå¼±å‡è®¾ï¼Œæˆ–ç”Ÿæˆä¸ä¹‹ç›¸å…³çš„æ›´æ–°ã€‚æˆ‘ä»¬æå‡ºäº†åäº‹å®æ€ç»´é“¾æ¡†æ¶å’Œç»“åˆASRè¾“å‡ºä¸å¤§å‹è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆæ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†VLMMsçš„åŠ¨æ€æ¨ç†èƒ½åŠ›ï¼Œå¹¶æ„å»ºäº†æ–°çš„åŸºå‡†æ•°æ®é›†ä»¥è¯„ä¼°ç”Ÿæˆæ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è§†é¢‘å¤šæ¨¡æ€æ¨¡å‹åœ¨é¢å¯¹æ–°ä¿¡æ¯æ—¶æ¨ç†æ›´æ–°ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•çµæ´»è°ƒæ•´æ¨ç†ç»“æœï¼Œå¯¼è‡´æ¨ç†çš„å±€é™æ€§å’Œåå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå¯å¦å®šè§†é¢‘è•´å«ï¼ˆDVidEï¼‰ä»»åŠ¡ï¼Œè¦æ±‚æ¨¡å‹åœ¨æ–°è¯æ®å‡ºç°æ—¶ï¼ŒåŠ¨æ€æ›´æ–°å…¶æ¨ç†ï¼Œå¢å¼ºæ¨¡å‹çš„é€‚åº”æ€§å’Œçµæ´»æ€§ã€‚é€šè¿‡åäº‹å®æ€ç»´å’Œç”Ÿæˆæ¡†æ¶ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚çš„æ¨ç†ä»»åŠ¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šåˆ†ç±»ä»»åŠ¡å’Œç”Ÿæˆä»»åŠ¡ã€‚åˆ†ç±»ä»»åŠ¡åˆ©ç”¨åäº‹å®æ€ç»´é“¾æ¡†æ¶ï¼Œç”Ÿæˆä»»åŠ¡åˆ™ç»“åˆASRè¾“å‡ºä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œå†…å®¹ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†åäº‹å®æ€ç»´é“¾æ¡†æ¶å’Œç»“åˆASRä¸LLMçš„ç”Ÿæˆæ–¹æ³•ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„é™æ€æ¨ç†æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„åŠ¨æ€æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œé‡‡ç”¨åäº‹å®æ¨ç†å’Œç†ç”±ç²¾ç‚¼æŠ€æœ¯ä»¥å‡å°‘æ¨ç†åå·®ï¼›åœ¨ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œè®¾è®¡äº†ä¸ç›®æ ‡å¼ºåº¦ç›¸ç¬¦çš„æ›´æ–°ç”Ÿæˆæœºåˆ¶ï¼Œç¡®ä¿ç”Ÿæˆå†…å®¹çš„è¿è´¯æ€§å’Œç›¸å…³æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨åŠ¨æ€æ¨ç†èƒ½åŠ›ä¸Šæ˜¾è‘—æå‡ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œåˆ†ç±»ä»»åŠ¡çš„å‡†ç¡®ç‡æé«˜äº†XX%ï¼Œç”Ÿæˆä»»åŠ¡çš„è¿è´¯æ€§è¯„åˆ†æå‡äº†YY%ã€‚è¿™äº›ç»“æœéªŒè¯äº†åäº‹å®æ€ç»´å’Œç”Ÿæˆæ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è§†é¢‘åˆ†æã€æ™ºèƒ½ç›‘æ§ã€è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆç­‰ã€‚é€šè¿‡æå‡è§†é¢‘å¤šæ¨¡æ€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°æ”¯æŒå¤æ‚åœºæ™¯ä¸‹çš„å†³ç­–å’Œç†è§£ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Video Large Multimodal Models (VLMMs) have made impressive strides in understanding video content, but they often struggle with abstract and adaptive reasoning-the ability to revise their interpretations when new information emerges. In reality, conclusions are rarely set in stone; additional context can strengthen or weaken an initial inference. To address this, we introduce Defeasible Video Entailment (DVidE), a new task that challenges models to think like doubters, constantly updating their reasoning based on evolving evidence. In DVidE, given a video premise and a textual hypothesis, models must determine whether a new update strengthens or weakens the hypothesis (classification version) or generate a coherent update that modifies the entailment relationship (generation version). For solving the classification task, we propose the Chain of Counterfactual Thought framework, utilizing counterfactual reasoning, ASR-enhanced video content, and rationale refinement to reduce inference bias. For the generation task, we develop a framework that combines ASR output with a Large Language Model (LLM) to produce coherent, contextually relevant updates aligned with the intended strengthener or weakener goals. Additionally, we introduce a novel benchmark dataset, with strengthener/weakener annotations and an LLM-based evaluation metric specifically designed for assessing generative performance. Experimental results demonstrate significant improvements, highlighting our proposed method in enhancing dynamic reasoning capabilities of VLMMs.

