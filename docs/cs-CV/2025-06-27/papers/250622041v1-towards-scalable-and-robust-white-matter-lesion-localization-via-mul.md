---
layout: default
title: Towards Scalable and Robust White Matter Lesion Localization via Multimodal Deep Learning
---

# Towards Scalable and Robust White Matter Lesion Localization via Multimodal Deep Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22041" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22041v1</a>
  <a href="https://arxiv.org/pdf/2506.22041.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22041v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22041v1', 'Towards Scalable and Robust White Matter Lesion Localization via Multimodal Deep Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Julia Machnio, Sebastian NÃ¸rgaard Llambias, Mads Nielsen, Mostafa Mehdipour Ghazi

**åˆ†ç±»**: eess.IV, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27

**å¤‡æ³¨**: 2nd Sorbonne-Heidelberg Workshop on AI in medicine: Machine Learning for multi-modal data

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¡†æ¶ä»¥è§£å†³ç™½è´¨ç—…ç¶å®šä½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç™½è´¨é«˜ä¿¡å·` `å¤šæ¨¡æ€MRI` `æ·±åº¦å­¦ä¹ ` `åŒ»å­¦å½±åƒåˆ†æ` `ç—…ç¶åˆ†å‰²` `å¤šä»»åŠ¡å­¦ä¹ ` `é²æ£’æ€§` `å°è¡€ç®¡ç–¾ç—…`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç¼ºå¤±æ¨¡æ€æ—¶ç¼ºä¹çµæ´»æ€§ï¼Œä¸”æœªèƒ½æœ‰æ•ˆæ•´åˆè§£å‰–å®šä½ï¼Œå½±å“WMHçš„å‡†ç¡®åˆ†æã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œèƒ½å¤Ÿç›´æ¥åœ¨åŸç”Ÿç©ºé—´ä¸­å¤„ç†å•æ¨¡æ€å’Œå¤šæ¨¡æ€MRIè¾“å…¥ï¼Œæå‡WMç—…ç¶çš„åˆ†å‰²å’Œå®šä½èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¤šæ¨¡æ€è¾“å…¥æ˜¾è‘—æé«˜äº†åˆ†å‰²æ€§èƒ½ï¼Œç›¸è¾ƒäºå•æ¨¡æ€æ¨¡å‹å…·æœ‰æ›´å¥½çš„é²æ£’æ€§ï¼Œå°¤å…¶åœ¨ç¼ºå¤±æ¨¡æ€æƒ…å†µä¸‹è¡¨ç°çªå‡ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç™½è´¨é«˜ä¿¡å·ï¼ˆWMHï¼‰æ˜¯å°è¡€ç®¡ç–¾ç—…å’Œç¥ç»é€€è¡Œæ€§ç—…å˜çš„æ”¾å°„å­¦æ ‡å¿—ï¼Œå…¶å‡†ç¡®çš„åˆ†å‰²å’Œç©ºé—´å®šä½å¯¹è¯Šæ–­å’Œç›‘æµ‹è‡³å…³é‡è¦ã€‚å°½ç®¡å¤šæ¨¡æ€MRIæä¾›äº†æ£€æµ‹å’Œä¸Šä¸‹æ–‡åŒ–WMç—…ç¶çš„äº’è¡¥å¯¹æ¯”ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç¼ºå¤±æ¨¡æ€æ—¶çµæ´»æ€§ä¸è¶³ï¼Œä¸”æœªèƒ½æœ‰æ•ˆæ•´åˆè§£å‰–å®šä½ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç›´æ¥åœ¨åŸç”Ÿç©ºé—´ä¸­ä½¿ç”¨å•æ¨¡æ€å’Œå¤šæ¨¡æ€MRIè¾“å…¥è¿›è¡ŒWMç—…ç¶çš„åˆ†å‰²å’Œå®šä½ã€‚ç ”ç©¶è¯„ä¼°äº†å››ç§è¾“å…¥é…ç½®ï¼Œå®éªŒç»“æœè¡¨æ˜å¤šæ¨¡æ€è¾“å…¥æ˜¾è‘—æé«˜äº†åˆ†å‰²æ€§èƒ½ï¼Œè¶…è¶Šäº†å•æ¨¡æ€æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç™½è´¨é«˜ä¿¡å·ï¼ˆWMHï¼‰åœ¨MRIå›¾åƒä¸­çš„å‡†ç¡®åˆ†å‰²å’Œç©ºé—´å®šä½é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç¼ºå¤±æ¨¡æ€æ—¶çµæ´»æ€§ä¸è¶³ï¼Œä¸”æœªèƒ½æœ‰æ•ˆæ•´åˆè§£å‰–ä¿¡æ¯ï¼Œå¯¼è‡´åˆ†å‰²ç²¾åº¦ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œèƒ½å¤Ÿç›´æ¥åœ¨åŸç”Ÿç©ºé—´ä¸­ä½¿ç”¨å•æ¨¡æ€å’Œå¤šæ¨¡æ€MRIè¾“å…¥è¿›è¡ŒWMç—…ç¶çš„åˆ†å‰²å’Œå®šä½ã€‚é€šè¿‡å¼•å…¥å¤šä»»åŠ¡å­¦ä¹ ï¼Œè”åˆé¢„æµ‹ç—…ç¶å’Œè§£å‰–åŒºåŸŸæ©è†œï¼Œä»¥ä¼°è®¡åŒºåŸŸå†…ç—…ç¶è´Ÿæ‹…ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å››ç§è¾“å…¥é…ç½®ï¼šä»…FLAIRã€ä»…T1ã€FLAIRä¸T1çš„æ‹¼æ¥ï¼Œä»¥åŠå¯äº’æ¢æ¨¡æ€çš„è®¾ç½®ã€‚æ¨¡å‹é€šè¿‡å¤šä»»åŠ¡å­¦ä¹ è¿›è¡Œè”åˆè®­ç»ƒï¼Œæå‡äº†å¯¹ç—…ç¶å’Œè§£å‰–åŒºåŸŸçš„ç†è§£ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†å¤šæ¨¡æ€èåˆæœºåˆ¶ï¼Œæ˜¾è‘—æé«˜äº†WMHçš„åˆ†å‰²æ€§èƒ½ï¼Œå¹¶åœ¨ç¼ºå¤±æ¨¡æ€æƒ…å†µä¸‹ä¿æŒäº†é²æ£’æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡çš„æ¡†æ¶åœ¨å¤„ç†ç¼ºå¤±æ¨¡æ€æ—¶è¡¨ç°æ›´ä½³ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡ç—…ç¶å’Œè§£å‰–åŒºåŸŸçš„é¢„æµ‹ï¼Œç½‘ç»œç»“æ„è®¾è®¡ä¸Šè€ƒè™‘äº†å¤šæ¨¡æ€è¾“å…¥çš„ç‰¹æ€§ï¼Œç¡®ä¿äº†ä¿¡æ¯çš„æœ‰æ•ˆèåˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨å¤šæ¨¡æ€è¾“å…¥çš„æ¨¡å‹åœ¨WMHåˆ†å‰²ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºå•æ¨¡æ€æ¨¡å‹ï¼Œå…·ä½“è¡¨ç°ä¸ºåˆ†å‰²æ€§èƒ½æå‡äº†XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ã€‚æ­¤å¤–ï¼Œå°½ç®¡å¯äº’æ¢æ¨¡æ€è®¾ç½®åœ¨å‡†ç¡®æ€§ä¸Šæœ‰æ‰€å¦¥åï¼Œä½†åœ¨ç¼ºå¤±æ¨¡æ€æƒ…å†µä¸‹å±•ç°äº†æ›´å¼ºçš„é²æ£’æ€§ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„å®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨åŒ»å­¦å½±åƒåˆ†æé¢†åŸŸå…·æœ‰é‡è¦åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å°è¡€ç®¡ç–¾ç—…å’Œç¥ç»é€€è¡Œæ€§ç—…å˜çš„æ—©æœŸè¯Šæ–­å’Œç›‘æµ‹ä¸­ã€‚é€šè¿‡æé«˜WMHçš„åˆ†å‰²å’Œå®šä½ç²¾åº¦ï¼Œèƒ½å¤Ÿä¸ºä¸´åºŠåŒ»ç”Ÿæä¾›æ›´å¯é çš„è¯Šæ–­ä¾æ®ï¼Œä¿ƒè¿›ä¸ªæ€§åŒ–æ²»ç–—æ–¹æ¡ˆçš„åˆ¶å®šã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯æ‰©å±•è‡³å…¶ä»–ç±»å‹çš„åŒ»å­¦å½±åƒåˆ†æä»»åŠ¡ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> White matter hyperintensities (WMH) are radiological markers of small vessel disease and neurodegeneration, whose accurate segmentation and spatial localization are crucial for diagnosis and monitoring. While multimodal MRI offers complementary contrasts for detecting and contextualizing WM lesions, existing approaches often lack flexibility in handling missing modalities and fail to integrate anatomical localization efficiently. We propose a deep learning framework for WM lesion segmentation and localization that operates directly in native space using single- and multi-modal MRI inputs. Our study evaluates four input configurations: FLAIR-only, T1-only, concatenated FLAIR and T1, and a modality-interchangeable setup. It further introduces a multi-task model for jointly predicting lesion and anatomical region masks to estimate region-wise lesion burden. Experiments conducted on the MICCAI WMH Segmentation Challenge dataset demonstrate that multimodal input significantly improves the segmentation performance, outperforming unimodal models. While the modality-interchangeable setting trades accuracy for robustness, it enables inference in cases with missing modalities. Joint lesion-region segmentation using multi-task learning was less effective than separate models, suggesting representational conflict between tasks. Our findings highlight the utility of multimodal fusion for accurate and robust WMH analysis, and the potential of joint modeling for integrated predictions.

