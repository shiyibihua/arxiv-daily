---
layout: default
title: Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation
---

# Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22567" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.22567v1</a>
  <a href="https://arxiv.org/pdf/2506.22567.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22567v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22567v1', 'Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Shansong Wang, Zhecheng Jin, Mingzhe Hu, Mojtaba Safari, Feng Zhao, Chih-Wei Chang, Richard LJ Qiu, Justin Roper, David S. Yu, Xiaofeng Yang

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-27

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MMKD-CLIP‰ª•Ëß£ÂÜ≥ÁîüÁâ©ÂåªÂ≠¶È¢ÜÂüüÊ®°ÂûãÊ≥õÂåñÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÁîüÁâ©ÂåªÂ≠¶` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Áü•ËØÜËí∏È¶è` `CLIPÊ®°Âûã` `ÂõæÂÉè-ÊñáÊú¨ÂØπ` `Ê®°ÂûãÊ≥õÂåñ` `ÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÊûê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÁîüÁâ©ÂåªÂ≠¶Ê®°ÂûãÁî±‰∫éÊï∞ÊçÆÁ®ÄÁº∫ÂíåÊ†áÂáÜ‰∏ç‰∏ÄÔºåÈöæ‰ª•ÂÆûÁé∞Áªü‰∏ÄÂíåÊ≥õÂåñ„ÄÇ
2. MMKD-CLIPÈÄöËøáÂ§öÂåªÂ≠¶CLIPÁü•ËØÜËí∏È¶èÔºåÂà©Áî®Â§ö‰∏™È¢ÑËÆ≠ÁªÉÊ®°ÂûãÁöÑÁü•ËØÜÔºåÂÖãÊúçÊï∞ÊçÆÈôêÂà∂„ÄÇ
3. Âú®58‰∏™ÁîüÁâ©ÂåªÂ≠¶Êï∞ÊçÆÈõÜ‰∏äÔºåMMKD-CLIPÂú®ÂêÑÈ°π‰ªªÂä°‰∏≠Âùá‰ºò‰∫éÊâÄÊúâÊïôÂ∏àÊ®°ÂûãÔºåÂ±ïÁé∞Âá∫ËâØÂ•ΩÁöÑÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

CLIPÊ®°ÂûãÂú®Ëá™ÁÑ∂ÂõæÂÉè‰∏äÁªèËøá‰∫øÁ∫ßÂõæÂÉè-ÊñáÊú¨ÂØπÁöÑÈ¢ÑËÆ≠ÁªÉÂêéÔºåÂ±ïÁé∞‰∫ÜÂú®Èõ∂-shotÂàÜÁ±ª„ÄÅË∑®Ê®°ÊÄÅÊ£ÄÁ¥¢ÂíåÂºÄÊîæÂºèËßÜËßâÈóÆÁ≠îÁ≠â‰ªªÂä°‰∏≠ÁöÑÂçìË∂äËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂ∞ÜËøô‰∏ÄÊàêÂäüËΩ¨ÁßªÂà∞ÁîüÁâ©ÂåªÂ≠¶È¢ÜÂüüÈù¢‰∏¥ÁùÄÂ§ßËßÑÊ®°ÁîüÁâ©ÂåªÂ≠¶ÂõæÂÉè-ÊñáÊú¨ËØ≠ÊñôÁ®ÄÁº∫„ÄÅÂõæÂÉèÊ®°ÊÄÅÂºÇË¥®ÊÄßÂèäÊï∞ÊçÆÊ†áÂáÜÁ¢éÁâáÂåñÁ≠âÊåëÊàò„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜMMKD-CLIPÔºå‰∏Ä‰∏™ÈÄöËøáÂ§öÂåªÂ≠¶CLIPÁü•ËØÜËí∏È¶èÂºÄÂèëÁöÑÈÄöÁî®ÁîüÁâ©ÂåªÂ≠¶Âü∫Á°ÄÊ®°Âûã„ÄÇËØ•Ê®°ÂûãÈÄöËøá‰ªé‰πù‰∏™È¢ÜÂüüÁâπÂÆöÊàñÈÄöÁî®ÁîüÁâ©ÂåªÂ≠¶CLIPÊ®°Âûã‰∏≠ÊèêÂèñÁü•ËØÜÔºåËÄåÈùû‰æùËµñ‰∫øÁ∫ßÂéüÂßãÊï∞ÊçÆÔºåÂ±ïÁ§∫‰∫ÜÂú®58‰∏™Â§öÊ†∑ÂåñÁîüÁâ©ÂåªÂ≠¶Êï∞ÊçÆÈõÜ‰∏äÁöÑ‰ºòË∂äÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÁîüÁâ©ÂåªÂ≠¶È¢ÜÂüü‰∏≠Áº∫‰πèÂ§ßËßÑÊ®°ÂõæÂÉè-ÊñáÊú¨Êï∞ÊçÆÁöÑÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Êï∞ÊçÆÁ®ÄÁº∫ÂíåÂºÇË¥®ÊÄßÊñπÈù¢Ë°®Áé∞‰∏ç‰Ω≥ÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÂ§öÂåªÂ≠¶CLIPÁü•ËØÜËí∏È¶èÔºåMMKD-CLIP‰ªéÂ§ö‰∏™È¢ÑËÆ≠ÁªÉÁöÑÁîüÁâ©ÂåªÂ≠¶CLIPÊ®°Âûã‰∏≠ÊèêÂèñÁü•ËØÜÔºåÈÅøÂÖç‰∫ÜÂØπÂ§ßËßÑÊ®°ÂéüÂßãÊï∞ÊçÆÁöÑ‰æùËµñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂàÜ‰∏∫‰∏§‰∏™Èò∂ÊÆµÔºöÁ¨¨‰∏ÄÈò∂ÊÆµÊòØÂØπË∂ÖËøá290‰∏áÁîüÁâ©ÂåªÂ≠¶ÂõæÂÉè-ÊñáÊú¨ÂØπËøõË°åCLIPÈ£éÊ†ºÁöÑÈ¢ÑËÆ≠ÁªÉÔºåÁ¨¨‰∫åÈò∂ÊÆµÂàôÊòØ‰ΩøÁî®‰ªéÊïôÂ∏àÊ®°Âûã‰∏≠ÊèêÂèñÁöÑ1920‰∏áÁâπÂæÅÂØπËøõË°åÁâπÂæÅÁ∫ßËí∏È¶è„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÈááÁî®Â§öÊïôÂ∏àÁü•ËØÜËí∏È¶èÁöÑÊñπÂºèÔºåÊòæËëóÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÊ≥õÂåñËÉΩÂäõÔºåËøô‰∏é‰º†ÁªüÂçï‰∏ÄÊ®°ÂûãËÆ≠ÁªÉÊñπÊ≥ïÊúâÊú¨Ë¥®Âå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆ≠ÁªÉ‰∏≠ÔºåÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑËÆæËÆ°Ôºå‰ª•Á°Æ‰øùÁü•ËØÜËí∏È¶èËøáÁ®ãÁöÑÊúâÊïàÊÄßÂíåÁ®≥ÂÆöÊÄßÔºåÂêåÊó∂‰ºòÂåñ‰∫ÜÂèÇÊï∞ËÆæÁΩÆ‰ª•ÈÄÇÂ∫îÂ§öÊ®°ÊÄÅÊï∞ÊçÆÁöÑÁâπÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MMKD-CLIPÂú®58‰∏™ÁîüÁâ©ÂåªÂ≠¶Êï∞ÊçÆÈõÜ‰∏äÁöÑËØÑ‰º∞ÁªìÊûúÊòæÁ§∫ÔºåÂÖ∂Âú®Èõ∂-shotÂàÜÁ±ª„ÄÅÁ∫øÊÄßÊé¢Êµã„ÄÅË∑®Ê®°ÊÄÅÊ£ÄÁ¥¢Á≠â‰ªªÂä°‰∏≠ÂùáË∂ÖË∂ä‰∫ÜÊâÄÊúâÊïôÂ∏àÊ®°ÂûãÔºåÂ±ïÁé∞Âá∫ÊòæËëóÁöÑÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõÔºåÂ∞§ÂÖ∂Âú®‰∏çÂêåÂõæÂÉèÊ®°ÊÄÅÂíå‰ªªÂä°ËÆæÁΩÆ‰∏ãÁöÑË°®Áé∞Â∞§‰∏∫Á™ÅÂá∫„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÊûê„ÄÅÁñæÁóÖÈ¢ÑÊµãÂíå‰∏¥Â∫äÂÜ≥Á≠ñÊîØÊåÅÁ≠â„ÄÇÈÄöËøáÊûÑÂª∫È´òÊÄßËÉΩÁöÑÁîüÁâ©ÂåªÂ≠¶Âü∫Á°ÄÊ®°ÂûãÔºåMMKD-CLIPËÉΩÂ§üÂú®ÂÆûÈôÖÂåªÁñóÂú∫ÊôØ‰∏≠Êèê‰æõÊõ¥‰∏∫Á≤æÂáÜÁöÑËæÖÂä©ËØäÊñ≠ÂíåÂÜ≥Á≠ñÊîØÊåÅÔºåÊé®Âä®ÁîüÁâ©ÂåªÂ≠¶È¢ÜÂüüÁöÑÊô∫ËÉΩÂåñËøõÁ®ã„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> CLIP models pretrained on natural images with billion-scale image-text pairs have demonstrated impressive capabilities in zero-shot classification, cross-modal retrieval, and open-ended visual answering. However, transferring this success to biomedicine is hindered by the scarcity of large-scale biomedical image-text corpora, the heterogeneity of image modalities, and fragmented data standards across institutions. These limitations hinder the development of a unified and generalizable biomedical foundation model trained from scratch. To overcome this, we introduce MMKD-CLIP, a generalist biomedical foundation model developed via Multiple Medical CLIP Knowledge Distillation. Rather than relying on billion-scale raw data, MMKD-CLIP distills knowledge from nine state-of-the-art domain-specific or generalist biomedical CLIP models, each pretrained on millions of biomedical image-text pairs. Our two-stage training pipeline first performs CLIP-style pretraining on over 2.9 million biomedical image-text pairs from 26 image modalities, followed by feature-level distillation using over 19.2 million feature pairs extracted from teacher models. We evaluate MMKD-CLIP on 58 diverse biomedical datasets, encompassing over 10.8 million biomedical images across nine image modalities. The evaluation spans six core task types: zero-shot classification, linear probing, cross-modal retrieval, visual question answering, survival prediction, and cancer diagnosis. MMKD-CLIP consistently outperforms all teacher models while demonstrating remarkable robustness and generalization across image domains and task settings. These results underscore that multi-teacher knowledge distillation is a scalable and effective paradigm for building high-performing biomedical foundation models under the practical constraints of real-world data availability.

