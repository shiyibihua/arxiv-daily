---
layout: default
title: Exploring Semantic Masked Autoencoder for Self-supervised Point Cloud Understanding
---

# Exploring Semantic Masked Autoencoder for Self-supervised Point Cloud Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21957" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21957v1</a>
  <a href="https://arxiv.org/pdf/2506.21957.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21957v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21957v1', 'Exploring Semantic Masked Autoencoder for Self-supervised Point Cloud Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yixin Zha, Chuxin Wang, Wenfei Yang, Tianzhu Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27

**å¤‡æ³¨**: Accepted by IJCAI 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­ä¹‰æ©ç è‡ªç¼–ç å™¨ä»¥è§£å†³ç‚¹äº‘ç†è§£ä¸­çš„è¯­ä¹‰å…³ç³»æ•æ‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç‚¹äº‘ç†è§£` `è‡ªç›‘ç£å­¦ä¹ ` `è¯­ä¹‰å»ºæ¨¡` `æ©ç ç­–ç•¥` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç‚¹äº‘ç†è§£æ–¹æ³•åœ¨æ•æ‰è¯­ä¹‰å…³ç³»æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéšæœºæ©ç ç­–ç•¥æ— æ³•æœ‰æ•ˆæ¢å¤å®Œæ•´çš„ç»„ä»¶ç»“æ„ã€‚
2. æœ¬æ–‡æå‡ºçš„è¯­ä¹‰æ©ç è‡ªç¼–ç å™¨é€šè¿‡ç»„ä»¶è¯­ä¹‰å»ºæ¨¡å’Œè¯­ä¹‰å¢å¼ºæ©ç ç­–ç•¥ï¼Œæ”¹å–„äº†éšæœºæ©ç çš„å±€é™æ€§ã€‚
3. åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç‚¹äº‘ç†è§£æ—¨åœ¨ä»æœªæ ‡è®°æ•°æ®ä¸­è·å–ç¨³å¥ä¸”é€šç”¨çš„ç‰¹å¾è¡¨ç¤ºã€‚åŸºäºæ©ç ç‚¹å»ºæ¨¡çš„æ–¹æ³•åœ¨å„ç§ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›é¢„è®­ç»ƒæ–¹æ³•ä¾èµ–éšæœºæ©ç ç­–ç•¥æ¥æ¢å¤æŸåçš„ç‚¹äº‘è¾“å…¥ï¼Œå¯¼è‡´è‡ªç›‘ç£æ¨¡å‹æœªèƒ½æœ‰æ•ˆæ•æ‰åˆç†çš„è¯­ä¹‰å…³ç³»ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†è¯­ä¹‰æ©ç è‡ªç¼–ç å™¨ï¼ŒåŒ…å«ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼šåŸºäºåŸå‹çš„ç»„ä»¶è¯­ä¹‰å»ºæ¨¡æ¨¡å—å’Œç»„ä»¶è¯­ä¹‰å¢å¼ºæ©ç ç­–ç•¥ã€‚é€šè¿‡è®¾è®¡ç»„ä»¶è¯­ä¹‰å¼•å¯¼æœºåˆ¶ï¼Œæœ¬æ–‡å¼•å¯¼å¯å­¦ä¹ çš„åŸå‹æ•æ‰ä¸åŒå¯¹è±¡ç»„ä»¶çš„è¯­ä¹‰ï¼Œå¹¶å¼€å‘å‡ºæœ‰æ•ˆè¦†ç›–å®Œæ•´ç»„ä»¶ç»“æ„çš„æ©ç ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ¨¡å—åœ¨ScanObjectNNã€ModelNet40å’ŒShapeNetPartç­‰æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ç‚¹äº‘ç†è§£æ–¹æ³•åœ¨æ•æ‰è¯­ä¹‰å…³ç³»æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯éšæœºæ©ç ç­–ç•¥å¯¼è‡´çš„è¯­ä¹‰ä¿¡æ¯ç¼ºå¤±é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºè¯­ä¹‰æ©ç è‡ªç¼–ç å™¨ï¼Œé€šè¿‡ç»„ä»¶è¯­ä¹‰å»ºæ¨¡æ¨¡å—å’Œè¯­ä¹‰å¢å¼ºæ©ç ç­–ç•¥ï¼Œåˆ©ç”¨å¯å­¦ä¹ çš„åŸå‹æ¥å¼•å¯¼æ¨¡å‹æ•æ‰å¯¹è±¡çš„è¯­ä¹‰ç»„ä»¶ï¼Œä»è€Œæ”¹å–„è¯­ä¹‰å…³ç³»çš„æ¢å¤ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç»„ä»¶è¯­ä¹‰å»ºæ¨¡æ¨¡å—å’Œç»„ä»¶è¯­ä¹‰å¢å¼ºæ©ç ç­–ç•¥ã€‚å‰è€…é€šè¿‡ç»„ä»¶è¯­ä¹‰å¼•å¯¼æœºåˆ¶å¼•å¯¼åŸå‹å­¦ä¹ ï¼Œåè€…åˆ™é€šè¿‡å¢å¼ºæ©ç ç­–ç•¥è¦†ç›–å®Œæ•´çš„ç»„ä»¶ç»“æ„ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†ç»„ä»¶è¯­ä¹‰å¼•å¯¼æœºåˆ¶å’Œè¯­ä¹‰å¢å¼ºæ©ç ç­–ç•¥ï¼Œè¿™ä¸ä¼ ç»Ÿçš„éšæœºæ©ç æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•æ‰è¯­ä¹‰ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼Œé‡‡ç”¨äº†å¯å­¦ä¹ çš„åŸå‹æ¥è¡¨ç¤ºä¸åŒç»„ä»¶çš„è¯­ä¹‰ï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥äº†é’ˆå¯¹è¯­ä¹‰æ¢å¤çš„ä¼˜åŒ–ç›®æ ‡ï¼Œä»¥æå‡æ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æè¯­ä¹‰æ©ç è‡ªç¼–ç å™¨åœ¨ScanObjectNNã€ModelNet40å’ŒShapeNetPartæ•°æ®é›†ä¸Šå‡æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°äº†XX%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•è¡¨ç°å‡ºæ›´ä¼˜çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººè§†è§‰å’Œä¸‰ç»´ç‰©ä½“è¯†åˆ«ç­‰ã€‚é€šè¿‡æé«˜ç‚¹äº‘ç†è§£çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„ç‰©ä½“è¯†åˆ«ä¸åœºæ™¯ç†è§£ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Point cloud understanding aims to acquire robust and general feature representations from unlabeled data. Masked point modeling-based methods have recently shown significant performance across various downstream tasks. These pre-training methods rely on random masking strategies to establish the perception of point clouds by restoring corrupted point cloud inputs, which leads to the failure of capturing reasonable semantic relationships by the self-supervised models. To address this issue, we propose Semantic Masked Autoencoder, which comprises two main components: a prototype-based component semantic modeling module and a component semantic-enhanced masking strategy. Specifically, in the component semantic modeling module, we design a component semantic guidance mechanism to direct a set of learnable prototypes in capturing the semantics of different components from objects. Leveraging these prototypes, we develop a component semantic-enhanced masking strategy that addresses the limitations of random masking in effectively covering complete component structures. Furthermore, we introduce a component semantic-enhanced prompt-tuning strategy, which further leverages these prototypes to improve the performance of pre-trained models in downstream tasks. Extensive experiments conducted on datasets such as ScanObjectNN, ModelNet40, and ShapeNetPart demonstrate the effectiveness of our proposed modules.

