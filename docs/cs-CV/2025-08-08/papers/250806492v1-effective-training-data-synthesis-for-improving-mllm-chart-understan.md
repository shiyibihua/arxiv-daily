---
layout: default
title: Effective Training Data Synthesis for Improving MLLM Chart Understanding
---

# Effective Training Data Synthesis for Improving MLLM Chart Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.06492" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.06492v1</a>
  <a href="https://arxiv.org/pdf/2508.06492.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.06492v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.06492v1', 'Effective Training Data Synthesis for Improving MLLM Chart Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuwei Yang, Zeyu Zhang, Yunzhong Hou, Zhuowan Li, Gaowen Liu, Ali Payani, Yuan-Sen Ting, Liang Zheng

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-08

**å¤‡æ³¨**: Accepted by ICCV 2025 (poster). 26 pages, 17 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/yuweiyang-anu/ECD)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæœ‰æ•ˆæ•°æ®åˆæˆæ–¹æ³•ä»¥æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å›¾è¡¨ç†è§£èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾è¡¨ç†è§£` `æ•°æ®åˆæˆ` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `ç§‘å­¦æ™ºèƒ½ä½“` `è§†è§‰å¤šæ ·åŒ–` `é—®ç­”ç”Ÿæˆ` `æ¨¡å‹å¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç§‘å­¦å›¾è¡¨ç†è§£æ–¹é¢è¡¨ç°ä¸ä½³ï¼ŒæˆåŠŸç‡ä½äºé¢„æœŸã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§äº”æ­¥æ•°æ®åˆæˆæµç¨‹ï¼Œé€šè¿‡æ¨¡å—åŒ–ç”Ÿæˆå’Œè§†è§‰å¤šæ ·åŒ–æ¥æå‡æ¨¡å‹æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç”Ÿæˆçš„æœ‰æ•ˆå›¾è¡¨æ•°æ®é›†æ˜¾è‘—æé«˜äº†å¤šç§MLLMåœ¨ä¸åŒæµ‹è¯•é›†ä¸Šçš„è¡¨ç°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ‰æ•ˆé˜…è¯»ç§‘å­¦å›¾è¡¨æ˜¯æ„å»ºç§‘å­¦æ™ºèƒ½ä½“çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¤æ‚åŸºå‡†æµ‹è¯•ä¸­çš„æˆåŠŸç‡ä»…ä¸º30%-50%ã€‚ä»¥å¾€çš„åˆæˆå›¾è¡¨å¾®è°ƒç ”ç©¶ç”±äºä¸çœŸå®å›¾è¡¨çš„ç›¸ä¼¼æ€§ä¸è¶³ï¼Œå½±å“äº†æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚æœ¬æ–‡å±•ç¤ºäº†é€šè¿‡æ¨¡å—åŒ–å›¾è¡¨ç”Ÿæˆå’Œå¤šæ ·åŒ–è§†è§‰ç»†èŠ‚æ¥æå‡å›¾è¡¨ç†è§£èƒ½åŠ›ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªäº”æ­¥æ•°æ®åˆæˆæµç¨‹ï¼Œç”Ÿæˆäº†åŒ…å«10,000å¤šå¼ å›¾è¡¨å’Œ300,000å¤šä¸ªé—®ç­”å¯¹çš„æœ‰æ•ˆå›¾è¡¨æ•°æ®é›†ï¼ˆECDï¼‰ï¼Œæ˜¾è‘—æå‡äº†å¤šç§MLLMåœ¨çœŸå®å’Œåˆæˆæµ‹è¯•é›†ä¸Šçš„è¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç§‘å­¦å›¾è¡¨ç†è§£ä¸­çš„ä½æˆåŠŸç‡é—®é¢˜ï¼Œå°¤å…¶æ˜¯åˆæˆå›¾è¡¨ä¸çœŸå®å›¾è¡¨ç›¸ä¼¼æ€§ä¸è¶³å¯¼è‡´çš„è®­ç»ƒæ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ¨¡å—åŒ–å›¾è¡¨ç”Ÿæˆå’Œè§†è§‰ç»†èŠ‚å¤šæ ·åŒ–ï¼Œæå‡åˆæˆå›¾è¡¨çš„è´¨é‡å’Œå¤šæ ·æ€§ï¼Œä»è€Œæ”¹å–„æ¨¡å‹çš„ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶è®¾è®¡äº†ä¸€ä¸ªäº”æ­¥æ•°æ®åˆæˆæµç¨‹ï¼ŒåŒ…æ‹¬å•ä¸ªå›¾è¡¨ç”Ÿæˆçš„æ•°æ®ä¸åŠŸèƒ½åˆ›å»ºã€å­å›¾ç”Ÿæˆçš„æ¡ä»¶åŒ–ã€è§†è§‰å¤šæ ·åŒ–ã€ä½è´¨é‡æ•°æ®è¿‡æ»¤ï¼Œä»¥åŠä½¿ç”¨GPT-4oç”Ÿæˆé—®ç­”å¯¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæœ‰æ•ˆå›¾è¡¨æ•°æ®é›†ï¼ˆECDï¼‰çš„æ„å»ºï¼ŒåŒ…å«10,000å¤šå¼ å›¾è¡¨å’Œ300,000å¤šä¸ªé—®ç­”å¯¹ï¼Œæ¶µç›–25ä¸ªä¸»é¢˜å’Œ250å¤šç§å›¾è¡¨ç±»å‹ç»„åˆï¼Œæå¤§ä¸°å¯Œäº†è®­ç»ƒæ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®åˆæˆè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†å¤šå±‚æ¬¡çš„æ¡ä»¶ç”Ÿæˆç­–ç•¥å’Œè§†è§‰å¤šæ ·åŒ–æŠ€æœ¯ï¼Œç¡®ä¿ç”Ÿæˆçš„å›¾è¡¨åœ¨è§†è§‰å¤æ‚æ€§å’Œå†…å®¹ç›¸å…³æ€§ä¸Šéƒ½èƒ½æ»¡è¶³é«˜æ ‡å‡†ã€‚å®éªŒä¸­ä½¿ç”¨çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„æœªè¯¦ç»†è¯´æ˜ï¼Œéœ€è¿›ä¸€æ­¥æ¢ç´¢ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨æœ‰æ•ˆå›¾è¡¨æ•°æ®é›†ï¼ˆECDï¼‰åï¼Œå„ç§å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨çœŸå®å’Œåˆæˆæµ‹è¯•é›†ä¸Šçš„æ€§èƒ½å‡æœ‰æ˜¾è‘—æå‡ï¼ŒæˆåŠŸç‡æé«˜äº†20%-30%ã€‚è¿™ä¸€æˆæœä¸ºå›¾è¡¨ç†è§£é¢†åŸŸæä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘å’Œæ•°æ®æ”¯æŒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç§‘å­¦ç ”ç©¶ã€æ•™è‚²å’Œæ•°æ®å¯è§†åŒ–ç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å›¾è¡¨ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°æ”¯æŒç§‘å­¦æ•°æ®åˆ†æã€è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆå’Œæ™ºèƒ½æ•™è‚²ç³»ç»Ÿçš„å¼€å‘ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Being able to effectively read scientific plots, or chart understanding, is a central part toward building effective agents for science. However, existing multimodal large language models (MLLMs), especially open-source ones, are still falling behind with a typical success rate of 30%-50% on challenging benchmarks. Previous studies on fine-tuning MLLMs with synthetic charts are often restricted by their inadequate similarity to the real charts, which could compromise model training and performance on complex real-world charts. In this study, we show that modularizing chart generation and diversifying visual details improves chart understanding capabilities. In particular, we design a five-step data synthesis pipeline, where we separate data and function creation for single plot generation, condition the generation of later subplots on earlier ones for multi-subplot figures, visually diversify the generated figures, filter out low quality data, and finally generate the question-answer (QA) pairs with GPT-4o. This approach allows us to streamline the generation of fine-tuning datasets and introduce the effective chart dataset (ECD), which contains 10k+ chart images and 300k+ QA pairs, covering 25 topics and featuring 250+ chart type combinations with high visual complexity. We show that ECD consistently improves the performance of various MLLMs on a range of real-world and synthetic test sets. Code, data and models are available at: https://github.com/yuweiyang-anu/ECD.

