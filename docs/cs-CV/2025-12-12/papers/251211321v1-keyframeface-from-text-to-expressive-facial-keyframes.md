---
layout: default
title: KeyframeFace: From Text to Expressive Facial Keyframes
---

# KeyframeFace: From Text to Expressive Facial Keyframes

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.11321" target="_blank" class="toolbar-btn">arXiv: 2512.11321v1</a>
    <a href="https://arxiv.org/pdf/2512.11321.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.11321v1" 
            onclick="toggleFavorite(this, '2512.11321v1', 'KeyframeFace: From Text to Expressive Facial Keyframes')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jingchao Wu, Zejian Kang, Haibo Liu, Yuanchen Fei, Xiangru Huang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-12

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/wjc12345123/KeyframeFace)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**KeyframeFaceÔºöÊèêÂá∫Âü∫‰∫éÊñáÊú¨È©±Âä®ÁöÑ„ÄÅÂèØËß£ÈáäÁöÑÂÖ≥ÈîÆÂ∏ß‰∫∫ËÑ∏Ë°®ÊÉÖÂä®ÁîªÁîüÊàêÊ°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `ÊñáÊú¨È©±Âä®Âä®Áîª` `‰∫∫ËÑ∏Ë°®ÊÉÖÁîüÊàê` `ÂÖ≥ÈîÆÂ∏ßÂä®Áîª` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Â§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ÊñáÊú¨È©±Âä®‰∫∫ËÑ∏Âä®ÁîªÁîüÊàêÊñπÈù¢ÔºåÁº∫‰πèÂØπÊó∂Â∫èËØ≠‰πâÂíåÁªÜÁ≤íÂ∫¶Ë°®ÊÉÖÂèòÂåñÁöÑÊúâÊïàÂª∫Ê®°ÔºåÊï∞ÊçÆÈõÜ‰πüÂ§öÈõÜ‰∏≠‰∫éËØ≠Èü≥È©±Âä®ÊàñÈùûÁªìÊûÑÂåñË°®ÊÉÖÂ∫èÂàó„ÄÇ
2. KeyframeFaceÈÄöËøáÊûÑÂª∫Â§ßËßÑÊ®°Â§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜÔºåÂπ∂ÁªìÂêàLLMÂÖàÈ™åÁü•ËØÜÔºåÊòæÂºèÂú∞Âà©Áî®ÂÖ≥ÈîÆÂ∏ßËøõË°å‰∫∫ËÑ∏ËøêÂä®ÂêàÊàêÔºåÂÆûÁé∞ÂèØËß£ÈáäÁöÑÈ´ò‰øùÁúüÂä®ÁîªÁîüÊàê„ÄÇ
3. ËÆ∫ÊñáÊûÑÂª∫‰∫ÜÂåÖÂê´‰∏∞ÂØåÊ†áÊ≥®ÁöÑÊï∞ÊçÆÈõÜÔºåÂπ∂ÊèêÂá∫‰∫ÜÂü∫‰∫éLLMÁöÑÊñáÊú¨Âà∞Âä®ÁîªÊ°ÜÊû∂Ôºå‰∏∫ÂêéÁª≠Á†îÁ©∂Â•†ÂÆö‰∫ÜÂü∫Á°ÄÔºåÂÖ∑‰ΩìÊÄßËÉΩÊèêÂçáÊï∞ÊçÆÊú™Áü•„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫KeyframeFaceÔºå‰∏Ä‰∏™Â§ßËßÑÊ®°Â§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜÔºåÊó®Âú®ÈÄöËøáÂÖ≥ÈîÆÂ∏ßÁ∫ßÂà´ÁöÑÁõëÁù£ËøõË°åÊñáÊú¨Âà∞Âä®ÁîªÁöÑÁ†îÁ©∂„ÄÇKeyframeFaceÊèê‰æõ‰∫Ü2100‰∏™ÂØåÊúâË°®Áé∞ÂäõÁöÑËÑöÊú¨ÔºåÂπ∂ÈÖçÊúâÂçïÁõÆËßÜÈ¢ë„ÄÅÈÄêÂ∏ßARKitÁ≥ªÊï∞„ÄÅ‰∏ä‰∏ãÊñáËÉåÊôØ„ÄÅÂ§çÊùÇÁöÑÊÉÖÊÑü„ÄÅÊâãÂä®ÂÆö‰πâÁöÑÂÖ≥ÈîÆÂ∏ßÔºå‰ª•ÂèäÂü∫‰∫éARKitÁ≥ªÊï∞ÂíåÂõæÂÉèÔºåÈÄöËøáÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂíåÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâËøõË°åÁöÑÂ§öËßÜËßíÊ†áÊ≥®„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáËøòÊèêÂá∫‰∫ÜÁ¨¨‰∏Ä‰∏™ÊñáÊú¨Âà∞Âä®ÁîªÁöÑÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂ÊòæÂºèÂú∞Âà©Áî®LLMÂÖàÈ™åÁü•ËØÜËøõË°åÂèØËß£ÈáäÁöÑÈù¢ÈÉ®ËøêÂä®ÂêàÊàê„ÄÇËøôÁßçËÆæËÆ°Â∞ÜLLMÁöÑËØ≠‰πâÁêÜËß£ËÉΩÂäõ‰∏éARKitÁ≥ªÊï∞ÁöÑÂèØËß£ÈáäÁªìÊûÑÂØπÈΩêÔºå‰ªéËÄåÂÆûÁé∞È´ò‰øùÁúüÂ∫¶ÁöÑË°®ÊÉÖÂä®Áîª„ÄÇKeyframeFaceÂíåÂü∫‰∫éLLMÁöÑÊ°ÜÊû∂ÂÖ±Âêå‰∏∫ÂèØËß£ÈáäÁöÑ„ÄÅÂÖ≥ÈîÆÂ∏ßÂºïÂØºÁöÑ„ÄÅ‰ª•Âèä‰∏ä‰∏ãÊñáÊÑüÁü•ÁöÑÊñáÊú¨Âà∞Âä®ÁîªÂ•†ÂÆö‰∫ÜÊñ∞ÁöÑÂü∫Á°Ä„ÄÇ‰ª£Á†ÅÂíåÊï∞ÊçÆÂèØÂú®https://github.com/wjc12345123/KeyframeFaceËé∑Âèñ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊñáÊú¨È©±Âä®‰∫∫ËÑ∏Âä®ÁîªÁîüÊàêÊñπÊ≥ïÈöæ‰ª•ÊçïÊçâÊó∂Â∫èËØ≠‰πâÂíåÁªÜÁ≤íÂ∫¶Ë°®ÊÉÖÂèòÂåñÔºåÊï∞ÊçÆÈõÜÈÄöÂ∏∏Áº∫‰πèËØ≠‰πâ grounding ÂíåÊó∂Â∫èÁªìÊûÑÔºåÈôêÂà∂‰∫ÜÁîüÊàêÂØåÊúâË°®Áé∞ÂäõÁöÑ‰∫∫ËÑ∏Âä®ÁîªÁöÑËÉΩÂäõ„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠Âú®ËØ≠Èü≥È©±Âä®ÊàñÈùûÁªìÊûÑÂåñË°®ÊÉÖÂ∫èÂàóÔºåÂøΩÁï•‰∫ÜÊñáÊú¨‰∏≠Ëï¥Âê´ÁöÑ‰∏∞ÂØåÊÉÖÊÑüÂíå‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÂº∫Â§ßËØ≠‰πâÁêÜËß£ËÉΩÂäõÔºåÁªìÂêàARKitÁ≥ªÊï∞ÁöÑÂèØËß£ÈáäÁªìÊûÑÔºåÈÄöËøáÂÖ≥ÈîÆÂ∏ßÂºïÂØºÁöÑÊñπÂºèÔºåÂÆûÁé∞È´ò‰øùÁúüÂ∫¶ÁöÑË°®ÊÉÖÂä®ÁîªÁîüÊàê„ÄÇÈÄöËøáÊòæÂºèÂú∞Âà©Áî®LLMÁöÑÂÖàÈ™åÁü•ËØÜÔºåÂ∞ÜÊñáÊú¨‰∏≠ÁöÑËØ≠‰πâ‰ø°ÊÅØËΩ¨Âåñ‰∏∫ÂèØÊéßÁöÑÈù¢ÈÉ®ËøêÂä®ÂèÇÊï∞Ôºå‰ªéËÄåÁîüÊàêÊõ¥Ëá™ÁÑ∂„ÄÅÊõ¥ÂØåÊúâË°®Áé∞ÂäõÁöÑ‰∫∫ËÑ∏Âä®Áîª„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´Êï∞ÊçÆÈõÜÊûÑÂª∫ÂíåÊ®°ÂûãËÆ≠ÁªÉ‰∏§ÈÉ®ÂàÜ„ÄÇÊï∞ÊçÆÈõÜÊûÑÂª∫ÊñπÈù¢ÔºåKeyframeFaceÊï∞ÊçÆÈõÜÂåÖÂê´2100‰∏™ËÑöÊú¨ÔºåÊØè‰∏™ËÑöÊú¨ÈÉΩÈÖçÊúâÂçïÁõÆËßÜÈ¢ë„ÄÅÈÄêÂ∏ßARKitÁ≥ªÊï∞„ÄÅ‰∏ä‰∏ãÊñáËÉåÊôØ„ÄÅÂ§çÊùÇÊÉÖÊÑü„ÄÅÊâãÂä®ÂÆö‰πâÁöÑÂÖ≥ÈîÆÂ∏ß‰ª•ÂèäÂ§öËßÜËßíÊ†áÊ≥®„ÄÇÊ®°ÂûãËÆ≠ÁªÉÊñπÈù¢ÔºåËØ•Ê°ÜÊû∂Âà©Áî®LLMÂ∞ÜÊñáÊú¨‰ø°ÊÅØÊò†Â∞ÑÂà∞ARKitÁ≥ªÊï∞Á©∫Èó¥ÔºåÂπ∂ÈÄöËøáÂÖ≥ÈîÆÂ∏ßÂºïÂØºÁöÑÊñπÂºè‰ºòÂåñÁîüÊàêÁªìÊûú„ÄÇÂÖ∑‰ΩìÊ®°ÂùóÁªÜËäÇÊú™Áü•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÊòæÂºèÂú∞Âà©Áî®LLMÁöÑÂÖàÈ™åÁü•ËØÜËøõË°åÂèØËß£ÈáäÁöÑÈù¢ÈÉ®ËøêÂä®ÂêàÊàê„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£ÊñáÊú¨‰∏≠ÁöÑËØ≠‰πâ‰ø°ÊÅØÔºåÂπ∂Â∞ÜËøô‰∫õ‰ø°ÊÅØËΩ¨Âåñ‰∏∫ÂèØÊéßÁöÑÈù¢ÈÉ®ËøêÂä®ÂèÇÊï∞Ôºå‰ªéËÄåÁîüÊàêÊõ¥Ëá™ÁÑ∂„ÄÅÊõ¥ÂØåÊúâË°®Áé∞ÂäõÁöÑ‰∫∫ËÑ∏Âä®Áîª„ÄÇÊ≠§Â§ñÔºåKeyframeFaceÊï∞ÊçÆÈõÜÁöÑÊûÑÂª∫‰πü‰∏∫ÊñáÊú¨È©±Âä®‰∫∫ËÑ∏Âä®ÁîªÁîüÊàêÁ†îÁ©∂Êèê‰æõ‰∫ÜÊñ∞ÁöÑËµÑÊ∫ê„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰∏≠ÂÖ≥‰∫éÂèÇÊï∞ËÆæÁΩÆ„ÄÅÊçüÂ§±ÂáΩÊï∞„ÄÅÁΩëÁªúÁªìÊûÑÁ≠âÊäÄÊúØÁªÜËäÇÊèèËø∞ËæÉÂ∞ëÔºåÂÖ∑‰ΩìËÆæËÆ°Êú™Áü•„ÄÇ‰ΩÜÂèØ‰ª•Êé®ÊµãÔºåÊçüÂ§±ÂáΩÊï∞ÂèØËÉΩÂåÖÂê´ÈáçÊûÑÊçüÂ§±„ÄÅÂÖ≥ÈîÆÂ∏ßÂØπÈΩêÊçüÂ§±Á≠âÔºå‰ª•‰øùËØÅÁîüÊàêÁªìÊûúÁöÑ‰øùÁúüÂ∫¶ÂíåÂÖ≥ÈîÆÂ∏ßÁöÑÂáÜÁ°ÆÊÄß„ÄÇÁΩëÁªúÁªìÊûÑÂèØËÉΩÂåÖÂê´ÊñáÊú¨ÁºñÁ†ÅÂô®„ÄÅARKitÁ≥ªÊï∞Ëß£Á†ÅÂô®Á≠âÊ®°ÂùóÔºåÂÖ∑‰ΩìÁªìÊûÑÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÊûÑÂª∫‰∫ÜÂ§ßËßÑÊ®°Â§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜKeyframeFaceÔºåÂåÖÂê´2100‰∏™ËÑöÊú¨Âíå‰∏∞ÂØåÁöÑÊ†áÊ≥®‰ø°ÊÅØ„ÄÇÊèêÂá∫‰∫ÜÂü∫‰∫éLLMÁöÑÊñáÊú¨Âà∞Âä®ÁîªÊ°ÜÊû∂ÔºåËÉΩÂ§üÁîüÊàêÈ´ò‰øùÁúüÂ∫¶ÁöÑË°®ÊÉÖÂä®Áîª„ÄÇËôΩÁÑ∂ËÆ∫Êñá‰∏≠Ê≤°ÊúâÁªôÂá∫ÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÔºå‰ΩÜËØ•Ê°ÜÊû∂‰∏∫ÂèØËß£ÈáäÁöÑ„ÄÅÂÖ≥ÈîÆÂ∏ßÂºïÂØºÁöÑ„ÄÅ‰ª•Âèä‰∏ä‰∏ãÊñáÊÑüÁü•ÁöÑÊñáÊú¨Âà∞Âä®ÁîªÂ•†ÂÆö‰∫ÜÊñ∞ÁöÑÂü∫Á°Ä„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËôöÊãüÁé∞ÂÆû„ÄÅÊ∏∏ÊàèÂºÄÂèë„ÄÅÂú®Á∫øÊïôËÇ≤„ÄÅÊï∞Â≠ó‰∫∫Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊñáÊú¨È©±Âä®ÔºåÂèØ‰ª•Âø´ÈÄüÁîüÊàêÂêÑÁßçË°®ÊÉÖÂíåÂä®‰ΩúÁöÑ‰∫∫ËÑ∏Âä®ÁîªÔºåÊèêÈ´òÂÜÖÂÆπÂàõ‰ΩúÊïàÁéáÂíåÁî®Êà∑‰ΩìÈ™å„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂ∫îÁî®‰∫é‰∏™ÊÄßÂåñËôöÊãüÂä©Êâã„ÄÅÊÉÖÊÑüÈô™‰º¥Êú∫Âô®‰∫∫Á≠âÈ¢ÜÂüüÔºåÂÆûÁé∞Êõ¥Ëá™ÁÑ∂„ÄÅÊõ¥Êô∫ËÉΩÁöÑ‰∫∫Êú∫‰∫§‰∫í„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Generating dynamic 3D facial animation from natural language requires understanding both temporally structured semantics and fine-grained expression changes. Existing datasets and methods mainly focus on speech-driven animation or unstructured expression sequences and therefore lack the semantic grounding and temporal structures needed for expressive human performance generation. In this work, we introduce KeyframeFace, a large-scale multimodal dataset designed for text-to-animation research through keyframe-level supervision. KeyframeFace provides 2,100 expressive scripts paired with monocular videos, per-frame ARKit coefficients, contextual backgrounds, complex emotions, manually defined keyframes, and multi-perspective annotations based on ARKit coefficients and images via Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs). Beyond the dataset, we propose the first text-to-animation framework that explicitly leverages LLM priors for interpretable facial motion synthesis. This design aligns the semantic understanding capabilities of LLMs with the interpretable structure of ARKit's coefficients, enabling high-fidelity expressive animation. KeyframeFace and our LLM-based framework together establish a new foundation for interpretable, keyframe-guided, and context-aware text-to-animation. Code and data are available at https://github.com/wjc12345123/KeyframeFace.

