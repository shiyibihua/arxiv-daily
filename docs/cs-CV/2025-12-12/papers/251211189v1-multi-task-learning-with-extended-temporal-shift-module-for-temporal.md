---
layout: default
title: Multi-task Learning with Extended Temporal Shift Module for Temporal Action Localization
---

# Multi-task Learning with Extended Temporal Shift Module for Temporal Action Localization

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.11189" target="_blank" class="toolbar-btn">arXiv: 2512.11189v1</a>
    <a href="https://arxiv.org/pdf/2512.11189.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.11189v1" 
            onclick="toggleFavorite(this, '2512.11189v1', 'Multi-task Learning with Extended Temporal Shift Module for Temporal Action Localization')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Anh-Kiet Duong, Petra Gomez-Kr√§mer

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-12

**Â§áÊ≥®**: BinEgo360@ICCV25

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Êâ©Â±ïÊó∂Â∫è‰ΩçÁßªÊ®°ÂùóÁöÑÂ§ö‰ªªÂä°Â≠¶‰π†ÊñπÊ≥ïÔºåÁî®‰∫éÊó∂Â∫èÂä®‰ΩúÂÆö‰Ωç**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Êó∂Â∫èÂä®‰ΩúÂÆö‰Ωç` `Â§ö‰ªªÂä°Â≠¶‰π†` `Êó∂Â∫è‰ΩçÁßªÊ®°Âùó` `Â§öËßÜËßíËßÜÈ¢ë` `Â§öÊ®°ÊÄÅËûçÂêà` `ËßÜÈ¢ëÁêÜËß£` `Ë°å‰∏∫ËØÜÂà´`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂà©Áî®Â§öËßÜËßí„ÄÅÂ§öÊ®°ÊÄÅËßÜÈ¢ë‰∏≠ÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØËøõË°åÁ≤æÁ°ÆÊó∂Â∫èÂä®‰ΩúÂÆö‰Ωç„ÄÇ
2. ÈÄöËøáÊâ©Â±ïÊó∂Â∫è‰ΩçÁßªÊ®°ÂùóÔºåÂπ∂ÁªìÂêàÂ§ö‰ªªÂä°Â≠¶‰π†Ê°ÜÊû∂ÔºåÂêåÊó∂‰ºòÂåñÂú∫ÊôØÂàÜÁ±ªÂíåÂä®‰ΩúÂÆö‰Ωç„ÄÇ
3. Âú®BinEgo-360ÊåëÊàòËµõ‰∏≠ÂèñÂæóÁ¨¨‰∏ÄÂêçÔºåÈ™åËØÅ‰∫ÜËØ•ÊñπÊ≥ïÂú®Â§öËßÜËßí„ÄÅÂ§öÊ®°ÊÄÅËßÜÈ¢ëÂä®‰ΩúÂÆö‰Ωç‰∏äÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫ÜÈíàÂØπICCV 2025 BinEgo-360ÊåëÊàòËµõÁöÑÊó∂Â∫èÂä®‰ΩúÂÆö‰ΩçÔºàTALÔºâËß£ÂÜ≥ÊñπÊ°àÔºåËØ•ÊåëÊàòËµõÂÖ≥Ê≥®Â§öËßÜËßíÂíåÂ§öÊ®°ÊÄÅËßÜÈ¢ëÁéØÂ¢É‰∏ãÁöÑÂä®‰ΩúÂÆö‰Ωç„ÄÇÊåëÊàòËµõÊèê‰æõÂåÖÂê´ÂÖ®ÊôØ„ÄÅÁ¨¨‰∏â‰∫∫Áß∞Âíå‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑÂΩïÂÉèÊï∞ÊçÆÈõÜÔºåÂπ∂Ê†áÊ≥®‰∫ÜÁªÜÁ≤íÂ∫¶ÁöÑÂä®‰ΩúÁ±ªÂà´„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂü∫‰∫éÊó∂Â∫è‰ΩçÁßªÊ®°ÂùóÔºàTSMÔºâÔºåÈÄöËøáÂºïÂÖ•ËÉåÊôØÁ±ªÂπ∂ÂØπÂõ∫ÂÆöÈïøÂ∫¶ÁöÑÈùûÈáçÂè†Èó¥ÈöîËøõË°åÂàÜÁ±ªÔºåÂ∞ÜÂÖ∂Êâ©Â±ïÂà∞Â§ÑÁêÜTAL„ÄÇÊàë‰ª¨ÈááÁî®Â§ö‰ªªÂä°Â≠¶‰π†Ê°ÜÊû∂ÔºåËÅîÂêà‰ºòÂåñÂú∫ÊôØÂàÜÁ±ªÂíåTALÔºå‰ªéËÄåÂà©Áî®Âä®‰ΩúÂíåÁéØÂ¢É‰πãÈó¥ÁöÑ‰∏ä‰∏ãÊñáÁ∫øÁ¥¢„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ÈÄöËøáÂä†ÊùÉÈõÜÊàêÁ≠ñÁï•Êï¥ÂêàÂ§ö‰∏™Ê®°ÂûãÔºåÊèêÈ´ò‰∫ÜÈ¢ÑÊµãÁöÑÈ≤ÅÊ£íÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ÊØîËµõÁöÑÂàùÂßãÂíåÊâ©Â±ïËΩÆÊ¨°‰∏≠ÂùáÊéíÂêçÁ¨¨‰∏ÄÔºåËØÅÊòé‰∫ÜÂ§ö‰ªªÂä°Â≠¶‰π†„ÄÅÈ´òÊïàÈ™®Âπ≤ÁΩëÁªúÂíåÈõÜÊàêÂ≠¶‰π†Áõ∏ÁªìÂêàÂú®TAL‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öËßÜËßí„ÄÅÂ§öÊ®°ÊÄÅËßÜÈ¢ë‰∏≠ÁöÑÊó∂Â∫èÂä®‰ΩúÂÆö‰ΩçÔºàTALÔºâÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Èöæ‰ª•ÊúâÊïàÂà©Áî®‰∏çÂêåËßÜËßíÂíåÊ®°ÊÄÅ‰πãÈó¥ÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºåÂØºËá¥Âä®‰ΩúÂÆö‰ΩçÁ≤æÂ∫¶‰∏çÈ´òÔºåÂ∞§ÂÖ∂ÊòØÂú®ÁªÜÁ≤íÂ∫¶Âä®‰ΩúËØÜÂà´ÊñπÈù¢Ë°®Áé∞‰∏çË∂≥„ÄÇÊ≠§Â§ñÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞Â∞ÜÂú∫ÊôØ‰ø°ÊÅØËûçÂÖ•Âà∞Âä®‰ΩúÂÆö‰Ωç‰ªªÂä°‰∏≠‰πüÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Â§ö‰ªªÂä°Â≠¶‰π†Ê°ÜÊû∂ÔºåÂêåÊó∂Â≠¶‰π†Âú∫ÊôØÂàÜÁ±ªÂíåÊó∂Â∫èÂä®‰ΩúÂÆö‰Ωç„ÄÇÈÄöËøáÂÖ±‰∫´Â∫ïÂ±ÇÁâπÂæÅË°®Á§∫ÔºåÂú∫ÊôØÂàÜÁ±ª‰ªªÂä°ÂèØ‰ª•‰∏∫Âä®‰ΩúÂÆö‰Ωç‰ªªÂä°Êèê‰æõ‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òÂä®‰ΩúÂÆö‰ΩçÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÊâ©Â±ï‰∫ÜÊó∂Â∫è‰ΩçÁßªÊ®°ÂùóÔºàTSMÔºâÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂ§ÑÁêÜTAL‰ªªÂä°ÔºåÂπ∂ÂºïÂÖ•ËÉåÊôØÁ±ªÊù•Âå∫ÂàÜÈùûÂä®‰ΩúÁâáÊÆµ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºö‰ΩøÁî®Âç∑ÁßØÁ•ûÁªèÁΩëÁªúÔºàCNNÔºâÊèêÂèñËßÜÈ¢ëÂ∏ßÁöÑËßÜËßâÁâπÂæÅ„ÄÇ2) Êó∂Â∫èÂª∫Ê®°Ê®°ÂùóÔºö‰ΩøÁî®Êâ©Â±ïÁöÑÊó∂Â∫è‰ΩçÁßªÊ®°ÂùóÔºàTSMÔºâÂØπËßÜÈ¢ëÂ∫èÂàóËøõË°åÊó∂Â∫èÂª∫Ê®°ÔºåÊçïÊçâÂä®‰ΩúÁöÑÊó∂Â∫èÂä®ÊÄÅ„ÄÇ3) Â§ö‰ªªÂä°Â≠¶‰π†Ê®°ÂùóÔºöÂêåÊó∂ËøõË°åÂú∫ÊôØÂàÜÁ±ªÂíåÊó∂Â∫èÂä®‰ΩúÂÆö‰ΩçÔºåÂÖ±‰∫´Â∫ïÂ±ÇÁâπÂæÅË°®Á§∫„ÄÇ4) ÈõÜÊàêÊ®°ÂùóÔºöÈÄöËøáÂä†ÊùÉÈõÜÊàêÂ§ö‰∏™Ê®°ÂûãÁöÑÈ¢ÑÊµãÁªìÊûúÔºåÊèêÈ´òÈ¢ÑÊµãÁöÑÈ≤ÅÊ£íÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞ÁÇπÂú®‰∫éÔºö1) Êâ©Â±ï‰∫ÜÊó∂Â∫è‰ΩçÁßªÊ®°ÂùóÔºàTSMÔºâÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂ§ÑÁêÜÊó∂Â∫èÂä®‰ΩúÂÆö‰Ωç‰ªªÂä°ÔºåÂπ∂ÂºïÂÖ•ËÉåÊôØÁ±ª„ÄÇ2) ÊèêÂá∫‰∫ÜÂ§ö‰ªªÂä°Â≠¶‰π†Ê°ÜÊû∂ÔºåËÅîÂêà‰ºòÂåñÂú∫ÊôØÂàÜÁ±ªÂíåÊó∂Â∫èÂä®‰ΩúÂÆö‰ΩçÔºå‰ªéËÄåÂà©Áî®Âú∫ÊôØ‰∏ä‰∏ãÊñá‰ø°ÊÅØÊèêÈ´òÂä®‰ΩúÂÆö‰ΩçÁ≤æÂ∫¶„ÄÇ3) ÈááÁî®‰∫ÜÂä†ÊùÉÈõÜÊàêÁ≠ñÁï•ÔºåÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Â§ö‰ªªÂä°Â≠¶‰π†Ê°ÜÊû∂‰∏≠Ôºå‰ΩøÁî®‰∫Ü‰∫§ÂèâÁÜµÊçüÂ§±ÂáΩÊï∞Êù•‰ºòÂåñÂú∫ÊôØÂàÜÁ±ªÂíåÊó∂Â∫èÂä®‰ΩúÂÆö‰Ωç‰ªªÂä°„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊÄªÊçüÂ§±ÂáΩÊï∞ÊòØÂú∫ÊôØÂàÜÁ±ªÊçüÂ§±ÂíåÂä®‰ΩúÂÆö‰ΩçÊçüÂ§±ÁöÑÂä†ÊùÉÂíå„ÄÇÊùÉÈáçÁöÑÈÄâÊã©ÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰ΩìÊï∞ÊçÆÈõÜËøõË°åË∞ÉÊï¥Ôºå‰ª•Âπ≥Ë°°‰∏§‰∏™‰ªªÂä°ÁöÑÂ≠¶‰π†ËøõÂ∫¶„ÄÇÂú®Êâ©Â±ïÁöÑTSM‰∏≠ÔºåÈÄöËøáË∞ÉÊï¥‰ΩçÁßªÊìç‰ΩúÁöÑÂèÇÊï∞ÔºåÂèØ‰ª•ÊéßÂà∂Ê®°ÂûãÂØπÊó∂Â∫è‰ø°ÊÅØÁöÑÊïèÊÑüÁ®ãÂ∫¶„ÄÇÊ≠§Â§ñÔºåÂú®ÈõÜÊàêÊ®°Âùó‰∏≠Ôºå‰ΩøÁî®‰∫ÜÂä†ÊùÉÂπ≥ÂùáÁ≠ñÁï•ÔºåÊùÉÈáçÁöÑÈÄâÊã©ÂèØ‰ª•Âü∫‰∫éÊ®°ÂûãÂú®È™åËØÅÈõÜ‰∏äÁöÑÊÄßËÉΩËøõË°å‰ºòÂåñ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËØ•ÊñπÊ≥ïÂú®BinEgo-360ÊåëÊàòËµõ‰∏≠ÂèñÂæó‰∫ÜÁ¨¨‰∏ÄÂêçÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®Â§öËßÜËßí„ÄÅÂ§öÊ®°ÊÄÅËßÜÈ¢ëÊó∂Â∫èÂä®‰ΩúÂÆö‰ΩçÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÈÄöËøáÂ§ö‰ªªÂä°Â≠¶‰π†ÂíåÈõÜÊàêÁ≠ñÁï•ÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞Âà©Áî®Âú∫ÊôØ‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºåÊèêÈ´òÂä®‰ΩúÂÆö‰ΩçÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜÊØîËµõÊéíÂêçËØÅÊòé‰∫ÜÂÖ∂‰ºòË∂äÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩÁõëÊéß„ÄÅ‰∫∫Êú∫‰∫§‰∫í„ÄÅÊú∫Âô®‰∫∫ÂØºËà™Á≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Êô∫ËÉΩÁõëÊéß‰∏≠ÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïËá™Âä®Ê£ÄÊµãÂºÇÂ∏∏Ë°å‰∏∫ÔºõÂú®‰∫∫Êú∫‰∫§‰∫í‰∏≠ÔºåÂèØ‰ª•ËØÜÂà´Áî®Êà∑ÁöÑÂä®‰ΩúÊÑèÂõæÔºå‰ªéËÄåÊèê‰æõÊõ¥Ëá™ÁÑ∂„ÄÅÊõ¥Êô∫ËÉΩÁöÑ‰∫§‰∫í‰ΩìÈ™åÔºõÂú®Êú∫Âô®‰∫∫ÂØºËà™‰∏≠ÔºåÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫ÁêÜËß£Âë®Âõ¥ÁéØÂ¢ÉÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÂÆåÊàê‰ªªÂä°„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We present our solution to the BinEgo-360 Challenge at ICCV 2025, which focuses on temporal action localization (TAL) in multi-perspective and multi-modal video settings. The challenge provides a dataset containing panoramic, third-person, and egocentric recordings, annotated with fine-grained action classes. Our approach is built on the Temporal Shift Module (TSM), which we extend to handle TAL by introducing a background class and classifying fixed-length non-overlapping intervals. We employ a multi-task learning framework that jointly optimizes for scene classification and TAL, leveraging contextual cues between actions and environments. Finally, we integrate multiple models through a weighted ensemble strategy, which improves robustness and consistency of predictions. Our method is ranked first in both the initial and extended rounds of the competition, demonstrating the effectiveness of combining multi-task learning, an efficient backbone, and ensemble learning for TAL.

