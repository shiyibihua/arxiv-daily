---
layout: default
title: UFVideo: Towards Unified Fine-Grained Video Cooperative Understanding with Large Language Models
---

# UFVideo: Towards Unified Fine-Grained Video Cooperative Understanding with Large Language Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.11336" target="_blank" class="toolbar-btn">arXiv: 2512.11336v1</a>
    <a href="https://arxiv.org/pdf/2512.11336.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.11336v1" 
            onclick="toggleFavorite(this, '2512.11336v1', 'UFVideo: Towards Unified Fine-Grained Video Cooperative Understanding with Large Language Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Hewen Pan, Cong Wei, Dashuang Liang, Zepeng Huang, Pengfei Gao, Ziqi Zhou, Lulu Xue, Pengfei Yan, Xiaoming Wei, Minghui Li, Shengshan Hu

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-12

**Â§áÊ≥®**: 22 pages, 13 figures, technical report

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫UFVideoÔºåÂÆûÁé∞Áªü‰∏ÄÁöÑÂ§öÁ≤íÂ∫¶ËßÜÈ¢ëÂçèÂêåÁêÜËß£ÔºåË∂ÖË∂äÁé∞ÊúâVideo LLM„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÁêÜËß£` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ËßÜËßâ-ËØ≠Ë®ÄÂØπÈΩê` `Â§öÁ≤íÂ∫¶ÁêÜËß£`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVideo LLM‰∏ìÊ≥®‰∫éÁâπÂÆö‰ªªÂä°ÔºåÁº∫‰πèÂÖ®Èù¢ÂíåÂ§öÁ≤íÂ∫¶ÁöÑËßÜÈ¢ëÁêÜËß£ËÉΩÂäõ„ÄÇ
2. UFVideoÈÄöËøáÁªü‰∏ÄÁöÑËßÜËßâ-ËØ≠Ë®ÄÂºïÂØºÂØπÈΩêÔºåÂú®Âçï‰∏ÄÊ®°Âûã‰∏≠Â§ÑÁêÜÂÖ®Â±Ä„ÄÅÂÉèÁ¥†ÂíåÊó∂Èó¥Â∞∫Â∫¶ÁöÑËßÜÈ¢ëÁêÜËß£„ÄÇ
3. UFVideo-BenchËØÑ‰º∞Â§öÁ≤íÂ∫¶ËßÜÈ¢ëÁêÜËß£ÔºåËØÅÊòéUFVideo‰ºò‰∫éGPT-4oÔºåÂπ∂Âú®9‰∏™Âü∫ÂáÜÊµãËØï‰∏≠È™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑËøõÊ≠•ÔºåËßÜÈ¢ëLLMsÂæóÂà∞‰∫ÜËøõ‰∏ÄÊ≠•ÂèëÂ±ïÔºå‰ª•ÊâßË°åÊï¥‰ΩìÂíå‰∏ì‰∏öÁöÑËßÜÈ¢ëÁêÜËß£„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÂ∑•‰Ωú‰ªÖÈôê‰∫é‰∏ìÈó®ÁöÑËßÜÈ¢ëÁêÜËß£‰ªªÂä°ÔºåÊú™ËÉΩÂÆûÁé∞ÂÖ®Èù¢ÂíåÂ§öÁ≤íÂ∫¶ÁöÑËßÜÈ¢ëÊÑüÁü•„ÄÇ‰∏∫‰∫ÜÂº•ÂêàËøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨Êé®Âá∫‰∫ÜUFVideoÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™ÂÖ∑ÊúâÁªü‰∏ÄÂ§öÁ≤íÂ∫¶ÂçèÂêåÁêÜËß£ËÉΩÂäõÁöÑËßÜÈ¢ëLLM„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ËÆæËÆ°‰∫ÜÁªü‰∏ÄÁöÑËßÜËßâ-ËØ≠Ë®ÄÂºïÂØºÂØπÈΩêÔºå‰ª•Âú®Âçï‰∏™Ê®°Âûã‰∏≠ÁÅµÊ¥ªÂú∞Â§ÑÁêÜË∑®ÂÖ®Â±Ä„ÄÅÂÉèÁ¥†ÂíåÊó∂Èó¥Â∞∫Â∫¶ÁöÑËßÜÈ¢ëÁêÜËß£„ÄÇUFVideoÂä®ÊÄÅÂú∞ÁºñÁ†Å‰∏çÂêå‰ªªÂä°ÁöÑËßÜËßâÂíåÊñáÊú¨ËæìÂÖ•ÔºåÂπ∂ÁîüÊàêÊñáÊú¨ÂìçÂ∫î„ÄÅÊó∂Èó¥ÂÆö‰ΩçÊàñÊé•Âú∞ÁöÑÊé©Á†Å„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫ÜËØÑ‰º∞ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂ§öÁ≤íÂ∫¶ËßÜÈ¢ëÁêÜËß£‰ªªÂä°ÔºåÊàë‰ª¨ÊûÑÂª∫‰∫ÜUFVideo-BenchÔºåÂÆÉÁî±Â∞∫Â∫¶ÂÜÖÁöÑ‰∏â‰∏™‰∏çÂêåÁöÑÂçè‰Ωú‰ªªÂä°ÁªÑÊàêÔºåËøôËØÅÊòé‰∫ÜUFVideoÁõ∏ÂØπ‰∫éGPT-4oÁöÑÁÅµÊ¥ªÊÄßÂíå‰ºòÂäø„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Âú®Ê∂µÁõñÂêÑÁßçÂ∏∏ËßÅËßÜÈ¢ëÁêÜËß£‰ªªÂä°ÁöÑ9‰∏™ÂÖ¨ÂÖ±Âü∫ÂáÜ‰∏äÈ™åËØÅ‰∫ÜÊàë‰ª¨Ê®°ÂûãÁöÑÊúâÊïàÊÄßÔºå‰∏∫Êú™Êù•ÁöÑËßÜÈ¢ëLLMsÊèê‰æõ‰∫ÜÊúâ‰ª∑ÂÄºÁöÑËßÅËß£„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâVideo LLMÈÄöÂ∏∏ÈíàÂØπÁâπÂÆöËßÜÈ¢ëÁêÜËß£‰ªªÂä°ËøõË°å‰ºòÂåñÔºå‰æãÂ¶ÇËßÜÈ¢ëÊèèËø∞„ÄÅÂä®‰ΩúËØÜÂà´Á≠âÔºåÁº∫‰πè‰∏ÄÁßçËÉΩÂ§üÂêåÊó∂Â§ÑÁêÜÂÖ®Â±ÄËØ≠‰πâÁêÜËß£„ÄÅÂÉèÁ¥†Á∫ßÁªÜËäÇÊÑüÁü•ÂíåÊó∂Èó¥Áª¥Â∫¶Êé®ÁêÜÁöÑÁªü‰∏ÄÊ°ÜÊû∂„ÄÇËøôÈôêÂà∂‰∫ÜÊ®°ÂûãÂú®Â§çÊùÇÂú∫ÊôØ‰∏ãÁöÑÂ∫îÁî®Ôºå‰æãÂ¶ÇÈúÄË¶ÅÁªìÂêàÂÖ®Â±Ä‰∏ä‰∏ãÊñáËøõË°åÁ≤æÁªÜÂÆö‰ΩçÁöÑ‰ªªÂä°„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•Âú®‰∏çÂêåÁ≤íÂ∫¶Â±ÇÈù¢‰∏äËøõË°åÂçèÂêåÁêÜËß£ÔºåÂØºËá¥ÊÄßËÉΩÁì∂È¢à„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöUFVideoÁöÑÊ†∏ÂøÉÂú®‰∫éËÆæËÆ°‰∏Ä‰∏™Áªü‰∏ÄÁöÑËßÜËßâ-ËØ≠Ë®ÄÂºïÂØºÂØπÈΩêÊú∫Âà∂Ôºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÁÅµÊ¥ªÂú∞Â§ÑÁêÜ‰∏çÂêåÁ≤íÂ∫¶ÁöÑËßÜÈ¢ëÁêÜËß£‰ªªÂä°„ÄÇÈÄöËøáÂä®ÊÄÅÁºñÁ†ÅËßÜËßâÂíåÊñáÊú¨ËæìÂÖ•ÔºåÂπ∂ÁîüÊàêÁõ∏Â∫îÁöÑÊñáÊú¨ÂìçÂ∫î„ÄÅÊó∂Èó¥ÂÆö‰ΩçÊàñÂàÜÂâ≤Êé©Á†ÅÔºåÂÆûÁé∞ÂÖ®Â±Ä„ÄÅÂÉèÁ¥†ÂíåÊó∂Èó¥Â∞∫Â∫¶‰∏äÁöÑÂçèÂêåÁêÜËß£„ÄÇËøôÁßçËÆæËÆ°ÂÖÅËÆ∏Ê®°ÂûãÊ†πÊçÆ‰ªªÂä°ÈúÄÊ±ÇËá™ÈÄÇÂ∫îÂú∞Ë∞ÉÊï¥ÂÖ≥Ê≥®ÁÇπÔºå‰ªéËÄåÊèêÈ´òÊï¥‰ΩìÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöUFVideoÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ËßÜÈ¢ëÁºñÁ†ÅÂô®ÔºöÁî®‰∫éÊèêÂèñËßÜÈ¢ëÂ∏ßÁöÑËßÜËßâÁâπÂæÅ„ÄÇ2) ÊñáÊú¨ÁºñÁ†ÅÂô®ÔºöÁî®‰∫éÊèêÂèñÊñáÊú¨ËæìÂÖ•ÁöÑËØ≠‰πâ‰ø°ÊÅØ„ÄÇ3) ËßÜËßâ-ËØ≠Ë®ÄÂØπÈΩêÊ®°ÂùóÔºöÂ∞ÜËßÜËßâÁâπÂæÅÂíåÊñáÊú¨ÁâπÂæÅËøõË°åÂØπÈΩêÔºåÂª∫Á´ãË∑®Ê®°ÊÄÅÁöÑÂÖ≥ËÅî„ÄÇ4) ‰ªªÂä°Ëß£Á†ÅÂô®ÔºöÊ†πÊçÆ‰ªªÂä°Á±ªÂûãÔºåÁîüÊàêÁõ∏Â∫îÁöÑËæìÂá∫Ôºå‰æãÂ¶ÇÊñáÊú¨ÊèèËø∞„ÄÅÊó∂Èó¥ÂÆö‰ΩçÊàñÂàÜÂâ≤Êé©Á†Å„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØÁ´ØÂà∞Á´ØÂèØËÆ≠ÁªÉÁöÑÔºåÂÖÅËÆ∏Ê®°ÂûãÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠Ëá™Âä®Â≠¶‰π†ÊúÄ‰Ω≥ÁöÑÁâπÂæÅË°®Á§∫ÂíåÂØπÈΩêÁ≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöUFVideoÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂÖ∂Áªü‰∏ÄÁöÑËßÜËßâ-ËØ≠Ë®ÄÂºïÂØºÂØπÈΩêÊú∫Âà∂„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ï‰∏çÂêåÔºåUFVideo‰∏çÊòØÈíàÂØπÊØè‰∏™‰ªªÂä°ÂçïÁã¨ËÆæËÆ°Ê®°ÂûãÔºåËÄåÊòØÈááÁî®‰∏ÄÁßçÈÄöÁî®ÁöÑÊ°ÜÊû∂ÔºåÈÄöËøáÂä®ÊÄÅË∞ÉÊï¥ËßÜËßâÂíåÊñáÊú¨ËæìÂÖ•ÁöÑÁºñÁ†ÅÊñπÂºèÔºå‰ª•Âèä‰ªªÂä°Ëß£Á†ÅÂô®ÁöÑÁªìÊûÑÔºåÊù•ÈÄÇÂ∫î‰∏çÂêåÁöÑ‰ªªÂä°ÈúÄÊ±Ç„ÄÇËøôÁßçËÆæËÆ°‰ΩøÂæóUFVideoÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÊ≥õÂåñËÉΩÂäõÂíåÁÅµÊ¥ªÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËßÜËßâ-ËØ≠Ë®ÄÂØπÈΩêÊ®°Âùó‰∏≠ÔºåÈááÁî®‰∫ÜÊ≥®ÊÑèÂäõÊú∫Âà∂Êù•Âä®ÊÄÅÂú∞Ë∞ÉÊï¥ËßÜËßâÁâπÂæÅÂíåÊñáÊú¨ÁâπÂæÅÁöÑÊùÉÈáçÔºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÊõ¥Âä†ÂÖ≥Ê≥®‰∏é‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÈÉ®ÂàÜ„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫ÜÊõ¥Â•ΩÂú∞Â§ÑÁêÜÊó∂Èó¥Áª¥Â∫¶‰∏äÁöÑ‰ø°ÊÅØÔºå‰ΩøÁî®‰∫ÜTransformerÁªìÊûÑÊù•Âª∫Ê®°ËßÜÈ¢ëÂ∏ß‰πãÈó¥ÁöÑ‰æùËµñÂÖ≥Á≥ª„ÄÇÊçüÂ§±ÂáΩÊï∞ÊñπÈù¢ÔºåÈááÁî®‰∫ÜÂ§ö‰ªªÂä°Â≠¶‰π†ÁöÑÊñπÂºèÔºåÂêåÊó∂‰ºòÂåñÊñáÊú¨ÁîüÊàê„ÄÅÊó∂Èó¥ÂÆö‰ΩçÂíåÂàÜÂâ≤Êé©Á†ÅÁöÑÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

UFVideoÂú®UFVideo-Bench‰∏äÊòæËëó‰ºò‰∫éGPT-4oÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®Â§öÁ≤íÂ∫¶ËßÜÈ¢ëÁêÜËß£ÊñπÈù¢ÁöÑ‰ºòÂäø„ÄÇÊ≠§Â§ñÔºåÂú®9‰∏™ÂÖ¨ÂÖ±Âü∫ÂáÜÊµãËØï‰∏≠ÔºåUFVideo‰πüÂèñÂæó‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÁªìÊûúÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®ÂêÑÁßçÂ∏∏ËßÅËßÜÈ¢ëÁêÜËß£‰ªªÂä°‰∏äÁöÑÊúâÊïàÊÄß„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Âú®ÊëòË¶Å‰∏≠ÊòéÁ°ÆÁªôÂá∫Ôºå‰ΩÜÂº∫Ë∞É‰∫ÜÂÖ∂‰ºò‰∫éGPT-4oÁöÑÁªìËÆ∫„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

UFVideoÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÊô∫ËÉΩÁõëÊéß„ÄÅËßÜÈ¢ëÁºñËæë„ÄÅËá™Âä®È©æÈ©∂„ÄÅÂåªÁñóÂΩ±ÂÉèÂàÜÊûêÁ≠âÈ¢ÜÂüü„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÁêÜËß£ÁõëÊéßËßÜÈ¢ë‰∏≠ÁöÑÂºÇÂ∏∏Ë°å‰∏∫ÔºåËæÖÂä©ËßÜÈ¢ëÁºñËæë‰∫∫ÂëòËøõË°åÂÜÖÂÆπÂàõ‰ΩúÔºåÊèêÈ´òËá™Âä®È©æÈ©∂Á≥ªÁªüÁöÑÁéØÂ¢ÉÊÑüÁü•ËÉΩÂäõÔºå‰ª•ÂèäÂ∏ÆÂä©ÂåªÁîüÂàÜÊûêÂåªÁñóÂΩ±ÂÉèÊï∞ÊçÆ„ÄÇÊú™Êù•ÔºåUFVideoÊúâÊúõÊàê‰∏∫ÂêÑÁßçËßÜÈ¢ëÁêÜËß£Â∫îÁî®ÁöÑÂü∫Á°ÄÊ®°Âûã„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> With the advancement of multi-modal Large Language Models (LLMs), Video LLMs have been further developed to perform on holistic and specialized video understanding. However, existing works are limited to specialized video understanding tasks, failing to achieve a comprehensive and multi-grained video perception. To bridge this gap, we introduce UFVideo, the first Video LLM with unified multi-grained cooperative understanding capabilities. Specifically, we design unified visual-language guided alignment to flexibly handle video understanding across global, pixel and temporal scales within a single model. UFVideo dynamically encodes the visual and text inputs of different tasks and generates the textual response, temporal localization, or grounded mask. Additionally, to evaluate challenging multi-grained video understanding tasks, we construct the UFVideo-Bench consisting of three distinct collaborative tasks within the scales, which demonstrates UFVideo's flexibility and advantages over GPT-4o. Furthermore, we validate the effectiveness of our model across 9 public benchmarks covering various common video understanding tasks, providing valuable insights for future Video LLMs.

