---
layout: default
title: MoirÃ©XNet: Adaptive Multi-Scale DemoirÃ©ing with Linear Attention Test-Time Training and Truncated Flow Matching Prior
---

# MoirÃ©XNet: Adaptive Multi-Scale DemoirÃ©ing with Linear Attention Test-Time Training and Truncated Flow Matching Prior

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15929" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15929v1</a>
  <a href="https://arxiv.org/pdf/2506.15929.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15929v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15929v1', 'MoirÃ©XNet: Adaptive Multi-Scale DemoirÃ©ing with Linear Attention Test-Time Training and Truncated Flow Matching Prior')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Liangyan Li, Yimo Ning, Kevin Le, Wei Dong, Yunzhe Li, Jun Chen, Xiaohong Liu

**åˆ†ç±»**: cs.CV, cs.AI, eess.IV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMoirÃ©XNetä»¥è§£å†³å›¾åƒè§†é¢‘å»æ‘©å°”çº¹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å»æ‘©å°”çº¹` `å›¾åƒæ¢å¤` `æ·±åº¦å­¦ä¹ ` `æœ€å¤§åéªŒä¼°è®¡` `çº¿æ€§æ³¨æ„åŠ›` `æˆªæ–­æµåŒ¹é…` `éçº¿æ€§æ˜ å°„`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å»æ‘©å°”çº¹æ–¹æ³•åœ¨å¤„ç†éçº¿æ€§é™è§£æ—¶å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆå»é™¤æ‘©å°”çº¹æˆ–å¯¼è‡´å›¾åƒç»†èŠ‚æŸå¤±ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆMAPæ¡†æ¶ï¼Œç»“åˆçº¿æ€§æ³¨æ„åŠ›çš„æµ‹è¯•æ—¶è®­ç»ƒå’Œæˆªæ–­æµåŒ¹é…å…ˆéªŒï¼Œç›´æ¥å­¦ä¹ RAWåˆ°sRGBçš„éçº¿æ€§æ˜ å°„ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å»æ‘©å°”çº¹æ•ˆæœä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ¢å¤é«˜é¢‘ç»†èŠ‚å¹¶æŠ‘åˆ¶ä¼ªå½±ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å›¾åƒå’Œè§†é¢‘å»æ‘©å°”çº¹æ¡†æ¶ï¼Œé€šè¿‡å°†æœ€å¤§åéªŒä¼°è®¡ï¼ˆMAPï¼‰ä¸å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æŠ€æœ¯ç›¸ç»“åˆï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨å»æ‘©å°”çº¹è¿‡ç¨‹ä¸­é¢ä¸´çš„éçº¿æ€§é™è§£é—®é¢˜ã€‚ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ æ–¹æ³•å¾€å¾€æ— æ³•å®Œå…¨å»é™¤æ‘©å°”çº¹ï¼Œæˆ–å¯¼è‡´å›¾åƒè¿‡äºå¹³æ»‘ï¼Œä¸»è¦ç”±äºæ¨¡å‹èƒ½åŠ›å—é™å’Œè®­ç»ƒæ•°æ®ç¨€ç¼ºã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆçš„MAPæ¡†æ¶ï¼Œç»“åˆäº†é«˜æ•ˆçš„çº¿æ€§æ³¨æ„åŠ›æµ‹è¯•æ—¶è®­ç»ƒæ¨¡å—å’Œæˆªæ–­æµåŒ¹é…å…ˆéªŒï¼Œæ˜¾è‘—æé«˜äº†å»æ‘©å°”çº¹çš„æ•ˆæœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å›¾åƒå’Œè§†é¢‘ä¸­çš„æ‘©å°”çº¹å»é™¤é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†éçº¿æ€§é™è§£æ—¶ï¼Œå¾€å¾€æ— æ³•å®Œå…¨å»é™¤æ‘©å°”çº¹ï¼Œæˆ–å¯¼è‡´å›¾åƒç»†èŠ‚çš„è¿‡åº¦å¹³æ»‘ï¼Œå½±å“é‡å»ºè´¨é‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§æ··åˆçš„MAPæ¡†æ¶ï¼Œç»“åˆçº¿æ€§æ³¨æ„åŠ›çš„æµ‹è¯•æ—¶è®­ç»ƒæ¨¡å—å’Œæˆªæ–­æµåŒ¹é…å…ˆéªŒï¼Œæ—¨åœ¨ç›´æ¥å­¦ä¹ éçº¿æ€§æ˜ å°„å¹¶å¯¹è¾“å‡ºè¿›è¡Œç»†åŒ–ï¼Œä»è€Œæ›´å¥½åœ°æ¢å¤é«˜é¢‘ç»†èŠ‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯å¢å¼ºçš„ç›‘ç£å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡çº¿æ€§æ³¨æ„åŠ›çš„æµ‹è¯•æ—¶è®­ç»ƒç›´æ¥å­¦ä¹ RAWåˆ°sRGBçš„æ˜ å°„ï¼›å…¶æ¬¡æ˜¯æˆªæ–­æµåŒ¹é…å…ˆéªŒï¼Œç”¨äºè¿›ä¸€æ­¥å¯¹è¾“å‡ºè¿›è¡Œç»†åŒ–ï¼Œç¡®ä¿ä¸å¹²å‡€å›¾åƒåˆ†å¸ƒçš„å¯¹é½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†çº¿æ€§æ³¨æ„åŠ›ä¸ç”Ÿæˆæ¨¡å‹çš„ç»†åŒ–èƒ½åŠ›ç›¸ç»“åˆï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•åœ¨éçº¿æ€§å»æ‘©å°”çº¹ä¸­çš„å±€é™æ€§ï¼Œæ˜¾è‘—æå‡äº†æ¢å¤æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†é«˜æ•ˆçš„çº¿æ€§æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¼˜åŒ–äº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å‡½æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ åˆ°å¤æ‚çš„éçº¿æ€§æ˜ å°„å…³ç³»ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMoirÃ©XNetåœ¨å»æ‘©å°”çº¹ä»»åŠ¡ä¸­ç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æé«˜äº†20%ä»¥ä¸Šçš„å›¾åƒè´¨é‡è¯„åˆ†ï¼Œä¸”åœ¨é«˜é¢‘ç»†èŠ‚æ¢å¤æ–¹é¢è¡¨ç°å°¤ä¸ºçªå‡ºï¼Œæœ‰æ•ˆæŠ‘åˆ¶äº†ä¼ªå½±çš„äº§ç”Ÿã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨å›¾åƒå¤„ç†é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æ‘„å½±ã€è§†é¢‘åˆ¶ä½œå’Œæ•°å­—è‰ºæœ¯ç­‰è¡Œä¸šä¸­ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å›¾åƒè´¨é‡ï¼Œå»é™¤æ‘©å°”çº¹å¸¦æ¥çš„è§†è§‰å¹²æ‰°ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯æ‰©å±•åˆ°å…¶ä»–å›¾åƒæ¢å¤ä»»åŠ¡ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper introduces a novel framework for image and video demoirÃ©ing by integrating Maximum A Posteriori (MAP) estimation with advanced deep learning techniques. DemoirÃ©ing addresses inherently nonlinear degradation processes, which pose significant challenges for existing methods.
>   Traditional supervised learning approaches either fail to remove moirÃ© patterns completely or produce overly smooth results. This stems from constrained model capacity and scarce training data, which inadequately represent the clean image distribution and hinder accurate reconstruction of ground-truth images. While generative models excel in image restoration for linear degradations, they struggle with nonlinear cases such as demoirÃ©ing and often introduce artifacts.
>   To address these limitations, we propose a hybrid MAP-based framework that integrates two complementary components. The first is a supervised learning model enhanced with efficient linear attention Test-Time Training (TTT) modules, which directly learn nonlinear mappings for RAW-to-sRGB demoirÃ©ing. The second is a Truncated Flow Matching Prior (TFMP) that further refines the outputs by aligning them with the clean image distribution, effectively restoring high-frequency details and suppressing artifacts. These two components combine the computational efficiency of linear attention with the refinement abilities of generative models, resulting in improved restoration performance.

