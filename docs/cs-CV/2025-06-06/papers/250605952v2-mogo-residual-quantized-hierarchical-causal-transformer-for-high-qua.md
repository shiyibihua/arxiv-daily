---
layout: default
title: MOGO: Residual Quantized Hierarchical Causal Transformer for High-Quality and Real-Time 3D Human Motion Generation
---

# MOGO: Residual Quantized Hierarchical Causal Transformer for High-Quality and Real-Time 3D Human Motion Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05952" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05952v2</a>
  <a href="https://arxiv.org/pdf/2506.05952.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05952v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05952v2', 'MOGO: Residual Quantized Hierarchical Causal Transformer for High-Quality and Real-Time 3D Human Motion Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dongjie Fu, Tengjiao Sun, Pengcheng Fang, Xiaohao Cai, Hansung Kim

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06 (æ›´æ–°: 2025-08-07)

**å¤‡æ³¨**: 9 pages, 4 figures, conference

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMOGOä»¥è§£å†³é«˜è´¨é‡å®æ—¶3Däººç±»è¿åŠ¨ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `3Dè¿åŠ¨ç”Ÿæˆ` `å˜æ¢å™¨` `è‡ªå›å½’æ¡†æ¶` `æ®‹å·®é‡åŒ–` `å®æ—¶æ€§èƒ½` `æ–‡æœ¬æ¡ä»¶å¯¹é½` `è¿åŠ¨è¡¨ç¤º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ–‡æœ¬åˆ°è¿åŠ¨ç”Ÿæˆæ–¹æ³•åœ¨é«˜ä¿çœŸåº¦ã€å®æ—¶æ€§å’Œå¯æ‰©å±•æ€§æ–¹é¢é¢ä¸´æŒ‘æˆ˜ï¼Œéš¾ä»¥åŒæ—¶æ»¡è¶³è¿™äº›éœ€æ±‚ã€‚
2. MOGOé€šè¿‡å¼•å…¥MoSA-VQå’ŒRQHC-Transformeræ¨¡å—ï¼Œæä¾›äº†ä¸€ç§é«˜æ•ˆçš„è‡ªå›å½’æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨å•æ¬¡å‰å‘ä¼ é€’ä¸­ç”Ÿæˆè¿åŠ¨åºåˆ—ã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šï¼ŒMOGOçš„ç”Ÿæˆè´¨é‡ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“æˆ–æ›´ä¼˜ï¼ŒåŒæ—¶åœ¨å®æ—¶æ€§èƒ½å’Œæµåª’ä½“ç”Ÿæˆæ–¹é¢æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼ŒåŸºäºå˜æ¢å™¨çš„æ–‡æœ¬åˆ°è¿åŠ¨ç”ŸæˆæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œèƒ½å¤Ÿåˆæˆé«˜è´¨é‡çš„äººç±»è¿åŠ¨ã€‚ç„¶è€Œï¼Œå®ç°é«˜ä¿çœŸåº¦ã€æµåª’ä½“èƒ½åŠ›ã€å®æ—¶å“åº”å’Œå¯æ‰©å±•æ€§ä»ç„¶æ˜¯ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†MOGOï¼ˆMotion Generation with One-passï¼‰ï¼Œä¸€ç§æ–°é¢–çš„è‡ªå›å½’æ¡†æ¶ï¼Œæ—¨åœ¨é«˜æ•ˆä¸”å®æ—¶åœ°ç”Ÿæˆ3Dè¿åŠ¨ã€‚MOGOåŒ…å«ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šMoSA-VQï¼Œä¸€ä¸ªè¿åŠ¨å°ºåº¦è‡ªé€‚åº”æ®‹å·®å‘é‡é‡åŒ–æ¨¡å—ï¼Œèƒ½å¤Ÿåˆ†å±‚ç¦»æ•£è¿åŠ¨åºåˆ—å¹¶ç”Ÿæˆç´§å‡‘è€Œå¯Œæœ‰è¡¨ç°åŠ›çš„è¡¨ç¤ºï¼›RQHC-Transformerï¼Œä¸€ä¸ªæ®‹å·®é‡åŒ–å±‚æ¬¡å› æœå˜æ¢å™¨ï¼Œèƒ½å¤Ÿåœ¨å•æ¬¡å‰å‘ä¼ é€’ä¸­ç”Ÿæˆå¤šå±‚è¿åŠ¨æ ‡è®°ï¼Œæ˜¾è‘—é™ä½æ¨ç†å»¶è¿Ÿã€‚é€šè¿‡å¼•å…¥æ–‡æœ¬æ¡ä»¶å¯¹é½æœºåˆ¶ï¼Œè¿›ä¸€æ­¥æé«˜äº†è¿åŠ¨è§£ç çš„è¯­ä¹‰ä¿çœŸåº¦ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMOGOåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†ä¸ç°æœ‰æœ€å…ˆè¿›çš„å˜æ¢å™¨æ–¹æ³•ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›æˆ–æ›´ä¼˜çš„ç”Ÿæˆè´¨é‡ï¼ŒåŒæ—¶åœ¨å®æ—¶æ€§èƒ½ã€æµåª’ä½“ç”Ÿæˆå’Œé›¶-shotè®¾ç½®ä¸‹çš„æ³›åŒ–èƒ½åŠ›ä¸Šæœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é«˜è´¨é‡å®æ—¶3Däººç±»è¿åŠ¨ç”Ÿæˆä¸­çš„é«˜ä¿çœŸåº¦ã€æµåª’ä½“èƒ½åŠ›å’Œå®æ—¶å“åº”ç­‰åŸºæœ¬æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™äº›æ–¹é¢å­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼Œéš¾ä»¥æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMOGOçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡MoSA-VQå’ŒRQHC-Transformeræ¨¡å—ï¼Œé‡‡ç”¨è‡ªå›å½’æ¡†æ¶å®ç°é«˜æ•ˆçš„è¿åŠ¨ç”Ÿæˆï¼Œç‰¹åˆ«æ˜¯åœ¨æ¨ç†å»¶è¿Ÿæ–¹é¢è¿›è¡Œä¼˜åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMOGOçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šMoSA-VQç”¨äºè¿åŠ¨åºåˆ—çš„å±‚æ¬¡ç¦»æ•£åŒ–ï¼ŒRQHC-Transformerç”¨äºåœ¨å•æ¬¡å‰å‘ä¼ é€’ä¸­ç”Ÿæˆå¤šå±‚è¿åŠ¨æ ‡è®°ã€‚

**å…³é”®åˆ›æ–°**ï¼šMOGOçš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†è¿åŠ¨å°ºåº¦è‡ªé€‚åº”æ®‹å·®å‘é‡é‡åŒ–å’Œæ®‹å·®é‡åŒ–å±‚æ¬¡å› æœå˜æ¢å™¨ï¼Œè¿™ä½¿å¾—ç”Ÿæˆè¿‡ç¨‹æ›´åŠ é«˜æ•ˆï¼Œå¹¶æ˜¾è‘—é™ä½äº†æ¨ç†å»¶è¿Ÿã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒMoSA-VQæ¨¡å—é‡‡ç”¨å¯å­¦ä¹ çš„ç¼©æ”¾ç­–ç•¥ï¼Œç¡®ä¿ç”Ÿæˆçš„è¿åŠ¨è¡¨ç¤ºæ—¢ç´§å‡‘åˆå¯Œæœ‰è¡¨ç°åŠ›ã€‚åŒæ—¶ï¼ŒRQHC-Transformeré€šè¿‡æ®‹å·®è¿æ¥ä¼˜åŒ–äº†ä¿¡æ¯æµåŠ¨ï¼Œæå‡äº†ç”Ÿæˆè´¨é‡ã€‚å®éªŒä¸­è¿˜å¼•å…¥äº†æ–‡æœ¬æ¡ä»¶å¯¹é½æœºåˆ¶ï¼Œä»¥å¢å¼ºè¿åŠ¨è§£ç çš„è¯­ä¹‰ä¿çœŸåº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨HumanML3Dã€KIT-MLå’ŒCMPç­‰åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMOGOåœ¨ç”Ÿæˆè´¨é‡ä¸Šä¸æœ€å…ˆè¿›çš„å˜æ¢å™¨æ–¹æ³•ç›¸å½“æˆ–æ›´ä¼˜ï¼ŒåŒæ—¶åœ¨å®æ—¶æ€§èƒ½ä¸Šæå‡äº†æ˜¾è‘—çš„é€Ÿåº¦ï¼Œæ¨ç†å»¶è¿Ÿå¤§å¹…é™ä½ï¼Œå±•ç°å‡ºè‰¯å¥½çš„æµåª’ä½“ç”Ÿæˆèƒ½åŠ›å’Œé›¶-shotæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘å’Œäººæœºäº¤äº’ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿä¸ºè¿™äº›é¢†åŸŸæä¾›é«˜è´¨é‡çš„è¿åŠ¨ç”ŸæˆæŠ€æœ¯ã€‚MOGOçš„å®æ—¶æ€§èƒ½å’Œé«˜ä¿çœŸåº¦ä½¿å…¶åœ¨åŠ¨æ€ç¯å¢ƒä¸­å…·æœ‰å®é™…ä»·å€¼ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¹¿æ³›çš„åº”ç”¨å’Œç ”ç©¶ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in transformer-based text-to-motion generation have led to impressive progress in synthesizing high-quality human motion. Nevertheless, jointly achieving high fidelity, streaming capability, real-time responsiveness, and scalability remains a fundamental challenge. In this paper, we propose MOGO (Motion Generation with One-pass), a novel autoregressive framework tailored for efficient and real-time 3D motion generation. MOGO comprises two key components: (1) MoSA-VQ, a motion scale-adaptive residual vector quantization module that hierarchically discretizes motion sequences with learnable scaling to produce compact yet expressive representations; and (2) RQHC-Transformer, a residual quantized hierarchical causal transformer that generates multi-layer motion tokens in a single forward pass, significantly reducing inference latency. To enhance semantic fidelity, we further introduce a text condition alignment mechanism that improves motion decoding under textual control. Extensive experiments on benchmark datasets including HumanML3D, KIT-ML, and CMP demonstrate that MOGO achieves competitive or superior generation quality compared to state-of-the-art transformer-based methods, while offering substantial improvements in real-time performance, streaming generation, and generalization under zero-shot settings.

