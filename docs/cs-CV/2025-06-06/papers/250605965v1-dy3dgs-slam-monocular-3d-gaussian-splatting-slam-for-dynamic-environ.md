---
layout: default
title: Dy3DGS-SLAM: Monocular 3D Gaussian Splatting SLAM for Dynamic Environments
---

# Dy3DGS-SLAM: Monocular 3D Gaussian Splatting SLAM for Dynamic Environments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05965" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05965v1</a>
  <a href="https://arxiv.org/pdf/2506.05965.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05965v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05965v1', 'Dy3DGS-SLAM: Monocular 3D Gaussian Splatting SLAM for Dynamic Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mingrui Li, Yiming Zhou, Hongxing Zhou, Xinggang Hu, Florian Roemer, Hongyu Wang, Ahmad Osman

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDy3DGS-SLAMä»¥è§£å†³åŠ¨æ€ç¯å¢ƒä¸‹å•ç›®SLAMé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `åŠ¨æ€SLAM` `å•ç›®è§†è§‰` `3Dé«˜æ–¯ç‚¹äº‘` `ç¥ç»è¾å°„åœº` `å…‰æµæ©ç ` `å§¿æ€ä¼°è®¡` `å®æ—¶å®šä½` `åœ°å›¾æ„å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰SLAMæ–¹æ³•åœ¨åŠ¨æ€ç¯å¢ƒä¸‹çš„è·Ÿè¸ªå’Œé‡å»ºèƒ½åŠ›ä¸è¶³ï¼Œå°¤å…¶æ˜¯ä¾èµ–RGB-Dè¾“å…¥çš„æ–¹æ¡ˆè¾ƒå°‘é€‚ç”¨äºå•ç›®RGBè¾“å…¥ã€‚
2. Dy3DGS-SLAMé€šè¿‡èåˆå…‰æµå’Œæ·±åº¦æ©ç ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„åŠ¨æ€æ©ç ç”Ÿæˆæ–¹æ³•ï¼Œå¹¶è®¾è®¡äº†è¿åŠ¨æŸå¤±ä»¥æ”¹è¿›å§¿æ€ä¼°è®¡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDy3DGS-SLAMåœ¨åŠ¨æ€åœºæ™¯ä¸­çš„è·Ÿè¸ªå’Œæ¸²æŸ“æ€§èƒ½ä¼˜äºç°æœ‰RGB-Dæ–¹æ³•ï¼Œå±•ç°å‡ºæ˜¾è‘—çš„æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰åŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æˆ–3Dé«˜æ–¯ç‚¹äº‘çš„åŒæ—¶å®šä½ä¸åœ°å›¾æ„å»ºï¼ˆSLAMï¼‰æ–¹æ³•åœ¨é‡å»ºé™æ€3Dåœºæ™¯æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨åŠ¨æ€ç¯å¢ƒä¸­ï¼ˆå¦‚å…·æœ‰ç§»åŠ¨å…ƒç´ çš„çœŸå®åœºæ™¯ï¼‰çš„è·Ÿè¸ªå’Œé‡å»ºèƒ½åŠ›è¾ƒå¼±ã€‚ç°æœ‰çš„NeRFåŸºç¡€SLAMæ–¹æ³•é€šå¸¸ä¾èµ–RGB-Dè¾“å…¥ï¼Œçº¯RGBè¾“å…¥çš„é€‚åº”æ€§è¾ƒå°‘ã€‚ä¸ºå…‹æœè¿™äº›é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†Dy3DGS-SLAMï¼Œè¿™æ˜¯é¦–ä¸ªä½¿ç”¨å•ç›®RGBè¾“å…¥çš„åŠ¨æ€åœºæ™¯3Dé«˜æ–¯ç‚¹äº‘SLAMæ–¹æ³•ã€‚é€šè¿‡èåˆå…‰æµæ©ç å’Œæ·±åº¦æ©ç ï¼Œè·å¾—èåˆåŠ¨æ€æ©ç ï¼Œå¹¶è®¾è®¡äº†æ–°çš„è¿åŠ¨æŸå¤±ä»¥çº¦æŸå§¿æ€ä¼°è®¡ç½‘ç»œã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDy3DGS-SLAMåœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„è·Ÿè¸ªå’Œæ¸²æŸ“æ€§èƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ï¼Œè¶…è¶Šæˆ–åŒ¹é…äº†ç°æœ‰çš„RGB-Dæ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŠ¨æ€ç¯å¢ƒä¸‹å•ç›®SLAMçš„è·Ÿè¸ªå’Œé‡å»ºé—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†åŠ¨æ€å…ƒç´ æ—¶é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯ä¾èµ–RGB-Dè¾“å…¥çš„æ–¹æ¡ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDy3DGS-SLAMé€šè¿‡èåˆå…‰æµæ©ç å’Œæ·±åº¦æ©ç ï¼Œç”Ÿæˆä¸€ä¸ªèåˆåŠ¨æ€æ©ç ï¼Œä»¥æ­¤æ¥çº¦æŸè·Ÿè¸ªå°ºåº¦å¹¶ä¼˜åŒ–æ¸²æŸ“å‡ ä½•ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…æ‹¬åŠ¨æ€æ©ç ç”Ÿæˆã€å§¿æ€ä¼°è®¡ç½‘ç»œå’ŒåŠ¨æ€åƒç´ æ¸²æŸ“ç­‰ä¸»è¦æ¨¡å—ã€‚é¦–å…ˆç”ŸæˆåŠ¨æ€æ©ç ï¼Œç„¶åé€šè¿‡è¿åŠ¨æŸå¤±çº¦æŸå§¿æ€ä¼°è®¡ï¼Œæœ€åè¿›è¡ŒåŠ¨æ€åƒç´ çš„æ¸²æŸ“ã€‚

**å…³é”®åˆ›æ–°**ï¼šDy3DGS-SLAMçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºé¦–æ¬¡å°†3Dé«˜æ–¯ç‚¹äº‘SLAMåº”ç”¨äºåŠ¨æ€åœºæ™¯ï¼Œå¹¶ä½¿ç”¨å•ç›®RGBè¾“å…¥ï¼Œæ˜¾è‘—æå‡äº†åŠ¨æ€ç¯å¢ƒä¸‹çš„SLAMæ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†èåˆå…‰æµå’Œæ·±åº¦æ©ç çš„æ¦‚ç‡æ¨¡å‹ï¼Œå¹¶å¼•å…¥äº†æ–°çš„è¿åŠ¨æŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–å§¿æ€ä¼°è®¡ç½‘ç»œçš„è¾“å‡ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDy3DGS-SLAMåœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„è·Ÿè¸ªå’Œæ¸²æŸ“æ€§èƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ï¼Œè¶…è¶Šæˆ–åŒ¹é…äº†ç°æœ‰RGB-Dæ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦æœªçŸ¥ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨åŠ¨æ€åœºæ™¯å¤„ç†ä¸­çš„ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Dy3DGS-SLAMçš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œå¢å¼ºç°å®ç­‰é¢†åŸŸï¼Œèƒ½å¤Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­å®ç°é«˜æ•ˆçš„å®æ—¶å®šä½ä¸åœ°å›¾æ„å»ºã€‚è¿™ä¸€ç ”ç©¶çš„å®é™…ä»·å€¼åœ¨äºæå‡äº†SLAMæŠ€æœ¯åœ¨å¤æ‚åœºæ™¯ä¸­çš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current Simultaneous Localization and Mapping (SLAM) methods based on Neural Radiance Fields (NeRF) or 3D Gaussian Splatting excel in reconstructing static 3D scenes but struggle with tracking and reconstruction in dynamic environments, such as real-world scenes with moving elements. Existing NeRF-based SLAM approaches addressing dynamic challenges typically rely on RGB-D inputs, with few methods accommodating pure RGB input. To overcome these limitations, we propose Dy3DGS-SLAM, the first 3D Gaussian Splatting (3DGS) SLAM method for dynamic scenes using monocular RGB input. To address dynamic interference, we fuse optical flow masks and depth masks through a probabilistic model to obtain a fused dynamic mask. With only a single network iteration, this can constrain tracking scales and refine rendered geometry. Based on the fused dynamic mask, we designed a novel motion loss to constrain the pose estimation network for tracking. In mapping, we use the rendering loss of dynamic pixels, color, and depth to eliminate transient interference and occlusion caused by dynamic objects. Experimental results demonstrate that Dy3DGS-SLAM achieves state-of-the-art tracking and rendering in dynamic environments, outperforming or matching existing RGB-D methods.

