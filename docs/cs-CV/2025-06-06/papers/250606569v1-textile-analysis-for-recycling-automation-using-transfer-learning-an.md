---
layout: default
title: Textile Analysis for Recycling Automation using Transfer Learning and Zero-Shot Foundation Models
---

# Textile Analysis for Recycling Automation using Transfer Learning and Zero-Shot Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.06569" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.06569v1</a>
  <a href="https://arxiv.org/pdf/2506.06569.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.06569v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.06569v1', 'Textile Analysis for Recycling Automation using Transfer Learning and Zero-Shot Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yannis Spyridis, Vasileios Argyriou

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06

**æœŸåˆŠ**: IEEE DCOSS IoTi5 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè¿ç§»å­¦ä¹ å’Œé›¶æ ·æœ¬æ¨¡å‹çš„çººç»‡å“å›æ”¶è‡ªåŠ¨åŒ–åˆ†ææ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çººç»‡å“å›æ”¶` `è¿ç§»å­¦ä¹ ` `é›¶æ ·æœ¬å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰` `è‡ªåŠ¨åŒ–åˆ†æ‹£` `æ·±åº¦å­¦ä¹ ` `ç‰¹å¾åˆ†å‰²`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨çººç»‡å“å›æ”¶ä¸­é¢ä¸´ææ–™æˆåˆ†è¯†åˆ«å’Œæ±¡æŸ“ç‰©æ£€æµ‹çš„å‡†ç¡®æ€§æŒ‘æˆ˜ï¼Œé™åˆ¶äº†è‡ªåŠ¨åŒ–åˆ†æ‹£çš„æ•ˆç‡ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨æ ‡å‡†RGBå›¾åƒè¿›è¡Œçººç»‡å“åˆ†ç±»å’Œéçººç»‡ç‰¹å¾åˆ†å‰²çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿï¼Œé‡‡ç”¨è¿ç§»å­¦ä¹ å’Œé›¶æ ·æœ¬æ¨¡å‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEfficientNetB0åœ¨åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°äº†81.25%çš„å‡†ç¡®ç‡ï¼Œè€Œé›¶æ ·æœ¬åˆ†å‰²æ–¹æ³•çš„mIoUè¾¾åˆ°äº†0.90ï¼Œæ˜¾è‘—æå‡äº†æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªåŠ¨åŒ–åˆ†æ‹£å¯¹æé«˜çººç»‡å“å›æ”¶çš„æ•ˆç‡å’Œå¯æ‰©å±•æ€§è‡³å…³é‡è¦ï¼Œä½†ä»ä¼ æ„Ÿå™¨æ•°æ®ä¸­å‡†ç¡®è¯†åˆ«ææ–™æˆåˆ†å’Œæ£€æµ‹æ±¡æŸ“ç‰©ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬æ–‡æ¢è®¨äº†ä½¿ç”¨æ ‡å‡†RGBå›¾åƒä½œä¸ºä¸€ç§ç»æµæœ‰æ•ˆçš„ä¼ æ„Ÿæ–¹å¼ï¼Œåœ¨è‡ªåŠ¨åŒ–ç³»ç»Ÿä¸­è¿›è¡Œå…³é”®é¢„å¤„ç†ä»»åŠ¡ã€‚æˆ‘ä»¬è®¾è®¡äº†è®¡ç®—æœºè§†è§‰ç»„ä»¶ï¼Œæ—¨åœ¨åœ¨ä¼ é€å¸¦è®¾ç½®ä¸­æ‰§è¡Œå››ç§å¸¸è§çººç»‡å“ç±»å‹çš„åˆ†ç±»å’Œéçººç»‡ç‰¹å¾ï¼ˆå¦‚çº½æ‰£å’Œæ‹‰é“¾ï¼‰çš„åˆ†å‰²ã€‚é€šè¿‡è¿ç§»å­¦ä¹ å’Œäº¤å‰éªŒè¯è¯„ä¼°äº†å¤šç§é¢„è®­ç»ƒæ¶æ„ï¼ŒEfficientNetB0åœ¨ä¿ç•™çš„æµ‹è¯•é›†ä¸Šå–å¾—äº†81.25%çš„æœ€ä½³å‡†ç¡®ç‡ã€‚å¯¹äºç‰¹å¾åˆ†å‰²ï¼Œé‡‡ç”¨äº†ç»“åˆGrounding DINOå¼€æ”¾è¯æ±‡æ£€æµ‹å™¨ä¸Segment Anything Model (SAM)çš„é›¶æ ·æœ¬æ–¹æ³•ï¼Œç”Ÿæˆçš„æ©ç ä¸çœŸå®å€¼çš„mIoUè¾¾åˆ°äº†0.90ï¼Œè¡¨ç°å‡ºè‰²ã€‚æ­¤ç ”ç©¶å±•ç¤ºäº†ç»“åˆç°ä»£æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„RGBå›¾åƒåœ¨è‡ªåŠ¨åŒ–çººç»‡å“å›æ”¶ç®¡é“ä¸­è¿›è¡Œå…³é”®åˆ†ææ­¥éª¤çš„å¯è¡Œæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³çººç»‡å“å›æ”¶è¿‡ç¨‹ä¸­ææ–™æˆåˆ†è¯†åˆ«å’Œæ±¡æŸ“ç‰©æ£€æµ‹çš„å‡†ç¡®æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä¼ æ„Ÿå™¨æ•°æ®æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆåŒºåˆ†ä¸åŒç±»å‹çš„çººç»‡å“å’Œéçººç»‡ç‰¹å¾ï¼Œå¯¼è‡´è‡ªåŠ¨åŒ–åˆ†æ‹£æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºåˆ©ç”¨æ ‡å‡†RGBå›¾åƒä½œä¸ºä¼ æ„Ÿå™¨æ•°æ®ï¼Œé€šè¿‡è¿ç§»å­¦ä¹ è¿›è¡Œçººç»‡å“åˆ†ç±»ï¼Œå¹¶ç»“åˆé›¶æ ·æœ¬å­¦ä¹ æ–¹æ³•è¿›è¡Œç‰¹å¾åˆ†å‰²ï¼Œä»¥æé«˜è‡ªåŠ¨åŒ–ç³»ç»Ÿçš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨é™ä½æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒé«˜æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€æ˜¯åŸºäºè¿ç§»å­¦ä¹ çš„åˆ†ç±»æ¨¡å—ï¼Œä½¿ç”¨EfficientNetB0æ¶æ„è¿›è¡Œå››ç§å¸¸è§çººç»‡å“çš„åˆ†ç±»ï¼›äºŒæ˜¯åŸºäºé›¶æ ·æœ¬å­¦ä¹ çš„åˆ†å‰²æ¨¡å—ï¼Œç»“åˆGrounding DINOå’ŒSegment Anything Model (SAM)è¿›è¡Œéçººç»‡ç‰¹å¾çš„åˆ†å‰²ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºå°†è¿ç§»å­¦ä¹ ä¸é›¶æ ·æœ¬å­¦ä¹ ç›¸ç»“åˆï¼Œåˆ©ç”¨RGBå›¾åƒè¿›è¡Œçººç»‡å“åˆ†ç±»å’Œç‰¹å¾åˆ†å‰²ï¼Œçªç ´äº†ä¼ ç»Ÿæ–¹æ³•åœ¨ææ–™è¯†åˆ«å’Œæ±¡æŸ“ç‰©æ£€æµ‹ä¸Šçš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œé‡‡ç”¨EfficientNetB0ä½œä¸ºåŸºç¡€ç½‘ç»œï¼Œé€šè¿‡è¿ç§»å­¦ä¹ è¿›è¡Œå¾®è°ƒï¼Œä¼˜åŒ–äº†æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚åœ¨åˆ†å‰²ä»»åŠ¡ä¸­ï¼Œä½¿ç”¨Grounding DINOè¿›è¡Œå¼€æ”¾è¯æ±‡æ£€æµ‹ï¼Œç»“åˆSAMç”Ÿæˆé«˜è´¨é‡çš„åˆ†å‰²æ©ç ï¼Œç¡®ä¿äº†mIoUçš„é«˜è¾¾0.90ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEfficientNetB0åœ¨åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°äº†81.25%çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–é¢„è®­ç»ƒæ¨¡å‹ã€‚åŒæ—¶ï¼Œç»“åˆGrounding DINOå’ŒSAMçš„é›¶æ ·æœ¬åˆ†å‰²æ–¹æ³•åœ¨ç‰¹å¾åˆ†å‰²ä»»åŠ¡ä¸­å®ç°äº†0.90çš„mIoUï¼Œå±•ç°äº†æé«˜çš„æ€§èƒ½å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬çººç»‡å“å›æ”¶è¡Œä¸šçš„è‡ªåŠ¨åŒ–åˆ†æ‹£ç³»ç»Ÿï¼Œèƒ½å¤Ÿæœ‰æ•ˆæé«˜å›æ”¶æ•ˆç‡å’Œé™ä½äººå·¥æˆæœ¬ã€‚é€šè¿‡å®ç°é«˜ç²¾åº¦çš„ææ–™è¯†åˆ«å’Œæ±¡æŸ“ç‰©æ£€æµ‹ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¹¿æ³›çš„å¯æŒç»­å‘å±•å®è·µï¼Œä¿ƒè¿›å¾ªç¯ç»æµçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Automated sorting is crucial for improving the efficiency and scalability of textile recycling, but accurately identifying material composition and detecting contaminants from sensor data remains challenging. This paper investigates the use of standard RGB imagery, a cost-effective sensing modality, for key pre-processing tasks in an automated system. We present computer vision components designed for a conveyor belt setup to perform (a) classification of four common textile types and (b) segmentation of non-textile features such as buttons and zippers. For classification, several pre-trained architectures were evaluated using transfer learning and cross-validation, with EfficientNetB0 achieving the best performance on a held-out test set with 81.25\% accuracy. For feature segmentation, a zero-shot approach combining the Grounding DINO open-vocabulary detector with the Segment Anything Model (SAM) was employed, demonstrating excellent performance with a mIoU of 0.90 for the generated masks against ground truth. This study demonstrates the feasibility of using RGB images coupled with modern deep learning techniques, including transfer learning for classification and foundation models for zero-shot segmentation, to enable essential analysis steps for automated textile recycling pipelines.

