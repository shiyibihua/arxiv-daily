---
layout: default
title: Pts3D-LLM: Studying the Impact of Token Structure for 3D Scene Understanding With Large Language Models
---

# Pts3D-LLM: Studying the Impact of Token Structure for 3D Scene Understanding With Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05689" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05689v1</a>
  <a href="https://arxiv.org/pdf/2506.05689.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05689v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05689v1', 'Pts3D-LLM: Studying the Impact of Token Structure for 3D Scene Understanding With Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hugues Thomas, Chen Chen, Jian Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06

**å¤‡æ³¨**: Main paper and appendix

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPts3D-LLMä»¥æå‡3Dåœºæ™¯ç†è§£çš„æ•ˆæœ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dåœºæ™¯ç†è§£` `å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹` `ç‚¹äº‘ç‰¹å¾` `è§†é¢‘åŸºç¡€æ ‡è®°` `ç‚¹åŸºç¡€æ ‡è®°` `ç‰¹å¾èåˆ` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–2Då›¾åƒç‰¹å¾ï¼Œç¼ºä¹å¯¹3Dåœºæ™¯çš„æœ‰æ•ˆè¡¨ç¤ºï¼Œå¯¼è‡´ç†è§£èƒ½åŠ›ä¸è¶³ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆ3Dç‚¹äº‘ç‰¹å¾æ¥ä¸°å¯Œè§†è§‰æ ‡è®°ï¼Œç³»ç»Ÿæ¯”è¾ƒè§†é¢‘åŸºç¡€å’Œç‚¹åŸºç¡€çš„æ ‡è®°ç»“æ„ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œåˆå¹¶3Dç‰¹å¾æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œç‚¹åŸºç¡€æ ‡è®°ç»“æ„åœ¨å·§å¦™é‡‡æ ·ä¸‹å¯ä¸è§†é¢‘åŸºç¡€ç»“æ„åª²ç¾ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ‰æ•ˆè¡¨ç¤º3Dåœºæ™¯å¯¹äºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰è‡³å…³é‡è¦ï¼Œä½†é¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä»…ä¾èµ–2Då›¾åƒç‰¹å¾ï¼Œå¹¶é‡‡ç”¨ä¸åŒçš„æ ‡è®°åŒ–æ–¹æ³•ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿæ¯”è¾ƒäº†è§†é¢‘åŸºç¡€å’Œç‚¹åŸºç¡€çš„3Dæ ‡è®°ç»“æ„ï¼Œæå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆæ¥è‡ªSonataé¢„è®­ç»ƒçš„Point Transformer V3ç¼–ç å™¨çš„3Dç‚¹äº‘ç‰¹å¾æ¥ä¸°å¯Œè§†è§‰æ ‡è®°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåˆå¹¶æ˜¾å¼çš„3Dç‰¹å¾æ˜¾è‘—æå‡äº†æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åœ¨å·§å¦™é‡‡æ ·å’Œæ’åºçš„æƒ…å†µä¸‹ï¼Œç‚¹åŸºç¡€çš„æ ‡è®°ç»“æ„å¯ä»¥ä¸è§†é¢‘åŸºç¡€çš„æ ‡è®°ç»“æ„ç›¸åª²ç¾ã€‚æˆ‘ä»¬çš„æœ€ä½³æ¨¡å‹åœ¨å¤šä¸ª3Dç†è§£åŸºå‡†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚æˆ‘ä»¬å¼ºè°ƒå¯¹æ ‡è®°ç»“æ„çš„åˆ†ææ˜¯å…³é”®è´¡çŒ®ä¹‹ä¸€ï¼Œå¹¶é€æ˜æŠ¥å‘Šäº†å¤šæ¬¡å®éªŒçš„ç»“æœï¼Œè®¤ä¸ºè¿™æ˜¯è¯¥é¢†åŸŸç¨³å¥è¿›å±•çš„é‡è¦å®è·µã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•æœ‰æ•ˆè¡¨ç¤º3Dåœºæ™¯ä»¥æå‡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„ç†è§£èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–2Då›¾åƒç‰¹å¾ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨3Dä¿¡æ¯ï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡ç»“åˆ3Dç‚¹äº‘ç‰¹å¾æ¥ä¸°å¯Œè§†è§‰æ ‡è®°ï¼Œä»è€Œæå‡æ¨¡å‹å¯¹3Dåœºæ™¯çš„ç†è§£èƒ½åŠ›ã€‚é€šè¿‡ç³»ç»Ÿæ¯”è¾ƒè§†é¢‘åŸºç¡€å’Œç‚¹åŸºç¡€çš„æ ‡è®°ç»“æ„ï¼Œæ¢ç´¢å…¶åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªSonataé¢„è®­ç»ƒçš„Point Transformer V3ç¼–ç å™¨ï¼Œè´Ÿè´£æå–3Dç‚¹äº‘ç‰¹å¾ï¼Œå¹¶å°†å…¶ä¸è§†è§‰æ ‡è®°ç»“åˆã€‚æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œç¡®ä¿å‚æ•°ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„ç‚¹åŸºç¡€æ ‡è®°ç»“æ„ï¼Œé€šè¿‡å·§å¦™çš„é‡‡æ ·å’Œæ’åºï¼Œä½¿å…¶æ€§èƒ½èƒ½å¤Ÿä¸è§†é¢‘åŸºç¡€æ ‡è®°ç»“æ„ç›¸åª²ç¾ã€‚è¿™ä¸€æ–¹æ³•åœ¨3Dåœºæ™¯ç†è§£ä¸­å¼•å…¥äº†æ˜¾å¼çš„3Dç‰¹å¾ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†Sonataé¢„è®­ç»ƒçš„Point Transformer V3ä½œä¸ºç‰¹å¾æå–å™¨ï¼Œç¡®ä¿äº†3Dç‰¹å¾çš„æœ‰æ•ˆæ€§ã€‚å®éªŒä¸­ä½¿ç”¨äº†å¤šæ¬¡éšæœºç§å­è¿›è¡Œç»“æœéªŒè¯ï¼Œä»¥æé«˜ç»“æœçš„å¯é æ€§ã€‚æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåˆå¹¶3Dç‚¹äº‘ç‰¹å¾åï¼Œæ¨¡å‹åœ¨å¤šä¸ª3Dç†è§£åŸºå‡†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚ç‚¹åŸºç¡€æ ‡è®°ç»“æ„åœ¨å·§å¦™é‡‡æ ·å’Œæ’åºçš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½ä¸è§†é¢‘åŸºç¡€ç»“æ„ç›¸å½“ï¼Œå±•ç¤ºäº†æ˜¾è‘—çš„æå‡å¹…åº¦ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªè¯¦è¿°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººå¯¼èˆªç­‰ã€‚é€šè¿‡æå‡3Dåœºæ™¯ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿä¸ºè¿™äº›é¢†åŸŸæä¾›æ›´æ™ºèƒ½çš„å†³ç­–æ”¯æŒå’Œäº¤äº’ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Effectively representing 3D scenes for Multimodal Large Language Models (MLLMs) is crucial yet challenging. Existing approaches commonly only rely on 2D image features and use varied tokenization approaches. This work presents a rigorous study of 3D token structures, systematically comparing video-based and point-based representations while maintaining consistent model backbones and parameters. We propose a novel approach that enriches visual tokens by incorporating 3D point cloud features from a Sonata pretrained Point Transformer V3 encoder. Our experiments demonstrate that merging explicit 3D features significantly boosts performance. Furthermore, we show that point-based token structures can rival video-based ones when the points are cleverly sampled and ordered. Our best models from both structures achieve state-of-the-art results on multiple 3D understanding benchmarks. We emphasize our analysis of token structures as a key contribution, alongside transparent reporting of results averaged over multiple seeds, a practice we believe is vital for robust progress in the field.

