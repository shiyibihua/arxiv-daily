---
layout: default
title: HMVLM: Multistage Reasoning-Enhanced Vision-Language Model for Long-Tailed Driving Scenarios
---

# HMVLM: Multistage Reasoning-Enhanced Vision-Language Model for Long-Tailed Driving Scenarios

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05883" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05883v1</a>
  <a href="https://arxiv.org/pdf/2506.05883.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05883v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05883v1', 'HMVLM: Multistage Reasoning-Enhanced Vision-Language Model for Long-Tailed Driving Scenarios')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Daming Wang, Yuhao Song, Zijian He, Kangliang Chen, Xing Pan, Lu Deng, Weihao Gu

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06

**å¤‡æ³¨**: WOD Vision-based End-to-End Driving Challenge

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHMVLMä»¥è§£å†³é•¿å°¾é©¾é©¶åœºæ™¯ä¸­çš„å†³ç­–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿å°¾é©¾é©¶` `è§†è§‰-è¯­è¨€æ¨¡å‹` `å¿«æ…¢æ¶æ„` `å¤šé˜¶æ®µæ¨ç†` `è½¨è¿¹è§„åˆ’` `è‡ªåŠ¨é©¾é©¶` `å†³ç­–ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨é•¿å°¾é©¾é©¶åœºæ™¯ä¸­é¢ä¸´å†³ç­–å»¶è¿Ÿå’Œå‡†ç¡®æ€§ä¸è¶³çš„æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºçš„HMVLMé€šè¿‡å¿«æ…¢æ¶æ„ç»“åˆè§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œä¼˜åŒ–äº†é©¾é©¶å†³ç­–æµç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHMVLMåœ¨WaymoæŒ‘æˆ˜ä¸­å–å¾—äº†ä¼˜å¼‚æˆç»©ï¼Œæ˜¾è‘—æå‡äº†è¯„åˆ†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†HaoMoè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆHMVLMï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„é©¾é©¶æ¡†æ¶ï¼Œé‡‡ç”¨äº†å—è®¤çŸ¥å¯å‘çš„å¿«æ…¢æ¶æ„ã€‚å¿«é€Ÿæ§åˆ¶å™¨è¾“å‡ºä½çº§åˆ«çš„è½¬å‘ã€æ²¹é—¨å’Œåˆ¹è½¦æŒ‡ä»¤ï¼Œè€Œæ…¢é€Ÿè§„åˆ’å™¨â€”â€”ä¸€ä¸ªå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹â€”â€”ç”Ÿæˆé«˜å±‚æ¬¡çš„æ„å›¾ï¼Œå¦‚â€œè®©è¡Œç»™è¡Œäººâ€æˆ–â€œåœ¨å¡è½¦åå¹¶å…¥â€ã€‚HMVLMå¼•å…¥äº†ä¸‰é¡¹å‡çº§ï¼šé€‰æ‹©æ€§äº”è§†å›¾æç¤ºï¼ŒåµŒå…¥4ç§’çš„è‡ªæˆ‘è¿åŠ¨å†å²ï¼›å¤šé˜¶æ®µæ€ç»´é“¾æç¤ºï¼Œå¼ºåˆ¶æ‰§è¡Œåœºæ™¯ç†è§£ã€é©¾é©¶å†³ç­–å’Œè½¨è¿¹æ¨æ–­çš„æ¨ç†æµç¨‹ï¼›åŸºäºæ ·æ¡çš„è½¨è¿¹åå¤„ç†ï¼Œæ¶ˆé™¤åæœŸæŠ–åŠ¨å’Œæ€¥è½¬å¼¯ã€‚ç»è¿‡åœ¨Waymoå¼€æ”¾æ•°æ®é›†ä¸Šçš„è®­ç»ƒï¼Œè¿™äº›å‡çº§ä½¿HMVLMåœ¨2025å¹´WaymoåŸºäºè§†è§‰çš„ç«¯åˆ°ç«¯é©¾é©¶æŒ‘æˆ˜ä¸­è·å¾—äº†7.7367çš„è¯„åˆ†ï¼Œæ’åç¬¬äºŒï¼Œè¶…è¶Šå…¬å…±åŸºçº¿2.77%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³é•¿å°¾é©¾é©¶åœºæ™¯ä¸­å†³ç­–å»¶è¿Ÿå’Œå‡†ç¡®æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸‹éš¾ä»¥å¿«é€Ÿåšå‡ºåˆç†çš„é©¾é©¶å†³ç­–ï¼Œå¯¼è‡´å®‰å…¨æ€§å’Œæ•ˆç‡çš„é™ä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHMVLMé‡‡ç”¨å¿«æ…¢æ¶æ„ï¼Œå¿«é€Ÿæ§åˆ¶å™¨è´Ÿè´£å®æ—¶ä½çº§åˆ«æŒ‡ä»¤è¾“å‡ºï¼Œè€Œæ…¢é€Ÿè§„åˆ’å™¨åˆ™åˆ©ç”¨å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ç”Ÿæˆé«˜å±‚æ¬¡çš„é©¾é©¶æ„å›¾ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å¹³è¡¡å†³ç­–çš„é€Ÿåº¦ä¸å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHMVLMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå¿«é€Ÿæ§åˆ¶å™¨å’Œæ…¢é€Ÿè§„åˆ’å™¨ã€‚å¿«é€Ÿæ§åˆ¶å™¨å®æ—¶å¤„ç†ä¼ æ„Ÿå™¨æ•°æ®å¹¶è¾“å‡ºä½çº§åˆ«æ§åˆ¶æŒ‡ä»¤ï¼Œæ…¢é€Ÿè§„åˆ’å™¨åˆ™é€šè¿‡å¤šé˜¶æ®µæ¨ç†ç”Ÿæˆé«˜å±‚æ¬¡çš„é©¾é©¶å†³ç­–ã€‚

**å…³é”®åˆ›æ–°**ï¼šHMVLMçš„ä¸‰é¡¹å…³é”®åˆ›æ–°åŒ…æ‹¬é€‰æ‹©æ€§äº”è§†å›¾æç¤ºã€å¼ºåˆ¶æ¨ç†æµç¨‹çš„å¤šé˜¶æ®µæ€ç»´é“¾æç¤ºï¼Œä»¥åŠåŸºäºæ ·æ¡çš„è½¨è¿¹åå¤„ç†ã€‚è¿™äº›åˆ›æ–°ä½¿å¾—æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„å†³ç­–èƒ½åŠ›æ˜¾è‘—æå‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé€‰æ‹©æ€§äº”è§†å›¾æç¤ºç»“åˆäº†4ç§’çš„è‡ªæˆ‘è¿åŠ¨å†å²ï¼Œä»¥å¢å¼ºåœºæ™¯ç†è§£ï¼›å¤šé˜¶æ®µæ€ç»´é“¾æç¤ºç¡®ä¿äº†æ¨ç†æµç¨‹çš„è¿è´¯æ€§ï¼›æ ·æ¡è½¨è¿¹åå¤„ç†åˆ™æœ‰æ•ˆå‡å°‘äº†å†³ç­–åçš„æŠ–åŠ¨å’Œæ€¥è½¬å¼¯ç°è±¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

HMVLMåœ¨2025å¹´WaymoåŸºäºè§†è§‰çš„ç«¯åˆ°ç«¯é©¾é©¶æŒ‘æˆ˜ä¸­å–å¾—äº†7.7367çš„è¯„åˆ†ï¼Œæ’åç¬¬äºŒï¼Œè¶…è¶Šå…¬å…±åŸºçº¿2.77%ã€‚è¿™ä¸€æˆç»©å±•ç¤ºäº†å…¶åœ¨é•¿å°¾é©¾é©¶åœºæ™¯ä¸­çš„ä¼˜è¶Šæ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚å†³ç­–å’Œè½¨è¿¹è§„åˆ’æ–¹é¢çš„æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

HMVLMçš„ç ”ç©¶æˆæœåœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚å’ŒåŠ¨æ€çš„åŸå¸‚é©¾é©¶ç¯å¢ƒä¸­ã€‚é€šè¿‡æé«˜å†³ç­–çš„å‡†ç¡®æ€§å’Œå®æ—¶æ€§ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ˜¾è‘—æå‡è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œç”¨æˆ·ä½“éªŒï¼Œæœªæ¥å¯åº”ç”¨äºæ— äººé©¾é©¶å‡ºç§Ÿè½¦ã€ç‰©æµè¿è¾“ç­‰åœºæ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present HaoMo Vision-Language Model (HMVLM), an end-to-end driving framework that implements the slow branch of a cognitively inspired fast-slow architecture. A fast controller outputs low-level steering, throttle, and brake commands, while a slow planner-a large vision-language model-generates high-level intents such as "yield to pedestrian" or "merge after the truck" without compromising latency. HMVLM introduces three upgrades: (1) selective five-view prompting with an embedded 4s history of ego kinematics, (2) multi-stage chain-of-thought (CoT) prompting that enforces a Scene Understanding -> Driving Decision -> Trajectory Inference reasoning flow, and (3) spline-based trajectory post-processing that removes late-stage jitter and sharp turns. Trained on the Waymo Open Dataset, these upgrades enable HMVLM to achieve a Rater Feedback Score (RFS) of 7.7367, securing 2nd place in the 2025 Waymo Vision-based End-to-End (E2E) Driving Challenge and surpassing the public baseline by 2.77%.

