---
layout: default
title: Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation
---

# Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05890" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05890v1</a>
  <a href="https://arxiv.org/pdf/2506.05890.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05890v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05890v1', 'Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yiheng Li, Yang Yang, Zichang Tan, Huan Liu, Weihua Chen, Xu Zhou, Zhen Lei

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06

**å¤‡æ³¨**: Accepted by CVPR 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/liyih/CSCL)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸Šä¸‹æ–‡è¯­ä¹‰ä¸€è‡´æ€§å­¦ä¹ ä»¥è§£å†³å¤šæ¨¡æ€åª’ä½“æ“æ§æ£€æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å¤šæ¨¡æ€åª’ä½“` `ä¼ªé€ æ£€æµ‹` `ä¸€è‡´æ€§å­¦ä¹ ` `ä¸Šä¸‹æ–‡åˆ†æ` `è¯­ä¹‰ç†è§£` `å‡æ–°é—»` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†æŒ–æ˜å±€éƒ¨å†…å®¹ä¸­çš„ç»†ç²’åº¦ä¸€è‡´æ€§ï¼Œå¯¼è‡´å¯¹ä¼ªé€ å†…å®¹çš„æ„ŸçŸ¥ä¸è¶³å’Œç»“æœä¸å¯é ã€‚
2. æå‡ºä¸Šä¸‹æ–‡è¯­ä¹‰ä¸€è‡´æ€§å­¦ä¹ ï¼ˆCSCLï¼‰ï¼Œé€šè¿‡ä¸¤ä¸ªçº§è”è§£ç å™¨æ•æ‰æ¨¡æ€å†…å¤–çš„ä¸€è‡´æ€§ç‰¹å¾ï¼Œä»è€Œå¢å¼ºä¼ªé€ æ„ŸçŸ¥èƒ½åŠ›ã€‚
3. åœ¨DGM4æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒCSCLåœ¨å®šä½æ“æ§å†…å®¹æ–¹é¢è¾¾åˆ°äº†æ–°çš„æœ€å…ˆè¿›æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†æ£€æµ‹æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºåº”å¯¹å‡æ–°é—»çš„å¨èƒï¼Œæ£€æµ‹å’Œå®šä½å¤šæ¨¡æ€åª’ä½“æ“æ§çš„ä»»åŠ¡DGM4å—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•æœªèƒ½æ·±å…¥æ¢ç´¢å±€éƒ¨å†…å®¹ä¸­çš„ç»†ç²’åº¦ä¸€è‡´æ€§ï¼Œå¯¼è‡´å¯¹ä¼ªé€ ç»†èŠ‚çš„æ„ŸçŸ¥ä¸è¶³ï¼Œç»“æœä¸å¯é ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œç§°ä¸ºä¸Šä¸‹æ–‡è¯­ä¹‰ä¸€è‡´æ€§å­¦ä¹ ï¼ˆCSCLï¼‰ï¼Œä»¥å¢å¼ºDGM4çš„ä¼ªé€ ç»†ç²’åº¦æ„ŸçŸ¥èƒ½åŠ›ã€‚è¯¥æ–¹æ³•å»ºç«‹äº†å›¾åƒå’Œæ–‡æœ¬ä¸¤ç§æ¨¡æ€çš„ä¸¤ä¸ªåˆ†æ”¯ï¼Œæ¯ä¸ªåˆ†æ”¯åŒ…å«ä¸¤ä¸ªçº§è”è§£ç å™¨ï¼Œå³ä¸Šä¸‹æ–‡ä¸€è‡´æ€§è§£ç å™¨ï¼ˆCCDï¼‰å’Œè¯­ä¹‰ä¸€è‡´æ€§è§£ç å™¨ï¼ˆSCDï¼‰ï¼Œåˆ†åˆ«æ•æ‰æ¨¡æ€å†…çš„ä¸Šä¸‹æ–‡ä¸€è‡´æ€§å’Œæ¨¡æ€é—´çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCSCLåœ¨DGM4æ•°æ®é›†ä¸Šå®ç°äº†æ–°çš„æœ€å…ˆè¿›æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨å®šä½æ“æ§å†…å®¹çš„ç»“æœä¸Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€åª’ä½“æ“æ§æ£€æµ‹ä¸­çš„ç»†ç²’åº¦ä¸€è‡´æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸æœªèƒ½æ·±å…¥åˆ†æå±€éƒ¨å†…å®¹ï¼Œå¯¼è‡´å¯¹ä¼ªé€ ç»†èŠ‚çš„æ„ŸçŸ¥ä¸å¤Ÿå‡†ç¡®ï¼Œç»“æœä¹Ÿä¸å¤Ÿå¯é ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„ä¸Šä¸‹æ–‡è¯­ä¹‰ä¸€è‡´æ€§å­¦ä¹ ï¼ˆCSCLï¼‰é€šè¿‡å»ºç«‹å›¾åƒå’Œæ–‡æœ¬æ¨¡æ€çš„ä¸¤ä¸ªåˆ†æ”¯ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡ä¸€è‡´æ€§è§£ç å™¨ï¼ˆCCDï¼‰å’Œè¯­ä¹‰ä¸€è‡´æ€§è§£ç å™¨ï¼ˆSCDï¼‰æ¥æ•æ‰æ¨¡æ€å†…å¤–çš„ä¸€è‡´æ€§ç‰¹å¾ï¼Œä»è€Œæå‡ä¼ªé€ æ„ŸçŸ¥èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCSCLçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦åˆ†æ”¯ï¼šå›¾åƒåˆ†æ”¯å’Œæ–‡æœ¬åˆ†æ”¯ã€‚æ¯ä¸ªåˆ†æ”¯åŒ…å«ä¸¤ä¸ªçº§è”è§£ç å™¨ï¼ŒCCDç”¨äºæ•æ‰æ¨¡æ€å†…çš„ä¸Šä¸‹æ–‡ä¸€è‡´æ€§ï¼ŒSCDç”¨äºæ•æ‰æ¨¡æ€é—´çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚æ¯ä¸ªæ¨¡å—é€šè¿‡å¼‚æ„ä¿¡æ¯çš„é¢å¤–ç›‘ç£æ„å»ºä¸€è‡´æ€§ç‰¹å¾ï¼Œå¹¶è¿›è¡Œä¼ªé€ æ„ŸçŸ¥æ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šCSCLçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºåŒæ—¶åˆ©ç”¨æ¨¡æ€å†…å’Œæ¨¡æ€é—´çš„ä¸€è‡´æ€§ç‰¹å¾ï¼Œæ˜¾è‘—æå‡äº†å¯¹ä¼ªé€ ç»†èŠ‚çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚è¿™ä¸€æ–¹æ³•ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå…¶åŒé‡ä¸€è‡´æ€§æ•æ‰æœºåˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ä¸€è‡´æ€§ç‰¹å¾çš„å­¦ä¹ ï¼Œå¹¶é€šè¿‡ä¼ªé€ æ„ŸçŸ¥æ¨ç†æ¨¡å—æ·±å…¥æŒ–æ˜ä¼ªé€ çº¿ç´¢ã€‚ç½‘ç»œç»“æ„ä¸Šï¼ŒCCDå’ŒSCDçš„çº§è”è®¾è®¡ä½¿å¾—ä¿¡æ¯æµåŠ¨æ›´åŠ é«˜æ•ˆï¼Œæå‡äº†æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCSCLåœ¨DGM4æ•°æ®é›†ä¸Šè¾¾åˆ°äº†æ–°çš„æœ€å…ˆè¿›æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨å®šä½æ“æ§å†…å®¹æ–¹é¢ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æå‡äº†æ˜¾è‘—çš„æ£€æµ‹å‡†ç¡®ç‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªæä¾›ï¼Œä½†æå‡å¹…åº¦æ˜¾è‘—ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨å‡æ–°é—»æ£€æµ‹ã€ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸å’Œå¤šæ¨¡æ€ä¿¡æ¯éªŒè¯ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜å¯¹ä¼ªé€ å†…å®¹çš„æ£€æµ‹èƒ½åŠ›ï¼ŒCSCLèƒ½å¤Ÿå¸®åŠ©ç›¸å…³æœºæ„æ›´æœ‰æ•ˆåœ°è¯†åˆ«å’Œåº”å¯¹è™šå‡ä¿¡æ¯ï¼Œä»è€Œç»´æŠ¤ä¿¡æ¯çš„çœŸå®æ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> To tackle the threat of fake news, the task of detecting and grounding multi-modal media manipulation DGM4 has received increasing attention. However, most state-of-the-art methods fail to explore the fine-grained consistency within local content, usually resulting in an inadequate perception of detailed forgery and unreliable results. In this paper, we propose a novel approach named Contextual-Semantic Consistency Learning (CSCL) to enhance the fine-grained perception ability of forgery for DGM4. Two branches for image and text modalities are established, each of which contains two cascaded decoders, i.e., Contextual Consistency Decoder (CCD) and Semantic Consistency Decoder (SCD), to capture within-modality contextual consistency and across-modality semantic consistency, respectively. Both CCD and SCD adhere to the same criteria for capturing fine-grained forgery details. To be specific, each module first constructs consistency features by leveraging additional supervision from the heterogeneous information of each token pair. Then, the forgery-aware reasoning or aggregating is adopted to deeply seek forgery cues based on the consistency features. Extensive experiments on DGM4 datasets prove that CSCL achieves new state-of-the-art performance, especially for the results of grounding manipulated content. Codes and weights are avaliable at https://github.com/liyih/CSCL.

