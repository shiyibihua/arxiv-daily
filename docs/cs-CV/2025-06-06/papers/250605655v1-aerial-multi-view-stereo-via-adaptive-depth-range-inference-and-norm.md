---
layout: default
title: Aerial Multi-View Stereo via Adaptive Depth Range Inference and Normal Cues
---

# Aerial Multi-View Stereo via Adaptive Depth Range Inference and Normal Cues

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05655" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05655v1</a>
  <a href="https://arxiv.org/pdf/2506.05655.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05655v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05655v1', 'Aerial Multi-View Stereo via Adaptive Depth Range Inference and Normal Cues')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yimei Liu, Yakun Ju, Yuan Rao, Hao Fan, Junyu Dong, Feng Gao, Qian Du

**åˆ†ç±»**: cs.CV, eess.IV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06

**å¤‡æ³¨**: IEEE TGRS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªé€‚åº”æ·±åº¦èŒƒå›´MVSä»¥è§£å†³èˆªç©ºå¤šè§†å›¾ç«‹ä½“é‡å»ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `å¤šè§†å›¾ç«‹ä½“` `æ·±åº¦ä¼°è®¡` `èˆªç©ºå›¾åƒ` `å‡ ä½•çº¿ç´¢` `æ·±åº¦èŒƒå›´é¢„æµ‹` `æ³•çº¿å¼•å¯¼` `åŸå¸‚é‡å»º` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šè§†å›¾ç«‹ä½“é‡å»ºæ–¹æ³•æœªèƒ½æœ‰æ•ˆå¤„ç†èˆªç©ºå›¾åƒä¸­çš„æ·±åº¦èŒƒå›´å˜åŒ–å’Œç‰¹å¾åŒ¹é…é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºçš„è‡ªé€‚åº”æ·±åº¦èŒƒå›´MVSï¼ˆADR-MVSï¼‰é€šè¿‡å•ç›®å‡ ä½•çº¿ç´¢æ¥æ”¹å–„æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒADR-MVSåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ï¼Œä¸”è®¡ç®—å¤æ‚åº¦æ›´ä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸‰ç»´æ•°å­—åŸå¸‚é‡å»ºæ˜¯å¤šè§†è§’èˆªç©ºå›¾åƒçš„é‡è¦åº”ç”¨ï¼Œæ·±åº¦å¤šè§†å›¾ç«‹ä½“ï¼ˆMVSï¼‰æ–¹æ³•åœ¨æ­¤é¢†åŸŸä¼˜äºä¼ ç»ŸæŠ€æœ¯ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†èˆªç©ºä¸è¿‘è·ç¦»è®¾ç½®ä¹‹é—´çš„å…³é”®å·®å¼‚ï¼Œå¦‚æ²¿æçº¿çš„æ·±åº¦èŒƒå›´å˜åŒ–åŠä½ç»†èŠ‚èˆªç©ºå›¾åƒçš„ç‰¹å¾åŒ¹é…ä¸æ•æ„Ÿã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§è‡ªé€‚åº”æ·±åº¦èŒƒå›´MVSï¼ˆADR-MVSï¼‰ï¼Œé€šè¿‡æ•´åˆå•ç›®å‡ ä½•çº¿ç´¢æ¥æé«˜å¤šè§†å›¾æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚ADR-MVSçš„å…³é”®ç»„ä»¶æ˜¯æ·±åº¦èŒƒå›´é¢„æµ‹å™¨ï¼Œå®ƒåˆ©ç”¨äº¤å‰æ³¨æ„åŠ›å·®å¼‚å­¦ä¹ ç”Ÿæˆè‡ªé€‚åº”èŒƒå›´å›¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒADR-MVSåœ¨WHUã€LuoJia-MVSå’Œæ…•å°¼é»‘æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶å±•ç°å‡ºä¼˜è¶Šçš„è®¡ç®—å¤æ‚åº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³èˆªç©ºå¤šè§†å›¾ç«‹ä½“é‡å»ºä¸­çš„æ·±åº¦ä¼°è®¡ä¸å‡†ç¡®å’Œç‰¹å¾åŒ¹é…å›°éš¾ç­‰é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†èˆªç©ºå›¾åƒæ—¶ï¼Œå¸¸å¸¸å¿½ç•¥äº†æ·±åº¦èŒƒå›´çš„å˜åŒ–å’Œä½ç»†èŠ‚ç‰¹å¾çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šADR-MVSçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å•ç›®å‡ ä½•çº¿ç´¢æ¥å¢å¼ºæ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œåˆ©ç”¨æ·±åº¦èŒƒå›´é¢„æµ‹å™¨ç”Ÿæˆè‡ªé€‚åº”èŒƒå›´å›¾ï¼Œä»è€Œæ”¹å–„ç‰¹å¾åŒ¹é…çš„å¯è¾¨åˆ«æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šADR-MVSçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªé˜¶æ®µï¼Œé¦–å…ˆé€šè¿‡å•ç›®çº¿ç´¢ç”Ÿæˆåˆæ­¥çš„èŒƒå›´å›¾ï¼Œéšåé€æ­¥æ”¶çª„èŒƒå›´å›¾ï¼Œæœ€ç»ˆä¸çº§è”MVSæ¡†æ¶å¯¹æ¥ä»¥å®ç°ç²¾ç¡®çš„æ·±åº¦å›å½’ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†æ·±åº¦èŒƒå›´é¢„æµ‹å™¨å’ŒåŸºäºæ³•çº¿å¼•å¯¼çš„æˆæœ¬èšåˆæ“ä½œï¼Œæ˜¾è‘—æå‡äº†èˆªç©ºç«‹ä½“å›¾åƒçš„å‡ ä½•æ„ŸçŸ¥èƒ½åŠ›ï¼Œä¸ç°æœ‰çš„RGBå¼•å¯¼æ–¹æ³•ç›¸æ¯”ï¼Œæ•ˆæœæ›´ä½³ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†äº¤å‰æ³¨æ„åŠ›å·®å¼‚å­¦ä¹ æ¥ç”ŸæˆèŒƒå›´å›¾ï¼Œå¹¶è®¾è®¡äº†æ³•çº¿å¼•å¯¼çš„æˆæœ¬èšåˆæ¨¡å—ï¼Œä»¥å¢å¼ºæˆæœ¬ä½“ç§¯ä¸­çš„å‡ ä½•ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒADR-MVSåœ¨WHUã€LuoJia-MVSå’Œæ…•å°¼é»‘æ•°æ®é›†ä¸Šå‡å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œæ·±åº¦ä¼°è®¡ç²¾åº¦æå‡äº†XX%ï¼Œå¹¶ä¸”åœ¨è®¡ç®—å¤æ‚åº¦ä¸Šè¡¨ç°å‡ºæ˜æ˜¾ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨åŸå¸‚ä¸‰ç»´é‡å»ºã€æ— äººæœºèˆªæ‹å›¾åƒå¤„ç†åŠåœ°ç†ä¿¡æ¯ç³»ç»Ÿç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜èˆªç©ºå›¾åƒçš„æ·±åº¦ä¼°è®¡ç²¾åº¦ï¼Œèƒ½å¤Ÿä¸ºåŸå¸‚è§„åˆ’ã€ç¯å¢ƒç›‘æµ‹åŠç¾åé‡å»ºç­‰æä¾›æ›´ä¸ºå‡†ç¡®çš„æ•°æ®æ”¯æŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Three-dimensional digital urban reconstruction from multi-view aerial images is a critical application where deep multi-view stereo (MVS) methods outperform traditional techniques. However, existing methods commonly overlook the key differences between aerial and close-range settings, such as varying depth ranges along epipolar lines and insensitive feature-matching associated with low-detailed aerial images. To address these issues, we propose an Adaptive Depth Range MVS (ADR-MVS), which integrates monocular geometric cues to improve multi-view depth estimation accuracy. The key component of ADR-MVS is the depth range predictor, which generates adaptive range maps from depth and normal estimates using cross-attention discrepancy learning. In the first stage, the range map derived from monocular cues breaks through predefined depth boundaries, improving feature-matching discriminability and mitigating convergence to local optima. In later stages, the inferred range maps are progressively narrowed, ultimately aligning with the cascaded MVS framework for precise depth regression. Moreover, a normal-guided cost aggregation operation is specially devised for aerial stereo images to improve geometric awareness within the cost volume. Finally, we introduce a normal-guided depth refinement module that surpasses existing RGB-guided techniques. Experimental results demonstrate that ADR-MVS achieves state-of-the-art performance on the WHU, LuoJia-MVS, and MÃ¼nchen datasets, while exhibits superior computational complexity.

