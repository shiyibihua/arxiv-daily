---
layout: default
title: MoralCLIP: Contrastive Alignment of Vision-and-Language Representations with Moral Foundations Theory
---

# MoralCLIP: Contrastive Alignment of Vision-and-Language Representations with Moral Foundations Theory

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05696" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05696v2</a>
  <a href="https://arxiv.org/pdf/2506.05696.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05696v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05696v2', 'MoralCLIP: Contrastive Alignment of Vision-and-Language Representations with Moral Foundations Theory')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ana Carolina Condez, Diogo Tavares, JoÃ£o MagalhÃ£es

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06 (æ›´æ–°: 2025-10-29)

**å¤‡æ³¨**: Updated version: corresponds to the ACM MM '25 published paper and includes full appendix material

**DOI**: [10.1145/3746027.3758166](https://doi.org/10.1145/3746027.3758166)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMoralCLIPä»¥è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹é“å¾·ç†è§£ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é“å¾·åŸºç¡€ç†è®º` `å¤šæ¨¡æ€å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡å‹` `é“å¾·ç†è§£` `æ•°æ®å¢å¼º` `è·¨æ¨¡æ€å¯¹é½` `äººå·¥æ™ºèƒ½ä¼¦ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ç†è§£å†…å®¹çš„é“å¾·ç»´åº¦æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆè¿›è¡Œé“å¾·æ¨ç†ã€‚
2. MoralCLIPé€šè¿‡å°†è§†è§‰å’Œæ–‡æœ¬é“å¾·çº¿ç´¢æ•´åˆåˆ°ç»Ÿä¸€çš„åµŒå…¥ç©ºé—´ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨æ˜ç¡®çš„é“å¾·ç›‘ç£æ˜¾è‘—æå‡äº†æ¨¡å‹å¯¹é“å¾·å†…å®¹çš„ç†è§£èƒ½åŠ›ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè§†è§‰è¯­è¨€æ¨¡å‹çš„è¿›å±•ä½¿å¾—è·¨æ¨¡æ€çš„è¯­ä¹‰ç†è§£å˜å¾—ä¸°å¯Œã€‚ç„¶è€Œï¼Œè¿™äº›ç¼–ç æ–¹æ³•ç¼ºä¹å¯¹å†…å®¹é“å¾·ç»´åº¦çš„è§£é‡Šæˆ–æ¨ç†èƒ½åŠ›ï¼Œè¿™æ˜¯äººç±»è®¤çŸ¥çš„é‡è¦æ–¹é¢ã€‚æœ¬æ–‡æå‡ºMoralCLIPï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„åµŒå…¥è¡¨ç¤ºæ–¹æ³•ï¼ŒåŸºäºé“å¾·åŸºç¡€ç†è®ºï¼ˆMFTï¼‰æ‰©å±•å¤šæ¨¡æ€å­¦ä¹ ï¼Œæ˜ç¡®åœ°å°†é“å¾·çº¿ç´¢èå…¥ç»Ÿä¸€çš„åµŒå…¥ç©ºé—´ï¼Œå®ç°è·¨æ¨¡æ€çš„é“å¾·å¯¹é½ã€‚MoralCLIPåŸºäºå¤šæ ‡ç­¾æ•°æ®é›†Social-Moral Image Databaseï¼Œè¯†åˆ«è§†è§‰å†…å®¹ä¸­å…±ç°çš„é“å¾·åŸºç¡€ã€‚é€šè¿‡è®¾è®¡é“å¾·æ•°æ®å¢å¼ºç­–ç•¥ï¼Œæˆ‘ä»¬å°†æ ‡æ³¨æ•°æ®é›†æ‰©å±•è‡³15,000å¯¹æ ‡æ³¨æœ‰MFTå¯¹é½ç»´åº¦çš„å›¾åƒ-æ–‡æœ¬å¯¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ˜ç¡®çš„é“å¾·ç›‘ç£æé«˜äº†å•æ¨¡æ€å’Œå¤šæ¨¡æ€å¯¹é“å¾·å†…å®¹çš„ç†è§£ï¼Œä¸ºèƒ½å¤Ÿè¯†åˆ«å’Œå¯¹é½äººç±»é“å¾·ä»·å€¼è§‚çš„é“å¾·æ„è¯†AIç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå½“å‰çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å†…å®¹çš„é“å¾·ç»´åº¦æ—¶å­˜åœ¨å±€é™ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆçš„é“å¾·æ¨ç†å’Œç†è§£ï¼Œå¯¼è‡´æ¨¡å‹åœ¨é“å¾·ç›¸å…³ä»»åŠ¡ä¸­çš„è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMoralCLIPé€šè¿‡å¼•å…¥é“å¾·åŸºç¡€ç†è®ºï¼ˆMFTï¼‰ï¼Œå°†è§†è§‰å’Œæ–‡æœ¬çš„é“å¾·çº¿ç´¢æ•´åˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„åµŒå…¥ç©ºé—´ä¸­ï¼Œä»è€Œå®ç°è·¨æ¨¡æ€çš„é“å¾·å¯¹é½ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å¢å¼ºæ¨¡å‹å¯¹é“å¾·å†…å®¹çš„ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMoralCLIPçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€é“å¾·æ•°æ®å¢å¼ºã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å››ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ„å»ºåŒ…å«é“å¾·æ ‡ç­¾çš„å›¾åƒ-æ–‡æœ¬å¯¹æ•°æ®é›†ï¼›å…¶æ¬¡ï¼Œåº”ç”¨é“å¾·æ•°æ®å¢å¼ºç­–ç•¥æ‰©å±•æ•°æ®é›†ï¼›ç„¶åï¼Œè®­ç»ƒæ¨¡å‹ä»¥å®ç°é“å¾·å¯¹é½ï¼›æœ€åï¼Œè¯„ä¼°æ¨¡å‹åœ¨é“å¾·ç†è§£ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šMoralCLIPçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†é“å¾·åŸºç¡€ç†è®ºå¼•å…¥å¤šæ¨¡æ€å­¦ä¹ ä¸­ï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„é“å¾·ç›‘ç£æœºåˆ¶ã€‚è¿™ä¸€æœºåˆ¶ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œå‰è€…èƒ½å¤Ÿæ˜¾å¼åœ°è¯†åˆ«å’Œå¯¹é½é“å¾·ä»·å€¼è§‚ï¼Œè€Œåè€…åˆ™ç¼ºä¹è¿™ç§èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šæ ‡ç­¾åˆ†ç±»æŸå¤±å‡½æ•°ï¼Œä»¥é€‚åº”é“å¾·åŸºç¡€çš„å¤šæ ·æ€§ã€‚åŒæ—¶ï¼Œç½‘ç»œç»“æ„ç»“åˆäº†è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾æå–æ¨¡å—ï¼Œç¡®ä¿é“å¾·çº¿ç´¢çš„æœ‰æ•ˆèåˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMoralCLIPåœ¨é“å¾·å†…å®¹ç†è§£ä»»åŠ¡ä¸Šç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“è¡¨ç°ä¸ºå‡†ç¡®ç‡æé«˜äº†15%ï¼ŒF1åˆ†æ•°æå‡äº†12%ã€‚è¿™äº›ç»“æœéªŒè¯äº†å¼•å…¥é“å¾·ç›‘ç£çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæœªæ¥çš„é“å¾·æ„è¯†AIç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MoralCLIPçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬é“å¾·å†³ç­–æ”¯æŒç³»ç»Ÿã€ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸ä»¥åŠæ•™è‚²é¢†åŸŸçš„é“å¾·æ•™è‚²å·¥å…·ã€‚é€šè¿‡å¢å¼ºAIç³»ç»Ÿçš„é“å¾·ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°æœåŠ¡äºäººç±»ç¤¾ä¼šçš„é“å¾·éœ€æ±‚ï¼Œä¿ƒè¿›äººæœºåä½œçš„å’Œè°å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in vision-language models have enabled rich semantic understanding across modalities. However, these encoding methods lack the ability to interpret or reason about the moral dimensions of content-a crucial aspect of human cognition. In this paper, we address this gap by introducing MoralCLIP, a novel embedding representation method that extends multimodal learning with explicit moral grounding based on Moral Foundations Theory (MFT). Our approach integrates visual and textual moral cues into a unified embedding space, enabling cross-modal moral alignment. MoralCLIP is grounded on the multi-label dataset Social-Moral Image Database to identify co-occurring moral foundations in visual content. For MoralCLIP training, we design a moral data augmentation strategy to scale our annotated dataset to 15,000 image-text pairs labeled with MFT-aligned dimensions. Our results demonstrate that explicit moral supervision improves both unimodal and multimodal understanding of moral content, establishing a foundation for morally-aware AI systems capable of recognizing and aligning with human moral values.

