---
layout: default
title: See the Text: From Tokenization to Visual Reading
---

# See the Text: From Tokenization to Visual Reading

**arXiv**: [2510.18840v1](https://arxiv.org/abs/2510.18840) | [PDF](https://arxiv.org/pdf/2510.18840.pdf)

**ä½œè€…**: Ling Xing, Alex Jinpeng Wang, Rui Yan, Hongyu Qu, Zechao Li, Jinhui Tang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSeeTokæ–¹æ³•ï¼Œé€šè¿‡è§†è§‰åŒ–æ–‡æœ¬å¤„ç†è§£å†³å­è¯åˆ†è¯åœ¨ä½Žèµ„æºè¯­è¨€ä¸­çš„è¿‡åˆ†å‰²é—®é¢˜ã€‚**

**å…³é”®è¯**: `è§†è§‰æ–‡æœ¬å¤„ç†` `å¤šæ¨¡æ€å¤§æ¨¡åž‹` `å­è¯åˆ†è¯` `ä½Žèµ„æºè¯­è¨€` `è®¡ç®—æ•ˆçŽ‡ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå­è¯åˆ†è¯åœ¨ä½Žèµ„æºè¯­è¨€ä¸­è¿‡åˆ†å‰²ï¼Œå¯¼è‡´åºåˆ—é•¿ã€è®¡ç®—é‡å¤§ä¸”è¯­ä¹‰ç¼ºå¤±ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†æ–‡æœ¬æ¸²æŸ“ä¸ºå›¾åƒï¼Œåˆ©ç”¨é¢„è®­ç»ƒå¤šæ¨¡æ€å¤§æ¨¡åž‹è¿›è¡Œè§†è§‰è¯»å–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªè¯­è¨€ä»»åŠ¡ä¸­ï¼Œå‡å°‘70.5% FLOPsï¼Œæå‡è·¨è¯­è¨€æ³›åŒ–å’ŒæŠ—å™ªèƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> People see text. Humans read by recognizing words as visual objects,
> including their shapes, layouts, and patterns, before connecting them to
> meaning, which enables us to handle typos, distorted fonts, and various scripts
> effectively. Modern large language models (LLMs), however, rely on subword
> tokenization, fragmenting text into pieces from a fixed vocabulary. While
> effective for high-resource languages, this approach over-segments low-resource
> languages, yielding long, linguistically meaningless sequences and inflating
> computation. In this work, we challenge this entrenched paradigm and move
> toward a vision-centric alternative. Our method, SeeTok, renders text as images
> (visual-text) and leverages pretrained multimodal LLMs to interpret them,
> reusing strong OCR and text-vision alignment abilities learned from large-scale
> multimodal training. Across three different language tasks, SeeTok matches or
> surpasses subword tokenizers while requiring 4.43 times fewer tokens and
> reducing FLOPs by 70.5%, with additional gains in cross-lingual generalization,
> robustness to typographic noise, and linguistic hierarchy. SeeTok signals a
> shift from symbolic tokenization to human-like visual reading, and takes a step
> toward more natural and cognitively inspired language models.

