---
layout: default
title: EfficientNav: Towards On-Device Object-Goal Navigation with Navigation Map Caching and Retrieval
---

# EfficientNav: Towards On-Device Object-Goal Navigation with Navigation Map Caching and Retrieval

**arXiv**: [2510.18546v1](https://arxiv.org/abs/2510.18546) | [PDF](https://arxiv.org/pdf/2510.18546.pdf)

**ä½œè€…**: Zebin Yang, Sunjian Zheng, Tong Xie, Tianshi Xu, Bo Yu, Fan Wang, Jie Tang, Shaoshan Liu, Meng Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEfficientNavä»¥è§£å†³è®¾å¤‡ç«¯å¯¹è±¡ç›®æ ‡å¯¼èˆªä¸­çš„é«˜å»¶è¿Ÿå’Œä½ŽæˆåŠŸçŽ‡é—®é¢˜**

**å…³é”®è¯**: `å¯¹è±¡ç›®æ ‡å¯¼èˆª` `è®¾å¤‡ç«¯æŽ¨ç†` `è®°å¿†æ£€ç´¢` `KVç¼“å­˜ä¼˜åŒ–` `è¯­ä¹‰æ„ŸçŸ¥` `å¯¼èˆªåœ°å›¾`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè®¾å¤‡ç«¯å°è¯­è¨€æ¨¡åž‹åœ¨å¯¹è±¡ç›®æ ‡å¯¼èˆªä¸­å› åœ°å›¾ç†è§£èƒ½åŠ›ä¸è¶³å¯¼è‡´æˆåŠŸçŽ‡ä¸‹é™å’Œå»¶è¿Ÿé«˜
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨è¯­ä¹‰æ„ŸçŸ¥è®°å¿†æ£€ç´¢å’Œç¦»æ•£è®°å¿†ç¼“å­˜ä¼˜åŒ–å¯¼èˆªåœ°å›¾å¤„ç†ä¸ŽKVç¼“å­˜é‡ç”¨
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨HM3DåŸºå‡†ä¸ŠæˆåŠŸçŽ‡æå‡11.1%ï¼Œå»¶è¿Ÿé™ä½Ž6.7å€å®žæ—¶å’Œ4.7å€ç«¯åˆ°ç«¯

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Object-goal navigation (ObjNav) tasks an agent with navigating to the
> location of a specific object in an unseen environment. Embodied agents
> equipped with large language models (LLMs) and online constructed navigation
> maps can perform ObjNav in a zero-shot manner. However, existing agents heavily
> rely on giant LLMs on the cloud, e.g., GPT-4, while directly switching to small
> LLMs, e.g., LLaMA3.2-11b, suffer from significant success rate drops due to
> limited model capacity for understanding complex navigation maps, which
> prevents deploying ObjNav on local devices. At the same time, the long prompt
> introduced by the navigation map description will cause high planning latency
> on local devices. In this paper, we propose EfficientNav to enable on-device
> efficient LLM-based zero-shot ObjNav. To help the smaller LLMs better
> understand the environment, we propose semantics-aware memory retrieval to
> prune redundant information in navigation maps. To reduce planning latency, we
> propose discrete memory caching and attention-based memory clustering to
> efficiently save and re-use the KV cache. Extensive experimental results
> demonstrate that EfficientNav achieves 11.1% improvement in success rate on
> HM3D benchmark over GPT-4-based baselines, and demonstrates 6.7x real-time
> latency reduction and 4.7x end-to-end latency reduction over GPT-4 planner. Our
> code will be released soon.

