---
layout: default
title: Beyond Single Models: Mitigating Multimodal Hallucinations via Adaptive Token Ensemble Decoding
---

# Beyond Single Models: Mitigating Multimodal Hallucinations via Adaptive Token Ensemble Decoding

**arXiv**: [2510.18321v1](https://arxiv.org/abs/2510.18321) | [PDF](https://arxiv.org/pdf/2510.18321.pdf)

**ä½œè€…**: Jinlin Li, Yuran Wang, Yifei Yuan, Xiao Zhou, Yingying Zhang, Xixian Yong, Yefeng Zheng, Xian Wu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªé€‚åº”ä»¤ç‰Œé›†æˆè§£ç ä»¥ç¼“è§£å¤šæ¨¡æ€å¤§æ¨¡åž‹ä¸­çš„ç‰©ä½“å¹»è§‰é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§æ¨¡åž‹` `ç‰©ä½“å¹»è§‰` `é›†æˆè§£ç ` `è‡ªé€‚åº”æƒé‡` `æŽ¨ç†ä¼˜åŒ–` `è¯­ä¹‰ä¸€è‡´æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€å¤§æ¨¡åž‹åœ¨å›¾åƒæè¿°ç­‰ä»»åŠ¡ä¸­æ˜“äº§ç”Ÿç‰©ä½“å¹»è§‰ï¼Œç”Ÿæˆä¸å­˜åœ¨æˆ–è¯¯è¯†åˆ«å¯¹è±¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ— éœ€è®­ç»ƒçš„ä»¤ç‰Œçº§é›†æˆæ¡†æž¶ï¼ŒåŠ¨æ€åŠ æƒèšåˆå¤šä¸ªæ¨¡åž‹é¢„æµ‹ä»¥æå‡å¯é æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—å‡å°‘å¹»è§‰ï¼Œä¿æŒæµç•…æ€§å’Œç›¸å…³æ€§ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Vision-Language Models (LVLMs) have recently achieved impressive
> results in multimodal tasks such as image captioning and visual question
> answering. However, they remain prone to object hallucination -- generating
> descriptions of nonexistent or misidentified objects. Prior work has partially
> mitigated this via auxiliary training objectives or external modules, but
> challenges remain in terms of scalability, adaptability, and model
> independence. To address these limitations, we propose Adaptive Token Ensemble
> Decoding (ATED), a training-free, token-level ensemble framework that mitigates
> hallucination by aggregating predictions from multiple LVLMs during inference.
> ATED dynamically computes uncertainty-based weights for each model, reflecting
> their reliability at each decoding step. It also integrates diverse decoding
> paths to improve contextual grounding and semantic consistency. Experiments on
> standard hallucination detection benchmarks demonstrate that ATED significantly
> outperforms state-of-the-art methods, reducing hallucination without
> compromising fluency or relevance. Our findings highlight the benefits of
> adaptive ensembling and point to a promising direction for improving LVLM
> robustness in high-stakes applications. The code is available at
> https://github.com/jinlin2021/ATED.

