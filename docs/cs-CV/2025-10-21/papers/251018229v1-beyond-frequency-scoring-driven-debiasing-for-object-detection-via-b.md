---
layout: default
title: Beyond Frequency: Scoring-Driven Debiasing for Object Detection via Blueprint-Prompted Image Synthesis
---

# Beyond Frequency: Scoring-Driven Debiasing for Object Detection via Blueprint-Prompted Image Synthesis

**arXiv**: [2510.18229v1](https://arxiv.org/abs/2510.18229) | [PDF](https://arxiv.org/pdf/2510.18229.pdf)

**ä½œè€…**: Xinhao Cai, Liulei Li, Gensheng Pei, Tao Chen, Jinshan Pan, Yazhou Yao, Wenguan Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè¡¨ç¤ºåˆ†æ•°å’Œè“å›¾æç¤ºçš„å›¾åƒåˆæˆæ¡†æž¶ï¼Œä»¥è§£å†³ç›®æ ‡æ£€æµ‹ä¸­çš„è¡¨ç¤ºåå·®é—®é¢˜ã€‚**

**å…³é”®è¯**: `ç›®æ ‡æ£€æµ‹` `åŽ»åæ–¹æ³•` `å›¾åƒåˆæˆ` `è¡¨ç¤ºåˆ†æ•°` `ç”Ÿæˆå¯¹é½` `è§†è§‰è“å›¾`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰åŽ»åæ–¹æ³•å—é™äºŽæ ·æœ¬å¤šæ ·æ€§ï¼Œä¸”ç”Ÿæˆå¼å¢žå¼ºæ˜“ä¿ç•™åå·®ï¼›å®žä¾‹é¢‘çŽ‡ä¸è¶³ä»¥åæ˜ æ¨¡åž‹çœŸå®žéœ€æ±‚ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥è¡¨ç¤ºåˆ†æ•°è¯Šæ–­è¡¨ç¤ºå·®è·ï¼Œä½¿ç”¨è§†è§‰è“å›¾å’Œç”Ÿæˆå¯¹é½ç­–ç•¥æå‡åˆæˆå›¾åƒè´¨é‡ä¸ŽæŽ§åˆ¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ˜¾è‘—æ”¹å–„ç½•è§å¯¹è±¡æ£€æµ‹æ€§èƒ½ï¼Œå¦‚å¤§/ç¨€æœ‰å®žä¾‹mAPæå‡4.4/3.6ï¼Œå¸ƒå±€ç²¾åº¦è¶…è¶Šå…ˆå‰æ¨¡åž‹15.9 mAPã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper presents a generation-based debiasing framework for object
> detection. Prior debiasing methods are often limited by the representation
> diversity of samples, while naive generative augmentation often preserves the
> biases it aims to solve. Moreover, our analysis reveals that simply generating
> more data for rare classes is suboptimal due to two core issues: i) instance
> frequency is an incomplete proxy for the true data needs of a model, and ii)
> current layout-to-image synthesis lacks the fidelity and control to generate
> high-quality, complex scenes. To overcome this, we introduce the representation
> score (RS) to diagnose representational gaps beyond mere frequency, guiding the
> creation of new, unbiased layouts. To ensure high-quality synthesis, we replace
> ambiguous text prompts with a precise visual blueprint and employ a generative
> alignment strategy, which fosters communication between the detector and
> generator. Our method significantly narrows the performance gap for
> underrepresented object groups, \eg, improving large/rare instances by 4.4/3.6
> mAP over the baseline, and surpassing prior L2I synthesis models by 15.9 mAP
> for layout accuracy in generated images.

