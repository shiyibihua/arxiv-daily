---
layout: default
title: StreamingTOM: Streaming Token Compression for Efficient Video Understanding
---

# StreamingTOM: Streaming Token Compression for Efficient Video Understanding

**arXiv**: [2510.18269v1](https://arxiv.org/abs/2510.18269) | [PDF](https://arxiv.org/pdf/2510.18269.pdf)

**ä½œè€…**: Xueyi Chen, Keda Tao, Kele Shao, Huan Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºStreamingTOMæ¡†æž¶ä»¥è§£å†³æµå¼è§†é¢‘ç†è§£ä¸­çš„å› æžœæ€§å’Œç´¯ç§¯æ€§æ•ˆçŽ‡ç“¶é¢ˆ**

**å…³é”®è¯**: `æµå¼è§†é¢‘ç†è§£` `ä»¤ç‰ŒåŽ‹ç¼©` `å› æžœæ€§å¤„ç†` `é”®å€¼ç¼“å­˜ä¼˜åŒ–` `è®­ç»ƒå…è´¹æ–¹æ³•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæµå¼è§†é¢‘æ¨¡åž‹å—å› æžœæ€§é™åˆ¶æ— æ³•è®¿é—®æœªæ¥å¸§ï¼Œä¸”ä»¤ç‰Œç´¯ç§¯å¯¼è‡´æ•ˆçŽ‡ä¸‹é™
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å› æžœæ—¶é—´å‡å°‘å’Œåœ¨çº¿é‡åŒ–å†…å­˜ä¸¤é˜¶æ®µï¼ŒåŽ‹ç¼©é¢„å¡«å……å’Œé”®å€¼ç¼“å­˜
3. å®žéªŒæ•ˆæžœï¼šå®žçŽ°15.7å€é”®å€¼ç¼“å­˜åŽ‹ç¼©ã€2å€é¦–ä»¤ç‰Œæ—¶é—´åŠ é€Ÿï¼Œä¿æŒé«˜å‡†ç¡®çŽ‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Unlike offline processing, streaming video vision-language models face two
> fundamental constraints: causality and accumulation. Causality prevents access
> to future frames that offline methods exploit, while accumulation causes tokens
> to grow unbounded, creating efficiency bottlenecks. However, existing
> approaches only regulate post-LLM kv-cache, leaving costly pre-LLM prefill
> unchanged. We introduce StreamingTOM, a training-free, plug-and-play two-stage
> framework that addresses both pre-LLM and post-LLM bottlenecks with predictable
> latency. Causal Temporal Reduction imposes a fixed per-frame budget and selects
> tokens based on adjacent-frame changes and token saliency, drastically reducing
> per-frame prefill cost by processing only a compact subset of visual tokens per
> frame instead of all visual tokens. Online Quantized Memory stores tokens in
> 4-bit format, retrieves relevant groups on demand, and dequantizes them,
> keeping the active kv-cache bounded regardless of stream length. Experiments
> demonstrate our method achieves $15.7\times$ kv-cache compression, $1.2\times$
> lower peak memory and $2\times$ faster TTFT compared to prior SOTA.
> StreamingTOM maintains state-of-the-art accuracy among training-free methods
> with an average of $63.8\%$ on offline benchmarks and $55.8\%/3.7$ on RVS.
> These results highlight the practical benefits of our two-stage approach for
> efficient streaming video understanding with bounded growth.

