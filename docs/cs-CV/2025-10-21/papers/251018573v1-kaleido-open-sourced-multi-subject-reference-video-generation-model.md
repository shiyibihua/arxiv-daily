---
layout: default
title: Kaleido: Open-Sourced Multi-Subject Reference Video Generation Model
---

# Kaleido: Open-Sourced Multi-Subject Reference Video Generation Model

**arXiv**: [2510.18573v1](https://arxiv.org/abs/2510.18573) | [PDF](https://arxiv.org/pdf/2510.18573.pdf)

**ä½œè€…**: Zhenxing Zhang, Jiayan Teng, Zhuoyi Yang, Tiankun Cao, Cheng Wang, Xiaotao Gu, Jie Tang, Dan Guo, Meng Wang

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºKaleidoæ¡†æ¶ä»¥è§£å†³å¤šä¸»ä½“å‚è€ƒè§†é¢‘ç”Ÿæˆä¸­çš„ä¸€è‡´æ€§å’ŒèƒŒæ™¯åˆ†ç¦»é—®é¢˜**

**å…³é”®è¯**: `ä¸»é¢˜åˆ°è§†é¢‘ç”Ÿæˆ` `å¤šä¸»ä½“ä¸€è‡´æ€§` `å‚è€ƒå›¾åƒé›†æˆ` `æ•°æ®åˆæˆ` `ä½ç½®ç¼–ç ` `è§†é¢‘åˆæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ–¹æ³•åœ¨å¤šå›¾åƒæ¡ä»¶ä¸‹éš¾ä»¥ä¿æŒå¤šä¸»ä½“ä¸€è‡´æ€§å’ŒèƒŒæ™¯åˆ†ç¦»ï¼Œå¯¼è‡´å‚è€ƒä¿çœŸåº¦ä½å’Œè¯­ä¹‰æ¼‚ç§»
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥æ•°æ®æ„å»ºç®¡é“å’Œå‚è€ƒæ—‹è½¬ä½ç½®ç¼–ç ï¼Œä¼˜åŒ–å¤šå‚è€ƒå›¾åƒé›†æˆå’Œè®­ç»ƒæ•°æ®è´¨é‡
3. å®éªŒæˆ–æ•ˆæœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒKaleidoåœ¨ä¸€è‡´æ€§ã€ä¿çœŸåº¦å’Œæ³›åŒ–æ€§ä¸Šæ˜¾è‘—ä¼˜äºå…ˆå‰æ–¹æ³•

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present Kaleido, a subject-to-video~(S2V) generation framework, which aims
> to synthesize subject-consistent videos conditioned on multiple reference
> images of target subjects. Despite recent progress in S2V generation models,
> existing approaches remain inadequate at maintaining multi-subject consistency
> and at handling background disentanglement, often resulting in lower reference
> fidelity and semantic drift under multi-image conditioning. These shortcomings
> can be attributed to several factors. Primarily, the training dataset suffers
> from a lack of diversity and high-quality samples, as well as cross-paired
> data, i.e., paired samples whose components originate from different instances.
> In addition, the current mechanism for integrating multiple reference images is
> suboptimal, potentially resulting in the confusion of multiple subjects. To
> overcome these limitations, we propose a dedicated data construction pipeline,
> incorporating low-quality sample filtering and diverse data synthesis, to
> produce consistency-preserving training data. Moreover, we introduce Reference
> Rotary Positional Encoding (R-RoPE) to process reference images, enabling
> stable and precise multi-image integration. Extensive experiments across
> numerous benchmarks demonstrate that Kaleido significantly outperforms previous
> methods in consistency, fidelity, and generalization, marking an advance in S2V
> generation.

