---
layout: default
title: SAM 2++: Tracking Anything at Any Granularity
---

# SAM 2++: Tracking Anything at Any Granularity

**arXiv**: [2510.18822v1](https://arxiv.org/abs/2510.18822) | [PDF](https://arxiv.org/pdf/2510.18822.pdf)

**ä½œè€…**: Jiaming Zhang, Cheng Liang, Yichun Yang, Chenkai Zeng, Yutao Cui, Xinwen Zhang, Xin Zhou, Kai Ma, Gangshan Wu, Limin Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSAM 2++ç»Ÿä¸€æ¨¡åž‹ä»¥è§£å†³è§†é¢‘è·Ÿè¸ªä¸­ä¸åŒç²’åº¦ä»»åŠ¡çš„åˆ†å‰²é—®é¢˜**

**å…³é”®è¯**: `è§†é¢‘è·Ÿè¸ª` `ç»Ÿä¸€æ¨¡åž‹` `ä»»åŠ¡è‡ªé€‚åº”å†…å­˜` `å¤šç²’åº¦è·Ÿè¸ª` `æ•°æ®å¼•æ“Ž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è·Ÿè¸ªå™¨é’ˆå¯¹å•ä¸€ä»»åŠ¡è®¾è®¡ï¼Œç¼ºä¹æ³›åŒ–æ€§ï¼Œå¯¼è‡´æ¨¡åž‹å†—ä½™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡ä»»åŠ¡ç‰¹å®šæç¤ºå’Œç»Ÿä¸€è§£ç å™¨ï¼Œå¼•å…¥ä»»åŠ¡è‡ªé€‚åº”å†…å­˜æœºåˆ¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®žçŽ°æ–°SOTAï¼ŒéªŒè¯ç»Ÿä¸€è·Ÿè¸ªæ¡†æž¶çš„é²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video tracking aims at finding the specific target in subsequent frames given
> its initial state. Due to the varying granularity of target states across
> different tasks, most existing trackers are tailored to a single task and
> heavily rely on custom-designed modules within the individual task, which
> limits their generalization and leads to redundancy in both model design and
> parameters. To unify video tracking tasks, we present SAM 2++, a unified model
> towards tracking at any granularity, including masks, boxes, and points. First,
> to extend target granularity, we design task-specific prompts to encode various
> task inputs into general prompt embeddings, and a unified decoder to unify
> diverse task results into a unified form pre-output. Next, to satisfy memory
> matching, the core operation of tracking, we introduce a task-adaptive memory
> mechanism that unifies memory across different granularities. Finally, we
> introduce a customized data engine to support tracking training at any
> granularity, producing a large and diverse video tracking dataset with rich
> annotations at three granularities, termed Tracking-Any-Granularity, which
> represents a comprehensive resource for training and benchmarking on unified
> tracking. Comprehensive experiments on multiple benchmarks confirm that SAM 2++
> sets a new state of the art across diverse tracking tasks at different
> granularities, establishing a unified and robust tracking framework.

