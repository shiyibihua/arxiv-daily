---
layout: default
title: ScaleNet: Scaling up Pretrained Neural Networks with Incremental Parameters
---

# ScaleNet: Scaling up Pretrained Neural Networks with Incremental Parameters

**arXiv**: [2510.18431v1](https://arxiv.org/abs/2510.18431) | [PDF](https://arxiv.org/pdf/2510.18431.pdf)

**ä½œè€…**: Zhiwei Hao, Jianyuan Guo, Li Shen, Kai Han, Yehui Tang, Han Hu, Yunhe Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºScaleNetä»¥é«˜æ•ˆæ‰©å±•é¢„è®­ç»ƒè§†è§‰Transformeræ¨¡åž‹**

**å…³é”®è¯**: `è§†è§‰Transformer` `æ¨¡åž‹æ‰©å±•` `å‚æ•°å…±äº«` `é«˜æ•ˆè®­ç»ƒ` `å›¾åƒåˆ†ç±»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè®­ç»ƒå¤§åž‹è§†è§‰Transformeræ¨¡åž‹è®¡ç®—æˆæœ¬é«˜ä¸”è€—æ—¶
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æ’å…¥å…±äº«æƒé‡å±‚å’Œè°ƒæ•´å‚æ•°å®žçŽ°æ¨¡åž‹æ‰©å±•
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ImageNet-1Kä¸Šï¼Œ2å€æ·±åº¦æ‰©å±•æ¨¡åž‹å‡†ç¡®çŽ‡æå‡7.42%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advancements in vision transformers (ViTs) have demonstrated that
> larger models often achieve superior performance. However, training these
> models remains computationally intensive and costly. To address this challenge,
> we introduce ScaleNet, an efficient approach for scaling ViT models. Unlike
> conventional training from scratch, ScaleNet facilitates rapid model expansion
> with negligible increases in parameters, building on existing pretrained
> models. This offers a cost-effective solution for scaling up ViTs.
> Specifically, ScaleNet achieves model expansion by inserting additional layers
> into pretrained ViTs, utilizing layer-wise weight sharing to maintain
> parameters efficiency. Each added layer shares its parameter tensor with a
> corresponding layer from the pretrained model. To mitigate potential
> performance degradation due to shared weights, ScaleNet introduces a small set
> of adjustment parameters for each layer. These adjustment parameters are
> implemented through parallel adapter modules, ensuring that each instance of
> the shared parameter tensor remains distinct and optimized for its specific
> function. Experiments on the ImageNet-1K dataset demonstrate that ScaleNet
> enables efficient expansion of ViT models. With a 2$\times$ depth-scaled
> DeiT-Base model, ScaleNet achieves a 7.42% accuracy improvement over training
> from scratch while requiring only one-third of the training epochs,
> highlighting its efficiency in scaling ViTs. Beyond image classification, our
> method shows significant potential for application in downstream vision areas,
> as evidenced by the validation in object detection task.

