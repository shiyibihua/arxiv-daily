---
layout: default
title: Descriptor: Occluded nuScenes: A Multi-Sensor Dataset for Evaluating Perception Robustness in Automated Driving
---

# Descriptor: Occluded nuScenes: A Multi-Sensor Dataset for Evaluating Perception Robustness in Automated Driving

**arXiv**: [2510.18552v1](https://arxiv.org/abs/2510.18552) | [PDF](https://arxiv.org/pdf/2510.18552.pdf)

**ä½œè€…**: Sanjay Kumar, Tim Brophy, Reenu Mohandas, Eoin Martino Grua, Ganesh Sistu, Valentina Donzella, Ciaran Eising

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOccluded nuScenesæ•°æ®é›†ä»¥è¯„ä¼°è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥åœ¨ä¼ æ„Ÿå™¨é®æŒ¡ä¸‹çš„é²æ£’æ€§**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥` `å¤šä¼ æ„Ÿå™¨æ•°æ®é›†` `ä¼ æ„Ÿå™¨é®æŒ¡` `é²æ£’æ€§è¯„ä¼°` `nuScenesæ‰©å±•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ•°æ®é›†ç¼ºä¹å¯æŽ§å¤šä¼ æ„Ÿå™¨é€€åŒ–ï¼Œé™åˆ¶æ„ŸçŸ¥æ¨¡åž‹åœ¨ä¸è‰¯æ¡ä»¶ä¸‹çš„ç³»ç»Ÿè¯„ä¼°
2. æ–¹æ³•è¦ç‚¹ï¼šæ‰©å±•nuScenesï¼Œæä¾›ç›¸æœºã€é›·è¾¾å’ŒLiDARçš„å‚æ•°åŒ–é®æŒ¡è„šæœ¬ï¼Œæ”¯æŒå¯é‡å¤æ•°æ®ç”Ÿæˆ
3. å®žéªŒæˆ–æ•ˆæžœï¼šæœªçŸ¥å…·ä½“æ€§èƒ½æå‡ï¼Œä½†èµ„æºæ”¯æŒä¸€è‡´ã€å¯é‡å¤çš„æ„ŸçŸ¥æ¨¡åž‹è¯„ä¼°

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Robust perception in automated driving requires reliable performance under
> adverse conditions, where sensors may be affected by partial failures or
> environmental occlusions. Although existing autonomous driving datasets
> inherently contain sensor noise and environmental variability, very few enable
> controlled, parameterised, and reproducible degradations across multiple
> sensing modalities. This gap limits the ability to systematically evaluate how
> perception and fusion architectures perform under well-defined adverse
> conditions. To address this limitation, we introduce the Occluded nuScenes
> Dataset, a novel extension of the widely used nuScenes benchmark. For the
> camera modality, we release both the full and mini versions with four types of
> occlusions, two adapted from public implementations and two newly designed. For
> radar and LiDAR, we provide parameterised occlusion scripts that implement
> three types of degradations each, enabling flexible and repeatable generation
> of occluded data. This resource supports consistent, reproducible evaluation of
> perception models under partial sensor failures and environmental interference.
> By releasing the first multi-sensor occlusion dataset with controlled and
> reproducible degradations, we aim to advance research on robust sensor fusion,
> resilience analysis, and safety-critical perception in automated driving.

