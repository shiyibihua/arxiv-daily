---
layout: default
title: Beyond Single Images: Retrieval Self-Augmented Unsupervised Camouflaged Object Detection
---

# Beyond Single Images: Retrieval Self-Augmented Unsupervised Camouflaged Object Detection

**arXiv**: [2510.18437v1](https://arxiv.org/abs/2510.18437) | [PDF](https://arxiv.org/pdf/2510.18437.pdf)

**ä½œè€…**: Ji Du, Xin Wang, Fangwei Hao, Mingyang Yu, Chunyuan Chen, Jiesheng Wu, Bin Wang, Jing Xu, Ping Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRISEæ£€ç´¢è‡ªå¢žå¼ºèŒƒå¼ï¼Œåˆ©ç”¨æ•°æ®é›†ä¸Šä¸‹æ–‡ç”Ÿæˆä¼ªæ ‡ç­¾ä»¥è§£å†³æ— ç›‘ç£ä¼ªè£…ç‰©ä½“æ£€æµ‹é—®é¢˜**

**å…³é”®è¯**: `ä¼ªè£…ç‰©ä½“æ£€æµ‹` `æ— ç›‘ç£å­¦ä¹ ` `æ£€ç´¢å¢žå¼º` `ä¼ªæ ‡ç­¾ç”Ÿæˆ` `å¤šè§†å›¾æ£€ç´¢` `åŽŸåž‹åº“æž„å»º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ªè£…ç‰©ä½“æ£€æµ‹éœ€ä»Žé«˜åº¦ç›¸ä¼¼èƒŒæ™¯ä¸­åˆ†å‰²ç‰©ä½“ï¼ŒçŽ°æœ‰æ–¹æ³•ä¾èµ–å›¾åƒçº§å»ºæ¨¡æˆ–æ ‡æ³¨ï¼Œæœªå……åˆ†åˆ©ç”¨æ•°æ®é›†çº§ä¿¡æ¯
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡èšç±»-æ£€ç´¢ç­–ç•¥æž„å»ºåŽŸåž‹åº“ï¼Œå¹¶é‡‡ç”¨å¤šè§†å›¾KNNæ£€ç´¢ç”Ÿæˆé²æ£’ä¼ªæŽ©ç ï¼Œæ— éœ€æ ‡æ³¨
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ— ç›‘ç£å’Œæç¤ºæ–¹æ³•ä¸­è¡¨çŽ°ä¼˜å¼‚ï¼Œä»£ç å·²å¼€æº

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> At the core of Camouflaged Object Detection (COD) lies segmenting objects
> from their highly similar surroundings. Previous efforts navigate this
> challenge primarily through image-level modeling or annotation-based
> optimization. Despite advancing considerably, this commonplace practice hardly
> taps valuable dataset-level contextual information or relies on laborious
> annotations. In this paper, we propose RISE, a RetrIeval SElf-augmented
> paradigm that exploits the entire training dataset to generate pseudo-labels
> for single images, which could be used to train COD models. RISE begins by
> constructing prototype libraries for environments and camouflaged objects using
> training images (without ground truth), followed by K-Nearest Neighbor (KNN)
> retrieval to generate pseudo-masks for each image based on these libraries. It
> is important to recognize that using only training images without annotations
> exerts a pronounced challenge in crafting high-quality prototype libraries. In
> this light, we introduce a Clustering-then-Retrieval (CR) strategy, where
> coarse masks are first generated through clustering, facilitating subsequent
> histogram-based image filtering and cross-category retrieval to produce
> high-confidence prototypes. In the KNN retrieval stage, to alleviate the effect
> of artifacts in feature maps, we propose Multi-View KNN Retrieval (MVKR), which
> integrates retrieval results from diverse views to produce more robust and
> precise pseudo-masks. Extensive experiments demonstrate that RISE outperforms
> state-of-the-art unsupervised and prompt-based methods. Code is available at
> https://github.com/xiaohainku/RISE.

