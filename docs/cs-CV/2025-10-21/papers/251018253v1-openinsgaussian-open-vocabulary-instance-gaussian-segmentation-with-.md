---
layout: default
title: OpenInsGaussian: Open-vocabulary Instance Gaussian Segmentation with Context-aware Cross-view Fusion
---

# OpenInsGaussian: Open-vocabulary Instance Gaussian Segmentation with Context-aware Cross-view Fusion

**arXiv**: [2510.18253v1](https://arxiv.org/abs/2510.18253) | [PDF](https://arxiv.org/pdf/2510.18253.pdf)

**ä½œè€…**: Tianyu Huang, Runnan Chen, Dongting Hu, Fengming Huang, Mingming Gong, Tongliang Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOpenInsGaussianæ¡†æž¶ï¼Œé€šè¿‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰¹å¾æå–å’Œæ³¨æ„åŠ›é©±åŠ¨èžåˆï¼Œæå‡å¼€æ”¾è¯æ±‡3Dé«˜æ–¯åˆ†å‰²æ€§èƒ½ã€‚**

**å…³é”®è¯**: `3Dåœºæ™¯ç†è§£` `é«˜æ–¯åˆ†å‰²` `å¼€æ”¾è¯æ±‡åˆ†å‰²` `å¤šè§†å›¾èžåˆ` `ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰¹å¾`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨é¢„å¤„ç†ä¸­ç¼ºä¹ä¸Šä¸‹æ–‡çº¿ç´¢ï¼Œå¤šè§†å›¾ç‰¹å¾èžåˆä¸ä¸€è‡´ä¸”ç»†èŠ‚ç¼ºå¤±ã€‚
2. é‡‡ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰¹å¾æå–å¢žå¼ºæŽ©ç è¯­ä¹‰ï¼Œæ³¨æ„åŠ›é©±åŠ¨ç‰¹å¾èšåˆä¼˜åŒ–å¤šè§†å›¾èžåˆã€‚
3. åœ¨åŸºå‡†æ•°æ®é›†ä¸Šå®žçŽ°æœ€å…ˆè¿›ç»“æžœï¼Œæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰åŸºçº¿ï¼ŒéªŒè¯æ–¹æ³•çš„é²æ£’æ€§å’Œé€šç”¨æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Understanding 3D scenes is pivotal for autonomous driving, robotics, and
> augmented reality. Recent semantic Gaussian Splatting approaches leverage
> large-scale 2D vision models to project 2D semantic features onto 3D scenes.
> However, they suffer from two major limitations: (1) insufficient contextual
> cues for individual masks during preprocessing and (2) inconsistencies and
> missing details when fusing multi-view features from these 2D models. In this
> paper, we introduce \textbf{OpenInsGaussian}, an \textbf{Open}-vocabulary
> \textbf{Ins}tance \textbf{Gaussian} segmentation framework with Context-aware
> Cross-view Fusion. Our method consists of two modules: Context-Aware Feature
> Extraction, which augments each mask with rich semantic context, and
> Attention-Driven Feature Aggregation, which selectively fuses multi-view
> features to mitigate alignment errors and incompleteness. Through extensive
> experiments on benchmark datasets, OpenInsGaussian achieves state-of-the-art
> results in open-vocabulary 3D Gaussian segmentation, outperforming existing
> baselines by a large margin. These findings underscore the robustness and
> generality of our proposed approach, marking a significant step forward in 3D
> scene understanding and its practical deployment across diverse real-world
> scenarios.

