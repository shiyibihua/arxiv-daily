---
layout: default
title: Ensembling Pruned Attention Heads For Uncertainty-Aware Efficient Transformers
---

# Ensembling Pruned Attention Heads For Uncertainty-Aware Efficient Transformers

**arXiv**: [2510.18358v1](https://arxiv.org/abs/2510.18358) | [PDF](https://arxiv.org/pdf/2510.18358.pdf)

**ä½œè€…**: Firas Gabetni, Giuseppe Curci, Andrea Pilzer, Subhankar Roy, Elisa Ricci, Gianni Franchi

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHydra Ensemblesä»¥é«˜æ•ˆå®ç°ä¸ç¡®å®šæ€§é‡åŒ–ï¼Œé€‚ç”¨äºå®‰å…¨å…³é”®åœºæ™¯ã€‚**

**å…³é”®è¯**: `ä¸ç¡®å®šæ€§é‡åŒ–` `æ³¨æ„åŠ›å¤´å‰ªæ` `é«˜æ•ˆé›†æˆ` `Transformeræ¨¡å‹` `é›¶æ ·æœ¬åˆ†ç±»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ·±åº¦é›†æˆæ–¹æ³•è®¡ç®—å’Œå†…å­˜æˆæœ¬é«˜ï¼Œéš¾ä»¥æ‰©å±•åˆ°å¤§å‹æ¨¡å‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å‰ªææ³¨æ„åŠ›å¤´åˆ›å»ºå¤šæ ·æˆå‘˜ï¼Œå¹¶ä½¿ç”¨åˆ†ç»„å…¨è¿æ¥å±‚åˆå¹¶ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šåœ¨å›¾åƒå’Œæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œæ€§èƒ½åŒ¹é…æˆ–è¶…è¶ŠDeep Ensemblesï¼Œæ¨ç†é€Ÿåº¦æ¥è¿‘å•ç½‘ç»œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Uncertainty quantification (UQ) is essential for deploying deep neural
> networks in safety-critical settings. Although methods like Deep Ensembles
> achieve strong UQ performance, their high computational and memory costs hinder
> scalability to large models. We introduce Hydra Ensembles, an efficient
> transformer-based ensemble that prunes attention heads to create diverse
> members and merges them via a new multi-head attention with grouped
> fully-connected layers. This yields a compact model with inference speed close
> to a single network, matching or surpassing Deep Ensembles in UQ performance
> without retraining from scratch. We also provide an in-depth analysis of
> pruning, showing that naive approaches can harm calibration, whereas Hydra
> Ensembles preserves robust uncertainty. Experiments on image and text
> classification tasks, with various architectures, show consistent gains over
> Deep Ensembles. Remarkably, in zero-shot classification on ImageNet-1k, our
> approach surpasses state of the art methods, even without requiring additional
> training.

