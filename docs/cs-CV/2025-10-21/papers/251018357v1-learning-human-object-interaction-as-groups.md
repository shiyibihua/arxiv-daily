---
layout: default
title: Learning Human-Object Interaction as Groups
---

# Learning Human-Object Interaction as Groups

**arXiv**: [2510.18357v1](https://arxiv.org/abs/2510.18357) | [PDF](https://arxiv.org/pdf/2510.18357.pdf)

**ä½œè€…**: Jiajun Hong, Jianan Wei, Wenguan Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGroupHOIæ¡†æž¶ï¼Œé€šè¿‡åˆ†ç»„å»ºæ¨¡è§£å†³äººç±»-ç‰©ä½“äº¤äº’æ£€æµ‹ä¸­çš„é›†ä½“è¡Œä¸ºé—®é¢˜**

**å…³é”®è¯**: `äººç±»-ç‰©ä½“äº¤äº’æ£€æµ‹` `åˆ†ç»„å»ºæ¨¡` `å‡ ä½•é‚»è¿‘` `è¯­ä¹‰ç›¸ä¼¼æ€§` `è‡ªæ³¨æ„åŠ›æœºåˆ¶` `éžè¯­è¨€äº¤äº’æ£€æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•å…³æ³¨æˆå¯¹å…³ç³»ï¼Œå¿½ç•¥çŽ°å®žåœºæ™¯ä¸­å¤šäººç±»å’Œç‰©ä½“å‚ä¸Žçš„é›†ä½“äº¤äº’è¡Œä¸ºã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå‡ ä½•é‚»è¿‘å’Œè¯­ä¹‰ç›¸ä¼¼æ€§åˆ†ç»„ï¼Œä½¿ç”¨å¯å­¦ä¹ é‚»è¿‘ä¼°è®¡å™¨å’Œè‡ªæ³¨æ„åŠ›ä¼ æ’­ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨HICO-DETå’ŒV-COCOåŸºå‡†ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨NVI-DETä»»åŠ¡ä¸­è¡¨çŽ°é¢†å…ˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Human-Object Interaction Detection (HOI-DET) aims to localize human-object
> pairs and identify their interactive relationships. To aggregate contextual
> cues, existing methods typically propagate information across all detected
> entities via self-attention mechanisms, or establish message passing between
> humans and objects with bipartite graphs. However, they primarily focus on
> pairwise relationships, overlooking that interactions in real-world scenarios
> often emerge from collective behaviors (multiple humans and objects engaging in
> joint activities). In light of this, we revisit relation modeling from a group
> view and propose GroupHOI, a framework that propagates contextual information
> in terms of geometric proximity and semantic similarity. To exploit the
> geometric proximity, humans and objects are grouped into distinct clusters
> using a learnable proximity estimator based on spatial features derived from
> bounding boxes. In each group, a soft correspondence is computed via
> self-attention to aggregate and dispatch contextual cues. To incorporate the
> semantic similarity, we enhance the vanilla transformer-based interaction
> decoder with local contextual cues from HO-pair features. Extensive experiments
> on HICO-DET and V-COCO benchmarks demonstrate the superiority of GroupHOI over
> the state-of-the-art methods. It also exhibits leading performance on the more
> challenging Nonverbal Interaction Detection (NVI-DET) task, which involves
> varied forms of higher-order interactions within groups.

