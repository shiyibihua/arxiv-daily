---
layout: default
title: iFlyBot-VLA Technical Report
---

# iFlyBot-VLA Technical Report

**arXiv**: [2511.01914v1](https://arxiv.org/abs/2511.01914) | [PDF](https://arxiv.org/pdf/2511.01914.pdf)

**ä½œè€…**: Yuan Zhang, Chenyu Xue, Wenjie Xu, Chao Ji, Jiajia wu, Jia Pan

**åˆ†ç±»**: cs.CV, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-01

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºiFlyBot-VLAï¼Œä¸€ç§åŸºäºŽåŒå±‚åŠ¨ä½œè¡¨ç¤ºçš„è§†è§‰-è¯­è¨€-åŠ¨ä½œå¤§æ¨¡åž‹ï¼Œæå‡æœºå™¨äººæ“ä½œèƒ½åŠ›ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `æœºå™¨äººæ“ä½œ` `åŒå±‚åŠ¨ä½œè¡¨ç¤º` `æ½œåœ¨åŠ¨ä½œæ¨¡åž‹` `è·¨å…·èº«å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æœºå™¨äººæ“ä½œæ¨¡åž‹åœ¨ç†è§£é«˜çº§æ„å›¾å’Œç”Ÿæˆç²¾ç»†åŠ¨ä½œæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥åº”å¯¹å¤æ‚ä»»åŠ¡ã€‚
2. iFlyBot-VLAé€šè¿‡åŒå±‚åŠ¨ä½œè¡¨ç¤ºï¼ŒåŒæ—¶å­¦ä¹ éšå¼é«˜çº§æ„å›¾å’Œæ˜¾å¼ä½Žçº§åŠ¨åŠ›å­¦ï¼Œå¼¥åˆäº†è§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œä¹‹é—´çš„é¸¿æ²Ÿã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒiFlyBot-VLAåœ¨LIBERO FrankaåŸºå‡†æµ‹è¯•å’ŒçœŸå®žä¸–ç•Œæ“ä½œä»»åŠ¡ä¸­å‡è¡¨çŽ°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»iFlyBot-VLAï¼Œä¸€ä¸ªåŸºäºŽæ–°æ¡†æž¶è®­ç»ƒçš„å¤§è§„æ¨¡è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹ã€‚ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªåœ¨å¤§åž‹äººç±»å’Œæœºå™¨äººæ“ä½œè§†é¢‘ä¸Šå……åˆ†è®­ç»ƒçš„æ½œåœ¨åŠ¨ä½œæ¨¡åž‹ï¼›ï¼ˆ2ï¼‰ä¸€ä¸ªåŒå±‚åŠ¨ä½œè¡¨ç¤ºæ¡†æž¶ï¼Œåœ¨è®­ç»ƒæœŸé—´è”åˆç›‘ç£è§†è§‰-è¯­è¨€æ¨¡åž‹ï¼ˆVLMï¼‰å’ŒåŠ¨ä½œä¸“å®¶ï¼›ï¼ˆ3ï¼‰ä¸€ç§æ··åˆè®­ç»ƒç­–ç•¥ï¼Œå°†æœºå™¨äººè½¨è¿¹æ•°æ®ä¸Žé€šç”¨é—®ç­”å’Œç©ºé—´é—®ç­”æ•°æ®é›†ç›¸ç»“åˆï¼Œæœ‰æ•ˆå¢žå¼ºäº†VLMéª¨å¹²ç½‘ç»œçš„3Dæ„ŸçŸ¥å’ŒæŽ¨ç†èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼ŒVLMè¢«è®­ç»ƒæ¥é¢„æµ‹ä¸¤ç§äº’è¡¥å½¢å¼çš„åŠ¨ä½œï¼šæ½œåœ¨åŠ¨ä½œï¼Œæ¥æºäºŽæˆ‘ä»¬é¢„è®­ç»ƒçš„è·¨å…·èº«æ“ä½œæ•°æ®çš„æ½œåœ¨åŠ¨ä½œæ¨¡åž‹ï¼Œæ•æ‰éšå¼çš„é«˜çº§æ„å›¾ï¼›ä»¥åŠç»“æž„åŒ–çš„ç¦»æ•£åŠ¨ä½œtokensï¼Œé€šè¿‡è¿žç»­æŽ§åˆ¶ä¿¡å·çš„é¢‘åŸŸå˜æ¢èŽ·å¾—ï¼Œç¼–ç æ˜¾å¼çš„ä½Žçº§åŠ¨åŠ›å­¦ã€‚è¿™ç§åŒé‡ç›‘ç£å¯¹é½äº†è¯­è¨€ã€è§†è§‰å’ŒåŠ¨ä½œçš„è¡¨ç¤ºç©ºé—´ï¼Œä½¿VLMèƒ½å¤Ÿç›´æŽ¥è´¡çŒ®äºŽåŠ¨ä½œç”Ÿæˆã€‚åœ¨LIBERO FrankaåŸºå‡†æµ‹è¯•ä¸Šçš„å®žéªŒç»“æžœè¯æ˜Žäº†æˆ‘ä»¬æ¡†æž¶çš„ä¼˜è¶Šæ€§ï¼Œè€ŒçœŸå®žä¸–ç•Œçš„è¯„ä¼°è¿›ä¸€æ­¥è¡¨æ˜Žï¼ŒiFlyBot-VLAåœ¨å„ç§å…·æœ‰æŒ‘æˆ˜æ€§çš„æ“ä½œä»»åŠ¡ä¸­å–å¾—äº†å…·æœ‰ç«žäº‰åŠ›çš„æˆåŠŸçŽ‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¡åˆ’å¼€æºéƒ¨åˆ†è‡ªå»ºæ•°æ®é›†ï¼Œä»¥æ”¯æŒç¤¾åŒºæœªæ¥çš„ç ”ç©¶ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰æœºå™¨äººæ“ä½œæ¨¡åž‹é€šå¸¸éš¾ä»¥åŒæ—¶ç†è§£é«˜çº§æ„å›¾å’Œç”Ÿæˆç²¾ç»†çš„åŠ¨ä½œæŽ§åˆ¶ä¿¡å·ã€‚å®ƒä»¬è¦ä¹ˆä¾èµ–äºŽå¤§é‡çš„ä¸“å®¶æ•°æ®ï¼Œè¦ä¹ˆéš¾ä»¥æ³›åŒ–åˆ°æ–°çš„ä»»åŠ¡å’ŒçŽ¯å¢ƒã€‚ç—›ç‚¹åœ¨äºŽç¼ºä¹ä¸€ç§èƒ½å¤Ÿæœ‰æ•ˆè¿žæŽ¥è§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œçš„ç»Ÿä¸€è¡¨ç¤ºæ¡†æž¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šiFlyBot-VLAçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åŒå±‚åŠ¨ä½œè¡¨ç¤ºï¼Œå°†åŠ¨ä½œåˆ†è§£ä¸ºéšå¼çš„é«˜çº§æ„å›¾ï¼ˆlatent actionsï¼‰å’Œæ˜¾å¼çš„ä½Žçº§åŠ¨åŠ›å­¦ï¼ˆstructured discrete action tokensï¼‰ã€‚é€šè¿‡è”åˆç›‘ç£è§†è§‰-è¯­è¨€æ¨¡åž‹ï¼ˆVLMï¼‰å’ŒåŠ¨ä½œä¸“å®¶ï¼Œå¯¹é½ä¸åŒæ¨¡æ€çš„è¡¨ç¤ºç©ºé—´ï¼Œä»Žè€Œä½¿VLMèƒ½å¤Ÿç›´æŽ¥å‚ä¸ŽåŠ¨ä½œç”Ÿæˆã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šiFlyBot-VLAçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ½œåœ¨åŠ¨ä½œæ¨¡åž‹ï¼šé¢„è®­ç»ƒåœ¨å¤§é‡äººç±»å’Œæœºå™¨äººæ“ä½œè§†é¢‘ä¸Šï¼Œç”¨äºŽæå–é«˜çº§æ„å›¾ã€‚2) è§†è§‰-è¯­è¨€æ¨¡åž‹ï¼ˆVLMï¼‰ï¼šä½œä¸ºæ ¸å¿ƒæŽ§åˆ¶å™¨ï¼ŒæŽ¥æ”¶è§†è§‰å’Œè¯­è¨€è¾“å…¥ï¼Œå¹¶é¢„æµ‹åŒå±‚åŠ¨ä½œè¡¨ç¤ºã€‚3) åŠ¨ä½œä¸“å®¶ï¼šè´Ÿè´£å°†ç¦»æ•£åŠ¨ä½œtokensè½¬æ¢ä¸ºè¿žç»­æŽ§åˆ¶ä¿¡å·ï¼Œé©±åŠ¨æœºå™¨äººæ‰§è¡ŒåŠ¨ä½œã€‚4) æ··åˆè®­ç»ƒç­–ç•¥ï¼šç»“åˆæœºå™¨äººè½¨è¿¹æ•°æ®ã€é€šç”¨é—®ç­”å’Œç©ºé—´é—®ç­”æ•°æ®é›†ï¼Œå¢žå¼ºVLMçš„3Dæ„ŸçŸ¥å’ŒæŽ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šiFlyBot-VLAçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶åŒå±‚åŠ¨ä½œè¡¨ç¤ºæ¡†æž¶ã€‚ä¸Žä¼ ç»Ÿçš„å•å±‚åŠ¨ä½œè¡¨ç¤ºç›¸æ¯”ï¼Œè¯¥æ¡†æž¶èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰åŠ¨ä½œçš„å±‚æ¬¡ç»“æž„ï¼Œä»Žè€Œæé«˜æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡é¢‘åŸŸå˜æ¢å°†è¿žç»­æŽ§åˆ¶ä¿¡å·è½¬æ¢ä¸ºç¦»æ•£åŠ¨ä½œtokensï¼Œç®€åŒ–äº†åŠ¨ä½œç”Ÿæˆè¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šæ½œåœ¨åŠ¨ä½œæ¨¡åž‹é‡‡ç”¨å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ç»“æž„ï¼Œå­¦ä¹ åŠ¨ä½œçš„æ½œåœ¨ç©ºé—´è¡¨ç¤ºã€‚VLMé‡‡ç”¨Transformeræž¶æž„ï¼Œå¹¶ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°å¯¹é½ä¸åŒæ¨¡æ€çš„è¡¨ç¤ºã€‚ç¦»æ•£åŠ¨ä½œtokensé€šè¿‡å¯¹è¿žç»­æŽ§åˆ¶ä¿¡å·è¿›è¡Œå‚…é‡Œå¶å˜æ¢å¾—åˆ°ï¼Œå¹¶ä½¿ç”¨k-meansèšç±»è¿›è¡Œé‡åŒ–ã€‚æ··åˆè®­ç»ƒç­–ç•¥ä¸­ï¼Œä¸åŒæ•°æ®é›†çš„æƒé‡æ ¹æ®ç»éªŒè¿›è¡Œè°ƒæ•´ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

iFlyBot-VLAåœ¨LIBERO FrankaåŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸è¾ƒäºŽçŽ°æœ‰æ–¹æ³•ï¼ŒæˆåŠŸçŽ‡æé«˜äº†XX%ã€‚åœ¨çœŸå®žä¸–ç•Œçš„æ“ä½œä»»åŠ¡ä¸­ï¼ŒiFlyBot-VLAä¹Ÿè¡¨çŽ°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸­å–å¾—äº†å…·æœ‰ç«žäº‰åŠ›çš„æˆåŠŸçŽ‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

iFlyBot-VLAå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬å®¶åº­æœåŠ¡æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—è¾…åŠ©ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ä½¿æœºå™¨äººæ›´å¥½åœ°ç†è§£äººç±»æŒ‡ä»¤ï¼Œæ‰§è¡Œå¤æ‚çš„ä»»åŠ¡ï¼Œå¹¶é€‚åº”ä¸åŒçš„çŽ¯å¢ƒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æŽ¨åŠ¨æœºå™¨äººæ™ºèƒ½çš„è¿›ä¸€æ­¥å‘å±•ï¼Œå®žçŽ°äººæœºåä½œçš„æ›´é«˜çº§å½¢å¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce iFlyBot-VLA, a large-scale Vision-Language-Action (VLA) model trained under a novel framework. The main contributions are listed as follows: (1) a latent action model thoroughly trained on large-scale human and robotic manipulation videos; (2) a dual-level action representation framework that jointly supervises both the Vision-Language Model (VLM) and the action expert during training; (3) a mixed training strategy that combines robot trajectory data with general QA and spatial QA datasets, effectively enhancing the 3D perceptual and reasoning capabilities of the VLM backbone. Specifically, the VLM is trained to predict two complementary forms of actions: latent actions, derived from our latent action model pretrained on cross-embodiment manipulation data, which capture implicit high-level intentions; and structured discrete action tokens, obtained through frequency-domain transformations of continuous control signals, which encode explicit low-level dynamics. This dual supervision aligns the representation spaces of language, vision, and action, enabling the VLM to directly contribute to action generation. Experimental results on the LIBERO Franka benchmark demonstrate the superiority of our frame-work, while real-world evaluations further show that iFlyBot-VLA achieves competitive success rates across diverse and challenging manipulation tasks. Furthermore, we plan to open-source a portion of our self-constructed dataset to support future research in the community

