---
layout: default
title: iFlyBot-VLA Technical Report
---

# iFlyBot-VLA Technical Report

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.01914" target="_blank" class="toolbar-btn">arXiv: 2511.01914v1</a>
    <a href="https://arxiv.org/pdf/2511.01914.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.01914v1" 
            onclick="toggleFavorite(this, '2511.01914v1', 'iFlyBot-VLA Technical Report')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yuan Zhang, Chenyu Xue, Wenjie Xu, Chao Ji, Jiajia wu, Jia Pan

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-01

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫iFlyBot-VLAÔºå‰∏ÄÁßçÂü∫‰∫éÂèåÂ±ÇÂä®‰ΩúË°®Á§∫ÁöÑËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÂ§ßÊ®°ÂûãÔºåÊèêÂçáÊú∫Âô®‰∫∫Êìç‰ΩúËÉΩÂäõ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∏ÉÔºöÂä®‰ΩúÈáçÂÆöÂêë (Motion Retargeting)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã` `Êú∫Âô®‰∫∫Êìç‰Ωú` `ÂèåÂ±ÇÂä®‰ΩúË°®Á§∫` `ÊΩúÂú®Âä®‰ΩúÊ®°Âûã` `Ë∑®ÂÖ∑Ë∫´Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊú∫Âô®‰∫∫Êìç‰ΩúÊ®°ÂûãÂú®ÁêÜËß£È´òÁ∫ßÊÑèÂõæÂíåÁîüÊàêÁ≤æÁªÜÂä®‰ΩúÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÈöæ‰ª•Â∫îÂØπÂ§çÊùÇ‰ªªÂä°„ÄÇ
2. iFlyBot-VLAÈÄöËøáÂèåÂ±ÇÂä®‰ΩúË°®Á§∫ÔºåÂêåÊó∂Â≠¶‰π†ÈöêÂºèÈ´òÁ∫ßÊÑèÂõæÂíåÊòæÂºè‰ΩéÁ∫ßÂä®ÂäõÂ≠¶ÔºåÂº•Âêà‰∫ÜËßÜËßâ„ÄÅËØ≠Ë®ÄÂíåÂä®‰Ωú‰πãÈó¥ÁöÑÈ∏øÊ≤ü„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåiFlyBot-VLAÂú®LIBERO FrankaÂü∫ÂáÜÊµãËØïÂíåÁúüÂÆû‰∏ñÁïåÊìç‰Ωú‰ªªÂä°‰∏≠ÂùáË°®Áé∞Âá∫Ëâ≤ÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨Êñá‰ªãÁªçiFlyBot-VLAÔºå‰∏Ä‰∏™Âü∫‰∫éÊñ∞Ê°ÜÊû∂ËÆ≠ÁªÉÁöÑÂ§ßËßÑÊ®°ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÔºàVLAÔºâÊ®°Âûã„ÄÇ‰∏ªË¶ÅË¥°ÁåÆÂåÖÊã¨ÔºöÔºà1Ôºâ‰∏Ä‰∏™Âú®Â§ßÂûã‰∫∫Á±ªÂíåÊú∫Âô®‰∫∫Êìç‰ΩúËßÜÈ¢ë‰∏äÂÖÖÂàÜËÆ≠ÁªÉÁöÑÊΩúÂú®Âä®‰ΩúÊ®°ÂûãÔºõÔºà2Ôºâ‰∏Ä‰∏™ÂèåÂ±ÇÂä®‰ΩúË°®Á§∫Ê°ÜÊû∂ÔºåÂú®ËÆ≠ÁªÉÊúüÈó¥ËÅîÂêàÁõëÁù£ËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâÂíåÂä®‰Ωú‰∏ìÂÆ∂ÔºõÔºà3Ôºâ‰∏ÄÁßçÊ∑∑ÂêàËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂ∞ÜÊú∫Âô®‰∫∫ËΩ®ËøπÊï∞ÊçÆ‰∏éÈÄöÁî®ÈóÆÁ≠îÂíåÁ©∫Èó¥ÈóÆÁ≠îÊï∞ÊçÆÈõÜÁõ∏ÁªìÂêàÔºåÊúâÊïàÂ¢ûÂº∫‰∫ÜVLMÈ™®Âπ≤ÁΩëÁªúÁöÑ3DÊÑüÁü•ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåVLMË¢´ËÆ≠ÁªÉÊù•È¢ÑÊµã‰∏§Áßç‰∫íË°•ÂΩ¢ÂºèÁöÑÂä®‰ΩúÔºöÊΩúÂú®Âä®‰ΩúÔºåÊù•Ê∫ê‰∫éÊàë‰ª¨È¢ÑËÆ≠ÁªÉÁöÑË∑®ÂÖ∑Ë∫´Êìç‰ΩúÊï∞ÊçÆÁöÑÊΩúÂú®Âä®‰ΩúÊ®°ÂûãÔºåÊçïÊçâÈöêÂºèÁöÑÈ´òÁ∫ßÊÑèÂõæÔºõ‰ª•ÂèäÁªìÊûÑÂåñÁöÑÁ¶ªÊï£Âä®‰ΩútokensÔºåÈÄöËøáËøûÁª≠ÊéßÂà∂‰ø°Âè∑ÁöÑÈ¢ëÂüüÂèòÊç¢Ëé∑ÂæóÔºåÁºñÁ†ÅÊòæÂºèÁöÑ‰ΩéÁ∫ßÂä®ÂäõÂ≠¶„ÄÇËøôÁßçÂèåÈáçÁõëÁù£ÂØπÈΩê‰∫ÜËØ≠Ë®Ä„ÄÅËßÜËßâÂíåÂä®‰ΩúÁöÑË°®Á§∫Á©∫Èó¥Ôºå‰ΩøVLMËÉΩÂ§üÁõ¥Êé•Ë¥°ÁåÆ‰∫éÂä®‰ΩúÁîüÊàê„ÄÇÂú®LIBERO FrankaÂü∫ÂáÜÊµãËØï‰∏äÁöÑÂÆûÈ™åÁªìÊûúËØÅÊòé‰∫ÜÊàë‰ª¨Ê°ÜÊû∂ÁöÑ‰ºòË∂äÊÄßÔºåËÄåÁúüÂÆû‰∏ñÁïåÁöÑËØÑ‰º∞Ëøõ‰∏ÄÊ≠•Ë°®ÊòéÔºåiFlyBot-VLAÂú®ÂêÑÁßçÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊìç‰Ωú‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÊàêÂäüÁéá„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËÆ°ÂàíÂºÄÊ∫êÈÉ®ÂàÜËá™Âª∫Êï∞ÊçÆÈõÜÔºå‰ª•ÊîØÊåÅÁ§æÂå∫Êú™Êù•ÁöÑÁ†îÁ©∂„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊú∫Âô®‰∫∫Êìç‰ΩúÊ®°ÂûãÈÄöÂ∏∏Èöæ‰ª•ÂêåÊó∂ÁêÜËß£È´òÁ∫ßÊÑèÂõæÂíåÁîüÊàêÁ≤æÁªÜÁöÑÂä®‰ΩúÊéßÂà∂‰ø°Âè∑„ÄÇÂÆÉ‰ª¨Ë¶Å‰πà‰æùËµñ‰∫éÂ§ßÈáèÁöÑ‰∏ìÂÆ∂Êï∞ÊçÆÔºåË¶Å‰πàÈöæ‰ª•Ê≥õÂåñÂà∞Êñ∞ÁöÑ‰ªªÂä°ÂíåÁéØÂ¢É„ÄÇÁóõÁÇπÂú®‰∫éÁº∫‰πè‰∏ÄÁßçËÉΩÂ§üÊúâÊïàËøûÊé•ËßÜËßâ„ÄÅËØ≠Ë®ÄÂíåÂä®‰ΩúÁöÑÁªü‰∏ÄË°®Á§∫Ê°ÜÊû∂„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöiFlyBot-VLAÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ÂèåÂ±ÇÂä®‰ΩúË°®Á§∫ÔºåÂ∞ÜÂä®‰ΩúÂàÜËß£‰∏∫ÈöêÂºèÁöÑÈ´òÁ∫ßÊÑèÂõæÔºàlatent actionsÔºâÂíåÊòæÂºèÁöÑ‰ΩéÁ∫ßÂä®ÂäõÂ≠¶Ôºàstructured discrete action tokensÔºâ„ÄÇÈÄöËøáËÅîÂêàÁõëÁù£ËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâÂíåÂä®‰Ωú‰∏ìÂÆ∂ÔºåÂØπÈΩê‰∏çÂêåÊ®°ÊÄÅÁöÑË°®Á§∫Á©∫Èó¥Ôºå‰ªéËÄå‰ΩøVLMËÉΩÂ§üÁõ¥Êé•ÂèÇ‰∏éÂä®‰ΩúÁîüÊàê„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöiFlyBot-VLAÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÊΩúÂú®Âä®‰ΩúÊ®°ÂûãÔºöÈ¢ÑËÆ≠ÁªÉÂú®Â§ßÈáè‰∫∫Á±ªÂíåÊú∫Âô®‰∫∫Êìç‰ΩúËßÜÈ¢ë‰∏äÔºåÁî®‰∫éÊèêÂèñÈ´òÁ∫ßÊÑèÂõæ„ÄÇ2) ËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâÔºö‰Ωú‰∏∫Ê†∏ÂøÉÊéßÂà∂Âô®ÔºåÊé•Êî∂ËßÜËßâÂíåËØ≠Ë®ÄËæìÂÖ•ÔºåÂπ∂È¢ÑÊµãÂèåÂ±ÇÂä®‰ΩúË°®Á§∫„ÄÇ3) Âä®‰Ωú‰∏ìÂÆ∂ÔºöË¥üË¥£Â∞ÜÁ¶ªÊï£Âä®‰ΩútokensËΩ¨Êç¢‰∏∫ËøûÁª≠ÊéßÂà∂‰ø°Âè∑ÔºåÈ©±Âä®Êú∫Âô®‰∫∫ÊâßË°åÂä®‰Ωú„ÄÇ4) Ê∑∑ÂêàËÆ≠ÁªÉÁ≠ñÁï•ÔºöÁªìÂêàÊú∫Âô®‰∫∫ËΩ®ËøπÊï∞ÊçÆ„ÄÅÈÄöÁî®ÈóÆÁ≠îÂíåÁ©∫Èó¥ÈóÆÁ≠îÊï∞ÊçÆÈõÜÔºåÂ¢ûÂº∫VLMÁöÑ3DÊÑüÁü•ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöiFlyBot-VLAÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÂèåÂ±ÇÂä®‰ΩúË°®Á§∫Ê°ÜÊû∂„ÄÇ‰∏é‰º†ÁªüÁöÑÂçïÂ±ÇÂä®‰ΩúË°®Á§∫Áõ∏ÊØîÔºåËØ•Ê°ÜÊû∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÊçïÊçâÂä®‰ΩúÁöÑÂ±ÇÊ¨°ÁªìÊûÑÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÂíåÈ≤ÅÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºåÈÄöËøáÈ¢ëÂüüÂèòÊç¢Â∞ÜËøûÁª≠ÊéßÂà∂‰ø°Âè∑ËΩ¨Êç¢‰∏∫Á¶ªÊï£Âä®‰ΩútokensÔºåÁÆÄÂåñ‰∫ÜÂä®‰ΩúÁîüÊàêËøáÁ®ã„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊΩúÂú®Âä®‰ΩúÊ®°ÂûãÈááÁî®ÂèòÂàÜËá™ÁºñÁ†ÅÂô®ÔºàVAEÔºâÁªìÊûÑÔºåÂ≠¶‰π†Âä®‰ΩúÁöÑÊΩúÂú®Á©∫Èó¥Ë°®Á§∫„ÄÇVLMÈááÁî®TransformerÊû∂ÊûÑÔºåÂπ∂‰ΩøÁî®ÂØπÊØîÂ≠¶‰π†ÊçüÂ§±ÂáΩÊï∞ÂØπÈΩê‰∏çÂêåÊ®°ÊÄÅÁöÑË°®Á§∫„ÄÇÁ¶ªÊï£Âä®‰ΩútokensÈÄöËøáÂØπËøûÁª≠ÊéßÂà∂‰ø°Âè∑ËøõË°åÂÇÖÈáåÂè∂ÂèòÊç¢ÂæóÂà∞ÔºåÂπ∂‰ΩøÁî®k-meansËÅöÁ±ªËøõË°åÈáèÂåñ„ÄÇÊ∑∑ÂêàËÆ≠ÁªÉÁ≠ñÁï•‰∏≠Ôºå‰∏çÂêåÊï∞ÊçÆÈõÜÁöÑÊùÉÈáçÊ†πÊçÆÁªèÈ™åËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

iFlyBot-VLAÂú®LIBERO FrankaÂü∫ÂáÜÊµãËØï‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÁõ∏ËæÉ‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÊàêÂäüÁéáÊèêÈ´ò‰∫ÜXX%„ÄÇÂú®ÁúüÂÆû‰∏ñÁïåÁöÑÊìç‰Ωú‰ªªÂä°‰∏≠ÔºåiFlyBot-VLA‰πüË°®Áé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂú®Â§ö‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑ‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÂÖ∑ÊúâÁ´û‰∫âÂäõÁöÑÊàêÂäüÁéá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

iFlyBot-VLAÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨ÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öËá™Âä®Âåñ„ÄÅÂåªÁñóËæÖÂä©Á≠âÈ¢ÜÂüü„ÄÇÂÆÉÂèØ‰ª•‰ΩøÊú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÁêÜËß£‰∫∫Á±ªÊåá‰ª§ÔºåÊâßË°åÂ§çÊùÇÁöÑ‰ªªÂä°ÔºåÂπ∂ÈÄÇÂ∫î‰∏çÂêåÁöÑÁéØÂ¢É„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÊé®Âä®Êú∫Âô®‰∫∫Êô∫ËÉΩÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ïÔºåÂÆûÁé∞‰∫∫Êú∫Âçè‰ΩúÁöÑÊõ¥È´òÁ∫ßÂΩ¢Âºè„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We introduce iFlyBot-VLA, a large-scale Vision-Language-Action (VLA) model trained under a novel framework. The main contributions are listed as follows: (1) a latent action model thoroughly trained on large-scale human and robotic manipulation videos; (2) a dual-level action representation framework that jointly supervises both the Vision-Language Model (VLM) and the action expert during training; (3) a mixed training strategy that combines robot trajectory data with general QA and spatial QA datasets, effectively enhancing the 3D perceptual and reasoning capabilities of the VLM backbone. Specifically, the VLM is trained to predict two complementary forms of actions: latent actions, derived from our latent action model pretrained on cross-embodiment manipulation data, which capture implicit high-level intentions; and structured discrete action tokens, obtained through frequency-domain transformations of continuous control signals, which encode explicit low-level dynamics. This dual supervision aligns the representation spaces of language, vision, and action, enabling the VLM to directly contribute to action generation. Experimental results on the LIBERO Franka benchmark demonstrate the superiority of our frame-work, while real-world evaluations further show that iFlyBot-VLA achieves competitive success rates across diverse and challenging manipulation tasks. Furthermore, we plan to open-source a portion of our self-constructed dataset to support future research in the community

