---
layout: default
title: Kvasir-VQA-x1: A Multimodal Dataset for Medical Reasoning and Robust MedVQA in Gastrointestinal Endoscopy
---

# Kvasir-VQA-x1: A Multimodal Dataset for Medical Reasoning and Robust MedVQA in Gastrointestinal Endoscopy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09958" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09958v1</a>
  <a href="https://arxiv.org/pdf/2506.09958.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09958v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09958v1', 'Kvasir-VQA-x1: A Multimodal Dataset for Medical Reasoning and Robust MedVQA in Gastrointestinal Endoscopy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sushant Gautam, Michael A. Riegler, PÃ¥l Halvorsen

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Simula/Kvasir-VQA-x1) | [HUGGINGFACE](https://huggingface.co/datasets/SimulaMet)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºKvasir-VQA-x1ä»¥è§£å†³åŒ»ç–—è§†è§‰é—®ç­”æ•°æ®é›†ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒ»ç–—è§†è§‰é—®ç­”` `å¤šæ¨¡æ€æ•°æ®é›†` `ä¸´åºŠæ¨ç†` `è§†è§‰å¢å¼º` `å¤§è§„æ¨¡æ•°æ®é›†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„MedVQAæ•°æ®é›†ç¼ºä¹ä¸´åºŠå¤æ‚æ€§å’Œè§†è§‰å¤šæ ·æ€§ï¼Œé™åˆ¶äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚
2. Kvasir-VQA-x1é€šè¿‡å¼•å…¥159,549ä¸ªæ–°é—®é¢˜-ç­”æ¡ˆå¯¹ï¼Œç³»ç»ŸåŒ–ç”Ÿæˆé—®é¢˜ä»¥æµ‹è¯•ä¸´åºŠæ¨ç†èƒ½åŠ›ã€‚
3. è¯¥æ•°æ®é›†æ”¯æŒæ ‡å‡†VQAæ€§èƒ½è¯„ä¼°å’Œæ¨¡å‹å¯¹è§†è§‰æ‰°åŠ¨çš„é²æ£’æ€§æµ‹è¯•ï¼Œæä¾›æ›´å…·æŒ‘æˆ˜æ€§çš„åŸºå‡†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŒ»ç–—è§†è§‰é—®ç­”ï¼ˆMedVQAï¼‰æ˜¯ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿçš„é‡è¦é¢†åŸŸï¼Œä½†ç°æœ‰æ•°æ®é›†å¾€å¾€ç¼ºä¹ä¸´åºŠå¤æ‚æ€§å’Œè§†è§‰å¤šæ ·æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Kvasir-VQA-x1ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹èƒƒè‚ å†…çª¥é•œçš„æ–°å‹å¤§è§„æ¨¡æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†æ–°å¢159,549ä¸ªé—®é¢˜-ç­”æ¡ˆå¯¹ï¼Œæ—¨åœ¨æµ‹è¯•æ›´æ·±å±‚æ¬¡çš„ä¸´åºŠæ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬é‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç³»ç»ŸåŒ–ç”Ÿæˆè¿™äº›é—®é¢˜ï¼Œå¹¶é€šè¿‡è§†è§‰å¢å¼ºæŠ€æœ¯æ¨¡æ‹Ÿå¸¸è§æˆåƒä¼ªå½±ï¼Œä»¥ç¡®ä¿æ•°æ®é›†èƒ½å¤Ÿä¸ºæ¨¡å‹åœ¨çœŸå®ä¸´åºŠåœºæ™¯ä¸­çš„åº”ç”¨åšå¥½å‡†å¤‡ã€‚Kvasir-VQA-x1æ—¨åœ¨åŠ é€Ÿæ›´å¯é å’Œæœ‰æ•ˆçš„å¤šæ¨¡æ€AIç³»ç»Ÿçš„å‘å±•ï¼Œå¹¶éµå¾ªFAIRæ•°æ®åŸåˆ™ï¼Œå®Œå…¨å¼€æ”¾ç»™ç ”ç©¶ç¤¾åŒºä½¿ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰MedVQAæ•°æ®é›†åœ¨ä¸´åºŠå¤æ‚æ€§å’Œè§†è§‰å¤šæ ·æ€§æ–¹é¢çš„ä¸è¶³ï¼Œå¯¼è‡´æ¨¡å‹æ¨ç†èƒ½åŠ›å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥å¤§è§„æ¨¡é—®é¢˜-ç­”æ¡ˆå¯¹å’Œè§†è§‰å¢å¼ºæŠ€æœ¯ï¼ŒKvasir-VQA-x1æ—¨åœ¨æå‡æ¨¡å‹åœ¨çœŸå®ä¸´åºŠåœºæ™¯ä¸­çš„è¡¨ç°å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•°æ®é›†çš„æ„å»ºåŒ…æ‹¬é—®é¢˜ç”Ÿæˆã€è§†è§‰å¢å¼ºå’Œè¯„ä¼°æ¨¡å—ã€‚é—®é¢˜ç”Ÿæˆä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè§†è§‰å¢å¼ºåˆ™æ¨¡æ‹Ÿå¸¸è§çš„æˆåƒä¼ªå½±ã€‚

**å…³é”®åˆ›æ–°**ï¼šKvasir-VQA-x1çš„åˆ›æ–°åœ¨äºå…¶ç³»ç»ŸåŒ–çš„é—®é¢˜ç”Ÿæˆæ–¹æ³•å’Œè§†è§‰å¢å¼ºç­–ç•¥ï¼Œä½¿å¾—æ•°æ®é›†æ›´å…·ä¸´åºŠç›¸å…³æ€§å’ŒæŒ‘æˆ˜æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨é—®é¢˜ç”Ÿæˆä¸­ï¼Œé—®é¢˜æŒ‰å¤æ‚æ€§åˆ†å±‚è®¾è®¡ï¼Œç¡®ä¿è¦†ç›–ä¸åŒæ¨ç†èƒ½åŠ›çš„è¯„ä¼°ï¼›è§†è§‰å¢å¼ºåˆ™é€šè¿‡å¤šç§ä¼ªå½±æ¨¡æ‹ŸçœŸå®åœºæ™¯ä¸­çš„å¹²æ‰°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Kvasir-VQA-x1åœ¨æ ‡å‡†VQAæ€§èƒ½è¯„ä¼°ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤æ‚ä¸´åºŠåœºæ™¯ä¸‹çš„æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡å¼•å…¥è§†è§‰æ‰°åŠ¨æµ‹è¯•ï¼Œæ¨¡å‹çš„é²æ£’æ€§ä¹Ÿå¾—åˆ°äº†æœ‰æ•ˆéªŒè¯ï¼Œå±•ç¤ºäº†ç›¸è¾ƒäºç°æœ‰åŸºçº¿çš„æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Kvasir-VQA-x1å¯å¹¿æ³›åº”ç”¨äºåŒ»ç–—å½±åƒåˆ†æã€ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿçš„å¼€å‘åŠå¤šæ¨¡æ€AIç³»ç»Ÿçš„è®­ç»ƒã€‚å…¶ä¸°å¯Œçš„æ•°æ®é›†ä¸ºç ”ç©¶äººå‘˜æä¾›äº†ä¸€ä¸ªæ›´å…·æŒ‘æˆ˜æ€§çš„åŸºå‡†ï¼Œæ¨åŠ¨åŒ»ç–—AIæŠ€æœ¯çš„è¿›æ­¥ï¼Œæå‡ä¸´åºŠåº”ç”¨çš„å¯é æ€§ä¸æœ‰æ•ˆæ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Medical Visual Question Answering (MedVQA) is a promising field for developing clinical decision support systems, yet progress is often limited by the available datasets, which can lack clinical complexity and visual diversity. To address these gaps, we introduce Kvasir-VQA-x1, a new, large-scale dataset for gastrointestinal (GI) endoscopy. Our work significantly expands upon the original Kvasir-VQA by incorporating 159,549 new question-answer pairs that are designed to test deeper clinical reasoning. We developed a systematic method using large language models to generate these questions, which are stratified by complexity to better assess a model's inference capabilities. To ensure our dataset prepares models for real-world clinical scenarios, we have also introduced a variety of visual augmentations that mimic common imaging artifacts. The dataset is structured to support two main evaluation tracks: one for standard VQA performance and another to test model robustness against these visual perturbations. By providing a more challenging and clinically relevant benchmark, Kvasir-VQA-x1 aims to accelerate the development of more reliable and effective multimodal AI systems for use in clinical settings. The dataset is fully accessible and adheres to FAIR data principles, making it a valuable resource for the wider research community. Code and data: https://github.com/Simula/Kvasir-VQA-x1 and https://huggingface.co/datasets/SimulaMet/Kvasir-VQA-x1

