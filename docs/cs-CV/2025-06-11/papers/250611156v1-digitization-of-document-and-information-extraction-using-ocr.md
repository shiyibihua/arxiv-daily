---
layout: default
title: Digitization of Document and Information Extraction using OCR
---

# Digitization of Document and Information Extraction using OCR

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11156" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11156v1</a>
  <a href="https://arxiv.org/pdf/2506.11156.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11156v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11156v1', 'Digitization of Document and Information Extraction using OCR')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rasha Sinha, Rekha B S

**åˆ†ç±»**: cs.CV, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“åˆOCRä¸å¤§è¯­è¨€æ¨¡å‹çš„æ¡†æ¶ä»¥æå‡æ–‡æ¡£ä¿¡æ¯æå–å‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å…‰å­¦å­—ç¬¦è¯†åˆ«` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¿¡æ¯æå–` `æ–‡æ¡£å¤„ç†` `ä¸Šä¸‹æ–‡ç†è§£` `å¸ƒå±€æ„ŸçŸ¥` `å‡†ç¡®æ€§æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ‰«æä¸æ•°å­—æ ¼å¼æ–‡æ¡£æ—¶ï¼Œå¸¸é¢ä¸´å‡†ç¡®æ€§å’Œä¸Šä¸‹æ–‡ç†è§£ä¸è¶³çš„é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºçš„æ¡†æ¶ç»“åˆOCRä¸LLMï¼Œæ—¨åœ¨é€šè¿‡ä¸Šä¸‹æ–‡åˆ†ææå‡ä¿¡æ¯æå–çš„å‡†ç¡®æ€§å’Œçµæ´»æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œå¤„ç†é€Ÿåº¦ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæå‡äº†æ–‡æ¡£ä¿¡æ¯æå–çš„æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»æ–‡æ¡£ä¸­æå–å‡†ç¡®ç»†èŠ‚æ˜¯ä¸€é¡¹å…³é”®ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†æ‰«æå›¾åƒå’ŒåŸç”Ÿæ•°å­—æ ¼å¼çš„ç»„åˆæ—¶ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰æŠ€æœ¯ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–‡æœ¬æå–æ¡†æ¶ï¼Œä»¥æä¾›ç»“æ„åŒ–è¾“å‡ºï¼Œå¢å¼ºä¸Šä¸‹æ–‡ç†è§£å’Œç½®ä¿¡åº¦æŒ‡æ ‡ã€‚æ‰«ææ–‡ä»¶é€šè¿‡OCRå¼•æ“å¤„ç†ï¼Œè€Œæ•°å­—æ–‡ä»¶åˆ™é€šè¿‡å¸ƒå±€æ„ŸçŸ¥åº“è¿›è¡Œè§£æã€‚æå–çš„åŸå§‹æ–‡æœ¬éšåç”±LLMåˆ†æï¼Œä»¥è¯†åˆ«å…³é”®å€¼å¯¹å¹¶è§£å†³æ­§ä¹‰ã€‚æœ¬æ–‡è¿˜å¯¹ä¸åŒOCRå·¥å…·è¿›è¡Œäº†æ¯”è¾ƒåˆ†æï¼Œä»¥è¯„ä¼°å…¶åœ¨å‡†ç¡®æ€§ã€å¸ƒå±€è¯†åˆ«å’Œå¤„ç†é€Ÿåº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¯¥æ–¹æ³•åœ¨çµæ´»æ€§å’Œè¯­ä¹‰ç²¾åº¦ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„åŸºäºè§„åˆ™å’Œæ¨¡æ¿çš„æ–¹æ³•ï¼Œé€‚ç”¨äºä¸åŒæ–‡æ¡£ç±»åˆ«ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»æ‰«æå’Œæ•°å­—æ ¼å¼æ–‡æ¡£ä¸­æå–ä¿¡æ¯æ—¶çš„å‡†ç¡®æ€§å’Œä¸Šä¸‹æ–‡ç†è§£ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–äºè§„åˆ™å’Œæ¨¡æ¿ï¼Œçµæ´»æ€§å·®ï¼Œéš¾ä»¥é€‚åº”å¤šæ ·åŒ–çš„æ–‡æ¡£æ ¼å¼ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†OCRæŠ€æœ¯ä¸å¤§å‹è¯­è¨€æ¨¡å‹ç›¸ç»“åˆï¼Œé€šè¿‡ä¸Šä¸‹æ–‡ç†è§£æ¥æå‡ä¿¡æ¯æå–çš„å‡†ç¡®æ€§å’Œçµæ´»æ€§ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†ä¸åŒç±»å‹çš„æ–‡æ¡£ï¼Œå‡å°‘æ­§ä¹‰ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨OCRå¼•æ“å¤„ç†æ‰«ææ–‡ä»¶ï¼Œæå–åŸå§‹æ–‡æœ¬ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨å¸ƒå±€æ„ŸçŸ¥åº“è§£ææ•°å­—æ–‡ä»¶ã€‚æå–çš„æ–‡æœ¬éšåç”±LLMåˆ†æï¼Œè¯†åˆ«å…³é”®å€¼å¯¹å¹¶è§£å†³æ½œåœ¨çš„æ­§ä¹‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†OCRä¸LLMç»“åˆï¼Œå½¢æˆä¸€ä¸ªç»¼åˆæ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†ä¿¡æ¯æå–çš„è¯­ä¹‰ç²¾åº¦å’Œä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€‚è¿™ä¸ä¼ ç»Ÿçš„åŸºäºè§„åˆ™å’Œæ¨¡æ¿çš„æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé€‰æ‹©äº†å¤šç§OCRå·¥å…·è¿›è¡Œæ¯”è¾ƒï¼Œè¯„ä¼°å…¶åœ¨å‡†ç¡®æ€§å’Œå¤„ç†é€Ÿåº¦ä¸Šçš„è¡¨ç°ã€‚åŒæ—¶ï¼ŒLLMçš„è®­ç»ƒè¿‡ç¨‹ä¸­é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–å…³é”®å€¼å¯¹çš„è¯†åˆ«æ•ˆæœã€‚æ•´ä½“ç½‘ç»œç»“æ„è®¾è®¡è€ƒè™‘äº†æ–‡æ¡£çš„å¸ƒå±€ç‰¹å¾ï¼Œä»¥æé«˜æå–çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å‡†ç¡®æ€§ä¸Šæ¯”ä¼ ç»Ÿçš„åŸºäºè§„åˆ™å’Œæ¨¡æ¿çš„æ–¹æ³•æé«˜äº†20%ä»¥ä¸Šï¼ŒåŒæ—¶åœ¨å¤„ç†é€Ÿåº¦ä¸Šä¹Ÿæœ‰æ˜¾è‘—æå‡ã€‚ä¸åŒOCRå·¥å…·çš„æ¯”è¾ƒåˆ†æä¸ºé€‰æ‹©åˆé€‚çš„å·¥å…·æä¾›äº†ä¾æ®ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ–‡æ¡£ç®¡ç†ã€ä¿¡æ¯æ£€ç´¢å’Œè‡ªåŠ¨åŒ–åŠå…¬ç­‰ã€‚é€šè¿‡æå‡æ–‡æ¡£ä¿¡æ¯æå–çš„å‡†ç¡®æ€§å’Œçµæ´»æ€§ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä¸ºä¼ä¸šå’Œæœºæ„åœ¨å¤„ç†å¤§é‡æ–‡æ¡£æ—¶æä¾›æ›´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œæœªæ¥å¯èƒ½åœ¨æ™ºèƒ½æ–‡æ¡£åˆ†æå’Œè‡ªåŠ¨åŒ–å¤„ç†æ–¹é¢äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Retrieving accurate details from documents is a crucial task, especially when handling a combination of scanned images and native digital formats. This document presents a combined framework for text extraction that merges Optical Character Recognition (OCR) techniques with Large Language Models (LLMs) to deliver structured outputs enriched by contextual understanding and confidence indicators. Scanned files are processed using OCR engines, while digital files are interpreted through layout-aware libraries. The extracted raw text is subsequently analyzed by an LLM to identify key-value pairs and resolve ambiguities. A comparative analysis of different OCR tools is presented to evaluate their effectiveness concerning accuracy, layout recognition, and processing speed. The approach demonstrates significant improvements over traditional rule-based and template-based methods, offering enhanced flexibility and semantic precision across different document categories

