---
layout: default
title: "Multimodal Interpretation of Remote Sensing Images: Dynamic Resolution Input Strategy and Multi-scale Vision-Language Alignment Mechanism"
---

# Multimodal Interpretation of Remote Sensing Images: Dynamic Resolution Input Strategy and Multi-scale Vision-Language Alignment Mechanism

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.23243" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.23243v1</a>
  <a href="https://arxiv.org/pdf/2512.23243.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.23243v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.23243v1', 'Multimodal Interpretation of Remote Sensing Images: Dynamic Resolution Input Strategy and Multi-scale Vision-Language Alignment Mechanism')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Siyu Zhang, Ying Chen, Lianlei Shan, Runhe Qiu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDRISå’ŒMS-VLAMï¼Œç”¨äºæå‡é¥æ„Ÿå›¾åƒå¤šæ¨¡æ€èåˆçš„æ•ˆç‡å’Œè¯­ä¹‰ç†è§£ç²¾åº¦ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é¥æ„Ÿå›¾åƒ` `å¤šæ¨¡æ€èåˆ` `è§†è§‰-è¯­è¨€æ¨¡å‹` `åŠ¨æ€åˆ†è¾¨ç‡` `å¤šå°ºåº¦å¯¹é½` `å›¾åƒæè¿°` `è·¨æ¨¡æ€æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é¥æ„Ÿå›¾åƒå¤šæ¨¡æ€èåˆæ–¹æ³•åœ¨å›ºå®šåˆ†è¾¨ç‡ä¸‹éš¾ä»¥å¹³è¡¡æ•ˆç‡ä¸ç»†èŠ‚ï¼Œä¸”å•å°ºåº¦å¯¹é½ç¼ºä¹è¯­ä¹‰å±‚çº§ã€‚
2. æå‡ºåŠ¨æ€åˆ†è¾¨ç‡è¾“å…¥ç­–ç•¥ï¼ˆDRISï¼‰å’Œå¤šå°ºåº¦è§†è§‰-è¯­è¨€å¯¹é½æœºåˆ¶ï¼ˆMS-VLAMï¼‰æ¥æå‡æ•ˆç‡å’Œè¯­ä¹‰ç†è§£ç²¾åº¦ã€‚
3. åœ¨RS-GPT4Væ•°æ®é›†ä¸Šï¼Œè¯¥æ¡†æ¶åœ¨å›¾åƒæè¿°å’Œè·¨æ¨¡æ€æ£€ç´¢ä»»åŠ¡ä¸­æ˜¾è‘—æé«˜äº†è¯­ä¹‰ç†è§£ç²¾åº¦å’Œè®¡ç®—æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶é’ˆå¯¹é¥æ„Ÿå›¾åƒå¤šæ¨¡æ€èåˆä¸­å›ºå®šåˆ†è¾¨ç‡éš¾ä»¥å…¼é¡¾æ•ˆç‡ä¸ç»†èŠ‚ã€å•å°ºåº¦å¯¹é½ç¼ºä¹è¯­ä¹‰å±‚çº§çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªèåˆåŠ¨æ€åˆ†è¾¨ç‡è¾“å…¥ç­–ç•¥ï¼ˆDRISï¼‰å’Œå¤šå°ºåº¦è§†è§‰-è¯­è¨€å¯¹é½æœºåˆ¶ï¼ˆMS-VLAMï¼‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æ¡†æ¶ã€‚DRISé‡‡ç”¨ç”±ç²—åˆ°ç²¾çš„æ–¹æ³•ï¼Œæ ¹æ®å›¾åƒå†…å®¹çš„å¤æ‚æ€§è‡ªé€‚åº”åœ°åˆ†é…è®¡ç®—èµ„æºï¼Œä»è€Œåœ¨ä¿ç•™å…³é”®ç»†ç²’åº¦ç‰¹å¾çš„åŒæ—¶ï¼Œå‡å°‘å†—ä½™è®¡ç®—å¼€é”€ã€‚MS-VLAMæ„å»ºäº†ä¸€ä¸ªæ¶µç›–å¯¹è±¡ã€å±€éƒ¨åŒºåŸŸå’Œå…¨å±€å±‚é¢çš„ä¸‰å±‚å¯¹é½æœºåˆ¶ï¼Œç³»ç»Ÿåœ°æ•è·è·¨æ¨¡æ€è¯­ä¹‰ä¸€è‡´æ€§ï¼Œå¹¶ç¼“è§£è¯­ä¹‰é”™ä½å’Œç²’åº¦ä¸å¹³è¡¡çš„é—®é¢˜ã€‚åœ¨RS-GPT4Væ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¡†æ¶æ˜¾è‘—æé«˜äº†å›¾åƒæè¿°å’Œè·¨æ¨¡æ€æ£€ç´¢ç­‰ä»»åŠ¡ä¸­çš„è¯­ä¹‰ç†è§£ç²¾åº¦å’Œè®¡ç®—æ•ˆç‡ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œåœ¨å›¾åƒæè¿°çš„BLEU-4å’ŒCIDEræŒ‡æ ‡ä»¥åŠè·¨æ¨¡æ€æ£€ç´¢çš„R@10æŒ‡æ ‡ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚è¯¥æŠ€æœ¯æ¡†æ¶ä¸ºæ„å»ºé«˜æ•ˆã€é²æ£’çš„å¤šæ¨¡æ€é¥æ„Ÿç³»ç»Ÿæä¾›äº†ä¸€ç§æ–°æ–¹æ³•ï¼Œä¸ºæ™ºèƒ½é¥æ„Ÿè§£è¯‘çš„å·¥ç¨‹åº”ç”¨å¥ å®šäº†ç†è®ºåŸºç¡€ï¼Œå¹¶æä¾›äº†æŠ€æœ¯æŒ‡å¯¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šé¥æ„Ÿå›¾åƒçš„å¤šæ¨¡æ€èåˆæ—¨åœ¨å…‹æœå•æºæ•°æ®çš„å±€é™æ€§ï¼Œæé«˜åœ°è¡¨ä¿¡æ¯æå–çš„å‡†ç¡®æ€§ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨å›ºå®šåˆ†è¾¨ç‡çš„å›¾åƒè¾“å…¥ï¼Œæ— æ³•æ ¹æ®å›¾åƒå†…å®¹çš„å¤æ‚æ€§è‡ªé€‚åº”åœ°è°ƒæ•´è®¡ç®—èµ„æºï¼Œå¯¼è‡´è®¡ç®—æ•ˆç‡ä½ä¸‹æˆ–ç»†èŠ‚ä¿¡æ¯ä¸¢å¤±ã€‚æ­¤å¤–ï¼Œå•å°ºåº¦çš„è§†è§‰-è¯­è¨€å¯¹é½æœºåˆ¶ç¼ºä¹å¯¹è¯­ä¹‰å±‚çº§çš„è€ƒè™‘ï¼Œå®¹æ˜“å‡ºç°è¯­ä¹‰é”™ä½å’Œç²’åº¦ä¸å¹³è¡¡çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿè‡ªé€‚åº”è°ƒæ•´è¾“å…¥åˆ†è¾¨ç‡å¹¶è¿›è¡Œå¤šå°ºåº¦è¯­ä¹‰å¯¹é½çš„è§†è§‰-è¯­è¨€æ¨¡å‹ã€‚é€šè¿‡åŠ¨æ€è°ƒæ•´åˆ†è¾¨ç‡ï¼Œå¯ä»¥åœ¨ä¿è¯å…³é”®ç»†èŠ‚ä¿¡æ¯çš„åŒæ—¶å‡å°‘è®¡ç®—å†—ä½™ã€‚é€šè¿‡å¤šå°ºåº¦å¯¹é½ï¼Œå¯ä»¥æ›´å…¨é¢åœ°æ•æ‰è·¨æ¨¡æ€çš„è¯­ä¹‰å…³è”ï¼Œä»è€Œæé«˜è¯­ä¹‰ç†è§£çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šåŠ¨æ€åˆ†è¾¨ç‡è¾“å…¥ç­–ç•¥ï¼ˆDRISï¼‰å’Œå¤šå°ºåº¦è§†è§‰-è¯­è¨€å¯¹é½æœºåˆ¶ï¼ˆMS-VLAMï¼‰ã€‚DRISé¦–å…ˆå¯¹è¾“å…¥å›¾åƒè¿›è¡Œç²—ç•¥åˆ†æï¼Œæ ¹æ®å›¾åƒå¤æ‚åº¦ç¡®å®šåˆé€‚çš„åˆ†è¾¨ç‡ã€‚ç„¶åï¼ŒMS-VLAMåœ¨å¯¹è±¡ã€å±€éƒ¨åŒºåŸŸå’Œå…¨å±€ä¸‰ä¸ªå±‚é¢ä¸Šè¿›è¡Œè§†è§‰å’Œè¯­è¨€ç‰¹å¾çš„å¯¹é½ã€‚æœ€åï¼Œèåˆåçš„ç‰¹å¾ç”¨äºå®Œæˆä¸‹æ¸¸ä»»åŠ¡ï¼Œå¦‚å›¾åƒæè¿°å’Œè·¨æ¨¡æ€æ£€ç´¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºDRISå’ŒMS-VLAMçš„ç»“åˆã€‚DRISèƒ½å¤Ÿè‡ªé€‚åº”åœ°è°ƒæ•´è¾“å…¥åˆ†è¾¨ç‡ï¼Œä»è€Œåœ¨æ•ˆç‡å’Œç»†èŠ‚ä¹‹é—´å–å¾—å¹³è¡¡ã€‚MS-VLAMåˆ™é€šè¿‡å¤šå°ºåº¦å¯¹é½ï¼Œæ›´å…¨é¢åœ°æ•æ‰è·¨æ¨¡æ€çš„è¯­ä¹‰å…³è”ï¼Œè§£å†³äº†è¯­ä¹‰é”™ä½å’Œç²’åº¦ä¸å¹³è¡¡çš„é—®é¢˜ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨è®¡ç®—èµ„æºï¼Œå¹¶æé«˜è¯­ä¹‰ç†è§£çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šDRISçš„å…·ä½“å®ç°å¯èƒ½æ¶‰åŠå›¾åƒåˆ†å‰²ã€æ˜¾è‘—æ€§æ£€æµ‹ç­‰æŠ€æœ¯ï¼Œç”¨äºè¯„ä¼°å›¾åƒçš„å¤æ‚åº¦ã€‚MS-VLAMçš„å…·ä½“å®ç°å¯èƒ½é‡‡ç”¨å¤šå±‚Transformerç»“æ„ï¼Œåˆ†åˆ«æå–å¯¹è±¡ã€å±€éƒ¨åŒºåŸŸå’Œå…¨å±€å±‚é¢çš„è§†è§‰å’Œè¯­è¨€ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨å¯¹æ¯”å­¦ä¹ ç­‰æ–¹æ³•è¿›è¡Œå¯¹é½ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦è€ƒè™‘ä¸åŒå°ºåº¦çš„å¯¹é½æŸå¤±ï¼Œå¹¶è¿›è¡ŒåŠ æƒå¹³å‡ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23243v1/Fig.1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23243v1/Fig.2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23243v1/Fig.3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨RS-GPT4Væ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨å›¾åƒæè¿°ä»»åŠ¡ä¸­ï¼ŒBLEU-4å’ŒCIDEræŒ‡æ ‡å‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚åœ¨è·¨æ¨¡æ€æ£€ç´¢ä»»åŠ¡ä¸­ï¼ŒR@10æŒ‡æ ‡ä¹Ÿå¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜é¥æ„Ÿå›¾åƒå¤šæ¨¡æ€èåˆçš„æ•ˆç‡å’Œè¯­ä¹‰ç†è§£ç²¾åº¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºç¯å¢ƒç›‘æµ‹ã€åŸå¸‚è§„åˆ’ã€ç¾å®³è¯„ä¼°ç­‰é¢†åŸŸã€‚é€šè¿‡æ›´å‡†ç¡®åœ°ç†è§£é¥æ„Ÿå›¾åƒä¸­çš„ä¿¡æ¯ï¼Œå¯ä»¥ä¸ºç›¸å…³å†³ç­–æä¾›æ›´å¯é çš„ä¾æ®ã€‚ä¾‹å¦‚ï¼Œåœ¨ç¯å¢ƒç›‘æµ‹ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯ç›‘æµ‹æ¤è¢«è¦†ç›–å˜åŒ–ã€æ°´ä½“æ±¡æŸ“ç­‰æƒ…å†µã€‚åœ¨åŸå¸‚è§„åˆ’ä¸­ï¼Œå¯ä»¥ç”¨äºåˆ†æåŸå¸‚æ‰©å¼ ã€åœŸåœ°åˆ©ç”¨ç­‰é—®é¢˜ã€‚åœ¨ç¾å®³è¯„ä¼°ä¸­ï¼Œå¯ä»¥å¿«é€Ÿè¯„ä¼°ç¾æƒ…ï¼Œä¸ºæ•‘æ´å·¥ä½œæä¾›æ”¯æŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›ä¸æ— äººæœºã€å«æ˜Ÿç­‰å¹³å°ç»“åˆï¼Œå®ç°æ›´å¹¿æ³›çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal fusion of remote sensing images serves as a core technology for overcoming the limitations of single-source data and improving the accuracy of surface information extraction, which exhibits significant application value in fields such as environmental monitoring and urban planning. To address the deficiencies of existing methods, including the failure of fixed resolutions to balance efficiency and detail, as well as the lack of semantic hierarchy in single-scale alignment, this study proposes a Vision-language Model (VLM) framework integrated with two key innovations: the Dynamic Resolution Input Strategy (DRIS) and the Multi-scale Vision-language Alignment Mechanism (MS-VLAM).Specifically, the DRIS adopts a coarse-to-fine approach to adaptively allocate computational resources according to the complexity of image content, thereby preserving key fine-grained features while reducing redundant computational overhead. The MS-VLAM constructs a three-tier alignment mechanism covering object, local-region and global levels, which systematically captures cross-modal semantic consistency and alleviates issues of semantic misalignment and granularity imbalance.Experimental results on the RS-GPT4V dataset demonstrate that the proposed framework significantly improves the accuracy of semantic understanding and computational efficiency in tasks including image captioning and cross-modal retrieval. Compared with conventional methods, it achieves superior performance in evaluation metrics such as BLEU-4 and CIDEr for image captioning, as well as R@10 for cross-modal retrieval. This technical framework provides a novel approach for constructing efficient and robust multimodal remote sensing systems, laying a theoretical foundation and offering technical guidance for the engineering application of intelligent remote sensing interpretation.

