---
layout: default
title: "RS-Prune: Training-Free Data Pruning at High Ratios for Efficient Remote Sensing Diffusion Foundation Models"
---

# RS-Prune: Training-Free Data Pruning at High Ratios for Efficient Remote Sensing Diffusion Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.23239" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.23239v1</a>
  <a href="https://arxiv.org/pdf/2512.23239.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.23239v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.23239v1', 'RS-Prune: Training-Free Data Pruning at High Ratios for Efficient Remote Sensing Diffusion Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fan Wei, Runmin Dong, Yushan Lai, Yixiang Yang, Zhaoyang Luo, Jinxiao Zhang, Miao Yang, Shuai Yuan, Jiyao Zhao, Bin Luo, Haohuan Fu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**RS-Pruneï¼šé¢å‘é¥æ„Ÿæ‰©æ•£æ¨¡å‹çš„é«˜æ¯”ä¾‹å…è®­ç»ƒæ•°æ®å‰ªæ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é¥æ„Ÿå›¾åƒ` `æ‰©æ•£æ¨¡å‹` `æ•°æ®å‰ªæ` `å…è®­ç»ƒ` `åœºæ™¯æ„ŸçŸ¥èšç±»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é¥æ„Ÿæ‰©æ•£æ¨¡å‹è®­ç»ƒä¾èµ–å¤§é‡æ•°æ®ï¼Œä½†æ•°æ®ä¸­å­˜åœ¨å†—ä½™ã€å™ªå£°å’Œç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œå½±å“è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ”¶æ•›ã€‚
2. æå‡ºä¸€ç§å…è®­ç»ƒçš„ä¸¤é˜¶æ®µæ•°æ®å‰ªææ–¹æ³•ï¼Œé€šè¿‡ç†µå€¼ç­›é€‰ä½ä¿¡æ¯æ ·æœ¬ï¼Œå¹¶ç»“åˆåœºæ™¯æ„ŸçŸ¥èšç±»å’Œåˆ†å±‚æŠ½æ ·ï¼Œé€‰æ‹©é«˜è´¨é‡æ•°æ®å­é›†ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå³ä½¿å‰ªæ85%çš„æ•°æ®ï¼Œè¯¥æ–¹æ³•ä»èƒ½æ˜¾è‘—æå‡æ¨¡å‹æ”¶æ•›é€Ÿåº¦å’Œç”Ÿæˆè´¨é‡ï¼Œå¹¶åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­å–å¾—SOTAæ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºæ‰©æ•£çš„é¥æ„Ÿï¼ˆRSï¼‰ç”Ÿæˆå¼åŸºç¡€æ¨¡å‹å¯¹äºä¸‹æ¸¸ä»»åŠ¡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹ä¾èµ–äºå¤§é‡çš„å…¨å±€ä»£è¡¨æ€§æ•°æ®ï¼Œè¿™äº›æ•°æ®é€šå¸¸åŒ…å«å†—ä½™ã€å™ªå£°å’Œç±»åˆ«ä¸å¹³è¡¡ï¼Œä»è€Œé™ä½äº†è®­ç»ƒæ•ˆç‡å¹¶é˜»ç¢äº†æ”¶æ•›ã€‚ç°æœ‰çš„RSæ‰©æ•£åŸºç¡€æ¨¡å‹é€šå¸¸èšåˆå¤šä¸ªåˆ†ç±»æ•°æ®é›†æˆ–åº”ç”¨ç®€å•çš„å»é‡ï¼Œå¿½ç•¥äº†ç”Ÿæˆå»ºæ¨¡çš„åˆ†å¸ƒéœ€æ±‚å’ŒRSå›¾åƒçš„å¼‚è´¨æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å…è®­ç»ƒçš„ä¸¤é˜¶æ®µæ•°æ®å‰ªææ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¿«é€Ÿé€‰æ‹©é«˜è´¨é‡çš„å­é›†ï¼Œå³ä½¿åœ¨é«˜å‰ªæç‡ä¸‹ä¹Ÿèƒ½å®ç°åˆæ­¥åŸºç¡€æ¨¡å‹çš„å¿«é€Ÿæ”¶æ•›ï¼Œå¹¶ä½œä¸ºç”Ÿæˆã€ä¸‹æ¸¸å¾®è°ƒå’Œå…¶ä»–åº”ç”¨çš„å¤šåŠŸèƒ½éª¨å¹²ç½‘ç»œã€‚æˆ‘ä»¬çš„æ–¹æ³•è”åˆè€ƒè™‘äº†å±€éƒ¨ä¿¡æ¯å†…å®¹ä¸å…¨å±€åœºæ™¯çº§åˆ«çš„å¤šæ ·æ€§å’Œä»£è¡¨æ€§ã€‚é¦–å…ˆï¼ŒåŸºäºç†µçš„æ ‡å‡†æœ‰æ•ˆåœ°ç§»é™¤ä½ä¿¡æ¯é‡çš„æ ·æœ¬ã€‚æ¥ä¸‹æ¥ï¼Œåˆ©ç”¨RSåœºæ™¯åˆ†ç±»æ•°æ®é›†ä½œä¸ºå‚è€ƒåŸºå‡†ï¼Œæˆ‘ä»¬æ‰§è¡Œåœºæ™¯æ„ŸçŸ¥çš„èšç±»å’Œåˆ†å±‚æŠ½æ ·ï¼Œä»¥æé«˜èšç±»æ•ˆæœï¼ŒåŒæ—¶é™ä½å¤§è§„æ¨¡æ— æ ‡ç­¾æ•°æ®çš„è®¡ç®—æˆæœ¬ã€‚æœ€åï¼Œé€šè¿‡å¹³è¡¡èšç±»çº§åˆ«çš„å‡åŒ€æ€§å’Œæ ·æœ¬ä»£è¡¨æ€§ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨é«˜å‰ªæç‡ä¸‹è¿›è¡Œç»†ç²’åº¦é€‰æ‹©ï¼ŒåŒæ—¶ä¿æŒæ•´ä½“çš„å¤šæ ·æ€§å’Œä»£è¡¨æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œå³ä½¿åœ¨å‰ªæ85%çš„è®­ç»ƒæ•°æ®åï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¹Ÿèƒ½æ˜¾è‘—æé«˜æ”¶æ•›æ€§å’Œç”Ÿæˆè´¨é‡ã€‚æ­¤å¤–ï¼Œä½¿ç”¨æˆ‘ä»¬çš„æ–¹æ³•è®­ç»ƒçš„æ‰©æ•£åŸºç¡€æ¨¡å‹åœ¨åŒ…æ‹¬è¶…åˆ†è¾¨ç‡å’Œè¯­ä¹‰å›¾åƒåˆæˆåœ¨å†…çš„ä¸‹æ¸¸ä»»åŠ¡ä¸­å§‹ç»ˆå–å¾—æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¿™ç§æ•°æ®å‰ªæèŒƒå¼ä¸ºå¼€å‘RSç”Ÿæˆå¼åŸºç¡€æ¨¡å‹æä¾›äº†å®è·µæŒ‡å¯¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šé¥æ„Ÿæ‰©æ•£æ¨¡å‹è®­ç»ƒéœ€è¦å¤§é‡æ•°æ®ï¼Œä½†ç°æœ‰æ•°æ®é›†å­˜åœ¨å†—ä½™ã€å™ªå£°å’Œç±»åˆ«ä¸å¹³è¡¡ç­‰é—®é¢˜ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆç‡ä½ä¸‹ï¼Œæ¨¡å‹éš¾ä»¥æ”¶æ•›ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨ç®€å•çš„æ•°æ®å»é‡æˆ–ç›´æ¥èšåˆå¤šä¸ªæ•°æ®é›†ï¼Œå¿½ç•¥äº†é¥æ„Ÿå›¾åƒçš„å¼‚è´¨æ€§å’Œç”Ÿæˆæ¨¡å‹çš„åˆ†å¸ƒéœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ä¸¤é˜¶æ®µçš„æ•°æ®å‰ªæç­–ç•¥ï¼Œåœ¨ä¸è¿›è¡Œæ¨¡å‹è®­ç»ƒçš„å‰æä¸‹ï¼Œä»åŸå§‹æ•°æ®é›†ä¸­é€‰æ‹©ä¸€ä¸ªé«˜è´¨é‡ã€å…·æœ‰ä»£è¡¨æ€§çš„å­é›†ã€‚ç¬¬ä¸€é˜¶æ®µåŸºäºç†µå€¼å»é™¤ä½ä¿¡æ¯é‡æ ·æœ¬ï¼Œç¬¬äºŒé˜¶æ®µåˆ©ç”¨åœºæ™¯åˆ†ç±»ä¿¡æ¯è¿›è¡Œèšç±»å’Œåˆ†å±‚æŠ½æ ·ï¼Œä¿è¯æ•°æ®å­é›†çš„å¤šæ ·æ€§å’Œä»£è¡¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1) åŸºäºç†µå€¼çš„ä¿¡æ¯é‡ç­›é€‰ï¼šè®¡ç®—æ¯ä¸ªæ ·æœ¬çš„ä¿¡æ¯ç†µï¼Œå»é™¤ç†µå€¼è¾ƒä½çš„æ ·æœ¬ï¼Œä»è€Œè¿‡æ»¤æ‰å†—ä½™å’Œæ— ä¿¡æ¯çš„å›¾åƒã€‚2) åœºæ™¯æ„ŸçŸ¥çš„èšç±»å’Œåˆ†å±‚æŠ½æ ·ï¼šåˆ©ç”¨é¥æ„Ÿåœºæ™¯åˆ†ç±»æ•°æ®é›†ä½œä¸ºå‚è€ƒï¼Œå¯¹å‰©ä½™æ ·æœ¬è¿›è¡Œèšç±»ï¼Œå¹¶æ ¹æ®åœºæ™¯ç±»åˆ«è¿›è¡Œåˆ†å±‚æŠ½æ ·ï¼Œä¿è¯æ¯ä¸ªåœºæ™¯ç±»åˆ«éƒ½æœ‰è¶³å¤Ÿçš„æ ·æœ¬è¢«ä¿ç•™ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºç»“åˆäº†å±€éƒ¨ä¿¡æ¯å†…å®¹ï¼ˆç†µå€¼ï¼‰å’Œå…¨å±€åœºæ™¯çº§åˆ«çš„å¤šæ ·æ€§å’Œä»£è¡¨æ€§ã€‚ä¼ ç»Ÿçš„å‰ªææ–¹æ³•é€šå¸¸åªå…³æ³¨å•ä¸ªæ ·æœ¬çš„ä¿¡æ¯é‡ï¼Œè€Œå¿½ç•¥äº†æ•°æ®é›†çš„æ•´ä½“åˆ†å¸ƒã€‚è¯¥æ–¹æ³•é€šè¿‡åœºæ™¯æ„ŸçŸ¥çš„èšç±»å’Œåˆ†å±‚æŠ½æ ·ï¼Œä¿è¯äº†å‰ªæåçš„æ•°æ®é›†ä»ç„¶èƒ½å¤Ÿè¦†ç›–åŸå§‹æ•°æ®é›†çš„å„ç§åœºæ™¯ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ä¿¡æ¯é‡ç­›é€‰é˜¶æ®µï¼Œä½¿ç”¨å›¾åƒçš„åƒç´ å€¼è®¡ç®—ç†µå€¼ã€‚åœ¨åœºæ™¯æ„ŸçŸ¥èšç±»é˜¶æ®µï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„åœºæ™¯åˆ†ç±»æ¨¡å‹æå–å›¾åƒçš„ç‰¹å¾ï¼Œç„¶åä½¿ç”¨K-meansç®—æ³•è¿›è¡Œèšç±»ã€‚åœ¨åˆ†å±‚æŠ½æ ·é˜¶æ®µï¼Œæ ¹æ®æ¯ä¸ªèšç±»çš„æ ·æœ¬æ•°é‡ï¼ŒæŒ‰ç…§æ¯”ä¾‹è¿›è¡ŒæŠ½æ ·ï¼Œä¿è¯æ¯ä¸ªåœºæ™¯ç±»åˆ«éƒ½æœ‰è¶³å¤Ÿçš„æ ·æœ¬è¢«ä¿ç•™ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23239v1/Pictures/head.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23239v1/Pictures/0ef27c9b830072a346925b518d7876ee.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23239v1/x1.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿å‰ªæ85%çš„è®­ç»ƒæ•°æ®ï¼Œä½¿ç”¨RS-Pruneæ–¹æ³•è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹åœ¨æ”¶æ•›é€Ÿåº¦å’Œç”Ÿæˆè´¨é‡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨è¶…åˆ†è¾¨ç‡å’Œè¯­ä¹‰å›¾åƒåˆæˆç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­å–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼ŒéªŒè¯äº†è¯¥æ•°æ®å‰ªææ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºé¥æ„Ÿå›¾åƒç”Ÿæˆã€è¶…åˆ†è¾¨ç‡é‡å»ºã€è¯­ä¹‰å›¾åƒåˆæˆç­‰é¢†åŸŸã€‚é€šè¿‡é«˜æ•ˆçš„æ•°æ®å‰ªæï¼Œå¯ä»¥é™ä½é¥æ„Ÿæ‰©æ•£æ¨¡å‹è®­ç»ƒçš„è®¡ç®—æˆæœ¬å’Œæ—¶é—´æˆæœ¬ï¼ŒåŠ é€Ÿé¥æ„ŸåŸºç¡€æ¨¡å‹çš„å‘å±•ï¼Œå¹¶ä¸ºä¸‹æ¸¸åº”ç”¨æä¾›æ›´é«˜è´¨é‡çš„æ•°æ®æ”¯æŒï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Diffusion-based remote sensing (RS) generative foundation models are cruial for downstream tasks. However, these models rely on large amounts of globally representative data, which often contain redundancy, noise, and class imbalance, reducing training efficiency and preventing convergence. Existing RS diffusion foundation models typically aggregate multiple classification datasets or apply simplistic deduplication, overlooking the distributional requirements of generation modeling and the heterogeneity of RS imagery. To address these limitations, we propose a training-free, two-stage data pruning approach that quickly select a high-quality subset under high pruning ratios, enabling a preliminary foundation model to converge rapidly and serve as a versatile backbone for generation, downstream fine-tuning, and other applications. Our method jointly considers local information content with global scene-level diversity and representativeness. First, an entropy-based criterion efficiently removes low-information samples. Next, leveraging RS scene classification datasets as reference benchmarks, we perform scene-aware clustering with stratified sampling to improve clustering effectiveness while reducing computational costs on large-scale unlabeled data. Finally, by balancing cluster-level uniformity and sample representativeness, the method enables fine-grained selection under high pruning ratios while preserving overall diversity and representativeness. Experiments show that, even after pruning 85\% of the training data, our method significantly improves convergence and generation quality. Furthermore, diffusion foundation models trained with our method consistently achieve state-of-the-art performance across downstream tasks, including super-resolution and semantic image synthesis. This data pruning paradigm offers practical guidance for developing RS generative foundation models.

