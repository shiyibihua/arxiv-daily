---
layout: default
title: "MedGemma vs GPT-4: Open-Source and Proprietary Zero-shot Medical Disease Classification from Images"
---

# MedGemma vs GPT-4: Open-Source and Proprietary Zero-shot Medical Disease Classification from Images

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.23304" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.23304v1</a>
  <a href="https://arxiv.org/pdf/2512.23304.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.23304v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.23304v1', 'MedGemma vs GPT-4: Open-Source and Proprietary Zero-shot Medical Disease Classification from Images')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Md. Sazzadul Islam Prottasha, Nabil Walid Rafi

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-29

**å¤‡æ³¨**: Accepted for publication in the Journal of Machine Learning and Deep Learning (JMLDL). 9 pages, 9 figures, 10 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MedGemmaåœ¨åŒ»å­¦å›¾åƒç–¾ç—…åˆ†ç±»ä¸­ä¼˜äºGPT-4ï¼Œé¢†åŸŸå¾®è°ƒè‡³å…³é‡è¦**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒåˆ†ç±»` `å¤šæ¨¡æ€å¤§æ¨¡å‹` `é¢†åŸŸå¾®è°ƒ` `MedGemma` `GPT-4` `ä½ç§©é€‚åº”` `ç–¾ç—…è¯Šæ–­`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é€šç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨åŒ»å­¦å›¾åƒè¯Šæ–­ä¸­å­˜åœ¨å¹»è§‰é—®é¢˜ï¼Œé™åˆ¶äº†å…¶ä¸´åºŠåº”ç”¨ã€‚
2. è®ºæ–‡æå‡ºåˆ©ç”¨é¢†åŸŸçŸ¥è¯†å¾®è°ƒå¼€æºæ¨¡å‹MedGemmaï¼Œæå‡å…¶åœ¨ç‰¹å®šç–¾ç—…åˆ†ç±»ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒåçš„MedGemmaåœ¨å‡†ç¡®ç‡å’Œçµæ•åº¦ä¸Šå‡ä¼˜äºæœªå¾®è°ƒçš„GPT-4ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶å¯¹æ¯”äº†ä¸¤ç§æ¶æ„è¿¥å¼‚çš„AIæ¨¡å‹åœ¨åŒ»å­¦å›¾åƒç–¾ç—…åˆ†ç±»ä¸­çš„è¡¨ç°ï¼šä¸“é—¨çš„å¼€æºæ¨¡å‹MedGemmaå’Œä¸“æœ‰çš„å¤šæ¨¡æ€å¤§æ¨¡å‹GPT-4ï¼Œç”¨äºè¯Šæ–­å…­ç§ä¸åŒçš„ç–¾ç—…ã€‚ç»“æœè¡¨æ˜ï¼Œç»è¿‡ä½ç§©é€‚åº”(LoRA)å¾®è°ƒçš„MedGemma-4b-itæ¨¡å‹è¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„è¯Šæ–­èƒ½åŠ›ï¼Œå¹³å‡æµ‹è¯•å‡†ç¡®ç‡è¾¾åˆ°80.37%ï¼Œè€Œæœªè°ƒä¼˜çš„GPT-4ä¸º69.58%ã€‚æ­¤å¤–ï¼ŒMedGemmaåœ¨é«˜é£é™©ä¸´åºŠä»»åŠ¡ï¼ˆå¦‚ç™Œç—‡å’Œè‚ºç‚æ£€æµ‹ï¼‰ä¸­è¡¨ç°å‡ºæ˜æ˜¾æ›´é«˜çš„çµæ•åº¦ã€‚é€šè¿‡æ··æ·†çŸ©é˜µå’Œåˆ†ç±»æŠ¥å‘Šè¿›è¡Œçš„å®šé‡åˆ†æï¼Œå…¨é¢æ·±å…¥åœ°å±•ç¤ºäº†æ¨¡å‹åœ¨æ‰€æœ‰ç±»åˆ«ä¸­çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœå¼ºè°ƒï¼Œé¢†åŸŸç‰¹å®šçš„å¾®è°ƒå¯¹äºæœ€å°åŒ–ä¸´åºŠåº”ç”¨ä¸­çš„å¹»è§‰è‡³å…³é‡è¦ï¼Œä½¿MedGemmaæˆä¸ºå¤æ‚ã€åŸºäºè¯æ®çš„åŒ»å­¦æ¨ç†çš„å¼ºå¤§å·¥å…·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŒ»å­¦å›¾åƒç–¾ç—…åˆ†ç±»é—®é¢˜ã€‚ç°æœ‰é€šç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰è™½ç„¶æ‹¥æœ‰å¹¿æ³›çš„çŸ¥è¯†ï¼Œä½†åœ¨åŒ»å­¦é¢†åŸŸç¼ºä¹ä¸“ä¸šçŸ¥è¯†ï¼Œå®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œå¯¼è‡´è¯Šæ–­é”™è¯¯ã€‚è¿™é™åˆ¶äº†å®ƒä»¬åœ¨ä¸´åºŠç¯å¢ƒä¸­çš„å¯é åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢†åŸŸç‰¹å®šçš„æ•°æ®å¯¹å¼€æºæ¨¡å‹MedGemmaè¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶æ›´å¥½åœ°é€‚åº”åŒ»å­¦å›¾åƒçš„ç‰¹ç‚¹å’Œç–¾ç—…çš„è¯Šæ–­é€»è¾‘ã€‚é€šè¿‡å¾®è°ƒï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°æ›´å‡†ç¡®çš„åŒ»å­¦çŸ¥è¯†ï¼Œä»è€Œå‡å°‘å¹»è§‰ï¼Œæé«˜è¯Šæ–­å‡†ç¡®ç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œä½¿ç”¨ä½ç§©é€‚åº”(LoRA)æ–¹æ³•å¯¹MedGemma-4b-itæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶é€‚åº”åŒ»å­¦å›¾åƒæ•°æ®ã€‚å…¶æ¬¡ï¼Œå°†å¾®è°ƒåçš„MedGemmaä¸æœªå¾®è°ƒçš„GPT-4è¿›è¡Œæ¯”è¾ƒï¼Œè¯„ä¼°å®ƒä»¬åœ¨å…­ç§ä¸åŒç–¾ç—…çš„åˆ†ç±»ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬å‡†ç¡®ç‡ã€çµæ•åº¦ã€æ··æ·†çŸ©é˜µå’Œåˆ†ç±»æŠ¥å‘Šã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºè¯æ˜äº†é¢†åŸŸç‰¹å®šå¾®è°ƒå¯¹äºæé«˜å¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨åŒ»å­¦å›¾åƒè¯Šæ–­ä¸­çš„æ€§èƒ½è‡³å…³é‡è¦ã€‚é€šè¿‡å¯¹å¼€æºæ¨¡å‹MedGemmaè¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¶…è¶Šäº†æœªå¾®è°ƒçš„ä¸“æœ‰æ¨¡å‹GPT-4ï¼Œçªå‡ºäº†é¢†åŸŸçŸ¥è¯†çš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä½¿ç”¨äº†ä½ç§©é€‚åº”(LoRA)æ–¹æ³•è¿›è¡Œå¾®è°ƒï¼Œè¿™æ˜¯ä¸€ç§å‚æ•°é«˜æ•ˆçš„å¾®è°ƒæŠ€æœ¯ï¼Œå¯ä»¥åœ¨ä¸ä¿®æ”¹åŸå§‹æ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡å¼•å…¥å°‘é‡å¯è®­ç»ƒçš„å‚æ•°æ¥é€‚åº”æ–°çš„ä»»åŠ¡ã€‚å…·ä½“æ¥è¯´ï¼ŒLoRAé€šè¿‡åœ¨é¢„è®­ç»ƒæ¨¡å‹çš„æƒé‡çŸ©é˜µæ—è¾¹æ·»åŠ ä½ç§©çŸ©é˜µæ¥å®ç°ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ä»”ç»†é€‰æ‹©äº†ç”¨äºå¾®è°ƒçš„æ•°æ®é›†ï¼Œå¹¶é’ˆå¯¹ä¸åŒçš„ç–¾ç—…ç±»åˆ«è¿›è¡Œäº†æ€§èƒ½è¯„ä¼°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡LoRAå¾®è°ƒçš„MedGemma-4b-itæ¨¡å‹åœ¨å…­ç§ç–¾ç—…çš„å¹³å‡æµ‹è¯•å‡†ç¡®ç‡è¾¾åˆ°80.37%ï¼Œæ˜¾è‘—é«˜äºæœªè°ƒä¼˜çš„GPT-4çš„69.58%ã€‚å°¤å…¶åœ¨ç™Œç—‡å’Œè‚ºç‚ç­‰é«˜é£é™©ç–¾ç—…çš„æ£€æµ‹ä¸­ï¼ŒMedGemmaè¡¨ç°å‡ºæ›´é«˜çš„çµæ•åº¦ï¼Œè¡¨æ˜é¢†åŸŸå¾®è°ƒèƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹åœ¨å…³é”®ä¸´åºŠä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œç–¾ç—…è¯Šæ–­ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºæœ‰é™çš„åœ°åŒºï¼Œå¯ä»¥åˆ©ç”¨å¼€æºæ¨¡å‹å’Œé¢†åŸŸå¾®è°ƒæŠ€æœ¯æ„å»ºä½æˆæœ¬ã€é«˜æ€§èƒ½çš„åŒ»å­¦å›¾åƒè¯Šæ–­ç³»ç»Ÿã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ‰©å±•åˆ°æ›´å¤šç–¾ç—…çš„è¯Šæ–­ï¼Œå¹¶ä¸å…¶ä»–åŒ»ç–—ä¿¡æ¯ç³»ç»Ÿé›†æˆï¼Œæå‡åŒ»ç–—æœåŠ¡çš„æ•ˆç‡å’Œè´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Large Language Models (LLMs) introduce an emerging paradigm for medical imaging by interpreting scans through the lens of extensive clinical knowledge, offering a transformative approach to disease classification. This study presents a critical comparison between two fundamentally different AI architectures: the specialized open-source agent MedGemma and the proprietary large multimodal model GPT-4 for diagnosing six different diseases. The MedGemma-4b-it model, fine-tuned using Low-Rank Adaptation (LoRA), demonstrated superior diagnostic capability by achieving a mean test accuracy of 80.37% compared to 69.58% for the untuned GPT-4. Furthermore, MedGemma exhibited notably higher sensitivity in high-stakes clinical tasks, such as cancer and pneumonia detection. Quantitative analysis via confusion matrices and classification reports provides comprehensive insights into model performance across all categories. These results emphasize that domain-specific fine-tuning is essential for minimizing hallucinations in clinical implementation, positioning MedGemma as a sophisticated tool for complex, evidence-based medical reasoning.

