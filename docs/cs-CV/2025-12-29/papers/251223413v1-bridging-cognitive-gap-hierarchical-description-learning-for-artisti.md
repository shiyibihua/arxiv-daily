---
layout: default
title: "Bridging Cognitive Gap: Hierarchical Description Learning for Artistic Image Aesthetics Assessment"
---

# Bridging Cognitive Gap: Hierarchical Description Learning for Artistic Image Aesthetics Assessment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.23413" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.23413v1</a>
  <a href="https://arxiv.org/pdf/2512.23413.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.23413v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.23413v1', 'Bridging Cognitive Gap: Hierarchical Description Learning for Artistic Image Aesthetics Assessment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Henglin Liu, Nisha Huang, Chang Liu, Jiangpeng Yan, Huijuan Huang, Jixuan Ying, Tong-Yee Lee, Pengfei Wan, Xiangyang Ji

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-29

**å¤‡æ³¨**: AAAI2026,Project Page:https://github.com/Henglin-Liu/ArtQuant

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºArtQuantæ¡†æ¶ï¼Œé€šè¿‡å±‚çº§æè¿°å­¦ä¹ è§£å†³è‰ºæœ¯å›¾åƒç¾å­¦è¯„ä¼°ä¸­çš„è®¤çŸ¥é¸¿æ²Ÿã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‰ºæœ¯å›¾åƒç¾å­¦è¯„ä¼°` `å±‚çº§æè¿°å­¦ä¹ ` `AIGC` `å¤šæ¨¡æ€å­¦ä¹ ` `LLM` `æ•°æ®é›†æ„å»º` `è®¤çŸ¥é¸¿æ²Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç¾å­¦è¯„ä¼°æ•°æ®é›†æ ‡æ³¨æˆæœ¬é«˜æ˜‚ï¼Œå¯¼è‡´æ•°æ®ç¨€ç¼ºä¸”ä¾§é‡è§†è§‰æ„ŸçŸ¥ï¼Œå¿½ç•¥äº†è®¤çŸ¥å’Œæƒ…æ„Ÿç­‰æ·±å±‚ç»´åº¦ã€‚
2. ArtQuantæ¡†æ¶é€šè¿‡è”åˆæè¿°ç”Ÿæˆè€¦åˆç¾å­¦ç»´åº¦ï¼Œå¹¶åˆ©ç”¨LLMè§£ç å™¨å»ºæ¨¡é•¿æ–‡æœ¬è¯­ä¹‰ï¼Œä»è€Œç¼©å°è®¤çŸ¥å·®è·ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒArtQuantåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œä¸”ä»…éœ€ä¼ ç»Ÿè®­ç»ƒepochçš„33%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¾å­¦è´¨é‡è¯„ä¼°å¯¹äºå¼€å‘ä¸äººç±»è®¤çŸ¥å¯¹é½çš„AIGCå®šé‡è¯„ä¼°ç³»ç»Ÿè‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå…¶å†…åœ¨çš„å¤æ‚æ€§ï¼Œè·¨è¶Šè§†è§‰æ„ŸçŸ¥ã€è®¤çŸ¥å’Œæƒ…æ„Ÿï¼Œå¸¦æ¥äº†æ ¹æœ¬æ€§çš„æŒ‘æˆ˜ã€‚å°½ç®¡ç¾å­¦æè¿°ä¸ºæ­¤å¤æ‚æ€§æä¾›äº†ä¸€ç§å¯è¡Œçš„è¡¨ç¤ºï¼Œä½†ä»ç„¶å­˜åœ¨ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰æ•°æ®ç¨€ç¼ºå’Œä¸å¹³è¡¡ï¼šç”±äºæ˜‚è´µçš„æ‰‹åŠ¨æ ‡æ³¨ï¼Œç°æœ‰æ•°æ®é›†è¿‡åº¦å…³æ³¨è§†è§‰æ„ŸçŸ¥è€Œå¿½ç•¥äº†æ›´æ·±å±‚æ¬¡çš„ç»´åº¦ï¼›ï¼ˆ2ï¼‰æ¨¡å‹ç¢ç‰‡åŒ–ï¼šå½“å‰è§†è§‰ç½‘ç»œä½¿ç”¨å¤šåˆ†æ”¯ç¼–ç å™¨éš”ç¦»ç¾å­¦å±æ€§ï¼Œè€Œä»¥å¯¹æ¯”å­¦ä¹ ä¸ºä»£è¡¨çš„å¤šæ¨¡æ€æ–¹æ³•éš¾ä»¥æœ‰æ•ˆå¤„ç†é•¿æ–‡æœ¬æè¿°ã€‚ä¸ºäº†è§£å†³æŒ‘æˆ˜ï¼ˆ1ï¼‰ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº†ç²¾ç‚¼ç¾å­¦æè¿°ï¼ˆRADï¼‰æ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡ï¼ˆ70kï¼‰ã€å¤šç»´ç»“æ„åŒ–æ•°æ®é›†ï¼Œé€šè¿‡è¿­ä»£æµç¨‹ç”Ÿæˆï¼Œæ— éœ€å¤§é‡æ ‡æ³¨æˆæœ¬ä¸”æ˜“äºæ‰©å±•ã€‚ä¸ºäº†è§£å†³æŒ‘æˆ˜ï¼ˆ2ï¼‰ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºè‰ºæœ¯å›¾åƒçš„ç¾å­¦è¯„ä¼°æ¡†æ¶ArtQuantï¼Œè¯¥æ¡†æ¶ä¸ä»…é€šè¿‡è”åˆæè¿°ç”Ÿæˆè€¦åˆäº†å­¤ç«‹çš„ç¾å­¦ç»´åº¦ï¼Œè€Œä¸”å€ŸåŠ©LLMè§£ç å™¨æ›´å¥½åœ°å»ºæ¨¡äº†é•¿æ–‡æœ¬è¯­ä¹‰ã€‚æ­¤å¤–ï¼Œç†è®ºåˆ†æè¯å®äº†è¿™ç§å…±ç”Ÿå…³ç³»ï¼šRADçš„è¯­ä¹‰å……åˆ†æ€§ï¼ˆæ•°æ®ï¼‰å’Œç”ŸæˆèŒƒå¼ï¼ˆæ¨¡å‹ï¼‰å…±åŒæœ€å°åŒ–äº†é¢„æµ‹ç†µï¼Œä¸ºè¯¥æ¡†æ¶æä¾›äº†æ•°å­¦åŸºç¡€ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä»…éœ€è¦ä¼ ç»Ÿè®­ç»ƒepochçš„33%ï¼Œç¼©å°äº†è‰ºæœ¯å›¾åƒå’Œç¾å­¦åˆ¤æ–­ä¹‹é—´çš„è®¤çŸ¥å·®è·ã€‚æˆ‘ä»¬å°†å‘å¸ƒä»£ç å’Œæ•°æ®é›†ä»¥æ”¯æŒæœªæ¥çš„ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è‰ºæœ¯å›¾åƒç¾å­¦è¯„ä¼°ä¸­å­˜åœ¨çš„è®¤çŸ¥é¸¿æ²Ÿé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å­˜åœ¨ä¸¤ä¸ªç—›ç‚¹ï¼šä¸€æ˜¯æ•°æ®é›†æ ‡æ³¨æˆæœ¬é«˜æ˜‚ï¼Œå¯¼è‡´æ•°æ®ç¨€ç¼ºä¸”ä¸å¹³è¡¡ï¼Œéš¾ä»¥è¦†ç›–ç¾å­¦çš„å¤šç»´åº¦ç‰¹å¾ï¼›äºŒæ˜¯æ¨¡å‹è®¾è®¡ä¸Šï¼Œè§†è§‰ç½‘ç»œé€šå¸¸é‡‡ç”¨å¤šåˆ†æ”¯ç»“æ„å­¤ç«‹åœ°å¤„ç†å„ä¸ªç¾å­¦å±æ€§ï¼Œè€Œå¤šæ¨¡æ€æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨é•¿æ–‡æœ¬æè¿°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå¤§è§„æ¨¡ã€å¤šç»´åº¦çš„ç¾å­¦æè¿°æ•°æ®é›†ï¼ˆRADï¼‰ï¼Œå¹¶è®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨è¯¥æ•°æ®é›†è¿›è¡Œè®­ç»ƒçš„ç¾å­¦è¯„ä¼°æ¡†æ¶ï¼ˆArtQuantï¼‰ã€‚ArtQuanté€šè¿‡è”åˆç”Ÿæˆç¾å­¦æè¿°æ¥è€¦åˆå„ä¸ªç»´åº¦ï¼Œå¹¶å€ŸåŠ©LLMè§£ç å™¨æ›´å¥½åœ°ç†è§£å’Œåˆ©ç”¨é•¿æ–‡æœ¬è¯­ä¹‰ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šArtQuantæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1)å›¾åƒç¼–ç å™¨ï¼šç”¨äºæå–å›¾åƒçš„è§†è§‰ç‰¹å¾ï¼›2)æ–‡æœ¬ç¼–ç å™¨ï¼šç”¨äºç¼–ç ç¾å­¦æè¿°æ–‡æœ¬ï¼›3)è”åˆæè¿°ç”Ÿæˆå™¨ï¼šåŸºäºå›¾åƒç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾ï¼Œç”Ÿæˆå¯¹å›¾åƒç¾å­¦å±æ€§çš„æè¿°ï¼›4)ç¾å­¦è´¨é‡è¯„ä¼°å™¨ï¼šåŸºäºç”Ÿæˆçš„ç¾å­¦æè¿°ï¼Œé¢„æµ‹å›¾åƒçš„ç¾å­¦è´¨é‡ã€‚æ•´ä¸ªæµç¨‹æ˜¯ç«¯åˆ°ç«¯å¯è®­ç»ƒçš„ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1)æå‡ºäº†RADæ•°æ®é›†ï¼Œè§£å†³äº†æ•°æ®ç¨€ç¼ºå’Œä¸å¹³è¡¡çš„é—®é¢˜ï¼›2)æå‡ºäº†ArtQuantæ¡†æ¶ï¼Œé€šè¿‡è”åˆæè¿°ç”Ÿæˆå’ŒLLMè§£ç å™¨ï¼Œæœ‰æ•ˆè€¦åˆäº†ç¾å­¦ç»´åº¦å¹¶åˆ©ç”¨äº†é•¿æ–‡æœ¬è¯­ä¹‰ï¼›3)ä»ç†è®ºä¸Šåˆ†æäº†RADæ•°æ®é›†å’ŒArtQuantæ¡†æ¶çš„å…±ç”Ÿå…³ç³»ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šRADæ•°æ®é›†é€šè¿‡è¿­ä»£æµç¨‹ç”Ÿæˆï¼Œé™ä½äº†æ ‡æ³¨æˆæœ¬ã€‚ArtQuantæ¡†æ¶ä½¿ç”¨Transformeræ¶æ„ä½œä¸ºè”åˆæè¿°ç”Ÿæˆå™¨å’ŒLLMè§£ç å™¨ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æè¿°ç”ŸæˆæŸå¤±å’Œç¾å­¦è´¨é‡è¯„ä¼°æŸå¤±ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23413v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23413v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23413v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

ArtQuantæ¡†æ¶åœ¨å¤šä¸ªè‰ºæœ¯å›¾åƒç¾å­¦è¯„ä¼°æ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œä¾‹å¦‚åœ¨XXXXæ•°æ®é›†ä¸Šï¼Œç›¸æ¯”äºä¹‹å‰çš„æœ€ä½³æ–¹æ³•ï¼Œå‡†ç¡®ç‡æå‡äº†X%ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒArtQuantä»…éœ€ä¼ ç»Ÿè®­ç»ƒepochçš„33%å³å¯è¾¾åˆ°SOTAæ€§èƒ½ï¼Œæ˜¾è‘—é™ä½äº†è®­ç»ƒæˆæœ¬ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºAIGCå†…å®¹çš„è´¨é‡è¯„ä¼°ã€å›¾åƒæœç´¢æ’åºã€è‰ºæœ¯å“æ¨èã€ä»¥åŠä¸ªæ€§åŒ–å†…å®¹ç”Ÿæˆç­‰é¢†åŸŸã€‚é€šè¿‡æ›´å‡†ç¡®åœ°è¯„ä¼°è‰ºæœ¯å›¾åƒçš„ç¾å­¦è´¨é‡ï¼Œå¯ä»¥æå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶ä¸ºAIGCçš„å‘å±•æä¾›æ›´æœ‰æ•ˆçš„åé¦ˆæœºåˆ¶ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„å†…å®¹ï¼Œå¦‚è§†é¢‘ã€éŸ³ä¹ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The aesthetic quality assessment task is crucial for developing a human-aligned quantitative evaluation system for AIGC. However, its inherently complex nature, spanning visual perception, cognition, and emotion, poses fundamental challenges. Although aesthetic descriptions offer a viable representation of this complexity, two critical challenges persist: (1) data scarcity and imbalance: existing dataset overly focuses on visual perception and neglects deeper dimensions due to the expensive manual annotation; and (2) model fragmentation: current visual networks isolate aesthetic attributes with multi-branch encoder, while multimodal methods represented by contrastive learning struggle to effectively process long-form textual descriptions. To resolve challenge (1), we first present the Refined Aesthetic Description (RAD) dataset, a large-scale (70k), multi-dimensional structured dataset, generated via an iterative pipeline without heavy annotation costs and easy to scale. To address challenge (2), we propose ArtQuant, an aesthetics assessment framework for artistic images which not only couples isolated aesthetic dimensions through joint description generation, but also better models long-text semantics with the help of LLM decoders. Besides, theoretical analysis confirms this symbiosis: RAD's semantic adequacy (data) and generation paradigm (model) collectively minimize prediction entropy, providing mathematical grounding for the framework. Our approach achieves state-of-the-art performance on several datasets while requiring only 33% of conventional training epochs, narrowing the cognitive gap between artistic images and aesthetic judgment. We will release both code and dataset to support future research.

