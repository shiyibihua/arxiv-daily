---
layout: default
title: "ThinkGen: Generalized Thinking for Visual Generation"
---

# ThinkGen: Generalized Thinking for Visual Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.23568" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.23568v1</a>
  <a href="https://arxiv.org/pdf/2512.23568.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.23568v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.23568v1', 'ThinkGen: Generalized Thinking for Visual Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Siyu Jiao, Yiheng Lin, Yujie Zhong, Qi She, Wei Zhou, Xiaohan Lan, Zilong Huang, Fei Yu, Yingchen Yu, Yunqing Zhao, Yao Zhao, Yunchao Wei

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-29

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/jiaosiyuu/ThinkGen)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ThinkGenï¼šæå‡ºåŸºäºå¹¿ä¹‰æ€ç»´çš„è§†è§‰ç”Ÿæˆæ¡†æ¶ï¼Œæå‡å¤šåœºæ™¯é€‚åº”æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰ç”Ÿæˆ` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `æ€ç»´é“¾` `æ‰©æ•£æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `å›¾åƒç¼–è¾‘` `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆä»»åŠ¡ä¸­åº”ç”¨CoTæ¨ç†å—é™äºç‰¹å®šåœºæ™¯æœºåˆ¶ï¼Œç¼ºä¹æ³›åŒ–æ€§å’Œé€‚åº”æ€§ã€‚
2. ThinkGenåˆ©ç”¨MLLMçš„CoTæ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡è§£è€¦æ¶æ„å’Œå¯åˆ†ç¦»è®­ç»ƒèŒƒå¼å®ç°è·¨åœºæ™¯çš„è§†è§‰ç”Ÿæˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒThinkGenåœ¨å¤šä¸ªç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†é¢†å…ˆçš„æ€§èƒ½è¡¨ç°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºThinkGenï¼Œä¸€ç§åŸºäºæ€ç»´é©±åŠ¨çš„è§†è§‰ç”Ÿæˆæ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„æ€ç»´é“¾ï¼ˆCoTï¼‰æ¨ç†èƒ½åŠ›ï¼Œè§£å†³ç”Ÿæˆä»»åŠ¡ä¸­åœºæ™¯æ³›åŒ–æ€§ä¸è¶³çš„é—®é¢˜ã€‚ThinkGené‡‡ç”¨è§£è€¦æ¶æ„ï¼ŒåŒ…å«é¢„è®­ç»ƒçš„MLLMå’Œæ‰©æ•£Transformerï¼ˆDiTï¼‰ã€‚MLLMæ ¹æ®ç”¨æˆ·æ„å›¾ç”Ÿæˆå®šåˆ¶æŒ‡ä»¤ï¼ŒDiTåœ¨æŒ‡ä»¤å¼•å¯¼ä¸‹ç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚æ­¤å¤–ï¼Œè®ºæ–‡æå‡ºä¸€ç§å¯åˆ†ç¦»çš„åŸºäºGRPOçš„è®­ç»ƒèŒƒå¼ï¼ˆSepGRPOï¼‰ï¼Œåœ¨MLLMå’ŒDiTæ¨¡å—ä¹‹é—´äº¤æ›¿è¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€‚è¿™ç§çµæ´»çš„è®¾è®¡æ”¯æŒè·¨å¤šä¸ªæ•°æ®é›†çš„è”åˆè®­ç»ƒï¼Œä»è€Œä¿ƒè¿›CoTæ¨ç†åœ¨å„ç§ç”Ÿæˆåœºæ™¯ä¸­çš„æœ‰æ•ˆåº”ç”¨ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒThinkGenåœ¨å¤šä¸ªç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†ç¨³å¥çš„ã€æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰ç”Ÿæˆæ–¹æ³•åœ¨åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„æ€ç»´é“¾ï¼ˆCoTï¼‰æ¨ç†èƒ½åŠ›æ—¶ï¼Œå¾€å¾€é’ˆå¯¹ç‰¹å®šåœºæ™¯è®¾è®¡ï¼Œå¯¼è‡´æ¨¡å‹åœ¨é¢å¯¹ä¸åŒç”Ÿæˆä»»åŠ¡æ—¶æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚è¿™äº›æ–¹æ³•ç¼ºä¹ä¸€ç§é€šç”¨çš„æœºåˆ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨MLLMçš„æ¨ç†èƒ½åŠ›æ¥æŒ‡å¯¼å›¾åƒç”Ÿæˆï¼Œä»è€Œé™åˆ¶äº†å…¶åœ¨æ›´å¹¿æ³›åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šThinkGençš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è§†è§‰ç”Ÿæˆè¿‡ç¨‹åˆ†è§£ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œåˆ©ç”¨MLLMçš„CoTæ¨ç†èƒ½åŠ›ï¼Œæ ¹æ®ç”¨æˆ·æ„å›¾ç”Ÿæˆè¯¦ç»†çš„æŒ‡ä»¤ï¼›ç„¶åï¼Œåˆ©ç”¨æ‰©æ•£Transformerï¼ˆDiTï¼‰åœ¨è¿™äº›æŒ‡ä»¤çš„å¼•å¯¼ä¸‹ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚è¿™ç§è§£è€¦çš„è®¾è®¡ä½¿å¾—MLLMå¯ä»¥ä¸“æ³¨äºæ¨ç†ï¼Œè€ŒDiTå¯ä»¥ä¸“æ³¨äºå›¾åƒç”Ÿæˆï¼Œä»è€Œæé«˜äº†æ•´ä½“çš„æ•ˆç‡å’Œæ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šThinkGençš„æ•´ä½“æ¶æ„åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€ä¸ªé¢„è®­ç»ƒçš„MLLMå’Œä¸€ä¸ªæ‰©æ•£Transformerï¼ˆDiTï¼‰ã€‚ç”¨æˆ·è¾“å…¥æ–‡æœ¬æˆ–å›¾åƒï¼ŒMLLMæ ¹æ®è¾“å…¥ç”Ÿæˆä¸€ç³»åˆ—çš„æ¨ç†æ­¥éª¤å’Œæœ€ç»ˆçš„ç”ŸæˆæŒ‡ä»¤ã€‚è¿™äº›æŒ‡ä»¤è¢«ä¼ é€’ç»™DiTï¼ŒDiTæ ¹æ®æŒ‡ä»¤ç”Ÿæˆæœ€ç»ˆçš„å›¾åƒã€‚ä¸ºäº†æ›´å¥½åœ°è®­ç»ƒè¿™ä¸¤ä¸ªæ¨¡å—ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ä¸ªå¯åˆ†ç¦»çš„åŸºäºGRPOçš„è®­ç»ƒèŒƒå¼ï¼ˆSepGRPOï¼‰ï¼Œè¯¥èŒƒå¼äº¤æ›¿åœ°å¯¹MLLMå’ŒDiTè¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šThinkGençš„å…³é”®åˆ›æ–°åœ¨äºå…¶è§£è€¦çš„æ¶æ„å’Œå¯åˆ†ç¦»çš„è®­ç»ƒèŒƒå¼ã€‚è§£è€¦æ¶æ„ä½¿å¾—MLLMå’ŒDiTå¯ä»¥ç‹¬ç«‹åœ°è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œæé«˜äº†æ•´ä½“çš„æ€§èƒ½ã€‚å¯åˆ†ç¦»çš„è®­ç»ƒèŒƒå¼å…è®¸åœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šè”åˆè®­ç»ƒMLLMå’ŒDiTï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒThinkGenæ˜¯ç¬¬ä¸€ä¸ªæ˜¾å¼åœ°åˆ©ç”¨MLLMçš„CoTæ¨ç†èƒ½åŠ›æ¥æŒ‡å¯¼è§†è§‰ç”Ÿæˆçš„æ¡†æ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šSepGRPOè®­ç»ƒèŒƒå¼æ˜¯å…³é”®è®¾è®¡ä¹‹ä¸€ï¼Œå®ƒé€šè¿‡äº¤æ›¿å¼ºåŒ–å­¦ä¹ çš„æ–¹å¼ï¼Œåˆ†åˆ«ä¼˜åŒ–MLLMå’ŒDiTã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆå›ºå®šDiTï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–MLLMï¼Œä½¿å…¶ç”Ÿæˆæ›´æœ‰æ•ˆçš„æŒ‡ä»¤ï¼›ç„¶åå›ºå®šMLLMï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–DiTï¼Œä½¿å…¶æ›´å¥½åœ°ç†è§£å’Œæ‰§è¡ŒæŒ‡ä»¤ã€‚è¿™ç§äº¤æ›¿ä¼˜åŒ–çš„æ–¹å¼å¯ä»¥æœ‰æ•ˆåœ°æé«˜æ•´ä½“çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦å¹³è¡¡ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œä¸æŒ‡ä»¤çš„ä¸€è‡´æ€§ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23568v1/x3.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23568v1/x4.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23568v1/x5.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

ThinkGenåœ¨å¤šä¸ªç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒThinkGençš„FIDå¾—åˆ†ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¡¨æ˜å…¶ç”Ÿæˆçš„å›¾åƒè´¨é‡æ›´é«˜ã€‚æ­¤å¤–ï¼ŒThinkGenåœ¨å›¾åƒç¼–è¾‘ä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·æŒ‡ä»¤å¯¹å›¾åƒè¿›è¡Œç²¾ç¡®çš„ä¿®æ”¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒThinkGenèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨MLLMçš„CoTæ¨ç†èƒ½åŠ›æ¥æŒ‡å¯¼è§†è§‰ç”Ÿæˆï¼Œä»è€Œæé«˜äº†æ•´ä½“çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ThinkGenå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬å›¾åƒç¼–è¾‘ã€å›¾åƒç”Ÿæˆã€è‰ºæœ¯åˆ›ä½œã€äº§å“è®¾è®¡ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºæ ¹æ®ç”¨æˆ·æä¾›çš„æ–‡æœ¬æè¿°æˆ–è‰å›¾ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒï¼Œä¹Ÿå¯ä»¥ç”¨äºå¯¹ç°æœ‰å›¾åƒè¿›è¡Œç¼–è¾‘å’Œä¿®æ”¹ã€‚æ­¤å¤–ï¼ŒThinkGenè¿˜å¯ä»¥åº”ç”¨äºè™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘ç­‰é¢†åŸŸï¼Œä¸ºç”¨æˆ·æä¾›æ›´åŠ é€¼çœŸå’Œæ²‰æµ¸å¼çš„ä½“éªŒã€‚æœªæ¥ï¼ŒThinkGenæœ‰æœ›æˆä¸ºè§†è§‰ç”Ÿæˆé¢†åŸŸçš„é‡è¦å·¥å…·ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent progress in Multimodal Large Language Models (MLLMs) demonstrates that Chain-of-Thought (CoT) reasoning enables systematic solutions to complex understanding tasks. However, its extension to generation tasks remains nascent and limited by scenario-specific mechanisms that hinder generalization and adaptation. In this work, we present ThinkGen, the first think-driven visual generation framework that explicitly leverages MLLM's CoT reasoning in various generation scenarios. ThinkGen employs a decoupled architecture comprising a pretrained MLLM and a Diffusion Transformer (DiT), wherein the MLLM generates tailored instructions based on user intent, and DiT produces high-quality images guided by these instructions. We further propose a separable GRPO-based training paradigm (SepGRPO), alternating reinforcement learning between the MLLM and DiT modules. This flexible design enables joint training across diverse datasets, facilitating effective CoT reasoning for a wide range of generative scenarios. Extensive experiments demonstrate that ThinkGen achieves robust, state-of-the-art performance across multiple generation benchmarks. Code is available: https://github.com/jiaosiyuu/ThinkGen

