---
layout: default
title: "LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation"
---

# LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.23576" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.23576v1</a>
  <a href="https://arxiv.org/pdf/2512.23576.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.23576v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.23576v1', 'LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ethan Chern, Zhulin Hu, Bohao Tang, Jiadi Su, Steffi Chern, Zhijie Deng, Pengfei Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ”¹è¿›çš„On-Policyè’¸é¦æ–¹æ³•ï¼Œå®ç°å¤šæ¨¡æ€äº¤äº’å¼å®æ—¶è§†é¢‘æ‰©æ•£**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å®æ—¶è§†é¢‘ç”Ÿæˆ` `å¤šæ¨¡æ€äº¤äº’` `æ‰©æ•£æ¨¡å‹` `On-Policyè’¸é¦` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ‰©æ•£æ¨¡å‹åœ¨å®æ—¶è§†é¢‘ç”Ÿæˆä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯å¤šæ¨¡æ€æ¡ä»¶ä¸‹çš„äº¤äº’å¼åº”ç”¨ï¼Œä¸»è¦åŸå› æ˜¯å…¶åŒå‘æ³¨æ„åŠ›å’Œè¿­ä»£é‡‡æ ·è¿‡ç¨‹ã€‚
2. è®ºæ–‡æå‡ºæ”¹è¿›çš„On-Policyè’¸é¦æ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–æ¡ä»¶è¾“å…¥è´¨é‡å’Œè’¸é¦è¿‡ç¨‹ï¼Œæ˜¾è‘—æå‡äº†å¤šæ¨¡æ€æ¡ä»¶ä¸‹çš„è§†é¢‘ç”Ÿæˆæ•ˆç‡å’Œè´¨é‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿è¯è§†è§‰è´¨é‡çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†æ¨ç†æˆæœ¬å’Œå»¶è¿Ÿï¼Œå¹¶åœ¨å¤šè½®äº¤äº’åœºæ™¯ä¸­ä¼˜äºç°æœ‰å…ˆè¿›æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€äº¤äº’å¼AIç³»ç»Ÿä¸­å®æ—¶è§†é¢‘ç”Ÿæˆçš„é—®é¢˜ã€‚ç°æœ‰çš„æ‰©æ•£æ¨¡å‹ç”±äºå…¶è¿­ä»£è¿‡ç¨‹ä¸­çš„åŒå‘æ³¨æ„åŠ›æœºåˆ¶ï¼Œéš¾ä»¥å®ç°å®æ—¶äº¤äº’ã€‚è™½ç„¶è’¸é¦æ–¹æ³•å¯ä»¥é€šè¿‡è‡ªå›å½’å»ºæ¨¡å’Œå‡å°‘é‡‡æ ·æ­¥éª¤æ¥ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œä½†å®ƒä»¬ä¸»è¦é›†ä¸­åœ¨æ–‡æœ¬åˆ°è§†é¢‘çš„ç”Ÿæˆï¼Œå¯¼è‡´äººæœºäº¤äº’ä¸è‡ªç„¶ä¸”æ•ˆç‡ä½ä¸‹ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›çš„è’¸é¦æ–¹æ³•ï¼Œé‡ç‚¹å…³æ³¨æ¡ä»¶è¾“å…¥çš„è´¨é‡ä»¥åŠOn-Policyä¼˜åŒ–çš„åˆå§‹åŒ–å’Œè°ƒåº¦ï¼Œä»¥å®ç°åŸºäºæ–‡æœ¬ã€å›¾åƒå’ŒéŸ³é¢‘ç­‰å¤šæ¨¡æ€ä¸Šä¸‹æ–‡çš„å®æ—¶äº¤äº’å¼è§†é¢‘æ‰©æ•£ã€‚åœ¨HDTFã€AVSpeechå’ŒCelebV-HQç­‰æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨è§†è§‰è´¨é‡ä¸Šä¸å…¨æ­¥ã€åŒå‘åŸºçº¿æ¨¡å‹ç›¸å½“ï¼ŒåŒæ—¶æ¨ç†æˆæœ¬å’Œå»¶è¿Ÿé™ä½äº†20å€ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹é›†æˆäº†éŸ³é¢‘è¯­è¨€æ¨¡å‹å’ŒAnchor-Heavy Identity Sinksé•¿è§†é¢‘æ¨ç†æŠ€æœ¯ï¼Œæ„å»ºäº†LiveTalkå®æ—¶å¤šæ¨¡æ€äº¤äº’å¼åŒ–èº«ç³»ç»Ÿã€‚ç³»ç»Ÿçº§è¯„ä¼°è¡¨æ˜ï¼ŒLiveTalkåœ¨å¤šè½®è§†é¢‘è¿è´¯æ€§å’Œå†…å®¹è´¨é‡æ–¹é¢ä¼˜äºSora2å’ŒVeo3ç­‰æ¨¡å‹ï¼Œå¹¶å°†å“åº”å»¶è¿Ÿä»1-2åˆ†é’Ÿé™ä½åˆ°å®æ—¶ç”Ÿæˆï¼Œä»è€Œå®ç°æ— ç¼çš„äººæœºå¤šæ¨¡æ€äº¤äº’ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€äº¤äº’å¼AIç³»ç»Ÿä¸­å®æ—¶è§†é¢‘ç”Ÿæˆçš„é—®é¢˜ã€‚ç°æœ‰æ‰©æ•£æ¨¡å‹ç”±äºå…¶è¿­ä»£è¿‡ç¨‹ä¸­çš„åŒå‘æ³¨æ„åŠ›æœºåˆ¶ï¼Œéš¾ä»¥å®ç°å®æ—¶äº¤äº’ã€‚ç°æœ‰çš„è’¸é¦æ–¹æ³•è™½ç„¶å¯ä»¥åŠ é€Ÿç”Ÿæˆï¼Œä½†åœ¨å¤šæ¨¡æ€æ¡ä»¶ä¸‹çš„æ•ˆæœä¸ä½³ï¼Œå®¹æ˜“å‡ºç°è§†è§‰ä¼ªå½±ï¼Œå¦‚é—ªçƒã€é»‘å¸§å’Œè´¨é‡ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ”¹è¿›On-Policyè’¸é¦æ–¹æ³•ï¼Œæé«˜å¤šæ¨¡æ€æ¡ä»¶ä¸‹çš„è§†é¢‘ç”Ÿæˆè´¨é‡å’Œæ•ˆç‡ã€‚å…³é”®åœ¨äºä¼˜åŒ–æ¡ä»¶è¾“å…¥çš„è´¨é‡ï¼Œå¹¶æ”¹è¿›On-Policyä¼˜åŒ–çš„åˆå§‹åŒ–å’Œè°ƒåº¦ç­–ç•¥ã€‚é€šè¿‡é«˜è´¨é‡çš„æ¡ä»¶è¾“å…¥å’Œæ›´æœ‰æ•ˆçš„è’¸é¦è¿‡ç¨‹ï¼Œå¯ä»¥ç”Ÿæˆæ›´é€¼çœŸã€æ›´è¿è´¯çš„è§†é¢‘ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªå¤šæ¨¡æ€æ¡ä»¶ç¼–ç å™¨ï¼Œç”¨äºå°†æ–‡æœ¬ã€å›¾åƒå’ŒéŸ³é¢‘ä¿¡æ¯ç¼–ç ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚ç„¶åï¼Œä½¿ç”¨æ”¹è¿›çš„On-Policyè’¸é¦æ–¹æ³•è®­ç»ƒä¸€ä¸ªè‡ªå›å½’æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ ¹æ®æ½œåœ¨è¡¨ç¤ºç”Ÿæˆè§†é¢‘å¸§ã€‚æœ€åï¼Œå°†è¯¥æ¨¡å‹é›†æˆåˆ°LiveTalkç³»ç»Ÿä¸­ï¼Œå®ç°å®æ—¶å¤šæ¨¡æ€äº¤äº’ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæ”¹è¿›çš„On-Policyè’¸é¦æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç‰¹åˆ«å…³æ³¨æ¡ä»¶è¾“å…¥çš„è´¨é‡ä»¥åŠè’¸é¦è¿‡ç¨‹çš„ä¼˜åŒ–ã€‚ä¸ä¼ ç»Ÿçš„è’¸é¦æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤šæ¨¡æ€æ¡ä»¶ï¼Œå¹¶ç”Ÿæˆæ›´é«˜è´¨é‡çš„è§†é¢‘ã€‚æ­¤å¤–ï¼ŒLiveTalkç³»ç»Ÿçš„é›†æˆä¹Ÿå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å…³é”®çš„è®¾è®¡åŒ…æ‹¬ï¼š(1) ä½¿ç”¨é«˜è´¨é‡çš„å¤šæ¨¡æ€æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œç¡®ä¿æ¡ä»¶è¾“å…¥çš„å‡†ç¡®æ€§ï¼›(2) æ”¹è¿›On-Policyä¼˜åŒ–çš„åˆå§‹åŒ–ç­–ç•¥ï¼Œé¿å…è®­ç»ƒåˆæœŸå‡ºç°ä¸ç¨³å®šçš„æƒ…å†µï¼›(3) è°ƒæ•´è’¸é¦è¿‡ç¨‹ä¸­çš„è°ƒåº¦ç­–ç•¥ï¼Œå¹³è¡¡ç”Ÿæˆé€Ÿåº¦å’Œè§†é¢‘è´¨é‡ï¼›(4) ä½¿ç”¨Anchor-Heavy Identity SinksæŠ€æœ¯ï¼Œæé«˜é•¿è§†é¢‘çš„è¿è´¯æ€§ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23576v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23576v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23576v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨HDTFã€AVSpeechå’ŒCelebV-HQç­‰æ•°æ®é›†ä¸Šï¼Œåœ¨è§†è§‰è´¨é‡ä¸Šä¸å…¨æ­¥ã€åŒå‘åŸºçº¿æ¨¡å‹ç›¸å½“ï¼ŒåŒæ—¶æ¨ç†æˆæœ¬å’Œå»¶è¿Ÿé™ä½äº†20å€ã€‚åœ¨å¤šè½®äº¤äº’åœºæ™¯ä¸­ï¼ŒLiveTalkç³»ç»Ÿåœ¨è§†é¢‘è¿è´¯æ€§å’Œå†…å®¹è´¨é‡æ–¹é¢ä¼˜äºSora2å’ŒVeo3ç­‰æ¨¡å‹ï¼Œå¹¶å°†å“åº”å»¶è¿Ÿä»1-2åˆ†é’Ÿé™ä½åˆ°å®æ—¶ç”Ÿæˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè™šæ‹ŸåŒ–èº«ã€åœ¨çº¿ä¼šè®®ã€æ¸¸æˆã€æ•™è‚²ç­‰é¢†åŸŸã€‚é€šè¿‡å®æ—¶å¤šæ¨¡æ€äº¤äº’ï¼Œå¯ä»¥åˆ›å»ºæ›´è‡ªç„¶ã€æ›´å…·å¸å¼•åŠ›çš„ç”¨æˆ·ä½“éªŒã€‚ä¾‹å¦‚ï¼Œç”¨æˆ·å¯ä»¥ä¸è™šæ‹ŸåŒ–èº«è¿›è¡Œå®æ—¶å¯¹è¯ï¼Œå¹¶æ ¹æ®ç”¨æˆ·çš„è¯­éŸ³ã€è¡¨æƒ…å’Œæ–‡æœ¬è¾“å…¥ï¼Œç”Ÿæˆç›¸åº”çš„è§†é¢‘å†…å®¹ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥å‘å±•ï¼Œå®ç°æ›´é«˜çº§çš„äººæœºäº¤äº’ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Real-time video generation via diffusion is essential for building general-purpose multimodal interactive AI systems. However, the simultaneous denoising of all video frames with bidirectional attention via an iterative process in diffusion models prevents real-time interaction. While existing distillation methods can make the model autoregressive and reduce sampling steps to mitigate this, they focus primarily on text-to-video generation, leaving the human-AI interaction unnatural and less efficient. This paper targets real-time interactive video diffusion conditioned on a multimodal context, including text, image, and audio, to bridge the gap. Given the observation that the leading on-policy distillation approach Self Forcing encounters challenges (visual artifacts like flickering, black frames, and quality degradation) with multimodal conditioning, we investigate an improved distillation recipe with emphasis on the quality of condition inputs as well as the initialization and schedule for the on-policy optimization. On benchmarks for multimodal-conditioned (audio, image, and text) avatar video generation including HDTF, AVSpeech, and CelebV-HQ, our distilled model matches the visual quality of the full-step, bidirectional baselines of similar or larger size with 20x less inference cost and latency. Further, we integrate our model with audio language models and long-form video inference technique Anchor-Heavy Identity Sinks to build LiveTalk, a real-time multimodal interactive avatar system. System-level evaluation on our curated multi-turn interaction benchmark shows LiveTalk outperforms state-of-the-art models (Sora2, Veo3) in multi-turn video coherence and content quality, while reducing response latency from 1 to 2 minutes to real-time generation, enabling seamless human-AI multimodal interaction.

