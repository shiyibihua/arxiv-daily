---
layout: default
title: Visual Language Hypothesis
---

# Visual Language Hypothesis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.23335" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.23335v1</a>
  <a href="https://arxiv.org/pdf/2512.23335.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.23335v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.23335v1', 'Visual Language Hypothesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiu Li

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§†è§‰è¯­è¨€å‡è®¾ï¼Œä»ç»“æ„å’Œæ‹“æ‰‘è§’åº¦åˆ†æè§†è§‰è¡¨å¾å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¡¨å¾å­¦ä¹ ` `çº¤ç»´æŸç†è®º` `æ‹“æ‰‘ç»“æ„` `è¯­ä¹‰ä¸å˜æ€§` `è§†è§‰è¯­è¨€` `æŠ½è±¡` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰è¡¨å¾å­¦ä¹ æ–¹æ³•ç¼ºä¹å¯¹è§†è§‰è¯­ä¹‰ç»“æ„å’Œæ‹“æ‰‘æ€§è´¨çš„æ·±å…¥ç†è§£ã€‚
2. è®ºæ–‡æå‡ºè§†è§‰è¯­è¨€å‡è®¾ï¼Œè®¤ä¸ºè§†è§‰ç†è§£ä¾èµ–äºç¦»æ•£è¯­ä¹‰çŠ¶æ€å’Œçº¤ç»´æŸç»“æ„ã€‚
3. è¯¥æ¡†æ¶ä¸ºç†è§£å¤§è§„æ¨¡åˆ¤åˆ«å’Œå¤šæ¨¡æ€æ¨¡å‹çš„ç»éªŒè§„å¾‹æä¾›äº†ä¸€ä¸ªæ‹“æ‰‘è§†è§’ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»ç»“æ„å’Œæ‹“æ‰‘çš„è§’åº¦ç ”ç©¶è§†è§‰è¡¨å¾å­¦ä¹ ã€‚æˆ‘ä»¬ä»ä¸€ä¸ªå‡è®¾å‡ºå‘ï¼šè§†è§‰ç†è§£é¢„è®¾äº†ä¸€ç§è§†è§‰è¯­ä¹‰è¯­è¨€ï¼Œå…¶ä¸­è®¸å¤šæ„ŸçŸ¥è§‚å¯Ÿå¯¹åº”äºå°‘é‡ç¦»æ•£çš„è¯­ä¹‰çŠ¶æ€ã€‚ç»“åˆè¡¨å¾å­¦ä¹ ä¸­å¹¿æ³›å‡è®¾çš„å¯è¿ç§»æ€§å’ŒæŠ½è±¡æ€§ï¼Œè¯¥å‡è®¾æ„å‘³ç€è§†è§‰è§‚å¯Ÿç©ºé—´å¿…é¡»ç»„ç»‡æˆç±»ä¼¼äºçº¤ç»´æŸçš„ç»“æ„ï¼Œå…¶ä¸­å¹²æ‰°å˜åŒ–å¡«å……çº¤ç»´ï¼Œè€Œè¯­ä¹‰å¯¹åº”äºå•†åŸºç©ºé—´ã€‚ä»è¿™ç§ç»“æ„ä¸­ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºä¸¤ä¸ªç†è®ºç»“æœã€‚é¦–å…ˆï¼Œè¯­ä¹‰å•†ç©ºé—´$X/G$ä¸æ˜¯$X$çš„å­æµå½¢ï¼Œä¸èƒ½ä»…é€šè¿‡å¹³æ»‘å˜å½¢è·å¾—ï¼Œè¯­ä¹‰ä¸å˜æ€§éœ€è¦éåŒèƒšçš„åˆ¤åˆ«ç›®æ ‡ï¼Œä¾‹å¦‚ï¼Œé€šè¿‡æ ‡ç­¾ã€è·¨å®ä¾‹è¯†åˆ«æˆ–æä¾›æ˜¾å¼è¯­ä¹‰ç­‰ä»·æ€§çš„å¤šæ¨¡æ€å¯¹é½è¿›è¡Œç›‘ç£ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬è¡¨æ˜ï¼Œè¿‘ä¼¼å•†ç©ºé—´ä¹Ÿå¯¹æ¨¡å‹æ¶æ„æå‡ºäº†ç»“æ„æ€§è¦æ±‚ã€‚è¯­ä¹‰æŠ½è±¡ä¸ä»…éœ€è¦å¤–éƒ¨è¯­ä¹‰ç›®æ ‡ï¼Œè¿˜éœ€è¦èƒ½å¤Ÿæ”¯æŒæ‹“æ‰‘å˜åŒ–çš„è¡¨å¾æœºåˆ¶ï¼šä¸€ç§æ‰©å±•å’Œæ•æ‰è¿‡ç¨‹ï¼Œå…¶ä¸­æµå½¢é¦–å…ˆåœ¨å‡ ä½•ä¸Šæ‰©å±•ä»¥åˆ†ç¦»ç»“æ„ï¼Œç„¶åå¡Œé™·ä»¥å½¢æˆç¦»æ•£çš„è¯­ä¹‰åŒºåŸŸã€‚æˆ‘ä»¬å¼ºè°ƒè¿™äº›ç»“æœæ˜¯è§£é‡Šæ€§çš„è€Œéè§„å®šæ€§çš„ï¼šè¯¥æ¡†æ¶æä¾›äº†ä¸€ä¸ªæ‹“æ‰‘è§†è§’ï¼Œä¸å¤§è§„æ¨¡åˆ¤åˆ«å’Œå¤šæ¨¡æ€æ¨¡å‹ä¸­è§‚å¯Ÿåˆ°çš„ç»éªŒè§„å¾‹ä»¥åŠç»Ÿè®¡å­¦ä¹ ç†è®ºä¸­çš„ç»å…¸åŸåˆ™ç›¸ä¸€è‡´ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨ç†è§£è§†è§‰è¡¨å¾å­¦ä¹ çš„å†…åœ¨ç»“æ„ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•ä»åŸå§‹åƒç´ ç©ºé—´æŠ½è±¡åˆ°é«˜çº§è¯­ä¹‰æ¦‚å¿µã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾§é‡äºä¼˜åŒ–æ¨¡å‹ä»¥æé«˜æ€§èƒ½ï¼Œè€Œå¿½ç•¥äº†å¯¹è¡¨å¾ç©ºé—´æ‹“æ‰‘ç»“æ„çš„åˆ†æï¼Œè¿™é™åˆ¶äº†å¯¹è§†è§‰ç†è§£æœ¬è´¨çš„ç†è§£ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹è¯­ä¹‰ä¸å˜æ€§çš„æ˜ç¡®å»ºæ¨¡ï¼Œå¯¼è‡´æ¨¡å‹å®¹æ˜“å—åˆ°å™ªå£°å’Œå¹²æ‰°çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥â€œè§†è§‰è¯­è¨€å‡è®¾â€ï¼Œå³è§†è§‰ç†è§£ä¾èµ–äºä¸€ä¸ªæ½œåœ¨çš„è¯­ä¹‰è¯­è¨€ï¼Œè¯¥è¯­è¨€å°†è¿ç»­çš„è§†è§‰è§‚å¯Ÿæ˜ å°„åˆ°å°‘é‡çš„ç¦»æ•£è¯­ä¹‰çŠ¶æ€ã€‚è¿™ç§å‡è®¾æš—ç¤ºè§†è§‰è§‚å¯Ÿç©ºé—´å…·æœ‰çº¤ç»´æŸç»“æ„ï¼Œå…¶ä¸­æ¯ä¸ªçº¤ç»´ä»£è¡¨åŒä¸€è¯­ä¹‰æ¦‚å¿µçš„ä¸åŒå˜ä½“ã€‚é€šè¿‡åˆ†æè¿™ç§ç»“æ„ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£è¯­ä¹‰ä¸å˜æ€§å’ŒæŠ½è±¡çš„æœ¬è´¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡æ„å»ºäº†ä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŸºäºçº¤ç»´æŸç†è®ºæ¥æè¿°è§†è§‰è¡¨å¾ç©ºé—´ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼š1) è§†è§‰è§‚å¯Ÿç©ºé—´Xï¼Œä»£è¡¨æ‰€æœ‰å¯èƒ½çš„è§†è§‰è¾“å…¥ã€‚2) è¯­ä¹‰ç©ºé—´Gï¼Œä»£è¡¨ç¦»æ•£çš„è¯­ä¹‰çŠ¶æ€ã€‚3) çº¤ç»´æŸç»“æ„ï¼Œå°†Xç»„ç»‡æˆçº¤ç»´ï¼Œæ¯ä¸ªçº¤ç»´å¯¹åº”äºGä¸­çš„ä¸€ä¸ªè¯­ä¹‰çŠ¶æ€ã€‚4) å•†ç©ºé—´X/Gï¼Œä»£è¡¨è¯­ä¹‰ä¸å˜çš„è¡¨å¾ã€‚è®ºæ–‡é€šè¿‡åˆ†æè¿™äº›ç»„æˆéƒ¨åˆ†ä¹‹é—´çš„å…³ç³»ï¼Œæ¨å¯¼å‡ºå…³äºè¯­ä¹‰ä¸å˜æ€§å’ŒæŠ½è±¡çš„ç†è®ºç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†çº¤ç»´æŸç†è®ºå¼•å…¥è§†è§‰è¡¨å¾å­¦ä¹ ï¼Œå¹¶æå‡ºäº†â€œè§†è§‰è¯­è¨€å‡è®¾â€ã€‚è¿™ç§å‡è®¾æä¾›äº†ä¸€ç§æ–°çš„è§†è§’æ¥ç†è§£è§†è§‰ç†è§£çš„æœ¬è´¨ï¼Œå¹¶ä¸ºè®¾è®¡æ›´æœ‰æ•ˆçš„è¡¨å¾å­¦ä¹ æ–¹æ³•æä¾›äº†ç†è®ºæŒ‡å¯¼ã€‚è®ºæ–‡å¼ºè°ƒäº†è¯­ä¹‰ä¸å˜æ€§éœ€è¦éåŒèƒšçš„åˆ¤åˆ«ç›®æ ‡ï¼Œè¿™ä¸ä¼ ç»Ÿçš„å¹³æ»‘å˜å½¢æ–¹æ³•ä¸åŒã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡æ²¡æœ‰æå‡ºå…·ä½“çš„æ¨¡å‹æ¶æ„æˆ–ç®—æ³•ï¼Œè€Œæ˜¯ä¾§é‡äºç†è®ºåˆ†æã€‚ç„¶è€Œï¼Œè®ºæ–‡çš„ç»“è®ºå¯¹æ¨¡å‹è®¾è®¡å…·æœ‰é‡è¦æ„ä¹‰ã€‚ä¾‹å¦‚ï¼Œè®ºæ–‡æŒ‡å‡ºè¯­ä¹‰æŠ½è±¡éœ€è¦èƒ½å¤Ÿæ”¯æŒæ‹“æ‰‘å˜åŒ–çš„è¡¨å¾æœºåˆ¶ï¼Œè¿™æš—ç¤ºäº†éœ€è¦ä½¿ç”¨å…·æœ‰éçº¿æ€§æ¿€æ´»å‡½æ•°æˆ–è·³è·ƒè¿æ¥çš„ç½‘ç»œç»“æ„ã€‚è®ºæ–‡è¿˜å¼ºè°ƒäº†éœ€è¦ä½¿ç”¨æ˜¾å¼çš„è¯­ä¹‰ç›‘ç£ä¿¡å·ï¼Œä¾‹å¦‚æ ‡ç­¾æˆ–å¤šæ¨¡æ€å¯¹é½ï¼Œæ¥å­¦ä¹ è¯­ä¹‰ä¸å˜çš„è¡¨å¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡çš„ä¸»è¦äº®ç‚¹åœ¨äºæå‡ºäº†è§†è§‰è¯­è¨€å‡è®¾ï¼Œå¹¶ä»æ‹“æ‰‘ç»“æ„è§’åº¦åˆ†æäº†è§†è§‰è¡¨å¾å­¦ä¹ ã€‚è™½ç„¶æ²¡æœ‰æä¾›å…·ä½“çš„å®éªŒç»“æœï¼Œä½†è¯¥ç†è®ºæ¡†æ¶ä¸ºç†è§£ç°æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è¡Œä¸ºæä¾›äº†ä¸€ç§æ–°çš„è§†è§’ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†æŒ‡å¯¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§è§†è§‰ç†è§£ä»»åŠ¡ï¼Œä¾‹å¦‚å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ã€‚é€šè¿‡æ›´å¥½åœ°ç†è§£è§†è§‰è¡¨å¾çš„å†…åœ¨ç»“æ„ï¼Œå¯ä»¥è®¾è®¡å‡ºæ›´é²æ£’ã€æ›´é«˜æ•ˆçš„è§†è§‰æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ä¿ƒè¿›è·¨æ¨¡æ€å­¦ä¹ å’Œæœºå™¨äººè§†è§‰ç­‰é¢†åŸŸçš„å‘å±•ï¼Œä¸ºå®ç°æ›´æ™ºèƒ½çš„è§†è§‰ç³»ç»Ÿå¥ å®šåŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We study visual representation learning from a structural and topological perspective. We begin from a single hypothesis: that visual understanding presupposes a semantic language for vision, in which many perceptual observations correspond to a small number of discrete semantic states. Together with widely assumed premises on transferability and abstraction in representation learning, this hypothesis implies that the visual observation space must be organized in a fiber bundle like structure, where nuisance variation populates fibers and semantics correspond to a quotient base space. From this structure we derive two theoretical consequences. First, the semantic quotient $X/G$ is not a submanifold of $X$ and cannot be obtained through smooth deformation alone, semantic invariance requires a non-homeomorphic, discriminative target, for example, supervision via labels, cross instance identification, or multimodal alignment that supplies explicit semantic equivalence. Second, we show that approximating the quotient also places structural demands on the model architecture. Semantic abstraction requires not only an external semantic target, but a representation mechanism capable of supporting topology change: an expand-and-snap process in which the manifold is first geometrically expanded to separate structure and then collapsed to form discrete semantic regions. We emphasize that these results are interpretive rather than prescriptive: the framework provides a topological lens that aligns with empirical regularities observed in large-scale discriminative and multimodal models, and with classical principles in statistical learning theory.

