---
layout: default
title: "AVOID: The Adverse Visual Conditions Dataset with Obstacles for Driving Scene Understanding"
---

# AVOID: The Adverse Visual Conditions Dataset with Obstacles for Driving Scene Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.23215" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.23215v1</a>
  <a href="https://arxiv.org/pdf/2512.23215.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.23215v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.23215v1', 'AVOID: The Adverse Visual Conditions Dataset with Obstacles for Driving Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jongoh Jeong, Taek-Jin Song, Jong-Hwan Kim, Kuk-Jin Yoon

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**AVOIDï¼šç”¨äºé©¾é©¶åœºæ™¯ç†è§£çš„å«éšœç¢ç‰©æ¶åŠ£è§†è§‰æ¡ä»¶æ•°æ®é›†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `é“è·¯éšœç¢ç‰©æ£€æµ‹` `æ¶åŠ£è§†è§‰æ¡ä»¶` `æ•°æ®é›†` `æ¨¡æ‹Ÿç¯å¢ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é©¾é©¶æ•°æ®é›†ç¼ºä¹åœ¨æ¶åŠ£è§†è§‰æ¡ä»¶ä¸‹ï¼Œä¸å…¶å®ƒç±»åˆ«åŒåŸŸçš„é“è·¯éšœç¢ç‰©æ•°æ®ï¼Œé™åˆ¶äº†è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ç³»ç»Ÿçš„é²æ£’æ€§ã€‚
2. AVOIDæ•°æ®é›†æ—¨åœ¨æä¾›ä¸€ä¸ªåŒ…å«å„ç§æ¶åŠ£å¤©æ°”å’Œå…‰ç…§æ¡ä»¶ä¸‹çš„é“è·¯éšœç¢ç‰©å›¾åƒï¼Œä»¥åŠè¯­ä¹‰ã€æ·±åº¦ã€LiDARå’Œèˆªç‚¹ä¿¡æ¯çš„æ•°æ®é›†ã€‚
3. è®ºæ–‡åœ¨AVOIDæ•°æ®é›†ä¸Šå¯¹å®æ—¶éšœç¢ç‰©æ£€æµ‹ç½‘ç»œè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œå¹¶ä½¿ç”¨å¤šä»»åŠ¡ç½‘ç»œè¿›è¡Œäº†è¯­ä¹‰åˆ†å‰²ã€æ·±åº¦å’Œèˆªç‚¹é¢„æµ‹çš„æ¶ˆèç ”ç©¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†æ™ºèƒ½è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼Œç†è§£é“è·¯åœºæ™¯è‡³å…³é‡è¦ã€‚å°¤å…¶æ˜¯åœ¨å„ç§æ¶åŠ£æ¡ä»¶ï¼ˆå¦‚å¤©æ°”å’Œæ—¥å…‰ï¼‰ä¸‹ï¼Œå¯é åœ°å®æ—¶æ£€æµ‹åˆ°æ„å¤–çš„å°å‹é“è·¯éšœç¢ç‰©æ˜¯ç†æƒ³çš„ã€‚ç„¶è€Œï¼Œç°æœ‰çš„é“è·¯é©¾é©¶æ•°æ®é›†é€šå¸¸åªæä¾›åœ¨æ­£å¸¸æˆ–æ¶åŠ£åœºæ™¯ä¸‹è·å–çš„å¤§è§„æ¨¡å›¾åƒï¼Œå¹¶ä¸”é€šå¸¸ä¸åŒ…å«ä¸å…¶ä»–ç±»åˆ«åœ¨åŒä¸€è§†è§‰åŸŸä¸­æ•è·çš„é“è·¯éšœç¢ç‰©ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåä¸ºAVOIDçš„æ–°æ•°æ®é›†ï¼Œå³æ¶åŠ£è§†è§‰æ¡ä»¶æ•°æ®é›†ï¼Œç”¨äºåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­æ”¶é›†çš„å®æ—¶éšœç¢ç‰©æ£€æµ‹ã€‚AVOIDåŒ…å«å¤§é‡ä½äºæ¯æ¡è·¯å¾„ä¸Šçš„æ„å¤–é“è·¯éšœç¢ç‰©ï¼Œè¿™äº›éšœç¢ç‰©æ˜¯åœ¨å„ç§å¤©æ°”å’Œæ—¶é—´æ¡ä»¶ä¸‹æ•è·çš„ã€‚æ¯å¼ å›¾åƒéƒ½é…æœ‰ç›¸åº”çš„è¯­ä¹‰å›¾å’Œæ·±åº¦å›¾ã€åŸå§‹å’Œè¯­ä¹‰LiDARæ•°æ®ä»¥åŠèˆªç‚¹ï¼Œä»è€Œæ”¯æŒå¤§å¤šæ•°è§†è§‰æ„ŸçŸ¥ä»»åŠ¡ã€‚æˆ‘ä»¬å¯¹ç”¨äºéšœç¢ç‰©æ£€æµ‹ä»»åŠ¡çš„é«˜æ€§èƒ½å®æ—¶ç½‘ç»œè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œå¹¶æå‡ºå¹¶ä½¿ç”¨ç»¼åˆå¤šä»»åŠ¡ç½‘ç»œè¿›è¡Œè¯­ä¹‰åˆ†å‰²ã€æ·±åº¦å’Œèˆªç‚¹é¢„æµ‹ä»»åŠ¡çš„æ¶ˆèç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸‹ï¼Œåœ¨æ¶åŠ£è§†è§‰æ¡ä»¶ä¸‹å®æ—¶æ£€æµ‹é“è·¯éšœç¢ç‰©çš„é—®é¢˜ã€‚ç°æœ‰çš„é“è·¯é©¾é©¶æ•°æ®é›†è¦ä¹ˆåªåŒ…å«æ­£å¸¸åœºæ™¯ï¼Œè¦ä¹ˆåªåŒ…å«æ¶åŠ£åœºæ™¯ï¼Œå¹¶ä¸”é€šå¸¸ç¼ºä¹ä¸å…¶å®ƒç±»åˆ«åœ¨åŒä¸€è§†è§‰åŸŸä¸­æ•è·çš„é“è·¯éšœç¢ç‰©æ•°æ®ã€‚è¿™ä½¿å¾—è®­ç»ƒå‡ºçš„æ¨¡å‹åœ¨å®é™…å¤æ‚ç¯å¢ƒä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œéš¾ä»¥å¯é åœ°æ£€æµ‹å‡ºé“è·¯ä¸Šçš„æ½œåœ¨å±é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåŒ…å«å„ç§æ¶åŠ£è§†è§‰æ¡ä»¶ï¼ˆå¤©æ°”ã€å…‰ç…§ï¼‰ä¸‹çš„é“è·¯éšœç¢ç‰©æ•°æ®é›†ï¼Œå¹¶æä¾›ä¸°å¯Œçš„æ ‡æ³¨ä¿¡æ¯ï¼ˆè¯­ä¹‰ã€æ·±åº¦ã€LiDARã€èˆªç‚¹ï¼‰ï¼Œä»è€Œä¸ºè®­ç»ƒæ›´é²æ£’çš„è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥æ¨¡å‹æä¾›æ•°æ®åŸºç¡€ã€‚é€šè¿‡åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­ç”Ÿæˆæ•°æ®ï¼Œå¯ä»¥æ–¹ä¾¿åœ°æ§åˆ¶å„ç§æ¡ä»¶ï¼Œå¹¶è·å–ç²¾ç¡®çš„æ ‡æ³¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAVOIDæ•°æ®é›†çš„æ„å»ºæµç¨‹ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è®¾ç½®ä¸åŒçš„å¤©æ°”å’Œå…‰ç…§æ¡ä»¶ï¼›ç„¶åï¼Œåœ¨é“è·¯ä¸Šéšæœºæ”¾ç½®å„ç§éšœç¢ç‰©ï¼›æ¥ç€ï¼Œä½¿ç”¨è™šæ‹Ÿç›¸æœºå’Œä¼ æ„Ÿå™¨ï¼ˆLiDARï¼‰é‡‡é›†å›¾åƒã€æ·±åº¦å›¾ã€è¯­ä¹‰å›¾å’Œç‚¹äº‘æ•°æ®ï¼›æœ€åï¼Œå¯¹é‡‡é›†åˆ°çš„æ•°æ®è¿›è¡Œæ ‡æ³¨ï¼ŒåŒ…æ‹¬éšœç¢ç‰©çš„ç±»åˆ«ã€ä½ç½®ã€æ·±åº¦ç­‰ä¿¡æ¯ã€‚æ•°æ®é›†è¿˜æä¾›äº†èˆªç‚¹ä¿¡æ¯ï¼Œç”¨äºæ”¯æŒè·¯å¾„è§„åˆ’ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªä¸“é—¨é’ˆå¯¹æ¶åŠ£è§†è§‰æ¡ä»¶ä¸‹çš„é“è·¯éšœç¢ç‰©æ£€æµ‹çš„æ•°æ®é›†ã€‚ä¸ç°æœ‰æ•°æ®é›†ç›¸æ¯”ï¼ŒAVOIDæ•°æ®é›†æ›´åŠ å…³æ³¨æ¶åŠ£å¤©æ°”å’Œå…‰ç…§æ¡ä»¶ä¸‹çš„éšœç¢ç‰©æ£€æµ‹ï¼Œå¹¶ä¸”æä¾›äº†ä¸°å¯Œçš„æ ‡æ³¨ä¿¡æ¯ï¼Œå¯ä»¥æ”¯æŒå¤šç§è§†è§‰æ„ŸçŸ¥ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œæ•°æ®é›†æ˜¯åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­ç”Ÿæˆçš„ï¼Œå¯ä»¥æ–¹ä¾¿åœ°æ‰©å±•å’Œä¿®æ”¹ï¼Œä»¥æ»¡è¶³ä¸åŒçš„ç ”ç©¶éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šAVOIDæ•°æ®é›†åŒ…å«å¤šç§å¤©æ°”æ¡ä»¶ï¼ˆæ™´å¤©ã€é›¨å¤©ã€é›¾å¤©ã€é›ªå¤©ï¼‰å’Œæ—¶é—´æ¡ä»¶ï¼ˆç™½å¤©ã€å¤œæ™šã€é»„æ˜ï¼‰ã€‚éšœç¢ç‰©çš„ç§ç±»åŒ…æ‹¬è¡Œäººã€è½¦è¾†ã€äº¤é€šé”¥ã€åƒåœ¾æ¡¶ç­‰ã€‚æ•°æ®é›†çš„å›¾åƒåˆ†è¾¨ç‡ä¸º1920x1080ã€‚è®ºæ–‡è¿˜ä½¿ç”¨äº†å¸¸è§çš„å®æ—¶ç›®æ ‡æ£€æµ‹ç½‘ç»œï¼ˆå…·ä½“ç½‘ç»œåç§°æœªçŸ¥ï¼‰ä½œä¸ºåŸºçº¿æ¨¡å‹ï¼Œå¹¶åœ¨æ•°æ®é›†ä¸Šè¿›è¡Œäº†æ€§èƒ½è¯„ä¼°ã€‚å¤šä»»åŠ¡ç½‘ç»œç”¨äºè¯­ä¹‰åˆ†å‰²ã€æ·±åº¦é¢„æµ‹å’Œèˆªç‚¹é¢„æµ‹ï¼ŒæŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„çš„å…·ä½“ç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡åœ¨AVOIDæ•°æ®é›†ä¸Šå¯¹é«˜æ€§èƒ½å®æ—¶ç½‘ç»œè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œç»“æœè¡¨æ˜ï¼Œç°æœ‰æ¨¡å‹åœ¨æ¶åŠ£è§†è§‰æ¡ä»¶ä¸‹çš„éšœç¢ç‰©æ£€æµ‹æ€§èƒ½ä»ç„¶æœ‰å¾…æé«˜ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ä½¿ç”¨å¤šä»»åŠ¡ç½‘ç»œè¿›è¡Œäº†è¯­ä¹‰åˆ†å‰²ã€æ·±åº¦å’Œèˆªç‚¹é¢„æµ‹çš„æ¶ˆèç ”ç©¶ï¼Œç»“æœè¡¨æ˜ï¼Œå¤šä»»åŠ¡å­¦ä¹ å¯ä»¥æé«˜æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦æœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AVOIDæ•°æ®é›†å¯ç”¨äºè®­ç»ƒå’Œè¯„ä¼°è‡ªåŠ¨é©¾é©¶æ±½è½¦çš„æ„ŸçŸ¥ç³»ç»Ÿï¼Œå°¤å…¶æ˜¯åœ¨æ¶åŠ£è§†è§‰æ¡ä»¶ä¸‹çš„éšœç¢ç‰©æ£€æµ‹èƒ½åŠ›ã€‚è¯¥æ•°æ®é›†å¯ä»¥ä¿ƒè¿›ç›¸å…³ç®—æ³•çš„å¼€å‘å’Œæ”¹è¿›ï¼Œæé«˜è‡ªåŠ¨é©¾é©¶æ±½è½¦åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ•°æ®é›†è¿˜å¯ä»¥åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€æ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Understanding road scenes for visual perception remains crucial for intelligent self-driving cars. In particular, it is desirable to detect unexpected small road hazards reliably in real-time, especially under varying adverse conditions (e.g., weather and daylight). However, existing road driving datasets provide large-scale images acquired in either normal or adverse scenarios only, and often do not contain the road obstacles captured in the same visual domain as for the other classes. To address this, we introduce a new dataset called AVOID, the Adverse Visual Conditions Dataset, for real-time obstacle detection collected in a simulated environment. AVOID consists of a large set of unexpected road obstacles located along each path captured under various weather and time conditions. Each image is coupled with the corresponding semantic and depth maps, raw and semantic LiDAR data, and waypoints, thereby supporting most visual perception tasks. We benchmark the results on high-performing real-time networks for the obstacle detection task, and also propose and conduct ablation studies using a comprehensive multi-task network for semantic segmentation, depth and waypoint prediction tasks.

