---
layout: default
title: Socratic-MCTS: Test-Time Visual Reasoning by Asking the Right Questions
---

# Socratic-MCTS: Test-Time Visual Reasoning by Asking the Right Questions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.08927" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.08927v1</a>
  <a href="https://arxiv.org/pdf/2506.08927.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.08927v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.08927v1', 'Socratic-MCTS: Test-Time Visual Reasoning by Asking the Right Questions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: David Acuna, Ximing Lu, Jaehun Jung, Hyunwoo Kim, Amlan Kar, Sanja Fidler, Yejin Choi

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-10

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSocratic-MCTSä»¥è§£å†³è§†è§‰æ¨ç†æ¨¡å‹çš„çŸ¥è¯†æŒ–æ˜é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰æ¨ç†` `è’™ç‰¹å¡æ´›æ ‘æœç´¢` `çŸ¥è¯†æŒ–æ˜` `é•¿é“¾æ¨ç†` `éæ¨ç†æ¨¡å‹` `ç®—æ³•ä¼˜åŒ–` `ä¿¡æ¯æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯å¯¹äºå·²ç»è®­ç»ƒçš„éæ¨ç†æ¨¡å‹ï¼Œç¼ºä¹æœ‰æ•ˆçš„çŸ¥è¯†æŒ–æ˜æœºåˆ¶ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºè’™ç‰¹å¡æ´›æ ‘æœç´¢çš„ç®—æ³•ï¼Œé€šè¿‡å°†å­é—®é¢˜-å­ç­”æ¡ˆå¯¹èå…¥æ¨¡å‹è¾“å‡ºï¼Œä¿ƒè¿›æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ã€‚
3. åœ¨MMM-PROåŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•æ•´ä½“æå‡äº†2%çš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨Liberal Artsé¢†åŸŸå–å¾—äº†9%çš„æ˜¾è‘—å¢ç›Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„ç ”ç©¶é›†ä¸­åœ¨é€šè¿‡è’¸é¦å’Œå¼ºåŒ–å­¦ä¹ èµ‹äºˆå…¶éšå¼çš„é•¿é“¾æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå¯¹äºå·²ç»è®­ç»ƒå¹¶éƒ¨ç½²çš„éæ¨ç†æ¨¡å‹ï¼Œæˆ‘ä»¬æ˜¯å¦åº”è¯¥æ”¾å¼ƒå®ƒä»¬ï¼Ÿæœ¬æ–‡æ¢è®¨äº†ä¸€ç§å¯èƒ½æ€§ï¼Œä½¿ç”¨å—è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰å¯å‘çš„ç®—æ³•ï¼Œé€šè¿‡å°†å­é—®é¢˜-å­ç­”æ¡ˆå¯¹æ³¨å…¥æ¨¡å‹è¾“å‡ºæµï¼Œå¸®åŠ©æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­â€œè¿æ¥ç¢ç‰‡çŸ¥è¯†â€ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªåŸºå‡†ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œè§‚å¯Ÿåˆ°ä¸€è‡´çš„æ”¹è¿›ï¼Œç‰¹åˆ«æ˜¯åœ¨Liberal Artsé¢†åŸŸå–å¾—äº†9%çš„æ˜¾è‘—æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•ä»å·²ç»è®­ç»ƒçš„éæ¨ç†è§†è§‰è¯­è¨€æ¨¡å‹ä¸­æŒ–æ˜éšå«çŸ¥è¯†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆåˆ©ç”¨è¿™äº›æ¨¡å‹çš„æ½œåŠ›ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ¨ç†è¿‡ç¨‹è§†ä¸ºä¸€ç§æœç´¢è¿‡ç¨‹ï¼Œé€šè¿‡å¼•å…¥å­é—®é¢˜-å­ç­”æ¡ˆå¯¹ï¼Œå¸®åŠ©æ¨¡å‹åœ¨æ¨ç†æ—¶è¿æ¥åˆ†æ•£çš„çŸ¥è¯†ï¼Œä»è€Œç”Ÿæˆæ›´é•¿çš„æ¨ç†é“¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªåŸºäºMCTSçš„æœç´¢æœºåˆ¶ï¼Œæ¨¡å‹åœ¨æ¨ç†æ—¶ç”Ÿæˆå­é—®é¢˜ï¼Œå¹¶é€šè¿‡è¿™äº›å­é—®é¢˜è¿›è¡Œå†³ç­–ï¼Œæœ€ç»ˆå½¢æˆå®Œæ•´çš„æ¨ç†è½¨è¿¹ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬é—®é¢˜ç”Ÿæˆã€ç­”æ¡ˆç”Ÿæˆå’Œæ¨ç†è·¯å¾„ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†æ¨ç†è§†ä¸ºæœç´¢è¿‡ç¨‹çš„æ¡†æ¶è®¾è®¡ï¼Œä½¿å¾—éæ¨ç†æ¨¡å‹èƒ½å¤Ÿåœ¨æ²¡æœ‰é¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹è¿›è¡Œæœ‰æ•ˆçš„çŸ¥è¯†æŒ–æ˜ï¼Œä¸ä¼ ç»Ÿçš„æ¨ç†æ¨¡å‹å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œç®—æ³•é€šè¿‡åŠ¨æ€è°ƒæ•´å­é—®é¢˜çš„ç”Ÿæˆç­–ç•¥æ¥ä¼˜åŒ–æ¨ç†è·¯å¾„ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šåˆ™è€ƒè™‘äº†æ¨ç†çš„è¿è´¯æ€§å’Œå®Œæ•´æ€§ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„ç­”æ¡ˆä¸é—®é¢˜çš„ç›¸å…³æ€§ã€‚æ•´ä½“ç½‘ç»œç»“æ„ä¿æŒäº†åŸæœ‰æ¨¡å‹çš„æ¶æ„ï¼Œä½†å¢åŠ äº†æœç´¢æœºåˆ¶çš„æ¨¡å—ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSocratic-MCTSæ–¹æ³•åœ¨MMM-PROåŸºå‡†æµ‹è¯•ä¸­æ•´ä½“æå‡äº†2%çš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨Liberal Artsé¢†åŸŸå–å¾—äº†9%çš„æ˜¾è‘—å¢ç›Šï¼Œè¡¨æ˜è¯¥æ–¹æ³•åœ¨çŸ¥è¯†æŒ–æ˜å’Œæ¨ç†èƒ½åŠ›æå‡æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æå‡éæ¨ç†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥åœ¨è¿™äº›é¢†åŸŸä¸­å®ç°æ›´é«˜æ•ˆçš„çŸ¥è¯†è·å–å’Œä¿¡æ¯å¤„ç†ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent research in vision-language models (VLMs) has centered around the possibility of equipping them with implicit long-form chain-of-thought reasoning -- akin to the success observed in language models -- via distillation and reinforcement learning. But what about the non-reasoning models already trained and deployed across the internet? Should we simply abandon them, or is there hope for a search mechanism that can elicit hidden knowledge and induce long reasoning traces -- without any additional training or supervision? In this paper, we explore this possibility using a Monte Carlo Tree Search (MCTS)-inspired algorithm, which injects subquestion-subanswer pairs into the model's output stream. We show that framing reasoning as a search process -- where subquestions act as latent decisions within a broader inference trajectory -- helps the model "connect the dots" between fragmented knowledge and produce extended reasoning traces in non-reasoning models. We evaluate our method across three benchmarks and observe consistent improvements. Notably, our approach yields a 2% overall improvement on MMMU-PRO, including a significant 9% gain in Liberal Arts.

