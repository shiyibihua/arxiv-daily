---
layout: default
title: FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization
---

# FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20841" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20841v1</a>
  <a href="https://arxiv.org/pdf/2506.20841.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20841v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20841v1', 'FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ha Min Son, Shahbaz Rezaei, Xin Liu

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFixCLRä»¥è§£å†³åŠç›‘ç£é¢†åŸŸæ³›åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `åŠç›‘ç£å­¦ä¹ ` `é¢†åŸŸæ³›åŒ–` `å¯¹æ¯”å­¦ä¹ ` `ä¼ªæ ‡ç­¾` `æ¨¡å‹æ³›åŒ–` `è‡ªç›‘ç£å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŠç›‘ç£é¢†åŸŸæ³›åŒ–æ–¹æ³•å› æ ‡ç­¾ç¨€ç¼ºè€Œè¡¨ç°ä¸ä½³ï¼Œæœªèƒ½æœ‰æ•ˆå­¦ä¹ è·¨é¢†åŸŸçš„ä¸å˜è¡¨ç¤ºã€‚
2. FixCLRé€šè¿‡å¼•å…¥ä¼ªæ ‡ç­¾çš„ç±»ä¿¡æ¯å’Œæ’æ–¥é¡¹ï¼Œæ˜ç¡®æ­£åˆ™åŒ–ä»¥å®ç°é¢†åŸŸä¸å˜æ€§ï¼Œæå‡æ¨¡å‹æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒFixCLRåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯ä¸å…¶ä»–åŠç›‘ç£æ–¹æ³•ç»“åˆæ—¶ï¼Œæ€§èƒ½æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŠç›‘ç£é¢†åŸŸæ³›åŒ–ï¼ˆSSDGï¼‰æ—¨åœ¨è§£å†³åœ¨æ ‡ç­¾ç¨€ç¼ºçš„æƒ…å†µä¸‹å¯¹åˆ†å¸ƒå¤–æ•°æ®è¿›è¡Œæ³›åŒ–çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å› æ ‡ç­¾ä¸è¶³è€Œè¡¨ç°ä¸ä½³ï¼Œé€šå¸¸ç»“åˆåŠç›‘ç£å­¦ä¹ ä¸å„ç§æ­£åˆ™åŒ–é¡¹ï¼Œä½†æœªèƒ½æ˜ç¡®æ­£åˆ™åŒ–ä»¥å­¦ä¹ è·¨æ‰€æœ‰é¢†åŸŸçš„ä¸å˜è¡¨ç¤ºã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºFixCLRï¼Œå€Ÿé‰´è‡ªç›‘ç£å­¦ä¹ çš„æˆåŠŸï¼Œè°ƒæ•´äº†ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šåˆ©ç”¨ä¼ªæ ‡ç­¾çš„ç±»ä¿¡æ¯å’Œä»…ä½¿ç”¨æ’æ–¥é¡¹ã€‚FixCLRå¯ä¸ç°æœ‰çš„SSDGå’ŒåŠç›‘ç£æ–¹æ³•ç»“åˆï¼Œä»¥å®ç°äº’è¡¥çš„æ€§èƒ½æå‡ã€‚æˆ‘ä»¬çš„ç ”ç©¶åŒ…æ‹¬äº†åœ¨SSDGç ”ç©¶ä¸­æœªæ›¾æ¢ç´¢çš„å¹¿æ³›å®éªŒï¼Œè¯„ä¼°äº†é¢„è®­ç»ƒä¸éé¢„è®­ç»ƒæ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶åœ¨å¤šä¸ªé¢†åŸŸçš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ã€‚æ€»ä½“è€Œè¨€ï¼ŒFixCLRè¢«è¯æ˜æ˜¯ä¸€ç§æœ‰æ•ˆçš„SSDGæ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨ä¸å…¶ä»–åŠç›‘ç£æ–¹æ³•ç»“åˆæ—¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŠç›‘ç£é¢†åŸŸæ³›åŒ–ä¸­çš„æ ‡ç­¾ç¨€ç¼ºé—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆå­¦ä¹ è·¨é¢†åŸŸçš„ä¸å˜è¡¨ç¤ºï¼Œå¯¼è‡´æ³›åŒ–æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFixCLRé€šè¿‡å¼•å…¥ä¼ªæ ‡ç­¾çš„ç±»ä¿¡æ¯å’Œä»…ä½¿ç”¨æ’æ–¥é¡¹ï¼Œæ˜ç¡®æ­£åˆ™åŒ–ä»¥å®ç°é¢†åŸŸä¸å˜æ€§ï¼Œä»è€Œæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFixCLRçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ä¼ªæ ‡ç­¾ç”Ÿæˆã€å¯¹æ¯”å­¦ä¹ æ¨¡å—å’ŒæŸå¤±è®¡ç®—é˜¶æ®µï¼Œç¡®ä¿æ¨¡å‹åœ¨å¤šä¸ªé¢†åŸŸä¸Šå­¦ä¹ åˆ°ä¸å˜ç‰¹å¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šFixCLRçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å¯¹æ¯”å­¦ä¹ çš„è®¾è®¡ï¼Œåˆ©ç”¨ä¼ªæ ‡ç­¾ä¿¡æ¯å’Œæ’æ–¥é¡¹çš„ç»“åˆï¼Œæ˜¾è‘—åŒºåˆ«äºä¼ ç»Ÿçš„åŠç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°ä¸­ï¼ŒFixCLRé‡‡ç”¨äº†ç‰¹å®šçš„æ’æ–¥æŸå¤±ï¼Œç¡®ä¿æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸé—´çš„è¡¨ç¤ºä¸å‘ç”Ÿæ··æ·†ï¼ŒåŒæ—¶ä¼˜åŒ–ç½‘ç»œç»“æ„ä»¥é€‚åº”å¤šé¢†åŸŸæ•°æ®é›†çš„ç‰¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFixCLRåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æ€§èƒ½æå‡æ˜¾è‘—ï¼Œå°¤å…¶åœ¨é¢„è®­ç»ƒæ¨¡å‹çš„ä½¿ç”¨ä¸Šï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°10%ä»¥ä¸Šï¼ŒéªŒè¯äº†å…¶åœ¨åŠç›‘ç£é¢†åŸŸæ³›åŒ–ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FixCLRçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤„ç†ç¨€ç¼ºæ ‡ç­¾çš„åœºæ™¯ï¼Œå¦‚åŒ»ç–—å½±åƒåˆ†æã€è‡ªåŠ¨é©¾é©¶å’Œäººè„¸è¯†åˆ«ç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æé«˜ç³»ç»Ÿçš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Semi-supervised domain generalization (SSDG) aims to solve the problem of generalizing to out-of-distribution data when only a few labels are available. Due to label scarcity, applying domain generalization methods often underperform. Consequently, existing SSDG methods combine semi-supervised learning methods with various regularization terms. However, these methods do not explicitly regularize to learn domains invariant representations across all domains, which is a key goal for domain generalization. To address this, we introduce FixCLR. Inspired by success in self-supervised learning, we change two crucial components to adapt contrastive learning for explicit domain invariance regularization: utilization of class information from pseudo-labels and using only a repelling term. FixCLR can also be added on top of most existing SSDG and semi-supervised methods for complementary performance improvements. Our research includes extensive experiments that have not been previously explored in SSDG studies. These experiments include benchmarking different improvements to semi-supervised methods, evaluating the performance of pretrained versus non-pretrained models, and testing on datasets with many domains. Overall, FixCLR proves to be an effective SSDG method, especially when combined with other semi-supervised methods.

