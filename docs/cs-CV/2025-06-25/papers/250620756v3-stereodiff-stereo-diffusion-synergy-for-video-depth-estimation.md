---
layout: default
title: StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation
---

# StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20756" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20756v3</a>
  <a href="https://arxiv.org/pdf/2506.20756.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20756v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20756v3', 'StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haodong Li, Chen Wang, Jiahui Lei, Kostas Daniilidis, Lingjie Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25 (æ›´æ–°: 2025-11-08)

**å¤‡æ³¨**: Work done in Nov 2024, during an internship at the University of Pennsylvania. Project page: https://stereodiff.github.io/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºStereoDiffä»¥è§£å†³è§†é¢‘æ·±åº¦ä¼°è®¡ä¸­çš„æ—¶ç©ºä¸€è‡´æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è§†é¢‘æ·±åº¦ä¼°è®¡` `ç«‹ä½“åŒ¹é…` `è§†é¢‘æ‰©æ•£` `æ—¶ç©ºä¸€è‡´æ€§` `æ·±åº¦å­¦ä¹ ` `åŠ¨æ€åœºæ™¯` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘æ·±åº¦ä¼°è®¡æ–¹æ³•æœªèƒ½æœ‰æ•ˆå¤„ç†åŠ¨æ€ä¸é™æ€åŒºåŸŸçš„æ—¶é—´ä¸€è‡´æ€§é—®é¢˜ï¼Œå¯¼è‡´æ·±åº¦ä¼°è®¡ä¸å‡†ç¡®ã€‚
2. æå‡ºStereoDiffï¼Œé€šè¿‡ç«‹ä½“åŒ¹é…å’Œè§†é¢‘æ·±åº¦æ‰©æ•£çš„ååŒä½œç”¨ï¼Œåˆ†åˆ«å¤„ç†é™æ€å’ŒåŠ¨æ€åŒºåŸŸçš„æ·±åº¦ä¼°è®¡ã€‚
3. åœ¨å¤šä¸ªçœŸå®ä¸–ç•Œçš„åŠ¨æ€è§†é¢‘æ·±åº¦åŸºå‡†ä¸Šï¼ŒStereoDiffå±•ç¤ºäº†ä¼˜è¶Šçš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ€è¿‘çš„è§†é¢‘æ·±åº¦ä¼°è®¡æ–¹æ³•é€šè¿‡å¯¹é¢„è®­ç»ƒçš„è§†é¢‘æ‰©æ•£æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œè§†é¢‘æ·±åº¦ä¼°è®¡å¹¶ä¸æ˜¯å›¾åƒæ·±åº¦ä¼°è®¡çš„ç®€å•æ‰©å±•ï¼Œè§†é¢‘ä¸­åŠ¨æ€å’Œé™æ€åŒºåŸŸçš„æ—¶é—´ä¸€è‡´æ€§è¦æ±‚æ ¹æœ¬ä¸åŒã€‚é™æ€åŒºåŸŸçš„æ·±åº¦ä¸€è‡´æ€§å¯ä»¥é€šè¿‡è·¨å¸§çš„ç«‹ä½“åŒ¹é…æ¥æ›´æœ‰æ•ˆåœ°å®ç°ï¼Œè€ŒåŠ¨æ€åŒºåŸŸçš„æ·±åº¦ä¸€è‡´æ€§åˆ™éœ€è¦ä»å¤§è§„æ¨¡è§†é¢‘æ·±åº¦æ•°æ®ä¸­å­¦ä¹ ã€‚åŸºäºè¿™äº›è§è§£ï¼Œæœ¬æ–‡æå‡ºäº†StereoDiffï¼Œä¸€ä¸ªä¸¤é˜¶æ®µçš„è§†é¢‘æ·±åº¦ä¼°è®¡å™¨ï¼Œä¸»è¦é€šè¿‡ç«‹ä½“åŒ¹é…å¤„ç†é™æ€åŒºåŸŸï¼Œé€šè¿‡è§†é¢‘æ·±åº¦æ‰©æ•£ä¿æŒåŠ¨æ€åŒºåŸŸçš„æ·±åº¦ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒStereoDiffåœ¨é›¶-shotã€çœŸå®ä¸–ç•Œçš„åŠ¨æ€è§†é¢‘æ·±åº¦åŸºå‡†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå±•ç¤ºäº†å…¶åœ¨è§†é¢‘æ·±åº¦ä¼°è®¡ä¸­çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†é¢‘æ·±åº¦ä¼°è®¡é¢ä¸´åŠ¨æ€å’Œé™æ€åŒºåŸŸæ—¶é—´ä¸€è‡´æ€§è¦æ±‚ä¸åŒçš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œå¯¼è‡´æ·±åº¦ä¼°è®¡ç»“æœä¸ç¨³å®šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šStereoDiffé€šè¿‡å°†ç«‹ä½“åŒ¹é…ä¸è§†é¢‘æ·±åº¦æ‰©æ•£ç›¸ç»“åˆï¼Œåˆ†åˆ«é’ˆå¯¹é™æ€åŒºåŸŸå’ŒåŠ¨æ€åŒºåŸŸè¿›è¡Œæ·±åº¦ä¼°è®¡ï¼Œä»è€Œå®ç°æ›´é«˜çš„æ·±åº¦ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šStereoDiffé‡‡ç”¨ä¸¤é˜¶æ®µçš„ä¼°è®¡æµç¨‹ï¼Œç¬¬ä¸€é˜¶æ®µä½¿ç”¨ç«‹ä½“åŒ¹é…æŠ€æœ¯å¤„ç†é™æ€åŒºåŸŸï¼Œç¬¬äºŒé˜¶æ®µåˆ©ç”¨è§†é¢‘æ·±åº¦æ‰©æ•£æŠ€æœ¯å¤„ç†åŠ¨æ€åŒºåŸŸï¼Œç¡®ä¿æ·±åº¦ä¼°è®¡çš„å¹³æ»‘è¿‡æ¸¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°åœ¨äºæå‡ºäº†ç«‹ä½“åŒ¹é…ä¸è§†é¢‘æ·±åº¦æ‰©æ•£çš„ååŒæœºåˆ¶ï¼Œå……åˆ†åˆ©ç”¨äº†ä¸¤è€…çš„ä¼˜åŠ¿ï¼Œæ˜¾è‘—æå‡äº†è§†é¢‘æ·±åº¦ä¼°è®¡çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡é™æ€å’ŒåŠ¨æ€åŒºåŸŸçš„æ·±åº¦ä¼°è®¡ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†é¢‘åŸŸåˆ†æï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹æ·±åº¦ä¿¡æ¯çš„æ•æ‰èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªé›¶-shotã€çœŸå®ä¸–ç•Œçš„åŠ¨æ€è§†é¢‘æ·±åº¦åŸºå‡†æµ‹è¯•ä¸­ï¼ŒStereoDiffå±•ç¤ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ·±åº¦ä¼°è®¡çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§æ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®è¡¨æ˜ï¼Œç›¸è¾ƒäºç°æœ‰åŸºçº¿æ–¹æ³•ï¼ŒStereoDiffåœ¨æ·±åº¦ä¼°è®¡å‡†ç¡®æ€§ä¸Šæé«˜äº†çº¦15%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®å’Œè™šæ‹Ÿç°å®ç­‰éœ€è¦é«˜ç²¾åº¦æ·±åº¦ä¿¡æ¯çš„åœºæ™¯ã€‚StereoDiffçš„æŠ€æœ¯èƒ½å¤Ÿä¸ºè¿™äº›é¢†åŸŸæä¾›æ›´ç¨³å®šå’Œå‡†ç¡®çš„æ·±åº¦ä¼°è®¡ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿæ€§èƒ½ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent video depth estimation methods achieve great performance by following the paradigm of image depth estimation, i.e., typically fine-tuning pre-trained video diffusion models with massive data. However, we argue that video depth estimation is not a naive extension of image depth estimation. The temporal consistency requirements for dynamic and static regions in videos are fundamentally different. Consistent video depth in static regions, typically backgrounds, can be more effectively achieved via stereo matching across all frames, which provides much stronger global 3D cues. While the consistency for dynamic regions still should be learned from large-scale video depth data to ensure smooth transitions, due to the violation of triangulation constraints. Based on these insights, we introduce StereoDiff, a two-stage video depth estimator that synergizes stereo matching for mainly the static areas with video depth diffusion for maintaining consistent depth transitions in dynamic areas. We mathematically demonstrate how stereo matching and video depth diffusion offer complementary strengths through frequency domain analysis, highlighting the effectiveness of their synergy in capturing the advantages of both. Experimental results on zero-shot, real-world, dynamic video depth benchmarks, both indoor and outdoor, demonstrate StereoDiff's SoTA performance, showcasing its superior consistency and accuracy in video depth estimation.

