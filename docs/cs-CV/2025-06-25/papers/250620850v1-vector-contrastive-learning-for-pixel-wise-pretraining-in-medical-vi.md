---
layout: default
title: Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision
---

# Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20850" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20850v1</a>
  <a href="https://arxiv.org/pdf/2506.20850.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20850v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20850v1', 'Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuting He, Shuo Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25

**å¤‡æ³¨**: Accepted by ICCV 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå‘é‡å¯¹æ¯”å­¦ä¹ ä»¥è§£å†³åŒ»å­¦è§†è§‰ä¸­çš„åƒç´ çº§é¢„è®­ç»ƒé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹æ¯”å­¦ä¹ ` `åŒ»å­¦è§†è§‰` `è‡ªç›‘ç£å­¦ä¹ ` `åƒç´ çº§è¡¨ç¤º` `å‘é‡å›å½’` `ç‰¹å¾å»ºæ¨¡` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯¹æ¯”å­¦ä¹ æ–¹æ³•åœ¨åŒ»å­¦è§†è§‰ä¸­çš„åƒç´ çº§è¡¨ç¤ºæ‰©å±•ä¸Šå­˜åœ¨æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯ç‰¹å¾åˆ†æ•£å¯¼è‡´çš„ç±»å†…ç‰¹å¾ç›¸å…³æ€§ç ´åã€‚
2. æœ¬æ–‡æå‡ºçš„å‘é‡å¯¹æ¯”å­¦ä¹ é€šè¿‡å°†CLé‡æ–°å®šä¹‰ä¸ºå‘é‡å›å½’é—®é¢˜ï¼Œè§£å†³äº†åƒç´ çº§é¢„è®­ç»ƒä¸­çš„åˆ†æ•£é‡åŒ–é—®é¢˜ã€‚
3. åœ¨8ä¸ªä»»åŠ¡çš„å¹¿æ³›å®éªŒä¸­ï¼ŒCOVERæ¡†æ¶æ˜¾è‘—æå‡äº†åƒç´ çº§SSPçš„æ€§èƒ½ï¼Œæ¨åŠ¨äº†åŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹çš„è¿›æ­¥ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯¹æ¯”å­¦ä¹ ï¼ˆCLï¼‰å·²æˆä¸ºåŸºç¡€æ¨¡å‹è‡ªç›‘ç£é¢„è®­ç»ƒï¼ˆSSPï¼‰çš„åŸºçŸ³ï¼Œä½†å°†CLæ‰©å±•åˆ°åŒ»å­¦è§†è§‰ä¸­çš„åƒç´ çº§è¡¨ç¤ºä»ç„¶æ˜¯ä¸€ä¸ªæœªè§£å†³çš„é—®é¢˜ã€‚æ ‡å‡†çš„CLå°†SSPå…¬å¼åŒ–ä¸ºäºŒå…ƒä¼˜åŒ–é—®é¢˜ï¼ˆbinary CLï¼‰ï¼Œè¿‡åº¦è¿½æ±‚ç‰¹å¾åˆ†æ•£å¯¼è‡´è¿‡åº¦åˆ†æ•£é—®é¢˜ï¼Œç ´åäº†åƒç´ çº§ç‰¹å¾çš„ç›¸å…³æ€§ï¼Œä»è€Œæ‰°ä¹±äº†ç±»å†…åˆ†å¸ƒã€‚æœ¬æ–‡æå‡ºçš„å‘é‡CLå°†CLé‡æ–°å…¬å¼åŒ–ä¸ºå‘é‡å›å½’é—®é¢˜ï¼Œé€šè¿‡å»ºæ¨¡ç‰¹å¾è·ç¦»æ¥é‡åŒ–åƒç´ çº§é¢„è®­ç»ƒä¸­çš„åˆ†æ•£ã€‚ä¸ºå®ç°è¿™ä¸€æ–°èŒƒå¼ï¼Œæˆ‘ä»¬æå‡ºäº†COVERæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å»ºç«‹äº†å¯æ‰©å±•çš„åŸºäºå‘é‡çš„è‡ªå­¦ä¹ ï¼Œå¼ºåˆ¶ä»å‘é‡å›å½’åˆ°è·ç¦»å»ºæ¨¡çš„ä¸€è‡´ä¼˜åŒ–æµç¨‹ï¼Œå¹¶åˆ©ç”¨å‘é‡é‡‘å­—å¡”æ¶æ„è¿›è¡Œç²’åº¦é€‚åº”ï¼Œä»è€Œåœ¨SSPä¸­ä¿æŒåƒç´ çº§ç‰¹å¾çš„ç›¸å…³æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCOVERæ˜¾è‘—æå‡äº†åƒç´ çº§SSPï¼Œæ¨åŠ¨äº†å¯æ³›åŒ–çš„åŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹çš„å‘å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å°†å¯¹æ¯”å­¦ä¹ æ‰©å±•åˆ°åŒ»å­¦è§†è§‰ä¸­çš„åƒç´ çº§è¡¨ç¤ºçš„é—®é¢˜ã€‚ç°æœ‰çš„æ ‡å‡†å¯¹æ¯”å­¦ä¹ æ–¹æ³•åœ¨è¿½æ±‚ç‰¹å¾åˆ†æ•£æ—¶ï¼Œå¯¼è‡´äº†è¿‡åº¦åˆ†æ•£é—®é¢˜ï¼Œç ´åäº†åƒç´ çº§ç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå½±å“äº†ç±»å†…åˆ†å¸ƒçš„ç¨³å®šæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„å‘é‡å¯¹æ¯”å­¦ä¹ é€šè¿‡å°†CLé‡æ–°å…¬å¼åŒ–ä¸ºå‘é‡å›å½’é—®é¢˜ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé‡åŒ–åƒç´ çº§é¢„è®­ç»ƒä¸­çš„ç‰¹å¾åˆ†æ•£ã€‚è¿™ç§è®¾è®¡ä½¿å¾—ç‰¹å¾è·ç¦»çš„å»ºæ¨¡æˆä¸ºå¯èƒ½ï¼Œä»è€Œä¿æŒäº†åƒç´ çº§ç‰¹å¾çš„ç›¸å…³æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCOVERæ¡†æ¶åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆæ˜¯å‘é‡å›å½’æ¨¡å—ï¼Œé€šè¿‡å›å½’ä½ç§»å‘é‡æ¥å»ºæ¨¡ç‰¹å¾è·ç¦»ï¼›å…¶æ¬¡æ˜¯è·ç¦»å»ºæ¨¡æ¨¡å—ï¼Œç¡®ä¿ä¼˜åŒ–æµç¨‹çš„ä¸€è‡´æ€§ï¼›æœ€åæ˜¯å‘é‡é‡‘å­—å¡”æ¶æ„ï¼Œç”¨äºé€‚åº”ä¸åŒç²’åº¦çš„ç‰¹å¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†å¯¹æ¯”å­¦ä¹ ä»äºŒå…ƒä¼˜åŒ–è½¬å˜ä¸ºå‘é‡å›å½’ï¼Œå…è®¸å¯¹åƒç´ çº§ç‰¹å¾çš„åˆ†æ•£è¿›è¡Œé‡åŒ–ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•ä¸­çš„è¿‡åº¦åˆ†æ•£é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨COVERæ¡†æ¶ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å‘é‡å›å½’è¿‡ç¨‹ï¼Œå¹¶è®¾è®¡äº†å‘é‡é‡‘å­—å¡”æ¶æ„ä»¥é€‚åº”ä¸åŒå±‚æ¬¡çš„ç‰¹å¾è¡¨ç¤ºï¼Œç¡®ä¿äº†åƒç´ çº§ç‰¹å¾çš„ç›¸å…³æ€§å¾—ä»¥ä¿æŒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨8ä¸ªä¸åŒä»»åŠ¡çš„å®éªŒä¸­ï¼ŒCOVERæ¡†æ¶æ˜¾è‘—æå‡äº†åƒç´ çº§è‡ªç›‘ç£é¢„è®­ç»ƒçš„æ€§èƒ½ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ï¼Œå±•ç¤ºäº†å…¶åœ¨åŒ»å­¦è§†è§‰é¢†åŸŸçš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨åŒ»å­¦å›¾åƒåˆ†æã€ç–¾ç—…è¯Šæ–­å’Œæ²»ç–—è§„åˆ’ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡åƒç´ çº§ç‰¹å¾çš„è¡¨ç¤ºèƒ½åŠ›ï¼ŒCOVERæ¡†æ¶èƒ½å¤Ÿä¸ºåŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹æä¾›æ›´å¼ºçš„æ”¯æŒï¼Œä»è€Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥å’Œä¸´åºŠåº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šå½±å“åŒ»å­¦å½±åƒå¤„ç†çš„æ ‡å‡†åŒ–æµç¨‹ï¼Œæé«˜è¯Šæ–­çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Contrastive learning (CL) has become a cornerstone of self-supervised pretraining (SSP) in foundation models, however, extending CL to pixel-wise representation, crucial for medical vision, remains an open problem. Standard CL formulates SSP as a binary optimization problem (binary CL) where the excessive pursuit of feature dispersion leads to an over-dispersion problem, breaking pixel-wise feature correlation thus disrupting the intra-class distribution. Our vector CL reformulates CL as a vector regression problem, enabling dispersion quantification in pixel-wise pretraining via modeling feature distances in regressing displacement vectors. To implement this novel paradigm, we propose the COntrast in VEctor Regression (COVER) framework. COVER establishes an extendable vector-based self-learning, enforces a consistent optimization flow from vector regression to distance modeling, and leverages a vector pyramid architecture for granularity adaptation, thus preserving pixel-wise feature correlations in SSP. Extensive experiments across 8 tasks, spanning 2 dimensions and 4 modalities, show that COVER significantly improves pixel-wise SSP, advancing generalizable medical visual foundation models.

