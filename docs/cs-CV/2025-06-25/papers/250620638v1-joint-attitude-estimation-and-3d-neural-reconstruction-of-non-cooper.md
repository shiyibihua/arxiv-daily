---
layout: default
title: Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects
---

# Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20638" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20638v1</a>
  <a href="https://arxiv.org/pdf/2506.20638.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20638v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20638v1', 'Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: ClÃ©ment Forray, Pauline Delporte, Nicolas Delaygue, Florence Genin, Dawa Derksen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25

**å¤‡æ³¨**: accepted for CVPR 2025 NFBCC workshop

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨NeRFå®ç°éåˆä½œç©ºé—´ç‰©ä½“çš„å§¿æ€ä¼°è®¡ä¸3Dé‡å»º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ç©ºé—´æ€åŠ¿æ„ŸçŸ¥` `3Dé‡å»º` `ç¥ç»è¾å°„åœº` `ç›¸æœºå§¿æ€ä¼°è®¡` `éåˆä½œç‰©ä½“`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†éåˆä½œç©ºé—´ç‰©ä½“æ—¶é¢ä¸´ç›¸æœºç‰¹æ€§å’Œç¯å¢ƒæ¡ä»¶çš„æŒ‘æˆ˜ï¼Œå¦‚å•è‰²å›¾åƒå’Œæœ‰é™è§†è§’ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡è”åˆä¼˜åŒ–ç›¸æœºå§¿æ€å’ŒNeRFæ¥å®ç°3Dé‡å»ºï¼Œé€å¸§è®­ç»ƒç­–ç•¥æ˜¾è‘—æå‡é‡å»ºç²¾åº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€å¸§è®­ç»ƒæ–¹æ³•åœ¨3Dé‡å»ºç²¾åº¦ä¸Šä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œä¼˜åŒ–ç›¸æœºå§¿æ€çš„ç­–ç•¥æœ‰æ•ˆå‡å°‘äº†å§¿æ€é—´çš„å·®å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è·å–ç¯ç»•åœ°çƒç‰©ä½“çš„å½“å‰çŠ¶æ€å’Œè¡Œä¸ºä¿¡æ¯å¯¹äºä¸»åŠ¨æ¸…é™¤ç©ºé—´åƒåœ¾ã€åœ¨è½¨ç»´æŠ¤å’Œå¼‚å¸¸æ£€æµ‹ç­‰åº”ç”¨è‡³å…³é‡è¦ã€‚3Dæ¨¡å‹åœ¨ç©ºé—´æ€åŠ¿æ„ŸçŸ¥ä¸­æä¾›äº†é‡è¦çš„ä¿¡æ¯æ¥æºã€‚æœ¬æ–‡åˆ©ç”¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å¯¹éåˆä½œç©ºé—´ç‰©ä½“è¿›è¡Œ3Dé‡å»ºï¼Œé¢å¯¹å•è‰²å›¾åƒã€æœªçŸ¥ç‰©ä½“æ–¹å‘ã€æœ‰é™è§†è§’å’Œç¼ºä¹æ¼«åå°„å…‰ç­‰æŒ‘æˆ˜ï¼Œé‡ç‚¹ä¼˜åŒ–ç›¸æœºå§¿æ€ä¸NeRFçš„è”åˆè®­ç»ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé€å¸§è®­ç»ƒèƒ½å¤Ÿå®ç°æœ€ç²¾ç¡®çš„3Dé‡å»ºï¼Œå¹¶é€šè¿‡ä¼˜åŒ–å‡åŒ€æ—‹è½¬æ¥ä¼°è®¡ç›¸æœºå§¿æ€ï¼Œä½¿ç”¨æ­£åˆ™åŒ–é˜²æ­¢ç›¸é‚»å§¿æ€è¿‡äºåˆ†æ•£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³éåˆä½œç©ºé—´ç‰©ä½“çš„3Dé‡å»ºé—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç‰¹æ®Šç›¸æœºç‰¹æ€§å’Œç¯å¢ƒæ¡ä»¶æ—¶è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´é‡å»ºç²¾åº¦ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è”åˆä¼˜åŒ–ç›¸æœºå§¿æ€ä¸NeRFæ¨¡å‹ï¼Œé€å¸§è®­ç»ƒç­–ç•¥èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•æ‰ç‰©ä½“çš„3Dç»“æ„ï¼Œå…‹æœä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬å›¾åƒé‡‡é›†ã€ç›¸æœºå§¿æ€ä¼°è®¡ã€NeRFæ¨¡å‹è®­ç»ƒå’Œ3Dé‡å»ºï¼Œä¸»è¦æ¨¡å—ä¸ºç›¸æœºå§¿æ€ä¼˜åŒ–å’ŒNeRFç½‘ç»œã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºå°†ç›¸æœºå§¿æ€ä¼˜åŒ–ä¸NeRFæ¨¡å‹è®­ç»ƒç›¸ç»“åˆï¼Œæ˜¾è‘—æé«˜äº†åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„é‡å»ºç²¾åº¦ï¼ŒåŒºåˆ«äºä»¥å¾€å•ç‹¬å¤„ç†çš„æ–¹å¼ã€‚

**å…³é”®è®¾è®¡**ï¼šé‡‡ç”¨å‡åŒ€æ—‹è½¬ä¼˜åŒ–ç›¸æœºå§¿æ€ï¼Œå¹¶å¼•å…¥æ­£åˆ™åŒ–æŠ€æœ¯ä»¥é™åˆ¶ç›¸é‚»å§¿æ€çš„å·®å¼‚ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹çš„ç¨³å®šæ€§å’Œé‡å»ºç»“æœçš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€å¸§è®­ç»ƒæ–¹æ³•åœ¨3Dé‡å»ºç²¾åº¦ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªæä¾›ï¼Œä½†æå‡å¹…åº¦æ˜æ˜¾ï¼ŒéªŒè¯äº†è”åˆä¼˜åŒ–ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨ç©ºé—´æ€åŠ¿æ„ŸçŸ¥ã€ç©ºé—´åƒåœ¾æ¸…é™¤å’Œåœ¨è½¨ç»´æŠ¤ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡ç²¾ç¡®çš„3Dé‡å»ºï¼Œèƒ½å¤Ÿæå‡å¯¹ç©ºé—´ç‰©ä½“çš„ç›‘æµ‹ä¸ç®¡ç†èƒ½åŠ›ï¼Œä¸ºæœªæ¥çš„ç©ºé—´æ¢ç´¢å’Œå®‰å…¨æä¾›æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Obtaining a better knowledge of the current state and behavior of objects orbiting Earth has proven to be essential for a range of applications such as active debris removal, in-orbit maintenance, or anomaly detection. 3D models represent a valuable source of information in the field of Space Situational Awareness (SSA). In this work, we leveraged Neural Radiance Fields (NeRF) to perform 3D reconstruction of non-cooperative space objects from simulated images. This scenario is challenging for NeRF models due to unusual camera characteristics and environmental conditions : mono-chromatic images, unknown object orientation, limited viewing angles, absence of diffuse lighting etc. In this work we focus primarly on the joint optimization of camera poses alongside the NeRF. Our experimental results show that the most accurate 3D reconstruction is achieved when training with successive images one-by-one. We estimate camera poses by optimizing an uniform rotation and use regularization to prevent successive poses from being too far apart.

