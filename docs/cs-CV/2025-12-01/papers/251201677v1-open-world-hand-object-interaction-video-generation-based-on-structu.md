---
layout: default
title: Open-world Hand-Object Interaction Video Generation Based on Structure and Contact-aware Representation
---

# Open-world Hand-Object Interaction Video Generation Based on Structure and Contact-aware Representation

**arXiv**: [2512.01677v1](https://arxiv.org/abs/2512.01677) | [PDF](https://arxiv.org/pdf/2512.01677.pdf)

**ä½œè€…**: Haodong Yan, Hang Yu, Zhide Zhong, Weilin Yuan, Xin Gong, Zehang Luo, Chengxi Heyu, Junfeng Li, Wenxuan Song, Shunbo Zhou, Haoang Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“æž„-æŽ¥è§¦æ„ŸçŸ¥è¡¨ç¤ºä»¥è§£å†³å¼€æ”¾ä¸–ç•Œæ‰‹ç‰©äº¤äº’è§†é¢‘ç”Ÿæˆä¸­ç‰©ç†çº¦æŸå»ºæ¨¡çš„éš¾é¢˜**

**å…³é”®è¯**: `æ‰‹ç‰©äº¤äº’è§†é¢‘ç”Ÿæˆ` `ç»“æž„-æŽ¥è§¦æ„ŸçŸ¥è¡¨ç¤º` `å¼€æ”¾ä¸–ç•Œæ³›åŒ–` `ç‰©ç†çº¦æŸå»ºæ¨¡` `è”åˆç”ŸæˆèŒƒå¼`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‰‹ç‰©äº¤äº’è§†é¢‘ç”Ÿæˆä¸­ï¼ŒçŽ°æœ‰2Dä¸Ž3Dè¡¨ç¤ºéš¾ä»¥å…¼é¡¾å¯æ‰©å±•æ€§å’Œäº¤äº’ä¿çœŸåº¦
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡æ— 3Dæ ‡æ³¨çš„ç»“æž„-æŽ¥è§¦æ„ŸçŸ¥è¡¨ç¤ºï¼Œæ•èŽ·æŽ¥è§¦ã€é®æŒ¡å’Œæ•´ä½“ç»“æž„ï¼Œå¹¶é‡‡ç”¨å…±äº«-ä¸“ä¸šåŒ–è”åˆç”ŸæˆèŒƒå¼
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žæ•°æ®é›†ä¸Šè¶…è¶Šå…ˆè¿›æ–¹æ³•ï¼Œç”Ÿæˆç‰©ç†çœŸå®žä¸”æ—¶åºè¿žè´¯çš„è§†é¢‘ï¼Œå¹¶å±•ç¤ºå¯¹å¼€æ”¾ä¸–ç•Œåœºæ™¯çš„å¼ºæ³›åŒ–èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generating realistic hand-object interactions (HOI) videos is a significant challenge due to the difficulty of modeling physical constraints (e.g., contact and occlusion between hands and manipulated objects). Current methods utilize HOI representation as an auxiliary generative objective to guide video synthesis. However, there is a dilemma between 2D and 3D representations that cannot simultaneously guarantee scalability and interaction fidelity. To address this limitation, we propose a structure and contact-aware representation that captures hand-object contact, hand-object occlusion, and holistic structure context without 3D annotations. This interaction-oriented and scalable supervision signal enables the model to learn fine-grained interaction physics and generalize to open-world scenarios. To fully exploit the proposed representation, we introduce a joint-generation paradigm with a share-and-specialization strategy that generates interaction-oriented representations and videos. Extensive experiments demonstrate that our method outperforms state-of-the-art methods on two real-world datasets in generating physics-realistic and temporally coherent HOI videos. Furthermore, our approach exhibits strong generalization to challenging open-world scenarios, highlighting the benefit of our scalable design. Our project page is https://hgzn258.github.io/SCAR/.

