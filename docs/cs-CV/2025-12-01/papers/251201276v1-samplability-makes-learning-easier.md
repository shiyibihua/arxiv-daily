---
layout: default
title: Samplability makes learning easier
---

# Samplability makes learning easier

**arXiv**: [2512.01276v1](https://arxiv.org/abs/2512.01276) | [PDF](https://arxiv.org/pdf/2512.01276.pdf)

**ä½œè€…**: Guy Blanc, Caleb Koch, Jane Lange, Carmen Strassle, Li-Yang Tan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ˜¾å¼è§„é¿é›†ä»¥è¯æ˜Žå¯é‡‡æ ·PACå­¦ä¹ æ˜¾è‘—å¢žå¼ºé«˜æ•ˆå­¦ä¹ èƒ½åŠ›**

**å…³é”®è¯**: `PACå­¦ä¹ ` `å¯é‡‡æ ·åˆ†å¸ƒ` `æ˜¾å¼è§„é¿é›†` `è®¡ç®—å¤æ‚åº¦` `æ ·æœ¬å¤æ‚åº¦` `åœ¨çº¿å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ ‡å‡†PACå­¦ä¹ è¦æ±‚æ‰€æœ‰åˆ†å¸ƒï¼ŒåŒ…æ‹¬éš¾é‡‡æ ·åˆ†å¸ƒï¼Œé™åˆ¶äº†é«˜æ•ˆå­¦ä¹ 
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥æ˜¾å¼è§„é¿é›†ä½œä¸ºå¤æ‚åº¦åŽŸè¯­ï¼ŒåŒºåˆ†æ ‡å‡†ä¸Žå¯é‡‡æ ·PACå­¦ä¹ 
3. å®žéªŒæˆ–æ•ˆæžœï¼šæž„å»ºæ¦‚å¿µç±»ï¼Œåœ¨å¯é‡‡æ ·PACä¸­å¤šé¡¹å¼æ ·æœ¬å¯å­¦ï¼Œæ ‡å‡†PACä¸­éœ€æŒ‡æ•°æ ·æœ¬

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The standard definition of PAC learning (Valiant 1984) requires learners to succeed under all distributions -- even ones that are intractable to sample from. This stands in contrast to samplable PAC learning (Blum, Furst, Kearns, and Lipton 1993), where learners only have to succeed under samplable distributions. We study this distinction and show that samplable PAC substantially expands the power of efficient learners.
>   We first construct a concept class that requires exponential sample complexity in standard PAC but is learnable with polynomial sample complexity in samplable PAC. We then lift this statistical separation to the computational setting and obtain a separation relative to a random oracle. Our proofs center around a new complexity primitive, explicit evasive sets, that we introduce and study. These are sets for which membership is easy to determine but are extremely hard to sample from.
>   Our results extend to the online setting to similarly show how its landscape changes when the adversary is assumed to be efficient instead of computationally unbounded.

