---
layout: default
title: Deep Unsupervised Anomaly Detection in Brain Imaging: Large-Scale Benchmarking and Bias Analysis
---

# Deep Unsupervised Anomaly Detection in Brain Imaging: Large-Scale Benchmarking and Bias Analysis

**arXiv**: [2512.01534v1](https://arxiv.org/abs/2512.01534) | [PDF](https://arxiv.org/pdf/2512.01534.pdf)

**ä½œè€…**: Alexander Frotscher, Christian F. Baumgartner, Thomas Wolfers

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤§è§„æ¨¡å¤šä¸­å¿ƒåŸºå‡†ä»¥è¯„ä¼°è„‘æˆåƒæ·±åº¦æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ï¼Œåˆ†æžç®—æ³•æ€§èƒ½ä¸Žåå·®ã€‚**

**å…³é”®è¯**: `è„‘æˆåƒå¼‚å¸¸æ£€æµ‹` `æ— ç›‘ç£å­¦ä¹ ` `å¤šä¸­å¿ƒåŸºå‡†` `ç®—æ³•åå·®åˆ†æž` `ç—…å˜åˆ†å‰²`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè„‘æˆåƒæ— ç›‘ç£å¼‚å¸¸æ£€æµ‹å› è¯„ä¼°ç¢Žç‰‡åŒ–ã€æ•°æ®é›†å¼‚è´¨å’ŒæŒ‡æ ‡ä¸ä¸€è‡´é˜»ç¢ä¸´åºŠè½¬åŒ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽé‡å»ºæ–¹æ³•ï¼ˆå¦‚æ‰©æ•£å¯å‘å¼ï¼‰åœ¨ç—…å˜åˆ†å‰²ä¸­è¡¨çŽ°æœ€ä½³ï¼Œç‰¹å¾æ–¹æ³•åœ¨åˆ†å¸ƒåç§»ä¸‹æ›´ç¨³å¥ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæµ‹è¯•æ˜¾ç¤ºDiceåˆ†æ•°0.03-0.65ï¼Œç®—æ³•å­˜åœ¨æ‰«æä»ªã€ç—…å˜å¤§å°å’Œäººå£ç»Ÿè®¡å­¦ç›¸å…³åå·®ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deep unsupervised anomaly detection in brain magnetic resonance imaging offers a promising route to identify pathological deviations without requiring lesion-specific annotations. Yet, fragmented evaluations, heterogeneous datasets, and inconsistent metrics have hindered progress toward clinical translation. Here, we present a large-scale, multi-center benchmark of deep unsupervised anomaly detection for brain imaging. The training cohort comprised 2,976 T1 and 2,972 T2-weighted scans from healthy individuals across six scanners, with ages ranging from 6 to 89 years. Validation used 92 scans to tune hyperparameters and estimate unbiased thresholds. Testing encompassed 2,221 T1w and 1,262 T2w scans spanning healthy datasets and diverse clinical cohorts. Across all algorithms, the Dice-based segmentation performance varied between 0.03 and 0.65, indicating substantial variability. To assess robustness, we systematically evaluated the impact of different scanners, lesion types and sizes, as well as demographics (age, sex). Reconstruction-based methods, particularly diffusion-inspired approaches, achieved the strongest lesion segmentation performance, while feature-based methods showed greater robustness under distributional shifts. However, systematic biases, such as scanner-related effects, were observed for the majority of algorithms, including that small and low-contrast lesions were missed more often, and that false positives varied with age and sex. Increasing healthy training data yields only modest gains, underscoring that current unsupervised anomaly detection frameworks are limited algorithmically rather than by data availability. Our benchmark establishes a transparent foundation for future research and highlights priorities for clinical translation, including image native pretraining, principled deviation measures, fairness-aware modeling, and robust domain adaptation.

