---
layout: default
title: Deep FlexQP: Accelerated Nonlinear Programming via Deep Unfolding
---

# Deep FlexQP: Accelerated Nonlinear Programming via Deep Unfolding

**arXiv**: [2512.01565v1](https://arxiv.org/abs/2512.01565) | [PDF](https://arxiv.org/pdf/2512.01565.pdf)

**ä½œè€…**: Alex Oshin, Rahul Vodeb Ghosh, Augustinos D. Saravanos, Evangelos A. Theodorou

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDeep FlexQPï¼Œé€šè¿‡æ·±åº¦å±•å¼€åŠ é€Ÿéžçº¿æ€§è§„åˆ’æ±‚è§£ï¼Œæå‡ä¼˜åŒ–å™¨æ€§èƒ½ä¸Žæ³›åŒ–èƒ½åŠ›ã€‚**

**å…³é”®è¯**: `æ·±åº¦å±•å¼€` `äºŒæ¬¡è§„åˆ’ä¼˜åŒ–` `éžçº¿æ€§è§„åˆ’åŠ é€Ÿ` `æ³›åŒ–æ€§èƒ½ä¿è¯` `æ•°æ®é©±åŠ¨ä¼˜åŒ–` `é¢„æµ‹å®‰å…¨æ»¤æ³¢å™¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»ŸäºŒæ¬¡è§„åˆ’ï¼ˆQPï¼‰ä¼˜åŒ–å™¨åœ¨çº¦æŸä¸å¯è¡Œæ—¶æ€§èƒ½å—é™ï¼Œä¸”éš¾ä»¥é«˜æ•ˆå¤„ç†é«˜ç»´é—®é¢˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽFlexQPï¼Œé€šè¿‡æ·±åº¦å±•å¼€å­¦ä¹ å‚æ•°åé¦ˆç­–ç•¥ï¼Œå®žçŽ°æ•°æ®é©±åŠ¨çš„åŠ é€Ÿä¸Žç»´åº¦æ— å…³çš„æ³›åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æŠ•èµ„ç»„åˆä¼˜åŒ–ã€åˆ†ç±»å’Œå›žå½’ç­‰åŸºå‡†æµ‹è¯•ä¸­ï¼Œä¼˜äºŽçŽ°æœ‰åŠ é€ŸQPæ–¹æ³•ï¼Œæä¾›PACè´å¶æ–¯æ³›åŒ–ä¿è¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We propose an always-feasible quadratic programming (QP) optimizer, FlexQP, which is based on an exact relaxation of the QP constraints. If the original constraints are feasible, then the optimizer finds the optimal solution to the original QP. On the other hand, if the constraints are infeasible, the optimizer identifies a solution that minimizes the constraint violation in a sparse manner. FlexQP scales favorably with respect to the problem dimension, is robust to both feasible and infeasible QPs with minimal assumptions on the problem data, and can be effectively warm-started. We subsequently apply deep unfolding to improve our optimizer through data-driven techniques, leading to an accelerated Deep FlexQP. By learning dimension-agnostic feedback policies for the parameters from a small number of training examples, Deep FlexQP generalizes to problems with larger dimensions and can optimize for many more iterations than it was initially trained for. Our approach outperforms two recently proposed state-of-the-art accelerated QP approaches on a suite of benchmark systems including portfolio optimization, classification, and regression problems. We provide guarantees on the expected performance of our deep QP optimizer through probably approximately correct (PAC) Bayes generalization bounds. These certificates are used to design an accelerated sequential quadratic programming solver that solves nonlinear optimal control and predictive safety filter problems faster than traditional approaches. Overall, our approach is very robust and greatly outperforms existing non-learning and learning-based optimizers in terms of both runtime and convergence to the optimal solution across multiple classes of NLPs.

