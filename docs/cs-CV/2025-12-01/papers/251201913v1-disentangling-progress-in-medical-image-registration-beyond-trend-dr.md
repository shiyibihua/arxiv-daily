---
layout: default
title: Disentangling Progress in Medical Image Registration: Beyond Trend-Driven Architectures towards Domain-Specific Strategies
---

# Disentangling Progress in Medical Image Registration: Beyond Trend-Driven Architectures towards Domain-Specific Strategies

**arXiv**: [2512.01913v1](https://arxiv.org/abs/2512.01913) | [PDF](https://arxiv.org/pdf/2512.01913.pdf)

**ä½œè€…**: Bailiang Jian, Jiazhen Pan, Rohit Jena, Morteza Ghahremani, Hongwei Bran Li, Daniel Rueckert, Christian Wachinger, Benedikt Wiestler

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡æ¨¡å—åŒ–æ¡†æž¶æ­ç¤ºåŒ»å­¦å›¾åƒé…å‡†ä¸­é¢†åŸŸç‰¹å®šè®¾è®¡ä¼˜äºŽé€šç”¨æž¶æž„è¶‹åŠ¿**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒé…å‡†` `æ¨¡å—åŒ–æ¡†æž¶` `é¢†åŸŸç‰¹å®šè®¾è®¡` `è¶‹åŠ¿é©±åŠ¨æž¶æž„` `å¯æ‰©å±•åŸºå‡†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŒ»å­¦å›¾åƒé…å‡†ä¸­é€šç”¨è®¡ç®—æ¨¡å—ä¸Žé¢†åŸŸç‰¹å®šè®¾è®¡çš„è´¡çŒ®ä¸æ˜Žç¡®ï¼Œéœ€æ˜Žç¡®æœªæ¥ç ”ç©¶æ–¹å‘
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ¨¡å—åŒ–æ¡†æž¶ç³»ç»Ÿåˆ†ç¦»ä½Žå±‚è¶‹åŠ¿é©±åŠ¨æ¨¡å—å’Œé«˜å±‚é…å‡†ç‰¹å®šè®¾è®¡çš„å½±å“
3. å®žéªŒæˆ–æ•ˆæžœï¼šé¢†åŸŸç‰¹å®šè®¾è®¡æ˜¾è‘—æå‡é…å‡†æ€§èƒ½ï¼Œå¹³å‡ç›¸å¯¹æ”¹è¿›çº¦3%ï¼Œä¼˜äºŽè¶‹åŠ¿é©±åŠ¨æ¨¡å—

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Medical image registration drives quantitative analysis across organs, modalities, and patient populations. Recent deep learning methods often combine low-level "trend-driven" computational blocks from computer vision, such as large-kernel CNNs, Transformers, and state-space models, with high-level registration-specific designs like motion pyramids, correlation layers, and iterative refinement. Yet, their relative contributions remain unclear and entangled. This raises a central question: should future advances in registration focus on importing generic architectural trends or on refining domain-specific design principles? Through a modular framework spanning brain, lung, cardiac, and abdominal registration, we systematically disentangle the influence of these two paradigms. Our evaluation reveals that low-level "trend-driven" computational blocks offer only marginal or inconsistent gains, while high-level registration-specific designs consistently deliver more accurate, smoother, and more robust deformations. These domain priors significantly elevate the performance of a standard U-Net baseline, far more than variants incorporating "trend-driven" blocks, achieving an average relative improvement of $\sim3\%$. All models and experiments are released within a transparent, modular benchmark that enables plug-and-play comparison for new architectures and registration tasks (https://github.com/BailiangJ/rethink-reg). This dynamic and extensible platform establishes a common ground for reproducible and fair evaluation, inviting the community to isolate genuine methodological contributions from domain priors. Our findings advocate a shift in research emphasis: from following architectural trends to embracing domain-specific design principles as the true drivers of progress in learning-based medical image registration.

