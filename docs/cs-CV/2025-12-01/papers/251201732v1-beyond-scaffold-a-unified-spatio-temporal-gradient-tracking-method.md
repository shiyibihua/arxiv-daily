---
layout: default
title: Beyond Scaffold: A Unified Spatio-Temporal Gradient Tracking Method
---

# Beyond Scaffold: A Unified Spatio-Temporal Gradient Tracking Method

**arXiv**: [2512.01732v1](https://arxiv.org/abs/2512.01732) | [PDF](https://arxiv.org/pdf/2512.01732.pdf)

**ä½œè€…**: Yan Huang, Jinming Xu, Jiming Chen, Karl Henrik Johansson

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€æ—¶ç©ºæ¢¯åº¦è·Ÿè¸ªç®—æ³•ST-GTï¼Œä»¥è§£å†³åˆ†å¸ƒå¼éšæœºä¼˜åŒ–ä¸­æ•°æ®å¼‚æž„å’Œå™ªå£°å¯¼è‡´çš„æ¨¡åž‹æ¼‚ç§»é—®é¢˜ã€‚**

**å…³é”®è¯**: `åˆ†å¸ƒå¼å­¦ä¹ ` `æ¢¯åº¦è·Ÿè¸ª` `æ•°æ®å¼‚æž„` `é€šä¿¡æ•ˆçŽ‡` `éšæœºä¼˜åŒ–` `æ—¶å˜å›¾`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåˆ†å¸ƒå¼å­¦ä¹ ä¸­å¤šè½®æœ¬åœ°æ›´æ–°å¯¼è‡´æ¨¡åž‹æ¼‚ç§»ï¼ŒæºäºŽæ•°æ®å¼‚æž„å’Œæœ¬åœ°æ¢¯åº¦å™ªå£°ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡é‚»å±…èŠ‚ç‚¹è·Ÿè¸ªå…¨å±€æ¢¯åº¦ç¼“è§£å¼‚æž„ï¼Œæœ¬åœ°æ¢¯åº¦å¹³å‡æŠ‘åˆ¶å™ªå£°ï¼Œæ”¯æŒæ—¶å˜å›¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç†è®ºè¯æ˜Žå¼ºå‡¸é—®é¢˜çº¿æ€§æ”¶æ•›ï¼Œéžå‡¸æ¬¡çº¿æ€§æ”¶æ•›ï¼Œé€šä¿¡å¤æ‚åº¦é¦–æ¬¡å®žçŽ°çº¿æ€§åŠ é€Ÿã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In distributed and federated learning algorithms, communication overhead is often reduced by performing multiple local updates between communication rounds. However, due to data heterogeneity across nodes and the local gradient noise within each node, this strategy can lead to the drift of local models away from the global optimum. To address this issue, we revisit the well-known federated learning method Scaffold (Karimireddy et al., 2020) under a gradient tracking perspective, and propose a unified spatio-temporal gradient tracking algorithm, termed ST-GT, for distributed stochastic optimization over time-varying graphs. ST-GT tracks the global gradient across neighboring nodes to mitigate data heterogeneity, while maintaining a running average of local gradients to substantially suppress noise, with slightly more storage overhead. Without assuming bounded data heterogeneity, we prove that ST-GT attains a linear convergence rate for strongly convex problems and a sublinear rate for nonconvex cases. Notably, ST-GT achieves the first linear speed-up in communication complexity with respect to the number of local updates per round $Ï„$ for the strongly-convex setting. Compared to traditional gradient tracking methods, ST-GT reduces the topology-dependent noise term from $Ïƒ^2$ to $Ïƒ^2/Ï„$, where $Ïƒ^2$ denotes the noise level, thereby improving communication efficiency.

