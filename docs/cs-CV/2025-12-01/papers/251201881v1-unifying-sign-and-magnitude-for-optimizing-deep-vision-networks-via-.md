---
layout: default
title: Unifying Sign and Magnitude for Optimizing Deep Vision Networks via ThermoLion
---

# Unifying Sign and Magnitude for Optimizing Deep Vision Networks via ThermoLion

**arXiv**: [2512.01881v1](https://arxiv.org/abs/2512.01881) | [PDF](https://arxiv.org/pdf/2512.01881.pdf)

**ä½œè€…**: Ahmed Nebli

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºThermoLionæ¡†æž¶ï¼Œé€šè¿‡åŠ¨æ€è°ƒåˆ¶æ›´æ–°æ¯”ç‰¹çŽ‡ä¼˜åŒ–æ·±åº¦è§†è§‰ç½‘ç»œè®­ç»ƒ**

**å…³é”®è¯**: `æ·±åº¦è§†è§‰ç½‘ç»œä¼˜åŒ–` `æ¢¯åº¦å™ªå£°å¤„ç†` `åŠ¨æ€æ¯”ç‰¹çŽ‡è°ƒåˆ¶` `ä¿¡å™ªæ¯”é—¨æŽ§` `åŠ¨é‡å¯¹é½æœºåˆ¶` `è¶…å‚æ•°è‡ªç”±è®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ä¼˜åŒ–æ–¹æ³•åœ¨æ¢¯åº¦å™ªå£°ä¸Žç²¾åº¦é—´é™æ€å¦¥åï¼Œå¯¼è‡´æ”¶æ•›æ•ˆçŽ‡ä½Ž
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå±€éƒ¨ä¿¡å™ªæ¯”é—¨æŽ§ï¼ŒåŠ¨æ€åˆ‡æ¢ä½Žæ¯”ç‰¹æŽ¢ç´¢ä¸Žé«˜ç²¾åº¦åˆ©ç”¨é˜¶æ®µ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨12ä¸ªè§†è§‰æ•°æ®é›†ä¸Šè¶…è¶ŠAdamWå’ŒLionï¼Œæ— éœ€è¶…å‚æ•°è°ƒä¼˜

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The training of deep vision models is fundamentally a signal recovery problem amidst high-dimensional stochastic noise. Current optimization paradigms impose a static compromise on information channel capacity. For instance, magnitude-based methods, such as AdamW, operate on the assumption that gradient norms are high-fidelity curvature signals. While this allows for precision in smooth regimes, it leads to catastrophic noise amplification when applied to rugged, non-convex landscapes. Conversely, sign-based methods (e.g., Lion) perform a radical 1-bit quantization of the gradient, which aims to provide robust regularization at the cost of discarding fine-grained descent information. We propose that optimal convergence requires neither static prior, but rather a dynamic modulation of the update bitrate. We introduce \textbf{ThermoLion}, a vision-centric framework that utilizes local Signal-to-Noise Ratio (SNR) gating to autonomously transition parameters between a "low-bit" exploration phase and a "high-precision" exploitation phase. Furthermore, we introduce a Momentum Alignment mechanism that detects constructive interference between historical drift and instantaneous gradients to accelerate convergence during stable trajectories. Empirical benchmarks across 12 diverse vision datasets (including CIFAR, SVHN, and GTSRB) demonstrate that ThermoLion serves as a hyperparameter-free generalist, surpassing both AdamW and Lion in convergence speed and terminal accuracy without architecture-specific tuning.

