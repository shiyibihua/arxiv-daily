---
layout: default
title: Revisiting Direct Encoding: Learnable Temporal Dynamics for Static Image Spiking Neural Networks
---

# Revisiting Direct Encoding: Learnable Temporal Dynamics for Static Image Spiking Neural Networks

**arXiv**: [2512.01687v1](https://arxiv.org/abs/2512.01687) | [PDF](https://arxiv.org/pdf/2512.01687.pdf)

**ä½œè€…**: Huaxu He

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯å­¦ä¹ æ—¶åºç¼–ç ä»¥è§£å†³é™æ€å›¾åƒè„‰å†²ç¥žç»ç½‘ç»œä¸­æ—¶åºå»ºæ¨¡ä¸è¶³çš„é—®é¢˜**

**å…³é”®è¯**: `è„‰å†²ç¥žç»ç½‘ç»œ` `é™æ€å›¾åƒå¤„ç†` `æ—¶åºç¼–ç ` `å¯å­¦ä¹ åŠ¨æ€` `æ›¿ä»£æ¢¯åº¦` `å·ç§¯ç½‘ç»œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé™æ€å›¾åƒç¼ºä¹å›ºæœ‰æ—¶åºåŠ¨æ€ï¼Œå¯¼è‡´ç›´æŽ¥è®­ç»ƒè„‰å†²ç¥žç»ç½‘ç»œæ—¶æ—¶åºç»´åº¦é€€åŒ–ï¼Œæ— æ³•æœ‰æ•ˆå»ºæ¨¡
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥æœ€å°å¯å­¦ä¹ æ—¶åºç¼–ç ï¼Œé€šè¿‡è‡ªé€‚åº”ç›¸ä½åç§»ä»Žé™æ€è¾“å…¥è¯±å¯¼æœ‰æ„ä¹‰çš„æ—¶åºå˜åŒ–
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¾„æ¸…ç›´æŽ¥ç¼–ç ä¸Žé€ŸçŽ‡ç¼–ç æ€§èƒ½å·®è·æºäºŽå·ç§¯å¯å­¦ä¹ æ€§å’Œæ›¿ä»£æ¢¯åº¦ï¼Œè€Œéžç¼–ç æ–¹æ¡ˆæœ¬èº«

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Handling static images that lack inherent temporal dynamics remains a fundamental challenge for spiking neural networks (SNNs). In directly trained SNNs, static inputs are typically repeated across time steps, causing the temporal dimension to collapse into a rate like representation and preventing meaningful temporal modeling. This work revisits the reported performance gap between direct and rate based encodings and shows that it primarily stems from convolutional learnability and surrogate gradient formulations rather than the encoding schemes themselves. To illustrate this mechanism level clarification, we introduce a minimal learnable temporal encoding that adds adaptive phase shifts to induce meaningful temporal variation from static inputs.

