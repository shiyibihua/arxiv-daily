---
layout: default
title: MEGConformer: Conformer-Based MEG Decoder for Robust Speech and Phoneme Classification
---

# MEGConformer: Conformer-Based MEG Decoder for Robust Speech and Phoneme Classification

**arXiv**: [2512.01443v1](https://arxiv.org/abs/2512.01443) | [PDF](https://arxiv.org/pdf/2512.01443.pdf)

**ä½œè€…**: Xabier de Zuazo, Ibon Saratxaga, Eva Navas

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽConformerçš„MEGè§£ç å™¨ï¼Œç”¨äºŽé²æ£’çš„è¯­éŸ³å’ŒéŸ³ç´ åˆ†ç±»ä»»åŠ¡ã€‚**

**å…³é”®è¯**: `è„‘ç£å›¾è§£ç ` `Conformeræ¨¡åž‹` `è¯­éŸ³åˆ†ç±»` `éŸ³ç´ åˆ†ç±»` `æ•°æ®å¢žå¼º` `ä¿¡å·å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§£å†³è„‘ç£å›¾ä¿¡å·åœ¨è¯­éŸ³æ£€æµ‹å’ŒéŸ³ç´ åˆ†ç±»ä¸­çš„è§£ç æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ç´§å‡‘Conformerå¤„ç†åŽŸå§‹MEGä¿¡å·ï¼Œç»“åˆä»»åŠ¡ç‰¹å®šå¤´å’ŒMEGå¢žå¼ºæŠ€æœ¯ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å®˜æ–¹è¯„ä¼°ä¸­ï¼Œè¯­éŸ³æ£€æµ‹è¾¾88.9%ï¼ŒéŸ³ç´ åˆ†ç±»è¾¾65.8%ï¼Œè¶…è¶ŠåŸºçº¿å¹¶è¿›å…¥å‰åã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present Conformer-based decoders for the LibriBrain 2025 PNPL competition, targeting two foundational MEG tasks: Speech Detection and Phoneme Classification. Our approach adapts a compact Conformer to raw 306-channel MEG signals, with a lightweight convolutional projection layer and task-specific heads. For Speech Detection, a MEG-oriented SpecAugment provided a first exploration of MEG-specific augmentation. For Phoneme Classification, we used inverse-square-root class weighting and a dynamic grouping loader to handle 100-sample averaged examples. In addition, a simple instance-level normalization proved critical to mitigate distribution shifts on the holdout split. Using the official Standard track splits and F1-macro for model selection, our best systems achieved 88.9% (Speech) and 65.8% (Phoneme) on the leaderboard, surpassing the competition baselines and ranking within the top-10 in both tasks. For further implementation details, the technical documentation, source code, and checkpoints are available at https://github.com/neural2speech/libribrain-experiments.

