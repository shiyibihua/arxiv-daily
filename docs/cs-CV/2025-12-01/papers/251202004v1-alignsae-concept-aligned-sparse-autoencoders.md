---
layout: default
title: AlignSAE: Concept-Aligned Sparse Autoencoders
---

# AlignSAE: Concept-Aligned Sparse Autoencoders

**arXiv**: [2512.02004v1](https://arxiv.org/abs/2512.02004) | [PDF](https://arxiv.org/pdf/2512.02004.pdf)

**ä½œè€…**: Minglai Yang, Xinyu Guo, Mihai Surdeanu, Liangming Pan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAlignSAEæ–¹æ³•ï¼Œé€šè¿‡é¢„è®­ç»ƒåŽè®­ç»ƒè¯¾ç¨‹å¯¹é½ç¨€ç–è‡ªç¼–ç å™¨ç‰¹å¾ä¸Žæ¦‚å¿µï¼Œä»¥è§£å†³å¤§è¯­è¨€æ¨¡åž‹éšè—å‚æ•°ç©ºé—´éš¾ä»¥è§£é‡Šå’ŒæŽ§åˆ¶çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `ç¨€ç–è‡ªç¼–ç å™¨` `æ¦‚å¿µå¯¹é½` `å¤§è¯­è¨€æ¨¡åž‹` `å¯è§£é‡Šæ€§` `å› æžœå¹²é¢„`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç¨€ç–è‡ªç¼–ç å™¨ç‰¹å¾ä¸Žäººç±»å®šä¹‰æ¦‚å¿µå¯¹é½å›°éš¾ï¼Œå¯¼è‡´ç‰¹å¾çº ç¼ å’Œåˆ†å¸ƒè¡¨ç¤ºã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨é¢„è®­ç»ƒåŽè®­ç»ƒè¯¾ç¨‹ï¼Œå…ˆæ— ç›‘ç£è®­ç»ƒï¼ŒåŽç›‘ç£åŽè®­ç»ƒï¼Œå°†ç‰¹å®šæ¦‚å¿µç»‘å®šåˆ°ä¸“ç”¨æ½œåœ¨æ§½ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žçŽ°ç²¾ç¡®å› æžœå¹²é¢„ï¼Œå¦‚å¯é æ¦‚å¿µäº¤æ¢ï¼Œé€šè¿‡é’ˆå¯¹è¯­ä¹‰å¯¹é½çš„å•ä¸ªæ§½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Language Models (LLMs) encode factual knowledge within hidden parametric spaces that are difficult to inspect or control. While Sparse Autoencoders (SAEs) can decompose hidden activations into more fine-grained, interpretable features, they often struggle to reliably align these features with human-defined concepts, resulting in entangled and distributed feature representations. To address this, we introduce AlignSAE, a method that aligns SAE features with a defined ontology through a "pre-train, then post-train" curriculum. After an initial unsupervised training phase, we apply supervised post-training to bind specific concepts to dedicated latent slots while preserving the remaining capacity for general reconstruction. This separation creates an interpretable interface where specific relations can be inspected and controlled without interference from unrelated features. Empirical results demonstrate that AlignSAE enables precise causal interventions, such as reliable "concept swaps", by targeting single, semantically aligned slots.

