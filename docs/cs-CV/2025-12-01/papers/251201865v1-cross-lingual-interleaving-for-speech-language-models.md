---
layout: default
title: Cross-Lingual Interleaving for Speech Language Models
---

# Cross-Lingual Interleaving for Speech Language Models

**arXiv**: [2512.01865v1](https://arxiv.org/abs/2512.01865) | [PDF](https://arxiv.org/pdf/2512.01865.pdf)

**ä½œè€…**: Adel Moumen, Guangzhi Sun, Philip C. Woodland

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè·¨è¯­è¨€äº¤é”™æ–¹æ³•ä»¥æž„å»ºå¤šè¯­è¨€è¯­éŸ³è¯­è¨€æ¨¡åž‹ï¼Œè§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚**

**å…³é”®è¯**: `è¯­éŸ³è¯­è¨€æ¨¡åž‹` `è·¨è¯­è¨€å­¦ä¹ ` `æ— ç›‘ç£è®­ç»ƒ` `è¯­ä¹‰è¯„ä¼°` `å¤šè¯­è¨€å¯¹è¯`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè¯­éŸ³è¯­è¨€æ¨¡åž‹å‘å±•ä»¥è‹±è¯­ä¸ºä¸­å¿ƒï¼Œè·¨è¯­è¨€å­¦ä¹ å› æ•°æ®ç¨€ç¼ºè€Œå›°éš¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ— æ–‡æœ¬ç›‘ç£ä¸‹æ··åˆè·¨è¯­è¨€è¯­éŸ³æ ‡è®°ï¼Œå®žçŽ°è·¨è¯­è¨€äº¤é”™è®­ç»ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŒ¹é…è®­ç»ƒæ ‡è®°é¢„ç®—ä¸‹ï¼Œæå‡å•è¯­è¯­ä¹‰å‡†ç¡®æ€§ï¼Œå¢žå¼ºè·¨è¯­è¨€å»¶ç»­å’Œå¯¹é½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Spoken Language Models (SLMs) aim to learn linguistic competence directly from speech using discrete units, widening access to Natural Language Processing (NLP) technologies for languages with limited written resources. However, progress has been largely English-centric due to scarce spoken evaluation benchmarks and training data, making cross-lingual learning difficult. We present a cross-lingual interleaving method that mixes speech tokens across languages without textual supervision. We also release an EN-FR training dataset, TinyStories (~42k hours), together with EN-FR spoken StoryCloze and TopicCloze benchmarks for cross-lingual semantic evaluation, both synthetically generated using GPT-4. On 360M and 1B SLMs under matched training-token budgets, interleaving improves monolingual semantic accuracy, enables robust cross-lingual continuation, and strengthens cross-lingual hidden-state alignment. Taken together, these results indicate that cross-lingual interleaving is a simple, scalable route to building multilingual SLMs that understand and converse across languages. All resources will be made open-source to support reproducibility.

