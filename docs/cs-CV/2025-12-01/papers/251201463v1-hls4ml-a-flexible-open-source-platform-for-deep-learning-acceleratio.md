---
layout: default
title: hls4ml: A Flexible, Open-Source Platform for Deep Learning Acceleration on Reconfigurable Hardware
---

# hls4ml: A Flexible, Open-Source Platform for Deep Learning Acceleration on Reconfigurable Hardware

**arXiv**: [2512.01463v1](https://arxiv.org/abs/2512.01463) | [PDF](https://arxiv.org/pdf/2512.01463.pdf)

**ä½œè€…**: Jan-Frederik Schulte, Benjamin Ramhorst, Chang Sun, Jovan Mitrevski, NicolÃ² Ghielmetti, Enrico Lupi, Dimitrios Danopoulos, Vladimir Loncar, Javier Duarte, David Burnette, Lauri Laatu, Stylianos Tzelepis, Konstantinos Axiotis, Quentin Berthet, Haoyan Wang, Paul White, Suleyman Demirsoy, Marco Colombo, Thea Aarrestad, Sioni Summers, Maurizio Pierini, Giuseppe Di Guglielmo, Jennifer Ngadiuba, Javier Campos, Ben Hawks, Abhijith Gandrakota, Farah Fahim, Nhan Tran, George Constantinides, Zhiqiang Que, Wayne Luk, Alexander Tapper, Duc Hoang, Noah Paladino, Philip Harris, Bo-Cheng Lai, Manuel Valentin, Ryan Forelli, Seda Ogrenci, Lino Gerlach, Rian Flynn, Mia Liu, Daniel Diaz, Elham Khoda, Melissa Quinnan, Russell Solares, Santosh Parajuli, Mark Neubauer, Christian Herwig, Ho Fung Tsoi, Dylan Rankin, Shih-Chieh Hsu, Scott Hauck

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºhls4mlå¹³å°ï¼Œå°†æ·±åº¦å­¦ä¹ æ¨¡åž‹è½¬æ¢ä¸ºHLSä»£ç ä»¥åŠ é€ŸFPGA/ASICæŽ¨ç†**

**å…³é”®è¯**: `æ·±åº¦å­¦ä¹ åŠ é€Ÿ` `ç¡¬ä»¶åˆæˆ` `FPGAéƒ¨ç½²` `å¼€æºå¹³å°` `ä½Žå»¶è¿ŸæŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåœ¨ä½Žå»¶è¿Ÿã€ä½Žèµ„æºæ¶ˆè€—åœºæ™¯ä¸‹åŠ é€Ÿæ·±åº¦å­¦ä¹ æŽ¨ç†
2. æ–¹æ³•è¦ç‚¹ï¼šå¼€æºå¹³å°æ”¯æŒå¤šæ¡†æž¶æ¨¡åž‹è½¬æ¢ï¼Œç”Ÿæˆå¯é›†æˆåˆ°FPGA/ASICçš„HLSä»£ç 
3. å®žéªŒæˆ–æ•ˆæžœï¼šåº”ç”¨äºŽå•†ä¸šå’Œç§‘å­¦é¢†åŸŸï¼Œå®žçŽ°é«˜æ•ˆç¡¬ä»¶åŠ é€Ÿ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present hls4ml, a free and open-source platform that translates machine learning (ML) models from modern deep learning frameworks into high-level synthesis (HLS) code that can be integrated into full designs for field-programmable gate arrays (FPGAs) or application-specific integrated circuits (ASICs). With its flexible and modular design, hls4ml supports a large number of deep learning frameworks and can target HLS compilers from several vendors, including Vitis HLS, Intel oneAPI and Catapult HLS. Together with a wider eco-system for software-hardware co-design, hls4ml has enabled the acceleration of ML inference in a wide range of commercial and scientific applications where low latency, resource usage, and power consumption are critical. In this paper, we describe the structure and functionality of the hls4ml platform. The overarching design considerations for the generated HLS code are discussed, together with selected performance results.

