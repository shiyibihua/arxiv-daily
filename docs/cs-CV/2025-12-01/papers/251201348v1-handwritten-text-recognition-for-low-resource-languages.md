---
layout: default
title: Handwritten Text Recognition for Low Resource Languages
---

# Handwritten Text Recognition for Low Resource Languages

**arXiv**: [2512.01348v1](https://arxiv.org/abs/2512.01348) | [PDF](https://arxiv.org/pdf/2512.01348.pdf)

**ä½œè€…**: Sayantan Dey, Alireza Alaei, Partha Pratim Roy

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBharatOCRæ¨¡åž‹ï¼Œç”¨äºŽä½Žèµ„æºè¯­è¨€ï¼ˆå¦‚å°åœ°è¯­å’Œä¹Œå°”éƒ½è¯­ï¼‰çš„æ®µè½çº§æ‰‹å†™æ–‡æœ¬è¯†åˆ«ã€‚**

**å…³é”®è¯**: `æ‰‹å†™æ–‡æœ¬è¯†åˆ«` `ä½Žèµ„æºè¯­è¨€` `æ®µè½çº§OCR` `Vision Transformer` `Transformerè§£ç å™¨` `è¯­è¨€æ¨¡åž‹ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é’ˆå¯¹ä½Žèµ„æºè¯­è¨€æ®µè½çº§æ‰‹å†™æ–‡æœ¬è¯†åˆ«éš¾é¢˜ï¼Œç¼ºä¹å…¨é¢è¯­è¨€èµ„æºã€‚
2. é‡‡ç”¨ViT-Transformer Decoder-LMæž¶æž„ï¼Œç»“åˆè§†è§‰ç‰¹å¾æå–ã€åºåˆ—ç”Ÿæˆå’Œè¯­è¨€æ¨¡åž‹ä¼˜åŒ–ã€‚
3. åœ¨è‡ªå®šä¹‰å’Œå…¬å…±æ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œå®žçŽ°é«˜å­—ç¬¦è¯†åˆ«çŽ‡ï¼Œè¶…è¶ŠçŽ°æœ‰ä¹Œå°”éƒ½è¯­æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite considerable progress in handwritten text recognition, paragraph-level handwritten text recognition, especially in low-resource languages, such as Hindi, Urdu and similar scripts, remains a challenging problem. These languages, often lacking comprehensive linguistic resources, require special attention to develop robust systems for accurate optical character recognition (OCR). This paper introduces BharatOCR, a novel segmentation-free paragraph-level handwritten Hindi and Urdu text recognition. We propose a ViT-Transformer Decoder-LM architecture for handwritten text recognition, where a Vision Transformer (ViT) extracts visual features, a Transformer decoder generates text sequences, and a pre-trained language model (LM) refines the output to improve accuracy, fluency, and coherence. Our model utilizes a Data-efficient Image Transformer (DeiT) model proposed for masked image modeling in this research work. In addition, we adopt a RoBERTa architecture optimized for masked language modeling (MLM) to enhance the linguistic comprehension and generative capabilities of the proposed model. The transformer decoder generates text sequences from visual embeddings. This model is designed to iteratively process a paragraph image line by line, called implicit line segmentation. The proposed model was evaluated using our custom dataset ('Parimal Urdu') and ('Parimal Hindi'), introduced in this research work, as well as two public datasets. The proposed model achieved benchmark results in the NUST-UHWR, PUCIT-OUHL, and Parimal-Urdu datasets, achieving character recognition rates of 96.24%, 92.05%, and 94.80%, respectively. The model also provided benchmark results using the Hindi dataset achieving a character recognition rate of 80.64%. The results obtained from our proposed model indicated that it outperformed several state-of-the-art Urdu text recognition methods.

