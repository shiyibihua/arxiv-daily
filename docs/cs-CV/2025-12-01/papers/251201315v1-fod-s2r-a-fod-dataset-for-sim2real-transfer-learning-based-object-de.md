---
layout: default
title: FOD-S2R: A FOD Dataset for Sim2Real Transfer Learning based Object Detection
---

# FOD-S2R: A FOD Dataset for Sim2Real Transfer Learning based Object Detection

**arXiv**: [2512.01315v1](https://arxiv.org/abs/2512.01315) | [PDF](https://arxiv.org/pdf/2512.01315.pdf)

**ä½œè€…**: Ashish Vashist, Qiranul Saadiyean, Suresh Sundaram, Chandra Sekhar Seelamantula

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFOD-S2Ræ•°æ®é›†ä»¥è§£å†³é£žæœºæ²¹ç®±å†…å¼‚ç‰©æ£€æµ‹çš„æ¨¡æ‹Ÿåˆ°çœŸå®žè¿ç§»å­¦ä¹ é—®é¢˜**

**å…³é”®è¯**: `å¼‚ç‰©æ£€æµ‹` `æ¨¡æ‹Ÿåˆ°çœŸå®žè¿ç§»å­¦ä¹ ` `åˆæˆæ•°æ®å¢žå¼º` `å°é—­çŽ¯å¢ƒè§†è§‰` `é£žæœºç»´æŠ¤` `ç›®æ ‡æ£€æµ‹æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé£žæœºæ²¹ç®±å†…å¼‚ç‰©æ£€æµ‹ç¼ºä¹é’ˆå¯¹å°é—­çŽ¯å¢ƒçš„ä¸“ç”¨æ•°æ®é›†ï¼Œå­˜åœ¨å®‰å…¨é£Žé™©ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºåŒ…å«çœŸå®žä¸Žåˆæˆå›¾åƒçš„FOD-S2Ræ•°æ®é›†ï¼Œé¦–æ¬¡ç³»ç»Ÿè¯„ä¼°åˆæˆæ•°æ®åœ¨å°é—­ç»“æž„ä¸­çš„æœ‰æ•ˆæ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåŸºå‡†æµ‹è¯•æ˜¾ç¤ºåˆæˆæ•°æ®æå‡æ£€æµ‹ç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›ï¼Œç¼©å°æ¨¡æ‹Ÿåˆ°çœŸå®žå·®è·ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Foreign Object Debris (FOD) within aircraft fuel tanks presents critical safety hazards including fuel contamination, system malfunctions, and increased maintenance costs. Despite the severity of these risks, there is a notable lack of dedicated datasets for the complex, enclosed environments found inside fuel tanks. To bridge this gap, we present a novel dataset, FOD-S2R, composed of real and synthetic images of the FOD within a simulated aircraft fuel tank. Unlike existing datasets that focus on external or open-air environments, our dataset is the first to systematically evaluate the effectiveness of synthetic data in enhancing the real-world FOD detection performance in confined, closed structures. The real-world subset consists of 3,114 high-resolution HD images captured in a controlled fuel tank replica, while the synthetic subset includes 3,137 images generated using Unreal Engine. The dataset is composed of various Field of views (FOV), object distances, lighting conditions, color, and object size. Prior research has demonstrated that synthetic data can reduce reliance on extensive real-world annotations and improve the generalizability of vision models. Thus, we benchmark several state-of-the-art object detection models and demonstrate that introducing synthetic data improves the detection accuracy and generalization to real-world conditions. These experiments demonstrate the effectiveness of synthetic data in enhancing the model performance and narrowing the Sim2Real gap, providing a valuable foundation for developing automated FOD detection systems for aviation maintenance.

