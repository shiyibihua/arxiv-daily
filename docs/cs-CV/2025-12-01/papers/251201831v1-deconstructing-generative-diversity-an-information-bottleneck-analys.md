---
layout: default
title: Deconstructing Generative Diversity: An Information Bottleneck Analysis of Discrete Latent Generative Models
---

# Deconstructing Generative Diversity: An Information Bottleneck Analysis of Discrete Latent Generative Models

**arXiv**: [2512.01831v1](https://arxiv.org/abs/2512.01831) | [PDF](https://arxiv.org/pdf/2512.01831.pdf)

**ä½œè€…**: Yudi Wu, Wenhao Zhao, Dianbo Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽä¿¡æ¯ç“¶é¢ˆçš„è¯Šæ–­æ¡†æž¶ï¼Œåˆ†æžç¦»æ•£æ½œåœ¨ç”Ÿæˆæ¨¡åž‹çš„ç”Ÿæˆå¤šæ ·æ€§å·®å¼‚**

**å…³é”®è¯**: `ç”Ÿæˆå¤šæ ·æ€§` `ä¿¡æ¯ç“¶é¢ˆåˆ†æž` `ç¦»æ•£æ½œåœ¨æ¨¡åž‹` `é›¶æ ·æœ¬å¹²é¢„` `åŽ‹ç¼©ä¸Žå¤šæ ·æ€§æƒè¡¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šARã€MIMå’Œæ‰©æ•£æ¨¡åž‹åœ¨ç”Ÿæˆå¤šæ ·æ€§ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ŒåŽŸå› æœªçŸ¥
2. æ–¹æ³•è¦ç‚¹ï¼šå°†ç”Ÿæˆå»ºæ¨¡ä¸ºåŽ‹ç¼©åŽ‹åŠ›ä¸Žå¤šæ ·æ€§åŽ‹åŠ›çš„å†²çªï¼Œå¹¶åˆ†è§£ä¸ºè·¯å¾„å¤šæ ·æ€§å’Œæ‰§è¡Œå¤šæ ·æ€§
3. å®žéªŒæˆ–æ•ˆæžœï¼šåº”ç”¨é›¶æ ·æœ¬å¹²é¢„æ­ç¤ºä¸‰ç§æ¨¡åž‹çš„ç­–ç•¥ï¼šMIMä¼˜å…ˆå¤šæ ·æ€§ã€ARä¼˜å…ˆåŽ‹ç¼©ã€æ‰©æ•£è§£è€¦

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generative diversity varies significantly across discrete latent generative models such as AR, MIM, and Diffusion. We propose a diagnostic framework, grounded in Information Bottleneck (IB) theory, to analyze the underlying strategies resolving this behavior. The framework models generation as a conflict between a 'Compression Pressure' - a drive to minimize overall codebook entropy - and a 'Diversity Pressure' - a drive to maximize conditional entropy given an input. We further decompose this diversity into two primary sources: 'Path Diversity', representing the choice of high-level generative strategies, and 'Execution Diversity', the randomness in executing a chosen strategy. To make this decomposition operational, we introduce three zero-shot, inference-time interventions that directly perturb the latent generative process and reveal how models allocate and express diversity. Application of this probe-based framework to representative AR, MIM, and Diffusion systems reveals three distinct strategies: "Diversity-Prioritized" (MIM), "Compression-Prioritized" (AR), and "Decoupled" (Diffusion). Our analysis provides a principled explanation for their behavioral differences and informs a novel inference-time diversity enhancement technique.

