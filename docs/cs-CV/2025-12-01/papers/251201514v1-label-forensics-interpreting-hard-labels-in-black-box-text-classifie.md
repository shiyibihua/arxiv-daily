---
layout: default
title: Label Forensics: Interpreting Hard Labels in Black-Box Text Classifier
---

# Label Forensics: Interpreting Hard Labels in Black-Box Text Classifier

**arXiv**: [2512.01514v1](https://arxiv.org/abs/2512.01514) | [PDF](https://arxiv.org/pdf/2512.01514.pdf)

**ä½œè€…**: Mengyao Du, Gang Yang, Han Fang, Quanjun Yin, Ee-chien Chang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ ‡ç­¾å–è¯æ¡†æž¶ä»¥è§£é‡Šé»‘ç›’æ–‡æœ¬åˆ†ç±»å™¨çš„ç¡¬æ ‡ç­¾è¯­ä¹‰**

**å…³é”®è¯**: `é»‘ç›’åˆ†ç±»å™¨` `æ ‡ç­¾è¯­ä¹‰è§£é‡Š` `æ–‡æœ¬åˆ†ç±»` `AIå®¡è®¡` `å¥å­åµŒå…¥åˆ†å¸ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé»‘ç›’æ–‡æœ¬åˆ†ç±»å™¨ä»…è¾“å‡ºç¡¬æ ‡ç­¾ï¼Œå…¶å†…éƒ¨è¯­ä¹‰æœªçŸ¥ï¼Œå¼•å‘å®¡è®¡ä¸Žå–è¯æ‹…å¿§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡è¯­ä¹‰é‚»åŸŸé‡‡æ ·å’Œè¿­ä»£ä¼˜åŒ–ï¼Œæž„å»ºå¥å­åµŒå…¥åˆ†å¸ƒæ¥é‡æž„æ ‡ç­¾çš„è¯­ä¹‰æ¦‚å¿µã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªé»‘ç›’åˆ†ç±»å™¨ä¸Šå¹³å‡æ ‡ç­¾ä¸€è‡´æ€§è¾¾92.24%ï¼ŒéªŒè¯äº†è¯­ä¹‰æ•èŽ·çš„å‡†ç¡®æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The widespread adoption of natural language processing techniques has led to an unprecedented growth of text classifiers across the modern web. Yet many of these models circulate with their internal semantics undocumented or even intentionally withheld. Such opaque classifiers, which may expose only hard-label outputs, can operate in unregulated web environments or be repurposed for unknown intents, raising legitimate forensic and auditing concerns. In this paper, we position ourselves as investigators and work to infer the semantic concept each label encodes in an undocumented black-box classifier.
>   Specifically, we introduce label forensics, a black-box framework that reconstructs a label's semantic meaning. Concretely, we represent a label by a sentence embedding distribution from which any sample reliably reflects the concept the classifier has implicitly learned for that label. We believe this distribution should maintain two key properties: precise, with samples consistently classified into the target label, and general, covering the label's broad semantic space. To realize this, we design a semantic neighborhood sampler and an iterative optimization procedure to select representative seed sentences that jointly maximize label consistency and distributional coverage. The final output, an optimized seed sentence set combined with the sampler, constitutes the empirical distribution representing the label's semantics. Experiments on multiple black-box classifiers achieve an average label consistency of around 92.24 percent, demonstrating that the embedding regions accurately capture each classifier's label semantics. We further validate our framework on an undocumented HuggingFace classifier, enabling fine-grained label interpretation and supporting responsible AI auditing.

