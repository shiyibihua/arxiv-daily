---
layout: default
title: Textured Geometry Evaluation: Perceptual 3D Textured Shape Metric via 3D Latent-Geometry Network
---

# Textured Geometry Evaluation: Perceptual 3D Textured Shape Metric via 3D Latent-Geometry Network

**arXiv**: [2512.01380v1](https://arxiv.org/abs/2512.01380) | [PDF](https://arxiv.org/pdf/2512.01380.pdf)

**ä½œè€…**: Tianyu Luan, Xuelu Feng, Zixin Zhu, Phani Nuney, Sheng Liu, Xuan Gong, David Doermann, Chunming Qiao, Junsong Yuan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTGEæ–¹æ³•ä»¥ç›´æŽ¥è¯„ä¼°å¸¦çº¹ç†3Dç½‘æ ¼çš„ä¿çœŸåº¦ï¼Œé¿å…æ¸²æŸ“ä¾èµ–**

**å…³é”®è¯**: `3Då½¢çŠ¶è¯„ä¼°` `çº¹ç†ç½‘æ ¼` `æ„ŸçŸ¥åº¦é‡` `çœŸå®žä¸–ç•Œå¤±çœŸ` `å‡ ä½•ä¸Žé¢œè‰²è”åˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰3Då½¢çŠ¶è¯„ä¼°æŒ‡æ ‡å¦‚Chamfer Distanceä¸Žäººç±»æ„ŸçŸ¥ä¸ä¸€è‡´ï¼ŒåŸºäºŽæ¸²æŸ“çš„æ–¹æ³•å­˜åœ¨ç»“æž„è¦†ç›–ä¸å…¨å’Œè§†è§’æ•æ„Ÿé—®é¢˜
2. æ–¹æ³•è¦ç‚¹ï¼šTGEç›´æŽ¥åŸºäºŽ3Dç½‘æ ¼å’Œé¢œè‰²ä¿¡æ¯è”åˆè®¡ç®—ä¿çœŸåº¦ï¼Œæ— éœ€æ¸²æŸ“ï¼Œä½¿ç”¨çœŸå®žä¸–ç•Œå¤±çœŸæ•°æ®é›†è®­ç»ƒ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žä¸–ç•Œå¤±çœŸæ•°æ®é›†ä¸Šï¼ŒTGEä¼˜äºŽåŸºäºŽæ¸²æŸ“å’Œä»…å‡ ä½•çš„æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Textured high-fidelity 3D models are crucial for games, AR/VR, and film, but human-aligned evaluation methods still fall behind despite recent advances in 3D reconstruction and generation. Existing metrics, such as Chamfer Distance, often fail to align with how humans evaluate the fidelity of 3D shapes. Recent learning-based metrics attempt to improve this by relying on rendered images and 2D image quality metrics. However, these approaches face limitations due to incomplete structural coverage and sensitivity to viewpoint choices. Moreover, most methods are trained on synthetic distortions, which differ significantly from real-world distortions, resulting in a domain gap. To address these challenges, we propose a new fidelity evaluation method that is based directly on 3D meshes with texture, without relying on rendering. Our method, named Textured Geometry Evaluation TGE, jointly uses the geometry and color information to calculate the fidelity of the input textured mesh with comparison to a reference colored shape. To train and evaluate our metric, we design a human-annotated dataset with real-world distortions. Experiments show that TGE outperforms rendering-based and geometry-only methods on real-world distortion dataset.

