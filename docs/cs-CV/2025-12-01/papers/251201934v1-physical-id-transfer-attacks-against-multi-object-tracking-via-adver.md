---
layout: default
title: Physical ID-Transfer Attacks against Multi-Object Tracking via Adversarial Trajectory
---

# Physical ID-Transfer Attacks against Multi-Object Tracking via Adversarial Trajectory

**arXiv**: [2512.01934v1](https://arxiv.org/abs/2512.01934) | [PDF](https://arxiv.org/pdf/2512.01934.pdf)

**ä½œè€…**: Chenyi Wang, Yanmao Man, Raymond Muller, Ming Li, Z. Berkay Celik, Ryan Gerdes, Jonathan Petit

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAdvTrajæ”»å‡»ï¼Œé€šè¿‡å¯¹æŠ—è½¨è¿¹åœ¨å¤šç›®æ ‡è·Ÿè¸ªä¸­ç‰©ç†è½¬ç§»IDä»¥æ··æ·†ç³»ç»Ÿã€‚**

**å…³é”®è¯**: `å¤šç›®æ ‡è·Ÿè¸ª` `å¯¹æŠ—æ”»å‡»` `ç‰©ç†æ”»å‡»` `è½¨è¿¹ç”Ÿæˆ` `IDè½¬ç§»` `ç³»ç»Ÿé²æ£’æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šç›®æ ‡è·Ÿè¸ªä¸­å¯¹è±¡ä¸ŽIDé”™è¯¯å…³è”çš„å¨èƒæœªå……åˆ†ç ”ç©¶ï¼ŒçŽ°æœ‰æ”»å‡»æ¨¡åž‹ç‰¹å®šä¸”éžé²æ£’ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šAdvTrajæ”»å‡»åœ¨æ£€æµ‹è·Ÿè¸ªæ¡†æž¶ä¸­ï¼Œåˆ©ç”¨å¯¹æŠ—è½¨è¿¹åœ¨çº¿ç‰©ç†è½¬ç§»IDï¼Œä¸æ”»å‡»å¯¹è±¡æ£€æµ‹æ¨¡å—ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CARLAæ¨¡æ‹Ÿä¸­ï¼Œç™½ç›’æ”»å‡»SORTæˆåŠŸçŽ‡100%ï¼Œå¯¹SOTAç®—æ³•è½¬ç§»æ”»å‡»æˆåŠŸçŽ‡é«˜è¾¾93%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-Object Tracking (MOT) is a critical task in computer vision, with applications ranging from surveillance systems to autonomous driving. However, threats to MOT algorithms have yet been widely studied. In particular, incorrect association between the tracked objects and their assigned IDs can lead to severe consequences, such as wrong trajectory predictions. Previous attacks against MOT either focused on hijacking the trackers of individual objects, or manipulating the tracker IDs in MOT by attacking the integrated object detection (OD) module in the digital domain, which are model-specific, non-robust, and only able to affect specific samples in offline datasets. In this paper, we present AdvTraj, the first online and physical ID-manipulation attack against tracking-by-detection MOT, in which an attacker uses adversarial trajectories to transfer its ID to a targeted object to confuse the tracking system, without attacking OD. Our simulation results in CARLA show that AdvTraj can fool ID assignments with 100% success rate in various scenarios for white-box attacks against SORT, which also have high attack transferability (up to 93% attack success rate) against state-of-the-art (SOTA) MOT algorithms due to their common design principles. We characterize the patterns of trajectories generated by AdvTraj and propose two universal adversarial maneuvers that can be performed by a human walker/driver in daily scenarios. Our work reveals under-explored weaknesses in the object association phase of SOTA MOT systems, and provides insights into enhancing the robustness of such systems.

