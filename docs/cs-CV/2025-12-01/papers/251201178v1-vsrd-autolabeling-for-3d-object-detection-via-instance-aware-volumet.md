---
layout: default
title: VSRD++: Autolabeling for 3D Object Detection via Instance-Aware Volumetric Silhouette Rendering
---

# VSRD++: Autolabeling for 3D Object Detection via Instance-Aware Volumetric Silhouette Rendering

**arXiv**: [2512.01178v1](https://arxiv.org/abs/2512.01178) | [PDF](https://arxiv.org/pdf/2512.01178.pdf)

**ä½œè€…**: Zihua Liu, Hiroki Sakuma, Masatoshi Okutomi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVSRD++ï¼Œé€šè¿‡å®žä¾‹æ„ŸçŸ¥ä½“ç§¯è½®å»“æ¸²æŸ“å®žçŽ°å¼±ç›‘ç£å•ç›®3Dç›®æ ‡æ£€æµ‹ï¼Œå‡å°‘å¯¹3Dæ ‡æ³¨çš„ä¾èµ–ã€‚**

**å…³é”®è¯**: `å•ç›®3Dç›®æ ‡æ£€æµ‹` `å¼±ç›‘ç£å­¦ä¹ ` `ä½“ç§¯æ¸²æŸ“` `è‡ªåŠ¨æ ‡æ³¨` `åŠ¨æ€åœºæ™¯å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå•ç›®3Dç›®æ ‡æ£€æµ‹ä¾èµ–å¤§é‡3Dæ ‡æ³¨ï¼Œæ ‡æ³¨æˆæœ¬é«˜ä¸”è€—æ—¶ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨ä¸¤é˜¶æ®µæµç¨‹ï¼ŒåŒ…æ‹¬å¤šè§†å›¾3Dè‡ªåŠ¨æ ‡æ³¨å’Œå•ç›®æ£€æµ‹å™¨è®­ç»ƒï¼ŒåŸºäºŽSDFå’ŒRDFä¼˜åŒ–3Dè¾¹ç•Œæ¡†ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨KITTI-360æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰å¼±ç›‘ç£æ–¹æ³•ï¼Œé€‚ç”¨äºŽé™æ€å’ŒåŠ¨æ€åœºæ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Monocular 3D object detection is a fundamental yet challenging task in 3D scene understanding. Existing approaches heavily depend on supervised learning with extensive 3D annotations, which are often acquired from LiDAR point clouds through labor-intensive labeling processes. To tackle this problem, we propose VSRD++, a novel weakly supervised framework for monocular 3D object detection that eliminates the reliance on 3D annotations and leverages neural-field-based volumetric rendering with weak 2D supervision. VSRD++ consists of a two-stage pipeline: multi-view 3D autolabeling and subsequent monocular 3D detector training. In the multi-view autolabeling stage, object surfaces are represented as signed distance fields (SDFs) and rendered as instance masks via the proposed instance-aware volumetric silhouette rendering. To optimize 3D bounding boxes, we decompose each instance's SDF into a cuboid SDF and a residual distance field (RDF) that captures deviations from the cuboid. To address the geometry inconsistency commonly observed in volume rendering methods applied to dynamic objects, we model the dynamic objects by including velocity into bounding box attributes as well as assigning confidence to each pseudo-label. Moreover, we also employ a 3D attribute initialization module to initialize the dynamic bounding box parameters. In the monocular 3D object detection phase, the optimized 3D bounding boxes serve as pseudo labels for training monocular 3D object detectors. Extensive experiments on the KITTI-360 dataset demonstrate that VSRD++ significantly outperforms existing weakly supervised approaches for monocular 3D object detection on both static and dynamic scenes. Code is available at https://github.com/Magicboomliu/VSRD_plus_plus

