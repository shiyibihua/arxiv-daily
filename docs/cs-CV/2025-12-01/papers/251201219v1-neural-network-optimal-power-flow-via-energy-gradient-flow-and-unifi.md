---
layout: default
title: Neural Network Optimal Power Flow via Energy Gradient Flow and Unified Dynamics
---

# Neural Network Optimal Power Flow via Energy Gradient Flow and Unified Dynamics

**arXiv**: [2512.01219v1](https://arxiv.org/abs/2512.01219) | [PDF](https://arxiv.org/pdf/2512.01219.pdf)

**ä½œè€…**: Xuezhi Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽç¥žç»ç½‘ç»œåŠ¨åŠ›å­¦å’Œèƒ½é‡æ¢¯åº¦æµçš„OPFæ±‚è§£æ–¹æ³•ï¼Œå®žçŽ°æ— ç›‘ç£ç‰©ç†çº¦æŸå­¦ä¹ ã€‚**

**å…³é”®è¯**: `æœ€ä¼˜æ½®æµ` `ç¥žç»ç½‘ç»œåŠ¨åŠ›å­¦` `èƒ½é‡æ¢¯åº¦æµ` `æ— ç›‘ç£å­¦ä¹ ` `ç‰©ç†çº¦æŸä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»ŸOPFæ–¹æ³•è®¡ç®—æ•ˆçŽ‡ä½Žã€ä¾èµ–åˆå§‹å€¼ï¼ŒçŽ°æœ‰æ·±åº¦å­¦ä¹ OPFæ–¹æ³•éœ€å¤§é‡æ ‡æ³¨æ•°æ®ä¸”éš¾ä¿è¯ç‰©ç†ä¸€è‡´æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†OPFè½¬åŒ–ä¸ºèƒ½é‡æœ€å°åŒ–é—®é¢˜ï¼Œé€šè¿‡èƒ½é‡å‡½æ•°å’Œæ¢¯åº¦æµå¼•å¯¼ç½‘ç»œå­¦ä¹ æ»¡è¶³çº¦æŸçš„æœ€ä¼˜è§£ï¼Œæ— éœ€æ ‡æ³¨æ•°æ®ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæœªçŸ¥ï¼Œä½†æ–¹æ³•å£°ç§°å®žçŽ°æ— ç›‘ç£ç«¯åˆ°ç«¯å­¦ä¹ ï¼Œå¯èƒ½æå‡è®¡ç®—æ•ˆçŽ‡å’Œç‰©ç†ä¸€è‡´æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Optimal Power Flow (OPF) is a core optimization problem in power system operation and planning, aiming to minimize generation costs while satisfying physical constraints such as power flow equations, generator limits, and voltage limits. Traditional OPF solving methods typically employ iterative optimization algorithms (such as interior point methods, sequential quadratic programming, etc.), with limitations including low computational efficiency, initial value sensitivity, and low batch computation efficiency. Most existing deep learning-based OPF methods rely on supervised learning, requiring pre-solving large numbers of cases, and have difficulty guaranteeing physical consistency. This paper proposes an Optimal Power Flow solving method based on neural network dynamics and energy gradient flow, transforming OPF problems into energy minimization problems. By constructing an energy function to measure the degree of deviation from the constraint manifold, and guiding networks to learn optimal solutions that simultaneously satisfy power flow constraints and minimize costs through gradient flow. Neural networks are trained unsupervised by directly minimizing physical residuals, requiring no labeled data, achieving true "end-to-end" physics-constrained learning.

