---
layout: default
title: TabletopGen: Instance-Level Interactive 3D Tabletop Scene Generation from Text or Single Image
---

# TabletopGen: Instance-Level Interactive 3D Tabletop Scene Generation from Text or Single Image

**arXiv**: [2512.01204v1](https://arxiv.org/abs/2512.01204) | [PDF](https://arxiv.org/pdf/2512.01204.pdf)

**ä½œè€…**: Ziqian Wang, Yonghao He, Licheng Yang, Wei Zou, Hongxuan Ma, Liu Liu, Wei Sui, Yuxin Guo, Hu Su

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTabletopGenæ¡†æž¶ï¼Œä»Žæ–‡æœ¬æˆ–å•å›¾åƒç”Ÿæˆå®žä¾‹çº§äº¤äº’å¼3Dæ¡Œé¢åœºæ™¯**

**å…³é”®è¯**: `3Dåœºæ™¯ç”Ÿæˆ` `å®žä¾‹çº§é‡å»º` `æ¡Œé¢åœºæ™¯` `äº¤äº’å¼æ¨¡æ‹Ÿ` `ä½å§¿ä¼°è®¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•éš¾ä»¥ç”Ÿæˆé«˜å¯†åº¦å¸ƒå±€å’Œå¤æ‚ç©ºé—´å…³ç³»çš„æ¡Œé¢åœºæ™¯
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå‚è€ƒå›¾åƒè¿›è¡Œå®žä¾‹åˆ†å‰²ä¸Žè¡¥å…¨ï¼Œé€šè¿‡è§£è€¦çš„ä½å§¿å’Œå°ºåº¦å¯¹é½å®žçŽ°3Dé‡å»º
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨è§†è§‰ä¿çœŸåº¦ã€å¸ƒå±€å‡†ç¡®æ€§å’Œç‰©ç†åˆç†æ€§ä¸Šè¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œæ”¯æŒå¤šæ ·é£Žæ ¼

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generating high-fidelity, physically interactive 3D simulated tabletop scenes is essential for embodied AI--especially for robotic manipulation policy learning and data synthesis. However, current text- or image-driven 3D scene generation methods mainly focus on large-scale scenes, struggling to capture the high-density layouts and complex spatial relations that characterize tabletop scenes. To address these challenges, we propose TabletopGen, a training-free, fully automatic framework that generates diverse, instance-level interactive 3D tabletop scenes. TabletopGen accepts a reference image as input, which can be synthesized by a text-to-image model to enhance scene diversity. We then perform instance segmentation and completion on the reference to obtain per-instance images. Each instance is reconstructed into a 3D model followed by canonical coordinate alignment. The aligned 3D models then undergo pose and scale estimation before being assembled into a collision-free, simulation-ready tabletop scene. A key component of our framework is a novel pose and scale alignment approach that decouples the complex spatial reasoning into two stages: a Differentiable Rotation Optimizer for precise rotation recovery and a Top-view Spatial Alignment mechanism for robust translation and scale estimation, enabling accurate 3D reconstruction from 2D reference. Extensive experiments and user studies show that TabletopGen achieves state-of-the-art performance, markedly surpassing existing methods in visual fidelity, layout accuracy, and physical plausibility, capable of generating realistic tabletop scenes with rich stylistic and spatial diversity. Our code will be publicly available.

