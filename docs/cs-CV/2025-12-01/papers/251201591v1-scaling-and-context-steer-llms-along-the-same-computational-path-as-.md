---
layout: default
title: Scaling and context steer LLMs along the same computational path as the human brain
---

# Scaling and context steer LLMs along the same computational path as the human brain

**arXiv**: [2512.01591v1](https://arxiv.org/abs/2512.01591) | [PDF](https://arxiv.org/pdf/2512.01591.pdf)

**ä½œè€…**: JosÃ©phine Raugel, StÃ©phane d'Ascoli, JÃ©rÃ©my Rapin, Valentin Wyart, Jean-RÃ©mi King

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æŽ¢ç©¶LLMsä¸Žå¤§è„‘åœ¨è®¡ç®—è·¯å¾„ä¸Šçš„ç›¸ä¼¼æ€§ï¼ŒåŸºäºŽè„‘ç”µä¿¡å·ä¸Žå¤šæ¨¡åž‹åˆ†æž**

**å…³é”®è¯**: `LLMsä¸Žå¤§è„‘å¯¹é½` `è®¡ç®—è·¯å¾„ç›¸ä¼¼æ€§` `æ—¶é—´åˆ†è¾¨è„‘ä¿¡å·` `æ¨¡åž‹è§„æ¨¡å½±å“` `ä¸Šä¸‹æ–‡é•¿åº¦`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šLLMsä¸Žå¤§è„‘è¡¨å¾å¯¹é½æ˜¯å¦æºäºŽç›¸ä¼¼çš„è®¡ç®—åºåˆ—
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆæ—¶é—´åˆ†è¾¨è„‘ä¿¡å·ä¸Ž22ä¸ªä¸åŒè§„æ¨¡å’Œæž¶æž„çš„LLMsè¿›è¡Œè”åˆåˆ†æž
3. å®žéªŒæˆ–æ•ˆæžœï¼šå‘çŽ°LLMså±‚æ¿€æ´»ä¸Žå¤§è„‘å“åº”æ—¶é—´é¡ºåºä¸€è‡´ï¼Œä¸”å—æ¨¡åž‹è§„æ¨¡å’Œä¸Šä¸‹æ–‡é•¿åº¦å½±å“

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent studies suggest that the representations learned by large language models (LLMs) are partially aligned to those of the human brain. However, whether and why this alignment score arises from a similar sequence of computations remains elusive. In this study, we explore this question by examining temporally-resolved brain signals of participants listening to 10 hours of an audiobook. We study these neural dynamics jointly with a benchmark encompassing 22 LLMs varying in size and architecture type. Our analyses confirm that LLMs and the brain generate representations in a similar order: specifically, activations in the initial layers of LLMs tend to best align with early brain responses, while the deeper layers of LLMs tend to best align with later brain responses. This brain-LLM alignment is consistent across transformers and recurrent architectures. However, its emergence depends on both model size and context length. Overall, this study sheds light on the sequential nature of computations and the factors underlying the partial convergence between biological and artificial neural networks.

