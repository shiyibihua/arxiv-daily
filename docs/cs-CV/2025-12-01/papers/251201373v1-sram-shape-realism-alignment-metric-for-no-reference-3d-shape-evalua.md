---
layout: default
title: SRAM: Shape-Realism Alignment Metric for No Reference 3D Shape Evaluation
---

# SRAM: Shape-Realism Alignment Metric for No Reference 3D Shape Evaluation

**arXiv**: [2512.01373v1](https://arxiv.org/abs/2512.01373) | [PDF](https://arxiv.org/pdf/2512.01373.pdf)

**ä½œè€…**: Sheng Liu, Tianyu Luan, Phani Nuney, Xuelu Feng, Junsong Yuan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSRAMæ— å‚è€ƒä¸‰ç»´å½¢çŠ¶è¯„ä¼°æŒ‡æ ‡ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡åž‹å¯¹é½å½¢çŠ¶ä¿¡æ¯ä¸ŽçœŸå®žæ„Ÿè¯„ä»·ã€‚**

**å…³é”®è¯**: `ä¸‰ç»´å½¢çŠ¶è¯„ä¼°` `æ— å‚è€ƒè¯„ä¼°` `å¤§è¯­è¨€æ¨¡åž‹` `çœŸå®žæ„Ÿå¯¹é½` `ç½‘æ ¼ç¼–ç ` `æ•°æ®é›†æž„å»º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿä¸‰ç»´å½¢çŠ¶è¯„ä¼°ä¾èµ–çœŸå®žå‚è€ƒï¼Œä½†çœŸå®žæ„Ÿè¯„ä¼°å¸¸æ— å‚è€ƒï¼Œéœ€æ— å‚è€ƒè¯„ä¼°æ–¹æ³•ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ç½‘æ ¼ç¼–ç å°†ä¸‰ç»´å½¢çŠ¶è½¬æ¢ä¸ºè¯­è¨€æ ‡è®°ï¼Œè®¾è®¡çœŸå®žæ„Ÿè§£ç å™¨å¯¹é½å¤§è¯­è¨€æ¨¡åž‹è¾“å‡ºä¸Žäººç±»æ„ŸçŸ¥ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæž„å»ºRealismGradingæ•°æ®é›†ï¼Œé€šè¿‡äº¤å‰éªŒè¯éªŒè¯æŒ‡æ ‡ä¸Žäººç±»æ„ŸçŸ¥ç›¸å…³æ€§é«˜ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> 3D generation and reconstruction techniques have been widely used in computer games, film, and other content creation areas. As the application grows, there is a growing demand for 3D shapes that look truly realistic. Traditional evaluation methods rely on a ground truth to measure mesh fidelity. However, in many practical cases, a shape's realism does not depend on having a ground truth reference. In this work, we propose a Shape-Realism Alignment Metric that leverages a large language model (LLM) as a bridge between mesh shape information and realism evaluation. To achieve this, we adopt a mesh encoding approach that converts 3D shapes into the language token space. A dedicated realism decoder is designed to align the language model's output with human perception of realism. Additionally, we introduce a new dataset, RealismGrading, which provides human-annotated realism scores without the need for ground truth shapes. Our dataset includes shapes generated by 16 different algorithms on over a dozen objects, making it more representative of practical 3D shape distributions. We validate our metric's performance and generalizability through k-fold cross-validation across different objects. Experimental results show that our metric correlates well with human perceptions and outperforms existing methods, and has good generalizability.

