---
layout: default
title: Bayesian Ambiguity Contraction-based Adaptive Robust Markov Decision Processes for Adversarial Surveillance Missions
---

# Bayesian Ambiguity Contraction-based Adaptive Robust Markov Decision Processes for Adversarial Surveillance Missions

**arXiv**: [2512.01660v1](https://arxiv.org/abs/2512.01660) | [PDF](https://arxiv.org/pdf/2512.01660.pdf)

**ä½œè€…**: Jimin Choi, Max Z. Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè´å¶æ–¯æ¨¡ç³Šé›†æ”¶ç¼©çš„è‡ªé€‚åº”é²æ£’é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œç”¨äºŽå¯¹æŠ—æ€§ç›‘è§†ä»»åŠ¡**

**å…³é”®è¯**: `è‡ªé€‚åº”é²æ£’é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹` `å¯¹æŠ—æ€§ç›‘è§†` `è´å¶æ–¯æ¨¡ç³Šé›†æ”¶ç¼©` `åä½œä½œæˆ˜é£žæœº` `æ™ºèƒ½ç›‘è§†ä¸Žä¾¦å¯Ÿ` `æ¨¡åž‹ä¸ç¡®å®šæ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåœ¨å¯¹æŠ—æ€§çŽ¯å¢ƒä¸­ï¼Œé™æ€é²æ£’é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹æ— æ³•é€‚åº”æ–°è§‚æµ‹ï¼Œå¯¼è‡´æ¨¡åž‹ä¸ç¡®å®šæ€§å’Œå®žæ—¶å†³ç­–æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡äº¤æ›¿ç§»åŠ¨å’Œæ„ŸçŸ¥çŠ¶æ€å»ºæ¨¡ä»»åŠ¡ï¼Œå¢žé‡æ¶ˆé™¤ä¸ä¸€è‡´å¨èƒæ¨¡åž‹ï¼Œå®žçŽ°ä»Žä¿å®ˆåˆ°æ¿€è¿›è¡Œä¸ºçš„ç­–ç•¥ä¼˜åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šç§ç½‘ç»œæ‹“æ‰‘ä¸‹ï¼Œç›¸æ¯”åä¹‰å’Œé™æ€é²æ£’è§„åˆ’å™¨ï¼ŒèŽ·å¾—æ›´é«˜ä»»åŠ¡å¥–åŠ±å’Œæ›´å°‘æš´éœ²äº‹ä»¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Collaborative Combat Aircraft (CCAs) are envisioned to enable autonomous Intelligence, Surveillance, and Reconnaissance (ISR) missions in contested environments, where adversaries may act strategically to deceive or evade detection. These missions pose challenges due to model uncertainty and the need for safe, real-time decision-making. Robust Markov Decision Processes (RMDPs) provide worst-case guarantees but are limited by static ambiguity sets that capture initial uncertainty without adapting to new observations. This paper presents an adaptive RMDP framework tailored to ISR missions with CCAs. We introduce a mission-specific formulation in which aircraft alternate between movement and sensing states. Adversarial tactics are modeled as a finite set of transition kernels, each capturing assumptions about how adversarial sensing or environmental conditions affect rewards. Our approach incrementally refines policies by eliminating inconsistent threat models, allowing agents to shift from conservative to aggressive behaviors while maintaining robustness. We provide theoretical guarantees showing that the adaptive planner converges as credible sets contract to the true threat and maintains safety under uncertainty. Experiments under Gaussian and non-Gaussian threat models across diverse network topologies show higher mission rewards and fewer exposure events compared to nominal and static robust planners.

