---
layout: default
title: Structured Spectral Reasoning for Frequency-Adaptive Multimodal Recommendation
---

# Structured Spectral Reasoning for Frequency-Adaptive Multimodal Recommendation

**arXiv**: [2512.01372v1](https://arxiv.org/abs/2512.01372) | [PDF](https://arxiv.org/pdf/2512.01372.pdf)

**ä½œè€…**: Wei Yang, Rui Zhong, Yiqun Chen, Chi Lu, Peng Jiang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“æž„åŒ–è°±æŽ¨ç†æ¡†æž¶ä»¥è§£å†³å¤šæ¨¡æ€æŽ¨èä¸­çš„å™ªå£°ä¸Žä¸ä¸€è‡´é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€æŽ¨è` `è°±åŸŸåˆ†æž` `å›¾ç¥žç»ç½‘ç»œ` `é¢‘çŽ‡è‡ªé€‚åº”` `å¯¹æ¯”å­¦ä¹ ` `é²æ£’æ€§æå‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€æŽ¨èé¢ä¸´æ¨¡æ€å™ªå£°ã€è¯­ä¹‰ä¸ä¸€è‡´å’Œå›¾ä¼ æ’­ä¸ç¨³å®šï¼Œå¯¼è‡´æ³›åŒ–å·®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡è°±åˆ†è§£ã€è°±å¸¦æŽ©ç ã€è¶…è°±æŽ¨ç†å’Œå¯¹é½æ­£åˆ™åŒ–ï¼Œå®žçŽ°é¢‘çŽ‡è‡ªé€‚åº”å»ºæ¨¡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žåŸºå‡†ä¸Šä¼˜äºŽåŸºçº¿ï¼Œå°¤å…¶åœ¨ç¨€ç–å’Œå†·å¯åŠ¨åœºæ™¯ä¸­æå‡é²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal recommendation aims to integrate collaborative signals with heterogeneous content such as visual and textual information, but remains challenged by modality-specific noise, semantic inconsistency, and unstable propagation over user-item graphs. These issues are often exacerbated by naive fusion or shallow modeling strategies, leading to degraded generalization and poor robustness. While recent work has explored the frequency domain as a lens to separate stable from noisy signals, most methods rely on static filtering or reweighting, lacking the ability to reason over spectral structure or adapt to modality-specific reliability. To address these challenges, we propose a Structured Spectral Reasoning (SSR) framework for frequency-aware multimodal recommendation. Our method follows a four-stage pipeline: (i) Decompose graph-based multimodal signals into spectral bands via graph-guided transformations to isolate semantic granularity; (ii) Modulate band-level reliability with spectral band masking, a training-time masking with a prediction-consistency objective that suppresses brittle frequency components; (iii) Fuse complementary frequency cues using hyperspectral reasoning with low-rank cross-band interaction; and (iv) Align modality-specific spectral features via contrastive regularization to promote semantic and structural consistency. Experiments on three real-world benchmarks show consistent gains over strong baselines, particularly under sparse and cold-start settings. Additional analyses indicate that structured spectral modeling improves robustness and provides clearer diagnostics of how different bands contribute to performance.

