---
layout: default
title: Med-VCD: Mitigating Hallucination for Medical Large Vision Language Models through Visual Contrastive Decoding
---

# Med-VCD: Mitigating Hallucination for Medical Large Vision Language Models through Visual Contrastive Decoding

**arXiv**: [2512.01922v1](https://arxiv.org/abs/2512.01922) | [PDF](https://arxiv.org/pdf/2512.01922.pdf)

**ä½œè€…**: Zahra Mahdavi, Zahra Khodakaramimaghsoud, Hooman Khaloo, Sina Bakhshandeh Taleshani, Erfan Hashemi, Javad Mirzapour Kaleybar, Omid Nejati Manzari

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMed-VCDæ–¹æ³•ï¼Œé€šè¿‡è§†è§‰å¯¹æ¯”è§£ç ç¼“è§£åŒ»ç–—å¤§è§†è§‰è¯­è¨€æ¨¡åž‹çš„å¹»è§‰é—®é¢˜**

**å…³é”®è¯**: `åŒ»ç–—å¤§è§†è§‰è¯­è¨€æ¨¡åž‹` `å¹»è§‰ç¼“è§£` `è§†è§‰å¯¹æ¯”è§£ç ` `ç¨€ç–ä»¤ç‰Œé€‰æ‹©` `åŒ»ç–—è§†è§‰é—®ç­”` `åŒ»ç–—æŠ¥å‘Šç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åŒ»ç–—å¤§è§†è§‰è¯­è¨€æ¨¡åž‹åœ¨åŒ»ç–—åº”ç”¨ä¸­æ˜“äº§ç”Ÿçœ‹ä¼¼åˆç†ä½†é”™è¯¯çš„å¹»è§‰è¾“å‡º
2. Med-VCDé‡‡ç”¨ç¨€ç–è§†è§‰å¯¹æ¯”è§£ç ï¼ŒåŠ¨æ€é€‰æ‹©è§†è§‰ä¿¡æ¯ä»¤ç‰Œï¼Œæ— éœ€äºŒæ¬¡è§£ç ï¼Œå¹³è¡¡æ•ˆçŽ‡ä¸Žå¯é æ€§
3. åœ¨å…«ä¸ªåŒ»ç–—æ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œå¹³å‡æå‡äº‹å®žå‡†ç¡®æ€§13%ï¼Œå¹»è§‰å‡†ç¡®æ€§6%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large vision-language models (LVLMs) are now central to healthcare applications such as medical visual question answering and imaging report generation. Yet, these models remain vulnerable to hallucination outputs that appear plausible but are in fact incorrect. In the natural image domain, several decoding strategies have been proposed to mitigate hallucinations by reinforcing visual evidence, but most rely on secondary decoding or rollback procedures that substantially slow inference. Moreover, existing solutions are often domain-specific and may introduce misalignment between modalities or between generated and ground-truth content. We introduce Med-VCD, a sparse visual-contrastive decoding method that mitigates hallucinations in medical LVLMs without the time overhead of secondary decoding. Med-VCD incorporates a novel token-sparsification strategy that selects visually informed tokens on the fly, trimming redundancy while retaining critical visual context and thus balancing efficiency with reliability. Evaluations on eight medical datasets, spanning ophthalmology, radiology, and pathology tasks in visual question answering, report generation, and dedicated hallucination benchmarks, show that Med-VCD raises factual accuracy by an average of 13\% and improves hallucination accuracy by 6\% relative to baseline medical LVLMs.

