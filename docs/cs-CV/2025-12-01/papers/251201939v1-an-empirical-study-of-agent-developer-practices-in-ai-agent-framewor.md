---
layout: default
title: An Empirical Study of Agent Developer Practices in AI Agent Frameworks
---

# An Empirical Study of Agent Developer Practices in AI Agent Frameworks

**arXiv**: [2512.01939v1](https://arxiv.org/abs/2512.01939) | [PDF](https://arxiv.org/pdf/2512.01939.pdf)

**ä½œè€…**: Yanlin Wang, Xinyi Xu, Jiachi Chen, Tingting Bi, Wenchao Gu, Zibin Zheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åŸºäºŽLLMçš„AIä»£ç†æ¡†æž¶å®žè¯ç ”ç©¶ï¼Œåˆ†æžå¼€å‘è€…å®žè·µä¸Žæ¡†æž¶å·®å¼‚**

**å…³é”®è¯**: `AIä»£ç†æ¡†æž¶` `å®žè¯ç ”ç©¶` `å¼€å‘è€…å®žè·µ` `LLMåº”ç”¨` `æ¡†æž¶æ¯”è¾ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä»£ç†æ¡†æž¶çš„å®žé™…åº”ç”¨ä¸Žå¯¹å¼€å‘è¿‡ç¨‹çš„å½±å“æœªå……åˆ†æŽ¢ç´¢ï¼Œå¼€å‘è€…é¢ä¸´é€‰æ‹©å›°éš¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ”¶é›†å¹¶åˆ†æž10ä¸ªä»£ç†æ¡†æž¶çš„11,910æ¡å¼€å‘è€…è®¨è®ºï¼Œè¿›è¡Œå®žè¯ç ”ç©¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šä»Žå¼€å‘æ•ˆçŽ‡ã€åŠŸèƒ½æŠ½è±¡ç­‰äº”ä¸ªç»´åº¦æ¯”è¾ƒæ¡†æž¶ï¼Œæ­ç¤ºæ˜¾è‘—å·®å¼‚ä¸Žæ”¹è¿›æ–¹å‘ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The rise of large language models (LLMs) has sparked a surge of interest in agents, leading to the rapid growth of agent frameworks. Agent frameworks are software toolkits and libraries that provide standardized components, abstractions, and orchestration mechanisms to simplify agent development. Despite widespread use of agent frameworks, their practical applications and how they influence the agent development process remain underexplored. Different agent frameworks encounter similar problems during use, indicating that these recurring issues deserve greater attention and call for further improvements in agent framework design. Meanwhile, as the number of agent frameworks continues to grow and evolve, more than 80% of developers report difficulties in identifying the frameworks that best meet their specific development requirements. In this paper, we conduct the first empirical study of LLM-based agent frameworks, exploring real-world experiences of developers in building AI agents. To compare how well the agent frameworks meet developer needs, we further collect developer discussions for the ten previously identified agent frameworks, resulting in a total of 11,910 discussions. Finally, by analyzing these discussions, we compare the frameworks across five dimensions: development efficiency, functional abstraction, learning cost, performance optimization, and maintainability, which refers to how easily developers can update and extend both the framework itself and the agents built upon it over time. Our comparative analysis reveals significant differences among frameworks in how they meet the needs of agent developers. Overall, we provide a set of findings and implications for the LLM-driven AI agent framework ecosystem and offer insights for the design of future LLM-based agent frameworks and agent developers.

