---
layout: default
title: Modality-Augmented Fine-Tuning of Foundation Robot Policies for Cross-Embodiment Manipulation on GR1 and G1
---

# Modality-Augmented Fine-Tuning of Foundation Robot Policies for Cross-Embodiment Manipulation on GR1 and G1

**arXiv**: [2512.01358v1](https://arxiv.org/abs/2512.01358) | [PDF](https://arxiv.org/pdf/2512.01358.pdf)

**ä½œè€…**: Junsung Park, Hogun Kee, Songhwai Oh

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¨¡æ€å¢žå¼ºå¾®è°ƒæ¡†æž¶ï¼Œä»¥é€‚é…GR1å’ŒG1äººå½¢æœºå™¨äººçš„è·¨å…·èº«æ“ä½œä»»åŠ¡ã€‚**

**å…³é”®è¯**: `è·¨å…·èº«æ“ä½œ` `æ¨¡æ€å¢žå¼º` `å¾®è°ƒæ¡†æž¶` `äººå½¢æœºå™¨äºº` `å¤šæ¨¡æ€æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŸºç¡€æœºå™¨äººç­–ç•¥éš¾ä»¥é€‚åº”ä¸åŒäººå½¢æœºå™¨äººå…·èº«ï¼Œéœ€è·¨å…·èº«æ“ä½œèƒ½åŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æ¨¡æ€å¢žå¼ºå¾®è°ƒï¼ŒåŒ…æ‹¬åŽå¤„ç†æ¨¡æ€ï¼ˆå¦‚æŽ¥è§¦ä¿¡å·ï¼‰å’Œå¤šæ¨¡æ€æ•°æ®é›†ï¼ˆå¦‚è¿åŠ¨è§„åˆ’ï¼‰ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šGR1æˆåŠŸçŽ‡ä»Ž51%æå‡è‡³63%ï¼ŒG1ä»»åŠ¡æˆåŠŸçŽ‡ä»Ž48%æå‡è‡³94%ï¼ŒéªŒè¯äº†æ¨¡æ€å¢žå¼ºçš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper presents a modality-augmented fine-tuning framework designed to adapt foundation robot policies to diverse humanoid embodiments. We validate our approach across two distinct settings: (i) the GR1 embodiment, utilizing public datasets where we introduce post-processed modalities, including binary contact signals and ZoeDepth-generated metric depth; and (ii) the Unitree G1 embodiment, for which we contribute a novel multi-modal dataset incorporating cuRobo motion planning, inverse kinematics, and ground-truth contact-force measurements. Our experiments demonstrate that modality augmentation consistently enhances policy performance across different embodiments. Specifically, for the GR1, integrating contact-state cues and RGB-D fusion improves online success rates from 51% to 63%. Furthermore, in the G1 "Pick Apple to Bowl" task, our contact-augmented model achieves a success rate of 94%, significantly outperforming the 48% achieved by standard fine-tuning and the 0% baseline of zero-shot transfer. These results highlight that lightweight post-processing effectively strengthens policies for GR1, while high-quality multi-modal data is crucial for reliable transfer to the Unitree G1. Consequently, this work establishes a unified, data-centric pathway for extending foundation robot policies through targeted modality design and multi-modal fine-tuning.

