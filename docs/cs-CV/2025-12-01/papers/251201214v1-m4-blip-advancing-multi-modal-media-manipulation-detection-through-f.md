---
layout: default
title: M4-BLIP: Advancing Multi-Modal Media Manipulation Detection through Face-Enhanced Local Analysis
---

# M4-BLIP: Advancing Multi-Modal Media Manipulation Detection through Face-Enhanced Local Analysis

**arXiv**: [2512.01214v1](https://arxiv.org/abs/2512.01214) | [PDF](https://arxiv.org/pdf/2512.01214.pdf)

**ä½œè€…**: Hang Wu, Ke Sun, Jiayi Ji, Xiaoshuai Sun, Rongrong Ji

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºM4-BLIPæ¡†æž¶ï¼Œé€šè¿‡å¢žå¼ºå±€éƒ¨é¢éƒ¨åˆ†æžæå‡å¤šæ¨¡æ€åª’ä½“ç¯¡æ”¹æ£€æµ‹æ€§èƒ½**

**å…³é”®è¯**: `å¤šæ¨¡æ€åª’ä½“ç¯¡æ”¹æ£€æµ‹` `å±€éƒ¨ç‰¹å¾æå–` `é¢éƒ¨å…ˆéªŒçŸ¥è¯†` `ç‰¹å¾å¯¹é½èžåˆ` `å¤§è¯­è¨€æ¨¡åž‹é›†æˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰å¤šæ¨¡æ€åª’ä½“ç¯¡æ”¹æ£€æµ‹æ–¹æ³•å¸¸å¿½è§†å±€éƒ¨ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯é¢éƒ¨åŒºåŸŸçš„ç¯¡æ”¹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽBLIP-2æå–å±€éƒ¨ç‰¹å¾ï¼Œç»“åˆé¢éƒ¨å…ˆéªŒçŸ¥è¯†ï¼Œé€šè¿‡å¯¹é½èžåˆæ¨¡å—æ•´åˆå±€éƒ¨ä¸Žå…¨å±€ç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒéªŒè¯æ¡†æž¶æœ‰æ•ˆæ€§ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶é›†æˆå¤§è¯­è¨€æ¨¡åž‹æå‡ç»“æžœå¯è§£é‡Šæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In the contemporary digital landscape, multi-modal media manipulation has emerged as a significant societal threat, impacting the reliability and integrity of information dissemination. Current detection methodologies in this domain often overlook the crucial aspect of localized information, despite the fact that manipulations frequently occur in specific areas, particularly in facial regions. In response to this critical observation, we propose the M4-BLIP framework. This innovative framework utilizes the BLIP-2 model, renowned for its ability to extract local features, as the cornerstone for feature extraction. Complementing this, we incorporate local facial information as prior knowledge. A specially designed alignment and fusion module within M4-BLIP meticulously integrates these local and global features, creating a harmonious blend that enhances detection accuracy. Furthermore, our approach seamlessly integrates with Large Language Models (LLM), significantly improving the interpretability of the detection outcomes. Extensive quantitative and visualization experiments validate the effectiveness of our framework against the state-of-the-art competitors.

