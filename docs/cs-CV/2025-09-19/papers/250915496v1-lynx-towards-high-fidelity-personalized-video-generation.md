---
layout: default
title: Lynx: Towards High-Fidelity Personalized Video Generation
---

# Lynx: Towards High-Fidelity Personalized Video Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15496" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15496v1</a>
  <a href="https://arxiv.org/pdf/2509.15496.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15496v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15496v1', 'Lynx: Towards High-Fidelity Personalized Video Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shen Sang, Tiancheng Zhi, Tianpei Gu, Jing Liu, Linjie Luo

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

**å¤‡æ³¨**: Lynx Technical Report

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Lynxï¼šé¢å‘é«˜ä¿çœŸä¸ªæ€§åŒ–è§†é¢‘ç”Ÿæˆçš„æ‰©æ•£Transformeræ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸ªæ€§åŒ–è§†é¢‘ç”Ÿæˆ` `æ‰©æ•£Transformer` `èº«ä»½ä¿æŒ` `è§†é¢‘åˆæˆ` `DiT` `Perceiver Resampler` `VAE` `äº¤å‰æ³¨æ„åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ä¸ªæ€§åŒ–è§†é¢‘ç”Ÿæˆä¸­éš¾ä»¥å…¼é¡¾èº«ä»½ä¿æŒã€æ—¶é—´ä¸€è‡´æ€§å’Œè§†è§‰è´¨é‡ï¼Œé¢ä¸´è¯¸å¤šæŒ‘æˆ˜ã€‚
2. Lynxé€šè¿‡ID-adapterå’ŒRef-adapterä¸¤ä¸ªè½»é‡çº§æ¨¡å—ï¼Œåˆ†åˆ«ä»èº«ä»½åµŒå…¥å’Œå‚è€ƒå›¾åƒä¸­æå–ä¿¡æ¯ï¼Œå¢å¼ºèº«ä»½ä¿çœŸåº¦ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLynxåœ¨é¢éƒ¨ç›¸ä¼¼æ€§ã€æç¤ºéµå¾ªå’Œè§†é¢‘è´¨é‡æ–¹é¢å‡è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æå‡äº†ä¸ªæ€§åŒ–è§†é¢‘ç”Ÿæˆçš„æ°´å¹³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºLynxï¼Œä¸€ä¸ªåŸºäºå•å¼ è¾“å…¥å›¾åƒçš„é«˜ä¿çœŸä¸ªæ€§åŒ–è§†é¢‘åˆæˆæ¨¡å‹ã€‚Lynxæ„å»ºäºå¼€æºçš„æ‰©æ•£Transformer (DiT) åŸºç¡€æ¨¡å‹ä¹‹ä¸Šï¼Œå¼•å…¥äº†ä¸¤ä¸ªè½»é‡çº§çš„é€‚é…å™¨ä»¥ç¡®ä¿èº«ä»½ä¿çœŸåº¦ã€‚ID-adapteré‡‡ç”¨Perceiver Resamplerå°†ArcFaceå¯¼å‡ºçš„é¢éƒ¨åµŒå…¥è½¬æ¢ä¸ºç´§å‡‘çš„èº«ä»½tokensç”¨äºæ¡ä»¶æ§åˆ¶ï¼›Ref-adapteré›†æˆäº†æ¥è‡ªå†»ç»“å‚è€ƒè·¯å¾„çš„å¯†é›†VAEç‰¹å¾ï¼Œé€šè¿‡äº¤å‰æ³¨æ„åŠ›åœ¨æ‰€æœ‰Transformerå±‚ä¸­æ³¨å…¥ç»†ç²’åº¦çš„ç»†èŠ‚ã€‚è¿™äº›æ¨¡å—å…±åŒå®ç°äº†å¼ºå¤§çš„èº«ä»½ä¿æŒï¼ŒåŒæ—¶ä¿æŒäº†æ—¶é—´ä¸€è‡´æ€§å’Œè§†è§‰çœŸå®æ„Ÿã€‚åœ¨åŒ…å«40ä¸ªå¯¹è±¡å’Œ20ä¸ªæ— åæç¤ºçš„åŸºå‡†æµ‹è¯•ä¸­ï¼ˆå…±800ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼‰ï¼ŒLynxå±•ç¤ºäº†å“è¶Šçš„é¢éƒ¨ç›¸ä¼¼æ€§ã€æœ‰ç«äº‰åŠ›çš„æç¤ºéµå¾ªèƒ½åŠ›å’Œå¼ºå¤§çš„è§†é¢‘è´¨é‡ï¼Œä»è€Œæ¨è¿›äº†ä¸ªæ€§åŒ–è§†é¢‘ç”Ÿæˆçš„æŠ€æœ¯æ°´å¹³ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»å•å¼ å›¾åƒç”Ÿæˆä¸ªæ€§åŒ–è§†é¢‘çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä¿æŒç”Ÿæˆè§†é¢‘ä¸­äººç‰©èº«ä»½çš„ä¿çœŸåº¦ã€ç»´æŒè§†é¢‘çš„æ—¶é—´ä¸€è‡´æ€§ä»¥åŠä¿è¯è§†é¢‘çš„è§†è§‰è´¨é‡æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥åŒæ—¶æ»¡è¶³è¿™äº›è¦æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ‰©æ•£Transformer (DiT) ä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œå¹¶å¼•å…¥ä¸¤ä¸ªè½»é‡çº§çš„é€‚é…å™¨ï¼ˆID-adapterå’ŒRef-adapterï¼‰æ¥åˆ†åˆ«å¤„ç†èº«ä»½ä¿¡æ¯å’Œå‚è€ƒå›¾åƒçš„ç»†èŠ‚ä¿¡æ¯ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ å’Œä¿æŒäººç‰©çš„èº«ä»½ç‰¹å¾ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLynxçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) åŸºäºDiTçš„è§†é¢‘ç”Ÿæˆä¸»å¹²ç½‘ç»œï¼›2) ID-adapterï¼Œç”¨äºæå–å’Œç¼–ç èº«ä»½ä¿¡æ¯ï¼›3) Ref-adapterï¼Œç”¨äºæå–å’Œç¼–ç å‚è€ƒå›¾åƒçš„ç»†èŠ‚ä¿¡æ¯ã€‚ID-adapterä½¿ç”¨Perceiver Resamplerå°†ArcFaceæå–çš„é¢éƒ¨åµŒå…¥è½¬æ¢ä¸ºèº«ä»½tokensï¼ŒRef-adapteråˆ™åˆ©ç”¨VAEæå–å‚è€ƒå›¾åƒçš„å¯†é›†ç‰¹å¾ã€‚è¿™ä¸¤ä¸ªé€‚é…å™¨çš„è¾“å‡ºé€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶æ³¨å…¥åˆ°DiTçš„å„ä¸ªTransformerå±‚ä¸­ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ID-adapterå’ŒRef-adapterè¿™ä¸¤ä¸ªè½»é‡çº§ä¸”æœ‰æ•ˆçš„é€‚é…å™¨ã€‚ID-adapterèƒ½å¤Ÿå°†é«˜ç»´çš„é¢éƒ¨åµŒå…¥å‹ç¼©æˆç´§å‡‘çš„èº«ä»½tokensï¼Œä»è€Œé™ä½è®¡ç®—å¤æ‚åº¦å¹¶æé«˜æ•ˆç‡ã€‚Ref-adapteråˆ™èƒ½å¤Ÿå°†å‚è€ƒå›¾åƒçš„ç»†ç²’åº¦ç»†èŠ‚æ³¨å…¥åˆ°è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä»è€Œæé«˜è§†é¢‘çš„è§†è§‰è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šID-adapterä½¿ç”¨Perceiver Resampleræ¥å¤„ç†é¢éƒ¨åµŒå…¥ï¼Œè¯¥æ¨¡å—èƒ½å¤Ÿå°†ä¸åŒé•¿åº¦çš„è¾“å…¥åºåˆ—è½¬æ¢ä¸ºå›ºå®šé•¿åº¦çš„è¾“å‡ºåºåˆ—ã€‚Ref-adapterä½¿ç”¨é¢„è®­ç»ƒçš„VAEæ¥æå–å‚è€ƒå›¾åƒçš„ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å°†è¿™äº›ç‰¹å¾æ³¨å…¥åˆ°DiTçš„å„ä¸ªTransformerå±‚ä¸­ã€‚æŸå¤±å‡½æ•°æ–¹é¢ï¼Œè®ºæ–‡å¯èƒ½é‡‡ç”¨äº†æ ‡å‡†çš„æ‰©æ•£æ¨¡å‹è®­ç»ƒæŸå¤±ï¼Œå¹¶å¯èƒ½é’ˆå¯¹èº«ä»½ä¿æŒå’Œè§†é¢‘è´¨é‡æ·»åŠ äº†é¢å¤–çš„æ­£åˆ™åŒ–é¡¹ï¼ˆå…·ä½“ç»†èŠ‚æœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Lynxåœ¨åŒ…å«40ä¸ªå¯¹è±¡å’Œ20ä¸ªæ— åæç¤ºçš„åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå…±è®¡800ä¸ªæµ‹è¯•ç”¨ä¾‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLynxåœ¨é¢éƒ¨ç›¸ä¼¼æ€§æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æå‡ï¼ŒåŒæ—¶åœ¨æç¤ºéµå¾ªå’Œè§†é¢‘è´¨é‡æ–¹é¢ä¹Ÿå…·æœ‰ç«äº‰åŠ›ã€‚ç›¸è¾ƒäºå…¶ä»–ä¸ªæ€§åŒ–è§†é¢‘ç”Ÿæˆæ–¹æ³•ï¼ŒLynxèƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸã€æ›´ç¬¦åˆç”¨æˆ·æœŸæœ›çš„è§†é¢‘å†…å®¹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Lynxå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬è™šæ‹ŸåŒ–èº«ç”Ÿæˆã€ä¸ªæ€§åŒ–å†…å®¹åˆ›ä½œã€ç”µå½±ç‰¹æ•ˆåˆ¶ä½œã€æ¸¸æˆè§’è‰²å®šåˆ¶ç­‰ã€‚è¯¥æŠ€æœ¯å¯ä»¥å¸®åŠ©ç”¨æˆ·è½»æ¾åˆ›å»ºé€¼çœŸä¸”ä¸ªæ€§åŒ–çš„è§†é¢‘å†…å®¹ï¼Œæå¤§åœ°ä¸°å¯Œäº†æ•°å­—å¨±ä¹å’Œç¤¾äº¤ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ›´å¹¿æ³›çš„é¢†åŸŸï¼Œä¾‹å¦‚æ•™è‚²ã€åŒ»ç–—å’Œå·¥ä¸šç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present Lynx, a high-fidelity model for personalized video synthesis from a single input image. Built on an open-source Diffusion Transformer (DiT) foundation model, Lynx introduces two lightweight adapters to ensure identity fidelity. The ID-adapter employs a Perceiver Resampler to convert ArcFace-derived facial embeddings into compact identity tokens for conditioning, while the Ref-adapter integrates dense VAE features from a frozen reference pathway, injecting fine-grained details across all transformer layers through cross-attention. These modules collectively enable robust identity preservation while maintaining temporal coherence and visual realism. Through evaluation on a curated benchmark of 40 subjects and 20 unbiased prompts, which yielded 800 test cases, Lynx has demonstrated superior face resemblance, competitive prompt following, and strong video quality, thereby advancing the state of personalized video generation.

