---
layout: default
title: ENSAM: an efficient foundation model for interactive segmentation of 3D medical images
---

# ENSAM: an efficient foundation model for interactive segmentation of 3D medical images

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15874" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15874v1</a>
  <a href="https://arxiv.org/pdf/2509.15874.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15874v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15874v1', 'ENSAM: an efficient foundation model for interactive segmentation of 3D medical images')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Elias Stenhede, Agnar Martin BjÃ¸rnstad, Arian Ranjbar

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ENSAMï¼šä¸€ç§é«˜æ•ˆçš„ä¸‰ç»´åŒ»å­¦å›¾åƒäº¤äº’åˆ†å‰²åŸºç¡€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†å‰²` `äº¤äº’å¼åˆ†å‰²` `åŸºç¡€æ¨¡å‹` `è½»é‡çº§æ¨¡å‹` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†å‰²æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œé™åˆ¶äº†å…¶åœ¨æ•°æ®ç¨€ç¼ºå’Œè®¡ç®—èµ„æºæœ‰é™åœºæ™¯ä¸‹çš„åº”ç”¨ã€‚
2. ENSAMé€šè¿‡ç»“åˆSegResNetç¼–ç å™¨ã€æç¤ºç¼–ç å™¨å’Œæ©ç è§£ç å™¨ï¼Œå¹¶å¼•å…¥ç›¸å¯¹ä½ç½®ç¼–ç å’Œå½’ä¸€åŒ–æ³¨æ„åŠ›ç­‰æœºåˆ¶ï¼Œå®ç°äº†é«˜æ•ˆçš„ä¸‰ç»´åŒ»å­¦å›¾åƒäº¤äº’åˆ†å‰²ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒENSAMåœ¨æœ‰é™çš„æ•°æ®å’Œè®¡ç®—èµ„æºä¸‹ï¼Œèƒ½å¤Ÿä¼˜äºæˆ–åŒ¹é…ç°æœ‰çš„åŸºçº¿æ¨¡å‹ï¼Œå¹¶ä¸”ç›¸å¯¹ä½ç½®ç¼–ç å’ŒMuonä¼˜åŒ–å™¨èƒ½å¤Ÿæ˜¾è‘—æå‡æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§è½»é‡çº§çš„ã€å¯æç¤ºçš„é€šç”¨ä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹ENSAMï¼ˆEquivariant, Normalized, Segment Anything Modelï¼‰ã€‚ENSAMç»“åˆäº†åŸºäºSegResNetçš„ç¼–ç å™¨ã€æç¤ºç¼–ç å™¨å’Œæ©ç è§£ç å™¨ï¼Œé‡‡ç”¨U-Neté£æ ¼çš„æ¶æ„ï¼Œå¹¶ä½¿ç”¨æ½œåœ¨äº¤å‰æ³¨æ„åŠ›ã€ç›¸å¯¹ä½ç½®ç¼–ç ã€å½’ä¸€åŒ–æ³¨æ„åŠ›å’ŒMuonä¼˜åŒ–å™¨è¿›è¡Œè®­ç»ƒã€‚ENSAMæ—¨åœ¨åœ¨æœ‰é™çš„æ•°æ®å’Œè®¡ç®—é¢„ç®—ä¸‹å®ç°è‰¯å¥½çš„æ€§èƒ½ï¼Œä»…ä½¿ç”¨æ¥è‡ªå¤šç§æ¨¡æ€ï¼ˆCTã€MRIã€PETã€è¶…å£°ã€æ˜¾å¾®é•œï¼‰çš„ä¸åˆ°5000ä¸ªvolumeï¼Œåœ¨å•ä¸ª32 GB GPUä¸Šäº6å°æ—¶å†…ä»å¤´å¼€å§‹è®­ç»ƒã€‚åœ¨CVPR 2025 Foundation Models for Interactive 3D Biomedical Image Segmentation Challengeä¸­ï¼ŒENSAMåœ¨å¤šæ¨¡æ€ä¸‰ç»´åŒ»å­¦å›¾åƒçš„éšè—æµ‹è¯•é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè·å¾—äº†2.404çš„DSC AUCã€2.266çš„NSD AUCã€0.627çš„æœ€ç»ˆDSCå’Œ0.597çš„æœ€ç»ˆNSDï¼Œä¼˜äºä¹‹å‰å‘è¡¨çš„ä¸¤ä¸ªåŸºçº¿æ¨¡å‹ï¼ˆVISTA3Dã€SAM-Med3Dï¼‰ï¼Œå¹¶ä¸ç¬¬ä¸‰ä¸ªæ¨¡å‹ï¼ˆSegVolï¼‰ç›¸åŒ¹é…ï¼Œåœ¨æœ€ç»ˆDSCæ–¹é¢è¶…è¿‡äº†SegVolï¼Œä½†åœ¨å…¶ä»–ä¸‰ä¸ªæŒ‡æ ‡ä¸Šè½åã€‚åœ¨æŒ‘æˆ˜èµ›çš„coreset trackä¸­ï¼ŒENSAMåœ¨æ€»å…±10ä¸ªæ–¹æ³•ä¸­æ’åç¬¬5ï¼Œå¹¶ä¸”æ˜¯åœ¨æœªä½¿ç”¨é¢„è®­ç»ƒæƒé‡çš„æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³çš„ã€‚æ¶ˆèç ”ç©¶è¯å®ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„ç›¸å¯¹ä½ç½®ç¼–ç å’ŒMuonä¼˜åŒ–å™¨éƒ½æ˜¾è‘—åŠ å¿«äº†æ”¶æ•›é€Ÿåº¦å¹¶æé«˜äº†åˆ†å‰²è´¨é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†å‰²æ—¨åœ¨ä»ä¸‰ç»´åŒ»å­¦å›¾åƒä¸­å‡†ç¡®åœ°åˆ†å‰²å‡ºæ„Ÿå…´è¶£çš„ç»„ç»‡æˆ–å™¨å®˜ã€‚ç°æœ‰çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºå¤§é‡çš„æ ‡æ³¨æ•°æ®å’Œå¼ºå¤§çš„è®¡ç®—èµ„æºï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®è·å–å›°éš¾æˆ–è®¡ç®—èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ã€‚æ­¤å¤–ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°åˆ©ç”¨ç”¨æˆ·äº¤äº’ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œæç¤ºï¼‰æ¥æŒ‡å¯¼åˆ†å‰²è¿‡ç¨‹ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„ç ”ç©¶é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šENSAMçš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªè½»é‡çº§ã€å¯æç¤ºçš„åˆ†å‰²æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨æœ‰é™çš„æ•°æ®å’Œè®¡ç®—èµ„æºä¸‹å®ç°è‰¯å¥½çš„åˆ†å‰²æ€§èƒ½ã€‚é€šè¿‡ç»“åˆSegResNetç¼–ç å™¨ã€æç¤ºç¼–ç å™¨å’Œæ©ç è§£ç å™¨ï¼Œå¹¶å¼•å…¥ç›¸å¯¹ä½ç½®ç¼–ç å’Œå½’ä¸€åŒ–æ³¨æ„åŠ›ç­‰æœºåˆ¶ï¼ŒENSAMèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨å›¾åƒä¿¡æ¯å’Œç”¨æˆ·æç¤ºä¿¡æ¯ï¼Œä»è€Œå®ç°å‡†ç¡®çš„åˆ†å‰²ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šENSAMé‡‡ç”¨U-Neté£æ ¼çš„æ¶æ„ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) SegResNetç¼–ç å™¨ï¼šç”¨äºæå–ä¸‰ç»´åŒ»å­¦å›¾åƒçš„ç‰¹å¾ï¼›2) æç¤ºç¼–ç å™¨ï¼šç”¨äºç¼–ç ç”¨æˆ·æä¾›çš„æç¤ºä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œç‚¹æˆ–æ¡†ï¼‰ï¼›3) æ©ç è§£ç å™¨ï¼šç”¨äºç”Ÿæˆåˆ†å‰²æ©ç ã€‚è¿™äº›æ¨¡å—é€šè¿‡æ½œåœ¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œè¿æ¥ï¼Œä»è€Œå®ç°å›¾åƒç‰¹å¾å’Œæç¤ºä¿¡æ¯çš„èåˆã€‚

**å…³é”®åˆ›æ–°**ï¼šENSAMçš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºå…¶è½»é‡çº§çš„è®¾è®¡å’Œå¯¹ç”¨æˆ·æç¤ºä¿¡æ¯çš„æœ‰æ•ˆåˆ©ç”¨ã€‚ä¸ç°æœ‰çš„æ–¹æ³•ç›¸æ¯”ï¼ŒENSAMèƒ½å¤Ÿåœ¨æœ‰é™çš„æ•°æ®å’Œè®¡ç®—èµ„æºä¸‹å®ç°å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œå¹¶ä¸”èƒ½å¤Ÿé€šè¿‡ç”¨æˆ·äº¤äº’æ¥æŒ‡å¯¼åˆ†å‰²è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œç›¸å¯¹ä½ç½®ç¼–ç å’Œå½’ä¸€åŒ–æ³¨æ„åŠ›çš„å¼•å…¥ä¹Ÿæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šENSAMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨SegResNetä½œä¸ºç¼–ç å™¨ï¼Œä»¥æå–æœ‰æ•ˆçš„å›¾åƒç‰¹å¾ï¼›2) å¼•å…¥ç›¸å¯¹ä½ç½®ç¼–ç ï¼Œä»¥æ›´å¥½åœ°æ•æ‰ç©ºé—´ä¿¡æ¯ï¼›3) ä½¿ç”¨å½’ä¸€åŒ–æ³¨æ„åŠ›ï¼Œä»¥æé«˜æ¨¡å‹çš„é²æ£’æ€§ï¼›4) ä½¿ç”¨Muonä¼˜åŒ–å™¨è¿›è¡Œè®­ç»ƒï¼Œä»¥åŠ å¿«æ”¶æ•›é€Ÿåº¦ï¼›5) é€šè¿‡æ½œåœ¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶èåˆå›¾åƒç‰¹å¾å’Œæç¤ºä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ENSAMåœ¨CVPR 2025 Foundation Models for Interactive 3D Biomedical Image Segmentation Challengeä¸­å–å¾—äº†ä¼˜å¼‚çš„æˆç»©ï¼Œåœ¨éšè—æµ‹è¯•é›†ä¸Šè·å¾—äº†2.404çš„DSC AUCã€2.266çš„NSD AUCã€0.627çš„æœ€ç»ˆDSCå’Œ0.597çš„æœ€ç»ˆNSDï¼Œä¼˜äºä¹‹å‰å‘è¡¨çš„ä¸¤ä¸ªåŸºçº¿æ¨¡å‹ï¼ˆVISTA3Dã€SAM-Med3Dï¼‰ï¼Œå¹¶åœ¨æœ€ç»ˆDSCæ–¹é¢è¶…è¿‡äº†SegVolã€‚æ¶ˆèç ”ç©¶è¡¨æ˜ï¼Œç›¸å¯¹ä½ç½®ç¼–ç å’ŒMuonä¼˜åŒ–å™¨èƒ½å¤Ÿæ˜¾è‘—æå‡æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ENSAMå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚è¾…åŠ©åŒ»ç”Ÿè¿›è¡Œç–¾ç—…è¯Šæ–­ã€æ‰‹æœ¯è§„åˆ’å’Œæ²»ç–—è¯„ä¼°ã€‚è¯¥æ¨¡å‹å¯ä»¥åº”ç”¨äºå¤šç§åŒ»å­¦å½±åƒæ¨¡æ€ï¼Œä¾‹å¦‚CTã€MRIã€PETå’Œè¶…å£°ï¼Œä»è€Œå®ç°å¯¹ä¸åŒç»„ç»‡å’Œå™¨å®˜çš„åˆ†å‰²ã€‚æ­¤å¤–ï¼ŒENSAMçš„è½»é‡çº§è®¾è®¡ä½¿å…¶èƒ½å¤Ÿåœ¨ç§»åŠ¨è®¾å¤‡æˆ–åµŒå…¥å¼ç³»ç»Ÿä¸Šéƒ¨ç½²ï¼Œä»è€Œå®ç°åºŠæ—è¯Šæ–­å’Œè¿œç¨‹åŒ»ç–—ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present ENSAM (Equivariant, Normalized, Segment Anything Model), a lightweight and promptable model for universal 3D medical image segmentation. ENSAM combines a SegResNet-based encoder with a prompt encoder and mask decoder in a U-Net-style architecture, using latent cross-attention, relative positional encoding, normalized attention, and the Muon optimizer for training. ENSAM is designed to achieve good performance under limited data and computational budgets, and is trained from scratch on under 5,000 volumes from multiple modalities (CT, MRI, PET, ultrasound, microscopy) on a single 32 GB GPU in 6 hours. As part of the CVPR 2025 Foundation Models for Interactive 3D Biomedical Image Segmentation Challenge, ENSAM was evaluated on hidden test set with multimodal 3D medical images, obtaining a DSC AUC of 2.404, NSD AUC of 2.266, final DSC of 0.627, and final NSD of 0.597, outperforming two previously published baseline models (VISTA3D, SAM-Med3D) and matching the third (SegVol), surpassing its performance in final DSC but trailing behind in the other three metrics. In the coreset track of the challenge, ENSAM ranks 5th of 10 overall and best among the approaches not utilizing pretrained weights. Ablation studies confirm that our use of relative positional encodings and the Muon optimizer each substantially speed up convergence and improve segmentation quality.

