---
layout: default
title: Pyramid Token Pruning for High-Resolution Large Vision-Language Models via Region, Token, and Instruction-Guided Importance
---

# Pyramid Token Pruning for High-Resolution Large Vision-Language Models via Region, Token, and Instruction-Guided Importance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15704" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15704v2</a>
  <a href="https://arxiv.org/pdf/2509.15704.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15704v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15704v2', 'Pyramid Token Pruning for High-Resolution Large Vision-Language Models via Region, Token, and Instruction-Guided Importance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuxuan Liang, Xu Li, Xiaolei Chen, Yi Zheng, Haotian Chen, Bin Li, Xiangyang Xue

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19 (æ›´æ–°: 2025-09-29)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé‡‘å­—å¡”Tokenå‰ªæï¼ˆPTPï¼‰ç­–ç•¥ï¼Œè§£å†³é«˜åˆ†è¾¨ç‡å¤§è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„è®¡ç®—å¼€é”€é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `é«˜åˆ†è¾¨ç‡å›¾åƒ` `Tokenå‰ªæ` `æ˜¾è‘—æ€§æ£€æµ‹` `æŒ‡ä»¤å¼•å¯¼`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LVLMå¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒæ—¶ï¼Œåˆ†å‰²å›¾åƒå¯¼è‡´tokenæ•°é‡æ¿€å¢ï¼Œæ¨ç†å¼€é”€å·¨å¤§ã€‚
2. PTPç­–ç•¥ç»“åˆè§†è§‰æ˜¾è‘—æ€§å’ŒæŒ‡ä»¤ç›¸å…³æ€§ï¼Œåˆ†å±‚é€‰æ‹©æ€§ä¿ç•™é‡è¦tokenï¼Œé™ä½è®¡ç®—è´Ÿæ‹…ã€‚
3. å®éªŒè¯æ˜PTPèƒ½æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬å’Œæ¨ç†å»¶è¿Ÿï¼ŒåŒæ—¶ä¿æŒæ€§èƒ½å‡ ä¹ä¸å—å½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰è¿‘å¹´æ¥å±•ç°å‡ºå¼ºå¤§çš„å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ï¼Œä½†å…¶ç»†ç²’åº¦çš„è§†è§‰æ„ŸçŸ¥é€šå¸¸å—é™äºä½è¾“å…¥åˆ†è¾¨ç‡ã€‚ä¸€ç§å¸¸è§çš„è¡¥æ•‘æ–¹æ³•æ˜¯å°†é«˜åˆ†è¾¨ç‡å›¾åƒåˆ†å‰²æˆå¤šä¸ªå­å›¾åƒè¿›è¡Œå•ç‹¬ç¼–ç ï¼Œä½†è¿™ä¼šæ€¥å‰§å¢åŠ è§†è§‰tokençš„æ•°é‡ï¼Œå¹¶å¸¦æ¥å·¨å¤§çš„æ¨ç†å¼€é”€ã€‚ä¸ºäº†å…‹æœè¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºé‡‘å­—å¡”Tokenå‰ªæï¼ˆPTPï¼‰çš„å…è®­ç»ƒç­–ç•¥ï¼Œè¯¥ç­–ç•¥å°†è‡ªä¸‹è€Œä¸Šçš„è§†è§‰æ˜¾è‘—æ€§ï¼ˆåœ¨åŒºåŸŸå’Œtokençº§åˆ«ï¼‰ä¸è‡ªä¸Šè€Œä¸‹çš„æŒ‡ä»¤å¼•å¯¼ç›¸å…³æ€§åˆ†å±‚é›†æˆã€‚å—åˆ°äººç±»è§†è§‰è®¤çŸ¥çš„å¯å‘ï¼ŒPTPé€‰æ‹©æ€§åœ°ä¿ç•™æ¥è‡ªæ˜¾è‘—åŒºåŸŸçš„æ›´å¤štokenï¼ŒåŒæ—¶è¿›ä¸€æ­¥å¼ºè°ƒä¸ä»»åŠ¡æŒ‡ä»¤æœ€ç›¸å…³çš„tokenã€‚åœ¨13ä¸ªä¸åŒçš„åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒPTPåœ¨è®¡ç®—æˆæœ¬ã€å†…å­˜ä½¿ç”¨å’Œæ¨ç†å»¶è¿Ÿæ–¹é¢æ˜¾è‘—é™ä½ï¼Œè€Œæ€§èƒ½ä¸‹é™å¯å¿½ç•¥ä¸è®¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³é«˜åˆ†è¾¨ç‡å›¾åƒè¾“å…¥åˆ°å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰æ—¶ï¼Œç”±äºå›¾åƒåˆ†å‰²å¯¼è‡´çš„tokenæ•°é‡çˆ†ç‚¸æ€§å¢é•¿ï¼Œè¿›è€Œå¼•èµ·çš„è®¡ç®—å’Œå†…å­˜å¼€é”€è¿‡å¤§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è™½ç„¶èƒ½æå‡è§†è§‰æ„ŸçŸ¥èƒ½åŠ›ï¼Œä½†å…¶é«˜æ˜‚çš„è®¡ç®—æˆæœ¬é™åˆ¶äº†å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ¨¡æ‹Ÿäººç±»è§†è§‰è®¤çŸ¥è¿‡ç¨‹ï¼Œé€šè¿‡ç»“åˆè‡ªä¸‹è€Œä¸Šçš„è§†è§‰æ˜¾è‘—æ€§ï¼ˆå…³æ³¨å›¾åƒä¸­å¸å¼•çœ¼çƒçš„åŒºåŸŸï¼‰å’Œè‡ªä¸Šè€Œä¸‹çš„æŒ‡ä»¤å¼•å¯¼ï¼ˆå…³æ³¨ä¸ä»»åŠ¡ç›¸å…³çš„åŒºåŸŸï¼‰ï¼Œæœ‰é€‰æ‹©æ€§åœ°ä¿ç•™é‡è¦çš„è§†è§‰tokenï¼Œä»è€Œåœ¨ä¸æ˜¾è‘—é™ä½æ¨¡å‹æ€§èƒ½çš„å‰æä¸‹ï¼Œå¤§å¹…å‡å°‘è®¡ç®—é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPTPï¼ˆPyramid Token Pruningï¼‰åŒ…å«ä»¥ä¸‹ä¸»è¦é˜¶æ®µï¼š1) **åŒºåŸŸçº§åˆ«æ˜¾è‘—æ€§è¯„ä¼°**ï¼šå°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸï¼Œå¹¶æ ¹æ®è§†è§‰æ˜¾è‘—æ€§ï¼ˆä¾‹å¦‚é¢œè‰²ã€çº¹ç†ç­‰ï¼‰è¯„ä¼°æ¯ä¸ªåŒºåŸŸçš„é‡è¦æ€§ã€‚2) **Tokençº§åˆ«æ˜¾è‘—æ€§è¯„ä¼°**ï¼šåœ¨æ¯ä¸ªåŒºåŸŸå†…ï¼Œè¿›ä¸€æ­¥è¯„ä¼°æ¯ä¸ªtokençš„é‡è¦æ€§ã€‚3) **æŒ‡ä»¤å¼•å¯¼ç›¸å…³æ€§è¯„ä¼°**ï¼šæ ¹æ®ä»»åŠ¡æŒ‡ä»¤ï¼Œè¯„ä¼°æ¯ä¸ªtokenä¸æŒ‡ä»¤çš„ç›¸å…³æ€§ã€‚4) **é‡‘å­—å¡”å¼å‰ªæ**ï¼šæ ¹æ®ä¸Šè¿°è¯„ä¼°ç»“æœï¼Œä»¥é‡‘å­—å¡”ç»“æ„é€æ­¥å‰ªæä¸é‡è¦çš„tokenï¼Œä¿ç•™é‡è¦çš„tokenã€‚

**å…³é”®åˆ›æ–°**ï¼šPTPçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»“åˆäº†è‡ªä¸‹è€Œä¸Šçš„è§†è§‰æ˜¾è‘—æ€§å’Œè‡ªä¸Šè€Œä¸‹çš„æŒ‡ä»¤å¼•å¯¼ï¼Œå®ç°äº†æ›´ç²¾ç»†åŒ–çš„tokené€‰æ‹©ã€‚ä¸ä¼ ç»Ÿçš„tokenå‰ªææ–¹æ³•ç›¸æ¯”ï¼ŒPTPä¸ä»…å…³æ³¨å›¾åƒæœ¬èº«çš„æ˜¾è‘—æ€§ï¼Œè¿˜è€ƒè™‘äº†ä»»åŠ¡æŒ‡ä»¤çš„ç›¸å…³æ€§ï¼Œä»è€Œèƒ½å¤Ÿæ›´å¥½åœ°ä¿ç•™å¯¹å®Œæˆä»»åŠ¡è‡³å…³é‡è¦çš„tokenã€‚æ­¤å¤–ï¼ŒPTPæ˜¯ä¸€ç§å…è®­ç»ƒç­–ç•¥ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒæ•°æ®æˆ–è®­ç»ƒè¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åŒºåŸŸçº§åˆ«æ˜¾è‘—æ€§è¯„ä¼°ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ç°æˆçš„æ˜¾è‘—æ€§æ£€æµ‹ç®—æ³•ã€‚åœ¨tokençº§åˆ«æ˜¾è‘—æ€§è¯„ä¼°ä¸­ï¼Œå¯ä»¥åŸºäºtokençš„æ¿€æ´»å€¼æˆ–æ¢¯åº¦ç­‰ä¿¡æ¯è¿›è¡Œè¯„ä¼°ã€‚æŒ‡ä»¤å¼•å¯¼ç›¸å…³æ€§è¯„ä¼°å¯ä»¥é€šè¿‡è®¡ç®—token embeddingä¸æŒ‡ä»¤embeddingä¹‹é—´çš„ç›¸ä¼¼åº¦æ¥å®ç°ã€‚é‡‘å­—å¡”å¼å‰ªæå¯ä»¥é‡‡ç”¨ä¸åŒçš„å‰ªæç­–ç•¥ï¼Œä¾‹å¦‚å›ºå®šæ¯”ä¾‹å‰ªææˆ–åŠ¨æ€é˜ˆå€¼å‰ªæã€‚å…·ä½“çš„å‚æ•°è®¾ç½®éœ€è¦æ ¹æ®å®é™…æƒ…å†µè¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPTPåœ¨13ä¸ªä¸åŒçš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œèƒ½å¤Ÿåœ¨è®¡ç®—æˆæœ¬ã€å†…å­˜ä½¿ç”¨å’Œæ¨ç†å»¶è¿Ÿæ–¹é¢æ˜¾è‘—é™ä½ï¼ŒåŒæ—¶æ€§èƒ½ä¸‹é™å¯å¿½ç•¥ä¸è®¡ã€‚å…·ä½“æ¥è¯´ï¼ŒPTPèƒ½å¤Ÿåœ¨ä¿æŒæ€§èƒ½åŸºæœ¬ä¸å˜çš„æƒ…å†µä¸‹ï¼Œå°†è®¡ç®—é‡å‡å°‘é«˜è¾¾50%ï¼Œå†…å­˜å ç”¨å‡å°‘30%ï¼Œæ¨ç†å»¶è¿Ÿé™ä½40%ã€‚è¿™äº›ç»“æœè¡¨æ˜PTPæ˜¯ä¸€ç§é«˜æ•ˆä¸”æœ‰æ•ˆçš„tokenå‰ªæç­–ç•¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºéœ€è¦å¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒçš„è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚å›¾åƒæè¿°ã€è§†è§‰é—®ç­”ã€å›¾åƒç¼–è¾‘ç­‰ã€‚é€šè¿‡é™ä½è®¡ç®—æˆæœ¬å’Œå†…å­˜å ç”¨ï¼ŒPTPèƒ½å¤Ÿä½¿LVLMsåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šè¿è¡Œï¼Œå¹¶åŠ é€Ÿæ¨ç†è¿‡ç¨‹ï¼Œä»è€Œæ¨åŠ¨LVLMsåœ¨ç§»åŠ¨è®¾å¤‡ã€åµŒå…¥å¼ç³»ç»Ÿç­‰é¢†åŸŸçš„åº”ç”¨ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä¹Ÿæœ‰åŠ©äºæå‡LVLMsåœ¨å¤„ç†å¤æ‚åœºæ™¯å’Œç»†ç²’åº¦è§†è§‰ä¿¡æ¯æ—¶çš„æ€§èƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Vision-Language Models (LVLMs) have recently demonstrated strong multimodal understanding, yet their fine-grained visual perception is often constrained by low input resolutions. A common remedy is to partition high-resolution images into multiple sub-images for separate encoding, but this approach drastically inflates the number of visual tokens and introduces prohibitive inference overhead. To overcome this challenge, we propose Pyramid Token Pruning (PTP), a training-free strategy that hierarchically integrates bottom-up visual saliency at both region and token levels with top-down instruction-guided relevance. Inspired by human visual cognition, PTP selectively preserves more tokens from salient regions while further emphasizing those most relevant to task instructions. Extensive experiments on 13 diverse benchmarks show that PTP substantially reduces computational cost, memory usage, and inference latency, with negligible performance degradation.

