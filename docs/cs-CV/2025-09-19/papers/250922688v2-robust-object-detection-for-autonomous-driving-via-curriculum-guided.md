---
layout: default
title: Robust Object Detection for Autonomous Driving via Curriculum-Guided Group Relative Policy Optimization
---

# Robust Object Detection for Autonomous Driving via Curriculum-Guided Group Relative Policy Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22688" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22688v2</a>
  <a href="https://arxiv.org/pdf/2509.22688.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22688v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22688v2', 'Robust Object Detection for Autonomous Driving via Curriculum-Guided Group Relative Policy Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xu Jia

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19 (æ›´æ–°: 2025-10-07)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯¾ç¨‹å¼•å¯¼çš„ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼Œæå‡è‡ªåŠ¨é©¾é©¶ç›®æ ‡æ£€æµ‹çš„é²æ£’æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `ç›®æ ‡æ£€æµ‹` `å¼ºåŒ–å­¦ä¹ ` `è¯¾ç¨‹å­¦ä¹ ` `ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–` `é²æ£’æ€§` `å¤šæ¨¡æ€`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç›®æ ‡æ£€æµ‹æ–¹æ³•åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­ï¼Œé¢å¯¹å¤æ‚ç¯å¢ƒå’Œå™ªå£°æ•°æ®æ—¶ï¼Œé²æ£’æ€§ä¸è¶³ï¼Œéš¾ä»¥ä¿è¯æ£€æµ‹ç²¾åº¦ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¡†æ¶ï¼Œç»“åˆè¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œå¼•å¯¼æ¨¡å‹é€æ­¥é€‚åº”å¤æ‚æ ·æœ¬ï¼Œæå‡æ£€æµ‹æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è‡ªåŠ¨é©¾é©¶æ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†æ£€æµ‹ç²¾åº¦å’Œé²æ£’æ€§ï¼ŒéªŒè¯äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹(MLLMs)åœ¨è§†è§‰-è¯­è¨€æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†é€šå¸¸åœ¨éœ€è¦ç²¾ç¡®å®šä½å’Œé²æ£’æ€§çš„ç»“æ„åŒ–æ„ŸçŸ¥ä»»åŠ¡ä¸­é‡åˆ°å›°éš¾ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡åŸºäºè¯¾ç¨‹çš„æ•°æ®è°ƒåº¦å’Œéš¾åº¦æ„ŸçŸ¥è¿‡æ»¤æ¥å¢å¼ºç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)ã€‚è¿™ç§æ–¹æ³•ç¨³å®šäº†ç¨€ç–ã€å™ªå£°å¥–åŠ±ä¸‹çš„ä¼˜åŒ–ï¼Œå¹¶å®ç°äº†å¯¹å¤æ‚æ ·æœ¬çš„æ¸è¿›å¼é€‚åº”ã€‚åœ¨è‡ªåŠ¨é©¾é©¶åŸºå‡†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œæ£€æµ‹ç²¾åº¦å’Œé²æ£’æ€§å¾—åˆ°äº†æ˜¾è‘—æé«˜ã€‚æ¶ˆèç ”ç©¶è¯å®äº†å¥–åŠ±è®¾è®¡ã€KLæ­£åˆ™åŒ–å’Œè¯¾ç¨‹æ­¥è°ƒå¯¹äºæ”¶æ•›ç¨³å®šæ€§å’Œæ³›åŒ–çš„é‡è¦æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå…·æœ‰ç»“æ„åŒ–æ•°æ®è¯¾ç¨‹çš„å¼ºåŒ–å­¦ä¹ é©±åŠ¨ä¼˜åŒ–æ˜¯å®ç°é²æ£’ä¸”å¯è§£é‡Šçš„å¤šæ¨¡æ€æ£€æµ‹çš„å¯æ‰©å±•é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸‹çš„ç›®æ ‡æ£€æµ‹ä»»åŠ¡é¢ä¸´ç€ç¯å¢ƒå¤æ‚ã€å…‰ç…§å˜åŒ–ã€é®æŒ¡ä¸¥é‡ä»¥åŠæ•°æ®å™ªå£°ç­‰è¯¸å¤šæŒ‘æˆ˜ï¼Œå¯¼è‡´ç°æœ‰ç›®æ ‡æ£€æµ‹ç®—æ³•çš„é²æ£’æ€§è¾ƒå·®ï¼Œéš¾ä»¥æ»¡è¶³å®é™…åº”ç”¨çš„éœ€æ±‚ã€‚å°¤å…¶æ˜¯åœ¨ç¨€ç–å’Œå™ªå£°å¥–åŠ±çš„æƒ…å†µä¸‹ï¼Œä¼˜åŒ–è¿‡ç¨‹æ›´åŠ å›°éš¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ æ¥ä¼˜åŒ–ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼Œå¹¶å¼•å…¥è¯¾ç¨‹å­¦ä¹ çš„æ€æƒ³ï¼Œè®©æ¨¡å‹ä»ç®€å•åˆ°å¤æ‚é€æ­¥å­¦ä¹ ã€‚é€šè¿‡ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)æ¥ç¨³å®šä¼˜åŒ–è¿‡ç¨‹ï¼Œå¹¶ä½¿ç”¨éš¾åº¦æ„ŸçŸ¥è¿‡æ»¤æ¥é€‰æ‹©æ›´æœ‰ä»·å€¼çš„è®­ç»ƒæ ·æœ¬ã€‚è¿™æ ·å¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨æ•°æ®ï¼Œæé«˜æ¨¡å‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼šä½œä¸ºå¼ºåŒ–å­¦ä¹ çš„agentï¼Œè´Ÿè´£ç”Ÿæˆç›®æ ‡æ£€æµ‹ç»“æœã€‚2) å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼šæ¨¡æ‹Ÿè‡ªåŠ¨é©¾é©¶åœºæ™¯ï¼Œæä¾›è®­ç»ƒæ•°æ®å’Œå¥–åŠ±ä¿¡å·ã€‚3) ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)ï¼šç”¨äºç¨³å®šå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒè¿‡ç¨‹ã€‚4) è¯¾ç¨‹å­¦ä¹ æ¨¡å—ï¼šæ ¹æ®æ ·æœ¬çš„éš¾åº¦ï¼ŒåŠ¨æ€è°ƒæ•´è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒã€‚5) éš¾åº¦æ„ŸçŸ¥è¿‡æ»¤ï¼šè¿‡æ»¤æ‰å¯¹æ¨¡å‹è®­ç»ƒæ²¡æœ‰å¸®åŠ©çš„æ ·æœ¬ã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼Œç›®æ ‡æ£€æµ‹æ¨¡å‹åœ¨å¼ºåŒ–å­¦ä¹ ç¯å¢ƒä¸­è¿›è¡Œè®­ç»ƒï¼Œæ ¹æ®æ£€æµ‹ç»“æœè·å¾—å¥–åŠ±ï¼Œç„¶ååˆ©ç”¨GRPOæ›´æ–°æ¨¡å‹å‚æ•°ã€‚è¯¾ç¨‹å­¦ä¹ æ¨¡å—å’Œéš¾åº¦æ„ŸçŸ¥è¿‡æ»¤æ¨¡å—åˆ™è´Ÿè´£é€‰æ‹©åˆé€‚çš„è®­ç»ƒæ•°æ®ï¼Œä»¥æé«˜è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†è¯¾ç¨‹å­¦ä¹ å’Œç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ç›¸ç»“åˆï¼Œç”¨äºè§£å†³è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸‹çš„ç›®æ ‡æ£€æµ‹é—®é¢˜ã€‚ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶ï¼Œå®¹æ˜“å‡ºç°è®­ç»ƒä¸ç¨³å®šå’Œæ”¶æ•›é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚è€Œè¯¾ç¨‹å­¦ä¹ å¯ä»¥æœ‰æ•ˆåœ°å¼•å¯¼æ¨¡å‹é€æ­¥å­¦ä¹ ï¼Œæé«˜è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚GRPOåˆ™å¯ä»¥ç¨³å®šå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒè¿‡ç¨‹ï¼Œé¿å…å‡ºç°æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸ç­‰é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è¯¾ç¨‹å­¦ä¹ æ–¹é¢ï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ç§åŸºäºæ ·æœ¬éš¾åº¦çš„è¯¾ç¨‹ç­–ç•¥ï¼Œæ ¹æ®æ ·æœ¬çš„æ£€æµ‹éš¾åº¦ï¼ŒåŠ¨æ€è°ƒæ•´è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒã€‚åœ¨å¥–åŠ±å‡½æ•°è®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡ç»¼åˆè€ƒè™‘äº†æ£€æµ‹ç²¾åº¦ã€å¬å›ç‡å’Œå®šä½ç²¾åº¦ç­‰å› ç´ ï¼Œè®¾è®¡äº†ä¸€ä¸ªç»¼åˆæ€§çš„å¥–åŠ±å‡½æ•°ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ä½¿ç”¨äº†KLæ­£åˆ™åŒ–æ¥çº¦æŸç­–ç•¥çš„æ›´æ–°ï¼Œé¿å…å‡ºç°ç­–ç•¥æ¼‚ç§»çš„é—®é¢˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨è‡ªåŠ¨é©¾é©¶æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œæ£€æµ‹ç²¾åº¦æé«˜äº†X%ï¼Œé²æ£’æ€§æé«˜äº†Y%ã€‚æ¶ˆèç ”ç©¶éªŒè¯äº†å¥–åŠ±è®¾è®¡ã€KLæ­£åˆ™åŒ–å’Œè¯¾ç¨‹æ­¥è°ƒå¯¹äºæ”¶æ•›ç¨³å®šæ€§å’Œæ³›åŒ–çš„é‡è¦æ€§ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¯ä¸€ç§æœ‰æ•ˆçš„è‡ªåŠ¨é©¾é©¶ç›®æ ‡æ£€æµ‹è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½äº¤é€šã€æœºå™¨äººç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜ç›®æ ‡æ£€æµ‹çš„é²æ£’æ€§å’Œç²¾åº¦ï¼Œå¯ä»¥æå‡è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§ï¼Œå‡å°‘äº¤é€šäº‹æ•…çš„å‘ç”Ÿã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºæ™ºèƒ½ç›‘æ§ã€å®‰é˜²ç­‰é¢†åŸŸï¼Œæé«˜ç›®æ ‡è¯†åˆ«å’Œè·Ÿè¸ªçš„å‡†ç¡®æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„å¸‚åœºå‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) excel in vision-language reasoning but often struggle with structured perception tasks requiring precise localization and robustness. We propose a reinforcement learning framework that augments Group Relative Policy Optimization (GRPO) with curriculum-based data scheduling and difficulty-aware filtering. This approach stabilizes optimization under sparse, noisy rewards and enables progressive adaptation to complex samples. Evaluations on autonomous driving benchmarks demonstrate substantial improvements in detection accuracy and robustness. Ablation studies confirm the importance of reward design, KL regularization, and curriculum pacing for convergence stability and generalization. Our findings highlight reinforcement-driven optimization with structured data curricula as a scalable path toward robust and interpretable multimodal detection.

