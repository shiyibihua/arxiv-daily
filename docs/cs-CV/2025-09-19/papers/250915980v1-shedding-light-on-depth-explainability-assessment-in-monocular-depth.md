---
layout: default
title: Shedding Light on Depth: Explainability Assessment in Monocular Depth Estimation
---

# Shedding Light on Depth: Explainability Assessment in Monocular Depth Estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15980" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15980v1</a>
  <a href="https://arxiv.org/pdf/2509.15980.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15980v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15980v1', 'Shedding Light on Depth: Explainability Assessment in Monocular Depth Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lorenzo Cirillo, Claudio Schiavella, Lorenzo Papa, Paolo Russo, Irene Amerini

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

**å¤‡æ³¨**: 8 pages, 3 figures, 2 tables. This paper has been accepted at the International Joint Conference on Neural Networks (IJCNN) 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å•ç›®æ·±åº¦ä¼°è®¡å¯è§£é‡Šæ€§ç ”ç©¶ï¼šæå‡ºAttribution Fidelityè¯„ä¼°è§£é‡Šå¯é æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å•ç›®æ·±åº¦ä¼°è®¡` `å¯è§£é‡Šæ€§` `ç‰¹å¾å½’å› ` `Saliency Maps` `Integrated Gradients` `Attribution Fidelity` `æ·±åº¦å­¦ä¹ ` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å•ç›®æ·±åº¦ä¼°è®¡å¯è§£é‡Šæ€§ä¸è¶³ï¼Œé˜»ç¢äº†å…¶åœ¨å®‰å…¨æ”¸å…³åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œéœ€è¦æ·±å…¥ç†è§£æ¨¡å‹å†³ç­–è¿‡ç¨‹ã€‚
2. é€šè¿‡åˆ†æç‰¹å¾å½’å› æ–¹æ³•åœ¨MDEæ¨¡å‹ä¸­çš„è¡¨ç°ï¼Œå¹¶æå‡ºAttribution FidelityæŒ‡æ ‡ï¼Œè¯„ä¼°è§£é‡Šçš„å¯é æ€§ã€‚
3. å®éªŒè¡¨æ˜Saliency Mapså’ŒIntegrated Gradientsåœ¨ä¸åŒæ¨¡å‹ä¸Šè¡¨ç°å„å¼‚ï¼ŒAttribution Fidelityèƒ½æœ‰æ•ˆè¯†åˆ«è§£é‡Šå¤±æ•ˆæƒ…å†µã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡è‡´åŠ›äºç ”ç©¶å•ç›®æ·±åº¦ä¼°è®¡(MDE)ç½‘ç»œçš„å¯è§£é‡Šæ€§ï¼Œæ—¨åœ¨ç†è§£è¾“å…¥å›¾åƒåˆ°é¢„æµ‹æ·±åº¦å›¾çš„æ˜ å°„è¿‡ç¨‹ã€‚å°½ç®¡MDEå·²å¹¿æ³›åº”ç”¨äºç°å®åœºæ™¯ï¼Œä½†å…¶å¯è§£é‡Šæ€§ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡ç ”ç©¶äº†ä¸‰ç§ç‰¹å¾å½’å› æ–¹æ³•ï¼šSaliency Mapsã€Integrated Gradientså’ŒAttention Rolloutï¼Œåº”ç”¨äºä¸¤ç§è®¡ç®—å¤æ‚åº¦ä¸åŒçš„MDEæ¨¡å‹ï¼šè½»é‡çº§ç½‘ç»œMETERå’Œæ·±åº¦ç½‘ç»œPixelFormerã€‚é€šè¿‡é€‰æ‹©æ€§åœ°æ‰°åŠ¨ç”±å¯è§£é‡Šæ€§æ–¹æ³•è¯†åˆ«çš„æœ€ç›¸å…³å’Œæœ€ä¸ç›¸å…³çš„åƒç´ ï¼Œå¹¶åˆ†æè¿™äº›æ‰°åŠ¨å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ï¼Œæ¥è¯„ä¼°ç”Ÿæˆçš„å¯è§†åŒ–è§£é‡Šçš„è´¨é‡ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹ç°æœ‰è¯„ä¼°æŒ‡æ ‡åœ¨è¡¡é‡MDEå¯è§†åŒ–è§£é‡Šæœ‰æ•ˆæ€§æ–¹é¢çš„å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æŒ‡æ ‡ï¼šAttribution Fidelityï¼Œé€šè¿‡è¯„ä¼°ç‰¹å¾å½’å› ä¸é¢„æµ‹æ·±åº¦å›¾çš„ä¸€è‡´æ€§æ¥è¡¡é‡å…¶å¯é æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSaliency Mapså’ŒIntegrated Gradientsåœ¨åˆ†åˆ«çªå‡ºæ˜¾ç¤ºè½»é‡çº§å’Œæ·±åº¦MDEæ¨¡å‹çš„æœ€é‡è¦è¾“å…¥ç‰¹å¾æ–¹é¢è¡¨ç°è‰¯å¥½ã€‚æ­¤å¤–ï¼ŒAttribution Fidelityèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å¯è§£é‡Šæ€§æ–¹æ³•æœªèƒ½äº§ç”Ÿå¯é å¯è§†åŒ–å›¾çš„æƒ…å†µï¼Œå³ä½¿åœ¨ä¼ ç»ŸæŒ‡æ ‡å¯èƒ½æ˜¾ç¤ºä»¤äººæ»¡æ„çš„ç»“æœçš„æƒ…å†µä¸‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå•ç›®æ·±åº¦ä¼°è®¡(MDE)åœ¨è®¸å¤šå®é™…åº”ç”¨ä¸­å‘æŒ¥ä½œç”¨ï¼Œä½†å…¶å†…éƒ¨å†³ç­–è¿‡ç¨‹å¦‚åŒé»‘ç›’ï¼Œç¼ºä¹é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆè¯„ä¼°MDEæ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¯è§†åŒ–è§£é‡Šçš„å¯é æ€§æ–¹é¢ï¼Œä¼ ç»ŸæŒ‡æ ‡å¯èƒ½æ— æ³•å‡†ç¡®åæ˜ è§£é‡Šçš„è´¨é‡ã€‚å› æ­¤ï¼Œå¦‚ä½•ç†è§£MDEç½‘ç»œå¦‚ä½•ä»è¾“å…¥å›¾åƒé¢„æµ‹æ·±åº¦å›¾ï¼Œå¹¶è¯„ä¼°è§£é‡Šçš„å¯é æ€§ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç‰¹å¾å½’å› æ–¹æ³•æ¥çªå‡ºæ˜¾ç¤ºè¾“å…¥å›¾åƒä¸­å¯¹æ·±åº¦é¢„æµ‹è´¡çŒ®æœ€å¤§çš„åŒºåŸŸï¼Œå¹¶è®¾è®¡æ–°çš„è¯„ä¼°æŒ‡æ ‡æ¥è¡¡é‡è¿™äº›å½’å› çš„å¯é æ€§ã€‚é€šè¿‡æ‰°åŠ¨å›¾åƒä¸­çš„å…³é”®åŒºåŸŸï¼Œè§‚å¯Ÿæ¨¡å‹è¾“å‡ºçš„å˜åŒ–ï¼Œä»è€ŒéªŒè¯å½’å› çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæå‡ºAttribution FidelityæŒ‡æ ‡ï¼Œç›´æ¥è¯„ä¼°å½’å› ä¸é¢„æµ‹æ·±åº¦å›¾çš„ä¸€è‡´æ€§ï¼Œä»è€Œæ›´å…¨é¢åœ°è¯„ä¼°è§£é‡Šçš„å¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæœ¬æ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) é€‰æ‹©ä¸¤ç§å…·æœ‰ä»£è¡¨æ€§çš„MDEæ¨¡å‹ï¼ˆMETERå’ŒPixelFormerï¼‰ï¼›2) åº”ç”¨ä¸‰ç§ç‰¹å¾å½’å› æ–¹æ³•ï¼ˆSaliency Mapsã€Integrated Gradientså’ŒAttention Rolloutï¼‰ç”Ÿæˆå¯è§†åŒ–è§£é‡Šï¼›3) é€šè¿‡æ‰°åŠ¨è¾“å…¥å›¾åƒçš„å…³é”®åŒºåŸŸæ¥è¯„ä¼°è§£é‡Šçš„æœ‰æ•ˆæ€§ï¼›4) æå‡ºå¹¶ä½¿ç”¨Attribution FidelityæŒ‡æ ‡è¯„ä¼°è§£é‡Šçš„å¯é æ€§ã€‚æ•´ä¸ªæµç¨‹æ—¨åœ¨ç³»ç»Ÿåœ°åˆ†æå’Œè¯„ä¼°MDEæ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†Attribution FidelityæŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°MDEæ¨¡å‹å¯è§†åŒ–è§£é‡Šçš„å¯é æ€§ã€‚ä¸ä¼ ç»Ÿçš„è¯„ä¼°æŒ‡æ ‡ä¸åŒï¼ŒAttribution Fidelityç›´æ¥è¡¡é‡ç‰¹å¾å½’å› ä¸é¢„æµ‹æ·±åº¦å›¾ä¹‹é—´çš„ä¸€è‡´æ€§ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°åæ˜ è§£é‡Šçš„è´¨é‡ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡ç³»ç»Ÿåœ°æ¯”è¾ƒäº†ä¸åŒç‰¹å¾å½’å› æ–¹æ³•åœ¨ä¸åŒMDEæ¨¡å‹ä¸Šçš„è¡¨ç°ï¼Œä¸ºé€‰æ‹©åˆé€‚çš„å¯è§£é‡Šæ€§æ–¹æ³•æä¾›äº†æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šAttribution Fidelityçš„è®¡ç®—æ–¹å¼æ˜¯åŸºäºç‰¹å¾å½’å› å›¾å’Œé¢„æµ‹æ·±åº¦å›¾ä¹‹é—´çš„ç›¸å…³æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆå¯¹ç‰¹å¾å½’å› å›¾å’Œæ·±åº¦å›¾è¿›è¡Œå½’ä¸€åŒ–ï¼Œç„¶åè®¡ç®—å®ƒä»¬ä¹‹é—´çš„çš®å°”é€Šç›¸å…³ç³»æ•°ã€‚ç›¸å…³ç³»æ•°è¶Šé«˜ï¼Œè¯´æ˜ç‰¹å¾å½’å› ä¸æ·±åº¦é¢„æµ‹è¶Šä¸€è‡´ï¼Œè§£é‡Šçš„å¯é æ€§è¶Šé«˜ã€‚æ­¤å¤–ï¼Œåœ¨æ‰°åŠ¨å®éªŒä¸­ï¼Œé€‰æ‹©æ€§åœ°é®æŒ¡æˆ–ä¿ç•™ç”±ç‰¹å¾å½’å› æ–¹æ³•è¯†åˆ«çš„æœ€é‡è¦å’Œæœ€ä¸é‡è¦çš„åƒç´ ï¼Œå¹¶è§‚å¯Ÿæ¨¡å‹è¾“å‡ºçš„å˜åŒ–ï¼Œä»è€Œè¯„ä¼°è§£é‡Šçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSaliency Mapsåœ¨è½»é‡çº§æ¨¡å‹METERä¸Šè¡¨ç°è‰¯å¥½ï¼Œè€ŒIntegrated Gradientsåœ¨æ·±åº¦æ¨¡å‹PixelFormerä¸Šæ›´æœ‰æ•ˆã€‚Attribution Fidelityèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«ä¼ ç»ŸæŒ‡æ ‡å¯èƒ½æ— æ³•æ£€æµ‹åˆ°çš„è§£é‡Šå¤±æ•ˆæƒ…å†µã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå³ä½¿æ‰°åŠ¨å®éªŒæ˜¾ç¤ºäº†ä»¤äººæ»¡æ„çš„ç»“æœï¼ŒAttribution Fidelityä»ç„¶å¯ä»¥æ£€æµ‹åˆ°ç‰¹å¾å½’å› ä¸æ·±åº¦é¢„æµ‹ä¹‹é—´çš„ä¸ä¸€è‡´æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€ä¸‰ç»´é‡å»ºç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜å•ç›®æ·±åº¦ä¼°è®¡çš„å¯è§£é‡Šæ€§ï¼Œå¯ä»¥å¢å¼ºäººä»¬å¯¹æ¨¡å‹é¢„æµ‹ç»“æœçš„ä¿¡ä»»ï¼Œä»è€Œä¿ƒè¿›å…¶åœ¨å®‰å…¨æ”¸å…³åœºæ™¯ä¸­çš„åº”ç”¨ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢æ›´æœ‰æ•ˆçš„å¯è§£é‡Šæ€§æ–¹æ³•ï¼Œå¹¶å°†å…¶åº”ç”¨äºæ›´å¤æ‚çš„æ·±åº¦ä¼°è®¡æ¨¡å‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Explainable artificial intelligence is increasingly employed to understand the decision-making process of deep learning models and create trustworthiness in their adoption. However, the explainability of Monocular Depth Estimation (MDE) remains largely unexplored despite its wide deployment in real-world applications. In this work, we study how to analyze MDE networks to map the input image to the predicted depth map. More in detail, we investigate well-established feature attribution methods, Saliency Maps, Integrated Gradients, and Attention Rollout on different computationally complex models for MDE: METER, a lightweight network, and PixelFormer, a deep network. We assess the quality of the generated visual explanations by selectively perturbing the most relevant and irrelevant pixels, as identified by the explainability methods, and analyzing the impact of these perturbations on the model's output. Moreover, since existing evaluation metrics can have some limitations in measuring the validity of visual explanations for MDE, we additionally introduce the Attribution Fidelity. This metric evaluates the reliability of the feature attribution by assessing their consistency with the predicted depth map. Experimental results demonstrate that Saliency Maps and Integrated Gradients have good performance in highlighting the most important input features for MDE lightweight and deep models, respectively. Furthermore, we show that Attribution Fidelity effectively identifies whether an explainability method fails to produce reliable visual maps, even in scenarios where conventional metrics might suggest satisfactory results.

