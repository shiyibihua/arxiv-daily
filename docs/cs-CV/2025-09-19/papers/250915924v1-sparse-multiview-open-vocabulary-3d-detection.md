---
layout: default
title: Sparse Multiview Open-Vocabulary 3D Detection
---

# Sparse Multiview Open-Vocabulary 3D Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15924" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15924v1</a>
  <a href="https://arxiv.org/pdf/2509.15924.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15924v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15924v1', 'Sparse Multiview Open-Vocabulary 3D Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Olivier Moliner, Viktor Larsson, Kalle Ã…strÃ¶m

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

**å¤‡æ³¨**: ICCV 2025; OpenSUN3D Workshop; Camera ready version

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§ç¨€ç–å¤šè§†è§’å¼€æ”¾è¯æ±‡3Dæ£€æµ‹æ–¹æ³•ï¼Œæ— éœ€è®­ç»ƒä¸”æ€§èƒ½ä¼˜å¼‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dç›®æ ‡æ£€æµ‹` `å¼€æ”¾è¯æ±‡` `å¤šè§†è§’` `ç¨€ç–è§†è§’` `é¢„è®­ç»ƒæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿ3Dç›®æ ‡æ£€æµ‹ä¾èµ–å›ºå®šç±»åˆ«è®­ç»ƒï¼Œæ³›åŒ–èƒ½åŠ›å—é™ï¼Œéš¾ä»¥é€‚åº”å¼€æ”¾è¯æ±‡åœºæ™¯ã€‚
2. åˆ©ç”¨é¢„è®­ç»ƒ2Dæ¨¡å‹ï¼Œé€šè¿‡è§†è§’ä¸€è‡´æ€§ä¼˜åŒ–3D proposalsï¼Œé¿å…æ˜‚è´µçš„3Dç‰¹å¾å­¦ä¹ ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç¨€ç–è§†è§’ä¸‹æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå¹¶åœ¨å¯†é›†è§†è§’ä¸‹å…·æœ‰ç«äº‰åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†å…·æœ‰æŒ‘æˆ˜æ€§ä½†å®ç”¨çš„ç¨€ç–è§†è§’ä¸‹çš„å¼€æ”¾è¯æ±‡3Dç›®æ ‡æ£€æµ‹é—®é¢˜ï¼Œå³ä»…ä½¿ç”¨æœ‰é™æ•°é‡çš„å¸¦ä½å§¿RGBå›¾åƒä½œä¸ºè¾“å…¥ã€‚è¯¥æ–¹æ³•æ— éœ€è®­ç»ƒï¼Œè€Œæ˜¯ä¾èµ–äºé¢„è®­ç»ƒçš„ã€ç°æˆçš„2DåŸºç¡€æ¨¡å‹ï¼Œé¿å…äº†è®¡ç®—é‡å¤§çš„3Dç‰¹å¾èåˆæˆ–éœ€è¦3Dç‰¹å®šå­¦ä¹ ã€‚é€šè¿‡æå‡2Dæ£€æµ‹ç»“æœå¹¶ç›´æ¥ä¼˜åŒ–3D proposalsï¼Œä»¥å®ç°è·¨è§†è§’çš„ç‰¹å¾åº¦é‡ä¸€è‡´æ€§ï¼Œå……åˆ†åˆ©ç”¨äº†2Dä¸­å¯ç”¨çš„æµ·é‡è®­ç»ƒæ•°æ®ã€‚é€šè¿‡æ ‡å‡†åŸºå‡†æµ‹è¯•ï¼Œè¯æ˜äº†è¯¥ç®€å•æµç¨‹å»ºç«‹äº†ä¸€ä¸ªå¼ºå¤§çš„åŸºçº¿ï¼Œåœ¨å¯†é›†é‡‡æ ·åœºæ™¯ä¸­ä¸æœ€å…ˆè¿›çš„æŠ€æœ¯ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›ï¼Œå¹¶ä¸”åœ¨ç¨€ç–è§†è§’è®¾ç½®ä¸­æ˜¾è‘—ä¼˜äºå®ƒä»¬ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç¨€ç–å¤šè§†è§’ä¸‹çš„å¼€æ”¾è¯æ±‡3Dç›®æ ‡æ£€æµ‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦é’ˆå¯¹ç‰¹å®šç±»åˆ«è¿›è¡Œ3Dæ•°æ®è®­ç»ƒï¼Œæ³›åŒ–èƒ½åŠ›å·®ï¼Œæ— æ³•æ£€æµ‹æœªè§è¿‡çš„ç‰©ä½“ç±»åˆ«ã€‚æ­¤å¤–ï¼Œç›´æ¥è¿›è¡Œ3Dç‰¹å¾èåˆè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œä¸”åœ¨ç¨€ç–è§†è§’ä¸‹æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„2Dè§†è§‰åŸºç¡€æ¨¡å‹ï¼Œå°†2Dæ£€æµ‹ç»“æœæå‡åˆ°3Dç©ºé—´ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–3D proposalsæ¥å®ç°è·¨è§†è§’çš„ç‰¹å¾åº¦é‡ä¸€è‡´æ€§ã€‚è¿™æ ·å¯ä»¥å……åˆ†åˆ©ç”¨2Dé¢†åŸŸçš„å¤§é‡è®­ç»ƒæ•°æ®ï¼Œé¿å…ç›´æ¥è¿›è¡Œ3Dç‰¹å¾å­¦ä¹ ï¼Œä»è€Œå®ç°å¼€æ”¾è¯æ±‡çš„3Dç›®æ ‡æ£€æµ‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹å¦‚ä¸‹ï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„2Dç›®æ ‡æ£€æµ‹å™¨åœ¨å¤šä¸ªè§†è§’å›¾åƒä¸­æ£€æµ‹ç‰©ä½“ã€‚2) å°†2Dæ£€æµ‹ç»“æœåæŠ•å½±åˆ°3Dç©ºé—´ï¼Œç”Ÿæˆ3D proposalsã€‚3) å¯¹æ¯ä¸ª3D proposalï¼Œæå–å…¶åœ¨å„ä¸ªè§†è§’ä¸‹çš„2Dç‰¹å¾ã€‚4) é€šè¿‡ä¼˜åŒ–3D proposalçš„ä½ç½®å’Œå°ºå¯¸ï¼Œä½¿å¾—å…¶åœ¨ä¸åŒè§†è§’ä¸‹çš„2Dç‰¹å¾å°½å¯èƒ½ä¸€è‡´ã€‚5) è¾“å‡ºä¼˜åŒ–åçš„3D bounding boxä½œä¸ºæ£€æµ‹ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨2Dé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œ3Dç›®æ ‡æ£€æµ‹ï¼Œé¿å…äº†3Dæ•°æ®çš„è®­ç»ƒï¼Œä»è€Œå®ç°äº†å¼€æ”¾è¯æ±‡çš„3Dæ£€æµ‹ã€‚æ­¤å¤–ï¼Œé€šè¿‡ä¼˜åŒ–3D proposalsæ¥å®ç°è·¨è§†è§’çš„ç‰¹å¾ä¸€è‡´æ€§ï¼Œå……åˆ†åˆ©ç”¨äº†å¤šè§†è§’ä¿¡æ¯ï¼Œæé«˜äº†æ£€æµ‹ç²¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨CLIPç­‰é¢„è®­ç»ƒçš„2Dæ¨¡å‹æå–å›¾åƒç‰¹å¾ã€‚2) ä½¿ç”¨IoUä½œä¸ºåº¦é‡æ ‡å‡†æ¥è¯„ä¼°3D proposalsçš„è´¨é‡ã€‚3) ä½¿ç”¨Adamä¼˜åŒ–å™¨æ¥ä¼˜åŒ–3D proposalçš„ä½ç½®å’Œå°ºå¯¸ã€‚4) æŸå¤±å‡½æ•°è®¾è®¡ä¸ºæœ€å°åŒ–ä¸åŒè§†è§’ä¸‹åŒä¸€proposalçš„ç‰¹å¾å·®å¼‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ScanNetå’ŒSUN RGB-Dç­‰æ ‡å‡†æ•°æ®é›†ä¸Šå–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚ç‰¹åˆ«æ˜¯åœ¨ç¨€ç–è§†è§’è®¾ç½®ä¸‹ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¾‹å¦‚åœ¨ScanNetæ•°æ®é›†ä¸Šï¼Œç›¸æ¯”äºç°æœ‰æ–¹æ³•æå‡äº†è¶…è¿‡10%çš„mAPã€‚è¿™è¯æ˜äº†è¯¥æ–¹æ³•åœ¨ç¨€ç–è§†è§’ä¸‹çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€åœºæ™¯ç†è§£ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œæœºå™¨äººå¯ä»¥åœ¨æœªçŸ¥ç¯å¢ƒä¸­æ£€æµ‹å¹¶è¯†åˆ«å„ç§ç‰©ä½“ï¼Œä»è€Œæ›´å¥½åœ°å®Œæˆä»»åŠ¡ã€‚è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯æ£€æµ‹è¡Œäººã€è½¦è¾†ç­‰ç›®æ ‡ï¼Œæé«˜å®‰å…¨æ€§ã€‚è¯¥æ–¹æ³•æ— éœ€è®­ç»ƒçš„ç‰¹æ€§ä½¿å…¶å…·æœ‰å¾ˆå¼ºçš„é€‚åº”æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œæœªæ¥æœ‰æœ›åœ¨æ›´å¤šé¢†åŸŸå¾—åˆ°åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The ability to interpret and comprehend a 3D scene is essential for many vision and robotics systems. In numerous applications, this involves 3D object detection, i.e.~identifying the location and dimensions of objects belonging to a specific category, typically represented as bounding boxes. This has traditionally been solved by training to detect a fixed set of categories, which limits its use. In this work, we investigate open-vocabulary 3D object detection in the challenging yet practical sparse-view setting, where only a limited number of posed RGB images are available as input. Our approach is training-free, relying on pre-trained, off-the-shelf 2D foundation models instead of employing computationally expensive 3D feature fusion or requiring 3D-specific learning. By lifting 2D detections and directly optimizing 3D proposals for featuremetric consistency across views, we fully leverage the extensive training data available in 2D compared to 3D. Through standard benchmarks, we demonstrate that this simple pipeline establishes a powerful baseline, performing competitively with state-of-the-art techniques in densely sampled scenarios while significantly outperforming them in the sparse-view setting.

