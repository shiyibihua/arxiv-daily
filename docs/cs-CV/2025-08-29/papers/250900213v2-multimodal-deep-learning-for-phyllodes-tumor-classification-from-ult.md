---
layout: default
title: Multimodal Deep Learning for Phyllodes Tumor Classification from Ultrasound and Clinical Data
---

# Multimodal Deep Learning for Phyllodes Tumor Classification from Ultrasound and Clinical Data

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00213" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00213v2</a>
  <a href="https://arxiv.org/pdf/2509.00213.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00213v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00213v2', 'Multimodal Deep Learning for Phyllodes Tumor Classification from Ultrasound and Clinical Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Farhan Fuad Abir, Abigail Elliott Daly, Kyle Anderman, Tolga Ozmen, Laura J. Brattain

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-29 (æ›´æ–°: 2025-09-25)

**å¤‡æ³¨**: IEEE-EMBS International Conference on Body Sensor Networks (IEEE-EMBS BSN 2025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¡†æ¶ä»¥æé«˜è…ºç˜¤åˆ†ç±»å‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ ` `è…ºç˜¤åˆ†ç±»` `ä¹³è…ºè¶…å£°` `ä¸´åºŠæ•°æ®` `ç‰¹å¾èåˆ` `ç¥ç»ç½‘ç»œ` `éä¾µå…¥æ€§è¯Šæ–­`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è…ºç˜¤çš„æœ¯å‰åˆ†ç±»å›°éš¾ï¼Œç°æœ‰æ–¹æ³•å¸¸å› å½±åƒå­¦ç›¸ä¼¼æ€§å¯¼è‡´è¯¯è¯Šï¼Œå¢åŠ ä¸å¿…è¦çš„æ‰‹æœ¯é£é™©ã€‚
2. æå‡ºçš„å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¡†æ¶ç»“åˆè¶…å£°å›¾åƒå’Œä¸´åºŠæ•°æ®ï¼Œé€šè¿‡åŒåˆ†æ”¯ç¥ç»ç½‘ç»œæå–å’Œèåˆç‰¹å¾ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è‰¯æ€§ä¸æ¶æ€§è…ºç˜¤åˆ†ç±»ä¸­æ˜¾è‘—ä¼˜äºå•æ¨¡æ€æ–¹æ³•ï¼Œæå‡äº†è¯Šæ–­å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è…ºç˜¤ï¼ˆPTsï¼‰æ˜¯ä¸€ç§ç½•è§çš„çº¤ç»´ä¸Šçš®ä¹³è…ºç—…å˜ï¼Œç”±äºå…¶ä¸è‰¯æ€§çº¤ç»´è…ºç˜¤åœ¨å½±åƒå­¦ä¸Šçš„ç›¸ä¼¼æ€§ï¼Œå¯¼è‡´æœ¯å‰åˆ†ç±»å›°éš¾ï¼Œå¸¸å¼•å‘ä¸å¿…è¦çš„æ‰‹æœ¯åˆ‡é™¤ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå°†ä¹³è…ºè¶…å£°ï¼ˆBUSï¼‰å›¾åƒä¸ç»“æ„åŒ–ä¸´åºŠæ•°æ®ç›¸ç»“åˆï¼Œä»¥æé«˜è¯Šæ–­å‡†ç¡®æ€§ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåŒåˆ†æ”¯ç¥ç»ç½‘ç»œï¼Œä»81åç¡®è¯ŠPTæ‚£è€…çš„è¶…å£°å›¾åƒå’Œæ‚£è€…å…ƒæ•°æ®ä¸­æå–å¹¶èåˆç‰¹å¾ã€‚é€šè¿‡ç±»åˆ«æ„ŸçŸ¥é‡‡æ ·å’Œå—è¯•è€…åˆ†å±‚çš„5æŠ˜äº¤å‰éªŒè¯ï¼Œé˜²æ­¢ç±»åˆ«ä¸å¹³è¡¡å’Œæ•°æ®æ³„æ¼ã€‚ç»“æœè¡¨æ˜ï¼Œæ‰€æå¤šæ¨¡æ€æ–¹æ³•åœ¨è‰¯æ€§ä¸è¾¹ç¼˜/æ¶æ€§PTåˆ†ç±»ä¸­ä¼˜äºå•æ¨¡æ€åŸºçº¿ï¼ŒConvNeXtå’ŒResNet18åœ¨å¤šæ¨¡æ€è®¾ç½®ä¸‹åˆ†åˆ«è·å¾—äº†0.9427å’Œ0.9349çš„AUC-ROCåˆ†æ•°ï¼Œä»¥åŠ0.6720å’Œ0.7294çš„F1åˆ†æ•°ï¼Œå±•ç¤ºäº†å¤šæ¨¡æ€AIä½œä¸ºéä¾µå…¥æ€§è¯Šæ–­å·¥å…·çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è…ºç˜¤ï¼ˆPTsï¼‰æœ¯å‰åˆ†ç±»çš„å›°éš¾ï¼Œç°æœ‰æ–¹æ³•å› å½±åƒå­¦ç‰¹å¾ç›¸ä¼¼æ€§å¯¼è‡´è¯¯è¯Šï¼Œå¢åŠ äº†ä¸å¿…è¦çš„æ‰‹æœ¯åˆ‡é™¤é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆä¹³è…ºè¶…å£°å›¾åƒå’Œç»“æ„åŒ–ä¸´åºŠæ•°æ®ï¼Œåˆ©ç”¨åŒåˆ†æ”¯ç¥ç»ç½‘ç»œæå–å’Œèåˆç‰¹å¾ï¼Œä»¥æé«˜åˆ†ç±»çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦åˆ†æ”¯ï¼šä¸€ä¸ªç”¨äºå¤„ç†è¶…å£°å›¾åƒï¼Œå¦ä¸€ä¸ªç”¨äºå¤„ç†æ‚£è€…çš„ä¸´åºŠæ•°æ®ã€‚é€šè¿‡ç‰¹å¾èåˆï¼Œå¢å¼ºæ¨¡å‹å¯¹ä¸åŒæ•°æ®æºçš„ç†è§£èƒ½åŠ›ã€‚é‡‡ç”¨ç±»åˆ«æ„ŸçŸ¥é‡‡æ ·å’Œ5æŠ˜äº¤å‰éªŒè¯ç­–ç•¥ï¼Œä»¥é˜²æ­¢ç±»åˆ«ä¸å¹³è¡¡å’Œæ•°æ®æ³„æ¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¤šæ¨¡æ€ç‰¹å¾çš„èåˆï¼Œåˆ©ç”¨åŒåˆ†æ”¯ç½‘ç»œç»“æ„æœ‰æ•ˆæ•´åˆä¸åŒç±»å‹çš„æ•°æ®ï¼Œæ˜¾è‘—æé«˜äº†åˆ†ç±»æ€§èƒ½ï¼Œä¸ä¼ ç»Ÿå•æ¨¡æ€æ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰æ›´é«˜çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨äº†ConvNeXtå’ŒResNet18ä½œä¸ºå›¾åƒç¼–ç å™¨ï¼Œä¼˜åŒ–äº†è¶…å£°å›¾åƒçš„ç‰¹å¾æå–ã€‚æŸå¤±å‡½æ•°è®¾è®¡ä¸ºé€‚åº”å¤šæ¨¡æ€å­¦ä¹ ï¼Œç¡®ä¿æ¨¡å‹åœ¨ä¸åŒæ•°æ®æºä¸Šå‡èƒ½æœ‰æ•ˆå­¦ä¹ ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå¤šæ¨¡æ€æ–¹æ³•åœ¨è‰¯æ€§ä¸æ¶æ€§è…ºç˜¤åˆ†ç±»ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒConvNeXtå’ŒResNet18çš„AUC-ROCåˆ†æ•°åˆ†åˆ«è¾¾åˆ°0.9427å’Œ0.9349ï¼ŒF1åˆ†æ•°åˆ†åˆ«ä¸º0.6720å’Œ0.7294ï¼Œæ˜¾è‘—ä¼˜äºå•æ¨¡æ€åŸºçº¿ï¼Œå±•ç¤ºäº†å¤šæ¨¡æ€å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¹³è…ºè‚¿ç˜¤çš„éä¾µå…¥æ€§è¯Šæ–­ï¼Œèƒ½å¤Ÿå‡å°‘ä¸å¿…è¦çš„æ´»æ£€ï¼Œæé«˜ä¸´åºŠå†³ç­–çš„å‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯æ‰©å±•è‡³å…¶ä»–ç±»å‹è‚¿ç˜¤çš„åˆ†ç±»å’Œè¯Šæ–­ï¼Œæ¨åŠ¨åŒ»ç–—å½±åƒå­¦çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Phyllodes tumors (PTs) are rare fibroepithelial breast lesions that are difficult to classify preoperatively due to their radiological similarity to benign fibroadenomas. This often leads to unnecessary surgical excisions. To address this, we propose a multimodal deep learning framework that integrates breast ultrasound (BUS) images with structured clinical data to improve diagnostic accuracy. We developed a dual-branch neural network that extracts and fuses features from ultrasound images and patient metadata from 81 subjects with confirmed PTs. Class-aware sampling and subject-stratified 5-fold cross-validation were applied to prevent class imbalance and data leakage. The results show that our proposed multimodal method outperforms unimodal baselines in classifying benign versus borderline/malignant PTs. Among six image encoders, ConvNeXt and ResNet18 achieved the best performance in the multimodal setting, with AUC-ROC scores of 0.9427 and 0.9349, and F1-scores of 0.6720 and 0.7294, respectively. This study demonstrates the potential of multimodal AI to serve as a non-invasive diagnostic tool, reducing unnecessary biopsies and improving clinical decision-making in breast tumor management.

