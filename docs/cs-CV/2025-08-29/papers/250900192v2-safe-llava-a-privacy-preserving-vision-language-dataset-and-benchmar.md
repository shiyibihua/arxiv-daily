---
layout: default
title: Safe-LLaVA: A Privacy-Preserving Vision-Language Dataset and Benchmark for Biometric Safety
---

# Safe-LLaVA: A Privacy-Preserving Vision-Language Dataset and Benchmark for Biometric Safety

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00192" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00192v2</a>
  <a href="https://arxiv.org/pdf/2509.00192.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00192v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00192v2', 'Safe-LLaVA: A Privacy-Preserving Vision-Language Dataset and Benchmark for Biometric Safety')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Younggun Kim, Sirnam Swetha, Fazil Kagdi, Mubarak Shah

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-29 (æ›´æ–°: 2025-10-06)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSafe-LLaVAä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„ç”Ÿç‰©ç‰¹å¾æ³„éœ²é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç”Ÿç‰©ç‰¹å¾ä¿æŠ¤` `éšç§ä¿æŠ¤` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `æ•°æ®é›†æ„å»º` `è¯„ä¼°åŸºå‡†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†è§†è§‰-è¯­è¨€ä»»åŠ¡æ—¶ï¼Œå¸¸å¸¸æ— æ„ä¸­æ³„éœ²æ•æ„Ÿçš„ç”Ÿç‰©ç‰¹å¾ä¿¡æ¯ï¼Œé€ æˆéšç§é£é™©ã€‚
2. æœ¬æ–‡æå‡ºäº†PRISMåŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°MLLMsåœ¨æ‹’ç»ç”Ÿç‰©ç‰¹å¾æŸ¥è¯¢å’Œéšæ€§æ³„éœ²æ–¹é¢çš„èƒ½åŠ›ï¼ŒåŒæ—¶æ„å»ºäº†Safe-LLaVAæ•°æ®é›†ä»¥æ¶ˆé™¤ç”Ÿç‰©ç‰¹å¾ä¿¡æ¯ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡Safe-LLaVAè®­ç»ƒçš„æ¨¡å‹æ˜¾è‘—å‡å°‘äº†ç”Ÿç‰©ç‰¹å¾æ³„éœ²ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸­å±•ç°å‡ºæ˜¾è‘—èƒ½åŠ›ï¼Œä½†å¸¸å¸¸åœ¨æœªæ˜ç¡®è¯·æ±‚çš„æƒ…å†µä¸‹æ¨æ–­å¹¶æ³„éœ²æ•æ„Ÿçš„ç”Ÿç‰©ç‰¹å¾ä¿¡æ¯ï¼Œå¦‚ç§æ—ã€æ€§åˆ«ã€å¹´é¾„ç­‰ã€‚è¿™åœ¨ç°å®åº”ç”¨å’Œç¤¾ä¼šæ•æ„Ÿé¢†åŸŸå¼•å‘äº†ä¸¥é‡çš„éšç§æ‹…å¿§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†PRISMåŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°MLLMsåœ¨æ‹’ç»ç”Ÿç‰©ç‰¹å¾æŸ¥è¯¢å’Œä¸€èˆ¬å“åº”ä¸­çš„éšæ€§ç”Ÿç‰©ç‰¹å¾æ³„éœ²æ–¹é¢çš„è¡¨ç°ã€‚åŒæ—¶ï¼Œæœ¬æ–‡å®¡è®¡äº†å¹¿æ³›ä½¿ç”¨çš„LLaVAæ•°æ®é›†ï¼Œå‘ç°äº†å¤§é‡çš„ç”Ÿç‰©ç‰¹å¾æ³„éœ²ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æ„å»ºäº†Safe-LLaVAæ•°æ®é›†ï¼Œç³»ç»Ÿæ€§åœ°ç§»é™¤äº†LLaVAæ•°æ®é›†ä¸­çš„æ˜¾æ€§å’Œéšæ€§ç”Ÿç‰©ä¿¡æ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSafe-LLaVAæ˜¾è‘—å‡å°‘äº†ç”Ÿç‰©ç‰¹å¾æ³„éœ²ï¼Œæ ‡å¿—ç€éšç§å¯¹é½çš„MLLMå¼€å‘ä¸è¯„ä¼°çš„æ–°æ ‡å‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ä»»åŠ¡æ—¶æ— æ„æ³„éœ²ç”Ÿç‰©ç‰¹å¾ä¿¡æ¯çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„è¯„ä¼°æ ‡å‡†å’Œæ•°æ®é›†æ¥æ£€æµ‹å’Œå‡å°‘è¿™ç§æ³„éœ²ï¼Œå¯¼è‡´éšç§é£é™©åŠ å‰§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†PRISMåŸºå‡†ï¼Œä¸“æ³¨äºè¯„ä¼°æ¨¡å‹åœ¨æ‹’ç»ç”Ÿç‰©ç‰¹å¾æŸ¥è¯¢å’Œéšæ€§æ³„éœ²æ–¹é¢çš„è¡¨ç°ã€‚åŒæ—¶ï¼Œæ„å»ºSafe-LLaVAæ•°æ®é›†ï¼Œé€šè¿‡ç³»ç»Ÿæ€§ç§»é™¤ç”Ÿç‰©ç‰¹å¾ä¿¡æ¯æ¥ä¿æŠ¤éšç§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šPRISMåŸºå‡†ç”¨äºè¯„ä¼°æ¨¡å‹çš„éšç§ä¿æŠ¤èƒ½åŠ›ï¼ŒSafe-LLaVAæ•°æ®é›†ç”¨äºè®­ç»ƒæ¨¡å‹ä»¥å‡å°‘ç”Ÿç‰©ç‰¹å¾æ³„éœ²ã€‚è¯„ä¼°è¿‡ç¨‹åŒ…æ‹¬å¯¹æ¨¡å‹å“åº”çš„å®¡è®¡å’Œåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ„å»ºäº†ç¬¬ä¸€ä¸ªéšç§ä¿æŠ¤çš„MLLMè®­ç»ƒæ•°æ®é›†Safe-LLaVAï¼Œå¹¶æå‡ºäº†PRISMåŸºå‡†æ¥ç³»ç»Ÿæ€§è¯„ä¼°ç”Ÿç‰©ç‰¹å¾æ³„éœ²ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æ ¹æœ¬åŒºåˆ«åœ¨äºå…³æ³¨éšç§ä¿æŠ¤è€Œéä»…ä»…æå‡æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç³»ç»Ÿæ€§ç§»é™¤æ˜¾æ€§å’Œéšæ€§ç”Ÿç‰©ç‰¹å¾ä¿¡æ¯çš„ç­–ç•¥ã€‚åŒæ—¶ï¼Œæ¨¡å‹çš„å¾®è°ƒè¿‡ç¨‹ä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿åœ¨å‡å°‘æ³„éœ²çš„åŒæ—¶ä¿æŒè¯­ä¹‰çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨Safe-LLaVAæ•°æ®é›†å¾®è°ƒçš„æ¨¡å‹åœ¨ç”Ÿç‰©ç‰¹å¾æ³„éœ²æ–¹é¢æ˜¾è‘—é™ä½ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨PRISMåŸºå‡†æµ‹è¯•ä¸­ï¼Œæ¨¡å‹åœ¨å¤šä¸ªç”Ÿç‰©ç‰¹å¾å±æ€§ä¸Šçš„æ³„éœ²ç‡å‡å°‘äº†çº¦30%ã€‚è¿™ä¸€ç»“æœå¼ºè°ƒäº†Safe-LLaVAåœ¨éšç§ä¿æŠ¤ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—ã€é‡‘èå’Œç¤¾äº¤åª’ä½“ç­‰å¯¹éšç§è¦æ±‚æé«˜çš„è¡Œä¸šã€‚é€šè¿‡å‡å°‘ç”Ÿç‰©ç‰¹å¾æ³„éœ²ï¼ŒSafe-LLaVAä¸ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨åº”ç”¨æä¾›äº†ä¿éšœï¼Œä¿ƒè¿›äº†éšç§ä¿æŠ¤æŠ€æœ¯çš„å‘å±•ã€‚æœªæ¥ï¼Œéšç€éšç§ä¿æŠ¤æ„è¯†çš„å¢å¼ºï¼Œè¯¥æ–¹æ³•å¯èƒ½æˆä¸ºå¤šæ¨¡æ€æ¨¡å‹å¼€å‘çš„æ ‡å‡†å®è·µã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in vision-language tasks. However, these models often infer and reveal sensitive biometric attributes such as race, gender, age, body weight, and eye color; even when such information is not explicitly requested. This raises critical concerns, particularly in real-world applications and socially-sensitive domains. Despite increasing awareness, no publicly available dataset or benchmark exists to comprehensively evaluate or mitigate biometric leakage in MLLMs. To address this gap, we introduce PRISM (Privacy-aware Evaluation of Responses in Sensitive Modalities), a new benchmark designed to assess MLLMs on two fronts: (1) refuse biometric-related queries and (2) implicit biometric leakage in general responses while maintaining semantic faithfulness. Further, we conduct a detailed audit of the widely used LLaVA datasets and uncover extensive biometric leakage across pretraining and instruction data. To address this, we present Safe-LLaVA dataset, the first privacy-preserving MLLM training dataset constructed by systematically removing explicit and implicit biometric information from LLaVA dataset. Our evaluations on PRISM reveal biometric leakages across MLLMs for different attributes, highlighting the detailed privacy-violations. We also fine-tune a model on Safe-LLaVA dataset and show that it substantially reduces the biometric leakages. Together, Safe-LLaVA and PRISM set a new standard for privacy-aligned development and evaluation of MLLMs.

