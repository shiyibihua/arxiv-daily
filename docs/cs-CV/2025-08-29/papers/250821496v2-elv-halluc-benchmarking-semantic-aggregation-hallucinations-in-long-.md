---
layout: default
title: ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding
---

# ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.21496" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.21496v2</a>
  <a href="https://arxiv.org/pdf/2508.21496.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.21496v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.21496v2', 'ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Hao Lu, Jiahao Wang, Yaolun Zhang, Ruohui Wang, Xuanyu Zheng, Yepeng Tang, Dahua Lin, Lewei Lu

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-29 (Êõ¥Êñ∞: 2025-09-02)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ELV-Halluc‰ª•Ëß£ÂÜ≥ÈïøËßÜÈ¢ëÁêÜËß£‰∏≠ÁöÑËØ≠‰πâËÅöÂêàÂπªËßâÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÈïøËßÜÈ¢ëÁêÜËß£` `ËØ≠‰πâËÅöÂêàÂπªËßâ` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `Êï∞ÊçÆÈõÜÊûÑÂª∫` `Ê®°ÂûãËÆ≠ÁªÉ` `ÊÄßËÉΩËØÑ‰º∞` `ÁºìËß£Á≠ñÁï•`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëÂπªËßâÂü∫ÂáÜ‰∏ªË¶ÅÈõÜ‰∏≠Âú®Áü≠ËßÜÈ¢ëÔºåÊú™ËÉΩÊ∑±ÂÖ•Êé¢ËÆ®ÈïøËßÜÈ¢ë‰∏≠ÁöÑËØ≠‰πâËÅöÂêàÂπªËßâÈóÆÈ¢ò„ÄÇ
2. ÊèêÂá∫ELV-HallucÂü∫ÂáÜÔºå‰∏ìÊ≥®‰∫éÈïøËßÜÈ¢ë‰∏≠ÁöÑËØ≠‰πâËÅöÂêàÂπªËßâÔºåÁ≥ªÁªüÊÄßÂàÜÊûêÂÖ∂ÊàêÂõ†ÂèäÂΩ±Âìç„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSAHÂú®ËØ≠‰πâÂ§çÊùÇÊÄßÂ¢ûÂä†Êó∂ÊòæËëó‰∏äÂçáÔºåÂπ∂ÈÄöËøáÊñ∞Á≠ñÁï•ÂÆûÁé∞‰∫Ü27.7%ÁöÑSAHÊØîÁéáÈôç‰Ωé„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜÈ¢ëÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàVideo-MLLMsÔºâÂú®ËßÜÈ¢ëÁêÜËß£ÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜ‰ªçÁÑ∂ÂÆπÊòì‰∫ßÁîü‰∏éËßÜÈ¢ëËæìÂÖ•‰∏ç‰∏ÄËá¥ÊàñÊó†ÂÖ≥ÁöÑÂπªËßâÂÜÖÂÆπ„ÄÇÁé∞ÊúâÁöÑËßÜÈ¢ëÂπªËßâÂü∫ÂáÜ‰∏ªË¶ÅÈõÜ‰∏≠Âú®Áü≠ËßÜÈ¢ë‰∏äÔºåËøá‰∫éÁÆÄÂåñ‰∫ÜÂπªËßâ‰∫ßÁîüÁöÑÂéüÂõ†„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜELV-HallucÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™‰∏ìÊ≥®‰∫éÈïøËßÜÈ¢ëÂπªËßâÁöÑÂü∫ÂáÜÔºåÁ≥ªÁªüÊÄßÂú∞Á†îÁ©∂‰∫ÜËØ≠‰πâËÅöÂêàÂπªËßâÔºàSAHÔºâ„ÄÇÂÆûÈ™åÁ°ÆËÆ§SAHÁöÑÂ≠òÂú®ÔºåÂπ∂ÊòæÁ§∫ÂÖ∂Âú®ËØ≠‰πâÂ§çÊùÇÊÄßÂ¢ûÂä†Êó∂Êõ¥‰∏∫ÊòéÊòæ„ÄÇÊàë‰ª¨ËøòÊé¢ËÆ®‰∫ÜÁºìËß£SAHÁöÑÊΩúÂú®ÊñπÊ≥ïÔºåÂπ∂ÈÄöËøáÊï∞ÊçÆÈõÜÁöÑÊûÑÂª∫ÂÆûÁé∞‰∫Ü27.7%ÁöÑSAHÊØîÁéáÈôç‰Ωé„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÈïøËßÜÈ¢ëÁêÜËß£‰∏≠Âá∫Áé∞ÁöÑËØ≠‰πâËÅöÂêàÂπªËßâÔºàSAHÔºâÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶ÅÂÖ≥Ê≥®Áü≠ËßÜÈ¢ëÔºåÊú™ËÉΩÂÖÖÂàÜËÄÉËôëÈïøËßÜÈ¢ë‰∏≠ËØ≠‰πâÂ§çÊùÇÊÄßÂ∏¶Êù•ÁöÑÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÂºïÂÖ•ELV-HallucÂü∫ÂáÜÔºåÁ≥ªÁªüÊÄßÂú∞ÂàÜÊûêSAHÁöÑÊàêÂõ†ÔºåÂπ∂ÊèêÂá∫ÁºìËß£Á≠ñÁï•Ôºå‰ª•ÊèêÈ´òÈïøËßÜÈ¢ëÁêÜËß£ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÈõÜÊûÑÂª∫„ÄÅSAHËØÜÂà´‰∏éÂàÜÊûê„ÄÅ‰ª•ÂèäÁºìËß£Á≠ñÁï•ÁöÑÂÆûÊñΩ„ÄÇ‰∏ªË¶ÅÊ®°ÂùóÂåÖÊã¨Êï∞ÊçÆÂØπÊØî„ÄÅÊ®°ÂûãËÆ≠ÁªÉÂíåÊÄßËÉΩËØÑ‰º∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÈ¶ñÊ¨°ÂÆö‰πâÂπ∂Á≥ªÁªüÊÄßÁ†îÁ©∂‰∫ÜSAHÔºåÊè≠Á§∫ÂÖ∂Âú®ÈïøËßÜÈ¢ë‰∏≠ÁöÑÈáçË¶ÅÊÄßÔºåÂπ∂ÊèêÂá∫‰∫ÜÊúâÊïàÁöÑÁºìËß£Á≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÈááÁî®‰ΩçÁΩÆÁºñÁ†ÅÁ≠ñÁï•ÂíåDPOÁ≠ñÁï•Êù•Â¢ûÂº∫Ê®°ÂûãÁöÑËØ≠‰πâÂå∫ÂàÜËÉΩÂäõÔºåËÆæËÆ°‰∫ÜÂåÖÂê´8KÂØπÊäóÊï∞ÊçÆÂØπÁöÑÊï∞ÊçÆÈõÜÔºå‰ª•ÊîØÊåÅÂÆûÈ™åÂíåËØÑ‰º∞„ÄÇÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåSAHÊØîÁéáÊòæËëóÈôç‰Ωé„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåSAHÂú®ËØ≠‰πâÂ§çÊùÇÊÄßÂ¢ûÂä†Êó∂ÊòæËëó‰∏äÂçáÔºåÈááÁî®Êñ∞Á≠ñÁï•ÂêéÔºåSAHÊØîÁéáÈôç‰Ωé‰∫Ü27.7%„ÄÇÊ≠§Â§ñÔºåÊ®°ÂûãÂú®Âø´ÈÄüÂèòÂåñËØ≠‰πâÂú∫ÊôØ‰∏ãÁöÑË°®Áé∞ÂæóÂà∞ÊîπÂñÑÔºåÈ™åËØÅ‰∫ÜÊèêÂá∫ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂Âú®ÈïøËßÜÈ¢ëÁêÜËß£È¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåËÉΩÂ§üÊèêÂçáËßÜÈ¢ëÂàÜÊûê„ÄÅËá™Âä®ÊëòË¶ÅÁîüÊàêÂíåÂ§öÊ®°ÊÄÅÊ£ÄÁ¥¢Á≠â‰ªªÂä°ÁöÑÊÄßËÉΩ„ÄÇÈÄöËøáËß£ÂÜ≥SAHÈóÆÈ¢òÔºåÊú™Êù•ÂèØÂú®Êô∫ËÉΩÁõëÊéß„ÄÅËßÜÈ¢ëÂÜÖÂÆπÊé®ËçêÂíå‰∫∫Êú∫‰∫§‰∫íÁ≠âÈ¢ÜÂüüÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Video multimodal large language models (Video-MLLMs) have achieved remarkable progress in video understanding. However, they remain vulnerable to hallucination-producing content inconsistent with or unrelated to video inputs. Previous video hallucination benchmarks primarily focus on short-videos. They attribute hallucinations to factors such as strong language priors, missing frames, or vision-language biases introduced by the visual encoder. While these causes indeed account for most hallucinations in short videos, they still oversimplify the cause of hallucinations. Sometimes, models generate incorrect outputs but with correct frame-level semantics. We refer to this type of hallucination as Semantic Aggregation Hallucination (SAH), which arises during the process of aggregating frame-level semantics into event-level semantic groups. Given that SAH becomes particularly critical in long videos due to increased semantic complexity across multiple events, it is essential to separate and thoroughly investigate the causes of this type of hallucination. To address the above issues, we introduce ELV-Halluc, the first benchmark dedicated to long-video hallucination, enabling a systematic investigation of SAH. Our experiments confirm the existence of SAH and show that it increases with semantic complexity. Additionally, we find that models are more prone to SAH on rapidly changing semantics. Moreover, we discuss potential approaches to mitigate SAH. We demonstrate that positional encoding strategy contributes to alleviating SAH, and further adopt DPO strategy to enhance the model's ability to distinguish semantics within and across events. To support this, we curate a dataset of 8K adversarial data pairs and achieve improvements on both ELV-Halluc and Video-MME, including a substantial 27.7% reduction in SAH ratio.

