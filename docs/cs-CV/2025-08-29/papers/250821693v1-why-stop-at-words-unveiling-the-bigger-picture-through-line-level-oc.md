---
layout: default
title: Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR
---

# Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.21693" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.21693v1</a>
  <a href="https://arxiv.org/pdf/2508.21693.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.21693v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.21693v1', 'Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Shashank Vempati, Nishit Anand, Gaurav Talebailkar, Arpan Garai, Chetan Arora

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.CL, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-29

**Â§áÊ≥®**: 11 pages. Project Website: https://nishitanand.github.io/line-level-ocr-website

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://nishitanand.github.io/line-level-ocr-website)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Ë°åÁ∫ßOCR‰ª•Ëß£ÂÜ≥ËØçÁ∫ßOCRÁöÑÂ±ÄÈôêÊÄß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂÖâÂ≠¶Â≠óÁ¨¶ËØÜÂà´` `Ë°åÁ∫ßOCR` `ÊñáÊú¨Ê£ÄÊµã` `ËØ≠Ë®ÄÊ®°Âûã` `ÊñáÊ°£Êï∞Â≠óÂåñ` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑOCRÊñπÊ≥ïÂú®Â≠óÁ¨¶ÂàÜÂâ≤‰∏äÂÆπÊòìÂá∫ÈîôÔºå‰∏îÁº∫‰πè‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºåÈôêÂà∂‰∫ÜËØ≠Ë®ÄÊ®°ÂûãÁöÑÊúâÊïàÂà©Áî®„ÄÇ
2. Êú¨ÊñáÊèêÂá∫Ë°åÁ∫ßOCRÔºåËÉΩÂ§üÁªïËøáÂçïËØçÊ£ÄÊµã‰∏≠ÁöÑÈîôËØØÔºåÂπ∂Êèê‰æõÊõ¥Â§ßÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òOCRÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéá„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåË°åÁ∫ßOCRÁöÑÁ´ØÂà∞Á´ØÂáÜÁ°ÆÊÄßÊèêÈ´ò‰∫Ü5.4%ÔºåÊïàÁéáÁõ∏ÊØîËØçÁ∫ßÁÆ°ÈÅìÊèêÂçá‰∫Ü4ÂÄçÔºåÊòæÁ§∫Âá∫ÊòæËëóÁöÑÊîπËøõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰º†ÁªüÁöÑÂÖâÂ≠¶Â≠óÁ¨¶ËØÜÂà´ÔºàOCRÔºâÊäÄÊúØÈÄöËøáÂàÜÂâ≤ÊØè‰∏™Â≠óÁ¨¶ËøõË°åËØÜÂà´ÔºåËøô‰ΩøÂæóÂ≠óÁ¨¶ÂàÜÂâ≤ÂÆπÊòìÂá∫ÈîôÔºåÂπ∂‰∏îÁº∫‰πèÂà©Áî®ËØ≠Ë®ÄÊ®°ÂûãÁöÑ‰∏ä‰∏ãÊñá„ÄÇËøëÂπ¥Êù•ÔºåÂ∫èÂàóÂà∞Â∫èÂàóÁøªËØëÁöÑËøõÂ±ï‰ΩøÂæóÁé∞‰ª£ÊäÄÊúØÈ¶ñÂÖàÊ£ÄÊµãÂçïËØçÔºåÁÑ∂ÂêéÈÄê‰∏™ËæìÂÖ•Âà∞Ê®°Âûã‰∏≠ÔºåÁõ¥Êé•ËæìÂá∫ÂÆåÊï¥ÁöÑÂ≠óÁ¨¶Â∫èÂàó„ÄÇËøôÁßçÊñπÊ≥ïÊèêÈ´ò‰∫ÜËØ≠Ë®ÄÊ®°ÂûãÁöÑÂà©Áî®ÊïàÁéáÔºåÁªïËøá‰∫ÜÂÆπÊòìÂá∫ÈîôÁöÑÂ≠óÁ¨¶ÂàÜÂâ≤Ê≠•È™§„ÄÇÁÑ∂ËÄåÔºåËøôÁßçËΩ¨Âèò‰ΩøÂæóÂáÜÁ°ÆÊÄßÁöÑÁì∂È¢àËΩ¨ÁßªÂà∞‰∫ÜÂçïËØçÂàÜÂâ≤‰∏ä„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßç‰ªéËØçÁ∫ßOCRÂà∞Ë°åÁ∫ßOCRÁöÑËá™ÁÑ∂ËøõÂ±ïÔºåËÉΩÂ§üÁªïËøáÂçïËØçÊ£ÄÊµã‰∏≠ÁöÑÈîôËØØÔºåÂπ∂Êèê‰æõÊõ¥Â§ßÁöÑÂè•Â≠ê‰∏ä‰∏ãÊñá‰ª•Êõ¥Â•ΩÂú∞Âà©Áî®ËØ≠Ë®ÄÊ®°Âûã„ÄÇÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåËØ•ÊäÄÊúØ‰∏ç‰ªÖÊèêÈ´ò‰∫ÜOCRÁöÑÂáÜÁ°ÆÊÄßÔºåËøòÊèêÈ´ò‰∫ÜÊïàÁéá„ÄÇÊàë‰ª¨ËøòË¥°ÁåÆ‰∫Ü‰∏Ä‰∏™ÂåÖÂê´251‰∏™Ëã±ÊñáÈ°µÈù¢ÂõæÂÉèÂèäË°åÁ∫ßÊ≥®ÈáäÁöÑÁ≤æÂøÉÁ≠ñÂàíÁöÑÊï∞ÊçÆÈõÜ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥‰º†ÁªüOCRÊñπÊ≥ïÂú®Â≠óÁ¨¶ÂàÜÂâ≤ÂíåÂçïËØçÊ£ÄÊµã‰∏≠Â≠òÂú®ÁöÑÈîôËØØÔºåÂØºËá¥Êï¥‰ΩìËØÜÂà´ÂáÜÁ°ÆÊÄß‰∏ãÈôçÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§çÊùÇÊñáÊ°£Êó∂ÔºåÂÆπÊòìÂèóÂà∞Â≠óÁ¨¶ÂíåÂçïËØçÂàÜÂâ≤ÁöÑÂΩ±Âìç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑË°åÁ∫ßOCRÊñπÊ≥ïÈÄöËøáÁõ¥Êé•Â§ÑÁêÜÊï¥Ë°åÊñáÊú¨ÔºåÈÅøÂÖç‰∫ÜÂçïËØçÊ£ÄÊµãÁöÑÈîôËØØÔºåÂπ∂Âà©Áî®Êõ¥‰∏∞ÂØåÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØÊù•ÊèêÂçáËØÜÂà´ÊïàÊûú„ÄÇËøôÁßçÊñπÊ≥ïÁöÑËÆæËÆ°Êó®Âú®ÊèêÈ´òOCRÁöÑÊï¥‰ΩìÂáÜÁ°ÆÊÄßÂíåÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Ë°åÁ∫ßÊñáÊú¨Ê£ÄÊµãÊ®°ÂùóÂíåÂ≠óÁ¨¶ËØÜÂà´Ê®°Âùó„ÄÇÈ¶ñÂÖàÔºåÁ≥ªÁªüÊ£ÄÊµãÊñáÊú¨Ë°åÔºåÁÑ∂ÂêéÂØπÊï¥Ë°åËøõË°åÂ≠óÁ¨¶ËØÜÂà´ÔºåÊúÄÂêéËæìÂá∫ÂÆåÊï¥ÁöÑÊñáÊú¨Â∫èÂàó„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫é‰ªéËØçÁ∫ßOCRËΩ¨ÂêëË°åÁ∫ßOCRÔºåËøô‰∏ÄËΩ¨Âèò‰ΩøÂæóÁ≥ªÁªüËÉΩÂ§üÂà©Áî®Êõ¥Â§ßÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºåÊòæËëóÂáèÂ∞ë‰∫ÜÈîôËØØÁéáÔºåÂπ∂ÊèêÈ´ò‰∫ÜÂ§ÑÁêÜÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÊäÄÊúØÁªÜËäÇ‰∏äÔºåÈááÁî®‰∫Ü‰ºòÂåñÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•ÈÄÇÂ∫îË°åÁ∫ßËØÜÂà´ÁöÑÈúÄÊ±ÇÔºåÂπ∂Âú®ÁΩëÁªúÁªìÊûÑ‰∏≠ÂºïÂÖ•‰∫ÜÈÄÇÂêàË°åÁ∫ßÊñáÊú¨ÁâπÂæÅÊèêÂèñÁöÑÂç∑ÁßØÂ±ÇÂíåÂæ™ÁéØÁ•ûÁªèÁΩëÁªúÔºàRNNÔºâÊ®°Âùó„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåË°åÁ∫ßOCRÁöÑÁ´ØÂà∞Á´ØÂáÜÁ°ÆÊÄßÊèêÈ´ò‰∫Ü5.4%ÔºåÁõ∏ÊØî‰º†ÁªüÁöÑËØçÁ∫ßOCRÔºåÊïàÁéáÊèêÂçá‰∫Ü4ÂÄç„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåË°åÁ∫ßOCRÂú®Â§ÑÁêÜÊñáÊ°£ÂõæÂÉèÊó∂ÂÖ∑ÊúâÊòæËëóÁöÑ‰ºòÂäøÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇÊñáÊú¨ÁéØÂ¢É‰∏≠„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÊñáÊ°£Êï∞Â≠óÂåñ„ÄÅËá™Âä®ÂåñÊï∞ÊçÆÂΩïÂÖ•Âíå‰ø°ÊÅØÊèêÂèñÁ≠â„ÄÇË°åÁ∫ßOCRËÉΩÂ§üÂú®Â§ÑÁêÜÂ§çÊùÇÊñáÊ°£Êó∂Êèê‰æõÊõ¥È´òÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÔºåÊú™Êù•ÂèØËÉΩÂú®Ê≥ïÂæã„ÄÅÂåªÁñóÂíåÈáëËûçÁ≠âË°å‰∏ö‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®ÔºåÊèêÂçá‰ø°ÊÅØÂ§ÑÁêÜÁöÑËá™Âä®ÂåñÊ∞¥Âπ≥„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Conventional optical character recognition (OCR) techniques segmented each character and then recognized. This made them prone to error in character segmentation, and devoid of context to exploit language models. Advances in sequence to sequence translation in last decade led to modern techniques first detecting words and then inputting one word at a time to a model to directly output full words as sequence of characters. This allowed better utilization of language models and bypass error-prone character segmentation step. We observe that the above transition in style has moved the bottleneck in accuracy to word segmentation. Hence, in this paper, we propose a natural and logical progression from word level OCR to line-level OCR. The proposal allows to bypass errors in word detection, and provides larger sentence context for better utilization of language models. We show that the proposed technique not only improves the accuracy but also efficiency of OCR. Despite our thorough literature survey, we did not find any public dataset to train and benchmark such shift from word to line-level OCR. Hence, we also contribute a meticulously curated dataset of 251 English page images with line-level annotations. Our experimentation revealed a notable end-to-end accuracy improvement of 5.4%, underscoring the potential benefits of transitioning towards line-level OCR, especially for document images. We also report a 4 times improvement in efficiency compared to word-based pipelines. With continuous improvements in large language models, our methodology also holds potential to exploit such advances. Project Website: https://nishitanand.github.io/line-level-ocr-website

