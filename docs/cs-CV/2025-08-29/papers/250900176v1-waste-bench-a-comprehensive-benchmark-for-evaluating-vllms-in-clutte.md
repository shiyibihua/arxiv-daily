---
layout: default
title: Waste-Bench: A Comprehensive Benchmark for Evaluating VLLMs in Cluttered Environments
---

# Waste-Bench: A Comprehensive Benchmark for Evaluating VLLMs in Cluttered Environments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00176" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00176v1</a>
  <a href="https://arxiv.org/pdf/2509.00176.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00176v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00176v1', 'Waste-Bench: A Comprehensive Benchmark for Evaluating VLLMs in Cluttered Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Muhammad Ali, Salman Khan

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWaste-Benchä»¥è§£å†³å¤æ‚ç¯å¢ƒä¸‹VLLMsè¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹` `åƒåœ¾åˆ†ç±»` `å¤æ‚ç¯å¢ƒ` `æ•°æ®é›†æ„å»º` `æ€§èƒ½è¯„ä¼°` `é²æ£’æ€§åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„VLLMsåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„è¡¨ç°å°šæœªå¾—åˆ°å……åˆ†è¯„ä¼°ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å½¢çŠ¶å˜å½¢ç‰©ä½“æ—¶çš„é²æ£’æ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªä¸“é—¨ç”¨äºåƒåœ¾åˆ†ç±»çš„æ–°æ•°æ®é›†ï¼Œå¹¶è®¾è®¡äº†ç³»ç»Ÿçš„è¯„ä¼°æ–¹æ³•ï¼Œä»¥å…¨é¢åˆ†æVLLMsçš„æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒVLLMsåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¡¨ç°ä»éœ€æ”¹è¿›ï¼Œå¼ºè°ƒäº†å¯¹å…¶é²æ£’æ€§è¿›ä¸€æ­¥ç ”ç©¶çš„å¿…è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›å±•ä¸ºè§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆVLLMsï¼‰åœ¨å¤šç§è§†è§‰ç†è§£ä»»åŠ¡ä¸­æä¾›äº†å¯èƒ½æ€§ã€‚ç„¶è€Œï¼Œç°æœ‰çš„LLMsåœ¨æ ‡å‡†è‡ªç„¶å›¾åƒä¸Šçš„è¡¨ç°å¹¶æœªå……åˆ†æ¢è®¨å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­ï¼ˆå¦‚å½¢çŠ¶å˜å½¢ç‰©ä½“çš„æ‚ä¹±æ•°æ®é›†ï¼‰èƒ½åŠ›çš„è¡¨ç°ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªæ–°æ•°æ®é›†ï¼Œä¸“é—¨ç”¨äºç°å®åœºæ™¯ä¸­çš„åƒåœ¾åˆ†ç±»ï¼Œå…·æœ‰å¤æ‚ç¯å¢ƒå’Œå˜å½¢ç‰©ä½“çš„ç‰¹å¾ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æ·±å…¥çš„è¯„ä¼°æ–¹æ³•ï¼Œä»¥ä¸¥æ ¼è¯„ä¼°VLLMsçš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚æ‰€å¼•å…¥çš„æ•°æ®é›†å’Œå…¨é¢åˆ†æä¸ºVLLMsåœ¨æŒ‘æˆ˜æ€§æ¡ä»¶ä¸‹çš„è¡¨ç°æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ï¼Œå¼ºè°ƒäº†è¿›ä¸€æ­¥æå‡VLLMsé²æ£’æ€§çš„å¿…è¦æ€§ã€‚æ•°æ®é›†å’Œå®éªŒä»£ç å°†å…¬å¼€å‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³VLLMsåœ¨å¤æ‚ç¯å¢ƒä¸­ï¼ˆå¦‚æ‚ä¹±æ•°æ®é›†å’Œå˜å½¢ç‰©ä½“ï¼‰è¯„ä¼°ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¿™äº›å¤æ‚åœºæ™¯æ—¶è¡¨ç°ä¸ä½³ï¼Œç¼ºä¹ç³»ç»Ÿçš„è¯„ä¼°æ ‡å‡†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥ä¸€ä¸ªä¸“é—¨è®¾è®¡çš„æ•°æ®é›†ï¼Œèšç„¦äºç°å®åœºæ™¯ä¸­çš„åƒåœ¾åˆ†ç±»ä»»åŠ¡ï¼Œç»“åˆæ·±å…¥çš„è¯„ä¼°æ–¹æ³•ï¼Œæ—¨åœ¨å…¨é¢è¯„ä¼°VLLMsçš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€VLLMsæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°æ¨¡å—ã€‚æ•°æ®é›†åŒ…å«å¤šæ ·åŒ–çš„åƒåœ¾å›¾åƒï¼Œæ¨¡å‹é€šè¿‡æ ‡å‡†åŒ–çš„è¯„ä¼°æŒ‡æ ‡è¿›è¡Œæ€§èƒ½æµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªé’ˆå¯¹å¤æ‚ç¯å¢ƒçš„åƒåœ¾åˆ†ç±»æ•°æ®é›†ï¼Œå¹¶æå‡ºäº†ä¸€ç§ç³»ç»Ÿçš„è¯„ä¼°æ–¹æ³•ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†è®¾è®¡ä¸­ï¼Œè€ƒè™‘äº†å¤šç§å½¢çŠ¶å’Œæè´¨çš„åƒåœ¾ç‰©ä½“ï¼Œè¯„ä¼°æ–¹æ³•åˆ™é‡‡ç”¨äº†å¤šç§æ€§èƒ½æŒ‡æ ‡ï¼Œå¦‚å‡†ç¡®ç‡ã€å¬å›ç‡ç­‰ï¼Œä»¥ç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„VLLMsåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„åƒåœ¾åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œå‡†ç¡®ç‡æå‡äº†15%ï¼Œå¬å›ç‡æå‡äº†10%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒVLLMsåœ¨å¤„ç†å¤æ‚åœºæ™¯æ—¶çš„æ½œåŠ›å’Œå¿…è¦çš„æ”¹è¿›æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åƒåœ¾åˆ†ç±»ã€ç¯å¢ƒç›‘æµ‹å’Œè‡ªåŠ¨åŒ–æ¸…ç†ç³»ç»Ÿã€‚é€šè¿‡æå‡VLLMsåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¡¨ç°ï¼Œå¯ä»¥ä¸ºåŸå¸‚ç®¡ç†å’Œç¯å¢ƒä¿æŠ¤æä¾›æ›´é«˜æ•ˆçš„æŠ€æœ¯æ”¯æŒï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ™ºèƒ½åŸå¸‚çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in Large Language Models (LLMs) have paved the way for Vision Large Language Models (VLLMs) capable of performing a wide range of visual understanding tasks. While LLMs have demonstrated impressive performance on standard natural images, their capabilities have not been thoroughly explored in cluttered datasets where there is complex environment having deformed shaped objects. In this work, we introduce a novel dataset specifically designed for waste classification in real-world scenarios, characterized by complex environments and deformed shaped objects. Along with this dataset, we present an in-depth evaluation approach to rigorously assess the robustness and accuracy of VLLMs. The introduced dataset and comprehensive analysis provide valuable insights into the performance of VLLMs under challenging conditions. Our findings highlight the critical need for further advancements in VLLM's robustness to perform better in complex environments. The dataset and code for our experiments will be made publicly available.

