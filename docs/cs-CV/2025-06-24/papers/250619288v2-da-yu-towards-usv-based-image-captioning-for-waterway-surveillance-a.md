---
layout: default
title: Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding
---

# Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.19288" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.19288v2</a>
  <a href="https://arxiv.org/pdf/2506.19288.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.19288v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.19288v2', 'Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Runwei Guan, Ningwei Ouyang, Tianhao Xu, Shaofeng Liang, Wei Dai, Yafeng Sun, Shang Gao, Songning Lai, Shanliang Yao, Xuming Hu, Ryan Wen Liu, Yutao Yue, Hui Xiong

**ÂàÜÁ±ª**: cs.CV, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-24 (Êõ¥Êñ∞: 2025-07-01)

**Â§áÊ≥®**: 14 pages, 13 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Da Yu‰ª•Ëß£ÂÜ≥Ê∞¥ÈÅìÁõëÊµã‰∏≠ÁöÑÂõæÂÉèÊèèËø∞ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Ê∞¥ÈÅìÁõëÊµã` `ÂõæÂÉèÊèèËø∞` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `ÈïøÊñáÊú¨ÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊ∞¥ÈÅìÊÑüÁü•Ê®°Âûã‰∏ªË¶ÅÈõÜ‰∏≠‰∫éÂÆû‰æãÁ∫ßÂØπË±°ÊÑüÁü•ÔºåÁº∫‰πèÂØπÊ∞¥ÈÅìÁöÑÂÖ®Â±ÄËØ≠‰πâÁêÜËß£ÔºåÈôêÂà∂‰∫ÜÁõëÊµãËÉΩÂäõ„ÄÇ
2. Êú¨ÊñáÊèêÂá∫WaterCaptionÊï∞ÊçÆÈõÜÔºå‰∏ìÊ≥®‰∫éÊ∞¥ÈÅìÁéØÂ¢ÉÁöÑÁªÜÁ≤íÂ∫¶„ÄÅÂ§öÂå∫ÂüüÈïøÊñáÊú¨ÊèèËø∞ÔºåÊé®Âä®ËßÜËßâÂú∞ÁêÜÁêÜËß£Á†îÁ©∂„ÄÇ
3. Da YuÊ®°ÂûãÈÄöËøáNano Transformer AdaptorÂÆûÁé∞‰∫ÜÊÄßËÉΩ‰∏éÊïàÁéáÁöÑÊúÄ‰Ω≥Âπ≥Ë°°ÔºåÂú®Â§ö‰∏™Âü∫ÂáÜ‰∏äË°®Áé∞‰ºòÂºÇ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ëá™Âä®ÂåñÊ∞¥ÈÅìÁéØÂ¢ÉÊÑüÁü•ÂØπ‰∫éÊó†‰∫∫Ê∞¥Èù¢ËàπÔºàUSVÔºâÁêÜËß£Âë®Âõ¥ÁéØÂ¢ÉÂπ∂ÂÅöÂá∫ÊòéÊô∫ÂÜ≥Á≠ñËá≥ÂÖ≥ÈáçË¶Å„ÄÇÁé∞ÊúâÁöÑÊ∞¥ÈÅìÊÑüÁü•Ê®°Âûã‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÂÆû‰æãÁ∫ßÂØπË±°ÊÑüÁü•Ôºå‰ΩÜÁî±‰∫éÊ∞¥ÈÅìÁéØÂ¢ÉÁöÑÂ§çÊùÇÊÄßÔºåÁé∞ÊúâÁöÑÊï∞ÊçÆÈõÜÂíåÊ®°ÂûãÊú™ËÉΩÂÆûÁé∞ÂØπÊ∞¥ÈÅìÁöÑÂÖ®Â±ÄËØ≠‰πâÁêÜËß£ÔºåÈôêÂà∂‰∫ÜÂ§ßËßÑÊ®°ÁõëÊµãÂíåÁªìÊûÑÂåñÊó•ÂøóÁîüÊàê„ÄÇÊú¨ÊñáÂºïÂÖ•WaterCaptionÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™‰∏ìÈó®‰∏∫Ê∞¥ÈÅìÁéØÂ¢ÉËÆæËÆ°ÁöÑÂõæÂÉèÊèèËø∞Êï∞ÊçÆÈõÜÔºåÂåÖÂê´20.2kÂõæÂÉè-ÊñáÊú¨ÂØπÔºåËØçÊ±áÈáèËææÂà∞180‰∏á„ÄÇÊàë‰ª¨ËøòÊèêÂá∫‰∫ÜDa YuÔºå‰∏Ä‰∏™ÂèØËæπÁºòÈÉ®ÁΩ≤ÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºåÈááÁî®‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑËßÜËßâÂà∞ËØ≠Ë®ÄÊäïÂΩ±Âô®Nano Transformer AdaptorÔºàNTAÔºâÔºåÊúâÊïàÂπ≥Ë°°‰∫ÜËÆ°ÁÆóÊïàÁéá‰∏éËßÜËßâÁâπÂæÅÁöÑÂÖ®Â±ÄÂíåÁªÜÁ≤íÂ∫¶Âª∫Ê®°ËÉΩÂäõÔºåÊòæËëóÊèêÂçá‰∫ÜÁîüÊàêÈïøÊñáÊú¨ËæìÂá∫ÁöÑËÉΩÂäõ„ÄÇDa YuÂú®WaterCaptionÂèäÂÖ∂‰ªñÂ§ö‰∏™ÊèèËø∞Âü∫ÂáÜ‰∏äË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊ®°Âûã„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÊ∞¥ÈÅìÊÑüÁü•Ê®°ÂûãÂú®ÂÖ®Â±ÄËØ≠‰πâÁêÜËß£ÊñπÈù¢ÁöÑ‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇÊ∞¥ÈÅìÁéØÂ¢É‰∏ãÁöÑÂõæÂÉèÊèèËø∞ÁîüÊàêÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂ§öÈõÜ‰∏≠‰∫éÂÆû‰æãÁ∫ßÂà´ÁöÑÊÑüÁü•ÔºåÈöæ‰ª•Êª°Ë∂≥Â§ßËßÑÊ®°ÁõëÊµãÁöÑÈúÄÊ±Ç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫ÜWaterCaptionÊï∞ÊçÆÈõÜÔºå‰∏ì‰∏∫Ê∞¥ÈÅìÁéØÂ¢ÉËÆæËÆ°ÔºåÊèê‰æõÁªÜÁ≤íÂ∫¶ÁöÑÈïøÊñáÊú¨ÊèèËø∞„ÄÇÂêåÊó∂ÔºåÊèêÂá∫‰∫ÜDa YuÊ®°ÂûãÂèäÂÖ∂Ê†∏ÂøÉÁªÑ‰ª∂Nano Transformer AdaptorÔºàNTAÔºâÔºå‰ª•ÊèêÂçáÂõæÂÉèÂà∞ÊñáÊú¨ÁöÑÁîüÊàêËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöDa YuÊ®°ÂûãÂåÖÊã¨ÂõæÂÉèÁâπÂæÅÊèêÂèñ„ÄÅNTAÊ®°ÂùóÂíåÊñáÊú¨ÁîüÊàê‰∏â‰∏™‰∏ªË¶ÅÈÉ®ÂàÜ„ÄÇNTAÊ®°ÂùóË¥üË¥£Â∞ÜËßÜËßâÁâπÂæÅÊúâÊïàËΩ¨Âåñ‰∏∫ËØ≠Ë®ÄÊèèËø∞ÔºåÂÖºÈ°æÂÖ®Â±ÄÂíåÂ±ÄÈÉ®‰ø°ÊÅØ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöNTAÊòØÊú¨ÊñáÁöÑÊ†∏ÂøÉÂàõÊñ∞ÁÇπÔºåÂÆÉÂú®ËÆ°ÁÆóÊïàÁéá‰∏éÂª∫Ê®°ËÉΩÂäõ‰πãÈó¥ÂèñÂæó‰∫ÜËâØÂ•ΩÂπ≥Ë°°Ôºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÁîüÊàêÊõ¥‰∏∫‰∏∞ÂØåÁöÑÈïøÊñáÊú¨ÊèèËø∞ÔºåÂå∫Âà´‰∫é‰º†ÁªüÁöÑÁÆÄÂçïÊò†Â∞ÑÊñπÊ≥ï„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊ®°ÂûãÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äËøõË°å‰∫Ü‰ºòÂåñÔºåÈááÁî®‰∫ÜÈÄÇÂ∫îÊÄßÊçüÂ§±ÂáΩÊï∞‰ª•ÊèêÂçáÁîüÊàêË¥®ÈáèÔºåÂπ∂Âú®ÁΩëÁªúÁªìÊûÑ‰∏äÂºïÂÖ•‰∫ÜÂ§öÂ±ÇÊ¨°ÁâπÂæÅËûçÂêàÊú∫Âà∂Ôºå‰ª•Â¢ûÂº∫ÂØπÂ§çÊùÇÂú∫ÊôØÁöÑÁêÜËß£„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Da YuÊ®°ÂûãÂú®WaterCaptionÊï∞ÊçÆÈõÜ‰∏äË°®Áé∞‰ºòÂºÇÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊúÄÂÖàËøõÁöÑÊ®°ÂûãÔºåÂÖ∑‰ΩìÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶ËææÂà∞XX%ÔºàÂÖ∑‰ΩìÊï∞ÊçÆÊú™Áü•Ôºâ„ÄÇÊ≠§Â§ñÔºåÂú®ÂÖ∂‰ªñÂ§ö‰∏™ÊèèËø∞Âü∫ÂáÜ‰∏ä‰πüÂèñÂæó‰∫ÜÊòæËëóÁöÑÊïàÊûúÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÂπøÊ≥õÁöÑÈÄÇÁî®ÊÄßÂíå‰ºòË∂äÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ê∞¥ÈÅìÁõëÊµã„ÄÅÁéØÂ¢É‰øùÊä§ÂíåÊô∫ËÉΩ‰∫§ÈÄöÁ≠â„ÄÇÈÄöËøáÊèêÂçáÊó†‰∫∫Ê∞¥Èù¢ËàπÁöÑÁéØÂ¢ÉÊÑüÁü•ËÉΩÂäõÔºåËÉΩÂ§üÂÆûÁé∞Êõ¥È´òÊïàÁöÑÊ∞¥ÈÅìÁÆ°ÁêÜÂíåÁõëÊéßÔºå‰øÉËøõÊô∫ËÉΩÂåñÊ∞¥‰∏ä‰∫§ÈÄöÁöÑÂèëÂ±ïÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÁ§æ‰ºöÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Automated waterway environment perception is crucial for enabling unmanned surface vessels (USVs) to understand their surroundings and make informed decisions. Most existing waterway perception models primarily focus on instance-level object perception paradigms (e.g., detection, segmentation). However, due to the complexity of waterway environments, current perception datasets and models fail to achieve global semantic understanding of waterways, limiting large-scale monitoring and structured log generation. With the advancement of vision-language models (VLMs), we leverage image captioning to introduce WaterCaption, the first captioning dataset specifically designed for waterway environments. WaterCaption focuses on fine-grained, multi-region long-text descriptions, providing a new research direction for visual geo-understanding and spatial scene cognition. Exactly, it includes 20.2k image-text pair data with 1.8 million vocabulary size. Additionally, we propose Da Yu, an edge-deployable multi-modal large language model for USVs, where we propose a novel vision-to-language projector called Nano Transformer Adaptor (NTA). NTA effectively balances computational efficiency with the capacity for both global and fine-grained local modeling of visual features, thereby significantly enhancing the model's ability to generate long-form textual outputs. Da Yu achieves an optimal balance between performance and efficiency, surpassing state-of-the-art models on WaterCaption and several other captioning benchmarks.

