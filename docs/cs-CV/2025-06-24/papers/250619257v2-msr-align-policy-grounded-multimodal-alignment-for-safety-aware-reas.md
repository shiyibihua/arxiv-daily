---
layout: default
title: MSR-Align: Policy-Grounded Multimodal Alignment for Safety-Aware Reasoning in Vision-Language Models
---

# MSR-Align: Policy-Grounded Multimodal Alignment for Safety-Aware Reasoning in Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.19257" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.19257v2</a>
  <a href="https://arxiv.org/pdf/2506.19257.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.19257v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.19257v2', 'MSR-Align: Policy-Grounded Multimodal Alignment for Safety-Aware Reasoning in Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yinan Xia, Yilei Jiang, Yingshui Tan, Xiaoyong Zhu, Xiangyu Yue, Bo Zheng

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-24 (æ›´æ–°: 2025-10-21)

**ğŸ”— ä»£ç /é¡¹ç›®**: [HUGGINGFACE](https://huggingface.co/datasets/Leigest)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMSR-Alignä»¥è§£å†³å¤šæ¨¡æ€æ¨¡å‹å®‰å…¨å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨ç†` `å®‰å…¨å¯¹é½` `è§†è§‰-è¯­è¨€æ¨¡å‹` `æ”¿ç­–æ¨ç†` `æ•°æ®é›†æ„å»º` `é²æ£’æ€§æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å®‰å…¨å¯¹é½æ–¹æ³•æ— æ³•æœ‰æ•ˆåº”å¯¹å¤šæ¨¡æ€è¾“å…¥å¸¦æ¥çš„å¤æ‚å¨èƒï¼Œå°¤å…¶æ˜¯åœ¨è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­ã€‚
2. æœ¬æ–‡æå‡ºMSR-Alignæ•°æ®é›†ï¼Œæ”¯æŒåŸºäºæ”¿ç­–çš„ç»†ç²’åº¦æ¨ç†ï¼Œæ—¨åœ¨æé«˜VLMsçš„å®‰å…¨æ€§å’Œé²æ£’æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒVLMsååœ¨MSR-Alignä¸Šæ˜¾è‘—æå‡äº†å¯¹æ”»å‡»çš„æŠµæŠ—èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒäº†æ¨ç†æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å¤šæ¨¡æ€æ¨ç†ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä¹Ÿå¸¦æ¥äº†æ–°çš„å®‰å…¨é£é™©ï¼Œå°¤å…¶æ˜¯å¯¹æœ‰å®³å¤šæ¨¡æ€æç¤ºçš„è„†å¼±æ€§ã€‚ç°æœ‰çš„å®‰å…¨å¯¹é½æ–¹æ³•ä¸»è¦é’ˆå¯¹å•æ¨¡æ€è¯­è¨€æ¨¡å‹ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹å¤šæ¨¡æ€è¾“å…¥çš„å¤æ‚å¨èƒã€‚æ­¤å¤–ï¼Œå½“å‰çš„å®‰å…¨æ•°æ®é›†ç¼ºä¹ç»†ç²’åº¦çš„ã€åŸºäºæ”¿ç­–çš„æ¨ç†ï¼Œæ— æ³•æœ‰æ•ˆå¯¹é½å…·å¤‡æ¨ç†èƒ½åŠ›çš„VLMsã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†MSR-Alignï¼Œä¸€ä¸ªé«˜è´¨é‡çš„å¤šæ¨¡æ€å®‰å…¨æ¨ç†æ•°æ®é›†ï¼Œæ—¨åœ¨å¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚MSR-Alignæ”¯æŒå¯¹è§†è§‰å’Œæ–‡æœ¬æ¨¡æ€çš„æ ‡å‡†åŒ–å®‰å…¨æ”¿ç­–è¿›è¡Œç»†è‡´çš„æ¨ç†ï¼Œå®éªŒè¡¨æ˜ï¼Œåœ¨MSR-Alignä¸Šå¾®è°ƒVLMsæ˜¾è‘—æé«˜äº†å¯¹æ–‡æœ¬å’Œè§†è§‰-è¯­è¨€æ”»å‡»çš„é²æ£’æ€§ï¼ŒåŒæ—¶ä¿æŒæˆ–æå‡äº†æ•´ä½“æ¨ç†æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨é¢å¯¹å¤šæ¨¡æ€è¾“å…¥æ—¶çš„å®‰å…¨å¯¹é½é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é’ˆå¯¹å•æ¨¡æ€æ¨¡å‹ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹å¤šæ¨¡æ€è¾“å…¥çš„å¤æ‚æ€§å’Œæ½œåœ¨å¨èƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºMSR-Alignæ•°æ®é›†ï¼Œå¼ºè°ƒå¤šæ¨¡æ€çš„å¤šæ ·æ€§å’ŒåŸºäºæ”¿ç­–çš„æ¨ç†ï¼Œä»¥å¢å¼ºVLMsçš„å®‰å…¨æ€§å’Œé²æ£’æ€§ã€‚é€šè¿‡ç»†è‡´çš„æ¨ç†å’Œè´¨é‡è¿‡æ»¤ï¼Œç¡®ä¿æ•°æ®é›†çš„é«˜è´¨é‡å’Œæœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMSR-Alignçš„æ•°æ®ç”Ÿæˆæµç¨‹åŒ…æ‹¬å¤šæ¨¡æ€æ•°æ®çš„æ”¶é›†ã€æ”¿ç­–çš„æ ‡å‡†åŒ–å®šä¹‰ã€ä»¥åŠä½¿ç”¨å¼ºå¤§çš„å¤šæ¨¡æ€è¯„å®¡è€…è¿›è¡Œè´¨é‡è¿‡æ»¤ã€‚æ•´ä½“æ¶æ„åˆ†ä¸ºæ•°æ®ç”Ÿæˆã€æ¨¡å‹å¾®è°ƒå’Œæ€§èƒ½è¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šMSR-Alignçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶é«˜è´¨é‡çš„å¤šæ¨¡æ€å®‰å…¨æ¨ç†æ•°æ®é›†ï¼Œå¡«è¡¥äº†ç°æœ‰æ•°æ®é›†åœ¨ç»†ç²’åº¦å’Œæ”¿ç­–å¯¹é½æ–¹é¢çš„ç©ºç™½ã€‚è¿™ä¸€è®¾è®¡ä½¿å¾—VLMsèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œåº”å¯¹å¤šæ¨¡æ€è¾“å…¥çš„å®‰å…¨æŒ‘æˆ˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†å¤šæ ·åŒ–çš„æ¨¡æ€ç»„åˆå’Œä¸¥æ ¼çš„è´¨é‡æ§åˆ¶ï¼Œç¡®ä¿æ¯ä¸ªæ ·æœ¬éƒ½èƒ½æœ‰æ•ˆæ”¯æŒåŸºäºæ”¿ç­–çš„æ¨ç†ã€‚åŒæ—¶ï¼Œå¾®è°ƒè¿‡ç¨‹ä¸­ä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨å®‰å…¨æ€§å’Œæ¨ç†èƒ½åŠ›ä¸Šçš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨MSR-Alignä¸Šå¾®è°ƒçš„VLMsåœ¨é¢å¯¹æ–‡æœ¬å’Œè§†è§‰-è¯­è¨€æ”»å‡»æ—¶ï¼Œé²æ£’æ€§æ˜¾è‘—æé«˜ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ï¼ŒåŒæ—¶ä¿æŒæˆ–æå‡äº†æ•´ä½“æ¨ç†æ€§èƒ½ï¼ŒéªŒè¯äº†æ•°æ®é›†çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§å’Œäººæœºäº¤äº’ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚éšç€å¤šæ¨¡æ€æŠ€æœ¯çš„å‘å±•ï¼ŒMSR-Alignä¸ºæœªæ¥çš„å®‰å…¨å¯¹é½ç ”ç©¶æä¾›äº†é‡è¦åŸºç¡€ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œå½±å“åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language Models (VLMs) have achieved remarkable progress in multimodal reasoning tasks through enhanced chain-of-thought capabilities. However, this advancement also introduces novel safety risks, as these models become increasingly vulnerable to harmful multimodal prompts that can trigger unethical or unsafe behaviors. Existing safety alignment approaches, primarily designed for unimodal language models, fall short in addressing the complex and nuanced threats posed by multimodal inputs. Moreover, current safety datasets lack the fine-grained, policy-grounded reasoning required to robustly align reasoning-capable VLMs. In this work, we introduce {MSR-Align}, a high-quality Multimodal Safety Reasoning dataset tailored to bridge this gap. MSR-Align supports fine-grained, deliberative reasoning over standardized safety policies across both vision and text modalities. Our data generation pipeline emphasizes multimodal diversity, policy-grounded reasoning, and rigorous quality filtering using strong multimodal judges. Extensive experiments demonstrate that fine-tuning VLMs on MSR-Align substantially improves robustness against both textual and vision-language jailbreak attacks, while preserving or enhancing general reasoning performance. MSR-Align provides a scalable and effective foundation for advancing the safety alignment of reasoning-capable VLMs. Our dataset is made publicly available at https://huggingface.co/datasets/Leigest/MSR-Align.

