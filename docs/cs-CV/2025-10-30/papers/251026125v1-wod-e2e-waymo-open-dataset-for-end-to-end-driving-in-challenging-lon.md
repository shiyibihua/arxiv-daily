---
layout: default
title: WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios
---

# WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios

**arXiv**: [2510.26125v1](https://arxiv.org/abs/2510.26125) | [PDF](https://arxiv.org/pdf/2510.26125.pdf)

**ä½œè€…**: Runsheng Xu, Hubert Lin, Wonseok Jeon, Hao Feng, Yuliang Zou, Liting Sun, John Gorman, Kate Tolstaya, Sarah Tang, Brandyn White, Ben Sapp, Mingxing Tan, Jyh-Jing Hwang, Drago Anguelov

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWOD-E2Eæ•°æ®é›†å’ŒRFSæŒ‡æ ‡ä»¥è¯„ä¼°ç«¯åˆ°ç«¯é©¾é©¶åœ¨é•¿å°¾åœºæ™¯ä¸­çš„æ€§èƒ½**

**å…³é”®è¯**: `ç«¯åˆ°ç«¯é©¾é©¶` `é•¿å°¾åœºæ™¯æ•°æ®é›†` `å¼€æ”¾çŽ¯è¯„ä¼°æŒ‡æ ‡` `å¤šæ¨¡æ€é©¾é©¶` `è‡ªåŠ¨é©¾é©¶æŒ‘æˆ˜`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰ç«¯åˆ°ç«¯é©¾é©¶åŸºå‡†ç¼ºä¹å¯¹é•¿å°¾åœºæ™¯çš„å……åˆ†æµ‹è¯•ï¼Œä¸”è¯„ä¼°æŒ‡æ ‡éš¾ä»¥æ•æ‰å¤šæ¨¡æ€ç‰¹æ€§
2. æž„å»ºåŒ…å«4021æ®µé•¿å°¾åœºæ™¯æ•°æ®çš„WOD-E2Eæ•°æ®é›†ï¼Œå¹¶è®¾è®¡åŸºäºŽè¯„åˆ†è€…åå¥½çš„RFSè¯„ä¼°æŒ‡æ ‡
3. é€šè¿‡å‘å¸ƒéªŒè¯é›†æ ‡ç­¾å’Œä¸¾åŠžæŒ‘æˆ˜èµ›ï¼ŒæŽ¨åŠ¨é²æ£’è‡ªåŠ¨é©¾é©¶ç ”ç©¶ï¼ŒæœªçŸ¥å…·ä½“æ€§èƒ½æå‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-based end-to-end (E2E) driving has garnered significant interest in
> the research community due to its scalability and synergy with multimodal large
> language models (MLLMs). However, current E2E driving benchmarks primarily
> feature nominal scenarios, failing to adequately test the true potential of
> these systems. Furthermore, existing open-loop evaluation metrics often fall
> short in capturing the multi-modal nature of driving or effectively evaluating
> performance in long-tail scenarios. To address these gaps, we introduce the
> Waymo Open Dataset for End-to-End Driving (WOD-E2E). WOD-E2E contains 4,021
> driving segments (approximately 12 hours), specifically curated for challenging
> long-tail scenarios that that are rare in daily life with an occurring
> frequency of less than 0.03%. Concretely, each segment in WOD-E2E includes the
> high-level routing information, ego states, and 360-degree camera views from 8
> surrounding cameras. To evaluate the E2E driving performance on these long-tail
> situations, we propose a novel open-loop evaluation metric: Rater Feedback
> Score (RFS). Unlike conventional metrics that measure the distance between
> predicted way points and the logs, RFS measures how closely the predicted
> trajectory matches rater-annotated trajectory preference labels. We have
> released rater preference labels for all WOD-E2E validation set segments, while
> the held out test set labels have been used for the 2025 WOD-E2E Challenge.
> Through our work, we aim to foster state of the art research into
> generalizable, robust, and safe end-to-end autonomous driving agents capable of
> handling complex real-world situations.

