---
layout: default
title: Leveraging Large-Scale Face Datasets for Deep Periocular Recognition via Ocular Cropping
---

# Leveraging Large-Scale Face Datasets for Deep Periocular Recognition via Ocular Cropping

**arXiv**: [2510.26294v1](https://arxiv.org/abs/2510.26294) | [PDF](https://arxiv.org/pdf/2510.26294.pdf)

**ä½œè€…**: Fernando Alonso-Fernandez, Kevin Hernandez-Diaz, Jose Maria Buades Rubio, Josef Bigun

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å¤§è§„æ¨¡äººè„¸æ•°æ®é›†é€šè¿‡çœ¼éƒ¨è£å‰ªè¿›è¡Œæ·±åº¦çœ¼å‘¨è¯†åˆ«**

**å…³é”®è¯**: `çœ¼å‘¨è¯†åˆ«` `å·ç§¯ç¥žç»ç½‘ç»œ` `å¤§è§„æ¨¡æ•°æ®é›†` `ç”Ÿç‰©è¯†åˆ«` `å›¾åƒè£å‰ª` `æ€§èƒ½è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçœ¼å‘¨ç”Ÿç‰©è¯†åˆ«åœ¨éžå—æŽ§æ¡ä»¶ä¸‹æ€§èƒ½å—é™ï¼ŒçŽ°æœ‰æ–¹æ³•ä¾èµ–å°è§„æ¨¡æ•°æ®é›†ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä»ŽVGGFace2æå–190ä¸‡çœ¼éƒ¨å›¾åƒï¼Œè®­ç»ƒä¸‰ç§CNNæž¶æž„è¯„ä¼°è¯†åˆ«æ•ˆæžœã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨UFPR-Periocularä¸ŠEERè¾¾1-2%ï¼Œä¼˜äºŽVGGFace2-Poseçš„9-15%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We focus on ocular biometrics, specifically the periocular region (the area
> around the eye), which offers high discrimination and minimal acquisition
> constraints. We evaluate three Convolutional Neural Network architectures of
> varying depth and complexity to assess their effectiveness for periocular
> recognition. The networks are trained on 1,907,572 ocular crops extracted from
> the large-scale VGGFace2 database. This significantly contrasts with existing
> works, which typically rely on small-scale periocular datasets for training
> having only a few thousand images. Experiments are conducted with ocular images
> from VGGFace2-Pose, a subset of VGGFace2 containing in-the-wild face images,
> and the UFPR-Periocular database, which consists of selfies captured via mobile
> devices with user guidance on the screen. Due to the uncontrolled conditions of
> VGGFace2, the Equal Error Rates (EERs) obtained with ocular crops range from
> 9-15%, noticeably higher than the 3-6% EERs achieved using full-face images. In
> contrast, UFPR-Periocular yields significantly better performance (EERs of
> 1-2%), thanks to higher image quality and more consistent acquisition
> protocols. To the best of our knowledge, these are the lowest reported EERs on
> the UFPR dataset to date.

