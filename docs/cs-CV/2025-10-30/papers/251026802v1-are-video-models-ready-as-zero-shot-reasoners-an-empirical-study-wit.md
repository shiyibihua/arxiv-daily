---
layout: default
title: Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark
---

# Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark

**arXiv**: [2510.26802v1](https://arxiv.org/abs/2510.26802) | [PDF](https://arxiv.org/pdf/2510.26802.pdf)

**ä½œè€…**: Ziyu Guo, Xinyan Chen, Renrui Zhang, Ruichuan An, Yu Qi, Dongzhi Jiang, Xiangtai Li, Manyuan Zhang, Hongsheng Li, Pheng-Ann Heng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°è§†é¢‘æ¨¡åž‹åœ¨é›¶æ ·æœ¬æŽ¨ç†ä¸­çš„èƒ½åŠ›ï¼Œæ­ç¤ºå…¶åœ¨MME-CoFåŸºå‡†ä¸Šçš„è¡¨çŽ°**

**å…³é”®è¯**: `è§†é¢‘æ¨¡åž‹è¯„ä¼°` `é›¶æ ·æœ¬æŽ¨ç†` `MME-CoFåŸºå‡†` `é“¾å¼å¸§æŽ¨ç†` `è§†è§‰æŽ¨ç†èƒ½åŠ›`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†é¢‘æ¨¡åž‹æ˜¯å¦å¯ä½œä¸ºé›¶æ ·æœ¬æŽ¨ç†å™¨å¤„ç†å¤æ‚è§†è§‰æŽ¨ç†åœºæ™¯
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨Veo-3æ¨¡åž‹ï¼Œåœ¨12ä¸ªç»´åº¦ä¸Šç³»ç»Ÿè¯„ä¼°æŽ¨ç†è¡Œä¸º
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¨¡åž‹åœ¨çŸ­æ—¶ç©ºé—´ä¸€è‡´æ€§è¡¨çŽ°è‰¯å¥½ï¼Œä½†é•¿æ—¶å› æžœæŽ¨ç†èƒ½åŠ›æœ‰é™

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent video generation models can produce high-fidelity, temporally coherent
> videos, indicating that they may encode substantial world knowledge. Beyond
> realistic synthesis, they also exhibit emerging behaviors indicative of visual
> perception, modeling, and manipulation. Yet, an important question still
> remains: Are video models ready to serve as zero-shot reasoners in challenging
> visual reasoning scenarios? In this work, we conduct an empirical study to
> comprehensively investigate this question, focusing on the leading and popular
> Veo-3. We evaluate its reasoning behavior across 12 dimensions, including
> spatial, geometric, physical, temporal, and embodied logic, systematically
> characterizing both its strengths and failure modes. To standardize this study,
> we curate the evaluation data into MME-CoF, a compact benchmark that enables
> in-depth and thorough assessment of Chain-of-Frame (CoF) reasoning. Our
> findings reveal that while current video models demonstrate promising reasoning
> patterns on short-horizon spatial coherence, fine-grained grounding, and
> locally consistent dynamics, they remain limited in long-horizon causal
> reasoning, strict geometric constraints, and abstract logic. Overall, they are
> not yet reliable as standalone zero-shot reasoners, but exhibit encouraging
> signs as complementary visual engines alongside dedicated reasoning models.
> Project page: https://video-cof.github.io

