---
layout: default
title: SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models
---

# SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models

**arXiv**: [2510.26769v1](https://arxiv.org/abs/2510.26769) | [PDF](https://arxiv.org/pdf/2510.26769.pdf)

**ä½œè€…**: Anushka Sivakumar, Andrew Zhang, Zaber Hakim, Chris Thomas

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSteerVLMè½»é‡æ¿€æ´»å¼•å¯¼æ¨¡å—ï¼Œä»¥å¢žå¼ºè§†è§‰è¯­è¨€æ¨¡åž‹çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡åž‹` `æ¿€æ´»å¼•å¯¼` `è½»é‡æŽ§åˆ¶` `æŽ¨ç†æ—¶å¹²é¢„` `å¤šæ¨¡æ€æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§‰è¯­è¨€æ¨¡åž‹è¾“å‡ºéš¾ä»¥ç²¾ç¡®éµå¾ªå¤æ‚æŒ‡ä»¤ï¼Œéœ€è½»é‡æŽ§åˆ¶æ–¹æ³•ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå­¦ä¹ é…å¯¹æç¤ºåµŒå…¥ï¼ŒåŠ¨æ€è°ƒæ•´æ¿€æ´»ï¼Œå®žçŽ°æŽ¨ç†æ—¶ç»†ç²’åº¦è¯­ä¹‰æŽ§åˆ¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¼•å¯¼å’Œå¹»è§‰ç¼“è§£åŸºå‡†ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå‚æ•°ä»…å åŽŸæ¨¡åž‹0.14%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This work introduces SteerVLM, a lightweight steering module designed to
> guide Vision-Language Models (VLMs) towards outputs that better adhere to
> desired instructions. Our approach learns from the latent embeddings of paired
> prompts encoding target and converse behaviors to dynamically adjust
> activations connecting the language modality with image context. This allows
> for fine-grained, inference-time control over complex output semantics without
> modifying model weights while preserving performance on off-target tasks. Our
> steering module requires learning parameters equal to 0.14% of the original
> VLM's size. Our steering module gains model control through dimension-wise
> activation modulation and adaptive steering across layers without requiring
> pre-extracted static vectors or manual tuning of intervention points.
> Furthermore, we introduce VNIA (Visual Narrative Intent Alignment), a
> multimodal dataset specifically created to facilitate the development and
> evaluation of VLM steering techniques. Our method outperforms existing
> intervention techniques on steering and hallucination mitigation benchmarks for
> VLMs and proposes a robust solution for multimodal model control through
> activation engineering.

