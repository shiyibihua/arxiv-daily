---
layout: default
title: MoTDiff: High-resolution Motion Trajectory estimation from a single blurred image using Diffusion models
---

# MoTDiff: High-resolution Motion Trajectory estimation from a single blurred image using Diffusion models

**arXiv**: [2510.26173v1](https://arxiv.org/abs/2510.26173) | [PDF](https://arxiv.org/pdf/2510.26173.pdf)

**ä½œè€…**: Wontae Choi, Jaelin Lee, Hyung Sup Yun, Byeungwoo Jeon, Il Yong Chun

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMoTDiffæ¡†æž¶ï¼Œä½¿ç”¨æ‰©æ•£æ¨¡åž‹ä»Žå•å¼ æ¨¡ç³Šå›¾åƒä¼°è®¡é«˜åˆ†è¾¨çŽ‡è¿åŠ¨è½¨è¿¹ã€‚**

**å…³é”®è¯**: `è¿åŠ¨è½¨è¿¹ä¼°è®¡` `æ‰©æ•£æ¨¡åž‹` `ç›²å›¾åƒåŽ»æ¨¡ç³Š` `ç¼–ç æ›å…‰æ‘„å½±` `é«˜åˆ†è¾¨çŽ‡ä¼°è®¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ä»Žå•å¼ æ¨¡ç³Šå›¾åƒæå–è¿åŠ¨ä¿¡æ¯çš„æ–¹æ³•è´¨é‡ä½Žï¼Œè½¨è¿¹ç²—ç³™ä¸”ä¸å‡†ç¡®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ¡ä»¶æ‰©æ•£æ¡†æž¶ï¼Œä»¥å¤šå°ºåº¦ç‰¹å¾å›¾ä¸ºæ¡ä»¶ï¼Œç»“åˆæ–°è®­ç»ƒæ–¹æ³•æå‡è½¨è¿¹ç²¾åº¦ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ç›²å›¾åƒåŽ»æ¨¡ç³Šå’Œç¼–ç æ›å…‰æ‘„å½±åº”ç”¨ä¸­ä¼˜äºŽçŽ°æœ‰å…ˆè¿›æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Accurate estimation of motion information is crucial in diverse computational
> imaging and computer vision applications. Researchers have investigated various
> methods to extract motion information from a single blurred image, including
> blur kernels and optical flow. However, existing motion representations are
> often of low quality, i.e., coarse-grained and inaccurate. In this paper, we
> propose the first high-resolution (HR) Motion Trajectory estimation framework
> using Diffusion models (MoTDiff). Different from existing motion
> representations, we aim to estimate an HR motion trajectory with high-quality
> from a single motion-blurred image. The proposed MoTDiff consists of two key
> components: 1) a new conditional diffusion framework that uses multi-scale
> feature maps extracted from a single blurred image as a condition, and 2) a new
> training method that can promote precise identification of a fine-grained
> motion trajectory, consistent estimation of overall shape and position of a
> motion path, and pixel connectivity along a motion trajectory. Our experiments
> demonstrate that the proposed MoTDiff can outperform state-of-the-art methods
> in both blind image deblurring and coded exposure photography applications.

