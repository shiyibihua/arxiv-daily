---
layout: default
title: Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems
---

# Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems

**arXiv**: [2510.26656v1](https://arxiv.org/abs/2510.26656) | [PDF](https://arxiv.org/pdf/2510.26656.pdf)

**ä½œè€…**: Georgios Kamaras, Craig Innes, Subramanian Ramamoorthy

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸‰ç§å¯å‘å¼LFIå˜ä½“ä»¥è§£å†³éšæœºåŠ¨åŠ›ç³»ç»Ÿä¸­é¢†åŸŸæ”¯æŒè¯¯è®¾é—®é¢˜**

**å…³é”®è¯**: `æ— ä¼¼ç„¶æŽ¨æ–­` `éšæœºåŠ¨åŠ›ç³»ç»Ÿ` `é¢†åŸŸé€‚åº”` `åŽéªŒæŽ¨æ–­` `å¯å‘å¼æ–¹æ³•` `æœºå™¨äººå­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šLFIä¸­å›ºå®šæ”¯æŒå¯èƒ½å¯¼è‡´åŽéªŒæ¬¡ä¼˜ä¸”è™šå‡ç¡®å®š
2. æ–¹æ³•è¦ç‚¹ï¼šEDGEã€MODEå’ŒCENTREå˜ä½“æ ¹æ®åŽéªŒæ¨¡å¼åç§»è‡ªé€‚åº”è°ƒæ•´æ”¯æŒ
3. å®žéªŒæ•ˆæžœï¼šåœ¨DLOæ“ä½œä»»åŠ¡ä¸­æå‡å‚æ•°æŽ¨æ–­å’Œç­–ç•¥å­¦ä¹ çš„é²æ£’æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In robotics, likelihood-free inference (LFI) can provide the domain
> distribution that adapts a learnt agent in a parametric set of deployment
> conditions. LFI assumes an arbitrary support for sampling, which remains
> constant as the initial generic prior is iteratively refined to more
> descriptive posteriors. However, a potentially misspecified support can lead to
> suboptimal, yet falsely certain, posteriors. To address this issue, we propose
> three heuristic LFI variants: EDGE, MODE, and CENTRE. Each interprets the
> posterior mode shift over inference steps in its own way and, when integrated
> into an LFI step, adapts the support alongside posterior inference. We first
> expose the support misspecification issue and evaluate our heuristics using
> stochastic dynamical benchmarks. We then evaluate the impact of heuristic
> support adaptation on parameter inference and policy learning for a dynamic
> deformable linear object (DLO) manipulation task. Inference results in a finer
> length and stiffness classification for a parametric set of DLOs. When the
> resulting posteriors are used as domain distributions for sim-based policy
> learning, they lead to more robust object-centric agent performance.

