---
layout: default
title: CATCH: A Modular Cross-domain Adaptive Template with Hook
---

# CATCH: A Modular Cross-domain Adaptive Template with Hook

**arXiv**: [2510.26582v1](https://arxiv.org/abs/2510.26582) | [PDF](https://arxiv.org/pdf/2510.26582.pdf)

**ä½œè€…**: Xinjin Li, Yulie Lu, Jinghan Cao, Yu Ma, Zhenglin Li, Yeyang Zhou

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCATCHæ¡†æž¶ä»¥è§£å†³è§†è§‰é—®ç­”æ¨¡åž‹è·¨åŸŸæ³›åŒ–é—®é¢˜**

**å…³é”®è¯**: `è§†è§‰é—®ç­”` `è·¨åŸŸé€‚åº”` `æ¨¡å—åŒ–æ¡†æž¶` `è½»é‡çº§é€‚é…å™¨` `å¤šåŸŸæ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šVQAæ¨¡åž‹åœ¨é¥æ„Ÿã€åŒ»ç–—ç­‰è·¨åŸŸåœºæ™¯ä¸­æ³›åŒ–æ€§èƒ½æ˜¾è‘—ä¸‹é™
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡è½»é‡çº§åŸŸåˆ†ç±»å™¨å’ŒåŒé€‚é…å™¨æ¨¡å—å®žçŽ°è§†è§‰ä¸Žè¯­è¨€è§£è€¦é€‚åº”
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªVQAåŸºå‡†ä¸Šå®žçŽ°æ€§èƒ½æå‡ï¼Œæ— éœ€é‡è®­ç»ƒéª¨å¹²æ¨¡åž‹

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in Visual Question Answering (VQA) have demonstrated
> impressive performance in natural image domains, with models like LLaVA
> leveraging large language models (LLMs) for open-ended reasoning. However,
> their generalization degrades significantly when transferred to out-of-domain
> scenarios such as remote sensing, medical imaging, or math diagrams, due to
> large distributional shifts and the lack of effective domain adaptation
> mechanisms. Existing approaches typically rely on per-domain fine-tuning or
> bespoke pipelines, which are costly, inflexible, and not scalable across
> diverse tasks. In this paper, we propose CATCH, a plug-and-play framework for
> cross-domain adaptation that improves the generalization of VQA models while
> requiring minimal changes to their core architecture. Our key idea is to
> decouple visual and linguistic adaptation by introducing two lightweight
> modules: a domain classifier to identify the input image type, and a dual
> adapter mechanism comprising a Prompt Adapter for language modulation and a
> Visual Adapter for vision feature adjustment. Both modules are dynamically
> injected via a unified hook interface, requiring no retraining of the backbone
> model. Experimental results across four domain-specific VQA benchmarks
> demonstrate that our framework achieves consistent performance gains without
> retraining the backbone model, including +2.3 BLEU on MathVQA, +2.6 VQA on
> MedVQA-RAD, and +3.1 ROUGE on ChartQA. These results highlight that CATCH
> provides a scalable and extensible approach to multi-domain VQA, enabling
> practical deployment across diverse application domains.

