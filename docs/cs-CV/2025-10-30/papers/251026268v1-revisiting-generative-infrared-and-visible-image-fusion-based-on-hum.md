---
layout: default
title: Revisiting Generative Infrared and Visible Image Fusion Based on Human Cognitive Laws
---

# Revisiting Generative Infrared and Visible Image Fusion Based on Human Cognitive Laws

**arXiv**: [2510.26268v1](https://arxiv.org/abs/2510.26268) | [PDF](https://arxiv.org/pdf/2510.26268.pdf)

**ä½œè€…**: Lin Guo, Xiaoqing Luo, Wei Xie, Zhancheng Zhang, Hui Li, Rui Wang, Zhenhua Feng, Xiaoning Song

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHCLFuseæ–¹æ³•ä»¥è§£å†³çº¢å¤–ä¸Žå¯è§å…‰å›¾åƒèžåˆä¸­çš„æ¨¡æ€å¹³è¡¡ä¸Žç”Ÿæˆèƒ½åŠ›é—®é¢˜**

**å…³é”®è¯**: `å›¾åƒèžåˆ` `ç”Ÿæˆæ¨¡åž‹` `å˜åˆ†ç¼–ç å™¨` `æ‰©æ•£æ¨¡åž‹` `è®¤çŸ¥å¯å‘` `å¤šæ¨¡æ€ä¿¡æ¯`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•éš¾ä»¥å¹³è¡¡æ¨¡æ€ä¿¡æ¯ï¼Œç”Ÿæˆèƒ½åŠ›æœ‰é™ä¸”ç¼ºä¹å¯è§£é‡Šæ€§
2. è®¾è®¡å¤šå°ºåº¦æŽ©ç è°ƒæŽ§å˜åˆ†ç“¶é¢ˆç¼–ç å™¨ï¼Œç»“åˆæ‰©æ•£æ¨¡åž‹ä¸Žç‰©ç†è§„å¾‹å¢žå¼ºç”Ÿæˆ
3. å®žéªŒæ˜¾ç¤ºåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®žçŽ°æœ€ä¼˜èžåˆæ€§èƒ½ï¼Œæ˜¾è‘—æå‡è¯­ä¹‰åˆ†å‰²æŒ‡æ ‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Existing infrared and visible image fusion methods often face the dilemma of
> balancing modal information. Generative fusion methods reconstruct fused images
> by learning from data distributions, but their generative capabilities remain
> limited. Moreover, the lack of interpretability in modal information selection
> further affects the reliability and consistency of fusion results in complex
> scenarios. This manuscript revisits the essence of generative image fusion
> under the inspiration of human cognitive laws and proposes a novel infrared and
> visible image fusion method, termed HCLFuse. First, HCLFuse investigates the
> quantification theory of information mapping in unsupervised fusion networks,
> which leads to the design of a multi-scale mask-regulated variational
> bottleneck encoder. This encoder applies posterior probability modeling and
> information decomposition to extract accurate and concise low-level modal
> information, thereby supporting the generation of high-fidelity structural
> details. Furthermore, the probabilistic generative capability of the diffusion
> model is integrated with physical laws, forming a time-varying physical
> guidance mechanism that adaptively regulates the generation process at
> different stages, thereby enhancing the ability of the model to perceive the
> intrinsic structure of data and reducing dependence on data quality.
> Experimental results show that the proposed method achieves state-of-the-art
> fusion performance in qualitative and quantitative evaluations across multiple
> datasets and significantly improves semantic segmentation metrics. This fully
> demonstrates the advantages of this generative image fusion method, drawing
> inspiration from human cognition, in enhancing structural consistency and
> detail quality.

