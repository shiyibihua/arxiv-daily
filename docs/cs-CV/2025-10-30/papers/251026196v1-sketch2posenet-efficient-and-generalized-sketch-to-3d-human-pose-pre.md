---
layout: default
title: Sketch2PoseNet: Efficient and Generalized Sketch to 3D Human Pose Prediction
---

# Sketch2PoseNet: Efficient and Generalized Sketch to 3D Human Pose Prediction

**arXiv**: [2510.26196v1](https://arxiv.org/abs/2510.26196) | [PDF](https://arxiv.org/pdf/2510.26196.pdf)

**ä½œè€…**: Li Wang, Yiyu Zhuang, Yanwen Wang, Xun Cao, Chuan Guo, Xinxin Zuo, Hao Zhu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSketch2PoseNetï¼Œé€šè¿‡åˆæˆæ•°æ®é›†å’Œç«¯åˆ°ç«¯æ¡†æž¶è§£å†³è‰å›¾åˆ°3Däººä½“å§¿æ€é¢„æµ‹é—®é¢˜**

**å…³é”®è¯**: `è‰å›¾åˆ°3Då§¿æ€é¢„æµ‹` `æ‰©æ•£æ¨¡åž‹åˆæˆ` `ç«¯åˆ°ç«¯æ¡†æž¶` `äººä½“å§¿æ€ä¼°è®¡` `åˆæˆæ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‰å›¾æŠ½è±¡ä¸”ä¸æˆæ¯”ä¾‹ï¼Œç¼ºä¹å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®ï¼Œä¼ ç»Ÿæ–¹æ³•è€—æ—¶ä¸”æ³›åŒ–æ€§å·®
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ‰©æ•£æ¨¡åž‹åˆæˆè‰å›¾æ•°æ®é›†ï¼Œç»“åˆ2Då§¿æ€æ£€æµ‹å™¨å’Œå‰é¦ˆç½‘ç»œè¿›è¡Œé«˜æ•ˆä¼°è®¡
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å‡†ç¡®æ€§å’Œé€Ÿåº¦ä¸Šæ˜¾è‘—è¶…è¶Šå…ˆå‰æ–¹æ³•ï¼Œæ”¯æŒå¤šç§è‰å›¾é£Žæ ¼

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> 3D human pose estimation from sketches has broad applications in computer
> animation and film production. Unlike traditional human pose estimation, this
> task presents unique challenges due to the abstract and disproportionate nature
> of sketches. Previous sketch-to-pose methods, constrained by the lack of
> large-scale sketch-3D pose annotations, primarily relied on optimization with
> heuristic rules-an approach that is both time-consuming and limited in
> generalizability. To address these challenges, we propose a novel approach
> leveraging a "learn from synthesis" strategy. First, a diffusion model is
> trained to synthesize sketch images from 2D poses projected from 3D human
> poses, mimicking disproportionate human structures in sketches. This process
> enables the creation of a synthetic dataset, SKEP-120K, consisting of 120k
> accurate sketch-3D pose annotation pairs across various sketch styles. Building
> on this synthetic dataset, we introduce an end-to-end data-driven framework for
> estimating human poses and shapes from diverse sketch styles. Our framework
> combines existing 2D pose detectors and generative diffusion priors for sketch
> feature extraction with a feed-forward neural network for efficient 2D pose
> estimation. Multiple heuristic loss functions are incorporated to guarantee
> geometric coherence between the derived 3D poses and the detected 2D poses
> while preserving accurate self-contacts. Qualitative, quantitative, and
> subjective evaluations collectively show that our model substantially surpasses
> previous ones in both estimation accuracy and speed for sketch-to-pose tasks.

