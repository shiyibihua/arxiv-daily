---
layout: default
title: ChartAB: A Benchmark for Chart Grounding & Dense Alignment
---

# ChartAB: A Benchmark for Chart Grounding & Dense Alignment

**arXiv**: [2510.26781v1](https://arxiv.org/abs/2510.26781) | [PDF](https://arxiv.org/pdf/2510.26781.pdf)

**ä½œè€…**: Aniruddh Bansal, Davit Soselia, Dang Nguyen, Tianyi Zhou

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºChartABåŸºå‡†ä»¥è¯„ä¼°è§†è§‰è¯­è¨€æ¨¡åž‹åœ¨å›¾è¡¨ç»†ç²’åº¦å¯¹é½ä¸Žæ¯”è¾ƒä¸­çš„èƒ½åŠ›**

**å…³é”®è¯**: `å›¾è¡¨ç†è§£` `è§†è§‰è¯­è¨€æ¨¡åž‹è¯„ä¼°` `ç»†ç²’åº¦å¯¹é½` `åŸºå‡†æµ‹è¯•` `å¤šå›¾è¡¨æ¯”è¾ƒ` `JSONæ¨¡æ¿`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†è§‰è¯­è¨€æ¨¡åž‹åœ¨å›¾è¡¨ç»†èŠ‚æ„ŸçŸ¥å’Œç»“æž„æå–æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå½±å“å¤šå›¾è¡¨æ¯”è¾ƒä¸ŽæŽ¨ç†
2. è®¾è®¡JSONæ¨¡æ¿å’Œä¸¤é˜¶æ®µæŽ¨ç†å·¥ä½œæµï¼Œæ”¯æŒå›¾è¡¨å…ƒç´ å®šä½ã€å±žæ€§è¯†åˆ«å’Œè·¨å›¾è¡¨å¯¹é½è¯„ä¼°
3. è¯„ä¼°å¤šä¸ªæ¨¡åž‹æ­ç¤ºæ„ŸçŸ¥åå·®ã€å¼±ç‚¹å’Œå¹»è§‰ï¼Œä¸ºæ¨¡åž‹æ”¹è¿›æä¾›å…·ä½“æ–¹å‘

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Charts play an important role in visualization, reasoning, data analysis, and
> the exchange of ideas among humans. However, existing vision-language models
> (VLMs) still lack accurate perception of details and struggle to extract
> fine-grained structures from charts. Such limitations in chart grounding also
> hinder their ability to compare multiple charts and reason over them. In this
> paper, we introduce a novel "ChartAlign Benchmark (ChartAB)" to provide a
> comprehensive evaluation of VLMs in chart grounding tasks, i.e., extracting
> tabular data, localizing visualization elements, and recognizing various
> attributes from charts of diverse types and complexities. We design a JSON
> template to facilitate the calculation of evaluation metrics specifically
> tailored for each grounding task. By incorporating a novel two-stage inference
> workflow, the benchmark can further evaluate VLMs' capability to align and
> compare elements/attributes across two charts. Our analysis of evaluations on
> several recent VLMs reveals new insights into their perception biases,
> weaknesses, robustness, and hallucinations in chart understanding. These
> findings highlight the fine-grained discrepancies among VLMs in chart
> understanding tasks and point to specific skills that need to be strengthened
> in current models.

