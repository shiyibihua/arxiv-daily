---
layout: default
title: Process-Centric Analysis of Agentic Software Systems
---

# Process-Centric Analysis of Agentic Software Systems

**arXiv**: [2512.02393v1](https://arxiv.org/abs/2512.02393) | [PDF](https://arxiv.org/pdf/2512.02393.pdf)

**ä½œè€…**: Shuyang Liu, Yang Chen, Rahul Krishna, Saurabh Sinha, Jatin Ganhotra, Reyhan Jabbarvand

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGraphectoryä»¥ç³»ç»Ÿåˆ†æžæ™ºèƒ½ä½“è½¯ä»¶ç³»ç»Ÿçš„è¿‡ç¨‹è´¨é‡ï¼Œç‹¬ç«‹äºŽæœ€ç»ˆæˆåŠŸ**

**å…³é”®è¯**: `æ™ºèƒ½ä½“è½¯ä»¶ç³»ç»Ÿ` `è¿‡ç¨‹åˆ†æž` `Graphectory` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `è½¯ä»¶å·¥ç¨‹ä»£ç†` `è½¨è¿¹åˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è¯„ä¼°èšç„¦æœ€ç»ˆç»“æžœï¼Œå¿½è§†æ™ºèƒ½ä½“æŽ¨ç†ã€è§„åˆ’å’Œç­–ç•¥å˜åŒ–çš„è¯¦ç»†è¿‡ç¨‹åˆ†æžã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥Graphectoryç¼–ç æ™ºèƒ½ä½“ç³»ç»Ÿçš„æ—¶ç©ºå’Œè¯­ä¹‰å…³ç³»ï¼Œæ”¯æŒè¿‡ç¨‹ä¸­å¿ƒåº¦é‡å’Œåˆ†æžã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåˆ†æž4000æ¡è½¨è¿¹ï¼Œæ­ç¤ºæç¤ºã€LLMå’Œé—®é¢˜éš¾åº¦å¦‚ä½•å½±å“ç­–ç•¥æ•ˆçŽ‡å’Œå¤æ‚æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Agentic systems are modern software systems: they consist of orchestrated modules, expose interfaces, and are deployed in software pipelines. Unlike conventional programs, their execution (i.e., trajectories) is inherently stochastic and adaptive to the problem they are solving. Evaluation of such systems is often outcome-centric, judging their performance based on success or failure at the final step. This narrow focus overlooks detailed insights about such systems, failing to explain how agents reason, plan, act, or change their strategies over time. Inspired by the structured representation of conventional software systems as graphs, we introduce Graphectory to systematically encode the temporal and semantic relations in such software systems. Graphectory facilitates the design of process-centric metrics and analyses to assess the quality of agentic workflows independent of final success.
>   Using Graphectory, we analyze 4000 trajectories of two dominant agentic programming workflows, namely SWE-agent and OpenHands, with a combination of four backbone Large Language Models (LLMs), attempting to resolve SWE-bench Verified issues. Our fully automated analyses reveal that: (1) agents using richer prompts or stronger LLMs exhibit more complex Graphectory, reflecting deeper exploration, broader context gathering, and more thorough validation before patch submission; (2) agents' problem-solving strategies vary with both problem difficulty and the underlying LLM -- for resolved issues, the strategies often follow coherent localization-patching-validation steps, while unresolved ones exhibit chaotic, repetitive, or backtracking behaviors; (3) even when successful, agentic programming systems often display inefficient processes, leading to unnecessarily prolonged trajectories.

