---
layout: default
title: From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?
---

# From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?

**arXiv**: [2512.03005v1](https://arxiv.org/abs/2512.03005) | [PDF](https://arxiv.org/pdf/2512.03005.pdf)

**ä½œè€…**: Dawei Li, Abdullah Alnaibari, Arslan Bisharat, Manny Sandoval, Deborah Hall, Yasin Silva, Huan Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLLMä½œä¸ºåœ¨çº¿å†²çªè°ƒè§£è€…çš„æ¡†æž¶ï¼Œé€šè¿‡åˆ¤æ–­ä¸Žå¼•å¯¼ä»»åŠ¡è¯„ä¼°å…¶è°ƒè§£èƒ½åŠ›ã€‚**

**å…³é”®è¯**: `å¤§åž‹è¯­è¨€æ¨¡åž‹` `åœ¨çº¿å†²çªè°ƒè§£` `æƒ…æ„Ÿåˆ†æž` `å¯¹è¯ç”Ÿæˆ` `è¯„ä¼°æ¡†æž¶` `Redditæ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæŽ¢ç´¢LLMèƒ½å¦ä»Žå†…å®¹å®¡æ ¸æ‰©å±•åˆ°åœ¨çº¿å†²çªè°ƒè§£ï¼Œä»¥ä¿ƒè¿›å»ºè®¾æ€§å¯¹è¯ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†è°ƒè§£åˆ†è§£ä¸ºåˆ¤æ–­å¯¹è¯å…¬å¹³æ€§ä¸Žæƒ…æ„ŸåŠ¨æ€ã€ç”Ÿæˆå…±æƒ…æ¶ˆæ¯å¼•å¯¼è§£å†³ä¸¤ä¸ªå­ä»»åŠ¡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåŸºäºŽRedditæ•°æ®é›†è¯„ä¼°ï¼ŒAPIæ¨¡åž‹åœ¨æŽ¨ç†å’Œå¹²é¢„å¯¹é½ä¸Šä¼˜äºŽå¼€æºæ¨¡åž‹ï¼Œæ˜¾ç¤ºæ½œåŠ›ä¸Žå±€é™ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The rapid advancement of large language models (LLMs) has opened new possibilities for AI for good applications. As LLMs increasingly mediate online communication, their potential to foster empathy and constructive dialogue becomes an important frontier for responsible AI research. This work explores whether LLMs can serve not only as moderators that detect harmful content, but as mediators capable of understanding and de-escalating online conflicts. Our framework decomposes mediation into two subtasks: judgment, where an LLM evaluates the fairness and emotional dynamics of a conversation, and steering, where it generates empathetic, de-escalatory messages to guide participants toward resolution. To assess mediation quality, we construct a large Reddit-based dataset and propose a multi-stage evaluation pipeline combining principle-based scoring, user simulation, and human comparison. Experiments show that API-based models outperform open-source counterparts in both reasoning and intervention alignment when doing mediation. Our findings highlight both the promise and limitations of current LLMs as emerging agents for online social mediation.

