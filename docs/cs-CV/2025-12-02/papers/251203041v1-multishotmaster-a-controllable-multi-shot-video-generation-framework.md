---
layout: default
title: MultiShotMaster: A Controllable Multi-Shot Video Generation Framework
---

# MultiShotMaster: A Controllable Multi-Shot Video Generation Framework

**arXiv**: [2512.03041v1](https://arxiv.org/abs/2512.03041) | [PDF](https://arxiv.org/pdf/2512.03041.pdf)

**ä½œè€…**: Qinghe Wang, Xiaoyu Shi, Baolu Li, Weikang Bian, Quande Liu, Huchuan Lu, Xintao Wang, Pengfei Wan, Kun Gai, Xu Jia

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMultiShotMasteræ¡†æž¶ä»¥è§£å†³å¯æŽ§å¤šé•œå¤´è§†é¢‘ç”Ÿæˆé—®é¢˜**

**å…³é”®è¯**: `å¤šé•œå¤´è§†é¢‘ç”Ÿæˆ` `å¯æŽ§è§†é¢‘ç”Ÿæˆ` `RoPEå˜ä½“` `æ—¶ç©ºä½ç½®æ„ŸçŸ¥` `è‡ªåŠ¨åŒ–æ•°æ®æ ‡æ³¨` `å™äº‹è¿žè´¯æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§†é¢‘ç”ŸæˆæŠ€æœ¯éš¾ä»¥ç”Ÿæˆå™äº‹è¿žè´¯ã€é•œå¤´å®‰æŽ’çµæ´»çš„å¤šé•œå¤´è§†é¢‘
2. æ–¹æ³•è¦ç‚¹ï¼šæ‰©å±•é¢„è®­ç»ƒå•é•œå¤´æ¨¡åž‹ï¼Œå¼•å…¥å¤šé•œå¤´å™äº‹RoPEå’Œæ—¶ç©ºä½ç½®æ„ŸçŸ¥RoPEå˜ä½“
3. å®žéªŒæˆ–æ•ˆæžœï¼šé€šè¿‡è‡ªåŠ¨åŒ–æ•°æ®æ ‡æ³¨å’Œå®žéªŒéªŒè¯äº†æ¡†æž¶çš„ä¼˜è¶Šæ€§èƒ½å’Œå¯æŽ§æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Current video generation techniques excel at single-shot clips but struggle to produce narrative multi-shot videos, which require flexible shot arrangement, coherent narrative, and controllability beyond text prompts. To tackle these challenges, we propose MultiShotMaster, a framework for highly controllable multi-shot video generation. We extend a pretrained single-shot model by integrating two novel variants of RoPE. First, we introduce Multi-Shot Narrative RoPE, which applies explicit phase shift at shot transitions, enabling flexible shot arrangement while preserving the temporal narrative order. Second, we design Spatiotemporal Position-Aware RoPE to incorporate reference tokens and grounding signals, enabling spatiotemporal-grounded reference injection. In addition, to overcome data scarcity, we establish an automated data annotation pipeline to extract multi-shot videos, captions, cross-shot grounding signals and reference images. Our framework leverages the intrinsic architectural properties to support multi-shot video generation, featuring text-driven inter-shot consistency, customized subject with motion control, and background-driven customized scene. Both shot count and duration are flexibly configurable. Extensive experiments demonstrate the superior performance and outstanding controllability of our framework.

