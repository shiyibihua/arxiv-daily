---
layout: default
title: Reasoning Path and Latent State Analysis for Multi-view Visual Spatial Reasoning: A Cognitive Science Perspective
---

# Reasoning Path and Latent State Analysis for Multi-view Visual Spatial Reasoning: A Cognitive Science Perspective

**arXiv**: [2512.02340v1](https://arxiv.org/abs/2512.02340) | [PDF](https://arxiv.org/pdf/2512.02340.pdf)

**ä½œè€…**: Qiyao Xue, Weichen Liu, Shiqi Wang, Haoming Wang, Yuyang Wu, Wei Gao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºReMindView-BenchåŸºå‡†ä»¥è¯„ä¼°å¤šè§†å›¾è§†è§‰ç©ºé—´æŽ¨ç†ä¸­è§†è§‰è¯­è¨€æ¨¡åž‹çš„è®¤çŸ¥èƒ½åŠ›**

**å…³é”®è¯**: `å¤šè§†å›¾ç©ºé—´æŽ¨ç†` `è§†è§‰è¯­è¨€æ¨¡åž‹` `è®¤çŸ¥åŸºå‡†` `è·¨è§†å›¾ä¸€è‡´æ€§` `æŽ¨ç†è·¯å¾„åˆ†æž` `ç†µåŠ¨æ€`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå½“å‰è§†è§‰è¯­è¨€æ¨¡åž‹åœ¨å¤šè§†å›¾ç©ºé—´æŽ¨ç†ä¸­ç¼ºä¹å‡ ä½•ä¸€è‡´æ€§å’Œè·¨è§†å›¾ä¸€è‡´æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºè®¤çŸ¥åŸºç¡€åŸºå‡†ï¼Œç³»ç»Ÿå˜åŒ–è§†å›¾ç©ºé—´æ¨¡å¼å’ŒæŸ¥è¯¢ç±»åž‹ä»¥æŽ¢æµ‹ç©ºé—´è®¤çŸ¥å…³é”®å› ç´ ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè¯„ä¼°15ä¸ªæ¨¡åž‹ï¼Œæ­ç¤ºè·¨è§†å›¾å¯¹é½å’Œè§†è§’é‡‡æ ·çš„å¤±è´¥ï¼Œå¹¶é€šè¿‡æ˜¾éšåˆ†æžè¯Šæ–­æŽ¨ç†è¿‡ç¨‹é€€åŒ–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Spatial reasoning is a core aspect of human intelligence that allows perception, inference and planning in 3D environments. However, current vision-language models (VLMs) struggle to maintain geometric coherence and cross-view consistency for spatial reasoning in multi-view settings. We attribute this gap to the lack of fine-grained benchmarks that isolate multi-view reasoning from single-view perception and temporal factors. To address this, we present ReMindView-Bench, a cognitively grounded benchmark for evaluating how VLMs construct, align and maintain spatial mental models across complementary viewpoints. ReMindView-Bench systematically varies viewpoint spatial pattern and query type to probe key factors of spatial cognition. Evaluations of 15 current VLMs reveals consistent failures in cross-view alignment and perspective-taking in multi-view spatial reasoning, motivating deeper analysis on the reasoning process. Explicit phase-wise analysis using LLM-as-a-judge and self-consistency prompting shows that VLMs perform well on in-frame perception but degrade sharply when integrating information across views. Implicit analysis, including linear probing and entropy dynamics, further show progressive loss of task-relevant information and uncertainty separation between correct and incorrect trajectories. These results provide a cognitively grounded diagnosis of VLM spatial reasoning and reveal how multi-view spatial mental models are formed, degraded and destabilized across reasoning phases. The ReMindView-Bench benchmark is available at https://huggingface.co/datasets/Xue0823/ReMindView-Bench, and the source codes of benchmark construction and VLM reasoning analysis are available at https://github.com/pittisl/ReMindView-Bench.

