---
layout: default
title: SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control
---

# SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control

**arXiv**: [2512.03028v1](https://arxiv.org/abs/2512.03028) | [PDF](https://arxiv.org/pdf/2512.03028.pdf)

**ä½œè€…**: Yuxuan Mu, Ziyu Zhang, Yi Shi, Minami Matsumoto, Kotaro Imamura, Guy Tevet, Chuan Guo, Michael Taylor, Chang Shu, Pengcheng Xi, Xue Bin Peng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯é‡ç”¨åˆ†æ•°åŒ¹é…è¿åŠ¨å…ˆéªŒï¼ŒåŸºäºŽæ‰©æ•£æ¨¡åž‹æå‡ç‰©ç†è§’è‰²æŽ§åˆ¶è‡ªç„¶æ€§**

**å…³é”®è¯**: `è¿åŠ¨å…ˆéªŒ` `åˆ†æ•°åŒ¹é…` `æ‰©æ•£æ¨¡åž‹` `ç‰©ç†è§’è‰²æŽ§åˆ¶` `å¯é‡ç”¨å¥–åŠ±`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¯¹æŠ—æ¨¡ä»¿å­¦ä¹ å…ˆéªŒéœ€é’ˆå¯¹æ¯ä¸ªæ–°æŽ§åˆ¶å™¨é‡æ–°è®­ç»ƒï¼Œé™åˆ¶é‡ç”¨æ€§å¹¶éœ€ä¿ç•™å‚è€ƒæ•°æ®
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨é¢„è®­ç»ƒè¿åŠ¨æ‰©æ•£æ¨¡åž‹å’Œåˆ†æ•°è’¸é¦é‡‡æ ·ï¼Œæž„å»ºä»»åŠ¡æ— å…³å¯é‡ç”¨è¿åŠ¨å…ˆéªŒä½œä¸ºå¥–åŠ±å‡½æ•°
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šæ ·åŒ–ç‰©ç†äººå½¢æŽ§åˆ¶ä»»åŠ¡ä¸­ï¼Œç”Ÿæˆé«˜è´¨é‡è¿åŠ¨ï¼Œå¯ç»„åˆé£Žæ ¼åˆæˆæ–°é£Žæ ¼

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Data-driven motion priors that can guide agents toward producing naturalistic behaviors play a pivotal role in creating life-like virtual characters. Adversarial imitation learning has been a highly effective method for learning motion priors from reference motion data. However, adversarial priors, with few exceptions, need to be retrained for each new controller, thereby limiting their reusability and necessitating the retention of the reference motion data when training on downstream tasks. In this work, we present Score-Matching Motion Priors (SMP), which leverages pre-trained motion diffusion models and score distillation sampling (SDS) to create reusable task-agnostic motion priors. SMPs can be pre-trained on a motion dataset, independent of any control policy or task. Once trained, SMPs can be kept frozen and reused as general-purpose reward functions to train policies to produce naturalistic behaviors for downstream tasks. We show that a general motion prior trained on large-scale datasets can be repurposed into a variety of style-specific priors. Furthermore SMP can compose different styles to synthesize new styles not present in the original dataset. Our method produces high-quality motion comparable to state-of-the-art adversarial imitation learning methods through reusable and modular motion priors. We demonstrate the effectiveness of SMP across a diverse suite of control tasks with physically simulated humanoid characters. Video demo available at https://youtu.be/ravlZJteS20

