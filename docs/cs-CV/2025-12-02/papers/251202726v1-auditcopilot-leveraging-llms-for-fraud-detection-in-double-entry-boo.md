---
layout: default
title: AuditCopilot: Leveraging LLMs for Fraud Detection in Double-Entry Bookkeeping
---

# AuditCopilot: Leveraging LLMs for Fraud Detection in Double-Entry Bookkeeping

**arXiv**: [2512.02726v1](https://arxiv.org/abs/2512.02726) | [PDF](https://arxiv.org/pdf/2512.02726.pdf)

**ä½œè€…**: Md Abdul Kadir, Sai Suresh Macharla Vasu, Sidharth S. Nair, Daniel Sonntag

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAuditCopilotï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡åž‹æ£€æµ‹å¤å¼è®°è´¦ä¸­çš„æ¬ºè¯ˆï¼Œä»¥æå‡å®¡è®¡æ•ˆçŽ‡å’Œå¯è§£é‡Šæ€§ã€‚**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹` `æ¬ºè¯ˆæ£€æµ‹` `å¤å¼è®°è´¦` `å®¡è®¡å¢žå¼º` `å¼‚å¸¸æ£€æµ‹` `å¯è§£é‡Šæ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»ŸåŸºäºŽè§„åˆ™çš„æ—¥è®°è´¦æµ‹è¯•åœ¨ç¨ŽåŠ¡ç›¸å…³è´¦æœ¬å¼‚å¸¸æ£€æµ‹ä¸­äº§ç”Ÿå¤§é‡è¯¯æŠ¥ï¼Œéš¾ä»¥å¤„ç†ç»†å¾®å¼‚å¸¸ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç ”ç©¶å¤§è¯­è¨€æ¨¡åž‹ä½œä¸ºå¼‚å¸¸æ£€æµ‹å™¨ï¼Œåœ¨åˆæˆå’ŒçœŸå®žåŒ¿åè´¦æœ¬ä¸ŠåŸºå‡†æµ‹è¯•LLaMAå’ŒGemmaç­‰æ¨¡åž‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå¤§è¯­è¨€æ¨¡åž‹åœ¨æ€§èƒ½ä¸Šä¼˜äºŽä¼ ç»Ÿè§„åˆ™æ–¹æ³•å’Œæœºå™¨å­¦ä¹ åŸºçº¿ï¼Œå¹¶æä¾›è‡ªç„¶è¯­è¨€è§£é‡Šå¢žå¼ºå¯è§£é‡Šæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Auditors rely on Journal Entry Tests (JETs) to detect anomalies in tax-related ledger records, but rule-based methods generate overwhelming false positives and struggle with subtle irregularities. We investigate whether large language models (LLMs) can serve as anomaly detectors in double-entry bookkeeping. Benchmarking SoTA LLMs such as LLaMA and Gemma on both synthetic and real-world anonymized ledgers, we compare them against JETs and machine learning baselines. Our results show that LLMs consistently outperform traditional rule-based JETs and classical ML baselines, while also providing natural-language explanations that enhance interpretability. These results highlight the potential of \textbf{AI-augmented auditing}, where human auditors collaborate with foundation models to strengthen financial integrity.

