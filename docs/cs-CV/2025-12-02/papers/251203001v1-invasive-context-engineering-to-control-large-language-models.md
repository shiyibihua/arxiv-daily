---
layout: default
title: Invasive Context Engineering to Control Large Language Models
---

# Invasive Context Engineering to Control Large Language Models

**arXiv**: [2512.03001v1](https://arxiv.org/abs/2512.03001) | [PDF](https://arxiv.org/pdf/2512.03001.pdf)

**ä½œè€…**: Thomas Rivasseau

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¾µå…¥å¼ä¸Šä¸‹æ–‡å·¥ç¨‹ä»¥å¢žå¼ºé•¿ä¸Šä¸‹æ–‡ä¸‹å¤§åž‹è¯­è¨€æ¨¡åž‹çš„å®‰å…¨æŽ§åˆ¶**

**å…³é”®è¯**: `ä¾µå…¥å¼ä¸Šä¸‹æ–‡å·¥ç¨‹` `å¤§åž‹è¯­è¨€æ¨¡åž‹å®‰å…¨` `é•¿ä¸Šä¸‹æ–‡æŽ§åˆ¶` `æ€ç»´é“¾å®‰å…¨` `æ¨¡åž‹é²æ£’æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé•¿ä¸Šä¸‹æ–‡ä¸‹LLMæ˜“å—æ»¥ç”¨å’Œè¶Šç‹±æ”»å‡»ï¼ŒçŽ°æœ‰æ–¹æ³•å¦‚åå¥½è®­ç»ƒå’Œè¿‡æ»¤ä¸è¶³ä»¥ä¿è¯å®‰å…¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å‘LLMä¸Šä¸‹æ–‡æ’å…¥æŽ§åˆ¶è¯­å¥ä½œä¸ºä¾µå…¥å¼å·¥ç¨‹ï¼Œæ— éœ€æ¨¡åž‹è®­ç»ƒï¼Œå¯æ³›åŒ–è‡³æ€ç»´é“¾è¿‡ç¨‹é˜²æ­¢ç­–ç•¥æ€§è¡Œä¸ºã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæœªçŸ¥å…·ä½“å®žéªŒç»†èŠ‚ï¼Œä½†å£°ç§°èƒ½éƒ¨åˆ†è§£å†³é•¿ä¸Šä¸‹æ–‡å®‰å…¨ä¿è¯é—®é¢˜ï¼Œé¿å…æ•°æ®çŸ­ç¼ºé™·é˜±ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Current research on operator control of Large Language Models improves model robustness against adversarial attacks and misbehavior by training on preference examples, prompting, and input/output filtering. Despite good results, LLMs remain susceptible to abuse, and jailbreak probability increases with context length. There is a need for robust LLM security guarantees in long-context situations. We propose control sentences inserted into the LLM context as invasive context engineering to partially solve the problem. We suggest this technique can be generalized to the Chain-of-Thought process to prevent scheming. Invasive Context Engineering does not rely on LLM training, avoiding data shortage pitfalls which arise in training models for long context situations.

