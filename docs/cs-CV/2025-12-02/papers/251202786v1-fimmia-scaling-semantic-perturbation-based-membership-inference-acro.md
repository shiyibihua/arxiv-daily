---
layout: default
title: FiMMIA: scaling semantic perturbation-based membership inference across modalities
---

# FiMMIA: scaling semantic perturbation-based membership inference across modalities

**arXiv**: [2512.02786v1](https://arxiv.org/abs/2512.02786) | [PDF](https://arxiv.org/pdf/2512.02786.pdf)

**ä½œè€…**: Anton Emelyanov, Sergei Kudriashov, Alena Fenogenova

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFiMMIAæ¡†æž¶ä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ä¸­çš„æˆå‘˜æŽ¨æ–­æ”»å‡»é—®é¢˜**

**å…³é”®è¯**: `æˆå‘˜æŽ¨æ–­æ”»å‡»` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `åˆ†å¸ƒåç§»` `æ‰°åŠ¨æ–¹æ³•` `æ¡†æž¶è®¾è®¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æˆå‘˜æŽ¨æ–­æ”»å‡»æ–¹æ³•åœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ä¸­æ€§èƒ½ä¸è¶³ï¼Œå› å¤šæ¨¡æ€ç»„ä»¶é€‚åº”ä¸ç¨³å®šå’Œåˆ†å¸ƒåç§»ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡è¯†åˆ«æ•°æ®é›†åˆ†å¸ƒåç§»ï¼Œå¹¶æ‰©å±•åŸºçº¿ç®¡é“ï¼Œå°†åŸºäºŽæ‰°åŠ¨çš„æˆå‘˜æŽ¨æ–­æ–¹æ³•æ³›åŒ–è‡³å¤šæ¨¡æ€æ¨¡åž‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šç§å¾®è°ƒå¤šæ¨¡æ€æ¨¡åž‹ä¸Šè¯„ä¼°ï¼ŒéªŒè¯äº†åŸºäºŽæ‰°åŠ¨çš„æ”»å‡»åœ¨å¤šæ¨¡æ€é¢†åŸŸçš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Membership Inference Attacks (MIAs) aim to determine whether a specific data point was included in the training set of a target model. Although there are have been numerous methods developed for detecting data contamination in large language models (LLMs), their performance on multimodal LLMs (MLLMs) falls short due to the instabilities introduced through multimodal component adaptation and possible distribution shifts across multiple inputs. In this work, we investigate multimodal membership inference and address two issues: first, by identifying distribution shifts in the existing datasets, and second, by releasing an extended baseline pipeline to detect them. We also generalize the perturbation-based membership inference methods to MLLMs and release \textbf{FiMMIA} -- a modular \textbf{F}ramework for \textbf{M}ultimodal \textbf{MIA}.\footnote{The source code and framework have been made publicly available under the MIT license via \href{https://github.com/ai-forever/data_leakage_detect}{link}.The video demonstration is available on \href{https://youtu.be/a9L4-H80aSg}{YouTube}.} Our approach trains a neural network to analyze the target model's behavior on perturbed inputs, capturing distributional differences between members and non-members. Comprehensive evaluations on various fine-tuned multimodal models demonstrate the effectiveness of our perturbation-based membership inference attacks in multimodal domains.

