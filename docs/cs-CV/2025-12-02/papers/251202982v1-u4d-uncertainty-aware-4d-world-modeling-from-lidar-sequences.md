---
layout: default
title: U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences
---

# U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences

**arXiv**: [2512.02982v1](https://arxiv.org/abs/2512.02982) | [PDF](https://arxiv.org/pdf/2512.02982.pdf)

**ä½œè€…**: Xiang Xu, Ao Liang, Youquan Liu, Linfeng Li, Lingdong Kong, Ziwei Liu, Qingshan Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºU4Dæ¡†æž¶ï¼Œé€šè¿‡ä¸ç¡®å®šæ€§æ„ŸçŸ¥å»ºæ¨¡è§£å†³LiDARåºåˆ—4Dä¸–ç•Œç”Ÿæˆä¸­çš„å‡ ä½•å¤±çœŸä¸Žæ—¶é—´ä¸ä¸€è‡´é—®é¢˜ã€‚**

**å…³é”®è¯**: `4Dä¸–ç•Œå»ºæ¨¡` `ä¸ç¡®å®šæ€§æ„ŸçŸ¥` `LiDARåºåˆ—ç”Ÿæˆ` `æ—¶ç©ºä¸€è‡´æ€§` `æ‰©æ•£æ¨¡åž‹` `è‡ªåŠ¨é©¾é©¶ä»¿çœŸ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•å‡åŒ€å¤„ç†ç©ºé—´åŒºåŸŸï¼Œå¿½ç•¥åœºæ™¯ä¸ç¡®å®šæ€§ï¼Œå¯¼è‡´å¤æ‚åŒºåŸŸç”Ÿæˆå¤±çœŸå’Œæ—¶é—´ç¨³å®šæ€§ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽé¢„è®­ç»ƒåˆ†å‰²æ¨¡åž‹ä¼°è®¡ç©ºé—´ä¸ç¡®å®šæ€§å›¾ï¼Œé‡‡ç”¨â€œéš¾åˆ°æ˜“â€ä¸¤é˜¶æ®µç”Ÿæˆï¼Œå¹¶å¼•å…¥æ—¶ç©ºæ··åˆå—å¢žå¼ºæ—¶é—´ä¸€è‡´æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒè¡¨æ˜ŽU4Dèƒ½ç”Ÿæˆå‡ ä½•ä¿çœŸä¸”æ—¶é—´ä¸€è‡´çš„LiDARåºåˆ—ï¼Œæå‡è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ä¸Žä»¿çœŸçš„å¯é æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Modeling dynamic 3D environments from LiDAR sequences is central to building reliable 4D worlds for autonomous driving and embodied AI. Existing generative frameworks, however, often treat all spatial regions uniformly, overlooking the varying uncertainty across real-world scenes. This uniform generation leads to artifacts in complex or ambiguous regions, limiting realism and temporal stability. In this work, we present U4D, an uncertainty-aware framework for 4D LiDAR world modeling. Our approach first estimates spatial uncertainty maps from a pretrained segmentation model to localize semantically challenging regions. It then performs generation in a "hard-to-easy" manner through two sequential stages: (1) uncertainty-region modeling, which reconstructs high-entropy regions with fine geometric fidelity, and (2) uncertainty-conditioned completion, which synthesizes the remaining areas under learned structural priors. To further ensure temporal coherence, U4D incorporates a mixture of spatio-temporal (MoST) block that adaptively fuses spatial and temporal representations during diffusion. Extensive experiments show that U4D produces geometrically faithful and temporally consistent LiDAR sequences, advancing the reliability of 4D world modeling for autonomous perception and simulation.

