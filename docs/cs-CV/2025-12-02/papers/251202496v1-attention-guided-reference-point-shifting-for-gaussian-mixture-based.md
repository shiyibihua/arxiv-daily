---
layout: default
title: Attention-guided reference point shifting for Gaussian-mixture-based partial point set registration
---

# Attention-guided reference point shifting for Gaussian-mixture-based partial point set registration

**arXiv**: [2512.02496v1](https://arxiv.org/abs/2512.02496) | [PDF](https://arxiv.org/pdf/2512.02496.pdf)

**ä½œè€…**: Mizuki Kikkawa, Tatsuya Yatagawa, Yutaka Ohtake, Hiromasa Suzuki

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ³¨æ„åŠ›å¼•å¯¼å‚è€ƒç‚¹åç§»å±‚ä»¥æå‡åŸºäºŽé«˜æ–¯æ··åˆæ¨¡åž‹çš„éƒ¨åˆ†ç‚¹äº‘é…å‡†æ€§èƒ½**

**å…³é”®è¯**: `ç‚¹äº‘é…å‡†` `é«˜æ–¯æ··åˆæ¨¡åž‹` `æ³¨æ„åŠ›æœºåˆ¶` `æ·±åº¦å­¦ä¹ ` `éƒ¨åˆ†ç‚¹äº‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åˆ†æžåŸºäºŽæ·±åº¦å­¦ä¹ å’ŒGMMçš„éƒ¨åˆ†ç‚¹äº‘é…å‡†æ–¹æ³•åœ¨å¹³ç§»æ—‹è½¬ä¸‹çš„ç‰¹å¾ä¸å˜æ€§é—®é¢˜
2. å¼•å…¥ARPSå±‚é€šè¿‡æ³¨æ„åŠ›æ¨¡å—ç¨³å¥è¯†åˆ«å…±åŒå‚è€ƒç‚¹ä»¥èŽ·å–å˜æ¢ä¸å˜ç‰¹å¾
3. å®žéªŒæ˜¾ç¤ºARPSæ˜¾è‘—å¢žå¼ºDeepGMRå’ŒUGMMRegï¼Œä¼˜äºŽçŽ°æœ‰åŸºäºŽæ³¨æ„åŠ›çš„æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This study investigates the impact of the invariance of feature vectors for partial-to-partial point set registration under translation and rotation of input point sets, particularly in the realm of techniques based on deep learning and Gaussian mixture models (GMMs). We reveal both theoretical and practical problems associated with such deep-learning-based registration methods using GMMs, with a particular focus on the limitations of DeepGMR, a pioneering study in this line, to the partial-to-partial point set registration. Our primary goal is to uncover the causes behind such methods and propose a comprehensible solution for that. To address this, we introduce an attention-based reference point shifting (ARPS) layer, which robustly identifies a common reference point of two partial point sets, thereby acquiring transformation-invariant features. The ARPS layer employs a well-studied attention module to find a common reference point rather than the overlap region. Owing to this, it significantly enhances the performance of DeepGMR and its recent variant, UGMMReg. Furthermore, these extension models outperform even prior deep learning methods using attention blocks and Transformer to extract the overlap region or common reference points. We believe these findings provide deeper insights into registration methods using deep learning and GMMs.

