---
layout: default
title: GraphFusion3D: Dynamic Graph Attention Convolution with Adaptive Cross-Modal Transformer for 3D Object Detection
---

# GraphFusion3D: Dynamic Graph Attention Convolution with Adaptive Cross-Modal Transformer for 3D Object Detection

**arXiv**: [2512.02991v1](https://arxiv.org/abs/2512.02991) | [PDF](https://arxiv.org/pdf/2512.02991.pdf)

**ä½œè€…**: Md Sohag Mia, Md Nahid Hasan, Tawhid Ahmed, Muhammad Abdullah Adnan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGraphFusion3Dæ¡†æž¶ï¼Œç»“åˆè‡ªé€‚åº”è·¨æ¨¡æ€Transformerå’ŒåŠ¨æ€å›¾æ³¨æ„åŠ›å·ç§¯ï¼Œä»¥è§£å†³3Dç‚¹äº‘ç›®æ ‡æ£€æµ‹ä¸­çš„ç¨€ç–æ€§å’Œä¸Šä¸‹æ–‡å…³ç³»é—®é¢˜ã€‚**

**å…³é”®è¯**: `3Dç›®æ ‡æ£€æµ‹` `å¤šæ¨¡æ€èžåˆ` `å›¾æ³¨æ„åŠ›ç½‘ç»œ` `è‡ªé€‚åº”Transformer` `ç‚¹äº‘å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç‚¹äº‘æ•°æ®ç¨€ç–ã€ç»“æž„ä¸å®Œæ•´ã€è¯­ä¹‰ä¿¡æ¯æœ‰é™ï¼Œä¸”éš¾ä»¥æ•èŽ·è¿œè·ç¦»å¯¹è±¡é—´çš„ä¸Šä¸‹æ–‡å…³ç³»ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥è‡ªé€‚åº”è·¨æ¨¡æ€Transformerèžåˆå›¾åƒç‰¹å¾ï¼Œå¢žå¼ºç‚¹äº‘å‡ ä½•å’Œè¯­ä¹‰ä¿¡æ¯ï¼›ä½¿ç”¨å›¾æŽ¨ç†æ¨¡å—é€šè¿‡å¤šå°ºåº¦å›¾æ³¨æ„åŠ›åŠ¨æ€å»ºæ¨¡é‚»åŸŸå…³ç³»ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨SUN RGB-Då’ŒScanNetV2æ•°æ®é›†ä¸Šå–å¾—æ˜¾è‘—æ€§èƒ½æå‡ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite significant progress in 3D object detection, point clouds remain challenging due to sparse data, incomplete structures, and limited semantic information. Capturing contextual relationships between distant objects presents additional difficulties. To address these challenges, we propose GraphFusion3D, a unified framework combining multi-modal fusion with advanced feature learning. Our approach introduces the Adaptive Cross-Modal Transformer (ACMT), which adaptively integrates image features into point representations to enrich both geometric and semantic information. For proposal refinement, we introduce the Graph Reasoning Module (GRM), a novel mechanism that models neighborhood relationships to simultaneously capture local geometric structures and global semantic context. The module employs multi-scale graph attention to dynamically weight both spatial proximity and feature similarity between proposals. We further employ a cascade decoder that progressively refines detections through multi-stage predictions. Extensive experiments on SUN RGB-D (70.6\% AP$_{25}$ and 51.2\% AP$_{50}$) and ScanNetV2 (75.1\% AP$_{25}$ and 60.8\% AP$_{50}$) demonstrate a substantial performance improvement over existing approaches.

