---
layout: default
title: CREST: Universal Safety Guardrails Through Cluster-Guided Cross-Lingual Transfer
---

# CREST: Universal Safety Guardrails Through Cluster-Guided Cross-Lingual Transfer

**arXiv**: [2512.02711v1](https://arxiv.org/abs/2512.02711) | [PDF](https://arxiv.org/pdf/2512.02711.pdf)

**ä½œè€…**: Lavish Bansal, Naman Mishra

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCRESTæ¨¡åž‹ï¼Œé€šè¿‡èšç±»å¼•å¯¼çš„è·¨è¯­è¨€è¿ç§»å®žçŽ°å¤šè¯­è¨€å®‰å…¨æŠ¤æ ï¼Œæ”¯æŒ100ç§è¯­è¨€ã€‚**

**å…³é”®è¯**: `å¤šè¯­è¨€å®‰å…¨åˆ†ç±»` `è·¨è¯­è¨€è¿ç§»` `å‚æ•°é«˜æ•ˆæ¨¡åž‹` `ä½Žèµ„æºè¯­è¨€` `å®‰å…¨æŠ¤æ ` `èšç±»å¼•å¯¼`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é—®é¢˜ï¼šçŽ°æœ‰å®‰å…¨æŠ¤æ ä¸»è¦é’ˆå¯¹é«˜èµ„æºè¯­è¨€ï¼Œä½Žèµ„æºè¯­è¨€å®‰å…¨é˜²æŠ¤ä¸è¶³ã€‚
2. æ–¹æ³•ï¼šåŸºäºŽ13ç§é«˜èµ„æºè¯­è¨€è®­ç»ƒï¼Œåˆ©ç”¨èšç±»å®žçŽ°è·¨è¯­è¨€è¿ç§»è‡³100ç§è¯­è¨€ï¼Œå‚æ•°é«˜æ•ˆã€‚
3. æ•ˆæžœï¼šåœ¨å…­ä¸ªå®‰å…¨åŸºå‡†ä¸Šè¶…è¶ŠåŒç±»è§„æ¨¡æ¨¡åž‹ï¼Œä¸Žæ›´å¤§å‚æ•°æ¨¡åž‹ç«žäº‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Ensuring content safety in large language models (LLMs) is essential for their deployment in real-world applications. However, existing safety guardrails are predominantly tailored for high-resource languages, leaving a significant portion of the world's population underrepresented who communicate in low-resource languages. To address this, we introduce CREST (CRoss-lingual Efficient Safety Transfer), a parameter-efficient multilingual safety classification model that supports 100 languages with only 0.5B parameters. By training on a strategically chosen subset of only 13 high-resource languages, our model utilizes cluster-based cross-lingual transfer from a few to 100 languages, enabling effective generalization to both unseen high-resource and low-resource languages. This approach addresses the challenge of limited training data in low-resource settings. We conduct comprehensive evaluations across six safety benchmarks to demonstrate that CREST outperforms existing state-of-the-art guardrails of comparable scale and achieves competitive results against models with significantly larger parameter counts (2.5B parameters and above). Our findings highlight the limitations of language-specific guardrails and underscore the importance of developing universal, language-agnostic safety systems that can scale effectively to serve global populations.

