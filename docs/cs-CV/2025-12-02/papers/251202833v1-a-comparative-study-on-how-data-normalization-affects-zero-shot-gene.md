---
layout: default
title: A Comparative Study on How Data Normalization Affects Zero-Shot Generalization in Time Series Foundation Models
---

# A Comparative Study on How Data Normalization Affects Zero-Shot Generalization in Time Series Foundation Models

**arXiv**: [2512.02833v1](https://arxiv.org/abs/2512.02833) | [PDF](https://arxiv.org/pdf/2512.02833.pdf)

**ä½œè€…**: Ihab Ahmed, Denis KrompaÃŸ, Cheng Feng, Volker Tresp

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¯”è¾ƒæ•°æ®å½’ä¸€åŒ–æ–¹æ³•å¯¹æ—¶é—´åºåˆ—åŸºç¡€æ¨¡åž‹é›¶æ ·æœ¬æ³›åŒ–çš„å½±å“ï¼Œç¡®ç«‹REVINä¸ºæœ€ä¼˜æ–¹æ³•**

**å…³é”®è¯**: `æ—¶é—´åºåˆ—åŸºç¡€æ¨¡åž‹` `æ•°æ®å½’ä¸€åŒ–` `é›¶æ ·æœ¬æ³›åŒ–` `REVINæ–¹æ³•` `è·¨åŸŸå°ºåº¦å˜åŒ–` `éžå¹³ç¨³æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç ”ç©¶æ—¶é—´åºåˆ—åŸºç¡€æ¨¡åž‹è¾“å…¥å½’ä¸€åŒ–æ–¹æ³•ï¼Œè§£å†³è·¨åŸŸå°ºåº¦å˜åŒ–å’Œéžå¹³ç¨³æ€§å¯¼è‡´çš„æ³›åŒ–é—®é¢˜
2. é€šè¿‡ç³»ç»Ÿè¯„ä¼°å››ç§æž¶æž„æ¨¡åž‹ï¼Œå®žè¯REVINåœ¨é›¶æ ·æœ¬MASEä¸Šç›¸å¯¹æœªå½’ä¸€åŒ–åŸºçº¿é™ä½Ž89%ï¼Œæ•ˆçŽ‡æœ€é«˜
3. å½’ä¸€åŒ–æ•ˆæžœå—æž¶æž„è®¾è®¡å’Œä¼˜åŒ–ç›®æ ‡å½±å“ï¼Œå¦‚è®­ç»ƒæŸå¤±å°ºåº¦æ•æ„Ÿæ€§å’Œæ¨¡åž‹ç±»åž‹

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We investigate input normalization methods for Time-Series Foundation Models (TSFMs). While normalization is well-studied in dataset-specific time-series models, it remains overlooked in TSFMs where generalization is critical. Time-series data, unlike text or images, exhibits significant scale variation across domains and channels, coupled with non-stationarity, can undermine TSFM performance regardless of architectural complexity. Through systematic evaluation across four architecturally diverse TSFMs, we empirically establish REVIN as the most efficient approach, reducing zero-shot MASE by 89\% relative to an un-normalized baseline and by 44\% versus other normalization methods, while matching the best in-domain accuracy (0.84 MASE) without any dataset-level preprocessing -- yielding the highest accuracy-efficiency trade-off. Yet its effect utilization depends on architectural design choices and optimization objective, particularly with respect to training loss scale sensitivity and model type (probabilistic, point-forecast, or LLM-based models).

