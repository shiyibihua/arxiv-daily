---
layout: default
title: Training Data Attribution for Image Generation using Ontology-Aligned Knowledge Graphs
---

# Training Data Attribution for Image Generation using Ontology-Aligned Knowledge Graphs

**arXiv**: [2512.02713v1](https://arxiv.org/abs/2512.02713) | [PDF](https://arxiv.org/pdf/2512.02713.pdf)

**ä½œè€…**: Theodoros Aivalis, Iraklis A. Klampanos, Antonis Troumpoukis, Joemon M. Jose

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæœ¬ä½“å¯¹é½çŸ¥è¯†å›¾è°±çš„è®­ç»ƒæ•°æ®å½’å› æ¡†æž¶ï¼Œä»¥å¢žå¼ºå›¾åƒç”Ÿæˆæ¨¡åž‹çš„é€æ˜Žåº¦å’Œå¯è§£é‡Šæ€§ã€‚**

**å…³é”®è¯**: `è®­ç»ƒæ•°æ®å½’å› ` `çŸ¥è¯†å›¾è°±æž„å»º` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `å›¾åƒç”Ÿæˆé€æ˜Žåº¦` `æœ¬ä½“å¯¹é½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç”Ÿæˆæ¨¡åž‹é€æ˜Žåº¦ä¸è¶³ï¼Œéš¾ä»¥è¿½è¸ªè®­ç»ƒæ•°æ®å¯¹è¾“å‡ºçš„è´¡çŒ®ï¼Œå¼•å‘ç‰ˆæƒå’Œé—®è´£æ‹…å¿§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ä»Žå›¾åƒæå–ç»“æž„åŒ–ä¸‰å…ƒç»„ï¼Œæž„å»ºæœ¬ä½“å¯¹é½çŸ¥è¯†å›¾è°±ï¼Œæ¯”è¾ƒç”Ÿæˆä¸Žè®­ç»ƒå›¾åƒçš„å›¾è°±ä»¥å½’å› å½±å“ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šé€šè¿‡å±€éƒ¨æ¨¡åž‹é—å¿˜å®žéªŒå’Œé£Žæ ¼ç‰¹å®šå®žéªŒéªŒè¯æ¡†æž¶ï¼Œæ”¯æŒç‰ˆæƒåˆ†æžå’ŒAIå¯è§£é‡Šæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> As generative models become powerful, concerns around transparency, accountability, and copyright violations have intensified. Understanding how specific training data contributes to a model's output is critical. We introduce a framework for interpreting generative outputs through the automatic construction of ontologyaligned knowledge graphs (KGs). While automatic KG construction from natural text has advanced, extracting structured and ontology-consistent representations from visual content remains challenging -- due to the richness and multi-object nature of images. Leveraging multimodal large language models (LLMs), our method extracts structured triples from images, aligned with a domain-specific ontology. By comparing the KGs of generated and training images, we can trace potential influences, enabling copyright analysis, dataset transparency, and interpretable AI. We validate our method through experiments on locally trained models via unlearning, and on large-scale models through a style-specific experiment. Our framework supports the development of AI systems that foster human collaboration, creativity and stimulate curiosity.

