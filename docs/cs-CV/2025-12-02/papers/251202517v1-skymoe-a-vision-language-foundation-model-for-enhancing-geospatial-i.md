---
layout: default
title: SkyMoE: A Vision-Language Foundation Model for Enhancing Geospatial Interpretation with Mixture of Experts
---

# SkyMoE: A Vision-Language Foundation Model for Enhancing Geospatial Interpretation with Mixture of Experts

**arXiv**: [2512.02517v1](https://arxiv.org/abs/2512.02517) | [PDF](https://arxiv.org/pdf/2512.02517.pdf)

**ä½œè€…**: Jiaqi Liu, Ronghao Fu, Lang Sun, Haoran Liu, Xiao Yang, Weipeng Zhang, Xu Na, Zhuoran Duan, Bo Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSkyMoEæ¨¡åž‹ï¼Œé€šè¿‡ä¸“å®¶æ··åˆæž¶æž„å¢žå¼ºé¥æ„Ÿå¤šä»»åŠ¡å¤šç²’åº¦è§†è§‰è¯­è¨€ç†è§£**

**å…³é”®è¯**: `é¥æ„Ÿè§†è§‰è¯­è¨€æ¨¡åž‹` `ä¸“å®¶æ··åˆæž¶æž„` `å¤šç²’åº¦ç†è§£` `è‡ªé€‚åº”è·¯ç”±` `ä¸Šä¸‹æ–‡è§£è€¦å¢žå¼º` `å¤šä»»åŠ¡åŸºå‡†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é—®é¢˜ï¼šé€šç”¨è§†è§‰è¯­è¨€æ¨¡åž‹åœ¨é¥æ„Ÿä»»åŠ¡ä¸­è¡¨çŽ°ä¸ä½³ï¼Œéš¾ä»¥å¹³è¡¡å±€éƒ¨ç»†èŠ‚ä¸Žå…¨å±€ä¸Šä¸‹æ–‡ç†è§£
2. æ–¹æ³•ï¼šé‡‡ç”¨è‡ªé€‚åº”è·¯ç”±å™¨å’Œä¸Šä¸‹æ–‡è§£è€¦å¢žå¼ºç­–ç•¥ï¼Œå®žçŽ°ä»»åŠ¡å’Œç²’åº¦æ„ŸçŸ¥çš„ä¸“å®¶åˆ†é…
3. æ•ˆæžœï¼šåœ¨21ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šè¾¾åˆ°å…ˆè¿›æ€§èƒ½ï¼ŒéªŒè¯äº†æ¨¡åž‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The emergence of large vision-language models (VLMs) has significantly enhanced the efficiency and flexibility of geospatial interpretation. However, general-purpose VLMs remain suboptimal for remote sensing (RS) tasks. Existing geospatial VLMs typically adopt a unified modeling strategy and struggle to differentiate between task types and interpretation granularities, limiting their ability to balance local detail perception and global contextual understanding. In this paper, we present SkyMoE, a Mixture-of-Experts (MoE) vision-language model tailored for multimodal, multi-task RS interpretation. SkyMoE employs an adaptive router that generates task- and granularity-aware routing instructions, enabling specialized large language model experts to handle diverse sub-tasks. To further promote expert decoupling and granularity sensitivity, we introduce a context-disentangled augmentation strategy that creates contrastive pairs between local and global features, guiding experts toward level-specific representation learning. We also construct MGRS-Bench, a comprehensive benchmark covering multiple RS interpretation tasks and granularity levels, to evaluate generalization in complex scenarios. Extensive experiments on 21 public datasets demonstrate that SkyMoE achieves state-of-the-art performance across tasks, validating its adaptability, scalability, and superior multi-granularity understanding in remote sensing.

