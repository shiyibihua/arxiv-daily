---
layout: default
title: From Navigation to Refinement: Revealing the Two-Stage Nature of Flow-based Diffusion Models through Oracle Velocity
---

# From Navigation to Refinement: Revealing the Two-Stage Nature of Flow-based Diffusion Models through Oracle Velocity

**arXiv**: [2512.02826v1](https://arxiv.org/abs/2512.02826) | [PDF](https://arxiv.org/pdf/2512.02826.pdf)

**ä½œè€…**: Haoming Liu, Jinnuo Liu, Yanhao Li, Liuyang Bai, Yunkai Ji, Yuanhe Guo, Shenji Wan, Hongyi Wen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡Oracle Velocityæ­ç¤ºåŸºäºŽæµçš„æ‰©æ•£æ¨¡åž‹çš„ä¸¤é˜¶æ®µè®­ç»ƒæœ¬è´¨ï¼Œè§£é‡Šå…¶è®°å¿†-æ³›åŒ–è¡Œä¸ºã€‚**

**å…³é”®è¯**: `æµåŒ¹é…` `æ‰©æ•£æ¨¡åž‹` `è®­ç»ƒåŠ¨æ€` `è®°å¿†æ³›åŒ–` `é€Ÿåº¦åœºåˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŸºäºŽæµçš„æ‰©æ•£æ¨¡åž‹çš„è®°å¿†-æ³›åŒ–è¡Œä¸ºæœºåˆ¶ä¸æ˜Žç¡®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ†æžæµåŒ¹é…ç›®æ ‡çš„è¾¹é™…é€Ÿåº¦åœºï¼Œå‘çŽ°å…¶é—­å¼è¡¨è¾¾å¼æ­ç¤ºä¸¤é˜¶æ®µè®­ç»ƒç›®æ ‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè§£é‡Šæ—¶é—´æ­¥åç§»è°ƒåº¦ã€æ— åˆ†ç±»å™¨å¼•å¯¼é—´éš”ç­‰å®žè·µæŠ€å·§çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Flow-based diffusion models have emerged as a leading paradigm for training generative models across images and videos. However, their memorization-generalization behavior remains poorly understood. In this work, we revisit the flow matching (FM) objective and study its marginal velocity field, which admits a closed-form expression, allowing exact computation of the oracle FM target. Analyzing this oracle velocity field reveals that flow-based diffusion models inherently formulate a two-stage training target: an early stage guided by a mixture of data modes, and a later stage dominated by the nearest data sample. The two-stage objective leads to distinct learning behaviors: the early navigation stage generalizes across data modes to form global layouts, whereas the later refinement stage increasingly memorizes fine-grained details. Leveraging these insights, we explain the effectiveness of practical techniques such as timestep-shifted schedules, classifier-free guidance intervals, and latent space design choices. Our study deepens the understanding of diffusion model training dynamics and offers principles for guiding future architectural and algorithmic improvements.

