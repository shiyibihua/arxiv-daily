---
layout: default
title: Distill, Forget, Repeat: A Framework for Continual Unlearning in Text-to-Image Diffusion Models
---

# Distill, Forget, Repeat: A Framework for Continual Unlearning in Text-to-Image Diffusion Models

**arXiv**: [2512.02657v1](https://arxiv.org/abs/2512.02657) | [PDF](https://arxiv.org/pdf/2512.02657.pdf)

**ä½œè€…**: Naveen George, Naoki Murata, Yuhta Takida, Konda Reddy Mopuri, Yuki Mitsufuji

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽç”Ÿæˆè’¸é¦çš„æŒç»­é—å¿˜æ¡†æž¶ï¼Œä»¥è§£å†³æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡åž‹ä¸­çš„åºåˆ—åˆ é™¤è¯·æ±‚é—®é¢˜ã€‚**

**å…³é”®è¯**: `æŒç»­é—å¿˜` `æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡åž‹` `æœºå™¨é—å¿˜` `ç”Ÿæˆè’¸é¦` `å¤šç›®æ ‡ä¼˜åŒ–` `æ¨¡åž‹ç¨³å®šæ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æœºå™¨é—å¿˜æ–¹æ³•æ— æ³•å¤„ç†åºåˆ—åˆ é™¤è¯·æ±‚ï¼Œå¯¼è‡´æ¨¡åž‹ç¨³å®šæ€§å’Œç”Ÿæˆè´¨é‡ä¸‹é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†æ¯ä¸ªé—å¿˜æ­¥éª¤é‡æž„ä¸ºå¤šç›®æ ‡å¸ˆç”Ÿè’¸é¦è¿‡ç¨‹ï¼Œç»“åˆæŒç»­å­¦ä¹ åŽŸåˆ™ä¿æŒæ¨¡åž‹å®Œæ•´æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨10æ­¥åºåˆ—åŸºå‡†æµ‹è¯•ä¸­ï¼Œæœ‰æ•ˆé—å¿˜ç›®æ ‡æ¦‚å¿µï¼ŒåŒæ—¶ä¿æŒä¿ç•™æ¦‚å¿µæ€§èƒ½å’Œæ•´ä½“å›¾åƒè´¨é‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The recent rapid growth of visual generative models trained on vast web-scale datasets has created significant tension with data privacy regulations and copyright laws, such as GDPR's ``Right to be Forgotten.'' This necessitates machine unlearning (MU) to remove specific concepts without the prohibitive cost of retraining. However, existing MU techniques are fundamentally ill-equipped for real-world scenarios where deletion requests arrive sequentially, a setting known as continual unlearning (CUL). Naively applying one-shot methods in a continual setting triggers a stability crisis, leading to a cascade of degradation characterized by retention collapse, compounding collateral damage to related concepts, and a sharp decline in generative quality. To address this critical challenge, we introduce a novel generative distillation based continual unlearning framework that ensures targeted and stable unlearning under sequences of deletion requests. By reframing each unlearning step as a multi-objective, teacher-student distillation process, the framework leverages principles from continual learning to maintain model integrity. Experiments on a 10-step sequential benchmark demonstrate that our method unlearns forget concepts with better fidelity and achieves this without significant interference to the performance on retain concepts or the overall image quality, substantially outperforming baselines. This framework provides a viable pathway for the responsible deployment and maintenance of large-scale generative models, enabling industries to comply with ongoing data removal requests in a practical and effective manner.

