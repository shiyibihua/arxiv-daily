---
layout: default
title: Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages
---

# Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages

**arXiv**: [2512.02841v1](https://arxiv.org/abs/2512.02841) | [PDF](https://arxiv.org/pdf/2512.02841.pdf)

**ä½œè€…**: Lechen Zhang, Yusheng Zhou, Tolga Ergen, Lajanugen Logeswaran, Moontae Lee, David Jurgens

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè·¨è¯­è¨€æç¤ºä¼˜åŒ–æ¡†æž¶ä»¥æå‡å¤šè¯­è¨€LLMçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§**

**å…³é”®è¯**: `è·¨è¯­è¨€æç¤ºå¼•å¯¼` `å¤šè¯­è¨€LLMè¯„ä¼°` `æç¤ºä¼˜åŒ–æ¡†æž¶` `ç³»ç»Ÿæç¤º` `æŽ¨ç†æ¨¡å¼åˆ†æž` `è¯­è¨€åˆ‡æ¢å‡å°‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç ”ç©¶ç³»ç»Ÿæç¤ºåœ¨å¤šè¯­è¨€çŽ¯å¢ƒä¸­å¦‚ä½•å¼•å¯¼LLMè¡Œä¸ºï¼Œèšç„¦è·¨è¯­è¨€å¯é æ€§çš„æ ¸å¿ƒé—®é¢˜
2. å¼€å‘ç»Ÿä¸€å››ç»´è¯„ä¼°æ¡†æž¶å’Œæç¤ºä¼˜åŒ–æ–¹æ³•ï¼Œè‡ªåŠ¨å‘çŽ°æå‡æ€§èƒ½çš„æç¤º
3. é€šè¿‡å¤§è§„æ¨¡å®žéªŒéªŒè¯ä¼˜åŒ–æç¤ºèƒ½æ”¹å–„æŒ‡æ ‡5-10%ï¼Œå¹¶åˆ†æžæŽ¨ç†æ¨¡å¼å˜åŒ–

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> System prompts provide a lightweight yet powerful mechanism for conditioning large language models (LLMs) at inference time. While prior work has focused on English-only settings, real-world deployments benefit from having a single prompt to operate reliably across languages. This paper presents a comprehensive study of how different system prompts steer models toward accurate and robust cross-lingual behavior. We propose a unified four-dimensional evaluation framework to assess system prompts in multilingual environments. Through large-scale experiments on five languages, three LLMs, and three benchmarks, we uncover that certain prompt components, such as CoT, emotion, and scenario, correlate with robust multilingual behavior. We develop a prompt optimization framework for multilingual settings and show it can automatically discover prompts that improve all metrics by 5-10%. Finally, we analyze over 10 million reasoning units and find that more performant system prompts induce more structured and consistent reasoning patterns, while reducing unnecessary language-switching. Together, we highlight system prompt optimization as a scalable path to accurate and robust multilingual LLM behavior.

