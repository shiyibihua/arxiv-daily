---
layout: default
title: LumiX: Structured and Coherent Text-to-Intrinsic Generation
---

# LumiX: Structured and Coherent Text-to-Intrinsic Generation

**arXiv**: [2512.02781v1](https://arxiv.org/abs/2512.02781) | [PDF](https://arxiv.org/pdf/2512.02781.pdf)

**ä½œè€…**: Xu Han, Biao Zhang, Xiangjun Tang, Xianzhi Li, Peter Wonka

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLumiXç»“æž„åŒ–æ‰©æ•£æ¡†æž¶ï¼Œç”¨äºŽæ–‡æœ¬åˆ°å†…åœ¨å±žæ€§çš„è¿žè´¯ç”Ÿæˆï¼Œç¡®ä¿ç‰©ç†ä¸€è‡´æ€§ã€‚**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å†…åœ¨å±žæ€§ç”Ÿæˆ` `ç»“æž„åŒ–æ‰©æ•£æ¡†æž¶` `æŸ¥è¯¢å¹¿æ’­æ³¨æ„åŠ›` `å¼ é‡LoRA` `ç‰©ç†ä¸€è‡´æ€§` `è”åˆè®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ–‡æœ¬åˆ°å†…åœ¨å±žæ€§ç”Ÿæˆä¸­ç¼ºä¹ç»“æž„ä¸€è‡´æ€§å’Œç‰©ç†åˆç†æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æŸ¥è¯¢å¹¿æ’­æ³¨æ„åŠ›å’Œå¼ é‡LoRAï¼Œå®žçŽ°è·¨åœ°å›¾å…³ç³»å»ºæ¨¡å’Œç¨³å®šè”åˆè®­ç»ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å†…åœ¨å±žæ€§ç”Ÿæˆä¸Šï¼Œæ¯”çŽ°æœ‰æ–¹æ³•å¯¹é½åº¦æé«˜23%ï¼Œåå¥½å¾—åˆ†æ›´ä¼˜ï¼Œå¹¶æ”¯æŒå›¾åƒæ¡ä»¶åˆ†è§£ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present LumiX, a structured diffusion framework for coherent text-to-intrinsic generation. Conditioned on text prompts, LumiX jointly generates a comprehensive set of intrinsic maps (e.g., albedo, irradiance, normal, depth, and final color), providing a structured and physically consistent description of an underlying scene. This is enabled by two key contributions: 1) Query-Broadcast Attention, a mechanism that ensures structural consistency by sharing queries across all maps in each self-attention block. 2) Tensor LoRA, a tensor-based adaptation that parameter-efficiently models cross-map relations for efficient joint training. Together, these designs enable stable joint diffusion training and unified generation of multiple intrinsic properties. Experiments show that LumiX produces coherent and physically meaningful results, achieving 23% higher alignment and a better preference score (0.19 vs. -0.41) compared to the state of the art, and it can also perform image-conditioned intrinsic decomposition within the same framework.

