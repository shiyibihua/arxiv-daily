---
layout: default
title: SpecPV: Improving Self-Speculative Decoding for Long-Context Generation via Partial Verification
---

# SpecPV: Improving Self-Speculative Decoding for Long-Context Generation via Partial Verification

**arXiv**: [2512.02337v1](https://arxiv.org/abs/2512.02337) | [PDF](https://arxiv.org/pdf/2512.02337.pdf)

**ä½œè€…**: Zhendong Tan, Xingjun Zhang, Chaoyi Hu, Junjie Peng, Kun Xia

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSpecPVè‡ªæŽ¨æµ‹è§£ç æ–¹æ³•ï¼Œé€šè¿‡éƒ¨åˆ†éªŒè¯åŠ é€Ÿé•¿ä¸Šä¸‹æ–‡ç”Ÿæˆä¸­çš„æŽ¨æµ‹è§£ç ã€‚**

**å…³é”®è¯**: `é•¿ä¸Šä¸‹æ–‡ç”Ÿæˆ` `æŽ¨æµ‹è§£ç ` `è‡ªæŽ¨æµ‹è§£ç ` `éƒ¨åˆ†éªŒè¯` `é”®å€¼çŠ¶æ€` `è§£ç åŠ é€Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é•¿ä¸Šä¸‹æ–‡ç”Ÿæˆä¸­æŽ¨æµ‹è§£ç çš„éªŒè¯æ­¥éª¤æˆä¸ºä¸»è¦ç“¶é¢ˆã€‚
2. é‡‡ç”¨éƒ¨åˆ†é”®å€¼çŠ¶æ€è¿›è¡Œå¿«é€ŸéªŒè¯ï¼Œå¹¶å®šæœŸå…¨éªŒè¯ä»¥çº æ­£ç´¯ç§¯é”™è¯¯ã€‚
3. åœ¨LLaMA-3.1-8B-Instructç­‰æ¨¡åž‹ä¸Šå®žçŽ°æœ€é«˜6å€è§£ç åŠ é€Ÿï¼Œæ€§èƒ½ç•¥æœ‰ä¸‹é™ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Growing demands from tasks like code generation, deep reasoning, and long-document understanding have made long-context generation a crucial capability for large language models (LLMs). Speculative decoding is one of the most direct and effective approaches for accelerating generation. It follows a draft-verify paradigm, where a lightweight draft model proposes several candidate tokens and the target model verifies them. However, we find that as the context length grows, verification becomes the dominant bottleneck. To further accelerate speculative decoding in long-context generation, we introduce SpecPV, a self-speculative decoding approach that performs fast verification using partial key-value states (KV) and periodically applies full verification to eliminate accumulated errors. We validate SpecPV across multiple long-context benchmarks and models, including LLaMA-3.1-8B-Instruct and Qwen3-series. Experimental results show that SpecPV achieves up to 6x decoding speedup over standard autoregressive decoding with minor degradation.

