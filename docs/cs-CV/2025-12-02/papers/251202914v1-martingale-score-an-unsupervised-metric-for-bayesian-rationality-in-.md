---
layout: default
title: Martingale Score: An Unsupervised Metric for Bayesian Rationality in LLM Reasoning
---

# Martingale Score: An Unsupervised Metric for Bayesian Rationality in LLM Reasoning

**arXiv**: [2512.02914v1](https://arxiv.org/abs/2512.02914) | [PDF](https://arxiv.org/pdf/2512.02914.pdf)

**ä½œè€…**: Zhonghao He, Tianyi Qiu, Hirokazu Shirado, Maarten Sap

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ— ç›‘ç£çš„éž…åˆ†æ•°ä»¥è¯„ä¼°å¤§è¯­è¨€æ¨¡åž‹æŽ¨ç†ä¸­çš„è´å¶æ–¯ç†æ€§åå·®**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹æŽ¨ç†` `ä¿¡å¿µå›ºåŒ–` `è´å¶æ–¯ç†æ€§` `æ— ç›‘ç£è¯„ä¼°` `éž…æ€§è´¨` `å›žå½’åˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè¿­ä»£æŽ¨ç†å¯èƒ½å¯¼è‡´ä¿¡å¿µå›ºåŒ–è€ŒéžçœŸç›¸å¯»æ±‚ï¼Œéœ€ç³»ç»Ÿè¯„ä¼°ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽéž…æ€§è´¨ï¼Œé€šè¿‡å›žå½’æ–¹æ³•è®¡ç®—æ— ç›‘ç£çš„éž…åˆ†æ•°æ¥è¡¡é‡åå·®ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªå¼€æ”¾åŸŸä¸­å‘çŽ°åå·®æ™®éï¼Œéž…åˆ†æ•°å¯é¢„æµ‹çœŸå®žå‡†ç¡®æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in reasoning techniques have substantially improved the performance of large language models (LLMs), raising expectations for their ability to provide accurate, truthful, and reliable information. However, emerging evidence suggests that iterative reasoning may foster belief entrenchment and confirmation bias, rather than enhancing truth-seeking behavior. In this study, we propose a systematic evaluation framework for belief entrenchment in LLM reasoning by leveraging the Martingale property from Bayesian statistics. This property implies that, under rational belief updating, the expected value of future beliefs should remain equal to the current belief, i.e., belief updates are unpredictable from the current belief. We propose the unsupervised, regression-based Martingale Score to measure violations of this property, which signal deviation from the Bayesian ability of updating on new evidence. In open-ended problem domains including event forecasting, value-laden questions, and academic paper review, we find such violations to be widespread across models and setups, where the current belief positively predicts future belief updates, a phenomenon which we term belief entrenchment. We identify the models, reasoning techniques, and domains more prone to belief entrenchment. Finally, we validate the Martingale Score by showing that it predicts ground-truth accuracy on problem domains where ground truth labels are available. This indicates that, while designed as an unsupervised metric that operates even in domains without access to ground truth, the Martingale Score is a useful proxy of the truth-seeking ability of a reasoning process.

