---
layout: default
title: Enhancing Automated Paper Reproduction via Prompt-Free Collaborative Agents
---

# Enhancing Automated Paper Reproduction via Prompt-Free Collaborative Agents

**arXiv**: [2512.02812v1](https://arxiv.org/abs/2512.02812) | [PDF](https://arxiv.org/pdf/2512.02812.pdf)

**ä½œè€…**: Zijie Lin, Qilin Cai, Liang Shen, Mingjun Xiao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ— æç¤ºåä½œä»£ç†æ¡†æž¶ä»¥å¢žå¼ºè‡ªåŠ¨åŒ–è®ºæ–‡å¤çŽ°çš„ä»£ç ç”Ÿæˆè´¨é‡**

**å…³é”®è¯**: `è‡ªåŠ¨åŒ–è®ºæ–‡å¤çŽ°` `åä½œä»£ç†` `ä»£ç ç”Ÿæˆ` `æ— æç¤ºç²¾ç‚¼` `éªŒè¯æœºåˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è‡ªåŠ¨åŒ–è®ºæ–‡å¤çŽ°æ¡†æž¶ç¼ºä¹æ­¥éª¤è¾“å‡ºéªŒè¯ä¸Žç²¾ç‚¼æœºåˆ¶ï¼Œä¾èµ–äººå·¥æç¤ºé™åˆ¶é€‚åº”æ€§
2. é‡‡ç”¨éªŒè¯ä»£ç†å’Œç²¾ç‚¼ä»£ç†åä½œï¼ŒåŸºäºŽåŽŸå§‹ç³»ç»Ÿæç¤ºè‡ªåŠ¨æ£€æŸ¥å¹¶æ”¹è¿›ç”Ÿæˆä»£ç 
3. åœ¨PaperBench Code-Devå’ŒPaper2CodeBenchæ•°æ®é›†ä¸Šå®žéªŒï¼Œä»£ç å‡†ç¡®æ€§å’Œå®Œæ•´æ€§æå‡çº¦15%å’Œ13%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Automated paper reproduction has emerged as a promising approach to accelerate scientific research, employing multi-step workflow frameworks to systematically convert academic papers into executable code. However, existing frameworks often lack mechanisms to verify and refine the outputs at each generation step, or rely heavily on manually designed prompts for self-refinement, which limits their adaptability and scalability. To address these limitations, we propose a prompt-free collaborative agent framework that automatically enhances the quality of paper-to-code generation. Our approach employs two collaborative agents: a verification agent that examines whether the outputs at each step satisfy the requirements specified in the corresponding system prompt, and a refinement agent that revises the outputs based on the identified issues. Unlike previous methods that require human experts to craft specific refinement prompts for each step, our framework achieves automatic verification and improvement by leveraging only the original system prompts. We integrate our collaborative agents into the Paper2Code framework and conduct comprehensive experiments on PaperBench Code-Dev and Paper2CodeBench datasets. Experimental results demonstrate that our approach significantly improves the accuracy and completeness of reproduced code, achieving performance gains of approximately 15\% and 13\%, respectively, compared to the baseline without our agents. Furthermore, comparative experiments against Self-Refine validate the robustness and consistency of our prompt-free approach across different datasets.

