---
layout: default
title: Action Anticipation at a Glimpse: To What Extent Can Multimodal Cues Replace Video?
---

# Action Anticipation at a Glimpse: To What Extent Can Multimodal Cues Replace Video?

**arXiv**: [2512.02846v1](https://arxiv.org/abs/2512.02846) | [PDF](https://arxiv.org/pdf/2512.02846.pdf)

**ä½œè€…**: Manuel Benavent-Lledo, Konstantinos Bacharidis, Victoria Manousaki, Konstantinos Papoutsakis, Antonis Argyros, Jose Garcia-Rodriguez

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAAGæ–¹æ³•ï¼Œé€šè¿‡å•å¸§å¤šæ¨¡æ€çº¿ç´¢æ›¿ä»£è§†é¢‘èšåˆï¼Œå®žçŽ°åŠ¨ä½œé¢„æµ‹ã€‚**

**å…³é”®è¯**: `åŠ¨ä½œé¢„æµ‹` `å•å¸§ç†è§£` `å¤šæ¨¡æ€èžåˆ` `ç©ºé—´æŽ¨ç†` `æ•™å­¦æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç ”ç©¶æ ¸å¿ƒé—®é¢˜ï¼šåŠ¨ä½œé¢„æµ‹èƒ½å¦ä»…ä¾èµ–å•å¸§å¤šæ¨¡æ€çº¿ç´¢ï¼Œè€Œéžä¼ ç»Ÿè§†é¢‘æ—¶åºä¿¡æ¯ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šAAGç»“åˆRGBç‰¹å¾ã€æ·±åº¦çº¿ç´¢å’Œå…ˆéªŒåŠ¨ä½œä¿¡æ¯ï¼Œå¢žå¼ºç©ºé—´æŽ¨ç†ä¸Žé•¿æœŸä¸Šä¸‹æ–‡ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨ä¸‰ä¸ªæ•™å­¦æ•°æ®é›†ä¸Šï¼ŒAAGä¸Žè§†é¢‘åŸºçº¿åŠå…ˆè¿›æ–¹æ³•ç«žäº‰æ€§ç›¸å½“ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Anticipating actions before they occur is a core challenge in action understanding research. While conventional methods rely on extracting and aggregating temporal information from videos, as humans we can often predict upcoming actions by observing a single moment from a scene, when given sufficient context. Can a model achieve this competence? The short answer is yes, although its effectiveness depends on the complexity of the task. In this work, we investigate to what extent video aggregation can be replaced with alternative modalities. To this end, based on recent advances in visual feature extraction and language-based reasoning, we introduce AAG, a method for Action Anticipation at a Glimpse. AAG combines RGB features with depth cues from a single frame for enhanced spatial reasoning, and incorporates prior action information to provide long-term context. This context is obtained either through textual summaries from Vision-Language Models, or from predictions generated by a single-frame action recognizer. Our results demonstrate that multimodal single-frame action anticipation using AAG can perform competitively compared to both temporally aggregated video baselines and state-of-the-art methods across three instructional activity datasets: IKEA-ASM, Meccano, and Assembly101.

