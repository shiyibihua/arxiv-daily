---
layout: default
title: In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs
---

# In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs

**arXiv**: [2512.02543v1](https://arxiv.org/abs/2512.02543) | [PDF](https://arxiv.org/pdf/2512.02543.pdf)

**ä½œè€…**: Vishnu Sarukkai, Asanshay Gupta, James Hong, MichaÃ«l Gharbi, Kayvon Fatahalian

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸Šä¸‹æ–‡è’¸é¦ä¸Žè‡ªä¸€è‡´æ€§çº§è”æ–¹æ³•ï¼Œä»¥é™ä½ŽLLMæ™ºèƒ½ä½“æŽ¨ç†æˆæœ¬ï¼Œæ— éœ€è®­ç»ƒæˆ–æ‰‹åŠ¨æç¤ºå·¥ç¨‹ã€‚**

**å…³é”®è¯**: `LLMæ™ºèƒ½ä½“` `ä¸Šä¸‹æ–‡è’¸é¦` `è‡ªä¸€è‡´æ€§çº§è”` `æŽ¨ç†æˆæœ¬ä¼˜åŒ–` `æ— è®­ç»ƒæ–¹æ³•` `æ™ºèƒ½ä½“åŸºå‡†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šLLMæ™ºèƒ½ä½“å¤§è§„æ¨¡æŽ¨ç†æˆæœ¬é«˜ï¼Œä¼ ç»Ÿæ–¹æ³•å¦‚å¾®è°ƒæˆ–æç¤ºå·¥ç¨‹å¼€å‘æ‘©æ“¦å¤§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥ä¸Šä¸‹æ–‡è’¸é¦ï¼Œé€šè¿‡æ£€ç´¢æ•™å¸ˆæ¼”ç¤ºä½œä¸ºä¸Šä¸‹æ–‡ç¤ºä¾‹ï¼Œä½¿ä½Žæˆæœ¬å­¦ç”Ÿæ¨¡åž‹åŠ¨æ€æ¨¡ä»¿æ•™å¸ˆè¡Œä¸ºï¼›ç»“åˆè‡ªä¸€è‡´æ€§çº§è”è‡ªé€‚åº”ä¿¡ä»»å­¦ç”Ÿã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ALFWorldåŸºå‡†ä¸Šä»¥2.5å€ä½Žæˆæœ¬åŒ¹é…æ•™å¸ˆå‡†ç¡®çŽ‡ï¼ŒAppWorldä¸Šå®žçŽ°2å€æˆæœ¬é™ä½Žï¼Œä¿æŒå‡†ç¡®çŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The world currently has an abundance of ideas for how to use new LLM agents, and developers seek to rapidly prototype and test new agentic designs. However, executing agents at scale using high-capacity LLMs incurs high inference costs. We propose a simple method for reducing LLM agent inference costs without incurring the development friction costs associated with LLM fine-tuning (long training cycles, optimization hyperparameter tweaking loops) or manual prompt engineering (laborious trial and error). Most importantly, we introduce $\textit{in-context distillation}$, which adapts the idea of knowledge distillation (training a low cost-student model to mimic a high-cost teacher) to an in-context learning setting. Our approach retrieves relevant teacher demonstrations at each agent step and provides them to the student as in-context examples, enabling the student to imitate teacher behavior on-the-fly. We combine in-context distillation with the established idea of $\textit{self-consistency cascades}$ to know when the trust the student. This adaptive strategy realizes the cost benefits of model specialization while preserving the productivity of working with frozen models. On the multi-step embodied reasoning benchmark ALFWorld, our method matches teacher-level accuracy at $\textbf{2.5$\times$ lower cost}$, reducing per-episode costs from \$0.059 to \$0.024. The upfront demonstration cost amortizes after just 843 episodes, yielding cumulative savings exceeding \$34,900 at deployment scale (1M episodes). On AppWorld, a complex agent benchmark requiring multi-step API workflows, we shift the Pareto frontier by achieving a $\textbf{2$\times$ cost reduction}$ at iso-accuracy. By reducing operational costs while maintaining rapid experimentation cycles with frozen models, our approach makes advanced agentic systems economically viable for a broader range of applications.

