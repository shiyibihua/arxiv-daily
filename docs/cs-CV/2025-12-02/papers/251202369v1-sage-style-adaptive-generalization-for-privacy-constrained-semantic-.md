---
layout: default
title: SAGE: Style-Adaptive Generalization for Privacy-Constrained Semantic Segmentation Across Domains
---

# SAGE: Style-Adaptive Generalization for Privacy-Constrained Semantic Segmentation Across Domains

**arXiv**: [2512.02369v1](https://arxiv.org/abs/2512.02369) | [PDF](https://arxiv.org/pdf/2512.02369.pdf)

**ä½œè€…**: Qingmei Li, Yang Zhang, Peifeng Zhang, Haohuan Fu, Juepeng Zheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSAGEæ¡†æž¶ä»¥è§£å†³éšç§çº¦æŸä¸‹å†»ç»“æ¨¡åž‹çš„è¯­ä¹‰åˆ†å‰²è·¨åŸŸæ³›åŒ–é—®é¢˜**

**å…³é”®è¯**: `è¯­ä¹‰åˆ†å‰²` `åŸŸæ³›åŒ–` `éšç§çº¦æŸ` `é£Žæ ¼è‡ªé€‚åº”` `è§†è§‰æç¤º` `å†»ç»“æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šéšç§çº¦æŸä¸‹æ— æ³•è®¿é—®æ¨¡åž‹å‚æ•°ï¼Œä¼ ç»Ÿå¾®è°ƒå—é™ï¼Œéœ€è¾“å…¥çº§ç­–ç•¥æå‡æ³›åŒ–èƒ½åŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡é£Žæ ¼è½¬ç§»æž„å»ºæºåŸŸå¤šæ ·é£Žæ ¼è¡¨ç¤ºï¼Œè‡ªé€‚åº”èžåˆé£Žæ ¼çº¿ç´¢ç”ŸæˆåŠ¨æ€æç¤ºï¼Œéšå¼å¯¹é½ç‰¹å¾åˆ†å¸ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šï¼ŒSAGEåœ¨éšç§çº¦æŸä¸‹è¾¾åˆ°æˆ–è¶…è¶Šå…ˆè¿›æ–¹æ³•ï¼Œä¼˜äºŽå…¨å¾®è°ƒåŸºçº¿ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Domain generalization for semantic segmentation aims to mitigate the degradation in model performance caused by domain shifts. However, in many real-world scenarios, we are unable to access the model parameters and architectural details due to privacy concerns and security constraints. Traditional fine-tuning or adaptation is hindered, leading to the demand for input-level strategies that can enhance generalization without modifying model weights. To this end, we propose a \textbf{S}tyle-\textbf{A}daptive \textbf{GE}neralization framework (\textbf{SAGE}), which improves the generalization of frozen models under privacy constraints. SAGE learns to synthesize visual prompts that implicitly align feature distributions across styles instead of directly fine-tuning the backbone. Specifically, we first utilize style transfer to construct a diverse style representation of the source domain, thereby learning a set of style characteristics that can cover a wide range of visual features. Then, the model adaptively fuses these style cues according to the visual context of each input, forming a dynamic prompt that harmonizes the image appearance without touching the interior of the model. Through this closed-loop design, SAGE effectively bridges the gap between frozen model invariance and the diversity of unseen domains. Extensive experiments on five benchmark datasets demonstrate that SAGE achieves competitive or superior performance compared to state-of-the-art methods under privacy constraints and outperforms full fine-tuning baselines in all settings.

