---
layout: default
title: WeMMU: Enhanced Bridging of Vision-Language Models and Diffusion Models via Noisy Query Tokens
---

# WeMMU: Enhanced Bridging of Vision-Language Models and Diffusion Models via Noisy Query Tokens

**arXiv**: [2512.02536v1](https://arxiv.org/abs/2512.02536) | [PDF](https://arxiv.org/pdf/2512.02536.pdf)

**ä½œè€…**: Jian Yang, Dacheng Yin, Xiaoxuan He, Yong Li, Fengyun Rao, Jing Lyu, Wei Zhai, Yang Cao, Zheng-Jun Zha

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNoisy Query Tokensä»¥è§£å†³è§†è§‰è¯­è¨€æ¨¡åž‹ä¸Žæ‰©æ•£æ¨¡åž‹æ¡¥æŽ¥ä¸­çš„æ³›åŒ–å´©æºƒé—®é¢˜**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡åž‹` `æ‰©æ•£æ¨¡åž‹` `æ¡¥æŽ¥æ–¹æ³•` `æŒç»­å­¦ä¹ ` `å›¾åƒç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå›ºå®šæŸ¥è¯¢ä»¤ç‰Œæ–¹æ³•åœ¨æ¡¥æŽ¥è§†è§‰è¯­è¨€æ¨¡åž‹ä¸Žæ‰©æ•£æ¨¡åž‹æ—¶ï¼Œé¢ä¸´ä»»åŠ¡æ³›åŒ–å´©æºƒï¼Œéš¾ä»¥é€‚åº”æ–°ä»»åŠ¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥Noisy Query Tokensï¼Œé€šè¿‡ç«¯åˆ°ç«¯ä¼˜åŒ–å­¦ä¹ åˆ†å¸ƒå¼è¡¨ç¤ºç©ºé—´ï¼Œå¹¶æ·»åŠ VAEåˆ†æ”¯ä»¥æ¢å¤å›¾åƒç»†èŠ‚ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒè¯å®žè¯¥æ–¹æ³•ç¼“è§£æ³›åŒ–å´©æºƒï¼Œæ”¯æŒè·¨ä»»åŠ¡çš„ç¨³å®šæŒç»­å­¦ä¹ ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent progress in multimodal large language models (MLLMs) has highlighted the challenge of efficiently bridging pre-trained Vision-Language Models (VLMs) with Diffusion Models. While methods using a fixed number of learnable query tokens offer computational efficiency, they suffer from task generalization collapse, failing to adapt to new tasks that are distant from their pre-training tasks. To overcome this, we propose Noisy Query Tokens, which learn a distributed representation space between the VLM and Diffusion Model via end-to-end optimization, enhancing continual learning. Additionally, we introduce a VAE branch with linear projection to recover fine-grained image details. Experimental results confirm our approach mitigates generalization collapse and enables stable continual learning across diverse tasks.

