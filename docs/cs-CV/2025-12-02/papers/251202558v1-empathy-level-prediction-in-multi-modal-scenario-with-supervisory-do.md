---
layout: default
title: Empathy Level Prediction in Multi-Modal Scenario with Supervisory Documentation Assistance
---

# Empathy Level Prediction in Multi-Modal Scenario with Supervisory Documentation Assistance

**arXiv**: [2512.02558v1](https://arxiv.org/abs/2512.02558) | [PDF](https://arxiv.org/pdf/2512.02558.pdf)

**ä½œè€…**: Yufei Xiao, Shangfei Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€å…±æƒ…é¢„æµ‹æ–¹æ³•ï¼Œç»“åˆç›‘ç£æ–‡æ¡£è¾…åŠ©è®­ç»ƒä»¥æå‡æ€§èƒ½ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€å…±æƒ…é¢„æµ‹` `è·¨æ¨¡æ€èžåˆ` `ç›‘ç£æ–‡æ¡£è¾…åŠ©è®­ç»ƒ` `ç‰¹æƒä¿¡æ¯åˆ©ç”¨` `Latent Dirichlet Allocation`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰å…±æƒ…é¢„æµ‹æ–¹æ³•å¤šä¾èµ–å•ä¸€æ¨¡æ€ï¼Œå¿½ç•¥å¤šæ¨¡æ€å¤„ç†å’Œç‰¹æƒä¿¡æ¯åˆ©ç”¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ•´åˆè§†é¢‘ã€éŸ³é¢‘å’Œæ–‡æœ¬ç‰¹å¾ï¼Œé€šè¿‡è·¨æ¨¡æ€èžåˆé¢„æµ‹å…±æƒ…æ ‡ç­¾ï¼Œå¹¶å¼•å…¥ç›‘ç£æ–‡æ¡£ä½œä¸ºè®­ç»ƒç‰¹æƒä¿¡æ¯ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šæ¨¡æ€å’Œå¯¹è¯å…±æƒ…æ•°æ®é›†ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Prevalent empathy prediction techniques primarily concentrate on a singular modality, typically textual, thus neglecting multi-modal processing capabilities. They also overlook the utilization of certain privileged information, which may encompass additional empathetic content. In response, we introduce an advanced multi-modal empathy prediction method integrating video, audio, and text information. The method comprises the Multi-Modal Empathy Prediction and Supervisory Documentation Assisted Training. We use pre-trained networks in the empathy prediction network to extract features from various modalities, followed by a cross-modal fusion. This process yields a multi-modal feature representation, which is employed to predict empathy labels. To enhance the extraction of text features, we incorporate supervisory documents as privileged information during the assisted training phase. Specifically, we apply the Latent Dirichlet Allocation model to identify potential topic distributions to constrain text features. These supervisory documents, created by supervisors, focus on the counseling topics and the counselor's display of empathy. Notably, this privileged information is only available during training and is not accessible during the prediction phase. Experimental results on the multi-modal and dialogue empathy datasets demonstrate that our approach is superior to the existing methods.

