---
layout: default
title: Two-Stage Vision Transformer for Image Restoration: Colorization Pretraining + Residual Upsampling
---

# Two-Stage Vision Transformer for Image Restoration: Colorization Pretraining + Residual Upsampling

**arXiv**: [2512.02512v1](https://arxiv.org/abs/2512.02512) | [PDF](https://arxiv.org/pdf/2512.02512.pdf)

**ä½œè€…**: Aditya Chaudhary, Prachet Dev Singh, Ankit Jha

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºViT-SRï¼Œé€šè¿‡ç€è‰²é¢„è®­ç»ƒå’Œæ®‹å·®ä¸Šé‡‡æ ·ä¸¤é˜¶æ®µç­–ç•¥æå‡å•å›¾åƒè¶…åˆ†è¾¨çŽ‡æ€§èƒ½ã€‚**

**å…³é”®è¯**: `å•å›¾åƒè¶…åˆ†è¾¨çŽ‡` `è§†è§‰Transformer` `è‡ªç›‘ç£é¢„è®­ç»ƒ` `æ®‹å·®å­¦ä¹ ` `å›¾åƒæ¢å¤`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå•å›¾åƒè¶…åˆ†è¾¨çŽ‡ï¼ˆSISRï¼‰åœ¨è®¡ç®—æœºè§†è§‰ä¸­ä»å…·æŒ‘æˆ˜æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒï¼Œå…ˆè‡ªç›‘ç£ç€è‰²é¢„è®­ç»ƒå­¦ä¹ é€šç”¨è§†è§‰è¡¨ç¤ºï¼Œå†å¾®è°ƒè¿›è¡Œ4å€è¶…åˆ†è¾¨çŽ‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨DIV2Kæ•°æ®é›†ä¸Šå®žçŽ°SSIM 0.712å’ŒPSNR 22.90 dBï¼ŒéªŒè¯æ–¹æ³•æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In computer vision, Single Image Super-Resolution (SISR) is still a difficult problem. We present ViT-SR, a new technique to improve the performance of a Vision Transformer (ViT) employing a two-stage training strategy. In our method, the model learns rich, generalizable visual representations from the data itself through a self-supervised pretraining phase on a colourization task. The pre-trained model is then adjusted for 4x super-resolution. By predicting the addition of a high-frequency residual image to an initial bicubic interpolation, this design simplifies residual learning. ViT-SR, trained and evaluated on the DIV2K benchmark dataset, achieves an impressive SSIM of 0.712 and PSNR of 22.90 dB. These results demonstrate the efficacy of our two-stage approach and highlight the potential of self-supervised pre-training for complex image restoration tasks. Further improvements may be possible with larger ViT architectures or alternative pretext tasks.

