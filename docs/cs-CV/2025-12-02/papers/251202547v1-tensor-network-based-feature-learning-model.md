---
layout: default
title: Tensor Network Based Feature Learning Model
---

# Tensor Network Based Feature Learning Model

**arXiv**: [2512.02547v1](https://arxiv.org/abs/2512.02547) | [PDF](https://arxiv.org/pdf/2512.02547.pdf)

**ä½œè€…**: Albert Saiapin, Kim Batselier

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå¼ é‡ç½‘ç»œçš„ç‰¹å¾å­¦ä¹ æ¨¡åž‹ï¼Œé€šè¿‡å¯å­¦ä¹ CPDä¼˜åŒ–ç‰¹å¾è¶…å‚æ•°ï¼Œæå‡å¤§è§„æ¨¡æ ¸æ–¹æ³•è®­ç»ƒæ•ˆçŽ‡ã€‚**

**å…³é”®è¯**: `å¼ é‡ç½‘ç»œ` `ç‰¹å¾å­¦ä¹ ` `æ ¸æ–¹æ³•` `è¶…å‚æ•°ä¼˜åŒ–` `äº¤æ›¿æœ€å°äºŒä¹˜æ³•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ ¸æ–¹æ³•ä¸­ç‰¹å¾è¶…å‚æ•°ä¼˜åŒ–ä¾èµ–äº¤å‰éªŒè¯ï¼Œæ•ˆçŽ‡ä½Žä¸”æœªè‡ªåŠ¨åŒ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†å¼ é‡ç§¯ç‰¹å¾è¡¨ç¤ºä¸ºå¯å­¦ä¹ CPDï¼Œä½¿ç”¨ALSè”åˆä¼˜åŒ–æ¨¡åž‹ä¸Žè¶…å‚æ•°ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žæ•°æ®ä¸Šè®­ç»ƒå¿«3-5å€ï¼Œé¢„æµ‹è´¨é‡ä¸Žæ ‡å‡†æ¨¡åž‹ç›¸å½“ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Many approximations were suggested to circumvent the cubic complexity of kernel-based algorithms, allowing their application to large-scale datasets. One strategy is to consider the primal formulation of the learning problem by mapping the data to a higher-dimensional space using tensor-product structured polynomial and Fourier features. The curse of dimensionality due to these tensor-product features was effectively solved by a tensor network reparameterization of the model parameters. However, another important aspect of model training - identifying optimal feature hyperparameters - has not been addressed and is typically handled using the standard cross-validation approach. In this paper, we introduce the Feature Learning (FL) model, which addresses this issue by representing tensor-product features as a learnable Canonical Polyadic Decomposition (CPD). By leveraging this CPD structure, we efficiently learn the hyperparameters associated with different features alongside the model parameters using an Alternating Least Squares (ALS) optimization method. We prove the effectiveness of the FL model through experiments on real data of various dimensionality and scale. The results show that the FL model can be consistently trained 3-5 times faster than and have the prediction quality on par with a standard cross-validated model.

