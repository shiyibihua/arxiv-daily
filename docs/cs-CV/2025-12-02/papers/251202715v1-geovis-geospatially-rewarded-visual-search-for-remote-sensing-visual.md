---
layout: default
title: GeoViS: Geospatially Rewarded Visual Search for Remote Sensing Visual Grounding
---

# GeoViS: Geospatially Rewarded Visual Search for Remote Sensing Visual Grounding

**arXiv**: [2512.02715v1](https://arxiv.org/abs/2512.02715) | [PDF](https://arxiv.org/pdf/2512.02715.pdf)

**ä½œè€…**: Peirong Zhang, Yidan Zhang, Luxiao Xu, Jinliang Lin, Zonghao Guo, Fengxiang Wang, Xue Yang, Kaiwen Wei, Lei Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGeoViSæ¡†æž¶ï¼Œé€šè¿‡æ¸è¿›å¼æœç´¢è§£å†³é¥æ„Ÿå›¾åƒä¸­å¾®å°ç›®æ ‡çš„è§†è§‰å®šä½é—®é¢˜ã€‚**

**å…³é”®è¯**: `é¥æ„Ÿè§†è§‰å®šä½` `æ¸è¿›å¼æœç´¢` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `åœ°ç†ç©ºé—´æŽ¨ç†` `å¥–åŠ±å¼•å¯¼æŽ¢ç´¢`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé¥æ„Ÿå›¾åƒä¸­ç›®æ ‡æžå°ä¸”æŸ¥è¯¢æ¶‰åŠå¤æ‚åœ°ç†ç©ºé—´å…³ç³»ï¼Œå¯¼è‡´è§†è§‰å®šä½å›°éš¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ ‘çŠ¶ç»“æž„æ¸è¿›æœç´¢ï¼Œç»“åˆå¤šæ¨¡æ€æ„ŸçŸ¥å’Œå¥–åŠ±å¼•å¯¼æŽ¢ç´¢ï¼Œè¿­ä»£ä¼˜åŒ–åœ°ç†ç©ºé—´å‡è®¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œå±•çŽ°ç²¾ç¡®åœ°ç†ç©ºé—´ç†è§£å’Œå¼ºæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in multimodal large language models(MLLMs) have led to remarkable progress in visual grounding, enabling fine-grained cross-modal alignment between textual queries and image regions. However, transferring such capabilities to remote sensing imagery remains challenging, as targets are often extremely small within kilometer-scale scenes, and queries typically involve intricate geospatial relations such as relative positions, spatial hierarchies, or contextual dependencies across distant objects. To address these challenges, we propose GeoViS, a Geospatially Rewarded Visual Search framework that reformulates remote sensing visual grounding as a progressive search-and-reasoning process. Rather than directly predicting the target location in a single step, GeoViS actively explores the global image through a tree-structured sequence of visual cues, integrating multimodal perception, spatial reasoning, and reward-guided exploration to refine geospatial hypotheses iteratively. This design enables the model to detect subtle small-scale targets while maintaining holistic scene awareness. Extensive experiments on five remote sensing grounding benchmarks demonstrate that GeoViS achieves precise geospatial understanding and consistently surpasses existing methods across key visual grounding metrics, highlighting its strong cross-domain generalization and interpretability.

