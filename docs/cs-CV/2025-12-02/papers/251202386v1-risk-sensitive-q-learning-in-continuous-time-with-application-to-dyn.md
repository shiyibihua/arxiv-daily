---
layout: default
title: Risk-Sensitive Q-Learning in Continuous Time with Application to Dynamic Portfolio Selection
---

# Risk-Sensitive Q-Learning in Continuous Time with Application to Dynamic Portfolio Selection

**arXiv**: [2512.02386v1](https://arxiv.org/abs/2512.02386) | [PDF](https://arxiv.org/pdf/2512.02386.pdf)

**ä½œè€…**: Chuhan Xie

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCT-RS-qç®—æ³•ä»¥è§£å†³è¿žç»­æ—¶é—´é£Žé™©æ•æ„Ÿå¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œåº”ç”¨äºŽåŠ¨æ€æŠ•èµ„ç»„åˆé€‰æ‹©ã€‚**

**å…³é”®è¯**: `é£Žé™©æ•æ„Ÿå¼ºåŒ–å­¦ä¹ ` `è¿žç»­æ—¶é—´æŽ§åˆ¶` `éšæœºå¾®åˆ†æ–¹ç¨‹` `ä¼˜åŒ–ç¡®å®šæ€§ç­‰ä»·` `åŠ¨æ€æŠ•èµ„ç»„åˆé€‰æ‹©` `éž…è¡¨å¾`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç ”ç©¶è¿žç»­æ—¶é—´é£Žé™©æ•æ„Ÿå¼ºåŒ–å­¦ä¹ ï¼ŒçŽ¯å¢ƒç”±å¯æŽ§éšæœºå¾®åˆ†æ–¹ç¨‹æè¿°ï¼Œç›®æ ‡ä¸ºç´¯ç§¯å¥–åŠ±çš„éžçº¿æ€§æ³›å‡½ã€‚
2. è¯æ˜Žå½“æ³›å‡½ä¸ºä¼˜åŒ–ç¡®å®šæ€§ç­‰ä»·æ—¶ï¼Œæœ€ä¼˜ç­–ç•¥ç›¸å¯¹äºŽå¢žå¼ºçŽ¯å¢ƒæ˜¯é©¬å°”å¯å¤«çš„ï¼Œå¹¶åŸºäºŽéž…è¡¨å¾æå‡ºCT-RS-qç®—æ³•ã€‚
3. åœ¨åŠ¨æ€æŠ•èµ„ç»„åˆé€‰æ‹©æ¨¡æ‹Ÿä¸­éªŒè¯ç®—æ³•æœ‰æ•ˆæ€§ï¼ŒæœªçŸ¥å…·ä½“æ€§èƒ½æŒ‡æ ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper studies the problem of risk-sensitive reinforcement learning (RSRL) in continuous time, where the environment is characterized by a controllable stochastic differential equation (SDE) and the objective is a potentially nonlinear functional of cumulative rewards. We prove that when the functional is an optimized certainty equivalent (OCE), the optimal policy is Markovian with respect to an augmented environment. We also propose \textit{CT-RS-q}, a risk-sensitive q-learning algorithm based on a novel martingale characterization approach. Finally, we run a simulation study on a dynamic portfolio selection problem and illustrate the effectiveness of our algorithm.

