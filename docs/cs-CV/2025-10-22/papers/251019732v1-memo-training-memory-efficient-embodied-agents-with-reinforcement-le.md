---
layout: default
title: Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning
---

# Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning

**arXiv**: [2510.19732v1](https://arxiv.org/abs/2510.19732) | [PDF](https://arxiv.org/pdf/2510.19732.pdf)

**ä½œè€…**: Gunshi Gupta, Karmesh Yadav, Zsolt Kira, Yarin Gal, Rahaf Aljundi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMemoæž¶æž„ä»¥è§£å†³é•¿æ—¶ç¨‹å…·èº«ä»»åŠ¡ä¸­transformerå†…å­˜æ•ˆçŽ‡é—®é¢˜**

**å…³é”®è¯**: `å…·èº«æ™ºèƒ½` `å¼ºåŒ–å­¦ä¹ ` `transformeræž¶æž„` `å†…å­˜æ•ˆçŽ‡` `é•¿æ—¶ç¨‹ä»»åŠ¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼štransformeråœ¨å…·èº«å†³ç­–ä¸­è§†è§‰è¾“å…¥æ˜“è¶…ä¸Šä¸‹æ–‡é™åˆ¶ï¼Œéœ€é«˜æ•ˆè®°å¿†æœºåˆ¶
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥å‘¨æœŸæ€§æ‘˜è¦ä»¤ç‰Œï¼Œåœ¨è®­ç»ƒä¸­é›†æˆè®°å¿†åˆ›å»ºä¸Žæ£€ç´¢
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ç½‘æ ¼ä¸–ç•Œå’Œå®¤å†…å¯¼èˆªä»»åŠ¡ä¸­ä¼˜äºŽåŸºçº¿ï¼Œæå‡è®¡ç®—æ•ˆçŽ‡ä¸Žæ³›åŒ–èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> To enable embodied agents to operate effectively over extended timeframes, it
> is crucial to develop models that form and access memories to stay
> contextualized in their environment. In the current paradigm of training
> transformer-based policies for embodied sequential decision-making tasks,
> visual inputs often overwhelm the context limits of transformers, while humans
> can maintain and utilize a lifetime of experience compressed as memories.
> Significant compression is possible in principle, as much of the input is
> irrelevant and can be abstracted. However, existing approaches predominantly
> focus on either recurrent models with fixed-size memory or transformers with
> full-context reliance. In this work, we propose Memo, a transformer-based
> architecture and training recipe for reinforcement learning (RL) on
> memory-intensive, long-horizon tasks. Memo incorporates the creation and
> retrieval of memory by interleaving periodic summarization tokens with the
> inputs of a model during training. We demonstrate Memo's effectiveness on a
> gridworld meta-RL benchmark and a multi-object navigation task in
> photo-realistic indoor settings. Memo outperforms naive long-context
> transformer baselines while being more compute and storage efficient.
> Additionally, Memo generalizes better to longer contexts at inference time and
> remains robust in streaming settings, where historical context must be
> truncated to fit inference constraints.

