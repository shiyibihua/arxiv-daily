---
layout: default
title: PruneHal: Reducing Hallucinations in Multi-modal Large Language Models through Adaptive KV Cache Pruning
---

# PruneHal: Reducing Hallucinations in Multi-modal Large Language Models through Adaptive KV Cache Pruning

**arXiv**: [2510.19183v1](https://arxiv.org/abs/2510.19183) | [PDF](https://arxiv.org/pdf/2510.19183.pdf)

**ä½œè€…**: Fengyuan Sun, Hui Chen, Xinhao Xu, Dandan Zheng, Jingdong Chen, Jun Zhou, Jungong Han, Guiguang Ding

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPruneHalæ–¹æ³•ï¼Œé€šè¿‡è‡ªé€‚åº”KVç¼“å­˜å‰ªæå‡å°‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å¹»è§‰ç¼“è§£` `KVç¼“å­˜å‰ªæ` `æ³¨æ„åŠ›æœºåˆ¶` `è®­ç»ƒæ— å…³æ–¹æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å¹»è§‰ä¸è§†è§‰ä»¤ç‰Œæ³¨æ„åŠ›ä¸è¶³ç›¸å…³ï¼Œå†—ä½™ä»¤ç‰Œåˆ†æ•£æ³¨æ„åŠ›
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨è®­ç»ƒæ— å…³çš„è‡ªé€‚åº”KVç¼“å­˜å‰ªæï¼Œå¢å¼ºå¯¹å…³é”®è§†è§‰ä¿¡æ¯çš„å…³æ³¨
3. å®éªŒæˆ–æ•ˆæœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­éªŒè¯ï¼Œæ— éœ€é¢å¤–è®­ç»ƒä¸”æ¨ç†æˆæœ¬å‡ ä¹ä¸ºé›¶

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While multi-modal large language models (MLLMs) have made significant
> progress in recent years, the issue of hallucinations remains a major
> challenge. To mitigate this phenomenon, existing solutions either introduce
> additional data for further training or incorporate external or internal
> information during inference. However, these approaches inevitably introduce
> extra computational costs. In this paper, we observe that hallucinations in
> MLLMs are strongly associated with insufficient attention allocated to visual
> tokens. In particular, the presence of redundant visual tokens disperses the
> model's attention, preventing it from focusing on the most informative ones. As
> a result, critical visual cues are often under-attended, which in turn
> exacerbates the occurrence of hallucinations. Building on this observation, we
> propose \textbf{PruneHal}, a training-free, simple yet effective method that
> leverages adaptive KV cache pruning to enhance the model's focus on critical
> visual information, thereby mitigating hallucinations. To the best of our
> knowledge, we are the first to apply token pruning for hallucination mitigation
> in MLLMs. Notably, our method don't require additional training and incurs
> nearly no extra inference cost. Moreover, PruneHal is model-agnostic and can be
> seamlessly integrated with different decoding strategies, including those
> specifically designed for hallucination mitigation. We evaluate PruneHal on
> several widely used hallucination evaluation benchmarks using four mainstream
> MLLMs, achieving robust and outstanding results that highlight the
> effectiveness and superiority of our method. Our code will be publicly
> available.

