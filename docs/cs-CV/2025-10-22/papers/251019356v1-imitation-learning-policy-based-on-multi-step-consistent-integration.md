---
layout: default
title: Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model
---

# Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model

**arXiv**: [2510.19356v1](https://arxiv.org/abs/2510.19356) | [PDF](https://arxiv.org/pdf/2510.19356.pdf)

**ä½œè€…**: Yu Fang, Xinyu Wang, Xuehe Zhang, Wanli Xue, Mingwei Zhang, Shengyong Chen, Jie Zhao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ­¥ä¸€è‡´é›†æˆæ·å¾„æ¨¡åž‹ä»¥å¹³è¡¡æœºå™¨äººæ¨¡ä»¿å­¦ä¹ çš„æŽ¨ç†é€Ÿåº¦ä¸Žæ€§èƒ½**

**å…³é”®è¯**: `æœºå™¨äººæ¨¡ä»¿å­¦ä¹ ` `æµåŒ¹é…æ–¹æ³•` `å¤šæ­¥ä¸€è‡´æ€§æŸå¤±` `è‡ªé€‚åº”æ¢¯åº¦åˆ†é…` `ä¸€æ­¥æŽ¨ç†ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæµåŒ¹é…æ–¹æ³•åœ¨æœºå™¨äººæ¨¡ä»¿å­¦ä¹ ä¸­æŽ¨ç†æ—¶é—´é«˜ï¼ŒçŽ°æœ‰è’¸é¦å’Œä¸€è‡´æ€§æ–¹æ³•æ€§èƒ½ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ‰©å±•å¤šæ­¥ä¸€è‡´æ€§æŸå¤±ï¼Œåˆ†å‰²ä¸€æ­¥æŸå¤±ä¸ºå¤šæ­¥ï¼Œå¹¶é‡‡ç”¨è‡ªé€‚åº”æ¢¯åº¦åˆ†é…ç¨³å®šä¼˜åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ¨¡æ‹ŸåŸºå‡†å’ŒçœŸå®žçŽ¯å¢ƒä»»åŠ¡ä¸­éªŒè¯ç®—æ³•æœ‰æ•ˆæ€§ï¼Œæå‡ä¸€æ­¥æŽ¨ç†æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The wide application of flow-matching methods has greatly promoted the
> development of robot imitation learning. However, these methods all face the
> problem of high inference time. To address this issue, researchers have
> proposed distillation methods and consistency methods, but the performance of
> these methods still struggles to compete with that of the original diffusion
> models and flow-matching models. In this article, we propose a one-step
> shortcut method with multi-step integration for robot imitation learning. To
> balance the inference speed and performance, we extend the multi-step
> consistency loss on the basis of the shortcut model, split the one-step loss
> into multi-step losses, and improve the performance of one-step inference.
> Secondly, to solve the problem of unstable optimization of the multi-step loss
> and the original flow-matching loss, we propose an adaptive gradient allocation
> method to enhance the stability of the learning process. Finally, we evaluate
> the proposed method in two simulation benchmarks and five real-world
> environment tasks. The experimental results verify the effectiveness of the
> proposed algorithm.

