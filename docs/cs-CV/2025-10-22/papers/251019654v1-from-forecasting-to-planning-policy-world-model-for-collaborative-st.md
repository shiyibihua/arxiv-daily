---
layout: default
title: From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction
---

# From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction

**arXiv**: [2510.19654v1](https://arxiv.org/abs/2510.19654) | [PDF](https://arxiv.org/pdf/2510.19654.pdf)

**ä½œè€…**: Zhida Zhao, Talas Fu, Yifan Wang, Lijun Wang, Huchuan Lu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç­–ç•¥ä¸–ç•Œæ¨¡åž‹ä»¥ç»Ÿä¸€ä¸–ç•Œå»ºæ¨¡ä¸Žè½¨è¿¹è§„åˆ’ï¼Œæå‡è‡ªåŠ¨é©¾é©¶æ€§èƒ½**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶ä¸–ç•Œæ¨¡åž‹` `è½¨è¿¹è§„åˆ’` `çŠ¶æ€-åŠ¨ä½œé¢„æµ‹` `è§†é¢‘é¢„æµ‹` `åŠ¨æ€å¢žå¼ºæœºåˆ¶` `åä½œé¢„æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰é©¾é©¶ä¸–ç•Œæ¨¡åž‹å¤šç”¨äºŽä»¿çœŸï¼Œä¸Žè½¨è¿¹è§„åˆ’è„±èŠ‚ï¼ŒååŒæœºåˆ¶æœªå……åˆ†æŽ¢ç´¢ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆä¸–ç•Œå»ºæ¨¡ä¸Žè§„åˆ’ï¼Œé€šè¿‡æ— åŠ¨ä½œæœªæ¥çŠ¶æ€é¢„æµ‹å’Œåä½œçŠ¶æ€-åŠ¨ä½œé¢„æµ‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šä»…ç”¨å‰æ‘„åƒå¤´è¾“å…¥ï¼Œæ€§èƒ½åŒ¹é…æˆ–è¶…è¶Šä¾èµ–å¤šè§†å›¾å¤šæ¨¡æ€çš„å…ˆè¿›æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite remarkable progress in driving world models, their potential for
> autonomous systems remains largely untapped: the world models are mostly
> learned for world simulation and decoupled from trajectory planning. While
> recent efforts aim to unify world modeling and planning in a single framework,
> the synergistic facilitation mechanism of world modeling for planning still
> requires further exploration. In this work, we introduce a new driving paradigm
> named Policy World Model (PWM), which not only integrates world modeling and
> trajectory planning within a unified architecture, but is also able to benefit
> planning using the learned world knowledge through the proposed action-free
> future state forecasting scheme. Through collaborative state-action prediction,
> PWM can mimic the human-like anticipatory perception, yielding more reliable
> planning performance. To facilitate the efficiency of video forecasting, we
> further introduce a dynamically enhanced parallel token generation mechanism,
> equipped with a context-guided tokenizer and an adaptive dynamic focal loss.
> Despite utilizing only front camera input, our method matches or exceeds
> state-of-the-art approaches that rely on multi-view and multi-modal inputs.
> Code and model weights will be released at
> https://github.com/6550Zhao/Policy-World-Model.

