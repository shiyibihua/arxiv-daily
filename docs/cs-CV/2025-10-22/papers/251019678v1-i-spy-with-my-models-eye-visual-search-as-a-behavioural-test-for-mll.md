---
layout: default
title: I Spy With My Model's Eye: Visual Search as a Behavioural Test for MLLMs
---

# I Spy With My Model's Eye: Visual Search as a Behavioural Test for MLLMs

**arXiv**: [2510.19678v1](https://arxiv.org/abs/2510.19678) | [PDF](https://arxiv.org/pdf/2510.19678.pdf)

**ä½œè€…**: John Burden, Jonathan Prunty, Ben Slater, Matthieu Tehenan, Greg Davis, Lucy Cheke

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§†è§‰æœç´¢ä½œä¸ºè¡Œä¸ºæµ‹è¯•ï¼Œè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹çš„æ„ŸçŸ¥æœºåˆ¶ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `è§†è§‰æœç´¢` `å¼¹å‡ºæ•ˆåº”` `è®¤çŸ¥å¿ƒç†å­¦` `æœºåˆ¶è¯„ä¼°` `åœºæ™¯å…ˆéªŒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹çš„è§†è§‰å¤„ç†æœºåˆ¶ä¸é€æ˜Žï¼ŒçŽ°æœ‰è¯„ä¼°éš¾ä»¥æ­ç¤ºåº•å±‚æœºåˆ¶ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå€Ÿé‰´è®¤çŸ¥å¿ƒç†å­¦ï¼Œé‡‡ç”¨ç»å…¸è§†è§‰æœç´¢èŒƒå¼æµ‹è¯•æ¨¡åž‹æ˜¯å¦è¡¨çŽ°å‡ºå¼¹å‡ºæ•ˆåº”ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¨¡åž‹åœ¨é¢œè‰²æˆ–å¤§å°æœç´¢ä¸­è¡¨çŽ°å‡ºäººç±»ç±»ä¼¼å¼¹å‡ºæ•ˆåº”ï¼Œå¹¶å—åœºæ™¯å…ˆéªŒå½±å“ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) achieve strong performance on
> vision-language tasks, yet their visual processing is opaque. Most black-box
> evaluations measure task accuracy, but reveal little about underlying
> mechanisms. Drawing on cognitive psychology, we adapt classic visual search
> paradigms -- originally developed to study human perception -- to test whether
> MLLMs exhibit the ``pop-out'' effect, where salient visual features are
> detected independently of distractor set size. Using controlled experiments
> targeting colour, size and lighting features, we find that advanced MLLMs
> exhibit human-like pop-out effects in colour or size-based disjunctive (single
> feature) search, as well as capacity limits for conjunctive (multiple feature)
> search. We also find evidence to suggest that MLLMs, like humans, incorporate
> natural scene priors such as lighting direction into object representations. We
> reinforce our findings using targeted fine-tuning and mechanistic
> interpretability analyses. Our work shows how visual search can serve as a
> cognitively grounded diagnostic tool for evaluating perceptual capabilities in
> MLLMs.

