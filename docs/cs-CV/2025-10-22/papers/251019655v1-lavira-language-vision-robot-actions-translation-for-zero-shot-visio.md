---
layout: default
title: LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments
---

# LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments

**arXiv**: [2510.19655v1](https://arxiv.org/abs/2510.19655) | [PDF](https://arxiv.org/pdf/2510.19655.pdf)

**ä½œè€…**: Hongyu Ding, Ziming Xu, Yudong Fang, You Wu, Zixuan Chen, Jieqi Shi, Jing Huo, Yifan Zhang, Yang Gao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLaViRAæ¡†æž¶ä»¥è§£å†³é›¶æ ·æœ¬è§†è§‰è¯­è¨€å¯¼èˆªä¸­çš„æ³›åŒ–ä¸ŽæŽ¨ç†æƒè¡¡é—®é¢˜**

**å…³é”®è¯**: `é›¶æ ·æœ¬å¯¼èˆª` `è§†è§‰è¯­è¨€å¯¼èˆª` `å¤šæ¨¡æ€å¤§æ¨¡åž‹` `åŠ¨ä½œåˆ†è§£` `è¿žç»­çŽ¯å¢ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé›¶æ ·æœ¬è§†è§‰è¯­è¨€å¯¼èˆªåœ¨è¿žç»­çŽ¯å¢ƒä¸­é¢ä¸´æ³›åŒ–ä¸ŽæŽ¨ç†èƒ½åŠ›çš„æƒè¡¡
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨è¯­è¨€-è§†è§‰-æœºå™¨äººåŠ¨ä½œçš„ç²—åˆ°ç»†å±‚æ¬¡åˆ†è§£ï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§æ¨¡åž‹ä¼˜åŠ¿
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨VLN-CEåŸºå‡†ä¸Šæ˜¾è‘—è¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œå±•ç¤ºä¼˜è¶Šæ³›åŒ–èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Zero-shot Vision-and-Language Navigation in Continuous Environments (VLN-CE)
> requires an agent to navigate unseen environments based on natural language
> instructions without any prior training. Current methods face a critical
> trade-off: either rely on environment-specific waypoint predictors that limit
> scene generalization, or underutilize the reasoning capabilities of large
> models during navigation. We introduce LaViRA, a simple yet effective zero-shot
> framework that addresses this dilemma by decomposing action into a
> coarse-to-fine hierarchy: Language Action for high-level planning, Vision
> Action for perceptual grounding, and Robot Action for robust navigation. This
> modular decomposition allows us to leverage the distinct strengths of different
> scales of Multimodal Large Language Models (MLLMs) at each stage, creating a
> system that is powerful in its reasoning, grounding and practical control.
> LaViRA significantly outperforms existing state-of-the-art methods on the
> VLN-CE benchmark, demonstrating superior generalization capabilities in unseen
> environments, while maintaining transparency and efficiency for real-world
> deployment.

