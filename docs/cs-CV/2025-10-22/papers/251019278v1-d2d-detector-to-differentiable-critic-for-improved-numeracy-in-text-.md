---
layout: default
title: D2D: Detector-to-Differentiable Critic for Improved Numeracy in Text-to-Image Generation
---

# D2D: Detector-to-Differentiable Critic for Improved Numeracy in Text-to-Image Generation

**arXiv**: [2510.19278v1](https://arxiv.org/abs/2510.19278) | [PDF](https://arxiv.org/pdf/2510.19278.pdf)

**ä½œè€…**: Nobline Yoo, Olga Russakovsky, Ye Zhu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºD2Dæ¡†æž¶å°†éžå¯å¾®æ£€æµ‹å™¨è½¬åŒ–ä¸ºå¯å¾®æ‰¹è¯„å™¨ï¼Œä»¥æå‡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„å¯¹è±¡è®¡æ•°å‡†ç¡®æ€§**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `å¯¹è±¡è®¡æ•°` `å¯å¾®æ‰¹è¯„å™¨` `æ£€æµ‹å™¨è½¬æ¢` `æ‰©æ•£æ¨¡åž‹ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡åž‹åœ¨ç”ŸæˆæŒ‡å®šå¯¹è±¡æ•°é‡æ—¶å­˜åœ¨å›°éš¾ï¼ŒçŽ°æœ‰æ–¹æ³•å—é™äºŽå¯å¾®æ€§è€Œæ— æ³•ä½¿ç”¨é«˜æ€§èƒ½æ£€æµ‹å™¨
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡è‡ªå®šä¹‰æ¿€æ´»å‡½æ•°å°†æ£€æµ‹å™¨è¾“å‡ºè½¬æ¢ä¸ºè½¯äºŒè¿›åˆ¶æŒ‡ç¤ºå™¨ï¼Œç”¨äºŽåœ¨æŽ¨ç†æ—¶ä¼˜åŒ–å™ªå£°å…ˆéªŒ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡è®¡æ•°å‡†ç¡®çŽ‡ï¼Œæœ€é«˜è¾¾13.7%ï¼Œä¸”å›¾åƒè´¨é‡å’Œè®¡ç®—å¼€é”€å½±å“å°

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-to-image (T2I) diffusion models have achieved strong performance in
> semantic alignment, yet they still struggle with generating the correct number
> of objects specified in prompts. Existing approaches typically incorporate
> auxiliary counting networks as external critics to enhance numeracy. However,
> since these critics must provide gradient guidance during generation, they are
> restricted to regression-based models that are inherently differentiable, thus
> excluding detector-based models with superior counting ability, whose
> count-via-enumeration nature is non-differentiable. To overcome this
> limitation, we propose Detector-to-Differentiable (D2D), a novel framework that
> transforms non-differentiable detection models into differentiable critics,
> thereby leveraging their superior counting ability to guide numeracy
> generation. Specifically, we design custom activation functions to convert
> detector logits into soft binary indicators, which are then used to optimize
> the noise prior at inference time with pre-trained T2I models. Our extensive
> experiments on SDXL-Turbo, SD-Turbo, and Pixart-DMD across four benchmarks of
> varying complexity (low-density, high-density, and multi-object scenarios)
> demonstrate consistent and substantial improvements in object counting accuracy
> (e.g., boosting up to 13.7% on D2D-Small, a 400-prompt, low-density benchmark),
> with minimal degradation in overall image quality and computational overhead.

