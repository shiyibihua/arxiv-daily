---
layout: default
title: Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models
---

# Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models

**arXiv**: [2510.19268v1](https://arxiv.org/abs/2510.19268) | [PDF](https://arxiv.org/pdf/2510.19268.pdf)

**ä½œè€…**: Mingen Li, Houjian Yu, Yixuan Huang, Youngjin Hong, Changhyun Choi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆ†å±‚æ¡†æž¶ç»“åˆå¼ºåŒ–å­¦ä¹ å’Œè§†è§‰è¯­è¨€æ¨¡åž‹ï¼Œä»¥è§£å†³å¯å˜å½¢çº¿æ€§ç‰©ä½“çš„é•¿æ—¶ç¨‹è·¯ç”±ä»»åŠ¡ã€‚**

**å…³é”®è¯**: `å¯å˜å½¢çº¿æ€§ç‰©ä½“è·¯ç”±` `åˆ†å±‚æ¡†æž¶` `å¼ºåŒ–å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡åž‹` `é•¿æ—¶ç¨‹è§„åˆ’` `å¤±è´¥æ¢å¤æœºåˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¯å˜å½¢çº¿æ€§ç‰©ä½“åœ¨å·¥ä¸šè£…é…ä¸­éœ€é•¿æ—¶ç¨‹è§„åˆ’å’Œå¯é æŠ€èƒ½æ‰§è¡Œï¼Œé€‚åº”éžçº¿æ€§åŠ¨æ€ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡åž‹è¿›è¡Œä¸Šä¸‹æ–‡æŽ¨ç†ç”Ÿæˆè®¡åˆ’ï¼Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒä½Žå±‚æŠ€èƒ½æ‰§è¡Œã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨é•¿æ—¶ç¨‹è·¯ç”±åœºæ™¯ä¸­æˆåŠŸçŽ‡92.5%ï¼Œä¼˜äºŽåŸºçº¿æ–¹æ³•è¿‘50%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Long-horizon routing tasks of deformable linear objects (DLOs), such as
> cables and ropes, are common in industrial assembly lines and everyday life.
> These tasks are particularly challenging because they require robots to
> manipulate DLO with long-horizon planning and reliable skill execution.
> Successfully completing such tasks demands adapting to their nonlinear
> dynamics, decomposing abstract routing goals, and generating multi-step plans
> composed of multiple skills, all of which require accurate high-level reasoning
> during execution. In this paper, we propose a fully autonomous hierarchical
> framework for solving challenging DLO routing tasks. Given an implicit or
> explicit routing goal expressed in language, our framework leverages
> vision-language models~(VLMs) for in-context high-level reasoning to synthesize
> feasible plans, which are then executed by low-level skills trained via
> reinforcement learning. To improve robustness in long horizons, we further
> introduce a failure recovery mechanism that reorients the DLO into
> insertion-feasible states. Our approach generalizes to diverse scenes involving
> object attributes, spatial descriptions, as well as implicit language commands.
> It outperforms the next best baseline method by nearly 50% and achieves an
> overall success rate of 92.5% across long-horizon routing scenarios.

