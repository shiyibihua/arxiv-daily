---
layout: default
title: CARES: Context-Aware Resolution Selector for VLMs
---

# CARES: Context-Aware Resolution Selector for VLMs

**arXiv**: [2510.19496v1](https://arxiv.org/abs/2510.19496) | [PDF](https://arxiv.org/pdf/2510.19496.pdf)

**ä½œè€…**: Moshe Kimhi, Nimrod Shabtay, Raja Giryes, Chaim Baskin, Eli Schwartz

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCARESæ¨¡å—ä»¥åŠ¨æ€é€‰æ‹©å›¾åƒåˆ†è¾¨çŽ‡ï¼Œé™ä½Žè§†è§‰è¯­è¨€æ¨¡åž‹è®¡ç®—å¼€é”€ã€‚**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡åž‹` `åˆ†è¾¨çŽ‡é€‰æ‹©` `è®¡ç®—ä¼˜åŒ–` `è½»é‡é¢„å¤„ç†` `å¤šæ¨¡æ€åŸºå‡†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†è§‰è¯­è¨€æ¨¡åž‹å¸¸å¤„ç†é«˜åˆ†è¾¨çŽ‡å›¾åƒï¼Œå¯¼è‡´è§†è§‰ä»¤ç‰Œå æ¯”é«˜ï¼Œå¢žåŠ è®¡ç®—å’Œå»¶è¿Ÿã€‚
2. CARESä½¿ç”¨è½»é‡VLMé¢„æµ‹æœ€å°è¶³å¤Ÿåˆ†è¾¨çŽ‡ï¼Œè®­ç»ƒä¸ºç¦»æ•£åˆ†ç±»å™¨ï¼ŒæŽ¨ç†æ—¶æ”¯æŒè¿žç»­æ’å€¼ã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒCARESä¿æŒä»»åŠ¡æ€§èƒ½ï¼Œè®¡ç®—é‡å‡å°‘é«˜è¾¾80%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large vision-language models (VLMs) commonly process images at native or high
> resolution to remain effective across tasks. This inflates visual tokens ofter
> to 97-99% of total tokens, resulting in high compute and latency, even when
> low-resolution images would suffice. We introduce \emph{CARES}-a
> \textbf{C}ontext-\textbf{A}ware \textbf{R}esolution \textbf{S}elector, a
> lightweight preprocessing module that, given an image-query pair, predicts the
> \emph{minimal} sufficient input resolution. CARES uses a compact VLM (350M) to
> extract features and predict when a target pretrained VLM's response converges
> to its peak ability to answer correctly. Though trained as a discrete
> classifier over a set of optional resolutions, CARES interpolates continuous
> resolutions at inference for fine-grained control. Across five multimodal
> benchmarks spanning documents and natural images, as well as diverse target
> VLMs, CARES preserves task performance while reducing compute by up to 80%.

