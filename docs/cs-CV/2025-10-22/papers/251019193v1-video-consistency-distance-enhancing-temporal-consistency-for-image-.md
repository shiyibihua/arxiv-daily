---
layout: default
title: Video Consistency Distance: Enhancing Temporal Consistency for Image-to-Video Generation via Reward-Based Fine-Tuning
---

# Video Consistency Distance: Enhancing Temporal Consistency for Image-to-Video Generation via Reward-Based Fine-Tuning

**arXiv**: [2510.19193v1](https://arxiv.org/abs/2510.19193) | [PDF](https://arxiv.org/pdf/2510.19193.pdf)

**ä½œè€…**: Takehiro Aoshima, Yusuke Shinohara, Park Byeongseon

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§†é¢‘ä¸€è‡´æ€§è·ç¦»ä»¥å¢žå¼ºå›¾åƒåˆ°è§†é¢‘ç”Ÿæˆä¸­çš„æ—¶åºä¸€è‡´æ€§**

**å…³é”®è¯**: `å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆ` `å¥–åŠ±å¾®è°ƒ` `æ—¶åºä¸€è‡´æ€§` `é¢‘åŸŸåˆ†æž` `è§†é¢‘æ‰©æ•£æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŸºäºŽå¥–åŠ±çš„å¾®è°ƒåœ¨å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆä¸­å¸¸å¯¼è‡´æ—¶åºä¸€è‡´æ€§ä¸è¶³
2. æ–¹æ³•è¦ç‚¹ï¼šå®šä¹‰è§†é¢‘ä¸€è‡´æ€§è·ç¦»ï¼Œåœ¨é¢‘åŸŸåˆ†æžè§†é¢‘å¸§ç‰¹å¾ä»¥æå‡æ—¶åºä¸€è‡´æ€§
3. å®žéªŒæˆ–æ•ˆæžœï¼šå¤šæ•°æ®é›†å®žéªŒæ˜¾ç¤ºï¼Œå¾®è°ƒåŽæ—¶åºä¸€è‡´æ€§æ˜¾è‘—å¢žå¼ºï¼Œå…¶ä»–æ€§èƒ½æœªä¸‹é™

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reward-based fine-tuning of video diffusion models is an effective approach
> to improve the quality of generated videos, as it can fine-tune models without
> requiring real-world video datasets. However, it can sometimes be limited to
> specific performances because conventional reward functions are mainly aimed at
> enhancing the quality across the whole generated video sequence, such as
> aesthetic appeal and overall consistency. Notably, the temporal consistency of
> the generated video often suffers when applying previous approaches to
> image-to-video (I2V) generation tasks. To address this limitation, we propose
> Video Consistency Distance (VCD), a novel metric designed to enhance temporal
> consistency, and fine-tune a model with the reward-based fine-tuning framework.
> To achieve coherent temporal consistency relative to a conditioning image, VCD
> is defined in the frequency space of video frame features to capture frame
> information effectively through frequency-domain analysis. Experimental results
> across multiple I2V datasets demonstrate that fine-tuning a video generation
> model with VCD significantly enhances temporal consistency without degrading
> other performance compared to the previous method.

