---
layout: default
title: Augmenting Moment Retrieval: Zero-Dependency Two-Stage Learning
---

# Augmenting Moment Retrieval: Zero-Dependency Two-Stage Learning

**arXiv**: [2510.19622v1](https://arxiv.org/abs/2510.19622) | [PDF](https://arxiv.org/pdf/2510.19622.pdf)

**ä½œè€…**: Zhengxuan Wei, Jiajin Tang, Sibei Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé›¶ä¾èµ–ä¸¤é˜¶æ®µå­¦ä¹ æ¡†æž¶AMRï¼Œä»¥è§£å†³æ—¶åˆ»æ£€ç´¢ä¸­çš„æ•°æ®ç¨€ç¼ºã€è¾¹ç•Œæ¨¡ç³Šå’Œè¯­ä¹‰åŒºåˆ†ä¸è¶³é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ—¶åˆ»æ£€ç´¢` `ä¸¤é˜¶æ®µå­¦ä¹ ` `æ•°æ®å¢žå¼º` `è’¸é¦è®­ç»ƒ` `è¾¹ç•Œæ£€æµ‹` `è¯­ä¹‰åŒºåˆ†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•é¢ä¸´æ•°æ®ç¨€ç¼ºã€è¾¹ç•Œæ¨¡ç³Šå’Œç»†ç²’åº¦è¯­ä¹‰åŒºåˆ†ä¸è¶³çš„ç“¶é¢ˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒï¼Œå†·å¯åŠ¨é˜¶æ®µå¢žå¼ºè¾¹ç•Œå’Œè¯­ä¹‰æ„ŸçŸ¥ï¼Œè’¸é¦é˜¶æ®µé€šè¿‡åŒæŸ¥è¯¢é›†å®žçŽ°æ³›åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒAMRæ€§èƒ½ä¼˜äºŽå…ˆå‰æœ€å…ˆè¿›æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Existing Moment Retrieval methods face three critical bottlenecks: (1) data
> scarcity forces models into shallow keyword-feature associations; (2) boundary
> ambiguity in transition regions between adjacent events; (3) insufficient
> discrimination of fine-grained semantics (e.g., distinguishing ``kicking" vs.
> ``throwing" a ball). In this paper, we propose a zero-external-dependency
> Augmented Moment Retrieval framework, AMR, designed to overcome local optima
> caused by insufficient data annotations and the lack of robust boundary and
> semantic discrimination capabilities. AMR is built upon two key insights: (1)
> it resolves ambiguous boundary information and semantic confusion in existing
> annotations without additional data (avoiding costly manual labeling), and (2)
> it preserves boundary and semantic discriminative capabilities enhanced by
> training while generalizing to real-world scenarios, significantly improving
> performance. Furthermore, we propose a two-stage training framework with
> cold-start and distillation adaptation. The cold-start stage employs curriculum
> learning on augmented data to build foundational boundary/semantic awareness.
> The distillation stage introduces dual query sets: Original Queries maintain
> DETR-based localization using frozen Base Queries from the cold-start model,
> while Active Queries dynamically adapt to real-data distributions. A
> cross-stage distillation loss enforces consistency between Original and Base
> Queries, preventing knowledge forgetting while enabling real-world
> generalization. Experiments on multiple benchmarks show that AMR achieves
> improved performance over prior state-of-the-art approaches.

