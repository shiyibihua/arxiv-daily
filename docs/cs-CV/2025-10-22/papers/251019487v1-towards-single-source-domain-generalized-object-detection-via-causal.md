---
layout: default
title: Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts
---

# Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts

**arXiv**: [2510.19487v1](https://arxiv.org/abs/2510.19487) | [PDF](https://arxiv.org/pdf/2510.19487.pdf)

**ä½œè€…**: Chen Li, Huiying Xu, Changxin Gao, Zeyu Wang, Yun Liu, Xinzhong Zhu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCauvisæ–¹æ³•ä»¥è§£å†³å•æºåŸŸæ³›åŒ–ç›®æ ‡æ£€æµ‹ä¸­çš„ä¼ªç›¸å…³æ€§é—®é¢˜**

**å…³é”®è¯**: `å•æºåŸŸæ³›åŒ–ç›®æ ‡æ£€æµ‹` `å› æžœè§†è§‰æç¤º` `è·¨æ³¨æ„åŠ›æœºåˆ¶` `ç‰¹å¾è§£è€¦` `é«˜é¢‘ç‰¹å¾æå–` `é²æ£’æ€§å¢žå¼º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ¨¡åž‹åœ¨å•æºåŸŸè®­ç»ƒä¸­æ˜“é™·å…¥ä¼ªç›¸å…³ï¼Œè¿‡åº¦ä¾èµ–é¢œè‰²ç­‰æµ…å±‚ç‰¹å¾è€Œéžè½®å»“ç­‰ä¸å˜è¡¨ç¤ºã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥è·¨æ³¨æ„åŠ›æç¤ºæ¨¡å—å’ŒåŒåˆ†æ”¯é€‚é…å™¨ï¼Œè§£è€¦å› æžœ-ä¼ªç‰¹å¾å¹¶æå–é«˜é¢‘ç‰¹å¾å®žçŽ°åŸŸé€‚åº”ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨SDGODæ•°æ®é›†ä¸Šæ€§èƒ½æå‡15.9-31.4%ï¼Œå¹¶åœ¨å¤æ‚å¹²æ‰°çŽ¯å¢ƒä¸­å±•çŽ°å¼ºé²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Single-source Domain Generalized Object Detection (SDGOD), as a cutting-edge
> research topic in computer vision, aims to enhance model generalization
> capability in unseen target domains through single-source domain training.
> Current mainstream approaches attempt to mitigate domain discrepancies via data
> augmentation techniques. However, due to domain shift and limited
> domain-specific knowledge, models tend to fall into the pitfall of spurious
> correlations. This manifests as the model's over-reliance on simplistic
> classification features (e.g., color) rather than essential domain-invariant
> representations like object contours. To address this critical challenge, we
> propose the Cauvis (Causal Visual Prompts) method. First, we introduce a
> Cross-Attention Prompts module that mitigates bias from spurious features by
> integrating visual prompts with cross-attention. To address the inadequate
> domain knowledge coverage and spurious feature entanglement in visual prompts
> for single-domain generalization, we propose a dual-branch adapter that
> disentangles causal-spurious features while achieving domain adaptation via
> high-frequency feature extraction. Cauvis achieves state-of-the-art performance
> with 15.9-31.4% gains over existing domain generalization methods on SDGOD
> datasets, while exhibiting significant robustness advantages in complex
> interference environments.

