---
layout: default
title: A Matter of Time: Revealing the Structure of Time in Vision-Language Models
---

# A Matter of Time: Revealing the Structure of Time in Vision-Language Models

**arXiv**: [2510.19559v1](https://arxiv.org/abs/2510.19559) | [PDF](https://arxiv.org/pdf/2510.19559.pdf)

**ä½œè€…**: Nidham Tekaya, Manuela Waldner, Matthias Zeppelzauer

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ—¶é—´çº¿è¡¨ç¤ºæ–¹æ³•ä»¥å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹çš„æ—¶é—´æ¨ç†èƒ½åŠ›**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `æ—¶é—´æ„ŸçŸ¥` `åµŒå…¥ç©ºé—´` `æ—¶é—´çº¿è¡¨ç¤º` `åŸºå‡†æ•°æ®é›†` `æ—¶é—´æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç ”ç©¶è§†è§‰è¯­è¨€æ¨¡å‹å¯¹è§†è§‰å†…å®¹çš„æ—¶é—´å®šä½èƒ½åŠ›
2. å‘ç°æ—¶é—´ä¿¡æ¯åœ¨åµŒå…¥ç©ºé—´ä¸­å‘ˆä½ç»´éçº¿æ€§æµå½¢ç»“æ„
3. åŸºäºæ­¤æå‡ºæ—¶é—´çº¿è¡¨ç¤ºæ–¹æ³•ï¼Œåœ¨åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºåŸºçº¿

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large-scale vision-language models (VLMs) such as CLIP have gained popularity
> for their generalizable and expressive multimodal representations. By
> leveraging large-scale training data with diverse textual metadata, VLMs
> acquire open-vocabulary capabilities, solving tasks beyond their training
> scope. This paper investigates the temporal awareness of VLMs, assessing their
> ability to position visual content in time. We introduce TIME10k, a benchmark
> dataset of over 10,000 images with temporal ground truth, and evaluate the
> time-awareness of 37 VLMs by a novel methodology. Our investigation reveals
> that temporal information is structured along a low-dimensional, non-linear
> manifold in the VLM embedding space. Based on this insight, we propose methods
> to derive an explicit ``timeline'' representation from the embedding space.
> These representations model time and its chronological progression and thereby
> facilitate temporal reasoning tasks. Our timeline approaches achieve
> competitive to superior accuracy compared to a prompt-based baseline while
> being computationally efficient. All code and data are available at
> https://tekayanidham.github.io/timeline-page/.

