---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-11-11
---

# cs.CVï¼ˆ2025-11-11ï¼‰

ğŸ“Š å…± **34** ç¯‡è®ºæ–‡
 | ğŸ”— **12** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (18 ğŸ”—4)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (9 ğŸ”—6)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (6 ğŸ”—1)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (18 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251108032v1-perceptual-quality-assessment-of-3d-gaussian-splatting-a-subjective-.html">Perceptual Quality Assessment of 3D Gaussian Splatting: A Subjective Dataset and Prediction Metric</a></td>
  <td>æå‡º3DGS-QAæ•°æ®é›†ä¸æ— å‚è€ƒè´¨é‡è¯„ä¼°æ¨¡å‹ï¼Œè§£å†³3Dé«˜æ–¯æº…å°„æ„ŸçŸ¥è´¨é‡è¯„ä¼°é—®é¢˜</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08032v1" onclick="toggleFavorite(this, '2511.08032v1', 'Perceptual Quality Assessment of 3D Gaussian Splatting: A Subjective Dataset and Prediction Metric')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251108387v1-raptr-radar-based-3d-pose-estimation-using-transformer.html">RAPTR: Radar-based 3D Pose Estimation using Transformer</a></td>
  <td>RAPTRï¼šåˆ©ç”¨Transformerçš„é›·è¾¾3Däººä½“å§¿æ€ä¼°è®¡ï¼Œä½¿ç”¨å¼±ç›‘ç£å­¦ä¹ ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08387v1" onclick="toggleFavorite(this, '2511.08387v1', 'RAPTR: Radar-based 3D Pose Estimation using Transformer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251108036v1-wedepth-efficient-adaptation-of-world-knowledge-for-monocular-depth-.html">WEDepth: Efficient Adaptation of World Knowledge for Monocular Depth Estimation</a></td>
  <td>WEDepthï¼šé«˜æ•ˆåˆ©ç”¨ä¸–ç•ŒçŸ¥è¯†è‡ªé€‚åº”å•ç›®æ·±åº¦ä¼°è®¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08036v1" onclick="toggleFavorite(this, '2511.08036v1', 'WEDepth: Efficient Adaptation of World Knowledge for Monocular Depth Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251107743v1-ultrags-gaussian-splatting-for-ultrasound-novel-view-synthesis.html">UltraGS: Gaussian Splatting for Ultrasound Novel View Synthesis</a></td>
  <td>UltraGSï¼šç”¨äºè¶…å£°æ–°è§†è§’åˆæˆçš„é«˜æ–¯æº…å°„æ–¹æ³•</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.07743v1" onclick="toggleFavorite(this, '2511.07743v1', 'UltraGS: Gaussian Splatting for Ultrasound Novel View Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251108294v2-skelsplat-robust-multi-view-3d-human-pose-estimation-with-differenti.html">SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering</a></td>
  <td>SkelSplatï¼šåŸºäºå¯å¾®é«˜æ–¯æ¸²æŸ“çš„é²æ£’å¤šè§†è§’3Däººä½“å§¿æ€ä¼°è®¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08294v2" onclick="toggleFavorite(this, '2511.08294v2', 'SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251108007v2-eagle-episodic-appearance-and-geometry-aware-memory-for-unified-2d-3.html">EAGLE: Episodic Appearance- and Geometry-aware Memory for Unified 2D-3D Visual Query Localization in Egocentric Vision</a></td>
  <td>EAGLEï¼šåŸºäºæƒ…æ™¯å¤–è§‚å’Œå‡ ä½•æ„ŸçŸ¥çš„è®°å¿†ï¼Œç”¨äºä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†è§‰æŸ¥è¯¢å®šä½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08007v2" onclick="toggleFavorite(this, '2511.08007v2', 'EAGLE: Episodic Appearance- and Geometry-aware Memory for Unified 2D-3D Visual Query Localization in Egocentric Vision')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251108823v1-dt-nvs-diffusion-transformers-for-novel-view-synthesis.html">DT-NVS: Diffusion Transformers for Novel View Synthesis</a></td>
  <td>æå‡ºDT-NVSï¼Œåˆ©ç”¨Transformerçš„3Dæ‰©æ•£æ¨¡å‹å®ç°çœŸå®åœºæ™¯çš„æ–°è§†è§’åˆæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08823v1" onclick="toggleFavorite(this, '2511.08823v1', 'DT-NVS: Diffusion Transformers for Novel View Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251108809v1-adaptive-graph-kolmogorov-arnold-network-for-3d-human-pose-estimatio.html">Adaptive graph Kolmogorov-Arnold network for 3D human pose estimation</a></td>
  <td>æå‡ºPoseKANï¼šä¸€ç§è‡ªé€‚åº”å›¾Kolmogorov-Arnoldç½‘ç»œï¼Œç”¨äº3Däººä½“å§¿æ€ä¼°è®¡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08809v1" onclick="toggleFavorite(this, '2511.08809v1', 'Adaptive graph Kolmogorov-Arnold network for 3D human pose estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251108233v1-accurate-and-efficient-surface-reconstruction-from-point-clouds-via-.html">Accurate and Efficient Surface Reconstruction from Point Clouds via Geometry-Aware Local Adaptation</a></td>
  <td>æå‡ºåŸºäºå‡ ä½•æ„ŸçŸ¥çš„å±€éƒ¨è‡ªé€‚åº”ç‚¹äº‘è¡¨é¢é‡å»ºæ–¹æ³•ï¼Œæå‡ç²¾åº¦ä¸æ•ˆç‡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08233v1" onclick="toggleFavorite(this, '2511.08233v1', 'Accurate and Efficient Surface Reconstruction from Point Clouds via Geometry-Aware Local Adaptation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251107978v2-dance-density-agnostic-and-class-aware-network-for-point-cloud-compl.html">DANCE: Density-agnostic and Class-aware Network for Point Cloud Completion</a></td>
  <td>DANCEï¼šä¸€ç§å¯†åº¦æ— å…³ä¸”ç±»åˆ«æ„ŸçŸ¥çš„ç‚¹äº‘è¡¥å…¨ç½‘ç»œ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.07978v2" onclick="toggleFavorite(this, '2511.07978v2', 'DANCE: Density-agnostic and Class-aware Network for Point Cloud Completion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251107940v1-is-it-truly-necessary-to-process-and-fit-minutes-long-reference-vide.html">Is It Truly Necessary to Process and Fit Minutes-Long Reference Videos for Personalized Talking Face Generation?</a></td>
  <td>æå‡ºISExploreç­–ç•¥ï¼ŒåŠ é€Ÿä¸ªæ€§åŒ–è¯´è¯äººè„¸ç”Ÿæˆï¼Œå‡å°‘å‚è€ƒè§†é¢‘å¤„ç†æ—¶é•¿ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.07940v1" onclick="toggleFavorite(this, '2511.07940v1', 'Is It Truly Necessary to Process and Fit Minutes-Long Reference Videos for Personalized Talking Face Generation?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251108833v1-enhancing-rotation-invariant-3d-learning-with-global-pose-awareness-.html">Enhancing Rotation-Invariant 3D Learning with Global Pose Awareness and Attention Mechanisms</a></td>
  <td>æå‡ºSiPFå’ŒRIAttnConvï¼Œå¢å¼ºæ—‹è½¬ä¸å˜3Då­¦ä¹ çš„å…¨å±€å§¿æ€æ„ŸçŸ¥å’ŒåŒºåˆ†èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08833v1" onclick="toggleFavorite(this, '2511.08833v1', 'Enhancing Rotation-Invariant 3D Learning with Global Pose Awareness and Attention Mechanisms')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251108258v1-top2ground-a-height-aware-dual-conditioning-diffusion-model-for-robu.html">Top2Ground: A Height-Aware Dual Conditioning Diffusion Model for Robust Aerial-to-Ground View Generation</a></td>
  <td>æå‡ºTop2Groundï¼Œä¸€ç§é«˜ç¨‹æ„ŸçŸ¥åŒé‡æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºç¨³å¥çš„èˆªæ‹å›¾åˆ°åœ°è§†å›¾ç”Ÿæˆã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08258v1" onclick="toggleFavorite(this, '2511.08258v1', 'Top2Ground: A Height-Aware Dual Conditioning Diffusion Model for Robust Aerial-to-Ground View Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251108186v1-pixel-level-quality-assessment-for-oriented-object-detection.html">Pixel-level Quality Assessment for Oriented Object Detection</a></td>
  <td>æå‡ºåƒç´ çº§è´¨é‡è¯„ä¼°PQAï¼Œè§£å†³æœ‰å‘ç›®æ ‡æ£€æµ‹ä¸­IoUé¢„æµ‹çš„ç»“æ„è€¦åˆé—®é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08186v1" onclick="toggleFavorite(this, '2511.08186v1', 'Pixel-level Quality Assessment for Oriented Object Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251108178v1-warpgan-warping-guided-3d-gan-inversion-with-style-based-novel-view-.html">WarpGAN: Warping-Guided 3D GAN Inversion with Style-Based Novel View Inpainting</a></td>
  <td>WarpGANï¼šåŸºäºå½¢å˜å¼•å¯¼å’Œé£æ ¼åŒ–è§†è§’è¡¥å…¨çš„3D GANåæ¼”</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08178v1" onclick="toggleFavorite(this, '2511.08178v1', 'WarpGAN: Warping-Guided 3D GAN Inversion with Style-Based Novel View Inpainting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251108173v1-vlmdiff-leveraging-vision-language-models-for-multi-class-anomaly-de.html">VLMDiff: Leveraging Vision-Language Models for Multi-Class Anomaly Detection with Diffusion</a></td>
  <td>VLMDiffï¼šåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹å’Œæ‰©æ•£æ¨¡å‹è¿›è¡Œå¤šç±»åˆ«å¼‚å¸¸æ£€æµ‹</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08173v1" onclick="toggleFavorite(this, '2511.08173v1', 'VLMDiff: Leveraging Vision-Language Models for Multi-Class Anomaly Detection with Diffusion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251107813v1-sparse3dpr-training-free-3d-hierarchical-scene-parsing-and-task-adap.html">Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views</a></td>
  <td>Sparse3DPRï¼šä¸€ç§åŸºäºç¨€ç–RGBè§†å›¾çš„æ— è®­ç»ƒ3Dåœºæ™¯åˆ†å±‚è§£æä¸ä»»åŠ¡è‡ªé€‚åº”å­å›¾æ¨ç†æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.07813v1" onclick="toggleFavorite(this, '2511.07813v1', 'Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251107710v3-cross-modal-fine-grained-alignment-via-granularity-aware-and-region-.html">Cross Modal Fine-Grained Alignment via Granularity-Aware and Region-Uncertain Modeling</a></td>
  <td>æå‡ºç²’åº¦æ„ŸçŸ¥å’ŒåŒºåŸŸä¸ç¡®å®šæ€§å»ºæ¨¡çš„è·¨æ¨¡æ€ç»†ç²’åº¦å¯¹é½æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.07710v3" onclick="toggleFavorite(this, '2511.07710v3', 'Cross Modal Fine-Grained Alignment via Granularity-Aware and Region-Uncertain Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>19</td>
  <td><a href="./papers/251107823v1-cloudmamba-grouped-selective-state-spaces-for-point-cloud-analysis.html">CloudMamba: Grouped Selective State Spaces for Point Cloud Analysis</a></td>
  <td>CloudMambaï¼šé¢å‘ç‚¹äº‘åˆ†æçš„åˆ†ç»„é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼Œæ˜¾è‘—é™ä½è®¡ç®—å¤æ‚åº¦å¹¶æå‡æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.07823v1" onclick="toggleFavorite(this, '2511.07823v1', 'CloudMamba: Grouped Selective State Spaces for Point Cloud Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251107948v1-reidmamba-learning-discriminative-features-with-visual-state-space-m.html">ReIDMamba: Learning Discriminative Features with Visual State Space Model for Person Re-Identification</a></td>
  <td>æå‡ºReIDMambaï¼Œåˆ©ç”¨è§†è§‰çŠ¶æ€ç©ºé—´æ¨¡å‹å­¦ä¹ åˆ¤åˆ«æ€§ç‰¹å¾ï¼Œå®ç°é«˜æ•ˆè¡Œäººé‡è¯†åˆ«</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.07948v1" onclick="toggleFavorite(this, '2511.07948v1', 'ReIDMamba: Learning Discriminative Features with Visual State Space Model for Person Re-Identification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/251108240v1-hierarchical-direction-perception-via-atomic-dot-product-operators-f.html">Hierarchical Direction Perception via Atomic Dot-Product Operators for Rotation-Invariant Point Clouds Learning</a></td>
  <td>æå‡ºDiPVNetï¼Œé€šè¿‡åŸå­ç‚¹ç§¯ç®—å­å®ç°æ—‹è½¬ä¸å˜çš„ç‚¹äº‘åˆ†å±‚æ–¹å‘æ„ŸçŸ¥å­¦ä¹ </td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08240v1" onclick="toggleFavorite(this, '2511.08240v1', 'Hierarchical Direction Perception via Atomic Dot-Product Operators for Rotation-Invariant Point Clouds Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251108155v1-non-aligned-reference-image-quality-assessment-for-novel-view-synthe.html">Non-Aligned Reference Image Quality Assessment for Novel View Synthesis</a></td>
  <td>æå‡ºNAR-IQAæ¡†æ¶ï¼Œç”¨äºè§£å†³æ–°è§†è§’åˆæˆä¸­éå¯¹é½å‚è€ƒå›¾åƒçš„è´¨é‡è¯„ä¼°é—®é¢˜</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08155v1" onclick="toggleFavorite(this, '2511.08155v1', 'Non-Aligned Reference Image Quality Assessment for Novel View Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/251107966v1-multi-modal-assistance-for-unsupervised-domain-adaptation-on-point-c.html">Multi-Modal Assistance for Unsupervised Domain Adaptation on Point Cloud 3D Object Detection</a></td>
  <td>æå‡ºMMAssistï¼Œåˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯è¾…åŠ©LiDARç‚¹äº‘3Dç›®æ ‡æ£€æµ‹çš„æ— ç›‘ç£åŸŸè‡ªé€‚åº”ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.07966v1" onclick="toggleFavorite(this, '2511.07966v1', 'Multi-Modal Assistance for Unsupervised Domain Adaptation on Point Cloud 3D Object Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/251108536v1-3d4d-an-interactive-editable-4d-world-model-via-3d-video-generation.html">3D4D: An Interactive, Editable, 4D World Model via 3D Video Generation</a></td>
  <td>3D4Dï¼šé€šè¿‡3Dè§†é¢‘ç”Ÿæˆå®ç°äº¤äº’å¼ã€å¯ç¼–è¾‘çš„4Dä¸–ç•Œæ¨¡å‹</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08536v1" onclick="toggleFavorite(this, '2511.08536v1', '3D4D: An Interactive, Editable, 4D World Model via 3D Video Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/251108399v1-aligning-by-misaligning-boundary-aware-curriculum-learning-for-multi.html">Aligning by Misaligning: Boundary-aware Curriculum Learning for Multimodal Alignment</a></td>
  <td>æå‡ºè¾¹ç•Œæ„ŸçŸ¥è¯¾ç¨‹å­¦ä¹ æ–¹æ³•BACLï¼Œæå‡å¤šæ¨¡æ€å¯¹é½æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08399v1" onclick="toggleFavorite(this, '2511.08399v1', 'Aligning by Misaligning: Boundary-aware Curriculum Learning for Multimodal Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/251107808v2-di3cl-contrastive-learning-with-dynamic-instances-and-contour-consis.html">DI3CL: Contrastive Learning With Dynamic Instances and Contour Consistency for SAR Land-Cover Classification Foundation Model</a></td>
  <td>æå‡ºDI3CLæ¡†æ¶ï¼Œåˆ©ç”¨åŠ¨æ€å®ä¾‹å’Œè½®å»“ä¸€è‡´æ€§å¯¹æ¯”å­¦ä¹ ï¼Œæ„å»ºSARåœ°ç‰©åˆ†ç±»åŸºç¡€æ¨¡å‹ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.07808v2" onclick="toggleFavorite(this, '2511.07808v2', 'DI3CL: Contrastive Learning With Dynamic Instances and Contour Consistency for SAR Land-Cover Classification Foundation Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/251108480v1-compression-then-matching-an-efficient-pre-training-paradigm-for-mul.html">Compression then Matching: An Efficient Pre-training Paradigm for Multimodal Embedding</a></td>
  <td>æå‡ºCoMaï¼šä¸€ç§é«˜æ•ˆçš„å¤šæ¨¡æ€åµŒå…¥é¢„è®­ç»ƒèŒƒå¼ï¼Œæå‡è§†è§‰-è¯­è¨€æ¨¡å‹æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08480v1" onclick="toggleFavorite(this, '2511.08480v1', 'Compression then Matching: An Efficient Pre-training Paradigm for Multimodal Embedding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (6 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>28</td>
  <td><a href="./papers/251108545v1-repose-nerf-robust-radiance-fields-for-mesh-reconstruction-under-noi.html">RePose-NeRF: Robust Radiance Fields for Mesh Reconstruction under Noisy Camera Poses</a></td>
  <td>RePose-NeRFï¼šæå‡ºä¸€ç§é²æ£’çš„è¾å°„åœºæ–¹æ³•ï¼Œç”¨äºåœ¨å™ªå£°ç›¸æœºä½å§¿ä¸‹è¿›è¡Œç½‘æ ¼é‡å»º</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08545v1" onclick="toggleFavorite(this, '2511.08545v1', 'RePose-NeRF: Robust Radiance Fields for Mesh Reconstruction under Noisy Camera Poses')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/251108031v1-multi-modal-deepfake-detection-and-localization-with-fpn-transformer.html">Multi-modal Deepfake Detection and Localization with FPN-Transformer</a></td>
  <td>æå‡ºåŸºäºFPN-Transformerçš„å¤šæ¨¡æ€æ·±åº¦ä¼ªé€ æ£€æµ‹ä¸å®šä½æ¡†æ¶ï¼Œæå‡è·¨æ¨¡æ€æ³›åŒ–èƒ½åŠ›å’Œæ—¶åºè¾¹ç•Œå›å½’ç²¾åº¦ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08031v1" onclick="toggleFavorite(this, '2511.08031v1', 'Multi-modal Deepfake Detection and Localization with FPN-Transformer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>30</td>
  <td><a href="./papers/251107889v1-generating-sketches-in-a-hierarchical-auto-regressive-process-for-fl.html">Generating Sketches in a Hierarchical Auto-Regressive Process for Flexible Sketch Drawing Manipulation at Stroke-Level</a></td>
  <td>æå‡ºä¸€ç§åˆ†å±‚è‡ªå›å½’è‰å›¾ç”Ÿæˆæ–¹æ³•ï¼Œå®ç°ç¬”ç”»çº§çµæ´»æ“æ§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.07889v1" onclick="toggleFavorite(this, '2511.07889v1', 'Generating Sketches in a Hierarchical Auto-Regressive Process for Flexible Sketch Drawing Manipulation at Stroke-Level')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>31</td>
  <td><a href="./papers/251108365v1-retrospective-motion-correction-in-mri-using-disentangled-embeddings.html">Retrospective motion correction in MRI using disentangled embeddings</a></td>
  <td>æå‡ºåŸºäºè§£è€¦åµŒå…¥çš„MRIè¿åŠ¨ä¼ªå½±çŸ«æ­£æ–¹æ³•ï¼Œæå‡æ¨¡å‹æ³›åŒ–æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08365v1" onclick="toggleFavorite(this, '2511.08365v1', 'Retrospective motion correction in MRI using disentangled embeddings')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>32</td>
  <td><a href="./papers/251108065v1-i2e-real-time-image-to-event-conversion-for-high-performance-spiking.html">I2E: Real-Time Image-to-Event Conversion for High-Performance Spiking Neural Networks</a></td>
  <td>I2Eï¼šç”¨äºé«˜æ€§èƒ½è„‰å†²ç¥ç»ç½‘ç»œçš„å®æ—¶å›¾åƒåˆ°äº‹ä»¶è½¬æ¢æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08065v1" onclick="toggleFavorite(this, '2511.08065v1', 'I2E: Real-Time Image-to-Event Conversion for High-Performance Spiking Neural Networks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>33</td>
  <td><a href="./papers/251108048v1-generalized-scale-object-counting-with-gradual-query-aggregation.html">Generalized-Scale Object Counting with Gradual Query Aggregation</a></td>
  <td>GECO2ï¼šé€šè¿‡æ¸è¿›å¼æŸ¥è¯¢èšåˆå®ç°å¹¿ä¹‰å°ºåº¦ç›®æ ‡è®¡æ•°</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.08048v1" onclick="toggleFavorite(this, '2511.08048v1', 'Generalized-Scale Object Counting with Gradual Query Aggregation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>34</td>
  <td><a href="./papers/251107819v1-human-motion-synthesis-in-3d-scenes-via-unified-scene-semantic-occup.html">Human Motion Synthesis in 3D Scenes via Unified Scene Semantic Occupancy</a></td>
  <td>æå‡ºSSOMotionï¼Œåˆ©ç”¨ç»Ÿä¸€åœºæ™¯è¯­ä¹‰å æ®è¡¨ç¤ºè¿›è¡Œ3Dåœºæ™¯ä¸­çš„äººä½“è¿åŠ¨åˆæˆã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2511.07819v1" onclick="toggleFavorite(this, '2511.07819v1', 'Human Motion Synthesis in 3D Scenes via Unified Scene Semantic Occupancy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)