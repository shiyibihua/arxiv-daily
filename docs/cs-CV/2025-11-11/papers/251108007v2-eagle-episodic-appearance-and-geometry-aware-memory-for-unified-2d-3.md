---
layout: default
title: EAGLE: Episodic Appearance- and Geometry-aware Memory for Unified 2D-3D Visual Query Localization in Egocentric Vision
---

# EAGLE: Episodic Appearance- and Geometry-aware Memory for Unified 2D-3D Visual Query Localization in Egocentric Vision

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.08007" target="_blank" class="toolbar-btn">arXiv: 2511.08007v2</a>
    <a href="https://arxiv.org/pdf/2511.08007.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.08007v2" 
            onclick="toggleFavorite(this, '2511.08007v2', 'EAGLE: Episodic Appearance- and Geometry-aware Memory for Unified 2D-3D Visual Query Localization in Egocentric Vision')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yifei Cao, Yu Liu, Guolong Wang, Zhu Liu, Kai Wang, Xianjie Zhang, Jizhe Yu, Xun Tu

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-11 (Êõ¥Êñ∞: 2025-11-12)

**Â§áÊ≥®**: 13 Pages, accepted by AAAI-2026

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**EAGLEÔºöÂü∫‰∫éÊÉÖÊôØÂ§ñËßÇÂíåÂá†‰ΩïÊÑüÁü•ÁöÑËÆ∞ÂøÜÔºåÁî®‰∫é‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜËßâÊü•ËØ¢ÂÆö‰Ωç**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâÊü•ËØ¢ÂÆö‰Ωç` `‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉËßÜËßâ` `ÊÉÖÊôØËÆ∞ÂøÜ` `Â§ñËßÇÊÑüÁü•` `Âá†‰ΩïÊÑüÁü•` `2D-3DÁªü‰∏Ä` `ÂÖÉÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜËßâÊü•ËØ¢ÂÆö‰ΩçÈù¢‰∏¥Áõ∏Êú∫ËøêÂä®„ÄÅËßÜËßíÂèòÂåñÂíåÂ§ñËßÇÂ∑ÆÂºÇÂ∏¶Êù•ÁöÑÊåëÊàòÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂ∫îÂØπ„ÄÇ
2. EAGLEÊ°ÜÊû∂ÈÄöËøáÊÉÖÊôØÂ§ñËßÇÂíåÂá†‰ΩïÊÑüÁü•ÁöÑËÆ∞ÂøÜÔºåÂçèÂêåÊï¥ÂêàÂ§ñËßÇÊÑüÁü•ÂàÜÂâ≤ÂíåÂá†‰ΩïÊÑüÁü•Ë∑üË∏™ÔºåÂÆûÁé∞È≤ÅÊ£íÁöÑËßÜËßâÊü•ËØ¢ÂÆö‰Ωç„ÄÇ
3. EAGLEÂú®Ego4D-VQÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜËßâÊü•ËØ¢ÂÆö‰ΩçÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜËßâÊü•ËØ¢ÂÆö‰ΩçÂØπ‰∫éÂÖ∑Ë∫´Êô∫ËÉΩÂíåVR/ARËá≥ÂÖ≥ÈáçË¶ÅÔºå‰ΩÜÁî±‰∫éÁõ∏Êú∫ËøêÂä®„ÄÅËßÜËßíÂèòÂåñÂíåÂ§ñËßÇÂ∑ÆÂºÇËÄå‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊàòÊÄß„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜEAGLEÔºå‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊ°ÜÊû∂ÔºåÂÆÉÂà©Áî®ÊÉÖÊôØÂ§ñËßÇÂíåÂá†‰ΩïÊÑüÁü•ÁöÑËÆ∞ÂøÜÊù•ÂÆûÁé∞‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜËßâ‰∏≠Áªü‰∏ÄÁöÑ2D-3DËßÜËßâÊü•ËØ¢ÂÆö‰Ωç„ÄÇÂèóÂà∞È∏üÁ±ªËÆ∞ÂøÜÂ∑©Âõ∫ÁöÑÂêØÂèëÔºåEAGLEÂçèÂêåÂú∞Êï¥Âêà‰∫ÜÁî±Â§ñËßÇÊÑüÁü•ÂÖÉÂ≠¶‰π†ËÆ∞ÂøÜÔºàAMMÔºâÂºïÂØºÁöÑÂàÜÂâ≤Ôºå‰ª•ÂèäÁî±Âá†‰ΩïÊÑüÁü•ÂÆö‰ΩçËÆ∞ÂøÜÔºàGLMÔºâÈ©±Âä®ÁöÑË∑üË∏™„ÄÇËøôÁßçËÆ∞ÂøÜÂ∑©Âõ∫Êú∫Âà∂ÔºåÈÄöËøáÁªìÊûÑÂåñÁöÑÂ§ñËßÇÂíåÂá†‰ΩïËÆ∞ÂøÜÂ∫ìÔºåÂ≠òÂÇ®È´òÁΩÆ‰ø°Â∫¶ÁöÑÊ£ÄÁ¥¢Ê†∑Êú¨ÔºåÊúâÊïàÂú∞ÊîØÊåÅÁõÆÊ†áÂ§ñËßÇÂèòÂåñÁöÑÈïøÊúüÂíåÁü≠ÊúüÂª∫Ê®°„ÄÇËøô‰ΩøÂæóËÉΩÂ§üÁ≤æÁ°ÆÂú∞ÊèèÁªòËΩÆÂªìÔºåÂπ∂ÂÖ∑ÊúâÂº∫Â§ßÁöÑÁ©∫Èó¥Ëæ®Âà´ËÉΩÂäõÔºå‰ªéËÄåÊòæËëóÊèêÈ´òÊ£ÄÁ¥¢Á≤æÂ∫¶„ÄÇÊ≠§Â§ñÔºåÈÄöËøáÂ∞ÜVQL-2DËæìÂá∫‰∏éËßÜËßâÂá†‰ΩïÊé•Âú∞ÁöÑTransformerÔºàVGGTÔºâÈõÜÊàêÔºåÊàë‰ª¨ÂÆûÁé∞‰∫Ü2DÂíå3D‰ªªÂä°ÁöÑÊúâÊïàÁªü‰∏ÄÔºå‰ªéËÄåËÉΩÂ§üÂø´ÈÄüÂáÜÁ°ÆÂú∞ÂèçÊäïÂΩ±Âà∞3DÁ©∫Èó¥„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Ego4D-VQÂü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰ª•Ëá™Êàë‰∏∫‰∏≠ÂøÉÁöÑËßÜËßâÊü•ËØ¢ÂÆö‰ΩçÈóÆÈ¢òÔºåÂç≥Âú®Á¨¨‰∏Ä‰∫∫Áß∞ËßÜËßíËßÜÈ¢ë‰∏≠ÔºåÊ†πÊçÆÁªôÂÆöÁöÑÊü•ËØ¢ÂõæÂÉèÔºåÂÆö‰ΩçÁõÆÊ†áÁâ©‰ΩìÂú®ËßÜÈ¢ë‰∏≠ÁöÑ‰ΩçÁΩÆ„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÁõ∏Êú∫ËøêÂä®„ÄÅËßÜËßíÂèòÂåñÂíåÂ§ñËßÇÂ∑ÆÂºÇÊó∂Ë°®Áé∞‰∏ç‰Ω≥ÔºåÂØºËá¥ÂÆö‰ΩçÁ≤æÂ∫¶‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ÊÉÖÊôØËÆ∞ÂøÜÔºåÊ®°ÊãüÈ∏üÁ±ªËÆ∞ÂøÜÂ∑©Âõ∫ÁöÑËøáÁ®ãÔºåÂ∞ÜÂ§ñËßÇ‰ø°ÊÅØÂíåÂá†‰Ωï‰ø°ÊÅØÂàÜÂà´Â≠òÂÇ®Âú®‰∏çÂêåÁöÑËÆ∞ÂøÜÊ®°Âùó‰∏≠ÔºåÂπ∂ÂçèÂêåÂà©Áî®Ëøô‰∫õ‰ø°ÊÅØËøõË°åËßÜËßâÊü•ËØ¢ÂÆö‰Ωç„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÂèØ‰ª•ÊúâÊïàÂú∞Â§ÑÁêÜÁõÆÊ†áÂ§ñËßÇÁöÑÂèòÂåñÔºåÂπ∂ÊèêÈ´òÂÆö‰ΩçÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöEAGLEÊ°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÁöÑËÆ∞ÂøÜÊ®°ÂùóÔºöÂ§ñËßÇÊÑüÁü•ÂÖÉÂ≠¶‰π†ËÆ∞ÂøÜÔºàAMMÔºâÂíåÂá†‰ΩïÊÑüÁü•ÂÆö‰ΩçËÆ∞ÂøÜÔºàGLMÔºâ„ÄÇAMMË¥üË¥£Â≠òÂÇ®ÁõÆÊ†áÁöÑÂ§ñËßÇ‰ø°ÊÅØÔºåÂπ∂Áî®‰∫éÊåáÂØºÂõæÂÉèÂàÜÂâ≤ÔºõGLMË¥üË¥£Â≠òÂÇ®ÁõÆÊ†áÁöÑÂá†‰Ωï‰ø°ÊÅØÔºåÂπ∂Áî®‰∫éÈ©±Âä®ÁõÆÊ†áË∑üË∏™„ÄÇÊ°ÜÊû∂È¶ñÂÖàÂà©Áî®AMMËøõË°åÂõæÂÉèÂàÜÂâ≤ÔºåÁÑ∂ÂêéÂà©Áî®GLMËøõË°åÁõÆÊ†áË∑üË∏™ÔºåÊúÄÂêéÂ∞Ü2DÂÆö‰ΩçÁªìÊûú‰∏éËßÜËßâÂá†‰ΩïÊé•Âú∞ÁöÑTransformerÔºàVGGTÔºâÈõÜÊàêÔºåÂÆûÁé∞2D-3DÁöÑÁªü‰∏Ä„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜÊÉÖÊôØÂ§ñËßÇÂíåÂá†‰ΩïÊÑüÁü•ÁöÑËÆ∞ÂøÜÊú∫Âà∂ÔºåÂ∞ÜÂ§ñËßÇ‰ø°ÊÅØÂíåÂá†‰Ωï‰ø°ÊÅØÂàÜÂà´Â≠òÂÇ®Âú®‰∏çÂêåÁöÑËÆ∞ÂøÜÊ®°Âùó‰∏≠ÔºåÂπ∂ÂçèÂêåÂà©Áî®Ëøô‰∫õ‰ø°ÊÅØËøõË°åËßÜËßâÊü•ËØ¢ÂÆö‰Ωç„ÄÇËøôÁßçÊú∫Âà∂ÂèØ‰ª•ÊúâÊïàÂú∞Â§ÑÁêÜÁõÆÊ†áÂ§ñËßÇÁöÑÂèòÂåñÔºåÂπ∂ÊèêÈ´òÂÆö‰ΩçÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÊèêÂá∫‰∫ÜÂ∞Ü2DÂÆö‰ΩçÁªìÊûú‰∏éËßÜËßâÂá†‰ΩïÊé•Âú∞ÁöÑTransformerÔºàVGGTÔºâÈõÜÊàêÁöÑÊñπÊ≥ïÔºåÂÆûÁé∞‰∫Ü2D-3DÁöÑÁªü‰∏Ä„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAMMÈááÁî®ÂÖÉÂ≠¶‰π†ÁöÑÊñπÂºèËøõË°åËÆ≠ÁªÉÔºåÂèØ‰ª•Âø´ÈÄüÈÄÇÂ∫îÊñ∞ÁöÑÁõÆÊ†áÂ§ñËßÇ„ÄÇGLMÈááÁî®Âü∫‰∫éÂÖ≥ÈîÆÂ∏ßÁöÑË∑üË∏™ÊñπÊ≥ïÔºåÂèØ‰ª•ÊúâÊïàÂú∞Â§ÑÁêÜÁõ∏Êú∫ËøêÂä®ÂíåËßÜËßíÂèòÂåñ„ÄÇVGGTÂà©Áî®ËßÜËßâÂíåÂá†‰Ωï‰ø°ÊÅØÔºåÂ∞Ü2DÂÆö‰ΩçÁªìÊûúÂèçÊäïÂΩ±Âà∞3DÁ©∫Èó¥„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÂàÜÂâ≤ÊçüÂ§±„ÄÅË∑üË∏™ÊçüÂ§±Âíå3DÂÆö‰ΩçÊçüÂ§±„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

EAGLEÂú®Ego4D-VQÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåEAGLEÂú®ÊâÄÊúâÊåáÊ†á‰∏äÈÉΩ‰ºò‰∫éÁé∞ÊúâÁöÑÊñπÊ≥ïÔºå‰æãÂ¶ÇÔºåÂú®R@1ÊåáÊ†á‰∏äÔºåEAGLEÁöÑÊÄßËÉΩÊØîÁ¨¨‰∫åÂ•ΩÁöÑÊñπÊ≥ïÊèêÈ´ò‰∫Ü5%‰ª•‰∏ä„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEAGLEÊ°ÜÊû∂ËÉΩÂ§üÊúâÊïàÂú∞Â§ÑÁêÜÁõÆÊ†áÂ§ñËßÇÁöÑÂèòÂåñÔºåÂπ∂ÊèêÈ´òÂÆö‰ΩçÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÂÖ∑Ë∫´Êô∫ËÉΩ„ÄÅVR/ARÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Êú∫Âô®‰∫∫ÂØºËà™‰∏≠ÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïÂÆö‰ΩçÁõÆÊ†áÁâ©‰ΩìÔºå‰ªéËÄåÂÆûÁé∞Ëá™‰∏ªÂØºËà™„ÄÇÂú®VR/ARÂ∫îÁî®‰∏≠ÔºåÁî®Êà∑ÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïÂú®ËôöÊãüÁéØÂ¢É‰∏≠ÂÆö‰ΩçÁõÆÊ†áÁâ©‰ΩìÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Ëá™ÁÑ∂ÁöÑ‰∫§‰∫í„ÄÇËØ•Á†îÁ©∂ËøòÊúâÂä©‰∫éÊèêÂçáÊô∫ËÉΩÁõëÊéß„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüüÁöÑÊÄßËÉΩ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Egocentric visual query localization is vital for embodied AI and VR/AR, yet remains challenging due to camera motion, viewpoint changes, and appearance variations. We present EAGLE, a novel framework that leverages episodic appearance- and geometry-aware memory to achieve unified 2D-3D visual query localization in egocentric vision. Inspired by avian memory consolidation, EAGLE synergistically integrates segmentation guided by an appearance-aware meta-learning memory (AMM), with tracking driven by a geometry-aware localization memory (GLM). This memory consolidation mechanism, through structured appearance and geometry memory banks, stores high-confidence retrieval samples, effectively supporting both long- and short-term modeling of target appearance variations. This enables precise contour delineation with robust spatial discrimination, leading to significantly improved retrieval accuracy. Furthermore, by integrating the VQL-2D output with a visual geometry grounded Transformer (VGGT), we achieve a efficient unification of 2D and 3D tasks, enabling rapid and accurate back-projection into 3D space. Our method achieves state-ofthe-art performance on the Ego4D-VQ benchmark.

