---
layout: default
title: X-IONet: Cross-Platform Inertial Odometry Network with Dual-Stage Attention
---

# X-IONet: Cross-Platform Inertial Odometry Network with Dual-Stage Attention

**arXiv**: [2511.08277v1](https://arxiv.org/abs/2511.08277) | [PDF](https://arxiv.org/pdf/2511.08277.pdf)

**ä½œè€…**: Dehan Shen, Changhao Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºX-IONetä»¥è§£å†³è·¨å¹³å°æƒ¯æ€§é‡Œç¨‹è®¡åœ¨è¡Œäººå’Œå››è¶³æœºå™¨äººä¸Šçš„æ€§èƒ½é€€åŒ–é—®é¢˜**

**å…³é”®è¯**: `æƒ¯æ€§é‡Œç¨‹è®¡` `è·¨å¹³å°å­¦ä¹ ` `åŒé˜¶æ®µæ³¨æ„åŠ›` `ä¸“å®¶ç½‘ç»œ` `çŠ¶æ€ä¼°è®¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŸºäºŽå­¦ä¹ çš„æƒ¯æ€§é‡Œç¨‹è®¡åœ¨å››è¶³æœºå™¨äººä¸Šæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œå› è¿åŠ¨æ¨¡å¼å·®å¼‚å¤§
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åŸºäºŽè§„åˆ™çš„ä¸“å®¶é€‰æ‹©æ¨¡å—å’ŒåŒé˜¶æ®µæ³¨æ„åŠ›ç½‘ç»œï¼Œç»“åˆEKFè¿›è¡ŒçŠ¶æ€ä¼°è®¡
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å…¬å¼€å’Œè‡ªæ”¶é›†æ•°æ®é›†ä¸Šï¼ŒATEå’ŒRTEåœ¨è¡Œäººå’Œå››è¶³æœºå™¨äººæ•°æ®ä¸Šå‡æ˜¾è‘—é™ä½Ž

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Learning-based inertial odometry has achieved remarkable progress in pedestrian navigation. However, extending these methods to quadruped robots remains challenging due to their distinct and highly dynamic motion patterns. Models that perform well on pedestrian data often experience severe degradation when deployed on legged platforms. To tackle this challenge, we introduce X-IONet, a cross-platform inertial odometry framework that operates solely using a single Inertial Measurement Unit (IMU). X-IONet incorporates a rule-based expert selection module to classify motion platforms and route IMU sequences to platform-specific expert networks. The displacement prediction network features a dual-stage attention architecture that jointly models long-range temporal dependencies and inter-axis correlations, enabling accurate motion representation. It outputs both displacement and associated uncertainty, which are further fused through an Extended Kalman Filter (EKF) for robust state estimation. Extensive experiments on public pedestrian datasets and a self-collected quadruped robot dataset demonstrate that X-IONet achieves state-of-the-art performance, reducing Absolute Trajectory Error (ATE) by 14.3% and Relative Trajectory Error (RTE) by 11.4% on pedestrian data, and by 52.8% and 41.3% on quadruped robot data. These results highlight the effectiveness of X-IONet in advancing accurate and robust inertial navigation across both human and legged robot platforms.

