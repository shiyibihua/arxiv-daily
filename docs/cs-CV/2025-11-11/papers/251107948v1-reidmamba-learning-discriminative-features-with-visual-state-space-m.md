---
layout: default
title: ReIDMamba: Learning Discriminative Features with Visual State Space Model for Person Re-Identification
---

# ReIDMamba: Learning Discriminative Features with Visual State Space Model for Person Re-Identification

**arXiv**: [2511.07948v1](https://arxiv.org/abs/2511.07948) | [PDF](https://arxiv.org/pdf/2511.07948.pdf)

**ä½œè€…**: Hongyang Gu, Qisong Yang, Lei Pu, Siming Han, Yao Ding

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11

**å¤‡æ³¨**: 11 pages, 8 figures. Accepted to IEEE Transactions on Multimedia (TMM). Accepted Manuscript version uploaded

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/GuHY777/ReIDMamba)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºReIDMambaï¼Œåˆ©ç”¨è§†è§‰çŠ¶æ€ç©ºé—´æ¨¡åž‹å­¦ä¹ åˆ¤åˆ«æ€§ç‰¹å¾ï¼Œå®žçŽ°é«˜æ•ˆè¡Œäººé‡è¯†åˆ«**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è¡Œäººé‡è¯†åˆ«` `Mamba` `çŠ¶æ€ç©ºé—´æ¨¡åž‹` `å¤šç²’åº¦ç‰¹å¾` `Tripletæ­£åˆ™åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŸºäºŽTransformerçš„ReIDæ–¹æ³•é¢ä¸´ç€è®¡ç®—å’Œå†…å­˜éœ€æ±‚éšè¾“å…¥åºåˆ—é•¿åº¦å‘ˆäºŒæ¬¡æ–¹å¢žé•¿çš„å¯æ‰©å±•æ€§é—®é¢˜ã€‚
2. ReIDMambaé‡‡ç”¨çº¯Mambaæž¶æž„ï¼Œé€šè¿‡å¤šç²’åº¦ç‰¹å¾æå–å’ŒæŽ’åºæ„ŸçŸ¥çš„Tripletæ­£åˆ™åŒ–æ¥å­¦ä¹ é²æ£’çš„åˆ¤åˆ«æ€§ç‰¹å¾ã€‚
3. ReIDMambaåœ¨äº”ä¸ªè¡ŒäººReIDåŸºå‡†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œä¸”å‚æ•°é‡ä»…ä¸ºTransReIDçš„ä¸‰åˆ†ä¹‹ä¸€ï¼Œå¹¶é™ä½Žäº†GPUå†…å­˜å ç”¨ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æå–é²æ£’çš„åˆ¤åˆ«æ€§ç‰¹å¾æ˜¯è¡Œäººé‡è¯†åˆ«ï¼ˆReIDï¼‰ä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚è™½ç„¶åŸºäºŽTransformerçš„æ–¹æ³•æˆåŠŸåœ°è§£å†³äº†å·ç§¯ç¥žç»ç½‘ç»œï¼ˆCNNï¼‰çš„ä¸€äº›å±€é™æ€§ï¼Œä¾‹å¦‚å…¶å±€éƒ¨å¤„ç†ç‰¹æ€§ä»¥åŠå·ç§¯å’Œä¸‹é‡‡æ ·æ“ä½œå¯¼è‡´çš„ä¿¡æ¯ä¸¢å¤±ï¼Œä½†ç”±äºŽå†…å­˜å’Œè®¡ç®—éœ€æ±‚éšè¾“å…¥åºåˆ—é•¿åº¦å‘ˆäºŒæ¬¡æ–¹å¢žé•¿ï¼Œå®ƒä»¬ä»ç„¶é¢ä¸´å¯æ‰©å±•æ€§é—®é¢˜ã€‚ä¸ºäº†å…‹æœè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªçº¯ç²¹åŸºäºŽMambaçš„è¡ŒäººReIDæ¡†æž¶ï¼Œåä¸ºReIDMambaã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªåŸºäºŽMambaçš„å¼ºå¤§åŸºçº¿ï¼Œé€šè¿‡å¼•å…¥å¤šä¸ªç±»åˆ«tokenæ¥æœ‰æ•ˆåœ°åˆ©ç”¨ç»†ç²’åº¦çš„åˆ¤åˆ«æ€§å…¨å±€ç‰¹å¾ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¢žå¼ºMambaä¸­é²æ£’ç‰¹å¾çš„å­¦ä¹ ï¼Œæˆ‘ä»¬ç²¾å¿ƒè®¾è®¡äº†ä¸¤ç§æ–°é¢–çš„æŠ€æœ¯ã€‚é¦–å…ˆï¼Œå¤šç²’åº¦ç‰¹å¾æå–å™¨ï¼ˆMGFEï¼‰æ¨¡å—é‡‡ç”¨å¤šåˆ†æ”¯æž¶æž„å’Œç±»åˆ«tokenèžåˆï¼Œæœ‰æ•ˆåœ°å½¢æˆå¤šç²’åº¦ç‰¹å¾ï¼Œå¢žå¼ºäº†åˆ¤åˆ«èƒ½åŠ›å’Œç»†ç²’åº¦è¦†ç›–ã€‚å…¶æ¬¡ï¼Œå¼•å…¥äº†æŽ’åºæ„ŸçŸ¥çš„Tripletæ­£åˆ™åŒ–ï¼ˆRATRï¼‰æ¥å‡å°‘æ¥è‡ªå¤šä¸ªåˆ†æ”¯çš„ç‰¹å¾å†—ä½™ï¼Œé€šè¿‡ç»“åˆç±»å†…å’Œç±»é—´å¤šæ ·æ€§çº¦æŸæ¥å¢žå¼ºå¤šç²’åº¦ç‰¹å¾çš„å¤šæ ·æ€§ï¼Œä»Žè€Œç¡®ä¿è¡Œäººç‰¹å¾çš„é²æ£’æ€§ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå°†çº¯Mambaé©±åŠ¨çš„æ–¹æ³•é›†æˆåˆ°ReIDç ”ç©¶ä¸­çš„å·¥ä½œã€‚æˆ‘ä»¬æå‡ºçš„ReIDMambaæ¨¡åž‹ä»…æœ‰TransReIDä¸‰åˆ†ä¹‹ä¸€çš„å‚æ•°ï¼ŒåŒæ—¶å…·æœ‰æ›´ä½Žçš„GPUå†…å­˜ä½¿ç”¨é‡å’Œæ›´å¿«çš„æŽ¨ç†åžåé‡ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒReIDMambaå…·æœ‰å“è¶Šå’Œæœ‰å¸Œæœ›çš„æ€§èƒ½ï¼Œåœ¨äº”ä¸ªè¡ŒäººReIDåŸºå‡†ä¸Šå®žçŽ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè¡Œäººé‡è¯†åˆ«æ—¨åœ¨è·¨ä¸åŒçš„æ‘„åƒå¤´è§†è§’è¯†åˆ«åŒä¸€è¡Œäººã€‚çŽ°æœ‰åŸºäºŽTransformerçš„æ–¹æ³•è™½ç„¶åœ¨å»ºæ¨¡å…¨å±€å…³ç³»æ–¹é¢è¡¨çŽ°å‡ºè‰²ï¼Œä½†è®¡ç®—å¤æ‚åº¦é«˜ï¼Œéš¾ä»¥æ‰©å±•åˆ°é«˜åˆ†è¾¨çŽ‡å›¾åƒã€‚CNNæ–¹æ³•åˆ™å—é™äºŽå±€éƒ¨æ„Ÿå—é‡Žï¼Œéš¾ä»¥æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶é™ä½Žè®¡ç®—æˆæœ¬ï¼Œæ˜¯è¡Œäººé‡è¯†åˆ«é¢†åŸŸçš„ä¸€ä¸ªé‡è¦æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šReIDMambaçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Mambaæž¶æž„çš„çº¿æ€§å¤æ‚åº¦æ¥å…‹æœTransformerçš„è®¡ç®—ç“¶é¢ˆï¼ŒåŒæ—¶è®¾è®¡å¤šç²’åº¦ç‰¹å¾æå–æ¨¡å—å’ŒæŽ’åºæ„ŸçŸ¥çš„Tripletæ­£åˆ™åŒ–æ¥å¢žå¼ºç‰¹å¾çš„åˆ¤åˆ«æ€§å’Œé²æ£’æ€§ã€‚é€šè¿‡Mambaçš„å…¨å±€å»ºæ¨¡èƒ½åŠ›å’Œç²¾å¿ƒè®¾è®¡çš„ç‰¹å¾æå–ç­–ç•¥ï¼ŒReIDMambaèƒ½å¤Ÿåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½Žè®¡ç®—æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šReIDMambaçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ï¼š1) è¾“å…¥å›¾åƒç»è¿‡ä¸€ä¸ªåˆå§‹çš„ç‰¹å¾æå–å±‚ï¼›2) æå–çš„ç‰¹å¾è¾“å…¥åˆ°å¤šä¸ªMambaå—ä¸­è¿›è¡Œå…¨å±€ç‰¹å¾å»ºæ¨¡ï¼›3) å¤šç²’åº¦ç‰¹å¾æå–å™¨ï¼ˆMGFEï¼‰æ¨¡å—ä»ŽMambaå—çš„è¾“å‡ºä¸­æå–å¤šç²’åº¦ç‰¹å¾ï¼›4) æŽ’åºæ„ŸçŸ¥çš„Tripletæ­£åˆ™åŒ–ï¼ˆRATRï¼‰ç”¨äºŽä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºï¼›5) æœ€åŽï¼Œä½¿ç”¨åˆ†ç±»å™¨è¿›è¡Œèº«ä»½é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šReIDMambaçš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) é¦–æ¬¡å°†çº¯Mambaæž¶æž„å¼•å…¥è¡Œäººé‡è¯†åˆ«é¢†åŸŸï¼Œåˆ©ç”¨å…¶çº¿æ€§å¤æ‚åº¦ä¼˜åŠ¿ï¼›2) æå‡ºäº†å¤šç²’åº¦ç‰¹å¾æå–å™¨ï¼ˆMGFEï¼‰ï¼Œé€šè¿‡å¤šåˆ†æ”¯ç»“æž„å’Œç±»åˆ«tokenèžåˆï¼Œå¢žå¼ºç‰¹å¾çš„åˆ¤åˆ«èƒ½åŠ›å’Œç»†ç²’åº¦è¦†ç›–ï¼›3) å¼•å…¥äº†æŽ’åºæ„ŸçŸ¥çš„Tripletæ­£åˆ™åŒ–ï¼ˆRATRï¼‰ï¼Œå‡å°‘ç‰¹å¾å†—ä½™ï¼Œå¢žå¼ºç‰¹å¾å¤šæ ·æ€§ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒReIDMambaåœ¨è®¡ç®—æ•ˆçŽ‡å’Œç‰¹å¾è¡¨è¾¾èƒ½åŠ›ä¸Šéƒ½å…·æœ‰ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šMGFEæ¨¡å—é‡‡ç”¨å¤šåˆ†æ”¯ç»“æž„ï¼Œæ¯ä¸ªåˆ†æ”¯æå–ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚ç±»åˆ«tokenè¢«ç”¨äºŽèžåˆä¸åŒåˆ†æ”¯çš„ç‰¹å¾ï¼Œä»Žè€Œå½¢æˆå¤šç²’åº¦è¡¨ç¤ºã€‚RATRæŸå¤±å‡½æ•°ç»“åˆäº†ç±»å†…å’Œç±»é—´å¤šæ ·æ€§çº¦æŸï¼Œé¼“åŠ±æ¨¡åž‹å­¦ä¹ æ›´å…·åŒºåˆ†æ€§çš„ç‰¹å¾ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°è®¾è®¡å’Œç½‘ç»œç»“æž„å‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

ReIDMambaåœ¨äº”ä¸ªè¡ŒäººReIDåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨Market-1501æ•°æ®é›†ä¸Šï¼ŒRank-1å‡†ç¡®çŽ‡è¾¾åˆ°äº†æ–°çš„é«˜åº¦ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒReIDMambaçš„å‚æ•°é‡ä»…ä¸ºTransReIDçš„ä¸‰åˆ†ä¹‹ä¸€ï¼ŒåŒæ—¶é™ä½Žäº†GPUå†…å­˜å ç”¨ï¼Œå¹¶æé«˜äº†æŽ¨ç†é€Ÿåº¦ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒReIDMambaåœ¨æ€§èƒ½å’Œæ•ˆçŽ‡æ–¹é¢éƒ½å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

ReIDMambaåœ¨æ™ºèƒ½å®‰é˜²ã€æ™ºæ…§åŸŽå¸‚ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºŽåœ¨å¤§åž‹å•†åœºã€æœºåœºç­‰å…¬å…±åœºæ‰€è¿›è¡Œè¡Œäººè¿½è¸ªå’Œèº«ä»½è¯†åˆ«ï¼Œæé«˜å®‰å…¨æ€§å’Œç®¡ç†æ•ˆçŽ‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºŽæ™ºèƒ½é›¶å”®ã€äººæµåˆ†æžç­‰é¢†åŸŸï¼Œä¸ºå•†ä¸šå†³ç­–æä¾›æ•°æ®æ”¯æŒã€‚æœªæ¥ï¼ŒReIDMambaæœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–è§†è§‰è¯†åˆ«ä»»åŠ¡ä¸­ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Extracting robust discriminative features is a critical challenge in person re-identification (ReID). While Transformer-based methods have successfully addressed some limitations of convolutional neural networks (CNNs), such as their local processing nature and information loss resulting from convolution and downsampling operations, they still face the scalability issue due to the quadratic increase in memory and computational requirements with the length of the input sequence. To overcome this, we propose a pure Mamba-based person ReID framework named ReIDMamba. Specifically, we have designed a Mamba-based strong baseline that effectively leverages fine-grained, discriminative global features by introducing multiple class tokens. To further enhance robust features learning within Mamba, we have carefully designed two novel techniques. First, the multi-granularity feature extractor (MGFE) module, designed with a multi-branch architecture and class token fusion, effectively forms multi-granularity features, enhancing both discrimination ability and fine-grained coverage. Second, the ranking-aware triplet regularization (RATR) is introduced to reduce redundancy in features from multiple branches, enhancing the diversity of multi-granularity features by incorporating both intra-class and inter-class diversity constraints, thus ensuring the robustness of person features. To our knowledge, this is the pioneering work that integrates a purely Mamba-driven approach into ReID research. Our proposed ReIDMamba model boasts only one-third the parameters of TransReID, along with lower GPU memory usage and faster inference throughput. Experimental results demonstrate ReIDMamba's superior and promising performance, achieving state-of-the-art performance on five person ReID benchmarks. Code is available at https://github.com/GuHY777/ReIDMamba.

