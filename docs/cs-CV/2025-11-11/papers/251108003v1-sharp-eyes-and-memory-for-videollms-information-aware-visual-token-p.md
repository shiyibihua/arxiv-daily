---
layout: default
title: Sharp Eyes and Memory for VideoLLMs: Information-Aware Visual Token Pruning for Efficient and Reliable VideoLLM Reasoning
---

# Sharp Eyes and Memory for VideoLLMs: Information-Aware Visual Token Pruning for Efficient and Reliable VideoLLM Reasoning

**arXiv**: [2511.08003v1](https://arxiv.org/abs/2511.08003) | [PDF](https://arxiv.org/pdf/2511.08003.pdf)

**ä½œè€…**: Jialong Qin, Xin Zou, Di Lu, Yibo Yan, Xuming Hu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSharpVä»¥è§£å†³VideoLLMsä¸­è§†è§‰ä»¤ç‰Œå†—ä½™å¯¼è‡´çš„æ•ˆçŽ‡é—®é¢˜**

**å…³é”®è¯**: `è§†é¢‘å¤§è¯­è¨€æ¨¡åž‹` `è§†è§‰ä»¤ç‰Œå‰ªæž` `KVç¼“å­˜ä¼˜åŒ–` `è‡ªé€‚åº”åŽ‹ç¼©` `ä¿¡æ¯ç“¶é¢ˆ` `ç¡¬ä»¶åŠ é€Ÿå…¼å®¹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šVideoLLMså› å¤„ç†å†—ä½™è§†è§‰ä»¤ç‰Œå¯¼è‡´è®¡ç®—å¤æ‚åº¦å’ŒKVç¼“å­˜å¢žé•¿
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽæ—¶ç©ºä¿¡æ¯åŠ¨æ€è°ƒæ•´å‰ªæžæ¯”ä¾‹ï¼Œå¹¶è‡ªæ ¡å‡†å‰ªæžé€€åŒ–ç‰¹å¾
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨çŽ°ä¼˜è¶Šï¼Œæ— éœ€æ³¨æ„åŠ›åˆ†æ•°å³å¯å…¼å®¹ç¡¬ä»¶åŠ é€Ÿ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Current Video Large Language Models (VideoLLMs) suffer from quadratic computational complexity and key-value cache scaling, due to their reliance on processing excessive redundant visual tokens. To address this problem, we propose SharpV, a minimalist and efficient method for adaptive pruning of visual tokens and KV cache. Different from most uniform compression approaches, SharpV dynamically adjusts pruning ratios based on spatial-temporal information. Remarkably, this adaptive mechanism occasionally achieves performance gains over dense models, offering a novel paradigm for adaptive pruning. During the KV cache pruning stage, based on observations of visual information degradation, SharpV prunes degraded visual features via a self-calibration manner, guided by similarity to original visual features. In this way, SharpV achieves hierarchical cache pruning from the perspective of information bottleneck, offering a new insight into VideoLLMs' information flow. Experiments on multiple public benchmarks demonstrate the superiority of SharpV. Moreover, to the best of our knowledge, SharpV is notably the first two-stage pruning framework that operates without requiring access to exposed attention scores, ensuring full compatibility with hardware acceleration techniques like Flash Attention.

