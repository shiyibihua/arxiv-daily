---
layout: default
title: UI2Code$^\text{N}$: A Visual Language Model for Test-Time Scalable Interactive UI-to-Code Generation
---

# UI2Code$^\text{N}$: A Visual Language Model for Test-Time Scalable Interactive UI-to-Code Generation

**arXiv**: [2511.08195v1](https://arxiv.org/abs/2511.08195) | [PDF](https://arxiv.org/pdf/2511.08195.pdf)

**ä½œè€…**: Zhen Yang, Wenyi Hong, Mingde Xu, Xinyue Fan, Weihan Wang, Jiele Cheng, Xiaotao Gu, Jie Tang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUI2Code^Nè§†è§‰è¯­è¨€æ¨¡åž‹ï¼Œé€šè¿‡äº¤äº’å¼UIåˆ°ä»£ç ç”Ÿæˆè§£å†³å¤šæ¨¡æ€ç¼–ç ä¸è¶³é—®é¢˜ã€‚**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡åž‹` `UIåˆ°ä»£ç ç”Ÿæˆ` `å¤šæ¨¡æ€ç¼–ç ` `äº¤äº’å¼ç”Ÿæˆ` `æµ‹è¯•æ—¶æ‰©å±•` `å¼ºåŒ–å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šUIç¼–ç¨‹å¤æ‚ï¼ŒçŽ°æœ‰è§†è§‰è¯­è¨€æ¨¡åž‹å¤šæ¨¡æ€ç¼–ç èƒ½åŠ›å¼±ä¸”ç¼ºä¹è¿­ä»£åé¦ˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åˆ†é˜¶æ®µé¢„è®­ç»ƒã€å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ï¼Œç»Ÿä¸€UIç”Ÿæˆã€ç¼–è¾‘å’Œä¼˜åŒ–èƒ½åŠ›ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨UIåˆ°ä»£ç å’Œä¼˜åŒ–åŸºå‡†ä¸Šè¾¾åˆ°å¼€æºæ¨¡åž‹æœ€ä¼˜ï¼Œæ€§èƒ½æŽ¥è¿‘é—­æºé¢†å…ˆæ¨¡åž‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> User interface (UI) programming is a core yet highly complex part of modern software development. Recent advances in visual language models (VLMs) highlight the potential of automatic UI coding, but current approaches face two key limitations: multimodal coding capabilities remain underdeveloped, and single-turn paradigms make little use of iterative visual feedback. We address these challenges with an interactive UI-to-code paradigm that better reflects real-world workflows and raises the upper bound of achievable performance. Under this paradigm, we present UI2Code$^\text{N}$, a visual language model trained through staged pretraining, fine-tuning, and reinforcement learning to achieve foundational improvements in multimodal coding. The model unifies three key capabilities: UI-to-code generation, UI editing, and UI polishing. We further explore test-time scaling for interactive generation, enabling systematic use of multi-turn feedback. Experiments on UI-to-code and UI polishing benchmarks show that UI2Code$^\text{N}$ establishes a new state of the art among open-source models and achieves performance comparable to leading closed-source models such as Claude-4-Sonnet and GPT-5. Our code and models are available at https://github.com/zai-org/UI2Code_N.

