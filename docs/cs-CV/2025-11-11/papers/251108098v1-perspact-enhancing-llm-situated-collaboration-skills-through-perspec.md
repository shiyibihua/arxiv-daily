---
layout: default
title: PerspAct: Enhancing LLM Situated Collaboration Skills through Perspective Taking and Active Vision
---

# PerspAct: Enhancing LLM Situated Collaboration Skills through Perspective Taking and Active Vision

**arXiv**: [2511.08098v1](https://arxiv.org/abs/2511.08098) | [PDF](https://arxiv.org/pdf/2511.08098.pdf)

**ä½œè€…**: Sabrina Patania, Luca Annese, Anita Pellegrini, Silvia Serino, Anna Lambiase, Luca Pallonetto, Silvia Rossi, Simone Colombani, Tom Foulsham, Azzurra Ruggeri, Dimitri Ognibene

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPerspActæ–¹æ³•ï¼Œé€šè¿‡è§†è§’é‡‡æ‹©å’Œä¸»åŠ¨è§†è§‰å¢žå¼ºLLMåœ¨åä½œç³»ç»Ÿä¸­çš„èƒ½åŠ›**

**å…³é”®è¯**: `è§†è§’é‡‡æ‹©` `ä¸»åŠ¨è§†è§‰` `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `ReActæ¡†æž¶` `LLMåä½œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šLLMåœ¨å¤šæ™ºèƒ½ä½“äº¤äº’ä¸­ç¼ºä¹è§†è§’é‡‡æ‹©èƒ½åŠ›ï¼Œå¯¼è‡´æŽ¨ç†ä¸»è§‚è§†è§’å›°éš¾
2. æ–¹æ³•è¦ç‚¹ï¼šæ‰©å±•ReActæ¡†æž¶ï¼Œå¼•å…¥ä¸»åŠ¨è§†è§‰æŽ¢ç´¢å’Œå¤šæ ·åŒ–è§†è§’æç¤ºç­–ç•¥
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä¸ƒç§å¤æ‚åœºæ™¯ä¸­ï¼Œæ˜¾è‘—æå‡æ¨¡åž‹è§£é‡Šå‡†ç¡®æ€§å’Œåä½œæœ‰æ•ˆæ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in Large Language Models (LLMs) and multimodal foundation models have significantly broadened their application in robotics and collaborative systems. However, effective multi-agent interaction necessitates robust perspective-taking capabilities, enabling models to interpret both physical and epistemic viewpoints. Current training paradigms often neglect these interactive contexts, resulting in challenges when models must reason about the subjectivity of individual perspectives or navigate environments with multiple observers. This study evaluates whether explicitly incorporating diverse points of view using the ReAct framework, an approach that integrates reasoning and acting, can enhance an LLM's ability to understand and ground the demands of other agents. We extend the classic Director task by introducing active visual exploration across a suite of seven scenarios of increasing perspective-taking complexity. These scenarios are designed to challenge the agent's capacity to resolve referential ambiguity based on visual access and interaction, under varying state representations and prompting strategies, including ReAct-style reasoning. Our results demonstrate that explicit perspective cues, combined with active exploration strategies, significantly improve the model's interpretative accuracy and collaborative effectiveness. These findings highlight the potential of integrating active perception with perspective-taking mechanisms in advancing LLMs' application in robotics and multi-agent systems, setting a foundation for future research into adaptive and context-aware AI systems.

