---
layout: default
title: High-Quality Proposal Encoding and Cascade Denoising for Imaginary Supervised Object Detection
---

# High-Quality Proposal Encoding and Cascade Denoising for Imaginary Supervised Object Detection

**arXiv**: [2511.08018v1](https://arxiv.org/abs/2511.08018) | [PDF](https://arxiv.org/pdf/2511.08018.pdf)

**ä½œè€…**: Zhiyuan Chen, Yuelin Guo, Zitong Huang, Haoyu He, Renhao Lu, Weizhe Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCascade HQP-DETRä»¥è§£å†³è™šæž„ç›‘ç£ç›®æ ‡æ£€æµ‹ä¸­çš„æ•°æ®è´¨é‡ã€æ”¶æ•›æ…¢å’Œå™ªå£°è¿‡æ‹Ÿåˆé—®é¢˜**

**å…³é”®è¯**: `è™šæž„ç›‘ç£ç›®æ ‡æ£€æµ‹` `æŸ¥è¯¢åˆå§‹åŒ–` `çº§è”åŽ»å™ª` `åˆæˆæ•°æ®ç”Ÿæˆ` `DETRæž¶æž„`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåˆæˆæ•°æ®è´¨é‡å·®ã€DETRæ”¶æ•›æ…¢ã€ä¼ªæ ‡ç­¾å™ªå£°å¯¼è‡´è¿‡æ‹Ÿåˆ
2. æ–¹æ³•è¦ç‚¹ï¼šé«˜è´¨é‡æ•°æ®ç”Ÿæˆã€åŸºäºŽSAMçš„æŸ¥è¯¢åˆå§‹åŒ–ã€çº§è”åŽ»å™ªè®­ç»ƒ
3. å®žéªŒæˆ–æ•ˆæžœï¼šä»…è®­ç»ƒ12epochsï¼Œåœ¨PASCAL VOCä¸Šè¾¾åˆ°61.04% mAP@0.5

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Object detection models demand large-scale annotated datasets, which are costly and labor-intensive to create. This motivated Imaginary Supervised Object Detection (ISOD), where models train on synthetic images and test on real images. However, existing methods face three limitations: (1) synthetic datasets suffer from simplistic prompts, poor image quality, and weak supervision; (2) DETR-based detectors, due to their random query initialization, struggle with slow convergence and overfitting to synthetic patterns, hindering real-world generalization; (3) uniform denoising pressure promotes model overfitting to pseudo-label noise. We propose Cascade HQP-DETR to address these limitations. First, we introduce a high-quality data pipeline using LLaMA-3, Flux, and Grounding DINO to generate the FluxVOC and FluxCOCO datasets, advancing ISOD from weak to full supervision. Second, our High-Quality Proposal guided query encoding initializes object queries with image-specific priors from SAM-generated proposals and RoI-pooled features, accelerating convergence while steering the model to learn transferable features instead of overfitting to synthetic patterns. Third, our cascade denoising algorithm dynamically adjusts training weights through progressively increasing IoU thresholds across decoder layers, guiding the model to learn robust boundaries from reliable visual cues rather than overfitting to noisy labels. Trained for just 12 epochs solely on FluxVOC, Cascade HQP-DETR achieves a SOTA 61.04\% mAP@0.5 on PASCAL VOC 2007, outperforming strong baselines, with its competitive real-data performance confirming the architecture's universal applicability.

