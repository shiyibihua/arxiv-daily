---
layout: default
title: Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views
---

# Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.07813" target="_blank" class="toolbar-btn">arXiv: 2511.07813v1</a>
    <a href="https://arxiv.org/pdf/2511.07813.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.07813v1" 
            onclick="toggleFavorite(this, '2511.07813v1', 'Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Haida Feng, Hao Wei, Zewen Xu, Haolin Wang, Chade Li, Yihong Wu

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-11

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Sparse3DPRÔºö‰∏ÄÁßçÂü∫‰∫éÁ®ÄÁñèRGBËßÜÂõæÁöÑÊó†ËÆ≠ÁªÉ3DÂú∫ÊôØÂàÜÂ±ÇËß£Êûê‰∏é‰ªªÂä°Ëá™ÈÄÇÂ∫îÂ≠êÂõæÊé®ÁêÜÊ°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `3DÂú∫ÊôØÁêÜËß£` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Êó†ËÆ≠ÁªÉÂ≠¶‰π†` `Âú∫ÊôØÂõæ` `Âπ≥Èù¢ÁªìÊûÑ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑ3DÂú∫ÊôØÁêÜËß£ÊñπÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÊó†ËÆ≠ÁªÉÊñπÊ≥ïÔºåÂú®ÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÊñπÈù¢Â≠òÂú®ÊåëÊàòÔºåÈôêÂà∂‰∫ÜÂÆûÈôÖÈÉ®ÁΩ≤„ÄÇ
2. Sparse3DPRÈÄöËøáÂºïÂÖ•ÂàÜÂ±ÇÂπ≥Èù¢Â¢ûÂº∫Âú∫ÊôØÂõæÂíå‰ªªÂä°Ëá™ÈÄÇÂ∫îÂ≠êÂõæÊèêÂèñÔºåÊèêÂçá‰∫ÜÊé®ÁêÜÈìæÁöÑÊ∏ÖÊô∞Â∫¶ÔºåÂπ∂ÂáèÂ∞ë‰∫Ü‰∏ä‰∏ãÊñáÂô™Â£∞„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåSparse3DPRÂú®Space3D-Bench‰∏äÊòæËëóÊèêÂçá‰∫ÜÊÄßËÉΩÂíåÊïàÁéáÔºåÂπ∂Âú®ScanQA‰∏äÂèñÂæó‰∫Ü‰∏éËÆ≠ÁªÉÊñπÊ≥ïÁõ∏ÂΩìÁöÑÁªìÊûú„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫Sparse3DPRÔºå‰∏ÄÁßçÊñ∞È¢ñÁöÑÊó†ËÆ≠ÁªÉÊ°ÜÊû∂ÔºåÁî®‰∫éÂºÄÊîæÂºèÂú∫ÊôØÁêÜËß£„ÄÇËØ•Ê°ÜÊû∂Âà©Áî®È¢ÑËÆ≠ÁªÉÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ªÖÈúÄÁ®ÄÁñèËßÜËßíÁöÑRGBËæìÂÖ•„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂàÜÂ±ÇÂπ≥Èù¢Â¢ûÂº∫Âú∫ÊôØÂõæÔºåÊîØÊåÅÂºÄÊîæËØçÊ±áË°®ÔºåÂπ∂ÈááÁî®‰∏ªË¶ÅÂπ≥Èù¢ÁªìÊûÑ‰Ωú‰∏∫Á©∫Èó¥ÈîöÁÇπÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Ê∏ÖÊô∞ÁöÑÊé®ÁêÜÈìæÂíåÊõ¥ÂèØÈù†ÁöÑÈ´òÁ∫ßÊé®Êñ≠„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏ÄÁßç‰ªªÂä°Ëá™ÈÄÇÂ∫îÂ≠êÂõæÊèêÂèñÊñπÊ≥ïÔºå‰ª•Âä®ÊÄÅËøáÊª§‰∏éÊü•ËØ¢Êó†ÂÖ≥ÁöÑ‰ø°ÊÅØÔºåÂáèÂ∞ë‰∏ä‰∏ãÊñáÂô™Â£∞ÔºåÊèêÈ´ò3DÂú∫ÊôØÊé®ÁêÜÁöÑÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSparse3DPRÂÖ∑Êúâ‰ºòË∂äÊÄßÔºåÂú®Space3D-Bench‰∏äÔºåEM@1ÊåáÊ†áÊèêÂçá‰∫Ü28.7%ÔºåÈÄüÂ∫¶ÊèêÂçá‰∫Ü78.2%Ôºà‰∏éConceptGraphsÁõ∏ÊØîÔºâ„ÄÇÊ≠§Â§ñÔºåSparse3DPRÂú®ScanQA‰∏äËé∑Âæó‰∫Ü‰∏éÂü∫‰∫éËÆ≠ÁªÉÁöÑÊñπÊ≥ïÁõ∏ÂΩìÁöÑÊÄßËÉΩÔºåÂπ∂ÈÄöËøáÈ¢ùÂ§ñÁöÑÁúüÂÆû‰∏ñÁïåÂÆûÈ™åËØÅÂÆû‰∫ÜÂÖ∂È≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éLLMÁöÑÊó†ËÆ≠ÁªÉ3DÂú∫ÊôØÁêÜËß£ÊñπÊ≥ïÔºåËôΩÁÑ∂ÂÖ∑ÊúâÁÅµÊ¥ªÊÄßÂíåÊ≥õÂåñÊÄßÔºå‰ΩÜÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Èù¢‰∏¥ÂáÜÁ°ÆÁéá‰ΩéÂíåÊïàÁéá‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇËøô‰∫õÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂú∞‰ªéÁ®ÄÁñèÁöÑRGBËßÜÂõæ‰∏≠ÊèêÂèñÂÖ≥ÈîÆ‰ø°ÊÅØÔºåÂπ∂ËøõË°åÂèØÈù†ÁöÑÊé®ÁêÜ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSparse3DPRÁöÑÊ†∏ÂøÉÂú®‰∫éÂà©Áî®È¢ÑËÆ≠ÁªÉLLMÁöÑÂº∫Â§ßÊé®ÁêÜËÉΩÂäõÔºåÂπ∂ÁªìÂêàÁ≤æÂøÉËÆæËÆ°ÁöÑÂú∫ÊôØÂõæË°®Á§∫Âíå‰ªªÂä°Ëá™ÈÄÇÂ∫îÂ≠êÂõæÊèêÂèñÁ≠ñÁï•„ÄÇÈÄöËøáÂ∞ÜÂú∫ÊôØË°®Á§∫‰∏∫ÂàÜÂ±Ç„ÄÅÂπ≥Èù¢Â¢ûÂº∫ÁöÑÂõæÁªìÊûÑÔºåÂπ∂Âä®ÊÄÅËøáÊª§Êó†ÂÖ≥‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òÊé®ÁêÜÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSparse3DPRÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) **Âú∫ÊôØÂõæÊûÑÂª∫**Ôºö‰ªéÁ®ÄÁñèRGBËßÜÂõæ‰∏≠ÊèêÂèñÂπ≥Èù¢ÁªìÊûÑÔºåÂπ∂ÊûÑÂª∫ÂàÜÂ±ÇÂú∫ÊôØÂõæÔºåÂÖ∂‰∏≠Âπ≥Èù¢‰Ωú‰∏∫Á©∫Èó¥ÈîöÁÇπ„ÄÇ2) **ÂºÄÊîæËØçÊ±áË°®ÊîØÊåÅ**ÔºöÂà©Áî®LLMÊîØÊåÅÂºÄÊîæËØçÊ±áË°®ÔºåÂÖÅËÆ∏ÂØπÂú∫ÊôØ‰∏≠ÁöÑÂØπË±°ÂíåÂÖ≥Á≥ªËøõË°åÁÅµÊ¥ªÁöÑÊèèËø∞„ÄÇ3) **‰ªªÂä°Ëá™ÈÄÇÂ∫îÂ≠êÂõæÊèêÂèñ**ÔºöÊ†πÊçÆÁî®Êà∑Êü•ËØ¢ÔºåÂä®ÊÄÅÊèêÂèñ‰∏é‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÂ≠êÂõæÔºåÂáèÂ∞ë‰∏ä‰∏ãÊñáÂô™Â£∞„ÄÇ4) **LLMÊé®ÁêÜ**ÔºöÂà©Áî®È¢ÑËÆ≠ÁªÉLLMÂØπÊèêÂèñÁöÑÂ≠êÂõæËøõË°åÊé®ÁêÜÔºåÁîüÊàêÊúÄÁªàÁöÑÂú∫ÊôØÁêÜËß£ÁªìÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSparse3DPRÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÂàÜÂ±ÇÂπ≥Èù¢Â¢ûÂº∫Âú∫ÊôØÂõæÂíå‰ªªÂä°Ëá™ÈÄÇÂ∫îÂ≠êÂõæÊèêÂèñÊñπÊ≥ï„ÄÇ‰º†ÁªüÁöÑÂú∫ÊôØÂõæË°®Á§∫ÂèØËÉΩÁº∫‰πèÊòéÁ°ÆÁöÑÁ©∫Èó¥ÁªìÊûÑÔºåËÄåSparse3DPRÈÄöËøáÂºïÂÖ•Âπ≥Èù¢ÁªìÊûÑ‰Ωú‰∏∫Á©∫Èó¥ÈîöÁÇπÔºåÂ¢ûÂº∫‰∫ÜÊé®ÁêÜÈìæÁöÑÊ∏ÖÊô∞Â∫¶„ÄÇÊ≠§Â§ñÔºå‰ªªÂä°Ëá™ÈÄÇÂ∫îÂ≠êÂõæÊèêÂèñËÉΩÂ§üÊúâÊïàÂú∞ËøáÊª§Êó†ÂÖ≥‰ø°ÊÅØÔºåÊèêÈ´òÊé®ÁêÜÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Âú∫ÊôØÂõæÊûÑÂª∫Èò∂ÊÆµÔºåÈúÄË¶ÅÁ≤æÁ°ÆÂú∞ÊèêÂèñÂú∫ÊôØ‰∏≠ÁöÑÂπ≥Èù¢ÁªìÊûÑÔºåÂπ∂Â∞ÜÂÖ∂‰Ωú‰∏∫ËäÇÁÇπÊ∑ªÂä†Âà∞Âú∫ÊôØÂõæ‰∏≠„ÄÇÂ≠êÂõæÊèêÂèñÁ≠ñÁï•ÈúÄË¶ÅÊ†πÊçÆ‰∏çÂêåÁöÑ‰ªªÂä°ËøõË°åË∞ÉÊï¥Ôºå‰ª•Á°Æ‰øùÊèêÂèñÁöÑÂ≠êÂõæÂåÖÂê´Ë∂≥Â§üÁöÑ‰ø°ÊÅØÔºåÂêåÊó∂ÈÅøÂÖçÂºïÂÖ•ËøáÂ§öÁöÑÂô™Â£∞„ÄÇLLMÁöÑÈÄâÊã©ÂíåpromptËÆæËÆ°‰πü‰ºöÂΩ±ÂìçÊúÄÁªàÁöÑÊé®ÁêÜÁªìÊûú„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Sparse3DPRÂú®Space3D-BenchÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåEM@1ÊåáÊ†áÊèêÈ´ò‰∫Ü28.7%ÔºåÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü78.2%Ôºà‰∏éConceptGraphsÁõ∏ÊØîÔºâ„ÄÇÊ≠§Â§ñÔºåSparse3DPRÂú®ScanQAÊï∞ÊçÆÈõÜ‰∏äËé∑Âæó‰∫Ü‰∏éÂü∫‰∫éËÆ≠ÁªÉÁöÑÊñπÊ≥ïÁõ∏ÂΩìÁöÑÊÄßËÉΩÔºåÂêåÊó∂Âú®ÁúüÂÆû‰∏ñÁïåÂÆûÈ™å‰∏≠Ë°®Áé∞Âá∫ËâØÂ•ΩÁöÑÈ≤ÅÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåSparse3DPRÊòØ‰∏ÄÁßçÈ´òÊïà‰∏îÂáÜÁ°ÆÁöÑÊó†ËÆ≠ÁªÉ3DÂú∫ÊôØÁêÜËß£Ê°ÜÊû∂„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Sparse3DPRÂú®Êú∫Âô®‰∫∫ÂØºËà™„ÄÅÊô∫ËÉΩÂÆ∂Â±Ö„ÄÅËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫ÁêÜËß£Âë®Âõ¥ÁéØÂ¢ÉÔºåËøõË°åËá™‰∏ªÂØºËà™ÔºõÂèØ‰ª•Áî®‰∫éÊô∫ËÉΩÂÆ∂Â±ÖÂú∫ÊôØ‰∏≠ÁöÑÁâ©‰ΩìËØÜÂà´Âíå‰∫§‰∫íÔºõËøòÂèØ‰ª•‰∏∫VR/ARÂ∫îÁî®Êèê‰æõÊõ¥ÈÄºÁúüÁöÑ3DÂú∫ÊôØÁêÜËß£ËÉΩÂäõ„ÄÇËØ•Á†îÁ©∂ÊúâÊúõÊé®Âä®3DÂú∫ÊôØÁêÜËß£ÊäÄÊúØÁöÑÂèëÂ±ïÔºåÂπ∂‰øÉËøõÂÖ∂Âú®ÂêÑ‰∏™È¢ÜÂüüÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recently, large language models (LLMs) have been explored widely for 3D scene understanding. Among them, training-free approaches are gaining attention for their flexibility and generalization over training-based methods. However, they typically struggle with accuracy and efficiency in practical deployment. To address the problems, we propose Sparse3DPR, a novel training-free framework for open-ended scene understanding, which leverages the reasoning capabilities of pre-trained LLMs and requires only sparse-view RGB inputs. Specifically, we introduce a hierarchical plane-enhanced scene graph that supports open vocabulary and adopts dominant planar structures as spatial anchors, which enables clearer reasoning chains and more reliable high-level inferences. Furthermore, we design a task-adaptive subgraph extraction method to filter query-irrelevant information dynamically, reducing contextual noise and improving 3D scene reasoning efficiency and accuracy. Experimental results demonstrate the superiority of Sparse3DPR, which achieves a 28.7% EM@1 improvement and a 78.2% speedup compared with ConceptGraphs on the Space3D-Bench. Moreover, Sparse3DPR obtains comparable performance to training-based methods on ScanQA, with additional real-world experiments confirming its robustness and generalization capability.

