---
layout: default
title: Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views
---

# Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views

**arXiv**: [2511.07813v1](https://arxiv.org/abs/2511.07813) | [PDF](https://arxiv.org/pdf/2511.07813.pdf)

**ä½œè€…**: Haida Feng, Hao Wei, Zewen Xu, Haolin Wang, Chade Li, Yihong Wu

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Sparse3DPRï¼šä¸€ç§åŸºäºŽç¨€ç–RGBè§†å›¾çš„æ— è®­ç»ƒ3Dåœºæ™¯åˆ†å±‚è§£æžä¸Žä»»åŠ¡è‡ªé€‚åº”å­å›¾æŽ¨ç†æ¡†æž¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dåœºæ™¯ç†è§£` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `æ— è®­ç»ƒå­¦ä¹ ` `åœºæ™¯å›¾` `å¹³é¢ç»“æž„`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŸºäºŽå¤§åž‹è¯­è¨€æ¨¡åž‹çš„3Dåœºæ™¯ç†è§£æ–¹æ³•ï¼Œå°¤å…¶æ˜¯æ— è®­ç»ƒæ–¹æ³•ï¼Œåœ¨å‡†ç¡®æ€§å’Œæ•ˆçŽ‡æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å®žé™…éƒ¨ç½²ã€‚
2. Sparse3DPRé€šè¿‡å¼•å…¥åˆ†å±‚å¹³é¢å¢žå¼ºåœºæ™¯å›¾å’Œä»»åŠ¡è‡ªé€‚åº”å­å›¾æå–ï¼Œæå‡äº†æŽ¨ç†é“¾çš„æ¸…æ™°åº¦ï¼Œå¹¶å‡å°‘äº†ä¸Šä¸‹æ–‡å™ªå£°ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒSparse3DPRåœ¨Space3D-Benchä¸Šæ˜¾è‘—æå‡äº†æ€§èƒ½å’Œæ•ˆçŽ‡ï¼Œå¹¶åœ¨ScanQAä¸Šå–å¾—äº†ä¸Žè®­ç»ƒæ–¹æ³•ç›¸å½“çš„ç»“æžœã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºSparse3DPRï¼Œä¸€ç§æ–°é¢–çš„æ— è®­ç»ƒæ¡†æž¶ï¼Œç”¨äºŽå¼€æ”¾å¼åœºæ™¯ç†è§£ã€‚è¯¥æ¡†æž¶åˆ©ç”¨é¢„è®­ç»ƒå¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰çš„æŽ¨ç†èƒ½åŠ›ï¼Œä»…éœ€ç¨€ç–è§†è§’çš„RGBè¾“å…¥ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åˆ†å±‚å¹³é¢å¢žå¼ºåœºæ™¯å›¾ï¼Œæ”¯æŒå¼€æ”¾è¯æ±‡è¡¨ï¼Œå¹¶é‡‡ç”¨ä¸»è¦å¹³é¢ç»“æž„ä½œä¸ºç©ºé—´é”šç‚¹ï¼Œä»Žè€Œå®žçŽ°æ›´æ¸…æ™°çš„æŽ¨ç†é“¾å’Œæ›´å¯é çš„é«˜çº§æŽ¨æ–­ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ä»»åŠ¡è‡ªé€‚åº”å­å›¾æå–æ–¹æ³•ï¼Œä»¥åŠ¨æ€è¿‡æ»¤ä¸ŽæŸ¥è¯¢æ— å…³çš„ä¿¡æ¯ï¼Œå‡å°‘ä¸Šä¸‹æ–‡å™ªå£°ï¼Œæé«˜3Dåœºæ™¯æŽ¨ç†çš„æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒSparse3DPRå…·æœ‰ä¼˜è¶Šæ€§ï¼Œåœ¨Space3D-Benchä¸Šï¼ŒEM@1æŒ‡æ ‡æå‡äº†28.7%ï¼Œé€Ÿåº¦æå‡äº†78.2%ï¼ˆä¸ŽConceptGraphsç›¸æ¯”ï¼‰ã€‚æ­¤å¤–ï¼ŒSparse3DPRåœ¨ScanQAä¸ŠèŽ·å¾—äº†ä¸ŽåŸºäºŽè®­ç»ƒçš„æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ï¼Œå¹¶é€šè¿‡é¢å¤–çš„çœŸå®žä¸–ç•Œå®žéªŒè¯å®žäº†å…¶é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰åŸºäºŽLLMçš„æ— è®­ç»ƒ3Dåœºæ™¯ç†è§£æ–¹æ³•ï¼Œè™½ç„¶å…·æœ‰çµæ´»æ€§å’Œæ³›åŒ–æ€§ï¼Œä½†åœ¨å®žé™…åº”ç”¨ä¸­é¢ä¸´å‡†ç¡®çŽ‡ä½Žå’Œæ•ˆçŽ‡ä¸è¶³çš„é—®é¢˜ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåœ°ä»Žç¨€ç–çš„RGBè§†å›¾ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¹¶è¿›è¡Œå¯é çš„æŽ¨ç†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSparse3DPRçš„æ ¸å¿ƒåœ¨äºŽåˆ©ç”¨é¢„è®­ç»ƒLLMçš„å¼ºå¤§æŽ¨ç†èƒ½åŠ›ï¼Œå¹¶ç»“åˆç²¾å¿ƒè®¾è®¡çš„åœºæ™¯å›¾è¡¨ç¤ºå’Œä»»åŠ¡è‡ªé€‚åº”å­å›¾æå–ç­–ç•¥ã€‚é€šè¿‡å°†åœºæ™¯è¡¨ç¤ºä¸ºåˆ†å±‚ã€å¹³é¢å¢žå¼ºçš„å›¾ç»“æž„ï¼Œå¹¶åŠ¨æ€è¿‡æ»¤æ— å…³ä¿¡æ¯ï¼Œä»Žè€Œæé«˜æŽ¨ç†çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šSparse3DPRæ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **åœºæ™¯å›¾æž„å»º**ï¼šä»Žç¨€ç–RGBè§†å›¾ä¸­æå–å¹³é¢ç»“æž„ï¼Œå¹¶æž„å»ºåˆ†å±‚åœºæ™¯å›¾ï¼Œå…¶ä¸­å¹³é¢ä½œä¸ºç©ºé—´é”šç‚¹ã€‚2) **å¼€æ”¾è¯æ±‡è¡¨æ”¯æŒ**ï¼šåˆ©ç”¨LLMæ”¯æŒå¼€æ”¾è¯æ±‡è¡¨ï¼Œå…è®¸å¯¹åœºæ™¯ä¸­çš„å¯¹è±¡å’Œå…³ç³»è¿›è¡Œçµæ´»çš„æè¿°ã€‚3) **ä»»åŠ¡è‡ªé€‚åº”å­å›¾æå–**ï¼šæ ¹æ®ç”¨æˆ·æŸ¥è¯¢ï¼ŒåŠ¨æ€æå–ä¸Žä»»åŠ¡ç›¸å…³çš„å­å›¾ï¼Œå‡å°‘ä¸Šä¸‹æ–‡å™ªå£°ã€‚4) **LLMæŽ¨ç†**ï¼šåˆ©ç”¨é¢„è®­ç»ƒLLMå¯¹æå–çš„å­å›¾è¿›è¡ŒæŽ¨ç†ï¼Œç”Ÿæˆæœ€ç»ˆçš„åœºæ™¯ç†è§£ç»“æžœã€‚

**å…³é”®åˆ›æ–°**ï¼šSparse3DPRçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶åˆ†å±‚å¹³é¢å¢žå¼ºåœºæ™¯å›¾å’Œä»»åŠ¡è‡ªé€‚åº”å­å›¾æå–æ–¹æ³•ã€‚ä¼ ç»Ÿçš„åœºæ™¯å›¾è¡¨ç¤ºå¯èƒ½ç¼ºä¹æ˜Žç¡®çš„ç©ºé—´ç»“æž„ï¼Œè€ŒSparse3DPRé€šè¿‡å¼•å…¥å¹³é¢ç»“æž„ä½œä¸ºç©ºé—´é”šç‚¹ï¼Œå¢žå¼ºäº†æŽ¨ç†é“¾çš„æ¸…æ™°åº¦ã€‚æ­¤å¤–ï¼Œä»»åŠ¡è‡ªé€‚åº”å­å›¾æå–èƒ½å¤Ÿæœ‰æ•ˆåœ°è¿‡æ»¤æ— å…³ä¿¡æ¯ï¼Œæé«˜æŽ¨ç†æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åœºæ™¯å›¾æž„å»ºé˜¶æ®µï¼Œéœ€è¦ç²¾ç¡®åœ°æå–åœºæ™¯ä¸­çš„å¹³é¢ç»“æž„ï¼Œå¹¶å°†å…¶ä½œä¸ºèŠ‚ç‚¹æ·»åŠ åˆ°åœºæ™¯å›¾ä¸­ã€‚å­å›¾æå–ç­–ç•¥éœ€è¦æ ¹æ®ä¸åŒçš„ä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼Œä»¥ç¡®ä¿æå–çš„å­å›¾åŒ…å«è¶³å¤Ÿçš„ä¿¡æ¯ï¼ŒåŒæ—¶é¿å…å¼•å…¥è¿‡å¤šçš„å™ªå£°ã€‚LLMçš„é€‰æ‹©å’Œpromptè®¾è®¡ä¹Ÿä¼šå½±å“æœ€ç»ˆçš„æŽ¨ç†ç»“æžœã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

Sparse3DPRåœ¨Space3D-Benchæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒEM@1æŒ‡æ ‡æé«˜äº†28.7%ï¼Œé€Ÿåº¦æé«˜äº†78.2%ï¼ˆä¸ŽConceptGraphsç›¸æ¯”ï¼‰ã€‚æ­¤å¤–ï¼ŒSparse3DPRåœ¨ScanQAæ•°æ®é›†ä¸ŠèŽ·å¾—äº†ä¸ŽåŸºäºŽè®­ç»ƒçš„æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨çœŸå®žä¸–ç•Œå®žéªŒä¸­è¡¨çŽ°å‡ºè‰¯å¥½çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒSparse3DPRæ˜¯ä¸€ç§é«˜æ•ˆä¸”å‡†ç¡®çš„æ— è®­ç»ƒ3Dåœºæ™¯ç†è§£æ¡†æž¶ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

Sparse3DPRåœ¨æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½å®¶å±…ã€è™šæ‹ŸçŽ°å®žå’Œå¢žå¼ºçŽ°å®žç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººç†è§£å‘¨å›´çŽ¯å¢ƒï¼Œè¿›è¡Œè‡ªä¸»å¯¼èˆªï¼›å¯ä»¥ç”¨äºŽæ™ºèƒ½å®¶å±…åœºæ™¯ä¸­çš„ç‰©ä½“è¯†åˆ«å’Œäº¤äº’ï¼›è¿˜å¯ä»¥ä¸ºVR/ARåº”ç”¨æä¾›æ›´é€¼çœŸçš„3Dåœºæ™¯ç†è§£èƒ½åŠ›ã€‚è¯¥ç ”ç©¶æœ‰æœ›æŽ¨åŠ¨3Dåœºæ™¯ç†è§£æŠ€æœ¯çš„å‘å±•ï¼Œå¹¶ä¿ƒè¿›å…¶åœ¨å„ä¸ªé¢†åŸŸçš„åº”ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recently, large language models (LLMs) have been explored widely for 3D scene understanding. Among them, training-free approaches are gaining attention for their flexibility and generalization over training-based methods. However, they typically struggle with accuracy and efficiency in practical deployment. To address the problems, we propose Sparse3DPR, a novel training-free framework for open-ended scene understanding, which leverages the reasoning capabilities of pre-trained LLMs and requires only sparse-view RGB inputs. Specifically, we introduce a hierarchical plane-enhanced scene graph that supports open vocabulary and adopts dominant planar structures as spatial anchors, which enables clearer reasoning chains and more reliable high-level inferences. Furthermore, we design a task-adaptive subgraph extraction method to filter query-irrelevant information dynamically, reducing contextual noise and improving 3D scene reasoning efficiency and accuracy. Experimental results demonstrate the superiority of Sparse3DPR, which achieves a 28.7% EM@1 improvement and a 78.2% speedup compared with ConceptGraphs on the Space3D-Bench. Moreover, Sparse3DPR obtains comparable performance to training-based methods on ScanQA, with additional real-world experiments confirming its robustness and generalization capability.

