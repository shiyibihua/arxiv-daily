---
layout: default
title: EAGLE: Episodic Appearance- and Geometry-aware Memory for Unified 2D-3D Visual Query Localization in Egocentric Vision
---

# EAGLE: Episodic Appearance- and Geometry-aware Memory for Unified 2D-3D Visual Query Localization in Egocentric Vision

**arXiv**: [2511.08007v1](https://arxiv.org/abs/2511.08007) | [PDF](https://arxiv.org/pdf/2511.08007.pdf)

**ä½œè€…**: Yifei Cao, Yu Liu, Guolong Wang, Zhu Liu, Kai Wang, Xianjie Zhang, Jizhe Yu, Xun Tu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEAGLEæ¡†æž¶ï¼Œåˆ©ç”¨å¤–è§‚å’Œå‡ ä½•æ„ŸçŸ¥è®°å¿†å®žçŽ°ç»Ÿä¸€2D-3Dè§†è§‰æŸ¥è¯¢å®šä½ï¼Œè§£å†³è‡ªæˆ‘ä¸­å¿ƒè§†è§‰ä¸­çš„æŒ‘æˆ˜ã€‚**

**å…³é”®è¯**: `è‡ªæˆ‘ä¸­å¿ƒè§†è§‰` `è§†è§‰æŸ¥è¯¢å®šä½` `è®°å¿†æœºåˆ¶` `2D-3Dç»Ÿä¸€` `å¤–è§‚å˜åŒ–å»ºæ¨¡` `å‡ ä½•æ„ŸçŸ¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‡ªæˆ‘ä¸­å¿ƒè§†è§‰æŸ¥è¯¢å®šä½å› ç›¸æœºè¿åŠ¨ã€è§†è§’å˜åŒ–å’Œå¤–è§‚å˜åŒ–è€Œå›°éš¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆå¤–è§‚æ„ŸçŸ¥å…ƒå­¦ä¹ è®°å¿†å’Œå‡ ä½•æ„ŸçŸ¥å®šä½è®°å¿†ï¼Œæ”¯æŒç›®æ ‡å¤–è§‚çš„é•¿æœŸå’ŒçŸ­æœŸå»ºæ¨¡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Ego4D-VQåŸºå‡†ä¸Šå®žçŽ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œæå‡æ£€ç´¢ç²¾åº¦å’Œ3Dç©ºé—´æŠ•å½±æ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Egocentric visual query localization is vital for embodied AI and VR/AR, yet remains challenging due to camera motion, viewpoint changes, and appearance variations. We present EAGLE, a novel framework that leverages episodic appearance- and geometry-aware memory to achieve unified 2D-3D visual query localization in egocentric vision. Inspired by avian memory consolidation, EAGLE synergistically integrates segmentation guided by an appearance-aware meta-learning memory (AMM), with tracking driven by a geometry-aware localization memory (GLM). This memory consolidation mechanism, through structured appearance and geometry memory banks, stores high-confidence retrieval samples, effectively supporting both long- and short-term modeling of target appearance variations. This enables precise contour delineation with robust spatial discrimination, leading to significantly improved retrieval accuracy. Furthermore, by integrating the VQL-2D output with a visual geometry grounded Transformer (VGGT), we achieve a efficient unification of 2D and 3D tasks, enabling rapid and accurate back-projection into 3D space. Our method achieves state-ofthe-art performance on the Ego4D-VQ benchmark.

