---
layout: default
title: I2E: Real-Time Image-to-Event Conversion for High-Performance Spiking Neural Networks
---

# I2E: Real-Time Image-to-Event Conversion for High-Performance Spiking Neural Networks

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.08065" target="_blank" class="toolbar-btn">arXiv: 2511.08065v1</a>
    <a href="https://arxiv.org/pdf/2511.08065.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.08065v1" 
            onclick="toggleFavorite(this, '2511.08065v1', 'I2E: Real-Time Image-to-Event Conversion for High-Performance Spiking Neural Networks')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Ruichen Ma, Liwei Meng, Guanchao Qiao, Ning Ning, Yang Liu, Shaogang Hu

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-11

**Â§áÊ≥®**: AAAI-26 Oral

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**I2EÔºöÁî®‰∫éÈ´òÊÄßËÉΩËÑâÂÜ≤Á•ûÁªèÁΩëÁªúÁöÑÂÆûÊó∂ÂõæÂÉèÂà∞‰∫ã‰ª∂ËΩ¨Êç¢Ê°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `ËÑâÂÜ≤Á•ûÁªèÁΩëÁªú` `‰∫ã‰ª∂Áõ∏Êú∫` `ÂõæÂÉèÂà∞‰∫ã‰ª∂ËΩ¨Êç¢` `Êï∞ÊçÆÂ¢ûÂº∫` `Á•ûÁªèÂΩ¢ÊÄÅËÆ°ÁÆó`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ËÑâÂÜ≤Á•ûÁªèÁΩëÁªúÁº∫‰πèË∂≥Â§üÁöÑ‰∫ã‰ª∂ÊµÅÊï∞ÊçÆÔºåÈôêÂà∂‰∫ÜÂÖ∂ÂèëÂ±ïÂíåÂ∫îÁî®„ÄÇ
2. I2EÈÄöËøáÊ®°ÊãüÂæÆÁúºË∑≥ËøêÂä®ÔºåÂ∞ÜÈùôÊÄÅÂõæÂÉèÈ´òÊïàËΩ¨Êç¢‰∏∫È´ò‰øùÁúü‰∫ã‰ª∂ÊµÅÔºåÂÆûÁé∞Êï∞ÊçÆÂ¢ûÂº∫„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåI2EÁîüÊàêÁöÑÊï∞ÊçÆËÉΩÊúâÊïàËÆ≠ÁªÉSNNÔºåÂπ∂Âú®ÁúüÂÆûÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰ºòÂºÇÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËÑâÂÜ≤Á•ûÁªèÁΩëÁªú(SNNs)ÂÖ∑ÊúâÈ´òËÉΩÊïàËÆ°ÁÆóÁöÑÊΩúÂäõÔºå‰ΩÜ‰∫ã‰ª∂ÊµÅÊï∞ÊçÆÁöÑ‰∏•ÈáçÂåÆ‰πèÈòªÁ¢ç‰∫ÜÂÖ∂Â∫îÁî®„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜI2EÔºå‰∏Ä‰∏™ÈÄöËøáÂ∞ÜÈùôÊÄÅÂõæÂÉèËΩ¨Êç¢‰∏∫È´ò‰øùÁúü‰∫ã‰ª∂ÊµÅÊù•Ëß£ÂÜ≥Ëøô‰∏ÄÁì∂È¢àÁöÑÁÆóÊ≥ïÊ°ÜÊû∂„ÄÇÈÄöËøá‰ΩøÁî®È´òÂ∫¶Âπ∂Ë°åÂåñÁöÑÂç∑ÁßØÊ®°ÊãüÂæÆÁúºË∑≥ËøêÂä®ÔºåI2EÂÆûÁé∞‰∫ÜÊØîÁé∞ÊúâÊñπÊ≥ïÂø´300ÂÄç‰ª•‰∏äÁöÑËΩ¨Êç¢ÈÄüÂ∫¶Ôºå‰ªéËÄåËÉΩÂ§ü‰∏∫SNNËÆ≠ÁªÉËøõË°åÂÆûÊó∂Êï∞ÊçÆÂ¢ûÂº∫„ÄÇËØ•Ê°ÜÊû∂ÁöÑÊúâÊïàÊÄßÂ∑≤Âú®Â§ßËßÑÊ®°Âü∫ÂáÜÊµãËØï‰∏≠ÂæóÂà∞È™åËØÅ„ÄÇÂú®ÁîüÊàêÁöÑI2E-ImageNetÊï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉÁöÑSNNËææÂà∞‰∫Ü60.50%ÁöÑÊúÄÂÖàËøõÁ≤æÂ∫¶„ÄÇÈáçË¶ÅÁöÑÊòØÔºåËøôÈ°πÂ∑•‰ΩúÂª∫Á´ã‰∫Ü‰∏Ä‰∏™Âº∫Â§ßÁöÑsim-to-realËåÉ‰æãÔºåÂç≥Âú®ÂêàÊàêI2EÊï∞ÊçÆ‰∏äËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÂπ∂Âú®ÁúüÂÆû‰∏ñÁïåÁöÑCIFAR10-DVSÊï∞ÊçÆÈõÜ‰∏äËøõË°åÂæÆË∞ÉÔºå‰ªéËÄå‰∫ßÁîü‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑ92.5%ÁöÑÁ≤æÂ∫¶„ÄÇËøô‰∏ÄÁªìÊûúÈ™åËØÅ‰∫ÜÂêàÊàê‰∫ã‰ª∂Êï∞ÊçÆÂèØ‰ª•‰Ωú‰∏∫ÁúüÂÆû‰º†ÊÑüÂô®Êï∞ÊçÆÁöÑÈ´ò‰øùÁúü‰ª£ÁêÜÔºåÂº•Âêà‰∫ÜÁ•ûÁªèÂΩ¢ÊÄÅÂ∑•Á®ã‰∏≠ÈïøÊúüÂ≠òÂú®ÁöÑÂ∑ÆË∑ù„ÄÇÈÄöËøá‰∏∫Êï∞ÊçÆÈóÆÈ¢òÊèê‰æõÂèØÊâ©Â±ïÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåI2E‰∏∫ÂºÄÂèëÈ´òÊÄßËÉΩÁ•ûÁªèÂΩ¢ÊÄÅÁ≥ªÁªüÊèê‰æõ‰∫Ü‰∏Ä‰∏™Âü∫Á°ÄÂ∑•ÂÖ∑ÂåÖ„ÄÇÂºÄÊ∫êÁÆóÊ≥ïÂíåÊâÄÊúâÁîüÊàêÁöÑÊï∞ÊçÆÈõÜÂùáÂ∑≤Êèê‰æõÔºå‰ª•Âä†ÈÄüËØ•È¢ÜÂüüÁöÑÁ†îÁ©∂„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÑâÂÜ≤Á•ûÁªèÁΩëÁªú(SNNs)‰Ωú‰∏∫‰∏ÄÁßçÊñ∞ÂÖ¥ÁöÑ‰ΩéÂäüËÄóËÆ°ÁÆóÊ®°ÂûãÔºåÂèóÂà∞Ë∂äÊù•Ë∂äÂ§öÁöÑÂÖ≥Ê≥®„ÄÇÁÑ∂ËÄåÔºåSNNÁöÑËÆ≠ÁªÉÈúÄË¶ÅÂ§ßÈáèÁöÑ‰∫ã‰ª∂ÊµÅÊï∞ÊçÆÔºåËÄåÁúüÂÆû‰∫ã‰ª∂Áõ∏Êú∫Ëé∑ÂèñÁöÑÊï∞ÊçÆÊúâÈôê‰∏îÊòÇË¥µ„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈÄüÂ∫¶ËæÉÊÖ¢ÔºåÈöæ‰ª•Êª°Ë∂≥Â§ßËßÑÊ®°SNNËÆ≠ÁªÉÁöÑÈúÄÊ±Ç„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÈ´òÊïàÂú∞Â∞ÜÈùôÊÄÅÂõæÂÉèËΩ¨Êç¢‰∏∫È´òË¥®ÈáèÁöÑ‰∫ã‰ª∂ÊµÅÊï∞ÊçÆÔºåÊàê‰∏∫SNNÁ†îÁ©∂ÁöÑÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöI2EÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊ®°Êãü‰∫∫Á±ªËßÜËßâÁ≥ªÁªü‰∏≠ÁöÑÂæÆÁúºË∑≥ËøêÂä®ÔºåÈÄöËøáÂú®ÈùôÊÄÅÂõæÂÉè‰∏äÂºïÂÖ•ÂæÆÂ∞èÁöÑ‰ΩçÁßªÔºå‰∫ßÁîüÁ±ª‰ºº‰∫é‰∫ã‰ª∂Áõ∏Êú∫ÊçïÊçâÂà∞ÁöÑ‰∫ã‰ª∂ÊµÅ„ÄÇËøôÁßçÊñπÊ≥ïÂà©Áî®‰∫ÜÂç∑ÁßØËøêÁÆóÁöÑÈ´òÂ∫¶Âπ∂Ë°åÊÄßÔºå‰ªéËÄåÂÆûÁé∞‰∫ÜÂø´ÈÄüÁöÑÂõæÂÉèÂà∞‰∫ã‰ª∂ËΩ¨Êç¢„ÄÇÈÄöËøáÊéßÂà∂ÂæÆÁúºË∑≥ÁöÑÂèÇÊï∞ÔºåÂèØ‰ª•ÁîüÊàê‰∏çÂêåÁâπÂæÅÁöÑ‰∫ã‰ª∂ÊµÅÊï∞ÊçÆÔºåÁî®‰∫éSNNÁöÑËÆ≠ÁªÉÂíåÊµãËØï„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöI2EÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) **ÂõæÂÉèËæìÂÖ•**ÔºöËæìÂÖ•ÈùôÊÄÅÂõæÂÉè„ÄÇ2) **ÂæÆÁúºË∑≥Ê®°Êãü**Ôºö‰ΩøÁî®Âç∑ÁßØÊ†∏Ê®°ÊãüÂæÆÁúºË∑≥ËøêÂä®ÔºåÂØπÂõæÂÉèËøõË°åÂæÆÂ∞èÁöÑ‰ΩçÁßª„ÄÇÂç∑ÁßØÊ†∏ÁöÑÂèÇÊï∞ÂÜ≥ÂÆö‰∫ÜÂæÆÁúºË∑≥ÁöÑÂπÖÂ∫¶ÂíåÊñπÂêë„ÄÇ3) **‰∫ã‰ª∂ÁîüÊàê**ÔºöÊ†πÊçÆÂõæÂÉèÂÉèÁ¥†ÂÄºÁöÑÂèòÂåñÔºåÁîüÊàê‰∫ã‰ª∂ÊµÅÊï∞ÊçÆ„ÄÇÂÉèÁ¥†ÂÄºÂèòÂåñË∂ÖËøá‰∏ÄÂÆöÈòàÂÄºÊó∂ÔºåÂàôËÆ§‰∏∫‰∫ßÁîü‰∫Ü‰∏Ä‰∏™‰∫ã‰ª∂„ÄÇ4) **Êï∞ÊçÆËæìÂá∫**ÔºöËæìÂá∫ÁîüÊàêÁöÑ‰∫ã‰ª∂ÊµÅÊï∞ÊçÆÔºåÁî®‰∫éSNNÁöÑËÆ≠ÁªÉÊàñÊµãËØï„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöI2EÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÂÖ∂È´òÊïàÁöÑÂõæÂÉèÂà∞‰∫ã‰ª∂ËΩ¨Êç¢ÁÆóÊ≥ï„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåI2EÂà©Áî®Âç∑ÁßØËøêÁÆóÁöÑÂπ∂Ë°åÊÄßÔºåÊòæËëóÊèêÈ´ò‰∫ÜËΩ¨Êç¢ÈÄüÂ∫¶ÔºåÂÆûÁé∞‰∫Ü300ÂÄç‰ª•‰∏äÁöÑÂä†ÈÄü„ÄÇÊ≠§Â§ñÔºåI2EËøòÊèê‰æõ‰∫Ü‰∏ÄÁßçsim-to-realÁöÑËÆ≠ÁªÉËåÉÂºèÔºåÂç≥ÂÖàÂú®ÂêàÊàêÊï∞ÊçÆ‰∏äËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÁÑ∂ÂêéÂú®ÁúüÂÆûÊï∞ÊçÆ‰∏äËøõË°åÂæÆË∞ÉÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜSNNÂú®ÁúüÂÆûÂú∫ÊôØ‰∏≠ÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöI2EÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) **Âç∑ÁßØÊ†∏ÁöÑËÆæËÆ°**ÔºöÂç∑ÁßØÊ†∏ÁöÑÂèÇÊï∞ÂÜ≥ÂÆö‰∫ÜÂæÆÁúºË∑≥ÁöÑÂπÖÂ∫¶ÂíåÊñπÂêëÔºåÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰ΩìÁöÑÂ∫îÁî®Âú∫ÊôØËøõË°åË∞ÉÊï¥„ÄÇ2) **‰∫ã‰ª∂ÈòàÂÄºÁöÑËÆæÁΩÆ**Ôºö‰∫ã‰ª∂ÈòàÂÄºÂÜ≥ÂÆö‰∫ÜÂÉèÁ¥†ÂÄºÂèòÂåñÂ§öÂ∞ëÊâç‰ºöË¢´ËÆ§‰∏∫ÊòØ‰∏Ä‰∏™‰∫ã‰ª∂ÔºåÈúÄË¶ÅÊ†πÊçÆÂõæÂÉèÁöÑÂô™Â£∞Ê∞¥Âπ≥ËøõË°åË∞ÉÊï¥„ÄÇ3) **Êï∞ÊçÆÂ¢ûÂº∫Á≠ñÁï•**ÔºöÈÄöËøáË∞ÉÊï¥ÂæÆÁúºË∑≥ÁöÑÂèÇÊï∞ÔºåÂèØ‰ª•ÁîüÊàê‰∏çÂêåÁâπÂæÅÁöÑ‰∫ã‰ª∂ÊµÅÊï∞ÊçÆÔºåÁî®‰∫éÊï∞ÊçÆÂ¢ûÂº∫„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËØ•Á†îÁ©∂Âú®I2E-ImageNetÊï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉÁöÑSNNËææÂà∞‰∫Ü60.50%ÁöÑstate-of-the-artÁ≤æÂ∫¶„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÈÄöËøáÂú®ÂêàÊàêI2EÊï∞ÊçÆ‰∏äÈ¢ÑËÆ≠ÁªÉÔºåÂπ∂Âú®ÁúüÂÆû‰∏ñÁïåÁöÑCIFAR10-DVSÊï∞ÊçÆÈõÜ‰∏äÂæÆË∞ÉÔºåSNNËææÂà∞‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑ92.5%ÁöÑÁ≤æÂ∫¶„ÄÇËøôË°®ÊòéÂêàÊàê‰∫ã‰ª∂Êï∞ÊçÆÂèØ‰ª•‰Ωú‰∏∫ÁúüÂÆû‰º†ÊÑüÂô®Êï∞ÊçÆÁöÑÈ´ò‰øùÁúü‰ª£ÁêÜÔºå‰∏∫SNNÁöÑËÆ≠ÁªÉÊèê‰æõ‰∫Ü‰∏ÄÁßçÊúâÊïàÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

I2EÊ°ÜÊû∂Âú®Á•ûÁªèÂΩ¢ÊÄÅËÆ°ÁÆóÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éËß£ÂÜ≥SNNËÆ≠ÁªÉ‰∏≠Êï∞ÊçÆÂåÆ‰πèÁöÑÈóÆÈ¢òÔºåÂä†ÈÄüSNNÂú®ÂõæÂÉèËØÜÂà´„ÄÅÁõÆÊ†áÊ£ÄÊµã„ÄÅÊú∫Âô®‰∫∫ÂØºËà™Á≠âÈ¢ÜÂüüÁöÑÂ∫îÁî®„ÄÇÊ≠§Â§ñÔºåI2EËøòÂèØ‰ª•Áî®‰∫éÁîüÊàêÁî®‰∫éËØÑ‰º∞SNNÊÄßËÉΩÁöÑÂêàÊàêÊï∞ÊçÆÈõÜÔºå‰∏∫SNNÁÆóÊ≥ïÁöÑÂºÄÂèëÂíå‰ºòÂåñÊèê‰æõÊîØÊåÅ„ÄÇËØ•Á†îÁ©∂ÊúâÊúõÊé®Âä®Á•ûÁªèÂΩ¢ÊÄÅËÆ°ÁÆóÁöÑÂèëÂ±ïÔºåÂÆûÁé∞Êõ¥È´òÊïà„ÄÅÊõ¥Êô∫ËÉΩÁöÑËÆ°ÁÆóÁ≥ªÁªü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Spiking neural networks (SNNs) promise highly energy-efficient computing, but their adoption is hindered by a critical scarcity of event-stream data. This work introduces I2E, an algorithmic framework that resolves this bottleneck by converting static images into high-fidelity event streams. By simulating microsaccadic eye movements with a highly parallelized convolution, I2E achieves a conversion speed over 300x faster than prior methods, uniquely enabling on-the-fly data augmentation for SNN training. The framework's effectiveness is demonstrated on large-scale benchmarks. An SNN trained on the generated I2E-ImageNet dataset achieves a state-of-the-art accuracy of 60.50%. Critically, this work establishes a powerful sim-to-real paradigm where pre-training on synthetic I2E data and fine-tuning on the real-world CIFAR10-DVS dataset yields an unprecedented accuracy of 92.5%. This result validates that synthetic event data can serve as a high-fidelity proxy for real sensor data, bridging a long-standing gap in neuromorphic engineering. By providing a scalable solution to the data problem, I2E offers a foundational toolkit for developing high-performance neuromorphic systems. The open-source algorithm and all generated datasets are provided to accelerate research in the field.

