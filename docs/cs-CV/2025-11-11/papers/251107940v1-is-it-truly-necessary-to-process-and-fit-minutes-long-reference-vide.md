---
layout: default
title: Is It Truly Necessary to Process and Fit Minutes-Long Reference Videos for Personalized Talking Face Generation?
---

# Is It Truly Necessary to Process and Fit Minutes-Long Reference Videos for Personalized Talking Face Generation?

**arXiv**: [2511.07940v1](https://arxiv.org/abs/2511.07940) | [PDF](https://arxiv.org/pdf/2511.07940.pdf)

**ä½œè€…**: Rui-Qing Sun, Ang Li, Zhijing Wu, Tian Lan, Qianyu Lu, Xingshan Yao, Chen Xu, Xian-Ling Mao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºISExploreç­–ç•¥ï¼ŒåŠ é€Ÿä¸ªæ€§åŒ–è¯´è¯äººè„¸ç”Ÿæˆï¼Œå‡å°‘å‚è€ƒè§†é¢‘å¤„ç†æ—¶é•¿ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è¯´è¯äººè„¸ç”Ÿæˆ` `ç¥žç»è¾å°„åœº` `3Dé«˜æ–¯æº…å°„` `è§†é¢‘ç‰‡æ®µé€‰æ‹©` `ä¿¡æ¯é‡è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è¯´è¯äººè„¸ç”Ÿæˆæ–¹æ³•ä¾èµ–æ•°åˆ†é’Ÿå‚è€ƒè§†é¢‘ï¼Œå¤„ç†è€—æ—¶ï¼Œé™åˆ¶äº†å®žé™…åº”ç”¨ã€‚
2. ISExploreç­–ç•¥è‡ªåŠ¨é€‰æ‹©ä¿¡æ¯é‡å¤§çš„5ç§’è§†é¢‘ç‰‡æ®µï¼Œæå‡è®­ç»ƒæ•ˆçŽ‡ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒISExploreåœ¨åŠ é€Ÿ5å€ä»¥ä¸Šçš„åŒæ—¶ï¼Œä¿æŒäº†é«˜ä¿çœŸç”Ÿæˆæ•ˆæžœã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯´è¯äººè„¸ç”Ÿæˆ(TFG)æ—¨åœ¨ç”Ÿæˆé€¼çœŸä¸”åŠ¨æ€çš„è¯´è¯äººåƒï¼Œåœ¨æ•°å­—æ•™è‚²ã€å½±è§†åˆ¶ä½œã€ç”µå•†ç›´æ’­ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›åº”ç”¨ã€‚å½“å‰ï¼ŒåŸºäºŽç¥žç»è¾å°„åœº(NeRF)æˆ–3Dé«˜æ–¯æº…å°„(3DGS)çš„TFGæ–¹æ³•å—åˆ°å¹¿æ³›å…³æ³¨ã€‚å®ƒä»¬ä»Žæ¯ä¸ªç›®æ ‡ä¸ªä½“çš„å‚è€ƒè§†é¢‘ä¸­å­¦ä¹ å’Œå­˜å‚¨ä¸ªæ€§åŒ–ç‰¹å¾ï¼Œä»¥ç”Ÿæˆé€¼çœŸçš„è¯´è¯è§†é¢‘ã€‚ä¸ºäº†ç¡®ä¿æ¨¡åž‹èƒ½å¤Ÿæ•èŽ·è¶³å¤Ÿçš„3Dä¿¡æ¯å¹¶æˆåŠŸå­¦ä¹ å”‡-éŸ³é¢‘æ˜ å°„ï¼Œä»¥å¾€çš„ç ”ç©¶é€šå¸¸éœ€è¦ç»†è‡´åœ°å¤„ç†å’Œæ‹Ÿåˆå‡ åˆ†é’Ÿçš„å‚è€ƒè§†é¢‘ï¼Œè¿™é€šå¸¸éœ€è¦æ•°å°æ—¶ã€‚å¤„ç†å’Œæ‹Ÿåˆé•¿å‚è€ƒè§†é¢‘çš„è®¡ç®—è´Ÿæ‹…ä¸¥é‡é™åˆ¶äº†è¿™äº›æ–¹æ³•çš„å®žé™…åº”ç”¨ä»·å€¼ã€‚ç„¶è€Œï¼ŒçœŸçš„æœ‰å¿…è¦æ‹Ÿåˆè¿™ä¹ˆé•¿çš„å‚è€ƒè§†é¢‘å—ï¼Ÿæˆ‘ä»¬çš„æŽ¢ç´¢æ€§æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜Žï¼Œä½¿ç”¨ä¸€äº›ä¿¡æ¯é‡å¤§çš„å‚è€ƒè§†é¢‘ç‰‡æ®µï¼ˆä»…å‡ ç§’é’Ÿï¼‰å¯ä»¥å®žçŽ°ä¸Žå®Œæ•´å‚è€ƒè§†é¢‘ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚è¿™è¡¨æ˜Žè§†é¢‘çš„ä¿¡æ¯è´¨é‡æ¯”å…¶é•¿åº¦é‡è¦å¾—å¤šã€‚å—æ­¤è§‚å¯Ÿçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„ç‰‡æ®µé€‰æ‹©ç­–ç•¥ISExploreï¼ˆä¿¡æ¯ç‰‡æ®µæŽ¢ç´¢çš„ç¼©å†™ï¼‰ï¼Œè¯¥ç­–ç•¥åŸºäºŽä¸‰ä¸ªå…³é”®æ•°æ®è´¨é‡ç»´åº¦è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯é‡å¤§çš„5ç§’å‚è€ƒè§†é¢‘ç‰‡æ®µï¼šéŸ³é¢‘ç‰¹å¾å¤šæ ·æ€§ã€å”‡éƒ¨è¿åŠ¨å¹…åº¦å’Œç›¸æœºè§†è§’æ•°é‡ã€‚å¤§é‡çš„å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†NeRFå’Œ3DGSæ–¹æ³•çš„æ•°æ®å¤„ç†å’Œè®­ç»ƒé€Ÿåº¦æé«˜äº†5å€ä»¥ä¸Šï¼ŒåŒæ—¶ä¿æŒäº†é«˜ä¿çœŸè¾“å‡ºã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰åŸºäºŽNeRFæˆ–3DGSçš„ä¸ªæ€§åŒ–è¯´è¯äººè„¸ç”Ÿæˆæ–¹æ³•ï¼Œä¸ºäº†ä¿è¯ç”Ÿæˆè´¨é‡ï¼Œéœ€è¦ä½¿ç”¨æ•°åˆ†é’Ÿçš„å‚è€ƒè§†é¢‘è¿›è¡Œè®­ç»ƒã€‚ç„¶è€Œï¼Œå¤„ç†è¿™äº›é•¿è§†é¢‘éœ€è¦è€—è´¹å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºï¼Œä¸¥é‡é˜»ç¢äº†è¿™äº›æ–¹æ³•åœ¨å®žé™…åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œä¾‹å¦‚å¿«é€Ÿç”Ÿæˆä¸ªæ€§åŒ–çš„ç›´æ’­è§†é¢‘ç­‰ã€‚å› æ­¤ï¼Œå¦‚ä½•å‡å°‘å‚è€ƒè§†é¢‘çš„å¤„ç†æ—¶é•¿ï¼ŒåŒæ—¶ä¿è¯ç”Ÿæˆè´¨é‡ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ï¼Œå¹¶éžå‚è€ƒè§†é¢‘çš„é•¿åº¦è¶Šé•¿è¶Šå¥½ï¼Œè§†é¢‘çš„ä¿¡æ¯é‡æ‰æ˜¯å…³é”®ã€‚é€šè¿‡åˆ†æžå‘çŽ°ï¼Œåªéœ€è¦åŒ…å«è¶³å¤ŸéŸ³é¢‘ç‰¹å¾å¤šæ ·æ€§ã€å”‡éƒ¨è¿åŠ¨å¹…åº¦ä»¥åŠå¤šè§’åº¦ä¿¡æ¯çš„çŸ­è§†é¢‘ç‰‡æ®µï¼Œå°±èƒ½è¾¾åˆ°ç”šè‡³è¶…è¿‡é•¿è§†é¢‘çš„è®­ç»ƒæ•ˆæžœã€‚å› æ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§è‡ªåŠ¨é€‰æ‹©ä¿¡æ¯é‡å¤§çš„çŸ­è§†é¢‘ç‰‡æ®µçš„ç­–ç•¥ï¼Œä»Žè€Œå‡å°‘äº†æ•°æ®å¤„ç†å’Œè®­ç»ƒçš„æ—¶é—´ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šISExploreç­–ç•¥ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) å¯¹å‚è€ƒè§†é¢‘è¿›è¡Œåˆ†æ®µï¼Œä¾‹å¦‚åˆ†æˆè‹¥å¹²ä¸ª5ç§’çš„ç‰‡æ®µï¼›2) å¯¹æ¯ä¸ªç‰‡æ®µè¿›è¡Œä¿¡æ¯é‡è¯„ä¼°ï¼Œè¯„ä¼°çš„ç»´åº¦åŒ…æ‹¬éŸ³é¢‘ç‰¹å¾å¤šæ ·æ€§ã€å”‡éƒ¨è¿åŠ¨å¹…åº¦ä»¥åŠç›¸æœºè§†è§’æ•°é‡ï¼›3) æ ¹æ®è¯„ä¼°ç»“æžœï¼Œé€‰æ‹©ä¿¡æ¯é‡æœ€å¤§çš„ç‰‡æ®µä½œä¸ºè®­ç»ƒæ•°æ®ã€‚æ•´ä¸ªæµç¨‹ç®€å•é«˜æ•ˆï¼Œæ˜“äºŽé›†æˆåˆ°çŽ°æœ‰çš„NeRFæˆ–3DGSæ¡†æž¶ä¸­ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ISExploreç­–ç•¥ï¼Œè¯¥ç­–ç•¥èƒ½å¤Ÿè‡ªåŠ¨é€‰æ‹©ä¿¡æ¯é‡å¤§çš„çŸ­è§†é¢‘ç‰‡æ®µï¼Œä»Žè€Œåœ¨ä¿è¯ç”Ÿæˆè´¨é‡çš„å‰æä¸‹ï¼Œå¤§å¹…å‡å°‘äº†æ•°æ®å¤„ç†å’Œè®­ç»ƒçš„æ—¶é—´ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•éœ€è¦æ‰‹åŠ¨é€‰æ‹©æˆ–è€…ä½¿ç”¨å®Œæ•´é•¿è§†é¢‘ç›¸æ¯”ï¼ŒISExploreç­–ç•¥æ›´åŠ è‡ªåŠ¨åŒ–å’Œé«˜æ•ˆã€‚

**å…³é”®è®¾è®¡**ï¼šISExploreç­–ç•¥çš„å…³é”®è®¾è®¡åœ¨äºŽä¿¡æ¯é‡è¯„ä¼°çš„ä¸‰ä¸ªç»´åº¦ï¼šéŸ³é¢‘ç‰¹å¾å¤šæ ·æ€§ã€å”‡éƒ¨è¿åŠ¨å¹…åº¦ä»¥åŠç›¸æœºè§†è§’æ•°é‡ã€‚éŸ³é¢‘ç‰¹å¾å¤šæ ·æ€§ä¿è¯äº†æ¨¡åž‹èƒ½å¤Ÿå­¦ä¹ åˆ°ä¸°å¯Œçš„è¯­éŸ³ä¿¡æ¯ï¼›å”‡éƒ¨è¿åŠ¨å¹…åº¦ä¿è¯äº†æ¨¡åž‹èƒ½å¤Ÿå­¦ä¹ åˆ°å‡†ç¡®çš„å”‡-éŸ³é¢‘æ˜ å°„ï¼›ç›¸æœºè§†è§’æ•°é‡ä¿è¯äº†æ¨¡åž‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´å®Œæ•´çš„3Dç»“æž„ã€‚å…·ä½“å®žçŽ°ä¸Šï¼Œå¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒçš„éŸ³é¢‘ç‰¹å¾æå–å™¨æå–éŸ³é¢‘ç‰¹å¾ï¼Œä½¿ç”¨äººè„¸å…³é”®ç‚¹æ£€æµ‹ç®—æ³•æ£€æµ‹å”‡éƒ¨è¿åŠ¨å¹…åº¦ï¼Œå¹¶ç»Ÿè®¡è§†é¢‘ä¸­å‡ºçŽ°çš„ä¸åŒç›¸æœºè§†è§’æ•°é‡ã€‚æœ€ç»ˆï¼Œå°†è¿™ä¸‰ä¸ªç»´åº¦çš„è¯„ä¼°ç»“æžœè¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°æ¯ä¸ªç‰‡æ®µçš„ä¿¡æ¯é‡å¾—åˆ†ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œä½¿ç”¨ISExploreç­–ç•¥é€‰æ‹©çš„5ç§’è§†é¢‘ç‰‡æ®µè¿›è¡Œè®­ç»ƒï¼Œåœ¨NeRFå’Œ3DGSæ–¹æ³•ä¸Šï¼Œæ•°æ®å¤„ç†å’Œè®­ç»ƒé€Ÿåº¦æé«˜äº†5å€ä»¥ä¸Šï¼ŒåŒæ—¶ä¿æŒäº†ä¸Žä½¿ç”¨å®Œæ•´å‚è€ƒè§†é¢‘ç›¸å½“ç”šè‡³æ›´å¥½çš„ç”Ÿæˆè´¨é‡ã€‚è¿™å……åˆ†è¯æ˜Žäº†ISExploreç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ºä¸ªæ€§åŒ–è¯´è¯äººè„¸ç”Ÿæˆæä¾›äº†ä¸€ç§æ›´åŠ é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯å¹¿æ³›åº”ç”¨äºŽæ•°å­—æ•™è‚²ã€å½±è§†åˆ¶ä½œã€ç”µå•†ç›´æ’­ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆä¸ªæ€§åŒ–çš„æ•™å­¦è§†é¢‘ã€ç”µå½±è§’è‰²é…éŸ³ã€ç”µå•†ç›´æ’­è™šæ‹Ÿå½¢è±¡ç­‰ã€‚é€šè¿‡å‡å°‘å‚è€ƒè§†é¢‘çš„å¤„ç†æ—¶é•¿ï¼Œå¯ä»¥å¤§å¤§é™ä½Žç”Ÿæˆé«˜è´¨é‡è¯´è¯äººè„¸è§†é¢‘çš„é—¨æ§›ï¼Œä½¿å¾—æ›´å¤šç”¨æˆ·èƒ½å¤Ÿè½»æ¾åˆ›å»ºè‡ªå·±çš„è™šæ‹Ÿå½¢è±¡ï¼Œå¹¶åº”ç”¨äºŽå„ç§å®žé™…åœºæ™¯ä¸­ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ä¸Žè™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žç­‰æŠ€æœ¯ç›¸ç»“åˆï¼Œåˆ›é€ æ›´åŠ æ²‰æµ¸å¼çš„ç”¨æˆ·ä½“éªŒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Talking Face Generation (TFG) aims to produce realistic and dynamic talking portraits, with broad applications in fields such as digital education, film and television production, e-commerce live streaming, and other related areas. Currently, TFG methods based on Neural Radiated Field (NeRF) or 3D Gaussian sputtering (3DGS) are received widespread attention. They learn and store personalized features from reference videos of each target individual to generate realistic speaking videos. To ensure models can capture sufficient 3D information and successfully learns the lip-audio mapping, previous studies usually require meticulous processing and fitting several minutes of reference video, which always takes hours. The computational burden of processing and fitting long reference videos severely limits the practical application value of these methods.However, is it really necessary to fit such minutes of reference video? Our exploratory case studies show that using some informative reference video segments of just a few seconds can achieve performance comparable to or even better than the full reference video. This indicates that video informative quality is much more important than its length. Inspired by this observation, we propose the ISExplore (short for Informative Segment Explore), a simple-yet-effective segment selection strategy that automatically identifies the informative 5-second reference video segment based on three key data quality dimensions: audio feature diversity, lip movement amplitude, and number of camera views. Extensive experiments demonstrate that our approach increases data processing and training speed by more than 5x for NeRF and 3DGS methods, while maintaining high-fidelity output. Project resources are available at xx.

