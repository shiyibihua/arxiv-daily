---
layout: default
title: VideoChain: A Transformer-Based Framework for Multi-hop Video Question Generation
---

# VideoChain: A Transformer-Based Framework for Multi-hop Video Question Generation

**arXiv**: [2511.08348v1](https://arxiv.org/abs/2511.08348) | [PDF](https://arxiv.org/pdf/2511.08348.pdf)

**ä½œè€…**: Arpan Phukan, Anupam Pandey, Deepjyoti Bodo, Asif Ekbal

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVideoChainæ¡†æž¶ä»¥è§£å†³å¤šè·³è§†é¢‘é—®é¢˜ç”Ÿæˆä»»åŠ¡**

**å…³é”®è¯**: `å¤šè·³è§†é¢‘é—®é¢˜ç”Ÿæˆ` `Transformeræ¡†æž¶` `è§†é¢‘åµŒå…¥` `BARTæ¨¡åž‹` `å¤šæ¨¡æ€æŽ¨ç†` `TVQA+æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šè·³é—®é¢˜ç”Ÿæˆå±€é™äºŽæ–‡æœ¬ï¼Œè§†é¢‘é—®é¢˜ç”Ÿæˆä»…æ”¯æŒé›¶è·³å•ç‰‡æ®µ
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽæ”¹è¿›BARTçš„æ¨¡å—åŒ–æž¶æž„ï¼Œèžåˆè§†é¢‘åµŒå…¥æ•èŽ·å¤šæ¨¡æ€ä¾èµ–
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨MVQ-60æ•°æ®é›†ä¸Šè¯„ä¼°ï¼ŒROUGE-Lè¾¾0.6454ï¼Œç”Ÿæˆé—®é¢˜è¿žè´¯ä¸”æŽ¨ç†å¯†é›†

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-hop Question Generation (QG) effectively evaluates reasoning but remains confined to text; Video Question Generation (VideoQG) is limited to zero-hop questions over single segments. To address this, we introduce VideoChain, a novel Multi-hop Video Question Generation (MVQG) framework designed to generate questions that require reasoning across multiple, temporally separated video segments. VideoChain features a modular architecture built on a modified BART backbone enhanced with video embeddings, capturing textual and visual dependencies. Using the TVQA+ dataset, we automatically construct the large-scale MVQ-60 dataset by merging zero-hop QA pairs, ensuring scalability and diversity. Evaluations show VideoChain's strong performance across standard generation metrics: ROUGE-L (0.6454), ROUGE-1 (0.6854), BLEU-1 (0.6711), BERTScore-F1 (0.7967), and semantic similarity (0.8110). These results highlight the model's ability to generate coherent, contextually grounded, and reasoning-intensive questions.

