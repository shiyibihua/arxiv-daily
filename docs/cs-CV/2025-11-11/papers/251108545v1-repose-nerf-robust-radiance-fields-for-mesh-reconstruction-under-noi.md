---
layout: default
title: RePose-NeRF: Robust Radiance Fields for Mesh Reconstruction under Noisy Camera Poses
---

# RePose-NeRF: Robust Radiance Fields for Mesh Reconstruction under Noisy Camera Poses

**arXiv**: [2511.08545v1](https://arxiv.org/abs/2511.08545) | [PDF](https://arxiv.org/pdf/2511.08545.pdf)

**ä½œè€…**: Sriram Srinivasan, Gautam Ramachandra

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11

**å¤‡æ³¨**: Several figures are included to illustrate the reconstruction and rendering quality of the proposed method, which is why the submission exceeds the 50MB file size limit. > Several figures are included to illustrate the reconstruction and rendering quality of the proposed method, which is why the submission exceeds the 50,000 KB file size limit (Now this has been resolved)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**RePose-NeRFï¼šæå‡ºä¸€ç§é²æ£’çš„è¾å°„åœºæ–¹æ³•ï¼Œç”¨äºŽåœ¨å™ªå£°ç›¸æœºä½å§¿ä¸‹è¿›è¡Œç½‘æ ¼é‡å»º**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `NeRF` `ä¸‰ç»´é‡å»º` `ç›¸æœºä½å§¿ä¼°è®¡` `é²æ£’æ€§` `éšå¼è¡¨ç¤º` `æœºå™¨äºº` `å¤šè§†è§’å‡ ä½•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰NeRFæ–¹æ³•ä¾èµ–ç²¾ç¡®ç›¸æœºä½å§¿ï¼Œä½†åœ¨çœŸå®žåœºæ™¯ä¸­èŽ·å–ç²¾ç¡®ä½å§¿å›°éš¾ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚
2. æå‡ºRePose-NeRFï¼Œè”åˆä¼˜åŒ–ç›¸æœºä½å§¿å’Œéšå¼åœºæ™¯è¡¨ç¤ºï¼Œç›´æŽ¥ä»Žå¤šè§†è§’å›¾åƒé‡å»ºé«˜è´¨é‡ç½‘æ ¼ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨ä½å§¿ä¸ç¡®å®šæ€§ä¸‹å®žçŽ°äº†å‡†ç¡®é²æ£’çš„3Dé‡å»ºï¼Œå¹¶ç”Ÿæˆå¯ç”¨äºŽæœºå™¨äººå·¥å…·çš„ç½‘æ ¼ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»Žå¤šè§†è§’å›¾åƒä¸­è¿›è¡Œç²¾ç¡®çš„3Dé‡å»ºå¯¹äºŽå¯¼èˆªã€æ“ä½œå’ŒçŽ¯å¢ƒç†è§£ç­‰ä¸‹æ¸¸æœºå™¨äººä»»åŠ¡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå³ä½¿åœ¨å·²çŸ¥æ ¡å‡†å‚æ•°çš„æƒ…å†µä¸‹ï¼Œåœ¨çœŸå®žçŽ¯å¢ƒä¸­èŽ·å¾—ç²¾ç¡®çš„ç›¸æœºä½å§¿ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚è¿™é™åˆ¶äº†çŽ°æœ‰NeRFæ–¹æ³•çš„å®žç”¨æ€§ï¼Œå› ä¸ºå®ƒä»¬ä¸¥é‡ä¾èµ–äºŽç²¾ç¡®çš„å¤–éƒ¨å‚æ•°ä¼°è®¡ã€‚æ­¤å¤–ï¼Œå®ƒä»¬çš„éšå¼ä½“ç§¯è¡¨ç¤ºä¸Žå¹¿æ³›é‡‡ç”¨çš„å¤šè¾¹å½¢ç½‘æ ¼æ˜¾è‘—ä¸åŒï¼Œä½¿å¾—åœ¨æ ‡å‡†3Dè½¯ä»¶ä¸­è¿›è¡Œæ¸²æŸ“å’Œæ“ä½œæ•ˆçŽ‡ä½Žä¸‹ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é²æ£’çš„æ¡†æž¶ï¼Œå¯ä»¥ç›´æŽ¥ä»Žå…·æœ‰å™ªå£°å¤–éƒ¨å‚æ•°çš„å¤šè§†è§’å›¾åƒä¸­é‡å»ºé«˜è´¨é‡ã€å¯ç¼–è¾‘çš„3Dç½‘æ ¼ã€‚æˆ‘ä»¬çš„æ–¹æ³•è”åˆä¼˜åŒ–ç›¸æœºä½å§¿ï¼ŒåŒæ—¶å­¦ä¹ éšå¼åœºæ™¯è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºæ•èŽ·ç²¾ç»†çš„å‡ ä½•ç»†èŠ‚å’Œé€¼çœŸçš„å¤–è§‚ã€‚ç”Ÿæˆçš„ç½‘æ ¼ä¸Žå¸¸è§çš„3Då›¾å½¢å’Œæœºå™¨äººå·¥å…·å…¼å®¹ï¼Œä»Žè€Œå¯ä»¥é«˜æ•ˆåœ°è¿›è¡Œä¸‹æ¸¸ä½¿ç”¨ã€‚åœ¨æ ‡å‡†åŸºå‡†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä½å§¿ä¸ç¡®å®šæ€§ä¸‹å®žçŽ°äº†å‡†ç¡®è€Œé²æ£’çš„3Dé‡å»ºï¼Œå¼¥åˆäº†ç¥žç»éšå¼è¡¨ç¤ºä¸Žå®žé™…æœºå™¨äººåº”ç”¨ä¹‹é—´çš„å·®è·ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰åŸºäºŽNeRFçš„3Dé‡å»ºæ–¹æ³•å¯¹ç›¸æœºä½å§¿ç²¾åº¦è¦æ±‚é«˜ï¼Œä½†åœ¨å®žé™…åº”ç”¨ä¸­ï¼Œç›¸æœºä½å§¿å¾€å¾€å­˜åœ¨å™ªå£°ã€‚æ­¤å¤–ï¼ŒNeRFç”Ÿæˆçš„éšå¼ä½“ç§¯è¡¨ç¤ºä¸Žå¸¸ç”¨çš„å¤šè¾¹å½¢ç½‘æ ¼æ ¼å¼ä¸åŒï¼Œä¸åˆ©äºŽåœ¨æ ‡å‡†3Dè½¯ä»¶å’Œæœºå™¨äººå·¥å…·ä¸­ä½¿ç”¨ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿå®¹å¿ç›¸æœºä½å§¿å™ªå£°ï¼Œå¹¶ç›´æŽ¥ç”Ÿæˆå¯ç¼–è¾‘ç½‘æ ¼çš„3Dé‡å»ºæ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRePose-NeRFçš„æ ¸å¿ƒæ€è·¯æ˜¯è”åˆä¼˜åŒ–ç›¸æœºä½å§¿å’Œéšå¼åœºæ™¯è¡¨ç¤ºã€‚é€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒæ—¶ä¼˜åŒ–ç›¸æœºä½å§¿ï¼Œå¯ä»¥å‡è½»ä½å§¿å™ªå£°çš„å½±å“ï¼Œä»Žè€Œæé«˜é‡å»ºçš„é²æ£’æ€§ã€‚åŒæ—¶ï¼Œé€šè¿‡è®¾è®¡åˆé€‚çš„ç½‘ç»œç»“æž„å’ŒæŸå¤±å‡½æ•°ï¼Œå¯ä»¥ç›´æŽ¥ä»Žéšå¼è¡¨ç¤ºä¸­æå–é«˜è´¨é‡çš„3Dç½‘æ ¼ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šRePose-NeRFçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¤šè§†è§’å›¾åƒè¾“å…¥ï¼›2) ç›¸æœºä½å§¿åˆå§‹åŒ–ï¼ˆå¯èƒ½åŒ…å«å™ªå£°ï¼‰ï¼›3) åŸºäºŽNeRFçš„éšå¼åœºæ™¯è¡¨ç¤ºå­¦ä¹ ï¼›4) ç›¸æœºä½å§¿ä¼˜åŒ–ï¼›5) ç½‘æ ¼æå–ã€‚è¯¥æ¡†æž¶é€šè¿‡è¿­ä»£ä¼˜åŒ–ç›¸æœºä½å§¿å’Œéšå¼åœºæ™¯è¡¨ç¤ºï¼Œæœ€ç»ˆå¾—åˆ°é«˜è´¨é‡çš„3Dç½‘æ ¼æ¨¡åž‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šRePose-NeRFçš„å…³é”®åˆ›æ–°åœ¨äºŽè”åˆä¼˜åŒ–ç›¸æœºä½å§¿å’Œéšå¼åœºæ™¯è¡¨ç¤ºï¼Œä»Žè€Œæé«˜äº†å¯¹ç›¸æœºä½å§¿å™ªå£°çš„é²æ£’æ€§ã€‚ä¸Žä¼ ç»Ÿçš„å…ˆä¼°è®¡ä½å§¿å†è¿›è¡Œé‡å»ºçš„æ–¹æ³•ä¸åŒï¼ŒRePose-NeRFå°†ä½å§¿ä¼°è®¡å’Œé‡å»ºè¿‡ç¨‹é›†æˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æž¶ä¸­ï¼Œå®žçŽ°äº†ç«¯åˆ°ç«¯çš„ä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç›´æŽ¥ç”Ÿæˆå¯ç¼–è¾‘çš„3Dç½‘æ ¼ï¼Œæ–¹ä¾¿åœ¨æ ‡å‡†3Dè½¯ä»¶å’Œæœºå™¨äººå·¥å…·ä¸­ä½¿ç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šRePose-NeRFçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨å¯å¾®åˆ†çš„æ¸²æŸ“æŠ€æœ¯ï¼Œä½¿å¾—ç›¸æœºä½å§¿ä¼˜åŒ–æˆä¸ºå¯èƒ½ï¼›2) è®¾è®¡åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚å…‰åº¦ä¸€è‡´æ€§æŸå¤±å’Œå‡ ä½•çº¦æŸæŸå¤±ï¼Œä»¥ä¿è¯é‡å»ºçš„è´¨é‡ï¼›3) ä½¿ç”¨é«˜æ•ˆçš„ç½‘æ ¼æå–ç®—æ³•ï¼Œä»Žéšå¼è¡¨ç¤ºä¸­æå–é«˜è´¨é‡çš„3Dç½‘æ ¼ã€‚å…·ä½“çš„ç½‘ç»œç»“æž„å’Œå‚æ•°è®¾ç½®æœªçŸ¥ï¼Œéœ€è¦å‚è€ƒè®ºæ–‡ç»†èŠ‚ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

RePose-NeRFåœ¨æ ‡å‡†benchmarkä¸Šè¿›è¡Œäº†å®žéªŒï¼Œè¯æ˜Žäº†å…¶åœ¨ä½å§¿ä¸ç¡®å®šæ€§ä¸‹çš„é‡å»ºç²¾åº¦å’Œé²æ£’æ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªçŸ¥ï¼Œä½†æ‘˜è¦è¡¨æ˜Žè¯¥æ–¹æ³•ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶èƒ½ç”Ÿæˆé«˜è´¨é‡ã€å¯ç¼–è¾‘çš„3Dç½‘æ ¼ï¼Œæ–¹ä¾¿ä¸‹æ¸¸ä»»åŠ¡ä½¿ç”¨ã€‚å®žéªŒç»“æžœéªŒè¯äº†è¯¥æ–¹æ³•åœ¨å®žé™…æœºå™¨äººåº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

RePose-NeRFåœ¨æœºå™¨äººå¯¼èˆªã€æ“ä½œå’ŒçŽ¯å¢ƒç†è§£ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºŽåœ¨æœªçŸ¥æˆ–ä¸ç¡®å®šçŽ¯å¢ƒä¸­è¿›è¡Œ3Dåœ°å›¾æž„å»ºï¼Œä¸ºæœºå™¨äººæä¾›å‡†ç¡®çš„çŽ¯å¢ƒä¿¡æ¯ã€‚æ­¤å¤–ï¼ŒRePose-NeRFç”Ÿæˆçš„å¯ç¼–è¾‘ç½‘æ ¼æ¨¡åž‹å¯ä»¥æ–¹ä¾¿åœ°ç”¨äºŽæœºå™¨äººä»¿çœŸå’Œè§„åˆ’ï¼Œæé«˜æœºå™¨äººçš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚è¯¥ç ”ç©¶æœ‰æœ›æŽ¨åŠ¨æœºå™¨äººæŠ€æœ¯åœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„åº”ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Accurate 3D reconstruction from multi-view images is essential for downstream robotic tasks such as navigation, manipulation, and environment understanding. However, obtaining precise camera poses in real-world settings remains challenging, even when calibration parameters are known. This limits the practicality of existing NeRF-based methods that rely heavily on accurate extrinsic estimates. Furthermore, their implicit volumetric representations differ significantly from the widely adopted polygonal meshes, making rendering and manipulation inefficient in standard 3D software. In this work, we propose a robust framework that reconstructs high-quality, editable 3D meshes directly from multi-view images with noisy extrinsic parameters. Our approach jointly refines camera poses while learning an implicit scene representation that captures fine geometric detail and photorealistic appearance. The resulting meshes are compatible with common 3D graphics and robotics tools, enabling efficient downstream use. Experiments on standard benchmarks demonstrate that our method achieves accurate and robust 3D reconstruction under pose uncertainty, bridging the gap between neural implicit representations and practical robotic applications.

