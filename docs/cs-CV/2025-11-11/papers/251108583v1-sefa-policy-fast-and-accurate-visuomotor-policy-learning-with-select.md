---
layout: default
title: SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment
---

# SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment

**arXiv**: [2511.08583v1](https://arxiv.org/abs/2511.08583) | [PDF](https://arxiv.org/pdf/2511.08583.pdf)

**ä½œè€…**: Rong Xue, Jiageng Mao, Mingtong Zhang, Yue Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€‰æ‹©æ€§æµå¯¹é½ä»¥è§£å†³è§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ ä¸­çš„åŠ¨ä½œåå·®é—®é¢˜**

**å…³é”®è¯**: `è§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ ` `é€‰æ‹©æ€§æµå¯¹é½` `æ•´æµæµæ–¹æ³•` `åŠ¨ä½œä¸€è‡´æ€§æ ¡æ­£` `æœºå™¨äººæ¨¡ä»¿å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ•´æµæµæ–¹æ³•åœ¨è¿­ä»£è’¸é¦åŽï¼Œç”ŸæˆåŠ¨ä½œåç¦»å½“å‰è§†è§‰è§‚å¯Ÿï¼Œå¯¼è‡´ç´¯ç§¯è¯¯å·®å’Œä¸ç¨³å®šæ‰§è¡Œ
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨ä¸“å®¶æ¼”ç¤ºé€‰æ‹©æ€§æ ¡æ­£ç”ŸæˆåŠ¨ä½œï¼Œä¿æŒè§‚å¯Ÿä¸€è‡´æ€§å’Œå¤šæ¨¡æ€æ€§ï¼ŒåŒæ—¶æ”¯æŒä¸€æ­¥æŽ¨ç†
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žæ“ä½œä»»åŠ¡ä¸­è¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œæé«˜å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼ŒæŽ¨ç†å»¶è¿Ÿé™ä½Žè¶…98%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Developing efficient and accurate visuomotor policies poses a central challenge in robotic imitation learning. While recent rectified flow approaches have advanced visuomotor policy learning, they suffer from a key limitation: After iterative distillation, generated actions may deviate from the ground-truth actions corresponding to the current visual observation, leading to accumulated error as the reflow process repeats and unstable task execution. We present Selective Flow Alignment (SeFA), an efficient and accurate visuomotor policy learning framework. SeFA resolves this challenge by a selective flow alignment strategy, which leverages expert demonstrations to selectively correct generated actions and restore consistency with observations, while preserving multimodality. This design introduces a consistency correction mechanism that ensures generated actions remain observation-aligned without sacrificing the efficiency of one-step flow inference. Extensive experiments across both simulated and real-world manipulation tasks show that SeFA Policy surpasses state-of-the-art diffusion-based and flow-based policies, achieving superior accuracy and robustness while reducing inference latency by over 98%. By unifying rectified flow efficiency with observation-consistent action generation, SeFA provides a scalable and dependable solution for real-time visuomotor policy learning. Code is available on https://github.com/RongXueZoe/SeFA.

