---
layout: default
title: ImagebindDC: Compressing Multi-modal Data with Imagebind-based Condensation
---

# ImagebindDC: Compressing Multi-modal Data with Imagebind-based Condensation

**arXiv**: [2511.08263v1](https://arxiv.org/abs/2511.08263) | [PDF](https://arxiv.org/pdf/2511.08263.pdf)

**ä½œè€…**: Yue Min, Shaobo Wang, Jiaze Li, Tianle Niu, Junxin Fan, Yongliang Miao, Lijin Yang, Linfeng Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºImageBindDCä»¥è§£å†³å¤šæ¨¡æ€æ•°æ®åŽ‹ç¼©ä¸­æ¨¡æ€é—´ä¾èµ–ä¿ç•™é—®é¢˜**

**å…³é”®è¯**: `æ•°æ®åŽ‹ç¼©` `å¤šæ¨¡æ€å­¦ä¹ ` `ç‰¹å¾å‡½æ•°æŸå¤±` `ImageBindæ¡†æž¶` `åˆ†å¸ƒå¯¹é½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿæ•°æ®åŽ‹ç¼©æ–¹æ³•åœ¨å¤šæ¨¡æ€åœºæ™¯ä¸­éš¾ä»¥ä¿æŒæ¨¡æ€é—´å¤æ‚ä¾èµ–å…³ç³»
2. æ–¹æ³•è¦ç‚¹ï¼šåœ¨ImageBindç»Ÿä¸€ç‰¹å¾ç©ºé—´ä½¿ç”¨ç‰¹å¾å‡½æ•°æŸå¤±å®žçŽ°ç²¾ç¡®ç»Ÿè®¡å¯¹é½
3. å®žéªŒæ•ˆæžœï¼šåœ¨NYU-v2æ•°æ®é›†ä¸Šï¼Œæ¯ç±»5ä¸ªåŽ‹ç¼©æ•°æ®ç‚¹å®žçŽ°æ— æŸæ€§èƒ½ï¼Œè¶…è¶ŠçŽ°æœ‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Data condensation techniques aim to synthesize a compact dataset from a larger one to enable efficient model training, yet while successful in unimodal settings, they often fail in multimodal scenarios where preserving intricate inter-modal dependencies is crucial. To address this, we introduce ImageBindDC, a novel data condensation framework operating within the unified feature space of ImageBind. Our approach moves beyond conventional distribution-matching by employing a powerful Characteristic Function (CF) loss, which operates in the Fourier domain to facilitate a more precise statistical alignment via exact infinite moment matching. We design our objective to enforce three critical levels of distributional consistency: (i) uni-modal alignment, which matches the statistical properties of synthetic and real data within each modality; (ii) cross-modal alignment, which preserves pairwise semantics by matching the distributions of hybrid real-synthetic data pairs; and (iii) joint-modal alignment, which captures the complete multivariate data structure by aligning the joint distribution of real data pairs with their synthetic counterparts. Extensive experiments highlight the effectiveness of ImageBindDC: on the NYU-v2 dataset, a model trained on just 5 condensed datapoints per class achieves lossless performance comparable to one trained on the full dataset, achieving a new state-of-the-art with an 8.2\% absolute improvement over the previous best method and more than 4$\times$ less condensation time.

