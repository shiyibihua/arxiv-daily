---
layout: default
title: WarpGAN: Warping-Guided 3D GAN Inversion with Style-Based Novel View Inpainting
---

# WarpGAN: Warping-Guided 3D GAN Inversion with Style-Based Novel View Inpainting

**arXiv**: [2511.08178v1](https://arxiv.org/abs/2511.08178) | [PDF](https://arxiv.org/pdf/2511.08178.pdf)

**ä½œè€…**: Kaitao Huang, Yan Yan, Jing-Hao Xue, Hanzi Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWarpGANæ–¹æ³•ä»¥è§£å†³å•è§†å›¾å›¾åƒ3D GANåæ¼”ä¸­é®æŒ¡åŒºåŸŸç”Ÿæˆè´¨é‡å·®çš„é—®é¢˜**

**å…³é”®è¯**: `3D GANåæ¼”` `å•è§†å›¾åˆæˆ` `å›¾åƒä¿®å¤` `å¤šè§†å›¾ä¸€è‡´æ€§` `æ‰­æ›²å¼•å¯¼` `å¯¹ç§°æ€§å…ˆéªŒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰3D GANåæ¼”æ–¹æ³•åœ¨é®æŒ¡åŒºåŸŸç”Ÿæˆè´¨é‡å·®ï¼Œå› ä½Žæ¯”ç‰¹çŽ‡æ½œåœ¨ç å¯¼è‡´ä¿¡æ¯ä¸¢å¤±
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆæ‰­æ›²ä¸Žä¿®å¤ç­–ç•¥ï¼Œä½¿ç”¨SVINetåŸºäºŽå¯¹ç§°æ€§å’Œå¤šè§†å›¾å¯¹åº”ä¿®å¤é®æŒ¡åŒºåŸŸ
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®šé‡å’Œå®šæ€§å®žéªŒæ˜¾ç¤ºï¼ŒWarpGANåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šä¼˜äºŽçŽ°æœ‰å…ˆè¿›æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> 3D GAN inversion projects a single image into the latent space of a pre-trained 3D GAN to achieve single-shot novel view synthesis, which requires visible regions with high fidelity and occluded regions with realism and multi-view consistency. However, existing methods focus on the reconstruction of visible regions, while the generation of occluded regions relies only on the generative prior of 3D GAN. As a result, the generated occluded regions often exhibit poor quality due to the information loss caused by the low bit-rate latent code. To address this, we introduce the warping-and-inpainting strategy to incorporate image inpainting into 3D GAN inversion and propose a novel 3D GAN inversion method, WarpGAN. Specifically, we first employ a 3D GAN inversion encoder to project the single-view image into a latent code that serves as the input to 3D GAN. Then, we perform warping to a novel view using the depth map generated by 3D GAN. Finally, we develop a novel SVINet, which leverages the symmetry prior and multi-view image correspondence w.r.t. the same latent code to perform inpainting of occluded regions in the warped image. Quantitative and qualitative experiments demonstrate that our method consistently outperforms several state-of-the-art methods.

