---
layout: default
title: WarpGAN: Warping-Guided 3D GAN Inversion with Style-Based Novel View Inpainting
---

# WarpGAN: Warping-Guided 3D GAN Inversion with Style-Based Novel View Inpainting

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.08178" target="_blank" class="toolbar-btn">arXiv: 2511.08178v1</a>
    <a href="https://arxiv.org/pdf/2511.08178.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.08178v1" 
            onclick="toggleFavorite(this, '2511.08178v1', 'WarpGAN: Warping-Guided 3D GAN Inversion with Style-Based Novel View Inpainting')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Kaitao Huang, Yan Yan, Jing-Hao Xue, Hanzi Wang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-11

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**WarpGANÔºöÂü∫‰∫éÂΩ¢ÂèòÂºïÂØºÂíåÈ£éÊ†ºÂåñËßÜËßíË°•ÂÖ®ÁöÑ3D GANÂèçÊºî**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `3D GANÂèçÊºî` `Êñ∞ËßÜËßíÂêàÊàê` `ÂõæÂÉèË°•ÂÖ®` `Ê∑±Â∫¶Âõæ` `ÂΩ¢Âèò` `ÈÅÆÊå°Âå∫Âüü` `ÂØπÁß∞ÂÖàÈ™å`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3D GANÂèçÊºîÊñπÊ≥ïÂú®Êñ∞ËßÜËßíÂêàÊàê‰∏≠ÔºåÂØπÈÅÆÊå°Âå∫ÂüüÁöÑÁîüÊàêË¥®Èáè‰∏çÈ´òÔºå‰∏ªË¶Å‰æùËµñÁîüÊàêÂÖàÈ™åÔºåÂØºËá¥‰ø°ÊÅØÊçüÂ§±„ÄÇ
2. WarpGANÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂ∞ÜÂõæÂÉèË°•ÂÖ®ÊäÄÊúØËûçÂÖ•3D GANÂèçÊºîÔºåÈÄöËøáÂΩ¢ÂèòÂíåË°•ÂÖ®Á≠ñÁï•ÔºåÊèêÂçáÈÅÆÊå°Âå∫ÂüüÁöÑÁîüÊàêË¥®Èáè„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåWarpGANÂú®ÂçïËßÜËßíÂõæÂÉèÊñ∞ËßÜËßíÂêàÊàê‰ªªÂä°‰∏≠ÔºåÊòæËëó‰ºò‰∫éÂΩìÂâçÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑ3D GANÂèçÊºîÊñπÊ≥ïWarpGANÔºåÊó®Âú®Ëß£ÂÜ≥ÂçïËßÜËßíÂõæÂÉèÊñ∞ËßÜËßíÂêàÊàê‰∏≠ÈÅÆÊå°Âå∫ÂüüÁîüÊàêË¥®ÈáèÂ∑ÆÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰æßÈáç‰∫éÈáçÂª∫ÂèØËßÅÂå∫ÂüüÔºåËÄåÈÅÆÊå°Âå∫ÂüüÁöÑÁîüÊàê‰ªÖ‰æùËµñ‰∫é3D GANÁöÑÁîüÊàêÂÖàÈ™åÔºåÂØºËá¥‰ΩéÊØîÁâπÁéáÊΩúÂú®ÁºñÁ†ÅÈÄ†Êàê‰ø°ÊÅØÊçüÂ§±ÔºåÁîüÊàêË¥®Èáè‰∏ç‰Ω≥„ÄÇWarpGANÂºïÂÖ•‰∫ÜÂΩ¢ÂèòÂíåË°•ÂÖ®Á≠ñÁï•ÔºåÂ∞ÜÂõæÂÉèË°•ÂÖ®ËûçÂÖ•3D GANÂèçÊºî„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÈ¶ñÂÖà‰ΩøÁî®3D GANÂèçÊºîÁºñÁ†ÅÂô®Â∞ÜÂçïËßÜËßíÂõæÂÉèÊäïÂΩ±Âà∞ÊΩúÂú®Á©∫Èó¥Ôºå‰Ωú‰∏∫3D GANÁöÑËæìÂÖ•„ÄÇÁÑ∂ÂêéÔºåÂà©Áî®3D GANÁîüÊàêÁöÑÊ∑±Â∫¶ÂõæÂ∞ÜÂõæÂÉèÂΩ¢ÂèòÂà∞Êñ∞ÁöÑËßÜËßí„ÄÇÊúÄÂêéÔºåÂºÄÂèë‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑSVINetÔºåÂà©Áî®ÂØπÁß∞ÂÖàÈ™åÂíåÂÖ≥‰∫éÂêå‰∏ÄÊΩúÂú®ÁºñÁ†ÅÁöÑÂ§öËßÜËßíÂõæÂÉèÂØπÂ∫îÂÖ≥Á≥ªÔºåÂØπÂΩ¢ÂèòÂõæÂÉè‰∏≠ÁöÑÈÅÆÊå°Âå∫ÂüüËøõË°åË°•ÂÖ®„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®ÂÆöÈáèÂíåÂÆöÊÄßÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊäÄÊúØ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞Êúâ3D GANÂèçÊºîÊñπÊ≥ïÂú®ÂçïËßÜËßíÂõæÂÉèÊñ∞ËßÜËßíÂêàÊàê‰ªªÂä°‰∏≠Ôºå‰∏ªË¶ÅÂÖ≥Ê≥®ÂèØËßÅÂå∫ÂüüÁöÑÈáçÂª∫ÔºåËÄåÂØπ‰∫éÈÅÆÊå°Âå∫ÂüüÁöÑÁîüÊàêÔºå‰ªÖ‰ªÖ‰æùËµñ‰∫é3D GANÁöÑÁîüÊàêÂÖàÈ™å„ÄÇÁî±‰∫éÊΩúÂú®ÁºñÁ†ÅÁöÑ‰ΩéÊØîÁâπÁéáÁâπÊÄßÔºåÂØºËá¥ÈÅÆÊå°Âå∫ÂüüÁöÑ‰ø°ÊÅØÊçüÂ§±‰∏•ÈáçÔºåÁîüÊàêË¥®ÈáèËæÉÂ∑ÆÔºåÁº∫‰πèÁúüÂÆûÊÑüÂíåÂ§öËßÜËßí‰∏ÄËá¥ÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöWarpGANÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÂõæÂÉèË°•ÂÖ®ÊäÄÊúØËûçÂÖ•Âà∞3D GANÂèçÊºîÊ°ÜÊû∂‰∏≠„ÄÇÈÄöËøáÈ¶ñÂÖàÂ∞ÜÂçïËßÜËßíÂõæÂÉèÊäïÂΩ±Âà∞3D GANÁöÑÊΩúÂú®Á©∫Èó¥ÔºåÁÑ∂ÂêéÂà©Áî®ÁîüÊàêÁöÑÊ∑±Â∫¶ÂõæÂ∞ÜÂõæÂÉèÂΩ¢ÂèòÂà∞Êñ∞ÁöÑËßÜËßíÔºåÊúÄÂêé‰ΩøÁî®‰∏ìÈó®ËÆæËÆ°ÁöÑÁΩëÁªúÂØπÂΩ¢ÂèòÂêéÁöÑÂõæÂÉèËøõË°åÈÅÆÊå°Âå∫ÂüüÁöÑË°•ÂÖ®Ôºå‰ªéËÄåÊèêÈ´òÈÅÆÊå°Âå∫ÂüüÁöÑÁîüÊàêË¥®Èáè„ÄÇËøôÁßçÊñπÊ≥ïÁªìÂêà‰∫Ü3D GANÁöÑÁîüÊàêËÉΩÂäõÂíåÂõæÂÉèË°•ÂÖ®ÁöÑÁªÜËäÇÊÅ¢Â§çËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöWarpGANÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) 3D GANÂèçÊºîÁºñÁ†ÅÂô®ÔºöÂ∞ÜÂçïËßÜËßíÂõæÂÉèÊäïÂΩ±Âà∞3D GANÁöÑÊΩúÂú®Á©∫Èó¥ÔºåÂæóÂà∞ÊΩúÂú®ÁºñÁ†Å„ÄÇ2) ÂΩ¢ÂèòÊ®°ÂùóÔºöÂà©Áî®3D GANÁîüÊàêÁöÑÊ∑±Â∫¶ÂõæÔºåÂ∞ÜÂéüÂßãÂõæÂÉèÂΩ¢ÂèòÂà∞Êñ∞ÁöÑËßÜËßí„ÄÇ3) SVINetÔºàSymmetry and View Inpainting NetworkÔºâÔºö‰∏Ä‰∏™‰∏ìÈó®ËÆæËÆ°ÁöÑÂõæÂÉèË°•ÂÖ®ÁΩëÁªúÔºåÁî®‰∫éÂØπÂΩ¢ÂèòÂêéÁöÑÂõæÂÉèËøõË°åÈÅÆÊå°Âå∫ÂüüÁöÑË°•ÂÖ®„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØÂÖàÂèçÊºîÔºåÂÜçÂΩ¢ÂèòÔºåÊúÄÂêéË°•ÂÖ®„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöWarpGANÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÂõæÂÉèË°•ÂÖ®ÊäÄÊúØ‰∏é3D GANÂèçÊºîÁõ∏ÁªìÂêàÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÂΩ¢ÂèòÂºïÂØºÁöÑË°•ÂÖ®Á≠ñÁï•„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåWarpGAN‰∏çÂÜç‰ªÖ‰ªÖ‰æùËµñ‰∫é3D GANÁöÑÁîüÊàêÂÖàÈ™åÊù•ÁîüÊàêÈÅÆÊå°Âå∫ÂüüÔºåËÄåÊòØÂà©Áî®ÂõæÂÉèË°•ÂÖ®ÊäÄÊúØÊù•ÊÅ¢Â§çÈÅÆÊå°Âå∫ÂüüÁöÑÁªÜËäÇÂíåÁúüÂÆûÊÑü„ÄÇÊ≠§Â§ñÔºåSVINetÁöÑËÆæËÆ°‰πüÂÖÖÂàÜÂà©Áî®‰∫ÜÂØπÁß∞ÂÖàÈ™åÂíåÂ§öËßÜËßíÂõæÂÉèÁöÑÂØπÂ∫îÂÖ≥Á≥ªÔºåËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜË°•ÂÖ®ÊïàÊûú„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöSVINetÊòØWarpGAN‰∏≠ÁöÑÂÖ≥ÈîÆÊ®°ÂùóÔºåÂÖ∂ËÆæËÆ°ËÄÉËôë‰∫Ü‰ª•‰∏ãÂá†‰∏™ÊñπÈù¢Ôºö1) ÂØπÁß∞ÂÖàÈ™åÔºöÂà©Áî®Áâ©‰ΩìÊú¨Ë∫´ÁöÑÂØπÁß∞ÊÄßÊù•Á∫¶ÊùüË°•ÂÖ®ÁªìÊûúÔºåÊèêÈ´òÁîüÊàêË¥®Èáè„ÄÇ2) Â§öËßÜËßíÂõæÂÉèÂØπÂ∫îÂÖ≥Á≥ªÔºöÂà©Áî®Âêå‰∏ÄÊΩúÂú®ÁºñÁ†ÅÂØπÂ∫îÁöÑ‰∏çÂêåËßÜËßíÂõæÂÉè‰πãÈó¥ÁöÑÂØπÂ∫îÂÖ≥Á≥ªÔºåÊù•ÊåáÂØºÈÅÆÊå°Âå∫ÂüüÁöÑË°•ÂÖ®„ÄÇ3) ÊçüÂ§±ÂáΩÊï∞Ôºö‰ΩøÁî®‰∫ÜÂ§öÁßçÊçüÂ§±ÂáΩÊï∞ÔºåÂåÖÊã¨ÈáçÂª∫ÊçüÂ§±„ÄÅÂØπÊäóÊçüÂ§±ÂíåÊÑüÁü•ÊçüÂ§±Ôºå‰ª•‰øùËØÅË°•ÂÖ®ÁªìÊûúÁöÑÁúüÂÆûÊÑüÂíå‰∏ÄËá¥ÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåWarpGANÂú®ÂçïËßÜËßíÂõæÂÉèÊñ∞ËßÜËßíÂêàÊàê‰ªªÂä°‰∏≠ÔºåÊòæËëó‰ºò‰∫éÂΩìÂâçÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇÂú®ÂÆöÈáèÊåáÊ†á‰∏äÔºåWarpGANÂú®PSNR„ÄÅSSIMÁ≠âÊåáÊ†á‰∏äÂùáÂèñÂæó‰∫ÜÊòéÊòæÁöÑÊèêÂçá„ÄÇÂú®ÂÆöÊÄßÊñπÈù¢ÔºåWarpGANÁîüÊàêÁöÑÈÅÆÊå°Âå∫ÂüüÊõ¥Âä†ÁúüÂÆû„ÄÅÁªÜËäÇÊõ¥Âä†‰∏∞ÂØåÔºåÂπ∂‰∏îÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÂ§öËßÜËßí‰∏ÄËá¥ÊÄß„ÄÇ‰æãÂ¶ÇÔºåÂú®CelebAÊï∞ÊçÆÈõÜ‰∏äÔºåWarpGANÁõ∏ÊØî‰∫éÂü∫Á∫øÊñπÊ≥ïÔºåPSNRÊèêÂçá‰∫ÜË∂ÖËøá2dB„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

WarpGANÂú®ÂçïËßÜËßíÂõæÂÉè‰∏âÁª¥ÈáçÂª∫„ÄÅÊñ∞ËßÜËßíÂêàÊàê„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫é‰ªéÂçïÂº†ÁÖßÁâáÁîüÊàêÈÄºÁúüÁöÑ‰∏âÁª¥Ê®°ÂûãÔºåÊàñËÄÖÂú®ËôöÊãüÁéØÂ¢É‰∏≠ÂàõÂª∫Êñ∞ÁöÑËßÜËßíÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™å„ÄÇÊ≠§Â§ñÔºåËØ•ÊäÄÊúØËøòÂèØ‰ª•Â∫îÁî®‰∫éÂõæÂÉèÁºñËæë„ÄÅ‰øÆÂ§çÁ≠â‰ªªÂä°ÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊΩúÂú®ÁöÑÂïÜ‰∏ö‰ª∑ÂÄº„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> 3D GAN inversion projects a single image into the latent space of a pre-trained 3D GAN to achieve single-shot novel view synthesis, which requires visible regions with high fidelity and occluded regions with realism and multi-view consistency. However, existing methods focus on the reconstruction of visible regions, while the generation of occluded regions relies only on the generative prior of 3D GAN. As a result, the generated occluded regions often exhibit poor quality due to the information loss caused by the low bit-rate latent code. To address this, we introduce the warping-and-inpainting strategy to incorporate image inpainting into 3D GAN inversion and propose a novel 3D GAN inversion method, WarpGAN. Specifically, we first employ a 3D GAN inversion encoder to project the single-view image into a latent code that serves as the input to 3D GAN. Then, we perform warping to a novel view using the depth map generated by 3D GAN. Finally, we develop a novel SVINet, which leverages the symmetry prior and multi-view image correspondence w.r.t. the same latent code to perform inpainting of occluded regions in the warped image. Quantitative and qualitative experiments demonstrate that our method consistently outperforms several state-of-the-art methods.

