---
layout: default
title: DT-NVS: Diffusion Transformers for Novel View Synthesis
---

# DT-NVS: Diffusion Transformers for Novel View Synthesis

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.08823" target="_blank" class="toolbar-btn">arXiv: 2511.08823v1</a>
    <a href="https://arxiv.org/pdf/2511.08823.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.08823v1" 
            onclick="toggleFavorite(this, '2511.08823v1', 'DT-NVS: Diffusion Transformers for Novel View Synthesis')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Wonbong Jang, Jonathan Tremblay, Lourdes Agapito

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-11

**Â§áÊ≥®**: 14 pages

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫DT-NVSÔºåÂà©Áî®TransformerÁöÑ3DÊâ©Êï£Ê®°ÂûãÂÆûÁé∞ÁúüÂÆûÂú∫ÊôØÁöÑÊñ∞ËßÜËßíÂêàÊàê**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Êñ∞ËßÜËßíÂêàÊàê` `Êâ©Êï£Ê®°Âûã` `Transformer` `3DÊÑüÁü•` `ÂçïÁõÆËßÜËßâ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑÊñ∞ËßÜËßíÂêàÊàêÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠‰∫éÂ∞èËåÉÂõ¥Áõ∏Êú∫ËøêÂä®ÊàñÈùûËá™ÁÑ∂Áâ©‰Ωì‰∏≠ÂøÉÂú∫ÊôØÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®ÁúüÂÆûÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®„ÄÇ
2. DT-NVSÂà©Áî®TransformerÊû∂ÊûÑÔºåÊûÑÂª∫3DÊÑüÁü•ÁöÑÊâ©Êï£Ê®°ÂûãÔºåÂπ∂ËÆæËÆ°‰∫ÜÁõ∏Êú∫Êù°‰ª∂Á≠ñÁï•Ôºå‰ª•ÈÄÇÂ∫îÁúüÂÆû‰∏ñÁïåÊú™ÂØπÈΩêÁöÑÊï∞ÊçÆÈõÜ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåDT-NVSÂú®ÂçïËßÜËßíÂõæÂÉèÁîüÊàêÊñ∞ËßÜËßí‰ªªÂä°‰∏äÔºåË∂ÖË∂ä‰∫ÜÁé∞Êúâ3DÊÑüÁü•Êâ©Êï£Ê®°ÂûãÂíåÁ°ÆÂÆöÊÄßÊñπÊ≥ïÔºåÂπ∂ËÉΩÁîüÊàêÂ§öÊ†∑ÂåñÁªìÊûú„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÈíàÂØπ‰ªéÂçïËßÜËßíÂõæÂÉèÁîüÊàêËá™ÁÑ∂Âú∫ÊôØÊñ∞ËßÜËßíËøô‰∏ÄÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢ÁöÑÈóÆÈ¢òÔºåÊèêÂá∫‰∫ÜDT-NVSÔºå‰∏ÄÁßçÂü∫‰∫éTransformerÊû∂ÊûÑÁöÑ3DÊÑüÁü•Êâ©Êï£Ê®°ÂûãÔºåÁî®‰∫éÂπø‰πâÊñ∞ËßÜËßíÂêàÊàê„ÄÇËØ•Ê®°ÂûãÂú®ÂåÖÂê´ÁúüÂÆû‰∏ñÁïå„ÄÅÂ§öÁ±ªÂà´„ÄÅÊú™ÂØπÈΩê‰∏îÈöèÊÑèÊãçÊëÑÁöÑÊó•Â∏∏Âú∫ÊôØËßÜÈ¢ëÁöÑÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜ‰∏äÔºå‰ªÖ‰ΩøÁî®ÂõæÂÉèÊçüÂ§±ËøõË°åËÆ≠ÁªÉ„ÄÇËÆ∫ÊñáÂØπTransformerÂíåËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ËøõË°å‰∫ÜÈáçË¶ÅÊîπËøõÔºå‰ª•Â∞ÜÂõæÂÉèËΩ¨Êç¢‰∏∫3DË°®Á§∫ÔºåÂπ∂ÊèêÂá∫‰∫ÜÊñ∞ÁöÑÁõ∏Êú∫Êù°‰ª∂Á≠ñÁï•Ôºå‰ªéËÄåÂèØ‰ª•Âú®ÁúüÂÆû‰∏ñÁïåÊú™ÂØπÈΩêÁöÑÊï∞ÊçÆÈõÜ‰∏äËøõË°åËÆ≠ÁªÉ„ÄÇÊ≠§Â§ñÔºåËøòÂºïÂÖ•‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑËÆ≠ÁªÉËåÉÂºèÔºåÂç≥Âú®Êù°‰ª∂ÂõæÂÉèÂíåÈááÊ†∑ÁöÑÂô™Â£∞ËæìÂÖ•‰πãÈó¥‰∫§Êç¢ÂèÇËÄÉÂ∏ßÁöÑËßíËâ≤„ÄÇÂú®Âπø‰πâÊñ∞ËßÜËßíÂêàÊàê‰ªªÂä°‰∏äÁöÑËØÑ‰º∞Ë°®ÊòéÔºåËØ•ÊñπÊ≥ï‰ºò‰∫éÊúÄÂÖàËøõÁöÑ3DÊÑüÁü•Êâ©Êï£Ê®°ÂûãÂíåÁ°ÆÂÆöÊÄßÊñπÊ≥ïÔºåÂπ∂ËÉΩÁîüÊàêÂ§öÊ†∑ÂåñÁöÑËæìÂá∫„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰ªéÂçïÂº†ÂõæÂÉèÁîüÊàêÁúüÂÆû‰∏ñÁïåÂ§çÊùÇÂú∫ÊôØÁöÑÊñ∞ËßÜËßíÂõæÂÉèÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÁâπÂà´ÊòØÂü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑÊñπÊ≥ïÔºåÈÄöÂ∏∏ÂèóÈôê‰∫éÂ∞èËåÉÂõ¥ÁöÑÁõ∏Êú∫ËøêÂä®ÊàñËÄÖ‰ªÖÈÄÇÁî®‰∫éÁâ©‰Ωì‰∏≠ÂøÉÂú∫ÊôØÔºåÊó†Ê≥ïÂæàÂ•ΩÂú∞Â§ÑÁêÜÁúüÂÆû‰∏ñÁïå‰∏≠Â§öÁ±ªÂà´„ÄÅÊú™ÂØπÈΩêÁöÑÊó•Â∏∏Âú∫ÊôØËßÜÈ¢ë„ÄÇËøô‰∫õÈôêÂà∂ÈòªÁ¢ç‰∫ÜÊñ∞ËßÜËßíÂêàÊàêÊäÄÊúØÂú®Êõ¥ÂπøÊ≥õÁöÑÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊΩúÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®3DÊÑüÁü•ÁöÑÊâ©Êï£Ê®°ÂûãÔºåÁªìÂêàTransformerÊû∂ÊûÑÁöÑÂº∫Â§ßË°®Á§∫ËÉΩÂäõÔºåÂ≠¶‰π†‰ªéÂçïÂº†ÂõæÂÉèÂà∞3DÂú∫ÊôØË°®Á§∫ÁöÑÊò†Â∞ÑÔºåÂπ∂Âú®Ê≠§Âü∫Á°Ä‰∏äÁîüÊàêÊñ∞ÁöÑËßÜËßí„ÄÇÈÄöËøáÂºïÂÖ•Áõ∏Êú∫Êù°‰ª∂Á≠ñÁï•ÂíåÂàõÊñ∞ÁöÑËÆ≠ÁªÉËåÉÂºèÔºåÊ®°ÂûãËÉΩÂ§üÈÄÇÂ∫îÁúüÂÆû‰∏ñÁïåÊú™ÂØπÈΩêÁöÑÊï∞ÊçÆÈõÜÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Âπø‰πâÁöÑÊñ∞ËßÜËßíÂêàÊàê„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöDT-NVSÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÊòØ‰∏Ä‰∏™Âü∫‰∫éTransformerÁöÑ3DÊâ©Êï£Ê®°Âûã„ÄÇ‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) ÂõæÂÉèÁºñÁ†ÅÂô®ÔºöÂ∞ÜËæìÂÖ•ÂõæÂÉèÁºñÁ†ÅÊàêÁâπÂæÅË°®Á§∫„ÄÇ2) 3DË°®Á§∫Ê®°ÂùóÔºöÂà©Áî®ÊîπËøõÁöÑTransformerÂíåËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåÂ∞ÜÂõæÂÉèÁâπÂæÅËΩ¨Êç¢‰∏∫3DÂú∫ÊôØË°®Á§∫„ÄÇ3) Áõ∏Êú∫Êù°‰ª∂Ê®°ÂùóÔºöÂ∞ÜÁõÆÊ†áÁõ∏Êú∫ÁöÑ‰ΩçÂßø‰ø°ÊÅØËûçÂÖ•Âà∞Ê®°Âûã‰∏≠ÔºåÊåáÂØºÊñ∞ËßÜËßíÁöÑÁîüÊàê„ÄÇ4) Êâ©Êï£Ê®°ÂûãÔºöÈÄöËøáÈÄêÊ≠•ÂéªÂô™ÁöÑËøáÁ®ãÔºå‰ªéÂô™Â£∞‰∏≠ÁîüÊàêÊñ∞ËßÜËßíÁöÑÂõæÂÉè„ÄÇËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÈááÁî®‰∫ÜÂõæÂÉèÊçüÂ§±ÂáΩÊï∞Êù•‰ºòÂåñÊ®°Âûã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ª•‰∏ãÂá†‰∏™ÊñπÈù¢Ôºö1) ÈíàÂØπTransformerÂíåËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÊîπËøõÔºå‰ΩøÂÖ∂Êõ¥ÈÄÇÂêà‰∫éÂõæÂÉèÂà∞3DË°®Á§∫ÁöÑËΩ¨Êç¢„ÄÇ2) Êñ∞ÁöÑÁõ∏Êú∫Êù°‰ª∂Á≠ñÁï•ÔºåÂÖÅËÆ∏Ê®°ÂûãÂú®ÁúüÂÆû‰∏ñÁïåÊú™ÂØπÈΩêÁöÑÊï∞ÊçÆÈõÜ‰∏äËøõË°åËÆ≠ÁªÉ„ÄÇ3) ÂàõÊñ∞ÁöÑËÆ≠ÁªÉËåÉÂºèÔºåÂç≥Âú®Êù°‰ª∂ÂõæÂÉèÂíåÈááÊ†∑ÁöÑÂô™Â£∞ËæìÂÖ•‰πãÈó¥‰∫§Êç¢ÂèÇËÄÉÂ∏ßÁöÑËßíËâ≤ÔºåÂ¢ûÂº∫‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÁΩëÁªúÁªìÊûÑÊñπÈù¢ÔºåËÆ∫ÊñáÂèØËÉΩÈááÁî®‰∫ÜÊüêÁßçÂΩ¢ÂºèÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂Ôºå‰æãÂ¶ÇSparse AttentionÊàñËÄÖAxial AttentionÔºå‰ª•Èôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶„ÄÇÂú®ÊçüÂ§±ÂáΩÊï∞ÊñπÈù¢ÔºåÈô§‰∫ÜÂ∏∏ËßÅÁöÑL1ÊàñL2ÊçüÂ§±Â§ñÔºåÂèØËÉΩËøò‰ΩøÁî®‰∫ÜÊÑüÁü•ÊçüÂ§±ÊàñÂØπÊäóÊçüÂ§±Ôºå‰ª•ÊèêÈ´òÁîüÊàêÂõæÂÉèÁöÑË¥®Èáè„ÄÇÁõ∏Êú∫Êù°‰ª∂Ê®°ÂùóÁöÑËÆæËÆ°‰πüËá≥ÂÖ≥ÈáçË¶ÅÔºåÈúÄË¶ÅÊúâÊïàÂú∞Â∞ÜÁõ∏Êú∫‰ΩçÂßø‰ø°ÊÅØËûçÂÖ•Âà∞Ê®°Âûã‰∏≠Ôºå‰æãÂ¶ÇÈÄöËøáÁâπÂæÅËûçÂêàÊàñÊù°‰ª∂ÂΩí‰∏ÄÂåñÁ≠âÊñπÂºè„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

DT-NVSÂú®Âπø‰πâÊñ∞ËßÜËßíÂêàÊàê‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑ3DÊÑüÁü•Êâ©Êï£Ê®°ÂûãÂíåÁ°ÆÂÆöÊÄßÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜÊëòË¶ÅÂº∫Ë∞É‰∫ÜÂÖ∂Âú®ÁîüÊàêÂ§öÊ†∑ÂåñËæìÂá∫ÊñπÈù¢ÁöÑ‰ºòÂäø„ÄÇËØ•ÊñπÊ≥ïÂú®Â§ÑÁêÜÁúüÂÆû‰∏ñÁïå„ÄÅÂ§öÁ±ªÂà´„ÄÅÊú™ÂØπÈΩêÁöÑÊó•Â∏∏Âú∫ÊôØËßÜÈ¢ëÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤ÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊΩúÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆû„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Êú∫Âô®‰∫∫ÂØºËà™‰∏≠ÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Âà©Áî®ÂçïÁõÆÊëÑÂÉèÂ§¥ÊãçÊëÑÁöÑÂõæÂÉèÔºåÁîüÊàêÂë®Âõ¥ÁéØÂ¢ÉÁöÑÊñ∞ËßÜËßíÂõæÂÉèÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÁêÜËß£ÁéØÂ¢ÉÂπ∂ËßÑÂàíË∑ØÂæÑ„ÄÇÂú®ËôöÊãüÁé∞ÂÆû‰∏≠ÔºåÁî®Êà∑ÂèØ‰ª•ÈÄöËøáÂçïÂº†ÁÖßÁâáÁîüÊàêÈÄºÁúüÁöÑ3DÂú∫ÊôØÔºå‰ªéËÄåËé∑ÂæóÊõ¥Ê≤âÊµ∏ÂºèÁöÑ‰ΩìÈ™å„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Generating novel views of a natural scene, e.g., every-day scenes both indoors and outdoors, from a single view is an under-explored problem, even though it is an organic extension to the object-centric novel view synthesis. Existing diffusion-based approaches focus rather on small camera movements in real scenes or only consider unnatural object-centric scenes, limiting their potential applications in real-world settings. In this paper we move away from these constrained regimes and propose a 3D diffusion model trained with image-only losses on a large-scale dataset of real-world, multi-category, unaligned, and casually acquired videos of everyday scenes. We propose DT-NVS, a 3D-aware diffusion model for generalized novel view synthesis that exploits a transformer-based architecture backbone. We make significant contributions to transformer and self-attention architectures to translate images to 3d representations, and novel camera conditioning strategies to allow training on real-world unaligned datasets. In addition, we introduce a novel training paradigm swapping the role of reference frame between the conditioning image and the sampled noisy input. We evaluate our approach on the 3D task of generalized novel view synthesis from a single input image and show improvements over state-of-the-art 3D aware diffusion models and deterministic approaches, while generating diverse outputs.

