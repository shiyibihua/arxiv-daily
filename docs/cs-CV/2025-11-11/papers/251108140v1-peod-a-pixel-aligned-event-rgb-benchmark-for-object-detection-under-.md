---
layout: default
title: PEOD: A Pixel-Aligned Event-RGB Benchmark for Object Detection under Challenging Conditions
---

# PEOD: A Pixel-Aligned Event-RGB Benchmark for Object Detection under Challenging Conditions

**arXiv**: [2511.08140v1](https://arxiv.org/abs/2511.08140) | [PDF](https://arxiv.org/pdf/2511.08140.pdf)

**ä½œè€…**: Luoping Cui, Hanqing Liu, Mingjie Liu, Endian Lin, Donghong Jiang, Yuhao Wang, Chuang Zhu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPEODæ•°æ®é›†ä»¥è§£å†³æŒ‘æˆ˜æ¡ä»¶ä¸‹äº‹ä»¶-RGBç›®æ ‡æ£€æµ‹çš„åŸºå‡†ä¸è¶³é—®é¢˜**

**å…³é”®è¯**: `äº‹ä»¶ç›¸æœº` `ç›®æ ‡æ£€æµ‹` `å¤šæ¨¡æ€èžåˆ` `æŒ‘æˆ˜æ¡ä»¶` `é«˜åˆ†è¾¨çŽ‡æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰äº‹ä»¶-RGBæ•°æ®é›†è¦†ç›–æžç«¯æ¡ä»¶ç¨€ç–ä¸”åˆ†è¾¨çŽ‡ä½Žï¼Œé˜»ç¢é²æ£’æ£€æµ‹è¯„ä¼°
2. æž„å»ºé¦–ä¸ªå¤§è§„æ¨¡åƒç´ å¯¹é½é«˜åˆ†è¾¨çŽ‡äº‹ä»¶-RGBæ•°æ®é›†ï¼Œå«130+åºåˆ—å’Œ34ä¸‡æ ‡æ³¨æ¡†
3. åŸºå‡†æµ‹è¯•æ˜¾ç¤ºèžåˆæ¨¡åž‹åœ¨æ­£å¸¸æ¡ä»¶ä¸‹ä¼˜ï¼Œäº‹ä»¶æ¨¡åž‹åœ¨å…‰ç…§æŒ‘æˆ˜ä¸‹é¢†å…ˆèžåˆæ¨¡åž‹

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Robust object detection for challenging scenarios increasingly relies on event cameras, yet existing Event-RGB datasets remain constrained by sparse coverage of extreme conditions and low spatial resolution (<= 640 x 480), which prevents comprehensive evaluation of detectors under challenging scenarios. To address these limitations, we propose PEOD, the first large-scale, pixel-aligned and high-resolution (1280 x 720) Event-RGB dataset for object detection under challenge conditions. PEOD contains 130+ spatiotemporal-aligned sequences and 340k manual bounding boxes, with 57% of data captured under low-light, overexposure, and high-speed motion. Furthermore, we benchmark 14 methods across three input configurations (Event-based, RGB-based, and Event-RGB fusion) on PEOD. On the full test set and normal subset, fusion-based models achieve the excellent performance. However, in illumination challenge subset, the top event-based model outperforms all fusion models, while fusion models still outperform their RGB-based counterparts, indicating limits of existing fusion methods when the frame modality is severely degraded. PEOD establishes a realistic, high-quality benchmark for multimodal perception and facilitates future research.

