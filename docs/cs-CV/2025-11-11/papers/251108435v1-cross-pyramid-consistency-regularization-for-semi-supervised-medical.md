---
layout: default
title: Cross-pyramid consistency regularization for semi-supervised medical image segmentation
---

# Cross-pyramid consistency regularization for semi-supervised medical image segmentation

**arXiv**: [2511.08435v1](https://arxiv.org/abs/2511.08435) | [PDF](https://arxiv.org/pdf/2511.08435.pdf)

**ä½œè€…**: Matus Bojko, Maros Kollar, Marek Jakab, Wanda Benesova

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè·¨é‡‘å­—å¡”ä¸€è‡´æ€§æ­£åˆ™åŒ–ä»¥æå‡åŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²æ€§èƒ½**

**å…³é”®è¯**: `åŠç›‘ç£å­¦ä¹ ` `åŒ»å­¦å›¾åƒåˆ†å‰²` `ä¸€è‡´æ€§æ­£åˆ™åŒ–` `é‡‘å­—å¡”ç½‘ç»œ` `çŸ¥è¯†è’¸é¦`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŠç›‘ç£å­¦ä¹ åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­å¦‚ä½•æœ‰æ•ˆåˆ©ç”¨æœªæ ‡è®°æ•°æ®
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡åŒåˆ†æ”¯é‡‘å­—å¡”ç½‘ç»œï¼Œç»“åˆè·¨è§£ç å™¨é‡‘å­—å¡”é¢„æµ‹ä¸€è‡´æ€§æ­£åˆ™åŒ–
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å…¬å…±æ•°æ®é›†ä¸Šä¼˜äºŽäº”ç§è‡ªç›‘ç£æ–¹æ³•ï¼Œä¸Žæœ€æ–°æ–¹æ³•æ€§èƒ½ç›¸å½“

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Semi-supervised learning (SSL) enables training of powerful models with the assumption of limited, carefully labelled data and a large amount of unlabeled data to support the learning. In this paper, we propose a hybrid consistency learning approach to effectively exploit unlabeled data for semi-supervised medical image segmentation by leveraging Cross-Pyramid Consistency Regularization (CPCR) between two decoders. First, we design a hybrid Dual Branch Pyramid Network (DBPNet), consisting of an encoder and two decoders that differ slightly, each producing a pyramid of perturbed auxiliary predictions across multiple resolution scales. Second, we present a learning strategy for this network named CPCR that combines existing consistency learning and uncertainty minimization approaches on the main output predictions of decoders with our novel regularization term. More specifically, in this term, we extend the soft-labeling setting to pyramid predictions across decoders to support knowledge distillation in deep hierarchical features. Experimental results show that DBPNet with CPCR outperforms five state-of-the-art self-supervised learning methods and has comparable performance with recent ones on a public benchmark dataset.

