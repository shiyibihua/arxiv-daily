---
layout: default
title: Perceptual Quality Assessment of 3D Gaussian Splatting: A Subjective Dataset and Prediction Metric
---

# Perceptual Quality Assessment of 3D Gaussian Splatting: A Subjective Dataset and Prediction Metric

**arXiv**: [2511.08032v1](https://arxiv.org/abs/2511.08032) | [PDF](https://arxiv.org/pdf/2511.08032.pdf)

**ä½œè€…**: Zhaolin Wan, Yining Diao, Jingqi Xu, Hao Wang, Zhiyang Li, Xiaopeng Fan, Wangmeng Zuo, Debin Zhao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/diaoyn/3DGSQA)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡º3DGS-QAæ•°æ®é›†ä¸Žæ— å‚è€ƒè´¨é‡è¯„ä¼°æ¨¡åž‹ï¼Œè§£å†³3Dé«˜æ–¯æº…å°„æ„ŸçŸ¥è´¨é‡è¯„ä¼°é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Dé«˜æ–¯æº…å°„` `è´¨é‡è¯„ä¼°` `æ„ŸçŸ¥è´¨é‡` `æ— å‚è€ƒè¯„ä¼°` `ä¸»è§‚æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰3DGSè´¨é‡è¯„ä¼°ç¼ºä¹ç³»ç»Ÿç ”ç©¶ï¼Œå°¤å…¶æ˜¯åœ¨å„ç§é‡å»ºæ¡ä»¶ä¸‹çš„æ„ŸçŸ¥è´¨é‡è¯„ä¼°ã€‚
2. æå‡ºä¸€ç§æ— éœ€å‚è€ƒçš„è´¨é‡é¢„æµ‹æ¨¡åž‹ï¼Œç›´æŽ¥ä½œç”¨äºŽ3Dé«˜æ–¯åŸºå…ƒï¼Œæå–ç©ºé—´å’Œå…‰åº¦çº¿ç´¢ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨3DGSå†…å®¹è¯„ä¼°ä¸­è¡¨çŽ°å‡ºä¼˜è¶Šçš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€3Då¯è§†åŒ–çš„å¿«é€Ÿå‘å±•ï¼Œ3Dé«˜æ–¯æº…å°„(3DGS)å·²æˆä¸ºå®žæ—¶ã€é«˜ä¿çœŸæ¸²æŸ“çš„ä¸»æµæŠ€æœ¯ã€‚è™½ç„¶ä¹‹å‰çš„ç ”ç©¶å¼ºè°ƒäº†ç®—æ³•æ€§èƒ½å’Œè§†è§‰ä¿çœŸåº¦ï¼Œä½†3DGSæ¸²æŸ“å†…å®¹çš„æ„ŸçŸ¥è´¨é‡ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒçš„é‡å»ºæ¡ä»¶ä¸‹ï¼Œåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä»æœªè¢«æŽ¢ç´¢ã€‚å®žé™…ä¸Šï¼Œè§†ç‚¹ç¨€ç–æ€§ã€æœ‰é™çš„è®­ç»ƒè¿­ä»£æ¬¡æ•°ã€ç‚¹é™é‡‡æ ·ã€å™ªå£°å’Œé¢œè‰²å¤±çœŸç­‰å› ç´ ä¼šæ˜¾è‘—é™ä½Žè§†è§‰è´¨é‡ï¼Œä½†å®ƒä»¬å¯¹æ„ŸçŸ¥çš„å½±å“å°šæœªå¾—åˆ°ç³»ç»Ÿç ”ç©¶ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†3DGS-QAï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªé’ˆå¯¹3DGSçš„ä¸»è§‚è´¨é‡è¯„ä¼°æ•°æ®é›†ã€‚å®ƒåŒ…å«15ç§å¯¹è±¡ç±»åž‹çš„225ä¸ªé™çº§é‡å»ºï¼Œä»Žè€Œèƒ½å¤Ÿå¯¹å¸¸è§å¤±çœŸå› ç´ è¿›è¡Œå—æŽ§ç ”ç©¶ã€‚åŸºäºŽæ­¤æ•°æ®é›†ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ— éœ€å‚è€ƒçš„è´¨é‡é¢„æµ‹æ¨¡åž‹ï¼Œè¯¥æ¨¡åž‹ç›´æŽ¥åœ¨åŽŸç”Ÿ3Dé«˜æ–¯åŸºå…ƒä¸Šè¿è¡Œï¼Œè€Œæ— éœ€æ¸²æŸ“å›¾åƒæˆ–ground-truthå‚è€ƒã€‚æˆ‘ä»¬çš„æ¨¡åž‹ä»Žé«˜æ–¯è¡¨ç¤ºä¸­æå–ç©ºé—´å’Œå…‰åº¦çº¿ç´¢ï¼Œä»¥ç»“æž„æ„ŸçŸ¥çš„æ–¹å¼ä¼°è®¡æ„ŸçŸ¥è´¨é‡ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å¯¹çŽ°æœ‰çš„è´¨é‡è¯„ä¼°æ–¹æ³•è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬ä¼ ç»Ÿæ–¹æ³•å’ŒåŸºäºŽå­¦ä¹ çš„æ–¹æ³•ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆèƒ½èŽ·å¾—ä¼˜è¶Šçš„æ€§èƒ½ï¼Œçªå‡ºäº†å…¶åœ¨3DGSå†…å®¹è¯„ä¼°ä¸­çš„é²æ£’æ€§å’Œæœ‰æ•ˆæ€§ã€‚æ•°æ®é›†å’Œä»£ç å·²åœ¨https://github.com/diaoyn/3DGSQAä¸Šå…¬å¼€å‘å¸ƒï¼Œä»¥ä¿ƒè¿›æœªæ¥åœ¨3DGSè´¨é‡è¯„ä¼°æ–¹é¢çš„ç ”ç©¶ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³3Dé«˜æ–¯æº…å°„ï¼ˆ3DGSï¼‰æ¸²æŸ“ç»“æžœçš„æ„ŸçŸ¥è´¨é‡è¯„ä¼°é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•è¦ä¹ˆä¾èµ–äºŽæ¸²æŸ“åŽçš„å›¾åƒè¿›è¡Œè¯„ä¼°ï¼Œè¦ä¹ˆéœ€è¦ground-truthä½œä¸ºå‚è€ƒï¼Œæ— æ³•ç›´æŽ¥å¯¹3Dé«˜æ–¯åŸºå…ƒè¿›è¡Œè´¨é‡è¯„ä¼°ï¼Œä¸”ç¼ºä¹é’ˆå¯¹3DGSç‰¹å®šå¤±çœŸå› ç´ çš„ç³»ç»Ÿç ”ç©¶ã€‚è¿™äº›ç—›ç‚¹é™åˆ¶äº†3DGSåœ¨å®žé™…åº”ç”¨ä¸­çš„è´¨é‡æŽ§åˆ¶å’Œä¼˜åŒ–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç›´æŽ¥ä»Ž3Dé«˜æ–¯åŸºå…ƒä¸­æå–ç‰¹å¾ï¼Œæž„å»ºä¸€ä¸ªæ— éœ€å‚è€ƒçš„è´¨é‡è¯„ä¼°æ¨¡åž‹ã€‚è¯¥æ¨¡åž‹é€šè¿‡åˆ†æžé«˜æ–¯åˆ†å¸ƒçš„ç©ºé—´å’Œå…‰åº¦å±žæ€§ï¼Œæ¥é¢„æµ‹äººç±»å¯¹æ¸²æŸ“ç»“æžœçš„æ„ŸçŸ¥è´¨é‡ã€‚è¿™ç§æ–¹æ³•é¿å…äº†æ¸²æŸ“è¿‡ç¨‹ï¼Œæé«˜äº†è¯„ä¼°æ•ˆçŽ‡ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰3DGSç‰¹æœ‰çš„å¤±çœŸæ¨¡å¼ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æž„å»º3DGS-QAæ•°æ®é›†ï¼ŒåŒ…å«ä¸åŒå¯¹è±¡å’Œä¸åŒå¤±çœŸç¨‹åº¦çš„3DGSé‡å»ºç»“æžœï¼Œå¹¶è¿›è¡Œä¸»è§‚è´¨é‡è¯„ä¼°ï¼›2) è®¾è®¡ç‰¹å¾æå–æ¨¡å—ï¼Œä»Žæ¯ä¸ªé«˜æ–¯åŸºå…ƒä¸­æå–ç©ºé—´ï¼ˆå¦‚ä½ç½®ã€å°ºåº¦ã€æ—‹è½¬ï¼‰å’Œå…‰åº¦ï¼ˆå¦‚é¢œè‰²ã€é€æ˜Žåº¦ï¼‰ç‰¹å¾ï¼›3) æž„å»ºè´¨é‡é¢„æµ‹æ¨¡åž‹ï¼Œåˆ©ç”¨æå–çš„ç‰¹å¾é¢„æµ‹æ„ŸçŸ¥è´¨é‡å¾—åˆ†ã€‚è¯¥æ¨¡åž‹å¯ä»¥ä½¿ç”¨æœºå™¨å­¦ä¹ æˆ–æ·±åº¦å­¦ä¹ æ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽæå‡ºäº†ä¸€ä¸ªç›´æŽ¥ä½œç”¨äºŽ3Dé«˜æ–¯åŸºå…ƒçš„æ— éœ€å‚è€ƒè´¨é‡è¯„ä¼°æ¨¡åž‹ã€‚ä¸Žä¼ ç»Ÿçš„åŸºäºŽå›¾åƒçš„è´¨é‡è¯„ä¼°æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•æ‰3DGSç‰¹æœ‰çš„å¤±çœŸæ¨¡å¼ï¼Œå¹¶ä¸”é¿å…äº†æ¸²æŸ“è¿‡ç¨‹ï¼Œæé«˜äº†è¯„ä¼°æ•ˆçŽ‡ã€‚æ­¤å¤–ï¼Œ3DGS-QAæ•°æ®é›†çš„æž„å»ºä¹Ÿä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†å®è´µèµ„æºã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç‰¹å¾æå–æ¨¡å—çš„è®¾è®¡ï¼Œéœ€è¦é€‰æ‹©èƒ½å¤Ÿæœ‰æ•ˆè¡¨å¾é«˜æ–¯åŸºå…ƒè´¨é‡çš„ç‰¹å¾ï¼›2) è´¨é‡é¢„æµ‹æ¨¡åž‹çš„é€‰æ‹©å’Œè®­ç»ƒï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„æ¨¡åž‹ç»“æž„å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥å®žçŽ°å‡†ç¡®çš„è´¨é‡é¢„æµ‹ï¼›3) æ•°æ®é›†çš„æž„å»ºï¼Œéœ€è¦è¦†ç›–ä¸åŒçš„å¯¹è±¡å’Œå¤±çœŸç¨‹åº¦ï¼Œä»¥ä¿è¯æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æž„ç­‰ç»†èŠ‚åœ¨è®ºæ–‡ä¸­åº”è¯¥æœ‰è¯¦ç»†æè¿°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨3DGSè´¨é‡è¯„ä¼°ä»»åŠ¡ä¸­å–å¾—äº†ä¼˜è¶Šçš„æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰çš„ä¼ ç»Ÿå’ŒåŸºäºŽå­¦ä¹ çš„è´¨é‡è¯„ä¼°æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•åœ¨3DGS-QAæ•°æ®é›†ä¸Šå–å¾—äº†æœ€é«˜çš„é¢„æµ‹å‡†ç¡®çŽ‡å’Œä¸€è‡´æ€§ï¼Œè¯æ˜Žäº†å…¶åœ¨3DGSå†…å®¹è¯„ä¼°ä¸­çš„é²æ£’æ€§å’Œæœ‰æ•ˆæ€§ã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽ3Då†…å®¹åˆ›ä½œã€3Dé‡å»ºå’Œå®žæ—¶æ¸²æŸ“ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥å¸®åŠ©å¼€å‘è€…è¯„ä¼°å’Œä¼˜åŒ–3DGSæ¸²æŸ“ç»“æžœçš„è´¨é‡ï¼Œæé«˜ç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºŽè‡ªåŠ¨åŒ–çš„3Då†…å®¹è´¨é‡æŽ§åˆ¶ï¼Œä¾‹å¦‚åœ¨3Dæ¨¡åž‹åº“ä¸­ç­›é€‰é«˜è´¨é‡çš„æ¨¡åž‹ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥æ‰©å±•åˆ°å…¶ä»–åŸºäºŽç‚¹çš„æ¸²æŸ“æŠ€æœ¯ï¼Œå¹¶ä¸Žå…¶ä»–è´¨é‡è¯„ä¼°æ–¹æ³•ç›¸ç»“åˆï¼Œè¿›ä¸€æ­¥æé«˜3Då†…å®¹è´¨é‡è¯„ä¼°çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> With the rapid advancement of 3D visualization, 3D Gaussian Splatting (3DGS) has emerged as a leading technique for real-time, high-fidelity rendering. While prior research has emphasized algorithmic performance and visual fidelity, the perceptual quality of 3DGS-rendered content, especially under varying reconstruction conditions, remains largely underexplored. In practice, factors such as viewpoint sparsity, limited training iterations, point downsampling, noise, and color distortions can significantly degrade visual quality, yet their perceptual impact has not been systematically studied. To bridge this gap, we present 3DGS-QA, the first subjective quality assessment dataset for 3DGS. It comprises 225 degraded reconstructions across 15 object types, enabling a controlled investigation of common distortion factors. Based on this dataset, we introduce a no-reference quality prediction model that directly operates on native 3D Gaussian primitives, without requiring rendered images or ground-truth references. Our model extracts spatial and photometric cues from the Gaussian representation to estimate perceived quality in a structure-aware manner. We further benchmark existing quality assessment methods, spanning both traditional and learning-based approaches. Experimental results show that our method consistently achieves superior performance, highlighting its robustness and effectiveness for 3DGS content evaluation. The dataset and code are made publicly available at https://github.com/diaoyn/3DGSQA to facilitate future research in 3DGS quality assessment.

