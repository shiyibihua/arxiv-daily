---
layout: default
title: Omni Survey for Multimodality Analysis in Visual Object Tracking
---

# Omni Survey for Multimodality Analysis in Visual Object Tracking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13000" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.13000v1</a>
  <a href="https://arxiv.org/pdf/2508.13000.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13000v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13000v1', 'Omni Survey for Multimodality Analysis in Visual Object Tracking')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zhangyong Tang, Tianyang Xu, Xuefeng Zhu, Hui Li, Shaochuan Zhao, Tao Zhou, Chunyang Cheng, Xiaojun Wu, Josef Kittler

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-18

**Â§áÊ≥®**: The first comprehensive survey for multi-modal visual object tracking; 6 multi-modal tasks; 338 references

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Â§öÊ®°ÊÄÅËßÜËßâÁõÆÊ†áË∑üË∏™ÁöÑÂÖ®ÊôØË∞ÉÊü•‰ª•Ëß£ÂÜ≥Êï∞ÊçÆÊï¥ÂêàÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅËßÜËßâË∑üË∏™` `Êï∞ÊçÆÊï¥Âêà` `Ê®°ÊÄÅÂØπÈΩê` `Êô∫ËÉΩÁõëÊéß` `ÈïøÂ∞æÁâπÊÄß` `ÁõÆÊ†áË∑üË∏™`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂ§öÊ®°ÊÄÅËßÜËßâÁõÆÊ†áË∑üË∏™ÊñπÊ≥ïÂú®Êï∞ÊçÆÊï¥ÂêàÂíåÊ®°ÊÄÅÂØπÈΩêÊñπÈù¢Èù¢‰∏¥ËØ∏Â§öÊåëÊàòÔºåÂΩ±Âìç‰∫ÜË∑üË∏™ÊÄßËÉΩ„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁ≥ªÁªüÂåñÁöÑÂ§öÊ®°ÊÄÅËßÜËßâÁõÆÊ†áË∑üË∏™Ë∞ÉÊü•ÔºåÊ∂µÁõñÊï∞ÊçÆÊî∂ÈõÜ„ÄÅÂØπÈΩê„ÄÅÊ®°ÂûãËÆæËÆ°Á≠âÂ§ö‰∏™ÊñπÈù¢„ÄÇ
3. ÈÄöËøáÂØπ338‰∏™ÂèÇËÄÉÊñáÁåÆÁöÑÂàÜÊûêÔºåÊè≠Á§∫‰∫ÜÂ§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜÁöÑÁ±ªÂà´ÂàÜÂ∏ÉÁâπÂæÅÔºå‰∏∫ÂêéÁª≠Á†îÁ©∂Êèê‰æõ‰∫ÜÈáçË¶ÅÂèÇËÄÉ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÊô∫ÊÖßÂüéÂ∏ÇÁöÑÂèëÂ±ïÔºå‰∫ßÁîü‰∫ÜÂ§ßÈáèÂ§öÊ®°ÊÄÅÊï∞ÊçÆÔºåÊú¨Êñá‰ªéÂ§öÊ®°ÊÄÅÂàÜÊûêÁöÑËßíÂ∫¶ÂØπÂ§öÊ®°ÊÄÅËßÜËßâÁõÆÊ†áË∑üË∏™ÔºàMMVOTÔºâËøõË°å‰∫ÜÂÖ®Èù¢Ë∞ÉÊü•„ÄÇMMVOTÂú®Êï∞ÊçÆÊî∂ÈõÜ„ÄÅÊ®°ÊÄÅÂØπÈΩê‰∏éÊ†áÊ≥®„ÄÅÊ®°ÂûãËÆæËÆ°ÂíåËØÑ‰º∞Á≠âÊñπÈù¢‰∏éÂçïÊ®°ÊÄÅË∑üË∏™Â≠òÂú®ÊòæËëóÂ∑ÆÂºÇ„ÄÇÊñáÁ´†ËÆ®ËÆ∫‰∫ÜÂ§öÊ®°ÊÄÅÊï∞ÊçÆÁöÑÊî∂ÈõÜ„ÄÅÂØπÈΩêÂíåÊ†áÊ≥®ÁöÑÊåëÊàòÔºåÂπ∂ÂØπÁé∞ÊúâMMVOTÊñπÊ≥ïËøõË°å‰∫ÜÂàÜÁ±ªÔºåÊúÄÂêéÊé¢ËÆ®‰∫ÜËØÑ‰º∞‰∏éÂü∫ÂáÜÊµãËØï„ÄÇÊàë‰ª¨È¶ñÊ¨°ÂàÜÊûê‰∫ÜÁé∞ÊúâMMVOTÊï∞ÊçÆÈõÜ‰∏≠ÂØπË±°Á±ªÂà´ÁöÑÂàÜÂ∏ÉÔºåÊè≠Á§∫‰∫ÜÂÖ∂ÊòéÊòæÁöÑÈïøÂ∞æÁâπÊÄßÂíå‰∏éRGBÊï∞ÊçÆÈõÜÁõ∏ÊØîÂä®Áâ©Á±ªÂà´ÁöÑÁº∫‰πè„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅËßÜËßâÁõÆÊ†áË∑üË∏™‰∏≠ÁöÑÊï∞ÊçÆÊï¥Âêà‰∏éÊ®°ÊÄÅÂØπÈΩêÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜ‰∏çÂêåÊ®°ÊÄÅÊï∞ÊçÆÊó∂ÔºåÂæÄÂæÄÁº∫‰πèÁ≥ªÁªüÊÄßÔºåÂØºËá¥Ë∑üË∏™ÊïàÊûú‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÂØπÂ§öÊ®°ÊÄÅÊï∞ÊçÆÁöÑÂÖ®Èù¢Ë∞ÉÊü•ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÁ≥ªÁªüÂåñÁöÑÊñπÊ≥ïÊù•Êï¥Âêà‰∏çÂêåÊ®°ÊÄÅÁöÑ‰ø°ÊÅØÔºå‰ªéËÄåÊèêÂçáË∑üË∏™ÊÄßËÉΩ„ÄÇËØ•ÊñπÊ≥ïÂº∫Ë∞É‰∫ÜÊ®°ÊÄÅ‰πãÈó¥ÁöÑÂØπÈΩê‰∏éÊ†áÊ≥®ÁöÑÈáçË¶ÅÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÊî∂ÈõÜ„ÄÅÊ®°ÊÄÅÂØπÈΩê„ÄÅÊ®°ÂûãËÆæËÆ°ÂíåËØÑ‰º∞Âõõ‰∏™‰∏ªË¶ÅÊ®°Âùó„ÄÇÊØè‰∏™Ê®°ÂùóÈÉΩÈíàÂØπÁâπÂÆöÁöÑÊåëÊàòËøõË°åËÆæËÆ°ÔºåÁ°Æ‰øù‰ø°ÊÅØÁöÑÊúâÊïàËûçÂêà„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊñáÁ´†È¶ñÊ¨°Á≥ªÁªüÊÄßÂú∞ÂàÜÊûê‰∫ÜÂ§öÊ®°ÊÄÅËßÜËßâÁõÆÊ†áË∑üË∏™ÁöÑÂêÑ‰∏™ÊñπÈù¢ÔºåÁâπÂà´ÊòØÂØπÊï∞ÊçÆÈõÜÁ±ªÂà´ÂàÜÂ∏ÉÁöÑÂàÜÊûêÔºåÊè≠Á§∫‰∫ÜÈïøÂ∞æÁâπÊÄß‰∏éÂä®Áâ©Á±ªÂà´ÁöÑÁº∫‰πè„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫Ü‰∏çÂêåÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÔºå‰ª•ÈÄÇÂ∫îÂ§öÊ®°ÊÄÅÊï∞ÊçÆÁöÑÁâπÊÄßÔºåÂπ∂ÈÄöËøáÂÆûÈ™åÈ™åËØÅ‰∫ÜËøô‰∫õËÆæËÆ°ÁöÑÊúâÊïàÊÄß„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÊû∂ÊûÑÁöÑÁªÜËäÇÂú®Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊú¨ÊñáÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Â§öÊ®°ÊÄÅËßÜËßâÁõÆÊ†áË∑üË∏™‰ªªÂä°‰∏≠ÔºåÁõ∏ËæÉ‰∫é‰º†ÁªüÂçïÊ®°ÊÄÅÊñπÊ≥ïÔºåÊÄßËÉΩÊèêÂçáÊòæËëóÔºåÂ∞§ÂÖ∂Âú®Â§ÑÁêÜÂ§çÊùÇÂú∫ÊôØÊó∂ÔºåË∑üË∏™Á≤æÂ∫¶ÊèêÈ´ò‰∫Ü15%„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩÁõëÊéß„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊó†‰∫∫Êú∫ÁõëÊéßÁ≠âÂú∫ÊôØÔºåËÉΩÂ§üÊúâÊïàÊèêÂçáÂ§öÊ®°ÊÄÅÊï∞ÊçÆÂú®ÁõÆÊ†áË∑üË∏™‰∏≠ÁöÑÂ∫îÁî®‰ª∑ÂÄº„ÄÇÊú™Êù•ÔºåÈöèÁùÄÂ§öÊ®°ÊÄÅÊï∞ÊçÆÁöÑ‰∏çÊñ≠‰∏∞ÂØåÔºåÊú¨ÊñáÁöÑÁ†îÁ©∂ÊàêÊûúÂ∞Ü‰∏∫Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÊäÄÊúØËøõÊ≠•Êèê‰æõÈáçË¶ÅÊîØÊåÅ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The development of smart cities has led to the generation of massive amounts of multi-modal data in the context of a range of tasks that enable a comprehensive monitoring of the smart city infrastructure and services. This paper surveys one of the most critical tasks, multi-modal visual object tracking (MMVOT), from the perspective of multimodality analysis. Generally, MMVOT differs from single-modal tracking in four key aspects, data collection, modality alignment and annotation, model designing, and evaluation. Accordingly, we begin with an introduction to the relevant data modalities, laying the groundwork for their integration. This naturally leads to a discussion of challenges of multi-modal data collection, alignment, and annotation. Subsequently, existing MMVOT methods are categorised, based on different ways to deal with visible (RGB) and X modalities: programming the auxiliary X branch with replicated or non-replicated experimental configurations from the RGB branch. Here X can be thermal infrared (T), depth (D), event (E), near infrared (NIR), language (L), or sonar (S). The final part of the paper addresses evaluation and benchmarking. In summary, we undertake an omni survey of all aspects of multi-modal visual object tracking (VOT), covering six MMVOT tasks and featuring 338 references in total. In addition, we discuss the fundamental rhetorical question: Is multi-modal tracking always guaranteed to provide a superior solution to unimodal tracking with the help of information fusion, and if not, in what circumstances its application is beneficial. Furthermore, for the first time in this field, we analyse the distributions of the object categories in the existing MMVOT datasets, revealing their pronounced long-tail nature and a noticeable lack of animal categories when compared with RGB datasets.

