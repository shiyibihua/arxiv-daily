---
layout: default
title: Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping
---

# Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13065" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13065v3</a>
  <a href="https://arxiv.org/pdf/2508.13065.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13065v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13065v3', 'Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Siddharth Khandelwal, Sridhar Kamath, Arjun Jain

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-18 (æ›´æ–°: 2025-09-25)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOdoä»¥è§£å†³äººå½¢ç¼–è¾‘ä¸­çš„å½¢çŠ¶ä¿ç•™é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `äººå½¢ç¼–è¾‘` `æ·±åº¦å­¦ä¹ ` `æ‰©æ•£æ¨¡å‹` `3Dé‡å¡‘` `è®¡ç®—æœºè§†è§‰` `è™šæ‹Ÿç°å®` `å›¾åƒå¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„äººå½¢ç¼–è¾‘æ–¹æ³•å¤šä¾èµ–äº3Dæ¨¡å‹æˆ–å›¾åƒæ‰­æ›²ï¼Œå¯¼è‡´ä¸è‡ªç„¶çš„èº«ä½“æ¯”ä¾‹å’Œçº¹ç†å¤±çœŸã€‚
2. æœ¬æ–‡æå‡ºOdoï¼Œä¸€ä¸ªåŸºäºæ‰©æ•£çš„ç«¯åˆ°ç«¯æ–¹æ³•ï¼Œç»“åˆå†»ç»“çš„UNetå’ŒControlNetï¼Œå®ç°çœŸå®çš„èº«ä½“é‡å¡‘ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOdoåœ¨æ¯ä¸ªé¡¶ç‚¹é‡å»ºè¯¯å·®ä¸Šè¾¾åˆ°7.5mmï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•çš„13.6mmï¼Œæ•ˆæœæ›´åŠ çœŸå®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººå½¢ç¼–è¾‘å…è®¸å¯¹ä¸ªä½“ä½“å‹è¿›è¡Œå¯æ§å˜æ¢ï¼Œå¦‚ç˜¦ã€è‚Œè‚‰å‘è¾¾æˆ–è¶…é‡ï¼ŒåŒæ—¶ä¿æŒå§¿åŠ¿ã€èº«ä»½ã€æœè£…å’ŒèƒŒæ™¯ã€‚ä¸å¿«é€Ÿå‘å±•çš„å§¿åŠ¿ç¼–è¾‘ç›¸æ¯”ï¼Œå½¢çŠ¶ç¼–è¾‘ä»ç›¸å¯¹æœªè¢«å……åˆ†æ¢ç´¢ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äº3Då¯å˜å½¢æ¨¡å‹æˆ–å›¾åƒæ‰­æ›²ï¼Œå¸¸å¼•å…¥ä¸ç°å®çš„èº«ä½“æ¯”ä¾‹ã€çº¹ç†å¤±çœŸå’ŒèƒŒæ™¯ä¸ä¸€è‡´ç­‰é—®é¢˜ã€‚æœ¬æ–‡é¦–æ¬¡å¼•å…¥ä¸€ä¸ªåŒ…å«18,573å¼ å›¾åƒçš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œä¸“ä¸ºå—æ§äººå½¢ç¼–è¾‘è®¾è®¡ã€‚åŸºäºè¯¥æ•°æ®é›†ï¼Œæˆ‘ä»¬æå‡ºäº†Odoï¼Œä¸€ä¸ªåŸºäºæ‰©æ•£çš„ç«¯åˆ°ç«¯æ–¹æ³•ï¼Œèƒ½å¤Ÿé€šè¿‡ç®€å•çš„è¯­ä¹‰å±æ€§å®ç°çœŸå®ä¸”ç›´è§‚çš„èº«ä½“é‡å¡‘ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¯ä¸ªé¡¶ç‚¹é‡å»ºè¯¯å·®ä¸Šè¾¾åˆ°7.5mmï¼Œæ˜¾è‘—ä½äºåŸºçº¿æ–¹æ³•çš„13.6mmï¼ŒåŒæ—¶ç”Ÿæˆçš„ç»“æœçœŸå®ä¸”å‡†ç¡®åŒ¹é…ç›®æ ‡å½¢çŠ¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³äººå½¢ç¼–è¾‘ä¸­å½¢çŠ¶ä¿ç•™çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¸¸å¼•å…¥ä¸è‡ªç„¶çš„èº«ä½“æ¯”ä¾‹å’Œçº¹ç†å¤±çœŸï¼Œç¼ºä¹å¤§è§„æ¨¡å…¬å¼€æ•°æ®é›†ä»¥æ”¯æŒè®­ç»ƒå’Œè¯„ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOdoæ–¹æ³•é€šè¿‡ç»“åˆå†»ç»“çš„UNetå’ŒControlNetï¼Œåˆ©ç”¨ç›®æ ‡SMPLæ·±åº¦å›¾å¼•å¯¼å½¢çŠ¶å˜æ¢ï¼Œä»è€Œå®ç°æ›´ä¸ºçœŸå®å’Œç›´è§‚çš„èº«ä½“é‡å¡‘ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå†»ç»“çš„UNetç”¨äºä¿ç•™è¾“å…¥å›¾åƒçš„ç»†èŠ‚ï¼ŒControlNetåˆ™è´Ÿè´£æ ¹æ®æ·±åº¦å›¾å¼•å¯¼å½¢çŠ¶å˜æ¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šOdoçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶æ‰©æ•£åŸºç¡€çš„è®¾è®¡ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒèº«ä»½å’ŒèƒŒæ™¯ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œå®ç°çµæ´»çš„ä½“å‹å˜æ¢ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•æ˜¾è‘—ä¸åŒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨äº†å†»ç»“çš„UNetä»¥ç¡®ä¿ç»†èŠ‚ä¿ç•™ï¼ŒåŒæ—¶ä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å½¢çŠ¶é‡å¡‘çš„å‡†ç¡®æ€§ï¼Œç¡®ä¿ç”Ÿæˆç»“æœçš„çœŸå®æ„Ÿã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Odoæ–¹æ³•åœ¨æ¯ä¸ªé¡¶ç‚¹é‡å»ºè¯¯å·®ä¸Šè¾¾åˆ°7.5mmï¼Œæ˜¾è‘—ä½äºåŸºçº¿æ–¹æ³•çš„13.6mmï¼Œå±•ç¤ºäº†å…¶åœ¨å½¢çŠ¶é‡å¡‘ä¸­çš„ä¼˜è¶Šæ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„ç»“æœæ›´ä¸ºçœŸå®ï¼Œèƒ½å¤Ÿå‡†ç¡®åŒ¹é…ç›®æ ‡å½¢çŠ¶ï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘å’Œä¸ªæ€§åŒ–æ—¶å°šç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡å®ç°çœŸå®çš„èº«ä½“å½¢çŠ¶ç¼–è¾‘ï¼Œç”¨æˆ·å¯ä»¥åœ¨æ•°å­—ç¯å¢ƒä¸­æ›´å¥½åœ°è¡¨è¾¾è‡ªæˆ‘ï¼Œæå‡äº¤äº’ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯ä¹Ÿå¯ç”¨äºåŒ»å­¦å›¾åƒåˆ†æå’Œä¸ªæ€§åŒ–å¥èº«æŒ‡å¯¼ç­‰åœºæ™¯ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Human shape editing enables controllable transformation of a person's body shape, such as thin, muscular, or overweight, while preserving pose, identity, clothing, and background. Unlike human pose editing, which has advanced rapidly, shape editing remains relatively under-explored. Current approaches typically rely on 3D morphable models or image warping, often introducing unrealistic body proportions, texture distortions, and background inconsistencies due to alignment errors and deformations. A key limitation is the lack of large-scale, publicly available datasets for training and evaluating body shape manipulation methods. In this work, we introduce the first large-scale dataset of 18,573 images across 1523 subjects, specifically designed for controlled human shape editing. It features diverse variations in body shape, including fat, muscular and thin, captured under consistent identity, clothing, and background conditions. Using this dataset, we propose Odo, an end-to-end diffusion-based method that enables realistic and intuitive body reshaping guided by simple semantic attributes. Our approach combines a frozen UNet that preserves fine-grained appearance and background details from the input image with a ControlNet that guides shape transformation using target SMPL depth maps. Extensive experiments demonstrate that our method outperforms prior approaches, achieving per-vertex reconstruction errors as low as 7.5mm, significantly lower than the 13.6mm observed in baseline methods, while producing realistic results that accurately match the desired target shapes.

