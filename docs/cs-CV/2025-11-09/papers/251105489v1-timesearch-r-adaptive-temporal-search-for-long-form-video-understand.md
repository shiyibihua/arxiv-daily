---
layout: default
title: TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning
---

# TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning

**arXiv**: [2511.05489v1](https://arxiv.org/abs/2511.05489) | [PDF](https://arxiv.org/pdf/2511.05489.pdf)

**ä½œè€…**: Junwen Pan, Qizhe Zhang, Rui Zhang, Ming Lu, Xin Wan, Yuan Zhang, Chang Liu, Qi She

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTimeSearch-Rä»¥é€šè¿‡è‡ªéªŒè¯å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–é•¿è§†é¢‘æ—¶åºæœç´¢**

**å…³é”®è¯**: `æ—¶åºæœç´¢` `é•¿è§†é¢‘ç†è§£` `å¼ºåŒ–å­¦ä¹ ` `è‡ªéªŒè¯` `è§†é¢‘æŽ¨ç†` `ç«¯åˆ°ç«¯ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ—¶åºæœç´¢æ–¹æ³•ä¾èµ–æ‰‹å·¥è¿‡ç¨‹ï¼Œç¼ºä¹ç«¯åˆ°ç«¯ä¼˜åŒ–ï¼Œå¯¼è‡´æœç´¢ä¸å®Œæ•´å’ŒæŽ¨ç†ä¸ä¸€è‡´ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥GRPO-CSVï¼Œé€šè¿‡è‡ªéªŒè¯æœºåˆ¶æ£€æŸ¥æœç´¢å¸§çš„å……åˆ†æ€§ï¼Œæå‡è§†é¢‘æŽ¨ç†çš„å®Œæ•´æ€§ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡æ€§èƒ½ï¼Œå¦‚LongVideoBenchä¸Šè¶…è¶ŠQwen2.5-VLå’ŒVideo-R1ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Temporal search aims to identify a minimal set of relevant frames from tens
> of thousands based on a given query, serving as a foundation for accurate
> long-form video understanding. Existing works attempt to progressively narrow
> the search space. However, these approaches typically rely on a hand-crafted
> search process, lacking end-to-end optimization for learning optimal search
> strategies. In this paper, we propose TimeSearch-R, which reformulates temporal
> search as interleaved text-video thinking, seamlessly integrating searching
> video clips into the reasoning process through reinforcement learning (RL).
> However, applying RL training methods, such as Group Relative Policy
> Optimization (GRPO), to video reasoning can result in unsupervised intermediate
> search decisions. This leads to insufficient exploration of the video content
> and inconsistent logical reasoning. To address these issues, we introduce GRPO
> with Completeness Self-Verification (GRPO-CSV), which gathers searched video
> frames from the interleaved reasoning process and utilizes the same policy
> model to verify the adequacy of searched frames, thereby improving the
> completeness of video reasoning. Additionally, we construct datasets
> specifically designed for the SFT cold-start and RL training of GRPO-CSV,
> filtering out samples with weak temporal dependencies to enhance task
> difficulty and improve temporal search capabilities. Extensive experiments
> demonstrate that TimeSearch-R achieves significant improvements on temporal
> search benchmarks such as Haystack-LVBench and Haystack-Ego4D, as well as
> long-form video understanding benchmarks like VideoMME and MLVU. Notably,
> TimeSearch-R establishes a new state-of-the-art on LongVideoBench with 4.1%
> improvement over the base model Qwen2.5-VL and 2.0% over the advanced video
> reasoning model Video-R1. Our code is available at
> https://github.com/Time-Search/TimeSearch-R.

