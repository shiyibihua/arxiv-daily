---
layout: default
title: Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings
---

# Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings

**arXiv**: [2511.05017v1](https://arxiv.org/abs/2511.05017) | [PDF](https://arxiv.org/pdf/2511.05017.pdf)

**ä½œè€…**: Aakriti Agrawal, Gouthaman KV, Rohith Aralikatti, Gauri Jagatap, Jiaxin Yuan, Vijay Kamarshi, Andrea Fanelli, Furong Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€šè¿‡ç²¾ç‚¼æ–‡æœ¬åµŒå…¥æ¥ç¼“è§£å¤§åž‹è§†è§‰è¯­è¨€æ¨¡åž‹ä¸­çš„å¹»è§‰é—®é¢˜**

**å…³é”®è¯**: `å¤§åž‹è§†è§‰è¯­è¨€æ¨¡åž‹` `å¹»è§‰ç¼“è§£` `æ–‡æœ¬åµŒå…¥ç²¾ç‚¼` `è§†è§‰ç‰¹å¾èžåˆ` `æ¨¡æ€ä¸å¹³è¡¡` `è§†è§‰æŽ¥åœ°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰LVLMæž¶æž„åå‘è¯­è¨€æ¨¡æ€ï¼Œå¯¼è‡´è§†è§‰å¹»è§‰
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å¹³å‡æ± åŒ–è§†è§‰ç‰¹å¾ç²¾ç‚¼æ–‡æœ¬åµŒå…¥ï¼Œå¢žå¼ºè§†è§‰åŸºç¡€
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—å‡å°‘å¹»è§‰ï¼Œæå‡è§†è§‰æŽ¥åœ°èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this work, we identify an inherent bias in prevailing LVLM architectures
> toward the language modality, largely resulting from the common practice of
> simply appending visual embeddings to the input text sequence. To address this,
> we propose a simple yet effective method that refines textual embeddings by
> integrating average-pooled visual features. Our approach demonstrably improves
> visual grounding and significantly reduces hallucinations on established
> benchmarks. While average pooling offers a straightforward, robust, and
> efficient means of incorporating visual information, we believe that more
> sophisticated fusion methods could further enhance visual grounding and
> cross-modal alignment. Given that the primary focus of this work is to
> highlight the modality imbalance and its impact on hallucinations -- and to
> show that refining textual embeddings with visual information mitigates this
> issue -- we leave exploration of advanced fusion strategies for future work.

