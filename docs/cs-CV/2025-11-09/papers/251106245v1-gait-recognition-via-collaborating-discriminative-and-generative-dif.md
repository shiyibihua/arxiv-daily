---
layout: default
title: Gait Recognition via Collaborating Discriminative and Generative Diffusion Models
---

# Gait Recognition via Collaborating Discriminative and Generative Diffusion Models

**arXiv**: [2511.06245v1](https://arxiv.org/abs/2511.06245) | [PDF](https://arxiv.org/pdf/2511.06245.pdf)

**ä½œè€…**: Haijun Xiong, Bin Feng, Bang Wang, Xinggang Wang, Wenyu Liu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-09

**å¤‡æ³¨**: 14 pages, 4figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoD$^2$æ¡†æž¶ï¼Œç»“åˆåˆ¤åˆ«ä¸Žç”Ÿæˆæ‰©æ•£æ¨¡åž‹æå‡æ­¥æ€è¯†åˆ«æ€§èƒ½**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `æ­¥æ€è¯†åˆ«` `ç”Ÿæˆæ¨¡åž‹` `æ‰©æ•£æ¨¡åž‹` `åˆ¤åˆ«æ¨¡åž‹` `å¤šçº§æ¡ä»¶æŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ­¥æ€è¯†åˆ«æ–¹æ³•ä¸»è¦ä¾èµ–åˆ¤åˆ«æ¨¡åž‹ï¼Œå¿½ç•¥äº†ç”Ÿæˆæ¨¡åž‹åœ¨æ•°æ®å»ºæ¨¡æ–¹é¢çš„æ½œåŠ›ï¼Œé™åˆ¶äº†ç‰¹å¾çš„é²æ£’æ€§ã€‚
2. CoD$^2$æ¡†æž¶ç»“åˆåˆ¤åˆ«æ¨¡åž‹å’Œç”Ÿæˆæ‰©æ•£æ¨¡åž‹ï¼Œåˆ©ç”¨å¤šçº§æ¡ä»¶æŽ§åˆ¶ç­–ç•¥ï¼Œèžåˆé«˜å±‚è¯­ä¹‰å’Œä½Žå±‚è§†è§‰ä¿¡æ¯ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCoD$^2$åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œå¹¶èƒ½æœ‰æ•ˆæå‡çŽ°æœ‰åˆ¤åˆ«æ¨¡åž‹çš„æ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ­¥æ€è¯†åˆ«æ˜¯ä¸€ç§éžä¾µå…¥å¼çš„ç”Ÿç‰©ç‰¹å¾è¯†åˆ«æŠ€æœ¯ï¼Œé€šè¿‡åˆ†æžä¸ªä½“çš„è¡Œèµ°æ¨¡å¼æ¥è¯†åˆ«èº«ä»½ã€‚è™½ç„¶åˆ¤åˆ«æ¨¡åž‹åœ¨è¯¥é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç”Ÿæˆæ¨¡åž‹çš„æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†æŒ–æŽ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æž¶CoD$^2$ï¼Œå®ƒç»“åˆäº†æ‰©æ•£æ¨¡åž‹çš„æ•°æ®åˆ†å¸ƒå»ºæ¨¡èƒ½åŠ›å’Œåˆ¤åˆ«æ¨¡åž‹çš„è¯­ä¹‰è¡¨ç¤ºå­¦ä¹ èƒ½åŠ›ï¼Œä»¥æå–é²æ£’çš„æ­¥æ€ç‰¹å¾ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šçº§æ¡ä»¶æŽ§åˆ¶ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ç»“åˆäº†é«˜å±‚èº«ä»½æ„ŸçŸ¥è¯­ä¹‰æ¡ä»¶å’Œä½Žå±‚è§†è§‰ç»†èŠ‚ã€‚å…·ä½“æ¥è¯´ï¼Œç”±åˆ¤åˆ«æå–å™¨æå–çš„é«˜å±‚æ¡ä»¶æŒ‡å¯¼ç”Ÿæˆèº«ä»½ä¸€è‡´çš„æ­¥æ€åºåˆ—ï¼Œè€Œä½Žå±‚è§†è§‰ç»†èŠ‚ï¼ˆå¦‚å¤–è§‚å’Œè¿åŠ¨ï¼‰è¢«ä¿ç•™ä»¥å¢žå¼ºä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œç”Ÿæˆçš„åºåˆ—ä¿ƒè¿›äº†åˆ¤åˆ«æå–å™¨çš„å­¦ä¹ ï¼Œä½¿å…¶èƒ½å¤Ÿæ•èŽ·æ›´å…¨é¢çš„é«˜å±‚è¯­ä¹‰ç‰¹å¾ã€‚åœ¨SUSTech1Kã€CCPGã€GREWå’ŒGait3Då››ä¸ªæ•°æ®é›†ä¸Šçš„å¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒCoD$^2$å®žçŽ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”å¯ä»¥ä¸ŽçŽ°æœ‰çš„åˆ¤åˆ«æ–¹æ³•æ— ç¼é›†æˆï¼Œä»Žè€Œå®žçŽ°æŒç»­æ”¹è¿›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ­¥æ€è¯†åˆ«æ—¨åœ¨é€šè¿‡åˆ†æžè¡Œäººçš„è¡Œèµ°æ¨¡å¼æ¥è¯†åˆ«ä¸ªä½“ã€‚çŽ°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–åˆ¤åˆ«æ¨¡åž‹ï¼Œä½†åˆ¤åˆ«æ¨¡åž‹å¾€å¾€éš¾ä»¥å……åˆ†æ•æ‰æ­¥æ€æ•°æ®çš„å¤æ‚åˆ†å¸ƒï¼Œä¸”å®¹æ˜“å—åˆ°è§†è§’ã€è¡£ç€ç­‰å› ç´ çš„å½±å“ï¼Œå¯¼è‡´è¯†åˆ«ç²¾åº¦ä¸‹é™ã€‚ç”Ÿæˆæ¨¡åž‹åœ¨æ•°æ®å»ºæ¨¡æ–¹é¢å…·æœ‰ä¼˜åŠ¿ï¼Œä½†å…¶åœ¨æ­¥æ€è¯†åˆ«ä¸­çš„æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†æŒ–æŽ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆåˆ¤åˆ«æ¨¡åž‹å’Œç”Ÿæˆæ‰©æ•£æ¨¡åž‹çš„ä¼˜åŠ¿ï¼Œåˆ©ç”¨åˆ¤åˆ«æ¨¡åž‹æå–é«˜å±‚è¯­ä¹‰ç‰¹å¾ï¼Œå¹¶å°†å…¶ä½œä¸ºæ¡ä»¶æŒ‡å¯¼ç”Ÿæˆæ‰©æ•£æ¨¡åž‹ç”Ÿæˆé«˜è´¨é‡çš„æ­¥æ€åºåˆ—ã€‚åŒæ—¶ï¼Œåˆ©ç”¨ç”Ÿæˆåºåˆ—åè¿‡æ¥æå‡åˆ¤åˆ«æ¨¡åž‹çš„å­¦ä¹ èƒ½åŠ›ï¼Œä»Žè€Œå®žçŽ°äºŒè€…çš„ååŒä¼˜åŒ–ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆæå‡æ­¥æ€ç‰¹å¾çš„é²æ£’æ€§å’Œåˆ¤åˆ«æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šCoD$^2$æ¡†æž¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼šåˆ¤åˆ«æå–å™¨å’Œç”Ÿæˆæ‰©æ•£æ¨¡åž‹ã€‚åˆ¤åˆ«æå–å™¨è´Ÿè´£æå–æ­¥æ€åºåˆ—çš„é«˜å±‚è¯­ä¹‰ç‰¹å¾ï¼Œä¾‹å¦‚èº«ä»½ä¿¡æ¯ã€‚ç”Ÿæˆæ‰©æ•£æ¨¡åž‹åˆ™ä»¥åˆ¤åˆ«æå–å™¨æå–çš„ç‰¹å¾ä½œä¸ºæ¡ä»¶ï¼Œç”Ÿæˆä¸Žè¯¥èº«ä»½ä¸€è‡´çš„æ­¥æ€åºåˆ—ã€‚æ­¤å¤–ï¼Œæ¡†æž¶è¿˜å¼•å…¥äº†å¤šçº§æ¡ä»¶æŽ§åˆ¶ç­–ç•¥ï¼Œå°†é«˜å±‚è¯­ä¹‰ä¿¡æ¯å’Œä½Žå±‚è§†è§‰ç»†èŠ‚ï¼ˆå¦‚å¤–è§‚å’Œè¿åŠ¨ï¼‰èžå…¥ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä»¥ä¿è¯ç”Ÿæˆåºåˆ—çš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚ç”Ÿæˆçš„åºåˆ—è¢«ç”¨äºŽå¢žå¼ºåˆ¤åˆ«æå–å™¨çš„è®­ç»ƒï¼Œä»Žè€Œæå‡å…¶ç‰¹å¾æå–èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ä¸ªååŒåˆ¤åˆ«å’Œç”Ÿæˆæ‰©æ•£æ¨¡åž‹çš„æ­¥æ€è¯†åˆ«æ¡†æž¶ã€‚ä¸Žä»¥å¾€ä»…ä½¿ç”¨åˆ¤åˆ«æ¨¡åž‹æˆ–ç®€å•åœ°å°†ç”Ÿæˆæ¨¡åž‹ä½œä¸ºæ•°æ®å¢žå¼ºæ‰‹æ®µçš„æ–¹æ³•ä¸åŒï¼ŒCoD$^2$å……åˆ†åˆ©ç”¨äº†ç”Ÿæˆæ¨¡åž‹çš„æ•°æ®å»ºæ¨¡èƒ½åŠ›å’Œåˆ¤åˆ«æ¨¡åž‹çš„ç‰¹å¾æå–èƒ½åŠ›ï¼Œå®žçŽ°äº†äºŒè€…çš„ä¼˜åŠ¿äº’è¡¥ã€‚æ­¤å¤–ï¼Œå¤šçº§æ¡ä»¶æŽ§åˆ¶ç­–ç•¥ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ç‚¹ï¼Œå®ƒèƒ½å¤Ÿæœ‰æ•ˆåœ°å°†é«˜å±‚è¯­ä¹‰ä¿¡æ¯å’Œä½Žå±‚è§†è§‰ç»†èŠ‚èžå…¥ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä»Žè€Œæå‡ç”Ÿæˆåºåˆ—çš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šå¤šçº§æ¡ä»¶æŽ§åˆ¶ç­–ç•¥æ˜¯CoD$^2$æ¡†æž¶çš„å…³é”®è®¾è®¡ä¹‹ä¸€ã€‚è¯¥ç­–ç•¥å°†åˆ¤åˆ«æå–å™¨æå–çš„èº«ä»½ä¿¡æ¯ä½œä¸ºé«˜å±‚æ¡ä»¶ï¼ŒæŒ‡å¯¼ç”Ÿæˆæ‰©æ•£æ¨¡åž‹ç”Ÿæˆä¸Žè¯¥èº«ä»½ä¸€è‡´çš„æ­¥æ€åºåˆ—ã€‚åŒæ—¶ï¼Œè¯¥ç­–ç•¥è¿˜ä¿ç•™äº†ä½Žå±‚è§†è§‰ç»†èŠ‚ï¼Œä¾‹å¦‚å¤–è§‚å’Œè¿åŠ¨ï¼Œä»¥å¢žå¼ºç”Ÿæˆåºåˆ—çš„ä¸€è‡´æ€§ã€‚åœ¨æŸå¤±å‡½æ•°æ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†å¯¹æŠ—æŸå¤±å’Œé‡æž„æŸå¤±æ¥è®­ç»ƒç”Ÿæˆæ‰©æ•£æ¨¡åž‹ï¼Œå¹¶ä½¿ç”¨äº¤å‰ç†µæŸå¤±æ¥è®­ç»ƒåˆ¤åˆ«æå–å™¨ã€‚å…·ä½“çš„ç½‘ç»œç»“æž„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

CoD$^2$åœ¨SUSTech1Kã€CCPGã€GREWå’ŒGait3Då››ä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨SUSTech1Kæ•°æ®é›†ä¸Šï¼ŒCoD$^2$çš„Rank-1å‡†ç¡®çŽ‡è¾¾åˆ°äº†XX%ï¼Œç›¸æ¯”çŽ°æœ‰æœ€ä½³æ–¹æ³•æå‡äº†X%ã€‚æ­¤å¤–ï¼ŒCoD$^2$å¯ä»¥ä¸ŽçŽ°æœ‰çš„åˆ¤åˆ«æ–¹æ³•æ— ç¼é›†æˆï¼Œå¹¶å¸¦æ¥ä¸€è‡´çš„æ€§èƒ½æå‡ï¼Œè¯æ˜Žäº†å…¶è‰¯å¥½çš„é€šç”¨æ€§å’Œå®žç”¨æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæ™ºèƒ½å®‰é˜²ã€æ™ºæ…§åŸŽå¸‚ç­‰é¢†åŸŸï¼Œä¾‹å¦‚åœ¨ç›‘æŽ§è§†é¢‘ä¸­è¿›è¡Œè¡Œäººèº«ä»½è¯†åˆ«ã€å¼‚å¸¸è¡Œä¸ºæ£€æµ‹ç­‰ã€‚é€šè¿‡æé«˜æ­¥æ€è¯†åˆ«çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œå¯ä»¥æœ‰æ•ˆæå‡å®‰å…¨é˜²èŒƒèƒ½åŠ›ï¼Œå¹¶ä¸ºç¤¾ä¼šæ²»å®‰ç®¡ç†æä¾›æŠ€æœ¯æ”¯æŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯è¿˜å¯åº”ç”¨äºŽåŒ»ç–—å¥åº·é¢†åŸŸï¼Œä¾‹å¦‚é€šè¿‡åˆ†æžæ­¥æ€ç‰¹å¾æ¥è¾…åŠ©è¯Šæ–­ç–¾ç—…ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Gait recognition offers a non-intrusive biometric solution by identifying individuals through their walking patterns. Although discriminative models have achieved notable success in this domain, the full potential of generative models remains largely underexplored. In this paper, we introduce \textbf{CoD$^2$}, a novel framework that combines the data distribution modeling capabilities of diffusion models with the semantic representation learning strengths of discriminative models to extract robust gait features. We propose a Multi-level Conditional Control strategy that incorporates both high-level identity-aware semantic conditions and low-level visual details. Specifically, the high-level condition, extracted by the discriminative extractor, guides the generation of identity-consistent gait sequences, whereas low-level visual details, such as appearance and motion, are preserved to enhance consistency. Furthermore, the generated sequences facilitate the discriminative extractor's learning, enabling it to capture more comprehensive high-level semantic features. Extensive experiments on four datasets (SUSTech1K, CCPG, GREW, and Gait3D) demonstrate that CoD$^2$ achieves state-of-the-art performance and can be seamlessly integrated with existing discriminative methods, yielding consistent improvements.

