---
layout: default
title: VideoSSR: Video Self-Supervised Reinforcement Learning
---

# VideoSSR: Video Self-Supervised Reinforcement Learning

**arXiv**: [2511.06281v1](https://arxiv.org/abs/2511.06281) | [PDF](https://arxiv.org/pdf/2511.06281.pdf)

**ä½œè€…**: Zefeng He, Xiaoye Qu, Yafu Li, Siyuan Huang, Daizong Liu, Yu Cheng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-09

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/lcqysl/VideoSSR)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVideoSSRï¼Œåˆ©ç”¨è§†é¢‘è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹çš„è§†é¢‘ç†è§£èƒ½åŠ›ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è§†é¢‘ç†è§£` `è‡ªç›‘ç£å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `è§†é¢‘é—®ç­”`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†é¢‘æ•°æ®é›†éš¾ä»¥æ»¡è¶³å¿«é€Ÿå‘å±•çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹çš„éœ€æ±‚ï¼Œè€Œäººå·¥æ ‡æ³¨é«˜è´¨é‡æ•°æ®æˆæœ¬é«˜æ˜‚ã€‚
2. VideoSSRåˆ©ç”¨è§†é¢‘å†…åœ¨ä¿¡æ¯è‡ªç›‘ç£ç”Ÿæˆé«˜è´¨é‡ã€å¯éªŒè¯çš„è®­ç»ƒæ•°æ®ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ æå‡æ¨¡åž‹æ€§èƒ½ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒVideoSSRåœ¨å¤šä¸ªè§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•ä¸­æŒç»­æå‡æ¨¡åž‹æ€§èƒ½ï¼Œå¹³å‡æå‡è¶…è¿‡5%ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†å¦‚ä½•åˆ©ç”¨è§†é¢‘ä¸­ä¸°å¯Œçš„å†…åœ¨ä¿¡æ¯æ¥è‡ªæˆ‘ç”Ÿæˆé«˜è´¨é‡ã€å¯éªŒè¯çš„è®­ç»ƒæ•°æ®ï¼Œä»¥æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ï¼ˆMLLMï¼‰çš„è§†é¢‘ç†è§£èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸‰ä¸ªè‡ªç›‘ç£é¢„è®­ç»ƒä»»åŠ¡ï¼šå¼‚å¸¸å®šä½ã€ç‰©ä½“è®¡æ•°å’Œæ—¶é—´æ‹¼å›¾ï¼Œå¹¶æž„å»ºäº†è§†é¢‘å†…åœ¨ç†è§£åŸºå‡†ï¼ˆVIUBenchï¼‰æ¥éªŒè¯è¿™äº›ä»»åŠ¡çš„éš¾åº¦ã€‚å®žéªŒè¡¨æ˜Žï¼Œå½“å‰æœ€å…ˆè¿›çš„MLLMåœ¨è¿™äº›ä»»åŠ¡ä¸Šè¡¨çŽ°ä¸ä½³ã€‚åŸºäºŽè¿™äº›é¢„è®­ç»ƒä»»åŠ¡ï¼Œä½œè€…æž„å»ºäº†VideoSSR-30Kæ•°æ®é›†ï¼Œå¹¶æå‡ºäº†VideoSSRï¼Œä¸€ç§ç”¨äºŽRLVRçš„è§†é¢‘è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ æ¡†æž¶ã€‚åœ¨æ¶µç›–å››ä¸ªä¸»è¦è§†é¢‘é¢†åŸŸï¼ˆé€šç”¨è§†é¢‘é—®ç­”ã€é•¿è§†é¢‘é—®ç­”ã€æ—¶é—´å®šä½å’Œå¤æ‚æŽ¨ç†ï¼‰çš„17ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œå¹¿æ³›çš„å®žéªŒè¡¨æ˜ŽVideoSSRèƒ½å¤ŸæŒç»­æå‡æ¨¡åž‹æ€§èƒ½ï¼Œå¹³å‡æå‡è¶…è¿‡5%ã€‚è¿™äº›ç»“æžœè¡¨æ˜ŽVideoSSRæ˜¯å¼€å‘æ›´é«˜çº§MLLMè§†é¢‘ç†è§£èƒ½åŠ›çš„å¼ºå¤§åŸºç¡€æ¡†æž¶ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰è§†é¢‘æ•°æ®é›†çš„å¤æ‚åº¦å’Œè§„æ¨¡å·²ç»æ— æ³•æ»¡è¶³å¿«é€Ÿå‘å±•çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ï¼ˆMLLMï¼‰çš„éœ€æ±‚ã€‚äººå·¥æ ‡æ³¨æ–°çš„é«˜è´¨é‡è§†é¢‘æ•°æ®æˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†MLLMåœ¨è§†é¢‘ç†è§£æ–¹é¢çš„è¿›ä¸€æ­¥å‘å±•ã€‚å› æ­¤ï¼Œå¦‚ä½•é«˜æ•ˆåœ°èŽ·å–é«˜è´¨é‡çš„è§†é¢‘è®­ç»ƒæ•°æ®æˆä¸ºä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è§†é¢‘æœ¬èº«æ‰€è•´å«çš„ä¸°å¯Œä¿¡æ¯ï¼Œé€šè¿‡è‡ªç›‘ç£å­¦ä¹ çš„æ–¹å¼ï¼Œè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡ã€å¯éªŒè¯çš„è®­ç»ƒæ•°æ®ã€‚è¿™ç§æ–¹æ³•é¿å…äº†æ˜‚è´µçš„äººå·¥æ ‡æ³¨ï¼Œå¹¶ä¸”èƒ½å¤Ÿå……åˆ†æŒ–æŽ˜è§†é¢‘æ•°æ®çš„å†…åœ¨ä»·å€¼ï¼Œä»Žè€Œæå‡MLLMçš„è§†é¢‘ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šVideoSSRæ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) è‡ªç›‘ç£é¢„è®­ç»ƒä»»åŠ¡è®¾è®¡ï¼šè®¾è®¡äº†Anomaly Groundingï¼ˆå¼‚å¸¸å®šä½ï¼‰ã€Object Countingï¼ˆç‰©ä½“è®¡æ•°ï¼‰å’ŒTemporal Jigsawï¼ˆæ—¶é—´æ‹¼å›¾ï¼‰ä¸‰ä¸ªè‡ªç›‘ç£é¢„è®­ç»ƒä»»åŠ¡ï¼Œç”¨äºŽæŒ–æŽ˜è§†é¢‘çš„å†…åœ¨ä¿¡æ¯ã€‚2) VideoSSR-30Kæ•°æ®é›†æž„å»ºï¼šåŸºäºŽä¸Šè¿°é¢„è®­ç»ƒä»»åŠ¡ï¼Œæž„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„è‡ªç›‘ç£è§†é¢‘æ•°æ®é›†VideoSSR-30Kã€‚3) å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼šåˆ©ç”¨VideoSSR-30Kæ•°æ®é›†ï¼Œé‡‡ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•è®­ç»ƒMLLMï¼Œæå‡å…¶è§†é¢‘ç†è§£èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šVideoSSRçš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ä¸ªå®Œæ•´çš„è§†é¢‘è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ æ¡†æž¶ï¼Œè¯¥æ¡†æž¶èƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼Œå¹¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•æå‡MLLMçš„è§†é¢‘ç†è§£èƒ½åŠ›ã€‚ä¸Žä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼ŒVideoSSRæ— éœ€äººå·¥æ ‡æ³¨æ•°æ®ï¼Œèƒ½å¤Ÿæ›´é«˜æ•ˆåœ°åˆ©ç”¨è§†é¢‘æ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è‡ªç›‘ç£é¢„è®­ç»ƒä»»åŠ¡è®¾è®¡æ–¹é¢ï¼ŒAnomaly Groundingæ—¨åœ¨è®©æ¨¡åž‹å­¦ä¹ è¯†åˆ«è§†é¢‘ä¸­çš„å¼‚å¸¸äº‹ä»¶ï¼›Object Countingæ—¨åœ¨è®©æ¨¡åž‹å­¦ä¹ è§†é¢‘ä¸­ç‰©ä½“çš„æ•°é‡ï¼›Temporal Jigsawæ—¨åœ¨è®©æ¨¡åž‹å­¦ä¹ è§†é¢‘çš„æ—¶é—´é¡ºåºã€‚åœ¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ–¹é¢ï¼Œé‡‡ç”¨äº†Reinforcement Learning with Verifiable Rewards (RLVR)æ¡†æž¶ï¼Œå¹¶æ ¹æ®ä¸åŒçš„è§†é¢‘ç†è§£ä»»åŠ¡è®¾è®¡äº†ç›¸åº”çš„å¥–åŠ±å‡½æ•°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒVideoSSRåœ¨17ä¸ªè§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå¹³å‡æå‡è¶…è¿‡5%ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨é€šç”¨è§†é¢‘é—®ç­”ã€é•¿è§†é¢‘é—®ç­”ã€æ—¶é—´å®šä½å’Œå¤æ‚æŽ¨ç†ç­‰ä»»åŠ¡ä¸Šï¼ŒVideoSSRéƒ½ä¼˜äºŽçŽ°æœ‰çš„åŸºçº¿æ–¹æ³•ï¼Œè¯æ˜Žäº†å…¶æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒVideoSSRæ˜¯ä¸€ç§å¾ˆæœ‰æ½œåŠ›çš„è§†é¢‘è‡ªç›‘ç£å­¦ä¹ æ¡†æž¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡MLLMçš„è§†é¢‘ç†è§£èƒ½åŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

VideoSSRå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºŽæ™ºèƒ½ç›‘æŽ§ã€è‡ªåŠ¨é©¾é©¶ã€è§†é¢‘æœç´¢ã€æ™ºèƒ½å®¢æœç­‰é¢†åŸŸã€‚é€šè¿‡æå‡MLLMçš„è§†é¢‘ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥å®žçŽ°æ›´æ™ºèƒ½åŒ–çš„è§†é¢‘åˆ†æžå’Œå¤„ç†ï¼Œä¾‹å¦‚è‡ªåŠ¨è¯†åˆ«ç›‘æŽ§è§†é¢‘ä¸­çš„å¼‚å¸¸è¡Œä¸ºã€ç†è§£è‡ªåŠ¨é©¾é©¶è½¦è¾†å‘¨å›´çš„äº¤é€šçŠ¶å†µã€æ ¹æ®ç”¨æˆ·queryæ£€ç´¢ç›¸å…³è§†é¢‘å†…å®¹ã€ä»¥åŠä¸ºç”¨æˆ·æä¾›æ›´ç²¾å‡†çš„è§†é¢‘é—®ç­”æœåŠ¡ã€‚æœªæ¥ï¼ŒVideoSSRæœ‰æœ›æˆä¸ºæž„å»ºæ›´å¼ºå¤§çš„è§†é¢‘æ™ºèƒ½ç³»ç»Ÿçš„å…³é”®æŠ€æœ¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reinforcement Learning with Verifiable Rewards (RLVR) has substantially advanced the video understanding capabilities of Multimodal Large Language Models (MLLMs). However, the rapid progress of MLLMs is outpacing the complexity of existing video datasets, while the manual annotation of new, high-quality data remains prohibitively expensive. This work investigates a pivotal question: Can the rich, intrinsic information within videos be harnessed to self-generate high-quality, verifiable training data? To investigate this, we introduce three self-supervised pretext tasks: Anomaly Grounding, Object Counting, and Temporal Jigsaw. We construct the Video Intrinsic Understanding Benchmark (VIUBench) to validate their difficulty, revealing that current state-of-the-art MLLMs struggle significantly on these tasks. Building upon these pretext tasks, we develop the VideoSSR-30K dataset and propose VideoSSR, a novel video self-supervised reinforcement learning framework for RLVR. Extensive experiments across 17 benchmarks, spanning four major video domains (General Video QA, Long Video QA, Temporal Grounding, and Complex Reasoning), demonstrate that VideoSSR consistently enhances model performance, yielding an average improvement of over 5\%. These results establish VideoSSR as a potent foundational framework for developing more advanced video understanding in MLLMs. The code is available at https://github.com/lcqysl/VideoSSR.

