---
layout: default
title: Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space
---

# Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space

**arXiv**: [2511.05203v1](https://arxiv.org/abs/2511.05203) | [PDF](https://arxiv.org/pdf/2511.05203.pdf)

**ä½œè€…**: Linus Nwankwo, BjÃ¶rn Ellensohn, Christian Rauch, Elmar Rueckert

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå…±ç”Ÿäº¤äº’å­¦ä¹ æ–¹æ³•ï¼Œåœ¨å…±äº«æ½œåœ¨ç©ºé—´ä¸­å®žçŽ°äººæœºåŒå‘å…±åŒé€‚åº”ã€‚**

**å…³é”®è¯**: `å…±ç”Ÿäº¤äº’å­¦ä¹ ` `å…±äº«æ½œåœ¨ç©ºé—´` `äººæœºäº¤äº’` `åŸºç¡€æ¨¡åž‹` `å…±åŒé€‚åº”` `ä»»åŠ¡è¡¨ç¤º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰äººæœºäº¤äº’æ²¿ç”¨ä¸»ä»Žæ¨¡å¼ï¼Œç¼ºä¹åŒå‘å…±åŒé€‚åº”ã€‚
2. æ–¹æ³•åœ¨å…±äº«æ½œåœ¨ä»»åŠ¡ç©ºé—´ä¸­å®žçŽ°è”åˆä¿¡å¿µçŠ¶æ€æ¼”åŒ–ï¼Œæ”¯æŒä¸»åŠ¨æ¾„æ¸…å’Œè®¡åˆ’ä¼˜åŒ–ã€‚
3. åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žä»»åŠ¡ä¸­éªŒè¯ï¼ŒåŒ…æ‹¬æŒ‡ä»¤è·Ÿéšå’Œäº¤äº’å¯¹è¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Today's autonomous agents can understand free-form natural language
> instructions and execute long-horizon tasks in a manner akin to human-level
> reasoning. These capabilities are mostly driven by large-scale pre-trained
> foundation models (FMs). However, the approaches with which these models are
> grounded for human-robot interaction (HRI) perpetuate a master-apprentice
> model, where the apprentice (embodied agent) passively receives and executes
> the master's (human's) commands without reciprocal learning. This reactive
> interaction approach does not capture the co-adaptive dynamics inherent in
> everyday multi-turn human-human interactions. To address this, we propose a
> Symbiotic Interactive Learning (SIL) approach that enables both the master and
> the apprentice to co-adapt through mutual, bidirectional interactions. We
> formalised SIL as a co-adaptation process within a shared latent task space,
> where the agent and human maintain joint belief states that evolve based on
> interaction history. This enables the agent to move beyond reactive execution
> to proactive clarification, adaptive suggestions, and shared plan refinement.
> To realise these novel behaviours, we leveraged pre-trained FMs for spatial
> perception and reasoning, alongside a lightweight latent encoder that grounds
> the models' outputs into task-specific representations. Furthermore, to ensure
> stability as the tasks evolve, we augment SIL with a memory architecture that
> prevents the forgetting of learned task-space representations. We validate SIL
> on both simulated and real-world embodied tasks, including instruction
> following, information retrieval, query-oriented reasoning, and interactive
> dialogues. Demos and resources are public
> at:~\href{https://linusnep.github.io/SIL/}{https://linusnep.github.io/SIL/}.

