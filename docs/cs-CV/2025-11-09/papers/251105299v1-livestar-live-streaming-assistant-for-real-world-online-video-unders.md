---
layout: default
title: LiveStar: Live Streaming Assistant for Real-World Online Video Understanding
---

# LiveStar: Live Streaming Assistant for Real-World Online Video Understanding

**arXiv**: [2511.05299v1](https://arxiv.org/abs/2511.05299) | [PDF](https://arxiv.org/pdf/2511.05299.pdf)

**ä½œè€…**: Zhenyu Yang, Kairui Zhang, Yuhang Hu, Bing Wang, Shengsheng Qian, Bin Wen, Fan Yang, Tingting Gao, Weiming Dong, Changsheng Xu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLiveStarä»¥è§£å†³åœ¨çº¿è§†é¢‘ç†è§£ä¸­å®žæ—¶å“åº”ä¸Žå™äº‹è¿žè´¯æ€§é—®é¢˜**

**å…³é”®è¯**: `åœ¨çº¿è§†é¢‘ç†è§£` `æµå¼è§£ç ` `å†…å­˜åŽ‹ç¼©` `è§†é¢‘å¤§è¯­è¨€æ¨¡åž‹` `å®žæ—¶å“åº”`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åœ¨çº¿è§†é¢‘å¤§æ¨¡åž‹éš¾ä»¥åŒæ—¶å¤„ç†è¿žç»­å¸§è¾“å…¥å¹¶ç¡®å®šæœ€ä½³å“åº”æ—¶æœºï¼Œå½±å“å®žæ—¶æ€§ä¸Žè¿žè´¯æ€§
2. é‡‡ç”¨è‡ªé€‚åº”æµå¼è§£ç ï¼ŒåŒ…æ‹¬å¢žé‡è§†é¢‘è¯­è¨€å¯¹é½ã€å“åº”é™é»˜è§£ç æ¡†æž¶å’Œå†…å­˜æ„ŸçŸ¥åŠ é€Ÿ
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯­ä¹‰æ­£ç¡®æ€§å¹³å‡æå‡19.5%ï¼ŒæŽ¨ç†é€Ÿåº¦æå‡12.0%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite significant progress in Video Large Language Models (Video-LLMs) for
> offline video understanding, existing online Video-LLMs typically struggle to
> simultaneously process continuous frame-by-frame inputs and determine optimal
> response timing, often compromising real-time responsiveness and narrative
> coherence. To address these limitations, we introduce LiveStar, a pioneering
> live streaming assistant that achieves always-on proactive responses through
> adaptive streaming decoding. Specifically, LiveStar incorporates: (1) a
> training strategy enabling incremental video-language alignment for
> variable-length video streams, preserving temporal consistency across
> dynamically evolving frame sequences; (2) a response-silence decoding framework
> that determines optimal proactive response timing via a single forward pass
> verification; (3) memory-aware acceleration via peak-end memory compression for
> online inference on 10+ minute videos, combined with streaming key-value cache
> to achieve 1.53x faster inference. We also construct an OmniStar dataset, a
> comprehensive dataset for training and benchmarking that encompasses 15 diverse
> real-world scenarios and 5 evaluation tasks for online video understanding.
> Extensive experiments across three benchmarks demonstrate LiveStar's
> state-of-the-art performance, achieving an average 19.5% improvement in
> semantic correctness with 18.1% reduced timing difference compared to existing
> online Video-LLMs, while improving FPS by 12.0% across all five OmniStar tasks.
> Our model and dataset can be accessed at https://github.com/yzy-bupt/LiveStar.

