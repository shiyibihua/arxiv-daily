---
layout: default
title: VDNeRF: Vision-only Dynamic Neural Radiance Field for Urban Scenes
---

# VDNeRF: Vision-only Dynamic Neural Radiance Field for Urban Scenes

**arXiv**: [2511.06408v1](https://arxiv.org/abs/2511.06408) | [PDF](https://arxiv.org/pdf/2511.06408.pdf)

**ä½œè€…**: Zhengyu Zou, Jingfeng Li, Hao Li, Xiaolei Hou, Jinwen Hu, Jingkun Chen, Lechao Cheng, Dingwen Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-09

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVDNeRFä»¥è§£å†³åŠ¨æ€åŸŽå¸‚åœºæ™¯ä¸­çš„ç›¸æœºå§¿æ€ä¼°è®¡é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `åŠ¨æ€ç¥žç»è¾å°„åœº` `ç›¸æœºå§¿æ€ä¼°è®¡` `åŸŽå¸‚åœºæ™¯é‡å»º` `è‡ªç›‘ç£å­¦ä¹ ` `ä¸‰ç»´åœºæ™¯æµ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰NeRFæ–¹æ³•åœ¨åŠ¨æ€åŸŽå¸‚åœºæ™¯ä¸­é¢ä¸´ç›¸æœºå§¿æ€ä¼°è®¡ä¸å‡†ç¡®å’ŒåŠ¨æ€ç‰©ä½“é‡å»ºå›°éš¾çš„æŒ‘æˆ˜ã€‚
2. VDNeRFé€šè¿‡è§†è§‰ä¿¡æ¯æ¢å¤ç›¸æœºè½¨è¿¹ï¼Œå¹¶ä½¿ç”¨ä¸¤ä¸ªNeRFæ¨¡åž‹åˆ†åˆ«å¤„ç†é™æ€å’ŒåŠ¨æ€å…ƒç´ ï¼Œé¿å…äº†å¯¹é¢å¤–ä¼ æ„Ÿå™¨æ•°æ®çš„ä¾èµ–ã€‚
3. å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒVDNeRFåœ¨ä¸»æµåŸŽå¸‚é©¾é©¶æ•°æ®é›†ä¸Šï¼Œè¶…è¶Šäº†æœ€å…ˆè¿›çš„æ— å§¿æ€NeRFæ–¹æ³•ï¼Œæå‡äº†ç›¸æœºå§¿æ€ä¼°è®¡å’ŒåŠ¨æ€è§†è§’åˆæˆçš„æ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¥žç»è¾å°„åœºï¼ˆNeRFï¼‰é€šè¿‡å·²çŸ¥ç›¸æœºå§¿æ€çš„å›¾åƒé›†éšå¼å»ºæ¨¡è¿žç»­ä¸‰ç»´åœºæ™¯ï¼Œä»Žè€Œå®žçŽ°é€¼çœŸçš„æ–°è§†è§’æ¸²æŸ“ã€‚ç„¶è€Œï¼ŒçŽ°æœ‰NeRFæ–¹æ³•åœ¨è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººæ„ŸçŸ¥ç­‰åº”ç”¨ä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦æ˜¯ç”±äºŽå‡†ç¡®æ•æ‰ç›¸æœºå§¿æ€çš„å›°éš¾ä»¥åŠå¤„ç†å¤§è§„æ¨¡åŠ¨æ€çŽ¯å¢ƒçš„å±€é™æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†è§†è§‰ä¸“ç”¨åŠ¨æ€NeRFï¼ˆVDNeRFï¼‰ï¼Œè¯¥æ–¹æ³•æ— éœ€é¢å¤–çš„ç›¸æœºå§¿æ€ä¿¡æ¯æˆ–æ˜‚è´µçš„ä¼ æ„Ÿå™¨æ•°æ®ï¼Œèƒ½å¤Ÿå‡†ç¡®æ¢å¤ç›¸æœºè½¨è¿¹å¹¶å­¦ä¹ åŠ¨æ€åŸŽå¸‚åœºæ™¯çš„æ—¶ç©ºè¡¨ç¤ºã€‚VDNeRFé‡‡ç”¨ä¸¤ä¸ªç‹¬ç«‹çš„NeRFæ¨¡åž‹å…±åŒé‡å»ºåœºæ™¯ï¼Œå…¶ä¸­é™æ€NeRFæ¨¡åž‹ä¼˜åŒ–ç›¸æœºå§¿æ€å’Œé™æ€èƒŒæ™¯ï¼Œè€ŒåŠ¨æ€NeRFæ¨¡åž‹ç»“åˆä¸‰ç»´åœºæ™¯æµä»¥ç¡®ä¿åŠ¨æ€ç‰©ä½“çš„å‡†ç¡®ä¸€è‡´é‡å»ºã€‚é€šè¿‡æœ‰æ•ˆçš„è®­ç»ƒæ¡†æž¶ï¼ŒVDNeRFå®žçŽ°äº†ç¨³å¥çš„ç›¸æœºå§¿æ€ä¼°è®¡å’Œé™æ€ä¸ŽåŠ¨æ€å…ƒç´ çš„è‡ªç›‘ç£åˆ†è§£ã€‚å¤§é‡è¯„ä¼°è¡¨æ˜Žï¼ŒVDNeRFåœ¨ç›¸æœºå§¿æ€ä¼°è®¡å’ŒåŠ¨æ€æ–°è§†è§’åˆæˆæ–¹é¢è¶…è¶Šäº†çŽ°æœ‰çš„æ— å§¿æ€NeRFæ–¹æ³•ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŠ¨æ€åŸŽå¸‚åœºæ™¯ä¸­ç›¸æœºå§¿æ€ä¼°è®¡ä¸å‡†ç¡®å’ŒåŠ¨æ€ç‰©ä½“é‡å»ºå›°éš¾çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•åœ¨æ•æ‰ç›¸æœºå§¿æ€å’Œå¤„ç†å¤§è§„æ¨¡åŠ¨æ€çŽ¯å¢ƒæ—¶å­˜åœ¨æ˜¾è‘—å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVDNeRFçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è§†è§‰ä¿¡æ¯æ¢å¤ç›¸æœºè½¨è¿¹ï¼Œå¹¶åˆ©ç”¨ä¸¤ä¸ªç‹¬ç«‹çš„NeRFæ¨¡åž‹åˆ†åˆ«å¤„ç†é™æ€èƒŒæ™¯å’ŒåŠ¨æ€ç‰©ä½“ï¼Œä»Žè€Œå®žçŽ°é«˜è´¨é‡çš„åœºæ™¯é‡å»ºã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šVDNeRFçš„æ•´ä½“æž¶æž„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé™æ€NeRFæ¨¡åž‹å’ŒåŠ¨æ€NeRFæ¨¡åž‹ã€‚é™æ€NeRFæ¨¡åž‹è´Ÿè´£ä¼˜åŒ–ç›¸æœºå§¿æ€å’Œé™æ€èƒŒæ™¯ï¼Œè€ŒåŠ¨æ€NeRFæ¨¡åž‹åˆ™ç»“åˆä¸‰ç»´åœºæ™¯æµæ¥å¤„ç†åŠ¨æ€ç‰©ä½“ã€‚

**å…³é”®åˆ›æ–°**ï¼šVDNeRFçš„å…³é”®åˆ›æ–°åœ¨äºŽè®¾è®¡äº†ä¸€ç§æœ‰æ•ˆçš„è®­ç»ƒæ¡†æž¶ï¼Œèƒ½å¤Ÿå®žçŽ°ç¨³å¥çš„ç›¸æœºå§¿æ€ä¼°è®¡å’Œé™æ€ä¸ŽåŠ¨æ€å…ƒç´ çš„è‡ªç›‘ç£åˆ†è§£ã€‚è¿™ä¸€æ–¹æ³•ä¸ŽçŽ°æœ‰çš„ä¾èµ–é¢å¤–ä¼ æ„Ÿå™¨æ•°æ®çš„NeRFæ–¹æ³•æœ¬è´¨ä¸Šä¸åŒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼ŒVDNeRFé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç›¸æœºå§¿æ€å’Œåœºæ™¯é‡å»ºï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æž„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿åŠ¨æ€ç‰©ä½“çš„å‡†ç¡®é‡å»ºå’Œä¸€è‡´æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œæž¶æž„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨å®žéªŒä¸­ï¼ŒVDNeRFåœ¨ä¸»æµåŸŽå¸‚é©¾é©¶æ•°æ®é›†ä¸Šè¡¨çŽ°ä¼˜å¼‚ï¼Œç›¸æ¯”äºŽæœ€å…ˆè¿›çš„æ— å§¿æ€NeRFæ–¹æ³•ï¼ŒVDNeRFåœ¨ç›¸æœºå§¿æ€ä¼°è®¡å’ŒåŠ¨æ€æ–°è§†è§’åˆæˆæ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªè¯¦ç»†åˆ—å‡ºï¼Œä½†æ•´ä½“æ•ˆæžœè¶…è¶Šäº†çŽ°æœ‰æŠ€æœ¯ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

VDNeRFçš„ç ”ç©¶æˆæžœåœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººæ„ŸçŸ¥å’Œè™šæ‹ŸçŽ°å®žç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æä¾›é«˜è´¨é‡çš„åŠ¨æ€åœºæ™¯é‡å»ºï¼ŒVDNeRFèƒ½å¤Ÿæå‡è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„çŽ¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ï¼Œå¹¶ä¸ºæœºå™¨äººåœ¨å¤æ‚åŸŽå¸‚çŽ¯å¢ƒä¸­çš„å¯¼èˆªæä¾›æ”¯æŒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•çš„è‡ªç›‘ç£ç‰¹æ€§é™ä½Žäº†å¯¹æ˜‚è´µä¼ æ„Ÿå™¨çš„ä¾èµ–ï¼Œå…·æœ‰é‡è¦çš„å®žé™…ä»·å€¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Neural Radiance Fields (NeRFs) implicitly model continuous three-dimensional scenes using a set of images with known camera poses, enabling the rendering of photorealistic novel views. However, existing NeRF-based methods encounter challenges in applications such as autonomous driving and robotic perception, primarily due to the difficulty of capturing accurate camera poses and limitations in handling large-scale dynamic environments. To address these issues, we propose Vision-only Dynamic NeRF (VDNeRF), a method that accurately recovers camera trajectories and learns spatiotemporal representations for dynamic urban scenes without requiring additional camera pose information or expensive sensor data. VDNeRF employs two separate NeRF models to jointly reconstruct the scene. The static NeRF model optimizes camera poses and static background, while the dynamic NeRF model incorporates the 3D scene flow to ensure accurate and consistent reconstruction of dynamic objects. To address the ambiguity between camera motion and independent object motion, we design an effective and powerful training framework to achieve robust camera pose estimation and self-supervised decomposition of static and dynamic elements in a scene. Extensive evaluations on mainstream urban driving datasets demonstrate that VDNeRF surpasses state-of-the-art NeRF-based pose-free methods in both camera pose estimation and dynamic novel view synthesis.

