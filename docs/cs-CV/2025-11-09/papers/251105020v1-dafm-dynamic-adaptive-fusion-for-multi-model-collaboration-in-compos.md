---
layout: default
title: DAFM: Dynamic Adaptive Fusion for Multi-Model Collaboration in Composed Image Retrieval
---

# DAFM: Dynamic Adaptive Fusion for Multi-Model Collaboration in Composed Image Retrieval

**arXiv**: [2511.05020v1](https://arxiv.org/abs/2511.05020) | [PDF](https://arxiv.org/pdf/2511.05020.pdf)

**ä½œè€…**: Yawei Cai, Jiapeng Mi, Nan Ji, Haotian Rong, Yawei Zhang, Zhangti Li, Wenbin Guo, Rensong Xie

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŠ¨æ€è‡ªé€‚åº”èžåˆæ–¹æ³•ä»¥è§£å†³ç»„åˆå›¾åƒæ£€ç´¢ä¸­å•æ¨¡åž‹èžåˆä¸è¶³é—®é¢˜**

**å…³é”®è¯**: `ç»„åˆå›¾åƒæ£€ç´¢` `åŠ¨æ€èžåˆ` `å¤šæ¨¡åž‹åä½œ` `å¼‚æž„æ¨¡åž‹` `æ£€ç´¢ç²¾åº¦` `è‡ªé€‚åº”æƒé‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå•æ¨¡åž‹åœ¨ç»„åˆå›¾åƒæ£€ç´¢ä¸­éš¾ä»¥åŒæ—¶å¤„ç†å…¨å±€ä¸Žç»†èŠ‚ï¼Œä¸”ç¼ºä¹åŠ¨æ€æƒé‡åˆ†é…å¯¼è‡´åµŒå…¥åå·®
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨å¼‚æž„æ¨¡åž‹äº’è¡¥ä¼˜åŠ¿ï¼ŒåŠ¨æ€è°ƒæ•´æ¨¡åž‹è´¡çŒ®ï¼Œæå‡èžåˆé²æ£’æ€§å’Œæ£€ç´¢ç²¾åº¦
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CIRRå’ŒFashionIQåŸºå‡†ä¸ŠRecall@10è¾¾93.21ï¼Œå¹³å‡Rmeanæå‡æœ€é«˜4.5%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Composed Image Retrieval (CIR) is a cross-modal task that aims to retrieve
> target images from large-scale databases using a reference image and a
> modification text. Most existing methods rely on a single model to perform
> feature fusion and similarity matching. However, this paradigm faces two major
> challenges. First, one model alone can't see the whole picture and the tiny
> details at the same time; it has to handle different tasks with the same
> weights, so it often misses the small but important links between image and
> text. Second, the absence of dynamic weight allocation prevents adaptive
> leveraging of complementary model strengths, so the resulting embedding drifts
> away from the target and misleads the nearest-neighbor search in CIR. To
> address these limitations, we propose Dynamic Adaptive Fusion (DAFM) for
> multi-model collaboration in CIR. Rather than optimizing a single method in
> isolation, DAFM exploits the complementary strengths of heterogeneous models
> and adaptively rebalances their contributions. This not only maximizes
> retrieval accuracy but also ensures that the performance gains are independent
> of the fusion order, highlighting the robustness of our approach. Experiments
> on the CIRR and FashionIQ benchmarks demonstrate consistent improvements. Our
> method achieves a Recall@10 of 93.21 and an Rmean of 84.43 on CIRR, and an
> average Rmean of 67.48 on FashionIQ, surpassing recent strong baselines by up
> to 4.5%. These results confirm that dynamic multi-model collaboration provides
> an effective and general solution for CIR.

