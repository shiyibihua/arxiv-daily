---
layout: default
title: Cross-domain EEG-based Emotion Recognition with Contrastive Learning
---

# Cross-domain EEG-based Emotion Recognition with Contrastive Learning

**arXiv**: [2511.05293v1](https://arxiv.org/abs/2511.05293) | [PDF](https://arxiv.org/pdf/2511.05293.pdf)

**ä½œè€…**: Rui Yan, Yibo Li, Han Ding, Fei Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEmotionCLIPæ¡†æž¶ï¼Œé€šè¿‡EEG-æ–‡æœ¬åŒ¹é…è§£å†³è·¨åŸŸè„‘ç”µæƒ…ç»ªè¯†åˆ«é—®é¢˜**

**å…³é”®è¯**: `è„‘ç”µæƒ…ç»ªè¯†åˆ«` `è·¨åŸŸå­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `å¤šæ¨¡æ€åŒ¹é…` `Transformerç½‘ç»œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè„‘ç”µæƒ…ç»ªè¯†åˆ«é¢ä¸´ç‰¹å¾åˆ©ç”¨ä¸è¶³å’Œè·¨åŸŸæ³›åŒ–æŒ‘æˆ˜
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨SST-LegoViTéª¨å¹²ç½‘ç»œæå–ç©ºé—´ã€é¢‘è°±å’Œæ—¶é—´ç‰¹å¾
3. å®žéªŒæ•ˆæžœï¼šåœ¨SEEDå’ŒSEED-IVæ•°æ®é›†ä¸Šå®žçŽ°é«˜è·¨åŸŸå‡†ç¡®çŽ‡ï¼Œä¼˜äºŽçŽ°æœ‰æ¨¡åž‹

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Electroencephalogram (EEG)-based emotion recognition is vital for affective
> computing but faces challenges in feature utilization and cross-domain
> generalization. This work introduces EmotionCLIP, which reformulates
> recognition as an EEG-text matching task within the CLIP framework. A tailored
> backbone, SST-LegoViT, captures spatial, spectral, and temporal features using
> multi-scale convolution and Transformer modules. Experiments on SEED and
> SEED-IV datasets show superior cross-subject accuracies of 88.69% and 73.50%,
> and cross-time accuracies of 88.46% and 77.54%, outperforming existing models.
> Results demonstrate the effectiveness of multimodal contrastive learning for
> robust EEG emotion recognition.

