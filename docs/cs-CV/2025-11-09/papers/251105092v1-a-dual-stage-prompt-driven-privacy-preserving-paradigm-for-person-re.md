---
layout: default
title: A Dual-stage Prompt-driven Privacy-preserving Paradigm for Person Re-Identification
---

# A Dual-stage Prompt-driven Privacy-preserving Paradigm for Person Re-Identification

**arXiv**: [2511.05092v1](https://arxiv.org/abs/2511.05092) | [PDF](https://arxiv.org/pdf/2511.05092.pdf)

**ä½œè€…**: Ruolin Li, Min Liu, Yuan Bian, Zhaoyang Li, Yuzhen Li, Xueping Wang, Yaonan Wang

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒé˜¶æ®µæç¤ºé©±åŠ¨éšç§ä¿æŠ¤èŒƒå¼ï¼Œè§£å†³è¡Œäººé‡è¯†åˆ«ä¸­è™šæ‹Ÿæ•°æ®æ„å»ºä¸æ³›åŒ–éš¾é¢˜**

**å…³é”®è¯**: `è¡Œäººé‡è¯†åˆ«` `éšç§ä¿æŠ¤` `æ‰©æ•£æ¨¡å‹` `æç¤ºé©±åŠ¨` `åŸŸæ³›åŒ–` `å¯¹æ¯”å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè™šæ‹Ÿæ•°æ®é›†æ„å»ºå¤æ‚ä¸”æ³›åŒ–èƒ½åŠ›å·®ï¼Œéš¾ä»¥ç”¨äºå®é™…è¡Œäººé‡è¯†åˆ«åœºæ™¯
2. æ–¹æ³•è¦ç‚¹ï¼šé¦–é˜¶æ®µç”¨å¤šç»´æç¤ºé©±åŠ¨æ‰©æ•£æ¨¡å‹åˆæˆå¤šæ ·æ•°æ®ï¼›æ¬¡é˜¶æ®µé€šè¿‡æç¤ºé©±åŠ¨è§£è€¦æœºåˆ¶å­¦ä¹ åŸŸä¸å˜ç‰¹å¾
3. å®éªŒæˆ–æ•ˆæœï¼šåœ¨GenePersonæ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œæ³›åŒ–æ€§èƒ½è¾¾åˆ°æœ€å…ˆè¿›æ°´å¹³ï¼Œè¶…è¶ŠçœŸå®å’Œè™šæ‹Ÿæ•°æ®é›†

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With growing concerns over data privacy, researchers have started using
> virtual data as an alternative to sensitive real-world images for training
> person re-identification (Re-ID) models. However, existing virtual datasets
> produced by game engines still face challenges such as complex construction and
> poor domain generalization, making them difficult to apply in real scenarios.
> To address these challenges, we propose a Dual-stage Prompt-driven
> Privacy-preserving Paradigm (DPPP). In the first stage, we generate rich
> prompts incorporating multi-dimensional attributes such as pedestrian
> appearance, illumination, and viewpoint that drive the diffusion model to
> synthesize diverse data end-to-end, building a large-scale virtual dataset
> named GenePerson with 130,519 images of 6,641 identities. In the second stage,
> we propose a Prompt-driven Disentanglement Mechanism (PDM) to learn
> domain-invariant generalization features. With the aid of contrastive learning,
> we employ two textual inversion networks to map images into pseudo-words
> representing style and content, respectively, thereby constructing
> style-disentangled content prompts to guide the model in learning
> domain-invariant content features at the image level. Experiments demonstrate
> that models trained on GenePerson with PDM achieve state-of-the-art
> generalization performance, surpassing those on popular real and virtual Re-ID
> datasets.

