---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-08-15
---

# cs.CVï¼ˆ2025-08-15ï¼‰

ğŸ“Š å…± **5** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250811834v1-recent-advances-in-transformer-and-large-language-models-for-uav-app.html">Recent Advances in Transformer and Large Language Models for UAV Applications</a></td>
  <td>ç³»ç»Ÿè¯„ä¼°Transformeræ¨¡å‹åœ¨æ— äººæœºåº”ç”¨ä¸­çš„è¿›å±•ä¸æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11834v1" data-paper-url="./papers/250811834v1-recent-advances-in-transformer-and-large-language-models-for-uav-app.html" onclick="toggleFavorite(this, '2508.11834v1', 'Recent Advances in Transformer and Large Language Models for UAV Applications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250811737v1-ovis25-technical-report.html">Ovis2.5 Technical Report</a></td>
  <td>æå‡ºOvis2.5ä»¥è§£å†³å¤šæ¨¡æ€æ¨ç†ä¸è§†è§‰æ„ŸçŸ¥é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">DPO</span> <span class="paper-tag">multimodal</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11737v1" data-paper-url="./papers/250811737v1-ovis25-technical-report.html" onclick="toggleFavorite(this, '2508.11737v1', 'Ovis2.5 Technical Report')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>3</td>
  <td><a href="./papers/250819257v3-ttf-vla-temporal-token-fusion-via-pixel-attention-integration-for-vi.html">TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models</a></td>
  <td>æå‡ºTTFä»¥è§£å†³è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹ä¸­çš„æ—¶é—´ä¿¡æ¯ç¼ºå¤±é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.19257v3" data-paper-url="./papers/250819257v3-ttf-vla-temporal-token-fusion-via-pixel-attention-integration-for-vi.html" onclick="toggleFavorite(this, '2508.19257v3', 'TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>4</td>
  <td><a href="./papers/250811616v1-controlling-multimodal-llms-via-reward-guided-decoding.html">Controlling Multimodal LLMs via Reward-guided Decoding</a></td>
  <td>æå‡ºå¥–åŠ±å¼•å¯¼è§£ç æ–¹æ³•ä»¥æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å¯æ§æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span> <span class="paper-tag">visual grounding</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11616v1" data-paper-url="./papers/250811616v1-controlling-multimodal-llms-via-reward-guided-decoding.html" onclick="toggleFavorite(this, '2508.11616v1', 'Controlling Multimodal LLMs via Reward-guided Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>5</td>
  <td><a href="./papers/250811808v1-labels-or-input-rethinking-augmentation-in-multimodal-hate-detection.html">Labels or Input? Rethinking Augmentation in Multimodal Hate Detection</a></td>
  <td>æå‡ºåŒé‡æ–¹æ³•ä»¥æå‡å¤šæ¨¡æ€ä»‡æ¨æ£€æµ‹çš„å‡†ç¡®æ€§</td>
  <td class="tags-cell"><span class="paper-tag">HuMoR</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11808v1" data-paper-url="./papers/250811808v1-labels-or-input-rethinking-augmentation-in-multimodal-hate-detection.html" onclick="toggleFavorite(this, '2508.11808v1', 'Labels or Input? Rethinking Augmentation in Multimodal Hate Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)