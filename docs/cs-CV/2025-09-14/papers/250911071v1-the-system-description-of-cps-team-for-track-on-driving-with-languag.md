---
layout: default
title: The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge
---

# The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.11071" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.11071v1</a>
  <a href="https://arxiv.org/pdf/2509.11071.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.11071v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.11071v1', 'The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jinghan Peng, Jingwen Wang, Xing Yu, Dehui Du

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-14

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**CPSå›¢é˜Ÿæå‡ºåŸºäºLLaVAå¾®è°ƒå’Œæ·±åº¦ä¿¡æ¯èåˆçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œç”¨äºCVPR 2024è‡ªåŠ¨é©¾é©¶æŒ‘æˆ˜èµ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `è‡ªåŠ¨é©¾é©¶` `LLaVA` `LoRA` `DoRA` `æ·±åº¦ä¼°è®¡` `Chain-of-Thought`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­ï¼Œå¯¹å¤æ‚æŒ‡ä»¤ç†è§£å’Œæ¨ç†èƒ½åŠ›ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤šæ¨¡æ€ä¿¡æ¯èåˆæ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚
2. è¯¥æ–¹æ³•é€šè¿‡å¾®è°ƒLLaVAæ¨¡å‹ï¼Œå¹¶ç»“åˆLoRAå’ŒDoRAæŠ€æœ¯ï¼Œæå‡æ¨¡å‹åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šçš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨DriveLM-nuScenesæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒéªŒè¯é›†æ’è¡Œæ¦œä¸Šæ’åç¬¬ä¸€ï¼Œå¾—åˆ†ä¸º0.7799ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æŠ¥å‘Šæ¦‚è¿°äº†æˆ‘ä»¬åœ¨CVPR 2024è‡ªåŠ¨é©¾é©¶æŒ‘æˆ˜èµ›â€œåŸºäºè¯­è¨€çš„é©¾é©¶â€èµ›é“ä¸­ï¼Œä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ç³»ç»Ÿçš„æ–¹æ³•ã€‚æˆ‘ä»¬å®Œå…¨ä½¿ç”¨DriveLM-nuScenesæ•°æ®é›†æ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿå»ºç«‹åœ¨LLaVAæ¨¡å‹ä¹‹ä¸Šï¼Œå¹¶é€šè¿‡LoRAå’ŒDoRAæ–¹æ³•è¿›è¡Œå¾®è°ƒæ¥å¢å¼ºæ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é›†æˆäº†æ¥è‡ªå¼€æºæ·±åº¦ä¼°è®¡æ¨¡å‹çš„æ·±åº¦ä¿¡æ¯ï¼Œä»¥ä¸°å¯Œè®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ã€‚å¯¹äºæ¨ç†ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤šé¡¹é€‰æ‹©é¢˜å’Œæ˜¯/å¦é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†Chain-of-Thoughtï¼ˆCoTï¼Œæ€ç»´é“¾ï¼‰æ¨ç†æ–¹æ³•ï¼Œä»¥æé«˜ç»“æœçš„å‡†ç¡®æ€§ã€‚è¿™ç§å…¨é¢çš„æ–¹æ³•ä½¿æˆ‘ä»¬åœ¨éªŒè¯é›†æ’è¡Œæ¦œä¸Šè·å¾—äº†0.7799çš„æœ€é«˜åˆ†ï¼Œæ’åç¬¬ä¸€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸‹ï¼Œè§†è§‰è¯­è¨€æ¨¡å‹å¦‚ä½•æ›´å¥½åœ°ç†è§£å’Œæ‰§è¡ŒåŸºäºè‡ªç„¶è¯­è¨€çš„é©¾é©¶æŒ‡ä»¤çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚åœºæ™¯å’ŒæŒ‡ä»¤æ—¶ï¼Œå¾€å¾€ç¼ºä¹è¶³å¤Ÿçš„æ¨ç†èƒ½åŠ›å’Œå¯¹ç¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¤šæ¨¡æ€ä¿¡æ¯èåˆæ–¹é¢å­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„LLaVAæ¨¡å‹ä½œä¸ºåŸºç¡€ï¼Œé€šè¿‡å¾®è°ƒå’ŒçŸ¥è¯†å¢å¼ºæ¥æå‡å…¶åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡LoRAå’ŒDoRAç­‰é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”DriveLM-nuScenesæ•°æ®é›†ã€‚åŒæ—¶ï¼Œå¼•å…¥æ·±åº¦ä¿¡æ¯æ¥å¢å¼ºæ¨¡å‹å¯¹ç¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¹¶é‡‡ç”¨Chain-of-Thoughtæ¨ç†æ–¹æ³•æ¥æé«˜æ¨ç†çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹å¾®è°ƒå’Œæ¨ç†ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚æ•°æ®é¢„å¤„ç†é˜¶æ®µä¸»è¦å¯¹DriveLM-nuScenesæ•°æ®é›†è¿›è¡Œæ¸…æ´—å’Œæ ¼å¼åŒ–ï¼Œå¹¶åˆ©ç”¨å¼€æºæ·±åº¦ä¼°è®¡æ¨¡å‹ç”Ÿæˆæ·±åº¦ä¿¡æ¯ã€‚æ¨¡å‹å¾®è°ƒé˜¶æ®µä½¿ç”¨LoRAå’ŒDoRAæ–¹æ³•å¯¹LLaVAæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶é€‚åº”è‡ªåŠ¨é©¾é©¶åœºæ™¯ã€‚æ¨ç†é˜¶æ®µåˆ™é‡‡ç”¨Chain-of-Thoughtæ¨ç†æ–¹æ³•ï¼Œé€æ­¥æ¨å¯¼ç­”æ¡ˆï¼Œæé«˜å‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†æ·±åº¦ä¿¡æ¯èå…¥åˆ°è§†è§‰è¯­è¨€æ¨¡å‹ä¸­ï¼Œä»è€Œå¢å¼ºäº†æ¨¡å‹å¯¹ç¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨Chain-of-Thoughtæ¨ç†æ–¹æ³•ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œæ›´å¤æ‚çš„æ¨ç†ï¼Œæé«˜äº†ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚åŒæ—¶ï¼Œä½¿ç”¨LoRAå’ŒDoRAç­‰é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼Œé™ä½äº†è®­ç»ƒæˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹å¾®è°ƒé˜¶æ®µï¼Œé‡‡ç”¨äº†LoRAå’ŒDoRAä¸¤ç§æ–¹æ³•ï¼Œä»¥å¹³è¡¡è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚å…·ä½“å‚æ•°è®¾ç½®æœªçŸ¥ã€‚æ·±åº¦ä¿¡æ¯çš„èåˆæ–¹å¼ä¹ŸæœªçŸ¥ã€‚Chain-of-Thoughtæ¨ç†æ–¹æ³•çš„å…·ä½“å®ç°ç»†èŠ‚ä¹ŸæœªçŸ¥ï¼Œä¾‹å¦‚promptçš„è®¾è®¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨CVPR 2024è‡ªåŠ¨é©¾é©¶æŒ‘æˆ˜èµ›çš„â€œåŸºäºè¯­è¨€çš„é©¾é©¶â€èµ›é“ä¸­ï¼Œåœ¨éªŒè¯é›†æ’è¡Œæ¦œä¸Šå–å¾—äº†0.7799çš„æœ€é«˜åˆ†ï¼Œæ’åç¬¬ä¸€ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼Œé€šè¿‡å¾®è°ƒLLaVAæ¨¡å‹ã€èåˆæ·±åº¦ä¿¡æ¯å’Œé‡‡ç”¨Chain-of-Thoughtæ¨ç†æ–¹æ³•ï¼Œå¯ä»¥æ˜¾è‘—æå‡è§†è§‰è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶æ±½è½¦çš„è‡ªç„¶è¯­è¨€äº¤äº’ç³»ç»Ÿï¼Œä¾‹å¦‚ï¼Œé©¾é©¶å‘˜å¯ä»¥é€šè¿‡è¯­éŸ³æŒ‡ä»¤æ§åˆ¶è½¦è¾†è¡Œé©¶ï¼Œæˆ–è€…è¯¢é—®è½¦è¾†å‘¨å›´ç¯å¢ƒä¿¡æ¯ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€æ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸï¼Œæå‡æœºå™¨å¯¹ç¯å¢ƒçš„ç†è§£å’Œäº¤äº’èƒ½åŠ›ã€‚æœªæ¥ï¼Œç»“åˆæ›´å…ˆè¿›çš„è§†è§‰å’Œè¯­è¨€æ¨¡å‹ï¼Œæœ‰æœ›å®ç°æ›´æ™ºèƒ½ã€æ›´å®‰å…¨çš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This report outlines our approach using vision language model systems for the Driving with Language track of the CVPR 2024 Autonomous Grand Challenge. We have exclusively utilized the DriveLM-nuScenes dataset for training our models. Our systems are built on the LLaVA models, which we enhanced through fine-tuning with the LoRA and DoRA methods. Additionally, we have integrated depth information from open-source depth estimation models to enrich the training and inference processes. For inference, particularly with multiple-choice and yes/no questions, we adopted a Chain-of-Thought reasoning approach to improve the accuracy of the results. This comprehensive methodology enabled us to achieve a top score of 0.7799 on the validation set leaderboard, ranking 1st on the leaderboard.

