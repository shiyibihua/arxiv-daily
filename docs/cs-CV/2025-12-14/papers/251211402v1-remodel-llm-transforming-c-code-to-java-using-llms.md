---
layout: default
title: REMODEL-LLM: Transforming C code to Java using LLMs
---

# REMODEL-LLM: Transforming C code to Java using LLMs

**arXiv**: [2512.11402v1](https://arxiv.org/abs/2512.11402) | [PDF](https://arxiv.org/pdf/2512.11402.pdf)

**ä½œè€…**: Aryan Gupta, Y. Raghu Reddy

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽASTå’Œè§„åˆ™æç¤ºçš„æ··åˆç®¡é“ï¼Œè¯„ä¼°å°é‡åŒ–LLMåœ¨Cåˆ°Javaä»£ç ç¿»è¯‘ä¸­çš„æ€§èƒ½**

**å…³é”®è¯**: `ä»£ç ç¿»è¯‘` `é‡åŒ–è¯­è¨€æ¨¡åž‹` `æŠ½è±¡è¯­æ³•æ ‘` `è§„åˆ™æç¤º` `Cåˆ°Javaè½¬æ¢` `æ€§èƒ½è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç ”ç©¶Cåˆ°Javaä»£ç è‡ªåŠ¨ç¿»è¯‘çš„æŒ‘æˆ˜ï¼Œæ¶‰åŠèŒƒå¼ã€å†…å­˜æ¨¡åž‹å’Œæ•°æ®ç±»åž‹å·®å¼‚
2. é‡‡ç”¨ASTè¯­ä¹‰åˆ†è§£å’Œçº¦æŸè§„åˆ™æç¤ºçš„æ··åˆæ–¹æ³•ï¼Œæµ‹è¯•19ä¸ªå°é‡åŒ–LLM
3. ç»“æžœæ˜¾ç¤ºä»…ä¸‰ä¸ªæ¨¡åž‹é€šè¿‡è¶…50%æµ‹è¯•ï¼Œä½†å¤æ‚æ¦‚å¿µå¦‚å‡½æ•°æŒ‡é’ˆä»å¤±è´¥

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The automated translation of C code to Java code is a notoriously difficult task, fraught with challenges stemming from fundamental paradigm shifts (procedural vs. Object Oriented), memory models (manual pointers vs. Garbage Collection), and incompatible data types. This paper investigates the efficacy of 19 small, quantized LLMs (under 20 billion parameters) for the C to Java translation task. We use a novel, hybrid pipeline that leverages Abstract Syntax Trees (ASTs) for semantic decomposition and employs a highly constrained, rule based prompting strategy. The results are stark: a clear multi tiered performance divide emerged. The vast majority of models (Tier 3, e.g., llama3.1, gemma3, starcoder2) failed 100\% of the tests, proving incapable of generating even basic, runnable Java boilerplate. A small middle tier (Tier 2, e.g., mistral-nemo and mistral) produced runnable code but was plagued by dangerous semantic failures and wrong translations. Only three models (Tier 1: phi4, deepseek-coder-v2, codeqwen) proved viable, passing over 50\% of the test suite. Even these top models failed on the most complex C concepts, such as function pointers, sizeof, and enum logic, revealing a hard ceiling for the reasoning capabilities of current quantized models.

