---
layout: default
title: PersonaLive! Expressive Portrait Image Animation for Live Streaming
---

# PersonaLive! Expressive Portrait Image Animation for Live Streaming

**arXiv**: [2512.11253v1](https://arxiv.org/abs/2512.11253) | [PDF](https://arxiv.org/pdf/2512.11253.pdf)

**ä½œè€…**: Zhiyuan Li, Chi-Man Pun, Chen Fang, Jue Wang, Xiaodong Cun

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPersonaLiveæ¡†æž¶ï¼Œé€šè¿‡æ··åˆéšå¼ä¿¡å·å’Œè’¸é¦ç­–ç•¥å®žçŽ°ç›´æ’­åœºæ™¯ä¸‹çš„å®žæ—¶è‚–åƒåŠ¨ç”»ã€‚**

**å…³é”®è¯**: `è‚–åƒåŠ¨ç”»` `æ‰©æ•£æ¨¡åž‹` `å®žæ—¶ç”Ÿæˆ` `éšå¼è¡¨ç¤º` `è’¸é¦è®­ç»ƒ` `ç›´æ’­åº”ç”¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰æ‰©æ•£æ¨¡åž‹åœ¨è‚–åƒåŠ¨ç”»ä¸­å¿½è§†ç”Ÿæˆå»¶è¿Ÿå’Œå®žæ—¶æ€§èƒ½ï¼Œé™åˆ¶ç›´æ’­åº”ç”¨ã€‚
2. é‡‡ç”¨æ··åˆéšå¼ä¿¡å·å’Œè¾ƒå°‘æ­¥æ•°å¤–è§‚è’¸é¦ï¼Œæå‡è¿åŠ¨æŽ§åˆ¶å’ŒæŽ¨ç†æ•ˆçŽ‡ã€‚
3. å®žéªŒæ˜¾ç¤ºPersonaLiveåœ¨æ€§èƒ½ä¸Šè¾¾åˆ°å…ˆè¿›æ°´å¹³ï¼Œé€Ÿåº¦æå‡7-22å€ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Current diffusion-based portrait animation models predominantly focus on enhancing visual quality and expression realism, while overlooking generation latency and real-time performance, which restricts their application range in the live streaming scenario. We propose PersonaLive, a novel diffusion-based framework towards streaming real-time portrait animation with multi-stage training recipes. Specifically, we first adopt hybrid implicit signals, namely implicit facial representations and 3D implicit keypoints, to achieve expressive image-level motion control. Then, a fewer-step appearance distillation strategy is proposed to eliminate appearance redundancy in the denoising process, greatly improving inference efficiency. Finally, we introduce an autoregressive micro-chunk streaming generation paradigm equipped with a sliding training strategy and a historical keyframe mechanism to enable low-latency and stable long-term video generation. Extensive experiments demonstrate that PersonaLive achieves state-of-the-art performance with up to 7-22x speedup over prior diffusion-based portrait animation models.

