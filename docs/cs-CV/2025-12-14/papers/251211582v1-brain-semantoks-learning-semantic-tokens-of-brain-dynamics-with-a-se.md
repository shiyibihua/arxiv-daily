---
layout: default
title: Brain-Semantoks: Learning Semantic Tokens of Brain Dynamics with a Self-Distilled Foundation Model
---

# Brain-Semantoks: Learning Semantic Tokens of Brain Dynamics with a Self-Distilled Foundation Model

**arXiv**: [2512.11582v1](https://arxiv.org/abs/2512.11582) | [PDF](https://arxiv.org/pdf/2512.11582.pdf)

**ä½œè€…**: Sam Gijsen, Marc-Andre Schulz, Kerstin Ritter

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBrain-Semantoksæ¡†æž¶ä»¥å­¦ä¹ è„‘åŠŸèƒ½ç£å…±æŒ¯æˆåƒæ—¶é—´åºåˆ—çš„æŠ½è±¡è¡¨ç¤ºï¼Œæå‡ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ã€‚**

**å…³é”®è¯**: `åŠŸèƒ½ç£å…±æŒ¯æˆåƒ` `è‡ªç›‘ç£å­¦ä¹ ` `è¯­ä¹‰åˆ†è¯å™¨` `è‡ªè’¸é¦` `è„‘åŠ¨åŠ›å­¦` `åŸºç¡€æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰fMRIåŸºç¡€æ¨¡åž‹å¸¸åŸºäºŽå°åŒºåŸŸæŽ©ç é‡å»ºè®­ç»ƒï¼Œå¯¼è‡´è¡¨ç¤ºå¯¹å™ªå£°æ•æ„Ÿï¼Œéœ€å¤§é‡å¾®è°ƒã€‚
2. å¼•å…¥è¯­ä¹‰åˆ†è¯å™¨èšåˆåŒºåŸŸä¿¡å·ä¸ºåŠŸèƒ½ç½‘ç»œä»¤ç‰Œï¼Œç»“åˆè‡ªè’¸é¦ç›®æ ‡å¢žå¼ºæ—¶é—´ç¨³å®šæ€§ã€‚
3. å­¦ä¹ è¡¨ç¤ºåœ¨çº¿æ€§æŽ¢é’ˆä¸‹å®žçŽ°å¼ºä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ï¼Œç¼©æ”¾åˆ†æžæ˜¾ç¤ºæ— æ ‡ç­¾æ•°æ®æå‡åˆ†å¸ƒå¤–æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The development of foundation models for functional magnetic resonance imaging (fMRI) time series holds significant promise for predicting phenotypes related to disease and cognition. Current models, however, are often trained using a mask-and-reconstruct objective on small brain regions. This focus on low-level information leads to representations that are sensitive to noise and temporal fluctuations, necessitating extensive fine-tuning for downstream tasks. We introduce Brain-Semantoks, a self-supervised framework designed specifically to learn abstract representations of brain dynamics. Its architecture is built on two core innovations: a semantic tokenizer that aggregates noisy regional signals into robust tokens representing functional networks, and a self-distillation objective that enforces representational stability across time. We show that this objective is stabilized through a novel training curriculum, ensuring the model robustly learns meaningful features from low signal-to-noise time series. We demonstrate that learned representations enable strong performance on a variety of downstream tasks even when only using a linear probe. Furthermore, we provide comprehensive scaling analyses indicating more unlabeled data reliably results in out-of-distribution performance gains without domain adaptation.

