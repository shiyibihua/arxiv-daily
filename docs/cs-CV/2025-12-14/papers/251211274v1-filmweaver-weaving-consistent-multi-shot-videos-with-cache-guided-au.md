---
layout: default
title: FilmWeaver: Weaving Consistent Multi-Shot Videos with Cache-Guided Autoregressive Diffusion
---

# FilmWeaver: Weaving Consistent Multi-Shot Videos with Cache-Guided Autoregressive Diffusion

**arXiv**: [2512.11274v1](https://arxiv.org/abs/2512.11274) | [PDF](https://arxiv.org/pdf/2512.11274.pdf)

**ä½œè€…**: Xiangyang Luo, Qingyu Li, Xiaokun Liu, Wenyu Qin, Miao Yang, Meng Wang, Pengfei Wan, Di Zhang, Kun Gai, Shao-Lun Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFilmWeaveræ¡†æž¶ï¼Œé€šè¿‡ç¼“å­˜å¼•å¯¼çš„è‡ªå›žå½’æ‰©æ•£ç”Ÿæˆä¸€è‡´çš„å¤šé•œå¤´è§†é¢‘**

**å…³é”®è¯**: `å¤šé•œå¤´è§†é¢‘ç”Ÿæˆ` `ä¸€è‡´æ€§ä¿æŒ` `è‡ªå›žå½’æ‰©æ•£æ¨¡åž‹` `ç¼“å­˜æœºåˆ¶` `è§†é¢‘æ•°æ®é›†æž„å»º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§†é¢‘ç”Ÿæˆæ¨¡åž‹éš¾ä»¥ä¿æŒå¤šé•œå¤´è§†é¢‘ä¸­è§’è‰²å’ŒèƒŒæ™¯çš„ä¸€è‡´æ€§ï¼Œä¸”æ— æ³•çµæ´»ç”Ÿæˆé•¿åº¦å’Œé•œå¤´æ•°ä»»æ„çš„è§†é¢‘ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨è‡ªå›žå½’æ‰©æ•£èŒƒå¼å®žçŽ°ä»»æ„é•¿åº¦ç”Ÿæˆï¼Œé€šè¿‡åŒçº§ç¼“å­˜æœºåˆ¶ï¼ˆé•œå¤´è®°å¿†å’Œæ—¶åºè®°å¿†ï¼‰è§£è€¦é•œå¤´é—´ä¸€è‡´æ€§å’Œé•œå¤´å†…è¿žè´¯æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä¸€è‡´æ€§å’Œç¾Žå­¦è´¨é‡æŒ‡æ ‡ä¸Šè¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œæ”¯æŒå¤šæ¦‚å¿µæ³¨å…¥å’Œè§†é¢‘æ‰©å±•ç­‰ä¸‹æ¸¸ä»»åŠ¡ï¼Œå¹¶æž„å»ºäº†é«˜è´¨é‡å¤šé•œå¤´è§†é¢‘æ•°æ®é›†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Current video generation models perform well at single-shot synthesis but struggle with multi-shot videos, facing critical challenges in maintaining character and background consistency across shots and flexibly generating videos of arbitrary length and shot count. To address these limitations, we introduce \textbf{FilmWeaver}, a novel framework designed to generate consistent, multi-shot videos of arbitrary length. First, it employs an autoregressive diffusion paradigm to achieve arbitrary-length video generation. To address the challenge of consistency, our key insight is to decouple the problem into inter-shot consistency and intra-shot coherence. We achieve this through a dual-level cache mechanism: a shot memory caches keyframes from preceding shots to maintain character and scene identity, while a temporal memory retains a history of frames from the current shot to ensure smooth, continuous motion. The proposed framework allows for flexible, multi-round user interaction to create multi-shot videos. Furthermore, due to this decoupled design, our method demonstrates high versatility by supporting downstream tasks such as multi-concept injection and video extension. To facilitate the training of our consistency-aware method, we also developed a comprehensive pipeline to construct a high-quality multi-shot video dataset. Extensive experimental results demonstrate that our method surpasses existing approaches on metrics for both consistency and aesthetic quality, opening up new possibilities for creating more consistent, controllable, and narrative-driven video content. Project Page: https://filmweaver.github.io

