---
layout: default
title: Seeing to Act, Prompting to Specify: A Bayesian Factorization of Vision Language Action Policy
---

# Seeing to Act, Prompting to Specify: A Bayesian Factorization of Vision Language Action Policy

**arXiv**: [2512.11218v1](https://arxiv.org/abs/2512.11218) | [PDF](https://arxiv.org/pdf/2512.11218.pdf)

**ä½œè€…**: Kechun Xu, Zhenjie Zhu, Anzhe Chen, Shuqi Zhao, Qing Huang, Yifei Yang, Haojian Lu, Rong Xiong, Masayoshi Tomizuka, Yue Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBayesVLAè´å¶æ–¯åˆ†è§£æ–¹æ³•ï¼Œè§£å†³è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹ä¸­æ¨¡æ€ä¸å¹³è¡¡å¯¼è‡´çš„æ³›åŒ–é—®é¢˜ã€‚**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `è´å¶æ–¯åˆ†è§£` `æ¨¡æ€ä¸å¹³è¡¡` `æ³›åŒ–èƒ½åŠ›` `ä¿¡æ¯è®ºåˆ†æž` `é¢„è®­ç»ƒæ¨¡åž‹åˆ©ç”¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šVLAæ¨¡åž‹å¾®è°ƒæ—¶å› æ¨¡æ€ä¸å¹³è¡¡ï¼ˆè¯­è¨€å¤šæ ·æ€§ä½Žï¼‰å¯¼è‡´è§†è§‰æ·å¾„å’Œè¯­è¨€é—å¿˜ï¼Œé˜»ç¢åˆ†å¸ƒå¤–æ³›åŒ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡è´å¶æ–¯åˆ†è§£å°†ç­–ç•¥åˆ†è§£ä¸ºè§†è§‰-åŠ¨ä½œå…ˆéªŒå’Œè¯­è¨€æ¡ä»¶ä¼¼ç„¶ï¼Œæ”¯æŒâ€œçœ‹åˆ°å³è¡ŒåŠ¨â€å’Œâ€œæç¤ºæŒ‡å®šâ€ï¼Œä¿ç•™æ³›åŒ–èƒ½åŠ›ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æœªè§æŒ‡ä»¤ã€å¯¹è±¡å’ŒçŽ¯å¢ƒä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œä¿¡æ¯è®ºåˆ†æžéªŒè¯ç¼“è§£æ·å¾„å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The pursuit of out-of-distribution generalization in Vision-Language-Action (VLA) models is often hindered by catastrophic forgetting of the Vision-Language Model (VLM) backbone during fine-tuning. While co-training with external reasoning data helps, it requires experienced tuning and data-related overhead. Beyond such external dependencies, we identify an intrinsic cause within VLA datasets: modality imbalance, where language diversity is much lower than visual and action diversity. This imbalance biases the model toward visual shortcuts and language forgetting. To address this, we introduce BayesVLA, a Bayesian factorization that decomposes the policy into a visual-action prior, supporting seeing-to-act, and a language-conditioned likelihood, enabling prompt-to-specify. This inherently preserves generalization and promotes instruction following. We further incorporate pre- and post-contact phases to better leverage pre-trained foundation models. Information-theoretic analysis formally validates our effectiveness in mitigating shortcut learning. Extensive experiments show superior generalization to unseen instructions, objects, and environments compared to existing methods. Project page is available at: https://xukechun.github.io/papers/BayesVLA.

