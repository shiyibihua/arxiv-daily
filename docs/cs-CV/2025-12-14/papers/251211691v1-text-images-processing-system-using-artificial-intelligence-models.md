---
layout: default
title: Text images processing system using artificial intelligence models
---

# Text images processing system using artificial intelligence models

**arXiv**: [2512.11691v1](https://arxiv.org/abs/2512.11691) | [PDF](https://arxiv.org/pdf/2512.11691.pdf)

**ä½œè€…**: Aya Kaysan Bahjat

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽDBNet++å’ŒBARTçš„æ–‡æœ¬å›¾åƒå¤„ç†ç³»ç»Ÿï¼Œç”¨äºŽåœ¨å¤æ‚æ¡ä»¶ä¸‹åˆ†ç±»Invoiceã€Formã€Letteræˆ–Reportã€‚**

**å…³é”®è¯**: `æ–‡æœ¬å›¾åƒåˆ†ç±»` `DBNet++` `BARTæ¨¡åž‹` `å¤æ‚æ¡ä»¶å¤„ç†` `ç”¨æˆ·ç•Œé¢é›†æˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§£å†³å›¾åƒä¸­æ–‡æœ¬è¯†åˆ«ä¸Žåˆ†ç±»çš„æŒ‘æˆ˜ï¼Œå¦‚å…‰ç…§å˜åŒ–ã€ä½Žåˆ†è¾¨çŽ‡ã€æ–‡æœ¬éƒ¨åˆ†è¦†ç›–ç­‰ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨DBNet++æ£€æµ‹æ–‡æœ¬å…ƒç´ ï¼ŒBARTæ¨¡åž‹è¿›è¡Œåˆ†ç±»ï¼Œé›†æˆPython/PyQt5ç”¨æˆ·ç•Œé¢ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Total-Textæ•°æ®é›†ä¸Šæµ‹è¯•10å°æ—¶ï¼Œæ–‡æœ¬è¯†åˆ«çŽ‡çº¦94.62%ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This is to present a text image classifier device that identifies textual content in images and then categorizes each image into one of four predefined categories, including Invoice, Form, Letter, or Report. The device supports a gallery mode, in which users browse files on flash disks, hard disk drives, or microSD cards, and a live mode which renders feeds of cameras connected to it. Its design is specifically aimed at addressing pragmatic challenges, such as changing light, random orientation, curvature or partial coverage of text, low resolution, and slightly visible text. The steps of the processing process are divided into four steps: image acquisition and preprocessing, textual elements detection with the help of DBNet++ (Differentiable Binarization Network Plus) model, BART (Bidirectional Auto-Regressive Transformers) model that classifies detected textual elements, and the presentation of the results through a user interface written in Python and PyQt5. All the stages are connected in such a way that they form a smooth workflow. The system achieved a text recognition rate of about 94.62% when tested over ten hours on the mentioned Total-Text dataset, that includes high resolution images, created so as to represent a wide range of problematic conditions. These experimental results support the effectiveness of the suggested methodology to practice, mixed-source text categorization, even in uncontrolled imaging conditions.

