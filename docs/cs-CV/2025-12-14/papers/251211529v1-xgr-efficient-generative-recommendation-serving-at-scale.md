---
layout: default
title: xGR: Efficient Generative Recommendation Serving at Scale
---

# xGR: Efficient Generative Recommendation Serving at Scale

**arXiv**: [2512.11529v1](https://arxiv.org/abs/2512.11529) | [PDF](https://arxiv.org/pdf/2512.11529.pdf)

**ä½œè€…**: Qingxiao Sun, Tongxuan Liu, Shen Zhang, Siyu Wu, Peijun Yang, Haotian Liang, Menxin Li, Xiaolong Ma, Zhiwei Liang, Ziyi Ren, Minchao Zhang, Xinyu Liu, Ke Zhang, Depei Qian, Hailong Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºxGRä»¥è§£å†³é«˜å¹¶å‘ä¸‹ç”Ÿæˆå¼æŽ¨èç³»ç»Ÿä½Žå»¶è¿ŸæœåŠ¡é—®é¢˜**

**å…³é”®è¯**: `ç”Ÿæˆå¼æŽ¨è` `ä½Žå»¶è¿ŸæœåŠ¡` `KVç¼“å­˜ä¼˜åŒ–` `æŽ’åºåŠ é€Ÿ` `æµæ°´çº¿å¹¶è¡Œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç”Ÿæˆå¼æŽ¨èå¤„ç†é•¿æç¤ºã€çŸ­è¾“å‡ºï¼Œä½†è§£ç é˜¶æ®µè®¡ç®—å’ŒæŽ’åºå¼€é”€å¤§ï¼Œéš¾ä»¥æ»¡è¶³é«˜å¹¶å‘ä½Žå»¶è¿Ÿéœ€æ±‚ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡é˜¶æ®µåŒ–è®¡ç®—å’Œåˆ†ç¦»KVç¼“å­˜ç»Ÿä¸€é¢„å¡«å……ä¸Žè§£ç ï¼Œåˆ©ç”¨æ—©æœŸæŽ’åºç»ˆæ­¢å’ŒåŸºäºŽæŽ©ç çš„è¿‡æ»¤ä¼˜åŒ–æŽ’åºï¼Œé‡æž„æµæ°´çº¿å®žçŽ°å¤šçº§é‡å å’Œå¤šæµå¹¶è¡Œã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žæŽ¨èæ•°æ®é›†ä¸Šï¼ŒxGRåœ¨ä¸¥æ ¼å»¶è¿Ÿçº¦æŸä¸‹æ¯”çŽ°æœ‰åŸºçº¿è‡³å°‘æå‡3.49å€åžåé‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recommendation system delivers substantial economic benefits by providing personalized predictions. Generative recommendation (GR) integrates LLMs to enhance the understanding of long user-item sequences. Despite employing attention-based architectures, GR's workload differs markedly from that of LLM serving. GR typically processes long prompt while producing short, fixed-length outputs, yet the computational cost of each decode phase is especially high due to the large beam width. In addition, since the beam search involves a vast item space, the sorting overhead becomes particularly time-consuming. We propose xGR, a GR-oriented serving system that meets strict low-latency requirements under highconcurrency scenarios. First, xGR unifies the processing of prefill and decode phases through staged computation and separated KV cache. Second, xGR enables early sorting termination and mask-based item filtering with data structure reuse. Third, xGR reconstructs the overall pipeline to exploit multilevel overlap and multi-stream parallelism. Our experiments with real-world recommendation service datasets demonstrate that xGR achieves at least 3.49x throughput compared to the state-of-the-art baseline under strict latency constraints.

