---
layout: default
title: RoomPilot: Controllable Synthesis of Interactive Indoor Environments via Multimodal Semantic Parsing
---

# RoomPilot: Controllable Synthesis of Interactive Indoor Environments via Multimodal Semantic Parsing

**arXiv**: [2512.11234v1](https://arxiv.org/abs/2512.11234) | [PDF](https://arxiv.org/pdf/2512.11234.pdf)

**ä½œè€…**: Wentang Chen, Shougao Zhang, Yiman Zhang, Tianhao Zhou, Ruihui Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRoomPilotæ¡†æž¶ï¼Œé€šè¿‡å¤šæ¨¡æ€è¯­ä¹‰è§£æžå®žçŽ°å¯æŽ§äº¤äº’å¼å®¤å†…åœºæ™¯åˆæˆ**

**å…³é”®è¯**: `å®¤å†…åœºæ™¯ç”Ÿæˆ` `å¤šæ¨¡æ€è¯­ä¹‰è§£æž` `å¯æŽ§åˆæˆ` `äº¤äº’å¼çŽ¯å¢ƒ` `é¢†åŸŸç‰¹å®šè¯­è¨€`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•è¾“å…¥æ¨¡æ€æœ‰é™æˆ–ä¾èµ–éšæœºè¿‡ç¨‹ï¼Œéš¾ä»¥ç”Ÿæˆå¯æŽ§äº¤äº’å¼å®¤å†…åœºæ™¯ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡å®¤å†…é¢†åŸŸç‰¹å®šè¯­è¨€ï¼ˆIDSLï¼‰ä½œä¸ºå…±äº«è¯­ä¹‰è¡¨ç¤ºï¼Œè§£æžæ–‡æœ¬æˆ–CADå¹³é¢å›¾ä»¥ç”Ÿæˆç»“æž„åŒ–åœºæ™¯ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šéªŒè¯äº†å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ã€ç»†ç²’åº¦å¯æŽ§æ€§ï¼Œä»¥åŠç‰©ç†ä¸€è‡´æ€§å’Œè§†è§‰ä¿çœŸåº¦çš„æå‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generating controllable and interactive indoor scenes is fundamental to applications in game development, architectural visualization, and embodied AI training. Yet existing approaches either handle a narrow range of input modalities or rely on stochastic processes that hinder controllability. To overcome these limitations, we introduce RoomPilot, a unified framework that parses diverse multi-modal inputs--textual descriptions or CAD floor plans--into an Indoor Domain-Specific Language (IDSL) for indoor structured scene generation. The key insight is that a well-designed IDSL can act as a shared semantic representation, enabling coherent, high-quality scene synthesis from any single modality while maintaining interaction semantics. In contrast to conventional procedural methods that produce visually plausible but functionally inert layouts, RoomPilot leverages a curated dataset of interaction-annotated assets to synthesize environments exhibiting realistic object behaviors. Extensive experiments further validate its strong multi-modal understanding, fine-grained controllability in scene generation, and superior physical consistency and visual fidelity, marking a significant step toward general-purpose controllable 3D indoor scene generation.

