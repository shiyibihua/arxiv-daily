---
layout: default
title: Multi-Objective Reinforcement Learning for Large-Scale Mixed Traffic Control
---

# Multi-Objective Reinforcement Learning for Large-Scale Mixed Traffic Control

**arXiv**: [2512.11247v1](https://arxiv.org/abs/2512.11247) | [PDF](https://arxiv.org/pdf/2512.11247.pdf)

**ä½œè€…**: Iftekharul Islam, Weizi Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ ä¸Žæˆ˜ç•¥è·¯ç”±çš„æ··åˆäº¤é€šæŽ§åˆ¶æ¡†æž¶ï¼Œä»¥æå‡å…¬å¹³æ€§ã€å®‰å…¨æ€§å’Œæ•ˆçŽ‡ã€‚**

**å…³é”®è¯**: `æ··åˆäº¤é€šæŽ§åˆ¶` `å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ ` `æˆ˜ç•¥è·¯ç”±` `å…¬å¹³æ€§ä¼˜åŒ–` `å†²çªé¿å…`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•ç¼ºä¹å…¬å¹³æ€§æœºåˆ¶ï¼Œå¯¼è‡´ä½Žéœ€æ±‚è½¦è¾†æœåŠ¡ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆå¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œå±€éƒ¨æŽ§åˆ¶ï¼Œå¼•å…¥å†²çªå¨èƒå‘é‡å’Œé˜Ÿåˆ—å‡ç­‰æƒ©ç½šã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žç½‘ç»œä¸­æ˜¾è‘—å‡å°‘ç­‰å¾…æ—¶é—´ã€é¥¥é¥¿å’Œå†²çªçŽ‡ï¼ŒåŒæ—¶ä¿æŒç‡ƒæ²¹æ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Effective mixed traffic control requires balancing efficiency, fairness, and safety. Existing approaches excel at optimizing efficiency and enforcing safety constraints but lack mechanisms to ensure equitable service, resulting in systematic starvation of vehicles on low-demand approaches. We propose a hierarchical framework combining multi-objective reinforcement learning for local intersection control with strategic routing for network-level coordination. Our approach introduces a Conflict Threat Vector that provides agents with explicit risk signals for proactive conflict avoidance, and a queue parity penalty that ensures equitable service across all traffic streams. Extensive experiments on a real-world network across different robot vehicle (RV) penetration rates demonstrate substantial improvements: up to 53% reductions in average wait time, up to 86% reductions in maximum starvation, and up to 86\% reduction in conflict rate compared to baselines, while maintaining fuel efficiency. Our analysis reveals that strategic routing effectiveness scales with RV penetration, becoming increasingly valuable at higher autonomy levels. The results demonstrate that multi-objective optimization through well-curated reward functions paired with strategic RV routing yields significant benefits in fairness and safety metrics critical for equitable mixed-autonomy deployment.

