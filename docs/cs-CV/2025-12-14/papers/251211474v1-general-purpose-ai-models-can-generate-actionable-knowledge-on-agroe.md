---
layout: default
title: General-purpose AI models can generate actionable knowledge on agroecological crop protection
---

# General-purpose AI models can generate actionable knowledge on agroecological crop protection

**arXiv**: [2512.11474v1](https://arxiv.org/abs/2512.11474) | [PDF](https://arxiv.org/pdf/2512.11474.pdf)

**ä½œè€…**: Kris A. G. Wyckhuys

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°é€šç”¨AIæ¨¡åž‹åœ¨å†œä¸šç”Ÿæ€ä½œç‰©ä¿æŠ¤ä¸­ç”Ÿæˆå¯æ“ä½œçŸ¥è¯†çš„æ½œåŠ›**

**å…³é”®è¯**: `å†œä¸šç”Ÿæ€ä½œç‰©ä¿æŠ¤` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `çŸ¥è¯†ç”Ÿæˆ` `å¹»è§‰æ£€æµ‹` `å†³ç­–æ”¯æŒ` `ç§‘å­¦éªŒè¯`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šAIåœ¨å†œä¸šé£Ÿå“ç§‘å­¦ä¸­ç”Ÿæˆç§‘å­¦çŸ¥è¯†çš„åº”ç”¨æœªå……åˆ†æŽ¢ç´¢ï¼Œéœ€éªŒè¯å…¶å‡†ç¡®æ€§ä¸Žå®žç”¨æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ¯”è¾ƒåŸºäºŽç½‘ç»œä¸Žéžç½‘ç»œçš„LLMsï¼ˆDeepSeekä¸ŽChatGPTï¼‰åœ¨ä¹ç§å…¨çƒæ€§ç—…è™«å®³ä¸Šçš„çŸ¥è¯†ç”Ÿæˆèƒ½åŠ›ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šDeepSeekåœ¨æ–‡çŒ®è¦†ç›–ã€è§£å†³æ–¹æ¡ˆæ•°é‡å’Œä¸€è‡´æ€§ä¸Šä¼˜äºŽChatGPTï¼Œä½†ä¸¤è€…å‡å­˜åœ¨å¹»è§‰å’Œé—æ¼é—®é¢˜ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generative artificial intelligence (AI) offers potential for democratizing scientific knowledge and converting this to clear, actionable information, yet its application in agri-food science remains unexplored. Here, we verify the scientific knowledge on agroecological crop protection that is generated by either web-grounded or non-grounded large language models (LLMs), i.e., DeepSeek versus the free-tier version of ChatGPT. For nine globally limiting pests, weeds, and plant diseases, we assessed the factual accuracy, data consistency, and breadth of knowledge or data completeness of each LLM. Overall, DeepSeek consistently screened a 4.8-49.7-fold larger literature corpus and reported 1.6-2.4-fold more biological control agents or management solutions than ChatGPT. As a result, DeepSeek reported 21.6% higher efficacy estimates, exhibited greater laboratory-to-field data consistency, and showed more realistic effects of pest identity and management tactics. However, both models hallucinated, i.e., fabricated fictitious agents or references, reported on implausible ecological interactions or outcomes, confused old and new scientific nomenclatures, and omitted data on key agents or solutions. Despite these shortcomings, both LLMs correctly reported low-resolution efficacy trends. Overall, when paired with rigorous human oversight, LLMs may pose a powerful tool to support farm-level decision-making and unleash scientific creativity.

