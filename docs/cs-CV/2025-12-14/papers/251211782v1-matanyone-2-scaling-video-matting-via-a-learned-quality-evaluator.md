---
layout: default
title: MatAnyone 2: Scaling Video Matting via a Learned Quality Evaluator
---

# MatAnyone 2: Scaling Video Matting via a Learned Quality Evaluator

**arXiv**: [2512.11782v1](https://arxiv.org/abs/2512.11782) | [PDF](https://arxiv.org/pdf/2512.11782.pdf)

**ä½œè€…**: Peiqing Yang, Shangchen Zhou, Kai Hao, Qingyi Tao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå­¦ä¹ åž‹æŠ å›¾è´¨é‡è¯„ä¼°å™¨ä»¥æ‰©å±•è§†é¢‘æŠ å›¾ï¼Œé€šè¿‡è´¨é‡åé¦ˆå’Œæ•°æ®é›†æž„å»ºæå‡æ€§èƒ½ã€‚**

**å…³é”®è¯**: `è§†é¢‘æŠ å›¾` `è´¨é‡è¯„ä¼°` `æ•°æ®é›†æž„å»º` `å‚è€ƒå¸§è®­ç»ƒ` `è¯­ä¹‰ç¨³å®šæ€§` `è¾¹ç•Œç›‘ç£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†é¢‘æŠ å›¾å—é™äºŽæ•°æ®é›†è§„æ¨¡å’ŒçœŸå®žæ€§ï¼Œç¼ºä¹æœ‰æ•ˆè¾¹ç•Œç›‘ç£å¯¼è‡´ç»†èŠ‚ç¼ºå¤±ã€‚
2. å¼•å…¥å­¦ä¹ åž‹æŠ å›¾è´¨é‡è¯„ä¼°å™¨ï¼Œæ— éœ€çœŸå€¼è¯„ä¼°è¯­ä¹‰å’Œè¾¹ç•Œè´¨é‡ï¼Œæä¾›åƒç´ çº§è¯„ä¼°å›¾ã€‚
3. æž„å»ºå¤§è§„æ¨¡çœŸå®žè§†é¢‘æŠ å›¾æ•°æ®é›†VMRealï¼Œç»“åˆå‚è€ƒå¸§è®­ç»ƒç­–ç•¥ï¼Œåœ¨åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°æœ€ä¼˜æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video matting remains limited by the scale and realism of existing datasets. While leveraging segmentation data can enhance semantic stability, the lack of effective boundary supervision often leads to segmentation-like mattes lacking fine details. To this end, we introduce a learned Matting Quality Evaluator (MQE) that assesses semantic and boundary quality of alpha mattes without ground truth. It produces a pixel-wise evaluation map that identifies reliable and erroneous regions, enabling fine-grained quality assessment. The MQE scales up video matting in two ways: (1) as an online matting-quality feedback during training to suppress erroneous regions, providing comprehensive supervision, and (2) as an offline selection module for data curation, improving annotation quality by combining the strengths of leading video and image matting models. This process allows us to build a large-scale real-world video matting dataset, VMReal, containing 28K clips and 2.4M frames. To handle large appearance variations in long videos, we introduce a reference-frame training strategy that incorporates long-range frames beyond the local window for effective training. Our MatAnyone 2 achieves state-of-the-art performance on both synthetic and real-world benchmarks, surpassing prior methods across all metrics.

