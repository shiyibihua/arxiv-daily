---
layout: default
title: SATMapTR: Satellite Image Enhanced Online HD Map Construction
---

# SATMapTR: Satellite Image Enhanced Online HD Map Construction

**arXiv**: [2512.11319v1](https://arxiv.org/abs/2512.11319) | [PDF](https://arxiv.org/pdf/2512.11319.pdf)

**ä½œè€…**: Bingyuan Huang, Guanyi Zhao, Qian Xu, Yang Lou, Yung-Hui Li, Jianping Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSATMapTRæ¨¡åž‹ï¼Œé€šè¿‡èžåˆå«æ˜Ÿå›¾åƒå¢žå¼ºåœ¨çº¿é«˜ç²¾åœ°å›¾æž„å»ºï¼Œä»¥è§£å†³è½¦è½½ä¼ æ„Ÿå™¨æ•°æ®è´¨é‡ä½Žçš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `é«˜ç²¾åœ°å›¾æž„å»º` `å«æ˜Ÿå›¾åƒèžåˆ` `åœ¨çº¿åœ°å›¾ç”Ÿæˆ` `è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥` `ç‰¹å¾èžåˆ` `BEVè§†è§’`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè½¦è½½ä¼ æ„Ÿå™¨æ•°æ®å› é®æŒ¡å’Œèƒ½åŠ›é™åˆ¶å¯¼è‡´é«˜ç²¾åœ°å›¾æž„å»ºä¸å®Œæ•´ã€å™ªå£°å¤§ï¼Œå½±å“è‡ªåŠ¨é©¾é©¶ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥é—¨æŽ§ç‰¹å¾ç»†åŒ–æ¨¡å—å’Œå‡ ä½•æ„ŸçŸ¥èžåˆæ¨¡å—ï¼Œè‡ªé€‚åº”è¿‡æ»¤å«æ˜Ÿå›¾åƒç‰¹å¾å¹¶é«˜æ•ˆèžåˆBEVç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨nuScenesæ•°æ®é›†ä¸Šè¾¾åˆ°73.8 mAPï¼Œä¼˜äºŽçŽ°æœ‰å«æ˜Ÿå¢žå¼ºæ¨¡åž‹ï¼Œå¹¶åœ¨æ¶åŠ£æ¡ä»¶ä¸‹è¡¨çŽ°æ›´ç¨³å¥ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> High-definition (HD) maps are evolving from pre-annotated to real-time construction to better support autonomous driving in diverse scenarios. However, this process is hindered by low-quality input data caused by onboard sensors limited capability and frequent occlusions, leading to incomplete, noisy, or missing data, and thus reduced mapping accuracy and robustness. Recent efforts have introduced satellite images as auxiliary input, offering a stable, wide-area view to complement the limited ego perspective. However, satellite images in Bird's Eye View are often degraded by shadows and occlusions from vegetation and buildings. Prior methods using basic feature extraction and fusion remain ineffective. To address these challenges, we propose SATMapTR, a novel online map construction model that effectively fuses satellite image through two key components: (1) a gated feature refinement module that adaptively filters satellite image features by integrating high-level semantics with low-level structural cues to extract high signal-to-noise ratio map-relevant representations; and (2) a geometry-aware fusion module that consistently fuse satellite and BEV features at a grid-to-grid level, minimizing interference from irrelevant regions and low-quality inputs. Experimental results on the nuScenes dataset show that SATMapTR achieves the highest mean average precision (mAP) of 73.8, outperforming state-of-the-art satellite-enhanced models by up to 14.2 mAP. It also shows lower mAP degradation under adverse weather and sensor failures, and achieves nearly 3 times higher mAP at extended perception ranges.

