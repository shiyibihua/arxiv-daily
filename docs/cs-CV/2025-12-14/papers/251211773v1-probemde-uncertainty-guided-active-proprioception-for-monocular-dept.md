---
layout: default
title: ProbeMDE: Uncertainty-Guided Active Proprioception for Monocular Depth Estimation in Surgical Robotics
---

# ProbeMDE: Uncertainty-Guided Active Proprioception for Monocular Depth Estimation in Surgical Robotics

**arXiv**: [2512.11773v1](https://arxiv.org/abs/2512.11773) | [PDF](https://arxiv.org/pdf/2512.11773.pdf)

**ä½œè€…**: Britton Jordan, Jordan Thompson, Jesse F. d'Almeida, Hao Li, Nithesh Kumar, Susheela Sharma Stern, Ipek Oguz, Robert J. Webster, Daniel Brown, Alan Kuntz, James Ferguson

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºProbeMDEæ¡†æž¶ï¼Œç»“åˆRGBå›¾åƒä¸Žç¨€ç–æœ¬ä½“æ„ŸçŸ¥æµ‹é‡ä»¥æå‡æ‰‹æœ¯æœºå™¨äººå•ç›®æ·±åº¦ä¼°è®¡ç²¾åº¦**

**å…³é”®è¯**: `å•ç›®æ·±åº¦ä¼°è®¡` `æ‰‹æœ¯æœºå™¨äºº` `ä¸ç¡®å®šæ€§å¼•å¯¼` `ä¸»åŠ¨æ„ŸçŸ¥` `æœ¬ä½“æ„ŸçŸ¥æµ‹é‡` `æ¨¡åž‹é›†æˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå•ç›®æ·±åº¦ä¼°è®¡åœ¨æ‰‹æœ¯åœºæ™¯ä¸­å› çº¹ç†ç¼ºå¤±ã€é•œé¢åå°„å’Œé®æŒ¡å¯¼è‡´é¢„æµ‹ä¸ç¡®å®šå’Œä¸å‡†ç¡®
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨æ¨¡åž‹é›†æˆé¢„æµ‹å¯†é›†æ·±åº¦å›¾ï¼ŒåŸºäºŽä¸ç¡®å®šæ€§æ¢¯åº¦é€šè¿‡SVGDé€‰æ‹©æœ€ä¼˜æœ¬ä½“æ„ŸçŸ¥æµ‹é‡ä½ç½®
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ¨¡æ‹Ÿå’Œç‰©ç†å®žéªŒä¸­éªŒè¯ï¼Œä¼˜äºŽåŸºçº¿æ–¹æ³•ï¼Œæé«˜ç²¾åº¦å¹¶å‡å°‘æ‰€éœ€æµ‹é‡æ¬¡æ•°

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Monocular depth estimation (MDE) provides a useful tool for robotic perception, but its predictions are often uncertain and inaccurate in challenging environments such as surgical scenes where textureless surfaces, specular reflections, and occlusions are common. To address this, we propose ProbeMDE, a cost-aware active sensing framework that combines RGB images with sparse proprioceptive measurements for MDE. Our approach utilizes an ensemble of MDE models to predict dense depth maps conditioned on both RGB images and on a sparse set of known depth measurements obtained via proprioception, where the robot has touched the environment in a known configuration. We quantify predictive uncertainty via the ensemble's variance and measure the gradient of the uncertainty with respect to candidate measurement locations. To prevent mode collapse while selecting maximally informative locations to propriocept (touch), we leverage Stein Variational Gradient Descent (SVGD) over this gradient map. We validate our method in both simulated and physical experiments on central airway obstruction surgical phantoms. Our results demonstrate that our approach outperforms baseline methods across standard depth estimation metrics, achieving higher accuracy while minimizing the number of required proprioceptive measurements.

