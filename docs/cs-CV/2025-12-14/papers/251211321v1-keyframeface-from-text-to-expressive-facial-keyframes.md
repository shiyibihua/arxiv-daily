---
layout: default
title: KeyframeFace: From Text to Expressive Facial Keyframes
---

# KeyframeFace: From Text to Expressive Facial Keyframes

**arXiv**: [2512.11321v1](https://arxiv.org/abs/2512.11321) | [PDF](https://arxiv.org/pdf/2512.11321.pdf)

**ä½œè€…**: Jingchao Wu, Zejian Kang, Haibo Liu, Yuanchen Fei, Xiangru Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºKeyframeFaceæ•°æ®é›†ä¸ŽLLMæ¡†æž¶ï¼Œä»¥è§£å†³æ–‡æœ¬åˆ°è¡¨æƒ…åŠ¨ç”»çš„è¯­ä¹‰ä¸Žæ—¶é—´ç»“æž„é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°åŠ¨ç”»` `é¢éƒ¨åŠ¨ç”»` `å…³é”®å¸§ç›‘ç£` `å¤šæ¨¡æ€æ•°æ®é›†` `LLMå…ˆéªŒ` `ARKitç³»æ•°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•ç¼ºä¹è¯­ä¹‰åŸºç¡€å’Œæ—¶é—´ç»“æž„ï¼Œéš¾ä»¥ä»Žæ–‡æœ¬ç”ŸæˆåŠ¨æ€3Dé¢éƒ¨åŠ¨ç”»ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºå¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®é›†ï¼Œå¹¶åˆ©ç”¨LLMå…ˆéªŒå®žçŽ°å¯è§£é‡Šçš„é¢éƒ¨è¿åŠ¨åˆæˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šé€šè¿‡å…³é”®å¸§ç›‘ç£å’ŒARKitç³»æ•°ï¼Œå®žçŽ°é«˜ä¿çœŸã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„åŠ¨ç”»ç”Ÿæˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generating dynamic 3D facial animation from natural language requires understanding both temporally structured semantics and fine-grained expression changes. Existing datasets and methods mainly focus on speech-driven animation or unstructured expression sequences and therefore lack the semantic grounding and temporal structures needed for expressive human performance generation. In this work, we introduce KeyframeFace, a large-scale multimodal dataset designed for text-to-animation research through keyframe-level supervision. KeyframeFace provides 2,100 expressive scripts paired with monocular videos, per-frame ARKit coefficients, contextual backgrounds, complex emotions, manually defined keyframes, and multi-perspective annotations based on ARKit coefficients and images via Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs). Beyond the dataset, we propose the first text-to-animation framework that explicitly leverages LLM priors for interpretable facial motion synthesis. This design aligns the semantic understanding capabilities of LLMs with the interpretable structure of ARKit's coefficients, enabling high-fidelity expressive animation. KeyframeFace and our LLM-based framework together establish a new foundation for interpretable, keyframe-guided, and context-aware text-to-animation. Code and data are available at https://github.com/wjc12345123/KeyframeFace.

