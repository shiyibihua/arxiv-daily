---
layout: default
title: SpectralKrum: A Spectral-Geometric Defense Against Byzantine Attacks in Federated Learning
---

# SpectralKrum: A Spectral-Geometric Defense Against Byzantine Attacks in Federated Learning

**arXiv**: [2512.11760v1](https://arxiv.org/abs/2512.11760) | [PDF](https://arxiv.org/pdf/2512.11760.pdf)

**ä½œè€…**: Aditya Tripathi, Karan Sharma, Rahul Mishra, Tapas Kumar Maiti

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSpectralKrumé˜²å¾¡æ–¹æ³•ï¼Œç»“åˆè°±å­ç©ºé—´ä¼°è®¡ä¸Žå‡ ä½•é‚»å±…é€‰æ‹©ï¼Œä»¥åº”å¯¹è”é‚¦å­¦ä¹ ä¸­çš„æ‹œå åº­æ”»å‡»ã€‚**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `æ‹œå åº­æ”»å‡»é˜²å¾¡` `è°±å­ç©ºé—´ä¼°è®¡` `é²æ£’èšåˆ` `éžç‹¬ç«‹åŒåˆ†å¸ƒæ•°æ®` `æ¨¡åž‹æ›´æ–°è¿‡æ»¤`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè”é‚¦å­¦ä¹ åœ¨éžç‹¬ç«‹åŒåˆ†å¸ƒæ•°æ®ä¸‹ï¼ŒçŽ°æœ‰é²æ£’èšåˆæ–¹æ³•å¯¹æ‹œå åº­æ”»å‡»çš„é˜²å¾¡æ•ˆæžœæ˜¾è‘—ä¸‹é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡åŽ†å²èšåˆä¼°è®¡ä½Žç»´æµå½¢ï¼Œå°†æ›´æ–°æŠ•å½±åˆ°å­ç©ºé—´ï¼Œç»“åˆKrumé€‰æ‹©å’Œæ®‹å·®èƒ½é‡é˜ˆå€¼è¿‡æ»¤ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CIFAR-10éžç‹¬ç«‹åŒåˆ†å¸ƒæ•°æ®ä¸Šè¯„ä¼°ï¼Œå¯¹æ–¹å‘æ€§å’Œå­ç©ºé—´æ„ŸçŸ¥æ”»å‡»æœ‰æ•ˆï¼Œä½†å¯¹æ ‡ç­¾ç¿»è½¬å’Œæœ€å°æœ€å¤§æ”»å‡»ä¼˜åŠ¿æœ‰é™ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Federated Learning (FL) distributes model training across clients who retain their data locally, but this architecture exposes a fundamental vulnerability: Byzantine clients can inject arbitrarily corrupted updates that degrade or subvert the global model. While robust aggregation methods (including Krum, Bulyan, and coordinate-wise defenses) offer theoretical guarantees under idealized assumptions, their effectiveness erodes substantially when client data distributions are heterogeneous (non-IID) and adversaries can observe or approximate the defense mechanism.
>   This paper introduces SpectralKrum, a defense that fuses spectral subspace estimation with geometric neighbor-based selection. The core insight is that benign optimization trajectories, despite per-client heterogeneity, concentrate near a low-dimensional manifold that can be estimated from historical aggregates. SpectralKrum projects incoming updates into this learned subspace, applies Krum selection in compressed coordinates, and filters candidates whose orthogonal residual energy exceeds a data-driven threshold. The method requires no auxiliary data, operates entirely on model updates, and preserves FL privacy properties.
>   We evaluate SpectralKrum against eight robust baselines across seven attack scenarios on CIFAR-10 with Dirichlet-distributed non-IID partitions (alpha = 0.1). Experiments spanning over 56,000 training rounds show that SpectralKrum is competitive against directional and subspace-aware attacks (adaptive-steer, buffer-drift), but offers limited advantage under label-flip and min-max attacks where malicious updates remain spectrally indistinguishable from benign ones.

