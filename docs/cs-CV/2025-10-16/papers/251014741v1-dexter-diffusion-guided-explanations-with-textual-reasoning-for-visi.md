---
layout: default
title: DEXTER: Diffusion-Guided EXplanations with TExtual Reasoning for Vision Models
---

# DEXTER: Diffusion-Guided EXplanations with TExtual Reasoning for Vision Models

**arXiv**: [2510.14741v1](https://arxiv.org/abs/2510.14741) | [PDF](https://arxiv.org/pdf/2510.14741.pdf)

**ä½œè€…**: Simone Carnemolla, Matteo Pennisi, Sarinda Samarasinghe, Giovanni Bellitto, Simone Palazzo, Daniela Giordano, Mubarak Shah, Concetto Spampinato

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDEXTERæ¡†æž¶ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡åž‹å’Œå¤§åž‹è¯­è¨€æ¨¡åž‹ç”Ÿæˆè§†è§‰åˆ†ç±»å™¨çš„å…¨å±€æ–‡æœ¬è§£é‡Šã€‚**

**å…³é”®è¯**: `è§†è§‰æ¨¡åž‹è§£é‡Š` `æ‰©æ•£æ¨¡åž‹` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `æ•°æ®è‡ªç”±æ¡†æž¶` `åˆ†ç±»å™¨åè§åˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç†è§£è§†è§‰åˆ†ç±»å™¨å†³ç­–è¿‡ç¨‹ï¼Œæ— éœ€è®­ç»ƒæ•°æ®æˆ–çœŸå®žæ ‡ç­¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä¼˜åŒ–æ–‡æœ¬æç¤ºåˆæˆç±»æ¡ä»¶å›¾åƒï¼Œæ¿€æ´»åˆ†ç±»å™¨å¹¶ç”Ÿæˆè‡ªç„¶è¯­è¨€æŠ¥å‘Šã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ImageNetç­‰æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œè¾“å‡ºå‡†ç¡®å¯è§£é‡Šã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Understanding and explaining the behavior of machine learning models is
> essential for building transparent and trustworthy AI systems. We introduce
> DEXTER, a data-free framework that employs diffusion models and large language
> models to generate global, textual explanations of visual classifiers. DEXTER
> operates by optimizing text prompts to synthesize class-conditional images that
> strongly activate a target classifier. These synthetic samples are then used to
> elicit detailed natural language reports that describe class-specific decision
> patterns and biases. Unlike prior work, DEXTER enables natural language
> explanation about a classifier's decision process without access to training
> data or ground-truth labels. We demonstrate DEXTER's flexibility across three
> tasks-activation maximization, slice discovery and debiasing, and bias
> explanation-each illustrating its ability to uncover the internal mechanisms of
> visual classifiers. Quantitative and qualitative evaluations, including a user
> study, show that DEXTER produces accurate, interpretable outputs. Experiments
> on ImageNet, Waterbirds, CelebA, and FairFaces confirm that DEXTER outperforms
> existing approaches in global model explanation and class-level bias reporting.
> Code is available at https://github.com/perceivelab/dexter.

