---
layout: default
title: Towards Adaptable Humanoid Control via Adaptive Motion Tracking
---

# Towards Adaptable Humanoid Control via Adaptive Motion Tracking

**arXiv**: [2510.14454v1](https://arxiv.org/abs/2510.14454) | [PDF](https://arxiv.org/pdf/2510.14454.pdf)

**ä½œè€…**: Tao Huang, Huayi Wang, Junli Ren, Kangning Yin, Zirui Wang, Xiao Chen, Feiyu Jia, Wentao Zhang, Junfeng Long, Jingbo Wang, Jiangmiao Pang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAdaMimicç®—æ³•ï¼Œå®žçŽ°ä»Žå•ä¸€å‚è€ƒè¿åŠ¨è¿›è¡Œå¯é€‚åº”äººå½¢æœºå™¨äººæŽ§åˆ¶ã€‚**

**å…³é”®è¯**: `äººå½¢æœºå™¨äººæŽ§åˆ¶` `è¿åŠ¨è·Ÿè¸ª` `è‡ªé€‚åº”ç®—æ³•` `å…³é”®å¸§ç¨€ç–åŒ–` `æ—¶é—´æ‰­æ›²`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•åœ¨è¿åŠ¨é€‚åº”æ€§å’Œæ¨¡ä»¿ç²¾åº¦é—´å­˜åœ¨æƒè¡¡ï¼Œéš¾ä»¥ä»Žå•ä¸€è¿åŠ¨å®žçŽ°é«˜ç²¾åº¦é€‚åº”ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡ç¨€ç–åŒ–å‚è€ƒè¿åŠ¨ä¸ºå…³é”®å¸§ï¼Œè®­ç»ƒç­–ç•¥ç”Ÿæˆå¯†é›†è¿åŠ¨ï¼Œå¹¶ä½¿ç”¨é€‚é…å™¨è°ƒæ•´é€Ÿåº¦å’ŒåŠ¨ä½œã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä»¿çœŸå’ŒçœŸå®žäººå½¢æœºå™¨äººä¸ŠéªŒè¯ï¼Œåœ¨å¤šç§é€‚åº”æ¡ä»¶ä¸‹æå‡æ¨¡ä»¿ç²¾åº¦å’Œé€‚åº”æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Humanoid robots are envisioned to adapt demonstrated motions to diverse
> real-world conditions while accurately preserving motion patterns. Existing
> motion prior approaches enable well adaptability with a few motions but often
> sacrifice imitation accuracy, whereas motion-tracking methods achieve accurate
> imitation yet require many training motions and a test-time target motion to
> adapt. To combine their strengths, we introduce AdaMimic, a novel motion
> tracking algorithm that enables adaptable humanoid control from a single
> reference motion. To reduce data dependence while ensuring adaptability, our
> method first creates an augmented dataset by sparsifying the single reference
> motion into keyframes and applying light editing with minimal physical
> assumptions. A policy is then initialized by tracking these sparse keyframes to
> generate dense intermediate motions, and adapters are subsequently trained to
> adjust tracking speed and refine low-level actions based on the adjustment,
> enabling flexible time warping that further improves imitation accuracy and
> adaptability. We validate these significant improvements in our approach in
> both simulation and the real-world Unitree G1 humanoid robot in multiple tasks
> across a wide range of adaptation conditions. Videos and code are available at
> https://taohuang13.github.io/adamimic.github.io/.

