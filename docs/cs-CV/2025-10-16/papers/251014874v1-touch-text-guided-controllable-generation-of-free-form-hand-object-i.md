---
layout: default
title: TOUCH: Text-guided Controllable Generation of Free-Form Hand-Object Interactions
---

# TOUCH: Text-guided Controllable Generation of Free-Form Hand-Object Interactions

**arXiv**: [2510.14874v1](https://arxiv.org/abs/2510.14874) | [PDF](https://arxiv.org/pdf/2510.14874.pdf)

**ä½œè€…**: Guangyi Han, Wei Zhai, Yuhang Yang, Yang Cao, Zheng-Jun Zha

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTOUCHæ¡†æž¶ä»¥ç”Ÿæˆå¯æŽ§ã€å¤šæ ·ä¸”ç‰©ç†åˆç†çš„æ‰‹-ç‰©ä½“è‡ªç”±äº¤äº’**

**å…³é”®è¯**: `æ‰‹-ç‰©ä½“äº¤äº’ç”Ÿæˆ` `è‡ªç”±å½¢å¼äº¤äº’` `å¤šçº§æ‰©æ•£æ¨¡åž‹` `ç»†ç²’åº¦è¯­ä¹‰æŽ§åˆ¶` `ç‰©ç†çº¦æŸä¼˜åŒ–` `WildO2æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ‰‹-ç‰©ä½“äº¤äº’ç”Ÿæˆå±€é™äºŽå›ºå®šæŠ“å–æ¨¡å¼ï¼Œç¼ºä¹æ—¥å¸¸äº¤äº’å¤šæ ·æ€§ã€‚
2. TOUCHä½¿ç”¨å¤šçº§æ‰©æ•£æ¨¡åž‹ï¼Œç»“åˆç»†ç²’åº¦è¯­ä¹‰æŽ§åˆ¶ï¼Œç”Ÿæˆè¶…è¶ŠæŠ“å–çš„æ‰‹éƒ¨å§¿åŠ¿ã€‚
3. å®žéªŒéªŒè¯æ–¹æ³•èƒ½ç”Ÿæˆå¯æŽ§ã€å¤šæ ·ä¸”ç‰©ç†åˆç†çš„æ‰‹äº¤äº’ï¼Œä»£è¡¨æ—¥å¸¸æ´»åŠ¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Hand-object interaction (HOI) is fundamental for humans to express intent.
> Existing HOI generation research is predominantly confined to fixed grasping
> patterns, where control is tied to physical priors such as force closure or
> generic intent instructions, even when expressed through elaborate language.
> Such an overly general conditioning imposes a strong inductive bias for stable
> grasps, thus failing to capture the diversity of daily HOI. To address these
> limitations, we introduce Free-Form HOI Generation, which aims to generate
> controllable, diverse, and physically plausible HOI conditioned on fine-grained
> intent, extending HOI from grasping to free-form interactions, like pushing,
> poking, and rotating. To support this task, we construct WildO2, an in-the-wild
> diverse 3D HOI dataset, which includes diverse HOI derived from internet
> videos. Specifically, it contains 4.4k unique interactions across 92 intents
> and 610 object categories, each with detailed semantic annotations. Building on
> this dataset, we propose TOUCH, a three-stage framework centered on a
> multi-level diffusion model that facilitates fine-grained semantic control to
> generate versatile hand poses beyond grasping priors. This process leverages
> explicit contact modeling for conditioning and is subsequently refined with
> contact consistency and physical constraints to ensure realism. Comprehensive
> experiments demonstrate our method's ability to generate controllable, diverse,
> and physically plausible hand interactions representative of daily activities.
> The project page is $\href{https://guangyid.github.io/hoi123touch}{here}$.

