---
layout: default
title: From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance
---

# From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance

**arXiv**: [2510.14952v1](https://arxiv.org/abs/2510.14952) | [PDF](https://arxiv.org/pdf/2510.14952.pdf)

**ä½œè€…**: Zhe Li, Cheng Chi, Yangyang Wei, Boan Zhu, Yibo Peng, Tao Huang, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang, Chang Xu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRoboGhostæ¡†æž¶ï¼Œé€šè¿‡è¿åŠ¨æ½œåœ¨å¼•å¯¼å®žçŽ°å…é‡å®šå‘çš„äººå½¢æœºå™¨äººæŽ§åˆ¶**

**å…³é”®è¯**: `äººå½¢æœºå™¨äººæŽ§åˆ¶` `è¯­è¨€åˆ°åŠ¨ä½œ` `æ‰©æ•£æ¨¡åž‹` `è¿åŠ¨æ½œåœ¨è¡¨ç¤º` `å…é‡å®šå‘æ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è¯­è¨€å¼•å¯¼äººå½¢æœºå™¨äººè¿åŠ¨æµç¨‹ç¹çï¼Œæ˜“äº§ç”Ÿç´¯ç§¯è¯¯å·®å’Œå»¶è¿Ÿ
2. ä½¿ç”¨æ‰©æ•£ç­–ç•¥ç›´æŽ¥ä»Žå™ªå£°åŽ»å™ªç”Ÿæˆå¯æ‰§è¡ŒåŠ¨ä½œï¼Œé¿å…ä¸­é—´é˜¶æ®µ
3. å®žéªŒæ˜¾ç¤ºé™ä½Žå»¶è¿Ÿã€æé«˜æˆåŠŸçŽ‡ï¼Œå¹¶æ”¯æŒå¤šæ¨¡æ€æ‰©å±•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Natural language offers a natural interface for humanoid robots, but existing
> language-guided humanoid locomotion pipelines remain cumbersome and unreliable.
> They typically decode human motion, retarget it to robot morphology, and then
> track it with a physics-based controller. However, this multi-stage process is
> prone to cumulative errors, introduces high latency, and yields weak coupling
> between semantics and control. These limitations call for a more direct pathway
> from language to action, one that eliminates fragile intermediate stages.
> Therefore, we present RoboGhost, a retargeting-free framework that directly
> conditions humanoid policies on language-grounded motion latents. By bypassing
> explicit motion decoding and retargeting, RoboGhost enables a diffusion-based
> policy to denoise executable actions directly from noise, preserving semantic
> intent and supporting fast, reactive control. A hybrid causal
> transformer-diffusion motion generator further ensures long-horizon consistency
> while maintaining stability and diversity, yielding rich latent representations
> for precise humanoid behavior. Extensive experiments demonstrate that RoboGhost
> substantially reduces deployment latency, improves success rates and tracking
> accuracy, and produces smooth, semantically aligned locomotion on real
> humanoids. Beyond text, the framework naturally extends to other modalities
> such as images, audio, and music, providing a general foundation for
> vision-language-action humanoid systems.

