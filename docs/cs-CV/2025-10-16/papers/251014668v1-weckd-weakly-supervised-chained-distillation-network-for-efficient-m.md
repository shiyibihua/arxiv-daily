---
layout: default
title: WeCKD: Weakly-supervised Chained Distillation Network for Efficient Multimodal Medical Imaging
---

# WeCKD: Weakly-supervised Chained Distillation Network for Efficient Multimodal Medical Imaging

**arXiv**: [2510.14668v1](https://arxiv.org/abs/2510.14668) | [PDF](https://arxiv.org/pdf/2510.14668.pdf)

**ä½œè€…**: Md. Abdur Rahman, Mohaimenul Azam Khan Raiaan, Sami Azam, Asif Karim, Jemima Beissbarth, Amanda Leach

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¼±ç›‘ç£é“¾å¼è’¸é¦ç½‘ç»œä»¥è§£å†³æœ‰é™æ•°æ®ä¸‹åŒ»å­¦å›¾åƒåˆ†æžé—®é¢˜**

**å…³é”®è¯**: `çŸ¥è¯†è’¸é¦` `å¼±ç›‘ç£å­¦ä¹ ` `åŒ»å­¦å›¾åƒåˆ†æž` `é“¾å¼ç»“æž„` `å¤šæ¨¡æ€æˆåƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»ŸçŸ¥è¯†è’¸é¦ä¾èµ–å¼ºæ•™å¸ˆæˆ–å¤§æ ‡æ³¨æ•°æ®ï¼Œæ˜“å¯¼è‡´çŸ¥è¯†é€€åŒ–å’Œç›‘ç£ä½Žæ•ˆ
2. é‡‡ç”¨é“¾å¼ç»“æž„ï¼Œæ¨¡åž‹é€çº§å­¦ä¹ å’Œç²¾ç‚¼çŸ¥è¯†ï¼Œå‡å°‘æ•°æ®ä¾èµ–å¹¶å¢žå¼ºç‰¹å¾å­¦ä¹ 
3. åœ¨å¤šä¸ªåŒ»å­¦å›¾åƒæ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæ€§èƒ½è¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œå‡†ç¡®çŽ‡æå‡é«˜è¾¾23%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Knowledge distillation (KD) has traditionally relied on a static
> teacher-student framework, where a large, well-trained teacher transfers
> knowledge to a single student model. However, these approaches often suffer
> from knowledge degradation, inefficient supervision, and reliance on either a
> very strong teacher model or large labeled datasets, which limits their
> effectiveness in real-world, limited-data scenarios. To address these, we
> present the first-ever Weakly-supervised Chain-based KD network (WeCKD) that
> redefines knowledge transfer through a structured sequence of interconnected
> models. Unlike conventional KD, it forms a progressive distillation chain,
> where each model not only learns from its predecessor but also refines the
> knowledge before passing it forward. This structured knowledge transfer further
> enhances feature learning, reduces data dependency, and mitigates the
> limitations of one-step KD. Each model in the distillation chain is trained on
> only a fraction of the dataset and demonstrates that effective learning can be
> achieved with minimal supervision. Extensive evaluations across four otoscopic
> imaging datasets demonstrate that it not only matches but in many cases
> surpasses the performance of existing supervised methods. Experimental results
> on two other datasets further underscore its generalization across diverse
> medical imaging modalities, including microscopic and magnetic resonance
> imaging. Furthermore, our evaluations resulted in cumulative accuracy gains of
> up to +23% over a single backbone trained on the same limited data, which
> highlights its potential for real-world adoption.

