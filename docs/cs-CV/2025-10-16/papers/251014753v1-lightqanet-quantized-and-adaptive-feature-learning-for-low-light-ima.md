---
layout: default
title: LightQANet: Quantized and Adaptive Feature Learning for Low-Light Image Enhancement
---

# LightQANet: Quantized and Adaptive Feature Learning for Low-Light Image Enhancement

**arXiv**: [2510.14753v1](https://arxiv.org/abs/2510.14753) | [PDF](https://arxiv.org/pdf/2510.14753.pdf)

**ä½œè€…**: Xu Wu, Zhihui Lai, Xianxu Hou, Jie Zhou, Ya-nan Zhang, Linlin Shen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLightQANetï¼Œé€šè¿‡é‡åŒ–ä¸Žè‡ªé€‚åº”ç‰¹å¾å­¦ä¹ å¢žå¼ºä½Žå…‰å›¾åƒ**

**å…³é”®è¯**: `ä½Žå…‰å›¾åƒå¢žå¼º` `é‡åŒ–ç‰¹å¾å­¦ä¹ ` `è‡ªé€‚åº”å­¦ä¹ ` `å…‰ç…§å»ºæ¨¡` `å›¾åƒè´¨é‡æå‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä½Žå…‰å›¾åƒåƒç´ ä¿¡æ¯é€€åŒ–ï¼Œå¯¼è‡´çº¹ç†æ¢å¤å·®ã€é¢œè‰²ä¸ä¸€è‡´å’Œä¼ªå½±
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡LQMé‡åŒ–å…‰ç…§å› ç´ ï¼ŒLAPMç”¨å¯å­¦ä¹ æç¤ºåŠ¨æ€å¼•å¯¼ç‰¹å¾å­¦ä¹ 
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®žçŽ°SOTAï¼Œæå‡å„ç§å…‰ç…§åœºæ™¯çš„å›¾åƒè´¨é‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Low-light image enhancement (LLIE) aims to improve illumination while
> preserving high-quality color and texture. However, existing methods often fail
> to extract reliable feature representations due to severely degraded
> pixel-level information under low-light conditions, resulting in poor texture
> restoration, color inconsistency, and artifact. To address these challenges, we
> propose LightQANet, a novel framework that introduces quantized and adaptive
> feature learning for low-light enhancement, aiming to achieve consistent and
> robust image quality across diverse lighting conditions. From the static
> modeling perspective, we design a Light Quantization Module (LQM) to explicitly
> extract and quantify illumination-related factors from image features. By
> enforcing structured light factor learning, LQM enhances the extraction of
> light-invariant representations and mitigates feature inconsistency across
> varying illumination levels. From the dynamic adaptation perspective, we
> introduce a Light-Aware Prompt Module (LAPM), which encodes illumination priors
> into learnable prompts to dynamically guide the feature learning process. LAPM
> enables the model to flexibly adapt to complex and continuously changing
> lighting conditions, further improving image enhancement. Extensive experiments
> on multiple low-light datasets demonstrate that our method achieves
> state-of-the-art performance, delivering superior qualitative and quantitative
> results across various challenging lighting scenarios.

