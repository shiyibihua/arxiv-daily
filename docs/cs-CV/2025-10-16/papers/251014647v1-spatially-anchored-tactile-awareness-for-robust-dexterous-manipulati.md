---
layout: default
title: Spatially anchored Tactile Awareness for Robust Dexterous Manipulation
---

# Spatially anchored Tactile Awareness for Robust Dexterous Manipulation

**arXiv**: [2510.14647v1](https://arxiv.org/abs/2510.14647) | [PDF](https://arxiv.org/pdf/2510.14647.pdf)

**ä½œè€…**: Jialei Huang, Yang Ye, Yuanqing Gong, Xuezhou Zhu, Yang Gao, Kaifeng Zhang

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSaTAæ¡†æ¶ï¼Œé€šè¿‡ç©ºé—´é”šå®šè§¦è§‰ç‰¹å¾è§£å†³çµå·§æ“ä½œä¸­çš„äºšæ¯«ç±³ç²¾åº¦ä»»åŠ¡**

**å…³é”®è¯**: `çµå·§æ“ä½œ` `è§¦è§‰æ„ŸçŸ¥` `ç©ºé—´é”šå®š` `å‡ ä½•æ¨ç†` `å¼ºåŒ–å­¦ä¹ ` `äºšæ¯«ç±³ç²¾åº¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰è§†è§‰è§¦è§‰å­¦ä¹ æ–¹æ³•éš¾ä»¥å¤„ç†äºšæ¯«ç±³ç²¾åº¦ä»»åŠ¡ï¼Œç¼ºä¹è§¦è§‰ä¿¡å·ä¸æ‰‹éƒ¨è¿åŠ¨çš„ç©ºé—´å…³è”
2. æ–¹æ³•è¦ç‚¹ï¼šSaTAé€šè¿‡å‰å‘è¿åŠ¨å­¦å°†è§¦è§‰ç‰¹å¾é”šå®šåˆ°æ‰‹éƒ¨åæ ‡ç³»ï¼Œå®ç°æ— æ¨¡å‹å‡ ä½•æ¨ç†
3. å®éªŒæ•ˆæœï¼šåœ¨USB-Cæ’æ¥ç­‰ä»»åŠ¡ä¸­ï¼ŒæˆåŠŸç‡æå‡30%ï¼Œå®Œæˆæ—¶é—´å‡å°‘27%

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Dexterous manipulation requires precise geometric reasoning, yet existing
> visuo-tactile learning methods struggle with sub-millimeter precision tasks
> that are routine for traditional model-based approaches. We identify a key
> limitation: while tactile sensors provide rich contact information, current
> learning frameworks fail to effectively leverage both the perceptual richness
> of tactile signals and their spatial relationship with hand kinematics. We
> believe an ideal tactile representation should explicitly ground contact
> measurements in a stable reference frame while preserving detailed sensory
> information, enabling policies to not only detect contact occurrence but also
> precisely infer object geometry in the hand's coordinate system. We introduce
> SaTA (Spatially-anchored Tactile Awareness for dexterous manipulation), an
> end-to-end policy framework that explicitly anchors tactile features to the
> hand's kinematic frame through forward kinematics, enabling accurate geometric
> reasoning without requiring object models or explicit pose estimation. Our key
> insight is that spatially grounded tactile representations allow policies to
> not only detect contact occurrence but also precisely infer object geometry in
> the hand's coordinate system. We validate SaTA on challenging dexterous
> manipulation tasks, including bimanual USB-C mating in free space, a task
> demanding sub-millimeter alignment precision, as well as light bulb
> installation requiring precise thread engagement and rotational control, and
> card sliding that demands delicate force modulation and angular precision.
> These tasks represent significant challenges for learning-based methods due to
> their stringent precision requirements. Across multiple benchmarks, SaTA
> significantly outperforms strong visuo-tactile baselines, improving success
> rates by up to 30 percentage while reducing task completion times by 27
> percentage.

