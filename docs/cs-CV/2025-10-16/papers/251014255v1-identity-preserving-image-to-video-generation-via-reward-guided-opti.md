---
layout: default
title: Identity-Preserving Image-to-Video Generation via Reward-Guided Optimization
---

# Identity-Preserving Image-to-Video Generation via Reward-Guided Optimization

**arXiv**: [2510.14255v1](https://arxiv.org/abs/2510.14255) | [PDF](https://arxiv.org/pdf/2510.14255.pdf)

**ä½œè€…**: Liao Shen, Wentao Jiang, Yiran Zhu, Tiezheng Ge, Zhiguo Cao, Bo Zheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºèº«ä»½ä¿æŒå¥–åŠ±å¼•å¯¼ä¼˜åŒ–æ–¹æ³•ä»¥è§£å†³å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆä¸­èº«ä»½ä¸€è‡´æ€§é—®é¢˜**

**å…³é”®è¯**: `å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆ` `èº«ä»½ä¿æŒ` `å¥–åŠ±å¼•å¯¼ä¼˜åŒ–` `æ‰©æ•£æ¨¡åž‹` `äººè„¸èº«ä»½è¯„åˆ†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰å›¾åƒåˆ°è§†é¢‘æ¨¡åž‹åœ¨äººç‰©è¡¨æƒ…å’Œè¿åŠ¨å˜åŒ–æ—¶éš¾ä»¥ä¿æŒè¾“å…¥å›¾åƒä¸Žç”Ÿæˆè§†é¢‘çš„èº«ä»½ä¸€è‡´æ€§
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ‰©æ•£æ¨¡åž‹ï¼Œä½¿ç”¨äººè„¸èº«ä»½è¯„åˆ†å™¨å’ŒKLæ•£åº¦æ­£åˆ™åŒ–æå‡èº«ä»½ä¿æŒ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Wan 2.2å’Œå†…éƒ¨æ¨¡åž‹ä¸ŠéªŒè¯æ–¹æ³•æœ‰æ•ˆæ€§ï¼Œå¢žå¼ºèº«ä»½ä¿æŒå’Œæ³›åŒ–èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in image-to-video (I2V) generation have achieved remarkable
> progress in synthesizing high-quality, temporally coherent videos from static
> images. Among all the applications of I2V, human-centric video generation
> includes a large portion. However, existing I2V models encounter difficulties
> in maintaining identity consistency between the input human image and the
> generated video, especially when the person in the video exhibits significant
> expression changes and movements. This issue becomes critical when the human
> face occupies merely a small fraction of the image. Since humans are highly
> sensitive to identity variations, this poses a critical yet under-explored
> challenge in I2V generation. In this paper, we propose Identity-Preserving
> Reward-guided Optimization (IPRO), a novel video diffusion framework based on
> reinforcement learning to enhance identity preservation. Instead of introducing
> auxiliary modules or altering model architectures, our approach introduces a
> direct and effective tuning algorithm that optimizes diffusion models using a
> face identity scorer. To improve performance and accelerate convergence, our
> method backpropagates the reward signal through the last steps of the sampling
> chain, enabling richer gradient feedback. We also propose a novel facial
> scoring mechanism that treats faces in ground-truth videos as facial feature
> pools, providing multi-angle facial information to enhance generalization. A
> KL-divergence regularization is further incorporated to stabilize training and
> prevent overfitting to the reward signal. Extensive experiments on Wan 2.2 I2V
> model and our in-house I2V model demonstrate the effectiveness of our method.
> Our project and code are available at
> \href{https://ipro-alimama.github.io/}{https://ipro-alimama.github.io/}.

