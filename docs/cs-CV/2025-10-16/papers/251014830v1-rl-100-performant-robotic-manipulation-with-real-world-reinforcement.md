---
layout: default
title: RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning
---

# RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning

**arXiv**: [2510.14830v1](https://arxiv.org/abs/2510.14830) | [PDF](https://arxiv.org/pdf/2510.14830.pdf)

**ä½œè€…**: Kun Lei, Huanyu Li, Dongjie Yu, Zhenyu Wei, Lingxiao Guo, Zhennan Jiang, Ziyu Wang, Shiyu Liang, Huazhe Xu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRL-100æ¡†æž¶ï¼Œé€šè¿‡ä¸‰é˜¶æ®µå¼ºåŒ–å­¦ä¹ å®žçŽ°çœŸå®žä¸–ç•Œæœºå™¨äººæ“ä½œçš„é«˜æ€§èƒ½ã€‚**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `å¼ºåŒ–å­¦ä¹ ` `æ‰©æ•£ç­–ç•¥` `ç¦»çº¿ç­–ç•¥è¯„ä¼°` `ä¸€è‡´æ€§è’¸é¦` `çœŸå®žä¸–ç•Œåº”ç”¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçœŸå®žä¸–ç•Œæœºå™¨äººæ“ä½œéœ€é«˜å¯é æ€§ã€æ•ˆçŽ‡å’Œé²æ£’æ€§ï¼Œä»¥æŽ¥è¿‘æˆ–è¶…è¶Šäººç±»æ“ä½œå‘˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ¨¡ä»¿å­¦ä¹ ã€ç¦»çº¿å¼ºåŒ–å­¦ä¹ å’Œåœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¸‰é˜¶æ®µç®¡é“ï¼Œç»“åˆæ‰©æ•£ç­–ç•¥å’Œä¸€è‡´æ€§è’¸é¦ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä¸ƒé¡¹ä»»åŠ¡ä¸­å®žçŽ°100%æˆåŠŸçŽ‡ï¼Œå…±900æ¬¡è¯•éªŒï¼Œå¹¶å±•ç¤ºå¤šå°æ—¶ä¸é—´æ–­æ“ä½œã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Real-world robotic manipulation in homes and factories demands reliability,
> efficiency, and robustness that approach or surpass skilled human operators. We
> present RL-100, a real-world reinforcement learning training framework built on
> diffusion visuomotor policies trained bu supervised learning. RL-100 introduces
> a three-stage pipeline. First, imitation learning leverages human priors.
> Second, iterative offline reinforcement learning uses an Offline Policy
> Evaluation procedure, abbreviated OPE, to gate PPO-style updates that are
> applied in the denoising process for conservative and reliable improvement.
> Third, online reinforcement learning eliminates residual failure modes. An
> additional lightweight consistency distillation head compresses the multi-step
> sampling process in diffusion into a single-step policy, enabling
> high-frequency control with an order-of-magnitude reduction in latency while
> preserving task performance. The framework is task-, embodiment-, and
> representation-agnostic and supports both 3D point clouds and 2D RGB inputs, a
> variety of robot platforms, and both single-step and action-chunk policies. We
> evaluate RL-100 on seven real-robot tasks spanning dynamic rigid-body control,
> such as Push-T and Agile Bowling, fluids and granular pouring, deformable cloth
> folding, precise dexterous unscrewing, and multi-stage orange juicing. RL-100
> attains 100\% success across evaluated trials for a total of 900 out of 900
> episodes, including up to 250 out of 250 consecutive trials on one task. The
> method achieves near-human teleoperation or better time efficiency and
> demonstrates multi-hour robustness with uninterrupted operation lasting up to
> two hours.

