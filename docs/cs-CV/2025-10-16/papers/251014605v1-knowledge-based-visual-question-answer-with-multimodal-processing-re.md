---
layout: default
title: Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering
---

# Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering

**arXiv**: [2510.14605v1](https://arxiv.org/abs/2510.14605) | [PDF](https://arxiv.org/pdf/2510.14605.pdf)

**ä½œè€…**: Yuyang Hong, Jiaqi Gu, Qi Yang, Lubin Fan, Yue Wu, Ying Wang, Kun Ding, Shiming Xiang, Jieping Ye

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWiki-PRFä¸‰é˜¶æ®µæ–¹æ³•ä»¥è§£å†³çŸ¥è¯†åž‹è§†è§‰é—®ç­”ä¸­æŸ¥è¯¢è´¨é‡å’Œæ£€ç´¢ç»“æžœç›¸å…³æ€§é—®é¢˜**

**å…³é”®è¯**: `çŸ¥è¯†åž‹è§†è§‰é—®ç­”` `å¤šæ¨¡æ€æ£€ç´¢` `å¼ºåŒ–å­¦ä¹ è®­ç»ƒ` `æ£€ç´¢å¢žå¼ºç”Ÿæˆ` `è§†è§‰è¯­è¨€æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŸ¥è¯†åž‹è§†è§‰é—®ç­”ä¸­å¤šæ¨¡æ€æŸ¥è¯¢è´¨é‡å·®å’Œæ£€ç´¢ç»“æžœç›¸å…³æ€§ä½Ž
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å¤„ç†ã€æ£€ç´¢å’Œè¿‡æ»¤ä¸‰é˜¶æ®µï¼Œç»“åˆè§†è§‰å·¥å…·å’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨E-VQAå’ŒInfoSeekæ•°æ®é›†ä¸Šç­”æ¡ˆè´¨é‡æ˜¾è‘—æå‡ï¼Œè¾¾åˆ°SOTAæ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Knowledge-based visual question answering (KB-VQA) requires visual language
> models (VLMs) to integrate visual understanding with external knowledge
> retrieval. Although retrieval-augmented generation (RAG) achieves significant
> advances in this task by combining knowledge-base querying, it still struggles
> with the quality of multimodal queries and the relevance of retrieved results.
> To overcome these challenges, we propose a novel three-stage method, termed
> Wiki-PRF, including Processing, Retrieval and Filtering stages. The processing
> stage dynamically invokes visual tools to extract precise multimodal
> information for retrieval. The retrieval stage integrates visual and text
> features to achieve multimodal knowledge retrieval. The filtering stage
> performs relevance filtering and concentration on retrieval results. To this
> end, we introduce a visual language model trained with answer accuracy and
> format consistency as reward signals via a reinforcement learning manner. This
> enhances the model's reasoning, tool invocation for accurate queries, and
> filtering of irrelevant content. Experiments on benchmark datasets (E-VQA and
> InfoSeek) show significant improvements~(36.0 and 42.8) in answer quality,
> achieving state-of-the-art performance. Code is available at
> https://github.com/cqu-student/Wiki-PRF

