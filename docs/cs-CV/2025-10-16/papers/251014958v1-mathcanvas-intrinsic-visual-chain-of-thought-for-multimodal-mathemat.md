---
layout: default
title: MathCanvas: Intrinsic Visual Chain-of-Thought for Multimodal Mathematical Reasoning
---

# MathCanvas: Intrinsic Visual Chain-of-Thought for Multimodal Mathematical Reasoning

**arXiv**: [2510.14958v1](https://arxiv.org/abs/2510.14958) | [PDF](https://arxiv.org/pdf/2510.14958.pdf)

**ä½œè€…**: Weikang Shi, Aldrich Yu, Rongyao Fang, Houxing Ren, Ke Wang, Aojun Zhou, Changyao Tian, Xinyu Fu, Yuxuan Hu, Zimu Lu, Linjiang Huang, Si Liu, Rui Liu, Hongsheng Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMathCanvasæ¡†æž¶ä»¥å¢žå¼ºå¤šæ¨¡æ€æ¨¡åž‹åœ¨æ•°å­¦æŽ¨ç†ä¸­çš„è§†è§‰æ€ç»´é“¾èƒ½åŠ›**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ•°å­¦æŽ¨ç†` `è§†è§‰æ€ç»´é“¾` `å›¾è¡¨ç”Ÿæˆ` `é¢„è®­ç»ƒæ•°æ®é›†` `åŸºå‡†è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§†è§‰æ€ç»´é“¾æ–¹æ³•åœ¨æ•°å­¦é¢†åŸŸå—é™äºŽå¤–éƒ¨å·¥å…·ï¼Œéš¾ä»¥ç”Ÿæˆé«˜ä¿çœŸã€é€‚æ—¶å›¾è¡¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡è§†è§‰æ“ä½œé¢„è®­ç»ƒå’Œç­–ç•¥æ€§è§†è§‰è¾…åŠ©æŽ¨ç†å¾®è°ƒï¼Œå®žçŽ°å†…åœ¨è§†è§‰æ€ç»´é“¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨MathCanvas-Benchä¸Šç›¸å¯¹åŸºçº¿æå‡86%ï¼Œå¹¶æ³›åŒ–è‡³å…¶ä»–æ•°å­¦åŸºå‡†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While Large Language Models (LLMs) have excelled in textual reasoning, they
> struggle with mathematical domains like geometry that intrinsically rely on
> visual aids. Existing approaches to Visual Chain-of-Thought (VCoT) are often
> limited by rigid external tools or fail to generate the high-fidelity,
> strategically-timed diagrams necessary for complex problem-solving. To bridge
> this gap, we introduce MathCanvas, a comprehensive framework designed to endow
> unified Large Multimodal Models (LMMs) with intrinsic VCoT capabilities for
> mathematics. Our approach consists of two phases. First, a Visual Manipulation
> stage pre-trains the model on a novel 15.2M-pair corpus, comprising 10M
> caption-to-diagram pairs (MathCanvas-Imagen) and 5.2M step-by-step editing
> trajectories (MathCanvas-Edit), to master diagram generation and editing.
> Second, a Strategic Visual-Aided Reasoning stage fine-tunes the model on
> MathCanvas-Instruct, a new 219K-example dataset of interleaved visual-textual
> reasoning paths, teaching it when and how to leverage visual aids. To
> facilitate rigorous evaluation, we introduce MathCanvas-Bench, a challenging
> benchmark with 3K problems that require models to produce interleaved
> visual-textual solutions. Our model, BAGEL-Canvas, trained under this
> framework, achieves an 86% relative improvement over strong LMM baselines on
> MathCanvas-Bench, demonstrating excellent generalization to other public math
> benchmarks. Our work provides a complete toolkit-framework, datasets, and
> benchmark-to unlock complex, human-like visual-aided reasoning in LMMs. Project
> Page: https://mathcanvas.github.io/

