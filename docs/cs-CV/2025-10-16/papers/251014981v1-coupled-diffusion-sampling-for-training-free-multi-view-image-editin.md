---
layout: default
title: Coupled Diffusion Sampling for Training-Free Multi-View Image Editing
---

# Coupled Diffusion Sampling for Training-Free Multi-View Image Editing

**arXiv**: [2510.14981v1](https://arxiv.org/abs/2510.14981) | [PDF](https://arxiv.org/pdf/2510.14981.pdf)

**ä½œè€…**: Hadi Alzayer, Yunzhi Zhang, Chen Geng, Jia-Bin Huang, Jiajun Wu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè€¦åˆæ‰©æ•£é‡‡æ ·æ–¹æ³•ï¼Œå®žçŽ°å…è®­ç»ƒçš„å¤šè§†è§’å›¾åƒç¼–è¾‘ä¸€è‡´æ€§**

**å…³é”®è¯**: `å¤šè§†è§’å›¾åƒç¼–è¾‘` `æ‰©æ•£æ¨¡åž‹` `ä¸€è‡´æ€§çº¦æŸ` `å…è®­ç»ƒæ–¹æ³•` `å›¾åƒç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé¢„è®­ç»ƒ2Dç¼–è¾‘æ¨¡åž‹åœ¨å¤šè§†è§’å›¾åƒç¼–è¾‘ä¸­ç¼ºä¹è·¨è§†è§’ä¸€è‡´æ€§
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡è€¦åˆæ‰©æ•£é‡‡æ ·ï¼Œçº¦æŸç”Ÿæˆå›¾åƒåºåˆ—ç¬¦åˆå¤šè§†è§’åˆ†å¸ƒ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä¸‰ä¸ªå¤šè§†è§’ç¼–è¾‘ä»»åŠ¡ä¸­éªŒè¯æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present an inference-time diffusion sampling method to perform multi-view
> consistent image editing using pre-trained 2D image editing models. These
> models can independently produce high-quality edits for each image in a set of
> multi-view images of a 3D scene or object, but they do not maintain consistency
> across views. Existing approaches typically address this by optimizing over
> explicit 3D representations, but they suffer from a lengthy optimization
> process and instability under sparse view settings. We propose an implicit 3D
> regularization approach by constraining the generated 2D image sequences to
> adhere to a pre-trained multi-view image distribution. This is achieved through
> coupled diffusion sampling, a simple diffusion sampling technique that
> concurrently samples two trajectories from both a multi-view image distribution
> and a 2D edited image distribution, using a coupling term to enforce the
> multi-view consistency among the generated images. We validate the
> effectiveness and generality of this framework on three distinct multi-view
> image editing tasks, demonstrating its applicability across various model
> architectures and highlighting its potential as a general solution for
> multi-view consistent editing.

