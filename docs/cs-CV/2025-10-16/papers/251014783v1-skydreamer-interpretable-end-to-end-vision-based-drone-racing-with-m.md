---
layout: default
title: SkyDreamer: Interpretable End-to-End Vision-Based Drone Racing with Model-Based Reinforcement Learning
---

# SkyDreamer: Interpretable End-to-End Vision-Based Drone Racing with Model-Based Reinforcement Learning

**arXiv**: [2510.14783v1](https://arxiv.org/abs/2510.14783) | [PDF](https://arxiv.org/pdf/2510.14783.pdf)

**ä½œè€…**: Aderik Verraest, Stavrow Bahnam, Robin Ferede, Guido de Croon, Christophe De Wagter

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSkyDreamerä»¥è§£å†³ç«¯åˆ°ç«¯è§†è§‰æ— äººæœºç«žé€Ÿçš„é²æ£’æ€§ä¸Žé«˜æ€§èƒ½é—®é¢˜**

**å…³é”®è¯**: `æ— äººæœºç«žé€Ÿ` `ç«¯åˆ°ç«¯è§†è§‰` `æ¨¡åž‹å¼ºåŒ–å­¦ä¹ ` `ä»¿çœŸåˆ°çœŸå®žè½¬ç§»` `æœºè½½æ‰§è¡Œ` `çŠ¶æ€ä¼°è®¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è‡ªä¸»æ— äººæœºç«žé€Ÿç³»ç»Ÿç¼ºä¹ç«¯åˆ°ç«¯è§†è§‰æ–¹æ³•ï¼Œæ— æ³•åŒæ—¶å®žçŽ°å…¨ä»¿çœŸåˆ°çœŸå®žè½¬ç§»ã€æœºè½½æ‰§è¡Œå’Œå† å†›çº§æ€§èƒ½ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽæ¨¡åž‹å¼ºåŒ–å­¦ä¹ ï¼Œä¸–ç•Œæ¨¡åž‹è§£ç ç‰¹æƒä¿¡æ¯ï¼Œå®žçŽ°éšå¼çŠ¶æ€ä¼°è®¡ï¼Œæå‡å¯è§£é‡Šæ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žä¸–ç•Œå®žçŽ°é«˜é€Ÿé£žè¡Œï¼Œæœ€é«˜é€Ÿåº¦21 m/sï¼ŒåŠ é€Ÿåº¦6 gï¼Œå¹¶å±•ç¤ºå¯¹è§†è§‰æ¨¡ç³Šå’Œç”µæ± è€—å°½çš„é²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Autonomous drone racing (ADR) systems have recently achieved champion-level
> performance, yet remain highly specific to drone racing. While end-to-end
> vision-based methods promise broader applicability, no system to date
> simultaneously achieves full sim-to-real transfer, onboard execution, and
> champion-level performance. In this work, we present SkyDreamer, to the best of
> our knowledge, the first end-to-end vision-based ADR policy that maps directly
> from pixel-level representations to motor commands. SkyDreamer builds on
> informed Dreamer, a model-based reinforcement learning approach where the world
> model decodes to privileged information only available during training. By
> extending this concept to end-to-end vision-based ADR, the world model
> effectively functions as an implicit state and parameter estimator, greatly
> improving interpretability. SkyDreamer runs fully onboard without external aid,
> resolves visual ambiguities by tracking progress using the state decoded from
> the world model's hidden state, and requires no extrinsic camera calibration,
> enabling rapid deployment across different drones without retraining.
> Real-world experiments show that SkyDreamer achieves robust, high-speed flight,
> executing tight maneuvers such as an inverted loop, a split-S and a ladder,
> reaching speeds of up to 21 m/s and accelerations of up to 6 g. It further
> demonstrates a non-trivial visual sim-to-real transfer by operating on
> poor-quality segmentation masks, and exhibits robustness to battery depletion
> by accurately estimating the maximum attainable motor RPM and adjusting its
> flight path in real-time. These results highlight SkyDreamer's adaptability to
> important aspects of the reality gap, bringing robustness while still achieving
> extremely high-speed, agile flight.

