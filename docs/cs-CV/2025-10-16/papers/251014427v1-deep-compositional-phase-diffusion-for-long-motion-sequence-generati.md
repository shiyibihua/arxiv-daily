---
layout: default
title: Deep Compositional Phase Diffusion for Long Motion Sequence Generation
---

# Deep Compositional Phase Diffusion for Long Motion Sequence Generation

**arXiv**: [2510.14427v1](https://arxiv.org/abs/2510.14427) | [PDF](https://arxiv.org/pdf/2510.14427.pdf)

**ä½œè€…**: Ho Yin Au, Jie Chen, Junkun Jiang, Jingyu Xiang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»„åˆç›¸ä½æ‰©æ•£æ–¹æ³•ä»¥è§£å†³é•¿è¿åŠ¨åºåˆ—ç”Ÿæˆä¸­çš„è¿‡æ¸¡ä¸è¿žç»­é—®é¢˜**

**å…³é”®è¯**: `è¿åŠ¨åºåˆ—ç”Ÿæˆ` `æ‰©æ•£æ¨¡åž‹` `ç›¸ä½æ‰©æ•£` `ç»„åˆè¿åŠ¨` `è¿‡æ¸¡è¿žç»­æ€§` `è¿åŠ¨æ’å€¼`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ¨¡åž‹ç”Ÿæˆå¤šè¯­ä¹‰è¿åŠ¨åºåˆ—æ—¶ï¼Œè¿‡æ¸¡è¾¹ç•Œå¤„è¿åŠ¨åŠ¨æ€ä¸è¿žç»­ï¼Œäº§ç”Ÿçªå…€ä¼ªå½±ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨SPDMå’ŒTPDMåœ¨æ½œåœ¨è¿åŠ¨é¢‘åŸŸä¸­é€æ­¥èžå…¥è¯­ä¹‰æŒ‡å¯¼å’Œç›¸é‚»è¿åŠ¨ç›¸ä½ç»†èŠ‚ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¡†æž¶åœ¨ç”Ÿæˆè¯­ä¹‰å¯¹é½çš„ç»„åˆè¿åŠ¨åºåˆ—ä¸­è¡¨çŽ°ç«žäº‰æ€§ï¼Œä¿æŒç›¸ä½è¿‡æ¸¡è¿žç»­æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent research on motion generation has shown significant progress in
> generating semantically aligned motion with singular semantics. However, when
> employing these models to create composite sequences containing multiple
> semantically generated motion clips, they often struggle to preserve the
> continuity of motion dynamics at the transition boundaries between clips,
> resulting in awkward transitions and abrupt artifacts. To address these
> challenges, we present Compositional Phase Diffusion, which leverages the
> Semantic Phase Diffusion Module (SPDM) and Transitional Phase Diffusion Module
> (TPDM) to progressively incorporate semantic guidance and phase details from
> adjacent motion clips into the diffusion process. Specifically, SPDM and TPDM
> operate within the latent motion frequency domain established by the
> pre-trained Action-Centric Motion Phase Autoencoder (ACT-PAE). This allows them
> to learn semantically important and transition-aware phase information from
> variable-length motion clips during training. Experimental results demonstrate
> the competitive performance of our proposed framework in generating
> compositional motion sequences that align semantically with the input
> conditions, while preserving phase transitional continuity between preceding
> and succeeding motion clips. Additionally, motion inbetweening task is made
> possible by keeping the phase parameter of the input motion sequences fixed
> throughout the diffusion process, showcasing the potential for extending the
> proposed framework to accommodate various application scenarios. Codes are
> available at https://github.com/asdryau/TransPhase.

