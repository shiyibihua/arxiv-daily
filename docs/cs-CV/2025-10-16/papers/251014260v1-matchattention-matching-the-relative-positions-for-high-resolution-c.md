---
layout: default
title: MatchAttention: Matching the Relative Positions for High-Resolution Cross-View Matching
---

# MatchAttention: Matching the Relative Positions for High-Resolution Cross-View Matching

**arXiv**: [2510.14260v1](https://arxiv.org/abs/2510.14260) | [PDF](https://arxiv.org/pdf/2510.14260.pdf)

**ä½œè€…**: Tingman Yan, Tao Liu, Xilian Yang, Qunfei Zhao, Zeyang Xia

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMatchAttentionæœºåˆ¶ä»¥è§£å†³é«˜åˆ†è¾¨çŽ‡è·¨è§†å›¾åŒ¹é…çš„æ•ˆçŽ‡å’Œç²¾åº¦é—®é¢˜**

**å…³é”®è¯**: `è·¨è§†å›¾åŒ¹é…` `æ³¨æ„åŠ›æœºåˆ¶` `ç«‹ä½“åŒ¹é…` `é«˜åˆ†è¾¨çŽ‡å›¾åƒå¤„ç†` `å®žæ—¶æŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé«˜åˆ†è¾¨çŽ‡å›¾åƒè·¨è§†å›¾åŒ¹é…å­˜åœ¨äºŒæ¬¡å¤æ‚åº¦å’Œç¼ºä¹æ˜¾å¼åŒ¹é…çº¦æŸçš„æŒ‘æˆ˜
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡BilinearSoftmaxå®žçŽ°è¿žç»­å¯å¾®æ»‘åŠ¨çª—å£æ³¨æ„åŠ›é‡‡æ ·ï¼Œè¿­ä»£æ›´æ–°ç›¸å¯¹ä½ç½®
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¾¾åˆ°SOTAï¼Œæ”¯æŒå®žæ—¶é«˜åˆ†è¾¨çŽ‡å¤„ç†ï¼Œå¦‚4Kå›¾åƒ0.1ç§’æŽ¨ç†

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Cross-view matching is fundamentally achieved through cross-attention
> mechanisms. However, matching of high-resolution images remains challenging due
> to the quadratic complexity and lack of explicit matching constraints in the
> existing cross-attention. This paper proposes an attention mechanism,
> MatchAttention, that dynamically matches relative positions. The relative
> position determines the attention sampling center of the key-value pairs given
> a query. Continuous and differentiable sliding-window attention sampling is
> achieved by the proposed BilinearSoftmax. The relative positions are
> iteratively updated through residual connections across layers by embedding
> them into the feature channels. Since the relative position is exactly the
> learning target for cross-view matching, an efficient hierarchical cross-view
> decoder, MatchDecoder, is designed with MatchAttention as its core component.
> To handle cross-view occlusions, gated cross-MatchAttention and a
> consistency-constrained loss are proposed. These two components collectively
> mitigate the impact of occlusions in both forward and backward passes, allowing
> the model to focus more on learning matching relationships. When applied to
> stereo matching, MatchStereo-B ranked 1st in average error on the public
> Middlebury benchmark and requires only 29ms for KITTI-resolution inference.
> MatchStereo-T can process 4K UHD images in 0.1 seconds using only 3GB of GPU
> memory. The proposed models also achieve state-of-the-art performance on KITTI
> 2012, KITTI 2015, ETH3D, and Spring flow datasets. The combination of high
> accuracy and low computational complexity makes real-time, high-resolution, and
> high-accuracy cross-view matching possible. Code is available at
> https://github.com/TingmanYan/MatchAttention.

