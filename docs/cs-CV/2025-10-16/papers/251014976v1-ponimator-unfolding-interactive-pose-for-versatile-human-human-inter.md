---
layout: default
title: Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation
---

# Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation

**arXiv**: [2510.14976v1](https://arxiv.org/abs/2510.14976) | [PDF](https://arxiv.org/pdf/2510.14976.pdf)

**ä½œè€…**: Shaowei Liu, Chuan Guo, Bing Zhou, Jian Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPonimatoræ¡†æž¶ï¼ŒåŸºäºŽè¿‘è·äº¤äº’å§¿æ€å®žçŽ°å¤šæ ·åŒ–äºº-äººäº¤äº’åŠ¨ç”»**

**å…³é”®è¯**: `äºº-äººäº¤äº’åŠ¨ç”»` `æ¡ä»¶æ‰©æ•£æ¨¡åž‹` `å§¿æ€å…ˆéªŒ` `è¿åŠ¨ç”Ÿæˆ` `æ–‡æœ¬åˆ°äº¤äº’åˆæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•ä»Žè¿‘è·äºº-äººäº¤äº’å§¿æ€æŽ¨æ–­å’Œç”ŸæˆåŠ¨æ€äº¤äº’åŠ¨ç”»
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨ä¸¤ä¸ªæ¡ä»¶æ‰©æ•£æ¨¡åž‹ï¼Œåˆ†åˆ«å¤„ç†æ—¶ç©ºå…ˆéªŒç”Ÿæˆè¿åŠ¨å’Œå§¿æ€
3. å®žéªŒæ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†éªŒè¯æ¡†æž¶é€šç”¨æ€§ã€æœ‰æ•ˆæ€§å’Œé²æ£’æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Close-proximity human-human interactive poses convey rich contextual
> information about interaction dynamics. Given such poses, humans can
> intuitively infer the context and anticipate possible past and future dynamics,
> drawing on strong priors of human behavior. Inspired by this observation, we
> propose Ponimator, a simple framework anchored on proximal interactive poses
> for versatile interaction animation. Our training data consists of
> close-contact two-person poses and their surrounding temporal context from
> motion-capture interaction datasets. Leveraging interactive pose priors,
> Ponimator employs two conditional diffusion models: (1) a pose animator that
> uses the temporal prior to generate dynamic motion sequences from interactive
> poses, and (2) a pose generator that applies the spatial prior to synthesize
> interactive poses from a single pose, text, or both when interactive poses are
> unavailable. Collectively, Ponimator supports diverse tasks, including
> image-based interaction animation, reaction animation, and text-to-interaction
> synthesis, facilitating the transfer of interaction knowledge from high-quality
> mocap data to open-world scenarios. Empirical experiments across diverse
> datasets and applications demonstrate the universality of the pose prior and
> the effectiveness and robustness of our framework.

