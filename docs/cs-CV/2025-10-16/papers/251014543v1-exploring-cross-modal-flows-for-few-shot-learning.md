---
layout: default
title: Exploring Cross-Modal Flows for Few-Shot Learning
---

# Exploring Cross-Modal Flows for Few-Shot Learning

**arXiv**: [2510.14543v1](https://arxiv.org/abs/2510.14543) | [PDF](https://arxiv.org/pdf/2510.14543.pdf)

**ä½œè€…**: Ziqi Jiang, Yanghao Wang, Long Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFlow Matching Alignmentä»¥è§£å†³å¤æ‚æ•°æ®é›†ä¸­çš„è·¨æ¨¡æ€å¯¹é½é—®é¢˜**

**å…³é”®è¯**: `è·¨æ¨¡æ€å­¦ä¹ ` `å°‘æ ·æœ¬å­¦ä¹ ` `å‚æ•°é«˜æ•ˆå¾®è°ƒ` `Flow Matching` `ç‰¹å¾å¯¹é½` `å™ªå£°å¢žå¼º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ä»…å•æ­¥è°ƒæ•´ï¼Œéš¾ä»¥å¤„ç†é«˜åº¦çº ç¼ çš„è·¨æ¨¡æ€ç‰¹å¾
2. FMAé€šè¿‡å¤šæ­¥è°ƒæ•´å­¦ä¹ è·¨æ¨¡æ€é€Ÿåº¦åœºï¼Œå¹¶å¼•å…¥å™ªå£°å¢žå¼ºå’Œæ—©åœæ±‚è§£å™¨
3. å®žéªŒæ˜¾ç¤ºFMAåœ¨å¤šä¸ªåŸºå‡†å’Œéª¨å¹²ç½‘ç»œä¸Šæ˜¾è‘—æå‡æ€§èƒ½ï¼Œå°¤å…¶åœ¨æŒ‘æˆ˜æ€§æ•°æ®é›†

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Aligning features from different modalities, is one of the most fundamental
> challenges for cross-modal tasks. Although pre-trained vision-language models
> can achieve a general alignment between image and text, they often require
> parameter-efficient fine-tuning (PEFT) for further adjustment. Today's PEFT
> methods (e.g., prompt tuning, LoRA-based, or adapter-based) always selectively
> fine-tune a subset of parameters, which can slightly adjust either visual or
> textual features, and avoid overfitting. In this paper, we are the first to
> highlight that all existing PEFT methods perform one-step adjustment. It is
> insufficient for complex (or difficult) datasets, where features of different
> modalities are highly entangled. To this end, we propose the first
> model-agnostic multi-step adjustment approach by learning a cross-modal
> velocity field: Flow Matching Alignment (FMA). Specifically, to ensure the
> correspondence between categories during training, we first utilize a fixed
> coupling strategy. Then, we propose a noise augmentation strategy to alleviate
> the data scarcity issue. Finally, we design an early-stopping solver, which
> terminates the transformation process earlier, improving both efficiency and
> accuracy. Compared with one-step PEFT methods, FMA has the multi-step
> rectification ability to achieve more precise and robust alignment. Extensive
> results have demonstrated that FMA can consistently yield significant
> performance gains across various benchmarks and backbones, particularly on
> challenging datasets.

