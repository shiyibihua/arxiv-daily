---
layout: default
title: ChangingGrounding: 3D Visual Grounding in Changing Scenes
---

# ChangingGrounding: 3D Visual Grounding in Changing Scenes

**arXiv**: [2510.14965v1](https://arxiv.org/abs/2510.14965) | [PDF](https://arxiv.org/pdf/2510.14965.pdf)

**ä½œè€…**: Miao Hu, Zhiwei Huang, Tai Wang, Jiangmiao Pang, Dahua Lin, Nanning Zheng, Runsen Xu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºChangingGroundingåŸºå‡†ä¸ŽMem-ChangingGrounderæ–¹æ³•ï¼Œä»¥è§£å†³åŠ¨æ€åœºæ™¯ä¸­çš„3Dè§†è§‰å®šä½é—®é¢˜ã€‚**

**å…³é”®è¯**: `3Dè§†è§‰å®šä½` `åŠ¨æ€åœºæ™¯` `è·¨æ¨¡æ€æ£€ç´¢` `å¤šè§†å›¾èžåˆ` `é›¶æ ·æœ¬å­¦ä¹ ` `åŸºå‡†æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰3Dè§†è§‰å®šä½æ–¹æ³•ä¾èµ–æ›´æ–°ç‚¹äº‘ï¼Œåœ¨åŠ¨æ€åœºæ™¯ä¸­æˆæœ¬é«˜ä¸”ä¸å®žç”¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆè·¨æ¨¡æ€æ£€ç´¢ä¸Žè½»é‡å¤šè§†å›¾èžåˆï¼Œå®žçŽ°é›¶æ ·æœ¬ç›®æ ‡å®šä½ä¸Žé«˜æ•ˆæŽ¢ç´¢ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ChangingGroundingåŸºå‡†ä¸Šï¼ŒMem-ChangingGrounderå®šä½ç²¾åº¦æœ€é«˜ä¸”æŽ¢ç´¢æˆæœ¬æ˜¾è‘—é™ä½Žã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Real-world robots localize objects from natural-language instructions while
> scenes around them keep changing. Yet most of the existing 3D visual grounding
> (3DVG) method still assumes a reconstructed and up-to-date point cloud, an
> assumption that forces costly re-scans and hinders deployment. We argue that
> 3DVG should be formulated as an active, memory-driven problem, and we introduce
> ChangingGrounding, the first benchmark that explicitly measures how well an
> agent can exploit past observations, explore only where needed, and still
> deliver precise 3D boxes in changing scenes. To set a strong reference point,
> we also propose Mem-ChangingGrounder, a zero-shot method for this task that
> marries cross-modal retrieval with lightweight multi-view fusion: it identifies
> the object type implied by the query, retrieves relevant memories to guide
> actions, then explores the target efficiently in the scene, falls back when
> previous operations are invalid, performs multi-view scanning of the target,
> and projects the fused evidence from multi-view scans to get accurate object
> bounding boxes. We evaluate different baselines on ChangingGrounding, and our
> Mem-ChangingGrounder achieves the highest localization accuracy while greatly
> reducing exploration cost. We hope this benchmark and method catalyze a shift
> toward practical, memory-centric 3DVG research for real-world applications.
> Project page: https://hm123450.github.io/CGB/ .

