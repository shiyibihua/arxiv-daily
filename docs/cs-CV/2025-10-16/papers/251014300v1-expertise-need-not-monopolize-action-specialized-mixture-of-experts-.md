---
layout: default
title: Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning
---

# Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning

**arXiv**: [2510.14300v1](https://arxiv.org/abs/2510.14300) | [PDF](https://arxiv.org/pdf/2510.14300.pdf)

**ä½œè€…**: Weijie Shen, Yitian Liu, Yuhao Wu, Zhixuan Liang, Sijia Gu, Dehui Wang, Tian Nian, Lei Xu, Yusen Qin, Jiangmiao Pang, Xinping Guan, Xiaokang Yang, Yao Mu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAdaMoEæž¶æž„ä»¥è§£å†³è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹æ‰©å±•ä¸­çš„è®¡ç®—æ•ˆçŽ‡ä¸Žæ€§èƒ½å¹³è¡¡é—®é¢˜**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `æ··åˆä¸“å®¶æž¶æž„` `æœºå™¨äººæ“ä½œ` `æ¨¡åž‹æ‰©å±•` `è®¡ç®—æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šVLAæ¨¡åž‹æ‰©å±•éœ€é«˜è®¡ç®—èµ„æºä¸Žç¨€ç¼ºæœºå™¨äººæ•°æ®ï¼Œä¸”éœ€å¹³è¡¡æ¨¡åž‹å®¹é‡ä¸Žå®žæ—¶æŽ§åˆ¶æ•ˆçŽ‡
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ··åˆä¸“å®¶æž¶æž„ï¼Œç»§æ‰¿é¢„è®­ç»ƒæƒé‡ï¼Œé€šè¿‡è§£è€¦ä¸“å®¶é€‰æ‹©ä¸Žæƒé‡å®žçŽ°åä½œåˆ©ç”¨
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨LIBEROå’ŒRoboTwinåŸºå‡†ä¸Šæ€§èƒ½æå‡1.8%å’Œ9.3%ï¼ŒçœŸå®žä¸–ç•Œå®žéªŒæå‡21.5%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models are experiencing rapid development and
> demonstrating promising capabilities in robotic manipulation tasks. However,
> scaling up VLA models presents several critical challenges: (1) Training new
> VLA models from scratch demands substantial computational resources and
> extensive datasets. Given the current scarcity of robot data, it becomes
> particularly valuable to fully leverage well-pretrained VLA model weights
> during the scaling process. (2) Real-time control requires carefully balancing
> model capacity with computational efficiency. To address these challenges, We
> propose AdaMoE, a Mixture-of-Experts (MoE) architecture that inherits
> pretrained weights from dense VLA models, and scales up the action expert by
> substituting the feedforward layers into sparsely activated MoE layers. AdaMoE
> employs a decoupling technique that decouples expert selection from expert
> weighting through an independent scale adapter working alongside the
> traditional router. This enables experts to be selected based on task relevance
> while contributing with independently controlled weights, allowing
> collaborative expert utilization rather than winner-takes-all dynamics. Our
> approach demonstrates that expertise need not monopolize. Instead, through
> collaborative expert utilization, we can achieve superior performance while
> maintaining computational efficiency. AdaMoE consistently outperforms the
> baseline model across key benchmarks, delivering performance gains of 1.8% on
> LIBERO and 9.3% on RoboTwin. Most importantly, a substantial 21.5% improvement
> in real-world experiments validates its practical effectiveness for robotic
> manipulation tasks.

