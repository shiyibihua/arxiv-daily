---
layout: default
title: In-Context Learning with Unpaired Clips for Instruction-based Video Editing
---

# In-Context Learning with Unpaired Clips for Instruction-based Video Editing

**arXiv**: [2510.14648v1](https://arxiv.org/abs/2510.14648) | [PDF](https://arxiv.org/pdf/2510.14648.pdf)

**ä½œè€…**: Xinyao Liao, Xianfang Zeng, Ziye Song, Zhoujie Fu, Gang Yu, Guosheng Lin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽä¸Šä¸‹æ–‡å­¦ä¹ çš„æ— é…å¯¹è§†é¢‘å‰ªè¾‘é¢„è®­ç»ƒç­–ç•¥ï¼Œä»¥è§£å†³æŒ‡ä»¤è§†é¢‘ç¼–è¾‘çš„æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚**

**å…³é”®è¯**: `æŒ‡ä»¤è§†é¢‘ç¼–è¾‘` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `æ— é…å¯¹æ•°æ®é¢„è®­ç»ƒ` `è§†é¢‘ç”Ÿæˆæ¨¡åž‹` `ç¼–è¾‘æŒ‡ä»¤å¯¹é½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæŒ‡ä»¤è§†é¢‘ç¼–è¾‘å› å¤§è§„æ¨¡é…å¯¹æ•°æ®æˆæœ¬é«˜è€Œå‘å±•å—é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨æ— é…å¯¹è§†é¢‘å‰ªè¾‘é¢„è®­ç»ƒï¼Œèµ‹äºˆæ¨¡åž‹é€šç”¨ç¼–è¾‘èƒ½åŠ›ï¼Œå†å°‘é‡ç²¾è°ƒã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨æŒ‡ä»¤å¯¹é½å’Œè§†è§‰ä¿çœŸåº¦ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œæå‡12%æŒ‡ä»¤éµå¾ªå’Œ15%ç¼–è¾‘è´¨é‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite the rapid progress of instruction-based image editing, its extension
> to video remains underexplored, primarily due to the prohibitive cost and
> complexity of constructing large-scale paired video editing datasets. To
> address this challenge, we introduce a low-cost pretraining strategy for
> instruction-based video editing that leverages in-context learning from
> unpaired video clips. We show that pretraining a foundation video generation
> model with this strategy endows it with general editing capabilities, such as
> adding, replacing, or deleting operations, according to input editing
> instructions. The pretrained model can then be efficiently refined with a small
> amount of high-quality paired editing data. Built upon HunyuanVideoT2V, our
> framework first pretrains on approximately 1M real video clips to learn basic
> editing concepts, and subsequently fine-tunes on fewer than 150k curated
> editing pairs to extend more editing tasks and improve the editing quality.
> Comparative experiments show that our method surpasses existing
> instruction-based video editing approaches in both instruction alignment and
> visual fidelity, achieving a 12\% improvement in editing instruction following
> and a 15\% improvement in editing quality.

