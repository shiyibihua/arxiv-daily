---
layout: default
title: Language as an Anchor: Preserving Relative Visual Geometry for Domain Incremental Learning
---

# Language as an Anchor: Preserving Relative Visual Geometry for Domain Incremental Learning

**arXiv**: [2511.14401v1](https://arxiv.org/abs/2511.14401) | [PDF](https://arxiv.org/pdf/2511.14401.pdf)

**ä½œè€…**: Shuyi Geng, Tao Zhou, Yi Zhou

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLAVAæ¡†æž¶ï¼Œåˆ©ç”¨è¯­è¨€é”šç‚¹è§£å†³é¢†åŸŸå¢žé‡å­¦ä¹ ä¸­çš„è¯­ä¹‰å¤±çœŸé—®é¢˜**

**å…³é”®è¯**: `é¢†åŸŸå¢žé‡å­¦ä¹ ` `è¯­è¨€é”šç‚¹` `ç›¸å¯¹å‡ ä½•å¯¹é½` `è¯­ä¹‰ç›¸ä¼¼æ€§` `çŸ¥è¯†ä¿ç•™` `è§†è§‰è¡¨ç¤ºå­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé¢†åŸŸå¢žé‡å­¦ä¹ é¢ä¸´ç»Ÿä¸€è§†è§‰ç©ºé—´å¯¼è‡´è¯­ä¹‰å¤±çœŸä¸Žéš”ç¦»å‚æ•°å¯¼è‡´çŸ¥è¯†ç¢Žç‰‡åŒ–çš„å›°å¢ƒ
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ–‡æœ¬é”šç‚¹é©±åŠ¨ç›¸å¯¹å¯¹é½ï¼Œä¿æŒè§†è§‰è¡¨ç¤ºçš„ç›¸å¯¹å‡ ä½•ç»“æž„ä¸€è‡´
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œä»£ç å·²å¼€æº

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> A key challenge in Domain Incremental Learning (DIL) is to continually learn under shifting distributions while preserving knowledge from previous domains. Existing methods face a fundamental dilemma. On one hand, projecting all domains into a single unified visual space leads to inter-domain interference and semantic distortion, as large shifts may vary with not only visual appearance but also underlying semantics. On the other hand, isolating domain-specific parameters causes knowledge fragmentation, creating "knowledge islands" that hamper knowledge reuse and exacerbate forgetting. To address this issue, we propose LAVA (Language-Anchored Visual Alignment), a novel DIL framework that replaces direct feature alignment with relative alignment driven by a text-based reference anchor. LAVA guides the visual representations of each incoming domain to preserve a consistent relative geometry, which is defined by mirroring the pairwise semantic similarities between the class names. This anchored geometric structure acts as a bridge across domains, enabling the retrieval of class-aware prior knowledge and facilitating robust feature aggregation. Extensive experiments on standard DIL benchmarks demonstrate that LAVA achieves significant performance improvements over state-of-the-arts. Code is available at https://github.com/ShuyiGeng/LAVA.

