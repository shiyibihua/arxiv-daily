---
layout: default
title: Semantic Context Matters: Improving Conditioning for Autoregressive Models
---

# Semantic Context Matters: Improving Conditioning for Autoregressive Models

**arXiv**: [2511.14063v1](https://arxiv.org/abs/2511.14063) | [PDF](https://arxiv.org/pdf/2511.14063.pdf)

**ä½œè€…**: Dongyang Jin, Ryan Xu, Jianhao Zeng, Rui Lan, Yancheng Bai, Lei Sun, Xiangxiang Chu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSCARæ–¹æ³•ä»¥å¢žå¼ºè‡ªå›žå½’æ¨¡åž‹çš„è¯­ä¹‰æ¡ä»¶ï¼Œæå‡å›¾åƒç¼–è¾‘æ€§èƒ½**

**å…³é”®è¯**: `è‡ªå›žå½’æ¨¡åž‹` `å›¾åƒç¼–è¾‘` `è¯­ä¹‰æ¡ä»¶` `é¢„å¡«å……æŠ€æœ¯` `å¯æŽ§ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è‡ªå›žå½’æ¨¡åž‹åœ¨å›¾åƒç”Ÿæˆä¸­æ¡ä»¶å¼±ä¸”æ•ˆçŽ‡ä½Žï¼Œå¯¼è‡´æŒ‡ä»¤éµå¾ªå·®å’Œè§†è§‰ä¼ªå½±
2. SCARå¼•å…¥åŽ‹ç¼©è¯­ä¹‰é¢„å¡«å……å’Œè¯­ä¹‰å¯¹é½æŒ‡å¯¼ï¼Œå¼ºåŒ–è¯­ä¹‰ç¼–ç ä¸Žè§£ç å¯¹é½
3. åœ¨æŒ‡ä»¤ç¼–è¾‘å’Œå¯æŽ§ç”ŸæˆåŸºå‡†ä¸Šå®žçŽ°æ›´é«˜è§†è§‰ä¿çœŸåº¦å’Œè¯­ä¹‰å¯¹é½ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recently, autoregressive (AR) models have shown strong potential in image generation, offering better scalability and easier integration with unified multi-modal systems compared to diffusion-based methods. However, extending AR models to general image editing remains challenging due to weak and inefficient conditioning, often leading to poor instruction adherence and visual artifacts. To address this, we propose SCAR, a Semantic-Context-driven method for Autoregressive models. SCAR introduces two key components: Compressed Semantic Prefilling, which encodes high-level semantics into a compact and efficient prefix, and Semantic Alignment Guidance, which aligns the last visual hidden states with target semantics during autoregressive decoding to enhance instruction fidelity. Unlike decoding-stage injection methods, SCAR builds upon the flexibility and generality of vector-quantized-based prefilling while overcoming its semantic limitations and high cost. It generalizes across both next-token and next-set AR paradigms with minimal architectural changes. SCAR achieves superior visual fidelity and semantic alignment on both instruction editing and controllable generation benchmarks, outperforming prior AR-based methods while maintaining controllability. All code will be released.

