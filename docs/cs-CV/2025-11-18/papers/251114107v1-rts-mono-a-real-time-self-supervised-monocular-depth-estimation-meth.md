---
layout: default
title: RTS-Mono: A Real-Time Self-Supervised Monocular Depth Estimation Method for Real-World Deployment
---

# RTS-Mono: A Real-Time Self-Supervised Monocular Depth Estimation Method for Real-World Deployment

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.14107" target="_blank" class="toolbar-btn">arXiv: 2511.14107v1</a>
    <a href="https://arxiv.org/pdf/2511.14107.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.14107v1" 
            onclick="toggleFavorite(this, '2511.14107v1', 'RTS-Mono: A Real-Time Self-Supervised Monocular Depth Estimation Method for Real-World Deployment')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Zeyu Cheng, Tongfei Liu, Tao Lei, Xiang Hua, Yi Zhang, Chengkai Tang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-18

**Â§áÊ≥®**: 14 pages, 10 figures

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/ZYCheng777/RTS-Mono)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**RTS-MonoÔºö‰∏ÄÁßçÁî®‰∫éÁúüÂÆû‰∏ñÁïåÈÉ®ÁΩ≤ÁöÑÂÆûÊó∂Ëá™ÁõëÁù£ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°` `Ëá™ÁõëÁù£Â≠¶‰π†` `ÂÆûÊó∂Êé®ÁêÜ` `ËΩªÈáèÂåñÁΩëÁªú` `Ëá™Âä®È©æÈ©∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°Ê®°ÂûãËÆ°ÁÆóËµÑÊ∫êÊ∂àËÄóÂ§ßÔºåËΩªÈáèÂåñÂêéÊÄßËÉΩÊòæËëó‰∏ãÈôçÔºåÈòªÁ¢ç‰∫ÜÂÖ∂Âú®Ëá™Âä®È©æÈ©∂ÂíåÊú∫Âô®‰∫∫ÂØºËà™Á≠âÈ¢ÜÂüüÁöÑÂÆûÈôÖÈÉ®ÁΩ≤„ÄÇ
2. RTS-MonoÈááÁî®ËΩªÈáèÁ∫ßÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®Êû∂ÊûÑÔºåÂà©Áî®Lite-EncoderÂíåÂ§öÂ∞∫Â∫¶Á®ÄÁñèËûçÂêàÊ°ÜÊû∂ÔºåÂú®‰øùËØÅÊÄßËÉΩÁöÑÂêåÊó∂ÔºåÊòæËëóÈôç‰Ωé‰∫ÜËÆ°ÁÆóÂÜó‰Ωô„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåRTS-MonoÂú®KITTIÊï∞ÊçÆÈõÜ‰∏ä‰ª•ÊûÅ‰ΩéÁöÑÂèÇÊï∞ÈáèÂÆûÁé∞‰∫ÜSOTAÊÄßËÉΩÔºåÂπ∂Âú®Nvidia Jetson Orin‰∏äÂÆûÁé∞‰∫Ü49 FPSÁöÑÂÆûÊó∂Êé®ÁêÜ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫RTS-MonoÁöÑÂÆûÊó∂Ëá™ÁõëÁù£ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÊñπÊ≥ïÔºåÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÊñπÊ≥ïËÆ°ÁÆóËµÑÊ∫êÊ∂àËÄóÂ§ß„ÄÅÊÄßËÉΩ‰∏ãÈôçÁ≠âÈóÆÈ¢òÔºå‰ªéËÄå‰øÉËøõËá™ÁõëÁù£ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°Ê®°ÂûãÂú®Áé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑÈÉ®ÁΩ≤„ÄÇRTS-MonoÈááÁî®ËΩªÈáèÈ´òÊïàÁöÑÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®Êû∂ÊûÑÔºåÂÖ∂‰∏≠ÁºñÁ†ÅÂô®Âü∫‰∫éLite-EncoderÔºåËß£Á†ÅÂô®ÈááÁî®Â§öÂ∞∫Â∫¶Á®ÄÁñèËûçÂêàÊ°ÜÊû∂Ôºå‰ª•ÊúÄÂ∞èÂåñÂÜó‰ΩôÔºå‰øùËØÅÊÄßËÉΩÂπ∂ÊèêÈ´òÊé®ÁêÜÈÄüÂ∫¶„ÄÇÂú®KITTIÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåRTS-Mono‰ª•ÊûÅ‰ΩéÁöÑÂèÇÊï∞ÈáèÔºà3MÔºâÂú®È´òÂàÜËæ®ÁéáÂíå‰ΩéÂàÜËæ®Áéá‰∏ãÂùáÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ‰∏éËΩªÈáèÁ∫ßÊñπÊ≥ïÁõ∏ÊØîÔºåRTS-MonoÂú®‰ΩéÂàÜËæ®Áéá‰∏ãÂ∞ÜAbs RelÂíåSq RelÂàÜÂà´ÊèêÈ´ò‰∫Ü5.6%Âíå9.8%ÔºåÂú®È´òÂàÜËæ®Áéá‰∏ãÂ∞ÜSq RelÂíåRMSEÂàÜÂà´ÊèêÈ´ò‰∫Ü6.1%Âíå1.9%„ÄÇÂú®ÁúüÂÆû‰∏ñÁïåÈÉ®ÁΩ≤ÂÆûÈ™å‰∏≠ÔºåRTS-MonoÂÖ∑ÊúâÊûÅÈ´òÁöÑÁ≤æÂ∫¶ÔºåÂπ∂‰∏îÂèØ‰ª•Âú®Nvidia Jetson Orin‰∏ä‰ª•49 FPSÁöÑÈÄüÂ∫¶ÊâßË°åÂÆûÊó∂Êé®ÁêÜ„ÄÇÊ∫ê‰ª£Á†ÅÂ∑≤Âú®https://github.com/ZYCheng777/RTS-Mono‰∏äÂèëÂ∏É„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Ëá™ÁõëÁù£ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°Ê®°ÂûãÂú®ÂÆûÈôÖÈÉ®ÁΩ≤‰∏≠Èù¢‰∏¥ÁöÑËÆ°ÁÆóËµÑÊ∫êÊ∂àËÄóÂ§ßÂíåÊÄßËÉΩ‰∏ãÈôçÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïË¶Å‰πàËÆ°ÁÆóÈáèÂ§ßÈöæ‰ª•ÂÆûÊó∂ËøêË°åÔºåË¶Å‰πà‰∏∫‰∫ÜËΩªÈáèÂåñËÄåÁâ∫Áâ≤‰∫ÜÁ≤æÂ∫¶ÔºåÊó†Ê≥ïÊª°Ë∂≥ÁúüÂÆûÂú∫ÊôØÁöÑÈúÄÊ±Ç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØËÆæËÆ°‰∏Ä‰∏™ËΩªÈáèÁ∫ß‰ΩÜÈ´òÊïàÁöÑÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®Êû∂ÊûÑÔºåÈÄöËøáÂáèÂ∞ëÂÜó‰ΩôËÆ°ÁÆóÂíå‰ºòÂåñÁΩëÁªúÁªìÊûÑÔºåÂú®‰øùËØÅÊ∑±Â∫¶‰º∞ËÆ°Á≤æÂ∫¶ÁöÑÂêåÊó∂ÔºåÊòæËëóÈôç‰ΩéÊ®°ÂûãÁöÑÂèÇÊï∞ÈáèÂíåËÆ°ÁÆóÂ§çÊùÇÂ∫¶Ôºå‰ªéËÄåÂÆûÁé∞ÂÆûÊó∂Êé®ÁêÜ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRTS-MonoÁöÑÊï¥‰ΩìÊû∂ÊûÑÊòØ‰∏Ä‰∏™ÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®ÁªìÊûÑ„ÄÇÁºñÁ†ÅÂô®ÈÉ®ÂàÜÈááÁî®Lite-EncoderÔºåÁî®‰∫éÊèêÂèñÂõæÂÉèÁâπÂæÅ„ÄÇËß£Á†ÅÂô®ÈÉ®ÂàÜÈááÁî®Â§öÂ∞∫Â∫¶Á®ÄÁñèËûçÂêàÊ°ÜÊû∂ÔºåÂ∞Ü‰∏çÂêåÂ∞∫Â∫¶ÁöÑÁâπÂæÅËøõË°åËûçÂêàÔºåÂπ∂ËæìÂá∫Ê∑±Â∫¶Âõæ„ÄÇËØ•Ê°ÜÊû∂ÈÅøÂÖç‰∫Ü‰º†ÁªüËß£Á†ÅÂô®‰∏≠Â§ßÈáèÁöÑ‰∏äÈááÊ†∑ÂíåÂç∑ÁßØÊìç‰ΩúÔºå‰ªéËÄåÈôç‰Ωé‰∫ÜËÆ°ÁÆóÈáè„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöRTS-MonoÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ËΩªÈáèÁ∫ßËß£Á†ÅÂô®ÁöÑËÆæËÆ°ÔºåÂç≥Â§öÂ∞∫Â∫¶Á®ÄÁñèËûçÂêàÊ°ÜÊû∂„ÄÇËØ•Ê°ÜÊû∂ÈÄöËøáÈÄâÊã©ÊÄßÂú∞ËûçÂêà‰∏çÂêåÂ∞∫Â∫¶ÁöÑÁâπÂæÅÔºåÈÅøÂÖç‰∫ÜÂÜó‰ΩôËÆ°ÁÆóÔºåÂêåÊó∂‰øùËØÅ‰∫ÜÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÁ≤æÂ∫¶„ÄÇÊ≠§Â§ñÔºåLite-EncoderÁöÑ‰ΩøÁî®‰πüËøõ‰∏ÄÊ≠•Èôç‰Ωé‰∫ÜÊ®°ÂûãÁöÑÂèÇÊï∞Èáè„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËß£Á†ÅÂô®‰∏≠ÁöÑÂ§öÂ∞∫Â∫¶Á®ÄÁñèËûçÂêàÊ®°ÂùóÊòØÂÖ≥ÈîÆËÆæËÆ°‰πã‰∏Ä„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåËØ•Ê®°ÂùóÈ¶ñÂÖàÂØπ‰∏çÂêåÂ∞∫Â∫¶ÁöÑÁâπÂæÅÂõæËøõË°åÁ®ÄÁñèÈááÊ†∑ÔºåÁÑ∂ÂêéÂ∞ÜÈááÊ†∑ÂêéÁöÑÁâπÂæÅËøõË°åËûçÂêà„ÄÇÁ®ÄÁñèÈááÊ†∑ÁöÑÊØî‰æãÊòØ‰∏Ä‰∏™ÈáçË¶ÅÁöÑË∂ÖÂèÇÊï∞ÔºåÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰Ωì‰ªªÂä°ËøõË°åË∞ÉÊï¥„ÄÇÊ≠§Â§ñÔºåÊçüÂ§±ÂáΩÊï∞‰πüÂØπÊ®°ÂûãÁöÑÊÄßËÉΩÊúâÈáçË¶ÅÂΩ±ÂìçÔºåËÆ∫ÊñáÂèØËÉΩÈááÁî®‰∫ÜÂ§öÁßçÊçüÂ§±ÂáΩÊï∞ÁöÑÁªÑÂêàÔºå‰æãÂ¶ÇÂÖâÂ∫¶‰∏ÄËá¥ÊÄßÊçüÂ§±ÂíåÊ∑±Â∫¶Âπ≥ÊªëÊçüÂ§±„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

RTS-MonoÂú®KITTIÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂú®‰ΩéÂàÜËæ®Áéá‰∏ãÔºåAbs RelÂíåSq RelÂàÜÂà´ÊèêÈ´ò‰∫Ü5.6%Âíå9.8%„ÄÇÂú®È´òÂàÜËæ®Áéá‰∏ãÔºåSq RelÂíåRMSEÂàÜÂà´ÊèêÈ´ò‰∫Ü6.1%Âíå1.9%„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåRTS-MonoÂú®Nvidia Jetson Orin‰∏äÂÆûÁé∞‰∫Ü49 FPSÁöÑÂÆûÊó∂Êé®ÁêÜÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÂèØË°åÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

RTS-MonoÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨Ëá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÂÆÉÂèØ‰ª•‰∏∫ËΩ¶ËæÜÊèê‰æõÂáÜÁ°ÆÁöÑÊ∑±Â∫¶‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òËΩ¶ËæÜÁöÑÊÑüÁü•ËÉΩÂäõÂíåÂÆâÂÖ®ÊÄß„ÄÇÂú®Êú∫Âô®‰∫∫ÂØºËà™‰∏≠ÔºåÂÆÉÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫ÁêÜËß£Âë®Âõ¥ÁéØÂ¢ÉÔºå‰ªéËÄåÂÆûÁé∞Ëá™‰∏ªÂØºËà™„ÄÇÂú®Â¢ûÂº∫Áé∞ÂÆû‰∏≠ÔºåÂÆÉÂèØ‰ª•Â∞ÜËôöÊãüÁâ©‰Ωì‰∏éÁúüÂÆûÂú∫ÊôØËøõË°åËûçÂêàÔºå‰ªéËÄåÊèê‰æõÊõ¥Âä†Ê≤âÊµ∏ÂºèÁöÑ‰ΩìÈ™å„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Depth information is crucial for autonomous driving and intelligent robot navigation. The simplicity and flexibility of self-supervised monocular depth estimation are conducive to its role in these fields. However, most existing monocular depth estimation models consume many computing resources. Although some methods have reduced the model's size and improved computing efficiency, the performance deteriorates, seriously hindering the real-world deployment of self-supervised monocular depth estimation models in the real world. To address this problem, we proposed a real-time self-supervised monocular depth estimation method and implemented it in the real world. It is called RTS-Mono, which is a lightweight and efficient encoder-decoder architecture. The encoder is based on Lite-Encoder, and the decoder is designed with a multi-scale sparse fusion framework to minimize redundancy, ensure performance, and improve inference speed. RTS-Mono achieved state-of-the-art (SoTA) performance in high and low resolutions with extremely low parameter counts (3 M) in experiments based on the KITTI dataset. Compared with lightweight methods, RTS-Mono improved Abs Rel and Sq Rel by 5.6% and 9.8% at low resolution and improved Sq Rel and RMSE by 6.1% and 1.9% at high resolution. In real-world deployment experiments, RTS-Mono has extremely high accuracy and can perform real-time inference on Nvidia Jetson Orin at a speed of 49 FPS. Source code is available at https://github.com/ZYCheng777/RTS-Mono.

