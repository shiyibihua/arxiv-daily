---
layout: default
title: RTS-Mono: A Real-Time Self-Supervised Monocular Depth Estimation Method for Real-World Deployment
---

# RTS-Mono: A Real-Time Self-Supervised Monocular Depth Estimation Method for Real-World Deployment

**arXiv**: [2511.14107v1](https://arxiv.org/abs/2511.14107) | [PDF](https://arxiv.org/pdf/2511.14107.pdf)

**ä½œè€…**: Zeyu Cheng, Tongfei Liu, Tao Lei, Xiang Hua, Yi Zhang, Chengkai Tang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRTS-Monoå®žæ—¶è‡ªç›‘ç£å•ç›®æ·±åº¦ä¼°è®¡æ–¹æ³•ï¼Œè§£å†³è®¡ç®—èµ„æºæ¶ˆè€—å¤§é—®é¢˜ï¼Œé€‚ç”¨äºŽè‡ªåŠ¨é©¾é©¶éƒ¨ç½²ã€‚**

**å…³é”®è¯**: `è‡ªç›‘ç£å­¦ä¹ ` `å•ç›®æ·±åº¦ä¼°è®¡` `å®žæ—¶è®¡ç®—` `è½»é‡æ¨¡åž‹` `è‡ªåŠ¨é©¾é©¶` `ç¼–ç å™¨-è§£ç å™¨æž¶æž„`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰å•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹è®¡ç®—èµ„æºæ¶ˆè€—å¤§ï¼Œæ€§èƒ½ä¸Žæ•ˆçŽ‡éš¾ä»¥å…¼é¡¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨è½»é‡ç¼–ç å™¨-è§£ç å™¨æž¶æž„ï¼Œå¤šå°ºåº¦ç¨€ç–èžåˆå‡å°‘å†—ä½™ï¼Œæå‡æŽ¨ç†é€Ÿåº¦ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨KITTIæ•°æ®é›†ä¸Šå‚æ•°ä»…3Mï¼Œç²¾åº¦æå‡ï¼ŒNvidia Jetson Orinä¸Šè¾¾49 FPSå®žæ—¶æŽ¨ç†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Depth information is crucial for autonomous driving and intelligent robot navigation. The simplicity and flexibility of self-supervised monocular depth estimation are conducive to its role in these fields. However, most existing monocular depth estimation models consume many computing resources. Although some methods have reduced the model's size and improved computing efficiency, the performance deteriorates, seriously hindering the real-world deployment of self-supervised monocular depth estimation models in the real world. To address this problem, we proposed a real-time self-supervised monocular depth estimation method and implemented it in the real world. It is called RTS-Mono, which is a lightweight and efficient encoder-decoder architecture. The encoder is based on Lite-Encoder, and the decoder is designed with a multi-scale sparse fusion framework to minimize redundancy, ensure performance, and improve inference speed. RTS-Mono achieved state-of-the-art (SoTA) performance in high and low resolutions with extremely low parameter counts (3 M) in experiments based on the KITTI dataset. Compared with lightweight methods, RTS-Mono improved Abs Rel and Sq Rel by 5.6% and 9.8% at low resolution and improved Sq Rel and RMSE by 6.1% and 1.9% at high resolution. In real-world deployment experiments, RTS-Mono has extremely high accuracy and can perform real-time inference on Nvidia Jetson Orin at a speed of 49 FPS. Source code is available at https://github.com/ZYCheng777/RTS-Mono.

