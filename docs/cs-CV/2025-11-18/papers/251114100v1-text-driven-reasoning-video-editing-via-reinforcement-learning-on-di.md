---
layout: default
title: Text-Driven Reasoning Video Editing via Reinforcement Learning on Digital Twin Representations
---

# Text-Driven Reasoning Video Editing via Reinforcement Learning on Digital Twin Representations

**arXiv**: [2511.14100v1](https://arxiv.org/abs/2511.14100) | [PDF](https://arxiv.org/pdf/2511.14100.pdf)

**ä½œè€…**: Yiqing Shen, Chenjia Li, Mathias Unberath

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRIVERæ¨¡åž‹ä»¥è§£å†³åŸºäºŽæ–‡æœ¬æŽ¨ç†çš„è§†é¢‘ç¼–è¾‘ä»»åŠ¡**

**å…³é”®è¯**: `æŽ¨ç†è§†é¢‘ç¼–è¾‘` `æ•°å­—å­ªç”Ÿè¡¨ç¤º` `å¼ºåŒ–å­¦ä¹ è®­ç»ƒ` `éšå¼æŸ¥è¯¢å¤„ç†` `å¤šè·³æŽ¨ç†` `æ‰©æ•£æ¨¡åž‹ç¼–è¾‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•éœ€æ˜¾å¼æè¿°ç¼–è¾‘ç›®æ ‡ï¼Œæ— æ³•å¤„ç†åŸºäºŽè¯­ä¹‰å±žæ€§æˆ–å¯¹è±¡å…³ç³»çš„éšå¼æŸ¥è¯¢
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ•°å­—å­ªç”Ÿè¡¨ç¤ºå’Œå¤§åž‹è¯­è¨€æ¨¡åž‹è¿›è¡Œå¤šè·³æŽ¨ç†ï¼ŒæŒ‡å¯¼æ‰©æ•£æ¨¡åž‹æ‰§è¡Œåƒç´ çº§ç¼–è¾‘
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨RVEBenchmarkå’Œä¸¤ä¸ªé¢å¤–åŸºå‡†ä¸Šè¡¨çŽ°æœ€ä½³ï¼Œè¶…è¶Šå…­ä¸ªåŸºçº¿æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-driven video editing enables users to modify video content only using text queries. While existing methods can modify video content if explicit descriptions of editing targets with precise spatial locations and temporal boundaries are provided, these requirements become impractical when users attempt to conceptualize edits through implicit queries referencing semantic properties or object relationships. We introduce reasoning video editing, a task where video editing models must interpret implicit queries through multi-hop reasoning to infer editing targets before executing modifications, and a first model attempting to solve this complex task, RIVER (Reasoning-based Implicit Video Editor). RIVER decouples reasoning from generation through digital twin representations of video content that preserve spatial relationships, temporal trajectories, and semantic attributes. A large language model then processes this representation jointly with the implicit query, performing multi-hop reasoning to determine modifications, then outputs structured instructions that guide a diffusion-based editor to execute pixel-level changes. RIVER training uses reinforcement learning with rewards that evaluate reasoning accuracy and generation quality. Finally, we introduce RVEBenchmark, a benchmark of 100 videos with 519 implicit queries spanning three levels and categories of reasoning complexity specifically for reasoning video editing. RIVER demonstrates best performance on the proposed RVEBenchmark and also achieves state-of-the-art performance on two additional video editing benchmarks (VegGIE and FiVE), where it surpasses six baseline methods.

