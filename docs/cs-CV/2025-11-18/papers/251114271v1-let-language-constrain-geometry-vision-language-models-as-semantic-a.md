---
layout: default
title: Let Language Constrain Geometry: Vision-Language Models as Semantic and Spatial Critics for 3D Generation
---

# Let Language Constrain Geometry: Vision-Language Models as Semantic and Spatial Critics for 3D Generation

**arXiv**: [2511.14271v1](https://arxiv.org/abs/2511.14271) | [PDF](https://arxiv.org/pdf/2511.14271.pdf)

**ä½œè€…**: Weimin Bai, Yubo Li, Weijian Luo, Zeqiang Lai, Yequan Wang, Wenzheng Chen, He Sun

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVLM3Dæ¡†æž¶ï¼Œåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡åž‹ä½œä¸ºè¯­ä¹‰å’Œç©ºé—´æ‰¹è¯„å™¨ä»¥æ”¹è¿›æ–‡æœ¬åˆ°3Dç”Ÿæˆ**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°3Dç”Ÿæˆ` `è§†è§‰è¯­è¨€æ¨¡åž‹` `è¯­ä¹‰å¯¹é½` `ç©ºé—´ç†è§£` `æ‰¹è¯„ä¿¡å·` `3Dç”Ÿæˆä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ–‡æœ¬åˆ°3Dç”Ÿæˆæ¨¡åž‹å­˜åœ¨è¯­ä¹‰å¯¹é½ç²—ç³™å’Œç©ºé—´ç†è§£ä¸è¶³çš„é—®é¢˜
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨VLMçš„åŒæŸ¥è¯¢æ‰¹è¯„ä¿¡å·è¯„ä¼°è¯­ä¹‰ä¿çœŸåº¦å’Œå‡ ä½•ä¸€è‡´æ€§
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä¼˜åŒ–å’Œå‰é¦ˆç®¡é“ä¸­æ˜¾è‘—æå‡æ€§èƒ½ï¼Œçº æ­£ç©ºé—´é”™è¯¯

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-to-3D generation has advanced rapidly, yet state-of-the-art models, encompassing both optimization-based and feed-forward architectures, still face two fundamental limitations. First, they struggle with coarse semantic alignment, often failing to capture fine-grained prompt details. Second, they lack robust 3D spatial understanding, leading to geometric inconsistencies and catastrophic failures in part assembly and spatial relationships. To address these challenges, we propose VLM3D, a general framework that repurposes large vision-language models (VLMs) as powerful, differentiable semantic and spatial critics. Our core contribution is a dual-query critic signal derived from the VLM's Yes or No log-odds, which assesses both semantic fidelity and geometric coherence. We demonstrate the generality of this guidance signal across two distinct paradigms: (1) As a reward objective for optimization-based pipelines, VLM3D significantly outperforms existing methods on standard benchmarks. (2) As a test-time guidance module for feed-forward pipelines, it actively steers the iterative sampling process of SOTA native 3D models to correct severe spatial errors. VLM3D establishes a principled and generalizable path to inject the VLM's rich, language-grounded understanding of both semantics and space into diverse 3D generative pipelines.

