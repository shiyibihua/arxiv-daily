---
layout: default
title: Iterative Diffusion-Refined Neural Attenuation Fields for Multi-Source Stationary CT Reconstruction: NAF Meets Diffusion Model
---

# Iterative Diffusion-Refined Neural Attenuation Fields for Multi-Source Stationary CT Reconstruction: NAF Meets Diffusion Model

**arXiv**: [2511.14310v1](https://arxiv.org/abs/2511.14310) | [PDF](https://arxiv.org/pdf/2511.14310.pdf)

**ä½œè€…**: Jiancheng Fang, Shaoyu Wang, Junlin Wang, Weiwen Wu, Yikun Zhang, Qiegen Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDiff-NAFä»¥è§£å†³è¶…ç¨€ç–è§†å›¾å¤šæºé™æ€CTé‡å»ºé—®é¢˜**

**å…³é”®è¯**: `CTé‡å»º` `ç¥žç»è¡°å‡åœº` `æ‰©æ•£æ¨¡åž‹` `è¶…ç¨€ç–è§†å›¾` `å¤šæºCT` `è¿­ä»£ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è¶…ç¨€ç–è§†å›¾é‡‡æ ·å¯¼è‡´CTé‡å»ºè´¨é‡ä¸¥é‡ä¸‹é™
2. ç»“åˆç¥žç»è¡°å‡åœºä¸ŽåŒåˆ†æ”¯æ¡ä»¶æ‰©æ•£æ¨¡åž‹è¿›è¡Œè¿­ä»£ä¼˜åŒ–
3. å®žéªŒæ˜¾ç¤ºåœ¨è¶…ç¨€ç–è§†å›¾æ¡ä»¶ä¸‹æ€§èƒ½æœ€ä½³

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-source stationary computed tomography (CT) has recently attracted attention for its ability to achieve rapid image reconstruction, making it suitable for time-sensitive clinical and industrial applications. However, practical systems are often constrained by ultra-sparse-view sampling, which significantly degrades reconstruction quality. Traditional methods struggle under ultra-sparse-view settings, where interpolation becomes inaccurate and the resulting reconstructions are unsatisfactory. To address this challenge, this study proposes Diffusion-Refined Neural Attenuation Fields (Diff-NAF), an iterative framework tailored for multi-source stationary CT under ultra-sparse-view conditions. Diff-NAF combines a Neural Attenuation Field representation with a dual-branch conditional diffusion model. The process begins by training an initial NAF using ultra-sparse-view projections. New projections are then generated through an Angle-Prior Guided Projection Synthesis strategy that exploits inter view priors, and are subsequently refined by a Diffusion-driven Reuse Projection Refinement Module. The refined projections are incorporated as pseudo-labels into the training set for the next iteration. Through iterative refinement, Diff-NAF progressively enhances projection completeness and reconstruction fidelity under ultra-sparse-view conditions, ultimately yielding high-quality CT reconstructions. Experimental results on multiple simulated 3D CT volumes and real projection data demonstrate that Diff-NAF achieves the best performance under ultra-sparse-view conditions.

