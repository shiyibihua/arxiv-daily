---
layout: default
title: Diffusion As Self-Distillation: End-to-End Latent Diffusion In One Model
---

# Diffusion As Self-Distillation: End-to-End Latent Diffusion In One Model

**arXiv**: [2511.14716v1](https://arxiv.org/abs/2511.14716) | [PDF](https://arxiv.org/pdf/2511.14716.pdf)

**ä½œè€…**: Xiyuan Wang, Muhan Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ‰©æ•£è‡ªè’¸é¦æ¡†æž¶ä»¥è§£å†³æ½œåœ¨æ‰©æ•£æ¨¡åž‹æ¨¡å—åŒ–è®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜**

**å…³é”®è¯**: `æ½œåœ¨æ‰©æ•£æ¨¡åž‹` `è‡ªè’¸é¦` `ç«¯åˆ°ç«¯è®­ç»ƒ` `å›¾åƒç”Ÿæˆ` `è®­ç»ƒç¨³å®šæ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ‡å‡†æ½œåœ¨æ‰©æ•£æ¨¡åž‹é‡‡ç”¨ç¼–ç å™¨ã€è§£ç å™¨å’Œæ‰©æ•£ç½‘ç»œåˆ†ç¦»æž¶æž„ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆçŽ‡ä½Žå’Œæ€§èƒ½ä¸ä½³
2. é€šè¿‡ç±»æ¯”è‡ªè’¸é¦æ–¹æ³•ï¼Œæå‡ºDSDæ¡†æž¶ä¿®æ”¹è®­ç»ƒç›®æ ‡ï¼Œç¨³å®šæ½œåœ¨ç©ºé—´å­¦ä¹ 
3. åœ¨ImageNet 256Ã—256æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œä»¥è¾ƒå°‘å‚æ•°å’Œè®­ç»ƒè½®æ¬¡å®žçŽ°é«˜FIDåˆ†æ•°

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Standard Latent Diffusion Models rely on a complex, three-part architecture consisting of a separate encoder, decoder, and diffusion network, which are trained in multiple stages. This modular design is computationally inefficient, leads to suboptimal performance, and prevents the unification of diffusion with the single-network architectures common in vision foundation models. Our goal is to unify these three components into a single, end-to-end trainable network. We first demonstrate that a naive joint training approach fails catastrophically due to ``latent collapse'', where the diffusion training objective interferes with the network's ability to learn a good latent representation. We identify the root causes of this instability by drawing a novel analogy between diffusion and self-distillation based unsupervised learning method. Based on this insight, we propose Diffusion as Self-Distillation (DSD), a new framework with key modifications to the training objective that stabilize the latent space. This approach enables, for the first time, the stable end-to-end training of a single network that simultaneously learns to encode, decode, and perform diffusion. DSD achieves outstanding performance on the ImageNet $256\times 256$ conditional generation task: FID=13.44/6.38/4.25 with only 42M/118M/205M parameters and 50 training epochs on ImageNet, without using classifier-free-guidance.

