---
layout: default
title: Diffusion As Self-Distillation: End-to-End Latent Diffusion In One Model
---

# Diffusion As Self-Distillation: End-to-End Latent Diffusion In One Model

**arXiv**: [2511.14716v1](https://arxiv.org/abs/2511.14716) | [PDF](https://arxiv.org/pdf/2511.14716.pdf)

**ä½œè€…**: Xiyuan Wang, Muhan Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-18

**å¤‡æ³¨**: Tech Report. 10 pages

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDSDæ¡†æž¶ï¼Œå®žçŽ°ç«¯åˆ°ç«¯æ½œåœ¨æ‰©æ•£æ¨¡åž‹å•ç½‘ç»œè®­ç»ƒï¼Œè§£å†³å¤šé˜¶æ®µè®­ç»ƒä½Žæ•ˆé—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹` `è‡ªè’¸é¦` `ç«¯åˆ°ç«¯è®­ç»ƒ` `å›¾åƒç”Ÿæˆ` `æ½œåœ¨ç©ºé—´` `å•ç½‘ç»œæž¶æž„` `ImageNet`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ½œåœ¨æ‰©æ•£æ¨¡åž‹ç»“æž„å¤æ‚ï¼ŒåŒ…å«ç¼–ç å™¨ã€è§£ç å™¨å’Œæ‰©æ•£ç½‘ç»œï¼Œè®­ç»ƒè¿‡ç¨‹åˆ†é˜¶æ®µè¿›è¡Œï¼Œæ•ˆçŽ‡è¾ƒä½Žã€‚
2. è®ºæ–‡æå‡ºDiffusion as Self-Distillation (DSD)æ¡†æž¶ï¼Œé€šè¿‡æ”¹è¿›è®­ç»ƒç›®æ ‡ï¼Œç¨³å®šæ½œåœ¨ç©ºé—´ï¼Œå®žçŽ°ç«¯åˆ°ç«¯å•ç½‘ç»œè®­ç»ƒã€‚
3. DSDåœ¨ImageNet 256x256å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„FIDåˆ†æ•°ï¼Œä¸”å‚æ•°é‡è¾ƒå°ï¼Œæ— éœ€æ— åˆ†ç±»å™¨æŒ‡å¯¼ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ ‡å‡†çš„æ½œåœ¨æ‰©æ•£æ¨¡åž‹ä¾èµ–äºŽä¸€ä¸ªå¤æ‚çš„ä¸‰éƒ¨åˆ†æž¶æž„ï¼ŒåŒ…æ‹¬ç‹¬ç«‹çš„ç¼–ç å™¨ã€è§£ç å™¨å’Œæ‰©æ•£ç½‘ç»œï¼Œè¿™äº›ç½‘ç»œéœ€è¦ç»è¿‡å¤šä¸ªé˜¶æ®µçš„è®­ç»ƒã€‚è¿™ç§æ¨¡å—åŒ–è®¾è®¡åœ¨è®¡ç®—ä¸Šæ•ˆçŽ‡ä½Žä¸‹ï¼Œå¯¼è‡´æ¬¡ä¼˜çš„æ€§èƒ½ï¼Œå¹¶ä¸”é˜»ç¢äº†æ‰©æ•£æ¨¡åž‹ä¸Žè§†è§‰åŸºç¡€æ¨¡åž‹ä¸­å¸¸è§çš„å•ç½‘ç»œæž¶æž„çš„ç»Ÿä¸€ã€‚æœ¬æ–‡æ—¨åœ¨å°†è¿™ä¸‰ä¸ªç»„ä»¶ç»Ÿä¸€åˆ°ä¸€ä¸ªå•ä¸€çš„ã€ç«¯åˆ°ç«¯å¯è®­ç»ƒçš„ç½‘ç»œä¸­ã€‚ç ”ç©¶è¡¨æ˜Žï¼Œç”±äºŽâ€œæ½œåœ¨å´©æºƒâ€ï¼Œæœ´ç´ çš„è”åˆè®­ç»ƒæ–¹æ³•ä¼šå½»åº•å¤±è´¥ï¼Œå…¶ä¸­æ‰©æ•£è®­ç»ƒç›®æ ‡ä¼šå¹²æ‰°ç½‘ç»œå­¦ä¹ è‰¯å¥½æ½œåœ¨è¡¨ç¤ºçš„èƒ½åŠ›ã€‚é€šè¿‡å°†æ‰©æ•£ä¸ŽåŸºäºŽè‡ªè’¸é¦çš„æ— ç›‘ç£å­¦ä¹ æ–¹æ³•è¿›è¡Œç±»æ¯”ï¼Œæ­ç¤ºäº†è¿™ç§ä¸ç¨³å®šæ€§çš„æ ¹æœ¬åŽŸå› ã€‚åŸºäºŽæ­¤ï¼Œæå‡ºäº†æ‰©æ•£å³è‡ªè’¸é¦ï¼ˆDSDï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„æ¡†æž¶ï¼Œé€šè¿‡å¯¹è®­ç»ƒç›®æ ‡çš„å…³é”®ä¿®æ”¹æ¥ç¨³å®šæ½œåœ¨ç©ºé—´ã€‚è¿™ç§æ–¹æ³•é¦–æ¬¡å®žçŽ°äº†å•ä¸ªç½‘ç»œçš„ç¨³å®šç«¯åˆ°ç«¯è®­ç»ƒï¼Œè¯¥ç½‘ç»œåŒæ—¶å­¦ä¹ ç¼–ç ã€è§£ç å’Œæ‰§è¡Œæ‰©æ•£ã€‚DSDåœ¨ImageNet $256	imes 256$ æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†å‡ºè‰²çš„æ€§èƒ½ï¼šä»…ä½¿ç”¨42M/118M/205Må‚æ•°ï¼Œåœ¨ImageNetä¸Šè®­ç»ƒ50ä¸ªepochï¼ŒFIDåˆ†åˆ«ä¸º13.44/6.38/4.25ï¼Œä¸”æœªä½¿ç”¨æ— åˆ†ç±»å™¨æŒ‡å¯¼ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰æ½œåœ¨æ‰©æ•£æ¨¡åž‹é€šå¸¸é‡‡ç”¨å¤šæ¨¡å—ã€å¤šé˜¶æ®µçš„è®­ç»ƒæ–¹å¼ï¼Œè®¡ç®—æ•ˆçŽ‡ä½Žï¼Œæ€§èƒ½å­˜åœ¨ä¼˜åŒ–ç©ºé—´ï¼Œä¸”éš¾ä»¥ä¸Žè§†è§‰åŸºç¡€æ¨¡åž‹çš„å•ç½‘ç»œæž¶æž„ç»Ÿä¸€ã€‚ç›´æŽ¥è¿›è¡Œç«¯åˆ°ç«¯è”åˆè®­ç»ƒä¼šå¯¼è‡´â€œæ½œåœ¨å´©æºƒâ€é—®é¢˜ï¼Œå³æ‰©æ•£è®­ç»ƒç›®æ ‡ä¼šå¹²æ‰°ç½‘ç»œå­¦ä¹ æœ‰æ•ˆçš„æ½œåœ¨è¡¨ç¤ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ‰©æ•£è¿‡ç¨‹ç±»æ¯”ä¸ºè‡ªè’¸é¦å­¦ä¹ ï¼Œé€šè¿‡åˆ†æžè‡ªè’¸é¦å­¦ä¹ çš„åŽŸç†ï¼Œæ‰¾åˆ°å¯¼è‡´æ½œåœ¨å´©æºƒçš„åŽŸå› ï¼Œå¹¶å¯¹è®­ç»ƒç›®æ ‡è¿›è¡Œä¿®æ”¹ï¼Œä»Žè€Œç¨³å®šæ½œåœ¨ç©ºé—´ï¼Œå®žçŽ°ç«¯åˆ°ç«¯çš„å•ç½‘ç»œè®­ç»ƒã€‚è¿™ç§ç±»æ¯”ä½¿å¾—èƒ½å¤Ÿå€Ÿé‰´è‡ªè’¸é¦å­¦ä¹ ä¸­çš„æŠ€å·§æ¥è§£å†³æ‰©æ•£æ¨¡åž‹è®­ç»ƒä¸­çš„é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šDSDæ¡†æž¶çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªå•ç½‘ç»œç»“æž„ï¼Œè¯¥ç½‘ç»œåŒæ—¶æ‰¿æ‹…ç¼–ç ã€è§£ç å’Œæ‰©æ•£çš„ä»»åŠ¡ã€‚è®­ç»ƒè¿‡ç¨‹ä¸å†æ˜¯åˆ†é˜¶æ®µçš„ï¼Œè€Œæ˜¯ç«¯åˆ°ç«¯çš„ã€‚å…³é”®åœ¨äºŽä¿®æ”¹åŽçš„è®­ç»ƒç›®æ ‡ï¼Œè¯¥ç›®æ ‡èƒ½å¤Ÿé¿å…æ½œåœ¨å´©æºƒï¼Œå¹¶ä¿ƒè¿›ç½‘ç»œå­¦ä¹ æœ‰æ•ˆçš„æ½œåœ¨è¡¨ç¤ºã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼šè¾“å…¥å›¾åƒç»è¿‡ç½‘ç»œç¼–ç ä¸ºæ½œåœ¨è¡¨ç¤ºï¼Œç„¶åŽè¿›è¡Œæ‰©æ•£è¿‡ç¨‹ï¼Œæœ€åŽé€šè¿‡ç½‘ç»œè§£ç é‡æž„å›¾åƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå‘çŽ°äº†æ‰©æ•£è¿‡ç¨‹ä¸Žè‡ªè’¸é¦å­¦ä¹ ä¹‹é—´çš„è”ç³»ï¼Œå¹¶åŸºäºŽæ­¤æå‡ºäº†æ–°çš„è®­ç»ƒç›®æ ‡ã€‚è¯¥è®­ç»ƒç›®æ ‡é€šè¿‡ç¨³å®šæ½œåœ¨ç©ºé—´ï¼Œè§£å†³äº†ç«¯åˆ°ç«¯è®­ç»ƒä¸­çš„æ½œåœ¨å´©æºƒé—®é¢˜ï¼Œä½¿å¾—å•ç½‘ç»œç»“æž„çš„æ½œåœ¨æ‰©æ•£æ¨¡åž‹æˆä¸ºå¯èƒ½ã€‚ä¸Žä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒDSDæ— éœ€å•ç‹¬è®­ç»ƒç¼–ç å™¨å’Œè§£ç å™¨ï¼Œå¤§å¤§ç®€åŒ–äº†è®­ç»ƒæµç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šDSDçš„å…³é”®è®¾è®¡åœ¨äºŽä¿®æ”¹åŽçš„è®­ç»ƒç›®æ ‡å‡½æ•°ã€‚å…·ä½“çš„ä¿®æ”¹ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ŒåŒ…æ‹¬å¦‚ä½•å€Ÿé‰´è‡ªè’¸é¦å­¦ä¹ ä¸­çš„æŠ€å·§æ¥ç¨³å®šæ½œåœ¨ç©ºé—´ï¼Œä»¥åŠå¦‚ä½•å¹³è¡¡ç¼–ç ã€è§£ç å’Œæ‰©æ•£ä¸‰ä¸ªä»»åŠ¡ä¹‹é—´çš„å…³ç³»ã€‚æ­¤å¤–ï¼Œç½‘ç»œç»“æž„çš„å…·ä½“è®¾è®¡ä¹Ÿå¯¹æ€§èƒ½æœ‰å½±å“ï¼Œè®ºæ–‡ä¸­å¯èƒ½é‡‡ç”¨äº†ç‰¹å®šçš„å·ç§¯ç¥žç»ç½‘ç»œç»“æž„æˆ–Transformerç»“æž„ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

DSDåœ¨ImageNet 256x256æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—æˆæžœã€‚ä»…ä½¿ç”¨42Må‚æ•°çš„æ¨¡åž‹ï¼ŒFIDè¾¾åˆ°13.44ï¼›ä½¿ç”¨118Må‚æ•°çš„æ¨¡åž‹ï¼ŒFIDè¾¾åˆ°6.38ï¼›ä½¿ç”¨205Må‚æ•°çš„æ¨¡åž‹ï¼ŒFIDè¾¾åˆ°4.25ã€‚è¿™äº›ç»“æžœæ˜¯åœ¨ä»…è®­ç»ƒ50ä¸ªepochä¸”æœªä½¿ç”¨æ— åˆ†ç±»å™¨æŒ‡å¯¼çš„æƒ…å†µä¸‹èŽ·å¾—çš„ï¼Œè¡¨æ˜ŽDSDå…·æœ‰å¾ˆé«˜çš„è®­ç»ƒæ•ˆçŽ‡å’Œç”Ÿæˆè´¨é‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

DSDæ¡†æž¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºŽå›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘ã€è§†é¢‘ç”Ÿæˆç­‰é¢†åŸŸã€‚ç”±äºŽå…¶å•ç½‘ç»œç»“æž„å’Œç«¯åˆ°ç«¯è®­ç»ƒæ–¹å¼ï¼Œæ›´æ˜“äºŽéƒ¨ç½²å’Œåº”ç”¨ã€‚æœªæ¥ï¼ŒDSDæœ‰æœ›æˆä¸ºè§†è§‰åŸºç¡€æ¨¡åž‹çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼ŒæŽ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨å›¾åƒå’Œè§†é¢‘é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Standard Latent Diffusion Models rely on a complex, three-part architecture consisting of a separate encoder, decoder, and diffusion network, which are trained in multiple stages. This modular design is computationally inefficient, leads to suboptimal performance, and prevents the unification of diffusion with the single-network architectures common in vision foundation models. Our goal is to unify these three components into a single, end-to-end trainable network. We first demonstrate that a naive joint training approach fails catastrophically due to ``latent collapse'', where the diffusion training objective interferes with the network's ability to learn a good latent representation. We identify the root causes of this instability by drawing a novel analogy between diffusion and self-distillation based unsupervised learning method. Based on this insight, we propose Diffusion as Self-Distillation (DSD), a new framework with key modifications to the training objective that stabilize the latent space. This approach enables, for the first time, the stable end-to-end training of a single network that simultaneously learns to encode, decode, and perform diffusion. DSD achieves outstanding performance on the ImageNet $256\times 256$ conditional generation task: FID=13.44/6.38/4.25 with only 42M/118M/205M parameters and 50 training epochs on ImageNet, without using classifier-free-guidance.

