---
layout: default
title: A Generative Data Framework with Authentic Supervision for Underwater Image Restoration and Enhancement
---

# A Generative Data Framework with Authentic Supervision for Underwater Image Restoration and Enhancement

**arXiv**: [2511.14521v1](https://arxiv.org/abs/2511.14521) | [PDF](https://arxiv.org/pdf/2511.14521.pdf)

**ä½œè€…**: Yufeng Tian, Yifan Chen, Zhe Sun, Libang Chen, Mingyu Dou, Jijun Lu, Ye Zheng, Xuelong Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç”Ÿæˆå¼æ•°æ®æ¡†æž¶ï¼Œåˆ©ç”¨ç©ºä¸­å›¾åƒæž„å»ºåˆæˆæ•°æ®é›†ä»¥è§£å†³æ°´ä¸‹å›¾åƒæ¢å¤ä¸Žå¢žå¼ºé—®é¢˜**

**å…³é”®è¯**: `æ°´ä¸‹å›¾åƒæ¢å¤` `å›¾åƒå¢žå¼º` `ç”Ÿæˆå¼æ•°æ®æ¡†æž¶` `éžé…å¯¹å›¾åƒç¿»è¯‘` `åˆæˆæ•°æ®é›†` `é¢œè‰²å¤±çœŸæ ¡æ­£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ°´ä¸‹å›¾åƒæ¢å¤å—é™äºŽé«˜è´¨é‡é…å¯¹æ•°æ®ç¨€ç¼ºï¼ŒçŽ°æœ‰åŸºå‡†ç¼ºä¹çœŸå®žç›‘ç£ä¿¡å·
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽéžé…å¯¹å›¾åƒç¿»è¯‘ï¼Œå°†ç©ºä¸­å›¾åƒè½¬æ¢ä¸ºæ°´ä¸‹é€€åŒ–ç‰ˆæœ¬ï¼Œæä¾›ç²¾ç¡®çœŸå€¼æ ‡ç­¾
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨6ç§ç½‘ç»œæž¶æž„å’Œ3ä¸ªæµ‹è¯•é›†ä¸Šï¼Œåˆæˆæ•°æ®è®­ç»ƒæ¨¡åž‹åœ¨é¢œè‰²æ¢å¤å’Œæ³›åŒ–æ€§èƒ½ä¸Šè¡¨çŽ°ä¼˜å¼‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Underwater image restoration and enhancement are crucial for correcting color distortion and restoring image details, thereby establishing a fundamental basis for subsequent underwater visual tasks. However, current deep learning methodologies in this area are frequently constrained by the scarcity of high-quality paired datasets. Since it is difficult to obtain pristine reference labels in underwater scenes, existing benchmarks often rely on manually selected results from enhancement algorithms, providing debatable reference images that lack globally consistent color and authentic supervision. This limits the model's capabilities in color restoration, image enhancement, and generalization. To overcome this limitation, we propose using in-air natural images as unambiguous reference targets and translating them into underwater-degraded versions, thereby constructing synthetic datasets that provide authentic supervision signals for model learning. Specifically, we establish a generative data framework based on unpaired image-to-image translation, producing a large-scale dataset that covers 6 representative underwater degradation types. The framework constructs synthetic datasets with precise ground-truth labels, which facilitate the learning of an accurate mapping from degraded underwater images to their pristine scene appearances. Extensive quantitative and qualitative experiments across 6 representative network architectures and 3 independent test sets show that models trained on our synthetic data achieve comparable or superior color restoration and generalization performance to those trained on existing benchmarks. This research provides a reliable and scalable data-driven solution for underwater image restoration and enhancement. The generated dataset is publicly available at: https://github.com/yftian2025/SynUIEDatasets.git.

