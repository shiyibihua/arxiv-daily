---
layout: default
title: FashionMAC: Deformation-Free Fashion Image Generation with Fine-Grained Model Appearance Customization
---

# FashionMAC: Deformation-Free Fashion Image Generation with Fine-Grained Model Appearance Customization

**arXiv**: [2511.14031v1](https://arxiv.org/abs/2511.14031) | [PDF](https://arxiv.org/pdf/2511.14031.pdf)

**ä½œè€…**: Rong Zhang, Jinxiao Li, Jingnan Wang, Zhiwen Zuo, Jianfeng Dong, Wei Li, Chi Wang, Weiwei Xu, Xun Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFashionMACæ¡†æž¶ä»¥è§£å†³æ—¶å°šå›¾åƒç”Ÿæˆä¸­çš„æœè£…å˜å½¢å’Œç»†ç²’åº¦æŽ§åˆ¶é—®é¢˜**

**å…³é”®è¯**: `æ—¶å°šå›¾åƒç”Ÿæˆ` `æ‰©æ•£æ¨¡åž‹` `æ— å˜å½¢ç”Ÿæˆ` `ç»†ç²’åº¦æŽ§åˆ¶` `æ³¨æ„åŠ›æœºåˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•éœ€æœè£…å˜å½¢ï¼Œå¯¼è‡´çº¹ç†å¤±çœŸï¼Œä¸”ç¼ºä¹ç»†ç²’åº¦å¤–è§‚æŽ§åˆ¶æœºåˆ¶
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ— å˜å½¢æ¡†æž¶ç›´æŽ¥å¤–æŽ¨æœè£…ï¼Œå¹¶å¼•å…¥RADAæœºåˆ¶å’Œé“¾å¼æŽ©ç æ³¨å…¥ç­–ç•¥
3. å®žéªŒæˆ–æ•ˆæžœï¼šå¹¿æ³›å®žéªŒéªŒè¯ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œæå‡è§†è§‰ä¿çœŸåº¦å’Œå¯æŽ§æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Garment-centric fashion image generation aims to synthesize realistic and controllable human models dressing a given garment, which has attracted growing interest due to its practical applications in e-commerce. The key challenges of the task lie in two aspects: (1) faithfully preserving the garment details, and (2) gaining fine-grained controllability over the model's appearance. Existing methods typically require performing garment deformation in the generation process, which often leads to garment texture distortions. Also, they fail to control the fine-grained attributes of the generated models, due to the lack of specifically designed mechanisms. To address these issues, we propose FashionMAC, a novel diffusion-based deformation-free framework that achieves high-quality and controllable fashion showcase image generation. The core idea of our framework is to eliminate the need for performing garment deformation and directly outpaint the garment segmented from a dressed person, which enables faithful preservation of the intricate garment details. Moreover, we propose a novel region-adaptive decoupled attention (RADA) mechanism along with a chained mask injection strategy to achieve fine-grained appearance controllability over the synthesized human models. Specifically, RADA adaptively predicts the generated regions for each fine-grained text attribute and enforces the text attribute to focus on the predicted regions by a chained mask injection strategy, significantly enhancing the visual fidelity and the controllability. Extensive experiments validate the superior performance of our framework compared to existing state-of-the-art methods.

