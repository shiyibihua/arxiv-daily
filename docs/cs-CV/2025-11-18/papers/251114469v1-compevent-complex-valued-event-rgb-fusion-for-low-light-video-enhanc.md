---
layout: default
title: CompEvent: Complex-valued Event-RGB Fusion for Low-light Video Enhancement and Deblurring
---

# CompEvent: Complex-valued Event-RGB Fusion for Low-light Video Enhancement and Deblurring

**arXiv**: [2511.14469v1](https://arxiv.org/abs/2511.14469) | [PDF](https://arxiv.org/pdf/2511.14469.pdf)

**ä½œè€…**: Mingchen Zhong, Xin Lu, Dong Li, Senyan Xu, Ruixuan Jiang, Xueyang Fu, Baocai Yin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCompEventæ¡†æž¶ï¼Œé€šè¿‡å¤å€¼ç¥žç»ç½‘ç»œèžåˆäº‹ä»¶ä¸ŽRGBæ•°æ®ï¼Œè§£å†³ä½Žå…‰è§†é¢‘åŽ»æ¨¡ç³Šé—®é¢˜ã€‚**

**å…³é”®è¯**: `ä½Žå…‰è§†é¢‘å¢žå¼º` `äº‹ä»¶ç›¸æœºèžåˆ` `å¤å€¼ç¥žç»ç½‘ç»œ` `è§†é¢‘åŽ»æ¨¡ç³Š` `æ—¶ç©ºèžåˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä½Žå…‰è§†é¢‘ä¸­å…‰ç…§ä¸è¶³å’Œè¿åŠ¨æ¨¡ç³Šå¯¼è‡´åŽ»æ¨¡ç³Šå›°éš¾ï¼Œå½±å“å¤œé—´ç›‘æŽ§å’Œè‡ªåŠ¨é©¾é©¶åº”ç”¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å¤å€¼æ—¶åºå¯¹é½GRUå’Œç©ºé—´-é¢‘çŽ‡å­¦ä¹ æ¨¡å—ï¼Œå®žçŽ°äº‹ä»¶ä¸ŽRGBæ•°æ®çš„å…¨æµç¨‹èžåˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¹¿æ³›å®žéªŒä¸­ï¼ŒCompEventä¼˜äºŽçŽ°æœ‰å…ˆè¿›æ–¹æ³•ï¼Œä»£ç å·²å¼€æºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Low-light video deblurring poses significant challenges in applications like nighttime surveillance and autonomous driving due to dim lighting and long exposures. While event cameras offer potential solutions with superior low-light sensitivity and high temporal resolution, existing fusion methods typically employ staged strategies, limiting their effectiveness against combined low-light and motion blur degradations. To overcome this, we propose CompEvent, a complex neural network framework enabling holistic full-process fusion of event data and RGB frames for enhanced joint restoration. CompEvent features two core components: 1) Complex Temporal Alignment GRU, which utilizes complex-valued convolutions and processes video and event streams iteratively via GRU to achieve temporal alignment and continuous fusion; and 2) Complex Space-Frequency Learning module, which performs unified complex-valued signal processing in both spatial and frequency domains, facilitating deep fusion through spatial structures and system-level characteristics. By leveraging the holistic representation capability of complex-valued neural networks, CompEvent achieves full-process spatiotemporal fusion, maximizes complementary learning between modalities, and significantly strengthens low-light video deblurring capability. Extensive experiments demonstrate that CompEvent outperforms SOTA methods in addressing this challenging task. The code is available at https://github.com/YuXie1/CompEvent.

