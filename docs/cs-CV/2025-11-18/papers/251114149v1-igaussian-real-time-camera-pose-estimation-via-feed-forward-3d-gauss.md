---
layout: default
title: iGaussian: Real-Time Camera Pose Estimation via Feed-Forward 3D Gaussian Splatting Inversion
---

# iGaussian: Real-Time Camera Pose Estimation via Feed-Forward 3D Gaussian Splatting Inversion

**arXiv**: [2511.14149v1](https://arxiv.org/abs/2511.14149) | [PDF](https://arxiv.org/pdf/2511.14149.pdf)

**ä½œè€…**: Hao Wang, Linqing Zhao, Xiuwei Xu, Jiwen Lu, Haibin Yan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºiGaussiané€šè¿‡å‰é¦ˆ3Dé«˜æ–¯åæ¼”å®žçŽ°å®žæ—¶ç›¸æœºä½å§¿ä¼°è®¡**

**å…³é”®è¯**: `ç›¸æœºä½å§¿ä¼°è®¡` `3Dé«˜æ–¯åæ¼”` `å‰é¦ˆæ¡†æž¶` `å®žæ—¶SLAM` `ç‰¹å¾åŒ¹é…` `å¤šæ¨¡åž‹èžåˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–è¿­ä»£æ¸²æŸ“æ¯”è¾ƒå¾ªçŽ¯ï¼Œè®¡ç®—å¼€é”€å¤§ï¼Œéš¾ä»¥å®žæ—¶åº”ç”¨
2. é‡‡ç”¨ä¸¤é˜¶æ®µå‰é¦ˆæ¡†æž¶ï¼Œå…ˆç²—å›žå½’ä½å§¿ï¼Œå†é€šè¿‡ç‰¹å¾åŒ¹é…å’Œå¤šæ¨¡åž‹èžåˆç²¾ç‚¼
3. å®žéªŒæ˜¾ç¤ºæ˜¾è‘—é™ä½Žæ—‹è½¬è¯¯å·®è‡³0.2Â°ï¼Œé€Ÿåº¦æå‡10å€ï¼Œè¾¾2.87 FPS

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent trends in SLAM and visual navigation have embraced 3D Gaussians as the preferred scene representation, highlighting the importance of estimating camera poses from a single image using a pre-built Gaussian model. However, existing approaches typically rely on an iterative \textit{render-compare-refine} loop, where candidate views are first rendered using NeRF or Gaussian Splatting, then compared against the target image, and finally, discrepancies are used to update the pose. This multi-round process incurs significant computational overhead, hindering real-time performance in robotics. In this paper, we propose iGaussian, a two-stage feed-forward framework that achieves real-time camera pose estimation through direct 3D Gaussian inversion. Our method first regresses a coarse 6DoF pose using a Gaussian Scene Prior-based Pose Regression Network with spatial uniform sampling and guided attention mechanisms, then refines it through feature matching and multi-model fusion. The key contribution lies in our cross-correlation module that aligns image embeddings with 3D Gaussian attributes without differentiable rendering, coupled with a Weighted Multiview Predictor that fuses features from Multiple strategically sampled viewpoints. Experimental results on the NeRF Synthetic, Mip-NeRF 360, and T\&T+DB datasets demonstrate a significant performance improvement over previous methods, reducing median rotation errors to 0.2Â° while achieving 2.87 FPS tracking on mobile robots, which is an impressive 10 times speedup compared to optimization-based approaches. Code: https://github.com/pythongod-exe/iGaussian

