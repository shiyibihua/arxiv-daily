---
layout: default
title: 3D Ground Truth Reconstruction from Multi-Camera Annotations Using UKF
---

# 3D Ground Truth Reconstruction from Multi-Camera Annotations Using UKF

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.17609" target="_blank" class="toolbar-btn">arXiv: 2511.17609v1</a>
    <a href="https://arxiv.org/pdf/2511.17609.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.17609v1" 
            onclick="toggleFavorite(this, '2511.17609v1', '3D Ground Truth Reconstruction from Multi-Camera Annotations Using UKF')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Linh Van Ma, Unse Fatima, Tepy Sokun Chriv, Haroon Imran, Moongu Jeon

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-18

**Â§áÊ≥®**: International Conference on Control, Automation and Information Sciences (ICCAIS) 2025, October 27 - 29, 2025 \| Jeju, Korea

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫‰∏ÄÁßçÂü∫‰∫éUKFÁöÑÂ§öÁõ∏Êú∫2DÊ†áÊ≥®ËûçÂêà3DÈáçÂª∫ÊñπÊ≥ïÔºåÁî®‰∫éËá™Âä®È©æÈ©∂Á≠âÂú∫ÊôØ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `3DÈáçÂª∫` `Â§öÁõ∏Êú∫Á≥ªÁªü` `Unscented Kalman Filter` `2DÊ†áÊ≥®` `ÁõÆÊ†áË∑üË∏™`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÈöæ‰ª•‰ªéÂ§öÁõ∏Êú∫2DÊ†áÊ≥®‰∏≠ÂáÜÁ°ÆÈáçÂª∫3D ground truthÔºåÂ∞§ÂÖ∂ÊòØÂú®Â≠òÂú®ÈÅÆÊå°ÁöÑÊÉÖÂÜµ‰∏ã„ÄÇ
2. ËØ•ÊñπÊ≥ïÂà©Áî®UKFËûçÂêàÂ§öÁõ∏Êú∫2DÊ†áÊ≥®ÔºåÈÄöËøáÂçïÂ∫îÊÄßÊäïÂΩ±Â∞Ü2DÂùêÊ†áËΩ¨Êç¢‰∏∫È≤ÅÊ£íÁöÑ3D‰∏ñÁïåÂùêÊ†á„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®3DÂÆö‰ΩçÊñπÈù¢ÂÖ∑ÊúâÈ´òÁ≤æÂ∫¶ÔºåÂπ∂ËÉΩËæìÂá∫Áâ©‰ΩìÁöÑÂÆåÊï¥3DÂΩ¢Áä∂Ôºå‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÊñπÊ≥ïÔºåÂà©Áî®Unscented Kalman Filter (UKF) Â∞ÜÊù•Ëá™Â§ö‰∏™Ê†°ÂáÜÁõ∏Êú∫ÁöÑ2D bounding boxÊàñÂßøÊÄÅÂÖ≥ÈîÆÁÇπÊ†áÊ≥®ËûçÂêà‰∏∫Á≤æÁ°ÆÁöÑ3D ground truth„ÄÇËØ•ÊñπÊ≥ïÂà©Áî®‰∫∫Â∑•Ê†áÊ≥®ÁöÑ2D ground truthÔºåÈÄöËøáÂü∫‰∫éÂçïÂ∫îÊÄßÁöÑÊäïÂΩ±ÂíåÂü∫‰∫éUKFÁöÑËûçÂêàÔºåÂ∞Ü2DÂõæÂÉèÂùêÊ†áËΩ¨Êç¢‰∏∫È≤ÅÊ£íÁöÑ3D‰∏ñÁïåÂùêÊ†áÔºåÂÆûÁé∞Â§öÁõ∏Êú∫ÂçïÁõÆÊ†áË∑üË∏™„ÄÇËØ•ÁÆóÊ≥ïÂ§ÑÁêÜÂ§öËßÜËßíÊï∞ÊçÆ‰ª•‰º∞ËÆ°Áâ©‰ΩìÁöÑ‰ΩçÁΩÆÂíåÂΩ¢Áä∂ÔºåÂêåÊó∂ÊúâÊïàÂ§ÑÁêÜÈÅÆÊå°Á≠âÊåëÊàò„ÄÇÊàë‰ª¨Âú®CMC„ÄÅWildtrackÂíåPanopticÊï∞ÊçÆÈõÜ‰∏äËØÑ‰º∞‰∫ÜËØ•ÊñπÊ≥ïÔºåÁªìÊûúË°®ÊòéÔºå‰∏éÁé∞ÊúâÁöÑ3D ground truthÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÂú®3DÂÆö‰ΩçÊñπÈù¢ÂÖ∑ÊúâÂæàÈ´òÁöÑÁ≤æÂ∫¶„ÄÇ‰∏é‰ªÖÊèê‰æõÂú∞Èù¢‰ø°ÊÅØÁöÑÁé∞ÊúâÊñπÊ≥ï‰∏çÂêåÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïËøòËæìÂá∫ÊØè‰∏™Áâ©‰ΩìÁöÑÂÆåÊï¥3DÂΩ¢Áä∂„ÄÇÊ≠§Â§ñÔºåËØ•ÁÆóÊ≥ï‰∏∫Â§öÁõ∏Êú∫Á≥ªÁªüÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂèØÊâ©Â±ï‰∏îÂÆåÂÖ®Ëá™Âä®ÂåñÁöÑËß£ÂÜ≥ÊñπÊ°àÔºå‰ªÖ‰ΩøÁî®2DÂõæÂÉèÊ†áÊ≥®„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰ªéÂ§öÁõ∏Êú∫Á≥ªÁªüÁöÑ2DÂõæÂÉèÊ†áÊ≥®‰∏≠ÂáÜÁ°ÆÈáçÂª∫3D ground truthÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Âè™Êèê‰æõÂú∞Èù¢‰ø°ÊÅØÔºåÊó†Ê≥ïÊèê‰æõÁâ©‰ΩìÁöÑÂÆåÊï¥3DÂΩ¢Áä∂ÔºåÂπ∂‰∏îÂú®Â§ÑÁêÜÈÅÆÊå°Á≠âÈóÆÈ¢òÊó∂Ë°®Áé∞‰∏ç‰Ω≥„ÄÇÊ≠§Â§ñÔºåÁé∞ÊúâÊñπÊ≥ïÂèØËÉΩÈúÄË¶ÅÂ§çÊùÇÁöÑÊ†áÂÆöÊàñ‰∫∫Â∑•Âπ≤È¢ÑÔºåÈöæ‰ª•ÂÆûÁé∞Ëá™Âä®ÂåñÂíåÊâ©Â±ï„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Unscented Kalman Filter (UKF) ËûçÂêàÊù•Ëá™Â§ö‰∏™Ê†°ÂáÜÁõ∏Êú∫ÁöÑ2DÊ†áÊ≥®‰ø°ÊÅØÔºå‰ªéËÄå‰º∞ËÆ°Âá∫Á≤æÁ°ÆÁöÑ3DÁâ©‰Ωì‰ΩçÁΩÆÂíåÂΩ¢Áä∂„ÄÇÈÄöËøáÂ∞Ü2DÂõæÂÉèÂùêÊ†áÊäïÂΩ±Âà∞3D‰∏ñÁïåÂùêÊ†áÁ≥ªÔºåÂπ∂Âà©Áî®UKFËøõË°åÁä∂ÊÄÅ‰º∞ËÆ°ÂíåÂô™Â£∞ÊäëÂà∂ÔºåÂèØ‰ª•ÊúâÊïàÂú∞Â§ÑÁêÜÂ§öËßÜËßíÊï∞ÊçÆ‰∏≠ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÂíåÈÅÆÊå°ÈóÆÈ¢ò„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ï‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) 2DÊ†áÊ≥®Ëé∑ÂèñÔºö‰ªéÂ§ö‰∏™Ê†°ÂáÜÁõ∏Êú∫Ëé∑Âèñ2D bounding boxÊàñÂßøÊÄÅÂÖ≥ÈîÆÁÇπÊ†áÊ≥®„ÄÇ2) ÂçïÂ∫îÊÄßÊäïÂΩ±ÔºöÂà©Áî®Áõ∏Êú∫ÂÜÖÂ§ñÂèÇÊï∞ÂíåÂçïÂ∫îÊÄßÁü©ÈòµÔºåÂ∞Ü2DÂõæÂÉèÂùêÊ†áÊäïÂΩ±Âà∞3D‰∏ñÁïåÂùêÊ†áÁ≥ª„ÄÇ3) UKFËûçÂêàÔºö‰ΩøÁî®UKFÂ∞ÜÊù•Ëá™‰∏çÂêåÁõ∏Êú∫ÁöÑ3DÂùêÊ†á‰º∞ËÆ°ËøõË°åËûçÂêàÔºåÂæóÂà∞ÊúÄÁªàÁöÑ3DÁâ©‰Ωì‰ΩçÁΩÆÂíåÂΩ¢Áä∂‰º∞ËÆ°„ÄÇ4) Áä∂ÊÄÅÊõ¥Êñ∞ÔºöÊ†πÊçÆUKFÁöÑÈ¢ÑÊµãÂíåÊõ¥Êñ∞Ê≠•È™§Ôºå‰∏çÊñ≠‰ºòÂåñ3DÁâ©‰ΩìÁä∂ÊÄÅ‰º∞ËÆ°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂà©Áî®UKFÊ°ÜÊû∂ÊúâÊïàÂú∞ËûçÂêà‰∫ÜÂ§öÁõ∏Êú∫2DÊ†áÊ≥®‰ø°ÊÅØÔºå‰ªéËÄåÂÆûÁé∞‰∫ÜÁ≤æÁ°ÆÁöÑ3D ground truthÈáçÂª∫„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ï‰∏ç‰ªÖÂèØ‰ª•Êèê‰æõÁâ©‰ΩìÁöÑ3D‰ΩçÁΩÆÔºåËøòÂèØ‰ª•‰º∞ËÆ°Áâ©‰ΩìÁöÑÂÆåÊï¥3DÂΩ¢Áä∂„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÂÖ∑ÊúâÂèØÊâ©Â±ïÊÄßÂíåËá™Âä®ÂåñÁâπÊÄßÔºåÂè™ÈúÄ2DÂõæÂÉèÊ†áÊ≥®Âç≥ÂèØÂÆûÁé∞Â§öÁõ∏Êú∫Á≥ªÁªüÁöÑ3DÈáçÂª∫„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®UKFÊ°ÜÊû∂‰∏≠ÔºåÈúÄË¶ÅÈÄâÊã©ÂêàÈÄÇÁöÑÁä∂ÊÄÅÂêëÈáè„ÄÅËøáÁ®ãÂô™Â£∞ÂíåËßÇÊµãÂô™Â£∞„ÄÇÁä∂ÊÄÅÂêëÈáèÂèØ‰ª•ÂåÖÂê´Áâ©‰ΩìÁöÑ‰ΩçÁΩÆ„ÄÅÈÄüÂ∫¶ÂíåÂΩ¢Áä∂ÂèÇÊï∞„ÄÇËøáÁ®ãÂô™Â£∞Áî®‰∫éÊ®°ÊãüÁâ©‰ΩìËøêÂä®ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÔºåËßÇÊµãÂô™Â£∞Áî®‰∫éÊ®°Êãü2DÊ†áÊ≥®ÁöÑËØØÂ∑Æ„ÄÇÊ≠§Â§ñÔºåÂçïÂ∫îÊÄßÁü©ÈòµÁöÑËÆ°ÁÆóÁ≤æÂ∫¶‰πü‰ºöÂΩ±ÂìçÊúÄÁªàÁöÑ3DÈáçÂª∫ÁªìÊûú„ÄÇËÆ∫ÊñáÂèØËÉΩËøòÊ∂âÂèä‰∏Ä‰∫õÂèÇÊï∞Ë∞É‰ºòÔºå‰æãÂ¶ÇUKFÁöÑÂèÇÊï∞ËÆæÁΩÆÔºå‰ª•ÂèäÂçïÂ∫îÊÄßÁü©ÈòµÁöÑÈ≤ÅÊ£í‰º∞ËÆ°ÊñπÊ≥ï„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËØ•ÊñπÊ≥ïÂú®CMC„ÄÅWildtrackÂíåPanopticÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰∏éÁé∞ÊúâÁöÑ3D ground truthÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÂú®3DÂÆö‰ΩçÊñπÈù¢ÂÖ∑ÊúâÂæàÈ´òÁöÑÁ≤æÂ∫¶„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üËæìÂá∫Áâ©‰ΩìÁöÑÂÆåÊï¥3DÂΩ¢Áä∂ÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÂú∞Èù¢‰ø°ÊÅØÔºåËøô‰∏∫ÂêéÁª≠ÁöÑÂ∫îÁî®Êèê‰æõ‰∫ÜÊõ¥‰∏∞ÂØåÁöÑ‰ø°ÊÅØ„ÄÇÂÆûÈ™åÁªìÊûúÈ™åËØÅ‰∫ÜËØ•ÊñπÊ≥ïÂú®Â§öÁõ∏Êú∫3DÈáçÂª∫ÊñπÈù¢ÁöÑÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÁõëÊéß„ÄÅÊú∫Âô®‰∫∫Á≠âÈ¢ÜÂüü„ÄÇÂú®Ëá™Âä®È©æÈ©∂‰∏≠ÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ï‰ªéÂ§öÁõ∏Êú∫Êï∞ÊçÆ‰∏≠ÈáçÂª∫Âë®Âõ¥ÁéØÂ¢ÉÁöÑ3DÊ®°ÂûãÔºåÊèêÈ´òËΩ¶ËæÜÁöÑÊÑüÁü•ËÉΩÂäõÂíåÂÆâÂÖ®ÊÄß„ÄÇÂú®Êô∫ËÉΩÁõëÊéß‰∏≠ÔºåÂèØ‰ª•Áî®‰∫éË∑üË∏™ÂíåËØÜÂà´‰∫∫Áæ§‰∏≠ÁöÑÁõÆÊ†áÔºåÂÆûÁé∞Êõ¥Êô∫ËÉΩÁöÑÁõëÊéßÁ≥ªÁªü„ÄÇÂú®Êú∫Âô®‰∫∫È¢ÜÂüüÔºåÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÊìç‰ΩúÂë®Âõ¥ÁéØÂ¢É„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Accurate 3D ground truth estimation is critical for applications such as autonomous navigation, surveillance, and robotics. This paper introduces a novel method that uses an Unscented Kalman Filter (UKF) to fuse 2D bounding box or pose keypoint ground truth annotations from multiple calibrated cameras into accurate 3D ground truth. By leveraging human-annotated ground-truth 2D, our proposed method, a multi-camera single-object tracking algorithm, transforms 2D image coordinates into robust 3D world coordinates through homography-based projection and UKF-based fusion. Our proposed algorithm processes multi-view data to estimate object positions and shapes while effectively handling challenges such as occlusion. We evaluate our method on the CMC, Wildtrack, and Panoptic datasets, demonstrating high accuracy in 3D localization compared to the available 3D ground truth. Unlike existing approaches that provide only ground-plane information, our method also outputs the full 3D shape of each object. Additionally, the algorithm offers a scalable and fully automatic solution for multi-camera systems using only 2D image annotations.

