---
layout: default
title: DeCo-VAE: Learning Compact Latents for Video Reconstruction via Decoupled Representation
---

# DeCo-VAE: Learning Compact Latents for Video Reconstruction via Decoupled Representation

**arXiv**: [2511.14530v1](https://arxiv.org/abs/2511.14530) | [PDF](https://arxiv.org/pdf/2511.14530.pdf)

**ä½œè€…**: Xiangchen Yin, Jiahui Yuan, Zhangchi Hu, Wenzhang Sun, Jie Chen, Xiaozhen Qiao, Hao Li, Xiaoyan Sun

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDeCo-VAEé€šè¿‡è§£è€¦è¡¨ç¤ºå­¦ä¹ ç´§å‡‘æ½œåœ¨å˜é‡ä»¥æ”¹è¿›è§†é¢‘é‡å»º**

**å…³é”®è¯**: `è§†é¢‘å˜åˆ†è‡ªç¼–ç å™¨` `è§£è€¦è¡¨ç¤ºå­¦ä¹ ` `ç´§å‡‘æ½œåœ¨å˜é‡` `è§†é¢‘é‡å»º` `3Dè§£ç å™¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†é¢‘VAEå¿½ç•¥å¸§é—´ç›¸ä¼¼æ€§ï¼Œå¯¼è‡´æ½œåœ¨å»ºæ¨¡å†—ä½™
2. å°†è§†é¢‘è§£è€¦ä¸ºå…³é”®å¸§ã€è¿åŠ¨å’Œæ®‹å·®ç»„ä»¶ï¼Œå¹¶å­¦ä¹ ä¸“ç”¨æ½œåœ¨è¡¨ç¤º
3. å®žéªŒæ˜¾ç¤ºDeCo-VAEåœ¨è§†é¢‘é‡å»ºæ€§èƒ½ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Existing video Variational Autoencoders (VAEs) generally overlook the similarity between frame contents, leading to redundant latent modeling. In this paper, we propose decoupled VAE (DeCo-VAE) to achieve compact latent representation. Instead of encoding RGB pixels directly, we decompose video content into distinct components via explicit decoupling: keyframe, motion and residual, and learn dedicated latent representation for each. To avoid cross-component interference, we design dedicated encoders for each decoupled component and adopt a shared 3D decoder to maintain spatiotemporal consistency during reconstruction. We further utilize a decoupled adaptation strategy that freezes partial encoders while training the others sequentially, ensuring stable training and accurate learning of both static and dynamic features. Extensive quantitative and qualitative experiments demonstrate that DeCo-VAE achieves superior video reconstruction performance.

