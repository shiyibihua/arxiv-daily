---
layout: default
title: Breaking the Passive Learning Trap: An Active Perception Strategy for Human Motion Prediction
---

# Breaking the Passive Learning Trap: An Active Perception Strategy for Human Motion Prediction

**arXiv**: [2511.14237v1](https://arxiv.org/abs/2511.14237) | [PDF](https://arxiv.org/pdf/2511.14237.pdf)

**ä½œè€…**: Juncheng Hu, Zijian Zhang, Zeyu Wang, Guoyu Wang, Yingji Li, Kedi Lyu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸»åŠ¨æ„ŸçŸ¥ç­–ç•¥ä»¥è§£å†³3Däººä½“è¿åŠ¨é¢„æµ‹ä¸­çš„è¢«åŠ¨å­¦ä¹ é—®é¢˜**

**å…³é”®è¯**: `3Däººä½“è¿åŠ¨é¢„æµ‹` `ä¸»åŠ¨æ„ŸçŸ¥ç­–ç•¥` `å•†ç©ºé—´è¡¨ç¤º` `è¾…åŠ©å­¦ä¹ ` `æ—¶ç©ºå»ºæ¨¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•ä¾èµ–éšå¼ç½‘ç»œå»ºæ¨¡ï¼Œå¯¼è‡´å†—ä½™åæ ‡èŽ·å–å’Œå•è°ƒå­¦ä¹ 
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å•†ç©ºé—´è¡¨ç¤ºå’Œè¾…åŠ©å­¦ä¹ ç›®æ ‡ï¼Œå¢žå¼ºè¿åŠ¨å±žæ€§å’Œæ—¶ç©ºå»ºæ¨¡
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®žçŽ°SOTAï¼Œæ€§èƒ½æå‡è¶…è¿‡10%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Forecasting 3D human motion is an important embodiment of fine-grained understanding and cognition of human behavior by artificial agents. Current approaches excessively rely on implicit network modeling of spatiotemporal relationships and motion characteristics, falling into the passive learning trap that results in redundant and monotonous 3D coordinate information acquisition while lacking actively guided explicit learning mechanisms. To overcome these issues, we propose an Active Perceptual Strategy (APS) for human motion prediction, leveraging quotient space representations to explicitly encode motion properties while introducing auxiliary learning objectives to strengthen spatio-temporal modeling. Specifically, we first design a data perception module that projects poses into the quotient space, decoupling motion geometry from coordinate redundancy. By jointly encoding tangent vectors and Grassmann projections, this module simultaneously achieves geometric dimension reduction, semantic decoupling, and dynamic constraint enforcement for effective motion pose characterization. Furthermore, we introduce a network perception module that actively learns spatio-temporal dependencies through restorative learning. This module deliberately masks specific joints or injects noise to construct auxiliary supervision signals. A dedicated auxiliary learning network is designed to actively adapt and learn from perturbed information. Notably, APS is model agnostic and can be integrated with different prediction models to enhance active perceptual. The experimental results demonstrate that our method achieves the new state-of-the-art, outperforming existing methods by large margins: 16.3% on H3.6M, 13.9% on CMU Mocap, and 10.1% on 3DPW.

