---
layout: default
title: BEDLAM2.0: Synthetic Humans and Cameras in Motion
---

# BEDLAM2.0: Synthetic Humans and Cameras in Motion

**arXiv**: [2511.14394v1](https://arxiv.org/abs/2511.14394) | [PDF](https://arxiv.org/pdf/2511.14394.pdf)

**ä½œè€…**: Joachim Tesch, Giorgio Becherini, Prerana Achar, Anastasios Yiannakidis, Muhammed Kocabas, Priyanka Patel, Michael J. Black

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBEDLAM2.0æ•°æ®é›†ä»¥è§£å†³è§†é¢‘ä¸­3Däººä½“å’Œç›¸æœºè¿åŠ¨ä¼°è®¡é—®é¢˜**

**å…³é”®è¯**: `3Däººä½“è¿åŠ¨ä¼°è®¡` `åˆæˆæ•°æ®é›†` `ä¸–ç•Œåæ ‡ç³»` `ç›¸æœºè¿åŠ¨` `è§†é¢‘åˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç¼ºä¹çœŸå®žè§†é¢‘æ•°æ®ï¼Œéš¾ä»¥ä¼°è®¡ä¸–ç•Œåæ ‡ç³»ä¸­çš„äººä½“å’Œç›¸æœºè¿åŠ¨
2. æ–¹æ³•è¦ç‚¹ï¼šæ‰©å±•BEDLAMæ•°æ®é›†ï¼Œå¢žåŠ å¤šæ ·æ€§äººä½“ã€ç›¸æœºã€çŽ¯å¢ƒå’Œæœè£…
3. å®žéªŒæˆ–æ•ˆæžœï¼šè®­ç»ƒæ–¹æ³•åœ¨BEDLAM2.0ä¸Šæ˜¾è‘—æå‡ä¼°è®¡å‡†ç¡®æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Inferring 3D human motion from video remains a challenging problem with many applications. While traditional methods estimate the human in image coordinates, many applications require human motion to be estimated in world coordinates. This is particularly challenging when there is both human and camera motion. Progress on this topic has been limited by the lack of rich video data with ground truth human and camera movement. We address this with BEDLAM2.0, a new dataset that goes beyond the popular BEDLAM dataset in important ways. In addition to introducing more diverse and realistic cameras and camera motions, BEDLAM2.0 increases diversity and realism of body shape, motions, clothing, hair, and 3D environments. Additionally, it adds shoes, which were missing in BEDLAM. BEDLAM has become a key resource for training 3D human pose and motion regressors today and we show that BEDLAM2.0 is significantly better, particularly for training methods that estimate humans in world coordinates. We compare state-of-the art methods trained on BEDLAM and BEDLAM2.0, and find that BEDLAM2.0 significantly improves accuracy over BEDLAM. For research purposes, we provide the rendered videos, ground truth body parameters, and camera motions. We also provide the 3D assets to which we have rights and links to those from third parties.

