---
layout: default
title: MindCross: Fast New Subject Adaptation with Limited Data for Cross-subject Video Reconstruction from Brain Signals
---

# MindCross: Fast New Subject Adaptation with Limited Data for Cross-subject Video Reconstruction from Brain Signals

**arXiv**: [2511.14196v1](https://arxiv.org/abs/2511.14196) | [PDF](https://arxiv.org/pdf/2511.14196.pdf)

**ä½œè€…**: Xuan-Hao Liu, Yan-Kai Liu, Tianyi Zhou, Bao-Liang Lu, Wei-Long Zheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMindCrossæ¡†æž¶ï¼Œé€šè¿‡å¤šç¼–ç å™¨ä¸ŽTop-Kåä½œå®žçŽ°å¿«é€Ÿå°‘æ•°æ®è·¨è¢«è¯•è§†é¢‘é‡å»º**

**å…³é”®è¯**: `è„‘ä¿¡å·è§£ç ` `è·¨è¢«è¯•é€‚åº”` `è§†é¢‘é‡å»º` `å¤šç¼–ç å™¨æ¡†æž¶` `Top-Kåä½œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè·¨è¢«è¯•è„‘ä¿¡å·è§†é¢‘é‡å»ºæ•°æ®ç¨€ç¼ºï¼ŒçŽ°æœ‰æ–¹æ³•å¿½ç•¥è¢«è¯•ç‰¹å¼‚æ€§ä¿¡æ¯ï¼Œé€‚åº”æ…¢
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡Nä¸ªç‰¹å®šç¼–ç å™¨æå–è¢«è¯•ç‰¹å¼‚æ€§ä¿¡æ¯ï¼Œå…±äº«ç¼–ç å™¨æå–ä¸å˜ä¿¡æ¯ï¼ŒTop-Kæ¨¡å—åä½œå¢žå¼ºè§£ç 
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨fMRI/EEGåŸºå‡†ä¸ŠéªŒè¯ï¼Œä»…éœ€ä¸€ä¸ªæ¨¡åž‹å®žçŽ°é«˜æ•ˆè·¨è¢«è¯•è§£ç ä¸Žæ–°è¢«è¯•å¿«é€Ÿé€‚åº”

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reconstructing video from brain signals is an important brain decoding task. Existing brain decoding frameworks are primarily built on a subject-dependent paradigm, which requires large amounts of brain data for each subject. However, the expensive cost of collecting brain-video data causes severe data scarcity. Although some cross-subject methods being introduced, they often overfocus with subject-invariant information while neglecting subject-specific information, resulting in slow fine-tune-based adaptation strategy. To achieve fast and data-efficient new subject adaptation, we propose MindCross, a novel cross-subject framework. MindCross's N specific encoders and one shared encoder are designed to extract subject-specific and subject-invariant information, respectively. Additionally, a Top-K collaboration module is adopted to enhance new subject decoding with the knowledge learned from previous subjects' encoders. Extensive experiments on fMRI/EEG-to-video benchmarks demonstrate MindCross's efficacy and efficiency of cross-subject decoding and new subject adaptation using only one model.

