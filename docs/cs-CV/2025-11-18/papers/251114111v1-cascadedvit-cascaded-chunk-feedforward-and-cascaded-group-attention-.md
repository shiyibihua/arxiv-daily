---
layout: default
title: CascadedViT: Cascaded Chunk-FeedForward and Cascaded Group Attention Vision Transformer
---

# CascadedViT: Cascaded Chunk-FeedForward and Cascaded Group Attention Vision Transformer

**arXiv**: [2511.14111v1](https://arxiv.org/abs/2511.14111) | [PDF](https://arxiv.org/pdf/2511.14111.pdf)

**ä½œè€…**: Srivathsan Sivakumar, Faisal Z. Qureshi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCascadedViTä»¥é™ä½Žè§†è§‰Transformerçš„è®¡ç®—å’Œèƒ½è€—ï¼Œé€‚ç”¨äºŽèµ„æºå—é™è®¾å¤‡ã€‚**

**å…³é”®è¯**: `è§†è§‰Transformer` `è½»é‡çº§æž¶æž„` `è®¡ç®—æ•ˆçŽ‡` `èƒ½è€—ä¼˜åŒ–` `ç§»åŠ¨è®¾å¤‡éƒ¨ç½²`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†è§‰Transformerè®¡ç®—å’Œå†…å­˜éœ€æ±‚é«˜ï¼Œé™åˆ¶åœ¨èµ„æºå—é™å¹³å°éƒ¨ç½²ã€‚
2. å¼•å…¥çº§è”åˆ†å—å‰é¦ˆç½‘ç»œï¼Œåˆ†å‰²è¾“å…¥ç‰¹å¾æå‡å‚æ•°å’ŒFLOPæ•ˆçŽ‡ã€‚
3. åœ¨ImageNet-1Kä¸ŠéªŒè¯ï¼ŒCViT-XLå‡†ç¡®çŽ‡75.5%ï¼ŒFLOPså‡å°‘15%ï¼Œèƒ½è€—é™ä½Ž3.3%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision Transformers (ViTs) have demonstrated remarkable performance across a range of computer vision tasks; however, their high computational, memory, and energy demands hinder deployment on resource-constrained platforms. In this paper, we propose \emph{Cascaded-ViT (CViT)}, a lightweight and compute-efficient vision transformer architecture featuring a novel feedforward network design called \emph{Cascaded-Chunk Feed Forward Network (CCFFN)}. By splitting input features, CCFFN improves parameter and FLOP efficiency without sacrificing accuracy. Experiments on ImageNet-1K show that our \emph{CViT-XL} model achieves 75.5\% Top-1 accuracy while reducing FLOPs by 15\% and energy consumption by 3.3\% compared to EfficientViT-M5. Across various model sizes, the CViT family consistently exhibits the lowest energy consumption, making it suitable for deployment on battery-constrained devices such as mobile phones and drones. Furthermore, when evaluated using a new metric called \emph{Accuracy-Per-FLOP (APF)}, which quantifies compute efficiency relative to accuracy, CViT models consistently achieve top-ranking efficiency. Particularly, CViT-L is 2.2\% more accurate than EfficientViT-M2 while having comparable APF scores.

