---
layout: default
title: Enhancing End-to-End Autonomous Driving with Risk Semantic Distillaion from VLM
---

# Enhancing End-to-End Autonomous Driving with Risk Semantic Distillaion from VLM

**arXiv**: [2511.14499v1](https://arxiv.org/abs/2511.14499) | [PDF](https://arxiv.org/pdf/2511.14499.pdf)

**ä½œè€…**: Jack Qin, Zhitao Wang, Yinan Zheng, Keyu Chen, Yang Zhou, Yuanxin Zhong, Siyuan Cheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé£Žé™©è¯­ä¹‰è’¸é¦æ¡†æž¶ä»¥å¢žå¼ºç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶çš„æ³›åŒ–èƒ½åŠ›**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `é£Žé™©è¯­ä¹‰è’¸é¦` `è§†è§‰è¯­è¨€æ¨¡åž‹` `ç«¯åˆ°ç«¯å­¦ä¹ ` `é¸Ÿçž°å›¾ç‰¹å¾` `æ³›åŒ–èƒ½åŠ›`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå½“å‰è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿæ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œéš¾ä»¥å¤„ç†æœªçŸ¥åœºæ™¯æˆ–ä¼ æ„Ÿå™¨é…ç½®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥RiskHeadæ¨¡å—ï¼Œä»Žè§†è§‰è¯­è¨€æ¨¡åž‹è’¸é¦é£Žé™©ä¼°è®¡åˆ°é¸Ÿçž°å›¾ç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Bench2DriveåŸºå‡†æµ‹è¯•ä¸­ï¼Œæ„ŸçŸ¥å’Œè§„åˆ’èƒ½åŠ›æ˜¾è‘—æå‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The autonomous driving (AD) system has exhibited remarkable performance in complex driving scenarios. However, generalization is still a key limitation for the current system, which refers to the ability to handle unseen scenarios or unfamiliar sensor configurations.Related works have explored the use of Vision-Language Models (VLMs) to address few-shot or zero-shot tasks. While promising, these methods introduce a new challenge: the emergence of a hybrid AD system, where two distinct systems are used to plan a trajectory, leading to potential inconsistencies. Alternative research directions have explored Vision-Language-Action (VLA) frameworks that generate control actions from VLM directly. However, these end-to-end solutions demonstrate prohibitive computational demands. To overcome these challenges, we introduce Risk Semantic Distillation (RSD), a novel framework that leverages VLMs to enhance the training of End-to-End (E2E) AD backbones. By providing risk attention for key objects, RSD addresses the issue of generalization. Specifically, we introduce RiskHead, a plug-in module that distills causal risk estimates from Vision-Language Models into Bird's-Eye-View (BEV) features, yielding interpretable risk-attention maps.This approach allows BEV features to learn richer and more nuanced risk attention representations, which directly enhance the model's ability to handle spatial boundaries and risky objects.By focusing on risk attention, RSD aligns better with human-like driving behavior, which is essential to navigate in complex and dynamic environments. Our experiments on the Bench2Drive benchmark demonstrate the effectiveness of RSD in managing complex and unpredictable driving conditions. Due to the enhanced BEV representations enabled by RSD, we observed a significant improvement in both perception and planning capabilities.

