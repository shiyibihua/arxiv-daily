---
layout: default
title: Agentic Video Intelligence: A Flexible Framework for Advanced Video Exploration and Understanding
---

# Agentic Video Intelligence: A Flexible Framework for Advanced Video Exploration and Understanding

**arXiv**: [2511.14446v1](https://arxiv.org/abs/2511.14446) | [PDF](https://arxiv.org/pdf/2511.14446.pdf)

**ä½œè€…**: Hong Gao, Yiming Bao, Xuezhen Tu, Yutong Xu, Yue Jin, Yiyang Mu, Bin Zhong, Linan Yue, Min-Ling Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAgentic Video Intelligenceæ¡†æž¶ï¼Œé€šè¿‡å…è®­ç»ƒè®¾è®¡è§£å†³è§†é¢‘ç†è§£ä¸­çš„è¿­ä»£æŽ¨ç†é—®é¢˜**

**å…³é”®è¯**: `è§†é¢‘ç†è§£` `æ™ºèƒ½ä½“æ¡†æž¶` `å…è®­ç»ƒæ–¹æ³•` `å¤šç²’åº¦å·¥å…·` `å¼€æºæ¨¡åž‹é›†æˆ` `å¯è§£é‡Šæ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§†é¢‘ç†è§£æ–¹æ³•ç¼ºä¹è¯æ®é‡è®¿å’Œè¿­ä»£ä¼˜åŒ–ï¼Œä¾èµ–æ˜‚è´µæ¨¡åž‹æˆ–å¼ºåŒ–å­¦ä¹ 
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥ä¸‰é˜¶æ®µæŽ¨ç†è¿‡ç¨‹ã€ç»“æž„åŒ–çŸ¥è¯†åº“å’Œå¼€æºæ¨¡åž‹é›†æˆï¼Œå®žçŽ°çµæ´»è§†é¢‘æŽ¢ç´¢
3. å®žéªŒæ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°ç«žäº‰æ€§èƒ½ï¼Œå¹¶æä¾›é«˜å¯è§£é‡Šæ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video understanding requires not only visual recognition but also complex reasoning. While Vision-Language Models (VLMs) demonstrate impressive capabilities, they typically process videos largely in a single-pass manner with limited support for evidence revisit and iterative refinement. While recently emerging agent-based methods enable long-horizon reasoning, they either depend heavily on expensive proprietary models or require extensive agentic RL training. To overcome these limitations, we propose Agentic Video Intelligence (AVI), a flexible and training-free framework that can mirror human video comprehension through system-level design and optimization. AVI introduces three key innovations: (1) a human-inspired three-phase reasoning process (Retrieve-Perceive-Review) that ensures both sufficient global exploration and focused local analysis, (2) a structured video knowledge base organized through entity graphs, along with multi-granularity integrated tools, constituting the agent's interaction environment, and (3) an open-source model ensemble combining reasoning LLMs with lightweight base CV models and VLM, eliminating dependence on proprietary APIs or RL training. Experiments on LVBench, VideoMME-Long, LongVideoBench, and Charades-STA demonstrate that AVI achieves competitive performance while offering superior interpretability.

