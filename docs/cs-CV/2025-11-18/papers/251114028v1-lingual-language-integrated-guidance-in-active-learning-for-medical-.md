---
layout: default
title: LINGUAL: Language-INtegrated GUidance in Active Learning for Medical Image Segmentation
---

# LINGUAL: Language-INtegrated GUidance in Active Learning for Medical Image Segmentation

**arXiv**: [2511.14028v1](https://arxiv.org/abs/2511.14028) | [PDF](https://arxiv.org/pdf/2511.14028.pdf)

**ä½œè€…**: Md Shazid Islam, Shreyangshu Bera, Sudipta Paul, Amit K. Roy-Chowdhury

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLINGUALæ¡†æž¶ï¼Œé€šè¿‡è¯­è¨€æŒ‡å¯¼å‡å°‘åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„æ ‡æ³¨è´Ÿæ‹…ã€‚**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒåˆ†å‰²` `ä¸»åŠ¨å­¦ä¹ ` `è¯­è¨€æŒ‡å¯¼` `åŸŸé€‚åº”` `æ ‡æ³¨æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­ï¼Œä¸»åŠ¨å­¦ä¹ æ ‡æ³¨æ¨¡ç³Šè¾¹ç•Œæ—¶åŠ³åŠ¨å¯†é›†ä¸”è®¤çŸ¥è´Ÿæ‹…é«˜ã€‚
2. LINGUALå°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤è½¬åŒ–ä¸ºç¨‹åºï¼Œè‡ªåŠ¨æ‰§è¡Œå­ä»»åŠ¡ï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚
3. åœ¨ä¸»åŠ¨åŸŸé€‚åº”ä¸­ï¼Œæ€§èƒ½å¯æ¯”æˆ–ä¼˜äºŽåŸºçº¿ï¼Œä¼°è®¡æ ‡æ³¨æ—¶é—´å‡å°‘çº¦80%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Although active learning (AL) in segmentation tasks enables experts to annotate selected regions of interest (ROIs) instead of entire images, it remains highly challenging, labor-intensive, and cognitively demanding due to the blurry and ambiguous boundaries commonly observed in medical images. Also, in conventional AL, annotation effort is a function of the ROI- larger regions make the task cognitively easier but incur higher annotation costs, whereas smaller regions demand finer precision and more attention from the expert. In this context, language guidance provides an effective alternative, requiring minimal expert effort while bypassing the cognitively demanding task of precise boundary delineation in segmentation. Towards this goal, we introduce LINGUAL: a framework that receives natural language instructions from an expert, translates them into executable programs through in-context learning, and automatically performs the corresponding sequence of sub-tasks without any human intervention. We demonstrate the effectiveness of LINGUAL in active domain adaptation (ADA) achieving comparable or superior performance to AL baselines while reducing estimated annotation time by approximately 80%.

