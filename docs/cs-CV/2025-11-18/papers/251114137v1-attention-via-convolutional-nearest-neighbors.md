---
layout: default
title: Attention Via Convolutional Nearest Neighbors
---

# Attention Via Convolutional Nearest Neighbors

**arXiv**: [2511.14137v1](https://arxiv.org/abs/2511.14137) | [PDF](https://arxiv.org/pdf/2511.14137.pdf)

**ä½œè€…**: Mingi Kang, JeovÃ¡ Farias Sales Rocha Neto

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå·ç§¯æœ€è¿‘é‚»æ¡†æž¶ä»¥ç»Ÿä¸€å·ç§¯ä¸Žæ³¨æ„åŠ›ï¼Œæå‡å›¾åƒåˆ†ç±»æ€§èƒ½**

**å…³é”®è¯**: `å·ç§¯ç¥žç»ç½‘ç»œ` `è‡ªæ³¨æ„åŠ›æœºåˆ¶` `kè¿‘é‚»èšåˆ` `å›¾åƒåˆ†ç±»` `æž¶æž„ç»Ÿä¸€` `æ­£åˆ™åŒ–æ•ˆæžœ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå·ç§¯ä¸Žè‡ªæ³¨æ„åŠ›è¢«è§†ä¸ºä¸åŒæž¶æž„ï¼Œç¼ºä¹ç»Ÿä¸€ç†è®ºæ¡†æž¶
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽkè¿‘é‚»èšåˆï¼Œå·ç§¯é€‰ç©ºé—´é‚»è¿‘ï¼Œæ³¨æ„åŠ›é€‰ç‰¹å¾ç›¸ä¼¼
3. å®žéªŒæ•ˆæžœï¼šåœ¨CIFARæ•°æ®é›†ä¸Šï¼Œæ··åˆæž¶æž„å’ŒViTå˜ä½“å‡ä¼˜äºŽæ ‡å‡†æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The shift from Convolutional Neural Networks to Transformers has reshaped computer vision, yet these two architectural families are typically viewed as fundamentally distinct. We argue that convolution and self-attention, despite their apparent differences, can be unified within a single k-nearest neighbor aggregation framework. The critical insight is that both operations are special cases of neighbor selection and aggregation; convolution selects neighbors by spatial proximity, while attention selects by feature similarity, revealing they exist on a continuous spectrum. We introduce Convolutional Nearest Neighbors (ConvNN), a unified framework that formalizes this connection. Crucially, ConvNN serves as a drop-in replacement for convolutional and attention layers, enabling systematic exploration of the intermediate spectrum between these two extremes. We validate the framework's coherence on CIFAR-10 and CIFAR-100 classification tasks across two complementary architectures: (1) Hybrid branching in VGG improves accuracy on both CIFAR datasets by combining spatial-proximity and feature-similarity selection; and (2) ConvNN in ViT outperforms standard attention and other attention variants on both datasets. Extensive ablations on $k$ values and architectural variants reveal that interpolating along this spectrum provides regularization benefits by balancing local and global receptive fields. Our work provides a unifying framework that dissolves the apparent distinction between convolution and attention, with implications for designing more principled and interpretable vision architectures.

