---
layout: default
title: Coffee: Controllable Diffusion Fine-tuning
---

# Coffee: Controllable Diffusion Fine-tuning

**arXiv**: [2511.14113v1](https://arxiv.org/abs/2511.14113) | [PDF](https://arxiv.org/pdf/2511.14113.pdf)

**ä½œè€…**: Ziyao Zeng, Jingcheng Ni, Ruyi Liu, Alex Wong

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoffeeæ–¹æ³•ä»¥è§£å†³æ‰©æ•£æ¨¡åž‹å¾®è°ƒä¸­ä¸æœŸæœ›æ¦‚å¿µå­¦ä¹ çš„é—®é¢˜**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹å¾®è°ƒ` `å¯æŽ§ç”Ÿæˆ` `æ¦‚å¿µå¯¹é½` `æ–‡æœ¬åˆ°å›¾åƒ` `åè§ç¼“è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‰©æ•£æ¨¡åž‹å¾®è°ƒæ—¶æ˜“å­¦ä¹ ä¸æœŸæœ›æ¦‚å¿µå¹¶ä¸Žç”¨æˆ·æç¤ºçº ç¼ 
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨è¯­è¨€æŒ‡å®šä¸æœŸæœ›æ¦‚å¿µï¼Œé˜²æ­¢ç”¨æˆ·æç¤ºåµŒå…¥ä¸Žå…¶å¯¹é½
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å›¾åƒå¾®è°ƒä¸­ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œæ— éœ€é¢å¤–è®­ç»ƒ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-to-image diffusion models can generate diverse content with flexible prompts, which makes them well-suited for customization through fine-tuning with a small amount of user-provided data. However, controllable fine-tuning that prevents models from learning undesired concepts present in the fine-tuning data, and from entangling those concepts with user prompts, remains an open challenge. It is crucial for downstream tasks like bias mitigation, preventing malicious adaptation, attribute disentanglement, and generalizable fine-tuning of diffusion policy. We propose Coffee that allows using language to specify undesired concepts to regularize the adaptation process. The crux of our method lies in keeping the embeddings of the user prompt from aligning with undesired concepts. Crucially, Coffee requires no additional training and enables flexible modification of undesired concepts by modifying textual descriptions. We evaluate Coffee by fine-tuning on images associated with user prompts paired with undesired concepts. Experimental results demonstrate that Coffee can prevent text-to-image models from learning specified undesired concepts during fine-tuning and outperforms existing methods. Code will be released upon acceptance.

