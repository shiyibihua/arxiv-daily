---
layout: default
title: SparseSurf: Sparse-View 3D Gaussian Splatting for Surface Reconstruction
---

# SparseSurf: Sparse-View 3D Gaussian Splatting for Surface Reconstruction

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.14633" target="_blank" class="toolbar-btn">arXiv: 2511.14633v1</a>
    <a href="https://arxiv.org/pdf/2511.14633.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.14633v1" 
            onclick="toggleFavorite(this, '2511.14633v1', 'SparseSurf: Sparse-View 3D Gaussian Splatting for Surface Reconstruction')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Meiying Gu, Jiawei Zhang, Jiahe Li, Xiaohan Yu, Haonan Luo, Jin Zheng, Xiao Bai

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-18

**å¤‡æ³¨**: Accepted at AAAI 2026. Project page: https://miya-oi.github.io/SparseSurf-project

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SparseSurfï¼šç¨€ç–è§†å›¾ä¸‹åŸºäº3Dé«˜æ–¯æº…å°„çš„è¡¨é¢é‡å»º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `ä¸‰ç»´é‡å»º` `é«˜æ–¯æº…å°„` `ç¨€ç–è§†å›¾` `è¡¨é¢é‡å»º` `å‡ ä½•ä¸€è‡´æ€§` `ç«‹ä½“è§†è§‰` `æ–°è§†è§’åˆæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç¨€ç–è§†å›¾ä¸‹è¿›è¡Œ3Dé«˜æ–¯æº…å°„è¡¨é¢é‡å»ºæ—¶ï¼Œå®¹æ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆï¼Œå¯¼è‡´é‡å»ºè´¨é‡ä¸ä½³ï¼Œè¿™æ˜¯æ ¸å¿ƒæŒ‘æˆ˜ã€‚
2. SparseSurfçš„æ ¸å¿ƒæ€æƒ³æ˜¯å¼•å…¥ç«‹ä½“å‡ ä½•-çº¹ç†å¯¹é½ï¼Œå°†æ¸²æŸ“è´¨é‡ä¸å‡ ä½•ä¼°è®¡è”ç³»èµ·æ¥ï¼Œä»è€Œå…±åŒä¼˜åŒ–è¡¨é¢é‡å»ºå’Œè§†è§’åˆæˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSparseSurfåœ¨DTUã€BlendedMVSå’ŒMip-NeRF360æ•°æ®é›†ä¸Šå‡å–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºSparseSurfçš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä»ç¨€ç–è§†å›¾å›¾åƒä¸­é‡å»ºé«˜è´¨é‡ã€ç»†èŠ‚ä¸°å¯Œçš„è¡¨é¢å‡ ä½•ç»“æ„çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç¨€ç–è§†å›¾ä¸‹å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œå¯¼è‡´é‡å»ºè´¨é‡ä¸‹é™ã€‚è™½ç„¶ä½¿ç”¨æ‰å¹³é«˜æ–¯åŸºå…ƒå’Œæ·±åº¦æ­£åˆ™åŒ–å¯ä»¥ç¼“è§£å‡ ä½•æ­§ä¹‰ï¼Œä½†æ‰å¹³é«˜æ–¯å¸¦æ¥çš„å„å‘å¼‚æ€§ä¼šåŠ å‰§è¿‡æ‹Ÿåˆï¼Œå½±å“è¡¨é¢æ‹Ÿåˆå’Œæ–°è§†è§’åˆæˆã€‚SparseSurfé€šè¿‡å¼•å…¥ç«‹ä½“å‡ ä½•-çº¹ç†å¯¹é½ï¼Œå°†æ¸²æŸ“è´¨é‡ä¸å‡ ä½•ä¼°è®¡è”ç³»èµ·æ¥ï¼Œä»è€Œå…±åŒæå‡è¡¨é¢é‡å»ºå’Œè§†è§’åˆæˆè´¨é‡ã€‚æ­¤å¤–ï¼Œæå‡ºäº†ä¼ªç‰¹å¾å¢å¼ºå‡ ä½•ä¸€è‡´æ€§ï¼Œé€šè¿‡ç»“åˆè®­ç»ƒè§†å›¾å’Œæœªè§è§†å›¾æ¥å¢å¼ºå¤šè§†å›¾å‡ ä½•ä¸€è‡´æ€§ï¼Œæœ‰æ•ˆç¼“è§£ç¨€ç–ç›‘ç£å¯¼è‡´çš„è¿‡æ‹Ÿåˆã€‚åœ¨DTUã€BlendedMVSå’ŒMip-NeRF360æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨ç¨€ç–è§†å›¾æ¡ä»¶ä¸‹ï¼Œåˆ©ç”¨3Dé«˜æ–¯æº…å°„è¿›è¡Œç²¾ç¡®è¡¨é¢é‡å»ºçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚ç›´æ¥ä¼˜åŒ–é«˜æ–¯å‚æ•°æˆ–ä½¿ç”¨æ‰å¹³é«˜æ–¯ï¼Œåœ¨ç¨€ç–è§†å›¾ä¸‹å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œå¯¼è‡´å‡ ä½•å½¢çŠ¶ä¸å‡†ç¡®ï¼Œæ–°è§†è§’æ¸²æŸ“è´¨é‡ä¸‹é™ã€‚ç°æœ‰æ–¹æ³•åœ¨ç¨€ç–è§†å›¾ä¸‹å‡ ä½•ä¿¡æ¯ä¸è¶³ï¼Œæ˜“å—å™ªå£°å¹²æ‰°ï¼Œéš¾ä»¥ä¿è¯é‡å»ºçš„å‡ ä½•ä¸€è‡´æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSparseSurfçš„æ ¸å¿ƒæ€è·¯æ˜¯å»ºç«‹æ¸²æŸ“è´¨é‡å’Œå‡ ä½•ä¼°è®¡ä¹‹é—´çš„æ¡¥æ¢ï¼Œé€šè¿‡ç«‹ä½“å‡ ä½•-çº¹ç†å¯¹é½ï¼Œå°†æ¸²æŸ“æŸå¤±åå‘ä¼ æ’­åˆ°å‡ ä½•ä¼˜åŒ–ä¸­ï¼Œä»è€Œæé«˜é‡å»ºç²¾åº¦ã€‚åŒæ—¶ï¼Œåˆ©ç”¨ä¼ªç‰¹å¾å¢å¼ºå‡ ä½•ä¸€è‡´æ€§ï¼Œå¼•å…¥æœªè§è§†å›¾çš„ä¿¡æ¯ï¼Œå¢å¼ºå¤šè§†å›¾å‡ ä½•ä¸€è‡´æ€§ï¼Œç¼“è§£è¿‡æ‹Ÿåˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSparseSurfåŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç«‹ä½“å‡ ä½•-çº¹ç†å¯¹é½å’Œä¼ªç‰¹å¾å¢å¼ºå‡ ä½•ä¸€è‡´æ€§ã€‚é¦–å…ˆï¼Œé€šè¿‡ç«‹ä½“å‡ ä½•-çº¹ç†å¯¹é½æ¨¡å—ï¼Œåˆ©ç”¨æ¸²æŸ“æŸå¤±ä¼˜åŒ–é«˜æ–¯å‚æ•°ï¼Œå®ç°å‡ ä½•å’Œçº¹ç†çš„ååŒä¼˜åŒ–ã€‚ç„¶åï¼Œé€šè¿‡ä¼ªç‰¹å¾å¢å¼ºå‡ ä½•ä¸€è‡´æ€§æ¨¡å—ï¼Œåˆ©ç”¨è®­ç»ƒè§†å›¾å’Œæœªè§è§†å›¾çš„ä¼ªç‰¹å¾ï¼Œçº¦æŸé«˜æ–¯å‚æ•°ï¼Œå¢å¼ºå¤šè§†å›¾å‡ ä½•ä¸€è‡´æ€§ã€‚æ•´ä½“æµç¨‹æ˜¯è¿­ä»£ä¼˜åŒ–é«˜æ–¯å‚æ•°ï¼Œç›´è‡³æ”¶æ•›ã€‚

**å…³é”®åˆ›æ–°**ï¼šSparseSurfçš„å…³é”®åˆ›æ–°åœ¨äºç«‹ä½“å‡ ä½•-çº¹ç†å¯¹é½å’Œä¼ªç‰¹å¾å¢å¼ºå‡ ä½•ä¸€è‡´æ€§ã€‚ç«‹ä½“å‡ ä½•-çº¹ç†å¯¹é½å°†æ¸²æŸ“è´¨é‡ç›´æ¥åé¦ˆåˆ°å‡ ä½•ä¼˜åŒ–ä¸­ï¼Œé¿å…äº†å•ç‹¬ä¼˜åŒ–å‡ ä½•å½¢çŠ¶å¯¼è‡´çš„åå·®ã€‚ä¼ªç‰¹å¾å¢å¼ºå‡ ä½•ä¸€è‡´æ€§åˆ©ç”¨æœªè§è§†å›¾çš„ä¿¡æ¯ï¼Œæœ‰æ•ˆç¼“è§£äº†ç¨€ç–è§†å›¾ä¸‹çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSparseSurfæ›´æœ‰æ•ˆåœ°åˆ©ç”¨äº†ç¨€ç–è§†å›¾çš„ä¿¡æ¯ï¼Œå®ç°äº†æ›´ç²¾ç¡®çš„è¡¨é¢é‡å»ºã€‚

**å…³é”®è®¾è®¡**ï¼šç«‹ä½“å‡ ä½•-çº¹ç†å¯¹é½æ¨¡å—ä½¿ç”¨æ¸²æŸ“æŸå¤±ï¼ˆå¦‚L1æŸå¤±ã€SSIMæŸå¤±ï¼‰ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼ŒæŒ‡å¯¼é«˜æ–¯å‚æ•°çš„æ›´æ–°ã€‚ä¼ªç‰¹å¾å¢å¼ºå‡ ä½•ä¸€è‡´æ€§æ¨¡å—é¦–å…ˆæå–è®­ç»ƒè§†å›¾å’Œæœªè§è§†å›¾çš„ä¼ªç‰¹å¾ï¼Œç„¶ååˆ©ç”¨è¿™äº›ä¼ªç‰¹å¾è®¡ç®—å‡ ä½•ä¸€è‡´æ€§æŸå¤±ï¼Œçº¦æŸé«˜æ–¯å‚æ•°ã€‚å…·ä½“å®ç°ä¸­ï¼Œå¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒçš„æ·±åº¦ä¼°è®¡ç½‘ç»œæå–ä¼ªç‰¹å¾ï¼Œå¹¶ä½¿ç”¨HuberæŸå¤±ç­‰é²æ£’æŸå¤±å‡½æ•°è®¡ç®—å‡ ä½•ä¸€è‡´æ€§æŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SparseSurfåœ¨DTUã€BlendedMVSå’ŒMip-NeRF360æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨è¡¨é¢é‡å»ºè´¨é‡å’Œæ–°è§†è§’æ¸²æŸ“è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨DTUæ•°æ®é›†ä¸Šï¼ŒSparseSurfåœ¨L1è¯¯å·®å’ŒPSNRæŒ‡æ ‡ä¸Šå‡å–å¾—äº†æ˜¾è‘—æå‡ï¼Œè¯æ˜äº†å…¶åœ¨ç¨€ç–è§†å›¾ä¸‹çš„ä¼˜è¶Šæ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SparseSurfåœ¨ä¸‰ç»´é‡å»ºé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚ï¼šé€†å‘å·¥ç¨‹ã€æ–‡ç‰©æ•°å­—åŒ–ã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€æœºå™¨äººå¯¼èˆªç­‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿä»æœ‰é™çš„å›¾åƒä¸­é‡å»ºå‡ºé«˜è´¨é‡çš„ä¸‰ç»´æ¨¡å‹ï¼Œé™ä½äº†æ•°æ®é‡‡é›†çš„æˆæœ¬å’Œéš¾åº¦ï¼Œä¸ºç›¸å…³åº”ç”¨æä¾›äº†æ›´ä¾¿æ·çš„è§£å†³æ–¹æ¡ˆã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€åŸå¸‚å»ºæ¨¡ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in optimizing Gaussian Splatting for scene geometry have enabled efficient reconstruction of detailed surfaces from images. However, when input views are sparse, such optimization is prone to overfitting, leading to suboptimal reconstruction quality. Existing approaches address this challenge by employing flattened Gaussian primitives to better fit surface geometry, combined with depth regularization to alleviate geometric ambiguities under limited viewpoints. Nevertheless, the increased anisotropy inherent in flattened Gaussians exacerbates overfitting in sparse-view scenarios, hindering accurate surface fitting and degrading novel view synthesis performance. In this paper, we propose \net{}, a method that reconstructs more accurate and detailed surfaces while preserving high-quality novel view rendering. Our key insight is to introduce Stereo Geometry-Texture Alignment, which bridges rendering quality and geometry estimation, thereby jointly enhancing both surface reconstruction and view synthesis. In addition, we present a Pseudo-Feature Enhanced Geometry Consistency that enforces multi-view geometric consistency by incorporating both training and unseen views, effectively mitigating overfitting caused by sparse supervision. Extensive experiments on the DTU, BlendedMVS, and Mip-NeRF360 datasets demonstrate that our method achieves the state-of-the-art performance.

