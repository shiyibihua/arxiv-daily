---
layout: default
title: MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to Misleading Visual Inputs in LVLMs
---

# MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to Misleading Visual Inputs in LVLMs

**arXiv**: [2511.14159v1](https://arxiv.org/abs/2511.14159) | [PDF](https://arxiv.org/pdf/2511.14159.pdf)

**ä½œè€…**: Huiyi Chen, Jiawei Peng, Dehai Min, Changchang Sun, Kaijie Chen, Yan Yan, Xu Yang, Lu Cheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMVI-BenchåŸºå‡†ä»¥è¯„ä¼°LVLMå¯¹è¯¯å¯¼æ€§è§†è§‰è¾“å…¥çš„é²æ£’æ€§**

**å…³é”®è¯**: `å¤§åž‹è§†è§‰è¯­è¨€æ¨¡åž‹` `é²æ£’æ€§è¯„ä¼°` `è¯¯å¯¼æ€§è§†è§‰è¾“å…¥` `è§†è§‰é—®ç­”åŸºå‡†` `MVI-SensitivityæŒ‡æ ‡` `è§†è§‰åŽŸè¯­åˆ†ç±»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŸºå‡†å¤šå…³æ³¨æ–‡æœ¬è¯¯å¯¼ï¼Œå¿½ç•¥è§†è§‰è¯¯å¯¼å¯¹LVLMé²æ£’æ€§çš„å½±å“
2. åŸºäºŽè§†è§‰åŽŸè¯­æž„å»ºä¸‰å±‚è¯¯å¯¼è¾“å…¥åˆ†ç±»ï¼Œå¹¶æ”¶é›†1248ä¸ªVQAå®žä¾‹
3. å¼•å…¥MVI-SensitivityæŒ‡æ ‡ï¼Œè¯„ä¼°18ä¸ªLVLMæ˜¾ç¤ºæ˜¾è‘—è„†å¼±æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Evaluating the robustness of Large Vision-Language Models (LVLMs) is essential for their continued development and responsible deployment in real-world applications. However, existing robustness benchmarks typically focus on hallucination or misleading textual inputs, while largely overlooking the equally critical challenge posed by misleading visual inputs in assessing visual understanding. To fill this important gap, we introduce MVI-Bench, the first comprehensive benchmark specially designed for evaluating how Misleading Visual Inputs undermine the robustness of LVLMs. Grounded in fundamental visual primitives, the design of MVI-Bench centers on three hierarchical levels of misleading visual inputs: Visual Concept, Visual Attribute, and Visual Relationship. Using this taxonomy, we curate six representative categories and compile 1,248 expertly annotated VQA instances. To facilitate fine-grained robustness evaluation, we further introduce MVI-Sensitivity, a novel metric that characterizes LVLM robustness at a granular level. Empirical results across 18 state-of-the-art LVLMs uncover pronounced vulnerabilities to misleading visual inputs, and our in-depth analyses on MVI-Bench provide actionable insights that can guide the development of more reliable and robust LVLMs. The benchmark and codebase can be accessed at https://github.com/chenyil6/MVI-Bench.

