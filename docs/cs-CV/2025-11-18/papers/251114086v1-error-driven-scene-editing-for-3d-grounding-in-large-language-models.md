---
layout: default
title: Error-Driven Scene Editing for 3D Grounding in Large Language Models
---

# Error-Driven Scene Editing for 3D Grounding in Large Language Models

**arXiv**: [2511.14086v1](https://arxiv.org/abs/2511.14086) | [PDF](https://arxiv.org/pdf/2511.14086.pdf)

**ä½œè€…**: Yue Zhang, Zun Wang, Han Lin, Jialu Li, Jianing Yang, Yonatan Bitton, Idan Szpektor, Mohit Bansal

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-11-18

**å¤‡æ³¨**: Code: https://github.com/zhangyuejoslin/Deer-3D

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDEER-3Dæ¡†æž¶ï¼Œé€šè¿‡è¯¯å·®é©±åŠ¨çš„åœºæ™¯ç¼–è¾‘æå‡3D-LLMçš„ç©ºé—´ç†è§£èƒ½åŠ›**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3D-LLM` `åœºæ™¯ç†è§£` `è¯¯å·®é©±åŠ¨å­¦ä¹ ` `åäº‹å®žæ•°æ®å¢žå¼º` `ç©ºé—´æŽ¨ç†` `3Dåœºæ™¯ç¼–è¾‘` `è°“è¯çº§åˆ«åˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰3D-LLMåœ¨è¯­è¨€ä¸Ž3Dåœºæ™¯å…ƒç´ å¯¹åº”æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œä¸»è¦åŽŸå› æ˜¯è®­ç»ƒæ•°æ®ä¾§é‡è¯­è¨€æŽ¨ç†ï¼Œç¼ºä¹ç©ºé—´ç†è§£ã€‚
2. DEER-3Dæ¡†æž¶é€šè¿‡è¯¯å·®é©±åŠ¨çš„3Dåœºæ™¯ç¼–è¾‘ï¼Œç”Ÿæˆé’ˆå¯¹æ€§çš„åäº‹å®žæ•°æ®ï¼Œè¿­ä»£å¾®è°ƒæ¨¡åž‹ï¼Œæå‡ç©ºé—´ç†è§£èƒ½åŠ›ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒDEER-3Dåœ¨å¤šä¸ª3Då¯¹åº”å’Œåœºæ™¯ç†è§£ä»»åŠ¡ä¸Šå‡å–å¾—äº†æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡3D-LLMå–å¾—äº†è¿›å±•ï¼Œä½†åœ¨å°†è¯­è¨€ç²¾ç¡®åœ°å¯¹åº”åˆ°3DçŽ¯å¢ƒä¸­çš„è§†è§‰å’Œç©ºé—´å…ƒç´ æ–¹é¢ä»ç„¶å­˜åœ¨å±€é™æ€§ã€‚è¿™éƒ¨åˆ†æºäºŽè®­ç»ƒæ•°æ®ä¾§é‡äºŽè¯­è¨€æŽ¨ç†è€Œéžç©ºé—´ç†è§£ï¼Œå¯¼è‡´å›ºæœ‰çš„å¯¹åº”åå·®æœªè¢«è§£å†³ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡º3Dåœºæ™¯ç¼–è¾‘ä½œä¸ºä¸€ç§å…³é”®æœºåˆ¶ï¼Œç”Ÿæˆç²¾ç¡®çš„è§†è§‰åäº‹å®žï¼Œé€šè¿‡ç»†ç²’åº¦çš„ç©ºé—´æ“ä½œæ¥ç¼“è§£è¿™äº›åå·®ï¼Œè€Œæ— éœ€æ˜‚è´µçš„åœºæ™¯é‡å»ºæˆ–å¤§è§„æ¨¡3Dæ•°æ®æ”¶é›†ã€‚æ­¤å¤–ï¼Œä¸ºäº†ä½¿è¿™äº›ç¼–è¾‘å…·æœ‰é’ˆå¯¹æ€§å¹¶ç›´æŽ¥è§£å†³æ¨¡åž‹çš„ç‰¹å®šå¼±ç‚¹ï¼Œæˆ‘ä»¬å¼•å…¥äº†DEER-3Dï¼Œè¿™æ˜¯ä¸€ä¸ªè¯¯å·®é©±åŠ¨çš„æ¡†æž¶ï¼Œéµå¾ªç»“æž„åŒ–çš„â€œåˆ†è§£ã€è¯Šæ–­è¯„ä¼°ã€ç¼–è¾‘å’Œå†è®­ç»ƒâ€å·¥ä½œæµç¨‹ï¼Œè€Œä¸æ˜¯åƒä¼ ç»Ÿæ–¹æ³•é‚£æ ·å¹¿æ³›æˆ–éšæœºåœ°æ‰©å……æ•°æ®ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨è¯†åˆ«å‡º3D-LLMçš„å¯¹åº”å¤±è´¥åŽï¼Œæˆ‘ä»¬çš„æ¡†æž¶é¦–å…ˆè¯Šæ–­ç²¾ç¡®çš„è°“è¯çº§åˆ«é”™è¯¯ï¼ˆä¾‹å¦‚ï¼Œå±žæ€§æˆ–ç©ºé—´å…³ç³»ï¼‰ã€‚ç„¶åŽï¼Œå®ƒæ‰§è¡Œæœ€å°çš„ã€è°“è¯å¯¹é½çš„3Dåœºæ™¯ç¼–è¾‘ï¼Œä¾‹å¦‚é‡æ–°ç€è‰²æˆ–é‡æ–°å®šä½ï¼Œä»¥äº§ç”Ÿæœ‰é’ˆå¯¹æ€§çš„åäº‹å®žç›‘ç£ï¼Œç”¨äºŽè¿­ä»£æ¨¡åž‹å¾®è°ƒï¼Œä»Žè€Œæ˜¾è‘—æé«˜å¯¹åº”å‡†ç¡®æ€§ã€‚æˆ‘ä»¬åœ¨å¤šä¸ª3Då¯¹åº”å’Œåœºæ™¯ç†è§£ä»»åŠ¡çš„åŸºå‡†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„ç¼–è¾‘æµç¨‹ï¼Œå§‹ç»ˆè¯æ˜Žé€šè¿‡è¿­ä»£æ”¹è¿›ï¼Œæ‰€æœ‰è¯„ä¼°æ•°æ®é›†éƒ½å¾—åˆ°äº†æ”¹è¿›ã€‚DEER-3Då¼ºè°ƒäº†æœ‰é’ˆå¯¹æ€§çš„ã€è¯¯å·®é©±åŠ¨çš„åœºæ™¯ç¼–è¾‘åœ¨å¼¥åˆ3D LLMä¸­çš„è¯­è¨€æŽ¨ç†èƒ½åŠ›ä¸Žç©ºé—´å¯¹åº”æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰3D-LLMåœ¨å°†è¯­è¨€æè¿°ä¸Ž3Dåœºæ™¯ä¸­çš„ç‰©ä½“åŠå…¶ç©ºé—´å…³ç³»å¯¹åº”æ—¶ï¼Œå­˜åœ¨å‡†ç¡®æ€§ä¸è¶³çš„é—®é¢˜ã€‚ä¸»è¦åŽŸå› æ˜¯è®­ç»ƒæ•°æ®é›†ä¸­ç¼ºä¹è¶³å¤Ÿçš„ç©ºé—´ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡åž‹åœ¨ç©ºé—´æŽ¨ç†æ–¹é¢å­˜åœ¨åå·®ã€‚ä¼ ç»Ÿçš„æ•°æ®å¢žå¼ºæ–¹æ³•é€šå¸¸æ˜¯éšæœºæˆ–å¹¿æ³›çš„ï¼Œæ— æ³•é’ˆå¯¹æ€§åœ°è§£å†³è¿™äº›åå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDEER-3Dçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è¯¯å·®é©±åŠ¨çš„åœºæ™¯ç¼–è¾‘ï¼Œç”Ÿæˆå…·æœ‰é’ˆå¯¹æ€§çš„åäº‹å®žæ•°æ®ï¼Œä»Žè€Œçº æ­£3D-LLMåœ¨ç©ºé—´ç†è§£æ–¹é¢çš„åå·®ã€‚é€šè¿‡åˆ†æžæ¨¡åž‹çš„é”™è¯¯ï¼Œç¡®å®šéœ€è¦ä¿®æ”¹çš„è°“è¯ï¼ˆå¦‚å±žæ€§æˆ–ç©ºé—´å…³ç³»ï¼‰ï¼Œç„¶åŽå¯¹åœºæ™¯è¿›è¡Œæœ€å°åŒ–çš„ç¼–è¾‘ï¼Œç”Ÿæˆæ–°çš„è®­ç»ƒæ ·æœ¬ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šDEER-3Dæ¡†æž¶åŒ…å«å››ä¸ªä¸»è¦é˜¶æ®µï¼šåˆ†è§£ï¼ˆDecomposeï¼‰ã€è¯Šæ–­è¯„ä¼°ï¼ˆDiagnostic Evaluationï¼‰ã€ç¼–è¾‘ï¼ˆEditï¼‰å’Œå†è®­ç»ƒï¼ˆRe-trainï¼‰ã€‚é¦–å…ˆï¼Œåˆ†è§£é˜¶æ®µå°†å¤æ‚çš„è¯­è¨€æè¿°åˆ†è§£ä¸ºæ›´å°çš„è°“è¯å•å…ƒã€‚ç„¶åŽï¼Œè¯Šæ–­è¯„ä¼°é˜¶æ®µè¯†åˆ«æ¨¡åž‹åœ¨å“ªäº›è°“è¯ä¸Šå‡ºçŽ°é”™è¯¯ã€‚æŽ¥ä¸‹æ¥ï¼Œç¼–è¾‘é˜¶æ®µæ ¹æ®è¯Šæ–­ç»“æžœï¼Œå¯¹3Dåœºæ™¯è¿›è¡Œé’ˆå¯¹æ€§çš„ä¿®æ”¹ï¼Œç”Ÿæˆåäº‹å®žæ•°æ®ã€‚æœ€åŽï¼Œå†è®­ç»ƒé˜¶æ®µä½¿ç”¨åŽŸå§‹æ•°æ®å’Œåäº‹å®žæ•°æ®å¯¹æ¨¡åž‹è¿›è¡Œå¾®è°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šDEER-3Dçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶è¯¯å·®é©±åŠ¨çš„ç¼–è¾‘ç­–ç•¥ã€‚ä¸Žä¼ ç»Ÿçš„æ•°æ®å¢žå¼ºæ–¹æ³•ä¸åŒï¼ŒDEER-3Dä¸æ˜¯éšæœºåœ°ä¿®æ”¹åœºæ™¯ï¼Œè€Œæ˜¯æ ¹æ®æ¨¡åž‹çš„é”™è¯¯è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„ç¼–è¾‘ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æ›´æœ‰æ•ˆåœ°çº æ­£æ¨¡åž‹çš„åå·®ï¼Œæé«˜å…¶ç©ºé—´ç†è§£èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒDEER-3Dé‡‡ç”¨æœ€å°åŒ–ç¼–è¾‘ç­–ç•¥ï¼Œé¿å…å¼•å…¥ä¸å¿…è¦çš„å™ªå£°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç¼–è¾‘é˜¶æ®µï¼ŒDEER-3Dæ ¹æ®ä¸åŒçš„è°“è¯ç±»åž‹é‡‡ç”¨ä¸åŒçš„ç¼–è¾‘ç­–ç•¥ã€‚ä¾‹å¦‚ï¼Œå¯¹äºŽå±žæ€§è°“è¯ï¼ˆå¦‚é¢œè‰²ï¼‰ï¼Œå¯ä»¥é€šè¿‡æ”¹å˜ç‰©ä½“çš„é¢œè‰²æ¥ç”Ÿæˆåäº‹å®žæ•°æ®ã€‚å¯¹äºŽç©ºé—´å…³ç³»è°“è¯ï¼ˆå¦‚â€œåœ¨...ä¹‹ä¸Šâ€ï¼‰ï¼Œå¯ä»¥é€šè¿‡æ”¹å˜ç‰©ä½“çš„ä½ç½®æ¥ç”Ÿæˆåäº‹å®žæ•°æ®ã€‚ç¼–è¾‘çš„å¹…åº¦è¢«è®¾è®¡ä¸ºå°½å¯èƒ½å°ï¼Œä»¥é¿å…å¼•å…¥ä¸å¿…è¦çš„å™ªå£°ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨æ ‡å‡†çš„äº¤å‰ç†µæŸå¤±ï¼Œç”¨äºŽè®­ç»ƒæ¨¡åž‹ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒDEER-3Dåœ¨å¤šä¸ª3Då¯¹åº”å’Œåœºæ™¯ç†è§£ä»»åŠ¡ä¸Šå‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨ScanQAæ•°æ®é›†ä¸Šï¼ŒDEER-3Då°†æ¨¡åž‹çš„å‡†ç¡®çŽ‡æé«˜äº†5%ä»¥ä¸Šã€‚ä¸Žå…¶ä»–æ•°æ®å¢žå¼ºæ–¹æ³•ç›¸æ¯”ï¼ŒDEER-3Dèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°çº æ­£æ¨¡åž‹çš„åå·®ï¼Œæé«˜å…¶ç©ºé—´ç†è§£èƒ½åŠ›ã€‚å®žéªŒè¿˜è¡¨æ˜Žï¼Œè¿­ä»£çš„ç¼–è¾‘å’Œå†è®­ç»ƒå¯ä»¥è¿›ä¸€æ­¥æé«˜æ¨¡åž‹çš„æ€§èƒ½ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

DEER-3Dæ¡†æž¶å¯åº”ç”¨äºŽå„ç§éœ€è¦3Dåœºæ™¯ç†è§£å’Œäº¤äº’çš„é¢†åŸŸï¼Œä¾‹å¦‚æœºå™¨äººå¯¼èˆªã€è™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žå’Œæ™ºèƒ½å®¶å±…ã€‚é€šè¿‡æé«˜3D-LLMçš„ç©ºé—´ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥ä½¿è¿™äº›åº”ç”¨æ›´åŠ æ™ºèƒ½å’Œè‡ªç„¶ï¼Œä¾‹å¦‚ï¼Œæœºå™¨äººå¯ä»¥æ›´å‡†ç¡®åœ°ç†è§£äººç±»çš„æŒ‡ä»¤ï¼Œå¹¶åœ¨å¤æ‚çš„3DçŽ¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡ã€‚è¯¥ç ”ç©¶ä¹Ÿæœ‰åŠ©äºŽæå‡3Dåœºæ™¯çš„è‡ªåŠ¨æ ‡æ³¨å’Œå†…å®¹ç”Ÿæˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite recent progress in 3D-LLMs, they remain limited in accurately grounding language to visual and spatial elements in 3D environments. This limitation stems in part from training data that focuses on language reasoning rather than spatial understanding due to scarce 3D resources, leaving inherent grounding biases unresolved. To address this, we propose 3D scene editing as a key mechanism to generate precise visual counterfactuals that mitigate these biases through fine-grained spatial manipulation, without requiring costly scene reconstruction or large-scale 3D data collection. Furthermore, to make these edits targeted and directly address the specific weaknesses of the model, we introduce DEER-3D, an error-driven framework following a structured "Decompose, Diagnostic Evaluation, Edit, and Re-train" workflow, rather than broadly or randomly augmenting data as in conventional approaches. Specifically, upon identifying a grounding failure of the 3D-LLM, our framework first diagnoses the exact predicate-level error (e.g., attribute or spatial relation). It then executes minimal, predicate-aligned 3D scene edits, such as recoloring or repositioning, to produce targeted counterfactual supervision for iterative model fine-tuning, significantly enhancing grounding accuracy. We evaluate our editing pipeline across multiple benchmarks for 3D grounding and scene understanding tasks, consistently demonstrating improvements across all evaluated datasets through iterative refinement. DEER-3D underscores the effectiveness of targeted, error-driven scene editing in bridging linguistic reasoning capabilities with spatial grounding in 3D LLMs.

