---
layout: default
title: Parameter Aware Mamba Model for Multi-task Dense Prediction
---

# Parameter Aware Mamba Model for Multi-task Dense Prediction

**arXiv**: [2511.14503v1](https://arxiv.org/abs/2511.14503) | [PDF](https://arxiv.org/pdf/2511.14503.pdf)

**ä½œè€…**: Xinzhuo Yu, Yunzhi Zhuge, Sitong Gong, Lu Zhang, Pingping Zhang, Huchuan Lu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-18

**å¤‡æ³¨**: Accepted to IEEE Transactions on Cybernetics

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/CQC-gogopro/PAMM)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå‚æ•°æ„ŸçŸ¥Mambaæ¨¡åž‹PAMMï¼Œç”¨äºŽå¤šä»»åŠ¡å¯†é›†é¢„æµ‹ï¼Œæå‡ä»»åŠ¡é—´äº’è”æ€§ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šä»»åŠ¡å­¦ä¹ ` `å¯†é›†é¢„æµ‹` `çŠ¶æ€ç©ºé—´æ¨¡åž‹` `Mamba` `å‚æ•°æ„ŸçŸ¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨å¤šä»»åŠ¡å¯†é›†é¢„æµ‹ä¸­ä¸»è¦ä¾èµ–å·ç§¯å’Œæ³¨æ„åŠ›æœºåˆ¶æŽ¢ç´¢ä»»åŠ¡é—´äº¤äº’ï¼Œç¼ºä¹å¯¹ä»»åŠ¡å†…åœ¨å±žæ€§çš„æœ‰æ•ˆå»ºæ¨¡ã€‚
2. PAMMåˆ©ç”¨çŠ¶æ€ç©ºé—´æ¨¡åž‹ï¼ˆSSMï¼‰çš„å‚æ•°åŒ–èƒ½åŠ›ï¼Œé€šè¿‡åŒçŠ¶æ€ç©ºé—´å‚æ•°ä¸“å®¶é›†æˆä»»åŠ¡ç‰¹å®šå…ˆéªŒï¼Œå¢žå¼ºä»»åŠ¡äº’è”æ€§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒPAMMåœ¨NYUD-v2å’ŒPASCAL-Contextæ•°æ®é›†ä¸Šè¡¨çŽ°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶åœ¨å¤šä»»åŠ¡å¯†é›†é¢„æµ‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºŽè§£ç å™¨çš„æ¡†æž¶ï¼Œå³å‚æ•°æ„ŸçŸ¥Mambaæ¨¡åž‹ï¼ˆPAMMï¼‰ï¼Œä¸“é—¨ä¸ºå¤šä»»åŠ¡å­¦ä¹ çŽ¯å¢ƒä¸‹çš„å¯†é›†é¢„æµ‹è€Œè®¾è®¡ã€‚ä¸Žä½¿ç”¨Transformerå»ºæ¨¡æ•´ä½“ä»»åŠ¡å…³ç³»çš„æ–¹æ³•ä¸åŒï¼ŒPAMMåˆ©ç”¨çŠ¶æ€ç©ºé—´æ¨¡åž‹ï¼ˆSSMï¼‰ä¸°å¯Œä¸”å¯æ‰©å±•çš„å‚æ•°æ¥å¢žå¼ºä»»åŠ¡é—´çš„äº’è”æ€§ã€‚å®ƒé‡‡ç”¨åŒçŠ¶æ€ç©ºé—´å‚æ•°ä¸“å®¶ï¼Œé›†æˆå¹¶è®¾ç½®ä»»åŠ¡ç‰¹å®šçš„å‚æ•°å…ˆéªŒï¼Œä»Žè€Œæ•èŽ·æ¯ä¸ªä»»åŠ¡çš„å†…åœ¨å±žæ€§ã€‚è¿™ç§æ–¹æ³•ä¸ä»…ä¿ƒè¿›äº†ç²¾ç¡®çš„å¤šä»»åŠ¡äº¤äº’ï¼Œè¿˜å…è®¸é€šè¿‡ç»“æž„åŒ–çš„çŠ¶æ€ç©ºé—´åºåˆ—æ¨¡åž‹ï¼ˆS4ï¼‰è¿›è¡Œä»»åŠ¡å…ˆéªŒçš„å…¨å±€é›†æˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨å¤šæ–¹å‘Hilbertæ‰«ææ–¹æ³•æ¥æž„å»ºå¤šè§’åº¦ç‰¹å¾åºåˆ—ï¼Œä»Žè€Œå¢žå¼ºåºåˆ—æ¨¡åž‹å¯¹2Dæ•°æ®çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚åœ¨NYUD-v2å’ŒPASCAL-ContextåŸºå‡†ä¸Šçš„å¤§é‡å®žéªŒè¯æ˜Žäº†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤šä»»åŠ¡å¯†é›†é¢„æµ‹æ—¨åœ¨åŒæ—¶é¢„æµ‹å›¾åƒçš„å¤šä¸ªå±žæ€§ï¼Œä¾‹å¦‚æ·±åº¦ã€è¯­ä¹‰åˆ†å‰²å’Œè¡¨é¢æ³•çº¿ã€‚çŽ°æœ‰æ–¹æ³•ï¼Œå¦‚åŸºäºŽå·ç§¯ç¥žç»ç½‘ç»œï¼ˆCNNï¼‰å’Œæ³¨æ„åŠ›æœºåˆ¶çš„æ¨¡åž‹ï¼Œåœ¨æ•æ‰ä»»åŠ¡é—´çš„å¤æ‚å…³ç³»å’Œåˆ©ç”¨ä»»åŠ¡ç‰¹å®šå…ˆéªŒçŸ¥è¯†æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œéš¾ä»¥å……åˆ†æŒ–æŽ˜ä»»åŠ¡é—´çš„äº’è¡¥ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPAMMçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨çŠ¶æ€ç©ºé—´æ¨¡åž‹ï¼ˆSSMï¼‰ï¼Œç‰¹åˆ«æ˜¯Mambaæž¶æž„ï¼Œå…¶å…·æœ‰å¼ºå¤§çš„åºåˆ—å»ºæ¨¡èƒ½åŠ›å’Œå‚æ•°åŒ–æ•ˆçŽ‡ï¼Œæ¥æ˜¾å¼åœ°å»ºæ¨¡ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»å’Œä»»åŠ¡ç‰¹å®šçš„å…ˆéªŒçŸ¥è¯†ã€‚é€šè¿‡å‚æ•°åŒ–çš„çŠ¶æ€ç©ºé—´æ¨¡åž‹ï¼ŒPAMMèƒ½å¤Ÿå­¦ä¹ åˆ°æ¯ä¸ªä»»åŠ¡çš„å†…åœ¨å±žæ€§ï¼Œå¹¶å°†å…¶èžå…¥åˆ°å¤šä»»åŠ¡å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œä»Žè€Œæå‡æ•´ä½“é¢„æµ‹æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šPAMMæ˜¯ä¸€ä¸ªåŸºäºŽè§£ç å™¨çš„æ¡†æž¶ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) ç‰¹å¾æå–å™¨ï¼šç”¨äºŽæå–è¾“å…¥å›¾åƒçš„ç‰¹å¾è¡¨ç¤ºã€‚2) åŒçŠ¶æ€ç©ºé—´å‚æ•°ä¸“å®¶ï¼šåŒ…å«ä¸¤ä¸ªç‹¬ç«‹çš„SSMï¼Œåˆ†åˆ«ç”¨äºŽå­¦ä¹ ä»»åŠ¡ç‰¹å®šçš„å‚æ•°å…ˆéªŒã€‚3) çŠ¶æ€ç©ºé—´åºåˆ—æ¨¡åž‹ï¼ˆS4ï¼‰ï¼šç”¨äºŽå…¨å±€é›†æˆä»»åŠ¡å…ˆéªŒï¼Œå¹¶å»ºæ¨¡ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»ã€‚4) å¤šæ–¹å‘Hilbertæ‰«æï¼šç”¨äºŽå°†2Dç‰¹å¾å›¾è½¬æ¢ä¸ºåºåˆ—ï¼Œä»¥ä¾¿SSMè¿›è¡Œå¤„ç†ã€‚5) è§£ç å™¨ï¼šç”¨äºŽå°†åºåˆ—è¡¨ç¤ºè½¬æ¢ä¸ºæœ€ç»ˆçš„å¯†é›†é¢„æµ‹ç»“æžœã€‚

**å…³é”®åˆ›æ–°**ï¼šPAMMçš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) å¼•å…¥åŒçŠ¶æ€ç©ºé—´å‚æ•°ä¸“å®¶ï¼Œæ˜¾å¼åœ°å»ºæ¨¡ä»»åŠ¡ç‰¹å®šçš„å‚æ•°å…ˆéªŒã€‚2) åˆ©ç”¨Mambaæž¶æž„çš„å¼ºå¤§åºåˆ—å»ºæ¨¡èƒ½åŠ›ï¼Œå…¨å±€é›†æˆä»»åŠ¡å…ˆéªŒï¼Œå¹¶å»ºæ¨¡ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»ã€‚3) é‡‡ç”¨å¤šæ–¹å‘Hilbertæ‰«æï¼Œå¢žå¼ºåºåˆ—æ¨¡åž‹å¯¹2Dæ•°æ®çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒPAMMèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨ä»»åŠ¡é—´çš„äº’è¡¥ä¿¡æ¯ï¼Œå¹¶æå‡å¤šä»»åŠ¡å¯†é›†é¢„æµ‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåŒçŠ¶æ€ç©ºé—´å‚æ•°ä¸“å®¶ä½¿ç”¨ä¸¤ä¸ªç‹¬ç«‹çš„Mambaå—ï¼Œåˆ†åˆ«å­¦ä¹ ä»»åŠ¡ç‰¹å®šçš„å‚æ•°å…ˆéªŒã€‚S4æ¨¡å—ä½¿ç”¨æ ‡å‡†çš„S4æž¶æž„ï¼Œç”¨äºŽå…¨å±€é›†æˆä»»åŠ¡å…ˆéªŒã€‚å¤šæ–¹å‘Hilbertæ‰«æé‡‡ç”¨å››ä¸ªæ–¹å‘çš„Hilbertæ›²çº¿ï¼Œå°†2Dç‰¹å¾å›¾è½¬æ¢ä¸ºå››ä¸ªåºåˆ—ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨åŠ æƒçš„å¤šä»»åŠ¡æŸå¤±å‡½æ•°ï¼Œæƒé‡æ ¹æ®ä»»åŠ¡çš„é‡è¦æ€§è¿›è¡Œè°ƒæ•´ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨NYUD-v2å’ŒPASCAL-Contextæ•°æ®é›†ä¸Šçš„å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒPAMMæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰çš„å¤šä»»åŠ¡å¯†é›†é¢„æµ‹æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨NYUD-v2æ•°æ®é›†ä¸Šï¼ŒPAMMåœ¨æ·±åº¦é¢„æµ‹ã€è¡¨é¢æ³•çº¿é¢„æµ‹å’Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šå‡å–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚ä¸Žä¹‹å‰çš„æœ€ä½³æ–¹æ³•ç›¸æ¯”ï¼ŒPAMMåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

PAMMåœ¨å¤šä»»åŠ¡å¯†é›†é¢„æµ‹æ–¹é¢å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ï¼ˆåŒæ—¶é¢„æµ‹æ·±åº¦ã€è¯­ä¹‰åˆ†å‰²å’Œäº¤é€šæ ‡å¿—ï¼‰ã€æœºå™¨äººå¯¼èˆªï¼ˆåŒæ—¶é¢„æµ‹çŽ¯å¢ƒåœ°å›¾å’Œç‰©ä½“ç±»åˆ«ï¼‰å’ŒåŒ»å­¦å›¾åƒåˆ†æžï¼ˆåŒæ—¶é¢„æµ‹å™¨å®˜åˆ†å‰²å’Œç—…ç¶æ£€æµ‹ï¼‰ã€‚è¯¥ç ”ç©¶çš„æˆæžœå¯ä»¥æå‡è¿™äº›åº”ç”¨åœºæ™¯çš„æ„ŸçŸ¥èƒ½åŠ›å’Œå†³ç­–èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®žé™…ä»·å€¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Understanding the inter-relations and interactions between tasks is crucial for multi-task dense prediction. Existing methods predominantly utilize convolutional layers and attention mechanisms to explore task-level interactions. In this work, we introduce a novel decoder-based framework, Parameter Aware Mamba Model (PAMM), specifically designed for dense prediction in multi-task learning setting. Distinct from approaches that employ Transformers to model holistic task relationships, PAMM leverages the rich, scalable parameters of state space models to enhance task interconnectivity. It features dual state space parameter experts that integrate and set task-specific parameter priors, capturing the intrinsic properties of each task. This approach not only facilitates precise multi-task interactions but also allows for the global integration of task priors through the structured state space sequence model (S4). Furthermore, we employ the Multi-Directional Hilbert Scanning method to construct multi-angle feature sequences, thereby enhancing the sequence model's perceptual capabilities for 2D data. Extensive experiments on the NYUD-v2 and PASCAL-Context benchmarks demonstrate the effectiveness of our proposed method. Our code is available at https://github.com/CQC-gogopro/PAMM.

