---
layout: default
title: A Graph Attention Network-Based Framework for Reconstructing Missing LiDAR Beams
---

# A Graph Attention Network-Based Framework for Reconstructing Missing LiDAR Beams

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.12410" target="_blank" class="toolbar-btn">arXiv: 2512.12410v1</a>
    <a href="https://arxiv.org/pdf/2512.12410.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.12410v1" 
            onclick="toggleFavorite(this, '2512.12410v1', 'A Graph Attention Network-Based Framework for Reconstructing Missing LiDAR Beams')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Khalfalla Awedat, Mohamed Abidalrekab, Mohammad El-Yabroudi

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-13

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂõæÊ≥®ÊÑèÂäõÁΩëÁªúÁöÑLiDARÁº∫Â§±Ê≥¢ÊùüÈáçÂª∫Ê°ÜÊû∂ÔºåÊèêÂçáËá™Âä®È©æÈ©∂ÁéØÂ¢ÉÊÑüÁü•ËÉΩÂäõ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `LiDARÁÇπ‰∫ë` `Áº∫Â§±Ê≥¢ÊùüÈáçÂª∫` `ÂõæÊ≥®ÊÑèÂäõÁΩëÁªú` `Ëá™Âä®È©æÈ©∂` `‰∏âÁª¥ÊÑüÁü•`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ÊóãËΩ¨ÂºèLiDAR‰º†ÊÑüÂô®ÊòìÂèóÁéØÂ¢ÉÂõ†Á¥†ÂíåÁ°¨‰ª∂ËÄÅÂåñÁöÑÂΩ±ÂìçÔºåÂØºËá¥ÂûÇÁõ¥Ê≥¢ÊùüÁº∫Â§±Ôºå‰∏•ÈáçÈôç‰Ωé‰∫ÜËá™Âä®È©æÈ©∂Á≥ªÁªüÁöÑ3DÊÑüÁü•ËÉΩÂäõ„ÄÇ
2. ËØ•ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßçÂü∫‰∫éÂõæÊ≥®ÊÑèÂäõÁΩëÁªúÔºàGATÔºâÁöÑÊ°ÜÊû∂ÔºåÁõ¥Êé•‰ªéÂçïÂ∏ßLiDARÊï∞ÊçÆ‰∏≠ÈáçÂª∫Áº∫Â§±ÁöÑÂûÇÁõ¥ÈÄöÈÅìÔºåÊó†ÈúÄÈ¢ùÂ§ñÁöÑÁõ∏Êú∫ÊàñÊó∂Èó¥‰ø°ÊÅØ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®KITTIÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜËâØÂ•ΩÁöÑÈáçÂª∫ÊïàÊûúÔºåÂπ≥ÂùáÈ´òÂ∫¶RMSE‰∏∫11.67ÂéòÁ±≥Ôºå‰∏îÂ§ßÈÉ®ÂàÜÈáçÂª∫ÁÇπËØØÂ∑ÆÂú®10ÂéòÁ±≥‰ª•ÂÜÖ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂõæÊ≥®ÊÑèÂäõÁΩëÁªúÔºàGATÔºâÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫éÈáçÂª∫ÊóãËΩ¨ÂºèLiDAR‰º†ÊÑüÂô®‰∏≠Âõ†Á°¨‰ª∂ËÄÅÂåñ„ÄÅÁÅ∞Â∞ò„ÄÅÈõ™„ÄÅÈõæÊàñÂº∫ÂèçÂ∞ÑÂºïËµ∑ÁöÑÂûÇÁõ¥Ê≥¢ÊùüÁº∫Â§±„ÄÇËØ•ÊñπÊ≥ï‰ªÖ‰ΩøÁî®ÂΩìÂâçÁöÑLiDARÂ∏ßÔºåÊó†ÈúÄÁõ∏Êú∫ÂõæÂÉèÊàñÊó∂Èó¥‰ø°ÊÅØ„ÄÇÊØè‰∏™LiDARÊâ´ÊèèË¢´Ë°®Á§∫‰∏∫‰∏Ä‰∏™ÈùûÁªìÊûÑÂåñÁöÑÁ©∫Èó¥ÂõæÔºöÁÇπÊòØËäÇÁÇπÔºåËæπËøûÊé•ÈôÑËøëÁöÑÁÇπÔºåÂêåÊó∂‰øùÁïôÂéüÂßãÁöÑÊ≥¢ÊùüÁ¥¢ÂºïÈ°∫Â∫è„ÄÇÂ§öÂ±ÇGATÂ≠¶‰π†Â±ÄÈÉ®Âá†‰ΩïÈÇªÂüü‰∏äÁöÑËá™ÈÄÇÂ∫îÊ≥®ÊÑèÂäõÊùÉÈáçÔºåÂπ∂Áõ¥Êé•ÂõûÂΩíÁº∫Â§±‰ΩçÁΩÆÁöÑÈ´òÂ∫¶ÔºàzÔºâÂÄº„ÄÇÂú®Ê®°ÊãüÈÄöÈÅìÁº∫Â§±ÁöÑ1065‰∏™ÂéüÂßãKITTIÂ∫èÂàó‰∏äËøõË°åËÆ≠ÁªÉÂíåËØÑ‰º∞ÔºåËØ•ÊñπÊ≥ïÂÆûÁé∞‰∫Ü11.67ÂéòÁ±≥ÁöÑÂπ≥ÂùáÈ´òÂ∫¶RMSEÔºåÂπ∂‰∏î87.98%ÁöÑÈáçÂª∫ÁÇπËêΩÂú®10ÂéòÁ±≥ÁöÑËØØÂ∑ÆÈòàÂÄºÂÜÖ„ÄÇÂú®Âçï‰∏™GPU‰∏äÔºåÊØèÂ∏ßÁöÑÊé®ÁêÜÊó∂Èó¥‰∏∫14.65ÁßíÔºåÈáçÂª∫Ë¥®ÈáèÂØπ‰∫é‰∏çÂêåÁöÑÈÇªÂüüÂ§ßÂ∞èk‰øùÊåÅÁ®≥ÂÆö„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåÁ∫ØÁ≤πÁöÑÂõæÊ≥®ÊÑèÂäõÊ®°Âûã‰ªÖÂú®ÂéüÂßãÁÇπ‰∫ëÂá†‰Ωï‰∏äËøêË°åÔºåÂèØ‰ª•ÊúâÊïàÂú∞ÊÅ¢Â§çÁúüÂÆû‰º†ÊÑüÂô®ÈÄÄÂåñ‰∏ãÁöÑÁº∫Â§±ÂûÇÁõ¥Ê≥¢Êùü„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÊóãËΩ¨ÂºèLiDAR‰º†ÊÑüÂô®‰∏≠Â∏∏ËßÅÁöÑÂûÇÁõ¥Ê≥¢ÊùüÁº∫Â§±ÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂèØËÉΩ‰æùËµñ‰∫éÈ¢ùÂ§ñÁöÑ‰º†ÊÑüÂô®‰ø°ÊÅØÔºàÂ¶ÇÁõ∏Êú∫ÂõæÂÉèÔºâÊàñÊó∂Èó¥‰ø°ÊÅØÔºåÂ¢ûÂä†‰∫ÜÁ≥ªÁªüÁöÑÂ§çÊùÇÊÄßÂíåÊàêÊú¨„ÄÇÊ≠§Â§ñÔºåÁõ¥Êé•Â§ÑÁêÜÂéüÂßãÁÇπ‰∫ëÊï∞ÊçÆÂπ∂ÊúâÊïàÂà©Áî®ÂÖ∂Á©∫Èó¥ÁªìÊûÑ‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜLiDARÁÇπ‰∫ëÊï∞ÊçÆË°®Á§∫‰∏∫ÂõæÁªìÊûÑÔºåÂπ∂Âà©Áî®ÂõæÊ≥®ÊÑèÂäõÁΩëÁªúÔºàGATÔºâÂ≠¶‰π†ÁÇπ‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºå‰ªéËÄåÂÆûÁé∞Áº∫Â§±Ê≥¢ÊùüÁöÑÈáçÂª∫„ÄÇGATËÉΩÂ§üËá™ÈÄÇÂ∫îÂú∞Â≠¶‰π†ÈÇªÂüüÂÜÖ‰∏çÂêåÁÇπÁöÑÊùÉÈáçÔºåÊõ¥Â•ΩÂú∞ÊçïÊçâÂ±ÄÈÉ®Âá†‰ΩïÁâπÂæÅ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê≠•È™§Ôºö1) Â∞ÜLiDARÁÇπ‰∫ëËΩ¨Êç¢‰∏∫ÂõæÁªìÊûÑÔºåÂÖ∂‰∏≠ÁÇπ‰Ωú‰∏∫ËäÇÁÇπÔºåÁõ∏ÈÇªÁÇπ‰πãÈó¥Âª∫Á´ãËæπÔºåÂπ∂‰øùÁïôÂéüÂßãÊ≥¢ÊùüÁ¥¢Âºï‰ø°ÊÅØ„ÄÇ2) ‰ΩøÁî®Â§öÂ±ÇGATÁΩëÁªúÂ≠¶‰π†ÊØè‰∏™ËäÇÁÇπÁöÑÁâπÂæÅË°®Á§∫ÔºåGATÂ±ÇÈÄöËøáÊ≥®ÊÑèÂäõÊú∫Âà∂ËÅöÂêàÈÇªÂüü‰ø°ÊÅØ„ÄÇ3) ‰ΩøÁî®ÂõûÂΩíÂ±ÇÈ¢ÑÊµãÁº∫Â§±ÁÇπÁöÑÈ´òÂ∫¶ÔºàzÔºâÂÄº„ÄÇ4) ‰ΩøÁî®ÂùáÊñπÊ†πËØØÂ∑ÆÔºàRMSEÔºâ‰Ωú‰∏∫ÊçüÂ§±ÂáΩÊï∞Ôºå‰ºòÂåñÁΩëÁªúÂèÇÊï∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁ∫ØÁ≤πÂü∫‰∫éÂõæÊ≥®ÊÑèÂäõÁΩëÁªúÁöÑÁÇπ‰∫ëÈáçÂª∫ÊñπÊ≥ïÔºåÊó†ÈúÄÈ¢ùÂ§ñÁöÑ‰º†ÊÑüÂô®‰ø°ÊÅØÊàñÊó∂Èó¥‰ø°ÊÅØ„ÄÇ2) Âà©Áî®GATÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåËá™ÈÄÇÂ∫îÂú∞Â≠¶‰π†ÈÇªÂüüÂÜÖ‰∏çÂêåÁÇπÁöÑÊùÉÈáçÔºåÊõ¥Â•ΩÂú∞ÊçïÊçâÂ±ÄÈÉ®Âá†‰ΩïÁâπÂæÅ„ÄÇ3) Â∞ÜÂéüÂßãÊ≥¢ÊùüÁ¥¢Âºï‰ø°ÊÅØËûçÂÖ•ÂõæÁªìÊûÑ‰∏≠ÔºåÊúâÂä©‰∫é‰øùÊåÅÁÇπ‰∫ëÁöÑÁ©∫Èó¥ÁªìÊûÑ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂõæÊûÑÂª∫ÊñπÈù¢ÔºåÈááÁî®‰∫ÜkËøëÈÇªÁÆóÊ≥ïÁ°ÆÂÆöÊØè‰∏™ËäÇÁÇπÁöÑÈÇªÂüü„ÄÇGATÁΩëÁªúÈááÁî®‰∫ÜÂ§öÂ±ÇÁªìÊûÑÔºåÊØèÂ±ÇÂåÖÂê´Â§ö‰∏™Ê≥®ÊÑèÂäõÂ§¥Ôºå‰ª•Â¢ûÂº∫Ê®°ÂûãÁöÑË°®ËææËÉΩÂäõ„ÄÇÊçüÂ§±ÂáΩÊï∞ÈááÁî®È´òÂ∫¶ÔºàzÔºâÂÄºÁöÑÂùáÊñπÊ†πËØØÂ∑ÆÔºàRMSEÔºâ„ÄÇÂÆûÈ™å‰∏≠ÔºåÈÇªÂüüÂ§ßÂ∞èkÊòØ‰∏Ä‰∏™ÈáçË¶ÅÁöÑÂèÇÊï∞ÔºåËÆ∫ÊñáÂàÜÊûê‰∫Ü‰∏çÂêåkÂÄºÂØπÈáçÂª∫ÊïàÊûúÁöÑÂΩ±Âìç„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®KITTIÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÈáçÂª∫ÊïàÊûúÔºåÂπ≥ÂùáÈ´òÂ∫¶RMSE‰∏∫11.67ÂéòÁ±≥Ôºå87.98%ÁöÑÈáçÂª∫ÁÇπËêΩÂú®10ÂéòÁ±≥ÁöÑËØØÂ∑ÆÈòàÂÄºÂÜÖ„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÂú®Âçï‰∏™GPU‰∏äÁöÑÊé®ÁêÜÊó∂Èó¥‰∏∫14.65ÁßíÊØèÂ∏ßÔºåÂÖ∑Êúâ‰∏ÄÂÆöÁöÑÂÆûÊó∂ÊÄß„ÄÇÂÆûÈ™åËøòË°®ÊòéÔºåÈáçÂª∫Ë¥®ÈáèÂØπ‰∫é‰∏çÂêåÁöÑÈÇªÂüüÂ§ßÂ∞èk‰øùÊåÅÁ®≥ÂÆöÔºåË°®ÊòéËØ•ÊñπÊ≥ïÂÖ∑ÊúâËæÉÂº∫ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅ‰∏âÁª¥ÈáçÂª∫Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÈáçÂª∫Áº∫Â§±ÁöÑLiDARÊ≥¢ÊùüÔºåÂèØ‰ª•ÊèêÈ´òÁéØÂ¢ÉÊÑüÁü•ÁöÑÂÆåÊï¥ÊÄßÂíåÂáÜÁ°ÆÊÄßÔºå‰ªéËÄåÊèêÂçáËá™Âä®È©æÈ©∂ËΩ¶ËæÜÁöÑÂÆâÂÖ®ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Áî®‰∫é‰øÆÂ§çÂèóÊçüÁöÑLiDARÊï∞ÊçÆÔºåÂª∂Èïø‰º†ÊÑüÂô®ÁöÑ‰ΩøÁî®ÂØøÂëΩ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vertical beam dropout in spinning LiDAR sensors triggered by hardware aging, dust, snow, fog, or bright reflections removes entire vertical slices from the point cloud and severely degrades 3D perception in autonomous vehicles. This paper proposes a Graph Attention Network (GAT)-based framework that reconstructs these missing vertical channels using only the current LiDAR frame, with no camera images or temporal information required. Each LiDAR sweep is represented as an unstructured spatial graph: points are nodes and edges connect nearby points while preserving the original beam-index ordering. A multi-layer GAT learns adaptive attention weights over local geometric neighborhoods and directly regresses the missing elevation (z) values at dropout locations. Trained and evaluated on 1,065 raw KITTI sequences with simulated channel dropout, the method achieves an average height RMSE of 11.67 cm, with 87.98% of reconstructed points falling within a 10 cm error threshold. Inference takes 14.65 seconds per frame on a single GPU, and reconstruction quality remains stable for different neighborhood sizes k. These results show that a pure graph attention model operating solely on raw point-cloud geometry can effectively recover dropped vertical beams under realistic sensor degradation.

