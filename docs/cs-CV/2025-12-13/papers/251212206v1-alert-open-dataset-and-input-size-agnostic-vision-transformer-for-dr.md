---
layout: default
title: ALERT Open Dataset and Input-Size-Agnostic Vision Transformer for Driver Activity Recognition using IR-UWB
---

# ALERT Open Dataset and Input-Size-Agnostic Vision Transformer for Driver Activity Recognition using IR-UWB

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.12206" target="_blank" class="toolbar-btn">arXiv: 2512.12206v1</a>
    <a href="https://arxiv.org/pdf/2512.12206.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.12206v1" 
            onclick="toggleFavorite(this, '2512.12206v1', 'ALERT Open Dataset and Input-Size-Agnostic Vision Transformer for Driver Activity Recognition using IR-UWB')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Jeongjun Park, Sunwook Hwang, Hyeonho Noh, Jin Mo Yang, Hyun Jong Yang, Saewoong Bahk

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºISA-ViTå’ŒALERTæ•°æ®é›†ï¼Œç”¨äºè§£å†³åŸºäºIR-UWBé›·è¾¾çš„é©¾é©¶å‘˜è¡Œä¸ºè¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `é©¾é©¶å‘˜è¡Œä¸ºè¯†åˆ«` `IR-UWBé›·è¾¾` `Vision Transformer` `è¾“å…¥å°ºå¯¸æ— å…³` `é¢†åŸŸèåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºIR-UWBé›·è¾¾çš„é©¾é©¶å‘˜è¡Œä¸ºè¯†åˆ«æ–¹æ³•ç¼ºä¹å¤§è§„æ¨¡çœŸå®æ•°æ®é›†ï¼Œä¸”å›ºå®šè¾“å…¥å°ºå¯¸çš„ViTéš¾ä»¥é€‚åº”éæ ‡å‡†å°ºå¯¸çš„UWBé›·è¾¾æ•°æ®ã€‚
2. è®ºæ–‡æå‡ºISA-ViTæ¡†æ¶ï¼Œé€šè¿‡è°ƒæ•´patché…ç½®å’Œåˆ©ç”¨é¢„è®­ç»ƒçš„ä½ç½®åµŒå…¥å‘é‡ï¼Œä½¿ViTèƒ½å¤Ÿå¤„ç†ä»»æ„å°ºå¯¸çš„UWBé›·è¾¾æ•°æ®ï¼Œå¹¶èåˆè·ç¦»åŸŸå’Œé¢‘ç‡åŸŸç‰¹å¾ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒISA-ViTåœ¨UWBé›·è¾¾é©¾é©¶å‘˜è¡Œä¸ºè¯†åˆ«ä»»åŠ¡ä¸Šï¼Œç›¸æ¯”ç°æœ‰ViTæ–¹æ³•ï¼Œå‡†ç¡®ç‡æå‡äº†22.68%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åˆ†å¿ƒé©¾é©¶æ˜¯å…¨çƒè‡´å‘½è½¦ç¥¸çš„é‡è¦åŸå› ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç ”ç©¶äººå‘˜æ­£åœ¨ä½¿ç”¨åŸºäºè„‰å†²æ— çº¿ç”µè¶…å®½å¸¦(IR-UWB)é›·è¾¾çš„é©¾é©¶å‘˜è¡Œä¸ºè¯†åˆ«(DAR)æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å…·æœ‰æŠ—å¹²æ‰°ã€ä½åŠŸè€—å’Œä¿æŠ¤éšç§ç­‰ä¼˜ç‚¹ã€‚ç„¶è€Œï¼Œä¸¤ä¸ªæŒ‘æˆ˜é™åˆ¶äº†å®ƒçš„åº”ç”¨ï¼šç¼ºä¹æ¶µç›–å„ç§åˆ†å¿ƒé©¾é©¶è¡Œä¸ºçš„å¤§è§„æ¨¡çœŸå®UWBæ•°æ®é›†ï¼Œä»¥åŠéš¾ä»¥å°†å›ºå®šè¾“å…¥çš„Vision Transformers (ViTs)åº”ç”¨äºå…·æœ‰éæ ‡å‡†å°ºå¯¸çš„UWBé›·è¾¾æ•°æ®ã€‚æœ¬ç ”ç©¶æ—¨åœ¨è§£å†³è¿™ä¸¤ä¸ªæŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†ALERTæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«åœ¨çœŸå®é©¾é©¶æ¡ä»¶ä¸‹æ”¶é›†çš„ä¸ƒç§åˆ†å¿ƒé©¾é©¶æ´»åŠ¨çš„10220ä¸ªé›·è¾¾æ ·æœ¬ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§è¾“å…¥å°ºå¯¸æ— å…³çš„Vision Transformer (ISA-ViT)æ¡†æ¶ï¼Œä¸“ä¸ºåŸºäºé›·è¾¾çš„DARè®¾è®¡ã€‚æ‰€æå‡ºçš„æ–¹æ³•è°ƒæ•´UWBæ•°æ®çš„å¤§å°ä»¥æ»¡è¶³ViTè¾“å…¥è¦æ±‚ï¼ŒåŒæ—¶ä¿ç•™é›·è¾¾ç‰¹å®šçš„ä¿¡æ¯ï¼Œå¦‚å¤šæ™®å‹’é¢‘ç§»å’Œç›¸ä½ç‰¹æ€§ã€‚é€šè¿‡è°ƒæ•´patché…ç½®å’Œåˆ©ç”¨é¢„è®­ç»ƒçš„ä½ç½®åµŒå…¥å‘é‡(PEV)ï¼ŒISA-ViTå…‹æœäº†æœ´ç´ è°ƒæ•´å¤§å°æ–¹æ³•çš„å±€é™æ€§ã€‚æ­¤å¤–ï¼Œé¢†åŸŸèåˆç­–ç•¥ç»“åˆäº†è·ç¦»åŸŸå’Œé¢‘ç‡åŸŸç‰¹å¾ï¼Œä»¥è¿›ä¸€æ­¥æé«˜åˆ†ç±»æ€§èƒ½ã€‚ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒISA-ViTåœ¨åŸºäºUWBçš„DARä¸Šï¼Œæ¯”ç°æœ‰çš„åŸºäºViTçš„æ–¹æ³•æé«˜äº†22.68%çš„å‡†ç¡®ç‡ã€‚é€šè¿‡å…¬å¼€å‘å¸ƒALERTæ•°æ®é›†å¹¶è¯¦ç»†ä»‹ç»æˆ‘ä»¬çš„è¾“å…¥å°ºå¯¸æ— å…³ç­–ç•¥ï¼Œè¿™é¡¹å·¥ä½œä¿ƒè¿›äº†æ›´é²æ£’å’Œå¯æ‰©å±•çš„åˆ†å¿ƒé©¾é©¶æ£€æµ‹ç³»ç»Ÿçš„å¼€å‘ï¼Œä»¥ç”¨äºå®é™…éƒ¨ç½²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºIR-UWBé›·è¾¾çš„é©¾é©¶å‘˜è¡Œä¸ºè¯†åˆ«æ–¹æ³•é¢ä¸´ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯ç¼ºä¹å¤§è§„æ¨¡ã€çœŸå®åœºæ™¯ä¸‹çš„UWBæ•°æ®é›†ï¼Œè¿™é™åˆ¶äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼›äºŒæ˜¯ä¼ ç»Ÿçš„Vision Transformer (ViT) éœ€è¦å›ºå®šå°ºå¯¸çš„è¾“å…¥ï¼Œè€ŒUWBé›·è¾¾æ•°æ®é€šå¸¸å…·æœ‰éæ ‡å‡†å°ºå¯¸ï¼Œç›´æ¥resizeä¼šæŸå¤±é›·è¾¾ä¿¡å·çš„ç‰¹æœ‰ä¿¡æ¯ï¼Œä¾‹å¦‚å¤šæ™®å‹’é¢‘ç§»å’Œç›¸ä½ç‰¹å¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªè¾“å…¥å°ºå¯¸æ— å…³çš„Vision Transformer (ISA-ViT)ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†ä»»æ„å°ºå¯¸çš„UWBé›·è¾¾æ•°æ®ï¼ŒåŒæ—¶å°½å¯èƒ½ä¿ç•™é›·è¾¾ä¿¡å·çš„åŸå§‹ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œé€šè¿‡èåˆè·ç¦»åŸŸå’Œé¢‘ç‡åŸŸçš„ç‰¹å¾ï¼Œè¿›ä¸€æ­¥æå‡æ¨¡å‹çš„è¯†åˆ«æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šISA-ViTæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®é¢„å¤„ç†ï¼šå¯¹åŸå§‹UWBé›·è¾¾æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬é™å™ªã€æ»¤æ³¢ç­‰æ“ä½œã€‚2) æ•°æ®å°ºå¯¸è°ƒæ•´ï¼šé€šè¿‡ç‰¹å®šçš„resizeç­–ç•¥ï¼Œå°†UWBæ•°æ®è°ƒæ•´ä¸ºé€‚åˆViTè¾“å…¥çš„å°ºå¯¸ï¼ŒåŒæ—¶å°½é‡ä¿ç•™é›·è¾¾ä¿¡å·çš„ç‰¹å¾ã€‚3) ç‰¹å¾æå–ï¼šä½¿ç”¨ViTæå–é›·è¾¾æ•°æ®çš„ç‰¹å¾ã€‚4) é¢†åŸŸèåˆï¼šå°†è·ç¦»åŸŸå’Œé¢‘ç‡åŸŸçš„ç‰¹å¾è¿›è¡Œèåˆï¼Œä»¥è·å¾—æ›´å…¨é¢çš„ä¿¡æ¯ã€‚5) åˆ†ç±»ï¼šä½¿ç”¨åˆ†ç±»å™¨å¯¹èåˆåçš„ç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼Œå¾—åˆ°é©¾é©¶å‘˜çš„è¡Œä¸ºç±»åˆ«ã€‚

**å…³é”®åˆ›æ–°**ï¼šISA-ViTçš„å…³é”®åˆ›æ–°åœ¨äºå…¶è¾“å…¥å°ºå¯¸æ— å…³æ€§ã€‚ä¼ ç»Ÿçš„ViTéœ€è¦å›ºå®šå°ºå¯¸çš„è¾“å…¥ï¼Œè€ŒISA-ViTé€šè¿‡è°ƒæ•´patché…ç½®å’Œåˆ©ç”¨é¢„è®­ç»ƒçš„ä½ç½®åµŒå…¥å‘é‡ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†ä»»æ„å°ºå¯¸çš„è¾“å…¥ã€‚æ­¤å¤–ï¼Œé¢†åŸŸèåˆç­–ç•¥ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ï¼Œå®ƒèƒ½å¤Ÿå°†è·ç¦»åŸŸå’Œé¢‘ç‡åŸŸçš„ç‰¹å¾è¿›è¡Œæœ‰æ•ˆèåˆï¼Œä»è€Œæå‡æ¨¡å‹çš„è¯†åˆ«æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®å°ºå¯¸è°ƒæ•´æ–¹é¢ï¼Œè®ºæ–‡æ²¡æœ‰é‡‡ç”¨ç®€å•çš„resizeæ–¹æ³•ï¼Œè€Œæ˜¯è®¾è®¡äº†ä¸€ç§èƒ½å¤Ÿä¿ç•™é›·è¾¾ä¿¡å·ç‰¹å¾çš„resizeç­–ç•¥ã€‚åœ¨patché…ç½®æ–¹é¢ï¼Œè®ºæ–‡æ ¹æ®UWBæ•°æ®çš„ç‰¹ç‚¹ï¼Œé€‰æ‹©äº†åˆé€‚çš„patch sizeå’Œstrideã€‚åœ¨ä½ç½®åµŒå…¥å‘é‡æ–¹é¢ï¼Œè®ºæ–‡åˆ©ç”¨é¢„è®­ç»ƒçš„ä½ç½®åµŒå…¥å‘é‡ï¼ŒåŠ é€Ÿäº†æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸€ç§æœ‰æ•ˆçš„é¢†åŸŸèåˆç­–ç•¥ï¼Œå°†è·ç¦»åŸŸå’Œé¢‘ç‡åŸŸçš„ç‰¹å¾è¿›è¡Œæœ‰æ•ˆèåˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ISA-ViTåœ¨ALERTæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸æ¯”äºç°æœ‰çš„åŸºäºViTçš„æ–¹æ³•ï¼Œå‡†ç¡®ç‡æé«˜äº†22.68%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼ŒISA-ViTèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†ä»»æ„å°ºå¯¸çš„UWBé›·è¾¾æ•°æ®ï¼Œå¹¶èƒ½å¤Ÿå……åˆ†åˆ©ç”¨é›·è¾¾ä¿¡å·çš„ç‰¹å¾ä¿¡æ¯ã€‚åŒæ—¶ï¼ŒALERTæ•°æ®é›†çš„å‘å¸ƒä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†å®è´µçš„æ•°æ®èµ„æºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½æ±½è½¦ã€è¾…åŠ©é©¾é©¶ç³»ç»Ÿç­‰é¢†åŸŸï¼Œé€šè¿‡å®æ—¶ç›‘æµ‹é©¾é©¶å‘˜çš„è¡Œä¸ºçŠ¶æ€ï¼ŒåŠæ—¶å‘å‡ºé¢„è­¦ï¼Œä»è€Œé™ä½å› åˆ†å¿ƒé©¾é©¶å¯¼è‡´äº¤é€šäº‹æ•…çš„é£é™©ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯åº”ç”¨äºå…¶ä»–é›·è¾¾ä¿¡å·å¤„ç†é¢†åŸŸï¼Œä¾‹å¦‚äººä½“å§¿æ€è¯†åˆ«ã€æ‰‹åŠ¿è¯†åˆ«ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Distracted driving contributes to fatal crashes worldwide. To address this, researchers are using driver activity recognition (DAR) with impulse radio ultra-wideband (IR-UWB) radar, which offers advantages such as interference resistance, low power consumption, and privacy preservation. However, two challenges limit its adoption: the lack of large-scale real-world UWB datasets covering diverse distracted driving behaviors, and the difficulty of adapting fixed-input Vision Transformers (ViTs) to UWB radar data with non-standard dimensions.
>   This work addresses both challenges. We present the ALERT dataset, which contains 10,220 radar samples of seven distracted driving activities collected in real driving conditions. We also propose the input-size-agnostic Vision Transformer (ISA-ViT), a framework designed for radar-based DAR. The proposed method resizes UWB data to meet ViT input requirements while preserving radar-specific information such as Doppler shifts and phase characteristics. By adjusting patch configurations and leveraging pre-trained positional embedding vectors (PEVs), ISA-ViT overcomes the limitations of naive resizing approaches. In addition, a domain fusion strategy combines range- and frequency-domain features to further improve classification performance.
>   Comprehensive experiments demonstrate that ISA-ViT achieves a 22.68% accuracy improvement over an existing ViT-based approach for UWB-based DAR. By publicly releasing the ALERT dataset and detailing our input-size-agnostic strategy, this work facilitates the development of more robust and scalable distracted driving detection systems for real-world deployment.

