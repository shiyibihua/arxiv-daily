---
layout: default
title: MotionRAG-Diff: A Retrieval-Augmented Diffusion Framework for Long-Term Music-to-Dance Generation
---

# MotionRAG-Diff: A Retrieval-Augmented Diffusion Framework for Long-Term Music-to-Dance Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.02661" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.02661v1</a>
  <a href="https://arxiv.org/pdf/2506.02661.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.02661v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.02661v1', 'MotionRAG-Diff: A Retrieval-Augmented Diffusion Framework for Long-Term Music-to-Dance Generation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Mingyang Huang, Peng Zhang, Bang Zhang

**ÂàÜÁ±ª**: cs.SD, cs.CV, cs.GR, eess.AS

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-03

**Â§áÊ≥®**: 12 pages, 5 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MotionRAG-Diff‰ª•Ëß£ÂÜ≥ÈïøÊó∂Èó¥Èü≥‰πêÈ©±Âä®ËàûËπàÁîüÊàêÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `Èü≥‰πêÈ©±Âä®ÁîüÊàê` `ËàûËπàÂêàÊàê` `Êâ©Êï£Ê®°Âûã` `Ë∑®Ê®°ÊÄÅÂ≠¶‰π†` `ËøêÂä®Âõæ‰ºòÂåñ` `Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê` `ÈïøÊó∂Èó¥Â∫èÂàóÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ÁîüÊàêÈïøÊó∂Èó¥Èü≥‰πêÈ©±Âä®ËàûËπàÂ∫èÂàóÊó∂Â≠òÂú®ËøêÂä®Âõæ‰æùËµñÂõ∫ÂÆöÊ®°ÊùøÂíåÊâ©Êï£Ê®°ÂûãÁº∫‰πèÊó∂Èó¥‰∏ÄËá¥ÊÄßÁöÑÈóÆÈ¢ò„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫MotionRAG-DiffÔºåÈÄöËøáÁªìÂêàÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê‰∏éÊâ©Êï£Ê®°ÂûãÔºåËß£ÂÜ≥‰∫ÜËàûËπàÁîüÊàê‰∏≠ÁöÑÈü≥‰πê‰∏ÄËá¥ÊÄßÂíåÊó∂Èó¥ËøûË¥ØÊÄßÈóÆÈ¢ò„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåMotionRAG-DiffÂú®ËøêÂä®Ë¥®Èáè„ÄÅÂ§öÊ†∑ÊÄßÂíåÈü≥‰πê-Âä®‰ΩúÂêåÊ≠•ÂáÜÁ°ÆÊÄß‰∏äË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÁîüÊàêÈïøÊó∂Èó¥„ÄÅ‰∏ÄËá¥‰∏îÁúüÂÆûÁöÑÈü≥‰πêÈ©±Âä®ËàûËπàÂ∫èÂàó‰ªçÁÑ∂ÊòØ‰∫∫Á±ªËøêÂä®ÂêàÊàê‰∏≠ÁöÑ‰∏ÄÈ°πÊåëÊàò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂ≠òÂú®ÂÖ≥ÈîÆÂ±ÄÈôêÊÄßÔºöËøêÂä®ÂõæÊñπÊ≥ï‰æùËµñÂõ∫ÂÆöÊ®°ÊùøÂ∫ìÔºåÈôêÂà∂‰∫ÜÂàõÈÄ†ÊÄßÁîüÊàêÔºõËÄåÊâ©Êï£Ê®°ÂûãËôΩÁÑ∂ËÉΩÂ§ü‰∫ßÁîüÊñ∞È¢ñÁöÑÂä®‰ΩúÔºå‰ΩÜÂæÄÂæÄÁº∫‰πèÊó∂Èó¥‰∏ÄËá¥ÊÄßÂíåÈü≥‰πêÂØπÈΩê„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜMotionRAG-DiffÔºåËøôÊòØ‰∏ÄÁßçÂ∞ÜÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâ‰∏éÂü∫‰∫éÊâ©Êï£ÁöÑÁ≤æÁÇºÁõ∏ÁªìÂêàÁöÑÊ∑∑ÂêàÊ°ÜÊû∂ÔºåËÉΩÂ§ü‰∏∫‰ªªÊÑèÈïøÊó∂Èó¥Èü≥‰πêËæìÂÖ•ÁîüÊàêÈ´òË¥®Èáè„ÄÅÈü≥‰πê‰∏ÄËá¥ÁöÑËàûËπà„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏â‰∏™Ê†∏ÂøÉÂàõÊñ∞ÔºöË∑®Ê®°ÊÄÅÂØπÊØîÂ≠¶‰π†Êû∂ÊûÑ„ÄÅ‰ºòÂåñÁöÑËøêÂä®ÂõæÁ≥ªÁªü‰ª•ÂèäÂ§öÊù°‰ª∂Êâ©Êï£Ê®°Âûã„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåMotionRAG-DiffÂú®ËøêÂä®Ë¥®Èáè„ÄÅÂ§öÊ†∑ÊÄßÂíåÈü≥‰πê-Âä®‰ΩúÂêåÊ≠•ÂáÜÁ°ÆÊÄßÊñπÈù¢ËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÈïøÊó∂Èó¥Èü≥‰πêÈ©±Âä®ËàûËπàÁîüÊàê‰∏≠ÁöÑÊó∂Èó¥‰∏ÄËá¥ÊÄßÂíåÈü≥‰πêÂØπÈΩêÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂ¶ÇËøêÂä®Âõæ‰æùËµñÂõ∫ÂÆöÊ®°ÊùøÔºåÈôêÂà∂‰∫ÜÂàõÈÄ†ÊÄßÔºåËÄåÊâ©Êï£Ê®°ÂûãÂàôÁº∫‰πèÂøÖË¶ÅÁöÑÊó∂Èó¥ËøûË¥ØÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊàë‰ª¨ÊèêÂá∫ÁöÑMotionRAG-DiffÊ°ÜÊû∂ÁªìÂêà‰∫ÜÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÂíåÊâ©Êï£Ê®°ÂûãÁöÑ‰ºòÁÇπÔºåÈÄöËøáË∑®Ê®°ÊÄÅÂØπÊØîÂ≠¶‰π†Âíå‰ºòÂåñÁöÑËøêÂä®ÂõæÁ≥ªÁªüÔºåÊèêÂçá‰∫ÜËàûËπàÁîüÊàêÁöÑË¥®ÈáèÂíå‰∏ÄËá¥ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMotionRAG-DiffÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöË∑®Ê®°ÊÄÅÂØπÊØîÂ≠¶‰π†Ê®°Âùó„ÄÅ‰ºòÂåñËøêÂä®ÂõæÁ≥ªÁªüÂíåÂ§öÊù°‰ª∂Êâ©Êï£Ê®°Âûã„ÄÇÈ¶ñÂÖàÔºåÈÄöËøáÂØπÊØîÂ≠¶‰π†ÂØπÈü≥‰πêÂíåËàûËπàËøõË°åÂØπÈΩêÔºõÁÑ∂ÂêéÔºåÂà©Áî®ËøêÂä®ÂõæËøõË°åÈ´òÊïàÊ£ÄÁ¥¢ÂíåÊãºÊé•ÔºõÊúÄÂêéÔºå‰ΩøÁî®Êâ©Êï£Ê®°ÂûãËøõË°åËøêÂä®Ë¥®ÈáèÁöÑÊèêÂçáÂíåÂÖ®Â±ÄÂêåÊ≠•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨Á†îÁ©∂ÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜË∑®Ê®°ÊÄÅÂØπÊØîÂ≠¶‰π†Êû∂ÊûÑÔºåÂÆûÁé∞‰∫ÜÊó†ÁõëÁù£ÁöÑËØ≠‰πâÂØπÂ∫îÔºõ‰ºòÂåñÁöÑËøêÂä®ÂõæÁ≥ªÁªüÁ°Æ‰øù‰∫ÜÈïøÂ∫èÂàóÁöÑÁúüÂÆûÊÑüÂíåÊó∂Èó¥‰∏ÄËá¥ÊÄßÔºõÂ§öÊù°‰ª∂Êâ©Êï£Ê®°ÂûãÂàôÂ¢ûÂº∫‰∫ÜËøêÂä®Ë¥®ÈáèÂíåÂÖ®Â±ÄÂêåÊ≠•„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÊàë‰ª¨ÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞Êù•Âπ≥Ë°°ÂØπÊØîÂ≠¶‰π†ÂíåÊâ©Êï£Ê®°ÂûãÁöÑËÆ≠ÁªÉÔºåÁ°Æ‰øùÁîüÊàêÁöÑËàûËπàÂú®Ë¥®ÈáèÂíå‰∏ÄËá¥ÊÄß‰∏äËææÂà∞ÊúÄ‰Ω≥ÊïàÊûú„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMotionRAG-DiffÂú®ËøêÂä®Ë¥®Èáè„ÄÅÂ§öÊ†∑ÊÄßÂíåÈü≥‰πê-Âä®‰ΩúÂêåÊ≠•ÂáÜÁ°ÆÊÄß‰∏äÂùá‰ºò‰∫éÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ïÔºåÂÖ∑‰ΩìÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶ËææÂà∞20%‰ª•‰∏äÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ËàûËπàÁîüÊàêÈ¢ÜÂüüÁöÑÊòæËëó‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®Âú∫ÊôØÂåÖÊã¨ËàûËπàË°®Êºî„ÄÅÊ∏∏ÊàèÂä®ÁîªÂíåËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÂÆûÁé∞È´òË¥®ÈáèÁöÑÈü≥‰πêÈ©±Âä®ËàûËπàÁîüÊàêÔºåMotionRAG-DiffÂèØ‰ª•‰∏∫Ëâ∫ÊúØÂàõ‰ΩúÂíåÂ®±‰πê‰∫ß‰∏öÂ∏¶Êù•Êñ∞ÁöÑÂèØËÉΩÊÄßÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™åÂíåÂàõ‰ΩúÊïàÁéá„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Generating long-term, coherent, and realistic music-conditioned dance sequences remains a challenging task in human motion synthesis. Existing approaches exhibit critical limitations: motion graph methods rely on fixed template libraries, restricting creative generation; diffusion models, while capable of producing novel motions, often lack temporal coherence and musical alignment. To address these challenges, we propose $\textbf{MotionRAG-Diff}$, a hybrid framework that integrates Retrieval-Augmented Generation (RAG) with diffusion-based refinement to enable high-quality, musically coherent dance generation for arbitrary long-term music inputs. Our method introduces three core innovations: (1) A cross-modal contrastive learning architecture that aligns heterogeneous music and dance representations in a shared latent space, establishing unsupervised semantic correspondence without paired data; (2) An optimized motion graph system for efficient retrieval and seamless concatenation of motion segments, ensuring realism and temporal coherence across long sequences; (3) A multi-condition diffusion model that jointly conditions on raw music signals and contrastive features to enhance motion quality and global synchronization. Extensive experiments demonstrate that MotionRAG-Diff achieves state-of-the-art performance in motion quality, diversity, and music-motion synchronization accuracy. This work establishes a new paradigm for music-driven dance generation by synergizing retrieval-based template fidelity with diffusion-based creative enhancement.

