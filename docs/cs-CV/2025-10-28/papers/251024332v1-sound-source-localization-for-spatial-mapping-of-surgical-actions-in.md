---
layout: default
title: Sound Source Localization for Spatial Mapping of Surgical Actions in Dynamic Scenes
---

# Sound Source Localization for Spatial Mapping of Surgical Actions in Dynamic Scenes

**arXiv**: [2510.24332v1](https://arxiv.org/abs/2510.24332) | [PDF](https://arxiv.org/pdf/2510.24332.pdf)

**ä½œè€…**: Jonas Hein, Lazaros Vlachopoulos, Maurits Geert Laurent Olthof, Bastian Sigrist, Philipp FÃ¼rnstahl, Matthias Seibold

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå£°æºå®šä½çš„4DéŸ³é¢‘-è§†è§‰æ¡†æž¶ï¼Œä»¥å¢žå¼ºåŠ¨æ€æ‰‹æœ¯åœºæ™¯çš„å¤šæ¨¡æ€ç†è§£ã€‚**

**å…³é”®è¯**: `å£°æºå®šä½` `æ‰‹æœ¯åœºæ™¯ç†è§£` `å¤šæ¨¡æ€èžåˆ` `4DéŸ³é¢‘-è§†è§‰è¡¨ç¤º` `å˜æ¢å™¨æ£€æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå½“å‰æ‰‹æœ¯åœºæ™¯ç†è§£ä¾èµ–è§†è§‰æˆ–ç«¯åˆ°ç«¯å­¦ä¹ ï¼Œç¼ºä¹ç»†ç²’åº¦ä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨ç›¸æŽ§éº¦å…‹é£Žé˜µåˆ—å’ŒRGB-Dç›¸æœºï¼Œé€šè¿‡å˜æ¢å™¨æ£€æµ‹å£°å­¦äº‹ä»¶å¹¶æŠ•å½±åˆ°åŠ¨æ€ç‚¹äº‘ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ¨¡æ‹Ÿæ‰‹æœ¯ä¸­éªŒè¯ï¼Œå®žçŽ°å‡†ç¡®3Då£°æºå®šä½å’Œç¨³å¥å¤šæ¨¡æ€æ•°æ®èžåˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Purpose: Surgical scene understanding is key to advancing computer-aided and
> intelligent surgical systems. Current approaches predominantly rely on visual
> data or end-to-end learning, which limits fine-grained contextual modeling.
> This work aims to enhance surgical scene representations by integrating 3D
> acoustic information, enabling temporally and spatially aware multimodal
> understanding of surgical environments.
>   Methods: We propose a novel framework for generating 4D audio-visual
> representations of surgical scenes by projecting acoustic localization
> information from a phased microphone array onto dynamic point clouds from an
> RGB-D camera. A transformer-based acoustic event detection module identifies
> relevant temporal segments containing tool-tissue interactions which are
> spatially localized in the audio-visual scene representation. The system was
> experimentally evaluated in a realistic operating room setup during simulated
> surgical procedures performed by experts.
>   Results: The proposed method successfully localizes surgical acoustic events
> in 3D space and associates them with visual scene elements. Experimental
> evaluation demonstrates accurate spatial sound localization and robust fusion
> of multimodal data, providing a comprehensive, dynamic representation of
> surgical activity.
>   Conclusion: This work introduces the first approach for spatial sound
> localization in dynamic surgical scenes, marking a significant advancement
> toward multimodal surgical scene representations. By integrating acoustic and
> visual data, the proposed framework enables richer contextual understanding and
> provides a foundation for future intelligent and autonomous surgical systems.

