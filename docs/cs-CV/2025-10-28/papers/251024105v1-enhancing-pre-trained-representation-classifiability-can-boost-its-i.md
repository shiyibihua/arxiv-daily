---
layout: default
title: Enhancing Pre-trained Representation Classifiability can Boost its Interpretability
---

# Enhancing Pre-trained Representation Classifiability can Boost its Interpretability

**arXiv**: [2510.24105v1](https://arxiv.org/abs/2510.24105) | [PDF](https://arxiv.org/pdf/2510.24105.pdf)

**ä½œè€…**: Shufan Shen, Zhaobo Qi, Junshu Sun, Qingming Huang, Qi Tian, Shuhui Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInherent Interpretability Scoreä»¥é‡åŒ–é¢„è®­ç»ƒè§†è§‰æ¨¡åž‹çš„è¡¨ç¤ºå¯è§£é‡Šæ€§ä¸Žå¯åˆ†ç±»æ€§æ­£ç›¸å…³**

**å…³é”®è¯**: `é¢„è®­ç»ƒè§†è§‰æ¨¡åž‹` `è¡¨ç¤ºå¯è§£é‡Šæ€§` `å¯åˆ†ç±»æ€§` `Inherent Interpretability Score` `è¯­ä¹‰é‡åŒ–` `å¾®è°ƒä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé¢„è®­ç»ƒè§†è§‰æ¨¡åž‹çš„è¡¨ç¤ºèƒ½å¦åŒæ—¶å®žçŽ°é«˜å¯è§£é‡Šæ€§å’Œé«˜å¯åˆ†ç±»æ€§
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽä¿¡æ¯æŸå¤±å®šä¹‰Inherent Interpretability Scoreï¼Œé‡åŒ–è¡¨ç¤ºä¸­å¯è§£é‡Šè¯­ä¹‰çš„æ¯”ä¾‹
3. å®žéªŒæˆ–æ•ˆæžœï¼šå‘çŽ°å¯è§£é‡Šæ€§ä¸Žå¯åˆ†ç±»æ€§æ­£ç›¸å…³ï¼Œå¹¶é€šè¿‡å¾®è°ƒæå‡ä¸¤è€…æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The visual representation of a pre-trained model prioritizes the
> classifiability on downstream tasks, while the widespread applications for
> pre-trained visual models have posed new requirements for representation
> interpretability. However, it remains unclear whether the pre-trained
> representations can achieve high interpretability and classifiability
> simultaneously. To answer this question, we quantify the representation
> interpretability by leveraging its correlation with the ratio of interpretable
> semantics within the representations. Given the pre-trained representations,
> only the interpretable semantics can be captured by interpretations, whereas
> the uninterpretable part leads to information loss. Based on this fact, we
> propose the Inherent Interpretability Score (IIS) that evaluates the
> information loss, measures the ratio of interpretable semantics, and quantifies
> the representation interpretability. In the evaluation of the representation
> interpretability with different classifiability, we surprisingly discover that
> the interpretability and classifiability are positively correlated, i.e.,
> representations with higher classifiability provide more interpretable
> semantics that can be captured in the interpretations. This observation further
> supports two benefits to the pre-trained representations. First, the
> classifiability of representations can be further improved by fine-tuning with
> interpretability maximization. Second, with the classifiability improvement for
> the representations, we obtain predictions based on their interpretations with
> less accuracy degradation. The discovered positive correlation and
> corresponding applications show that practitioners can unify the improvements
> in interpretability and classifiability for pre-trained vision models. Codes
> are available at https://github.com/ssfgunner/IIS.

