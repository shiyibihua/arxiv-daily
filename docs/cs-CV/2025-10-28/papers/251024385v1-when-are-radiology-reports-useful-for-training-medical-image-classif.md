---
layout: default
title: When are radiology reports useful for training medical image classifiers?
---

# When are radiology reports useful for training medical image classifiers?

**arXiv**: [2510.24385v1](https://arxiv.org/abs/2510.24385) | [PDF](https://arxiv.org/pdf/2510.24385.pdf)

**ä½œè€…**: Herman BergstrÃ¶m, Zhongqi Yue, Fredrik D. Johansson

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç³»ç»Ÿç ”ç©¶æ”¾å°„å­¦æŠ¥å‘Šåœ¨åŒ»å­¦å›¾åƒåˆ†ç±»è®­ç»ƒä¸­çš„é€‚ç”¨æ¡ä»¶ä¸Žæ–¹æ³•**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒåˆ†ç±»` `æ”¾å°„å­¦æŠ¥å‘Š` `é¢„è®­ç»ƒæ–¹æ³•` `å¾®è°ƒç­–ç•¥` `è¯Šæ–­ä»»åŠ¡` `é¢„åŽä»»åŠ¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ”¾å°„å­¦æŠ¥å‘Šä½•æ—¶èƒ½æå‡å›¾åƒåˆ†ç±»æ€§èƒ½ï¼Œé¿å…ä¾èµ–æ‰‹åŠ¨æ ‡æ³¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåœ¨é¢„è®­ç»ƒå’Œå¾®è°ƒé˜¶æ®µåˆ©ç”¨æŠ¥å‘Šï¼Œè¯„ä¼°è¯Šæ–­ä¸Žé¢„åŽä»»åŠ¡ã€‚
3. å®žéªŒæ•ˆæžœï¼šé¢„è®­ç»ƒå¯¹æ–‡æœ¬ç›¸å…³ä»»åŠ¡æœ‰ç›Šï¼Œå¾®è°ƒåœ¨æŸäº›åœºæ™¯ä¸‹å½±å“æ›´å¤§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Medical images used to train machine learning models are often accompanied by
> radiology reports containing rich expert annotations. However, relying on these
> reports as inputs for clinical prediction requires the timely manual work of a
> trained radiologist. This raises a natural question: when can radiology reports
> be leveraged during training to improve image-only classification? Prior works
> are limited to evaluating pre-trained image representations by fine-tuning them
> to predict diagnostic labels, often extracted from reports, ignoring tasks with
> labels that are weakly associated with the text. To address this gap, we
> conduct a systematic study of how radiology reports can be used during both
> pre-training and fine-tuning, across diagnostic and prognostic tasks (e.g.,
> 12-month readmission), and under varying training set sizes. Our findings
> reveal that: (1) Leveraging reports during pre-training is beneficial for
> downstream classification tasks where the label is well-represented in the
> text; however, pre-training through explicit image-text alignment can be
> detrimental in settings where it's not; (2) Fine-tuning with reports can lead
> to significant improvements and even have a larger impact than the pre-training
> method in certain settings. These results provide actionable insights into when
> and how to leverage privileged text data to train medical image classifiers
> while highlighting gaps in current research.

