---
layout: default
title: Enhancing CLIP Robustness via Cross-Modality Alignment
---

# Enhancing CLIP Robustness via Cross-Modality Alignment

**arXiv**: [2510.24038v1](https://arxiv.org/abs/2510.24038) | [PDF](https://arxiv.org/pdf/2510.24038.pdf)

**ä½œè€…**: Xingyu Zhu, Beier Zhu, Shuo Wang, Kesen Zhao, Hanwang Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCOLAæ¡†æž¶ä»¥è§£å†³CLIPåœ¨å¯¹æŠ—æ‰°åŠ¨ä¸‹çš„è·¨æ¨¡æ€ç‰¹å¾å¤±å‡†é—®é¢˜**

**å…³é”®è¯**: `è·¨æ¨¡æ€å¯¹é½` `å¯¹æŠ—é²æ£’æ€§` `æœ€ä¼˜ä¼ è¾“` `é›¶æ ·æœ¬åˆ†ç±»` `ç‰¹å¾æŠ•å½±`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šCLIPçš„å›¾åƒä¸Žæ–‡æœ¬ç‰¹å¾åœ¨å¯¹æŠ—æ‰°åŠ¨ä¸‹ä¸¥é‡å¤±å‡†ï¼Œå¯¼è‡´åˆ†ç±»æ€§èƒ½ä¸‹é™
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æœ€ä¼˜ä¼ è¾“ä¼˜åŒ–è·¨æ¨¡æ€å¯¹é½ï¼ŒåŒ…æ‹¬å­ç©ºé—´æŠ•å½±å’Œå±€éƒ¨ç»“æž„ä¸€è‡´æ€§å¢žå¼º
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨14ä¸ªåŸºå‡†æµ‹è¯•ä¸­å¹³å‡æå‡6.7%å¯¹æŠ—é²æ£’æ€§ï¼Œä¸”ä¿æŒå¹²å‡€æ ·æœ¬é«˜ç²¾åº¦

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-language models (VLMs) such as CLIP demonstrate strong generalization
> in zero-shot classification but remain highly vulnerable to adversarial
> perturbations. Existing methods primarily focus on adversarial fine-tuning or
> prompt optimization; they often overlook the gaps in CLIP's encoded features,
> which is shown as the text and image features lie far apart from each other.
> This misalignment is significantly amplified under adversarial perturbations,
> leading to severe degradation in classification performance. To address this
> problem, we propose Cross-modality Alignment, dubbed COLA, an optimal
> transport-based framework that explicitly addresses adversarial misalignment by
> restoring both global image-text alignment and local structural consistency in
> the feature space. (1) COLA first projects adversarial image embeddings onto a
> subspace spanned by class text features, effectively filtering out non-semantic
> distortions while preserving discriminative information. (2) It then models
> images and texts as discrete distributions over multiple augmented views and
> refines their alignment via OT, with the subspace projection seamlessly
> integrated into the cost computation. This design ensures stable cross-modal
> alignment even under adversarial conditions. COLA is training-free and
> compatible with existing fine-tuned models. Extensive evaluations across 14
> zero-shot classification benchmarks demonstrate the effectiveness of COLA,
> especially with an average improvement of 6.7% on ImageNet and its variants
> under PGD adversarial attacks, while maintaining high accuracy on clean
> samples.

