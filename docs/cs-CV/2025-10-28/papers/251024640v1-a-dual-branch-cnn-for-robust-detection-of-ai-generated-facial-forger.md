---
layout: default
title: A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries
---

# A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries

**arXiv**: [2510.24640v1](https://arxiv.org/abs/2510.24640) | [PDF](https://arxiv.org/pdf/2510.24640.pdf)

**ä½œè€…**: Xin Zhang, Yuqi Song, Fei Zuo

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒåˆ†æ”¯CNNä»¥æ£€æµ‹AIç”Ÿæˆé¢éƒ¨ä¼ªé€ ï¼Œæå‡AIå®‰å…¨ä¸Žåª’ä½“å®Œæ•´æ€§**

**å…³é”®è¯**: `é¢éƒ¨ä¼ªé€ æ£€æµ‹` `åŒåˆ†æ”¯CNN` `é¢‘åŸŸåˆ†æž` `é€šé“æ³¨æ„åŠ›` `ç»Ÿä¸€æŸå¤±å‡½æ•°` `AIå®‰å…¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç”ŸæˆAIæŠ€æœ¯å¯¼è‡´é¢éƒ¨ä¼ªé€ å›¾åƒæ³›æ»¥ï¼Œå¨èƒAIå®‰å…¨ä¸Žæ•°å­—åª’ä½“å¯ä¿¡åº¦ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆç©ºé—´ä¸Žé¢‘åŸŸåˆ†æ”¯ï¼Œä½¿ç”¨é€šé“æ³¨æ„åŠ›èžåˆç‰¹å¾ï¼Œè®¾è®¡ç»Ÿä¸€æŸå¤±å‡½æ•°å¢žå¼ºé²æ£’æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨DiFFåŸºå‡†æµ‹è¯•ä¸­è¡¨çŽ°ä¼˜å¼‚ï¼Œè¶…è¶Šäººç±»å¹³å‡å‡†ç¡®çŽ‡ï¼ŒéªŒè¯æ¨¡åž‹æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The rapid advancement of generative AI has enabled the creation of highly
> realistic forged facial images, posing significant threats to AI security,
> digital media integrity, and public trust. Face forgery techniques, ranging
> from face swapping and attribute editing to powerful diffusion-based image
> synthesis, are increasingly being used for malicious purposes such as
> misinformation, identity fraud, and defamation. This growing challenge
> underscores the urgent need for robust and generalizable face forgery detection
> methods as a critical component of AI security infrastructure. In this work, we
> propose a novel dual-branch convolutional neural network for face forgery
> detection that leverages complementary cues from both spatial and frequency
> domains. The RGB branch captures semantic information, while the frequency
> branch focuses on high-frequency artifacts that are difficult for generative
> models to suppress. A channel attention module is introduced to adaptively fuse
> these heterogeneous features, highlighting the most informative channels for
> forgery discrimination. To guide the network's learning process, we design a
> unified loss function, FSC Loss, that combines focal loss, supervised
> contrastive loss, and a frequency center margin loss to enhance class
> separability and robustness. We evaluate our model on the DiFF benchmark, which
> includes forged images generated from four representative methods:
> text-to-image, image-to-image, face swap, and face edit. Our method achieves
> strong performance across all categories and outperforms average human
> accuracy. These results demonstrate the model's effectiveness and its potential
> contribution to safeguarding AI ecosystems against visual forgery attacks.

