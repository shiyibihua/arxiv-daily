---
layout: default
title: SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through Synthetic Data Integration
---

# SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through Synthetic Data Integration

**arXiv**: [2510.24052v1](https://arxiv.org/abs/2510.24052) | [PDF](https://arxiv.org/pdf/2510.24052.pdf)

**ä½œè€…**: Jongsuk Kim, Jaeyoung Lee, Gyojin Han, Dongjae Lee, Minki Jeong, Junmo Kim

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSynADæ¡†æž¶ï¼Œé€šè¿‡åˆæˆæ•°æ®é›†æˆå¢žå¼ºç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ¨¡åž‹**

**å…³é”®è¯**: `ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶` `åˆæˆæ•°æ®é›†æˆ` `é¸Ÿçž°å›¾ç‰¹å¾` `å¤šæ™ºèƒ½ä½“åœºæ™¯` `å®‰å…¨æ€§èƒ½å¢žå¼º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçœŸå®žä¸–ç•Œæ•°æ®é™åˆ¶è®­ç»ƒåœºæ™¯å¤šæ ·æ€§ï¼Œåˆæˆåœºæ™¯ç¼ºä¹æŒ‡å®šè‡ªè½¦å’Œä¼ æ„Ÿå™¨è¾“å…¥ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåœ¨å¤šæ™ºèƒ½ä½“åˆæˆåœºæ™¯ä¸­æŒ‡å®šè‡ªè½¦ï¼Œä½¿ç”¨Map-to-BEVç½‘ç»œç”Ÿæˆé¸Ÿçž°å›¾ç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒæ˜¾ç¤ºSynADæœ‰æ•ˆæ•´åˆç»„ä»¶ï¼Œæ˜¾è‘—æå‡å®‰å…¨æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advancements in deep learning and the availability of high-quality
> real-world driving datasets have propelled end-to-end autonomous driving.
> Despite this progress, relying solely on real-world data limits the variety of
> driving scenarios for training. Synthetic scenario generation has emerged as a
> promising solution to enrich the diversity of training data; however, its
> application within E2E AD models remains largely unexplored. This is primarily
> due to the absence of a designated ego vehicle and the associated sensor
> inputs, such as camera or LiDAR, typically provided in real-world scenarios. To
> address this gap, we introduce SynAD, the first framework designed to enhance
> real-world E2E AD models using synthetic data. Our method designates the agent
> with the most comprehensive driving information as the ego vehicle in a
> multi-agent synthetic scenario. We further project path-level scenarios onto
> maps and employ a newly developed Map-to-BEV Network to derive bird's-eye-view
> features without relying on sensor inputs. Finally, we devise a training
> strategy that effectively integrates these map-based synthetic data with real
> driving data. Experimental results demonstrate that SynAD effectively
> integrates all components and notably enhances safety performance. By bridging
> synthetic scenario generation and E2E AD, SynAD paves the way for more
> comprehensive and robust autonomous driving models.

