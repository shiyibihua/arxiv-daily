---
layout: default
title: OmniText: A Training-Free Generalist for Controllable Text-Image Manipulation
---

# OmniText: A Training-Free Generalist for Controllable Text-Image Manipulation

**arXiv**: [2510.24093v1](https://arxiv.org/abs/2510.24093) | [PDF](https://arxiv.org/pdf/2510.24093.pdf)

**ä½œè€…**: Agus Gunawan, Samuel Teodoro, Yun Chen, Soo Ye Kim, Jihyong Oh, Munchurl Kim

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmniTextè®­ç»ƒå…è´¹é€šç”¨æ–¹æ³•ï¼Œè§£å†³æ–‡æœ¬å›¾åƒæ“ä½œä¸­çš„æ–‡æœ¬ç§»é™¤ã€é£Žæ ¼æŽ§åˆ¶å’Œé‡å¤å­—æ¯é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ–‡æœ¬å›¾åƒæ“ä½œ` `è®­ç»ƒå…è´¹æ–¹æ³•` `æ³¨æ„åŠ›æœºåˆ¶` `æ–‡æœ¬ç§»é™¤` `é£Žæ ¼æŽ§åˆ¶` `åŸºå‡†æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–‡æœ¬ä¿®å¤æ–¹æ³•æ— æ³•ç§»é™¤æ–‡æœ¬ã€ç¼ºä¹é£Žæ ¼æŽ§åˆ¶ä¸”æ˜“ç”Ÿæˆé‡å¤å­—æ¯ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨è‡ªæ³¨æ„åŠ›åè½¬å’Œäº¤å‰æ³¨æ„åŠ›é‡åˆ†å¸ƒå®žçŽ°æ–‡æœ¬ç§»é™¤ä¸Žé£Žæ ¼å†…å®¹æŽ§åˆ¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨OmniText-BenchåŸºå‡†ä¸Šå®žçŽ°SOTAæ€§èƒ½ï¼Œä¸Žä¸“ä¸šæ–¹æ³•ç›¸å½“ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advancements in diffusion-based text synthesis have demonstrated
> significant performance in inserting and editing text within images via
> inpainting. However, despite the potential of text inpainting methods, three
> key limitations hinder their applicability to broader Text Image Manipulation
> (TIM) tasks: (i) the inability to remove text, (ii) the lack of control over
> the style of rendered text, and (iii) a tendency to generate duplicated
> letters. To address these challenges, we propose OmniText, a training-free
> generalist capable of performing a wide range of TIM tasks. Specifically, we
> investigate two key properties of cross- and self-attention mechanisms to
> enable text removal and to provide control over both text styles and content.
> Our findings reveal that text removal can be achieved by applying
> self-attention inversion, which mitigates the model's tendency to focus on
> surrounding text, thus reducing text hallucinations. Additionally, we
> redistribute cross-attention, as increasing the probability of certain text
> tokens reduces text hallucination. For controllable inpainting, we introduce
> novel loss functions in a latent optimization framework: a cross-attention
> content loss to improve text rendering accuracy and a self-attention style loss
> to facilitate style customization. Furthermore, we present OmniText-Bench, a
> benchmark dataset for evaluating diverse TIM tasks. It includes input images,
> target text with masks, and style references, covering diverse applications
> such as text removal, rescaling, repositioning, and insertion and editing with
> various styles. Our OmniText framework is the first generalist method capable
> of performing diverse TIM tasks. It achieves state-of-the-art performance
> across multiple tasks and metrics compared to other text inpainting methods and
> is comparable with specialist methods.

