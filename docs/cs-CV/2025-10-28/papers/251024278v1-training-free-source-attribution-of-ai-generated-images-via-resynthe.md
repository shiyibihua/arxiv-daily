---
layout: default
title: Training-free Source Attribution of AI-generated Images via Resynthesis
---

# Training-free Source Attribution of AI-generated Images via Resynthesis

**arXiv**: [2510.24278v1](https://arxiv.org/abs/2510.24278) | [PDF](https://arxiv.org/pdf/2510.24278.pdf)

**ä½œè€…**: Pietro Bongini, Valentina Molinari, Andrea Costanzo, Benedetta Tondi, Mauro Barni

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå›¾åƒé‡åˆæˆçš„å…è®­ç»ƒå•æ ·æœ¬å½’å±žæ–¹æ³•ï¼Œä»¥è§£å†³æ•°æ®ç¨€ç¼ºä¸‹çš„AIç”Ÿæˆå›¾åƒæ¥æºå½’å±žé—®é¢˜ã€‚**

**å…³é”®è¯**: `å›¾åƒæ¥æºå½’å±ž` `å…è®­ç»ƒæ–¹æ³•` `å›¾åƒé‡åˆæˆ` `å°‘æ ·æœ¬å­¦ä¹ ` `é›¶æ ·æœ¬åˆ†ç±»` `åˆæˆå›¾åƒæ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåœ¨æ•°æ®ç¨€ç¼ºæ¡ä»¶ä¸‹ï¼Œå®žçŽ°AIç”Ÿæˆå›¾åƒçš„å°‘æ ·æœ¬æˆ–é›¶æ ·æœ¬æ¥æºå½’å±žã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡ç”Ÿæˆæè¿°æç¤ºï¼Œç”¨å€™é€‰æ¥æºé‡åˆæˆå›¾åƒï¼Œå¹¶åœ¨ç‰¹å¾ç©ºé—´ä¸­æ¯”è¾ƒä¸ŽåŽŸå›¾çš„ç›¸ä¼¼åº¦ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ–°å»ºæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•ä¼˜äºŽçŽ°æœ‰å°‘æ ·æœ¬æ–¹æ³•ï¼Œå°¤å…¶åœ¨è®­ç»ƒæ ·æœ¬æœ‰é™æ—¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Synthetic image source attribution is a challenging task, especially in data
> scarcity conditions requiring few-shot or zero-shot classification
> capabilities. We present a new training-free one-shot attribution method based
> on image resynthesis. A prompt describing the image under analysis is
> generated, then it is used to resynthesize the image with all the candidate
> sources. The image is attributed to the model which produced the resynthesis
> closest to the original image in a proper feature space. We also introduce a
> new dataset for synthetic image attribution consisting of face images from
> commercial and open-source text-to-image generators. The dataset provides a
> challenging attribution framework, useful for developing new attribution models
> and testing their capabilities on different generative architectures. The
> dataset structure allows to test approaches based on resynthesis and to compare
> them to few-shot methods. Results from state-of-the-art few-shot approaches and
> other baselines show that the proposed resynthesis method outperforms existing
> techniques when only a few samples are available for training or fine-tuning.
> The experiments also demonstrate that the new dataset is a challenging one and
> represents a valuable benchmark for developing and evaluating future few-shot
> and zero-shot methods.

