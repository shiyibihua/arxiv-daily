---
layout: default
title: OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents
---

# OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents

**arXiv**: [2510.24563v1](https://arxiv.org/abs/2510.24563) | [PDF](https://arxiv.org/pdf/2510.24563.pdf)

**ä½œè€…**: Hongrui Jia, Jitong Liao, Xi Zhang, Haiyang Xu, Tianbao Xie, Chaoya Jiang, Ming Yan, Si Liu, Wei Ye, Fei Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOSWorld-MCPåŸºå‡†ä»¥å…¬å¹³è¯„ä¼°è®¡ç®—æœºä½¿ç”¨ä»£ç†çš„å·¥å…·è°ƒç”¨ä¸ŽGUIæ“ä½œèƒ½åŠ›**

**å…³é”®è¯**: `è®¡ç®—æœºä½¿ç”¨ä»£ç†` `å·¥å…·è°ƒç”¨åŸºå‡†` `å¤šæ¨¡æ€è¯„ä¼°` `æ¨¡åž‹ä¸Šä¸‹æ–‡åè®®` `è‡ªåŠ¨åŒ–ä»£ç ç”Ÿæˆ` `ä»»åŠ¡æˆåŠŸçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è¯„ä¼°å¤šå…³æ³¨GUIäº¤äº’ï¼Œå¿½è§†å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œå¯¼è‡´ä¸å…¬å¹³æ¯”è¾ƒ
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡è‡ªåŠ¨åŒ–ä»£ç ç”Ÿæˆå’Œæ‰‹åŠ¨éªŒè¯æž„å»º158ä¸ªé«˜è´¨é‡å·¥å…·ï¼Œè¦†ç›–7ä¸ªå¸¸è§åº”ç”¨
3. å®žéªŒæˆ–æ•ˆæžœï¼šMCPå·¥å…·æå‡ä»»åŠ¡æˆåŠŸçŽ‡ï¼Œä½†æœ€å¼ºæ¨¡åž‹å·¥å…·è°ƒç”¨çŽ‡ä»…36.3%ï¼Œæ˜¾ç¤ºæ”¹è¿›ç©ºé—´

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> With advances in decision-making and reasoning capabilities, multimodal
> agents show strong potential in computer application scenarios. Past
> evaluations have mainly assessed GUI interaction skills, while tool invocation
> abilities, such as those enabled by the Model Context Protocol (MCP), have been
> largely overlooked. Comparing agents with integrated tool invocation to those
> evaluated only on GUI interaction is inherently unfair. We present OSWorld-MCP,
> the first comprehensive and fair benchmark for assessing computer-use agents'
> tool invocation, GUI operation, and decision-making abilities in a real-world
> environment. We design a novel automated code-generation pipeline to create
> tools and combine them with a curated selection from existing tools. Rigorous
> manual validation yields 158 high-quality tools (covering 7 common
> applications), each verified for correct functionality, practical
> applicability, and versatility. Extensive evaluations of state-of-the-art
> multimodal agents on OSWorld-MCP show that MCP tools generally improve task
> success rates (e.g., from 8.3% to 20.4% for OpenAI o3 at 15 steps, from 40.1%
> to 43.3% for Claude 4 Sonnet at 50 steps), underscoring the importance of
> assessing tool invocation capabilities. However, even the strongest models have
> relatively low tool invocation rates, Only 36.3%, indicating room for
> improvement and highlighting the benchmark's challenge. By explicitly measuring
> MCP tool usage skills, OSWorld-MCP deepens understanding of multimodal agents
> and sets a new standard for evaluating performance in complex, tool-assisted
> environments. Our code, environment, and data are publicly available at
> https://osworld-mcp.github.io.

