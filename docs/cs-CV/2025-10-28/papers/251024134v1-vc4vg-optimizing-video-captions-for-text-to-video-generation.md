---
layout: default
title: VC4VG: Optimizing Video Captions for Text-to-Video Generation
---

# VC4VG: Optimizing Video Captions for Text-to-Video Generation

**arXiv**: [2510.24134v1](https://arxiv.org/abs/2510.24134) | [PDF](https://arxiv.org/pdf/2510.24134.pdf)

**ä½œè€…**: Yang Du, Zhuoran Lin, Kaiqiang Song, Biao Wang, Zhicheng Zheng, Tiezheng Ge, Bo Zheng, Qin Jin

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVC4VGæ¡†æ¶ä¼˜åŒ–è§†é¢‘å­—å¹•ä»¥æå‡æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ€§èƒ½**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆ` `è§†é¢‘å­—å¹•ä¼˜åŒ–` `åŸºå‡†æ„å»º` `å¤šç»´åº¦è¯„ä¼°` `å­—å¹•è®¾è®¡æ–¹æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆä¸­é«˜è´¨é‡è§†é¢‘-æ–‡æœ¬å¯¹ä¼˜åŒ–ç­–ç•¥ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡å¤šç»´åº¦å­—å¹•åˆ†è§£ä¸ä¼˜åŒ–æ–¹æ³•ï¼Œæ„å»ºVC4VG-BenchåŸºå‡†ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå¾®è°ƒå®éªŒæ˜¾ç¤ºå­—å¹•è´¨é‡ä¸è§†é¢‘ç”Ÿæˆæ€§èƒ½å¼ºç›¸å…³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in text-to-video (T2V) generation highlight the critical role
> of high-quality video-text pairs in training models capable of producing
> coherent and instruction-aligned videos. However, strategies for optimizing
> video captions specifically for T2V training remain underexplored. In this
> paper, we introduce VC4VG (Video Captioning for Video Generation), a
> comprehensive caption optimization framework tailored to the needs of T2V
> models.We begin by analyzing caption content from a T2V perspective,
> decomposing the essential elements required for video reconstruction into
> multiple dimensions, and proposing a principled caption design methodology. To
> support evaluation, we construct VC4VG-Bench, a new benchmark featuring
> fine-grained, multi-dimensional, and necessity-graded metrics aligned with
> T2V-specific requirements.Extensive T2V fine-tuning experiments demonstrate a
> strong correlation between improved caption quality and video generation
> performance, validating the effectiveness of our approach. We release all
> benchmark tools and code at https://github.com/qyr0403/VC4VG to support further
> research.

