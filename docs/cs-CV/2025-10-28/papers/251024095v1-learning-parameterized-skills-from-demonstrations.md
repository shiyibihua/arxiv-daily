---
layout: default
title: Learning Parameterized Skills from Demonstrations
---

# Learning Parameterized Skills from Demonstrations

**arXiv**: [2510.24095v1](https://arxiv.org/abs/2510.24095) | [PDF](https://arxiv.org/pdf/2510.24095.pdf)

**ä½œè€…**: Vedant Gupta, Haotian Fu, Calvin Luo, Yiding Jiang, George Konidaris

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDEPSç®—æ³•ä»Žä¸“å®¶æ¼”ç¤ºä¸­å­¦ä¹ å‚æ•°åŒ–æŠ€èƒ½ï¼Œä»¥æå‡æœªè§ä»»åŠ¡çš„æ³›åŒ–èƒ½åŠ›ã€‚**

**å…³é”®è¯**: `å‚æ•°åŒ–æŠ€èƒ½å­¦ä¹ ` `ä¸“å®¶æ¼”ç¤º` `å˜åˆ†æŽ¨ç†` `ä¿¡æ¯è®ºæ­£åˆ™åŒ–` `å¤šä»»åŠ¡æ³›åŒ–` `å…ƒç­–ç•¥å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä»Žå¤šä»»åŠ¡ä¸“å®¶æ¼”ç¤ºä¸­å­¦ä¹ å‚æ•°åŒ–æŠ€èƒ½ï¼Œé¿å…æ½œåœ¨å˜é‡æ¨¡åž‹çš„é€€åŒ–é—®é¢˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆæ—¶é—´å˜åˆ†æŽ¨ç†å’Œä¿¡æ¯è®ºæ­£åˆ™åŒ–ï¼Œè”åˆå­¦ä¹ æŠ€èƒ½ç­–ç•¥å’Œå…ƒç­–ç•¥ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨LIBEROå’ŒMetaWorldåŸºå‡†ä¸Šä¼˜äºŽå¤šä»»åŠ¡å’ŒæŠ€èƒ½å­¦ä¹ åŸºçº¿æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present DEPS, an end-to-end algorithm for discovering parameterized skills
> from expert demonstrations. Our method learns parameterized skill policies
> jointly with a meta-policy that selects the appropriate discrete skill and
> continuous parameters at each timestep. Using a combination of temporal
> variational inference and information-theoretic regularization methods, we
> address the challenge of degeneracy common in latent variable models, ensuring
> that the learned skills are temporally extended, semantically meaningful, and
> adaptable. We empirically show that learning parameterized skills from
> multitask expert demonstrations significantly improves generalization to unseen
> tasks. Our method outperforms multitask as well as skill learning baselines on
> both LIBERO and MetaWorld benchmarks. We also demonstrate that DEPS discovers
> interpretable parameterized skills, such as an object grasping skill whose
> continuous arguments define the grasp location.

