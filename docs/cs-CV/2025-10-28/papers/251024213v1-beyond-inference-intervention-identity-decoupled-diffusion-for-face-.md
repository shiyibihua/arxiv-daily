---
layout: default
title: Beyond Inference Intervention: Identity-Decoupled Diffusion for Face Anonymization
---

# Beyond Inference Intervention: Identity-Decoupled Diffusion for Face Anonymization

**arXiv**: [2510.24213v1](https://arxiv.org/abs/2510.24213) | [PDF](https://arxiv.org/pdf/2510.24213.pdf)

**ä½œè€…**: Haoxin Yang, Yihong Lin, Jingdan Kang, Xuemiao Xu, Yue Li, Cheng Xu, Shengfeng He

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIDÂ²Faceæ¡†æž¶ä»¥è§£å†³äººè„¸åŒ¿ååŒ–ä¸­èº«ä»½ä¸Žéžèº«ä»½å±žæ€§çº ç¼ é—®é¢˜**

**å…³é”®è¯**: `äººè„¸åŒ¿ååŒ–` `æ‰©æ•£æ¨¡åž‹` `èº«ä»½è§£è€¦` `æ½œåœ¨ç©ºé—´å­¦ä¹ ` `æŽ¨ç†ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ‰©æ•£æ¨¡åž‹ä¾èµ–æŽ¨ç†æ—¶å¹²é¢„ï¼Œå¯¼è‡´åˆ†å¸ƒåç§»å’Œå±žæ€§çº ç¼ ï¼Œé™ä½Žè§†è§‰ä¿çœŸåº¦ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡æ¡ä»¶æ‰©æ•£æ¨¡åž‹ï¼Œé€šè¿‡èº«ä»½è§£è€¦æ½œåœ¨é‡ç»„å™¨å®žçŽ°èº«ä»½ä¸Žéžèº«ä»½å±žæ€§çš„æ˜¾å¼è§£ç¼ ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šIDÂ²Faceåœ¨è§†è§‰è´¨é‡ã€èº«ä»½æŠ‘åˆ¶å’Œæ•ˆç”¨ä¿æŒæ–¹é¢ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Face anonymization aims to conceal identity information while preserving
> non-identity attributes. Mainstream diffusion models rely on inference-time
> interventions such as negative guidance or energy-based optimization, which are
> applied post-training to suppress identity features. These interventions often
> introduce distribution shifts and entangle identity with non-identity
> attributes, degrading visual fidelity and data utility. To address this, we
> propose \textbf{ID\textsuperscript{2}Face}, a training-centric anonymization
> framework that removes the need for inference-time optimization. The rationale
> of our method is to learn a structured latent space where identity and
> non-identity information are explicitly disentangled, enabling direct and
> controllable anonymization at inference. To this end, we design a conditional
> diffusion model with an identity-masked learning scheme. An Identity-Decoupled
> Latent Recomposer uses an Identity Variational Autoencoder to model identity
> features, while non-identity attributes are extracted from same-identity pairs
> and aligned through bidirectional latent alignment. An Identity-Guided Latent
> Harmonizer then fuses these representations via soft-gating conditioned on
> noisy feature prediction. The model is trained with a recomposition-based
> reconstruction loss to enforce disentanglement. At inference, anonymization is
> achieved by sampling a random identity vector from the learned identity space.
> To further suppress identity leakage, we introduce an Orthogonal Identity
> Mapping strategy that enforces orthogonality between sampled and source
> identity vectors. Experiments demonstrate that ID\textsuperscript{2}Face
> outperforms existing methods in visual quality, identity suppression, and
> utility preservation.

