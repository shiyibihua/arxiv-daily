---
layout: default
title: ResNet: Enabling Deep Convolutional Neural Networks through Residual Learning
---

# ResNet: Enabling Deep Convolutional Neural Networks through Residual Learning

**arXiv**: [2510.24036v1](https://arxiv.org/abs/2510.24036) | [PDF](https://arxiv.org/pdf/2510.24036.pdf)

**ä½œè€…**: Xingyu Liu, Kun Ming Goh

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ®‹å·®ç½‘ç»œä»¥è§£å†³æ·±åº¦å·ç§¯ç¥žç»ç½‘ç»œè®­ç»ƒä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜**

**å…³é”®è¯**: `æ®‹å·®ç½‘ç»œ` `è·³è·ƒè¿žæŽ¥` `æ¢¯åº¦æ¶ˆå¤±` `æ·±åº¦å·ç§¯ç¥žç»ç½‘ç»œ` `CIFAR-10`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ·±åº¦å·ç§¯ç¥žç»ç½‘ç»œè®­ç»ƒå›°éš¾ï¼Œä¸»è¦ç”±äºŽæ¢¯åº¦æ¶ˆå¤±é—®é¢˜
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥è·³è·ƒè¿žæŽ¥ï¼Œä½¿æ¢¯åº¦å¯ç›´æŽ¥é€šè¿‡æ·å¾„ä¼ æ’­
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CIFAR-10æ•°æ®é›†ä¸Šï¼ŒResNet-18å‡†ç¡®çŽ‡è¾¾89.9%ï¼Œä¼˜äºŽä¼ ç»Ÿæ·±åº¦CNN

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Convolutional Neural Networks (CNNs) has revolutionized computer vision, but
> training very deep networks has been challenging due to the vanishing gradient
> problem. This paper explores Residual Networks (ResNet), introduced by He et
> al. (2015), which overcomes this limitation by using skip connections. ResNet
> enables the training of networks with hundreds of layers by allowing gradients
> to flow directly through shortcut connections that bypass intermediate layers.
> In our implementation on the CIFAR-10 dataset, ResNet-18 achieves 89.9%
> accuracy compared to 84.1% for a traditional deep CNN of similar depth, while
> also converging faster and training more stably.

