---
layout: default
title: Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?
---

# Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?

**arXiv**: [2510.24709v1](https://arxiv.org/abs/2510.24709) | [PDF](https://arxiv.org/pdf/2510.24709.pdf)

**ä½œè€…**: Yihao Li, Saeed Salehi, Lyle Ungar, Konrad P. Kording

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºè‡ªç›‘ç£ViTä¸­è‡ªç„¶æ¶ŒçŽ°å¯¹è±¡ç»‘å®šèƒ½åŠ›ï¼Œæå‡ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½**

**å…³é”®è¯**: `è§†è§‰Transformer` `å¯¹è±¡ç»‘å®š` `è‡ªç›‘ç£å­¦ä¹ ` `æ³¨æ„åŠ›æœºåˆ¶` `è¡¥ä¸åµŒå…¥` `ä¸‹æ¸¸ä»»åŠ¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé¢„è®­ç»ƒViTæ˜¯å¦è‡ªç„¶å…·å¤‡å¯¹è±¡ç»‘å®šèƒ½åŠ›ï¼Œå³è¯†åˆ«å›¾åƒè¡¥ä¸æ˜¯å¦å±žäºŽåŒä¸€å¯¹è±¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨ç›¸ä¼¼æ€§æŽ¢é’ˆä»ŽViTè¡¥ä¸åµŒå…¥è§£ç IsSameObjectå±žæ€§ï¼Œåˆ†æžå…¶ç¼–ç ä¸Žæ³¨æ„åŠ›å¼•å¯¼ã€‚
3. å®žéªŒæ•ˆæžœï¼šè‡ªç›‘ç£ViTå¯¹è±¡ç»‘å®šå‡†ç¡®çŽ‡è¶…90%ï¼Œä¼˜äºŽç›‘ç£æ¨¡åž‹ï¼Œæ¶ˆèžå®žéªŒæ˜¾ç¤ºå…¶æœåŠ¡äºŽé¢„è®­ç»ƒç›®æ ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Object binding, the brain's ability to bind the many features that
> collectively represent an object into a coherent whole, is central to human
> cognition. It groups low-level perceptual features into high-level object
> representations, stores those objects efficiently and compositionally in
> memory, and supports human reasoning about individual object instances. While
> prior work often imposes object-centric attention (e.g., Slot Attention)
> explicitly to probe these benefits, it remains unclear whether this ability
> naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they
> could: recognizing which patches belong to the same object should be useful for
> downstream prediction and thus guide attention. Motivated by the quadratic
> nature of self-attention, we hypothesize that ViTs represent whether two
> patches belong to the same object, a property we term IsSameObject. We decode
> IsSameObject from patch embeddings across ViT layers using a similarity probe,
> which reaches over 90% accuracy. Crucially, this object-binding capability
> emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker
> in ImageNet-supervised models, suggesting that binding is not a trivial
> architectural artifact, but an ability acquired through specific pretraining
> objectives. We further discover that IsSameObject is encoded in a
> low-dimensional subspace on top of object features, and that this signal
> actively guides attention. Ablating IsSameObject from model activations
> degrades downstream performance and works against the learning objective,
> implying that emergent object binding naturally serves the pretraining
> objective. Our findings challenge the view that ViTs lack object binding and
> highlight how symbolic knowledge of "which parts belong together" emerges
> naturally in a connectionist system.

