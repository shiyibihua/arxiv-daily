---
layout: default
title: Reasoning Visual Language Model for Chest X-Ray Analysis
---

# Reasoning Visual Language Model for Chest X-Ray Analysis

**arXiv**: [2510.23968v1](https://arxiv.org/abs/2510.23968) | [PDF](https://arxiv.org/pdf/2510.23968.pdf)

**ä½œè€…**: Andriy Myronenko, Dong Yang, Baris Turkbey, Mariam Aboian, Sena Azamat, Esra Akcicek, Hongxu Yin, Pavlo Molchanov, Marc Edgar, Yufan He, Pengfei Guo, Yucheng Tang, Daguang Xu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“åˆæ€ç»´é“¾æŽ¨ç†çš„è§†è§‰è¯­è¨€æ¨¡åž‹ä»¥æå‡èƒ¸éƒ¨Xå…‰åˆ†æžçš„é€æ˜Žåº¦å’Œå‡†ç¡®æ€§**

**å…³é”®è¯**: `èƒ¸éƒ¨Xå…‰åˆ†æž` `æ€ç»´é“¾æŽ¨ç†` `è§†è§‰è¯­è¨€æ¨¡åž‹` `å¯è§£é‡ŠAI` `å¼ºåŒ–å­¦ä¹ ` `åŒ»å­¦å›¾åƒå¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§†è§‰è¯­è¨€æ¨¡åž‹åœ¨åŒ»å­¦å›¾åƒåˆ†æžä¸­ç¼ºä¹é€æ˜ŽæŽ¨ç†ï¼Œæ— æ³•æä¾›ä¸´åºŠæ‰€éœ€çš„é€æ­¥è§£é‡Šã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒï¼ŒåŒ…æ‹¬æŽ¨ç†é£Žæ ¼ç›‘ç£å¾®è°ƒå’ŒåŸºäºŽå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åˆ†å¸ƒå¤–è¯„ä¼°ä¸­å®žçŽ°ç«žäº‰æ€§åˆ†ç±»æ€§èƒ½ï¼Œå¹¶é€šè¿‡ä¸“å®¶ç ”ç©¶æé«˜æŠ¥å‘Šæ•ˆçŽ‡å’Œå¯ä¿¡åº¦ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-language models (VLMs) have shown strong promise for medical image
> analysis, but most remain opaque, offering predictions without the transparent,
> stepwise reasoning clinicians rely on. We present a framework that brings
> chain-of-thought (CoT) reasoning to chest X-ray interpretation. Inspired by
> reasoning-first training paradigms, our approach is designed to learn how
> experts reason, not just what they conclude, by aligning intermediate steps
> with observable image evidence and radiology workflow. Beyond accuracy, the
> explicit reasoning traces support clinical auditability: they reveal why a
> conclusion was reached, which alternatives were considered, and where
> uncertainty remains, enabling quality assurance, error analysis, and safer
> human-AI collaboration.
>   Our model couples high-fidelity visual encoding with a two-stage training
> recipe: a reasoning-style supervised fine-tuning (SFT) followed by
> reinforcement learning (RL) that uses verifiable rewards over a list of X-ray
> abnormalities. The model outputs reasoning that mirrors radiologists systematic
> thought process, uncertainty, and differential diagnosis. In
> out-of-distribution evaluation, the approach achieves competitive multi-label
> classification while improving interpretability. In a reader study with expert
> radiologists, full reasoning traces increased confidence, supported error
> auditing, and reduced time to finalize reports. We release code and the model
> NV-Reason-CXR-3B to support community progress toward trustworthy, explainable
> AI in chest radiography and other medical imaging tasks where reasoning quality
> is as critical as prediction quality.

