---
layout: default
title: Compositional Image Synthesis with Inference-Time Scaling
---

# Compositional Image Synthesis with Inference-Time Scaling

**arXiv**: [2510.24133v1](https://arxiv.org/abs/2510.24133) | [PDF](https://arxiv.org/pdf/2510.24133.pdf)

**ä½œè€…**: Minsuk Ji, Sanghyeok Lee, Namhyuk Ahn

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè®­ç»ƒå…è´¹æ¡†æž¶ï¼Œç»“åˆå¯¹è±¡ä¸­å¿ƒæ–¹æ³•ä¸Žè‡ªç²¾ç‚¼ï¼Œæå‡æ–‡æœ¬åˆ°å›¾åƒåˆæˆçš„å¸ƒå±€å¿ å®žåº¦ã€‚**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒåˆæˆ` `å¸ƒå±€å¿ å®žåº¦` `å¯¹è±¡ä¸­å¿ƒæ–¹æ³•` `è‡ªç²¾ç‚¼` `æŽ¨ç†æ—¶ç¼©æ”¾` `è§†è§‰è¯­è¨€æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°ä»£æ–‡æœ¬åˆ°å›¾åƒæ¨¡åž‹åœ¨ç»„åˆæ€§ä¸Šè¡¨çŽ°ä¸ä½³ï¼Œå¸¸æ— æ³•å‡†ç¡®æ¸²æŸ“å¯¹è±¡æ•°é‡ã€å±žæ€§å’Œç©ºé—´å…³ç³»ã€‚
2. åˆ©ç”¨å¤§è¯­è¨€æ¨¡åž‹åˆæˆæ˜¾å¼å¸ƒå±€ï¼Œå¹¶é€šè¿‡å¯¹è±¡ä¸­å¿ƒè§†è§‰è¯­è¨€æ¨¡åž‹è¿­ä»£é‡æŽ’å€™é€‰å›¾åƒä»¥å¯¹é½æç¤ºã€‚
3. æ¡†æž¶åœ¨æŽ¨ç†æ—¶ç¼©æ”¾ï¼Œå®žçŽ°æ›´å¼ºçš„åœºæ™¯å¯¹é½ï¼ŒåŒæ—¶ä¿æŒç¾Žå­¦è´¨é‡ï¼Œä»£ç å·²å¼€æºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite their impressive realism, modern text-to-image models still struggle
> with compositionality, often failing to render accurate object counts,
> attributes, and spatial relations. To address this challenge, we present a
> training-free framework that combines an object-centric approach with
> self-refinement to improve layout faithfulness while preserving aesthetic
> quality. Specifically, we leverage large language models (LLMs) to synthesize
> explicit layouts from input prompts, and we inject these layouts into the image
> generation process, where a object-centric vision-language model (VLM) judge
> reranks multiple candidates to select the most prompt-aligned outcome
> iteratively. By unifying explicit layout-grounding with self-refine-based
> inference-time scaling, our framework achieves stronger scene alignment with
> prompts compared to recent text-to-image models. The code are available at
> https://github.com/gcl-inha/ReFocus.

