---
layout: default
title: Calibrating MLLM-as-a-judge via Multimodal Bayesian Prompt Ensembles
---

# Calibrating MLLM-as-a-judge via Multimodal Bayesian Prompt Ensembles

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.08777" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.08777v1</a>
  <a href="https://arxiv.org/pdf/2509.08777.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.08777v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.08777v1', 'Calibrating MLLM-as-a-judge via Multimodal Bayesian Prompt Ensembles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Eric Slyman, Mehrab Tanjim, Kushal Kafle, Stefan Lee

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-10

**å¤‡æ³¨**: 17 pages, 8 figures, Accepted at ICCV 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMMBæ–¹æ³•ï¼Œé€šè¿‡å¤šæ¨¡æ€è´å¶æ–¯æç¤ºé›†æˆæ ¡å‡†MLLMåœ¨æ–‡å›¾ç”Ÿæˆè¯„åˆ¤ä¸­çš„åå·®ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ–‡å›¾ç”Ÿæˆ` `æç¤ºå·¥ç¨‹` `è´å¶æ–¯ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„MLLMè¯„åˆ¤æ¨¡å‹åœ¨è¯„ä¼°æ–‡å›¾ç”Ÿæˆä»»åŠ¡æ—¶å­˜åœ¨åå·®ã€è¿‡åº¦è‡ªä¿¡ä»¥åŠè·¨åŸŸè¡¨ç°ä¸ä¸€è‡´ç­‰é—®é¢˜ã€‚
2. MMBæ–¹æ³•é€šè¿‡å›¾åƒèšç±»å¢å¼ºè´å¶æ–¯æç¤ºé›†æˆï¼ŒåŠ¨æ€åœ°æ ¹æ®å›¾åƒè§†è§‰ç‰¹å¾åˆ†é…æç¤ºæƒé‡ï¼Œä»è€Œæå‡è¯„åˆ¤çš„å‡†ç¡®æ€§å’Œæ ¡å‡†ã€‚
3. åœ¨HPSv2å’ŒMJBenchåŸºå‡†æµ‹è¯•ä¸­ï¼ŒMMBåœ¨ä¸äººç±»æ ‡æ³¨å¯¹é½å’Œæ ¡å‡†æ–¹é¢ä¼˜äºç°æœ‰åŸºçº¿ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰è¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨äºè¯„ä¼°æ–‡æœ¬åˆ°å›¾åƒï¼ˆTTIï¼‰ç”Ÿæˆç³»ç»Ÿï¼ŒåŸºäºè§†è§‰å’Œæ–‡æœ¬ä¸Šä¸‹æ–‡æä¾›è‡ªåŠ¨åˆ¤æ–­ã€‚ç„¶è€Œï¼Œè¿™äº›â€œè¯„åˆ¤â€æ¨¡å‹å¸¸å¸¸å­˜åœ¨åå·®ã€è¿‡åº¦è‡ªä¿¡ä»¥åŠåœ¨ä¸åŒå›¾åƒé¢†åŸŸè¡¨ç°ä¸ä¸€è‡´çš„é—®é¢˜ã€‚è™½ç„¶æç¤ºé›†æˆå·²æ˜¾ç¤ºå‡ºåœ¨å•æ¨¡æ€ã€çº¯æ–‡æœ¬è®¾ç½®ä¸­ç¼“è§£è¿™äº›é—®é¢˜çš„æ½œåŠ›ï¼Œä½†æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œæ ‡å‡†é›†æˆæ–¹æ³•æ— æ³•æœ‰æ•ˆåœ°æ¨å¹¿åˆ°TTIä»»åŠ¡ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¤šæ¨¡æ€æ„ŸçŸ¥æ–¹æ³•ï¼Œç§°ä¸ºå¤šæ¨¡æ€æ··åˆè´å¶æ–¯æç¤ºé›†æˆï¼ˆMMBï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨è´å¶æ–¯æç¤ºé›†æˆæ–¹æ³•ï¼Œå¹¶é€šè¿‡å›¾åƒèšç±»è¿›è¡Œå¢å¼ºï¼Œå…è®¸è¯„åˆ¤æ¨¡å‹æ ¹æ®æ¯ä¸ªæ ·æœ¬çš„è§†è§‰ç‰¹å¾åŠ¨æ€åœ°åˆ†é…æç¤ºæƒé‡ã€‚æˆ‘ä»¬è¡¨æ˜ï¼ŒMMBæé«˜äº†æˆå¯¹åå¥½åˆ¤æ–­çš„å‡†ç¡®æ€§ï¼Œå¹¶å¤§å¤§å¢å¼ºäº†æ ¡å‡†æ•ˆæœï¼Œä»è€Œæ›´å®¹æ˜“è¡¡é‡è¯„åˆ¤æ¨¡å‹çš„çœŸå®ä¸ç¡®å®šæ€§ã€‚åœ¨HPSv2å’ŒMJBenchä¸¤ä¸ªTTIåŸºå‡†ä¸Šçš„è¯„ä¼°ä¸­ï¼ŒMMBåœ¨ä¸äººç±»æ³¨é‡Šå¯¹é½å’Œè·¨ä¸åŒå›¾åƒå†…å®¹çš„æ ¡å‡†æ–¹é¢å‡ä¼˜äºç°æœ‰åŸºçº¿ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒäº†å¤šæ¨¡æ€ç‰¹å®šç­–ç•¥å¯¹äºè¯„åˆ¤æ¨¡å‹æ ¡å‡†çš„é‡è¦æ€§ï¼Œå¹¶ä¸ºå¯é çš„å¤§è§„æ¨¡TTIè¯„ä¼°æå‡ºäº†ä¸€ä¸ªæœ‰å¸Œæœ›çš„é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ä½œä¸ºæ–‡å›¾ç”Ÿæˆï¼ˆTTIï¼‰ç³»ç»Ÿè¯„åˆ¤è€…æ—¶å­˜åœ¨çš„åå·®ã€è¿‡åº¦è‡ªä¿¡å’Œè·¨åŸŸæ€§èƒ½ä¸ä¸€è‡´çš„é—®é¢˜ã€‚ç°æœ‰çš„æç¤ºé›†æˆæ–¹æ³•åœ¨å•æ¨¡æ€æ–‡æœ¬ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†ç›´æ¥åº”ç”¨äºå¤šæ¨¡æ€ TTI ä»»åŠ¡æ—¶æ•ˆæœä¸ä½³ï¼Œæ— æ³•æœ‰æ•ˆè§£å†³ä¸Šè¿°é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å›¾åƒçš„è§†è§‰ç‰¹å¾æ¥æŒ‡å¯¼æç¤ºé›†æˆã€‚é€šè¿‡å¯¹å›¾åƒè¿›è¡Œèšç±»ï¼Œå°†è§†è§‰ç›¸ä¼¼çš„å›¾åƒå½’ä¸ºä¸€ç±»ï¼Œç„¶åé’ˆå¯¹æ¯ä¸€ç±»å›¾åƒå­¦ä¹ ä¸åŒçš„æç¤ºæƒé‡ã€‚è¿™æ ·ï¼Œè¯„åˆ¤æ¨¡å‹å¯ä»¥æ ¹æ®è¾“å…¥å›¾åƒçš„è§†è§‰ç‰¹å¾åŠ¨æ€åœ°è°ƒæ•´æç¤ºæƒé‡ï¼Œä»è€Œæé«˜è¯„åˆ¤çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMMBæ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **å›¾åƒèšç±»**ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰æ¨¡å‹æå–å›¾åƒç‰¹å¾ï¼Œå¹¶ä½¿ç”¨èšç±»ç®—æ³•ï¼ˆå¦‚k-meansï¼‰å°†å›¾åƒåˆ’åˆ†ä¸ºè‹¥å¹²ä¸ªç°‡ã€‚2) **è´å¶æ–¯æç¤ºé›†æˆ**ï¼šä¸ºæ¯ä¸ªå›¾åƒç°‡æ„å»ºä¸€ä¸ªè´å¶æ–¯æç¤ºé›†æˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åŒ…å«å¤šä¸ªä¸åŒçš„æç¤ºï¼Œå¹¶ä¸ºæ¯ä¸ªæç¤ºåˆ†é…ä¸€ä¸ªæƒé‡ã€‚3) **æƒé‡å­¦ä¹ **ï¼šä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–ç®—æ³•ï¼Œé’ˆå¯¹æ¯ä¸ªå›¾åƒç°‡ï¼Œå­¦ä¹ ä¸€ç»„æœ€ä¼˜çš„æç¤ºæƒé‡ï¼Œä½¿å¾—è¯„åˆ¤æ¨¡å‹åœ¨è¯¥ç°‡ä¸Šçš„è¡¨ç°æœ€ä½³ã€‚4) **è¯„åˆ¤**ï¼šå¯¹äºä¸€ä¸ªæ–°çš„è¾“å…¥å›¾åƒï¼Œé¦–å…ˆå°†å…¶åˆ’åˆ†åˆ°å¯¹åº”çš„å›¾åƒç°‡ï¼Œç„¶åä½¿ç”¨è¯¥ç°‡å¯¹åº”çš„è´å¶æ–¯æç¤ºé›†æˆæ¨¡å‹è¿›è¡Œè¯„åˆ¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šMMBæ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨äºå°†å›¾åƒçš„è§†è§‰ç‰¹å¾èå…¥åˆ°æç¤ºé›†æˆè¿‡ç¨‹ä¸­ã€‚ä¼ ç»Ÿçš„æç¤ºé›†æˆæ–¹æ³•é€šå¸¸å¿½ç•¥äº†è¾“å…¥æ•°æ®çš„è§†è§‰ä¿¡æ¯ï¼Œè€ŒMMBæ–¹æ³•åˆ™åˆ©ç”¨å›¾åƒèšç±»å°†è§†è§‰ç›¸ä¼¼çš„å›¾åƒåˆ†ç»„ï¼Œå¹¶ä¸ºæ¯ä¸ªç»„å­¦ä¹ ä¸åŒçš„æç¤ºæƒé‡ã€‚è¿™ç§å¤šæ¨¡æ€æ„ŸçŸ¥çš„æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒçš„å›¾åƒå†…å®¹ï¼Œä»è€Œæé«˜è¯„åˆ¤çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå›¾åƒèšç±»ä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰æ¨¡å‹ï¼ˆä¾‹å¦‚CLIPï¼‰æå–å›¾åƒç‰¹å¾ï¼Œå¹¶ä½¿ç”¨k-meansç®—æ³•è¿›è¡Œèšç±»ã€‚è´å¶æ–¯æç¤ºé›†æˆä½¿ç”¨é«˜æ–¯è¿‡ç¨‹ä½œä¸ºå…ˆéªŒåˆ†å¸ƒï¼Œå¹¶ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–ç®—æ³•å­¦ä¹ æç¤ºæƒé‡ã€‚æŸå¤±å‡½æ•°é€šå¸¸é‡‡ç”¨pairwise ranking lossï¼Œé¼“åŠ±æ¨¡å‹å¯¹äººç±»åå¥½è¿›è¡Œæ­£ç¡®æ’åºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MMBæ–¹æ³•åœ¨HPSv2å’ŒMJBenchä¸¤ä¸ª TTI åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨ä¸äººç±»æ ‡æ³¨å¯¹é½æ–¹é¢ï¼ŒMMBä¼˜äºç°æœ‰çš„åŸºçº¿æ–¹æ³•ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒMMBæ˜¾è‘—æé«˜äº†è¯„åˆ¤æ¨¡å‹çš„æ ¡å‡†æ•ˆæœï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å‡†ç¡®åœ°åæ˜ å…¶ä¸ç¡®å®šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMMBæ˜¯ä¸€ç§æœ‰æ•ˆçš„å¤šæ¨¡æ€è¯„åˆ¤æ¨¡å‹æ ¡å‡†æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤§è§„æ¨¡æ–‡å›¾ç”Ÿæˆæ¨¡å‹çš„è‡ªåŠ¨è¯„ä¼°ï¼Œå‡å°‘å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ï¼ŒåŠ é€Ÿæ¨¡å‹è¿­ä»£å’Œä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä¹Ÿå¯æ¨å¹¿åˆ°å…¶ä»–å¤šæ¨¡æ€è¯„åˆ¤ä»»åŠ¡ï¼Œä¾‹å¦‚è§†é¢‘è´¨é‡è¯„ä¼°ã€å›¾åƒæè¿°ç”Ÿæˆè¯„ä¼°ç­‰ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯å’Œå®é™…ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) are increasingly used to evaluate text-to-image (TTI) generation systems, providing automated judgments based on visual and textual context. However, these "judge" models often suffer from biases, overconfidence, and inconsistent performance across diverse image domains. While prompt ensembling has shown promise for mitigating these issues in unimodal, text-only settings, our experiments reveal that standard ensembling methods fail to generalize effectively for TTI tasks. To address these limitations, we propose a new multimodal-aware method called Multimodal Mixture-of-Bayesian Prompt Ensembles (MMB). Our method uses a Bayesian prompt ensemble approach augmented by image clustering, allowing the judge to dynamically assign prompt weights based on the visual characteristics of each sample. We show that MMB improves accuracy in pairwise preference judgments and greatly enhances calibration, making it easier to gauge the judge's true uncertainty. In evaluations on two TTI benchmarks, HPSv2 and MJBench, MMB outperforms existing baselines in alignment with human annotations and calibration across varied image content. Our findings highlight the importance of multimodal-specific strategies for judge calibration and suggest a promising path forward for reliable large-scale TTI evaluation.

