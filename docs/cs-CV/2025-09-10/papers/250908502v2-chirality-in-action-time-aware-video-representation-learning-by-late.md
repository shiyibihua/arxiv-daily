---
layout: default
title: Chirality in Action: Time-Aware Video Representation Learning by Latent Straightening
---

# Chirality in Action: Time-Aware Video Representation Learning by Latent Straightening

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.08502" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.08502v2</a>
  <a href="https://arxiv.org/pdf/2509.08502.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.08502v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.08502v2', 'Chirality in Action: Time-Aware Video Representation Learning by Latent Straightening')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Piyush Bagad, Andrew Zisserman

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-10 (æ›´æ–°: 2025-09-23)

**å¤‡æ³¨**: Project page: https://bpiyush.github.io/lift-website/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ½œåœ¨ç©ºé—´çŸ«æ­£çš„æ—¶é—´æ„ŸçŸ¥è§†é¢‘è¡¨å¾å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºæ‰‹æ€§åŠ¨ä½œè¯†åˆ«ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†é¢‘è¡¨å¾å­¦ä¹ ` `æ—¶é—´æ•æ„Ÿæ€§` `æ‰‹æ€§åŠ¨ä½œè¯†åˆ«` `è‡ªç›‘ç£å­¦ä¹ ` `æ½œåœ¨ç©ºé—´çŸ«æ­£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘è¡¨å¾æ–¹æ³•åœ¨æ•æ‰ç»†å¾®çš„æ—¶é—´å˜åŒ–æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨åŒºåˆ†æ—¶é—´ç›¸åçš„åŠ¨ä½œæ—¶è¡¨ç°ä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡åœ¨è‡ªç¼–ç å™¨çš„æ½œåœ¨ç©ºé—´ä¸­å¼•å…¥æ„ŸçŸ¥çŸ«æ­£çš„å½’çº³åç½®ï¼Œæ¥å¢å¼ºè§†é¢‘è¡¨å¾çš„æ—¶é—´æ•æ„Ÿæ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ‰‹æ€§åŠ¨ä½œè¯†åˆ«ä»»åŠ¡ä¸Šä¼˜äºå¤§å‹è§†é¢‘æ¨¡å‹ï¼Œå¹¶ä¸”å¯ä»¥æå‡ç°æœ‰æ¨¡å‹åœ¨æ ‡å‡†åŸºå‡†ä¸Šçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ—¨åœ¨å¼€å‘å¯¹æ—¶é—´å˜åŒ–æ•æ„Ÿçš„ç´§å‡‘è§†é¢‘è¡¨å¾ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªæ–°çš„ä»»åŠ¡ï¼šæ‰‹æ€§åŠ¨ä½œè¯†åˆ«ï¼Œå³åŒºåˆ†æ—¶é—´ä¸Šç›¸åçš„åŠ¨ä½œå¯¹ï¼Œä¾‹å¦‚â€œå¼€é—¨ä¸å…³é—¨â€ã€â€œé è¿‘ä¸è¿œç¦»â€ã€â€œæŠ˜å ä¸å±•å¼€çº¸å¼ â€ç­‰ã€‚è¿™äº›åŠ¨ä½œï¼ˆiï¼‰åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­é¢‘ç¹å‘ç”Ÿï¼Œï¼ˆiiï¼‰éœ€è¦ç†è§£ç®€å•çš„è§†è§‰æ—¶é—´å˜åŒ–ï¼ˆåœ¨ç‰©ä½“çŠ¶æ€ã€å¤§å°ã€ç©ºé—´ä½ç½®ã€æ•°é‡ç­‰æ–¹é¢ï¼‰ï¼Œå¹¶ä¸”ï¼ˆiiiï¼‰å·²çŸ¥è®¸å¤šè§†é¢‘åµŒå…¥å¯¹å®ƒä»¬çš„è¡¨å¾æ•ˆæœä¸ä½³ã€‚æœ¬æ–‡çš„ç›®æ ‡æ˜¯æ„å»ºæ—¶é—´æ„ŸçŸ¥çš„è§†é¢‘è¡¨å¾ï¼Œä»è€Œåœ¨çº¿æ€§å¯åˆ†æ€§æ–¹é¢åŒºåˆ†è¿™äº›æ‰‹æ€§å¯¹ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§è‡ªç›‘ç£çš„é€‚åº”æ–¹æ³•ï¼Œå°†æ—¶é—´æ•æ„Ÿæ€§æ³¨å…¥åˆ°ä¸€ç³»åˆ—å†»ç»“çš„å›¾åƒç‰¹å¾ä¸­ã€‚è¯¥æ¨¡å‹åŸºäºä¸€ä¸ªè‡ªç¼–ç å™¨ï¼Œå…¶æ½œåœ¨ç©ºé—´å…·æœ‰å—æ„ŸçŸ¥çŸ«æ­£å¯å‘çš„å½’çº³åç½®ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸‰ä¸ªæ•°æ®é›†ï¼ˆSomething-Somethingã€EPIC-Kitchens å’Œ Charadeï¼‰ä¸Šä¸ºæ‰€æå‡ºçš„ä»»åŠ¡ç”Ÿæˆäº†ç´§å‡‘ä½†æ—¶é—´æ•æ„Ÿçš„è§†é¢‘è¡¨å¾ã€‚è¯¥æ–¹æ³•ï¼ˆiï¼‰ä¼˜äºåœ¨å¤§å‹è§†é¢‘æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„æ›´å¤§çš„è§†é¢‘æ¨¡å‹ï¼Œå¹¶ä¸”ï¼ˆiiï¼‰åœ¨ä¸è¿™äº›ç°æœ‰æ¨¡å‹ç»“åˆä½¿ç”¨æ—¶ï¼Œæé«˜äº†æ ‡å‡†åŸºå‡†ä¸Šçš„åˆ†ç±»æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†é¢‘è¡¨å¾å¯¹æ—¶é—´æ•æ„Ÿæ€§ä¸è¶³çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨åŒºåˆ†æ—¶é—´ä¸Šç›¸åçš„åŠ¨ä½œï¼ˆæ‰‹æ€§åŠ¨ä½œï¼‰æ—¶ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æ•æ‰ç»†å¾®çš„æ—¶é—´å˜åŒ–ï¼Œå¯¼è‡´æ— æ³•æœ‰æ•ˆåŒºåˆ†â€œå¼€é—¨â€å’Œâ€œå…³é—¨â€è¿™ç±»åŠ¨ä½œã€‚è¿™äº›åŠ¨ä½œåœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­å¾ˆå¸¸è§ï¼Œä½†ç°æœ‰è§†é¢‘åµŒå…¥çš„è¡¨å¾æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è‡ªç›‘ç£å­¦ä¹ ï¼Œå°†æ—¶é—´æ•æ„Ÿæ€§æ³¨å…¥åˆ°è§†é¢‘è¡¨å¾ä¸­ã€‚å…·ä½“æ¥è¯´ï¼Œåˆ©ç”¨è‡ªç¼–ç å™¨å­¦ä¹ è§†é¢‘åºåˆ—çš„æ½œåœ¨è¡¨å¾ï¼Œå¹¶åœ¨æ½œåœ¨ç©ºé—´ä¸­å¼•å…¥æ„ŸçŸ¥çŸ«æ­£çš„å½’çº³åç½®ã€‚è¿™ç§å½’çº³åç½®é¼“åŠ±æ¨¡å‹å­¦ä¹ åˆ°å¯¹æ—¶é—´å˜åŒ–æ›´æ•æ„Ÿçš„è¡¨å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶æ˜¯ä¸€ä¸ªè‡ªç¼–ç å™¨ç»“æ„ã€‚é¦–å…ˆï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„å›¾åƒç‰¹å¾æå–å™¨ï¼ˆä¾‹å¦‚ï¼Œä»ImageNeté¢„è®­ç»ƒçš„æ¨¡å‹ä¸­æå–çš„ç‰¹å¾ï¼‰æå–è§†é¢‘å¸§çš„ç‰¹å¾ã€‚ç„¶åï¼Œå°†è¿™äº›ç‰¹å¾åºåˆ—è¾“å…¥åˆ°è‡ªç¼–ç å™¨ä¸­ï¼Œè‡ªç¼–ç å™¨ç”±ç¼–ç å™¨å’Œè§£ç å™¨ç»„æˆã€‚ç¼–ç å™¨å°†ç‰¹å¾åºåˆ—æ˜ å°„åˆ°æ½œåœ¨ç©ºé—´ï¼Œè§£ç å™¨åˆ™ä»æ½œåœ¨ç©ºé—´é‡æ„åŸå§‹ç‰¹å¾åºåˆ—ã€‚å…³é”®åœ¨äºæ½œåœ¨ç©ºé—´çš„è®¾è®¡ï¼Œå®ƒè¢«è®¾è®¡ä¸ºå…·æœ‰æ„ŸçŸ¥çŸ«æ­£çš„ç‰¹æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæ½œåœ¨ç©ºé—´çš„è®¾è®¡ï¼Œå®ƒå€Ÿé‰´äº†æ„ŸçŸ¥çŸ«æ­£çš„æ€æƒ³ã€‚æ„ŸçŸ¥çŸ«æ­£æ˜¯æŒ‡äººç±»è§†è§‰ç³»ç»Ÿå€¾å‘äºå°†å¼¯æ›²çš„ç‰©ä½“æ„ŸçŸ¥ä¸ºç›´çº¿ã€‚è®ºæ–‡å°†è¿™ç§æ€æƒ³åº”ç”¨åˆ°è§†é¢‘è¡¨å¾å­¦ä¹ ä¸­ï¼Œé€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­å¼•å…¥ç›¸åº”çš„çº¦æŸï¼Œä½¿å¾—æ¨¡å‹æ›´å®¹æ˜“å­¦ä¹ åˆ°å¯¹æ—¶é—´å˜åŒ–æ•æ„Ÿçš„è¡¨å¾ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦ä»å¤´è®­ç»ƒå¤§å‹è§†é¢‘æ¨¡å‹ï¼Œè€Œæ˜¯é€šè¿‡è‡ªç›‘ç£å­¦ä¹ å¯¹é¢„è®­ç»ƒçš„å›¾åƒç‰¹å¾è¿›è¡Œå¾®è°ƒï¼Œä»è€Œæ›´é«˜æ•ˆåœ°å­¦ä¹ æ—¶é—´æ•æ„Ÿçš„è§†é¢‘è¡¨å¾ã€‚

**å…³é”®è®¾è®¡**ï¼šè‡ªç¼–ç å™¨çš„æŸå¤±å‡½æ•°åŒ…æ‹¬é‡æ„æŸå¤±å’Œæ­£åˆ™åŒ–é¡¹ã€‚é‡æ„æŸå¤±ç”¨äºç¡®ä¿è§£ç å™¨èƒ½å¤Ÿä»æ½œåœ¨ç©ºé—´é‡æ„åŸå§‹ç‰¹å¾åºåˆ—ã€‚æ­£åˆ™åŒ–é¡¹ç”¨äºçº¦æŸæ½œåœ¨ç©ºé—´çš„ç»“æ„ï¼Œä½¿å…¶å…·æœ‰æ„ŸçŸ¥çŸ«æ­£çš„ç‰¹æ€§ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®å–å†³äºæ‰€ä½¿ç”¨çš„æ•°æ®é›†å’Œé¢„è®­ç»ƒæ¨¡å‹ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†ä¸åŒçš„æ•°æ®é›†ï¼ˆSomething-Something, EPIC-Kitchens, Charadeï¼‰è¿›è¡Œå®éªŒï¼Œå¹¶é’ˆå¯¹æ¯ä¸ªæ•°æ®é›†è°ƒæ•´äº†ç½‘ç»œç»“æ„å’Œå‚æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ‰‹æ€§åŠ¨ä½œè¯†åˆ«ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨Something-Somethingæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•ä¼˜äºåœ¨å¤§å‹è§†é¢‘æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„æ›´å¤§çš„è§†é¢‘æ¨¡å‹ã€‚æ­¤å¤–ï¼Œå°†è¯¥æ–¹æ³•ä¸ç°æœ‰æ¨¡å‹ç»“åˆä½¿ç”¨æ—¶ï¼Œå¯ä»¥æå‡æ ‡å‡†åŸºå‡†ä¸Šçš„åˆ†ç±»æ€§èƒ½ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ åˆ°æ—¶é—´æ•æ„Ÿçš„è§†é¢‘è¡¨å¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€æ™ºèƒ½ç›‘æ§ã€äººæœºäº¤äº’ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œæœºå™¨äººå¯ä»¥åˆ©ç”¨æ—¶é—´æ•æ„Ÿçš„è§†é¢‘è¡¨å¾æ¥æ›´å¥½åœ°ç†è§£å‘¨å›´ç¯å¢ƒçš„å˜åŒ–ï¼Œä»è€Œæ›´å®‰å…¨åœ°è¿›è¡Œå¯¼èˆªã€‚åœ¨æ™ºèƒ½ç›‘æ§ä¸­ï¼Œå¯ä»¥ç”¨äºæ£€æµ‹å¼‚å¸¸è¡Œä¸ºï¼Œä¾‹å¦‚éæ³•å…¥ä¾µæˆ–è·Œå€’ç­‰ã€‚åœ¨äººæœºäº¤äº’ä¸­ï¼Œå¯ä»¥ç”¨äºè¯†åˆ«ç”¨æˆ·çš„æ‰‹åŠ¿å’ŒåŠ¨ä½œï¼Œä»è€Œå®ç°æ›´è‡ªç„¶çš„äººæœºäº¤äº’ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Our objective is to develop compact video representations that are sensitive to visual change over time. To measure such time-sensitivity, we introduce a new task: chiral action recognition, where one needs to distinguish between a pair of temporally opposite actions, such as "opening vs. closing a door", "approaching vs. moving away from something", "folding vs. unfolding paper", etc. Such actions (i) occur frequently in everyday life, (ii) require understanding of simple visual change over time (in object state, size, spatial position, count . . . ), and (iii) are known to be poorly represented by many video embeddings. Our goal is to build time aware video representations which offer linear separability between these chiral pairs. To that end, we propose a self-supervised adaptation recipe to inject time-sensitivity into a sequence of frozen image features. Our model is based on an auto-encoder with a latent space with inductive bias inspired by perceptual straightening. We show that this results in a compact but time-sensitive video representation for the proposed task across three datasets: Something-Something, EPIC-Kitchens, and Charade. Our method (i) outperforms much larger video models pre-trained on large-scale video datasets, and (ii) leads to an improvement in classification performance on standard benchmarks when combined with these existing models.

