---
layout: default
title: UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding
---

# UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23219" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.23219v1</a>
  <a href="https://arxiv.org/pdf/2506.23219.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23219v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23219v1', 'UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Jie Feng, Shengyuan Wang, Tianhui Liu, Yanxin Xi, Yong Li

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-29

**Â§áÊ≥®**: Accepted by ICCV 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/tsinghua-fib-lab/UrbanLLaVA)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫UrbanLLaVA‰ª•Ëß£ÂÜ≥ÂüéÂ∏ÇÊô∫ËÉΩ‰∏≠ÁöÑÂ§öÊ®°ÊÄÅÊï∞ÊçÆÂ§ÑÁêÜÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `ÂüéÂ∏ÇÊô∫ËÉΩ` `Á©∫Èó¥Êé®ÁêÜ` `Êï∞ÊçÆÈõÜÊûÑÂª∫` `Ê®°ÂûãËÆ≠ÁªÉ` `ÊÄßËÉΩËØÑ‰º∞` `Ë∑®Ê®°ÊÄÅÊï∞ÊçÆÂ§ÑÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂ§öÈõÜ‰∏≠‰∫éÁâπÂÆöÊï∞ÊçÆÁ±ªÂûãÔºåÁº∫‰πèÁªü‰∏ÄÊ°ÜÊû∂ÔºåÂØºËá¥ÂüéÂ∏ÇÊô∫ËÉΩ‰ªªÂä°Â§ÑÁêÜËÉΩÂäõ‰∏çË∂≥„ÄÇ
2. UrbanLLaVAÈÄöËøáÊûÑÂª∫Â§öÊ†∑ÂåñÁöÑÂüéÂ∏ÇÊåá‰ª§Êï∞ÊçÆÈõÜÂíåÂ§öÈò∂ÊÆµËÆ≠ÁªÉÊ°ÜÊû∂ÔºåËß£ÂÜ≥‰∫ÜÂ§öÊ®°ÊÄÅÊï∞ÊçÆÂ§ÑÁêÜÁöÑÊåëÊàò„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåUrbanLLaVAÂú®ÂçïÊ®°ÊÄÅÂíåÂ§çÊùÇË∑®Ê®°ÊÄÅ‰ªªÂä°‰∏≠Âùá‰ºò‰∫éÁé∞ÊúâÊ®°ÂûãÔºåÂ±ïÁé∞Âá∫ËâØÂ•ΩÁöÑÂüéÂ∏ÇÈó¥Ê≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂüéÂ∏ÇÁ†îÁ©∂Ê∂âÂèäÂ§öÁßçÂú∫ÊôØÂíå‰ªªÂä°ÔºåÈúÄË¶ÅÁêÜËß£Â§öÊ®°ÊÄÅÊï∞ÊçÆ„ÄÇÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄ‰∏ìÊ≥®‰∫éÁâπÂÆöÊï∞ÊçÆÁ±ªÂûãÔºåÁº∫‰πèÁªü‰∏ÄÊ°ÜÊû∂„ÄÇÊú¨ÊñáÊèêÂá∫UrbanLLaVAÔºå‰∏Ä‰∏™Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºåËÉΩÂ§üÂêåÊó∂Â§ÑÁêÜÂõõÁßçÊï∞ÊçÆÁ±ªÂûãÔºåÂπ∂Âú®Â§öÈ°πÂüéÂ∏Ç‰ªªÂä°‰∏≠Ë°®Áé∞‰ºòÂºÇ„ÄÇÊàë‰ª¨È¶ñÂÖàÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Â§öÊ†∑ÂåñÁöÑÂüéÂ∏ÇÊåá‰ª§Êï∞ÊçÆÈõÜÔºåÊ∂µÁõñÂçïÊ®°ÊÄÅÂíåË∑®Ê®°ÊÄÅÊï∞ÊçÆ„ÄÇÊé•ÁùÄÔºåÊèêÂá∫‰∫Ü‰∏Ä‰∏™Â§öÈò∂ÊÆµËÆ≠ÁªÉÊ°ÜÊû∂ÔºåÂ∞ÜÁ©∫Èó¥Êé®ÁêÜÂ¢ûÂº∫‰∏éÈ¢ÜÂüüÁü•ËØÜÂ≠¶‰π†Ëß£ËÄ¶Ôºå‰ªéËÄåÊèêÈ´ò‰∫ÜUrbanLLaVAÂú®Â§öÊ†∑ÂåñÂüéÂ∏Ç‰ªªÂä°‰∏≠ÁöÑÂÖºÂÆπÊÄßÂíå‰∏ãÊ∏∏ÊÄßËÉΩ„ÄÇÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåUrbanLLaVAÂú®‰∏â‰∏™ÂüéÂ∏ÇÁöÑÊµãËØï‰∏≠Ë∂ÖË∂ä‰∫ÜÂºÄÊ∫êÂíå‰∏ìÊúâÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºåÂ±ïÁé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÂüéÂ∏ÇÊô∫ËÉΩÈ¢ÜÂüü‰∏≠Â§öÊ®°ÊÄÅÊï∞ÊçÆÂ§ÑÁêÜÁöÑ‰∏çË∂≥ÔºåÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÊó†Ê≥ïÂÖ®Èù¢Â§ÑÁêÜ‰∏çÂêåÁ±ªÂûãÁöÑÊï∞ÊçÆÔºåÂØºËá¥ÊÄßËÉΩÂèóÈôê„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöUrbanLLaVAÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑËÆæËÆ°ÔºåËÉΩÂ§üÂêåÊó∂Â§ÑÁêÜÂ§öÁßçÊï∞ÊçÆÁ±ªÂûãÔºåÂπ∂ÈÄöËøáÂ§öÈò∂ÊÆµËÆ≠ÁªÉÊ°ÜÊû∂ÊèêÂçáÊ®°ÂûãÁöÑÂÖºÂÆπÊÄßÂíåÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöUrbanLLaVAÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÈõÜÊûÑÂª∫„ÄÅÊ®°ÂûãËÆ≠ÁªÉÂíåÊÄßËÉΩËØÑ‰º∞‰∏â‰∏™‰∏ªË¶ÅÊ®°Âùó„ÄÇÈ¶ñÂÖàÔºåÊûÑÂª∫Ê∂µÁõñÂçïÊ®°ÊÄÅÂíåË∑®Ê®°ÊÄÅÊï∞ÊçÆÁöÑÂüéÂ∏ÇÊåá‰ª§Êï∞ÊçÆÈõÜÔºõÂÖ∂Ê¨°ÔºåÈááÁî®Â§öÈò∂ÊÆµËÆ≠ÁªÉÊ°ÜÊû∂ËøõË°åÊ®°ÂûãËÆ≠ÁªÉÔºõÊúÄÂêéÔºåÈÄöËøáÊâ©Â±ïÁé∞ÊúâÂü∫ÂáÜÊµãËØïËØÑ‰º∞Ê®°ÂûãÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöUrbanLLaVAÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂ∞ÜÁ©∫Èó¥Êé®ÁêÜÂ¢ûÂº∫‰∏éÈ¢ÜÂüüÁü•ËØÜÂ≠¶‰π†Ëß£ËÄ¶ÔºåÊèêÂçá‰∫ÜÊ®°ÂûãÂú®Â§öÊ†∑ÂåñÂüéÂ∏Ç‰ªªÂä°‰∏≠ÁöÑË°®Áé∞„ÄÇËøô‰∏ÄËÆæËÆ°‰ΩøÂæóÊ®°ÂûãÂú®Â§ÑÁêÜÂ§çÊùÇ‰ªªÂä°Êó∂Êõ¥ÂÖ∑ÁÅµÊ¥ªÊÄßÂíåÈÄÇÂ∫îÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÔºå‰ª•‰ºòÂåñÂ§öÊ®°ÊÄÅÊï∞ÊçÆÁöÑËûçÂêàÂíåÂ§ÑÁêÜËÉΩÂäõ„ÄÇÂêåÊó∂ÔºåÊï∞ÊçÆÈõÜÁöÑÂ§öÊ†∑ÊÄßÂíåËÆ≠ÁªÉÁ≠ñÁï•ÁöÑÁÅµÊ¥ªÊÄß‰πüÊòØÂÖ≥ÈîÆËÆæËÆ°Ë¶ÅÁ¥†„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåUrbanLLaVAÂú®‰∏â‰∏™ÂüéÂ∏ÇÁöÑÊµãËØï‰∏≠ÔºåÂçïÊ®°ÊÄÅ‰ªªÂä°ÂíåÂ§çÊùÇË∑®Ê®°ÊÄÅ‰ªªÂä°ÁöÑË°®Áé∞Âùá‰ºò‰∫éÁé∞ÊúâÁöÑÂºÄÊ∫êÂíå‰∏ìÊúâÊ®°ÂûãÔºåÂÖ∑‰ΩìÊèêÂçáÂπÖÂ∫¶ËææÂà∞10%‰ª•‰∏äÔºåÂ±ïÁé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÂíåÈÄÇÂ∫îÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

UrbanLLaVAÁöÑÁ†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÂüéÂ∏ÇËßÑÂàí„ÄÅ‰∫§ÈÄöÁÆ°ÁêÜ„ÄÅÁéØÂ¢ÉÁõëÊµãÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÂØπÂ§öÊ®°ÊÄÅÊï∞ÊçÆÁöÑÊúâÊïàÂ§ÑÁêÜÔºåËÉΩÂ§ü‰∏∫ÂüéÂ∏ÇÊô∫ËÉΩÂÜ≥Á≠ñÊèê‰æõÊõ¥‰∏∫Á≤æÂáÜÁöÑÊîØÊåÅÔºåÊèêÂçáÂüéÂ∏ÇÁÆ°ÁêÜÁöÑÊïàÁéáÂíåÁßëÂ≠¶ÊÄß„ÄÇÊú™Êù•ÔºåËØ•Ê®°ÂûãÊúâÊúõÂú®Êô∫ËÉΩÂüéÂ∏ÇÂª∫ËÆæ‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Urban research involves a wide range of scenarios and tasks that require the understanding of multi-modal data. Current methods often focus on specific data types and lack a unified framework in urban field for processing them comprehensively. The recent success of multi-modal large language models (MLLMs) presents a promising opportunity to overcome this limitation. In this paper, we introduce $\textit{UrbanLLaVA}$, a multi-modal large language model designed to process these four types of data simultaneously and achieve strong performance across diverse urban tasks compared with general MLLMs. In $\textit{UrbanLLaVA}$, we first curate a diverse urban instruction dataset encompassing both single-modal and cross-modal urban data, spanning from location view to global view of urban environment. Additionally, we propose a multi-stage training framework that decouples spatial reasoning enhancement from domain knowledge learning, thereby improving the compatibility and downstream performance of $\textit{UrbanLLaVA}$ across diverse urban tasks. Finally, we also extend existing benchmark for urban research to assess the performance of MLLMs across a wide range of urban tasks. Experimental results from three cities demonstrate that $\textit{UrbanLLaVA}$ outperforms open-source and proprietary MLLMs in both single-modal tasks and complex cross-modal tasks and shows robust generalization abilities across cities. Source codes and data are openly accessible to the research community via https://github.com/tsinghua-fib-lab/UrbanLLaVA.

