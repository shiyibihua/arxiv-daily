---
layout: default
title: MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation
---

# MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23151" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.23151v1</a>
  <a href="https://arxiv.org/pdf/2506.23151.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23151v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23151v1', 'MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Vladislav Bargatin, Egor Chistov, Alexander Yakovenko, Dmitriy Vatolin

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.MM

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-29

**Â§áÊ≥®**: Accepted at ICCV 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/msu-video-group/memfof)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MEMFOF‰ª•Ëß£ÂÜ≥È´òÂàÜËæ®ÁéáÂÖâÊµÅ‰º∞ËÆ°‰∏≠ÁöÑÂÜÖÂ≠òÊïàÁéáÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `ÂÖâÊµÅ‰º∞ËÆ°` `È´òÂàÜËæ®ÁéáËÆ≠ÁªÉ` `ÂÜÖÂ≠òÊïàÁéá` `Â§öÂ∏ß‰º∞ËÆ°` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂÖâÊµÅ‰º∞ËÆ°ÊñπÊ≥ïÂú®È´òÂàÜËæ®ÁéáËæìÂÖ•‰∏ãÔºåGPUÂÜÖÂ≠òÊ∂àËÄóËøáÂ§ßÔºåÂΩ±Âìç‰∫ÜÂÆûÈôÖÂ∫îÁî®„ÄÇ
2. MEMFOFÈÄöËøá‰ºòÂåñÂ§öÂ∏ß‰º∞ËÆ°‰∏éÂÜÖÂ≠ò‰ΩøÁî®ÁöÑÂπ≥Ë°°ÔºåÂÆûÁé∞‰∫ÜÈ´òÊïàÁöÑÂÖâÊµÅ‰º∞ËÆ°ÔºåÊîØÊåÅ1080pÂéüÁîüËÆ≠ÁªÉ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåMEMFOFÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÂáÜÁ°ÆÁéáÂíåËøêË°åÊïàÁéáÂùá‰ºò‰∫éËµÑÊ∫êÊ∂àËÄóÊõ¥Â§ßÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËøëÂπ¥Êù•ÔºåÂÖâÊµÅ‰º∞ËÆ°ÁöÑËøõÂ±ïËôΩÁÑ∂ÊèêÈ´ò‰∫ÜÂáÜÁ°ÆÊÄßÔºå‰ΩÜÂú®È´òÂàÜËæ®ÁéáÔºàFullHDÔºâËæìÂÖ•‰∏ãÔºåGPUÂÜÖÂ≠òÊ∂àËÄóÊòæËëóÂ¢ûÂä†„ÄÇÊú¨ÊñáÊèêÂá∫MEMFOFÔºå‰∏ÄÁßçÂÜÖÂ≠òÈ´òÊïàÁöÑÂ§öÂ∏ßÂÖâÊµÅÊñπÊ≥ïÔºåËÉΩÂ§üÂú®Â§öÂ∏ß‰º∞ËÆ°‰∏éGPUÂÜÖÂ≠ò‰ΩøÁî®‰πãÈó¥ÊâæÂà∞ËâØÂ•ΩÁöÑÂπ≥Ë°°„ÄÇMEMFOFÂú®1080pËæìÂÖ•‰∏ãËøêË°åÊó∂‰ªÖÈúÄ2.09 GBÁöÑGPUÂÜÖÂ≠òÔºåËÆ≠ÁªÉÊó∂‰∏∫28.5 GBÔºåÂÖÅËÆ∏Âú®ÂéüÁîü1080p‰∏ãËøõË°åËÆ≠ÁªÉÔºåÊó†ÈúÄË£ÅÂâ™Êàñ‰∏ãÈááÊ†∑„ÄÇÈÄöËøáÁ≥ªÁªüÊÄßÂú∞ÂõûÈ°æRAFTÁ±ªÊû∂ÊûÑÁöÑËÆæËÆ°ÈÄâÊã©ÔºåÁªìÂêàÂáèÂ∞ëÁöÑÁõ∏ÂÖ≥‰ΩìÁßØÂíåÈ´òÂàÜËæ®ÁéáËÆ≠ÁªÉÂçèËÆÆÔºåMEMFOFÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂêåÊó∂ÊòæËëóÈôç‰Ωé‰∫ÜÂÜÖÂ≠òÂºÄÈîÄ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥È´òÂàÜËæ®ÁéáÂÖâÊµÅ‰º∞ËÆ°‰∏≠GPUÂÜÖÂ≠òÊ∂àËÄóËøáÂ§ßÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜ1080pËæìÂÖ•Êó∂ÔºåÂæÄÂæÄÈúÄË¶ÅÂ§ßÈáèÂÜÖÂ≠òÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®Âú∫ÊôØ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMEMFOFÈÄöËøáÂºïÂÖ•ÂÜÖÂ≠òÈ´òÊïàÁöÑÂ§öÂ∏ßÂÖâÊµÅ‰º∞ËÆ°ÊñπÊ≥ïÔºå‰ºòÂåñ‰∫ÜÂ§öÂ∏ß‰º∞ËÆ°ËøáÁ®ã‰∏éGPUÂÜÖÂ≠ò‰ΩøÁî®‰πãÈó¥ÁöÑÊùÉË°°ÔºåÂÖÅËÆ∏Âú®‰∏çË£ÅÂâ™Êàñ‰∏ãÈááÊ†∑ÁöÑÊÉÖÂÜµ‰∏ãËøõË°åÈ´òÂàÜËæ®ÁéáËÆ≠ÁªÉ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMEMFOFÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Â§ö‰∏™Ê®°ÂùóÔºåÈ¶ñÂÖàÊòØËæìÂÖ•ÂõæÂÉèÁöÑÈ¢ÑÂ§ÑÁêÜÔºåÁÑ∂ÂêéÊòØÂ§öÂ∏ßÂÖâÊµÅÁöÑ‰º∞ËÆ°ÔºåÊúÄÂêéÈÄöËøáÈ´òÂàÜËæ®ÁéáËÆ≠ÁªÉÂçèËÆÆËøõË°å‰ºòÂåñ„ÄÇËØ•ÊñπÊ≥ïÁªìÂêà‰∫ÜÂáèÂ∞ëÁöÑÁõ∏ÂÖ≥‰ΩìÁßØÔºåÊèêÂçá‰∫ÜËÆ°ÁÆóÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMEMFOFÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂ÂÜÖÂ≠òÊïàÁéáÔºåËÉΩÂ§üÂú®‰ªÖÈúÄ2.09 GBÁöÑËøêË°åÂÜÖÂ≠òÂíå28.5 GBÁöÑËÆ≠ÁªÉÂÜÖÂ≠ò‰∏ãÂÆûÁé∞È´òÂàÜËæ®ÁéáÂÖâÊµÅ‰º∞ËÆ°ÔºåÊòæËëó‰ºò‰∫é‰º†ÁªüÊñπÊ≥ï„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏äÔºåMEMFOFÈááÁî®‰∫Ü‰ºòÂåñÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÔºåÂáèÂ∞ë‰∫ÜÁõ∏ÂÖ≥‰ΩìÁßØÁöÑËÆ°ÁÆóÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÈ´òÂàÜËæ®ÁéáËæìÂÖ•ÁöÑÂ§ÑÁêÜËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ÂÆûÈ™å‰∏≠ÔºåMEMFOFÂú®SpringÂü∫ÂáÜÊµãËØï‰∏≠‰ª•3.289ÁöÑ1ÂÉèÁ¥†ÂºÇÂ∏∏ÁéáÊéíÂêçÁ¨¨‰∏ÄÔºåÂú®SintelÔºàÂπ≤ÂáÄÔºâÊï∞ÊçÆÈõÜ‰∏ä‰ª•0.963ÁöÑÁ´ØÁÇπËØØÂ∑ÆÔºàEPEÔºâÈ¢ÜÂÖàÔºåÂπ∂Âú®KITTI-2015‰∏äÂÆûÁé∞‰∫Ü2.94%ÁöÑÊúÄ‰Ω≥Fl-allËØØÂ∑ÆÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÂáÜÁ°ÆÊÄßÂíåËøêË°åÊïàÁéá‰∏äÁöÑÊòæËëó‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MEMFOFÂú®ËßÜÈ¢ëÂàÜÊûê„ÄÅËá™Âä®È©æÈ©∂„ÄÅËøêÂä®ÊçïÊçâÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÂÖ∂È´òÊïàÁöÑÂÜÖÂ≠ò‰ΩøÁî®ÂíåÂáÜÁ°ÆÁöÑÂÖâÊµÅ‰º∞ËÆ°ËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂú®ËµÑÊ∫êÂèóÈôêÁöÑÁéØÂ¢É‰∏≠ÂÆûÁé∞ÂÆûÊó∂Â§ÑÁêÜÔºåÊé®Âä®‰∫ÜÁõ∏ÂÖ≥ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent advances in optical flow estimation have prioritized accuracy at the cost of growing GPU memory consumption, particularly for high-resolution (FullHD) inputs. We introduce MEMFOF, a memory-efficient multi-frame optical flow method that identifies a favorable trade-off between multi-frame estimation and GPU memory usage. Notably, MEMFOF requires only 2.09 GB of GPU memory at runtime for 1080p inputs, and 28.5 GB during training, which uniquely positions our method to be trained at native 1080p without the need for cropping or downsampling. We systematically revisit design choices from RAFT-like architectures, integrating reduced correlation volumes and high-resolution training protocols alongside multi-frame estimation, to achieve state-of-the-art performance across multiple benchmarks while substantially reducing memory overhead. Our method outperforms more resource-intensive alternatives in both accuracy and runtime efficiency, validating its robustness for flow estimation at high resolutions. At the time of submission, our method ranks first on the Spring benchmark with a 1-pixel (1px) outlier rate of 3.289, leads Sintel (clean) with an endpoint error (EPE) of 0.963, and achieves the best Fl-all error on KITTI-2015 at 2.94%. The code is available at https://github.com/msu-video-group/memfof.

