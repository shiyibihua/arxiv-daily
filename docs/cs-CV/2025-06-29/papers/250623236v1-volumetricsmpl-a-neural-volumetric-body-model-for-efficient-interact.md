---
layout: default
title: VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions
---

# VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23236" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23236v1</a>
  <a href="https://arxiv.org/pdf/2506.23236.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23236v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23236v1', 'VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Marko Mihajlovic, Siwei Zhang, Gen Li, Kaifeng Zhao, Lea MÃ¼ller, Siyu Tang

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29

**å¤‡æ³¨**: [ICCV 2025] https://markomih.github.io/VolumetricSMPL

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVolumetricSMPLä»¥è§£å†³é«˜æ•ˆäººæœºäº¤äº’é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `ä½“ç§¯æ¨¡å‹` `ç¥ç»ç½‘ç»œ` `äººæœºäº¤äº’` `è®¡ç®—æœºè§†è§‰` `é«˜æ•ˆæ¨ç†` `å§¿æ€ä¼°è®¡` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä½“ç§¯ç¥ç»éšå¼äººä½“æ¨¡å‹åœ¨å¤æ‚çš„äººä½“å…³èŠ‚è¿åŠ¨ä¸­è¡¨ç°ä¸è¶³ï¼Œä¸”è®¡ç®—å’Œå†…å­˜æˆæœ¬è¾ƒé«˜ã€‚
2. æœ¬æ–‡æå‡ºçš„VolumetricSMPLé€šè¿‡ç¥ç»æ··åˆæƒé‡ï¼ˆNBWï¼‰ç”Ÿæˆç´§å‡‘çš„MLPè§£ç å™¨ï¼Œæ˜¾è‘—æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVolumetricSMPLåœ¨æ¨ç†é€Ÿåº¦ä¸Šæ¯”ç°æœ‰æ¨¡å‹å¿«10å€ï¼ŒGPUå†…å­˜ä½¿ç”¨é‡é™ä½6å€ï¼Œä¸”å‡†ç¡®æ€§å¾—åˆ°æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‚æ•°åŒ–äººä½“æ¨¡å‹åœ¨è®¡ç®—æœºå›¾å½¢å­¦å’Œè§†è§‰ä¸­æ‰®æ¼”ç€é‡è¦è§’è‰²ï¼Œåº”ç”¨èŒƒå›´ä»äººç±»åŠ¨ä½œåˆ†æåˆ°ç†è§£äººç±»ä¸ç¯å¢ƒçš„äº¤äº’ã€‚ä¼ ç»Ÿæ¨¡å‹ä½¿ç”¨è¡¨é¢ç½‘æ ¼ï¼Œéš¾ä»¥é«˜æ•ˆå¤„ç†ä¸å…¶ä»–å‡ ä½•å®ä½“çš„äº¤äº’ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºVolumetricSMPLï¼Œä¸€ä¸ªåˆ©ç”¨ç¥ç»æ··åˆæƒé‡ï¼ˆNBWï¼‰ç”Ÿæˆç´§å‡‘é«˜æ•ˆçš„MLPè§£ç å™¨çš„ç¥ç»ä½“ç§¯æ¨¡å‹ã€‚ä¸ä»¥å¾€ä¾èµ–å¤§å‹MLPçš„æ–¹æ³•ä¸åŒï¼ŒNBWé€šè¿‡é¢„æµ‹çš„å½¢çŠ¶å’Œå§¿æ€ç›¸å…³ç³»æ•°åŠ¨æ€æ··åˆä¸€å°ç»„å­¦ä¹ çš„æƒé‡çŸ©é˜µï¼Œæ˜¾è‘—æé«˜è®¡ç®—æ•ˆç‡å¹¶ä¿æŒè¡¨è¾¾èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVolumetricSMPLåœ¨å¤šä¸ªä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿè¡¨é¢ç½‘æ ¼æ¨¡å‹åœ¨å¤„ç†äººæœºäº¤äº’æ—¶çš„æ•ˆç‡å’Œé²æ£’æ€§é—®é¢˜ã€‚ç°æœ‰çš„ä½“ç§¯ç¥ç»éšå¼æ¨¡å‹åœ¨å¤æ‚çš„äººä½“è¿åŠ¨å’Œé«˜è®¡ç®—æˆæœ¬æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVolumetricSMPLé€šè¿‡å¼•å…¥ç¥ç»æ··åˆæƒé‡ï¼ˆNBWï¼‰ï¼ŒåŠ¨æ€æ··åˆå°‘é‡å­¦ä¹ çš„æƒé‡çŸ©é˜µï¼Œä¼˜åŒ–äº†æ¨¡å‹çš„è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒäº†è¡¨è¾¾èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¨¡å‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥çš„å½¢çŠ¶å’Œå§¿æ€ä¿¡æ¯ï¼Œé€šè¿‡NBWç”Ÿæˆç›¸åº”çš„æƒé‡çŸ©é˜µï¼Œæœ€ç»ˆé€šè¿‡MLPè§£ç å™¨è¾“å‡ºä½“ç§¯è¡¨ç¤ºã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬è¾“å…¥å¤„ç†ã€æƒé‡ç”Ÿæˆå’Œä½“ç§¯è§£ç ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºä½¿ç”¨NBWåŠ¨æ€æ··åˆæƒé‡ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­å¯¹å¤§å‹MLPçš„ä¾èµ–ï¼Œä»è€Œåœ¨è®¡ç®—æ•ˆç‡å’Œå†…å­˜ä½¿ç”¨ä¸Šå®ç°äº†æ˜¾è‘—æå‡ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹è®¾è®¡ä¸­é‡‡ç”¨äº†å°å‹çš„MLPç»“æ„ï¼Œå¹¶é€šè¿‡æŸå¤±å‡½æ•°ä¼˜åŒ–ä½“ç§¯è¡¨ç¤ºçš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è°ƒæ•´æƒé‡çŸ©é˜µä»¥é€‚åº”ä¸åŒçš„å½¢çŠ¶å’Œå§¿æ€ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVolumetricSMPLåœ¨æ¨ç†é€Ÿåº¦ä¸Šæ¯”ç°æœ‰çš„ä½“ç§¯å ç”¨æ¨¡å‹COAPå¿«10å€ï¼ŒGPUå†…å­˜ä½¿ç”¨é‡é™ä½6å€ï¼ŒåŒæ—¶åœ¨å‡†ç¡®æ€§å’Œå¯å¾®åˆ†æ¥è§¦å»ºæ¨¡æ–¹é¢ä¹Ÿæœ‰æ˜¾è‘—æå‡ã€‚è¿™äº›ç»“æœè¡¨æ˜è¯¥æ¨¡å‹åœ¨å¤„ç†å¤æ‚äººæœºäº¤äº’ä»»åŠ¡æ—¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VolumetricSMPLåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼ŒåŒ…æ‹¬è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®å’Œæ¸¸æˆå¼€å‘ç­‰ã€‚å…¶é«˜æ•ˆçš„äººæœºäº¤äº’èƒ½åŠ›å¯ä»¥æå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶ä¸ºå¤æ‚åœºæ™¯ä¸­çš„äººç±»è¡Œä¸ºåˆ†ææä¾›æ”¯æŒã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨æœºå™¨äººæŠ€æœ¯ä¸­ä¹Ÿå¯ç”¨äºæé«˜äººæœºåä½œçš„æ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Parametric human body models play a crucial role in computer graphics and vision, enabling applications ranging from human motion analysis to understanding human-environment interactions. Traditionally, these models use surface meshes, which pose challenges in efficiently handling interactions with other geometric entities, such as objects and scenes, typically represented as meshes or point clouds. To address this limitation, recent research has explored volumetric neural implicit body models. However, existing works are either insufficiently robust for complex human articulations or impose high computational and memory costs, limiting their widespread use. To this end, we introduce VolumetricSMPL, a neural volumetric body model that leverages Neural Blend Weights (NBW) to generate compact, yet efficient MLP decoders. Unlike prior approaches that rely on large MLPs, NBW dynamically blends a small set of learned weight matrices using predicted shape- and pose-dependent coefficients, significantly improving computational efficiency while preserving expressiveness. VolumetricSMPL outperforms prior volumetric occupancy model COAP with 10x faster inference, 6x lower GPU memory usage, enhanced accuracy, and a Signed Distance Function (SDF) for efficient and differentiable contact modeling. We demonstrate VolumetricSMPL's strengths across four challenging tasks: (1) reconstructing human-object interactions from in-the-wild images, (2) recovering human meshes in 3D scenes from egocentric views, (3) scene-constrained motion synthesis, and (4) resolving self-intersections. Our results highlight its broad applicability and significant performance and efficiency gains.

