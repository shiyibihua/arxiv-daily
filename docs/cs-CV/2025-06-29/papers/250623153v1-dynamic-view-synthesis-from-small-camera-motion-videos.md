---
layout: default
title: Dynamic View Synthesis from Small Camera Motion Videos
---

# Dynamic View Synthesis from Small Camera Motion Videos

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23153" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.23153v1</a>
  <a href="https://arxiv.org/pdf/2506.23153.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23153v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23153v1', 'Dynamic View Synthesis from Small Camera Motion Videos')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Huiqiang Sun, Xingyi Li, Juewen Peng, Liao Shen, Zhiguo Cao, Ke Xian, Guosheng Lin

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-29

**Â§áÊ≥®**: Accepted by TVCG

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂàÜÂ∏ÉÁöÑÊ∑±Â∫¶Ê≠£ÂàôÂåñ‰ª•Ëß£ÂÜ≥Â∞èÁõ∏Êú∫ËøêÂä®‰∏ãÁöÑÂä®ÊÄÅËßÜÂõæÂêàÊàêÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `Âä®ÊÄÅËßÜÂõæÂêàÊàê` `Â∞èÁõ∏Êú∫ËøêÂä®` `Ê∑±Â∫¶Ê≠£ÂàôÂåñ` `Gumbel-softmax` `Âú∫ÊôØÂá†‰ΩïË°®Á§∫` `Áõ∏Êú∫ÂèÇÊï∞Â≠¶‰π†` `ËÆ°ÁÆóÊú∫ËßÜËßâ` `NeRF`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂü∫‰∫éNeRFÁöÑÊñπÊ≥ïÂú®Â∞èÁõ∏Êú∫ËøêÂä®ÊÉÖÂÜµ‰∏ãÔºåÈù¢‰∏¥Âú∫ÊôØÂá†‰ΩïË°®Á§∫‰∏çÂáÜÁ°ÆÂíåÁõ∏Êú∫ÂèÇÊï∞‰º∞ËÆ°‰∏çÂáÜÁ°ÆÁöÑÊåëÊàò„ÄÇ
2. Êú¨ÊñáÊèêÂá∫Âü∫‰∫éÂàÜÂ∏ÉÁöÑÊ∑±Â∫¶Ê≠£ÂàôÂåñÔºàDDRÔºâÔºåÈÄöËøáGumbel-softmaxÊñπÊ≥ïÊîπËøõÊ∏≤ÊüìÊùÉÈáçÂàÜÂ∏ÉÁöÑÂØπÈΩêÔºåÁ°Æ‰øùÂ≠¶‰π†Âà∞Ê≠£Á°ÆÁöÑÂú∫ÊôØÂá†‰Ωï„ÄÇ
3. Â§ßÈáèÂÆûÈ™åË°®ÊòéÔºåÊâÄÊèêÊñπÊ≥ïÂú®Â∞èÁõ∏Êú∫ËøêÂä®ËæìÂÖ•‰∏ãÁöÑÂú∫ÊôØË°®Á§∫ÊïàÊûú‰ºò‰∫éÁé∞ÊúâÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜËâØÂ•ΩÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âä®ÊÄÅ‰∏âÁª¥Âú∫ÊôØÁöÑËßÜÂõæÂêàÊàêÈù¢‰∏¥ÈáçÂ§ßÊåëÊàò„ÄÇÂ∞ΩÁÆ°ËÆ∏Â§öÂü∫‰∫éNeRFÁöÑÊñπÊ≥ïÂèñÂæó‰∫ÜÊòæËëóÊàêÊûúÔºå‰ΩÜÂÆÉ‰ª¨ÂØπËæìÂÖ•ÂõæÂÉèÊàñËßÜÈ¢ë‰∏≠ÁöÑËøêÂä®ËßÜÂ∑Æ‰æùËµñËæÉÂ§ß„ÄÇÂΩìÁõ∏Êú∫ËøêÂä®ËåÉÂõ¥ÊúâÈôêÊàñÈùôÊ≠¢Êó∂ÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Âú∫ÊôØÂá†‰ΩïË°®Á§∫ÂíåÁõ∏Êú∫ÂèÇÊï∞‰º∞ËÆ°‰∏äÂ≠òÂú®‰∏ªË¶ÅÊåëÊàò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Á¨¨‰∏Ä‰∏™ÊåëÊàòÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂü∫‰∫éÂàÜÂ∏ÉÁöÑÊ∑±Â∫¶Ê≠£ÂàôÂåñÔºàDDRÔºâÔºåÁ°Æ‰øùÊ∏≤ÊüìÊùÉÈáçÂàÜÂ∏É‰∏éÁúüÂÆûÂàÜÂ∏ÉÂØπÈΩê„ÄÇÊàë‰ª¨ÈÄöËøáGumbel-softmax‰ªéÁ¶ªÊï£Ê∏≤ÊüìÊùÉÈáçÂàÜÂ∏É‰∏≠ÂèØÂæÆÂàÜÂú∞ÈááÊ†∑ÁÇπÔºåËÆ°ÁÆóËØØÂ∑ÆÁöÑÊúüÊúõ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºïÂÖ•Á∫¶ÊùüÔºåÁ°Æ‰øùÂÖâÁ∫øÊ≤øÁâ©‰ΩìËæπÁïåÂâçÁöÑÁ©∫Èó¥ÁÇπÁöÑ‰ΩìÁßØÂØÜÂ∫¶Êé•ËøëÈõ∂Ôºå‰ªéËÄå‰ΩøÊ®°ÂûãÂ≠¶‰π†Ê≠£Á°ÆÁöÑÂú∫ÊôØÂá†‰Ωï„ÄÇ‰∏∫‰∫ÜËß£ÈáäDDRÔºåÊàë‰ª¨ËøòÊèêÂá∫‰∫Ü‰∏ÄÁßçÂèØËßÜÂåñÂ∑•ÂÖ∑ÔºåËÉΩÂ§üËßÇÂØüÊ∏≤ÊüìÊùÉÈáçÁ∫ßÂà´ÁöÑÂú∫ÊôØÂá†‰ΩïË°®Á§∫„ÄÇÂØπ‰∫éÁ¨¨‰∫å‰∏™ÊåëÊàòÔºåÊàë‰ª¨Âú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÁªìÂêàÁõ∏Êú∫ÂèÇÊï∞Â≠¶‰π†Ôºå‰ª•Â¢ûÂº∫Ê®°ÂûãÂØπÁõ∏Êú∫ÂèÇÊï∞ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Â∞èÁõ∏Êú∫ËøêÂä®ËæìÂÖ•ÁöÑÂú∫ÊôØË°®Á§∫‰∏äÊïàÊûúÊòæËëóÔºå‰ºò‰∫éÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Âä®ÊÄÅ‰∏âÁª¥Âú∫ÊôØÂú®Â∞èÁõ∏Êú∫ËøêÂä®‰∏ãÁöÑËßÜÂõæÂêàÊàêÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Áõ∏Êú∫ËøêÂä®ËåÉÂõ¥ÊúâÈôêÊó∂ÔºåÂæÄÂæÄÊó†Ê≥ïÂáÜÁ°ÆË°®Á§∫Âú∫ÊôØÂá†‰ΩïÂíå‰º∞ËÆ°Áõ∏Êú∫ÂèÇÊï∞ÔºåÂØºËá¥ÂêàÊàêÊïàÊûú‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**Ôºö‰∏∫‰∫ÜËß£ÂÜ≥Âú∫ÊôØÂá†‰ΩïË°®Á§∫‰∏çÂáÜÁ°ÆÁöÑÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂü∫‰∫éÂàÜÂ∏ÉÁöÑÊ∑±Â∫¶Ê≠£ÂàôÂåñÔºàDDRÔºâÔºåÈÄöËøáÂèØÂæÆÂàÜÁöÑGumbel-softmaxÊñπÊ≥ïÔºå‰ªéÁ¶ªÊï£Ê∏≤ÊüìÊùÉÈáçÂàÜÂ∏É‰∏≠ÈááÊ†∑ÁÇπÔºå‰ª•ËÆ°ÁÆóËØØÂ∑ÆÁöÑÊúüÊúõÔºå‰ªéËÄåÊèêÈ´òÊ∏≤ÊüìÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆËæìÂÖ•„ÄÅDDRÊ®°Âùó„ÄÅÁõ∏Êú∫ÂèÇÊï∞Â≠¶‰π†Ê®°ÂùóÂíåÊ∏≤ÊüìËæìÂá∫„ÄÇDDRÊ®°ÂùóË¥üË¥£Ë∞ÉÊï¥Ê∏≤ÊüìÊùÉÈáçÂàÜÂ∏ÉÔºåËÄåÁõ∏Êú∫ÂèÇÊï∞Â≠¶‰π†Ê®°ÂùóÂàôÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠‰ºòÂåñÁõ∏Êú∫ÂèÇÊï∞ÔºåÂ¢ûÂº∫Ê®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂºïÂÖ•Âü∫‰∫éÂàÜÂ∏ÉÁöÑÊ∑±Â∫¶Ê≠£ÂàôÂåñÔºàDDRÔºâÔºåÈÄöËøáÂØπÊ∏≤ÊüìÊùÉÈáçÂàÜÂ∏ÉÁöÑ‰ºòÂåñÔºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞Â≠¶‰π†Âú∫ÊôØÂá†‰Ωï„ÄÇËøô‰∏é‰º†ÁªüÊñπÊ≥ï‰æùËµñ‰∫éÊ∑±Â∫¶ÊçüÂ§±ÁöÑÊñπÂºèÊúâÊú¨Ë¥®Âå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÊäÄÊúØÁªÜËäÇ‰∏äÔºåÊú¨ÊñáËÆæËÆ°‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞Êù•Á∫¶ÊùüÁ©∫Èó¥ÁÇπÁöÑ‰ΩìÁßØÂØÜÂ∫¶ÔºåÁ°Æ‰øùÂÖ∂Âú®Áâ©‰ΩìËæπÁïåÂâçÊé•ËøëÈõ∂„ÄÇÊ≠§Â§ñÔºåGumbel-softmaxÁöÑ‰ΩøÁî®‰ΩøÂæó‰ªéÁ¶ªÊï£ÂàÜÂ∏É‰∏≠ÈááÊ†∑ÂèòÂæóÂèØÂæÆÂàÜÔºå‰æø‰∫éÊ®°ÂûãËÆ≠ÁªÉ„ÄÇÈÄöËøáËøô‰∫õËÆæËÆ°ÔºåÊ®°ÂûãÂú®Â∞èÁõ∏Êú∫ËøêÂä®ÊÉÖÂÜµ‰∏ãÁöÑË°®Áé∞ÂæóÂà∞‰∫ÜÊòæËëóÊèêÂçá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÊâÄÊèêÊñπÊ≥ïÂú®Â∞èÁõ∏Êú∫ËøêÂä®ËæìÂÖ•‰∏ãÁöÑÂú∫ÊôØÂêàÊàêÊïàÊûúÊòæËëó‰ºò‰∫éÁé∞ÊúâÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÔºåÂÖ∑‰ΩìÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶ËææÂà∞20%‰ª•‰∏äÔºåÈ™åËØÅ‰∫ÜÊ®°ÂûãÂú®Â§çÊùÇÂä®ÊÄÅÂú∫ÊôØ‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂Âú®ËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÂíåËÆ°ÁÆóÊú∫ÂõæÂΩ¢Â≠¶Á≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÈÄöËøáÊèêÈ´òÂä®ÊÄÅÂú∫ÊôØÁöÑËßÜÂõæÂêàÊàêË¥®ÈáèÔºåÂèØ‰ª•‰∏∫Áî®Êà∑Êèê‰æõÊõ¥ÁúüÂÆûÁöÑÊ≤âÊµ∏‰ΩìÈ™åÔºåÊé®Âä®Áõ∏ÂÖ≥ÊäÄÊúØÁöÑÂèëÂ±ïÂíåÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Novel view synthesis for dynamic $3$D scenes poses a significant challenge. Many notable efforts use NeRF-based approaches to address this task and yield impressive results. However, these methods rely heavily on sufficient motion parallax in the input images or videos. When the camera motion range becomes limited or even stationary (i.e., small camera motion), existing methods encounter two primary challenges: incorrect representation of scene geometry and inaccurate estimation of camera parameters. These challenges make prior methods struggle to produce satisfactory results or even become invalid. To address the first challenge, we propose a novel Distribution-based Depth Regularization (DDR) that ensures the rendering weight distribution to align with the true distribution. Specifically, unlike previous methods that use depth loss to calculate the error of the expectation, we calculate the expectation of the error by using Gumbel-softmax to differentiably sample points from discrete rendering weight distribution. Additionally, we introduce constraints that enforce the volume density of spatial points before the object boundary along the ray to be near zero, ensuring that our model learns the correct geometry of the scene. To demystify the DDR, we further propose a visualization tool that enables observing the scene geometry representation at the rendering weight level. For the second challenge, we incorporate camera parameter learning during training to enhance the robustness of our model to camera parameters. We conduct extensive experiments to demonstrate the effectiveness of our approach in representing scenes with small camera motion input, and our results compare favorably to state-of-the-art methods.

