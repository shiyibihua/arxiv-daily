---
layout: default
title: IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering
---

# IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23329" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23329v1</a>
  <a href="https://arxiv.org/pdf/2506.23329.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23329v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23329v1', 'IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Parker Liu, Chenxin Li, Zhengxin Li, Yipeng Wu, Wuyang Li, Zhiqin Yang, Zhenyuan Zhang, Yunlong Lin, Sirui Han, Brandon Y. Feng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29

**å¤‡æ³¨**: Project Page: https://ir3d-bench.github.io/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIR3D-Benchä»¥è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹åœºæ™¯ç†è§£ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `åœºæ™¯ç†è§£` `é€†æ¸²æŸ“` `å·¥å…·ä½¿ç”¨` `ç”Ÿæˆèƒ½åŠ›` `3Dé‡å»º` `è¯„ä¼°æŒ‡æ ‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨åœºæ™¯ç†è§£æ–¹é¢ä¸»è¦ä¾èµ–è¢«åŠ¨è¯†åˆ«ï¼Œç¼ºä¹ä¸»åŠ¨åˆ›é€ èƒ½åŠ›ã€‚
2. IR3D-Benché€šè¿‡è¦æ±‚æ¨¡å‹ä½¿ç”¨å·¥å…·é‡å»º3Dç»“æ„ï¼Œæ¨åŠ¨äº†â€œé€šè¿‡åˆ›é€ ç†è§£â€çš„æ–°æ–¹æ³•ã€‚
3. åˆæ­¥å®éªŒè¡¨æ˜ï¼Œå°½ç®¡å·¥å…·ä½¿ç”¨èƒ½åŠ›è‰¯å¥½ï¼Œä½†åœ¨è§†è§‰ç²¾åº¦æ–¹é¢ä»æœ‰å¾…æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨æè¿°æ€§ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬æ˜¯å¦çœŸæ­£ç†è§£è§†è§‰è§‚å¯Ÿä¸­çš„åœºæ™¯ä»ç„¶ä¸ç¡®å®šã€‚æˆ‘ä»¬å¼•å…¥äº†IR3D-Benchï¼Œä¸€ä¸ªåŸºå‡†æŒ‘æˆ˜VLMsé€šè¿‡ä¸»åŠ¨åˆ›é€ è€Œéè¢«åŠ¨è¯†åˆ«æ¥å±•ç¤ºç†è§£èƒ½åŠ›ã€‚åŸºäºåˆ†æ-åˆæˆèŒƒå¼ï¼ŒIR3D-Benchè¦æ±‚è§†è§‰è¯­è¨€ä»£ç†ï¼ˆVLAsï¼‰ä¸»åŠ¨ä½¿ç”¨ç¼–ç¨‹å’Œæ¸²æŸ“å·¥å…·é‡å»ºè¾“å…¥å›¾åƒçš„3Dç»“æ„ï¼Œå®ç°å·¥å…·ä½¿ç”¨ä¸‹çš„é€†æ¸²æŸ“ã€‚è¿™ç§â€œé€šè¿‡åˆ›é€ ç†è§£â€çš„æ–¹æ³•æ¢è®¨äº†VLAsçš„å·¥å…·ä½¿ç”¨ç”Ÿæˆèƒ½åŠ›ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿåœºæ™¯ç†è§£åŸºå‡†æ‰€æµ‹é‡çš„æè¿°æ€§æˆ–å¯¹è¯èƒ½åŠ›ã€‚æˆ‘ä»¬æä¾›äº†ä¸€å¥—å…¨é¢çš„æŒ‡æ ‡æ¥è¯„ä¼°å‡ ä½•å‡†ç¡®æ€§ã€ç©ºé—´å…³ç³»ã€å¤–è§‚å±æ€§å’Œæ•´ä½“å¯ä¿¡åº¦ã€‚åˆæ­¥å®éªŒæ˜¾ç¤ºï¼Œå°½ç®¡å½“å‰çš„VLMsåœ¨å·¥å…·ä½¿ç”¨æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨è§†è§‰ç²¾åº¦ä¸Šä»å­˜åœ¨å±€é™æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨åœºæ™¯ç†è§£ä¸­çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯å®ƒä»¬åœ¨è¢«åŠ¨è¯†åˆ«åœºæ™¯æ—¶ç¼ºä¹ä¸»åŠ¨åˆ›é€ èƒ½åŠ›çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡IR3D-BenchåŸºå‡†ï¼Œè¦æ±‚è§†è§‰è¯­è¨€ä»£ç†ä¸»åŠ¨ä½¿ç”¨ç¼–ç¨‹å’Œæ¸²æŸ“å·¥å…·é‡å»ºè¾“å…¥å›¾åƒçš„3Dç»“æ„ï¼Œä»è€Œå®ç°å·¥å…·ä½¿ç”¨ä¸‹çš„é€†æ¸²æŸ“ã€‚è¿™ç§æ–¹æ³•å¼ºè°ƒâ€œé€šè¿‡åˆ›é€ ç†è§£â€çš„ç†å¿µï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šIR3D-Benchçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€å·¥å…·ä½¿ç”¨ã€3Dé‡å»ºå’Œè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚æ¨¡å‹é¦–å…ˆæ¥æ”¶è¾“å…¥å›¾åƒï¼Œç„¶ååˆ©ç”¨ç¼–ç¨‹å’Œæ¸²æŸ“å·¥å…·è¿›è¡Œ3Dç»“æ„çš„é‡å»ºï¼Œæœ€åé€šè¿‡ä¸€ç³»åˆ—æŒ‡æ ‡è¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†â€œç†è§£-åˆ›é€ â€è¿™ä¸€æ–°èŒƒå¼ï¼Œçªç ´äº†ä¼ ç»Ÿåœºæ™¯ç†è§£çš„é™åˆ¶ï¼Œå¼ºè°ƒäº†å·¥å…·ä½¿ç”¨çš„ç”Ÿæˆèƒ½åŠ›ã€‚è¿™ä¸ä»¥å¾€ä»…ä¾èµ–æè¿°æ€§ä»»åŠ¡çš„æ¨¡å‹å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒIR3D-Benchä½¿ç”¨äº†ä¸€å¥—å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡ï¼ŒåŒ…æ‹¬å‡ ä½•å‡†ç¡®æ€§ã€ç©ºé—´å…³ç³»å’Œå¤–è§‚å±æ€§ç­‰ï¼Œä»¥ç¡®ä¿å¯¹æ¨¡å‹ç”Ÿæˆèƒ½åŠ›çš„å…¨é¢è¯„ä¼°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åˆæ­¥å®éªŒæ˜¾ç¤ºï¼Œå°½ç®¡å½“å‰çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å·¥å…·ä½¿ç”¨æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨è§†è§‰ç²¾åº¦ä¸Šä»å­˜åœ¨æ˜¾è‘—å±€é™ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨å‡ ä½•å‡†ç¡®æ€§å’Œç©ºé—´å…³ç³»çš„é‡å»ºä¸Šæœªèƒ½è¾¾åˆ°é¢„æœŸæ•ˆæœï¼Œæç¤ºæœªæ¥ç ”ç©¶éœ€èšç„¦äºæå‡è§†è§‰ç²¾åº¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘å’Œè‡ªåŠ¨åŒ–è®¾è®¡ç­‰ã€‚é€šè¿‡æå‡è§†è§‰è¯­è¨€æ¨¡å‹çš„åœºæ™¯ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥åœ¨è¿™äº›é¢†åŸŸå®ç°æ›´é«˜æ•ˆçš„å†…å®¹ç”Ÿæˆå’Œäº¤äº’ä½“éªŒï¼Œæ¨åŠ¨æ™ºèƒ½ä»£ç†çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-language models (VLMs) excel at descriptive tasks, but whether they truly understand scenes from visual observations remains uncertain. We introduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understanding through active creation rather than passive recognition. Grounded in the analysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs) with actively using programming and rendering tools to recreate the underlying 3D structure of an input image, achieving agentic inverse rendering through tool use. This "understanding-by-creating" approach probes the tool-using generative capacity of VLAs, moving beyond the descriptive or conversational capacity measured by traditional scene understanding benchmarks. We provide a comprehensive suite of metrics to evaluate geometric accuracy, spatial relations, appearance attributes, and overall plausibility. Initial experiments on agentic inverse rendering powered by various state-of-the-art VLMs highlight current limitations, particularly in visual precision rather than basic tool usage. IR3D-Bench, including data and evaluation protocols, is released to facilitate systematic study and development of tool-using VLAs towards genuine scene understanding by creating.

