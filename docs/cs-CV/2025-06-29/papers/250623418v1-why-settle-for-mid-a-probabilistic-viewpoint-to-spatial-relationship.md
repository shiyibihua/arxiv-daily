---
layout: default
title: Why Settle for Mid: A Probabilistic Viewpoint to Spatial Relationship Alignment in Text-to-image Models
---

# Why Settle for Mid: A Probabilistic Viewpoint to Spatial Relationship Alignment in Text-to-image Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23418" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23418v1</a>
  <a href="https://arxiv.org/pdf/2506.23418.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23418v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23418v1', 'Why Settle for Mid: A Probabilistic Viewpoint to Spatial Relationship Alignment in Text-to-image Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Parham Rezaei, Arash Marioriyad, Mahdieh Soleymani Baghshah, Mohammad Hossein Rohban

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29

**å¤‡æ³¨**: 12 main pages, 18 figures, and 16 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¦‚ç‡æ¡†æ¶ä»¥è§£å†³æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„ç©ºé—´å…³ç³»å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `ç©ºé—´å…³ç³»å¯¹é½` `æ¦‚ç‡æ¨¡å‹` `è¯„ä¼°æŒ‡æ ‡` `ç”Ÿæˆæ–¹æ³•` `è®¡ç®—æœºè§†è§‰` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹åœ¨ç»„åˆç”Ÿæˆä¸­é¢ä¸´ç©ºé—´å…³ç³»é”™ä½çš„é—®é¢˜ï¼Œéš¾ä»¥å‡†ç¡®åæ˜ è¾“å…¥æç¤ºä¸­çš„ç»†èŠ‚ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ¦‚ç‡çš„æ¡†æ¶ï¼Œé€šè¿‡ä¼˜è¶Šæ€§æ¦‚ç‡ï¼ˆPoSï¼‰å»ºæ¨¡å¯¹è±¡çš„ç›¸å¯¹ç©ºé—´ä½ç½®ï¼Œæ”¹å–„ç©ºé—´å…³ç³»å¯¹é½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPSEæŒ‡æ ‡ä¸äººç±»åˆ¤æ–­çš„å¯¹é½ç¨‹åº¦æ›´é«˜ï¼ŒPSGæ–¹æ³•åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡ã€çœŸå®ä¸”å¤šæ ·çš„å›¾åƒï¼Œä½†åœ¨ç»„åˆç”Ÿæˆæ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å‡†ç¡®è¡¨ç¤ºè¾“å…¥æç¤ºä¸­æŒ‡å®šçš„ç»†èŠ‚æ–¹é¢ã€‚ä¸€ä¸ªæ™®éå­˜åœ¨çš„é—®é¢˜æ˜¯ç©ºé—´å…³ç³»çš„é”™ä½ï¼Œæ¨¡å‹å¸¸å¸¸æ— æ³•å¿ å®ç”Ÿæˆåæ˜ è¾“å…¥æç¤ºä¸­å¯¹è±¡ä¹‹é—´ç©ºé—´é…ç½®çš„å›¾åƒã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¦‚ç‡æ¡†æ¶ï¼Œç”¨äºå»ºæ¨¡åœºæ™¯ä¸­å¯¹è±¡çš„ç›¸å¯¹ç©ºé—´ä½ç½®ï¼Œåˆ©ç”¨äº†ä¼˜è¶Šæ€§æ¦‚ç‡ï¼ˆPoSï¼‰çš„æ¦‚å¿µã€‚æˆ‘ä»¬åšå‡ºäº†ä¸¤é¡¹é‡è¦è´¡çŒ®ï¼šé¦–å…ˆï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡PoSåŸºç¡€è¯„ä¼°ï¼ˆPSEï¼‰ï¼Œç”¨äºè¯„ä¼°æ–‡æœ¬ä¸å›¾åƒä¹‹é—´çš„2Då’Œ3Dç©ºé—´å…³ç³»çš„å¯¹é½ç¨‹åº¦ï¼›å…¶æ¬¡ï¼Œæå‡ºäº†PoSåŸºç¡€ç”Ÿæˆï¼ˆPSGï¼‰ï¼Œä¸€ç§åœ¨æ¨ç†æ—¶æ”¹å–„T2Iæ¨¡å‹ä¸­2Då’Œ3Dç©ºé—´å…³ç³»å¯¹é½çš„æ–¹æ³•ï¼Œæ— éœ€å¾®è°ƒã€‚å®éªŒè¡¨æ˜ï¼ŒPSEæŒ‡æ ‡ä¸äººç±»åˆ¤æ–­çš„å¯¹é½ç¨‹åº¦ä¼˜äºä¼ ç»Ÿçš„ä¸­å¿ƒåŸºå‡†æŒ‡æ ‡ï¼ŒPSGæ˜¾è‘—æå‡äº†æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ç”ŸæˆæŒ‡å®šç©ºé—´é…ç½®å›¾åƒçš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹åœ¨ç»„åˆç”Ÿæˆä¸­ç©ºé—´å…³ç³»é”™ä½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆå›¾åƒæ—¶ï¼Œå¸¸å¸¸æ— æ³•å‡†ç¡®åæ˜ è¾“å…¥æç¤ºä¸­å¯¹è±¡ä¹‹é—´çš„ç©ºé—´é…ç½®ï¼Œå¯¼è‡´ç”Ÿæˆç»“æœä¸ç¬¦åˆäººç±»çš„ç›´è§‚ç†è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¦‚ç‡æ¡†æ¶ï¼Œåˆ©ç”¨ä¼˜è¶Šæ€§æ¦‚ç‡ï¼ˆPoSï¼‰æ¥å»ºæ¨¡å¯¹è±¡çš„ç›¸å¯¹ç©ºé—´ä½ç½®ã€‚é€šè¿‡å¼•å…¥PoSåŸºç¡€è¯„ä¼°ï¼ˆPSEï¼‰å’ŒPoSåŸºç¡€ç”Ÿæˆï¼ˆPSGï¼‰æ–¹æ³•ï¼Œæ”¹å–„äº†ç©ºé—´å…³ç³»çš„å¯¹é½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯PSEè¯„ä¼°æ¨¡å—ï¼Œç”¨äºè¯„ä¼°æ–‡æœ¬ä¸å›¾åƒä¹‹é—´çš„ç©ºé—´å…³ç³»å¯¹é½ï¼›å…¶æ¬¡æ˜¯PSGç”Ÿæˆæ¨¡å—ï¼Œåœ¨æ¨ç†é˜¶æ®µé€šè¿‡å¥–åŠ±å‡½æ•°ä¼˜åŒ–ç”Ÿæˆè¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†PSEè¯„ä¼°æŒ‡æ ‡å’ŒPSGç”Ÿæˆæ–¹æ³•ã€‚PSEä¸ä¼ ç»Ÿçš„ä¸­å¿ƒåŸºå‡†æŒ‡æ ‡ç›¸æ¯”ï¼Œæ›´èƒ½åæ˜ äººç±»çš„åˆ¤æ–­ï¼Œè€ŒPSGåˆ™åœ¨ä¸éœ€è¦å¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æ”¹å–„äº†ç©ºé—´å…³ç³»çš„å¯¹é½ã€‚

**å…³é”®è®¾è®¡**ï¼šPSGæ–¹æ³•é‡‡ç”¨äº†åŸºäºè¯æ€§ï¼ˆPart-of-Speechï¼‰çš„å¥–åŠ±å‡½æ•°ï¼Œèƒ½å¤Ÿé€šè¿‡ä¸¤ç§æ–¹å¼ä½¿ç”¨ï¼šä¸€ç§æ˜¯ä½œä¸ºæ¢¯åº¦å¼•å¯¼æœºåˆ¶ï¼Œåº”ç”¨äºå»å™ªæ­¥éª¤ä¸­çš„äº¤å‰æ³¨æ„åŠ›å›¾ï¼›å¦ä¸€ç§æ˜¯ä½œä¸ºæœç´¢ç­–ç•¥ï¼Œè¯„ä¼°ä¸€ç»„åˆå§‹å™ªå£°å‘é‡ä»¥é€‰æ‹©æœ€ä½³å‘é‡ã€‚å®éªŒä¸­ï¼ŒPSEæŒ‡æ ‡ä¸äººç±»åˆ¤æ–­çš„å¯¹é½ç¨‹åº¦æ˜¾è‘—æé«˜ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚ç©ºé—´å…³ç³»å‡†ç¡®æ€§è¯„ä¼°ä¸­çš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPSEæŒ‡æ ‡åœ¨ç©ºé—´å…³ç³»å¯¹é½æ–¹é¢ä¸äººç±»åˆ¤æ–­çš„å¯¹é½ç¨‹åº¦æ˜¾è‘—æé«˜ï¼Œä¸”PSGæ–¹æ³•åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæå‡å¹…åº¦è¾¾åˆ°XX%ã€‚å…·ä½“è€Œè¨€ï¼ŒPSGåœ¨ç”Ÿæˆå›¾åƒçš„ç©ºé—´é…ç½®å‡†ç¡®æ€§ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€å›¾åƒç”Ÿæˆã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰ã€‚é€šè¿‡æ”¹å–„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„ç©ºé—´å…³ç³»å¯¹é½èƒ½åŠ›ï¼Œå¯ä»¥æå‡ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå‡†ç¡®æ€§ï¼Œè¿›è€Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥å’Œåº”ç”¨è½åœ°ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šåœ¨è‰ºæœ¯åˆ›ä½œã€æ¸¸æˆè®¾è®¡å’Œè‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆç­‰æ–¹é¢äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite the ability of text-to-image models to generate high-quality, realistic, and diverse images, they face challenges in compositional generation, often struggling to accurately represent details specified in the input prompt. A prevalent issue in compositional generation is the misalignment of spatial relationships, as models often fail to faithfully generate images that reflect the spatial configurations specified between objects in the input prompts. To address this challenge, we propose a novel probabilistic framework for modeling the relative spatial positioning of objects in a scene, leveraging the concept of Probability of Superiority (PoS). Building on this insight, we make two key contributions. First, we introduce a novel evaluation metric, PoS-based Evaluation (PSE), designed to assess the alignment of 2D and 3D spatial relationships between text and image, with improved adherence to human judgment. Second, we propose PoS-based Generation (PSG), an inference-time method that improves the alignment of 2D and 3D spatial relationships in T2I models without requiring fine-tuning. PSG employs a Part-of-Speech PoS-based reward function that can be utilized in two distinct ways: (1) as a gradient-based guidance mechanism applied to the cross-attention maps during the denoising steps, or (2) as a search-based strategy that evaluates a set of initial noise vectors to select the best one. Extensive experiments demonstrate that the PSE metric exhibits stronger alignment with human judgment compared to traditional center-based metrics, providing a more nuanced and reliable measure of complex spatial relationship accuracy in text-image alignment. Furthermore, PSG significantly enhances the ability of text-to-image models to generate images with specified spatial configurations, outperforming state-of-the-art methods across multiple evaluation metrics and benchmarks.

