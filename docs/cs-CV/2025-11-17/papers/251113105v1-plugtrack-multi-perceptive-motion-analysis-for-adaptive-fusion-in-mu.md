---
layout: default
title: PlugTrack: Multi-Perceptive Motion Analysis for Adaptive Fusion in Multi-Object Tracking
---

# PlugTrack: Multi-Perceptive Motion Analysis for Adaptive Fusion in Multi-Object Tracking

**arXiv**: [2511.13105v1](https://arxiv.org/abs/2511.13105) | [PDF](https://arxiv.org/pdf/2511.13105.pdf)

**ä½œè€…**: Seungjae Kim, SeungJoon Lee, MyeongAh Cho

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPlugTrackæ¡†æž¶ï¼Œé€šè¿‡è‡ªé€‚åº”èžåˆè¿åŠ¨é¢„æµ‹å™¨è§£å†³å¤šç›®æ ‡è·Ÿè¸ªä¸­çº¿æ€§ä¸Žéžçº¿æ€§è¿åŠ¨æ¨¡å¼é—®é¢˜**

**å…³é”®è¯**: `å¤šç›®æ ‡è·Ÿè¸ª` `è¿åŠ¨é¢„æµ‹` `è‡ªé€‚åº”èžåˆ` `å¡å°”æ›¼æ»¤æ³¢å™¨` `æ•°æ®é©±åŠ¨æ–¹æ³•` `å¤šæ„ŸçŸ¥åˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šç›®æ ‡è·Ÿè¸ªä¸­ï¼Œå¡å°”æ›¼æ»¤æ³¢å™¨æ— æ³•å¤„ç†éžçº¿æ€§è¿åŠ¨ï¼Œè€Œæ•°æ®é©±åŠ¨é¢„æµ‹å™¨æ³›åŒ–å·®ä¸”è®¡ç®—å¼€é”€å¤§
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å¤šæ„ŸçŸ¥è¿åŠ¨åˆ†æžç”Ÿæˆè‡ªé€‚åº”èžåˆå› å­ï¼Œç»“åˆå¡å°”æ›¼æ»¤æ³¢å™¨å’Œæ•°æ®é©±åŠ¨é¢„æµ‹å™¨
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨MOT17/MOT20ä¸Šæ€§èƒ½æ˜¾è‘—æå‡ï¼Œåœ¨DanceTrackä¸Šè¾¾åˆ°æœ€å…ˆè¿›æ°´å¹³ï¼Œæ— éœ€ä¿®æ”¹çŽ°æœ‰é¢„æµ‹å™¨

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-object tracking (MOT) predominantly follows the tracking-by-detection paradigm, where Kalman filters serve as the standard motion predictor due to computational efficiency but inherently fail on non-linear motion patterns. Conversely, recent data-driven motion predictors capture complex non-linear dynamics but suffer from limited domain generalization and computational overhead. Through extensive analysis, we reveal that even in datasets dominated by non-linear motion, Kalman filter outperforms data-driven predictors in up to 34\% of cases, demonstrating that real-world tracking scenarios inherently involve both linear and non-linear patterns. To leverage this complementarity, we propose PlugTrack, a novel framework that adaptively fuses Kalman filter and data-driven motion predictors through multi-perceptive motion understanding. Our approach employs multi-perceptive motion analysis to generate adaptive blending factors. PlugTrack achieves significant performance gains on MOT17/MOT20 and state-of-the-art on DanceTrack without modifying existing motion predictors. To the best of our knowledge, PlugTrack is the first framework to bridge classical and modern motion prediction paradigms through adaptive fusion in MOT.

