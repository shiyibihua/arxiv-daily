---
layout: default
title: Towards Affect-Adaptive Human-Robot Interaction: A Protocol for Multimodal Dataset Collection on Social Anxiety
---

# Towards Affect-Adaptive Human-Robot Interaction: A Protocol for Multimodal Dataset Collection on Social Anxiety

**arXiv**: [2511.13530v1](https://arxiv.org/abs/2511.13530) | [PDF](https://arxiv.org/pdf/2511.13530.pdf)

**ä½œè€…**: Vesna Poprcova, Iulia Lefter, Matthias Wieser, Martijn Warnier, Frances Brazier

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€æ•°æ®é›†æ”¶é›†åè®®ä»¥æ”¯æŒç¤¾äº¤ç„¦è™‘æ£€æµ‹çš„äººæœºäº¤äº’ç ”ç©¶**

**å…³é”®è¯**: `ç¤¾äº¤ç„¦è™‘æ£€æµ‹` `å¤šæ¨¡æ€æ•°æ®é›†` `äººæœºäº¤äº’` `ç”Ÿç†ä¿¡å·` `æƒ…æ„Ÿè®¡ç®—` `æœºå™¨äººå®žéªŒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç¤¾äº¤ç„¦è™‘å½±å“äººé™…äº’åŠ¨ï¼Œä½†ç›¸å…³å¤šæ¨¡æ€æ•°æ®é›†ç¨€ç¼ºï¼Œé™åˆ¶ç ”ç©¶è¿›å±•ã€‚
2. è®¾è®¡åè®®æ”¶é›†åŒæ­¥éŸ³é¢‘ã€è§†é¢‘å’Œç”Ÿç†æ•°æ®ï¼Œç»“åˆæƒ…å¢ƒæ•°æ®å¢žå¼ºåˆ†æžã€‚
3. åœ¨å—æŽ§æ¡ä»¶ä¸‹ï¼Œä½¿ç”¨Furhatæœºå™¨äººè¿›è¡Œè§’è‰²æ‰®æ¼”å®žéªŒï¼Œæ¶‰åŠè‡³å°‘70åå‚ä¸Žè€…ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Social anxiety is a prevalent condition that affects interpersonal interactions and social functioning. Recent advances in artificial intelligence and social robotics offer new opportunities to examine social anxiety in the human-robot interaction context. Accurate detection of affective states and behaviours associated with social anxiety requires multimodal datasets, where each signal modality provides complementary insights into its manifestations. However, such datasets remain scarce, limiting progress in both research and applications. To address this, this paper presents a protocol for multimodal dataset collection designed to reflect social anxiety in a human-robot interaction context. The dataset will consist of synchronised audio, video, and physiological recordings acquired from at least 70 participants, grouped according to their level of social anxiety, as they engage in approximately 10-minute interactive Wizard-of-Oz role-play scenarios with the Furhat social robot under controlled experimental conditions. In addition to multimodal data, the dataset will be enriched with contextual data providing deeper insight into individual variability in social anxiety responses. This work can contribute to research on affect-adaptive human-robot interaction by providing support for robust multimodal detection of social anxiety.

