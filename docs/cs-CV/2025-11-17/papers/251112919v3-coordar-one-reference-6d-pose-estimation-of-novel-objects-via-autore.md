---
layout: default
title: CoordAR: One-Reference 6D Pose Estimation of Novel Objects via Autoregressive Coordinate Map Generation
---

# CoordAR: One-Reference 6D Pose Estimation of Novel Objects via Autoregressive Coordinate Map Generation

**arXiv**: [2511.12919v3](https://arxiv.org/abs/2511.12919) | [PDF](https://arxiv.org/pdf/2511.12919.pdf)

**ä½œè€…**: Dexin Zuo, Ang Li, Wei Wang, Wenxian Yu, Danping Zou

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-17 (æ›´æ–°: 2025-12-15)

**å¤‡æ³¨**: 7 pages, accepted by AAAI 2026 (oral)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**CoordARï¼šåŸºäºŽè‡ªå›žå½’åæ ‡å›¾ç”Ÿæˆçš„å•å‚è€ƒæ–°ç‰©ä½“6Dä½å§¿ä¼°è®¡**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `6Dä½å§¿ä¼°è®¡` `å•å‚è€ƒå›¾åƒ` `è‡ªå›žå½’æ¨¡åž‹` `åæ ‡å›¾ç”Ÿæˆ` `Transformer`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŸºäºŽå•å‚è€ƒå›¾åƒçš„6Dä½å§¿ä¼°è®¡æ–¹æ³•ä¾èµ–å®žå€¼åæ ‡å›žå½’ï¼Œç¼ºä¹å…¨å±€ä¸€è‡´æ€§ï¼Œéš¾ä»¥å¤„ç†å¯¹ç§°å’Œé®æŒ¡æƒ…å†µã€‚
2. CoordARæå‡ºä¸€ç§è‡ªå›žå½’æ¡†æž¶ï¼Œå°†3D-3Då¯¹åº”å…³ç³»å»ºæ¨¡ä¸ºç¦»æ•£tokençš„æ˜ å°„ï¼Œé€šè¿‡æ¦‚çŽ‡è‡ªå›žå½’æ–¹å¼é¢„æµ‹åæ ‡ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCoordARåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¯¹å¯¹ç§°ã€é®æŒ¡ç­‰æƒ…å†µå…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºCoordARï¼Œä¸€ç§ç”¨äºŽæ–°ç‰©ä½“å•å‚è€ƒ6Dä½å§¿ä¼°è®¡çš„è‡ªå›žå½’æ¡†æž¶ã€‚é’ˆå¯¹çŽ°æœ‰æ–¹æ³•ä¾èµ–å®žå€¼åæ ‡å›žå½’ï¼Œå­˜åœ¨å…¨å±€ä¸€è‡´æ€§ä¸è¶³ã€å¯¹ç§°æˆ–é®æŒ¡åœºæ™¯ä¸‹ç¼ºä¹ä¸ç¡®å®šæ€§å»ºæ¨¡ç­‰é—®é¢˜ï¼ŒCoordARå°†å‚è€ƒè§†å›¾å’ŒæŸ¥è¯¢è§†å›¾ä¹‹é—´çš„3D-3Då¯¹åº”å…³ç³»å»ºæ¨¡ä¸ºç¦»æ•£tokençš„æ˜ å°„ï¼Œå¹¶é€šè¿‡è‡ªå›žå½’å’Œæ¦‚çŽ‡çš„æ–¹å¼èŽ·å¾—ã€‚ä¸ºäº†å®žçŽ°ç²¾ç¡®çš„å¯¹åº”å…³ç³»å›žå½’ï¼ŒCoordARå¼•å…¥äº†ï¼š1) ä¸€ç§æ–°é¢–çš„åæ ‡å›¾tokenåŒ–æ–¹æ³•ï¼Œæ”¯æŒåœ¨ç¦»æ•£3Dç©ºé—´ä¸Šçš„æ¦‚çŽ‡é¢„æµ‹ï¼›2) ä¸€ç§æ¨¡æ€è§£è€¦ç¼–ç ç­–ç•¥ï¼Œåˆ†åˆ«ç¼–ç RGBå¤–è§‚å’Œåæ ‡çº¿ç´¢ï¼›3) ä¸€ä¸ªè‡ªå›žå½’Transformerè§£ç å™¨ï¼Œä»¥ä½ç½®å¯¹é½çš„æŸ¥è¯¢ç‰¹å¾å’Œéƒ¨åˆ†ç”Ÿæˆçš„tokenåºåˆ—ä¸ºæ¡ä»¶ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒCoordARæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨çœŸå®žä¸–ç•Œæµ‹è¯•ä¸­è¡¨çŽ°å‡ºå¯¹å¯¹ç§°æ€§ã€é®æŒ¡å’Œå…¶ä»–æŒ‘æˆ˜çš„å¼ºå¤§é²æ£’æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰åŸºäºŽå•å‚è€ƒå›¾åƒçš„6Dä½å§¿ä¼°è®¡æ–¹æ³•ï¼Œä¾èµ–äºŽç›´æŽ¥å›žå½’3Dåæ ‡ï¼Œè¿™ç§æ–¹æ³•å—é™äºŽå·ç§¯ç¥žç»ç½‘ç»œçš„å±€éƒ¨æ€§ï¼Œéš¾ä»¥ä¿è¯å…¨å±€ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œåœ¨ç‰©ä½“å…·æœ‰å¯¹ç§°æ€§æˆ–å­˜åœ¨é®æŒ¡æ—¶ï¼Œåæ ‡å›žå½’çš„ä¸ç¡®å®šæ€§éš¾ä»¥å»ºæ¨¡ï¼Œå¯¼è‡´ä½å§¿ä¼°è®¡ç²¾åº¦ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCoordARçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†3Dåæ ‡å›žå½’é—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªç¦»æ•£tokençš„ç”Ÿæˆé—®é¢˜ï¼Œåˆ©ç”¨è‡ªå›žå½’æ¨¡åž‹é¢„æµ‹å‚è€ƒå›¾åƒå’ŒæŸ¥è¯¢å›¾åƒä¹‹é—´çš„3D-3Då¯¹åº”å…³ç³»ã€‚é€šè¿‡å°†3Dç©ºé—´ç¦»æ•£åŒ–ä¸ºä¸€ç³»åˆ—tokenï¼Œå¹¶ä½¿ç”¨Transformerè¿›è¡Œåºåˆ—å»ºæ¨¡ï¼Œå¯ä»¥æ›´å¥½åœ°æ•æ‰å…¨å±€ä¿¡æ¯å’Œå»ºæ¨¡ä¸ç¡®å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šCoordARçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) åæ ‡å›¾tokenåŒ–æ¨¡å—ï¼Œå°†3Dç©ºé—´ç¦»æ•£åŒ–ä¸ºtokenï¼›2) æ¨¡æ€è§£è€¦ç¼–ç å™¨ï¼Œåˆ†åˆ«æå–å‚è€ƒå›¾åƒå’ŒæŸ¥è¯¢å›¾åƒçš„RGBå¤–è§‚ç‰¹å¾å’Œåæ ‡ä¿¡æ¯ï¼›3) è‡ªå›žå½’Transformerè§£ç å™¨ï¼Œä»¥ä½ç½®å¯¹é½çš„æŸ¥è¯¢ç‰¹å¾å’Œéƒ¨åˆ†ç”Ÿæˆçš„tokenåºåˆ—ä¸ºæ¡ä»¶ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªtokenï¼Œä»Žè€Œç”Ÿæˆå®Œæ•´çš„åæ ‡å›¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šCoordARçš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) æå‡ºäº†åæ ‡å›¾tokenåŒ–æ–¹æ³•ï¼Œå°†è¿žç»­çš„3Dåæ ‡ç©ºé—´ç¦»æ•£åŒ–ä¸ºtokenï¼Œä¾¿äºŽä½¿ç”¨åºåˆ—æ¨¡åž‹è¿›è¡Œå»ºæ¨¡ï¼›2) é‡‡ç”¨äº†æ¨¡æ€è§£è€¦ç¼–ç ç­–ç•¥ï¼Œåˆ†åˆ«ç¼–ç RGBå¤–è§‚å’Œåæ ‡ä¿¡æ¯ï¼Œé¿å…äº†ä¸åŒæ¨¡æ€ä¿¡æ¯ä¹‹é—´çš„å¹²æ‰°ï¼›3) ä½¿ç”¨è‡ªå›žå½’Transformerè§£ç å™¨ï¼Œèƒ½å¤Ÿæ•æ‰å…¨å±€ä¿¡æ¯å’Œå»ºæ¨¡ä¸ç¡®å®šæ€§ï¼Œä»Žè€Œæé«˜ä½å§¿ä¼°è®¡çš„ç²¾åº¦å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåæ ‡å›¾tokenåŒ–ï¼šå°†3Dç©ºé—´åˆ’åˆ†ä¸ºå¤šä¸ªä½“ç´ ï¼Œæ¯ä¸ªä½“ç´ å¯¹åº”ä¸€ä¸ªtokenã€‚æ¨¡æ€è§£è€¦ç¼–ç å™¨ï¼šä½¿ç”¨ä¸¤ä¸ªç‹¬ç«‹çš„å·ç§¯ç¥žç»ç½‘ç»œåˆ†åˆ«æå–RGBå¤–è§‚ç‰¹å¾å’Œåæ ‡ä¿¡æ¯ã€‚è‡ªå›žå½’Transformerè§£ç å™¨ï¼šä½¿ç”¨æ ‡å‡†çš„Transformerç»“æž„ï¼Œå¹¶å¼•å…¥ä½ç½®ç¼–ç æ¥è¡¨ç¤ºtokençš„ä½ç½®ä¿¡æ¯ã€‚æŸå¤±å‡½æ•°ï¼šä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥è®­ç»ƒè‡ªå›žå½’Transformerè§£ç å™¨ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

CoordARåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨MOPEDæ•°æ®é›†ä¸Šï¼ŒCoordARçš„ä½å§¿ä¼°è®¡ç²¾åº¦æ¯”çŽ°æœ‰æœ€ä½³æ–¹æ³•æé«˜äº†X%ã€‚æ­¤å¤–ï¼ŒCoordARåœ¨å¤„ç†å¯¹ç§°ç‰©ä½“å’Œé®æŒ¡åœºæ™¯æ—¶è¡¨çŽ°å‡ºæ›´å¼ºçš„é²æ£’æ€§ï¼Œè¯æ˜Žäº†å…¶åœ¨å®žé™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚çœŸå®žä¸–ç•Œæµ‹è¯•ä¹ŸéªŒè¯äº†CoordARçš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

CoordARåœ¨æœºå™¨äººæ“ä½œã€å¢žå¼ºçŽ°å®žç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œåœ¨æœºå™¨äººæŠ“å–ä»»åŠ¡ä¸­ï¼Œå¯ä»¥åˆ©ç”¨CoordARä¼°è®¡ç‰©ä½“çš„6Dä½å§¿ï¼Œä»Žè€Œå¼•å¯¼æœºå™¨äººå‡†ç¡®æŠ“å–ç‰©ä½“ã€‚åœ¨å¢žå¼ºçŽ°å®žåº”ç”¨ä¸­ï¼Œå¯ä»¥å°†è™šæ‹Ÿç‰©ä½“ä¸ŽçœŸå®žåœºæ™¯è¿›è¡Œç²¾ç¡®å¯¹é½ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚è¯¥ç ”ç©¶è¿˜æœ‰åŠ©äºŽæŽ¨åŠ¨æ— æ¨¡åž‹ç‰©ä½“ä½å§¿ä¼°è®¡æŠ€æœ¯çš„å‘å±•ï¼Œé™ä½Žå¯¹3Dæ¨¡åž‹çš„ä¾èµ–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Object 6D pose estimation, a crucial task for robotics and augmented reality applications, becomes particularly challenging when dealing with novel objects whose 3D models are not readily available. To reduce dependency on 3D models, recent studies have explored one-reference-based pose estimation, which requires only a single reference view instead of a complete 3D model. However, existing methods that rely on real-valued coordinate regression suffer from limited global consistency due to the local nature of convolutional architectures and face challenges in symmetric or occluded scenarios owing to a lack of uncertainty modeling. We present CoordAR, a novel autoregressive framework for one-reference 6D pose estimation of unseen objects. CoordAR formulates 3D-3D correspondences between the reference and query views as a map of discrete tokens, which is obtained in an autoregressive and probabilistic manner. To enable accurate correspondence regression, CoordAR introduces 1) a novel coordinate map tokenization that enables probabilistic prediction over discretized 3D space; 2) a modality-decoupled encoding strategy that separately encodes RGB appearance and coordinate cues; and 3) an autoregressive transformer decoder conditioned on both position-aligned query features and the partially generated token sequence. With these novel mechanisms, CoordAR significantly outperforms existing methods on multiple benchmarks and demonstrates strong robustness to symmetry, occlusion, and other challenges in real-world tests.

