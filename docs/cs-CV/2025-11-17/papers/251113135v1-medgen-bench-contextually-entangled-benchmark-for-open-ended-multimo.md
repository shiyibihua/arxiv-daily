---
layout: default
title: MedGEN-Bench: Contextually entangled benchmark for open-ended multimodal medical generation
---

# MedGEN-Bench: Contextually entangled benchmark for open-ended multimodal medical generation

**arXiv**: [2511.13135v1](https://arxiv.org/abs/2511.13135) | [PDF](https://arxiv.org/pdf/2511.13135.pdf)

**ä½œè€…**: Junjie Yang, Yuhao Yan, Gang Wu, Yuxuan Wang, Ruoyu Liang, Xinjie Jiang, Xiang Wan, Fenglei Fan, Yongquan Zhang, Feiwei Qin, Changmiao Wan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMedGEN-BenchåŸºå‡†ä»¥è§£å†³åŒ»å­¦å¤šæ¨¡æ€ç”Ÿæˆä¸­ä¸Šä¸‹æ–‡æŽ¨ç†ä¸è¶³çš„é—®é¢˜**

**å…³é”®è¯**: `åŒ»å­¦å¤šæ¨¡æ€ç”Ÿæˆ` `ä¸Šä¸‹æ–‡æŽ¨ç†åŸºå‡†` `å›¾åƒ-æ–‡æœ¬å¯¹` `å¼€æ”¾ç”Ÿæˆè¯„ä¼°` `ä¸´åºŠä»»åŠ¡` `å¤šæ¨¡æ€æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŒ»å­¦è§†è§‰åŸºå‡†å­˜åœ¨æŸ¥è¯¢æ¨¡ç³Šã€æŽ¨ç†ç®€åŒ–åŠå›¾åƒç”Ÿæˆè¯„ä¼°ç¼ºå¤±ç­‰æ ¸å¿ƒé—®é¢˜
2. æ–¹æ³•è¦ç‚¹åŒ…æ‹¬æž„å»ºä¸“å®¶éªŒè¯çš„å›¾åƒ-æ–‡æœ¬å¯¹ï¼Œå¹¶è®¾è®¡ä¸‰ç§æ ¼å¼æ”¯æŒå¼€æ”¾ç”Ÿæˆ
3. å®žéªŒè¯„ä¼°äº†18ä¸ªæ¨¡åž‹ï¼Œé‡‡ç”¨åƒç´ çº§ã€è¯­ä¹‰å’Œä¸´åºŠç›¸å…³æ€§ä¸‰å±‚è¯„ä¼°æ¡†æž¶

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> As Vision-Language Models (VLMs) increasingly gain traction in medical applications, clinicians are progressively expecting AI systems not only to generate textual diagnoses but also to produce corresponding medical images that integrate seamlessly into authentic clinical workflows. Despite the growing interest, existing medical visual benchmarks present notable limitations. They often rely on ambiguous queries that lack sufficient relevance to image content, oversimplify complex diagnostic reasoning into closed-ended shortcuts, and adopt a text-centric evaluation paradigm that overlooks the importance of image generation capabilities. To address these challenges, we introduce \textsc{MedGEN-Bench}, a comprehensive multimodal benchmark designed to advance medical AI research. MedGEN-Bench comprises 6,422 expert-validated image-text pairs spanning six imaging modalities, 16 clinical tasks, and 28 subtasks. It is structured into three distinct formats: Visual Question Answering, Image Editing, and Contextual Multimodal Generation. What sets MedGEN-Bench apart is its focus on contextually intertwined instructions that necessitate sophisticated cross-modal reasoning and open-ended generative outputs, moving beyond the constraints of multiple-choice formats. To evaluate the performance of existing systems, we employ a novel three-tier assessment framework that integrates pixel-level metrics, semantic text analysis, and expert-guided clinical relevance scoring. Using this framework, we systematically assess 10 compositional frameworks, 3 unified models, and 5 VLMs.

