---
layout: default
title: Attention Grounded Enhancement for Visual Document Retrieval
---

# Attention Grounded Enhancement for Visual Document Retrieval

**arXiv**: [2511.13415v1](https://arxiv.org/abs/2511.13415) | [PDF](https://arxiv.org/pdf/2511.13415.pdf)

**ä½œè€…**: Wanqing Cui, Wei Huang, Yazhi Guo, Yibo Hu, Meiguang Jin, Junfeng Ma, Keping Bi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAGREEæ¡†æž¶ä»¥è§£å†³è§†è§‰æ–‡æ¡£æ£€ç´¢ä¸­ä¾èµ–è¡¨é¢çº¿ç´¢çš„é—®é¢˜**

**å…³é”®è¯**: `è§†è§‰æ–‡æ¡£æ£€ç´¢` `è·¨æ¨¡æ€æ³¨æ„åŠ›` `å±€éƒ¨ç›‘ç£` `æ£€ç´¢å¢žå¼º` `å¤šæ¨¡æ€ç†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ£€ç´¢å™¨ä¾èµ–å…¨å±€ç›¸å…³æ ‡ç­¾ï¼Œéš¾ä»¥æ•æ‰éšå¼è¯­ä¹‰è¿žæŽ¥
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›ä½œä¸ºå±€éƒ¨ç›‘ç£ï¼Œç»“åˆå…¨å±€ä¿¡å·ä¼˜åŒ–æ£€ç´¢å™¨
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ViDoRe V2åŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºŽä»…å…¨å±€ç›‘ç£åŸºçº¿

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Visual document retrieval requires understanding heterogeneous and multi-modal content to satisfy information needs. Recent advances use screenshot-based document encoding with fine-grained late interaction, significantly improving retrieval performance. However, retrievers are still trained with coarse global relevance labels, without revealing which regions support the match. As a result, retrievers tend to rely on surface-level cues and struggle to capture implicit semantic connections, hindering their ability to handle non-extractive queries. To alleviate this problem, we propose a \textbf{A}ttention-\textbf{G}rounded \textbf{RE}triever \textbf{E}nhancement (AGREE) framework. AGREE leverages cross-modal attention from multimodal large language models as proxy local supervision to guide the identification of relevant document regions. During training, AGREE combines local signals with the global signals to jointly optimize the retriever, enabling it to learn not only whether documents match, but also which content drives relevance. Experiments on the challenging ViDoRe V2 benchmark show that AGREE significantly outperforms the global-supervision-only baseline. Quantitative and qualitative analyses further demonstrate that AGREE promotes deeper alignment between query terms and document regions, moving beyond surface-level matching toward more accurate and interpretable retrieval. Our code is available at: https://anonymous.4open.science/r/AGREE-2025.

