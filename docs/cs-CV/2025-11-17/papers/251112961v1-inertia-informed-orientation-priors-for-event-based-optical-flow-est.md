---
layout: default
title: Inertia-Informed Orientation Priors for Event-Based Optical Flow Estimation
---

# Inertia-Informed Orientation Priors for Event-Based Optical Flow Estimation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.12961" target="_blank" class="toolbar-btn">arXiv: 2511.12961v1</a>
    <a href="https://arxiv.org/pdf/2511.12961.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.12961v1" 
            onclick="toggleFavorite(this, '2511.12961v1', 'Inertia-Informed Orientation Priors for Event-Based Optical Flow Estimation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Pritam P. Karmokar, William J. Beksi

**ÂàÜÁ±ª**: eess.IV, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-17

**Â§áÊ≥®**: 13 pages, 9 figures, and 3 tables

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫‰∏ÄÁßçËûçÂêàÊÉØÊÄß‰ø°ÊÅØÁöÑ‰∫ã‰ª∂Áõ∏Êú∫ÂÖâÊµÅ‰º∞ËÆ°ÊñπÊ≥ïÔºåÊèêÂçáÈ≤ÅÊ£íÊÄßÂíåÊî∂ÊïõÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `‰∫ã‰ª∂Áõ∏Êú∫` `ÂÖâÊµÅ‰º∞ËÆ°` `ÊÉØÊÄß‰ø°ÊÅØËûçÂêà` `ÂØπÊØîÂ∫¶ÊúÄÂ§ßÂåñ` `Êú∫Âô®‰∫∫ËßÜËßâ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰∫ã‰ª∂Áõ∏Êú∫ÁöÑÊó∂Â∫èÂØÜÈõÜÂíåÁ©∫Èó¥Á®ÄÁñèÁâπÊÄßÁªôÂÖâÊµÅ‰º∞ËÆ°Â∏¶Êù•‰∫ÜÊåëÊàòÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÂÖºÈ°æÁ≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄß„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Âà©Áî®ÊÉØÊÄßÊµãÈáèÂçïÂÖÉ(IMU)Êï∞ÊçÆÁîüÊàêÊñπÂêëÂõæÔºå‰Ωú‰∏∫ÂÖàÈ™å‰ø°ÊÅØÂºïÂØºÂØπÊØîÂ∫¶ÊúÄÂ§ßÂåñ(CM)ËøáÁ®ãÔºåÁ∫¶ÊùüËøêÂä®ËΩ®ËøπÊêúÁ¥¢Á©∫Èó¥„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Ü‰ºò‰∫éÁé∞ÊúâÊäÄÊúØÁöÑÂÖâÊµÅ‰º∞ËÆ°Á≤æÂ∫¶ÔºåÈ™åËØÅ‰∫ÜÊñπÂêëÂºïÂØºÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂèóÁîüÁâ©Â≠¶ÂêØÂèëÁöÑÊ∑∑ÂêàÂØπÊØîÂ∫¶ÊúÄÂ§ßÂåñ(CM)ÊñπÊ≥ïÔºåÁî®‰∫é‰∫ã‰ª∂Áõ∏Êú∫ÂÖâÊµÅ‰º∞ËÆ°ÔºåËØ•ÊñπÊ≥ïÁªìÂêà‰∫ÜËßÜËßâÂíåÊÉØÊÄßËøêÂä®Á∫øÁ¥¢„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Âª∫ËÆÆ‰ΩøÁî®‰ªéÁõ∏Êú∫3DÈÄüÂ∫¶ÂØºÂá∫ÁöÑÊñπÂêëÂõæ‰Ωú‰∏∫ÂÖàÈ™åÊù•ÊåáÂØºCMËøáÁ®ã„ÄÇÊñπÂêëÂõæÊèê‰æõ‰∫ÜÊñπÂêëÂºïÂØºÔºåÂπ∂Á∫¶Êùü‰∫Ü‰º∞ËÆ°ÁöÑËøêÂä®ËΩ®ËøπÁ©∫Èó¥„ÄÇÊàë‰ª¨Ë°®ÊòéÔºåËøôÁßçÊñπÂêëÂºïÂØºÁöÑÂÖ¨ÂºèÂèØ‰ª•ÊèêÈ´ò‰∫ã‰ª∂Áõ∏Êú∫ÂÖâÊµÅ‰º∞ËÆ°ÁöÑÈ≤ÅÊ£íÊÄßÂíåÊî∂ÊïõÊÄß„ÄÇÂú®MVSEC„ÄÅDSECÂíåECDÊï∞ÊçÆÈõÜ‰∏äÁöÑËØÑ‰º∞Ë°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ï‰ºò‰∫éÁé∞ÊúâÊäÄÊúØ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**Ôºö‰∫ã‰ª∂Áõ∏Êú∫ÂÖâÊµÅ‰º∞ËÆ°Êó®Âú®‰ªéÂºÇÊ≠•‰∫ã‰ª∂ÊµÅ‰∏≠ÊÅ¢Â§çÂÉèÁ¥†Á∫ßÁöÑËøêÂä®‰ø°ÊÅØ„ÄÇÁé∞ÊúâÁöÑÂü∫‰∫éÂØπÊØîÂ∫¶ÊúÄÂ§ßÂåñ(CM)ÁöÑÊñπÊ≥ïËôΩÁÑ∂ÊúâÊïàÔºå‰ΩÜÈù¢‰∏¥È´òÂ∫¶ÈùûÂá∏‰ºòÂåñÈóÆÈ¢òÔºåÂÆπÊòìÈô∑ÂÖ•Â±ÄÈÉ®ÊúÄ‰ºòÔºåÂØºËá¥‰º∞ËÆ°Á≤æÂ∫¶‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®IMUÊèê‰æõÁöÑÁõ∏Êú∫3DÈÄüÂ∫¶‰ø°ÊÅØÔºåÁîüÊàêËøêÂä®ÊñπÂêëÁöÑÂÖàÈ™åÁü•ËØÜÔºåÂπ∂Â∞ÜÂÖ∂ËûçÂÖ•Âà∞CM‰ºòÂåñËøáÁ®ã‰∏≠„ÄÇÈÄöËøáÊñπÂêëÂõæÂºïÂØºÔºåÁº©Â∞èÊêúÁ¥¢Á©∫Èó¥ÔºåÈÅøÂÖç‰ºòÂåñËøáÁ®ãÈô∑ÂÖ•Â±ÄÈÉ®ÊúÄ‰ºòÔºå‰ªéËÄåÊèêÈ´òÂÖâÊµÅ‰º∞ËÆ°ÁöÑÈ≤ÅÊ£íÊÄßÂíåÁ≤æÂ∫¶„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ïÈ¶ñÂÖàÂà©Áî®IMUÊï∞ÊçÆËÆ°ÁÆóÁõ∏Êú∫3DÈÄüÂ∫¶ÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫ÊñπÂêëÂõæÔºå‰Ωú‰∏∫CM‰ºòÂåñÁöÑÂÖàÈ™å‰ø°ÊÅØ„ÄÇCM‰ºòÂåñÊ®°ÂùóÂàôÊ†πÊçÆ‰∫ã‰ª∂Êï∞ÊçÆÂíåÊñπÂêëÂõæÔºå‰º∞ËÆ°ÊØè‰∏™‰∫ã‰ª∂ÁöÑËøêÂä®ËΩ®Ëøπ„ÄÇÊï¥‰ΩìÊµÅÁ®ãÂèØ‰ª•Ê¶ÇÊã¨‰∏∫ÔºöIMUÊï∞ÊçÆÂ§ÑÁêÜ -> ÊñπÂêëÂõæÁîüÊàê -> CM‰ºòÂåñ -> ÂÖâÊµÅ‰º∞ËÆ°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÊÉØÊÄß‰ø°ÊÅØ‰ª•ÊñπÂêëÂõæÁöÑÂΩ¢ÂºèËûçÂÖ•Âà∞‰∫ã‰ª∂Áõ∏Êú∫ÂÖâÊµÅ‰º∞ËÆ°‰∏≠„ÄÇ‰∏é‰º†ÁªüÁöÑÁ∫ØËßÜËßâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÂà©Áî®‰∫ÜIMUÊèê‰æõÁöÑËøêÂä®ÂÖàÈ™åÔºåÊòæËëóÊèêÈ´ò‰∫Ü‰º∞ËÆ°ÁöÑÈ≤ÅÊ£íÊÄßÂíåÊî∂ÊïõÈÄüÂ∫¶„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊñπÂêëÂõæÁöÑÁîüÊàêÊñπÂºèÊòØÂÖ≥ÈîÆËÆæËÆ°‰πã‰∏ÄÔºåÈúÄË¶ÅÂ∞Ü3DÈÄüÂ∫¶‰ø°ÊÅØËΩ¨Êç¢‰∏∫ÈÄÇÂêàCM‰ºòÂåñÁöÑÊñπÂêë‰ø°ÊÅØ„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°ÈúÄË¶ÅËÄÉËôëÂ¶Ç‰ΩïÊúâÊïàÂú∞Â∞ÜÊñπÂêëÂõæ‰Ωú‰∏∫Á∫¶ÊùüÈ°πÂä†ÂÖ•Âà∞CM‰ºòÂåñÁõÆÊ†á‰∏≠ÔºåÂπ≥Ë°°Êï∞ÊçÆÈ°πÂíåÂÖàÈ™åÈ°π‰πãÈó¥ÁöÑÊùÉÈáç„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®MVSEC„ÄÅDSECÂíåECDÊï∞ÊçÆÈõÜ‰∏äÂùáÂèñÂæó‰∫Ü‰ºò‰∫éÁé∞ÊúâÊäÄÊúØÁöÑÂÖâÊµÅ‰º∞ËÆ°Á≤æÂ∫¶„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÂú®Á≤æÂ∫¶ÊåáÊ†á‰∏äÂèñÂæó‰∫ÜÊòæËëóÊèêÂçáÔºåÈ™åËØÅ‰∫ÜÊÉØÊÄß‰ø°ÊÅØÂºïÂØºÁöÑÊúâÊïàÊÄß„ÄÇÂÖ∑‰ΩìÊèêÂçáÂπÖÂ∫¶Âú®ËÆ∫Êñá‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÁöÑÈáèÂåñÂàÜÊûê„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊó†‰∫∫Êú∫Á≠âÈ¢ÜÂüü„ÄÇ‰∫ã‰ª∂Áõ∏Êú∫Âú®È´òÈÄüËøêÂä®ÂíåÈ´òÂä®ÊÄÅËåÉÂõ¥Âú∫ÊôØ‰∏ãÂÖ∑Êúâ‰ºòÂäøÔºåÁªìÂêàÊÉØÊÄß‰ø°ÊÅØÁöÑËûçÂêàÔºåÂèØ‰ª•ÊèêÈ´òËøêÂä®‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄßÔºå‰ªéËÄåÊèêÂçáÁõ∏ÂÖ≥Â∫îÁî®Âú®Â§çÊùÇÁéØÂ¢É‰∏ãÁöÑÊÄßËÉΩ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Event cameras, by virtue of their working principle, directly encode motion within a scene. Many learning-based and model-based methods exist that estimate event-based optical flow, however the temporally dense yet spatially sparse nature of events poses significant challenges. To address these issues, contrast maximization (CM) is a prominent model-based optimization methodology that estimates the motion trajectories of events within an event volume by optimally warping them. Since its introduction, the CM framework has undergone a series of refinements by the computer vision community. Nonetheless, it remains a highly non-convex optimization problem. In this paper, we introduce a novel biologically-inspired hybrid CM method for event-based optical flow estimation that couples visual and inertial motion cues. Concretely, we propose the use of orientation maps, derived from camera 3D velocities, as priors to guide the CM process. The orientation maps provide directional guidance and constrain the space of estimated motion trajectories. We show that this orientation-guided formulation leads to improved robustness and convergence in event-based optical flow estimation. The evaluation of our approach on the MVSEC, DSEC, and ECD datasets yields superior accuracy scores over the state of the art.

