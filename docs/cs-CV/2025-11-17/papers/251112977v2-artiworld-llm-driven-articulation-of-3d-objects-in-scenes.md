---
layout: default
title: ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes
---

# ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.12977" target="_blank" class="toolbar-btn">arXiv: 2511.12977v2</a>
    <a href="https://arxiv.org/pdf/2511.12977.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.12977v2" 
            onclick="toggleFavorite(this, '2511.12977v2', 'ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yixuan Yang, Luyang Xie, Zhen Luo, Zixiang Zhao, Tongsheng Ding, Mingqi Gao, Feng Zheng

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-17 (Êõ¥Êñ∞: 2025-11-18)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ArtiWorldÔºöÊèêÂá∫LLMÈ©±Âä®ÁöÑ3DÂú∫ÊôØÁâ©‰ΩìÂèØÂä®ÊÄßËá™Âä®ÁîüÊàêÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ÂèØÂä®ÊÄßÁîüÊàê` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `URDF` `3DÂú∫ÊôØÁêÜËß£` `Êú∫Âô®‰∫∫Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3DÊ®°ÊãüËµÑ‰∫ßÂ§ö‰∏∫ÂàöÊÄßÔºåÊâãÂä®ËΩ¨Êç¢‰∏∫ÂèØÂä®ÂØπË±°ÊàêÊú¨È´òÊòÇÔºåÁº∫‰πèËá™Âä®ÂåñÁöÑÂèØÂä®ÊÄßÁîüÊàêÊñπÊ≥ï„ÄÇ
2. ArtiWorldÂà©Áî®LLMÁöÑÂÖàÈ™åÁü•ËØÜÔºåÁªìÂêà3DÁÇπ‰∫ëÂíåURDFÂØºÂêëÁöÑÊèêÁ§∫ÔºåËá™Âä®Â∞ÜÂàöÊÄßÁâ©‰ΩìËΩ¨Êç¢‰∏∫ÂèØ‰∫§‰∫íÁöÑURDFÊ®°Âûã„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåArtiWorldÂú®Ê®°ÊãüÂíåÁúüÂÆûÂú∫ÊôØ‰∏≠Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåËÉΩÊúâÊïàÁîüÊàêÈ´òË¥®ÈáèÁöÑÂèØÂä®Ê®°Âûã„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÊûÑÂª∫‰∫§‰∫íÂºèÊ®°ÊãüÂô®ÂíåÂèØÊâ©Â±ïÁöÑÊú∫Âô®‰∫∫Â≠¶‰π†ÁéØÂ¢ÉÈúÄË¶ÅÂ§ßÈáèÂèØÂä®ËµÑ‰∫ß„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÊ®°Êãü‰∏≠ÁöÑÂ§ßÂ§öÊï∞3DËµÑ‰∫ßÊòØÂàöÊÄßÁöÑÔºåÊâãÂä®Â∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫ÂèØÂä®ÂØπË±°ÈúÄË¶ÅÂ§ßÈáèÁöÑ‰∫∫ÂäõÂíåÊàêÊú¨„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜArtiWorldÔºå‰∏Ä‰∏™Âú∫ÊôØÊÑüÁü•ÁöÑÊµÅÊ∞¥Á∫øÔºåÂèØ‰ª•‰ªéÊñáÊú¨Âú∫ÊôØÊèèËø∞‰∏≠ÂÆö‰ΩçÂÄôÈÄâÁöÑÂèØÂä®ÂØπË±°ÔºåÂπ∂ÈáçÂª∫‰øùÁïôÂéüÂßãÂá†‰ΩïÂΩ¢Áä∂ÁöÑÂèØÊâßË°åURDFÊ®°Âûã„ÄÇËØ•ÊµÅÊ∞¥Á∫øÁöÑÊ†∏ÂøÉÊòØArti4URDFÔºåÂÆÉÂà©Áî®3DÁÇπ‰∫ë„ÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÂÖàÈ™åÁü•ËØÜÂíåÈù¢ÂêëURDFÁöÑÊèêÁ§∫ËÆæËÆ°ÔºåÂø´ÈÄüÂ∞ÜÂàöÊÄßÂØπË±°ËΩ¨Êç¢‰∏∫Âü∫‰∫éURDFÁöÑ‰∫§‰∫íÂºèÂèØÂä®ÂØπË±°ÔºåÂêåÊó∂‰øùÊåÅÂÖ∂3DÂΩ¢Áä∂„ÄÇÂú®3DÊ®°ÊãüÂØπË±°„ÄÅÂÆåÊï¥3DÊ®°ÊãüÂú∫ÊôØÂíåÁúüÂÆû‰∏ñÁïåÊâ´ÊèèÂú∫ÊôØ‰∏â‰∏™Â±ÇÈù¢‰∏äËØÑ‰º∞‰∫ÜArtiWorld„ÄÇÂú®ÊâÄÊúâ‰∏â‰∏™ËÆæÁΩÆ‰∏≠ÔºåËØ•ÊñπÊ≥ïÂßãÁªà‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂêåÊó∂‰øùÁïô‰∫ÜÂØπË±°Âá†‰ΩïÂΩ¢Áä∂Âπ∂Ê≠£Á°ÆÊçïËé∑‰∫ÜÂØπË±°‰∫§‰∫íÊÄßÔºå‰ªéËÄåÁîüÊàê‰∫ÜÂèØÁî®ÁöÑÂü∫‰∫éURDFÁöÑÂèØÂä®Ê®°Âûã„ÄÇËøô‰∏∫Áõ¥Êé•‰ªéÁé∞Êúâ3DËµÑ‰∫ßÊûÑÂª∫‰∫§‰∫íÂºèÁöÑ„ÄÅÊú∫Âô®‰∫∫Â∞±Áª™ÁöÑÊ®°ÊãüÁéØÂ¢ÉÊèê‰æõ‰∫Ü‰∏ÄÊù°ÂÆûÁî®ÁöÑÈÄîÂæÑ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â¶Ç‰ΩïËá™Âä®Âú∞Â∞Ü3DÂú∫ÊôØ‰∏≠ÁöÑÂàöÊÄßÁâ©‰ΩìËΩ¨Êç¢‰∏∫ÂèØÂä®Ê®°ÂûãÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈúÄË¶ÅÂ§ßÈáè‰∫∫Â∑•Âπ≤È¢ÑÔºåÊàêÊú¨È´ò‰∏îÊïàÁéá‰ΩéÔºåÈöæ‰ª•Êª°Ë∂≥ÊûÑÂª∫Â§ßËßÑÊ®°‰∫§‰∫íÂºèÊ®°ÊãüÁéØÂ¢ÉÁöÑÈúÄÊ±Ç„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Âá†‰ΩïÂΩ¢Áä∂‰øùÊåÅÂíå‰∫§‰∫íÊÄßÊçïËé∑ÊñπÈù¢Â≠òÂú®‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÂÖàÈ™åÁü•ËØÜÊù•ÊåáÂØºÂèØÂä®ÊÄßÁîüÊàêËøáÁ®ã„ÄÇÈÄöËøáÁªìÂêà3DÁÇπ‰∫ë‰ø°ÊÅØÂíåURDFÔºàUnified Robot Description FormatÔºâÂØºÂêëÁöÑÊèêÁ§∫ÔºåLLMÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£Áâ©‰ΩìÁöÑÁªìÊûÑÂíåÊΩúÂú®ÁöÑËøêÂä®ÊñπÂºèÔºå‰ªéËÄåÁîüÊàêÊõ¥ÂêàÁêÜÁöÑÂèØÂä®Ê®°Âûã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöArtiWorldÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) Âú∫ÊôØÁêÜËß£Ê®°ÂùóÔºö‰ªéÊñáÊú¨ÊèèËø∞‰∏≠ËØÜÂà´ÊΩúÂú®ÁöÑÂèØÂä®ÂØπË±°„ÄÇ2) Arti4URDFÊ®°ÂùóÔºöÂà©Áî®3DÁÇπ‰∫ë„ÄÅLLMÂíåURDFÊèêÁ§∫ÔºåÂ∞ÜÂàöÊÄßÂØπË±°ËΩ¨Êç¢‰∏∫URDFÊ®°Âûã„ÄÇ3) ËØÑ‰º∞Ê®°ÂùóÔºöÂú®‰∏çÂêåÂú∫ÊôØ‰∏ãËØÑ‰º∞ÁîüÊàêÁöÑÂèØÂä®Ê®°ÂûãÁöÑË¥®Èáè„ÄÇArti4URDFÊòØÊ†∏ÂøÉÊ®°ÂùóÔºåË¥üË¥£Â∞ÜÂàöÊÄßÂØπË±°ËΩ¨Êç¢‰∏∫ÂèØÂä®ÂØπË±°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜLLMÂºïÂÖ•Âà∞ÂèØÂä®ÊÄßÁîüÊàêËøáÁ®ã‰∏≠„ÄÇÈÄöËøáÂà©Áî®LLMÁöÑÁü•ËØÜÔºåÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£Áâ©‰ΩìÁöÑÁªìÊûÑÂíåÂäüËÉΩÔºå‰ªéËÄåÁîüÊàêÊõ¥ÂêàÁêÜÁöÑÂèØÂä®Ê®°Âûã„ÄÇÊ≠§Â§ñÔºåURDFÂØºÂêëÁöÑÊèêÁ§∫ËÆæËÆ°‰πüÊèêÈ´ò‰∫ÜÁîüÊàêÊ®°ÂûãÁöÑË¥®Èáè„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöArti4URDFÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑLLMÔºå‰æãÂ¶ÇGPT-3Ôºå‰Ωú‰∏∫Áü•ËØÜÊù•Ê∫ê„ÄÇ2) ËÆæËÆ°URDFÂØºÂêëÁöÑÊèêÁ§∫ÔºåÂºïÂØºLLMÁîüÊàêÁ¨¶ÂêàURDFËßÑËåÉÁöÑÊ®°Âûã„ÄÇ3) ‰ΩøÁî®3DÁÇπ‰∫ë‰ø°ÊÅØÊù•Á∫¶ÊùüÁîüÊàêÊ®°ÂûãÁöÑÂá†‰ΩïÂΩ¢Áä∂„ÄÇ4) ‰ΩøÁî®ÊçüÂ§±ÂáΩÊï∞Êù•‰ºòÂåñÁîüÊàêÊ®°ÂûãÁöÑÂèÇÊï∞Ôºå‰æãÂ¶ÇÂÖ≥ËäÇ‰ΩçÁΩÆÂíåËøêÂä®ËåÉÂõ¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ArtiWorldÂú®3DÊ®°ÊãüÂØπË±°„ÄÅÂÆåÊï¥3DÊ®°ÊãüÂú∫ÊôØÂíåÁúüÂÆû‰∏ñÁïåÊâ´ÊèèÂú∫ÊôØ‰∏â‰∏™Â±ÇÈù¢‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÔºåÂùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåArtiWorldËÉΩÂ§üÊúâÊïàÂú∞ÁîüÊàêÈ´òË¥®ÈáèÁöÑÂèØÂä®Ê®°ÂûãÔºåÂêåÊó∂‰øùÊåÅÂØπË±°ÁöÑÂá†‰ΩïÂΩ¢Áä∂Âíå‰∫§‰∫íÊÄß„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜËÆ∫ÊñáÂº∫Ë∞ÉÂÖ∂Âú®ÊâÄÊúâÊµãËØïÂú∫ÊôØ‰∏≠ÂùáÂèñÂæó‰∫Üstate-of-the-artÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫Â≠¶‰π†„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÊ∏∏ÊàèÂºÄÂèëÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáËá™Âä®ÁîüÊàêÂèØÂä®Ê®°ÂûãÔºåÂèØ‰ª•Â§ßÂ§ßÈôç‰ΩéÊûÑÂª∫‰∫§‰∫íÂºèÊ®°ÊãüÁéØÂ¢ÉÁöÑÊàêÊú¨ÔºåÂä†ÈÄüÊú∫Âô®‰∫∫ÁÆóÊ≥ïÁöÑÂºÄÂèëÂíåÈ™åËØÅ„ÄÇÊ≠§Â§ñÔºåËØ•ÊäÄÊúØËøòÂèØ‰ª•Áî®‰∫éÂàõÂª∫Êõ¥ÈÄºÁúüÁöÑËôöÊãüÁé∞ÂÆû‰ΩìÈ™åÂíåÊõ¥ÂÖ∑‰∫íÂä®ÊÄßÁöÑÊ∏∏Êàè„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Building interactive simulators and scalable robot-learning environments requires a large number of articulated assets. However, most existing 3D assets in simulation are rigid, and manually converting them into articulated objects is extremely labor- and cost-intensive. This raises a natural question: can we automatically identify articulable objects in a scene and convert them into articulated assets directly? In this paper, we present ArtiWorld, a scene-aware pipeline that localizes candidate articulable objects from textual scene descriptions and reconstructs executable URDF models that preserve the original geometry. At the core of this pipeline is Arti4URDF, which leverages 3D point cloud, prior knowledge of a large language model (LLM), and a URDF-oriented prompt design to rapidly convert rigid objects into interactive URDF-based articulated objects while maintaining their 3D shape. We evaluate ArtiWorld at three levels: 3D simulated objects, full 3D simulated scenes, and real-world scan scenes. Across all three settings, our method consistently outperforms existing approaches and achieves state-of-the-art performance, while preserving object geometry and correctly capturing object interactivity to produce usable URDF-based articulated models. This provides a practical path toward building interactive, robot-ready simulation environments directly from existing 3D assets. Code and data will be released.

