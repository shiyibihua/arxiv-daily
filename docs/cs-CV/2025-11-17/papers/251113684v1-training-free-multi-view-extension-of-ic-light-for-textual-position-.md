---
layout: default
title: Training-Free Multi-View Extension of IC-Light for Textual Position-Aware Scene Relighting
---

# Training-Free Multi-View Extension of IC-Light for Textual Position-Aware Scene Relighting

**arXiv**: [2511.13684v1](https://arxiv.org/abs/2511.13684) | [PDF](https://arxiv.org/pdf/2511.13684.pdf)

**ä½œè€…**: Jiangnan Ye, Jiedong Zhuang, Lianrui Mu, Wenjie Zheng, Jiaqi Hu, Xingze Zou, Jing Wang, Haoji Hu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGS-Lightï¼Œå®žçŽ°åŸºäºŽæ–‡æœ¬çš„3Dé«˜æ–¯æº…å°„åœºæ™¯é‡å…‰ç…§ï¼Œæ— éœ€è®­ç»ƒæ‰©å±•å¤šè§†å›¾è¾“å…¥ã€‚**

**å…³é”®è¯**: `3Dé«˜æ–¯æº…å°„` `æ–‡æœ¬å¼•å¯¼é‡å…‰ç…§` `å¤šè§†å›¾æ‰©æ•£æ¨¡åž‹` `å…‰ç…§å…ˆéªŒèžåˆ` `è®­ç»ƒå…è´¹æ‰©å±•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ–‡æœ¬å¼•å¯¼çš„3Dåœºæ™¯é‡å…‰ç…§éœ€å¤„ç†å¤šè§†å›¾ä¸€è‡´æ€§ä¸Žç”¨æˆ·æ„å›¾å‡†ç¡®åæ˜ ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šèžåˆLVLMè§£æžå…‰ç…§å…ˆéªŒä¸Žå‡ ä½•çº¦æŸï¼Œç”Ÿæˆåˆå§‹æ½œç æŒ‡å¯¼æ‰©æ•£æ¨¡åž‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å®¤å†…å¤–åœºæ™¯è¯„ä¼°ï¼Œå¤šè§†å›¾ä¸€è‡´æ€§ä¸Žæˆåƒè´¨é‡ä¼˜äºŽåŸºçº¿æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce GS-Light, an efficient, textual position-aware pipeline for text-guided relighting of 3D scenes represented via Gaussian Splatting (3DGS). GS-Light implements a training-free extension of a single-input diffusion model to handle multi-view inputs. Given a user prompt that may specify lighting direction, color, intensity, or reference objects, we employ a large vision-language model (LVLM) to parse the prompt into lighting priors. Using off-the-shelf estimators for geometry and semantics (depth, surface normals, and semantic segmentation), we fuse these lighting priors with view-geometry constraints to compute illumination maps and generate initial latent codes for each view. These meticulously derived init latents guide the diffusion model to generate relighting outputs that more accurately reflect user expectations, especially in terms of lighting direction. By feeding multi-view rendered images, along with the init latents, into our multi-view relighting model, we produce high-fidelity, artistically relit images. Finally, we fine-tune the 3DGS scene with the relit appearance to obtain a fully relit 3D scene. We evaluate GS-Light on both indoor and outdoor scenes, comparing it to state-of-the-art baselines including per-view relighting, video relighting, and scene editing methods. Using quantitative metrics (multi-view consistency, imaging quality, aesthetic score, semantic similarity, etc.) and qualitative assessment (user studies), GS-Light demonstrates consistent improvements over baselines. Code and assets will be made available upon publication.

