---
layout: default
title: Infinite-Story: A Training-Free Consistent Text-to-Image Generation
---

# Infinite-Story: A Training-Free Consistent Text-to-Image Generation

**arXiv**: [2511.13002v1](https://arxiv.org/abs/2511.13002) | [PDF](https://arxiv.org/pdf/2511.13002.pdf)

**ä½œè€…**: Jihun Park, Kyoungmin Lee, Jongmin Gim, Hyeonseo Jo, Minseok Oh, Wonhyeok Choi, Kyumin Hwang, Jaeyeul Kim, Minwoo Choi, Sunghoon Im

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInfinite-Storyè®­ç»ƒå…è´¹æ¡†æž¶ï¼Œè§£å†³å¤šæç¤ºæ•…äº‹ç”Ÿæˆä¸­çš„èº«ä»½ä¸Žé£Žæ ¼ä¸ä¸€è‡´é—®é¢˜**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `ä¸€è‡´æ€§ç”Ÿæˆ` `è®­ç»ƒå…è´¹æ–¹æ³•` `æ³¨æ„åŠ›æœºåˆ¶` `å¤šæç¤ºæ•…äº‹` `å¿«é€ŸæŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæç¤ºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­èº«ä»½å’Œé£Žæ ¼ä¸ä¸€è‡´ï¼ŒçŽ°æœ‰æ–¹æ³•éœ€å¾®è°ƒæˆ–æŽ¨ç†æ…¢
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨èº«ä»½æç¤ºæ›¿æ¢å’Œç»Ÿä¸€æ³¨æ„åŠ›æŒ‡å¯¼ï¼Œæ— éœ€è®­ç»ƒï¼Œç¡®ä¿ä¸€è‡´æ€§ä¸Žæç¤ºä¿çœŸåº¦
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å®žéªŒä¸­å®žçŽ°æœ€å…ˆè¿›æ€§èƒ½ï¼ŒæŽ¨ç†é€Ÿåº¦æ¯”çŽ°æœ‰æœ€å¿«æ¨¡åž‹å¿«6å€ä»¥ä¸Š

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present Infinite-Story, a training-free framework for consistent text-to-image (T2I) generation tailored for multi-prompt storytelling scenarios. Built upon a scale-wise autoregressive model, our method addresses two key challenges in consistent T2I generation: identity inconsistency and style inconsistency. To overcome these issues, we introduce three complementary techniques: Identity Prompt Replacement, which mitigates context bias in text encoders to align identity attributes across prompts; and a unified attention guidance mechanism comprising Adaptive Style Injection and Synchronized Guidance Adaptation, which jointly enforce global style and identity appearance consistency while preserving prompt fidelity. Unlike prior diffusion-based approaches that require fine-tuning or suffer from slow inference, Infinite-Story operates entirely at test time, delivering high identity and style consistency across diverse prompts. Extensive experiments demonstrate that our method achieves state-of-the-art generation performance, while offering over 6X faster inference (1.72 seconds per image) than the existing fastest consistent T2I models, highlighting its effectiveness and practicality for real-world visual storytelling.

