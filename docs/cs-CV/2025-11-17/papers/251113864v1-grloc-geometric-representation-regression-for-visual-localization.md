---
layout: default
title: GRLoc: Geometric Representation Regression for Visual Localization
---

# GRLoc: Geometric Representation Regression for Visual Localization

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.13864" target="_blank" class="toolbar-btn">arXiv: 2511.13864v1</a>
    <a href="https://arxiv.org/pdf/2511.13864.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.13864v1" 
            onclick="toggleFavorite(this, '2511.13864v1', 'GRLoc: Geometric Representation Regression for Visual Localization')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Changyang Li, Xuejian Ma, Lixiang Liu, Zhan Li, Qingan Yan, Yi Xu

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-17

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫GRLocÔºöÈÄöËøáÂá†‰ΩïË°®Á§∫ÂõûÂΩíÂÆûÁé∞Êõ¥È≤ÅÊ£íÁöÑËßÜËßâÂÆö‰Ωç**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâÂÆö‰Ωç` `ÁªùÂØπ‰ΩçÂßøÂõûÂΩí` `Âá†‰ΩïË°®Á§∫Â≠¶‰π†` `ÈÄÜÊ∏≤Êüì` `Áõ∏Êú∫‰ΩçÂßø‰º∞ËÆ°`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰º†ÁªüÁªùÂØπ‰ΩçÂßøÂõûÂΩíÊ®°ÂûãÁº∫‰πèÂØπ3DÂú∫ÊôØÂá†‰ΩïÁöÑÁêÜËß£ÔºåÂÆπÊòìËÆ∞ÂøÜËÆ≠ÁªÉÊï∞ÊçÆÔºåÊ≥õÂåñËÉΩÂäõÂèóÈôê„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Âá†‰ΩïË°®Á§∫ÂõûÂΩí(GRR)Ê°ÜÊû∂ÔºåÈÄöËøáÈ¢ÑÊµãËß£ËÄ¶ÁöÑÂá†‰ΩïË°®Á§∫ÔºàÂÖâÁ∫øÊùüÊñπÂêëÂíåÁÇπÂõæÔºâÊù•‰º∞ËÆ°Áõ∏Êú∫‰ΩçÂßø„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåGRRÂú®7-ScenesÂíåCambridge LandmarksÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜSOTAÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜÈÄÜÊ∏≤ÊüìÂª∫Ê®°ÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÁªùÂØπ‰ΩçÂßøÂõûÂΩí(APR)Â∑≤Êàê‰∏∫ËßÜËßâÂÆö‰ΩçÁöÑ‰∏ÄÁßçÂºï‰∫∫Ê≥®ÁõÆÁöÑËåÉ‰æã„ÄÇÁÑ∂ËÄåÔºåAPRÊ®°ÂûãÈÄöÂ∏∏‰Ωú‰∏∫ÈªëÁõíËøêË°åÔºåÁõ¥Êé•‰ªéÊü•ËØ¢ÂõæÂÉèÂõûÂΩí6Ëá™Áî±Â∫¶(6-DoF)‰ΩçÂßøÔºåËøôÂèØËÉΩÂØºËá¥Ê®°ÂûãËÆ∞ÂøÜËÆ≠ÁªÉËßÜÂõæÔºåËÄå‰∏çÊòØÁêÜËß£3DÂú∫ÊôØÂá†‰Ωï„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂá†‰ΩïÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÂèóÂà∞Êñ∞ËßÜËßíÂêàÊàêÁöÑÂêØÂèëÔºåËØ•ÊñπÊ≥ï‰ªé‰∏≠Èó¥Âá†‰ΩïË°®Á§∫Ê∏≤ÊüìÂõæÂÉèÔºåÊàë‰ª¨Â∞ÜAPRÈáçÊñ∞ÂÆö‰πâ‰∏∫ÂÖ∂ÈÄÜËøáÁ®ãÔºåÂç≥Áõ¥Êé•‰ªéÂõæÂÉèÂõûÂΩíÊΩúÂú®ÁöÑ3DË°®Á§∫ÔºåÊàë‰ª¨Áß∞‰πã‰∏∫Âá†‰ΩïË°®Á§∫ÂõûÂΩí(GRR)„ÄÇÊàë‰ª¨ÁöÑÊ®°ÂûãÊòæÂºèÂú∞È¢ÑÊµã‰∏ñÁïåÂùêÊ†áÁ≥ª‰∏≠ÁöÑ‰∏§‰∏™Ëß£ËÄ¶ÁöÑÂá†‰ΩïË°®Á§∫Ôºö(1)Áî®‰∫é‰º∞ËÆ°Áõ∏Êú∫ÊóãËΩ¨ÁöÑÂÖâÁ∫øÊùüÊñπÂêëÔºå‰ª•Âèä(2)Áî®‰∫é‰º∞ËÆ°Áõ∏Êú∫Âπ≥ÁßªÁöÑÁõ∏Â∫îÁÇπÂõæ„ÄÇÁÑ∂Âêé‰ΩøÁî®ÂèØÂæÆÁ°ÆÂÆöÊÄßÊ±ÇËß£Âô®‰ªéËøô‰∫õÂá†‰ΩïÂàÜÈáè‰∏≠ÊÅ¢Â§çÊúÄÁªàÁöÑ6-DoFÁõ∏Êú∫‰ΩçÂßø„ÄÇËøôÁßçËß£ËÄ¶ÊñπÊ≥ïÂ∞ÜÂ≠¶‰π†Âà∞ÁöÑËßÜËßâÂà∞Âá†‰ΩïÁöÑÊò†Â∞Ñ‰∏éÊúÄÁªàÁöÑ‰ΩçÂßøËÆ°ÁÆóÂàÜÁ¶ªÔºå‰ªéËÄåÂ∞ÜÂº∫Â§ßÁöÑÂá†‰ΩïÂÖàÈ™åÂºïÂÖ•ÁΩëÁªú„ÄÇÊàë‰ª¨ÂèëÁé∞ÔºåÊòæÂºèÂú∞Ëß£ËÄ¶ÊóãËΩ¨ÂíåÂπ≥ÁßªÈ¢ÑÊµãÂèØ‰ª•ÊòæËëóÊèêÈ´òÊÄßËÉΩ„ÄÇÊàë‰ª¨Âú®7-ScenesÂíåCambridge LandmarksÊï∞ÊçÆÈõÜ‰∏äÂ±ïÁ§∫‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜÂØπÈÄÜÊ∏≤ÊüìËøáÁ®ãËøõË°åÂª∫Ê®°ÊòØÂÆûÁé∞ÈÄöÁî®ÁªùÂØπ‰ΩçÂßø‰º∞ËÆ°ÁöÑÊõ¥È≤ÅÊ£íÁöÑÈÄîÂæÑ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁªùÂØπ‰ΩçÂßøÂõûÂΩí(APR)Êó®Âú®Áõ¥Êé•‰ªéÂõæÂÉèÈ¢ÑÊµãÁõ∏Êú∫ÁöÑ6Ëá™Áî±Â∫¶‰ΩçÂßø„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑAPRÊñπÊ≥ïÈÄöÂ∏∏Â∞ÜÊ®°ÂûãËßÜ‰∏∫ÈªëÁõíÔºåÁº∫‰πèÂØπÂú∫ÊôØÂá†‰ΩïÁöÑÊòæÂºèÂª∫Ê®°ÔºåÂØºËá¥Ê®°ÂûãÂÆπÊòìËøáÊãüÂêàËÆ≠ÁªÉÊï∞ÊçÆÔºåÊ≥õÂåñËÉΩÂäõËæÉÂ∑Æ„ÄÇËøô‰∫õÊñπÊ≥ïÈöæ‰ª•Â∫îÂØπÂÖâÁÖßÂèòÂåñ„ÄÅËßÜËßíÂ∑ÆÂºÇÁ≠âÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜAPRÈóÆÈ¢òËΩ¨Âåñ‰∏∫‰∏Ä‰∏™ÈÄÜÊ∏≤ÊüìÈóÆÈ¢ò„ÄÇÈÄöËøáÈ¢ÑÊµãÂõæÂÉèÂØπÂ∫îÁöÑ3DÂá†‰ΩïË°®Á§∫ÔºåËÄå‰∏çÊòØÁõ¥Êé•ÂõûÂΩí‰ΩçÂßøÔºåÊ®°ÂûãÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£Âú∫ÊôØÁªìÊûÑÔºå‰ªéËÄåÊèêÈ´òÊ≥õÂåñËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊ®°ÂûãÈ¢ÑÊµã‰∏§‰∏™Ëß£ËÄ¶ÁöÑÂá†‰ΩïË°®Á§∫ÔºöÂÖâÁ∫øÊùüÊñπÂêëÔºàÁî®‰∫é‰º∞ËÆ°ÊóãËΩ¨ÔºâÂíåÁÇπÂõæÔºàÁî®‰∫é‰º∞ËÆ°Âπ≥ÁßªÔºâ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöGRLocÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºöÊèêÂèñËæìÂÖ•ÂõæÂÉèÁöÑËßÜËßâÁâπÂæÅ„ÄÇ2) Âá†‰ΩïË°®Á§∫ÂõûÂΩíÊ®°ÂùóÔºöÂü∫‰∫éËßÜËßâÁâπÂæÅÔºåÈ¢ÑÊµãÂÖâÁ∫øÊùüÊñπÂêëÂíåÁÇπÂõæ„ÄÇ3) ‰ΩçÂßøÊ±ÇËß£Ê®°ÂùóÔºöÂà©Áî®ÂèØÂæÆÁöÑÁ°ÆÂÆöÊÄßÊ±ÇËß£Âô®Ôºå‰ªéÂÖâÁ∫øÊùüÊñπÂêëÂíåÁÇπÂõæ‰∏≠ÊÅ¢Â§çÁõ∏Êú∫ÁöÑ6Ëá™Áî±Â∫¶‰ΩçÂßø„ÄÇÊï¥‰∏™Ê°ÜÊû∂ÊòØÁ´ØÂà∞Á´ØÂèØËÆ≠ÁªÉÁöÑ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöGRLocÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÁªùÂØπ‰ΩçÂßøÂõûÂΩíÈóÆÈ¢òËΩ¨Âåñ‰∏∫Âá†‰ΩïË°®Á§∫ÂõûÂΩíÈóÆÈ¢òÔºåÂπ∂ÊòæÂºèÂú∞Ëß£ËÄ¶‰∫ÜÊóãËΩ¨ÂíåÂπ≥ÁßªÁöÑÈ¢ÑÊµã„ÄÇËøôÁßçËß£ËÄ¶ÊñπÂºèÂºïÂÖ•‰∫ÜÊõ¥Âº∫ÁöÑÂá†‰ΩïÂÖàÈ™åÔºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£Âú∫ÊôØÁªìÊûÑÔºå‰ªéËÄåÊèêÈ´òÊ≥õÂåñËÉΩÂäõ„ÄÇ‰∏éÁõ¥Êé•ÂõûÂΩí‰ΩçÂßøÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåGRLocÊõ¥ÂÖ≥Ê≥®Â≠¶‰π†ÂõæÂÉè‰∏é3DÂá†‰Ωï‰πãÈó¥ÁöÑÊò†Â∞ÑÂÖ≥Á≥ª„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Âá†‰ΩïË°®Á§∫ÂõûÂΩíÊ®°Âùó‰∏≠ÔºåËÆ∫Êñá‰ΩøÁî®‰∫ÜÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÊù•È¢ÑÊµãÂÖâÁ∫øÊùüÊñπÂêëÂíåÁÇπÂõæ„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÂÖâÁ∫øÊùüÊñπÂêëÁöÑÂõûÂΩíÊçüÂ§±ÂíåÁÇπÂõæÁöÑÂõûÂΩíÊçüÂ§±„ÄÇ‰ΩçÂßøÊ±ÇËß£Ê®°ÂùóÈááÁî®‰∫Ü‰∏ÄÁßçÂèØÂæÆÁöÑËø≠‰ª£ÊúÄËøëÁÇπ(ICP)ÁÆóÊ≥ïÔºå‰ª•Á°Æ‰øùÊï¥‰∏™Ê°ÜÊû∂ÁöÑÂèØÂæÆÊÄß„ÄÇÂÖ∑‰ΩìÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

GRLocÂú®7-ScenesÂíåCambridge LandmarksÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Üstate-of-the-artÁöÑÊÄßËÉΩ„ÄÇ‰æãÂ¶ÇÔºåÂú®7-ScenesÊï∞ÊçÆÈõÜ‰∏äÔºåGRLocÁöÑÂπ≥ÂùáÂÆö‰ΩçËØØÂ∑ÆÊòæËëó‰Ωé‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊòæÂºèÂú∞Ëß£ËÄ¶ÊóãËΩ¨ÂíåÂπ≥ÁßªÈ¢ÑÊµãÂèØ‰ª•ÊòæËëóÊèêÈ´òÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜÈÄÜÊ∏≤ÊüìÂª∫Ê®°ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂ¢ûÂº∫Áé∞ÂÆû„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊõ¥ÂáÜÁ°ÆÁöÑËßÜËßâÂÆö‰ΩçÔºåÂèØ‰ª•ÊèêÂçáARÂ∫îÁî®ÁöÑÊ≤âÊµ∏ÊÑüÔºåÊèêÈ´òÊú∫Âô®‰∫∫ÂØºËà™ÁöÑÁ≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄßÔºå‰ª•ÂèäÂ¢ûÂº∫Ëá™Âä®È©æÈ©∂Á≥ªÁªüÁöÑÁéØÂ¢ÉÊÑüÁü•ËÉΩÂäõ„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÊâ©Â±ïÂà∞Êõ¥Â§ßËßÑÊ®°„ÄÅÊõ¥Â§çÊùÇÁöÑÂú∫ÊôØ‰∏≠„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Absolute Pose Regression (APR) has emerged as a compelling paradigm for visual localization. However, APR models typically operate as black boxes, directly regressing a 6-DoF pose from a query image, which can lead to memorizing training views rather than understanding 3D scene geometry. In this work, we propose a geometrically-grounded alternative. Inspired by novel view synthesis, which renders images from intermediate geometric representations, we reformulate APR as its inverse that regresses the underlying 3D representations directly from the image, and we name this paradigm Geometric Representation Regression (GRR). Our model explicitly predicts two disentangled geometric representations in the world coordinate system: (1) a ray bundle's directions to estimate camera rotation, and (2) a corresponding pointmap to estimate camera translation. The final 6-DoF camera pose is then recovered from these geometric components using a differentiable deterministic solver. This disentangled approach, which separates the learned visual-to-geometry mapping from the final pose calculation, introduces a strong geometric prior into the network. We find that the explicit decoupling of rotation and translation predictions measurably boosts performance. We demonstrate state-of-the-art performance on 7-Scenes and Cambridge Landmarks datasets, validating that modeling the inverse rendering process is a more robust path toward generalizable absolute pose estimation.

