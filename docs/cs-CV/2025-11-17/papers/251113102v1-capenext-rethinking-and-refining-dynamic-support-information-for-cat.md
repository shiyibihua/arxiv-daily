---
layout: default
title: CapeNext: Rethinking and refining dynamic support information for category-agnostic pose estimation
---

# CapeNext: Rethinking and refining dynamic support information for category-agnostic pose estimation

**arXiv**: [2511.13102v1](https://arxiv.org/abs/2511.13102) | [PDF](https://arxiv.org/pdf/2511.13102.pdf)

**ä½œè€…**: Yu Zhu, Dan Zeng, Shuiwang Li, Qijun Zhao, Qiaomu Shen, Bo Tang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCapeNextæ¡†æž¶ï¼Œé€šè¿‡åŠ¨æ€æ”¯æŒä¿¡æ¯è§£å†³ç±»åˆ«æ— å…³å§¿æ€ä¼°è®¡ä¸­çš„è¯­ä¹‰æ­§ä¹‰å’Œç»†ç²’åº¦å·®å¼‚é—®é¢˜ã€‚**

**å…³é”®è¯**: `ç±»åˆ«æ— å…³å§¿æ€ä¼°è®¡` `è·¨æ¨¡æ€äº¤äº’` `ç‰¹å¾ç²¾ç‚¼` `è¯­ä¹‰åµŒå…¥` `å§¿æ€åŒ¹é…`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé™æ€å…³èŠ‚åµŒå…¥å­˜åœ¨è·¨ç±»åˆ«è¯­ä¹‰æ­§ä¹‰å’Œç»†ç²’åº¦å˜åŒ–åŒºåˆ†ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆå±‚æ¬¡è·¨æ¨¡æ€äº¤äº’ä¸ŽåŒæµç‰¹å¾ç²¾ç‚¼ï¼Œå¢žå¼ºå…³èŠ‚åµŒå…¥ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨MP-100æ•°æ®é›†ä¸Šå¤§å¹…è¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œä¸ä¾èµ–ç½‘ç»œéª¨å¹²ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent research in Category-Agnostic Pose Estimation (CAPE) has adopted fixed textual keypoint description as semantic prior for two-stage pose matching frameworks. While this paradigm enhances robustness and flexibility by disentangling the dependency of support images, our critical analysis reveals two inherent limitations of static joint embedding: (1) polysemy-induced cross-category ambiguity during the matching process(e.g., the concept "leg" exhibiting divergent visual manifestations across humans and furniture), and (2) insufficient discriminability for fine-grained intra-category variations (e.g., posture and fur discrepancies between a sleeping white cat and a standing black cat). To overcome these challenges, we propose a new framework that innovatively integrates hierarchical cross-modal interaction with dual-stream feature refinement, enhancing the joint embedding with both class-level and instance-specific cues from textual description and specific images. Experiments on the MP-100 dataset demonstrate that, regardless of the network backbone, CapeNext consistently outperforms state-of-the-art CAPE methods by a large margin.

