---
layout: default
title: Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space
---

# Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.13282" target="_blank" class="toolbar-btn">arXiv: 2511.13282v2</a>
    <a href="https://arxiv.org/pdf/2511.13282.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.13282v2" 
            onclick="toggleFavorite(this, '2511.13282v2', 'Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Kaiwen Wang, Kaili Zheng, Yiming Shi, Chenyi Guo, Ji Wu

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-17 (Êõ¥Êñ∞: 2025-11-20)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/gouba2333/MA-HMR)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Ê∑±Â∫¶Êù°‰ª∂Âπ≥Áßª‰ºòÂåñ‰∏éÂ∫¶ÈáèÊÑüÁü•ÁΩëÁªúÔºåÂÆûÁé∞Áõ∏Êú∫Á©∫Èó¥Â§ö‰∫∫ÁΩëÊ†ºÈáçÂª∫**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)** **ÊîØÊü±ÂÖ≠ÔºöËßÜÈ¢ëÊèêÂèñ‰∏éÂåπÈÖç (Video Extraction & Matching)**

**ÂÖ≥ÈîÆËØç**: `Â§ö‰∫∫‰∫∫‰ΩìÁΩëÊ†ºÈáçÂª∫` `Âú∫ÊôØ‰∏ÄËá¥ÊÄß` `Ê∑±Â∫¶Êù°‰ª∂Âπ≥Áßª‰ºòÂåñ` `Â∫¶ÈáèÊÑüÁü•Â≠¶‰π†` `‰º™ÁúüÂÄºÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂçï‰∫∫‰∫∫‰ΩìÁΩëÊ†ºÈáçÂª∫ÊñπÊ≥ïÂú®Â§ö‰∫∫Âú∫ÊôØ‰∏≠Áº∫‰πèÂú∫ÊôØ‰∏ÄËá¥ÊÄßÔºåÂØºËá¥Ê∑±Â∫¶ÂíåÂ∞∫Â∫¶ÂÜ≤Á™Å„ÄÇ
2. ÊèêÂá∫Ê∑±Â∫¶Êù°‰ª∂Âπ≥Áßª‰ºòÂåñ(DTO)ÊñπÊ≥ïÔºåËÅîÂêà‰ºòÂåñ‰∫∫Áæ§‰∏≠‰∏™‰ΩìÁöÑÁõ∏Êú∫Á©∫Èó¥‰ΩçÁΩÆÔºå‰øùËØÅÂú∫ÊôØ‰∏ÄËá¥ÊÄß„ÄÇ
3. ÊûÑÂª∫Â§ßËßÑÊ®°‰º™ÁúüÂÄºÊï∞ÊçÆÈõÜDTO-HumansÔºåÂπ∂ÊèêÂá∫Â∫¶ÈáèÊÑüÁü•HMRÁΩëÁªúÔºåÂÆûÈ™åË°®ÊòéÊÄßËÉΩ‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂçïÂõæÂÉèÂ§ö‰∫∫‰∫∫‰ΩìÁΩëÊ†ºÈáçÂª∫ÊûÅÂÖ∑ÊåëÊàòÔºå‰∏ªË¶ÅÈöúÁ¢çÂú®‰∫éÁº∫‰πèÁúüÂÆûÂú∫ÊôØÁöÑËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇÁõÆÂâçÊµÅË°åÁöÑÂú∫ÊôØ‰∫∫‰ΩìÁΩëÊ†º‰º™ÁúüÂÄº(pGT)ÁîüÊàêÊµÅÁ®ã‰ª•Âçï‰∫∫‰∏∫‰∏≠ÂøÉÔºåÁã¨Á´ãÂ§ÑÁêÜÊØè‰∏™‰∫∫ÔºåÁº∫‰πèËÅîÂêà‰ºòÂåñ„ÄÇËøôÂØºËá¥Âú∫ÊôØÁ∫ß‰∏ç‰∏ÄËá¥Ôºå‰∏™‰ΩìÊ∑±Â∫¶ÂíåÂ∞∫Â∫¶ÂÜ≤Á™Å„ÄÇ‰∏∫Ëß£ÂÜ≥Ê≠§ÈóÆÈ¢òÔºåÊàë‰ª¨ÂºïÂÖ•Ê∑±Â∫¶Êù°‰ª∂Âπ≥Áßª‰ºòÂåñ(DTO)Ôºå‰∏ÄÁßçÂü∫‰∫é‰ºòÂåñÁöÑÊñπÊ≥ïÔºåËÅîÂêà‰ºòÂåñ‰∫∫Áæ§‰∏≠ÊâÄÊúâ‰∏™‰ΩìÁöÑÁõ∏Êú∫Á©∫Èó¥Âπ≥Áßª„ÄÇDTOÂà©Áî®‰∫∫‰ΩìÊµãÈáèÂ≠¶ÂÖàÈ™åÂíåÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°Âô®ÁöÑÊ∑±Â∫¶Á∫øÁ¥¢ÔºåÂú®ÊúÄÂ§ßÂêéÈ™å(MAP)Ê°ÜÊû∂‰∏ãÊ±ÇËß£Âú∫ÊôØ‰∏ÄËá¥ÁöÑ‰∏™‰Ωì‰ΩçÁΩÆ„ÄÇÊàë‰ª¨Â∞ÜDTOÂ∫îÁî®‰∫é4D-HumansÊï∞ÊçÆÈõÜÔºåÊûÑÂª∫‰∫ÜDTO-HumansÔºå‰∏Ä‰∏™ÂåÖÂê´0.56MÈ´òË¥®Èáè„ÄÅÂú∫ÊôØ‰∏ÄËá¥ÁöÑÂ§ö‰∫∫ÂõæÂÉèÁöÑÂ§ßËßÑÊ®°pGTÊï∞ÊçÆÈõÜÔºåÂõæÂÉèÂπ≥ÂùáÂåÖÂê´4.8‰∫∫„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫Â∫¶ÈáèÊÑüÁü•HMRÔºå‰∏Ä‰∏™Á´ØÂà∞Á´ØÁΩëÁªúÔºåÁõ¥Êé•‰º∞ËÆ°Â∫¶ÈáèÂ∞∫Â∫¶ÁöÑ‰∫∫‰ΩìÁΩëÊ†ºÂíåÁõ∏Êú∫ÂèÇÊï∞„ÄÇËøôÈÄöËøáÁõ∏Êú∫ÂàÜÊîØÂíåÁõ∏ÂØπÂ∫¶ÈáèÊçüÂ§±ÂÆûÁé∞ÔºåËØ•ÊçüÂ§±Âº∫Âà∂ÊâßË°åÂêàÁêÜÁöÑÁõ∏ÂØπÂ∞∫Â∫¶„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Áõ∏ÂØπÊ∑±Â∫¶Êé®ÁêÜÂíå‰∫∫‰ΩìÁΩëÊ†ºÈáçÂª∫ÊñπÈù¢ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂçïÂº†ÂõæÂÉè‰∏≠Â§ö‰∫∫‰∫∫‰ΩìÁΩëÊ†ºÈáçÂª∫ÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶ÅÂü∫‰∫éÂçï‰∫∫ÈáçÂª∫ÔºåÂøΩÁï•‰∫ÜÂú∫ÊôØ‰∏≠Â§ö‰∫∫‰πãÈó¥ÁöÑÁõ∏‰∫íÂÖ≥Á≥ªÔºåÂØºËá¥ÈáçÂª∫ÁªìÊûúÂú®Ê∑±Â∫¶ÂíåÂ∞∫Â∫¶‰∏ä‰∏ç‰∏ÄËá¥ÔºåÁº∫‰πèÂú∫ÊôØÁ∫ßÁöÑÂêàÁêÜÊÄß„ÄÇÁé∞Êúâ‰º™ÁúüÂÄºÁîüÊàêÊµÅÁ®ã‰πüÂ≠òÂú®ÂêåÊ†∑ÁöÑÈóÆÈ¢òÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÂú®ÁúüÂÆûÂú∫ÊôØ‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØËÅîÂêà‰ºòÂåñÂú∫ÊôØ‰∏≠ÊâÄÊúâ‰∫∫ÁöÑÁõ∏Êú∫Á©∫Èó¥‰ΩçÁΩÆÔºå‰øùËØÅÈáçÂª∫ÁªìÊûúÁöÑÂú∫ÊôØ‰∏ÄËá¥ÊÄß„ÄÇÈÄöËøáÂºïÂÖ•‰∫∫‰ΩìÊµãÈáèÂ≠¶ÂÖàÈ™åÔºàÂ¶ÇË∫´È´òÔºâÂíåÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°Âô®ÁöÑÊ∑±Â∫¶‰ø°ÊÅØÔºåÊûÑÂª∫‰∏Ä‰∏™ËÉΩÈáèÂáΩÊï∞ÔºåÂπ∂ÈÄöËøá‰ºòÂåñÁÆóÊ≥ïÊ±ÇËß£ÊúÄ‰ºòÁöÑ‰∏™‰Ωì‰ΩçÁΩÆ„ÄÇÂêåÊó∂ÔºåËÆæËÆ°‰∏Ä‰∏™Â∫¶ÈáèÊÑüÁü•ÁöÑ‰∫∫‰ΩìÁΩëÊ†ºÈáçÂª∫ÁΩëÁªúÔºåÁõ¥Êé•È¢ÑÊµãÂ∫¶ÈáèÂ∞∫Â∫¶‰∏ãÁöÑÁΩëÊ†ºÂíåÁõ∏Êú∫ÂèÇÊï∞„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÈÉ®ÂàÜÔºö1) Âü∫‰∫éÊ∑±Â∫¶Êù°‰ª∂Âπ≥Áßª‰ºòÂåñ(DTO)ÁöÑ‰º™ÁúüÂÄºÁîüÊàêÊµÅÁ®ãÔºõ2) Â∫¶ÈáèÊÑüÁü•ÁöÑ‰∫∫‰ΩìÁΩëÊ†ºÈáçÂª∫ÁΩëÁªú(Metric-Aware HMR)„ÄÇDTOÊµÅÁ®ãÈ¶ñÂÖà‰ΩøÁî®Âçï‰∫∫HMRÊñπÊ≥ïÂàùÂßãÂåñÊØè‰∏™‰∫∫ÁöÑÁΩëÊ†ºÔºåÁÑ∂ÂêéÂà©Áî®ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°Âô®Êèê‰æõÊ∑±Â∫¶‰ø°ÊÅØÔºåÊúÄÂêéÈÄöËøá‰ºòÂåñÁÆóÊ≥ïË∞ÉÊï¥ÊØè‰∏™‰∫∫ÁöÑÁõ∏Êú∫Á©∫Èó¥Âπ≥ÁßªÔºåÁîüÊàêÂú∫ÊôØ‰∏ÄËá¥ÁöÑ‰º™ÁúüÂÄº„ÄÇMetric-Aware HMRÊòØ‰∏Ä‰∏™Á´ØÂà∞Á´ØÁΩëÁªúÔºåÂåÖÂê´‰∏Ä‰∏™Ê†áÂáÜÁöÑHMR‰∏ªÂπ≤ÁΩëÁªúÂíå‰∏Ä‰∏™Áõ∏Êú∫ÂàÜÊîØÔºåÁî®‰∫éÈ¢ÑÊµãÁõ∏Êú∫ÂèÇÊï∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫ÜÊ∑±Â∫¶Êù°‰ª∂Âπ≥Áßª‰ºòÂåñ(DTO)ÊñπÊ≥ïÔºåËÉΩÂ§üÁîüÊàêÂú∫ÊôØ‰∏ÄËá¥ÁöÑÂ§ö‰∫∫‰∫∫‰ΩìÁΩëÊ†º‰º™ÁúüÂÄºÔºõ2) ÊèêÂá∫‰∫ÜÂ∫¶ÈáèÊÑüÁü•ÁöÑ‰∫∫‰ΩìÁΩëÊ†ºÈáçÂª∫ÁΩëÁªú(Metric-Aware HMR)ÔºåËÉΩÂ§üÁõ¥Êé•È¢ÑÊµãÂ∫¶ÈáèÂ∞∫Â∫¶‰∏ãÁöÑÁΩëÊ†ºÂíåÁõ∏Êú∫ÂèÇÊï∞Ôºõ3) ÊûÑÂª∫‰∫ÜÂ§ßËßÑÊ®°ÁöÑÂú∫ÊôØ‰∏ÄËá¥Â§ö‰∫∫‰∫∫‰ΩìÁΩëÊ†º‰º™ÁúüÂÄºÊï∞ÊçÆÈõÜDTO-Humans„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöDTOÊñπÊ≥ï‰∏≠ÔºåËÉΩÈáèÂáΩÊï∞ÂåÖÂê´‰∏§ÈÉ®ÂàÜÔºö‰∏ÄÊòØÂü∫‰∫é‰∫∫‰ΩìË∫´È´òÂÖàÈ™åÁöÑÊ≠£ÂàôÈ°πÔºåÈºìÂä±‰∏™‰ΩìË∫´È´òÊé•ËøëÁúüÂÆûÂÄºÔºõ‰∫åÊòØÂü∫‰∫éÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÊ∑±Â∫¶‰∏ÄËá¥ÊÄßÈ°πÔºåÈºìÂä±‰∏™‰ΩìÊ∑±Â∫¶‰∏é‰º∞ËÆ°Ê∑±Â∫¶‰∏ÄËá¥„ÄÇMetric-Aware HMRÁΩëÁªú‰∏≠ÔºåÁõ∏Êú∫ÂàÜÊîØÈ¢ÑÊµãÁõ∏Êú∫ÂèÇÊï∞ÔºåÂπ∂ÂºïÂÖ•Áõ∏ÂØπÂ∫¶ÈáèÊçüÂ§±ÔºåÈºìÂä±È¢ÑÊµãÁöÑÁõ∏ÂØπÂ∞∫Â∫¶‰∏éÁúüÂÆûÁõ∏ÂØπÂ∞∫Â∫¶‰∏ÄËá¥„ÄÇÁõ∏ÂØπÂ∫¶ÈáèÊçüÂ§±ËÆ°ÁÆóÊñπÂºè‰∏∫È¢ÑÊµãË∫´È´ò‰∏éÁúüÂÆûË∫´È´òÁöÑÊØîÂÄºÔºåÂπ∂ÊúÄÂ∞èÂåñÂÖ∂‰∏é1ÁöÑÂ∑ÆË∑ù„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊèêÂá∫ÁöÑDTOÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÊèêÂçáÂ§ö‰∫∫‰∫∫‰ΩìÁΩëÊ†ºÈáçÂª∫ÁöÑÂú∫ÊôØ‰∏ÄËá¥ÊÄßÔºåÁîüÊàêÁöÑDTO-HumansÊï∞ÊçÆÈõÜËÉΩÂ§üÊòæËëóÊèêÂçáÁé∞ÊúâHMRÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇMetric-Aware HMRÁΩëÁªúÂú®benchmarkÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Üstate-of-the-artÁöÑÁªìÊûúÔºåÂú®Áõ∏ÂØπÊ∑±Â∫¶Êé®ÁêÜÂíå‰∫∫‰ΩìÁΩëÊ†ºÈáçÂª∫ÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆû„ÄÅÊô∫ËÉΩÁõëÊéß„ÄÅ‰∫∫Êú∫‰∫§‰∫íÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®ËôöÊãüÁé∞ÂÆû‰∏≠ÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊäÄÊúØÈáçÂª∫ËôöÊãüÂú∫ÊôØ‰∏≠ÁöÑÂ§ö‰∫∫ËßíËâ≤ÔºåÂπ∂‰øùËØÅËßíËâ≤‰πãÈó¥ÁöÑÁõ∏ÂØπ‰ΩçÁΩÆÂíåÂ∞∫Â∫¶ÂÖ≥Á≥ªÂêàÁêÜ„ÄÇÂú®Êô∫ËÉΩÁõëÊéß‰∏≠ÔºåÂèØ‰ª•Áî®‰∫é‰∫∫Áæ§Ë°å‰∏∫ÂàÜÊûêÂíåÂºÇÂ∏∏‰∫ã‰ª∂Ê£ÄÊµã„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÊèêÂçáÁõ∏ÂÖ≥Â∫îÁî®ÁöÑÁî®Êà∑‰ΩìÈ™åÂíåÊô∫ËÉΩÂåñÊ∞¥Âπ≥„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multi-person human mesh recovery from a single image is a challenging task, hindered by the scarcity of in-the-wild training data. Prevailing in-the-wild human mesh pseudo-ground-truth (pGT) generation pipelines are single-person-centric, where each human is processed individually without joint optimization. This oversight leads to a lack of scene-level consistency, producing individuals with conflicting depths and scales within the same image. To address this, we introduce Depth-conditioned Translation Optimization (DTO), a novel optimization-based method that jointly refines the camera-space translations of all individuals in a crowd. By leveraging anthropometric priors on human height and depth cues from a monocular depth estimator, DTO solves for a scene-consistent placement of all subjects within a principled Maximum a posteriori (MAP) framework. Applying DTO to the 4D-Humans dataset, we construct DTO-Humans, a new large-scale pGT dataset of 0.56M high-quality, scene-consistent multi-person images, featuring dense crowds with an average of 4.8 persons per image. Furthermore, we propose Metric-Aware HMR, an end-to-end network that directly estimates human mesh and camera parameters in metric scale. This is enabled by a camera branch and a relative metric loss that enforces plausible relative scales. Extensive experiments demonstrate that our method achieves state-of-the-art performance on relative depth reasoning and human mesh recovery. Code is available at: https://github.com/gouba2333/MA-HMR.

