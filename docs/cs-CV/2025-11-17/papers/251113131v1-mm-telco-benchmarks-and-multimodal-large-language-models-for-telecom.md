---
layout: default
title: MM-Telco: Benchmarks and Multimodal Large Language Models for Telecom Applications
---

# MM-Telco: Benchmarks and Multimodal Large Language Models for Telecom Applications

**arXiv**: [2511.13131v1](https://arxiv.org/abs/2511.13131) | [PDF](https://arxiv.org/pdf/2511.13131.pdf)

**ä½œè€…**: Gagan Raj Gupta, Anshul Kumar, Manish Rai, Apu Chakraborty, Ashutosh Modi, Abdelaali Chaoub, Soumajit Pramanik, Moyank Giri, Yashwanth Holla, Sunny Kumar, M. V. Kiran Sooraj

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMM-TelcoåŸºå‡†ä¸Žå¤šæ¨¡æ€å¤§æ¨¡åž‹ä»¥è§£å†³ç”µä¿¡é¢†åŸŸåº”ç”¨æŒ‘æˆ˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `ç”µä¿¡åº”ç”¨åŸºå‡†` `ç½‘ç»œè¿ç»´è‡ªåŠ¨åŒ–` `å›¾åƒæ–‡æœ¬æ£€ç´¢` `æ¨¡åž‹å¾®è°ƒ` `æ€§èƒ½è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç”µä¿¡é¢†åŸŸå¤§æ¨¡åž‹éƒ¨ç½²é¢ä¸´é¢†åŸŸç‰¹å®šæŒ‘æˆ˜ï¼Œéœ€ä¸“é—¨é€‚åº”ã€‚
2. æž„å»ºå¤šæ¨¡æ€åŸºå‡†ï¼Œæ¶µç›–æ–‡æœ¬ä¸Žå›¾åƒä»»åŠ¡ï¼Œæ”¯æŒç½‘ç»œè¿ç»´ç­‰ç”¨ä¾‹ã€‚
3. åŸºå‡†å®žéªŒæ˜¾ç¤ºå¾®è°ƒæ¨¡åž‹æ€§èƒ½æ˜¾è‘—æå‡ï¼Œå¹¶è¯†åˆ«å½“å‰æ¨¡åž‹å¼±ç‚¹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large Language Models (LLMs) have emerged as powerful tools for automating complex reasoning and decision-making tasks. In telecommunications, they hold the potential to transform network optimization, automate troubleshooting, enhance customer support, and ensure regulatory compliance. However, their deployment in telecom is hindered by domain-specific challenges that demand specialized adaptation. To overcome these challenges and to accelerate the adaptation of LLMs for telecom, we propose MM-Telco, a comprehensive suite of multimodal benchmarks and models tailored for the telecom domain. The benchmark introduces various tasks (both text based and image based) that address various practical real-life use cases such as network operations, network management, improving documentation quality, and retrieval of relevant text and images. Further, we perform baseline experiments with various LLMs and VLMs. The models fine-tuned on our dataset exhibit a significant boost in performance. Our experiments also help analyze the weak areas in the working of current state-of-art multimodal LLMs, thus guiding towards further development and research.

