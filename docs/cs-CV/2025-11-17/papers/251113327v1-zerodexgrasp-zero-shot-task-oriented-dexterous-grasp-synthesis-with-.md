---
layout: default
title: ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning
---

# ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning

**arXiv**: [2511.13327v1](https://arxiv.org/abs/2511.13327) | [PDF](https://arxiv.org/pdf/2511.13327.pdf)

**ä½œè€…**: Juntao Jian, Yi-Lin Wei, Chengjie Mou, Yuhao Lin, Xing Zhu, Yujun Shen, Wei-Shi Zheng, Ruizhen Hu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºZeroDexGraspæ¡†æž¶ä»¥è§£å†³é›¶æ ·æœ¬ä»»åŠ¡å¯¼å‘çµå·§æŠ“å–æ³›åŒ–é—®é¢˜**

**å…³é”®è¯**: `çµå·§æŠ“å–åˆæˆ` `é›¶æ ·æœ¬å­¦ä¹ ` `å¤šæ¨¡æ€æŽ¨ç†` `ä»»åŠ¡å¯¼å‘æŠ“å–` `æŠ“å–ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–æ ‡æ³¨æ•°æ®ï¼Œéš¾ä»¥æ³›åŒ–åˆ°å¤šæ ·ç‰©ä½“å’Œä»»åŠ¡æŒ‡ä»¤
2. ç»“åˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ä¸ŽæŠ“å–ä¼˜åŒ–ï¼ŒæŽ¨ç†åˆå§‹æŠ“å–é…ç½®å¹¶ä¼˜åŒ–ç‰©ç†å¯è¡Œæ€§
3. å®žéªŒæ˜¾ç¤ºåœ¨æœªè§ç‰©ä½“å’Œå¤æ‚ä»»åŠ¡ä¸Šå®žçŽ°é«˜è´¨é‡é›¶æ ·æœ¬æŠ“å–

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Task-oriented dexterous grasping holds broad application prospects in robotic manipulation and human-object interaction. However, most existing methods still struggle to generalize across diverse objects and task instructions, as they heavily rely on costly labeled data to ensure task-specific semantic alignment. In this study, we propose \textbf{ZeroDexGrasp}, a zero-shot task-oriented dexterous grasp synthesis framework integrating Multimodal Large Language Models with grasp refinement to generate human-like grasp poses that are well aligned with specific task objectives and object affordances. Specifically, ZeroDexGrasp employs prompt-based multi-stage semantic reasoning to infer initial grasp configurations and object contact information from task and object semantics, then exploits contact-guided grasp optimization to refine these poses for physical feasibility and task alignment. Experimental results demonstrate that ZeroDexGrasp enables high-quality zero-shot dexterous grasping on diverse unseen object categories and complex task requirements, advancing toward more generalizable and intelligent robotic grasping.

