---
layout: default
title: Semi-Supervised High Dynamic Range Image Reconstructing via Bi-Level Uncertain Area Masking
---

# Semi-Supervised High Dynamic Range Image Reconstructing via Bi-Level Uncertain Area Masking

**arXiv**: [2511.12939v1](https://arxiv.org/abs/2511.12939) | [PDF](https://arxiv.org/pdf/2511.12939.pdf)

**ä½œè€…**: Wei Jiang, Jiahao Cui, Yizheng Wu, Zhan Peng, Zhiyu Pan, Zhiguo Cao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒå±‚ä¸ç¡®å®šæ€§æŽ©ç çš„åŠç›‘ç£æ–¹æ³•ä»¥è§£å†³HDRå›¾åƒé‡å»ºä¸­æ ‡æ³¨æ•°æ®ç¨€ç¼ºé—®é¢˜**

**å…³é”®è¯**: `é«˜åŠ¨æ€èŒƒå›´å›¾åƒé‡å»º` `åŠç›‘ç£å­¦ä¹ ` `ä¸ç¡®å®šæ€§æŽ©ç ` `å¸ˆç”Ÿæ¨¡åž‹` `è®¡ç®—æ‘„å½±`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šHDRå›¾åƒé‡å»ºä¾èµ–LDR-HDRå›¾åƒå¯¹ï¼Œä½†æ ‡æ³¨æ•°æ®éš¾ä»¥èŽ·å–ï¼Œå¯¼è‡´æ€§èƒ½å—é™
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å¸ˆç”Ÿæ¨¡åž‹æ¡†æž¶ï¼Œé€šè¿‡åƒç´ å’Œè¡¥ä¸çº§ä¸ç¡®å®šæ€§æŽ©ç è¿‡æ»¤ä¼ªæ ‡ç­¾ä¸­çš„ä¸å¯é åŒºåŸŸ
3. å®žéªŒæˆ–æ•ˆæžœï¼šä»…ä½¿ç”¨6.7%æ ‡æ³¨æ•°æ®ï¼Œæ€§èƒ½ä¼˜äºŽçŽ°æœ‰åŠç›‘ç£æ–¹æ³•ï¼Œå¹¶åª²ç¾Žå…¨ç›‘ç£æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reconstructing high dynamic range (HDR) images from low dynamic range (LDR) bursts plays an essential role in the computational photography. Impressive progress has been achieved by learning-based algorithms which require LDR-HDR image pairs. However, these pairs are hard to obtain, which motivates researchers to delve into the problem of annotation-efficient HDR image reconstructing: how to achieve comparable performance with limited HDR ground truths (GTs). This work attempts to address this problem from the view of semi-supervised learning where a teacher model generates pseudo HDR GTs for the LDR samples without GTs and a student model learns from pseudo GTs. Nevertheless, the confirmation bias, i.e., the student may learn from the artifacts in pseudo HDR GTs, presents an impediment. To remove this impediment, an uncertainty-based masking process is proposed to discard unreliable parts of pseudo GTs at both pixel and patch levels, then the trusted areas can be learned from by the student. With this novel masking process, our semi-supervised HDR reconstructing method not only outperforms previous annotation-efficient algorithms, but also achieves comparable performance with up-to-date fully-supervised methods by using only 6.7% HDR GTs.

