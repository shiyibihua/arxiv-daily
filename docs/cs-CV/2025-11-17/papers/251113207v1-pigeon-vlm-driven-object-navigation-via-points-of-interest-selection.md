---
layout: default
title: PIGEON: VLM-Driven Object Navigation via Points of Interest Selection
---

# PIGEON: VLM-Driven Object Navigation via Points of Interest Selection

**arXiv**: [2511.13207v1](https://arxiv.org/abs/2511.13207) | [PDF](https://arxiv.org/pdf/2511.13207.pdf)

**ä½œè€…**: Cheng Peng, Zhenzhe Zhang, Cheng Chi, Xiaobao Wei, Yanhao Zhang, Heng Wang, Pengwei Wang, Zhongyuan Wang, Jing Liu, Shanghang Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPIGEONæ–¹æ³•ï¼Œé€šè¿‡å…´è¶£ç‚¹é€‰æ‹©è§£å†³æœªçŸ¥çŽ¯å¢ƒä¸­ç‰©ä½“å¯¼èˆªé—®é¢˜**

**å…³é”®è¯**: `ç‰©ä½“å¯¼èˆª` `è§†è§‰è¯­è¨€æ¨¡åž‹` `å…´è¶£ç‚¹é€‰æ‹©` `å¼ºåŒ–å­¦ä¹ ` `é›¶æ ·æœ¬è½¬ç§»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœªçŸ¥çŽ¯å¢ƒä¸­ç‰©ä½“å¯¼èˆªå†³ç­–é¢‘çŽ‡ä¸Žæ™ºèƒ½æ€§éš¾ä»¥å¹³è¡¡ï¼Œå¯¼è‡´çŸ­è§†æˆ–ä¸è¿žç»­åŠ¨ä½œ
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨VLMé€‰æ‹©å…´è¶£ç‚¹ï¼Œç»“åˆè½»é‡è¯­ä¹‰è®°å¿†å’Œä½Žçº§è§„åˆ’å™¨æé«˜å†³ç­–é¢‘çŽ‡
3. å®žéªŒæˆ–æ•ˆæžœï¼šé›¶æ ·æœ¬è½¬ç§»åœ¨åŸºå‡†æµ‹è¯•ä¸­è¾¾SOTAï¼ŒRLVRå¢žå¼ºè¯­ä¹‰å¼•å¯¼å’Œå®žæ—¶æŽ¨ç†èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Navigating to a specified object in an unknown environment is a fundamental yet challenging capability of embodied intelligence. However, current methods struggle to balance decision frequency with intelligence, resulting in decisions lacking foresight or discontinuous actions. In this work, we propose PIGEON: Point of Interest Guided Exploration for Object Navigation with VLM, maintaining a lightweight and semantically aligned snapshot memory during exploration as semantic input for the exploration strategy. We use a large Visual-Language Model (VLM), named PIGEON-VL, to select Points of Interest (PoI) formed during exploration and then employ a lower-level planner for action output, increasing the decision frequency. Additionally, this PoI-based decision-making enables the generation of Reinforcement Learning with Verifiable Reward (RLVR) data suitable for simulators. Experiments on classic object navigation benchmarks demonstrate that our zero-shot transfer method achieves state-of-the-art performance, while RLVR further enhances the model's semantic guidance capabilities, enabling deep reasoning during real-time navigation.

