---
layout: default
title: Explore How to Inject Beneficial Noise in MLLMs
---

# Explore How to Inject Beneficial Noise in MLLMs

**arXiv**: [2511.12917v1](https://arxiv.org/abs/2511.12917) | [PDF](https://arxiv.org/pdf/2511.12917.pdf)

**ä½œè€…**: Ruishu Zhu, Sida Huang, Ziheng Jiao, Hongyuan Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€å™ªå£°ç”Ÿæˆå™¨ä»¥ä¼˜åŒ–MLLMsè·¨æ¨¡æ€å¯¹é½ï¼Œå®žçŽ°é«˜æ•ˆå¾®è°ƒ**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `å™ªå£°æ³¨å…¥` `è·¨æ¨¡æ€å¯¹é½` `é«˜æ•ˆå¾®è°ƒ` `å˜åˆ†æŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰MLLMså¾®è°ƒæ–¹æ³•å¿½ç•¥è·¨æ¨¡æ€å¼‚æž„æ€§ï¼Œé™åˆ¶æ€§èƒ½æå‡
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå˜åˆ†æŽ¨ç†è®¾è®¡å™ªå£°ç”Ÿæˆå™¨ï¼ŒåŠ¨æ€åˆ†æžè·¨æ¨¡æ€å…³ç³»æ³¨å…¥æœ‰ç›Šå™ªå£°
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨QwenVLå’ŒLLaVAä¸Šè¶…è¶Šå…¨å‚æ•°å¾®è°ƒï¼Œä»…éœ€1~2%é¢å¤–å‚æ•°

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) have played an increasingly important role in multimodal intelligence. However, the existing fine-tuning methods often ignore cross-modal heterogeneity, limiting their full potential. In this work, we propose a novel fine-tuning strategy by injecting beneficial random noise, which outperforms previous methods and even surpasses full fine-tuning, with minimal additional parameters. The proposed Multimodal Noise Generator (MuNG) enables efficient modality fine-tuning by injecting customized noise into the frozen MLLMs. Specifically, we reformulate the reasoning process of MLLMs from a variational inference perspective, upon which we design a multimodal noise generator that dynamically analyzes cross-modal relationships in image-text pairs to generate task-adaptive beneficial noise. Injecting this type of noise into the MLLMs effectively suppresses irrelevant semantic components, leading to significantly improved cross-modal representation alignment and enhanced performance on downstream tasks. Experiments on two mainstream MLLMs, QwenVL and LLaVA, demonstrate that our method surpasses full-parameter fine-tuning and other existing fine-tuning approaches, while requiring adjustments to only about $1\sim2\%$ additional parameters. The relevant code is uploaded in the supplementary.

