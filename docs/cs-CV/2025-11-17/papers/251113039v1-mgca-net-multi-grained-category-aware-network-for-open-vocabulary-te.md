---
layout: default
title: MGCA-Net: Multi-Grained Category-Aware Network for Open-Vocabulary Temporal Action Localization
---

# MGCA-Net: Multi-Grained Category-Aware Network for Open-Vocabulary Temporal Action Localization

**arXiv**: [2511.13039v1](https://arxiv.org/abs/2511.13039) | [PDF](https://arxiv.org/pdf/2511.13039.pdf)

**ä½œè€…**: Zhenying Fang, Richang Hong

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-17

**å¤‡æ³¨**: 12 pages, 3 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMGCA-Netï¼Œé€šè¿‡å¤šç²’åº¦ç±»åˆ«æ„ŸçŸ¥è§£å†³å¼€æ”¾è¯æ±‡æ—¶åºåŠ¨ä½œå®šä½é—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å¼€æ”¾è¯æ±‡æ—¶åºåŠ¨ä½œå®šä½` `å¤šç²’åº¦å­¦ä¹ ` `ç±»åˆ«æ„ŸçŸ¥` `è§†é¢‘ç†è§£` `é›¶æ ·æœ¬å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¼€æ”¾è¯æ±‡æ—¶åºåŠ¨ä½œå®šä½æ–¹æ³•åœ¨å•ä¸€ç²’åº¦ä¸Šè¯†åˆ«åŠ¨ä½œç±»åˆ«ï¼Œå¯¼è‡´åŸºç¡€ç±»åˆ«å’Œæ–°ç±»åˆ«çš„è¯†åˆ«ç²¾åº¦ä¸‹é™ã€‚
2. MGCA-Neté€šè¿‡å¤šç²’åº¦ç±»åˆ«æ„ŸçŸ¥ï¼Œåˆ©ç”¨å®šä½å™¨ã€åŠ¨ä½œå­˜åœ¨é¢„æµ‹å™¨å’Œç²—åˆ°ç²¾åˆ†ç±»å™¨ï¼Œæå‡åŠ¨ä½œå®šä½æ€§èƒ½ã€‚
3. åœ¨THUMOS'14å’ŒActivityNet-1.3æ•°æ®é›†ä¸Šï¼ŒMGCA-Netå–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬è®¾ç½®ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šç²’åº¦ç±»åˆ«æ„ŸçŸ¥ç½‘ç»œ(MGCA-Net)ï¼Œç”¨äºŽè§£å†³å¼€æ”¾è¯æ±‡æ—¶åºåŠ¨ä½œå®šä½(OV-TAL)é—®é¢˜ã€‚OV-TALæ—¨åœ¨è¯†åˆ«å’Œå®šä½è§†é¢‘ä¸­ä»»æ„æœŸæœ›åŠ¨ä½œç±»åˆ«çš„å®žä¾‹ï¼Œè€Œæ— éœ€ä¸ºæ‰€æœ‰ç±»åˆ«æ˜¾å¼åœ°æ•´ç†è®­ç»ƒæ•°æ®ã€‚çŽ°æœ‰æ–¹æ³•å¤§å¤šåœ¨å•ä¸€ç²’åº¦ä¸Šè¯†åˆ«åŠ¨ä½œç±»åˆ«ï¼Œé™ä½Žäº†åŸºç¡€å’Œæ–°ç±»åˆ«åŠ¨ä½œçš„è¯†åˆ«ç²¾åº¦ã€‚MGCA-NetåŒ…å«ä¸€ä¸ªå®šä½å™¨ã€ä¸€ä¸ªåŠ¨ä½œå­˜åœ¨é¢„æµ‹å™¨ã€ä¸€ä¸ªä¼ ç»Ÿåˆ†ç±»å™¨å’Œä¸€ä¸ªç”±ç²—åˆ°ç²¾çš„åˆ†ç±»å™¨ã€‚å®šä½å™¨ç”¨äºŽå®šä½ç±»åˆ«æ— å…³çš„åŠ¨ä½œæè®®ã€‚åŠ¨ä½œå­˜åœ¨é¢„æµ‹å™¨ä¼°è®¡è¿™äº›åŠ¨ä½œæè®®å±žäºŽåŠ¨ä½œå®žä¾‹çš„æ¦‚çŽ‡ã€‚ä¼ ç»Ÿåˆ†ç±»å™¨é¢„æµ‹æ¯ä¸ªåŠ¨ä½œæè®®åœ¨ç‰‡æ®µç²’åº¦ä¸Šå±žäºŽåŸºç¡€åŠ¨ä½œç±»åˆ«çš„æ¦‚çŽ‡ã€‚ç”±ç²—åˆ°ç²¾çš„åˆ†ç±»å™¨è¯†åˆ«æ–°åŠ¨ä½œç±»åˆ«ï¼Œé¦–å…ˆåœ¨è§†é¢‘ç²’åº¦ä¸Šè¯†åˆ«åŠ¨ä½œå­˜åœ¨ï¼Œç„¶åŽå°†æ¯ä¸ªåŠ¨ä½œæè®®åˆ†é…åˆ°æè®®ç²’åº¦ä¸Šçš„ç²—ç±»åˆ«ã€‚é€šè¿‡å¯¹æ–°åŠ¨ä½œçš„ç”±ç²—åˆ°ç²¾çš„ç±»åˆ«æ„ŸçŸ¥å’Œä¼ ç»Ÿåˆ†ç±»å™¨å¯¹åŸºç¡€åŠ¨ä½œçš„æ„ŸçŸ¥ï¼Œå®žçŽ°äº†å¤šç²’åº¦ç±»åˆ«æ„ŸçŸ¥ï¼Œæœ‰æ•ˆæé«˜äº†å®šä½æ€§èƒ½ã€‚åœ¨THUMOS'14å’ŒActivityNet-1.3åŸºå‡†ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜Žï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒMGCA-Netåœ¨é›¶æ ·æœ¬æ—¶åºåŠ¨ä½œå®šä½è®¾ç½®ä¸‹ä¹Ÿå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æžœã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¼€æ”¾è¯æ±‡æ—¶åºåŠ¨ä½œå®šä½(OV-TAL)æ—¨åœ¨è¯†åˆ«å’Œå®šä½è§†é¢‘ä¸­ä»»æ„åŠ¨ä½œç±»åˆ«çš„å®žä¾‹ï¼Œè€Œæ— éœ€ä¸ºæ‰€æœ‰ç±»åˆ«å‡†å¤‡è®­ç»ƒæ•°æ®ã€‚çŽ°æœ‰æ–¹æ³•ä¸»è¦åœ¨å•ä¸€ç²’åº¦ä¸Šè¯†åˆ«åŠ¨ä½œç±»åˆ«ï¼Œè¿™é™åˆ¶äº†æ¨¡åž‹åŒºåˆ†ç»†ç²’åº¦åŠ¨ä½œçš„èƒ½åŠ›ï¼Œå¯¼è‡´åŸºç¡€ç±»åˆ«å’Œæ–°ç±»åˆ«çš„è¯†åˆ«ç²¾åº¦éƒ½å—åˆ°å½±å“ã€‚å› æ­¤ï¼Œå¦‚ä½•æå‡æ¨¡åž‹åœ¨ä¸åŒç²’åº¦ä¸Šè¯†åˆ«åŠ¨ä½œç±»åˆ«çš„èƒ½åŠ›æ˜¯å…³é”®æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMGCA-Netçš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥å¤šç²’åº¦ç±»åˆ«æ„ŸçŸ¥æœºåˆ¶ã€‚å¯¹äºŽåŸºç¡€åŠ¨ä½œç±»åˆ«ï¼Œä½¿ç”¨ä¼ ç»Ÿçš„åˆ†ç±»å™¨åœ¨ç‰‡æ®µç²’åº¦ä¸Šè¿›è¡Œè¯†åˆ«ï¼›å¯¹äºŽæ–°åŠ¨ä½œç±»åˆ«ï¼Œåˆ™é‡‡ç”¨ç”±ç²—åˆ°ç²¾çš„åˆ†ç±»å™¨ï¼Œé¦–å…ˆåœ¨è§†é¢‘ç²’åº¦ä¸Šåˆ¤æ–­åŠ¨ä½œæ˜¯å¦å­˜åœ¨ï¼Œç„¶åŽåœ¨æè®®ç²’åº¦ä¸Šå°†åŠ¨ä½œæè®®åˆ†é…åˆ°ç²—ç±»åˆ«ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡åž‹èƒ½å¤ŸåŒæ—¶æ„ŸçŸ¥ç²—ç²’åº¦å’Œç»†ç²’åº¦çš„ç±»åˆ«ä¿¡æ¯ï¼Œä»Žè€Œæé«˜åŠ¨ä½œå®šä½çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šMGCA-Netçš„æ•´ä½“æž¶æž„åŒ…å«å››ä¸ªä¸»è¦æ¨¡å—ï¼š1) å®šä½å™¨ï¼šç”¨äºŽç”Ÿæˆç±»åˆ«æ— å…³çš„åŠ¨ä½œæè®®ï¼›2) åŠ¨ä½œå­˜åœ¨é¢„æµ‹å™¨ï¼šä¼°è®¡æ¯ä¸ªåŠ¨ä½œæè®®å±žäºŽåŠ¨ä½œå®žä¾‹çš„æ¦‚çŽ‡ï¼›3) ä¼ ç»Ÿåˆ†ç±»å™¨ï¼šåœ¨ç‰‡æ®µç²’åº¦ä¸Šé¢„æµ‹æ¯ä¸ªåŠ¨ä½œæè®®å±žäºŽåŸºç¡€åŠ¨ä½œç±»åˆ«çš„æ¦‚çŽ‡ï¼›4) ç”±ç²—åˆ°ç²¾çš„åˆ†ç±»å™¨ï¼šé¦–å…ˆåœ¨è§†é¢‘ç²’åº¦ä¸Šè¯†åˆ«åŠ¨ä½œå­˜åœ¨ï¼Œç„¶åŽåœ¨æè®®ç²’åº¦ä¸Šå°†æ¯ä¸ªåŠ¨ä½œæè®®åˆ†é…åˆ°ç²—ç±»åˆ«ã€‚è¿™äº›æ¨¡å—ååŒå·¥ä½œï¼Œå®žçŽ°å¤šç²’åº¦ç±»åˆ«æ„ŸçŸ¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šMGCA-Netçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶å¤šç²’åº¦ç±»åˆ«æ„ŸçŸ¥æœºåˆ¶ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ä»…åœ¨å•ä¸€ç²’åº¦ä¸Šè¿›è¡Œç±»åˆ«è¯†åˆ«ä¸åŒï¼ŒMGCA-NetåŒæ—¶è€ƒè™‘äº†ç²—ç²’åº¦å’Œç»†ç²’åº¦çš„ç±»åˆ«ä¿¡æ¯ã€‚é€šè¿‡ç”±ç²—åˆ°ç²¾çš„åˆ†ç±»å™¨ï¼Œæ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°è¯†åˆ«æ–°åŠ¨ä½œç±»åˆ«ï¼Œå¹¶å°†å…¶ä¸ŽåŸºç¡€åŠ¨ä½œç±»åˆ«åŒºåˆ†å¼€æ¥ã€‚è¿™ç§å¤šç²’åº¦æ„ŸçŸ¥èƒ½åŠ›æ˜¾è‘—æé«˜äº†åŠ¨ä½œå®šä½çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç”±ç²—åˆ°ç²¾çš„åˆ†ç±»å™¨ä¸­ï¼Œè§†é¢‘ç²’åº¦çš„åŠ¨ä½œå­˜åœ¨é¢„æµ‹æ¨¡å—å¯èƒ½é‡‡ç”¨å¤šç¤ºä¾‹å­¦ä¹ (MIL)æ–¹æ³•ï¼Œå°†è§†é¢‘çº§åˆ«çš„æ ‡ç­¾ä¸Žæè®®çº§åˆ«çš„ç‰¹å¾å…³è”èµ·æ¥ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡å¯èƒ½åŒ…æ‹¬åˆ†ç±»æŸå¤±ã€å®šä½æŸå¤±å’ŒåŠ¨ä½œå­˜åœ¨é¢„æµ‹æŸå¤±ï¼Œä»¥è”åˆä¼˜åŒ–å„ä¸ªæ¨¡å—çš„æ€§èƒ½ã€‚ç½‘ç»œç»“æž„å¯èƒ½é‡‡ç”¨Transformeræˆ–å·ç§¯ç¥žç»ç½‘ç»œï¼Œä»¥æå–è§†é¢‘ç‰‡æ®µçš„ç‰¹å¾ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

MGCA-Netåœ¨THUMOS'14å’ŒActivityNet-1.3æ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ–¹æ³•åœ¨å¼€æ”¾è¯æ±‡æ—¶åºåŠ¨ä½œå®šä½ä»»åŠ¡ä¸­ï¼Œæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰çš„åŸºçº¿æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒMGCA-Netåœ¨é›¶æ ·æœ¬æ—¶åºåŠ¨ä½œå®šä½è®¾ç½®ä¸‹ä¹Ÿå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æžœï¼Œè¡¨æ˜Žå…¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›å®žéªŒç»“æžœå……åˆ†è¯æ˜Žäº†MGCA-Netçš„å¤šç²’åº¦ç±»åˆ«æ„ŸçŸ¥æœºåˆ¶çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

MGCA-Netåœ¨è§†é¢‘ç›‘æŽ§ã€æ™ºèƒ½å®‰é˜²ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºŽè¯†åˆ«å’Œå®šä½è§†é¢‘ä¸­çš„å¼‚å¸¸è¡Œä¸ºã€äº¤é€šäº‹ä»¶ç­‰ï¼Œæé«˜å®‰å…¨æ€§å’Œæ•ˆçŽ‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºŽè§†é¢‘å†…å®¹åˆ†æžã€è§†é¢‘æ£€ç´¢ç­‰é¢†åŸŸï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿæ‰¾åˆ°æ„Ÿå…´è¶£çš„è§†é¢‘ç‰‡æ®µã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥æ‰©å±•åˆ°æ›´å¤æ‚çš„åœºæ™¯ï¼Œä¾‹å¦‚å¤šæ¨¡æ€è§†é¢‘åˆ†æžã€äººæœºäº¤äº’ç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Open-Vocabulary Temporal Action Localization (OV-TAL) aims to recognize and localize instances of any desired action categories in videos without explicitly curating training data for all categories. Existing methods mostly recognize action categories at a single granularity, which degrades the recognition accuracy of both base and novel action categories. To address these issues, we propose a Multi-Grained Category-Aware Network (MGCA-Net) comprising a localizer, an action presence predictor, a conventional classifier, and a coarse-to-fine classifier. Specifically, the localizer localizes category-agnostic action proposals. For these action proposals, the action presence predictor estimates the probability that they belong to an action instance. At the same time, the conventional classifier predicts the probability of each action proposal over base action categories at the snippet granularity. Novel action categories are recognized by the coarse-to-fine classifier, which first identifies action presence at the video granularity. Finally, it assigns each action proposal to one category from the coarse categories at the proposal granularity. Through coarse-to-fine category awareness for novel actions and the conventional classifier's awareness of base actions, multi-grained category awareness is achieved, effectively enhancing localization performance. Comprehensive evaluations on the THUMOS'14 and ActivityNet-1.3 benchmarks demonstrate that our method achieves state-of-the-art performance. Furthermore, our MGCA-Net achieves state-of-the-art results under the Zero-Shot Temporal Action Localization setting.

