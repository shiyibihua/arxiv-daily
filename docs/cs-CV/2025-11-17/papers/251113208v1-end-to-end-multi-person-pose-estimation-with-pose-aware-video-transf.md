---
layout: default
title: End-to-End Multi-Person Pose Estimation with Pose-Aware Video Transformer
---

# End-to-End Multi-Person Pose Estimation with Pose-Aware Video Transformer

**arXiv**: [2511.13208v1](https://arxiv.org/abs/2511.13208) | [PDF](https://arxiv.org/pdf/2511.13208.pdf)

**ä½œè€…**: Yonghui Yu, Jiahang Cai, Xun Wang, Wenwu Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPAVE-Netç«¯åˆ°ç«¯è§†é¢‘å¤šäººå§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œæ¶ˆé™¤å¯å‘å¼æ“ä½œã€‚**

**å…³é”®è¯**: `ç«¯åˆ°ç«¯å§¿æ€ä¼°è®¡` `è§†é¢‘å§¿æ€ä¼°è®¡` `æ—¶ç©ºæ³¨æ„åŠ›` `å¤šäººå§¿æ€ä¼°è®¡` `å§¿æ€æ„ŸçŸ¥ç½‘ç»œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–æ£€æµ‹å’ŒNMSç­‰å¯å‘å¼æ“ä½œï¼Œé™åˆ¶ç²¾åº¦å’Œæ•ˆçŽ‡ã€‚
2. å¼•å…¥PAVE-Netï¼Œç»“åˆç©ºé—´ç¼–ç å™¨å’Œæ—¶ç©ºå§¿æ€è§£ç å™¨ï¼Œå®žçŽ°è·¨å¸§å…³è”ã€‚
3. åœ¨PoseTrack2017ä¸ŠmAPæå‡6.0ï¼Œç²¾åº¦ä¸Žå…ˆè¿›æ–¹æ³•ç›¸å½“ï¼Œæ•ˆçŽ‡æ˜¾è‘—æé«˜ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Existing multi-person video pose estimation methods typically adopt a two-stage pipeline: detecting individuals in each frame, followed by temporal modeling for single-person pose estimation. This design relies on heuristic operations such as detection, RoI cropping, and non-maximum suppression (NMS), limiting both accuracy and efficiency. In this paper, we present a fully end-to-end framework for multi-person 2D pose estimation in videos, effectively eliminating heuristic operations. A key challenge is to associate individuals across frames under complex and overlapping temporal trajectories. To address this, we introduce a novel Pose-Aware Video transformEr Network (PAVE-Net), which features a spatial encoder to model intra-frame relations and a spatiotemporal pose decoder to capture global dependencies across frames. To achieve accurate temporal association, we propose a pose-aware attention mechanism that enables each pose query to selectively aggregate features corresponding to the same individual across consecutive frames.Additionally, we explicitly model spatiotemporal dependencies among pose keypoints to improve accuracy. Notably, our approach is the first end-to-end method for multi-frame 2D human pose estimation.Extensive experiments show that PAVE-Net substantially outperforms prior image-based end-to-end methods, achieving a \textbf{6.0} mAP improvement on PoseTrack2017, and delivers accuracy competitive with state-of-the-art two-stage video-based approaches, while offering significant gains in efficiency.Project page: https://github.com/zgspose/PAVENet

