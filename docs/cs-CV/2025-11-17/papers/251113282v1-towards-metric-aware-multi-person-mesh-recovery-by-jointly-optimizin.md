---
layout: default
title: Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space
---

# Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space

**arXiv**: [2511.13282v1](https://arxiv.org/abs/2511.13282) | [PDF](https://arxiv.org/pdf/2511.13282.pdf)

**ä½œè€…**: Kaiwen Wang, Kaili Zheng, Yiming Shi, Chenyi Guo, Ji Wu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDTOå’ŒMetric-Aware HMRä»¥è§£å†³å¤šäººç½‘æ ¼æ¢å¤ä¸­çš„åœºæ™¯ä¸€è‡´æ€§å’Œåº¦é‡å°ºåº¦é—®é¢˜**

**å…³é”®è¯**: `å¤šäººç½‘æ ¼æ¢å¤` `åœºæ™¯ä¸€è‡´æ€§ä¼˜åŒ–` `åº¦é‡å°ºåº¦ä¼°è®¡` `æ·±åº¦æ¡ä»¶ä¼˜åŒ–` `ä¼ªçœŸå€¼æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå•ä¸­å¿ƒä¼ªçœŸå€¼ç”Ÿæˆå¯¼è‡´å¤šäººåœºæ™¯æ·±åº¦å’Œå°ºåº¦ä¸ä¸€è‡´
2. æ–¹æ³•è¦ç‚¹ï¼šDTOè”åˆä¼˜åŒ–ç›¸æœºç©ºé—´å¹³ç§»ï¼ŒMetric-Aware HMRç›´æŽ¥ä¼°è®¡åº¦é‡å°ºåº¦ç½‘æ ¼
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ç›¸å¯¹æ·±åº¦æŽ¨ç†å’Œç½‘æ ¼æ¢å¤ä¸Šè¾¾åˆ°å…ˆè¿›æ°´å¹³ï¼Œæž„å»ºDTO-Humansæ•°æ®é›†

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-person human mesh recovery from a single image is a challenging task, hindered by the scarcity of in-the-wild training data. Prevailing in-the-wild human mesh pseudo-ground-truth (pGT) generation pipelines are single-person-centric, where each human is processed individually without joint optimization. This oversight leads to a lack of scene-level consistency, producing individuals with conflicting depths and scales within the same image. To address this, we introduce Depth-conditioned Translation Optimization (DTO), a novel optimization-based method that jointly refines the camera-space translations of all individuals in a crowd. By leveraging anthropometric priors on human height and depth cues from a monocular depth estimator, DTO solves for a scene-consistent placement of all subjects within a principled Maximum a posteriori (MAP) framework. Applying DTO to the 4D-Humans dataset, we construct DTO-Humans, a new large-scale pGT dataset of 0.56M high-quality, scene-consistent multi-person images, featuring dense crowds with an average of 4.8 persons per image. Furthermore, we propose Metric-Aware HMR, an end-to-end network that directly estimates human mesh and camera parameters in metric scale. This is enabled by a camera branch and a novel relative metric loss that enforces plausible relative scales. Extensive experiments demonstrate that our method achieves state-of-the-art performance on relative depth reasoning and human mesh recovery. Code and data will be released publicly.

