---
layout: default
title: Medal S: Spatio-Textual Prompt Model for Medical Segmentation
---

# Medal S: Spatio-Textual Prompt Model for Medical Segmentation

**arXiv**: [2511.13001v1](https://arxiv.org/abs/2511.13001) | [PDF](https://arxiv.org/pdf/2511.13001.pdf)

**ä½œè€…**: Pengcheng Shi, Jiawei Chen, Jiaqi Liu, Xinglin Zhang, Tao Chen, Lei Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMedal SåŒ»å­¦åˆ†å‰²åŸºç¡€æ¨¡åž‹ï¼Œæ”¯æŒç©ºé—´å’Œæ–‡æœ¬æç¤ºä»¥æå‡å¤šç±»åˆ†å‰²æ•ˆçŽ‡ä¸Žç²¾åº¦**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒåˆ†å‰²` `ç©ºé—´æ–‡æœ¬æç¤º` `å¤šæ¨¡æ€å¤„ç†` `å¹¶è¡ŒæŽ¨ç†` `3Då·ç§¯ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–‡æœ¬æç¤ºæ–¹æ³•ç¼ºä¹ç©ºé—´æ„ŸçŸ¥ï¼Œå¯¼è‡´åˆ†è¾¨çŽ‡ä¸åŒ¹é…å’Œåˆ†å‰²ä¸å‡†ç¡®
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡é€šé“å¯¹é½å’Œè½»é‡3Då·ç§¯æ¨¡å—ï¼Œå®žçŽ°ç«¯åˆ°ç«¯ç©ºé—´ä¸Žæ–‡æœ¬æç¤ºå¹¶è¡Œå¤„ç†
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨äº”æ¨¡æ€éªŒè¯é›†ä¸Šï¼ŒDSCè¾¾75.44ï¼ŒæŽ¨ç†æ—¶é—´å‡å°‘è¶…90%ï¼Œä¼˜äºŽSATå’ŒnnU-Net

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce Medal S, a medical segmentation foundation model that supports native-resolution spatial and textual prompts within an end-to-end trainable framework. Unlike text-only methods lacking spatial awareness, Medal S achieves channel-wise alignment between volumetric prompts and text embeddings, mitigating inaccuracies from resolution mismatches. By preserving full 3D context, it efficiently processes multiple native-resolution masks in parallel, enhancing multi-class segmentation performance. A lightweight 3D convolutional module enables precise voxel-space refinement guided by both prompt types, supporting up to 243 classes across CT, MRI, PET, ultrasound, and microscopy modalities in the BiomedSegFM dataset. Medal S offers two prompting modes: a text-only mode, where model predictions serve as spatial prompts for self-refinement without human input, and a hybrid mode, incorporating manual annotations for enhanced flexibility. For 24-class segmentation, parallel spatial prompting reduces inference time by more than 90% compared to sequential prompting. We propose dynamic resampling to address target-patch ratio imbalance, extending SAT and nnU-Net for data augmentation. Furthermore, we develop optimized text preprocessing, a two-stage inference strategy, and post-processing techniques to improve memory efficiency, precision, and inference speed. On the five-modality average on the validation set, Medal S outperforms SAT with a DSC of 75.44 (vs. 69.83), NSD of 77.34 (vs. 71.06), F1 of 38.24 (vs. 24.88), and DSC TP of 65.46 (vs. 46.97). Medal S achieves excellent performance by harmonizing spatial precision with semantic textual guidance, demonstrating superior efficiency and accuracy in multi-class medical segmentation tasks compared to sequential prompt-based approaches. Medal S will be publicly available at https://github.com/yinghemedical/Medal-S.

