---
layout: default
title: DriveLiDAR4D: Sequential and Controllable LiDAR Scene Generation for Autonomous Driving
---

# DriveLiDAR4D: Sequential and Controllable LiDAR Scene Generation for Autonomous Driving

**arXiv**: [2511.13309v1](https://arxiv.org/abs/2511.13309) | [PDF](https://arxiv.org/pdf/2511.13309.pdf)

**ä½œè€…**: Kaiwen Cai, Xinze Liu, Xia Zhou, Hengtong Hu, Jie Xiang, Luyao Zhang, Xueyang Zhang, Kun Zhan, Yifei Zhan, Xianpeng Lang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDriveLiDAR4Dä»¥è§£å†³è‡ªåŠ¨é©¾é©¶ä¸­LiDARåœºæ™¯åºåˆ—ç”Ÿæˆä¸Žå¯æŽ§æ€§é—®é¢˜**

**å…³é”®è¯**: `LiDARç‚¹äº‘ç”Ÿæˆ` `è‡ªåŠ¨é©¾é©¶ä»¿çœŸ` `åºåˆ—ç”Ÿæˆ` `å¯æŽ§åœºæ™¯ç”Ÿæˆ` `å¤šæ¨¡æ€æ¡ä»¶` `å™ªå£°é¢„æµ‹æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰LiDARç‚¹äº‘ç”Ÿæˆæ–¹æ³•ç¼ºä¹åºåˆ—ç”Ÿæˆèƒ½åŠ›ï¼Œä¸”å‰æ™¯å¯¹è±¡å®šä½å’ŒèƒŒæ™¯çœŸå®žæ€§ä¸è¶³
2. é‡‡ç”¨å¤šæ¨¡æ€æ¡ä»¶å’ŒLiDAR4DNetæ¨¡åž‹ï¼Œå®žçŽ°ç«¯åˆ°ç«¯å¯æŽ§åºåˆ—ç”Ÿæˆ
3. åœ¨nuScenesæ•°æ®é›†ä¸ŠFRDå’ŒFVDåˆ†æ•°è¶…è¶ŠSOTAæ–¹æ³•ï¼Œæ€§èƒ½æå‡æ˜¾è‘—

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The generation of realistic LiDAR point clouds plays a crucial role in the development and evaluation of autonomous driving systems. Although recent methods for 3D LiDAR point cloud generation have shown significant improvements, they still face notable limitations, including the lack of sequential generation capabilities and the inability to produce accurately positioned foreground objects and realistic backgrounds. These shortcomings hinder their practical applicability. In this paper, we introduce DriveLiDAR4D, a novel LiDAR generation pipeline consisting of multimodal conditions and a novel sequential noise prediction model LiDAR4DNet, capable of producing temporally consistent LiDAR scenes with highly controllable foreground objects and realistic backgrounds. To the best of our knowledge, this is the first work to address the sequential generation of LiDAR scenes with full scene manipulation capability in an end-to-end manner. We evaluated DriveLiDAR4D on the nuScenes and KITTI datasets, where we achieved an FRD score of 743.13 and an FVD score of 16.96 on the nuScenes dataset, surpassing the current state-of-the-art (SOTA) method, UniScene, with an performance boost of 37.2% in FRD and 24.1% in FVD, respectively.

