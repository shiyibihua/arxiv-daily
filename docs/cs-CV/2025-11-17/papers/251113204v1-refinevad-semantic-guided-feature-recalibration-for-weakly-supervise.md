---
layout: default
title: RefineVAD: Semantic-Guided Feature Recalibration for Weakly Supervised Video Anomaly Detection
---

# RefineVAD: Semantic-Guided Feature Recalibration for Weakly Supervised Video Anomaly Detection

**arXiv**: [2511.13204v1](https://arxiv.org/abs/2511.13204) | [PDF](https://arxiv.org/pdf/2511.13204.pdf)

**ä½œè€…**: Junhee Lee, ChaeBeen Bang, MyoungChul Kim, MyeongAh Cho

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRefineVADæ¡†æž¶ï¼Œé€šè¿‡è¯­ä¹‰å¼•å¯¼ç‰¹å¾é‡æ ¡å‡†è§£å†³å¼±ç›‘ç£è§†é¢‘å¼‚å¸¸æ£€æµ‹ä¸­å¼‚å¸¸å¤šæ ·æ€§å»ºæ¨¡ä¸è¶³é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¼±ç›‘ç£è§†é¢‘å¼‚å¸¸æ£€æµ‹` `è¯­ä¹‰å¼•å¯¼ç‰¹å¾é‡æ ¡å‡†` `æ—¶åºæ³¨æ„åŠ›æœºåˆ¶` `ç±»åˆ«åŽŸåž‹å¯¹é½` `Transformerå»ºæ¨¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•å°†å¼‚å¸¸è§†ä¸ºå•ä¸€ç±»åˆ«ï¼Œå¿½ç•¥å…¶è¯­ä¹‰å’Œæ—¶åºå¤šæ ·æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆMoTARæ¨¡å—åŠ¨æ€è°ƒæ•´æ—¶åºç„¦ç‚¹ï¼ŒCOREæ¨¡å—æ³¨å…¥ç±»åˆ«å…ˆéªŒå¯¹é½ç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨WVADåŸºå‡†ä¸ŠéªŒè¯æœ‰æ•ˆæ€§ï¼Œå¼ºè°ƒè¯­ä¹‰ä¸Šä¸‹æ–‡å¯¹å¼‚å¸¸æ¨¡å¼å¼•å¯¼çš„é‡è¦æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Weakly-Supervised Video Anomaly Detection aims to identify anomalous events using only video-level labels, balancing annotation efficiency with practical applicability. However, existing methods often oversimplify the anomaly space by treating all abnormal events as a single category, overlooking the diverse semantic and temporal characteristics intrinsic to real-world anomalies. Inspired by how humans perceive anomalies, by jointly interpreting temporal motion patterns and semantic structures underlying different anomaly types, we propose RefineVAD, a novel framework that mimics this dual-process reasoning. Our framework integrates two core modules. The first, Motion-aware Temporal Attention and Recalibration (MoTAR), estimates motion salience and dynamically adjusts temporal focus via shift-based attention and global Transformer-based modeling. The second, Category-Oriented Refinement (CORE), injects soft anomaly category priors into the representation space by aligning segment-level features with learnable category prototypes through cross-attention. By jointly leveraging temporal dynamics and semantic structure, explicitly models both "how" motion evolves and "what" semantic category it resembles. Extensive experiments on WVAD benchmark validate the effectiveness of RefineVAD and highlight the importance of integrating semantic context to guide feature refinement toward anomaly-relevant patterns.

