---
layout: default
title: CloseUpShot: Close-up Novel View Synthesis from Sparse-views via Point-conditioned Diffusion Model
---

# CloseUpShot: Close-up Novel View Synthesis from Sparse-views via Point-conditioned Diffusion Model

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.13121" target="_blank" class="toolbar-btn">arXiv: 2511.13121v1</a>
    <a href="https://arxiv.org/pdf/2511.13121.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.13121v1" 
            onclick="toggleFavorite(this, '2511.13121v1', 'CloseUpShot: Close-up Novel View Synthesis from Sparse-views via Point-conditioned Diffusion Model')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yuqi Zhang, Guanying Chen, Jiaxing Chen, Chuanyu Fu, Chuan Huang, Shuguang Cui

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-17

**Â§áÊ≥®**: Project Link: https://zyqz97.github.io/CloseUpShot/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫CloseUpShotÔºåÈÄöËøáÁÇπ‰∫ëÊù°‰ª∂Êâ©Êï£Ê®°ÂûãÂÆûÁé∞Á®ÄÁñèËßÜËßí‰∏ãÁöÑËøëË∑ùÁ¶ªÊñ∞ËßÜËßíÂêàÊàê**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Êñ∞ËßÜËßíÂêàÊàê` `Êâ©Êï£Ê®°Âûã` `‰∏âÁª¥ÈáçÂª∫` `ÁÇπ‰∫ë` `ËøëË∑ùÁ¶ªÂú∫ÊôØ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Á®ÄÁñèËßÜËßí‰∏ãËøõË°å3DÈáçÂª∫ÂíåÊñ∞ËßÜËßíÂêàÊàêÊó∂ÔºåÈöæ‰ª•ÊçïÊçâËøëË∑ùÁ¶ªÂú∫ÊôØ‰∏≠ÁöÑÁ≤æÁªÜÁªÜËäÇÔºåÈù¢‰∏¥‰ø°ÊÅØ‰∏•ÈáçÂèóÈôêÁöÑÊåëÊàò„ÄÇ
2. CloseUpShotÈÄöËøáÁÇπ‰∫ëÊù°‰ª∂ËßÜÈ¢ëÊâ©Êï£ÔºåÂà©Áî®ÂàÜÂ±ÇÊâ≠Êõ≤„ÄÅÈÅÆÊå°ÊÑüÁü•Âô™Â£∞ÊäëÂà∂ÂíåÂÖ®Â±ÄÁªìÊûÑÂºïÂØºÔºåÊèêÂçáËøëË∑ùÁ¶ªÊñ∞ËßÜËßíÂêàÊàêÁöÑË¥®Èáè„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCloseUpShotÂú®ËøëË∑ùÁ¶ªÊñ∞ËßÜËßíÂêàÊàê‰ªªÂä°‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÈ™åËØÅ‰∫ÜÊâÄÊèêÂá∫ËÆæËÆ°ÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫CloseUpShotÁöÑÂü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫é‰ªéÁ®ÄÁñèËæìÂÖ•ËßÜËßíÂêàÊàêËøëË∑ùÁ¶ªÁöÑÊñ∞ËßÜËßí„ÄÇÈíàÂØπËøëË∑ùÁ¶ªÂú∫ÊôØ‰∏ãÂÉèÁ¥†Êâ≠Êõ≤Êù°‰ª∂ÂåñÂ≠òÂú®ÁöÑÁ®ÄÁñèÊÄßÂíåËÉåÊôØÊ≥ÑÈú≤ÈóÆÈ¢òÔºåÊèêÂá∫‰∫ÜÂàÜÂ±ÇÊâ≠Êõ≤ÂíåÈÅÆÊå°ÊÑüÁü•Âô™Â£∞ÊäëÂà∂Ôºå‰ª•ÊèêÈ´òËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÊù°‰ª∂ÂåñÂõæÂÉèÁöÑË¥®ÈáèÂíåÂÆåÊï¥ÊÄß„ÄÇÊ≠§Â§ñÔºåÂºïÂÖ•ÂÖ®Â±ÄÁªìÊûÑÂºïÂØºÔºåÂà©Áî®ÂØÜÈõÜËûçÂêàÁÇπ‰∫ë‰∏∫Êâ©Êï£ËøáÁ®ãÊèê‰æõ‰∏ÄËá¥ÁöÑÂá†‰Ωï‰∏ä‰∏ãÊñáÔºå‰ª•Âº•Ë°•Á®ÄÁñèÊù°‰ª∂ÂåñËæìÂÖ•‰∏≠Áº∫‰πèÂÖ®Â±Ä‰∏ÄËá¥ÁöÑ3DÁ∫¶Êùü„ÄÇÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ï‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÂú®ËøëË∑ùÁ¶ªÊñ∞ËßÜËßíÂêàÊàêÊñπÈù¢ÔºåÈ™åËØÅ‰∫ÜËÆæËÆ°ÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰ªéÁ®ÄÁñèËßÜËßíËæìÂÖ•ÈáçÂª∫3DÂú∫ÊôØÂπ∂ÂêàÊàêÊñ∞ËßÜËßíÁöÑÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÂÖ≥Ê≥®ËøëË∑ùÁ¶ªÂú∫ÊôØ„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜËøëË∑ùÁ¶ªÂú∫ÊôØÊó∂ÔºåÁî±‰∫éËæìÂÖ•‰ø°ÊÅØÊûÅÂ∫¶ÊúâÈôêÔºåÈöæ‰ª•ÊçïÊçâÂà∞Á≤æÁªÜÁöÑÁªÜËäÇÔºåÂØºËá¥ÈáçÂª∫Ë¥®Èáè‰∏ãÈôç„ÄÇÂÉèÁ¥†Êâ≠Êõ≤Êù°‰ª∂ÂåñÊñπÊ≥ïÂú®ËøëË∑ùÁ¶ªÂú∫ÊôØ‰∏ã‰ºöÈù¢‰∏¥‰∏•ÈáçÁöÑÁ®ÄÁñèÊÄßÂíåËÉåÊôØÊ≥ÑÈú≤ÈóÆÈ¢òÔºåËøõ‰∏ÄÊ≠•Âä†Ââß‰∫ÜËøô‰∏ÄÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÂº∫Â§ßÁöÑÊó∂Â∫èÊé®ÁêÜËÉΩÂäõÔºåÂπ∂ÁªìÂêàÁÇπ‰∫ëÊèê‰æõÁöÑÂá†‰Ωï‰ø°ÊÅØÔºåÊù•ÊèêÂçáÁ®ÄÁñèËßÜËßí‰∏ãÁöÑËøëË∑ùÁ¶ªÊñ∞ËßÜËßíÂêàÊàêË¥®Èáè„ÄÇÈÄöËøáÊîπËøõÊù°‰ª∂ÂåñÊñπÂºèÔºåÂáèÂ∞ëÁ®ÄÁñèÊÄßÂíåËÉåÊôØÊ≥ÑÈú≤ÔºåÂπ∂ÂºïÂÖ•ÂÖ®Â±ÄÁªìÊûÑÂºïÂØºÔºåÂº•Ë°•3DÁ∫¶ÊùüÁöÑ‰∏çË∂≥„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCloseUpShotÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) ÂàÜÂ±ÇÊâ≠Êõ≤ÂíåÈÅÆÊå°ÊÑüÁü•Âô™Â£∞ÊäëÂà∂Ê®°ÂùóÔºåÁî®‰∫éÁîüÊàêÈ´òË¥®ÈáèÁöÑÊù°‰ª∂ÂåñÂõæÂÉèÔºõ2) ÂÖ®Â±ÄÁªìÊûÑÂºïÂØºÊ®°ÂùóÔºåÂà©Áî®ÂØÜÈõÜËûçÂêàÁÇπ‰∫ëÊèê‰æõÂá†‰Ωï‰∏ä‰∏ãÊñáÔºõ3) Âü∫‰∫éËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÁöÑÁîüÊàêÊ®°ÂùóÔºåÊ†πÊçÆÊù°‰ª∂ÂåñÂõæÂÉèÂíåÂá†‰Ωï‰∏ä‰∏ãÊñáÁîüÊàêÊñ∞ËßÜËßíÂõæÂÉè„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÂÖàÂØπËæìÂÖ•ÂõæÂÉèËøõË°åÈ¢ÑÂ§ÑÁêÜÔºåÁÑ∂ÂêéÈÄöËøáÂàÜÂ±ÇÊâ≠Êõ≤ÂíåÂô™Â£∞ÊäëÂà∂ÁîüÊàêÊù°‰ª∂ÂåñÂõæÂÉèÔºåÂêåÊó∂ÊûÑÂª∫ÂÖ®Â±ÄÁÇπ‰∫ëÔºåÊúÄÂêéÂ∞ÜÊù°‰ª∂ÂåñÂõæÂÉèÂíåÁÇπ‰∫ë‰ø°ÊÅØËæìÂÖ•Âà∞ËßÜÈ¢ëÊâ©Êï£Ê®°Âûã‰∏≠ËøõË°åÊñ∞ËßÜËßíÂêàÊàê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫ÜÂàÜÂ±ÇÊâ≠Êõ≤ÂíåÈÅÆÊå°ÊÑüÁü•Âô™Â£∞ÊäëÂà∂ÊñπÊ≥ïÔºåÊúâÊïàÁºìËß£‰∫ÜËøëË∑ùÁ¶ªÂú∫ÊôØ‰∏ãÂÉèÁ¥†Êâ≠Êõ≤Êù°‰ª∂ÂåñÁöÑÁ®ÄÁñèÊÄßÂíåËÉåÊôØÊ≥ÑÈú≤ÈóÆÈ¢òÔºõ2) ÂºïÂÖ•‰∫ÜÂÖ®Â±ÄÁªìÊûÑÂºïÂØºÔºåÂà©Áî®ÁÇπ‰∫ëÊèê‰æõÂÖ®Â±Ä‰∏ÄËá¥ÁöÑÂá†‰ΩïÁ∫¶ÊùüÔºåÂº•Ë°•‰∫ÜÁ®ÄÁñèËßÜËßí‰∏ã3D‰ø°ÊÅØ‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂàÜÂ±ÇÊâ≠Êõ≤ÁöÑÂÖ∑‰ΩìÂÆûÁé∞ÊñπÂºèÊú™Áü•„ÄÇÈÅÆÊå°ÊÑüÁü•Âô™Â£∞ÊäëÂà∂ÂèØËÉΩÈÄöËøáÂ≠¶‰π†‰∏Ä‰∏™maskÊù•Âå∫ÂàÜÂâçÊôØÂíåËÉåÊôØÔºå‰ªéËÄåÊäëÂà∂ËÉåÊôØÂô™Â£∞„ÄÇÂÖ®Â±ÄÁªìÊûÑÂºïÂØºÂèØËÉΩÈÄöËøáÂ∞ÜÁÇπ‰∫ëÁâπÂæÅ‰∏éÂõæÂÉèÁâπÂæÅËøõË°åËûçÂêàÔºåÊàñËÄÖÁõ¥Êé•Â∞ÜÁÇπ‰∫ë‰Ωú‰∏∫Êâ©Êï£Ê®°ÂûãÁöÑËæìÂÖ•„ÄÇËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÂèØËÉΩÈááÁî®U-NetÁªìÊûÑÔºåÂπ∂‰ΩøÁî®ÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞ËøõË°åËÆ≠ÁªÉÔºå‰æãÂ¶ÇL1ÊçüÂ§±ÊàñÊÑüÁü•ÊçüÂ§±„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCloseUpShotÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏ä‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÂú®ËøëË∑ùÁ¶ªÊñ∞ËßÜËßíÂêàÊàêÊñπÈù¢Ë°®Áé∞Á™ÅÂá∫„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊèêÂçáÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜËÆ∫ÊñáÂº∫Ë∞ÉËØ•ÊñπÊ≥ïÂú®Â§ÑÁêÜËøëË∑ùÁ¶ªÂú∫ÊôØÊó∂ÔºåËÉΩÂ§üÁîüÊàêÊõ¥Ê∏ÖÊô∞„ÄÅÊõ¥ÂÆåÊï¥ÁöÑÂõæÂÉèÔºåÊúâÊïàÁºìËß£‰∫ÜÁ®ÄÁñèÊÄßÂíåËÉåÊôØÊ≥ÑÈú≤ÈóÆÈ¢òÔºåÈ™åËØÅ‰∫ÜÊâÄÊèêÂá∫ËÆæËÆ°ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂ¢ûÂº∫Áé∞ÂÆû„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅ‰∏âÁª¥ÈáçÂª∫„ÄÅÊ∏∏ÊàèÂºÄÂèëÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®AR/VRÂ∫îÁî®‰∏≠ÔºåÂèØ‰ª•Âà©Áî®Â∞ëÈáèÂõæÂÉèÂø´ÈÄüÁîüÊàêÈ´òË¥®ÈáèÁöÑËøëË∑ùÁ¶ªÂú∫ÊôØÊñ∞ËßÜËßíÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™å„ÄÇÂú®Êú∫Âô®‰∫∫ÂØºËà™‰∏≠ÔºåÂèØ‰ª•Âà©Áî®Á®ÄÁñèÁöÑËßÜËßâ‰ø°ÊÅØÈáçÂª∫Âë®Âõ¥ÁéØÂ¢ÉÔºåËæÖÂä©Êú∫Âô®‰∫∫ËøõË°åË∑ØÂæÑËßÑÂàíÂíåÈÅøÈöú„ÄÇÊ≠§Â§ñÔºåËØ•ÊäÄÊúØËøòÂèØÁî®‰∫éÊñáÁâ©‰øùÊä§ÔºåÈÄöËøáÂ∞ëÈáèÁÖßÁâáÈáçÂª∫ÊñáÁâ©ÁöÑ‰∏âÁª¥Ê®°Âûã„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Reconstructing 3D scenes and synthesizing novel views from sparse input views is a highly challenging task. Recent advances in video diffusion models have demonstrated strong temporal reasoning capabilities, making them a promising tool for enhancing reconstruction quality under sparse-view settings. However, existing approaches are primarily designed for modest viewpoint variations, which struggle in capturing fine-grained details in close-up scenarios since input information is severely limited. In this paper, we present a diffusion-based framework, called CloseUpShot, for close-up novel view synthesis from sparse inputs via point-conditioned video diffusion. Specifically, we observe that pixel-warping conditioning suffers from severe sparsity and background leakage in close-up settings. To address this, we propose hierarchical warping and occlusion-aware noise suppression, enhancing the quality and completeness of the conditioning images for the video diffusion model. Furthermore, we introduce global structure guidance, which leverages a dense fused point cloud to provide consistent geometric context to the diffusion process, to compensate for the lack of globally consistent 3D constraints in sparse conditioning inputs. Extensive experiments on multiple datasets demonstrate that our method outperforms existing approaches, especially in close-up novel view synthesis, clearly validating the effectiveness of our design.

