---
layout: default
title: Start Small, Think Big: Curriculum-based Relative Policy Optimization for Visual Grounding
---

# Start Small, Think Big: Curriculum-based Relative Policy Optimization for Visual Grounding

**arXiv**: [2511.13924v1](https://arxiv.org/abs/2511.13924) | [PDF](https://arxiv.org/pdf/2511.13924.pdf)

**ä½œè€…**: Qingyang Yan, Guangyao Chen, Yixiong Zou

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-17

**å¤‡æ³¨**: AAAI 2026 (Oral)

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/qyoung-yan/CuRPO)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè¯¾ç¨‹å­¦ä¹ çš„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–CuRPOï¼Œæå‡è§†è§‰å®šä½ä»»åŠ¡ä¸­CoTæŽ¨ç†çš„æ€§èƒ½ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è§†è§‰å®šä½` `Chain-of-Thought` `è¯¾ç¨‹å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŸºäºŽå¼ºåŒ–å­¦ä¹ å¾®è°ƒçš„CoTæŽ¨ç†åœ¨è§†è§‰å®šä½ä»»åŠ¡ä¸­è¡¨çŽ°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚æˆ–å†—é•¿çš„CoTè¾“å‡ºæ—¶ã€‚
2. æå‡ºCuRPOï¼Œåˆ©ç”¨CoTé•¿åº¦å’ŒgIoUå¥–åŠ±ä½œä¸ºå¤æ‚åº¦æŒ‡æ ‡ï¼Œé€šè¿‡è¯¾ç¨‹å­¦ä¹ çš„æ–¹å¼ï¼Œç”±ç®€å…¥éš¾åœ°ç»„ç»‡è®­ç»ƒæ•°æ®ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCuRPOåœ¨å¤šä¸ªè§†è§‰å®šä½æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨å°‘æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸‹è¡¨çŽ°å‡ºè‰²ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡å‘çŽ°ï¼ŒåŸºäºŽå¼ºåŒ–å­¦ä¹ å¾®è°ƒçš„CoTæŽ¨ç†åœ¨è§†è§‰å®šä½ä»»åŠ¡ä¸­ï¼Œå°¤å…¶æ˜¯åœ¨CoTè¾“å‡ºå†—é•¿æˆ–å¤æ‚æ—¶ï¼Œåè€Œä¼šé™ä½Žæ€§èƒ½ã€‚æ­¤å¤–ï¼Œç”±äºŽæ•°æ®å¤æ‚åº¦çš„å·®å¼‚ï¼Œå¢žåŠ æ•°æ®é›†å¤§å°å¹¶ä¸æ€»èƒ½æé«˜æ€§èƒ½ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒç­–ç•¥â€”â€”åŸºäºŽè¯¾ç¨‹å­¦ä¹ çš„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆCuRPOï¼‰ã€‚CuRPOåˆ©ç”¨CoTé•¿åº¦å’Œå¹¿ä¹‰äº¤å¹¶æ¯”ï¼ˆgIoUï¼‰å¥–åŠ±ä½œä¸ºå¤æ‚åº¦æŒ‡æ ‡ï¼Œé€æ­¥æž„å»ºè®­ç»ƒæ•°æ®ï¼Œä»Žç®€å•åˆ°æ›´å…·æŒ‘æˆ˜æ€§çš„ç¤ºä¾‹ã€‚åœ¨RefCOCOã€RefCOCO+ã€RefCOCOgå’ŒLISAæ•°æ®é›†ä¸Šçš„å¤§é‡å®žéªŒè¡¨æ˜Žäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚CuRPOå§‹ç»ˆä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼ŒåŒ…æ‹¬Visual-RFTï¼Œåœ¨RefCOCOä¸Šå®žçŽ°äº†é«˜è¾¾+12.52 mAPçš„æ˜¾è‘—æ”¹è¿›ã€‚æ­¤å¤–ï¼ŒCuRPOè¡¨çŽ°å‡ºå“è¶Šçš„æ•ˆçŽ‡å’Œé²æ£’æ€§ï¼Œå³ä½¿åœ¨å°‘æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸­ä¹Ÿèƒ½æä¾›å¼ºå¤§çš„å®šä½æ€§èƒ½ï¼Œå°¤å…¶æœ‰åˆ©äºŽä»¥æ¨¡ç³Šå’Œå¤æ‚çš„æ–‡æœ¬æè¿°ä¸ºç‰¹å¾çš„ä»»åŠ¡ã€‚ä»£ç å·²å¼€æºã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†è§‰å®šä½ä»»åŠ¡æ—¨åœ¨æ ¹æ®ç»™å®šçš„æ–‡æœ¬æè¿°ï¼Œåœ¨å›¾åƒä¸­å®šä½åˆ°å¯¹åº”çš„ç›®æ ‡åŒºåŸŸã€‚çŽ°æœ‰çš„åŸºäºŽChain-of-Thought (CoT) çš„æ–¹æ³•è™½ç„¶åœ¨å¾ˆå¤šä»»åŠ¡ä¸Šè¡¨çŽ°å‡ºè‰²ï¼Œä½†åœ¨è§†è§‰å®šä½ä»»åŠ¡ä¸­ï¼Œç›´æŽ¥ä½¿ç”¨å¼ºåŒ–å­¦ä¹ å¾®è°ƒCoTæŽ¨ç†åè€Œå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œå°¤å…¶æ˜¯åœ¨CoTè¾“å‡ºå˜å¾—å¤æ‚æˆ–å†—é•¿æ—¶ã€‚æ­¤å¤–ï¼Œç®€å•åœ°å¢žåŠ æ•°æ®é›†å¤§å°å¹¶ä¸ä¸€å®šèƒ½æå‡æ€§èƒ½ï¼Œå› ä¸ºæ•°æ®é›†ä¸­çš„æ ·æœ¬å¤æ‚åº¦å„ä¸ç›¸åŒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCuRPOçš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨è¯¾ç¨‹å­¦ä¹ çš„æ–¹å¼ï¼Œé€æ­¥å¼•å…¥æ›´å¤æ‚çš„è®­ç»ƒæ ·æœ¬ï¼Œä»Žè€Œé¿å…æ¨¡åž‹åœ¨è®­ç»ƒåˆæœŸå°±è¢«è¿‡äºŽå¤æ‚çš„CoTæŽ¨ç†è¿‡ç¨‹æ‰€å›°æ‰°ã€‚é€šè¿‡å°†CoTé•¿åº¦å’ŒgIoUå¥–åŠ±ä½œä¸ºå¤æ‚åº¦æŒ‡æ ‡ï¼ŒCuRPOèƒ½å¤Ÿæœ‰æ•ˆåœ°ç»„ç»‡è®­ç»ƒæ•°æ®ï¼Œä»Žç®€å•åˆ°å¤æ‚åœ°è¿›è¡Œå­¦ä¹ ã€‚è¿™ç§ç”±ç®€å…¥éš¾çš„å­¦ä¹ æ–¹å¼æœ‰åŠ©äºŽæ¨¡åž‹æ›´å¥½åœ°ç†è§£æ–‡æœ¬æè¿°å’Œå›¾åƒä¹‹é—´çš„å…³ç³»ï¼Œä»Žè€Œæé«˜å®šä½ç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šCuRPOçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) CoTæŽ¨ç†æ¨¡å—ï¼šç”¨äºŽç”Ÿæˆä¸­é—´æŽ¨ç†æ­¥éª¤ï¼›2) ç­–ç•¥ä¼˜åŒ–æ¨¡å—ï¼šä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¼˜åŒ–CoTæŽ¨ç†ç­–ç•¥ï¼›3) è¯¾ç¨‹å­¦ä¹ æ¨¡å—ï¼šæ ¹æ®CoTé•¿åº¦å’ŒgIoUå¥–åŠ±åŠ¨æ€è°ƒæ•´è®­ç»ƒæ•°æ®çš„éš¾åº¦ã€‚è®­ç»ƒè¿‡ç¨‹é¦–å…ˆä»Žç®€å•çš„æ ·æœ¬å¼€å§‹ï¼Œéšç€è®­ç»ƒçš„è¿›è¡Œï¼Œé€æ­¥å¼•å…¥æ›´å¤æ‚çš„æ ·æœ¬ã€‚åœ¨æ¯ä¸ªè®­ç»ƒè¿­ä»£ä¸­ï¼Œæ¨¡åž‹æ ¹æ®å½“å‰çš„ç­–ç•¥ç”ŸæˆCoTæŽ¨ç†è¿‡ç¨‹ï¼Œå¹¶æ ¹æ®gIoUå¥–åŠ±æ›´æ–°ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šCuRPOæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå°†è¯¾ç¨‹å­¦ä¹ ä¸Žç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ç›¸ç»“åˆï¼Œä»Žè€Œæœ‰æ•ˆåœ°è§£å†³äº†CoTæŽ¨ç†åœ¨è§†è§‰å®šä½ä»»åŠ¡ä¸­é‡åˆ°çš„é—®é¢˜ã€‚ä¸Žä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¸åŒï¼ŒCuRPOä¸æ˜¯ç›´æŽ¥ä¼˜åŒ–æ•´ä¸ªCoTæŽ¨ç†è¿‡ç¨‹ï¼Œè€Œæ˜¯é€šè¿‡è¯¾ç¨‹å­¦ä¹ çš„æ–¹å¼ï¼Œé€æ­¥å¼•å…¥æ›´å¤æ‚çš„æŽ¨ç†æ­¥éª¤ï¼Œä»Žè€Œé¿å…äº†æ¨¡åž‹åœ¨è®­ç»ƒåˆæœŸå°±è¢«è¿‡äºŽå¤æ‚çš„æŽ¨ç†è¿‡ç¨‹æ‰€å›°æ‰°ã€‚æ­¤å¤–ï¼ŒCuRPOè¿˜ä½¿ç”¨äº†ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼Œä»Žè€Œæ›´å¥½åœ°åˆ©ç”¨äº†CoTæŽ¨ç†è¿‡ç¨‹ä¸­çš„ä¸­é—´ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šCuRPOçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨CoTé•¿åº¦å’ŒgIoUå¥–åŠ±ä½œä¸ºå¤æ‚åº¦æŒ‡æ ‡ï¼Œç”¨äºŽè¡¡é‡è®­ç»ƒæ ·æœ¬çš„éš¾åº¦ï¼›2) è®¾è®¡äº†è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œç”¨äºŽåŠ¨æ€è°ƒæ•´è®­ç»ƒæ•°æ®çš„éš¾åº¦ï¼›3) ä½¿ç”¨ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼Œä»Žè€Œæ›´å¥½åœ°åˆ©ç”¨CoTæŽ¨ç†è¿‡ç¨‹ä¸­çš„ä¸­é—´ä¿¡æ¯ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æž„å–å†³äºŽå…·ä½“çš„è§†è§‰å®šä½ä»»åŠ¡å’Œæ•°æ®é›†ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

CuRPOåœ¨RefCOCOã€RefCOCO+ã€RefCOCOgå’ŒLISAæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®žéªŒï¼Œç»“æžœè¡¨æ˜ŽCuRPOå§‹ç»ˆä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼ŒåŒ…æ‹¬Visual-RFTã€‚åœ¨RefCOCOæ•°æ®é›†ä¸Šï¼ŒCuRPOå®žçŽ°äº†é«˜è¾¾+12.52 mAPçš„æ˜¾è‘—æ”¹è¿›ã€‚æ­¤å¤–ï¼ŒCuRPOåœ¨å°‘æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸­ä¹Ÿè¡¨çŽ°å‡ºè‰²ï¼Œè¯æ˜Žäº†å…¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

CuRPOåœ¨è§†è§‰å®šä½ä»»åŠ¡ä¸­è¡¨çŽ°å‡ºè‰²ï¼Œå¯åº”ç”¨äºŽæ™ºèƒ½é›¶å”®ã€è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½é›¶å”®ä¸­ï¼ŒCuRPOå¯ä»¥å¸®åŠ©æœºå™¨äººæ ¹æ®é¡¾å®¢çš„è¯­éŸ³æŒ‡ä»¤ï¼Œå‡†ç¡®åœ°å®šä½åˆ°è´§æž¶ä¸Šçš„å•†å“ã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼ŒCuRPOå¯ä»¥å¸®åŠ©è½¦è¾†æ ¹æ®äº¤é€šæ ‡å¿—çš„æ–‡æœ¬æè¿°ï¼Œå‡†ç¡®åœ°è¯†åˆ«äº¤é€šæ ‡å¿—ã€‚æœªæ¥ï¼ŒCuRPOæœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–è§†è§‰ä»»åŠ¡ï¼Œå¦‚å›¾åƒæè¿°ç”Ÿæˆã€è§†è§‰é—®ç­”ç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Chain-of-Thought (CoT) prompting has recently shown significant promise across various NLP and computer vision tasks by explicitly generating intermediate reasoning steps. However, we find that reinforcement learning (RL)-based fine-tuned CoT reasoning can paradoxically degrade performance in Visual Grounding tasks, particularly as CoT outputs become lengthy or complex. Additionally, our analysis reveals that increased dataset size does not always enhance performance due to varying data complexities. Motivated by these findings, we propose Curriculum-based Relative Policy Optimization (CuRPO), a novel training strategy that leverages CoT length and generalized Intersection over Union (gIoU) rewards as complexity indicators to progressively structure training data from simpler to more challenging examples. Extensive experiments on RefCOCO, RefCOCO+, RefCOCOg, and LISA datasets demonstrate the effectiveness of our approach. CuRPO consistently outperforms existing methods, including Visual-RFT, with notable improvements of up to +12.52 mAP on RefCOCO. Moreover, CuRPO exhibits exceptional efficiency and robustness, delivering strong localization performance even in few-shot learning scenarios, particularly benefiting tasks characterized by ambiguous and intricate textual descriptions.The code is released on https://github.com/qyoung-yan/CuRPO.

