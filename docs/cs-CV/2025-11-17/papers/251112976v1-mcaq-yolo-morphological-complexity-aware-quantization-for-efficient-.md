---
layout: default
title: MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning
---

# MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning

**arXiv**: [2511.12976v1](https://arxiv.org/abs/2511.12976) | [PDF](https://arxiv.org/pdf/2511.12976.pdf)

**ä½œè€…**: Yoonjae Seo, Ermal Elbasani, Jaehong Lee

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-17

**å¤‡æ³¨**: 9 pages, 2 figures, 7 tables. Preprint

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMCAQ-YOLOï¼Œé€šè¿‡å½¢æ€å¤æ‚åº¦æ„ŸçŸ¥é‡åŒ–æå‡ç›®æ ‡æ£€æµ‹æ•ˆçŽ‡ï¼Œé€‚ç”¨äºŽèµ„æºå—é™åœºæ™¯ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `ç›®æ ‡æ£€æµ‹` `æ¨¡åž‹é‡åŒ–` `å½¢æ€å­¦åˆ†æž` `è¯¾ç¨‹å­¦ä¹ ` `è¾¹ç¼˜è®¡ç®—`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰ç¥žç»ç½‘ç»œé‡åŒ–æ–¹æ³•å¿½ç•¥äº†è§†è§‰æ•°æ®å¼‚æž„çš„ç»“æž„å’Œçº¹ç†å¤æ‚åº¦ï¼Œé‡‡ç”¨ç»Ÿä¸€çš„æ¯”ç‰¹ç²¾åº¦ï¼Œé™åˆ¶äº†æ¨¡åž‹æ•ˆçŽ‡ã€‚
2. MCAQ-YOLOé€šè¿‡å½¢æ€å­¦æŒ‡æ ‡è¯„ä¼°å±€éƒ¨è§†è§‰å¤æ‚åº¦ï¼Œè‡ªé€‚åº”åœ°åˆ†é…æ¯”ç‰¹ç²¾åº¦ï¼Œå¹¶ç»“åˆè¯¾ç¨‹å­¦ä¹ ä¼˜åŒ–é‡åŒ–æ¨¡åž‹ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒMCAQ-YOLOåœ¨ç²¾åº¦å’Œæ•ˆçŽ‡ä¸Šä¼˜äºŽå‡åŒ€é‡åŒ–ï¼Œå¹¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§å½¢æ€å¤æ‚åº¦æ„ŸçŸ¥çš„é‡åŒ–æ¡†æž¶MCAQ-YOLOï¼Œç”¨äºŽé«˜æ•ˆçš„ç›®æ ‡æ£€æµ‹ã€‚è¯¥æ¡†æž¶åˆ©ç”¨åˆ†å½¢ç»´æ•°ã€çº¹ç†ç†µã€æ¢¯åº¦æ–¹å·®ã€è¾¹ç¼˜å¯†åº¦å’Œè½®å»“å¤æ‚åº¦è¿™äº”ä¸ªå½¢æ€å­¦æŒ‡æ ‡æ¥è¡¨å¾å±€éƒ¨è§†è§‰å½¢æ€ï¼Œå¹¶æŒ‡å¯¼ç©ºé—´è‡ªé€‚åº”çš„æ¯”ç‰¹åˆ†é…ã€‚é€šè¿‡å°†è¿™äº›æŒ‡æ ‡ä¸Žé‡åŒ–æ•æ„Ÿæ€§ç›¸å…³è”ï¼ŒMCAQ-YOLOæ ¹æ®ç©ºé—´å¤æ‚åº¦åŠ¨æ€è°ƒæ•´æ¯”ç‰¹ç²¾åº¦ã€‚æ­¤å¤–ï¼Œä¸€ç§åŸºäºŽè¯¾ç¨‹å­¦ä¹ çš„é‡åŒ–æ„ŸçŸ¥è®­ç»ƒæ–¹æ¡ˆé€æ­¥å¢žåŠ é‡åŒ–éš¾åº¦ï¼Œä»¥ç¨³å®šä¼˜åŒ–å¹¶åŠ é€Ÿæ”¶æ•›ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œå½¢æ€å¤æ‚åº¦ä¸Žé‡åŒ–æ•æ„Ÿæ€§ä¹‹é—´å­˜åœ¨å¾ˆå¼ºçš„ç›¸å…³æ€§ï¼Œå¹¶ä¸”MCAQ-YOLOç›¸æ¯”äºŽå‡åŒ€é‡åŒ–å®žçŽ°äº†æ›´å¥½çš„æ£€æµ‹ç²¾åº¦å’Œæ”¶æ•›æ•ˆçŽ‡ã€‚åœ¨å®‰å…¨è®¾å¤‡æ•°æ®é›†ä¸Šï¼ŒMCAQ-YOLOä»¥å¹³å‡4.2æ¯”ç‰¹å’Œ7.6å€çš„åŽ‹ç¼©çŽ‡è¾¾åˆ°äº†85.6%çš„mAP@0.5ï¼Œæ¯”å‡åŒ€4æ¯”ç‰¹é‡åŒ–é«˜å‡º3.5ä¸ªç™¾åˆ†ç‚¹ï¼Œå¹¶ä¸”æ¯å¼ å›¾åƒä»…å¼•å…¥1.8æ¯«ç§’çš„é¢å¤–è¿è¡Œæ—¶é—´å¼€é”€ã€‚åœ¨COCOå’ŒPascal VOCä¸Šçš„äº¤å‰æ•°æ®é›†éªŒè¯è¿›ä¸€æ­¥è¯å®žäº†ä¸€è‡´çš„æ€§èƒ½æå‡ï¼Œè¡¨æ˜Žå½¢æ€é©±åŠ¨çš„ç©ºé—´é‡åŒ–å¯ä»¥æé«˜è®¡ç®—å—é™ã€å®‰å…¨å…³é”®åž‹è§†è§‰è¯†åˆ«ä»»åŠ¡çš„æ•ˆçŽ‡å’Œé²æ£’æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰ç¥žç»ç½‘ç»œé‡åŒ–æ–¹æ³•é€šå¸¸é‡‡ç”¨ç»Ÿä¸€çš„æ¯”ç‰¹ç²¾åº¦ï¼Œå¿½ç•¥äº†å›¾åƒä¸åŒåŒºåŸŸçš„å¤æ‚æ€§å·®å¼‚ã€‚è¿™ç§æ–¹æ³•æ— æ³•å……åˆ†åˆ©ç”¨ç¡¬ä»¶èµ„æºï¼Œå¹¶ä¸”å¯èƒ½å¯¼è‡´åœ¨å¤æ‚åŒºåŸŸçš„ä¿¡æ¯æŸå¤±ï¼Œä»Žè€Œå½±å“ç›®æ ‡æ£€æµ‹çš„ç²¾åº¦ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿæ„ŸçŸ¥å›¾åƒå±€éƒ¨å¤æ‚æ€§å¹¶è‡ªé€‚åº”è°ƒæ•´é‡åŒ–æ¯”ç‰¹æ•°çš„æ–¹æ³•ï¼Œä»¥åœ¨ç²¾åº¦å’Œæ•ˆçŽ‡ä¹‹é—´å–å¾—æ›´å¥½çš„å¹³è¡¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMCAQ-YOLOçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å›¾åƒçš„å½¢æ€å­¦å¤æ‚åº¦æ¥æŒ‡å¯¼é‡åŒ–è¿‡ç¨‹ã€‚é€šè¿‡è®¡ç®—å›¾åƒä¸åŒåŒºåŸŸçš„å½¢æ€å­¦æŒ‡æ ‡ï¼Œå¦‚åˆ†å½¢ç»´æ•°ã€çº¹ç†ç†µç­‰ï¼Œå¯ä»¥é‡åŒ–å±€éƒ¨è§†è§‰ä¿¡æ¯çš„å¤æ‚ç¨‹åº¦ã€‚ç„¶åŽï¼Œå°†è¿™äº›æŒ‡æ ‡ä¸Žé‡åŒ–æ•æ„Ÿæ€§ç›¸å…³è”ï¼Œå³å¤æ‚åŒºåŸŸåˆ†é…æ›´é«˜çš„æ¯”ç‰¹æ•°ï¼Œç®€å•åŒºåŸŸåˆ†é…æ›´ä½Žçš„æ¯”ç‰¹æ•°ã€‚è¿™ç§è‡ªé€‚åº”çš„æ¯”ç‰¹åˆ†é…ç­–ç•¥å¯ä»¥åœ¨ä¿è¯ç²¾åº¦çš„å‰æä¸‹ï¼Œé™ä½Žæ¨¡åž‹çš„æ•´ä½“è®¡ç®—å¤æ‚åº¦ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šMCAQ-YOLOçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å½¢æ€å­¦å¤æ‚åº¦è¯„ä¼°æ¨¡å—ï¼šè®¡ç®—å›¾åƒä¸åŒåŒºåŸŸçš„å½¢æ€å­¦æŒ‡æ ‡ï¼Œç”Ÿæˆå¤æ‚åº¦å›¾ã€‚2) æ¯”ç‰¹åˆ†é…æ¨¡å—ï¼šæ ¹æ®å¤æ‚åº¦å›¾ï¼ŒåŠ¨æ€è°ƒæ•´æ¯ä¸ªåŒºåŸŸçš„é‡åŒ–æ¯”ç‰¹æ•°ã€‚3) é‡åŒ–æ¨¡å—ï¼šä½¿ç”¨è‡ªé€‚åº”çš„æ¯”ç‰¹ç²¾åº¦å¯¹æ¨¡åž‹è¿›è¡Œé‡åŒ–ã€‚4) è¯¾ç¨‹å­¦ä¹ è®­ç»ƒæ¨¡å—ï¼šé‡‡ç”¨è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œé€æ­¥å¢žåŠ é‡åŒ–éš¾åº¦ï¼Œä¼˜åŒ–é‡åŒ–æ¨¡åž‹ã€‚æ•´ä¸ªæµç¨‹é¦–å…ˆå¯¹è¾“å…¥å›¾åƒè¿›è¡Œå½¢æ€å­¦åˆ†æžï¼Œç„¶åŽæ ¹æ®åˆ†æžç»“æžœè¿›è¡Œé‡åŒ–ï¼Œæœ€åŽé€šè¿‡è¯¾ç¨‹å­¦ä¹ è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šMCAQ-YOLOçš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†å½¢æ€å¤æ‚åº¦æ„ŸçŸ¥çš„é‡åŒ–æ–¹æ³•ã€‚ä¸Žä¼ ç»Ÿçš„å‡åŒ€é‡åŒ–æ–¹æ³•ä¸åŒï¼ŒMCAQ-YOLOèƒ½å¤Ÿæ ¹æ®å›¾åƒçš„å±€éƒ¨å¤æ‚æ€§è‡ªé€‚åº”åœ°è°ƒæ•´é‡åŒ–æ¯”ç‰¹æ•°ã€‚æ­¤å¤–ï¼Œè¯¾ç¨‹å­¦ä¹ è®­ç»ƒç­–ç•¥ä¹Ÿæé«˜äº†é‡åŒ–æ¨¡åž‹çš„ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°å¹³è¡¡ç²¾åº¦å’Œæ•ˆçŽ‡ï¼Œç‰¹åˆ«é€‚ç”¨äºŽè®¡ç®—èµ„æºå—é™çš„åœºæ™¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å½¢æ€å­¦å¤æ‚åº¦è¯„ä¼°æ¨¡å—ä¸­ï¼Œé€‰æ‹©äº†äº”ä¸ªå½¢æ€å­¦æŒ‡æ ‡ï¼šåˆ†å½¢ç»´æ•°ã€çº¹ç†ç†µã€æ¢¯åº¦æ–¹å·®ã€è¾¹ç¼˜å¯†åº¦å’Œè½®å»“å¤æ‚åº¦ã€‚è¿™äº›æŒ‡æ ‡èƒ½å¤Ÿæœ‰æ•ˆåœ°è¡¨å¾å›¾åƒçš„å±€éƒ¨è§†è§‰ä¿¡æ¯ã€‚åœ¨æ¯”ç‰¹åˆ†é…æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†ä¸€ä¸ªæ˜ å°„å‡½æ•°å°†å½¢æ€å­¦æŒ‡æ ‡æ˜ å°„åˆ°é‡åŒ–æ¯”ç‰¹æ•°ã€‚åœ¨è¯¾ç¨‹å­¦ä¹ è®­ç»ƒæ¨¡å—ä¸­ï¼Œé€æ­¥é™ä½Žé‡åŒ–æ¯”ç‰¹æ•°ï¼Œå¹¶ä½¿ç”¨é‡åŒ–æ„ŸçŸ¥è®­ç»ƒæ–¹æ³•ä¼˜åŒ–æ¨¡åž‹å‚æ•°ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æ£€æµ‹æŸå¤±å’Œé‡åŒ–æŸå¤±ï¼Œç”¨äºŽå¹³è¡¡æ£€æµ‹ç²¾åº¦å’Œé‡åŒ–è¯¯å·®ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

MCAQ-YOLOåœ¨å®‰å…¨è®¾å¤‡æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œåœ¨å¹³å‡4.2æ¯”ç‰¹é‡åŒ–ä¸‹ï¼ŒmAP@0.5è¾¾åˆ°äº†85.6%ï¼Œæ¯”å‡åŒ€4æ¯”ç‰¹é‡åŒ–é«˜å‡º3.5ä¸ªç™¾åˆ†ç‚¹ï¼ŒåŒæ—¶åŽ‹ç¼©çŽ‡è¾¾åˆ°7.6å€ï¼Œå¹¶ä¸”æ¯å¼ å›¾åƒä»…å¢žåŠ 1.8æ¯«ç§’çš„é¢å¤–è¿è¡Œæ—¶é—´ã€‚åœ¨COCOå’ŒPascal VOCæ•°æ®é›†ä¸Šçš„äº¤å‰éªŒè¯ä¹Ÿè¡¨æ˜Žï¼ŒMCAQ-YOLOå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

MCAQ-YOLOé€‚ç”¨äºŽè®¡ç®—èµ„æºå—é™çš„å®‰å…¨å…³é”®åž‹è§†è§‰è¯†åˆ«ä»»åŠ¡ï¼Œä¾‹å¦‚æ— äººæœºå·¡æ£€ã€æ™ºèƒ½ç›‘æŽ§ã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚é€šè¿‡é™ä½Žæ¨¡åž‹è®¡ç®—å¤æ‚åº¦ï¼Œå¯ä»¥åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²é«˜æ€§èƒ½çš„ç›®æ ‡æ£€æµ‹æ¨¡åž‹ï¼Œæé«˜ç³»ç»Ÿçš„å®žæ—¶æ€§å’Œå¯é æ€§ã€‚è¯¥ç ”ç©¶çš„æˆæžœè¿˜å¯ä»¥åº”ç”¨äºŽå…¶ä»–è§†è§‰ä»»åŠ¡ï¼Œå¦‚å›¾åƒåˆ†ç±»ã€è¯­ä¹‰åˆ†å‰²ç­‰ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Most neural network quantization methods apply uniform bit precision across spatial regions, ignoring the heterogeneous structural and textural complexity of visual data. This paper introduces MCAQ-YOLO, a morphological complexity-aware quantization framework for object detection. The framework employs five morphological metrics - fractal dimension, texture entropy, gradient variance, edge density, and contour complexity - to characterize local visual morphology and guide spatially adaptive bit allocation. By correlating these metrics with quantization sensitivity, MCAQ-YOLO dynamically adjusts bit precision according to spatial complexity. In addition, a curriculum-based quantization-aware training scheme progressively increases quantization difficulty to stabilize optimization and accelerate convergence. Experimental results demonstrate a strong correlation between morphological complexity and quantization sensitivity and show that MCAQ-YOLO achieves superior detection accuracy and convergence efficiency compared with uniform quantization. On a safety equipment dataset, MCAQ-YOLO attains 85.6 percent mAP@0.5 with an average of 4.2 bits and a 7.6x compression ratio, yielding 3.5 percentage points higher mAP than uniform 4-bit quantization while introducing only 1.8 ms of additional runtime overhead per image. Cross-dataset validation on COCO and Pascal VOC further confirms consistent performance gains, indicating that morphology-driven spatial quantization can enhance efficiency and robustness for computationally constrained, safety-critical visual recognition tasks.

