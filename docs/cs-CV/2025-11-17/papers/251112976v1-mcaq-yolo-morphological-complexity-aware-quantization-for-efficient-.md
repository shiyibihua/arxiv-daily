---
layout: default
title: MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning
---

# MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning

**arXiv**: [2511.12976v1](https://arxiv.org/abs/2511.12976) | [PDF](https://arxiv.org/pdf/2511.12976.pdf)

**ä½œè€…**: Yoonjae Seo, Ermal Elbasani, Jaehong Lee

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå½¢æ€å¤æ‚åº¦æ„ŸçŸ¥é‡åŒ–æ–¹æ³•ä»¥æå‡å—é™è®¡ç®—åœºæ™¯ä¸‹çš„ç›®æ ‡æ£€æµ‹æ•ˆçŽ‡**

**å…³é”®è¯**: `ç›®æ ‡æ£€æµ‹` `ç¥žç»ç½‘ç»œé‡åŒ–` `å½¢æ€å¤æ‚åº¦æ„ŸçŸ¥` `è¯¾ç¨‹å­¦ä¹ ` `ç©ºé—´è‡ªé€‚åº”é‡åŒ–` `é«˜æ•ˆè§†è§‰è¯†åˆ«`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå‡åŒ€é‡åŒ–å¿½ç•¥è§†è§‰æ•°æ®ç©ºé—´å¼‚è´¨æ€§ï¼Œå¯¼è‡´æ£€æµ‹ç²¾åº¦ä¸‹é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå½¢æ€å­¦æŒ‡æ ‡åŠ¨æ€åˆ†é…æ¯”ç‰¹ï¼Œç»“åˆè¯¾ç¨‹å­¦ä¹ ç¨³å®šè®­ç»ƒã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨å®‰å…¨è£…å¤‡æ•°æ®é›†ä¸Šï¼ŒmAP@0.5è¾¾85.6%ï¼Œä¼˜äºŽå‡åŒ€é‡åŒ–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Most neural network quantization methods apply uniform bit precision across spatial regions, ignoring the heterogeneous structural and textural complexity of visual data. This paper introduces MCAQ-YOLO, a morphological complexity-aware quantization framework for object detection. The framework employs five morphological metrics - fractal dimension, texture entropy, gradient variance, edge density, and contour complexity - to characterize local visual morphology and guide spatially adaptive bit allocation. By correlating these metrics with quantization sensitivity, MCAQ-YOLO dynamically adjusts bit precision according to spatial complexity. In addition, a curriculum-based quantization-aware training scheme progressively increases quantization difficulty to stabilize optimization and accelerate convergence. Experimental results demonstrate a strong correlation between morphological complexity and quantization sensitivity and show that MCAQ-YOLO achieves superior detection accuracy and convergence efficiency compared with uniform quantization. On a safety equipment dataset, MCAQ-YOLO attains 85.6 percent mAP@0.5 with an average of 4.2 bits and a 7.6x compression ratio, yielding 3.5 percentage points higher mAP than uniform 4-bit quantization while introducing only 1.8 ms of additional runtime overhead per image. Cross-dataset validation on COCO and Pascal VOC further confirms consistent performance gains, indicating that morphology-driven spatial quantization can enhance efficiency and robustness for computationally constrained, safety-critical visual recognition tasks.

