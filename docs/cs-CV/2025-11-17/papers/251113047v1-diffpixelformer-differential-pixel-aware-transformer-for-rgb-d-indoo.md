---
layout: default
title: DiffPixelFormer: Differential Pixel-Aware Transformer for RGB-D Indoor Scene Segmentation
---

# DiffPixelFormer: Differential Pixel-Aware Transformer for RGB-D Indoor Scene Segmentation

**arXiv**: [2511.13047v1](https://arxiv.org/abs/2511.13047) | [PDF](https://arxiv.org/pdf/2511.13047.pdf)

**ä½œè€…**: Yan Gong, Jianli Lu, Yongsheng Gao, Jie Zhao, Xiaojuan Zhang, Susanto Rahardja

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDiffPixelFormerä»¥è§£å†³RGB-Då®¤å†…åœºæ™¯åˆ†å‰²ä¸­çš„ç‰¹å¾å¯¹é½å’Œè¡¨ç¤ºé—®é¢˜**

**å…³é”®è¯**: `RGB-Dèžåˆ` `Transformeræ¨¡åž‹` `å®¤å†…è¯­ä¹‰åˆ†å‰²` `è·¨æ¨¡æ€å¯¹é½` `åŠ¨æ€èžåˆç­–ç•¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. RGB-Dèžåˆæ–¹æ³•ä¾èµ–è®¡ç®—å¯†é›†åž‹è·¨æ³¨æ„åŠ›ï¼Œç‰¹å¾å…³ç³»å»ºæ¨¡ä¸è¶³å¯¼è‡´å¯¹é½ä¸ç²¾ç¡®
2. æ ¸å¿ƒIIMIBæ¨¡å—é€šè¿‡è‡ªæ³¨æ„åŠ›æ•èŽ·æ¨¡æ€å†…ä¾èµ–ï¼ŒDSIMæ¨¡å—è§£è€¦æ¨¡æ€ç‰¹å®šå’Œå…±äº«çº¿ç´¢
3. åœ¨SUN RGB-Då’ŒNYUDv2åŸºå‡†ä¸ŠmIoUè¾¾54.28%å’Œ59.95%ï¼Œä¼˜äºŽDFormer-L

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Indoor semantic segmentation is fundamental to computer vision and robotics, supporting applications such as autonomous navigation, augmented reality, and smart environments. Although RGB-D fusion leverages complementary appearance and geometric cues, existing methods often depend on computationally intensive cross-attention mechanisms and insufficiently model intra- and inter-modal feature relationships, resulting in imprecise feature alignment and limited discriminative representation. To address these challenges, we propose DiffPixelFormer, a differential pixel-aware Transformer for RGB-D indoor scene segmentation that simultaneously enhances intra-modal representations and models inter-modal interactions. At its core, the Intra-Inter Modal Interaction Block (IIMIB) captures intra-modal long-range dependencies via self-attention and models inter-modal interactions with the Differential-Shared Inter-Modal (DSIM) module to disentangle modality-specific and shared cues, enabling fine-grained, pixel-level cross-modal alignment. Furthermore, a dynamic fusion strategy balances modality contributions and fully exploits RGB-D information according to scene characteristics. Extensive experiments on the SUN RGB-D and NYUDv2 benchmarks demonstrate that DiffPixelFormer-L achieves mIoU scores of 54.28% and 59.95%, outperforming DFormer-L by 1.78% and 2.75%, respectively. Code is available at https://github.com/gongyan1/DiffPixelFormer.

