---
layout: default
title: ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes
---

# ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes

**arXiv**: [2511.12977v1](https://arxiv.org/abs/2511.12977) | [PDF](https://arxiv.org/pdf/2511.12977.pdf)

**ä½œè€…**: Yixuan Yang, Luyang Xie, Zhen Luo, Zixiang Zhao, Mingqi Gao, Feng Zheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºArtiWorldä»¥è‡ªåŠ¨å°†åœºæ™¯ä¸­çš„åˆšæ€§3Då¯¹è±¡è½¬æ¢ä¸ºå¯äº¤äº’çš„é“°æŽ¥æ¨¡åž‹**

**å…³é”®è¯**: `3Dé“°æŽ¥å¯¹è±¡` `å¤§è¯­è¨€æ¨¡åž‹` `URDFç”Ÿæˆ` `ç‚¹äº‘å¤„ç†` `æœºå™¨äººä»¿çœŸ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰3Dèµ„äº§å¤šä¸ºåˆšæ€§ï¼Œæ‰‹åŠ¨è½¬æ¢ä¸ºé“°æŽ¥å¯¹è±¡æˆæœ¬é«˜ä¸”è€—æ—¶
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨LLMå…ˆéªŒçŸ¥è¯†å’Œ3Dç‚¹äº‘ï¼Œé€šè¿‡Arti4URDFç”ŸæˆURDFæ¨¡åž‹
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žåœºæ™¯ä¸­ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œä¿æŒå‡ ä½•å½¢çŠ¶å’Œäº¤äº’æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Building interactive simulators and scalable robot-learning environments requires a large number of articulated assets. However, most existing 3D assets in simulation are rigid, and manually converting them into articulated objects is extremely labor- and cost-intensive. This raises a natural question: can we automatically identify articulable objects in a scene and convert them into articulated assets directly? In this paper, we present ArtiWorld, a scene-aware pipeline that localizes candidate articulable objects from textual scene descriptions and reconstructs executable URDF models that preserve the original geometry. At the core of this pipeline is Arti4URDF, which leverages 3D point cloud, prior knowledge of a large language model (LLM), and a URDF-oriented prompt design to rapidly convert rigid objects into interactive URDF-based articulated objects while maintaining their 3D shape. We evaluate ArtiWorld at three levels: 3D simulated objects, full 3D simulated scenes, and real-world scan scenes. Across all three settings, our method consistently outperforms existing approaches and achieves state-of-the-art performance, while preserving object geometry and correctly capturing object interactivity to produce usable URDF-based articulated models. This provides a practical path toward building interactive, robot-ready simulation environments directly from existing 3D assets. Code and data will be released.

