---
layout: default
title: DGS-Net: Distillation-Guided Gradient Surgery for CLIP Fine-Tuning in AI-Generated Image Detection
---

# DGS-Net: Distillation-Guided Gradient Surgery for CLIP Fine-Tuning in AI-Generated Image Detection

**arXiv**: [2511.13108v1](https://arxiv.org/abs/2511.13108) | [PDF](https://arxiv.org/pdf/2511.13108.pdf)

**ä½œè€…**: Jiazhen Yan, Ziqiang Li, Fan Wang, Boyu Wang, Zhangjie Fu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDGS-Netä»¥è§£å†³CLIPå¾®è°ƒä¸­çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œæå‡AIç”Ÿæˆå›¾åƒæ£€æµ‹æ€§èƒ½**

**å…³é”®è¯**: `AIç”Ÿæˆå›¾åƒæ£€æµ‹` `CLIPå¾®è°ƒ` `æ¢¯åº¦æ‰‹æœ¯` `è’¸é¦å­¦ä¹ ` `ç¾éš¾æ€§é—å¿˜` `è·¨åŸŸæ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šCLIPå¾®è°ƒå¯¼è‡´ç¾éš¾æ€§é—å¿˜ï¼ŒæŸå®³é¢„è®­ç»ƒå…ˆéªŒå¹¶é™åˆ¶è·¨åŸŸæ³›åŒ–
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æ¢¯åº¦ç©ºé—´åˆ†è§£ï¼ŒæŠ•å½±æœ‰å®³æ–¹å‘å¹¶å¯¹é½æœ‰ç›Šæ–¹å‘ï¼Œå®žçŽ°å…ˆéªŒä¿æŒä¸Žæ— å…³æŠ‘åˆ¶
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨50ä¸ªç”Ÿæˆæ¨¡åž‹ä¸Šå®žéªŒï¼Œå¹³å‡æ€§èƒ½æå‡6.6ï¼Œæ£€æµ‹ä¸Žæ³›åŒ–èƒ½åŠ›ä¼˜è¶Š

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The rapid progress of generative models such as GANs and diffusion models has led to the widespread proliferation of AI-generated images, raising concerns about misinformation, privacy violations, and trust erosion in digital media. Although large-scale multimodal models like CLIP offer strong transferable representations for detecting synthetic content, fine-tuning them often induces catastrophic forgetting, which degrades pre-trained priors and limits cross-domain generalization. To address this issue, we propose the Distillation-guided Gradient Surgery Network (DGS-Net), a novel framework that preserves transferable pre-trained priors while suppressing task-irrelevant components. Specifically, we introduce a gradient-space decomposition that separates harmful and beneficial descent directions during optimization. By projecting task gradients onto the orthogonal complement of harmful directions and aligning with beneficial ones distilled from a frozen CLIP encoder, DGS-Net achieves unified optimization of prior preservation and irrelevant suppression. Extensive experiments on 50 generative models demonstrate that our method outperforms state-of-the-art approaches by an average margin of 6.6, achieving superior detection performance and generalization across diverse generation techniques.

