---
layout: default
title: Multi-Level CLS Token Fusion for Contrastive Learning in Endoscopy Image Classification
---

# Multi-Level CLS Token Fusion for Contrastive Learning in Endoscopy Image Classification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00752" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00752v1</a>
  <a href="https://arxiv.org/pdf/2509.00752.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00752v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00752v1', 'Multi-Level CLS Token Fusion for Contrastive Learning in Endoscopy Image Classification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Y Hop Nguyen, Doan Anh Phan Huu, Trung Thai Tran, Nhat Nam Mai, Van Toi Giap, Thao Thi Phuong Dao, Trung-Nghia Le

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-31

**å¤‡æ³¨**: ACM Multimedia 2025

**DOI**: [10.1145/3746027.3762093](https://doi.org/10.1145/3746027.3762093)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šå±‚CLS Tokenèåˆä»¥è§£å†³å†…çª¥é•œå›¾åƒåˆ†ç±»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å†…çª¥é•œå›¾åƒåˆ†æ` `å¤šæ¨¡æ€å­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†` `åŒ»å­¦å›¾åƒåˆ†ç±»` `è§†è§‰-è¯­è¨€æ¡†æ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºCNNçš„æ–¹æ³•åœ¨æ•æ‰è·¨æ¨¡æ€è¯­ä¹‰æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œé™åˆ¶äº†å†…çª¥é•œå›¾åƒåˆ†æçš„æ•ˆæœã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºCLIP ViT-B/16çš„æ¡†æ¶ï¼Œé€šè¿‡ä½ç§©é€‚åº”å’Œå¤šå±‚CLS tokenèšåˆæ¥å¢å¼ºæ¨¡å‹çš„è¡¨ç°åŠ›ã€‚
3. åœ¨ACM MM'25 ENTRep Grand Challengeä¸­ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨åˆ†ç±»å’Œæ£€ç´¢ä»»åŠ¡ä¸­å‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„è§†è§‰-è¯­è¨€æ¡†æ¶ï¼Œä¸“ä¸ºè€³é¼»å–‰ç§‘å†…çª¥é•œå›¾åƒåˆ†æè€Œè®¾è®¡ï¼ŒåŒæ—¶è§£å†³å›¾åƒåˆ†ç±»ã€å›¾åƒåˆ°å›¾åƒæ£€ç´¢å’Œæ–‡æœ¬åˆ°å›¾åƒæ£€ç´¢ä¸‰é¡¹ä¸´åºŠç›¸å…³ä»»åŠ¡ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºCNNçš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨CLIP ViT-B/16éª¨å¹²ç½‘ç»œï¼Œå¹¶é€šè¿‡ä½ç§©é€‚åº”ã€å¤šå±‚CLS tokenèšåˆå’Œçƒé¢ç‰¹å¾æ’å€¼è¿›è¡Œå¢å¼ºã€‚è¿™äº›ç»„ä»¶å…±åŒå®ç°äº†åœ¨æœ‰é™åŒ»å­¦æ•°æ®ä¸Šçš„é«˜æ•ˆå¾®è°ƒï¼ŒåŒæ—¶æ”¹å–„äº†è·¨æ¨¡æ€çš„è¡¨ç¤ºå¤šæ ·æ€§å’Œè¯­ä¹‰å¯¹é½ã€‚ä¸ºç¼©å°è§†è§‰è¾“å…¥ä¸æ–‡æœ¬è¯Šæ–­ä¸Šä¸‹æ–‡ä¹‹é—´çš„å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç±»ç‰¹å®šçš„è‡ªç„¶è¯­è¨€æç¤ºï¼Œé€šè¿‡ç»“åˆç›‘ç£åˆ†ç±»ä¸å¯¹æ¯”å­¦ä¹ çš„è”åˆè®­ç»ƒç›®æ ‡æ¥å¼•å¯¼å›¾åƒç¼–ç å™¨ã€‚æˆ‘ä»¬åœ¨ACM MM'25 ENTRep Grand Challengeä¸­éªŒè¯äº†è¯¥æ¡†æ¶ï¼Œåˆ†ç±»å‡†ç¡®ç‡å’ŒF1-scoreè¾¾åˆ°95%ï¼Œå›¾åƒåˆ°å›¾åƒå’Œæ–‡æœ¬åˆ°å›¾åƒæ£€ç´¢çš„Recall@1åˆ†åˆ«ä¸º0.93å’Œ0.92ï¼ŒMRRåˆ†æ•°ä¸º0.97å’Œ0.96ã€‚æ¶ˆèç ”ç©¶è¯æ˜äº†æ¯ä¸ªæ¶æ„ç»„ä»¶çš„å¢ç›Šï¼ŒéªŒè¯äº†æˆ‘ä»¬è®¾è®¡åœ¨ä½èµ„æºä¸´åºŠç¯å¢ƒä¸­å®ç°ç¨³å¥å¤šæ¨¡æ€åŒ»å­¦ç†è§£çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å†…çª¥é•œå›¾åƒåˆ†ç±»åŠç›¸å…³æ£€ç´¢ä»»åŠ¡ä¸­çš„è·¨æ¨¡æ€è¯­ä¹‰æ•æ‰ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–äºCNNï¼Œéš¾ä»¥æœ‰æ•ˆæ•´åˆè§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºçš„æ¡†æ¶åˆ©ç”¨CLIP ViT-B/16éª¨å¹²ç½‘ç»œï¼Œé€šè¿‡ä½ç§©é€‚åº”å’Œå¤šå±‚CLS tokenèšåˆæ¥æå‡æ¨¡å‹åœ¨æœ‰é™åŒ»å­¦æ•°æ®ä¸Šçš„è¡¨ç°ï¼ŒåŒæ—¶å¼•å…¥ç±»ç‰¹å®šçš„è‡ªç„¶è¯­è¨€æç¤ºä»¥å¢å¼ºè¯­ä¹‰å¯¹é½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å›¾åƒç¼–ç å™¨å’Œæ–‡æœ¬ç¼–ç å™¨ï¼Œé‡‡ç”¨è”åˆè®­ç»ƒç›®æ ‡ï¼Œç»“åˆç›‘ç£åˆ†ç±»ä¸å¯¹æ¯”å­¦ä¹ ã€‚å›¾åƒç¼–ç å™¨é€šè¿‡è‡ªç„¶è¯­è¨€æç¤ºå¼•å¯¼ï¼Œå¢å¼ºäº†å¯¹å›¾åƒå†…å®¹çš„ç†è§£ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¤šå±‚CLS tokençš„èšåˆå’Œçƒé¢ç‰¹å¾æ’å€¼ï¼Œè¿™äº›è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨å¤šæ¨¡æ€æ•°æ®ä¸Šå®ç°äº†æ›´å¥½çš„è¡¨ç¤ºå¤šæ ·æ€§å’Œè¯­ä¹‰å¯¹é½ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„å•ä¸€ç‰¹å¾æå–æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šæˆ‘ä»¬åœ¨æ¨¡å‹ä¸­è®¾ç½®äº†ä½ç§©é€‚åº”çš„å‚æ•°ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡åˆ†ç±»ä¸å¯¹æ¯”å­¦ä¹ çš„ç›®æ ‡ï¼ŒåŒæ—¶ä¼˜åŒ–äº†ç½‘ç»œç»“æ„ä»¥é€‚åº”åŒ»å­¦å›¾åƒçš„ç‰¹æ€§ã€‚é€šè¿‡æ¶ˆèå®éªŒéªŒè¯äº†å„ä¸ªç»„ä»¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨ACM MM'25 ENTRep Grand Challengeä¸­ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°äº†95%çš„å‡†ç¡®ç‡å’ŒF1-scoreï¼Œå›¾åƒåˆ°å›¾åƒæ£€ç´¢å’Œæ–‡æœ¬åˆ°å›¾åƒæ£€ç´¢çš„Recall@1åˆ†åˆ«ä¸º0.93å’Œ0.92ï¼ŒMRRåˆ†æ•°ä¸º0.97å’Œ0.96ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—å½±åƒåˆ†æã€æ™ºèƒ½è¯Šæ–­ç³»ç»Ÿå’Œä¸´åºŠå†³ç­–æ”¯æŒã€‚é€šè¿‡æé«˜å†…çª¥é•œå›¾åƒçš„åˆ†æèƒ½åŠ›ï¼Œèƒ½å¤Ÿå¸®åŠ©åŒ»ç”Ÿæ›´å‡†ç¡®åœ°è¿›è¡Œè¯Šæ–­å’Œæ²»ç–—ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present a unified vision-language framework tailored for ENT endoscopy image analysis that simultaneously tackles three clinically-relevant tasks: image classification, image-to-image retrieval, and text-to-image retrieval. Unlike conventional CNN-based pipelines that struggle to capture cross-modal semantics, our approach leverages the CLIP ViT-B/16 backbone and enhances it through Low-Rank Adaptation, multi-level CLS token aggregation, and spherical feature interpolation. These components collectively enable efficient fine-tuning on limited medical data while improving representation diversity and semantic alignment across modalities. To bridge the gap between visual inputs and textual diagnostic context, we introduce class-specific natural language prompts that guide the image encoder through a joint training objective combining supervised classification with contrastive learning. We validated our framework through participation in the ACM MM'25 ENTRep Grand Challenge, achieving 95% accuracy and F1-score in classification, Recall@1 of 0.93 and 0.92 for image-to-image and text-to-image retrieval respectively, and MRR scores of 0.97 and 0.96. Ablation studies demonstrated the incremental benefits of each architectural component, validating the effectiveness of our design for robust multimodal medical understanding in low-resource clinical settings.

