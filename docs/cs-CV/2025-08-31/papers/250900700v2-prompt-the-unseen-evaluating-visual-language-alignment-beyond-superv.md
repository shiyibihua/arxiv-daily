---
layout: default
title: Prompt the Unseen: Evaluating Visual-Language Alignment Beyond Supervision
---

# Prompt the Unseen: Evaluating Visual-Language Alignment Beyond Supervision

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00700" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00700v2</a>
  <a href="https://arxiv.org/pdf/2509.00700.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00700v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00700v2', 'Prompt the Unseen: Evaluating Visual-Language Alignment Beyond Supervision')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Raehyuk Jung, Seungjun Yu, Hyunjung Shim

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-31 (æ›´æ–°: 2025-09-09)

**å¤‡æ³¨**: Link to publicly available codes is added

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–°åŸºå‡†ä»¥è¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹çš„æŠ•å½±å±‚æ³›åŒ–èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `æŠ•å½±å±‚` `æ³›åŒ–èƒ½åŠ›` `å¤šæ¨¡æ€å­¦ä¹ ` `æœºåˆ¶å¯è§£é‡Šæ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æœªè§è§†è§‰æ¦‚å¿µä¸Šçš„æ³›åŒ–èƒ½åŠ›ç¼ºä¹ç³»ç»Ÿè¯„ä¼°ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºå‡†ï¼Œé€šè¿‡è°ƒæ•´ç›®æ ‡æ£€æµ‹æ•°æ®é›†çš„æ ¼å¼ï¼Œè¯„ä¼°æŠ•å½±å±‚çš„æ³›åŒ–èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒæŠ•å½±å±‚åœ¨æœªè§ç±»åˆ«ä¸Šä¿æŒ79%è‡³88%çš„æ€§èƒ½ï¼Œè¡¨æ˜å…¶å…·å¤‡è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰é€šè¿‡å¯¹é½è®­ç»ƒç»“åˆè§†è§‰ç¼–ç å™¨å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œåœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ã€‚ç„¶è€Œï¼ŒæŠ•å½±å±‚åœ¨æœªè§è§†è§‰æ¦‚å¿µä¸Šçš„æ³›åŒ–èƒ½åŠ›å°šæœªå¾—åˆ°ç³»ç»Ÿè¯„ä¼°ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§è¯„ä¼°æŠ•å½±å±‚æ³›åŒ–çš„æ–°åŸºå‡†ï¼Œåˆ©ç”¨ä¸°å¯Œç»†ç²’åº¦æ³¨é‡Šçš„ç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼Œè®¾è®¡äº†è®­ç»ƒ/æµ‹è¯•åˆ†å‰²ä»¥å®ç°å·²è§ä¸æœªè§æ¦‚å¿µçš„ç²¾ç¡®æ§åˆ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒæŠ•å½±å±‚åœ¨æœªè§ç±»åˆ«ä¸Šçš„æ€§èƒ½ä¿æŒåœ¨79%è‡³88%ä¹‹é—´ï¼Œæ˜¾ç¤ºå‡ºå³ä½¿åœ¨æ²¡æœ‰æ˜ç¡®å¯¹é½ç›‘ç£çš„æƒ…å†µä¸‹ï¼Œä»å…·å¤‡éå¹³å‡¡çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡æœºåˆ¶å¯è§£é‡Šæ€§åˆ†æï¼Œå‘ç°æŠ•å½±å±‚ä¸­çš„å‰é¦ˆç½‘ç»œåœ¨å¤„ç†å·²è§å’Œæœªè§æ ‡è®°æ—¶è¡¨ç°ç›¸ä¼¼ï¼Œæå‡ºäº†æ–°çš„è¯„ä¼°æ¡†æ¶å¹¶å¼ºè°ƒäº†åœ¨æœ‰é™å¯¹é½æ•°æ®ä¸‹é«˜æ•ˆè®­ç»ƒVLMçš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹ä¸­æŠ•å½±å±‚å¯¹æœªè§è§†è§‰æ¦‚å¿µçš„æ³›åŒ–èƒ½åŠ›è¯„ä¼°ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½ç³»ç»Ÿæ€§åœ°æ£€éªŒæŠ•å½±å±‚åœ¨æœªè§æ¦‚å¿µä¸Šçš„è¡¨ç°ï¼Œé™åˆ¶äº†æ¨¡å‹çš„å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°åŸºå‡†ï¼Œé€šè¿‡å°†ç›®æ ‡æ£€æµ‹æ•°æ®é›†è½¬åŒ–ä¸ºæç¤ºæ ¼å¼ï¼Œå¹¶è®¾è®¡è®­ç»ƒ/æµ‹è¯•åˆ†å‰²ä»¥å®ç°å·²è§ä¸æœªè§æ¦‚å¿µçš„åˆ†ç¦»ï¼Œä»è€Œç³»ç»Ÿæ€§åœ°è¯„ä¼°æŠ•å½±å±‚çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è§†è§‰ç¼–ç å™¨ã€æŠ•å½±å±‚å’Œå¤§å‹è¯­è¨€æ¨¡å‹ã€‚é€šè¿‡å¯¹ç›®æ ‡æ£€æµ‹æ•°æ®é›†è¿›è¡Œæ ¼å¼è°ƒæ•´ï¼Œæ„å»ºäº†åŒ…å«å·²è§å’Œæœªè§ç±»åˆ«çš„è®­ç»ƒå’Œæµ‹è¯•é›†ï¼Œç¡®ä¿äº†è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®å¯¹é½ç›‘ç£çš„æƒ…å†µä¸‹ï¼Œè¯„ä¼°æŠ•å½±å±‚çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„è¯„ä¼°æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†ç»†ç²’åº¦æ³¨é‡Šçš„ç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼Œå¹¶è®¾è®¡äº†ä¸åŒçš„è®­ç»ƒ/æµ‹è¯•åˆ†å‰²ç­–ç•¥ï¼Œä»¥ç¡®ä¿å·²è§å’Œæœªè§ç±»åˆ«çš„æœ‰æ•ˆåˆ†ç¦»ã€‚æŠ•å½±å±‚çš„å‰é¦ˆç½‘ç»œè¢«è®¾è®¡ä¸ºç±»ä¼¼äºé”®å€¼å­˜å‚¨ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å·²è§å’Œæœªè§æ ‡è®°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒæŠ•å½±å±‚åœ¨æœªè§ç±»åˆ«ä¸Šçš„æ€§èƒ½ä¿æŒåœ¨79%è‡³88%ä¹‹é—´ï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™ä¸€å‘ç°è¡¨æ˜ï¼Œå³ä½¿åœ¨ç¼ºä¹æ˜ç¡®å¯¹é½ç›‘ç£çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹ä»èƒ½æœ‰æ•ˆå¤„ç†æœªè§æ¦‚å¿µï¼Œå…·æœ‰é‡è¦çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šæ¨¡æ€å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ä¸è‡ªç„¶è¯­è¨€å¤„ç†çš„ç»“åˆç­‰ã€‚é€šè¿‡æé«˜è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æœªè§æ¦‚å¿µä¸Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œå¯ä»¥åœ¨å®é™…åº”ç”¨ä¸­å®ç°æ›´é«˜æ•ˆçš„æ¨¡å‹è®­ç»ƒï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language Models (VLMs) combine a vision encoder and a large language model (LLM) through alignment training, showing strong performance on multimodal tasks. A central component in this architecture is the projection layer, which maps visual features into the LLM's embedding space. Despite its importance, its ability to generalize to unseen visual concepts has not been systematically evaluated. To address this, we propose a benchmark for evaluating projection-layer generalization. We adapt object detection datasets (rich in fine-grained annotations) into a prompting format and design train/test splits with disjoint label sets, enabling precise control over seen and unseen concept separation. Experimental results show that the projection layer retains about 79 to 88 percent of the performance on unseen classes compared to seen ones across various settings, suggesting a non-trivial level of generalization even without explicit alignment supervision on those concepts. We further analyze this behavior through a mechanistic interpretability lens. Our findings indicate that the feed-forward network in the projection layer functions like a key-value memory, processing seen and unseen tokens in similar ways. This study introduces a new evaluation framework for alignment generalization and highlights the potential for efficient VLM training with limited aligned data.

