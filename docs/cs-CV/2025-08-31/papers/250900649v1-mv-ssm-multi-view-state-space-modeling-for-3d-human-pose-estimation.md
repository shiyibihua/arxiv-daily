---
layout: default
title: MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation
---

# MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00649" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00649v1</a>
  <a href="https://arxiv.org/pdf/2509.00649.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00649v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00649v1', 'MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aviral Chharia, Wenbo Gou, Haoye Dong

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-31

**å¤‡æ³¨**: CVPR 2025; Project Website: https://aviralchharia.github.io/MV-SSM

**æœŸåˆŠ**: CVPR, Nashville, TN, USA, 2025, pp. 11590-11599

**DOI**: [10.1109/CVPR52734.2025.01082](https://doi.org/10.1109/CVPR52734.2025.01082)

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://aviralchharia.github.io/MV-SSM)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMV-SSMæ¡†æ¶ä»¥è§£å†³å¤šè§†è§’3Däººä½“å§¿æ€ä¼°è®¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `3Däººä½“å§¿æ€ä¼°è®¡` `å¤šè§†è§’å»ºæ¨¡` `çŠ¶æ€ç©ºé—´å»ºæ¨¡` `æŠ•å½±çŠ¶æ€ç©ºé—´` `æ·±åº¦å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šè§†è§’3Däººä½“å§¿æ€ä¼°è®¡ä¸­éš¾ä»¥æ³›åŒ–åˆ°æ–°çš„ç›¸æœºé…ç½®ï¼Œå°¤å…¶åœ¨é®æŒ¡åœºæ™¯ä¸‹è¡¨ç°ä¸ä½³ã€‚
2. æå‡ºMV-SSMæ¡†æ¶ï¼Œé€šè¿‡æŠ•å½±çŠ¶æ€ç©ºé—´æ¨¡å—åœ¨ç‰¹å¾å±‚å’Œå…³é”®ç‚¹å±‚æ˜¾å¼å»ºæ¨¡å…³èŠ‚ç©ºé—´åºåˆ—ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMV-SSMåœ¨å¤šä¸ªè®¾ç½®ä¸­å‡è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡åœ¨å•è§†è§’3Däººä½“å§¿æ€ä¼°è®¡æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å¤šè§†è§’3Däººä½“å§¿æ€ä¼°è®¡ä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨æ–°ç›¸æœºé…ç½®çš„æ³›åŒ–èƒ½åŠ›æ–¹é¢ã€‚ç°æœ‰çš„åŸºäºæ³¨æ„åŠ›çš„å˜æ¢å™¨åœ¨å‡†ç¡®å»ºæ¨¡å…³é”®ç‚¹çš„ç©ºé—´æ’åˆ—æ—¶å¸¸å¸¸è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨é®æŒ¡åœºæ™¯ä¸­ã€‚æ­¤å¤–ï¼Œå®ƒä»¬å¾€å¾€å¯¹ç‰¹å®šç›¸æœºæ’åˆ—å’Œè®­ç»ƒæ•°æ®ä¸­çš„è§†è§‰åœºæ™¯è¿‡æ‹Ÿåˆï¼Œå¯¼è‡´åœ¨æ–°ç¯å¢ƒä¸­æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šè§†è§’çŠ¶æ€ç©ºé—´å»ºæ¨¡æ¡†æ¶MV-SSMï¼Œç”¨äºç¨³å¥åœ°ä¼°è®¡3Däººä½“å…³é”®ç‚¹ã€‚æˆ‘ä»¬åœ¨ç‰¹å¾å±‚å’Œå…³é”®ç‚¹å±‚ä¸¤ä¸ªä¸åŒå±‚æ¬¡ä¸Šæ˜¾å¼å»ºæ¨¡å…³èŠ‚ç©ºé—´åºåˆ—ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æŠ•å½±çŠ¶æ€ç©ºé—´ï¼ˆPSSï¼‰æ¨¡å—ï¼Œä»¥ä½¿ç”¨çŠ¶æ€ç©ºé—´å»ºæ¨¡å­¦ä¹ å…³èŠ‚ç©ºé—´æ’åˆ—çš„å¹¿ä¹‰è¡¨ç¤ºã€‚å¤šä¸ªå®éªŒè¡¨æ˜ï¼ŒMV-SSMåœ¨æŒ‘æˆ˜æ€§çš„ä¸‰æ‘„åƒå¤´è®¾ç½®ä¸­è¶…è¶Šäº†æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒAP25æå‡äº†10.8ï¼ˆ24%ï¼‰ï¼Œåœ¨ä¸åŒç›¸æœºæ’åˆ—ä¸­æå‡äº†7.0ï¼ˆ13%ï¼‰ï¼Œåœ¨è·¨æ•°æ®é›†è¯„ä¼°ä¸­æå‡äº†15.3 PCPï¼ˆ38%ï¼‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤šè§†è§’3Däººä½“å§¿æ€ä¼°è®¡ä¸­çš„æ³›åŒ–é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨æ–°ç›¸æœºé…ç½®å’Œé®æŒ¡åœºæ™¯ä¸‹çš„è¡¨ç°ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€å¯¹è®­ç»ƒæ•°æ®ä¸­çš„ç‰¹å®šç›¸æœºæ’åˆ—è¿‡æ‹Ÿåˆï¼Œå¯¼è‡´åœ¨æ–°ç¯å¢ƒä¸­æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„MV-SSMæ¡†æ¶é€šè¿‡å¼•å…¥æŠ•å½±çŠ¶æ€ç©ºé—´ï¼ˆPSSï¼‰æ¨¡å—ï¼Œæ˜¾å¼å»ºæ¨¡å…³èŠ‚ç©ºé—´åºåˆ—ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚è¯¥è®¾è®¡æ—¨åœ¨å…‹æœç°æœ‰æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸­çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMV-SSMæ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªå±‚æ¬¡çš„å»ºæ¨¡ï¼šç‰¹å¾å±‚å’Œå…³é”®ç‚¹å±‚ã€‚ç‰¹å¾å±‚ä»å¤šè§†è§’å›¾åƒä¸­æå–ç‰¹å¾ï¼Œè€Œå…³é”®ç‚¹å±‚åˆ™å…³æ³¨äºå…³èŠ‚çš„ç©ºé—´æ’åˆ—ã€‚PSSæ¨¡å—æ˜¯è¯¥æ¡†æ¶çš„æ ¸å¿ƒï¼Œè´Ÿè´£å­¦ä¹ å…³èŠ‚ç©ºé—´çš„å¹¿ä¹‰è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šMV-SSMçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†PSSæ¨¡å—å’Œæ”¹è¿›çš„ç½‘æ ¼ä»¤ç‰Œå¼•å¯¼åŒå‘æ‰«æï¼ˆGTBSï¼‰æŠ€æœ¯ï¼Œè¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•æ‰å…³é”®ç‚¹çš„ç©ºé—´å…³ç³»ï¼Œå°¤å…¶æ˜¯åœ¨é®æŒ¡æƒ…å†µä¸‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼ŒPSSæ¨¡å—çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©è‡³å…³é‡è¦ã€‚GTBSçš„å¼•å…¥ä¼˜åŒ–äº†ä¼ ç»Ÿæ‰«ææ–¹å¼ï¼Œä½¿å¾—æ¨¡å‹åœ¨å¤„ç†å¤šè§†è§’æ•°æ®æ—¶æ›´åŠ é«˜æ•ˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMV-SSMåœ¨ä¸‰æ‘„åƒå¤´è®¾ç½®ä¸­AP25æå‡äº†10.8ï¼ˆ24%ï¼‰ï¼Œåœ¨ä¸åŒç›¸æœºæ’åˆ—ä¸­æå‡äº†7.0ï¼ˆ13%ï¼‰ï¼Œåœ¨è·¨æ•°æ®é›†è¯„ä¼°ä¸­æå‡äº†15.3 PCPï¼ˆ38%ï¼‰ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€è¿åŠ¨åˆ†æå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æé«˜å¤šè§†è§’3Däººä½“å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼ŒMV-SSMèƒ½å¤Ÿä¸ºè¿™äº›é¢†åŸŸæä¾›æ›´ä¸ºå¯é çš„æŠ€æœ¯æ”¯æŒï¼Œæ¨åŠ¨ç›¸å…³åº”ç”¨çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While significant progress has been made in single-view 3D human pose estimation, multi-view 3D human pose estimation remains challenging, particularly in terms of generalizing to new camera configurations. Existing attention-based transformers often struggle to accurately model the spatial arrangement of keypoints, especially in occluded scenarios. Additionally, they tend to overfit specific camera arrangements and visual scenes from training data, resulting in substantial performance drops in new settings. In this study, we introduce a novel Multi-View State Space Modeling framework, named MV-SSM, for robustly estimating 3D human keypoints. We explicitly model the joint spatial sequence at two distinct levels: the feature level from multi-view images and the person keypoint level. We propose a Projective State Space (PSS) block to learn a generalized representation of joint spatial arrangements using state space modeling. Moreover, we modify Mamba's traditional scanning into an effective Grid Token-guided Bidirectional Scanning (GTBS), which is integral to the PSS block. Multiple experiments demonstrate that MV-SSM achieves strong generalization, outperforming state-of-the-art methods: +10.8 on AP25 (+24%) on the challenging three-camera setting in CMU Panoptic, +7.0 on AP25 (+13%) on varying camera arrangements, and +15.3 PCP (+38%) on Campus A1 in cross-dataset evaluations. Project Website: https://aviralchharia.github.io/MV-SSM

