---
layout: default
title: CascadeFormer: A Family of Two-stage Cascading Transformers for Skeleton-based Human Action Recognition
---

# CascadeFormer: A Family of Two-stage Cascading Transformers for Skeleton-based Human Action Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00692" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00692v1</a>
  <a href="https://arxiv.org/pdf/2509.00692.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00692v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00692v1', 'CascadeFormer: A Family of Two-stage Cascading Transformers for Skeleton-based Human Action Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yusen Peng, Alper Yilmaz

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-31

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCascadeFormerä»¥è§£å†³éª¨æ¶åŸºç¡€çš„äººç±»åŠ¨ä½œè¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `éª¨æ¶åŠ¨ä½œè¯†åˆ«` `å˜æ¢å™¨æ¨¡å‹` `æ©ç é¢„è®­ç»ƒ` `çº§è”å¾®è°ƒ` `å›¾å·ç§¯ç½‘ç»œ` `æ—¶ç©ºç‰¹å¾` `è‡ªç›‘ç£å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å›¾å·ç§¯ç½‘ç»œï¼ˆGCNsï¼‰ï¼Œåœ¨å¤„ç†éª¨æ¶æ•°æ®æ—¶å­˜åœ¨ä¸€å®šçš„å±€é™æ€§ï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨å˜æ¢å™¨æ¨¡å‹çš„ä¼˜åŠ¿ã€‚
2. CascadeFormeré€šè¿‡å¼•å…¥ä¸¤é˜¶æ®µçš„çº§è”å˜æ¢å™¨æ¶æ„ï¼Œé¦–å…ˆè¿›è¡Œæ©ç é¢„è®­ç»ƒä»¥å­¦ä¹ é€šç”¨çš„éª¨æ¶è¡¨ç¤ºï¼Œéšåè¿›è¡Œå¾®è°ƒä»¥å®ç°é«˜æ•ˆçš„åŠ¨ä½œåˆ†ç±»ã€‚
3. åœ¨Penn Actionã€N-UCLAå’ŒNTU RGB+D 60ç­‰ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šï¼ŒCascadeFormerå±•ç°å‡ºç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºéª¨æ¶çš„äººç±»åŠ¨ä½œè¯†åˆ«åˆ©ç”¨äººç±»å…³èŠ‚åæ ‡åºåˆ—æ¥è¯†åˆ«è§†é¢‘ä¸­çš„åŠ¨ä½œã€‚ç”±äºéª¨æ¶æ•°æ®çš„å†…åœ¨æ—¶ç©ºç»“æ„ï¼Œå›¾å·ç§¯ç½‘ç»œï¼ˆGCNsï¼‰ä¸€ç›´æ˜¯è¯¥é¢†åŸŸçš„ä¸»æµæ¶æ„ã€‚ç„¶è€Œï¼Œè¿‘æœŸåœ¨å˜æ¢å™¨æ¨¡å‹å’Œæ©ç é¢„è®­ç»ƒæ¡†æ¶æ–¹é¢çš„è¿›å±•ä¸ºè¡¨ç¤ºå­¦ä¹ å¼€è¾Ÿäº†æ–°é€”å¾„ã€‚æœ¬æ–‡æå‡ºäº†CascadeFormerï¼Œä¸€ä¸ªç”¨äºéª¨æ¶åŸºç¡€äººç±»åŠ¨ä½œè¯†åˆ«çš„ä¸¤é˜¶æ®µçº§è”å˜æ¢å™¨ç³»åˆ—ã€‚æˆ‘ä»¬çš„æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªæ©ç é¢„è®­ç»ƒé˜¶æ®µï¼Œä»¥å­¦ä¹ å¯æ³›åŒ–çš„éª¨æ¶è¡¨ç¤ºï¼Œéšåæ˜¯ä¸€ä¸ªé’ˆå¯¹åŒºåˆ†æ€§åŠ¨ä½œåˆ†ç±»çš„çº§è”å¾®è°ƒé˜¶æ®µã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ï¼ˆPenn Actionã€N-UCLAå’ŒNTU RGB+D 60ï¼‰ä¸Šè¯„ä¼°äº†CascadeFormerï¼Œåœ¨æ‰€æœ‰ä»»åŠ¡ä¸­å‡å–å¾—äº†ç«äº‰åŠ›çš„è¡¨ç°ã€‚ä¸ºäº†ä¿ƒè¿›å¯é‡å¤æ€§ï¼Œæˆ‘ä»¬å‘å¸ƒäº†ä»£ç å’Œæ¨¡å‹æ£€æŸ¥ç‚¹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³éª¨æ¶åŸºç¡€çš„äººç±»åŠ¨ä½œè¯†åˆ«é—®é¢˜ï¼Œç°æœ‰çš„å›¾å·ç§¯ç½‘ç»œï¼ˆGCNsï¼‰åœ¨å¤„ç†æ—¶ç©ºç‰¹å¾æ—¶å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥å®ç°æ›´é«˜çš„è¯†åˆ«ç²¾åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCascadeFormerçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸¤é˜¶æ®µçš„çº§è”å˜æ¢å™¨æ¶æ„ï¼Œé¦–å…ˆè¿›è¡Œæ©ç é¢„è®­ç»ƒä»¥å­¦ä¹ æ›´å…·æ³›åŒ–èƒ½åŠ›çš„éª¨æ¶è¡¨ç¤ºï¼Œéšåè¿›è¡Œé’ˆå¯¹æ€§çš„å¾®è°ƒä»¥æé«˜åŠ¨ä½œåˆ†ç±»çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯æ©ç é¢„è®­ç»ƒï¼Œæ—¨åœ¨é€šè¿‡è‡ªç›‘ç£å­¦ä¹ è·å–é€šç”¨éª¨æ¶ç‰¹å¾ï¼›ç¬¬äºŒé˜¶æ®µæ˜¯çº§è”å¾®è°ƒï¼Œä¸“æ³¨äºä¼˜åŒ–åŠ¨ä½œåˆ†ç±»æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šCascadeFormerçš„åˆ›æ–°åœ¨äºç»“åˆäº†æ©ç é¢„è®­ç»ƒå’Œçº§è”å¾®è°ƒçš„ç­–ç•¥ï¼Œçªç ´äº†ä¼ ç»ŸGCNsçš„é™åˆ¶ï¼Œä½¿å¾—æ¨¡å‹åœ¨åŠ¨ä½œè¯†åˆ«ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´å¼ºçš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡é¢„è®­ç»ƒå’Œå¾®è°ƒé˜¶æ®µçš„å­¦ä¹ ç›®æ ‡ï¼ŒåŒæ—¶ä¼˜åŒ–äº†ç½‘ç»œç»“æ„ä»¥æé«˜è®¡ç®—æ•ˆç‡å’Œè¯†åˆ«ç²¾åº¦ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œå±‚æ¬¡ç»“æ„åœ¨è®ºæ–‡ä¸­è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CascadeFormeråœ¨Penn Actionã€N-UCLAå’ŒNTU RGB+D 60æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨NTU RGB+D 60æ•°æ®é›†ä¸Šç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æå‡äº†çº¦5%çš„å‡†ç¡®ç‡ï¼Œå±•ç°å‡ºå…¶åœ¨éª¨æ¶åŸºç¡€åŠ¨ä½œè¯†åˆ«ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œç«äº‰åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½ç›‘æ§ã€è™šæ‹Ÿç°å®ã€è¿åŠ¨åˆ†æç­‰ï¼Œèƒ½å¤Ÿä¸ºäººæœºäº¤äº’ã€è¡Œä¸ºè¯†åˆ«å’Œå®‰å…¨ç›‘æ§ç­‰åœºæ™¯æä¾›æ›´ç²¾å‡†çš„æŠ€æœ¯æ”¯æŒã€‚æœªæ¥ï¼ŒCascadeFormerå¯èƒ½æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„è¿›ä¸€æ­¥ç ”ç©¶ä¸åº”ç”¨ï¼Œæå‡è‡ªåŠ¨åŒ–å’Œæ™ºèƒ½åŒ–æ°´å¹³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Skeleton-based human action recognition leverages sequences of human joint coordinates to identify actions performed in videos. Owing to the intrinsic spatiotemporal structure of skeleton data, Graph Convolutional Networks (GCNs) have been the dominant architecture in this field. However, recent advances in transformer models and masked pretraining frameworks open new avenues for representation learning. In this work, we propose CascadeFormer, a family of two-stage cascading transformers for skeleton-based human action recognition. Our framework consists of a masked pretraining stage to learn generalizable skeleton representations, followed by a cascading fine-tuning stage tailored for discriminative action classification. We evaluate CascadeFormer across three benchmark datasets (Penn Action N-UCLA, and NTU RGB+D 60), achieving competitive performance on all tasks. To promote reproducibility, we release our code and model checkpoints.

