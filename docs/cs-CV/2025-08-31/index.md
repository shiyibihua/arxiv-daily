---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-08-31
---

# cs.CVï¼ˆ2025-08-31ï¼‰

ğŸ“Š å…± **21** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (6 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (6 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (6 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction" class="interest-badge">æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (2)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (6 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250900800v1-swagsplatting-semantic-guided-water-scene-augmented-gaussian-splatti.html">SWAGSplatting: Semantic-guided Water-scene Augmented Gaussian Splatting</a></td>
  <td>æå‡ºSWAGSplattingä»¥è§£å†³æ°´ä¸‹ç¯å¢ƒ3Dé‡å»ºé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">gaussian splatting</span> <span class="paper-tag">splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00800v1" data-paper-url="./papers/250900800v1-swagsplatting-semantic-guided-water-scene-augmented-gaussian-splatti.html" onclick="toggleFavorite(this, '2509.00800v1', 'SWAGSplatting: Semantic-guided Water-scene Augmented Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250900911v2-gs-tg-3d-gaussian-splatting-accelerator-with-tile-grouping-for-reduc.html">GS-TG: 3D Gaussian Splatting Accelerator with Tile Grouping for Reducing Redundant Sorting while Preserving Rasterization Efficiency</a></td>
  <td>æå‡ºGS-TGä»¥è§£å†³3D Gaussian Splattingæ¸²æŸ“é€Ÿåº¦ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">gaussian splatting</span> <span class="paper-tag">splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00911v2" data-paper-url="./papers/250900911v2-gs-tg-3d-gaussian-splatting-accelerator-with-tile-grouping-for-reduc.html" onclick="toggleFavorite(this, '2509.00911v2', 'GS-TG: 3D Gaussian Splatting Accelerator with Tile Grouping for Reducing Redundant Sorting while Preserving Rasterization Efficiency')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250900757v1-marksplatter-generalizable-watermarking-for-3d-gaussian-splatting-mo.html">MarkSplatter: Generalizable Watermarking for 3D Gaussian Splatting Model via Splatter Image Structure</a></td>
  <td>æå‡ºMarkSplatterä»¥è§£å†³3D Gaussian Splattingæ¨¡å‹çš„æ°´å°ä¿æŠ¤é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">3DGS</span> <span class="paper-tag">gaussian splatting</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00757v1" data-paper-url="./papers/250900757v1-marksplatter-generalizable-watermarking-for-3d-gaussian-splatting-mo.html" onclick="toggleFavorite(this, '2509.00757v1', 'MarkSplatter: Generalizable Watermarking for 3D Gaussian Splatting Model via Splatter Image Structure')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250900989v1-towards-integrating-multi-spectral-imaging-with-gaussian-splatting.html">Towards Integrating Multi-Spectral Imaging with Gaussian Splatting</a></td>
  <td>æå‡ºå¤šå…‰è°±æˆåƒä¸é«˜æ–¯ç‚¹äº‘èåˆä»¥æå‡3Dé‡å»ºè´¨é‡</td>
  <td class="tags-cell"><span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">3DGS</span> <span class="paper-tag">gaussian splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00989v1" data-paper-url="./papers/250900989v1-towards-integrating-multi-spectral-imaging-with-gaussian-splatting.html" onclick="toggleFavorite(this, '2509.00989v1', 'Towards Integrating Multi-Spectral Imaging with Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250900831v2-upgs-unified-pose-aware-gaussian-splatting-for-dynamic-scene-deblurr.html">UPGS: Unified Pose-aware Gaussian Splatting for Dynamic Scene Deblurring</a></td>
  <td>æå‡ºç»Ÿä¸€å§¿æ€æ„ŸçŸ¥é«˜æ–¯ç‚¹äº‘ä»¥è§£å†³åŠ¨æ€åœºæ™¯å»æ¨¡ç³Šé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">3DGS</span> <span class="paper-tag">gaussian splatting</span> <span class="paper-tag">splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00831v2" data-paper-url="./papers/250900831v2-upgs-unified-pose-aware-gaussian-splatting-for-dynamic-scene-deblurr.html" onclick="toggleFavorite(this, '2509.00831v2', 'UPGS: Unified Pose-aware Gaussian Splatting for Dynamic Scene Deblurring')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250900665v2-er-lora-effective-rank-guided-adaptation-for-weather-generalized-dep.html">ER-LoRA: Effective-Rank Guided Adaptation for Weather-Generalized Depth Estimation</a></td>
  <td>æå‡ºER-LoRAä»¥è§£å†³æ¶åŠ£å¤©æ°”ä¸‹æ·±åº¦ä¼°è®¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">depth estimation</span> <span class="paper-tag">monocular depth</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00665v2" data-paper-url="./papers/250900665v2-er-lora-effective-rank-guided-adaptation-for-weather-generalized-dep.html" onclick="toggleFavorite(this, '2509.00665v2', 'ER-LoRA: Effective-Rank Guided Adaptation for Weather-Generalized Depth Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (6 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>7</td>
  <td><a href="./papers/250900677v1-csfmamba-cross-state-fusion-mamba-operator-for-multimodal-remote-sen.html">CSFMamba: Cross State Fusion Mamba Operator for Multimodal Remote Sensing Image Classification</a></td>
  <td>æå‡ºCSFMambaä»¥è§£å†³å¤šæ¨¡æ€é¥æ„Ÿå›¾åƒåˆ†ç±»ä¸­çš„è®¡ç®—å¤æ‚æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">Mamba</span> <span class="paper-tag">SSM</span> <span class="paper-tag">state space model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00677v1" data-paper-url="./papers/250900677v1-csfmamba-cross-state-fusion-mamba-operator-for-multimodal-remote-sen.html" onclick="toggleFavorite(this, '2509.00677v1', 'CSFMamba: Cross State Fusion Mamba Operator for Multimodal Remote Sensing Image Classification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250900789v1-omnireason-a-temporal-guided-vision-language-action-framework-for-au.html">OmniReason: A Temporal-Guided Vision-Language-Action Framework for Autonomous Driving</a></td>
  <td>æå‡ºOmniReasonæ¡†æ¶ä»¥è§£å†³è‡ªåŠ¨é©¾é©¶ä¸­çš„æ—¶ç©ºæ¨ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">scene understanding</span> <span class="paper-tag">spatiotemporal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00789v1" data-paper-url="./papers/250900789v1-omnireason-a-temporal-guided-vision-language-action-framework-for-au.html" onclick="toggleFavorite(this, '2509.00789v1', 'OmniReason: A Temporal-Guided Vision-Language-Action Framework for Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250900649v1-mv-ssm-multi-view-state-space-modeling-for-3d-human-pose-estimation.html">MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation</a></td>
  <td>æå‡ºMV-SSMæ¡†æ¶ä»¥è§£å†³å¤šè§†è§’3Däººä½“å§¿æ€ä¼°è®¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">Mamba</span> <span class="paper-tag">SSM</span> <span class="paper-tag">state space model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00649v1" data-paper-url="./papers/250900649v1-mv-ssm-multi-view-state-space-modeling-for-3d-human-pose-estimation.html" onclick="toggleFavorite(this, '2509.00649v1', 'MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250900752v1-multi-level-cls-token-fusion-for-contrastive-learning-in-endoscopy-i.html">Multi-Level CLS Token Fusion for Contrastive Learning in Endoscopy Image Classification</a></td>
  <td>æå‡ºå¤šå±‚CLS Tokenèåˆä»¥è§£å†³å†…çª¥é•œå›¾åƒåˆ†ç±»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">contrastive learning</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00752v1" data-paper-url="./papers/250900752v1-multi-level-cls-token-fusion-for-contrastive-learning-in-endoscopy-i.html" onclick="toggleFavorite(this, '2509.00752v1', 'Multi-Level CLS Token Fusion for Contrastive Learning in Endoscopy Image Classification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250900676v1-llava-critic-r1-your-critic-model-is-secretly-a-strong-policy-model.html">LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model</a></td>
  <td>æå‡ºLLaVA-Critic-R1ä»¥ä¼˜åŒ–å¤šæ¨¡æ€ç”Ÿæˆä¸è¯„ä¼°</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00676v1" data-paper-url="./papers/250900676v1-llava-critic-r1-your-critic-model-is-secretly-a-strong-policy-model.html" onclick="toggleFavorite(this, '2509.00676v1', 'LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250900692v1-cascadeformer-a-family-of-two-stage-cascading-transformers-for-skele.html">CascadeFormer: A Family of Two-stage Cascading Transformers for Skeleton-based Human Action Recognition</a></td>
  <td>æå‡ºCascadeFormerä»¥è§£å†³éª¨æ¶åŸºç¡€çš„äººç±»åŠ¨ä½œè¯†åˆ«é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span> <span class="paper-tag">spatiotemporal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00692v1" data-paper-url="./papers/250900692v1-cascadeformer-a-family-of-two-stage-cascading-transformers-for-skele.html" onclick="toggleFavorite(this, '2509.00692v1', 'CascadeFormer: A Family of Two-stage Cascading Transformers for Skeleton-based Human Action Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (6 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/250900798v4-multimodal-iterative-rag-for-knowledge-intensive-visual-question-ans.html">Multimodal Iterative RAG for Knowledge-Intensive Visual Question Answering</a></td>
  <td>æå‡ºMI-RAGæ¡†æ¶ä»¥è§£å†³çŸ¥è¯†å¯†é›†å‹è§†è§‰é—®ç­”ä¸­çš„çŸ¥è¯†è·å–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00798v4" data-paper-url="./papers/250900798v4-multimodal-iterative-rag-for-knowledge-intensive-visual-question-ans.html" onclick="toggleFavorite(this, '2509.00798v4', 'Multimodal Iterative RAG for Knowledge-Intensive Visual Question Answering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250900664v1-fusion-to-enhance-fusion-visual-encoder-to-enhance-multimodal-langua.html">Fusion to Enhance: Fusion Visual Encoder to Enhance Multimodal Language Model</a></td>
  <td>æå‡ºFusion to Enhanceä»¥è§£å†³å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„è§†è§‰æ„ŸçŸ¥ç“¶é¢ˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00664v1" data-paper-url="./papers/250900664v1-fusion-to-enhance-fusion-visual-encoder-to-enhance-multimodal-langua.html" onclick="toggleFavorite(this, '2509.00664v1', 'Fusion to Enhance: Fusion Visual Encoder to Enhance Multimodal Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250900946v1-ultrasound-based-detection-and-malignancy-prediction-of-breast-lesio.html">Ultrasound-based detection and malignancy prediction of breast lesions eligible for biopsy: A multi-center clinical-scenario study using nomograms, large language models, and radiologist evaluation</a></td>
  <td>æå‡ºç»¼åˆè¶…å£°nomogramä»¥æé«˜ä¹³è…ºç—…å˜æ´»æ£€æ¨èå‡†ç¡®æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00946v1" data-paper-url="./papers/250900946v1-ultrasound-based-detection-and-malignancy-prediction-of-breast-lesio.html" onclick="toggleFavorite(this, '2509.00946v1', 'Ultrasound-based detection and malignancy prediction of breast lesions eligible for biopsy: A multi-center clinical-scenario study using nomograms, large language models, and radiologist evaluation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250900787v3-image-to-brain-signal-generation-for-visual-prosthesis-with-clip-gui.html">Image-to-Brain Signal Generation for Visual Prosthesis with CLIP Guided Multimodal Diffusion Models</a></td>
  <td>æå‡ºå›¾åƒåˆ°è„‘ä¿¡å·ç”Ÿæˆæ¡†æ¶ä»¥è§£å†³è§†è§‰å‡ä½“çš„ç¼–ç é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00787v3" data-paper-url="./papers/250900787v3-image-to-brain-signal-generation-for-visual-prosthesis-with-clip-gui.html" onclick="toggleFavorite(this, '2509.00787v3', 'Image-to-Brain Signal Generation for Visual Prosthesis with CLIP Guided Multimodal Diffusion Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250900751v1-event-retriever-event-aware-multimodal-image-retrieval-for-realistic.html">EVENT-Retriever: Event-Aware Multimodal Image Retrieval for Realistic Captions</a></td>
  <td>æå‡ºEVENT-Retrieverä»¥è§£å†³åŸºäºäº‹ä»¶çš„å¤šæ¨¡æ€å›¾åƒæ£€ç´¢é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00751v1" data-paper-url="./papers/250900751v1-event-retriever-event-aware-multimodal-image-retrieval-for-realistic.html" onclick="toggleFavorite(this, '2509.00751v1', 'EVENT-Retriever: Event-Aware Multimodal Image Retrieval for Realistic Captions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250900700v2-prompt-the-unseen-evaluating-visual-language-alignment-beyond-superv.html">Prompt the Unseen: Evaluating Visual-Language Alignment Beyond Supervision</a></td>
  <td>æå‡ºæ–°åŸºå‡†ä»¥è¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹çš„æŠ•å½±å±‚æ³›åŒ–èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00700v2" data-paper-url="./papers/250900700v2-prompt-the-unseen-evaluating-visual-language-alignment-beyond-superv.html" onclick="toggleFavorite(this, '2509.00700v2', 'Prompt the Unseen: Evaluating Visual-Language Alignment Beyond Supervision')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction">ğŸ”¬ æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>19</td>
  <td><a href="./papers/250900760v1-no-more-sibling-rivalry-debiasing-human-object-interaction-detection.html">No More Sibling Rivalry: Debiasing Human-Object Interaction Detection</a></td>
  <td>æå‡ºæ–°æ–¹æ³•ä»¥è§£å†³äººæœºäº¤äº’æ£€æµ‹ä¸­çš„åè§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">human-object interaction</span> <span class="paper-tag">HOI</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00760v1" data-paper-url="./papers/250900760v1-no-more-sibling-rivalry-debiasing-human-object-interaction-detection.html" onclick="toggleFavorite(this, '2509.00760v1', 'No More Sibling Rivalry: Debiasing Human-Object Interaction Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250900781v1-secure-and-scalable-face-retrieval-via-cancelable-product-quantizati.html">Secure and Scalable Face Retrieval via Cancelable Product Quantization</a></td>
  <td>æå‡ºå¯å–æ¶ˆçš„äº§å“é‡åŒ–ä»¥è§£å†³äººè„¸æ£€ç´¢éšç§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">OMOMO</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00781v1" data-paper-url="./papers/250900781v1-secure-and-scalable-face-retrieval-via-cancelable-product-quantizati.html" onclick="toggleFavorite(this, '2509.00781v1', 'Secure and Scalable Face Retrieval via Cancelable Product Quantization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/250900767v2-interpose-learning-to-generate-human-object-interactions-from-large-.html">InterPose: Learning to Generate Human-Object Interactions from Large-Scale Web Videos</a></td>
  <td>æå‡ºInterPoseä»¥è§£å†³å¤æ‚åœºæ™¯ä¸­äººæœºäº¤äº’ç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">motion generation</span> <span class="paper-tag">human-object interaction</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00767v2" data-paper-url="./papers/250900767v2-interpose-learning-to-generate-human-object-interactions-from-large-.html" onclick="toggleFavorite(this, '2509.00767v2', 'InterPose: Learning to Generate Human-Object Interactions from Large-Scale Web Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)