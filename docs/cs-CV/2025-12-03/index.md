---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-12-03
---

# cs.CVï¼ˆ2025-12-03ï¼‰

ğŸ“Š å…± **29** ç¯‡è®ºæ–‡
 | ğŸ”— **6** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (14 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (6 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (5 ğŸ”—2)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (2 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting" class="interest-badge">æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (14 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251204021v1-c3g-learning-compact-3d-representations-with-2k-gaussians.html">C3G: Learning Compact 3D Representations with 2K Gaussians</a></td>
  <td>C3Gï¼šä½¿ç”¨2Ké«˜æ–¯å­¦ä¹ ç´§å‡‘çš„3Dè¡¨ç¤ºï¼Œæå‡åœºæ™¯é‡å»ºä¸ç†è§£</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04021v1" onclick="toggleFavorite(this, '2512.04021v1', 'C3G: Learning Compact 3D Representations with 2K Gaussians')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251203601v1-motion4d-learning-3d-consistent-motion-and-semantics-for-4d-scene-un.html">Motion4D: Learning 3D-Consistent Motion and Semantics for 4D Scene Understanding</a></td>
  <td>Motion4Dï¼šå­¦ä¹ 3Dä¸€è‡´çš„è¿åŠ¨å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œç”¨äº4Dåœºæ™¯ç†è§£</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03601v1" onclick="toggleFavorite(this, '2512.03601v1', 'Motion4D: Learning 3D-Consistent Motion and Semantics for 4D Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251204315v1-synctrack4d-cross-video-motion-alignment-and-video-synchronization-f.html">SyncTrack4D: Cross-Video Motion Alignment and Video Synchronization for Multi-Video 4D Gaussian Splatting</a></td>
  <td>SyncTrack4Dï¼šé¢å‘æœªåŒæ­¥å¤šè§†è§’è§†é¢‘çš„4Dé«˜æ–¯æº…å°„åŠ¨æ€åœºæ™¯é‡å»ºã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04315v1" onclick="toggleFavorite(this, '2512.04315v1', 'SyncTrack4D: Cross-Video Motion Alignment and Video Synchronization for Multi-Video 4D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251203598v1-memory-guided-point-cloud-completion-for-dental-reconstruction.html">Memory-Guided Point Cloud Completion for Dental Reconstruction</a></td>
  <td>æå‡ºåŸºäºè®°å¿†å¼•å¯¼çš„ç‚¹äº‘è¡¥å…¨æ¡†æ¶ï¼Œç”¨äºç‰™ç§‘é‡å»ºï¼Œæå‡è¡¥å…¨ç²¾åº¦ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03598v1" onclick="toggleFavorite(this, '2512.03598v1', 'Memory-Guided Point Cloud Completion for Dental Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251204313v1-mind-to-face-neural-driven-photorealistic-avatar-synthesis-via-eeg-d.html">Mind-to-Face: Neural-Driven Photorealistic Avatar Synthesis via EEG Decoding</a></td>
  <td>Mind-to-Faceï¼šé¦–ä¸ªåŸºäºè„‘ç”µä¿¡å·è§£ç çš„é€¼çœŸäººè„¸Avatarç”Ÿæˆæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04313v1" onclick="toggleFavorite(this, '2512.04313v1', 'Mind-to-Face: Neural-Driven Photorealistic Avatar Synthesis via EEG Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251204248v1-mvroom-controllable-3d-indoor-scene-generation-with-multi-view-diffu.html">MVRoom: Controllable 3D Indoor Scene Generation with Multi-View Diffusion Models</a></td>
  <td>MVRoomï¼šåŸºäºå¤šè§†è§’æ‰©æ•£æ¨¡å‹çš„å¯æ§3Då®¤å†…åœºæ™¯ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04248v1" onclick="toggleFavorite(this, '2512.04248v1', 'MVRoom: Controllable 3D Indoor Scene Generation with Multi-View Diffusion Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251204012v1-emergent-outlier-view-rejection-in-visual-geometry-grounded-transfor.html">Emergent Outlier View Rejection in Visual Geometry Grounded Transformers</a></td>
  <td>å‘ç°VGGTä¸­éšå«çš„ç¦»ç¾¤ç‚¹æŠ‘åˆ¶èƒ½åŠ›ï¼Œæå‡é‡å¤–å›¾åƒä¸‰ç»´é‡å»ºé²æ£’æ€§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04012v1" onclick="toggleFavorite(this, '2512.04012v1', 'Emergent Outlier View Rejection in Visual Geometry Grounded Transformers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251203621v1-recamdriving-lidar-free-camera-controlled-novel-trajectory-video-gen.html">ReCamDriving: LiDAR-Free Camera-Controlled Novel Trajectory Video Generation</a></td>
  <td>æå‡ºReCamDrivingï¼Œä¸€ç§çº¯è§†è§‰ç›¸æœºæ§åˆ¶çš„æ–°è½¨è¿¹è§†é¢‘ç”Ÿæˆæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03621v1" onclick="toggleFavorite(this, '2512.03621v1', 'ReCamDriving: LiDAR-Free Camera-Controlled Novel Trajectory Video Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251203590v1-beyond-boundary-frames-audio-visual-semantic-guidance-for-context-aw.html">Beyond Boundary Frames: Audio-Visual Semantic Guidance for Context-Aware Video Interpolation</a></td>
  <td>æå‡ºBBFæ¡†æ¶ï¼Œåˆ©ç”¨éŸ³è§†é¢‘è¯­ä¹‰æŒ‡å¯¼ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è§†é¢‘æ’å¸§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03590v1" onclick="toggleFavorite(this, '2512.03590v1', 'Beyond Boundary Frames: Audio-Visual Semantic Guidance for Context-Aware Video Interpolation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251203566v1-gaot-generating-articulated-objects-through-text-guided-diffusion-mo.html">GAOT: Generating Articulated Objects Through Text-Guided Diffusion Models</a></td>
  <td>GAOTï¼šæå‡ºåŸºäºæ–‡æœ¬å¼•å¯¼æ‰©æ•£æ¨¡å‹çš„é“°æ¥ç‰©ä½“ç”Ÿæˆæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03566v1" onclick="toggleFavorite(this, '2512.03566v1', 'GAOT: Generating Articulated Objects Through Text-Guided Diffusion Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251203558v1-cartomapqa-a-fundamental-benchmark-dataset-evaluating-vision-languag.html">CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding</a></td>
  <td>CartoMapQAï¼šæå‡ºç”¨äºè¯„ä¼°è§†è§‰-è¯­è¨€æ¨¡å‹åœ°å›¾ç†è§£èƒ½åŠ›çš„åŸºç¡€åŸºå‡†æ•°æ®é›†ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03558v1" onclick="toggleFavorite(this, '2512.03558v1', 'CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251203532v1-opentrack3d-towards-accurate-and-generalizable-open-vocabulary-3d-in.html">OpenTrack3D: Towards Accurate and Generalizable Open-Vocabulary 3D Instance Segmentation</a></td>
  <td>OpenTrack3Dï¼šé¢å‘ç²¾ç¡®å’Œæ³›åŒ–çš„å¼€æ”¾è¯æ±‡3Då®ä¾‹åˆ†å‰²</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03532v1" onclick="toggleFavorite(this, '2512.03532v1', 'OpenTrack3D: Towards Accurate and Generalizable Open-Vocabulary 3D Instance Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251203509v1-afrobeats-dance-movement-analysis-using-computer-vision-a-proof-of-c.html">AfroBeats Dance Movement Analysis Using Computer Vision: A Proof-of-Concept Framework Combining YOLO and Segment Anything Model</a></td>
  <td>æå‡ºç»“åˆYOLOå’ŒSAMçš„AfroBeatsèˆè¹ˆåŠ¨ä½œåˆ†ææ¡†æ¶ï¼Œæ— éœ€ä¸“ä¸šè®¾å¤‡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03509v1" onclick="toggleFavorite(this, '2512.03509v1', 'AfroBeats Dance Movement Analysis Using Computer Vision: A Proof-of-Concept Framework Combining YOLO and Segment Anything Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251203500v1-eea-exploration-exploitation-agent-for-long-video-understanding.html">EEA: Exploration-Exploitation Agent for Long Video Understanding</a></td>
  <td>æå‡ºEEAï¼šä¸€ç§ç”¨äºé•¿è§†é¢‘ç†è§£çš„æ¢ç´¢-åˆ©ç”¨æ™ºèƒ½ä½“æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03500v1" onclick="toggleFavorite(this, '2512.03500v1', 'EEA: Exploration-Exploitation Agent for Long Video Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (6 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>15</td>
  <td><a href="./papers/251203577v1-cross-stain-contrastive-learning-for-paired-immunohistochemistry-and.html">Cross-Stain Contrastive Learning for Paired Immunohistochemistry and Histopathology Slide Representation Learning</a></td>
  <td>æå‡ºCross-Stain Contrastive Learningæ¡†æ¶ï¼Œè§£å†³å¤šæŸ“è‰²ç—…ç†åˆ‡ç‰‡è¡¨ç¤ºå­¦ä¹ ä¸­çš„å¯¹é½é—®é¢˜ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03577v1" onclick="toggleFavorite(this, '2512.03577v1', 'Cross-Stain Contrastive Learning for Paired Immunohistochemistry and Histopathology Slide Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251203963v2-tempr1-improving-temporal-understanding-of-mllms-via-temporal-aware-.html">TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning</a></td>
  <td>æå‡ºTempR1ï¼Œé€šè¿‡æ—¶åºæ„ŸçŸ¥å¤šä»»åŠ¡å¼ºåŒ–å­¦ä¹ æå‡MLLMå¯¹é•¿è§†é¢‘çš„æ—¶åºç†è§£èƒ½åŠ›ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03963v2" onclick="toggleFavorite(this, '2512.03963v2', 'TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251204040v1-relic-interactive-video-world-model-with-long-horizon-memory.html">RELIC: Interactive Video World Model with Long-Horizon Memory</a></td>
  <td>RELICï¼šåŸºäºé•¿æ—¶è®°å¿†çš„äº¤äº’å¼è§†é¢‘ä¸–ç•Œæ¨¡å‹ï¼Œå®ç°å®æ—¶åœºæ™¯æ¢ç´¢</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04040v1" onclick="toggleFavorite(this, '2512.04040v1', 'RELIC: Interactive Video World Model with Long-Horizon Memory')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251204007v2-on-the-temporality-for-sketch-representation-learning.html">On the Temporality for Sketch Representation Learning</a></td>
  <td>ç ”ç©¶è‰å›¾è¡¨ç¤ºå­¦ä¹ ä¸­æ—¶åºæ€§çš„å½±å“ï¼Œæ­ç¤ºæœ€ä¼˜å»ºæ¨¡æ–¹å¼ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04007v2" onclick="toggleFavorite(this, '2512.04007v2', 'On the Temporality for Sketch Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251203852v1-traffic-image-restoration-under-adverse-weather-via-frequency-aware-.html">Traffic Image Restoration under Adverse Weather via Frequency-Aware Mamba</a></td>
  <td>æå‡ºé¢‘ç‡æ„ŸçŸ¥Mambaï¼ˆFAMambaï¼‰ç”¨äºæ¶åŠ£å¤©æ°”ä¸‹çš„äº¤é€šå›¾åƒæ¢å¤ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03852v1" onclick="toggleFavorite(this, '2512.03852v1', 'Traffic Image Restoration under Adverse Weather via Frequency-Aware Mamba')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251204085v1-unique-lives-shared-world-learning-from-single-life-videos.html">Unique Lives, Shared World: Learning from Single-Life Videos</a></td>
  <td>æå‡ºå•ä¸€ç”Ÿæ¶¯å­¦ä¹ èŒƒå¼ï¼Œåˆ©ç”¨ä¸ªä½“ç”Ÿæ´»è§†é¢‘è‡ªç›‘ç£å­¦ä¹ é€šç”¨è§†è§‰è¡¨å¾ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04085v1" onclick="toggleFavorite(this, '2512.04085v1', 'Unique Lives, Shared World: Learning from Single-Life Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/251204303v1-gamma-from-mono-road-relative-metric-self-supervised-monocular-geome.html">Gamma-from-Mono: Road-Relative, Metric, Self-Supervised Monocular Geometry for Vehicular Applications</a></td>
  <td>æå‡ºGamma-from-Monoï¼Œç”¨äºè½¦è¾†åº”ç”¨ä¸­é“è·¯ç›¸å¯¹ã€åº¦é‡ã€è‡ªç›‘ç£å•ç›®å‡ ä½•ä¼°è®¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04303v1" onclick="toggleFavorite(this, '2512.04303v1', 'Gamma-from-Mono: Road-Relative, Metric, Self-Supervised Monocular Geometry for Vehicular Applications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251203619v2-lamp-language-assisted-motion-planning-for-controllable-video-genera.html">LAMP: Language-Assisted Motion Planning for Controllable Video Generation</a></td>
  <td>LAMPï¼šåˆ©ç”¨è¯­è¨€è¾…åŠ©çš„è¿åŠ¨è§„åˆ’å®ç°å¯æ§è§†é¢‘ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03619v2" onclick="toggleFavorite(this, '2512.03619v2', 'LAMP: Language-Assisted Motion Planning for Controllable Video Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/251204069v1-spacetools-tool-augmented-spatial-reasoning-via-double-interactive-r.html">SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL</a></td>
  <td>SpaceToolsï¼šé€šè¿‡åŒé‡äº¤äº’å¼ºåŒ–å­¦ä¹ å¢å¼ºå·¥å…·è¾…åŠ©çš„ç©ºé—´æ¨ç†èƒ½åŠ›</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04069v1" onclick="toggleFavorite(this, '2512.04069v1', 'SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/251206013v1-vat-vision-action-transformer-by-unlocking-full-representation-of-vi.html">VAT: Vision Action Transformer by Unlocking Full Representation of ViT</a></td>
  <td>æå‡ºVision Action Transformer (VAT)ï¼Œå……åˆ†åˆ©ç”¨ViTå„å±‚ç‰¹å¾è¿›è¡Œæœºå™¨äººåŠ¨ä½œå­¦ä¹ ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.06013v1" onclick="toggleFavorite(this, '2512.06013v1', 'VAT: Vision Action Transformer by Unlocking Full Representation of ViT')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/251203724v2-posa-vla-enhancing-action-generation-via-pose-conditioned-anchor-att.html">PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention</a></td>
  <td>PosA-VLAï¼šé€šè¿‡å§¿æ€æ¡ä»¶é”šç‚¹æ³¨æ„åŠ›å¢å¼ºå…·èº«ä»»åŠ¡ä¸­çš„åŠ¨ä½œç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03724v2" onclick="toggleFavorite(this, '2512.03724v2', 'PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>26</td>
  <td><a href="./papers/251203520v1-flooddiffusion-tailored-diffusion-forcing-for-streaming-motion-gener.html">FloodDiffusion: Tailored Diffusion Forcing for Streaming Motion Generation</a></td>
  <td>FloodDiffusionï¼šç”¨äºæµå¼è¿åŠ¨ç”Ÿæˆçš„å®šåˆ¶æ‰©æ•£å¼ºåˆ¶æ¡†æ¶</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03520v1" onclick="toggleFavorite(this, '2512.03520v1', 'FloodDiffusion: Tailored Diffusion Forcing for Streaming Motion Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/251203918v1-unimo-unifying-2d-video-and-3d-human-motion-with-an-autoregressive-f.html">UniMo: Unifying 2D Video and 3D Human Motion with an Autoregressive Framework</a></td>
  <td>UniMoï¼šæå‡ºä¸€ä¸ªè‡ªå›å½’æ¡†æ¶ï¼Œç»Ÿä¸€å»ºæ¨¡2Dè§†é¢‘å’Œ3Däººä½“è¿åŠ¨ï¼Œå®ç°åŒæ­¥ç”Ÿæˆä¸ç†è§£ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03918v1" onclick="toggleFavorite(this, '2512.03918v1', 'UniMo: Unifying 2D Video and 3D Human Motion with an Autoregressive Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting">ğŸ”¬ æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>28</td>
  <td><a href="./papers/251204282v1-inference-time-stochastic-refinement-of-gru-normalizing-flow-for-rea.html">Inference-time Stochastic Refinement of GRU-Normalizing Flow for Real-time Video Motion Transfer</a></td>
  <td>æå‡ºGRU-SNFï¼Œé€šè¿‡æ¨ç†æ—¶éšæœºç»†åŒ–GRU-NFï¼Œå®ç°å®æ—¶è§†é¢‘è¿åŠ¨è¿ç§»ä¸­å¤šæ ·æ€§é¢„æµ‹ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04282v1" onclick="toggleFavorite(this, '2512.04282v1', 'Inference-time Stochastic Refinement of GRU-Normalizing Flow for Real-time Video Motion Transfer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>29</td>
  <td><a href="./papers/251203848v1-pulse-a-unified-multi-task-architecture-for-cardiac-segmentation-dia.html">PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation</a></td>
  <td>PULSEï¼šç»Ÿä¸€å¤šä»»åŠ¡æ¶æ„ï¼Œç”¨äºå¿ƒè„åˆ†å‰²ã€è¯Šæ–­å’Œå°‘æ ·æœ¬è·¨æ¨¡æ€ä¸´åºŠè‡ªé€‚åº”</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.03848v1" onclick="toggleFavorite(this, '2512.03848v1', 'PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)