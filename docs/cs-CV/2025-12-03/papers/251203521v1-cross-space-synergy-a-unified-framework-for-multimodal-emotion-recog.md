---
layout: default
title: Cross-Space Synergy: A Unified Framework for Multimodal Emotion Recognition in Conversation
---

# Cross-Space Synergy: A Unified Framework for Multimodal Emotion Recognition in Conversation

**arXiv**: [2512.03521v1](https://arxiv.org/abs/2512.03521) | [PDF](https://arxiv.org/pdf/2512.03521.pdf)

**ä½œè€…**: Xiaosen Lyu, Jiayu Xiong, Yuren Chen, Wanlong Wang, Xiaoqing Dai, Jing Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCross-Space Synergyæ¡†æž¶ï¼Œé€šè¿‡ååŒè¡¨ç¤ºä¸Žä¼˜åŒ–è§£å†³å¤šæ¨¡æ€å¯¹è¯æƒ…æ„Ÿè¯†åˆ«ä¸­çš„äº¤äº’ä¸Žè®­ç»ƒé—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«` `å¯¹è¯æƒ…æ„Ÿåˆ†æž` `è·¨æ¨¡æ€äº¤äº’` `æ¢¯åº¦ä¼˜åŒ–` `å¸•ç´¯æ‰˜æœ€ä¼˜` `ä½Žç§©å¼ é‡åˆ†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•éš¾ä»¥æ•æ‰å¤æ‚è·¨æ¨¡æ€äº¤äº’ï¼Œä¸”æ·±å±‚æž¶æž„æ˜“å¯¼è‡´æ¢¯åº¦å†²çªä¸Žè®­ç»ƒä¸ç¨³å®šã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆSynergistic Polynomial Fusioné«˜æ•ˆå»ºæ¨¡é«˜é˜¶è·¨æ¨¡æ€äº¤äº’ï¼ŒPareto Gradient Modulatoræ²¿å¸•ç´¯æ‰˜æœ€ä¼˜æ–¹å‘ä¼˜åŒ–ä»¥ç¼“è§£æ¢¯åº¦å†²çªã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨IEMOCAPå’ŒMELDæ•°æ®é›†ä¸Šè¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œæå‡å‡†ç¡®çŽ‡ä¸Žè®­ç»ƒç¨³å®šæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal Emotion Recognition in Conversation (MERC) aims to predict speakers' emotions by integrating textual, acoustic, and visual cues. Existing approaches either struggle to capture complex cross-modal interactions or experience gradient conflicts and unstable training when using deeper architectures. To address these issues, we propose Cross-Space Synergy (CSS), which couples a representation component with an optimization component. Synergistic Polynomial Fusion (SPF) serves the representation role, leveraging low-rank tensor factorization to efficiently capture high-order cross-modal interactions. Pareto Gradient Modulator (PGM) serves the optimization role, steering updates along Pareto-optimal directions across competing objectives to alleviate gradient conflicts and improve stability. Experiments show that CSS outperforms existing representative methods on IEMOCAP and MELD in both accuracy and training stability, demonstrating its effectiveness in complex multimodal scenarios.

