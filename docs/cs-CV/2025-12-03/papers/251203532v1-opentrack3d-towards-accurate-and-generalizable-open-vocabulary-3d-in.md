---
layout: default
title: OpenTrack3D: Towards Accurate and Generalizable Open-Vocabulary 3D Instance Segmentation
---

# OpenTrack3D: Towards Accurate and Generalizable Open-Vocabulary 3D Instance Segmentation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.03532" target="_blank" class="toolbar-btn">arXiv: 2512.03532v1</a>
    <a href="https://arxiv.org/pdf/2512.03532.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.03532v1" 
            onclick="toggleFavorite(this, '2512.03532v1', 'OpenTrack3D: Towards Accurate and Generalizable Open-Vocabulary 3D Instance Segmentation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Zhishan Zhou, Siyuan Wei, Zengran Wang, Chunjie Wang, Xiaosheng Yan, Xiao Liu

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-03

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**OpenTrack3DÔºöÈù¢ÂêëÁ≤æÁ°ÆÂíåÊ≥õÂåñÁöÑÂºÄÊîæËØçÊ±á3DÂÆû‰æãÂàÜÂâ≤**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ÂºÄÊîæËØçÊ±á3DÂÆû‰æãÂàÜÂâ≤` `Êó†ÁΩëÊ†ºÊñπÊ≥ï` `ËßÜËßâ-Á©∫Èó¥Ë∑üË∏™` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `Êú∫Âô®‰∫∫` `AR/VR` `DINOÁâπÂæÅ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂºÄÊîæËØçÊ±á3DÂÆû‰æãÂàÜÂâ≤ÊñπÊ≥ï‰æùËµñÊï∞ÊçÆÈõÜÁâπÂÆöproposalÁΩëÁªúÊàñÁΩëÊ†ºÔºåÊ≥õÂåñÊÄßÂèóÈôêÔºå‰∏îCLIPÊñáÊú¨Êé®ÁêÜËÉΩÂäõÂº±ÔºåÈöæ‰ª•Â§ÑÁêÜÂ§çÊùÇÊü•ËØ¢„ÄÇ
2. OpenTrack3DÊèêÂá∫‰∏ÄÁßçÊñ∞È¢ñÁöÑËßÜËßâ-Á©∫Èó¥Ë∑üË∏™Âô®ÔºåÂú®Á∫øÊûÑÂª∫Ë∑®ËßÜÂõæ‰∏ÄËá¥ÁöÑÂØπË±°proposalÔºåÂπ∂Áî®MLLMÂ¢ûÂº∫ÁªÑÂêàÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. Âú®ScanNet200Á≠âÂ§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÔºåOpenTrack3DÂèñÂæó‰∫Üstate-of-the-artÁöÑÊÄßËÉΩÔºåÂπ∂Â±ïÁé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â∞ÜÂºÄÊîæËØçÊ±á3DÂÆû‰æãÂàÜÂâ≤ÔºàOV-3DISÔºâÊé®ÂπøÂà∞Â§öÊ†∑„ÄÅÈùûÁªìÊûÑÂåñÂíåÊó†ÁΩëÊ†ºÁéØÂ¢ÉÂØπ‰∫éÊú∫Âô®‰∫∫ÂíåAR/VRËá≥ÂÖ≥ÈáçË¶ÅÔºå‰ΩÜ‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÈáçÂ§ßÊåëÊàò„ÄÇÊàë‰ª¨ËÆ§‰∏∫ËøôÂΩíÂõ†‰∫éÁé∞ÊúâÊñπÊ≥ïÁöÑ‰∏§‰∏™ÂÖ≥ÈîÆÈôêÂà∂ÔºöÔºà1ÔºâproposalÁîüÊàê‰æùËµñ‰∫éÊï∞ÊçÆÈõÜÁâπÂÆöÁöÑproposalÁΩëÁªúÊàñÂü∫‰∫éÁΩëÊ†ºÁöÑË∂ÖÁÇπÔºå‰ΩøÂÖ∂‰∏çÈÄÇÁî®‰∫éÊó†ÁΩëÊ†ºÂú∫ÊôØÔºåÂπ∂ÈôêÂà∂‰∫ÜÂØπÊñ∞Âú∫ÊôØÁöÑÊ≥õÂåñÔºõÔºà2ÔºâÂü∫‰∫éCLIPÁöÑÂàÜÁ±ªÂô®Âú®ÊñáÊú¨Êé®ÁêÜÊñπÈù¢ÁöÑ‰∏çË∂≥ÔºåÈöæ‰ª•ËØÜÂà´ÁªÑÂêàÂíåÂäüËÉΩÊÄßÁî®Êà∑Êü•ËØ¢„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜOpenTrack3DÔºå‰∏Ä‰∏™ÈÄöÁî®‰∏îÁ≤æÁ°ÆÁöÑÊ°ÜÊû∂„ÄÇ‰∏é‰æùËµñ‰∫éÈ¢ÑÁîüÊàêproposalÁöÑÊñπÊ≥ï‰∏çÂêåÔºåOpenTrack3DÈááÁî®‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑËßÜËßâ-Á©∫Èó¥Ë∑üË∏™Âô®Êù•Âú®Á∫øÊûÑÂª∫Ë∑®ËßÜÂõæ‰∏ÄËá¥ÁöÑÂØπË±°proposal„ÄÇÁªôÂÆöRGB-DÊµÅÔºåÊàë‰ª¨ÁöÑpipelineÈ¶ñÂÖàÂà©Áî®2DÂºÄÊîæËØçÊ±áÂàÜÂâ≤Âô®ÁîüÊàêmaskÔºåÁÑ∂Âêé‰ΩøÁî®Ê∑±Â∫¶‰ø°ÊÅØÂ∞ÜÂÖ∂ÊèêÂçáÂà∞3DÁÇπ‰∫ë„ÄÇÁÑ∂Âêé‰ΩøÁî®DINOÁâπÂæÅÂõæÊèêÂèñmaskÂºïÂØºÁöÑÂÆû‰æãÁâπÂæÅÔºåÊàë‰ª¨ÁöÑË∑üË∏™Âô®ËûçÂêàËßÜËßâÂíåÁ©∫Èó¥Á∫øÁ¥¢‰ª•‰øùÊåÅÂÆû‰æã‰∏ÄËá¥ÊÄß„ÄÇÊ†∏ÂøÉpipelineÂÆåÂÖ®ÊòØÊó†ÁΩëÊ†ºÁöÑÔºå‰ΩÜÊàë‰ª¨‰πüÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂèØÈÄâÁöÑË∂ÖÁÇπÁªÜÂåñÊ®°ÂùóÔºå‰ª•Âú®Âú∫ÊôØÁΩëÊ†ºÂèØÁî®Êó∂Ëøõ‰∏ÄÊ≠•ÊèêÈ´òÊÄßËÉΩ„ÄÇÊúÄÂêéÔºåÊàë‰ª¨Áî®Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÊõøÊç¢CLIPÔºåÊòæËëóÂ¢ûÂº∫‰∫ÜÂ§çÊùÇÁî®Êà∑Êü•ËØ¢ÁöÑÁªÑÂêàÊé®ÁêÜËÉΩÂäõ„ÄÇÂú®ÂåÖÊã¨ScanNet200„ÄÅReplica„ÄÅScanNet++ÂíåSceneFun3DÂú®ÂÜÖÁöÑÂêÑÁßçbenchmark‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂÖ∑ÊúâÊúÄÂÖàËøõÁöÑÊÄßËÉΩÂíåÂº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂºÄÊîæËØçÊ±á3DÂÆû‰æãÂàÜÂâ≤ÔºàOV-3DISÔºâÂú®Â§öÊ†∑„ÄÅÈùûÁªìÊûÑÂåñÂíåÊó†ÁΩëÊ†ºÁéØÂ¢É‰∏ãÁöÑÊ≥õÂåñÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰æùËµñ‰∫éÊï∞ÊçÆÈõÜÁâπÂÆöÁöÑproposalÁΩëÁªúÊàñÂü∫‰∫éÁΩëÊ†ºÁöÑË∂ÖÁÇπÔºåÂØºËá¥Êó†Ê≥ïÂ∫îÁî®‰∫éÊó†ÁΩëÊ†ºÂú∫ÊôØÔºåÂπ∂‰∏îÂü∫‰∫éCLIPÁöÑÂàÜÁ±ªÂô®Âú®Â§ÑÁêÜÂ§çÊùÇÁöÑÁî®Êà∑Êü•ËØ¢Êó∂Ë°®Áé∞‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöOpenTrack3DÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøá‰∏Ä‰∏™ËßÜËßâ-Á©∫Èó¥Ë∑üË∏™Âô®Âú®Á∫øÁîüÊàêË∑®ËßÜÂõæ‰∏ÄËá¥ÁöÑÂØπË±°proposalÔºåÈÅøÂÖç‰∫ÜÂØπÈ¢ÑÂÆö‰πâproposalÁöÑ‰æùËµñ„ÄÇÂêåÊó∂Ôºå‰ΩøÁî®Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÊõøÊç¢CLIPÔºå‰ª•Â¢ûÂº∫ÂØπÂ§çÊùÇÁî®Êà∑Êü•ËØ¢ÁöÑÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöOpenTrack3DÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) ‰ΩøÁî®2DÂºÄÊîæËØçÊ±áÂàÜÂâ≤Âô®‰ªéRGB-DÊµÅ‰∏≠ÁîüÊàêmaskÔºõ2) Âà©Áî®Ê∑±Â∫¶‰ø°ÊÅØÂ∞Ü2D maskÊèêÂçáÂà∞3DÁÇπ‰∫ëÔºõ3) ‰ΩøÁî®DINOÁâπÂæÅÂõæÊèêÂèñmaskÂºïÂØºÁöÑÂÆû‰æãÁâπÂæÅÔºõ4) ‰ΩøÁî®ËßÜËßâ-Á©∫Èó¥Ë∑üË∏™Âô®ËûçÂêàËßÜËßâÂíåÁ©∫Èó¥Á∫øÁ¥¢Ôºå‰øùÊåÅÂÆû‰æã‰∏ÄËá¥ÊÄßÔºõ5) (ÂèØÈÄâ) ‰ΩøÁî®Ë∂ÖÁÇπÁªÜÂåñÊ®°ÂùóËøõ‰∏ÄÊ≠•ÊèêÈ´òÊÄßËÉΩÔºàÂΩìÂú∫ÊôØÁΩëÊ†ºÂèØÁî®Êó∂ÔºâÔºõ6) ‰ΩøÁî®MLLMËøõË°åÊúÄÁªàÁöÑÂÆû‰æãÂàÜÁ±ª„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöOpenTrack3DÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êó†ÁΩëÊ†ºÁöÑËßÜËßâ-Á©∫Èó¥Ë∑üË∏™Âô®ÔºåËÉΩÂ§üÂú®Á∫øÁîüÊàêÈ´òË¥®ÈáèÁöÑÂØπË±°proposalÔºåÈÅøÂÖç‰∫ÜÂØπÈ¢ÑÂÆö‰πâproposalÁöÑ‰æùËµñÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊ≥õÂåñËÉΩÂäõÔºõ2) ‰ΩøÁî®MLLMÊõøÊç¢CLIPÔºåÊòæËëóÂ¢ûÂº∫‰∫ÜÂØπÂ§çÊùÇÁî®Êà∑Êü•ËØ¢ÁöÑÁªÑÂêàÊé®ÁêÜËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËßÜËßâ-Á©∫Èó¥Ë∑üË∏™Âô®ËûçÂêà‰∫ÜËßÜËßâÁâπÂæÅÔºàDINOÁâπÂæÅÔºâÂíåÁ©∫Èó¥‰ø°ÊÅØÔºàÁÇπ‰∫ëÂùêÊ†áÔºâÔºåÈÄöËøáÂç°Â∞îÊõºÊª§Ê≥¢Á≠âÊñπÊ≥ïËøõË°åË∑üË∏™ÂíåÊõ¥Êñ∞„ÄÇMLLMÁöÑ‰ΩøÁî®Ê∂âÂèäpromptÂ∑•Á®ãÂíåÂæÆË∞ÉÁ≠ñÁï•Ôºå‰ª•ÈÄÇÂ∫î3DÂÆû‰æãÂàÜÂâ≤‰ªªÂä°„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÂèØËÉΩÂåÖÊã¨ÂàÜÂâ≤ÊçüÂ§±„ÄÅË∑üË∏™ÊçüÂ§±ÂíåÂàÜÁ±ªÊçüÂ§±Á≠â„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

OpenTrack3DÂú®ScanNet200„ÄÅReplica„ÄÅScanNet++ÂíåSceneFun3DÁ≠âÂ§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Üstate-of-the-artÁöÑÊÄßËÉΩÔºåËØÅÊòé‰∫ÜÂÖ∂‰ºòË∂äÁöÑÊÄßËÉΩÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜËÆ∫ÊñáÂº∫Ë∞É‰∫ÜÂÖ∂Âú®Â§çÊùÇÂú∫ÊôØÂíåÁî®Êà∑Êü•ËØ¢‰∏ãÁöÑÊòæËëóÊèêÂçá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

OpenTrack3DÂú®Êú∫Âô®‰∫∫„ÄÅAR/VRÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ‰æãÂ¶ÇÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Âà©Áî®ËØ•ÊäÄÊúØÂú®Êú™Áü•ÁéØÂ¢É‰∏≠ËØÜÂà´ÂíåÂàÜÂâ≤Áâ©‰ΩìÔºå‰ªéËÄåÂÆûÁé∞Ëá™‰∏ªÂØºËà™ÂíåÊìç‰Ωú„ÄÇÂú®AR/VR‰∏≠ÔºåËØ•ÊäÄÊúØÂèØ‰ª•Áî®‰∫éÂ¢ûÂº∫Áé∞ÂÆû‰ΩìÈ™åÔºå‰æãÂ¶ÇÂÖÅËÆ∏Áî®Êà∑‰∏éËôöÊãüÁâ©‰ΩìËøõË°å‰∫§‰∫í„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Generalizing open-vocabulary 3D instance segmentation (OV-3DIS) to diverse, unstructured, and mesh-free environments is crucial for robotics and AR/VR, yet remains a significant challenge. We attribute this to two key limitations of existing methods: (1) proposal generation relies on dataset-specific proposal networks or mesh-based superpoints, rendering them inapplicable in mesh-free scenarios and limiting generalization to novel scenes; and (2) the weak textual reasoning of CLIP-based classifiers, which struggle to recognize compositional and functional user queries. To address these issues, we introduce OpenTrack3D, a generalizable and accurate framework. Unlike methods that rely on pre-generated proposals, OpenTrack3D employs a novel visual-spatial tracker to construct cross-view consistent object proposals online. Given an RGB-D stream, our pipeline first leverages a 2D open-vocabulary segmenter to generate masks, which are lifted to 3D point clouds using depth. Mask-guided instance features are then extracted using DINO feature maps, and our tracker fuses visual and spatial cues to maintain instance consistency. The core pipeline is entirely mesh-free, yet we also provide an optional superpoints refinement module to further enhance performance when scene mesh is available. Finally, we replace CLIP with a multi-modal large language model (MLLM), significantly enhancing compositional reasoning for complex user queries. Extensive experiments on diverse benchmarks, including ScanNet200, Replica, ScanNet++, and SceneFun3D, demonstrate state-of-the-art performance and strong generalization capabilities.

