---
layout: default
title: Universally Converging Representations of Matter Across Scientific Foundation Models
---

# Universally Converging Representations of Matter Across Scientific Foundation Models

**arXiv**: [2512.03750v1](https://arxiv.org/abs/2512.03750) | [PDF](https://arxiv.org/pdf/2512.03750.pdf)

**ä½œè€…**: Sathya Edamadaka, Soojung Yang, Ju Li, Rafael GÃ³mez-Bombarelli

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºç§‘å­¦åŸºç¡€æ¨¡åž‹åœ¨ç‰©è´¨è¡¨ç¤ºä¸Šçš„æ™®éæ”¶æ•›æ€§ï¼Œè¯„ä¼°å…¶æ³›åŒ–èƒ½åŠ›**

**å…³é”®è¯**: `ç§‘å­¦åŸºç¡€æ¨¡åž‹` `è¡¨ç¤ºå¯¹é½` `ç‰©è´¨è¡¨ç¤º` `æ³›åŒ–è¯„ä¼°` `æ¨¡æ€è½¬æ¢`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¸åŒæ¨¡æ€çš„ç§‘å­¦æ¨¡åž‹æ˜¯å¦å­¦ä¹ ç›¸ä¼¼çš„å†…éƒ¨ç‰©è´¨è¡¨ç¤ºï¼Œä»¥æž„å»ºå¯é æ³›åŒ–çš„åŸºç¡€æ¨¡åž‹
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ†æžè¿‘60ä¸ªç§‘å­¦æ¨¡åž‹çš„è¡¨ç¤ºå¯¹é½ï¼Œæ¶µç›–å­—ç¬¦ä¸²ã€å›¾ã€3DåŽŸå­å’Œè›‹ç™½è´¨æ¨¡æ€
3. å®žéªŒæˆ–æ•ˆæžœï¼šå‘çŽ°æ¨¡åž‹åœ¨è®­ç»ƒç›¸ä¼¼è¾“å…¥ä¸Šè¡¨ç¤ºæ”¶æ•›ï¼Œä½†åœ¨ä¸åŒç»“æž„ä¸Šè¡¨ç¤ºå´©æºƒï¼Œè¡¨æ˜Žæ³›åŒ–æœ‰é™

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today's models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks.

