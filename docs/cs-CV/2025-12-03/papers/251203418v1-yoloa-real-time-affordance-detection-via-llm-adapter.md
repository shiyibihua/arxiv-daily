---
layout: default
title: YOLOA: Real-Time Affordance Detection via LLM Adapter
---

# YOLOA: Real-Time Affordance Detection via LLM Adapter

**arXiv**: [2512.03418v1](https://arxiv.org/abs/2512.03418) | [PDF](https://arxiv.org/pdf/2512.03418.pdf)

**ä½œè€…**: Yuqi Ji, Junjie Ke, Lihuo He, Jun Liu, Kaifan Zhang, Yu-Kun Lai, Guiguang Ding, Xinbo Gao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºYOLOAæ¨¡åž‹ï¼Œé€šè¿‡LLMé€‚é…å™¨è”åˆå¤„ç†ç‰©ä½“æ£€æµ‹ä¸Žå¯ä¾›æ€§å­¦ä¹ ï¼Œå®žçŽ°å®žæ—¶å¯ä¾›æ€§æ£€æµ‹ã€‚**

**å…³é”®è¯**: `å¯ä¾›æ€§æ£€æµ‹` `å®žæ—¶æ£€æµ‹` `LLMé€‚é…å™¨` `ç‰©ä½“æ£€æµ‹` `å¤šä»»åŠ¡å­¦ä¹ ` `è½»é‡çº§æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰å¯ä¾›æ€§æ£€æµ‹æ–¹æ³•å¸¸å¿½ç•¥ç‰©ä½“è¯†åˆ«ä¸Žå®šä½ï¼Œæˆ–ç¼ºä¹ä»»åŠ¡é—´äº¤äº’ä¸Žå®žæ—¶æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨è½»é‡çº§æ£€æµ‹å™¨ï¼Œç»“åˆLLMé€‚é…å™¨ä¼˜åŒ–ç‰©ä½“æ£€æµ‹å’Œå¯ä¾›æ€§å­¦ä¹ åˆ†æ”¯ï¼Œæå‡é¢„æµ‹ç²¾åº¦ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ADG-Detå’ŒIIT-HeatåŸºå‡†ä¸Šè¾¾åˆ°SOTAå‡†ç¡®çŽ‡ï¼ŒåŒæ—¶ä¿æŒé«˜å¸§çŽ‡å®žæ—¶æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Affordance detection aims to jointly address the fundamental "what-where-how" challenge in embodied AI by understanding "what" an object is, "where" the object is located, and "how" it can be used. However, most affordance learning methods focus solely on "how" objects can be used while neglecting the "what" and "where" aspects. Other affordance detection methods treat object detection and affordance learning as two independent tasks, lacking effective interaction and real-time capability. To overcome these limitations, we introduce YOLO Affordance (YOLOA), a real-time affordance detection model that jointly handles these two tasks via a large language model (LLM) adapter. Specifically, YOLOA employs a lightweight detector consisting of object detection and affordance learning branches refined through the LLM Adapter. During training, the LLM Adapter interacts with object and affordance preliminary predictions to refine both branches by generating more accurate class priors, box offsets, and affordance gates. Experiments on our relabeled ADG-Det and IIT-Heat benchmarks demonstrate that YOLOA achieves state-of-the-art accuracy (52.8 / 73.1 mAP on ADG-Det / IIT-Heat) while maintaining real-time performance (up to 89.77 FPS, and up to 846.24 FPS for the lightweight variant). This indicates that YOLOA achieves an excellent trade-off between accuracy and efficiency.

