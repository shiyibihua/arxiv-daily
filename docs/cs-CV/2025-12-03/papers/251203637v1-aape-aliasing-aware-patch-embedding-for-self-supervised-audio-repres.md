---
layout: default
title: AaPE: Aliasing-aware Patch Embedding for Self-Supervised Audio Representation Learning
---

# AaPE: Aliasing-aware Patch Embedding for Self-Supervised Audio Representation Learning

**arXiv**: [2512.03637v1](https://arxiv.org/abs/2512.03637) | [PDF](https://arxiv.org/pdf/2512.03637.pdf)

**‰ΩúËÄÖ**: Kohei Yamamoto, Kosuke Okusa

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫AaPE‰ª•ÁºìËß£TransformerÈü≥È¢ëËá™ÁõëÁù£Â≠¶‰π†‰∏≠ÁöÑÊ∑∑Âè†ÈóÆÈ¢òÂπ∂‰øùÁïôÈ´òÈ¢ë‰ø°ÊÅØ**

**ÂÖ≥ÈîÆËØç**: `Èü≥È¢ëËá™ÁõëÁù£Â≠¶‰π†` `Ê∑∑Âè†ÁºìËß£` `TransformerÊ®°Âûã` `È¢ëË∞±ÂõæÂ§ÑÁêÜ` `Ëá™ÈÄÇÂ∫îÂàÜÂùóÂµåÂÖ•` `Êé©Á†ÅÂ∏àÁîüÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Ê†∏ÂøÉÈóÆÈ¢òÔºöTransformerÈü≥È¢ëSSLÊ®°ÂûãÂ∞ÜÈ¢ëË∞±ÂõæËßÜ‰∏∫ÂõæÂÉèÔºåÂç∑ÁßØÂàÜÂùóÂØºËá¥Êó∂Èó¥‰∏ãÈááÊ†∑ÔºåÈôç‰ΩéÊúâÊïàÂ•àÂ•éÊñØÁâπÈ¢ëÁéáÂπ∂ÂºïÂÖ•Ê∑∑Âè†ÔºåËÄåÁÆÄÂçï‰ΩéÈÄöÊª§Ê≥¢‰ºö‰∏¢Â§±‰ªªÂä°Áõ∏ÂÖ≥È´òÈ¢ëÁ∫øÁ¥¢„ÄÇ
2. ÊñπÊ≥ïË¶ÅÁÇπÔºöAaPEÈÄöËøáÂ∏¶ÈôêÂ§çÊ≠£Âº¶Ê†∏ÂíåÂèåÊåáÊï∞Á™óÂè£Âä®ÊÄÅÁîüÊàêÁâπÂæÅÔºåÂ¢ûÂº∫Ê†áÂáÜÂàÜÂùó‰ª§ÁâåÔºåËá™ÈÄÇÂ∫îÂàÜÊûêÊòìÊ∑∑Âè†È¢ëÂ∏¶ÔºåÊó†ÁºùÈõÜÊàêÂà∞Êé©Á†ÅÂ∏àÁîüËá™ÁõëÁù£Â≠¶‰π†‰∏≠„ÄÇ
3. ÂÆûÈ™åÊàñÊïàÊûúÔºöÂú®AudioSetÈ¢ÑËÆ≠ÁªÉÂêéÔºå‰∏ãÊ∏∏‰ªªÂä°ÂæÆË∞ÉÂíåÁ∫øÊÄßÊé¢ÊµãËØÑ‰º∞ÊòæÁ§∫ÔºåÂú®ÈÉ®ÂàÜ‰ªªÂä°‰∏äËææÂà∞SOTAÔºåÂÖ∂‰Ωô‰ªªÂä°Ë°®Áé∞Á´û‰∫âÊÄßÔºåË°®ÊòéAaPEÊúâÊïàÁºìËß£Ê∑∑Âè†‰∏î‰øùÁïôÈ´òÈ¢ë‰ø°ÊÅØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Transformer-based audio SSL (self-supervised learning) models often treat spectrograms as images, applying convolutional patchification with heavy temporal downsampling. This lowers the effective Nyquist frequency and introduces aliasing, while na√Øve low-pass filtering removes task-relevant high-frequency cues. In this study, we present Aliasing-aware Patch Embedding (AaPE), a drop-in patch stem that mitigates aliasing while preserving high-frequency information. AaPE augments standard patch tokens with features produced by a band-limited complex sinusoidal kernel using a two-sided exponential window that dynamically targets alias-prone bands. Frequency and decay parameters of the kernel are estimated from the input, enabling parallel, adaptive subband analysis whose outputs are fused with the standard patch tokens. AaPE integrates seamlessly into the masked teacher-student self-supervised learning. In addition, we combine a multi-mask strategy with a contrastive objective to enforce consistency across diverse mask patterns, stabilizing training. Pre-training on AudioSet followed by fine-tuning evaluation across diverse downstream benchmarks, which spanned categories, such as environmental sounds and other common audio domains. This approach yields state-of-the-art performance on a subset of tasks and competitive results across the remainder. Complementary linear probing evaluation mirrors this pattern, yielding clear gains on several benchmarks and strong performance elsewhere. The collective analysis of these results indicates that AaPE serves to mitigate the effects of aliasing without discarding of informative high-frequency content.

