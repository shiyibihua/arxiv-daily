---
layout: default
title: Towards Irreversible Machine Unlearning for Diffusion Models
---

# Towards Irreversible Machine Unlearning for Diffusion Models

**arXiv**: [2512.03564v1](https://arxiv.org/abs/2512.03564) | [PDF](https://arxiv.org/pdf/2512.03564.pdf)

**ä½œè€…**: Xun Yuan, Zilong Zhao, Jiayu Li, Aryan Pasikhani, Prosanta Gope, Biplab Sikdar

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDiMRAæ”»å‡»ä¸ŽDiMUMæ–¹æ³•ä»¥å¢žå¼ºæ‰©æ•£æ¨¡åž‹æœºå™¨é—å¿˜çš„é²æ£’æ€§**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹` `æœºå™¨é—å¿˜` `é²æ£’æ€§å¢žå¼º` `å¯¹æŠ—æ”»å‡»` `å¾®è°ƒæ–¹æ³•` `ç”Ÿæˆæ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŸºäºŽå¾®è°ƒçš„æ‰©æ•£æ¨¡åž‹æœºå™¨é—å¿˜æ–¹æ³•æ˜“å—DiMRAæ”»å‡»ï¼Œå¯¼è‡´é—å¿˜å†…å®¹è¢«é‡æ–°å­¦ä¹ 
2. æ–¹æ³•è¦ç‚¹ï¼šDiMUMé€šè¿‡è®°å¿†æ›¿ä»£æ•°æ®æ¥é˜²æ­¢ç”Ÿæˆç›®æ ‡é—å¿˜å…ƒç´ ï¼Œè€Œéžç›´æŽ¥é—å¿˜
3. å®žéªŒæˆ–æ•ˆæžœï¼šDiMRAæˆåŠŸé€†è½¬çŽ°æœ‰é—å¿˜æ–¹æ³•ï¼ŒDiMUMåœ¨ä¿æŒç”Ÿæˆæ€§èƒ½çš„åŒæ—¶å¢žå¼ºå¯¹æŠ—æ”»å‡»çš„é²æ£’æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Diffusion models are renowned for their state-of-the-art performance in generating synthetic images. However, concerns related to safety, privacy, and copyright highlight the need for machine unlearning, which can make diffusion models forget specific training data and prevent the generation of sensitive or unwanted content. Current machine unlearning methods for diffusion models are primarily designed for conditional diffusion models and focus on unlearning specific data classes or features. Among these methods, finetuning-based machine unlearning methods are recognized for their efficiency and effectiveness, which update the parameters of pre-trained diffusion models by minimizing carefully designed loss functions. However, in this paper, we propose a novel attack named Diffusion Model Relearning Attack (DiMRA), which can reverse the finetuning-based machine unlearning methods, posing a significant vulnerability of this kind of technique. Without prior knowledge of the unlearning elements, DiMRA optimizes the unlearned diffusion model on an auxiliary dataset to reverse the unlearning, enabling the model to regenerate previously unlearned elements. To mitigate this vulnerability, we propose a novel machine unlearning method for diffusion models, termed as Diffusion Model Unlearning by Memorization (DiMUM). Unlike traditional methods that focus on forgetting, DiMUM memorizes alternative data or features to replace targeted unlearning data or features in order to prevent generating such elements. In our experiments, we demonstrate the effectiveness of DiMRA in reversing state-of-the-art finetuning-based machine unlearning methods for diffusion models, highlighting the need for more robust solutions. We extensively evaluate DiMUM, demonstrating its superior ability to preserve the generative performance of diffusion models while enhancing robustness against DiMRA.

