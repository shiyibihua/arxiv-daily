---
layout: default
title: Procedural Mistake Detection via Action Effect Modeling
---

# Procedural Mistake Detection via Action Effect Modeling

**arXiv**: [2512.03474v1](https://arxiv.org/abs/2512.03474) | [PDF](https://arxiv.org/pdf/2512.03474.pdf)

**ä½œè€…**: Wenliang Guo, Yujiang Pu, Yu Kong

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŠ¨ä½œæ•ˆæžœå»ºæ¨¡æ¡†æž¶ï¼Œé€šè¿‡è”åˆå»ºæ¨¡åŠ¨ä½œæ‰§è¡Œä¸Žç»“æžœä»¥æå‡è¿‡ç¨‹æ€§ä»»åŠ¡ä¸­çš„é”™è¯¯æ£€æµ‹æ€§èƒ½ã€‚**

**å…³é”®è¯**: `è¿‡ç¨‹æ€§é”™è¯¯æ£€æµ‹` `åŠ¨ä½œæ•ˆæžœå»ºæ¨¡` `è§†è§‰åŸºç¡€` `ç¬¦å·åœºæ™¯å›¾` `å•ç±»åˆ†ç±»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•å¿½ç•¥åŠ¨ä½œæ•ˆæžœï¼Œå¯¼è‡´è®¸å¤šé”™è¯¯æ— æ³•æ£€æµ‹ï¼Œå¦‚å¯¹è±¡çŠ¶æ€æˆ–ç©ºé—´æŽ’åˆ—é”™è¯¯ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šAEMæ¡†æž¶é€šè¿‡æ¦‚çŽ‡å»ºæ¨¡ï¼Œç»“åˆè§†è§‰åŸºç¡€å’Œç¬¦å·åœºæ™¯å›¾ï¼Œæå–æ•ˆæžœæ„ŸçŸ¥è¡¨ç¤ºï¼Œå¹¶è®¾è®¡åŸºäºŽæç¤ºçš„æ£€æµ‹å™¨ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨EgoPERå’ŒCaptainCook4DåŸºå‡†ä¸Šï¼Œåœ¨å•ç±»åˆ†ç±»è®¾ç½®ä¸‹è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ï¼ŒéªŒè¯äº†è”åˆå»ºæ¨¡çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Mistake detection in procedural tasks is essential for building intelligent systems that support learning and task execution. Existing approaches primarily analyze how an action is performed, while overlooking what it produces, i.e., the \textbf{action effect}. Yet many errors manifest not in the execution itself but in the resulting outcome, such as an unintended object state or incorrect spatial arrangement. To address this gap, we propose Action Effect Modeling (AEM), a unified framework that jointly captures action execution and its outcomes through a probabilistic formulation. AEM first identifies the outcome of an action by selecting the most informative effect frame based on semantic relevance and visual quality. It then extracts complementary cues from visual grounding and symbolic scene graphs, aligning them in a shared latent space to form robust effect-aware representations. To detect mistakes, we further design a prompt-based detector that incorporates task-specific prompts and aligns each action segment with its intended execution semantics. Our approach achieves state-of-the-art performance on the EgoPER and CaptainCook4D benchmarks under the challenging one-class classification (OCC) setting. These results demonstrate that modeling both execution and outcome yields more reliable mistake detection, and highlight the potential of effect-aware representations to benefit a broader range of downstream applications.

