---
layout: default
title: LAMP: Language-Assisted Motion Planning for Controllable Video Generation
---

# LAMP: Language-Assisted Motion Planning for Controllable Video Generation

**arXiv**: [2512.03619v1](https://arxiv.org/abs/2512.03619) | [PDF](https://arxiv.org/pdf/2512.03619.pdf)

**ä½œè€…**: Muhammed Burak Kizil, Enes Sanli, Niloy J. Mitra, Erkut Erdem, Aykut Erdem, Duygu Ceylan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLAMPæ¡†æž¶ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡åž‹å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸º3Dè½¨è¿¹ä»¥å¢žå¼ºè§†é¢‘ç”Ÿæˆçš„è¿åŠ¨å¯æŽ§æ€§ã€‚**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `è¿åŠ¨è§„åˆ’` `å¤§è¯­è¨€æ¨¡åž‹` `ç¨‹åºåˆæˆ` `3Dè½¨è¿¹` `å¯æŽ§æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†é¢‘ç”Ÿæˆä¸­è¿åŠ¨æŽ§åˆ¶ï¼ˆå¯¹è±¡åŠ¨æ€å’Œç›¸æœºè½¨è¿¹ï¼‰çš„æŽ¥å£æœ‰é™ï¼Œéš¾ä»¥ä»Žè‡ªç„¶è¯­è¨€ç›´æŽ¥ç”Ÿæˆå¤æ‚åœºæ™¯ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå®šä¹‰è¿åŠ¨é¢†åŸŸç‰¹å®šè¯­è¨€ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡åž‹ç¨‹åºåˆæˆèƒ½åŠ›ï¼Œå°†è‡ªç„¶è¯­è¨€æè¿°æ˜ å°„ä¸ºç»“æž„åŒ–è¿åŠ¨ç¨‹åºå’Œ3Dè½¨è¿¹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæž„å»ºå¤§è§„æ¨¡ç¨‹åºåŒ–æ•°æ®é›†ï¼Œå®žéªŒæ˜¾ç¤ºLAMPåœ¨è¿åŠ¨å¯æŽ§æ€§å’Œç”¨æˆ·æ„å›¾å¯¹é½æ–¹é¢ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video generation has achieved remarkable progress in visual fidelity and controllability, enabling conditioning on text, layout, or motion. Among these, motion control - specifying object dynamics and camera trajectories - is essential for composing complex, cinematic scenes, yet existing interfaces remain limited. We introduce LAMP that leverages large language models (LLMs) as motion planners to translate natural language descriptions into explicit 3D trajectories for dynamic objects and (relatively defined) cameras. LAMP defines a motion domain-specific language (DSL), inspired by cinematography conventions. By harnessing program synthesis capabilities of LLMs, LAMP generates structured motion programs from natural language, which are deterministically mapped to 3D trajectories. We construct a large-scale procedural dataset pairing natural text descriptions with corresponding motion programs and 3D trajectories. Experiments demonstrate LAMP's improved performance in motion controllability and alignment with user intent compared to state-of-the-art alternatives establishing the first framework for generating both object and camera motions directly from natural language specifications.

