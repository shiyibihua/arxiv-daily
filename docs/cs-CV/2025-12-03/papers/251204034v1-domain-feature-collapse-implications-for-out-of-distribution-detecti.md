---
layout: default
title: Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions
---

# Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions

**arXiv**: [2512.04034v1](https://arxiv.org/abs/2512.04034) | [PDF](https://arxiv.org/pdf/2512.04034.pdf)

**ä½œè€…**: Hong Yang, Devroop Kar, Qi Yu, Alex Ororbia, Travis Desell

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸŸç‰¹å¾åç¼©ç†è®ºä»¥è§£é‡Šå•åŸŸè®­ç»ƒä¸‹OODæ£€æµ‹å¤±è´¥ï¼Œå¹¶é€šè¿‡åŸŸè¿‡æ»¤è§£å†³**

**å…³é”®è¯**: `åŸŸç‰¹å¾åç¼©` `OODæ£€æµ‹` `ä¿¡æ¯ç“¶é¢ˆ` `å•åŸŸè®­ç»ƒ` `åŸŸè¿‡æ»¤` `è¿ç§»å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå•åŸŸæ•°æ®é›†è®­ç»ƒå¯¼è‡´æ¨¡åž‹ä¸¢å¼ƒåŸŸç‰¹å¾ï¼Œå¼•å‘OODæ£€æµ‹ç¾éš¾æ€§å¤±è´¥
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽä¿¡æ¯è®ºè¯æ˜ŽåŸŸç‰¹å¾åç¼©ï¼Œæå‡ºåŸŸè¿‡æ»¤ä¿ç•™åŸŸä¿¡æ¯ä»¥æå‡æ£€æµ‹
3. å®žéªŒæˆ–æ•ˆæžœï¼šæž„å»ºDomain BenchåŸºå‡†ï¼ŒéªŒè¯åŸŸè¿‡æ»¤æœ‰æ•ˆé™ä½Žå¤±è´¥çŽ‡ï¼Œå¦‚MNISTä¸ŠFPR@95è¾¾53%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Why do state-of-the-art OOD detection methods exhibit catastrophic failure when models are trained on single-domain datasets? We provide the first theoretical explanation for this phenomenon through the lens of information theory. We prove that supervised learning on single-domain data inevitably produces domain feature collapse -- representations where I(x_d; z) = 0, meaning domain-specific information is completely discarded. This is a fundamental consequence of information bottleneck optimization: models trained on single domains (e.g., medical images) learn to rely solely on class-specific features while discarding domain features, leading to catastrophic failure when detecting out-of-domain samples (e.g., achieving only 53% FPR@95 on MNIST). We extend our analysis using Fano's inequality to quantify partial collapse in practical scenarios. To validate our theory, we introduce Domain Bench, a benchmark of single-domain datasets, and demonstrate that preserving I(x_d; z) > 0 through domain filtering (using pretrained representations) resolves the failure mode. While domain filtering itself is conceptually straightforward, its effectiveness provides strong empirical evidence for our information-theoretic framework. Our work explains a puzzling empirical phenomenon, reveals fundamental limitations of supervised learning in narrow domains, and has broader implications for transfer learning and when to fine-tune versus freeze pretrained models.

