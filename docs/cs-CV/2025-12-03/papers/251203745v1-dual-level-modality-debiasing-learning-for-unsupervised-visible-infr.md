---
layout: default
title: Dual-level Modality Debiasing Learning for Unsupervised Visible-Infrared Person Re-Identification
---

# Dual-level Modality Debiasing Learning for Unsupervised Visible-Infrared Person Re-Identification

**arXiv**: [2512.03745v1](https://arxiv.org/abs/2512.03745) | [PDF](https://arxiv.org/pdf/2512.03745.pdf)

**ä½œè€…**: Jiaze Li, Yan Lu, Bin Liu, Guojun Yin, Mang Ye

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒå±‚çº§æ¨¡æ€åŽ»åå­¦ä¹ æ¡†æž¶ä»¥è§£å†³æ— ç›‘ç£å¯è§å…‰-çº¢å¤–è¡Œäººé‡è¯†åˆ«ä¸­çš„æ¨¡æ€åå·®é—®é¢˜**

**å…³é”®è¯**: `æ— ç›‘ç£å­¦ä¹ ` `å¯è§å…‰-çº¢å¤–è¡Œäººé‡è¯†åˆ«` `æ¨¡æ€åŽ»å` `å› æžœå»ºæ¨¡` `ç‰¹å¾å¯¹é½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¸¤é˜¶æ®µå­¦ä¹ æµç¨‹åœ¨æ— ç›‘ç£å¯è§å…‰-çº¢å¤–è¡Œäººé‡è¯†åˆ«ä¸­å¼•å…¥æ¨¡æ€åå·®ï¼ŒæŸå®³èº«ä»½åˆ¤åˆ«å’Œæ³›åŒ–èƒ½åŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåœ¨æ¨¡åž‹å±‚çº§ä½¿ç”¨å› æžœè°ƒæ•´å¹²é¢„æ¨¡å—ï¼Œåœ¨ä¼˜åŒ–å±‚çº§é‡‡ç”¨åä½œæ— åè®­ç»ƒç­–ç•¥ï¼Œå®žçŽ°åŒå±‚çº§åŽ»åã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŸºå‡†æ•°æ®é›†ä¸ŠéªŒè¯äº†æ¡†æž¶èƒ½å®žçŽ°æ¨¡æ€ä¸å˜ç‰¹å¾å­¦ä¹ å’Œæ›´æ³›åŒ–çš„æ¨¡åž‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Two-stage learning pipeline has achieved promising results in unsupervised visible-infrared person re-identification (USL-VI-ReID). It first performs single-modality learning and then operates cross-modality learning to tackle the modality discrepancy. Although promising, this pipeline inevitably introduces modality bias: modality-specific cues learned in the single-modality training naturally propagate into the following cross-modality learning, impairing identity discrimination and generalization. To address this issue, we propose a Dual-level Modality Debiasing Learning (DMDL) framework that implements debiasing at both the model and optimization levels. At the model level, we propose a Causality-inspired Adjustment Intervention (CAI) module that replaces likelihood-based modeling with causal modeling, preventing modality-induced spurious patterns from being introduced, leading to a low-biased model. At the optimization level, a Collaborative Bias-free Training (CBT) strategy is introduced to interrupt the propagation of modality bias across data, labels, and features by integrating modality-specific augmentation, label refinement, and feature alignment. Extensive experiments on benchmark datasets demonstrate that DMDL could enable modality-invariant feature learning and a more generalized model.

