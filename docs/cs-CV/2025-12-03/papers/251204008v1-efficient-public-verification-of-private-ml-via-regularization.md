---
layout: default
title: Efficient Public Verification of Private ML via Regularization
---

# Efficient Public Verification of Private ML via Regularization

**arXiv**: [2512.04008v1](https://arxiv.org/abs/2512.04008) | [PDF](https://arxiv.org/pdf/2512.04008.pdf)

**ä½œè€…**: ZoÃ« Ruha Bell, Anvith Thudi, Olive Franzese-McLaughlin, Nicolas Papernot, Shafi Goldwasser

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæ­£åˆ™åŒ–çš„å·®åˆ†éšç§ç®—æ³•ï¼Œä»¥é™ä½Žéšç§ä¿è¯éªŒè¯çš„è®¡ç®—æˆæœ¬**

**å…³é”®è¯**: `å·®åˆ†éšç§` `éšç§éªŒè¯` `æ­£åˆ™åŒ–ä¼˜åŒ–` `éšæœºå‡¸ä¼˜åŒ–` `è®¡ç®—æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå·®åˆ†éšç§è®­ç»ƒåŽï¼Œå…¬ä¼—éš¾ä»¥é«˜æ•ˆéªŒè¯æ¨¡åž‹æ˜¯å¦æ»¡è¶³éšç§ä¿è¯ï¼ŒéªŒè¯æˆæœ¬ä¸Žè®­ç»ƒæˆæœ¬ç›¸å½“
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡ç§æœ‰æœ€å°åŒ–ä¸€ç³»åˆ—æ­£åˆ™åŒ–ç›®æ ‡ï¼Œä½¿ç”¨æ ‡å‡†DPç»„åˆç•Œå®žçŽ°ç´§éšç§-æ•ˆç”¨æƒè¡¡
3. å®žéªŒæˆ–æ•ˆæžœï¼šéªŒè¯è®¡ç®—æˆæœ¬æ˜¾è‘—ä½ŽäºŽè®­ç»ƒæˆæœ¬ï¼Œé€‚ç”¨äºŽå¤§è§„æ¨¡æ•°æ®é›†ï¼Œéšç§-æ•ˆç”¨æŽ¥è¿‘æœ€ä¼˜

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Training with differential privacy (DP) provides a guarantee to members in a dataset that they cannot be identified by users of the released model. However, those data providers, and, in general, the public, lack methods to efficiently verify that models trained on their data satisfy DP guarantees. The amount of compute needed to verify DP guarantees for current algorithms scales with the amount of compute required to train the model. In this paper we design the first DP algorithm with near optimal privacy-utility trade-offs but whose DP guarantees can be verified cheaper than training. We focus on DP stochastic convex optimization (DP-SCO), where optimal privacy-utility trade-offs are known. Here we show we can obtain tight privacy-utility trade-offs by privately minimizing a series of regularized objectives and only using the standard DP composition bound. Crucially, this method can be verified with much less compute than training. This leads to the first known DP-SCO algorithm with near optimal privacy-utility whose DP verification scales better than training cost, significantly reducing verification costs on large datasets.

