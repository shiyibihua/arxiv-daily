---
layout: default
title: Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs
---

# Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs

**arXiv**: [2512.03994v1](https://arxiv.org/abs/2512.03994) | [PDF](https://arxiv.org/pdf/2512.03994.pdf)

**ä½œè€…**: Oren Rachmil, Roy Betser, Itay Gershon, Omer Hofman, Nitay Yakoby, Yuval Meron, Idan Yankelev, Asaf Shabtai, Yuval Elovici, Roman Vainshtein

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæ¿€æ´»ç©ºé—´ç™½åŒ–çš„å…è®­ç»ƒç­–ç•¥è¿è§„æ£€æµ‹æ–¹æ³•ï¼Œä»¥è§£å†³ç»„ç»‡å†…éƒ¨LLMéƒ¨ç½²ä¸­çš„æ”¿ç­–åˆè§„é—®é¢˜ã€‚**

**å…³é”®è¯**: `ç­–ç•¥è¿è§„æ£€æµ‹` `æ¿€æ´»ç©ºé—´ç™½åŒ–` `åˆ†å¸ƒå¤–æ£€æµ‹` `å…è®­ç»ƒæ–¹æ³•` `LLMå¯¹é½` `ç»„ç»‡æ”¿ç­–åˆè§„`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç»„ç»‡éƒ¨ç½²LLMæ—¶éœ€æ£€æµ‹å†…éƒ¨æ”¿ç­–è¿è§„ï¼ŒçŽ°æœ‰æ–¹æ³•å¦‚å®‰å…¨æŠ¤æ æˆ–å¾®è°ƒå­˜åœ¨å»¶è¿Ÿé«˜ã€å¯è§£é‡Šæ€§å·®ç­‰å±€é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†ç­–ç•¥è¿è§„æ£€æµ‹è§†ä¸ºåˆ†å¸ƒå¤–æ£€æµ‹é—®é¢˜ï¼Œé€šè¿‡çº¿æ€§å˜æ¢å¯¹éšè—æ¿€æ´»è¿›è¡ŒåŽ»ç›¸å…³å’Œæ ‡å‡†åŒ–ï¼Œä½¿ç”¨æ¬§å‡ é‡Œå¾—èŒƒæ•°ä½œä¸ºåˆè§„åˆ†æ•°ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æŒ‘æˆ˜æ€§æ”¿ç­–åŸºå‡†ä¸Šå–å¾—æœ€ä¼˜ç»“æžœï¼Œè¶…è¶ŠçŽ°æœ‰æŠ¤æ å’Œå¾®è°ƒæŽ¨ç†æ¨¡åž‹ï¼Œæä¾›è½»é‡çº§ã€æ˜“éƒ¨ç½²çš„è§£å†³æ–¹æ¡ˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Aligning proprietary large language models (LLMs) with internal organizational policies has become an urgent priority as organizations increasingly deploy LLMs in sensitive domains such as legal support, finance, and medical services. Beyond generic safety filters, enterprises require reliable mechanisms to detect policy violations within their regulatory and operational frameworks, where breaches can trigger legal and reputational risks. Existing content moderation frameworks, such as guardrails, remain largely confined to the safety domain and lack the robustness to capture nuanced organizational policies. LLM-as-a-judge and fine-tuning approaches, though flexible, introduce significant latency and lack interpretability. To address these limitations, we propose a training-free and efficient method that treats policy violation detection as an out-of-distribution (OOD) detection problem. Inspired by whitening techniques, we apply a linear transformation to decorrelate the model's hidden activations and standardize them to zero mean and unit variance, yielding near-identity covariance matrix. In this transformed space, we use the Euclidean norm as a compliance score to detect policy violations. The method requires only the policy text and a small number of illustrative samples, which makes it light-weight and easily deployable. On a challenging policy benchmark, our approach achieves state-of-the-art results, surpassing both existing guardrails and fine-tuned reasoning models. This work provides organizations with a practical and statistically grounded framework for policy-aware oversight of LLMs, advancing the broader goal of deployable AI governance. Code is available at: https://tinyurl.com/policy-violation-detection

