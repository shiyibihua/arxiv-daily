---
layout: default
title: Dynamic Content Moderation in Livestreams: Combining Supervised Classification with MLLM-Boosted Similarity Matching
---

# Dynamic Content Moderation in Livestreams: Combining Supervised Classification with MLLM-Boosted Similarity Matching

**arXiv**: [2512.03553v1](https://arxiv.org/abs/2512.03553) | [PDF](https://arxiv.org/pdf/2512.03553.pdf)

**ä½œè€…**: Wei Chee Yew, Hailun Xu, Sanjay Saha, Xiaotian Fan, Hiok Hian Ong, David Yuchen Wang, Kanchan Sarkar, Zhenheng Yang, Danhui Guan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“åˆç›‘ç£åˆ†ç±»ä¸ŽMLLMå¢žå¼ºç›¸ä¼¼æ€§åŒ¹é…çš„æ··åˆæ¡†æž¶ï¼Œä»¥è§£å†³ç›´æ’­ä¸­åŠ¨æ€å†…å®¹å®¡æ ¸çš„æŒ‘æˆ˜ã€‚**

**å…³é”®è¯**: `ç›´æ’­å†…å®¹å®¡æ ¸` `æ··åˆæ¡†æž¶` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `ç›¸ä¼¼æ€§åŒ¹é…` `ç›‘ç£åˆ†ç±»` `ç”Ÿäº§éƒ¨ç½²`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç›´æ’­å†…å®¹å®¡æ ¸éœ€åŠæ—¶ã€å¤šæ¨¡æ€ä¸”èƒ½åº”å¯¹æ–°åž‹è¿è§„å†…å®¹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ··åˆæ¡†æž¶ç»“åˆç›‘ç£åˆ†ç±»ä¸Žç›¸ä¼¼æ€§åŒ¹é…ï¼ŒMLLMè’¸é¦çŸ¥è¯†æå‡å‡†ç¡®æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç”Ÿäº§éƒ¨ç½²ä¸­ï¼Œåˆ†ç±»ç®¡é“å¬å›žçŽ‡67%ç²¾åº¦80%ï¼Œç›¸ä¼¼æ€§ç®¡é“å¬å›žçŽ‡76%ç²¾åº¦80%ï¼ŒA/Bæµ‹è¯•å‡å°‘6-8%ä¸è‰¯å†…å®¹è§‚çœ‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Content moderation remains a critical yet challenging task for large-scale user-generated video platforms, especially in livestreaming environments where moderation must be timely, multimodal, and robust to evolving forms of unwanted content. We present a hybrid moderation framework deployed at production scale that combines supervised classification for known violations with reference-based similarity matching for novel or subtle cases. This hybrid design enables robust detection of both explicit violations and novel edge cases that evade traditional classifiers. Multimodal inputs (text, audio, visual) are processed through both pipelines, with a multimodal large language model (MLLM) distilling knowledge into each to boost accuracy while keeping inference lightweight. In production, the classification pipeline achieves 67% recall at 80% precision, and the similarity pipeline achieves 76% recall at 80% precision. Large-scale A/B tests show a 6-8% reduction in user views of unwanted livestreams}. These results demonstrate a scalable and adaptable approach to multimodal content governance, capable of addressing both explicit violations and emerging adversarial behaviors.

