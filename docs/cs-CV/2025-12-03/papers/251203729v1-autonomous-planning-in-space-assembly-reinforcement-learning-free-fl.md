---
layout: default
title: Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing
---

# Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing

**arXiv**: [2512.03729v1](https://arxiv.org/abs/2512.03729) | [PDF](https://arxiv.org/pdf/2512.03729.pdf)

**ä½œè€…**: Samantha Chapin, Kenneth Stewart, Roxana Leontie, Carl Glen Henshaw

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå¼ºåŒ–å­¦ä¹ çš„è‡ªä¸»è§„åˆ’æ–¹æ³•ï¼Œåœ¨å›½é™…ç©ºé—´ç«™é›¶é‡åŠ›çŽ¯å¢ƒä¸‹æŽ§åˆ¶è‡ªç”±é£žè¡Œæœºå™¨äººAstrobeeã€‚**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ æŽ§åˆ¶` `è‡ªç”±é£žè¡Œæœºå™¨äºº` `é›¶é‡åŠ›çŽ¯å¢ƒ` `å›½é™…ç©ºé—´ç«™` `è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–` `è‡ªä¸»è§„åˆ’`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåœ¨ç©ºé—´é›¶é‡åŠ›çŽ¯å¢ƒä¸­å®žçŽ°è‡ªç”±é£žè¡Œæœºå™¨äººçš„è‡ªä¸»æŽ§åˆ¶ï¼Œä»¥æå‡æœºå™¨äººè‡ªä¸»æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ¼”å‘˜-è¯„è®ºå®¶è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ç½‘ç»œï¼Œåœ¨æ¨¡æ‹ŸçŽ¯å¢ƒä¸­è®­ç»ƒ6è‡ªç”±åº¦é²æ£’æŽ§åˆ¶ç­–ç•¥ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å›½é™…ç©ºé—´ç«™ä¸Šé¦–æ¬¡å®žçŽ°å¼ºåŒ–å­¦ä¹ æŽ§åˆ¶è‡ªç”±é£žè¡Œå™¨ï¼ŒéªŒè¯äº†å¿«é€Ÿéƒ¨ç½²å®šåˆ¶è¡Œä¸ºçš„èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The US Naval Research Laboratory's (NRL's) Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) experiment pioneers the use of reinforcement learning (RL) for control of free-flying robots in the zero-gravity (zero-G) environment of space. On Tuesday, May 27th 2025 the APIARY team conducted the first ever, to our knowledge, RL control of a free-flyer in space using the NASA Astrobee robot on-board the International Space Station (ISS). A robust 6-degrees of freedom (DOF) control policy was trained using an actor-critic Proximal Policy Optimization (PPO) network within the NVIDIA Isaac Lab simulation environment, randomizing over goal poses and mass distributions to enhance robustness. This paper details the simulation testing, ground testing, and flight validation of this experiment. This on-orbit demonstration validates the transformative potential of RL for improving robotic autonomy, enabling rapid development and deployment (in minutes to hours) of tailored behaviors for space exploration, logistics, and real-time mission needs.

