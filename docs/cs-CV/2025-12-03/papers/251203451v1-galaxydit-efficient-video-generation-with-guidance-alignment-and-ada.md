---
layout: default
title: GalaxyDiT: Efficient Video Generation with Guidance Alignment and Adaptive Proxy in Diffusion Transformers
---

# GalaxyDiT: Efficient Video Generation with Guidance Alignment and Adaptive Proxy in Diffusion Transformers

**arXiv**: [2512.03451v1](https://arxiv.org/abs/2512.03451) | [PDF](https://arxiv.org/pdf/2512.03451.pdf)

**ä½œè€…**: Zhiye Song, Steve Dai, Ben Keller, Brucek Khailany

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGalaxyDiTæ–¹æ³•ï¼Œé€šè¿‡æŒ‡å¯¼å¯¹é½å’Œè‡ªé€‚åº”ä»£ç†åŠ é€Ÿæ‰©æ•£Transformerè§†é¢‘ç”Ÿæˆ**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `æ‰©æ•£æ¨¡åž‹` `Transformeræž¶æž„` `è®¡ç®—åŠ é€Ÿ` `æŒ‡å¯¼å¯¹é½` `ä»£ç†é€‰æ‹©`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‰©æ•£æ¨¡åž‹è§†é¢‘ç”Ÿæˆè®¡ç®—å¯†é›†ï¼Œè¿­ä»£æ­¥éª¤å¤šä¸”åˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼åŠ å€è®¡ç®—éœ€æ±‚ï¼Œé˜»ç¢ä¸‹æ¸¸åº”ç”¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽç§©ç›¸å…³åˆ†æžï¼Œè®­ç»ƒå…è´¹åœ°é€‰æ‹©æœ€ä¼˜ä»£ç†ä»¥å®žçŽ°è®¡ç®—é‡ç”¨ï¼Œç¡®ä¿è·¨æ¨¡åž‹å’Œå‚æ•°è§„æ¨¡çš„é«˜æ•ˆæ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Wan2.1-1.3Bå’ŒWan2.1-14Bä¸Šå®žçŽ°1.87å€å’Œ2.37å€åŠ é€Ÿï¼ŒVBench-2.0åŸºå‡†æ€§èƒ½ä¸‹é™å°äºŽ1%ï¼Œé«˜åŠ é€ŸçŽ‡ä¸‹ä¿çœŸåº¦ä¼˜äºŽå…ˆå‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Diffusion models have revolutionized video generation, becoming essential tools in creative content generation and physical simulation. Transformer-based architectures (DiTs) and classifier-free guidance (CFG) are two cornerstones of this success, enabling strong prompt adherence and realistic video quality. Despite their versatility and superior performance, these models require intensive computation. Each video generation requires dozens of iterative steps, and CFG doubles the required compute. This inefficiency hinders broader adoption in downstream applications.
>   We introduce GalaxyDiT, a training-free method to accelerate video generation with guidance alignment and systematic proxy selection for reuse metrics. Through rank-order correlation analysis, our technique identifies the optimal proxy for each video model, across model families and parameter scales, thereby ensuring optimal computational reuse. We achieve $1.87\times$ and $2.37\times$ speedup on Wan2.1-1.3B and Wan2.1-14B with only 0.97% and 0.72% drops on the VBench-2.0 benchmark. At high speedup rates, our approach maintains superior fidelity to the base model, exceeding prior state-of-the-art approaches by 5 to 10 dB in peak signal-to-noise ratio (PSNR).

