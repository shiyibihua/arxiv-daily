---
layout: default
title: World Models for Autonomous Navigation of Terrestrial Robots from LIDAR Observations
---

# World Models for Autonomous Navigation of Terrestrial Robots from LIDAR Observations

**arXiv**: [2512.03429v1](https://arxiv.org/abs/2512.03429) | [PDF](https://arxiv.org/pdf/2512.03429.pdf)

**ä½œè€…**: Raul Steinmetz, Fabio Demo Rosa, Victor Augusto Kich, Jair Augusto Bottega, Ricardo Bedin Grando, Daniel Fernando Tello Gamarra

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽDreamerV3å’ŒMLP-VAEçš„ä¸–ç•Œæ¨¡åž‹æ¡†æž¶ï¼Œä»¥è§£å†³åœ°é¢æœºå™¨äººä»Žé«˜ç»´LIDARè§‚æµ‹ä¸­è‡ªä¸»å¯¼èˆªçš„æŒ‘æˆ˜ã€‚**

**å…³é”®è¯**: `è‡ªä¸»å¯¼èˆª` `å¼ºåŒ–å­¦ä¹ ` `ä¸–ç•Œæ¨¡åž‹` `LIDARç¼–ç ` `æ½œåœ¨è¡¨ç¤º` `æœºå™¨äººä»¿çœŸ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ¨¡åž‹æ— å…³å¼ºåŒ–å­¦ä¹ å¤„ç†å…¨åˆ†è¾¨çŽ‡LIDARæ•°æ®æ—¶æ ·æœ¬æ•ˆçŽ‡ä½Žï¼Œå¯¼è‡´å¯¼èˆªé²æ£’æ€§ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆMLP-VAEç¼–ç LIDARè§‚æµ‹ä¸ºç´§å‡‘æ½œåœ¨è¡¨ç¤ºï¼Œç»“åˆåŠ¨æ€é¢„æµ‹å™¨å®žçŽ°åŸºäºŽæƒ³è±¡çš„ç­–ç•¥ä¼˜åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ¨¡æ‹ŸTurtleBot3ä»»åŠ¡ä¸­ï¼Œç›¸æ¯”SACç­‰åŸºçº¿ï¼Œå®žçŽ°æ›´å¿«æ”¶æ•›å’Œ100%æˆåŠŸçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Autonomous navigation of terrestrial robots using Reinforcement Learning (RL) from LIDAR observations remains challenging due to the high dimensionality of sensor data and the sample inefficiency of model-free approaches. Conventional policy networks struggle to process full-resolution LIDAR inputs, forcing prior works to rely on simplified observations that reduce spatial awareness and navigation robustness. This paper presents a novel model-based RL framework built on top of the DreamerV3 algorithm, integrating a Multi-Layer Perceptron Variational Autoencoder (MLP-VAE) within a world model to encode high-dimensional LIDAR readings into compact latent representations. These latent features, combined with a learned dynamics predictor, enable efficient imagination-based policy optimization. Experiments on simulated TurtleBot3 navigation tasks demonstrate that the proposed architecture achieves faster convergence and higher success rate compared to model-free baselines such as SAC, DDPG, and TD3. It is worth emphasizing that the DreamerV3-based agent attains a 100% success rate across all evaluated environments when using the full dataset of the Turtlebot3 LIDAR (360 readings), while model-free methods plateaued below 85%. These findings demonstrate that integrating predictive world models with learned latent representations enables more efficient and robust navigation from high-dimensional sensory data.

