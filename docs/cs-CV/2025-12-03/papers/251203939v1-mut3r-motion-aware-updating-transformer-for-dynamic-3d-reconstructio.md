---
layout: default
title: MUT3R: Motion-aware Updating Transformer for Dynamic 3D Reconstruction
---

# MUT3R: Motion-aware Updating Transformer for Dynamic 3D Reconstruction

**arXiv**: [2512.03939v1](https://arxiv.org/abs/2512.03939) | [PDF](https://arxiv.org/pdf/2512.03939.pdf)

**ä½œè€…**: Guole Shen, Tianchen Deng, Xingrui Qin, Nailin Wang, Jianyu Wang, Yanbo Wang, Yongtao Chen, Hesheng Wang, Jingchuan Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMUT3Ræ¡†æž¶ï¼Œåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶æŠ‘åˆ¶åŠ¨æ€å†…å®¹ä»¥æå‡åŠ¨æ€3Dé‡å»ºçš„ç¨³å®šæ€§ã€‚**

**å…³é”®è¯**: `åŠ¨æ€3Dé‡å»º` `æ³¨æ„åŠ›æœºåˆ¶` `Transformer` `æ— è®­ç»ƒæ¡†æž¶` `è¿åŠ¨æ„ŸçŸ¥` `æµå¼åœºæ™¯`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰çŠ¶æ€å¾ªçŽ¯ç¥žç»ç½‘ç»œåœ¨åŠ¨æ€3Dé‡å»ºä¸­æ˜“å—è¿åŠ¨åŒºåŸŸå¹²æ‰°ï¼Œå¯¼è‡´ä¼ªå½±ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ†æžé¢„è®­ç»ƒTransformerçš„æ³¨æ„åŠ›å›¾ï¼Œæå–éšå«è¿åŠ¨çº¿ç´¢ï¼Œè®¾è®¡æ— è®­ç»ƒçš„é—¨æŽ§æ¨¡å—æŠ‘åˆ¶åŠ¨æ€å†…å®¹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŠ¨æ€åŸºå‡†æµ‹è¯•ä¸­ï¼Œæå‡æ—¶é—´ä¸€è‡´æ€§å’Œç›¸æœºå§¿æ€é²æ£’æ€§ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent stateful recurrent neural networks have achieved remarkable progress on static 3D reconstruction but remain vulnerable to motion-induced artifacts, where non-rigid regions corrupt attention propagation between the spatial memory and image feature. By analyzing the internal behaviors of the state and image token updating mechanism, we find that aggregating self-attention maps across layers reveals a consistent pattern: dynamic regions are naturally down-weighted, exposing an implicit motion cue that the pretrained transformer already encodes but never explicitly uses. Motivated by this observation, we introduce MUT3R, a training-free framework that applies the attention-derived motion cue to suppress dynamic content in the early layers of the transformer during inference. Our attention-level gating module suppresses the influence of dynamic regions before their artifacts propagate through the feature hierarchy. Notably, we do not retrain or fine-tune the model; we let the pretrained transformer diagnose its own motion cues and correct itself. This early regulation stabilizes geometric reasoning in streaming scenarios and leads to improvements in temporal consistency and camera pose robustness across multiple dynamic benchmarks, offering a simple and training-free pathway toward motion-aware streaming reconstruction.

