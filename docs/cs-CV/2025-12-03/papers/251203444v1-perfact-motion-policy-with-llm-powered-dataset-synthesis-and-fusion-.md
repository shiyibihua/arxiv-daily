---
layout: default
title: PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers
---

# PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers

**arXiv**: [2512.03444v1](https://arxiv.org/abs/2512.03444) | [PDF](https://arxiv.org/pdf/2512.03444.pdf)

**ä½œè€…**: Davood Soleymanzadeh, Xiao Liang, Minghui Zheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPerFACTæ–¹æ³•ï¼Œç»“åˆLLMç”Ÿæˆå¤šæ ·åŒ–å·¥ä½œç©ºé—´å’ŒèžåˆåŠ¨ä½œåˆ†å—Transformerï¼Œä»¥æå‡æœºå™¨äººè¿åŠ¨è§„åˆ’çš„æ³›åŒ–æ€§å’Œæ•ˆçŽ‡ã€‚**

**å…³é”®è¯**: `æœºå™¨äººè¿åŠ¨è§„åˆ’` `å¤§è¯­è¨€æ¨¡åž‹` `æ•°æ®é›†åˆæˆ` `Transformerç½‘ç»œ` `åŠ¨ä½œåˆ†å—` `æ³›åŒ–æ€§æå‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ç¥žç»è¿åŠ¨è§„åˆ’å™¨ä¾èµ–å°è§„æ¨¡æ‰‹åŠ¨ç”Ÿæˆæ•°æ®é›†ï¼Œæ³›åŒ–èƒ½åŠ›æœ‰é™ï¼Œä¸”ç½‘ç»œæž¶æž„éš¾ä»¥ç¼–ç å…³é”®è§„åˆ’ä¿¡æ¯ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥MotionGeneralizerï¼Œåˆ©ç”¨LLMç”Ÿæˆè¯­ä¹‰å¯è¡Œå·¥ä½œç©ºé—´ä»¥åˆæˆå¤§è§„æ¨¡æ•°æ®é›†ï¼›è®¾è®¡MpiNetsFusionï¼Œé‡‡ç”¨èžåˆåŠ¨ä½œåˆ†å—Transformerç¼–ç å¤šæ¨¡æ€ç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ”¶é›†350ä¸‡è½¨è¿¹è®­ç»ƒMpiNetsFusionï¼Œç›¸æ¯”å…ˆè¿›è§„åˆ’å™¨ï¼Œåœ¨è¯„ä¼°ä»»åŠ¡ä¸­è§„åˆ’é€Ÿåº¦æå‡æ•°å€ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deep learning methods have significantly enhanced motion planning for robotic manipulators by leveraging prior experiences within planning datasets. However, state-of-the-art neural motion planners are primarily trained on small datasets collected in manually generated workspaces, limiting their generalizability to out-of-distribution scenarios. Additionally, these planners often rely on monolithic network architectures that struggle to encode critical planning information. To address these challenges, we introduce Motion Policy with Dataset Synthesis powered by large language models (LLMs) and Fusion Action-Chunking Transformers (PerFACT), which incorporates two key components. Firstly, a novel LLM-powered workspace generation method, MotionGeneralizer, enables large-scale planning data collection by producing a diverse set of semantically feasible workspaces. Secondly, we introduce Fusion Motion Policy Networks (MpiNetsFusion), a generalist neural motion planner that uses a fusion action-chunking transformer to better encode planning signals and attend to multiple feature modalities. Leveraging MotionGeneralizer, we collect 3.5M trajectories to train and evaluate MpiNetsFusion against state-of-the-art planners, which shows that the proposed MpiNetsFusion can plan several times faster on the evaluated tasks.

