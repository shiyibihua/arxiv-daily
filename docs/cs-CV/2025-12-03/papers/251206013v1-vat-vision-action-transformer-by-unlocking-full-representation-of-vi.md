---
layout: default
title: VAT: Vision Action Transformer by Unlocking Full Representation of ViT
---

# VAT: Vision Action Transformer by Unlocking Full Representation of ViT

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.06013" target="_blank" class="toolbar-btn">arXiv: 2512.06013v1</a>
    <a href="https://arxiv.org/pdf/2512.06013.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.06013v1" 
            onclick="toggleFavorite(this, '2512.06013v1', 'VAT: Vision Action Transformer by Unlocking Full Representation of ViT')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Wenhao Li, Chengwei Ma, Weixin Mao

**ÂàÜÁ±ª**: cs.CV, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-03

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/sellerbubble/VAT)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Vision Action Transformer (VAT)ÔºåÂÖÖÂàÜÂà©Áî®ViTÂêÑÂ±ÇÁâπÂæÅËøõË°åÊú∫Âô®‰∫∫Âä®‰ΩúÂ≠¶‰π†„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Â≠¶‰π†` `Vision Transformer` `Ê®°‰ªøÂ≠¶‰π†` `ËßÜËßâÂä®‰ΩúËûçÂêà` `ÂàÜÂ±ÇÁâπÂæÅË°®Á§∫`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊú∫Âô®‰∫∫Â≠¶‰π†ÊñπÊ≥ïÈÄöÂ∏∏‰ªÖÂà©Áî®ViTÊúÄÂêé‰∏ÄÂ±ÇÁâπÂæÅÔºåÂøΩÁï•‰∫ÜViT‰∏≠Èó¥Â±ÇÊâÄÂåÖÂê´ÁöÑ‰∏∞ÂØåËßÜËßâ‰ø°ÊÅØ„ÄÇ
2. VATÈÄöËøáÂú®ViTÁöÑÊØè‰∏ÄÂ±ÇËûçÂêàËßÜËßâÁâπÂæÅÂíåÂä®‰ΩútokensÔºåÂÆûÁé∞‰∫ÜÊÑüÁü•ÂíåÂä®‰ΩúÁîüÊàêÁöÑÊ∑±Â∫¶ËûçÂêà„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåVATÂú®Ê®°ÊãüÊìç‰Ωú‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊñπÊ≥ïÔºåËææÂà∞‰∫ÜÊñ∞ÁöÑSOTA„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®Êú∫Âô®‰∫∫Â≠¶‰π†‰∏≠ÔºåVision Transformers (ViTs) Â∑≤Êàê‰∏∫ËßÜËßâÊÑüÁü•ÁöÑÊ†áÂáÜÔºå‰ΩÜÂ§ßÂ§öÊï∞ÊñπÊ≥ï‰ªÖ‰ΩøÁî®ÊúÄÂêé‰∏ÄÂ±ÇÁöÑÁâπÂæÅÔºå‰ªéËÄå‰∏¢ÂºÉ‰∫ÜÂÆùË¥µÁöÑ‰ø°ÊÅØ„ÄÇÊàë‰ª¨ËÆ§‰∏∫ËøôÊèê‰æõ‰∫Ü‰∏çÂÖÖÂàÜÁöÑË°®Á§∫ÔºåÂπ∂ÊèêÂá∫‰∫Ü Vision Action Transformer (VAT)ÔºåËøôÊòØ‰∏ÄÁßç‰ªé ViT Êâ©Â±ïËÄåÊù•ÁöÑÊñ∞ÂûãÊû∂ÊûÑÔºåÂèØËß£ÈîÅ ViT ÁöÑÂÆåÊï¥ÁâπÂæÅÂ±ÇÊ¨°ÁªìÊûÑ„ÄÇVAT ‰ΩøÁî®Ë∑®ÊâÄÊúâ Transformer Â±ÇÁöÑËßÜËßâÁâπÂæÅÂ§ÑÁêÜ‰∏ìÈó®ÁöÑÂä®‰Ωú tokensÔºå‰ªéËÄåÂÆûÁé∞ÊÑüÁü•ÂíåÂä®‰ΩúÁîüÊàêÁöÑÊ∑±Â∫¶ÂíåÊ∏êËøõÂºèËûçÂêà„ÄÇÂú®‰∏ÄÂ•óÊ®°ÊãüÊìç‰Ωú‰ªªÂä°‰∏≠ÔºåVAT Âú®Âõõ‰∏™ LIBERO Âü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫Ü 98.15% ÁöÑÂπ≥ÂùáÊàêÂäüÁéáÔºåÈÄöËøá‰ºò‰∫é OpenVLA-OFT Á≠âÂÖàÂâçÊñπÊ≥ïÔºåÂª∫Á´ã‰∫ÜÊñ∞ÁöÑÊúÄÂÖàËøõÊ∞¥Âπ≥„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰Ωú‰∏ç‰ªÖÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âº∫Â§ßÁöÑÊ®°‰ªøÂ≠¶‰π†Ê®°ÂûãÔºåËøòËØÅÊòé‰∫ÜÂà©Áî®ËßÜËßâÊ®°ÂûãÁöÑÂÆåÊï¥‚ÄúË°®Á§∫ËΩ®Ëøπ‚ÄùÂØπ‰∫éÊé®ËøõÊú∫Âô®‰∫∫Á≠ñÁï•Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éViTÁöÑÊú∫Âô®‰∫∫Â≠¶‰π†ÊñπÊ≥ïÈÄöÂ∏∏Âè™‰ΩøÁî®ViTÊúÄÂêé‰∏ÄÂ±ÇÁöÑÁâπÂæÅÔºåËøôÂØºËá¥‰∫Ü‰ø°ÊÅØÁì∂È¢àÔºåÊó†Ê≥ïÂÖÖÂàÜÂà©Áî®ViTÁöÑÂÖ®ÈÉ®Ë°®ÂæÅËÉΩÂäõ„ÄÇËøôÁßçÂÅöÊ≥ïÂøΩÁï•‰∫ÜViT‰∏≠Èó¥Â±ÇÊâÄÂåÖÂê´ÁöÑ‰∏∞ÂØåÁöÑËßÜËßâ‰ø°ÊÅØÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÂØπÁéØÂ¢ÉÁöÑÁêÜËß£ÂíåÂØπÂä®‰ΩúÁöÑËßÑÂàíËÉΩÂäõ„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÊúâÊïàÂà©Áî®ViTÁöÑÂÆåÊï¥ÁâπÂæÅÂ±ÇÁ∫ßÁªìÊûÑÊàê‰∏∫‰∫Ü‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVATÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂÖÖÂàÜÂà©Áî®ViTÁöÑÊØè‰∏ÄÂ±ÇÁâπÂæÅÔºåÈÄöËøáÂ∞ÜËßÜËßâÁâπÂæÅÂíåÂä®‰ΩútokensÂú®ÊØè‰∏ÄÂ±ÇËøõË°åËûçÂêàÔºåÂÆûÁé∞ÊÑüÁü•ÂíåÂä®‰ΩúÁîüÊàêÁöÑÊ∑±Â∫¶ËûçÂêà„ÄÇËøôÁßçÊ∏êËøõÂºèÁöÑËûçÂêàÊñπÂºèÂÖÅËÆ∏Ê®°ÂûãÂú®‰∏çÂêåÁöÑÊäΩË±°Â±ÇÊ¨°‰∏äÁêÜËß£ÁéØÂ¢ÉÔºåÂπ∂ÁîüÊàêÊõ¥Á≤æÁ°ÆÁöÑÂä®‰Ωú„ÄÇÈÄöËøáËß£ÈîÅViTÁöÑÂÆåÊï¥ÁâπÂæÅÂ±ÇÁ∫ßÁªìÊûÑÔºåVATËÉΩÂ§üËé∑ÂæóÊõ¥‰∏∞ÂØåÁöÑÁéØÂ¢ÉË°®ÂæÅÔºå‰ªéËÄåÊèêÈ´òÊú∫Âô®‰∫∫Á≠ñÁï•ÁöÑÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVATÁöÑÊï¥‰ΩìÊû∂ÊûÑÂü∫‰∫éViTÔºåÂπ∂ÂºïÂÖ•‰∫Ü‰∏ìÈó®ÁöÑÂä®‰Ωútokens„ÄÇÈ¶ñÂÖàÔºåËæìÂÖ•ÂõæÂÉèÈÄöËøáViTËøõË°åÁºñÁ†ÅÔºåÂæóÂà∞ÊØè‰∏ÄÂ±ÇÁöÑËßÜËßâÁâπÂæÅ„ÄÇÁÑ∂ÂêéÔºåÂä®‰Ωútokens‰∏éÊØè‰∏ÄÂ±ÇÁöÑËßÜËßâÁâπÂæÅËøõË°åËûçÂêàÔºåËûçÂêàÂêéÁöÑÁâπÂæÅË¢´‰º†ÈÄíÂà∞‰∏ã‰∏ÄÂ±Ç„ÄÇÂú®ÊØè‰∏ÄÂ±ÇÔºåÂä®‰ΩútokensÈÉΩ‰ºöÊ†πÊçÆËßÜËßâÁâπÂæÅËøõË°åÊõ¥Êñ∞Ôºå‰ªéËÄåÂÆûÁé∞ÊÑüÁü•ÂíåÂä®‰ΩúÁöÑÊ∏êËøõÂºèËûçÂêà„ÄÇÊúÄÁªàÔºåËûçÂêàÂêéÁöÑÁâπÂæÅË¢´Áî®‰∫éÁîüÊàêÊú∫Âô®‰∫∫ÁöÑÂä®‰Ωú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVATÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂÖ∂ËÉΩÂ§üÂÖÖÂàÜÂà©Áî®ViTÁöÑÂÆåÊï¥ÁâπÂæÅÂ±ÇÁ∫ßÁªìÊûÑ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÂè™‰ΩøÁî®ViTÊúÄÂêé‰∏ÄÂ±ÇÁâπÂæÅ‰∏çÂêåÔºåVATÂú®ÊØè‰∏ÄÂ±ÇÈÉΩËûçÂêà‰∫ÜËßÜËßâÁâπÂæÅÂíåÂä®‰ΩútokensÔºå‰ªéËÄåÂÆûÁé∞‰∫ÜÊÑüÁü•ÂíåÂä®‰ΩúÁöÑÊ∑±Â∫¶ËûçÂêà„ÄÇËøôÁßçÊ∏êËøõÂºèÁöÑËûçÂêàÊñπÂºèÂÖÅËÆ∏Ê®°ÂûãÂú®‰∏çÂêåÁöÑÊäΩË±°Â±ÇÊ¨°‰∏äÁêÜËß£ÁéØÂ¢ÉÔºåÂπ∂ÁîüÊàêÊõ¥Á≤æÁ°ÆÁöÑÂä®‰Ωú„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöVATÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Âä®‰ΩútokensÁöÑÂàùÂßãÂåñÊñπÂºè„ÄÅËßÜËßâÁâπÂæÅÂíåÂä®‰ΩútokensÁöÑËûçÂêàÊñπÂºè‰ª•ÂèäÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°„ÄÇÂä®‰ΩútokensÁöÑÂàùÂßãÂåñÊñπÂºè‰ºöÂΩ±ÂìçÊ®°ÂûãÁöÑÂ≠¶‰π†ÊïàÁéáÂíåÊÄßËÉΩ„ÄÇËßÜËßâÁâπÂæÅÂíåÂä®‰ΩútokensÁöÑËûçÂêàÊñπÂºèÂÜ≥ÂÆö‰∫ÜÊ®°ÂûãÂ¶Ç‰ΩïÂ∞ÜÊÑüÁü•‰ø°ÊÅØÂíåÂä®‰Ωú‰ø°ÊÅØÁªìÂêàËµ∑Êù•„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÂàôÂÜ≥ÂÆö‰∫ÜÊ®°ÂûãÁöÑÂ≠¶‰π†ÁõÆÊ†á„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

VATÂú®LIBEROÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂπ≥ÂùáÊàêÂäüÁéáËææÂà∞‰∫Ü98.15%ÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊñπÊ≥ïÔºå‰æãÂ¶ÇOpenVLA-OFT„ÄÇËøô‰∏ÄÁªìÊûúË°®ÊòéÔºåVATËÉΩÂ§üÊúâÊïàÂà©Áî®ViTÁöÑÂÆåÊï¥ÁâπÂæÅÂ±ÇÁ∫ßÁªìÊûÑÔºå‰ªéËÄåÊèêÈ´òÊú∫Âô®‰∫∫Á≠ñÁï•ÁöÑÊÄßËÉΩ„ÄÇÂÆûÈ™åÁªìÊûúÂÖÖÂàÜËØÅÊòé‰∫ÜVATÁöÑÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

VATÂú®Êú∫Âô®‰∫∫Êìç‰Ωú„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩÂà∂ÈÄ†Á≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éËÆ≠ÁªÉÊú∫Âô®‰∫∫ÂÆåÊàêÂêÑÁßçÂ§çÊùÇÁöÑ‰ªªÂä°Ôºå‰æãÂ¶ÇÁâ©‰ΩìÊäìÂèñ„ÄÅË£ÖÈÖç„ÄÅÂØºËà™Á≠â„ÄÇÈÄöËøáÂà©Áî®ËßÜËßâÊ®°ÂûãÁöÑÂÆåÊï¥Ë°®Á§∫ËΩ®ËøπÔºåVATÂèØ‰ª•ÊèêÈ´òÊú∫Âô®‰∫∫Á≠ñÁï•ÁöÑÊÄßËÉΩÂíåÈ≤ÅÊ£íÊÄßÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥È´òÊïàÁöÑËá™Âä®Âåñ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In robot learning, Vision Transformers (ViTs) are standard for visual perception, yet most methods discard valuable information by using only the final layer's features. We argue this provides an insufficient representation and propose the Vision Action Transformer (VAT), a novel architecture that is extended from ViT and unlocks the full feature hierarchy of ViT. VAT processes specialized action tokens with visual features across all transformer layers, enabling a deep and progressive fusion of perception and action generation. On a suite of simulated manipulation tasks, VAT achieves a 98.15\% average success rate across four LIBERO benchmarks, establishing a new state-of-the-art by outperforming prior methods like OpenVLA-OFT. Our work presents not only a powerful model for imitation learning but also demonstrates the critical importance of leveraging the complete ''representation trajectory'' of vision models to advance robotic policy. The GitHub URL for the project code is https://github.com/sellerbubble/VAT.

