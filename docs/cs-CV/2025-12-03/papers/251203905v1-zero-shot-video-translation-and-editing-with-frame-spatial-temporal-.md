---
layout: default
title: Zero-Shot Video Translation and Editing with Frame Spatial-Temporal Correspondence
---

# Zero-Shot Video Translation and Editing with Frame Spatial-Temporal Correspondence

**arXiv**: [2512.03905v1](https://arxiv.org/abs/2512.03905) | [PDF](https://arxiv.org/pdf/2512.03905.pdf)

**ä½œè€…**: Shuai Yang, Junxin Lin, Yifan Zhou, Ziwei Liu, Chen Change Loy

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFRESCOæ¡†æž¶ï¼Œé€šè¿‡å¢žå¼ºæ—¶ç©ºçº¦æŸè§£å†³é›¶æ ·æœ¬è§†é¢‘ç¿»è¯‘ä¸Žç¼–è¾‘ä¸­çš„æ—¶åºä¸ä¸€è‡´é—®é¢˜ã€‚**

**å…³é”®è¯**: `é›¶æ ·æœ¬å­¦ä¹ ` `è§†é¢‘ç¿»è¯‘` `è§†é¢‘ç¼–è¾‘` `æ—¶ç©ºä¸€è‡´æ€§` `æ‰©æ•£æ¨¡åž‹` `ç‰¹å¾ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰é›¶æ ·æœ¬æ–¹æ³•ä¾èµ–æ³¨æ„åŠ›æœºåˆ¶çš„è½¯çº¦æŸï¼Œå¯¼è‡´è§†é¢‘å¤„ç†æ—¶å‡ºçŽ°æ—¶åºä¸ä¸€è‡´ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆå¸§å†…ä¸Žå¸§é—´å¯¹åº”å…³ç³»ï¼Œæž„å»ºæ›´é²æ£’çš„æ—¶ç©ºçº¦æŸï¼Œä¼˜åŒ–ç‰¹å¾ä»¥æå‡ä¸€è‡´æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨è§†é¢‘åˆ°è§†é¢‘ç¿»è¯‘å’Œæ–‡æœ¬å¼•å¯¼è§†é¢‘ç¼–è¾‘ä»»åŠ¡ä¸­éªŒè¯ï¼Œç”Ÿæˆé«˜è´¨é‡ã€è¿žè´¯çš„è§†é¢‘ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The remarkable success in text-to-image diffusion models has motivated extensive investigation of their potential for video applications. Zero-shot techniques aim to adapt image diffusion models for videos without requiring further model training. Recent methods largely emphasize integrating inter-frame correspondence into attention mechanisms. However, the soft constraint applied to identify the valid features to attend is insufficient, which could lead to temporal inconsistency. In this paper, we present FRESCO, which integrates intra-frame correspondence with inter-frame correspondence to formulate a more robust spatial-temporal constraint. This enhancement ensures a consistent transformation of semantically similar content between frames. Our method goes beyond attention guidance to explicitly optimize features, achieving high spatial-temporal consistency with the input video, significantly enhancing the visual coherence of manipulated videos. We verify FRESCO adaptations on two zero-shot tasks of video-to-video translation and text-guided video editing. Comprehensive experiments demonstrate the effectiveness of our framework in generating high-quality, coherent videos, highlighting a significant advance over current zero-shot methods.

