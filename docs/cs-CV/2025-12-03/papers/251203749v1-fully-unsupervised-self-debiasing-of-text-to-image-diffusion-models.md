---
layout: default
title: Fully Unsupervised Self-debiasing of Text-to-Image Diffusion Models
---

# Fully Unsupervised Self-debiasing of Text-to-Image Diffusion Models

**arXiv**: [2512.03749v1](https://arxiv.org/abs/2512.03749) | [PDF](https://arxiv.org/pdf/2512.03749.pdf)

**ä½œè€…**: Korada Sri Vardhana, Shrikrishna Lolla, Soma Biswas

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSelfDebiasä»¥æ— ç›‘ç£æ–¹å¼å‡å°‘æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡åž‹çš„åè§è¾“å‡º**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `æ— ç›‘ç£åŽ»å` `æ‰©æ•£æ¨¡åž‹` `KLæ•£åº¦ä¼˜åŒ–` `è¯­ä¹‰èšç±»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é—®é¢˜ï¼šæ‰©æ•£æ¨¡åž‹å› è®­ç»ƒæ•°æ®åè§äº§ç”Ÿåˆ»æ¿å›¾åƒè¾“å‡º
2. æ–¹æ³•ï¼šåŸºäºŽå›¾åƒç¼–ç å™¨åµŒå…¥ç©ºé—´èšç±»ï¼Œåœ¨æŽ¨ç†æ—¶å¼•å¯¼æ‰©æ•£è¿‡ç¨‹æœ€å°åŒ–KLæ•£åº¦
3. æ•ˆæžœï¼šåœ¨å¤šç§æç¤ºå’Œæ¨¡åž‹æž¶æž„ä¸­æœ‰æ•ˆåŽ»åï¼Œä¿æŒå›¾åƒè´¨é‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-to-image (T2I) diffusion models have achieved widespread success due to their ability to generate high-resolution, photorealistic images. These models are trained on large-scale datasets, like LAION-5B, often scraped from the internet. However, since this data contains numerous biases, the models inherently learn and reproduce them, resulting in stereotypical outputs. We introduce SelfDebias, a fully unsupervised test-time debiasing method applicable to any diffusion model that uses a UNet as its noise predictor. SelfDebias identifies semantic clusters in an image encoder's embedding space and uses these clusters to guide the diffusion process during inference, minimizing the KL divergence between the output distribution and the uniform distribution. Unlike supervised approaches, SelfDebias does not require human-annotated datasets or external classifiers trained for each generated concept. Instead, it is designed to automatically identify semantic modes. Extensive experiments show that SelfDebias generalizes across prompts and diffusion model architectures, including both conditional and unconditional models. It not only effectively debiases images along key demographic dimensions while maintaining the visual fidelity of the generated images, but also more abstract concepts for which identifying biases is also challenging.

