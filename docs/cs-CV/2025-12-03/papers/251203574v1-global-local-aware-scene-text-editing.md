---
layout: default
title: Global-Local Aware Scene Text Editing
---

# Global-Local Aware Scene Text Editing

**arXiv**: [2512.03574v1](https://arxiv.org/abs/2512.03574) | [PDF](https://arxiv.org/pdf/2512.03574.pdf)

**ä½œè€…**: Fuxiang Yang, Tonghua Su, Donglin Di, Yin Chen, Xiangqian Wu, Zhongjie Wang, Lei Fan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGLASTEæ¡†æž¶ä»¥è§£å†³åœºæ™¯æ–‡æœ¬ç¼–è¾‘ä¸­çš„ä¸ä¸€è‡´æ€§å’Œé•¿åº¦ä¸æ•æ„Ÿé—®é¢˜**

**å…³é”®è¯**: `åœºæ™¯æ–‡æœ¬ç¼–è¾‘` `å…¨å±€-å±€éƒ¨æ„ŸçŸ¥` `æ–‡æœ¬é£Žæ ¼å‘é‡åŒ–` `ä¸€è‡´æ€§ä¿æŒ` `é•¿åº¦æ•æ„Ÿå¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•åœ¨ç¼–è¾‘åŽå±€éƒ¨ä¸Žå…¨å±€ä¸ä¸€è‡´ï¼Œä¸”éš¾ä»¥å¤„ç†æ–‡æœ¬é•¿åº¦å˜åŒ–
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡å…¨å±€-å±€éƒ¨ç»„åˆç»“æž„ã€è”åˆæŸå¤±å’Œæ–‡æœ¬é£Žæ ¼å‘é‡åŒ–ï¼Œç¡®ä¿é£Žæ ¼ä¸€è‡´ä¸Žå’Œè°
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žæ•°æ®é›†ä¸ŠéªŒè¯ï¼ŒGLASTEåœ¨å®šé‡å’Œå®šæ€§ç»“æžœä¸Šä¼˜äºŽå…ˆå‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Scene Text Editing (STE) involves replacing text in a scene image with new target text while preserving both the original text style and background texture. Existing methods suffer from two major challenges: inconsistency and length-insensitivity. They often fail to maintain coherence between the edited local patch and the surrounding area, and they struggle to handle significant differences in text length before and after editing. To tackle these challenges, we propose an end-to-end framework called Global-Local Aware Scene Text Editing (GLASTE), which simultaneously incorporates high-level global contextual information along with delicate local features. Specifically, we design a global-local combination structure, joint global and local losses, and enhance text image features to ensure consistency in text style within local patches while maintaining harmony between local and global areas. Additionally, we express the text style as a vector independent of the image size, which can be transferred to target text images of various sizes. We use an affine fusion to fill target text images into the editing patch while maintaining their aspect ratio unchanged. Extensive experiments on real-world datasets validate that our GLASTE model outperforms previous methods in both quantitative metrics and qualitative results and effectively mitigates the two challenges.

