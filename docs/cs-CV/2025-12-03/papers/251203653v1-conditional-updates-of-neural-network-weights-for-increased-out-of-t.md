---
layout: default
title: Conditional updates of neural network weights for increased out of training performance
---

# Conditional updates of neural network weights for increased out of training performance

**arXiv**: [2512.03653v1](https://arxiv.org/abs/2512.03653) | [PDF](https://arxiv.org/pdf/2512.03653.pdf)

**ä½œè€…**: Jan Saynisch-Wagner, Saran Rajendran Sari

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¡ä»¶æ€§æƒé‡æ›´æ–°æ–¹æ³•ä»¥å¢žå¼ºç¥žç»ç½‘ç»œåœ¨è®­ç»ƒæ•°æ®ä¸Žåº”ç”¨æ•°æ®ä¸ç›¸ä¼¼æ—¶çš„æ€§èƒ½**

**å…³é”®è¯**: `æ¡ä»¶æ€§æƒé‡æ›´æ–°` `åˆ†å¸ƒå¤–æ³›åŒ–` `æƒé‡å¤–æŽ¨` `æ°”å€™ç§‘å­¦åº”ç”¨` `ç¥žç»ç½‘ç»œé€‚åº”`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè®­ç»ƒæ•°æ®ä¸Žåº”ç”¨æ•°æ®ä¸ç›¸ä¼¼ï¼ˆå¦‚åˆ†å¸ƒå¤–é—®é¢˜ã€æ¨¡å¼æˆ–ä½“åˆ¶åç§»ï¼‰å¯¼è‡´ç¥žç»ç½‘ç»œæ€§èƒ½ä¸‹é™
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡é‡è®­ç»ƒå­é›†èŽ·å–æƒé‡å¼‚å¸¸ï¼Œå»ºç«‹é¢„æµ‹å™¨ä¸Žå¼‚å¸¸çš„å›žå½’å…³ç³»ï¼Œå¹¶å¤–æŽ¨æƒé‡è‡³åº”ç”¨æ•°æ®
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ°”å€™ç§‘å­¦ä¸‰ä¸ªç”¨ä¾‹ä¸­æˆåŠŸå®žçŽ°æ—¶é—´ã€ç©ºé—´å’Œè·¨åŸŸå¤–æŽ¨

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This study proposes a method to enhance neural network performance when training data and application data are not very similar, e.g., out of distribution problems, as well as pattern and regime shifts. The method consists of three main steps: 1) Retrain the neural network towards reasonable subsets of the training data set and note down the resulting weight anomalies. 2) Choose reasonable predictors and derive a regression between the predictors and the weight anomalies. 3) Extrapolate the weights, and thereby the neural network, to the application data. We show and discuss this method in three use cases from the climate sciences, which include successful temporal, spatial and cross-domain extrapolations of neural networks.

