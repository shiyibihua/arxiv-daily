---
layout: default
title: Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy
---

# Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy

**arXiv**: [2512.03883v1](https://arxiv.org/abs/2512.03883) | [PDF](https://arxiv.org/pdf/2512.03883.pdf)

**ä½œè€…**: Jorge Tapias Gomez, Despoina Kanata, Aneesh Rangnekar, Christina Lee, Julio Garcia-Aguilar, Joshua Jesse Smith, Harini Veeraraghavan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒäº¤å‰æ³¨æ„åŠ›å­ªç”ŸSwin Transformerï¼Œç”¨äºŽç›´è‚ ç™Œè§‚å¯Ÿç­‰å¾…å†…é•œä¸­çš„è‚¿ç˜¤å†ç”Ÿè¯„ä¼°ã€‚**

**å…³é”®è¯**: `ç›´è‚ ç™Œå†ç”Ÿè¯„ä¼°` `å­ªç”ŸTransformer` `åŒäº¤å‰æ³¨æ„åŠ›` `å†…é•œå›¾åƒåˆ†æž` `çºµå‘åŒ»å­¦å½±åƒ` `Swin Transformer`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç›´è‚ ç™Œè§‚å¯Ÿç­‰å¾…æœŸé—´ï¼Œä»Žéšè®¿å†…é•œå›¾åƒä¸­æ—©æœŸæ£€æµ‹å±€éƒ¨å†ç”Ÿç¼ºä¹å®¢è§‚å‡†ç¡®æ–¹æ³•ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å­ªç”ŸSwin Transformerç»“åˆåŒäº¤å‰æ³¨æ„åŠ›ï¼Œæ— éœ€å›¾åƒç©ºé—´å¯¹é½ï¼Œæ•´åˆçºµå‘å›¾åƒç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨62åæ‚£è€…æµ‹è¯•é›†ä¸Šï¼Œæ¨¡åž‹å¹³è¡¡å‡†ç¡®çŽ‡è¾¾81.76%ï¼Œå¯¹å›¾åƒä¼ªå½±å…·æœ‰é²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Increasing evidence supports watch-and-wait (WW) surveillance for patients with rectal cancer who show clinical complete response (cCR) at restaging following total neoadjuvant treatment (TNT). However, objectively accurate methods to early detect local regrowth (LR) from follow-up endoscopy images during WW are essential to manage care and prevent distant metastases. Hence, we developed a Siamese Swin Transformer with Dual Cross-Attention (SSDCA) to combine longitudinal endoscopic images at restaging and follow-up and distinguish cCR from LR. SSDCA leverages pretrained Swin transformers to extract domain agnostic features and enhance robustness to imaging variations. Dual cross attention is implemented to emphasize features from the two scans without requiring any spatial alignment of images to predict response. SSDCA as well as Swin-based baselines were trained using image pairs from 135 patients and evaluated on a held-out set of image pairs from 62 patients. SSDCA produced the best balanced accuracy (81.76\% $\pm$ 0.04), sensitivity (90.07\% $\pm$ 0.08), and specificity (72.86\% $\pm$ 0.05). Robustness analysis showed stable performance irrespective of artifacts including blood, stool, telangiectasia, and poor image quality. UMAP clustering of extracted features showed maximal inter-cluster separation (1.45 $\pm$ 0.18) and minimal intra-cluster dispersion (1.07 $\pm$ 0.19) with SSDCA, confirming discriminative representation learning.

