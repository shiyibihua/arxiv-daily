---
layout: default
title: Emergent Outlier View Rejection in Visual Geometry Grounded Transformers
---

# Emergent Outlier View Rejection in Visual Geometry Grounded Transformers

**arXiv**: [2512.04012v1](https://arxiv.org/abs/2512.04012) | [PDF](https://arxiv.org/pdf/2512.04012.pdf)

**ä½œè€…**: Jisang Han, Sunghwan Hong, Jaewoo Jung, Wooseok Jang, Honggyu An, Qianqian Wang, Seungryong Kim, Chen Feng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å‘çŽ°å‰é¦ˆä¸‰ç»´é‡å»ºæ¨¡åž‹VGGTéšå«ç¦»ç¾¤è§†å›¾æŠ‘åˆ¶èƒ½åŠ›ï¼Œæ— éœ€é¢å¤–è®­ç»ƒå³å¯æå‡é‡Žå¤–å›¾åƒé‡å»ºé²æ£’æ€§ã€‚**

**å…³é”®è¯**: `ä¸‰ç»´é‡å»º` `ç¦»ç¾¤è§†å›¾æŠ‘åˆ¶` `å‰é¦ˆæ¨¡åž‹` `è§†è§‰å‡ ä½•` `Transformer` `é‡Žå¤–å›¾åƒå¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé‡Žå¤–å›¾åƒé›†åˆä¸­çš„å™ªå£°å›¾åƒï¼ˆå¦‚æ— é‡å è§†å›¾ï¼‰ä¼šé™ä½Žå‰é¦ˆä¸‰ç»´é‡å»ºæ¨¡åž‹çš„æ€§èƒ½ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ†æžVGGTæ¨¡åž‹ï¼Œè¯†åˆ«å‡ºç‰¹å®šå±‚è‡ªç„¶ç¼–ç ç¦»ç¾¤æŠ‘åˆ¶è¡¨ç¤ºï¼Œç›´æŽ¥ç”¨äºŽç¦»ç¾¤è§†å›¾è¿‡æ»¤ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å—æŽ§å’Œé‡Žå¤–æ•°æ®é›†ä¸ŠéªŒè¯è¯¥éšå«è¿‡æ»¤æœºåˆ¶çš„ä¸€è‡´æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reliable 3D reconstruction from in-the-wild image collections is often hindered by "noisy" images-irrelevant inputs with little or no view overlap with others. While traditional Structure-from-Motion pipelines handle such cases through geometric verification and outlier rejection, feed-forward 3D reconstruction models lack these explicit mechanisms, leading to degraded performance under in-the-wild conditions. In this paper, we discover that the existing feed-forward reconstruction model, e.g., VGGT, despite lacking explicit outlier-rejection mechanisms or noise-aware training, can inherently distinguish distractor images. Through an in-depth analysis under varying proportions of synthetic distractors, we identify a specific layer that naturally exhibits outlier-suppressing behavior. Further probing reveals that this layer encodes discriminative internal representations that enable an effective noise-filtering capability, which we simply leverage to perform outlier-view rejection in feed-forward 3D reconstruction without any additional fine-tuning or supervision. Extensive experiments on both controlled and in-the-wild datasets demonstrate that this implicit filtering mechanism is consistent and generalizes well across diverse scenarios.

