---
layout: default
title: DirectDrag: High-Fidelity, Mask-Free, Prompt-Free Drag-based Image Editing via Readout-Guided Feature Alignment
---

# DirectDrag: High-Fidelity, Mask-Free, Prompt-Free Drag-based Image Editing via Readout-Guided Feature Alignment

**arXiv**: [2512.03981v1](https://arxiv.org/abs/2512.03981) | [PDF](https://arxiv.org/pdf/2512.03981.pdf)

**ä½œè€…**: Sheng-Hao Liao, Shang-Fu Chen, Tai-Ming Huang, Wen-Huang Cheng, Kai-Lung Hua

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDirectDragæ¡†æž¶ï¼Œå®žçŽ°æ— éœ€æŽ©ç å’Œæç¤ºçš„é«˜ä¿çœŸæ‹–æ‹½å¼å›¾åƒç¼–è¾‘**

**å…³é”®è¯**: `æ‹–æ‹½å¼å›¾åƒç¼–è¾‘` `æŽ©ç ç”Ÿæˆ` `ç‰¹å¾å¯¹é½` `ç”Ÿæˆæ¨¡åž‹` `å›¾åƒä¿çœŸåº¦` `äº¤äº’å¼ç¼–è¾‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ‹–æ‹½ç¼–è¾‘æ–¹æ³•ä¾èµ–æ‰‹åŠ¨æŽ©ç å’Œæ–‡æœ¬æç¤ºï¼ŒåŽ»é™¤åŽæ˜“äº§ç”Ÿè§†è§‰ä¼ªå½±æˆ–ç©ºé—´æŽ§åˆ¶å·®
2. å¼•å…¥è‡ªåŠ¨è½¯æŽ©ç ç”Ÿæˆå’Œè¯»å‡ºå¼•å¯¼ç‰¹å¾å¯¹é½æœºåˆ¶ï¼Œæ™ºèƒ½æŽ¨æ–­å¯ç¼–è¾‘åŒºåŸŸå¹¶ä¿æŒç»“æž„ä¸€è‡´æ€§
3. åœ¨DragBenchå’ŒçœŸå®žåœºæ™¯å®žéªŒä¸­ï¼ŒDirectDragåœ¨å›¾åƒè´¨é‡å’Œæ‹–æ‹½ç²¾åº¦ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Drag-based image editing using generative models provides intuitive control over image structures. However, existing methods rely heavily on manually provided masks and textual prompts to preserve semantic fidelity and motion precision. Removing these constraints creates a fundamental trade-off: visual artifacts without masks and poor spatial control without prompts. To address these limitations, we propose DirectDrag, a novel mask- and prompt-free editing framework. DirectDrag enables precise and efficient manipulation with minimal user input while maintaining high image fidelity and accurate point alignment. DirectDrag introduces two key innovations. First, we design an Auto Soft Mask Generation module that intelligently infers editable regions from point displacement, automatically localizing deformation along movement paths while preserving contextual integrity through the generative model's inherent capacity. Second, we develop a Readout-Guided Feature Alignment mechanism that leverages intermediate diffusion activations to maintain structural consistency during point-based edits, substantially improving visual fidelity. Despite operating without manual mask or prompt, DirectDrag achieves superior image quality compared to existing methods while maintaining competitive drag accuracy. Extensive experiments on DragBench and real-world scenarios demonstrate the effectiveness and practicality of DirectDrag for high-quality, interactive image manipulation. Project Page: https://frakw.github.io/DirectDrag/. Code is available at: https://github.com/frakw/DirectDrag.

