---
layout: default
title: AdaPower: Specializing World Foundation Models for Predictive Manipulation
---

# AdaPower: Specializing World Foundation Models for Predictive Manipulation

**arXiv**: [2512.03538v1](https://arxiv.org/abs/2512.03538) | [PDF](https://arxiv.org/pdf/2512.03538.pdf)

**ä½œè€…**: Yuhang Huang, Shilong Zou, Jiazhao Zhang, Xinwang Liu, Ruizhen Hu, Kai Xu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAdaPoweræ¡†æž¶ï¼Œé€šè¿‡è½»é‡é€‚åº”å°†é€šç”¨ä¸–ç•ŒåŸºç¡€æ¨¡åž‹è½¬åŒ–ä¸ºä¸“ç”¨ä¸–ç•Œæ¨¡åž‹ï¼Œä»¥æå‡é¢„è®­ç»ƒè§†è§‰è¯­è¨€ç­–ç•¥åœ¨æœºå™¨äººæŽ§åˆ¶ä¸­çš„ä»»åŠ¡æˆåŠŸçŽ‡ã€‚**

**å…³é”®è¯**: `ä¸–ç•ŒåŸºç¡€æ¨¡åž‹` `æœºå™¨äººæŽ§åˆ¶` `è½»é‡é€‚åº”` `æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶` `æµ‹è¯•æ—¶è®­ç»ƒ` `é•¿æ—¶ç¨‹ä¸€è‡´æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¸–ç•ŒåŸºç¡€æ¨¡åž‹åœ¨æœºå™¨äººæŽ§åˆ¶ä¸­å› ç”ŸæˆçœŸå®žæ€§ä¸ŽæŽ§åˆ¶ç²¾åº¦å·®è·è€Œå—é™ï¼ŒçŽ°æœ‰æ–¹æ³•è®¡ç®—æˆæœ¬é«˜ä¸”æœªå……åˆ†åˆ©ç”¨é¢„è®­ç»ƒç­–ç•¥ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥AdaPoweræ¡†æž¶ï¼ŒåŒ…å«æ—¶ç©ºæµ‹è¯•æ—¶è®­ç»ƒå’Œè®°å¿†æŒä¹…åŒ–ç»„ä»¶ï¼Œç”¨äºŽæŽ¨ç†æ—¶é€‚åº”å’Œé•¿æ—¶ç¨‹ä¸€è‡´æ€§ï¼Œé›†æˆäºŽæ¨¡åž‹é¢„æµ‹æŽ§åˆ¶æ¡†æž¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨LIBEROåŸºå‡†ä¸Šï¼Œä»»åŠ¡æˆåŠŸçŽ‡æå‡è¶…è¿‡41%ï¼Œæ— éœ€ç­–ç•¥é‡è®­ç»ƒï¼Œä¿æŒè®¡ç®—æ•ˆçŽ‡å’Œé€šç”¨èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> World Foundation Models (WFMs) offer remarkable visual dynamics simulation capabilities, yet their application to precise robotic control remains limited by the gap between generative realism and control-oriented precision. While existing approaches use WFMs as synthetic data generators, they suffer from high computational costs and underutilization of pre-trained VLA policies. We introduce \textbf{AdaPower} (\textbf{Ada}pt and Em\textbf{power}), a lightweight adaptation framework that transforms general-purpose WFMs into specialist world models through two novel components: Temporal-Spatial Test-Time Training (TS-TTT) for inference-time adaptation and Memory Persistence (MP) for long-horizon consistency. Integrated within a Model Predictive Control framework, our adapted world model empowers pre-trained VLAs, achieving over 41\% improvement in task success rates on LIBERO benchmarks without policy retraining, while preserving computational efficiency and generalist capabilities.

