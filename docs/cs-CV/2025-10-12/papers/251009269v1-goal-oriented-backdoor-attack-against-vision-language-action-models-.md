---
layout: default
title: Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects
---

# Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects

**arXiv**: [2510.09269v1](https://arxiv.org/abs/2510.09269) | [PDF](https://arxiv.org/pdf/2510.09269.pdf)

**ä½œè€…**: Zirun Zhou, Zhengyang Xiao, Haochuan Xu, Jing Sun, Di Wang, Jingfeng Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç›®æ ‡å¯¼å‘åŽé—¨æ”»å‡»ï¼Œé€šè¿‡ç‰©ç†å¯¹è±¡æ“çºµè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹**

**å…³é”®è¯**: `åŽé—¨æ”»å‡»` `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `ç‰©ç†è§¦å‘` `ç›®æ ‡å¯¼å‘` `å®‰å…¨è¯„ä¼°` `æœºå™¨äººæŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹ä¾èµ–æœªç­›é€‰æ•°æ®é›†ï¼Œæ˜“å—ç‰©ç†å¯¹è±¡åŽé—¨æ”»å‡»å¨èƒã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ³¨å…¥ç‰©ç†è§¦å‘å¯¹è±¡ï¼Œä½¿æ¨¡åž‹åœ¨è§¦å‘æ—¶æ‰§è¡Œé¢„è®¾ç›®æ ‡åŠ¨ä½œï¼Œæ­£å¸¸æ—¶æ— å½±å“ã€‚
3. å®žéªŒæ•ˆæžœï¼šæ”»å‡»æˆåŠŸçŽ‡97%ï¼Œæ¸…æ´è¾“å…¥æ€§èƒ½é›¶ä¸‹é™ï¼ŒåŠ¨ä½œè½¨è¿¹å’Œé¢œè‰²å½±å“æ˜¾è‘—ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in vision-language-action (VLA) models have greatly improved
> embodied AI, enabling robots to follow natural language instructions and
> perform diverse tasks. However, their reliance on uncurated training datasets
> raises serious security concerns. Existing backdoor attacks on VLAs mostly
> assume white-box access and result in task failures instead of enforcing
> specific actions. In this work, we reveal a more practical threat: attackers
> can manipulate VLAs by simply injecting physical objects as triggers into the
> training dataset. We propose goal-oriented backdoor attacks (GoBA), where the
> VLA behaves normally in the absence of physical triggers but executes
> predefined and goal-oriented actions in the presence of physical triggers.
> Specifically, based on a popular VLA benchmark LIBERO, we introduce BadLIBERO
> that incorporates diverse physical triggers and goal-oriented backdoor actions.
> In addition, we propose a three-level evaluation that categorizes the victim
> VLA's actions under GoBA into three states: nothing to do, try to do, and
> success to do. Experiments show that GoBA enables the victim VLA to
> successfully achieve the backdoor goal in 97 percentage of inputs when the
> physical trigger is present, while causing zero performance degradation on
> clean inputs. Finally, by investigating factors related to GoBA, we find that
> the action trajectory and trigger color significantly influence attack
> performance, while trigger size has surprisingly little effect. The code and
> BadLIBERO dataset are accessible via the project page at
> https://goba-attack.github.io/.

