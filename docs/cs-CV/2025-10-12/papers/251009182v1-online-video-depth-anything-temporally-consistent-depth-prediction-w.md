---
layout: default
title: Online Video Depth Anything: Temporally-Consistent Depth Prediction with Low Memory Consumption
---

# Online Video Depth Anything: Temporally-Consistent Depth Prediction with Low Memory Consumption

**arXiv**: [2510.09182v1](https://arxiv.org/abs/2510.09182) | [PDF](https://arxiv.org/pdf/2510.09182.pdf)

**ä½œè€…**: Johann-Friedrich Feiden, Tim KÃ¼chler, Denis Zavadski, Bogdan Savchynskyy, Carsten Rother

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåœ¨çº¿è§†é¢‘æ·±åº¦é¢„æµ‹æ–¹æ³•oVDAï¼Œå®ç°ä½å†…å­˜æ¶ˆè€—å’Œæ—¶åºä¸€è‡´æ€§ã€‚**

**å…³é”®è¯**: `åœ¨çº¿è§†é¢‘æ·±åº¦ä¼°è®¡` `æ—¶åºä¸€è‡´æ€§` `ä½å†…å­˜æ¶ˆè€—` `è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²` `æ½œåœ¨ç‰¹å¾ç¼“å­˜`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰è§†é¢‘æ·±åº¦é¢„æµ‹æ–¹æ³•ä¾èµ–æ‰¹å¤„ç†ï¼Œæ— æ³•åœ¨çº¿å®æ—¶åº”ç”¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå€Ÿé‰´LLMæŠ€æœ¯ï¼Œç¼“å­˜æ½œåœ¨ç‰¹å¾å¹¶è®­ç»ƒæ—¶æ©ç å¸§ã€‚
3. å®éªŒæ•ˆæœï¼šåœ¨ç²¾åº¦å’ŒVRAMä½¿ç”¨ä¸Šä¼˜äºå…¶ä»–åœ¨çº¿æ–¹æ³•ï¼Œè¾¹ç¼˜è®¾å¤‡å¯è¾¾20 FPSã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Depth estimation from monocular video has become a key component of many
> real-world computer vision systems. Recently, Video Depth Anything (VDA) has
> demonstrated strong performance on long video sequences. However, it relies on
> batch-processing which prohibits its use in an online setting. In this work, we
> overcome this limitation and introduce online VDA (oVDA). The key innovation is
> to employ techniques from Large Language Models (LLMs), namely, caching latent
> features during inference and masking frames at training. Our oVDA method
> outperforms all competing online video depth estimation methods in both
> accuracy and VRAM usage. Low VRAM usage is particularly important for
> deployment on edge devices. We demonstrate that oVDA runs at 42 FPS on an
> NVIDIA A100 and at 20 FPS on an NVIDIA Jetson edge device. We will release
> both, code and compilation scripts, making oVDA easy to deploy on low-power
> hardware.

