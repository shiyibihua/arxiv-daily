---
layout: default
title: Boosting Multi-modal Keyphrase Prediction with Dynamic Chain-of-Thought in Vision-Language Models
---

# Boosting Multi-modal Keyphrase Prediction with Dynamic Chain-of-Thought in Vision-Language Models

**arXiv**: [2510.09358v1](https://arxiv.org/abs/2510.09358) | [PDF](https://arxiv.org/pdf/2510.09358.pdf)

**ä½œè€…**: Qihang Ma, Shengyu Li, Jie Tang, Dingkang Yang, Shaodong Chen, Yingyi Zhang, Chao Feng, Jiao Ran

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŠ¨æ€æ€ç»´é“¾ç­–ç•¥ä»¥æå‡è§†è§‰è¯­è¨€æ¨¡åž‹åœ¨å¤šæ¨¡æ€å…³é”®è¯é¢„æµ‹ä¸­çš„æŽ¨ç†èƒ½åŠ›**

**å…³é”®è¯**: `å¤šæ¨¡æ€å…³é”®è¯é¢„æµ‹` `è§†è§‰è¯­è¨€æ¨¡åž‹` `æ€ç»´é“¾æŽ¨ç†` `åŠ¨æ€è®­ç»ƒç­–ç•¥` `æ¨¡åž‹å¾®è°ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€å…³é”®è¯é¢„æµ‹åœ¨ç¼ºå¤±å’Œæœªè§åœºæ™¯ä¸­è¡¨çŽ°ä¸ä½³ï¼Œä¸”çŽ°æœ‰åŸºå‡†é«˜ä¼°æ¨¡åž‹èƒ½åŠ›
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨é›¶æ ·æœ¬å’Œå¾®è°ƒè¯„ä¼°åŸºçº¿ï¼Œå¹¶å¼•å…¥åŠ¨æ€æ€ç»´é“¾ç­–ç•¥ä¼˜åŒ–æŽ¨ç†è¿‡ç¨‹
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä»£ç å·²å¼€æº

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-modal keyphrase prediction (MMKP) aims to advance beyond text-only
> methods by incorporating multiple modalities of input information to produce a
> set of conclusive phrases. Traditional multi-modal approaches have been proven
> to have significant limitations in handling the challenging absence and unseen
> scenarios. Additionally, we identify shortcomings in existing benchmarks that
> overestimate model capability due to significant overlap in training tests. In
> this work, we propose leveraging vision-language models (VLMs) for the MMKP
> task. Firstly, we use two widely-used strategies, e.g., zero-shot and
> supervised fine-tuning (SFT) to assess the lower bound performance of VLMs.
> Next, to improve the complex reasoning capabilities of VLMs, we adopt
> Fine-tune-CoT, which leverages high-quality CoT reasoning data generated by a
> teacher model to finetune smaller models. Finally, to address the
> "overthinking" phenomenon, we propose a dynamic CoT strategy which adaptively
> injects CoT data during training, allowing the model to flexibly leverage its
> reasoning capabilities during the inference stage. We evaluate the proposed
> strategies on various datasets and the experimental results demonstrate the
> effectiveness of the proposed approaches. The code is available at
> https://github.com/bytedance/DynamicCoT.

