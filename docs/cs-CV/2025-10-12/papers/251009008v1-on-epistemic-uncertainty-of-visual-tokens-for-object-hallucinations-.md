---
layout: default
title: On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models
---

# On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models

**arXiv**: [2510.09008v1](https://arxiv.org/abs/2510.09008) | [PDF](https://arxiv.org/pdf/2510.09008.pdf)

**ä½œè€…**: Hoigi Seo, Dong Un Kang, Hyunjin Cho, Joohoon Lee, Se Young Chun

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§†è§‰ç¼–ç å™¨ä¿®æ”¹ç­–ç•¥ä»¥ç¼“è§£å¤§è§†è§‰è¯­è¨€æ¨¡åž‹ä¸­çš„ç‰©ä½“å¹»è§‰é—®é¢˜**

**å…³é”®è¯**: `å¤§è§†è§‰è¯­è¨€æ¨¡åž‹` `ç‰©ä½“å¹»è§‰` `è§†è§‰ç¼–ç å™¨` `å¯¹æŠ—æ‰°åŠ¨` `è‡ªæ³¨æ„åŠ›æŽ©ç ` `ä¸ç¡®å®šæ€§ä¼°è®¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è§†è§‰è¯­è¨€æ¨¡åž‹å­˜åœ¨ç‰©ä½“å¹»è§‰ï¼Œå³ç”Ÿæˆå›¾åƒä¸­ä¸å­˜åœ¨çš„ç‰©ä½“æè¿°ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å¯¹æŠ—æ‰°åŠ¨è¯†åˆ«ä¸ç¡®å®šè§†è§‰ä»¤ç‰Œï¼Œå¹¶åœ¨è‡ªæ³¨æ„åŠ›è¿‡ç¨‹ä¸­æŽ©ç å®ƒä»¬ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒæ˜¾ç¤ºè¯¥æ–¹æ³•æ˜¾è‘—å‡å°‘ç‰©ä½“å¹»è§‰ï¼Œå¹¶èƒ½ä¸Žå…¶ä»–æ–¹æ³•ååŒå·¥ä½œã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large vision-language models (LVLMs), which integrate a vision encoder (VE)
> with a large language model, have achieved remarkable success across various
> tasks. However, there are still crucial challenges in LVLMs such as object
> hallucination, generating descriptions of objects that are not in the input
> image. Here, we argue that uncertain visual tokens within the VE is a key
> factor that contributes to object hallucination. Our statistical analysis found
> that there are positive correlations between visual tokens with high epistemic
> uncertainty and the occurrence of hallucinations. Furthermore, we show
> theoretically and empirically that visual tokens in early VE layers that
> exhibit large representation deviations under small adversarial perturbations
> indicate high epistemic uncertainty. Based on these findings, we propose a
> simple yet effective strategy to mitigate object hallucination by modifying the
> VE only. Our method comprises a proxy method with adversarial perturbations for
> identifying uncertain visual tokens efficiently and a method to mask these
> uncertain visual tokens during the self-attention process in the middle layers
> of the VE, suppressing their influence on visual encoding and thus alleviating
> hallucinations. Extensive experiments show that our method significantly
> reduces object hallucinations in LVLMs and can synergistically work with other
> prior arts.

