---
layout: default
title: 3D Reconstruction from Transient Measurements with Time-Resolved Transformer
---

# 3D Reconstruction from Transient Measurements with Time-Resolved Transformer

**arXiv**: [2510.09205v1](https://arxiv.org/abs/2510.09205) | [PDF](https://arxiv.org/pdf/2510.09205.pdf)

**ä½œè€…**: Yue Li, Shida Sun, Yu Hong, Feihu Xu, Zhiwei Xiong

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ—¶é—´åˆ†è¾¨Transformerä»¥æå‡å…‰å­é«˜æ•ˆæˆåƒä¸­çš„3Dé‡å»ºæ€§èƒ½**

**å…³é”®è¯**: `3Dé‡å»º` `çž¬æ€æµ‹é‡` `æ—¶é—´åˆ†è¾¨Transformer` `éžè§†è·æˆåƒ` `å…‰å­é«˜æ•ˆæˆåƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçž¬æ€æµ‹é‡ä¸­ä¼ æ„Ÿå™¨é‡å­æ•ˆçŽ‡ä½Žã€å™ªå£°é«˜ï¼Œå½±å“3Dé‡å»ºã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡æ—¶ç©ºè‡ªæ³¨æ„åŠ›å’Œäº¤å‰æ³¨æ„åŠ›ï¼Œæå–å±€éƒ¨ä¸Žå…¨å±€ç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åˆæˆå’ŒçœŸå®žæ•°æ®ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œè´¡çŒ®æ–°æ•°æ®é›†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Transient measurements, captured by the timeresolved systems, are widely
> employed in photon-efficient reconstruction tasks, including line-of-sight
> (LOS) and non-line-of-sight (NLOS) imaging. However, challenges persist in
> their 3D reconstruction due to the low quantum efficiency of sensors and the
> high noise levels, particularly for long-range or complex scenes. To boost the
> 3D reconstruction performance in photon-efficient imaging, we propose a generic
> Time-Resolved Transformer (TRT) architecture. Different from existing
> transformers designed for high-dimensional data, TRT has two elaborate
> attention designs tailored for the spatio-temporal transient measurements.
> Specifically, the spatio-temporal self-attention encoders explore both local
> and global correlations within transient data by splitting or downsampling
> input features into different scales. Then, the spatio-temporal cross attention
> decoders integrate the local and global features in the token space, resulting
> in deep features with high representation capabilities. Building on TRT, we
> develop two task-specific embodiments: TRT-LOS for LOS imaging and TRT-NLOS for
> NLOS imaging. Extensive experiments demonstrate that both embodiments
> significantly outperform existing methods on synthetic data and real-world data
> captured by different imaging systems. In addition, we contribute a
> large-scale, high-resolution synthetic LOS dataset with various noise levels
> and capture a set of real-world NLOS measurements using a custom-built imaging
> system, enhancing the data diversity in this field. Code and datasets are
> available at https://github.com/Depth2World/TRT.

