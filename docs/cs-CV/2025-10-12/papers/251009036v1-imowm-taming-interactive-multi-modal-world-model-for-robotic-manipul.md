---
layout: default
title: iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation
---

# iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation

**arXiv**: [2510.09036v1](https://arxiv.org/abs/2510.09036) | [PDF](https://arxiv.org/pdf/2510.09036.pdf)

**ä½œè€…**: Chuanrui Zhang, Zhengxian Wu, Guanxing Lu, Yansong Tang, Ziwei Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºiMoWMäº¤äº’å¼å¤šæ¨¡æ€ä¸–ç•Œæ¨¡åž‹ï¼Œä»¥å¢žå¼ºæœºå™¨äººæ“ä½œä¸­çš„ç‰©ç†æŽ¨ç†èƒ½åŠ›ã€‚**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `å¤šæ¨¡æ€ä¸–ç•Œæ¨¡åž‹` `è‡ªå›žå½’ç”Ÿæˆ` `æ·±åº¦é¢„æµ‹` `æ¨¡åž‹å¼ºåŒ–å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰2Dè§†é¢‘ä¸–ç•Œæ¨¡åž‹ç¼ºä¹å‡ ä½•å’Œç©ºé—´æŽ¨ç†ï¼Œéš¾ä»¥æ•æ‰3Dç‰©ç†ç»“æž„ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥MMTokenizerç»Ÿä¸€å¤šæ¨¡æ€è¾“å…¥ï¼Œå®žçŽ°è‡ªå›žå½’ç”Ÿæˆå›¾åƒã€æ·±åº¦å›¾å’Œæœºå™¨äººè‡‚æŽ©ç ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ¨¡åž‹å¼ºåŒ–å­¦ä¹ å’Œæ¨¡ä»¿å­¦ä¹ ä¸­å±•ç¤ºä¼˜è¶Šæ€§ï¼Œæå‡é¢„æµ‹è´¨é‡å’Œä»¿çœŸæ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Learned world models hold significant potential for robotic manipulation, as
> they can serve as simulator for real-world interactions. While extensive
> progress has been made in 2D video-based world models, these approaches often
> lack geometric and spatial reasoning, which is essential for capturing the
> physical structure of the 3D world. To address this limitation, we introduce
> iMoWM, a novel interactive world model designed to generate color images, depth
> maps, and robot arm masks in an autoregressive manner conditioned on actions.
> To overcome the high computational cost associated with three-dimensional
> information, we propose MMTokenizer, which unifies multi-modal inputs into a
> compact token representation. This design enables iMoWM to leverage large-scale
> pretrained VideoGPT models while maintaining high efficiency and incorporating
> richer physical information. With its multi-modal representation, iMoWM not
> only improves the visual quality of future predictions but also serves as an
> effective simulator for model-based reinforcement learning (MBRL) and
> facilitates real-world imitation learning. Extensive experiments demonstrate
> the superiority of iMoWM across these tasks, showcasing the advantages of
> multi-modal world modeling for robotic manipulation. Homepage:
> https://xingyoujun.github.io/imowm/

