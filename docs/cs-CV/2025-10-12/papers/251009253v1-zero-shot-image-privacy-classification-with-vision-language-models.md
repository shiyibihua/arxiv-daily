---
layout: default
title: Zero-shot image privacy classification with Vision-Language Models
---

# Zero-shot image privacy classification with Vision-Language Models

**arXiv**: [2510.09253v1](https://arxiv.org/abs/2510.09253) | [PDF](https://arxiv.org/pdf/2510.09253.pdf)

**ä½œè€…**: Alina Elena Baia, Alessio Xompero, Andrea Cavallaro

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å»ºç«‹é›¶æ ·æœ¬åŸºå‡†ä»¥å…¬å¹³æ¯”è¾ƒè§†è§‰è¯­è¨€æ¨¡å‹åœ¨å›¾åƒéšç§åˆ†ç±»ä¸­çš„æ€§èƒ½ã€‚**

**å…³é”®è¯**: `å›¾åƒéšç§åˆ†ç±»` `è§†è§‰è¯­è¨€æ¨¡å‹` `é›¶æ ·æœ¬å­¦ä¹ ` `åŸºå‡†è¯„ä¼°` `é²æ£’æ€§åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç¼ºä¹ç³»ç»Ÿè¯„ä¼°ï¼Œè§†è§‰è¯­è¨€æ¨¡å‹åœ¨å›¾åƒéšç§é¢„æµ‹ä¸­å¯èƒ½è¢«é«˜ä¼°ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨ä»»åŠ¡å¯¹é½æç¤ºè¯„ä¼°å¼€æºè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå¯¹æ¯”ä¸“ä¸šæ¨¡å‹ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šè§†è§‰è¯­è¨€æ¨¡å‹ç²¾åº¦è¾ƒä½ä½†é²æ£’æ€§æ›´é«˜ï¼Œèµ„æºæ¶ˆè€—å¤§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While specialized learning-based models have historically dominated image
> privacy prediction, the current literature increasingly favours adopting large
> Vision-Language Models (VLMs) designed for generic tasks. This trend risks
> overlooking the performance ceiling set by purpose-built models due to a lack
> of systematic evaluation. To address this problem, we establish a zero-shot
> benchmark for image privacy classification, enabling a fair comparison. We
> evaluate the top-3 open-source VLMs, according to a privacy benchmark, using
> task-aligned prompts and we contrast their performance, efficiency, and
> robustness against established vision-only and multi-modal methods.
> Counter-intuitively, our results show that VLMs, despite their
> resource-intensive nature in terms of high parameter count and slower
> inference, currently lag behind specialized, smaller models in privacy
> prediction accuracy. We also find that VLMs exhibit higher robustness to image
> perturbations.

