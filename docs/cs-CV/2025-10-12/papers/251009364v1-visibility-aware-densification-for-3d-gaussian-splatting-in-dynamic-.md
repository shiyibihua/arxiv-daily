---
layout: default
title: Visibility-Aware Densification for 3D Gaussian Splatting in Dynamic Urban Scenes
---

# Visibility-Aware Densification for 3D Gaussian Splatting in Dynamic Urban Scenes

**arXiv**: [2510.09364v1](https://arxiv.org/abs/2510.09364) | [PDF](https://arxiv.org/pdf/2510.09364.pdf)

**ä½œè€…**: Yikang Zhang, Rui Fan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVAD-GSæ¡†æž¶ä»¥è§£å†³åŠ¨æ€åŸŽå¸‚åœºæ™¯ä¸­3Dé«˜æ–¯æº…å°„çš„å‡ ä½•æ¢å¤é—®é¢˜**

**å…³é”®è¯**: `3Dé«˜æ–¯æº…å°„` `å‡ ä½•æ¢å¤` `åŠ¨æ€åŸŽå¸‚åœºæ™¯` `å¤šè§†å›¾ç«‹ä½“é‡å»º` `å¯è§æ€§æŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŠ¨æ€åŸŽå¸‚åœºæ™¯ä¸­åˆå§‹ç‚¹äº‘è¦†ç›–ä¸å‡å¯¼è‡´3Dé«˜æ–¯æº…å°„äº§ç”Ÿå¤±çœŸå’Œä¼ªå½±
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡ä½“ç´ å¯è§æ€§æŽ¨ç†ã€å¤šæ ·æ€§è§†å›¾é€‰æ‹©å’Œè¡¥ä¸åŒ¹é…å¤šè§†å›¾ç«‹ä½“é‡å»ºæ¢å¤ç¼ºå¤±ç»“æž„
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Waymoå’ŒnuScenesæ•°æ®é›†ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œæå‡é™æ€å’ŒåŠ¨æ€å¯¹è±¡é‡å»ºè´¨é‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> 3D Gaussian splatting (3DGS) has demonstrated impressive performance in
> synthesizing high-fidelity novel views. Nonetheless, its effectiveness
> critically depends on the quality of the initialized point cloud. Specifically,
> achieving uniform and complete point coverage over the underlying scene
> structure requires overlapping observation frustums, an assumption that is
> often violated in unbounded, dynamic urban environments. Training Gaussian
> models with partially initialized point clouds often leads to distortions and
> artifacts, as camera rays may fail to intersect valid surfaces, resulting in
> incorrect gradient propagation to Gaussian primitives associated with occluded
> or invisible geometry. Additionally, existing densification strategies simply
> clone and split Gaussian primitives from existing ones, incapable of
> reconstructing missing structures. To address these limitations, we propose
> VAD-GS, a 3DGS framework tailored for geometry recovery in challenging urban
> scenes. Our method identifies unreliable geometry structures via voxel-based
> visibility reasoning, selects informative supporting views through
> diversity-aware view selection, and recovers missing structures via patch
> matching-based multi-view stereo reconstruction. This design enables the
> generation of new Gaussian primitives guided by reliable geometric priors, even
> in regions lacking initial points. Extensive experiments on the Waymo and
> nuScenes datasets demonstrate that VAD-GS outperforms state-of-the-art 3DGS
> approaches and significantly improves the quality of reconstructed geometry for
> both static and dynamic objects. Source code will be released upon publication.

