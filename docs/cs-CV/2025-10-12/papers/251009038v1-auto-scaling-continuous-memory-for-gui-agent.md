---
layout: default
title: Auto-scaling Continuous Memory for GUI Agent
---

# Auto-scaling Continuous Memory for GUI Agent

**arXiv**: [2510.09038v1](https://arxiv.org/abs/2510.09038) | [PDF](https://arxiv.org/pdf/2510.09038.pdf)

**ä½œè€…**: Wenyi Wu, Kun Zhou, Ruoxin Yuan, Vivian Yu, Stephen Wang, Zhiting Hu, Biwei Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¿žç»­è®°å¿†æ–¹æ³•ä»¥å¢žå¼ºGUIä»£ç†åœ¨é™Œç”Ÿç•Œé¢å’Œé•¿ä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›**

**å…³é”®è¯**: `GUIä»£ç†` `è¿žç»­è®°å¿†` `è§†è§‰è¯­è¨€æ¨¡åž‹` `è‡ªåŠ¨æ‰©å±•` `é•¿ä»»åŠ¡æ³›åŒ–` `åµŒå…¥ç¼–ç `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰GUIä»£ç†åŽ‹ç¼©è½¨è¿¹ä¸ºæ–‡æœ¬ï¼Œå¯¼è‡´ä¸Šä¸‹æ–‡è¿‡é•¿ä¸”ä¸¢å¤±å…³é”®è§†è§‰ä¿¡æ¯ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨VLMç¼–ç è½¨è¿¹ä¸ºå›ºå®šé•¿åº¦è¿žç»­åµŒå…¥ï¼Œç›´æŽ¥è¾“å…¥éª¨å¹²ç½‘ç»œï¼Œé™ä½Žä¸Šä¸‹æ–‡æˆæœ¬ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žGUIåŸºå‡†æµ‹è¯•ä¸­ï¼ŒæˆåŠŸçŽ‡å’Œæ³›åŒ–èƒ½åŠ›æ˜¾è‘—æå‡ï¼Œæ€§èƒ½æŽ¥è¿‘é—­æºæ¨¡åž‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We study how to endow GUI agents with scalable memory that help generalize
> across unfamiliar interfaces and long-horizon tasks. Prior GUI agents compress
> past trajectories into text tokens, which balloons context length and misses
> decisive visual cues (e.g., exact widget size and position). We propose a
> continuous memory that encodes each GUI trajectory into a fixed-length sequence
> of continuous embeddings using the VLM itself as an encoder; these embeddings
> are plugged directly into the backbone's input layer, sharply reducing context
> cost while preserving fine-grained visual information. As memory size and
> retrieval depth increase, performance improves monotonically, unlike text
> memories that degrade with long prompts. To grow memory at low cost, we
> introduce an auto-scaling data flywheel that (i) discovers new environments via
> search, (ii) synthesizes tasks with an open-source VLM, (iii) rolls out
> trajectories with the agent, and (iv) verifies success with the same VLM. Using
> this pipeline, we collect 100k+ trajectories for about \$4000 and fine-tune
> only the memory encoder (LoRA on a Q-Former, 1.2\% parameters) with 1,500
> samples. On real-world GUI benchmarks, our memory-augmented agent consistently
> improves success rates under long horizons and distribution shifts. Notably,
> Qwen-2.5-VL-7B + continuous memory achieves performance comparable to
> state-of-the-art closed-source models (e.g., GPT-4o, Claude-4).

