---
layout: default
title: SOS: Synthetic Object Segments Improve Detection, Segmentation, and Grounding
---

# SOS: Synthetic Object Segments Improve Detection, Segmentation, and Grounding

**arXiv**: [2510.09110v1](https://arxiv.org/abs/2510.09110) | [PDF](https://arxiv.org/pdf/2510.09110.pdf)

**ä½œè€…**: Weikai Huang, Jieyu Zhang, Taoyang Jia, Chenhao Zheng, Ziqi Gao, Jae Sung Park, Ranjay Krishna

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSOSåˆæˆå¯¹è±¡åˆ†å‰²æ•°æ®ç®¡é“ï¼Œæå‡æ£€æµ‹ã€åˆ†å‰²å’Œè§†è§‰å®šä½æ€§èƒ½**

**å…³é”®è¯**: `åˆæˆæ•°æ®ç”Ÿæˆ` `å¯¹è±¡æ£€æµ‹` `å®žä¾‹åˆ†å‰²` `è§†è§‰å®šä½` `æ•°æ®å¢žå¼º` `æ³›åŒ–æ€§èƒ½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçœŸå®žæ ‡æ³¨æ•°æ®æˆæœ¬é«˜ã€åå·®å¤§ï¼Œåˆæˆæ•°æ®ç¼ºä¹å¤šæ ·æ€§å’Œå‡†ç¡®æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå¯¹è±¡ä¸­å¿ƒåˆæˆç­–ç•¥ï¼Œç»“åˆå¸ƒå±€å…ˆéªŒå’Œç”Ÿæˆé‡å…‰ç…§ï¼Œç”Ÿæˆé«˜è´¨é‡åˆæˆæ•°æ®ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ£€æµ‹å’Œè§†è§‰å®šä½ä»»åŠ¡ä¸­ï¼Œä¼˜äºŽå¤§åž‹çœŸå®žæ•°æ®é›†ï¼Œå¹¶å¢žå¼ºä½Žæ•°æ®åœºæ™¯æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Visual grouping -- operationalized via instance segmentation, visual
> grounding, and object detection -- underpins applications from robotic
> perception to photo editing. Large annotated datasets are costly, biased in
> coverage, and hard to scale. Synthetic data are promising but often lack
> flexibility, accuracy, and compositional diversity.
>   We present SOS, a simple and scalable data synthesis pipeline based on an
> object-centric composition strategy. It pastes high-quality synthetic object
> segments into new images using structured layout priors and generative
> relighting, producing accurate and diverse masks, boxes, and referring
> expressions. Models trained on 100000 synthetic images from SOS outperform
> those trained on larger real-image datasets such as GRIT (20M) and V3Det (200K)
> on detection and grounding tasks, achieving +10.9 AP on LVIS detection and +8.4
> $N_{\text{Acc}}$ on gRefCOCO grounding. SOS enables controllable dataset
> construction and improves generalization in both low-data and closed-vocabulary
> settings. Augmenting LVIS and COCO with synthetic object segments yields strong
> performance across real-data scales and even larger gains under extremely
> limited real data (for example, +3.83 $AP_{\text{rare}}$ on LVIS instance
> segmentation and +6.59 AP with a 1 percent COCO setup). This controllability
> also supports targeted data generation for challenging intra-class referring in
> visual grounding.

