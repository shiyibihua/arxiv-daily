---
layout: default
title: Cattle-CLIP: A Multimodal Framework for Cattle Behaviour Recognition
---

# Cattle-CLIP: A Multimodal Framework for Cattle Behaviour Recognition

**arXiv**: [2510.09203v1](https://arxiv.org/abs/2510.09203) | [PDF](https://arxiv.org/pdf/2510.09203.pdf)

**ä½œè€…**: Huimin Liu, Jing Gao, Daria Baran, AxelX Montout, Neill W Campbell, Andrew W Dowsey

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCattle-CLIPå¤šæ¨¡æ€æ¡†æž¶ï¼Œåˆ©ç”¨è¯­ä¹‰æç¤ºæå‡ç‰›åªè¡Œä¸ºè¯†åˆ«æ€§èƒ½ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `ç‰›åªè¡Œä¸ºè¯†åˆ«` `CLIPæ¨¡åž‹` `å°‘æ ·æœ¬å­¦ä¹ ` `æ•°æ®å¢žå¼º` `æ—¶é—´é›†æˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç‰›åªè¡Œä¸ºè¯†åˆ«å¯¹å¥åº·ç›‘æµ‹è‡³å…³é‡è¦ï¼Œä½†æ•°æ®ç¨€ç¼ºåœºæ™¯ä¸‹æ€§èƒ½å—é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽCLIPæ¨¡åž‹ï¼Œæ·»åŠ æ—¶é—´é›†æˆæ¨¡å—ï¼Œå¹¶é‡‡ç”¨æ•°æ®å¢žå¼ºå’Œä¸“ç”¨æ–‡æœ¬æç¤ºã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CattleBehaviours6æ•°æ®é›†ä¸Šï¼Œç›‘ç£å­¦ä¹ å‡†ç¡®çŽ‡è¾¾96.1%ï¼Œå°‘æ ·æœ¬å­¦ä¹ æ³›åŒ–æ€§å¼ºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Cattle behaviour is a crucial indicator of an individual animal health,
> productivity and overall well-being. Video-based monitoring, combined with deep
> learning techniques, has become a mainstream approach in animal biometrics, and
> it can offer high accuracy in some behaviour recognition tasks. We present
> Cattle-CLIP, a multimodal deep learning framework for cattle behaviour
> recognition, using semantic cues to improve the performance of video-based
> visual feature recognition. It is adapted from the large-scale image-language
> model CLIP by adding a temporal integration module. To address the domain gap
> between web data used for the pre-trained model and real-world cattle
> surveillance footage, we introduce tailored data augmentation strategies and
> specialised text prompts. Cattle-CLIP is evaluated under both fully-supervised
> and few-shot learning scenarios, with a particular focus on data-scarce
> behaviour recognition - an important yet under-explored goal in livestock
> monitoring. To evaluate the proposed method, we release the CattleBehaviours6
> dataset, which comprises six types of indoor behaviours: feeding, drinking,
> standing-self-grooming, standing-ruminating, lying-self-grooming and
> lying-ruminating. The dataset consists of 1905 clips collected from our John
> Oldacre Centre dairy farm research platform housing 200 Holstein-Friesian cows.
> Experiments show that Cattle-CLIP achieves 96.1% overall accuracy across six
> behaviours in a supervised setting, with nearly 100% recall for feeding,
> drinking and standing-ruminating behaviours, and demonstrates robust
> generalisation with limited data in few-shot scenarios, highlighting the
> potential of multimodal learning in agricultural and animal behaviour analysis.

