---
layout: default
title: MMAudioSep: Taming Video-to-Audio Generative Model Towards Video/Text-Queried Sound Separation
---

# MMAudioSep: Taming Video-to-Audio Generative Model Towards Video/Text-Queried Sound Separation

**arXiv**: [2510.09065v1](https://arxiv.org/abs/2510.09065) | [PDF](https://arxiv.org/pdf/2510.09065.pdf)

**ä½œè€…**: Akira Takahashi, Shusuke Takahashi, Yuki Mitsufuji

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMMAudioSepä»¥åŸºäºŽé¢„è®­ç»ƒè§†é¢‘-éŸ³é¢‘æ¨¡åž‹å®žçŽ°è§†é¢‘/æ–‡æœ¬æŸ¥è¯¢çš„å£°éŸ³åˆ†ç¦»**

**å…³é”®è¯**: `å£°éŸ³åˆ†ç¦»` `è§†é¢‘åˆ°éŸ³é¢‘ç”Ÿæˆ` `é¢„è®­ç»ƒæ¨¡åž‹å¾®è°ƒ` `å¤šæ¨¡æ€æŸ¥è¯¢` `ç”Ÿæˆæ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†é¢‘æˆ–æ–‡æœ¬æŸ¥è¯¢ä¸‹çš„å£°éŸ³åˆ†ç¦»ä»»åŠ¡ï¼Œéœ€é«˜æ•ˆè®­ç»ƒæ¨¡åž‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨é¢„è®­ç»ƒè§†é¢‘åˆ°éŸ³é¢‘ç”Ÿæˆæ¨¡åž‹çš„çŸ¥è¯†ï¼Œé€šè¿‡å¾®è°ƒè€Œéžä»Žå¤´è®­ç»ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åˆ†ç¦»æ€§èƒ½ä¸Šä¼˜äºŽåŸºçº¿æ¨¡åž‹ï¼Œå¹¶ä¿ç•™åŽŸå§‹è§†é¢‘åˆ°éŸ³é¢‘ç”Ÿæˆèƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce MMAudioSep, a generative model for video/text-queried sound
> separation that is founded on a pretrained video-to-audio model. By leveraging
> knowledge about the relationship between video/text and audio learned through a
> pretrained audio generative model, we can train the model more efficiently,
> i.e., the model does not need to be trained from scratch. We evaluate the
> performance of MMAudioSep by comparing it to existing separation models,
> including models based on both deterministic and generative approaches, and
> find it is superior to the baseline models. Furthermore, we demonstrate that
> even after acquiring functionality for sound separation via fine-tuning, the
> model retains the ability for original video-to-audio generation. This
> highlights the potential of foundational sound generation models to be adopted
> for sound-related downstream tasks. Our code is available at
> https://github.com/sony/mmaudiosep.

