---
layout: default
title: Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels
---

# Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels

**arXiv**: [2510.09035v1](https://arxiv.org/abs/2510.09035) | [PDF](https://arxiv.org/pdf/2510.09035.pdf)

**ä½œè€…**: Weitong Kong, Zichao Zeng, Di Wen, Jiale Wei, Kunyu Peng, June Moh Goo, Jan Boehm, Rainer Stiefelhagen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDuNeåŒè§†å›¾æ¡†æž¶ä»¥è§£å†³LiDARè¯­ä¹‰åˆ†å‰²åœ¨å™ªå£°æ ‡ç­¾ä¸‹çš„å•åŸŸæ³›åŒ–é—®é¢˜**

**å…³é”®è¯**: `LiDARè¯­ä¹‰åˆ†å‰²` `åŸŸæ³›åŒ–` `å™ªå£°æ ‡ç­¾å­¦ä¹ ` `åŒè§†å›¾æ¡†æž¶` `3Dç‚¹äº‘å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šLiDARæ ‡æ³¨å™ªå£°åœ¨åŸŸæ³›åŒ–ä¸­åŠ å‰§ï¼Œå½±å“3Dè¯­ä¹‰åˆ†å‰²çš„é²æ£’æ€§
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å¼ºå¼±åˆ†æ”¯åŒè§†å›¾æ¡†æž¶ï¼Œé€šè¿‡ç‰¹å¾ä¸€è‡´æ€§å’Œç½®ä¿¡åº¦è¿‡æ»¤ä¼˜åŒ–æŸå¤±
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®žçŽ°SOTAæ€§èƒ½ï¼ŒmIoUè¾¾49.57%ç®—æœ¯å¹³å‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Accurate perception is critical for vehicle safety, with LiDAR as a key
> enabler in autonomous driving. To ensure robust performance across
> environments, sensor types, and weather conditions without costly
> re-annotation, domain generalization in LiDAR-based 3D semantic segmentation is
> essential. However, LiDAR annotations are often noisy due to sensor
> imperfections, occlusions, and human errors. Such noise degrades segmentation
> accuracy and is further amplified under domain shifts, threatening system
> reliability. While noisy-label learning is well-studied in images, its
> extension to 3D LiDAR segmentation under domain generalization remains largely
> unexplored, as the sparse and irregular structure of point clouds limits direct
> use of 2D methods. To address this gap, we introduce the novel task Domain
> Generalization for LiDAR Semantic Segmentation under Noisy Labels (DGLSS-NL)
> and establish the first benchmark by adapting three representative noisy-label
> learning strategies from image classification to 3D segmentation. However, we
> find that existing noisy-label learning approaches adapt poorly to LiDAR data.
> We therefore propose DuNe, a dual-view framework with strong and weak branches
> that enforce feature-level consistency and apply cross-entropy loss based on
> confidence-aware filtering of predictions. Our approach shows state-of-the-art
> performance by achieving 56.86% mIoU on SemanticKITTI, 42.28% on nuScenes, and
> 52.58% on SemanticPOSS under 10% symmetric label noise, with an overall
> Arithmetic Mean (AM) of 49.57% and Harmonic Mean (HM) of 48.50%, thereby
> demonstrating robust domain generalization in DGLSS-NL tasks. The code is
> available on our project page.

