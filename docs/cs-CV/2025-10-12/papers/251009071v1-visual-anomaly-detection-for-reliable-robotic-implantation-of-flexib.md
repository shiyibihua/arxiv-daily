---
layout: default
title: Visual Anomaly Detection for Reliable Robotic Implantation of Flexible Microelectrode Array
---

# Visual Anomaly Detection for Reliable Robotic Implantation of Flexible Microelectrode Array

**arXiv**: [2510.09071v1](https://arxiv.org/abs/2510.09071) | [PDF](https://arxiv.org/pdf/2510.09071.pdf)

**ä½œè€…**: Yitong Chen, Xinyao Xu, Ping Zhu, Xinyong Han, Fangbo Qin, Shan Yu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè§†è§‰Transformerçš„å¼‚å¸¸æ£€æµ‹æ¡†æž¶ï¼Œç”¨äºŽæœºå™¨äººæŸ”æ€§å¾®ç”µæžæ¤å…¥è¿‡ç¨‹ç›‘æŽ§**

**å…³é”®è¯**: `è§†è§‰å¼‚å¸¸æ£€æµ‹` `æœºå™¨äººæ¤å…¥` `æŸ”æ€§å¾®ç”µæž` `è§†è§‰Transformer` `ç‰¹å¾é‡‡æ ·` `è„‘çš®å±‚ç›‘æŽ§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæŸ”æ€§å¾®ç”µæžæ¤å…¥è„‘çš®å±‚æ—¶ï¼Œå› ç»“æž„å˜å½¢å’Œç”Ÿç‰©ç»„ç»‡äº¤äº’ï¼Œéœ€å¯é ç›‘æŽ§ä»¥ç¡®ä¿å®‰å…¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨é¢„è®­ç»ƒViTæå–å¯¹é½ROIç‰¹å¾ï¼Œé‡‡ç”¨æ¸è¿›ç²’åº¦é‡‡æ ·å’Œç‰¹å¾é€šé“é€‰æ‹©ä¼˜åŒ–æ£€æµ‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ¤å…¥ç³»ç»Ÿæ”¶é›†çš„å›¾åƒæ•°æ®é›†ä¸ŠéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Flexible microelectrode (FME) implantation into brain cortex is challenging
> due to the deformable fiber-like structure of FME probe and the interaction
> with critical bio-tissue. To ensure reliability and safety, the implantation
> process should be monitored carefully. This paper develops an image-based
> anomaly detection framework based on the microscopic cameras of the robotic FME
> implantation system. The unified framework is utilized at four checkpoints to
> check the micro-needle, FME probe, hooking result, and implantation point,
> respectively. Exploiting the existing object localization results, the aligned
> regions of interest (ROIs) are extracted from raw image and input to a
> pretrained vision transformer (ViT). Considering the task specifications, we
> propose a progressive granularity patch feature sampling method to address the
> sensitivity-tolerance trade-off issue at different locations. Moreover, we
> select a part of feature channels with higher signal-to-noise ratios from the
> raw general ViT features, to provide better descriptors for each specific
> scene. The effectiveness of the proposed methods is validated with the image
> datasets collected from our implantation system.

