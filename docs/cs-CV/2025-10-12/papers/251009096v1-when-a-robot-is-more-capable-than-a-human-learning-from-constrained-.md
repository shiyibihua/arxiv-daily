---
layout: default
title: When a Robot is More Capable than a Human: Learning from Constrained Demonstrators
---

# When a Robot is More Capable than a Human: Learning from Constrained Demonstrators

**arXiv**: [2510.09096v1](https://arxiv.org/abs/2510.09096) | [PDF](https://arxiv.org/pdf/2510.09096.pdf)

**ä½œè€…**: Xinhu Li, Ayush Jain, Zhaojing Yang, Yigit Korkmaz, Erdem BÄ±yÄ±k

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä»Žå—é™ä¸“å®¶æ¼”ç¤ºä¸­å­¦ä¹ æ›´ä¼˜ç­–ç•¥çš„æ–¹æ³•ï¼Œé€šè¿‡çŠ¶æ€å¥–åŠ±æŽ¨æ–­å’ŒæŽ¢ç´¢æå‡æœºå™¨äººæ€§èƒ½ã€‚**

**å…³é”®è¯**: `æ¨¡ä»¿å­¦ä¹ ` `æœºå™¨äººå­¦ä¹ ` `å¥–åŠ±æŽ¨æ–­` `çŠ¶æ€å¥–åŠ±` `è½¨è¿¹ä¼˜åŒ–` `å—é™æ¼”ç¤º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¸“å®¶æ¼”ç¤ºå› æŽ§åˆ¶å—é™å¯¼è‡´ç­–ç•¥æ¬¡ä¼˜ï¼Œæœºå™¨äººèƒ½å¦å­¦ä¹ ä¼˜äºŽæ¼”ç¤ºçš„ç­–ç•¥ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæŽ¨æ–­çŠ¶æ€å¥–åŠ±ä¿¡å·ï¼Œé€šè¿‡æ—¶é—´æ’å€¼è‡ªæ ‡æ³¨å¥–åŠ±ï¼ŒæŽ¢ç´¢æ›´é«˜æ•ˆè½¨è¿¹ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨çœŸå®žæœºå™¨äººä¸Šä»»åŠ¡å®Œæˆæ—¶é—´æ¯”è¡Œä¸ºå…‹éš†å¿«10å€ï¼Œæ ·æœ¬æ•ˆçŽ‡æ›´é«˜ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Learning from demonstrations enables experts to teach robots complex tasks
> using interfaces such as kinesthetic teaching, joystick control, and
> sim-to-real transfer. However, these interfaces often constrain the expert's
> ability to demonstrate optimal behavior due to indirect control, setup
> restrictions, and hardware safety. For example, a joystick can move a robotic
> arm only in a 2D plane, even though the robot operates in a higher-dimensional
> space. As a result, the demonstrations collected by constrained experts lead to
> suboptimal performance of the learned policies. This raises a key question: Can
> a robot learn a better policy than the one demonstrated by a constrained
> expert? We address this by allowing the agent to go beyond direct imitation of
> expert actions and explore shorter and more efficient trajectories. We use the
> demonstrations to infer a state-only reward signal that measures task progress,
> and self-label reward for unknown states using temporal interpolation. Our
> approach outperforms common imitation learning in both sample efficiency and
> task completion time. On a real WidowX robotic arm, it completes the task in 12
> seconds, 10x faster than behavioral cloning, as shown in real-robot videos on
> https://sites.google.com/view/constrainedexpert .

