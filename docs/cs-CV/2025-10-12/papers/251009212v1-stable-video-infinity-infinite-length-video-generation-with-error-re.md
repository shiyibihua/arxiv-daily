---
layout: default
title: Stable Video Infinity: Infinite-Length Video Generation with Error Recycling
---

# Stable Video Infinity: Infinite-Length Video Generation with Error Recycling

**arXiv**: [2510.09212v1](https://arxiv.org/abs/2510.09212) | [PDF](https://arxiv.org/pdf/2510.09212.pdf)

**ä½œè€…**: Wuyang Li, Wentao Pan, Po-Chien Luan, Yang Gao, Alexandre Alahi

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºStable Video Infinityï¼Œé€šè¿‡é”™è¯¯å›æ”¶å¾®è°ƒå®ç°æ— é™é•¿åº¦è§†é¢‘ç”Ÿæˆ**

**å…³é”®è¯**: `æ— é™è§†é¢‘ç”Ÿæˆ` `é”™è¯¯å›æ”¶å¾®è°ƒ` `æ‰©æ•£å˜æ¢å™¨` `è‡ªå›å½’å­¦ä¹ ` `æµåŒ¹é…` `æ¡ä»¶ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè®­ç»ƒå‡è®¾ä¸è‡ªå›å½’ç”Ÿæˆé—´çš„è¯¯å·®ç´¯ç§¯å’Œå‡è®¾å·®è·ï¼Œå¯¼è‡´åœºæ™¯é‡å¤å’Œè¿åŠ¨å•è°ƒã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨é”™è¯¯å›æ”¶å¾®è°ƒï¼Œå°†è‡ªç”Ÿæˆé”™è¯¯ä½œä¸ºç›‘ç£æç¤ºï¼Œä¿ƒè¿›æ¨¡å‹ä¸»åŠ¨è¯†åˆ«å’Œçº æ­£é”™è¯¯ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šåœ¨ä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸­éªŒè¯å…¶å¤šåŠŸèƒ½æ€§å’Œå…ˆè¿›æ€§èƒ½ï¼Œæ”¯æŒä»ç§’çº§åˆ°æ— é™æ—¶é•¿è§†é¢‘ç”Ÿæˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We propose Stable Video Infinity (SVI) that is able to generate
> infinite-length videos with high temporal consistency, plausible scene
> transitions, and controllable streaming storylines. While existing long-video
> methods attempt to mitigate accumulated errors via handcrafted anti-drifting
> (e.g., modified noise scheduler, frame anchoring), they remain limited to
> single-prompt extrapolation, producing homogeneous scenes with repetitive
> motions. We identify that the fundamental challenge extends beyond error
> accumulation to a critical discrepancy between the training assumption (seeing
> clean data) and the test-time autoregressive reality (conditioning on
> self-generated, error-prone outputs). To bridge this hypothesis gap, SVI
> incorporates Error-Recycling Fine-Tuning, a new type of efficient training that
> recycles the Diffusion Transformer (DiT)'s self-generated errors into
> supervisory prompts, thereby encouraging DiT to actively identify and correct
> its own errors. This is achieved by injecting, collecting, and banking errors
> through closed-loop recycling, autoregressively learning from error-injected
> feedback. Specifically, we (i) inject historical errors made by DiT to
> intervene on clean inputs, simulating error-accumulated trajectories in flow
> matching; (ii) efficiently approximate predictions with one-step bidirectional
> integration and calculate errors with residuals; (iii) dynamically bank errors
> into replay memory across discretized timesteps, which are resampled for new
> input. SVI is able to scale videos from seconds to infinite durations with no
> additional inference cost, while remaining compatible with diverse conditions
> (e.g., audio, skeleton, and text streams). We evaluate SVI on three benchmarks,
> including consistent, creative, and conditional settings, thoroughly verifying
> its versatility and state-of-the-art role.

