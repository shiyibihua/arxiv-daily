---
layout: default
title: D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models
---

# D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models

**arXiv**: [2510.09473v1](https://arxiv.org/abs/2510.09473) | [PDF](https://arxiv.org/pdf/2510.09473.pdf)

**ä½œè€…**: Jisu Han, Wonjun Hwang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»´åº¦ç†µæœ€å¤§åŒ–æ–¹æ³•ä»¥æ”¹å–„è§†è§‰è¯­è¨€æ¨¡åž‹æµ‹è¯•æ—¶æç¤ºè°ƒä¼˜çš„æ ¡å‡†æ€§èƒ½**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡åž‹` `æµ‹è¯•æ—¶é€‚åº”` `æç¤ºè°ƒä¼˜` `ç»´åº¦ç†µæœ€å¤§åŒ–` `æ ¡å‡†è¯¯å·®` `æ¨¡æ€é—´éš™`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ¨¡æ€é—´éš™ç”±å•ä¸€ä¸»å¯¼ç‰¹å¾ç»´åº¦å¼•èµ·ï¼Œå¯¼è‡´æ ¡å‡†è¯¯å·®å¢žåŠ 
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æœ€å¤§åŒ–ç»´åº¦ç†µæ­£åˆ™åŒ–æ–‡æœ¬ç‰¹å¾åˆ†å¸ƒï¼Œå‡å°‘ä¸»å¯¼ç»´åº¦ä¾èµ–
3. å®žéªŒæˆ–æ•ˆæžœï¼šç¼“è§£æµ‹è¯•æ—¶æç¤ºè°ƒä¼˜ä¸­æ ¡å‡†æ€§èƒ½é€€åŒ–ï¼Œæå‡æ¨¡åž‹å¯é æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Test-time adaptation paradigm provides flexibility towards domain shifts by
> performing immediate adaptation on unlabeled target data from the source model.
> Vision-Language Models (VLMs) leverage their generalization capabilities for
> diverse downstream tasks, and test-time prompt tuning has emerged as a
> prominent solution for adapting VLMs. In this work, we explore contrastive VLMs
> and identify the modality gap caused by a single dominant feature dimension
> across modalities. We observe that the dominant dimensions in both text and
> image modalities exhibit high predictive sensitivity, and that constraining
> their influence can improve calibration error. Building on this insight, we
> propose dimensional entropy maximization that regularizes the distribution of
> textual features toward uniformity to mitigate the dependency of dominant
> dimensions. Our method alleviates the degradation of calibration performance in
> test-time prompt tuning, offering a simple yet effective solution to enhance
> the reliability of VLMs in real-world deployment scenarios.

