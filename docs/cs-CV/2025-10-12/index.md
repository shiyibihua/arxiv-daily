---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-10-12
---

# cs.CVï¼ˆ2025-10-12ï¼‰

ğŸ“Š å…± **25** ç¯‡è®ºæ–‡
 | ğŸ”— **4** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (9 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (8 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (4 ğŸ”—1)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (2)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251010671v1-image-to-video-transfer-learning-based-on-image-language-foundation-.html">Image-to-Video Transfer Learning based on Image-Language Foundation Models: A Comprehensive Survey</a></td>
  <td>é¦–ä¸ªåŸºäºå›¾åƒ-è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹çš„å›¾åƒåˆ°è§†é¢‘è¿ç§»å­¦ä¹ çš„ç»¼è¿°</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10671v1" onclick="toggleFavorite(this, '2510.10671v1', 'Image-to-Video Transfer Learning based on Image-Language Foundation Models: A Comprehensive Survey')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251010464v1-post-tips-prediction-via-multimodal-interaction-a-multi-center-datas.html">Post-TIPS Prediction via Multimodal Interaction: A Multi-Center Dataset and Framework for Survival, Complication, and Portal Pressure Assessment</a></td>
  <td>æå‡ºMultiTIPSæ•°æ®é›†å’Œå¤šæ¨¡æ€äº¤äº’æ¡†æ¶ï¼Œç”¨äºTIPSæœ¯åç”Ÿå­˜ã€å¹¶å‘ç—‡å’Œé—¨é™è„‰å‹åŠ›è¯„ä¼°ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10464v1" onclick="toggleFavorite(this, '2510.10464v1', 'Post-TIPS Prediction via Multimodal Interaction: A Multi-Center Dataset and Framework for Survival, Complication, and Portal Pressure Assessment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251010587v1-a-simple-and-better-baseline-for-visual-grounding.html">A Simple and Better Baseline for Visual Grounding</a></td>
  <td>æå‡ºåŸºäºç‰¹å¾é€‰æ‹©çš„è§†è§‰å®šä½åŸºçº¿FSVGï¼Œæå‡ç²¾åº¦ä¸æ•ˆç‡</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10587v1" onclick="toggleFavorite(this, '2510.10587v1', 'A Simple and Better Baseline for Visual Grounding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251010584v1-equipping-vision-foundation-model-with-mixture-of-experts-for-out-of.html">Equipping Vision Foundation Model with Mixture of Experts for Out-of-Distribution Detection</a></td>
  <td>æå‡ºMoFEæ¨¡å—å’ŒåŠ¨æ€Mixupç­–ç•¥ï¼Œæå‡è§†è§‰åŸºç¡€æ¨¡å‹åœ¨OODæ£€æµ‹ä¸­çš„æ€§èƒ½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10584v1" onclick="toggleFavorite(this, '2510.10584v1', 'Equipping Vision Foundation Model with Mixture of Experts for Out-of-Distribution Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251010546v1-glofnet-a-multimodal-dataset-for-glof-monitoring-and-prediction.html">GLOFNet -- A Multimodal Dataset for GLOF Monitoring and Prediction</a></td>
  <td>GLOFNetï¼šç”¨äºå†°æ¹–æºƒå†³æ´ªæ°´ç›‘æµ‹ä¸é¢„æµ‹çš„å¤šæ¨¡æ€æ•°æ®é›†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10546v1" onclick="toggleFavorite(this, '2510.10546v1', 'GLOFNet -- A Multimodal Dataset for GLOF Monitoring and Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251010518v3-vr-thinker-boosting-video-reward-models-through-thinking-with-image-.html">VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning</a></td>
  <td>VR-Thinkerï¼šé€šè¿‡å›¾åƒæ¨ç†å¢å¼ºè§†é¢‘å¥–åŠ±æ¨¡å‹ï¼Œæå‡é•¿è§†é¢‘åå¥½åˆ¤æ–­ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10518v3" onclick="toggleFavorite(this, '2510.10518v3', 'VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251010487v1-towards-self-refinement-of-vision-language-models-with-triangular-co.html">Towards Self-Refinement of Vision-Language Models with Triangular Consistency</a></td>
  <td>æå‡ºåŸºäºä¸‰è§’ä¸€è‡´æ€§çš„è‡ªç²¾ç‚¼æ¡†æ¶ï¼Œæå‡è§†è§‰-è¯­è¨€æ¨¡å‹æ€§èƒ½ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10487v1" onclick="toggleFavorite(this, '2510.10487v1', 'Towards Self-Refinement of Vision-Language Models with Triangular Consistency')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251010466v1-when-images-speak-louder-mitigating-language-bias-induced-hallucinat.html">When Images Speak Louder: Mitigating Language Bias-induced Hallucinations in VLMs through Cross-Modal Guidance</a></td>
  <td>æå‡ºè·¨æ¨¡æ€å¼•å¯¼ï¼ˆCMGï¼‰æ–¹æ³•ï¼Œç¼“è§£è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„è¯­è¨€åè§å¯¼è‡´çš„å¹»è§‰é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10466v1" onclick="toggleFavorite(this, '2510.10466v1', 'When Images Speak Louder: Mitigating Language Bias-induced Hallucinations in VLMs through Cross-Modal Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251010422v1-towards-cybersickness-severity-classification-from-vr-gameplay-video.html">Towards Cybersickness Severity Classification from VR Gameplay Videos Using Transfer Learning and Temporal Modeling</a></td>
  <td>æå‡ºåŸºäºè¿ç§»å­¦ä¹ å’Œæ—¶åºå»ºæ¨¡çš„VRæ¸¸æˆè§†é¢‘æ™•åŠ¨ç—‡ä¸¥é‡ç¨‹åº¦åˆ†ç±»æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10422v1" onclick="toggleFavorite(this, '2510.10422v1', 'Towards Cybersickness Severity Classification from VR Gameplay Videos Using Transfer Learning and Temporal Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (8 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>10</td>
  <td><a href="./papers/251010650v1-demo-disentangled-motion-latent-flow-matching-for-fine-grained-contr.html">DEMO: Disentangled Motion Latent Flow Matching for Fine-Grained Controllable Talking Portrait Synthesis</a></td>
  <td>DEMOï¼šè§£è€¦è¿åŠ¨æ½œåœ¨æµåŒ¹é…ï¼Œå®ç°ç»†ç²’åº¦å¯æ§çš„è¯´è¯äººåƒåˆæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10650v1" onclick="toggleFavorite(this, '2510.10650v1', 'DEMO: Disentangled Motion Latent Flow Matching for Fine-Grained Controllable Talking Portrait Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251010765v1-egd-yolo-a-lightweight-multimodal-framework-for-robust-drone-bird-di.html">EGD-YOLO: A Lightweight Multimodal Framework for Robust Drone-Bird Discrimination via Ghost-Enhanced YOLOv8n and EMA Attention under Adverse Condition</a></td>
  <td>EGD-YOLOï¼šè½»é‡çº§å¤šæ¨¡æ€æ¡†æ¶ï¼Œé€šè¿‡Ghostå¢å¼ºYOLOv8nå’ŒEMAæ³¨æ„åŠ›å®ç°æ¶åŠ£æ¡ä»¶ä¸‹æ— äººæœº-é¸Ÿç±»ç¨³å¥åŒºåˆ†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10765v1" onclick="toggleFavorite(this, '2510.10765v1', 'EGD-YOLO: A Lightweight Multimodal Framework for Robust Drone-Bird Discrimination via Ghost-Enhanced YOLOv8n and EMA Attention under Adverse Condition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251010663v1-scalable-face-security-vision-foundation-model-for-deepfake-diffusio.html">Scalable Face Security Vision Foundation Model for Deepfake, Diffusion, and Spoofing Detection</a></td>
  <td>æå‡ºFS-VFMï¼Œé€šè¿‡è‡ªç›‘ç£å­¦ä¹ æå‡äººè„¸å®‰å…¨ä»»åŠ¡çš„æ³›åŒ–èƒ½åŠ›</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10663v1" onclick="toggleFavorite(this, '2510.10663v1', 'Scalable Face Security Vision Foundation Model for Deepfake, Diffusion, and Spoofing Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251010478v2-msf-mamba-motion-aware-state-fusion-mamba-for-efficient-micro-gestur.html">MSF-Mamba: Motion-aware State Fusion Mamba for Efficient Micro-Gesture Recognition</a></td>
  <td>æå‡ºMSF-Mambaï¼Œé€šè¿‡è¿åŠ¨æ„ŸçŸ¥çŠ¶æ€èåˆæå‡Mambaåœ¨å¾®æ‰‹åŠ¿è¯†åˆ«ä¸­çš„æ•ˆç‡ä¸ç²¾åº¦ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10478v2" onclick="toggleFavorite(this, '2510.10478v2', 'MSF-Mamba: Motion-aware State Fusion Mamba for Efficient Micro-Gesture Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251010524v1-unified-open-world-segmentation-with-multi-modal-prompts.html">Unified Open-World Segmentation with Multi-Modal Prompts</a></td>
  <td>COSINEï¼šå¤šæ¨¡æ€æç¤ºä¸‹çš„ç»Ÿä¸€å¼€æ”¾ä¸–ç•Œåˆ†å‰²æ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10524v1" onclick="toggleFavorite(this, '2510.10524v1', 'Unified Open-World Segmentation with Multi-Modal Prompts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251010779v2-structured-spectral-graph-representation-learning-for-multi-label-ab.html">Structured Spectral Graph Representation Learning for Multi-label Abnormality Analysis from 3D CT Scans</a></td>
  <td>æå‡ºåŸºäºç»“æ„åŒ–è°±å›¾è¡¨ç¤ºå­¦ä¹ çš„3D CTå¤šæ ‡ç­¾å¼‚å¸¸åˆ†ææ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10779v2" onclick="toggleFavorite(this, '2510.10779v2', 'Structured Spectral Graph Representation Learning for Multi-label Abnormality Analysis from 3D CT Scans')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251010609v1-omniquality-r-advancing-reward-models-through-all-encompassing-quali.html">OmniQuality-R: Advancing Reward Models Through All-Encompassing Quality Assessment</a></td>
  <td>OmniQuality-Rï¼šé€šè¿‡å…¨æ–¹ä½è´¨é‡è¯„ä¼°æå‡å¥–åŠ±æ¨¡å‹æ€§èƒ½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10609v1" onclick="toggleFavorite(this, '2510.10609v1', 'OmniQuality-R: Advancing Reward Models Through All-Encompassing Quality Assessment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251010406v1-mesh-gait-a-unified-framework-for-gait-recognition-through-multi-mod.html">Mesh-Gait: A Unified Framework for Gait Recognition Through Multi-Modal Representation Learning from 2D Silhouettes</a></td>
  <td>Mesh-Gaitï¼šæå‡ºä¸€ç§åŸºäº2Dè½®å»“å¤šæ¨¡æ€è¡¨å¾å­¦ä¹ çš„ç»Ÿä¸€æ­¥æ€è¯†åˆ«æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10406v1" onclick="toggleFavorite(this, '2510.10406v1', 'Mesh-Gait: A Unified Framework for Gait Recognition Through Multi-Modal Representation Learning from 2D Silhouettes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>18</td>
  <td><a href="./papers/251010691v3-dynamic-gaussian-splatting-from-defocused-and-motion-blurred-monocul.html">Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos</a></td>
  <td>æå‡ºåŠ¨æ€é«˜æ–¯æº…å°„æ¡†æ¶ï¼Œè§£å†³æ•£ç„¦å’Œè¿åŠ¨æ¨¡ç³Šè§†é¢‘çš„æ–°è§†è§’åˆæˆé—®é¢˜</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10691v3" onclick="toggleFavorite(this, '2510.10691v3', 'Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251010426v1-taming-a-retrieval-framework-to-read-images-in-humanlike-manner-for-.html">Taming a Retrieval Framework to Read Images in Humanlike Manner for Augmenting Generation of MLLMs</a></td>
  <td>æå‡ºHuLiRAGæ¡†æ¶ï¼Œé€šè¿‡æ¨¡æ‹Ÿäººç±»è§†è§‰å¤„ç†æ–¹å¼å¢å¼ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10426v1" onclick="toggleFavorite(this, '2510.10426v1', 'Taming a Retrieval Framework to Read Images in Humanlike Manner for Augmenting Generation of MLLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251010577v1-injecting-frame-event-complementary-fusion-into-diffusion-for-optica.html">Injecting Frame-Event Complementary Fusion into Diffusion for Optical Flow in Challenging Scenes</a></td>
  <td>æå‡ºDiff-ABFlowï¼Œèåˆå¸§-äº‹ä»¶äº’è¡¥ä¿¡æ¯ï¼Œè§£å†³æ¶åŠ£åœºæ™¯å…‰æµä¼°è®¡éš¾é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10577v1" onclick="toggleFavorite(this, '2510.10577v1', 'Injecting Frame-Event Complementary Fusion into Diffusion for Optical Flow in Challenging Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/251010492v1-towards-efficient-3d-gaussian-human-avatar-compression-a-prior-guide.html">Towards Efficient 3D Gaussian Human Avatar Compression: A Prior-Guided Framework</a></td>
  <td>æå‡ºä¸€ç§å…ˆéªŒå¼•å¯¼çš„3Dé«˜æ–¯äººä½“Avataré«˜æ•ˆå‹ç¼©æ¡†æ¶ï¼Œç”¨äºè¶…ä½ç ç‡é«˜è´¨é‡çš„å…ƒå®‡å®™åº”ç”¨ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10492v1" onclick="toggleFavorite(this, '2510.10492v1', 'Towards Efficient 3D Gaussian Human Avatar Compression: A Prior-Guided Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>22</td>
  <td><a href="./papers/251010414v1-guided-image-feature-matching-using-feature-spatial-order.html">Guided Image Feature Matching using Feature Spatial Order</a></td>
  <td>æå‡ºä¸€ç§åˆ©ç”¨ç‰¹å¾ç©ºé—´é¡ºåºå¼•å¯¼çš„å›¾åƒç‰¹å¾åŒ¹é…æ–¹æ³•ï¼Œæå‡åŒ¹é…æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10414v1" onclick="toggleFavorite(this, '2510.10414v1', 'Guided Image Feature Matching using Feature Spatial Order')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/251010417v1-combo-gait-unified-transformer-framework-for-multi-modal-gait-recogn.html">Combo-Gait: Unified Transformer Framework for Multi-Modal Gait Recognition and Attribute Analysis</a></td>
  <td>æå‡ºCombo-Gaitï¼Œç”¨äºå¤šæ¨¡æ€æ­¥æ€è¯†åˆ«å’Œå±æ€§åˆ†æçš„ç»Ÿä¸€Transformeræ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10417v1" onclick="toggleFavorite(this, '2510.10417v1', 'Combo-Gait: Unified Transformer Framework for Multi-Modal Gait Recognition and Attribute Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>24</td>
  <td><a href="./papers/251010793v1-imhead-a-large-scale-implicit-morphable-model-for-localized-head-mod.html">ImHead: A Large-scale Implicit Morphable Model for Localized Head Modeling</a></td>
  <td>æå‡ºimHeadï¼šä¸€ç§ç”¨äºå±€éƒ¨å¤´éƒ¨å»ºæ¨¡çš„å¤§è§„æ¨¡éšå¼å¯å˜å½¢æ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10793v1" onclick="toggleFavorite(this, '2510.10793v1', 'ImHead: A Large-scale Implicit Morphable Model for Localized Head Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>25</td>
  <td><a href="./papers/251010612v1-ultrascatter-ray-based-simulation-of-ultrasound-scattering.html">UltraScatter: Ray-Based Simulation of Ultrasound Scattering</a></td>
  <td>UltraScatterï¼šæå‡ºåŸºäºå°„çº¿è¿½è¸ªçš„è¶…å£°æ•£å°„å¿«é€Ÿæ¨¡æ‹Ÿæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.10612v1" onclick="toggleFavorite(this, '2510.10612v1', 'UltraScatter: Ray-Based Simulation of Ultrasound Scattering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)