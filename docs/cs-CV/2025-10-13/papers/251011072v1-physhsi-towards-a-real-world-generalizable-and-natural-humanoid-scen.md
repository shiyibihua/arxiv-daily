---
layout: default
title: PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System
---

# PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System

**arXiv**: [2510.11072v1](https://arxiv.org/abs/2510.11072) | [PDF](https://arxiv.org/pdf/2510.11072.pdf)

**ä½œè€…**: Huayi Wang, Wentao Zhang, Runyi Yu, Tao Huang, Junli Ren, Feiyu Jia, Zirui Wang, Xiaojie Niu, Xiao Chen, Jiahe Chen, Qifeng Chen, Jingbo Wang, Jiangmiao Pang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPhysHSIç³»ç»Ÿï¼Œå®žçŽ°äººå½¢æœºå™¨äººåœ¨çœŸå®žä¸–ç•Œä¸­é€šç”¨ä¸”è‡ªç„¶çš„åœºæ™¯äº¤äº’ã€‚**

**å…³é”®è¯**: `äººå½¢æœºå™¨äººäº¤äº’` `å¯¹æŠ—è¿åŠ¨å…ˆéªŒ` `åœºæ™¯æ„ŸçŸ¥` `æ¨¡æ‹Ÿåˆ°çœŸå®žéƒ¨ç½²` `å¤šæ¨¡æ€å®šä½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šäººå½¢æœºå™¨äººéœ€åœ¨çœŸå®žçŽ¯å¢ƒä¸­æ‰§è¡Œäº¤äº’ä»»åŠ¡ï¼Œä½†çŽ°æœ‰æ–¹æ³•éš¾ä»¥ç»Ÿä¸€æ³›åŒ–è¿åŠ¨å’Œé²æ£’æ„ŸçŸ¥ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ¨¡æ‹Ÿå¯¹æŠ—è¿åŠ¨å…ˆéªŒå­¦ä¹ ï¼Œç»“åˆLiDARä¸Žç›¸æœºç²—åˆ°ç²¾å®šä½ï¼Œæå‡äº¤äº’è‡ªç„¶æ€§å’Œé²æ£’æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žä¸–ç•ŒéªŒè¯å››ç§äº¤äº’ä»»åŠ¡ï¼ŒæˆåŠŸçŽ‡é«˜ã€æ³›åŒ–å¼ºã€è¿åŠ¨è‡ªç„¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deploying humanoid robots to interact with real-world environments--such as
> carrying objects or sitting on chairs--requires generalizable, lifelike motions
> and robust scene perception. Although prior approaches have advanced each
> capability individually, combining them in a unified system is still an ongoing
> challenge. In this work, we present a physical-world humanoid-scene interaction
> system, PhysHSI, that enables humanoids to autonomously perform diverse
> interaction tasks while maintaining natural and lifelike behaviors. PhysHSI
> comprises a simulation training pipeline and a real-world deployment system. In
> simulation, we adopt adversarial motion prior-based policy learning to imitate
> natural humanoid-scene interaction data across diverse scenarios, achieving
> both generalization and lifelike behaviors. For real-world deployment, we
> introduce a coarse-to-fine object localization module that combines LiDAR and
> camera inputs to provide continuous and robust scene perception. We validate
> PhysHSI on four representative interactive tasks--box carrying, sitting, lying,
> and standing up--in both simulation and real-world settings, demonstrating
> consistently high success rates, strong generalization across diverse task
> goals, and natural motion patterns.

