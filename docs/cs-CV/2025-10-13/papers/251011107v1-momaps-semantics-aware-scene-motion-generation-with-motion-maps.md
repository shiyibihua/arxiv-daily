---
layout: default
title: MoMaps: Semantics-Aware Scene Motion Generation with Motion Maps
---

# MoMaps: Semantics-Aware Scene Motion Generation with Motion Maps

**arXiv**: [2510.11107v1](https://arxiv.org/abs/2510.11107) | [PDF](https://arxiv.org/pdf/2510.11107.pdf)

**ä½œè€…**: Jiahui Lei, Kyle Genova, George Kopanas, Noah Snavely, Leonidas Guibas

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMoMapsè¡¨ç¤ºä»¥ä»Žå•å¼ å›¾åƒé¢„æµ‹è¯­ä¹‰ä¸€è‡´çš„3Dåœºæ™¯è¿åŠ¨**

**å…³é”®è¯**: `3Dåœºæ™¯è¿åŠ¨ç”Ÿæˆ` `è¿åŠ¨åœ°å›¾è¡¨ç¤º` `æ‰©æ•£æ¨¡åž‹` `è§†é¢‘åˆæˆ` `è¯­ä¹‰è¿åŠ¨å…ˆéªŒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä»ŽçœŸå®žè§†é¢‘å­¦ä¹ è¯­ä¹‰å’ŒåŠŸèƒ½æœ‰æ„ä¹‰çš„3Dè¿åŠ¨å…ˆéªŒï¼Œç”¨äºŽå•å›¾åƒé¢„æµ‹æœªæ¥è¿åŠ¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥åƒç´ å¯¹é½çš„MoMapè¡¨ç¤ºï¼ŒåŸºäºŽæ‰©æ•£æ¨¡åž‹ä»Žå¤§è§„æ¨¡è§†é¢‘æ•°æ®åº“ç”Ÿæˆ3Dè¿åŠ¨ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç”Ÿæˆåˆç†ä¸”è¯­ä¹‰ä¸€è‡´çš„3Dåœºæ™¯è¿åŠ¨ï¼Œå¹¶æ”¯æŒ2Dè§†é¢‘åˆæˆæ–°æµç¨‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper addresses the challenge of learning semantically and functionally
> meaningful 3D motion priors from real-world videos, in order to enable
> prediction of future 3D scene motion from a single input image. We propose a
> novel pixel-aligned Motion Map (MoMap) representation for 3D scene motion,
> which can be generated from existing generative image models to facilitate
> efficient and effective motion prediction. To learn meaningful distributions
> over motion, we create a large-scale database of MoMaps from over 50,000 real
> videos and train a diffusion model on these representations. Our motion
> generation not only synthesizes trajectories in 3D but also suggests a new
> pipeline for 2D video synthesis: first generate a MoMap, then warp an image
> accordingly and complete the warped point-based renderings. Experimental
> results demonstrate that our approach generates plausible and semantically
> consistent 3D scene motion.

