---
layout: default
title: DiT360: High-Fidelity Panoramic Image Generation via Hybrid Training
---

# DiT360: High-Fidelity Panoramic Image Generation via Hybrid Training

**arXiv**: [2510.11712v1](https://arxiv.org/abs/2510.11712) | [PDF](https://arxiv.org/pdf/2510.11712.pdf)

**ä½œè€…**: Haoran Feng, Dizhe Zhang, Xiangtai Li, Bo Du, Lu Qi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDiT360æ¡†æž¶ï¼Œé€šè¿‡æ··åˆè®­ç»ƒè§£å†³å…¨æ™¯å›¾åƒç”Ÿæˆä¸­çš„å‡ ä½•ä¿çœŸåº¦å’ŒçœŸå®žæ„Ÿé—®é¢˜ã€‚**

**å…³é”®è¯**: `å…¨æ™¯å›¾åƒç”Ÿæˆ` `æ··åˆè®­ç»ƒ` `æ‰©æ•£å˜æ¢å™¨` `å‡ ä½•ä¿çœŸåº¦` `è¾¹ç•Œè¿žç»­æ€§` `å›¾åƒä¿®å¤`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç¼ºä¹å¤§è§„æ¨¡é«˜è´¨é‡çœŸå®žå…¨æ™¯æ•°æ®ï¼Œå½±å“ç”Ÿæˆå›¾åƒçš„å‡ ä½•ä¿çœŸåº¦å’ŒçœŸå®žæ„Ÿã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåœ¨å›¾åƒå’Œtokençº§åˆ«åº”ç”¨è·¨åŸŸå˜æ¢å’ŒåŸŸå†…å¢žå¼ºï¼ŒåŒ…æ‹¬è§†è§’å›¾åƒå¼•å¯¼å’Œå…¨æ™¯ä¼˜åŒ–ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨æ–‡æœ¬åˆ°å…¨æ™¯ã€ä¿®å¤å’Œæ‰©å±•ä»»åŠ¡ä¸­ï¼Œè¾¹ç•Œä¸€è‡´æ€§å’Œå›¾åƒä¿çœŸåº¦ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this work, we propose DiT360, a DiT-based framework that performs hybrid
> training on perspective and panoramic data for panoramic image generation. For
> the issues of maintaining geometric fidelity and photorealism in generation
> quality, we attribute the main reason to the lack of large-scale, high-quality,
> real-world panoramic data, where such a data-centric view differs from prior
> methods that focus on model design. Basically, DiT360 has several key modules
> for inter-domain transformation and intra-domain augmentation, applied at both
> the pre-VAE image level and the post-VAE token level. At the image level, we
> incorporate cross-domain knowledge through perspective image guidance and
> panoramic refinement, which enhance perceptual quality while regularizing
> diversity and photorealism. At the token level, hybrid supervision is applied
> across multiple modules, which include circular padding for boundary
> continuity, yaw loss for rotational robustness, and cube loss for distortion
> awareness. Extensive experiments on text-to-panorama, inpainting, and
> outpainting tasks demonstrate that our method achieves better boundary
> consistency and image fidelity across eleven quantitative metrics. Our code is
> available at https://github.com/Insta360-Research-Team/DiT360.

