---
layout: default
title: Point Prompting: Counterfactual Tracking with Video Diffusion Models
---

# Point Prompting: Counterfactual Tracking with Video Diffusion Models

**arXiv**: [2510.11715v1](https://arxiv.org/abs/2510.11715) | [PDF](https://arxiv.org/pdf/2510.11715.pdf)

**ä½œè€…**: Ayush Shrivastava, Sanyam Mehta, Daniel Geng, Andrew Owens

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç‚¹æç¤ºæ–¹æ³•ï¼Œåˆ©ç”¨è§†é¢‘æ‰©æ•£æ¨¡åž‹å®žçŽ°é›¶æ ·æœ¬ç‚¹è·Ÿè¸ªã€‚**

**å…³é”®è¯**: `ç‚¹è·Ÿè¸ª` `è§†é¢‘æ‰©æ•£æ¨¡åž‹` `é›¶æ ·æœ¬å­¦ä¹ ` `åäº‹å®žç”Ÿæˆ` `è¿åŠ¨åˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•åˆ©ç”¨è§†é¢‘ç”Ÿæˆæ¨¡åž‹è¿›è¡Œé›¶æ ·æœ¬ç‚¹è·Ÿè¸ªï¼Œåˆ†æžç‰©ä½“è¿åŠ¨è½¨è¿¹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æ·»åŠ å½©è‰²æ ‡è®°ç‚¹å¹¶åäº‹å®žç”Ÿæˆè§†é¢‘ï¼Œä¼ æ’­æ ‡è®°ä»¥è¿½è¸ªè½¨è¿¹ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨å¤šä¸ªæ¨¡åž‹ä¸Šæµ‹è¯•ï¼Œæ€§èƒ½ä¼˜äºŽçŽ°æœ‰é›¶æ ·æœ¬æ–¹æ³•ï¼Œå¯¹é®æŒ¡é²æ£’ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Trackers and video generators solve closely related problems: the former
> analyze motion, while the latter synthesize it. We show that this connection
> enables pretrained video diffusion models to perform zero-shot point tracking
> by simply prompting them to visually mark points as they move over time. We
> place a distinctively colored marker at the query point, then regenerate the
> rest of the video from an intermediate noise level. This propagates the marker
> across frames, tracing the point's trajectory. To ensure that the marker
> remains visible in this counterfactual generation, despite such markers being
> unlikely in natural videos, we use the unedited initial frame as a negative
> prompt. Through experiments with multiple image-conditioned video diffusion
> models, we find that these "emergent" tracks outperform those of prior
> zero-shot methods and persist through occlusions, often obtaining performance
> that is competitive with specialized self-supervised models.

