---
layout: default
title: HiMaCon: Discovering Hierarchical Manipulation Concepts from Unlabeled Multi-Modal Data
---

# HiMaCon: Discovering Hierarchical Manipulation Concepts from Unlabeled Multi-Modal Data

**arXiv**: [2510.11321v1](https://arxiv.org/abs/2510.11321) | [PDF](https://arxiv.org/pdf/2510.11321.pdf)

**ä½œè€…**: Ruizhe Liu, Pei Zhou, Qian Luo, Li Sun, Jun Cen, Yibing Song, Yanchao Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªç›‘ç£æ¡†æž¶HiMaConï¼Œä»Žæ— æ ‡ç­¾å¤šæ¨¡æ€æ•°æ®å­¦ä¹ å±‚æ¬¡åŒ–æ“ä½œæ¦‚å¿µä»¥æå‡æœºå™¨äººæ³›åŒ–èƒ½åŠ›**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `è‡ªç›‘ç£å­¦ä¹ ` `å±‚æ¬¡åŒ–è¡¨ç¤º` `å¤šæ¨¡æ€æ•°æ®` `æ—¶åºæŠ½è±¡` `æ³›åŒ–èƒ½åŠ›`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨äººæ“ä½œéœ€æ•æ‰è·¨çŽ¯å¢ƒå’Œä»»åŠ¡çš„ä¸å˜äº¤äº’æ¨¡å¼ä»¥å®žçŽ°æœ‰æ•ˆæ³›åŒ–
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆè·¨æ¨¡æ€ç›¸å…³ç½‘ç»œå’Œå¤šå°ºåº¦æ—¶åºé¢„æµ‹å™¨ï¼Œæ— ç›‘ç£å­¦ä¹ å±‚æ¬¡åŒ–æ“ä½œæ¦‚å¿µ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä»¿çœŸå’ŒçœŸå®žéƒ¨ç½²ä¸­ï¼Œæ¦‚å¿µå¢žå¼ºç­–ç•¥æ˜¾è‘—æå‡æ€§èƒ½ï¼Œæ¦‚å¿µç±»ä¼¼äººç±»å¯è§£é‡ŠåŽŸè¯­

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Effective generalization in robotic manipulation requires representations
> that capture invariant patterns of interaction across environments and tasks.
> We present a self-supervised framework for learning hierarchical manipulation
> concepts that encode these invariant patterns through cross-modal sensory
> correlations and multi-level temporal abstractions without requiring human
> annotation. Our approach combines a cross-modal correlation network that
> identifies persistent patterns across sensory modalities with a multi-horizon
> predictor that organizes representations hierarchically across temporal scales.
> Manipulation concepts learned through this dual structure enable policies to
> focus on transferable relational patterns while maintaining awareness of both
> immediate actions and longer-term goals. Empirical evaluation across simulated
> benchmarks and real-world deployments demonstrates significant performance
> improvements with our concept-enhanced policies. Analysis reveals that the
> learned concepts resemble human-interpretable manipulation primitives despite
> receiving no semantic supervision. This work advances both the understanding of
> representation learning for manipulation and provides a practical approach to
> enhancing robotic performance in complex scenarios.

