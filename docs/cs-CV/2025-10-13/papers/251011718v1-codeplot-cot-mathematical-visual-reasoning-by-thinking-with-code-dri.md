---
layout: default
title: CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images
---

# CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images

**arXiv**: [2510.11718v1](https://arxiv.org/abs/2510.11718) | [PDF](https://arxiv.org/pdf/2510.11718.pdf)

**ä½œè€…**: Chengqi Duan, Kaiyue Sun, Rongyao Fang, Manyuan Zhang, Yan Feng, Ying Luo, Yufang Liu, Ke Wang, Peng Pei, Xunliang Cai, Hongsheng Li, Yi Ma, Xihui Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCodePlot-CoTæ–¹æ³•ï¼Œé€šè¿‡ä»£ç é©±åŠ¨å›¾åƒè§£å†³æ•°å­¦è§†è§‰æŽ¨ç†é—®é¢˜**

**å…³é”®è¯**: `æ•°å­¦è§†è§‰æŽ¨ç†` `ä»£ç é©±åŠ¨æŽ¨ç†` `å¤šæ¨¡æ€å­¦ä¹ ` `æ•°æ®é›†æž„å»º` `å›¾åƒåˆ°ä»£ç è½¬æ¢`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šLLMså’ŒVLMsåœ¨éœ€è¦è§†è§‰è¾…åŠ©çš„æ•°å­¦æŽ¨ç†ä¸­ç¼ºä¹ç²¾ç¡®æ€§å’Œå¯æŽ§æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨VLMç”Ÿæˆæ–‡æœ¬æŽ¨ç†å’Œå¯æ‰§è¡Œç»˜å›¾ä»£ç ï¼Œæ¸²æŸ“å›¾åƒä½œä¸ºè§†è§‰æ€ç»´ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Math-VRåŸºå‡†ä¸Šï¼Œæ¨¡åž‹æ€§èƒ½æ¯”åŸºçº¿æå‡é«˜è¾¾21%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in Large Language Models (LLMs) and Vision Language Models
> (VLMs) have shown significant progress in mathematical reasoning, yet they
> still face a critical bottleneck with problems requiring visual assistance,
> such as drawing auxiliary lines or plotting functions to solve the problems.
> Most LLMs and VLMs are constrained to text-only reasoning chains, while
> multimodal unified models that can generate interleaved text and images lack
> the necessary precision and controllability for such tasks. To address this, we
> propose CodePlot-CoT, a code-driven Chain-of-Thought paradigm for "thinking
> with images" in mathematics. Our approach leverages the VLM to generate text
> reasoning as well as executable plotting code, which is then rendered into
> images as "visual thought", to solve mathematical problems. To achieve this, we
> first construct Math-VR, the first large-scale, bilingual dataset and benchmark
> for Mathematics problems with Visual Reasoning, comprising 178K samples.
> Second, to create high-quality training data, we develop a state-of-the-art
> image-to-code converter specialized for parsing complex mathematical figures
> into codes. Finally, using these training data, we train the CodePlot-CoT model
> for solving mathematical problems. Experimental results show that our model
> achieves up to 21% increase over base model on our new benchmark, fully
> validating the efficacy of our proposed code-driven reasoning paradigm. Our
> work opens a new direction for multimodal mathematical reasoning and provides
> the community with the first large-scale dataset, comprehensive benchmark, and
> strong approach for such problems. To facilitate future research, we make our
> datasets, code, and pretrained models publicly available at
> https://github.com/HKU-MMLab/Math-VR-CodePlot-CoT.

