---
layout: default
title: Lightweight Facial Landmark Detection in Thermal Images via Multi-Level Cross-Modal Knowledge Transfer
---

# Lightweight Facial Landmark Detection in Thermal Images via Multi-Level Cross-Modal Knowledge Transfer

**arXiv**: [2510.11128v1](https://arxiv.org/abs/2510.11128) | [PDF](https://arxiv.org/pdf/2510.11128.pdf)

**ä½œè€…**: Qiyi Tong, Olivia Nocentini, Marta Lagomarsino, Kuanqi Cai, Marta Lorenzini, Arash Ajoudani

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šçº§è·¨æ¨¡æ€çŸ¥è¯†è’¸é¦ä»¥è§£å†³çƒ­å›¾åƒä¸­è½»é‡çº§é¢éƒ¨å…³é”®ç‚¹æ£€æµ‹é—®é¢˜**

**å…³é”®è¯**: `é¢éƒ¨å…³é”®ç‚¹æ£€æµ‹` `çƒ­å›¾åƒåˆ†æž` `è·¨æ¨¡æ€çŸ¥è¯†è’¸é¦` `è½»é‡çº§æ¨¡åž‹` `æ¨¡æ€ä¸å˜ç‰¹å¾`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçƒ­å›¾åƒé¢éƒ¨å…³é”®ç‚¹æ£€æµ‹ç¼ºä¹ä¸°å¯Œè§†è§‰çº¿ç´¢ï¼Œä¼ ç»Ÿè·¨æ¨¡æ€æ–¹æ³•è®¡ç®—æ˜‚è´µæˆ–å¼•å…¥ç»“æž„ä¼ªå½±
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥åŒå‘åŒæ³¨å…¥çŸ¥è¯†è’¸é¦ï¼Œé€šè¿‡é—­çŽ¯ç›‘ç£å­¦ä¹ æ¨¡æ€ä¸å˜ç‰¹å¾ï¼Œç¡®ä¿è¯­ä¹‰å¯¹é½
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å…¬å¼€åŸºå‡†ä¸Šå®žçŽ°æ–°SOTAï¼Œæ˜¾è‘—é™ä½Žè®¡ç®—å¼€é”€å¹¶è¶…è¶Šå…ˆå‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Facial Landmark Detection (FLD) in thermal imagery is critical for
> applications in challenging lighting conditions, but it is hampered by the lack
> of rich visual cues. Conventional cross-modal solutions, like feature fusion or
> image translation from RGB data, are often computationally expensive or
> introduce structural artifacts, limiting their practical deployment. To address
> this, we propose Multi-Level Cross-Modal Knowledge Distillation (MLCM-KD), a
> novel framework that decouples high-fidelity RGB-to-thermal knowledge transfer
> from model compression to create both accurate and efficient thermal FLD
> models. A central challenge during knowledge transfer is the profound modality
> gap between RGB and thermal data, where traditional unidirectional distillation
> fails to enforce semantic consistency across disparate feature spaces. To
> overcome this, we introduce Dual-Injected Knowledge Distillation (DIKD), a
> bidirectional mechanism designed specifically for this task. DIKD establishes a
> connection between modalities: it not only guides the thermal student with rich
> RGB features but also validates the student's learned representations by
> feeding them back into the frozen teacher's prediction head. This closed-loop
> supervision forces the student to learn modality-invariant features that are
> semantically aligned with the teacher, ensuring a robust and profound knowledge
> transfer. Experiments show that our approach sets a new state-of-the-art on
> public thermal FLD benchmarks, notably outperforming previous methods while
> drastically reducing computational overhead.

