---
layout: default
title: A Framework for Low-Effort Training Data Generation for Urban Semantic Segmentation
---

# A Framework for Low-Effort Training Data Generation for Urban Semantic Segmentation

**arXiv**: [2510.11567v1](https://arxiv.org/abs/2510.11567) | [PDF](https://arxiv.org/pdf/2510.11567.pdf)

**ä½œè€…**: Denis Zavadski, Damjan KalÅ¡an, Tim KÃ¼chler, Haebom Lee, Stefan Roth, Carsten Rother

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ‰©æ•£æ¨¡å‹çš„æ¡†æ¶ï¼Œä»¥ä½ä»£ä»·ç”Ÿæˆé«˜ä¿çœŸåŸå¸‚è¯­ä¹‰åˆ†å‰²è®­ç»ƒæ•°æ®**

**å…³é”®è¯**: `åŸå¸‚è¯­ä¹‰åˆ†å‰²` `æ‰©æ•£æ¨¡å‹` `åŸŸé€‚åº”` `åˆæˆæ•°æ®ç”Ÿæˆ` `è®­ç»ƒæ•°æ®å¢å¼º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåˆæˆæ•°æ®ä¸çœŸå®å›¾åƒå­˜åœ¨åŸŸå·®è·ï¼Œå½±å“åŸå¸‚è¯­ä¹‰åˆ†å‰²æ¨¡å‹æ€§èƒ½
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨ä¸å®Œç¾ä¼ªæ ‡ç­¾é€‚é…æ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆç›®æ ‡åŸŸå¯¹é½å›¾åƒå¹¶è¿‡æ»¤ä¼˜åŒ–
3. å®éªŒæˆ–æ•ˆæœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼Œåˆ†å‰²æ€§èƒ½æå‡è¾¾8.0% mIoUï¼Œè¶…è¶Šç°æœ‰ç¿»è¯‘æ–¹æ³•

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Synthetic datasets are widely used for training urban scene recognition
> models, but even highly realistic renderings show a noticeable gap to real
> imagery. This gap is particularly pronounced when adapting to a specific target
> domain, such as Cityscapes, where differences in architecture, vegetation,
> object appearance, and camera characteristics limit downstream performance.
> Closing this gap with more detailed 3D modelling would require expensive asset
> and scene design, defeating the purpose of low-cost labelled data. To address
> this, we present a new framework that adapts an off-the-shelf diffusion model
> to a target domain using only imperfect pseudo-labels. Once trained, it
> generates high-fidelity, target-aligned images from semantic maps of any
> synthetic dataset, including low-effort sources created in hours rather than
> months. The method filters suboptimal generations, rectifies image-label
> misalignments, and standardises semantics across datasets, transforming weak
> synthetic data into competitive real-domain training sets. Experiments on five
> synthetic datasets and two real target datasets show segmentation gains of up
> to +8.0%pt. mIoU over state-of-the-art translation methods, making rapidly
> constructed synthetic datasets as effective as high-effort, time-intensive
> synthetic datasets requiring extensive manual design. This work highlights a
> valuable collaborative paradigm where fast semantic prototyping, combined with
> generative models, enables scalable, high-quality training data creation for
> urban scene understanding.

