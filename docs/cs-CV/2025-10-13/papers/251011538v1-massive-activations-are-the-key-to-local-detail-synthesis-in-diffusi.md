---
layout: default
title: Massive Activations are the Key to Local Detail Synthesis in Diffusion Transformers
---

# Massive Activations are the Key to Local Detail Synthesis in Diffusion Transformers

**arXiv**: [2510.11538v1](https://arxiv.org/abs/2510.11538) | [PDF](https://arxiv.org/pdf/2510.11538.pdf)

**ä½œè€…**: Chaofan Gan, Zicheng Zhao, Yuanpeng Tu, Xi Chen, Ziran Qin, Tieyuan Chen, Mehrtash Harandi, Weiyao Lin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»†èŠ‚å¼•å¯¼ç­–ç•¥ä»¥å¢žå¼ºæ‰©æ•£å˜æ¢å™¨ä¸­çš„å±€éƒ¨ç»†èŠ‚åˆæˆ**

**å…³é”®è¯**: `æ‰©æ•£å˜æ¢å™¨` `å¤§è§„æ¨¡æ¿€æ´»` `å±€éƒ¨ç»†èŠ‚åˆæˆ` `è‡ªå¼•å¯¼ç­–ç•¥` `è®­ç»ƒå…è´¹æ–¹æ³•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‰©æ•£å˜æ¢å™¨å†…éƒ¨ç‰¹å¾å›¾ä¸­çš„å¤§è§„æ¨¡æ¿€æ´»åŠŸèƒ½æœªæ˜Žï¼Œå½±å“å±€éƒ¨ç»†èŠ‚åˆæˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽå¤§è§„æ¨¡æ¿€æ´»æž„å»ºè®­ç»ƒå…è´¹è‡ªå¼•å¯¼ç­–ç•¥ï¼Œé€šè¿‡ç ´åæ¿€æ´»ç”Ÿæˆç»†èŠ‚ç¼ºé™·æ¨¡åž‹è¿›è¡ŒæŒ‡å¯¼ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šç§é¢„è®­ç»ƒæ‰©æ•£å˜æ¢å™¨ä¸ŠéªŒè¯ï¼Œç»†èŠ‚è´¨é‡ä¸€è‡´æå‡ï¼Œå¯ä¸Žåˆ†ç±»å™¨è‡ªç”±å¼•å¯¼ç»“åˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Diffusion Transformers (DiTs) have recently emerged as a powerful backbone
> for visual generation. Recent observations reveal \emph{Massive Activations}
> (MAs) in their internal feature maps, yet their function remains poorly
> understood. In this work, we systematically investigate these activations to
> elucidate their role in visual generation. We found that these massive
> activations occur across all spatial tokens, and their distribution is
> modulated by the input timestep embeddings. Importantly, our investigations
> further demonstrate that these massive activations play a key role in local
> detail synthesis, while having minimal impact on the overall semantic content
> of output. Building on these insights, we propose \textbf{D}etail
> \textbf{G}uidance (\textbf{DG}), a MAs-driven, training-free self-guidance
> strategy to explicitly enhance local detail fidelity for DiTs. Specifically, DG
> constructs a degraded ``detail-deficient'' model by disrupting MAs and
> leverages it to guide the original network toward higher-quality detail
> synthesis. Our DG can seamlessly integrate with Classifier-Free Guidance (CFG),
> enabling further refinements of fine-grained details. Extensive experiments
> demonstrate that our DG consistently improves fine-grained detail quality
> across various pre-trained DiTs (\eg, SD3, SD3.5, and Flux).

