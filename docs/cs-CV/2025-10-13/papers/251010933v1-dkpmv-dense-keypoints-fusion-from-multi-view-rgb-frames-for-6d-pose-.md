---
layout: default
title: DKPMV: Dense Keypoints Fusion from Multi-View RGB Frames for 6D Pose Estimation of Textureless Objects
---

# DKPMV: Dense Keypoints Fusion from Multi-View RGB Frames for 6D Pose Estimation of Textureless Objects

**arXiv**: [2510.10933v1](https://arxiv.org/abs/2510.10933) | [PDF](https://arxiv.org/pdf/2510.10933.pdf)

**ä½œè€…**: Jiahong Chen, Jinghao Wang, Zi Wang, Ziwen Wang, Banglei Guan, Qifeng Yu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDKPMVä»¥è§£å†³æ— çº¹ç†ç‰©ä½“6Då§¿æ€ä¼°è®¡ä¸­å¤šè§†è§’RGBå›¾åƒèžåˆä¸è¶³çš„é—®é¢˜**

**å…³é”®è¯**: `6Då§¿æ€ä¼°è®¡` `å¤šè§†è§’èžåˆ` `å¯†é›†å…³é”®ç‚¹` `æ— çº¹ç†ç‰©ä½“` `æ³¨æ„åŠ›æœºåˆ¶` `å¯¹ç§°æ„ŸçŸ¥è®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ— çº¹ç†ç‰©ä½“6Då§¿æ€ä¼°è®¡å¸¸å› æ·±åº¦ä¿¡æ¯ç¼ºå¤±è€Œå›°éš¾ï¼ŒçŽ°æœ‰å¤šè§†è§’æ–¹æ³•ä¾èµ–æ·±åº¦æ•°æ®æˆ–å‡ ä½•çº¿ç´¢åˆ©ç”¨ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡ä¸‰é˜¶æ®µæ¸è¿›å§¿æ€ä¼˜åŒ–ç­–ç•¥ï¼Œé€šè¿‡æ³¨æ„åŠ›èšåˆå’Œå¯¹ç§°æ„ŸçŸ¥è®­ç»ƒå¢žå¼ºå…³é”®ç‚¹ç½‘ç»œï¼Œå®žçŽ°å¯†é›†å…³é”®ç‚¹èžåˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ROBIæ•°æ®é›†ä¸Šä¼˜äºŽå¤šè§†è§’RGBæ–¹æ³•ï¼Œå¤šæ•°æƒ…å†µä¸‹è¶…è¶ŠRGB-Dæ–¹æ³•ï¼Œä»£ç å³å°†å‘å¸ƒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> 6D pose estimation of textureless objects is valuable for industrial robotic
> applications, yet remains challenging due to the frequent loss of depth
> information. Current multi-view methods either rely on depth data or
> insufficiently exploit multi-view geometric cues, limiting their performance.
> In this paper, we propose DKPMV, a pipeline that achieves dense keypoint-level
> fusion using only multi-view RGB images as input. We design a three-stage
> progressive pose optimization strategy that leverages dense multi-view keypoint
> geometry information. To enable effective dense keypoint fusion, we enhance the
> keypoint network with attentional aggregation and symmetry-aware training,
> improving prediction accuracy and resolving ambiguities on symmetric objects.
> Extensive experiments on the ROBI dataset demonstrate that DKPMV outperforms
> state-of-the-art multi-view RGB approaches and even surpasses the RGB-D methods
> in the majority of cases. The code will be available soon.

