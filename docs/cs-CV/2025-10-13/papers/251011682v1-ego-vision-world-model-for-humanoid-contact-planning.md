---
layout: default
title: Ego-Vision World Model for Humanoid Contact Planning
---

# Ego-Vision World Model for Humanoid Contact Planning

**arXiv**: [2510.11682v1](https://arxiv.org/abs/2510.11682) | [PDF](https://arxiv.org/pdf/2510.11682.pdf)

**ä½œè€…**: Hang Liu, Yuman Gao, Sangli Teng, Yufeng Chi, Yakun Sophia Shao, Zhongyu Li, Maani Ghaffari, Koushil Sreenath

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“åˆä¸–ç•Œæ¨¡åž‹ä¸Žæ¨¡åž‹é¢„æµ‹æŽ§åˆ¶çš„äººå½¢æœºå™¨äººæŽ¥è§¦è§„åˆ’æ¡†æž¶ï¼Œä»¥æå‡éžç»“æž„åŒ–çŽ¯å¢ƒä¸­çš„è‡ªä¸»æ€§ã€‚**

**å…³é”®è¯**: `äººå½¢æœºå™¨äºº` `æŽ¥è§¦è§„åˆ’` `ä¸–ç•Œæ¨¡åž‹` `æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶` `ç¦»çº¿å¼ºåŒ–å­¦ä¹ ` `è‡ªæˆ‘ä¸­å¿ƒè§†è§‰`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿä¼˜åŒ–è§„åˆ’å™¨éš¾ä»¥å¤„ç†å¤æ‚æŽ¥è§¦ï¼Œåœ¨çº¿å¼ºåŒ–å­¦ä¹ æ ·æœ¬æ•ˆçŽ‡ä½Žä¸”å¤šä»»åŠ¡èƒ½åŠ›æœ‰é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨ç¦»çº¿æ•°æ®é›†è®­ç»ƒä¸–ç•Œæ¨¡åž‹ï¼Œåœ¨åŽ‹ç¼©æ½œåœ¨ç©ºé—´é¢„æµ‹æœªæ¥ï¼Œç»“åˆé‡‡æ ·MPCå’Œä»£ç†ä»·å€¼å‡½æ•°ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ç‰©ç†äººå½¢æœºå™¨äººä¸Šå®žçŽ°å®žæ—¶æŽ¥è§¦è§„åˆ’ï¼Œæ”¯æŒæ‰°åŠ¨åŽæ”¯æ’‘ã€é˜»æŒ¡ç‰©ä½“å’Œç©¿è¶Šé™é«˜æ‹±é—¨ç­‰ä»»åŠ¡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Enabling humanoid robots to exploit physical contact, rather than simply
> avoid collisions, is crucial for autonomy in unstructured environments.
> Traditional optimization-based planners struggle with contact complexity, while
> on-policy reinforcement learning (RL) is sample-inefficient and has limited
> multi-task ability. We propose a framework combining a learned world model with
> sampling-based Model Predictive Control (MPC), trained on a demonstration-free
> offline dataset to predict future outcomes in a compressed latent space. To
> address sparse contact rewards and sensor noise, the MPC uses a learned
> surrogate value function for dense, robust planning. Our single, scalable model
> supports contact-aware tasks, including wall support after perturbation,
> blocking incoming objects, and traversing height-limited arches, with improved
> data efficiency and multi-task capability over on-policy RL. Deployed on a
> physical humanoid, our system achieves robust, real-time contact planning from
> proprioception and ego-centric depth images. Website:
> https://ego-vcp.github.io/

