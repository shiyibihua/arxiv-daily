---
layout: default
title: Human Uncertainty-Aware Data Selection and Automatic Labeling in Visual Question Answering
---

# Human Uncertainty-Aware Data Selection and Automatic Labeling in Visual Question Answering

**arXiv**: [2510.11295v1](https://arxiv.org/abs/2510.11295) | [PDF](https://arxiv.org/pdf/2510.11295.pdf)

**ä½œè€…**: Jian Lan, Zhicheng Liu, Udo Schlegel, Raoyuan Zhao, Yihong Liu, Hinrich SchÃ¼tze, Michael A. Hedderich, Thomas Seidl

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHaDolaæ¡†æž¶ä»¥åˆ©ç”¨äººç±»ä¸ç¡®å®šæ€§ä¼˜åŒ–è§†è§‰é—®ç­”æ¨¡åž‹è®­ç»ƒ**

**å…³é”®è¯**: `è§†è§‰é—®ç­”` `äººç±»ä¸ç¡®å®šæ€§` `æ•°æ®é€‰æ‹©` `è‡ªåŠ¨æ ‡æ³¨` `æ¨¡åž‹æ ¡å‡†` `ç›‘ç£å¾®è°ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šäººç±»ä¸ç¡®å®šæ€§å½±å“ç›‘ç£å¾®è°ƒï¼Œé«˜ä¸ç¡®å®šæ€§æ ·æœ¬å¯èƒ½é™ä½Žæ¨¡åž‹æ€§èƒ½ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šHaDolaé€šè¿‡å››é˜¶æ®µè¿­ä»£é€‰æ‹©æ•°æ®å¹¶è‡ªåŠ¨æ ‡æ³¨ï¼Œå‡å°‘å¯¹æ˜‚è´µæ ‡æ³¨çš„ä¾èµ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨VQAv2å’ŒVizWizæ•°æ®é›†ä¸Šï¼ŒHaDolaä»¥æ›´å°‘æ•°æ®åŒ¹é…æˆ–è¶…è¶Šå…ˆè¿›åŸºçº¿ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large vision-language models (VLMs) achieve strong performance in Visual
> Question Answering but still rely heavily on supervised fine-tuning (SFT) with
> massive labeled datasets, which is costly due to human annotations. Crucially,
> real-world datasets often exhibit human uncertainty (HU) -- variation in human
> confidence across annotations -- but standard SFT simply optimizes toward the
> most frequent label, disregarding HU distributions. This leaves two open
> questions: How does HU affect SFT, and how can HU be effectively leveraged in
> training? In this work, we first conduct a systematic evaluation of VLMs across
> varying HU levels. We have two key findings: (i) surprisingly, high-HU samples
> contribute little or even degrade model performance, and (ii) naively training
> on the full dataset yields under-calibrated models that fail to capture HU
> distributions. Motivated by these findings, we introduce HaDola, a human
> uncertainty-aware data selection and automatic labeling framework. HaDola
> operates in four stages -- discriminate, self-annotate, error trigger, and
> training -- to iteratively identify harmful samples, prioritize informative
> ones, and bootstrap from a small seed set (5\% of data). Our approach
> substantially reduces reliance on costly HU annotations and makes VLMs more
> accurate and better calibrated. Extensive experiments on VQAv2 and VizWiz
> datasets demonstrate that HaDola consistently matches or outperforms
> state-of-the-art baselines with less training data. Our work highlights the
> importance of explicitly modeling HU in SFT, suggesting that better utilization
> of HU is more effective than merely scaling up dataset size.

