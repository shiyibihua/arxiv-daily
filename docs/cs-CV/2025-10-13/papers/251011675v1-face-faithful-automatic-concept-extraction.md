---
layout: default
title: FACE: Faithful Automatic Concept Extraction
---

# FACE: Faithful Automatic Concept Extraction

**arXiv**: [2510.11675v1](https://arxiv.org/abs/2510.11675) | [PDF](https://arxiv.org/pdf/2510.11675.pdf)

**ä½œè€…**: Dipkamal Bhusal, Michael Clifford, Sara Rampazzi, Nidhi Rastogi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFACEæ¡†æž¶ä»¥è§£å†³è‡ªåŠ¨æ¦‚å¿µæå–ä¸­è§£é‡Šå¿ å®žæ€§é—®é¢˜**

**å…³é”®è¯**: `æ¦‚å¿µæå–` `è§£é‡Šå¿ å®žæ€§` `éžè´ŸçŸ©é˜µåˆ†è§£` `KLæ•£åº¦æ­£åˆ™åŒ–` `æ·±åº¦å­¦ä¹ è§£é‡Š`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è‡ªåŠ¨æ¦‚å¿µå‘çŽ°æ–¹æ³•å¸¸ä¸Žæ¨¡åž‹å†³ç­–è¿‡ç¨‹ä¸ä¸€è‡´ï¼Œå½±å“è§£é‡Šå¿ å®žæ€§ã€‚
2. FACEç»“åˆNMFä¸ŽKLæ•£åº¦æ­£åˆ™åŒ–ï¼Œç¡®ä¿æ¦‚å¿µé¢„æµ‹ä¸ŽåŽŸé¢„æµ‹å¯¹é½ã€‚
3. åœ¨ImageNetç­‰æ•°æ®é›†ä¸Šè¯„ä¼°ï¼ŒFACEåœ¨å¿ å®žæ€§å’Œç¨€ç–æ€§ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Interpreting deep neural networks through concept-based explanations offers a
> bridge between low-level features and high-level human-understandable
> semantics. However, existing automatic concept discovery methods often fail to
> align these extracted concepts with the model's true decision-making process,
> thereby compromising explanation faithfulness. In this work, we propose FACE
> (Faithful Automatic Concept Extraction), a novel framework that augments
> Non-negative Matrix Factorization (NMF) with a Kullback-Leibler (KL) divergence
> regularization term to ensure alignment between the model's original and
> concept-based predictions. Unlike prior methods that operate solely on encoder
> activations, FACE incorporates classifier supervision during concept learning,
> enforcing predictive consistency and enabling faithful explanations. We provide
> theoretical guarantees showing that minimizing the KL divergence bounds the
> deviation in predictive distributions, thereby promoting faithful local
> linearity in the learned concept space. Systematic evaluations on ImageNet,
> COCO, and CelebA datasets demonstrate that FACE outperforms existing methods
> across faithfulness and sparsity metrics.

