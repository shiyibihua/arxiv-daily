---
layout: default
title: VA-GS: Enhancing the Geometric Representation of Gaussian Splatting via View Alignment
---

# VA-GS: Enhancing the Geometric Representation of Gaussian Splatting via View Alignment

**arXiv**: [2510.11473v1](https://arxiv.org/abs/2510.11473) | [PDF](https://arxiv.org/pdf/2510.11473.pdf)

**ä½œè€…**: Qing Li, Huifang Feng, Xun Gong, Yu-Shen Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVA-GSæ–¹æ³•ï¼Œé€šè¿‡è§†å›¾å¯¹é½å¢žå¼º3Dé«˜æ–¯æ³¼æº…çš„å‡ ä½•è¡¨ç¤ºï¼Œä»¥æ”¹è¿›è¡¨é¢é‡å»ºå’Œæ–°è§†è§’åˆæˆã€‚**

**å…³é”®è¯**: `3Dé«˜æ–¯æ³¼æº…` `è¡¨é¢é‡å»º` `æ–°è§†è§’åˆæˆ` `è§†å›¾å¯¹é½` `å‡ ä½•è¡¨ç¤º` `å¤šè§†å›¾ä¸€è‡´æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼š3Dé«˜æ–¯æ³¼æº…åœ¨å›¾åƒæ¸²æŸ“æŸå¤±ä¸‹å‡ ä½•ä¸å‡†ç¡®ä¸”å¤šè§†å›¾å¯¹é½ä¸ä¸€è‡´ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥è¾¹ç¼˜æ„ŸçŸ¥æ¸²æŸ“æŸå¤±ã€å¯è§æ€§æ„ŸçŸ¥å…‰åº¦å¯¹é½æŸå¤±å’Œæ³•å‘çº¦æŸã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­å®žçŽ°è¡¨é¢é‡å»ºå’Œæ–°è§†è§’åˆæˆçš„æœ€å…ˆè¿›æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> 3D Gaussian Splatting has recently emerged as an efficient solution for
> high-quality and real-time novel view synthesis. However, its capability for
> accurate surface reconstruction remains underexplored. Due to the discrete and
> unstructured nature of Gaussians, supervision based solely on image rendering
> loss often leads to inaccurate geometry and inconsistent multi-view alignment.
> In this work, we propose a novel method that enhances the geometric
> representation of 3D Gaussians through view alignment (VA). Specifically, we
> incorporate edge-aware image cues into the rendering loss to improve surface
> boundary delineation. To enforce geometric consistency across views, we
> introduce a visibility-aware photometric alignment loss that models occlusions
> and encourages accurate spatial relationships among Gaussians. To further
> mitigate ambiguities caused by lighting variations, we incorporate normal-based
> constraints to refine the spatial orientation of Gaussians and improve local
> surface estimation. Additionally, we leverage deep image feature embeddings to
> enforce cross-view consistency, enhancing the robustness of the learned
> geometry under varying viewpoints and illumination. Extensive experiments on
> standard benchmarks demonstrate that our method achieves state-of-the-art
> performance in both surface reconstruction and novel view synthesis. The source
> code is available at https://github.com/LeoQLi/VA-GS.

