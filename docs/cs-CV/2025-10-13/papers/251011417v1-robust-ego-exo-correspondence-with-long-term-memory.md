---
layout: default
title: Robust Ego-Exo Correspondence with Long-Term Memory
---

# Robust Ego-Exo Correspondence with Long-Term Memory

**arXiv**: [2510.11417v1](https://arxiv.org/abs/2510.11417) | [PDF](https://arxiv.org/pdf/2510.11417.pdf)

**ä½œè€…**: Yijun Hu, Bing Fan, Xin Gu, Haiqing Ren, Dongfang Liu, Heng Fan, Libo Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽSAM 2çš„é•¿è®°å¿†EECæ¡†æž¶ï¼Œè§£å†³è§†è§’å˜åŒ–ä¸Žé•¿è§†é¢‘æŒ‘æˆ˜**

**å…³é”®è¯**: `ego-exoå¯¹åº”` `é•¿è§†é¢‘ç†è§£` `åŒè®°å¿†æž¶æž„` `è‡ªé€‚åº”ç‰¹å¾è·¯ç”±` `SAM 2æ”¹è¿›`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§’å˜åŒ–ã€é®æŒ¡å’Œå°ç‰©ä½“å¯¼è‡´ego-exoå¯¹åº”å›°éš¾ï¼ŒçŽ°æœ‰æ–¹æ³•æ€§èƒ½ä¸è¶³
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥åŒè®°å¿†æž¶æž„å’Œè‡ªé€‚åº”ç‰¹å¾è·¯ç”±æ¨¡å—ï¼Œæå‡ç‰¹å¾èžåˆä¸Žé•¿æœŸè®°å¿†èƒ½åŠ›
3. å®žéªŒæ•ˆæžœï¼šåœ¨EgoExo4DåŸºå‡†ä¸Šå®žçŽ°SOTAï¼Œæ˜¾è‘—ä¼˜äºŽSAM 2å’ŒçŽ°æœ‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Establishing object-level correspondence between egocentric and exocentric
> views is essential for intelligent assistants to deliver precise and intuitive
> visual guidance. However, this task faces numerous challenges, including
> extreme viewpoint variations, occlusions, and the presence of small objects.
> Existing approaches usually borrow solutions from video object segmentation
> models, but still suffer from the aforementioned challenges. Recently, the
> Segment Anything Model 2 (SAM 2) has shown strong generalization capabilities
> and excellent performance in video object segmentation. Yet, when simply
> applied to the ego-exo correspondence (EEC) task, SAM 2 encounters severe
> difficulties due to ineffective ego-exo feature fusion and limited long-term
> memory capacity, especially for long videos. Addressing these problems, we
> propose a novel EEC framework based on SAM 2 with long-term memories by
> presenting a dual-memory architecture and an adaptive feature routing module
> inspired by Mixture-of-Experts (MoE). Compared to SAM 2, our approach features
> (i) a Memory-View MoE module which consists of a dual-branch routing mechanism
> to adaptively assign contribution weights to each expert feature along both
> channel and spatial dimensions, and (ii) a dual-memory bank system with a
> simple yet effective compression strategy to retain critical long-term
> information while eliminating redundancy. In the extensive experiments on the
> challenging EgoExo4D benchmark, our method, dubbed LM-EEC, achieves new
> state-of-the-art results and significantly outperforms existing methods and the
> SAM 2 baseline, showcasing its strong generalization across diverse scenarios.
> Our code and model are available at https://github.com/juneyeeHu/LM-EEC.

