---
layout: default
title: SCOOP'D: Learning Mixed-Liquid-Solid Scooping via Sim2Real Generative Policy
---

# SCOOP'D: Learning Mixed-Liquid-Solid Scooping via Sim2Real Generative Policy

**arXiv**: [2510.11566v1](https://arxiv.org/abs/2510.11566) | [PDF](https://arxiv.org/pdf/2510.11566.pdf)

**ä½œè€…**: Kuanning Wang, Yongchong Gu, Yuqian Fu, Zeyu Shangguan, Sicheng He, Xiangyang Xue, Yanwei Fu, Daniel Seita

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSCOOP'Dæ–¹æ³•ï¼Œé€šè¿‡ä»¿çœŸåˆ°çœŸå®žç”Ÿæˆç­–ç•¥å­¦ä¹ æ··åˆæ¶²ä½“å›ºä½“èˆ€å–ã€‚**

**å…³é”®è¯**: `æœºå™¨äººèˆ€å–` `ä»¿çœŸåˆ°çœŸå®ž` `ç”Ÿæˆç­–ç•¥` `æ‰©æ•£æ¨¡åž‹` `å¯å˜å½¢ç‰©ä½“æ“ä½œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨äººèˆ€å–éœ€å¤„ç†å¤æ‚å·¥å…·-ç‰©ä½“äº¤äº’å’Œå¯å˜å½¢ç‰©ä½“åŠ¨æ€ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨ä»¿çœŸæ”¶é›†æ¼”ç¤ºï¼Œé€šè¿‡æ‰©æ•£ç”Ÿæˆç­–ç•¥æ¨¡ä»¿è§‚å¯Ÿè¾“å…¥ã€‚
3. å®žéªŒæ•ˆæžœï¼šé›¶æ ·æœ¬éƒ¨ç½²åœ¨465æ¬¡è¯•éªŒä¸­è¡¨çŽ°ä¼˜å¼‚ï¼Œä¼˜äºŽåŸºçº¿æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Scooping items with tools such as spoons and ladles is common in daily life,
> ranging from assistive feeding to retrieving items from environmental disaster
> sites. However, developing a general and autonomous robotic scooping policy is
> challenging since it requires reasoning about complex tool-object interactions.
> Furthermore, scooping often involves manipulating deformable objects, such as
> granular media or liquids, which is challenging due to their
> infinite-dimensional configuration spaces and complex dynamics. We propose a
> method, SCOOP'D, which uses simulation from OmniGibson (built on NVIDIA
> Omniverse) to collect scooping demonstrations using algorithmic procedures that
> rely on privileged state information. Then, we use generative policies via
> diffusion to imitate demonstrations from observational input. We directly apply
> the learned policy in diverse real-world scenarios, testing its performance on
> various item quantities, item characteristics, and container types. In
> zero-shot deployment, our method demonstrates promising results across 465
> trials in diverse scenarios, including objects of different difficulty levels
> that we categorize as "Level 1" and "Level 2." SCOOP'D outperforms all
> baselines and ablations, suggesting that this is a promising approach to
> acquiring robotic scooping skills. Project page is at
> https://scoopdiff.github.io/.

