---
layout: default
title: CoDefend: Cross-Modal Collaborative Defense via Diffusion Purification and Prompt Optimization
---

# CoDefend: Cross-Modal Collaborative Defense via Diffusion Purification and Prompt Optimization

**arXiv**: [2510.11096v1](https://arxiv.org/abs/2510.11096) | [PDF](https://arxiv.org/pdf/2510.11096.pdf)

**ä½œè€…**: Fengling Zhu, Boshi Liu, Jingyu Hua, Sheng Zhong

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç›‘ç£æ‰©æ•£åŽ»å™ªä¸Žæç¤ºä¼˜åŒ–ä»¥é˜²å¾¡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹çš„è§†è§‰å¯¹æŠ—æ”»å‡»**

**å…³é”®è¯**: `å¤šæ¨¡æ€é˜²å¾¡` `æ‰©æ•£åŽ»å™ª` `æç¤ºä¼˜åŒ–` `å¯¹æŠ—æ”»å‡»` `å›¾åƒé‡å»º` `é²æ£’æ€§æå‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹æ˜“å—è§†è§‰å¯¹æŠ—æ”»å‡»ï¼Œå¯¼è‡´æœ‰å®³æˆ–è¯¯å¯¼è¾“å‡º
2. ä½¿ç”¨ç›‘ç£æ‰©æ•£åŽ»å™ªæ¡†æž¶ï¼Œç»“åˆä»»åŠ¡ç‰¹å®šæŒ‡å¯¼æå‡å›¾åƒé‡å»ºè´¨é‡ä¸Žé˜²å¾¡é²æ£’æ€§
3. åœ¨å›¾åƒæè¿°å’Œè§†è§‰é—®ç­”ä»»åŠ¡ä¸­éªŒè¯ï¼Œæ˜¾è‘—æå‡é²æ£’æ€§å¹¶å…·å¼ºè¿ç§»æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) have achieved remarkable success in
> tasks such as image captioning, visual question answering, and cross-modal
> reasoning by integrating visual and textual modalities. However, their
> multimodal nature also exposes them to adversarial threats, where attackers can
> perturb either modality or both jointly to induce harmful, misleading, or
> policy violating outputs. Existing defense strategies, such as adversarial
> training and input purification, face notable limitations: adversarial training
> typically improves robustness only against known attacks while incurring high
> computational costs, whereas conventional purification approaches often suffer
> from degraded image quality and insufficient generalization to complex
> multimodal tasks.
>   In this work, we focus on defending the visual modality, which frequently
> serves as the primary entry point for adversarial manipulation. We propose a
> supervised diffusion based denoising framework that leverages paired
> adversarial clean image datasets to fine-tune diffusion models with
> directional, task specific guidance. Unlike prior unsupervised purification
> methods such as DiffPure, our approach achieves higher quality reconstructions
> while significantly improving defense robustness in multimodal tasks.
> Furthermore, we incorporate prompt optimization as a complementary defense
> mechanism, enhancing resistance against diverse and unseen attack strategies.
>   Extensive experiments on image captioning and visual question answering
> demonstrate that our method not only substantially improves robustness but also
> exhibits strong transferability to unknown adversarial attacks. These results
> highlight the effectiveness of supervised diffusion based denoising for
> multimodal defense, paving the way for more reliable and secure deployment of
> MLLMs in real world applications.

