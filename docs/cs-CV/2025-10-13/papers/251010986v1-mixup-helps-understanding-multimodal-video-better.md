---
layout: default
title: Mixup Helps Understanding Multimodal Video Better
---

# Mixup Helps Understanding Multimodal Video Better

**arXiv**: [2510.10986v1](https://arxiv.org/abs/2510.10986) | [PDF](https://arxiv.org/pdf/2510.10986.pdf)

**ä½œè€…**: Xiaoyu Ma, Ding Ding, Hao Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¹³è¡¡å¤šæ¨¡æ€æ··åˆæ–¹æ³•ä»¥è§£å†³å¤šæ¨¡æ€è§†é¢‘ç†è§£ä¸­çš„æ¨¡æ€ä¸å¹³è¡¡é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€è§†é¢‘ç†è§£` `æ¨¡æ€ä¸å¹³è¡¡` `æ··åˆç­–ç•¥` `æ³›åŒ–æ€§æå‡` `é²æ£’æ€§å¢žå¼º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€æ¨¡åž‹æ˜“è¿‡æ‹Ÿåˆå¼ºæ¨¡æ€ï¼ŒæŠ‘åˆ¶å¼±æ¨¡æ€è´¡çŒ®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå…ˆå¼•å…¥å¤šæ¨¡æ€æ··åˆï¼Œå†åŸºäºŽæ¨¡æ€è´¡çŒ®åŠ¨æ€è°ƒæ•´æ··åˆæ¯”ä¾‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠéªŒè¯æ–¹æ³•æå‡æ³›åŒ–æ€§å’Œé²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal video understanding plays a crucial role in tasks such as action
> recognition and emotion classification by combining information from different
> modalities. However, multimodal models are prone to overfitting strong
> modalities, which can dominate learning and suppress the contributions of
> weaker ones. To address this challenge, we first propose Multimodal Mixup (MM),
> which applies the Mixup strategy at the aggregated multimodal feature level to
> mitigate overfitting by generating virtual feature-label pairs. While MM
> effectively improves generalization, it treats all modalities uniformly and
> does not account for modality imbalance during training. Building on MM, we
> further introduce Balanced Multimodal Mixup (B-MM), which dynamically adjusts
> the mixing ratios for each modality based on their relative contributions to
> the learning objective. Extensive experiments on several datasets demonstrate
> the effectiveness of our methods in improving generalization and multimodal
> robustness.

