---
layout: default
title: ManiAgent: An Agentic Framework for General Robotic Manipulation
---

# ManiAgent: An Agentic Framework for General Robotic Manipulation

**arXiv**: [2510.11660v1](https://arxiv.org/abs/2510.11660) | [PDF](https://arxiv.org/pdf/2510.11660.pdf)

**ä½œè€…**: Yi Yang, Kefan Gu, Yuqing Wen, Hebei Li, Yucheng Zhao, Tiancai Wang, Xudong Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºManiAgentä»£ç†æ¡†æž¶ä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­å¤æ‚æŽ¨ç†å’Œé•¿æ—¶ä»»åŠ¡è§„åˆ’é—®é¢˜**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `ä»£ç†æ¡†æž¶` `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `ä»»åŠ¡è§„åˆ’` `å¤šä»£ç†ç³»ç»Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹åœ¨å¤æ‚æŽ¨ç†å’Œé•¿æ—¶ä»»åŠ¡è§„åˆ’ä¸­å—é™äºŽæ•°æ®ç¨€ç¼ºå’Œæ¨¡åž‹èƒ½åŠ›
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å¤šä»£ç†æž¶æž„ï¼Œé€šè¿‡ä»£ç†é—´é€šä¿¡å®žçŽ°çŽ¯å¢ƒæ„ŸçŸ¥ã€å­ä»»åŠ¡åˆ†è§£å’ŒåŠ¨ä½œç”Ÿæˆ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨SimplerEnvåŸºå‡†ä¸ŠæˆåŠŸçŽ‡86.8%ï¼ŒçœŸå®žä¸–ç•Œæ‹¾æ”¾ä»»åŠ¡æˆåŠŸçŽ‡95.8%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While Vision-Language-Action (VLA) models have demonstrated impressive
> capabilities in robotic manipulation, their performance in complex reasoning
> and long-horizon task planning is limited by data scarcity and model capacity.
> To address this, we introduce ManiAgent, an agentic architecture for general
> manipulation tasks that achieves end-to-end output from task descriptions and
> environmental inputs to robotic manipulation actions. In this framework,
> multiple agents involve inter-agent communication to perform environmental
> perception, sub-task decomposition and action generation, enabling efficient
> handling of complex manipulation scenarios. Evaluations show ManiAgent achieves
> an 86.8% success rate on the SimplerEnv benchmark and 95.8% on real-world
> pick-and-place tasks, enabling efficient data collection that yields VLA models
> with performance comparable to those trained on human-annotated datasets.The
> project webpage is available at https://yi-yang929.github.io/ManiAgent/.

