---
layout: default
title: COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models
---

# COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models

**arXiv**: [2510.11012v1](https://arxiv.org/abs/2510.11012) | [PDF](https://arxiv.org/pdf/2510.11012.pdf)

**ä½œè€…**: Sanchit Sinha, Guangzhi Xiong, Aidong Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCOCO-Treeæ¦‚å¿µæ ‘æ–¹æ³•ä»¥å¢žå¼ºè§†è§‰è¯­è¨€æ¨¡åž‹çš„ç»„åˆæŽ¨ç†èƒ½åŠ›**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡åž‹` `ç»„åˆæŽ¨ç†` `æ¦‚å¿µæ ‘` `ç¥žç»ç¬¦å·æ–¹æ³•` `åŸºå‡†æµ‹è¯•` `è§£é‡Šæ€§æŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§‰è¯­è¨€æ¨¡åž‹åœ¨ç»„åˆæŽ¨ç†ä¸­è¡¨çŽ°ä¸ä½³ï¼Œéš¾ä»¥ç†è§£å¤šå¯¹è±¡ã€å±žæ€§å’Œå…³ç³»çš„äº¤äº’ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨ç¥žç»ç¬¦å·æ¦‚å¿µæ ‘ä»Žå¤§åž‹è¯­è¨€æ¨¡åž‹å­¦ä¹ ï¼Œæå‡æŽ¨ç†è¿‡ç¨‹å¹¶æä¾›è§£é‡Šæ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œç»„åˆæ³›åŒ–æ€§èƒ½æå‡5-10%ï¼Œä¼˜äºŽåŸºçº¿æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Compositional reasoning remains a persistent weakness of modern vision
> language models (VLMs): they often falter when a task hinges on understanding
> how multiple objects, attributes, and relations interact within an image.
> Multiple research works have attempted to improve compositionality performance
> by creative tricks such as improving prompt structure, chain of thought
> reasoning, etc. A more recent line of work attempts to impart additional
> reasoning in VLMs using well-trained Large Language Models (LLMs), which are
> far superior in linguistic understanding than VLMs to compensate for the
> limited linguistic prowess of VLMs. However, these approaches are either
> resource-intensive or do not provide an interpretable reasoning process. In
> this paper, we present 'COCO-Tree' - a novel approach that augments VLM outputs
> with carefully designed neurosymbolic concept trees learned from LLMs to
> improve VLM's linguistic reasoning. COCO-Tree's beam search-inspired reasoning
> process boosts compositionality performance and provides a rationale behind VLM
> predictions. Empirical results on four compositionality benchmarks, Winoground,
> EqBench, ColorSwap, and SugarCrepe, in seven different open-source VLMs with
> varying sizes, demonstrate that COCO-Tree significantly improves compositional
> generalization by 5-10% over baselines.

