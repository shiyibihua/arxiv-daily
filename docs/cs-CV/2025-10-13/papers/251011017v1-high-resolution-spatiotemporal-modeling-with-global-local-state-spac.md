---
layout: default
title: High-Resolution Spatiotemporal Modeling with Global-Local State Space Models for Video-Based Human Pose Estimation
---

# High-Resolution Spatiotemporal Modeling with Global-Local State Space Models for Video-Based Human Pose Estimation

**arXiv**: [2510.11017v1](https://arxiv.org/abs/2510.11017) | [PDF](https://arxiv.org/pdf/2510.11017.pdf)

**ä½œè€…**: Runyang Feng, Hyung Jin Chang, Tze Ho Elden Tse, Boeun Kim, Yi Chang, Yixing Gao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå…¨å±€-å±€éƒ¨çŠ¶æ€ç©ºé—´æ¨¡åž‹ä»¥è§£å†³è§†é¢‘äººä½“å§¿æ€ä¼°è®¡ä¸­çš„é«˜åˆ†è¾¨çŽ‡æ—¶ç©ºå»ºæ¨¡é—®é¢˜**

**å…³é”®è¯**: `è§†é¢‘äººä½“å§¿æ€ä¼°è®¡` `çŠ¶æ€ç©ºé—´æ¨¡åž‹` `é«˜åˆ†è¾¨çŽ‡æ—¶ç©ºå»ºæ¨¡` `å…¨å±€-å±€éƒ¨åŠ¨æ€å»ºæ¨¡` `çº¿æ€§å¤æ‚åº¦` `Mambaæ‰©å±•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•éš¾ä»¥å¹³è¡¡å…¨å±€ä¸Žå±€éƒ¨åŠ¨æ€å»ºæ¨¡ï¼Œä¸”å…¨å±€ä¾èµ–æ•èŽ·å¤æ‚åº¦é«˜
2. æ‰©å±•Mambaæ¨¡åž‹ï¼Œåˆ†åˆ«è®¾è®¡å…¨å±€å’Œå±€éƒ¨æ¨¡å—ä»¥é«˜æ•ˆæå–æ—¶ç©ºè¡¨ç¤º
3. åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶å®žçŽ°æ›´å¥½çš„è®¡ç®—æƒè¡¡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Modeling high-resolution spatiotemporal representations, including both
> global dynamic contexts (e.g., holistic human motion tendencies) and local
> motion details (e.g., high-frequency changes of keypoints), is essential for
> video-based human pose estimation (VHPE). Current state-of-the-art methods
> typically unify spatiotemporal learning within a single type of modeling
> structure (convolution or attention-based blocks), which inherently have
> difficulties in balancing global and local dynamic modeling and may bias the
> network to one of them, leading to suboptimal performance. Moreover, existing
> VHPE models suffer from quadratic complexity when capturing global
> dependencies, limiting their applicability especially for high-resolution
> sequences. Recently, the state space models (known as Mamba) have demonstrated
> significant potential in modeling long-range contexts with linear complexity;
> however, they are restricted to 1D sequential data. In this paper, we present a
> novel framework that extends Mamba from two aspects to separately learn global
> and local high-resolution spatiotemporal representations for VHPE.
> Specifically, we first propose a Global Spatiotemporal Mamba, which performs 6D
> selective space-time scan and spatial- and temporal-modulated scan merging to
> efficiently extract global representations from high-resolution sequences. We
> further introduce a windowed space-time scan-based Local Refinement Mamba to
> enhance the high-frequency details of localized keypoint motions. Extensive
> experiments on four benchmark datasets demonstrate that the proposed model
> outperforms state-of-the-art VHPE approaches while achieving better
> computational trade-offs.

