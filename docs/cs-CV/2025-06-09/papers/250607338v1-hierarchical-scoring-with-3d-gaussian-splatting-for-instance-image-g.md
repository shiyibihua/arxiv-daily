---
layout: default
title: Hierarchical Scoring with 3D Gaussian Splatting for Instance Image-Goal Navigation
---

# Hierarchical Scoring with 3D Gaussian Splatting for Instance Image-Goal Navigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.07338" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.07338v1</a>
  <a href="https://arxiv.org/pdf/2506.07338.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.07338v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.07338v1', 'Hierarchical Scoring with 3D Gaussian Splatting for Instance Image-Goal Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yijie Deng, Shuaihang Yuan, Geeta Chandra Raju Bethala, Anthony Tzes, Yu-Shen Liu, Yi Fang

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-09

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå±‚æ¬¡è¯„åˆ†ä¸3Dé«˜æ–¯ç‚¹äº‘ä»¥è§£å†³å®ä¾‹å›¾åƒç›®æ ‡å¯¼èˆªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å®ä¾‹å›¾åƒå¯¼èˆª` `ä¸‰ç»´é«˜æ–¯ç‚¹äº‘` `å±‚æ¬¡è¯„åˆ†` `è¯­ä¹‰ç†è§£` `æœºå™¨äººå¯¼èˆª` `ç›®æ ‡è¯†åˆ«` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¾èµ–éšæœºé‡‡æ ·å¤šä¸ªè§†è§’ï¼Œå¯¼è‡´å†—ä½™çš„å›¾åƒæ ·æœ¬å’Œé«˜å¼€é”€ã€‚
2. æå‡ºäº†ä¸€ç§å±‚æ¬¡è¯„åˆ†æ¡†æ¶ï¼Œé€šè¿‡è¯­ä¹‰å’Œå‡ ä½•è¯„åˆ†ä¼˜åŒ–è§†è§’é€‰æ‹©ã€‚
3. åœ¨æ¨¡æ‹ŸIINåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½æ°´å¹³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å®ä¾‹å›¾åƒç›®æ ‡å¯¼èˆªï¼ˆIINï¼‰è¦æ±‚è‡ªä¸»ä»£ç†è¯†åˆ«å¹¶å¯¼èˆªè‡³å‚è€ƒå›¾åƒä¸­æç»˜çš„ç›®æ ‡å¯¹è±¡æˆ–ä½ç½®ã€‚å°½ç®¡è¿‘æœŸæ–¹æ³•åˆ©ç”¨äº†å¼ºå¤§çš„æ–°è§†è§’åˆæˆæŠ€æœ¯ï¼ˆNVSï¼‰ï¼Œå¦‚ä¸‰ç»´é«˜æ–¯ç‚¹äº‘ï¼ˆ3DGSï¼‰ï¼Œä½†é€šå¸¸ä¾èµ–éšæœºé‡‡æ ·å¤šä¸ªè§†è§’æˆ–è½¨è¿¹ä»¥ç¡®ä¿å¯¹åŒºåˆ†æ€§è§†è§‰çº¿ç´¢çš„å…¨é¢è¦†ç›–ã€‚è¿™ç§æ–¹æ³•å¯¼è‡´äº†é‡å å›¾åƒæ ·æœ¬çš„æ˜¾è‘—å†—ä½™ï¼Œå¹¶ç¼ºä¹åŸåˆ™æ€§çš„è§†è§’é€‰æ‹©ï¼Œæ˜¾è‘—å¢åŠ äº†æ¸²æŸ“å’Œæ¯”è¾ƒçš„å¼€é”€ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„IINæ¡†æ¶ï¼Œé‡‡ç”¨å±‚æ¬¡è¯„åˆ†èŒƒå¼æ¥ä¼°è®¡ç›®æ ‡åŒ¹é…çš„æœ€ä½³è§†è§’ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ•´åˆäº†è·¨å±‚è¯­ä¹‰è¯„åˆ†ï¼Œåˆ©ç”¨CLIPæ´¾ç”Ÿçš„ç›¸å…³æ€§åœºè¯†åˆ«ä¸ç›®æ ‡å¯¹è±¡ç±»åˆ«é«˜åº¦è¯­ä¹‰ç›¸ä¼¼çš„åŒºåŸŸï¼Œå¹¶é€šè¿‡ç²¾ç»†çš„å±€éƒ¨å‡ ä½•è¯„åˆ†åœ¨æœ‰å¸Œæœ›çš„åŒºåŸŸå†…è¿›è¡Œç²¾ç¡®çš„å§¿æ€ä¼°è®¡ã€‚å¹¿æ³›çš„è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¨¡æ‹ŸIINåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶å…·æœ‰å®é™…åº”ç”¨ä»·å€¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å®ä¾‹å›¾åƒç›®æ ‡å¯¼èˆªä¸­çš„è§†è§’é€‰æ‹©é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡éšæœºé‡‡æ ·è§†è§’ï¼Œå¯¼è‡´äº†å†—ä½™å’Œé«˜è®¡ç®—å¼€é”€ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºçš„å±‚æ¬¡è¯„åˆ†æ¡†æ¶é€šè¿‡ç»“åˆè¯­ä¹‰è¯„åˆ†å’Œå‡ ä½•è¯„åˆ†ï¼Œä¼˜åŒ–äº†ç›®æ ‡åŒ¹é…çš„è§†è§’é€‰æ‹©ï¼Œä»è€Œæé«˜äº†å¯¼èˆªæ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè·¨å±‚è¯­ä¹‰è¯„åˆ†æ¨¡å—å’Œå±€éƒ¨å‡ ä½•è¯„åˆ†æ¨¡å—ã€‚å‰è€…åˆ©ç”¨CLIPæ¨¡å‹æå–ç›®æ ‡ç±»åˆ«çš„ç›¸å…³æ€§ï¼Œåè€…åˆ™è¿›è¡Œç²¾ç¡®çš„å§¿æ€ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°åœ¨äºå¼•å…¥å±‚æ¬¡è¯„åˆ†æœºåˆ¶ï¼Œç»“åˆè¯­ä¹‰å’Œå‡ ä½•ä¿¡æ¯è¿›è¡Œè§†è§’é€‰æ‹©ï¼Œæ˜¾è‘—æå‡äº†å¯¼èˆªæ€§èƒ½ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå‡å°‘äº†å†—ä½™é‡‡æ ·ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†CLIPæ¨¡å‹ç”Ÿæˆç›¸å…³æ€§åœºï¼Œå¹¶é€šè¿‡æŸå¤±å‡½æ•°ä¼˜åŒ–è¯„åˆ†è¿‡ç¨‹ï¼Œç¡®ä¿åœ¨æœ‰å¸Œæœ›çš„åŒºåŸŸå†…è¿›è¡Œç²¾ç¡®çš„å§¿æ€ä¼°è®¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨æ¨¡æ‹ŸIINåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æå‡äº†çº¦15%çš„å¯¼èˆªæˆåŠŸç‡ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶å’Œå¢å¼ºç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡ä¼˜åŒ–è§†è§’é€‰æ‹©ï¼Œèƒ½å¤Ÿæé«˜è‡ªä¸»ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çš„ç›®æ ‡è¯†åˆ«å’Œå¯¼èˆªèƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Instance Image-Goal Navigation (IIN) requires autonomous agents to identify and navigate to a target object or location depicted in a reference image captured from any viewpoint. While recent methods leverage powerful novel view synthesis (NVS) techniques, such as three-dimensional Gaussian splatting (3DGS), they typically rely on randomly sampling multiple viewpoints or trajectories to ensure comprehensive coverage of discriminative visual cues. This approach, however, creates significant redundancy through overlapping image samples and lacks principled view selection, substantially increasing both rendering and comparison overhead. In this paper, we introduce a novel IIN framework with a hierarchical scoring paradigm that estimates optimal viewpoints for target matching. Our approach integrates cross-level semantic scoring, utilizing CLIP-derived relevancy fields to identify regions with high semantic similarity to the target object class, with fine-grained local geometric scoring that performs precise pose estimation within promising regions. Extensive evaluations demonstrate that our method achieves state-of-the-art performance on simulated IIN benchmarks and real-world applicability.

