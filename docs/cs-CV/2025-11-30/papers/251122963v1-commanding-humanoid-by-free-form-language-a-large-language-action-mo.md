---
layout: default
title: Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary
---

# Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary

**arXiv**: [2511.22963v1](https://arxiv.org/abs/2511.22963) | [PDF](https://arxiv.org/pdf/2511.22963.pdf)

**ä½œè€…**: Zhirui Liu, Kaiyang Ji, Ke Yang, Jingyi Yu, Ye Shi, Jingya Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHumanoid-LLAæ¨¡åž‹ï¼Œé€šè¿‡ç»Ÿä¸€è¿åŠ¨è¯æ±‡å’Œç‰©ç†æ„ŸçŸ¥å¾®è°ƒï¼Œå®žçŽ°äººå½¢æœºå™¨äººè‡ªç”±è¯­è¨€æŒ‡ä»¤çš„å…¨èº«æŽ§åˆ¶ã€‚**

**å…³é”®è¯**: `äººå½¢æœºå™¨äººæŽ§åˆ¶` `è¯­è¨€æŒ‡ä»¤æ‰§è¡Œ` `ç»Ÿä¸€è¿åŠ¨è¯æ±‡` `ç‰©ç†æ„ŸçŸ¥å¾®è°ƒ` `å¼ºåŒ–å­¦ä¹ ` `å…¨èº«åŠ¨ä½œç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•åœ¨è¯­è¨€æ¡ä»¶å…¨èº«æŽ§åˆ¶ä¸­ï¼Œå¸¸ç‰ºç‰²è¿åŠ¨å¤šæ ·æ€§æˆ–ç‰©ç†å¯è¡Œæ€§ï¼Œéš¾ä»¥å¤„ç†å¤æ‚æŒ‡ä»¤ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºç»Ÿä¸€è¿åŠ¨è¯æ±‡å¯¹é½äººç±»ä¸Žäººå½¢è¿åŠ¨åŸºå…ƒï¼Œç»“åˆè¯æ±‡å¯¼å‘æŽ§åˆ¶å™¨å’Œç‰©ç†æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ å¾®è°ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä»¿çœŸå’ŒçœŸå®žUnitree G1æœºå™¨äººä¸Šè¯„ä¼°ï¼Œæ˜¾ç¤ºå¼ºè¯­è¨€æ³›åŒ–èƒ½åŠ›ï¼Œè¿åŠ¨è‡ªç„¶æ€§ã€ç¨³å®šæ€§å’ŒæˆåŠŸçŽ‡ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Enabling humanoid robots to follow free-form language commands is critical for seamless human-robot interaction, collaborative task execution, and general-purpose embodied intelligence. While recent advances have improved low-level humanoid locomotion and robot manipulation, language-conditioned whole-body control remains a significant challenge. Existing methods are often limited to simple instructions and sacrifice either motion diversity or physical plausibility. To address this, we introduce Humanoid-LLA, a Large Language Action Model that maps expressive language commands to physically executable whole-body actions for humanoid robots. Our approach integrates three core components: a unified motion vocabulary that aligns human and humanoid motion primitives into a shared discrete space; a vocabulary-directed controller distilled from a privileged policy to ensure physical feasibility; and a physics-informed fine-tuning stage using reinforcement learning with dynamics-aware rewards to enhance robustness and stability. Extensive evaluations in simulation and on a real-world Unitree G1 humanoid show that Humanoid-LLA delivers strong language generalization while maintaining high physical fidelity, outperforming existing language-conditioned controllers in motion naturalness, stability, and execution success rate.

