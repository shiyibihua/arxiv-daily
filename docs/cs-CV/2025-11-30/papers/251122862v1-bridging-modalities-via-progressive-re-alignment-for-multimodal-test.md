---
layout: default
title: Bridging Modalities via Progressive Re-alignment for Multimodal Test-Time Adaptation
---

# Bridging Modalities via Progressive Re-alignment for Multimodal Test-Time Adaptation

**arXiv**: [2511.22862v1](https://arxiv.org/abs/2511.22862) | [PDF](https://arxiv.org/pdf/2511.22862.pdf)

**ä½œè€…**: Jiacheng Li, Songhe Feng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBriMPRæ¡†æž¶ä»¥è§£å†³å¤šæ¨¡æ€æµ‹è¯•æ—¶é€‚åº”ä¸­çš„æ¨¡æ€è€¦åˆæ•ˆåº”é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `æµ‹è¯•æ—¶é€‚åº”` `ç‰¹å¾å¯¹é½` `æç¤ºè°ƒè°` `å¯¹æ¯”å­¦ä¹ ` `åŸŸåç§»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€åœºæ™¯ä¸­ï¼Œå•æ¨¡æ€æµ…å±‚ç‰¹å¾åç§»ä¸Žè·¨æ¨¡æ€é«˜å±‚è¯­ä¹‰é”™ä½çš„è€¦åˆæ•ˆåº”é˜»ç¢æµ‹è¯•æ—¶é€‚åº”æ‰©å±•ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åˆ†æ²»ç­–ç•¥ï¼Œå…ˆé€šè¿‡æç¤ºè°ƒè°æ ¡å‡†å•æ¨¡æ€å…¨å±€ç‰¹å¾åˆ†å¸ƒï¼Œå†å¼•å…¥è·¨æ¨¡æ€å®žä¾‹å¯¹æ¯”å­¦ä¹ å¢žå¼ºä¿¡æ¯äº¤äº’ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŸºäºŽæŸåå’ŒçœŸå®žåŸŸåç§»åŸºå‡†çš„MMTTAä»»åŠ¡ä¸Šï¼Œå®žéªŒè¯æ˜Žäº†æ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Test-time adaptation (TTA) enables online model adaptation using only unlabeled test data, aiming to bridge the gap between source and target distributions. However, in multimodal scenarios, varying degrees of distribution shift across different modalities give rise to a complex coupling effect of unimodal shallow feature shift and cross-modal high-level semantic misalignment, posing a major obstacle to extending existing TTA methods to the multimodal field. To address this challenge, we propose a novel multimodal test-time adaptation (MMTTA) framework, termed as Bridging Modalities via Progressive Re-alignment (BriMPR). BriMPR, consisting of two progressively enhanced modules, tackles the coupling effect with a divide-and-conquer strategy. Specifically, we first decompose MMTTA into multiple unimodal feature alignment sub-problems. By leveraging the strong function approximation ability of prompt tuning, we calibrate the unimodal global feature distributions to their respective source distributions, so as to achieve the initial semantic re-alignment across modalities. Subsequently, we assign the credible pseudo-labels to combinations of masked and complete modalities, and introduce inter-modal instance-wise contrastive learning to further enhance the information interaction among modalities and refine the alignment. Extensive experiments on MMTTA tasks, including both corruption-based and real-world domain shift benchmarks, demonstrate the superiority of our method. Our source code is available at [this URL](https://github.com/Luchicken/BriMPR).

