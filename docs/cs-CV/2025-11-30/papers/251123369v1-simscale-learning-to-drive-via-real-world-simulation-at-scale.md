---
layout: default
title: SimScale: Learning to Drive via Real-World Simulation at Scale
---

# SimScale: Learning to Drive via Real-World Simulation at Scale

**arXiv**: [2511.23369v1](https://arxiv.org/abs/2511.23369) | [PDF](https://arxiv.org/pdf/2511.23369.pdf)

**ä½œè€…**: Haochen Tian, Tianyu Li, Haochen Liu, Jiazhi Yang, Yihang Qiu, Guang Li, Junli Wang, Yinfeng Gao, Zhang Zhang, Liang Wang, Hangjun Ye, Tieniu Tan, Long Chen, Hongyang Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSimScaleæ¡†æž¶ï¼Œé€šè¿‡å¤§è§„æ¨¡çœŸå®žä¸–ç•Œæ¨¡æ‹Ÿå¢žå¼ºè‡ªåŠ¨é©¾é©¶å†³ç­–çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶æ¨¡æ‹Ÿ` `ç¥žç»æ¸²æŸ“` `ä¼ªä¸“å®¶è½¨è¿¹` `ååŒè®­ç»ƒ` `æ•°æ®å¢žå¼º` `è§„åˆ’æ–¹æ³•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçœŸå®žé©¾é©¶æ•°æ®ç¼ºä¹å¤šæ ·æ€§å’Œå®‰å…¨å…³é”®åœºæ™¯ï¼Œé™åˆ¶è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿå†³ç­–å­¦ä¹ ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨ç¥žç»æ¸²æŸ“å’Œååº”å¼çŽ¯å¢ƒç”Ÿæˆé«˜ä¿çœŸæ¨¡æ‹Ÿæ•°æ®ï¼Œå¹¶è®¾è®¡ä¼ªä¸“å®¶è½¨è¿¹æä¾›åŠ¨ä½œç›‘ç£ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žåŸºå‡†æµ‹è¯•ä¸­ï¼Œé€šè¿‡ååŒè®­ç»ƒæ˜¾è‘—æå‡è§„åˆ’æ–¹æ³•æ€§èƒ½ï¼Œä¸”ä»…å¢žåŠ æ¨¡æ‹Ÿæ•°æ®å³å¯å¹³æ»‘æ‰©å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Achieving fully autonomous driving systems requires learning rational decisions in a wide span of scenarios, including safety-critical and out-of-distribution ones. However, such cases are underrepresented in real-world corpus collected by human experts. To complement for the lack of data diversity, we introduce a novel and scalable simulation framework capable of synthesizing massive unseen states upon existing driving logs. Our pipeline utilizes advanced neural rendering with a reactive environment to generate high-fidelity multi-view observations controlled by the perturbed ego trajectory. Furthermore, we develop a pseudo-expert trajectory generation mechanism for these newly simulated states to provide action supervision. Upon the synthesized data, we find that a simple co-training strategy on both real-world and simulated samples can lead to significant improvements in both robustness and generalization for various planning methods on challenging real-world benchmarks, up to +6.8 EPDMS on navhard and +2.9 on navtest. More importantly, such policy improvement scales smoothly by increasing simulation data only, even without extra real-world data streaming in. We further reveal several crucial findings of such a sim-real learning system, which we term SimScale, including the design of pseudo-experts and the scaling properties for different policy architectures. Our simulation data and code would be released.

