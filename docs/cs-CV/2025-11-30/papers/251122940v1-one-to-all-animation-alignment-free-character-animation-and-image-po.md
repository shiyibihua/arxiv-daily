---
layout: default
title: One-to-All Animation: Alignment-Free Character Animation and Image Pose Transfe
---

# One-to-All Animation: Alignment-Free Character Animation and Image Pose Transfe

**arXiv**: [2511.22940v1](https://arxiv.org/abs/2511.22940) | [PDF](https://arxiv.org/pdf/2511.22940.pdf)

**ä½œè€…**: Shijun Shi, Jing Xu, Zhihang Li, Chunli Peng, Xiaoda Yang, Lijing Lu, Kai Hu, Jiangning Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOne-to-All Animationæ¡†æž¶ï¼Œä»¥è§£å†³å‚è€ƒå§¿æ€ç©ºé—´ä¸å¯¹é½çš„è§’è‰²åŠ¨ç”»ä¸Žå§¿æ€è¿ç§»é—®é¢˜ã€‚**

**å…³é”®è¯**: `è§’è‰²åŠ¨ç”»` `å§¿æ€è¿ç§»` `æ‰©æ•£æ¨¡åž‹` `è‡ªç›‘ç£å­¦ä¹ ` `é•¿è§†é¢‘ç”Ÿæˆ` `å‚è€ƒå¯¹é½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•ä¾èµ–ç©ºé—´å¯¹é½çš„å‚è€ƒ-å§¿æ€å¯¹ï¼Œæ— æ³•å¤„ç†å¸ƒå±€ä»»æ„æˆ–éƒ¨åˆ†å¯è§çš„å‚è€ƒã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡è‡ªç›‘ç£å¤–ç»˜ä»»åŠ¡ç»Ÿä¸€è¾“å…¥æ ¼å¼ï¼Œè®¾è®¡å‚è€ƒæå–å™¨ä¸Žæ··åˆèžåˆæ³¨æ„åŠ›ï¼Œå¹¶å¼•å…¥èº«ä»½é²æ£’å§¿æ€æŽ§åˆ¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¹¿æ³›å®žéªŒä¸­ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œæ”¯æŒé«˜ä¿çœŸåŠ¨ç”»ä¸Žé•¿è§†é¢‘ç”Ÿæˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in diffusion models have greatly improved pose-driven character animation. However, existing methods are limited to spatially aligned reference-pose pairs with matched skeletal structures. Handling reference-pose misalignment remains unsolved. To address this, we present One-to-All Animation, a unified framework for high-fidelity character animation and image pose transfer for references with arbitrary layouts. First, to handle spatially misaligned reference, we reformulate training as a self-supervised outpainting task that transforms diverse-layout reference into a unified occluded-input format. Second, to process partially visible reference, we design a reference extractor for comprehensive identity feature extraction. Further, we integrate hybrid reference fusion attention to handle varying resolutions and dynamic sequence lengths. Finally, from the perspective of generation quality, we introduce identity-robust pose control that decouples appearance from skeletal structure to mitigate pose overfitting, and a token replace strategy for coherent long-video generation. Extensive experiments show that our method outperforms existing approaches. The code and model will be available at https://github.com/ssj9596/One-to-All-Animation.

