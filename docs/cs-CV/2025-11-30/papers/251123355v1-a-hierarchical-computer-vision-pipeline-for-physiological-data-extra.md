---
layout: default
title: A Hierarchical Computer Vision Pipeline for Physiological Data Extraction from Bedside Monitors
---

# A Hierarchical Computer Vision Pipeline for Physiological Data Extraction from Bedside Monitors

**arXiv**: [2511.23355v1](https://arxiv.org/abs/2511.23355) | [PDF](https://arxiv.org/pdf/2511.23355.pdf)

**ä½œè€…**: Vinh Chau, Khoa Le Dinh Van, Hon Huynh Ngoc, Binh Nguyen Thien, Hao Nguyen Thien, Vy Nguyen Quang, Phuc Vo Hong, Yen Lam Minh, Kieu Pham Tieu, Trinh Nguyen Thi Diem, Louise Thwaites, Hai Ho Bich

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè®¡ç®—æœºè§†è§‰çš„å±‚æ¬¡åŒ–ç®¡é“ï¼Œä»ŽåºŠè¾¹ç›‘æŠ¤ä»ªå±å¹•è‡ªåŠ¨æå–ç”Ÿç†æ•°æ®ä»¥è§£å†³ä½Žèµ„æºåŒ»ç–—çŽ¯å¢ƒçš„æ•°æ®é›†æˆé—®é¢˜ã€‚**

**å…³é”®è¯**: `è®¡ç®—æœºè§†è§‰` `ç”Ÿç†æ•°æ®æå–` `åºŠè¾¹ç›‘æŠ¤ä»ª` `å…‰å­¦å­—ç¬¦è¯†åˆ«` `ä½Žèµ„æºåŒ»ç–—` `å±‚æ¬¡åŒ–æ£€æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä½Žèµ„æºåŒ»ç–—çŽ¯å¢ƒä¸­ï¼ŒåºŠè¾¹ç›‘æŠ¤ä»ªç¼ºä¹ç½‘ç»œè¿žæŽ¥ï¼Œå¯¼è‡´ç”Ÿç†æ•°æ®éš¾ä»¥é›†æˆåˆ°ç”µå­å¥åº·è®°å½•ç³»ç»Ÿã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨YOLOv11è¿›è¡Œç›‘æŠ¤ä»ªå’Œæ„Ÿå…´è¶£åŒºåŸŸå®šä½ï¼Œç»“åˆPaddleOCRè¿›è¡Œæ–‡æœ¬æå–ï¼Œå¹¶é€šè¿‡å‡ ä½•æ ¡æ­£æ¨¡å—æå‡é²æ£’æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨6,498å¼ å›¾åƒæ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œç›‘æŠ¤ä»ªæ£€æµ‹mAP@50-95è¾¾99.5%ï¼Œç«¯åˆ°ç«¯æå–æ ¸å¿ƒå‚æ•°å‡†ç¡®çŽ‡è¶…è¿‡98.9%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In many low-resource healthcare settings, bedside monitors remain standalone legacy devices without network connectivity, creating a persistent interoperability gap that prevents seamless integration of physiological data into electronic health record (EHR) systems. To address this challenge without requiring costly hardware replacement, we present a computer vision-based pipeline for the automated capture and digitisation of vital sign data directly from bedside monitor screens. Our method employs a hierarchical detection framework combining YOLOv11 for accurate monitor and region of interest (ROI) localisation with PaddleOCR for robust text extraction. To enhance reliability across variable camera angles and lighting conditions, a geometric rectification module standardizes the screen perspective before character recognition. We evaluated the system on a dataset of 6,498 images collected from open-source corpora and real-world intensive care units in Vietnam. The model achieved a mean Average Precision (mAP@50-95) of 99.5% for monitor detection and 91.5% for vital sign ROI localisation. The end-to-end extraction accuracy exceeded 98.9% for core physiological parameters, including heart rate, oxygen saturation SpO2, and arterial blood pressure. These results demonstrate that a lightweight, camera-based approach can reliably transform unstructured information from screen captures into structured digital data, providing a practical and scalable pathway to improve information accessibility and clinical documentation in low-resource settings.

