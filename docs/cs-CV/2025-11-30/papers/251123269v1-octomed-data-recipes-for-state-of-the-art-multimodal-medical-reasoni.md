---
layout: default
title: OctoMed: Data Recipes for State-of-the-Art Multimodal Medical Reasoning
---

# OctoMed: Data Recipes for State-of-the-Art Multimodal Medical Reasoning

**arXiv**: [2511.23269v1](https://arxiv.org/abs/2511.23269) | [PDF](https://arxiv.org/pdf/2511.23269.pdf)

**ä½œè€…**: Timothy Ossowski, Sheng Zhang, Qianchu Liu, Guanghui Qin, Reuben Tan, Tristan Naumann, Junjie Hu, Hoifung Poon

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOctoMedæ•°æ®é…æ–¹ï¼Œé€šè¿‡ç»“æž„åŒ–æŽ¨ç†è½¨è¿¹æå‡åŒ»ç–—å¤šæ¨¡æ€æŽ¨ç†æ¨¡åž‹çš„æ³›åŒ–ä¸Žé²æ£’æ€§ã€‚**

**å…³é”®è¯**: `åŒ»ç–—å¤šæ¨¡æ€æŽ¨ç†` `æ•°æ®ç­–å±•` `ç»“æž„åŒ–æŽ¨ç†è½¨è¿¹` `ç›‘ç£å¾®è°ƒ` `æ³›åŒ–èƒ½åŠ›` `é²æ£’æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé«˜è´¨é‡æ•°æ®å¯¹åŒ»ç–—å¤§è¯­è¨€æ¨¡åž‹çš„æ³›åŒ–å’Œé²æ£’æ€§è‡³å…³é‡è¦ï¼Œéœ€ä¼˜åŒ–è®­ç»ƒä¸Žæ•°æ®ç­–å±•ç­–ç•¥ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ç›‘ç£å¾®è°ƒï¼Œè®¾è®¡æ•°æ®é…æ–¹åˆ©ç”¨ç»“æž„åŒ–æŽ¨ç†è½¨è¿¹ï¼Œç­–å±•å¤šæ ·è®­ç»ƒæ•°æ®é›†ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨è¶…800ä¸‡æ ·æœ¬æ•°æ®é›†ä¸Šå®žçŽ°å¼€æºæ¨¡åž‹ä¸­çš„æœ€å…ˆè¿›æ€§èƒ½ï¼Œæ¨¡åž‹èƒ½è‡ªæ ¡å‡†æŽ¨ç†è½¨è¿¹é•¿åº¦ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> High-quality and carefully curated data is a cornerstone of training medical large language models, as it directly impacts both generalization and robustness to unseen clinical tasks. We investigate strategies for training and data curation to develop a robust multimodal reasoning model in the medical domain. Our work focuses on supervised fine-tuning (SFT) and explores data recipes that leverage structured reasoning traces. Using our proposed data recipe, we scale experiments to a dataset of over 8 million examples and 6.8 billion response tokens, achieving state-of-the-art performance among open-source models across diverse out-of-distribution medical benchmark tasks. Our results further indicate that curating a high-quality, diverse training dataset with varying structured reasoning trace lengths enables the fine-tuned model to self-calibrate its reasoning trajectory lengths based on the downstream task, without explicit supervision. We present key insights, describe the data curation strategy, and outline next steps toward developing robust medical vision-language reasoning system.

