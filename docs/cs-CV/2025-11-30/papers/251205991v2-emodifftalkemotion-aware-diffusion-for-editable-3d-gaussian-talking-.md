---
layout: default
title: EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head
---

# EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.05991" target="_blank" class="toolbar-btn">arXiv: 2512.05991v2</a>
    <a href="https://arxiv.org/pdf/2512.05991.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.05991v2" 
            onclick="toggleFavorite(this, '2512.05991v2', 'EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Chang Liu, Tianjiao Jing, Chengcheng Ma, Xuanqi Zhou, Zhengxuan Lian, Qin Jin, Hongliang Yuan, Shi-Sheng Huang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-30 (Êõ¥Êñ∞: 2025-12-10)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**EmoDiffTalkÔºöÊèêÂá∫ÊÉÖÊÑüÊÑüÁü•Êâ©Êï£Ê®°ÂûãÔºåÁî®‰∫éÂèØÁºñËæëÁöÑ3DÈ´òÊñØËØ¥ËØùÂ§¥ÁîüÊàê„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `3DËØ¥ËØùÂ§¥ÁîüÊàê` `È´òÊñØÊ∫ÖÂ∞Ñ` `Êâ©Êï£Ê®°Âûã` `ÊÉÖÊÑüÊÑüÁü•` `Âä®‰ΩúÂçïÂÖÉ` `Â§öÊ®°ÊÄÅÁºñËæë` `ÊñáÊú¨Âà∞AU` `ÂèØÁºñËæëÊÄß`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂü∫‰∫é3DÈ´òÊñØÊ∫ÖÂ∞ÑÁöÑÈÄºÁúüËØ¥ËØùÂ§¥Âú®ÊÉÖÊÑüË°®ËææÊìçÊéßÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÂú®‰ΩøÁî®Â§öÊ®°ÊÄÅÊéßÂà∂ËøõË°åÁªÜÁ≤íÂ∫¶ÂíåÂπøÊ≥õÁöÑÂä®ÊÄÅÊÉÖÊÑüÁºñËæëÊó∂„ÄÇ
2. EmoDiffTalkÊèêÂá∫‰∫Ü‰∏ÄÁßçÊÉÖÊÑüÊÑüÁü•È´òÊñØÊâ©Êï£ÊñπÊ≥ïÔºåÈÄöËøáÂä®‰ΩúÂçïÂÖÉÔºàAUÔºâÊèêÁ§∫ÂíåÊñáÊú¨Âà∞AUÊÉÖÊÑüÊéßÂà∂Âô®ÔºåÂÆûÁé∞Á≤æÁªÜÁöÑÊÉÖÊÑüÊéßÂà∂ÂíåÁºñËæë„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEmoDiffTalkÂú®ÊÉÖÊÑüË°®ËææÁöÑÂæÆÂ¶ôÊÄß„ÄÅÂè£ÂûãÂêåÊ≠•ÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÊéßÊÄßÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊäÄÊúØÔºå‰∏∫È´òË¥®Èáè3DËØ¥ËØùÂ§¥ÂêàÊàêÊèê‰æõ‰∫ÜÊñ∞ÈÄîÂæÑ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂèØÁºñËæë3DÈ´òÊñØËØ¥ËØùÂ§¥Ê°ÜÊû∂ÔºåÂêç‰∏∫EmoDiffTalk„ÄÇÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂºïÂÖ•‰∏ÄÁßçÊÉÖÊÑüÊÑüÁü•È´òÊñØÊâ©Êï£ÊñπÊ≥ïÔºåÂåÖÊã¨Áî®‰∫éÁ≤æÁªÜÈù¢ÈÉ®Âä®ÁîªÊéßÂà∂ÁöÑÂä®‰ΩúÂçïÂÖÉÔºàAUÔºâÊèêÁ§∫È´òÊñØÊâ©Êï£ËøáÁ®ãÔºå‰ª•Âèä‰∏Ä‰∏™Á≤æÁ°ÆÁöÑÊñáÊú¨Âà∞AUÊÉÖÊÑüÊéßÂà∂Âô®Ôºå‰ªéËÄåÂÆûÁé∞‰ΩøÁî®ÊñáÊú¨ËæìÂÖ•ËøõË°åÂáÜÁ°ÆÂíåÂπøÊ≥õÁöÑÂä®ÊÄÅÊÉÖÊÑüÁºñËæë„ÄÇÂú®ÂÖ¨ÂÖ±EmoTalk3DÂíåRenderMe-360Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåEmoDiffTalkÂú®ÊÉÖÊÑüÂæÆÂ¶ôÊÄß„ÄÅÂè£ÂûãÂêåÊ≠•‰øùÁúüÂ∫¶ÂíåÂèØÊéßÊÄßÊñπÈù¢‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºå‰∏∫È´òË¥®Èáè„ÄÅÊâ©Êï£È©±Âä®„ÄÅÂ§öÊ®°ÊÄÅÂèØÁºñËæë3DËØ¥ËØùÂ§¥ÂêàÊàêÂª∫Á´ã‰∫Ü‰∏ÄÊù°ÊúâÊïàÈÄîÂæÑ„ÄÇÊçÆÊàë‰ª¨ÊâÄÁü•ÔºåEmoDiffTalkÊòØÈ¶ñÊâπÊîØÊåÅÂü∫‰∫éAUË°®ÊÉÖÁ©∫Èó¥ËøõË°åËøûÁª≠„ÄÅÂ§öÊ®°ÊÄÅÊÉÖÊÑüÁºñËæëÁöÑ3DÈ´òÊñØÊ∫ÖÂ∞ÑËØ¥ËØùÂ§¥ÁîüÊàêÊ°ÜÊû∂‰πã‰∏Ä„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞Êúâ3DËØ¥ËØùÂ§¥ÁîüÊàêÊñπÊ≥ïÔºåÁâπÂà´ÊòØÂü∫‰∫é3DÈ´òÊñØÊ∫ÖÂ∞ÑÁöÑÊñπÊ≥ïÔºåÂú®ÊÉÖÊÑüË°®ËææÁöÑÁ≤æÁªÜÊéßÂà∂ÂíåÂ§öÊ®°ÊÄÅÊÉÖÊÑüÁºñËæëÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄß„ÄÇÈöæ‰ª•ÂÆûÁé∞ÁªÜÁ≤íÂ∫¶ÁöÑÊÉÖÊÑüÊìçÊéßÔºåÂπ∂‰∏îÁº∫‰πèÈÄöËøáÊñáÊú¨Á≠âÊ®°ÊÄÅËøõË°åÂπøÊ≥õÊÉÖÊÑüÁºñËæëÁöÑËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöEmoDiffTalkÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Êâ©Êï£Ê®°ÂûãÁîüÊàêÂÖ∑ÊúâÊÉÖÊÑüË°®ËææÁöÑ3DÈ´òÊñØËØ¥ËØùÂ§¥„ÄÇÈÄöËøáÂ∞ÜÂä®‰ΩúÂçïÂÖÉÔºàAUÔºâ‰Ωú‰∏∫Êâ©Êï£ËøáÁ®ãÁöÑÊèêÁ§∫ÔºåÂπ∂ÁªìÂêàÊñáÊú¨Âà∞AUÁöÑÊÉÖÊÑüÊéßÂà∂Âô®ÔºåÂÆûÁé∞ÂØπÊÉÖÊÑüÁöÑÁ≤æÁ°ÆÊéßÂà∂ÂíåÁºñËæë„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÁîüÊàêÊõ¥Ëá™ÁÑ∂„ÄÅÊõ¥ÂØåÊúâË°®Áé∞ÂäõÁöÑËØ¥ËØùÂ§¥„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöEmoDiffTalkÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) 3DÈ´òÊñØÊ∫ÖÂ∞ÑË°®Á§∫Ê®°ÂùóÔºåÁî®‰∫éË°®Á§∫3DËØ¥ËØùÂ§¥Ôºõ2) Âä®‰ΩúÂçïÂÖÉÔºàAUÔºâÊèêÁ§∫È´òÊñØÊâ©Êï£Ê®°ÂùóÔºåÁî®‰∫éÁîüÊàêÂÖ∑ÊúâÁâπÂÆöAUË°®ÊÉÖÁöÑ3DÈ´òÊñØÂèÇÊï∞Ôºõ3) ÊñáÊú¨Âà∞AUÊÉÖÊÑüÊéßÂà∂Âô®ÔºåÁî®‰∫éÂ∞ÜÊñáÊú¨ÊÉÖÊÑü‰ø°ÊÅØËΩ¨Êç¢‰∏∫AUÂèÇÊï∞Ôºõ4) Ê∏≤ÊüìÊ®°ÂùóÔºåÁî®‰∫éÂ∞Ü3DÈ´òÊñØÂèÇÊï∞Ê∏≤ÊüìÊàêÂõæÂÉè„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØ‰ªéÊñáÊú¨ËæìÂÖ•ÂºÄÂßãÔºåÈÄöËøáÊÉÖÊÑüÊéßÂà∂Âô®ÁîüÊàêAUÂèÇÊï∞ÔºåÁÑ∂ÂêéÂà©Áî®AUÊèêÁ§∫È´òÊñØÊâ©Êï£Ê®°ÂùóÁîüÊàê3DÈ´òÊñØÂèÇÊï∞ÔºåÊúÄÂêéÊ∏≤ÊüìÂæóÂà∞ËØ¥ËØùÂ§¥ÂõæÂÉè„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöEmoDiffTalkÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊÉÖÊÑüÊÑüÁü•È´òÊñØÊâ©Êï£ÊñπÊ≥ïÔºåÂÆÉÂ∞ÜÂä®‰ΩúÂçïÂÖÉÔºàAUÔºâ‰Ωú‰∏∫Êâ©Êï£ËøáÁ®ãÁöÑÊèêÁ§∫ÔºåÂπ∂ÁªìÂêàÊñáÊú¨Âà∞AUÁöÑÊÉÖÊÑüÊéßÂà∂Âô®ÔºåÂÆûÁé∞‰∫ÜÂØπÊÉÖÊÑüÁöÑÁ≤æÁªÜÊéßÂà∂ÂíåÁºñËæë„ÄÇÊ≠§Â§ñÔºåËØ•Ê°ÜÊû∂ÊòØÈ¶ñÊâπÊîØÊåÅÂü∫‰∫éAUË°®ÊÉÖÁ©∫Èó¥ËøõË°åËøûÁª≠„ÄÅÂ§öÊ®°ÊÄÅÊÉÖÊÑüÁºñËæëÁöÑ3DÈ´òÊñØÊ∫ÖÂ∞ÑËØ¥ËØùÂ§¥ÁîüÊàêÊ°ÜÊû∂‰πã‰∏Ä„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®AUÊèêÁ§∫È´òÊñØÊâ©Êï£Ê®°Âùó‰∏≠Ôºå‰ΩøÁî®‰∫ÜÂô™Â£∞È¢ÑÊµãÁΩëÁªúÊù•È¢ÑÊµãÂô™Â£∞ÔºåÂπ∂ÈÄöËøáËø≠‰ª£ÂéªÂô™ËøáÁ®ãÁîüÊàê3DÈ´òÊñØÂèÇÊï∞„ÄÇÊñáÊú¨Âà∞AUÊÉÖÊÑüÊéßÂà∂Âô®ÈááÁî®TransformerÁªìÊûÑÔºåÂ∞ÜÊñáÊú¨ÊÉÖÊÑü‰ø°ÊÅØÊò†Â∞ÑÂà∞AUÂèÇÊï∞„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÈáçÂª∫ÊçüÂ§±„ÄÅAUÊçüÂ§±ÂíåÂØπÊäóÊçüÂ§±ÔºåÁî®‰∫é‰øùËØÅÁîüÊàêÂõæÂÉèÁöÑË¥®Èáè„ÄÅAUË°®ÊÉÖÁöÑÂáÜÁ°ÆÊÄßÂíåÁîüÊàêÁªìÊûúÁöÑÁúüÂÆûÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

EmoDiffTalkÂú®EmoTalk3DÂíåRenderMe-360Êï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEmoDiffTalkÂú®ÊÉÖÊÑüÂæÆÂ¶ôÊÄß„ÄÅÂè£ÂûãÂêåÊ≠•‰øùÁúüÂ∫¶ÂíåÂèØÊéßÊÄßÊñπÈù¢‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÂ∞§ÂÖ∂ÊòØÂú®ÊÉÖÊÑüÁºñËæëÊñπÈù¢ÔºåEmoDiffTalkËÉΩÂ§üÁîüÊàêÊõ¥Ëá™ÁÑ∂„ÄÅÊõ¥ÂØåÊúâË°®Áé∞ÂäõÁöÑËØ¥ËØùÂ§¥ÔºåÂπ∂‰∏îËÉΩÂ§üÈÄöËøáÊñáÊú¨ËæìÂÖ•ËøõË°åÁ≤æÁ°ÆÁöÑÊÉÖÊÑüÊéßÂà∂„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

EmoDiffTalkÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨ËôöÊãüÁé∞ÂÆû„ÄÅÂ¢ûÂº∫Áé∞ÂÆû„ÄÅÊ∏∏Êàè„ÄÅÁîµÂΩ±Âà∂‰Ωú„ÄÅÂú®Á∫øÊïôËÇ≤ÂíåËôöÊãüÂä©ÊâãÁ≠âÈ¢ÜÂüü„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÂàõÂª∫Êõ¥ÈÄºÁúü„ÄÅÊõ¥ÂÖ∑Ë°®Áé∞ÂäõÁöÑËôöÊãüËßíËâ≤ÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™å„ÄÇÊ≠§Â§ñÔºåËØ•ÊäÄÊúØËøòÂèØ‰ª•Â∫îÁî®‰∫éÊÉÖÊÑüÂàÜÊûêÂíåÊÉÖÊÑüËÆ°ÁÆóÁ≠âÁ†îÁ©∂È¢ÜÂüüÔºåÂ∏ÆÂä©ÁêÜËß£ÂíåÊ®°Êãü‰∫∫Á±ªÊÉÖÊÑü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent photo-realistic 3D talking head via 3D Gaussian Splatting still has significant shortcoming in emotional expression manipulation, especially for fine-grained and expansive dynamics emotional editing using multi-modal control. This paper introduces a new editable 3D Gaussian talking head, i.e. EmoDiffTalk. Our key idea is a novel Emotion-aware Gaussian Diffusion, which includes an action unit (AU) prompt Gaussian diffusion process for fine-grained facial animator, and moreover an accurate text-to-AU emotion controller to provide accurate and expansive dynamic emotional editing using text input. Experiments on public EmoTalk3D and RenderMe-360 datasets demonstrate superior emotional subtlety, lip-sync fidelity, and controllability of our EmoDiffTalk over previous works, establishing a principled pathway toward high-quality, diffusion-driven, multimodal editable 3D talking-head synthesis. To our best knowledge, our EmoDiffTalk is one of the first few 3D Gaussian Splatting talking-head generation framework, especially supporting continuous, multimodal emotional editing within the AU-based expression space.

