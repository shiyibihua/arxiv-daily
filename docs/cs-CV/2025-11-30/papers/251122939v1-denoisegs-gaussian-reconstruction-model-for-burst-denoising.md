---
layout: default
title: DenoiseGS: Gaussian Reconstruction Model for Burst Denoising
---

# DenoiseGS: Gaussian Reconstruction Model for Burst Denoising

**arXiv**: [2511.22939v1](https://arxiv.org/abs/2511.22939) | [PDF](https://arxiv.org/pdf/2511.22939.pdf)

**ä½œè€…**: Yongsen Cheng, Yuanhao Cai, Yulun Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDenoiseGSæ¡†æž¶ï¼Œåˆ©ç”¨3Dé«˜æ–¯æº…å°„é«˜æ•ˆå¤„ç†æ‰‹æŒè®¾å¤‡æ‹æ‘„çš„çªå‘åŽ»å™ªé—®é¢˜ã€‚**

**å…³é”®è¯**: `çªå‘åŽ»å™ª` `3Dé«˜æ–¯æº…å°„` `é«˜æ–¯è‡ªä¸€è‡´æ€§æŸå¤±` `logåŠ æƒé¢‘çŽ‡æŸå¤±` `æ–°è§†è§’åˆæˆ` `é«˜æ•ˆæŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçªå‘åŽ»å™ªæ–¹æ³•åœ¨å¤§è¿åŠ¨æˆ–é«˜è®¡ç®—æˆæœ¬ä¸‹è¡¨çŽ°ä¸ä½³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥é«˜æ–¯è‡ªä¸€è‡´æ€§æŸå¤±å’ŒlogåŠ æƒé¢‘çŽ‡æŸå¤±ï¼Œæå‡å™ªå£°è¾“å…¥ä¸‹çš„é‡å»ºè´¨é‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çªå‘åŽ»å™ªå’Œå™ªå£°æ¡ä»¶ä¸‹çš„æ–°è§†è§’åˆæˆä¸­è¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼ŒæŽ¨ç†é€Ÿåº¦æå‡250å€ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Burst denoising methods are crucial for enhancing images captured on handheld devices, but they often struggle with large motion or suffer from prohibitive computational costs. In this paper, we propose DenoiseGS, the first framework to leverage the efficiency of 3D Gaussian Splatting for burst denoising. Our approach addresses two key challenges when applying feedforward Gaussian reconsturction model to noisy inputs: the degradation of Gaussian point clouds and the loss of fine details. To this end, we propose a Gaussian self-consistency (GSC) loss, which regularizes the geometry predicted from noisy inputs with high-quality Gaussian point clouds. These point clouds are generated from clean inputs by the same model that we are training, thereby alleviating potential bias or domain gaps. Additionally, we introduce a log-weighted frequency (LWF) loss to strengthen supervision within the spectral domain, effectively preserving fine-grained details. The LWF loss adaptively weights frequency discrepancies in a logarithmic manner, emphasizing challenging high-frequency details. Extensive experiments demonstrate that DenoiseGS significantly exceeds the state-of-the-art NeRF-based methods on both burst denoising and novel view synthesis under noisy conditions, while achieving \textbf{250$\times$} faster inference speed. Code and models are released at https://github.com/yscheng04/DenoiseGS.

