---
layout: default
title: Analyzing Image Beyond Visual Aspect: Image Emotion Classification via Multiple-Affective Captioning
---

# Analyzing Image Beyond Visual Aspect: Image Emotion Classification via Multiple-Affective Captioning

**arXiv**: [2511.23115v1](https://arxiv.org/abs/2511.23115) | [PDF](https://arxiv.org/pdf/2511.23115.pdf)

**ä½œè€…**: Zibo Zhou, Zhengjun Zhai, Huimin Chen, Wei Dai, Hansen Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå¤šæƒ…æ„Ÿæè¿°çš„å›¾åƒæƒ…æ„Ÿåˆ†ç±»æ–¹æ³•ï¼Œä»¥è§£å†³æƒ…æ„Ÿé¸¿æ²Ÿé—®é¢˜ã€‚**

**å…³é”®è¯**: `å›¾åƒæƒ…æ„Ÿåˆ†ç±»` `æƒ…æ„Ÿé¸¿æ²Ÿ` `å¤šæƒ…æ„Ÿæè¿°` `å¯¹æ¯”å­¦ä¹ ` `è¯­è¨€æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå›¾åƒæƒ…æ„Ÿåˆ†ç±»å—æƒ…æ„Ÿé¸¿æ²Ÿé™åˆ¶ï¼Œé¢„è®­ç»ƒè§†è§‰æ¨¡åž‹çŸ¥è¯†åº”ç”¨å—é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å±‚æ¬¡åŒ–å¯¹æ¯”æŸå¤±æ£€æµ‹æƒ…æ„Ÿæ¦‚å¿µï¼Œç»“åˆæƒ…æ„Ÿå±žæ€§é“¾å¼æŽ¨ç†ç”Ÿæˆæè¿°ï¼Œåˆ©ç”¨è¯­è¨€æ¨¡åž‹åˆ†ç±»ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—ä¼˜å¼‚ç»“æžœï¼Œæœ‰æ•ˆæ¡¥æŽ¥æƒ…æ„Ÿé¸¿æ²Ÿã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Image emotion classification (IEC) is a longstanding research field that has received increasing attention with the rapid progress of deep learning. Although recent advances have leveraged the knowledge encoded in pre-trained visual models, their effectiveness is constrained by the "affective gap" , limits the applicability of pre-training knowledge for IEC tasks. It has been demonstrated in psychology that language exhibits high variability, encompasses diverse and abundant information, and can effectively eliminate the "affective gap". Inspired by this, we propose a novel Affective Captioning for Image Emotion Classification (ACIEC) to classify image emotion based on pure texts, which effectively capture the affective information in the image. In our method, a hierarchical multi-level contrastive loss is designed for detecting emotional concepts from images, while an emotional attribute chain-of-thought reasoning is proposed to generate affective sentences. Then, a pre-trained language model is leveraged to synthesize emotional concepts and affective sentences to conduct IEC. Additionally, a contrastive loss based on semantic similarity sampling is designed to solve the problem of large intra-class differences and small inter-class differences in affective datasets. Moreover, we also take the images with embedded texts into consideration, which were ignored by previous studies. Extensive experiments illustrate that our method can effectively bridge the affective gap and achieve superior results on multiple benchmarks.

