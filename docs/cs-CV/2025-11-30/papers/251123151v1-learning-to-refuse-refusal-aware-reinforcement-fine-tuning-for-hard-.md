---
layout: default
title: Learning to Refuse: Refusal-Aware Reinforcement Fine-Tuning for Hard-Irrelevant Queries in Video Temporal Grounding
---

# Learning to Refuse: Refusal-Aware Reinforcement Fine-Tuning for Hard-Irrelevant Queries in Video Temporal Grounding

**arXiv**: [2511.23151v1](https://arxiv.org/abs/2511.23151) | [PDF](https://arxiv.org/pdf/2511.23151.pdf)

**ä½œè€…**: Jin-Seop Lee, SungJoon Lee, SeongJun Jung, Boyang Li, Jee-Hyong Lee

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ‹’ç»æ„ŸçŸ¥å¼ºåŒ–å¾®è°ƒæ–¹æ³•ä»¥è§£å†³è§†é¢‘æ—¶åºå®šä½ä¸­ç¡¬æ— å…³æŸ¥è¯¢çš„æ‹’ç»é—®é¢˜**

**å…³é”®è¯**: `è§†é¢‘æ—¶åºå®šä½` `å¼ºåŒ–å­¦ä¹ å¾®è°ƒ` `æ‹’ç»æ„ŸçŸ¥` `ç¡¬æ— å…³æŸ¥è¯¢` `è¯­ä¹‰æŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†é¢‘æ—¶åºå®šä½æ¨¡åž‹å‡è®¾æŸ¥è¯¢æ€»æ˜¯ç›¸å…³ï¼Œå¯¼è‡´å¯¹æ— å…³æŸ¥è¯¢ä¹Ÿé¢„æµ‹ç‰‡æ®µï¼Œå°¤å…¶éš¾ä»¥å¤„ç†è¯­ä¹‰ç›¸ä¼¼ä½†å®žé™…æ— å…³çš„ç¡¬æ— å…³æŸ¥è¯¢ã€‚
2. åŸºäºŽGRPOæ¡†æž¶ï¼Œé›†æˆæ ¼å¼ã€æ‹’ç»IoUã€è§£é‡Šå’ŒæŸ¥è¯¢ä¿®æ­£å››ä¸ªå¥–åŠ±ç›®æ ‡ï¼Œæå‡ç›¸å…³æ€§åˆ¤åˆ«å’Œç»†ç²’åº¦è¯­ä¹‰æŽ¨ç†èƒ½åŠ›ã€‚
3. æž„å»ºç¡¬æ— å…³è§†é¢‘æ—¶åºå®šä½æ•°æ®é›†ï¼Œå¹¶åœ¨å¤šç§ç›¸å…³æ„ŸçŸ¥åœºæ™¯ä¸­éªŒè¯æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå±•ç¤ºå…¶å¯æ‰©å±•æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video Temporal Grounding (VTG) aims to localize a temporal segment in a video corresponding to a natural language query. However, existing VTG models assume that a relevant segment always exists, causing them to always predict a target segment even when the query is irrelevant to the video. While recent approaches attempt to handle irrelevant queries, they can only reject those that are entirely unrelated to the video and still fail to handle hard-irrelevant queries that are semantically similar but not actually relevant. To address this, we propose Refusal-Aware Reinforcement Fine-Tuning (RA-RFT) to effectively refuse hard-irrelevant queries in VTG. Our method is based on the Group Relative Policy Optimization (GRPO) framework and integrates four reward objectives-format, refuse-IoU, explain, and query correction-to improve both relevance discrimination and fine-grained semantic reasoning. In addition, to effectively support RA-RFT, we construct a Hard-Irrelevant VTG (HI-VTG) dataset, which includes hard-irrelevant queries and their refusal answers. We demonstrate the effectiveness of our method across various relevance-aware VTG scenarios, including hard-irrelevant VTG, simply-shuffled RA-VTG, and human-annotated RA-VTG settings. We also show that the proposed method is scalable by applying it to various LVLM-based VTG models. Our code is available at https://github.com/JINSUBY/RA-RFT.

