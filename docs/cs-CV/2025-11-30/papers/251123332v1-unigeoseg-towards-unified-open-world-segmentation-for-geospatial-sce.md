---
layout: default
title: UniGeoSeg: Towards Unified Open-World Segmentation for Geospatial Scenes
---

# UniGeoSeg: Towards Unified Open-World Segmentation for Geospatial Scenes

**arXiv**: [2511.23332v1](https://arxiv.org/abs/2511.23332) | [PDF](https://arxiv.org/pdf/2511.23332.pdf)

**ä½œè€…**: Shuo Ni, Di Wang, He Chen, Haonan Guo, Ning Zhang, Jing Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUniGeoSegç»Ÿä¸€æ¡†æž¶ï¼Œè§£å†³é¥æ„ŸæŒ‡ä»¤é©±åŠ¨åˆ†å‰²ä»»åŠ¡ç¢Žç‰‡åŒ–å’Œæ•°æ®ä¸è¶³é—®é¢˜ã€‚**

**å…³é”®è¯**: `é¥æ„Ÿå›¾åƒåˆ†å‰²` `æŒ‡ä»¤é©±åŠ¨å­¦ä¹ ` `å¤šä»»åŠ¡å­¦ä¹ ` `é›¶æ ·æœ¬æ³›åŒ–` `å¤§è§„æ¨¡æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰é¥æ„ŸæŒ‡ä»¤é©±åŠ¨åˆ†å‰²æ–¹æ³•ä»»åŠ¡ç¢Žç‰‡åŒ–ä¸”æ•°æ®æœ‰é™ï¼Œé˜»ç¢ç†è§£å’Œæ³›åŒ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºGeoSeg-1Mç™¾ä¸‡çº§æ•°æ®é›†ï¼Œå¹¶è®¾è®¡UniGeoSegæ¡†æž¶ï¼Œé›†æˆä»»åŠ¡æ„ŸçŸ¥æ–‡æœ¬å¢žå¼ºå’Œæ¸è¿›è®­ç»ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨GeoSeg-Benchå’Œå…¬å…±åŸºå‡†ä¸Šå®žçŽ°å…ˆè¿›æ€§èƒ½ï¼Œå±•ç¤ºå¼ºé›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Instruction-driven segmentation in remote sensing generates masks from guidance, offering great potential for accessible and generalizable applications. However, existing methods suffer from fragmented task formulations and limited instruction data, hindering effective understanding and generalization. To address these issues, we introduce GeoSeg-1M, the first million-scale dataset for remote sensing instruction-driven segmentation, constructed via an automatic mask filtering and instruction generation pipeline that synthesizes referring, interactive, and reasoning segmentation instructions from multiple public datasets. GeoSeg-1M contains 590K images, 117 categories, and 1.1M image-mask-instruction triplets. Building upon this foundation, we further curate GeoSeg-Bench, a challenging benchmark designed to evaluate contextual understanding and reasoning capabilities across diverse instruction-driven tasks and complex geospatial scenes. Furthermore, we present UniGeoSeg, a unified framework that serves as a strong baseline, incorporating task-aware text enhancement, latent knowledge memory, and a progressive training strategy to facilitate multi-task learning. Extensive experiments demonstrate the state-of-the-art performance of UniGeoSeg across GeoSeg-Bench and diverse public benchmarks, while exhibiting strong zero-shot generalization. Datasets and source code were released at https://github.com/MiliLab/UniGeoSeg.

