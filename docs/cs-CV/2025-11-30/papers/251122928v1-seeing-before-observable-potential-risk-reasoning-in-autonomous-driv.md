---
layout: default
title: Seeing before Observable: Potential Risk Reasoning in Autonomous Driving via Vision Language Models
---

# Seeing before Observable: Potential Risk Reasoning in Autonomous Driving via Vision Language Models

**arXiv**: [2511.22928v1](https://arxiv.org/abs/2511.22928) | [PDF](https://arxiv.org/pdf/2511.22928.pdf)

**ä½œè€…**: Jiaxin Liu, Xiangyu Yan, Liang Peng, Lei Yang, Lingjun Zhang, Yuechen Luo, Yueming Tao, Ashton Yu Xuan Tan, Mu Li, Lei Zhang, Ziqi Zhan, Sai Guo, Hong Wang, Jun Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPotentialRiskQAæ•°æ®é›†å’ŒPR-Reasoneræ¡†æž¶ï¼Œä»¥è§£å†³è‡ªåŠ¨é©¾é©¶ä¸­æ½œåœ¨é£Žé™©æŽ¨ç†é—®é¢˜ã€‚**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶å®‰å…¨` `æ½œåœ¨é£Žé™©æŽ¨ç†` `è§†è§‰è¯­è¨€æ¨¡åž‹` `æ•°æ®é›†æž„å»º` `è¯­ä¹‰ç†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‡ªåŠ¨é©¾é©¶åœ¨ç½•è§å¤æ‚åœºæ™¯ä¸­ï¼Œéš¾ä»¥è¯†åˆ«æœªè§‚å¯Ÿåˆ°çš„æ½œåœ¨é£Žé™©ï¼Œå¦‚åŸºäºŽç»†å¾®å‰å…†çš„æŽ¨ç†ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºPotentialRiskQAè§†è§‰è¯­è¨€æ•°æ®é›†ï¼ŒåŒ…å«ç»“æž„åŒ–åœºæ™¯æè¿°ã€è¯­ä¹‰å‰å…†å’Œé£Žé™©ç»“æžœæ ‡æ³¨ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåŸºäºŽæ•°æ®é›†å¾®è°ƒPR-Reasonerï¼Œç›¸æ¯”åŸºçº¿è§†è§‰è¯­è¨€æ¨¡åž‹ï¼Œæ˜¾è‘—æå‡æ½œåœ¨é£Žé™©æŽ¨ç†æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Ensuring safety remains a key challenge for autonomous vehicles (AVs), especially in rare and complex scenarios. One critical but understudied aspect is the \textbf{potential risk} situations, where the risk is \textbf{not yet observable} but can be inferred from subtle precursors, such as anomalous behaviors or commonsense violations. Recognizing these precursors requires strong semantic understanding and reasoning capabilities, which are often absent in current AV systems due to the scarcity of such cases in existing driving or risk-centric datasets. Moreover, current autonomous driving accident datasets often lack annotations of the causal reasoning chains behind incidents, which are essential for identifying potential risks before they become observable. To address these gaps, we introduce PotentialRiskQA, a novel vision-language dataset designed for reasoning about potential risks prior to observation. Each sample is annotated with structured scene descriptions, semantic precursors, and inferred risk outcomes. Based on this dataset, we further propose PR-Reasoner, a vision-language-model-based framework tailored for onboard potential risk reasoning. Experimental results show that fine-tuning on PotentialRiskQA enables PR-Reasoner to significantly enhance its performance on the potential risk reasoning task compared to baseline VLMs. Together, our dataset and model provide a foundation for developing autonomous systems with improved foresight and proactive safety capabilities, moving toward more intelligent and resilient AVs.

