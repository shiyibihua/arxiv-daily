---
layout: default
title: Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction
---

# Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction

**arXiv**: [2512.00960v2](https://arxiv.org/abs/2512.00960) | [PDF](https://arxiv.org/pdf/2512.00960.pdf)

**ä½œè€…**: Boran Wen, Ye Lu, Keyan Wan, Sirui Wang, Jiahong Zhou, Junxuan Liang, Xinpeng Liu, Bang Xiao, Dingbang Huang, Ruiyang Liu, Yong-Lu Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-30 (æ›´æ–°: 2025-12-06)

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://wenboran2002.github.io/open4dhoi/)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡º4DHOISolveræ¡†æž¶ï¼Œç»“åˆäººå·¥æ ‡æ³¨ï¼Œé«˜æ•ˆé‡å»ºå•ç›®è§†é¢‘ä¸­çš„äºº-ç‰©äº¤äº’è¿åŠ¨ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸Žååº” (Interaction & Reaction)**

**å…³é”®è¯**: `äºº-ç‰©äº¤äº’` `4Dé‡å»º` `å•ç›®è§†é¢‘` `è¿åŠ¨æ•æ‰` `å¼ºåŒ–å­¦ä¹ ` `æ•°æ®é›†` `æŽ¥è§¦ç‚¹æ ‡æ³¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä»Žå•ç›®è§†é¢‘ä¸­å‡†ç¡®ä¸”å¯æ‰©å±•åœ°æå–4Däºº-ç‰©äº¤äº’æ•°æ®ä»ç„¶æ˜¯ä¸€ä¸ªæœªè§£å†³çš„éš¾é¢˜ï¼Œé˜»ç¢äº†æœºå™¨äººä»Žäº’è”ç½‘è§†é¢‘ä¸­å­¦ä¹ ã€‚
2. è®ºæ–‡æå‡ºäº†4DHOISolveræ¡†æž¶ï¼Œé€šè¿‡ç»“åˆç¨€ç–çš„äººå·¥æŽ¥è§¦ç‚¹æ ‡æ³¨ï¼Œçº¦æŸ4D HOIé‡å»ºé—®é¢˜ï¼Œä¿è¯æ—¶ç©ºä¸€è‡´æ€§å’Œç‰©ç†åˆç†æ€§ã€‚
3. æž„å»ºäº†å¤§è§„æ¨¡4D HOIæ•°æ®é›†Open4DHOIï¼Œå¹¶éªŒè¯äº†é‡å»ºç»“æžœåœ¨å¼ºåŒ–å­¦ä¹ æ¨¡ä»¿ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼ŒåŒæ—¶æŒ‡å‡ºçŽ°æœ‰3Dæ¨¡åž‹åœ¨æŽ¥è§¦é¢„æµ‹æ–¹é¢çš„ä¸è¶³ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†ä½¿é€šç”¨æœºå™¨äººèƒ½å¤Ÿä»Žå¤šæ ·åŒ–ã€å¤§è§„æ¨¡çš„äºº-ç‰©äº¤äº’(HOI)ä¸­å­¦ä¹ ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–é«˜æ•ˆçš„ä¼˜åŒ–æ¡†æž¶4DHOISolverï¼Œç”¨äºŽçº¦æŸç—…æ€çš„4D HOIé‡å»ºé—®é¢˜ã€‚è¯¥æ¡†æž¶åˆ©ç”¨ç¨€ç–çš„äººå·¥æŽ¥è§¦ç‚¹æ ‡æ³¨ï¼ŒåŒæ—¶ä¿æŒé«˜æ—¶ç©ºä¸€è‡´æ€§å’Œç‰©ç†åˆç†æ€§ã€‚åŸºäºŽæ­¤æ¡†æž¶ï¼Œæž„å»ºäº†ä¸€ä¸ªæ–°çš„å¤§è§„æ¨¡4D HOIæ•°æ®é›†Open4DHOIï¼ŒåŒ…å«144ç§ç‰©ä½“ç±»åž‹å’Œ103ç§åŠ¨ä½œã€‚å®žéªŒè¡¨æ˜Žï¼Œé‡å»ºç»“æžœèƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒåŸºäºŽå¼ºåŒ–å­¦ä¹ çš„æ™ºèƒ½ä½“æ¨¡ä»¿ã€‚ç„¶è€Œï¼Œå¯¹çŽ°æœ‰3DåŸºç¡€æ¨¡åž‹çš„å…¨é¢è¯„ä¼°è¡¨æ˜Žï¼Œè‡ªåŠ¨é¢„æµ‹ç²¾ç¡®çš„äºº-ç‰©æŽ¥è§¦å¯¹åº”å…³ç³»ä»ç„¶æ˜¯ä¸€ä¸ªæœªè§£å†³çš„é—®é¢˜ï¼Œçªæ˜¾äº†äººå·¥å‚ä¸Žç­–ç•¥çš„å¿…è¦æ€§ï¼Œå¹¶ä¸ºç¤¾åŒºæå‡ºäº†ä¸€ä¸ªå¼€æ”¾çš„æŒ‘æˆ˜ã€‚æ•°æ®å’Œä»£ç å°†åœ¨æŒ‡å®šç½‘å€å…¬å¼€ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰æ–¹æ³•éš¾ä»¥ä»Žå•ç›®è§†é¢‘ä¸­å‡†ç¡®ä¸”å¯æ‰©å±•åœ°é‡å»º4Däºº-ç‰©äº¤äº’ï¼ˆHOIï¼‰è¿åŠ¨ã€‚ä¸»è¦ç—›ç‚¹åœ¨äºŽï¼šå•ç›®è§†è§‰çš„å›ºæœ‰æ­§ä¹‰æ€§å¯¼è‡´é‡å»ºç»“æžœä¸å‡†ç¡®ï¼Œç¼ºä¹å¤§è§„æ¨¡é«˜è´¨é‡çš„4D HOIæ•°æ®é›†ï¼Œä»¥åŠè‡ªåŠ¨é¢„æµ‹ç²¾ç¡®çš„äºº-ç‰©æŽ¥è§¦å¯¹åº”å…³ç³»ä»ç„¶æ˜¯ä¸€ä¸ªæœªè§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ç¨€ç–çš„äººå·¥æŽ¥è§¦ç‚¹æ ‡æ³¨æ¥çº¦æŸ4D HOIé‡å»ºè¿‡ç¨‹ï¼Œä»Žè€Œè§£å†³å•ç›®è§†è§‰çš„æ­§ä¹‰æ€§é—®é¢˜ã€‚äººå·¥æ ‡æ³¨æä¾›å…³é”®çš„äº¤äº’ä¿¡æ¯ï¼Œå¸®åŠ©ä¼˜åŒ–ç®—æ³•æ‰¾åˆ°æ›´å‡†ç¡®çš„è§£ã€‚åŒæ—¶ï¼Œé€šè¿‡ä¼˜åŒ–æ¡†æž¶ä¿è¯é‡å»ºç»“æžœçš„æ—¶ç©ºä¸€è‡´æ€§å’Œç‰©ç†åˆç†æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼š4DHOISolveræ¡†æž¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) è§†é¢‘è¾“å…¥å’Œé¢„å¤„ç†ï¼šä»Žå•ç›®è§†é¢‘ä¸­æå–äººä½“å’Œç‰©ä½“çš„2D/3Dä¿¡æ¯ã€‚2) äººå·¥æŽ¥è§¦ç‚¹æ ‡æ³¨ï¼šäººå·¥æ ‡æ³¨è§†é¢‘å¸§ä¸­äººä¸Žç‰©ä½“çš„æŽ¥è§¦ç‚¹ã€‚3) ä¼˜åŒ–æ¡†æž¶ï¼šåˆ©ç”¨äººå·¥æ ‡æ³¨çš„æŽ¥è§¦ç‚¹ä½œä¸ºçº¦æŸï¼Œä¼˜åŒ–äººä½“å’Œç‰©ä½“çš„4Då§¿æ€ï¼ŒåŒæ—¶ä¿è¯æ—¶ç©ºä¸€è‡´æ€§å’Œç‰©ç†åˆç†æ€§ã€‚4) è¿åŠ¨é‡å»ºï¼šè¾“å‡ºé‡å»ºçš„4D HOIè¿åŠ¨åºåˆ—ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽç»“åˆäº†äººå·¥æ ‡æ³¨å’Œä¼˜åŒ–æ¡†æž¶ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†å•ç›®4D HOIé‡å»ºçš„ç—…æ€é—®é¢˜ã€‚ä¸Žå®Œå…¨ä¾èµ–è‡ªåŠ¨ç®—æ³•çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤ŸèŽ·å¾—æ›´å‡†ç¡®ã€æ›´å¯é çš„é‡å»ºç»“æžœã€‚æ­¤å¤–ï¼Œæž„å»ºäº†å¤§è§„æ¨¡çš„Open4DHOIæ•°æ®é›†ï¼Œä¸ºç›¸å…³ç ”ç©¶æä¾›äº†å®è´µçš„æ•°æ®èµ„æºã€‚

**å…³é”®è®¾è®¡**ï¼šæ¡†æž¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç¨€ç–æŽ¥è§¦ç‚¹æ ‡æ³¨ç­–ç•¥ï¼šåªéœ€è¦å°‘é‡çš„äººå·¥æ ‡æ³¨å³å¯æœ‰æ•ˆçº¦æŸé‡å»ºè¿‡ç¨‹ã€‚2) æ—¶ç©ºä¸€è‡´æ€§æŸå¤±ï¼šä¿è¯é‡å»ºç»“æžœåœ¨æ—¶é—´ä¸Šçš„å¹³æ»‘æ€§å’Œä¸€è‡´æ€§ã€‚3) ç‰©ç†åˆç†æ€§æŸå¤±ï¼šä¿è¯é‡å»ºç»“æžœç¬¦åˆç‰©ç†è§„å¾‹ï¼Œä¾‹å¦‚é¿å…ç©¿é€ç­‰ã€‚4) ä¼˜åŒ–ç®—æ³•ï¼šé€‰æ‹©åˆé€‚çš„ä¼˜åŒ–ç®—æ³•ï¼Œä¾‹å¦‚åŸºäºŽæ¢¯åº¦çš„ä¼˜åŒ–æ–¹æ³•ï¼Œä»¥æœ€å°åŒ–æŸå¤±å‡½æ•°å¹¶èŽ·å¾—æœ€ä¼˜çš„é‡å»ºç»“æžœã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è®ºæ–‡æž„å»ºäº†åŒ…å«144ç§ç‰©ä½“ç±»åž‹å’Œ103ç§åŠ¨ä½œçš„å¤§è§„æ¨¡4D HOIæ•°æ®é›†Open4DHOIã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œä½¿ç”¨4DHOISolveré‡å»ºçš„è¿åŠ¨æ•°æ®èƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒåŸºäºŽå¼ºåŒ–å­¦ä¹ çš„æ™ºèƒ½ä½“æ¨¡ä»¿ä»»åŠ¡ï¼ŒéªŒè¯äº†é‡å»ºç»“æžœçš„æœ‰æ•ˆæ€§ã€‚åŒæ—¶ï¼Œè®ºæ–‡å¯¹çŽ°æœ‰3DåŸºç¡€æ¨¡åž‹è¿›è¡Œäº†è¯„ä¼°ï¼Œå‘çŽ°å…¶åœ¨è‡ªåŠ¨é¢„æµ‹ç²¾ç¡®çš„äºº-ç‰©æŽ¥è§¦å¯¹åº”å…³ç³»æ–¹é¢ä»ç„¶å­˜åœ¨ä¸è¶³ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæœºå™¨äººå­¦ä¹ ã€è™šæ‹ŸçŽ°å®žã€äººæœºäº¤äº’ç­‰é¢†åŸŸã€‚é€šè¿‡å­¦ä¹ äººç±»ä¸Žç‰©ä½“çš„äº¤äº’æ–¹å¼ï¼Œæœºå™¨äººå¯ä»¥æ›´å¥½åœ°ç†è§£å’Œæ¨¡ä»¿äººç±»è¡Œä¸ºï¼Œä»Žè€Œåœ¨å¤æ‚çŽ¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡ã€‚é‡å»ºçš„4D HOIæ•°æ®å¯ä»¥ç”¨äºŽè®­ç»ƒæœºå™¨äººæŽ§åˆ¶ç­–ç•¥ï¼Œæé«˜æœºå™¨äººçš„æ“ä½œæŠ€èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ç”¨äºŽåˆ›å»ºé€¼çœŸçš„è™šæ‹ŸçŽ°å®žä½“éªŒï¼Œä¾‹å¦‚æ¨¡æ‹Ÿäººç±»æ“ä½œç‰©ä½“çš„è¿‡ç¨‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generalized robots must learn from diverse, large-scale human-object interactions (HOI) to operate robustly in the real world. Monocular internet videos offer a nearly limitless and readily available source of data, capturing an unparalleled diversity of human activities, objects, and environments. However, accurately and scalably extracting 4D interaction data from these in-the-wild videos remains a significant and unsolved challenge. Thus, in this work, we introduce 4DHOISolver, a novel and efficient optimization framework that constrains the ill-posed 4D HOI reconstruction problem by leveraging sparse, human-in-the-loop contact point annotations, while maintaining high spatio-temporal coherence and physical plausibility. Leveraging this framework, we introduce Open4DHOI, a new large-scale 4D HOI dataset featuring a diverse catalog of 144 object types and 103 actions. Furthermore, we demonstrate the effectiveness of our reconstructions by enabling an RL-based agent to imitate the recovered motions. However, a comprehensive benchmark of existing 3D foundation models indicates that automatically predicting precise human-object contact correspondences remains an unsolved problem, underscoring the immediate necessity of our human-in-the-loop strategy while posing an open challenge to the community. Data and code will be publicly available at https://wenboran2002.github.io/open4dhoi/

