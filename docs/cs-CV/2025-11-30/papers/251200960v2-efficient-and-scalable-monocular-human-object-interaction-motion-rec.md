---
layout: default
title: Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction
---

# Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.00960" target="_blank" class="toolbar-btn">arXiv: 2512.00960v2</a>
    <a href="https://arxiv.org/pdf/2512.00960.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.00960v2" 
            onclick="toggleFavorite(this, '2512.00960v2', 'Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Boran Wen, Ye Lu, Keyan Wan, Sirui Wang, Jiahong Zhou, Junxuan Liang, Xinpeng Liu, Bang Xiao, Dingbang Huang, Ruiyang Liu, Yong-Lu Li

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-30 (Êõ¥Êñ∞: 2025-12-06)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://wenboran2002.github.io/open4dhoi/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫4DHOISolverÊ°ÜÊû∂ÔºåÁªìÂêà‰∫∫Â∑•Ê†áÊ≥®ÔºåÈ´òÊïàÈáçÂª∫ÂçïÁõÆËßÜÈ¢ë‰∏≠ÁöÑ‰∫∫-Áâ©‰∫§‰∫íËøêÂä®„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫îÔºö‰∫§‰∫í‰∏éÂèçÂ∫î (Interaction & Reaction)**

**ÂÖ≥ÈîÆËØç**: `‰∫∫-Áâ©‰∫§‰∫í` `4DÈáçÂª∫` `ÂçïÁõÆËßÜÈ¢ë` `ËøêÂä®ÊçïÊçâ` `Âº∫ÂåñÂ≠¶‰π†` `Êï∞ÊçÆÈõÜ` `Êé•Ëß¶ÁÇπÊ†áÊ≥®`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰ªéÂçïÁõÆËßÜÈ¢ë‰∏≠ÂáÜÁ°Æ‰∏îÂèØÊâ©Â±ïÂú∞ÊèêÂèñ4D‰∫∫-Áâ©‰∫§‰∫íÊï∞ÊçÆ‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™Êú™Ëß£ÂÜ≥ÁöÑÈöæÈ¢òÔºåÈòªÁ¢ç‰∫ÜÊú∫Âô®‰∫∫‰ªé‰∫íËÅîÁΩëËßÜÈ¢ë‰∏≠Â≠¶‰π†„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∫Ü4DHOISolverÊ°ÜÊû∂ÔºåÈÄöËøáÁªìÂêàÁ®ÄÁñèÁöÑ‰∫∫Â∑•Êé•Ëß¶ÁÇπÊ†áÊ≥®ÔºåÁ∫¶Êùü4D HOIÈáçÂª∫ÈóÆÈ¢òÔºå‰øùËØÅÊó∂Á©∫‰∏ÄËá¥ÊÄßÂíåÁâ©ÁêÜÂêàÁêÜÊÄß„ÄÇ
3. ÊûÑÂª∫‰∫ÜÂ§ßËßÑÊ®°4D HOIÊï∞ÊçÆÈõÜOpen4DHOIÔºåÂπ∂È™åËØÅ‰∫ÜÈáçÂª∫ÁªìÊûúÂú®Âº∫ÂåñÂ≠¶‰π†Ê®°‰ªø‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÂêåÊó∂ÊåáÂá∫Áé∞Êúâ3DÊ®°ÂûãÂú®Êé•Ëß¶È¢ÑÊµãÊñπÈù¢ÁöÑ‰∏çË∂≥„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∏∫‰∫Ü‰ΩøÈÄöÁî®Êú∫Âô®‰∫∫ËÉΩÂ§ü‰ªéÂ§öÊ†∑Âåñ„ÄÅÂ§ßËßÑÊ®°ÁöÑ‰∫∫-Áâ©‰∫§‰∫í(HOI)‰∏≠Â≠¶‰π†ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÈ´òÊïàÁöÑ‰ºòÂåñÊ°ÜÊû∂4DHOISolverÔºåÁî®‰∫éÁ∫¶ÊùüÁóÖÊÄÅÁöÑ4D HOIÈáçÂª∫ÈóÆÈ¢ò„ÄÇËØ•Ê°ÜÊû∂Âà©Áî®Á®ÄÁñèÁöÑ‰∫∫Â∑•Êé•Ëß¶ÁÇπÊ†áÊ≥®ÔºåÂêåÊó∂‰øùÊåÅÈ´òÊó∂Á©∫‰∏ÄËá¥ÊÄßÂíåÁâ©ÁêÜÂêàÁêÜÊÄß„ÄÇÂü∫‰∫éÊ≠§Ê°ÜÊû∂ÔºåÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÂ§ßËßÑÊ®°4D HOIÊï∞ÊçÆÈõÜOpen4DHOIÔºåÂåÖÂê´144ÁßçÁâ©‰ΩìÁ±ªÂûãÂíå103ÁßçÂä®‰Ωú„ÄÇÂÆûÈ™åË°®ÊòéÔºåÈáçÂª∫ÁªìÊûúËÉΩÂ§üÊúâÊïàÊîØÊåÅÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÊô∫ËÉΩ‰ΩìÊ®°‰ªø„ÄÇÁÑ∂ËÄåÔºåÂØπÁé∞Êúâ3DÂü∫Á°ÄÊ®°ÂûãÁöÑÂÖ®Èù¢ËØÑ‰º∞Ë°®ÊòéÔºåËá™Âä®È¢ÑÊµãÁ≤æÁ°ÆÁöÑ‰∫∫-Áâ©Êé•Ëß¶ÂØπÂ∫îÂÖ≥Á≥ª‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™Êú™Ëß£ÂÜ≥ÁöÑÈóÆÈ¢òÔºåÁ™ÅÊòæ‰∫Ü‰∫∫Â∑•ÂèÇ‰∏éÁ≠ñÁï•ÁöÑÂøÖË¶ÅÊÄßÔºåÂπ∂‰∏∫Á§æÂå∫ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÂºÄÊîæÁöÑÊåëÊàò„ÄÇÊï∞ÊçÆÂíå‰ª£Á†ÅÂ∞ÜÂú®ÊåáÂÆöÁΩëÂùÄÂÖ¨ÂºÄ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•‰ªéÂçïÁõÆËßÜÈ¢ë‰∏≠ÂáÜÁ°Æ‰∏îÂèØÊâ©Â±ïÂú∞ÈáçÂª∫4D‰∫∫-Áâ©‰∫§‰∫íÔºàHOIÔºâËøêÂä®„ÄÇ‰∏ªË¶ÅÁóõÁÇπÂú®‰∫éÔºöÂçïÁõÆËßÜËßâÁöÑÂõ∫ÊúâÊ≠ß‰πâÊÄßÂØºËá¥ÈáçÂª∫ÁªìÊûú‰∏çÂáÜÁ°ÆÔºåÁº∫‰πèÂ§ßËßÑÊ®°È´òË¥®ÈáèÁöÑ4D HOIÊï∞ÊçÆÈõÜÔºå‰ª•ÂèäËá™Âä®È¢ÑÊµãÁ≤æÁ°ÆÁöÑ‰∫∫-Áâ©Êé•Ëß¶ÂØπÂ∫îÂÖ≥Á≥ª‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™Êú™Ëß£ÂÜ≥ÁöÑÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Á®ÄÁñèÁöÑ‰∫∫Â∑•Êé•Ëß¶ÁÇπÊ†áÊ≥®Êù•Á∫¶Êùü4D HOIÈáçÂª∫ËøáÁ®ãÔºå‰ªéËÄåËß£ÂÜ≥ÂçïÁõÆËßÜËßâÁöÑÊ≠ß‰πâÊÄßÈóÆÈ¢ò„ÄÇ‰∫∫Â∑•Ê†áÊ≥®Êèê‰æõÂÖ≥ÈîÆÁöÑ‰∫§‰∫í‰ø°ÊÅØÔºåÂ∏ÆÂä©‰ºòÂåñÁÆóÊ≥ïÊâæÂà∞Êõ¥ÂáÜÁ°ÆÁöÑËß£„ÄÇÂêåÊó∂ÔºåÈÄöËøá‰ºòÂåñÊ°ÜÊû∂‰øùËØÅÈáçÂª∫ÁªìÊûúÁöÑÊó∂Á©∫‰∏ÄËá¥ÊÄßÂíåÁâ©ÁêÜÂêàÁêÜÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**Ôºö4DHOISolverÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) ËßÜÈ¢ëËæìÂÖ•ÂíåÈ¢ÑÂ§ÑÁêÜÔºö‰ªéÂçïÁõÆËßÜÈ¢ë‰∏≠ÊèêÂèñ‰∫∫‰ΩìÂíåÁâ©‰ΩìÁöÑ2D/3D‰ø°ÊÅØ„ÄÇ2) ‰∫∫Â∑•Êé•Ëß¶ÁÇπÊ†áÊ≥®Ôºö‰∫∫Â∑•Ê†áÊ≥®ËßÜÈ¢ëÂ∏ß‰∏≠‰∫∫‰∏éÁâ©‰ΩìÁöÑÊé•Ëß¶ÁÇπ„ÄÇ3) ‰ºòÂåñÊ°ÜÊû∂ÔºöÂà©Áî®‰∫∫Â∑•Ê†áÊ≥®ÁöÑÊé•Ëß¶ÁÇπ‰Ωú‰∏∫Á∫¶ÊùüÔºå‰ºòÂåñ‰∫∫‰ΩìÂíåÁâ©‰ΩìÁöÑ4DÂßøÊÄÅÔºåÂêåÊó∂‰øùËØÅÊó∂Á©∫‰∏ÄËá¥ÊÄßÂíåÁâ©ÁêÜÂêàÁêÜÊÄß„ÄÇ4) ËøêÂä®ÈáçÂª∫ÔºöËæìÂá∫ÈáçÂª∫ÁöÑ4D HOIËøêÂä®Â∫èÂàó„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÁªìÂêà‰∫Ü‰∫∫Â∑•Ê†áÊ≥®Âíå‰ºòÂåñÊ°ÜÊû∂ÔºåÊúâÊïàÂú∞Ëß£ÂÜ≥‰∫ÜÂçïÁõÆ4D HOIÈáçÂª∫ÁöÑÁóÖÊÄÅÈóÆÈ¢ò„ÄÇ‰∏éÂÆåÂÖ®‰æùËµñËá™Âä®ÁÆóÊ≥ïÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üËé∑ÂæóÊõ¥ÂáÜÁ°Æ„ÄÅÊõ¥ÂèØÈù†ÁöÑÈáçÂª∫ÁªìÊûú„ÄÇÊ≠§Â§ñÔºåÊûÑÂª∫‰∫ÜÂ§ßËßÑÊ®°ÁöÑOpen4DHOIÊï∞ÊçÆÈõÜÔºå‰∏∫Áõ∏ÂÖ≥Á†îÁ©∂Êèê‰æõ‰∫ÜÂÆùË¥µÁöÑÊï∞ÊçÆËµÑÊ∫ê„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊ°ÜÊû∂ÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Á®ÄÁñèÊé•Ëß¶ÁÇπÊ†áÊ≥®Á≠ñÁï•ÔºöÂè™ÈúÄË¶ÅÂ∞ëÈáèÁöÑ‰∫∫Â∑•Ê†áÊ≥®Âç≥ÂèØÊúâÊïàÁ∫¶ÊùüÈáçÂª∫ËøáÁ®ã„ÄÇ2) Êó∂Á©∫‰∏ÄËá¥ÊÄßÊçüÂ§±Ôºö‰øùËØÅÈáçÂª∫ÁªìÊûúÂú®Êó∂Èó¥‰∏äÁöÑÂπ≥ÊªëÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇ3) Áâ©ÁêÜÂêàÁêÜÊÄßÊçüÂ§±Ôºö‰øùËØÅÈáçÂª∫ÁªìÊûúÁ¨¶ÂêàÁâ©ÁêÜËßÑÂæãÔºå‰æãÂ¶ÇÈÅøÂÖçÁ©øÈÄèÁ≠â„ÄÇ4) ‰ºòÂåñÁÆóÊ≥ïÔºöÈÄâÊã©ÂêàÈÄÇÁöÑ‰ºòÂåñÁÆóÊ≥ïÔºå‰æãÂ¶ÇÂü∫‰∫éÊ¢ØÂ∫¶ÁöÑ‰ºòÂåñÊñπÊ≥ïÔºå‰ª•ÊúÄÂ∞èÂåñÊçüÂ§±ÂáΩÊï∞Âπ∂Ëé∑ÂæóÊúÄ‰ºòÁöÑÈáçÂª∫ÁªìÊûú„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËÆ∫ÊñáÊûÑÂª∫‰∫ÜÂåÖÂê´144ÁßçÁâ©‰ΩìÁ±ªÂûãÂíå103ÁßçÂä®‰ΩúÁöÑÂ§ßËßÑÊ®°4D HOIÊï∞ÊçÆÈõÜOpen4DHOI„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰ΩøÁî®4DHOISolverÈáçÂª∫ÁöÑËøêÂä®Êï∞ÊçÆËÉΩÂ§üÊúâÊïàÊîØÊåÅÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÊô∫ËÉΩ‰ΩìÊ®°‰ªø‰ªªÂä°ÔºåÈ™åËØÅ‰∫ÜÈáçÂª∫ÁªìÊûúÁöÑÊúâÊïàÊÄß„ÄÇÂêåÊó∂ÔºåËÆ∫ÊñáÂØπÁé∞Êúâ3DÂü∫Á°ÄÊ®°ÂûãËøõË°å‰∫ÜËØÑ‰º∞ÔºåÂèëÁé∞ÂÖ∂Âú®Ëá™Âä®È¢ÑÊµãÁ≤æÁ°ÆÁöÑ‰∫∫-Áâ©Êé•Ëß¶ÂØπÂ∫îÂÖ≥Á≥ªÊñπÈù¢‰ªçÁÑ∂Â≠òÂú®‰∏çË∂≥„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫Â≠¶‰π†„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅ‰∫∫Êú∫‰∫§‰∫íÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÂ≠¶‰π†‰∫∫Á±ª‰∏éÁâ©‰ΩìÁöÑ‰∫§‰∫íÊñπÂºèÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÊ®°‰ªø‰∫∫Á±ªË°å‰∏∫Ôºå‰ªéËÄåÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÊâßË°å‰ªªÂä°„ÄÇÈáçÂª∫ÁöÑ4D HOIÊï∞ÊçÆÂèØ‰ª•Áî®‰∫éËÆ≠ÁªÉÊú∫Âô®‰∫∫ÊéßÂà∂Á≠ñÁï•ÔºåÊèêÈ´òÊú∫Âô®‰∫∫ÁöÑÊìç‰ΩúÊäÄËÉΩ„ÄÇÊ≠§Â§ñÔºåËØ•ÊäÄÊúØËøòÂèØ‰ª•Áî®‰∫éÂàõÂª∫ÈÄºÁúüÁöÑËôöÊãüÁé∞ÂÆû‰ΩìÈ™åÔºå‰æãÂ¶ÇÊ®°Êãü‰∫∫Á±ªÊìç‰ΩúÁâ©‰ΩìÁöÑËøáÁ®ã„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Generalized robots must learn from diverse, large-scale human-object interactions (HOI) to operate robustly in the real world. Monocular internet videos offer a nearly limitless and readily available source of data, capturing an unparalleled diversity of human activities, objects, and environments. However, accurately and scalably extracting 4D interaction data from these in-the-wild videos remains a significant and unsolved challenge. Thus, in this work, we introduce 4DHOISolver, a novel and efficient optimization framework that constrains the ill-posed 4D HOI reconstruction problem by leveraging sparse, human-in-the-loop contact point annotations, while maintaining high spatio-temporal coherence and physical plausibility. Leveraging this framework, we introduce Open4DHOI, a new large-scale 4D HOI dataset featuring a diverse catalog of 144 object types and 103 actions. Furthermore, we demonstrate the effectiveness of our reconstructions by enabling an RL-based agent to imitate the recovered motions. However, a comprehensive benchmark of existing 3D foundation models indicates that automatically predicting precise human-object contact correspondences remains an unsolved problem, underscoring the immediate necessity of our human-in-the-loop strategy while posing an open challenge to the community. Data and code will be publicly available at https://wenboran2002.github.io/open4dhoi/

