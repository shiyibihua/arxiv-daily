---
layout: default
title: Fast Multi-view Consistent 3D Editing with Video Priors
---

# Fast Multi-view Consistent 3D Editing with Video Priors

**arXiv**: [2511.23172v1](https://arxiv.org/abs/2511.23172) | [PDF](https://arxiv.org/pdf/2511.23172.pdf)

**ä½œè€…**: Liyi Chen, Ruihuang Li, Guowen Zhang, Pengfei Wang, Lei Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºViP3DEï¼Œåˆ©ç”¨è§†é¢‘å…ˆéªŒå®žçŽ°å•æ¬¡å‰å‘ä¼ æ’­çš„å¤šè§†è§’ä¸€è‡´3Dç¼–è¾‘**

**å…³é”®è¯**: `3Dç¼–è¾‘` `å¤šè§†è§’ä¸€è‡´æ€§` `è§†é¢‘å…ˆéªŒ` `ç”Ÿæˆæ¨¡åž‹` `å‡ ä½•æ„ŸçŸ¥åŽ»å™ª`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–è¿­ä»£2D-3D-2Dæ›´æ–°ï¼Œå¯¼è‡´æ•ˆçŽ‡ä½Žä¸”ç»“æžœè¿‡å¹³æ»‘
2. ViP3DEåŸºäºŽè§†é¢‘ç”Ÿæˆæ¨¡åž‹ï¼Œé€šè¿‡å•ç¼–è¾‘è§†å›¾ç”Ÿæˆå…¶ä»–ä¸€è‡´è§†å›¾ï¼Œé¿å…è¿­ä»£
3. å®žéªŒæ˜¾ç¤ºViP3DEåœ¨å•æ¬¡å‰å‘ä¼ æ’­ä¸­å®žçŽ°é«˜è´¨é‡ç¼–è¾‘ï¼Œæ˜¾è‘—æå‡é€Ÿåº¦ä¸Žè´¨é‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Text-driven 3D editing enables user-friendly 3D object or scene editing with text instructions. Due to the lack of multi-view consistency priors, existing methods typically resort to employing 2D generation or editing models to process each view individually, followed by iterative 2D-3D-2D updating. However, these methods are not only time-consuming but also prone to over-smoothed results because the different editing signals gathered from different views are averaged during the iterative process. In this paper, we propose generative Video Prior based 3D Editing (ViP3DE) to employ the temporal consistency priors from pre-trained video generation models for multi-view consistent 3D editing in a single forward pass. Our key insight is to condition the video generation model on a single edited view to generate other consistent edited views for 3D updating directly, thereby bypassing the iterative editing paradigm. Since 3D updating requires edited views to be paired with specific camera poses, we propose motion-preserved noise blending for the video model to generate edited views at predefined camera poses. In addition, we introduce geometry-aware denoising to further enhance multi-view consistency by integrating 3D geometric priors into video models. Extensive experiments demonstrate that our proposed ViP3DE can achieve high-quality 3D editing results even within a single forward pass, significantly outperforming existing methods in both editing quality and speed.

