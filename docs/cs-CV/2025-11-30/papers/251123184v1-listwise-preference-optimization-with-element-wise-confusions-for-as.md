---
layout: default
title: Listwise Preference Optimization with Element-wise Confusions for Aspect Sentiment Quad Prediction
---

# Listwise Preference Optimization with Element-wise Confusions for Aspect Sentiment Quad Prediction

**arXiv**: [2511.23184v1](https://arxiv.org/abs/2511.23184) | [PDF](https://arxiv.org/pdf/2511.23184.pdf)

**ä½œè€…**: Wenna Lai, Haoran Xie, Guandong Xu, Qing Li, S. Joe Qin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽåˆ—è¡¨åå¥½ä¼˜åŒ–ä¸Žå…ƒç´ æ··æ·†çš„æ¡†æž¶ï¼Œä»¥æå‡æ–¹é¢æƒ…æ„Ÿå››å…ƒç»„é¢„æµ‹çš„ç»“æž„æœ‰æ•ˆæ€§å’Œå…³ç³»ä¸€è‡´æ€§ã€‚**

**å…³é”®è¯**: `æ–¹é¢æƒ…æ„Ÿå››å…ƒç»„é¢„æµ‹` `åˆ—è¡¨åå¥½ä¼˜åŒ–` `å…ƒç´ æ··æ·†` `æŽ¨ç†ç”Ÿæˆ` `è‡ªç„¶è¯­è¨€å¤„ç†` `æƒ…æ„Ÿåˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ–¹é¢æƒ…æ„Ÿå››å…ƒç»„é¢„æµ‹ä¸­ï¼ŒåŸºäºŽæ ‡è®°çš„æ–¹æ³•éš¾ä»¥å»ºæ¨¡å…ƒç´ é—´å¤æ‚å…³ç³»ï¼Œé«˜é˜¶å…ƒç´ é¢„æµ‹æ€§èƒ½ä¸‹é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åŸºäºŽæŽ¨ç†çš„ç”Ÿæˆè¾“å‡ºå››å…ƒç»„å’Œè‡ªç„¶è¯­è¨€ç†ç”±ï¼Œå¼•å…¥åˆ—è¡¨åå¥½ä¼˜åŒ–æ¡†æž¶ï¼Œé€šè¿‡å…ƒç´ æ··æ·†å€™é€‰æå‡å¯¹é½ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæœ‰æ•ˆæé«˜å››å…ƒç»„é¢„æµ‹å‡†ç¡®æ€§å’Œè§£é‡Šä¸€è‡´æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Aspect sentiment quad prediction (ASQP) is inherently challenging to predict a structured quadruple with four core sentiment elements, including aspect term (a), aspect category (c), opinion term (o), and sentiment polarity (s). Prior methods relying on marker-based prediction struggle with modeling the intricate relationships among elements and experience sharp performance declines when predicting higher-order elements (e.g., c and s) under standard supervised fine-tuning. To address these limitations, we employ reasoning-based generation to output both the quadruple and a natural language rationale under element prefixes within a unified template, encouraging explicit relational reasoning and interpretability. To further enhance element-wise alignment, we introduce a listwise preference optimization framework for improving structural validity and relational coherence. Specifically, we generate element-wise confusable candidates via syntactic and semantic proximity, then train the model with listwise objectives to prefer the gold candidates over closely competing alternatives. Extensive experiments on four benchmark datasets demonstrate that our framework effectively improves quadruple prediction accuracy and explanation consistency.

