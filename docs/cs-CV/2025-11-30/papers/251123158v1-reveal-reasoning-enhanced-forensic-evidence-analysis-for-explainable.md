---
layout: default
title: REVEAL: Reasoning-enhanced Forensic Evidence Analysis for Explainable AI-generated Image Detection
---

# REVEAL: Reasoning-enhanced Forensic Evidence Analysis for Explainable AI-generated Image Detection

**arXiv**: [2511.23158v1](https://arxiv.org/abs/2511.23158) | [PDF](https://arxiv.org/pdf/2511.23158.pdf)

**ä½œè€…**: Huangsen Cao, Qin Mei, Zhiheng Li, Yuxi Li, Ying Zhang, Chen Li, Zhimeng Zhang, Xin Ding, Yongwei Wang, Jing Lyu, Fei Wu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºREVEALæ¡†æž¶ä»¥è§£å†³AIç”Ÿæˆå›¾åƒæ£€æµ‹ä¸­è§£é‡Šæ€§ä¸è¶³å’Œæ³›åŒ–èƒ½åŠ›å·®çš„é—®é¢˜**

**å…³é”®è¯**: `AIç”Ÿæˆå›¾åƒæ£€æµ‹` `è§£é‡Šæ€§äººå·¥æ™ºèƒ½` `è¯æ®é“¾æŽ¨ç†` `å¼ºåŒ–å­¦ä¹ ` `å¤šæ¨¡æ€åŸºå‡†` `å›¾åƒå–è¯`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰AIç”Ÿæˆå›¾åƒæ£€æµ‹æ–¹æ³•ä¾èµ–è¡¨é¢æ¨¡å¼åŒ¹é…ï¼Œç¼ºä¹å¯éªŒè¯è¯æ®é“¾ï¼Œå¯¼è‡´è§£é‡Šæ€§å¼±å’Œæ³›åŒ–å·®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºREVEAL-BenchåŸºå‡†ï¼ŒåŸºäºŽå¤šä¸“å®¶æ¨¡åž‹è¯æ®é“¾ï¼Œå¹¶è®¾è®¡ä¸“å®¶é©±åŠ¨çš„å¼ºåŒ–å­¦ä¹ æ¡†æž¶ï¼Œè”åˆä¼˜åŒ–æ£€æµ‹å‡†ç¡®æ€§å’Œè§£é‡Šé€»è¾‘ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒæ˜¾ç¤ºREVEALæ˜¾è‘—æå‡æ£€æµ‹å‡†ç¡®æ€§ã€è§£é‡Šä¿çœŸåº¦å’Œè·¨æ¨¡åž‹æ³›åŒ–èƒ½åŠ›ï¼Œè¾¾åˆ°æ–°SOTAã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> With the rapid advancement of generative models, visually realistic AI-generated images have become increasingly difficult to distinguish from authentic ones, posing severe threats to social trust and information integrity. Consequently, there is an urgent need for efficient and truly explainable image forensic methods. Recent detection paradigms have shifted towards explainable forensics. However, state-of-the-art approaches primarily rely on post-hoc rationalizations or visual discrimination, lacking a verifiable chain of evidence. This reliance on surface-level pattern matching limits the generation of causally grounded explanations and often results in poor generalization. To bridge this critical gap, we introduce \textbf{REVEAL-Bench}, the first reasoning-enhanced multimodal benchmark for AI-generated image detection that is explicitly structured around a chain-of-evidence derived from multiple lightweight expert models, then records step-by-step reasoning traces and evidential justifications. Building upon this dataset, we propose \textbf{REVEAL} (\underline{R}easoning-\underline{e}nhanced Forensic E\underline{v}id\underline{e}nce \underline{A}na\underline{l}ysis), an effective and explainable forensic framework that integrates detection with a novel expert-grounded reinforcement learning. Our reward mechanism is specially tailored to jointly optimize detection accuracy, explanation fidelity, and logical coherence grounded in explicit forensic evidence, enabling REVEAL to produce fine-grained, interpretable, and verifiable reasoning chains alongside its detection outcomes. Extensive experimental results demonstrate that REVEAL significantly enhances detection accuracy, explanation fidelity, and robust cross-model generalization, benchmarking a new state of the art for explainable image forensics.

