---
layout: default
title: Resolving Evidence Sparsity: Agentic Context Engineering for Long-Document Understanding
---

# Resolving Evidence Sparsity: Agentic Context Engineering for Long-Document Understanding

**arXiv**: [2511.22850v1](https://arxiv.org/abs/2511.22850) | [PDF](https://arxiv.org/pdf/2511.22850.pdf)

**ä½œè€…**: Keliang Liu, Zizhi Chen, Mingcheng Li, Jingqun Tang, Dingkang Yang, Lihua Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSLEUTHå¤šæ™ºèƒ½ä½“æ¡†æž¶ä»¥è§£å†³é•¿æ–‡æ¡£ç†è§£ä¸­çš„è¯æ®ç¨€ç–é—®é¢˜**

**å…³é”®è¯**: `é•¿æ–‡æ¡£ç†è§£` `å¤šæ™ºèƒ½ä½“æ¡†æž¶` `è¯æ®ç¨€ç–` `è§†è§‰è¯­è¨€æ¨¡åž‹` `æ£€ç´¢å¢žå¼ºç”Ÿæˆ` `åˆ†å±‚ç²¾ç‚¼`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé•¿æ–‡æ¡£ä¸­çº¿ç´¢åˆ†æ•£ä¸”å†—ä½™ï¼Œå½±å“è§†è§‰è¯­è¨€æ¨¡åž‹æ€§èƒ½
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ç²—åˆ°ç»†æµç¨‹ï¼Œåè°ƒæ£€ç´¢å™¨å’Œå››ä¸ªæ™ºèƒ½ä½“è¿›è¡Œè¯æ®ç­›é€‰ä¸ŽæŽ¨ç†
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®žçŽ°SOTAï¼Œæ¶ˆèžç ”ç©¶éªŒè¯æ¨¡å—æœ‰æ•ˆæ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Document understanding is a long standing practical task. Vision Language Models (VLMs) have gradually become a primary approach in this domain, demonstrating effective performance on single page tasks. However, their effectiveness diminishes when handling long documents. In such scenarios, clues are often scattered across multiple pages and modalities, and redundancy from lengthy inputs can impair the models judgment. While retrieval augmented generation mitigates this issue by filtering for question relevant content, the retrieved results still contain substantial redundancy. To address these limitations, we propose SLEUTH, a multi agent framework. Concretely, SLEUTH orchestrates a retriever and four collaborative agents in a coarse to fine process. The framework identifies key textual and visual clues within the retrieved pages, filters for salient visual evidence such as tables and charts, and analyzes the query to devise a reasoning strategy. It ultimately synthesizes a distilled, evidence dense multimodal context to generate the final prediction. SLEUTH is model agnostic and scalable. When paired with advanced VLM backbones, it consistently improves performance on multiple long document benchmarks, achieving state of the art results. Ablation studies verify each modules effectiveness and confirm the benefits of our hierarchical refinement paradigm.

