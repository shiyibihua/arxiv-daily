---
layout: default
title: Accelerating Inference of Masked Image Generators via Reinforcement Learning
---

# Accelerating Inference of Masked Image Generators via Reinforcement Learning

**arXiv**: [2512.01094v1](https://arxiv.org/abs/2512.01094) | [PDF](https://arxiv.org/pdf/2512.01094.pdf)

**ä½œè€…**: Pranav Subbaraman, Shufan Li, Siyan Zhao, Aditya Grover

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-30

**å¤‡æ³¨**: 15 pages, 9 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSpeed-RLï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ åŠ é€ŸæŽ©ç å›¾åƒç”Ÿæˆæ¨¡åž‹æŽ¨ç†ï¼Œæ˜¾è‘—å‡å°‘é‡‡æ ·æ­¥éª¤ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `æŽ©ç å›¾åƒç”Ÿæˆæ¨¡åž‹` `å¼ºåŒ–å­¦ä¹ ` `æ¨¡åž‹åŠ é€Ÿ` `å›¾åƒç”Ÿæˆ` `æŽ¨ç†ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æŽ©ç ç”Ÿæˆæ¨¡åž‹ç”Ÿæˆé«˜è´¨é‡å›¾åƒèƒ½åŠ›å¼ºï¼Œä½†æŽ¨ç†é€Ÿåº¦æ…¢ï¼Œéœ€è¦å¤§é‡é‡‡æ ·æ­¥éª¤ã€‚
2. Speed-RLå°†åŠ é€Ÿé—®é¢˜è½¬åŒ–ä¸ºå¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œç»“åˆè´¨é‡å’Œé€Ÿåº¦å¥–åŠ±å¾®è°ƒæ¨¡åž‹ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒSpeed-RLèƒ½åœ¨ä¿æŒå›¾åƒè´¨é‡çš„åŒæ—¶ï¼Œå°†æ¨¡åž‹æŽ¨ç†é€Ÿåº¦æå‡3å€ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŽ©ç ç”Ÿæˆæ¨¡åž‹(MGM)åœ¨ç”Ÿæˆé«˜è´¨é‡å›¾åƒæ–¹é¢è¡¨çŽ°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬éœ€è¦å¤§é‡çš„é‡‡æ ·æ­¥éª¤æ‰èƒ½ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒï¼Œå¯¼è‡´æŽ¨ç†é€Ÿåº¦ç¼“æ…¢ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„èŒƒå¼Speed-RLï¼Œç”¨äºŽåŠ é€Ÿé¢„è®­ç»ƒçš„MGMï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨æ›´å°‘çš„æ­¥éª¤ä¸­ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚ä¸Žä¼ ç»Ÿçš„è’¸é¦æ–¹æ³•å°†åŠ é€Ÿé—®é¢˜å®šä¹‰ä¸ºåˆ†å¸ƒåŒ¹é…é—®é¢˜ä¸åŒï¼ˆå³è®­ç»ƒä¸€ä¸ªå°‘æ­¥æ•°çš„å­¦ç”Ÿæ¨¡åž‹æ¥åŒ¹é…å¤šæ­¥æ•°æ•™å¸ˆæ¨¡åž‹ç”Ÿæˆçš„åˆ†å¸ƒï¼‰ï¼Œæˆ‘ä»¬å°†è¿™ä¸ªé—®é¢˜è§†ä¸ºä¸€ä¸ªå¼ºåŒ–å­¦ä¹ é—®é¢˜ã€‚ç”±äºŽåŠ é€Ÿçš„ç›®æ ‡æ˜¯åœ¨æ›´å°‘çš„æ­¥éª¤ä¸­ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒï¼Œæˆ‘ä»¬å¯ä»¥å°†è´¨é‡å¥–åŠ±ä¸Žé€Ÿåº¦å¥–åŠ±ç›¸ç»“åˆï¼Œå¹¶ä½¿ç”¨å¼ºåŒ–å­¦ä¹ å¯¹åŸºç¡€æ¨¡åž‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶å°†ç»„åˆå¥–åŠ±ä½œä¸ºä¼˜åŒ–ç›®æ ‡ã€‚é€šè¿‡å¤§é‡çš„å®žéªŒï¼Œæˆ‘ä»¬è¡¨æ˜Žæ‰€æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿåœ¨ä¿æŒç›¸å½“å›¾åƒè´¨é‡çš„åŒæ—¶ï¼Œå°†åŸºç¡€æ¨¡åž‹åŠ é€Ÿ3å€ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æŽ©ç å›¾åƒç”Ÿæˆæ¨¡åž‹ï¼ˆMGMï¼‰æŽ¨ç†é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚çŽ°æœ‰çš„MGMéœ€è¦å¤§é‡çš„é‡‡æ ·æ­¥éª¤æ‰èƒ½ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨å®žé™…åº”ç”¨ä¸­çš„éƒ¨ç½²ã€‚ä¼ ç»Ÿçš„åŠ é€Ÿæ–¹æ³•ï¼Œå¦‚è’¸é¦ï¼Œé€šå¸¸å°†åŠ é€Ÿé—®é¢˜è§†ä¸ºåˆ†å¸ƒåŒ¹é…é—®é¢˜ï¼Œä½†è¿™ç§æ–¹æ³•å¯èƒ½éš¾ä»¥æ•æ‰åˆ°MGMçš„å¤æ‚ç”Ÿæˆè¿‡ç¨‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†MGMçš„åŠ é€Ÿé—®é¢˜å»ºæ¨¡ä¸ºä¸€ä¸ªå¼ºåŒ–å­¦ä¹ é—®é¢˜ã€‚é€šè¿‡å®šä¹‰ä¸€ä¸ªç»“åˆå›¾åƒè´¨é‡å’ŒæŽ¨ç†é€Ÿåº¦çš„å¥–åŠ±å‡½æ•°ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•æ¥ä¼˜åŒ–MGMçš„é‡‡æ ·ç­–ç•¥ï¼Œä»Žè€Œåœ¨æ›´å°‘çš„æ­¥éª¤å†…ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚è¿™ç§æ–¹æ³•ç›´æŽ¥ä¼˜åŒ–äº†åŠ é€Ÿçš„ç›®æ ‡ï¼Œé¿å…äº†ä¼ ç»Ÿè’¸é¦æ–¹æ³•ä¸­åˆ†å¸ƒåŒ¹é…çš„é—´æŽ¥æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šSpeed-RLçš„æŠ€æœ¯æ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) é¢„è®­ç»ƒçš„MGMä½œä¸ºåŸºç¡€æ¨¡åž‹ï¼›2) å¼ºåŒ–å­¦ä¹ çŽ¯å¢ƒï¼Œå…¶ä¸­çŠ¶æ€æ˜¯å½“å‰ç”Ÿæˆçš„å›¾åƒï¼ŒåŠ¨ä½œæ˜¯MGMçš„é‡‡æ ·æ­¥éª¤ï¼›3) å¥–åŠ±å‡½æ•°ï¼Œç»“åˆå›¾åƒè´¨é‡ï¼ˆå¦‚FIDåˆ†æ•°ï¼‰å’ŒæŽ¨ç†é€Ÿåº¦ï¼ˆé‡‡æ ·æ­¥éª¤æ•°ï¼‰ï¼›4) å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå¦‚PPOï¼‰ï¼Œç”¨äºŽä¼˜åŒ–MGMçš„é‡‡æ ·ç­–ç•¥ã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼ŒMGMåœ¨å¼ºåŒ–å­¦ä¹ çŽ¯å¢ƒä¸­è¿›è¡Œé‡‡æ ·ï¼Œæ ¹æ®ç”Ÿæˆçš„å›¾åƒå’Œé‡‡æ ·æ­¥éª¤è®¡ç®—å¥–åŠ±ï¼Œç„¶åŽä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•æ›´æ–°MGMçš„å‚æ•°ï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆæ›´é«˜è´¨é‡çš„å›¾åƒï¼ŒåŒæ—¶å‡å°‘é‡‡æ ·æ­¥éª¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šSpeed-RLçš„å…³é”®åˆ›æ–°åœ¨äºŽå°†MGMçš„åŠ é€Ÿé—®é¢˜å»ºæ¨¡ä¸ºä¸€ä¸ªå¼ºåŒ–å­¦ä¹ é—®é¢˜ã€‚ä¸Žä¼ ç»Ÿçš„è’¸é¦æ–¹æ³•ä¸åŒï¼ŒSpeed-RLç›´æŽ¥ä¼˜åŒ–äº†åŠ é€Ÿçš„ç›®æ ‡ï¼Œå³åœ¨æ›´å°‘çš„æ­¥éª¤å†…ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚æ­¤å¤–ï¼ŒSpeed-RLä½¿ç”¨äº†ä¸€ä¸ªç»“åˆå›¾åƒè´¨é‡å’ŒæŽ¨ç†é€Ÿåº¦çš„å¥–åŠ±å‡½æ•°ï¼Œè¿™ä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿåœ¨ä¸¤è€…ä¹‹é—´è¿›è¡Œæƒè¡¡ï¼Œä»Žè€ŒèŽ·å¾—æ›´å¥½çš„åŠ é€Ÿæ•ˆæžœã€‚

**å…³é”®è®¾è®¡**ï¼šå¥–åŠ±å‡½æ•°çš„è®¾è®¡æ˜¯Speed-RLçš„å…³é”®ã€‚è®ºæ–‡ä¸­ä½¿ç”¨çš„å¥–åŠ±å‡½æ•°é€šå¸¸åŒ…å«ä¸¤éƒ¨åˆ†ï¼šå›¾åƒè´¨é‡å¥–åŠ±å’Œé€Ÿåº¦å¥–åŠ±ã€‚å›¾åƒè´¨é‡å¥–åŠ±å¯ä»¥ä½¿ç”¨FIDåˆ†æ•°æˆ–Inception Scoreç­‰æŒ‡æ ‡æ¥è¡¡é‡ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚é€Ÿåº¦å¥–åŠ±åˆ™ä¸Žé‡‡æ ·æ­¥éª¤æ•°æˆåæ¯”ï¼Œé¼“åŠ±æ¨¡åž‹åœ¨æ›´å°‘çš„æ­¥éª¤å†…å®Œæˆç”Ÿæˆã€‚æ­¤å¤–ï¼Œå¼ºåŒ–å­¦ä¹ ç®—æ³•çš„é€‰æ‹©ä¹Ÿå¾ˆé‡è¦ï¼Œè®ºæ–‡ä¸­é€šå¸¸ä½¿ç”¨PPOç­‰ç®—æ³•æ¥ä¼˜åŒ–MGMçš„é‡‡æ ·ç­–ç•¥ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ï¼Œå¦‚å¥–åŠ±å‡½æ•°çš„æƒé‡ã€å­¦ä¹ çŽ‡ç­‰ï¼Œéœ€è¦æ ¹æ®å…·ä½“çš„ä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒSpeed-RLèƒ½å¤Ÿåœ¨ä¿æŒç›¸å½“å›¾åƒè´¨é‡çš„åŒæ—¶ï¼Œå°†åŸºç¡€MGMçš„æŽ¨ç†é€Ÿåº¦æå‡3å€ã€‚å…·ä½“æ¥è¯´ï¼ŒSpeed-RLåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„åŠ é€Ÿæ•ˆæžœï¼Œå¹¶ä¸”ç”Ÿæˆçš„å›¾åƒè´¨é‡ä¸ŽåŽŸå§‹MGMç›¸å½“ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒSpeed-RLæ˜¯ä¸€ç§æœ‰æ•ˆçš„MGMåŠ é€Ÿæ–¹æ³•ï¼Œå…·æœ‰å¾ˆå¼ºçš„å®žç”¨ä»·å€¼ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

Speed-RLå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ä»¥åº”ç”¨äºŽå„ç§éœ€è¦å¿«é€Ÿå›¾åƒç”Ÿæˆçš„åœºæ™¯ï¼Œä¾‹å¦‚å®žæ—¶å›¾åƒç¼–è¾‘ã€è§†é¢‘ç”Ÿæˆã€æ¸¸æˆå¼€å‘ç­‰ã€‚é€šè¿‡åŠ é€ŸMGMçš„æŽ¨ç†é€Ÿåº¦ï¼Œå¯ä»¥é™ä½Žè®¡ç®—æˆæœ¬ï¼Œæé«˜ç”¨æˆ·ä½“éªŒï¼Œå¹¶ä¿ƒè¿›MGMåœ¨å®žé™…åº”ç”¨ä¸­çš„éƒ¨ç½²ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä¹Ÿå¯ä»¥æŽ¨å¹¿åˆ°å…¶ä»–ç±»åž‹çš„ç”Ÿæˆæ¨¡åž‹ï¼Œä¾‹å¦‚æ–‡æœ¬ç”Ÿæˆæ¨¡åž‹å’ŒéŸ³é¢‘ç”Ÿæˆæ¨¡åž‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Masked Generative Models (MGM)s demonstrate strong capabilities in generating high-fidelity images. However, they need many sampling steps to create high-quality generations, resulting in slow inference speed. In this work, we propose Speed-RL, a novel paradigm for accelerating a pretrained MGMs to generate high-quality images in fewer steps. Unlike conventional distillation methods which formulate the acceleration problem as a distribution matching problem, where a few-step student model is trained to match the distribution generated by a many-step teacher model, we consider this problem as a reinforcement learning problem. Since the goal of acceleration is to generate high quality images in fewer steps, we can combine a quality reward with a speed reward and finetune the base model using reinforcement learning with the combined reward as the optimization target. Through extensive experiments, we show that the proposed method was able to accelerate the base model by a factor of 3x while maintaining comparable image quality.

