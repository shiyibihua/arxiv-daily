---
layout: default
title: Bandit Guided Submodular Curriculum for Adaptive Subset Selection
---

# Bandit Guided Submodular Curriculum for Adaptive Subset Selection

**arXiv**: [2511.22944v1](https://arxiv.org/abs/2511.22944) | [PDF](https://arxiv.org/pdf/2511.22944.pdf)

**ä½œè€…**: Prateek Chanda, Prayas Agrawal, Saral Sureka, Lokesh Reddy Polu, Atharv Kshirsagar, Ganesh Ramakrishnan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºONLINESUBMODï¼Œå°†è‡ªé€‚åº”å­é›†é€‰æ‹©å»ºæ¨¡ä¸ºå¤šè‡‚è€è™Žæœºé—®é¢˜ä»¥ä¼˜åŒ–è¯¾ç¨‹å­¦ä¹ ã€‚**

**å…³é”®è¯**: `è¯¾ç¨‹å­¦ä¹ ` `è‡ªé€‚åº”å­é›†é€‰æ‹©` `å¤šè‡‚è€è™Žæœº` `å­æ¨¡å‡½æ•°` `åœ¨çº¿ä¼˜åŒ–` `éªŒè¯é©±åŠ¨å¥–åŠ±`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿè¯¾ç¨‹å­¦ä¹ ä¾èµ–éš¾ä»¥å®šä¹‰çš„éš¾åº¦æ¦‚å¿µï¼Œé™åˆ¶äº†è‡ªé€‚åº”æ ·æœ¬é€‰æ‹©ã€‚
2. å°†å­é›†é€‰æ‹©é‡æ–°è§£é‡Šä¸ºå¤šè‡‚è€è™Žæœºï¼Œæ¯è‡‚å¯¹åº”å­æ¨¡å‡½æ•°ï¼Œæå‡ºåœ¨çº¿è´ªå©ªç­–ç•¥ONLINESUBMODå®žçŽ°æ— é—æ†¾æ€§èƒ½ã€‚
3. åœ¨è§†è§‰å’Œè¯­è¨€æ•°æ®é›†ä¸Šï¼ŒONLINESUBMODè¶…è¶Šä¼ ç»Ÿè¯¾ç¨‹å­¦ä¹ å’ŒåŒå±‚ä¼˜åŒ–æ–¹æ³•ï¼Œå±•ç¤ºæ›´ä¼˜çš„å‡†ç¡®çŽ‡-æ•ˆçŽ‡æƒè¡¡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Traditional curriculum learning proceeds from easy to hard samples, yet defining a reliable notion of difficulty remains elusive. Prior work has used submodular functions to induce difficulty scores in curriculum learning. We reinterpret adaptive subset selection and formulate it as a multi-armed bandit problem, where each arm corresponds to a submodular function guiding sample selection. We introduce ONLINESUBMOD, a novel online greedy policy that optimizes a utility-driven reward and provably achieves no-regret performance under various sampling regimes. Empirically, ONLINESUBMOD outperforms both traditional curriculum learning and bi-level optimization approaches across vision and language datasets, showing superior accuracy-efficiency tradeoffs. More broadly, we show that validationdriven reward metrics offer a principled way to guide the curriculum schedule.

