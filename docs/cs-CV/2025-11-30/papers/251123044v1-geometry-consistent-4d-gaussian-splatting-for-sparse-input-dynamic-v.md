---
layout: default
title: Geometry-Consistent 4D Gaussian Splatting for Sparse-Input Dynamic View Synthesis
---

# Geometry-Consistent 4D Gaussian Splatting for Sparse-Input Dynamic View Synthesis

**arXiv**: [2511.23044v1](https://arxiv.org/abs/2511.23044) | [PDF](https://arxiv.org/pdf/2511.23044.pdf)

**ä½œè€…**: Yiwei Li, Jiannong Cao, Penghui Ruan, Divya Saxena, Songye Zhu, Yinfeng Cao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGC-4DGSæ¡†æž¶ï¼Œé€šè¿‡å‡ ä½•ä¸€è‡´æ€§å¢žå¼ºè§£å†³ç¨€ç–è¾“å…¥åŠ¨æ€è§†å›¾åˆæˆè´¨é‡ä¸‹é™é—®é¢˜**

**å…³é”®è¯**: `åŠ¨æ€è§†å›¾åˆæˆ` `4Dé«˜æ–¯æ³¼æº…` `å‡ ä½•ä¸€è‡´æ€§` `ç¨€ç–è¾“å…¥ä¼˜åŒ–` `æ·±åº¦æ­£åˆ™åŒ–` `è¾¹ç¼˜è®¡ç®—`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç¨€ç–è¾“å…¥æ—¶4Dé«˜æ–¯æ³¼æº…æ–¹æ³•å‡ ä½•å­¦ä¹ ä¸è¿žè´¯ï¼Œå¯¼è‡´æ¸²æŸ“è´¨é‡æ˜¾è‘—ä¸‹é™
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥åŠ¨æ€ä¸€è‡´æ€§æ£€æŸ¥ç­–ç•¥å’Œå…¨å±€-å±€éƒ¨æ·±åº¦æ­£åˆ™åŒ–ï¼Œä»Žå•ç›®æ·±åº¦ä¸­æå–æ—¶ç©ºä¸€è‡´çš„å‡ ä½•ä¿¡æ¯
3. å®žéªŒæ•ˆæžœï¼šåœ¨N3DVå’ŒTechnicoloræ•°æ®é›†ä¸ŠPSNRæŒ‡æ ‡ä¼˜äºŽRF-DeRFå’ŒåŽŸå§‹4DGSï¼Œå¯åœ¨èµ„æºå—é™è®¾å¤‡éƒ¨ç½²

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Gaussian Splatting has been considered as a novel way for view synthesis of dynamic scenes, which shows great potential in AIoT applications such as digital twins. However, recent dynamic Gaussian Splatting methods significantly degrade when only sparse input views are available, limiting their applicability in practice. The issue arises from the incoherent learning of 4D geometry as input views decrease. This paper presents GC-4DGS, a novel framework that infuses geometric consistency into 4D Gaussian Splatting (4DGS), offering real-time and high-quality dynamic scene rendering from sparse input views. While learning-based Multi-View Stereo (MVS) and monocular depth estimators (MDEs) provide geometry priors, directly integrating these with 4DGS yields suboptimal results due to the ill-posed nature of sparse-input 4D geometric optimization. To address these problems, we introduce a dynamic consistency checking strategy to reduce estimation uncertainties of MVS across spacetime. Furthermore, we propose a global-local depth regularization approach to distill spatiotemporal-consistent geometric information from monocular depths, thereby enhancing the coherent geometry and appearance learning within the 4D volume. Extensive experiments on the popular N3DV and Technicolor datasets validate the effectiveness of GC-4DGS in rendering quality without sacrificing efficiency. Notably, our method outperforms RF-DeRF, the latest dynamic radiance field tailored for sparse-input dynamic view synthesis, and the original 4DGS by 2.62dB and 1.58dB in PSNR, respectively, with seamless deployability on resource-constrained IoT edge devices.

