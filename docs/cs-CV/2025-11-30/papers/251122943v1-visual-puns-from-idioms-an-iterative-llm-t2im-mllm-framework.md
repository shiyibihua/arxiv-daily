---
layout: default
title: Visual Puns from Idioms: An Iterative LLM-T2IM-MLLM Framework
---

# Visual Puns from Idioms: An Iterative LLM-T2IM-MLLM Framework

**arXiv**: [2511.22943v1](https://arxiv.org/abs/2511.22943) | [PDF](https://arxiv.org/pdf/2511.22943.pdf)

**ä½œè€…**: Kelaiti Xiao, Liang Yang, Dongyu Zhang, Paerhati Tulajiang, Hongfei Lin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¿­ä»£LLM-T2IM-MLLMæ¡†æž¶ä»¥è‡ªåŠ¨ç”Ÿæˆå’Œè¯„ä¼°åŸºäºŽä¹ è¯­çš„è§†è§‰åŒå…³å›¾åƒã€‚**

**å…³é”®è¯**: `è§†è§‰åŒå…³` `å¤šæ¨¡æ€ç”Ÿæˆ` `è¿­ä»£æ¡†æž¶` `ä¹ è¯­ç†è§£` `è‡ªåŠ¨è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç ”ç©¶åŸºäºŽä¹ è¯­çš„è§†è§‰åŒå…³å›¾åƒï¼Œç»“åˆå­—é¢ä¸Žæ¯”å–»æ„ä¹‰ã€‚
2. å¼€å‘è¿­ä»£æ¡†æž¶ï¼Œåè°ƒLLMã€T2IMå’ŒMLLMè¿›è¡Œç”Ÿæˆä¸Žè¯„ä¼°ã€‚
3. å®žéªŒä½¿ç”¨1,000ä¸ªä¹ è¯­ï¼Œè¯„ä¼°10ä¸ªLLMã€10ä¸ªMLLMå’Œä¸€ä¸ªT2IMçš„æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We study idiom-based visual puns--images that align an idiom's literal and figurative meanings--and present an iterative framework that coordinates a large language model (LLM), a text-to-image model (T2IM), and a multimodal LLM (MLLM) for automatic generation and evaluation. Given an idiom, the system iteratively (i) generates detailed visual prompts, (ii) synthesizes an image, (iii) infers the idiom from the image, and (iv) refines the prompt until recognition succeeds or a step limit is reached. Using 1,000 idioms as inputs, we synthesize a corresponding dataset of visual pun images with paired prompts, enabling benchmarking of both generation and understanding. Experiments across 10 LLMs, 10 MLLMs, and one T2IM (Qwen-Image) show that MLLM choice is the primary performance driver: GPT achieves the highest accuracies, Gemini follows, and the best open-source MLLM (Gemma) is competitive with some closed models. On the LLM side, Claude attains the strongest average performance for prompt generation.

