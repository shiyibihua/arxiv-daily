---
layout: default
title: Towards Understanding Transformers in Learning Random Walks
---

# Towards Understanding Transformers in Learning Random Walks

**arXiv**: [2511.23239v1](https://arxiv.org/abs/2511.23239) | [PDF](https://arxiv.org/pdf/2511.23239.pdf)

**ä½œè€…**: Wei Shi, Yuan Cao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç†è®ºåˆ†æžå•å±‚Transformerå­¦ä¹ åœ†ä¸Šéšæœºæ¸¸èµ°çš„èƒ½åŠ›ä¸Žå¯è§£é‡Šæ€§**

**å…³é”®è¯**: `Transformerç†è®º` `éšæœºæ¸¸èµ°` `å¯è§£é‡Šæ€§` `æ¢¯åº¦ä¸‹é™` `æ³¨æ„åŠ›æœºåˆ¶` `åºåˆ—é¢„æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç ”ç©¶Transformeråœ¨ç»å…¸ç»Ÿè®¡æ¨¡åž‹ï¼ˆåœ†ä¸Šéšæœºæ¸¸èµ°ï¼‰ä¸­çš„ç†è®ºèƒ½åŠ›ä¸Žå¯è§£é‡Šæ€§
2. è¯æ˜Žå•å±‚Transformerç»æ¢¯åº¦ä¸‹é™è®­ç»ƒå¯è¾¾åˆ°æœ€ä¼˜é¢„æµ‹ç²¾åº¦ï¼Œæ³¨æ„åŠ›æœºåˆ¶ä½œä¸ºä»¤ç‰Œé€‰æ‹©å™¨èšç„¦çˆ¶çŠ¶æ€
3. å®žéªŒéªŒè¯ç†è®ºå‘çŽ°ï¼Œæ­ç¤ºå°åˆå§‹åŒ–æ¢¯åº¦ä¸‹é™åœ¨ç®€å•ä»»åŠ¡ä¸­å¯èƒ½å¤±è´¥

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Transformers have proven highly effective across various applications, especially in handling sequential data such as natural languages and time series. However, transformer models often lack clear interpretability, and the success of transformers has not been well understood in theory. In this paper, we study the capability and interpretability of transformers in learning a family of classic statistical models, namely random walks on circles. We theoretically demonstrate that, after training with gradient descent, a one-layer transformer model can achieve optimal accuracy in predicting random walks. Importantly, our analysis reveals that the trained model is interpretable: the trained softmax attention serves as a token selector, focusing on the direct parent state; subsequently, the value matrix executes a one-step probability transition to predict the location of the next state based on this parent state. We also show that certain edge cases not covered by our theory are indeed failure cases, demonstrating that our theoretical conditions are tight. By investigating these success and failure cases, it is revealed that gradient descent with small initialization may fail or struggle to converge to a good solution in certain simple tasks even beyond random walks. Experiments are conducted to support our theoretical findings.

