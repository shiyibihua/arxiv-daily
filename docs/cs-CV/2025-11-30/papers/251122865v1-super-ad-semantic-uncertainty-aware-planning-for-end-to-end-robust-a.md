---
layout: default
title: SUPER-AD: Semantic Uncertainty-aware Planning for End-to-End Robust Autonomous Driving
---

# SUPER-AD: Semantic Uncertainty-aware Planning for End-to-End Robust Autonomous Driving

**arXiv**: [2511.22865v1](https://arxiv.org/abs/2511.22865) | [PDF](https://arxiv.org/pdf/2511.22865.pdf)

**ä½œè€…**: Wonjeong Ryu, Seungjun Yu, Seokha Moon, Hojun Choi, Junsung Park, Jinkyu Kim, Hyunjung Shim

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­ä¹‰ä¸ç¡®å®šæ€§æ„ŸçŸ¥è§„åˆ’æ¡†æž¶ï¼Œä»¥æå‡ä»…æ‘„åƒå¤´ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶çš„é²æ£’æ€§ã€‚**

**å…³é”®è¯**: `ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶` `ä¸ç¡®å®šæ€§å»ºæ¨¡` `BEVç©ºé—´è§„åˆ’` `è½¦é“è·Ÿéšæ­£åˆ™åŒ–` `ä»…æ‘„åƒå¤´æ„ŸçŸ¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå½“å‰ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿå¿½ç•¥æ„ŸçŸ¥ä¸ç¡®å®šæ€§ï¼Œåœ¨æ¨¡ç³Šåœºæ™¯ä¸­æ˜“å¤±æ•ˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåœ¨BEVç©ºé—´ä¼°è®¡ä¸ç¡®å®šæ€§ï¼Œç»“åˆè½¦é“è·Ÿéšæ­£åˆ™åŒ–ï¼Œç”Ÿæˆä¸ç¡®å®šæ€§æ„ŸçŸ¥å¯è¡Œé©¶åœ°å›¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨NAVSIMåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°æœ€ä¼˜æ€§èƒ½ï¼Œæ˜¾è‘—æå‡NAVHARDå’ŒNAVSAFEå­é›†è¡¨çŽ°ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> End-to-End (E2E) planning has become a powerful paradigm for autonomous driving, yet current systems remain fundamentally uncertainty-blind. They assume perception outputs are fully reliable, even in ambiguous or poorly observed scenes, leaving the planner without an explicit measure of uncertainty. To address this limitation, we propose a camera-only E2E framework that estimates aleatoric uncertainty directly in BEV space and incorporates it into planning. Our method produces a dense, uncertainty-aware drivability map that captures both semantic structure and geometric layout at pixel-level resolution. To further promote safe and rule-compliant behavior, we introduce a lane-following regularization that encodes lane structure and traffic norms. This prior stabilizes trajectory planning under normal conditions while preserving the flexibility needed for maneuvers such as overtaking or lane changes. Together, these components enable robust and interpretable trajectory planning, even under challenging uncertainty conditions. Evaluated on the NAVSIM benchmark, our method achieves state-of-the-art performance, delivering substantial gains on both the challenging NAVHARD and NAVSAFE subsets. These results demonstrate that our principled aleatoric uncertainty modeling combined with driving priors significantly advances the safety and reliability of camera-only E2E autonomous driving.

