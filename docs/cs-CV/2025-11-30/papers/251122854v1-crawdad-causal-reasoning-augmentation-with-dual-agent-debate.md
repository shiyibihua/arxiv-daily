---
layout: default
title: CRAwDAD: Causal Reasoning Augmentation with Dual-Agent Debate
---

# CRAwDAD: Causal Reasoning Augmentation with Dual-Agent Debate

**arXiv**: [2511.22854v1](https://arxiv.org/abs/2511.22854) | [PDF](https://arxiv.org/pdf/2511.22854.pdf)

**ä½œè€…**: Finn G. Vamosi, Nils D. Forkert

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒæ™ºèƒ½ä½“è¾©è®ºæ¡†æž¶CRAwDADï¼Œé€šè¿‡å†…éƒ¨å¯¹è¯æå‡è¯­è¨€æ¨¡åž‹åœ¨å› æžœæŽ¨ç†ä¸­çš„å‡†ç¡®æ€§ã€‚**

**å…³é”®è¯**: `å› æžœæŽ¨ç†` `å¤šæ™ºèƒ½ä½“è¾©è®º` `è¯­è¨€æ¨¡åž‹` `åäº‹å®žåˆ†æž` `CLadderæ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå› æžœæŽ¨ç†å¸¸éœ€è€ƒè™‘å¤šç§å‡è®¾ï¼Œç±»ä¼¼å†…éƒ¨å¯¹è¯ï¼Œä½†çŽ°æœ‰æ–¹æ³•æœªæ˜¾å¼æ¨¡æ‹Ÿæ­¤è¿‡ç¨‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åŒæ™ºèƒ½ä½“è¾©è®ºæ¡†æž¶ï¼Œä¸€æ™ºèƒ½ä½“è¿›è¡Œç»“æž„åŒ–å› æžœæŽ¨ç†ï¼Œå¦ä¸€æ™ºèƒ½ä½“æ‰¹åˆ¤æ€§å®¡æŸ¥é€»è¾‘ç¼ºé™·ï¼Œé€šè¿‡è¾©è®ºè¾¾æˆå…±è¯†ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CLadderæ•°æ®é›†ä¸Šï¼Œä½¿ç”¨Qwen3å’ŒDeepSeek-R1ï¼Œè¾©è®ºåŽæ¨¡åž‹æ•´ä½“å‡†ç¡®çŽ‡æå‡ï¼Œåäº‹å®žé—®é¢˜æ”¹è¿›æ˜¾è‘—ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> When people reason about cause and effect, they often consider many competing "what if" scenarios before deciding which explanation fits best. Analogously, advanced language models capable of causal inference can consider multiple interventions and counterfactuals to judge the validity of causal claims. Crucially, this type of reasoning is less like a single calculation and more like an internal dialogue between alternative hypotheses. In this paper, we make this dialogue explicit through a dual-agent debate framework where one model provides a structured causal inference, and the other critically examines this reasoning for logical flaws. When disagreements arise, agents attempt to persuade each other, challenging each other's logic and revising their conclusions until they converge on a mutually agreed answer. To take advantage of this deliberative process, we specifically use reasoning language models, whose strengths in both causal inference and adversarial debate remain under-explored relative to standard large language models. We evaluate our approach on the CLadder dataset, a benchmark linking natural language questions to formally defined causal graphs across all three rungs of Pearl's ladder of causation. With Qwen3 and DeepSeek-R1 as debater agents, we demonstrate that multi-agent debate improves DeepSeek-R1's overall accuracy in causal inference from 78.03% to 87.45%, with the counterfactual category specifically improving from 67.94% to 80.04% accuracy. Similarly, Qwen3's overall accuracy improves from 84.16% to 89.41%, and counterfactual questions from 71.53% to 80.35%, showing that strong models can still benefit greatly from debate with weaker agents. Our results highlight the potential of reasoning models as building blocks for multi-agent systems in causal inference, and demonstrate the importance of diverse perspectives in causal problem-solving.

