---
layout: default
title: RobotSeg: A Model and Dataset for Segmenting Robots in Image and Video
---

# RobotSeg: A Model and Dataset for Segmenting Robots in Image and Video

**arXiv**: [2511.22950v1](https://arxiv.org/abs/2511.22950) | [PDF](https://arxiv.org/pdf/2511.22950.pdf)

**ä½œè€…**: Haiyang Mei, Qiming Huang, Hai Ci, Mike Zheng Shou

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRobotSegæ¨¡åž‹ä¸ŽVRSæ•°æ®é›†ï¼Œä»¥è§£å†³æœºå™¨äººåˆ†å‰²ä¸­çš„ç»“æž„å¤æ‚æ€§å’Œæ ‡æ³¨æ•ˆçŽ‡é—®é¢˜ã€‚**

**å…³é”®è¯**: `æœºå™¨äººåˆ†å‰²` `åŸºç¡€æ¨¡åž‹` `è§†é¢‘æ•°æ®é›†` `ç»“æž„æ„ŸçŸ¥` `è‡ªåŠ¨æç¤º` `é«˜æ•ˆæ ‡æ³¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨äººåˆ†å‰²å› å½¢æ€å¤šæ ·ã€ç»“æž„å¤æ‚å’Œå¿«é€Ÿå˜åŒ–è€Œå…·æŒ‘æˆ˜æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽSAM 2æ”¹è¿›ï¼Œå¼•å…¥ç»“æž„å¢žå¼ºè®°å¿†å…³è”å™¨ã€æœºå™¨äººæç¤ºç”Ÿæˆå™¨å’Œé«˜æ•ˆæ ‡æ³¨è®­ç»ƒç­–ç•¥ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å›¾åƒå’Œè§†é¢‘ä¸Šå®žçŽ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œæž„å»ºåŒ…å«2.8kè§†é¢‘çš„æ•°æ®é›†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Accurate robot segmentation is a fundamental capability for robotic perception. It enables precise visual servoing for VLA systems, scalable robot-centric data augmentation, accurate real-to-sim transfer, and reliable safety monitoring in dynamic human-robot environments. Despite the strong capabilities of modern segmentation models, surprisingly it remains challenging to segment robots. This is due to robot embodiment diversity, appearance ambiguity, structural complexity, and rapid shape changes. Embracing these challenges, we introduce RobotSeg, a foundation model for robot segmentation in image and video. RobotSeg is built upon the versatile SAM 2 foundation model but addresses its three limitations for robot segmentation, namely the lack of adaptation to articulated robots, reliance on manual prompts, and the need for per-frame training mask annotations, by introducing a structure-enhanced memory associator, a robot prompt generator, and a label-efficient training strategy. These innovations collectively enable a structure-aware, automatic, and label-efficient solution. We further construct the video robot segmentation (VRS) dataset comprising over 2.8k videos (138k frames) with diverse robot embodiments and environments. Extensive experiments demonstrate that RobotSeg achieves state-of-the-art performance on both images and videos, establishing a strong foundation for future advances in robot perception.

