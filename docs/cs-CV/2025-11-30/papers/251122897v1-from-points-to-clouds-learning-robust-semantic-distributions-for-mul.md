---
layout: default
title: From Points to Clouds: Learning Robust Semantic Distributions for Multi-modal Prompts
---

# From Points to Clouds: Learning Robust Semantic Distributions for Multi-modal Prompts

**arXiv**: [2511.22897v1](https://arxiv.org/abs/2511.22897) | [PDF](https://arxiv.org/pdf/2511.22897.pdf)

**ä½œè€…**: Weiran Li, Yeqiang Liu, Yijie Wei, Mina Han, Xin Liu, Zhenbo Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPoints-to-Cloudsæ¡†æž¶ï¼Œé€šè¿‡è¯­ä¹‰åˆ†å¸ƒå­¦ä¹ è§£å†³å¤šæ¨¡æ€æç¤ºå­¦ä¹ ä¸­çš„æ³›åŒ–è„†å¼±æ€§é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€æç¤ºå­¦ä¹ ` `è¯­ä¹‰åˆ†å¸ƒå­¦ä¹ ` `åŽ»å™ªæœºåˆ¶` `è§†è§‰è¯­è¨€æ¨¡åž‹` `æ³›åŒ–æ€§èƒ½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•åŸºäºŽé™æ€ç‚¹è¡¨ç¤ºï¼Œæ˜“è¿‡æ‹Ÿåˆä¸”æ³›åŒ–å·®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥åŒåŽ»å™ªæœºåˆ¶ï¼Œå°†æç¤ºå­¦ä¹ é‡æž„ä¸ºåŠ¨æ€åŽ»å™ªä»»åŠ¡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨11ä¸ªæ•°æ®é›†ä¸ŠéªŒè¯ï¼ŒåŸºç±»åˆ°æ–°ç±»æ³›åŒ–æ€§èƒ½æå‡1.4%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal Prompt Learning (MPL) has emerged as a pivotal technique for adapting large-scale Visual Language Models (VLMs). However, current MPL methods are fundamentally limited by their optimization of a single, static point representation. This paradigm is inherently brittle, leads to overfitting on base classes, and generalizes poorly to novel or ambiguous categories. We challenge this point paradigm, proposing that robust generalization requires learning a semantic cloud (i.e., a distribution over the embedding space). To achieve this, we introduce Points-to-Clouds (P2C), a novel framework inspired by diffusion models that reframes prompt learning as a dynamic denoising task. At the core of P2C is a dual denoising mechanism: a Dynamic Prompt Denoising (DPD) mechanism perturbs text prompts with sophisticated, annealed noise to learn a smoother semantic landscape, while an auxiliary V-L Mapper denoising loss re-tasks the mapper as a denoising autoencoder. This forces the mapper to reconstruct clean visual prompts from noisy text inputs, ensuring robust cross-modal alignment. Extensive experiments across 11 datasets demonstrate that P2C consistently outperforms strong baselines. On the base-to-novel generalization benchmark, our method achieves a Harmonic Mean of 79.7%, representing a relative improvement of 1.4% over the baseline. The code and models are available at https://vranlee.github.io/P2C/.

