---
layout: default
title: A transfer learning approach for automatic conflicts detection in software requirement sentence pairs based on dual encoders
---

# A transfer learning approach for automatic conflicts detection in software requirement sentence pairs based on dual encoders

**arXiv**: [2511.23007v1](https://arxiv.org/abs/2511.23007) | [PDF](https://arxiv.org/pdf/2511.23007.pdf)

**ä½œè€…**: Yizheng Wang, Tao Jiang, Jinyan Bai, Zhengbin Zou, Tiancheng Xue, Nan Zhang, Jie Luan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽSBERTå’ŒSimCSEçš„åŒç¼–ç å™¨è¿ç§»å­¦ä¹ æ¡†æž¶ï¼Œä»¥æå‡è½¯ä»¶éœ€æ±‚å†²çªæ£€æµ‹çš„å‡†ç¡®æ€§å’Œè·¨åŸŸæ€§èƒ½ã€‚**

**å…³é”®è¯**: `è½¯ä»¶éœ€æ±‚å†²çªæ£€æµ‹` `åŒç¼–ç å™¨` `è¿ç§»å­¦ä¹ ` `SBERT` `SimCSE` `æ··åˆæŸå¤±ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè½¯ä»¶éœ€æ±‚æ–‡æ¡£ä¸­éœ€æ±‚å¯¹å†²çªæ£€æµ‹é¢ä¸´æ•°æ®ä¸å¹³è¡¡ã€è¯­ä¹‰æå–æœ‰é™å’Œè·¨åŸŸè¿ç§»å­¦ä¹ æ€§èƒ½ä¸è¶³çš„æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨SBERTå’ŒSimCSEåŒç¼–ç å™¨ç”ŸæˆåµŒå…¥ï¼Œç»“åˆå…­å…ƒç´ æ‹¼æŽ¥ç­–ç•¥å’Œå¸¦æ··åˆæŸå¤±ä¼˜åŒ–çš„ä¸¤å±‚å…¨è¿žæŽ¥ç½‘ç»œã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŸŸå†…è®¾ç½®ä¸­å®F1å’ŒåŠ æƒF1æå‡10.4%ï¼Œè·¨åŸŸåœºæ™¯ä¸­å®F1æå‡11.4%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Software Requirement Document (RD) typically contain tens of thousands of individual requirements, and ensuring consistency among these requirements is critical for the success of software engineering projects. Automated detection methods can significantly enhance efficiency and reduce costs; however, existing approaches still face several challenges, including low detection accuracy on imbalanced data, limited semantic extraction due to the use of a single encoder, and suboptimal performance in cross-domain transfer learning. To address these issues, this paper proposes a Transferable Software Requirement Conflict Detection Framework based on SBERT and SimCSE, termed TSRCDF-SS. First, the framework employs two independent encoders, Sentence-BERT (SBERT) and Simple Contrastive Sentence Embedding (SimCSE), to generate sentence embeddings for requirement pairs, followed by a six-element concatenation strategy. Furthermore, the classifier is enhanced by a two-layer fully connected feedforward neural network (FFNN) with a hybrid loss optimization strategy that integrates a variant of Focal Loss, domain-specific constraints, and a confidence-based penalty term. Finally, the framework synergistically integrates sequential and cross-domain transfer learning. Experimental results demonstrate that the proposed framework achieves a 10.4% improvement in both macro-F1 and weighted-F1 scores in in-domain settings, and an 11.4% increase in macro-F1 in cross-domain scenarios.

