---
layout: default
title: Evolutionary Discovery of Heuristic Policies for Traffic Signal Control
---

# Evolutionary Discovery of Heuristic Policies for Traffic Signal Control

**arXiv**: [2511.23122v1](https://arxiv.org/abs/2511.23122) | [PDF](https://arxiv.org/pdf/2511.23122.pdf)

**ä½œè€…**: Ruibing Wang, Shuhan Guo, Zeen Li, Zhen Wang, Quanming Yao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTemporal Policy Evolution for Trafficï¼Œåˆ©ç”¨LLMæ¼”åŒ–å¼•æ“Žç”Ÿæˆäº¤é€šä¿¡å·æŽ§åˆ¶çš„ä¸“ç”¨å¯å‘å¼ç­–ç•¥ã€‚**

**å…³é”®è¯**: `äº¤é€šä¿¡å·æŽ§åˆ¶` `å¯å‘å¼ç­–ç•¥` `å¤§è¯­è¨€æ¨¡åž‹æ¼”åŒ–` `ç»“æž„åŒ–çŠ¶æ€æŠ½è±¡` `ä¿¡ç”¨åˆ†é…åé¦ˆ` `æ— è®­ç»ƒä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šäº¤é€šä¿¡å·æŽ§åˆ¶ä¸­ï¼Œä¼ ç»Ÿå¯å‘å¼æ–¹æ³•æ•ˆçŽ‡é«˜ä½†ç®€åŒ–è¿‡åº¦ï¼ŒDRLæ€§èƒ½å¥½ä½†æ³›åŒ–å·®ä¸”ç­–ç•¥ä¸é€æ˜Žï¼Œåœ¨çº¿LLMæŽ¨ç†é€šç”¨ä½†å»¶è¿Ÿé«˜ä¸”ç¼ºä¹çŽ¯å¢ƒä¼˜åŒ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥ç»“æž„åŒ–çŠ¶æ€æŠ½è±¡å°†é«˜ç»´äº¤é€šæ•°æ®è½¬æ¢ä¸ºæ—¶åºé€»è¾‘äº‹å®žï¼Œä»¥åŠä¿¡ç”¨åˆ†é…åé¦ˆè¿½è¸ªå¾®è§‚å†³ç­–é”™è¯¯ä»¥è¿›è¡Œé’ˆå¯¹æ€§æ‰¹è¯„ï¼Œå®Œå…¨åœ¨æç¤ºå±‚é¢æ“ä½œæ— éœ€è®­ç»ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç”Ÿæˆè½»é‡çº§ã€é²æ£’çš„ç­–ç•¥ï¼Œé’ˆå¯¹ç‰¹å®šäº¤é€šçŽ¯å¢ƒä¼˜åŒ–ï¼Œæ€§èƒ½ä¼˜äºŽå¯å‘å¼æ–¹æ³•å’Œåœ¨çº¿LLMæ‰§è¡Œè€…ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Traffic Signal Control (TSC) involves a challenging trade-off: classic heuristics are efficient but oversimplified, while Deep Reinforcement Learning (DRL) achieves high performance yet suffers from poor generalization and opaque policies. Online Large Language Models (LLMs) provide general reasoning but incur high latency and lack environment-specific optimization. To address these issues, we propose Temporal Policy Evolution for Traffic (\textbf{\method{}}), which uses LLMs as an evolution engine to derive specialized heuristic policies. The framework introduces two key modules: (1) Structured State Abstraction (SSA), converting high-dimensional traffic data into temporal-logical facts for reasoning; and (2) Credit Assignment Feedback (CAF), tracing flawed micro-decisions to poor macro-outcomes for targeted critique. Operating entirely at the prompt level without training, \method{} yields lightweight, robust policies optimized for specific traffic environments, outperforming both heuristics and online LLM actors.

