---
layout: default
title: ThetaEvolve: Test-time Learning on Open Problems
---

# ThetaEvolve: Test-time Learning on Open Problems

**arXiv**: [2511.23473v1](https://arxiv.org/abs/2511.23473) | [PDF](https://arxiv.org/pdf/2511.23473.pdf)

**ä½œè€…**: Yiping Wang, Shao-Rong Su, Zhiyuan Zeng, Eva Xu, Liliang Ren, Xinyu Yang, Zeyi Huang, Xuehai He, Luyao Ma, Baolin Peng, Hao Cheng, Pengcheng He, Weizhu Chen, Shuohang Wang, Simon Shaolei Du, Yelong Shen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºThetaEvolveæ¡†æž¶ï¼Œé€šè¿‡æµ‹è¯•æ—¶å­¦ä¹ æ”¹è¿›å¼€æ”¾ä¼˜åŒ–é—®é¢˜**

**å…³é”®è¯**: `æµ‹è¯•æ—¶å­¦ä¹ ` `å¼€æ”¾ä¼˜åŒ–é—®é¢˜` `å¼ºåŒ–å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡åž‹` `ç¨‹åºæ¼”åŒ–` `å¼€æºæ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ç³»ç»Ÿå¦‚AlphaEvolveä¾èµ–å‰æ²¿å¤§æ¨¡åž‹ä¸”æ— æ³•å†…éƒ¨åŒ–æ¼”åŒ–ç­–ç•¥ï¼Œé™åˆ¶äº†å¯æ‰©å±•æ€§å’Œå­¦ä¹ èƒ½åŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šThetaEvolveç®€åŒ–å¹¶æ‰©å±•AlphaEvolveï¼Œç»“åˆä¸Šä¸‹æ–‡å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ï¼Œæ”¯æŒå•ä¸€å¤§æ¨¡åž‹ã€ç¨‹åºæ•°æ®åº“å’Œæ‰¹é‡é‡‡æ ·ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¼€æ”¾é—®é¢˜å¦‚åœ†åŒ…è£…å’Œè‡ªç›¸å…³ä¸ç­‰å¼ä¸Šï¼ŒThetaEvolveä½¿å¼€æºæ¨¡åž‹è¾¾åˆ°æ–°æœ€ä¼˜ç•Œï¼Œä¸”æµ‹è¯•æ—¶å¼ºåŒ–å­¦ä¹ ä¼˜äºŽçº¯æŽ¨ç†åŸºçº¿ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in large language models (LLMs) have enabled breakthroughs in mathematical discovery, exemplified by AlphaEvolve, a closed-source system that evolves programs to improve bounds on open problems. However, it relies on ensembles of frontier LLMs to achieve new bounds and is a pure inference system that models cannot internalize the evolving strategies. We introduce ThetaEvolve, an open-source framework that simplifies and extends AlphaEvolve to efficiently scale both in-context learning and Reinforcement Learning (RL) at test time, allowing models to continually learn from their experiences in improving open optimization problems. ThetaEvolve features a single LLM, a large program database for enhanced exploration, batch sampling for higher throughput, lazy penalties to discourage stagnant outputs, and optional reward shaping for stable training signals, etc. ThetaEvolve is the first evolving framework that enable a small open-source model, like DeepSeek-R1-0528-Qwen3-8B, to achieve new best-known bounds on open problems (circle packing and first auto-correlation inequality) mentioned in AlphaEvolve. Besides, across two models and four open tasks, we find that ThetaEvolve with RL at test-time consistently outperforms inference-only baselines, and the model indeed learns evolving capabilities, as the RL-trained checkpoints demonstrate faster progress and better final performance on both trained target task and other unseen tasks. We release our code publicly: https://github.com/ypwang61/ThetaEvolve

