---
layout: default
title: Obstruction reasoning for robotic grasping
---

# Obstruction reasoning for robotic grasping

**arXiv**: [2511.23186v1](https://arxiv.org/abs/2511.23186) | [PDF](https://arxiv.org/pdf/2511.23186.pdf)

**ä½œè€…**: Runyu Jiao, Matteo Bortolon, Francesco Giuliari, Alice Fasoli, Sergio Povoli, Guofeng Mei, Yiming Wang, Fabio Poiesi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUNOGraspæ¨¡åž‹ä»¥è§£å†³æœºå™¨äººæŠ“å–ä¸­çš„é®æŒ¡æŽ¨ç†é—®é¢˜**

**å…³é”®è¯**: `æœºå™¨äººæŠ“å–` `é®æŒ¡æŽ¨ç†` `è§†è§‰è¯­è¨€æ¨¡åž‹` `å¤šæ­¥æŽ¨ç†` `å¼ºåŒ–å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è§†è§‰è¯­è¨€æ¨¡åž‹åœ¨é®æŒ¡æŽ¨ç†å’Œå¯è¾¾æ€§è§„åˆ’æ–¹é¢å­˜åœ¨å±€é™
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽé®æŒ¡è·¯å¾„çš„å¤šæ­¥æŽ¨ç†ï¼Œç»“åˆç›‘ç£ä¸Žå¼ºåŒ–å¾®è°ƒ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åˆæˆå’ŒçœŸå®žçŽ¯å¢ƒä¸­æ˜¾è‘—æå‡é®æŒ¡æŽ¨ç†å’ŒæŠ“å–æˆåŠŸçŽ‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Successful robotic grasping in cluttered environments not only requires a model to visually ground a target object but also to reason about obstructions that must be cleared beforehand. While current vision-language embodied reasoning models show emergent spatial understanding, they remain limited in terms of obstruction reasoning and accessibility planning. To bridge this gap, we present UNOGrasp, a learning-based vision-language model capable of performing visually-grounded obstruction reasoning to infer the sequence of actions needed to unobstruct the path and grasp the target object. We devise a novel multi-step reasoning process based on obstruction paths originated by the target object. We anchor each reasoning step with obstruction-aware visual cues to incentivize reasoning capability. UNOGrasp combines supervised and reinforcement finetuning through verifiable reasoning rewards. Moreover, we construct UNOBench, a large-scale dataset for both training and benchmarking, based on MetaGraspNetV2, with over 100k obstruction paths annotated by humans with obstruction ratios, contact points, and natural-language instructions. Extensive experiments and real-robot evaluations show that UNOGrasp significantly improves obstruction reasoning and grasp success across both synthetic and real-world environments, outperforming generalist and proprietary alternatives. Project website: https://tev-fbk.github.io/UnoGrasp/.

