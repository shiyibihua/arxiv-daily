---
layout: default
title: PerfMamba: Performance Analysis and Pruning of Selective State Space Models
---

# PerfMamba: Performance Analysis and Pruning of Selective State Space Models

**arXiv**: [2511.22849v1](https://arxiv.org/abs/2511.22849) | [PDF](https://arxiv.org/pdf/2511.22849.pdf)

**ä½œè€…**: Abdullah Al Asif, Mobina Kashaniyan, Sixing Yu, Juan Pablo MuÃ±oz, Ali Jannesari

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡åž‹æ€§èƒ½åˆ†æžä¸Žå‰ªæžæ–¹æ³•ä»¥ä¼˜åŒ–éƒ¨ç½²æ•ˆçŽ‡**

**å…³é”®è¯**: `é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡åž‹` `æ€§èƒ½åˆ†æž` `æ¨¡åž‹å‰ªæž` `åºåˆ—å»ºæ¨¡` `è®¡ç®—æ•ˆçŽ‡` `å†…å­˜ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡åž‹åœ¨è¿è¡Œæ—¶è¡Œä¸ºã€èµ„æºåˆ©ç”¨å’Œæ‰©å±•ç‰¹æ€§æ–¹é¢ç¼ºä¹å…¨é¢ç†è§£ï¼Œé˜»ç¢å…¶æœ€ä¼˜éƒ¨ç½²ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¯¹Mamba-1å’ŒMamba-2è¿›è¡Œç³»ç»Ÿæ€§èƒ½åˆ†æžï¼ŒåŸºäºŽSSMç»„ä»¶èµ„æºæ¶ˆè€—æå‡ºé€‰æ‹©æ€§å‰ªæžä½Žæ´»åŠ¨çŠ¶æ€çš„æŠ€æœ¯ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå‰ªæžåœ¨ä¿æŒç²¾åº¦ä¸‹å®žçŽ°1.14å€åŠ é€Ÿå’Œ11.50%å†…å­˜å‡å°‘ï¼Œé€‚ç”¨äºŽä¸åŒåºåˆ—é•¿åº¦ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in sequence modeling have introduced selective SSMs as promising alternatives to Transformer architectures, offering theoretical computational efficiency and sequence processing advantages. A comprehensive understanding of selective SSMs in runtime behavior, resource utilization patterns, and scaling characteristics still remains unexplored, thus obstructing their optimal deployment and further architectural improvements. This paper presents a thorough empirical study of Mamba-1 and Mamba-2, systematically profiled for performance to assess the design principles that contribute to their efficiency in state-space modeling. A detailed analysis of computation patterns, memory access, I/O characteristics, and scaling properties was performed for sequence lengths ranging from 64 to 16384 tokens. Our findings show that the SSM component, a central part of the selective SSM architecture, demands a significant portion of computational resources compared to other components in the Mamba block. Based on these insights, we propose a pruning technique that selectively removes low-activity states within the SSM component, achieving measurable throughput and memory gains while maintaining accuracy within a moderate pruning regime. This approach results in performance improvements across varying sequence lengths, achieving a 1.14x speedup and reducing memory usage by 11.50\%. These results offer valuable guidance for designing more efficient SSM architectures that can be applied to a wide range of real-world applications.

