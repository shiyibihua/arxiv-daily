---
layout: default
title: Breaking the Visual Shortcuts in Multimodal Knowledge-Based Visual Question Answering
---

# Breaking the Visual Shortcuts in Multimodal Knowledge-Based Visual Question Answering

**arXiv**: [2511.22843v1](https://arxiv.org/abs/2511.22843) | [PDF](https://arxiv.org/pdf/2511.22843.pdf)

**ä½œè€…**: Dosung Lee, Sangwon Jung, Boyoung Kim, Minyoung Kim, Sungyeon Kim, Junyoung Sung, Paul Hongsuck Seo

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRETINAåŸºå‡†å’ŒMIMIRæ¨¡åž‹ä»¥è§£å†³å¤šæ¨¡æ€çŸ¥è¯†é—®ç­”ä¸­çš„è§†è§‰æ·å¾„é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€çŸ¥è¯†é—®ç­”` `è§†è§‰æ·å¾„` `åŸºå‡†æž„å»º` `å®žä½“å…³ç³»` `å›¾åƒå¢žå¼º` `æ–‡æ¡£æ£€ç´¢`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰MKB-VQAåŸºå‡†å­˜åœ¨è§†è§‰æ·å¾„ï¼Œæ¨¡åž‹å¯ä»…å‡­å›¾åƒåŒ¹é…ä¸»å®žä½“èŽ·å¾—é«˜å‡†ç¡®çŽ‡ã€‚
2. å¼•å…¥RETINAåŸºå‡†ï¼Œé€šè¿‡LLMé©±åŠ¨æž„å»ºï¼ŒæŸ¥è¯¢æ¶‰åŠæ¬¡è¦å®žä½“å¹¶é…å¯¹ç›¸å…³å›¾åƒä»¥æ¶ˆé™¤æ·å¾„ã€‚
3. æå‡ºMIMIRæ¨¡åž‹ï¼Œé€šè¿‡å¢žå¼ºå¤šç›¸å…³å®žä½“å›¾åƒä¸°å¯Œæ–‡æ¡£åµŒå…¥ï¼Œåœ¨RETINAä¸ŠéªŒè¯æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Existing Multimodal Knowledge-Based Visual Question Answering (MKB-VQA) benchmarks suffer from "visual shortcuts", as the query image typically matches the primary subject entity of the target document. We demonstrate that models can exploit these shortcuts, achieving comparable results using visual cues alone. To address this, we introduce Relational Entity Text-Image kNowledge Augmented (RETINA) benchmark, automatically constructed using an LLM-driven pipeline, consisting of 120k training and 2k human-curated test set. RETINA contains queries referencing secondary subjects (i.e. related entities) and pairs them with images of these related entities, removing the visual shortcut. When evaluated on RETINA existing models show significantly degraded performance, confirming their reliance on the shortcut. Furthermore, we propose Multi-Image MultImodal Retriever (MIMIR), which enriches document embeddings by augmenting images of multiple related entities, effectively handling RETINA, unlike prior work that uses only a single image per document. Our experiments validate the limitations of existing benchmarks and demonstrate the effectiveness of RETINA and MIMIR. Our project is available at: Project Page.

