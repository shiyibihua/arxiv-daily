---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-11-30
---

# cs.CVï¼ˆ2025-11-30ï¼‰

ğŸ“Š å…± **22** ç¯‡è®ºæ–‡
 | ğŸ”— **6** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (12 ğŸ”—3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (4 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction" class="interest-badge">æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (2 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (12 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251200850v1-smol-gs-compact-representations-for-abstract-3d-gaussian-splatting.html">Smol-GS: Compact Representations for Abstract 3D Gaussian Splatting</a></td>
  <td>Smol-GSï¼šæå‡ºç´§å‡‘çš„æŠ½è±¡3Dé«˜æ–¯æº…å°„è¡¨ç¤ºæ–¹æ³•ï¼Œå®ç°é«˜æ•ˆåœºæ™¯å‹ç¼©ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00850v1" onclick="toggleFavorite(this, '2512.00850v1', 'Smol-GS: Compact Representations for Abstract 3D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251200877v1-feed-forward-3d-gaussian-splatting-compression-with-long-context-mod.html">Feed-Forward 3D Gaussian Splatting Compression with Long-Context Modeling</a></td>
  <td>æå‡ºåŸºäºé•¿ç¨‹ä¸Šä¸‹æ–‡å»ºæ¨¡çš„å‰é¦ˆ3Dé«˜æ–¯æº…å°„å‹ç¼©æ–¹æ³•ï¼Œå®ç°é«˜å‹ç¼©ç‡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00877v1" onclick="toggleFavorite(this, '2512.00877v1', 'Feed-Forward 3D Gaussian Splatting Compression with Long-Context Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251200794v1-polargs-polarimetric-cues-for-ambiguity-free-gaussian-splatting-with.html">PolarGS: Polarimetric Cues for Ambiguity-Free Gaussian Splatting with Accurate Geometry Recovery</a></td>
  <td>PolarGSï¼šåˆ©ç”¨åæŒ¯ä¿¡æ¯å®ç°æ— æ­§ä¹‰é«˜æ–¯æº…å°„å’Œç²¾ç¡®å‡ ä½•é‡å»º</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00794v1" onclick="toggleFavorite(this, '2512.00794v1', 'PolarGS: Polarimetric Cues for Ambiguity-Free Gaussian Splatting with Accurate Geometry Recovery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251200771v1-eag3r-event-augmented-3d-geometry-estimation-for-dynamic-and-extreme.html">EAG3R: Event-Augmented 3D Geometry Estimation for Dynamic and Extreme-Lighting Scenes</a></td>
  <td>EAG3Rï¼šäº‹ä»¶ç›¸æœºå¢å¼ºçš„3Då‡ ä½•ä¼°è®¡ï¼Œè§£å†³åŠ¨æ€å’Œæç«¯å…‰ç…§åœºæ™¯é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00771v1" onclick="toggleFavorite(this, '2512.00771v1', 'EAG3R: Event-Augmented 3D Geometry Estimation for Dynamic and Extreme-Lighting Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251200927v1-lahnet-local-attentive-hashing-network-for-point-cloud-registration.html">LAHNet: Local Attentive Hashing Network for Point Cloud Registration</a></td>
  <td>LAHNetï¼šé¢å‘ç‚¹äº‘é…å‡†çš„å±€éƒ¨æ³¨æ„åŠ›å“ˆå¸Œç½‘ç»œï¼Œæå‡ç‰¹å¾åŒºåˆ†æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00927v1" onclick="toggleFavorite(this, '2512.00927v1', 'LAHNet: Local Attentive Hashing Network for Point Cloud Registration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251200677v1-dynamic-editor-training-free-text-driven-4d-scene-editing-with-multi.html">Dynamic-eDiTor: Training-Free Text-Driven 4D Scene Editing with Multimodal Diffusion Transformer</a></td>
  <td>Dynamic-eDiTorï¼šåŸºäºå¤šæ¨¡æ€æ‰©æ•£Transformerçš„å…è®­ç»ƒæ–‡æœ¬é©±åŠ¨4Dåœºæ™¯ç¼–è¾‘</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00677v1" onclick="toggleFavorite(this, '2512.00677v1', 'Dynamic-eDiTor: Training-Free Text-Driven 4D Scene Editing with Multimodal Diffusion Transformer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251200832v1-panflow-decoupled-motion-control-for-panoramic-video-generation.html">PanFlow: Decoupled Motion Control for Panoramic Video Generation</a></td>
  <td>PanFlowï¼šè§£è€¦è¿åŠ¨æ§åˆ¶çš„å…¨æ™¯è§†é¢‘ç”Ÿæˆæ–¹æ³•</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00832v1" onclick="toggleFavorite(this, '2512.00832v1', 'PanFlow: Decoupled Motion Control for Panoramic Video Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251200944v1-binary-gaussian-compact-and-progressive-representation-for-3d-gaussi.html">Binary-Gaussian: Compact and Progressive Representation for 3D Gaussian Segmentation</a></td>
  <td>æå‡ºBinary-Gaussianï¼Œç”¨äºå‹ç¼©3Dé«˜æ–¯åˆ†å‰²çš„ç‰¹å¾è¡¨ç¤ºå¹¶æå‡åˆ†å‰²ç²¾åº¦ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00944v1" onclick="toggleFavorite(this, '2512.00944v1', 'Binary-Gaussian: Compact and Progressive Representation for 3D Gaussian Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251200796v1-circleflow-flow-guided-camera-blur-estimation-using-a-circle-grid-ta.html">CircleFlow: Flow-Guided Camera Blur Estimation using a Circle Grid Target</a></td>
  <td>CircleFlowï¼šåˆ©ç”¨åœ†å½¢ç½‘æ ¼é¶æ ‡å’Œå…‰æµå¼•å¯¼çš„ç›¸æœºæ¨¡ç³Šä¼°è®¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00796v1" onclick="toggleFavorite(this, '2512.00796v1', 'CircleFlow: Flow-Guided Camera Blur Estimation using a Circle Grid Target')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251201128v1-omnifd-a-unified-model-for-versatile-face-forgery-detection.html">OmniFD: A Unified Model for Versatile Face Forgery Detection</a></td>
  <td>OmniFDï¼šç”¨äºå¤šåŠŸèƒ½äººè„¸ä¼ªé€ æ£€æµ‹çš„ç»Ÿä¸€æ¨¡å‹ï¼Œæå‡æ•ˆç‡å’Œæ³›åŒ–æ€§</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.01128v1" onclick="toggleFavorite(this, '2512.01128v1', 'OmniFD: A Unified Model for Versatile Face Forgery Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251201103v1-learning-eigenstructures-of-unstructured-data-manifolds.html">Learning Eigenstructures of Unstructured Data Manifolds</a></td>
  <td>æå‡ºä¸€ç§ç›´æ¥ä»éç»“æ„åŒ–æ•°æ®å­¦ä¹ è°±åŸºçš„æ¡†æ¶ï¼Œç”¨äºå½¢çŠ¶å’Œæµå½¢åˆ†æã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.01103v1" onclick="toggleFavorite(this, '2512.01103v1', 'Learning Eigenstructures of Unstructured Data Manifolds')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251200736v1-rem-evaluating-llm-embodied-spatial-reasoning-through-multi-frame-tr.html">REM: Evaluating LLM Embodied Spatial Reasoning through Multi-Frame Trajectories</a></td>
  <td>REMï¼šé€šè¿‡å¤šå¸§è½¨è¿¹è¯„ä¼°LLMå…·èº«ç©ºé—´æ¨ç†èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00736v1" onclick="toggleFavorite(this, '2512.00736v1', 'REM: Evaluating LLM Embodied Spatial Reasoning through Multi-Frame Trajectories')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/251200883v1-audio-visual-world-models-towards-multisensory-imagination-in-sight-.html">Audio-Visual World Models: Towards Multisensory Imagination in Sight and Sound</a></td>
  <td>æå‡ºAVWMæ¡†æ¶ï¼Œåˆ©ç”¨è§†å¬ä¿¡æ¯è¿›è¡Œç¯å¢ƒå»ºæ¨¡ï¼Œæå‡æ™ºèƒ½ä½“å¯¼èˆªæ€§èƒ½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00883v1" onclick="toggleFavorite(this, '2512.00883v1', 'Audio-Visual World Models: Towards Multisensory Imagination in Sight and Sound')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251200995v1-s2am3d-scale-controllable-part-segmentation-of-3d-point-cloud.html">S2AM3D: Scale-controllable Part Segmentation of 3D Point Cloud</a></td>
  <td>S2AM3Dï¼šæå‡ºå¯æ§ç²’åº¦çš„ä¸‰ç»´ç‚¹äº‘éƒ¨ä»¶åˆ†å‰²æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00995v1" onclick="toggleFavorite(this, '2512.00995v1', 'S2AM3D: Scale-controllable Part Segmentation of 3D Point Cloud')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251205992v2-stronger-is-not-better-better-augmentations-in-contrastive-learning-.html">Stronger is not better: Better Augmentations in Contrastive Learning for Medical Image Segmentation</a></td>
  <td>é’ˆå¯¹åŒ»å­¦å›¾åƒåˆ†å‰²ï¼Œç ”ç©¶å¯¹æ¯”å­¦ä¹ ä¸­æ›´ä¼˜çš„æ•°æ®å¢å¼ºç­–ç•¥</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05992v2" onclick="toggleFavorite(this, '2512.05992v2', 'Stronger is not better: Better Augmentations in Contrastive Learning for Medical Image Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251201094v1-accelerating-inference-of-masked-image-generators-via-reinforcement-.html">Accelerating Inference of Masked Image Generators via Reinforcement Learning</a></td>
  <td>æå‡ºSpeed-RLï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ åŠ é€Ÿæ©ç å›¾åƒç”Ÿæˆæ¨¡å‹æ¨ç†ï¼Œæ˜¾è‘—å‡å°‘é‡‡æ ·æ­¥éª¤ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.01094v1" onclick="toggleFavorite(this, '2512.01094v1', 'Accelerating Inference of Masked Image Generators via Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/251200691v1-silhouette-based-gait-foundation-model.html">Silhouette-based Gait Foundation Model</a></td>
  <td>æå‡ºFoundationGaitï¼Œé¦–ä¸ªå¯æ‰©å±•çš„æ­¥æ€è‡ªç›‘ç£é¢„è®­ç»ƒæ¡†æ¶ï¼Œæå‡å¤šç§æ­¥æ€ä»»åŠ¡æ€§èƒ½ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00691v1" onclick="toggleFavorite(this, '2512.00691v1', 'Silhouette-based Gait Foundation Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251205991v2-emodifftalkemotion-aware-diffusion-for-editable-3d-gaussian-talking-.html">EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head</a></td>
  <td>EmoDiffTalkï¼šæå‡ºæƒ…æ„Ÿæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå¯ç¼–è¾‘çš„3Dé«˜æ–¯è¯´è¯å¤´ç”Ÿæˆã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05991v2" onclick="toggleFavorite(this, '2512.05991v2', 'EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251200885v1-handyvqa-a-video-qa-benchmark-for-fine-grained-hand-object-interacti.html">HanDyVQA: A Video QA Benchmark for Fine-Grained Hand-Object Interaction Dynamics</a></td>
  <td>HanDyVQAï¼šä¸€ä¸ªç”¨äºç»†ç²’åº¦æ‰‹-ç‰©äº¤äº’åŠ¨æ€çš„è§†é¢‘é—®ç­”åŸºå‡†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00885v1" onclick="toggleFavorite(this, '2512.00885v1', 'HanDyVQA: A Video QA Benchmark for Fine-Grained Hand-Object Interaction Dynamics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251200752v1-charts-are-not-images-on-the-challenges-of-scientific-chart-editing.html">Charts Are Not Images: On the Challenges of Scientific Chart Editing</a></td>
  <td>æå‡ºFigEditåŸºå‡†ï¼Œæ­ç¤ºç°æœ‰ç”Ÿæˆæ¨¡å‹åœ¨ç§‘å­¦å›¾è¡¨ç¼–è¾‘ä¸­çš„ç»“æ„åŒ–è½¬æ¢èƒ½åŠ›ä¸è¶³</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00752v1" onclick="toggleFavorite(this, '2512.00752v1', 'Charts Are Not Images: On the Challenges of Scientific Chart Editing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction">ğŸ”¬ æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/251200960v2-efficient-and-scalable-monocular-human-object-interaction-motion-rec.html">Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction</a></td>
  <td>æå‡º4DHOISolveræ¡†æ¶ï¼Œç»“åˆäººå·¥æ ‡æ³¨ï¼Œé«˜æ•ˆé‡å»ºå•ç›®è§†é¢‘ä¸­çš„äºº-ç‰©äº¤äº’è¿åŠ¨ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00960v2" onclick="toggleFavorite(this, '2512.00960v2', 'Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251201148v1-socialfusion-addressing-social-degradation-in-pre-trained-vision-lan.html">SocialFusion: Addressing Social Degradation in Pre-trained Vision-Language Models</a></td>
  <td>æå‡ºSocialFusionæ¡†æ¶ï¼Œè§£å†³é¢„è®­ç»ƒè§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„ç¤¾ä¼šè®¤çŸ¥é€€åŒ–é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.01148v1" onclick="toggleFavorite(this, '2512.01148v1', 'SocialFusion: Addressing Social Degradation in Pre-trained Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)