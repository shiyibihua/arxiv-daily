---
layout: default
title: "MARC: Memory-Augmented RL Token Compression for Efficient Video Understanding"
---

# MARC: Memory-Augmented RL Token Compression for Efficient Video Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.07915" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.07915v1</a>
  <a href="https://arxiv.org/pdf/2510.07915.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07915v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.07915v1', 'MARC: Memory-Augmented RL Token Compression for Efficient Video Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Peiran Wu, Zhuorui Yu, Yunze Liu, Chi-Hao Wu, Enmin Zhou, Junxiao Shen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-09

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMARCï¼šä¸€ç§åŸºäºè®°å¿†å¢å¼ºå¼ºåŒ–å­¦ä¹ çš„è§†é¢‘tokenå‹ç¼©æ–¹æ³•ï¼Œç”¨äºé«˜æ•ˆè§†é¢‘ç†è§£ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘ç†è§£` `tokenå‹ç¼©` `å¼ºåŒ–å­¦ä¹ ` `çŸ¥è¯†è’¸é¦` `è§†è§‰è®°å¿†` `å¤šæ¨¡æ€å­¦ä¹ ` `è§†é¢‘æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘ç†è§£æ¨¡å‹è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œç›´æ¥åº”ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹é¢ä¸´æŒ‘æˆ˜ï¼Œè€Œtokenå‹ç¼©æ–¹æ³•å¸¸å¯¼è‡´ä¿¡æ¯æŸå¤±ã€‚
2. MARCé€šè¿‡è§†è§‰è®°å¿†æ£€ç´¢å™¨é€‰æ‹©å…³é”®ç‰‡æ®µï¼Œå¹¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è¿›è¡ŒçŸ¥è¯†è’¸é¦ï¼Œåœ¨å‹ç¼©tokençš„åŒæ—¶ä¿ç•™å…³é”®ä¿¡æ¯ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMARCåœ¨æ˜¾è‘—é™ä½è®¡ç®—èµ„æºæ¶ˆè€—çš„åŒæ—¶ï¼Œä¿æŒäº†æ¥è¿‘åŸå§‹æ¨¡å‹çš„æ€§èƒ½ï¼Œå…·æœ‰å®é™…åº”ç”¨æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•ä¸ºå¤šæ¨¡æ€æ¨¡å‹å¥ å®šäº†åŸºç¡€ã€‚ç„¶è€Œï¼Œç”±äºé«˜å¸§ç‡å’Œé•¿æ—¶é•¿ï¼Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä»å›¾åƒæ‰©å±•åˆ°è§†é¢‘æ—¶ä»ç„¶é¢ä¸´å·¨å¤§çš„è®¡ç®—æˆæœ¬ã€‚Tokenå‹ç¼©æ˜¯ä¸€ç§æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆï¼Œä½†ç°æœ‰çš„å¤§å¤šæ•°å…è®­ç»ƒæ–¹æ³•ä¼šå¯¼è‡´ä¿¡æ¯ä¸¢å¤±å’Œæ€§èƒ½ä¸‹é™ã€‚ä¸ºäº†å…‹æœè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†è®°å¿†å¢å¼ºå¼ºåŒ–å­¦ä¹ Tokenå‹ç¼©ï¼ˆMARCï¼‰ï¼Œå®ƒé›†æˆäº†ç»“æ„åŒ–æ£€ç´¢å’ŒåŸºäºå¼ºåŒ–å­¦ä¹ çš„çŸ¥è¯†è’¸é¦ã€‚MARCé‡‡ç”¨â€œæ£€ç´¢-ç„¶å-å‹ç¼©â€ç­–ç•¥ï¼Œä½¿ç”¨è§†è§‰è®°å¿†æ£€ç´¢å™¨ï¼ˆVMRï¼‰é€‰æ‹©å…³é”®ç‰‡æ®µï¼Œå¹¶ä½¿ç”¨å‹ç¼©ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆC-GRPOï¼‰æ¡†æ¶å°†æ¨ç†èƒ½åŠ›ä»æ•™å¸ˆæ¨¡å‹æç‚¼åˆ°å­¦ç”Ÿæ¨¡å‹ã€‚åœ¨å…­ä¸ªè§†é¢‘åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMARCä»…ä½¿ç”¨ä¸€å¸§çš„tokenå°±èƒ½è¾¾åˆ°æ¥è¿‘åŸºçº¿çš„å‡†ç¡®ç‡ï¼Œä»è€Œå°†è§†è§‰tokenå‡å°‘95ï¼…ï¼ŒGPUå†…å­˜å‡å°‘72ï¼…ï¼Œå»¶è¿Ÿå‡å°‘23.9ï¼…ã€‚è¿™è¯æ˜äº†å…¶åœ¨èµ„æºå—é™ç¯å¢ƒï¼ˆå¦‚è§†é¢‘é—®ç­”ã€ç›‘æ§å’Œè‡ªåŠ¨é©¾é©¶ï¼‰ä¸­è¿›è¡Œé«˜æ•ˆã€å®æ—¶è§†é¢‘ç†è§£çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†é¢‘ç†è§£ä¸­ï¼Œç”±äºè§†é¢‘å¸§ç‡é«˜ã€æ—¶é•¿é•¿å¯¼è‡´è®¡ç®—æˆæœ¬è¿‡é«˜çš„é—®é¢˜ã€‚ç°æœ‰çš„tokenå‹ç¼©æ–¹æ³•ï¼Œå°¤å…¶æ˜¯å…è®­ç»ƒæ–¹æ³•ï¼Œå¾€å¾€ä¼šé€ æˆä¿¡æ¯ä¸¢å¤±ï¼Œä»è€Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨å¤§å¹…å‡å°‘tokenæ•°é‡çš„åŒæ—¶ï¼Œå°½å¯èƒ½åœ°ä¿ç•™è§†é¢‘çš„å…³é”®ä¿¡æ¯ï¼Œæ˜¯æœ¬ç ”ç©¶è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨â€œæ£€ç´¢-ç„¶å-å‹ç¼©â€çš„ç­–ç•¥ã€‚é¦–å…ˆï¼Œåˆ©ç”¨è§†è§‰è®°å¿†æ£€ç´¢å™¨ï¼ˆVMRï¼‰ä»è§†é¢‘ä¸­é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„å…³é”®ç‰‡æ®µã€‚ç„¶åï¼Œä½¿ç”¨åŸºäºå¼ºåŒ–å­¦ä¹ çš„å‹ç¼©ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆC-GRPOï¼‰æ¡†æ¶ï¼Œå°†æ•™å¸ˆæ¨¡å‹çš„æ¨ç†èƒ½åŠ›æç‚¼åˆ°å­¦ç”Ÿæ¨¡å‹ï¼Œä»è€Œåœ¨å‹ç¼©tokençš„åŒæ—¶ï¼Œå°½å¯èƒ½åœ°ä¿ç•™è§†é¢‘çš„å…³é”®ä¿¡æ¯ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å…‹æœä¼ ç»Ÿtokenå‹ç¼©æ–¹æ³•çš„ä¿¡æ¯æŸå¤±é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMARCçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè§†è§‰è®°å¿†æ£€ç´¢å™¨ï¼ˆVMRï¼‰å’Œå‹ç¼©ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆC-GRPOï¼‰ã€‚VMRè´Ÿè´£ä»åŸå§‹è§†é¢‘ä¸­æ£€ç´¢å‡ºå…³é”®ç‰‡æ®µï¼Œè¿™äº›ç‰‡æ®µè¢«è®¤ä¸ºæ˜¯åŒ…å«è§†é¢‘æ ¸å¿ƒä¿¡æ¯çš„ä»£è¡¨æ€§å¸§ã€‚C-GRPOåˆ™åˆ©ç”¨å¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œè®­ç»ƒä¸€ä¸ªå­¦ç”Ÿæ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿæ¨¡ä»¿æ•™å¸ˆæ¨¡å‹åœ¨è¿™äº›å…³é”®ç‰‡æ®µä¸Šçš„æ¨ç†èƒ½åŠ›ï¼Œä»è€Œå®ç°tokenå‹ç¼©ã€‚æ•´ä¸ªæµç¨‹å¯ä»¥æ¦‚æ‹¬ä¸ºï¼šè¾“å…¥è§†é¢‘ -> VMRæ£€ç´¢å…³é”®ç‰‡æ®µ -> æ•™å¸ˆæ¨¡å‹æ¨ç† -> C-GRPOè®­ç»ƒå­¦ç”Ÿæ¨¡å‹ -> è¾“å‡ºå‹ç¼©åçš„è§†é¢‘è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šMARCçš„å…³é”®åˆ›æ–°åœ¨äºå°†ç»“æ„åŒ–æ£€ç´¢å’Œå¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œç”¨äºè§†é¢‘tokenå‹ç¼©ã€‚ä¼ ç»Ÿçš„tokenå‹ç¼©æ–¹æ³•å¾€å¾€æ˜¯æ— å·®åˆ«åœ°å‡å°‘tokenæ•°é‡ï¼Œè€ŒMARCé¦–å…ˆé€šè¿‡VMRé€‰æ‹©å…³é”®ç‰‡æ®µï¼Œä¿è¯äº†å‹ç¼©è¿‡ç¨‹ä¿ç•™äº†è§†é¢‘çš„æ ¸å¿ƒä¿¡æ¯ã€‚åŒæ—¶ï¼Œåˆ©ç”¨C-GRPOæ¡†æ¶ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ çš„æ–¹å¼ï¼Œå°†æ•™å¸ˆæ¨¡å‹çš„æ¨ç†èƒ½åŠ›è¿ç§»åˆ°å­¦ç”Ÿæ¨¡å‹ï¼Œé¿å…äº†ç›´æ¥å‹ç¼©å¸¦æ¥çš„ä¿¡æ¯æŸå¤±ã€‚è¿™ç§ç»“åˆä½¿å¾—MARCèƒ½å¤Ÿåœ¨å¤§å¹…é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œä¿æŒè¾ƒé«˜çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šVMRçš„è®¾è®¡å¯èƒ½æ¶‰åŠåˆ°å¦‚ä½•æ„å»ºå’Œç»´æŠ¤è§†è§‰è®°å¿†ï¼Œä»¥åŠå¦‚ä½•å®šä¹‰å…³é”®ç‰‡æ®µçš„é€‰æ‹©æ ‡å‡†ã€‚C-GRPOæ¡†æ¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼šå¦‚ä½•å®šä¹‰å¼ºåŒ–å­¦ä¹ çš„çŠ¶æ€ã€åŠ¨ä½œå’Œå¥–åŠ±å‡½æ•°ï¼Œä»¥åŠå¦‚ä½•è®¾è®¡å­¦ç”Ÿæ¨¡å‹çš„ç½‘ç»œç»“æ„ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆåœ°æ¨¡ä»¿æ•™å¸ˆæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦å¹³è¡¡å‹ç¼©ç‡å’Œæ€§èƒ½ä¹‹é—´çš„å…³ç³»ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚éœ€è¦åœ¨è®ºæ–‡ä¸­è¿›ä¸€æ­¥æŸ¥æ‰¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMARCä»…ä½¿ç”¨ä¸€å¸§çš„tokenå°±èƒ½è¾¾åˆ°æ¥è¿‘åŸºçº¿çš„å‡†ç¡®ç‡ï¼Œå®ç°äº†95%çš„è§†è§‰tokenå‡å°‘ï¼Œ72%çš„GPUå†…å­˜å‡å°‘ï¼Œä»¥åŠ23.9%çš„å»¶è¿Ÿé™ä½ã€‚è¿™äº›æ•°æ®è¡¨æ˜ï¼ŒMARCåœ¨å¤§å¹…é™ä½è®¡ç®—èµ„æºæ¶ˆè€—çš„åŒæ—¶ï¼Œä¿æŒäº†è¾ƒé«˜çš„æ€§èƒ½ï¼Œå…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MARCå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­ã€‚ä¾‹å¦‚ï¼Œåœ¨è§†é¢‘é—®ç­”ç³»ç»Ÿä¸­ï¼Œå¯ä»¥åˆ©ç”¨MARCå‹ç¼©è§†é¢‘tokenï¼Œé™ä½è®¡ç®—æˆæœ¬ï¼Œæé«˜å“åº”é€Ÿåº¦ã€‚åœ¨ç›‘æ§ç³»ç»Ÿä¸­ï¼Œå¯ä»¥å‡å°‘å­˜å‚¨ç©ºé—´å’Œå¸¦å®½éœ€æ±‚ã€‚åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œå¯ä»¥åŠ é€Ÿè§†é¢‘å¤„ç†ï¼Œæé«˜å†³ç­–æ•ˆç‡ã€‚æ­¤å¤–ï¼ŒMARCè¿˜å¯ä»¥åº”ç”¨äºè§†é¢‘æ‘˜è¦ã€è§†é¢‘æ£€ç´¢ç­‰é¢†åŸŸï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid progress of large language models (LLMs) has laid the foundation for multimodal models. However, visual language models (VLMs) still face heavy computational costs when extended from images to videos due to high frame rates and long durations. Token compression is a promising solution, yet most existing training-free methods cause information loss and performance degradation. To overcome this, we propose \textbf{Memory-Augmented Reinforcement Learning-based Token Compression (MARC)}, which integrates structured retrieval and RL-based distillation. MARC adopts a \textit{retrieve-then-compress} strategy using a \textbf{Visual Memory Retriever (VMR)} to select key clips and a \textbf{Compression Group Relative Policy Optimization (C-GRPO)} framework to distil reasoning ability from a teacher to a student model. Experiments on six video benchmarks show that MARC achieves near-baseline accuracy using only one frame's tokens -- reducing visual tokens by \textbf{95\% }, GPU memory by \textbf{72\% }, and latency by \textbf{23.9\% }. This demonstrates its potential for efficient, real-time video understanding in resource-constrained settings such as video QA, surveillance, and autonomous driving.

