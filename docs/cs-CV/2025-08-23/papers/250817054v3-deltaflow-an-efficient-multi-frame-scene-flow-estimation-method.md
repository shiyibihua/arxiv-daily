---
layout: default
title: DeltaFlow: An Efficient Multi-frame Scene Flow Estimation Method
---

# DeltaFlow: An Efficient Multi-frame Scene Flow Estimation Method

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17054" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.17054v3</a>
  <a href="https://arxiv.org/pdf/2508.17054.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17054v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17054v3', 'DeltaFlow: An Efficient Multi-frame Scene Flow Estimation Method')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qingwen Zhang, Xiaomeng Zhu, Yushan Zhang, Yixi Cai, Olov Andersson, Patric Jensfelt

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-23 (æ›´æ–°: 2025-12-22)

**å¤‡æ³¨**: NeurIPS 2025 Spotlight, 18 pages (10 main pages + 8 supp materail), 11 figures, code at https://github.com/Kin-Zhang/DeltaFlow

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Kin-Zhang/DeltaFlow)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDeltaFlowä»¥é«˜æ•ˆè§£å†³å¤šå¸§åœºæ™¯æµä¼°è®¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `åœºæ™¯æµä¼°è®¡` `å¤šå¸§æ¨ç†` `è¿åŠ¨æ•æ‰` `ç±»åˆ«å¹³è¡¡æŸå¤±` `å®ä¾‹ä¸€è‡´æ€§æŸå¤±` `è‡ªåŠ¨é©¾é©¶` `æœºå™¨äººå¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åœºæ™¯æµä¼°è®¡æ–¹æ³•ä¸»è¦ä¾èµ–äºä¸¤å¸§å›¾åƒï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨æ—¶é—´ä¿¡æ¯ï¼Œå¯¼è‡´æ€§èƒ½å—é™ã€‚
2. æœ¬æ–‡æå‡ºçš„DeltaFlowé€šè¿‡$Î”$æ–¹æ¡ˆé«˜æ•ˆæå–å¤šå¸§æ—¶é—´ç‰¹å¾ï¼Œæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ï¼Œæå‡åœºæ™¯æµä¼°è®¡çš„å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDeltaFlowåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†22%çš„è¯¯å·®é™ä½å’Œ2å€çš„æ¨ç†é€Ÿåº¦æå‡ï¼Œå±•ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„åœºæ™¯æµä¼°è®¡æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä¸¤å¸§ä¹‹é—´çš„ä¿¡æ¯ï¼Œå¿½è§†äº†æ—¶é—´åŸŸä¸­çš„å®è´µä¿¡æ¯ã€‚å°½ç®¡è¿‘æœŸçš„ç ”ç©¶è¶‹åŠ¿å‘å¤šå¸§æ¨ç†è½¬å˜ï¼Œä½†éšç€å¸§æ•°çš„å¢åŠ ï¼Œè®¡ç®—æˆæœ¬è¿…é€Ÿä¸Šå‡ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†DeltaFlowï¼ˆ$Î”$Flowï¼‰ï¼Œä¸€ä¸ªè½»é‡çº§çš„3Dæ¡†æ¶ï¼Œé€šè¿‡$Î”$æ–¹æ¡ˆæ•æ‰è¿åŠ¨çº¿ç´¢ï¼Œä»¥æœ€å°çš„è®¡ç®—æˆæœ¬æå–æ—¶é—´ç‰¹å¾ã€‚æ­¤å¤–ï¼Œåœºæ™¯æµä¼°è®¡è¿˜é¢ä¸´ç±»åˆ«ä¸å¹³è¡¡å’Œè¿åŠ¨ä¸ä¸€è‡´ç­‰æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡å¼•å…¥äº†ç±»åˆ«å¹³è¡¡æŸå¤±å’Œå®ä¾‹ä¸€è‡´æ€§æŸå¤±ï¼Œæå‡äº†æµçš„å‡†ç¡®æ€§ã€‚åœ¨Argoverse 2ã€Waymoå’ŒnuScenesæ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œ$Î”$Flowåœ¨æ€§èƒ½ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ï¼Œè¯¯å·®é™ä½äº†22%ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº†2å€ï¼ŒåŒæ—¶å±•ç°å‡ºå¼ºå¤§çš„è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰åœºæ™¯æµä¼°è®¡æ–¹æ³•åœ¨å¤„ç†å¤šå¸§è¾“å…¥æ—¶çš„è®¡ç®—æˆæœ¬è¿‡é«˜å’Œä¿¡æ¯åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–äºä¸¤å¸§å›¾åƒï¼Œæœªèƒ½æœ‰æ•ˆåˆ©ç”¨æ—¶é—´åŸŸä¿¡æ¯ï¼Œå¯¼è‡´æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDeltaFlowé€šè¿‡å¼•å…¥$Î”$æ–¹æ¡ˆï¼Œèƒ½å¤Ÿåœ¨ä¸å¢åŠ è®¡ç®—è´Ÿæ‹…çš„æƒ…å†µä¸‹ï¼Œæå–å¤šå¸§çš„æ—¶é—´ç‰¹å¾ï¼Œä»è€Œæ›´é«˜æ•ˆåœ°æ•æ‰è¿åŠ¨ä¿¡æ¯ã€‚è¯¥è®¾è®¡æ—¨åœ¨å¹³è¡¡è®¡ç®—æ•ˆç‡ä¸ä¼°è®¡å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDeltaFlowçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆé€šè¿‡$Î”$æ–¹æ¡ˆæå–æ—¶é—´ç‰¹å¾ï¼Œç„¶ååº”ç”¨ç±»åˆ«å¹³è¡¡æŸå¤±å’Œå®ä¾‹ä¸€è‡´æ€§æŸå¤±æ¥ä¼˜åŒ–å­¦ä¹ è¿‡ç¨‹ï¼Œæœ€ç»ˆè¾“å‡ºåœºæ™¯æµä¼°è®¡ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†ç±»åˆ«å¹³è¡¡æŸå¤±å’Œå®ä¾‹ä¸€è‡´æ€§æŸå¤±ï¼Œè¿™ä¸¤ç§æŸå¤±å‡½æ•°æœ‰æ•ˆè§£å†³äº†ç±»åˆ«ä¸å¹³è¡¡å’Œè¿åŠ¨ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†æµçš„ä¼°è®¡ç²¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼ŒDeltaFlowé‡‡ç”¨äº†è½»é‡çº§è®¾è®¡ï¼Œç¡®ä¿åœ¨å¤„ç†å¤šå¸§æ•°æ®æ—¶ä¿æŒè¾ƒä½çš„è®¡ç®—æˆæœ¬ã€‚åŒæ—¶ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ åˆ°ç¨€æœ‰ç±»åˆ«çš„ç‰¹å¾ï¼Œæé«˜äº†æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDeltaFlowç›¸æ¯”äºä¸‹ä¸€æœ€ä½³çš„å¤šå¸§ç›‘ç£æ–¹æ³•ï¼Œè¯¯å·®é™ä½äº†22%ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº†2å€ï¼Œå±•ç°å‡ºå“è¶Šçš„æ€§èƒ½å’Œå¼ºå¤§çš„è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œæ ‡å¿—ç€åœºæ™¯æµä¼°è®¡é¢†åŸŸçš„ä¸€æ¬¡é‡è¦è¿›å±•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DeltaFlowçš„ç ”ç©¶æˆæœåœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œè§†é¢‘åˆ†æç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡é«˜æ•ˆçš„åœºæ™¯æµä¼°è®¡ï¼Œèƒ½å¤Ÿæå‡æœºå™¨å¯¹åŠ¨æ€ç¯å¢ƒçš„ç†è§£èƒ½åŠ›ï¼Œä»è€Œå¢å¼ºæ™ºèƒ½ç³»ç»Ÿçš„å†³ç­–èƒ½åŠ›å’Œååº”é€Ÿåº¦ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Previous dominant methods for scene flow estimation focus mainly on input from two consecutive frames, neglecting valuable information in the temporal domain. While recent trends shift towards multi-frame reasoning, they suffer from rapidly escalating computational costs as the number of frames grows. To leverage temporal information more efficiently, we propose DeltaFlow ($Î”$Flow), a lightweight 3D framework that captures motion cues via a $Î”$ scheme, extracting temporal features with minimal computational cost, regardless of the number of frames. Additionally, scene flow estimation faces challenges such as imbalanced object class distributions and motion inconsistency. To tackle these issues, we introduce a Category-Balanced Loss to enhance learning across underrepresented classes and an Instance Consistency Loss to enforce coherent object motion, improving flow accuracy. Extensive evaluations on the Argoverse 2, Waymo and nuScenes datasets show that $Î”$Flow achieves state-of-the-art performance with up to 22% lower error and $2\times$ faster inference compared to the next-best multi-frame supervised method, while also demonstrating a strong cross-domain generalization ability. The code is open-sourced at https://github.com/Kin-Zhang/DeltaFlow along with trained model weights.

