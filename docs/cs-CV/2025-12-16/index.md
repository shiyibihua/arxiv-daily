---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-12-16
---

# cs.CVï¼ˆ2025-12-16ï¼‰

ğŸ“Š å…± **74** ç¯‡è®ºæ–‡
 | ğŸ”— **8** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (20 ğŸ”—3)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (15 ğŸ”—4)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (13)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (11 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (8)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (5)</a>
<a href="#æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting" class="interest-badge">æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (20 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251214095v1-anchorhoi-zero-shot-generation-of-4d-human-object-interaction-via-an.html">AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation</a></td>
  <td>AnchorHOIï¼šåŸºäºé”šç‚¹çš„å…ˆéªŒçŸ¥è¯†è’¸é¦å®ç°é›¶æ ·æœ¬4Däºº-ç‰©äº¤äº’ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14095v1" onclick="toggleFavorite(this, '2512.14095v1', 'AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251214352v1-hgs-hybrid-gaussian-splatting-with-static-dynamic-decomposition-for-.html">HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis</a></td>
  <td>æå‡ºHGSæ··åˆé«˜æ–¯æº…å°„æ–¹æ³•ï¼Œé€šè¿‡é™æ€-åŠ¨æ€è§£è€¦å®ç°ç´§å‡‘çš„åŠ¨æ€åœºæ™¯æ–°è§†è§’åˆæˆã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14352v1" onclick="toggleFavorite(this, '2512.14352v1', 'HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251214200v1-beyond-a-single-light-a-large-scale-aerial-dataset-for-urban-scene-r.html">Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination</a></td>
  <td>SkyLumeï¼šä¸€ä¸ªå¤§è§„æ¨¡å¤šå…‰ç…§åŸå¸‚é‡å»ºèˆªæ‹æ•°æ®é›†ï¼Œç”¨äºè§£å†³å…‰ç…§å˜åŒ–ä¸‹çš„ä¸‰ç»´é‡å»ºé—®é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14200v1" onclick="toggleFavorite(this, '2512.14200v1', 'Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251214020v1-deep-learning-perspective-of-scene-understanding-in-autonomous-robot.html">Deep Learning Perspective of Scene Understanding in Autonomous Robots</a></td>
  <td>ç»¼è¿°æ·±åº¦å­¦ä¹ åœ¨è‡ªä¸»æœºå™¨äººåœºæ™¯ç†è§£ä¸­çš„åº”ç”¨ï¼Œæå‡æœºå™¨äººæ„ŸçŸ¥ä¸å†³ç­–èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14020v1" onclick="toggleFavorite(this, '2512.14020v1', 'Deep Learning Perspective of Scene Understanding in Autonomous Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251214536v1-dasp-self-supervised-nighttime-monocular-depth-estimation-with-domai.html">DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors</a></td>
  <td>DASPï¼šåˆ©ç”¨æ—¶ç©ºå…ˆéªŒåŸŸé€‚åº”çš„è‡ªç›‘ç£å¤œé—´å•ç›®æ·±åº¦ä¼°è®¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14536v1" onclick="toggleFavorite(this, '2512.14536v1', 'DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251214406v1-broadening-view-synthesis-of-dynamic-scenes-from-constrained-monocul.html">Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos</a></td>
  <td>ExpanDyNeRFï¼šæ‰©å±•åŠ¨æ€åœºæ™¯è§†è§’åˆæˆï¼Œè§£å†³å•ç›®è§†é¢‘å¤§è§’åº¦æ¸²æŸ“å¤±çœŸé—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14406v1" onclick="toggleFavorite(this, '2512.14406v1', 'Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251214087v1-gaussianplant-structure-aligned-gaussian-splatting-for-3d-reconstruc.html">GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants</a></td>
  <td>æå‡ºGaussianPlantä»¥è§£å†³æ¤ç‰©3Dé‡å»ºä¸­çš„ç»“æ„ä¸å¤–è§‚åˆ†ç¦»é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14087v1" onclick="toggleFavorite(this, '2512.14087v1', 'GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251214032v1-ace-slam-scene-coordinate-regression-for-neural-implicit-real-time-s.html">ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM</a></td>
  <td>ACE-SLAMï¼šåŸºäºåœºæ™¯åæ ‡å›å½’çš„ç¥ç»éšå¼å®æ—¶SLAMç³»ç»Ÿ</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14032v1" onclick="toggleFavorite(this, '2512.14032v1', 'ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251214560v1-clnet-cross-view-correspondence-makes-a-stronger-geo-localizationer.html">CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer</a></td>
  <td>æå‡ºCLNetï¼Œé€šè¿‡è·¨è§†è§’å¯¹åº”å…³ç³»å¢å¼ºå›¾åƒæ£€ç´¢åœ°ç†å®šä½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14560v1" onclick="toggleFavorite(this, '2512.14560v1', 'CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251214364v1-unified-semantic-transformer-for-3d-scene-understanding.html">Unified Semantic Transformer for 3D Scene Understanding</a></td>
  <td>æå‡ºUNITEï¼šç”¨äº3Dåœºæ™¯ç†è§£çš„ç»Ÿä¸€è¯­ä¹‰Transformeræ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14364v1" onclick="toggleFavorite(this, '2512.14364v1', 'Unified Semantic Transformer for 3D Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251214235v1-4d-radiff-latent-diffusion-for-4d-radar-point-cloud-generation.html">4D-RaDiff: Latent Diffusion for 4D Radar Point Cloud Generation</a></td>
  <td>æå‡º4D-RaDiffï¼Œåˆ©ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆ4Dé›·è¾¾ç‚¹äº‘ï¼Œæå‡ç›®æ ‡æ£€æµ‹æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14235v1" onclick="toggleFavorite(this, '2512.14235v1', '4D-RaDiff: Latent Diffusion for 4D Radar Point Cloud Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251214222v1-history-enhanced-two-stage-transformer-for-aerial-vision-and-languag.html">History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation</a></td>
  <td>æå‡ºå†å²å¢å¼ºå‹ä¸¤é˜¶æ®µTransformerï¼Œè§£å†³æ— äººæœºè§†è§‰è¯­è¨€å¯¼èˆªä¸­å…¨å±€æ¨ç†ä¸å±€éƒ¨ç†è§£çš„å¹³è¡¡é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14222v1" onclick="toggleFavorite(this, '2512.14222v1', 'History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251214180v1-spherical-voronoi-directional-appearance-as-a-differentiable-partiti.html">Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere</a></td>
  <td>æå‡ºçƒé¢Voronoiæ–¹æ³•ï¼Œç”¨äº3Dé«˜æ–¯æº…å°„ä¸­é«˜æ•ˆå¯å¾®çš„æ–¹å‘å¤–è§‚å»ºæ¨¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14180v1" onclick="toggleFavorite(this, '2512.14180v1', 'Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251214162v1-fastddhpose-towards-unified-efficient-and-disentangled-3d-human-pose.html">FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation</a></td>
  <td>FastDDHPoseï¼šç»Ÿä¸€ã€é«˜æ•ˆã€è§£è€¦çš„3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14162v1" onclick="toggleFavorite(this, '2512.14162v1', 'FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251214126v1-consistent-instance-field-for-dynamic-scene-understanding.html">Consistent Instance Field for Dynamic Scene Understanding</a></td>
  <td>æå‡ºä¸€è‡´æ€§å®ä¾‹åœºï¼Œç”¨äºåŠ¨æ€åœºæ™¯ç†è§£ä¸­çš„æ—¶ç©ºä¸€è‡´æ€§åˆ†å‰²ä¸æŸ¥è¯¢ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14126v1" onclick="toggleFavorite(this, '2512.14126v1', 'Consistent Instance Field for Dynamic Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251214028v1-robust-single-shot-structured-light-3d-imaging-via-neural-feature-de.html">Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding</a></td>
  <td>æå‡ºåŸºäºç¥ç»ç‰¹å¾è§£ç çš„é²æ£’å•ç›®ç»“æ„å…‰3Dæˆåƒæ–¹æ³•ï¼Œæå‡å¤æ‚åœºæ™¯ä¸‹çš„æ·±åº¦ä¼°è®¡ç²¾åº¦ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14028v1" onclick="toggleFavorite(this, '2512.14028v1', 'Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251214039v1-asap-textured-gaussians-enhancing-textured-gaussians-with-adaptive-s.html">ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization</a></td>
  <td>ASAP-Textured Gaussiansï¼šé€šè¿‡è‡ªé€‚åº”é‡‡æ ·å’Œå„å‘å¼‚æ€§å‚æ•°åŒ–å¢å¼ºçº¹ç†é«˜æ–¯æ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14039v1" onclick="toggleFavorite(this, '2512.14039v1', 'ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251214274v1-tun-detecting-significant-points-in-persistence-diagrams-with-deep-l.html">TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning</a></td>
  <td>æå‡ºTUNç½‘ç»œï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ è‡ªåŠ¨æ£€æµ‹æŒä¹…åŒè°ƒå›¾ä¸­æ˜¾è‘—ç‰¹å¾ç‚¹ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14274v1" onclick="toggleFavorite(this, '2512.14274v1', 'TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251214273v1-zoom-zero-reinforced-coarse-to-fine-video-understanding-via-temporal.html">Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in</a></td>
  <td>Zoom-Zeroï¼šé€šè¿‡æ—¶é—´åŸŸç¼©æ”¾å¢å¼ºè§†é¢‘ç†è§£ï¼Œè§£å†³GVQAä¸­æ—¶åºå®šä½ä¸å‡†é—®é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14273v1" onclick="toggleFavorite(this, '2512.14273v1', 'Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251214236v1-elastic3d-controllable-stereo-video-conversion-with-guided-latent-de.html">Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding</a></td>
  <td>Elastic3Dï¼šåŸºäºå¼•å¯¼å¼æ½œåœ¨è§£ç çš„å¯æ§ç«‹ä½“è§†é¢‘è½¬æ¢æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14236v1" onclick="toggleFavorite(this, '2512.14236v1', 'Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (15 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/251214052v1-hypervl-an-efficient-and-dynamic-multimodal-large-language-model-for.html">HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices</a></td>
  <td>HyperVLï¼šé¢å‘è¾¹ç¼˜è®¾å¤‡çš„é«˜æ•ˆåŠ¨æ€å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14052v1" onclick="toggleFavorite(this, '2512.14052v1', 'HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251214594v1-llm-driven-knowledge-enhancement-for-multimodal-cancer-survival-pred.html">LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction</a></td>
  <td>æå‡ºKEMMæ¨¡å‹ï¼Œåˆ©ç”¨LLMå¢å¼ºçŸ¥è¯†çš„å¤šæ¨¡æ€ç™Œç—‡ç”Ÿå­˜é¢„æµ‹ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14594v1" onclick="toggleFavorite(this, '2512.14594v1', 'LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/251214102v1-neurosymbolic-inference-on-foundation-models-for-remote-sensing-text.html">Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries</a></td>
  <td>æå‡ºRUNEï¼Œç»“åˆç¥ç»ç¬¦å·æ¨ç†ä¸å¤§æ¨¡å‹ï¼Œè§£å†³é¥æ„Ÿå›¾åƒå¤æ‚æŸ¥è¯¢çš„æ–‡æœ¬åˆ°å›¾åƒæ£€ç´¢é—®é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14102v1" onclick="toggleFavorite(this, '2512.14102v1', 'Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/251214499v1-native-intelligence-emerges-from-large-scale-clinical-practice-a-ret.html">Native Intelligence Emerges from Large-Scale Clinical Practice: A Retinal Foundation Model with Deployment Efficiency</a></td>
  <td>ReVisionï¼šåŸºäºå¤§è§„æ¨¡ä¸´åºŠå®è·µçš„è§†ç½‘è†œåŸç”Ÿæ™ºèƒ½æ¨¡å‹ï¼Œæå‡éƒ¨ç½²æ•ˆç‡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14499v1" onclick="toggleFavorite(this, '2512.14499v1', 'Native Intelligence Emerges from Large-Scale Clinical Practice: A Retinal Foundation Model with Deployment Efficiency')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/251214489v1-signit-a-comprehensive-dataset-and-multimodal-analysis-for-italian-s.html">SignIT: A Comprehensive Dataset and Multimodal Analysis for Italian Sign Language Recognition</a></td>
  <td>å‘å¸ƒSignITæ„å¤§åˆ©æ‰‹è¯­æ•°æ®é›†ï¼Œå¹¶è¿›è¡Œå¤šæ¨¡æ€æ‰‹è¯­è¯†åˆ«åŸºå‡†åˆ†æ</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14489v1" onclick="toggleFavorite(this, '2512.14489v1', 'SignIT: A Comprehensive Dataset and Multimodal Analysis for Italian Sign Language Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/251214225v1-omnigen-unified-multimodal-sensor-generation-for-autonomous-driving.html">OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving</a></td>
  <td>OmniGenï¼šæå‡ºç»Ÿä¸€çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç”Ÿæˆæ¡†æ¶ï¼Œç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14225v1" onclick="toggleFavorite(this, '2512.14225v1', 'OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/251214058v1-real-time-prediction-of-workplane-illuminance-distribution-for-dayli.html">Real-time prediction of workplane illuminance distribution for daylight-linked controls using non-intrusive multimodal deep learning</a></td>
  <td>æå‡ºåŸºäºéä¾µå…¥å¼å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ çš„æ—¥å…‰ç…§æ˜æ§åˆ¶å·¥ä½œé¢ç…§åº¦å®æ—¶é¢„æµ‹æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14058v1" onclick="toggleFavorite(this, '2512.14058v1', 'Real-time prediction of workplane illuminance distribution for daylight-linked controls using non-intrusive multimodal deep learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/251214040v1-chartagent-a-chart-understanding-framework-with-tool-integrated-reas.html">ChartAgent: A Chart Understanding Framework with Tool Integrated Reasoning</a></td>
  <td>æå‡ºChartAgentï¼Œä¸€ä¸ªå·¥å…·é›†æˆæ¨ç†çš„å›¾è¡¨ç†è§£æ¡†æ¶ï¼Œæå‡ç¨€ç–æ ‡æ³¨ä¸‹çš„é²æ£’æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14040v1" onclick="toggleFavorite(this, '2512.14040v1', 'ChartAgent: A Chart Understanding Framework with Tool Integrated Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/251214017v1-kfs-bench-comprehensive-evaluation-of-key-frame-sampling-in-long-vid.html">KFS-Bench: Comprehensive Evaluation of Key Frame Sampling in Long Video Understanding</a></td>
  <td>æå‡ºKFS-BenchåŸºå‡†ï¼Œç”¨äºé•¿è§†é¢‘é—®ç­”ä¸­å…³é”®å¸§é‡‡æ ·çš„å…¨é¢è¯„ä¼°ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14017v1" onclick="toggleFavorite(this, '2512.14017v1', 'KFS-Bench: Comprehensive Evaluation of Key Frame Sampling in Long Video Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>30</td>
  <td><a href="./papers/251214654v1-virc-enhancing-visual-interleaved-mathematical-cot-with-reason-chunk.html">ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking</a></td>
  <td>æå‡ºViRCæ¡†æ¶ï¼Œé€šè¿‡Reason Chunkingå¢å¼ºå¤šæ¨¡æ€æ•°å­¦é—®é¢˜ä¸­çš„è§†è§‰æ¨ç†èƒ½åŠ›</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14654v1" onclick="toggleFavorite(this, '2512.14654v1', 'ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>31</td>
  <td><a href="./papers/251214574v1-foodlogathl-218-constructing-a-real-world-food-image-dataset-using-d.html">FoodLogAthl-218: Constructing a Real-World Food Image Dataset Using Dietary Management Applications</a></td>
  <td>FoodLogAthl-218ï¼šæ„å»ºåŸºäºè†³é£Ÿç®¡ç†åº”ç”¨é‡‡é›†çš„çœŸå®é£Ÿç‰©å›¾åƒæ•°æ®é›†</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14574v1" onclick="toggleFavorite(this, '2512.14574v1', 'FoodLogAthl-218: Constructing a Real-World Food Image Dataset Using Dietary Management Applications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>32</td>
  <td><a href="./papers/251214420v1-discode-distribution-aware-score-decoder-for-robust-automatic-evalua.html">DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning</a></td>
  <td>æå‡ºDISCODEï¼Œä¸€ç§åˆ†å¸ƒæ„ŸçŸ¥çš„åˆ†æ•°è§£ç å™¨ï¼Œç”¨äºæå‡å›¾åƒæè¿°è‡ªåŠ¨è¯„ä¼°çš„é²æ£’æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14420v1" onclick="toggleFavorite(this, '2512.14420v1', 'DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>33</td>
  <td><a href="./papers/251214257v1-enhancing-visual-programming-for-visual-reasoning-via-probabilistic-.html">Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs</a></td>
  <td>æå‡ºEVPGï¼Œé€šè¿‡æ¦‚ç‡å›¾å¢å¼ºè§†è§‰ç¼–ç¨‹åœ¨è§†è§‰æ¨ç†ä¸­çš„æ€§èƒ½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14257v1" onclick="toggleFavorite(this, '2512.14257v1', 'Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>34</td>
  <td><a href="./papers/251214141v1-torchtraceap-a-new-benchmark-dataset-for-detecting-performance-anti-.html">TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models</a></td>
  <td>æå‡ºTorchTraceAPåŸºå‡†æ•°æ®é›†ï¼Œç”¨äºæ£€æµ‹è®¡ç®—æœºè§†è§‰æ¨¡å‹ä¸­çš„æ€§èƒ½åæ¨¡å¼ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14141v1" onclick="toggleFavorite(this, '2512.14141v1', 'TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>35</td>
  <td><a href="./papers/251214113v1-selective-controlled-and-domain-agnostic-unlearning-in-pretrained-cl.html">Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach</a></td>
  <td>æå‡ºä¸€ç§å…è®­ç»ƒå…æ•°æ®çš„CLIPå¯æ§é€‰æ‹©æ€§é¢†åŸŸæ— å…³çŸ¥è¯†é—å¿˜æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14113v1" onclick="toggleFavorite(this, '2512.14113v1', 'Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (13 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>36</td>
  <td><a href="./papers/251214095v1-anchorhoi-zero-shot-generation-of-4d-human-object-interaction-via-an.html">AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation</a></td>
  <td>æå‡ºAnchorHOIä»¥è§£å†³4Däººæœºäº¤äº’ç”Ÿæˆä¸­çš„æ•°æ®ç¨€ç¼ºé—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14095v1" onclick="toggleFavorite(this, '2512.14095v1', 'AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>37</td>
  <td><a href="./papers/251214614v1-worldplay-towards-long-term-geometric-consistency-for-real-time-inte.html">WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling</a></td>
  <td>WorldPlayï¼šæå‡ºä¸€ç§å…·æœ‰é•¿æœŸå‡ ä½•ä¸€è‡´æ€§çš„å®æ—¶äº¤äº’å¼ä¸–ç•Œå»ºæ¨¡æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14614v1" onclick="toggleFavorite(this, '2512.14614v1', 'WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>38</td>
  <td><a href="./papers/251214698v1-timelens-rethinking-video-temporal-grounding-with-multimodal-llms.html">TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs</a></td>
  <td>æå‡ºTimeLensä»¥æå‡è§†é¢‘æ—¶é—´å®šä½çš„å‡†ç¡®æ€§ä¸å¯é æ€§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14698v1" onclick="toggleFavorite(this, '2512.14698v1', 'TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>39</td>
  <td><a href="./papers/251214442v1-a4-agent-an-agentic-framework-for-zero-shot-affordance-reasoning.html">A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning</a></td>
  <td>æå‡ºA4-Agentï¼šä¸€ä¸ªç”¨äºé›¶æ ·æœ¬å¯ä¾›æ€§æ¨ç†çš„Agentæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14442v1" onclick="toggleFavorite(this, '2512.14442v1', 'A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>40</td>
  <td><a href="./papers/251214364v1-unified-semantic-transformer-for-3d-scene-understanding.html">Unified Semantic Transformer for 3D Scene Understanding</a></td>
  <td>æå‡ºUNITEï¼šç”¨äº3Dåœºæ™¯ç†è§£çš„ç»Ÿä¸€è¯­ä¹‰Transformeræ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14364v1" onclick="toggleFavorite(this, '2512.14364v1', 'Unified Semantic Transformer for 3D Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>41</td>
  <td><a href="./papers/251214044v1-omnidrive-r1-reinforcement-driven-interleaved-multi-modal-chain-of-t.html">OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving</a></td>
  <td>OmniDrive-R1ï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„å¤šæ¨¡æ€äº¤é”™CoTï¼Œæå‡è‡ªåŠ¨é©¾é©¶è§†è§‰è¯­è¨€æ¨¡å‹çš„å¯é æ€§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14044v1" onclick="toggleFavorite(this, '2512.14044v1', 'OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>42</td>
  <td><a href="./papers/251214309v1-psmamba-progressive-self-supervised-vision-mamba-for-plant-disease-r.html">PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition</a></td>
  <td>PSMambaï¼šä¸€ç§ç”¨äºæ¤ç‰©ç—…å®³è¯†åˆ«çš„æ¸è¿›å¼è‡ªç›‘ç£è§†è§‰Mambaæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14309v1" onclick="toggleFavorite(this, '2512.14309v1', 'PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>43</td>
  <td><a href="./papers/251214440v1-s2d-sparse-to-dense-keymask-distillation-for-unsupervised-video-inst.html">S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation</a></td>
  <td>æå‡ºS2Dï¼šä¸€ç§ç¨€ç–åˆ°ç¨ å¯†çš„Keymaskè’¸é¦æ–¹æ³•ï¼Œç”¨äºæ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14440v1" onclick="toggleFavorite(this, '2512.14440v1', 'S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>44</td>
  <td><a href="./papers/251214056v1-facedit-unified-talking-face-editing-and-generation-via-facial-motio.html">FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling</a></td>
  <td>FacEDiTï¼šé€šè¿‡é¢éƒ¨è¿åŠ¨å¡«å……ç»Ÿä¸€å®ç°è¯´è¯äººè„¸ç¼–è¾‘ä¸ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14056v1" onclick="toggleFavorite(this, '2512.14056v1', 'FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>45</td>
  <td><a href="./papers/251214614v1-worldplay-towards-long-term-geometric-consistency-for-real-time-inte.html">WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling</a></td>
  <td>WorldPlayï¼šæå‡ºä¸€ç§å…·æœ‰é•¿æœŸå‡ ä½•ä¸€è‡´æ€§çš„å®æ—¶äº¤äº’å¼ä¸–ç•Œå»ºæ¨¡æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14614v1" onclick="toggleFavorite(this, '2512.14614v1', 'WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>46</td>
  <td><a href="./papers/251214309v1-psmamba-progressive-self-supervised-vision-mamba-for-plant-disease-r.html">PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition</a></td>
  <td>PSMambaï¼šä¸€ç§ç”¨äºæ¤ç‰©ç—…å®³è¯†åˆ«çš„æ¸è¿›å¼è‡ªç›‘ç£è§†è§‰Mambaæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14309v1" onclick="toggleFavorite(this, '2512.14309v1', 'PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>47</td>
  <td><a href="./papers/251214442v1-a4-agent-an-agentic-framework-for-zero-shot-affordance-reasoning.html">A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning</a></td>
  <td>æå‡ºA4-Agentï¼šä¸€ç§ç”¨äºé›¶æ ·æœ¬å¯ä¾›æ€§æ¨ç†çš„Agentæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14442v1" onclick="toggleFavorite(this, '2512.14442v1', 'A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>48</td>
  <td><a href="./papers/251214056v1-facedit-unified-talking-face-editing-and-generation-via-facial-motio.html">FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling</a></td>
  <td>FacEDiTï¼šé€šè¿‡é¢éƒ¨è¿åŠ¨å¡«å……å®ç°ç»Ÿä¸€çš„è¯´è¯äººè„¸ç¼–è¾‘ä¸ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14056v1" onclick="toggleFavorite(this, '2512.14056v1', 'FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (11 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>49</td>
  <td><a href="./papers/251214536v1-dasp-self-supervised-nighttime-monocular-depth-estimation-with-domai.html">DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors</a></td>
  <td>DASPï¼šåˆ©ç”¨æ—¶ç©ºå…ˆéªŒåŸŸé€‚åº”çš„è‡ªç›‘ç£å¤œé—´å•ç›®æ·±åº¦ä¼°è®¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14536v1" onclick="toggleFavorite(this, '2512.14536v1', 'DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>50</td>
  <td><a href="./papers/251214352v1-hgs-hybrid-gaussian-splatting-with-static-dynamic-decomposition-for-.html">HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis</a></td>
  <td>æå‡ºHGSæ··åˆé«˜æ–¯æº…å°„ï¼Œé€šè¿‡é™æ€-åŠ¨æ€åˆ†è§£å®ç°ç´§å‡‘çš„åŠ¨æ€è§†è§’åˆæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14352v1" onclick="toggleFavorite(this, '2512.14352v1', 'HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>51</td>
  <td><a href="./papers/251214087v1-gaussianplant-structure-aligned-gaussian-splatting-for-3d-reconstruc.html">GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants</a></td>
  <td>GaussianPlantï¼šç”¨äºæ¤ç‰©ä¸‰ç»´é‡å»ºçš„ç»“æ„å¯¹é½é«˜æ–¯æº…å°„æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14087v1" onclick="toggleFavorite(this, '2512.14087v1', 'GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>52</td>
  <td><a href="./papers/251214200v1-beyond-a-single-light-a-large-scale-aerial-dataset-for-urban-scene-r.html">Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination</a></td>
  <td>SkyLumeï¼šä¸€ä¸ªå¤§è§„æ¨¡åŸå¸‚èˆªæ‹æ•°æ®é›†ï¼Œç”¨äºç ”ç©¶å…‰ç…§å˜åŒ–ä¸‹çš„ä¸‰ç»´é‡å»º</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14200v1" onclick="toggleFavorite(this, '2512.14200v1', 'Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>53</td>
  <td><a href="./papers/251214406v1-broadening-view-synthesis-of-dynamic-scenes-from-constrained-monocul.html">Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos</a></td>
  <td>ExpanDyNeRFï¼šåˆ©ç”¨é«˜æ–¯å…ˆéªŒå’Œä¼ªçœŸå€¼ï¼Œæ‰©å±•åŠ¨æ€åœºæ™¯å•ç›®è§†é¢‘è§†è§’åˆæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14406v1" onclick="toggleFavorite(this, '2512.14406v1', 'Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>54</td>
  <td><a href="./papers/251214126v1-consistent-instance-field-for-dynamic-scene-understanding.html">Consistent Instance Field for Dynamic Scene Understanding</a></td>
  <td>æå‡ºä¸€è‡´æ€§å®ä¾‹åœºï¼Œç”¨äºåŠ¨æ€åœºæ™¯ç†è§£ä¸­çš„æ—¶ç©ºè¿ç»­å»ºæ¨¡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14126v1" onclick="toggleFavorite(this, '2512.14126v1', 'Consistent Instance Field for Dynamic Scene Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>55</td>
  <td><a href="./papers/251214020v1-deep-learning-perspective-of-scene-understanding-in-autonomous-robot.html">Deep Learning Perspective of Scene Understanding in Autonomous Robots</a></td>
  <td>ç»¼è¿°æ·±åº¦å­¦ä¹ åœ¨è‡ªä¸»æœºå™¨äººåœºæ™¯ç†è§£ä¸­çš„åº”ç”¨ï¼Œæå‡æœºå™¨äººæ„ŸçŸ¥ä¸å†³ç­–èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14020v1" onclick="toggleFavorite(this, '2512.14020v1', 'Deep Learning Perspective of Scene Understanding in Autonomous Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>56</td>
  <td><a href="./papers/251214180v1-spherical-voronoi-directional-appearance-as-a-differentiable-partiti.html">Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere</a></td>
  <td>æå‡ºåŸºäºçƒå½¢Voronoiå›¾çš„å¯å¾®æ–¹å‘å¤–è§‚å»ºæ¨¡æ–¹æ³•ï¼Œæå‡3Dé«˜æ–¯æº…å°„æ¸²æŸ“æ•ˆæœ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14180v1" onclick="toggleFavorite(this, '2512.14180v1', 'Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>57</td>
  <td><a href="./papers/251214039v1-asap-textured-gaussians-enhancing-textured-gaussians-with-adaptive-s.html">ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization</a></td>
  <td>æå‡ºASAP-Textured Gaussiansï¼Œé€šè¿‡è‡ªé€‚åº”é‡‡æ ·å’Œå„å‘å¼‚æ€§å‚æ•°åŒ–æå‡çº¹ç†é«˜æ–¯æ¨¡å‹çš„æ•ˆç‡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14039v1" onclick="toggleFavorite(this, '2512.14039v1', 'ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>58</td>
  <td><a href="./papers/251214028v1-robust-single-shot-structured-light-3d-imaging-via-neural-feature-de.html">Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding</a></td>
  <td>æå‡ºåŸºäºç¥ç»ç‰¹å¾è§£ç çš„é²æ£’å•ç›®ç»“æ„å…‰3Dæˆåƒæ–¹æ³•ï¼Œæå‡å¤æ‚åœºæ™¯ä¸‹çš„æ·±åº¦ä¼°è®¡ç²¾åº¦ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14028v1" onclick="toggleFavorite(this, '2512.14028v1', 'Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>59</td>
  <td><a href="./papers/251214236v1-elastic3d-controllable-stereo-video-conversion-with-guided-latent-de.html">Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding</a></td>
  <td>Elastic3Dï¼šåŸºäºå¼•å¯¼å¼æ½œåœ¨è§£ç çš„å¯æ§ç«‹ä½“è§†é¢‘è½¬æ¢æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14236v1" onclick="toggleFavorite(this, '2512.14236v1', 'Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (8 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>60</td>
  <td><a href="./papers/251214696v1-crisp-contact-guided-real2sim-from-monocular-video-with-planar-scene.html">CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives</a></td>
  <td>CRISPï¼šåŸºäºå•ç›®è§†é¢‘å’Œå¹³é¢åœºæ™¯åŸè¯­çš„æ¥è§¦å¼•å¯¼Real2Simæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14696v1" onclick="toggleFavorite(this, '2512.14696v1', 'CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>61</td>
  <td><a href="./papers/251214320v1-semantic-mismatch-and-perceptual-degradation-a-new-perspective-on-im.html">Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity</a></td>
  <td>æå‡ºååŒä¸­é—´ç‰¹å¾æ“çºµï¼ˆSIFMï¼‰æ–¹æ³•ï¼Œæå‡å›¾åƒé’ˆå¯¹æ¶æ„æ‰©æ•£æ¨¡å‹ç¼–è¾‘çš„å…ç–«åŠ›ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14320v1" onclick="toggleFavorite(this, '2512.14320v1', 'Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>62</td>
  <td><a href="./papers/251214217v1-draw2act-turning-depth-encoded-trajectories-into-robotic-demonstrati.html">DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos</a></td>
  <td>DRAW2ACTï¼šæå‡ºæ·±åº¦æ„ŸçŸ¥çš„è½¨è¿¹æ¡ä»¶è§†é¢‘ç”Ÿæˆæ¡†æ¶ï¼Œç”¨äºæœºå™¨äººæ“ä½œæ¼”ç¤ºè§†é¢‘ç”Ÿæˆã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14217v1" onclick="toggleFavorite(this, '2512.14217v1', 'DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>63</td>
  <td><a href="./papers/251214341v1-towards-transferable-defense-against-malicious-image-edits.html">Towards Transferable Defense Against Malicious Image Edits</a></td>
  <td>æå‡ºTDAEæ¡†æ¶ï¼Œå¢å¼ºå›¾åƒå¯¹æ¶æ„ç¼–è¾‘çš„é˜²å¾¡è¿ç§»èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14341v1" onclick="toggleFavorite(this, '2512.14341v1', 'Towards Transferable Defense Against Malicious Image Edits')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>64</td>
  <td><a href="./papers/251214336v1-vector-prism-animating-vector-graphics-by-stratifying-semantic-struc.html">Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure</a></td>
  <td>Vector Prismï¼šé€šè¿‡åˆ†å±‚è¯­ä¹‰ç»“æ„å®ç°çŸ¢é‡å›¾å½¢åŠ¨ç”»</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14336v1" onclick="toggleFavorite(this, '2512.14336v1', 'Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>65</td>
  <td><a href="./papers/251214696v1-crisp-contact-guided-real2sim-from-monocular-video-with-planar-scene.html">CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives</a></td>
  <td>CRISPï¼šåŸºäºå•ç›®è§†é¢‘å’Œå¹³é¢åœºæ™¯åŸè¯­çš„æ¥è§¦å¼•å¯¼Real2Simæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14696v1" onclick="toggleFavorite(this, '2512.14696v1', 'CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>66</td>
  <td><a href="./papers/251214336v1-vector-prism-animating-vector-graphics-by-stratifying-semantic-struc.html">Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure</a></td>
  <td>æå‡ºVector Prismï¼Œé€šè¿‡åˆ†å±‚è¯­ä¹‰ç»“æ„å®ç°çŸ¢é‡å›¾å½¢åŠ¨ç”»</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14336v1" onclick="toggleFavorite(this, '2512.14336v1', 'Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>67</td>
  <td><a href="./papers/251214217v1-draw2act-turning-depth-encoded-trajectories-into-robotic-demonstrati.html">DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos</a></td>
  <td>æå‡ºDRAW2ACTä»¥è§£å†³æœºå™¨äººæ¼”ç¤ºè§†é¢‘ç”Ÿæˆçš„å¯æ§æ€§é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14217v1" onclick="toggleFavorite(this, '2512.14217v1', 'DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>68</td>
  <td><a href="./papers/251214008v1-sparse-lavida-sparse-multimodal-discrete-diffusion-language-models.html">Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models</a></td>
  <td>Sparse-LaViDaï¼šé€šè¿‡ç¨€ç–åŒ–é‡‡æ ·åŠ é€Ÿå¤šæ¨¡æ€ç¦»æ•£æ‰©æ•£è¯­è¨€æ¨¡å‹æ¨ç†ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14008v1" onclick="toggleFavorite(this, '2512.14008v1', 'Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>69</td>
  <td><a href="./papers/251214234v1-vibes-a-conversational-agent-with-behaviorally-intelligent-3d-virtua.html">ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body</a></td>
  <td>ViBESï¼šä¸€ä¸ªå…·æœ‰è¡Œä¸ºæ™ºèƒ½çš„3Dè™šæ‹ŸåŒ–èº«å¯¹è¯ä»£ç†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14234v1" onclick="toggleFavorite(this, '2512.14234v1', 'ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>70</td>
  <td><a href="./papers/251214677v1-vasa-3d-lifelike-audio-driven-gaussian-head-avatars-from-a-single-im.html">VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image</a></td>
  <td>VASA-3Dï¼šåŸºäºå•å¼ å›¾åƒçš„é€¼çœŸéŸ³é¢‘é©±åŠ¨é«˜æ–¯å¤´éƒ¨åŒ–èº«ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14677v1" onclick="toggleFavorite(this, '2512.14677v1', 'VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>71</td>
  <td><a href="./papers/251214234v1-vibes-a-conversational-agent-with-behaviorally-intelligent-3d-virtua.html">ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body</a></td>
  <td>ViBESï¼šä¸€ç§å…·æœ‰è¡Œä¸ºæ™ºèƒ½çš„3Dè™šæ‹ŸåŒ–èº«å¯¹è¯ä»£ç†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14234v1" onclick="toggleFavorite(this, '2512.14234v1', 'ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>72</td>
  <td><a href="./papers/251214677v1-vasa-3d-lifelike-audio-driven-gaussian-head-avatars-from-a-single-im.html">VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image</a></td>
  <td>VASA-3Dï¼šåŸºäºå•å¼ å›¾åƒçš„é€¼çœŸéŸ³é¢‘é©±åŠ¨é«˜æ–¯å¤´éƒ¨åŒ–èº«ç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14677v1" onclick="toggleFavorite(this, '2512.14677v1', 'VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting">ğŸ”¬ æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>73</td>
  <td><a href="./papers/251214099v1-viewmask-1-to-3-multi-view-consistent-image-generation-via-multimoda.html">ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models</a></td>
  <td>ViewMask-1-to-3ï¼šåŸºäºå¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹å®ç°å¤šè§†è§’ä¸€è‡´çš„å›¾åƒç”Ÿæˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14099v1" onclick="toggleFavorite(this, '2512.14099v1', 'ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>74</td>
  <td><a href="./papers/251214140v1-sketchassist-a-practical-assistant-for-semantic-edits-and-precise-lo.html">SketchAssist: A Practical Assistant for Semantic Edits and Precise Local Redrawing</a></td>
  <td>SketchAssistï¼šç”¨äºè¯­ä¹‰ç¼–è¾‘å’Œç²¾ç¡®å±€éƒ¨é‡ç»˜çš„å®ç”¨è‰å›¾è¾…åŠ©å·¥å…·</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14140v1" onclick="toggleFavorite(this, '2512.14140v1', 'SketchAssist: A Practical Assistant for Semantic Edits and Precise Local Redrawing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)