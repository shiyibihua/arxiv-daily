---
layout: default
title: DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos
---

# DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.14217" target="_blank" class="toolbar-btn">arXiv: 2512.14217v1</a>
    <a href="https://arxiv.org/pdf/2512.14217.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14217v1" 
            onclick="toggleFavorite(this, '2512.14217v1', 'DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yang Bai, Liudi Yang, George Eskandar, Fengyi Shen, Mohammad Altillawi, Ziyuan Liu, Gitta Kutyniok

**ÂàÜÁ±ª**: cs.CV, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-16

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫DRAW2ACT‰ª•Ëß£ÂÜ≥Êú∫Âô®‰∫∫ÊºîÁ§∫ËßÜÈ¢ëÁîüÊàêÁöÑÂèØÊéßÊÄßÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÁîüÊàê` `Êú∫Âô®‰∫∫ÊºîÁ§∫` `Â§öÊ®°ÊÄÅËûçÂêà` `Ê∑±Â∫¶Â≠¶‰π†` `ËΩ®ËøπÊù°‰ª∂ÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑËΩ®ËøπÊù°‰ª∂ËßÜÈ¢ëÁîüÊàêÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫é‰∫åÁª¥ËΩ®ËøπÊàñÂçï‰∏ÄÊ®°ÊÄÅÔºåÂØºËá¥ÁîüÊàêÁöÑÊú∫Âô®‰∫∫ÊºîÁ§∫Áº∫‰πèÂèØÊéßÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑDRAW2ACTÊ°ÜÊû∂ÈÄöËøáÊèêÂèñÊ∑±Â∫¶„ÄÅËØ≠‰πâ„ÄÅÂΩ¢Áä∂ÂíåËøêÂä®Á≠âÂ§öÁßçÊ≠£‰∫§Ë°®Á§∫ÔºåÂ¢ûÂº∫‰∫ÜËßÜÈ¢ëÁîüÊàêÁöÑÂ§öÊ®°ÊÄÅÁâπÊÄß„ÄÇ
3. Âú®Bridge V2„ÄÅBerkeley AutolabÂíå‰ªøÁúüÂü∫ÂáÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåDRAW2ACTÂú®ËßÜËßâË¥®ÈáèÂíå‰∏ÄËá¥ÊÄß‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂ÊèêÈ´ò‰∫ÜÊìç‰ΩúÊàêÂäüÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜÈ¢ëÊâ©Êï£Ê®°Âûã‰∏∫ÂÖ∑Ë∫´‰∫∫Â∑•Êô∫ËÉΩÊèê‰æõ‰∫ÜÂº∫Â§ßÁöÑÁé∞ÂÆû‰∏ñÁïåÊ®°ÊãüÂô®Ôºå‰ΩÜÂú®Êú∫Âô®‰∫∫Êìç‰ΩúÁöÑÂèØÊéßÊÄßÊñπÈù¢‰ªçÁÑ∂ÊúâÈôê„ÄÇËøëÊúüÁöÑËΩ®ËøπÊù°‰ª∂ËßÜÈ¢ëÁîüÊàêÁ†îÁ©∂ËôΩÁÑ∂Â°´Ë°•‰∫ÜËøô‰∏ÄÁ©∫ÁôΩÔºå‰ΩÜÈÄöÂ∏∏‰æùËµñ‰∫é‰∫åÁª¥ËΩ®ËøπÊàñÂçï‰∏ÄÊ®°ÊÄÅÊù°‰ª∂ÔºåÈôêÂà∂‰∫ÜÂÖ∂ÁîüÊàêÂèØÊéß‰∏î‰∏ÄËá¥ÁöÑÊú∫Âô®‰∫∫ÊºîÁ§∫ÁöÑËÉΩÂäõ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜDRAW2ACTÔºå‰∏Ä‰∏™Ê∑±Â∫¶ÊÑüÁü•ÁöÑËΩ®ËøπÊù°‰ª∂ËßÜÈ¢ëÁîüÊàêÊ°ÜÊû∂Ôºå‰ªéËæìÂÖ•ËΩ®Ëøπ‰∏≠ÊèêÂèñÂ§ö‰∏™Ê≠£‰∫§Ë°®Á§∫ÔºåÊçïÊçâÊ∑±Â∫¶„ÄÅËØ≠‰πâ„ÄÅÂΩ¢Áä∂ÂíåËøêÂä®ÔºåÂπ∂Â∞ÜÂÖ∂Ê≥®ÂÖ•Êâ©Êï£Ê®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫ËÅîÂêàÁîüÊàêÁ©∫Èó¥ÂØπÈΩêÁöÑRGBÂíåÊ∑±Â∫¶ËßÜÈ¢ëÔºåÂà©Áî®Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÊú∫Âà∂ÂíåÊ∑±Â∫¶ÁõëÁù£Êù•Â¢ûÂº∫Êó∂Á©∫‰∏ÄËá¥ÊÄß„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ÂºïÂÖ•‰∏Ä‰∏™Â§öÊ®°ÊÄÅÁ≠ñÁï•Ê®°ÂûãÔºåÂü∫‰∫éÁîüÊàêÁöÑRGBÂíåÊ∑±Â∫¶Â∫èÂàóÂõûÂΩíÊú∫Âô®‰∫∫ÁöÑÂÖ≥ËäÇËßíÂ∫¶„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåDRAW2ACTÂú®ËßÜËßâ‰øùÁúüÂ∫¶Âíå‰∏ÄËá¥ÊÄßÊñπÈù¢‰ºò‰∫éÁé∞ÊúâÂü∫Á∫øÔºåÂêåÊó∂ÊèêÈ´ò‰∫ÜÊìç‰ΩúÊàêÂäüÁéá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâËΩ®ËøπÊù°‰ª∂ËßÜÈ¢ëÁîüÊàêÊñπÊ≥ïÂú®Êú∫Âô®‰∫∫ÊºîÁ§∫‰∏≠ÁöÑÂèØÊéßÊÄßÂíå‰∏ÄËá¥ÊÄß‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂ§ö‰æùËµñ‰∫é‰∫åÁª¥ËΩ®ËøπÊàñÂçï‰∏ÄÊ®°ÊÄÅÔºåÂØºËá¥ÁîüÊàêÁªìÊûúÁöÑÂ±ÄÈôêÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöDRAW2ACTÊ°ÜÊû∂ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÈÄöËøáÊ∑±Â∫¶ÊÑüÁü•ÁöÑËΩ®ËøπÊù°‰ª∂ÁîüÊàêËßÜÈ¢ëÔºåÊèêÂèñÂ§öÁßçÊ≠£‰∫§Ë°®Á§∫ÔºàÂ¶ÇÊ∑±Â∫¶„ÄÅËØ≠‰πâ„ÄÅÂΩ¢Áä∂ÂíåËøêÂä®ÔºâÔºåÂπ∂Â∞ÜÂÖ∂Ê≥®ÂÖ•Âà∞Êâ©Êï£Ê®°Âûã‰∏≠Ôºå‰ª•Â¢ûÂº∫ÁîüÊàêËßÜÈ¢ëÁöÑÂèØÊéßÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂ÂåÖÊã¨Â§ö‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈ¶ñÂÖàÔºå‰ªéËæìÂÖ•ËΩ®Ëøπ‰∏≠ÊèêÂèñÂ§öÊ®°ÊÄÅÁâπÂæÅÔºõÂÖ∂Ê¨°ÔºåÂà©Áî®Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÊú∫Âà∂ÁîüÊàêÁ©∫Èó¥ÂØπÈΩêÁöÑRGBÂíåÊ∑±Â∫¶ËßÜÈ¢ëÔºõÊúÄÂêéÔºåÂü∫‰∫éÁîüÊàêÁöÑËßÜÈ¢ëÂ∫èÂàóÂõûÂΩíÊú∫Âô®‰∫∫ÁöÑÂÖ≥ËäÇËßíÂ∫¶„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éËÅîÂêàÁîüÊàêRGBÂíåÊ∑±Â∫¶ËßÜÈ¢ëÔºåÂπ∂ÈÄöËøáË∑®Ê®°ÊÄÅÊ≥®ÊÑèÊú∫Âà∂ÂíåÊ∑±Â∫¶ÁõëÁù£Êù•Â¢ûÂº∫Êó∂Á©∫‰∏ÄËá¥ÊÄß„ÄÇËøô‰∏ÄËÆæËÆ°‰∏éÁé∞ÊúâÊñπÊ≥ïÁöÑÊú¨Ë¥®Âå∫Âà´Âú®‰∫éÂ§öÊ®°ÊÄÅËûçÂêàÁöÑÊ∑±Â∫¶ÊÑüÁü•ËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äÔºåÈááÁî®‰∫ÜÊ∑±Â∫¶ÁõëÁù£ÊçüÂ§±ÂáΩÊï∞‰ª•ÊèêÂçáÊ∑±Â∫¶‰ø°ÊÅØÁöÑÂáÜÁ°ÆÊÄßÔºåÂêåÊó∂ËÆæËÆ°‰∫ÜÁâπÂÆöÁöÑÁΩëÁªúÁªìÊûÑ‰ª•ÊîØÊåÅÂ§öÊ®°ÊÄÅÁâπÂæÅÁöÑÊèêÂèñÂíåËûçÂêà„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåDRAW2ACTÂú®ËßÜËßâ‰øùÁúüÂ∫¶Âíå‰∏ÄËá¥ÊÄßÊñπÈù¢ÊòæËëó‰ºò‰∫éÁé∞ÊúâÂü∫Á∫øÔºåÂÖ∑‰ΩìË°®Áé∞‰∏∫Âú®Êìç‰ΩúÊàêÂäüÁéá‰∏äÊèêÈ´ò‰∫ÜXX%ÔºàÂÖ∑‰ΩìÊï∞ÊçÆÊú™Áü•ÔºâÔºåÂπ∂Âú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Â±ïÁé∞Âá∫Êõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩÊú∫Âô®‰∫∫„ÄÅËá™Âä®ÂåñÁîü‰∫ßÁ∫øÂíå‰∫∫Êú∫‰∫§‰∫íÁ≠âÂú∫ÊôØ„ÄÇÈÄöËøáÊèêÂçáÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊìç‰ΩúËÉΩÂäõÔºåDRAW2ACTËÉΩÂ§ü‰∏∫ÂÆûÈôÖÂ∫îÁî®Êèê‰æõÊõ¥È´òÁöÑÁÅµÊ¥ªÊÄßÂíåÂèØÈù†ÊÄßÔºåÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Video diffusion models provide powerful real-world simulators for embodied AI but remain limited in controllability for robotic manipulation. Recent works on trajectory-conditioned video generation address this gap but often rely on 2D trajectories or single modality conditioning, which restricts their ability to produce controllable and consistent robotic demonstrations. We present DRAW2ACT, a depth-aware trajectory-conditioned video generation framework that extracts multiple orthogonal representations from the input trajectory, capturing depth, semantics, shape and motion, and injects them into the diffusion model. Moreover, we propose to jointly generate spatially aligned RGB and depth videos, leveraging cross-modality attention mechanisms and depth supervision to enhance the spatio-temporal consistency. Finally, we introduce a multimodal policy model conditioned on the generated RGB and depth sequences to regress the robot's joint angles. Experiments on Bridge V2, Berkeley Autolab, and simulation benchmarks show that DRAW2ACT achieves superior visual fidelity and consistency while yielding higher manipulation success rates compared to existing baselines.

