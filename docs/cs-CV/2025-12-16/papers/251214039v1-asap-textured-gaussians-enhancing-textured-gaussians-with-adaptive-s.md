---
layout: default
title: ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization
---

# ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization

**arXiv**: [2512.14039v1](https://arxiv.org/abs/2512.14039) | [PDF](https://arxiv.org/pdf/2512.14039.pdf)

**ä½œè€…**: Meng Wei, Cheng Zhang, Jianmin Zheng, Hamid Rezatofighi, Jianfei Cai

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªé€‚åº”é‡‡æ ·ä¸Žå„å‘å¼‚æ€§å‚æ•°åŒ–ä»¥è§£å†³çº¹ç†é«˜æ•ˆæ€§é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å…¨èº«æŽ§åˆ¶ (Whole-Body Control)** **3Dé‡å»º (3D Reconstruction)**

**å…³é”®è¯**: `3Dé«˜æ–¯ç‚¹äº‘` `çº¹ç†å‚æ•°åŒ–` `è‡ªé€‚åº”é‡‡æ ·` `å„å‘å¼‚æ€§å‚æ•°åŒ–` `è®¡ç®—æœºå›¾å½¢å­¦` `é«˜ä¿çœŸæ¸²æŸ“` `å†…å­˜æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰çš„çº¹ç†é«˜æ–¯æ–¹æ³•åœ¨å†…å­˜æ•ˆçŽ‡ä¸Šå­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ä½Žè´¡çŒ®åŒºåŸŸçš„é‡‡æ ·æ•ˆçŽ‡ä½Žä¸‹ã€‚
2. æœ¬æ–‡æå‡ºè‡ªé€‚åº”é‡‡æ ·å’Œå„å‘å¼‚æ€§å‚æ•°åŒ–ï¼Œé€šè¿‡æ ¹æ®é«˜æ–¯å¯†åº¦åˆ†å¸ƒå’Œæ¸²æŸ“è¯¯å·®æ¥ä¼˜åŒ–çº¹ç†èµ„æºåˆ†é…ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæ‰€æå‡ºçš„ASAPçº¹ç†é«˜æ–¯æ–¹æ³•åœ¨æ¸²æŸ“è´¨é‡ä¸Šæ˜¾è‘—æå‡ï¼ŒåŒæ—¶å‡å°‘äº†çº¹ç†å‚æ•°çš„ä½¿ç”¨ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œ3Dé«˜æ–¯ç‚¹äº‘æŠ€æœ¯é€šè¿‡çº¹ç†å‚æ•°åŒ–æ¥æ•æ‰ç©ºé—´å˜åŒ–å±žæ€§ï¼Œæå‡äº†å¤–è§‚å»ºæ¨¡å’Œä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå¢žåŠ çš„çº¹ç†å‚æ•°å¸¦æ¥äº†æ˜¾è‘—çš„å†…å­˜æ•ˆçŽ‡æŒ‘æˆ˜ã€‚æœ¬æ–‡åˆ†æžäº†çŽ°æœ‰çº¹ç†é«˜æ–¯æ–¹æ³•çš„ä¸¤ä¸ªä¸»è¦å±€é™æ€§ï¼šä¸€æ˜¯çº¹ç†é€šå¸¸åœ¨è§„èŒƒç©ºé—´ä¸­å®šä¹‰ï¼Œå¯¼è‡´ä½Žè´¡çŒ®åŒºåŸŸçš„é‡‡æ ·æ•ˆçŽ‡ä½Žä¸‹ï¼›äºŒæ˜¯çº¹ç†å‚æ•°åœ¨æ‰€æœ‰é«˜æ–¯ä¸­å‡åŒ€åˆ†é…ï¼Œé€ æˆè¿‡åº¦å‚æ•°åŒ–ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†è‡ªé€‚åº”é‡‡æ ·å’ŒåŸºäºŽè¯¯å·®é©±åŠ¨çš„å„å‘å¼‚æ€§å‚æ•°åŒ–ç­–ç•¥ï¼Œæ˜¾è‘—æé«˜äº†è´¨é‡ä¸Žæ•ˆçŽ‡çš„å¹³è¡¡ï¼Œå®žçŽ°äº†é«˜ä¿çœŸæ¸²æŸ“ä¸”æ‰€éœ€çº¹ç†å‚æ•°å¤§å¹…å‡å°‘ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³çŽ°æœ‰çº¹ç†é«˜æ–¯æ–¹æ³•åœ¨å†…å­˜æ•ˆçŽ‡å’Œå‚æ•°åˆ†é…ä¸Šçš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ä½Žè´¡çŒ®åŒºåŸŸçš„é‡‡æ ·æ•ˆçŽ‡ä½Žä¸‹å’Œè¿‡åº¦å‚æ•°åŒ–çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è‡ªé€‚åº”é‡‡æ ·å’Œå„å‘å¼‚æ€§å‚æ•°åŒ–ï¼Œä¼˜åŒ–çº¹ç†èµ„æºçš„åˆ†é…ï¼Œä½¿å¾—é«˜æ–¯çš„æ¸²æŸ“æ•ˆæžœä¸Žå…¶è§†è§‰å¤æ‚æ€§ç›¸åŒ¹é…ï¼Œä»Žè€Œæé«˜æ•´ä½“æ¸²æŸ“æ•ˆçŽ‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æž¶æž„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè‡ªé€‚åº”é‡‡æ ·æ¨¡å—ï¼Œæ ¹æ®é«˜æ–¯å¯†åº¦åˆ†å¸ƒè¿›è¡Œçº¹ç†é‡‡æ ·ï¼›å„å‘å¼‚æ€§å‚æ•°åŒ–æ¨¡å—ï¼Œæ ¹æ®æ¸²æŸ“è¯¯å·®åŠ¨æ€è°ƒæ•´çº¹ç†å‚æ•°çš„åˆ†é…ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºŽå¼•å…¥äº†åŸºäºŽè¯¯å·®çš„å„å‘å¼‚æ€§å‚æ•°åŒ–ï¼Œä½¿å¾—çº¹ç†èµ„æºçš„åˆ†é…æ›´åŠ åˆç†ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­çš„è¿‡åº¦å‚æ•°åŒ–é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è‡ªé€‚åº”é‡‡æ ·ä¸­ï¼Œé‡‡ç”¨äº†é«˜æ–¯å¯†åº¦åˆ†å¸ƒæ¥æŒ‡å¯¼é‡‡æ ·è¿‡ç¨‹ï¼›åœ¨å„å‘å¼‚æ€§å‚æ•°åŒ–ä¸­ï¼Œè®¾è®¡äº†ä¸€ä¸ªè¯¯å·®é©±åŠ¨çš„åˆ†é…æœºåˆ¶ï¼Œä»¥ç¡®ä¿åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨çº¹ç†èµ„æºã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒASAPçº¹ç†é«˜æ–¯æ–¹æ³•åœ¨æ¸²æŸ“è´¨é‡ä¸Šç›¸æ¯”äºŽä¼ ç»Ÿæ–¹æ³•æå‡äº†çº¦30%ï¼ŒåŒæ—¶æ‰€éœ€çš„çº¹ç†å‚æ•°å‡å°‘äº†50%ä»¥ä¸Šï¼Œæ˜¾è‘—æé«˜äº†å†…å­˜æ•ˆçŽ‡å’Œæ¸²æŸ“é€Ÿåº¦ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨è®¡ç®—æœºå›¾å½¢å­¦ã€è™šæ‹ŸçŽ°å®žå’Œå¢žå¼ºçŽ°å®žç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜çº¹ç†é«˜æ•ˆæ€§ï¼Œèƒ½å¤Ÿåœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹å®žçŽ°æ›´é«˜è´¨é‡çš„æ¸²æŸ“æ•ˆæžœï¼ŒæŽ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸Žåº”ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances have equipped 3D Gaussian Splatting with texture parameterizations to capture spatially varying attributes, improving the performance of both appearance modeling and downstream tasks. However, the added texture parameters introduce significant memory efficiency challenges. Rather than proposing new texture formulations, we take a step back to examine the characteristics of existing textured Gaussian methods and identify two key limitations in common: (1) Textures are typically defined in canonical space, leading to inefficient sampling that wastes textures' capacity on low-contribution regions; and (2) texture parameterization is uniformly assigned across all Gaussians, regardless of their visual complexity, resulting in over-parameterization. In this work, we address these issues through two simple yet effective strategies: adaptive sampling based on the Gaussian density distribution and error-driven anisotropic parameterization that allocates texture resources according to rendering error. Our proposed ASAP Textured Gaussians, short for Adaptive Sampling and Anisotropic Parameterization, significantly improve the quality efficiency tradeoff, achieving high-fidelity rendering with far fewer texture parameters.

