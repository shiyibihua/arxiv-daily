---
layout: default
title: The Devil is in Attention Sharing: Improving Complex Non-rigid Image Editing Faithfulness via Attention Synergy
---

# The Devil is in Attention Sharing: Improving Complex Non-rigid Image Editing Faithfulness via Attention Synergy

**arXiv**: [2512.14423v1](https://arxiv.org/abs/2512.14423) | [PDF](https://arxiv.org/pdf/2512.14423.pdf)

**ä½œè€…**: Zhuo Chen, Fanyue Wei, Runze Xu, Jingjing Li, Lixin Duan, Angela Yao, Wen Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Project page:https://synps26.github.io/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSynPSæ–¹æ³•ï¼Œé€šè¿‡æ³¨æ„åŠ›ååŒæœºåˆ¶è§£å†³å¤æ‚éžåˆšæ€§å›¾åƒç¼–è¾‘ä¸­çš„å¿ å®žæ€§é—®é¢˜**

**å…³é”®è¯**: `å›¾åƒç¼–è¾‘` `æ‰©æ•£æ¨¡åž‹` `æ³¨æ„åŠ›æœºåˆ¶` `éžåˆšæ€§å˜æ¢` `å¿ å®žæ€§è¯„ä¼°` `æ— è®­ç»ƒæ–¹æ³•` `è®¡ç®—æœºè§†è§‰` `äººå·¥æ™ºèƒ½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨å¤æ‚éžåˆšæ€§å›¾åƒç¼–è¾‘ä¸­å­˜åœ¨æ³¨æ„åŠ›å´©æºƒé—®é¢˜ï¼Œå¯¼è‡´è¿‡åº¦ç¼–è¾‘æˆ–ç¼–è¾‘ä¸è¶³ï¼Œå½±å“ç¼–è¾‘å¿ å®žæ€§ã€‚
2. æå‡ºSynPSæ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€è°ƒèŠ‚ä½ç½®åµŒå…¥å’Œè¯­ä¹‰ä¿¡æ¯çš„ååŒä½œç”¨ï¼Œå®žçŽ°ç¼–è¾‘å¹…åº¦è‡ªé€‚åº”æŽ§åˆ¶ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒSynPSåœ¨å…¬å…±å’Œæ–°åŸºå‡†ä¸Šæ˜¾è‘—æå‡ç¼–è¾‘å¿ å®žæ€§ï¼Œæœ‰æ•ˆå¹³è¡¡è¯­ä¹‰ä¿®æ”¹ä¸Žä¿çœŸåº¦ä¿æŒã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºŽå¤§åž‹æ‰©æ•£æ¨¡åž‹çš„æ— è®­ç»ƒå›¾åƒç¼–è¾‘å·²å˜å¾—å®žç”¨ï¼Œä½†å¿ å®žæ‰§è¡Œå¤æ‚éžåˆšæ€§ç¼–è¾‘ï¼ˆå¦‚å§¿æ€æˆ–å½¢çŠ¶å˜åŒ–ï¼‰ä»ç„¶æžå…·æŒ‘æˆ˜ã€‚æˆ‘ä»¬å‘çŽ°ä¸€ä¸ªå…³é”®æ ¹æœ¬åŽŸå› ï¼šçŽ°æœ‰æ³¨æ„åŠ›å…±äº«æœºåˆ¶ä¸­çš„æ³¨æ„åŠ›å´©æºƒï¼Œå…¶ä¸­ä½ç½®åµŒå…¥æˆ–è¯­ä¹‰ç‰¹å¾ä¸»å¯¼è§†è§‰å†…å®¹æ£€ç´¢ï¼Œå¯¼è‡´è¿‡åº¦ç¼–è¾‘æˆ–ç¼–è¾‘ä¸è¶³ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥SynPSï¼Œä¸€ç§ååŒåˆ©ç”¨ä½ç½®åµŒå…¥å’Œè¯­ä¹‰ä¿¡æ¯ä»¥å®žçŽ°å¿ å®žéžåˆšæ€§å›¾åƒç¼–è¾‘çš„æ–¹æ³•ã€‚æˆ‘ä»¬é¦–å…ˆæå‡ºä¸€ç§ç¼–è¾‘åº¦é‡ï¼Œé‡åŒ–æ¯ä¸ªåŽ»å™ªæ­¥éª¤æ‰€éœ€çš„ç¼–è¾‘å¹…åº¦ã€‚åŸºäºŽæ­¤åº¦é‡ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ³¨æ„åŠ›ååŒæµç¨‹ï¼ŒåŠ¨æ€è°ƒèŠ‚ä½ç½®åµŒå…¥çš„å½±å“ï¼Œä½¿SynPSèƒ½å¤Ÿå¹³è¡¡è¯­ä¹‰ä¿®æ”¹å’Œä¿çœŸåº¦ä¿æŒã€‚é€šè¿‡è‡ªé€‚åº”æ•´åˆä½ç½®å’Œè¯­ä¹‰çº¿ç´¢ï¼ŒSynPSæœ‰æ•ˆé¿å…è¿‡åº¦ç¼–è¾‘å’Œç¼–è¾‘ä¸è¶³ã€‚åœ¨å…¬å…±å’Œæ–°æž„å»ºçš„åŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®žéªŒè¯æ˜Žäº†æˆ‘ä»¬æ–¹æ³•çš„ä¼˜è¶Šæ€§èƒ½å’Œå¿ å®žæ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

SynPSçš„æ•´ä½“æ¡†æž¶åŸºäºŽæ‰©æ•£æ¨¡åž‹çš„æ— è®­ç»ƒå›¾åƒç¼–è¾‘æµç¨‹ï¼Œæ ¸å¿ƒåˆ›æ–°åœ¨äºŽæ³¨æ„åŠ›ååŒæœºåˆ¶ã€‚è¯¥æ–¹æ³•é¦–å…ˆå¼•å…¥ç¼–è¾‘åº¦é‡æ¥é‡åŒ–æ¯ä¸ªåŽ»å™ªæ­¥éª¤çš„ç¼–è¾‘éœ€æ±‚ï¼Œç„¶åŽè®¾è®¡åŠ¨æ€è°ƒåˆ¶æ¨¡å—ï¼Œæ ¹æ®åº¦é‡ç»“æžœè°ƒæ•´ä½ç½®åµŒå…¥åœ¨æ³¨æ„åŠ›å…±äº«ä¸­çš„æƒé‡ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå°†ä½ç½®åµŒå…¥å’Œè¯­ä¹‰ä¿¡æ¯ååŒæ•´åˆï¼Œé¿å…å•ä¸€å› ç´ ä¸»å¯¼å†…å®¹æ£€ç´¢ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œä¼ ç»Ÿæ–¹æ³•å¾€å¾€å›ºå®šä½ç½®æˆ–è¯­ä¹‰çš„è´¡çŒ®ï¼Œè€ŒSynPSé€šè¿‡è‡ªé€‚åº”è°ƒèŠ‚å®žçŽ°æ›´ç²¾ç»†çš„ç¼–è¾‘æŽ§åˆ¶ï¼Œä»Žè€Œæå‡å¤æ‚éžåˆšæ€§ç¼–è¾‘çš„å¿ å®žæ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨å…¬å…±åŸºå‡†å’Œæ–°æž„å»ºçš„æ•°æ®é›†ä¸Šï¼ŒSynPSè¡¨çŽ°å‡ºä¼˜è¶Šæ€§èƒ½ï¼Œæ˜¾è‘—å‡å°‘è¿‡åº¦ç¼–è¾‘å’Œç¼–è¾‘ä¸è¶³çŽ°è±¡ã€‚å®žéªŒç»“æžœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤æ‚éžåˆšæ€§ç¼–è¾‘ä»»åŠ¡ä¸­ï¼Œç¼–è¾‘å¿ å®žæ€§å¾—åˆ°å¤§å¹…æå‡ï¼Œæœ‰æ•ˆå¹³è¡¡è¯­ä¹‰ä¿®æ”¹ä¸Žå›¾åƒä¿çœŸåº¦ï¼ŒéªŒè¯äº†æ³¨æ„åŠ›ååŒæœºåˆ¶çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è®¡ç®—æœºè§†è§‰å’Œäººå·¥æ™ºèƒ½é¢†åŸŸå…·æœ‰å¹¿æ³›æ½œåœ¨åº”ç”¨ï¼Œå¦‚æ•°å­—åª’ä½“åˆ›ä½œä¸­çš„å›¾åƒç¼–è¾‘ã€è™šæ‹ŸçŽ°å®žå†…å®¹ç”Ÿæˆã€ä»¥åŠæœºå™¨äººè§†è§‰ç³»ç»Ÿçš„åœºæ™¯ç†è§£ä¸Žäº¤äº’ã€‚é€šè¿‡æå‡å¤æ‚éžåˆšæ€§ç¼–è¾‘çš„å¿ å®žæ€§ï¼Œå¯æ”¯æŒæ›´ç²¾å‡†çš„å›¾åƒä¿®æ”¹ä»»åŠ¡ï¼Œä¾‹å¦‚äººä½“å§¿æ€è°ƒæ•´ã€ç‰©ä½“å½¢çŠ¶å˜æ¢ç­‰ï¼Œä¸ºå®žé™…åº”ç”¨æä¾›æ›´å¯é çš„æŠ€æœ¯åŸºç¡€ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Training-free image editing with large diffusion models has become practical, yet faithfully performing complex non-rigid edits (e.g., pose or shape changes) remains highly challenging. We identify a key underlying cause: attention collapse in existing attention sharing mechanisms, where either positional embeddings or semantic features dominate visual content retrieval, leading to over-editing or under-editing.To address this issue, we introduce SynPS, a method that Synergistically leverages Positional embeddings and Semantic information for faithful non-rigid image editing. We first propose an editing measurement that quantifies the required editing magnitude at each denoising step. Based on this measurement, we design an attention synergy pipeline that dynamically modulates the influence of positional embeddings, enabling SynPS to balance semantic modifications and fidelity preservation.By adaptively integrating positional and semantic cues, SynPS effectively avoids both over- and under-editing. Extensive experiments on public and newly curated benchmarks demonstrate the superior performance and faithfulness of our approach.

