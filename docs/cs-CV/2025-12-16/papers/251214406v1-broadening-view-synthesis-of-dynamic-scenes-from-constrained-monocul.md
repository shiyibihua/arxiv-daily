---
layout: default
title: Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos
---

# Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos

**arXiv**: [2512.14406v1](https://arxiv.org/abs/2512.14406) | [PDF](https://arxiv.org/pdf/2512.14406.pdf)

**ä½œè€…**: Le Jiang, Shaotong Zhu, Yedi Luo, Shayda Moezzi, Sarah Ostadabbas

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºExpanDyNeRFæ¡†æž¶ï¼Œåˆ©ç”¨é«˜æ–¯æº…å°„å…ˆéªŒå’Œä¼ªçœŸå€¼ç”Ÿæˆç­–ç•¥ï¼Œè§£å†³åŠ¨æ€NeRFåœ¨å¤§è§†è§’æ—‹è½¬ä¸‹æ¸²æŸ“ä¸ç¨³å®šçš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `åŠ¨æ€ç¥žç»è¾å°„åœº` `æ–°è§†è§’åˆæˆ` `å•ç›®è§†é¢‘` `é«˜æ–¯æº…å°„å…ˆéªŒ` `ä¼ªçœŸå€¼ç”Ÿæˆ` `åˆæˆæ•°æ®é›†` `å¤§è§†è§’æ—‹è½¬` `æ¸²æŸ“ä¿çœŸåº¦`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰åŠ¨æ€NeRFæ–¹æ³•åœ¨å¤§è§†è§’æ—‹è½¬ä¸‹æ¸²æŸ“ä¸ç¨³å®šï¼Œå¯¼è‡´æ–°è§†è§’åˆæˆå¤±è´¥ï¼Œäº§ç”Ÿä¸çœŸå®žç»“æžœã€‚
2. ExpanDyNeRFç»“åˆé«˜æ–¯æº…å°„å…ˆéªŒå’Œä¼ªçœŸå€¼ç”Ÿæˆï¼Œä¼˜åŒ–å¯†åº¦å’Œé¢œè‰²ç‰¹å¾ï¼Œæå‡å¤§è§’åº¦è§†è§’ä¸‹çš„é‡å»ºè´¨é‡ã€‚
3. å®žéªŒæ˜¾ç¤ºï¼ŒExpanDyNeRFåœ¨SynDMå’ŒçœŸå®žæ•°æ®é›†ä¸Šï¼Œæ¸²æŸ“ä¿çœŸåº¦æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨æžç«¯è§†è§’åç§»ä¸‹ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨åŠ¨æ€ç¥žç»è¾å°„åœºï¼ˆNeRFï¼‰ç³»ç»Ÿä¸­ï¼Œå½“å‰æœ€å…ˆè¿›çš„æ–°è§†è§’åˆæˆæ–¹æ³•åœ¨æ˜¾è‘—è§†è§’åå·®ä¸‹å¸¸å¤±è´¥ï¼Œäº§ç”Ÿä¸ç¨³å®šå’Œä¸çœŸå®žçš„æ¸²æŸ“ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ‰©å±•åŠ¨æ€NeRFï¼ˆExpanDyNeRFï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå•ç›®NeRFæ¡†æž¶ï¼Œåˆ©ç”¨é«˜æ–¯æº…å°„å…ˆéªŒå’Œä¼ªçœŸå€¼ç”Ÿæˆç­–ç•¥ï¼Œä»¥å®žçŽ°å¤§è§’åº¦æ—‹è½¬ä¸‹çš„çœŸå®žåˆæˆã€‚ExpanDyNeRFä¼˜åŒ–å¯†åº¦å’Œé¢œè‰²ç‰¹å¾ï¼Œä»¥æ”¹è¿›ä»ŽæŒ‘æˆ˜æ€§è§†è§’çš„åœºæ™¯é‡å»ºã€‚æˆ‘ä»¬è¿˜æå‡ºäº†åˆæˆåŠ¨æ€å¤šè§†è§’ï¼ˆSynDMï¼‰æ•°æ®é›†ï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºŽåŠ¨æ€åœºæ™¯çš„åˆæˆå¤šè§†è§’æ•°æ®é›†ï¼Œå…·æœ‰æ˜Žç¡®çš„ä¾§è§†è§’ç›‘ç£ï¼Œé€šè¿‡åŸºäºŽGTA Vçš„è‡ªå®šä¹‰æ¸²æŸ“ç®¡çº¿åˆ›å»ºã€‚åœ¨SynDMå’ŒçœŸå®žä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®šé‡å’Œå®šæ€§ç»“æžœè¡¨æ˜Žï¼ŒExpanDyNeRFåœ¨æžç«¯è§†è§’åç§»ä¸‹çš„æ¸²æŸ“ä¿çœŸåº¦æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰åŠ¨æ€NeRFæ–¹æ³•ã€‚æ›´å¤šç»†èŠ‚è§è¡¥å……ææ–™ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

ExpanDyNeRFæ˜¯ä¸€ä¸ªå•ç›®NeRFæ¡†æž¶ï¼Œæ•´ä½“åŸºäºŽåŠ¨æ€ç¥žç»è¾å°„åœºï¼Œé€šè¿‡é«˜æ–¯æº…å°„å…ˆéªŒæä¾›å‡ ä½•çº¦æŸï¼Œå¹¶é‡‡ç”¨ä¼ªçœŸå€¼ç”Ÿæˆç­–ç•¥å¢žå¼ºè®­ç»ƒæ•°æ®ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬ï¼šå¼•å…¥é«˜æ–¯æº…å°„å…ˆéªŒä»¥ç¨³å®šå¤§è§†è§’ä¸‹çš„å¯†åº¦ä¼°è®¡ï¼Œä»¥åŠè®¾è®¡ä¼ªçœŸå€¼ç”Ÿæˆæœºåˆ¶æ¥æ¨¡æ‹Ÿå¤šè§†è§’ç›‘ç£ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œå®ƒä¸“é—¨é’ˆå¯¹å•ç›®è§†é¢‘è¾“å…¥ï¼Œé€šè¿‡å…ˆéªŒå’Œä¼ªçœŸå€¼ç­–ç•¥ï¼Œæœ‰æ•ˆç¼“è§£äº†è§†è§’åå·®å¯¼è‡´çš„æ¸²æŸ“ä¸ç¨³å®šæ€§ï¼Œè€Œæ— éœ€ä¾èµ–å¤šæ‘„åƒå¤´æˆ–å¤æ‚è¿åŠ¨æ¨¡åž‹ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨SynDMæ•°æ®é›†ä¸Šï¼ŒExpanDyNeRFåœ¨æžç«¯è§†è§’åç§»ä¸‹çš„æ¸²æŸ“ä¿çœŸåº¦æ˜¾è‘—æå‡ï¼Œå®šé‡æŒ‡æ ‡ä¼˜äºŽçŽ°æœ‰åŠ¨æ€NeRFæ–¹æ³•ï¼Œå®šæ€§ç»“æžœå±•ç¤ºæ›´ç¨³å®šå’ŒçœŸå®žçš„åˆæˆæ•ˆæžœã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽè™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žå’Œæœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸï¼Œé€šè¿‡å•ç›®è§†é¢‘å®žçŽ°åŠ¨æ€åœºæ™¯çš„é«˜è´¨é‡æ–°è§†è§’åˆæˆï¼Œæå‡æ²‰æµ¸å¼ä½“éªŒå’Œåœºæ™¯ç†è§£èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In dynamic Neural Radiance Fields (NeRF) systems, state-of-the-art novel view synthesis methods often fail under significant viewpoint deviations, producing unstable and unrealistic renderings. To address this, we introduce Expanded Dynamic NeRF (ExpanDyNeRF), a monocular NeRF framework that leverages Gaussian splatting priors and a pseudo-ground-truth generation strategy to enable realistic synthesis under large-angle rotations. ExpanDyNeRF optimizes density and color features to improve scene reconstruction from challenging perspectives. We also present the Synthetic Dynamic Multiview (SynDM) dataset, the first synthetic multiview dataset for dynamic scenes with explicit side-view supervision-created using a custom GTA V-based rendering pipeline. Quantitative and qualitative results on SynDM and real-world datasets demonstrate that ExpanDyNeRF significantly outperforms existing dynamic NeRF methods in rendering fidelity under extreme viewpoint shifts. Further details are provided in the supplementary materials.

