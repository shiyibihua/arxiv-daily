---
layout: default
title: FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation
---

# FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.14162" target="_blank" class="toolbar-btn">arXiv: 2512.14162v1</a>
    <a href="https://arxiv.org/pdf/2512.14162.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14162v1" 
            onclick="toggleFavorite(this, '2512.14162v1', 'FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Qingyuan Cai, Linxin Zhang, Xuecai Hu, Saihui Hou, Yongzhen Huang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-16

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/Andyen512/Fast3DHPE)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**FastDDHPoseÔºöÁªü‰∏Ä„ÄÅÈ´òÊïà„ÄÅËß£ËÄ¶ÁöÑ3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°` `Êâ©Êï£Ê®°Âûã` `Ëß£ËÄ¶Ë°®Á§∫` `ËøêÂä®Â≠¶Â±ÇÁ∫ß` `ÂçïÁõÆËßÜËßâ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÊñπÊ≥ïÁº∫‰πèÁªü‰∏ÄÁöÑËÆ≠ÁªÉÂíåËØÑ‰º∞Ê°ÜÊû∂ÔºåÈöæ‰ª•ËøõË°åÂÖ¨Âπ≥ÊØîËæÉÔºå‰∏îËÆ≠ÁªÉÊïàÁéáÊúâÂæÖÊèêÈ´ò„ÄÇ
2. FastDDHPoseÂà©Áî®Êâ©Êï£Ê®°ÂûãËß£ËÄ¶Âª∫Ê®°È™®È™ºÈïøÂ∫¶ÂíåÊñπÂêëÔºåÈÅøÂÖçÂ±ÇÁ∫ßËØØÂ∑ÆÁ¥ØÁßØÔºåÂπ∂ËÆæËÆ°È´òÊïàÂéªÂô™Âô®ÂÖ≥Ê≥®ËøêÂä®Â≠¶ÂÖ≥ËäÇÂ±ÇÁ∫ß„ÄÇ
3. FastDDHPoseÂú®Human3.6MÂíåMPI-INF-3DHPÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜSOTAÊÄßËÉΩÔºåÂπ∂Â±ïÁé∞Âá∫ËâØÂ•ΩÁöÑÊ≥õÂåñÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫Fast3DHPEÔºå‰∏Ä‰∏™Ê®°ÂùóÂåñÊ°ÜÊû∂ÔºåÊó®Âú®‰øÉËøõÂçïÁõÆ3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°Ôºà3D HPEÔºâÁöÑÂø´ÈÄüÂ§çÁé∞ÂíåÁÅµÊ¥ªÂºÄÂèëÔºåËß£ÂÜ≥Áé∞ÊúâÊñπÊ≥ïËÆ≠ÁªÉÂíåËØÑ‰º∞Ê°ÜÊû∂‰∏çÁªü‰∏ÄÔºåÁº∫‰πèÂÖ¨Âπ≥ÊØîËæÉÁöÑÈóÆÈ¢ò„ÄÇFast3DHPEÊ†áÂáÜÂåñ‰∫ÜËÆ≠ÁªÉÂíåËØÑ‰º∞ÊµÅÁ®ãÔºåÊòæËëóÊèêÈ´ò‰∫ÜËÆ≠ÁªÉÊïàÁéáÔºåÂπ∂ÊîØÊåÅÂêÑÁßç3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÊñπÊ≥ïÁöÑÂÖ¨Âπ≥ÊØîËæÉ„ÄÇÂú®Ê≠§Ê°ÜÊû∂‰∏ãÔºåÊú¨ÊñáËøõ‰∏ÄÊ≠•ÊèêÂá∫‰∫ÜFastDDHPoseÔºå‰∏ÄÁßçÂü∫‰∫éËß£ËÄ¶Êâ©Êï£ÁöÑ3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÊñπÊ≥ïÔºåÂà©Áî®Êâ©Êï£Ê®°ÂûãÂº∫Â§ßÁöÑÊΩúÂú®ÂàÜÂ∏ÉÂª∫Ê®°ËÉΩÂäõÔºåÊòæÂºèÂú∞ÂØπÈ™®È™ºÈïøÂ∫¶ÂíåÈ™®È™ºÊñπÂêëÁöÑÂàÜÂ∏ÉËøõË°åÂª∫Ê®°ÔºåÈÅøÂÖç‰∫ÜÂ±ÇÁ∫ßËØØÂ∑ÆÁ¥ØÁßØÁöÑËøõ‰∏ÄÊ≠•ÊîæÂ§ß„ÄÇÊ≠§Â§ñÔºåËÆæËÆ°‰∫Ü‰∏ÄÁßçÈ´òÊïàÁöÑËøêÂä®Â≠¶Â±ÇÁ∫ßÊó∂Á©∫ÂéªÂô™Âô®ÔºåÈºìÂä±Ê®°ÂûãÂÖ≥Ê≥®ËøêÂä®Â≠¶ÂÖ≥ËäÇÂ±ÇÁ∫ßÔºåÈÅøÂÖçÂØπËøá‰∫éÂ§çÊùÇÁöÑÂÖ≥ËäÇÊãìÊâëËøõË°å‰∏çÂøÖË¶ÅÁöÑÂª∫Ê®°„ÄÇÂú®Human3.6MÂíåMPI-INF-3DHP‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåFast3DHPEÊ°ÜÊû∂ËÉΩÂ§üÂÆûÁé∞ÊâÄÊúâÊñπÊ≥ïÁöÑÂÖ¨Âπ≥ÊØîËæÉÔºåÂπ∂ÊòæËëóÊèêÈ´òËÆ≠ÁªÉÊïàÁéá„ÄÇÂú®Áªü‰∏ÄÊ°ÜÊû∂‰∏ãÔºåFastDDHPoseÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂπ∂Âú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÂÖ∑ÊúâÂæàÂº∫ÁöÑÊ≥õÂåñÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂçïÁõÆ3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÊñπÊ≥ïÈÄöÂ∏∏Âú®‰∏çÂêåÁöÑÊ°ÜÊû∂‰∏ãËøõË°åËÆ≠ÁªÉÂíåËØÑ‰º∞ÔºåÁº∫‰πè‰∏Ä‰∏™Áªü‰∏ÄÁöÑÂπ≥Âè∞ËøõË°åÂÖ¨Âπ≥ÊØîËæÉ„ÄÇÊ≠§Â§ñÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Âª∫Ê®°‰∫∫‰ΩìÂßøÊÄÅÊó∂ÔºåÂÆπÊòìÂèóÂà∞Â±ÇÁ∫ßËØØÂ∑ÆÁ¥ØÁßØÁöÑÂΩ±ÂìçÔºåÂπ∂‰∏îÂèØËÉΩÂØπËøá‰∫éÂ§çÊùÇÁöÑÂÖ≥ËäÇÊãìÊâëËøõË°å‰∏çÂøÖË¶ÅÁöÑÂª∫Ê®°ÔºåÂØºËá¥ÊïàÁéáÈôç‰Ωé„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂Fast3DHPEÔºåÁî®‰∫éÂÖ¨Âπ≥Âú∞ËØÑ‰º∞ÂíåÊØîËæÉ‰∏çÂêåÁöÑ3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÊñπÊ≥ïÔºåÂπ∂Âú®Ê≠§Âü∫Á°Ä‰∏äÊèêÂá∫FastDDHPoseÔºåÂà©Áî®Ëß£ËÄ¶Êâ©Êï£Ê®°ÂûãÊòæÂºèÂú∞Âª∫Ê®°È™®È™ºÈïøÂ∫¶ÂíåÊñπÂêëÔºå‰ªéËÄåÈÅøÂÖçÂ±ÇÁ∫ßËØØÂ∑ÆÁ¥ØÁßØ„ÄÇÂêåÊó∂ÔºåËÆæËÆ°È´òÊïàÁöÑÂéªÂô™Âô®Ôºå‰∏ìÊ≥®‰∫éËøêÂä®Â≠¶ÂÖ≥ËäÇÂ±ÇÁ∫ßÔºåÂáèÂ∞ë‰∏çÂøÖË¶ÅÁöÑËÆ°ÁÆóÂºÄÈîÄ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöFast3DHPEÊ°ÜÊû∂ÂåÖÂê´Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ„ÄÅÊ®°ÂûãËÆ≠ÁªÉ„ÄÅÊ®°ÂûãËØÑ‰º∞Á≠âÊ®°ÂùóÔºåÊèê‰æõÊ†áÂáÜÂåñÁöÑÊé•Âè£ÂíåÊµÅÁ®ãÔºåÊñπ‰æøÁ†îÁ©∂‰∫∫ÂëòÂø´ÈÄüÂ§çÁé∞ÂíåÂºÄÂèëÊñ∞ÁöÑ3D‰∫∫‰ΩìÂßøÊÄÅ‰º∞ËÆ°ÊñπÊ≥ï„ÄÇFastDDHPoseÊ®°ÂûãÂàôÂü∫‰∫éÊâ©Êï£Ê®°ÂûãÔºåÈÄöËøáËø≠‰ª£ÂéªÂô™ÁöÑÊñπÂºè‰ªéÂô™Â£∞‰∏≠ÁîüÊàê3D‰∫∫‰ΩìÂßøÊÄÅ„ÄÇËØ•Ê®°ÂûãÂåÖÂê´‰∏Ä‰∏™ÁºñÁ†ÅÂô®ÔºåÁî®‰∫éÂ∞Ü2DÂÖ≥ÈîÆÁÇπÂ∫èÂàóÊò†Â∞ÑÂà∞ÊΩúÂú®Á©∫Èó¥Ôºõ‰∏Ä‰∏™Êâ©Êï£Ê®°ÂûãÔºåÁî®‰∫éÂª∫Ê®°ÊΩúÂú®Á©∫Èó¥‰∏≠È™®È™ºÈïøÂ∫¶ÂíåÊñπÂêëÁöÑÂàÜÂ∏ÉÔºõ‰ª•Âèä‰∏Ä‰∏™Ëß£Á†ÅÂô®ÔºåÁî®‰∫éÂ∞ÜÊΩúÂú®Á©∫Èó¥‰∏≠ÁöÑË°®Á§∫Êò†Â∞ÑÂõû3D‰∫∫‰ΩìÂßøÊÄÅ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöFastDDHPoseÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ΩøÁî®Ëß£ËÄ¶Êâ©Êï£Ê®°ÂûãÊòæÂºèÂú∞Âª∫Ê®°È™®È™ºÈïøÂ∫¶ÂíåÊñπÂêë„ÄÇ‰∏éÁõ¥Êé•ÂõûÂΩí3DÂßøÊÄÅÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåËøôÁßçÊñπÊ≥ïÂèØ‰ª•Êõ¥Â•ΩÂú∞ÊçïÊçâ‰∫∫‰ΩìÂßøÊÄÅÁöÑÂÜÖÂú®ÁªìÊûÑÔºåÂπ∂ÈÅøÂÖçÂ±ÇÁ∫ßËØØÂ∑ÆÁ¥ØÁßØ„ÄÇÊ≠§Â§ñÔºåÈ´òÊïàÁöÑËøêÂä®Â≠¶Â±ÇÁ∫ßÊó∂Á©∫ÂéªÂô™Âô®ËÉΩÂ§üÂáèÂ∞ë‰∏çÂøÖË¶ÅÁöÑËÆ°ÁÆóÔºåÊèêÈ´òÊ®°ÂûãÁöÑÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöFastDDHPose‰ΩøÁî®‰∫Ü‰∏ÄÁßçÂü∫‰∫éTransformerÁöÑÁºñÁ†ÅÂô®ÂíåËß£Á†ÅÂô®ÔºåÁî®‰∫éÂ§ÑÁêÜ2DÂÖ≥ÈîÆÁÇπÂ∫èÂàóÂíåÊΩúÂú®Á©∫Èó¥‰∏≠ÁöÑË°®Á§∫„ÄÇÊâ©Êï£Ê®°ÂûãÈááÁî®U-NetÁªìÊûÑÔºåÂπ∂ÂºïÂÖ•‰∫ÜÊ≥®ÊÑèÂäõÊú∫Âà∂Ôºå‰ª•Êõ¥Â•ΩÂú∞ÊçïÊçâÈ™®È™ºÈïøÂ∫¶ÂíåÊñπÂêë‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÈáçÂª∫ÊçüÂ§±ÂíåÊâ©Êï£ÊçüÂ§±ÔºåÁî®‰∫é‰ºòÂåñÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇËøêÂä®Â≠¶Â±ÇÁ∫ßÊó∂Á©∫ÂéªÂô™Âô®ÈÄöËøámaskÊú∫Âà∂Ôºå‰ΩøÂæóÊ®°ÂûãÊõ¥Âä†ÂÖ≥Ê≥®ÈáçË¶ÅÁöÑËøêÂä®Â≠¶ÂÖ≥ËäÇÂ±ÇÁ∫ß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

FastDDHPoseÂú®Human3.6MÂíåMPI-INF-3DHPÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Üstate-of-the-artÁöÑÊÄßËÉΩ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåFastDDHPoseÂú®‰øùËØÅÁ≤æÂ∫¶ÁöÑÂêåÊó∂ÔºåÊòæËëóÊèêÈ´ò‰∫ÜËÆ≠ÁªÉÊïàÁéá„ÄÇÊ≠§Â§ñÔºåFastDDHPoseÂú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫ÂæàÂº∫ÁöÑÊ≥õÂåñÊÄßÂíåÈ≤ÅÊ£íÊÄßÔºå‰ºò‰∫éÂÖ∂‰ªñÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫é‰∫∫Êú∫‰∫§‰∫í„ÄÅËôöÊãüÁé∞ÂÆû„ÄÅËøêÂä®ÂàÜÊûê„ÄÅÊ∏∏ÊàèÂºÄÂèëÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÂáÜÁ°ÆÈ´òÊïàÂú∞‰º∞ËÆ°‰∫∫‰ΩìÂßøÊÄÅÔºåÂèØ‰ª•ÂÆûÁé∞Êõ¥Ëá™ÁÑ∂ÁöÑ‰∫∫Êú∫‰∫§‰∫íÔºåÊèêÂçáËôöÊãüÁé∞ÂÆû‰ΩìÈ™åÔºåËæÖÂä©ËøêÂä®ÂëòËøõË°åËÆ≠ÁªÉÂàÜÊûêÔºåÂπ∂‰∏∫Ê∏∏ÊàèËßíËâ≤Êèê‰æõÊõ¥ÈÄºÁúüÁöÑÂä®‰Ωú„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent approaches for monocular 3D human pose estimation (3D HPE) have achieved leading performance by directly regressing 3D poses from 2D keypoint sequences. Despite the rapid progress in 3D HPE, existing methods are typically trained and evaluated under disparate frameworks, lacking a unified framework for fair comparison. To address these limitations, we propose Fast3DHPE, a modular framework that facilitates rapid reproduction and flexible development of new methods. By standardizing training and evaluation protocols, Fast3DHPE enables fair comparison across 3D human pose estimation methods while significantly improving training efficiency. Within this framework, we introduce FastDDHPose, a Disentangled Diffusion-based 3D Human Pose Estimation method which leverages the strong latent distribution modeling capability of diffusion models to explicitly model the distributions of bone length and bone direction while avoiding further amplification of hierarchical error accumulation. Moreover, we design an efficient Kinematic-Hierarchical Spatial and Temporal Denoiser that encourages the model to focus on kinematic joint hierarchies while avoiding unnecessary modeling of overly complex joint topologies. Extensive experiments on Human3.6M and MPI-INF-3DHP show that the Fast3DHPE framework enables fair comparison of all methods while significantly improving training efficiency. Within this unified framework, FastDDHPose achieves state-of-the-art performance with strong generalization and robustness in in-the-wild scenarios. The framework and models will be released at: https://github.com/Andyen512/Fast3DHPE

