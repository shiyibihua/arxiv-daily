---
layout: default
title: FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation
---

# FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation

**arXiv**: [2512.14162v1](https://arxiv.org/abs/2512.14162) | [PDF](https://arxiv.org/pdf/2512.14162.pdf)

**ä½œè€…**: Qingyuan Cai, Linxin Zhang, Xuecai Hu, Saihui Hou, Yongzhen Huang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Andyen512/Fast3DHPE)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFastDDHPoseæ¡†æž¶ï¼Œé€šè¿‡è§£è€¦æ‰©æ•£æ¨¡åž‹å®žçŽ°é«˜æ•ˆã€ç»Ÿä¸€çš„å•ç›®3Däººä½“å§¿æ€ä¼°è®¡ã€‚**

**å…³é”®è¯**: `3Däººä½“å§¿æ€ä¼°è®¡` `æ‰©æ•£æ¨¡åž‹` `è§£è€¦å­¦ä¹ ` `å•ç›®è§†è§‰` `è¿åŠ¨åˆ†æž` `æ·±åº¦å­¦ä¹ æ¡†æž¶` `è®¡ç®—æœºè§†è§‰` `æœºå™¨äººæ„ŸçŸ¥`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•ç¼ºä¹ç»Ÿä¸€æ¡†æž¶ï¼Œå¯¼è‡´è®­ç»ƒå’Œè¯„ä¼°åˆ†æ•£ï¼Œéš¾ä»¥å…¬å¹³æ¯”è¾ƒã€‚
2. æå‡ºFastDDHPoseï¼Œåˆ©ç”¨è§£è€¦æ‰©æ•£æ¨¡åž‹æ˜¾å¼å»ºæ¨¡éª¨éª¼é•¿åº¦å’Œæ–¹å‘åˆ†å¸ƒï¼Œé¿å…è¯¯å·®ç´¯ç§¯ã€‚
3. åœ¨Human3.6Må’ŒMPI-INF-3DHPæ•°æ®é›†ä¸Šå®žçŽ°SOTAæ€§èƒ½ï¼Œæ˜¾è‘—æå‡è®­ç»ƒæ•ˆçŽ‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼ŒåŸºäºŽ2Då…³é”®ç‚¹åºåˆ—ç›´æŽ¥å›žå½’3Då§¿æ€çš„å•ç›®3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•å–å¾—äº†é¢†å…ˆæ€§èƒ½ã€‚å°½ç®¡3D HPEè¿›å±•è¿…é€Ÿï¼ŒçŽ°æœ‰æ–¹æ³•é€šå¸¸åœ¨åˆ†æ•£çš„æ¡†æž¶ä¸‹è®­ç»ƒå’Œè¯„ä¼°ï¼Œç¼ºä¹ç»Ÿä¸€çš„å…¬å¹³æ¯”è¾ƒæ¡†æž¶ã€‚ä¸ºè§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºFast3DHPEï¼Œä¸€ä¸ªæ¨¡å—åŒ–æ¡†æž¶ï¼Œä¾¿äºŽå¿«é€Ÿå¤çŽ°å’Œçµæ´»å¼€å‘æ–°æ–¹æ³•ã€‚é€šè¿‡æ ‡å‡†åŒ–è®­ç»ƒå’Œè¯„ä¼°åè®®ï¼ŒFast3DHPEå®žçŽ°äº†3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•çš„å…¬å¹³æ¯”è¾ƒï¼ŒåŒæ—¶æ˜¾è‘—æé«˜è®­ç»ƒæ•ˆçŽ‡ã€‚åœ¨æ­¤æ¡†æž¶å†…ï¼Œæˆ‘ä»¬å¼•å…¥FastDDHPoseï¼Œä¸€ç§åŸºäºŽè§£è€¦æ‰©æ•£çš„3Däººä½“å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡åž‹çš„å¼ºå¤§æ½œåœ¨åˆ†å¸ƒå»ºæ¨¡èƒ½åŠ›ï¼Œæ˜¾å¼å»ºæ¨¡éª¨éª¼é•¿åº¦å’Œéª¨éª¼æ–¹å‘çš„åˆ†å¸ƒï¼ŒåŒæ—¶é¿å…è¿›ä¸€æ­¥æ”¾å¤§å±‚æ¬¡è¯¯å·®ç´¯ç§¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé«˜æ•ˆçš„åŠ¨åŠ›å­¦-å±‚æ¬¡ç©ºé—´å’Œæ—¶é—´åŽ»å™ªå™¨ï¼Œé¼“åŠ±æ¨¡åž‹å…³æ³¨åŠ¨åŠ›å­¦å…³èŠ‚å±‚æ¬¡ï¼ŒåŒæ—¶é¿å…å¯¹è¿‡äºŽå¤æ‚çš„å…³èŠ‚æ‹“æ‰‘è¿›è¡Œä¸å¿…è¦çš„å»ºæ¨¡ã€‚åœ¨Human3.6Må’ŒMPI-INF-3DHPä¸Šçš„å¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒFast3DHPEæ¡†æž¶å®žçŽ°äº†æ‰€æœ‰æ–¹æ³•çš„å…¬å¹³æ¯”è¾ƒï¼ŒåŒæ—¶æ˜¾è‘—æé«˜è®­ç»ƒæ•ˆçŽ‡ã€‚åœ¨æ­¤ç»Ÿä¸€æ¡†æž¶å†…ï¼ŒFastDDHPoseåœ¨é‡Žå¤–åœºæ™¯ä¸­å®žçŽ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…·æœ‰å¼ºå¤§çš„æ³›åŒ–æ€§å’Œé²æ£’æ€§ã€‚æ¡†æž¶å’Œæ¨¡åž‹å°†åœ¨https://github.com/Andyen512/Fast3DHPEå‘å¸ƒã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

è®ºæ–‡æå‡ºFast3DHPEç»Ÿä¸€æ¡†æž¶ï¼Œæ ‡å‡†åŒ–è®­ç»ƒå’Œè¯„ä¼°åè®®ï¼Œä¿ƒè¿›æ–¹æ³•å…¬å¹³æ¯”è¾ƒã€‚æ ¸å¿ƒæ–¹æ³•FastDDHPoseåŸºäºŽè§£è€¦æ‰©æ•£æ¨¡åž‹ï¼Œå°†3Då§¿æ€åˆ†è§£ä¸ºéª¨éª¼é•¿åº¦å’Œæ–¹å‘ä¸¤ä¸ªç‹¬ç«‹åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œåˆ©ç”¨æ‰©æ•£è¿‡ç¨‹çš„æ½œåœ¨åˆ†å¸ƒèƒ½åŠ›å‡å°‘å±‚æ¬¡è¯¯å·®ã€‚å…³é”®åˆ›æ–°åŒ…æ‹¬åŠ¨åŠ›å­¦-å±‚æ¬¡ç©ºé—´å’Œæ—¶é—´åŽ»å™ªå™¨ï¼Œä¼˜åŒ–å…³èŠ‚å±‚æ¬¡å…³æ³¨ï¼Œé¿å…å¤æ‚æ‹“æ‰‘å»ºæ¨¡ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•é€šè¿‡æ¨¡å—åŒ–è®¾è®¡å’Œè§£è€¦ç­–ç•¥ï¼Œæé«˜äº†æ•ˆçŽ‡å’Œé²æ£’æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨Human3.6Må’ŒMPI-INF-3DHPæ•°æ®é›†ä¸Šï¼ŒFastDDHPoseå®žçŽ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œè®­ç»ƒæ•ˆçŽ‡æ˜¾è‘—æå‡ï¼Œå¹¶åœ¨é‡Žå¤–åœºæ™¯ä¸­å±•ç¤ºå¼ºæ³›åŒ–æ€§å’Œé²æ£’æ€§ï¼Œæ”¯æŒå…¬å¹³æ–¹æ³•æ¯”è¾ƒã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽè™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žã€è¿åŠ¨åˆ†æžã€äººæœºäº¤äº’å’ŒåŠ¨ç”»åˆ¶ä½œç­‰é¢†åŸŸï¼Œä¸ºå®žæ—¶3Då§¿æ€ä¼°è®¡æä¾›é«˜æ•ˆè§£å†³æ–¹æ¡ˆï¼Œæå‡åœ¨å¤æ‚åœºæ™¯ä¸‹çš„å®žé™…åº”ç”¨ä»·å€¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent approaches for monocular 3D human pose estimation (3D HPE) have achieved leading performance by directly regressing 3D poses from 2D keypoint sequences. Despite the rapid progress in 3D HPE, existing methods are typically trained and evaluated under disparate frameworks, lacking a unified framework for fair comparison. To address these limitations, we propose Fast3DHPE, a modular framework that facilitates rapid reproduction and flexible development of new methods. By standardizing training and evaluation protocols, Fast3DHPE enables fair comparison across 3D human pose estimation methods while significantly improving training efficiency. Within this framework, we introduce FastDDHPose, a Disentangled Diffusion-based 3D Human Pose Estimation method which leverages the strong latent distribution modeling capability of diffusion models to explicitly model the distributions of bone length and bone direction while avoiding further amplification of hierarchical error accumulation. Moreover, we design an efficient Kinematic-Hierarchical Spatial and Temporal Denoiser that encourages the model to focus on kinematic joint hierarchies while avoiding unnecessary modeling of overly complex joint topologies. Extensive experiments on Human3.6M and MPI-INF-3DHP show that the Fast3DHPE framework enables fair comparison of all methods while significantly improving training efficiency. Within this unified framework, FastDDHPose achieves state-of-the-art performance with strong generalization and robustness in in-the-wild scenarios. The framework and models will be released at: https://github.com/Andyen512/Fast3DHPE

