---
layout: default
title: Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers
---

# Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers

**arXiv**: [2512.14026v1](https://arxiv.org/abs/2512.14026) | [PDF](https://arxiv.org/pdf/2512.14026.pdf)

**ä½œè€…**: Yibing Fu, Yunpeng Zhao, Zhitao Zeng, Cheng Chen, Yueming Jin

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCITabæ¡†æž¶ä»¥è§£å†³è·¨é˜Ÿåˆ—å›¾åƒ-è¡¨æ ¼è‡ªç›‘ç£å­¦ä¹ ä¸­çš„å¼‚æž„è¡¨æ ¼æ•°æ®å»ºæ¨¡éšœç¢é—®é¢˜ã€‚**

**å…³é”®è¯**: `è‡ªç›‘ç£å­¦ä¹ ` `å¤šæ¨¡æ€èžåˆ` `åŒ»å­¦å›¾åƒåˆ†æž` `è¡¨æ ¼æ•°æ®å¤„ç†` `è·¨é˜Ÿåˆ—å­¦ä¹ ` `å¼‚æž„æ•°æ®å»ºæ¨¡` `é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­` `è¯­ä¹‰æ„ŸçŸ¥å»ºæ¨¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨å›¾åƒ-è¡¨æ ¼å¤šæ¨¡æ€å­¦ä¹ ä¸­é¢ä¸´è·¨é˜Ÿåˆ—è¿ç§»å›°éš¾ï¼Œä¸»è¦ç”±äºŽå¼‚æž„è¡¨æ ¼æ•°æ®çš„åƒµåŒ–å»ºæ¨¡æœºåˆ¶é˜»ç¢äº†çŸ¥è¯†å…±äº«ã€‚
2. CITabæ¡†æž¶é€šè¿‡è¯­ä¹‰æ„ŸçŸ¥çš„è¡¨æ ¼å»ºæ¨¡æ•´åˆåˆ—æ ‡é¢˜ä½œä¸ºè¯­ä¹‰çº¿ç´¢ï¼Œå¹¶å¼•å…¥åŽŸåž‹å¼•å¯¼çš„çº¿æ€§æ··åˆå±‚æ¨¡å—ï¼Œä»¥ä¸“ä¸šåŒ–å¤„ç†è¡¨æ ¼æ•°æ®å¼‚æž„æ€§ã€‚
3. åœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­ä»»åŠ¡ä¸­ï¼ŒCITabåœ¨ä¸‰ä¸ªå…¬å¼€é˜Ÿåˆ—ä¸Šè¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæ•´åˆåŒ»å­¦å›¾åƒå’Œè¡¨æ ¼æ•°æ®çš„å¤šæ¨¡æ€å­¦ä¹ æ˜¾è‘—æŽ¨åŠ¨äº†ä¸´åºŠå†³ç­–çš„è¿›æ­¥ã€‚è‡ªç›‘ç£å­¦ä¹ å·²æˆä¸ºåœ¨è¿™äº›å¤§è§„æ¨¡æœªæ ‡è®°å›¾åƒ-è¡¨æ ¼æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„å¼ºå¤§èŒƒå¼ï¼Œæ—¨åœ¨å­¦ä¹ åˆ¤åˆ«æ€§è¡¨ç¤ºã€‚ç„¶è€Œï¼ŒçŽ°æœ‰çš„å›¾åƒ-è¡¨æ ¼è¡¨ç¤ºå­¦ä¹ è‡ªç›‘ç£æ–¹æ³•é€šå¸¸å±€é™äºŽç‰¹å®šæ•°æ®é˜Ÿåˆ—ï¼Œä¸»è¦ç”±äºŽå…¶åœ¨å»ºæ¨¡å¼‚æž„è¡¨æ ¼æ•°æ®æ—¶é‡‡ç”¨åƒµåŒ–çš„è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ã€‚è¿™ç§è·¨è¡¨æ ¼éšœç¢é˜»ç¢äº†å¤šæ¨¡æ€è‡ªç›‘ç£æ–¹æ³•æœ‰æ•ˆå­¦ä¹ è·¨ä¸åŒé˜Ÿåˆ—å…±äº«çš„å¯è¿ç§»åŒ»å­¦çŸ¥è¯†ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç›‘ç£å­¦ä¹ æ¡†æž¶ï¼Œå³CITabï¼Œæ—¨åœ¨ä»¥è·¨è¡¨æ ¼æ–¹å¼å­¦ä¹ å¼ºå¤§çš„å¤šæ¨¡æ€ç‰¹å¾è¡¨ç¤ºã€‚æˆ‘ä»¬ä»Žè¯­ä¹‰æ„ŸçŸ¥çš„è§’åº¦è®¾è®¡è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ï¼Œé€šè¿‡æ•´åˆåˆ—æ ‡é¢˜ä½œä¸ºè¯­ä¹‰çº¿ç´¢ï¼Œä¿ƒè¿›å¯è¿ç§»çŸ¥è¯†å­¦ä¹ å’Œåˆ©ç”¨å¤šä¸ªæ•°æ®æºè¿›è¡Œé¢„è®­ç»ƒçš„å¯æ‰©å±•æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†åŽŸåž‹å¼•å¯¼çš„çº¿æ€§æ··åˆå±‚æ¨¡å—ç”¨äºŽè¡¨æ ¼ç‰¹å¾ä¸“ä¸šåŒ–ï¼Œä½¿æ¨¡åž‹èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†è¡¨æ ¼æ•°æ®çš„å¼‚æž„æ€§å¹¶æŽ¢ç´¢æ½œåœ¨çš„åŒ»å­¦æ¦‚å¿µã€‚æˆ‘ä»¬åœ¨åŒ…å«4,461åå—è¯•è€…çš„ä¸‰ä¸ªå…¬å¼€æ•°æ®é˜Ÿåˆ—ä¸Šå¯¹é˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­ä»»åŠ¡è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒCITabä¼˜äºŽæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä¸ºæœ‰æ•ˆä¸”å¯æ‰©å±•çš„è·¨è¡¨æ ¼å¤šæ¨¡æ€å­¦ä¹ é“ºå¹³äº†é“è·¯ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

CITabæ˜¯ä¸€ä¸ªè‡ªç›‘ç£å­¦ä¹ æ¡†æž¶ï¼Œæ•´ä½“æž¶æž„åŒ…æ‹¬å›¾åƒç¼–ç å™¨ã€è¡¨æ ¼ç¼–ç å™¨å’Œå¤šæ¨¡æ€èžåˆæ¨¡å—ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽï¼šä»Žè¯­ä¹‰æ„ŸçŸ¥è§’åº¦è®¾è®¡è¡¨æ ¼å»ºæ¨¡æœºåˆ¶ï¼Œé€šè¿‡åˆ—æ ‡é¢˜ä½œä¸ºè¯­ä¹‰çº¿ç´¢å¢žå¼ºè·¨é˜Ÿåˆ—çŸ¥è¯†è¿ç§»ï¼›å¼•å…¥åŽŸåž‹å¼•å¯¼çš„çº¿æ€§æ··åˆå±‚æ¨¡å—ï¼ŒåŠ¨æ€è°ƒæ•´çº¿æ€§å±‚ä»¥ä¸“ä¸šåŒ–å¤„ç†è¡¨æ ¼æ•°æ®çš„å¼‚æž„æ€§ï¼ŒæŽ¢ç´¢æ½œåœ¨åŒ»å­¦æ¦‚å¿µã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œå®ƒæ‰“ç ´äº†è·¨è¡¨æ ¼éšœç¢ï¼Œé€šè¿‡æ›´çµæ´»çš„è¡¨æ ¼å»ºæ¨¡æ”¯æŒå¤šæºæ•°æ®é¢„è®­ç»ƒï¼Œè€Œä¼ ç»Ÿæ–¹æ³•é€šå¸¸ä¾èµ–å›ºå®šç»“æž„ï¼Œé™åˆ¶äº†å¯æ‰©å±•æ€§å’Œè¿ç§»èƒ½åŠ›ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨åŒ…å«4,461åå—è¯•è€…çš„ä¸‰ä¸ªå…¬å¼€é˜¿å°”èŒ¨æµ·é»˜ç—…æ•°æ®é˜Ÿåˆ—ä¸Šï¼ŒCITabåœ¨è¯Šæ–­ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œè¯æ˜Žäº†å…¶åœ¨è·¨é˜Ÿåˆ—åœºæ™¯ä¸‹çš„ä¼˜è¶Šæ€§èƒ½å’Œå¯æ‰©å±•æ€§ï¼Œä¸ºå¤šæ¨¡æ€åŒ»å­¦å­¦ä¹ æä¾›äº†æœ‰æ•ˆè§£å†³æ–¹æ¡ˆã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽåŒ»å­¦é¢†åŸŸï¼Œå¦‚é˜¿å°”èŒ¨æµ·é»˜ç—…ç­‰ç–¾ç—…çš„è¯Šæ–­å’Œé¢„æµ‹ï¼Œé€šè¿‡æ•´åˆåŒ»å­¦å›¾åƒå’Œä¸´åºŠè¡¨æ ¼æ•°æ®ï¼Œæå‡ä¸´åºŠå†³ç­–çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ã€‚æ½œåœ¨ä»·å€¼åŒ…æ‹¬æ”¯æŒè·¨åŒ»é™¢æˆ–ç ”ç©¶é˜Ÿåˆ—çš„æ•°æ®èžåˆï¼Œä¿ƒè¿›å¤§è§„æ¨¡å¤šæ¨¡æ€åŒ»å­¦AIæ¨¡åž‹çš„å¼€å‘ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-modal learning integrating medical images and tabular data has significantly advanced clinical decision-making in recent years. Self-Supervised Learning (SSL) has emerged as a powerful paradigm for pretraining these models on large-scale unlabeled image-tabular data, aiming to learn discriminative representations. However, existing SSL methods for image-tabular representation learning are often confined to specific data cohorts, mainly due to their rigid tabular modeling mechanisms when modeling heterogeneous tabular data. This inter-tabular barrier hinders the multi-modal SSL methods from effectively learning transferrable medical knowledge shared across diverse cohorts. In this paper, we propose a novel SSL framework, namely CITab, designed to learn powerful multi-modal feature representations in a cross-tabular manner. We design the tabular modeling mechanism from a semantic-awareness perspective by integrating column headers as semantic cues, which facilitates transferrable knowledge learning and the scalability in utilizing multiple data sources for pretraining. Additionally, we propose a prototype-guided mixture-of-linear layer (P-MoLin) module for tabular feature specialization, empowering the model to effectively handle the heterogeneity of tabular data and explore the underlying medical concepts. We conduct comprehensive evaluations on Alzheimer's disease diagnosis task across three publicly available data cohorts containing 4,461 subjects. Experimental results demonstrate that CITab outperforms state-of-the-art approaches, paving the way for effective and scalable cross-tabular multi-modal learning.

