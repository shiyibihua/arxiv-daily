---
layout: default
title: S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation
---

# S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14440" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14440v1</a>
  <a href="https://arxiv.org/pdf/2512.14440.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14440v1" onclick="toggleFavorite(this, '2512.14440v1', 'S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Leon Sick, Lukas Hoyer, Dominik Engel, Pedro Hermosilla, Timo Ropinski

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Project Page with Code/Models/Demo: https://leonsick.github.io/s2d/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºS2Dï¼šä¸€ç§ç¨€ç–åˆ°ç¨ å¯†çš„Keymaskè’¸é¦æ–¹æ³•ï¼Œç”¨äºæ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ— ç›‘ç£å­¦ä¹ ` `è§†é¢‘å®ä¾‹åˆ†å‰²` `ç¨€ç–åˆ°ç¨ å¯†` `Keymaskè’¸é¦` `æ·±åº¦è¿åŠ¨å…ˆéªŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²æ–¹æ³•ä¾èµ–åˆæˆæ•°æ®ï¼Œéš¾ä»¥æ¨¡æ‹ŸçœŸå®è§†é¢‘ä¸­çš„å¤æ‚è¿åŠ¨ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºS2Dæ–¹æ³•ï¼Œåˆ©ç”¨æ·±åº¦è¿åŠ¨å…ˆéªŒé€‰æ‹©é«˜è´¨é‡Keymaskï¼Œå¹¶é€šè¿‡ç¨€ç–åˆ°ç¨ å¯†çš„è’¸é¦å­¦ä¹ å®ç°æ©ç ä¼ æ’­ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯æ°´å¹³ï¼ŒéªŒè¯äº†å…¶åœ¨çœŸå®è§†é¢‘æ•°æ®ä¸Šçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²é¢†åŸŸçš„æœ€å…ˆè¿›æ–¹æ³•ä¸¥é‡ä¾èµ–äºåˆæˆè§†é¢‘æ•°æ®ï¼Œè¿™äº›æ•°æ®é€šå¸¸ç”±ImageNetç­‰ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„å›¾åƒæ•°æ®é›†ç”Ÿæˆã€‚ç„¶è€Œï¼Œé€šè¿‡äººä¸ºåœ°ç§»åŠ¨å’Œç¼©æ”¾å›¾åƒå®ä¾‹æ©ç æ¥åˆæˆè§†é¢‘ï¼Œæ— æ³•å‡†ç¡®åœ°æ¨¡æ‹Ÿè§†é¢‘ä¸­çœŸå®çš„è¿åŠ¨ï¼Œä¾‹å¦‚é€è§†å˜åŒ–ã€å•ä¸ªæˆ–å¤šä¸ªå®ä¾‹çš„éƒ¨åˆ†è¿åŠ¨æˆ–ç›¸æœºè¿åŠ¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å®Œå…¨åœ¨çœŸå®è§†é¢‘æ•°æ®ä¸Šè®­ç»ƒçš„æ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²æ¨¡å‹ã€‚æˆ‘ä»¬ä»å•ä¸ªè§†é¢‘å¸§ä¸Šçš„æ— ç›‘ç£å®ä¾‹åˆ†å‰²æ©ç å¼€å§‹ã€‚ç„¶è€Œï¼Œè¿™äº›å•å¸§åˆ†å‰²è¡¨ç°å‡ºæ—¶é—´å™ªå£°ï¼Œå¹¶ä¸”å…¶è´¨é‡åœ¨æ•´ä¸ªè§†é¢‘ä¸­å˜åŒ–ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é€šè¿‡åˆ©ç”¨æ·±åº¦è¿åŠ¨å…ˆéªŒæ¥è¯†åˆ«è§†é¢‘ä¸­çš„é«˜è´¨é‡Keymaskï¼Œä»è€Œå»ºç«‹æ—¶é—´ä¸€è‡´æ€§ã€‚ç„¶åï¼Œç¨€ç–çš„Keymaskä¼ªæ³¨é‡Šç”¨äºè®­ç»ƒåˆ†å‰²æ¨¡å‹ä»¥è¿›è¡Œéšå¼æ©ç ä¼ æ’­ï¼Œä¸ºæ­¤æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”±Temporal DropLossè¾…åŠ©çš„ç¨€ç–åˆ°ç¨ å¯†çš„è’¸é¦æ–¹æ³•ã€‚åœ¨ç”±æ­¤äº§ç”Ÿçš„ç¨ å¯†æ ‡ç­¾é›†ä¸Šè®­ç»ƒæœ€ç»ˆæ¨¡å‹åï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸­ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²æ—¨åœ¨æ— éœ€äººå·¥æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œå¯¹è§†é¢‘ä¸­çš„æ¯ä¸ªå®ä¾‹è¿›è¡Œåˆ†å‰²å’Œè·Ÿè¸ªã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºåœ¨åˆæˆæ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œä½†åˆæˆæ•°æ®éš¾ä»¥æ¨¡æ‹ŸçœŸå®è§†é¢‘ä¸­çš„å¤æ‚è¿åŠ¨ï¼ˆå¦‚é€è§†å˜æ¢ã€éƒ¨åˆ†é®æŒ¡ç­‰ï¼‰ï¼Œå¯¼è‡´æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸‹çš„æ€§èƒ½ä¸‹é™ã€‚æ­¤å¤–ï¼Œå•å¸§åˆ†å‰²ç»“æœå­˜åœ¨æ—¶é—´ä¸Šçš„ä¸ä¸€è‡´æ€§ï¼Œéœ€è¦æœ‰æ•ˆçš„æ—¶åºå»ºæ¨¡æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è§†é¢‘ä¸­çš„è¿åŠ¨ä¿¡æ¯æ¥é€‰æ‹©é«˜è´¨é‡çš„Keymaskï¼Œå¹¶åˆ©ç”¨è¿™äº›Keymaskä½œä¸ºä¼ªæ ‡ç­¾ï¼Œé€šè¿‡ç¨€ç–åˆ°ç¨ å¯†çš„è’¸é¦å­¦ä¹ ï¼Œè®­ç»ƒä¸€ä¸ªèƒ½å¤Ÿè¿›è¡Œéšå¼æ©ç ä¼ æ’­çš„åˆ†å‰²æ¨¡å‹ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å¯ä»¥åœ¨çœŸå®è§†é¢‘æ•°æ®ä¸Šå­¦ä¹ åˆ°æ›´é²æ£’çš„ç‰¹å¾è¡¨ç¤ºï¼Œå¹¶æé«˜åˆ†å‰²çš„å‡†ç¡®æ€§å’Œæ—¶é—´ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) å•å¸§æ— ç›‘ç£å®ä¾‹åˆ†å‰²ï¼šä½¿ç”¨ç°æœ‰çš„æ— ç›‘ç£å›¾åƒå®ä¾‹åˆ†å‰²æ–¹æ³•å¯¹æ¯ä¸€å¸§å›¾åƒè¿›è¡Œåˆ†å‰²ï¼Œå¾—åˆ°åˆå§‹çš„åˆ†å‰²ç»“æœã€‚2) Keymaské€‰æ‹©ï¼šåˆ©ç”¨æ·±åº¦è¿åŠ¨å…ˆéªŒï¼ˆä¾‹å¦‚å…‰æµï¼‰æ¥è¯„ä¼°æ¯ä¸ªåˆ†å‰²ç»“æœçš„è´¨é‡ï¼Œé€‰æ‹©é«˜è´¨é‡çš„Keymaskã€‚3) ç¨€ç–åˆ°ç¨ å¯†çš„è’¸é¦å­¦ä¹ ï¼šä½¿ç”¨Keymaskä½œä¸ºä¼ªæ ‡ç­¾ï¼Œè®­ç»ƒä¸€ä¸ªåˆ†å‰²æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿä»ç¨€ç–çš„Keymaskä¸­å­¦ä¹ åˆ°ç¨ å¯†çš„åˆ†å‰²ç»“æœã€‚4) Temporal DropLossï¼šä¸ºäº†å¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ï¼Œå¼•å…¥Temporal DropLossï¼Œéšæœºä¸¢å¼ƒä¸€äº›Keymaskï¼Œè¿«ä½¿æ¨¡å‹å­¦ä¹ åˆ°æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ç¨€ç–åˆ°ç¨ å¯†çš„Keymaskè’¸é¦æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨è§†é¢‘ä¸­çš„è¿åŠ¨ä¿¡æ¯æ¥é€‰æ‹©é«˜è´¨é‡çš„ä¼ªæ ‡ç­¾ï¼Œå¹¶è®­ç»ƒä¸€ä¸ªèƒ½å¤Ÿåœ¨çœŸå®è§†é¢‘æ•°æ®ä¸Šè¿›è¡Œåˆ†å‰²çš„æ¨¡å‹ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ— éœ€ä¾èµ–åˆæˆæ•°æ®ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†çœŸå®è§†é¢‘ä¸­çš„å¤æ‚è¿åŠ¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨Keymaské€‰æ‹©é˜¶æ®µï¼Œè®ºæ–‡åˆ©ç”¨å…‰æµçš„ä¸€è‡´æ€§æ¥è¯„ä¼°åˆ†å‰²ç»“æœçš„è´¨é‡ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºæ¯ä¸ªåˆ†å‰²ç»“æœï¼Œè®¡ç®—å…¶ä¸ç›¸é‚»å¸§çš„å…‰æµçš„å¯¹é½ç¨‹åº¦ï¼Œé€‰æ‹©å¯¹é½ç¨‹åº¦é«˜çš„åˆ†å‰²ç»“æœä½œä¸ºKeymaskã€‚åœ¨ç¨€ç–åˆ°ç¨ å¯†çš„è’¸é¦å­¦ä¹ é˜¶æ®µï¼Œè®ºæ–‡ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥è¡¡é‡æ¨¡å‹é¢„æµ‹ç»“æœä¸Keymaskä¹‹é—´çš„å·®å¼‚ã€‚Temporal DropLossé€šè¿‡éšæœºä¸¢å¼ƒKeymaskæ¥å®ç°ï¼Œä¸¢å¼ƒæ¦‚ç‡æ˜¯ä¸€ä¸ªå¯è°ƒçš„è¶…å‚æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨å¤šä¸ªæ— ç›‘ç£è§†é¢‘å®ä¾‹åˆ†å‰²åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸä¸ªæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•çš„åˆ†å‰²ç²¾åº¦æ¯”ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•æé«˜äº†5%ä»¥ä¸Šã€‚æ­¤å¤–ï¼Œå®éªŒç»“æœè¿˜è¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†çœŸå®è§†é¢‘ä¸­çš„å¤æ‚è¿åŠ¨ï¼Œå¹¶ä¸”å…·æœ‰è¾ƒå¥½çš„é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€è§†é¢‘ç›‘æ§ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•å¯¹é“è·¯ä¸Šçš„è½¦è¾†ã€è¡Œäººç­‰ç›®æ ‡è¿›è¡Œåˆ†å‰²å’Œè·Ÿè¸ªï¼Œæé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§ã€‚åœ¨è§†é¢‘ç›‘æ§ä¸­ï¼Œå¯ä»¥ç”¨äºå¼‚å¸¸è¡Œä¸ºæ£€æµ‹å’Œç›®æ ‡è¿½è¸ªã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºè§†é¢‘ç¼–è¾‘å’Œå¢å¼ºç°å®ç­‰åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In recent years, the state-of-the-art in unsupervised video instance segmentation has heavily relied on synthetic video data, generated from object-centric image datasets such as ImageNet. However, video synthesis by artificially shifting and scaling image instance masks fails to accurately model realistic motion in videos, such as perspective changes, movement by parts of one or multiple instances, or camera motion. To tackle this issue, we propose an unsupervised video instance segmentation model trained exclusively on real video data. We start from unsupervised instance segmentation masks on individual video frames. However, these single-frame segmentations exhibit temporal noise and their quality varies through the video. Therefore, we establish temporal coherence by identifying high-quality keymasks in the video by leveraging deep motion priors. The sparse keymask pseudo-annotations are then used to train a segmentation model for implicit mask propagation, for which we propose a Sparse-To-Dense Distillation approach aided by a Temporal DropLoss. After training the final model on the resulting dense labelset, our approach outperforms the current state-of-the-art across various benchmarks.

