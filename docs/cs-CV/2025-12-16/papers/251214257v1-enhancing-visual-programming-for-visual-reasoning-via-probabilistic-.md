---
layout: default
title: Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs
---

# Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14257" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14257v1</a>
  <a href="https://arxiv.org/pdf/2512.14257.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14257v1" onclick="toggleFavorite(this, '2512.14257v1', 'Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wentao Wan, Kaiyu Wu, Qingyang Ma, Nan Kang, Yunjie Chen, Liang Lin, Keze Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 13 Pages, 12 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEVPGï¼Œé€šè¿‡æ¦‚ç‡å›¾å¢å¼ºè§†è§‰ç¼–ç¨‹ä»¥æå‡è§†è§‰æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰ç¼–ç¨‹` `è§†è§‰æ¨ç†` `æ¦‚ç‡å›¾` `ç«¯åˆ°ç«¯å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰ç¼–ç¨‹æ–¹æ³•å¿½ç•¥äº†å¯¹VPè°ƒç”¨çš„é¢„è®­ç»ƒæ¨¡å‹çš„ä¼˜åŒ–ï¼Œå¯¼è‡´è§†è§‰æ¨ç†èƒ½åŠ›å—é™ã€‚
2. EVPGé€šè¿‡æ„å»ºæœ‰å‘æ¦‚ç‡å›¾ï¼Œå°†VPæ‰§è¡Œè¿‡ç¨‹è½¬åŒ–ä¸ºå¯å¾®çš„æ¦‚ç‡æ¨ç†è¿‡ç¨‹ï¼Œå®ç°ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚
3. åœ¨GQAã€NLVRv2å’ŒOpen Imagesç­‰ä»»åŠ¡ä¸Šï¼ŒEVPGæ˜¾è‘—æå‡äº†è§†è§‰ç¼–ç¨‹çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºEVPGçš„æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡æ¦‚ç‡å›¾å¢å¼ºè§†è§‰ç¼–ç¨‹ï¼ˆVPï¼‰ï¼Œä»è€Œæå‡è§†è§‰æ¨ç†ï¼ˆVRï¼‰èƒ½åŠ›ã€‚ç°æœ‰çš„VPå¢å¼ºæ–¹æ³•ä¸»è¦å…³æ³¨äºæå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆçš„è§†è§‰ç¨‹åºçš„è´¨é‡ï¼Œè€Œå¿½ç•¥äº†ä¼˜åŒ–VPè°ƒç”¨çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹ä½œä¸ºè§†è§‰å­ä»»åŠ¡çš„æ¨¡å—ã€‚éš¾ç‚¹åœ¨äºï¼Œç›®æ ‡VRä»»åŠ¡åªæœ‰æœ€ç»ˆæ ‡ç­¾ï¼Œè€Œæ²¡æœ‰å­ä»»åŠ¡çš„æ ‡ç­¾ã€‚æ­¤å¤–ï¼ŒVPçš„ä¸å¯å¾®æ€§é˜»ç¢äº†ç›´æ¥ä½¿ç”¨åŸºäºæ¢¯åº¦çš„ä¼˜åŒ–æ–¹æ³•ï¼Œä»è€Œæ— æ³•åˆ©ç”¨æœ€ç»ˆæ ‡ç­¾å¯¹æ•´ä¸ªVPæ¡†æ¶è¿›è¡Œç«¯åˆ°ç«¯å­¦ä¹ ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼ŒEVPGæ ¹æ®VPæ‰§è¡Œè¿‡ç¨‹ä¸­çš„å˜é‡ä¾èµ–å…³ç³»æ„å»ºäº†ä¸€ä¸ªæœ‰å‘æ¦‚ç‡å›¾ï¼Œå°†ä¸å¯å¾®çš„VPæ‰§è¡Œè¿‡ç¨‹é‡æ„ä¸ºè¯¥å›¾ä¸Šçš„å¯å¾®ç²¾ç¡®æ¦‚ç‡æ¨ç†è¿‡ç¨‹ã€‚è¿™ä½¿å¾—VPæ¡†æ¶èƒ½å¤Ÿåˆ©ç”¨æœ€ç»ˆæ ‡ç­¾è¿›è¡Œé«˜æ•ˆçš„ã€åŸºäºæ¢¯åº¦çš„ç«¯åˆ°ç«¯ç›‘ç£å­¦ä¹ ã€‚åœ¨GQAã€NLVRv2å’ŒOpen Imagesä¸‰ä¸ªç»å…¸å¤æ‚VRä»»åŠ¡ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒEVPGçš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ï¼Œå¹¶æ˜¾ç¤ºå‡ºVPçš„æ€§èƒ½æ˜¾è‘—æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†è§‰æ¨ç†ä»»åŠ¡ä¸­ï¼Œè§†è§‰ç¼–ç¨‹ï¼ˆVPï¼‰æ¡†æ¶ä¸‹é¢„è®­ç»ƒæ¨¡å‹ä¼˜åŒ–ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨äºä¼˜åŒ–LLMç”Ÿæˆçš„è§†è§‰ç¨‹åºï¼Œè€Œå¿½ç•¥äº†VPæ¡†æ¶ä¸­å„ä¸ªè§†è§‰æ¨¡å—ï¼ˆå³é¢„è®­ç»ƒæ¨¡å‹ï¼‰çš„ä¼˜åŒ–ã€‚ç”±äºç¼ºä¹å­ä»»åŠ¡çš„æ ‡ç­¾ä»¥åŠVPçš„ä¸å¯å¾®æ€§ï¼Œæ— æ³•ç›´æ¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ–¹æ³•è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒï¼Œä»è€Œé™åˆ¶äº†æ•´ä½“æ€§èƒ½çš„æå‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†VPçš„æ‰§è¡Œè¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ªæœ‰å‘æ¦‚ç‡å›¾ä¸Šçš„æ¦‚ç‡æ¨ç†è¿‡ç¨‹ã€‚é€šè¿‡æ„å»ºæ¦‚ç‡å›¾ï¼Œå°†VPä¸­å„ä¸ªæ¨¡å—ä¹‹é—´çš„ä¾èµ–å…³ç³»æ˜¾å¼åœ°è¡¨ç¤ºå‡ºæ¥ï¼Œå¹¶å°†åŸæœ¬ä¸å¯å¾®çš„VPæ‰§è¡Œè¿‡ç¨‹è½¬åŒ–ä¸ºå¯å¾®çš„æ¦‚ç‡æ¨ç†è¿‡ç¨‹ã€‚è¿™æ ·ï¼Œå°±å¯ä»¥åˆ©ç”¨æœ€ç»ˆçš„æ ‡ç­¾ä¿¡æ¯ï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™æ–¹æ³•å¯¹æ•´ä¸ªVPæ¡†æ¶è¿›è¡Œç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEVPGçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) ä½¿ç”¨LLMç”Ÿæˆè§†è§‰ç¨‹åºï¼›2) æ ¹æ®è§†è§‰ç¨‹åºçš„æ‰§è¡Œè¿‡ç¨‹ï¼Œæ„å»ºæœ‰å‘æ¦‚ç‡å›¾ï¼ŒèŠ‚ç‚¹è¡¨ç¤ºå˜é‡ï¼Œè¾¹è¡¨ç¤ºå˜é‡ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼›3) å°†VPçš„æ‰§è¡Œè¿‡ç¨‹è½¬åŒ–ä¸ºæ¦‚ç‡å›¾ä¸Šçš„æ¦‚ç‡æ¨ç†è¿‡ç¨‹ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨è´å¶æ–¯å…¬å¼è®¡ç®—åéªŒæ¦‚ç‡ï¼›4) ä½¿ç”¨æœ€ç»ˆçš„æ ‡ç­¾ä¿¡æ¯ï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™æ–¹æ³•å¯¹æ¦‚ç‡å›¾ä¸­çš„å‚æ•°è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œä¼˜åŒ–VPæ¡†æ¶ä¸­çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†ä¸å¯å¾®çš„VPæ‰§è¡Œè¿‡ç¨‹è½¬åŒ–ä¸ºå¯å¾®çš„æ¦‚ç‡æ¨ç†è¿‡ç¨‹ã€‚é€šè¿‡æ„å»ºæ¦‚ç‡å›¾ï¼Œæ˜¾å¼åœ°å»ºæ¨¡äº†VPä¸­å„ä¸ªæ¨¡å—ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œå¹¶åˆ©ç”¨æ¦‚ç‡æ¨ç†æ–¹æ³•å®ç°äº†ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚è¿™ç§æ–¹æ³•å…‹æœäº†VPçš„ä¸å¯å¾®æ€§é—®é¢˜ï¼Œä½¿å¾—å¯ä»¥åˆ©ç”¨æœ€ç»ˆçš„æ ‡ç­¾ä¿¡æ¯å¯¹æ•´ä¸ªæ¡†æ¶è¿›è¡Œä¼˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¦‚ç‡å›¾çš„æ„å»ºè¿‡ç¨‹ä¸­ï¼Œéœ€è¦ä»”ç»†è€ƒè™‘å˜é‡ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œç¡®ä¿æ¦‚ç‡å›¾èƒ½å¤Ÿå‡†ç¡®åœ°åæ˜ VPçš„æ‰§è¡Œè¿‡ç¨‹ã€‚åœ¨æ¦‚ç‡æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥é€‰æ‹©ä¸åŒçš„æ¨ç†ç®—æ³•ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨å˜åˆ†æ¨ç†æˆ–é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›æ–¹æ³•ã€‚åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ä¸åŒçš„æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°æˆ–hinge lossã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å–å†³äºæ‰€ä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹å’Œè§†è§‰ç¨‹åºçš„å¤æ‚ç¨‹åº¦ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14257v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14257v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14257v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒEVPGåœ¨GQAã€NLVRv2å’ŒOpen Imagesä¸‰ä¸ªç»å…¸å¤æ‚VRä»»åŠ¡ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨GQAä»»åŠ¡ä¸Šï¼ŒEVPGç›¸æ¯”äºåŸºçº¿æ–¹æ³•æå‡äº†è¶…è¿‡5ä¸ªç™¾åˆ†ç‚¹ã€‚è¿™äº›ç»“æœè¯æ˜äº†EVPGçš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ï¼Œè¡¨æ˜é€šè¿‡æ¦‚ç‡å›¾å¢å¼ºè§†è§‰ç¼–ç¨‹å¯ä»¥æ˜¾è‘—æå‡è§†è§‰æ¨ç†èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å¤æ‚è§†è§‰æ¨ç†çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½é—®ç­”ã€è§†è§‰å¯¼èˆªã€å›¾åƒç¼–è¾‘ç­‰ã€‚é€šè¿‡ä¼˜åŒ–è§†è§‰ç¼–ç¨‹æ¡†æ¶ä¸­çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¯ä»¥æå‡è§†è§‰æ¨ç†çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œä»è€Œæé«˜ç›¸å…³åº”ç”¨çš„æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„è§†è§‰ä»»åŠ¡å’Œæ¨¡å‹ï¼Œå¹¶ä¸å…¶ä»–æŠ€æœ¯ç›¸ç»“åˆï¼Œä¾‹å¦‚å¼ºåŒ–å­¦ä¹ å’Œè¿ç§»å­¦ä¹ ï¼Œä»¥å®ç°æ›´å¼ºå¤§çš„è§†è§‰æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently, Visual Programming (VP) based on large language models (LLMs) has rapidly developed and demonstrated significant potential in complex Visual Reasoning (VR) tasks. Previous works to enhance VP have primarily focused on improving the quality of LLM-generated visual programs. However, they have neglected to optimize the VP-invoked pre-trained models, which serve as modules for the visual sub-tasks decomposed from the targeted tasks by VP. The difficulty is that there are only final labels of targeted VR tasks rather than labels of sub-tasks. Besides, the non-differentiable nature of VP impedes the direct use of efficient gradient-based optimization methods to leverage final labels for end-to-end learning of the entire VP framework. To overcome these issues, we propose EVPG, a method to Enhance Visual Programming for visual reasoning via Probabilistic Graphs. Specifically, we creatively build a directed probabilistic graph according to the variable dependency relationships during the VP executing process, which reconstructs the non-differentiable VP executing process into a differentiable exact probability inference process on this directed probabilistic graph. As a result, this enables the VP framework to utilize the final labels for efficient, gradient-based optimization in end-to-end supervised learning on targeted VR tasks. Extensive and comprehensive experiments demonstrate the effectiveness and advantages of our EVPG, showing significant performance improvements for VP on three classical complex VR tasks: GQA, NLVRv2, and Open Images.

