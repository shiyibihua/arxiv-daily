---
layout: default
title: OUSAC: Optimized Guidance Scheduling with Adaptive Caching for DiT Acceleration
---

# OUSAC: Optimized Guidance Scheduling with Adaptive Caching for DiT Acceleration

**arXiv**: [2512.14096v1](https://arxiv.org/abs/2512.14096) | [PDF](https://arxiv.org/pdf/2512.14096.pdf)

**ä½œè€…**: Ruitong Sun, Tianze Yang, Wei Niu, Jin Sun

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 29 pages

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOUSACæ¡†æž¶ï¼Œé€šè¿‡ä¼˜åŒ–å¼•å¯¼è°ƒåº¦ä¸Žè‡ªé€‚åº”ç¼“å­˜åŠ é€Ÿæ‰©æ•£å˜æ¢å™¨ï¼Œè§£å†³CFGè®¡ç®—å¼€é”€å¤§çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹åŠ é€Ÿ` `æ— åˆ†ç±»å™¨å¼•å¯¼ä¼˜åŒ–` `ç¨€ç–è®¡ç®—` `è‡ªé€‚åº”ç¼“å­˜` `è¿›åŒ–ç®—æ³•è°ƒåº¦` `å˜æ¢å™¨å—æ ¡å‡†` `å›¾åƒç”Ÿæˆæ•ˆçŽ‡` `è®¡ç®—èŠ‚çœ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šCFGè™½æå‡æ‰©æ•£æ¨¡åž‹è´¨é‡ï¼Œä½†éœ€åŒå€è®¡ç®—ï¼Œä¸”çŽ°æœ‰ç¼“å­˜æ–¹æ³•åœ¨å¯å˜å¼•å¯¼ä¸‹å¤±æ•ˆï¼Œé˜»ç¢é«˜æ•ˆåŠ é€Ÿã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºä¸¤é˜¶æ®µæ¡†æž¶ï¼Œå…ˆä¼˜åŒ–å¼•å¯¼è°ƒåº¦å‡å°‘CFGæ­¥æ•°ï¼Œå†è‡ªé€‚åº”ç¼“å­˜è¡¥å¿åå·®ï¼Œå®žçŽ°ç¨€ç–è®¡ç®—ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªDiTæ¨¡åž‹ä¸Šæ˜¾è‘—èŠ‚çœè®¡ç®—å¹¶æå‡è´¨é‡ï¼Œå¦‚DiT-XL/2èŠ‚çœ53%è®¡ç®—ä¸”è´¨é‡æå‡15%ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰©æ•£æ¨¡åž‹å·²æˆä¸ºé«˜è´¨é‡å›¾åƒç”Ÿæˆçš„ä¸»å¯¼èŒƒå¼ï¼Œä½†å…¶è¿­ä»£åŽ»å™ªè¿‡ç¨‹è®¡ç®—å¼€é”€å·¨å¤§ã€‚æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰æ˜¾è‘—æå‡äº†ç”Ÿæˆè´¨é‡å’Œå¯æŽ§æ€§ï¼Œä½†éœ€è¦åœ¨æ¯ä¸ªæ—¶é—´æ­¥åŒæ—¶æ‰§è¡Œæ¡ä»¶å‰å‘ä¼ æ’­å’Œæ— æ¡ä»¶å‰å‘ä¼ æ’­ï¼Œå¯¼è‡´è®¡ç®—é‡åŠ å€ã€‚æœ¬æ–‡æå‡ºäº†OUSACï¼ˆä¼˜åŒ–å¼•å¯¼è°ƒåº¦ä¸Žè‡ªé€‚åº”ç¼“å­˜ï¼‰æ¡†æž¶ï¼Œé€šè¿‡ç³»ç»Ÿä¼˜åŒ–åŠ é€Ÿæ‰©æ•£å˜æ¢å™¨ï¼ˆDiTï¼‰ã€‚æ ¸å¿ƒæ´žè§æ˜¯ï¼šå¯å˜çš„å¼•å¯¼å°ºåº¦èƒ½å¤Ÿå®žçŽ°ç¨€ç–è®¡ç®—â€”â€”åœ¨æŸäº›æ—¶é—´æ­¥è°ƒæ•´å¼•å¯¼å°ºåº¦å¯ä»¥è¡¥å¿åœ¨å…¶ä»–æ—¶é—´æ­¥è·³è¿‡CFGçš„æ“ä½œï¼Œä»Žè€Œåœ¨ä¿æŒè´¨é‡çš„åŒæ—¶å‡å°‘æ€»é‡‡æ ·æ­¥æ•°å’ŒCFGæ­¥æ•°ã€‚ç„¶è€Œï¼Œå¯å˜çš„å¼•å¯¼æ¨¡å¼ä¼šå¼•å…¥åŽ»å™ªåå·®ï¼Œç ´åæ ‡å‡†ç¼“å­˜æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼ˆè¿™äº›æ–¹æ³•å‡è®¾CFGå°ºåº¦åœ¨æ­¥é—´æ’å®šï¼‰ã€‚æ­¤å¤–ï¼Œåœ¨åŠ¨æ€æ¡ä»¶ä¸‹ï¼Œä¸åŒçš„å˜æ¢å™¨å—å—åˆ°çš„å½±å“ç¨‹åº¦ä¸åŒã€‚æœ¬æ–‡åŸºäºŽè¿™äº›æ´žè§å¼€å‘äº†ä¸€ç§ä¸¤é˜¶æ®µæ–¹æ³•ï¼šç¬¬ä¸€é˜¶æ®µä½¿ç”¨è¿›åŒ–ç®—æ³•è”åˆä¼˜åŒ–è·³è¿‡å“ªäº›æ—¶é—´æ­¥ä»¥åŠä½¿ç”¨ä½•ç§å¼•å¯¼å°ºåº¦ï¼Œæœ€å¤šå¯æ¶ˆé™¤82%çš„æ— æ¡ä»¶å‰å‘ä¼ æ’­ï¼›ç¬¬äºŒé˜¶æ®µå¼•å…¥è‡ªé€‚åº”ç§©åˆ†é…ï¼Œé’ˆå¯¹æ¯ä¸ªå˜æ¢å™¨å—å®šåˆ¶æ ¡å‡†å·¥ä½œï¼Œåœ¨å¯å˜å¼•å¯¼ä¸‹ä¿æŒç¼“å­˜æœ‰æ•ˆæ€§ã€‚å®žéªŒè¡¨æ˜Žï¼ŒOUSACæ˜¾è‘—ä¼˜äºŽæœ€å…ˆè¿›çš„åŠ é€Ÿæ–¹æ³•ï¼Œåœ¨DiT-XL/2ï¼ˆImageNet 512x512ï¼‰ä¸Šå®žçŽ°äº†53%çš„è®¡ç®—èŠ‚çœå’Œ15%çš„è´¨é‡æå‡ï¼Œåœ¨PixArt-alphaï¼ˆMSCOCOï¼‰ä¸Šå®žçŽ°äº†60%çš„èŠ‚çœå’Œ16.1%çš„æå‡ï¼Œåœ¨FLUXä¸Šå®žçŽ°äº†5å€åŠ é€Ÿï¼ŒåŒæ—¶CLIPåˆ†æ•°è¶…è¿‡50æ­¥åŸºçº¿ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

OUSACæ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µæ¡†æž¶ï¼Œæ—¨åœ¨åŠ é€Ÿæ‰©æ•£å˜æ¢å™¨ï¼ˆDiTï¼‰ã€‚æ•´ä½“æ¡†æž¶åŒ…æ‹¬ï¼šç¬¬ä¸€é˜¶æ®µä½¿ç”¨è¿›åŒ–ç®—æ³•è”åˆä¼˜åŒ–æ—¶é—´æ­¥è·³è¿‡ç­–ç•¥å’Œå¼•å¯¼å°ºåº¦ï¼Œå®žçŽ°ç¨€ç–è®¡ç®—ï¼Œæœ€å¤šå¯æ¶ˆé™¤82%çš„æ— æ¡ä»¶å‰å‘ä¼ æ’­ï¼›ç¬¬äºŒé˜¶æ®µå¼•å…¥è‡ªé€‚åº”ç§©åˆ†é…ï¼Œæ ¹æ®åŠ¨æ€å¼•å¯¼æ¡ä»¶ä¸ºæ¯ä¸ªå˜æ¢å™¨å—å®šåˆ¶æ ¡å‡†ç§©ï¼Œä»¥ç»´æŒç¼“å­˜æœ‰æ•ˆæ€§ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽåˆ©ç”¨å¯å˜å¼•å¯¼å°ºåº¦è¡¥å¿è·³è¿‡CFGçš„åå·®ï¼Œä»¥åŠè‡ªé€‚åº”ç¼“å­˜æœºåˆ¶åº”å¯¹ä¸åŒå—çš„å¼‚è´¨æ€§å½±å“ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼šçŽ°æœ‰æ–¹æ³•é€šå¸¸å‡è®¾æ’å®šCFGå°ºåº¦æˆ–é‡‡ç”¨å›ºå®šç¼“å­˜ç­–ç•¥ï¼Œè€ŒOUSACé€šè¿‡ç³»ç»Ÿä¼˜åŒ–å’Œè‡ªé€‚åº”è®¾è®¡ï¼Œåœ¨å¯å˜å¼•å¯¼ä¸‹å®žçŽ°æ›´é«˜æ•ˆçš„åŠ é€Ÿï¼ŒåŒæ—¶ä¿æŒæˆ–æå‡ç”Ÿæˆè´¨é‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

OUSACåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨çŽ°ä¼˜å¼‚ï¼šDiT-XL/2ä¸ŠèŠ‚çœ53%è®¡ç®—ä¸”FIDæå‡15%ï¼ŒPixArt-alphaä¸ŠèŠ‚çœ60%è®¡ç®—ä¸”è´¨é‡æå‡16.1%ï¼ŒFLUXä¸Šå®žçŽ°5å€åŠ é€Ÿå¹¶è¶…è¶ŠåŸºçº¿CLIPåˆ†æ•°ï¼Œæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰åŠ é€Ÿæ–¹æ³•ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽéœ€è¦é«˜æ•ˆé«˜è´¨é‡å›¾åƒç”Ÿæˆçš„é¢†åŸŸï¼Œå¦‚å†…å®¹åˆ›ä½œã€æ¸¸æˆå¼€å‘ã€å¹¿å‘Šè®¾è®¡å’Œè™šæ‹ŸçŽ°å®žï¼Œé€šè¿‡å‡å°‘æ‰©æ•£æ¨¡åž‹çš„è®¡ç®—å¼€é”€ï¼Œé™ä½Žéƒ¨ç½²æˆæœ¬å¹¶æå‡å®žæ—¶æ€§ï¼Œå…·æœ‰å®žé™…å•†ä¸šä»·å€¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Diffusion models have emerged as the dominant paradigm for high-quality image generation, yet their computational expense remains substantial due to iterative denoising. Classifier-Free Guidance (CFG) significantly enhances generation quality and controllability but doubles the computation by requiring both conditional and unconditional forward passes at every timestep. We present OUSAC (Optimized gUidance Scheduling with Adaptive Caching), a framework that accelerates diffusion transformers (DiT) through systematic optimization. Our key insight is that variable guidance scales enable sparse computation: adjusting scales at certain timesteps can compensate for skipping CFG at others, enabling both fewer total sampling steps and fewer CFG steps while maintaining quality. However, variable guidance patterns introduce denoising deviations that undermine standard caching methods, which assume constant CFG scales across steps. Moreover, different transformer blocks are affected at different levels under dynamic conditions. This paper develops a two-stage approach leveraging these insights. Stage-1 employs evolutionary algorithms to jointly optimize which timesteps to skip and what guidance scale to use, eliminating up to 82% of unconditional passes. Stage-2 introduces adaptive rank allocation that tailors calibration efforts per transformer block, maintaining caching effectiveness under variable guidance. Experiments demonstrate that OUSAC significantly outperforms state-of-the-art acceleration methods, achieving 53% computational savings with 15% quality improvement on DiT-XL/2 (ImageNet 512x512), 60% savings with 16.1% improvement on PixArt-alpha (MSCOCO), and 5x speedup on FLUX while improving CLIP Score over the 50-step baseline.

