---
layout: default
title: OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving
---

# OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14225" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14225v1</a>
  <a href="https://arxiv.org/pdf/2512.14225.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14225v1" onclick="toggleFavorite(this, '2512.14225v1', 'OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tao Tang, Enhui Ma, xia zhou, Letian Wang, Tianyi Yan, Xueyang Zhang, Kun Zhan, Peng Jia, XianPeng Lang, Jia-Wang Bian, Kaicheng Yu, Xiaodan Liang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: ACM MM 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**OmniGenï¼šæå‡ºç»Ÿä¸€çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç”Ÿæˆæ¡†æ¶ï¼Œç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `å¤šæ¨¡æ€ç”Ÿæˆ` `ä¼ æ„Ÿå™¨èåˆ` `é¸Ÿç°å›¾` `æ‰©æ•£æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªåŠ¨é©¾é©¶æ•°æ®ç”Ÿæˆæ–¹æ³•ä¾§é‡äºå•æ¨¡æ€ï¼Œå¯¼è‡´å¤šæ¨¡æ€æ•°æ®ç”Ÿæˆæ•ˆç‡ä½ä¸”æ¨¡æ€é—´ä¸å¯¹é½ï¼Œéš¾ä»¥æ»¡è¶³è‡ªåŠ¨é©¾é©¶å¯¹å¤šä¼ æ„Ÿå™¨èåˆçš„éœ€æ±‚ã€‚
2. OmniGené€šè¿‡å…±äº«BEVç©ºé—´ç»Ÿä¸€å¤šæ¨¡æ€ç‰¹å¾ï¼Œå¹¶æå‡ºé€šç”¨å¤šæ¨¡æ€é‡å»ºæ–¹æ³•UAEï¼Œå®ç°æ¿€å…‰é›·è¾¾å’Œå¤šè§†è§’ç›¸æœºæ•°æ®çš„è”åˆè§£ç ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒOmniGenåœ¨ç»Ÿä¸€å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¿è¯äº†å¤šæ¨¡æ€ä¸€è‡´æ€§ï¼Œå¹¶æ”¯æŒçµæ´»çš„ä¼ æ„Ÿå™¨è°ƒæ•´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªåŠ¨é©¾é©¶çš„å‘å±•å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºå¤§é‡çš„çœŸå®ä¸–ç•Œæ•°æ®ã€‚ç„¶è€Œï¼Œè·å–å¤šæ ·åŒ–å’Œæç«¯æƒ…å†µçš„æ•°æ®ä»ç„¶æˆæœ¬é«˜æ˜‚ä¸”æ•ˆç‡ä½ä¸‹ã€‚ç”Ÿæˆæ¨¡å‹é€šè¿‡åˆæˆé€¼çœŸçš„ä¼ æ„Ÿå™¨æ•°æ®æä¾›äº†ä¸€ä¸ªæœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚ä½†æ˜¯ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å•æ¨¡æ€ç”Ÿæˆä¸Šï¼Œå¯¼è‡´å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®æ•ˆç‡ä½ä¸‹å’Œä¸å¯¹é½ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†OmniGenï¼Œå®ƒåœ¨ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ä¸­ç”Ÿæˆå¯¹é½çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨å…±äº«çš„é¸Ÿç°å›¾ï¼ˆBEVï¼‰ç©ºé—´æ¥ç»Ÿä¸€å¤šæ¨¡æ€ç‰¹å¾ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„é€šç”¨å¤šæ¨¡æ€é‡å»ºæ–¹æ³•UAEï¼Œä»¥è”åˆè§£ç æ¿€å…‰é›·è¾¾å’Œå¤šè§†è§’ç›¸æœºæ•°æ®ã€‚UAEé€šè¿‡ä½“æ¸²æŸ“å®ç°å¤šæ¨¡æ€ä¼ æ„Ÿå™¨è§£ç ï¼Œä»è€Œå®ç°å‡†ç¡®è€Œçµæ´»çš„é‡å»ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç»“åˆäº†å¸¦æœ‰ControlNetåˆ†æ”¯çš„Diffusion Transformerï¼ˆDiTï¼‰ï¼Œä»¥å®ç°å¯æ§çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç”Ÿæˆã€‚æˆ‘ä»¬å…¨é¢çš„å®éªŒè¡¨æ˜ï¼ŒOminiGenåœ¨ç»Ÿä¸€çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆä¸­å®ç°äº†æœŸæœ›çš„æ€§èƒ½ï¼Œå…·æœ‰å¤šæ¨¡æ€ä¸€è‡´æ€§å’Œçµæ´»çš„ä¼ æ„Ÿå™¨è°ƒæ•´ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è‡ªåŠ¨é©¾é©¶æ•°æ®ç”Ÿæˆæ–¹æ³•ä¸»è¦é›†ä¸­äºå•æ¨¡æ€æ•°æ®çš„ç”Ÿæˆï¼Œå¿½ç•¥äº†å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ä¹‹é—´çš„å¯¹é½é—®é¢˜ã€‚è¿™å¯¼è‡´ç”Ÿæˆçš„æ•°æ®åœ¨å¤šä¼ æ„Ÿå™¨èåˆæ—¶å­˜åœ¨å›°éš¾ï¼Œæ— æ³•æœ‰æ•ˆæ”¯æŒè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„è®­ç»ƒå’ŒéªŒè¯ã€‚æ­¤å¤–ï¼Œè·å–çœŸå®ä¸–ç•Œä¸­corner caseçš„æ•°æ®æˆæœ¬é«˜æ˜‚ï¼Œæ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOmniGençš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶æ¥ç”Ÿæˆå¯¹é½çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ã€‚é€šè¿‡åœ¨å…±äº«çš„é¸Ÿç°å›¾ï¼ˆBEVï¼‰ç©ºé—´ä¸­ç»Ÿä¸€å¤šæ¨¡æ€ç‰¹å¾ï¼Œå¹¶è®¾è®¡ä¸€ç§é€šç”¨çš„å¤šæ¨¡æ€é‡å»ºæ–¹æ³•ï¼ˆUAEï¼‰ï¼Œå®ç°æ¿€å…‰é›·è¾¾å’Œå¤šè§†è§’ç›¸æœºæ•°æ®çš„è”åˆè§£ç ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨æé«˜å¤šæ¨¡æ€æ•°æ®ç”Ÿæˆæ•ˆç‡ï¼Œå¹¶ä¿è¯æ¨¡æ€ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOmniGençš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¤šæ¨¡æ€ç‰¹å¾ç¼–ç å™¨ï¼šå°†ä¸åŒæ¨¡æ€çš„ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆå¦‚æ¿€å…‰é›·è¾¾ç‚¹äº‘å’Œå¤šè§†è§’å›¾åƒï¼‰ç¼–ç åˆ°å…±äº«çš„BEVç©ºé—´ä¸­ã€‚2) é€šç”¨å¤šæ¨¡æ€é‡å»ºæ¨¡å—ï¼ˆUAEï¼‰ï¼šåˆ©ç”¨ä½“æ¸²æŸ“æŠ€æœ¯ï¼Œä»BEVç‰¹å¾ä¸­è§£ç å‡ºæ¿€å…‰é›·è¾¾ç‚¹äº‘å’Œå¤šè§†è§’å›¾åƒã€‚3) Diffusion Transformer (DiT) with ControlNetï¼šä½¿ç”¨DiTä½œä¸ºç”Ÿæˆæ¨¡å‹çš„ä¸»å¹²ç½‘ç»œï¼Œå¹¶å¼•å…¥ControlNetåˆ†æ”¯ä»¥å®ç°å¯æ§çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šOmniGençš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç”Ÿæˆæ¡†æ¶ï¼Œèƒ½å¤ŸåŒæ—¶ç”Ÿæˆå¯¹é½çš„æ¿€å…‰é›·è¾¾å’Œç›¸æœºæ•°æ®ã€‚2) è®¾è®¡äº†ä¸€ç§é€šç”¨çš„å¤šæ¨¡æ€é‡å»ºæ–¹æ³•ï¼ˆUAEï¼‰ï¼Œé€šè¿‡ä½“æ¸²æŸ“æŠ€æœ¯å®ç°å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®çš„è§£ç ï¼Œæé«˜äº†é‡å»ºçš„å‡†ç¡®æ€§å’Œçµæ´»æ€§ã€‚3) å¼•å…¥ControlNetåˆ†æ”¯ï¼Œå®ç°äº†å¯¹ç”Ÿæˆè¿‡ç¨‹çš„å¯æ§æ€§ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®éœ€æ±‚è°ƒæ•´ç”Ÿæˆçš„ä¼ æ„Ÿå™¨æ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šUAEæ¨¡å—ä½¿ç”¨ä½“æ¸²æŸ“æŠ€æœ¯ï¼Œé€šè¿‡å°†BEVç‰¹å¾è½¬æ¢ä¸ºä½“ç´ è¡¨ç¤ºï¼Œç„¶åä½¿ç”¨å°„çº¿æŠ•å°„ç®—æ³•ç”Ÿæˆå›¾åƒå’Œç‚¹äº‘ã€‚DiTæ¨¡å‹é‡‡ç”¨Transformeræ¶æ„ï¼Œå¹¶ä½¿ç”¨æ‰©æ•£è¿‡ç¨‹é€æ­¥ç”Ÿæˆæ•°æ®ã€‚ControlNetåˆ†æ”¯å…è®¸ç”¨æˆ·é€šè¿‡è¾“å…¥æ§åˆ¶ä¿¡å·ï¼ˆå¦‚åœºæ™¯å¸ƒå±€æˆ–ç›®æ ‡ä½ç½®ï¼‰æ¥å½±å“ç”Ÿæˆè¿‡ç¨‹ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é‡å»ºæŸå¤±ï¼ˆç”¨äºä¿è¯ç”Ÿæˆæ•°æ®çš„å‡†ç¡®æ€§ï¼‰å’Œå¯¹æŠ—æŸå¤±ï¼ˆç”¨äºæé«˜ç”Ÿæˆæ•°æ®çš„çœŸå®æ„Ÿï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®éªŒéªŒè¯äº†OmniGenåœ¨ç»Ÿä¸€å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOmniGenèƒ½å¤Ÿç”Ÿæˆå…·æœ‰å¤šæ¨¡æ€ä¸€è‡´æ€§å’Œçµæ´»ä¼ æ„Ÿå™¨è°ƒæ•´èƒ½åŠ›çš„æ•°æ®ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†çš„å±•ç¤ºï¼Œè¯æ˜äº†OmniGenç›¸å¯¹äºç°æœ‰æ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOmniGenèƒ½å¤Ÿæ˜¾è‘—æé«˜ç”Ÿæˆæ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

OmniGenåœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºç”Ÿæˆå„ç§åœºæ™¯ä¸‹çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ï¼Œä»è€Œæ‰©å±•è®­ç»ƒæ•°æ®é›†ï¼Œæé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒOmniGenè¿˜å¯ä»¥ç”¨äºæ¨¡æ‹Ÿcorner caseåœºæ™¯ï¼Œå¸®åŠ©è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿæ›´å¥½åœ°åº”å¯¹æç«¯æƒ…å†µã€‚è¯¥ç ”ç©¶çš„æˆæœæœ‰åŠ©äºé™ä½è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å¼€å‘æˆæœ¬ï¼ŒåŠ é€Ÿè‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„å•†ä¸šåŒ–è¿›ç¨‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autonomous driving has seen remarkable advancements, largely driven by extensive real-world data collection. However, acquiring diverse and corner-case data remains costly and inefficient. Generative models have emerged as a promising solution by synthesizing realistic sensor data. However, existing approaches primarily focus on single-modality generation, leading to inefficiencies and misalignment in multimodal sensor data. To address these challenges, we propose OminiGen, which generates aligned multimodal sensor data in a unified framework. Our approach leverages a shared Bird\u2019s Eye View (BEV) space to unify multimodal features and designs a novel generalizable multimodal reconstruction method, UAE, to jointly decode LiDAR and multi-view camera data. UAE achieves multimodal sensor decoding through volume rendering, enabling accurate and flexible reconstruction. Furthermore, we incorporate a Diffusion Transformer (DiT) with a ControlNet branch to enable controllable multimodal sensor generation. Our comprehensive experiments demonstrate that OminiGen achieves desired performances in unified multimodal sensor data generation with multimodal consistency and flexible sensor adjustments.

