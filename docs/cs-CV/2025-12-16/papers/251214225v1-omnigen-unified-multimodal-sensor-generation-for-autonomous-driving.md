---
layout: default
title: OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving
---

# OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving

**arXiv**: [2512.14225v1](https://arxiv.org/abs/2512.14225) | [PDF](https://arxiv.org/pdf/2512.14225.pdf)

**ä½œè€…**: Tao Tang, Enhui Ma, xia zhou, Letian Wang, Tianyi Yan, Xueyang Zhang, Kun Zhan, Peng Jia, XianPeng Lang, Jia-Wang Bian, Kaicheng Yu, Xiaodan Liang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: ACM MM 2025

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmniGenç»Ÿä¸€æ¡†æž¶ä»¥è§£å†³è‡ªåŠ¨é©¾é©¶ä¸­å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆçš„å¯¹é½ä¸Žæ•ˆçŽ‡é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç”Ÿæˆ` `è‡ªåŠ¨é©¾é©¶æ•°æ®åˆæˆ` `é¸Ÿçž°å›¾ç©ºé—´ç»Ÿä¸€` `ä½“æ¸²æŸ“è§£ç ` `æ‰©æ•£å˜æ¢å™¨` `å¯æŽ§ç”Ÿæˆ` `æ¿€å…‰é›·è¾¾ä¸Žç›¸æœºå¯¹é½` `å¤šæ¨¡æ€ä¸€è‡´æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å•æ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆï¼Œå¯¼è‡´å¤šæ¨¡æ€æ•°æ®æ•ˆçŽ‡ä½Žä¸‹å’Œå¯¹é½ä¸å‡†ç¡®ï¼Œé™åˆ¶äº†è‡ªåŠ¨é©¾é©¶æ•°æ®åˆæˆçš„å®žç”¨æ€§ã€‚
2. æå‡ºOmniGenç»Ÿä¸€æ¡†æž¶ï¼Œåˆ©ç”¨å…±äº«BEVç©ºé—´ç»Ÿä¸€å¤šæ¨¡æ€ç‰¹å¾ï¼Œå¹¶è®¾è®¡UAEæ–¹æ³•é€šè¿‡ä½“æ¸²æŸ“è”åˆè§£ç æ¿€å…‰é›·è¾¾å’Œç›¸æœºæ•°æ®ï¼Œå®žçŽ°å¯¹é½ç”Ÿæˆã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒOmniGenåœ¨å¤šæ¨¡æ€ä¸€è‡´æ€§å’Œä¼ æ„Ÿå™¨è°ƒæ•´æ–¹é¢è¡¨çŽ°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆæ•°æ®çš„è´¨é‡å’Œçµæ´»æ€§ï¼Œæ”¯æŒå¯æŽ§ç”Ÿæˆä»»åŠ¡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªåŠ¨é©¾é©¶çš„æ˜¾è‘—è¿›æ­¥å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºŽå¤§è§„æ¨¡çœŸå®žä¸–ç•Œæ•°æ®æ”¶é›†ï¼Œä½†èŽ·å–å¤šæ ·åŒ–å’Œæžç«¯æ¡ˆä¾‹æ•°æ®ä»ç„¶æˆæœ¬é«˜æ˜‚ä¸”æ•ˆçŽ‡ä½Žä¸‹ã€‚ç”Ÿæˆæ¨¡åž‹é€šè¿‡åˆæˆé€¼çœŸçš„ä¼ æ„Ÿå™¨æ•°æ®æˆä¸ºä¸€ç§æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼ŒçŽ°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å•æ¨¡æ€ç”Ÿæˆï¼Œå¯¼è‡´å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®æ•ˆçŽ‡ä½Žä¸‹å’Œå¯¹é½ä¸å‡†ç¡®ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†OmniGenï¼Œåœ¨ç»Ÿä¸€æ¡†æž¶ä¸­ç”Ÿæˆå¯¹é½çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨å…±äº«çš„é¸Ÿçž°å›¾ç©ºé—´ç»Ÿä¸€å¤šæ¨¡æ€ç‰¹å¾ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„å¯æ³›åŒ–å¤šæ¨¡æ€é‡å»ºæ–¹æ³•UAEï¼Œè”åˆè§£ç æ¿€å…‰é›·è¾¾å’Œå¤šè§†è§’ç›¸æœºæ•°æ®ã€‚UAEé€šè¿‡ä½“æ¸²æŸ“å®žçŽ°å¤šæ¨¡æ€ä¼ æ„Ÿå™¨è§£ç ï¼Œæ”¯æŒå‡†ç¡®çµæ´»çš„é‡å»ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç»“åˆäº†å¸¦æœ‰ControlNetåˆ†æ”¯çš„æ‰©æ•£å˜æ¢å™¨ï¼Œå®žçŽ°å¯æŽ§çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç”Ÿæˆã€‚æˆ‘ä»¬çš„å…¨é¢å®žéªŒè¡¨æ˜Žï¼ŒOmniGenåœ¨å¤šæ¨¡æ€ä¸€è‡´æ€§å’Œçµæ´»ä¼ æ„Ÿå™¨è°ƒæ•´æ–¹é¢ï¼Œå®žçŽ°äº†ç»Ÿä¸€å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆçš„ç†æƒ³æ€§èƒ½ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

OmniGençš„æ•´ä½“æ¡†æž¶æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆç³»ç»Ÿï¼Œæ ¸å¿ƒåŒ…æ‹¬å…±äº«BEVç©ºé—´ç‰¹å¾ç»Ÿä¸€å’ŒUAEå¤šæ¨¡æ€é‡å»ºæ¨¡å—ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽï¼š1) åˆ©ç”¨BEVç©ºé—´ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œå°†ä¸åŒæ¨¡æ€çš„ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆå¦‚æ¿€å…‰é›·è¾¾ç‚¹äº‘å’Œå¤šè§†è§’ç›¸æœºå›¾åƒï¼‰å¯¹é½åˆ°åŒä¸€åæ ‡ç³»ï¼Œè§£å†³æ¨¡æ€é—´ä¸ä¸€è‡´é—®é¢˜ï¼›2) è®¾è®¡UAEæ–¹æ³•ï¼Œé€šè¿‡ä½“æ¸²æŸ“æŠ€æœ¯è”åˆè§£ç æ¿€å…‰é›·è¾¾å’Œç›¸æœºæ•°æ®ï¼Œå®žçŽ°å‡†ç¡®ä¸”çµæ´»çš„å¤šæ¨¡æ€é‡å»ºï¼›3) ç»“åˆæ‰©æ•£å˜æ¢å™¨ä¸ŽControlNetåˆ†æ”¯ï¼Œæ”¯æŒå¯æŽ§ç”Ÿæˆï¼Œå…è®¸ç”¨æˆ·è°ƒæ•´ä¼ æ„Ÿå™¨å‚æ•°æˆ–åœºæ™¯æ¡ä»¶ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼ŒOmniGené¦–æ¬¡åœ¨ç»Ÿä¸€æ¡†æž¶ä¸­å®žçŽ°å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®çš„å¯¹é½ç”Ÿæˆï¼Œé¿å…äº†ä¼ ç»Ÿå•æ¨¡æ€æ–¹æ³•å¯¼è‡´çš„æ•ˆçŽ‡ä½Žä¸‹å’Œé”™ä½é—®é¢˜ï¼Œæå‡äº†æ•°æ®åˆæˆçš„æ•´ä½“ä¸€è‡´æ€§å’Œå®žç”¨æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒOmniGenåœ¨ç»Ÿä¸€å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œå®žçŽ°äº†å¤šæ¨¡æ€ä¸€è‡´æ€§å’Œçµæ´»ä¼ æ„Ÿå™¨è°ƒæ•´çš„ä¼˜å¼‚æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨ç”Ÿæˆæ•°æ®çš„å¯¹é½ç²¾åº¦å’Œé‡å»ºè´¨é‡æ–¹é¢ï¼Œç›¸æ¯”çŽ°æœ‰å•æ¨¡æ€æ–¹æ³•æœ‰æ˜¾è‘—æå‡ï¼Œæ”¯æŒå¯æŽ§ç”Ÿæˆå¹¶éªŒè¯äº†å…¶åœ¨æ¨¡æ‹Ÿå¤æ‚é©¾é©¶åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶æ•°æ®åˆæˆæä¾›äº†é«˜æ•ˆè§£å†³æ–¹æ¡ˆã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œæ½œåœ¨ä»·å€¼åŒ…æ‹¬ï¼š1) åˆæˆå¤šæ ·åŒ–å’Œæžç«¯æ¡ˆä¾‹çš„ä¼ æ„Ÿå™¨æ•°æ®ï¼Œç”¨äºŽè®­ç»ƒå’Œæµ‹è¯•è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿï¼Œé™ä½ŽçœŸå®žæ•°æ®æ”¶é›†æˆæœ¬ï¼›2) æ”¯æŒå¯æŽ§æ•°æ®ç”Ÿæˆï¼Œä¾¿äºŽæ¨¡æ‹Ÿä¸åŒå¤©æ°”ã€å…‰ç…§æˆ–ä¼ æ„Ÿå™¨é…ç½®ä¸‹çš„é©¾é©¶åœºæ™¯ï¼Œå¢žå¼ºæ¨¡åž‹çš„é²æ£’æ€§ï¼›3) ä½œä¸ºæ•°æ®å¢žå¼ºå·¥å…·ï¼Œæå‡çŽ°æœ‰æ•°æ®é›†çš„å¤šæ ·æ€§å’Œè¦†ç›–èŒƒå›´ï¼ŒåŠ é€Ÿè‡ªåŠ¨é©¾é©¶ç®—æ³•çš„ç ”å‘è¿›ç¨‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Autonomous driving has seen remarkable advancements, largely driven by extensive real-world data collection. However, acquiring diverse and corner-case data remains costly and inefficient. Generative models have emerged as a promising solution by synthesizing realistic sensor data. However, existing approaches primarily focus on single-modality generation, leading to inefficiencies and misalignment in multimodal sensor data. To address these challenges, we propose OminiGen, which generates aligned multimodal sensor data in a unified framework. Our approach leverages a shared Bird\u2019s Eye View (BEV) space to unify multimodal features and designs a novel generalizable multimodal reconstruction method, UAE, to jointly decode LiDAR and multi-view camera data. UAE achieves multimodal sensor decoding through volume rendering, enabling accurate and flexible reconstruction. Furthermore, we incorporate a Diffusion Transformer (DiT) with a ControlNet branch to enable controllable multimodal sensor generation. Our comprehensive experiments demonstrate that OminiGen achieves desired performances in unified multimodal sensor data generation with multimodal consistency and flexible sensor adjustments.

