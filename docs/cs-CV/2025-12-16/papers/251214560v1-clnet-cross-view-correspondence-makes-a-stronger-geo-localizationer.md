---
layout: default
title: CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer
---

# CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer

**arXiv**: [2512.14560v1](https://arxiv.org/abs/2512.14560) | [PDF](https://arxiv.org/pdf/2512.14560.pdf)

**ä½œè€…**: Xianwei Cao, Dou Quan, Shuang Wang, Ning Huyan, Wei Wang, Yunan Li, Licheng Jiao

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 16 pages, 6 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCLNetæ¡†æž¶ï¼Œé€šè¿‡æ˜¾å¼è·¨è§†å›¾å¯¹åº”å…³ç³»å¢žå¼ºå›¾åƒæ£€ç´¢å¼åœ°ç†å®šä½æ€§èƒ½ã€‚**

**å…³é”®è¯**: `è·¨è§†å›¾åœ°ç†å®šä½` `å›¾åƒæ£€ç´¢` `ç‰¹å¾å¯¹é½` `ç¥žç»å¯¹åº”å›¾` `éžçº¿æ€§åµŒå…¥è½¬æ¢` `å…¨å±€ç‰¹å¾é‡æ ¡å‡†` `è¯­ä¹‰å¯¹åº”` `å‡ ä½•å¯¹åº”`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–å…¨å±€è¡¨ç¤ºæˆ–éšå¼å¯¹é½ï¼Œéš¾ä»¥å»ºæ¨¡è·¨è§†å›¾çš„æ˜¾å¼ç©ºé—´å¯¹åº”å…³ç³»ï¼Œå¯¼è‡´åœ°ç†å®šä½ç²¾åº¦å—é™ã€‚
2. CLNeté€šè¿‡ç¥žç»å¯¹åº”å›¾ã€éžçº¿æ€§åµŒå…¥è½¬æ¢å™¨å’Œå…¨å±€ç‰¹å¾é‡æ ¡å‡†ä¸‰ä¸ªæ¨¡å—ï¼Œæ˜¾å¼å­¦ä¹ è¯­ä¹‰å’Œå‡ ä½•å¯¹åº”ä»¥ç»†åŒ–ç‰¹å¾ã€‚
3. åœ¨CVUSAç­‰å››ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒCLNetè¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œæå‡å®šä½å‡†ç¡®çŽ‡å¹¶å¢žå¼ºæ¨¡åž‹å¯è§£é‡Šæ€§å’Œæ³›åŒ–æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºŽå›¾åƒæ£€ç´¢çš„è·¨è§†å›¾åœ°ç†å®šä½ï¼ˆIRCVGLï¼‰æ—¨åœ¨åŒ¹é…ä»Žæ˜¾è‘—ä¸åŒè§†è§’ï¼ˆå¦‚å«æ˜Ÿå’Œè¡—æ™¯ï¼‰æ•èŽ·çš„å›¾åƒã€‚çŽ°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å­¦ä¹ é²æ£’çš„å…¨å±€è¡¨ç¤ºæˆ–éšå¼ç‰¹å¾å¯¹é½ï¼Œå¾€å¾€æ— æ³•å»ºæ¨¡å¯¹ç²¾ç¡®å®šä½è‡³å…³é‡è¦çš„æ˜¾å¼ç©ºé—´å¯¹åº”å…³ç³»ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°é¢–çš„å¯¹åº”æ„ŸçŸ¥ç‰¹å¾ç»†åŒ–æ¡†æž¶ï¼Œç§°ä¸ºCLNetï¼Œå®ƒæ˜¾å¼åœ°æ¡¥æŽ¥ä¸åŒè§†å›¾ä¹‹é—´çš„è¯­ä¹‰å’Œå‡ ä½•å·®è·ã€‚CLNetå°†è§†å›¾å¯¹é½è¿‡ç¨‹åˆ†è§£ä¸ºä¸‰ä¸ªå¯å­¦ä¹ ä¸”äº’è¡¥çš„æ¨¡å—ï¼šç¥žç»å¯¹åº”å›¾ï¼ˆNCMï¼‰ï¼Œé€šè¿‡æ½œåœ¨å¯¹åº”åœºåœ¨ç©ºé—´ä¸Šå¯¹é½è·¨è§†å›¾ç‰¹å¾ï¼›éžçº¿æ€§åµŒå…¥è½¬æ¢å™¨ï¼ˆNECï¼‰ï¼Œä½¿ç”¨åŸºäºŽMLPçš„å˜æ¢è·¨è§†è§’é‡æ–°æ˜ å°„ç‰¹å¾ï¼›ä»¥åŠå…¨å±€ç‰¹å¾é‡æ ¡å‡†ï¼ˆGFRï¼‰æ¨¡å—ï¼Œé€šè¿‡å­¦ä¹ åˆ°çš„ç©ºé—´çº¿ç´¢å¼•å¯¼é‡æ–°åŠ æƒä¿¡æ¯ä¸°å¯Œçš„ç‰¹å¾é€šé“ã€‚æ‰€æå‡ºçš„CLNetèƒ½å¤Ÿè”åˆæ•èŽ·é«˜çº§è¯­ä¹‰å’Œç»†ç²’åº¦å¯¹é½ã€‚åœ¨å››ä¸ªå…¬å…±åŸºå‡†æµ‹è¯•ï¼ˆCVUSAã€CVACTã€VIGORå’ŒUniversity-1652ï¼‰ä¸Šçš„å¹¿æ³›å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„CLNetå®žçŽ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶æä¾›äº†æ›´å¥½çš„å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

CLNetæ˜¯ä¸€ä¸ªå¯¹åº”æ„ŸçŸ¥ç‰¹å¾ç»†åŒ–æ¡†æž¶ï¼Œæ•´ä½“æž¶æž„åŒ…æ‹¬ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šç¥žç»å¯¹åº”å›¾ï¼ˆNCMï¼‰é€šè¿‡æ½œåœ¨å¯¹åº”åœºå®žçŽ°è·¨è§†å›¾ç‰¹å¾çš„ç©ºé—´å¯¹é½ï¼Œæ•æ‰å‡ ä½•å¯¹åº”ï¼›éžçº¿æ€§åµŒå…¥è½¬æ¢å™¨ï¼ˆNECï¼‰ä½¿ç”¨MLPå˜æ¢è·¨è§†è§’é‡æ–°æ˜ å°„ç‰¹å¾ï¼Œå¤„ç†è§†è§’å·®å¼‚ï¼›å…¨å±€ç‰¹å¾é‡æ ¡å‡†ï¼ˆGFRï¼‰åŸºäºŽå­¦ä¹ åˆ°çš„ç©ºé—´çº¿ç´¢é‡æ–°åŠ æƒç‰¹å¾é€šé“ï¼Œå¢žå¼ºä¿¡æ¯ä¸°å¯Œåº¦ã€‚å…³é”®åˆ›æ–°åœ¨äºŽå°†è§†å›¾å¯¹é½åˆ†è§£ä¸ºå¯å­¦ä¹ çš„æ˜¾å¼å¯¹åº”å»ºæ¨¡ï¼ŒåŒºåˆ«äºŽçŽ°æœ‰æ–¹æ³•çš„å…¨å±€æˆ–éšå¼å¯¹é½ã€‚ä¸»è¦åŒºåˆ«åœ¨äºŽCLNetè”åˆä¼˜åŒ–è¯­ä¹‰å’Œå‡ ä½•å¯¹åº”ï¼Œæä¾›æ›´ç²¾ç»†çš„ç‰¹å¾å¯¹é½ï¼Œä»Žè€Œæé«˜åœ°ç†å®šä½çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨CVUSAã€CVACTã€VIGORå’ŒUniversity-1652å››ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒCLNetå‡è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œæ˜¾è‘—æå‡è·¨è§†å›¾åœ°ç†å®šä½çš„å‡†ç¡®çŽ‡ï¼ŒåŒæ—¶æ¨¡åž‹å±•çŽ°å‡ºæ›´å¥½çš„å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼ŒéªŒè¯äº†æ˜¾å¼å¯¹åº”å»ºæ¨¡çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶ã€æ— äººæœºå¯¼èˆªå’Œå¢žå¼ºçŽ°å®žç­‰é¢†åŸŸï¼Œé€šè¿‡è·¨è§†å›¾å›¾åƒåŒ¹é…å®žçŽ°ç²¾ç¡®çš„åœ°ç†å®šä½ï¼Œæ”¯æŒåŸŽå¸‚è§„åˆ’å’Œæ™ºèƒ½äº¤é€šç³»ç»Ÿï¼Œæå‡å®šä½æœåŠ¡çš„å¯é æ€§å’Œæ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Image retrieval-based cross-view geo-localization (IRCVGL) aims to match images captured from significantly different viewpoints, such as satellite and street-level images. Existing methods predominantly rely on learning robust global representations or implicit feature alignment, which often fail to model explicit spatial correspondences crucial for accurate localization. In this work, we propose a novel correspondence-aware feature refinement framework, termed CLNet, that explicitly bridges the semantic and geometric gaps between different views. CLNet decomposes the view alignment process into three learnable and complementary modules: a Neural Correspondence Map (NCM) that spatially aligns cross-view features via latent correspondence fields; a Nonlinear Embedding Converter (NEC) that remaps features across perspectives using an MLP-based transformation; and a Global Feature Recalibration (GFR) module that reweights informative feature channels guided by learned spatial cues. The proposed CLNet can jointly capture both high-level semantics and fine-grained alignments. Extensive experiments on four public benchmarks, CVUSA, CVACT, VIGOR, and University-1652, demonstrate that our proposed CLNet achieves state-of-the-art performance while offering better interpretability and generalizability.

