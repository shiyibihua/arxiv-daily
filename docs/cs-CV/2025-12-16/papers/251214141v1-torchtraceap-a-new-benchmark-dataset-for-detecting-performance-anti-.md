---
layout: default
title: TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models
---

# TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14141" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14141v1</a>
  <a href="https://arxiv.org/pdf/2512.14141.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14141v1" onclick="toggleFavorite(this, '2512.14141v1', 'TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hanning Chen, Keyu Man, Kevin Zhu, Chenguang Zhu, Haonan Li, Tongbo Luo, Xizhou Feng, Wei Sun, Sreen Tallam, Mohsen Imani, Partha Kanuparthy

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTorchTraceAPåŸºå‡†æ•°æ®é›†ï¼Œç”¨äºæ£€æµ‹è®¡ç®—æœºè§†è§‰æ¨¡å‹ä¸­çš„æ€§èƒ½åæ¨¡å¼ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ€§èƒ½åæ¨¡å¼æ£€æµ‹` `PyTorch traces` `è®¡ç®—æœºè§†è§‰æ¨¡å‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `åŸºå‡†æ•°æ®é›†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨å†—é•¿çš„æ‰§è¡Œtracesä¸­ç²¾ç¡®å®šä½æ€§èƒ½åæ¨¡å¼ï¼Œè‡ªåŠ¨åŒ–ç¨‹åº¦ä½ï¼Œä¾èµ–äººå·¥åˆ†æã€‚
2. æå‡ºä¸€ç§è¿­ä»£æ–¹æ³•ï¼Œå…ˆç”¨è½»é‡çº§MLæ¨¡å‹æ£€æµ‹traceç‰‡æ®µï¼Œå†ç”¨LLMè¿›è¡Œç»†ç²’åº¦åˆ†ç±»å’Œåé¦ˆã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºæ— ç›‘ç£èšç±»å’ŒåŸºäºè§„åˆ™çš„ç»Ÿè®¡æŠ€æœ¯ï¼Œå¹¶èƒ½æœ‰æ•ˆå¼¥è¡¥LLMçš„ä¸è¶³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯†åˆ«å’Œè§£å†³æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰æ¨¡å‹ä¸­çš„æ€§èƒ½åæ¨¡å¼å¯¹äºé«˜æ•ˆçš„è®­ç»ƒå’Œæ¨ç†è‡³å…³é‡è¦ï¼Œä½†è¿™é€šå¸¸éœ€è¦è·¨è¶Šç³»ç»ŸåŸºç¡€è®¾æ–½ã€MLæ¨¡å‹å’Œå†…æ ¸å¼€å‘çš„æ·±åšä¸“ä¸šçŸ¥è¯†ã€‚å¤§å‹ç§‘æŠ€å…¬å¸ä¾é ä¸“é—¨çš„MLåŸºç¡€è®¾æ–½å·¥ç¨‹å¸ˆæ¥åˆ†ætorch traceså’ŒåŸºå‡†æµ‹è¯•ï¼Œä½†è¿™ç§èµ„æºå¯†é›†å‹å·¥ä½œæµç¨‹å¯¹äºä¸€èˆ¬çš„è®¡ç®—æœºè§†è§‰ç ”ç©¶äººå‘˜æ¥è¯´åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯æ— æ³•å®ç°çš„ã€‚å…¶ä¸­ï¼Œåœ¨å†—é•¿çš„æ‰§è¡Œtracesä¸­ç²¾ç¡®å®šä½æœ‰é—®é¢˜çš„traceç‰‡æ®µä»ç„¶æ˜¯æœ€è€—æ—¶çš„ä»»åŠ¡ï¼Œå¹¶ä¸”å¾ˆéš¾ç”¨å½“å‰çš„MLæ¨¡å‹ï¼ˆåŒ…æ‹¬LLMï¼‰è‡ªåŠ¨å®Œæˆã€‚æœ¬æ–‡æå‡ºäº†ç¬¬ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°å’Œæé«˜MLæ¨¡å‹æ£€æµ‹tracesä¸­åæ¨¡å¼èƒ½åŠ›çš„åŸºå‡†æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªå¤šä¸ªç¡¬ä»¶å¹³å°ä¸Šæ”¶é›†çš„å„ç§è®¡ç®—æœºè§†è§‰æ¨¡å‹ï¼ˆåˆ†ç±»ã€æ£€æµ‹ã€åˆ†å‰²å’Œç”Ÿæˆï¼‰çš„600å¤šä¸ªPyTorch tracesã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æ–°é¢–çš„è¿­ä»£æ–¹æ³•ï¼šä¸€ä¸ªè½»é‡çº§çš„MLæ¨¡å‹é¦–å…ˆæ£€æµ‹å…·æœ‰åæ¨¡å¼çš„traceç‰‡æ®µï¼Œç„¶åä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œç»†ç²’åº¦åˆ†ç±»å’Œæœ‰é’ˆå¯¹æ€§çš„åé¦ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ£€æµ‹åæ¨¡å¼åŒºåŸŸæ–¹é¢æ˜æ˜¾ä¼˜äºæ— ç›‘ç£èšç±»å’ŒåŸºäºè§„åˆ™çš„ç»Ÿè®¡æŠ€æœ¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¿˜æœ‰æ•ˆåœ°å¼¥è¡¥äº†LLMæœ‰é™çš„ä¸Šä¸‹æ–‡é•¿åº¦å’Œæ¨ç†æ•ˆç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è®¡ç®—æœºè§†è§‰æ¨¡å‹æ€§èƒ½åˆ†æä¸­ï¼Œéš¾ä»¥è‡ªåŠ¨æ£€æµ‹å’Œå®šä½PyTorch tracesä¸­çš„æ€§èƒ½åæ¨¡å¼çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äººå·¥åˆ†æï¼Œè€—æ—¶ä¸”éœ€è¦ä¸“ä¸šçŸ¥è¯†ï¼Œè€Œç°æœ‰çš„MLæ¨¡å‹ï¼ŒåŒ…æ‹¬LLMï¼Œéš¾ä»¥å¤„ç†é•¿åºåˆ—çš„traceæ•°æ®ï¼Œä¸”æ¨ç†æ•ˆç‡è¾ƒä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†é—®é¢˜åˆ†è§£ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆä½¿ç”¨è½»é‡çº§çš„MLæ¨¡å‹å¿«é€Ÿæ£€æµ‹å‡ºå¯èƒ½å­˜åœ¨æ€§èƒ½åæ¨¡å¼çš„traceç‰‡æ®µï¼Œç„¶ååˆ©ç”¨LLMå¯¹è¿™äº›ç‰‡æ®µè¿›è¡Œç»†ç²’åº¦çš„åˆ†ç±»å’Œåˆ†æï¼Œå¹¶ç»™å‡ºé’ˆå¯¹æ€§çš„åé¦ˆã€‚è¿™ç§è¿­ä»£çš„æ–¹æ³•æ—¨åœ¨ç»“åˆä¸¤è€…çš„ä¼˜åŠ¿ï¼Œæé«˜æ£€æµ‹æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1) **åæ¨¡å¼åŒºåŸŸæ£€æµ‹**ï¼šä½¿ç”¨è½»é‡çº§MLæ¨¡å‹ï¼ˆå…·ä½“æ¨¡å‹æœªçŸ¥ï¼‰å¯¹PyTorch traceè¿›è¡Œåˆ†æï¼Œè¯†åˆ«å‡ºå¯èƒ½åŒ…å«æ€§èƒ½åæ¨¡å¼çš„traceç‰‡æ®µã€‚2) **ç»†ç²’åº¦åˆ†ç±»ä¸åé¦ˆ**ï¼šå°†æ£€æµ‹åˆ°çš„traceç‰‡æ®µè¾“å…¥åˆ°LLMä¸­ï¼ŒLLMå¯¹è¿™äº›ç‰‡æ®µè¿›è¡Œåˆ†ç±»ï¼Œè¯†åˆ«å‡ºå…·ä½“çš„æ€§èƒ½åæ¨¡å¼ç±»å‹ï¼Œå¹¶ç»™å‡ºç›¸åº”çš„ä¼˜åŒ–å»ºè®®ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†è½»é‡çº§MLæ¨¡å‹å’ŒLLMç»“åˆèµ·æ¥ï¼Œç”¨äºæ£€æµ‹å’Œåˆ†æPyTorch tracesä¸­çš„æ€§èƒ½åæ¨¡å¼ã€‚è½»é‡çº§æ¨¡å‹è´Ÿè´£å¿«é€Ÿå®šä½ï¼ŒLLMè´Ÿè´£ç»†ç²’åº¦åˆ†æï¼Œä»è€Œæé«˜äº†æ•´ä½“çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æå‡ºäº†ä¸€ç§è¿­ä»£çš„æµç¨‹ï¼Œå¯ä»¥ä¸æ–­ä¼˜åŒ–æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­æåˆ°ä½¿ç”¨è½»é‡çº§MLæ¨¡å‹è¿›è¡Œåˆæ­¥æ£€æµ‹ï¼Œä½†æœªæ˜ç¡®æŒ‡å‡ºå…·ä½“æ¨¡å‹ç»“æ„å’Œå‚æ•°è®¾ç½®ã€‚LLMçš„ä½¿ç”¨æ—¨åœ¨å¼¥è¡¥ä¸Šä¸‹æ–‡é•¿åº¦å’Œæ¨ç†æ•ˆç‡çš„ä¸è¶³ï¼Œä½†å…·ä½“å¦‚ä½•å¼¥è¡¥ï¼Œä¾‹å¦‚promptå·¥ç¨‹çš„è®¾è®¡ï¼Œè®ºæ–‡ä¸­æ²¡æœ‰è¯¦ç»†è¯´æ˜ã€‚æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚ä¹Ÿæœªåœ¨æ‘˜è¦ä¸­æåŠã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14141v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14141v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14141v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ£€æµ‹åæ¨¡å¼åŒºåŸŸæ–¹é¢æ˜æ˜¾ä¼˜äºæ— ç›‘ç£èšç±»å’ŒåŸºäºè§„åˆ™çš„ç»Ÿè®¡æŠ€æœ¯ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦æœªåœ¨æ‘˜è¦ä¸­ç»™å‡ºï¼Œä½†å¼ºè°ƒäº†è¯¥æ–¹æ³•åœ¨æ•ˆç‡å’Œå‡†ç¡®æ€§æ–¹é¢çš„ä¼˜åŠ¿ï¼Œä»¥åŠå¯¹LLMå±€é™æ€§çš„æœ‰æ•ˆè¡¥å¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè®¡ç®—æœºè§†è§‰æ¨¡å‹çš„æ€§èƒ½ä¼˜åŒ–ï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆå¿«é€Ÿå®šä½å’Œè§£å†³æ¨¡å‹ä¸­çš„æ€§èƒ½ç“¶é¢ˆï¼Œæé«˜æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ•°æ®é›†å¯ä»¥ä¿ƒè¿›ç›¸å…³é¢†åŸŸçš„ç ”ç©¶ï¼Œæ¨åŠ¨è‡ªåŠ¨åŒ–æ€§èƒ½åˆ†æå·¥å…·çš„å‘å±•ï¼Œé™ä½æ¨¡å‹ä¼˜åŒ–çš„é—¨æ§›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Identifying and addressing performance anti-patterns in machine learning (ML) models is critical for efficient training and inference, but it typically demands deep expertise spanning system infrastructure, ML models and kernel development. While large tech companies rely on dedicated ML infrastructure engineers to analyze torch traces and benchmarks, such resource-intensive workflows are largely inaccessible to computer vision researchers in general. Among the challenges, pinpointing problematic trace segments within lengthy execution traces remains the most time-consuming task, and is difficult to automate with current ML models, including LLMs. In this work, we present the first benchmark dataset specifically designed to evaluate and improve ML models' ability to detect anti patterns in traces. Our dataset contains over 600 PyTorch traces from diverse computer vision models classification, detection, segmentation, and generation collected across multiple hardware platforms. We also propose a novel iterative approach: a lightweight ML model first detects trace segments with anti patterns, followed by a large language model (LLM) for fine grained classification and targeted feedback. Experimental results demonstrate that our method significantly outperforms unsupervised clustering and rule based statistical techniques for detecting anti pattern regions. Our method also effectively compensates LLM's limited context length and reasoning inefficiencies.

