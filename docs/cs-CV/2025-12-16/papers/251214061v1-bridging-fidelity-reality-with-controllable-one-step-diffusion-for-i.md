---
layout: default
title: Bridging Fidelity-Reality with Controllable One-Step Diffusion for Image Super-Resolution
---

# Bridging Fidelity-Reality with Controllable One-Step Diffusion for Image Super-Resolution

**arXiv**: [2512.14061v1](https://arxiv.org/abs/2512.14061) | [PDF](https://arxiv.org/pdf/2512.14061.pdf)

**ä½œè€…**: Hao Chen, Junyang Chen, Jinshan Pan, Jiangxin Dong

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Project page: https://github.com/Chanson94/CODSR

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCODSRå¯æŽ§ä¸€æ­¥æ‰©æ•£ç½‘ç»œï¼Œé€šè¿‡LQå¼•å¯¼ç‰¹å¾è°ƒåˆ¶ã€åŒºåŸŸè‡ªé€‚åº”ç”Ÿæˆå…ˆéªŒæ¿€æ´»å’Œæ–‡æœ¬åŒ¹é…æŒ‡å¯¼ï¼Œè§£å†³å›¾åƒè¶…åˆ†è¾¨çŽ‡ä¸­ä¿çœŸåº¦ä¸è¶³ã€ç”Ÿæˆå…ˆéªŒæ¿€æ´»ä¸å……åˆ†å’Œæ–‡æœ¬æç¤ºé”™ä½é—®é¢˜ã€‚**

**å…³é”®è¯**: `å›¾åƒè¶…åˆ†è¾¨çŽ‡` `æ‰©æ•£æ¨¡åž‹` `ä¸€æ­¥æŽ¨ç†` `ä¿çœŸåº¦å¢žå¼º` `ç”Ÿæˆå…ˆéªŒæ¿€æ´»` `æ–‡æœ¬æŒ‡å¯¼` `å¯æŽ§ç½‘ç»œ` `åŒºåŸŸè‡ªé€‚åº”`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰ä¸€æ­¥æ‰©æ•£æ–¹æ³•åœ¨å›¾åƒè¶…åˆ†è¾¨çŽ‡ä¸­é¢ä¸´ä¿çœŸåº¦ä¸è¶³ã€ç”Ÿæˆå…ˆéªŒæ¿€æ´»ä¸å……åˆ†å’Œæ–‡æœ¬æç¤ºé”™ä½ä¸‰å¤§æŒ‘æˆ˜ã€‚
2. CODSRé€šè¿‡LQå¼•å¯¼ç‰¹å¾è°ƒåˆ¶ã€åŒºåŸŸè‡ªé€‚åº”ç”Ÿæˆå…ˆéªŒæ¿€æ´»å’Œæ–‡æœ¬åŒ¹é…æŒ‡å¯¼ï¼Œæå‡ä¿çœŸåº¦å’Œæ„ŸçŸ¥è´¨é‡ã€‚
3. å®žéªŒæ˜¾ç¤ºCODSRåœ¨ä¸€æ­¥æŽ¨ç†ä¸‹å®žçŽ°å“è¶Šæ„ŸçŸ¥è´¨é‡å’Œæœ‰ç«žäº‰åŠ›ä¿çœŸåº¦ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘æœŸåŸºäºŽæ‰©æ•£çš„ä¸€æ­¥æ–¹æ³•åœ¨å›¾åƒè¶…åˆ†è¾¨çŽ‡é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»å—é™äºŽä¸‰ä¸ªå…³é”®é—®é¢˜ï¼š(1) ç”±äºŽä½Žè´¨é‡è¾“å…¥åŽ‹ç¼©ç¼–ç å¯¼è‡´çš„ä¿¡æ¯æŸå¤±ï¼Œé€ æˆä¿çœŸåº¦æ€§èƒ½ä¸ä½³ï¼›(2) ç”Ÿæˆå…ˆéªŒçš„åŒºåŸŸåˆ¤åˆ«æ€§æ¿€æ´»ä¸è¶³ï¼›(3) æ–‡æœ¬æç¤ºä¸Žå…¶å¯¹åº”è¯­ä¹‰åŒºåŸŸä¹‹é—´çš„é”™ä½ã€‚ä¸ºè§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†CODSRï¼Œä¸€ç§å¯æŽ§çš„ä¸€æ­¥æ‰©æ•£ç½‘ç»œç”¨äºŽå›¾åƒè¶…åˆ†è¾¨çŽ‡ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªLQå¼•å¯¼çš„ç‰¹å¾è°ƒåˆ¶æ¨¡å—ï¼Œåˆ©ç”¨ä½Žè´¨é‡è¾“å…¥çš„åŽŸå§‹æœªåŽ‹ç¼©ä¿¡æ¯ä¸ºæ‰©æ•£è¿‡ç¨‹æä¾›é«˜ä¿çœŸåº¦æ¡ä»¶ã€‚ç„¶åŽï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŒºåŸŸè‡ªé€‚åº”çš„ç”Ÿæˆå…ˆéªŒæ¿€æ´»æ–¹æ³•ï¼Œä»¥æœ‰æ•ˆå¢žå¼ºæ„ŸçŸ¥ä¸°å¯Œæ€§è€Œä¸ç‰ºç‰²å±€éƒ¨ç»“æž„ä¿çœŸåº¦ã€‚æœ€åŽï¼Œæˆ‘ä»¬é‡‡ç”¨æ–‡æœ¬åŒ¹é…æŒ‡å¯¼ç­–ç•¥ï¼Œå……åˆ†åˆ©ç”¨æ–‡æœ¬æç¤ºçš„æ¡ä»¶æ½œåŠ›ã€‚å¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒCODSRåœ¨é«˜æ•ˆä¸€æ­¥æŽ¨ç†ä¸‹ï¼Œç›¸æ¯”æœ€å…ˆè¿›æ–¹æ³•å®žçŽ°äº†å“è¶Šçš„æ„ŸçŸ¥è´¨é‡å’Œæœ‰ç«žäº‰åŠ›çš„ä¿çœŸåº¦ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

CODSRæ˜¯ä¸€ä¸ªå¯æŽ§çš„ä¸€æ­¥æ‰©æ•£ç½‘ç»œï¼Œæ•´ä½“æ¡†æž¶åŸºäºŽæ‰©æ•£æ¨¡åž‹ï¼Œé€šè¿‡ä¸€æ­¥æŽ¨ç†å®žçŽ°å›¾åƒè¶…åˆ†è¾¨çŽ‡ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬ï¼šLQå¼•å¯¼ç‰¹å¾è°ƒåˆ¶æ¨¡å—ï¼Œåˆ©ç”¨ä½Žè´¨é‡è¾“å…¥çš„æœªåŽ‹ç¼©ä¿¡æ¯å¢žå¼ºä¿çœŸåº¦ï¼›åŒºåŸŸè‡ªé€‚åº”ç”Ÿæˆå…ˆéªŒæ¿€æ´»æ–¹æ³•ï¼Œé’ˆå¯¹ä¸åŒåŒºåŸŸè°ƒæ•´ç”Ÿæˆå…ˆéªŒä»¥å¹³è¡¡æ„ŸçŸ¥ä¸°å¯Œæ€§å’Œç»“æž„ä¿çœŸåº¦ï¼›æ–‡æœ¬åŒ¹é…æŒ‡å¯¼ç­–ç•¥ï¼Œä¼˜åŒ–æ–‡æœ¬æç¤ºä¸Žè¯­ä¹‰åŒºåŸŸçš„å¯¹åº”å…³ç³»ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼ŒCODSRç»¼åˆè§£å†³äº†ä¿çœŸåº¦æŸå¤±ã€å…ˆéªŒæ¿€æ´»ä¸è¶³å’Œæ–‡æœ¬é”™ä½é—®é¢˜ï¼Œé€šè¿‡æ¨¡å—åŒ–è®¾è®¡å®žçŽ°é«˜æ•ˆå¯æŽ§çš„è¶…åˆ†è¾¨çŽ‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

CODSRåœ¨ä¸€æ­¥æŽ¨ç†ä¸‹ï¼Œç›¸æ¯”æœ€å…ˆè¿›æ–¹æ³•ï¼Œå®žçŽ°äº†å“è¶Šçš„æ„ŸçŸ¥è´¨é‡å’Œæœ‰ç«žäº‰åŠ›çš„ä¿çœŸåº¦ï¼Œå®žéªŒéªŒè¯äº†å…¶åœ¨æ•ˆçŽ‡å’Œæ€§èƒ½ä¸Šçš„ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤æ‚åœºæ™¯æ—¶è¡¨çŽ°å‡ºè‰²ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽå›¾åƒå¢žå¼ºã€è§†é¢‘ä¿®å¤ã€åŒ»å­¦æˆåƒå’Œæ•°å­—åª’ä½“å¤„ç†ç­‰é¢†åŸŸï¼Œæå‡ä½Žåˆ†è¾¨çŽ‡å›¾åƒçš„è§†è§‰è´¨é‡å’Œç»†èŠ‚æ¢å¤èƒ½åŠ›ï¼Œå…·æœ‰å®žé™…ä»·å€¼å¦‚æ”¹å–„ç›‘æŽ§è§†é¢‘æ¸…æ™°åº¦æˆ–å¢žå¼ºåŽ†å²ç…§ç‰‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent diffusion-based one-step methods have shown remarkable progress in the field of image super-resolution, yet they remain constrained by three critical limitations: (1) inferior fidelity performance caused by the information loss from compression encoding of low-quality (LQ) inputs; (2) insufficient region-discriminative activation of generative priors; (3) misalignment between text prompts and their corresponding semantic regions. To address these limitations, we propose CODSR, a controllable one-step diffusion network for image super-resolution. First, we propose an LQ-guided feature modulation module that leverages original uncompressed information from LQ inputs to provide high-fidelity conditioning for the diffusion process. We then develop a region-adaptive generative prior activation method to effectively enhance perceptual richness without sacrificing local structural fidelity. Finally, we employ a text-matching guidance strategy to fully harness the conditioning potential of text prompts. Extensive experiments demonstrate that CODSR achieves superior perceptual quality and competitive fidelity compared with state-of-the-art methods with efficient one-step inference.

