---
layout: default
title: Distill Video Datasets into Images
---

# Distill Video Datasets into Images

**arXiv**: [2512.14621v1](https://arxiv.org/abs/2512.14621) | [PDF](https://arxiv.org/pdf/2512.14621.pdf)

**ä½œè€…**: Zhenghao Zhao, Haoxuan Wang, Kai Wang, Yuzhang Shang, Yuan Hong, Yan Yan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå•å¸§è§†é¢‘é›†è’¸é¦æ¡†æž¶ä»¥è§£å†³è§†é¢‘æ•°æ®é›†è’¸é¦ä¸­å‚æ•°æ¿€å¢žå’Œä¼˜åŒ–å›°éš¾çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `è§†é¢‘æ•°æ®é›†è’¸é¦` `å•å¸§è’¸é¦` `å¯å¾®åˆ†æ’å€¼` `é€šé“é‡å¡‘` `ä¼˜åŒ–æ•ˆçŽ‡` `åŠ¨ä½œè¯†åˆ«` `è§†é¢‘åˆ†ç±»` `è®¡ç®—æˆæœ¬é™ä½Ž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†é¢‘æ•°æ®é›†è’¸é¦é¢ä¸´æ—¶é—´ç»´åº¦å¯¼è‡´å‚æ•°æ¿€å¢žï¼Œä¼˜åŒ–å¤æ‚ä¸”æ”¶æ•›å›°éš¾ã€‚
2. æå‡ºSFVDæ¡†æž¶ï¼Œå°†è§†é¢‘è’¸é¦ä¸ºå•å¸§ï¼Œé€šè¿‡å¯å¾®åˆ†æ’å€¼å’Œé€šé“é‡å¡‘æ•´åˆæ—¶é—´ä¿¡æ¯ã€‚
3. åœ¨MiniUCFç­‰åŸºå‡†ä¸Šæ˜¾è‘—è¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œæ€§èƒ½æå‡æœ€é«˜è¾¾5.3%ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ•°æ®é›†è’¸é¦æ—¨åœ¨åˆæˆç´§å‡‘è€Œä¿¡æ¯ä¸°å¯Œçš„æ•°æ®é›†ï¼Œä½¿åœ¨å…¶ä¸Šè®­ç»ƒçš„æ¨¡åž‹èƒ½è¾¾åˆ°ä¸Žåœ¨å…¨æ•°æ®é›†ä¸Šè®­ç»ƒç›¸å½“çš„æ€§èƒ½ã€‚è™½ç„¶è¯¥æ–¹æ³•åœ¨å›¾åƒæ•°æ®ä¸Šå·²æ˜¾ç¤ºå‡ºæœ‰å¸Œæœ›çš„ç»“æžœï¼Œä½†å°†æ•°æ®é›†è’¸é¦æ–¹æ³•æ‰©å±•åˆ°è§†é¢‘æ•°æ®å·²è¢«è¯æ˜Žå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå¹¶ä¸”é€šå¸¸å¯¼è‡´æ¬¡ä¼˜æ€§èƒ½ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆå°†è§†é¢‘é›†è’¸é¦çš„æ ¸å¿ƒæŒ‘æˆ˜ç¡®å®šä¸ºè§†é¢‘æ—¶é—´ç»´åº¦å¼•å…¥çš„å¯å­¦ä¹ å‚æ•°å¤§å¹…å¢žåŠ ï¼Œè¿™ä½¿ä¼˜åŒ–å¤æ‚åŒ–å¹¶é˜»ç¢æ”¶æ•›ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°å•ä¸ªå¸§é€šå¸¸è¶³ä»¥æ•æ‰è§†é¢‘çš„åˆ¤åˆ«æ€§è¯­ä¹‰ã€‚åˆ©ç”¨è¿™ä¸€è§è§£ï¼Œæˆ‘ä»¬æå‡ºäº†å•å¸§è§†é¢‘é›†è’¸é¦ï¼ˆSFVDï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå°†è§†é¢‘è’¸é¦ä¸ºæ¯ä¸ªç±»åˆ«é«˜åº¦ä¿¡æ¯ä¸°å¯Œçš„å¸§çš„æ¡†æž¶ã€‚ä½¿ç”¨å¯å¾®åˆ†æ’å€¼ï¼Œè¿™äº›å¸§è¢«è½¬æ¢ä¸ºè§†é¢‘åºåˆ—å¹¶ä¸ŽåŽŸå§‹æ•°æ®é›†åŒ¹é…ï¼ŒåŒæ—¶æ›´æ–°ä»…é™äºŽå¸§æœ¬èº«ä»¥æé«˜ä¼˜åŒ–æ•ˆçŽ‡ã€‚ä¸ºäº†è¿›ä¸€æ­¥æ•´åˆæ—¶é—´ä¿¡æ¯ï¼Œåœ¨åŒ¹é…è¿‡ç¨‹ä¸­é€šè¿‡é€šé“é‡å¡‘å±‚å°†è’¸é¦å¸§ä¸Žä»ŽçœŸå®žè§†é¢‘ä¸­é‡‡æ ·çš„çœŸå®žè§†é¢‘ç»“åˆã€‚åœ¨å¤šä¸ªåŸºå‡†ä¸Šçš„å¹¿æ³›å®žéªŒè¡¨æ˜Žï¼ŒSFVDæ˜¾è‘—ä¼˜äºŽå…ˆå‰æ–¹æ³•ï¼Œåœ¨MiniUCFä¸Šå®žçŽ°äº†é«˜è¾¾5.3%çš„æ”¹è¿›ï¼Œä»Žè€Œæä¾›äº†æ›´æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

SFVDæ¡†æž¶çš„æ ¸å¿ƒæ˜¯å°†è§†é¢‘æ•°æ®é›†è’¸é¦ä¸ºæ¯ä¸ªç±»åˆ«çš„ä»£è¡¨æ€§å•å¸§ã€‚æ•´ä½“æ¡†æž¶åŒ…æ‹¬ï¼šé¦–å…ˆï¼Œä¸ºæ¯ä¸ªç±»åˆ«åˆæˆé«˜åº¦ä¿¡æ¯ä¸°å¯Œçš„å•å¸§ä½œä¸ºè’¸é¦æ ¸å¿ƒï¼›å…¶æ¬¡ï¼Œé€šè¿‡å¯å¾®åˆ†æ’å€¼æŠ€æœ¯å°†è¿™äº›å•å¸§æ‰©å±•ä¸ºè§†é¢‘åºåˆ—ï¼Œä»¥æ¨¡æ‹ŸåŽŸå§‹è§†é¢‘çš„æ—¶é—´åŠ¨æ€ï¼›ç¬¬ä¸‰ï¼Œåœ¨åŒ¹é…è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡é€šé“é‡å¡‘å±‚å°†è’¸é¦å¸§ä¸Žé‡‡æ ·çš„çœŸå®žè§†é¢‘ç»“åˆï¼Œä»¥æ•´åˆé¢å¤–çš„æ—¶é—´ä¿¡æ¯ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°åœ¨äºŽå°†ä¼˜åŒ–é™åˆ¶åœ¨å•å¸§ä¸Šï¼Œå¤§å¹…å‡å°‘å¯å­¦ä¹ å‚æ•°ï¼Œä»Žè€Œç®€åŒ–ä¼˜åŒ–è¿‡ç¨‹å¹¶æé«˜æ•ˆçŽ‡ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽé¿å…äº†ç›´æŽ¥å¤„ç†é«˜ç»´è§†é¢‘åºåˆ—çš„å¤æ‚æ€§ï¼Œè€Œæ˜¯é€šè¿‡å•å¸§è’¸é¦å’Œæ’å€¼ç­–ç•¥æœ‰æ•ˆæ•æ‰è§†é¢‘çš„åˆ¤åˆ«æ€§è¯­ä¹‰ï¼ŒåŒæ—¶é€šè¿‡é€šé“é‡å¡‘å¼•å…¥æ—¶é—´ä¸Šä¸‹æ–‡ï¼Œå®žçŽ°æ›´ä¼˜çš„æ€§èƒ½ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨MiniUCFåŸºå‡†ä¸Šï¼ŒSFVDå®žçŽ°äº†é«˜è¾¾5.3%çš„æ€§èƒ½æå‡ï¼Œæ˜¾è‘—ä¼˜äºŽå…ˆå‰è§†é¢‘æ•°æ®é›†è’¸é¦æ–¹æ³•ï¼ŒéªŒè¯äº†å•å¸§è’¸é¦æ¡†æž¶çš„æœ‰æ•ˆæ€§å’Œä¼˜åŒ–æ•ˆçŽ‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è§†é¢‘ç†è§£ã€åŠ¨ä½œè¯†åˆ«å’Œè§†é¢‘åˆ†ç±»ç­‰é¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œèƒ½æ˜¾è‘—é™ä½Žè§†é¢‘æ•°æ®å­˜å‚¨å’Œè®¡ç®—æˆæœ¬ï¼ŒåŠ é€Ÿæ¨¡åž‹è®­ç»ƒï¼Œé€‚ç”¨äºŽèµ„æºå—é™çŽ¯å¢ƒå¦‚è¾¹ç¼˜è®¾å¤‡æˆ–å¤§è§„æ¨¡è§†é¢‘åˆ†æžç³»ç»Ÿã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Dataset distillation aims to synthesize compact yet informative datasets that allow models trained on them to achieve performance comparable to training on the full dataset. While this approach has shown promising results for image data, extending dataset distillation methods to video data has proven challenging and often leads to suboptimal performance. In this work, we first identify the core challenge in video set distillation as the substantial increase in learnable parameters introduced by the temporal dimension of video, which complicates optimization and hinders convergence. To address this issue, we observe that a single frame is often sufficient to capture the discriminative semantics of a video. Leveraging this insight, we propose Single-Frame Video set Distillation (SFVD), a framework that distills videos into highly informative frames for each class. Using differentiable interpolation, these frames are transformed into video sequences and matched with the original dataset, while updates are restricted to the frames themselves for improved optimization efficiency. To further incorporate temporal information, the distilled frames are combined with sampled real videos from real videos during the matching process through a channel reshaping layer. Extensive experiments on multiple benchmarks demonstrate that SFVD substantially outperforms prior methods, achieving improvements of up to 5.3% on MiniUCF, thereby offering a more effective solution.

