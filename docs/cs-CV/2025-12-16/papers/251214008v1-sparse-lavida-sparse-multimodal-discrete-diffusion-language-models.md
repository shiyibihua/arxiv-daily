---
layout: default
title: Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models
---

# Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14008" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14008v1</a>
  <a href="https://arxiv.org/pdf/2512.14008.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14008v1" onclick="toggleFavorite(this, '2512.14008v1', 'Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shufan Li, Jiuxiang Gu, Kangning Liu, Zhe Lin, Zijun Wei, Aditya Grover, Jason Kuen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 18 pages (12 pages for the main paper and 6 pages for the appendix), 9 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Sparse-LaViDaï¼šé€šè¿‡ç¨€ç–åŒ–é‡‡æ ·åŠ é€Ÿå¤šæ¨¡æ€ç¦»æ•£æ‰©æ•£è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `ç¦»æ•£æ‰©æ•£æ¨¡å‹` `æ¨¡å‹åŠ é€Ÿ` `ç¨€ç–åŒ–` `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ©ç ç¦»æ•£æ‰©æ•£æ¨¡å‹(MDM)åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†æ¨ç†é€Ÿåº¦å› é‡å¤å¤„ç†å†—ä½™æ©ç tokenè€Œå—é™ã€‚
2. Sparse-LaViDaé€šè¿‡åŠ¨æ€æˆªæ–­ä¸å¿…è¦çš„æ©ç tokenæ¥åŠ é€ŸMDMé‡‡æ ·ï¼Œå¹¶å¼•å…¥å¯„å­˜å™¨tokenä¿æŒç”Ÿæˆè´¨é‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSparse-LaViDaåœ¨å¤šç§ä»»åŠ¡ä¸­å®ç°äº†é«˜è¾¾2å€çš„åŠ é€Ÿï¼ŒåŒæ—¶ä¿æŒäº†ä¸LaViDa-Oç›¸å½“çš„ç”Ÿæˆè´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºSparse-LaViDaï¼Œä¸€ç§æ–°é¢–çš„å»ºæ¨¡æ¡†æ¶ï¼Œæ—¨åœ¨åŠ¨æ€æˆªæ–­æ¯ä¸ªæ¨ç†æ­¥éª¤ä¸­ä¸å¿…è¦çš„æ©ç tokenï¼Œä»è€ŒåŠ é€Ÿæ©ç ç¦»æ•£æ‰©æ•£æ¨¡å‹(MDM)çš„é‡‡æ ·è¿‡ç¨‹ã€‚ä¸ºäº†ä¿æŒç”Ÿæˆè´¨é‡ï¼Œå¼•å…¥äº†ä¸“é—¨çš„å¯„å­˜å™¨tokenï¼Œä½œä¸ºè¢«æˆªæ–­tokençš„ç´§å‡‘è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¡®ä¿è®­ç»ƒå’Œæ¨ç†ä¹‹é—´çš„ä¸€è‡´æ€§ï¼Œè®¾è®¡äº†ä¸€ç§ä¸“é—¨çš„æ³¨æ„åŠ›æ©ç ï¼Œåœ¨è®­ç»ƒæœŸé—´å¿ å®åœ°åŒ¹é…æˆªæ–­é‡‡æ ·è¿‡ç¨‹ã€‚åŸºäºæœ€å…ˆè¿›çš„ç»Ÿä¸€MDM LaViDa-Oï¼ŒSparse-LaViDaåœ¨åŒ…æ‹¬æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘å’Œæ•°å­¦æ¨ç†ç­‰å¤šç§ä»»åŠ¡ä¸­å®ç°äº†é«˜è¾¾2å€çš„åŠ é€Ÿï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆè´¨é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„æ©ç ç¦»æ•£æ‰©æ•£æ¨¡å‹ï¼ˆMDMsï¼‰åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆæœï¼Œä½†å…¶æ¨ç†é€Ÿåº¦å—åˆ°é™åˆ¶ã€‚ä¸»è¦åŸå› æ˜¯éœ€è¦åœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤ä¸­é‡å¤å¤„ç†å¤§é‡çš„æ©ç tokenï¼Œè¿™äº›tokenåœ¨åç»­æ­¥éª¤ä¸­å¯èƒ½å˜å¾—ä¸å¿…è¦ï¼Œä»è€Œé€ æˆè®¡ç®—èµ„æºçš„æµªè´¹ã€‚å› æ­¤ï¼Œå¦‚ä½•å‡å°‘å†—ä½™è®¡ç®—ï¼ŒåŠ é€ŸMDMçš„æ¨ç†è¿‡ç¨‹æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSparse-LaViDaçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€åœ°æˆªæ–­é‚£äº›ä¸å¿…è¦çš„æ©ç tokenï¼Œä»è€Œå‡å°‘è®¡ç®—é‡ã€‚ä¸ºäº†å¼¥è¡¥æˆªæ–­tokenå¯èƒ½å¸¦æ¥çš„ä¿¡æ¯æŸå¤±ï¼Œå¼•å…¥äº†â€œå¯„å­˜å™¨tokenâ€ä½œä¸ºè¢«æˆªæ–­tokençš„ç´§å‡‘è¡¨ç¤ºï¼Œä»¥ä¿ç•™å…³é”®ä¿¡æ¯ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥åœ¨åŠ é€Ÿæ¨ç†çš„åŒæ—¶ï¼Œå°½å¯èƒ½åœ°ä¿æŒç”Ÿæˆè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSparse-LaViDaå»ºç«‹åœ¨ç°æœ‰çš„MDMæ¡†æ¶ï¼ˆå…·ä½“ä¸ºLaViDa-Oï¼‰ä¹‹ä¸Šã€‚å…¶ä¸»è¦æµç¨‹å¦‚ä¸‹ï¼š1. åœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤ä¸­ï¼Œæ¨¡å‹è¯„ä¼°å„ä¸ªæ©ç tokençš„é‡è¦æ€§ã€‚2. æ ¹æ®é‡è¦æ€§å¾—åˆ†ï¼Œæˆªæ–­ä¸€éƒ¨åˆ†ä¸é‡è¦çš„æ©ç tokenã€‚3. å°†è¢«æˆªæ–­çš„tokençš„ä¿¡æ¯èšåˆåˆ°å¯¹åº”çš„å¯„å­˜å™¨tokenä¸­ã€‚4. ä½¿ç”¨å‰©ä½™çš„tokenï¼ˆåŒ…æ‹¬æœªæˆªæ–­çš„æ©ç tokenå’Œå¯„å­˜å™¨tokenï¼‰è¿›è¡Œåç»­çš„é‡‡æ ·æ­¥éª¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šSparse-LaViDaçš„å…³é”®åˆ›æ–°åœ¨äºåŠ¨æ€æˆªæ–­æœºåˆ¶å’Œå¯„å­˜å™¨tokençš„è®¾è®¡ã€‚åŠ¨æ€æˆªæ–­æœºåˆ¶èƒ½å¤Ÿè‡ªé€‚åº”åœ°å‡å°‘è®¡ç®—é‡ï¼Œè€Œå¯„å­˜å™¨tokenåˆ™èƒ½å¤Ÿæœ‰æ•ˆåœ°ä¿ç•™è¢«æˆªæ–­tokençš„ä¿¡æ¯ï¼Œä»è€Œé¿å…ç”Ÿæˆè´¨é‡çš„ä¸‹é™ã€‚æ­¤å¤–ï¼Œä¸ºäº†ä¿è¯è®­ç»ƒå’Œæ¨ç†çš„ä¸€è‡´æ€§ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸€ç§ç‰¹æ®Šçš„æ³¨æ„åŠ›æ©ç ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡æ‹Ÿæˆªæ–­é‡‡æ ·è¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³äºåŠ¨æ€æˆªæ–­æœºåˆ¶ï¼Œè®ºæ–‡å¯èƒ½é‡‡ç”¨äº†ä¸€ç§åŸºäºæ³¨æ„åŠ›å¾—åˆ†æˆ–è€…å…¶ä»–é‡è¦æ€§æŒ‡æ ‡çš„æ–¹æ³•æ¥è¯„ä¼°æ©ç tokençš„é‡è¦æ€§ã€‚å¯„å­˜å™¨tokençš„è®¾è®¡å¯èƒ½æ¶‰åŠåˆ°ä¸€ç§ä¿¡æ¯èšåˆæœºåˆ¶ï¼Œä¾‹å¦‚ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æˆ–è€…ç®€å•çš„å¹³å‡æ± åŒ–ã€‚æ³¨æ„åŠ›æ©ç çš„è®¾è®¡éœ€è¦ä¿è¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°å¦‚ä½•å¤„ç†è¢«æˆªæ–­çš„tokenä»¥åŠå¯„å­˜å™¨tokenã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰ç»†èŠ‚åœ¨è®ºæ–‡ä¸­åº”è¯¥æœ‰æ›´è¯¦ç»†çš„æè¿°ï¼Œä½†æ ¹æ®æ‘˜è¦ä¿¡æ¯æ— æ³•å¾—çŸ¥ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14008v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14008v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14008v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

Sparse-LaViDaåœ¨å¤šç§ä»»åŠ¡ä¸­å®ç°äº†æ˜¾è‘—çš„åŠ é€Ÿæ•ˆæœã€‚ä¾‹å¦‚ï¼Œåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘å’Œæ•°å­¦æ¨ç†ç­‰ä»»åŠ¡ä¸­ï¼ŒSparse-LaViDaå®ç°äº†é«˜è¾¾2å€çš„åŠ é€Ÿï¼ŒåŒæ—¶ä¿æŒäº†ä¸åŸºçº¿æ¨¡å‹LaViDa-Oç›¸å½“çš„ç”Ÿæˆè´¨é‡ã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒSparse-LaViDaæ˜¯ä¸€ç§æœ‰æ•ˆçš„åŠ é€ŸMDMæ¨ç†çš„æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Sparse-LaViDaå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘ã€è§†é¢‘ç”Ÿæˆã€æ•°å­¦æ¨ç†ç­‰ã€‚å…¶åŠ é€Ÿæ¨ç†çš„èƒ½åŠ›ä½¿å¾—MDMèƒ½å¤Ÿæ›´é«˜æ•ˆåœ°åº”ç”¨äºèµ„æºå—é™çš„è®¾å¤‡ä¸Šï¼Œä¾‹å¦‚ç§»åŠ¨è®¾å¤‡å’ŒåµŒå…¥å¼ç³»ç»Ÿã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ä¿ƒè¿›MDMåœ¨äº¤äº’å¼åº”ç”¨ä¸­çš„åº”ç”¨ï¼Œä¾‹å¦‚å®æ—¶å›¾åƒç¼–è¾‘å’Œç”Ÿæˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Masked Discrete Diffusion Models (MDMs) have achieved strong performance across a wide range of multimodal tasks, including image understanding, generation, and editing. However, their inference speed remains suboptimal due to the need to repeatedly process redundant masked tokens at every sampling step. In this work, we propose Sparse-LaViDa, a novel modeling framework that dynamically truncates unnecessary masked tokens at each inference step to accelerate MDM sampling. To preserve generation quality, we introduce specialized register tokens that serve as compact representations for the truncated tokens. Furthermore, to ensure consistency between training and inference, we design a specialized attention mask that faithfully matches the truncated sampling procedure during training. Built upon the state-of-the-art unified MDM LaViDa-O, Sparse-LaViDa achieves up to a 2x speedup across diverse tasks including text-to-image generation, image editing, and mathematical reasoning, while maintaining generation quality.

