---
layout: default
title: Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models
---

# Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models

**arXiv**: [2512.14008v1](https://arxiv.org/abs/2512.14008) | [PDF](https://arxiv.org/pdf/2512.14008.pdf)

**ä½œè€…**: Shufan Li, Jiuxiang Gu, Kangning Liu, Zhe Lin, Zijun Wei, Aditya Grover, Jason Kuen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 18 pages (12 pages for the main paper and 6 pages for the appendix), 9 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSparse-LaViDaæ¡†æž¶ï¼Œé€šè¿‡åŠ¨æ€æˆªæ–­å†—ä½™æŽ©ç æ ‡è®°ä»¥åŠ é€ŸæŽ©ç ç¦»æ•£æ‰©æ•£æ¨¡åž‹æŽ¨ç†ï¼ŒåŒæ—¶ä¿æŒç”Ÿæˆè´¨é‡ã€‚**

**å…³é”®è¯**: `ç¨€ç–æ‰©æ•£æ¨¡åž‹` `å¤šæ¨¡æ€æŽ¨ç†` `æŽ©ç ç¦»æ•£æ‰©æ•£` `åŠ é€Ÿé‡‡æ ·` `å¯„å­˜å™¨æ ‡è®°` `æ³¨æ„åŠ›æŽ©ç ` `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `å›¾åƒç¼–è¾‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æŽ©ç ç¦»æ•£æ‰©æ•£æ¨¡åž‹æŽ¨ç†é€Ÿåº¦æ…¢ï¼Œå› éœ€åœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤é‡å¤å¤„ç†å†—ä½™æŽ©ç æ ‡è®°ï¼Œå¯¼è‡´æ•ˆçŽ‡ä½Žä¸‹ã€‚
2. æå‡ºSparse-LaViDaæ¡†æž¶ï¼ŒåŠ¨æ€æˆªæ–­å†—ä½™æ ‡è®°å¹¶ä½¿ç”¨å¯„å­˜å™¨æ ‡è®°ä¿æŒè´¨é‡ï¼Œè®¾è®¡æ³¨æ„åŠ›æŽ©ç ç¡®ä¿è®­ç»ƒä¸ŽæŽ¨ç†ä¸€è‡´ã€‚
3. åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç­‰ä»»åŠ¡ä¸­å®žçŽ°é«˜è¾¾2å€åŠ é€Ÿï¼ŒåŒæ—¶ç»´æŒç”Ÿæˆè´¨é‡ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŽ©ç ç¦»æ•£æ‰©æ•£æ¨¡åž‹ï¼ˆMDMsï¼‰åœ¨å›¾åƒç†è§£ã€ç”Ÿæˆå’Œç¼–è¾‘ç­‰å¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨çŽ°å‡ºè‰²ï¼Œä½†å…¶æŽ¨ç†é€Ÿåº¦å› éœ€åœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤é‡å¤å¤„ç†å†—ä½™æŽ©ç æ ‡è®°è€Œå—é™ã€‚æœ¬æ–‡æå‡ºSparse-LaViDaï¼Œä¸€ç§æ–°é¢–çš„å»ºæ¨¡æ¡†æž¶ï¼Œé€šè¿‡åŠ¨æ€æˆªæ–­æ¯ä¸ªæŽ¨ç†æ­¥éª¤ä¸­ä¸å¿…è¦çš„æŽ©ç æ ‡è®°æ¥åŠ é€ŸMDMé‡‡æ ·ã€‚ä¸ºä¿æŒç”Ÿæˆè´¨é‡ï¼Œå¼•å…¥äº†ä¸“é—¨çš„å¯„å­˜å™¨æ ‡è®°ä½œä¸ºæˆªæ–­æ ‡è®°çš„ç´§å‡‘è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œä¸ºç¡®ä¿è®­ç»ƒä¸ŽæŽ¨ç†çš„ä¸€è‡´æ€§ï¼Œè®¾è®¡äº†ä¸“é—¨çš„æ³¨æ„åŠ›æŽ©ç ï¼Œåœ¨è®­ç»ƒä¸­å¿ å®žåŒ¹é…æˆªæ–­é‡‡æ ·è¿‡ç¨‹ã€‚åŸºäºŽæœ€å…ˆè¿›çš„ç»Ÿä¸€MDM LaViDa-Oï¼ŒSparse-LaViDaåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘å’Œæ•°å­¦æŽ¨ç†ç­‰å¤šæ ·åŒ–ä»»åŠ¡ä¸­å®žçŽ°äº†é«˜è¾¾2å€çš„åŠ é€Ÿï¼ŒåŒæ—¶ç»´æŒç”Ÿæˆè´¨é‡ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

Sparse-LaViDaåŸºäºŽLaViDa-Oç»Ÿä¸€MDMæ¡†æž¶ï¼Œæ ¸å¿ƒåˆ›æ–°åœ¨äºŽåŠ¨æ€æˆªæ–­æœºåˆ¶ï¼šåœ¨æŽ¨ç†æ—¶è¯†åˆ«å¹¶ç§»é™¤å†—ä½™æŽ©ç æ ‡è®°ï¼Œå¼•å…¥å¯„å­˜å™¨æ ‡è®°ä½œä¸ºå…¶ç´§å‡‘è¡¨ç¤ºä»¥ä¿ç•™ä¿¡æ¯ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬ä¸“é—¨è®¾è®¡çš„æ³¨æ„åŠ›æŽ©ç ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹æ¨¡æ‹Ÿæˆªæ–­é‡‡æ ·ï¼Œä»Žè€Œä¿æŒä¸€è‡´æ€§ã€‚ä¸ŽçŽ°æœ‰MDMæ–¹æ³•ç›¸æ¯”ï¼Œä¸»è¦åŒºåˆ«åœ¨äºŽé€šè¿‡ç¨€ç–åŒ–å¤„ç†å‡å°‘è®¡ç®—å¼€é”€ï¼Œè€Œéžä¾èµ–å…¨æ ‡è®°å¤„ç†ï¼Œæ˜¾è‘—æå‡æŽ¨ç†æ•ˆçŽ‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒSparse-LaViDaåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘å’Œæ•°å­¦æŽ¨ç†ä»»åŠ¡ä¸­å®žçŽ°é«˜è¾¾2å€æŽ¨ç†åŠ é€Ÿï¼ŒåŒæ—¶ç”Ÿæˆè´¨é‡ä¸ŽåŸºçº¿æ¨¡åž‹ç›¸å½“ï¼ŒéªŒè¯äº†æ¡†æž¶çš„æœ‰æ•ˆæ€§å’Œå®žç”¨æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽå¤šæ¨¡æ€äººå·¥æ™ºèƒ½é¢†åŸŸï¼Œå¦‚æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘å’Œæ•°å­¦æŽ¨ç†ä»»åŠ¡ï¼Œé€šè¿‡åŠ é€ŸæŽ¨ç†è¿‡ç¨‹ï¼Œæå‡å®žæ—¶äº¤äº’å’Œæ‰¹é‡å¤„ç†æ•ˆçŽ‡ï¼Œå…·æœ‰å®žé™…éƒ¨ç½²ä»·å€¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Masked Discrete Diffusion Models (MDMs) have achieved strong performance across a wide range of multimodal tasks, including image understanding, generation, and editing. However, their inference speed remains suboptimal due to the need to repeatedly process redundant masked tokens at every sampling step. In this work, we propose Sparse-LaViDa, a novel modeling framework that dynamically truncates unnecessary masked tokens at each inference step to accelerate MDM sampling. To preserve generation quality, we introduce specialized register tokens that serve as compact representations for the truncated tokens. Furthermore, to ensure consistency between training and inference, we design a specialized attention mask that faithfully matches the truncated sampling procedure during training. Built upon the state-of-the-art unified MDM LaViDa-O, Sparse-LaViDa achieves up to a 2x speedup across diverse tasks including text-to-image generation, image editing, and mathematical reasoning, while maintaining generation quality.

