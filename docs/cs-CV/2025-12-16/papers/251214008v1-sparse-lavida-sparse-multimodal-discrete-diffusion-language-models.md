---
layout: default
title: Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models
---

# Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14008" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14008v1</a>
  <a href="https://arxiv.org/pdf/2512.14008.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14008v1" onclick="toggleFavorite(this, '2512.14008v1', 'Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shufan Li, Jiuxiang Gu, Kangning Liu, Zhe Lin, Zijun Wei, Aditya Grover, Jason Kuen

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 18 pages (12 pages for the main paper and 6 pages for the appendix), 9 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Sparse-LaViDaï¼šé€šè¿‡ç¨€ç–åŒ–é‡‡æ ·åŠ é€Ÿå¤šæ¨¡æ€ç¦»æ•£æ‰©æ•£è¯­è¨€æ¨¡å‹æ¨ç†ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹` `ç¨€ç–é‡‡æ ·` `æ¨ç†åŠ é€Ÿ` `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `å›¾åƒç¼–è¾‘`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. MDMæ¨ç†é€Ÿåº¦å—é™äºé‡å¤å¤„ç†å†—ä½™æ©ç tokenï¼Œæ•ˆç‡æœ‰å¾…æå‡ã€‚
2. Sparse-LaViDaåŠ¨æ€æˆªæ–­ä¸å¿…è¦çš„æ©ç tokenï¼Œå¹¶ç”¨register tokenä¿æŒç”Ÿæˆè´¨é‡ã€‚
3. é€šè¿‡ä¸“é—¨è®¾è®¡çš„attention maskï¼Œç¡®ä¿è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹çš„ä¸€è‡´æ€§ï¼ŒåŠ é€Ÿæ•ˆæœæ˜¾è‘—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºSparse-LaViDaçš„æ–°å»ºæ¨¡æ¡†æ¶ï¼Œæ—¨åœ¨åŠ é€ŸMasked Discrete Diffusion Models (MDMs)çš„æ¨ç†è¿‡ç¨‹ã€‚MDMsåœ¨å›¾åƒç†è§£ã€ç”Ÿæˆå’Œç¼–è¾‘ç­‰å¤šç§å¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºéœ€è¦åœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤ä¸­é‡å¤å¤„ç†å†—ä½™çš„æ©ç tokenï¼Œå…¶æ¨ç†é€Ÿåº¦ä»æœ‰ä¼˜åŒ–ç©ºé—´ã€‚Sparse-LaViDaé€šè¿‡åœ¨æ¯ä¸ªæ¨ç†æ­¥éª¤ä¸­åŠ¨æ€æˆªæ–­ä¸å¿…è¦çš„æ©ç tokenæ¥åŠ é€ŸMDMé‡‡æ ·ã€‚ä¸ºäº†ä¿æŒç”Ÿæˆè´¨é‡ï¼Œå¼•å…¥äº†ä¸“é—¨çš„register tokenä½œä¸ºæˆªæ–­tokençš„ç´§å‡‘è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¡®ä¿è®­ç»ƒå’Œæ¨ç†ä¹‹é—´çš„ä¸€è‡´æ€§ï¼Œè®¾è®¡äº†ä¸€ç§ä¸“é—¨çš„attention maskï¼Œåœ¨è®­ç»ƒæœŸé—´å¿ å®åœ°åŒ¹é…æˆªæ–­é‡‡æ ·è¿‡ç¨‹ã€‚åŸºäºæœ€å…ˆè¿›çš„ç»Ÿä¸€MDM LaViDa-Oï¼ŒSparse-LaViDaåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘å’Œæ•°å­¦æ¨ç†ç­‰å¤šç§ä»»åŠ¡ä¸­å®ç°äº†é«˜è¾¾2å€çš„åŠ é€Ÿï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆè´¨é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰Masked Discrete Diffusion Models (MDMs)åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†æ¨ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œä¸»è¦åŸå› æ˜¯éœ€è¦åœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤ä¸­é‡å¤å¤„ç†å¤§é‡çš„æ©ç tokenã€‚è¿™äº›å†—ä½™çš„è®¡ç®—æ¶ˆè€—äº†å¤§é‡çš„è®¡ç®—èµ„æºï¼Œé™åˆ¶äº†MDMsåœ¨å®é™…åº”ç”¨ä¸­çš„æ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSparse-LaViDaçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€åœ°æˆªæ–­ä¸å¿…è¦çš„æ©ç tokenï¼Œä»è€Œå‡å°‘è®¡ç®—é‡ï¼ŒåŠ é€Ÿé‡‡æ ·è¿‡ç¨‹ã€‚ä¸ºäº†å¼¥è¡¥æˆªæ–­tokenå¯èƒ½é€ æˆçš„ç”Ÿæˆè´¨é‡æŸå¤±ï¼Œå¼•å…¥äº†register tokenä½œä¸ºæˆªæ–­tokençš„ç´§å‡‘è¡¨ç¤ºï¼Œä»¥ä¿ç•™å…³é”®ä¿¡æ¯ã€‚é€šè¿‡è¿™ç§ç¨€ç–åŒ–çš„æ–¹å¼ï¼Œå¯ä»¥åœ¨ä¿è¯ç”Ÿæˆè´¨é‡çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSparse-LaViDaå»ºç«‹åœ¨LaViDa-Oæ¨¡å‹ä¹‹ä¸Šï¼Œå…¶æ•´ä½“æ¡†æ¶ä»ç„¶æ˜¯æ‰©æ•£æ¨¡å‹ã€‚ä¸»è¦æ”¹è¿›åœ¨äºé‡‡æ ·é˜¶æ®µã€‚åœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤ä¸­ï¼Œæ¨¡å‹é¦–å…ˆè¯„ä¼°å„ä¸ªæ©ç tokençš„é‡è¦æ€§ï¼Œç„¶åæ ¹æ®é‡è¦æ€§å¾—åˆ†æˆªæ–­ä¸€éƒ¨åˆ†tokenã€‚è¢«æˆªæ–­çš„tokençš„ä¿¡æ¯è¢«èšåˆåˆ°register tokenä¸­ã€‚ç„¶åï¼Œæ¨¡å‹åŸºäºå‰©ä½™çš„tokenå’Œregister tokenè¿›è¡Œä¸‹ä¸€æ­¥çš„é‡‡æ ·ã€‚

**å…³é”®åˆ›æ–°**ï¼šSparse-LaViDaçš„å…³é”®åˆ›æ–°åœ¨äºåŠ¨æ€ç¨€ç–åŒ–é‡‡æ ·å’Œregister tokençš„è®¾è®¡ã€‚åŠ¨æ€ç¨€ç–åŒ–é‡‡æ ·å…è®¸æ¨¡å‹è‡ªé€‚åº”åœ°å‡å°‘è®¡ç®—é‡ï¼Œè€Œregister tokenåˆ™ä¿è¯äº†åœ¨ç¨€ç–åŒ–è¿‡ç¨‹ä¸­ä¿¡æ¯çš„æœ‰æ•ˆä¿ç•™ã€‚æ­¤å¤–ï¼Œä¸“é—¨è®¾è®¡çš„attention maskç¡®ä¿äº†è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹çš„ä¸€è‡´æ€§ï¼Œé¿å…äº†å› è®­ç»ƒå’Œæ¨ç†å·®å¼‚å¯¼è‡´çš„æ€§èƒ½ä¸‹é™ã€‚

**å…³é”®è®¾è®¡**ï¼šregister tokençš„æ•°é‡æ˜¯ä¸€ä¸ªå…³é”®å‚æ•°ï¼Œéœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚attention maskçš„è®¾è®¡éœ€è¦ç²¾ç¡®åŒ¹é…æˆªæ–­é‡‡æ ·è¿‡ç¨‹ï¼Œä»¥ä¿è¯è®­ç»ƒçš„æœ‰æ•ˆæ€§ã€‚æŸå¤±å‡½æ•°æ–¹é¢ï¼ŒSparse-LaViDaæ²¿ç”¨äº†LaViDa-Oçš„æŸå¤±å‡½æ•°ï¼Œä½†å¯èƒ½éœ€è¦æ ¹æ®ç¨€ç–åŒ–ç¨‹åº¦è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSparse-LaViDaåœ¨å¤šç§ä»»åŠ¡ä¸Šå®ç°äº†æ˜¾è‘—çš„åŠ é€Ÿæ•ˆæœï¼Œæœ€é«˜å¯è¾¾2å€ï¼ŒåŒæ—¶ä¿æŒäº†ä¸LaViDa-Oç›¸å½“çš„ç”Ÿæˆè´¨é‡ã€‚åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒSparse-LaViDaåœ¨åŠ é€Ÿçš„åŒæ—¶ï¼ŒFIDæŒ‡æ ‡æ²¡æœ‰æ˜æ˜¾ä¸‹é™ã€‚åœ¨å›¾åƒç¼–è¾‘å’Œæ•°å­¦æ¨ç†ä»»åŠ¡ä¸­ï¼ŒSparse-LaViDaä¹Ÿè¡¨ç°å‡ºäº†ç±»ä¼¼çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Sparse-LaViDaå¯åº”ç”¨äºå„ç§å¤šæ¨¡æ€ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘ã€è§†è§‰æ¨ç†ç­‰ã€‚å…¶åŠ é€Ÿæ¨ç†çš„ç‰¹æ€§ä½¿å…¶æ›´é€‚åˆå¯¹å®æ—¶æ€§è¦æ±‚è¾ƒé«˜çš„åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚åœ¨çº¿å›¾åƒç¼–è¾‘ã€æ™ºèƒ½å®¢æœç­‰ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæ¨åŠ¨å¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„æ™®åŠã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Masked Discrete Diffusion Models (MDMs) have achieved strong performance across a wide range of multimodal tasks, including image understanding, generation, and editing. However, their inference speed remains suboptimal due to the need to repeatedly process redundant masked tokens at every sampling step. In this work, we propose Sparse-LaViDa, a novel modeling framework that dynamically truncates unnecessary masked tokens at each inference step to accelerate MDM sampling. To preserve generation quality, we introduce specialized register tokens that serve as compact representations for the truncated tokens. Furthermore, to ensure consistency between training and inference, we design a specialized attention mask that faithfully matches the truncated sampling procedure during training. Built upon the state-of-the-art unified MDM LaViDa-O, Sparse-LaViDa achieves up to a 2x speedup across diverse tasks including text-to-image generation, image editing, and mathematical reasoning, while maintaining generation quality.

