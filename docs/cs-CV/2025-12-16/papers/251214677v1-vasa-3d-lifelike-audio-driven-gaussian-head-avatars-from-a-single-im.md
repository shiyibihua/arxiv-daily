---
layout: default
title: VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image
---

# VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.14677" target="_blank" class="toolbar-btn">arXiv: 2512.14677v1</a>
    <a href="https://arxiv.org/pdf/2512.14677.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14677v1" 
            onclick="toggleFavorite(this, '2512.14677v1', 'VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Sicheng Xu, Guojun Chen, Jiaolong Yang, Yizhong Zhang, Yu Deng, Steve Lin, Baining Guo

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: NeurIPS 2025 paper. Project webpage: https://www.microsoft.com/en-us/research/project/vasa-3d/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VASA-3Dï¼šåŸºäºå•å¼ å›¾åƒçš„é€¼çœŸéŸ³é¢‘é©±åŠ¨é«˜æ–¯å¤´éƒ¨åŒ–èº«ç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `3Då¤´éƒ¨åŒ–èº«` `éŸ³é¢‘é©±åŠ¨` `å•å¼ å›¾åƒ` `è¡¨æƒ…å»ºæ¨¡` `é«˜æ–¯å¤´éƒ¨` `è‡ªç”±è§†ç‚¹è§†é¢‘` `VASA-1` `è¿åŠ¨æ½œåœ¨ç©ºé—´`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥ä»å•å¼ å›¾åƒç”Ÿæˆå…·æœ‰ç»†å¾®è¡¨æƒ…çš„é€¼çœŸ3Då¤´éƒ¨åŒ–èº«ï¼Œå°¤å…¶æ˜¯åœ¨æ•æ‰çœŸå®æ„Ÿå’Œç»†èŠ‚æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚
2. VASA-3Dçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†VASA-1çš„2Dè¿åŠ¨æ½œåœ¨ç©ºé—´è¿ç§»åˆ°3Då¤´éƒ¨æ¨¡å‹ï¼Œä»è€Œå®ç°å¯¹è¡¨æƒ…ç»†èŠ‚çš„ç²¾ç¡®å»ºæ¨¡å’Œæ§åˆ¶ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒVASA-3Dèƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„3Dè¯´è¯å¤´éƒ¨ï¼Œå¹¶æ”¯æŒé«˜è¾¾75 FPSçš„è‡ªç”±è§†ç‚¹è§†é¢‘ç”Ÿæˆï¼Œæ˜¾è‘—æå‡äº†ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºVASA-3Dï¼Œä¸€ç§éŸ³é¢‘é©±åŠ¨çš„ã€å•å¼ å›¾åƒ3Då¤´éƒ¨åŒ–èº«ç”Ÿæˆå™¨ã€‚è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šæ•æ‰çœŸå®äººè„¸ä¸­ç»†å¾®çš„è¡¨æƒ…ç»†èŠ‚ï¼Œä»¥åŠä»å•å¼ äººåƒå›¾åƒä¸­é‡å»ºå¤æ‚çš„3Då¤´éƒ¨åŒ–èº«ã€‚ä¸ºäº†å‡†ç¡®åœ°å»ºæ¨¡è¡¨æƒ…ç»†èŠ‚ï¼ŒVASA-3Dåˆ©ç”¨äº†VASA-1çš„è¿åŠ¨æ½œåœ¨ç©ºé—´ï¼Œè¯¥æ–¹æ³•åœ¨2Dè¯´è¯å¤´éƒ¨ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„çœŸå®æ„Ÿå’Œç”ŸåŠ¨æ€§ã€‚æœ¬æ–‡çš„å…³é”®åœ¨äºå°†è¿™ç§è¿åŠ¨æ½œåœ¨ç©ºé—´è½¬åŒ–ä¸º3Dï¼Œè¿™é€šè¿‡è®¾è®¡ä¸€ä¸ªä»¥è¿åŠ¨æ½œåœ¨ç©ºé—´ä¸ºæ¡ä»¶çš„3Då¤´éƒ¨æ¨¡å‹æ¥å®ç°ã€‚é€šè¿‡ä¸€ä¸ªä¼˜åŒ–æ¡†æ¶ï¼Œåˆ©ç”¨ä»è¾“å…¥å›¾åƒåˆæˆçš„å‚è€ƒå¤´éƒ¨çš„å¤§é‡è§†é¢‘å¸§ï¼Œå®ç°å¯¹è¯¥æ¨¡å‹çš„å•å¼ å›¾åƒå®šåˆ¶ã€‚è¯¥ä¼˜åŒ–è¿‡ç¨‹é‡‡ç”¨äº†å¯¹ä¼ªå½±å’Œç”Ÿæˆè®­ç»ƒæ•°æ®ä¸­æœ‰é™çš„å§¿æ€è¦†ç›–å…·æœ‰é²æ£’æ€§çš„å„ç§è®­ç»ƒæŸå¤±ã€‚å®éªŒè¡¨æ˜ï¼ŒVASA-3Dç”Ÿæˆäº†é€¼çœŸçš„3Dè¯´è¯å¤´éƒ¨ï¼Œè¿™æ˜¯ç°æœ‰æŠ€æœ¯æ— æ³•å®ç°çš„ï¼Œå¹¶ä¸”å®ƒæ”¯æŒä»¥é«˜è¾¾75 FPSçš„é€Ÿåº¦åœ¨çº¿ç”Ÿæˆ512x512è‡ªç”±è§†ç‚¹è§†é¢‘ï¼Œä»è€Œä¿ƒè¿›äº†ä¸é€¼çœŸ3DåŒ–èº«æ›´å…·æ²‰æµ¸æ„Ÿçš„äº’åŠ¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»å•å¼ å›¾åƒç”Ÿæˆé€¼çœŸä¸”å…·æœ‰ç»†å¾®è¡¨æƒ…çš„3Då¤´éƒ¨åŒ–èº«çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ•æ‰çœŸå®äººè„¸çš„ç»†å¾®è¡¨æƒ…ç»†èŠ‚ä»¥åŠä»å•å¼ å›¾åƒé‡å»ºå¤æ‚çš„3Då¤´éƒ¨åŒ–èº«æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œç”Ÿæˆçš„3DåŒ–èº«å¾€å¾€ç¼ºä¹çœŸå®æ„Ÿå’Œç”ŸåŠ¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†VASA-1åœ¨2Dè¯´è¯å¤´éƒ¨ç”Ÿæˆæ–¹é¢çš„ä¼˜åŠ¿ï¼Œå³å…¶ä¼˜ç§€çš„è¿åŠ¨æ½œåœ¨ç©ºé—´ï¼Œè¿ç§»åˆ°3Då¤´éƒ¨æ¨¡å‹çš„æ„å»ºä¸­ã€‚é€šè¿‡å°†3Då¤´éƒ¨æ¨¡å‹ä¸VASA-1çš„è¿åŠ¨æ½œåœ¨ç©ºé—´ç›¸ç»“åˆï¼Œå¯ä»¥å®ç°å¯¹è¡¨æƒ…ç»†èŠ‚çš„ç²¾ç¡®å»ºæ¨¡å’Œæ§åˆ¶ï¼Œä»è€Œç”Ÿæˆæ›´é€¼çœŸçš„3Då¤´éƒ¨åŒ–èº«ã€‚è¿™ç§è®¾è®¡æ€è·¯çš„å…³é”®åœ¨äºåˆ©ç”¨2Dé¢†åŸŸçš„å…ˆè¿›æŠ€æœ¯æ¥æå‡3Då¤´éƒ¨åŒ–èº«çš„ç”Ÿæˆè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVASA-3Dçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) åˆ©ç”¨VASA-1çš„è¿åŠ¨æ½œåœ¨ç©ºé—´æ¥é©±åŠ¨3Då¤´éƒ¨æ¨¡å‹çš„å½¢å˜ï¼›2) è®¾è®¡ä¸€ä¸ªä»¥è¿åŠ¨æ½œåœ¨ç©ºé—´ä¸ºæ¡ä»¶çš„3Då¤´éƒ¨æ¨¡å‹ï¼›3) é€šè¿‡ä¼˜åŒ–æ¡†æ¶ï¼Œåˆ©ç”¨ä»è¾“å…¥å›¾åƒåˆæˆçš„å‚è€ƒå¤´éƒ¨è§†é¢‘å¸§ï¼Œå®ç°å¯¹3Då¤´éƒ¨æ¨¡å‹çš„å•å¼ å›¾åƒå®šåˆ¶ï¼›4) ä½¿ç”¨å¯¹ä¼ªå½±å’Œæœ‰é™å§¿æ€è¦†ç›–å…·æœ‰é²æ£’æ€§çš„è®­ç»ƒæŸå¤±è¿›è¡Œä¼˜åŒ–ã€‚æ•´ä¸ªæµç¨‹ä»å•å¼ å›¾åƒå¼€å§‹ï¼Œç»è¿‡ä¸€ç³»åˆ—å¤„ç†ï¼Œæœ€ç»ˆç”Ÿæˆé€¼çœŸçš„3Dè¯´è¯å¤´éƒ¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šVASA-3Dæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†2Dè¯´è¯å¤´éƒ¨ç”Ÿæˆé¢†åŸŸçš„å…ˆè¿›æŠ€æœ¯ï¼ˆVASA-1çš„è¿åŠ¨æ½œåœ¨ç©ºé—´ï¼‰æˆåŠŸåœ°è¿ç§»åˆ°3Då¤´éƒ¨åŒ–èº«ç”Ÿæˆä¸­ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒVASA-3Dèƒ½å¤Ÿæ›´å‡†ç¡®åœ°æ•æ‰å’Œå»ºæ¨¡äººè„¸çš„ç»†å¾®è¡¨æƒ…ç»†èŠ‚ï¼Œä»è€Œç”Ÿæˆæ›´é€¼çœŸã€æ›´ç”ŸåŠ¨çš„3Då¤´éƒ¨åŒ–èº«ã€‚æ­¤å¤–ï¼ŒVASA-3Dè¿˜æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„å•å¼ å›¾åƒå®šåˆ¶æ–¹æ³•ï¼Œä½¿å¾—ç”¨æˆ·å¯ä»¥ä½¿ç”¨è‡ªå·±çš„ç…§ç‰‡å¿«é€Ÿç”Ÿæˆä¸ªæ€§åŒ–çš„3DåŒ–èº«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†ä»¥ä¸‹æŠ€æœ¯ç»†èŠ‚ï¼š1) è®¾è®¡äº†ä¸€ä¸ªä»¥è¿åŠ¨æ½œåœ¨ç©ºé—´ä¸ºæ¡ä»¶çš„3Då¤´éƒ¨æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ ¹æ®VASA-1çš„è¿åŠ¨æ½œåœ¨ç©ºé—´è¿›è¡Œå½¢å˜ï¼Œä»è€Œå®ç°å¯¹è¡¨æƒ…çš„æ§åˆ¶ï¼›2) æå‡ºäº†ä¸€ä¸ªä¼˜åŒ–æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ä»è¾“å…¥å›¾åƒåˆæˆçš„å‚è€ƒå¤´éƒ¨è§†é¢‘å¸§æ¥å®šåˆ¶3Då¤´éƒ¨æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨å„ç§å¯¹ä¼ªå½±å’Œæœ‰é™å§¿æ€è¦†ç›–å…·æœ‰é²æ£’æ€§çš„è®­ç»ƒæŸå¤±ï¼Œä¾‹å¦‚å…‰åº¦ä¸€è‡´æ€§æŸå¤±ã€landmarkæŸå¤±ç­‰ï¼›3) ä¸ºäº†æé«˜ç”Ÿæˆé€Ÿåº¦ï¼ŒVASA-3Dé‡‡ç”¨äº†é«˜æ–¯å¤´éƒ¨è¡¨ç¤ºï¼Œå¹¶è¿›è¡Œäº†ä¼˜åŒ–ï¼Œæœ€ç»ˆå®ç°äº†é«˜è¾¾75 FPSçš„è‡ªç”±è§†ç‚¹è§†é¢‘ç”Ÿæˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VASA-3Då®éªŒç»“æœè¡¨æ˜ï¼Œå…¶ç”Ÿæˆçš„3Dè¯´è¯å¤´éƒ¨åœ¨çœŸå®æ„Ÿå’Œç”ŸåŠ¨æ€§æ–¹é¢è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ã€‚VASA-3Dæ”¯æŒä»¥é«˜è¾¾75 FPSçš„é€Ÿåº¦åœ¨çº¿ç”Ÿæˆ512x512è‡ªç”±è§†ç‚¹è§†é¢‘ï¼Œè¿™ä½¿å¾—ç”¨æˆ·å¯ä»¥ä¸3DåŒ–èº«è¿›è¡Œæ›´æµç•…ã€æ›´è‡ªç„¶çš„äº’åŠ¨ã€‚é€šè¿‡å•å¼ å›¾åƒå³å¯ç”Ÿæˆä¸ªæ€§åŒ–3DåŒ–èº«ï¼Œæå¤§åœ°é™ä½äº†ä½¿ç”¨é—¨æ§›ã€‚è¿™äº›å®éªŒç»“æœå……åˆ†è¯æ˜äº†VASA-3Dåœ¨3Då¤´éƒ¨åŒ–èº«ç”Ÿæˆé¢†åŸŸçš„é¢†å…ˆåœ°ä½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VASA-3Då…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚è™šæ‹Ÿä¼šè®®ã€åœ¨çº¿æ•™è‚²ã€æ¸¸æˆã€ç¤¾äº¤åª’ä½“ç­‰ã€‚å®ƒå¯ä»¥ç”¨äºåˆ›å»ºä¸ªæ€§åŒ–çš„3Dè™šæ‹Ÿå½¢è±¡ï¼Œæå‡ç”¨æˆ·åœ¨è™šæ‹Ÿç¯å¢ƒä¸­çš„æ²‰æµ¸æ„Ÿå’Œäº’åŠ¨ä½“éªŒã€‚æ­¤å¤–ï¼ŒVASA-3Dè¿˜å¯ä»¥åº”ç”¨äºæ•°å­—å†…å®¹åˆ›ä½œï¼Œä¾‹å¦‚ç”µå½±ã€åŠ¨ç”»ç­‰ï¼Œä¸ºè§’è‰²è®¾è®¡å’ŒåŠ¨ç”»åˆ¶ä½œæä¾›æ–°çš„å·¥å…·å’Œæ–¹æ³•ã€‚æœªæ¥ï¼ŒVASA-3Dæœ‰æœ›æˆä¸ºå…ƒå®‡å®™ç­‰æ–°å…´é¢†åŸŸçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We propose VASA-3D, an audio-driven, single-shot 3D head avatar generator. This research tackles two major challenges: capturing the subtle expression details present in real human faces, and reconstructing an intricate 3D head avatar from a single portrait image. To accurately model expression details, VASA-3D leverages the motion latent of VASA-1, a method that yields exceptional realism and vividness in 2D talking heads. A critical element of our work is translating this motion latent to 3D, which is accomplished by devising a 3D head model that is conditioned on the motion latent. Customization of this model to a single image is achieved through an optimization framework that employs numerous video frames of the reference head synthesized from the input image. The optimization takes various training losses robust to artifacts and limited pose coverage in the generated training data. Our experiment shows that VASA-3D produces realistic 3D talking heads that cannot be achieved by prior art, and it supports the online generation of 512x512 free-viewpoint videos at up to 75 FPS, facilitating more immersive engagements with lifelike 3D avatars.

