---
layout: default
title: MFE-GAN: Efficient GAN-based Framework for Document Image Enhancement and Binarization with Multi-scale Feature Extraction
---

# MFE-GAN: Efficient GAN-based Framework for Document Image Enhancement and Binarization with Multi-scale Feature Extraction

**arXiv**: [2512.14114v1](https://arxiv.org/abs/2512.14114) | [PDF](https://arxiv.org/pdf/2512.14114.pdf)

**ä½œè€…**: Rui-Yang Ju, KokSheik Wong, Yanlin Jin, Jen-Shiun Chiang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Extended Journal Version of APSIPA ASC 2025

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://ruiyangju.github.io/MFE-GAN)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMFE-GANæ¡†æž¶ï¼Œé€šè¿‡å¤šå°ºåº¦ç‰¹å¾æå–å’ŒHaarå°æ³¢å˜æ¢ï¼Œé«˜æ•ˆè§£å†³æ–‡æ¡£å›¾åƒå¢žå¼ºä¸ŽäºŒå€¼åŒ–é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ–‡æ¡£å›¾åƒå¢žå¼º` `å›¾åƒäºŒå€¼åŒ–` `ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ` `å¤šå°ºåº¦ç‰¹å¾æå–` `Haarå°æ³¢å˜æ¢` `å…‰å­¦å­—ç¬¦è¯†åˆ«` `é«˜æ•ˆè®­ç»ƒ` `æ¶ˆèžç ”ç©¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä½¿ç”¨å¤šä¸ªç‹¬ç«‹GANå¤„ç†ä¸åŒé¢œè‰²é€šé“ï¼Œå¯¼è‡´è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´è¿‡é•¿ï¼Œæ•ˆçŽ‡ä½Žä¸‹ã€‚
2. æå‡ºMFE-GANæ¡†æž¶ï¼Œç»“åˆHaarå°æ³¢å˜æ¢å’Œå¤šå°ºåº¦ç‰¹å¾æå–ï¼Œä¼˜åŒ–å›¾åƒé¢„å¤„ç†ï¼Œå¹¶è®¾è®¡æ–°ç”Ÿæˆå™¨ã€åˆ¤åˆ«å™¨å’ŒæŸå¤±å‡½æ•°ã€‚
3. å®žéªŒæ˜¾ç¤ºï¼ŒMFE-GANåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—å‡å°‘è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ï¼ŒåŒæ—¶æ€§èƒ½ä¸ŽSOTAæ–¹æ³•ç›¸å½“ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡æ¡£å›¾åƒå¢žå¼ºä¸ŽäºŒå€¼åŒ–é€šå¸¸åœ¨æ–‡æ¡£åˆ†æžä¸Žè¯†åˆ«ä»»åŠ¡å‰æ‰§è¡Œï¼Œä»¥æé«˜å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰ç³»ç»Ÿçš„æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ã€‚è¿™æ˜¯å› ä¸ºç›´æŽ¥è¯†åˆ«é€€åŒ–æ–‡æ¡£ï¼ˆç‰¹åˆ«æ˜¯å½©è‰²å›¾åƒï¼‰ä¸­çš„æ–‡æœ¬å¾€å¾€å¯¼è‡´ä¸ç†æƒ³çš„è¯†åˆ«æ€§èƒ½ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼ŒçŽ°æœ‰æ–¹æ³•è®­ç»ƒç‹¬ç«‹çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å¤„ç†ä¸åŒé¢œè‰²é€šé“ä»¥åŽ»é™¤é˜´å½±å’Œå™ªå£°ï¼Œä»Žè€Œä¿ƒè¿›é«˜æ•ˆçš„æ–‡æœ¬ä¿¡æ¯æå–ã€‚ç„¶è€Œï¼Œéƒ¨ç½²å¤šä¸ªGANsä¼šå¯¼è‡´è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´è¿‡é•¿ã€‚ä¸ºå‡å°‘æ–‡æ¡£å›¾åƒå¢žå¼ºä¸ŽäºŒå€¼åŒ–æ¨¡åž‹çš„è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ï¼Œæˆ‘ä»¬æå‡ºäº†MFE-GANï¼Œè¿™æ˜¯ä¸€ç§åŸºäºŽGANçš„é«˜æ•ˆæ¡†æž¶ï¼Œé‡‡ç”¨å¤šå°ºåº¦ç‰¹å¾æå–ï¼ˆMFEï¼‰ï¼Œç»“åˆHaarå°æ³¢å˜æ¢ï¼ˆHWTï¼‰å’Œå½’ä¸€åŒ–å¤„ç†æ–‡æ¡£å›¾åƒï¼Œç„¶åŽè¾“å…¥GANsè¿›è¡Œè®­ç»ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†æ–°é¢–çš„ç”Ÿæˆå™¨ã€åˆ¤åˆ«å™¨å’ŒæŸå¤±å‡½æ•°ä»¥æå‡æ¨¡åž‹æ€§èƒ½ï¼Œå¹¶é€šè¿‡æ¶ˆèžç ”ç©¶éªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚åœ¨Benchmarkã€Nabucoå’ŒCMATERdbæ•°æ®é›†ä¸Šçš„å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæ‰€æå‡ºçš„MFE-GANæ˜¾è‘—å‡å°‘äº†æ€»è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ï¼ŒåŒæ—¶ä¿æŒäº†ä¸Žæœ€å…ˆè¿›ï¼ˆSOTAï¼‰æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚æœ¬å·¥ä½œçš„å®žçŽ°å¯åœ¨https://ruiyangju.github.io/MFE-GANèŽ·å–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

MFE-GANæ˜¯ä¸€ä¸ªåŸºäºŽç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„é«˜æ•ˆæ¡†æž¶ï¼Œæ•´ä½“æž¶æž„åŒ…æ‹¬é¢„å¤„ç†æ¨¡å—å’Œå¤šå°ºåº¦ç‰¹å¾æå–æ¨¡å—ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå¼•å…¥Haarå°æ³¢å˜æ¢å’Œå½’ä¸€åŒ–è¿›è¡Œå›¾åƒé¢„å¤„ç†ï¼Œä»¥åŠè®¾è®¡æ–°é¢–çš„ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ç»“æž„ï¼Œç»“åˆå¤šå°ºåº¦ç‰¹å¾æå–æ¥æ•èŽ·æ–‡æ¡£å›¾åƒçš„å…¨å±€å’Œå±€éƒ¨ä¿¡æ¯ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œå®ƒé¿å…äº†ä½¿ç”¨å¤šä¸ªç‹¬ç«‹GANå¤„ç†ä¸åŒé¢œè‰²é€šé“ï¼Œè€Œæ˜¯é€šè¿‡ç»Ÿä¸€çš„æ¡†æž¶å’Œä¼˜åŒ–é¢„å¤„ç†æ­¥éª¤ï¼Œæ˜¾è‘—é™ä½Žäº†è®¡ç®—å¤æ‚åº¦ï¼Œæé«˜äº†è®­ç»ƒå’ŒæŽ¨ç†æ•ˆçŽ‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨Benchmarkã€Nabucoå’ŒCMATERdbæ•°æ®é›†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼ŒMFE-GANæ˜¾è‘—å‡å°‘äº†æ€»è®­ç»ƒå’ŒæŽ¨ç†æ—¶é—´ï¼ŒåŒæ—¶ä¿æŒäº†ä¸Žæœ€å…ˆè¿›æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶é«˜æ•ˆæ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽæ–‡æ¡£å›¾åƒå¤„ç†é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯åœ¨å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰ç³»ç»Ÿä¸­ï¼Œç”¨äºŽå¢žå¼ºé€€åŒ–æ–‡æ¡£å›¾åƒï¼ˆå¦‚åŽ»é™¤é˜´å½±å’Œå™ªå£°ï¼‰å¹¶è¿›è¡ŒäºŒå€¼åŒ–ï¼Œä»¥æé«˜æ–‡æœ¬è¯†åˆ«çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ã€‚æ½œåœ¨åº”ç”¨åŒ…æ‹¬æ•°å­—åŒ–æ¡£æ¡ˆç®¡ç†ã€åŽ†å²æ–‡æ¡£ä¿®å¤ã€ç§»åŠ¨è®¾å¤‡æ‰«æåº”ç”¨ç­‰ï¼Œå…·æœ‰å®žé™…ä»·å€¼åœ¨äºŽæå‡è‡ªåŠ¨åŒ–æ–‡æ¡£å¤„ç†çš„é€Ÿåº¦å’Œå¯é æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Document image enhancement and binarization are commonly performed prior to document analysis and recognition tasks for improving the efficiency and accuracy of optical character recognition (OCR) systems. This is because directly recognizing text in degraded documents, particularly in color images, often results in unsatisfactory recognition performance. To address these issues, existing methods train independent generative adversarial networks (GANs) for different color channels to remove shadows and noise, which, in turn, facilitates efficient text information extraction. However, deploying multiple GANs results in long training and inference times. To reduce both training and inference times of document image enhancement and binarization models, we propose MFE-GAN, an efficient GAN-based framework with multi-scale feature extraction (MFE), which incorporates Haar wavelet transformation (HWT) and normalization to process document images before feeding them into GANs for training. In addition, we present novel generators, discriminators, and loss functions to improve the model's performance, and we conduct ablation studies to demonstrate their effectiveness. Experimental results on the Benchmark, Nabuco, and CMATERdb datasets demonstrate that the proposed MFE-GAN significantly reduces the total training and inference times while maintaining comparable performance with respect to state-of-the-art (SOTA) methods. The implementation of this work is available at https://ruiyangju.github.io/MFE-GAN.

