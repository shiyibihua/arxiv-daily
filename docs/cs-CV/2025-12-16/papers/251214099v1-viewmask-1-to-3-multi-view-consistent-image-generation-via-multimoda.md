---
layout: default
title: ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models
---

# ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models

**arXiv**: [2512.14099v1](https://arxiv.org/abs/2512.14099) | [PDF](https://arxiv.org/pdf/2512.14099.pdf)

**ä½œè€…**: Ruishu Zhu, Zhihao Huang, Jiacheng Sun, Ping Luo, Hongyuan Zhang, Xuelong Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºViewMask-1-to-3ï¼Œé€šè¿‡ç¦»æ•£æ‰©æ•£æ¨¡åž‹è§£å†³å•å›¾åƒç”Ÿæˆå¤šè§†è§’ä¸€è‡´å›¾åƒçš„æŒ‘æˆ˜ã€‚**

**å…³é”®è¯**: `å¤šè§†è§’å›¾åƒç”Ÿæˆ` `ç¦»æ•£æ‰©æ•£æ¨¡åž‹` `åºåˆ—å»ºæ¨¡` `æŽ©ç æ ‡è®°é¢„æµ‹` `å‡ ä½•ä¸€è‡´æ€§` `MAGVIT-v2æ ‡è®°åŒ–` `å¤šæ¨¡æ€èžåˆ` `è‡ªæ³¨æ„åŠ›æœºåˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä¾èµ–3Dæž¶æž„æˆ–ä¸“ç”¨æ‰©æ•£æ¨¡åž‹ï¼Œéœ€å¤§é‡å¤šè§†è§’æ•°æ®å’Œå¤æ‚å‡ ä½•å…ˆéªŒï¼Œå¯¼è‡´å®žçŽ°å¤æ‚ä¸”æˆæœ¬é«˜ã€‚
2. ViewMask-1-to-3å°†å¤šè§†è§’ç”Ÿæˆå»ºæ¨¡ä¸ºç¦»æ•£åºåˆ—é—®é¢˜ï¼Œä½¿ç”¨MAGVIT-v2æ ‡è®°åŒ–å’ŒæŽ©ç é¢„æµ‹ï¼Œé€šè¿‡éšæœºæŽ©ç ä¸Žè‡ªæ³¨æ„åŠ›ç¡®ä¿ä¸€è‡´æ€§ã€‚
3. åœ¨GSOå’Œ3D-FUTUREæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨PSNRã€SSIMå’ŒLPIPSæŒ‡æ ‡ä¸Šå¹³å‡æŽ’åç¬¬ä¸€ï¼ŒéªŒè¯äº†ç¦»æ•£æ‰©æ•£çš„æœ‰æ•ˆæ€§å’Œç®€æ´æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»Žå•å¼ å›¾åƒå’Œæ–‡æœ¬æè¿°ç”Ÿæˆå¤šè§†è§’å›¾åƒä¸€ç›´é¢ä¸´å‡ ä½•ä¸€è‡´æ€§éš¾ä»¥ä¿æŒçš„æŒ‘æˆ˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–3Dæ„ŸçŸ¥æž¶æž„æˆ–ä¸“ç”¨æ‰©æ•£æ¨¡åž‹ï¼Œéœ€è¦å¤§é‡å¤šè§†è§’è®­ç»ƒæ•°æ®å’Œå¤æ‚å‡ ä½•å…ˆéªŒã€‚æœ¬æ–‡æå‡ºViewMask-1-to-3ï¼Œé¦–æ¬¡å°†ç¦»æ•£æ‰©æ•£æ¨¡åž‹åº”ç”¨äºŽå¤šè§†è§’å›¾åƒç”Ÿæˆã€‚ä¸Žåœ¨æ½œåœ¨ç©ºé—´æ“ä½œçš„è¿žç»­æ‰©æ•£æ–¹æ³•ä¸åŒï¼ŒViewMask-1-to-3å°†å¤šè§†è§’åˆæˆå»ºæ¨¡ä¸ºç¦»æ•£åºåˆ—å»ºæ¨¡é—®é¢˜ï¼Œæ¯ä¸ªè§†è§’é€šè¿‡MAGVIT-v2æ ‡è®°åŒ–è¡¨ç¤ºä¸ºè§†è§‰æ ‡è®°ã€‚é€šè¿‡æŽ©ç æ ‡è®°é¢„æµ‹ç»Ÿä¸€è¯­è¨€å’Œè§†è§‰ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿé€šè¿‡æ–‡æœ¬è¾“å…¥çš„è¿­ä»£æ ‡è®°è§£æŽ©ç é€æ­¥ç”Ÿæˆå¤šä¸ªè§†è§’ã€‚ViewMask-1-to-3é€šè¿‡ç®€å•éšæœºæŽ©ç ç»“åˆè‡ªæ³¨æ„åŠ›å®žçŽ°è·¨è§†è§’ä¸€è‡´æ€§ï¼Œæ— éœ€å¤æ‚3Då‡ ä½•çº¦æŸæˆ–ä¸“ç”¨æ³¨æ„åŠ›æž¶æž„ã€‚å®žéªŒè¡¨æ˜Žï¼Œç¦»æ•£æ‰©æ•£ä¸ºçŽ°æœ‰å¤šè§†è§’ç”Ÿæˆæ–¹æ³•æä¾›äº†å¯è¡Œä¸”ç®€å•çš„æ›¿ä»£æ–¹æ¡ˆï¼Œåœ¨GSOå’Œ3D-FUTUREæ•°æ®é›†ä¸Šå¹³å‡PSNRã€SSIMå’ŒLPIPSæŒ‡æ ‡æŽ’åç¬¬ä¸€ï¼ŒåŒæ—¶ä¿æŒæž¶æž„ç®€æ´æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

ViewMask-1-to-3çš„æ•´ä½“æ¡†æž¶åŸºäºŽç¦»æ•£æ‰©æ•£æ¨¡åž‹ï¼Œå°†å¤šè§†è§’å›¾åƒç”Ÿæˆè½¬åŒ–ä¸ºåºåˆ—å»ºæ¨¡ä»»åŠ¡ã€‚é¦–å…ˆï¼Œä½¿ç”¨MAGVIT-v2å°†æ¯ä¸ªè§†è§’å›¾åƒæ ‡è®°åŒ–ä¸ºè§†è§‰æ ‡è®°åºåˆ—ï¼Œç»“åˆæ–‡æœ¬è¾“å…¥å½¢æˆå¤šæ¨¡æ€åºåˆ—ã€‚å…³é”®åˆ›æ–°ç‚¹åœ¨äºŽé‡‡ç”¨æŽ©ç æ ‡è®°é¢„æµ‹æœºåˆ¶ï¼Œé€šè¿‡è¿­ä»£è§£æŽ©ç é€æ­¥ç”Ÿæˆå¤šè§†è§’å›¾åƒï¼Œå¹¶åˆ©ç”¨éšæœºæŽ©ç å’Œè‡ªæ³¨æ„åŠ›æœºåˆ¶å®žçŽ°è·¨è§†è§’å‡ ä½•ä¸€è‡´æ€§ï¼Œæ— éœ€é¢å¤–3Dçº¦æŸã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼šå®ƒé¿å…äº†è¿žç»­æ‰©æ•£æ¨¡åž‹çš„æ½œåœ¨ç©ºé—´æ“ä½œï¼Œç®€åŒ–äº†æž¶æž„ï¼›ä¸ä¾èµ–å¤æ‚3Då‡ ä½•å…ˆéªŒæˆ–ä¸“ç”¨æ³¨æ„åŠ›æ¨¡å—ï¼Œé™ä½Žäº†å®žçŽ°éš¾åº¦å’Œè®¡ç®—æˆæœ¬ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨GSOå’Œ3D-FUTUREæ•°æ®é›†ä¸Šçš„å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒViewMask-1-to-3åœ¨PSNRã€SSIMå’ŒLPIPSæŒ‡æ ‡ä¸Šå¹³å‡æŽ’åç¬¬ä¸€ï¼Œæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œè¯æ˜Žäº†ç¦»æ•£æ‰©æ•£æ¨¡åž‹åœ¨å¤šè§†è§’ç”Ÿæˆä¸­çš„é«˜æ•ˆæ€§å’Œç®€æ´æž¶æž„ä¼˜åŠ¿ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è®¡ç®—æœºè§†è§‰å’Œæœºå™¨äººé¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨æ½œåŠ›ï¼Œå¦‚è™šæ‹ŸçŽ°å®žä¸­çš„åœºæ™¯é‡å»ºã€å¢žå¼ºçŽ°å®žçš„ç‰©ä½“å±•ç¤ºã€æœºå™¨äººå¯¼èˆªçš„çŽ¯å¢ƒæ„ŸçŸ¥ï¼Œä»¥åŠæ¸¸æˆå’Œå½±è§†åˆ¶ä½œä¸­çš„å¤šè§†è§’å†…å®¹ç”Ÿæˆï¼Œèƒ½é«˜æ•ˆç”Ÿæˆä¸€è‡´çš„å¤šè§†è§’å›¾åƒï¼Œæå‡çœŸå®žæ„Ÿå’Œäº¤äº’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-view image generation from a single image and text description remains challenging due to the difficulty of maintaining geometric consistency across different viewpoints. Existing approaches typically rely on 3D-aware architectures or specialized diffusion models that require extensive multi-view training data and complex geometric priors. In this work, we introduce ViewMask-1-to-3, a pioneering approach to apply discrete diffusion models to multi-view image generation. Unlike continuous diffusion methods that operate in latent spaces, ViewMask-1-to-3 formulates multi-view synthesis as a discrete sequence modeling problem, where each viewpoint is represented as visual tokens obtained through MAGVIT-v2 tokenization. By unifying language and vision through masked token prediction, our approach enables progressive generation of multiple viewpoints through iterative token unmasking with text input. ViewMask-1-to-3 achieves cross-view consistency through simple random masking combined with self-attention, eliminating the requirement for complex 3D geometric constraints or specialized attention architectures. Our approach demonstrates that discrete diffusion provides a viable and simple alternative to existing multi-view generation methods, ranking first on average across GSO and 3D-FUTURE datasets in terms of PSNR, SSIM, and LPIPS, while maintaining architectural simplicity.

