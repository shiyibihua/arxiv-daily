---
layout: default
title: ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models
---

# ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14099" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14099v1</a>
  <a href="https://arxiv.org/pdf/2512.14099.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14099v1" onclick="toggleFavorite(this, '2512.14099v1', 'ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ruishu Zhu, Zhihao Huang, Jiacheng Sun, Ping Luo, Hongyuan Zhang, Xuelong Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ViewMask-1-to-3ï¼šåŸºäºå¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹å®ç°å¤šè§†è§’ä¸€è‡´çš„å›¾åƒç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè§†è§’å›¾åƒç”Ÿæˆ` `ç¦»æ•£æ‰©æ•£æ¨¡å‹` `è·¨è§†è§’ä¸€è‡´æ€§` `MAGVIT-v2` `è‡ªæ³¨æ„åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å•å›¾å’Œæ–‡æœ¬æè¿°ç”Ÿæˆå¤šè§†è§’å›¾åƒæ—¶ï¼Œéš¾ä»¥ä¿æŒè§†è§’é—´çš„å‡ ä½•ä¸€è‡´æ€§ï¼Œé€šå¸¸ä¾èµ–3Dæ„ŸçŸ¥æ¶æ„æˆ–ä¸“ç”¨æ‰©æ•£æ¨¡å‹ã€‚
2. ViewMask-1-to-3å°†å¤šè§†è§’å›¾åƒç”Ÿæˆå»ºæ¨¡ä¸ºç¦»æ•£åºåˆ—é¢„æµ‹é—®é¢˜ï¼Œåˆ©ç”¨æ©ç tokené¢„æµ‹å’Œè‡ªæ³¨æ„åŠ›å®ç°è·¨è§†è§’ä¸€è‡´æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒViewMask-1-to-3åœ¨å¤šè§†è§’å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œåœ¨PSNRã€SSIMå’ŒLPIPSæŒ‡æ ‡ä¸Šå‡æ’åç¬¬ä¸€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºViewMask-1-to-3ï¼Œä¸€ç§åˆ©ç”¨ç¦»æ•£æ‰©æ•£æ¨¡å‹è¿›è¡Œå¤šè§†è§’å›¾åƒç”Ÿæˆçš„åˆ›æ–°æ–¹æ³•ã€‚ä¸åœ¨æ½œåœ¨ç©ºé—´ä¸­æ“ä½œçš„è¿ç»­æ‰©æ•£æ–¹æ³•ä¸åŒï¼ŒViewMask-1-to-3å°†å¤šè§†è§’åˆæˆé—®é¢˜å»ºæ¨¡ä¸ºç¦»æ•£åºåˆ—å»ºæ¨¡é—®é¢˜ï¼Œå…¶ä¸­æ¯ä¸ªè§†è§’è¡¨ç¤ºä¸ºé€šè¿‡MAGVIT-v2 tokenizationè·å¾—çš„è§†è§‰tokensã€‚é€šè¿‡åŸºäºæ©ç tokené¢„æµ‹ç»Ÿä¸€è¯­è¨€å’Œè§†è§‰ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿé€šè¿‡æ–‡æœ¬è¾“å…¥å’Œè¿­ä»£tokenè§£æ©ç é€æ­¥ç”Ÿæˆå¤šä¸ªè§†è§’ã€‚ViewMask-1-to-3é€šè¿‡ç®€å•çš„éšæœºæ©ç ç»“åˆè‡ªæ³¨æ„åŠ›å®ç°è·¨è§†è§’ä¸€è‡´æ€§ï¼Œæ— éœ€å¤æ‚çš„3Då‡ ä½•çº¦æŸæˆ–ä¸“é—¨çš„æ³¨æ„åŠ›æ¶æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç¦»æ•£æ‰©æ•£ä¸ºç°æœ‰çš„å¤šè§†è§’ç”Ÿæˆæ–¹æ³•æä¾›äº†ä¸€ç§å¯è¡Œä¸”ç®€å•çš„æ›¿ä»£æ–¹æ¡ˆï¼Œåœ¨GSOå’Œ3D-FUTUREæ•°æ®é›†ä¸Šï¼ŒViewMask-1-to-3åœ¨PSNRã€SSIMå’ŒLPIPSæŒ‡æ ‡ä¸Šå¹³å‡æ’åç¬¬ä¸€ï¼ŒåŒæ—¶ä¿æŒäº†æ¶æ„çš„ç®€æ´æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»å•å¼ å›¾åƒå’Œæ–‡æœ¬æè¿°ç”Ÿæˆå¤šä¸ªè§†è§’ä¸€è‡´å›¾åƒçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºå¤æ‚çš„3Dæ„ŸçŸ¥æ¶æ„æˆ–éœ€è¦å¤§é‡å¤šè§†è§’è®­ç»ƒæ•°æ®çš„ä¸“ç”¨æ‰©æ•£æ¨¡å‹ï¼Œå¹¶ä¸”éš¾ä»¥ä¿è¯ç”Ÿæˆå›¾åƒåœ¨ä¸åŒè§†è§’ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¤šè§†è§’å›¾åƒç”Ÿæˆé—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªç¦»æ•£åºåˆ—å»ºæ¨¡é—®é¢˜ï¼Œå¹¶åˆ©ç”¨ç¦»æ•£æ‰©æ•£æ¨¡å‹é€æ­¥ç”Ÿæˆä¸åŒè§†è§’çš„å›¾åƒã€‚é€šè¿‡å°†å›¾åƒè¡¨ç¤ºä¸ºç¦»æ•£çš„è§†è§‰tokensï¼Œå¹¶ç»“åˆæ©ç tokené¢„æµ‹å’Œè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°è·¨è§†è§’çš„ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šViewMask-1-to-3çš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) ä½¿ç”¨MAGVIT-v2å°†è¾“å…¥å›¾åƒå’Œæ–‡æœ¬æè¿°è½¬æ¢ä¸ºè§†è§‰å’Œæ–‡æœ¬tokensï¼›2) å¯¹è§†è§‰tokensè¿›è¡Œéšæœºæ©ç ï¼›3) ä½¿ç”¨ç¦»æ•£æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡è¿­ä»£tokenè§£æ©ç çš„æ–¹å¼é€æ­¥ç”Ÿæˆä¸åŒè§†è§’çš„å›¾åƒï¼›4) åˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶å¢å¼ºè·¨è§†è§’çš„ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†ç¦»æ•£æ‰©æ•£æ¨¡å‹åº”ç”¨äºå¤šè§†è§’å›¾åƒç”Ÿæˆä»»åŠ¡ï¼Œå¹¶æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„è·¨è§†è§’ä¸€è‡´æ€§ä¿æŒæ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„è¿ç»­æ‰©æ•£æ¨¡å‹ç›¸æ¯”ï¼Œç¦»æ•£æ‰©æ•£æ¨¡å‹æ›´æ˜“äºè®­ç»ƒå’Œæ¨ç†ï¼Œå¹¶ä¸”ä¸éœ€è¦å¤æ‚çš„å‡ ä½•çº¦æŸæˆ–ä¸“é—¨çš„æ³¨æ„åŠ›æ¶æ„ã€‚

**å…³é”®è®¾è®¡**ï¼šViewMask-1-to-3çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨MAGVIT-v2è¿›è¡Œtokenizationï¼Œå°†å›¾åƒè½¬æ¢ä¸ºç¦»æ•£çš„è§†è§‰tokensï¼›2) é‡‡ç”¨éšæœºæ©ç ç­–ç•¥ï¼Œå¯¹è§†è§‰tokensè¿›è¡Œéšæœºé®ç›–ï¼›3) ä½¿ç”¨Transformeræ¶æ„ä½œä¸ºç¦»æ•£æ‰©æ•£æ¨¡å‹çš„ä¸»å¹²ç½‘ç»œï¼Œè¿›è¡Œtokené¢„æµ‹ï¼›4) åˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå¢å¼ºä¸åŒè§†è§’ä¹‹é—´çš„ä¿¡æ¯äº¤äº’ï¼Œä»è€Œæé«˜è·¨è§†è§’ä¸€è‡´æ€§ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14099v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14099v1/figs/files/training.jpg" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14099v1/figs/files/infer.jpg" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒViewMask-1-to-3åœ¨GSOå’Œ3D-FUTUREæ•°æ®é›†ä¸Šï¼Œåœ¨PSNRã€SSIMå’ŒLPIPSæŒ‡æ ‡ä¸Šå¹³å‡æ’åç¬¬ä¸€ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å¤šè§†è§’å›¾åƒç”Ÿæˆæ–¹æ³•ã€‚è¿™è¡¨æ˜ViewMask-1-to-3èƒ½å¤Ÿç”Ÿæˆæ›´é«˜è´¨é‡ã€æ›´ä¸€è‡´çš„å¤šè§†è§’å›¾åƒï¼Œå¹¶ä¸”å…·æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¥æ–¹æ³•åœ¨ä¿æŒæ¶æ„ç®€æ´æ€§çš„åŒæ—¶ï¼Œå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ViewMask-1-to-3åœ¨ä¸‰ç»´é‡å»ºã€è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºä»å•å¼ å›¾åƒç”Ÿæˆä¸åŒè§†è§’çš„å›¾åƒï¼Œä»è€Œå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£å’Œæ„ŸçŸ¥ä¸‰ç»´åœºæ™¯ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºç”Ÿæˆå…·æœ‰ç‰¹å®šé£æ ¼æˆ–å†…å®¹çš„å›¾åƒï¼Œä¸ºåˆ›æ„è®¾è®¡æä¾›æ›´å¤šå¯èƒ½æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸï¼Œæå‡ç³»ç»Ÿçš„ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multi-view image generation from a single image and text description remains challenging due to the difficulty of maintaining geometric consistency across different viewpoints. Existing approaches typically rely on 3D-aware architectures or specialized diffusion models that require extensive multi-view training data and complex geometric priors. In this work, we introduce ViewMask-1-to-3, a pioneering approach to apply discrete diffusion models to multi-view image generation. Unlike continuous diffusion methods that operate in latent spaces, ViewMask-1-to-3 formulates multi-view synthesis as a discrete sequence modeling problem, where each viewpoint is represented as visual tokens obtained through MAGVIT-v2 tokenization. By unifying language and vision through masked token prediction, our approach enables progressive generation of multiple viewpoints through iterative token unmasking with text input. ViewMask-1-to-3 achieves cross-view consistency through simple random masking combined with self-attention, eliminating the requirement for complex 3D geometric constraints or specialized attention architectures. Our approach demonstrates that discrete diffusion provides a viable and simple alternative to existing multi-view generation methods, ranking first on average across GSO and 3D-FUTURE datasets in terms of PSNR, SSIM, and LPIPS, while maintaining architectural simplicity.

