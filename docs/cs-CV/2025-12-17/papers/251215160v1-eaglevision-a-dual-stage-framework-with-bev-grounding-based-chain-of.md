---
layout: default
title: EagleVision: A Dual-Stage Framework with BEV-grounding-based Chain-of-Thought for Spatial Intelligence
---

# EagleVision: A Dual-Stage Framework with BEV-grounding-based Chain-of-Thought for Spatial Intelligence

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.15160" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.15160v1</a>
  <a href="https://arxiv.org/pdf/2512.15160.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.15160v1" onclick="toggleFavorite(this, '2512.15160v1', 'EagleVision: A Dual-Stage Framework with BEV-grounding-based Chain-of-Thought for Spatial Intelligence')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiaxu Wan, Xu Wang, Mengwei Xie, Hang Zhang, Mu Xu, Yang Han, Hong Zhang, Ding Yuan, Yifan Yang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-17

**å¤‡æ³¨**: 13 pages, 7 figures, 6 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EagleVisionï¼šåŸºäºBEVçš„é“¾å¼æ€è€ƒåŒé˜¶æ®µæ¡†æ¶ï¼Œæå‡ç©ºé—´æ™ºèƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç©ºé—´æ™ºèƒ½` `é“¾å¼æ€è€ƒ` `BEVæ„ŸçŸ¥` `å¼ºåŒ–å­¦ä¹ ` `é•¿è§†é¢‘ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç©ºé—´ä¸€è‡´æ€§ã€è§†è§’å¤šæ ·æ€§å’Œè¯æ®è¿½æº¯æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆè¿›è¡Œç©ºé—´æ¨ç†ã€‚
2. EagleVisioné€šè¿‡åŒé˜¶æ®µæ¡†æ¶ï¼Œåˆ©ç”¨å®è§‚æ„ŸçŸ¥é€‰æ‹©å…³é”®å¸§ï¼Œå¾®è§‚éªŒè¯è¿›è¡Œå§¿æ€æŸ¥è¯¢ï¼Œå®ç°ç©ºé—´é“¾å¼æ€è€ƒã€‚
3. EagleVisionåœ¨VSI-Benchä¸Šå–å¾—äº†é¢†å…ˆæ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨ç©ºé—´ç†è§£æ–¹é¢çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„ç©ºé—´æ™ºèƒ½æ–¹æ³•é€šå¸¸å°†3Dçº¿ç´¢é™„åŠ åˆ°2Dæ¨ç†æµç¨‹ä¸­ï¼Œæˆ–å°†MLLMä¸é»‘ç›’é‡å»ºæ¨¡å—è€¦åˆï¼Œå¯¼è‡´ç©ºé—´ä¸€è‡´æ€§å¼±ã€è§†è§’å¤šæ ·æ€§æœ‰é™ï¼Œä¸”è¯æ®é“¾æ— æ³•è¿½æº¯åˆ°æ”¯æŒè§†å›¾ã€‚ç±»ä¼¼äºâ€œå›¾åƒæ€è€ƒâ€çš„æ¡†æ¶è™½ç„¶å±•ç¤ºäº†é€šè¿‡å‡è®¾å½¢æˆä¸ä¸»åŠ¨è·å–è§†è§‰è¯æ®äº¤é”™å®ç°é€æ­¥å¤šæ¨¡æ€æ¨ç†çš„å¯èƒ½æ€§ï¼Œä½†æœªè§£å†³ç©ºé—´é“¾å¼æ€è€ƒï¼ˆCoTï¼‰ä¸­çš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼šåœ¨ä¸¥æ ¼çš„tokené¢„ç®—ä¸‹æ„å»ºå…¨å±€ç©ºé—´æ„ŸçŸ¥ï¼Œå°†3Då‡è®¾ä¸è§†é¢‘å¸§æ˜¾å¼å…³è”ä»¥è¿›è¡ŒéªŒè¯ï¼Œä»¥åŠè®¾è®¡ç”¨äºå¼ºåŒ–å­¦ä¹ çš„ç©ºé—´å¯¹é½å¥–åŠ±ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†EagleVisionï¼Œä¸€ä¸ªé€šè¿‡å®è§‚æ„ŸçŸ¥å’Œå¾®è§‚éªŒè¯è¿›è¡Œæ¸è¿›å¼ç©ºé—´è®¤çŸ¥çš„åŒé˜¶æ®µæ¡†æ¶ã€‚åœ¨å®è§‚æ„ŸçŸ¥é˜¶æ®µï¼ŒEagleVisioné‡‡ç”¨è¯­ä¹‰-è§†è§’èåˆè¡Œåˆ—å¼ç‚¹è¿‡ç¨‹ï¼ˆSPF-DPPï¼‰ï¼Œåœ¨å›ºå®štokené¢„ç®—ä¸‹ä»é•¿è§†é¢‘ä¸­é€‰æ‹©ä¸€ç»„ç´§å‡‘çš„ã€å…·æœ‰å‡ ä½•å’Œè¯­ä¹‰ä¿¡æ¯çš„å…³é”®å¸§ã€‚åœ¨å¾®è§‚éªŒè¯é˜¶æ®µï¼Œæˆ‘ä»¬å°†ç©ºé—´CoTå½¢å¼åŒ–ä¸ºåŸºäºBEVçš„å§¿æ€æŸ¥è¯¢ï¼šæ™ºèƒ½ä½“è¿­ä»£åœ°é¢„æµ‹BEVå¹³é¢ä¸Šçš„å§¿æ€ï¼Œæ£€ç´¢æœ€è¿‘çš„çœŸå®å¸§ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œå…¶ç©ºé—´å¯¹é½å¥–åŠ±ç”¨äºè¯„ä¼°é¢„æµ‹å§¿æ€ä¸è§‚å¯Ÿåˆ°çš„è§†å›¾ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚åœ¨VSI-Benchä¸Šï¼ŒEagleVisionåœ¨å¼€æºè§†è§‰è¯­è¨€æ¨¡å‹ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†å¼ºå¤§ä¸”å¯æ³›åŒ–çš„ç©ºé—´ç†è§£èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ç©ºé—´æ™ºèƒ½æ–¹æ³•ä¾èµ–äº2Dæ¨ç†æˆ–é»‘ç›’3Dé‡å»ºï¼Œå¯¼è‡´ç©ºé—´ä¿¡æ¯åˆ©ç”¨ä¸è¶³ï¼Œæ¨ç†è¿‡ç¨‹ç¼ºä¹é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ã€‚å°¤å…¶æ˜¯åœ¨é•¿è§†é¢‘åœºæ™¯ä¸‹ï¼Œå¦‚ä½•é«˜æ•ˆåœ°åˆ©ç”¨æœ‰é™çš„è®¡ç®—èµ„æºè¿›è¡Œå…¨å±€ç©ºé—´æ„ŸçŸ¥æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEagleVisionçš„æ ¸å¿ƒåœ¨äºå°†ç©ºé—´æ¨ç†åˆ†è§£ä¸ºå®è§‚æ„ŸçŸ¥å’Œå¾®è§‚éªŒè¯ä¸¤ä¸ªé˜¶æ®µã€‚å®è§‚æ„ŸçŸ¥è´Ÿè´£ä»é•¿è§†é¢‘ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œæ„å»ºå…¨å±€ç©ºé—´è¡¨å¾ï¼›å¾®è§‚éªŒè¯åˆ™é€šè¿‡åŸºäºBEVçš„å§¿æ€æŸ¥è¯¢ï¼Œå°†3Då‡è®¾ä¸å®é™…å›¾åƒå¸§å…³è”ï¼Œè¿›è¡Œç²¾ç»†åŒ–çš„ç©ºé—´æ¨ç†ã€‚è¿™ç§åˆ†é˜¶æ®µçš„æ–¹æ³•æ—¢èƒ½æœ‰æ•ˆåˆ©ç”¨è®¡ç®—èµ„æºï¼Œåˆèƒ½æé«˜ç©ºé—´æ¨ç†çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEagleVisionæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šå®è§‚æ„ŸçŸ¥å’Œå¾®è§‚éªŒè¯ã€‚å®è§‚æ„ŸçŸ¥é˜¶æ®µä½¿ç”¨è¯­ä¹‰-è§†è§’èåˆè¡Œåˆ—å¼ç‚¹è¿‡ç¨‹ï¼ˆSPF-DPPï¼‰ä»é•¿è§†é¢‘ä¸­é€‰æ‹©å…³é”®å¸§ï¼Œè¯¥è¿‡ç¨‹è€ƒè™‘äº†å¸§çš„å‡ ä½•å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œä»¥ç¡®ä¿é€‰æ‹©çš„å¸§å…·æœ‰ä»£è¡¨æ€§ã€‚å¾®è§‚éªŒè¯é˜¶æ®µå°†ç©ºé—´CoTå½¢å¼åŒ–ä¸ºåŸºäºBEVçš„å§¿æ€æŸ¥è¯¢ï¼Œæ™ºèƒ½ä½“è¿­ä»£åœ°é¢„æµ‹BEVå¹³é¢ä¸Šçš„å§¿æ€ï¼Œå¹¶æ£€ç´¢æœ€è¿‘çš„çœŸå®å¸§ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œæ™ºèƒ½ä½“å­¦ä¹ é¢„æµ‹å‡†ç¡®çš„å§¿æ€ï¼Œä»è€Œå®ç°ç©ºé—´æ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šEagleVisionçš„å…³é”®åˆ›æ–°åœ¨äºå…¶åŒé˜¶æ®µæ¡†æ¶å’ŒåŸºäºBEVçš„å§¿æ€æŸ¥è¯¢æ–¹æ³•ã€‚åŒé˜¶æ®µæ¡†æ¶æœ‰æ•ˆåœ°å°†å…¨å±€ç©ºé—´æ„ŸçŸ¥å’Œå±€éƒ¨ç²¾ç»†æ¨ç†åˆ†ç¦»ï¼Œæé«˜äº†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚åŸºäºBEVçš„å§¿æ€æŸ¥è¯¢æ–¹æ³•å°†3Dç©ºé—´ä¿¡æ¯æ˜¾å¼åœ°èå…¥åˆ°æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå¢å¼ºäº†ç©ºé—´ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œä½¿ç”¨ç©ºé—´å¯¹é½å¥–åŠ±è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿå­¦ä¹ åˆ°ä¸çœŸå®ä¸–ç•Œå¯¹é½çš„ç©ºé—´è¡¨å¾ã€‚

**å…³é”®è®¾è®¡**ï¼šSPF-DPPçš„å…³é”®åœ¨äºå…¶è¡Œåˆ—å¼ç‚¹è¿‡ç¨‹ï¼Œç”¨äºé€‰æ‹©å…·æœ‰ä»£è¡¨æ€§çš„å…³é”®å¸§ã€‚BEV-grounded pose queryingçš„å…³é”®åœ¨äºå¦‚ä½•è®¾è®¡å¥–åŠ±å‡½æ•°ï¼Œè®ºæ–‡ä¸­ä½¿ç”¨ç©ºé—´å¯¹é½å¥–åŠ±ï¼Œé¼“åŠ±é¢„æµ‹çš„å§¿æ€ä¸è§‚å¯Ÿåˆ°çš„è§†å›¾ä¿æŒä¸€è‡´ã€‚å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„é€‰æ‹©ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦é€‰æ‹©é€‚åˆè¿ç»­åŠ¨ä½œç©ºé—´çš„ç®—æ³•ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.15160v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.15160v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.15160v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

EagleVisionåœ¨VSI-Benchæ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å¼€æºè§†è§‰è¯­è¨€æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEagleVisionåœ¨ç©ºé—´ç†è§£æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†é•¿è§†é¢‘åœºæ™¯ä¸‹çš„ç©ºé—´æ¨ç†ä»»åŠ¡ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EagleVisionåœ¨æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€è§†é¢‘ç›‘æ§ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å‘¨å›´ç¯å¢ƒï¼Œè¿›è¡Œæ›´ç²¾ç¡®çš„å®šä½å’Œå¯¼èˆªã€‚åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œå¯ä»¥æé«˜è½¦è¾†å¯¹å¤æ‚äº¤é€šåœºæ™¯çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚åœ¨è§†é¢‘ç›‘æ§é¢†åŸŸï¼Œå¯ä»¥å®ç°æ›´æ™ºèƒ½çš„äº‹ä»¶æ£€æµ‹å’Œè¡Œä¸ºåˆ†æã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent spatial intelligence approaches typically attach 3D cues to 2D reasoning pipelines or couple MLLMs with black-box reconstruction modules, leading to weak spatial consistency, limited viewpoint diversity, and evidence chains that cannot be traced back to supporting views. Frameworks for "thinking with images" (e.g., ChatGPT-o3 and DeepEyes) show that stepwise multimodal reasoning can emerge by interleaving hypothesis formation with active acquisition of visual evidence, but they do not address three key challenges in spatial Chain-of-Thought (CoT): building global space perception under strict token budgets, explicitly associating 3D hypotheses with video frames for verification, and designing spatially grounded rewards for reinforcement learning. To address these issues, we present EagleVision, a dual-stage framework for progressive spatial cognition through macro perception and micro verification. In the macro perception stage, EagleVision employs a semantics-perspective-fusion determinantal point process (SPF-DPP) to select a compact set of geometry- and semantics-aware keyframes from long videos under a fixed token budget. In the micro verification stage, we formalize spatial CoT as BEV-grounded pose querying: the agent iteratively predicts poses on a BEV plane, retrieves the nearest real frames, and is trained purely by reinforcement learning with a spatial grounding reward that scores the consistency between predicted poses and observed views. On VSI-Bench, EagleVision achieves state-of-the-art performance among open-source vision-language models, demonstrating strong and generalizable spatial understanding.

