---
layout: default
title: Preserving Marker Specificity with Lightweight Channel-Independent Representation Learning
---

# Preserving Marker Specificity with Lightweight Channel-Independent Representation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.15410" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.15410v1</a>
  <a href="https://arxiv.org/pdf/2512.15410.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.15410v1" onclick="toggleFavorite(this, '2512.15410v1', 'Preserving Marker Specificity with Lightweight Channel-Independent Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Simon Gutwein, Arthur Longuefosse, Jun Seita, Sabine Taschner-Mandl, Roxane Licandro

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-17

**å¤‡æ³¨**: 16 pages, 9 figures, MIDL 2026 conference

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/SimonBon/CIM-S)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè½»é‡çº§é€šé“ç‹¬ç«‹è¡¨ç¤ºå­¦ä¹ ä»¥æå‡æ ‡è®°ç‰¹å¼‚æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šé‡ç»„ç»‡æˆåƒ` `è‡ªç›‘ç£å­¦ä¹ ` `é€šé“ç‹¬ç«‹æ¨¡å‹` `æ·±åº¦å­¦ä¹ ` `åŒ»å­¦å½±åƒåˆ†æ` `ç»†èƒåˆ†ç±»` `æ ‡è®°ç‰¹å¼‚æ€§` `è½»é‡çº§æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å¤„ç†å¤šé‡ç»„ç»‡æˆåƒæ•°æ®æ—¶ï¼Œé€šå¸¸é‡‡ç”¨æ—©æœŸé€šé“èåˆï¼Œå¯¼è‡´æ ‡è®°ç‰¹å¼‚æ€§ä¿¡æ¯çš„ä¿ç•™èƒ½åŠ›æœ‰é™ï¼Œå°¤å…¶åœ¨ç¨€æœ‰ç»†èƒçš„åŒºåˆ†ä¸Šè¡¨ç°ä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„è½»é‡çº§é€šé“ç‹¬ç«‹æ¨¡å‹ï¼ˆCIM-Sï¼‰ï¼Œç»“åˆä¿æŒæ ‡è®°ç‹¬ç«‹æ€§å’Œæµ…å±‚æ¶æ„çš„è®¾è®¡ï¼Œæ—¨åœ¨æ”¹å–„è‡ªç›‘ç£è¡¨ç¤ºå­¦ä¹ çš„æ•ˆæœã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCIM-Sæ¨¡å‹åœ¨å¤šä¸ªè‡ªç›‘ç£æ¡†æ¶ä¸‹è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿåœ¨49ä¸ªæ ‡è®°å’Œå‡å°‘åˆ°18ä¸ªæ ‡è®°çš„è®¾ç½®ä¸­ï¼Œç¨³å®šåœ°è¶…è¶Šä¼ ç»Ÿçš„æ—©æœŸèåˆæ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šé‡ç»„ç»‡æˆåƒæŠ€æœ¯èƒ½å¤Ÿæµ‹é‡æ¯ä¸ªç»†èƒä¸­çš„æ•°åç§è›‹ç™½æ ‡è®°ï¼Œä½†å¤§å¤šæ•°æ·±åº¦å­¦ä¹ æ¨¡å‹ä»ç„¶é‡‡ç”¨æ—©æœŸé€šé“èåˆï¼Œå‡è®¾æ ‡è®°ä¹‹é—´å­˜åœ¨å…±äº«ç»“æ„ã€‚æœ¬æ–‡ç ”ç©¶äº†ä¿æŒæ ‡è®°ç‹¬ç«‹æ€§ä¸æ•…æ„æµ…å±‚æ¶æ„çš„ç»“åˆï¼Œæ˜¯å¦èƒ½ä¸ºå¤šé‡æ•°æ®çš„è‡ªç›‘ç£è¡¨ç¤ºå­¦ä¹ æä¾›æ›´åˆé€‚çš„å½’çº³åç½®ã€‚é€šè¿‡å¯¹145,000ä¸ªç»†èƒå’Œ49ä¸ªæ ‡è®°çš„éœå¥‡é‡‘æ·‹å·´ç˜¤CODEXæ•°æ®é›†è¿›è¡Œæ¯”è¾ƒï¼Œå‘ç°é€šé“ç‹¬ç«‹æ¶æ„ï¼Œå°¤å…¶æ˜¯æˆ‘ä»¬æå‡ºçš„CIM-Sæ¨¡å‹ï¼Œå°½ç®¡å‚æ•°é‡ä»…ä¸º5.5Kï¼Œå´èƒ½æ˜¾è‘—å¢å¼ºè¡¨ç¤ºèƒ½åŠ›ï¼Œå°¤å…¶åœ¨ç¨€æœ‰ç»†èƒçš„åŒºåˆ†ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œè½»é‡çº§çš„é€šé“ç‹¬ç«‹æ¶æ„èƒ½å¤ŸåŒ¹æ•Œæˆ–è¶…è¶Šæ·±åº¦æ—©æœŸèåˆCNNå’ŒåŸºç¡€æ¨¡å‹åœ¨å¤šé‡è¡¨ç¤ºå­¦ä¹ ä¸­çš„è¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å¤šé‡ç»„ç»‡æˆåƒæ•°æ®ä¸­å¯¹æ ‡è®°ç‰¹å¼‚æ€§ä¿¡æ¯ä¿ç•™ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨æ—©æœŸé€šé“èåˆï¼Œå¯¼è‡´å¯¹ç¨€æœ‰ç»†èƒçš„åŒºåˆ†èƒ½åŠ›è¾ƒå¼±ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„CIM-Sæ¨¡å‹é€šè¿‡ä¿æŒæ ‡è®°ç‹¬ç«‹æ€§ï¼Œç»“åˆæµ…å±‚æ¶æ„ï¼Œæä¾›äº†ä¸€ç§æ–°çš„è‡ªç›‘ç£è¡¨ç¤ºå­¦ä¹ çš„å½’çº³åç½®ï¼Œæ—¨åœ¨å¢å¼ºæ¨¡å‹å¯¹æ ‡è®°ç‰¹å¼‚æ€§ä¿¡æ¯çš„æ•æ‰èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCIM-Sæ¨¡å‹é‡‡ç”¨é€šé“ç‹¬ç«‹çš„æ¶æ„è®¾è®¡ï¼ŒåŒ…å«å¤šä¸ªæ¨¡å—ç”¨äºç‰¹å¾æå–å’Œè¡¨ç¤ºå­¦ä¹ ã€‚æ¨¡å‹åœ¨å¯¹æ¯”é¢„è®­ç»ƒåè¿›è¡Œçº¿æ€§è¯„ä¼°ï¼Œç¡®ä¿äº†è¡¨ç¤ºçš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šCIM-Sæ¨¡å‹çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶è½»é‡çº§è®¾è®¡å’Œé€šé“ç‹¬ç«‹æ€§ï¼Œæ˜¾è‘—ä¸åŒäºä¼ ç»Ÿçš„æ—©æœŸèåˆCNNï¼Œèƒ½å¤Ÿåœ¨ä¿æŒæ¨¡å‹å°å·§çš„åŒæ—¶ï¼Œæå‡è¡¨ç¤ºèƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šCIM-Sæ¨¡å‹ä»…åŒ…å«5.5Kä¸ªå‚æ•°ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„è®¾è®¡ï¼Œä»¥ç¡®ä¿åœ¨å¤šé‡æ ‡è®°æ•°æ®ä¸­æœ‰æ•ˆä¿ç•™æ ‡è®°ç‰¹å¼‚æ€§ä¿¡æ¯ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.15410v1/figures/experiment1_0-03.jpg" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.15410v1/figures/experiment1_0-01.jpg" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.15410v1/figures/experiment1_0-06.jpg" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCIM-Sæ¨¡å‹åœ¨æ ‡è®°ç‰¹å¼‚æ€§ä¿¡æ¯çš„ä¿ç•™ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„æ—©æœŸèåˆæ¨¡å‹ï¼Œå°¤å…¶åœ¨ç¨€æœ‰ç»†èƒçš„åŒºåˆ†ä¸Šè¡¨ç°çªå‡ºã€‚å…·ä½“è€Œè¨€ï¼ŒCIM-Såœ¨å¤šä¸ªè‡ªç›‘ç£æ¡†æ¶ä¸‹çš„è¡¨ç°ç¨³å®šï¼Œèƒ½å¤Ÿåœ¨49ä¸ªæ ‡è®°å’Œ18ä¸ªæ ‡è®°çš„è®¾ç½®ä¸­å‡å®ç°ä¼˜å¼‚çš„ç»“æœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»å­¦å½±åƒåˆ†æã€è‚¿ç˜¤æ ‡è®°ç‰©æ£€æµ‹å’Œç»†èƒåˆ†ç±»ç­‰ã€‚é€šè¿‡æå‡å¯¹å¤šé‡æ ‡è®°æ•°æ®çš„å¤„ç†èƒ½åŠ›ï¼ŒCIM-Sæ¨¡å‹èƒ½å¤Ÿä¸ºç”Ÿç‰©åŒ»å­¦ç ”ç©¶æä¾›æ›´å‡†ç¡®çš„åˆ†æå·¥å…·ï¼Œæ¨åŠ¨ä¸ªæ€§åŒ–åŒ»ç–—çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multiplexed tissue imaging measures dozens of protein markers per cell, yet most deep learning models still apply early channel fusion, assuming shared structure across markers. We investigate whether preserving marker independence, combined with deliberately shallow architectures, provides a more suitable inductive bias for self-supervised representation learning in multiplex data than increasing model scale. Using a Hodgkin lymphoma CODEX dataset with 145,000 cells and 49 markers, we compare standard early-fusion CNNs with channel-separated architectures, including a marker-aware baseline and our novel shallow Channel-Independent Model (CIM-S) with 5.5K parameters. After contrastive pretraining and linear evaluation, early-fusion models show limited ability to retain marker-specific information and struggle particularly with rare-cell discrimination. Channel-independent architectures, and CIM-S in particular, achieve substantially stronger representations despite their compact size. These findings are consistent across multiple self-supervised frameworks, remain stable across augmentation settings, and are reproducible across both the 49-marker and reduced 18-marker settings. These results show that lightweight, channel-independent architectures can match or surpass deep early-fusion CNNs and foundation models for multiplex representation learning. Code is available at https://github.com/SimonBon/CIM-S.

