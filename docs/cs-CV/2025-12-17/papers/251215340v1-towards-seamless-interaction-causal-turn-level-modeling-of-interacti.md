---
layout: default
title: Towards Seamless Interaction: Causal Turn-Level Modeling of Interactive 3D Conversational Head Dynamics
---

# Towards Seamless Interaction: Causal Turn-Level Modeling of Interactive 3D Conversational Head Dynamics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.15340" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.15340v1</a>
  <a href="https://arxiv.org/pdf/2512.15340.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.15340v1" onclick="toggleFavorite(this, '2512.15340v1', 'Towards Seamless Interaction: Causal Turn-Level Modeling of Interactive 3D Conversational Head Dynamics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junjie Chen, Fei Wang, Zhihao Huang, Qing Zhou, Kun Li, Dan Guo, Linfeng Zhang, Xun Yang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-17

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/CoderChen01/towards-seamleass-interaction)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTIMARï¼Œç”¨äºå»ºæ¨¡äº¤äº’å¼3Då¯¹è¯å¤´éƒ¨çš„å› æœturnçº§åŠ¨æ€ç”Ÿæˆã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Då¤´éƒ¨åŠ¨æ€ç”Ÿæˆ` `å¯¹è¯å»ºæ¨¡` `å› æœè‡ªå›å½’` `å¤šæ¨¡æ€èåˆ` `æ‰©æ•£æ¨¡å‹` `äººæœºäº¤äº’` `è™šæ‹ŸåŒ–èº«`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é€šå¸¸å°†è¯´è¯å’Œå¬è®²è§†ä¸ºç‹¬ç«‹è¿‡ç¨‹ï¼Œæˆ–ä¾èµ–éå› æœçš„å…¨åºåˆ—å»ºæ¨¡ï¼Œé˜»ç¢äº†turnä¹‹é—´çš„æ—¶é—´è¿è´¯æ€§ã€‚
2. TIMARé€šè¿‡turnçº§äº¤é”™æ©ç è‡ªå›å½’ï¼Œèåˆå¤šæ¨¡æ€ä¿¡æ¯å¹¶åˆ©ç”¨å› æœæ³¨æ„åŠ›ç´¯ç§¯å¯¹è¯å†å²ï¼Œä»è€Œå®ç°æ›´è‡ªç„¶çš„å¤´éƒ¨åŠ¨æ€ç”Ÿæˆã€‚
3. å®éªŒè¡¨æ˜ï¼ŒTIMARåœ¨DualTalkåŸºå‡†æµ‹è¯•ä¸Šæ˜¾è‘—é™ä½äº†FrÃ©chetè·ç¦»å’ŒMSEï¼Œå¹¶åœ¨åˆ†å¸ƒå¤–æ•°æ®ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äº3Då¯¹è¯å¤´éƒ¨ç”Ÿæˆçš„å› æœæ¡†æ¶TIMARï¼ˆTurn-level Interleaved Masked AutoRegressionï¼‰ï¼Œè¯¥æ¡†æ¶å°†å¯¹è¯å»ºæ¨¡ä¸ºäº¤é”™çš„éŸ³é¢‘-è§†è§‰ä¸Šä¸‹æ–‡ã€‚TIMARåœ¨æ¯ä¸ªturnä¸­èåˆå¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¹¶åº”ç”¨turnçº§å› æœæ³¨æ„åŠ›æ¥ç´¯ç§¯å¯¹è¯å†å²ã€‚åŒæ—¶ï¼Œä¸€ä¸ªè½»é‡çº§çš„æ‰©æ•£å¤´é¢„æµ‹è¿ç»­çš„3Då¤´éƒ¨åŠ¨æ€ï¼Œæ•æ‰åè°ƒæ€§å’Œè¡¨è¾¾æ€§å˜åŒ–ã€‚åœ¨DualTalkåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒTIMARåœ¨æµ‹è¯•é›†ä¸Šå°†FrÃ©chetè·ç¦»å’ŒMSEé™ä½äº†15-30%ï¼Œå¹¶åœ¨åˆ†å¸ƒå¤–æ•°æ®ä¸Šå–å¾—äº†ç±»ä¼¼çš„æå‡ã€‚æºä»£ç å°†åœ¨GitHubä»“åº“https://github.com/CoderChen01/towards-seamleass-interaction ä¸­å‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•åœ¨å»ºæ¨¡å¯¹è¯åœºæ™¯ä¸‹çš„3Då¤´éƒ¨åŠ¨æ€æ—¶ï¼Œé€šå¸¸å­˜åœ¨ä¸¤ä¸ªä¸»è¦é—®é¢˜ã€‚ä¸€æ˜¯å°†è¯´è¯è€…å’Œå¬è€…çš„å¤´éƒ¨åŠ¨ä½œè§†ä¸ºç‹¬ç«‹çš„ï¼Œå¿½ç•¥äº†å®ƒä»¬ä¹‹é—´çš„ç›¸äº’å½±å“ã€‚äºŒæ˜¯ä¾èµ–äºéå› æœçš„å…¨åºåˆ—å»ºæ¨¡ï¼Œæ— æ³•ä¿è¯ç”Ÿæˆç»“æœçš„æ—¶é—´è¿è´¯æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹è¯çš„turnåˆ‡æ¢æ—¶å®¹æ˜“å‡ºç°ä¸è‡ªç„¶çš„è·³å˜ã€‚è¿™äº›é—®é¢˜é™åˆ¶äº†è™šæ‹ŸåŒ–èº«å’Œäº¤äº’å¼æœºå™¨äººåœ¨å¯¹è¯åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTIMARçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¯¹è¯è¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ç³»åˆ—äº¤é”™çš„éŸ³é¢‘-è§†è§‰ä¸Šä¸‹æ–‡turnã€‚æ¯ä¸ªturnåŒ…å«è¯´è¯è€…çš„éŸ³é¢‘ä¿¡æ¯å’Œå¬è€…çš„å¤´éƒ¨åŠ¨æ€ä¿¡æ¯ï¼Œé€šè¿‡è¿™ç§äº¤é”™çš„æ–¹å¼ï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°è¯´è¯è€…å’Œå¬è€…ä¹‹é—´çš„ç›¸äº’ä¾èµ–å…³ç³»ã€‚æ­¤å¤–ï¼ŒTIMARé‡‡ç”¨å› æœè‡ªå›å½’çš„æ–¹å¼ï¼Œä¿è¯äº†ç”Ÿæˆç»“æœçš„æ—¶é—´è¿è´¯æ€§ï¼Œé¿å…äº†turnåˆ‡æ¢æ—¶çš„çªå…€æ„Ÿã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTIMARçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šå¤šæ¨¡æ€èåˆæ¨¡å—ã€turnçº§å› æœæ³¨æ„åŠ›æ¨¡å—å’Œæ‰©æ•£å¤´éƒ¨åŠ¨æ€é¢„æµ‹æ¨¡å—ã€‚é¦–å…ˆï¼Œå¤šæ¨¡æ€èåˆæ¨¡å—å°†éŸ³é¢‘å’Œè§†è§‰ä¿¡æ¯èåˆåˆ°æ¯ä¸ªturnçš„ä¸Šä¸‹æ–‡ä¸­ã€‚ç„¶åï¼Œturnçº§å› æœæ³¨æ„åŠ›æ¨¡å—åˆ©ç”¨å› æœæ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†å†å²turnçš„ä¿¡æ¯ç´¯ç§¯åˆ°å½“å‰turnä¸­ï¼Œä»è€Œæ•æ‰å¯¹è¯çš„å†å²ä¿¡æ¯ã€‚æœ€åï¼Œæ‰©æ•£å¤´éƒ¨åŠ¨æ€é¢„æµ‹æ¨¡å—åˆ©ç”¨æ‰©æ•£æ¨¡å‹é¢„æµ‹è¿ç»­çš„3Då¤´éƒ¨åŠ¨æ€ã€‚

**å…³é”®åˆ›æ–°**ï¼šTIMARçš„å…³é”®åˆ›æ–°åœ¨äºå…¶turnçº§äº¤é”™æ©ç è‡ªå›å½’å»ºæ¨¡æ–¹å¼ã€‚è¿™ç§æ–¹å¼èƒ½å¤Ÿæœ‰æ•ˆåœ°å»ºæ¨¡è¯´è¯è€…å’Œå¬è€…ä¹‹é—´çš„ç›¸äº’ä¾èµ–å…³ç³»ï¼Œå¹¶ä¿è¯ç”Ÿæˆç»“æœçš„æ—¶é—´è¿è´¯æ€§ã€‚æ­¤å¤–ï¼ŒTIMARé‡‡ç”¨è½»é‡çº§çš„æ‰©æ•£å¤´éƒ¨åŠ¨æ€é¢„æµ‹æ¨¡å—ï¼Œèƒ½å¤Ÿç”Ÿæˆæ›´åŠ è‡ªç„¶å’Œå¯Œæœ‰è¡¨ç°åŠ›çš„å¤´éƒ¨åŠ¨ä½œã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¤šæ¨¡æ€èåˆæ¨¡å—ä¸­ï¼Œè®ºæ–‡é‡‡ç”¨äº†äº¤å‰æ³¨æ„åŠ›æœºåˆ¶æ¥èåˆéŸ³é¢‘å’Œè§†è§‰ä¿¡æ¯ã€‚åœ¨turnçº§å› æœæ³¨æ„åŠ›æ¨¡å—ä¸­ï¼Œè®ºæ–‡é‡‡ç”¨äº†masked self-attentionæœºåˆ¶ï¼Œä¿è¯äº†å› æœæ€§ã€‚åœ¨æ‰©æ•£å¤´éƒ¨åŠ¨æ€é¢„æµ‹æ¨¡å—ä¸­ï¼Œè®ºæ–‡é‡‡ç”¨äº†U-Netç»“æ„ï¼Œå¹¶ä½¿ç”¨L1æŸå¤±å’Œå¯¹æŠ—æŸå¤±æ¥è®­ç»ƒæ¨¡å‹ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚å¯ä»¥åœ¨è®ºæ–‡çš„å®éªŒéƒ¨åˆ†æ‰¾åˆ°ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.15340v1/x2.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.15340v1/x3.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.15340v1/x4.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

TIMARåœ¨DualTalkåŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨æµ‹è¯•é›†ä¸Šï¼ŒTIMARå°†FrÃ©chetè·ç¦»å’ŒMSEåˆ†åˆ«é™ä½äº†15-30%ã€‚æ­¤å¤–ï¼ŒTIMARåœ¨åˆ†å¸ƒå¤–æ•°æ®ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒTIMARèƒ½å¤Ÿæœ‰æ•ˆåœ°å»ºæ¨¡å¯¹è¯åœºæ™¯ä¸‹çš„3Då¤´éƒ¨åŠ¨æ€ï¼Œå¹¶ç”Ÿæˆæ›´åŠ è‡ªç„¶å’Œè¿è´¯çš„å¤´éƒ¨åŠ¨ä½œã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TIMARçš„ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè™šæ‹ŸåŒ–èº«ã€äº¤äº’å¼æœºå™¨äººã€æ¸¸æˆè§’è‰²åŠ¨ç”»ç­‰é¢†åŸŸã€‚é€šè¿‡ç”Ÿæˆæ›´è‡ªç„¶ã€è¿è´¯çš„3Då¯¹è¯å¤´éƒ¨åŠ¨æ€ï¼Œå¯ä»¥æå‡ç”¨æˆ·åœ¨è™šæ‹Ÿç¯å¢ƒä¸­çš„æ²‰æµ¸æ„Ÿå’Œäº¤äº’ä½“éªŒï¼Œä½¿äººæœºäº¤äº’æ›´åŠ æµç•…è‡ªç„¶ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºè¿œç¨‹ä¼šè®®ã€åœ¨çº¿æ•™è‚²ã€è™šæ‹Ÿç¤¾äº¤ç­‰åœºæ™¯ï¼Œä¿ƒè¿›äººä¸æœºå™¨ä¹‹é—´çš„æ— ç¼äº¤æµã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Human conversation involves continuous exchanges of speech and nonverbal cues such as head nods, gaze shifts, and facial expressions that convey attention and emotion. Modeling these bidirectional dynamics in 3D is essential for building expressive avatars and interactive robots. However, existing frameworks often treat talking and listening as independent processes or rely on non-causal full-sequence modeling, hindering temporal coherence across turns. We present TIMAR (Turn-level Interleaved Masked AutoRegression), a causal framework for 3D conversational head generation that models dialogue as interleaved audio-visual contexts. It fuses multimodal information within each turn and applies turn-level causal attention to accumulate conversational history, while a lightweight diffusion head predicts continuous 3D head dynamics that captures both coordination and expressive variability. Experiments on the DualTalk benchmark show that TIMAR reduces FrÃ©chet Distance and MSE by 15-30% on the test set, and achieves similar gains on out-of-distribution data. The source code will be released in the GitHub repository https://github.com/CoderChen01/towards-seamleass-interaction.

