---
layout: default
title: RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought
---

# RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16796" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16796v2</a>
  <a href="https://arxiv.org/pdf/2506.16796.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16796v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16796v2', 'RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junbo Qiao, Miaomiao Cai, Wei Li, Yutong Liu, Xudong Huang, Gaoqi He, Jiao Xie, Jie Hu, Xinghao Chen, Shaohui Lin

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20 (æ›´æ–°: 2025-06-23)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRealSR-R1ä»¥è§£å†³çœŸå®åœºæ™¯å›¾åƒè¶…åˆ†è¾¨ç‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾åƒè¶…åˆ†è¾¨ç‡` `è§†è§‰è¯­è¨€æ¨ç†` `ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–` `æ·±åº¦å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰` `å›¾åƒæ¢å¤`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å›¾åƒè¶…åˆ†è¾¨ç‡æ–¹æ³•åœ¨ç†è§£é€€åŒ–å›¾åƒå†…å®¹æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´é‡å»ºæ•ˆæœä¸ç†æƒ³ã€‚
2. æœ¬æ–‡æå‡ºçš„VLCoTæ¡†æ¶ç»“åˆè§†è§‰å’Œè¯­è¨€æ¨ç†ï¼Œæ¨¡æ‹Ÿäººç±»å¤„ç†é€€åŒ–å›¾åƒçš„è¿‡ç¨‹ï¼Œæå‡å›¾åƒæ¢å¤èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒRealSR-R1åœ¨ç”ŸæˆçœŸå®ç»†èŠ‚å’Œç†è§£å›¾åƒå†…å®¹æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨å¤æ‚åœºæ™¯ä¸­æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çœŸå®åœºæ™¯å›¾åƒè¶…åˆ†è¾¨ç‡æ˜¯å›¾åƒæ¢å¤ä¸­æœ€å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¹‹ä¸€ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨ç†è§£é€€åŒ–å›¾åƒå†…å®¹æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå¯¼è‡´é‡å»ºç»“æœä½ä¿çœŸä¸”ä¸è‡ªç„¶ã€‚æœ¬æ–‡æå‡ºRealSR-R1ï¼Œèµ‹äºˆRealSRæ¨¡å‹ç†è§£å’Œæ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†VLCoTæ¡†æ¶ï¼Œç»“åˆè§†è§‰å’Œè¯­è¨€æ¨ç†ï¼Œæ—¨åœ¨é€šè¿‡é€æ­¥ç”Ÿæˆæ›´å…¨é¢çš„æ–‡æœ¬å’Œæ›´é«˜åˆ†è¾¨ç‡çš„å›¾åƒæ¥ç²¾ç¡®æ¢å¤å›¾åƒç»†èŠ‚ã€‚ä¸ºå…‹æœä¼ ç»Ÿç›‘ç£å­¦ä¹ CoTåœ¨çœŸå®åœºæ™¯ä¸­çš„æ³›åŒ–ä¸è¶³ï¼Œæˆ‘ä»¬é¦–æ¬¡å°†ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¼•å…¥çœŸå®åœºæ™¯å›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡ã€‚å®éªŒè¡¨æ˜ï¼ŒRealSR-R1èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„ç»†èŠ‚å¹¶å‡†ç¡®ç†è§£å›¾åƒå†…å®¹ï¼Œå°¤å…¶åœ¨è¯­ä¹‰ä¸°å¯Œæˆ–ä¸¥é‡é€€åŒ–çš„å›¾åƒä¸­è¡¨ç°çªå‡ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³çœŸå®åœºæ™¯å›¾åƒè¶…åˆ†è¾¨ç‡ä¸­çš„å†…å®¹ç†è§£ä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é€€åŒ–å›¾åƒæ—¶ï¼Œå¸¸å¸¸æ— æ³•å‡†ç¡®æ¢å¤ç»†èŠ‚ï¼Œå¯¼è‡´ç”Ÿæˆç»“æœä½ä¿çœŸä¸”ä¸è‡ªç„¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥è§†è§‰å’Œè¯­è¨€æ¨ç†çš„ç»“åˆï¼Œæ¨¡æ‹Ÿäººç±»å¤„ç†é€€åŒ–å›¾åƒçš„æ€ç»´è¿‡ç¨‹ï¼Œä»è€Œæå‡å›¾åƒæ¢å¤çš„å‡†ç¡®æ€§å’Œè‡ªç„¶æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬VLCoTæ¡†æ¶ï¼Œåˆ†ä¸ºå¤šä¸ªé˜¶æ®µï¼šé¦–å…ˆç”Ÿæˆæ–‡æœ¬æè¿°ï¼Œç„¶åé€æ­¥ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚æ¡†æ¶ä¸­è®¾è®¡äº†å››ä¸ªå¥–åŠ±å‡½æ•°ï¼Œä»¥å¼•å¯¼æ¨¡å‹ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯é¦–æ¬¡å°†ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¼•å…¥å›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨çœŸå®åœºæ™¯ä¸­çš„æ³›åŒ–é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šè®¾è®¡äº†å››ä¸ªå¥–åŠ±å‡½æ•°ï¼šæ ¼å¼å¥–åŠ±ã€é€€åŒ–å¥–åŠ±ã€ç†è§£å¥–åŠ±å’Œç”Ÿæˆå¥–åŠ±ï¼Œåˆ†åˆ«ç”¨äºæ ‡å‡†åŒ–CoTè¿‡ç¨‹ã€æ¿€åŠ±å‡†ç¡®çš„é€€åŒ–ä¼°è®¡ã€ç¡®ä¿ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§ï¼Œä»¥åŠåˆ©ç”¨è§†è§‰ä¸“å®¶æ¨¡å‹è¯„ä¼°ç”Ÿæˆå›¾åƒè´¨é‡ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨å®éªŒä¸­è¿›è¡Œäº†è¯¦ç»†è°ƒä¼˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRealSR-R1åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå°¤å…¶åœ¨å¤æ‚åœºæ™¯å’Œä¸¥é‡é€€åŒ–å›¾åƒä¸­ï¼Œç”Ÿæˆçš„å›¾åƒè´¨é‡æ˜¾è‘—æé«˜ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒéªŒè¯äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨å›¾åƒæ¢å¤ã€è®¡ç®—æœºè§†è§‰å’Œå›¾åƒå¤„ç†ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡å›¾åƒè¶…åˆ†è¾¨ç‡çš„è´¨é‡ï¼ŒRealSR-R1å¯åº”ç”¨äºåŒ»ç–—å½±åƒã€å«æ˜Ÿå›¾åƒåˆ†æã€è§†é¢‘ç›‘æ§ç­‰å¤šä¸ªå®é™…åœºæ™¯ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Real-World Image Super-Resolution is one of the most challenging task in image restoration. However, existing methods struggle with an accurate understanding of degraded image content, leading to reconstructed results that are both low-fidelity and unnatural. We present RealSR-R1 in this work, which empowers the RealSR models with understanding and reasoning capabilities. Inspired by the success of Chain of Thought (CoT) in large language models (LLMs), we simulate the human process of handling degraded images and propose the VLCoT framework, which integrates vision and language reasoning. The framework aims to precisely restore image details by progressively generating more comprehensive text and higher-resolution images. To overcome the challenge of traditional supervised learning CoT failing to generalize to real-world scenarios, we introduce, for the first time, Group Relative Policy Optimization (GRPO) into the Real-World Image Super-Resolution task. We propose VLCoT-GRPO as a solution, which designs four reward functions: (1) Format reward, used to standardize the CoT process; (2) Degradation reward, to incentivize accurate degradation estimation; (3) Understanding reward, to ensure the accuracy of the generated content; and (4) Generation reward, where we propose using a visual expert model to evaluate the quality of generated images, encouraging the model to generate more realistic images. Extensive experiments demonstrate that our proposed RealSR-R1 can generate realistic details and accurately understand image content, particularly in semantically rich scenes or images with severe degradation.

