---
layout: default
title: Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens
---

# Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17218" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17218v1</a>
  <a href="https://arxiv.org/pdf/2506.17218.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17218v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17218v1', 'Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zeyuan Yang, Xueyang Yu, Delin Chen, Maohao Shen, Chuang Gan

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20

**å¤‡æ³¨**: Project page: https://vlm-mirage.github.io/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæœºå™¨å¿ƒç†æ„è±¡æ¡†æ¶ä»¥å¢å¼ºå¤šæ¨¡æ€æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨ç†` `æ½œåœ¨è§†è§‰æ ‡è®°` `æœºå™¨å¿ƒç†æ„è±¡` `è§†è§‰è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤šæ¨¡æ€æ¨ç†ä¸­å—åˆ°æ–‡æœ¬è§£ç çš„é™åˆ¶ï¼Œéš¾ä»¥è¿›è¡Œæœ‰æ•ˆçš„è§†è§‰æƒ³è±¡ã€‚
2. æœ¬æ–‡æå‡ºçš„Mirageæ¡†æ¶é€šè¿‡å¼•å…¥æ½œåœ¨è§†è§‰æ ‡è®°ï¼Œä½¿æ¨¡å‹åœ¨æ¨ç†æ—¶æ— éœ€ç”Ÿæˆæ˜¾å¼å›¾åƒï¼Œå¢å¼ºäº†å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMirageåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å¤šæ¨¡æ€ç†è§£æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶ä»…ä¾èµ–æ–‡æœ¬è§£ç çš„æ–¹å¼é™åˆ¶äº†è§†è§‰æ¨ç†èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦è§†è§‰æƒ³è±¡çš„ä»»åŠ¡ä¸­ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºMirageçš„æœºå™¨å¿ƒç†æ„è±¡æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥æ½œåœ¨è§†è§‰æ ‡è®°æ¥å¢å¼ºVLMè§£ç èƒ½åŠ›ã€‚è¯¥æ¡†æ¶å…è®¸æ¨¡å‹åœ¨ä¸ç”Ÿæˆæ˜¾å¼å›¾åƒçš„æƒ…å†µä¸‹è¿›è¡Œå¤šæ¨¡æ€æ¨ç†ã€‚é€šè¿‡ä»çœŸå®å›¾åƒåµŒå…¥è¿›è¡Œè’¸é¦ç›‘ç£ï¼Œéšåè½¬å‘ä»…ä½¿ç”¨æ–‡æœ¬ç›‘ç£ï¼Œè¿›ä¸€æ­¥é€šè¿‡å¼ºåŒ–å­¦ä¹ æå‡å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMirageåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ¨ç†èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤šæ¨¡æ€æ¨ç†ä¸­å› ä»…ä¾èµ–æ–‡æœ¬è§£ç è€Œå¯¼è‡´çš„è§†è§‰æƒ³è±¡èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨éœ€è¦ç”Ÿæˆå›¾åƒçš„ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†æ¨ç†çš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„Mirageæ¡†æ¶é€šè¿‡å¼•å…¥æ½œåœ¨è§†è§‰æ ‡è®°ï¼Œä½¿æ¨¡å‹åœ¨è¿›è¡Œæ¨ç†æ—¶èƒ½å¤Ÿåœ¨ä¸ç”Ÿæˆæ˜¾å¼å›¾åƒçš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨å†…åœ¨çš„è§†è§‰çº¿ç´¢è¿›è¡Œæ€è€ƒã€‚è¿™ç§è®¾è®¡çµæ„Ÿæ¥æºäºäººç±»çš„å¿ƒç†æ„è±¡èƒ½åŠ›ï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMirageæ¡†æ¶çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œé€šè¿‡è’¸é¦çœŸå®å›¾åƒåµŒå…¥æ¥ç›‘ç£æ½œåœ¨è§†è§‰æ ‡è®°ï¼›å…¶æ¬¡ï¼Œè½¬å‘ä»…ä½¿ç”¨æ–‡æœ¬çš„ç›‘ç£æ–¹å¼ï¼Œä»¥ç¡®ä¿æ½œåœ¨è½¨è¿¹ä¸ä»»åŠ¡ç›®æ ‡çš„ç´§å¯†å¯¹é½ï¼›æœ€åï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›ä¸€æ­¥æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šMirageçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥æ½œåœ¨è§†è§‰æ ‡è®°ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸ä¾èµ–æ˜¾å¼å›¾åƒç”Ÿæˆã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å›¾åƒç”Ÿæˆé¢„è®­ç»ƒæ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œé¿å…äº†å›¾åƒç”Ÿæˆå¯¹æ¨ç†èƒ½åŠ›çš„è´Ÿé¢å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡æ–‡æœ¬å’Œæ½œåœ¨è§†è§‰æ ‡è®°çš„ç›‘ç£ï¼ŒåŒæ—¶åœ¨å¼ºåŒ–å­¦ä¹ é˜¶æ®µå¼•å…¥äº†å¥–åŠ±æœºåˆ¶ï¼Œä»¥è¿›ä¸€æ­¥ä¼˜åŒ–å¤šæ¨¡æ€æ¨ç†çš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMirageåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œæ¨ç†å‡†ç¡®ç‡æé«˜äº†çº¦15%ï¼Œåœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°å°¤ä¸ºçªå‡ºï¼Œå±•ç¤ºäº†å…¶åœ¨è§†è§‰æƒ³è±¡ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººè§†è§‰ç­‰ï¼Œèƒ½å¤Ÿåœ¨éœ€è¦å¤šæ¨¡æ€ç†è§£å’Œæ¨ç†çš„åœºæ™¯ä¸­æä¾›æ›´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚æœªæ¥ï¼ŒMirageæ¡†æ¶å¯èƒ½æ¨åŠ¨æ›´å¤æ‚çš„å¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿçš„å‘å±•ï¼Œæå‡äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæ™ºèƒ½åŒ–æ°´å¹³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-language models (VLMs) excel at multimodal understanding, yet their text-only decoding forces them to verbalize visual reasoning, limiting performance on tasks that demand visual imagination. Recent attempts train VLMs to render explicit images, but the heavy image-generation pre-training often hinders the reasoning ability. Inspired by the way humans reason with mental imagery-the internal construction and manipulation of visual cues-we investigate whether VLMs can reason through interleaved multimodal trajectories without producing explicit images. To this end, we present a Machine Mental Imagery framework, dubbed as Mirage, which augments VLM decoding with latent visual tokens alongside ordinary text. Concretely, whenever the model chooses to ``think visually'', it recasts its hidden states as next tokens, thereby continuing a multimodal trajectory without generating pixel-level images. Begin by supervising the latent tokens through distillation from ground-truth image embeddings, we then switch to text-only supervision to make the latent trajectory align tightly with the task objective. A subsequent reinforcement learning stage further enhances the multimodal reasoning capability. Experiments on diverse benchmarks demonstrate that Mirage unlocks stronger multimodal reasoning without explicit image generation.

