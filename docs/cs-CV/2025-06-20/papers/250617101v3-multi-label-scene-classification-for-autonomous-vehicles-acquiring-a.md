---
layout: default
title: Multi-label Scene Classification for Autonomous Vehicles: Acquiring and Accumulating Knowledge from Diverse Datasets
---

# Multi-label Scene Classification for Autonomous Vehicles: Acquiring and Accumulating Knowledge from Diverse Datasets

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17101" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17101v3</a>
  <a href="https://arxiv.org/pdf/2506.17101.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17101v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17101v3', 'Multi-label Scene Classification for Autonomous Vehicles: Acquiring and Accumulating Knowledge from Diverse Datasets')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ke Li, Chenyu Zhang, Yuxin Ding, Xianbiao Hu, Ruwen Qin

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20 (æ›´æ–°: 2025-09-17)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/KELISBU/KAA-CAL)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºKAA-CALä»¥è§£å†³è‡ªåŠ¨é©¾é©¶åœºæ™¯å¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `å¤šæ ‡ç­¾åˆ†ç±»` `çŸ¥è¯†è·å–` `ä¸»åŠ¨å­¦ä¹ ` `æ·±åº¦å­¦ä¹ ` `åœºæ™¯è¯†åˆ«` `æ•°æ®é›†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šæ ‡ç­¾åœºæ™¯åˆ†ç±»ä¸­é¢ä¸´æ•°æ®é›†è·å–å›°éš¾å’Œæ–°å±æ€§å‡ºç°æ—¶éœ€é‡æ–°æ³¨é‡Šçš„æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºçš„KAA-CALæ–¹æ³•é€šè¿‡çŸ¥è¯†è·å–ä¸ç§¯ç´¯å’Œä¸»åŠ¨å­¦ä¹ ç›¸ç»“åˆï¼Œè§£å†³äº†å¤šæ ‡ç­¾åˆ†ç±»çš„é€‚åº”æ€§é—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒKAA-CALåœ¨DSIæ•°æ®é›†ä¸Šæå‡äº†56.1%ï¼Œå¹¶åœ¨å…¶ä»–æ•°æ®é›†ä¸Šä»¥æ›´å°‘çš„æ•°æ®å®ç°äº†æ›´å¥½çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é©¾é©¶åœºæ™¯æœ¬è´¨ä¸Šæ˜¯å¼‚è´¨å’ŒåŠ¨æ€çš„ã€‚å¤šå±æ€§åœºæ™¯è¯†åˆ«ä½œä¸ºä¸€ç§é«˜çº§è§†è§‰æ„ŸçŸ¥èƒ½åŠ›ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶è½¦è¾†æä¾›äº†å¿…è¦çš„ä¸Šä¸‹æ–‡æ„è¯†ï¼Œä»¥ç†è§£ã€æ¨ç†å’Œä¸å¤æ‚é©¾é©¶ç¯å¢ƒäº’åŠ¨ã€‚å°½ç®¡åœºæ™¯è¯†åˆ«æœ€å¥½é€šè¿‡å¤šä»»åŠ¡å­¦ä¹ å»ºæ¨¡ä¸ºå¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜ï¼Œä½†é¢ä¸´ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šè·å–å¹³è¡¡ä¸”å…¨é¢æ³¨é‡Šçš„æ•°æ®é›†çš„å›°éš¾ï¼Œä»¥åŠå½“æ–°å±æ€§å‡ºç°æ—¶éœ€è¦é‡æ–°æ³¨é‡Šæ‰€æœ‰è®­ç»ƒæ•°æ®ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œå°†çŸ¥è¯†è·å–ä¸ç§¯ç´¯ï¼ˆKAAï¼‰ä¸åŸºäºä¸€è‡´æ€§çš„ä¸»åŠ¨å­¦ä¹ ï¼ˆCALï¼‰ç›¸ç»“åˆã€‚KAAåˆ©ç”¨å¼‚è´¨å•æ ‡ç­¾æ•°æ®é›†çš„å•ä»»åŠ¡å­¦ä¹ å»ºç«‹çŸ¥è¯†åŸºç¡€ï¼Œè€ŒCALåˆ™å¼¥åˆå•æ ‡ç­¾å’Œå¤šæ ‡ç­¾æ•°æ®ä¹‹é—´çš„å·®è·ï¼Œé€‚åº”å¤šæ ‡ç­¾åœºæ™¯åˆ†ç±»çš„åŸºç¡€æ¨¡å‹ã€‚å¯¹æ–°å¼€å‘çš„é©¾é©¶åœºæ™¯è¯†åˆ«ï¼ˆDSIï¼‰æ•°æ®é›†çš„æ¶ˆèç ”ç©¶è¡¨æ˜ï¼Œç›¸è¾ƒäºImageNeté¢„è®­ç»ƒåŸºçº¿ï¼Œæå‡äº†56.1%ã€‚æ­¤å¤–ï¼ŒKAA-CALåœ¨BDD100Kå’ŒHSDæ•°æ®é›†ä¸Šè¶…è¶Šäº†æœ€å…ˆè¿›çš„å¤šæ ‡ç­¾åˆ†ç±»æ–¹æ³•ï¼Œä½¿ç”¨çš„æ•°æ®é‡å‡å°‘äº†85%ï¼Œç”šè‡³èƒ½å¤Ÿè¯†åˆ«åœ¨åŸºç¡€æ¨¡å‹è®­ç»ƒæœŸé—´æœªè§è¿‡çš„å±æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è‡ªåŠ¨é©¾é©¶åœºæ™¯çš„å¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è·å–å¹³è¡¡æ•°æ®é›†å’Œåº”å¯¹æ–°å±æ€§æ—¶å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç»“åˆçŸ¥è¯†è·å–ä¸ç§¯ç´¯ï¼ˆKAAï¼‰å’ŒåŸºäºä¸€è‡´æ€§çš„ä¸»åŠ¨å­¦ä¹ ï¼ˆCALï¼‰ï¼Œæ„å»ºä¸€ä¸ªé€‚åº”æ€§å¼ºçš„å¤šæ ‡ç­¾åˆ†ç±»æ¡†æ¶ï¼Œä»¥ä¾¿æœ‰æ•ˆåˆ©ç”¨å¼‚è´¨æ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šKAAæ¨¡å—ç”¨äºä»å•æ ‡ç­¾æ•°æ®é›†ä¸­è·å–çŸ¥è¯†ï¼ŒCALæ¨¡å—åˆ™ç”¨äºå°†è¿™äº›çŸ¥è¯†é€‚åº”åˆ°å¤šæ ‡ç­¾åœºæ™¯åˆ†ç±»ä¸­ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºKAA-CALæ–¹æ³•çš„æå‡ºï¼Œå®ƒé€šè¿‡æœ‰æ•ˆæ•´åˆå•æ ‡ç­¾å’Œå¤šæ ‡ç­¾å­¦ä¹ ï¼Œæ˜¾è‘—æé«˜äº†åˆ†ç±»æ€§èƒ½ï¼Œå¹¶å‡å°‘äº†å¯¹æ•°æ®çš„éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡ä¸åŒæ ‡ç­¾çš„å½±å“ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥é€‚åº”å¤šæ ‡ç­¾çš„ç‰¹æ€§ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒKAA-CALæ–¹æ³•åœ¨æ–°å¼€å‘çš„DSIæ•°æ®é›†ä¸Šç›¸è¾ƒäºImageNeté¢„è®­ç»ƒåŸºçº¿æå‡äº†56.1%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨BDD100Kå’ŒHSDæ•°æ®é›†ä¸Šè¶…è¶Šäº†ç°æœ‰çš„å¤šæ ‡ç­¾åˆ†ç±»æŠ€æœ¯ï¼Œä¸”ä½¿ç”¨çš„æ•°æ®é‡å‡å°‘äº†85%ï¼Œå±•ç°å‡ºå¼ºå¤§çš„æ•°æ®æ•ˆç‡å’Œé€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿã€æ™ºèƒ½äº¤é€šç®¡ç†å’ŒåŸå¸‚ç¯å¢ƒç›‘æµ‹ç­‰ã€‚é€šè¿‡æå‡è‡ªåŠ¨é©¾é©¶è½¦è¾†å¯¹å¤æ‚åœºæ™¯çš„ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜è¡Œè½¦å®‰å…¨æ€§å’Œæ•ˆç‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Driving scenes are inherently heterogeneous and dynamic. Multi-attribute scene identification, as a high-level visual perception capability, provides autonomous vehicles (AVs) with essential contextual awareness to understand, reason through, and interact with complex driving environments. Although scene identification is best modeled as a multi-label classification problem via multitask learning, it faces two major challenges: the difficulty of acquiring balanced, comprehensively annotated datasets and the need to re-annotate all training data when new attributes emerge. To address these challenges, this paper introduces a novel deep learning method that integrates Knowledge Acquisition and Accumulation (KAA) with Consistency-based Active Learning (CAL). KAA leverages monotask learning on heterogeneous single-label datasets to build a knowledge foundation, while CAL bridges the gap between single- and multi-label data, adapting the foundation model for multi-label scene classification. An ablation study on the newly developed Driving Scene Identification (DSI) dataset demonstrates a 56.1% improvement over an ImageNet-pretrained baseline. Moreover, KAA-CAL outperforms state-of-the-art multi-label classification methods on the BDD100K and HSD datasets, achieving this with 85% less data and even recognizing attributes unseen during foundation model training. The DSI dataset and KAA-CAL implementation code are publicly available at https://github.com/KELISBU/KAA-CAL .

