---
layout: default
title: Positional Preservation Embedding for Multimodal Large Language Models
---

# Positional Preservation Embedding for Multimodal Large Language Models

**arXiv**: [2510.22936v1](https://arxiv.org/abs/2510.22936) | [PDF](https://arxiv.org/pdf/2510.22936.pdf)

**ä½œè€…**: Mouxiao Huang, Borui Jiang, Dehua Zheng, Hailin Hu, Kai Han, Xinghao Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä½ç½®ä¿æŒåµŒå…¥ä»¥è§£å†³å¤šæ¨¡æ€å¤§æ¨¡åž‹ä¸­è§†è§‰ä»¤ç‰ŒåŽ‹ç¼©æ—¶çš„ç©ºé—´å¸ƒå±€ç ´åé—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `è§†è§‰ä»¤ç‰ŒåŽ‹ç¼©` `ä½ç½®ä¿æŒåµŒå…¥` `ç©ºé—´å¸ƒå±€ä¿ç•™` `æ—¶é—´è¿žç»­æ€§` `çº§è”èšç±»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ä»¤ç‰Œåˆå¹¶æ–¹æ³•åœ¨å‡å°‘åºåˆ—é•¿åº¦æ—¶å¿½ç•¥ä½ç½®å…³ç³»ï¼Œç ´åç©ºé—´å¸ƒå±€å’Œæ—¶é—´è¿žç»­æ€§
2. æ–¹æ³•è¦ç‚¹ï¼šPPEé€šè¿‡è§£è€¦ç¼–ç 3Dä½ç½®ï¼Œä½¿åŽ‹ç¼©ä»¤ç‰Œå°è£…å¤šä¸ªåŽŸå§‹ä»¤ç‰Œçš„ä¸åŒä½ç½®
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®žçŽ°2%~5%æ€§èƒ½æå‡ï¼Œæ”¯æŒçº§è”èšç±»ç­–ç•¥

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) have achieved strong performance on
> vision-language tasks, yet often suffer from inefficiencies due to redundant
> visual tokens. Existing token merging methods reduce sequence length but
> frequently disrupt spatial layouts and temporal continuity by disregarding
> positional relationships. In this work, we propose a novel encoding operator
> dubbed as \textbf{P}ositional \textbf{P}reservation \textbf{E}mbedding
> (\textbf{PPE}), which has the main hallmark of preservation of spatiotemporal
> structure during visual token compression. PPE explicitly introduces the
> disentangled encoding of 3D positions in the token dimension, enabling each
> compressed token to encapsulate different positions from multiple original
> tokens. Furthermore, we show that PPE can effectively support cascade
> clustering -- a progressive token compression strategy that leads to better
> performance retention. PPE is a parameter-free and generic operator that can be
> seamlessly integrated into existing token merging methods without any
> adjustments. Applied to state-of-the-art token merging framework, PPE achieves
> consistent improvements of $2\%\sim5\%$ across multiple vision-language
> benchmarks, including MMBench (general vision understanding), TextVQA (layout
> understanding) and VideoMME (temporal understanding). These results demonstrate
> that preserving positional cues is critical for efficient and effective MLLM
> reasoning.

