---
layout: default
title: VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting
---

# VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting

**arXiv**: [2510.23205v1](https://arxiv.org/abs/2510.23205) | [PDF](https://arxiv.org/pdf/2510.23205.pdf)

**ä½œè€…**: Hoonhee Cho, Jae-Young Kang, Giwon Lee, Hyemin Yang, Heejun Park, Seokwoo Jung, Kuk-Jin Yoon

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVR-Driveä»¥è§£å†³ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ä¸­ç›¸æœºè§†è§’å˜åŒ–çš„é²æ£’æ€§é—®é¢˜**

**å…³é”®è¯**: `ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶` `3Dé«˜æ–¯æ³¼æº…` `è§†è§’é²æ£’æ€§` `è§†å›¾åˆæˆ` `è’¸é¦ç­–ç•¥` `åŸºå‡†æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶åœ¨å¤šæ ·åŒ–ç›¸æœºè§†è§’ä¸‹ç¼ºä¹é²æ£’æ€§ï¼Œå½±å“å®žé™…éƒ¨ç½²ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè”åˆå­¦ä¹ 3Dåœºæ™¯é‡å»ºä½œä¸ºè¾…åŠ©ä»»åŠ¡ï¼Œæ”¯æŒå‰é¦ˆæŽ¨ç†å’Œè§†è§’æ··åˆè®°å¿†åº“ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ–°åž‹è§†è§’åŸºå‡†æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæå‡è§„åˆ’æ€§èƒ½å¹¶å‡å°‘åˆæˆå™ªå£°ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> End-to-end autonomous driving (E2E-AD) has emerged as a promising paradigm
> that unifies perception, prediction, and planning into a holistic, data-driven
> framework. However, achieving robustness to varying camera viewpoints, a common
> real-world challenge due to diverse vehicle configurations, remains an open
> problem. In this work, we propose VR-Drive, a novel E2E-AD framework that
> addresses viewpoint generalization by jointly learning 3D scene reconstruction
> as an auxiliary task to enable planning-aware view synthesis. Unlike prior
> scene-specific synthesis approaches, VR-Drive adopts a feed-forward inference
> strategy that supports online training-time augmentation from sparse views
> without additional annotations. To further improve viewpoint consistency, we
> introduce a viewpoint-mixed memory bank that facilitates temporal interaction
> across multiple viewpoints and a viewpoint-consistent distillation strategy
> that transfers knowledge from original to synthesized views. Trained in a fully
> end-to-end manner, VR-Drive effectively mitigates synthesis-induced noise and
> improves planning under viewpoint shifts. In addition, we release a new
> benchmark dataset to evaluate E2E-AD performance under novel camera viewpoints,
> enabling comprehensive analysis. Our results demonstrate that VR-Drive is a
> scalable and robust solution for the real-world deployment of end-to-end
> autonomous driving systems.

