---
layout: default
title: LoMix: Learnable Weighted Multi-Scale Logits Mixing for Medical Image Segmentation
---

# LoMix: Learnable Weighted Multi-Scale Logits Mixing for Medical Image Segmentation

**arXiv**: [2510.22995v1](https://arxiv.org/abs/2510.22995) | [PDF](https://arxiv.org/pdf/2510.22995.pdf)

**ä½œè€…**: Md Mostafijur Rahman, Radu Marculescu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLoMixæ¨¡å—ï¼Œé€šè¿‡å¯å­¦ä¹ åŠ æƒå¤šå°ºåº¦logitsèžåˆæå‡åŒ»å­¦å›¾åƒåˆ†å‰²æ€§èƒ½ã€‚**

**å…³é”®è¯**: `åŒ»å­¦å›¾åƒåˆ†å‰²` `å¤šå°ºåº¦èžåˆ` `å¯å­¦ä¹ æƒé‡` `Uå½¢ç½‘ç»œ` `é›¶æŽ¨ç†å¼€é”€`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. Uå½¢ç½‘ç»œå¤šå°ºåº¦logitsè®­ç»ƒæ—¶å­¤ç«‹å¤„ç†ï¼Œæœªå……åˆ†åˆ©ç”¨ç²—-ç»†é¢„æµ‹èžåˆäº’è¡¥ä¿¡æ¯ã€‚
2. LoMixä½¿ç”¨å››ç§è½»é‡èžåˆç®—å­æ··åˆlogitsï¼Œå¹¶å­¦ä¹ è½¯åŠ æŸå¤±æƒé‡ï¼Œå®žçŽ°é›¶æŽ¨ç†å¼€é”€ã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒDICEæå‡è¾¾+13.5%ï¼Œæ•°æ®ç¨€ç¼ºæ—¶ä¼˜åŠ¿æ›´æ˜¾è‘—ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> U-shaped networks output logits at multiple spatial scales, each capturing a
> different blend of coarse context and fine detail. Yet, training still treats
> these logits in isolation - either supervising only the final,
> highest-resolution logits or applying deep supervision with identical loss
> weights at every scale - without exploring mixed-scale combinations.
> Consequently, the decoder output misses the complementary cues that arise only
> when coarse and fine predictions are fused. To address this issue, we introduce
> LoMix (Logits Mixing), a NAS-inspired, differentiable plug-and-play module that
> generates new mixed-scale outputs and learns how exactly each of them should
> guide the training process. More precisely, LoMix mixes the multi-scale decoder
> logits with four lightweight fusion operators: addition, multiplication,
> concatenation, and attention-based weighted fusion, yielding a rich set of
> synthetic mutant maps. Every original or mutant map is given a softplus loss
> weight that is co-optimized with network parameters, mimicking a one-step
> architecture search that automatically discovers the most useful scales,
> mixtures, and operators. Plugging LoMix into recent U-shaped architectures
> (i.e., PVT-V2-B2 backbone with EMCAD decoder) on Synapse 8-organ dataset
> improves DICE by +4.2% over single-output supervision, +2.2% over deep
> supervision, and +1.5% over equally weighted additive fusion, all with zero
> inference overhead. When training data are scarce (e.g., one or two labeled
> scans), the advantage grows to +9.23%, underscoring LoMix's data efficiency.
> Across four benchmarks and diverse U-shaped networks, LoMiX improves DICE by up
> to +13.5% over single-output supervision, confirming that learnable weighted
> mixed-scale fusion generalizes broadly while remaining data efficient, fully
> interpretable, and overhead-free at inference. Our code is available at
> https://github.com/SLDGroup/LoMix.

