---
layout: default
title: MergeMix: A Unified Augmentation Paradigm for Visual and Multi-Modal Understanding
---

# MergeMix: A Unified Augmentation Paradigm for Visual and Multi-Modal Understanding

**arXiv**: [2510.23479v1](https://arxiv.org/abs/2510.23479) | [PDF](https://arxiv.org/pdf/2510.23479.pdf)

**ä½œè€…**: Xin Jin, Siyuan Li, Siyong Jian, Kai Yu, Huan Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMergeMixä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ä¸­çš„å¯¹é½è´¨é‡ä¸Žæ•ˆçŽ‡æƒè¡¡é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `è®­ç»ƒå¢žå¼º` `åå¥½å¯¹é½` `å›¾åƒæ··åˆ` `SimPOæŸå¤±`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šSFTä¾èµ–å¤§é‡äººå·¥æ ‡æ³¨ä¸”æ— æ³•æ•æ‰ç»†å¾®åå¥½ï¼ŒRLæ•ˆçŽ‡ä½Žä¸”ä¸ç¨³å®šã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æ³¨æ„åŠ›æ„ŸçŸ¥å›¾åƒæ··åˆå’Œåå¥½é©±åŠ¨è®­ç»ƒï¼Œç»“åˆSimPOæŸå¤±ä¼˜åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åˆ†ç±»ä»»åŠ¡ä¸­å®žçŽ°ç«žäº‰æ€§å‡†ç¡®çŽ‡ï¼Œæå‡æ•ˆçŽ‡ä¸Žå¯¹é½è´¨é‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-language alignment in multi-modal large language models (MLLMs)
> typically relies on supervised fine-tuning (SFT) or reinforcement learning
> (RL). SFT is stable and efficient but requires large-scale human annotations
> and cannot capture subtle preferences, while RL brings in a reward signal for
> training, but suffers from overhead and instability. These limitations
> highlight a trade-off between scalability, robustness, and alignment quality.
> To address this, we propose MergeMix, a training-time augmentation paradigm
> that bridges SFT and RL. It first applies an attention-aware image mixing via
> token merge with more cluster representation and spatial context, and then
> presents a preference-driven training paradigm for MLLMs by building preference
> pairs with mixed images and raw images, and optimizing via SimPO loss. As a
> mixup augmentation, MergeMix enhances attention consistency and efficiency,
> surpassing other heuristic-based methods in classification. Extensive
> experiments demonstrate that MergeMix achieves competitive accuracy with
> improved efficiency, providing a scalable approach to preference alignment in
> classification and MLLMs.

