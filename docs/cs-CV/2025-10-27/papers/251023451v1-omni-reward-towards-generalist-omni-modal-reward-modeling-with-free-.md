---
layout: default
title: Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences
---

# Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences

**arXiv**: [2510.23451v1](https://arxiv.org/abs/2510.23451) | [PDF](https://arxiv.org/pdf/2510.23451.pdf)

**ä½œè€…**: Zhuoran Jin, Hongbang Yuan, Kejian Zhu, Jiachun Li, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmni-Rewardä»¥è§£å†³å¤šæ¨¡æ€å¥–åŠ±æ¨¡åž‹ä¸­çš„æ¨¡æ€ä¸å¹³è¡¡å’Œåå¥½åƒµåŒ–é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¥–åŠ±å»ºæ¨¡` `è‡ªç”±å½¢å¼åå¥½` `å¥–åŠ±æ¨¡åž‹åŸºå‡†` `å¤šæ¨¡æ€æ•°æ®é›†` `ç”Ÿæˆå¼å¥–åŠ±æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰å¥–åŠ±æ¨¡åž‹æ¨¡æ€ä¸å¹³è¡¡ï¼Œåå¥½åƒµåŒ–ï¼Œéš¾ä»¥å¤„ç†ä¸ªæ€§åŒ–åå¥½
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºå¤šæ¨¡æ€åŸºå‡†ã€æ•°æ®é›†å’Œæ¨¡åž‹ï¼Œæ”¯æŒè‡ªç”±å½¢å¼åå¥½
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Omni-RewardBenchç­‰åŸºå‡†ä¸Šè¡¨çŽ°ä¼˜å¼‚ï¼Œè¦†ç›–äº”ç§æ¨¡æ€

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reward models (RMs) play a critical role in aligning AI behaviors with human
> preferences, yet they face two fundamental challenges: (1) Modality Imbalance,
> where most RMs are mainly focused on text and image modalities, offering
> limited support for video, audio, and other modalities; and (2) Preference
> Rigidity, where training on fixed binary preference pairs fails to capture the
> complexity and diversity of personalized preferences. To address the above
> challenges, we propose Omni-Reward, a step toward generalist omni-modal reward
> modeling with support for free-form preferences, consisting of: (1) Evaluation:
> We introduce Omni-RewardBench, the first omni-modal RM benchmark with free-form
> preferences, covering nine tasks across five modalities including text, image,
> video, audio, and 3D; (2) Data: We construct Omni-RewardData, a multimodal
> preference dataset comprising 248K general preference pairs and 69K
> instruction-tuning pairs for training generalist omni-modal RMs; (3) Model: We
> propose Omni-RewardModel, which includes both discriminative and generative
> RMs, and achieves strong performance on Omni-RewardBench as well as other
> widely used reward modeling benchmarks.

