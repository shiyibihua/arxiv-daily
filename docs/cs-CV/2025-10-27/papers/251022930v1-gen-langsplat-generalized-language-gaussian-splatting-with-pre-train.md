---
layout: default
title: Gen-LangSplat: Generalized Language Gaussian Splatting with Pre-Trained Feature Compression
---

# Gen-LangSplat: Generalized Language Gaussian Splatting with Pre-Trained Feature Compression

**arXiv**: [2510.22930v1](https://arxiv.org/abs/2510.22930) | [PDF](https://arxiv.org/pdf/2510.22930.pdf)

**ä½œè€…**: Pranav Saxena

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGen-LangSplatä»¥æ¶ˆé™¤3Dè¯­è¨€åœºæž„å»ºä¸­çš„åœºæ™¯ç‰¹å®šè®­ç»ƒç“¶é¢ˆ**

**å…³é”®è¯**: `3Dé«˜æ–¯æ³¼æº…` `è¯­è¨€åœºå»ºæ¨¡` `é¢„è®­ç»ƒç‰¹å¾åŽ‹ç¼©` `å¼€æ”¾è¯æ±‡æŸ¥è¯¢` `è‡ªç¼–ç å™¨ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•éœ€ä¸ºæ¯ä¸ªåœºæ™¯è®­ç»ƒè¯­è¨€è‡ªç¼–ç å™¨ï¼Œå¯¼è‡´éƒ¨ç½²æ‰©å±•æ€§å·®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨é¢„è®­ç»ƒé€šç”¨è‡ªç¼–ç å™¨æ›¿ä»£åœºæ™¯ç‰¹å®šæ¨¡åž‹ï¼Œå®žçŽ°è·¨åœºæ™¯å›ºå®šæ½œåœ¨ç©ºé—´ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ScanNetæ•°æ®é›†éªŒè¯ï¼Œæ€§èƒ½ä¸ŽåŽŸæ–¹æ³•ç›¸å½“æˆ–æ›´ä¼˜ï¼Œæå‡æ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Modeling open-vocabulary language fields in 3D is essential for intuitive
> human-AI interaction and querying within physical environments.
> State-of-the-art approaches, such as LangSplat, leverage 3D Gaussian Splatting
> to efficiently construct these language fields, encoding features distilled
> from high-dimensional models like CLIP. However, this efficiency is currently
> offset by the requirement to train a scene-specific language autoencoder for
> feature compression, introducing a costly, per-scene optimization bottleneck
> that hinders deployment scalability. In this work, we introduce Gen-LangSplat,
> that eliminates this requirement by replacing the scene-wise autoencoder with a
> generalized autoencoder, pre-trained extensively on the large-scale ScanNet
> dataset. This architectural shift enables the use of a fixed, compact latent
> space for language features across any new scene without any scene-specific
> training. By removing this dependency, our entire language field construction
> process achieves a efficiency boost while delivering querying performance
> comparable to, or exceeding, the original LangSplat method. To validate our
> design choice, we perform a thorough ablation study empirically determining the
> optimal latent embedding dimension and quantifying representational fidelity
> using Mean Squared Error and cosine similarity between the original and
> reprojected 512-dimensional CLIP embeddings. Our results demonstrate that
> generalized embeddings can efficiently and accurately support open-vocabulary
> querying in novel 3D scenes, paving the way for scalable, real-time interactive
> 3D AI applications.

