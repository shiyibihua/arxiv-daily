---
layout: default
title: HieraMamba: Video Temporal Grounding via Hierarchical Anchor-Mamba Pooling
---

# HieraMamba: Video Temporal Grounding via Hierarchical Anchor-Mamba Pooling

**arXiv**: [2510.23043v1](https://arxiv.org/abs/2510.23043) | [PDF](https://arxiv.org/pdf/2510.23043.pdf)

**ä½œè€…**: Joungbin An, Kristen Grauman

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHieraMambaæž¶æž„ä»¥è§£å†³é•¿è§†é¢‘ä¸­è¯­è¨€æŸ¥è¯¢çš„æ—¶åºå®šä½é—®é¢˜**

**å…³é”®è¯**: `è§†é¢‘æ—¶åºå®šä½` `åˆ†å±‚æž¶æž„` `é”šç‚¹ä»¤ç‰Œ` `å¯¹æ¯”å­¦ä¹ ` `é•¿è§†é¢‘ç†è§£` `Mambaæ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé•¿è§†é¢‘æ—¶åºå®šä½éœ€å¹³è¡¡å…¨å±€ä¸Šä¸‹æ–‡ä¸Žç»†ç²’åº¦æ—¶åºç»†èŠ‚ï¼ŒçŽ°æœ‰æ–¹æ³•æ˜“å› è¿‡åº¦ä¸‹é‡‡æ ·æˆ–å›ºå®šçª—å£è€ŒæŸå¤±ç²¾åº¦ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åˆ†å±‚Anchor-MambaPoolingå—ï¼Œé€šè¿‡é€‰æ‹©æ€§æ‰«æç”Ÿæˆå¤šç²’åº¦é”šç‚¹ä»¤ç‰Œï¼Œç»“åˆå¯¹æ¯”æŸå¤±ä¿ç•™å±€éƒ¨ç»†èŠ‚ä¸Žå…¨å±€åŒºåˆ†æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Ego4D-NLQã€MADå’ŒTACoSæ•°æ®é›†ä¸Šè¾¾åˆ°æ–°SOTAï¼Œå®žçŽ°é•¿æœªä¿®å‰ªè§†é¢‘çš„ç²¾ç¡®æ—¶åºå®šä½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Video temporal grounding, the task of localizing the start and end times of a
> natural language query in untrimmed video, requires capturing both global
> context and fine-grained temporal detail. This challenge is particularly
> pronounced in long videos, where existing methods often compromise temporal
> fidelity by over-downsampling or relying on fixed windows. We present
> HieraMamba, a hierarchical architecture that preserves temporal structure and
> semantic richness across scales. At its core are Anchor-MambaPooling (AMP)
> blocks, which utilize Mamba's selective scanning to produce compact anchor
> tokens that summarize video content at multiple granularities. Two
> complementary objectives, anchor-conditioned and segment-pooled contrastive
> losses, encourage anchors to retain local detail while remaining globally
> discriminative. HieraMamba sets a new state-of-the-art on Ego4D-NLQ, MAD, and
> TACoS, demonstrating precise, temporally faithful localization in long,
> untrimmed videos.

