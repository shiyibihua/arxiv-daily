---
layout: default
title: Switchable Token-Specific Codebook Quantization For Face Image Compression
---

# Switchable Token-Specific Codebook Quantization For Face Image Compression

**arXiv**: [2510.22943v1](https://arxiv.org/abs/2510.22943) | [PDF](https://arxiv.org/pdf/2510.22943.pdf)

**ä½œè€…**: Yongbo Wang, Haonan Wang, Guodong Mu, Ruixin Zhang, Jiaqi Chen, Jingyun Zhang, Jun Wang, Yuan Xie, Zhizhong Zhang, Shouhong Ding

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯åˆ‡æ¢ä»¤ç‰Œç‰¹å®šç æœ¬é‡åŒ–æ–¹æ³•ä»¥æå‡äººè„¸å›¾åƒåŽ‹ç¼©æ€§èƒ½**

**å…³é”®è¯**: `äººè„¸å›¾åƒåŽ‹ç¼©` `ç æœ¬é‡åŒ–` `ä»¤ç‰Œç‰¹å®šç æœ¬` `å›¾åƒé‡æž„` `ä½Žæ¯”ç‰¹çŽ‡åŽ‹ç¼©`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. äººè„¸å›¾åƒåŽ‹ç¼©ä¸­å…¨å±€ç æœ¬å¿½ç•¥ç±»åˆ«ç›¸å…³æ€§å’Œä»¤ç‰Œè¯­ä¹‰å·®å¼‚ï¼Œå¯¼è‡´ä½Žæ¯”ç‰¹çŽ‡æ€§èƒ½ä¸ä½³
2. æ–¹æ³•ä¸ºä¸åŒå›¾åƒç±»åˆ«å­¦ä¹ ç æœ¬ç»„ï¼Œå¹¶ä¸ºæ¯ä¸ªä»¤ç‰Œåˆ†é…ç‹¬ç«‹ç æœ¬ï¼Œå‡å°‘ç æœ¬å¤§å°æŸå¤±
3. åœ¨0.05 bppä¸‹é‡æž„å›¾åƒå¹³å‡è¯†åˆ«å‡†ç¡®çŽ‡è¾¾93.51%ï¼Œå¯é›†æˆçŽ°æœ‰ç æœ¬æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> With the ever-increasing volume of visual data, the efficient and lossless
> transmission, along with its subsequent interpretation and understanding, has
> become a critical bottleneck in modern information systems. The emerged
> codebook-based solution utilize a globally shared codebook to quantize and
> dequantize each token, controlling the bpp by adjusting the number of tokens or
> the codebook size. However, for facial images, which are rich in attributes,
> such global codebook strategies overlook both the category-specific
> correlations within images and the semantic differences among tokens, resulting
> in suboptimal performance, especially at low bpp. Motivated by these
> observations, we propose a Switchable Token-Specific Codebook Quantization for
> face image compression, which learns distinct codebook groups for different
> image categories and assigns an independent codebook to each token. By
> recording the codebook group to which each token belongs with a small number of
> bits, our method can reduce the loss incurred when decreasing the size of each
> codebook group. This enables a larger total number of codebooks under a lower
> overall bpp, thereby enhancing the expressive capability and improving
> reconstruction performance. Owing to its generalizable design, our method can
> be integrated into any existing codebook-based representation learning approach
> and has demonstrated its effectiveness on face recognition datasets, achieving
> an average accuracy of 93.51% for reconstructed images at 0.05 bpp.

