---
layout: default
title: Dexbotic: Open-Source Vision-Language-Action Toolbox
---

# Dexbotic: Open-Source Vision-Language-Action Toolbox

**arXiv**: [2510.23511v1](https://arxiv.org/abs/2510.23511) | [PDF](https://arxiv.org/pdf/2510.23511.pdf)

**ä½œè€…**: Bin Xie, Erjin Zhou, Fan Jia, Hao Shi, Haoqiang Fan, Haowei Zhang, Hebei Li, Jianjian Sun, Jie Bin, Junwen Huang, Kai Liu, Kaixin Liu, Kefan Gu, Lin Sun, Meng Zhang, Peilong Han, Ruitao Hao, Ruitao Zhang, Saike Huang, Songhan Xie, Tiancai Wang, Tianle Liu, Wenbin Tang, Wenqi Zhu, Yang Chen, Yingfei Liu, Yizhuang Zhou, Yu Liu, Yucheng Zhao, Yunchao Ma, Yunfei Wei, Yuxiang Chen, Ze Chen, Zeming Li, Zhao Wu, Ziheng Zhang, Ziming Liu, Ziwei Yan, Ziyu Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¼€æºè§†è§‰-è¯­è¨€-åŠ¨ä½œå·¥å…·ç®±Dexboticï¼Œæ”¯æŒå¤šç­–ç•¥VLAç ”ç©¶ã€‚**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `å¼€æºå·¥å…·ç®±` `å…·èº«æ™ºèƒ½` `PyTorchæ¡†æž¶` `é¢„è®­ç»ƒæ¨¡åž‹` `å®žéªŒè„šæœ¬`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¸ºå…·èº«æ™ºèƒ½é¢†åŸŸæä¾›ä¸€ç«™å¼VLAç ”ç©¶æœåŠ¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽPyTorchï¼Œæ”¯æŒå¤šä¸»æµVLAç­–ç•¥ï¼Œç®€åŒ–çŽ¯å¢ƒè®¾ç½®ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæä¾›æ›´å¼ºé¢„è®­ç»ƒæ¨¡åž‹ï¼Œæå‡SOTA VLAç­–ç•¥æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this paper, we present Dexbotic, an open-source Vision-Language-Action
> (VLA) model toolbox based on PyTorch. It aims to provide a one-stop VLA
> research service for professionals in the field of embodied intelligence. It
> offers a codebase that supports multiple mainstream VLA policies
> simultaneously, allowing users to reproduce various VLA methods with just a
> single environment setup. The toolbox is experiment-centric, where the users
> can quickly develop new VLA experiments by simply modifying the Exp script.
> Moreover, we provide much stronger pretrained models to achieve great
> performance improvements for state-of-the-art VLA policies. Dexbotic will
> continuously update to include more of the latest pre-trained foundation models
> and cutting-edge VLA models in the industry.

