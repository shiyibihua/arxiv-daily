---
layout: default
title: Video-Thinker: Sparking "Thinking with Videos" via Reinforcement Learning
---

# Video-Thinker: Sparking "Thinking with Videos" via Reinforcement Learning

**arXiv**: [2510.23473v1](https://arxiv.org/abs/2510.23473) | [PDF](https://arxiv.org/pdf/2510.23473.pdf)

**ä½œè€…**: Shijian Wang, Jiarui Jin, Xingjian Wang, Linxin Song, Runhao Fu, Hecheng Wang, Zongyuan Ge, Yuan Lu, Xuelian Cheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVideo-Thinkerï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ å®žçŽ°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹åœ¨è§†é¢‘æŽ¨ç†ä¸­è‡ªä¸»æ€è€ƒ**

**å…³é”®è¯**: `è§†é¢‘æŽ¨ç†` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `å¼ºåŒ–å­¦ä¹ ` `è‡ªä¸»å·¥å…·ä½¿ç”¨` `é“¾å¼æ€ç»´æŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†é¢‘æŽ¨ç†ä¸­ç¼ºä¹åŠ¨æ€æŽ¨ç†èŒƒå¼ï¼Œæ— æ³•è‡ªä¸»åˆ©ç”¨æ¨¡åž‹èƒ½åŠ›ç”ŸæˆæŽ¨ç†çº¿ç´¢
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºVideo-Thinker-10Kæ•°æ®é›†ï¼Œç»“åˆç›‘ç£å¾®è°ƒå’ŒGRPOå¼ºåŒ–è®­ç»ƒï¼Œå®žçŽ°è‡ªä¸»å·¥å…·ä½¿ç”¨
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªè§†é¢‘æŽ¨ç†åŸºå‡†ä¸Šæ˜¾è‘—è¶…è¶ŠåŸºçº¿ï¼Œ7Bæ¨¡åž‹è¾¾åˆ°æœ€ä¼˜æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in image reasoning methods, particularly "Thinking with
> Images", have demonstrated remarkable success in Multimodal Large Language
> Models (MLLMs); however, this dynamic reasoning paradigm has not yet been
> extended to video reasoning tasks. In this paper, we propose Video-Thinker,
> which empowers MLLMs to think with videos by autonomously leveraging their
> intrinsic "grounding" and "captioning" capabilities to generate reasoning clues
> throughout the inference process. To spark this capability, we construct
> Video-Thinker-10K, a curated dataset featuring autonomous tool usage within
> chain-of-thought reasoning sequences. Our training strategy begins with
> Supervised Fine-Tuning (SFT) to learn the reasoning format, followed by Group
> Relative Policy Optimization (GRPO) to strengthen this reasoning capability.
> Through this approach, Video-Thinker enables MLLMs to autonomously navigate
> grounding and captioning tasks for video reasoning, eliminating the need for
> constructing and calling external tools. Extensive experiments demonstrate that
> Video-Thinker achieves significant performance gains on both in-domain tasks
> and challenging out-of-domain video reasoning benchmarks, including
> Video-Holmes, CG-Bench-Reasoning, and VRBench. Our Video-Thinker-7B
> substantially outperforms existing baselines such as Video-R1 and establishes
> state-of-the-art performance among 7B-sized MLLMs.

