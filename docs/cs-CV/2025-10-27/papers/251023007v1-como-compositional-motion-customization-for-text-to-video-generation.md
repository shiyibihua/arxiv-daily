---
layout: default
title: CoMo: Compositional Motion Customization for Text-to-Video Generation
---

# CoMo: Compositional Motion Customization for Text-to-Video Generation

**arXiv**: [2510.23007v1](https://arxiv.org/abs/2510.23007) | [PDF](https://arxiv.org/pdf/2510.23007.pdf)

**ä½œè€…**: Youcan Xu, Zhen Wang, Jiaxin Shi, Kexin Li, Feifei Shao, Jun Xiao, Yi Yang, Jun Yu, Long Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoMoæ¡†æž¶ä»¥è§£å†³æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆä¸­çš„å¤šè¿åŠ¨å®šåˆ¶é—®é¢˜**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆ` `è¿åŠ¨å®šåˆ¶` `å¤šè¿åŠ¨åˆæˆ` `è§£è€¦å­¦ä¹ ` `å¯æŽ§ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•éš¾ä»¥æŽ§åˆ¶å¤æ‚å¤šä¸»ä½“è¿åŠ¨ï¼Œå­˜åœ¨è¿åŠ¨-å¤–è§‚çº ç¼ å’Œå¤šè¿åŠ¨æ··åˆæ— æ•ˆé—®é¢˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä¸¤é˜¶æ®µæ–¹æ³•ï¼ŒåŒ…æ‹¬é™æ€-åŠ¨æ€è§£è€¦è°ƒè°å’Œå³æ’å³ç”¨åˆ†åˆç­–ç•¥ï¼Œå®žçŽ°å¤šè¿åŠ¨åˆæˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¼•å…¥çš„æ–°åŸºå‡†ä¸Šï¼ŒCoMoå®žçŽ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œæå‡å¯æŽ§è§†é¢‘ç”Ÿæˆèƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While recent text-to-video models excel at generating diverse scenes, they
> struggle with precise motion control, particularly for complex, multi-subject
> motions. Although methods for single-motion customization have been developed
> to address this gap, they fail in compositional scenarios due to two primary
> challenges: motion-appearance entanglement and ineffective multi-motion
> blending. This paper introduces CoMo, a novel framework for
> $\textbf{compositional motion customization}$ in text-to-video generation,
> enabling the synthesis of multiple, distinct motions within a single video.
> CoMo addresses these issues through a two-phase approach. First, in the
> single-motion learning phase, a static-dynamic decoupled tuning paradigm
> disentangles motion from appearance to learn a motion-specific module. Second,
> in the multi-motion composition phase, a plug-and-play divide-and-merge
> strategy composes these learned motions without additional training by
> spatially isolating their influence during the denoising process. To facilitate
> research in this new domain, we also introduce a new benchmark and a novel
> evaluation metric designed to assess multi-motion fidelity and blending.
> Extensive experiments demonstrate that CoMo achieves state-of-the-art
> performance, significantly advancing the capabilities of controllable video
> generation. Our project page is at https://como6.github.io/.

