---
layout: default
title: AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes
---

# AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes

**arXiv**: [2510.23151v1](https://arxiv.org/abs/2510.23151) | [PDF](https://arxiv.org/pdf/2510.23151.pdf)

**ä½œè€…**: Sixian Liu, Chen Xu, Qiang Wang, Donghai Shi, Yiwen Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªé€‚åº”é—¨æŽ§èžåˆæ–¹æ³•ä»¥æå‡å¤æ‚åœºæ™¯ä¸­3Dç›®æ ‡æ£€æµ‹çš„é²æ£’æ€§**

**å…³é”®è¯**: `3Dç›®æ ‡æ£€æµ‹` `å¤šæ¨¡æ€èžåˆ` `è‡ªé€‚åº”é—¨æŽ§` `BEVè¡¨ç¤º` `é²æ£’æ€§` `å¤æ‚åœºæ™¯`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰å¤šæ¨¡æ€èžåˆæ–¹æ³•åœ¨ä¼ æ„Ÿå™¨é€€åŒ–æˆ–çŽ¯å¢ƒå¹²æ‰°åœºæ™¯ä¸­æ€§èƒ½æ˜¾è‘—ä¸‹é™
2. æ–¹æ³•è¦ç‚¹ï¼šåœ¨BEVç©ºé—´ä½¿ç”¨çª—å£æ³¨æ„åŠ›å’Œè·¨æ¨¡æ€æ³¨æ„åŠ›é—¨æŽ§èžåˆç‰¹å¾
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨KITTIæ•°æ®é›†è¾¾93.92%ç²¾åº¦ï¼ŒE3Dæ•°æ®é›†æ¯”åŸºçº¿æå‡24.88%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal camera-LiDAR fusion technology has found extensive application in
> 3D object detection, demonstrating encouraging performance. However, existing
> methods exhibit significant performance degradation in challenging scenarios
> characterized by sensor degradation or environmental disturbances. We propose a
> novel Adaptive Gated Fusion (AG-Fusion) approach that selectively integrates
> cross-modal knowledge by identifying reliable patterns for robust detection in
> complex scenes. Specifically, we first project features from each modality into
> a unified BEV space and enhance them using a window-based attention mechanism.
> Subsequently, an adaptive gated fusion module based on cross-modal attention is
> designed to integrate these features into reliable BEV representations robust
> to challenging environments. Furthermore, we construct a new dataset named
> Excavator3D (E3D) focusing on challenging excavator operation scenarios to
> benchmark performance in complex conditions. Our method not only achieves
> competitive performance on the standard KITTI dataset with 93.92% accuracy, but
> also significantly outperforms the baseline by 24.88% on the challenging E3D
> dataset, demonstrating superior robustness to unreliable modal information in
> complex industrial scenes.

