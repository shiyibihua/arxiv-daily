---
layout: default
title: A U-Net and Transformer Pipeline for Multilingual Image Translation
---

# A U-Net and Transformer Pipeline for Multilingual Image Translation

**arXiv**: [2510.23554v1](https://arxiv.org/abs/2510.23554) | [PDF](https://arxiv.org/pdf/2510.23554.pdf)

**ä½œè€…**: Siddharth Sahay, Radhika Agarwal

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽU-Netå’ŒTransformerçš„å¤šè¯­è¨€å›¾åƒç¿»è¯‘ç®¡é“ï¼Œç”¨äºŽä»Žå›¾åƒä¸­ç›´æŽ¥ç¿»è¯‘æ–‡æœ¬ã€‚**

**å…³é”®è¯**: `å›¾åƒæ–‡æœ¬æ£€æµ‹` `å¤šè¯­è¨€æœºå™¨ç¿»è¯‘` `U-Netæ¨¡åž‹` `Transformeræž¶æž„` `ç«¯åˆ°ç«¯ç®¡é“`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä»Žå›¾åƒä¸­æ£€æµ‹ã€è¯†åˆ«å¹¶ç¿»è¯‘å¤šè¯­è¨€æ–‡æœ¬ï¼Œé¿å…ä¾èµ–é¢„è®­ç»ƒæ¨¡åž‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨U-Netæ£€æµ‹æ–‡æœ¬åŒºåŸŸï¼ŒTesseractè¯†åˆ«æ–‡æœ¬ï¼Œè‡ªå®šä¹‰Transformerè¿›è¡Œç¿»è¯‘ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè¯„ä¼°æ–‡æœ¬æ£€æµ‹å‡†ç¡®æ€§ã€è¯†åˆ«è´¨é‡å’Œç¿»è¯‘BLEUåˆ†æ•°ï¼Œç»“æžœè¡¨çŽ°è‰¯å¥½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper presents an end-to-end multilingual translation pipeline that
> integrates a custom U-Net for text detection, the Tesseract engine for text
> recognition, and a from-scratch sequence-to-sequence (Seq2Seq) Transformer for
> Neural Machine Translation (NMT). Our approach first utilizes a U-Net model,
> trained on a synthetic dataset , to accurately segment and detect text regions
> from an image. These detected regions are then processed by Tesseract to
> extract the source text. This extracted text is fed into a custom Transformer
> model trained from scratch on a multilingual parallel corpus spanning 5
> languages. Unlike systems reliant on monolithic pre-trained models, our
> architecture emphasizes full customization and adaptability. The system is
> evaluated on its text detection accuracy, text recognition quality, and
> translation performance via BLEU scores. The complete pipeline demonstrates
> promising results, validating the viability of a custom-built system for
> translating text directly from images.

