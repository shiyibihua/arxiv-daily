---
layout: default
title: Awakening Facial Emotional Expressions in Human-Robot
---

# Awakening Facial Emotional Expressions in Human-Robot

**arXiv**: [2510.23059v1](https://arxiv.org/abs/2510.23059) | [PDF](https://arxiv.org/pdf/2510.23059.pdf)

**ä½œè€…**: Yongtong Zhu, Lei Li, Iggy Qian, WenBin Zhou, Ye Yuan, Qingdu Li, Na Liu, Jianwei Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽKANå’Œæ³¨æ„åŠ›æœºåˆ¶çš„ç«¯åˆ°ç«¯å­¦ä¹ æ¡†æž¶ï¼Œä»¥è§£å†³äººå½¢ç¤¾äº¤æœºå™¨äººé¢éƒ¨è¡¨æƒ…ç”Ÿæˆçš„è‡ªä¸»æ€§é—®é¢˜ã€‚**

**å…³é”®è¯**: `äººå½¢ç¤¾äº¤æœºå™¨äºº` `é¢éƒ¨è¡¨æƒ…ç”Ÿæˆ` `KANç½‘ç»œ` `æ³¨æ„åŠ›æœºåˆ¶` `ç«¯åˆ°ç«¯å­¦ä¹ ` `ä»¿ç”Ÿæœºå™¨äººè„¸`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šäººå½¢ç¤¾äº¤æœºå™¨äººä¾èµ–é¢„ç¼–ç¨‹è¡¨æƒ…ï¼Œæˆæœ¬é«˜ä¸”ç¼ºä¹è‡ªä¸»æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡ä»¿ç”Ÿæœºå™¨äººè„¸ï¼Œç»“åˆKANå’Œæ³¨æ„åŠ›æœºåˆ¶å®žçŽ°ç«¯åˆ°ç«¯å­¦ä¹ ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè¯„ä¼°æ˜¾ç¤ºæ–¹æ³•èƒ½å‡†ç¡®ã€å¤šæ ·åœ°æ¨¡ä»¿ä¸åŒæµ‹è¯•å¯¹è±¡çš„é¢éƒ¨è¡¨æƒ…ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The facial expression generation capability of humanoid social robots is
> critical for achieving natural and human-like interactions, playing a vital
> role in enhancing the fluidity of human-robot interactions and the accuracy of
> emotional expression. Currently, facial expression generation in humanoid
> social robots still relies on pre-programmed behavioral patterns, which are
> manually coded at high human and time costs. To enable humanoid robots to
> autonomously acquire generalized expressive capabilities, they need to develop
> the ability to learn human-like expressions through self-training. To address
> this challenge, we have designed a highly biomimetic robotic face with
> physical-electronic animated facial units and developed an end-to-end learning
> framework based on KAN (Kolmogorov-Arnold Network) and attention mechanisms.
> Unlike previous humanoid social robots, we have also meticulously designed an
> automated data collection system based on expert strategies of facial motion
> primitives to construct the dataset. Notably, to the best of our knowledge,
> this is the first open-source facial dataset for humanoid social robots.
> Comprehensive evaluations indicate that our approach achieves accurate and
> diverse facial mimicry across different test subjects.

