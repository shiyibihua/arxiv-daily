---
layout: default
title: PixelRefer: A Unified Framework for Spatio-Temporal Object Referring with Arbitrary Granularity
---

# PixelRefer: A Unified Framework for Spatio-Temporal Object Referring with Arbitrary Granularity

**arXiv**: [2510.23603v1](https://arxiv.org/abs/2510.23603) | [PDF](https://arxiv.org/pdf/2510.23603.pdf)

**ä½œè€…**: Yuqian Yuan, Wenqiao Zhang, Xin Li, Shihao Wang, Kehan Li, Wentong Li, Jun Xiao, Lei Zhang, Beng Chin Ooi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPixelReferç»Ÿä¸€æ¡†æž¶ï¼Œå®žçŽ°å›¾åƒå’Œè§†é¢‘ä¸­ä»»æ„ç²’åº¦å¯¹è±¡çš„ç»†ç²’åº¦ç†è§£**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `ç»†ç²’åº¦å¯¹è±¡ç†è§£` `åŒºåŸŸçº§è§†è§‰æŽ¨ç†` `é«˜æ•ˆè®¡ç®—æ¡†æž¶` `æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰MLLMså¤šå…³æ³¨åœºæ™¯çº§ç†è§£ï¼Œç¼ºä¹å¯¹è±¡çº§ç»†ç²’åº¦æŽ¨ç†èƒ½åŠ›
2. å¼•å…¥Scale-Adaptive Object Tokenizerç”Ÿæˆå¯¹è±¡è¡¨ç¤ºï¼Œå¹¶è®¾è®¡é«˜æ•ˆå˜ä½“PixelRefer-Lite
3. å®žéªŒéªŒè¯åœ¨å¤šä¸ªåŸºå‡†ä¸Šé¢†å…ˆæ€§èƒ½ï¼ŒPixelRefer-Liteåœ¨ä¿æŒç²¾åº¦ä¸‹æ˜¾è‘—æå‡æ•ˆçŽ‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) have demonstrated strong
> general-purpose capabilities in open-world visual comprehension. However, most
> existing MLLMs primarily focus on holistic, scene-level understanding, often
> overlooking the need for fine-grained, object-centric reasoning. In this paper,
> we present PixelRefer, a unified region-level MLLM framework that enables
> advanced fine-grained understanding over user-specified regions across both
> images and videos. Motivated by the observation that LLM attention
> predominantly focuses on object-level tokens, we propose a Scale-Adaptive
> Object Tokenizer (SAOT) to generate compact and semantically rich object
> representations from free-form regions. Our analysis reveals that global visual
> tokens contribute mainly in early LLM layers, inspiring the design of
> PixelRefer-Lite, an efficient variant that employs an Object-Centric Infusion
> module to pre-fuse global context into object tokens. This yields a lightweight
> Object-Only Framework that substantially reduces computational cost while
> maintaining high semantic fidelity. To facilitate fine-grained instruction
> tuning, we curate PixelRefer-2.2M, a high-quality object-centric instruction
> dataset. Extensive experiments across a range of benchmarks validate that
> PixelRefer achieves leading performance with fewer training samples, while
> PixelRefer-Lite offers competitive accuracy with notable gains in efficiency.

