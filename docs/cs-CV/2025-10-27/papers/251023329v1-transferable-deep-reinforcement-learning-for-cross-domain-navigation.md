---
layout: default
title: Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon
---

# Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon

**arXiv**: [2510.23329v1](https://arxiv.org/abs/2510.23329) | [PDF](https://arxiv.org/pdf/2510.23329.pdf)

**ä½œè€…**: Shreya Santra, Thomas Robbins, Kazuya Yoshida

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯è¿ç§»æ·±åº¦å¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œå®ç°ä»å†œç”°åˆ°æœˆçƒçš„è·¨åŸŸè‡ªä¸»å¯¼èˆªã€‚**

**å…³é”®è¯**: `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `è·¨åŸŸå¯¼èˆª` `ç­–ç•¥è¿ç§»` `è‡ªä¸»æœºå™¨äºº` `æ¨¡æ‹ŸéªŒè¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿå¯¼èˆªæ–¹æ³•éœ€ç¯å¢ƒç‰¹å®šè°ƒä¼˜ï¼Œéš¾ä»¥é€‚åº”æ–°é¢†åŸŸã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨PPOç®—æ³•è®­ç»ƒDRLç­–ç•¥ï¼Œåœ¨å†œç”°æ¨¡æ‹Ÿä¸­å­¦ä¹ å¯¼èˆªä¸é¿éšœã€‚
3. å®éªŒæ•ˆæœï¼šé›¶æ ·æœ¬è¿ç§»è‡³æœˆçƒæ¨¡æ‹Ÿï¼ŒæˆåŠŸç‡è¿‘50%ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autonomous navigation in unstructured environments is essential for field and
> planetary robotics, where robots must efficiently reach goals while avoiding
> obstacles under uncertain conditions. Conventional algorithmic approaches often
> require extensive environment-specific tuning, limiting scalability to new
> domains. Deep Reinforcement Learning (DRL) provides a data-driven alternative,
> allowing robots to acquire navigation strategies through direct interactions
> with their environment. This work investigates the feasibility of DRL policy
> generalization across visually and topographically distinct simulated domains,
> where policies are trained in terrestrial settings and validated in a zero-shot
> manner in extraterrestrial environments. A 3D simulation of an agricultural
> rover is developed and trained using Proximal Policy Optimization (PPO) to
> achieve goal-directed navigation and obstacle avoidance in farmland settings.
> The learned policy is then evaluated in a lunar-like simulated environment to
> assess transfer performance. The results indicate that policies trained under
> terrestrial conditions retain a high level of effectiveness, achieving close to
> 50\% success in lunar simulations without the need for additional training and
> fine-tuning. This underscores the potential of cross-domain DRL-based policy
> transfer as a promising approach to developing adaptable and efficient
> autonomous navigation for future planetary exploration missions, with the added
> benefit of minimizing retraining costs.

