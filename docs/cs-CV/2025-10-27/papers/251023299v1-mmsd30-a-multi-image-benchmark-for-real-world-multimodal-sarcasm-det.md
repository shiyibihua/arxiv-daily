---
layout: default
title: MMSD3.0: A Multi-Image Benchmark for Real-World Multimodal Sarcasm Detection
---

# MMSD3.0: A Multi-Image Benchmark for Real-World Multimodal Sarcasm Detection

**arXiv**: [2510.23299v1](https://arxiv.org/abs/2510.23299) | [PDF](https://arxiv.org/pdf/2510.23299.pdf)

**ä½œè€…**: Haochen Zhao, Yuyao Kong, Yongxiu Xu, Gaopeng Gou, Hongbo Xu, Yubin Wang, Haoliang Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMMSD3.0å¤šå›¾åƒåŸºå‡†å’ŒCIRMæ¨¡åž‹ä»¥è§£å†³çœŸå®žä¸–ç•Œå¤šæ¨¡æ€è®½åˆºæ£€æµ‹é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€è®½åˆºæ£€æµ‹` `å¤šå›¾åƒåŸºå‡†` `è·¨å›¾åƒæŽ¨ç†` `è·¨æ¨¡æ€èžåˆ` `çœŸå®žä¸–ç•Œæ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•å¤šå…³æ³¨å•å›¾åƒåœºæ™¯ï¼Œå¿½ç•¥å¤šå›¾åƒé—´çš„è¯­ä¹‰å’Œæƒ…æ„Ÿå…³ç³»ï¼Œå¯¼è‡´çœŸå®žä¸–ç•Œè®½åˆºæ£€æµ‹ä¸è¶³
2. å¼•å…¥è·¨å›¾åƒæŽ¨ç†æ¨¡åž‹CIRMï¼Œé€šè¿‡åºåˆ—å»ºæ¨¡å’Œç›¸å…³æ€§å¼•å¯¼çš„è·¨æ¨¡æ€èžåˆæ•èŽ·å›¾åƒé—´è¿žæŽ¥
3. åœ¨MMSDç³»åˆ—åŸºå‡†ä¸Šå®žéªŒï¼ŒCIRMå®žçŽ°å…ˆè¿›æ€§èƒ½ï¼ŒéªŒè¯å…¶åœ¨å•å›¾åƒå’Œå¤šå›¾åƒåœºæ™¯çš„æœ‰æ•ˆæ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite progress in multimodal sarcasm detection, existing datasets and
> methods predominantly focus on single-image scenarios, overlooking potential
> semantic and affective relations across multiple images. This leaves a gap in
> modeling cases where sarcasm is triggered by multi-image cues in real-world
> settings. To bridge this gap, we introduce MMSD3.0, a new benchmark composed
> entirely of multi-image samples curated from tweets and Amazon reviews. We
> further propose the Cross-Image Reasoning Model (CIRM), which performs targeted
> cross-image sequence modeling to capture latent inter-image connections. In
> addition, we introduce a relevance-guided, fine-grained cross-modal fusion
> mechanism based on text-image correspondence to reduce information loss during
> integration. We establish a comprehensive suite of strong and representative
> baselines and conduct extensive experiments, showing that MMSD3.0 is an
> effective and reliable benchmark that better reflects real-world conditions.
> Moreover, CIRM demonstrates state-of-the-art performance across MMSD, MMSD2.0
> and MMSD3.0, validating its effectiveness in both single-image and multi-image
> scenarios.

