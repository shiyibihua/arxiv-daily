---
layout: default
title: FAME: Fairness-aware Attention-modulated Video Editing
---

# FAME: Fairness-aware Attention-modulated Video Editing

**arXiv**: [2510.22960v1](https://arxiv.org/abs/2510.22960) | [PDF](https://arxiv.org/pdf/2510.22960.pdf)

**ä½œè€…**: Zhangkai Wu, Xuhui Fan, Zhongyuan Xie, Kaize Shi, Zhidong Li, Longbing Cao

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFAMEæ–¹æ³•ä»¥ç¼“è§£è§†é¢‘ç¼–è¾‘ä¸­çš„èŒä¸šç›¸å…³æ€§åˆ«åè§ï¼ŒåŒæ—¶ä¿æŒæç¤ºå¯¹é½å’Œæ—¶é—´ä¸€è‡´æ€§ã€‚**

**å…³é”®è¯**: `è§†é¢‘ç¼–è¾‘` `å…¬å¹³æ€§` `æ³¨æ„åŠ›æœºåˆ¶` `æ—¶é—´ä¸€è‡´æ€§` `å»åæŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ— è®­ç»ƒè§†é¢‘ç¼–è¾‘æ¨¡å‹åœ¨æ¸²æŸ“èŒä¸šç›¸å…³æç¤ºæ—¶æ˜“é™·å…¥æ€§åˆ«åˆ»æ¿å°è±¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡è½¯æ³¨å…¥å»åæ ‡è®°å’Œè°ƒåˆ¶æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¢å¼ºå…¬å¹³æ€§å¹¶å‡å°‘æ—¶é—´ä¸ä¸€è‡´ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šåœ¨FairVEåŸºå‡†ä¸Šï¼ŒFAMEåœ¨å…¬å¹³å¯¹é½å’Œè¯­ä¹‰ä¿çœŸåº¦ä¸Šä¼˜äºç°æœ‰åŸºçº¿ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Training-free video editing (VE) models tend to fall back on gender
> stereotypes when rendering profession-related prompts. We propose \textbf{FAME}
> for \textit{Fairness-aware Attention-modulated Video Editing} that mitigates
> profession-related gender biases while preserving prompt alignment and temporal
> consistency for coherent VE. We derive fairness embeddings from existing
> minority representations by softly injecting debiasing tokens into the text
> encoder. Simultaneously, FAME integrates fairness modulation into both temporal
> self attention and prompt-to-region cross attention to mitigate the motion
> corruption and temporal inconsistency caused by directly introducing fairness
> cues. For temporal self attention, FAME introduces a region constrained
> attention mask combined with time decay weighting, which enhances intra-region
> coherence while suppressing irrelevant inter-region interactions. For cross
> attention, it reweights tokens to region matching scores by incorporating
> fairness sensitive similarity masks derived from debiasing prompt embeddings.
> Together, these modulations keep fairness-sensitive semantics tied to the right
> visual regions and prevent temporal drift across frames. Extensive experiments
> on new VE fairness-oriented benchmark \textit{FairVE} demonstrate that FAME
> achieves stronger fairness alignment and semantic fidelity, surpassing existing
> VE baselines.

