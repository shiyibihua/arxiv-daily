---
layout: default
title: If They Disagree, Will You Conform? Exploring the Role of Robots' Value Awareness in a Decision-Making Task
---

# If They Disagree, Will You Conform? Exploring the Role of Robots' Value Awareness in a Decision-Making Task

**arXiv**: [2510.23204v1](https://arxiv.org/abs/2510.23204) | [PDF](https://arxiv.org/pdf/2510.23204.pdf)

**ä½œè€…**: Giulia Pusceddu, Giulio Antonio Abbo, Francesco Rea, Tony Belpaeme, Alessandra Sciutti

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æŽ¢ç´¢æœºå™¨äººä»·å€¼æ„è¯†å¯¹äººç±»å†³ç­–çš„å½±å“ï¼Œé€šè¿‡æ ‡ç­¾ä»»åŠ¡å®žéªŒæ­ç¤ºå…¶æ½œåœ¨é£Žé™©ä¸Žç›Šå¤„ã€‚**

**å…³é”®è¯**: `ç¤¾ä¼šæœºå™¨äºº` `ä»·å€¼æ„è¯†` `å†³ç­–å½±å“` `äººæœºäº¤äº’` `å®žéªŒç ”ç©¶` `ä¼¦ç†é£Žé™©`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨äººä»·å€¼æ„è¯†æ˜¯å¦å¢žå¼ºå…¶å¯¹äººç±»å†³ç­–çš„å½±å“åŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨ä»·å€¼æ„è¯†å’Œéžä»·å€¼æ„è¯†æœºå™¨äººè¿›è¡Œå›¾åƒæ ‡ç­¾ä»»åŠ¡äº¤äº’ã€‚
3. å®žéªŒæ•ˆæžœï¼šå‚ä¸Žè€…æ³¨è§†ä»·å€¼æ„è¯†æœºå™¨äººæ›´å¤šï¼Œæ„ŸçŸ¥å…¶æ›´å¿ è¯šï¼Œä¸”æœºå™¨äººåˆ†æ­§å¼•å‘çŠ¹è±«ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This study investigates whether the opinions of robotic agents are more
> likely to influence human decision-making when the robots are perceived as
> value-aware (i.e., when they display an understanding of human principles). We
> designed an experiment in which participants interacted with two Furhat robots
> - one programmed to be Value-Aware and the other Non-Value-Aware - during a
> labeling task for images representing human values. Results indicate that
> participants distinguished the Value-Aware robot from the Non-Value-Aware one.
> Although their explicit choices did not indicate a clear preference for one
> robot over the other, participants directed their gaze more toward the
> Value-Aware robot. Additionally, the Value-Aware robot was perceived as more
> loyal, suggesting that value awareness in a social robot may enhance its
> perceived commitment to the group. Finally, when both robots disagreed with the
> participant, conformity occurred in about one out of four trials, and
> participants took longer to confirm their responses, suggesting that two robots
> expressing dissent may introduce hesitation in decision-making. On one hand,
> this highlights the potential risk that robots, if misused, could manipulate
> users for unethical purposes. On the other hand, it reinforces the idea that
> social robots might encourage reflection in ambiguous situations and help users
> avoid scams.

