---
layout: default
title: Scaling Up Occupancy-centric Driving Scene Generation: Dataset and Method
---

# Scaling Up Occupancy-centric Driving Scene Generation: Dataset and Method

**arXiv**: [2510.22973v1](https://arxiv.org/abs/2510.22973) | [PDF](https://arxiv.org/pdf/2510.22973.pdf)

**ä½œè€…**: Bohan Li, Xin Jin, Hu Zhu, Hongsi Liu, Ruikai Li, Jiazhe Guo, Kaiwen Cai, Chao Ma, Yueming Jin, Hao Zhao, Xiaokang Yang, Wenjun Zeng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€æ¡†æž¶ä¸ŽNuplan-Occæ•°æ®é›†ï¼Œä»¥è§£å†³é©¾é©¶åœºæ™¯ç”Ÿæˆä¸­å ç”¨æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚**

**å…³é”®è¯**: `é©¾é©¶åœºæ™¯ç”Ÿæˆ` `è¯­ä¹‰å ç”¨` `å¤šæ¨¡æ€åˆæˆ` `LiDARæ¨¡æ‹Ÿ` `æ—¶ç©ºè§£è€¦æž¶æž„`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå ç”¨ä¸­å¿ƒæ–¹æ³•ä¾èµ–ç¨€ç¼ºçš„æ ‡æ³¨å ç”¨æ•°æ®ï¼Œé™åˆ¶é©¾é©¶åœºæ™¯ç”Ÿæˆæ€§èƒ½ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼€å‘ç»Ÿä¸€æ¡†æž¶ï¼Œè”åˆç”Ÿæˆè¯­ä¹‰å ç”¨ã€å¤šè§†è§’è§†é¢‘å’ŒLiDARç‚¹äº‘ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Nuplan-Occæ•°æ®é›†ä¸ŠéªŒè¯ï¼Œç”Ÿæˆä¿çœŸåº¦å’Œå¯æ‰©å±•æ€§ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Driving scene generation is a critical domain for autonomous driving,
> enabling downstream applications, including perception and planning evaluation.
> Occupancy-centric methods have recently achieved state-of-the-art results by
> offering consistent conditioning across frames and modalities; however, their
> performance heavily depends on annotated occupancy data, which still remains
> scarce. To overcome this limitation, we curate Nuplan-Occ, the largest semantic
> occupancy dataset to date, constructed from the widely used Nuplan benchmark.
> Its scale and diversity facilitate not only large-scale generative modeling but
> also autonomous driving downstream applications. Based on this dataset, we
> develop a unified framework that jointly synthesizes high-quality semantic
> occupancy, multi-view videos, and LiDAR point clouds. Our approach incorporates
> a spatio-temporal disentangled architecture to support high-fidelity spatial
> expansion and temporal forecasting of 4D dynamic occupancy. To bridge modal
> gaps, we further propose two novel techniques: a Gaussian splatting-based
> sparse point map rendering strategy that enhances multi-view video generation,
> and a sensor-aware embedding strategy that explicitly models LiDAR sensor
> properties for realistic multi-LiDAR simulation. Extensive experiments
> demonstrate that our method achieves superior generation fidelity and
> scalability compared to existing approaches, and validates its practical value
> in downstream tasks. Repo:
> https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation/tree/v2

