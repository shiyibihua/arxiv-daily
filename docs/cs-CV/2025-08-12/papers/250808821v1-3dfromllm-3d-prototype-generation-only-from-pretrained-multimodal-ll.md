---
layout: default
title: 3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs
---

# 3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08821" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08821v1</a>
  <a href="https://arxiv.org/pdf/2508.08821.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08821v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08821v1', '3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Noor Ahmed, Cameron Braunstein, Steffen Eger, Eddy Ilg

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡º3DFroMLLMä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç©ºé—´æ¨ç†ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `3Dç‰©ä½“ç”Ÿæˆ` `ç©ºé—´æ¨ç†` `å›¾åƒåˆ†ç±»` `ç»†ç²’åº¦è§†è§‰-è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç©ºé—´æ¨ç†èƒ½åŠ›ä¸Šå­˜åœ¨ä¸è¶³ï¼Œé™åˆ¶äº†å…¶åœ¨3Dç‰©ä½“ç”Ÿæˆä¸­çš„åº”ç”¨ã€‚
2. 3DFroMLLMæ¡†æ¶é€šè¿‡ä»é¢„è®­ç»ƒçš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç›´æ¥ç”Ÿæˆ3Dç‰©ä½“åŸå‹ï¼Œç®€åŒ–äº†ç”Ÿæˆè¿‡ç¨‹å¹¶æé«˜äº†æ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨è¯¥æ¡†æ¶ç”Ÿæˆçš„å›¾åƒåœ¨å›¾åƒåˆ†ç±»é¢„è®­ç»ƒä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå‡†ç¡®ç‡æå‡è¾¾15%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨æ–‡æœ¬å’Œå›¾åƒçš„è”åˆè¡¨ç¤ºå­¦ä¹ æ–¹é¢å±•ç°äº†å¼ºå¤§çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨ç©ºé—´æ¨ç†æ–¹é¢ä»å­˜åœ¨å±€é™æ€§ã€‚æˆ‘ä»¬æå‡ºäº†3DFroMLLMï¼Œä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿç›´æ¥ä»MLLMsç”Ÿæˆ3Dç‰©ä½“åŸå‹ï¼ŒåŒ…æ‹¬å‡ ä½•å½¢çŠ¶å’Œéƒ¨ä»¶æ ‡ç­¾ã€‚æˆ‘ä»¬çš„æµç¨‹æ˜¯è‡ªä¸»çš„ï¼ŒåŒ…å«è®¾è®¡å¸ˆã€ç¼–ç å™¨å’Œè§†è§‰æ£€æŸ¥å‘˜åœ¨ä¸€ä¸ªä¼˜åŒ–å¾ªç¯ä¸­æ“ä½œã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸éœ€è¦é¢å¤–çš„è®­ç»ƒæ•°æ®æˆ–è¯¦ç»†çš„ç”¨æˆ·æŒ‡ä»¤ã€‚åŸºäºä¹‹å‰çš„2Dç”Ÿæˆå·¥ä½œï¼Œæˆ‘ä»¬å±•ç¤ºäº†é€šè¿‡æˆ‘ä»¬çš„æ¡†æ¶ç”Ÿæˆçš„æ¸²æŸ“å›¾åƒå¯ä»¥æœ‰æ•ˆç”¨äºå›¾åƒåˆ†ç±»é¢„è®­ç»ƒä»»åŠ¡ï¼Œå¹¶æ¯”ä¹‹å‰çš„æ–¹æ³•æé«˜äº†15%ã€‚ä½œä¸ºä¸€ä¸ªå¼•äººæ³¨ç›®çš„å®é™…åº”ç”¨æ¡ˆä¾‹ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ç”Ÿæˆçš„åŸå‹å¯ä»¥ç”¨äºæ”¹å–„ç»†ç²’åº¦è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡ä½¿ç”¨æ¸²æŸ“çš„éƒ¨ä»¶æ ‡è®°åŸå‹æ¥å¾®è°ƒCLIPè¿›è¡Œéƒ¨ä»¶åˆ†å‰²ï¼Œå‡†ç¡®ç‡æé«˜äº†55%ï¼Œè€Œæ— éœ€ä¾èµ–ä»»ä½•é¢å¤–çš„äººç±»æ ‡æ³¨æ•°æ®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç©ºé—´æ¨ç†æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆ3Dç‰©ä½“åŸå‹æ—¶çš„å±€é™æ€§ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè¯¦ç»†çš„ç”¨æˆ·æŒ‡ä»¤ï¼Œå¯¼è‡´ç”Ÿæˆè¿‡ç¨‹å¤æ‚ä¸”æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼š3DFroMLLMçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œç›´æ¥ç”ŸæˆåŒ…å«å‡ ä½•å½¢çŠ¶å’Œéƒ¨ä»¶æ ‡ç­¾çš„3Dç‰©ä½“åŸå‹ã€‚é€šè¿‡è®¾è®¡ä¸€ä¸ªè‡ªä¸»çš„ç”Ÿæˆæµç¨‹ï¼Œå‡å°‘å¯¹é¢å¤–æ•°æ®å’Œç”¨æˆ·è¾“å…¥çš„ä¾èµ–ï¼Œä»è€Œæé«˜ç”Ÿæˆæ•ˆç‡å’Œçµæ´»æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè®¾è®¡å¸ˆã€ç¼–ç å™¨å’Œè§†è§‰æ£€æŸ¥å‘˜ã€‚è®¾è®¡å¸ˆè´Ÿè´£ç”Ÿæˆåˆæ­¥çš„3DåŸå‹ï¼Œç¼–ç å™¨å°†å…¶è½¬åŒ–ä¸ºå¯æ“ä½œçš„æ ¼å¼ï¼Œè§†è§‰æ£€æŸ¥å‘˜åˆ™åœ¨ä¼˜åŒ–å¾ªç¯ä¸­å¯¹ç”Ÿæˆç»“æœè¿›è¡Œè¯„ä¼°å’Œæ”¹è¿›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºå®ç°äº†ä»å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åˆ°3Dç‰©ä½“åŸå‹çš„ç›´æ¥ç”Ÿæˆï¼Œçªç ´äº†ä¼ ç»Ÿæ–¹æ³•å¯¹è®­ç»ƒæ•°æ®å’Œç”¨æˆ·æŒ‡ä»¤çš„ä¾èµ–ï¼Œæ˜¾è‘—æé«˜äº†ç”Ÿæˆæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œæ¡†æ¶è®¾è®¡äº†é«˜æ•ˆçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç”Ÿæˆè´¨é‡ï¼Œå¹¶é‡‡ç”¨äº†é€‚åˆ3Dæ•°æ®çš„ç½‘ç»œç»“æ„ï¼Œç¡®ä¿ç”Ÿæˆçš„åŸå‹åœ¨å‡ ä½•å’Œè¯­ä¹‰ä¸Šéƒ½å…·å¤‡é«˜è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œ3DFroMLLMç”Ÿæˆçš„å›¾åƒåœ¨å›¾åƒåˆ†ç±»é¢„è®­ç»ƒä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå‡†ç¡®ç‡æå‡è¾¾15%ã€‚æ­¤å¤–ï¼Œé€šè¿‡ä½¿ç”¨æ¸²æŸ“çš„éƒ¨ä»¶æ ‡è®°åŸå‹å¾®è°ƒCLIPè¿›è¡Œéƒ¨ä»¶åˆ†å‰²ï¼Œå‡†ç¡®ç‡æé«˜äº†55%ï¼Œä¸”æ— éœ€ä¾èµ–é¢å¤–çš„äººç±»æ ‡æ³¨æ•°æ®ï¼Œå±•ç°äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘å’Œå·¥ä¸šè®¾è®¡ç­‰ã€‚é€šè¿‡ç”Ÿæˆé«˜è´¨é‡çš„3Dç‰©ä½“åŸå‹ï¼Œèƒ½å¤Ÿå¤§å¹…åº¦æé«˜è®¾è®¡æ•ˆç‡å’Œåˆ›ä½œçµæ´»æ€§ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥å’Œåˆ›æ–°ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶è¿˜å¯èƒ½æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œè¿›ä¸€æ­¥æå‡AIåœ¨åˆ›æ„é¢†åŸŸçš„åº”ç”¨ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent Multi-Modal Large Language Models (MLLMs) have demonstrated strong capabilities in learning joint representations from text and images. However, their spatial reasoning remains limited. We introduce 3DFroMLLM, a novel framework that enables the generation of 3D object prototypes directly from MLLMs, including geometry and part labels. Our pipeline is agentic, comprising a designer, coder, and visual inspector operating in a refinement loop. Notably, our approach requires no additional training data or detailed user instructions. Building on prior work in 2D generation, we demonstrate that rendered images produced by our framework can be effectively used for image classification pretraining tasks and outperforms previous methods by 15%. As a compelling real-world use case, we show that the generated prototypes can be leveraged to improve fine-grained vision-language models by using the rendered, part-labeled prototypes to fine-tune CLIP for part segmentation and achieving a 55% accuracy improvement without relying on any additional human-labeled data.

