---
layout: default
title: Addressing Bias in VLMs for Glaucoma Detection Without Protected Attribute Supervision
---

# Addressing Bias in VLMs for Glaucoma Detection Without Protected Attribute Supervision

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09087" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09087v1</a>
  <a href="https://arxiv.org/pdf/2508.09087.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09087v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09087v1', 'Addressing Bias in VLMs for Glaucoma Detection Without Protected Attribute Supervision')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ahsan Habib Akash, Greg Murray, Annahita Amireskandari, Joel Palko, Carol Laxson, Binod Bhattarai, Prashnna Gyawali

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

**å¤‡æ³¨**: 3rd Workshop in Data Engineering in Medical Imaging (DEMI), MICCAI-2025 Workshop

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ— ç›‘ç£å±æ€§å»åè§æ–¹æ³•ä»¥æ”¹å–„é’å…‰çœ¼æ£€æµ‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é’å…‰çœ¼æ£€æµ‹` `è§†è§‰è¯­è¨€æ¨¡å‹` `å»åè§` `æ— ç›‘ç£å­¦ä¹ ` `å¤šæ¨¡æ€å­¦ä¹ ` `åŒ»ç–—å½±åƒåˆ†æ` `å…¬å¹³æ€§è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨é’å…‰çœ¼æ£€æµ‹ä¸­å­˜åœ¨äººå£ç»Ÿè®¡åè§ï¼Œå°¤å…¶æ˜¯åœ¨ç¼ºä¹ä¿æŠ¤å±æ€§ç›‘ç£çš„æƒ…å†µä¸‹ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„å»åè§æ–¹æ³•ï¼Œé€šè¿‡èšç±»æ¨æ–­å­ç¾¤ä½“å¹¶è®¡ç®—æ¢¯åº¦ç›¸ä¼¼æ€§æƒé‡æ¥æ”¹å–„æ¨¡å‹æ€§èƒ½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªå…¬å¹³æ€§æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—å‡å°‘äº†ä¸åŒå­ç¾¤ä½“é—´çš„æ€§èƒ½å·®å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†åœ¨ç¼ºä¹æ˜ç¡®ä¿æŠ¤å±æ€§çš„è®­ç»ƒä¸‹ï¼Œä»å¯èƒ½è¡¨ç°å‡ºäººå£ç»Ÿè®¡åè§ã€‚æœ¬æ–‡èšç„¦äºè‡ªåŠ¨é’å…‰çœ¼ç­›æŸ¥ï¼Œæå‡ºäº†ä¸€ç§åŸºäºé‡åŠ æƒçš„å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œé‡‡ç”¨æ— ç›‘ç£èšç±»æ¨æ–­ä»£ç†å­ç¾¤ä½“ï¼Œå¹¶è®¡ç®—CLIPé£æ ¼å¤šæ¨¡æ€æŸå¤±ä¸SimCLRé£æ ¼å›¾åƒå¯¹æ¯”æŸå¤±ä¹‹é—´çš„æ¢¯åº¦ç›¸ä¼¼æ€§æƒé‡ã€‚é€šè¿‡åœ¨è”åˆçš„åŠ æƒç›®æ ‡ä¸­åº”ç”¨è¿™äº›æƒé‡ï¼Œæœ¬æ–‡çš„æ–¹æ³•èƒ½å¤Ÿè‡ªé€‚åº”åœ°é’ˆå¯¹è¡¨ç°ä¸ä½³çš„å­ç¾¤ä½“ï¼Œä»è€Œå‡å°‘ç¾¤ä½“é—´çš„å·®å¼‚ã€‚æˆ‘ä»¬åœ¨å“ˆä½›FairVLMedé’å…‰çœ¼å­é›†ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ï¼ŒæŠ¥å‘Šäº†å‡è¡¡å‡ ç‡è·ç¦»ï¼ˆEODï¼‰ã€å‡è¡¡å­ç¾¤ä½“AUCï¼ˆES AUCï¼‰å’Œç¾¤ä½“AUCï¼Œä»¥å±•ç¤ºåœ¨æ¨æ–­çš„äººå£å­ç¾¤ä½“é—´çš„å…¬å¹³æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹åœ¨é’å…‰çœ¼æ£€æµ‹ä¸­å­˜åœ¨çš„äººå£ç»Ÿè®¡åè§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç¼ºä¹ä¿æŠ¤å±æ€§ç›‘ç£çš„æƒ…å†µä¸‹ï¼Œå®¹æ˜“å¯¼è‡´æ¨¡å‹å¯¹æŸäº›ç¾¤ä½“çš„è¡¨ç°ä¸ä½³ï¼Œä»è€Œå½±å“å…¬å¹³æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„å»åè§æ–¹æ³•ï¼Œåˆ©ç”¨å›¾åƒåµŒå…¥çš„æ— ç›‘ç£èšç±»æ¨æ–­ä»£ç†å­ç¾¤ä½“ï¼Œå¹¶é€šè¿‡è®¡ç®—æ¢¯åº¦ç›¸ä¼¼æ€§æƒé‡æ¥å¢å¼ºæ¨¡å‹å¯¹è¡¨ç°ä¸ä½³å­ç¾¤ä½“çš„å…³æ³¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œé€šè¿‡æ— ç›‘ç£èšç±»æ¨æ–­å›¾åƒåµŒå…¥çš„å­ç¾¤ä½“ï¼›å…¶æ¬¡ï¼Œè®¡ç®—CLIPé£æ ¼å¤šæ¨¡æ€æŸå¤±ä¸SimCLRé£æ ¼å›¾åƒå¯¹æ¯”æŸå¤±ä¹‹é—´çš„æ¢¯åº¦ç›¸ä¼¼æ€§æƒé‡ï¼›æœ€åï¼Œå°†è¿™äº›æƒé‡åº”ç”¨äºåŠ æƒç›®æ ‡ï¼Œä»¥æå‡è¡¨ç°ä¸ä½³çš„å­ç¾¤ä½“çš„æƒé‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„å»åè§æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®æ ‡ç­¾çš„æƒ…å†µä¸‹ï¼Œè‡ªåŠ¨è¯†åˆ«å¹¶è°ƒæ•´æ¨¡å‹å¯¹ä¸åŒå­ç¾¤ä½“çš„å…³æ³¨ç¨‹åº¦ï¼Œä»è€Œæ”¹å–„å…¬å¹³æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡‡ç”¨äº†åŠ æƒçš„å¤šæ¨¡æ€æŸå¤±å’Œå¯¹æ¯”æŸå¤±ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿè‡ªé€‚åº”åœ°å…³æ³¨è¡¨ç°ä¸ä½³çš„å­ç¾¤ä½“ã€‚æ­¤å¤–ï¼Œèšç±»ç®—æ³•çš„é€‰æ‹©å’Œå‚æ•°è®¾ç½®ä¹Ÿå¯¹æœ€ç»ˆæ•ˆæœæœ‰é‡è¦å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å“ˆä½›FairVLMedé’å…‰çœ¼å­é›†ä¸Šæ˜¾è‘—æå‡äº†æ¨¡å‹çš„å…¬å¹³æ€§æŒ‡æ ‡ï¼ŒåŒ…æ‹¬å‡è¡¡å‡ ç‡è·ç¦»ï¼ˆEODï¼‰å’Œå‡è¡¡å­ç¾¤ä½“AUCï¼ˆES AUCï¼‰ï¼Œæœ‰æ•ˆå‡å°‘äº†ä¸åŒå­ç¾¤ä½“é—´çš„æ€§èƒ½å·®å¼‚ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨åŒ»ç–—å½±åƒåˆ†æé¢†åŸŸå…·æœ‰é‡è¦åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨é’å…‰çœ¼ç­‰çœ¼ç§‘ç–¾ç—…çš„è‡ªåŠ¨ç­›æŸ¥ä¸­ã€‚é€šè¿‡å‡å°‘æ¨¡å‹çš„åè§ï¼Œèƒ½å¤Ÿæé«˜å¯¹ä¸åŒäººç¾¤çš„è¯Šæ–­å‡†ç¡®æ€§ï¼Œè¿›è€Œæ”¹å–„åŒ»ç–—æœåŠ¡çš„å…¬å¹³æ€§å’Œå¯åŠæ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯æ‰©å±•åˆ°å…¶ä»–ç–¾ç—…çš„æ£€æµ‹å’Œç­›æŸ¥ä¸­ï¼Œæ¨åŠ¨æ™ºèƒ½åŒ»ç–—çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language Models (VLMs) have achieved remarkable success on multimodal tasks such as image-text retrieval and zero-shot classification, yet they can exhibit demographic biases even when explicit protected attributes are absent during training. In this work, we focus on automated glaucoma screening from retinal fundus images, a critical application given that glaucoma is a leading cause of irreversible blindness and disproportionately affects underserved populations. Building on a reweighting-based contrastive learning framework, we introduce an attribute-agnostic debiasing method that (i) infers proxy subgroups via unsupervised clustering of image-image embeddings, (ii) computes gradient-similarity weights between the CLIP-style multimodal loss and a SimCLR-style image-pair contrastive loss, and (iii) applies these weights in a joint, top-$k$ weighted objective to upweight underperforming clusters. This label-free approach adaptively targets the hardest examples, thereby reducing subgroup disparities. We evaluate our method on the Harvard FairVLMed glaucoma subset, reporting Equalized Odds Distance (EOD), Equalized Subgroup AUC (ES AUC), and Groupwise AUC to demonstrate equitable performance across inferred demographic subgroups.

