---
layout: default
title: A new dataset and comparison for multi-camera frame synthesis
---

# A new dataset and comparison for multi-camera frame synthesis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09068" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09068v2</a>
  <a href="https://arxiv.org/pdf/2508.09068.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09068v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09068v2', 'A new dataset and comparison for multi-camera frame synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Conall Daly, Anil Kokaram

**åˆ†ç±»**: eess.IV, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12 (æ›´æ–°: 2025-09-18)

**å¤‡æ³¨**: SPIE 2025 - Applications of Digital Image Processing XLVIII accepted manuscript, 13 pages

**DOI**: [10.1117/12.3065025](https://doi.org/10.1117/12.3065025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ‘„åƒå¤´æ•°æ®é›†ä»¥è§£å†³å¸§åˆæˆæ–¹æ³•æ¯”è¾ƒé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¸§åˆæˆ` `å¤šæ‘„åƒå¤´` `æ•°æ®é›†` `è§†å›¾åˆæˆ` `æ·±åº¦å­¦ä¹ ` `å›¾åƒå¤„ç†` `æ€§èƒ½è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¸§åˆæˆæ–¹æ³•åœ¨æ¯”è¾ƒå¸§æ’å€¼å’Œè§†å›¾åˆæˆæ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯æ•°æ®é›†çš„åå·®é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„å¤šæ‘„åƒå¤´æ•°æ®é›†ï¼Œæ—¨åœ¨é€šè¿‡å…¬å¹³çš„å®éªŒè®¾è®¡æ¥æ¯”è¾ƒä¸åŒçš„å¸§åˆæˆæ–¹æ³•ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨çœŸå®å›¾åƒæ•°æ®ä¸Šï¼Œç»å…¸æ–¹æ³•ä¸æ·±åº¦å­¦ä¹ æ–¹æ³•çš„æ€§èƒ½ç›¸è¿‘ï¼Œè€Œåœ¨åˆæˆåœºæ™¯ä¸­ï¼Œ3Dé«˜æ–¯ç‚¹äº‘æ–¹æ³•è¡¨ç°æ›´ä½³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„å¸§åˆæˆæ–¹æ³•å¯åˆ†ä¸ºå¸§æ’å€¼å’Œè§†å›¾åˆæˆæŠ€æœ¯ï¼Œä½†å¤§å¤šæ•°å¸§æ’å€¼æ•°æ®é›†ä¾§é‡äºå•æ‘„åƒå¤´çš„æ—¶é—´åºåˆ—ï¼Œè€Œè§†å›¾åˆæˆæ•°æ®é›†åˆ™åå‘äºç«‹ä½“æ·±åº¦ä¼°è®¡ã€‚è¿™ä½¿å¾—ä¸¤è€…ä¹‹é—´çš„ç›´æ¥æ¯”è¾ƒå˜å¾—å›°éš¾ã€‚æœ¬æ–‡å¼€å‘äº†ä¸€ç§æ–°å‹å¤šæ‘„åƒå¤´æ•°æ®é›†ï¼Œåˆ©ç”¨å®šåˆ¶çš„å¯†é›†çº¿æ€§æ‘„åƒå¤´é˜µåˆ—ï¼Œæ—¨åœ¨å®ç°å…¬å¹³æ¯”è¾ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨çœŸå®å›¾åƒæ•°æ®ä¸Šå¹¶æœªæ˜¾è‘—ä¼˜äºç»å…¸æ–¹æ³•ï¼Œè€Œåœ¨åˆæˆåœºæ™¯ä¸­ï¼Œ3Dé«˜æ–¯ç‚¹äº‘æ–¹æ³•çš„è¡¨ç°åˆ™ä¼˜äºå¸§æ’å€¼ç®—æ³•ï¼Œæå‡å¹…åº¦è¾¾åˆ°è¿‘5 dB PSNRã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¸§æ’å€¼ä¸è§†å›¾åˆæˆæ–¹æ³•ä¹‹é—´çš„æ¯”è¾ƒé—®é¢˜ï¼Œç°æœ‰æ•°æ®é›†çš„åå·®ä½¿å¾—ç›´æ¥æ¯”è¾ƒå˜å¾—å›°éš¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼€å‘ä¸€ä¸ªæ–°å‹çš„å¤šæ‘„åƒå¤´æ•°æ®é›†ï¼Œåˆ©ç”¨å®šåˆ¶çš„å¯†é›†çº¿æ€§æ‘„åƒå¤´é˜µåˆ—ï¼Œæä¾›å…¬å¹³çš„å®éªŒåŸºç¡€ï¼Œä»¥ä¾¿å¯¹æ¯”ä¸åŒçš„å¸§åˆæˆæŠ€æœ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†çš„æ„å»ºã€ç»å…¸ä¸æ·±åº¦å­¦ä¹ å¸§æ’å€¼ç®—æ³•çš„è¯„ä¼°ï¼Œä»¥åŠä¸è§†å›¾åˆæˆæ–¹æ³•ï¼ˆ3Dé«˜æ–¯ç‚¹äº‘ï¼‰çš„æ¯”è¾ƒã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é‡‡é›†ã€æ¨¡å‹è®­ç»ƒå’Œæ€§èƒ½è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªå¤šæ‘„åƒå¤´æ•°æ®é›†ï¼Œèƒ½å¤ŸåŒæ—¶æ”¯æŒå¸§æ’å€¼å’Œè§†å›¾åˆæˆçš„æ¯”è¾ƒï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§ç»å…¸å’Œæ·±åº¦å­¦ä¹ çš„å¸§æ’å€¼ç®—æ³•ï¼Œå¹¶ä½¿ç”¨3Dé«˜æ–¯ç‚¹äº‘ä½œä¸ºè§†å›¾åˆæˆåŸºçº¿ï¼Œè¯„ä¼°æŒ‡æ ‡ä¸ºPSNRï¼Œç¡®ä¿äº†å®éªŒçš„ä¸¥è°¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨çœŸå®å›¾åƒæ•°æ®ä¸Šï¼Œæ·±åº¦å­¦ä¹ æ–¹æ³•çš„æ€§èƒ½ä¸ç»å…¸æ–¹æ³•ç›¸å½“ï¼Œ3Dé«˜æ–¯ç‚¹äº‘æ–¹æ³•åœ¨åˆæˆåœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæå‡å¹…åº¦è¾¾åˆ°è¿‘5 dB PSNRï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨ç‰¹å®šæ¡ä»¶ä¸‹çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è§†é¢‘å¤„ç†ã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿä¸ºå¤šè§†è§’å›¾åƒåˆæˆæä¾›æ›´ä¸ºå‡†ç¡®å’Œé«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚æœªæ¥ï¼Œè¯¥æ•°æ®é›†å’Œæ¯”è¾ƒæ–¹æ³•å¯èƒ½æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶è¿›å±•ï¼Œä¿ƒè¿›æ–°ç®—æ³•çš„å¼€å‘ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Many methods exist for frame synthesis in image sequences but can be broadly categorised into frame interpolation and view synthesis techniques. Fundamentally, both frame interpolation and view synthesis tackle the same task, interpolating a frame given surrounding frames in time or space. However, most frame interpolation datasets focus on temporal aspects with single cameras moving through time and space, while view synthesis datasets are typically biased toward stereoscopic depth estimation use cases. This makes direct comparison between view synthesis and frame interpolation methods challenging. In this paper, we develop a novel multi-camera dataset using a custom-built dense linear camera array to enable fair comparison between these approaches. We evaluate classical and deep learning frame interpolators against a view synthesis method (3D Gaussian Splatting) for the task of view in-betweening. Our results reveal that deep learning methods do not significantly outperform classical methods on real image data, with 3D Gaussian Splatting actually underperforming frame interpolators by as much as 3.5 dB PSNR. However, in synthetic scenes, the situation reverses -- 3D Gaussian Splatting outperforms frame interpolation algorithms by almost 5 dB PSNR at a 95% confidence level.

