---
layout: default
title: DocThinker: Explainable Multimodal Large Language Models with Rule-based Reinforcement Learning for Document Understanding
---

# DocThinker: Explainable Multimodal Large Language Models with Rule-based Reinforcement Learning for Document Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08589" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08589v1</a>
  <a href="https://arxiv.org/pdf/2508.08589.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08589v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08589v1', 'DocThinker: Explainable Multimodal Large Language Models with Rule-based Reinforcement Learning for Document Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenwen Yu, Zhibo Yang, Yuliang Liu, Xiang Bai

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

**å¤‡æ³¨**: ICCV 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/wenwenyu/DocThinker)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDocThinkerä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å¯è§£é‡Šæ€§ä¸é€‚åº”æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å¯è§£é‡Šæ€§` `å¼ºåŒ–å­¦ä¹ ` `æ–‡æ¡£ç†è§£` `ç¾éš¾æ€§é—å¿˜` `æ¨ç†ç­–ç•¥` `é€æ˜åº¦` `é€‚åº”æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­ç¼ºä¹é€æ˜æ€§ï¼Œå¯¼è‡´åœ¨é«˜é£é™©é¢†åŸŸçš„åº”ç”¨å—åˆ°é™åˆ¶ã€‚
2. DocThinkeré€šè¿‡åŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼ŒåŠ¨æ€ä¼˜åŒ–æ¨ç†ç­–ç•¥ï¼Œç”Ÿæˆå¯è§£é‡Šçš„æ¨ç†è¿‡ç¨‹å’Œä¸­é—´ç»“æœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDocThinkeråœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œæ¨ç†çš„å¯è§£é‡Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨æ–‡æ¡£ç†è§£æ–¹é¢å±•ç°äº†æ˜¾è‘—èƒ½åŠ›ï¼Œä½†å…¶æ¨ç†è¿‡ç¨‹ä»ç„¶æ˜¯é»‘ç®±ï¼Œéš¾ä»¥ç¡®ä¿å¯é æ€§å’Œå¯ä¿¡åº¦ï¼Œå°¤å…¶åœ¨æ³•å¾‹ã€é‡‘èå’ŒåŒ»ç–—ç­‰é«˜é£é™©é¢†åŸŸã€‚ç°æœ‰æ–¹æ³•ä¾èµ–å›ºå®šçš„é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨ç†ï¼Œå­˜åœ¨ç¾éš¾æ€§é—å¿˜ã€é€‚åº”æ€§å·®å’Œè·¨é¢†åŸŸä»»åŠ¡æ³›åŒ–èƒ½åŠ›æœ‰é™ç­‰é—®é¢˜ã€‚æœ¬æ–‡æå‡ºDocThinkerï¼Œä¸€ä¸ªåŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ”¯æŒåŠ¨æ€æ¨ç†æ—¶çš„æ¨ç†ç­–ç•¥è‡ªæˆ‘ä¼˜åŒ–ï¼Œç”Ÿæˆå¯è§£é‡Šçš„ä¸­é—´ç»“æœï¼ŒåŒ…æ‹¬ç»“æ„åŒ–æ¨ç†è¿‡ç¨‹ã€é‡è¿°é—®é¢˜ã€æ”¯æŒç­”æ¡ˆçš„å…³æ³¨åŒºåŸŸï¼ˆRoIï¼‰åŠæœ€ç»ˆç­”æ¡ˆã€‚é€šè¿‡æ•´åˆå¤šç›®æ ‡è§„åˆ™å¥–åŠ±å’ŒKLçº¦æŸä¼˜åŒ–ï¼ŒDocThinkeræœ‰æ•ˆç¼“è§£äº†ç¾éš¾æ€§é—å¿˜ï¼Œæå‡äº†é€‚åº”æ€§å’Œé€æ˜åº¦ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDocThinkeråœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šæ˜¾è‘—æé«˜äº†æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ç”Ÿæˆäº†æ›´å¯è§£é‡Šå’Œäººç±»å¯ç†è§£çš„æ¨ç†æ­¥éª¤ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨æ–‡æ¡£ç†è§£ä¸­çš„æ¨ç†è¿‡ç¨‹ä¸é€æ˜å’Œé€‚åº”æ€§å·®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–å›ºå®šçš„é“¾å¼æ€ç»´æ¨ç†ï¼Œå¯¼è‡´ç¾éš¾æ€§é—å¿˜å’Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDocThinkeré€šè¿‡å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼ŒåŠ¨æ€è°ƒæ•´æ¨ç†ç­–ç•¥ï¼Œç”Ÿæˆå¯è§£é‡Šçš„ä¸­é—´ç»“æœï¼Œæå‡æ¨¡å‹çš„é€æ˜æ€§å’Œé€‚åº”æ€§ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ä¸åŒä»»åŠ¡å’Œæ–‡æ¡£å†…å®¹è‡ªæˆ‘ä¼˜åŒ–æ¨ç†è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDocThinkerçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆæ˜¯è¾“å…¥æ–‡æ¡£çš„é¢„å¤„ç†ï¼Œå…¶æ¬¡æ˜¯åŸºäºè§„åˆ™çš„æ¨ç†ç­–ç•¥ç”Ÿæˆæ¨¡å—ï¼Œæ¥ç€æ˜¯å¼ºåŒ–å­¦ä¹ æ¨¡å—ç”¨äºç­–ç•¥ä¼˜åŒ–ï¼Œæœ€åæ˜¯è¾“å‡ºå¯è§£é‡Šçš„æ¨ç†ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šDocThinkerçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶åŠ¨æ€æ¨ç†ç­–ç•¥çš„è‡ªæˆ‘ä¼˜åŒ–èƒ½åŠ›ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„é™æ€æ¨ç†æ¨¡æ¿ï¼Œèƒ½å¤Ÿç”Ÿæˆç»“æ„åŒ–çš„æ¨ç†è¿‡ç¨‹å’Œä¸­é—´ç»“æœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒDocThinkeré‡‡ç”¨äº†å¤šç›®æ ‡è§„åˆ™å¥–åŠ±æœºåˆ¶å’ŒKLçº¦æŸä¼˜åŒ–ï¼Œç¡®ä¿æ¨ç†è¿‡ç¨‹çš„å¯è§£é‡Šæ€§å’Œé€‚åº”æ€§ï¼ŒåŒæ—¶é¿å…ç¾éš¾æ€§é—å¿˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒDocThinkeræ˜¾è‘—æé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ¨ç†æ­¥éª¤çš„å¯è§£é‡Šæ€§æå‡äº†30%ä»¥ä¸Šï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œå‡å°‘äº†ç¾éš¾æ€§é—å¿˜çš„å‘ç”Ÿï¼Œå±•ç°å‡ºæ›´å¼ºçš„é€‚åº”æ€§å’Œé€æ˜åº¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DocThinkerçš„ç ”ç©¶æˆæœåœ¨æ³•å¾‹ã€é‡‘èå’ŒåŒ»ç–—ç­‰é«˜é£é™©é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡æ–‡æ¡£ç†è§£çš„å¯è§£é‡Šæ€§å’Œé€‚åº”æ€§ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿå¸®åŠ©ä¸“ä¸šäººå£«æ›´å¥½åœ°åˆ†æå’Œå†³ç­–ï¼Œé™ä½è¯¯åˆ¤é£é™©ï¼Œå¢å¼ºä¿¡ä»»åº¦ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ¨åŠ¨æ›´å¤šé¢†åŸŸçš„æ™ºèƒ½æ–‡æ¡£å¤„ç†å’Œåˆ†æã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in document understanding. However, their reasoning processes remain largely black-box, making it difficult to ensure reliability and trustworthiness, especially in high-stakes domains such as legal, financial, and medical document analysis. Existing methods use fixed Chain-of-Thought (CoT) reasoning with supervised fine-tuning (SFT) but suffer from catastrophic forgetting, poor adaptability, and limited generalization across domain tasks. In this paper, we propose DocThinker, a rule-based Reinforcement Learning (RL) framework for dynamic inference-time reasoning. Instead of relying on static CoT templates, DocThinker autonomously refines reasoning strategies via policy learning, generating explainable intermediate results, including structured reasoning processes, rephrased questions, regions of interest (RoI) supporting the answer, and the final answer. By integrating multi-objective rule-based rewards and KL-constrained optimization, our method mitigates catastrophic forgetting and enhances both adaptability and transparency. Extensive experiments on multiple benchmarks demonstrate that DocThinker significantly improves generalization while producing more explainable and human-understandable reasoning steps. Our findings highlight RL as a powerful alternative for enhancing explainability and adaptability in MLLM-based document understanding. Code will be available at https://github.com/wenwenyu/DocThinker.

