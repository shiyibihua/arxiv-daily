---
layout: default
title: X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents
---

# X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09383" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09383v1</a>
  <a href="https://arxiv.org/pdf/2508.09383.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09383v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09383v1', 'X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Guoxian Song, Hongyi Xu, Xiaochen Zhao, You Xie, Tianpei Gu, Zenan Li, Chenxu Zhang, Linjie Luo

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºX-UniMotionä»¥å®ç°é«˜ä¿çœŸã€èº«ä»½æ— å…³çš„äººä½“åŠ¨ç”»**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `äººä½“åŠ¨ç”»` `è¿åŠ¨è½¬ç§»` `éšå¼æ½œåœ¨è¡¨ç¤º` `è‡ªç›‘ç£å­¦ä¹ ` `è™šæ‹Ÿç°å®` `å¢å¼ºç°å®` `å¤šæ¨¡æ€ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¿åŠ¨è½¬ç§»æ–¹æ³•ä¾èµ–æ˜¾å¼éª¨éª¼å§¿åŠ¿ï¼Œç¼ºä¹å¯¹å¤šæ ·åŒ–èº«ä»½å’Œå§¿åŠ¿çš„æœ‰æ•ˆå¤„ç†ã€‚
2. X-UniMotioné€šè¿‡ä»å•å¼ å›¾åƒä¸­æå–è§£è€¦çš„æ½œåœ¨æ ‡è®°ï¼Œæä¾›äº†ä¸€ç§æ–°çš„è¿åŠ¨è¡¨ç¤ºæ–¹å¼ï¼Œå…·æœ‰èº«ä»½æ— å…³æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒX-UniMotionåœ¨è¿åŠ¨è¡¨ç°åŠ›å’Œèº«ä»½ä¿ç•™æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæå‡å¹…åº¦æ˜æ˜¾ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†X-UniMotionï¼Œä¸€ç§ç»Ÿä¸€ä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„éšå¼æ½œåœ¨è¡¨ç¤ºï¼Œç”¨äºæ•´ä¸ªäººä½“è¿åŠ¨çš„åŠ¨ç”»ï¼ŒåŒ…æ‹¬é¢éƒ¨è¡¨æƒ…ã€èº«ä½“å§¿åŠ¿å’Œæ‰‹åŠ¿ã€‚ä¸ä¾èµ–æ˜¾å¼éª¨éª¼å§¿åŠ¿å’Œå¯å‘å¼è·¨èº«ä»½è°ƒæ•´çš„ä¼ ç»Ÿè¿åŠ¨è½¬ç§»æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç›´æ¥ä»å•å¼ å›¾åƒä¸­ç¼–ç å¤šç²’åº¦è¿åŠ¨ï¼Œç”Ÿæˆå››ä¸ªè§£è€¦çš„æ½œåœ¨æ ‡è®°ï¼Œåˆ†åˆ«å¯¹åº”é¢éƒ¨è¡¨æƒ…ã€èº«ä½“å§¿åŠ¿å’Œæ¯åªæ‰‹ã€‚è¿™äº›è¿åŠ¨æ½œåœ¨æ ‡è®°å…·æœ‰é«˜åº¦è¡¨ç°åŠ›å’Œèº«ä»½æ— å…³æ€§ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒèº«ä»½ã€å§¿åŠ¿å’Œç©ºé—´é…ç½®çš„ä¸»ä½“ä¹‹é—´å®ç°é«˜ä¿çœŸã€è¯¦ç»†çš„è·¨èº«ä»½è¿åŠ¨è½¬ç§»ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªç›‘ç£çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œè”åˆå­¦ä¹ è¿åŠ¨ç¼–ç å™¨å’Œæ½œåœ¨è¡¨ç¤ºï¼Œå¹¶ä¸åŸºäºDiTçš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ä¸€èµ·è®­ç»ƒï¼Œä½¿ç”¨å¤§è§„æ¨¡å¤šæ ·çš„äººä½“è¿åŠ¨æ•°æ®é›†ã€‚é€šè¿‡2Dç©ºé—´å’Œé¢œè‰²å¢å¼ºä»¥åŠå…±äº«å§¿åŠ¿ä¸‹çš„è·¨èº«ä»½ä¸»ä½“å¯¹çš„åˆæˆ3Dæ¸²æŸ“ï¼Œå¼ºåˆ¶æ‰§è¡Œè¿åŠ¨ä¸èº«ä»½çš„è§£è€¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡è¾…åŠ©è§£ç å™¨å¼•å¯¼è¿åŠ¨æ ‡è®°å­¦ä¹ ï¼Œä»¥ä¿ƒè¿›ç»†ç²’åº¦ã€è¯­ä¹‰å¯¹é½å’Œæ·±åº¦æ„ŸçŸ¥çš„è¿åŠ¨åµŒå…¥ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒX-UniMotionåœ¨è¡¨ç°åŠ›å’Œè¿åŠ¨ä¿çœŸåº¦æ–¹é¢è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¿åŠ¨è½¬ç§»æ–¹æ³•åœ¨å¤„ç†å¤šæ ·åŒ–èº«ä»½å’Œå§¿åŠ¿æ—¶çš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯ä¾èµ–æ˜¾å¼éª¨éª¼å§¿åŠ¿çš„ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„éšå¼æ½œåœ¨è¡¨ç¤ºï¼Œèƒ½å¤Ÿä»å•å¼ å›¾åƒä¸­ç›´æ¥æå–å¤šç²’åº¦è¿åŠ¨ä¿¡æ¯ï¼Œç”Ÿæˆè§£è€¦çš„æ½œåœ¨æ ‡è®°ï¼Œä»¥å®ç°é«˜ä¿çœŸã€èº«ä»½æ— å…³çš„åŠ¨ç”»æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è¿åŠ¨ç¼–ç å™¨ã€æ½œåœ¨è¡¨ç¤ºå­¦ä¹ æ¨¡å—å’ŒåŸºäºDiTçš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ã€‚é€šè¿‡è‡ªç›‘ç£å­¦ä¹ ï¼Œè”åˆä¼˜åŒ–è¿™äº›æ¨¡å—ï¼Œä»¥æé«˜è¿åŠ¨ç”Ÿæˆçš„è´¨é‡å’Œè¡¨ç°åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºè¿åŠ¨ä¸èº«ä»½çš„è§£è€¦ï¼Œé€šè¿‡å¼•å…¥2Då¢å¼ºå’Œåˆæˆ3Dæ¸²æŸ“æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡äº†è¿åŠ¨è½¬ç§»çš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†è¾…åŠ©è§£ç å™¨æ¥ä¿ƒè¿›è¿åŠ¨æ ‡è®°çš„å­¦ä¹ ï¼Œç¡®ä¿ç”Ÿæˆçš„è¿åŠ¨åµŒå…¥åœ¨è¯­ä¹‰ä¸Šå¯¹é½ä¸”å…·å¤‡æ·±åº¦æ„ŸçŸ¥èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒX-UniMotionåœ¨è¿åŠ¨è¡¨ç°åŠ›å’Œä¿çœŸåº¦æ–¹é¢è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨å¤šæ ·åŒ–èº«ä»½å’Œå§¿åŠ¿ä¸‹çš„åŠ¨ç”»ç”Ÿæˆè´¨é‡æå‡äº†æ˜¾è‘—çš„ç™¾åˆ†æ¯”ï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŠ¨ç”»åˆ¶ä½œã€æ¸¸æˆå¼€å‘ã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰ã€‚é€šè¿‡å®ç°é«˜ä¿çœŸä¸”èº«ä»½æ— å…³çš„äººä½“åŠ¨ç”»ï¼ŒX-UniMotionå¯ä»¥ä¸ºåˆ›ä½œè€…æä¾›æ›´çµæ´»çš„å·¥å…·ï¼Œæ¨åŠ¨æ•°å­—å†…å®¹åˆ›ä½œçš„åˆ›æ–°ä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present X-UniMotion, a unified and expressive implicit latent representation for whole-body human motion, encompassing facial expressions, body poses, and hand gestures. Unlike prior motion transfer methods that rely on explicit skeletal poses and heuristic cross-identity adjustments, our approach encodes multi-granular motion directly from a single image into a compact set of four disentangled latent tokens -- one for facial expression, one for body pose, and one for each hand. These motion latents are both highly expressive and identity-agnostic, enabling high-fidelity, detailed cross-identity motion transfer across subjects with diverse identities, poses, and spatial configurations. To achieve this, we introduce a self-supervised, end-to-end framework that jointly learns the motion encoder and latent representation alongside a DiT-based video generative model, trained on large-scale, diverse human motion datasets. Motion-identity disentanglement is enforced via 2D spatial and color augmentations, as well as synthetic 3D renderings of cross-identity subject pairs under shared poses. Furthermore, we guide motion token learning with auxiliary decoders that promote fine-grained, semantically aligned, and depth-aware motion embeddings. Extensive experiments show that X-UniMotion outperforms state-of-the-art methods, producing highly expressive animations with superior motion fidelity and identity preservation.

