---
layout: default
title: Revisiting Efficient Semantic Segmentation: Learning Offsets for Better Spatial and Class Feature Alignment
---

# Revisiting Efficient Semantic Segmentation: Learning Offsets for Better Spatial and Class Feature Alignment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08811" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08811v1</a>
  <a href="https://arxiv.org/pdf/2508.08811.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08811v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08811v1', 'Revisiting Efficient Semantic Segmentation: Learning Offsets for Better Spatial and Class Feature Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shi-Chen Zhang, Yunheng Li, Yu-Huan Wu, Qibin Hou, Ming-Ming Cheng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

**å¤‡æ³¨**: Accepted at ICCV 2025. Project page: https://github.com/HVision-NKU/OffSeg

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåç§»å­¦ä¹ æ–¹æ³•ä»¥è§£å†³è¯­ä¹‰åˆ†å‰²ä¸­çš„ç‰¹å¾å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è¯­ä¹‰åˆ†å‰²` `åç§»å­¦ä¹ ` `ç‰¹å¾å¯¹é½` `è½»é‡åŒ–ç½‘ç»œ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­ä¹‰åˆ†å‰²æ–¹æ³•åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šåº”ç”¨æ—¶ï¼Œé¢ä¸´ç±»è¡¨ç¤ºä¸å›¾åƒç‰¹å¾é”™ä½çš„é—®é¢˜ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºè€¦åˆåŒåˆ†æ”¯åç§»å­¦ä¹ èŒƒå¼ï¼Œé€šè¿‡å­¦ä¹ ç‰¹å¾å’Œç±»åˆ«åç§»ï¼ŒåŠ¨æ€ä¼˜åŒ–ç±»è¡¨ç¤ºä¸å›¾åƒç‰¹å¾çš„å¯¹é½ã€‚
3. åœ¨ADE20Kç­‰æ•°æ®é›†ä¸Šï¼ŒOffSegç½‘ç»œåœ¨å¤šä¸ªåŸºçº¿æ¨¡å‹ä¸Šå®ç°äº†2.7%è‡³1.9%çš„mIoUæå‡ï¼Œä»…å¢åŠ 0.1-0.2Må‚æ•°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯­ä¹‰åˆ†å‰²æ˜¯è§†è§‰ç³»ç»Ÿä¸­å®ç°åƒç´ çº§åœºæ™¯ç†è§£çš„åŸºç¡€ï¼Œä½†åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šéƒ¨ç½²æ—¶éœ€è¦é«˜æ•ˆçš„æ¶æ„ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡è½»é‡åŒ–è®¾è®¡å®ç°å®æ—¶æ¨ç†ï¼Œä½†å­˜åœ¨ç±»è¡¨ç¤ºä¸å›¾åƒç‰¹å¾ä¹‹é—´çš„é”™ä½é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§è€¦åˆåŒåˆ†æ”¯åç§»å­¦ä¹ èŒƒå¼ï¼Œæ˜¾å¼å­¦ä¹ ç‰¹å¾å’Œç±»åˆ«åç§»ï¼Œä»¥åŠ¨æ€ä¼˜åŒ–ç±»è¡¨ç¤ºå’Œç©ºé—´å›¾åƒç‰¹å¾ã€‚åŸºäºè¯¥èŒƒå¼ï¼Œæ„å»ºäº†é«˜æ•ˆçš„è¯­ä¹‰åˆ†å‰²ç½‘ç»œOffSegã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡å–å¾—äº†æ˜¾è‘—æå‡ï¼Œä¸”ä»…éœ€å°‘é‡é¢å¤–å‚æ•°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¯­ä¹‰åˆ†å‰²æ–¹æ³•ä¸­ç±»è¡¨ç¤ºä¸å›¾åƒç‰¹å¾ä¹‹é—´çš„é”™ä½é—®é¢˜ã€‚ç°æœ‰çš„é€åƒç´ åˆ†ç±»èŒƒå¼å‡è®¾åŒä¸€ç±»åˆ«åœ¨ä¸åŒå›¾åƒä¸­çš„åƒç´ ç‰¹å¾ä¸åº”å˜åŒ–ï¼Œè¿™åœ¨é«˜æ•ˆåœºæ™¯ä¸­æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºè€¦åˆåŒåˆ†æ”¯åç§»å­¦ä¹ èŒƒå¼ï¼Œé€šè¿‡æ˜¾å¼å­¦ä¹ ç‰¹å¾å’Œç±»åˆ«çš„åç§»ï¼ŒåŠ¨æ€è°ƒæ•´ç±»è¡¨ç¤ºå’Œç©ºé—´å›¾åƒç‰¹å¾ï¼Œä»è€Œæé«˜å¯¹é½æ•ˆæœã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆç¼“è§£ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦åˆ†æ”¯ï¼šä¸€ä¸ªç”¨äºå­¦ä¹ ç±»åˆ«åç§»ï¼Œå¦ä¸€ä¸ªç”¨äºå­¦ä¹ ç‰¹å¾åç§»ã€‚é€šè¿‡è¿™ä¸¤ä¸ªåˆ†æ”¯çš„è€¦åˆï¼Œç½‘ç»œèƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´ç‰¹å¾è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºåç§»å­¦ä¹ èŒƒå¼çš„å¼•å…¥ï¼Œä½¿å¾—ç°æœ‰çš„è½»é‡åŒ–è¯­ä¹‰åˆ†å‰²æ–¹æ³•æ— éœ€é¢å¤–çš„æ¶æ„ä¿®æ”¹å³å¯å®ç°æ€§èƒ½æå‡ã€‚è¿™ä¸€æ–¹æ³•åœ¨ç‰¹å¾å¯¹é½æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸­ï¼Œé‡‡ç”¨äº†è½»é‡åŒ–è®¾è®¡ä»¥ä¿æŒé«˜æ•ˆæ€§ï¼ŒåŒæ—¶åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥äº†åç§»å­¦ä¹ çš„ç›¸å…³æŸå¤±ï¼Œä»¥ç¡®ä¿ç‰¹å¾å’Œç±»åˆ«çš„å¯¹é½æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOffSegç½‘ç»œåœ¨ADE20Kæ•°æ®é›†ä¸Šå¯¹SegFormer-B0ã€SegNeXt-Tå’ŒMask2Former-Tinyçš„mIoUåˆ†åˆ«æå‡äº†2.7%ã€1.9%å’Œ2.6%ï¼Œä¸”ä»…å¢åŠ äº†0.1-0.2Mçš„å‚æ•°ï¼ŒéªŒè¯äº†åç§»å­¦ä¹ èŒƒå¼çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§å’Œå¢å¼ºç°å®ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šå®ç°é«˜æ•ˆçš„è¯­ä¹‰åˆ†å‰²ï¼Œæå‡ç³»ç»Ÿçš„å®æ—¶æ€§å’Œå‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨æ›´å¤šè½»é‡åŒ–è§†è§‰ä»»åŠ¡çš„ç ”ç©¶ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Semantic segmentation is fundamental to vision systems requiring pixel-level scene understanding, yet deploying it on resource-constrained devices demands efficient architectures. Although existing methods achieve real-time inference through lightweight designs, we reveal their inherent limitation: misalignment between class representations and image features caused by a per-pixel classification paradigm. With experimental analysis, we find that this paradigm results in a highly challenging assumption for efficient scenarios: Image pixel features should not vary for the same category in different images. To address this dilemma, we propose a coupled dual-branch offset learning paradigm that explicitly learns feature and class offsets to dynamically refine both class representations and spatial image features. Based on the proposed paradigm, we construct an efficient semantic segmentation network, OffSeg. Notably, the offset learning paradigm can be adopted to existing methods with no additional architectural changes. Extensive experiments on four datasets, including ADE20K, Cityscapes, COCO-Stuff-164K, and Pascal Context, demonstrate consistent improvements with negligible parameters. For instance, on the ADE20K dataset, our proposed offset learning paradigm improves SegFormer-B0, SegNeXt-T, and Mask2Former-Tiny by 2.7%, 1.9%, and 2.6% mIoU, respectively, with only 0.1-0.2M additional parameters required.

