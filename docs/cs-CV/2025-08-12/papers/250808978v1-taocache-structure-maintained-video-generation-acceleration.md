---
layout: default
title: TaoCache: Structure-Maintained Video Generation Acceleration
---

# TaoCache: Structure-Maintained Video Generation Acceleration

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08978" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08978v1</a>
  <a href="https://arxiv.org/pdf/2508.08978.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08978v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08978v1', 'TaoCache: Structure-Maintained Video Generation Acceleration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhentao Fan, Zongzuo Wang, Weiwei Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTaoCacheä»¥è§£å†³è§†é¢‘ç”ŸæˆåŠ é€Ÿä¸­çš„ç»“æ„ä¸€è‡´æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `ç¼“å­˜åŠ é€Ÿ` `å»å™ªæ¨¡å‹` `ç»“æ„ä¸€è‡´æ€§` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¼“å­˜åŠ é€Ÿæ–¹æ³•åœ¨è§†é¢‘ç”Ÿæˆä¸­è·³è¿‡æ—©æœŸæˆ–ä¸­æœŸå»å™ªæ­¥éª¤ï¼Œå¯¼è‡´ç»“æ„ä¸ä¸€è‡´æ€§ï¼Œå½±å“ç”Ÿæˆè´¨é‡ã€‚
2. TaoCacheé‡‡ç”¨å›ºå®šç‚¹è§†è§’é¢„æµ‹å™ªå£°è¾“å‡ºï¼Œé€šè¿‡æ ¡å‡†å™ªå£°å¢é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦å’ŒèŒƒæ•°æ¯”ï¼Œä¿æŒé«˜åˆ†è¾¨ç‡ç»“æ„ã€‚
3. åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼ŒTaoCacheåœ¨ç›¸åŒåŠ é€Ÿæ¡ä»¶ä¸‹æ˜¾è‘—æé«˜äº†è§†è§‰è´¨é‡ï¼Œè¶…è¶Šäº†ä»¥å¾€çš„ç¼“å­˜æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰åŸºäºç¼“å­˜çš„è§†é¢‘æ‰©æ•£æ¨¡å‹åŠ é€Ÿæ–¹æ³•ä¸»è¦è·³è¿‡æ—©æœŸæˆ–ä¸­æœŸå»å™ªæ­¥éª¤ï¼Œè¿™å¸¸å¸¸å¯¼è‡´ç”Ÿæˆç»“æœä¸å®Œæ•´æ—¶é—´æ­¥ä¹‹é—´å­˜åœ¨ç»“æ„å·®å¼‚ï¼Œå½±å“æŒ‡ä»¤éµå¾ªå’Œè§’è‰²ä¸€è‡´æ€§ã€‚æœ¬æ–‡æå‡ºäº†TaoCacheï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„å³æ’å³ç”¨ç¼“å­˜ç­–ç•¥ï¼Œé‡‡ç”¨å›ºå®šç‚¹è§†è§’é¢„æµ‹æ¨¡å‹çš„å™ªå£°è¾“å‡ºï¼Œç‰¹åˆ«æœ‰æ•ˆäºåæœŸå»å™ªé˜¶æ®µã€‚é€šè¿‡æ ¡å‡†è¿ç»­å™ªå£°å¢é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦å’ŒèŒƒæ•°æ¯”ï¼ŒTaoCacheåœ¨å®ç°æ¿€è¿›è·³è¿‡çš„åŒæ—¶ä¿æŒé«˜åˆ†è¾¨ç‡ç»“æ„ã€‚è¯¥æ–¹æ³•ä¸Pyramid Attention Broadcast (PAB)å’ŒTeaCacheç­‰è¡¥å……åŠ é€Ÿæ–¹æ³•æ˜¯æ­£äº¤çš„ï¼Œå¹¶èƒ½æ— ç¼é›†æˆåˆ°åŸºäºDiTçš„æ¡†æ¶ä¸­ã€‚åœ¨Latte-1ã€OpenSora-Plan v110å’ŒWan2.1ä¸Šï¼ŒTaoCacheåœ¨ç›¸åŒåŠ é€Ÿæ¡ä»¶ä¸‹æ˜¾è‘—æé«˜äº†è§†è§‰è´¨é‡ï¼ˆLPIPSã€SSIMã€PSNRï¼‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„ç¼“å­˜åŠ é€Ÿæ–¹æ³•åœ¨è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­å¸¸å¸¸è·³è¿‡æ—©æœŸæˆ–ä¸­æœŸçš„å»å™ªæ­¥éª¤ï¼Œå¯¼è‡´ç”Ÿæˆç»“æœä¸å®Œæ•´æ—¶é—´æ­¥ä¹‹é—´å­˜åœ¨ç»“æ„å·®å¼‚ã€‚è¿™ç§å·®å¼‚ä¸ä»…å½±å“äº†ç”Ÿæˆçš„è§†è§‰è´¨é‡ï¼Œè¿˜å¯èƒ½å¦¨ç¢æŒ‡ä»¤éµå¾ªå’Œè§’è‰²ä¸€è‡´æ€§ï¼Œé™åˆ¶äº†æ¨¡å‹çš„å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTaoCacheæå‡ºäº†ä¸€ç§æ–°çš„ç¼“å­˜ç­–ç•¥ï¼Œé‡‡ç”¨å›ºå®šç‚¹è§†è§’æ¥é¢„æµ‹æ¨¡å‹çš„å™ªå£°è¾“å‡ºï¼Œè€Œä¸æ˜¯ä¾èµ–äºæ®‹å·®ç¼“å­˜ã€‚è¿™ç§æ–¹æ³•ç‰¹åˆ«å…³æ³¨åæœŸå»å™ªé˜¶æ®µï¼Œé€šè¿‡æ ¡å‡†è¿ç»­å™ªå£°å¢é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦å’ŒèŒƒæ•°æ¯”ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒé«˜åˆ†è¾¨ç‡ç»“æ„çš„åŒæ—¶å®ç°æ¿€è¿›çš„è·³è¿‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTaoCacheçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å™ªå£°é¢„æµ‹æ¨¡å—å’Œç»“æ„ä¿æŒæ¨¡å—ã€‚å™ªå£°é¢„æµ‹æ¨¡å—è´Ÿè´£ç”Ÿæˆå™ªå£°è¾“å‡ºï¼Œè€Œç»“æ„ä¿æŒæ¨¡å—åˆ™é€šè¿‡æ ¡å‡†å™ªå£°å¢é‡çš„ç›¸ä¼¼åº¦å’ŒèŒƒæ•°æ¯”æ¥ç¡®ä¿ç”Ÿæˆç»“æœçš„ç»“æ„ä¸€è‡´æ€§ã€‚è¯¥æ–¹æ³•å¯ä»¥æ— ç¼é›†æˆåˆ°åŸºäºDiTçš„æ¡†æ¶ä¸­ï¼Œå¢å¼ºå…¶åŠ é€Ÿèƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šTaoCacheçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å›ºå®šç‚¹è§†è§’çš„å™ªå£°é¢„æµ‹æ–¹æ³•ï¼Œè¿™ä¸ä¼ ç»Ÿçš„æ®‹å·®ç¼“å­˜æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚é€šè¿‡è¿™ç§æ–°é¢–çš„è®¾è®¡ï¼ŒTaoCacheèƒ½å¤Ÿåœ¨åŠ é€Ÿç”Ÿæˆçš„åŒæ—¶ä¿æŒé«˜è´¨é‡çš„è§†è§‰ç»“æ„ï¼Œè§£å†³äº†ä»¥å¾€æ–¹æ³•çš„ä¸è¶³ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨TaoCacheä¸­ï¼Œå…³é”®çš„å‚æ•°è®¾ç½®åŒ…æ‹¬å™ªå£°å¢é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦å’ŒèŒƒæ•°æ¯”çš„æ ¡å‡†ã€‚è¿™äº›è®¾è®¡ç»†èŠ‚ç¡®ä¿äº†åœ¨åŠ é€Ÿç”Ÿæˆçš„åŒæ—¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆä¿æŒç”Ÿæˆç»“æœçš„é«˜åˆ†è¾¨ç‡å’Œç»“æ„ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨Latte-1ã€OpenSora-Plan v110å’ŒWan2.1æ•°æ®é›†ä¸Šï¼ŒTaoCacheåœ¨ç›¸åŒåŠ é€Ÿæ¡ä»¶ä¸‹æ˜¾è‘—æé«˜äº†è§†è§‰è´¨é‡ï¼Œå…·ä½“è¡¨ç°ä¸ºLPIPSã€SSIMå’ŒPSNRç­‰æŒ‡æ ‡å‡ä¼˜äºä»¥å¾€çš„ç¼“å­˜æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨è§†é¢‘ç”Ÿæˆé¢†åŸŸçš„å¼ºå¤§æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TaoCacheçš„ç ”ç©¶æˆæœåœ¨è§†é¢‘ç”Ÿæˆã€åŠ¨ç”»åˆ¶ä½œå’Œè™šæ‹Ÿç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜è§†é¢‘ç”Ÿæˆçš„æ•ˆç‡å’Œè´¨é‡ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä¸ºå®æ—¶è§†é¢‘å¤„ç†å’Œé«˜è´¨é‡å†…å®¹åˆ›ä½œæä¾›æ”¯æŒï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨ã€‚æœªæ¥ï¼ŒTaoCacheå¯èƒ½ä¼šåœ¨æ›´å¤æ‚çš„ç”Ÿæˆä»»åŠ¡ä¸­å±•ç°å‡ºæ›´å¤§çš„ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing cache-based acceleration methods for video diffusion models primarily skip early or mid denoising steps, which often leads to structural discrepancies relative to full-timestep generation and can hinder instruction following and character consistency. We present TaoCache, a training-free, plug-and-play caching strategy that, instead of residual-based caching, adopts a fixed-point perspective to predict the model's noise output and is specifically effective in late denoising stages. By calibrating cosine similarities and norm ratios of consecutive noise deltas, TaoCache preserves high-resolution structure while enabling aggressive skipping. The approach is orthogonal to complementary accelerations such as Pyramid Attention Broadcast (PAB) and TeaCache, and it integrates seamlessly into DiT-based frameworks. Across Latte-1, OpenSora-Plan v110, and Wan2.1, TaoCache attains substantially higher visual quality (LPIPS, SSIM, PSNR) than prior caching methods under the same speedups.

