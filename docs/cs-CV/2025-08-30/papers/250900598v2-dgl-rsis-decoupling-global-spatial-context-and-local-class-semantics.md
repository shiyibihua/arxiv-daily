---
layout: default
title: DGL-RSIS: Decoupling Global Spatial Context and Local Class Semantics for Training-Free Remote Sensing Image Segmentation
---

# DGL-RSIS: Decoupling Global Spatial Context and Local Class Semantics for Training-Free Remote Sensing Image Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00598" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.00598v2</a>
  <a href="https://arxiv.org/pdf/2509.00598.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00598v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00598v2', 'DGL-RSIS: Decoupling Global Spatial Context and Local Class Semantics for Training-Free Remote Sensing Image Segmentation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Boyi Li, Ce Zhang, Richard M. Timmerman, Wenxuan Bao

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-30 (Êõ¥Êñ∞: 2025-11-11)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫DGL-RSIS‰ª•Ëß£ÂÜ≥ÈÅ•ÊÑüÂõæÂÉèÂàÜÂâ≤‰∏≠ÁöÑËÆ≠ÁªÉÈúÄÊ±ÇÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÈÅ•ÊÑüÂõæÂÉèÂàÜÂâ≤` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `Â§öÊ®°ÊÄÅÁêÜËß£` `ÂºÄÊîæËØçÊ±áÂàÜÂâ≤` `Êåá‰ª£Ë°®ËææÂàÜÂâ≤` `Êó†ËÆ≠ÁªÉÊñπÊ≥ï` `‰∏ä‰∏ãÊñáÊÑüÁü•ÁâπÂæÅ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ÈÅ•ÊÑüÂõæÂÉèÂàÜÂâ≤‰∏≠Èù¢‰∏¥ËæÉÂ§ßÁöÑÈ¢ÜÂüüÂ∑ÆË∑ùÂíåËæìÂÖ•Â§öÊ†∑ÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂºÄÊîæËØçÊ±áÂíåÊåá‰ª£Ë°®Ëææ‰ªªÂä°‰∏≠„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑDGL-RSISÊ°ÜÊû∂ÈÄöËøáËß£ËÄ¶ËßÜËßâÂíåÊñáÊú¨Ë°®Á§∫ÔºåÂÆûÁé∞Â±ÄÈÉ®ÂíåÂÖ®Â±ÄÁöÑËßÜËßâ-ËØ≠Ë®ÄÂØπÈΩêÔºåÈÅøÂÖç‰∫ÜÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉËøáÁ®ã„ÄÇ
3. Âú®iSAIDÂíåRRSIS-DÂü∫ÂáÜÊµãËØï‰∏≠ÔºåDGL-RSISÁöÑË°®Áé∞‰ºò‰∫éÁé∞ÊúâÁöÑÊó†ËÆ≠ÁªÉÊñπÊ≥ïÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàVLMsÔºâÁöÑÂá∫Áé∞ÔºåËßÜËßâ‰∏éËØ≠Ë®Ä‰πãÈó¥ÁöÑÈ∏øÊ≤üÂæó‰ª•Âº•ÂêàÔºå‰ΩøÂæóÂ§öÊ®°ÊÄÅÁêÜËß£Ë∂ÖË∂ä‰∫Ü‰º†ÁªüÁöÑËßÜËßâÊ∑±Â∫¶Â≠¶‰π†Ê®°Âûã„ÄÇÁÑ∂ËÄåÔºåÂ∞ÜVLMs‰ªéËá™ÁÑ∂ÂõæÂÉèÈ¢ÜÂüüËøÅÁßªÂà∞ÈÅ•ÊÑüÔºàRSÔºâÂàÜÂâ≤‰ªçÁÑ∂Èù¢‰∏¥ÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂºÄÊîæËØçÊ±áËØ≠‰πâÂàÜÂâ≤ÔºàOVSSÔºâÂíåÊåá‰ª£Ë°®ËææÂàÜÂâ≤ÔºàRESÔºâ‰∏≠„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊó†ËÆ≠ÁªÉÁöÑÁªü‰∏ÄÊ°ÜÊû∂DGL-RSISÔºåÈÄöËøáÂú®Â±ÄÈÉ®ËØ≠‰πâÂíåÂÖ®Â±Ä‰∏ä‰∏ãÊñáÂ±ÇÈù¢Ëß£ËÄ¶ËßÜËßâÂíåÊñáÊú¨Ë°®Á§∫ÔºåËøõË°åËßÜËßâ-ËØ≠Ë®ÄÂØπÈΩê„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåDGL-RSISÂú®iSAIDÔºàOVSSÔºâÂíåRRSIS-DÔºàRESÔºâÂü∫ÂáÜ‰∏ä‰ºò‰∫éÁé∞ÊúâÁöÑÊó†ËÆ≠ÁªÉÊñπÊ≥ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÈÅ•ÊÑüÂõæÂÉèÂàÜÂâ≤‰∏≠Áî±‰∫éÈ¢ÜÂüüÂ∑ÆË∑ùÂíåËæìÂÖ•Â§öÊ†∑ÊÄßÂØºËá¥ÁöÑËÆ≠ÁªÉÈúÄÊ±ÇÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®ÂºÄÊîæËØçÊ±áËØ≠‰πâÂàÜÂâ≤ÂíåÊåá‰ª£Ë°®ËææÂàÜÂâ≤‰∏≠Ë°®Áé∞‰∏ç‰Ω≥ÔºåÈöæ‰ª•ÊúâÊïàËøÅÁßªËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÁöÑËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöDGL-RSISÈÄöËøáËß£ËÄ¶ËßÜËßâÂíåÊñáÊú¨Ë°®Á§∫ÔºåÂàÜÂà´ÊèêÂèñÂ±ÄÈÉ®ËØ≠‰πâÂíåÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºå‰ªéËÄåÂÆûÁé∞Êó†ËÆ≠ÁªÉÁöÑÂõæÂÉèÂàÜÂâ≤„ÄÇËØ•ËÆæËÆ°‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂú®‰∏çÂêå‰ªªÂä°‰∏≠Ëá™ÈÄÇÂ∫îË∞ÉÊï¥ÔºåÊèêÂçá‰∫ÜÂàÜÂâ≤ÊïàÊûú„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöDGL-RSISÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÊã¨‰∏â‰∏™Ê®°ÂùóÔºöÂÖ®Â±Ä-Â±ÄÈÉ®Ëß£ËÄ¶ÔºàGLDÔºâÊ®°Âùó„ÄÅÂ±ÄÈÉ®ËßÜËßâ-ÊñáÊú¨ÂØπÈΩêÔºàLVTAÔºâÊ®°ÂùóÂíåÂÖ®Â±ÄËßÜËßâ-ÊñáÊú¨ÂØπÈΩêÔºàGVTAÔºâÊ®°Âùó„ÄÇGLDÊ®°ÂùóÂ∞ÜÊñáÊú¨ËæìÂÖ•ÂàÜËß£‰∏∫Â±ÄÈÉ®ËØ≠‰πâÂíåÂÖ®Â±Ä‰∏ä‰∏ãÊñáÊ†áËÆ∞ÔºåÂõæÂÉèËæìÂÖ•ÂàôË¢´ÂàíÂàÜ‰∏∫Á±ªÊó†ÂÖ≥ÁöÑÊé©Á†ÅÊèêËÆÆ„ÄÇLVTAÊ®°Âùó‰ªéÊé©Á†ÅÊèêËÆÆ‰∏≠ÊèêÂèñ‰∏ä‰∏ãÊñáÊÑüÁü•ÁöÑËßÜËßâÁâπÂæÅÔºåËÄåGVTAÊ®°ÂùóÂàôÂà©Áî®Â¢ûÂº∫ÁöÑGrad-CAMÊú∫Âà∂ÊçïÊçâ‰∏ä‰∏ãÊñáÁ∫øÁ¥¢„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöDGL-RSISÊòØÈ¶ñ‰∏™Êó†ËÆ≠ÁªÉÁöÑÁªü‰∏ÄÊ°ÜÊû∂ÔºåÊàêÂäüÂ∞ÜËá™ÁÑ∂ÂõæÂÉè‰∏äËÆ≠ÁªÉÁöÑVLMÁöÑËØ≠‰πâËÉΩÂäõËΩ¨ÁßªÂà∞ÈÅ•ÊÑüÈ¢ÜÂüüÔºåÊòæËëóÈôç‰Ωé‰∫ÜÂØπËÆ≠ÁªÉÊï∞ÊçÆÁöÑ‰æùËµñ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÁü•ËØÜÂºïÂØºÁöÑÊèêÁ§∫Â∑•Á®ãÊù•‰∏∞ÂØåÊñáÊú¨ÁâπÂæÅÔºåÂπ∂ÈÄöËøáÊé©Á†ÅÈÄâÊã©Ê®°ÂùóÂ∞ÜÂÉèÁ¥†Á∫ßÊøÄÊ¥ªÊï¥Âêà‰∏∫Êé©Á†ÅÁ∫ßÂàÜÂâ≤ËæìÂá∫ÔºåÁ°Æ‰øù‰∫ÜÂàÜÂâ≤ÁªìÊûúÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®iSAIDÂíåRRSIS-DÂü∫ÂáÜÊµãËØï‰∏≠ÔºåDGL-RSISÁöÑÊÄßËÉΩÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÊó†ËÆ≠ÁªÉÊñπÊ≥ïÔºåÂÖ∑‰ΩìË°®Áé∞‰∏∫Âú®OVSS‰ªªÂä°‰∏≠ÊèêÂçá‰∫ÜX%ÔºàÂÖ∑‰ΩìÊï∞ÊçÆÂæÖË°•ÂÖÖÔºâÔºåÂú®RES‰ªªÂä°‰∏≠ÊèêÂçá‰∫ÜY%ÔºàÂÖ∑‰ΩìÊï∞ÊçÆÂæÖË°•ÂÖÖÔºâÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÈÅ•ÊÑüÂõæÂÉèÂàÜÊûê„ÄÅÁéØÂ¢ÉÁõëÊµã„ÄÅÂüéÂ∏ÇËßÑÂàíÁ≠â„ÄÇÈÄöËøáÊèê‰æõÊó†ËÆ≠ÁªÉÁöÑÂàÜÂâ≤ÊñπÊ≥ïÔºåDGL-RSISËÉΩÂ§üÂú®ËµÑÊ∫êÊúâÈôêÁöÑÊÉÖÂÜµ‰∏ãÔºåÂø´ÈÄüÈÄÇÂ∫î‰∏çÂêåÁöÑÈÅ•ÊÑü‰ªªÂä°ÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The emergence of vision language models (VLMs) bridges the gap between vision and language, enabling multimodal understanding beyond traditional visual-only deep learning models. However, transferring VLMs from the natural image domain to remote sensing (RS) segmentation remains challenging due to the large domain gap and the diversity of RS inputs across tasks, particularly in open-vocabulary semantic segmentation (OVSS) and referring expression segmentation (RES). Here, we propose a training-free unified framework, termed DGL-RSIS, which decouples visual and textual representations and performs visual-language alignment at both local semantic and global contextual levels. Specifically, a Global-Local Decoupling (GLD) module decomposes textual inputs into local semantic tokens and global contextual tokens, while image inputs are partitioned into class-agnostic mask proposals. Then, a Local Visual-Textual Alignment (LVTA) module adaptively extracts context-aware visual features from the mask proposals and enriches textual features through knowledge-guided prompt engineering, achieving OVSS from a local perspective. Furthermore, a Global Visual-Textual Alignment (GVTA) module employs a global-enhanced Grad-CAM mechanism to capture contextual cues for referring expressions, followed by a mask selection module that integrates pixel-level activations into mask-level segmentation outputs, thereby achieving RES from a global perspective. Experiments on the iSAID (OVSS) and RRSIS-D (RES) benchmarks demonstrate that DGL-RSIS outperforms existing training-free approaches. Ablation studies further validate the effectiveness of each module. To the best of our knowledge, this is the first unified training-free framework for RS image segmentation, which effectively transfers the semantic capability of VLMs trained on natural images to the RS domain without additional training.

