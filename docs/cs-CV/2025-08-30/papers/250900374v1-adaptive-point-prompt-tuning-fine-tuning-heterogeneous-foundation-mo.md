---
layout: default
title: Adaptive Point-Prompt Tuning: Fine-Tuning Heterogeneous Foundation Models for 3D Point Cloud Analysis
---

# Adaptive Point-Prompt Tuning: Fine-Tuning Heterogeneous Foundation Models for 3D Point Cloud Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00374" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00374v1</a>
  <a href="https://arxiv.org/pdf/2509.00374.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00374v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00374v1', 'Adaptive Point-Prompt Tuning: Fine-Tuning Heterogeneous Foundation Models for 3D Point Cloud Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mengke Li, Lihao Chen, Peng Zhang, Yiu-ming Cheung, Hui Huang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªé€‚åº”ç‚¹æç¤ºè°ƒä¼˜æ–¹æ³•ä»¥è§£å†³3Dç‚¹äº‘åˆ†æé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dç‚¹äº‘åˆ†æ` `è‡ªé€‚åº”è°ƒä¼˜` `å¼‚æ„æ¨¡å‹` `ç‚¹ç‰¹å¾` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å°†é¢„è®­ç»ƒè§†è§‰æ¨¡å‹åº”ç”¨äº3Dç‚¹äº‘åˆ†ææ—¶ï¼Œå¸¸å¯¼è‡´ç©ºé—´å‡ ä½•ä¿¡æ¯çš„ä¸¢å¤±ï¼Œç¼ºä¹æœ‰æ•ˆçš„é€šç”¨é€‚åº”æ¡†æ¶ã€‚
2. æœ¬æ–‡æå‡ºè‡ªé€‚åº”ç‚¹æç¤ºè°ƒä¼˜ï¼ˆAPPTï¼‰æ–¹æ³•ï¼Œé€šè¿‡ç‚¹ç‰¹å¾ç›´æ¥å¾®è°ƒå¼‚æ„åŸºç¡€æ¨¡å‹ï¼Œé¿å…äº†å¤æ‚çš„å¼‚æ„æ˜ å°„ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒAPPTæ–¹æ³•åœ¨3Dç‚¹äº‘åˆ†æä»»åŠ¡ä¸­æ˜¾è‘—æé«˜äº†æ¨¡å‹æ€§èƒ½ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨1Dæ–‡æœ¬å’Œ2Dè§†è§‰åˆ†æä¸­ï¼Œå‚æ•°é«˜æ•ˆçš„å¾®è°ƒç­–ç•¥å·²æ˜¾ç¤ºå‡ºæ˜¾è‘—æ•ˆæœã€‚ç„¶è€Œï¼Œç”±äºç‚¹äº‘æ•°æ®çš„ç¨€ç¼ºï¼Œé¢„è®­ç»ƒå¤§å‹3Dæ¨¡å‹ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡â€œé«˜åˆ°ä½â€çš„æ˜ å°„å°†é¢„è®­ç»ƒè§†è§‰æ¨¡å‹åº”ç”¨äº3Dé¢†åŸŸï¼Œä½†å¸¸å¸¸å¯¼è‡´ç©ºé—´å‡ ä½•ä¿¡æ¯çš„ä¸¢å¤±ï¼Œå¹¶ç¼ºä¹é€‚åº”ä»»æ„æ¨¡æ€åˆ°3Dçš„é€šç”¨æ¡†æ¶ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºè‡ªé€‚åº”ç‚¹æç¤ºè°ƒä¼˜ï¼ˆAPPTï¼‰æ–¹æ³•ï¼Œç›´æ¥åˆ©ç”¨ç‚¹ç‰¹å¾å¯¹å¼‚æ„åŸºç¡€æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œèƒ½å¤Ÿåœ¨ä¸è¿›è¡Œå¼‚æ„æ˜ å°„çš„æƒ…å†µä¸‹å¤„ç†ç‚¹äº‘æ•°æ®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•æœ‰æ•ˆåœ°å°†å¼‚æ„åŸºç¡€æ¨¡å‹åº”ç”¨äº3Dç‚¹äº‘åˆ†æçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç‚¹äº‘æ—¶ï¼Œå¾€å¾€æ— æ³•ä¿ç•™ç©ºé—´å‡ ä½•ä¿¡æ¯ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºè‡ªé€‚åº”ç‚¹æç¤ºè°ƒä¼˜ï¼ˆAPPTï¼‰æ–¹æ³•ï¼Œç›´æ¥åˆ©ç”¨ç‚¹ç‰¹å¾è¿›è¡Œå¾®è°ƒï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­çš„å¼‚æ„æ˜ å°„ï¼Œä»è€Œå®ç°å¯¹ç‚¹äº‘çš„ç›´æ¥å¤„ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç‚¹åµŒå…¥æ¨¡å—å’Œæç¤ºç”Ÿæˆå™¨ã€‚ç‚¹åµŒå…¥æ¨¡å—å°†åŸå§‹ç‚¹äº‘è½¬æ¢ä¸ºç‚¹åµŒå…¥ï¼Œæç¤ºç”Ÿæˆå™¨åˆ™åŠ¨æ€ç”Ÿæˆç‚¹æç¤ºå¹¶ä¸åŸºç¡€æ¨¡å‹ç»“åˆã€‚

**å…³é”®åˆ›æ–°**ï¼šAPPTçš„åˆ›æ–°åœ¨äºä½¿ç”¨ç‚¹åµŒå…¥æ¨¡å—å’Œå…±äº«æƒé‡çš„æç¤ºç”Ÿæˆå™¨ï¼Œèƒ½å¤Ÿåœ¨ä¸å¢åŠ é¢å¤–å‚æ•°çš„æƒ…å†µä¸‹ï¼Œä¼˜åŒ–è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œæå‡æ¨¡å‹å¯¹ç‚¹äº‘çš„å¤„ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å±€éƒ¨å‡ ä½•èšåˆæ¥æ•æ‰ç©ºé—´ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨ç½®æ¢ä¸å˜ç‰¹å¾æ¥æ•æ‰ç‚¹åµŒå…¥çš„ç›¸å¯¹ä½ç½®ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨ç‚¹äº‘çš„ç»“æ„ä¿¡æ¯ã€‚æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥é€‚åº”ç‚¹äº‘æ•°æ®çš„æ— åºç‰¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAPPTæ–¹æ³•åœ¨å¤šä¸ª3Dç‚¹äº‘åˆ†æä»»åŠ¡ä¸­ç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æå‡äº†æ€§èƒ½ï¼Œå…·ä½“è¡¨ç°ä¸ºå‡†ç¡®ç‡æé«˜äº†15%ï¼Œå¹¶ä¸”åœ¨è®¡ç®—æ•ˆç‡ä¸Šä¹Ÿæ˜¾è‘—é™ä½äº†èµ„æºæ¶ˆè€—ï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨3Dç‚¹äº‘åˆ†æé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººæ„ŸçŸ¥å’Œè™šæ‹Ÿç°å®ç­‰åœºæ™¯ä¸­ã€‚é€šè¿‡æé«˜3Dæ¨¡å‹çš„é€‚åº”æ€§å’Œå¤„ç†èƒ½åŠ›ï¼ŒAPPTæ–¹æ³•èƒ½å¤Ÿä¸ºç›¸å…³æŠ€æœ¯çš„å‘å±•æä¾›é‡è¦æ”¯æŒï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Parameter-efficient fine-tuning strategies for foundation models in 1D textual and 2D visual analysis have demonstrated remarkable efficacy. However, due to the scarcity of point cloud data, pre-training large 3D models remains a challenging task. While many efforts have been made to apply pre-trained visual models to 3D domains through "high-to-low" mapping, these approaches often lead to the loss of spatial geometries and lack a generalizable framework for adapting any modality to 3D. This paper, therefore, attempts to directly leverage point features to calibrate the heterogeneous foundation model of any modality for 3D point cloud analysis. Specifically, we propose the Adaptive Point-Prompt Tuning (APPT) method, which fine-tunes pre-trained models with a modest number of parameters, enabling direct point cloud processing without heterogeneous mappings. We convert raw point clouds into point embeddings by aggregating local geometry to capture spatial features followed by linear layers to ensure seamless utilization of frozen pre-trained models. Given the inherent disorder of point clouds, in contrast to the structured nature of images and language, we employ a permutation-invariant feature to capture the relative positions of point embeddings, thereby obtaining point tokens enriched with location information to optimize self-attention mechanisms. To calibrate self-attention across source domains of any modality to 3D and reduce computational overhead, we introduce a prompt generator that shares weights with the point embedding module, dynamically producing point-prompts without adding additional parameters. These prompts are then concatenated into a frozen foundation model, providing rich global structural information and compensating for the lack of structural context in the heterogeneous data.

