---
layout: default
title: Make me an Expert: Distilling from Generalist Black-Box Models into Specialized Models for Semantic Segmentation
---

# Make me an Expert: Distilling from Generalist Black-Box Models into Specialized Models for Semantic Segmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00509" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00509v1</a>
  <a href="https://arxiv.org/pdf/2509.00509.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00509v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00509v1', 'Make me an Expert: Distilling from Generalist Black-Box Models into Specialized Models for Semantic Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yasser Benigmim, Subhankar Roy, Khalid Oublal, Imad Eddine Marouf, Slim Essid, Vicky Kalogeiton, StÃ©phane LathuiliÃ¨re

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30

**å¤‡æ³¨**: Github repo : https://github.com/yasserben/ATGC

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/yasserben/ATGC)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé»‘ç®±è’¸é¦æ–¹æ³•ä»¥è§£å†³å±€éƒ¨æ¨¡å‹è®­ç»ƒé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `é»‘ç®±è’¸é¦` `è¯­ä¹‰åˆ†å‰²` `æ¨¡å‹é€‚åº”` `æ³¨æ„åŠ›æœºåˆ¶` `å¼€æ”¾è¯æ±‡æ¨¡å‹` `DINOv2` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é¢†åŸŸé€‚åº”æ–¹æ³•åœ¨é»‘ç®±æ¨¡å‹çš„è®­ç»ƒä¸­é¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯æ— æ³•è®¿é—®æ¨¡å‹çš„å†…éƒ¨å‚æ•°å’Œæ•°æ®ã€‚
2. æœ¬æ–‡æå‡ºçš„ATGCæ–¹æ³•é€šè¿‡åˆ©ç”¨DINOv2çš„æ³¨æ„åŠ›å›¾ï¼ŒåŠ¨æ€é€‰æ‹©æœ€ä½³å°ºåº¦æ¥å…‹æœå¼€æ”¾è¯æ±‡æ¨¡å‹çš„åˆ†è¾¨ç‡æ•æ„Ÿæ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒATGCåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æœ‰æ˜¾è‘—æå‡ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€äººå·¥æ™ºèƒ½å³æœåŠ¡ï¼ˆAIaaSï¼‰çš„å…´èµ·ï¼Œå¦‚ä½•åœ¨ä¸æš´éœ²æƒé‡ã€è®­ç»ƒæ•°æ®æˆ–logitsçš„æƒ…å†µä¸‹æœ‰æ•ˆè®­ç»ƒå±€éƒ¨æ¨¡å‹æˆä¸ºä¸€ä¸ªé‡è¦é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†é»‘ç®±è’¸é¦ï¼ˆB2Dï¼‰è®¾ç½®ï¼Œå…è®¸åœ¨ç°å®çº¦æŸä¸‹è¿›è¡Œå±€éƒ¨æ¨¡å‹é€‚åº”ã€‚ç ”ç©¶å‘ç°ï¼Œå¼€æ”¾è¯æ±‡æ¨¡å‹å¯¹è¾“å…¥åˆ†è¾¨ç‡éå¸¸æ•æ„Ÿï¼Œä¸åŒç‰©ä½“ç±»åˆ«åœ¨ä¸åŒå°ºåº¦ä¸‹çš„åˆ†å‰²æ•ˆæœæœ€ä½³ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†åŸºäºDINOv2æ³¨æ„åŠ›å›¾çš„ATGCæ–¹æ³•ï¼ŒåŠ¨æ€é€‰æ‹©é»‘ç®±æ¨¡å‹æ¨ç†çš„æœ€ä½³å°ºåº¦ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†é»‘ç®±ç›‘ç£ä¸‹çš„æ€§èƒ½ï¼Œä»…éœ€ä¾èµ–ä¸€çƒ­ç¼–ç çš„APIé¢„æµ‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•åœ¨æ²¡æœ‰è®¿é—®é»‘ç®±æ¨¡å‹å†…éƒ¨ä¿¡æ¯çš„æƒ…å†µä¸‹ï¼Œè¿›è¡Œå±€éƒ¨æ¨¡å‹çš„æœ‰æ•ˆè®­ç»ƒã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹é»‘ç®±æ¨¡å‹æ—¶ï¼Œæ— æ³•åˆ©ç”¨å…¶æƒé‡å’Œè®­ç»ƒæ•°æ®ï¼Œå¯¼è‡´é€‚åº”æ€§å·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„ATGCæ–¹æ³•é€šè¿‡åˆ†æDINOv2çš„æ³¨æ„åŠ›å›¾ï¼ŒåŠ¨æ€é€‰æ‹©é€‚åˆä¸åŒç‰©ä½“ç±»åˆ«çš„æœ€ä½³è¾“å…¥å°ºåº¦ï¼Œä»è€Œæé«˜æ¨¡å‹çš„åˆ†å‰²æ€§èƒ½ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨è§£å†³å¼€æ”¾è¯æ±‡æ¨¡å‹åœ¨ä¸åŒåˆ†è¾¨ç‡ä¸‹çš„æ€§èƒ½ä¸å‡è¡¡é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šATGCçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ³¨æ„åŠ›å›¾ç”Ÿæˆã€å°ºåº¦é€‰æ‹©å’Œä¼ªæ ‡ç­¾ç”Ÿæˆç­‰æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡APIè·å–ä¸€çƒ­ç¼–ç çš„é¢„æµ‹ï¼Œç„¶ååˆ©ç”¨æ³¨æ„åŠ›å›¾è¯„ä¼°ä¸åŒå°ºåº¦çš„æœ‰æ•ˆæ€§ï¼Œæœ€åç”Ÿæˆä¼ªæ ‡ç­¾è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šATGCçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†åŸºäºæ³¨æ„åŠ›å›¾çš„åŠ¨æ€å°ºåº¦é€‰æ‹©æœºåˆ¶ï¼Œè¿™ä¸€æœºåˆ¶ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒçš„è¾“å…¥åˆ†è¾¨ç‡ä¸‹ä¼˜åŒ–åˆ†å‰²æ•ˆæœï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„é€‚åº”æ€§å’Œæ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ATGCä¸­ï¼Œæ³¨æ„åŠ›å›¾çš„è¯„åˆ†é‡‡ç”¨äº†ç†µå€¼æ¥è¯†åˆ«ä¿¡æ¯ä¸°å¯Œçš„å°ºåº¦ï¼Œç¡®ä¿ä¼ªæ ‡ç­¾çš„ç”Ÿæˆæ›´åŠ æœ‰æ•ˆã€‚æ­¤å¤–ï¼Œæ¨¡å‹çš„æŸå¤±å‡½æ•°è®¾è®¡è€ƒè™‘äº†ä¸åŒå°ºåº¦ä¸‹çš„åˆ†å‰²æ•ˆæœï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†è®­ç»ƒçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒATGCåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æå‡äº†20%ä»¥ä¸Šçš„åˆ†å‰²æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨é»‘ç®±ç›‘ç£ä¸‹çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚è¯¥æ–¹æ³•ä»…ä¾èµ–ä¸€çƒ­ç¼–ç çš„APIé¢„æµ‹ï¼Œæå¤§åœ°é™ä½äº†æ•°æ®ä¾èµ–æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ä¸­çš„è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­ï¼Œèƒ½å¤Ÿåˆ©ç”¨ç°æœ‰çš„é»‘ç®±æ¨¡å‹è¿›è¡Œé«˜æ•ˆçš„æ¨¡å‹è®­ç»ƒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨æ›´å¤šåŸºäºAPIçš„æ¨¡å‹é€‚åº”æŠ€æœ¯çš„å‘å±•ï¼Œä¿ƒè¿›AIæŠ€æœ¯çš„æ™®åŠä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rise of Artificial Intelligence as a Service (AIaaS) democratizes access to pre-trained models via Application Programming Interfaces (APIs), but also raises a fundamental question: how can local models be effectively trained using black-box models that do not expose their weights, training data, or logits, a constraint in which current domain adaptation paradigms are impractical ? To address this challenge, we introduce the Black-Box Distillation (B2D) setting, which enables local model adaptation under realistic constraints: (1) the API model is open-vocabulary and trained on large-scale general-purpose data, and (2) access is limited to one-hot predictions only. We identify that open-vocabulary models exhibit significant sensitivity to input resolution, with different object classes being segmented optimally at different scales, a limitation termed the "curse of resolution". Our method, ATtention-Guided sCaler (ATGC), addresses this challenge by leveraging DINOv2 attention maps to dynamically select optimal scales for black-box model inference. ATGC scores the attention maps with entropy to identify informative scales for pseudo-labelling, enabling effective distillation. Experiments demonstrate substantial improvements under black-box supervision across multiple datasets while requiring only one-hot API predictions. Our code is available at https://github.com/yasserben/ATGC.

