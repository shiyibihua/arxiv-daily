---
layout: default
title: VideoRewardBench: Comprehensive Evaluation of Multimodal Reward Models for Video Understanding
---

# VideoRewardBench: Comprehensive Evaluation of Multimodal Reward Models for Video Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00484" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.00484v1</a>
  <a href="https://arxiv.org/pdf/2509.00484.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00484v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00484v1', 'VideoRewardBench: Comprehensive Evaluation of Multimodal Reward Models for Video Understanding')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zhihong Zhang, Xiaojian Huang, Jin Xu, Zhuodong Luo, Xinzhi Wang, Jiansheng Wei, Xuejin Chen

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-30

**Â§áÊ≥®**: https://videorewardbench.github.io/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫VideoRewardBench‰ª•Ëß£ÂÜ≥ËßÜÈ¢ëÁêÜËß£‰∏≠Â§öÊ®°ÊÄÅÂ•ñÂä±Ê®°ÂûãËØÑ‰º∞‰∏çË∂≥ÁöÑÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜÈ¢ëÁêÜËß£` `Â§öÊ®°ÊÄÅÂ•ñÂä±Ê®°Âûã` `ËØÑ‰º∞Âü∫ÂáÜ` `AIËæÖÂä©Êï∞ÊçÆÁÆ°ÈÅì` `Ê®°ÂûãÊÄßËÉΩÂØπÊØî`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑËßÜÈ¢ëÈ¢ÜÂüüÂ§öÊ®°ÊÄÅÂ•ñÂä±Ê®°ÂûãËØÑ‰º∞Âü∫ÂáÜÂú®ÈóÆÈ¢òÊï∞ÈáèÂíåÂ§öÊ†∑ÊÄß„ÄÅËØÑ‰º∞Áª¥Â∫¶ÂèäMRMsÁ±ªÂûãÁöÑËØÑ‰º∞‰∏äÂ≠òÂú®ÊòæËëó‰∏çË∂≥„ÄÇ
2. Êú¨ÊñáÊèêÂá∫VideoRewardBenchÔºåÊ∂µÁõñËßÜÈ¢ëÁêÜËß£ÁöÑÊÑüÁü•„ÄÅÁü•ËØÜ„ÄÅÊé®ÁêÜÂíåÂÆâÂÖ®Âõõ‰∏™Ê†∏ÂøÉÊñπÈù¢ÔºåÊèê‰æõ‰∫ÜÊõ¥ÂÖ®Èù¢ÁöÑËØÑ‰º∞Ê°ÜÊû∂„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÈ°∂Á∫ßÊ®°ÂûãÁöÑÂáÜÁ°ÆÁéá‰ªçÁÑ∂ËæÉ‰ΩéÔºå‰∏î‰∏çÂêåÁ±ªÂûãÁöÑMRMsÂú®Êé®ÁêÜÊó∂ÁöÑË°®Áé∞ÂèóËæìÂÖ•ËßÜÈ¢ëÂ∏ßÊï∞ÂΩ±ÂìçÊòæËëó„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ•ñÂä±Ê®°ÂûãÔºàMRMsÔºâÂú®Â§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàLVLMsÔºâÁöÑËÆ≠ÁªÉ„ÄÅÊé®ÁêÜÂíåËØÑ‰º∞‰∏≠Ëµ∑ÁùÄÂÖ≥ÈîÆ‰ΩúÁî®Ôºå‰∏ªË¶ÅÈÄöËøáËØÑ‰º∞ÂìçÂ∫îË¥®Èáè„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑËßÜÈ¢ëÈ¢ÜÂüüMRMsËØÑ‰º∞Âü∫ÂáÜÂ≠òÂú®ÈóÆÈ¢òÔºåÂåÖÊã¨ÈóÆÈ¢òÊï∞ÈáèÂíåÂ§öÊ†∑ÊÄß‰∏çË∂≥„ÄÅËØÑ‰º∞Áª¥Â∫¶‰∏çÂÖ®Èù¢‰ª•ÂèäÂØπ‰∏çÂêåÁ±ªÂûãMRMsËØÑ‰º∞‰∏çÂÖÖÂàÜ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜVideoRewardBenchÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™Ê∂µÁõñËßÜÈ¢ëÁêÜËß£Âõõ‰∏™Ê†∏ÂøÉÊñπÈù¢ÁöÑÁªºÂêàÂü∫ÂáÜÔºöÊÑüÁü•„ÄÅÁü•ËØÜ„ÄÅÊé®ÁêÜÂíåÂÆâÂÖ®„ÄÇÈÄöËøáAIËæÖÂä©ÁöÑÊï∞ÊçÆÁÆ°ÈÅìÔºåÊàë‰ª¨Êï¥ÁêÜ‰∫Ü‰∏Ä‰∏™ÂåÖÂê´1,563‰∏™Ê†áÊ≥®Ê†∑Êú¨ÁöÑÈ´òË¥®ÈáèÂÅèÂ•ΩÊï∞ÊçÆÈõÜÔºåÊ†∑Êú¨Êï∞ÈáèÊòØÁé∞ÊúâÂü∫ÂáÜÁöÑ15ÂÄç„ÄÇÊàë‰ª¨ÂØπ28ÁßçMRMsËøõË°å‰∫ÜÂÖ®Èù¢ËØÑ‰º∞ÔºåÁªìÊûúÊòæÁ§∫Âç≥‰ΩøÊòØË°®Áé∞ÊúÄÂ•ΩÁöÑÊ®°ÂûãGPT-4oÁöÑÊÄª‰ΩìÂáÜÁ°ÆÁéá‰πü‰ªÖ‰∏∫57.0%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâËßÜÈ¢ëÈ¢ÜÂüüÂ§öÊ®°ÊÄÅÂ•ñÂä±Ê®°ÂûãËØÑ‰º∞Âü∫ÂáÜÂú®ÈóÆÈ¢òÊï∞Èáè„ÄÅËØÑ‰º∞Áª¥Â∫¶ÂèäMRMsÁ±ªÂûãËØÑ‰º∞‰∏äÁöÑ‰∏çË∂≥ÔºåÂØºËá¥ËØÑ‰º∞ÁªìÊûú‰∏çÂ§üÂÖ®Èù¢ÂíåÂáÜÁ°Æ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÂºïÂÖ•VideoRewardBenchÔºåÊèê‰æõ‰∏Ä‰∏™Ê∂µÁõñËßÜÈ¢ëÁêÜËß£Âõõ‰∏™Ê†∏ÂøÉÊñπÈù¢ÁöÑÁªºÂêàËØÑ‰º∞Ê°ÜÊû∂Ôºå‰ª•ÊèêÂçáÂØπMRMsÁöÑËØÑ‰º∞Ë¥®ÈáèÂíåÂ§öÊ†∑ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÊî∂ÈõÜ„ÄÅÊ†∑Êú¨Ê†áÊ≥®ÂíåÊ®°ÂûãËØÑ‰º∞‰∏â‰∏™‰∏ªË¶ÅÊ®°Âùó„ÄÇÊï∞ÊçÆÊî∂ÈõÜÈÄöËøáAIËæÖÂä©ÁÆ°ÈÅìËøõË°åÔºåÊ†∑Êú¨Ê†áÊ≥®Á°Æ‰øùÊï∞ÊçÆÁöÑÈ´òË¥®ÈáèÔºåÊ®°ÂûãËØÑ‰º∞ÂàôÊ∂µÁõñ28ÁßçMRMsÁöÑÊÄßËÉΩÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVideoRewardBenchÊòØÁ¨¨‰∏Ä‰∏™ÂÖ®Èù¢ËØÑ‰º∞ËßÜÈ¢ëÁêÜËß£ÁöÑÂ§öÊ®°ÊÄÅÂ•ñÂä±Ê®°ÂûãÁöÑÂü∫ÂáÜÔºåÊòæËëóÊèêÂçá‰∫ÜÈóÆÈ¢òÁöÑÊï∞ÈáèÂíåÂ§öÊ†∑ÊÄßÔºåÊèê‰æõ‰∫ÜÊõ¥‰∏∞ÂØåÁöÑËØÑ‰º∞Áª¥Â∫¶„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊï∞ÊçÆÈõÜ‰∏≠ÂåÖÂê´1,563‰∏™Ê†áÊ≥®Ê†∑Êú¨ÔºåÊ†∑Êú¨‰∏∫ËßÜÈ¢ë-ÊñáÊú¨ÊèêÁ§∫„ÄÅÈÄâÊã©ÁöÑÂìçÂ∫îÂíåÊãíÁªùÁöÑÂìçÂ∫îÁöÑ‰∏âÂÖÉÁªÑÔºåÁ°Æ‰øù‰∫ÜËØÑ‰º∞ÁöÑÂÖ®Èù¢ÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂ∞ΩÁÆ°GPT-4oÊòØË°®Áé∞ÊúÄÂ•ΩÁöÑÊ®°ÂûãÔºåÂÖ∂ÊÄª‰ΩìÂáÜÁ°ÆÁéá‰ªÖ‰∏∫57.0%ÔºåËÄåÂºÄÊ∫êÊ®°ÂûãQwen2.5-VL-72BÁöÑÂáÜÁ°ÆÁéá‰∏∫53.3%„ÄÇËøô‰∫õÁªìÊûúÊè≠Á§∫‰∫ÜÂΩìÂâçMRMsÂú®ËßÜÈ¢ëÁêÜËß£‰ªªÂä°‰∏≠ÁöÑÂ±ÄÈôêÊÄßÔºåÂº∫Ë∞É‰∫ÜËøõ‰∏ÄÊ≠•Á†îÁ©∂ÁöÑÂøÖË¶ÅÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ËßÜÈ¢ëÂÜÖÂÆπÂàÜÊûê„ÄÅÊô∫ËÉΩÁõëÊéß„ÄÅËá™Âä®ËßÜÈ¢ëÊëòË¶ÅÁîüÊàêÁ≠â„ÄÇÈÄöËøáÊèê‰æõÊõ¥ÂÖ®Èù¢ÁöÑËØÑ‰º∞Âü∫ÂáÜÔºåVideoRewardBenchÂ∞ÜÊé®Âä®Â§öÊ®°ÊÄÅÂ•ñÂä±Ê®°ÂûãÂú®ËßÜÈ¢ëÁêÜËß£È¢ÜÂüüÁöÑÂèëÂ±ïÔºåÊèêÂçáÁõ∏ÂÖ≥ÊäÄÊúØÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄº„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal reward models (MRMs) play a crucial role in the training, inference, and evaluation of Large Vision Language Models (LVLMs) by assessing response quality. However, existing benchmarks for evaluating MRMs in the video domain suffer from a limited number and diversity of questions, a lack of comprehensive evaluation dimensions, and inadequate evaluation of diverse types of MRMs. To address these gaps, we introduce VideoRewardBench, the first comprehensive benchmark covering four core aspects of video understanding: perception, knowledge, reasoning, and safety. Through our AI-assisted data pipeline, we curate a high-quality preference dataset of 1,563 annotated samples, including 1,482 unique videos and 1,559 distinct questions--15 times the number found in the most question-rich prior benchmark. Each sample is a triplet consisting of a video-text prompt, a chosen response, and a rejected response. We also conduct a comprehensive evaluation across 28 multimodal reward models spanning three categories: generative, discriminative, and semi-scalar. Results show that even the top-performing model GPT-4o achieves only 57.0% overall accuracy, and the state-of-the-art open-source model Qwen2.5-VL-72B reaches merely 53.3%. Our analysis further reveals three key insights: (i) MRMs trained with reinforcement learning (RL) do not necessarily exhibit stronger cross-modal generalization than those trained without RL; (ii) except for discriminative MRMs, other types of MRMs across varying model capacities can benefit from inference-time scaling; and (iii) variations in input video frame count have different effects on different types of MRMs. We believe VideoRewardBench offers a challenging and valuable benchmark for advancing the evaluation and development of MRMs in the video domain.

