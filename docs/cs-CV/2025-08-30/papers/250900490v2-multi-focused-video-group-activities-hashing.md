---
layout: default
title: Multi-Focused Video Group Activities Hashing
---

# Multi-Focused Video Group Activities Hashing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00490" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00490v2</a>
  <a href="https://arxiv.org/pdf/2509.00490.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00490v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00490v2', 'Multi-Focused Video Group Activities Hashing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhongmiao Qi, Yan Jiang, Bolin Zhang, Lijun Guo, Chong Wang, Qiangbo Qian

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30 (æ›´æ–°: 2025-11-03)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šèšç„¦è§†é¢‘ç»„æ´»åŠ¨å“ˆå¸ŒæŠ€æœ¯ä»¥è§£å†³è§†é¢‘æ£€ç´¢é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `è§†é¢‘æ£€ç´¢` `ç»„æ´»åŠ¨è¯†åˆ«` `æ—¶ç©ºç‰¹å¾` `å¤šèšç„¦å­¦ä¹ ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘æ£€ç´¢æ–¹æ³•å¤šé›†ä¸­äºæ•´ä¸ªè§†é¢‘ï¼Œéš¾ä»¥æ»¡è¶³å¯¹å…·ä½“æ´»åŠ¨ç²’åº¦çš„æ£€ç´¢éœ€æ±‚ã€‚
2. æœ¬æ–‡æå‡ºçš„STVHæŠ€æœ¯é€šè¿‡å»ºæ¨¡ä¸ªä½“ä¸ç»„é—´çš„åŠ¨æ€äº¤äº’ï¼Œé¦–æ¬¡å®ç°äº†æ´»åŠ¨ä¸è§†è§‰ç‰¹å¾çš„è”åˆå»ºæ¨¡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSTVHå’ŒM-STVHåœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æå‡äº†æ£€ç´¢æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€è§†é¢‘æ•°æ®åœ¨å„ç§å¤æ‚åœºæ™¯ä¸­çš„çˆ†ç‚¸æ€§å¢é•¿ï¼Œå¿«é€Ÿæ£€ç´¢ç»„æ´»åŠ¨å·²æˆä¸ºä¸€ä¸ªç´§è¿«çš„é—®é¢˜ã€‚ç„¶è€Œï¼Œè®¸å¤šç°æœ‰ä»»åŠ¡åªèƒ½æ£€ç´¢æ•´ä¸ªè§†é¢‘ï¼Œè€Œæ— æ³•å…³æ³¨æ´»åŠ¨çš„ç²’åº¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡é¦–æ¬¡æå‡ºäº†ä¸€ç§æ–°çš„æ—¶ç©ºäº¤é”™è§†é¢‘å“ˆå¸Œï¼ˆSTVHï¼‰æŠ€æœ¯ã€‚é€šè¿‡ç»Ÿä¸€æ¡†æ¶ï¼ŒSTVHåŒæ—¶å»ºæ¨¡ä¸ªä½“å¯¹è±¡åŠ¨æ€å’Œç»„é—´äº¤äº’ï¼Œæ•æ‰ç»„è§†è§‰ç‰¹å¾å’Œä½ç½®ç‰¹å¾çš„æ—¶ç©ºæ¼”å˜ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹å®é™…è§†é¢‘æ£€ç´¢åœºæ™¯ä¸­å¯¹æ´»åŠ¨ç‰¹å¾å’Œå¯¹è±¡è§†è§‰ç‰¹å¾çš„ä¸åŒéœ€æ±‚ï¼Œè¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§å¢å¼ºç‰ˆçš„å¤šèšç„¦æ—¶ç©ºè§†é¢‘å“ˆå¸Œï¼ˆM-STVHï¼‰ã€‚è¯¥æ–¹æ³•é€šè¿‡å¤šèšç„¦è¡¨ç¤ºå­¦ä¹ æ•´åˆå±‚æ¬¡ç‰¹å¾ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå…±åŒå…³æ³¨æ´»åŠ¨è¯­ä¹‰ç‰¹å¾å’Œå¯¹è±¡è§†è§‰ç‰¹å¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSTVHå’ŒM-STVHåœ¨å…¬å¼€æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ•ˆæœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å¤æ‚è§†é¢‘åœºæ™¯ä¸­å¿«é€Ÿæ£€ç´¢ç»„æ´»åŠ¨çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€åªèƒ½å¤„ç†æ•´ä½“è§†é¢‘ï¼Œæ— æ³•é’ˆå¯¹å…·ä½“æ´»åŠ¨è¿›è¡Œæœ‰æ•ˆæ£€ç´¢ï¼Œå¯¼è‡´æ£€ç´¢æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„STVHæŠ€æœ¯é€šè¿‡åŒæ—¶å»ºæ¨¡ä¸ªä½“å¯¹è±¡çš„åŠ¨æ€å’Œç»„é—´çš„äº¤äº’ï¼Œæ•æ‰æ—¶ç©ºæ¼”å˜ï¼Œè¿›è€Œå®ç°å¯¹æ´»åŠ¨å’Œè§†è§‰ç‰¹å¾çš„æœ‰æ•ˆæ•´åˆã€‚M-STVHä½œä¸ºå¢å¼ºç‰ˆï¼Œè¿›ä¸€æ­¥é€šè¿‡å¤šèšç„¦è¡¨ç¤ºå­¦ä¹ æ¥å¤„ç†ä¸åŒç‰¹å¾éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šSTVHç”¨äºåŸºç¡€çš„æ—¶ç©ºç‰¹å¾å»ºæ¨¡ï¼ŒM-STVHåˆ™åœ¨æ­¤åŸºç¡€ä¸Šå¼•å…¥å±‚æ¬¡ç‰¹å¾æ•´åˆã€‚æ¨¡å‹é€šè¿‡è”åˆè®­ç»ƒæ¥ä¼˜åŒ–æ´»åŠ¨è¯­ä¹‰å’Œå¯¹è±¡è§†è§‰ç‰¹å¾çš„æå–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé¦–æ¬¡æå‡ºäº†STVHå’ŒM-STVHæŠ€æœ¯ï¼Œèƒ½å¤ŸåŒæ—¶å…³æ³¨æ´»åŠ¨å’Œè§†è§‰ç‰¹å¾çš„æ—¶ç©ºæ¼”å˜ï¼Œæ˜¾è‘—æå‡äº†è§†é¢‘æ£€ç´¢çš„ç²¾åº¦å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šå±‚æ¬¡çš„ç‰¹å¾èåˆç­–ç•¥ï¼ŒæŸå¤±å‡½æ•°ç»“åˆäº†æ´»åŠ¨è¯†åˆ«å’Œå¯¹è±¡æ£€æµ‹çš„ç›®æ ‡ï¼Œç½‘ç»œç»“æ„åˆ™åŸºäºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰è¿›è¡Œä¼˜åŒ–ï¼Œä»¥é€‚åº”æ—¶ç©ºç‰¹å¾çš„æå–éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSTVHå’ŒM-STVHåœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨æ´»åŠ¨æ£€ç´¢ç²¾åº¦ä¸Šï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æå‡å¹…åº¦è¶…è¿‡20%ã€‚è¿™äº›ç»“æœéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½ç›‘æ§ã€ç¤¾äº¤åª’ä½“è§†é¢‘åˆ†æå’Œä½“è‚²èµ›äº‹å›æ”¾ç­‰ã€‚é€šè¿‡æé«˜è§†é¢‘æ£€ç´¢çš„ç²¾åº¦å’Œæ•ˆç‡ï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´ä¸ºç²¾å‡†çš„å†…å®¹æ¨èå’Œä¿¡æ¯æ£€ç´¢æœåŠ¡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the explosive growth of video data in various complex scenarios, quickly retrieving group activities has become an urgent problem. However, many tasks can only retrieve videos focusing on an entire video, not the activity granularity. To solve this problem, we propose a new STVH (spatiotemporal interleaved video hashing) technique for the first time. Through a unified framework, the STVH simultaneously models individual object dynamics and group interactions, capturing the spatiotemporal evolution on both group visual features and positional features. Moreover, in real-life video retrieval scenarios, it may sometimes require activity features, while at other times, it may require visual features of objects. We then further propose a novel M-STVH (multi-focused spatiotemporal video hashing) as an enhanced version to handle this difficult task. The advanced method incorporates hierarchical feature integration through multi-focused representation learning, allowing the model to jointly focus on activity semantics features and object visual features. We conducted comparative experiments on publicly available datasets, and both STVH and M-STVH can achieve excellent results.

