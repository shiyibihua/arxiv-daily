---
layout: default
title: SurgLLM: A Versatile Large Multimodal Model with Spatial Focus and Temporal Awareness for Surgical Video Understanding
---

# SurgLLM: A Versatile Large Multimodal Model with Spatial Focus and Temporal Awareness for Surgical Video Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00357" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.00357v1</a>
  <a href="https://arxiv.org/pdf/2509.00357.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00357v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00357v1', 'SurgLLM: A Versatile Large Multimodal Model with Spatial Focus and Temporal Awareness for Surgical Video Understanding')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zhen Chen, Xingjian Luo, Kun Yuan, Jinlin Wu, Danny T. M. Chan, Nassir Navab, Hongbin Liu, Zhen Lei, Jiebo Luo

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-30

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/franciszchen/SurgLLM)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SurgLLM‰ª•Ëß£ÂÜ≥Â§ñÁßëËßÜÈ¢ëÁêÜËß£‰∏≠ÁöÑÁ©∫Èó¥ÂíåÊó∂Èó¥ÊÑüÁü•‰∏çË∂≥ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ñÁßëËßÜÈ¢ëÁêÜËß£` `Â§öÊ®°ÊÄÅÊ®°Âûã` `Êó∂Èó¥ÊÑüÁü•` `Á©∫Èó¥ËÅöÁÑ¶` `ËÆ°ÁÆóÊú∫ËæÖÂä©Â§ñÁßë` `ËßÜÈ¢ëÁºñÁ†Å` `Â§öÊ®°ÊÄÅÂØπÈΩê` `Âä®ÊÄÅÈõÜÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Â§ñÁßëËßÜÈ¢ëÁêÜËß£‰∏≠Â≠òÂú®ËßÜËßâÂÜÖÂÆπÊÑüÁü•‰∏çË∂≥ÂíåÊó∂Èó¥ÊÑüÁü•‰∏çË∂≥ÁöÑÈóÆÈ¢òÔºåÈôêÂà∂‰∫ÜËÆ°ÁÆóÊú∫ËæÖÂä©Â§ñÁßëÁ≥ªÁªüÁöÑÂ§öÊ†∑ÂåñÂ∫îÁî®„ÄÇ
2. Êú¨ÊñáÊèêÂá∫SurgLLMÊ°ÜÊû∂ÔºåÈÄöËøáÂ§ñÁßë‰∏ä‰∏ãÊñáÊÑüÁü•ÁöÑÂ§öÊ®°ÊÄÅÈ¢ÑËÆ≠ÁªÉÂíåÊó∂Èó¥ÊÑüÁü•ÁöÑÂ§öÊ®°ÊÄÅË∞É‰ºòÔºåÂ¢ûÂº∫Â§ñÁßëËßÜÈ¢ëÁöÑÁ©∫Èó¥ËÅöÁÑ¶ÂíåÊó∂Èó¥ÊÑüÁü•ËÉΩÂäõ„ÄÇ
3. Âú®Â§öÈ°πÂ§ñÁßëËßÜÈ¢ëÁêÜËß£‰ªªÂä°‰∏äËøõË°åÁöÑÂπøÊ≥õÂÆûÈ™åË°®ÊòéÔºåSurgLLMÂú®ËßÜÈ¢ëÂ≠óÂπïÁîüÊàê„ÄÅ‰∏ÄËà¨ËßÜËßâÈóÆÁ≠îÂíåÊó∂Èó¥ËßÜËßâÈóÆÁ≠îÁ≠â‰ªªÂä°‰∏äÊòæËëóË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ñÁßëËßÜÈ¢ëÁêÜËß£ÂØπËÆ°ÁÆóÊú∫ËæÖÂä©Â§ñÁßëÔºàCASÔºâÁ≥ªÁªüËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂ∞ΩÁÆ°Áé∞ÊúâÁ†îÁ©∂ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜ‰ªçÂ≠òÂú®ËßÜËßâÂÜÖÂÆπÊÑüÁü•‰∏çË∂≥ÂíåÊó∂Èó¥ÊÑüÁü•‰∏çË∂≥ÁöÑ‰∏§Â§ß‰∏ªË¶ÅÈôêÂà∂ÔºåÈòªÁ¢ç‰∫ÜÂ§öÊ†∑ÂåñCASËß£ÂÜ≥ÊñπÊ°àÁöÑÂèëÂ±ï„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜSurgLLMÊ°ÜÊû∂ÔºåËøôÊòØ‰∏ÄÁßçÊúâÊïàÁöÑÂ§ßÂûãÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºåÊó®Âú®Â¢ûÂº∫Â§ñÁßëËßÜÈ¢ëÁêÜËß£‰ªªÂä°‰∏≠ÁöÑÁ©∫Èó¥ËÅöÁÑ¶ÂíåÊó∂Èó¥ÊÑüÁü•„ÄÇÈÄöËøáËÆæËÆ°Â§ñÁßë‰∏ä‰∏ãÊñáÊÑüÁü•ÁöÑÂ§öÊ®°ÊÄÅÈ¢ÑËÆ≠ÁªÉÔºàSurg-PretrainÔºâÂíåÊó∂Èó¥ÊÑüÁü•ÁöÑÂ§öÊ®°ÊÄÅË∞É‰ºòÔºàTM-TuningÔºâÔºåSurgLLMÊòæËëóÊèêÂçá‰∫ÜÂ§ñÁßëËßÜÈ¢ëÁöÑÁêÜËß£ËÉΩÂäõ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂú®Â§ñÁßëËßÜÈ¢ëÁêÜËß£ÁöÑÂ§öÈ°π‰ªªÂä°‰∏äÔºåSurgLLMÁõ∏ËæÉ‰∫éÁé∞ÊúâÊúÄÂÖàËøõÁöÑÊñπÊ≥ïË°®Áé∞Âá∫ÊòæËëóÁöÑÊîπËøõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ñÁßëËßÜÈ¢ëÁêÜËß£‰∏≠ÁöÑÁ©∫Èó¥ÂíåÊó∂Èó¥ÊÑüÁü•‰∏çË∂≥ÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§ñÁßëËßÜÈ¢ëÊó∂ÔºåÂæÄÂæÄÊó†Ê≥ïÂÖÖÂàÜÁêÜËß£ËßÜÈ¢ë‰∏≠ÁöÑËßÜËßâÂÜÖÂÆπÂíåÊó∂Èó¥Â∫èÂàó‰ø°ÊÅØÔºåÂØºËá¥ÁêÜËß£ÊïàÊûú‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSurgLLMÊ°ÜÊû∂ÈÄöËøáÂºïÂÖ•Â§ñÁßë‰∏ä‰∏ãÊñáÊÑüÁü•ÁöÑÂ§öÊ®°ÊÄÅÈ¢ÑËÆ≠ÁªÉÂíåÊó∂Èó¥ÊÑüÁü•ÁöÑÂ§öÊ®°ÊÄÅË∞É‰ºòÔºåÊó®Âú®ÊèêÂçáÊ®°ÂûãÂØπÂ§ñÁßëËßÜÈ¢ëÁöÑÁ©∫Èó¥ËÅöÁÑ¶ÂíåÊó∂Èó¥Êé®ÁêÜËÉΩÂäõ„ÄÇËøôÊ†∑ÁöÑËÆæËÆ°‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞ÊçïÊçâÂ§ñÁßëÊâãÊúØ‰∏≠ÁöÑÂÖ≥ÈîÆÁªÜËäÇÂíåÊó∂Èó¥Âä®ÊÄÅ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSurgLLMÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Â§ñÁßë‰∏ä‰∏ãÊñáÊÑüÁü•ÁöÑÂ§öÊ®°ÊÄÅÈ¢ÑËÆ≠ÁªÉÔºàSurg-PretrainÔºâÔºåÁî®‰∫éÂ¢ûÂº∫ËßÜÈ¢ëÁºñÁ†ÅÂô®ÁöÑÁ©∫Èó¥ËÅöÁÑ¶Ôºõ2) Êó∂Èó¥ÊÑüÁü•ÁöÑÂ§öÊ®°ÊÄÅË∞É‰ºòÔºàTM-TuningÔºâÔºåÁî®‰∫éÊèêÂçáÊó∂Èó¥Êé®ÁêÜËÉΩÂäõÔºõ3) Â§ñÁßë‰ªªÂä°Âä®ÊÄÅÈõÜÊàêÔºåÁî®‰∫éÈ´òÊïàÂ§ÑÁêÜ‰∏çÂêåÁöÑÁêÜËß£‰ªªÂä°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSurgLLMÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÁªìÂêà‰∫ÜÁ©∫Èó¥ËÅöÁÑ¶ÂíåÊó∂Èó¥ÊÑüÁü•ÁöÑÂ§öÊ®°ÊÄÅÂ≠¶‰π†ÔºåÂ∞§ÂÖ∂ÊòØÈÄöËøá‰ª™Âô®‰∏≠ÂøÉÁöÑÊé©ËîΩËßÜÈ¢ëÈáçÂª∫ÔºàMV-ReconÔºâÂíå‰∫§ÈîôÁöÑÂ§öÊ®°ÊÄÅÂµåÂÖ•Êù•ÂÆûÁé∞Êó∂Èó¥Êé®ÁêÜ„ÄÇËøô‰∏éÁé∞ÊúâÊñπÊ≥ïÁöÑÂçï‰∏ÄÊ®°ÊÄÅÂ§ÑÁêÜÊñπÂºèÂΩ¢Êàê‰∫ÜÈ≤úÊòéÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞Êù•‰ºòÂåñÂ§öÊ®°ÊÄÅÂØπÈΩêÔºåÂπ∂ËÆæÁΩÆ‰∫ÜÂèØÂ≠¶‰π†ÁöÑÂèÇÊï∞‰ª•ÈÄÇÂ∫î‰∏çÂêåÁöÑÂ§ñÁßë‰ªªÂä°„ÄÇÊ≠§Â§ñÔºåÊ®°ÂûãÁöÑÁΩëÁªúÁªìÊûÑÁªèËøáÁ≤æÂøÉËÆæËÆ°Ôºå‰ª•Á°Æ‰øùÂú®Â§ÑÁêÜÂ§çÊùÇËßÜÈ¢ëÊï∞ÊçÆÊó∂ÁöÑÈ´òÊïàÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®Â§öÈ°πÂ§ñÁßëËßÜÈ¢ëÁêÜËß£‰ªªÂä°‰∏≠ÔºåSurgLLMÊòæËëóÊèêÂçá‰∫ÜÊÄßËÉΩ„ÄÇ‰æãÂ¶ÇÔºåÂú®ËßÜÈ¢ëÂ≠óÂπïÁîüÊàêÂíåËßÜËßâÈóÆÁ≠î‰ªªÂä°‰∏äÔºåÊ®°ÂûãÁöÑË°®Áé∞Ë∂ÖËøá‰∫ÜÁé∞ÊúâÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÔºåÂÖ∑‰ΩìÊèêÂçáÂπÖÂ∫¶ËææÂà∞XX%ÔºàÂÖ∑‰ΩìÊï∞ÊçÆÊú™Áü•ÔºâÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®Â§ñÁßëËßÜÈ¢ëÁêÜËß£‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SurgLLMÂú®ËÆ°ÁÆóÊú∫ËæÖÂä©Â§ñÁßëÔºàCASÔºâÁ≥ªÁªü‰∏≠ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåËÉΩÂ§üÊèêÂçáÂ§ñÁßëÊâãÊúØËøáÁ®ã‰∏≠ÁöÑËßÜÈ¢ëÁêÜËß£ËÉΩÂäõ„ÄÇËøô‰∏ÄÁ†îÁ©∂‰∏ç‰ªÖ‰∏∫Â§ñÁßëÂåªÁîüÊèê‰æõ‰∫ÜÊõ¥‰∏∫Á≤æÂáÜÁöÑËæÖÂä©Â∑•ÂÖ∑Ôºå‰πü‰∏∫Êú™Êù•ÁöÑÊô∫ËÉΩÂåªÁñóÁ≥ªÁªüÂ•†ÂÆö‰∫ÜÂü∫Á°ÄÔºåÊé®Âä®‰∫ÜÂ§ñÁßëÈ¢ÜÂüüÁöÑÊäÄÊúØËøõÊ≠•„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Surgical video understanding is crucial for facilitating Computer-Assisted Surgery (CAS) systems. Despite significant progress in existing studies, two major limitations persist, including inadequate visual content perception and insufficient temporal awareness in surgical videos, and hinder the development of versatile CAS solutions. In this work, we propose the SurgLLM framework, an effective large multimodal model tailored for versatile surgical video understanding tasks with enhanced spatial focus and temporal awareness. Specifically, to empower the spatial focus of surgical videos, we first devise Surgical Context-aware Multimodal Pretraining (Surg-Pretrain) for the video encoder of SurgLLM, by performing instrument-centric Masked Video Reconstruction (MV-Recon) and subsequent multimodal alignment. To incorporate surgical temporal knowledge into SurgLLM, we further propose Temporal-aware Multimodal Tuning (TM-Tuning) to enhance temporal reasoning with interleaved multimodal embeddings. Moreover, to accommodate various understanding tasks of surgical videos without conflicts, we devise a Surgical Task Dynamic Ensemble to efficiently triage a query with optimal learnable parameters in our SurgLLM. Extensive experiments performed on diverse surgical video understanding tasks, including captioning, general VQA, and temporal VQA, demonstrate significant improvements over the state-of-the-art approaches, validating the effectiveness of our SurgLLM in versatile surgical video understanding. The source code is available at https://github.com/franciszchen/SurgLLM.

