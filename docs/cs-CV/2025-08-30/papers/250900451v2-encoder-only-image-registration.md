---
layout: default
title: Encoder-Only Image Registration
---

# Encoder-Only Image Registration

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00451" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00451v2</a>
  <a href="https://arxiv.org/pdf/2509.00451.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00451v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00451v2', 'Encoder-Only Image Registration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiang Chen, Renjiu Hu, Jinwei Zhang, Yuxi Zhang, Xinyao Yue, Min Liu, Yaonan Wang, Hang Zhang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30 (æ›´æ–°: 2025-09-04)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/XiangChen1994/EOIR)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEncoder-Onlyå›¾åƒé…å‡†æ¡†æ¶ä»¥è§£å†³è®¡ç®—å¤æ‚æ€§ä¸å¤§å˜å½¢é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å›¾åƒé…å‡†` `å·ç§¯ç¥ç»ç½‘ç»œ` `ç‰¹å¾æå–` `æµä¼°è®¡` `å¤§å˜å½¢` `åŒ»å­¦å›¾åƒå¤„ç†` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯å˜å½¢å›¾åƒé…å‡†æ–¹æ³•åœ¨å¤„ç†å¤§å˜å½¢æ—¶è®¡ç®—å¤æ‚æ€§è¾ƒé«˜ï¼Œä¸”éš¾ä»¥å¹³è¡¡å‡†ç¡®æ€§ä¸æ•ˆç‡ã€‚
2. æœ¬æ–‡æå‡ºçš„EOIRæ¡†æ¶é€šè¿‡åˆ†ç¦»ç‰¹å¾å­¦ä¹ ä¸æµä¼°è®¡ï¼Œåˆ©ç”¨ç®€å•çš„3å±‚ConvNetå’Œæµä¼°è®¡å™¨æ¥ä¼˜åŒ–é…å‡†è¿‡ç¨‹ã€‚
3. åœ¨äº”ä¸ªä¸åŒæ¨¡æ€å’Œè§£å‰–åŒºåŸŸçš„æ•°æ®é›†ä¸Šï¼ŒEOIRå±•ç¤ºäº†åœ¨å‡†ç¡®æ€§ä¸æ•ˆç‡ä¹‹é—´çš„ä¼˜è¶Šå¹³è¡¡ï¼Œæ˜¾è‘—æå‡äº†é…å‡†æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºå­¦ä¹ çš„æŠ€æœ¯æ˜¾è‘—æé«˜äº†å¯å˜å½¢å›¾åƒé…å‡†çš„å‡†ç¡®æ€§å’Œé€Ÿåº¦ï¼Œä½†åœ¨é™ä½è®¡ç®—å¤æ‚æ€§å’Œå¤„ç†å¤§å˜å½¢æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡åˆ†æäº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆConvNetsï¼‰å¦‚ä½•å½±å“é…å‡†æ€§èƒ½ï¼Œå¹¶æå‡ºäº†Encoder-Onlyå›¾åƒé…å‡†ï¼ˆEOIRï¼‰æ¡†æ¶ã€‚EOIRé€šè¿‡å°†ç‰¹å¾å­¦ä¹ ä¸æµä¼°è®¡åˆ†ç¦»ï¼Œé‡‡ç”¨3å±‚ConvNetè¿›è¡Œç‰¹å¾æå–ï¼Œå¹¶åˆ©ç”¨ä¸€ç»„3å±‚æµä¼°è®¡å™¨æ„å»ºæ‹‰æ™®æ‹‰æ–¯ç‰¹å¾é‡‘å­—å¡”ï¼Œé€æ­¥ç»„åˆå¤§å˜å½¢æ¨¡å‹ä¸‹çš„å¾®åˆ†å˜å½¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEOIRåœ¨ä¸åŒæ¨¡æ€å’Œè§£å‰–åŒºåŸŸçš„äº”ä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºä¼˜è¶Šçš„å‡†ç¡®æ€§-æ•ˆç‡å’Œå‡†ç¡®æ€§-å¹³æ»‘æ€§æƒè¡¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¯å˜å½¢å›¾åƒé…å‡†æ–¹æ³•åœ¨å¤„ç†å¤§å˜å½¢æ—¶çš„è®¡ç®—å¤æ‚æ€§å’Œå‡†ç¡®æ€§ä¹‹é—´çš„çŸ›ç›¾ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€éš¾ä»¥åœ¨æ•ˆç‡å’Œæ•ˆæœä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEOIRæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†ç‰¹å¾å­¦ä¹ ä¸æµä¼°è®¡åˆ†å¼€ï¼Œé€šè¿‡ä½¿ç”¨ç®€å•çš„3å±‚å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œç‰¹å¾æå–ï¼Œè¿›è€Œåˆ©ç”¨æµä¼°è®¡å™¨æ„å»ºæ‹‰æ™®æ‹‰æ–¯ç‰¹å¾é‡‘å­—å¡”ï¼Œä»¥å®ç°æ›´é«˜æ•ˆçš„é…å‡†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEOIRæ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç‰¹å¾æå–æ¨¡å—å’Œæµä¼°è®¡æ¨¡å—ã€‚ç‰¹å¾æå–æ¨¡å—ä½¿ç”¨3å±‚ConvNetæå–å›¾åƒç‰¹å¾ï¼Œè€Œæµä¼°è®¡æ¨¡å—åˆ™ä½¿ç”¨ä¸€ç»„3å±‚æµä¼°è®¡å™¨æ¥å¤„ç†ç‰¹å¾ï¼Œé€æ­¥æ„å»ºå‡ºå¾®åˆ†å˜å½¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šEOIRçš„åˆ›æ–°ä¹‹å¤„åœ¨äºå…¶å°†ç‰¹å¾å­¦ä¹ ä¸æµä¼°è®¡åˆ†ç¦»çš„è®¾è®¡ï¼Œä½¿å¾—åœ¨å¤„ç†å¤§å˜å½¢æ—¶èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¿›è¡Œé…å‡†ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œä½¿ç”¨äº†3å±‚çš„å·ç§¯ç¥ç»ç½‘ç»œå’Œæµä¼°è®¡å™¨ï¼Œæ„å»ºäº†æ‹‰æ™®æ‹‰æ–¯ç‰¹å¾é‡‘å­—å¡”ï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°ä¸­è€ƒè™‘äº†å‡†ç¡®æ€§ä¸å¹³æ»‘æ€§ä¹‹é—´çš„æƒè¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨äº”ä¸ªä¸åŒæ¨¡æ€å’Œè§£å‰–åŒºåŸŸçš„æ•°æ®é›†ä¸Šï¼ŒEOIRæ¡†æ¶å®ç°äº†ä¼˜äºç°æœ‰æ–¹æ³•çš„å‡†ç¡®æ€§-æ•ˆç‡å’Œå‡†ç¡®æ€§-å¹³æ»‘æ€§æƒè¡¡ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨ä¿æŒç›¸ä¼¼å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜äº†å¤„ç†æ•ˆç‡å’Œé…å‡†å¹³æ»‘æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»å­¦å›¾åƒå¤„ç†ã€é¥æ„Ÿå›¾åƒåˆ†æä»¥åŠè®¡ç®—æœºè§†è§‰ä¸­çš„å›¾åƒé…å‡†ä»»åŠ¡ã€‚EOIRæ¡†æ¶çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ä½¿å…¶åœ¨éœ€è¦å¿«é€Ÿå¤„ç†å’Œé«˜ç²¾åº¦é…å‡†çš„åœºæ™¯ä¸­å…·æœ‰å®é™…ä»·å€¼ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Learning-based techniques have significantly improved the accuracy and speed of deformable image registration. However, challenges such as reducing computational complexity and handling large deformations persist. To address these challenges, we analyze how convolutional neural networks (ConvNets) influence registration performance using the Horn-Schunck optical flow equation. Supported by prior studies and our empirical experiments, we observe that ConvNets play two key roles in registration: linearizing local intensities and harmonizing global contrast variations. Based on these insights, we propose the Encoder-Only Image Registration (EOIR) framework, designed to achieve a better accuracy-efficiency trade-off. EOIR separates feature learning from flow estimation, employing only a 3-layer ConvNet for feature extraction and a set of 3-layer flow estimators to construct a Laplacian feature pyramid, progressively composing diffeomorphic deformations under a large-deformation model. Results on five datasets across different modalities and anatomical regions demonstrate EOIR's effectiveness, achieving superior accuracy-efficiency and accuracy-smoothness trade-offs. With comparable accuracy, EOIR provides better efficiency and smoothness, and vice versa. The source code of EOIR is publicly available on https://github.com/XiangChen1994/EOIR.

