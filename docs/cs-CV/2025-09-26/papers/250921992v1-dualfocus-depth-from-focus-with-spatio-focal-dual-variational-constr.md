---
layout: default
title: DualFocus: Depth from Focus with Spatio-Focal Dual Variational Constraints
---

# DualFocus: Depth from Focus with Spatio-Focal Dual Variational Constraints

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21992" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21992v1</a>
  <a href="https://arxiv.org/pdf/2509.21992.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21992v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21992v1', 'DualFocus: Depth from Focus with Spatio-Focal Dual Variational Constraints')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sungmin Woo, Sangyoun Lee

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

**å¤‡æ³¨**: Accepted by NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DualFocusï¼šåˆ©ç”¨ç©ºåŸŸ-ç„¦åŸŸåŒé‡å˜åˆ†çº¦æŸçš„æ™¯æ·±ä¼°è®¡æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `æ™¯æ·±ä¼°è®¡` `ç„¦ç‚¹çº¿ç´¢` `å˜åˆ†æ–¹æ³•` `ç©ºé—´çº¦æŸ` `ç„¦åŸŸçº¦æŸ` `æ·±åº¦å­¦ä¹ ` `å›¾åƒå¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºå­¦ä¹ çš„DFFæ–¹æ³•åœ¨å¤„ç†å¤æ‚åœºæ™¯æ—¶ï¼Œç”±äºç„¦ç‚¹çº¿ç´¢æ¨¡ç³Šæˆ–è¯¯å¯¼ï¼Œæ·±åº¦ä¼°è®¡ç²¾åº¦ä¼šä¸‹é™ã€‚
2. DualFocusé€šè¿‡è”åˆå»ºæ¨¡ç©ºé—´å’Œç„¦åŸŸçš„ç„¦ç‚¹å˜åŒ–ï¼Œå¹¶å¼•å…¥åŒé‡å˜åˆ†çº¦æŸæ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDualFocusåœ¨æ·±åº¦ç²¾åº¦å’Œæ„ŸçŸ¥è´¨é‡ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚åœºæ™¯ä¸­ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºDualFocusçš„æ™¯æ·±ä¼°è®¡(DFF)æ–°æ¡†æ¶ã€‚DFFé€šè¿‡åˆ†æä¸åŒç„¦è·ä¸‹æ‹æ‘„çš„å›¾åƒæ ˆä¸­çš„ç„¦ç‚¹çº¿ç´¢æ¥å®ç°ç²¾ç¡®çš„æ·±åº¦ä¼°è®¡ã€‚è™½ç„¶æœ€è¿‘åŸºäºå­¦ä¹ çš„æ–¹æ³•åœ¨è¯¥é¢†åŸŸå–å¾—äº†è¿›å±•ï¼Œä½†å®ƒä»¬åœ¨å…·æœ‰ç²¾ç»†çº¹ç†æˆ–çªå˜æ·±åº¦å˜åŒ–çš„å¤æ‚åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼Œå› ä¸ºåœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œç„¦ç‚¹çº¿ç´¢å¯èƒ½å˜å¾—æ¨¡ç³Šæˆ–å…·æœ‰è¯¯å¯¼æ€§ã€‚DualFocusåˆ©ç”¨ç„¦ç‚¹å˜åŒ–å¼•èµ·çš„ç„¦ç‚¹æ ˆç‹¬ç‰¹çš„æ¢¯åº¦æ¨¡å¼ï¼Œè”åˆå»ºæ¨¡ç©ºé—´å’Œç„¦åŸŸç»´åº¦ä¸Šçš„ç„¦ç‚¹å˜åŒ–ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ç§å…·æœ‰é’ˆå¯¹DFFçš„åŒé‡çº¦æŸçš„å˜åˆ†å…¬å¼ï¼šç©ºé—´çº¦æŸåˆ©ç”¨ç„¦ç‚¹æ°´å¹³ä¸Šçš„æ¢¯åº¦æ¨¡å¼å˜åŒ–æ¥åŒºåˆ†çœŸå®æ·±åº¦è¾¹ç¼˜å’Œçº¹ç†ä¼ªå½±ï¼Œè€Œç„¦åŸŸçº¦æŸå¼ºåˆ¶æ‰§è¡Œä¸ç‰©ç†ç„¦ç‚¹è¡Œä¸ºå¯¹é½çš„å•å³°ã€å•è°ƒç„¦ç‚¹æ¦‚ç‡ã€‚è¿™äº›å½’çº³åç½®æé«˜äº†åœ¨å…·æœ‰æŒ‘æˆ˜æ€§åŒºåŸŸçš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚åœ¨å››ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒDualFocusåœ¨æ·±åº¦ç²¾åº¦å’Œæ„ŸçŸ¥è´¨é‡æ–¹é¢å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„åŸºäºå­¦ä¹ çš„Depth-from-Focus (DFF)æ–¹æ³•åœ¨å¤„ç†å…·æœ‰ç²¾ç»†çº¹ç†æˆ–æ·±åº¦çªå˜çš„å¤æ‚åœºæ™¯æ—¶ï¼Œç”±äºç„¦ç‚¹çº¿ç´¢çš„æ¨¡ç³Šæ€§æˆ–è¯¯å¯¼æ€§ï¼Œæ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ä¼šå—åˆ°å½±å“ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥åŒºåˆ†çœŸå®çš„æ·±åº¦è¾¹ç¼˜å’Œçº¹ç†ä¼ªå½±ï¼Œå¯¼è‡´æ·±åº¦ä¼°è®¡ç»“æœä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDualFocusçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ç„¦ç‚¹æ ˆä¸­ç”±ç„¦ç‚¹å˜åŒ–å¼•èµ·çš„ç‹¬ç‰¹æ¢¯åº¦æ¨¡å¼ï¼Œå¹¶è”åˆå»ºæ¨¡ç©ºé—´å’Œç„¦åŸŸç»´åº¦ä¸Šçš„ç„¦ç‚¹å˜åŒ–ã€‚é€šè¿‡å¼•å…¥ç©ºé—´å’Œç„¦åŸŸçš„åŒé‡å˜åˆ†çº¦æŸï¼Œå¯ä»¥æ›´å¥½åœ°åˆ©ç”¨ç„¦ç‚¹ä¿¡æ¯ï¼Œä»è€Œæé«˜æ·±åº¦ä¼°è®¡çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚ç©ºé—´çº¦æŸç”¨äºåŒºåˆ†çœŸå®æ·±åº¦è¾¹ç¼˜å’Œçº¹ç†ä¼ªå½±ï¼Œè€Œç„¦åŸŸçº¦æŸåˆ™å¼ºåˆ¶æ‰§è¡Œä¸ç‰©ç†ç„¦ç‚¹è¡Œä¸ºä¸€è‡´çš„å•å³°ã€å•è°ƒç„¦ç‚¹æ¦‚ç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDualFocusæ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) è¾“å…¥ç„¦ç‚¹æ ˆå›¾åƒï¼›2) è®¡ç®—æ¯ä¸ªåƒç´ åœ¨ä¸åŒç„¦è·ä¸‹çš„ç„¦ç‚¹åº¦é‡ï¼›3) æ„å»ºåŒ…å«ç©ºé—´å’Œç„¦åŸŸçº¦æŸçš„å˜åˆ†èƒ½é‡å‡½æ•°ï¼›4) é€šè¿‡ä¼˜åŒ–è¯¥èƒ½é‡å‡½æ•°ï¼Œå¾—åˆ°æœ€ç»ˆçš„æ·±åº¦ä¼°è®¡ç»“æœã€‚è¯¥æ¡†æ¶åˆ©ç”¨å˜åˆ†æ–¹æ³•å°†æ·±åº¦ä¼°è®¡é—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªèƒ½é‡æœ€å°åŒ–é—®é¢˜ï¼Œå¹¶é€šè¿‡è¿­ä»£ä¼˜åŒ–ç®—æ³•æ±‚è§£ã€‚

**å…³é”®åˆ›æ–°**ï¼šDualFocusçš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ç©ºåŸŸ-ç„¦åŸŸåŒé‡å˜åˆ†çº¦æŸã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDualFocusä¸ä»…è€ƒè™‘äº†ç©ºé—´åŸŸä¸Šçš„ç„¦ç‚¹å˜åŒ–ï¼Œè¿˜è€ƒè™‘äº†ç„¦åŸŸä¸Šçš„ç„¦ç‚¹å˜åŒ–ï¼Œä»è€Œæ›´å…¨é¢åœ°åˆ©ç”¨äº†ç„¦ç‚¹ä¿¡æ¯ã€‚æ­¤å¤–ï¼ŒDualFocusé€šè¿‡å¼•å…¥ç©ºé—´çº¦æŸå’Œç„¦åŸŸçº¦æŸï¼Œæœ‰æ•ˆåœ°æŠ‘åˆ¶äº†çº¹ç†ä¼ªå½±ï¼Œå¹¶ä¿è¯äº†æ·±åº¦ä¼°è®¡ç»“æœçš„ç‰©ç†ä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨DualFocusä¸­ï¼Œç©ºé—´çº¦æŸé€šè¿‡æ¢¯åº¦ç®—å­å®ç°ï¼Œç”¨äºè¡¡é‡ç›¸é‚»åƒç´ ä¹‹é—´çš„æ·±åº¦å·®å¼‚ã€‚ç„¦åŸŸçº¦æŸåˆ™é€šè¿‡å•è°ƒæ€§å’Œå•å³°æ€§çº¦æŸå®ç°ï¼Œç”¨äºä¿è¯ç„¦ç‚¹æ¦‚ç‡åˆ†å¸ƒçš„ç‰©ç†åˆç†æ€§ã€‚èƒ½é‡å‡½æ•°çš„è®¾è®¡è‡³å…³é‡è¦ï¼Œå®ƒéœ€è¦å¹³è¡¡ç©ºé—´çº¦æŸå’Œç„¦åŸŸçº¦æŸä¹‹é—´çš„æƒé‡ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œä¼˜åŒ–ç®—æ³•çš„é€‰æ‹©ä¹Ÿä¼šå½±å“æœ€ç»ˆçš„æ·±åº¦ä¼°è®¡ç»“æœã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦è€ƒè™‘åˆ°æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§å’Œå¹³æ»‘æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DualFocusåœ¨å››ä¸ªå…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ï¼ŒDualFocusåœ¨æ·±åº¦ç²¾åº¦å’Œæ„ŸçŸ¥è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸä¸ªæ•°æ®é›†ä¸Šï¼ŒDualFocusçš„å¹³å‡ç»å¯¹è¯¯å·®(MAE)æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•é™ä½äº†10%ä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒDualFocusåœ¨å¤„ç†å…·æœ‰ç²¾ç»†çº¹ç†å’Œæ·±åº¦çªå˜çš„å¤æ‚åœºæ™¯æ—¶ï¼Œè¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DualFocusæŠ€æœ¯å¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€ä¸‰ç»´é‡å»ºã€å›¾åƒç¼–è¾‘ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œå‡†ç¡®çš„æ·±åº¦ä¿¡æ¯å¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°æ„ŸçŸ¥å‘¨å›´ç¯å¢ƒï¼Œä»è€Œå®ç°è‡ªä¸»å¯¼èˆªã€‚åœ¨ä¸‰ç»´é‡å»ºä¸­ï¼ŒDualFocuså¯ä»¥ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„ä¸‰ç»´æ¨¡å‹ã€‚åœ¨å›¾åƒç¼–è¾‘ä¸­ï¼Œå¯ä»¥å®ç°é€¼çœŸçš„æ™¯æ·±æ•ˆæœã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥æé«˜è½¦è¾†å¯¹å‘¨å›´ç¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œä»è€Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Depth-from-Focus (DFF) enables precise depth estimation by analyzing focus cues across a stack of images captured at varying focal lengths. While recent learning-based approaches have advanced this field, they often struggle in complex scenes with fine textures or abrupt depth changes, where focus cues may become ambiguous or misleading. We present DualFocus, a novel DFF framework that leverages the focal stack's unique gradient patterns induced by focus variation, jointly modeling focus changes over spatial and focal dimensions. Our approach introduces a variational formulation with dual constraints tailored to DFF: spatial constraints exploit gradient pattern changes across focus levels to distinguish true depth edges from texture artifacts, while focal constraints enforce unimodal, monotonic focus probabilities aligned with physical focus behavior. These inductive biases improve robustness and accuracy in challenging regions. Comprehensive experiments on four public datasets demonstrate that DualFocus consistently outperforms state-of-the-art methods in both depth accuracy and perceptual quality.

