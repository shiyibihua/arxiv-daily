---
layout: default
title: LongScape: Advancing Long-Horizon Embodied World Models with Context-Aware MoE
---

# LongScape: Advancing Long-Horizon Embodied World Models with Context-Aware MoE

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21790" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21790v1</a>
  <a href="https://arxiv.org/pdf/2509.21790.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21790v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21790v1', 'LongScape: Advancing Long-Horizon Embodied World Models with Context-Aware MoE')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yu Shang, Lei Jin, Yiding Ma, Xin Zhang, Chen Gao, Wei Wu, Yong Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

**å¤‡æ³¨**: 13 pages, 8 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/tsinghua-fib-lab/Longscape)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**LongScapeï¼šæå‡ºä¸Šä¸‹æ–‡æ„ŸçŸ¥MoEçš„é•¿æ—¶ç¨‹å…·èº«ä¸–ç•Œæ¨¡å‹ï¼Œè§£å†³è§†é¢‘ç”Ÿæˆä¸­çš„æ—¶åºä¸ä¸€è‡´é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `é•¿æ—¶ç¨‹ç”Ÿæˆ` `å…·èº«ä¸–ç•Œæ¨¡å‹` `è§†é¢‘ç”Ÿæˆ` `æ‰©æ•£æ¨¡å‹` `è‡ªå›å½’æ¨¡å‹` `æ··åˆä¸“å®¶æ¨¡å‹` `åŠ¨ä½œå¼•å¯¼` `æœºå™¨äººæ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºæ‰©æ•£çš„è§†é¢‘ç”Ÿæˆæ–¹æ³•åœ¨é•¿æ—¶ç¨‹ç”Ÿæˆä¸­å­˜åœ¨æ—¶é—´ä¸ä¸€è‡´å’Œè§†è§‰æ¼‚ç§»é—®é¢˜ï¼Œè‡ªå›å½’æ–¹æ³•åˆ™ç‰ºç‰²äº†è§†è§‰ç»†èŠ‚ã€‚
2. LongScapeé€šè¿‡åŠ¨ä½œå¼•å¯¼çš„åˆ†å—æœºåˆ¶å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ··åˆä¸“å®¶æ¨¡å‹ï¼Œè‡ªé€‚åº”åœ°ç»“åˆæ‰©æ•£æ¨¡å‹å’Œè‡ªå›å½’æ¨¡å‹ï¼Œå®ç°ç¨³å®šé•¿æ—¶ç¨‹ç”Ÿæˆã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLongScapeåœ¨é•¿æ—¶é—´rolloutä¸­å®ç°äº†ç¨³å®šå’Œä¸€è‡´çš„ç”Ÿæˆæ•ˆæœï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºLongScapeï¼Œä¸€ä¸ªæ··åˆæ¡†æ¶ï¼Œç”¨äºç”Ÿæˆé«˜è´¨é‡çš„å…·èº«æ“ä½œæ•°æ®ã€‚è¯¥æ¡†æ¶è‡ªé€‚åº”åœ°ç»“åˆäº†å—å†…æ‰©æ•£å»å™ªå’Œå—é—´è‡ªå›å½’å› æœç”Ÿæˆã€‚æ ¸å¿ƒåˆ›æ–°æ˜¯åŠ¨ä½œå¼•å¯¼çš„å¯å˜é•¿åº¦åˆ†å—æœºåˆ¶ï¼Œå®ƒåŸºäºæœºå™¨äººåŠ¨ä½œçš„è¯­ä¹‰ä¸Šä¸‹æ–‡æ¥åˆ†å‰²è§†é¢‘ï¼Œç¡®ä¿æ¯ä¸ªå—ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„ã€è¿è´¯çš„åŠ¨ä½œï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿçµæ´»åœ°ç”Ÿæˆå¤šæ ·åŒ–çš„åŠ¨æ€ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ··åˆä¸“å®¶(CMoE)æ¡†æ¶ï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­è‡ªé€‚åº”åœ°æ¿€æ´»æ¯ä¸ªå—çš„ä¸“é—¨ä¸“å®¶ï¼Œä¿è¯äº†é«˜è´¨é‡çš„è§†è§‰æ•ˆæœå’Œæ— ç¼çš„å—è¿‡æ¸¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é•¿æ—¶é—´çš„rolloutä¸­å®ç°äº†ç¨³å®šå’Œä¸€è‡´çš„é•¿æ—¶ç¨‹ç”Ÿæˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºè§†é¢‘çš„ä¸–ç•Œæ¨¡å‹åœ¨é•¿æ—¶ç¨‹ç”Ÿæˆä»»åŠ¡ä¸­é¢ä¸´æŒ‘æˆ˜ã€‚åŸºäºæ‰©æ•£çš„æ¨¡å‹å®¹æ˜“å‡ºç°æ—¶é—´ä¸ä¸€è‡´æ€§å’Œè§†è§‰æ¼‚ç§»ï¼Œè€Œè‡ªå›å½’æ¨¡å‹åˆ™å¾€å¾€ç‰ºç‰²è§†è§‰ç»†èŠ‚ä»¥ä¿è¯è¿è´¯æ€§ã€‚å› æ­¤ï¼Œå¦‚ä½•å®ç°æ—¢å…·æœ‰é«˜è§†è§‰è´¨é‡åˆä¿æŒæ—¶é—´ä¸€è‡´æ€§çš„é•¿æ—¶ç¨‹è§†é¢‘ç”Ÿæˆæ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLongScapeçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è§†é¢‘åˆ†å‰²æˆå…·æœ‰è¯­ä¹‰æ„ä¹‰çš„åŠ¨ä½œå—ï¼Œå¹¶ç»“åˆæ‰©æ•£æ¨¡å‹å’Œè‡ªå›å½’æ¨¡å‹çš„ä¼˜åŠ¿ã€‚é€šè¿‡åŠ¨ä½œå¼•å¯¼çš„åˆ†å—æœºåˆ¶ï¼Œç¡®ä¿æ¯ä¸ªå—å†…éƒ¨çš„è¿è´¯æ€§ï¼Œå¹¶åˆ©ç”¨è‡ªå›å½’æ¨¡å‹åœ¨å—é—´å»ºç«‹å› æœå…³ç³»ï¼Œä»è€Œå®ç°é•¿æ—¶ç¨‹çš„ç¨³å®šç”Ÿæˆã€‚ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ··åˆä¸“å®¶æ¨¡å‹åˆ™ç”¨äºæå‡æ¯ä¸ªå—çš„è§†è§‰è´¨é‡å’Œä¿è¯å—ä¹‹é—´çš„å¹³æ»‘è¿‡æ¸¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLongScapeçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) **åŠ¨ä½œå¼•å¯¼çš„åˆ†å—æœºåˆ¶**ï¼šæ ¹æ®æœºå™¨äººåŠ¨ä½œçš„è¯­ä¹‰ä¸Šä¸‹æ–‡å°†è§†é¢‘åˆ†å‰²æˆå¯å˜é•¿åº¦çš„å—ã€‚2) **å—å†…æ‰©æ•£å»å™ª**ï¼šä½¿ç”¨æ‰©æ•£æ¨¡å‹å¯¹æ¯ä¸ªå—è¿›è¡Œå»å™ªï¼Œæå‡è§†è§‰è´¨é‡ã€‚3) **å—é—´è‡ªå›å½’ç”Ÿæˆ**ï¼šä½¿ç”¨è‡ªå›å½’æ¨¡å‹åœ¨å—ä¹‹é—´å»ºç«‹å› æœå…³ç³»ï¼Œä¿è¯æ—¶é—´ä¸€è‡´æ€§ã€‚4) **ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ··åˆä¸“å®¶(CMoE)**ï¼šæ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè‡ªé€‚åº”åœ°é€‰æ‹©ä¸åŒçš„ä¸“å®¶æ¨¡å‹æ¥å¤„ç†æ¯ä¸ªå—ï¼Œæå‡è§†è§‰è´¨é‡å’Œä¿è¯å—ä¹‹é—´çš„å¹³æ»‘è¿‡æ¸¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šLongScapeçš„å…³é”®åˆ›æ–°åœ¨äºä»¥ä¸‹ä¸¤ç‚¹ï¼š1) **åŠ¨ä½œå¼•å¯¼çš„å¯å˜é•¿åº¦åˆ†å—æœºåˆ¶**ï¼šä¸å›ºå®šé•¿åº¦åˆ†å—ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰è§†é¢‘ä¸­çš„è¯­ä¹‰ä¿¡æ¯ï¼Œç¡®ä¿æ¯ä¸ªå—ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„åŠ¨ä½œã€‚2) **ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ··åˆä¸“å®¶(CMoE)**ï¼šèƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯è‡ªé€‚åº”åœ°é€‰æ‹©ä¸åŒçš„ä¸“å®¶æ¨¡å‹ï¼Œä»è€Œæå‡è§†è§‰è´¨é‡å’Œä¿è¯å—ä¹‹é—´çš„å¹³æ»‘è¿‡æ¸¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåŠ¨ä½œå¼•å¯¼åˆ†å—æœºåˆ¶ä¾èµ–äºå¯¹æœºå™¨äººåŠ¨ä½œçš„å‡†ç¡®è¯†åˆ«ï¼Œå…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ã€‚CMoEæ¡†æ¶ä¸­ï¼Œä¸“å®¶æ¨¡å‹çš„æ•°é‡å’Œç»“æ„éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦å¹³è¡¡è§†è§‰è´¨é‡å’Œæ—¶é—´ä¸€è‡´æ€§ï¼Œå…·ä½“å½¢å¼æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®éªŒéªŒè¯äº†LongScapeåœ¨é•¿æ—¶ç¨‹è§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLongScapeèƒ½å¤Ÿç”Ÿæˆæ¯”ç°æœ‰æ–¹æ³•æ›´ç¨³å®šã€æ›´ä¸€è‡´çš„è§†é¢‘åºåˆ—ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†LongScapeåœ¨é•¿æ—¶é—´rolloutä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LongScapeåœ¨æœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼Œæå‡æœºå™¨äººæ“ä½œçš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œå¯ä»¥ç”¨äºç”Ÿæˆå„ç§å¤æ‚çš„é©¾é©¶åœºæ™¯ï¼Œæå‡è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„é²æ£’æ€§ã€‚åœ¨æ¸¸æˆAIé¢†åŸŸï¼Œå¯ä»¥ç”¨äºç”Ÿæˆæ›´åŠ é€¼çœŸçš„æ¸¸æˆç¯å¢ƒå’Œè§’è‰²è¡Œä¸ºã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Video-based world models hold significant potential for generating high-quality embodied manipulation data. However, current video generation methods struggle to achieve stable long-horizon generation: classical diffusion-based approaches often suffer from temporal inconsistency and visual drift over multiple rollouts, while autoregressive methods tend to compromise on visual detail. To solve this, we introduce LongScape, a hybrid framework that adaptively combines intra-chunk diffusion denoising with inter-chunk autoregressive causal generation. Our core innovation is an action-guided, variable-length chunking mechanism that partitions video based on the semantic context of robotic actions. This ensures each chunk represents a complete, coherent action, enabling the model to flexibly generate diverse dynamics. We further introduce a Context-aware Mixture-of-Experts (CMoE) framework that adaptively activates specialized experts for each chunk during generation, guaranteeing high visual quality and seamless chunk transitions. Extensive experimental results demonstrate that our method achieves stable and consistent long-horizon generation over extended rollouts. Our code is available at: https://github.com/tsinghua-fib-lab/Longscape.

