---
layout: default
title: LABELING COPILOT: A Deep Research Agent for Automated Data Curation in Computer Vision
---

# LABELING COPILOT: A Deep Research Agent for Automated Data Curation in Computer Vision

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22631" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22631v1</a>
  <a href="https://arxiv.org/pdf/2509.22631.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22631v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22631v1', 'LABELING COPILOT: A Deep Research Agent for Automated Data Curation in Computer Vision')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Debargha Ganguly, Sumit Kumar, Ishwar Balappanawar, Weicong Chen, Shashank Kambhatla, Srinivasan Iyengar, Shivkumar Kalyanaraman, Ponnurangam Kumaraguru, Vipin Chaudhary

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLabeling Copilotï¼Œç”¨äºè®¡ç®—æœºè§†è§‰ä¸­è‡ªåŠ¨åŒ–æ•°æ®æ ‡æ³¨çš„æ·±åº¦ç ”ç©¶Agentã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ•°æ®æ ‡æ³¨` `è®¡ç®—æœºè§†è§‰` `æ·±åº¦å­¦ä¹ ` `Agent` `ä¸»åŠ¨å­¦ä¹ ` `å¤šæ¨¡æ€å­¦ä¹ ` `ç›®æ ‡æ£€æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é«˜è´¨é‡ã€ç‰¹å®šé¢†åŸŸæ•°æ®é›†çš„æ ‡æ³¨æ˜¯éƒ¨ç½²é²æ£’è§†è§‰ç³»ç»Ÿçš„ä¸»è¦ç“¶é¢ˆï¼Œéœ€è¦åœ¨æ•°æ®è´¨é‡ã€å¤šæ ·æ€§å’Œæˆæœ¬ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚
2. Labeling Copiloté€šè¿‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„Agentï¼Œåè°ƒæ ¡å‡†å‘ç°ã€å¯æ§åˆæˆå’Œå…±è¯†æ ‡æ³¨ä¸‰ä¸ªæ¨¡å—ï¼Œå®ç°è‡ªåŠ¨åŒ–æ•°æ®æ ‡æ³¨ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLabeling Copilotåœ¨COCOå’ŒOpen Imagesæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå¹¶åœ¨è®¡ç®—æ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»Labeling Copilotï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºè®¡ç®—æœºè§†è§‰çš„æ•°æ®æ ‡æ³¨æ·±åº¦ç ”ç©¶Agentã€‚è¯¥Agentç”±å¤§å‹å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ä¸­å¿ƒåè°ƒå™¨ç»„æˆï¼Œé€šè¿‡å¤šæ­¥éª¤æ¨ç†æ¥æ‰§è¡Œè·¨ä¸‰ä¸ªæ ¸å¿ƒåŠŸèƒ½çš„ä¸“ç”¨å·¥å…·ï¼šï¼ˆ1ï¼‰æ ¡å‡†å‘ç°ï¼šä»å¤§å‹å­˜å‚¨åº“ä¸­è·å–ç›¸å…³çš„ã€åˆ†å¸ƒå†…çš„æ•°æ®ï¼›ï¼ˆ2ï¼‰å¯æ§åˆæˆï¼šä¸ºç½•è§åœºæ™¯ç”Ÿæˆå…·æœ‰é²æ£’è¿‡æ»¤çš„æ–°æ•°æ®ï¼›ï¼ˆ3ï¼‰å…±è¯†æ ‡æ³¨ï¼šé€šè¿‡ç»“åˆéæå¤§å€¼æŠ‘åˆ¶å’ŒæŠ•ç¥¨çš„æ–°å‹å…±è¯†æœºåˆ¶ï¼Œåè°ƒå¤šä¸ªåŸºç¡€æ¨¡å‹ä»¥äº§ç”Ÿå‡†ç¡®çš„æ ‡ç­¾ã€‚å¤§è§„æ¨¡éªŒè¯è¯æ˜äº†Labeling Copilotç»„ä»¶çš„æœ‰æ•ˆæ€§ã€‚å…±è¯†æ ‡æ³¨æ¨¡å—æ“…é•¿ç›®æ ‡å‘ç°ï¼šåœ¨å¯†é›†çš„COCOæ•°æ®é›†ä¸Šï¼Œå®ƒå¹³å‡æ¯å¼ å›¾åƒäº§ç”Ÿ14.2ä¸ªå€™é€‰æè®®ï¼Œå‡ ä¹æ˜¯7.4ä¸ªçœŸå®ç›®æ ‡çš„äºŒå€ï¼Œæœ€ç»ˆæ ‡æ³¨çš„mAPè¾¾åˆ°37.1%ã€‚åœ¨ç½‘ç»œè§„æ¨¡çš„Open Imagesæ•°æ®é›†ä¸Šï¼Œå®ƒå…‹æœäº†æç«¯çš„ç±»åˆ«ä¸å¹³è¡¡ï¼Œå‘ç°äº†903ä¸ªæ–°çš„è¾¹ç•Œæ¡†ç±»åˆ«ï¼Œå°†å…¶èƒ½åŠ›æ‰©å±•åˆ°è¶…è¿‡1500ä¸ªã€‚åŒæ—¶ï¼Œæˆ‘ä»¬çš„æ ¡å‡†å‘ç°å·¥å…·åœ¨1000ä¸‡æ ·æœ¬è§„æ¨¡ä¸‹è¿›è¡Œäº†æµ‹è¯•ï¼Œå…¶ä¸»åŠ¨å­¦ä¹ ç­–ç•¥æ¯”å…·æœ‰åŒç­‰æ ·æœ¬æ•ˆç‡çš„æ›¿ä»£æ–¹æ¡ˆè®¡ç®—æ•ˆç‡é«˜å‡º40å€ã€‚è¿™äº›å®éªŒéªŒè¯äº†å…·æœ‰ä¼˜åŒ–ã€å¯æ‰©å±•å·¥å…·çš„Agentå·¥ä½œæµç¨‹ä¸ºæ ‡æ³¨å·¥ä¸šè§„æ¨¡æ•°æ®é›†æä¾›äº†å¼ºå¤§çš„åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è®¡ç®—æœºè§†è§‰é¢†åŸŸä¸­ï¼Œå¤§è§„æ¨¡æ— æ ‡æ³¨æ•°æ®é›†ä¸­é«˜æ•ˆã€é«˜è´¨é‡æ•°æ®æ ‡æ³¨çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é¢ä¸´æ•°æ®è´¨é‡ä¸é«˜ã€æ ‡æ³¨æˆæœ¬è¿‡é«˜ã€éš¾ä»¥å¤„ç†é•¿å°¾åˆ†å¸ƒç­‰æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåŸºäºAgentçš„è‡ªåŠ¨åŒ–æ•°æ®æ ‡æ³¨ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿåƒç ”ç©¶äººå‘˜ä¸€æ ·ï¼Œé€šè¿‡å¤šæ­¥éª¤æ¨ç†å’Œå·¥å…·è°ƒç”¨ï¼Œè‡ªä¸»åœ°å®Œæˆæ•°æ®å‘ç°ã€æ•°æ®ç”Ÿæˆå’Œæ•°æ®æ ‡æ³¨ç­‰ä»»åŠ¡ã€‚è¿™ç§Agenticçš„æ–¹æ³•æ—¨åœ¨æé«˜æ ‡æ³¨æ•ˆç‡ã€é™ä½æ ‡æ³¨æˆæœ¬ï¼Œå¹¶æå‡æ ‡æ³¨è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLabeling Copilotçš„æ•´ä½“æ¶æ„åŒ…å«ä¸€ä¸ªä¸­å¿ƒåè°ƒå™¨Agentå’Œä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šæ ¡å‡†å‘ç°ï¼ˆCalibrated Discoveryï¼‰ã€å¯æ§åˆæˆï¼ˆControllable Synthesisï¼‰å’Œå…±è¯†æ ‡æ³¨ï¼ˆConsensus Annotationï¼‰ã€‚ä¸­å¿ƒåè°ƒå™¨Agentè´Ÿè´£ä»»åŠ¡åˆ†è§£ã€å·¥å…·é€‰æ‹©å’Œç»“æœæ•´åˆã€‚æ ¡å‡†å‘ç°æ¨¡å—ä»å¤§å‹æ•°æ®é›†ä¸­ç­›é€‰å‡ºç›¸å…³çš„æ•°æ®æ ·æœ¬ã€‚å¯æ§åˆæˆæ¨¡å—ç”Ÿæˆç½•è§åœºæ™¯ä¸‹çš„æ•°æ®æ ·æœ¬ï¼Œä»¥å¢å¼ºæ•°æ®é›†çš„å¤šæ ·æ€§ã€‚å…±è¯†æ ‡æ³¨æ¨¡å—é€šè¿‡é›†æˆå¤šä¸ªåŸºç¡€æ¨¡å‹çš„é¢„æµ‹ç»“æœï¼Œç”Ÿæˆé«˜è´¨é‡çš„æ ‡æ³¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªå®Œæ•´çš„ã€å¯æ‰©å±•çš„Agenticæ•°æ®æ ‡æ³¨æ¡†æ¶ï¼Œå¹¶é’ˆå¯¹æ¯ä¸ªæ¨¡å—è®¾è®¡äº†ä¸“é—¨çš„ä¼˜åŒ–ç­–ç•¥ã€‚å…±è¯†æ ‡æ³¨æ¨¡å—é‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„å…±è¯†æœºåˆ¶ï¼Œç»“åˆäº†éæå¤§å€¼æŠ‘åˆ¶å’ŒæŠ•ç¥¨ç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜æ ‡æ³¨çš„å‡†ç¡®æ€§ã€‚æ ¡å‡†å‘ç°æ¨¡å—é‡‡ç”¨ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ï¼Œæ˜¾è‘—æé«˜äº†æ ·æœ¬æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…±è¯†æ ‡æ³¨æ¨¡å—ä¸­ï¼Œè®ºæ–‡é‡‡ç”¨äº†éæå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰æ¥å‡å°‘å†—ä½™çš„å€™é€‰æ¡†ï¼Œå¹¶ä½¿ç”¨æŠ•ç¥¨ç­–ç•¥æ¥é›†æˆä¸åŒæ¨¡å‹çš„é¢„æµ‹ç»“æœã€‚åœ¨æ ¡å‡†å‘ç°æ¨¡å—ä¸­ï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ç§ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ï¼Œé€šè¿‡é€‰æ‹©ä¿¡æ¯é‡æœ€å¤§çš„æ ·æœ¬è¿›è¡Œæ ‡æ³¨ï¼Œä»è€Œæé«˜æ ·æœ¬æ•ˆç‡ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡æ­£æ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLabeling Copilotåœ¨COCOæ•°æ®é›†ä¸Šå®ç°äº†37.1%çš„mAPï¼Œå¹¶ä¸”åœ¨Open Imagesæ•°æ®é›†ä¸Šå‘ç°äº†903ä¸ªæ–°çš„è¾¹ç•Œæ¡†ç±»åˆ«ã€‚æ ¡å‡†å‘ç°æ¨¡å—çš„ä¸»åŠ¨å­¦ä¹ ç­–ç•¥æ¯”å…¶ä»–æ–¹æ³•è®¡ç®—æ•ˆç‡é«˜å‡º40å€ã€‚è¿™äº›ç»“æœéªŒè¯äº†Labeling Copilotåœ¨æ•°æ®æ ‡æ³¨æ–¹é¢çš„æœ‰æ•ˆæ€§å’Œæ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Labeling Copilotå¯åº”ç”¨äºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œä¾‹å¦‚ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²å’Œå›¾åƒåˆ†ç±»ã€‚å®ƒå¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆå¿«é€Ÿæ„å»ºé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®é›†ï¼Œä»è€ŒåŠ é€Ÿè§†è§‰ç³»ç»Ÿçš„å¼€å‘å’Œéƒ¨ç½²ã€‚è¯¥ç³»ç»Ÿå°¤å…¶é€‚ç”¨äºéœ€è¦å¤„ç†å¤§è§„æ¨¡ã€é•¿å°¾åˆ†å¸ƒæ•°æ®çš„åœºæ™¯ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½å®‰é˜²å’ŒåŒ»ç–—å½±åƒåˆ†æç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Curating high-quality, domain-specific datasets is a major bottleneck for deploying robust vision systems, requiring complex trade-offs between data quality, diversity, and cost when researching vast, unlabeled data lakes. We introduce Labeling Copilot, the first data curation deep research agent for computer vision. A central orchestrator agent, powered by a large multimodal language model, uses multi-step reasoning to execute specialized tools across three core capabilities: (1) Calibrated Discovery sources relevant, in-distribution data from large repositories; (2) Controllable Synthesis generates novel data for rare scenarios with robust filtering; and (3) Consensus Annotation produces accurate labels by orchestrating multiple foundation models via a novel consensus mechanism incorporating non-maximum suppression and voting. Our large-scale validation proves the effectiveness of Labeling Copilot's components. The Consensus Annotation module excels at object discovery: on the dense COCO dataset, it averages 14.2 candidate proposals per image-nearly double the 7.4 ground-truth objects-achieving a final annotation mAP of 37.1%. On the web-scale Open Images dataset, it navigated extreme class imbalance to discover 903 new bounding box categories, expanding its capability to over 1500 total. Concurrently, our Calibrated Discovery tool, tested at a 10-million sample scale, features an active learning strategy that is up to 40x more computationally efficient than alternatives with equivalent sample efficiency. These experiments validate that an agentic workflow with optimized, scalable tools provides a robust foundation for curating industrial-scale datasets.

