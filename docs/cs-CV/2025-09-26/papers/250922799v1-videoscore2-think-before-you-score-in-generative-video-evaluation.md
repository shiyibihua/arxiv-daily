---
layout: default
title: VideoScore2: Think before You Score in Generative Video Evaluation
---

# VideoScore2: Think before You Score in Generative Video Evaluation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22799" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22799v1</a>
  <a href="https://arxiv.org/pdf/2509.22799.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22799v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22799v1', 'VideoScore2: Think before You Score in Generative Video Evaluation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xuan He, Dongfu Jiang, Ping Nie, Minghao Liu, Zhengxuan Jiang, Mingyi Su, Wentao Ma, Junru Lin, Chun Ye, Yi Lu, Keming Wu, Benjamin Schneider, Quy Duc Do, Zhuofeng Li, Yiming Jia, Yuxuan Zhang, Guo Cheng, Haozhe Wang, Wangchunshu Zhou, Qunshu Lin, Yuanxing Zhang, Ge Zhang, Wenhao Huang, Wenhu Chen

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://tiger-ai-lab.github.io/VideoScore2/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VideoScore2ï¼šæå‡ºå¤šç»´åº¦ã€å¯è§£é‡Šçš„è§†é¢‘ç”Ÿæˆè¯„ä¼°æ¡†æ¶ï¼Œæå‡è¯„ä¼°å‡†ç¡®æ€§å’Œå¯æ§æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆè¯„ä¼°` `å¤šç»´åº¦è¯„ä¼°` `å¯è§£é‡Šæ€§` `æ€ç»´é“¾` `å¼ºåŒ–å­¦ä¹ ` `GRPO` `æ–‡æœ¬åˆ°è§†é¢‘` `è§†é¢‘è´¨é‡è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘ç”Ÿæˆè¯„ä¼°æ–¹æ³•ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œæ— æ³•æä¾›ç»†ç²’åº¦çš„åˆ†æï¼Œéš¾ä»¥å…¨é¢è¯„ä¼°è§†é¢‘è´¨é‡ã€‚
2. VideoScore2é€šè¿‡å¤šç»´åº¦è¯„ä¼°ï¼ˆè§†è§‰è´¨é‡ã€è¯­ä¹‰å¯¹é½ã€ç‰©ç†ä¸€è‡´æ€§ï¼‰å’Œæ€ç»´é“¾æ¨ç†ï¼Œå®ç°å¯è§£é‡Šçš„è§†é¢‘è¯„ä¼°ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVideoScore2åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†è¯„ä¼°å‡†ç¡®æ€§ï¼Œå¹¶èƒ½æœ‰æ•ˆæ”¯æŒå¯æ§è§†é¢‘ç”Ÿæˆã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡æœ¬åˆ°è§†é¢‘ç”ŸæˆæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†è§†é¢‘è¯„ä¼°ä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºè§†é¢‘åœ¨è§†è§‰è´¨é‡ã€è¯­ä¹‰å¯¹é½å’Œç‰©ç†ä¸€è‡´æ€§ç­‰å¤šæ–¹é¢éƒ½å…·æœ‰å¤æ‚æ€§ã€‚ç°æœ‰çš„è¯„ä¼°å™¨å’Œå¥–åŠ±æ¨¡å‹é€šå¸¸åªæä¾›å•ä¸€çš„ã€ä¸é€æ˜çš„åˆ†æ•°ï¼Œç¼ºä¹å¯è§£é‡Šæ€§ï¼Œæˆ–è€…åªèƒ½æä¾›ç²—ç•¥çš„åˆ†æï¼Œæ— æ³•å…¨é¢æ•æ‰è§†é¢‘è´¨é‡è¯„ä¼°çš„æœ¬è´¨ã€‚æœ¬æ–‡æå‡ºäº†VideoScore2ï¼Œä¸€ä¸ªå¤šç»´åº¦ã€å¯è§£é‡Šä¸”ä¸äººç±»å¯¹é½çš„æ¡†æ¶ï¼Œå®ƒæ˜¾å¼åœ°è¯„ä¼°è§†è§‰è´¨é‡ã€æ–‡æœ¬åˆ°è§†é¢‘çš„å¯¹é½ä»¥åŠç‰©ç†/å¸¸è¯†ä¸€è‡´æ€§ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„æ€ç»´é“¾æ¨ç†è¿‡ç¨‹ã€‚è¯¥æ¨¡å‹åœ¨åŒ…å«27168ä¸ªäººå·¥æ ‡æ³¨è§†é¢‘çš„å¤§è§„æ¨¡æ•°æ®é›†VideoFeedback2ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¯¥æ•°æ®é›†åŒ…å«ä¸‰ä¸ªç»´åº¦çš„åˆ†æ•°å’Œæ¨ç†è½¨è¿¹ï¼Œä½¿ç”¨ç›‘ç£å¾®è°ƒå’ŒåŸºäºGroup Relative Policy Optimization (GRPO)çš„å¼ºåŒ–å­¦ä¹ çš„ä¸¤é˜¶æ®µæµç¨‹ï¼Œä»¥å¢å¼ºåˆ†æçš„é²æ£’æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒVideoScore2åœ¨æˆ‘ä»¬çš„é¢†åŸŸå†…åŸºå‡†VideoScore-Bench-v2ä¸Šå®ç°äº†44.35 (+5.94)çš„å‡†ç¡®ç‡ï¼Œå¹¶åœ¨å››ä¸ªé¢†åŸŸå¤–åŸºå‡†ï¼ˆVideoGenReward-Benchã€VideoPhy2ç­‰ï¼‰ä¸Šå®ç°äº†50.37 (+4.32)çš„å¹³å‡æ€§èƒ½ï¼ŒåŒæ—¶æä¾›å¯è§£é‡Šçš„è¯„ä¼°ï¼Œé€šè¿‡æœ‰æ•ˆçš„å¥–åŠ±å»ºæ¨¡æ¥å¼¥åˆè¯„ä¼°å’Œå¯æ§ç”Ÿæˆä¹‹é—´çš„å·®è·ï¼Œä»è€Œå®ç°Best-of-Né‡‡æ ·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå½“å‰æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆè¯„ä¼°æ–¹æ³•ä¸»è¦å­˜åœ¨ä¸‰ä¸ªç—›ç‚¹ï¼šä¸€æ˜¯è¯„ä¼°ç»“æœç¼ºä¹å¯è§£é‡Šæ€§ï¼Œéš¾ä»¥ç†è§£æ¨¡å‹åˆ¤æ–­ä¾æ®ï¼›äºŒæ˜¯è¯„ä¼°ç»´åº¦å•ä¸€ï¼Œæ— æ³•å…¨é¢è¡¡é‡è§†é¢‘è´¨é‡ï¼ˆè§†è§‰è´¨é‡ã€è¯­ä¹‰å¯¹é½ã€ç‰©ç†ä¸€è‡´æ€§ï¼‰ï¼›ä¸‰æ˜¯è¯„ä¼°ç»“æœä¸äººç±»æ„ŸçŸ¥å­˜åœ¨åå·®ï¼Œéš¾ä»¥æŒ‡å¯¼è§†é¢‘ç”Ÿæˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVideoScore2çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è§†é¢‘è¯„ä¼°åˆ†è§£ä¸ºå¤šä¸ªç»´åº¦ï¼Œå¹¶å¼•å…¥æ€ç»´é“¾æ¨ç†ï¼Œä»è€Œæé«˜è¯„ä¼°çš„å¯è§£é‡Šæ€§å’Œå‡†ç¡®æ€§ã€‚é€šè¿‡æ˜¾å¼åœ°è¯„ä¼°è§†è§‰è´¨é‡ã€æ–‡æœ¬åˆ°è§†é¢‘çš„å¯¹é½ä»¥åŠç‰©ç†/å¸¸è¯†ä¸€è‡´æ€§ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„æ¨ç†è¿‡ç¨‹ï¼Œä½¿å¾—è¯„ä¼°ç»“æœæ›´æ˜“äºç†è§£å’Œä¿¡ä»»ã€‚åŒæ—¶ï¼Œåˆ©ç”¨å¤§è§„æ¨¡äººå·¥æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä½¿å¾—æ¨¡å‹è¯„ä¼°ç»“æœæ›´ç¬¦åˆäººç±»æ„ŸçŸ¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVideoScore2é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ã€‚ç¬¬ä¸€é˜¶æ®µæ˜¯ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œä½¿ç”¨VideoFeedback2æ•°æ®é›†ï¼Œè®­ç»ƒæ¨¡å‹é¢„æµ‹äººå·¥æ ‡æ³¨çš„åˆ†æ•°å’Œæ¨ç†è¿‡ç¨‹ã€‚ç¬¬äºŒé˜¶æ®µæ˜¯å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ï¼Œä½¿ç”¨Group Relative Policy Optimization (GRPO)ç®—æ³•ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹çš„è¯„ä¼°èƒ½åŠ›ï¼Œä½¿å…¶æ›´å…·é²æ£’æ€§ã€‚æ•´ä½“æ¡†æ¶åŒ…å«è§†é¢‘ç‰¹å¾æå–æ¨¡å—ã€æ–‡æœ¬ç‰¹å¾æå–æ¨¡å—ã€å¤šç»´åº¦è¯„ä¼°æ¨¡å—å’Œæ€ç»´é“¾ç”Ÿæˆæ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šVideoScore2çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†å¤šç»´åº¦çš„è§†é¢‘è¯„ä¼°æ¡†æ¶ï¼Œèƒ½å¤Ÿå…¨é¢è¡¡é‡è§†é¢‘è´¨é‡ï¼›2) å¼•å…¥äº†æ€ç»´é“¾æ¨ç†ï¼Œæé«˜äº†è¯„ä¼°çš„å¯è§£é‡Šæ€§ï¼›3) ä½¿ç”¨GRPOç®—æ³•è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œå¢å¼ºäº†æ¨¡å‹çš„é²æ£’æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒVideoScore2ä¸ä»…èƒ½å¤Ÿæä¾›æ›´å‡†ç¡®çš„è¯„ä¼°ç»“æœï¼Œè€Œä¸”èƒ½å¤Ÿæä¾›å¯è§£é‡Šçš„è¯„ä¼°ä¾æ®ï¼Œä»è€Œæ›´å¥½åœ°æŒ‡å¯¼è§†é¢‘ç”Ÿæˆã€‚

**å…³é”®è®¾è®¡**ï¼šVideoScore2çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) VideoFeedback2æ•°æ®é›†ï¼ŒåŒ…å«27168ä¸ªäººå·¥æ ‡æ³¨è§†é¢‘ï¼Œæä¾›äº†ä¸°å¯Œçš„æ•°æ®æ”¯æŒï¼›2) å¤šç»´åº¦è¯„ä¼°æ¨¡å—ï¼Œåˆ†åˆ«è¯„ä¼°è§†è§‰è´¨é‡ã€æ–‡æœ¬åˆ°è§†é¢‘çš„å¯¹é½ä»¥åŠç‰©ç†/å¸¸è¯†ä¸€è‡´æ€§ï¼›3) æ€ç»´é“¾ç”Ÿæˆæ¨¡å—ï¼Œç”Ÿæˆè¯¦ç»†çš„æ¨ç†è¿‡ç¨‹ï¼Œè§£é‡Šè¯„ä¼°ç»“æœï¼›4) GRPOç®—æ³•ï¼Œç”¨äºå¼ºåŒ–å­¦ä¹ ï¼Œä¼˜åŒ–æ¨¡å‹çš„è¯„ä¼°èƒ½åŠ›ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VideoScore2åœ¨VideoScore-Bench-v2ä¸Šå®ç°äº†44.35çš„å‡†ç¡®ç‡ï¼Œç›¸æ¯”ç°æœ‰æ–¹æ³•æå‡äº†5.94ã€‚åœ¨å››ä¸ªé¢†åŸŸå¤–åŸºå‡†æµ‹è¯•ï¼ˆVideoGenReward-Benchã€VideoPhy2ç­‰ï¼‰ä¸Šï¼ŒVideoScore2å–å¾—äº†50.37çš„å¹³å‡æ€§èƒ½ï¼Œç›¸æ¯”ç°æœ‰æ–¹æ³•æå‡äº†4.32ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒVideoScore2å…·æœ‰ä¼˜è¶Šçš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VideoScore2å¯åº”ç”¨äºæ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„è¯„ä¼°å’Œä¼˜åŒ–ï¼Œå¸®åŠ©å¼€å‘è€…æ›´å¥½åœ°ç†è§£æ¨¡å‹çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶è¿›è¡Œé’ˆå¯¹æ€§çš„æ”¹è¿›ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜å¯ä»¥ç”¨äºè§†é¢‘è´¨é‡è¯„ä¼°ã€è§†é¢‘å†…å®¹å®¡æ ¸ç­‰é¢†åŸŸï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯å’Œå®é™…ä»·å€¼ã€‚æœªæ¥ï¼Œå¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢VideoScore2åœ¨å¯æ§è§†é¢‘ç”Ÿæˆã€è§†é¢‘ç¼–è¾‘ç­‰æ–¹é¢çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in text-to-video generation have produced increasingly realistic and diverse content, yet evaluating such videos remains a fundamental challenge due to their multi-faceted nature encompassing visual quality, semantic alignment, and physical consistency. Existing evaluators and reward models are limited to single opaque scores, lack interpretability, or provide only coarse analysis, making them insufficient for capturing the comprehensive nature of video quality assessment. We present VideoScore2, a multi-dimensional, interpretable, and human-aligned framework that explicitly evaluates visual quality, text-to-video alignment, and physical/common-sense consistency while producing detailed chain-of-thought rationales. Our model is trained on a large-scale dataset VideoFeedback2 containing 27,168 human-annotated videos with both scores and reasoning traces across three dimensions, using a two-stage pipeline of supervised fine-tuning followed by reinforcement learning with Group Relative Policy Optimization (GRPO) to enhance analytical robustness. Extensive experiments demonstrate that VideoScore2 achieves superior performance with 44.35 (+5.94) accuracy on our in-domain benchmark VideoScore-Bench-v2 and 50.37 (+4.32) average performance across four out-of-domain benchmarks (VideoGenReward-Bench, VideoPhy2, etc), while providing interpretable assessments that bridge the gap between evaluation and controllable generation through effective reward modeling for Best-of-N sampling. Project Page: https://tiger-ai-lab.github.io/VideoScore2/

