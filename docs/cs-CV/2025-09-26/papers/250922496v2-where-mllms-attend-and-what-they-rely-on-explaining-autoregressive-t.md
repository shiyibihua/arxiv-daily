---
layout: default
title: Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation
---

# Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22496" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22496v2</a>
  <a href="https://arxiv.org/pdf/2509.22496.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22496v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22496v2', 'Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ruoyu Chen, Xiaoqing Guo, Kangwei Liu, Siyuan Liang, Shiming Liu, Qunli Zhang, Hua Zhang, Xiaochun Cao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26 (æ›´æ–°: 2025-10-17)

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://ruoyuchen10.github.io/EAGLE/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EAGLEï¼šä¸€ç§è½»é‡çº§æ¡†æ¶ï¼Œç”¨äºè§£é‡Šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è‡ªå›å½’tokenç”Ÿæˆè¿‡ç¨‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å¯è§£é‡Šæ€§` `è‡ªå›å½’ç”Ÿæˆ` `è§†è§‰å½’å› ` `æ¨¡æ€æ„ŸçŸ¥åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç¼ºä¹å¯¹ç”Ÿæˆtokenä¸è§†è§‰æ¨¡æ€ä¾èµ–ç¨‹åº¦çš„æ·±å…¥ç†è§£ï¼Œé™åˆ¶äº†è§£é‡Šæ€§å’Œå¯é æ€§ã€‚
2. EAGLEæ¡†æ¶é€šè¿‡é‡åŒ–è¯­è¨€å…ˆéªŒå’Œæ„ŸçŸ¥è¯æ®çš„å½±å“ï¼Œå°†tokenå½’å› äºç´§å‡‘çš„æ„ŸçŸ¥åŒºåŸŸï¼Œä»è€Œè§£é‡Šè‡ªå›å½’tokenç”Ÿæˆã€‚
3. å®éªŒè¡¨æ˜ï¼ŒEAGLEåœ¨å¿ å®æ€§ã€å®šä½å’Œå¹»è§‰è¯Šæ–­æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”æ‰€éœ€GPUå†…å­˜æ›´å°‘ï¼Œå…·æœ‰å®ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨è§†è§‰è¾“å…¥ä¸è‡ªç„¶è¯­è¨€è¾“å‡ºçš„å¯¹é½æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå¯¹äºç”Ÿæˆçš„tokenåœ¨å¤šå¤§ç¨‹åº¦ä¸Šä¾èµ–äºè§†è§‰æ¨¡æ€çš„ç†è§£ä»ç„¶ä¸è¶³ï¼Œè¿™é™åˆ¶äº†è§£é‡Šæ€§å’Œå¯é æ€§ã€‚æœ¬æ–‡æå‡ºEAGLEï¼Œä¸€ä¸ªè½»é‡çº§çš„é»‘ç›’æ¡†æ¶ï¼Œç”¨äºè§£é‡ŠMLLMä¸­çš„è‡ªå›å½’tokenç”Ÿæˆã€‚EAGLEå°†ä»»ä½•é€‰å®šçš„tokenå½’å› äºç´§å‡‘çš„æ„ŸçŸ¥åŒºåŸŸï¼ŒåŒæ—¶é‡åŒ–è¯­è¨€å…ˆéªŒå’Œæ„ŸçŸ¥è¯æ®çš„ç›¸å¯¹å½±å“ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ä¸ªç›®æ ‡å‡½æ•°ï¼Œç»Ÿä¸€äº†å……åˆ†æ€§ï¼ˆæ´å¯ŸåŠ›å¾—åˆ†ï¼‰å’Œä¸å¯æˆ–ç¼ºæ€§ï¼ˆå¿…è¦æ€§å¾—åˆ†ï¼‰ï¼Œé€šè¿‡å¯¹ç¨€ç–åŒ–å›¾åƒåŒºåŸŸçš„è´ªå©ªæœç´¢è¿›è¡Œä¼˜åŒ–ï¼Œä»¥å®ç°å¿ å®å’Œé«˜æ•ˆçš„å½’å› ã€‚é™¤äº†ç©ºé—´å½’å› ä¹‹å¤–ï¼ŒEAGLEè¿˜æ‰§è¡Œæ¨¡æ€æ„ŸçŸ¥åˆ†æï¼Œè§£è€¦tokenæ‰€ä¾èµ–çš„å†…å®¹ï¼Œä»è€Œæä¾›å¯¹æ¨¡å‹å†³ç­–çš„ç»†ç²’åº¦è§£é‡Šã€‚åœ¨å¼€æºMLLMä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒEAGLEåœ¨å¿ å®æ€§ã€å®šä½å’Œå¹»è§‰è¯Šæ–­æ–¹é¢å§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶éœ€è¦æ›´å°‘çš„GPUå†…å­˜ã€‚è¿™äº›ç»“æœçªå‡ºäº†å…¶åœ¨æé«˜MLLMå¯è§£é‡Šæ€§æ–¹é¢çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚ä»£ç å°†åœ¨https://ruoyuchen10.github.io/EAGLE/å‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œæˆ‘ä»¬éš¾ä»¥ç†è§£æ¯ä¸ªtokençš„ç”Ÿæˆç©¶ç«Ÿä¾èµ–äºå“ªäº›è§†è§‰ä¿¡æ¯ï¼Œä»¥åŠè¯­è¨€å…ˆéªŒçŸ¥è¯†åœ¨å…¶ä¸­èµ·åˆ°çš„ä½œç”¨ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸æ— æ³•æä¾›ç»†ç²’åº¦çš„è§£é‡Šï¼Œæˆ–è€…è®¡ç®—æˆæœ¬è¿‡é«˜ï¼Œéš¾ä»¥åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEAGLEçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡é‡åŒ–æ¯ä¸ªtokenç”Ÿæˆè¿‡ç¨‹ä¸­è§†è§‰ä¿¡æ¯å’Œè¯­è¨€å…ˆéªŒçŸ¥è¯†çš„è´¡çŒ®ï¼Œä»è€Œè§£é‡Šæ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ã€‚å®ƒé€šè¿‡å¯»æ‰¾å¯¹tokenç”Ÿæˆå½±å“æœ€å¤§çš„å›¾åƒåŒºåŸŸæ¥å®ç°è§†è§‰å½’å› ï¼Œå¹¶ç»“åˆæ¨¡æ€æ„ŸçŸ¥åˆ†ææ¥åŒºåˆ†ä¸åŒæ¨¡æ€çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEAGLEæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **Tokené€‰æ‹©**ï¼šé€‰æ‹©éœ€è¦è§£é‡Šçš„ç›®æ ‡tokenã€‚2) **åŒºåŸŸç¨€ç–åŒ–**ï¼šå¯¹è¾“å…¥å›¾åƒè¿›è¡ŒåŒºåŸŸåˆ’åˆ†ï¼Œå¹¶é€æ­¥ç¨€ç–åŒ–ï¼Œå³ç§»é™¤éƒ¨åˆ†åŒºåŸŸã€‚3) **ç›®æ ‡å‡½æ•°ä¼˜åŒ–**ï¼šè®¾è®¡ä¸€ä¸ªç›®æ ‡å‡½æ•°ï¼ŒåŒæ—¶è€ƒè™‘å……åˆ†æ€§ï¼ˆç§»é™¤é‡è¦åŒºåŸŸä¼šå¯¼è‡´tokenç”Ÿæˆæ¦‚ç‡æ˜¾è‘—ä¸‹é™ï¼‰å’Œä¸å¯æˆ–ç¼ºæ€§ï¼ˆä¿ç•™é‡è¦åŒºåŸŸèƒ½æœ‰æ•ˆæå‡tokenç”Ÿæˆæ¦‚ç‡ï¼‰ã€‚é€šè¿‡è´ªå©ªæœç´¢ï¼Œæ‰¾åˆ°å¯¹ç›®æ ‡tokenå½±å“æœ€å¤§çš„ç¨€ç–åŒ–å›¾åƒåŒºåŸŸã€‚4) **æ¨¡æ€æ„ŸçŸ¥åˆ†æ**ï¼šåˆ†ætokenç”Ÿæˆå¯¹ä¸åŒæ¨¡æ€çš„ä¾èµ–ç¨‹åº¦ï¼ŒåŒºåˆ†è§†è§‰ä¿¡æ¯å’Œè¯­è¨€å…ˆéªŒçŸ¥è¯†çš„è´¡çŒ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šEAGLEçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç›®æ ‡å‡½æ•°çš„è®¾è®¡ï¼Œå®ƒåŒæ—¶è€ƒè™‘äº†å……åˆ†æ€§å’Œä¸å¯æˆ–ç¼ºæ€§ï¼Œä»è€Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°å®šä½å¯¹tokenç”Ÿæˆè‡³å…³é‡è¦çš„å›¾åƒåŒºåŸŸã€‚æ­¤å¤–ï¼ŒEAGLEçš„æ¨¡æ€æ„ŸçŸ¥åˆ†æèƒ½å¤Ÿæä¾›æ›´ç»†ç²’åº¦çš„è§£é‡Šï¼Œæ­ç¤ºæ¨¡å‹å†³ç­–è¿‡ç¨‹ä¸­ä¸åŒæ¨¡æ€çš„ä½œç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šEAGLEä½¿ç”¨è´ªå©ªæœç´¢æ¥ä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼Œå¯»æ‰¾æœ€ä¼˜çš„ç¨€ç–åŒ–å›¾åƒåŒºåŸŸã€‚ç›®æ ‡å‡½æ•°ç»“åˆäº†insight scoreï¼ˆè¡¡é‡ç§»é™¤åŒºåŸŸåtokenç”Ÿæˆæ¦‚ç‡çš„ä¸‹é™ç¨‹åº¦ï¼‰å’Œnecessity scoreï¼ˆè¡¡é‡ä¿ç•™åŒºåŸŸåtokenç”Ÿæˆæ¦‚ç‡çš„æå‡ç¨‹åº¦ï¼‰ã€‚æ¡†æ¶é‡‡ç”¨è½»é‡çº§è®¾è®¡ï¼Œé™ä½äº†è®¡ç®—æˆæœ¬ï¼Œä½¿å…¶èƒ½å¤Ÿåº”ç”¨äºå¤§è§„æ¨¡MLLMã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒEAGLEåœ¨å¿ å®æ€§ã€å®šä½å’Œå¹»è§‰è¯Šæ–­æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨è§†è§‰å½’å› ä»»åŠ¡ä¸­ï¼ŒEAGLEèƒ½å¤Ÿæ›´å‡†ç¡®åœ°å®šä½å¯¹tokenç”Ÿæˆè‡³å…³é‡è¦çš„å›¾åƒåŒºåŸŸã€‚åŒæ—¶ï¼ŒEAGLEæ‰€éœ€çš„GPUå†…å­˜æ˜¾è‘—ä½äºå…¶ä»–æ–¹æ³•ï¼Œä½¿å…¶æ›´å…·å®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EAGLEå¯ç”¨äºæé«˜å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œå¯é æ€§ï¼Œä¾‹å¦‚åœ¨åŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ç­‰å®‰å…¨æ”¸å…³çš„é¢†åŸŸï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£æ¨¡å‹çš„å†³ç­–ä¾æ®ï¼Œä»è€Œå¢å¼ºä¿¡ä»»ã€‚æ­¤å¤–ï¼ŒEAGLEè¿˜å¯ä»¥ç”¨äºè¯Šæ–­æ¨¡å‹çš„å¹»è§‰é—®é¢˜ï¼Œå¹¶æŒ‡å¯¼æ¨¡å‹è®­ç»ƒï¼Œæå‡ç”Ÿæˆè´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in aligning visual inputs with natural language outputs. Yet, the extent to which generated tokens depend on visual modalities remains poorly understood, limiting interpretability and reliability. In this work, we present EAGLE, a lightweight black-box framework for explaining autoregressive token generation in MLLMs. EAGLE attributes any selected tokens to compact perceptual regions while quantifying the relative influence of language priors and perceptual evidence. The framework introduces an objective function that unifies sufficiency (insight score) and indispensability (necessity score), optimized via greedy search over sparsified image regions for faithful and efficient attribution. Beyond spatial attribution, EAGLE performs modality-aware analysis that disentangles what tokens rely on, providing fine-grained interpretability of model decisions. Extensive experiments across open-source MLLMs show that EAGLE consistently outperforms existing methods in faithfulness, localization, and hallucination diagnosis, while requiring substantially less GPU memory. These results highlight its effectiveness and practicality for advancing the interpretability of MLLMs. The code will be released at https://ruoyuchen10.github.io/EAGLE/.

