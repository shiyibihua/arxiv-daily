---
layout: default
title: Training-Free Multimodal Deepfake Detection via Graph Reasoning
---

# Training-Free Multimodal Deepfake Detection via Graph Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21774" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21774v1</a>
  <a href="https://arxiv.org/pdf/2509.21774.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21774v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21774v1', 'Training-Free Multimodal Deepfake Detection via Graph Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuxin Liu, Fei Wang, Kun Li, Yiqi Nie, Junjie Chen, Yanyan Wei, Zhangling Duan, Zhaohong Jia

**åˆ†ç±»**: cs.CV, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGASP-ICLæ¡†æ¶ï¼Œæ— éœ€è®­ç»ƒå³å¯å®ç°å¤šæ¨¡æ€Deepfakeæ£€æµ‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€Deepfakeæ£€æµ‹` `å…è®­ç»ƒå­¦ä¹ ` `å›¾æ¨ç†` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡å‹` `ä¿¡æ¯å®‰å…¨` `ä¼ªé€ æ£€æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥æ•æ‰ç»†å¾®çš„ä¼ªé€ çº¿ç´¢ï¼Œæ— æ³•æœ‰æ•ˆè§£å†³è·¨æ¨¡æ€ä¸ä¸€è‡´é—®é¢˜ï¼Œä¸”ç¼ºä¹ä»»åŠ¡å¯¹é½çš„æ£€ç´¢èƒ½åŠ›ã€‚
2. GASP-ICLæ¡†æ¶é€šè¿‡å¼•å¯¼å¼è‡ªé€‚åº”è¯„åˆ†å™¨å’Œä¼ æ’­ä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œå°†ä»»åŠ¡æ„ŸçŸ¥çŸ¥è¯†æ³¨å…¥LVLMsï¼Œå®ç°å…è®­ç»ƒçš„MDDã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGASP-ICLåœ¨å››ç§ä¼ªé€ ç±»å‹ä¸Šè¶…è¶Šäº†ç°æœ‰åŸºçº¿ï¼Œæ— éœ€å¯¹LVLMè¿›è¡Œå¾®è°ƒå³å¯å®ç°æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€Deepfakeæ£€æµ‹(MDD)æ—¨åœ¨æ­ç¤ºè§†è§‰ã€æ–‡æœ¬å’Œå¬è§‰æ¨¡æ€ä¸­çš„ç¯¡æ”¹ï¼Œä»è€Œå¢å¼ºç°ä»£ä¿¡æ¯ç³»ç»Ÿçš„å¯é æ€§ã€‚å°½ç®¡å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹(LVLMs)è¡¨ç°å‡ºå¼ºå¤§çš„å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ï¼Œä½†å®ƒä»¬åœ¨MDDä¸­çš„æœ‰æ•ˆæ€§å—åˆ°æ•æ‰ç»†å¾®ä¼ªé€ çº¿ç´¢ã€è§£å†³è·¨æ¨¡æ€ä¸ä¸€è‡´ä»¥åŠæ‰§è¡Œä»»åŠ¡å¯¹é½æ£€ç´¢ç­‰æŒ‘æˆ˜çš„é™åˆ¶ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºå¼•å¯¼å¼è‡ªé€‚åº”è¯„åˆ†å™¨å’Œä¼ æ’­ä¸Šä¸‹æ–‡å­¦ä¹ (GASP-ICL)ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºMDDçš„å…è®­ç»ƒæ¡†æ¶ã€‚GASP-ICLé‡‡ç”¨æµæ°´çº¿æ¥ä¿æŒè¯­ä¹‰ç›¸å…³æ€§ï¼ŒåŒæ—¶å°†ä»»åŠ¡æ„ŸçŸ¥çŸ¥è¯†æ³¨å…¥LVLMsã€‚æˆ‘ä»¬åˆ©ç”¨MDDè‡ªé€‚åº”ç‰¹å¾æå–å™¨æ¥æ£€ç´¢å¯¹é½çš„å›¾åƒ-æ–‡æœ¬å¯¹å¹¶æ„å»ºå€™é€‰é›†ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è®¾è®¡äº†å›¾ç»“æ„æ³°å‹’è‡ªé€‚åº”è¯„åˆ†å™¨(GSTAS)æ¥æ•è·è·¨æ ·æœ¬å…³ç³»å¹¶ä¼ æ’­æŸ¥è¯¢å¯¹é½ä¿¡å·ï¼Œä»è€Œäº§ç”ŸåŒºåˆ†æ€§å¼ºçš„ç¤ºä¾‹ã€‚è¿™ä½¿å¾—èƒ½å¤Ÿç²¾ç¡®é€‰æ‹©è¯­ä¹‰å¯¹é½çš„ã€ä»»åŠ¡ç›¸å…³çš„æ¼”ç¤ºï¼Œä»è€Œå¢å¼ºLVLMsçš„é²æ£’MDDèƒ½åŠ›ã€‚åœ¨å››ç§ä¼ªé€ ç±»å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGASP-ICLè¶…è¶Šäº†å¼ºå¤§çš„åŸºçº¿ï¼Œåœ¨æ²¡æœ‰LVLMå¾®è°ƒçš„æƒ…å†µä¸‹å®ç°äº†æ€§èƒ½æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€Deepfakeæ£€æµ‹ï¼ˆMDDï¼‰é—®é¢˜ï¼Œå³æ£€æµ‹åœ¨è§†è§‰ã€æ–‡æœ¬å’Œå¬è§‰ç­‰å¤šç§æ¨¡æ€ä¸Šè¿›è¡Œçš„ç¯¡æ”¹ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäºå¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰çš„æ–¹æ³•ï¼Œåœ¨æ•æ‰ç»†å¾®çš„ä¼ªé€ çº¿ç´¢ã€è§£å†³è·¨æ¨¡æ€ä¸ä¸€è‡´æ€§ä»¥åŠæ‰§è¡Œä»»åŠ¡å¯¹é½çš„æ£€ç´¢æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´æ£€æµ‹æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªå…è®­ç»ƒçš„æ¡†æ¶ï¼Œé€šè¿‡å¼•å¯¼å¼è‡ªé€‚åº”è¯„åˆ†å™¨å’Œä¼ æ’­ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆGASP-ICLï¼‰ï¼Œå°†ä»»åŠ¡ç›¸å…³çš„çŸ¥è¯†æ³¨å…¥åˆ°LVLMsä¸­ï¼Œä»è€Œæé«˜å…¶åœ¨MDDä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•æ—¨åœ¨é€šè¿‡ç²¾ç¡®é€‰æ‹©è¯­ä¹‰å¯¹é½ä¸”ä»»åŠ¡ç›¸å…³çš„ç¤ºä¾‹ï¼Œå¢å¼ºLVLMsçš„é²æ£’æ€§ï¼Œè€Œæ— éœ€è¿›è¡Œæ˜‚è´µçš„å¾®è°ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGASP-ICLæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) MDDè‡ªé€‚åº”ç‰¹å¾æå–å™¨ï¼Œç”¨äºæ£€ç´¢å¯¹é½çš„å›¾åƒ-æ–‡æœ¬å¯¹å¹¶æ„å»ºå€™é€‰é›†ï¼›2) å›¾ç»“æ„æ³°å‹’è‡ªé€‚åº”è¯„åˆ†å™¨ï¼ˆGSTASï¼‰ï¼Œç”¨äºæ•è·è·¨æ ·æœ¬å…³ç³»å¹¶ä¼ æ’­æŸ¥è¯¢å¯¹é½ä¿¡å·ï¼Œç”Ÿæˆå…·æœ‰åŒºåˆ†æ€§çš„ç¤ºä¾‹ï¼›3) ä¸Šä¸‹æ–‡å­¦ä¹ æ¨¡å—ï¼Œåˆ©ç”¨GSTASé€‰æ‹©çš„ç¤ºä¾‹ï¼Œå¢å¼ºLVLMsçš„MDDèƒ½åŠ›ã€‚æ•´ä½“æµç¨‹æ˜¯å…ˆæå–ç‰¹å¾ï¼Œç„¶åæ„å»ºå›¾å¹¶è¿›è¡Œè¯„åˆ†ï¼Œæœ€ååˆ©ç”¨è¯„åˆ†ç»“æœè¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†å›¾ç»“æ„æ³°å‹’è‡ªé€‚åº”è¯„åˆ†å™¨ï¼ˆGSTASï¼‰ï¼Œç”¨äºæ•è·è·¨æ ·æœ¬å…³ç³»å¹¶ä¼ æ’­æŸ¥è¯¢å¯¹é½ä¿¡å·ã€‚GSTASèƒ½å¤Ÿæ›´ç²¾ç¡®åœ°é€‰æ‹©ä¸æŸ¥è¯¢ç›¸å…³çš„ç¤ºä¾‹ï¼Œä»è€Œæé«˜ä¸Šä¸‹æ–‡å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æ˜¯å…è®­ç»ƒçš„ï¼Œé¿å…äº†å¯¹LVLMsè¿›è¡Œå¾®è°ƒçš„éœ€è¦ï¼Œé™ä½äº†è®¡ç®—æˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šMDDè‡ªé€‚åº”ç‰¹å¾æå–å™¨çš„å…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ï¼Œä½†å…¶ç›®æ ‡æ˜¯æå–é€‚åˆMDDä»»åŠ¡çš„ç‰¹å¾ã€‚GSTASçš„å…·ä½“ç»“æ„å’Œå‚æ•°è®¾ç½®æœªçŸ¥ï¼Œä½†å…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨å›¾ç»“æ„æ¥å»ºæ¨¡æ ·æœ¬ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶ä½¿ç”¨æ³°å‹’å±•å¼€æ¥è¿‘ä¼¼è¯„åˆ†å‡½æ•°ã€‚ä¸Šä¸‹æ–‡å­¦ä¹ æ¨¡å—çš„å…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ï¼Œä½†å…¶ç›®æ ‡æ˜¯åˆ©ç”¨GSTASé€‰æ‹©çš„ç¤ºä¾‹æ¥æŒ‡å¯¼LVLMsè¿›è¡ŒMDDã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

GASP-ICLæ¡†æ¶åœ¨å››ç§ä¼ªé€ ç±»å‹ä¸Šçš„å®éªŒä¸­ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å¼ºå¤§åŸºçº¿æ–¹æ³•ï¼Œå®ç°äº†æ€§èƒ½æå‡ï¼Œå¹¶ä¸”æ— éœ€å¯¹å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMï¼‰è¿›è¡Œå¾®è°ƒã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®æœªçŸ¥ï¼Œä½†ç»“æœè¡¨æ˜è¯¥æ¡†æ¶åœ¨å¤šæ¨¡æ€Deepfakeæ£€æµ‹æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ–°é—»åª’ä½“ã€ç¤¾äº¤å¹³å°ç­‰é¢†åŸŸï¼Œç”¨äºæ£€æµ‹å’Œè¯†åˆ«Deepfakeå†…å®¹ï¼Œç»´æŠ¤ä¿¡æ¯çš„çœŸå®æ€§å’Œå¯é æ€§ï¼Œé˜²æ­¢è™šå‡ä¿¡æ¯ä¼ æ’­ï¼Œä¿éšœç¤¾ä¼šç¨³å®šã€‚æœªæ¥å¯æ‰©å±•åˆ°æ›´å¤šæ¨¡æ€çš„Deepfakeæ£€æµ‹ï¼Œå¹¶ä¸å…¶ä»–å®‰å…¨æŠ€æœ¯ç»“åˆï¼Œæ„å»ºæ›´å®Œå–„çš„ç½‘ç»œå®‰å…¨ä½“ç³»ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal deepfake detection (MDD) aims to uncover manipulations across visual, textual, and auditory modalities, thereby reinforcing the reliability of modern information systems. Although large vision-language models (LVLMs) exhibit strong multimodal reasoning, their effectiveness in MDD is limited by challenges in capturing subtle forgery cues, resolving cross-modal inconsistencies, and performing task-aligned retrieval. To this end, we propose Guided Adaptive Scorer and Propagation In-Context Learning (GASP-ICL), a training-free framework for MDD. GASP-ICL employs a pipeline to preserve semantic relevance while injecting task-aware knowledge into LVLMs. We leverage an MDD-adapted feature extractor to retrieve aligned image-text pairs and build a candidate set. We further design the Graph-Structured Taylor Adaptive Scorer (GSTAS) to capture cross-sample relations and propagate query-aligned signals, producing discriminative exemplars. This enables precise selection of semantically aligned, task-relevant demonstrations, enhancing LVLMs for robust MDD. Experiments on four forgery types show that GASP-ICL surpasses strong baselines, delivering gains without LVLM fine-tuning.

