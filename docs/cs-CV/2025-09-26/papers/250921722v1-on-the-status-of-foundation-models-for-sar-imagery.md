---
layout: default
title: On the Status of Foundation Models for SAR Imagery
---

# On the Status of Foundation Models for SAR Imagery

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21722" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21722v1</a>
  <a href="https://arxiv.org/pdf/2509.21722.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21722v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21722v1', 'On the Status of Foundation Models for SAR Imagery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nathan Inkawhich

**åˆ†ç±»**: cs.CV, eess.IV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢ç´¢SARå›¾åƒçš„Foundation Modelï¼šè‡ªç›‘ç£å¾®è°ƒDINOv2å®ç°ç›®æ ‡è¯†åˆ«æ–°SOTA**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `SARå›¾åƒ` `ç›®æ ‡è¯†åˆ«` `è‡ªç›‘ç£å­¦ä¹ ` `Foundation Model` `DINOv2` `è¿ç§»å­¦ä¹ ` `åˆæˆå­”å¾„é›·è¾¾` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰åŸºç¡€æ¨¡å‹åœ¨SARå›¾åƒç›®æ ‡è¯†åˆ«ä¸­è¡¨ç°ä¸ä½³ï¼Œæ— æ³•ç›´æ¥æå–æœ‰æ•ˆçš„è¯­ä¹‰ç‰¹å¾ã€‚
2. é‡‡ç”¨è‡ªç›‘ç£å­¦ä¹ å¾®è°ƒç­–ç•¥ï¼Œåˆ©ç”¨SARæ•°æ®å¯¹ç°æœ‰SSLæ¨¡å‹è¿›è¡Œé€‚é…ï¼Œæå‡ç‰¹å¾æå–èƒ½åŠ›ã€‚
3. AFRL-DINOv2åœ¨SARç›®æ ‡è¯†åˆ«ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†å½“å‰æœ€ä½³SARé¢†åŸŸæ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†åŸºç¡€AI/MLæ¨¡å‹åœ¨åˆæˆå­”å¾„é›·è¾¾(SAR)ç›®æ ‡è¯†åˆ«ä»»åŠ¡ä¸­çš„å¯è¡Œæ€§ã€‚å—åˆ°è‡ªç„¶å›¾åƒé¢†åŸŸå·¨å¤§è¿›å±•çš„å¯å‘ï¼Œè¯¥é¢†åŸŸé€šè¿‡è‡ªç›‘ç£å­¦ä¹ (SSL)åœ¨ç½‘ç»œè§„æ¨¡æ•°æ®é›†ä¸Šè®­ç»ƒå¤§å‹æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹èƒ½å¤Ÿä»¥æå°‘çš„æ ‡æ³¨æ•°æ®è¿›è¡Œä¸‹æ¸¸ä»»åŠ¡é€‚é…ï¼Œå¯¹åˆ†å¸ƒåç§»æ›´å…·é²æ£’æ€§ï¼Œä¸”ç‰¹å¾å…·æœ‰é«˜åº¦å¯è¿ç§»æ€§ã€‚æœ¬æ–‡é¦–å…ˆè¯„ä¼°äº†DINOv2ã€DINOv3å’ŒPE-Coreç­‰è§†è§‰åŸºç¡€æ¨¡å‹åœ¨SARå›¾åƒä¸Šçš„è¡¨ç°ï¼Œå‘ç°å®ƒä»¬åœ¨æå–è¯­ä¹‰ç›¸å…³çš„SARç›®æ ‡ç‰¹å¾æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚ç„¶åï¼Œé€šè¿‡å¯¹å…¬å¼€çš„SSLæ¨¡å‹è¿›è¡ŒSARæ•°æ®è‡ªç›‘ç£å¾®è°ƒï¼ŒéªŒè¯äº†AFRL-DINOv2çš„å¯è¡Œæ€§ï¼Œå¹¶å»ºç«‹äº†æ–°çš„SARåŸºç¡€æ¨¡å‹SOTAï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æœ€ä½³SARé¢†åŸŸæ¨¡å‹SARATR-Xã€‚å®éªŒè¿›ä¸€æ­¥åˆ†æäº†ä¸åŒéª¨å¹²ç½‘ç»œä¸ä¸‹æ¸¸ä»»åŠ¡é€‚é…æ–¹æ¡ˆçš„æ€§èƒ½æƒè¡¡ï¼Œå¹¶ç›‘æµ‹äº†æ¨¡å‹åœ¨ä¸‹æ¸¸ç¯å¢ƒä¸­å…‹æœæŒ‘æˆ˜çš„èƒ½åŠ›ã€‚å¸Œæœ›è¿™é¡¹å·¥ä½œèƒ½å¤Ÿä¸ºæœªæ¥çš„SARåŸºç¡€æ¨¡å‹æ„å»ºè€…æä¾›å‚è€ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³SARå›¾åƒç›®æ ‡è¯†åˆ«é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œæ³›åŒ–èƒ½åŠ›å¼±ï¼Œä¸”éš¾ä»¥é€‚åº”å¤æ‚çš„æ“ä½œç¯å¢ƒã€‚ç›´æ¥åº”ç”¨è‡ªç„¶å›¾åƒé¢†åŸŸé¢„è®­ç»ƒçš„è§†è§‰åŸºç¡€æ¨¡å‹ï¼Œæ— æ³•æœ‰æ•ˆæå–SARå›¾åƒçš„è¯­ä¹‰ç‰¹å¾ï¼Œå¯¼è‡´è¯†åˆ«ç²¾åº¦è¾ƒä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ (SSL)çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œé€šè¿‡åœ¨SARæ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°SARå›¾åƒç‰¹æœ‰çš„ç‰¹å¾è¡¨ç¤ºã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨åˆ©ç”¨å¤§è§„æ¨¡æ— æ ‡æ³¨SARæ•°æ®ï¼Œæå‡æ¨¡å‹åœ¨å°‘é‡æ ‡æ³¨æ•°æ®ä¸‹çš„æ€§èƒ½ï¼Œå¹¶å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) é€‰æ‹©åˆé€‚çš„è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆå¦‚DINOv2ï¼‰ï¼›2) åˆ©ç”¨å…¬å¼€çš„SARæ•°æ®é›†è¿›è¡Œè‡ªç›‘ç£å¾®è°ƒï¼Œè®­ç»ƒAFRL-DINOv2æ¨¡å‹ï¼›3) åœ¨ä¸‹æ¸¸SARç›®æ ‡è¯†åˆ«ä»»åŠ¡ä¸Šè¯„ä¼°å¾®è°ƒåçš„æ¨¡å‹æ€§èƒ½ï¼›4) åˆ†æä¸åŒéª¨å¹²ç½‘ç»œå’Œä¸‹æ¸¸ä»»åŠ¡é€‚é…æ–¹æ¡ˆçš„æ€§èƒ½æƒè¡¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šå…³é”®åˆ›æ–°åœ¨äºå°†è‡ªç›‘ç£å­¦ä¹ çš„é¢„è®­ç»ƒæ¨¡å‹æˆåŠŸåº”ç”¨äºSARå›¾åƒé¢†åŸŸï¼Œå¹¶é€šè¿‡å¾®è°ƒæ˜¾è‘—æå‡äº†SARç›®æ ‡è¯†åˆ«çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ç³»ç»Ÿåœ°åˆ†æäº†ä¸åŒéª¨å¹²ç½‘ç»œå’Œä¸‹æ¸¸ä»»åŠ¡é€‚é…æ–¹æ¡ˆå¯¹æ€§èƒ½çš„å½±å“ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é€‰æ‹©DINOv2ä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œå› ä¸ºå®ƒåœ¨è‡ªç„¶å›¾åƒé¢†åŸŸè¡¨ç°å‡ºè‰²ï¼Œå…·æœ‰è‰¯å¥½çš„ç‰¹å¾æå–èƒ½åŠ›ï¼›2) ä½¿ç”¨è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•è¿›è¡Œå¾®è°ƒï¼Œä»¥å……åˆ†åˆ©ç”¨æ— æ ‡æ³¨SARæ•°æ®ï¼›3) è®¾è®¡åˆç†çš„ä¸‹æ¸¸ä»»åŠ¡é€‚é…æ–¹æ¡ˆï¼Œä»¥æœ€å¤§åŒ–æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡SARæ•°æ®è‡ªç›‘ç£å¾®è°ƒçš„AFRL-DINOv2æ¨¡å‹åœ¨SARç›®æ ‡è¯†åˆ«ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†å½“å‰æœ€ä½³SARé¢†åŸŸæ¨¡å‹SARATR-Xï¼Œå»ºç«‹äº†æ–°çš„SOTAã€‚è¿™éªŒè¯äº†è‡ªç›‘ç£å­¦ä¹ åœ¨SARå›¾åƒé¢†åŸŸçš„æœ‰æ•ˆæ€§ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†æœ‰åŠ›çš„æ”¯æŒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå†›äº‹ä¾¦å¯Ÿã€ç¾å®³ç›‘æµ‹ã€ç¯å¢ƒç›‘æµ‹ã€èµ„æºå‹˜æ¢ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡SARå›¾åƒç›®æ ‡è¯†åˆ«çš„ç²¾åº¦å’Œæ•ˆç‡ï¼Œå¯ä»¥æ›´å¿«é€Ÿã€å‡†ç¡®åœ°è·å–ç›®æ ‡ä¿¡æ¯ï¼Œä¸ºå†³ç­–æä¾›æ”¯æŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½äº¤é€šç­‰é¢†åŸŸï¼Œå®ç°å…¨å¤©å€™ã€å…¨å¤©æ—¶çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this work we investigate the viability of foundational AI/ML models for Synthetic Aperture Radar (SAR) object recognition tasks. We are inspired by the tremendous progress being made in the wider community, particularly in the natural image domain where frontier labs are training huge models on web-scale datasets with unprecedented computing budgets. It has become clear that these models, often trained with Self-Supervised Learning (SSL), will transform how we develop AI/ML solutions for object recognition tasks - they can be adapted downstream with very limited labeled data, they are more robust to many forms of distribution shift, and their features are highly transferable out-of-the-box. For these reasons and more, we are motivated to apply this technology to the SAR domain. In our experiments we first run tests with today's most powerful visual foundational models, including DINOv2, DINOv3 and PE-Core and observe their shortcomings at extracting semantically-interesting discriminative SAR target features when used off-the-shelf. We then show that Self-Supervised finetuning of publicly available SSL models with SAR data is a viable path forward by training several AFRL-DINOv2s and setting a new state-of-the-art for SAR foundation models, significantly outperforming today's best SAR-domain model SARATR-X. Our experiments further analyze the performance trade-off of using different backbones with different downstream task-adaptation recipes, and we monitor each model's ability to overcome challenges within the downstream environments (e.g., extended operating conditions and low amounts of labeled data). We hope this work will inform and inspire future SAR foundation model builders, because despite our positive results, we still have a long way to go.

