---
layout: default
title: Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models
---

# Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22221" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22221v1</a>
  <a href="https://arxiv.org/pdf/2509.22221.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22221v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22221v1', 'Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiaqi Liu, Lang Sun, Ronghao Fu, Bo Yang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ„ŸçŸ¥çš„åœ°ç†ç©ºé—´æ€ç»´é“¾Geo-CoTï¼Œæå‡é¥æ„Ÿè§†è§‰-è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é¥æ„Ÿå›¾åƒåˆ†æ` `è§†è§‰-è¯­è¨€æ¨¡å‹` `æ€ç»´é“¾` `åœ°ç†ç©ºé—´æ¨ç†` `å¯è§£é‡Šæ€§` `ç¾¤ä½“å¥–åŠ±ç­–ç•¥ä¼˜åŒ–` `æ•°æ®é›†æ„å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é¥æ„ŸVLMç«¯åˆ°ç«¯è®­ç»ƒå¿½ç•¥æ¨ç†æ­¥éª¤ï¼Œå¯¼è‡´ç»“æœä¸å¯é ï¼Œé™åˆ¶äº†å¤æ‚åˆ†æä»»åŠ¡çš„åº”ç”¨ã€‚
2. æå‡ºGeo-CoTæ¡†æ¶ï¼Œå°†é¥æ„Ÿåˆ†æåˆ†è§£ä¸ºå¯éªŒè¯çš„å¤šæ­¥éª¤è¿‡ç¨‹ï¼Œæ¨¡æ‹Ÿäººç±»æ¨ç†ã€‚
3. æ„å»ºGeo-CoT380kæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨SFTå’ŒGRPOç­–ç•¥è®­ç»ƒRSThinkeræ¨¡å‹ï¼Œæ˜¾è‘—æå‡æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é¥æ„Ÿé¢†åŸŸçš„è§†è§‰-è¯­è¨€æ¨¡å‹(VLMs)åœ¨å¤æ‚åˆ†æä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œè¿™æ˜¯ç”±äºå…¶ç«¯åˆ°ç«¯è®­ç»ƒèŒƒå¼ç»•è¿‡äº†å…³é”®çš„æ¨ç†æ­¥éª¤ï¼Œå¯¼è‡´è¾“å‡ºç»“æœéš¾ä»¥éªŒè¯ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæ„ŸçŸ¥çš„åœ°ç†ç©ºé—´æ€ç»´é“¾(Geo-CoT)æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†é¥æ„Ÿåˆ†æå»ºæ¨¡ä¸ºä¸€ä¸ªå¯éªŒè¯çš„å¤šæ­¥éª¤è¿‡ç¨‹ã€‚æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªä¸¤é˜¶æ®µå¯¹é½ç­–ç•¥æ¥çŒè¾“è¿™ç§åˆ†æè¿‡ç¨‹ï¼Œåˆ©ç”¨Geo-CoT380kï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå¤§è§„æ¨¡çš„ç»“æ„åŒ–Geo-CoTæ¨ç†æ•°æ®é›†ã€‚è¯¥ç­–ç•¥é¦–å…ˆé‡‡ç”¨ç›‘ç£å¾®è°ƒ(SFT)æ¥çŒè¾“åŸºç¡€è®¤çŸ¥æ¶æ„ï¼Œç„¶ååˆ©ç”¨ç¾¤ä½“å¥–åŠ±ç­–ç•¥ä¼˜åŒ–(GRPO)æ¥æ”¹è¿›æ¨¡å‹çš„æ¨ç†ç­–ç•¥ï¼Œä½¿å…¶æ›´ç¬¦åˆäº‹å®ã€‚ç”±æ­¤äº§ç”Ÿçš„æ¨¡å‹RSThinkerï¼Œè¾“å‡ºæœ€ç»ˆç­”æ¡ˆåŠå…¶å¯éªŒè¯çš„åˆ†æè½¨è¿¹ã€‚è¿™ç§èƒ½åŠ›äº§ç”Ÿäº†å“è¶Šçš„æ€§èƒ½ï¼Œåœ¨å„ç§ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ã€‚Geo-CoT380kæ•°æ®é›†å’ŒRSThinkeræ¨¡å‹çš„å…¬å¼€å‘å¸ƒï¼Œä¸ºåœ°çƒè§‚æµ‹ä»ä¸é€æ˜çš„æ„ŸçŸ¥èµ°å‘ç»“æ„åŒ–çš„ã€å¯éªŒè¯çš„æ¨ç†æä¾›äº†ä¸€æ¡å…·ä½“çš„é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šé¥æ„Ÿé¢†åŸŸä¸­çš„è§†è§‰-è¯­è¨€æ¨¡å‹(VLMs)åœ¨æ‰§è¡Œå¤æ‚çš„åˆ†æä»»åŠ¡æ—¶ï¼Œç”±äºç¼ºä¹æ˜ç¡®çš„æ¨ç†è¿‡ç¨‹ï¼Œå¾€å¾€éš¾ä»¥ç»™å‡ºå‡†ç¡®ä¸”å¯ä¿¡çš„ç»“æœã€‚ç°æœ‰çš„ç«¯åˆ°ç«¯è®­ç»ƒæ–¹æ³•è™½ç„¶èƒ½å¤Ÿç›´æ¥å°†å›¾åƒæ˜ å°„åˆ°ç­”æ¡ˆï¼Œä½†å¿½ç•¥äº†ä¸­é—´çš„æ¨ç†æ­¥éª¤ï¼Œå¯¼è‡´æ¨¡å‹æˆä¸ºä¸€ä¸ªâ€œé»‘ç›’â€ï¼Œå…¶è¾“å‡ºç»“æœéš¾ä»¥éªŒè¯ï¼Œä¹Ÿéš¾ä»¥è§£é‡Šå…¶å†³ç­–è¿‡ç¨‹ã€‚è¿™ç§æ–¹å¼åœ¨éœ€è¦ç²¾ç¡®åœ°ç†ç©ºé—´æ¨ç†çš„é¥æ„Ÿåº”ç”¨ä¸­å°¤å…¶ä¸åˆ©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†é¥æ„Ÿåˆ†æä»»åŠ¡åˆ†è§£ä¸ºä¸€ç³»åˆ—å¯éªŒè¯çš„æ­¥éª¤ï¼Œæ¨¡æ‹Ÿäººç±»ä¸“å®¶è¿›è¡Œåœ°ç†ç©ºé—´æ¨ç†çš„è¿‡ç¨‹ã€‚é€šè¿‡å¼•å…¥â€œæ€ç»´é“¾â€ï¼ˆChain-of-Thought, CoTï¼‰çš„æ¦‚å¿µï¼Œæ¨¡å‹ä¸å†ç›´æ¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆï¼Œè€Œæ˜¯é€æ­¥ç”Ÿæˆä¸­é—´æ¨ç†æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤éƒ½åŸºäºå¯æ„ŸçŸ¥çš„åœ°ç†ç©ºé—´ä¿¡æ¯ã€‚è¿™ç§æ–¹å¼ä½¿å¾—æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹æ›´åŠ é€æ˜ï¼Œä¹Ÿæ›´å®¹æ˜“è¿›è¡Œè°ƒè¯•å’Œæ”¹è¿›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œä½¿ç”¨ç›‘ç£å¾®è°ƒ(SFT)åœ¨Geo-CoT380kæ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œä½¿å…¶å…·å¤‡ç”Ÿæˆåœ°ç†ç©ºé—´æ€ç»´é“¾çš„åŸºæœ¬èƒ½åŠ›ã€‚Geo-CoT380kæ•°æ®é›†åŒ…å«å¤§é‡çš„é¥æ„Ÿå›¾åƒå’Œå¯¹åº”çš„ç»“æ„åŒ–æ¨ç†è¿‡ç¨‹ã€‚å…¶æ¬¡ï¼Œä½¿ç”¨ç¾¤ä½“å¥–åŠ±ç­–ç•¥ä¼˜åŒ–(GRPO)è¿›ä¸€æ­¥æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶è¾“å‡ºçš„æ¨ç†é“¾æ›´ç¬¦åˆäº‹å®ï¼Œæœ€ç»ˆç­”æ¡ˆæ›´åŠ å‡†ç¡®ã€‚GRPOé€šè¿‡å¯¹å¤šä¸ªæ¨ç†é“¾è¿›è¡Œè¯„ä¼°ï¼Œå¹¶æ ¹æ®å…¶æ­£ç¡®æ€§å’Œå®Œæ•´æ€§ç»™äºˆä¸åŒçš„å¥–åŠ±ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹å­¦ä¹ æ›´æœ‰æ•ˆçš„æ¨ç†ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†æ€ç»´é“¾æ¨ç†ä¸åœ°ç†ç©ºé—´æ„ŸçŸ¥ç›¸ç»“åˆï¼Œæå‡ºäº†Perceptually-Grounded Geospatial Chain-of-Thought (Geo-CoT)æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„ç«¯åˆ°ç«¯æ¨¡å‹ç›¸æ¯”ï¼ŒGeo-CoTèƒ½å¤Ÿç”Ÿæˆå¯éªŒè¯çš„æ¨ç†è¿‡ç¨‹ï¼Œæé«˜äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œå¯é æ€§ã€‚æ­¤å¤–ï¼ŒGeo-CoT380kæ•°æ®é›†çš„æ„å»ºä¹Ÿä¸ºé¥æ„Ÿé¢†åŸŸçš„æ€ç»´é“¾ç ”ç©¶æä¾›äº†é‡è¦çš„æ•°æ®åŸºç¡€ã€‚

**å…³é”®è®¾è®¡**ï¼šGeo-CoT380kæ•°æ®é›†åŒ…å«äº†38ä¸‡ä¸ªé¥æ„Ÿå›¾åƒå’Œå¯¹åº”çš„ç»“æ„åŒ–æ¨ç†è¿‡ç¨‹ï¼Œæ¶µç›–äº†å¤šç§åœ°ç†ç©ºé—´åˆ†æä»»åŠ¡ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒSFTä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚GRPOåˆ™é‡‡ç”¨äº†ä¸€ç§åŸºäºç¾¤ä½“å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡å¯¹å¤šä¸ªæ¨ç†é“¾è¿›è¡Œè¯„ä¼°ï¼Œå¹¶æ ¹æ®å…¶æ­£ç¡®æ€§å’Œå®Œæ•´æ€§ç»™äºˆä¸åŒçš„å¥–åŠ±ã€‚å…·ä½“çš„å¥–åŠ±å‡½æ•°è®¾è®¡éœ€è¦æ ¹æ®ä»»åŠ¡çš„ç‰¹ç‚¹è¿›è¡Œè°ƒæ•´ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ­£ç¡®çš„æ¨ç†ç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

RSThinkeræ¨¡å‹åœ¨å¤šä¸ªé¥æ„Ÿåˆ†æä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œè¯æ˜äº†Geo-CoTæ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“æ€§èƒ½æå‡æ•°æ®åœ¨è®ºæ–‡ä¸­ç»™å‡ºï¼Œè¡¨æ˜è¯¥æ¨¡å‹åœ¨å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚Geo-CoT380kæ•°æ®é›†çš„å‘å¸ƒä¹Ÿä¸ºé¥æ„Ÿé¢†åŸŸçš„æ€ç»´é“¾ç ”ç©¶æä¾›äº†å®è´µèµ„æºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºé¥æ„Ÿå›¾åƒåˆ†æé¢†åŸŸï¼Œä¾‹å¦‚åœŸåœ°åˆ©ç”¨åˆ†ç±»ã€ç¾å®³ç›‘æµ‹ã€åŸå¸‚è§„åˆ’ç­‰ã€‚é€šè¿‡æä¾›å¯éªŒè¯çš„æ¨ç†è¿‡ç¨‹ï¼Œå¯ä»¥æé«˜å†³ç­–çš„é€æ˜åº¦å’Œå¯é æ€§ï¼Œä¸ºæ”¿åºœã€ä¼ä¸šå’Œç ”ç©¶æœºæ„æä¾›æ›´å¯é çš„åœ°ç†ç©ºé—´ä¿¡æ¯æ”¯æŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°å…¶ä»–éœ€è¦å¤æ‚æ¨ç†çš„é¥æ„Ÿåº”ç”¨ä¸­ï¼Œä¾‹å¦‚æ°”å€™å˜åŒ–ç ”ç©¶ã€ç¯å¢ƒç›‘æµ‹ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language Models (VLMs) in remote sensing often fail at complex analytical tasks, a limitation stemming from their end-to-end training paradigm that bypasses crucial reasoning steps and leads to unverifiable outputs. To address this limitation, we introduce the Perceptually-Grounded Geospatial Chain-of-Thought (Geo-CoT), a framework that models remote sensing analysis as a verifiable, multi-step process. We instill this analytical process through a two-stage alignment strategy, leveraging Geo-CoT380k, the first large-scale dataset of structured Geo-CoT rationales. This strategy first employs supervised fine-tuning (SFT) to instill the foundational cognitive architecture, then leverages Group Reward Policy Optimization (GRPO) to refine the model's reasoning policy towards factual correctness. The resulting model, RSThinker, outputs both a final answer and its justifying, verifiable analytical trace. This capability yields dominant performance, significantly outperforming state-of-the-art models across a comprehensive range of tasks. The public release of our Geo-CoT380k dataset and RSThinker model upon publication serves as a concrete pathway from opaque perception towards structured, verifiable reasoning for Earth Observation.

