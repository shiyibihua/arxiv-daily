---
layout: default
title: DeLiVR: Differential Spatiotemporal Lie Bias for Efficient Video Deraining
---

# DeLiVR: Differential Spatiotemporal Lie Bias for Efficient Video Deraining

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21719" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21719v1</a>
  <a href="https://arxiv.org/pdf/2509.21719.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21719v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21719v1', 'DeLiVR: Differential Spatiotemporal Lie Bias for Efficient Video Deraining')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuning Sun, Jialang Lu, Xiang Chen, Jichao Wang, Dianjie Lu, Guijuan Zhang, Guangwei Gao, Zhuoran Zheng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DeLiVRï¼šåˆ©ç”¨æ—¶ç©ºLieç¾¤å¾®åˆ†åç½®å®ç°é«˜æ•ˆè§†é¢‘å»é›¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `è§†é¢‘å»é›¨` `Lieç¾¤` `æ—¶ç©ºä¸€è‡´æ€§` `æ³¨æ„åŠ›æœºåˆ¶` `å‡ ä½•å˜æ¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘å»é›¨æ–¹æ³•ä¾èµ–å…‰æµæˆ–å¯å‘å¼å¯¹é½ï¼Œè®¡ç®—é‡å¤§ä¸”é²æ£’æ€§ä¸è¶³ï¼Œéš¾ä»¥å¤„ç†ç›¸æœºå§¿æ€å˜åŒ–å¸¦æ¥çš„å¸§é—´ä¸åŒ¹é…ã€‚
2. DeLiVRé€šè¿‡å°†æ—¶ç©ºLieç¾¤å¾®åˆ†åç½®æ³¨å…¥ç½‘ç»œæ³¨æ„åŠ›ï¼Œåˆ©ç”¨Lieç¾¤è¡¨ç¤ºè¿ç»­å‡ ä½•å˜æ¢çš„ä¼˜åŠ¿ï¼Œå¢å¼ºæ—¶ç©ºä¸€è‡´æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDeLiVRåœ¨å…¬å¼€æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶åœ¨è§†é¢‘å»é›¨ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨é‡å¤–æ‹æ‘„çš„è§†é¢‘é€šå¸¸ä¼šå—åˆ°é›¨ç—•ã€æ¨¡ç³Šå’Œå™ªå£°çš„å½±å“ã€‚æ­¤å¤–ï¼Œå³ä½¿ç›¸æœºå§¿æ€çš„å¾®å°å˜åŒ–ä¹Ÿä¼šæ”¾å¤§å¸§é—´ä¸åŒ¹é…å’Œæ—¶é—´ä¼ªå½±ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå…‰æµæˆ–å¯å‘å¼å¯¹é½ï¼Œè¿™äº›æ–¹æ³•è®¡ç®—æˆæœ¬é«˜ä¸”é²æ£’æ€§è¾ƒå·®ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼ŒLieç¾¤æä¾›äº†ä¸€ç§è¡¨ç¤ºè¿ç»­å‡ ä½•å˜æ¢çš„åŸåˆ™æ€§æ–¹æ³•ï¼Œä½¿å…¶éå¸¸é€‚åˆäºåœ¨è§†é¢‘å»ºæ¨¡ä¸­å¼ºåˆ¶æ‰§è¡Œç©ºé—´å’Œæ—¶é—´ä¸€è‡´æ€§ã€‚åŸºäºè¿™ä¸€æ´å¯Ÿï¼Œæˆ‘ä»¬æå‡ºDeLiVRï¼Œä¸€ç§é«˜æ•ˆçš„è§†é¢‘å»é›¨æ–¹æ³•ï¼Œå®ƒå°†æ—¶ç©ºLieç¾¤å¾®åˆ†åç½®ç›´æ¥æ³¨å…¥åˆ°ç½‘ç»œçš„æ³¨æ„åŠ›åˆ†æ•°ä¸­ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†ä¸¤ä¸ªäº’è¡¥çš„ç»„ä»¶ã€‚é¦–å…ˆï¼Œä¸€ä¸ªæ—‹è½¬æœ‰ç•Œçš„Lieç›¸å¯¹åç½®ä½¿ç”¨ä¸€ä¸ªç´§å‡‘çš„é¢„æµ‹æ¨¡å—æ¥é¢„æµ‹æ¯ä¸€å¸§çš„å¹³é¢å†…è§’åº¦ï¼Œå…¶ä¸­å½’ä¸€åŒ–çš„åæ ‡è¢«æ—‹è½¬å¹¶ä¸åŸºæœ¬åæ ‡è¿›è¡Œæ¯”è¾ƒï¼Œä»¥åœ¨ç‰¹å¾èšåˆä¹‹å‰å®ç°å‡ ä½•ä¸€è‡´çš„å¯¹é½ã€‚å…¶æ¬¡ï¼Œä¸€ä¸ªå¾®åˆ†ç¾¤ä½ç§»è®¡ç®—ç›¸é‚»å¸§ä¹‹é—´çš„è§’åº¦å·®ï¼Œä»¥ä¼°è®¡é€Ÿåº¦ã€‚è¿™ç§åç½®è®¡ç®—ç»“åˆäº†æ—¶é—´è¡°å‡å’Œæ³¨æ„åŠ›æ©ç ï¼Œä»¥å…³æ³¨å¸§é—´å…³ç³»ï¼ŒåŒæ—¶ç²¾ç¡®åŒ¹é…é›¨ç—•çš„æ–¹å‘ã€‚å¤§é‡çš„å®éªŒç»“æœè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•åœ¨å…¬å¼€åŸºå‡†ä¸Šçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†é¢‘å»é›¨é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨ç›¸æœºå­˜åœ¨è¿åŠ¨çš„æƒ…å†µä¸‹ï¼Œä¼ ç»Ÿæ–¹æ³•ä¾èµ–å…‰æµæˆ–å¯å‘å¼å¯¹é½ï¼Œè®¡ç®—å¤æ‚åº¦é«˜ï¼Œä¸”å®¹æ˜“å—åˆ°è¿åŠ¨ä¼°è®¡è¯¯å·®çš„å½±å“ï¼Œå¯¼è‡´å»é›¨æ•ˆæœä¸ä½³ï¼Œå¹¶äº§ç”Ÿæ—¶é—´ä¼ªå½±ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨æ•ˆç‡å’Œé²æ£’æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Lieç¾¤æ¥è¡¨ç¤ºè§†é¢‘å¸§ä¹‹é—´çš„å‡ ä½•å˜æ¢ï¼Œå¹¶å°†å…¶ä½œä¸ºå…ˆéªŒçŸ¥è¯†ï¼ˆåç½®ï¼‰æ³¨å…¥åˆ°ç½‘ç»œçš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ã€‚Lieç¾¤èƒ½å¤Ÿä»¥ä¸€ç§è¿ç»­ä¸”å‚æ•°åŒ–çš„æ–¹å¼æè¿°æ—‹è½¬å’Œå¹³ç§»ç­‰å˜æ¢ï¼Œä»è€Œæ›´å¥½åœ°å»ºæ¨¡å¸§é—´å…³ç³»ï¼Œå¹¶æé«˜å»é›¨ç½‘ç»œçš„æ—¶ç©ºä¸€è‡´æ€§ã€‚é€šè¿‡å°†Lieç¾¤ä¿¡æ¯èå…¥æ³¨æ„åŠ›æœºåˆ¶ï¼Œç½‘ç»œå¯ä»¥æ›´æœ‰æ•ˆåœ°å…³æ³¨ç›¸å…³çš„å¸§é—´ä¿¡æ¯ï¼Œä»è€Œæé«˜å»é›¨æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDeLiVRçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæ—‹è½¬æœ‰ç•Œçš„Lieç›¸å¯¹åç½®æ¨¡å—å’Œå¾®åˆ†ç¾¤ä½ç§»æ¨¡å—ã€‚æ—‹è½¬æœ‰ç•Œçš„Lieç›¸å¯¹åç½®æ¨¡å—ç”¨äºé¢„æµ‹æ¯ä¸€å¸§çš„å¹³é¢å†…æ—‹è½¬è§’åº¦ï¼Œä»è€Œå®ç°å‡ ä½•ä¸€è‡´çš„å¸§å¯¹é½ã€‚å¾®åˆ†ç¾¤ä½ç§»æ¨¡å—ç”¨äºè®¡ç®—ç›¸é‚»å¸§ä¹‹é—´çš„è§’åº¦å·®ï¼Œä»¥ä¼°è®¡é€Ÿåº¦ï¼Œå¹¶ç»“åˆæ—¶é—´è¡°å‡å’Œæ³¨æ„åŠ›æ©ç ï¼Œä»¥å…³æ³¨å¸§é—´å…³ç³»ï¼ŒåŒæ—¶ç²¾ç¡®åŒ¹é…é›¨ç—•çš„æ–¹å‘ã€‚è¿™ä¸¤ä¸ªæ¨¡å—å…±åŒä½œç”¨ï¼Œå°†æ—¶ç©ºLieç¾¤å¾®åˆ†åç½®æ³¨å…¥åˆ°ç½‘ç»œçš„æ³¨æ„åŠ›åˆ†æ•°ä¸­ï¼Œä»è€Œæé«˜å»é›¨æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†Lieç¾¤ç†è®ºå¼•å…¥åˆ°è§†é¢‘å»é›¨ä»»åŠ¡ä¸­ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„æ—¶ç©ºLieç¾¤å¾®åˆ†åç½®æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å»ºæ¨¡å¸§é—´å‡ ä½•å˜æ¢ï¼Œå¹¶æé«˜å»é›¨ç½‘ç»œçš„æ—¶ç©ºä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å…·æœ‰è®¡ç®—æ•ˆç‡é«˜çš„ä¼˜ç‚¹ï¼Œä½¿å…¶èƒ½å¤Ÿåº”ç”¨äºå®é™…çš„è§†é¢‘å»é›¨åœºæ™¯ã€‚

**å…³é”®è®¾è®¡**ï¼šæ—‹è½¬æœ‰ç•Œçš„Lieç›¸å¯¹åç½®æ¨¡å—ä½¿ç”¨ä¸€ä¸ªç´§å‡‘çš„é¢„æµ‹æ¨¡å—æ¥é¢„æµ‹æ¯ä¸€å¸§çš„å¹³é¢å†…è§’åº¦ï¼Œå…¶ä¸­å½’ä¸€åŒ–çš„åæ ‡è¢«æ—‹è½¬å¹¶ä¸åŸºæœ¬åæ ‡è¿›è¡Œæ¯”è¾ƒï¼Œä»¥åœ¨ç‰¹å¾èšåˆä¹‹å‰å®ç°å‡ ä½•ä¸€è‡´çš„å¯¹é½ã€‚å¾®åˆ†ç¾¤ä½ç§»æ¨¡å—ä½¿ç”¨æ—¶é—´è¡°å‡å’Œæ³¨æ„åŠ›æ©ç æ¥å…³æ³¨å¸§é—´å…³ç³»ï¼ŒåŒæ—¶ç²¾ç¡®åŒ¹é…é›¨ç—•çš„æ–¹å‘ã€‚æŸå¤±å‡½æ•°æ–¹é¢ï¼Œè®ºæ–‡å¯èƒ½é‡‡ç”¨äº†å¸¸è§çš„å›¾åƒé‡å»ºæŸå¤±ï¼Œä¾‹å¦‚L1æŸå¤±æˆ–L2æŸå¤±ï¼Œä»¥åŠå¯èƒ½çš„æ­£åˆ™åŒ–é¡¹æ¥çº¦æŸLieç¾¤å‚æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡åœ¨å…¬å¼€æ•°æ®é›†ä¸Šè¿›è¡Œå¤§é‡å®éªŒï¼ŒéªŒè¯äº†DeLiVRçš„æœ‰æ•ˆæ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†æ‘˜è¦ä¸­æåˆ°DeLiVRåœ¨å…¬å¼€åŸºå‡†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œè¡¨æ˜å…¶åœ¨è§†é¢‘å»é›¨ä»»åŠ¡ä¸­å…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDeLiVRèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å»é™¤é›¨ç—•ï¼Œå¹¶å‡å°‘æ—¶é—´ä¼ªå½±ï¼Œä»è€Œæé«˜è§†é¢‘è´¨é‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DeLiVRåœ¨è§†é¢‘ç›‘æ§ã€è‡ªåŠ¨é©¾é©¶ã€ç”µå½±åˆ¶ä½œç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚åœ¨è§†é¢‘ç›‘æ§ä¸­ï¼Œå®ƒå¯ä»¥æé«˜é›¨å¤©ç¯å¢ƒä¸‹çš„è§†é¢‘æ¸…æ™°åº¦ï¼Œä»è€Œæé«˜ç›®æ ‡æ£€æµ‹å’Œè·Ÿè¸ªçš„å‡†ç¡®æ€§ã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå®ƒå¯ä»¥æé«˜é›¨å¤©ç¯å¢ƒä¸‹çš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œä»è€Œæé«˜é©¾é©¶å®‰å…¨æ€§ã€‚åœ¨ç”µå½±åˆ¶ä½œä¸­ï¼Œå®ƒå¯ä»¥ç”¨äºå»é™¤é›¨å¤©æ‹æ‘„çš„è§†é¢‘ä¸­çš„é›¨ç—•ï¼Œä»è€Œæé«˜è§†é¢‘è´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Videos captured in the wild often suffer from rain streaks, blur, and noise. In addition, even slight changes in camera pose can amplify cross-frame mismatches and temporal artifacts. Existing methods rely on optical flow or heuristic alignment, which are computationally expensive and less robust. To address these challenges, Lie groups provide a principled way to represent continuous geometric transformations, making them well-suited for enforcing spatial and temporal consistency in video modeling. Building on this insight, we propose DeLiVR, an efficient video deraining method that injects spatiotemporal Lie-group differential biases directly into attention scores of the network. Specifically, the method introduces two complementary components. First, a rotation-bounded Lie relative bias predicts the in-plane angle of each frame using a compact prediction module, where normalized coordinates are rotated and compared with base coordinates to achieve geometry-consistent alignment before feature aggregation. Second, a differential group displacement computes angular differences between adjacent frames to estimate a velocity. This bias computation combines temporal decay and attention masks to focus on inter-frame relationships while precisely matching the direction of rain streaks. Extensive experimental results demonstrate the effectiveness of our method on publicly available benchmarks.

