---
layout: default
title: SPARK: Synergistic Policy And Reward Co-Evolving Framework
---

# SPARK: Synergistic Policy And Reward Co-Evolving Framework

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22624" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.22624v1</a>
  <a href="https://arxiv.org/pdf/2509.22624.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22624v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22624v1', 'SPARK: Synergistic Policy And Reward Co-Evolving Framework')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Ziyu Liu, Yuhang Zang, Shengyuan Ding, Yuhang Cao, Xiaoyi Dong, Haodong Duan, Dahua Lin, Jiaqi Wang

**ÂàÜÁ±ª**: cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-26

**Â§áÊ≥®**: Project:https://github.com/InternLM/Spark

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SPARKÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥RLHF‰∏éRLVRÁöÑÊïàÁéá‰∏éÂáÜÁ°ÆÊÄßÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Âº∫ÂåñÂ≠¶‰π†` `Â•ñÂä±Ê®°Âûã` `ÂçèÂêåÊºîÂåñ` `ÁîüÊàêÊ®°Âûã` `Â§ö‰ªªÂä°Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑRLHFÊñπÊ≥ïÊàêÊú¨È´ò‰∏îÂèØËÉΩÂØºËá¥Â•ñÂä±‰∏éÁ≠ñÁï•‰πãÈó¥ÁöÑ‰∏çÂåπÈÖçÔºåËÄåRLVRÂàôÊµ™Ë¥π‰∫ÜÈáçË¶ÅÁöÑÁõëÁù£‰ø°ÊÅØ„ÄÇ
2. SPARKÊ°ÜÊû∂ÈÄöËøáÂõûÊî∂ÂõûÊªöÂíåÊ≠£Á°ÆÊÄßÊï∞ÊçÆÔºåÊûÑÂª∫ÁîüÊàêÂ•ñÂä±Ê®°ÂûãÔºåÂÆûÁé∞Â•ñÂä±‰∏éÁ≠ñÁï•ÁöÑÂçèÂêåÊºîÂåñ„ÄÇ
3. SPARKÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰æãÂ¶ÇÂú®7‰∏™Êé®ÁêÜÂü∫ÂáÜ‰∏äÂπ≥ÂùáÊèêÂçá9.7%ÔºåÂú®2‰∏™Â•ñÂä±Âü∫ÂáÜ‰∏äÊèêÂçá12.1%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËøëÂπ¥Êù•ÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂíåÂ§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàLVLMsÔºâÂú®ÂêéÊúüËÆ≠ÁªÉ‰∏≠Ë∂äÊù•Ë∂äÂ§öÂú∞‰ΩøÁî®Âº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÔºåÂ¶ÇÂèØÈ™åËØÅÂ•ñÂä±ÁöÑRLÔºàRLVRÔºâÂíåÂü∫‰∫é‰∫∫Á±ªÂèçÈ¶àÁöÑRLÔºàRLHFÔºâ„ÄÇÁÑ∂ËÄåÔºåRLHFÂ≠òÂú®È´òÊàêÊú¨ÂíåÊΩúÂú®ÁöÑÂ•ñÂä±-Á≠ñÁï•‰∏çÂåπÈÖçÈóÆÈ¢òÔºåËÄåRLVRÂàôÂú®ÊØèÊ¨°Êõ¥Êñ∞Âêé‰∏¢ÂºÉ‰∫ÜÈáçË¶ÅÁöÑÂõûÊªöÂíåÊ≠£Á°ÆÊÄß‰ø°Âè∑„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÊåëÊàòÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÈ´òÊïà„ÄÅÁ®≥ÂÆöÁöÑÂçèÂêåÁ≠ñÁï•‰∏éÂ•ñÂä±ÂÖ±ÂêåÊºîÂåñÊ°ÜÊû∂ÔºàSPARKÔºâÔºåËØ•Ê°ÜÊû∂ÈÄöËøáÂõûÊî∂ÂõûÊªöÂíåÊ≠£Á°ÆÊÄßÊï∞ÊçÆÔºåÂà©Áî®Ê∑∑ÂêàÁõÆÊ†áÂêåÊó∂ËÆ≠ÁªÉÁîüÊàêÂ•ñÂä±Ê®°ÂûãÔºå‰ªéËÄåÊ∂àÈô§‰∫ÜÂØπÂçïÁã¨Â•ñÂä±Ê®°ÂûãÂíå‰∫∫Á±ªÂÅèÂ•ΩÊï∞ÊçÆÁöÑÈúÄÊ±Ç„ÄÇÂÆûÈ™åË°®ÊòéÔºåSPARKÂú®Â§ö‰∏™LLMÂíåLVLMÊ®°Âûã‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ï‰∏≠RLHFÁöÑÈ´òÊàêÊú¨ÂíåRLVRÁöÑÁõëÁù£‰ø°ÊÅØÊµ™Ë¥πÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Êõ¥Êñ∞ËøáÁ®ã‰∏≠‰∏¢ÂºÉ‰∫ÜÈáçË¶ÅÁöÑÂõûÊªöÂíåÊ≠£Á°ÆÊÄß‰ø°Âè∑ÔºåÂØºËá¥ÊïàÁéá‰Ωé‰∏ã„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSPARKÊ°ÜÊû∂ÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂõûÊî∂ÂíåÂà©Áî®Ëøô‰∫õ‰∏¢ÂºÉÁöÑ‰ø°ÊÅØÔºåÈÄöËøáÂêåÊó∂ËÆ≠ÁªÉÁîüÊàêÂ•ñÂä±Ê®°ÂûãÊù•ÊèêÈ´òÂ•ñÂä±ÁöÑÂáÜÁ°ÆÊÄßÔºå‰ªéËÄå‰ºòÂåñÁ≠ñÁï•„ÄÇËøôÊ†∑ÁöÑËÆæËÆ°Êó®Âú®Ê∂àÈô§ÂØπÂ§ñÈÉ®Â•ñÂä±Ê®°ÂûãÂíå‰∫∫Á±ªÂÅèÂ•ΩÊï∞ÊçÆÁöÑ‰æùËµñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSPARKÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÂõûÊî∂Ê®°Âùó„ÄÅÁîüÊàêÂ•ñÂä±Ê®°ÂûãËÆ≠ÁªÉÊ®°ÂùóÂíåÁ≠ñÁï•‰ºòÂåñÊ®°Âùó„ÄÇÊï∞ÊçÆÂõûÊî∂Ê®°ÂùóË¥üË¥£Êî∂ÈõÜÂõûÊªöÂíåÊ≠£Á°ÆÊÄß‰ø°Âè∑ÔºåÁîüÊàêÂ•ñÂä±Ê®°ÂûãËÆ≠ÁªÉÊ®°Âùó‰ΩøÁî®Ê∑∑ÂêàÁõÆÊ†áËøõË°åËÆ≠ÁªÉÔºåÁ≠ñÁï•‰ºòÂåñÊ®°ÂùóÂàôÂü∫‰∫éÊîπËøõÁöÑÂ•ñÂä±ËøõË°åÁ≠ñÁï•Êõ¥Êñ∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSPARKÁöÑÊúÄÂ§ßÂàõÊñ∞Âú®‰∫éÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Ê≠£ÂêëÂèçÈ¶àÂæ™ÁéØÔºåÈÄöËøáÊèêÈ´òÂ•ñÂä±ÁöÑÂáÜÁ°ÆÊÄßÊù•‰ºòÂåñÁ≠ñÁï•Ê¢ØÂ∫¶Ôºå‰ªéËÄåÁîüÊàêÊõ¥È´òË¥®ÈáèÁöÑÂõûÊªöÔºåËøõ‰∏ÄÊ≠•ÊèêÂçáÂ•ñÂä±Ê®°ÂûãÁöÑÊÄßËÉΩ„ÄÇËøôÁßçÂçèÂêåÊºîÂåñÊú∫Âà∂‰∏é‰º†ÁªüÊñπÊ≥ïÊà™ÁÑ∂‰∏çÂêå„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏äÔºåSPARKÈááÁî®‰∫ÜÂ§öÁßçÁõÆÊ†áÂáΩÊï∞ÔºåÂåÖÊã¨ÁÇπÂØπÁÇπÂ•ñÂä±ËØÑÂàÜ„ÄÅÊàêÂØπÊØîËæÉÂíåÂü∫‰∫éËøõ‰∏ÄÊ≠•ÂèçÊÄùÁöÑËØÑ‰º∞Ôºå‰ª•ÊåáÂØºÊ®°ÂûãËØÑ‰º∞ÂíåÊîπËøõËá™Ë∫´ÁöÑÂìçÂ∫î„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SPARKÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Â±ïÁé∞Âá∫ÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºå‰æãÂ¶ÇSPARK-VL-7BÂú®7‰∏™Êé®ÁêÜÂü∫ÂáÜ‰∏äÂπ≥ÂùáÊèêÂçá9.7%ÔºåÂú®2‰∏™Â•ñÂä±Âü∫ÂáÜ‰∏äÊèêÂçá12.1%ÔºåÂú®8‰∏™ÈÄöÁî®Âü∫ÂáÜ‰∏äÊèêÂçá1.5%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéSPARKÂú®Â§öÁßç‰ªªÂä°‰∏≠ÂÖ∑ÊúâËâØÂ•ΩÁöÑÈ≤ÅÊ£íÊÄßÂíåÂπøÊ≥õÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SPARKÊ°ÜÊû∂Âú®Â§ö‰∏™È¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÈ´òÊïàÂíåÂáÜÁ°ÆÁöÑÂÜ≥Á≠ñÊîØÊåÅÁ≥ªÁªü‰∏≠ÔºåÂ¶ÇËá™Âä®ÂåñÂÆ¢Êúç„ÄÅÊô∫ËÉΩÊé®ËçêÁ≥ªÁªüÂíåÂ§çÊùÇ‰ªªÂä°ÁöÑËá™Âä®ÂåñÂ§ÑÁêÜ„ÄÇÈÄöËøáÂáèÂ∞ëÂØπ‰∫∫Á±ªÂèçÈ¶àÁöÑ‰æùËµñÔºåSPARKËÉΩÂ§üÈôç‰ΩéÊàêÊú¨Âπ∂ÊèêÈ´òÁ≥ªÁªüÁöÑËá™ÈÄÇÂ∫îËÉΩÂäõÔºåÊú™Êù•ÂèØËÉΩÂú®Êõ¥Â§öÂÆûÈôÖÂ∫îÁî®‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) increasingly use Reinforcement Learning (RL) for post-pretraining, such as RL with Verifiable Rewards (RLVR) for objective tasks and RL from Human Feedback (RLHF) for subjective tasks. However, RLHF incurs high costs and potential reward-policy mismatch due to reliance on human preferences, while RLVR still wastes supervision by discarding rollouts and correctness signals after each update. To address these challenges, we introduce the Synergistic Policy And Reward Co-Evolving Framework (SPARK), an efficient, on-policy, and stable method that builds on RLVR. Instead of discarding rollouts and correctness data, SPARK recycles this valuable information to simultaneously train the model itself as a generative reward model. This auxiliary training uses a mix of objectives, such as pointwise reward score, pairwise comparison, and evaluation conditioned on further-reflection responses, to teach the model to evaluate and improve its own responses. Our process eliminates the need for a separate reward model and costly human preference data. SPARK creates a positive co-evolving feedback loop: improved reward accuracy yields better policy gradients, which in turn produce higher-quality rollouts that further refine the reward model. Our unified framework supports test-time scaling via self-reflection without external reward models and their associated costs. We show that SPARK achieves significant performance gains on multiple LLM and LVLM models and multiple reasoning, reward models, and general benchmarks. For example, SPARK-VL-7B achieves an average 9.7% gain on 7 reasoning benchmarks, 12.1% on 2 reward benchmarks, and 1.5% on 8 general benchmarks over the baselines, demonstrating robustness and broad generalization.

