---
layout: default
title: FastVGGT: Training-Free Acceleration of Visual Geometry Transformer
---

# FastVGGT: Training-Free Acceleration of Visual Geometry Transformer

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.02560" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.02560v2</a>
  <a href="https://arxiv.org/pdf/2509.02560.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.02560v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.02560v2', 'FastVGGT: Training-Free Acceleration of Visual Geometry Transformer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: You Shen, Zhipeng Zhang, Yansong Qu, Xiawu Zheng, Jiayi Ji, Shengchuan Zhang, Liujuan Cao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-02 (æ›´æ–°: 2025-11-09)

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://mystorm16.github.io/fastvggt/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**FastVGGTï¼šé€šè¿‡æ— è®­ç»ƒTokenåˆå¹¶åŠ é€Ÿè§†è§‰å‡ ä½•Transformerï¼Œæå‡3Dè§†è§‰æ•ˆç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dè§†è§‰` `Transformer` `Tokenåˆå¹¶` `æ¨¡å‹åŠ é€Ÿ` `æ— è®­ç»ƒ` `é•¿åºåˆ—` `ä¸‰ç»´é‡å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dè§†è§‰Transformeræ¨¡å‹åœ¨å¤„ç†é•¿åºåˆ—å›¾åƒæ—¶ï¼Œæ¨ç†æ•ˆç‡ä½ï¼Œéš¾ä»¥æ‰©å±•ã€‚
2. æå‡ºFastVGGTï¼Œé€šè¿‡æ— è®­ç»ƒçš„tokenåˆå¹¶ç­–ç•¥ï¼Œå‡å°‘å†—ä½™è®¡ç®—ï¼ŒåŠ é€ŸVGGTæ¨¡å‹ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒFastVGGTåœ¨ä¿æŒé‡å»ºèƒ½åŠ›çš„åŒæ—¶ï¼Œå®ç°äº†4å€çš„åŠ é€Ÿï¼Œå¹¶å‡è½»äº†é•¿åºåˆ—è¯¯å·®ç´¯ç§¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸‰ç»´è§†è§‰åŸºç¡€æ¨¡å‹æœ€è¿‘åœ¨3Dæ„ŸçŸ¥æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç”±äºæ¨ç†æ—¶æ•ˆç‡ä½ä¸‹ï¼Œå°†è¿™äº›æ¨¡å‹æ‰©å±•åˆ°é•¿åºåˆ—å›¾åƒè¾“å…¥ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚æœ¬æ–‡å¯¹æœ€å…ˆè¿›çš„å‰é¦ˆè§†è§‰å‡ ä½•æ¨¡å‹VGGTè¿›è¡Œäº†è¯¦ç»†åˆ†æï¼Œå¹¶ç¡®å®šäº†å…¶ä¸»è¦ç“¶é¢ˆã€‚å¯è§†åŒ–è¿›ä¸€æ­¥æ­ç¤ºäº†æ³¨æ„åŠ›å›¾ä¸­çš„tokenå´©æºƒç°è±¡ã€‚å—è¿™äº›å‘ç°çš„å¯å‘ï¼Œæˆ‘ä»¬æ¢ç´¢äº†tokenåˆå¹¶åœ¨å‰é¦ˆè§†è§‰å‡ ä½•æ¨¡å‹ä¸­çš„æ½œåŠ›ã€‚ç”±äº3Dæ¨¡å‹çš„ç‹¬ç‰¹æ¶æ„å’Œç‰¹å®šäºä»»åŠ¡çš„å±æ€§ï¼Œç›´æ¥åº”ç”¨ç°æœ‰çš„åˆå¹¶æŠ€æœ¯å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†FastVGGTï¼Œå®ƒé¦–æ¬¡é€šè¿‡ä¸€ç§æ— è®­ç»ƒæœºåˆ¶åœ¨3Dé¢†åŸŸåˆ©ç”¨tokenåˆå¹¶æ¥åŠ é€ŸVGGTã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ç‹¬ç‰¹çš„tokenåˆ’åˆ†ç­–ç•¥ï¼Œä¸“é—¨ä¸º3Dæ¶æ„å’Œä»»åŠ¡é‡èº«å®šåˆ¶ï¼Œæœ‰æ•ˆåœ°æ¶ˆé™¤äº†å†—ä½™è®¡ç®—ï¼ŒåŒæ—¶ä¿ç•™äº†VGGTå¼ºå¤§çš„é‡å»ºèƒ½åŠ›ã€‚åœ¨å¤šä¸ª3Då‡ ä½•åŸºå‡†ä¸Šçš„å¤§é‡å®éªŒéªŒè¯äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¯¹äº1000ä¸ªè¾“å…¥å›¾åƒï¼ŒFastVGGTå®ç°äº†æ¯”VGGTå¿«4å€çš„é€Ÿåº¦ï¼ŒåŒæ—¶å‡è½»äº†é•¿åºåˆ—åœºæ™¯ä¸­çš„è¯¯å·®ç´¯ç§¯ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†tokenåˆå¹¶ä½œä¸ºå¯æ‰©å±•3Dè§†è§‰ç³»ç»Ÿçš„åŸåˆ™æ€§è§£å†³æ–¹æ¡ˆçš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³3Dè§†è§‰Transformeræ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯VGGTæ¨¡å‹ï¼Œåœ¨å¤„ç†é•¿åºåˆ—å›¾åƒè¾“å…¥æ—¶æ¨ç†æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ‰©å±•æ¨¡å‹åˆ°é•¿åºåˆ—è¾“å…¥æ—¶é¢ä¸´è®¡ç®—é‡æ˜¾è‘—å¢åŠ çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´å®é™…åº”ç”¨å—é™ã€‚VGGTæ¨¡å‹åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­å­˜åœ¨tokenå´©æºƒç°è±¡ï¼Œè¿›ä¸€æ­¥åŠ å‰§äº†è®¡ç®—å†—ä½™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡tokenåˆå¹¶æ¥å‡å°‘VGGTæ¨¡å‹ä¸­çš„å†—ä½™è®¡ç®—ï¼Œä»è€ŒåŠ é€Ÿæ¨ç†è¿‡ç¨‹ã€‚é€šè¿‡åˆå¹¶ç›¸ä¼¼æˆ–ä¸é‡è¦çš„tokenï¼Œå¯ä»¥æœ‰æ•ˆå‡å°‘Transformerå±‚çš„è®¡ç®—é‡ï¼Œæé«˜æ¨¡å‹æ•ˆç‡ã€‚è®ºæ–‡ç‰¹åˆ«å¼ºè°ƒäº†æ— è®­ç»ƒçš„tokenåˆå¹¶ç­–ç•¥ï¼Œé¿å…äº†é¢å¤–çš„è®­ç»ƒå¼€é”€å’Œå¯¹åŸå§‹æ¨¡å‹æ€§èƒ½çš„æ½œåœ¨å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFastVGGTçš„æ•´ä½“æ¡†æ¶æ˜¯åœ¨VGGTæ¨¡å‹çš„åŸºç¡€ä¸Šå¼•å…¥tokenåˆå¹¶æ¨¡å—ã€‚è¯¥æ¨¡å—åœ¨Transformerå±‚ä¹‹é—´è¿›è¡Œtokenåˆ’åˆ†å’Œåˆå¹¶æ“ä½œã€‚å…·ä½“æµç¨‹åŒ…æ‹¬ï¼š1) è¾“å…¥å›¾åƒåºåˆ—ç»è¿‡VGGTçš„åˆå§‹å¤„ç†ï¼›2) åœ¨Transformerå±‚ä¸­ï¼Œåº”ç”¨tokenåˆ’åˆ†ç­–ç•¥å°†tokenåˆ†æˆä¸åŒçš„ç»„ï¼›3) å¯¹æ¯ç»„tokenè¿›è¡Œåˆå¹¶ï¼Œå‡å°‘tokenæ•°é‡ï¼›4) åˆå¹¶åçš„tokenç»§ç»­é€šè¿‡åç»­çš„Transformerå±‚ï¼›5) æœ€ç»ˆè¾“å‡º3Dé‡å»ºç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§é’ˆå¯¹3Dè§†è§‰Transformerçš„æ— è®­ç»ƒtokenåˆå¹¶ç­–ç•¥ã€‚ä¸ç›´æ¥åº”ç”¨ç°æœ‰tokenåˆå¹¶æŠ€æœ¯ä¸åŒï¼ŒFastVGGTé’ˆå¯¹3Dæ¶æ„å’Œä»»åŠ¡ç‰¹æ€§ï¼Œè®¾è®¡äº†ç‹¬ç‰¹çš„tokenåˆ’åˆ†ç­–ç•¥ï¼Œé¿å…äº†æ€§èƒ½ä¸‹é™ã€‚è¿™ç§æ— è®­ç»ƒçš„æ–¹å¼ä½¿å¾—FastVGGTå¯ä»¥å³æ’å³ç”¨ï¼Œæ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œé™ä½äº†ä½¿ç”¨æˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šFastVGGTçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) Tokenåˆ’åˆ†ç­–ç•¥ï¼šæ ¹æ®3Dåœºæ™¯çš„å‡ ä½•ç‰¹æ€§ï¼Œå°†tokenåˆ’åˆ†ä¸ºä¸åŒçš„ç»„ï¼Œä¾‹å¦‚åŸºäºç©ºé—´ä½ç½®æˆ–ç‰¹å¾ç›¸ä¼¼åº¦ã€‚2) Tokenåˆå¹¶å‡†åˆ™ï¼šé‡‡ç”¨æ— è®­ç»ƒçš„æ–¹å¼ï¼Œä¾‹å¦‚åŸºäºtokençš„èƒ½é‡æˆ–é‡è¦æ€§è¿›è¡Œæ’åºï¼Œåˆå¹¶ä½èƒ½é‡æˆ–ä¸é‡è¦çš„tokenã€‚3) åˆå¹¶æ¯”ä¾‹ï¼šæ ¹æ®è®¡ç®—èµ„æºå’Œæ€§èƒ½éœ€æ±‚ï¼ŒåŠ¨æ€è°ƒæ•´åˆå¹¶æ¯”ä¾‹ï¼Œä»¥è¾¾åˆ°æœ€ä½³çš„åŠ é€Ÿæ•ˆæœã€‚è®ºæ–‡æœªæ˜ç¡®æåŠæŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„çš„ä¿®æ”¹ï¼Œé‡ç‚¹åœ¨äºtokenåˆå¹¶æ¨¡å—çš„è®¾è®¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFastVGGTåœ¨1000ä¸ªè¾“å…¥å›¾åƒçš„æƒ…å†µä¸‹ï¼Œå®ç°äº†æ¯”VGGTå¿«4å€çš„åŠ é€Ÿã€‚åŒæ—¶ï¼ŒFastVGGTæœ‰æ•ˆåœ°å‡è½»äº†é•¿åºåˆ—åœºæ™¯ä¸­çš„è¯¯å·®ç´¯ç§¯ï¼Œä¿æŒäº†VGGTå¼ºå¤§çš„é‡å»ºèƒ½åŠ›ã€‚è¿™äº›ç»“æœéªŒè¯äº†tokenåˆå¹¶ä½œä¸ºå¯æ‰©å±•3Dè§†è§‰ç³»ç»Ÿæœ‰æ•ˆè§£å†³æ–¹æ¡ˆçš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FastVGGTåœ¨æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€ä¸‰ç»´é‡å»ºç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚é€šè¿‡æé«˜3Dè§†è§‰æ¨¡å‹çš„æ¨ç†æ•ˆç‡ï¼Œå¯ä»¥æ”¯æŒæ›´å¤æ‚çš„åœºæ™¯ç†è§£å’Œæ›´å®æ—¶çš„å†³ç­–ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæ¨åŠ¨3Dè§†è§‰æŠ€æœ¯åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„éƒ¨ç½²ï¼Œä¾‹å¦‚ç§»åŠ¨æœºå™¨äººå’ŒåµŒå…¥å¼ç³»ç»Ÿï¼Œå¹¶åŠ é€Ÿç›¸å…³åº”ç”¨çš„è½åœ°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Foundation models for 3D vision have recently demonstrated remarkable capabilities in 3D perception. However, scaling these models to long-sequence image inputs remains a significant challenge due to inference-time inefficiency. In this work, we present a detailed analysis of VGGT, a state-of-the-art feed-forward visual geometry model and identify its primary bottleneck. Visualization further reveals a token collapse phenomenon in the attention maps. Motivated by these findings, we explore the potential of token merging in the feed-forward visual geometry model. Owing to the unique architectural and task-specific properties of 3D models, directly applying existing merging techniques proves challenging. To this end, we propose FastVGGT, which, for the first time, leverages token merging in the 3D domain through a training-free mechanism for accelerating VGGT. we devise a unique token partitioning strategy tailored to 3D architectures and tasks, effectively eliminating redundant computation while preserving VGGT's powerful reconstruction capacity. Extensive experiments on multiple 3D geometry benchmarks validate the effectiveness of our approach. Notably, with 1000 input images, FastVGGT achieves a 4x speedup over VGGT while mitigating error accumulation in long-sequence scenarios. These findings underscore the potential of token merging as a principled solution for scalable 3D vision systems. Code is available at: https://mystorm16.github.io/fastvggt/.

