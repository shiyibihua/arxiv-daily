---
layout: default
title: FusWay: Multimodal hybrid fusion approach. Application to Railway Defect Detection
---

# FusWay: Multimodal hybrid fusion approach. Application to Railway Defect Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.06987" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.06987v1</a>
  <a href="https://arxiv.org/pdf/2509.06987.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.06987v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.06987v1', 'FusWay: Multimodal hybrid fusion approach. Application to Railway Defect Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alexey Zhukov, Jenny Benois-Pineau, Amira Youssef, Akka Zemmari, Mohamed Mosbah, Virginie Taillandier

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-02

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFusWayå¤šæ¨¡æ€èåˆæ–¹æ³•ï¼Œç”¨äºæå‡é“è·¯ç¼ºé™·æ£€æµ‹ç²¾åº¦ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é“è·¯ç¼ºé™·æ£€æµ‹` `å¤šæ¨¡æ€èåˆ` `YOLOv8` `Vision Transformer` `éŸ³é¢‘ç‰¹å¾` `ç›®æ ‡æ£€æµ‹` `ç»“æ„å¥åº·ç›‘æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é“è·¯ç¼ºé™·æ£€æµ‹æ–¹æ³•ä¾èµ–å•ä¸€è§†è§‰æ¨¡æ€ï¼Œæ˜“å—å¹²æ‰°ï¼Œå¯¼è‡´è¿‡åº¦æ£€æµ‹ï¼Œå½±å“æ£€æµ‹ç²¾åº¦ã€‚
2. FusWayèåˆå›¾åƒå’ŒéŸ³é¢‘ä¿¡æ¯ï¼Œåˆ©ç”¨YOLOv8nå¿«é€Ÿæ£€æµ‹å’ŒViTæå–å¤šå±‚ç‰¹å¾ï¼Œæå‡æ£€æµ‹å‡†ç¡®ç‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒFusWayåœ¨é“è·¯ç¼ºé™·æ£€æµ‹ä¸­ï¼Œç²¾åº¦å’Œæ•´ä½“å‡†ç¡®ç‡ç›¸è¾ƒäºä»…è§†è§‰æ–¹æ³•æå‡0.2ä¸ªç™¾åˆ†ç‚¹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€èåˆæ˜¯ä¸€ç§å¤šåª’ä½“æŠ€æœ¯ï¼Œå·²å¹¿æ³›åº”ç”¨äºå›¾åƒä¿¡æ¯ä¼´éšä¿¡å·/éŸ³é¢‘çš„ä»»åŠ¡ä¸­ã€‚åè€…å¯èƒ½ä¸ä¼ è¾¾é«˜åº¦è¯­ä¹‰ä¿¡æ¯ï¼Œä¾‹å¦‚è¯­éŸ³æˆ–éŸ³ä¹ï¼Œä½†å¯ä»¥åŒ…å«ç”¨äºæ£€æµ‹è½¨é“ç»“æ„å…ƒç´ æˆ–ç¼ºé™·çš„éŸ³é¢‘ä¿¡å·ã€‚è™½ç„¶è¯¸å¦‚YOLOç³»åˆ—æ£€æµ‹å™¨ç­‰ç»å…¸æ£€æµ‹æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°éƒ¨ç½²åœ¨å›¾åƒæ¨¡æ€ä¸Šè¿›è¡Œç¼ºé™·æ£€æµ‹ï¼Œä½†å•æ¨¡æ€æ–¹æ³•ä»ç„¶å­˜åœ¨å±€é™æ€§ï¼Œåœ¨å‡ºç°ä¸æ­£å¸¸ç»“æ„å…ƒç´ ç›¸ä¼¼çš„å¤–è§‚æ—¶å®¹æ˜“è¿‡åº¦æ£€æµ‹ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¤šæ¨¡æ€èåˆæ¶æ„ï¼Œè¯¥æ¶æ„åŸºäºé¢†åŸŸè§„åˆ™ï¼Œå¹¶ç»“åˆäº†YOLOå’ŒVision Transformeréª¨å¹²ç½‘ç»œã€‚å®ƒé›†æˆäº†YOLOv8nç”¨äºå¿«é€Ÿç›®æ ‡æ£€æµ‹ï¼Œå¹¶ä½¿ç”¨Vision Transformer (ViT) ç»“åˆä»å¤šä¸ªå±‚ï¼ˆ7ã€16å’Œ19ï¼‰æå–çš„ç‰¹å¾å›¾ä»¥åŠåˆæˆçš„éŸ³é¢‘è¡¨ç¤ºï¼Œç”¨äºä¸¤ç§ç¼ºé™·ç±»åˆ«ï¼šè½¨é“æ–­è£‚å’Œè¡¨é¢ç¼ºé™·ã€‚èåˆåœ¨éŸ³é¢‘å’Œå›¾åƒä¹‹é—´è¿›è¡Œã€‚åœ¨çœŸå®é“è·¯æ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œä¸ä»…ä½¿ç”¨è§†è§‰çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„å¤šæ¨¡æ€èåˆå°†ç²¾åº¦å’Œæ•´ä½“å‡†ç¡®ç‡æé«˜äº†0.2ä¸ªç™¾åˆ†ç‚¹ã€‚Student's unpaired t-testä¹Ÿè¯å®äº†å¹³å‡å‡†ç¡®ç‡å·®å¼‚çš„ç»Ÿè®¡æ˜¾è‘—æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šé“è·¯ç¼ºé™·æ£€æµ‹æ˜¯ä¿éšœé“è·¯å®‰å…¨çš„å…³é”®ç¯èŠ‚ã€‚ç°æœ‰çš„åŸºäºè§†è§‰çš„ç¼ºé™·æ£€æµ‹æ–¹æ³•ï¼Œä¾‹å¦‚YOLOç³»åˆ—ï¼Œåœ¨å¤æ‚åœºæ™¯ä¸‹å®¹æ˜“å—åˆ°å…‰ç…§ã€é˜´å½±ç­‰å› ç´ çš„å¹²æ‰°ï¼Œå¯¼è‡´å°†æ­£å¸¸ç»“æ„å…ƒç´ è¯¯åˆ¤ä¸ºç¼ºé™·ï¼Œäº§ç”Ÿè¿‡åº¦æ£€æµ‹çš„é—®é¢˜ã€‚è¿™é™ä½äº†æ£€æµ‹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFusWayçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šæ¨¡æ€èåˆï¼Œå°†å›¾åƒä¿¡æ¯å’ŒéŸ³é¢‘ä¿¡æ¯ç»“åˆèµ·æ¥ï¼Œäº’è¡¥å½¼æ­¤çš„ä¸è¶³ã€‚å›¾åƒä¿¡æ¯æä¾›ç¼ºé™·çš„è§†è§‰ç‰¹å¾ï¼Œè€ŒéŸ³é¢‘ä¿¡æ¯åˆ™æä¾›ç¼ºé™·äº§ç”Ÿçš„æŒ¯åŠ¨æˆ–å£°éŸ³ç‰¹å¾ã€‚é€šè¿‡èåˆè¿™ä¸¤ç§æ¨¡æ€çš„ä¿¡æ¯ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°åˆ¤æ–­ç¼ºé™·çš„å­˜åœ¨å’Œç±»å‹ï¼Œå‡å°‘è¿‡åº¦æ£€æµ‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFusWayçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) YOLOv8nç›®æ ‡æ£€æµ‹å™¨ï¼šç”¨äºå¿«é€Ÿæ£€æµ‹å›¾åƒä¸­çš„æ½œåœ¨ç¼ºé™·åŒºåŸŸã€‚2) Vision Transformer (ViT)ï¼šç”¨äºæå–å›¾åƒçš„å¤šå±‚ç‰¹å¾ï¼Œæ•æ‰æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚3) éŸ³é¢‘ç‰¹å¾æå–æ¨¡å—ï¼šç”¨äºå°†éŸ³é¢‘ä¿¡å·è½¬æ¢ä¸ºå¯ç”¨çš„ç‰¹å¾è¡¨ç¤ºã€‚4) å¤šæ¨¡æ€èåˆæ¨¡å—ï¼šå°†å›¾åƒç‰¹å¾å’ŒéŸ³é¢‘ç‰¹å¾è¿›è¡Œèåˆï¼Œå¾—åˆ°æœ€ç»ˆçš„ç¼ºé™·æ£€æµ‹ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šFusWayçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å¤šæ¨¡æ€èåˆç­–ç•¥ã€‚å®ƒä¸æ˜¯ç®€å•åœ°å°†å›¾åƒå’ŒéŸ³é¢‘ç‰¹å¾è¿›è¡Œæ‹¼æ¥ï¼Œè€Œæ˜¯æ ¹æ®é¢†åŸŸçŸ¥è¯†ï¼Œé€‰æ‹©æ€§åœ°èåˆä¸åŒæ¨¡æ€çš„ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œå¯¹äºæŸäº›ç±»å‹çš„ç¼ºé™·ï¼ŒéŸ³é¢‘ä¿¡æ¯å¯èƒ½æ›´å…·æœ‰åˆ¤åˆ«æ€§ï¼Œå› æ­¤åœ¨èåˆæ—¶ä¼šèµ‹äºˆéŸ³é¢‘ç‰¹å¾æ›´é«˜çš„æƒé‡ã€‚æ­¤å¤–ï¼ŒFusWayè¿˜åˆ©ç”¨ViTæå–å›¾åƒçš„å¤šå±‚ç‰¹å¾ï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰ç¼ºé™·çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šFusWayçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) YOLOv8nä½œä¸ºå¿«é€Ÿç›®æ ‡æ£€æµ‹å™¨ï¼Œä¿è¯äº†æ£€æµ‹çš„æ•ˆç‡ã€‚2) ViTæå–å›¾åƒçš„ç¬¬7ã€16å’Œ19å±‚ç‰¹å¾ï¼Œä»¥æ•æ‰ä¸åŒå°ºåº¦çš„ä¿¡æ¯ã€‚3) éŸ³é¢‘ç‰¹å¾çš„åˆæˆæ–¹å¼ï¼Œéœ€è¦æ ¹æ®å…·ä½“çš„éŸ³é¢‘ä¿¡å·ç‰¹ç‚¹è¿›è¡Œè®¾è®¡ã€‚4) å¤šæ¨¡æ€èåˆæ¨¡å—çš„èåˆç­–ç•¥ï¼Œéœ€è¦æ ¹æ®ä¸åŒç¼ºé™·ç±»å‹çš„ç‰¹ç‚¹è¿›è¡Œä¼˜åŒ–ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿéœ€è¦è€ƒè™‘å¤šæ¨¡æ€ä¿¡æ¯çš„ç‰¹ç‚¹ï¼Œä¾‹å¦‚å¯ä»¥ä½¿ç”¨å¯¹æ¯”æŸå¤±æ¥å¢å¼ºä¸åŒæ¨¡æ€ä¹‹é—´çš„å…³è”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

FusWayåœ¨çœŸå®é“è·¯æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä»…ä½¿ç”¨è§†è§‰çš„æ–¹æ³•ç›¸æ¯”ï¼ŒFusWayå°†ç²¾åº¦å’Œæ•´ä½“å‡†ç¡®ç‡æé«˜äº†0.2ä¸ªç™¾åˆ†ç‚¹ã€‚Student's unpaired t-testä¹Ÿè¯å®äº†å¹³å‡å‡†ç¡®ç‡å·®å¼‚çš„ç»Ÿè®¡æ˜¾è‘—æ€§ã€‚è¿™è¡¨æ˜FusWayçš„å¤šæ¨¡æ€èåˆç­–ç•¥èƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡é“è·¯ç¼ºé™·æ£€æµ‹çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FusWayå¯åº”ç”¨äºé“è·¯è½¨é“å®‰å…¨æ£€æµ‹ã€æ¡¥æ¢ç»“æ„å¥åº·ç›‘æµ‹ç­‰é¢†åŸŸã€‚é€šè¿‡èåˆè§†è§‰å’Œå¬è§‰ç­‰å¤šæ¨¡æ€ä¿¡æ¯ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®ã€æ›´å¯é åœ°æ£€æµ‹ç»“æ„æ€§ç¼ºé™·ï¼Œé™ä½å®‰å…¨é£é™©ï¼Œå‡å°‘ç»´æŠ¤æˆæœ¬ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal fusion is a multimedia technique that has become popular in the wide range of tasks where image information is accompanied by a signal/audio. The latter may not convey highly semantic information, such as speech or music, but some measures such as audio signal recorded by mics in the goal to detect rail structure elements or defects. While classical detection approaches such as You Only Look Once (YOLO) family detectors can be efficiently deployed for defect detection on the image modality, the single modality approaches remain limited. They yield an overdetection in case of the appearance similar to normal structural elements. The paper proposes a new multimodal fusion architecture built on the basis of domain rules with YOLO and Vision transformer backbones. It integrates YOLOv8n for rapid object detection with a Vision Transformer (ViT) to combine feature maps extracted from multiple layers (7, 16, and 19) and synthesised audio representations for two defect classes: rail Rupture and Surface defect. Fusion is performed between audio and image. Experimental evaluation on a real-world railway dataset demonstrates that our multimodal fusion improves precision and overall accuracy by 0.2 points compared to the vision-only approach. Student's unpaired t-test also confirms statistical significance of differences in the mean accuracy.

