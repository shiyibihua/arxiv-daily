---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-12-15
---

# cs.CVï¼ˆ2025-12-15ï¼‰

ğŸ“Š å…± **26** ç¯‡è®ºæ–‡
 | ğŸ”— **7** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (12 ğŸ”—5)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (10 ğŸ”—2)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1)</a>
<a href="#æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting" class="interest-badge">æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1)</a>
<a href="#æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction" class="interest-badge">æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (12 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 1 | [StarryGazer: Leveraging Monocular Depth Estimation Models for Domain-Agnostic Single Depth Image Completion](./papers/251213147v1-starrygazer-leveraging-monocular-depth-estimation-models-for-domain-.html) | StarryGazerï¼šåˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹å®ç°é¢†åŸŸæ— å…³çš„å•æ·±åº¦å›¾åƒè¡¥å…¨ |  |
| 2 | [Nexels: Neurally-Textured Surfels for Real-Time Novel View Synthesis with Sparse Geometries](./papers/251213796v1-nexels-neurally-textured-surfels-for-real-time-novel-view-synthesis-.html) | æå‡ºåŸºäºç¥ç»çº¹ç†Surfelçš„æ–°è§†è§’åˆæˆæ–¹æ³•ï¼Œåœ¨ç¨€ç–å‡ ä½•ä¸‹å®ç°å®æ—¶æ¸²æŸ“ã€‚ |  |
| 3 | [Charge: A Comprehensive Novel View Synthesis Benchmark and Dataset to Bind Them All](./papers/251213639v1-charge-a-comprehensive-novel-view-synthesis-benchmark-and-dataset-to.html) | æå‡ºChargeæ•°æ®é›†ï¼Œç”¨äºé«˜è´¨é‡æ–°è§†è§’åˆæˆçš„ç»¼åˆåŸºå‡†æµ‹è¯•ã€‚ |  |
| 4 | [Computer vision training dataset generation for robotic environments using Gaussian splatting](./papers/251213411v1-computer-vision-training-dataset-generation-for-robotic-environments.html) | æå‡ºåŸºäºé«˜æ–¯æº…å°„çš„æœºå™¨äººç¯å¢ƒè®¡ç®—æœºè§†è§‰è®­ç»ƒæ•°æ®é›†ç”Ÿæˆæµç¨‹ |  |
| 5 | [MMDrive: Interactive Scene Understanding Beyond Vision with Multi-representational Fusion](./papers/251213177v2-mmdrive-interactive-scene-understanding-beyond-vision-with-multi-rep.html) | MMDriveï¼šæå‡ºå¤šæ¨¡æ€èåˆçš„äº¤äº’å¼åœºæ™¯ç†è§£æ¡†æ¶ï¼Œè¶…è¶Šè§†è§‰å±€é™ |  |
| 6 | [TWLR: Text-Guided Weakly-Supervised Lesion Localization and Severity Regression for Explainable Diabetic Retinopathy Grading](./papers/251213008v1-twlr-text-guided-weakly-supervised-lesion-localization-and-severity-.html) | æå‡ºTWLRæ¡†æ¶ï¼Œåˆ©ç”¨æ–‡æœ¬å¼•å¯¼çš„å¼±ç›‘ç£å­¦ä¹ è¿›è¡Œç³–å°¿ç—…è§†ç½‘è†œç—…å˜åˆ†çº§ä¸ç—…ç¶å®šä½ã€‚ |  |
| 7 | [LASER: Layer-wise Scale Alignment for Training-Free Streaming 4D Reconstruction](./papers/251213680v1-laser-layer-wise-scale-alignment-for-training-free-streaming-4d-reco.html) | æå‡ºLASERä»¥è§£å†³æµåª’ä½“4Dé‡å»ºä¸­çš„è®­ç»ƒéœ€æ±‚é—®é¢˜ | âœ… |
| 8 | [LitePT: Lighter Yet Stronger Point Transformer](./papers/251213689v1-litept-lighter-yet-stronger-point-transformer.html) | LitePTï¼šä¸€ç§æ›´è½»é‡ä½†æ›´å¼ºå¤§çš„ç‚¹äº‘Transformerï¼Œé€šè¿‡å·ç§¯ä¸æ³¨æ„åŠ›æœºåˆ¶çš„æœ‰æ•ˆç»“åˆæå‡æ€§èƒ½ã€‚ | âœ… |
| 9 | [I-Scene: 3D Instance Models are Implicit Generalizable Spatial Learners](./papers/251213683v1-i-scene-3d-instance-models-are-implicit-generalizable-spatial-learne.html) | I-Sceneï¼šåˆ©ç”¨é¢„è®­ç»ƒ3Då®ä¾‹ç”Ÿæˆå™¨å®ç°å¯æ³›åŒ–çš„éšå¼åœºæ™¯ç©ºé—´å­¦ä¹  | âœ… |
| 10 | [On-Device Continual Learning for Unsupervised Visual Anomaly Detection in Dynamic Manufacturing](./papers/251213497v1-on-device-continual-learning-for-unsupervised-visual-anomaly-detecti.html) | æå‡ºåŸºäºè®¾å¤‡ç«¯æŒç»­å­¦ä¹ çš„PatchCoreæ”¹è¿›æ–¹æ³•ï¼Œç”¨äºåŠ¨æ€åˆ¶é€ ä¸­çš„æ— ç›‘ç£è§†è§‰å¼‚å¸¸æ£€æµ‹ã€‚ |  |
| 11 | [DePT3R: Joint Dense Point Tracking and 3D Reconstruction of Dynamic Scenes in a Single Forward Pass](./papers/251213122v1-dept3r-joint-dense-point-tracking-and-3d-reconstruction-of-dynamic-s.html) | DePT3Rï¼šå•æ¬¡å‰å‘ä¼ æ’­å®ç°åŠ¨æ€åœºæ™¯çš„è”åˆç¨ å¯†ç‚¹è¿½è¸ªä¸3Dé‡å»º | âœ… |
| 12 | [VoroLight: Learning Quality Volumetric Voronoi Meshes from General Inputs](./papers/251212984v1-vorolight-learning-quality-volumetric-voronoi-meshes-from-general-in.html) | VoroLightï¼šæå‡ºåŸºäºå¯å¾®Voronoiå›¾çš„é€šç”¨è¾“å…¥ä¸‰ç»´å½¢çŠ¶é‡å»ºæ¡†æ¶ | âœ… |


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (10 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 13 | [Motus: A Unified Latent Action World Model](./papers/251213030v1-motus-a-unified-latent-action-world-model.html) | æå‡ºMotusä»¥è§£å†³å¤šæ¨¡æ€ç”Ÿæˆèƒ½åŠ›ç»Ÿä¸€é—®é¢˜ |  |
| 14 | [Recurrent Video Masked Autoencoders](./papers/251213684v1-recurrent-video-masked-autoencoders.html) | æå‡ºRVMï¼šä¸€ç§åŸºäºTransformerå¾ªç¯ç¥ç»ç½‘ç»œçš„è§†é¢‘æ©ç è‡ªç¼–ç å™¨ï¼Œç”¨äºé«˜æ•ˆè§†é¢‘è¡¨å¾å­¦ä¹ ã€‚ |  |
| 15 | [MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning](./papers/251213636v2-minddrive-a-vision-language-action-model-for-autonomous-driving-via-.html) | MindDriveï¼šæå‡ºåŸºäºåœ¨çº¿å¼ºåŒ–å­¦ä¹ çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼Œç”¨äºè‡ªåŠ¨é©¾é©¶ã€‚ |  |
| 16 | [Self-Supervised Ultrasound Representation Learning for Renal Anomaly Prediction in Prenatal Imaging](./papers/251213434v1-self-supervised-ultrasound-representation-learning-for-renal-anomaly.html) | æå‡ºåŸºäºè‡ªç›‘ç£å­¦ä¹ çš„USF-MAEæ¨¡å‹ï¼Œç”¨äºäº§å‰è¶…å£°è‚¾è„å¼‚å¸¸è‡ªåŠ¨é¢„æµ‹ã€‚ |  |
| 17 | [SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning](./papers/251213874v1-sage-training-smart-any-horizon-agents-for-long-video-reasoning-with.html) | æå‡ºSAGEï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ™ºèƒ½ä»»æ„æ—¶åŸŸAgentï¼Œç”¨äºé•¿è§†é¢‘æ¨ç†ã€‚ |  |
| 18 | [LongVie 2: Multimodal Controllable Ultra-Long Video World Model](./papers/251213604v1-longvie-2-multimodal-controllable-ultra-long-video-world-model.html) | LongVie 2ï¼šå¤šæ¨¡æ€å¯æ§è¶…é•¿è§†é¢‘ä¸–ç•Œæ¨¡å‹ï¼Œå®ç°é«˜è´¨é‡é•¿æ—¶åºè§†é¢‘ç”Ÿæˆã€‚ |  |
| 19 | [Enhancing Semi-Supervised Multi-View Graph Convolutional Networks via Supervised Contrastive Learning and Self-Training](./papers/251213770v1-enhancing-semi-supervised-multi-view-graph-convolutional-networks-vi.html) | æå‡ºMV-SupGCNï¼Œé€šè¿‡ç›‘ç£å¯¹æ¯”å­¦ä¹ å’Œè‡ªè®­ç»ƒå¢å¼ºåŠç›‘ç£å¤šè§†å›¾å›¾å·ç§¯ç½‘ç»œ | âœ… |
| 20 | [ADHint: Adaptive Hints with Difficulty Priors for Reinforcement Learning](./papers/251213095v1-adhint-adaptive-hints-with-difficulty-priors-for-reinforcement-learn.html) | ADHintï¼šåˆ©ç”¨éš¾åº¦å…ˆéªŒçš„è‡ªé€‚åº”æç¤ºå¼ºåŒ–å­¦ä¹ ï¼Œæå‡æ¨ç†èƒ½åŠ›å’Œæ³›åŒ–æ€§ |  |
| 21 | [RecTok: Reconstruction Distillation along Rectified Flow](./papers/251213421v1-rectok-reconstruction-distillation-along-rectified-flow.html) | RecTokï¼šé€šè¿‡æ ¡æ­£æµä¸Šçš„é‡æ„è’¸é¦ï¼Œçªç ´é«˜ç»´è§†è§‰Tokenizersçš„æ€§èƒ½ç“¶é¢ˆ | âœ… |
| 22 | [AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection](./papers/251213671v1-agentiad-tool-augmented-single-agent-for-industrial-anomaly-detectio.html) | AgentIADï¼šå·¥å…·å¢å¼ºçš„å•æ™ºèƒ½ä½“å·¥ä¸šå¼‚å¸¸æ£€æµ‹æ¡†æ¶ |  |


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 23 | [MoLingo: Motion-Language Alignment for Text-to-Motion Generation](./papers/251213840v1-molingo-motion-language-alignment-for-text-to-motion-generation.html) | MoLingoï¼šé€šè¿‡è¿åŠ¨-è¯­è¨€å¯¹é½å®ç°æ–‡æœ¬åˆ°åŠ¨ä½œç”Ÿæˆï¼Œè¾¾åˆ°æ–°çš„SOTAã€‚ |  |


<h2 id="æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting">ğŸ”¬ æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 24 | [Grab-3D: Detecting AI-Generated Videos from 3D Geometric Temporal Consistency](./papers/251213665v1-grab-3d-detecting-ai-generated-videos-from-3d-geometric-temporal-con.html) | æå‡ºGrab-3Dï¼Œåˆ©ç”¨3Då‡ ä½•æ—¶åºä¸€è‡´æ€§æ£€æµ‹AIç”Ÿæˆè§†é¢‘ |  |


<h2 id="æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction">ğŸ”¬ æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 25 | [3D Human-Human Interaction Anomaly Detection](./papers/251213560v1-3d-human-human-interaction-anomaly-detection.html) | æå‡ºIADNetï¼Œç”¨äºæ£€æµ‹3Däººä½“äº¤äº’ä¸­çš„å¼‚å¸¸è¡Œä¸º |  |


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 26 | [KlingAvatar 2.0 Technical Report](./papers/251213313v1-klingavatar-20-technical-report.html) | æå‡ºKlingAvatar 2.0ä»¥è§£å†³é•¿è§†é¢‘ç”Ÿæˆä¸­çš„æ•ˆç‡ä¸ä¸€è‡´æ€§é—®é¢˜ |  |


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)