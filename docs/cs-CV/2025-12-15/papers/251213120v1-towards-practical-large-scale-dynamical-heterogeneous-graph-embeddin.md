---
layout: default
title: Towards Practical Large-scale Dynamical Heterogeneous Graph Embedding: Cold-start Resilient Recommendation
---

# Towards Practical Large-scale Dynamical Heterogeneous Graph Embedding: Cold-start Resilient Recommendation

**arXiv**: [2512.13120v1](https://arxiv.org/abs/2512.13120) | [PDF](https://arxiv.org/pdf/2512.13120.pdf)

**ä½œè€…**: Mabiao Long, Jiaxi Liu, Yufeng Li, Hao Xiong, Junchi Yan, Kefan Wang, Yi Cao, Jiandong Ding

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸¤é˜¶æ®µåŠ¨æ€å¼‚æž„å›¾åµŒå…¥æ¡†æž¶ï¼Œä»¥è§£å†³å¤§è§„æ¨¡ç”Ÿäº§çŽ¯å¢ƒä¸­çš„å¯æ‰©å±•æ€§ã€æ•°æ®æ–°é²œåº¦å’Œå†·å¯åŠ¨é—®é¢˜ã€‚**

**å…³é”®è¯**: `åŠ¨æ€å¼‚æž„å›¾åµŒå…¥` `å†·å¯åŠ¨æŽ¨è` `å¢žé‡å­¦ä¹ ` `å›¾å˜æ¢å™¨` `å®žæ—¶æ›´æ–°` `ç”Ÿäº§éƒ¨ç½²`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŠ¨æ€å¼‚æž„å›¾åµŒå…¥åœ¨ç”Ÿäº§éƒ¨ç½²ä¸­é¢ä¸´å¯æ‰©å±•æ€§ã€æ•°æ®æ–°é²œåº¦å’Œå†·å¯åŠ¨æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆHetSGFormerè¿›è¡Œé™æ€å…¨å±€å­¦ä¹ ï¼Œä½¿ç”¨ILLEè¿›è¡Œè½»é‡çº§å®žæ—¶å¢žé‡æ›´æ–°ï¼Œé¿å…å…¨å›¾é‡è®­ç»ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åäº¿çº§å›¾ä¸Šï¼ŒA/Bæµ‹è¯•æ˜¾ç¤ºHetSGFormeræå‡å¹¿å‘Šä»·å€¼6.11%ï¼ŒILLEé¢å¤–æå‡3.22%ï¼Œåˆ·æ–°æ—¶æ•ˆæ€§æé«˜83.2%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deploying dynamic heterogeneous graph embeddings in production faces key challenges of scalability, data freshness, and cold-start. This paper introduces a practical, two-stage solution that balances deep graph representation with low-latency incremental updates. Our framework combines HetSGFormer, a scalable graph transformer for static learning, with Incremental Locally Linear Embedding (ILLE), a lightweight, CPU-based algorithm for real-time updates. HetSGFormer captures global structure with linear scalability, while ILLE provides rapid, targeted updates to incorporate new data, thus avoiding costly full retraining. This dual approach is cold-start resilient, leveraging the graph to create meaningful embeddings from sparse data. On billion-scale graphs, A/B tests show HetSGFormer achieved up to a 6.11% lift in Advertiser Value over previous methods, while the ILLE module added another 3.22% lift and improved embedding refresh timeliness by 83.2%. Our work provides a validated framework for deploying dynamic graph learning in production environments.

