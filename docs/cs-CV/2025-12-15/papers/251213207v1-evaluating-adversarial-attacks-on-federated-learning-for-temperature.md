---
layout: default
title: Evaluating Adversarial Attacks on Federated Learning for Temperature Forecasting
---

# Evaluating Adversarial Attacks on Federated Learning for Temperature Forecasting

**arXiv**: [2512.13207v1](https://arxiv.org/abs/2512.13207) | [PDF](https://arxiv.org/pdf/2512.13207.pdf)

**ä½œè€…**: Karina Chichifoi, Fabio Merizzi, Michele Colajanni

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¯¹æŠ—æ”»å‡»å¯¹è”é‚¦å­¦ä¹ æ¸©åº¦é¢„æµ‹çš„å½±å“ï¼Œæ­ç¤ºç©ºé—´ä¾èµ–æ€§æ”¾å¤§å¨èƒ**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `å¯¹æŠ—æ”»å‡»` `æ¸©åº¦é¢„æµ‹` `æ•°æ®æŠ•æ¯’` `ç©ºé—´ä¾èµ–æ€§` `é˜²å¾¡æœºåˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç ”ç©¶è”é‚¦å­¦ä¹ åœ¨æ¸©åº¦é¢„æµ‹ä¸­é¢ä¸´çš„æ•°æ®æŠ•æ¯’æ”»å‡»ï¼Œç‰¹åˆ«æ˜¯åŸºäºŽç©ºé—´ä¾èµ–æ€§çš„å¨èƒ
2. æ¨¡æ‹Ÿåˆ†å¸ƒå¼å®¢æˆ·ç«¯ï¼Œè¯„ä¼°å…¨å±€åç½®å’ŒåŸºäºŽè¡¥ä¸çš„æ”»å‡»å¯¹åŒºåŸŸé¢„æµ‹çš„æ‰­æ›²æ•ˆæžœ
3. å®žéªŒæ˜¾ç¤ºå°‘é‡ä¸­æ¯’å®¢æˆ·ç«¯å¯è¯¯å¯¼å¤§é¢ç§¯é¢„æµ‹ï¼Œä¿®å‰ªå‡å€¼èšåˆé˜²å¾¡å¯¹å…¨å±€æ”»å‡»æœ‰æ•ˆä½†å¯¹è¡¥ä¸æ”»å‡»å¤±è´¥

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deep learning and federated learning (FL) are becoming powerful partners for next-generation weather forecasting. Deep learning enables high-resolution spatiotemporal forecasts that can surpass traditional numerical models, while FL allows institutions in different locations to collaboratively train models without sharing raw data, addressing efficiency and security concerns. While FL has shown promise across heterogeneous regions, its distributed nature introduces new vulnerabilities. In particular, data poisoning attacks, in which compromised clients inject manipulated training data, can degrade performance or introduce systematic biases. These threats are amplified by spatial dependencies in meteorological data, allowing localized perturbations to influence broader regions through global model aggregation. In this study, we investigate how adversarial clients distort federated surface temperature forecasts trained on the Copernicus European Regional ReAnalysis (CERRA) dataset. We simulate geographically distributed clients and evaluate patch-based and global biasing attacks on regional temperature forecasts. Our results show that even a small fraction of poisoned clients can mislead predictions across large, spatially connected areas. A global temperature bias attack from a single compromised client shifts predictions by up to -1.7 K, while coordinated patch attacks more than triple the mean squared error and produce persistent regional anomalies exceeding +3.5 K. Finally, we assess trimmed mean aggregation as a defense mechanism, showing that it successfully defends against global bias attacks (2-13\% degradation) but fails against patch attacks (281-603\% amplification), exposing limitations of outlier-based defenses for spatially correlated data.

