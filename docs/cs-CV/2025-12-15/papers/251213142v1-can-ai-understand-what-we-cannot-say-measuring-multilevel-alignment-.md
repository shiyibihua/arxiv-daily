---
layout: default
title: Can AI Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma Across Cognitive, Interpersonal, and Structural Levels
---

# Can AI Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma Across Cognitive, Interpersonal, and Structural Levels

**arXiv**: [2512.13142v1](https://arxiv.org/abs/2512.13142) | [PDF](https://arxiv.org/pdf/2512.13142.pdf)

**ä½œè€…**: Anika Sharma, Malavika Mampally, Chidaksh Ravuru, Kandyce Brennan, Neil Gaikwad

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§è¯­è¨€æ¨¡åž‹å¯¹å •èƒŽè€»è¾±çš„å¤šå±‚æ¬¡ç†è§£ï¼Œæ­ç¤ºå…¶ç¼ºä¹è¿žè´¯å¿ƒç†ç”Ÿç†è®¤çŸ¥**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹è¯„ä¼°` `å •èƒŽè€»è¾±` `å¤šå±‚æ¬¡å¯¹é½` `å¿ƒç†ç”Ÿç†ç†è§£` `AIå®‰å…¨` `åè§æ£€æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è¯­è¨€æ¨¡åž‹èƒ½å¦çœŸå®žç†è§£å¤æ‚å¿ƒç†ç”Ÿç†çŽ°è±¡å¦‚å •èƒŽè€»è¾±ï¼Œåœ¨è®¤çŸ¥ã€äººé™…å’Œç»“æž„å±‚æ¬¡ä¸Šä¿æŒè¿žè´¯æ€§
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨éªŒè¯è¿‡çš„ä¸ªä½“æ°´å¹³å •èƒŽè€»è¾±é‡è¡¨ï¼Œç³»ç»Ÿæµ‹è¯•äº”ä¸ªé¢†å…ˆæ¨¡åž‹åœ¨627ä¸ªå¤šæ ·åŒ–äººç‰©è§’è‰²ä¸Šçš„è¡¨çŽ°
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ¨¡åž‹åœ¨æ‰€æœ‰å±‚æ¬¡ä¸Šå‡æœªé€šè¿‡çœŸå®žç†è§£æµ‹è¯•ï¼Œè¡¨çŽ°å‡ºåå·®ã€çŸ›ç›¾å’Œä¸ä¸€è‡´ï¼Œå¼ºè°ƒéœ€æ–°è®¾è®¡ã€è¯„ä¼°å’Œæ²»ç†æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> As large language models increasingly mediate stigmatized health decisions, their capacity to genuinely understand complex psychological and physiological phenomena remains poorly evaluated. Can AI understand what we cannot say? We investigate whether LLMs coherently represent abortion stigma across the cognitive, interpersonal, and structural levels where it operates. We systematically tested 627 demographically diverse personas across five leading LLMs using the validated Individual Level Abortion Stigma Scale (ILAS). Our multilevel analysis examined whether models coherently represent stigma at the cognitive level (self-judgment), interpersonal level (anticipated judgment and isolation), and structural level (community condemnation and disclosure patterns), as well as overall stigma. Models fail tests of genuine understanding across all levels. They overestimate interpersonal stigma while underestimating cognitive stigma, assume uniform community condemnation, introduce demographic biases absent from human validation data, miss the empirically validated stigma-secrecy relationship, and contradict themselves within theoretical constructs. These patterns reveal that current alignment approaches ensure appropriate language but not coherent multilevel understanding. This work provides empirical evidence that current LLMs lack coherent multilevel understanding of psychological and physiological constructs. AI safety in high-stakes contexts demands new approaches to design (multilevel coherence), evaluation (continuous auditing), governance and regulation (mandatory audits, accountability, deployment restrictions), and AI literacy in domains where understanding what people cannot say determines whether support helps or harms.

