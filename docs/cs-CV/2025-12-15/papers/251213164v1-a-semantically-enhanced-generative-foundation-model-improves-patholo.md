---
layout: default
title: A Semantically Enhanced Generative Foundation Model Improves Pathological Image Synthesis
---

# A Semantically Enhanced Generative Foundation Model Improves Pathological Image Synthesis

**arXiv**: [2512.13164v1](https://arxiv.org/abs/2512.13164) | [PDF](https://arxiv.org/pdf/2512.13164.pdf)

**ä½œè€…**: Xianchao Guan, Zhiyuan Fan, Yifeng Wang, Fuqiang Chen, Yanjiang Zhou, Zengyang Che, Hongxue Meng, Xin Li, Yaowei Wang, Hongpeng Wang, Min Zhang, Heng Tao Shen, Zheng Zhang, Yongbing Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCRAFTSç”ŸæˆåŸºç¡€æ¨¡åž‹ä»¥è§£å†³ç—…ç†å›¾åƒåˆæˆä¸­çš„è¯­ä¹‰ä¸ç¨³å®šé—®é¢˜**

**å…³é”®è¯**: `ç—…ç†å›¾åƒåˆæˆ` `ç”ŸæˆåŸºç¡€æ¨¡åž‹` `è¯­ä¹‰å¯¹é½` `æ•°æ®å¢žå¼º` `ä¸´åºŠAI`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç—…ç†AIå‘å±•å—é™äºŽé«˜è´¨é‡æ ‡æ³¨æ•°æ®ç¨€ç¼ºï¼ŒçŽ°æœ‰ç”Ÿæˆæ¨¡åž‹å­˜åœ¨è¯­ä¹‰æ¼‚ç§»å’Œå½¢æ€å¹»è§‰ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åŒé˜¶æ®µè®­ç»ƒå’Œç›¸å…³æ€§å¯¹é½æœºåˆ¶ï¼ŒåŸºäºŽ280ä¸‡å›¾åƒ-æ–‡æœ¬å¯¹ï¼Œç¡®ä¿ç”Ÿç‰©å‡†ç¡®æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç”Ÿæˆ30ç§ç™Œç—‡ç±»åž‹å›¾åƒï¼Œé€šè¿‡å®¢è§‚æŒ‡æ ‡å’Œç—…ç†å­¦å®¶è¯„ä¼°éªŒè¯ï¼Œå¢žå¼ºå¤šç§ä¸´åºŠä»»åŠ¡æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The development of clinical-grade artificial intelligence in pathology is limited by the scarcity of diverse, high-quality annotated datasets. Generative models offer a potential solution but suffer from semantic instability and morphological hallucinations that compromise diagnostic reliability. To address this challenge, we introduce a Correlation-Regulated Alignment Framework for Tissue Synthesis (CRAFTS), the first generative foundation model for pathology-specific text-to-image synthesis. By leveraging a dual-stage training strategy on approximately 2.8 million image-caption pairs, CRAFTS incorporates a novel alignment mechanism that suppresses semantic drift to ensure biological accuracy. This model generates diverse pathological images spanning 30 cancer types, with quality rigorously validated by objective metrics and pathologist evaluations. Furthermore, CRAFTS-augmented datasets enhance the performance across various clinical tasks, including classification, cross-modal retrieval, self-supervised learning, and visual question answering. In addition, coupling CRAFTS with ControlNet enables precise control over tissue architecture from inputs such as nuclear segmentation masks and fluorescence images. By overcoming the critical barriers of data scarcity and privacy concerns, CRAFTS provides a limitless source of diverse, annotated histology data, effectively unlocking the creation of robust diagnostic tools for rare and complex cancer phenotypes.

