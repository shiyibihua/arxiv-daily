---
layout: default
title: Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration
---

# Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration

**arXiv**: [2512.13293v1](https://arxiv.org/abs/2512.13293) | [PDF](https://arxiv.org/pdf/2512.13293.pdf)

**ä½œè€…**: Hao Fua, Wei Liu, Shuai Zhoua

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå†…åœ¨åŠ¨æœºåè°ƒæŽ¢ç´¢çš„å¤šæœºå™¨äººå¼ºåŒ–å­¦ä¹ ç®—æ³•ä»¥è§£å†³ç¤¾äº¤ç¼–é˜Ÿå¯¼èˆªä¸­çš„æŽ¢ç´¢æ•ˆçŽ‡é—®é¢˜**

**å…³é”®è¯**: `å¤šæœºå™¨äººå¼ºåŒ–å­¦ä¹ ` `ç¤¾äº¤ç¼–é˜Ÿå¯¼èˆª` `å†…åœ¨åŠ¨æœºæŽ¢ç´¢` `åè°ƒæŽ¢ç´¢` `é›†ä¸­è®­ç»ƒåˆ†æ•£æ‰§è¡Œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæœºå™¨äººç¤¾äº¤ç¼–é˜Ÿå¯¼èˆªä¸­ï¼Œè¡Œäººè¡Œä¸ºä¸å¯é¢„æµ‹ä¸”ä¸åˆä½œï¼Œå¯¼è‡´åè°ƒæŽ¢ç´¢æ•ˆçŽ‡ä½Žä¸‹
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥å†…åœ¨å¥–åŠ±æœºåˆ¶ç¼“è§£ç­–ç•¥ä¿å®ˆæ€§ï¼Œé‡‡ç”¨åŒé‡‡æ ·æ¨¡å¼å’Œä¸¤æ—¶é—´å°ºåº¦æ›´æ–°è§„åˆ™ä¼˜åŒ–ç­–ç•¥ä¸Žå¥–åŠ±è¡¨ç¤º
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ç¤¾äº¤ç¼–é˜Ÿå¯¼èˆªåŸºå‡†æµ‹è¯•ä¸­ï¼Œç®—æ³•åœ¨å…³é”®æŒ‡æ ‡ä¸Šä¼˜äºŽçŽ°æœ‰å…ˆè¿›æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper investigates the application of reinforcement learning (RL) to multi-robot social formation navigation, a critical capability for enabling seamless human-robot coexistence. While RL offers a promising paradigm, the inherent unpredictability and often uncooperative dynamics of pedestrian behavior pose substantial challenges, particularly concerning the efficiency of coordinated exploration among robots. To address this, we propose a novel coordinated-exploration multi-robot RL algorithm introducing an intrinsic motivation exploration. Its core component is a self-learning intrinsic reward mechanism designed to collectively alleviate policy conservatism. Moreover, this algorithm incorporates a dual-sampling mode within the centralized training and decentralized execution framework to enhance the representation of both the navigation policy and the intrinsic reward, leveraging a two-time-scale update rule to decouple parameter updates. Empirical results on social formation navigation benchmarks demonstrate the proposed algorithm's superior performance over existing state-of-the-art methods across crucial metrics. Our code and video demos are available at: https://github.com/czxhunzi/CEMRRL.

