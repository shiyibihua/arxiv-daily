---
layout: default
title: Unified Interactive Multimodal Moment Retrieval via Cascaded Embedding-Reranking and Temporal-Aware Score Fusion
---

# Unified Interactive Multimodal Moment Retrieval via Cascaded Embedding-Reranking and Temporal-Aware Score Fusion

**arXiv**: [2512.12935v1](https://arxiv.org/abs/2512.12935) | [PDF](https://arxiv.org/pdf/2512.12935.pdf)

**ä½œè€…**: Toan Le Ngo Thanh, Phat Ha Huu, Tan Nguyen Dang Duy, Thong Nguyen Le Minh, Anh Nguyen Nhu Tinh

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€äº¤äº’å¼å¤šæ¨¡æ€æ—¶åˆ»æ£€ç´¢ç³»ç»Ÿï¼Œé€šè¿‡çº§è”åµŒå…¥-é‡æŽ’åºå’Œæ—¶åºæ„ŸçŸ¥è¯„åˆ†èžåˆè§£å†³è·¨æ¨¡æ€å™ªå£°å’Œæ¨¡ç³ŠæŸ¥è¯¢é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ—¶åˆ»æ£€ç´¢` `æ—¶åºå»ºæ¨¡` `æŸ¥è¯¢åˆ†è§£` `åµŒå…¥èžåˆ` `äº¤äº’å¼æœç´¢` `è§†é¢‘ç†è§£`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•é¢ä¸´å›ºå®šæƒé‡èžåˆç­–ç•¥å¤±æ•ˆã€æ—¶åºå»ºæ¨¡éš¾ä»¥æ•æ‰è¿žè´¯äº‹ä»¶åºåˆ—ã€éœ€æ‰‹åŠ¨æ¨¡æ€é€‰æ‹©é™ä½Žå¯ç”¨æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨çº§è”åŒåµŒå…¥ç®¡é“ç»“åˆBEIT-3å’ŒSigLIPè¿›è¡Œå¹¿æ³›æ£€ç´¢ï¼ŒBLIP-2é‡æŽ’åºä¼˜åŒ–ï¼›æ—¶åºæ„ŸçŸ¥è¯„åˆ†æœºåˆ¶é€šè¿‡æ³¢æŸæœç´¢æ–½åŠ æŒ‡æ•°è¡°å‡æƒ©ç½šï¼›Agentå¼•å¯¼æŸ¥è¯¢åˆ†è§£è‡ªåŠ¨è§£é‡Šæ¨¡ç³ŠæŸ¥è¯¢å¹¶è‡ªé€‚åº”èžåˆåˆ†æ•°ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç³»ç»Ÿæœ‰æ•ˆå¤„ç†æ¨¡ç³ŠæŸ¥è¯¢ï¼Œæ£€ç´¢æ—¶åºè¿žè´¯åºåˆ—ï¼ŒåŠ¨æ€é€‚åº”èžåˆç­–ç•¥ï¼Œæå‡äº¤äº’å¼æ—¶åˆ»æœç´¢èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The exponential growth of video content has created an urgent need for efficient multimodal moment retrieval systems. However, existing approaches face three critical challenges: (1) fixed-weight fusion strategies fail across cross modal noise and ambiguous queries, (2) temporal modeling struggles to capture coherent event sequences while penalizing unrealistic gaps, and (3) systems require manual modality selection, reducing usability. We propose a unified multimodal moment retrieval system with three key innovations. First, a cascaded dual-embedding pipeline combines BEIT-3 and SigLIP for broad retrieval, refined by BLIP-2 based reranking to balance recall and precision. Second, a temporal-aware scoring mechanism applies exponential decay penalties to large temporal gaps via beam search, constructing coherent event sequences rather than isolated frames. Third, Agent-guided query decomposition (GPT-4o) automatically interprets ambiguous queries, decomposes them into modality specific sub-queries (visual/OCR/ASR), and performs adaptive score fusion eliminating manual modality selection. Qualitative analysis demonstrates that our system effectively handles ambiguous queries, retrieves temporally coherent sequences, and dynamically adapts fusion strategies, advancing interactive moment search capabilities.

