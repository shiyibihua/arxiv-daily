---
layout: default
title: Sharpness-aware Dynamic Anchor Selection for Generalized Category Discovery
---

# Sharpness-aware Dynamic Anchor Selection for Generalized Category Discovery

**arXiv**: [2512.12925v1](https://arxiv.org/abs/2512.12925) | [PDF](https://arxiv.org/pdf/2512.12925.pdf)

**ä½œè€…**: Zhimao Peng, Enguang Wang, Fei Yang, Xialei Liu, Ming-Ming Cheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSharpness-aware Dynamic Anchor Selectionä»¥è§£å†³å¹¿ä¹‰ç±»åˆ«å‘çŽ°ä¸­ä¼ªæ ‡ç­¾å™ªå£°é—®é¢˜**

**å…³é”®è¯**: `å¹¿ä¹‰ç±»åˆ«å‘çŽ°` `ä¼ªæ ‡ç­¾å™ªå£°` `æŸå¤±é”åº¦æƒ©ç½š` `åŠ¨æ€é”šç‚¹é€‰æ‹©` `å¼€æ”¾ä¸–ç•Œå­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§é¢„è®­ç»ƒæ¨¡åž‹åå¥½ç‰¹å®šè§†è§‰æ¨¡å¼ï¼Œå¯¼è‡´æœªæ ‡è®°æ•°æ®ç¼–ç ä¼ªç›¸å…³å’Œç”Ÿæˆå™ªå£°ä¼ªæ ‡ç­¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥æŸå¤±é”åº¦æƒ©ç½šå¢žå¼ºæ¨¡åž‹é²æ£’æ€§ï¼ŒåŠ¨æ€é”šç‚¹é€‰æ‹©åŸºäºŽKNNå¯†åº¦å’Œç±»æ¦‚çŽ‡é€‰å–æœªçŸ¥ç±»ä»£è¡¨æ ·æœ¬ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªGCDåŸºå‡†æµ‹è¯•ä¸­å®žçŽ°æœ€å…ˆè¿›ç»“æžœï¼Œæœ‰æ•ˆå‡è½»ä¼ªæ ‡ç­¾å™ªå£°ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generalized category discovery (GCD) is an important and challenging task in open-world learning. Specifically, given some labeled data of known classes, GCD aims to cluster unlabeled data that contain both known and unknown classes. Current GCD methods based on parametric classification adopt the DINO-like pseudo-labeling strategy, where the sharpened probability output of one view is used as supervision information for the other view. However, large pre-trained models have a preference for some specific visual patterns, resulting in encoding spurious correlation for unlabeled data and generating noisy pseudo-labels. To address this issue, we propose a novel method, which contains two modules: Loss Sharpness Penalty (LSP) and Dynamic Anchor Selection (DAS). LSP enhances the robustness of model parameters to small perturbations by minimizing the worst-case loss sharpness of the model, which suppressing the encoding of trivial features, thereby reducing overfitting of noise samples and improving the quality of pseudo-labels. Meanwhile, DAS selects representative samples for the unknown classes based on KNN density and class probability during the model training and assigns hard pseudo-labels to them, which not only alleviates the confidence difference between known and unknown classes but also enables the model to quickly learn more accurate feature distribution for the unknown classes, thus further improving the clustering accuracy. Extensive experiments demonstrate that the proposed method can effectively mitigate the noise of pseudo-labels, and achieve state-of-the-art results on multiple GCD benchmarks.

