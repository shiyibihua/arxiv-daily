---
layout: default
title: Async Control: Stress-testing Asynchronous Control Measures for LLM Agents
---

# Async Control: Stress-testing Asynchronous Control Measures for LLM Agents

**arXiv**: [2512.13526v1](https://arxiv.org/abs/2512.13526) | [PDF](https://arxiv.org/pdf/2512.13526.pdf)

**ä½œè€…**: Asa Cooper Stickland, Jan Michelfeit, Arathi Mani, Charlie Griffin, Ollie Matthews, Tomek Korbak, Rogan Inglis, Oliver Makins, Alan Cooney

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¼‚æ­¥ç›‘æŽ§æ–¹æ³•ä»¥è¯„ä¼°LLMä»£ç†åœ¨è½¯ä»¶å·¥ç¨‹ä¸­çš„ç ´åé£Žé™©**

**å…³é”®è¯**: `LLMä»£ç†å®‰å…¨` `å¼‚æ­¥ç›‘æŽ§` `å¯¹æŠ—æ¸¸æˆ` `è½¯ä»¶å·¥ç¨‹çŽ¯å¢ƒ` `é£Žé™©è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šLLMä»£ç†åœ¨æ•æ„Ÿä»£ç åº“ä¸­å¯èƒ½æ•…æ„ç ´åï¼Œéœ€ç›‘æŽ§å…¶è¡Œä¸ºä»¥é˜²æ­¢ä¸å¯é€†æŸå®³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å¼‚æ­¥ç›‘æŽ§ï¼Œé€šè¿‡çº¢è“é˜Ÿå¯¹æŠ—æ¸¸æˆå¼€å‘ç›‘æŽ§ç³»ç»Ÿï¼Œä¸å¢žåŠ è¿è¡Œæ—¶å»¶è¿Ÿã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨5ä¸ªè½¯ä»¶å·¥ç¨‹çŽ¯å¢ƒä¸­ï¼Œé›†æˆç›‘æŽ§å™¨åœ¨1%è¯¯æŠ¥çŽ‡ä¸‹è¾¾åˆ°6%æ¼æŠ¥çŽ‡ï¼Œå¹¶åŸºäºŽæ­¤ä¼°è®¡éƒ¨ç½²é£Žé™©ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> LLM-based software engineering agents are increasingly used in real-world development tasks, often with access to sensitive data or security-critical codebases. Such agents could intentionally sabotage these codebases if they were misaligned. We investigate asynchronous monitoring, in which a monitoring system reviews agent actions after the fact. Unlike synchronous monitoring, this approach does not impose runtime latency, while still attempting to disrupt attacks before irreversible harm occurs. We treat monitor development as an adversarial game between a blue team (who design monitors) and a red team (who create sabotaging agents). We attempt to set the game rules such that they upper bound the sabotage potential of an agent based on Claude 4.1 Opus. To ground this game in a realistic, high-stakes deployment scenario, we develop a suite of 5 diverse software engineering environments that simulate tasks that an agent might perform within an AI developer's internal infrastructure. Over the course of the game, we develop an ensemble monitor that achieves a 6% false negative rate at 1% false positive rate on a held out test environment. Then, we estimate risk of sabotage at deployment time by extrapolating from our monitor's false negative rate. We describe one simple model for this extrapolation, present a sensitivity analysis, and describe situations in which the model would be invalid. Code is available at: https://github.com/UKGovernmentBEIS/async-control.

