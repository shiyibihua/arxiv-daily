---
layout: default
title: AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection
---

# AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.13671" target="_blank" class="toolbar-btn">arXiv: 2512.13671v1</a>
    <a href="https://arxiv.org/pdf/2512.13671.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.13671v1" 
            onclick="toggleFavorite(this, '2512.13671v1', 'AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Junwen Miao, Penghui Du, Yi Liu, Yu Wang, Yan Wang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-15

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**AgentIADÔºöÂ∑•ÂÖ∑Â¢ûÂº∫ÁöÑÂçïÊô∫ËÉΩ‰ΩìÂ∑•‰∏öÂºÇÂ∏∏Ê£ÄÊµãÊ°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Â∑•‰∏öÂºÇÂ∏∏Ê£ÄÊµã` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `Êô∫ËÉΩ‰Ωì` `Âº∫ÂåñÂ≠¶‰π†` `Â∑•ÂÖ∑Â¢ûÂº∫` `Â§öÈò∂ÊÆµÊ£ÄÊü•` `ÂèØËß£ÈáäÊÄß`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Â∑•‰∏öÂºÇÂ∏∏Ê£ÄÊµã‰∏≠ÔºåÊ≠£Â∏∏Ê†∑Êú¨Â∞ë‰∏îÁº∫Èô∑ÁªÜÂæÆÔºå‰º†ÁªüÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàËØÜÂà´„ÄÇ
2. AgentIADÂà©Áî®Â∑•ÂÖ∑Â¢ûÂº∫ÁöÑÊô∫ËÉΩ‰ΩìÔºåÈÄöËøáÂ§öÈò∂ÊÆµÊ£ÄÊü•ÂíåÊØîËæÉÊ≠£Â∏∏Ê†∑Êú¨Êù•Ê£ÄÊµãÂºÇÂ∏∏„ÄÇ
3. AgentIADÂú®MMADÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Ü97.62%ÁöÑÂàÜÁ±ªÁ≤æÂ∫¶ÔºåË∂ÖË∂äÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â∑•‰∏öÂºÇÂ∏∏Ê£ÄÊµã(IAD)Èù¢‰∏¥Ê≠£Â∏∏Ê†∑Êú¨Á®ÄÁº∫ÂíåÁº∫Èô∑ÁªÜÂæÆÂ±ÄÈÉ®ÁöÑÊåëÊàò„ÄÇÂçïÊ¨°ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã(VLM)Â∏∏ÂøΩÁï•Â∞èÂºÇÂ∏∏ÔºåÁº∫‰πè‰∏éÊ†áÂáÜÊ≠£Â∏∏Ê®°ÂºèÊØîËæÉÁöÑÊú∫Âà∂„ÄÇÊàë‰ª¨ÊèêÂá∫AgentIADÔºå‰∏Ä‰∏™Â∑•ÂÖ∑È©±Âä®ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºåÂÆûÁé∞Â§öÈò∂ÊÆµËßÜËßâÊ£ÄÊü•„ÄÇÊô∫ËÉΩ‰ΩìÈÖçÂ§áÊÑüÁü•Áº©ÊîæÂô®(PZ)ËøõË°åÂ±ÄÈÉ®ÁªÜÁ≤íÂ∫¶ÂàÜÊûêÔºå‰ª•ÂèäÊØîËæÉÊ£ÄÁ¥¢Âô®(CR)Âú®ËØÅÊçÆÊ®°Á≥äÊó∂Êü•ËØ¢Ê≠£Â∏∏Ê†∑Êú¨„ÄÇ‰∏∫ËÆ≠ÁªÉÊ£ÄÊü•Ë°å‰∏∫ÔºåÊàë‰ª¨‰ªéMMADÊï∞ÊçÆÈõÜÊûÑÂª∫ÁªìÊûÑÂåñÁöÑÊÑüÁü•ÂíåÊØîËæÉËΩ®ËøπÔºåÂπ∂ÂàÜ‰∏§Èò∂ÊÆµËÆ≠ÁªÉÔºöÁõëÁù£ÂæÆË∞ÉÂíåÂº∫ÂåñÂ≠¶‰π†„ÄÇÂèåÈáçÂ•ñÂä±ËÆæËÆ°È©±Âä®Ê≠§ËøáÁ®ãÔºöÊÑüÁü•Â•ñÂä±ÁõëÁù£ÂàÜÁ±ªÁ≤æÂ∫¶„ÄÅÁ©∫Èó¥ÂØπÈΩêÂíåÁ±ªÂûãÊ≠£Á°ÆÊÄßÔºåË°å‰∏∫Â•ñÂä±ÈºìÂä±È´òÊïàÂ∑•ÂÖ∑‰ΩøÁî®„ÄÇËøô‰∫õÁªÑ‰ª∂ÂÖ±Âêå‰ΩøÊ®°ÂûãÈÄöËøáÈÄêÊ≠•ËßÇÂØü„ÄÅÁº©ÊîæÂíåÈ™åËØÅÊù•ÊîπËøõÂà§Êñ≠„ÄÇAgentIADÂú®MMAD‰∏äËææÂà∞97.62%ÁöÑÂàÜÁ±ªÁ≤æÂ∫¶ÔºåË∂ÖË∂ä‰∫ÜÂÖàÂâçÁöÑÂü∫‰∫éMLLMÁöÑÊñπÊ≥ïÔºåÂπ∂‰∫ßÁîüÈÄèÊòé‰∏îÂèØËß£ÈáäÁöÑÊ£ÄÊü•ËΩ®Ëøπ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂ∑•‰∏öÂºÇÂ∏∏Ê£ÄÊµã‰ªªÂä°Êó®Âú®ËØÜÂà´Áîü‰∫ßÁ∫ø‰∏äÁöÑÁº∫Èô∑‰∫ßÂìÅ„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÁâπÂà´ÊòØÂçïÊ¨°ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã(VLM)ÔºåÂú®Â§ÑÁêÜÁªÜÂæÆ„ÄÅÂ±ÄÈÉ®ÂºÇÂ∏∏Êó∂Ë°®Áé∞‰∏ç‰Ω≥ÔºåÁº∫‰πè‰∏éÊ≠£Â∏∏Ê†∑Êú¨ËøõË°åÊòæÂºèÊØîËæÉÁöÑÊú∫Âà∂ÔºåÂÆπÊòìÂøΩÁï•ÂÖ≥ÈîÆÁº∫Èô∑„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞Âà©Áî®ÊúâÈôêÁöÑÊ≠£Â∏∏Ê†∑Êú¨‰ø°ÊÅØÔºåÂπ∂ËÆæËÆ°ËÉΩÂ§üËÅöÁÑ¶ÁªÜÂæÆÂºÇÂ∏∏ÁöÑÊ£ÄÊµãÊµÅÁ®ãÔºåÊòØÊú¨ËÆ∫ÊñáË¶ÅËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂºïÂÖ•‰∏Ä‰∏™Â∑•ÂÖ∑Â¢ûÂº∫ÁöÑÊô∫ËÉΩ‰ΩìÔºåÈÄöËøáÂ§öÈò∂ÊÆµÁöÑËßÜËßâÊ£ÄÊü•ÊµÅÁ®ãÊù•Ê®°Êãü‰∫∫Á±ª‰∏ìÂÆ∂ÁöÑÊ£ÄÊµãËøáÁ®ã„ÄÇÊô∫ËÉΩ‰ΩìÂèØ‰ª•Âà©Áî®‚ÄúÊÑüÁü•Áº©ÊîæÂô®‚ÄùËÅöÁÑ¶Â±ÄÈÉ®Âå∫ÂüüÔºåÂπ∂Âà©Áî®‚ÄúÊØîËæÉÊ£ÄÁ¥¢Âô®‚ÄùÊü•ËØ¢Ê≠£Â∏∏Ê†∑Êú¨ËøõË°åÂØπÊØîÔºå‰ªéËÄåÊõ¥ÂáÜÁ°ÆÂú∞Âà§Êñ≠ÊòØÂê¶Â≠òÂú®ÂºÇÂ∏∏„ÄÇËøôÁßçËÆæËÆ°ÂÄüÈâ¥‰∫Ü‰∫∫Á±ª‰∏ìÂÆ∂ÈÄêÊ≠•ËßÇÂØü„ÄÅÊîæÂ§ßÁªÜËäÇ„ÄÅÂØπÊØîÂèÇËÄÉÁöÑÊ£ÄÊµã‰π†ÊÉØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAgentIADÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) **Perceptive Zoomer (PZ)**ÔºöÁî®‰∫éÂØπÂõæÂÉèÁöÑÂ±ÄÈÉ®Âå∫ÂüüËøõË°åÁªÜÁ≤íÂ∫¶ÂàÜÊûê„ÄÇ2) **Comparative Retriever (CR)**ÔºöÁî®‰∫é‰ªéÊ≠£Â∏∏Ê†∑Êú¨Â∫ì‰∏≠Ê£ÄÁ¥¢Áõ∏‰ººÁöÑÊ†∑Êú¨ËøõË°åÊØîËæÉ„ÄÇ3) **Agent**ÔºöË¥üË¥£ÊéßÂà∂PZÂíåCRÁöÑ‰ΩøÁî®ÔºåÂπ∂Ê†πÊçÆËßÇÂØüÁªìÊûúÂÅöÂá∫Âà§Êñ≠„ÄÇËÆ≠ÁªÉËøáÁ®ãÂàÜ‰∏∫‰∏§‰∏™Èò∂ÊÆµÔºöÈ¶ñÂÖàÔºå‰ΩøÁî®ÁõëÁù£Â≠¶‰π†ÂØπÊô∫ËÉΩ‰ΩìËøõË°åÂæÆË∞ÉÔºå‰ΩøÂÖ∂ÂàùÊ≠•ÂÖ∑Â§áÊÑüÁü•ÂíåÊØîËæÉËÉΩÂäõÔºõÁÑ∂ÂêéÔºå‰ΩøÁî®Âº∫ÂåñÂ≠¶‰π†Ëøõ‰∏ÄÊ≠•‰ºòÂåñÊô∫ËÉΩ‰ΩìÁöÑË°å‰∏∫Á≠ñÁï•Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®Â∑•ÂÖ∑ËøõË°åÊ£ÄÊµã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ËÆ∫ÊñáÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÂ∞ÜÂ∑•ÂÖ∑Â¢ûÂº∫ÁöÑÊô∫ËÉΩ‰ΩìÂºïÂÖ•Â∑•‰∏öÂºÇÂ∏∏Ê£ÄÊµãÈ¢ÜÂüü„ÄÇ‰∏é‰º†ÁªüÁöÑÂçïÊ¨°VLMÊñπÊ≥ïÁõ∏ÊØîÔºåAgentIADËÉΩÂ§üÈÄöËøáÂ§öÈò∂ÊÆµÁöÑÊ£ÄÊü•ÊµÅÁ®ãÔºåÊõ¥ÊúâÊïàÂú∞Âà©Áî®Â±ÄÈÉ®‰ø°ÊÅØÂíåÊ≠£Â∏∏Ê†∑Êú¨‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òÊ£ÄÊµãÁ≤æÂ∫¶„ÄÇÊ≠§Â§ñÔºåAgentIADÁöÑÊ£ÄÊü•ËøáÁ®ãÊòØÈÄèÊòé‰∏îÂèØËß£ÈáäÁöÑÔºåÂèØ‰ª•‰∏∫Áî®Êà∑Êèê‰æõÊõ¥ËØ¶ÁªÜÁöÑÂºÇÂ∏∏ËØäÊñ≠‰ø°ÊÅØ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåËÆ∫ÊñáËÆæËÆ°‰∫Ü‰∏Ä‰∏™ÂèåÈáçÂ•ñÂä±Êú∫Âà∂Ôºö1) **ÊÑüÁü•Â•ñÂä±**ÔºöÁî®‰∫éÁõëÁù£ÂàÜÁ±ªÁ≤æÂ∫¶„ÄÅÁ©∫Èó¥ÂØπÈΩêÂíåÁ±ªÂûãÊ≠£Á°ÆÊÄßÔºåÁ°Æ‰øùÊô∫ËÉΩ‰ΩìËÉΩÂ§üÂáÜÁ°ÆÂú∞ËØÜÂà´ÂºÇÂ∏∏Á±ªÂûãÂíå‰ΩçÁΩÆ„ÄÇ2) **Ë°å‰∏∫Â•ñÂä±**ÔºöÁî®‰∫éÈºìÂä±Êô∫ËÉΩ‰ΩìÈ´òÊïàÂú∞‰ΩøÁî®Â∑•ÂÖ∑Ôºå‰æãÂ¶ÇÔºåÂáèÂ∞ë‰∏çÂøÖË¶ÅÁöÑÁº©ÊîæÊàñÊ£ÄÁ¥¢Êìç‰Ωú„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÊûÑÂª∫‰∫ÜÁªìÊûÑÂåñÁöÑÊÑüÁü•ÂíåÊØîËæÉËΩ®ËøπÔºåÁî®‰∫éÊåáÂØºÊô∫ËÉΩ‰ΩìÁöÑÂ≠¶‰π†ËøáÁ®ã„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåËøô‰∫õËΩ®ËøπÊ®°Êãü‰∫Ü‰∫∫Á±ª‰∏ìÂÆ∂Âú®Ê£ÄÊµãËøáÁ®ã‰∏≠ÁöÑÊÄùËÄÉË∑ØÂæÑÂíåÊìç‰ΩúÊ≠•È™§„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

AgentIADÂú®MMADÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Ü97.62%ÁöÑÂàÜÁ±ªÁ≤æÂ∫¶ÔºåÊòæËëóË∂ÖË∂ä‰∫ÜÂÖàÂâçÁöÑÂü∫‰∫éMLLMÁöÑÊñπÊ≥ïÔºåËææÂà∞‰∫ÜÊñ∞ÁöÑstate-of-the-artÊ∞¥Âπ≥„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÈÄöËøáÂ∑•ÂÖ∑Â¢ûÂº∫ÂíåÂ§öÈò∂ÊÆµÊ£ÄÊü•ÔºåAgentIADËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Ê£ÄÊµãÁªÜÂæÆ„ÄÅÂ±ÄÈÉ®ÁöÑÂ∑•‰∏öÂºÇÂ∏∏ÔºåÂπ∂Êèê‰æõÂèØËß£ÈáäÁöÑÊ£ÄÊü•ËΩ®Ëøπ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

AgentIADÂèØÂ∫îÁî®‰∫éÂêÑÁßçÂ∑•‰∏öÁîü‰∫ßÁ∫øÁöÑË¥®ÈáèÊ£ÄÊµãÁéØËäÇÔºå‰æãÂ¶ÇÁîµÂ≠êÂÖÉ‰ª∂„ÄÅÊ±ΩËΩ¶Èõ∂ÈÉ®‰ª∂„ÄÅÁ∫∫ÁªáÂìÅÁ≠â‰∫ßÂìÅÁöÑÁº∫Èô∑Ê£ÄÊµã„ÄÇËØ•ÊñπÊ≥ïËÉΩÂ§üÊèêÈ´òÊ£ÄÊµãÁ≤æÂ∫¶ÔºåÈôç‰ΩéÊºèÊ£ÄÁéáÔºå‰ªéËÄåÊèêÂçá‰∫ßÂìÅË¥®ÈáèÂíåÁîü‰∫ßÊïàÁéá„ÄÇÊ≠§Â§ñÔºåAgentIADÁöÑÈÄèÊòéÊ£ÄÊü•ËøáÁ®ãÊúâÂä©‰∫éÂàÜÊûêÁº∫Èô∑ÂéüÂõ†Ôºå‰∏∫ÊîπËøõÁîü‰∫ßÂ∑•Ëâ∫Êèê‰æõÂèÇËÄÉ„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÊâ©Â±ïÂà∞ÂÖ∂‰ªñÈúÄË¶ÅÁ≤æÁªÜËßÜËßâÊ£ÄÊü•ÁöÑÈ¢ÜÂüüÔºåÂ¶ÇÂåªÁñóÂΩ±ÂÉèÂàÜÊûê„ÄÅÈÅ•ÊÑüÂõæÂÉèËß£ËØëÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Industrial anomaly detection (IAD) is difficult due to the scarcity of normal reference samples and the subtle, localized nature of many defects. Single-pass vision-language models (VLMs) often overlook small abnormalities and lack explicit mechanisms to compare against canonical normal patterns. We propose AgentIAD, a tool-driven agentic framework that enables multi-stage visual inspection. The agent is equipped with a Perceptive Zoomer (PZ) for localized fine-grained analysis and a Comparative Retriever (CR) for querying normal exemplars when evidence is ambiguous. To teach these inspection behaviors, we construct structured perceptive and comparative trajectories from the MMAD dataset and train the model in two stages: supervised fine-tuning followed by reinforcement learning. A two-part reward design drives this process: a perception reward that supervises classification accuracy, spatial alignment, and type correctness, and a behavior reward that encourages efficient tool use. Together, these components enable the model to refine its judgment through step-wise observation, zooming, and verification. AgentIAD achieves a new state-of-the-art 97.62% classification accuracy on MMAD, surpassing prior MLLM-based approaches while producing transparent and interpretable inspection traces.

