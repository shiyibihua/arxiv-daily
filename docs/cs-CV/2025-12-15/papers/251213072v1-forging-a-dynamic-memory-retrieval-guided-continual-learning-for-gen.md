---
layout: default
title: Forging a Dynamic Memory: Retrieval-Guided Continual Learning for Generalist Medical Foundation Models
---

# Forging a Dynamic Memory: Retrieval-Guided Continual Learning for Generalist Medical Foundation Models

**arXiv**: [2512.13072v1](https://arxiv.org/abs/2512.13072) | [PDF](https://arxiv.org/pdf/2512.13072.pdf)

**ä½œè€…**: Zizhi Chen, Yizhen Gao, Minghao Han, Yizhou Liu, Zhaoyu Chen, Dingkang Yang, Lihua Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ£€ç´¢å¢žå¼ºç”Ÿæˆä¸ŽåŠ¨æ€çŸ¥è¯†è’¸é¦æ¡†æž¶ï¼Œä»¥è§£å†³åŒ»å­¦å¤šæ¨¡æ€åŸºç¡€æ¨¡åž‹åœ¨æŒç»­å­¦ä¹ ä¸­ä¿ç•™ç»†ç²’åº¦ç‰¹å¾ä¸Žè·¨æ¨¡æ€åŸŸå·®è·çš„éš¾é¢˜ã€‚**

**å…³é”®è¯**: `åŒ»å­¦å¤šæ¨¡æ€åŸºç¡€æ¨¡åž‹` `æŒç»­å­¦ä¹ ` `æ£€ç´¢å¢žå¼ºç”Ÿæˆ` `åŠ¨æ€çŸ¥è¯†è’¸é¦` `åŒ»å­¦ä»»åŠ¡å¢žé‡å­¦ä¹ ` `è·¨æ¨¡æ€åŸŸå·®è·`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŒ»å­¦å¤šæ¨¡æ€è§†è§‰è¯­è¨€æ¨¡åž‹åœ¨æŒç»­å­¦ä¹ ä¸­é¢ä¸´ä¿ç•™ç»†ç²’åº¦æ¨¡æ€å†…ç‰¹å¾ä¸Žè·¨è¶Šæ¨¡æ€åŸŸå·®è·çš„å›°å¢ƒã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽ1800ä¸‡åŒ»å­¦æ£€ç´¢æ•°æ®åº“ï¼Œé›†æˆå¤šæ¨¡æ€å¤šå±‚æ£€ç´¢å¢žå¼ºç”Ÿæˆï¼Œå¹¶å¼•å…¥åŠ¨æ€çŸ¥è¯†è’¸é¦æ¡†æž¶ï¼ŒåŠ¨æ€è°ƒèŠ‚å‚æ•°ç©ºé—´ã€çŸ¥è¯†ç²’åº¦ä¸Žæ•°æ®åˆ†å¸ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè®¾è®¡åŒ»å­¦é€šç”¨ä»»åŠ¡å¢žé‡å­¦ä¹ åŸºå‡†ï¼Œå®žéªŒæ˜¾ç¤ºæ–¹æ³•åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šè¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œä»£ç å·²æä¾›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal biomedical Vision-Language Models (VLMs) exhibit immense potential in the field of Continual Learning (CL). However, they confront a core dilemma: how to preserve fine-grained intra-modality features while bridging the significant domain gap across different modalities. To address this challenge, we propose a comprehensive framework. Leveraging our 18-million multimodal and comprehensive medical retrieval database derived from PubMed scientific papers, we pioneer the integration of Retrieval-Augmented Generation (RAG) into CL. Specifically, we employ a multi-modal, multi-layer RAG system that provides real-time guidance for model fine-tuning through dynamic, on-demand knowledge retrieval. Building upon this, we introduce a dynamic knowledge distillation framework. This framework precisely resolves the aforementioned core dilemma by dynamically modulating the importance of the parameter space, the granularity of the distilled knowledge, and the data distribution of the reference dataset in accordance with the required level of detail. To thoroughly validate the clinical value of our strategy, we have designed a more rigorous \textbf{M}edical Generalist Task Incremental Learning (MGTIL) benchmark. This benchmark is engineered to simultaneously evaluate the model's capacity for adaptation to significant domain shifts, retention of subtle intra-domain features, and real-time learning of novel and complex medical tasks. Extensive experimental results demonstrate that our proposed method achieves state-of-the-art (SOTA) performance across all metrics. The code is provided in the supplementary materials.

