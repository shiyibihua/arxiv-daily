---
layout: default
title: StarryGazer: Leveraging Monocular Depth Estimation Models for Domain-Agnostic Single Depth Image Completion
---

# StarryGazer: Leveraging Monocular Depth Estimation Models for Domain-Agnostic Single Depth Image Completion

**arXiv**: [2512.13147v1](https://arxiv.org/abs/2512.13147) | [PDF](https://arxiv.org/pdf/2512.13147.pdf)

**ä½œè€…**: Sangmin Hong, Suyoung Lee, Kyoung Mu Lee

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºStarryGazeræ¡†æž¶ï¼Œåˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹å®žçŽ°é¢†åŸŸæ— å…³çš„å•æ·±åº¦å›¾åƒè¡¥å…¨**

**å…³é”®è¯**: `æ·±åº¦è¡¥å…¨` `å•ç›®æ·±åº¦ä¼°è®¡` `æ— ç›‘ç£å­¦ä¹ ` `é¢†åŸŸæ— å…³` `ç¨€ç–æ·±åº¦å›¾` `å›¾åƒåˆæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ— ç›‘ç£æ·±åº¦è¡¥å…¨æ–¹æ³•ä¾èµ–è¾…åŠ©æ•°æ®ï¼Œå•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹æ— æ³•ç›´æŽ¥ç»“åˆç¨€ç–æ·±åº¦å›¾
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨é¢„è®­ç»ƒå•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹ç”Ÿæˆç›¸å¯¹æ·±åº¦å›¾ï¼Œé€šè¿‡åˆ†å‰²å’Œéšæœºç¼©æ”¾åˆæˆä¼ªçœŸå€¼å¯¹è®­ç»ƒç»†åŒ–ç½‘ç»œ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šä¼˜äºŽçŽ°æœ‰æ— ç›‘ç£æ–¹æ³•ï¼Œæœ‰æ•ˆåˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡æ¨¡åž‹å¹¶ä¿®æ­£è¯¯å·®

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The problem of depth completion involves predicting a dense depth image from a single sparse depth map and an RGB image. Unsupervised depth completion methods have been proposed for various datasets where ground truth depth data is unavailable and supervised methods cannot be applied. However, these models require auxiliary data to estimate depth values, which is far from real scenarios. Monocular depth estimation (MDE) models can produce a plausible relative depth map from a single image, but there is no work to properly combine the sparse depth map with MDE for depth completion; a simple affine transformation to the depth map will yield a high error since MDE are inaccurate at estimating depth difference between objects. We introduce StarryGazer, a domain-agnostic framework that predicts dense depth images from a single sparse depth image and an RGB image without relying on ground-truth depth by leveraging the power of large MDE models. First, we employ a pre-trained MDE model to produce relative depth images. These images are segmented and randomly rescaled to form synthetic pairs for dense pseudo-ground truth and corresponding sparse depths. A refinement network is trained with the synthetic pairs, incorporating the relative depth maps and RGB images to improve the model's accuracy and robustness. StarryGazer shows superior results over existing unsupervised methods and transformed MDE results on various datasets, demonstrating that our framework exploits the power of MDE models while appropriately fixing errors using sparse depth information.

