---
layout: default
title: On-Device Continual Learning for Unsupervised Visual Anomaly Detection in Dynamic Manufacturing
---

# On-Device Continual Learning for Unsupervised Visual Anomaly Detection in Dynamic Manufacturing

**arXiv**: [2512.13497v1](https://arxiv.org/abs/2512.13497) | [PDF](https://arxiv.org/pdf/2512.13497.pdf)

**ä½œè€…**: Haoyu Ren, Kay Koehle, Kirill Dorofeev, Darko Anicic

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè®¾å¤‡ç«¯æŒç»­å­¦ä¹ çš„æ— ç›‘ç£è§†è§‰å¼‚å¸¸æ£€æµ‹æ–¹æ³•ï¼Œä»¥åº”å¯¹åŠ¨æ€åˆ¶é€ ä¸­çš„å¿«é€Ÿäº§å“å˜åŒ–å’Œèµ„æºé™åˆ¶ã€‚**

**å…³é”®è¯**: `è®¾å¤‡ç«¯æŒç»­å­¦ä¹ ` `æ— ç›‘ç£è§†è§‰å¼‚å¸¸æ£€æµ‹` `åŠ¨æ€åˆ¶é€ ` `è¾¹ç¼˜è®¡ç®—` `æ ¸å¿ƒé›†æ›´æ–°` `å·¥ä¸šåº”ç”¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŠ¨æ€åˆ¶é€ ä¸­äº§å“é¢‘ç¹å˜åŒ–ã€è¾¹ç¼˜è®¾å¤‡èµ„æºæœ‰é™åŠå¼‚å¸¸æ•°æ®ç¨€ç¼ºï¼Œå¯¼è‡´ä¼ ç»Ÿè§†è§‰å¼‚å¸¸æ£€æµ‹éš¾ä»¥é€‚åº”ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ‰©å±•PatchCoreï¼Œé‡‡ç”¨è½»é‡ç‰¹å¾æå–å™¨å’ŒåŸºäºŽkä¸­å¿ƒé€‰æ‹©çš„å¢žé‡æ ¸å¿ƒé›†æ›´æ–°æœºåˆ¶ï¼Œå®žçŽ°è®¾å¤‡ç«¯åœ¨çº¿å­¦ä¹ ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å·¥ä¸šç”¨ä¾‹ä¸­ï¼ŒAUROCæå‡12%ï¼Œå†…å­˜ä½¿ç”¨å‡å°‘80%ï¼Œè®­ç»ƒé€Ÿåº¦ä¼˜äºŽæ‰¹é‡é‡è®­ç»ƒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In modern manufacturing, Visual Anomaly Detection (VAD) is essential for automated inspection and consistent product quality. Yet, increasingly dynamic and flexible production environments introduce key challenges: First, frequent product changes in small-batch and on-demand manufacturing require rapid model updates. Second, legacy edge hardware lacks the resources to train and run large AI models. Finally, both anomalous and normal training data are often scarce, particularly for newly introduced product variations. We investigate on-device continual learning for unsupervised VAD with localization, extending the PatchCore to incorporate online learning for real-world industrial scenarios. The proposed method leverages a lightweight feature extractor and an incremental coreset update mechanism based on k-center selection, enabling rapid, memory-efficient adaptation from limited data while eliminating costly cloud retraining. Evaluations on an industrial use case are conducted using a testbed designed to emulate flexible production with frequent variant changes in a controlled environment. Our method achieves a 12% AUROC improvement over the baseline, an 80% reduction in memory usage, and faster training compared to batch retraining. These results confirm that our method delivers accurate, resource-efficient, and adaptive VAD suitable for dynamic and smart manufacturing.

