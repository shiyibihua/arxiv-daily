---
layout: default
title: SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning
---

# SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.13874" target="_blank" class="toolbar-btn">arXiv: 2512.13874v1</a>
    <a href="https://arxiv.org/pdf/2512.13874.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.13874v1" 
            onclick="toggleFavorite(this, '2512.13874v1', 'SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jitesh Jain, Jialuo Li, Zixian Ma, Jieyu Zhang, Chris Dongjoo Kim, Sangho Lee, Rohun Tripathi, Tanmay Gupta, Christopher Clark, Humphrey Shi

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-15

**Â§áÊ≥®**: Project Page: https://praeclarumjj3.github.io/sage/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SAGEÔºåÂà©Áî®Âº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÊô∫ËÉΩ‰ªªÊÑèÊó∂ÂüüAgentÔºåÁî®‰∫éÈïøËßÜÈ¢ëÊé®ÁêÜ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÈïøËßÜÈ¢ëÊé®ÁêÜ` `‰ªªÊÑèÊó∂ÂüüÊé®ÁêÜ` `Âº∫ÂåñÂ≠¶‰π†` `Êô∫ËÉΩAgent` `ËßÜÈ¢ëÁêÜËß£`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜÈ¢ëÊé®ÁêÜÊ®°ÂûãÈÄöÂ∏∏‰ª•ÂçïËΩÆÊñπÂºèÂ§ÑÁêÜÂ§ßÈáèÂ∏ßÔºåÁ±ª‰ºº‰∫éËßÇÁúãÂÆåÊï¥ÈïøËßÜÈ¢ëÔºåÊ∂àËÄóÂ§ßÈáèËµÑÊ∫êÔºåÁº∫‰πèÁÅµÊ¥ªÊÄß„ÄÇ
2. SAGEÁ≥ªÁªüÈÄöËøáÂ§öËΩÆÊé®ÁêÜÂ§ÑÁêÜÈïøËßÜÈ¢ëÔºåÂπ∂ËÉΩ‰ª•ÂçïËΩÆÊñπÂºèÂ§ÑÁêÜÁÆÄÂçïÈóÆÈ¢òÔºåÊ®°‰ªø‰∫∫Á±ªÁöÑËßÇÁúã‰π†ÊÉØÔºåÊèêÂçáÊïàÁéá„ÄÇ
3. ÈÄöËøáÂêàÊàêÊï∞ÊçÆÁîüÊàêÂíåÂº∫ÂåñÂ≠¶‰π†ÂêéËÆ≠ÁªÉÔºåSAGEÂú®ÈïøËßÜÈ¢ëÊé®ÁêÜ‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÊèêÂçáÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈïøËßÜÈ¢ë‰∏ä„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫SAGEÔºå‰∏Ä‰∏™Êô∫ËÉΩAgentÁ≥ªÁªüÔºåÂÆÉËÉΩÂ§üÂÉè‰∫∫Á±ª‰∏ÄÊ†∑ËøõË°å‰ªªÊÑèÊó∂ÂüüÁöÑÊé®ÁêÜÔºåÂç≥Ê†πÊçÆ‰ªªÂä°ÈúÄË¶ÅÔºåÂÜ≥ÂÆöÊòØÂø´ÈÄüÊµèËßàÈïøËßÜÈ¢ëËøòÊòØÂÆåÊï¥ËßÇÁúãÁü≠ËßÜÈ¢ë„ÄÇ‰∏∫‰∫ÜËÆ≠ÁªÉSAGEÁöÑÊ†∏ÂøÉÊ®°ÂùóSAGE-MMÔºåÊàë‰ª¨Âà©Áî®Gemini-2.5-FlashÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÁÆÄÊòìÁöÑÂêàÊàêÊï∞ÊçÆÁîüÊàêÊµÅÁ®ã„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËøòÊèêÂá∫‰∫Ü‰∏ÄÁßçÊúâÊïàÁöÑÂº∫ÂåñÂ≠¶‰π†ÂêéËÆ≠ÁªÉÊñπÊ≥ïÔºåËøôÂØπ‰∫éÂú®SAGE-MM‰∏≠ÂüπÂÖª‰ªªÊÑèÊó∂ÂüüÊé®ÁêÜËÉΩÂäõËá≥ÂÖ≥ÈáçË¶Å„ÄÇ‰∏∫‰∫ÜËØÑ‰º∞ÁúüÂÆûÂ®±‰πêÂú∫ÊôØ‰∏ãËßÜÈ¢ëÊé®ÁêÜËÉΩÂäõÔºåÊàë‰ª¨ÊûÑÂª∫‰∫ÜSAGE-BenchÔºåÂÖ∂Âπ≥ÂùáËßÜÈ¢ëÊó∂ÈïøË∂ÖËøá700Áßí„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑÁ≥ªÁªü„ÄÅÊï∞ÊçÆÂíåÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÊòØÊúâÊïàÁöÑÔºåÂú®ÂºÄÊîæÂºèËßÜÈ¢ëÊé®ÁêÜ‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÈ´òËææ6.1%ÁöÑÊòæËëóÊèêÂçáÔºåÂú®Ë∂ÖËøá10ÂàÜÈíüÁöÑËßÜÈ¢ë‰∏äÂèñÂæó‰∫Ü8.2%ÁöÑÊèêÂçá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜÈ¢ëÊé®ÁêÜÊ®°ÂûãÈÄöÂ∏∏ÈúÄË¶Å‰∏ÄÊ¨°ÊÄßÂ§ÑÁêÜÂ§ßÈáèËßÜÈ¢ëÂ∏ßÔºåËÆ°ÁÆóÊàêÊú¨È´òÊòÇÔºåÂπ∂‰∏îÁº∫‰πèÂÉè‰∫∫Á±ª‰∏ÄÊ†∑ÁöÑÁÅµÊ¥ªÊé®ÁêÜËÉΩÂäõÔºåÊó†Ê≥ïÊ†πÊçÆËßÜÈ¢ëÂÜÖÂÆπÂíå‰ªªÂä°ÈúÄÊ±ÇË∞ÉÊï¥ËßÇÁúãÁ≠ñÁï•„ÄÇÂÆÉ‰ª¨Êó†Ê≥ïÂú®ÈúÄË¶ÅÊó∂Âø´ÈÄüÊµèËßàÈïøËßÜÈ¢ëÔºåÊàñËÄÖÂú®ÂøÖË¶ÅÊó∂ÂÆåÊï¥ËßÇÁúãÁü≠ËßÜÈ¢ë„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSAGEÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØËÆ≠ÁªÉ‰∏Ä‰∏™Êô∫ËÉΩAgentÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂÉè‰∫∫Á±ª‰∏ÄÊ†∑ËøõË°å‰ªªÊÑèÊó∂ÂüüÁöÑÊé®ÁêÜ„ÄÇËØ•AgentÂèØ‰ª•ÂÜ≥ÂÆöÊòØËø≠‰ª£Âú∞ÊµèËßàÈïøËßÜÈ¢ëÔºåËøòÊòØÂÆåÊï¥Âú∞ËßÇÁúãÁü≠ËßÜÈ¢ëÔºå‰ªéËÄåÂú®ÊïàÁéáÂíåÂáÜÁ°ÆÊÄß‰πãÈó¥ÂèñÂæóÂπ≥Ë°°„ÄÇËøôÁßçËÆæËÆ°Ê®°‰ªø‰∫Ü‰∫∫Á±ªÂú®Â§ÑÁêÜËßÜÈ¢ëÊó∂ÁöÑËá™ÁÑ∂Ë°å‰∏∫„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSAGEÁ≥ªÁªüÂåÖÂê´‰∏Ä‰∏™Ê†∏ÂøÉÊ®°ÂùóSAGE-MMÔºåÂÆÉË¥üË¥£Ê†πÊçÆÂΩìÂâçÁä∂ÊÄÅÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•ÁöÑÂä®‰ΩúÔºå‰æãÂ¶ÇËßÇÁúã‰∏ÄÈÉ®ÂàÜËßÜÈ¢ë„ÄÅÂõûÁ≠îÈóÆÈ¢òÁ≠â„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØÂ§öËΩÆ‰∫§‰∫íÂºèÁöÑÔºåAgentÊ†πÊçÆÊØè‰∏ÄËΩÆÁöÑËßÇÂØüÂíåÂ•ñÂä±Ôºå‰∏çÊñ≠‰ºòÂåñÂÖ∂Êé®ÁêÜÁ≠ñÁï•„ÄÇÁ≥ªÁªü‰ΩøÁî®Gemini-2.5-FlashÁîüÊàêÂêàÊàêÊï∞ÊçÆÔºåÁî®‰∫éÈ¢ÑËÆ≠ÁªÉSAGE-MM„ÄÇ‰πãÂêéÔºåÈááÁî®Âº∫ÂåñÂ≠¶‰π†ÂØπSAGE-MMËøõË°åÂêéËÆ≠ÁªÉÔºå‰ª•ÊèêÂçáÂÖ∂‰ªªÊÑèÊó∂ÂüüÊé®ÁêÜËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSAGEÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂‰ªªÊÑèÊó∂ÂüüÊé®ÁêÜËÉΩÂäõÂíåÂº∫ÂåñÂ≠¶‰π†ÂêéËÆ≠ÁªÉÊñπÊ≥ï„ÄÇ‰º†ÁªüÁöÑËßÜÈ¢ëÊé®ÁêÜÊ®°ÂûãÈÄöÂ∏∏ÊòØÂçïËΩÆÁöÑÔºåËÄåSAGEËÉΩÂ§üËøõË°åÂ§öËΩÆ‰∫§‰∫íÂºèÊé®ÁêÜÔºåÊõ¥Âä†ÁÅµÊ¥ªÈ´òÊïà„ÄÇÂº∫ÂåñÂ≠¶‰π†ÂêéËÆ≠ÁªÉÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞ÊèêÂçáAgentÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫î‰∏çÂêåÁöÑËßÜÈ¢ëÂíå‰ªªÂä°„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöSAGE-MMÁöÑËÆ≠ÁªÉÂåÖÊã¨È¢ÑËÆ≠ÁªÉÂíåÂº∫ÂåñÂ≠¶‰π†‰∏§‰∏™Èò∂ÊÆµ„ÄÇÈ¢ÑËÆ≠ÁªÉ‰ΩøÁî®ÂêàÊàêÊï∞ÊçÆÔºåÁõÆÊ†áÊòØËÆ©AgentÂàùÊ≠•ÂÖ∑Â§áËßÜÈ¢ëÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇÂº∫ÂåñÂ≠¶‰π†Èò∂ÊÆµÂàô‰ΩøÁî®Â•ñÂä±ÂáΩÊï∞Êù•ÂºïÂØºAgentÂ≠¶‰π†ÊúÄ‰Ω≥ÁöÑËßÇÁúãÁ≠ñÁï•„ÄÇÂ•ñÂä±ÂáΩÊï∞ÁöÑËÆæËÆ°Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÈúÄË¶ÅÂπ≥Ë°°ÂáÜÁ°ÆÊÄßÂíåÊïàÁéá„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞Ôºå‰ΩÜÊ≠§Â§ÑÊú™Êèê‰æõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SAGEÂú®ÂºÄÊîæÂºèËßÜÈ¢ëÊé®ÁêÜ‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÊèêÂçáÔºåÈ´òËææ6.1%„ÄÇÂ∞§ÂÖ∂ÊòØÂú®Ë∂ÖËøá10ÂàÜÈíüÁöÑÈïøËßÜÈ¢ë‰∏äÔºåSAGEÁöÑÊÄßËÉΩÊèêÂçáËææÂà∞‰∫Ü8.2%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåSAGEÁöÑ‰ªªÊÑèÊó∂ÂüüÊé®ÁêÜËÉΩÂäõÂíåÂº∫ÂåñÂ≠¶‰π†ÂêéËÆ≠ÁªÉÊñπÊ≥ïÊòØÊúâÊïàÁöÑÔºåËÉΩÂ§üÊòæËëóÊèêÂçáÈïøËßÜÈ¢ëÊé®ÁêÜÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SAGEÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩËßÜÈ¢ëÁõëÊéß„ÄÅÊô∫ËÉΩÊïôËÇ≤„ÄÅÂ®±‰πêËßÜÈ¢ëÂàÜÊûêÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®ËßÜÈ¢ëÁõëÊéß‰∏≠ÔºåSAGEÂèØ‰ª•Âø´ÈÄüÂÆö‰ΩçÂºÇÂ∏∏‰∫ã‰ª∂ÔºõÂú®Êô∫ËÉΩÊïôËÇ≤‰∏≠ÔºåSAGEÂèØ‰ª•Ê†πÊçÆÂ≠¶ÁîüÁöÑÂ≠¶‰π†ËøõÂ∫¶ÂíåÁêÜËß£Á®ãÂ∫¶ÔºåÊô∫ËÉΩÊé®ËçêÂ≠¶‰π†ÂÜÖÂÆπÔºõÂú®Â®±‰πêËßÜÈ¢ëÂàÜÊûê‰∏≠ÔºåSAGEÂèØ‰ª•Â∏ÆÂä©Áî®Êà∑Âø´ÈÄüÊâæÂà∞ÊÑüÂÖ¥Ë∂£ÁöÑÁâáÊÆµ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> As humans, we are natural any-horizon reasoners, i.e., we can decide whether to iteratively skim long videos or watch short ones in full when necessary for a given task. With this in mind, one would expect video reasoning models to reason flexibly across different durations. However, SOTA models are still trained to predict answers in a single turn while processing a large number of frames, akin to watching an entire long video, requiring significant resources. This raises the question: Is it possible to develop performant any-horizon video reasoning systems? Inspired by human behavior, we first propose SAGE, an agent system that performs multi-turn reasoning on long videos while handling simpler problems in a single turn. Secondly, we introduce an easy synthetic data generation pipeline using Gemini-2.5-Flash to train the orchestrator, SAGE-MM, which lies at the core of SAGE. We further propose an effective RL post-training recipe essential for instilling any-horizon reasoning ability in SAGE-MM. Thirdly, we curate SAGE-Bench with an average duration of greater than 700 seconds for evaluating video reasoning ability in real-world entertainment use cases. Lastly, we empirically validate the effectiveness of our system, data, and RL recipe, observing notable improvements of up to 6.1% on open-ended video reasoning tasks, as well as an impressive 8.2% improvement on videos longer than 10 minutes.

