---
layout: default
title: RecTok: Reconstruction Distillation along Rectified Flow
---

# RecTok: Reconstruction Distillation along Rectified Flow

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.13421" target="_blank" class="toolbar-btn">arXiv: 2512.13421v1</a>
    <a href="https://arxiv.org/pdf/2512.13421.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.13421v1" 
            onclick="toggleFavorite(this, '2512.13421v1', 'RecTok: Reconstruction Distillation along Rectified Flow')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Qingyu Shi, Size Wu, Jinbin Bai, Kaidong Yu, Yujing Wang, Yunhai Tong, Xiangtai Li, Xuelong Li

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-15

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://shi-qingyu.github.io/rectok.github.io)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**RecTokÔºöÈÄöËøáÊ†°Ê≠£ÊµÅ‰∏äÁöÑÈáçÊûÑËí∏È¶èÔºåÁ™ÅÁ†¥È´òÁª¥ËßÜËßâTokenizersÁöÑÊÄßËÉΩÁì∂È¢à**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâTokenizers` `Êâ©Êï£Ê®°Âûã` `ÊµÅÂåπÈÖç` `ËØ≠‰πâËí∏È¶è` `ÈáçÊûÑËí∏È¶è` `ÂõæÂÉèÁîüÊàê` `È´òÁª¥ÊΩúÂú®Á©∫Èó¥`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜËßâTokenizersÂèóÈôê‰∫éÁª¥Â∫¶‰∏éÁîüÊàêË¥®ÈáèÁöÑÊùÉË°°ÔºåÈ´òÁª¥TokenizersÊÄßËÉΩ‰∏ç‰Ω≥„ÄÇ
2. RecTokÈÄöËøáÊµÅËØ≠‰πâËí∏È¶èÂíåÈáçÊûÑ-ÂØπÈΩêËí∏È¶èÔºå‰∏∞ÂØåÂâçÂêëÊµÅÁöÑËØ≠‰πâ‰ø°ÊÅØÔºåÊèêÂçáÈ´òÁª¥TokenizersÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåRecTokÂú®ÂõæÂÉèÈáçÂª∫„ÄÅÁîüÊàêË¥®ÈáèÂíåÂà§Âà´ÊÄßËÉΩ‰∏äÂùáËææÂà∞SOTAÔºå‰∏îÊÄßËÉΩÈöèÁª¥Â∫¶Â¢ûÂä†ËÄåÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâTokenizersÂú®Êâ©Êï£Ê®°Âûã‰∏≠Ëµ∑ÁùÄÂÖ≥ÈîÆ‰ΩúÁî®„ÄÇÊΩúÂú®Á©∫Èó¥ÁöÑÁª¥Â∫¶ÂÜ≥ÂÆö‰∫ÜÈáçÂª∫‰øùÁúüÂ∫¶ÂíåÊΩúÂú®ÁâπÂæÅÁöÑËØ≠‰πâË°®ËææËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁª¥Â∫¶ÂíåÁîüÊàêË¥®Èáè‰πãÈó¥Â≠òÂú®ÁùÄÊ†πÊú¨ÁöÑÊùÉË°°ÔºåËøôÈôêÂà∂‰∫ÜÁé∞ÊúâÊñπÊ≥ïÂè™ËÉΩ‰ΩøÁî®‰ΩéÁª¥ÊΩúÂú®Á©∫Èó¥„ÄÇÂ∞ΩÁÆ°ÊúÄËøëÁöÑÁ†îÁ©∂Âà©Áî®ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÊù•‰∏∞ÂØåËßÜËßâTokenizersÁöÑËØ≠‰πâÂπ∂Âä†ÈÄüÊî∂ÊïõÔºå‰ΩÜÈ´òÁª¥TokenizersÁöÑÊÄßËÉΩ‰ªçÁÑ∂‰∏çÂ¶Ç‰ΩéÁª¥Tokenizers„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜRecTokÔºåÈÄöËøáÊµÅËØ≠‰πâËí∏È¶èÂíåÈáçÊûÑ-ÂØπÈΩêËí∏È¶èËøô‰∏§‰∏™ÂÖ≥ÈîÆÂàõÊñ∞ÔºåÂÖãÊúç‰∫ÜÈ´òÁª¥ËßÜËßâTokenizersÁöÑÂ±ÄÈôêÊÄß„ÄÇÊàë‰ª¨ÁöÑÂÖ≥ÈîÆËßÅËß£ÊòØ‰ΩøÊµÅÂåπÈÖç‰∏≠ÁöÑÂâçÂêëÊµÅÂú®ËØ≠‰πâ‰∏ä‰∏∞ÂØåÔºåÂ∞ÜÂÖ∂‰Ωú‰∏∫Êâ©Êï£TransformerÁöÑËÆ≠ÁªÉÁ©∫Èó¥ÔºåËÄå‰∏çÊòØÂÉè‰ª•ÂâçÁöÑÂ∑•‰ΩúÈÇ£Ê†∑‰∏ìÊ≥®‰∫éÊΩúÂú®Á©∫Èó¥„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂ∞ÜËßÜËßâÂü∫Á°ÄÊ®°Âûã‰∏≠ÁöÑËØ≠‰πâ‰ø°ÊÅØÊèêÁÇºÂà∞ÊµÅÂåπÈÖç‰∏≠ÁöÑÂâçÂêëÊµÅËΩ®Ëøπ‰∏≠„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•ÈÄöËøáÂºïÂÖ•Êé©Á†ÅÁâπÂæÅÈáçÊûÑÊçüÂ§±Êù•Â¢ûÂº∫ËØ≠‰πâ„ÄÇÊàë‰ª¨ÁöÑRecTokÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÂõæÂÉèÈáçÂª∫„ÄÅÁîüÊàêË¥®ÈáèÂíåÂà§Âà´ÊÄßËÉΩ„ÄÇÂú®ÊúâÂíåÊ≤°ÊúâÊó†ÂàÜÁ±ªÂô®ÊåáÂØºËÆæÁΩÆ‰∏ãÔºåÂÆÉÂú®gFID-50K‰∏äÈÉΩÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÁªìÊûúÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜËØ≠‰πâ‰∏∞ÂØåÁöÑÊΩúÂú®Á©∫Èó¥ÁªìÊûÑ„ÄÇÊ≠§Â§ñÔºåÈöèÁùÄÊΩúÂú®Áª¥Â∫¶ÁöÑÂ¢ûÂä†ÔºåÊàë‰ª¨ËßÇÂØüÂà∞ÊåÅÁª≠ÁöÑÊîπËøõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥È´òÁª¥ËßÜËßâTokenizersÂú®Êâ©Êï£Ê®°Âûã‰∏≠ÊÄßËÉΩ‰∏ç‰Ω≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂèóÈôê‰∫éÊΩúÂú®Á©∫Èó¥Áª¥Â∫¶ÂíåÁîüÊàêË¥®ÈáèÁöÑÊùÉË°°ÔºåÂØºËá¥È´òÁª¥TokenizersÊó†Ê≥ïÂÖÖÂàÜÂèëÊå•ÂÖ∂ËØ≠‰πâË°®ËææËÉΩÂäõ„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠Âú®‰ºòÂåñÊΩúÂú®Á©∫Èó¥ÔºåÂøΩÁï•‰∫ÜÂâçÂêëÊµÅÁöÑËØ≠‰πâ‰ø°ÊÅØ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜËßÜËßâÂü∫Á°ÄÊ®°Âûã‰∏≠ÁöÑËØ≠‰πâ‰ø°ÊÅØÊèêÁÇºÂà∞ÊµÅÂåπÈÖçÁöÑÂâçÂêëÊµÅËΩ®Ëøπ‰∏≠Ôºå‰ΩøÂâçÂêëÊµÅÂú®ËØ≠‰πâ‰∏äÊõ¥Âä†‰∏∞ÂØå„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÊâ©Êï£TransformerÁöÑËÆ≠ÁªÉÁ©∫Èó¥‰∏çÂÜçÂ±ÄÈôê‰∫éÊΩúÂú®Á©∫Èó¥ÔºåËÄåÊòØÊâ©Â±ïÂà∞Êï¥‰∏™ÂâçÂêëÊµÅÔºå‰ªéËÄåÊèêÂçáÈ´òÁª¥TokenizersÁöÑÊÄßËÉΩ„ÄÇÂêåÊó∂ÔºåÂºïÂÖ•ÈáçÊûÑ-ÂØπÈΩêËí∏È¶èÔºåËøõ‰∏ÄÊ≠•Â¢ûÂº∫ËØ≠‰πâ‰ø°ÊÅØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRecTokÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ‰ΩøÁî®ËßÜËßâÂü∫Á°ÄÊ®°ÂûãÊèêÂèñÂõæÂÉèÁâπÂæÅÔºõ2) ‰ΩøÁî®ÊµÅÂåπÈÖçÊñπÊ≥ïÊûÑÂª∫ÂâçÂêëÊµÅÔºõ3) Â∞ÜËßÜËßâÂü∫Á°ÄÊ®°ÂûãÁöÑËØ≠‰πâ‰ø°ÊÅØËí∏È¶èÂà∞ÂâçÂêëÊµÅËΩ®Ëøπ‰∏≠Ôºõ4) ÂºïÂÖ•Êé©Á†ÅÁâπÂæÅÈáçÊûÑÊçüÂ§±ÔºåÂ¢ûÂº∫ËØ≠‰πâ‰ø°ÊÅØÔºõ5) ‰ΩøÁî®Êâ©Êï£TransformerËøõË°åÂõæÂÉèÁîüÊàê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöRecTokÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜËßÜËßâÂü∫Á°ÄÊ®°ÂûãÁöÑËØ≠‰πâ‰ø°ÊÅØËí∏È¶èÂà∞ÊµÅÂåπÈÖçÁöÑÂâçÂêëÊµÅËΩ®Ëøπ‰∏≠„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ï‰∏çÂêåÔºåRecTok‰∏çÂÜç‰ªÖ‰ªÖÂÖ≥Ê≥®ÊΩúÂú®Á©∫Èó¥ÁöÑ‰ºòÂåñÔºåËÄåÊòØÂ∞ÜÂâçÂêëÊµÅ‰Ωú‰∏∫Êâ©Êï£TransformerÁöÑËÆ≠ÁªÉÁ©∫Èó¥Ôºå‰ªéËÄåÂÖÖÂàÜÂà©Áî®‰∫ÜËßÜËßâÂü∫Á°ÄÊ®°ÂûãÁöÑËØ≠‰πâ‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåÈáçÊûÑ-ÂØπÈΩêËí∏È¶è‰πüÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÂàõÊñ∞ÔºåÂÆÉÈÄöËøáÂºïÂÖ•Êé©Á†ÅÁâπÂæÅÈáçÊûÑÊçüÂ§±ÔºåËøõ‰∏ÄÊ≠•Â¢ûÂº∫‰∫ÜËØ≠‰πâ‰ø°ÊÅØ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÊµÅËØ≠‰πâËí∏È¶è‰∏≠Ôºå‰ΩøÁî®KLÊï£Â∫¶ÊçüÂ§±Êù•Ë°°ÈáèÂâçÂêëÊµÅËΩ®ËøπÂíåËßÜËßâÂü∫Á°ÄÊ®°ÂûãÁâπÂæÅ‰πãÈó¥ÁöÑÂ∑ÆÂºÇÔºå‰ªéËÄåÂ∞ÜËØ≠‰πâ‰ø°ÊÅØ‰ªéËßÜËßâÂü∫Á°ÄÊ®°Âûã‰º†ÈÄíÂà∞ÂâçÂêëÊµÅ„ÄÇÂú®ÈáçÊûÑ-ÂØπÈΩêËí∏È¶è‰∏≠Ôºå‰ΩøÁî®Êé©Á†ÅÁâπÂæÅÈáçÊûÑÊçüÂ§±Êù•‰øÉ‰ΩøÊ®°ÂûãÂ≠¶‰π†Âà∞Êõ¥‰∏∞ÂØåÁöÑËØ≠‰πâ‰ø°ÊÅØ„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÈúÄË¶ÅÂèÇËÄÉËÆ∫ÊñáÂéüÊñá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

RecTokÂú®gFID-50KÊåáÊ†á‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂú®ÊúâÂíåÊ≤°ÊúâÊó†ÂàÜÁ±ªÂô®ÊåáÂØºËÆæÁΩÆ‰∏ãÈÉΩËææÂà∞‰∫ÜSOTAÊ∞¥Âπ≥„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåRecTokËÉΩÂ§üÊúâÊïàÊèêÂçáÂõæÂÉèÈáçÂª∫„ÄÅÁîüÊàêË¥®ÈáèÂíåÂà§Âà´ÊÄßËÉΩ„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÈöèÁùÄÊΩúÂú®Áª¥Â∫¶ÁöÑÂ¢ûÂä†ÔºåRecTokÁöÑÊÄßËÉΩÊåÅÁª≠ÊèêÂçáÔºåËøôË°®ÊòéËØ•ÊñπÊ≥ïËÉΩÂ§üÂÖÖÂàÜÂà©Áî®È´òÁª¥ÊΩúÂú®Á©∫Èó¥ÁöÑ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

RecTokÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÁî®‰∫éÂõæÂÉèÁîüÊàê„ÄÅÂõæÂÉèÁºñËæë„ÄÅÂõæÂÉè‰øÆÂ§çÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÂçáÈ´òÁª¥ËßÜËßâTokenizersÁöÑÊÄßËÉΩÔºåRecTokÂèØ‰ª•ÁîüÊàêÊõ¥È´òË¥®Èáè„ÄÅÊõ¥ÈÄºÁúüÁöÑÂõæÂÉèÔºåÂπ∂‰∏∫ÂêÑÁßçËßÜËßâ‰ªªÂä°Êèê‰æõÊõ¥Âº∫Â§ßÁöÑËØ≠‰πâË°®ËææËÉΩÂäõ„ÄÇËØ•Á†îÁ©∂ÁöÑÊàêÊûúÊúâÊúõÊé®Âä®Êâ©Êï£Ê®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Visual tokenizers play a crucial role in diffusion models. The dimensionality of latent space governs both reconstruction fidelity and the semantic expressiveness of the latent feature. However, a fundamental trade-off is inherent between dimensionality and generation quality, constraining existing methods to low-dimensional latent spaces. Although recent works have leveraged vision foundation models to enrich the semantics of visual tokenizers and accelerate convergence, high-dimensional tokenizers still underperform their low-dimensional counterparts. In this work, we propose RecTok, which overcomes the limitations of high-dimensional visual tokenizers through two key innovations: flow semantic distillation and reconstruction--alignment distillation. Our key insight is to make the forward flow in flow matching semantically rich, which serves as the training space of diffusion transformers, rather than focusing on the latent space as in previous works. Specifically, our method distills the semantic information in VFMs into the forward flow trajectories in flow matching. And we further enhance the semantics by introducing a masked feature reconstruction loss. Our RecTok achieves superior image reconstruction, generation quality, and discriminative performance. It achieves state-of-the-art results on the gFID-50K under both with and without classifier-free guidance settings, while maintaining a semantically rich latent space structure. Furthermore, as the latent dimensionality increases, we observe consistent improvements. Code and model are available at https://shi-qingyu.github.io/rectok.github.io.

