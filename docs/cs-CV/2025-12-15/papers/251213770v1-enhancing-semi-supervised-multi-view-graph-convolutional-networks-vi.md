---
layout: default
title: Enhancing Semi-Supervised Multi-View Graph Convolutional Networks via Supervised Contrastive Learning and Self-Training
---

# Enhancing Semi-Supervised Multi-View Graph Convolutional Networks via Supervised Contrastive Learning and Self-Training

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.13770" target="_blank" class="toolbar-btn">arXiv: 2512.13770v1</a>
    <a href="https://arxiv.org/pdf/2512.13770.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.13770v1" 
            onclick="toggleFavorite(this, '2512.13770v1', 'Enhancing Semi-Supervised Multi-View Graph Convolutional Networks via Supervised Contrastive Learning and Self-Training')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Huaiyuan Xiao, Fadi Dornaika, Jingjun Bi

**ÂàÜÁ±ª**: cs.LG, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-15

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/HuaiyuanXiao/MVSupGCN)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MV-SupGCNÔºåÈÄöËøáÁõëÁù£ÂØπÊØîÂ≠¶‰π†ÂíåËá™ËÆ≠ÁªÉÂ¢ûÂº∫ÂçäÁõëÁù£Â§öËßÜÂõæÂõæÂç∑ÁßØÁΩëÁªú**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Â§öËßÜÂõæÂ≠¶‰π†` `ÂõæÂç∑ÁßØÁΩëÁªú` `ÂçäÁõëÁù£Â≠¶‰π†` `ÂØπÊØîÂ≠¶‰π†` `Ëá™ËÆ≠ÁªÉ` `ÁõëÁù£ÂØπÊØîÂ≠¶‰π†` `ÂõæÊûÑÂª∫`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éGCNÁöÑÂ§öËßÜÂõæÂ≠¶‰π†ÊñπÊ≥ïÈöæ‰ª•ÂÖÖÂàÜÂà©Áî®Ë∑®ËßÜÂõæ‰∫íË°•‰ø°ÊÅØÔºåÂØºËá¥ÁâπÂæÅË°®Á§∫Ê¨°‰ºòÂíåÊÄßËÉΩÂèóÈôê„ÄÇ
2. ÊèêÂá∫MV-SupGCNÔºåÁªìÂêàÁõëÁù£ÂØπÊØîÂ≠¶‰π†„ÄÅÂ§öÂõæÊûÑÂª∫ÂíåËá™ËÆ≠ÁªÉÔºå‰ª•ÊèêÂçáÂçäÁõëÁù£Â§öËßÜÂõæÂ≠¶‰π†ÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMV-SupGCNÂú®Â§ö‰∏™Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊúÄ‰ºòÊñπÊ≥ïÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âü∫‰∫éÂõæÂç∑ÁßØÁΩëÁªú(GCN)ÁöÑÂ§öËßÜÂõæÂ≠¶‰π†‰∏∫Êï¥ÂêàÂºÇÊûÑËßÜÂõæÁöÑÁªìÊûÑ‰ø°ÊÅØÊèê‰æõ‰∫Ü‰∏Ä‰∏™Âº∫Â§ßÁöÑÊ°ÜÊû∂Ôºå‰ªéËÄåËÉΩÂ§üÊúâÊïàÂú∞Âª∫Ê®°Â§çÊùÇÁöÑÂ§öËßÜÂõæÊï∞ÊçÆ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÊñπÊ≥ïÈÄöÂ∏∏‰∏çËÉΩÂÖÖÂàÜÂà©Áî®Ë∑®ËßÜÂõæÁöÑ‰∫íË°•‰ø°ÊÅØÔºåÂØºËá¥Ê¨°‰ºòÁöÑÁâπÂæÅË°®Á§∫ÂíåÊúâÈôêÁöÑÊÄßËÉΩ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜMV-SupGCNÔºå‰∏Ä‰∏™ÂçäÁõëÁù£GCNÊ®°ÂûãÔºåÂÆÉÈõÜÊàê‰∫ÜÂá†‰∏™‰∫íË°•ÁöÑÁªÑ‰ª∂ÔºåÂÖ∑ÊúâÊ∏ÖÊô∞ÁöÑÂä®Êú∫ÂíåÁõ∏‰∫íÂä†Âº∫ÁöÑ‰ΩúÁî®„ÄÇÈ¶ñÂÖàÔºå‰∏∫‰∫ÜÊõ¥Â•ΩÂú∞ÊçïËé∑Âà§Âà´ÊÄßÁâπÂæÅÂπ∂ÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™ËÅîÂêàÊçüÂ§±ÂáΩÊï∞ÔºåÂ∞Ü‰∫§ÂèâÁÜµÊçüÂ§±‰∏éÁõëÁù£ÂØπÊØîÊçüÂ§±Áõ∏ÁªìÂêàÔºåÈºìÂä±Ê®°ÂûãÂêåÊó∂ÊúÄÂ∞èÂåñÁ±ªÂÜÖÊñπÂ∑ÆÂíåÊúÄÂ§ßÂåñÊΩúÂú®Á©∫Èó¥‰∏≠ÁöÑÁ±ªÈó¥ÂèØÂàÜÊÄß„ÄÇÂÖ∂Ê¨°ÔºåËÆ§ËØÜÂà∞Âçï‰∏ÄÂõæÊûÑÂª∫ÊñπÊ≥ïÁöÑ‰∏çÁ®≥ÂÆöÊÄßÂíå‰∏çÂÆåÊï¥ÊÄßÔºåÊàë‰ª¨Â∞ÜÂü∫‰∫éKNNÂíåÂçäÁõëÁù£ÁöÑÂõæÊûÑÂª∫ÊñπÊ≥ïÁªìÂêàÂú®ÊØè‰∏™ËßÜÂõæ‰∏äÔºå‰ªéËÄåÂ¢ûÂº∫‰∫ÜÊï∞ÊçÆÁªìÊûÑË°®Á§∫ÁöÑÈ≤ÅÊ£íÊÄßÔºåÂπ∂Èôç‰Ωé‰∫ÜÊ≥õÂåñËØØÂ∑Æ„ÄÇÁ¨¨‰∏âÔºå‰∏∫‰∫ÜÊúâÊïàÂú∞Âà©Áî®Â§ßÈáèÁöÑÊú™Ê†áËÆ∞Êï∞ÊçÆÂπ∂Â¢ûÂº∫Â§ö‰∏™ËßÜÂõæ‰πãÈó¥ÁöÑËØ≠‰πâÂØπÈΩêÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂ÈõÜÊàê‰∫ÜÂØπÊØîÂ≠¶‰π†Ôºå‰ª•Â¢ûÂº∫Â§öËßÜÂõæÂµåÂÖ•‰πãÈó¥ÁöÑ‰∏ÄËá¥ÊÄßÂπ∂ÊçïËé∑ÊúâÊÑè‰πâÁöÑËßÜÂõæÈó¥ÂÖ≥Á≥ªÔºå‰ª•Âèä‰º™Ê†áÁ≠æÔºåÂÆÉÊèê‰æõ‰∫ÜÈ¢ùÂ§ñÁöÑÁõëÁù£ÔºåÂ∫îÁî®‰∫é‰∫§ÂèâÁÜµÂíåÂØπÊØîÊçüÂ§±ÂáΩÊï∞Ôºå‰ª•Â¢ûÂº∫Ê®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åË°®ÊòéÔºåMV-SupGCNÂßãÁªà‰ºò‰∫éÂ§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÁöÑÊúÄÂÖàËøõÊñπÊ≥ïÔºåÈ™åËØÅ‰∫ÜÊàë‰ª¨ÈõÜÊàêÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑÂ§öËßÜÂõæÂõæÂç∑ÁßØÁΩëÁªúÊñπÊ≥ïÂú®Âà©Áî®‰∏çÂêåËßÜÂõæ‰πãÈó¥ÁöÑ‰∫íË°•‰ø°ÊÅØÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÂØºËá¥Â≠¶‰π†Âà∞ÁöÑÁâπÂæÅË°®Á§∫‰∏çÂ§üÂÖ∑ÊúâÂå∫ÂàÜÊÄßÔºåÊ®°ÂûãÊ≥õÂåñËÉΩÂäõËæÉÂ∑Æ„ÄÇÊ≠§Â§ñÔºåÂçï‰∏ÄÁöÑÂõæÊûÑÂª∫ÊñπÊ≥ïÂÆπÊòìÂèóÂà∞Âô™Â£∞ÁöÑÂΩ±ÂìçÔºåÂØºËá¥Êï∞ÊçÆÁªìÊûÑË°®Á§∫‰∏çÁ®≥ÂÆö„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMV-SupGCNÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÁªìÂêàÁõëÁù£ÂØπÊØîÂ≠¶‰π†„ÄÅÂ§öÂõæÊûÑÂª∫ÂíåËá™ËÆ≠ÁªÉÔºåÊù•Â¢ûÂº∫Ê®°ÂûãÂØπÂ§öËßÜÂõæÊï∞ÊçÆÁöÑÁêÜËß£ÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÁõëÁù£ÂØπÊØîÂ≠¶‰π†Êó®Âú®Â≠¶‰π†Êõ¥ÂÖ∑Âå∫ÂàÜÊÄßÁöÑÁâπÂæÅË°®Á§∫ÔºåÂ§öÂõæÊûÑÂª∫Â¢ûÂº∫Êï∞ÊçÆÁªìÊûÑË°®Á§∫ÁöÑÈ≤ÅÊ£íÊÄßÔºåËá™ËÆ≠ÁªÉÂàôÂà©Áî®Êú™Ê†áËÆ∞Êï∞ÊçÆÊèêÂçáÊ®°ÂûãÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMV-SupGCNÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Â§öËßÜÂõæÂõæÊûÑÂª∫ÔºöÂØπÊØè‰∏™ËßÜÂõæÂàÜÂà´‰ΩøÁî®KNNÂíåÂçäÁõëÁù£ÊñπÊ≥ïÊûÑÂª∫ÂõæÔºõ2) ÁâπÂæÅÁºñÁ†ÅÔºö‰ΩøÁî®ÂõæÂç∑ÁßØÁΩëÁªúÂØπÊØè‰∏™ËßÜÂõæÁöÑÂõæÁªìÊûÑÊï∞ÊçÆËøõË°åÁâπÂæÅÁºñÁ†ÅÔºõ3) ÁõëÁù£ÂØπÊØîÂ≠¶‰π†ÔºöÁªìÂêà‰∫§ÂèâÁÜµÊçüÂ§±ÂíåÁõëÁù£ÂØπÊØîÊçüÂ§±Ôºå‰ºòÂåñÁâπÂæÅË°®Á§∫Ôºõ4) Ëá™ËÆ≠ÁªÉÔºö‰ΩøÁî®‰º™Ê†áÁ≠æÂØπÊú™Ê†áËÆ∞Êï∞ÊçÆËøõË°åËÆ≠ÁªÉÔºåÂπ∂Â∞ÜÂÖ∂Á∫≥ÂÖ•‰∫§ÂèâÁÜµÊçüÂ§±ÂíåÂØπÊØîÊçüÂ§±‰∏≠Ôºõ5) Â§öËßÜÂõæ‰∏ÄËá¥ÊÄßÔºöÈÄöËøáÂØπÊØîÂ≠¶‰π†ÔºåÂ¢ûÂº∫Â§öËßÜÂõæÂµåÂÖ•‰πãÈó¥ÁöÑ‰∏ÄËá¥ÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMV-SupGCNÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÁªìÂêàÁõëÁù£ÂØπÊØîÂ≠¶‰π†Âíå‰∫§ÂèâÁÜµÊçüÂ§±ÔºåÊèêÂçáÁâπÂæÅË°®Á§∫ÁöÑÂå∫ÂàÜÊÄßÔºõ2) ÈááÁî®Â§öÂõæÊûÑÂª∫ÊñπÊ≥ïÔºåÂ¢ûÂº∫Êï∞ÊçÆÁªìÊûÑË°®Á§∫ÁöÑÈ≤ÅÊ£íÊÄßÔºõ3) Â∞ÜÂØπÊØîÂ≠¶‰π†Âíå‰º™Ê†áÁ≠æËûçÂÖ•Ëá™ËÆ≠ÁªÉÊ°ÜÊû∂ÔºåÊúâÊïàÂà©Áî®Êú™Ê†áËÆ∞Êï∞ÊçÆÂπ∂Â¢ûÂº∫Â§öËßÜÂõæ‰∏ÄËá¥ÊÄß„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåMV-SupGCNÊõ¥ÂÖ®Èù¢Âú∞ËÄÉËôë‰∫ÜÂ§öËßÜÂõæÂ≠¶‰π†‰∏≠ÁöÑÂÖ≥ÈîÆÈóÆÈ¢òÔºåÂπ∂ÊèêÂá∫‰∫ÜÁõ∏Â∫îÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂõæÊûÑÂª∫ÊñπÈù¢ÔºåÁªìÂêà‰∫ÜKNNÂíåÂçäÁõëÁù£ÂõæÊûÑÂª∫ÊñπÊ≥ïÔºåÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÊú™Áü•„ÄÇÊçüÂ§±ÂáΩÊï∞ÊñπÈù¢Ôºå‰ΩøÁî®‰∫Ü‰∫§ÂèâÁÜµÊçüÂ§±ÂíåÁõëÁù£ÂØπÊØîÊçüÂ§±ÁöÑÂä†ÊùÉÂíåÔºåÊùÉÈáçÂèÇÊï∞Êú™Áü•„ÄÇÂú®Ëá™ËÆ≠ÁªÉËøáÁ®ã‰∏≠Ôºå‰º™Ê†áÁ≠æÁöÑÁîüÊàêÊñπÂºèÂíåÁΩÆ‰ø°Â∫¶ÈòàÂÄºÊú™Áü•„ÄÇÁΩëÁªúÁªìÊûÑÊñπÈù¢ÔºåGCNÁöÑÂÖ∑‰ΩìÂ±ÇÊï∞ÂíåÈöêËóèÂ±ÇÁª¥Â∫¶Êú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMV-SupGCNÂú®Â§ö‰∏™Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÊúÄ‰ºòÊñπÊ≥ï„ÄÇ‰æãÂ¶ÇÔºåÂú®Êï∞ÊçÆÈõÜDBLP‰∏äÔºåMV-SupGCNÁöÑÂáÜÁ°ÆÁéáÊØîÁé∞ÊúâÊúÄ‰ºòÊñπÊ≥ïÊèêÈ´ò‰∫ÜË∂ÖËøá2%„ÄÇËøô‰∫õÁªìÊûúÈ™åËØÅ‰∫ÜMV-SupGCNÂú®ÂçäÁõëÁù£Â§öËßÜÂõæÂ≠¶‰π†‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MV-SupGCNÂèØÂ∫îÁî®‰∫éÂêÑÁßçÂ§öËßÜÂõæÊï∞ÊçÆÂàÜÊûê‰ªªÂä°Ôºå‰æãÂ¶ÇÁ§æ‰∫§ÁΩëÁªúÂàÜÊûê„ÄÅÂõæÂÉèÂàÜÁ±ª„ÄÅÁîüÁâ©‰ø°ÊÅØÂ≠¶Á≠â„ÄÇÈÄöËøáÊï¥ÂêàÊù•Ëá™‰∏çÂêåÊù•Ê∫êÁöÑ‰ø°ÊÅØÔºåMV-SupGCNËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞ÁêÜËß£Â§çÊùÇÊï∞ÊçÆÔºå‰∏∫ÂÜ≥Á≠ñÊèê‰æõÊõ¥ÂèØÈù†ÁöÑ‰æùÊçÆ„ÄÇËØ•Á†îÁ©∂ÁöÑÊàêÊûúÊúâÂä©‰∫éÊé®Âä®Â§öËßÜÂõæÂ≠¶‰π†Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The advent of graph convolutional network (GCN)-based multi-view learning provides a powerful framework for integrating structural information from heterogeneous views, enabling effective modeling of complex multi-view data. However, existing methods often fail to fully exploit the complementary information across views, leading to suboptimal feature representations and limited performance. To address this, we propose MV-SupGCN, a semi-supervised GCN model that integrates several complementary components with clear motivations and mutual reinforcement. First, to better capture discriminative features and improve model generalization, we design a joint loss function that combines Cross-Entropy loss with Supervised Contrastive loss, encouraging the model to simultaneously minimize intra-class variance and maximize inter-class separability in the latent space. Second, recognizing the instability and incompleteness of single graph construction methods, we combine both KNN-based and semi-supervised graph construction approaches on each view, thereby enhancing the robustness of the data structure representation and reducing generalization error. Third, to effectively utilize abundant unlabeled data and enhance semantic alignment across multiple views, we propose a unified framework that integrates contrastive learning in order to enforce consistency among multi-view embeddings and capture meaningful inter-view relationships, together with pseudo-labeling, which provides additional supervision applied to both the cross-entropy and contrastive loss functions to enhance model generalization. Extensive experiments demonstrate that MV-SupGCN consistently surpasses state-of-the-art methods across multiple benchmarks, validating the effectiveness of our integrated approach. The source code is available at https://github.com/HuaiyuanXiao/MVSupGCN

