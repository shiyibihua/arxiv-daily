---
layout: default
title: CoDeQ: End-to-End Joint Model Compression with Dead-Zone Quantizer for High-Sparsity and Low-Precision Networks
---

# CoDeQ: End-to-End Joint Model Compression with Dead-Zone Quantizer for High-Sparsity and Low-Precision Networks

**arXiv**: [2512.12981v1](https://arxiv.org/abs/2512.12981) | [PDF](https://arxiv.org/pdf/2512.12981.pdf)

**ä½œè€…**: Jonathan WenshÃ¸j, Tong Chen, Bob Pepin, Raghavendra Selvan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoDeQæ–¹æ³•ï¼Œé€šè¿‡å¯å­¦ä¹ æ­»åŒºé‡åŒ–å™¨å®žçŽ°ç«¯åˆ°ç«¯è”åˆå‰ªæžä¸Žé‡åŒ–ï¼Œç”¨äºŽé«˜ç¨€ç–ä½Žç²¾åº¦ç½‘ç»œã€‚**

**å…³é”®è¯**: `æ¨¡åž‹åŽ‹ç¼©` `è”åˆå‰ªæžé‡åŒ–` `æ­»åŒºé‡åŒ–å™¨` `ç«¯åˆ°ç«¯ä¼˜åŒ–` `é«˜ç¨€ç–ç½‘ç»œ` `ä½Žç²¾åº¦ç½‘ç»œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è”åˆå‰ªæž-é‡åŒ–æ–¹æ³•ä¾èµ–è®­ç»ƒå¾ªçŽ¯å¤–çš„è¾…åŠ©è¿‡ç¨‹ï¼Œå¯¼è‡´å·¥ç¨‹å¤æ‚å’Œæ¬¡ä¼˜åŽ‹ç¼©ã€‚
2. CoDeQåˆ©ç”¨é‡åŒ–å™¨æ­»åŒºç­‰æ•ˆäºŽå¹…åº¦å‰ªæžï¼Œé€šè¿‡å‚æ•°åŒ–æ­»åŒºå®½åº¦å®žçŽ°ç«¯åˆ°ç«¯å¯å¾®åˆ†ä¼˜åŒ–ã€‚
3. åœ¨ImageNetä¸Šï¼ŒCoDeQå°†ResNet-18çš„æ¯”ç‰¹æ“ä½œé™è‡³çº¦5%ï¼ŒåŒæ—¶ä¿æŒæŽ¥è¿‘å…¨ç²¾åº¦å‡†ç¡®çŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While joint pruning--quantization is theoretically superior to sequential application, current joint methods rely on auxiliary procedures outside the training loop for finding compression parameters. This reliance adds engineering complexity and hyperparameter tuning, while also lacking a direct data-driven gradient signal, which might result in sub-optimal compression. In this paper, we introduce CoDeQ, a simple, fully differentiable method for joint pruning--quantization. Our approach builds on a key observation: the dead-zone of a scalar quantizer is equivalent to magnitude pruning, and can be used to induce sparsity directly within the quantization operator. Concretely, we parameterize the dead-zone width and learn it via backpropagation, alongside the quantization parameters. This design provides explicit control of sparsity, regularized by a single global hyperparameter, while decoupling sparsity selection from bit-width selection. The result is a method for Compression with Dead-zone Quantizer (CoDeQ) that supports both fixed-precision and mixed-precision quantization (controlled by an optional second hyperparameter). It simultaneously determines the sparsity pattern and quantization parameters in a single end-to-end optimization. Consequently, CoDeQ does not require any auxiliary procedures, making the method architecture-agnostic and straightforward to implement. On ImageNet with ResNet-18, CoDeQ reduces bit operations to ~5% while maintaining close to full precision accuracy in both fixed and mixed-precision regimes.

