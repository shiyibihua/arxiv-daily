---
layout: default
title: JoDiffusion: Jointly Diffusing Image with Pixel-Level Annotations for Semantic Segmentation Promotion
---

# JoDiffusion: Jointly Diffusing Image with Pixel-Level Annotations for Semantic Segmentation Promotion

**arXiv**: [2512.13014v1](https://arxiv.org/abs/2512.13014) | [PDF](https://arxiv.org/pdf/2512.13014.pdf)

**ä½œè€…**: Haoyu Wang, Lei Zhang, Wenrui Liu, Dengyang Jiang, Wei Wei, Chen Ding

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºJoDiffusionæ¡†æž¶ï¼Œé€šè¿‡è”åˆæ‰©æ•£ç”Ÿæˆå›¾åƒä¸Žåƒç´ çº§æ ‡æ³¨ä»¥æå‡è¯­ä¹‰åˆ†å‰²æ€§èƒ½ã€‚**

**å…³é”®è¯**: `è¯­ä¹‰åˆ†å‰²` `æ‰©æ•£æ¨¡åž‹` `æ•°æ®é›†ç”Ÿæˆ` `åƒç´ çº§æ ‡æ³¨` `è”åˆåˆ†å¸ƒå»ºæ¨¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•ç”Ÿæˆåˆæˆæ•°æ®é›†æ—¶å­˜åœ¨å›¾åƒ-æ ‡æ³¨è¯­ä¹‰ä¸ä¸€è‡´æˆ–å¯æ‰©å±•æ€§é—®é¢˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥ç‹¬ç«‹æ ‡æ³¨VAEç½‘ç»œï¼Œä½¿æ‰©æ•£æ¨¡åž‹æ•èŽ·å›¾åƒä¸Žæ ‡æ³¨çš„è”åˆåˆ†å¸ƒï¼Œä»…åŸºäºŽæ–‡æœ¬æç¤ºåŒæ—¶ç”Ÿæˆé…å¯¹æ•°æ®ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Pascal VOCç­‰æ•°æ®é›†ä¸Šï¼Œç”Ÿæˆæ•°æ®é›†æ˜¾è‘—æå‡è¯­ä¹‰åˆ†å‰²æ¨¡åž‹æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Given the inherently costly and time-intensive nature of pixel-level annotation, the generation of synthetic datasets comprising sufficiently diverse synthetic images paired with ground-truth pixel-level annotations has garnered increasing attention recently for training high-performance semantic segmentation models. However, existing methods necessitate to either predict pseudo annotations after image generation or generate images conditioned on manual annotation masks, which incurs image-annotation semantic inconsistency or scalability problem. To migrate both problems with one stone, we present a novel dataset generative diffusion framework for semantic segmentation, termed JoDiffusion. Firstly, given a standard latent diffusion model, JoDiffusion incorporates an independent annotation variational auto-encoder (VAE) network to map annotation masks into the latent space shared by images. Then, the diffusion model is tailored to capture the joint distribution of each image and its annotation mask conditioned on a text prompt. By doing these, JoDiffusion enables simultaneously generating paired images and semantically consistent annotation masks solely conditioned on text prompts, thereby demonstrating superior scalability. Additionally, a mask optimization strategy is developed to mitigate the annotation noise produced during generation. Experiments on Pascal VOC, COCO, and ADE20K datasets show that the annotated dataset generated by JoDiffusion yields substantial performance improvements in semantic segmentation compared to existing methods.

