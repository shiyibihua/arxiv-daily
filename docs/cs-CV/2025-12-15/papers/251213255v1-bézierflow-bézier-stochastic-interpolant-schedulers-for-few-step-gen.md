---
layout: default
title: BÃ©zierFlow: BÃ©zier Stochastic Interpolant Schedulers for Few-Step Generation
---

# BÃ©zierFlow: BÃ©zier Stochastic Interpolant Schedulers for Few-Step Generation

**arXiv**: [2512.13255v1](https://arxiv.org/abs/2512.13255) | [PDF](https://arxiv.org/pdf/2512.13255.pdf)

**ä½œè€…**: Yunhong Min, Juil Koo, Seungwoo Yoo, Minhyuk Sung

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBÃ©zierFlowï¼Œé€šè¿‡å‚æ•°åŒ–éšæœºæ’å€¼è°ƒåº¦å™¨ä¼˜åŒ–é‡‡æ ·è½¨è¿¹ï¼Œå®žçŽ°å°‘æ­¥ç”Ÿæˆæ€§èƒ½æå‡ã€‚**

**å…³é”®è¯**: `å°‘æ­¥ç”Ÿæˆ` `éšæœºæ’å€¼è°ƒåº¦å™¨` `BÃ©zierå‡½æ•°` `æ‰©æ•£æ¨¡åž‹` `æµæ¨¡åž‹` `è½»é‡è®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è½»é‡è®­ç»ƒæ–¹æ³•å±€é™äºŽODEç¦»æ•£åŒ–ï¼Œéš¾ä»¥ä¼˜åŒ–é‡‡æ ·è½¨è¿¹å˜æ¢ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨BÃ©zierå‡½æ•°å‚æ•°åŒ–è°ƒåº¦å™¨ï¼Œæ»¡è¶³è¾¹ç•Œæ¡ä»¶å’Œå•è°ƒæ€§ç­‰å…³é”®éœ€æ±‚ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨é¢„è®­ç»ƒæ‰©æ•£å’Œæµæ¨¡åž‹ä¸­ï¼ŒBÃ©zierFlowåœ¨â‰¤10æ­¥é‡‡æ ·æ—¶æ€§èƒ½æå‡2-3å€ï¼Œè®­ç»ƒä»…éœ€15åˆ†é’Ÿã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce BÃ©zierFlow, a lightweight training approach for few-step generation with pretrained diffusion and flow models. BÃ©zierFlow achieves a 2-3x performance improvement for sampling with $\leq$ 10 NFEs while requiring only 15 minutes of training. Recent lightweight training approaches have shown promise by learning optimal timesteps, but their scope remains restricted to ODE discretizations. To broaden this scope, we propose learning the optimal transformation of the sampling trajectory by parameterizing stochastic interpolant (SI) schedulers. The main challenge lies in designing a parameterization that satisfies critical desiderata, including boundary conditions, differentiability, and monotonicity of the SNR. To effectively meet these requirements, we represent scheduler functions as BÃ©zier functions, where control points naturally enforce these properties. This reduces the problem to learning an ordered set of points in the time range, while the interpretation of the points changes from ODE timesteps to BÃ©zier control points. Across a range of pretrained diffusion and flow models, BÃ©zierFlow consistently outperforms prior timestep-learning methods, demonstrating the effectiveness of expanding the search space from discrete timesteps to BÃ©zier-based trajectory transformations.

