---
layout: default
title: MoLingo: Motion-Language Alignment for Text-to-Motion Generation
---

# MoLingo: Motion-Language Alignment for Text-to-Motion Generation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.13840" target="_blank" class="toolbar-btn">arXiv: 2512.13840v1</a>
    <a href="https://arxiv.org/pdf/2512.13840.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.13840v1" 
            onclick="toggleFavorite(this, '2512.13840v1', 'MoLingo: Motion-Language Alignment for Text-to-Motion Generation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yannan He, Garvita Tiwari, Xiaohan Zhang, Pankaj Bora, Tolga Birdal, Jan Eric Lenssen, Gerard Pons-Moll

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-15

**Â§áÊ≥®**: Project page: https://hynann.github.io/molingo/MoLingo.html

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**MoLingoÔºöÈÄöËøáËøêÂä®-ËØ≠Ë®ÄÂØπÈΩêÂÆûÁé∞ÊñáÊú¨Âà∞Âä®‰ΩúÁîüÊàêÔºåËææÂà∞Êñ∞ÁöÑSOTA„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `ÊñáÊú¨Âà∞Âä®‰ΩúÁîüÊàê` `ËøêÂä®ÁîüÊàê` `Êâ©Êï£Ê®°Âûã` `ËØ≠‰πâÂØπÈΩê` `‰∫§ÂèâÊ≥®ÊÑèÂäõ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñáÊú¨Âà∞Âä®‰ΩúÁîüÊàêÊñπÊ≥ïÂú®ËØ≠‰πâÂØπÈΩêÁöÑÊΩúÂú®Á©∫Èó¥ÊûÑÂª∫ÂíåÊñáÊú¨Êù°‰ª∂Ê≥®ÂÖ•ÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÂΩ±Âìç‰∫ÜÁîüÊàêÂä®‰ΩúÁöÑÁúüÂÆûÊÄßÂíåÊñáÊú¨‰∏ÄËá¥ÊÄß„ÄÇ
2. MoLingoÈÄöËøáËÆ≠ÁªÉËØ≠‰πâÂØπÈΩêÁöÑËøêÂä®ÁºñÁ†ÅÂô®ÔºåÂπ∂ÁªìÂêàÂ§ötoken‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÂ¢ûÂº∫‰∫ÜÊΩúÂú®Á©∫Èó¥ÁöÑËØ≠‰πâË°®ËææËÉΩÂäõÂíåÊñáÊú¨Êù°‰ª∂ÁöÑÊúâÊïàÊÄß„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMoLingoÂú®‰∫∫Á±ªËøêÂä®ÁîüÊàê‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂπ∂Âú®Ê†áÂáÜÊåáÊ†áÂíåÁî®Êà∑Á†îÁ©∂‰∏≠ËææÂà∞‰∫ÜÊñ∞ÁöÑSOTA„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êàë‰ª¨ÊèêÂá∫‰∫ÜMoLingoÔºå‰∏Ä‰∏™ÊñáÊú¨Âà∞Âä®‰ΩúÔºàT2MÔºâÊ®°ÂûãÔºåÂÆÉÈÄöËøáÂú®ËøûÁª≠ÊΩúÂú®Á©∫Èó¥‰∏≠ÂéªÂô™Êù•ÁîüÊàêÈÄºÁúü„ÄÅÊ†©Ê†©Â¶ÇÁîüÁöÑ‰∫∫Á±ªËøêÂä®„ÄÇÊúÄËøëÁöÑÂ∑•‰ΩúÂú®Êï¥‰∏™ÊΩúÂú®Á©∫Èó¥‰∏ä‰∏ÄÊ¨°ÊÄßÂú∞ÊàñÈÄöËøáÂ§ö‰∏™ÊΩúÂú®ÂèòÈáèËá™ÂõûÂΩíÂú∞ÊâßË°åÊΩúÂú®Á©∫Èó¥Êâ©Êï£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Á†îÁ©∂Â¶Ç‰Ωï‰ΩøËøûÁª≠ËøêÂä®ÊΩúÂú®ÂèòÈáè‰∏äÁöÑÊâ©Êï£ÊïàÊûúÊúÄ‰Ω≥„ÄÇÊàë‰ª¨‰∏ìÊ≥®‰∫é‰∏§‰∏™ÈóÆÈ¢òÔºöÔºà1ÔºâÂ¶Ç‰ΩïÊûÑÂª∫ËØ≠‰πâÂØπÈΩêÁöÑÊΩúÂú®Á©∫Èó¥Ôºå‰ΩøÊâ©Êï£Êõ¥ÊúâÊïàÔºõÔºà2ÔºâÂ¶Ç‰ΩïÊúÄÂ•ΩÂú∞Ê≥®ÂÖ•ÊñáÊú¨Êù°‰ª∂Ôºå‰ΩøËøêÂä®Á¥ßÂØÜÂú∞ÈÅµÂæ™ÊèèËø∞„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ËØ≠‰πâÂØπÈΩêÁöÑËøêÂä®ÁºñÁ†ÅÂô®ÔºåËØ•ÁºñÁ†ÅÂô®‰ΩøÁî®Â∏ßÁ∫ßÂà´ÁöÑÊñáÊú¨Ê†áÁ≠æËøõË°åËÆ≠ÁªÉÔºå‰ª•‰æøÂÖ∑ÊúâÁõ∏‰ººÊñáÊú¨Âê´‰πâÁöÑÊΩúÂú®ÂèòÈáè‰øùÊåÅÊé•ËøëÔºåËøô‰ΩøÂæóÊΩúÂú®Á©∫Èó¥Êõ¥ÈÄÇÂêàÊâ©Êï£„ÄÇÊàë‰ª¨ËøòÂ∞ÜÂçïtokenÊù°‰ª∂‰∏éÂ§ötoken‰∫§ÂèâÊ≥®ÊÑèÂäõÊñπÊ°àËøõË°å‰∫ÜÊØîËæÉÔºåÂèëÁé∞‰∫§ÂèâÊ≥®ÊÑèÂäõÊèê‰æõ‰∫ÜÊõ¥Â•ΩÁöÑËøêÂä®ÁúüÂÆûÊÑüÂíåÊñáÊú¨-ËøêÂä®ÂØπÈΩê„ÄÇÂá≠ÂÄüËØ≠‰πâÂØπÈΩêÁöÑÊΩúÂú®ÂèòÈáè„ÄÅËá™ÂõûÂΩíÁîüÊàêÂíå‰∫§ÂèâÊ≥®ÊÑèÂäõÊñáÊú¨Êù°‰ª∂ÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÂú®Ê†áÂáÜÊåáÊ†áÂíåÁî®Êà∑Á†îÁ©∂‰∏≠ÔºåÂú®‰∫∫Á±ªËøêÂä®ÁîüÊàêÊñπÈù¢Ê†ëÁ´ã‰∫ÜÊñ∞ÁöÑÊäÄÊúØÊ∞¥Âπ≥„ÄÇÊàë‰ª¨Â∞ÜÂèëÂ∏ÉÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂíåÊ®°ÂûãÔºå‰ª•‰æõËøõ‰∏ÄÊ≠•Á†îÁ©∂Âíå‰∏ãÊ∏∏‰ΩøÁî®„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊñáÊú¨Âà∞Âä®‰ΩúÁîüÊàêÔºàT2MÔºâÊó®Âú®Ê†πÊçÆÁªôÂÆöÁöÑÊñáÊú¨ÊèèËø∞ÁîüÊàêÂØπÂ∫îÁöÑ‰∫∫‰ΩìËøêÂä®Â∫èÂàó„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®ÁîüÊàêÈÄºÁúü‰∏î‰∏éÊñáÊú¨ÊèèËø∞È´òÂ∫¶‰∏ÄËá¥ÁöÑËøêÂä®ÊñπÈù¢Â≠òÂú®ÊåëÊàò„ÄÇ‰∏ªË¶ÅÁóõÁÇπÂú®‰∫éÂ¶Ç‰ΩïÊûÑÂª∫‰∏Ä‰∏™ËÉΩÂ§üÊúâÊïàÊçïÊçâËøêÂä®ËØ≠‰πâÁöÑÊΩúÂú®Á©∫Èó¥Ôºå‰ª•ÂèäÂ¶Ç‰ΩïÂ∞ÜÊñáÊú¨‰ø°ÊÅØÊúâÊïàÂú∞ËûçÂÖ•Âà∞ËøêÂä®ÁîüÊàêËøáÁ®ã‰∏≠„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMoLingoÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™ËØ≠‰πâÂØπÈΩêÁöÑËøêÂä®ÊΩúÂú®Á©∫Èó¥ÔºåÂπ∂ÈááÁî®Â§ötoken‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂Êù•Â¢ûÂº∫ÊñáÊú¨Êù°‰ª∂ÁöÑ‰ΩúÁî®„ÄÇÈÄöËøáËØ≠‰πâÂØπÈΩêÔºå‰ΩøÂæóÊΩúÂú®Á©∫Èó¥‰∏≠ÁöÑÁÇπËÉΩÂ§üÊõ¥Â•ΩÂú∞ÂèçÊò†ËøêÂä®ÁöÑËØ≠‰πâ‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òÁîüÊàêËøêÂä®ÁöÑË¥®Èáè„ÄÇ‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂ÂàôËÉΩÂ§üÊõ¥Á≤æÁªÜÂú∞ÊçïÊçâÊñáÊú¨ÊèèËø∞‰∏≠ÁöÑÂÖ≥ÈîÆ‰ø°ÊÅØÔºåÂπ∂Â∞ÜÂÖ∂ËûçÂÖ•Âà∞ËøêÂä®ÁîüÊàêËøáÁ®ã‰∏≠„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMoLingoÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ËøêÂä®ÁºñÁ†ÅÂô®ÔºöÂ∞ÜËøêÂä®Â∫èÂàóÁºñÁ†ÅÂà∞ÊΩúÂú®Á©∫Èó¥‰∏≠„ÄÇ2) ÊñáÊú¨ÁºñÁ†ÅÂô®ÔºöÂ∞ÜÊñáÊú¨ÊèèËø∞ÁºñÁ†Å‰∏∫ÊñáÊú¨ÁâπÂæÅ„ÄÇ3) Êâ©Êï£Ê®°ÂûãÔºöÂú®ÊΩúÂú®Á©∫Èó¥‰∏≠ËøõË°åÂéªÂô™Êâ©Êï£ÔºåÁîüÊàêÊñ∞ÁöÑËøêÂä®ÊΩúÂú®Ë°®Á§∫„ÄÇ4) ËøêÂä®Ëß£Á†ÅÂô®ÔºöÂ∞ÜÊΩúÂú®Ë°®Á§∫Ëß£Á†Å‰∏∫ËøêÂä®Â∫èÂàó„ÄÇÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠Ôºå‰ΩøÁî®Â∏ßÁ∫ßÂà´ÁöÑÊñáÊú¨Ê†áÁ≠æÊù•ËÆ≠ÁªÉËøêÂä®ÁºñÁ†ÅÂô®Ôºå‰ª•ÂÆûÁé∞ËØ≠‰πâÂØπÈΩê„ÄÇÂú®ÁîüÊàêËøáÁ®ã‰∏≠Ôºå‰ΩøÁî®‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂Â∞ÜÊñáÊú¨ÁâπÂæÅËûçÂÖ•Âà∞Êâ©Êï£Ê®°ÂûãÁöÑÂéªÂô™ËøáÁ®ã‰∏≠„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMoLingoÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫ÜËØ≠‰πâÂØπÈΩêÁöÑËøêÂä®ÁºñÁ†ÅÂô®ÔºåÈÄöËøáÂ∏ßÁ∫ßÂà´ÁöÑÊñáÊú¨Ê†áÁ≠æËÆ≠ÁªÉÔºå‰ΩøÂæóÊΩúÂú®Á©∫Èó¥ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÂèçÊò†ËøêÂä®ÁöÑËØ≠‰πâ‰ø°ÊÅØ„ÄÇ2) ÈááÁî®‰∫ÜÂ§ötoken‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåËÉΩÂ§üÊõ¥Á≤æÁªÜÂú∞ÊçïÊçâÊñáÊú¨ÊèèËø∞‰∏≠ÁöÑÂÖ≥ÈîÆ‰ø°ÊÅØÔºåÂπ∂Â∞ÜÂÖ∂ËûçÂÖ•Âà∞ËøêÂä®ÁîüÊàêËøáÁ®ã‰∏≠„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËØ≠‰πâÂØπÈΩêÁöÑËøêÂä®ÁºñÁ†ÅÂô®‰∏≠Ôºå‰ΩøÁî®‰∫ÜÂØπÊØîÂ≠¶‰π†ÊçüÂ§±Êù•ÊãâËøëÂÖ∑ÊúâÁõ∏‰ººÊñáÊú¨Âê´‰πâÁöÑËøêÂä®ÊΩúÂú®Ë°®Á§∫„ÄÇÂú®‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂‰∏≠Ôºå‰ΩøÁî®‰∫ÜÂ§ö‰∏™Ê≥®ÊÑèÂäõÂ§¥Êù•ÊçïÊçâÊñáÊú¨ÊèèËø∞‰∏≠ÁöÑ‰∏çÂêåÊñπÈù¢ÁöÑ‰ø°ÊÅØ„ÄÇÊâ©Êï£Ê®°ÂûãÈááÁî®‰∫ÜÊ†áÂáÜÁöÑÊâ©Êï£Ê®°ÂûãÊû∂ÊûÑÔºåÂπ∂‰ΩøÁî®U-Net‰Ωú‰∏∫ÂéªÂô™ÁΩëÁªú„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MoLingoÂú®HumanML3DÂíåKIT-MLÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÔºåÂπ∂Âú®Â§ö‰∏™ÊåáÊ†á‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºåÂú®HumanML3DÊï∞ÊçÆÈõÜ‰∏äÔºåMoLingoÂú®FIDÊåáÊ†á‰∏ä‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂Âú®Áî®Êà∑Á†îÁ©∂‰∏≠Ëé∑Âæó‰∫ÜÊõ¥È´òÁöÑÁî®Êà∑Êª°ÊÑèÂ∫¶ËØÑÂàÜ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMoLingoËÉΩÂ§üÁîüÊàêÊõ¥ÈÄºÁúü„ÄÅÊõ¥Á¨¶ÂêàÊñáÊú¨ÊèèËø∞ÁöÑËøêÂä®Â∫èÂàó„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MoLingoÂú®ËôöÊãüÁé∞ÂÆû„ÄÅÊ∏∏ÊàèÂºÄÂèë„ÄÅÂä®ÁîªÂà∂‰ΩúÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÁîüÊàêÈÄºÁúüÁöÑ‰∫∫‰ΩìËøêÂä®Ôºå‰ªéËÄåÂ¢ûÂº∫ËôöÊãüËßíËâ≤ÁöÑË°®Áé∞ÂäõÔºåÊèêÈ´òÁî®Êà∑‰ΩìÈ™å„ÄÇÊ≠§Â§ñÔºåMoLingoËøòÂèØ‰ª•Áî®‰∫éËøêÂä®ÂàÜÊûê„ÄÅÂ∫∑Â§çËÆ≠ÁªÉÁ≠âÈ¢ÜÂüüÔºåÈÄöËøáÂàÜÊûê‰∫∫‰ΩìËøêÂä®Êï∞ÊçÆÔºå‰∏∫Áõ∏ÂÖ≥Á†îÁ©∂Êèê‰æõÊîØÊåÅ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We introduce MoLingo, a text-to-motion (T2M) model that generates realistic, lifelike human motion by denoising in a continuous latent space. Recent works perform latent space diffusion, either on the whole latent at once or auto-regressively over multiple latents. In this paper, we study how to make diffusion on continuous motion latents work best. We focus on two questions: (1) how to build a semantically aligned latent space so diffusion becomes more effective, and (2) how to best inject text conditioning so the motion follows the description closely. We propose a semantic-aligned motion encoder trained with frame-level text labels so that latents with similar text meaning stay close, which makes the latent space more diffusion-friendly. We also compare single-token conditioning with a multi-token cross-attention scheme and find that cross-attention gives better motion realism and text-motion alignment. With semantically aligned latents, auto-regressive generation, and cross-attention text conditioning, our model sets a new state of the art in human motion generation on standard metrics and in a user study. We will release our code and models for further research and downstream usage.

