---
layout: default
title: Scalable Formal Verification via Autoencoder Latent Space Abstraction
---

# Scalable Formal Verification via Autoencoder Latent Space Abstraction

**arXiv**: [2512.13593v1](https://arxiv.org/abs/2512.13593) | [PDF](https://arxiv.org/pdf/2512.13593.pdf)

**ä½œè€…**: Robert Reed, Morteza Lahijanian, Luca Laurenti

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå‡¸è‡ªç¼–ç å™¨æ½œåœ¨ç©ºé—´æŠ½è±¡çš„å¯æ‰©å±•å½¢å¼éªŒè¯æ–¹æ³•ï¼Œä»¥è§£å†³é«˜ç»´ç³»ç»ŸéªŒè¯çš„æ‰©å±•æ€§é—®é¢˜ã€‚**

**å…³é”®è¯**: `å½¢å¼éªŒè¯` `è‡ªç¼–ç å™¨` `æ½œåœ¨ç©ºé—´æŠ½è±¡` `å¯æ‰©å±•æ€§` `é«˜ç»´ç³»ç»Ÿ` `æ ¸æ–¹æ³•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé«˜ç»´ç³»ç»Ÿå½¢å¼éªŒè¯é¢ä¸´çŠ¶æ€ç©ºé—´ç¦»æ•£åŒ–å¯¼è‡´çš„æŒ‡æ•°çº§æ‰©å±•æ€§æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å‡¸è‡ªç¼–ç å™¨é™ç»´ï¼ŒåŸºäºŽæ ¸æ–¹æ³•å­¦ä¹ æ½œåœ¨ç©ºé—´åŠ¨æ€ï¼Œå¹¶æž„å»ºåŒ…å«åŽŸå§‹ç³»ç»Ÿè¡Œä¸ºçš„æœ‰é™æŠ½è±¡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŒ…æ‹¬26Dç¥žç»ç½‘ç»œæŽ§åˆ¶ç³»ç»Ÿåœ¨å†…çš„å¤šä¸ªç³»ç»Ÿä¸ŠéªŒè¯ï¼Œæ˜¾è‘—æå‡æ‰©å±•æ€§è€Œä¸å¤±ä¸¥è°¨æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Finite Abstraction methods provide a powerful formal framework for proving that systems satisfy their specifications. However, these techniques face scalability challenges for high-dimensional systems, as they rely on state-space discretization which grows exponentially with dimension. Learning-based approaches to dimensionality reduction, utilizing neural networks and autoencoders, have shown great potential to alleviate this problem. However, ensuring the correctness of the resulting verification results remains an open question. In this work, we provide a formal approach to reduce the dimensionality of systems via convex autoencoders and learn the dynamics in the latent space through a kernel-based method. We then construct a finite abstraction from the learned model in the latent space and guarantee that the abstraction contains the true behaviors of the original system. We show that the verification results in the latent space can be mapped back to the original system. Finally, we demonstrate the effectiveness of our approach on multiple systems, including a 26D system controlled by a neural network, showing significant scalability improvements without loss of rigor.

