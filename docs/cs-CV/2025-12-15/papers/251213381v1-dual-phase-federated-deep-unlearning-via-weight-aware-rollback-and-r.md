---
layout: default
title: Dual-Phase Federated Deep Unlearning via Weight-Aware Rollback and Reconstruction
---

# Dual-Phase Federated Deep Unlearning via Weight-Aware Rollback and Reconstruction

**arXiv**: [2512.13381v1](https://arxiv.org/abs/2512.13381) | [PDF](https://arxiv.org/pdf/2512.13381.pdf)

**ä½œè€…**: Changjun Zhou, Jintao Zheng, Leyou Yang, Pengfei Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒé˜¶æ®µè”é‚¦æ·±åº¦é—å¿˜æ–¹æ³•ï¼Œé€šè¿‡æƒé‡æ„ŸçŸ¥å›žæ»šä¸Žé‡å»ºè§£å†³éšç§æ³„éœ²é—®é¢˜**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `éšç§ä¿æŠ¤` `æ·±åº¦é—å¿˜` `æƒé‡å›žæ»š` `å˜åˆ†è‡ªç¼–ç å™¨` `æ¨¡åž‹é‡å»º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è”é‚¦é—å¿˜æ–¹æ³•ä¾èµ–æœåŠ¡å™¨ç«¯çŸ¥è¯†è’¸é¦ï¼Œä»…ç§»é™¤ç›®æ ‡å®¢æˆ·ç«¯æ›´æ–°ï¼Œå¿½ç•¥å…¶ä»–å®¢æˆ·ç«¯è´¡çŒ®ä¸­çš„éšç§ï¼Œå¯èƒ½å¯¼è‡´éšç§æ³„éœ²ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽæƒé‡æ„ŸçŸ¥ï¼Œå›žæ»šé«˜æƒé‡å‚æ•°ï¼Œåˆ©ç”¨å˜åˆ†è‡ªç¼–ç å™¨é‡å»ºå¹¶æ¶ˆé™¤ä½Žæƒé‡å‚æ•°ï¼Œç»“åˆæŠ•å½±æŠ€æœ¯æ¢å¤æ¨¡åž‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å››ä¸ªæ•°æ®é›†ä¸ŠéªŒè¯ï¼Œç›¸æ¯”åŸºçº¿æ–¹æ³•ï¼Œå‡†ç¡®çŽ‡æå‡1%-5%ï¼Œæ—¶é—´æˆæœ¬é™ä½Žé«˜è¾¾12å€ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Federated Unlearning (FUL) focuses on client data and computing power to offer a privacy-preserving solution. However, high computational demands, complex incentive mechanisms, and disparities in client-side computing power often lead to long times and higher costs. To address these challenges, many existing methods rely on server-side knowledge distillation that solely removes the updates of the target client, overlooking the privacy embedded in the contributions of other clients, which can lead to privacy leakage. In this work, we introduce DPUL, a novel server-side unlearning method that deeply unlearns all influential weights to prevent privacy pitfalls. Our approach comprises three components: (i) identifying high-weight parameters by filtering client update magnitudes, and rolling them back to ensure deep removal. (ii) leveraging the variational autoencoder (VAE) to reconstruct and eliminate low-weight parameters. (iii) utilizing a projection-based technique to recover the model. Experimental results on four datasets demonstrate that DPUL surpasses state-of-the-art baselines, providing a 1%-5% improvement in accuracy and up to 12x reduction in time cost.

