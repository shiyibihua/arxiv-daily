---
layout: default
title: MiniLingua: A Small Open-Source LLM for European Languages
---

# MiniLingua: A Small Open-Source LLM for European Languages

**arXiv**: [2512.13298v1](https://arxiv.org/abs/2512.13298) | [PDF](https://arxiv.org/pdf/2512.13298.pdf)

**ä½œè€…**: Anna Aksenova, Boris Zverkov, Nicola Dainese, Alexander Nikitin, Pekka Marttinen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMiniLinguaå°åž‹å¼€æºå¤šè¯­è¨€å¤§æ¨¡åž‹ï¼Œä»¥è§£å†³æ¬§æ´²è¯­è¨€è¦†ç›–ä¸ŽæŒ‡ä»¤è·Ÿéšçš„å¹³è¡¡é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤šè¯­è¨€å¤§æ¨¡åž‹` `å°åž‹æ¨¡åž‹` `æŒ‡ä»¤è·Ÿéš` `æ¬§æ´²è¯­è¨€` `å¼€æºæ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§æ¨¡åž‹è®¡ç®—æˆæœ¬é«˜ã€éšç§æ‹…å¿§åŠè‹±è¯­ä¸­å¿ƒåŒ–è®­ç»ƒé™åˆ¶åº”ç”¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä»Žå¤´è®­ç»ƒ10äº¿å‚æ•°æ¨¡åž‹ï¼Œè¦†ç›–13ç§æ¬§æ´²è¯­è¨€ï¼Œæ³¨é‡æŒ‡ä»¤è·Ÿéšèƒ½åŠ›ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šé¡¹ä»»åŠ¡ä¸­ä¼˜äºŽEuroLLMï¼Œä¸Žå…ˆè¿›æ¨¡åž‹åœ¨å¼€æ”¾ç”Ÿæˆä»»åŠ¡ä¸­ç«žäº‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large language models are powerful but often limited by high computational cost, privacy concerns, and English-centric training. Recent progress demonstrates that small, efficient models with around one billion parameters can deliver strong results and enable on-device use. This paper introduces MiniLingua, a multilingual open-source LLM of one billion parameters trained from scratch for 13 European languages, designed to balance coverage and instruction-following capabilities. Based on evaluation results, the instruction-tuned version of MiniLingua outperforms EuroLLM, a model with a similar training approach but a larger training budget, on summarization, classification and both open- and closed-book question answering. Moreover, it remains competitive with more advanced state-of-the-art models on open-ended generation tasks. We release model weights, tokenizer and source code used for data processing and model training.

