---
layout: default
title: Computer vision training dataset generation for robotic environments using Gaussian splatting
---

# Computer vision training dataset generation for robotic environments using Gaussian splatting

**arXiv**: [2512.13411v1](https://arxiv.org/abs/2512.13411) | [PDF](https://arxiv.org/pdf/2512.13411.pdf)

**ä½œè€…**: Patryk NiÅ¼eniec, Marcin Iwanowski

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽé«˜æ–¯æ³¼æº…çš„æœºå™¨äººè§†è§‰æ•°æ®é›†ç”Ÿæˆæµæ°´çº¿ï¼Œä»¥è§£å†³åˆæˆä¸ŽçœŸå®žå›¾åƒåŸŸå·®è·å’Œæ‰‹åŠ¨æ ‡æ³¨ç“¶é¢ˆã€‚**

**å…³é”®è¯**: `é«˜æ–¯æ³¼æº…` `æ•°æ®é›†ç”Ÿæˆ` `æœºå™¨äººè§†è§‰` `åˆæˆæ•°æ®` `åŸŸé€‚åº”` `è‡ªåŠ¨æ ‡æ³¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåˆæˆä¸ŽçœŸå®žå›¾åƒåŸŸå·®è·åŠæ‰‹åŠ¨æ ‡æ³¨è€—æ—¶ï¼Œé˜»ç¢æœºå™¨äººè§†è§‰æ•°æ®é›†ç”Ÿæˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨3Dé«˜æ–¯æ³¼æº…åˆ›å»ºé€¼çœŸçŽ¯å¢ƒï¼Œç»“åˆæ¸¸æˆå¼•æ“Žç‰©ç†æ¨¡æ‹Ÿå’Œä¸¤éæ¸²æŸ“å¢žå¼ºçœŸå®žæ„Ÿã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ··åˆå°‘é‡çœŸå®žå›¾åƒä¸Žå¤§é‡åˆæˆæ•°æ®è®­ç»ƒï¼Œæå‡æ£€æµ‹ä¸Žåˆ†å‰²æ€§èƒ½ï¼ŒéªŒè¯ä¸ºé«˜æ•ˆç­–ç•¥ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper introduces a novel pipeline for generating large-scale, highly realistic, and automatically labeled datasets for computer vision tasks in robotic environments. Our approach addresses the critical challenges of the domain gap between synthetic and real-world imagery and the time-consuming bottleneck of manual annotation. We leverage 3D Gaussian Splatting (3DGS) to create photorealistic representations of the operational environment and objects. These assets are then used in a game engine where physics simulations create natural arrangements. A novel, two-pass rendering technique combines the realism of splats with a shadow map generated from proxy meshes. This map is then algorithmically composited with the image to add both physically plausible shadows and subtle highlights, significantly enhancing realism. Pixel-perfect segmentation masks are generated automatically and formatted for direct use with object detection models like YOLO. Our experiments show that a hybrid training strategy, combining a small set of real images with a large volume of our synthetic data, yields the best detection and segmentation performance, confirming this as an optimal strategy for efficiently achieving robust and accurate models.

