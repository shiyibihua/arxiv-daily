---
layout: default
title: Computer vision training dataset generation for robotic environments using Gaussian splatting
---

# Computer vision training dataset generation for robotic environments using Gaussian splatting

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.13411" target="_blank" class="toolbar-btn">arXiv: 2512.13411v1</a>
    <a href="https://arxiv.org/pdf/2512.13411.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.13411v1" 
            onclick="toggleFavorite(this, '2512.13411v1', 'Computer vision training dataset generation for robotic environments using Gaussian splatting')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Patryk NiÅ¼eniec, Marcin Iwanowski

**åˆ†ç±»**: cs.CV, cs.GR

**å‘å¸ƒæ—¥æœŸ**: 2025-12-15

**å¤‡æ³¨**: Code available at: https://patrykni.github.io/UnitySplat2Data/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºé«˜æ–¯æº…å°„çš„æœºå™¨äººç¯å¢ƒè®¡ç®—æœºè§†è§‰è®­ç»ƒæ•°æ®é›†ç”Ÿæˆæµç¨‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æœºå™¨äººè§†è§‰` `æ•°æ®é›†ç”Ÿæˆ` `3Dé«˜æ–¯æº…å°„` `é¢†åŸŸè‡ªé€‚åº”` `åˆæˆæ•°æ®` `ç›®æ ‡æ£€æµ‹` `å›¾åƒåˆ†å‰²` `ç‰©ç†æ¨¡æ‹Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åˆæˆæ•°æ®ä¸çœŸå®æ•°æ®å­˜åœ¨é¢†åŸŸå·®å¼‚ï¼Œä¸”äººå·¥æ ‡æ³¨è€—æ—¶ï¼Œé˜»ç¢äº†æœºå™¨äººè§†è§‰æ¨¡å‹è®­ç»ƒã€‚
2. åˆ©ç”¨3Dé«˜æ–¯æº…å°„ç”Ÿæˆé€¼çœŸåœºæ™¯å’Œç‰©ä½“ï¼Œç»“åˆæ¸¸æˆå¼•æ“ç‰©ç†æ¨¡æ‹Ÿå’Œä¸¤é˜¶æ®µæ¸²æŸ“æŠ€æœ¯ï¼Œè‡ªåŠ¨ç”Ÿæˆæ ‡æ³¨æ•°æ®ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå°‘é‡çœŸå®æ•°æ®ä¸å¤§é‡åˆæˆæ•°æ®æ··åˆè®­ç»ƒï¼Œå¯æœ‰æ•ˆæå‡ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æµç¨‹ï¼Œç”¨äºç”Ÿæˆå¤§è§„æ¨¡ã€é«˜åº¦é€¼çœŸä¸”è‡ªåŠ¨æ ‡æ³¨çš„æœºå™¨äººç¯å¢ƒè®¡ç®—æœºè§†è§‰ä»»åŠ¡æ•°æ®é›†ã€‚è¯¥æ–¹æ³•æ—¨åœ¨è§£å†³åˆæˆå›¾åƒä¸çœŸå®å›¾åƒä¹‹é—´çš„é¢†åŸŸå·®è·ä»¥åŠæ‰‹åŠ¨æ ‡æ³¨è€—æ—¶çš„é—®é¢˜ã€‚æˆ‘ä»¬åˆ©ç”¨3Dé«˜æ–¯æº…å°„(3DGS)åˆ›å»ºæ“ä½œç¯å¢ƒå’Œç‰©ä½“çš„ç…§ç‰‡çº§çœŸå®æ„Ÿè¡¨ç¤ºã€‚è¿™äº›èµ„æºéšåè¢«ç”¨äºæ¸¸æˆå¼•æ“ä¸­ï¼Œé€šè¿‡ç‰©ç†æ¨¡æ‹Ÿåˆ›å»ºè‡ªç„¶çš„åœºæ™¯å¸ƒç½®ã€‚ä¸€ç§æ–°é¢–çš„ä¸¤é˜¶æ®µæ¸²æŸ“æŠ€æœ¯å°†æº…å°„çš„çœŸå®æ„Ÿä¸ä»£ç†ç½‘æ ¼ç”Ÿæˆçš„é˜´å½±å›¾ç›¸ç»“åˆã€‚è¯¥é˜´å½±å›¾é€šè¿‡ç®—æ³•ä¸å›¾åƒåˆæˆï¼Œä»è€Œæ·»åŠ ç‰©ç†ä¸Šåˆç†çš„é˜´å½±å’Œç»†å¾®çš„é«˜å…‰ï¼Œæ˜¾è‘—å¢å¼ºäº†çœŸå®æ„Ÿã€‚åƒç´ å®Œç¾çš„åˆ†å‰²æ©ç è¢«è‡ªåŠ¨ç”Ÿæˆï¼Œå¹¶æ ¼å¼åŒ–ä¸ºå¯ç›´æ¥ç”¨äºYOLOç­‰ç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚å®éªŒè¡¨æ˜ï¼Œå°†å°‘é‡çœŸå®å›¾åƒä¸å¤§é‡åˆæˆæ•°æ®ç›¸ç»“åˆçš„æ··åˆè®­ç»ƒç­–ç•¥ï¼Œèƒ½å¤Ÿäº§ç”Ÿæœ€ä½³çš„æ£€æµ‹å’Œåˆ†å‰²æ€§èƒ½ï¼Œè¯å®äº†è¿™æ˜¯ä¸€ç§æœ‰æ•ˆå®ç°é²æ£’å’Œå‡†ç¡®æ¨¡å‹çš„æœ€ä½³ç­–ç•¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººç¯å¢ƒä¸­è®¡ç®—æœºè§†è§‰æ¨¡å‹è®­ç»ƒæ•°æ®é›†çš„è·å–é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆä¾èµ–äºè€—æ—¶è€—åŠ›çš„äººå·¥æ ‡æ³¨çœŸå®æ•°æ®ï¼Œè¦ä¹ˆä½¿ç”¨åˆæˆæ•°æ®ï¼Œä½†åˆæˆæ•°æ®ä¸çœŸå®æ•°æ®ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„é¢†åŸŸå·®å¼‚(domain gap)ï¼Œå¯¼è‡´æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸‹çš„æ€§èƒ½ä¸‹é™ã€‚å› æ­¤ï¼Œå¦‚ä½•é«˜æ•ˆã€ä½æˆæœ¬åœ°ç”Ÿæˆé«˜è´¨é‡ã€å¤§è§„æ¨¡çš„è®­ç»ƒæ•°æ®é›†æ˜¯å…³é”®æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨3Dé«˜æ–¯æº…å°„(3DGS)æŠ€æœ¯ç”Ÿæˆé«˜çœŸå®åº¦çš„åœºæ™¯å’Œç‰©ä½“è¡¨ç¤ºï¼Œå¹¶ç»“åˆæ¸¸æˆå¼•æ“çš„ç‰©ç†æ¨¡æ‹Ÿèƒ½åŠ›ï¼Œè‡ªåŠ¨ç”Ÿæˆå…·æœ‰çœŸå®æ„Ÿçš„è®­ç»ƒæ•°æ®ã€‚é€šè¿‡ç®—æ³•åˆæˆé˜´å½±å’Œé«˜å…‰ï¼Œè¿›ä¸€æ­¥æå‡å›¾åƒçš„çœŸå®åº¦ï¼Œä»è€Œç¼©å°åˆæˆæ•°æ®ä¸çœŸå®æ•°æ®ä¹‹é—´çš„é¢†åŸŸå·®è·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) ä½¿ç”¨3DGSåˆ›å»ºåœºæ™¯å’Œç‰©ä½“çš„é€¼çœŸè¡¨ç¤ºï¼›2) å°†è¿™äº›è¡¨ç¤ºå¯¼å…¥æ¸¸æˆå¼•æ“ï¼Œåˆ©ç”¨ç‰©ç†å¼•æ“æ¨¡æ‹Ÿç‰©ä½“åœ¨åœºæ™¯ä¸­çš„è‡ªç„¶æ’åˆ—ï¼›3) ä½¿ç”¨ä¸€ç§ä¸¤é˜¶æ®µæ¸²æŸ“æŠ€æœ¯ï¼Œå°†3DGSæ¸²æŸ“çš„å›¾åƒä¸ä»£ç†ç½‘æ ¼ç”Ÿæˆçš„é˜´å½±å›¾è¿›è¡Œåˆæˆï¼Œä»¥æ·»åŠ é€¼çœŸçš„é˜´å½±å’Œé«˜å…‰ï¼›4) è‡ªåŠ¨ç”Ÿæˆåƒç´ çº§åˆ«çš„åˆ†å‰²æ©ç ï¼Œå¹¶å°†å…¶æ ¼å¼åŒ–ä¸ºå¯ç›´æ¥ç”¨äºç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼ˆå¦‚YOLOï¼‰çš„æ ¼å¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºç»“åˆäº†3DGSçš„çœŸå®æ„Ÿæ¸²æŸ“èƒ½åŠ›å’Œæ¸¸æˆå¼•æ“çš„ç‰©ç†æ¨¡æ‹Ÿèƒ½åŠ›ï¼Œå®ç°äº†ä¸€ç§è‡ªåŠ¨åŒ–çš„ã€é«˜çœŸå®åº¦çš„è®­ç»ƒæ•°æ®ç”Ÿæˆæµç¨‹ã€‚æ­¤å¤–ï¼Œä¸¤é˜¶æ®µæ¸²æŸ“æŠ€æœ¯é€šè¿‡ç®—æ³•åˆæˆé˜´å½±å’Œé«˜å…‰ï¼Œè¿›ä¸€æ­¥æå‡äº†å›¾åƒçš„çœŸå®æ„Ÿï¼Œè¿™æ˜¯ä¸ä¼ ç»Ÿåˆæˆæ•°æ®ç”Ÿæˆæ–¹æ³•çš„é‡è¦åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šä¸¤é˜¶æ®µæ¸²æŸ“æŠ€æœ¯æ˜¯å…³é”®è®¾è®¡ä¹‹ä¸€ã€‚å®ƒé¦–å…ˆä½¿ç”¨3DGSæ¸²æŸ“åœºæ™¯ï¼Œç„¶åä½¿ç”¨ä»£ç†ç½‘æ ¼ç”Ÿæˆé˜´å½±å›¾ã€‚é˜´å½±å›¾é€šè¿‡ç®—æ³•ä¸3DGSæ¸²æŸ“çš„å›¾åƒè¿›è¡Œåˆæˆï¼Œä»è€Œæ·»åŠ é€¼çœŸçš„é˜´å½±å’Œé«˜å…‰ã€‚å…·ä½“åˆæˆæ–¹æ³•å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­å¯èƒ½æœ‰æ‰€æè¿°ï¼Œä½†æ ¹æ®æ‘˜è¦ä¿¡æ¯ï¼Œå…·ä½“ç»†èŠ‚æœªçŸ¥ã€‚æ­¤å¤–ï¼Œè‡ªåŠ¨ç”Ÿæˆåˆ†å‰²æ©ç çš„å…·ä½“ç®—æ³•ä¹ŸæœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå°†å°‘é‡çœŸå®å›¾åƒä¸å¤§é‡åˆæˆæ•°æ®ç›¸ç»“åˆçš„æ··åˆè®­ç»ƒç­–ç•¥ï¼Œèƒ½å¤Ÿäº§ç”Ÿæœ€ä½³çš„æ£€æµ‹å’Œåˆ†å‰²æ€§èƒ½ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªçŸ¥ï¼Œä½†è¯¥æ··åˆè®­ç»ƒç­–ç•¥è¢«è¯å®æ˜¯ä¸€ç§æœ‰æ•ˆå®ç°é²æ£’å’Œå‡†ç¡®æ¨¡å‹çš„æœ€ä½³ç­–ç•¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæœºå™¨äººè§†è§‰é¢†åŸŸï¼Œä¾‹å¦‚æœºå™¨äººæŠ“å–ã€å¯¼èˆªã€ç‰©ä½“è¯†åˆ«ç­‰ã€‚é€šè¿‡è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼Œå¯ä»¥é™ä½æ¨¡å‹è®­ç»ƒçš„æˆæœ¬å’Œæ—¶é—´ï¼Œæé«˜æ¨¡å‹åœ¨çœŸå®ç¯å¢ƒä¸­çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°æ›´å¤æ‚çš„åœºæ™¯å’Œä»»åŠ¡ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper introduces a novel pipeline for generating large-scale, highly realistic, and automatically labeled datasets for computer vision tasks in robotic environments. Our approach addresses the critical challenges of the domain gap between synthetic and real-world imagery and the time-consuming bottleneck of manual annotation. We leverage 3D Gaussian Splatting (3DGS) to create photorealistic representations of the operational environment and objects. These assets are then used in a game engine where physics simulations create natural arrangements. A novel, two-pass rendering technique combines the realism of splats with a shadow map generated from proxy meshes. This map is then algorithmically composited with the image to add both physically plausible shadows and subtle highlights, significantly enhancing realism. Pixel-perfect segmentation masks are generated automatically and formatted for direct use with object detection models like YOLO. Our experiments show that a hybrid training strategy, combining a small set of real images with a large volume of our synthetic data, yields the best detection and segmentation performance, confirming this as an optimal strategy for efficiently achieving robust and accurate models.

