---
layout: default
title: LongVie 2: Multimodal Controllable Ultra-Long Video World Model
---

# LongVie 2: Multimodal Controllable Ultra-Long Video World Model

**arXiv**: [2512.13604v1](https://arxiv.org/abs/2512.13604) | [PDF](https://arxiv.org/pdf/2512.13604.pdf)

**ä½œè€…**: Jianxiong Gao, Zhaoxi Chen, Xian Liu, Junhao Zhuang, Chengming Xu, Jianfeng Feng, Yu Qiao, Yanwei Fu, Chenyang Si, Ziwei Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLongVie 2ä»¥è§£å†³é•¿è§†é¢‘ä¸–ç•Œæ¨¡åž‹çš„å¯æŽ§æ€§ã€è§†è§‰è´¨é‡å’Œæ—¶é—´ä¸€è‡´æ€§é—®é¢˜**

**å…³é”®è¯**: `é•¿è§†é¢‘ä¸–ç•Œæ¨¡åž‹` `å¤šæ¨¡æ€å¯æŽ§ç”Ÿæˆ` `è‡ªå›žå½’æ¡†æž¶` `æ—¶é—´ä¸€è‡´æ€§` `è§†è§‰è´¨é‡ä¿æŒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæž„å»ºè§†é¢‘ä¸–ç•Œæ¨¡åž‹éœ€å…¼é¡¾å¯æŽ§æ€§ã€é•¿æœŸè§†è§‰è´¨é‡å’Œæ—¶é—´ä¸€è‡´æ€§
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä¸‰é˜¶æ®µè‡ªå›žå½’è®­ç»ƒï¼Œé›†æˆå¤šæ¨¡æ€å¼•å¯¼ã€é€€åŒ–æ„ŸçŸ¥è®­ç»ƒå’ŒåŽ†å²ä¸Šä¸‹æ–‡å¼•å¯¼
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨LongVGenBenchä¸Šå®žçŽ°å…ˆè¿›æ€§èƒ½ï¼Œæ”¯æŒé•¿è¾¾äº”åˆ†é’Ÿçš„è¿žç»­è§†é¢‘ç”Ÿæˆ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Building video world models upon pretrained video generation systems represents an important yet challenging step toward general spatiotemporal intelligence. A world model should possess three essential properties: controllability, long-term visual quality, and temporal consistency. To this end, we take a progressive approach-first enhancing controllability and then extending toward long-term, high-quality generation. We present LongVie 2, an end-to-end autoregressive framework trained in three stages: (1) Multi-modal guidance, which integrates dense and sparse control signals to provide implicit world-level supervision and improve controllability; (2) Degradation-aware training on the input frame, bridging the gap between training and long-term inference to maintain high visual quality; and (3) History-context guidance, which aligns contextual information across adjacent clips to ensure temporal consistency. We further introduce LongVGenBench, a comprehensive benchmark comprising 100 high-resolution one-minute videos covering diverse real-world and synthetic environments. Extensive experiments demonstrate that LongVie 2 achieves state-of-the-art performance in long-range controllability, temporal coherence, and visual fidelity, and supports continuous video generation lasting up to five minutes, marking a significant step toward unified video world modeling.

