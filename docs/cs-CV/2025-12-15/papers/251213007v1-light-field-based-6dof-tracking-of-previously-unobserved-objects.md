---
layout: default
title: Light Field Based 6DoF Tracking of Previously Unobserved Objects
---

# Light Field Based 6DoF Tracking of Previously Unobserved Objects

**arXiv**: [2512.13007v1](https://arxiv.org/abs/2512.13007) | [PDF](https://arxiv.org/pdf/2512.13007.pdf)

**ä½œè€…**: Nikolai Goncharov, James L. Gray, Donald G. Dansereau

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå…‰åœºå›¾åƒçš„6DoFè·Ÿè¸ªæ–¹æ³•ï¼Œæ— éœ€é¢„è®­ç»ƒæ¨¡åž‹ï¼Œé€‚ç”¨äºŽæœªè§‚æµ‹å¤æ‚ç‰©ä½“ã€‚**

**å…³é”®è¯**: `å…‰åœºå›¾åƒ` `6DoFè·Ÿè¸ª` `æœªè§‚æµ‹ç‰©ä½“` `é«˜æ–¯æº…å°„` `å¯å¾®æ¸²æŸ“` `æœºå™¨äººè§†è§‰`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰é«˜æ€§èƒ½è·Ÿè¸ªæ–¹æ³•ä¾èµ–é¢„æ•èŽ·ç‰©ä½“è§†å›¾ï¼Œé™åˆ¶äºŽå·²çŸ¥ç‰©ä½“é›†ï¼Œä¸”å¯¹å¤æ‚å¤–è§‚ï¼ˆå¦‚åå°„ï¼‰æ•æ„Ÿã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡åž‹ä»Žå…‰åœºè¾“å…¥æå–è¯­ä¹‰å’Œå‡ ä½•ç‰¹å¾ï¼Œè½¬æ¢ä¸ºè§†å›¾ç›¸å…³é«˜æ–¯æº…å°„ä½œä¸ºç»Ÿä¸€å¯¹è±¡è¡¨ç¤ºï¼Œæ”¯æŒå¯å¾®æ¸²æŸ“å’Œå§¿æ€ä¼˜åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŒ…å«æŒ‘æˆ˜æ€§åå°„ç‰©ä½“çš„å…‰åœºè·Ÿè¸ªæ•°æ®é›†ä¸Šå®žéªŒï¼Œä¸Žæœ€å…ˆè¿›åŸºäºŽæ¨¡åž‹çš„è·Ÿè¸ªå™¨ç«žäº‰ï¼ŒæŽ¨åŠ¨æœºå™¨äººç³»ç»Ÿé€šç”¨ç‰©ä½“è·Ÿè¸ªã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Object tracking is an important step in robotics and reautonomous driving pipelines, which has to generalize to previously unseen and complex objects. Existing high-performing methods often rely on pre-captured object views to build explicit reference models, which restricts them to a fixed set of known objects. However, such reference models can struggle with visually complex appearance, reducing the quality of tracking. In this work, we introduce an object tracking method based on light field images that does not depend on a pre-trained model, while being robust to complex visual behavior, such as reflections. We extract semantic and geometric features from light field inputs using vision foundation models and convert them into view-dependent Gaussian splats. These splats serve as a unified object representation, supporting differentiable rendering and pose optimization. We further introduce a light field object tracking dataset containing challenging reflective objects with precise ground truth poses. Experiments demonstrate that our method is competitive with state-of-the-art model-based trackers in these difficult cases, paving the way toward universal object tracking in robotic systems. Code/data available at https://github.com/nagonch/LiFT-6DoF.

