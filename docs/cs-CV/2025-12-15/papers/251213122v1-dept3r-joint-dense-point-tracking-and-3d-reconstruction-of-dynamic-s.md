---
layout: default
title: DePT3R: Joint Dense Point Tracking and 3D Reconstruction of Dynamic Scenes in a Single Forward Pass
---

# DePT3R: Joint Dense Point Tracking and 3D Reconstruction of Dynamic Scenes in a Single Forward Pass

**arXiv**: [2512.13122v1](https://arxiv.org/abs/2512.13122) | [PDF](https://arxiv.org/pdf/2512.13122.pdf)

**ä½œè€…**: Vivek Alumootil, Tuan-Anh Vu, M. Khalid Jawed

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDePT3Ræ¡†æž¶ï¼Œåœ¨å•æ¬¡å‰å‘ä¼ æ’­ä¸­è”åˆå®žçŽ°åŠ¨æ€åœºæ™¯çš„å¯†é›†ç‚¹è·Ÿè¸ªä¸Ž3Dé‡å»ºã€‚**

**å…³é”®è¯**: `åŠ¨æ€åœºæ™¯ç†è§£` `å¯†é›†ç‚¹è·Ÿè¸ª` `3Dé‡å»º` `å¤šä»»åŠ¡å­¦ä¹ ` `æ— ç›¸æœºä½å§¿` `å•æ¬¡å‰å‘ä¼ æ’­`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰åŠ¨æ€åœºæ™¯å¯†é›†ç‚¹è·Ÿè¸ªæ–¹æ³•ä¾èµ–æˆå¯¹å¤„ç†ã€å·²çŸ¥ç›¸æœºä½å§¿æˆ–æ—¶åºå‡è®¾ï¼Œé™åˆ¶çµæ´»æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å¼ºå¤§éª¨å¹²ç½‘ç»œæå–æ—¶ç©ºç‰¹å¾ï¼Œä½¿ç”¨å¯†é›†é¢„æµ‹å¤´å›žå½’åƒç´ çº§æ˜ å°„ï¼Œæ— éœ€ç›¸æœºä½å§¿ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŠ¨æ€åœºæ™¯åŸºå‡†æµ‹è¯•ä¸­è¡¨çŽ°ä¼˜å¼‚ï¼Œå†…å­˜æ•ˆçŽ‡æ˜¾è‘—æå‡ï¼Œä»£ç å¼€æºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Current methods for dense 3D point tracking in dynamic scenes typically rely on pairwise processing, require known camera poses, or assume a temporal ordering to input frames, constraining their flexibility and applicability. Additionally, recent advances have successfully enabled efficient 3D reconstruction from large-scale, unposed image collections, underscoring opportunities for unified approaches to dynamic scene understanding. Motivated by this, we propose DePT3R, a novel framework that simultaneously performs dense point tracking and 3D reconstruction of dynamic scenes from multiple images in a single forward pass. This multi-task learning is achieved by extracting deep spatio-temporal features with a powerful backbone and regressing pixel-wise maps with dense prediction heads. Crucially, DePT3R operates without requiring camera poses, substantially enhancing its adaptability and efficiency-especially important in dynamic environments with rapid changes. We validate DePT3R on several challenging benchmarks involving dynamic scenes, demonstrating strong performance and significant improvements in memory efficiency over existing state-of-the-art methods. Data and codes are available via the open repository: https://github.com/StructuresComp/DePT3R

