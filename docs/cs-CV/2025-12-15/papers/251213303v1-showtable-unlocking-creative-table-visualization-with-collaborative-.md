---
layout: default
title: ShowTable: Unlocking Creative Table Visualization with Collaborative Reflection and Refinement
---

# ShowTable: Unlocking Creative Table Visualization with Collaborative Reflection and Refinement

**arXiv**: [2512.13303v1](https://arxiv.org/abs/2512.13303) | [PDF](https://arxiv.org/pdf/2512.13303.pdf)

**ä½œè€…**: Zhihang Liu, Xiaoyi Bao, Pandeng Li, Junjie Zhou, Zhaohe Liao, Yefei He, Kaixun Jiang, Chen-Wei Xie, Yun Zheng, Hongtao Xie

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºShowTableç®¡é“ï¼Œé€šè¿‡åä½œåæ€ä¸Žç²¾ç‚¼è§£å†³åˆ›æ„è¡¨æ ¼å¯è§†åŒ–ä»»åŠ¡**

**å…³é”®è¯**: `åˆ›æ„è¡¨æ ¼å¯è§†åŒ–` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `æ‰©æ•£æ¨¡åž‹` `åä½œåæ€` `æ•°æ®æž„é€ ç®¡é“` `åŸºå‡†è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ¨¡åž‹åœ¨éœ€è¦æ·±åº¦æŽ¨ç†å’Œç²¾ç¡®æ•°æ®æ˜ å°„çš„åˆ›æ„è¡¨æ ¼å¯è§†åŒ–ä»»åŠ¡ä¸Šè¡¨çŽ°ä¸è¶³
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆMLLMä½œä¸ºä¸­å¤®åè°ƒå™¨è¿›è¡ŒæŽ¨ç†å’Œé”™è¯¯æ ¡æ­£ï¼Œæ‰©æ•£æ¨¡åž‹æ‰§è¡ŒæŒ‡ä»¤ï¼Œå®žçŽ°é«˜ä¿çœŸç”Ÿæˆ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨TableVisBenchåŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºŽåŸºçº¿ï¼ŒéªŒè¯äº†å¤šæ¨¡æ€æŽ¨ç†å’Œé”™è¯¯æ ¡æ­£èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While existing generation and unified models excel at general image generation, they struggle with tasks requiring deep reasoning, planning, and precise data-to-visual mapping abilities beyond general scenarios. To push beyond the existing limitations, we introduce a new and challenging task: creative table visualization, requiring the model to generate an infographic that faithfully and aesthetically visualizes the data from a given table. To address this challenge, we propose ShowTable, a pipeline that synergizes MLLMs with diffusion models via a progressive self-correcting process. The MLLM acts as the central orchestrator for reasoning the visual plan and judging visual errors to provide refined instructions, the diffusion execute the commands from MLLM, achieving high-fidelity results. To support this task and our pipeline, we introduce three automated data construction pipelines for training different modules. Furthermore, we introduce TableVisBench, a new benchmark with 800 challenging instances across 5 evaluation dimensions, to assess performance on this task. Experiments demonstrate that our pipeline, instantiated with different models, significantly outperforms baselines, highlighting its effective multi-modal reasoning, generation, and error correction capabilities.

