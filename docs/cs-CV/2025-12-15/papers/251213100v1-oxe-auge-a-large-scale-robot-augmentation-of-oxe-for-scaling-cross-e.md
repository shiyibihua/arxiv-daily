---
layout: default
title: OXE-AugE: A Large-Scale Robot Augmentation of OXE for Scaling Cross-Embodiment Policy Learning
---

# OXE-AugE: A Large-Scale Robot Augmentation of OXE for Scaling Cross-Embodiment Policy Learning

**arXiv**: [2512.13100v1](https://arxiv.org/abs/2512.13100) | [PDF](https://arxiv.org/pdf/2512.13100.pdf)

**ä½œè€…**: Guanhua Ji, Harsha Polavaram, Lawrence Yunliang Chen, Sandeep Bajamahal, Zehan Ma, Simeon Adebola, Chenfeng Xu, Ken Goldberg

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOXE-AugEæ•°æ®é›†ä¸ŽAugE-Toolkitæµæ°´çº¿ï¼Œé€šè¿‡æœºå™¨äººå¢žå¼ºè§£å†³è·¨å…·èº«ç­–ç•¥å­¦ä¹ çš„æ•°æ®ä¸å¹³è¡¡é—®é¢˜ã€‚**

**å…³é”®è¯**: `è·¨å…·èº«ç­–ç•¥å­¦ä¹ ` `æœºå™¨äººæ•°æ®å¢žå¼º` `å¤§è§„æ¨¡æ•°æ®é›†` `é€šç”¨æœºå™¨äººç­–ç•¥` `åˆ†å¸ƒåç§»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šOpen X-Embodimentæ•°æ®é›†é«˜åº¦ä¸å¹³è¡¡ï¼Œå‰å››ç§æœºå™¨äººç±»åž‹å çœŸå®žæ•°æ®è¶…85%ï¼Œå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼€å‘AugE-Toolkitæµæ°´çº¿ï¼Œç”ŸæˆOXE-AugEæ•°æ®é›†ï¼Œå¢žå¼º9ç§æœºå™¨äººå…·èº«ï¼Œè½¨è¿¹æ•°è¶…440ä¸‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå¢žå¼ºæå‡ç­–ç•¥æ€§èƒ½ï¼ŒåŒ…æ‹¬æœªè§æœºå™¨äººï¼›å¾®è°ƒOpenVLAå’ŒÏ€_0åœ¨çœŸå®žä»»åŠ¡ä¸­æˆåŠŸçŽ‡æé«˜24-45%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large and diverse datasets are needed for training generalist robot policies that have potential to control a variety of robot embodiments -- robot arm and gripper combinations -- across diverse tasks and environments. As re-collecting demonstrations and retraining for each new hardware platform are prohibitively costly, we show that existing robot data can be augmented for transfer and generalization. The Open X-Embodiment (OXE) dataset, which aggregates demonstrations from over 60 robot datasets, has been widely used as the foundation for training generalist policies. However, it is highly imbalanced: the top four robot types account for over 85\% of its real data, which risks overfitting to robot--scene combinations. We present AugE-Toolkit, a scalable robot augmentation pipeline, and OXE-AugE, a high-quality open-source dataset that augments OXE with 9 different robot embodiments. OXE-AugE provides over 4.4 million trajectories, more than triple the size of the original OXE. We conduct a systematic study of how scaling robot augmentation impacts cross-embodiment learning. Results suggest that augmenting datasets with diverse arms and grippers improves policy performance not only on the augmented robots, but also on unseen robots and even the original robots under distribution shifts. In physical experiments, we demonstrate that state-of-the-art generalist policies such as OpenVLA and $Ï€_0$ benefit from fine-tuning on OXE-AugE, improving success rates by 24-45% on previously unseen robot--gripper combinations across four real-world manipulation tasks. Project website: https://OXE-AugE.github.io/.

