---
layout: default
title: MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph
---

# MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph

**arXiv**: [2512.13510v1](https://arxiv.org/abs/2512.13510) | [PDF](https://arxiv.org/pdf/2512.13510.pdf)

**ä½œè€…**: Linjie Mu, Yannian Gu, Zhongzhen Huang, Yakun Zhu, Shaoting Zhang, Xiaofan Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMedCEGæ¡†æž¶ï¼Œé€šè¿‡å…³é”®è¯æ®å›¾å¢žå¼ºåŒ»å­¦è¯­è¨€æ¨¡åž‹çš„å¯éªŒè¯æŽ¨ç†èƒ½åŠ›ã€‚**

**å…³é”®è¯**: `åŒ»å­¦æŽ¨ç†` `å…³é”®è¯æ®å›¾` `å¼ºåŒ–å­¦ä¹ ` `ä¸´åºŠå¯é æ€§` `è¯­è¨€æ¨¡åž‹å¢žå¼º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŒ»å­¦æŽ¨ç†ä¸­å¼ºåŒ–å­¦ä¹ å¸¸å¿½è§†å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§ï¼Œå¯¼è‡´ä¸´åºŠå¯é æ€§å—é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºå…³é”®è¯æ®å›¾ç›‘ç£æŽ¨ç†è¿‡ç¨‹ï¼Œå¼•å…¥ä¸´åºŠæŽ¨ç†ç¨‹åºå¥–åŠ±è¯„ä¼°èŠ‚ç‚¹è¦†ç›–ã€ç»“æž„æ­£ç¡®æ€§å’Œé“¾å®Œæ•´æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æŒ‘æˆ˜æ€§ä¸´åºŠæ¡ˆä¾‹æ•°æ®é›†ä¸Šï¼ŒMedCEGè¶…è¶ŠçŽ°æœ‰æ–¹æ³•ï¼Œç”Ÿæˆä¸´åºŠæœ‰æ•ˆæŽ¨ç†é“¾ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Large language models with reasoning capabilities have demonstrated impressive performance across a wide range of domains. In clinical applications, a transparent, step-by-step reasoning process provides physicians with strong evidence to support decision-making. While reinforcement learning has effectively enhanced reasoning performance in medical contexts, the clinical reliability of these reasoning processes remains limited because their accuracy and validity are often overlooked during training. To address this gap, we propose MedCEG, a framework that augments medical language models with clinically valid reasoning pathways by explicitly supervising the reasoning process through a Critical Evidence Graph (CEG). We curate a dataset of challenging clinical cases and algorithmically construct a CEG for each sample to represent a high-quality verifiable reasoning pathway. To guide the reasoning process, we introduce a Clinical Reasoning Procedure Reward, which evaluates Node Coverage, Structural Correctness, and Chain Completeness, thereby providing a holistic assessment of reasoning quality. Experimental results show that MedCEG surpasses existing methods in performance while producing clinically valid reasoning chains, representing a solid advancement in reliable medical AI reasoning. The code and models are available at https://github.com/LinjieMu/MedCEG.

