---
layout: default
title: No One Left Behind: How to Exploit the Incomplete and Skewed Multi-Label Data for Conversion Rate Prediction
---

# No One Left Behind: How to Exploit the Incomplete and Skewed Multi-Label Data for Conversion Rate Prediction

**arXiv**: [2512.13300v1](https://arxiv.org/abs/2512.13300) | [PDF](https://arxiv.org/pdf/2512.13300.pdf)

**ä½œè€…**: Qinglin Jia, Zhaocheng Du, Chuhan Wu, Huifeng Guo, Ruiming Tang, Shuting Shi, Muyu Zhang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºKAMLæ¡†æž¶ä»¥è§£å†³åœ¨çº¿å¹¿å‘Šä¸­å¤šä»»åŠ¡å­¦ä¹ æ•°æ®ä¸å®Œæ•´å’Œåæ–œé—®é¢˜**

**å…³é”®è¯**: `å¤šä»»åŠ¡å­¦ä¹ ` `è½¬åŒ–çŽ‡é¢„æµ‹` `çŸ¥è¯†è¿ç§»` `æ•°æ®åæ–œ` `åœ¨çº¿å¹¿å‘Š`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¹¿å‘Šç³»ç»Ÿå¤šä»»åŠ¡æ•°æ®æ ‡ç­¾ä¸å®Œæ•´ä¸”åˆ†å¸ƒåæ–œï¼Œå¯¼è‡´è®­ç»ƒä¸Žéƒ¨ç½²æ•°æ®ä¸åŒ¹é…
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥ADMç­–ç•¥å’ŒHKEæœºåˆ¶ï¼Œç»“åˆæŽ’åºæŸå¤±ï¼Œä¼˜åŒ–çŸ¥è¯†è¿ç§»
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ç¦»çº¿è¡Œä¸šæ•°æ®é›†å’Œåœ¨çº¿A/Bæµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰åŸºçº¿

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In most real-world online advertising systems, advertisers typically have diverse customer acquisition goals. A common solution is to use multi-task learning (MTL) to train a unified model on post-click data to estimate the conversion rate (CVR) for these diverse targets. In practice, CVR prediction often encounters missing conversion data as many advertisers submit only a subset of user conversion actions due to privacy or other constraints, making the labels of multi-task data incomplete. If the model is trained on all available samples where advertisers submit user conversion actions, it may struggle when deployed to serve a subset of advertisers targeting specific conversion actions, as the training and deployment data distributions are mismatched. While considerable MTL efforts have been made, a long-standing challenge is how to effectively train a unified model with the incomplete and skewed multi-label data. In this paper, we propose a fine-grained Knowledge transfer framework for Asymmetric Multi-Label data (KAML). We introduce an attribution-driven masking strategy (ADM) to better utilize data with asymmetric multi-label data in training. However, the more relaxed masking in ADM is a double-edged sword: it provides additional training signals but also introduces noise due to skewed data. To address this, we propose a hierarchical knowledge extraction mechanism (HKE) to model the sample discrepancy within the target task tower. Finally, to maximize the utility of unlabeled samples, we incorporate ranking loss strategy to further enhance our model. The effectiveness of KAML has been demonstrated through comprehensive evaluations on offline industry datasets and online A/B tests, which show significant performance improvements over existing MTL baselines.

