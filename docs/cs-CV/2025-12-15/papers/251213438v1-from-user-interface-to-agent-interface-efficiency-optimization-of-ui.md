---
layout: default
title: From User Interface to Agent Interface: Efficiency Optimization of UI Representations for LLM Agents
---

# From User Interface to Agent Interface: Efficiency Optimization of UI Representations for LLM Agents

**arXiv**: [2512.13438v1](https://arxiv.org/abs/2512.13438) | [PDF](https://arxiv.org/pdf/2512.13438.pdf)

**ä½œè€…**: Dezhi Ran, Zhi Gong, Yuzhe Guo, Mengzhou Wu, Yuan Cao, Haochuan Lu, Hengyu Zhang, Xia Zeng, Gang Cao, Liangchao Yao, Yuetang Deng, Wei Yang, Tao Xie

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUIFormeræ¡†æž¶ä»¥ä¼˜åŒ–UIè¡¨ç¤ºï¼Œæå‡LLMä»£ç†åœ¨è‡ªåŠ¨åŒ–UIå¯¼èˆªä¸­çš„æ•ˆçŽ‡**

**å…³é”®è¯**: `UIè¡¨ç¤ºä¼˜åŒ–` `LLMä»£ç†` `ç¨‹åºåˆæˆ` `è‡ªåŠ¨åŒ–UIå¯¼èˆª` `æ•ˆçŽ‡æå‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šUIè¡¨ç¤ºæ•ˆçŽ‡ä½Žä¸‹æˆä¸ºLLMä»£ç†æ€§èƒ½ç“¶é¢ˆï¼Œç¼ºä¹å¸ƒå°”é¢„è¨€æœºé˜»ç¢è¯­ä¹‰æ­£ç¡®æ€§éªŒè¯
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽDSLé™åˆ¶ç¨‹åºç©ºé—´ï¼Œç»“åˆLLMè¿­ä»£ä¼˜åŒ–ï¼Œå®žçŽ°æ•ˆçŽ‡ä¸Žå®Œæ•´æ€§çš„ååŒä¼˜åŒ–
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Androidå’ŒWebåŸºå‡†æµ‹è¯•ä¸­å®žçŽ°48.7%è‡³55.8%çš„ä»¤ç‰Œå‡å°‘ï¼Œä¿æŒæˆ–æå‡ä»£ç†æ€§èƒ½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While Large Language Model (LLM) agents show great potential for automated UI navigation such as automated UI testing and AI assistants, their efficiency has been largely overlooked. Our motivating study reveals that inefficient UI representation creates a critical performance bottleneck. However, UI representation optimization, formulated as the task of automatically generating programs that transform UI representations, faces two unique challenges. First, the lack of Boolean oracles, which traditional program synthesis uses to decisively validate semantic correctness, poses a fundamental challenge to co-optimization of token efficiency and completeness. Second, the need to process large, complex UI trees as input while generating long, compositional transformation programs, making the search space vast and error-prone. Toward addressing the preceding limitations, we present UIFormer, the first automated optimization framework that synthesizes UI transformation programs by conducting constraint-based optimization with structured decomposition of the complex synthesis task. First, UIFormer restricts the program space using a domain-specific language (DSL) that captures UI-specific operations. Second, UIFormer conducts LLM-based iterative refinement with correctness and efficiency rewards, providing guidance for achieving the efficiency-completeness co-optimization. UIFormer operates as a lightweight plugin that applies transformation programs for seamless integration with existing LLM agents, requiring minimal modifications to their core logic. Evaluations across three UI navigation benchmarks spanning Android and Web platforms with five LLMs demonstrate that UIFormer achieves 48.7% to 55.8% token reduction with minimal runtime overhead while maintaining or improving agent performance. Real-world industry deployment at WeChat further validates the practical impact of UIFormer.

