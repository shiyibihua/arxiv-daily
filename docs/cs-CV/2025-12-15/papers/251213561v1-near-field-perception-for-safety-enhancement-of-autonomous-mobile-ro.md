---
layout: default
title: Near-Field Perception for Safety Enhancement of Autonomous Mobile Robots in Manufacturing Environments
---

# Near-Field Perception for Safety Enhancement of Autonomous Mobile Robots in Manufacturing Environments

**arXiv**: [2512.13561v1](https://arxiv.org/abs/2512.13561) | [PDF](https://arxiv.org/pdf/2512.13561.pdf)

**ä½œè€…**: Li-Wei Shih, Ruo-Syuan Mei, Jesse Heidrich, Hui-Ping Wang, Joel Hooton, Joshua Solomon, Jorge Arinez, Guangze Li, Chenhui Shao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸‰å±‚è¿‘åœºæ„ŸçŸ¥æ¡†æž¶ä»¥å¢žå¼ºåˆ¶é€ çŽ¯å¢ƒä¸­è‡ªä¸»ç§»åŠ¨æœºå™¨äººçš„å®‰å…¨æ€§**

**å…³é”®è¯**: `è¿‘åœºæ„ŸçŸ¥` `è‡ªä¸»ç§»åŠ¨æœºå™¨äºº` `åˆ¶é€ çŽ¯å¢ƒå®‰å…¨` `å…‰é—´æ–­æ£€æµ‹` `å…‰ä½ç§»æµ‹é‡` `åµŒå…¥å¼AI`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿæµ‹è·ä¼ æ„Ÿå™¨éš¾ä»¥æ£€æµ‹æœºå™¨äººåŸºåº§é™„è¿‘çš„å°ç‰©ä½“ï¼Œå½±å“AMRå®‰å…¨æ“ä½œã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å…‰é—´æ–­æ£€æµ‹ã€å…‰ä½ç§»æµ‹é‡å’ŒåŸºäºŽè®¡ç®—æœºè§†è§‰çš„å¯¹è±¡æ£€æµ‹ï¼Œå®žçŽ°å¿«é€Ÿéšœç¢æ„ŸçŸ¥ã€é«˜åº¦ä¼°è®¡å’Œè¯­ä¹‰åˆ†ç±»ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Raspberry Pi 5ä¸Šå®žæ—¶è¿è¡Œï¼Œå¸§çŽ‡è¾¾25æˆ–50fpsï¼Œå¹³è¡¡ç²¾åº¦ã€è®¡ç®—å’Œæˆæœ¬ï¼Œæå‡AMRå®‰å…¨æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Near-field perception is essential for the safe operation of autonomous mobile robots (AMRs) in manufacturing environments. Conventional ranging sensors such as light detection and ranging (LiDAR) and ultrasonic devices provide broad situational awareness but often fail to detect small objects near the robot base. To address this limitation, this paper presents a three-tier near-field perception framework. The first approach employs light-discontinuity detection, which projects a laser stripe across the near-field zone and identifies interruptions in the stripe to perform fast, binary cutoff sensing for obstacle presence. The second approach utilizes light-displacement measurement to estimate object height by analyzing the geometric displacement of a projected stripe in the camera image, which provides quantitative obstacle height information with minimal computational overhead. The third approach employs a computer vision-based object detection model on embedded AI hardware to classify objects, enabling semantic perception and context-aware safety decisions. All methods are implemented on a Raspberry Pi 5 system, achieving real-time performance at 25 or 50 frames per second. Experimental evaluation and comparative analysis demonstrate that the proposed hierarchy balances precision, computation, and cost, thereby providing a scalable perception solution for enabling safe operations of AMRs in manufacturing environments.

