---
layout: default
title: SeVeDo: A Heterogeneous Transformer Accelerator for Low-Bit Inference via Hierarchical Group Quantization and SVD-Guided Mixed Precision
---

# SeVeDo: A Heterogeneous Transformer Accelerator for Low-Bit Inference via Hierarchical Group Quantization and SVD-Guided Mixed Precision

**arXiv**: [2512.12930v1](https://arxiv.org/abs/2512.12930) | [PDF](https://arxiv.org/pdf/2512.12930.pdf)

**ä½œè€…**: Yuseon Choi, Sangjin Kim, Jungjun Oh, Byeongcheol Kim, Hoi-Jun Yoo

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSeVeDoå¼‚æž„åŠ é€Ÿå™¨ï¼Œé€šè¿‡åˆ†å±‚ç»„é‡åŒ–å’ŒSVDå¼•å¯¼æ··åˆç²¾åº¦è§£å†³ä½Žæ¯”ç‰¹æŽ¨ç†ä¸­çš„æ¿€æ´»å¼‚å¸¸å€¼é—®é¢˜**

**å…³é”®è¯**: `ä½Žæ¯”ç‰¹é‡åŒ–` `å¼‚æž„åŠ é€Ÿå™¨` `åˆ†å±‚ç»„é‡åŒ–` `SVDå¼•å¯¼æ··åˆç²¾åº¦` `èƒ½æ•ˆä¼˜åŒ–` `TransformeræŽ¨ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä½Žæ¯”ç‰¹é‡åŒ–å› æ¿€æ´»å¼‚å¸¸å€¼å¯¼è‡´ç²¾åº¦ä¸‹é™ï¼ŒçŽ°æœ‰æ–¹æ³•èƒ½è€—é«˜
2. æ–¹æ³•è¦ç‚¹ï¼šå¼‚æž„æž¶æž„åˆ†ç¦»å¼‚å¸¸å€¼æ•æ„Ÿç»„ä»¶ï¼Œç»“åˆåˆ†å±‚ç»„é‡åŒ–å’ŒSVDå¼•å¯¼æ··åˆç²¾åº¦
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ViT-Baseå’ŒLlama2-7Bä¸Šå®žçŽ°æœ€é«˜13.8TOPS/Wçš„èƒ½æ•ˆï¼Œè¶…è¶Šä¼ ç»Ÿè®¾è®¡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Low-bit quantization is a promising technique for efficient transformer inference by reducing computational and memory overhead. However, aggressive bitwidth reduction remains challenging due to activation outliers, leading to accuracy degradation. Existing methods, such as outlier-handling and group quantization, achieve high accuracy but incur substantial energy consumption. To address this, we propose SeVeDo, an energy-efficient SVD-based heterogeneous accelerator that structurally separates outlier-sensitive components into a high-precision low-rank path, while the remaining computations are executed in a low-bit residual datapath with group quantization. To further enhance efficiency, Hierarchical Group Quantization (HGQ) combines coarse-grained floating-point scaling with fine-grained shifting, effectively reducing dequantization cost. Also, SVD-guided mixed precision (SVD-MP) statically allocates higher bitwidths to precision-sensitive components identified through low-rank decomposition, thereby minimizing floating-point operation cost. Experimental results show that SeVeDo achieves a peak energy efficiency of 13.8TOPS/W, surpassing conventional designs, with 12.7TOPS/W on ViT-Base and 13.4TOPS/W on Llama2-7B benchmarks.

