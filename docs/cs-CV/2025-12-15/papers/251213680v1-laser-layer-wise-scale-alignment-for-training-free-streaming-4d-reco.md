---
layout: default
title: "LASER: Layer-wise Scale Alignment for Training-Free Streaming 4D Reconstruction"
---

# LASER: Layer-wise Scale Alignment for Training-Free Streaming 4D Reconstruction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.13680" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.13680v1</a>
  <a href="https://arxiv.org/pdf/2512.13680.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.13680v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.13680v1', 'LASER: Layer-wise Scale Alignment for Training-Free Streaming 4D Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tianye Ding, Yiming Xie, Yiqing Liang, Moitreya Chatterjee, Pedro Miraldo, Huaizu Jiang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-15

**å¤‡æ³¨**: 16 pages

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://neu-vi.github.io/LASER/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLASERä»¥è§£å†³æµåª’ä½“4Dé‡å»ºä¸­çš„è®­ç»ƒéœ€æ±‚é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æµåª’ä½“é‡å»º` `æ·±åº¦å­¦ä¹ ` `å‡ ä½•å…ˆéªŒ` `å®æ—¶è§†é¢‘å¤„ç†` `ç›¸æœºå§¿æ€ä¼°è®¡` `ç‚¹å›¾é‡å»º` `æ— è®­ç»ƒæ¡†æ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é‡å»ºæ¨¡å‹åœ¨å¤„ç†æµåª’ä½“è§†é¢‘æ—¶é¢ä¸´å†…å­˜å¤æ‚åº¦é«˜çš„é—®é¢˜ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚
2. LASERé€šè¿‡å±‚çº§å°ºåº¦å¯¹é½æŠ€æœ¯ï¼Œå°†ç¦»çº¿é‡å»ºæ¨¡å‹è½¬åŒ–ä¸ºæµåª’ä½“ç³»ç»Ÿï¼Œé¿å…äº†é‡æ–°è®­ç»ƒçš„éœ€æ±‚ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLASERåœ¨ç›¸æœºå§¿æ€ä¼°è®¡å’Œç‚¹å›¾é‡å»ºä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¸”è¿è¡Œæ•ˆç‡é«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼ŒVGGTå’Œ$Ï€^3$ç­‰å‰é¦ˆé‡å»ºæ¨¡å‹åœ¨é‡å»ºè´¨é‡ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç”±äºå…¶äºŒæ¬¡å†…å­˜å¤æ‚åº¦ï¼Œæ— æ³•å¤„ç†æµåª’ä½“è§†é¢‘ï¼Œé™åˆ¶äº†å®é™…åº”ç”¨ã€‚ç°æœ‰çš„æµåª’ä½“æ–¹æ³•é€šè¿‡å­¦ä¹ çš„è®°å¿†æœºåˆ¶æˆ–å› æœæ³¨æ„åŠ›æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½†éœ€è¦å¤§é‡çš„é‡æ–°è®­ç»ƒï¼Œå¹¶ä¸”å¯èƒ½æ— æ³•å……åˆ†åˆ©ç”¨æœ€å…ˆè¿›çš„ç¦»çº¿æ¨¡å‹çš„å‡ ä½•å…ˆéªŒã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºLASERï¼Œä¸€ä¸ªæ— è®­ç»ƒçš„æ¡†æ¶ï¼Œé€šè¿‡å¯¹è¿ç»­æ—¶é—´çª—å£çš„é¢„æµ‹è¿›è¡Œå¯¹é½ï¼Œå°†ç¦»çº¿é‡å»ºæ¨¡å‹è½¬æ¢ä¸ºæµåª’ä½“ç³»ç»Ÿã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ç®€å•çš„ç›¸ä¼¼å˜æ¢å¯¹é½ç”±äºå±‚æ·±åº¦ä¸å¯¹é½è€Œå¤±è´¥ï¼Œå› æ­¤å¼•å…¥äº†åˆ†å±‚å°ºåº¦å¯¹é½ï¼Œè®¡ç®—æ¯å±‚çš„å°ºåº¦å› å­ï¼Œå¹¶åœ¨ç›¸é‚»çª—å£å’Œæ—¶é—´æˆ³ä¹‹é—´ä¼ æ’­ã€‚å®éªŒè¡¨æ˜ï¼ŒLASERåœ¨ç›¸æœºå§¿æ€ä¼°è®¡å’Œç‚¹å›¾é‡å»ºè´¨é‡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨RTX A6000 GPUä¸Šä»¥14 FPSçš„é€Ÿåº¦è¿è¡Œï¼Œå…·å¤‡äº†å®é™…åº”ç”¨äºåƒç±³çº§æµåª’ä½“è§†é¢‘çš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰é‡å»ºæ¨¡å‹åœ¨å¤„ç†æµåª’ä½“è§†é¢‘æ—¶çš„é«˜å†…å­˜éœ€æ±‚å’Œè®­ç»ƒå¤æ‚æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€éœ€è¦å¤§é‡çš„é‡æ–°è®­ç»ƒï¼Œä¸”æœªèƒ½å……åˆ†åˆ©ç”¨ç¦»çº¿æ¨¡å‹çš„å‡ ä½•å…ˆéªŒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLASERçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å±‚çº§å°ºåº¦å¯¹é½ï¼Œå°†ç¦»çº¿é‡å»ºæ¨¡å‹è½¬æ¢ä¸ºæµåª’ä½“ç³»ç»Ÿï¼Œé¿å…äº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¤æ‚æ€§ã€‚é€šè¿‡å¯¹è¿ç»­æ—¶é—´çª—å£çš„é¢„æµ‹è¿›è¡Œå¯¹é½ï¼Œè§£å†³äº†æ·±åº¦ä¸ä¸€è‡´æ€§çš„é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLASERæ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªæ¨¡å—ï¼š1) æ·±åº¦é¢„æµ‹åˆ†å±‚ï¼Œå°†æ·±åº¦ä¿¡æ¯åˆ†ä¸ºå¤šä¸ªå±‚æ¬¡ï¼›2) è®¡ç®—æ¯å±‚çš„å°ºåº¦å› å­ï¼›3) åœ¨ç›¸é‚»æ—¶é—´çª—å£ä¹‹é—´ä¼ æ’­è¿™äº›å°ºåº¦å› å­ï¼Œä»¥å®ç°ä¸€è‡´çš„æ·±åº¦é‡å»ºã€‚

**å…³é”®åˆ›æ–°**ï¼šLASERçš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†å±‚çº§å°ºåº¦å¯¹é½æŠ€æœ¯ï¼Œè§£å†³äº†ç®€å•ç›¸ä¼¼å˜æ¢å¯¹é½å¤±è´¥çš„é—®é¢˜ã€‚è¿™ä¸€æ–¹æ³•ä¸ç°æœ‰çš„æµåª’ä½“é‡å»ºæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†æ·±åº¦é¢„æµ‹çš„ä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒLASERé‡‡ç”¨äº†åˆ†å±‚æ·±åº¦é¢„æµ‹æœºåˆ¶ï¼Œç¡®ä¿æ¯å±‚çš„å°ºåº¦å› å­èƒ½å¤Ÿå‡†ç¡®è®¡ç®—å¹¶æœ‰æ•ˆä¼ æ’­ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿåœ¨å†…å­˜ä½¿ç”¨ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä½¿å…¶åœ¨é«˜æ•ˆè¿è¡Œçš„åŒæ—¶ä¿æŒé«˜é‡å»ºè´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

LASERåœ¨ç›¸æœºå§¿æ€ä¼°è®¡å’Œç‚¹å›¾é‡å»ºæ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¿è¡Œé€Ÿåº¦ä¸º14 FPSï¼Œå†…å­˜å³°å€¼ä¸º6 GBï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„æµåª’ä½“é‡å»ºæ–¹æ³•ã€‚è¿™ä¸€æˆæœå±•ç¤ºäº†LASERåœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§å’Œé«˜æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®æ—¶è§†é¢‘ç›‘æ§ã€æ— äººé©¾é©¶æ±½è½¦çš„ç¯å¢ƒæ„ŸçŸ¥ä»¥åŠè™šæ‹Ÿç°å®ä¸­çš„åœºæ™¯é‡å»ºç­‰ã€‚LASERçš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ä½¿å…¶åœ¨å¤„ç†å¤§è§„æ¨¡æµåª’ä½“è§†é¢‘æ—¶å…·æœ‰å®é™…ä»·å€¼ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent feed-forward reconstruction models like VGGT and $Ï€^3$ achieve impressive reconstruction quality but cannot process streaming videos due to quadratic memory complexity, limiting their practical deployment. While existing streaming methods address this through learned memory mechanisms or causal attention, they require extensive retraining and may not fully leverage the strong geometric priors of state-of-the-art offline models. We propose LASER, a training-free framework that converts an offline reconstruction model into a streaming system by aligning predictions across consecutive temporal windows. We observe that simple similarity transformation ($\mathrm{Sim}(3)$) alignment fails due to layer depth misalignment: monocular scale ambiguity causes relative depth scales of different scene layers to vary inconsistently between windows. To address this, we introduce layer-wise scale alignment, which segments depth predictions into discrete layers, computes per-layer scale factors, and propagates them across both adjacent windows and timestamps. Extensive experiments show that LASER achieves state-of-the-art performance on camera pose estimation and point map reconstruction %quality with offline models while operating at 14 FPS with 6 GB peak memory on a RTX A6000 GPU, enabling practical deployment for kilometer-scale streaming videos. Project website: $\href{https://neu-vi.github.io/LASER/}{\texttt{https://neu-vi.github.io/LASER/} }$

