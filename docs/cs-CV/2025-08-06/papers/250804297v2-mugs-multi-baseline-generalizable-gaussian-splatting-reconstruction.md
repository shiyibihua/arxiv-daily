---
layout: default
title: MuGS: Multi-Baseline Generalizable Gaussian Splatting Reconstruction
---

# MuGS: Multi-Baseline Generalizable Gaussian Splatting Reconstruction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04297" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04297v2</a>
  <a href="https://arxiv.org/pdf/2508.04297.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04297v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04297v2', 'MuGS: Multi-Baseline Generalizable Gaussian Splatting Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yaopeng Lou, Liao Shen, Tianqi Liu, Jiaqi Li, Zihao Huang, Huiqiang Sun, Zhiguo Cao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06 (æ›´æ–°: 2025-10-23)

**å¤‡æ³¨**: This work is accepted by ICCV 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/EuclidLou/MuGS)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMuGSä»¥è§£å†³å¤šåŸºçº¿è§†å›¾åˆæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¤šåŸºçº¿åˆæˆ` `é«˜æ–¯è¡¨ç¤º` `æ·±åº¦èåˆ` `ç‰¹å¾å¢å¼º` `è™šæ‹Ÿç°å®` `è®¡ç®—æœºå›¾å½¢å­¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šåŸºçº¿è§†å›¾åˆæˆæ—¶ï¼Œå¾€å¾€å¯¹è¾“å…¥è§†å›¾çš„ç¨€ç–æ€§å’ŒåŸºçº¿å·®å¼‚æ•æ„Ÿï¼Œå¯¼è‡´é‡å»ºæ•ˆæœä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆå¤šè§†å›¾ç«‹ä½“å’Œå•ç›®æ·±åº¦ä¼°è®¡çš„ç‰¹å¾å¢å¼ºæ–¹æ³•ï¼Œå¹¶å¼•å…¥æŠ•å½±ä¸é‡‡æ ·æœºåˆ¶ä»¥ä¼˜åŒ–æ·±åº¦èåˆè¿‡ç¨‹ã€‚
3. MuGSåœ¨DTUã€RealEstate10Kç­‰æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä¸”åœ¨LLFFå’ŒMip-NeRF 360æ•°æ®é›†ä¸Šå®ç°äº†é›¶-shotæ€§èƒ½ï¼Œå±•ç¤ºäº†å…¶å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†å¤šåŸºçº¿é«˜æ–¯ç‚¹äº‘é‡å»ºï¼ˆMuGSï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é€šç”¨çš„å‰é¦ˆæ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†åŒ…æ‹¬ç¨€ç–è¾“å…¥è§†å›¾åœ¨å†…çš„å¤šç§åŸºçº¿è®¾ç½®ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬ç»“åˆäº†å¤šè§†å›¾ç«‹ä½“ï¼ˆMVSï¼‰å’Œå•ç›®æ·±åº¦ä¼°è®¡ï¼ˆMDEï¼‰çš„ç‰¹å¾ï¼Œä»¥å¢å¼ºå¯æ³›åŒ–é‡å»ºçš„ç‰¹å¾è¡¨ç¤ºã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æŠ•å½±ä¸é‡‡æ ·æœºåˆ¶ï¼Œç”¨äºæ·±åº¦èåˆï¼Œæ„å»ºç²¾ç»†çš„æ¦‚ç‡ä½“ç§¯ä»¥æŒ‡å¯¼ç‰¹å¾å›¾çš„å›å½’ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†å‚è€ƒè§†å›¾æŸå¤±ï¼Œä»¥æé«˜å‡ ä½•å’Œä¼˜åŒ–æ•ˆç‡ã€‚MuGSåœ¨å¤šä¸ªåŸºçº¿è®¾ç½®å’Œä»ç®€å•ç‰©ä½“åˆ°å¤æ‚å®¤å†…å¤–åœºæ™¯çš„å¤šç§åœºæ™¯ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨LLFFå’ŒMip-NeRF 360æ•°æ®é›†ä¸Šå±•ç¤ºäº†è‰¯å¥½çš„é›¶-shotæ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤šåŸºçº¿è§†å›¾åˆæˆä¸­çš„é‡å»ºè´¨é‡é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç¨€ç–è¾“å…¥è§†å›¾å’Œä¸åŒåŸºçº¿æ—¶æ•ˆæœä¸ä½³ï¼Œéš¾ä»¥å®ç°é«˜è´¨é‡çš„é‡å»ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºMuGSï¼Œé€šè¿‡ç»“åˆå¤šè§†å›¾ç«‹ä½“ï¼ˆMVSï¼‰å’Œå•ç›®æ·±åº¦ä¼°è®¡ï¼ˆMDEï¼‰æ¥å¢å¼ºç‰¹å¾è¡¨ç¤ºï¼Œå¹¶é€šè¿‡æŠ•å½±ä¸é‡‡æ ·æœºåˆ¶ä¼˜åŒ–æ·±åº¦èåˆï¼Œä»è€Œæé«˜é‡å»ºçš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMuGSçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç‰¹å¾æå–ã€æ·±åº¦èåˆå’Œé‡å»ºä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚ç‰¹å¾æå–æ¨¡å—è´Ÿè´£ä»è¾“å…¥è§†å›¾ä¸­æå–ç‰¹å¾ï¼Œæ·±åº¦èåˆæ¨¡å—é€šè¿‡æŠ•å½±ä¸é‡‡æ ·æœºåˆ¶æ„å»ºæ¦‚ç‡ä½“ç§¯ï¼Œæœ€åé‡å»ºæ¨¡å—ç”Ÿæˆæœ€ç»ˆçš„è§†å›¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†å‚è€ƒè§†å›¾æŸå¤±ï¼Œæ˜¾è‘—æé«˜äº†å‡ ä½•é‡å»ºçš„ç²¾åº¦å’Œä¼˜åŒ–æ•ˆç‡ï¼ŒåŒæ—¶åˆ©ç”¨3Dé«˜æ–¯è¡¨ç¤ºåŠ é€Ÿäº†è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šæˆ‘ä»¬è®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å‡ ä½•é‡å»ºï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸­é‡‡ç”¨äº†é«˜æ–¯è¡¨ç¤ºï¼Œä»¥æé«˜æ¸²æŸ“è´¨é‡å’Œè®­ç»ƒé€Ÿåº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MuGSåœ¨DTUå’ŒRealEstate10Kæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚åœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ã€‚æ­¤å¤–ï¼Œåœ¨LLFFå’ŒMip-NeRF 360æ•°æ®é›†ä¸Šå±•ç¤ºäº†è‰¯å¥½çš„é›¶-shotæ€§èƒ½ï¼Œè¯æ˜äº†å…¶å¹¿æ³›çš„é€‚ç”¨æ€§å’Œå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®å’Œè®¡ç®—æœºå›¾å½¢å­¦ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚MuGSèƒ½å¤Ÿåœ¨å¤šç§åœºæ™¯ä¸­å®ç°é«˜è´¨é‡çš„è§†å›¾åˆæˆï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present Multi-Baseline Gaussian Splatting (MuGS), a generalized feed-forward approach for novel view synthesis that effectively handles diverse baseline settings, including sparse input views with both small and large baselines. Specifically, we integrate features from Multi-View Stereo (MVS) and Monocular Depth Estimation (MDE) to enhance feature representations for generalizable reconstruction. Next, We propose a projection-and-sampling mechanism for deep depth fusion, which constructs a fine probability volume to guide the regression of the feature map. Furthermore, We introduce a reference-view loss to improve geometry and optimization efficiency. We leverage 3D Gaussian representations to accelerate training and inference time while enhancing rendering quality. MuGS achieves state-of-the-art performance across multiple baseline settings and diverse scenarios ranging from simple objects (DTU) to complex indoor and outdoor scenes (RealEstate10K). We also demonstrate promising zero-shot performance on the LLFF and Mip-NeRF 360 datasets. Code is available at https://github.com/EuclidLou/MuGS.

