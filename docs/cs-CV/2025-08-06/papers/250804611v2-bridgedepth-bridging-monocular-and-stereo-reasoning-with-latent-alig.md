---
layout: default
title: BridgeDepth: Bridging Monocular and Stereo Reasoning with Latent Alignment
---

# BridgeDepth: Bridging Monocular and Stereo Reasoning with Latent Alignment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04611" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04611v2</a>
  <a href="https://arxiv.org/pdf/2508.04611.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04611v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04611v2', 'BridgeDepth: Bridging Monocular and Stereo Reasoning with Latent Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tongfan Guan, Jiaxin Guo, Chen Wang, Yun-Hui Liu

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06 (æ›´æ–°: 2025-08-13)

**å¤‡æ³¨**: ICCV 2025 Highlight

**æœŸåˆŠ**: IEEE/CVF International Conference on Computer Vision (ICCV), 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/aeolusguan/BridgeDepth)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBridgeDepthä»¥è§£å†³å•ç›®ä¸ç«‹ä½“æ·±åº¦ä¼°è®¡çš„èåˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `æ·±åº¦ä¼°è®¡` `å•ç›®è§†è§‰` `ç«‹ä½“è§†è§‰` `å¤šæ¨¡æ€èåˆ` `3Dæ„ŸçŸ¥` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å•ç›®å’Œç«‹ä½“æ·±åº¦ä¼°è®¡æ–¹æ³•åœ¨å‡ ä½•ç²¾åº¦å’Œä¸Šä¸‹æ–‡ä¿¡æ¯æ•æ‰ä¸Šå„æœ‰ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆç»“åˆã€‚
2. æå‡ºäº†ä¸€ç§é€šè¿‡æ½œåœ¨è¡¨ç¤ºçš„åŒå‘å¯¹é½æœºåˆ¶ï¼ŒåŠ¨æ€åŒæ­¥å•ç›®å’Œç«‹ä½“ä¿¡æ¯çš„ç»Ÿä¸€æ¡†æ¶ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—é™ä½äº†æ³›åŒ–è¯¯å·®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å•ç›®å’Œç«‹ä½“æ·±åº¦ä¼°è®¡å„æœ‰ä¼˜ç¼ºç‚¹ï¼šå•ç›®æ–¹æ³•æ•æ‰ä¸°å¯Œçš„ä¸Šä¸‹æ–‡å…ˆéªŒï¼Œä½†ç¼ºä¹å‡ ä½•ç²¾åº¦ï¼›ç«‹ä½“æ–¹æ³•åˆ©ç”¨æå‡ ä½•ï¼Œä½†åœ¨åå°„æˆ–æ— çº¹ç†è¡¨é¢ç­‰æ¨¡ç³Šæƒ…å†µä¸‹è¡¨ç°ä¸ä½³ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡å¯¹å…¶æ½œåœ¨è¡¨ç¤ºçš„åŒå‘å¯¹é½ï¼Œè¿æ¥è¿™ä¸¤ç§æ–¹æ³•ã€‚æ ¸å¿ƒæ˜¯ä¸€ä¸ªæ–°é¢–çš„äº¤å‰æ³¨æ„åŠ›å¯¹é½æœºåˆ¶ï¼Œåœ¨ç«‹ä½“æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€åŒæ­¥å•ç›®ä¸Šä¸‹æ–‡çº¿ç´¢ä¸ç«‹ä½“å‡è®¾è¡¨ç¤ºã€‚è¿™ç§ç›¸äº’å¯¹é½é€šè¿‡æ³¨å…¥å•ç›®ç»“æ„å…ˆéªŒæ¥è§£å†³ç«‹ä½“æ¨¡ç³Šï¼ŒåŒæ—¶åœ¨å•ä¸€ç½‘ç»œä¸­åˆ©ç”¨ç«‹ä½“å‡ ä½•æ¥ä¼˜åŒ–å•ç›®æ·±åº¦ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨Middleburyå’ŒETH3Dä¸Šå°†é›¶-shotæ³›åŒ–è¯¯å·®é™ä½äº†è¶…è¿‡40%ï¼Œå¹¶è§£å†³äº†é€æ˜å’Œåå°„è¡¨é¢ä¸Šçš„é•¿æœŸå¤±è´¥é—®é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å•ç›®å’Œç«‹ä½“æ·±åº¦ä¼°è®¡æ–¹æ³•ä¹‹é—´çš„èåˆé—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†åå°„å’Œæ— çº¹ç†è¡¨é¢æ—¶å­˜åœ¨æ˜¾è‘—çš„å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥äº¤å‰æ³¨æ„åŠ›å¯¹é½æœºåˆ¶ï¼ŒåŠ¨æ€åŒæ­¥å•ç›®ä¸Šä¸‹æ–‡ä¿¡æ¯ä¸ç«‹ä½“å‡è®¾ï¼Œä»è€Œå®ç°ä¸¤è€…çš„äº’è¡¥ï¼Œå¢å¼ºæ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ½œåœ¨è¡¨ç¤ºçš„åŒå‘å¯¹é½æ¨¡å—ï¼Œå•ç›®ä¸Šä¸‹æ–‡æå–æ¨¡å—å’Œç«‹ä½“å‡ ä½•ä¼˜åŒ–æ¨¡å—ï¼Œå½¢æˆä¸€ä¸ªç«¯åˆ°ç«¯çš„æ·±åº¦ä¼°è®¡ç½‘ç»œã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºäº¤å‰æ³¨æ„åŠ›å¯¹é½æœºåˆ¶ï¼Œå®ƒæœ‰æ•ˆè§£å†³äº†ç«‹ä½“æ·±åº¦ä¼°è®¡ä¸­çš„æ¨¡ç³Šæ€§é—®é¢˜ï¼Œå¹¶é€šè¿‡å•ç›®å…ˆéªŒå¢å¼ºäº†æ·±åº¦ä¼°è®¡çš„ç²¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œè®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡å•ç›®å’Œç«‹ä½“ä¿¡æ¯çš„è´¡çŒ®ï¼Œå¹¶é€šè¿‡å¤šå±‚æ¬¡çš„ç‰¹å¾æå–æ¥å¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒBridgeDepthåœ¨Middleburyå’ŒETH3Dæ•°æ®é›†ä¸Šå°†é›¶-shotæ³›åŒ–è¯¯å·®é™ä½äº†è¶…è¿‡40%ï¼Œå¹¶æœ‰æ•ˆè§£å†³äº†é€æ˜å’Œåå°„è¡¨é¢ä¸Šçš„é•¿æœŸé—®é¢˜ï¼Œå±•ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œå¢å¼ºç°å®ç­‰ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡3Dæ„ŸçŸ¥çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æ·±åº¦ä¼°è®¡ä»»åŠ¡ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Monocular and stereo depth estimation offer complementary strengths: monocular methods capture rich contextual priors but lack geometric precision, while stereo approaches leverage epipolar geometry yet struggle with ambiguities such as reflective or textureless surfaces. Despite post-hoc synergies, these paradigms remain largely disjoint in practice. We introduce a unified framework that bridges both through iterative bidirectional alignment of their latent representations. At its core, a novel cross-attentive alignment mechanism dynamically synchronizes monocular contextual cues with stereo hypothesis representations during stereo reasoning. This mutual alignment resolves stereo ambiguities (e.g., specular surfaces) by injecting monocular structure priors while refining monocular depth with stereo geometry within a single network. Extensive experiments demonstrate state-of-the-art results: \textbf{it reduces zero-shot generalization error by $\!>\!40\%$ on Middlebury and ETH3D}, while addressing longstanding failures on transparent and reflective surfaces. By harmonizing multi-view geometry with monocular context, our approach enables robust 3D perception that transcends modality-specific limitations. Codes available at https://github.com/aeolusguan/BridgeDepth.

