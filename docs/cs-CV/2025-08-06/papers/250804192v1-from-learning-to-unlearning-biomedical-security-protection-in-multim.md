---
layout: default
title: From Learning to Unlearning: Biomedical Security Protection in Multimodal Large Language Models
---

# From Learning to Unlearning: Biomedical Security Protection in Multimodal Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04192" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.04192v1</a>
  <a href="https://arxiv.org/pdf/2508.04192.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04192v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04192v1', 'From Learning to Unlearning: Biomedical Security Protection in Multimodal Large Language Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Dunyuan Xu, Xikai Yang, Yaoqian Li, Jinpeng Li, Pheng-Ann Heng

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-06

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MLLMU-Med‰ª•Ëß£ÂÜ≥ÁîüÁâ©ÂåªÂ≠¶Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÆâÂÖ®ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÁîüÁâ©ÂåªÂ≠¶` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `Êú∫Âô®ÈÅóÂøò` `ÈöêÁßÅ‰øùÊä§` `ÈîôËØØÁü•ËØÜÂéªÈô§` `Êï∞ÊçÆÁîüÊàê` `ÈÅóÂøòÊïàÁéáËØÑÂàÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁîüÁâ©ÂåªÂ≠¶Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®ËÆ≠ÁªÉ‰∏≠ÂÆπÊòìÂåÖÂê´ÁßÅ‰∫∫‰ø°ÊÅØÂíåÈîôËØØÁü•ËØÜÔºåÂØºËá¥ÈöêÁßÅÊ≥ÑÈú≤ÂíåÈîôËØØËæìÂá∫„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫ÜMLLMU-MedÂü∫ÂáÜÊï∞ÊçÆÈõÜÔºåÈÄöËøáÂêàÊàêÁßÅ‰∫∫Êï∞ÊçÆÂíå‰∫ãÂÆûÈîôËØØÁîüÊàêËÆ≠ÁªÉÈõÜÔºåËØÑ‰º∞Ê®°ÂûãÁöÑÈÅóÂøòËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫Ôºå‰∫îÁßçÈÅóÂøòÊñπÊ≥ïÂú®ÂéªÈô§ÊúâÂÆ≥Áü•ËØÜÊñπÈù¢ÊïàÊûúÊúâÈôêÔºåË°®ÊòéËØ•È¢ÜÂüüÁöÑÁ†îÁ©∂‰ªçÈúÄÊ∑±ÂÖ•Êé¢Á¥¢„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÁîüÁâ©ÂåªÂ≠¶Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÁöÑÂÆâÂÖ®ÊÄßÊó•ÁõäÂèóÂà∞ÂÖ≥Ê≥®„ÄÇÁÑ∂ËÄåÔºåËÆ≠ÁªÉÊ†∑Êú¨‰∏≠ÂèØËÉΩÂåÖÂê´Èöæ‰ª•Ê£ÄÊµãÁöÑÁßÅ‰∫∫‰ø°ÊÅØÂíåÈîôËØØÁü•ËØÜÔºåÂØºËá¥ÈöêÁßÅÊ≥ÑÈú≤ÊàñÈÉ®ÁΩ≤Âêé‰∫ßÁîüÈîôËØØËæìÂá∫„ÄÇ‰º†ÁªüÁöÑËß£ÂÜ≥ÊñπÊ°àÊòØÈáçÊñ∞Â§ÑÁêÜËÆ≠ÁªÉÈõÜÂπ∂‰ªéÂ§¥ÂºÄÂßãÈáçÊñ∞ËÆ≠ÁªÉÊ®°ÂûãÔºå‰ΩÜËøôÂú®ËÆ°ÁÆó‰∏ä‰∏çÂèØË°å„ÄÇÊú∫Âô®ÈÅóÂøò‰Ωú‰∏∫‰∏ÄÁßçÊñ∞ÂÖ¥Ëß£ÂÜ≥ÊñπÊ°àÔºåÂèØ‰ª•ÈÄâÊã©ÊÄßÂú∞ÁßªÈô§ÊúâÂÆ≥Ê†∑Êú¨‰∏≠ÁöÑ‰∏çÂøÖË¶ÅÁü•ËØÜÔºåÂêåÊó∂‰øùÁïôÊ≠£Â∏∏Ê°à‰æãÁöÑËÉΩÂäõ„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜÁ¨¨‰∏Ä‰∏™Âü∫ÂáÜÊï∞ÊçÆÈõÜMLLMU-MedÔºåÊó®Âú®ËØÑ‰º∞ÁîüÁâ©ÂåªÂ≠¶MLLMsÁöÑÈÅóÂøòË¥®ÈáèÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÈÅóÂøòÊïàÁéáËØÑÂàÜÔºåÂèçÊò†‰∏çÂêåÂ≠êÈõÜÁöÑÊï¥‰ΩìÈÅóÂøòÊÄßËÉΩ„ÄÇÂÆûÈ™åË°®ÊòéÔºåÁé∞ÊúâÁöÑ‰∫îÁßçÈÅóÂøòÊñπÊ≥ïÂú®ÂéªÈô§ÊúâÂÆ≥Áü•ËØÜÊñπÈù¢ÊïàÊûúÊúâÈôêÔºåË°®ÊòéËØ•È¢ÜÂüü‰ªçÊúâÂæàÂ§ßÁöÑÊîπËøõÁ©∫Èó¥„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÁîüÁâ©ÂåªÂ≠¶Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã‰∏≠ÁßÅ‰∫∫‰ø°ÊÅØÂíåÈîôËØØÁü•ËØÜÁöÑÈÅóÂøòÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®ÂéªÈô§Ëøô‰∫õ‰∏çÂøÖË¶ÅÁü•ËØÜÊó∂ÔºåÂæÄÂæÄÈúÄË¶ÅÂÆåÂÖ®ÈáçÊñ∞ËÆ≠ÁªÉÊ®°ÂûãÔºåËÆ°ÁÆóÊàêÊú¨È´òÊòÇ‰∏î‰∏çÂàáÂÆûÈôÖ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Êú∫Âô®ÈÅóÂøòÊäÄÊúØÔºåÈÄâÊã©ÊÄßÂú∞ÁßªÈô§ÊúâÂÆ≥Ê†∑Êú¨‰∏≠ÁöÑÁü•ËØÜÔºåËÄå‰∏çÈúÄË¶Å‰ªéÂ§¥ÂºÄÂßãÈáçÊñ∞ËÆ≠ÁªÉÊ®°Âûã„ÄÇÈÄöËøáÊûÑÂª∫MLLMU-MedÂü∫ÂáÜÊï∞ÊçÆÈõÜÔºåËØÑ‰º∞Ê®°ÂûãÂú®ÈöêÁßÅ‰øùÊä§ÂíåÈîôËØØÁü•ËØÜÂéªÈô§ÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÁîüÊàêÁÆ°ÈÅì„ÄÅÊ®°ÂûãËÆ≠ÁªÉÂíåËØÑ‰º∞Ê®°Âùó„ÄÇÊï∞ÊçÆÁîüÊàêÁÆ°ÈÅìË¥üË¥£ÂêàÊàêÁßÅ‰∫∫Êï∞ÊçÆÂíåÈîôËØØÁü•ËØÜÔºåËÆ≠ÁªÉÊ®°Âùó‰ΩøÁî®Ëøô‰∫õÊï∞ÊçÆËÆ≠ÁªÉÊ®°ÂûãÔºåËØÑ‰º∞Ê®°ÂùóÂàôÈÄöËøáÈÅóÂøòÊïàÁéáËØÑÂàÜÊù•Ë°°ÈáèÊ®°ÂûãÁöÑÈÅóÂøòÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜMLLMU-MedÂü∫ÂáÜÊï∞ÊçÆÈõÜÂíåÈÅóÂøòÊïàÁéáËØÑÂàÜÔºåËøô‰∏∫ÁîüÁâ©ÂåªÂ≠¶MLLMsÁöÑÂÆâÂÖ®ÊÄßËØÑ‰º∞Êèê‰æõ‰∫ÜÊñ∞ÁöÑÂ∑•ÂÖ∑ÂíåÊñπÊ≥ïÔºåÂ°´Ë°•‰∫ÜÁé∞ÊúâÁ†îÁ©∂ÁöÑÁ©∫ÁôΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Êï∞ÊçÆÁîüÊàêËøáÁ®ã‰∏≠ÔºåÈááÁî®‰∫ÜÂêàÊàêÊäÄÊúØÁîüÊàêÁßÅ‰∫∫‰ø°ÊÅØÂíåÈîôËØØÁü•ËØÜÔºåÁ°Æ‰øùËÆ≠ÁªÉÈõÜÁöÑÂ§öÊ†∑ÊÄßÂíåÂ§çÊùÇÊÄß„ÄÇÈÅóÂøòÊïàÁéáËØÑÂàÜÁöÑËÆæËÆ°ËÄÉËôë‰∫Ü‰∏çÂêåÂ≠êÈõÜÁöÑË°®Áé∞ÔºåËÉΩÂ§üÂÖ®Èù¢ÂèçÊò†Ê®°ÂûãÁöÑÈÅóÂøòËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰∫îÁßç‰∏çÂêåÁöÑÈÅóÂøòÊñπÊ≥ïÂú®ÂéªÈô§ÁîüÁâ©ÂåªÂ≠¶Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã‰∏≠ÁöÑÊúâÂÆ≥Áü•ËØÜÊó∂ÊïàÊûúÊúâÈôêÔºåÊòæÁ§∫Âá∫‰ªÖÊúâÂ∞èÂπÖÂ∫¶ÁöÑÊÄßËÉΩÊèêÂçá„ÄÇËøô‰∏ÄÂèëÁé∞Âº∫Ë∞É‰∫ÜËØ•È¢ÜÂüüÂú®Ê®°ÂûãÂÆâÂÖ®ÊÄßÂíåÈöêÁßÅ‰øùÊä§ÊñπÈù¢ÁöÑÁ†îÁ©∂‰ªçÈúÄËøõ‰∏ÄÊ≠•Ê∑±ÂÖ•„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÂåªÁñóÂÅ•Â∫∑„ÄÅ‰∏¥Â∫äÂÜ≥Á≠ñÊîØÊåÅÂíåÁîüÁâ©ÂåªÂ≠¶Á†îÁ©∂Á≠â„ÄÇÈÄöËøáÊèêÈ´òÁîüÁâ©ÂåªÂ≠¶Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÆâÂÖ®ÊÄßÔºåËÉΩÂ§üÊõ¥Â•ΩÂú∞‰øùÊä§ÊÇ£ËÄÖÈöêÁßÅÔºåÂáèÂ∞ëÈîôËØØ‰ø°ÊÅØÁöÑ‰º†Êí≠Ôºå‰ªéËÄåÊèêÂçáÂåªÁñóÊúçÂä°ÁöÑË¥®ÈáèÂíåÂÆâÂÖ®ÊÄß„ÄÇÊú™Êù•ÔºåËØ•Á†îÁ©∂ÂèØËÉΩÊé®Âä®Áõ∏ÂÖ≥È¢ÜÂüüÂú®Êï∞ÊçÆÈöêÁßÅÂíåÊ®°ÂûãÂÆâÂÖ®ÊÄßÊñπÈù¢ÁöÑËøõ‰∏ÄÊ≠•Êé¢Á¥¢‰∏éÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The security of biomedical Multimodal Large Language Models (MLLMs) has attracted increasing attention. However, training samples easily contain private information and incorrect knowledge that are difficult to detect, potentially leading to privacy leakage or erroneous outputs after deployment. An intuitive idea is to reprocess the training set to remove unwanted content and retrain the model from scratch. Yet, this is impractical due to significant computational costs, especially for large language models. Machine unlearning has emerged as a solution to this problem, which avoids complete retraining by selectively removing undesired knowledge derived from harmful samples while preserving required capabilities on normal cases. However, there exist no available datasets to evaluate the unlearning quality for security protection in biomedical MLLMs. To bridge this gap, we propose the first benchmark Multimodal Large Language Model Unlearning for BioMedicine (MLLMU-Med) built upon our novel data generation pipeline that effectively integrates synthetic private data and factual errors into the training set. Our benchmark targets two key scenarios: 1) Privacy protection, where patient private information is mistakenly included in the training set, causing models to unintentionally respond with private data during inference; and 2) Incorrectness removal, where wrong knowledge derived from unreliable sources is embedded into the dataset, leading to unsafe model responses. Moreover, we propose a novel Unlearning Efficiency Score that directly reflects the overall unlearning performance across different subsets. We evaluate five unlearning approaches on MLLMU-Med and find that these methods show limited effectiveness in removing harmful knowledge from biomedical MLLMs, indicating significant room for improvement. This work establishes a new pathway for further research in this promising field.

