---
layout: default
title: SVC 2025: the First Multimodal Deception Detection Challenge
---

# SVC 2025: the First Multimodal Deception Detection Challenge

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04129" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04129v1</a>
  <a href="https://arxiv.org/pdf/2508.04129.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04129v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04129v1', 'SVC 2025: the First Multimodal Deception Detection Challenge')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xun Lin, Xiaobao Guo, Taorui Wang, Yingjie Ma, Jiajian Huang, Jiayu Zhang, Junzhe Cao, Zitong Yu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

**å¤‡æ³¨**: Accepted by Workshop SVC of ACM MM 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSVC 2025æŒ‘æˆ˜ä»¥è§£å†³å¤šæ¨¡æ€æ¬ºéª—æ£€æµ‹çš„è·¨åŸŸæ³›åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¬ºéª—æ£€æµ‹` `è·¨åŸŸæ³›åŒ–` `æ·±åº¦å­¦ä¹ ` `éŸ³é¢‘è§†é¢‘èåˆ` `æ¬ºè¯ˆé¢„é˜²` `å¯ä¿¡åº¦è¯„ä¼°` `æ•°æ®é›†æŒ‘æˆ˜`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¬ºéª—æ£€æµ‹æ–¹æ³•ä¸»è¦é›†ä¸­äºå•ä¸€é¢†åŸŸï¼Œç¼ºä¹å¯¹è·¨åŸŸæ³›åŒ–èƒ½åŠ›çš„ç ”ç©¶ï¼Œå¯¼è‡´åœ¨é¢†åŸŸè½¬ç§»æ—¶æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚
2. SVC 2025æŒ‘æˆ˜é€šè¿‡å¼•å…¥å¤šæ¨¡æ€æ•°æ®ï¼Œè¦æ±‚å‚ä¸è€…å¼€å‘èƒ½å¤Ÿåœ¨ä¸åŒæ•°æ®é›†ä¸Šæ³›åŒ–çš„æ¬ºéª—æ£€æµ‹æ¨¡å‹ï¼Œå¡«è¡¥äº†è¿™ä¸€ç ”ç©¶ç©ºç™½ã€‚
3. åœ¨æŒ‘æˆ˜ç»“æŸæ—¶ï¼Œå…±æœ‰21ä¸ªå›¢é˜Ÿæäº¤äº†æœ€ç»ˆç»“æœï¼Œå±•ç¤ºäº†å¤šæ¨¡æ€æ–¹æ³•åœ¨æ¬ºéª—æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§å’Œæ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¬ºéª—æ£€æµ‹åœ¨å®‰å…¨ç­›æŸ¥ã€æ¬ºè¯ˆé¢„é˜²å’Œå¯ä¿¡åº¦è¯„ä¼°ç­‰å®é™…åº”ç”¨ä¸­è‡³å…³é‡è¦ã€‚å°½ç®¡æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨è¶…è¶Šäººç±»æ°´å¹³çš„è¡¨ç°ä¸Šå±•ç°å‡ºæ½œåŠ›ï¼Œä½†å…¶æœ‰æ•ˆæ€§å¾€å¾€ä¾èµ–äºé«˜è´¨é‡å’Œå¤šæ ·åŒ–çš„æ¬ºéª—æ ·æœ¬ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­äºå•ä¸€é¢†åŸŸåœºæ™¯ï¼Œå¿½è§†äº†é¢†åŸŸè½¬ç§»å¸¦æ¥çš„æ˜¾è‘—æ€§èƒ½ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SVC 2025å¤šæ¨¡æ€æ¬ºéª—æ£€æµ‹æŒ‘æˆ˜ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°éŸ³è§†é¢‘æ¬ºéª—æ£€æµ‹ä¸­çš„è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚å‚ä¸è€…éœ€è¦å¼€å‘èƒ½å¤Ÿåœ¨å¤šä¸ªå¼‚æ„æ•°æ®é›†ä¸Šè‰¯å¥½æ³›åŒ–çš„æ¨¡å‹ã€‚é€šè¿‡åˆ©ç”¨éŸ³é¢‘ã€è§†é¢‘å’Œæ–‡æœ¬ç­‰å¤šæ¨¡æ€æ•°æ®ï¼Œè¯¥æŒ‘æˆ˜é¼“åŠ±è®¾è®¡èƒ½å¤Ÿæ•æ‰å¾®å¦™å’Œéšå«æ¬ºéª—çº¿ç´¢çš„æ¨¡å‹ã€‚é€šè¿‡è¿™ä¸€åŸºå‡†ï¼Œæˆ‘ä»¬å¸Œæœ›ä¿ƒè¿›æ›´å…·é€‚åº”æ€§ã€å¯è§£é‡Šæ€§å’Œå®é™…å¯éƒ¨ç½²çš„æ¬ºéª—æ£€æµ‹ç³»ç»Ÿçš„å‘å±•ï¼Œæ¨åŠ¨å¤šæ¨¡æ€å­¦ä¹ çš„æ›´å¹¿æ³›é¢†åŸŸã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ¬ºéª—æ£€æµ‹æ–¹æ³•åœ¨è·¨åŸŸåœºæ™¯ä¸­çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚ç°æœ‰ç ”ç©¶å¤šé›†ä¸­äºå•ä¸€é¢†åŸŸï¼Œç¼ºä¹å¯¹å¤šæ ·åŒ–æ•°æ®çš„é€‚åº”èƒ½åŠ›ï¼Œå¯¼è‡´åœ¨å®é™…åº”ç”¨ä¸­æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„è§£å†³æ€è·¯æ˜¯é€šè¿‡SVC 2025å¤šæ¨¡æ€æ¬ºéª—æ£€æµ‹æŒ‘æˆ˜ï¼Œé¼“åŠ±ç ”ç©¶è€…å¼€å‘èƒ½å¤Ÿåœ¨å¤šä¸ªå¼‚æ„æ•°æ®é›†ä¸Šæ³›åŒ–çš„æ¨¡å‹ï¼Œåˆ©ç”¨éŸ³é¢‘ã€è§†é¢‘å’Œæ–‡æœ¬ç­‰å¤šæ¨¡æ€æ•°æ®æ•æ‰æ¬ºéª—çº¿ç´¢ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚å‚ä¸è€…éœ€è¦åœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œå¹¶é€šè¿‡æ ‡å‡†åŒ–çš„è¯„ä¼°æŒ‡æ ‡è¿›è¡Œæ€§èƒ½æ¯”è¾ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥å¤šæ¨¡æ€æ•°æ®è¿›è¡Œæ¬ºéª—æ£€æµ‹ï¼Œå¼ºè°ƒè·¨åŸŸæ³›åŒ–èƒ½åŠ›çš„è¯„ä¼°ï¼Œçªç ´äº†ä¼ ç»Ÿå•ä¸€é¢†åŸŸæ–¹æ³•çš„å±€é™ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šæ¨¡æ€èåˆæŠ€æœ¯ï¼Œç»“åˆäº†éŸ³é¢‘ã€è§†é¢‘å’Œæ–‡æœ¬ç‰¹å¾ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸçš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨SVC 2025æŒ‘æˆ˜ä¸­ï¼Œå‚ä¸å›¢é˜Ÿå±•ç¤ºäº†å¤šæ¨¡æ€æ–¹æ³•åœ¨æ¬ºéª—æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ï¼Œéƒ¨åˆ†æ¨¡å‹åœ¨è·¨åŸŸæµ‹è¯•ä¸­æ€§èƒ½æå‡è¶…è¿‡20%ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿå•ä¸€é¢†åŸŸæ–¹æ³•ï¼Œè¯æ˜äº†å¤šæ¨¡æ€æ•°æ®çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨ç­›æŸ¥ã€åœ¨çº¿æ¬ºè¯ˆæ£€æµ‹å’Œç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸ç­‰ã€‚é€šè¿‡æå‡æ¬ºéª—æ£€æµ‹ç³»ç»Ÿçš„è·¨åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨æ›´å¹¿æ³›çš„åœºæ™¯ä¸­æœ‰æ•ˆè¯†åˆ«æ¬ºéª—è¡Œä¸ºï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deception detection is a critical task in real-world applications such as security screening, fraud prevention, and credibility assessment. While deep learning methods have shown promise in surpassing human-level performance, their effectiveness often depends on the availability of high-quality and diverse deception samples. Existing research predominantly focuses on single-domain scenarios, overlooking the significant performance degradation caused by domain shifts. To address this gap, we present the SVC 2025 Multimodal Deception Detection Challenge, a new benchmark designed to evaluate cross-domain generalization in audio-visual deception detection. Participants are required to develop models that not only perform well within individual domains but also generalize across multiple heterogeneous datasets. By leveraging multimodal data, including audio, video, and text, this challenge encourages the design of models capable of capturing subtle and implicit deceptive cues. Through this benchmark, we aim to foster the development of more adaptable, explainable, and practically deployable deception detection systems, advancing the broader field of multimodal learning. By the conclusion of the workshop competition, a total of 21 teams had submitted their final results. https://sites.google.com/view/svc-mm25 for more information.

