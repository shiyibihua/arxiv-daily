---
layout: default
title: Thinking With Videos: Multimodal Tool-Augmented Reinforcement Learning for Long Video Reasoning
---

# Thinking With Videos: Multimodal Tool-Augmented Reinforcement Learning for Long Video Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04416" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.04416v2</a>
  <a href="https://arxiv.org/pdf/2508.04416.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04416v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04416v2', 'Thinking With Videos: Multimodal Tool-Augmented Reinforcement Learning for Long Video Reasoning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Haoji Zhang, Xin Gu, Jiawen Li, Chixiang Ma, Sule Bai, Chubin Zhang, Bowen Zhang, Zhichao Zhou, Dongliang He, Yansong Tang

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-06 (Êõ¥Êñ∞: 2025-09-03)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://zhang9302002.github.io/thinkingwithvideos-page/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫VITALÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥ÈïøËßÜÈ¢ëÊé®ÁêÜ‰∏≠ÁöÑÂ§öÊ®°ÊÄÅ‰∫§‰∫í‰∏çË∂≥ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÈïøËßÜÈ¢ëÁêÜËß£` `Â§öÊ®°ÊÄÅÊé®ÁêÜ` `Âº∫ÂåñÂ≠¶‰π†` `ËßÜÈ¢ëÈóÆÁ≠î` `Êó∂Èó¥ÂÆö‰Ωç` `ËßÜËßâÂ∑•ÂÖ∑ÁÆ±` `ÈìæÂºèÊé®ÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ÈïøËßÜÈ¢ëÊé®ÁêÜ‰∏≠Èù¢‰∏¥Ë∑®Ê®°ÊÄÅ‰∫§‰∫í‰∏çË∂≥ÂíåÂπªËßâÁé∞Ë±°Â¢ûÂä†ÁöÑÊåëÊàòÔºåÂΩ±Âìç‰∫ÜÊé®ÁêÜÁöÑÂáÜÁ°ÆÊÄß„ÄÇ
2. Êú¨ÊñáÊèêÂá∫VITALÊ°ÜÊû∂ÔºåÈÄöËøáËßÜËßâÂ∑•ÂÖ∑ÁÆ±ÂÆûÁé∞ÊåâÈúÄËßÜÈ¢ëÂ∏ßÈááÊ†∑ÂíåÂ§öÊ®°ÊÄÅÈìæÂºèÊé®ÁêÜÔºåÊèêÂçáÈïøËßÜÈ¢ëÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. Âú®11‰∏™ËßÜÈ¢ëÁêÜËß£Âü∫ÂáÜ‰∏äËøõË°åÁöÑÂÆûÈ™åË°®ÊòéÔºåVITALÂú®ËßÜÈ¢ëÈóÆÁ≠îÂíåÊó∂Èó¥ÂÆö‰Ωç‰ªªÂä°‰∏≠Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÁâπÂà´ÊòØÂú®ÈïøËßÜÈ¢ëÂú∫ÊôØ‰∏≠„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÂú®ËßÜÈ¢ëÊé®ÁêÜËÉΩÂäõ‰∏äËá≥ÂÖ≥ÈáçË¶ÅÔºåÂ∞§ÂÖ∂ÊòØÂú®ËßÜÈ¢ëÈóÆÁ≠îÂíåÊó∂Èó¥ÂÆö‰ΩçÁ≠â‰∏ãÊ∏∏‰ªªÂä°‰∏≠„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®ÊñáÊú¨ÈìæÂºèÊé®ÁêÜÊñπÈù¢Â≠òÂú®Ë∑®Ê®°ÊÄÅ‰∫§‰∫íÊúâÈôêÂíåÂπªËßâÁé∞Ë±°Â¢ûÂä†ÁöÑÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜËæÉÈïøËßÜÈ¢ëÊàñÊé®ÁêÜÈìæÊó∂„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÊåëÊàòÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÁ´ØÂà∞Á´ØËßÜÈ¢ëÊé®ÁêÜÊ°ÜÊû∂VITALÔºåÈÄöËøáËßÜËßâÂ∑•ÂÖ∑ÁÆ±ÔºåÊ®°ÂûãËÉΩÂ§üÊåâÈúÄÂØÜÈõÜÈááÊ†∑Êñ∞ÁöÑËßÜÈ¢ëÂ∏ßÔºåÂπ∂ÁîüÊàêÂ§öÊ®°ÊÄÅÈìæÂºèÊé®ÁêÜ‰ª•ÂÆûÁé∞Á≤æÁ°ÆÁöÑÈïøËßÜÈ¢ëÊé®ÁêÜ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊó∂Èó¥ÂÆö‰ΩçÂíåÈóÆÁ≠î‰ªªÂä°ÂØπËßÜÈ¢ëÁêÜËß£ÊòØ‰∫íÂà©ÁöÑÔºåVITALÂú®Â§ö‰∏™ËßÜÈ¢ëÁêÜËß£Âü∫ÂáÜ‰∏äË°®Áé∞‰ºòÂºÇÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈïøËßÜÈ¢ëÂú∫ÊôØ‰∏≠„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÈïøËßÜÈ¢ëÊé®ÁêÜ‰∏≠ÁöÑÂ§öÊ®°ÊÄÅ‰∫§‰∫í‰∏çË∂≥ÂíåÂπªËßâÁé∞Ë±°ÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§çÊùÇËßÜÈ¢ëÊó∂Â∏∏Â∏∏Êó†Ê≥ïÊúâÊïàÊï¥Âêà‰ø°ÊÅØÔºåÂØºËá¥Êé®ÁêÜÁªìÊûú‰∏çÂáÜÁ°Æ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVITALÊ°ÜÊû∂ÈÄöËøáÂºïÂÖ•ËßÜËßâÂ∑•ÂÖ∑ÁÆ±ÔºåÂÖÅËÆ∏Ê®°ÂûãÊåâÈúÄÈááÊ†∑ËßÜÈ¢ëÂ∏ßÔºåÂπ∂ÁîüÊàêÂ§öÊ®°ÊÄÅÈìæÂºèÊé®ÁêÜÔºå‰ªéËÄåÂ¢ûÂº∫Ê®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÂíåÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨ËßÜÈ¢ëÂ∏ßÈááÊ†∑Ê®°Âùó„ÄÅÈìæÂºèÊé®ÁêÜÁîüÊàêÊ®°ÂùóÂíåÂ§ö‰ªªÂä°Â≠¶‰π†Ê®°ÂùóÔºåÊîØÊåÅËßÜÈ¢ëÈóÆÁ≠îÂíåÊó∂Èó¥ÂÆö‰Ωç‰ªªÂä°ÁöÑËÅîÂêàËÆ≠ÁªÉ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVITALÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÂºïÂÖ•ËßÜËßâÂ∑•ÂÖ∑ÁÆ±ÂíåÂ§öÊ®°ÊÄÅÈìæÂºèÊé®ÁêÜÔºåÊòæËëóÊèêÂçá‰∫ÜÊ®°ÂûãÂú®ÈïøËßÜÈ¢ëÊé®ÁêÜ‰∏≠ÁöÑË°®Áé∞Ôºå‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåÂ¢ûÂº∫‰∫ÜË∑®Ê®°ÊÄÅ‰ø°ÊÅØÁöÑÊï¥ÂêàËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÂõ∞ÈöæÊÑüÁü•ÁöÑÁõ∏ÂØπÁ≠ñÁï•‰ºòÂåñÁÆóÊ≥ïÔºàDGRPOÔºâÊù•Âπ≥Ë°°Â§ö‰ªªÂä°Âº∫ÂåñÂ≠¶‰π†‰∏≠ÁöÑÂõ∞ÈöæÁ®ãÂ∫¶ÔºåÁ°Æ‰øùÊ®°ÂûãÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ËÉΩÂ§üÊúâÊïàÂ∫îÂØπ‰∏çÂêå‰ªªÂä°ÁöÑÊåëÊàò„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑËÆæËÆ°‰πüÁªèËøáÁ≤æÂøÉË∞ÉÊï¥Ôºå‰ª•‰ºòÂåñÊé®ÁêÜÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®11‰∏™ËßÜÈ¢ëÁêÜËß£Âü∫ÂáÜ‰∏äÔºåVITALÊ°ÜÊû∂Âú®ËßÜÈ¢ëÈóÆÁ≠îÂíåÊó∂Èó¥ÂÆö‰Ωç‰ªªÂä°‰∏≠ÂùáË°®Áé∞Âá∫Ëâ≤ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈïøËßÜÈ¢ëÂú∫ÊôØ‰∏≠ÔºåÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÊèêÂçáÂπÖÂ∫¶ËææÂà∞20%‰ª•‰∏äÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂ÂÖàËøõÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ËßÜÈ¢ëÈóÆÁ≠îÁ≥ªÁªü„ÄÅËßÜÈ¢ëÁõëÊéßÂàÜÊûêÂíåËá™Âä®ËßÜÈ¢ëÊëòË¶ÅÁîüÊàêÁ≠â„ÄÇÈÄöËøáÊèêÂçáÈïøËßÜÈ¢ëÊé®ÁêÜËÉΩÂäõÔºåVITALÊ°ÜÊû∂ËÉΩÂ§üÂú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠Êèê‰æõÊõ¥ÂáÜÁ°ÆÁöÑÁêÜËß£ÂíåÂàÜÊûêÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The video reasoning ability of multimodal large language models (MLLMs) is crucial for downstream tasks like video question answering and temporal grounding. While recent approaches have explored text-based chain-of-thought (CoT) reasoning for MLLMs, these methods often suffer from limited cross-modal interaction and increased hallucination, especially with longer videos or reasoning chains. To address these challenges, we propose Video Intelligence via Tool-Augmented Learning (VITAL), a novel end-to-end agentic video reasoning framework. With a visual toolbox, the model can densely sample new video frames on demand and generate multimodal CoT for precise long video reasoning. We observe that temporal grounding and question answering are mutually beneficial for video understanding tasks. Therefore, we construct two high-quality multi-task video reasoning datasets MTVR-CoT-72k for supervised fine-tuning and MTVR-RL-110k for reinforcement learning. Moreover, we propose a Difficulty-aware Group Relative Policy Optimization algorithm (DGRPO) to mitigate difficulty imbalance in multi-task reinforcement learning. Extensive experiments on 11 challenging video understanding benchmarks demonstrate the advanced reasoning ability of VITAL, outperforming existing methods in video question answering and temporal grounding tasks, especially in long video scenarios. Code is available at https://zhang9302002.github.io/thinkingwithvideos-page/.

