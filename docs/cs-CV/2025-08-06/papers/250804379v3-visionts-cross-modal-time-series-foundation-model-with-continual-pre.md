---
layout: default
title: VisionTS++: Cross-Modal Time Series Foundation Model with Continual Pre-trained Vision Backbones
---

# VisionTS++: Cross-Modal Time Series Foundation Model with Continual Pre-trained Vision Backbones

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04379" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04379v3</a>
  <a href="https://arxiv.org/pdf/2508.04379.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04379v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04379v3', 'VisionTS++: Cross-Modal Time Series Foundation Model with Continual Pre-trained Vision Backbones')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lefei Shen, Mouxiang Chen, Xu Liu, Han Fu, Xiaoxue Ren, Jianling Sun, Zhuo Li, Chenghao Liu

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06 (æ›´æ–°: 2025-10-10)

**å¤‡æ³¨**: 19 pages

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/HALF111/VisionTSpp)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVisionTS++ä»¥è§£å†³è§†è§‰æ¨¡å‹åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„è·¨æ¨¡æ€è½¬ç§»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ—¶é—´åºåˆ—é¢„æµ‹` `è·¨æ¨¡æ€å­¦ä¹ ` `è§†è§‰æ¨¡å‹` `å¤šå˜é‡å»ºæ¨¡` `æ¦‚ç‡é¢„æµ‹` `æ·±åº¦å­¦ä¹ ` `æŒç»­é¢„è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è§†è§‰æ¨¡å‹ä¸æ—¶é—´åºåˆ—ä¹‹é—´çš„è·¨æ¨¡æ€è½¬ç§»é¢ä¸´æ•°æ®æ¨¡æ€å·®å¼‚ã€å¤šå˜é‡é¢„æµ‹å·®å¼‚å’Œæ¦‚ç‡é¢„æµ‹å·®å¼‚ç­‰æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºçš„VisionTS++é€šè¿‡æŒç»­é¢„è®­ç»ƒè§†è§‰æ¨¡å‹ï¼Œç»“åˆè§†è§‰æ¨¡å‹è¿‡æ»¤å’Œå¤šåˆ†ä½é¢„æµ‹ç­‰åˆ›æ–°æ–¹æ³•ï¼Œè§£å†³äº†ä¸Šè¿°é—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVisionTS++åœ¨23ä¸ªæ•°æ®é›†çš„GIFT-EvalåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒMSEå‡å°‘å¹…åº¦è¾¾åˆ°6%-44%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘æœŸç ”ç©¶è¡¨æ˜ï¼Œç»è¿‡å›¾åƒé¢„è®­ç»ƒçš„è§†è§‰æ¨¡å‹å¯ä»¥ä½œä¸ºæ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ï¼ˆTSFMï¼‰ï¼Œé€šè¿‡å°†æ—¶é—´åºåˆ—é¢„æµ‹é‡æ„ä¸ºå›¾åƒé‡å»ºã€‚ç„¶è€Œï¼Œç”±äºæ•°æ®æ¨¡æ€å·®å¼‚ã€å¤šå˜é‡é¢„æµ‹å·®å¼‚å’Œæ¦‚ç‡é¢„æµ‹å·®å¼‚ï¼Œè§†è§‰åˆ°æ—¶é—´åºåˆ—çš„æœ‰æ•ˆè·¨æ¨¡æ€è½¬ç§»ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†VisionTS++ï¼Œè¯¥æ¨¡å‹åŸºäºå¯¹è§†è§‰æ¨¡å‹è¿›è¡Œå¤§è§„æ¨¡æ—¶é—´åºåˆ—çš„æŒç»­é¢„è®­ç»ƒã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸‰é¡¹å…³é”®åˆ›æ–°ï¼šè§†è§‰æ¨¡å‹è¿‡æ»¤ä»¥è¯†åˆ«é«˜è´¨é‡åºåˆ—ï¼Œå½©è‰²å¤šå˜é‡è½¬æ¢ä»¥å¢å¼ºè·¨å˜é‡å»ºæ¨¡ï¼Œä»¥åŠå¤šåˆ†ä½é¢„æµ‹ä»¥ç”Ÿæˆæ— å‚æ•°å‡è®¾çš„åˆ†ä½é¢„æµ‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVisionTS++åœ¨åˆ†å¸ƒå†…å’Œåˆ†å¸ƒå¤–é¢„æµ‹ä¸­å‡å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºä¸“é—¨çš„TSFMåœ¨å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ä¸Šå‡å°‘äº†6%-44%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰æ¨¡å‹åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„è·¨æ¨¡æ€è½¬ç§»é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æ•°æ®æ¨¡æ€ã€é¢„æµ‹å˜é‡å’Œè¾“å‡ºå½¢å¼ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¯¹è§†è§‰æ¨¡å‹è¿›è¡Œå¤§è§„æ¨¡æ—¶é—´åºåˆ—çš„æŒç»­é¢„è®­ç»ƒï¼Œç»“åˆè§†è§‰æ¨¡å‹è¿‡æ»¤å’Œå¤šåˆ†ä½é¢„æµ‹ç­‰æŠ€æœ¯ï¼Œæ¥ç¼©å°è¿™äº›å·®è·ï¼Œä»è€Œæå‡æ—¶é—´åºåˆ—é¢„æµ‹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè§†è§‰æ¨¡å‹è¿‡æ»¤æ¨¡å—ç”¨äºç­›é€‰é«˜è´¨é‡åºåˆ—ï¼Œå½©è‰²å¤šå˜é‡è½¬æ¢æ¨¡å—å°†å¤šå˜é‡æ—¶é—´åºåˆ—ç¼–ç ä¸ºå¤šå­å›¾RGBå›¾åƒï¼Œä»¥åŠå¤šåˆ†ä½é¢„æµ‹æ¨¡å—é€šè¿‡å¹¶è¡Œé‡å»ºå¤´ç”Ÿæˆåˆ†ä½é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥è§†è§‰æ¨¡å‹è¿‡æ»¤å’Œå½©è‰²å¤šå˜é‡è½¬æ¢ï¼Œå‰è€…å¸®åŠ©ç¨³å®šé¢„è®­ç»ƒè¿‡ç¨‹ï¼Œåè€…å¢å¼ºäº†è·¨å˜é‡å»ºæ¨¡èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå¤šåˆ†ä½é¢„æµ‹æ–¹æ³•å…è®¸åœ¨æ— å‚æ•°å‡è®¾ä¸‹ç”Ÿæˆæ›´ä¸ºçµæ´»çš„é¢„æµ‹ç»“æœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¤šåˆ†ä½é¢„æµ‹çš„æ•ˆæœï¼Œå¹¶é€šè¿‡è°ƒæ•´ç½‘ç»œç»“æ„ä»¥é€‚åº”å¤šå˜é‡è¾“å…¥ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†ä¸åŒæ•°é‡çš„å˜é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVisionTS++åœ¨GIFT-EvalåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¾ƒä¸“é—¨çš„æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹åœ¨å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ä¸Šå‡å°‘äº†6%-44%ï¼Œå¹¶åœ¨23ä¸ªæ•°æ®é›†ä¸Šæ’åç¬¬ä¸€ï¼Œå±•ç¤ºäº†å…¶å¼ºå¤§çš„é¢„æµ‹èƒ½åŠ›å’Œå¹¿æ³›çš„é€‚ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èå¸‚åœºé¢„æµ‹ã€æ°”è±¡æ•°æ®åˆ†æå’ŒåŒ»ç–—å¥åº·ç›‘æµ‹ç­‰ï¼Œèƒ½å¤Ÿä¸ºè¿™äº›é¢†åŸŸæä¾›æ›´ä¸ºç²¾å‡†çš„æ—¶é—´åºåˆ—é¢„æµ‹è§£å†³æ–¹æ¡ˆã€‚æœªæ¥ï¼ŒVisionTS++æœ‰æœ›æ¨åŠ¨è·¨æ¨¡æ€å­¦ä¹ çš„å‘å±•ï¼Œä¿ƒè¿›ä¸åŒæ•°æ®ç±»å‹çš„èåˆä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent studies have indicated that vision models pre-trained on images can serve as time series foundation models (TSFMs) by reformulating time series forecasting (TSF) as image reconstruction. However, effective cross-modal transfer from vision to time series remains challenging due to three discrepancies: (1) the data-modality gap between structured, bounded image data and unbounded, heterogeneous time series; (2) the multivariate-forecasting gap between fixed RGB-three-channel vision models and time series with arbitrary numbers of variates; and (3) the probabilistic-forecasting gap between the deterministic outputs of vision models and the requirement for uncertainty-aware probabilistic predictions. To bridge these gaps, we propose VisonTS++, a TSFM based on continual pre-training of a vision model on large-scale time series. Our approach introduces three key innovations: (1) vision-model-based filtering to identify high-quality sequences to stabilize pre-training and mitigate modality gap; (2) colorized multivariate conversion, encoding multivariate series as multi-subfigure RGB images to enhance cross-variate modeling; (3) multi-quantile forecasting, using parallel reconstruction heads to generate quantile forecasts without parametric assumptions. Experiments show that VisionTS++ achieves state-of-the-art performance in both in-distribution and out-of-distribution forecasting, outperforming specialized TSFMs by 6%-44% in MSE reduction and ranking first in GIFT-Eval benchmark which comprises 23 datasets across 7 domains. Our work demonstrates that with appropriate adaptation, vision models can effectively generalize to TSF, thus advancing the pursuit of universal TSFMs. Code is available at https://github.com/HALF111/VisionTSpp.

