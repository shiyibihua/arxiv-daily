---
layout: default
title: TurboTrain: Towards Efficient and Balanced Multi-Task Learning for Multi-Agent Perception and Prediction
---

# TurboTrain: Towards Efficient and Balanced Multi-Task Learning for Multi-Agent Perception and Prediction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04682" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04682v2</a>
  <a href="https://arxiv.org/pdf/2508.04682.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04682v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04682v2', 'TurboTrain: Towards Efficient and Balanced Multi-Task Learning for Multi-Agent Perception and Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zewei Zhou, Seth Z. Zhao, Tianhui Cai, Zhiyu Huang, Bolei Zhou, Jiaqi Ma

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06 (æ›´æ–°: 2025-08-07)

**å¤‡æ³¨**: ICCV 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTurboTrainä»¥è§£å†³å¤šä»£ç†æ„ŸçŸ¥ä¸é¢„æµ‹çš„é«˜æ•ˆè®­ç»ƒé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `å¤šä»£ç†ç³»ç»Ÿ` `æ„ŸçŸ¥ä¸é¢„æµ‹` `å¤šä»»åŠ¡å­¦ä¹ ` `æ—¶ç©ºé¢„è®­ç»ƒ` `æ¢¯åº¦å†²çªæŠ‘åˆ¶` `è‡ªåŠ¨é©¾é©¶` `æ™ºèƒ½äº¤é€š`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šä»£ç†ç³»ç»Ÿçš„è®­ç»ƒæ–¹æ³•å¤æ‚ï¼Œéœ€å¤§é‡æ‰‹åŠ¨è®¾è®¡ä¸ç›‘æ§ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ã€‚
2. TurboTrainé€šè¿‡å¼•å…¥æ—¶ç©ºé¢„è®­ç»ƒå’Œæ¢¯åº¦å†²çªæŠ‘åˆ¶ç­–ç•¥ï¼Œç®€åŒ–äº†å¤šä»»åŠ¡å­¦ä¹ è¿‡ç¨‹ã€‚
3. åœ¨V2XPnP-Seqæ•°æ®é›†ä¸Šï¼ŒTurboTrainæ˜¾è‘—æå‡äº†å¤šä»£ç†æ„ŸçŸ¥ä¸é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šä»£ç†ç³»ç»Ÿçš„ç«¯åˆ°ç«¯è®­ç»ƒåœ¨æå‡å¤šä»»åŠ¡æ€§èƒ½æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œä½†è®­ç»ƒè¿‡ç¨‹å¤æ‚ä¸”éœ€å¤§é‡æ‰‹åŠ¨è®¾è®¡ä¸ç›‘æ§ã€‚æœ¬æ–‡æå‡ºTurboTrainï¼Œä¸€ä¸ªæ–°é¢–ä¸”é«˜æ•ˆçš„å¤šä»£ç†æ„ŸçŸ¥ä¸é¢„æµ‹è®­ç»ƒæ¡†æ¶ã€‚TurboTrainåŒ…å«ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šåŸºäºæ©ç é‡å»ºå­¦ä¹ çš„å¤šä»£ç†æ—¶ç©ºé¢„è®­ç»ƒæ–¹æ¡ˆï¼Œä»¥åŠåŸºäºæ¢¯åº¦å†²çªæŠ‘åˆ¶çš„å¹³è¡¡å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥ã€‚é€šè¿‡ç®€åŒ–è®­ç»ƒè¿‡ç¨‹ï¼ŒTurboTrainæ¶ˆé™¤äº†æ‰‹åŠ¨è®¾è®¡å’Œè°ƒä¼˜å¤æ‚å¤šé˜¶æ®µè®­ç»ƒç®¡é“çš„éœ€æ±‚ï¼Œæ˜¾è‘—å‡å°‘äº†è®­ç»ƒæ—¶é—´å¹¶æå‡äº†æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨çœŸå®çš„åˆä½œé©¾é©¶æ•°æ®é›†V2XPnP-Seqä¸Šè¯„ä¼°äº†TurboTrainï¼Œç»“æœè¡¨æ˜å…¶è¿›ä¸€æ­¥æå‡äº†ç°æœ‰å¤šä»£ç†æ„ŸçŸ¥ä¸é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ï¼Œé¢„è®­ç»ƒæœ‰æ•ˆæ•æ‰äº†æ—¶ç©ºå¤šä»£ç†ç‰¹å¾ï¼Œå¹¶æ˜¾è‘—æœ‰åˆ©äºä¸‹æ¸¸ä»»åŠ¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šä»£ç†ç³»ç»Ÿè®­ç»ƒè¿‡ç¨‹ä¸­çš„å¤æ‚æ€§ä¸ä½æ•ˆæ€§ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€éœ€è¦å¤§é‡æ‰‹åŠ¨è®¾è®¡ä¸è°ƒä¼˜ï¼Œå¯¼è‡´è®­ç»ƒæ—¶é—´é•¿ä¸”æ€§èƒ½ä¸ç¨³å®šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTurboTrainçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥æ—¶ç©ºé¢„è®­ç»ƒå’Œæ¢¯åº¦å†²çªæŠ‘åˆ¶ç­–ç•¥ï¼Œä¼˜åŒ–å¤šä»»åŠ¡å­¦ä¹ è¿‡ç¨‹ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTurboTrainæ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªæ¨¡å—ï¼šé¦–å…ˆæ˜¯åŸºäºæ©ç é‡å»ºå­¦ä¹ çš„å¤šä»£ç†æ—¶ç©ºé¢„è®­ç»ƒæ–¹æ¡ˆï¼Œå…¶æ¬¡æ˜¯å¹³è¡¡å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥ï¼Œé€šè¿‡æŠ‘åˆ¶æ¢¯åº¦å†²çªæ¥ä¼˜åŒ–ä»»åŠ¡é—´çš„å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šTurboTrainçš„å…³é”®åˆ›æ–°åœ¨äºå…¶é«˜æ•ˆçš„è®­ç»ƒæµç¨‹ï¼Œæ¶ˆé™¤äº†ä¼ ç»Ÿæ–¹æ³•ä¸­å¤æ‚çš„å¤šé˜¶æ®µè®­ç»ƒç®¡é“ï¼Œæ˜¾è‘—é™ä½äº†æ‰‹åŠ¨å¹²é¢„çš„éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥æ”¯æŒæ©ç é‡å»ºå­¦ä¹ ï¼Œå¹¶é€šè¿‡è°ƒæ•´å­¦ä¹ ç‡å’Œä»»åŠ¡æƒé‡æ¥å®ç°æ¢¯åº¦å†²çªçš„æŠ‘åˆ¶ï¼Œç¡®ä¿å„ä»»åŠ¡é—´çš„å¹³è¡¡å­¦ä¹ ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨V2XPnP-Seqæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTurboTrainæ˜¾è‘—æå‡äº†å¤šä»£ç†æ„ŸçŸ¥ä¸é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºç°æœ‰æœ€å…ˆè¿›æ¨¡å‹ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°äº†X%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ï¼ŒéªŒè¯äº†é¢„è®­ç»ƒå’Œå¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TurboTrainçš„ç ”ç©¶æˆæœåœ¨è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½äº¤é€šç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡å¤šä»£ç†ç³»ç»Ÿçš„æ„ŸçŸ¥ä¸é¢„æµ‹èƒ½åŠ›ï¼Œå¯ä»¥æœ‰æ•ˆæé«˜äº¤é€šå®‰å…¨æ€§å’Œæ•ˆç‡ï¼Œæ¨åŠ¨æ™ºèƒ½äº¤é€šç³»ç»Ÿçš„å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶è¿˜å¯æ‰©å±•åˆ°å…¶ä»–å¤šä»»åŠ¡å­¦ä¹ åœºæ™¯ï¼Œå¦‚æœºå™¨äººåä½œå’Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> End-to-end training of multi-agent systems offers significant advantages in improving multi-task performance. However, training such models remains challenging and requires extensive manual design and monitoring. In this work, we introduce TurboTrain, a novel and efficient training framework for multi-agent perception and prediction. TurboTrain comprises two key components: a multi-agent spatiotemporal pretraining scheme based on masked reconstruction learning and a balanced multi-task learning strategy based on gradient conflict suppression. By streamlining the training process, our framework eliminates the need for manually designing and tuning complex multi-stage training pipelines, substantially reducing training time and improving performance. We evaluate TurboTrain on a real-world cooperative driving dataset, V2XPnP-Seq, and demonstrate that it further improves the performance of state-of-the-art multi-agent perception and prediction models. Our results highlight that pretraining effectively captures spatiotemporal multi-agent features and significantly benefits downstream tasks. Moreover, the proposed balanced multi-task learning strategy enhances detection and prediction.

