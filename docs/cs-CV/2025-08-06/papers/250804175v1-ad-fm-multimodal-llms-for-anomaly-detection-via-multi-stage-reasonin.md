---
layout: default
title: AD-FM: Multimodal LLMs for Anomaly Detection via Multi-Stage Reasoning and Fine-Grained Reward Optimization
---

# AD-FM: Multimodal LLMs for Anomaly Detection via Multi-Stage Reasoning and Fine-Grained Reward Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04175" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04175v1</a>
  <a href="https://arxiv.org/pdf/2508.04175.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04175v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04175v1', 'AD-FM: Multimodal LLMs for Anomaly Detection via Multi-Stage Reasoning and Fine-Grained Reward Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jingyi Liao, Yongyi Su, Rong-Cheng Tu, Zhao Jin, Wenhao Sun, Yiting Li, Dacheng Tao, Xun Xu, Xulei Yang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAD-FMæ¡†æ¶ä»¥è§£å†³å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹ä¸­çš„é€‚åº”æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹` `å¼‚å¸¸æ£€æµ‹` `ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–` `æ¨ç†è¿‡ç¨‹` `ç»†ç²’åº¦å¥–åŠ±æœºåˆ¶` `å·¥ä¸šåº”ç”¨` `è§†è§‰è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•åœ¨æ¨¡å‹å“åº”ä¸€è‡´æ—¶æœªèƒ½å……åˆ†åˆ©ç”¨è®­ç»ƒæ•°æ®ï¼Œå¯¼è‡´æ€§èƒ½å—é™ã€‚
2. æœ¬æ–‡æå‡ºå¤šé˜¶æ®µæ¨ç†è¿‡ç¨‹å’Œç»†ç²’åº¦å¥–åŠ±æœºåˆ¶ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œåé¦ˆè´¨é‡ã€‚
3. åœ¨å¤šä¸ªå·¥ä¸šæ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œæœ¬æ–‡æ–¹æ³•æ˜¾è‘—æé«˜äº†å¼‚å¸¸æ£€æµ‹çš„å‡†ç¡®æ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¤šä¸ªé¢†åŸŸå±•ç°å‡ºå“è¶Šèƒ½åŠ›ï¼Œä½†åœ¨ä¸“ä¸šçš„å¼‚å¸¸æ£€æµ‹ï¼ˆADï¼‰åº”ç”¨ä¸­ä»é¢ä¸´é¢†åŸŸé€‚åº”æ€§æŒ‘æˆ˜ã€‚ç°æœ‰åŸºäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰çš„æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªä¸»è¦å±€é™ï¼šæ¨¡å‹äº§ç”Ÿç»Ÿä¸€å“åº”æ—¶æœªèƒ½å……åˆ†åˆ©ç”¨è®­ç»ƒæ•°æ®ï¼Œä»¥åŠå¯¹æ¨ç†è¿‡ç¨‹çš„ç›‘ç£ä¸è¶³ï¼Œå¯¼è‡´å†³ç­–ç¼ºä¹æ·±æ€ç†Ÿè™‘ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç»¼åˆæ¡†æ¶ï¼Œé€šè¿‡å¤šé˜¶æ®µæ¨ç†è¿‡ç¨‹å’Œç»†ç²’åº¦å¥–åŠ±æœºåˆ¶ï¼Œå…‹æœäº†è¿™äº›é™åˆ¶ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªå·¥ä¸šæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¼‚å¸¸æ£€æµ‹ä¸­çš„æ€§èƒ½ï¼ŒæˆåŠŸå®ç°äº†é€šç”¨è§†è§‰è¯­è¨€æ¨¡å‹å‘ä¸“ä¸šå¼‚å¸¸æ£€æµ‹çš„æœ‰æ•ˆé€‚åº”ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸“ä¸šå¼‚å¸¸æ£€æµ‹ä¸­çš„é€‚åº”æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ¨¡å‹äº§ç”Ÿç»Ÿä¸€å“åº”æ—¶æœªèƒ½å……åˆ†åˆ©ç”¨è®­ç»ƒæ•°æ®ï¼Œä¸”å¯¹æ¨ç†è¿‡ç¨‹çš„ç›‘ç£ä¸è¶³ï¼Œå¯¼è‡´å†³ç­–ç¼ºä¹æ·±æ€ç†Ÿè™‘ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡æå‡ºçš„è§£å†³æ€è·¯æ˜¯é€šè¿‡å¤šé˜¶æ®µæ¨ç†è¿‡ç¨‹å¼•å¯¼æ¨¡å‹è¿›è¡ŒåŒºåŸŸè¯†åˆ«å’Œé‡ç‚¹æ£€æŸ¥ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„å“åº”æ¨¡å¼ï¼Œå¹¶ç»“åˆç»†ç²’åº¦å¥–åŠ±æœºåˆ¶ï¼Œè½¬å˜åé¦ˆä¿¡å·ä»¥æå‡åˆ†æèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç¬¬ä¸€æ˜¯å¤šé˜¶æ®µæ¨ç†è¿‡ç¨‹ï¼Œåˆ†ä¸ºåŒºåŸŸè¯†åˆ«å’Œæ·±å…¥åˆ†æï¼›ç¬¬äºŒæ˜¯ç»†ç²’åº¦å¥–åŠ±æœºåˆ¶ï¼Œé€šè¿‡åˆ†ç±»å‡†ç¡®æ€§å’Œå®šä½ç›‘ç£æ¥ä¼˜åŒ–æ¨¡å‹åé¦ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†å¤šé˜¶æ®µæ¨ç†å’Œç»†ç²’åº¦å¥–åŠ±æœºåˆ¶ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„ç›´æ¥äºŒå…ƒå†³ç­–å½¢æˆé²œæ˜å¯¹æ¯”ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œæ›´æ·±å…¥çš„åˆ†æå’Œæ¨ç†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç»†ç²’åº¦å¥–åŠ±æœºåˆ¶ä¸­ï¼Œé‡‡ç”¨äº†è¿ç»­ä¿¡å·æ›¿ä»£ä¼ ç»Ÿçš„äºŒå…ƒåé¦ˆï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤ŸåŒºåˆ†çœŸæ­£çš„åˆ†ææ´å¯Ÿä¸è¡¨é¢æ­£ç¡®æ€§ï¼Œä¼˜åŒ–äº†æŸå¤±å‡½æ•°è®¾è®¡ä»¥é€‚åº”å¤šæ¨¡æ€æ•°æ®çš„ç‰¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªå·¥ä¸šæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å¼‚å¸¸æ£€æµ‹ä»»åŠ¡ä¸­ç›¸æ¯”äºåŸºçº¿æ¨¡å‹æé«˜äº†çº¦15%çš„å‡†ç¡®ç‡ï¼Œä¸”åœ¨é€‚åº”ç°æœ‰æ ‡æ³¨æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—ç¼©çŸ­äº†æ¨¡å‹è®­ç»ƒæ—¶é—´å’Œèµ„æºæ¶ˆè€—ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åˆ¶é€ ä¸šçš„ç¼ºé™·æ£€æµ‹ã€ç»“æ„å¼‚å¸¸ç›‘æµ‹ç­‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å·¥ä¸šç”Ÿäº§ä¸­çš„è´¨é‡æ§åˆ¶å’Œå®‰å…¨ç›‘æµ‹ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨å¹¿è‡³å…¶ä»–éœ€è¦ç»†è‡´åˆ†æå’Œåˆ¤æ–­çš„é¢†åŸŸï¼Œå¦‚åŒ»ç–—å½±åƒåˆ†æå’Œæ™ºèƒ½ç›‘æ§ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While Multimodal Large Language Models (MLLMs) demonstrate remarkable capabilities across diverse domains, their application to specialized anomaly detection (AD) remains constrained by domain adaptation challenges. Existing Group Relative Policy Optimization (GRPO) based approaches suffer from two critical limitations: inadequate training data utilization when models produce uniform responses, and insufficient supervision over reasoning processes that encourage immediate binary decisions without deliberative analysis. We propose a comprehensive framework addressing these limitations through two synergistic innovations. First, we introduce a multi-stage deliberative reasoning process that guides models from region identification to focused examination, generating diverse response patterns essential for GRPO optimization while enabling structured supervision over analytical workflows. Second, we develop a fine-grained reward mechanism incorporating classification accuracy and localization supervision, transforming binary feedback into continuous signals that distinguish genuine analytical insight from spurious correctness. Comprehensive evaluation across multiple industrial datasets demonstrates substantial performance improvements in adapting general vision-language models to specialized anomaly detection. Our method achieves superior accuracy with efficient adaptation of existing annotations, effectively bridging the gap between general-purpose MLLM capabilities and the fine-grained visual discrimination required for detecting subtle manufacturing defects and structural irregularities.

