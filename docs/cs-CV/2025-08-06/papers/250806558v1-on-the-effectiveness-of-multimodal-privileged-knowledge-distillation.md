---
layout: default
title: On the effectiveness of multimodal privileged knowledge distillation in two vision transformer based diagnostic applications
---

# On the effectiveness of multimodal privileged knowledge distillation in two vision transformer based diagnostic applications

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.06558" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.06558v1</a>
  <a href="https://arxiv.org/pdf/2508.06558.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.06558v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.06558v1', 'On the effectiveness of multimodal privileged knowledge distillation in two vision transformer based diagnostic applications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Simon Baur, Alexandra Benova, Emilio Dolgener CantÃº, Jackie Ma

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€ç‰¹æƒçŸ¥è¯†è’¸é¦ä»¥æå‡è§†è§‰æ¨¡å‹è¯Šæ–­èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€ç‰¹æƒçŸ¥è¯†è’¸é¦` `è§†è§‰å˜æ¢å™¨` `åŒ»å­¦å½±åƒåˆ†æ` `çŸ¥è¯†è’¸é¦` `æ·±åº¦å­¦ä¹ ` `ä¸´åºŠå†³ç­–` `é›¶-shotå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ä¸´åºŠåº”ç”¨ä¸­é¢ä¸´å¤šæ¨¡æ€æ•°æ®ä¸å¯ç”¨çš„é—®é¢˜ï¼Œå¯¼è‡´å†³ç­–çš„ç¨³å¥æ€§å’Œå¯ä¿¡åº¦ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºçš„MMPKDç­–ç•¥é€šè¿‡åˆ©ç”¨è®­ç»ƒæœŸé—´çš„é¢å¤–æ¨¡æ€ï¼ŒæŒ‡å¯¼å•æ¨¡æ€è§†è§‰æ¨¡å‹çš„å­¦ä¹ ï¼Œæå‡æ¨¡å‹æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒMMPKDæ˜¾è‘—æé«˜äº†æ³¨æ„åŠ›å›¾åœ¨å®šä½è¾“å…¥å›¾åƒä¸­æ„Ÿå…´è¶£åŒºåŸŸçš„èƒ½åŠ›ï¼Œä½†åœ¨ä¸åŒé¢†åŸŸé—´çš„æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ä¸´åºŠå®è·µä¸­ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„éƒ¨ç½²é€šå¸¸éœ€è¦åˆ©ç”¨å¤šç§æ•°æ®æ¨¡æ€ï¼ˆå¦‚å›¾åƒã€æ–‡æœ¬å’Œç»“æ„åŒ–æ•°æ®ï¼‰ä»¥å®ç°ç¨³å¥å’Œå¯ä¿¡çš„å†³ç­–ã€‚ç„¶è€Œï¼Œå¹¶éæ‰€æœ‰æ¨¡æ€åœ¨æ¨ç†æ—¶éƒ½å¯ç”¨ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€ç‰¹æƒçŸ¥è¯†è’¸é¦ï¼ˆMMPKDï¼‰è®­ç»ƒç­–ç•¥ï¼Œåˆ©ç”¨ä»…åœ¨è®­ç»ƒæœŸé—´å¯ç”¨çš„é¢å¤–æ¨¡æ€æ¥æŒ‡å¯¼å•æ¨¡æ€è§†è§‰æ¨¡å‹ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬ä½¿ç”¨åŸºäºæ–‡æœ¬çš„æ•™å¸ˆæ¨¡å‹ï¼ˆMIMIC-CXRï¼‰å’ŒåŸºäºè¡¨æ ¼å…ƒæ•°æ®çš„æ•™å¸ˆæ¨¡å‹ï¼ˆCBIS-DDSMï¼‰æ¥å°†çŸ¥è¯†è’¸é¦åˆ°è§†è§‰å˜æ¢å™¨å­¦ç”Ÿæ¨¡å‹ä¸­ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒMMPKDèƒ½å¤Ÿæ”¹å–„ç”Ÿæˆçš„æ³¨æ„åŠ›å›¾åœ¨è¾“å…¥å›¾åƒä¸­å®šä½æ„Ÿå…´è¶£åŒºåŸŸçš„é›¶-shot èƒ½åŠ›ï¼Œä½†è¿™ä¸€æ•ˆæœå¹¶æœªåœ¨ä¸åŒé¢†åŸŸé—´æ™®éé€‚ç”¨ï¼Œåè€Œä¸å…ˆå‰ç ”ç©¶çš„å»ºè®®ç›¸æ‚–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨æ¨ç†æ—¶å¤šæ¨¡æ€æ•°æ®ä¸å¯ç”¨çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è¿™ç§æƒ…å†µä¸‹çš„å†³ç­–èƒ½åŠ›ä¸è¶³ï¼Œå½±å“ä¸´åºŠåº”ç”¨çš„æœ‰æ•ˆæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥å¤šæ¨¡æ€ç‰¹æƒçŸ¥è¯†è’¸é¦ï¼ˆMMPKDï¼‰ï¼Œåˆ©ç”¨è®­ç»ƒæœŸé—´å¯ç”¨çš„é¢å¤–æ¨¡æ€ï¼ˆå¦‚æ–‡æœ¬å’Œè¡¨æ ¼æ•°æ®ï¼‰æ¥æŒ‡å¯¼å•æ¨¡æ€è§†è§‰æ¨¡å‹çš„å­¦ä¹ ï¼Œä»è€Œæå‡å…¶æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ã€‚æ•™å¸ˆæ¨¡å‹åˆ†åˆ«åŸºäºæ–‡æœ¬å’Œè¡¨æ ¼æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè€Œå­¦ç”Ÿæ¨¡å‹åˆ™æ˜¯ä¸€ä¸ªè§†è§‰å˜æ¢å™¨ï¼Œè´Ÿè´£ä»æ•™å¸ˆæ¨¡å‹ä¸­è’¸é¦çŸ¥è¯†ã€‚

**å…³é”®åˆ›æ–°**ï¼šMMPKDçš„åˆ›æ–°åœ¨äºå…¶åˆ©ç”¨è®­ç»ƒæœŸé—´çš„å¤šæ¨¡æ€ä¿¡æ¯æ¥å¢å¼ºå•æ¨¡æ€æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›ï¼Œè¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å•æ¨¡æ€è®­ç»ƒæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡æ•™å¸ˆæ¨¡å‹ä¸å­¦ç”Ÿæ¨¡å‹ä¹‹é—´çš„çŸ¥è¯†ä¼ é€’ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šä¼˜åŒ–äº†è§†è§‰å˜æ¢å™¨çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥æé«˜å…¶å¯¹è¾“å…¥å›¾åƒçš„ç†è§£èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMMPKDæ˜¾è‘—æå‡äº†è§†è§‰å˜æ¢å™¨æ¨¡å‹åœ¨é›¶-shotæƒ…å†µä¸‹å®šä½æ„Ÿå…´è¶£åŒºåŸŸçš„èƒ½åŠ›ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨MIMIC-CXRå’ŒCBIS-DDSMæ•°æ®é›†ä¸Šçš„æ€§èƒ½æå‡ï¼Œå°½ç®¡è¯¥æ•ˆæœåœ¨ä¸åŒé¢†åŸŸé—´çš„æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„æ½œåœ¨åº”ç”¨åœºæ™¯ï¼Œå°¤å…¶æ˜¯åœ¨åŒ»å­¦å½±åƒåˆ†æé¢†åŸŸã€‚é€šè¿‡æå‡è§†è§‰æ¨¡å‹åœ¨å¤šæ¨¡æ€æ•°æ®ç¨€ç¼ºæƒ…å†µä¸‹çš„è¡¨ç°ï¼Œèƒ½å¤Ÿå¸®åŠ©åŒ»ç”Ÿæ›´å‡†ç¡®åœ°è¿›è¡Œç–¾ç—…è¯Šæ–­ï¼Œä»è€Œæé«˜ä¸´åºŠå†³ç­–çš„è´¨é‡å’Œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•ä¹Ÿå¯æ‰©å±•åˆ°å…¶ä»–éœ€è¦å¤šæ¨¡æ€æ•°æ®çš„åº”ç”¨åœºæ™¯ï¼Œå¦‚è‡ªåŠ¨é©¾é©¶å’Œæ™ºèƒ½ç›‘æ§ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deploying deep learning models in clinical practice often requires leveraging multiple data modalities, such as images, text, and structured data, to achieve robust and trustworthy decisions. However, not all modalities are always available at inference time. In this work, we propose multimodal privileged knowledge distillation (MMPKD), a training strategy that utilizes additional modalities available solely during training to guide a unimodal vision model. Specifically, we used a text-based teacher model for chest radiographs (MIMIC-CXR) and a tabular metadata-based teacher model for mammography (CBIS-DDSM) to distill knowledge into a vision transformer student model. We show that MMPKD can improve the resulting attention maps' zero-shot capabilities of localizing ROI in input images, while this effect does not generalize across domains, as contrarily suggested by prior research.

