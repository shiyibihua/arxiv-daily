---
layout: default
title: Static and Plugged: Make Embodied Evaluation Simple
---

# Static and Plugged: Make Embodied Evaluation Simple

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.06553" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.06553v1</a>
  <a href="https://arxiv.org/pdf/2508.06553.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.06553v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.06553v1', 'Static and Plugged: Make Embodied Evaluation Simple')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiahao Xiao, Jianbo Zhang, BoWen Yan, Shengyu Guo, Tongrui Ye, Kaiwei Zhang, Zicheng Zhang, Xiaohong Liu, Zhengxue Cheng, Lei Fan, Chuyi Li, Guangtao Zhai

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºStaticEmbodiedBenchä»¥è§£å†³ç°æœ‰è¯„ä¼°æ–¹æ³•çš„å±€é™æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å…·èº«æ™ºèƒ½` `è¯„ä¼°æ–¹æ³•` `é™æ€åœºæ™¯` `è§†è§‰-è¯­è¨€æ¨¡å‹` `æœºå™¨äººå¯¼èˆª` `æ™ºèƒ½å®¶å±…` `è™šæ‹ŸåŠ©æ‰‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯„ä¼°æ–¹æ³•ä¾èµ–äºå¤æ‚çš„äº¤äº’å¼ç¯å¢ƒï¼Œå¯¼è‡´æˆæœ¬é«˜ä¸”éš¾ä»¥æ‰©å±•ï¼Œé™åˆ¶äº†å…·èº«æ™ºèƒ½çš„è¯„ä¼°æ•ˆç‡ã€‚
2. æœ¬æ–‡æå‡ºStaticEmbodiedBenchï¼Œé€šè¿‡é™æ€åœºæ™¯è¡¨ç¤ºå®ç°ç»Ÿä¸€è¯„ä¼°ï¼Œç®€åŒ–äº†è¯„ä¼°æµç¨‹å¹¶æé«˜äº†å¯æ‰©å±•æ€§ã€‚
3. å®éªŒä¸­è¯„ä¼°äº†19ä¸ªVLMså’Œ11ä¸ªVLAsï¼Œå»ºç«‹äº†ç¬¬ä¸€ä¸ªé™æ€æ’è¡Œæ¦œï¼Œæ¨åŠ¨äº†å…·èº«æ™ºèƒ½çš„ç ”ç©¶è¿›å±•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å…·èº«æ™ºèƒ½çš„å¿«é€Ÿå‘å±•ï¼Œè¯„ä¼°æ–¹æ³•çš„æ•ˆç‡éœ€æ±‚æ—¥ç›Šå¢åŠ ã€‚ç›®å‰çš„åŸºå‡†æµ‹è¯•é€šå¸¸ä¾èµ–äºäº¤äº’å¼æ¨¡æ‹Ÿç¯å¢ƒæˆ–ç°å®ä¸–ç•Œè®¾ç½®ï¼Œè¿™äº›æ–¹æ³•æˆæœ¬é«˜ã€ç¢ç‰‡åŒ–ä¸”éš¾ä»¥æ‰©å±•ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†StaticEmbodiedBenchï¼Œä¸€ä¸ªå³æ’å³ç”¨çš„åŸºå‡†æµ‹è¯•ï¼Œèƒ½å¤Ÿé€šè¿‡é™æ€åœºæ™¯è¡¨ç¤ºå®ç°ç»Ÿä¸€è¯„ä¼°ã€‚è¯¥åŸºå‡†è¦†ç›–42ç§å¤šæ ·åŒ–åœºæ™¯å’Œ8ä¸ªæ ¸å¿ƒç»´åº¦ï¼Œæ”¯æŒé€šè¿‡ç®€å•æ¥å£è¿›è¡Œå¯æ‰©å±•å’Œå…¨é¢çš„è¯„ä¼°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯„ä¼°äº†19ä¸ªè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å’Œ11ä¸ªè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼ˆVLAsï¼‰ï¼Œå»ºç«‹äº†å…·èº«æ™ºèƒ½çš„ç¬¬ä¸€ä¸ªç»Ÿä¸€é™æ€æ’è¡Œæ¦œï¼Œå¹¶å‘å¸ƒäº†200ä¸ªæ ·æœ¬ä»¥åŠ é€Ÿå…·èº«æ™ºèƒ½çš„å‘å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å…·èº«æ™ºèƒ½è¯„ä¼°æ–¹æ³•çš„é«˜æˆæœ¬å’Œä½å¯æ‰©å±•æ€§é—®é¢˜ã€‚å½“å‰æ–¹æ³•ä¾èµ–äºå¤æ‚çš„äº¤äº’å¼ç¯å¢ƒï¼Œå¯¼è‡´è¯„ä¼°è¿‡ç¨‹ç¢ç‰‡åŒ–ä¸”éš¾ä»¥ç»Ÿä¸€ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºStaticEmbodiedBenchï¼Œé€šè¿‡é™æ€åœºæ™¯è¡¨ç¤ºå®ç°è¯„ä¼°çš„ç»Ÿä¸€æ€§å’Œå¯æ‰©å±•æ€§ã€‚è¯¥æ–¹æ³•è®¾è®¡ä¸ºå³æ’å³ç”¨ï¼Œç®€åŒ–äº†è¯„ä¼°æµç¨‹ï¼Œé€‚ç”¨äºå¤šç§åœºæ™¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬é™æ€åœºæ™¯è¡¨ç¤ºæ¨¡å—ã€è¯„ä¼°æ¥å£å’Œç»“æœè¾“å‡ºæ¨¡å—ã€‚é™æ€åœºæ™¯è¡¨ç¤ºæ¨¡å—è´Ÿè´£æ„å»ºå¤šæ ·åŒ–çš„åœºæ™¯ï¼Œè¯„ä¼°æ¥å£åˆ™æä¾›ç»Ÿä¸€çš„è¯„ä¼°æ ‡å‡†å’Œæ–¹æ³•ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥é™æ€åœºæ™¯è¡¨ç¤ºï¼Œä½¿å¾—è¯„ä¼°ä¸å†ä¾èµ–äºåŠ¨æ€äº¤äº’ç¯å¢ƒï¼Œä»è€Œé™ä½äº†æˆæœ¬å¹¶æé«˜äº†è¯„ä¼°çš„å¯æ‰©å±•æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†42ç§ä¸åŒçš„åœºæ™¯å’Œ8ä¸ªæ ¸å¿ƒç»´åº¦è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿äº†è¯„ä¼°çš„å…¨é¢æ€§å’Œå¤šæ ·æ€§ã€‚åŒæ—¶ï¼Œå‘å¸ƒçš„200ä¸ªæ ·æœ¬ä¸ºåç»­ç ”ç©¶æä¾›äº†åŸºç¡€æ•°æ®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒStaticEmbodiedBenchèƒ½å¤Ÿæœ‰æ•ˆè¯„ä¼°19ä¸ªVLMså’Œ11ä¸ªVLAsï¼Œå»ºç«‹äº†ç¬¬ä¸€ä¸ªé™æ€æ’è¡Œæ¦œï¼Œæ¨åŠ¨äº†å…·èº«æ™ºèƒ½çš„ç ”ç©¶è¿›å±•ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯„ä¼°æ•ˆç‡æ˜¾è‘—æå‡ï¼Œä¸”è¯„ä¼°ç»“æœæ›´åŠ ä¸€è‡´ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½å®¶å±…ç³»ç»Ÿå’Œè™šæ‹ŸåŠ©æ‰‹ç­‰ã€‚é€šè¿‡æä¾›ç»Ÿä¸€çš„è¯„ä¼°æ ‡å‡†ï¼ŒStaticEmbodiedBenchèƒ½å¤ŸåŠ é€Ÿå…·èº«æ™ºèƒ½çš„ç ”ç©¶ä¸å¼€å‘ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å®é™…åº”ç”¨ä¸è½åœ°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Embodied intelligence is advancing rapidly, driving the need for efficient evaluation. Current benchmarks typically rely on interactive simulated environments or real-world setups, which are costly, fragmented, and hard to scale. To address this, we introduce StaticEmbodiedBench, a plug-and-play benchmark that enables unified evaluation using static scene representations. Covering 42 diverse scenarios and 8 core dimensions, it supports scalable and comprehensive assessment through a simple interface. Furthermore, we evaluate 19 Vision-Language Models (VLMs) and 11 Vision-Language-Action models (VLAs), establishing the first unified static leaderboard for Embodied intelligence. Moreover, we release a subset of 200 samples from our benchmark to accelerate the development of embodied intelligence.

