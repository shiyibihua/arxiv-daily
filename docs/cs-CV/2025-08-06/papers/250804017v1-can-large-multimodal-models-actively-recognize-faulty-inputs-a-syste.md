---
layout: default
title: Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability
---

# Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04017" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04017v1</a>
  <a href="https://arxiv.org/pdf/2508.04017.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04017v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04017v1', 'Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haiqi Yang, Jinzhe Li, Gengxu Li, Yi Chang, Yuan Wu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

**å¤‡æ³¨**: 9pages, 2figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/MLGroupJLU/LMM_ISEval)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¾“å…¥å®¡æŸ¥èƒ½åŠ›è¯„ä¼°æ¡†æ¶ä»¥è§£å†³å¤šæ¨¡æ€æ¨¡å‹è¾“å…¥é”™è¯¯è¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨¡å‹` `è¾“å…¥å®¡æŸ¥` `é”™è¯¯è¯†åˆ«` `é€»è¾‘è°¬è¯¯` `è¯„ä¼°æ¡†æ¶` `äººå·¥æ™ºèƒ½` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨å¤„ç†ç¼ºé™·è¾“å…¥æ—¶è¡¨ç°å‡ºè¢«åŠ¨æ¥å—çš„å€¾å‘ï¼Œç¼ºä¹ä¸»åŠ¨è¯†åˆ«èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºäº†è¾“å…¥å®¡æŸ¥èƒ½åŠ›è¯„ä¼°æ¡†æ¶ï¼ˆISEvalï¼‰ï¼Œé€šè¿‡ä¸ƒç±»ç¼ºé™·å‰æå’Œä¸‰ç§è¯„ä¼°æŒ‡æ ‡æ¥è¯„ä¼°æ¨¡å‹çš„è¾“å…¥å®¡æŸ¥èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¤§å¤šæ•°æ¨¡å‹åœ¨è¯†åˆ«é€»è¾‘è°¬è¯¯æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨è¡¨é¢è¯­è¨€é”™è¯¯å’Œæ¡ä»¶ç¼ºé™·ä¸Šå­˜åœ¨æ˜æ˜¾ä¸è¶³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨å¤„ç†å¤æ‚çš„å¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬å¯¹ç¼ºé™·è¾“å…¥çš„è¢«åŠ¨æ¥å—ç°è±¡å¼•å‘äº†å…³æ³¨ã€‚æœ¬æ–‡æå‡ºäº†è¾“å…¥å®¡æŸ¥èƒ½åŠ›è¯„ä¼°æ¡†æ¶ï¼ˆISEvalï¼‰ï¼Œæ¶µç›–ä¸ƒç±»ç¼ºé™·å‰æå’Œä¸‰ç§è¯„ä¼°æŒ‡æ ‡ã€‚å¯¹åç§å…ˆè¿›LMMsçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå¤§å¤šæ•°æ¨¡å‹åœ¨æ²¡æœ‰æŒ‡å¯¼çš„æƒ…å†µä¸‹éš¾ä»¥ä¸»åŠ¨è¯†åˆ«æ–‡æœ¬ç¼ºé™·ï¼Œå°¤å…¶åœ¨è¯†åˆ«è¡¨é¢è¯­è¨€é”™è¯¯å’ŒæŸäº›æ¡ä»¶ç¼ºé™·æ—¶è¡¨ç°ä¸ä½³ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†å¢å¼ºLMMsä¸»åŠ¨éªŒè¯è¾“å…¥æœ‰æ•ˆæ€§çš„ç´§è¿«æ€§ï¼Œå¹¶ä¸ºè§£å†³è¿™ä¸€é—®é¢˜æä¾›äº†æ–°æ€è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨é¢å¯¹ç¼ºé™·è¾“å…¥æ—¶çš„ä¸»åŠ¨è¯†åˆ«èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºæ˜ç¡®çš„æç¤ºï¼Œå¯¼è‡´æ¨¡å‹åœ¨ç¼ºé™·è¾“å…¥çš„è¯†åˆ«ä¸Šè¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºè¾“å…¥å®¡æŸ¥èƒ½åŠ›è¯„ä¼°æ¡†æ¶ï¼ˆISEvalï¼‰ï¼Œé€šè¿‡ç³»ç»ŸåŒ–çš„è¯„ä¼°æ–¹æ³•æ¥åˆ†ææ¨¡å‹å¯¹ç¼ºé™·è¾“å…¥çš„è¯†åˆ«èƒ½åŠ›ï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„ä¸»åŠ¨éªŒè¯èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šISEvalæ¡†æ¶åŒ…æ‹¬ä¸ƒç±»ç¼ºé™·å‰æï¼ˆå¦‚é€»è¾‘è°¬è¯¯ã€è¡¨é¢è¯­è¨€é”™è¯¯ç­‰ï¼‰å’Œä¸‰ç§è¯„ä¼°æŒ‡æ ‡ï¼Œæ•´ä½“æµç¨‹æ¶µç›–ç¼ºé™·è¾“å…¥ç”Ÿæˆã€æ¨¡å‹è¯„ä¼°å’Œç»“æœåˆ†æç­‰ä¸»è¦æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°è¯„ä¼°å¤šæ¨¡æ€æ¨¡å‹å¯¹ç¼ºé™·è¾“å…¥çš„è¯†åˆ«èƒ½åŠ›ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ï¼Œæä¾›äº†æ–°çš„è¯„ä¼°è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è¯„ä¼°è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†å¤šç§è¯„ä¼°æŒ‡æ ‡æ¥é‡åŒ–æ¨¡å‹çš„è¯†åˆ«èƒ½åŠ›ï¼Œç‰¹åˆ«å…³æ³¨ä¸åŒç±»å‹é”™è¯¯å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œç¡®ä¿è¯„ä¼°ç»“æœçš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¤§å¤šæ•°æ¨¡å‹åœ¨è¯†åˆ«é€»è¾‘è°¬è¯¯æ—¶è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨è¡¨é¢è¯­è¨€é”™è¯¯å’Œæ¡ä»¶ç¼ºé™·çš„è¯†åˆ«ä¸Šå­˜åœ¨æ˜æ˜¾ä¸è¶³ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨é€»è¾‘è°¬è¯¯è¯†åˆ«ä¸Šçš„å‡†ç¡®ç‡é«˜è¾¾70%ï¼Œè€Œåœ¨è¡¨é¢è¯­è¨€é”™è¯¯è¯†åˆ«ä¸Šä»…ä¸º40%ã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†æ¨¡å‹åœ¨ä¸åŒç±»å‹é”™è¯¯è¯†åˆ«ä¸Šçš„æ€§èƒ½å·®å¼‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€è‡ªåŠ¨å†…å®¹å®¡æ ¸å’Œäººæœºäº¤äº’ç­‰åœºæ™¯ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€æ¨¡å‹å¯¹è¾“å…¥æœ‰æ•ˆæ€§çš„ä¸»åŠ¨éªŒè¯èƒ½åŠ›ï¼Œå¯ä»¥æ˜¾è‘—æé«˜ç³»ç»Ÿçš„é²æ£’æ€§å’Œç”¨æˆ·ä½“éªŒï¼Œæœªæ¥å¯èƒ½åœ¨å¤šä¸ªè¡Œä¸šä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Multimodal Models (LMMs) have witnessed remarkable growth, showcasing formidable capabilities in handling intricate multimodal tasks with exceptional performance. Recent research has underscored the inclination of large language models to passively accept defective inputs, often resulting in futile reasoning on invalid prompts. However, the same critical question of whether LMMs can actively detect and scrutinize erroneous inputs still remains unexplored. To address this gap, we introduce the Input Scrutiny Ability Evaluation Framework (ISEval), which encompasses seven categories of flawed premises and three evaluation metrics. Our extensive evaluation of ten advanced LMMs has identified key findings. Most models struggle to actively detect flawed textual premises without guidance, which reflects a strong reliance on explicit prompts for premise error identification. Error type affects performance: models excel at identifying logical fallacies but struggle with surface-level linguistic errors and certain conditional flaws. Modality trust varies-Gemini 2.5 pro and Claude Sonnet 4 balance visual and textual info, while aya-vision-8b over-rely on text in conflicts. These insights underscore the urgent need to enhance LMMs' proactive verification of input validity and shed novel insights into mitigating the problem. The code is available at https://github.com/MLGroupJLU/LMM_ISEval.

