---
layout: default
title: Worst-case generation via minimax optimization in Wasserstein space
---

# Worst-case generation via minimax optimization in Wasserstein space

**arXiv**: [2512.08176v1](https://arxiv.org/abs/2512.08176) | [PDF](https://arxiv.org/pdf/2512.08176.pdf)

**ä½œè€…**: Xiuyuan Cheng, Yao Xie, Linglingzhi Zhu, Yunqin Zhu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽWassersteinç©ºé—´æžå°æžå¤§ä¼˜åŒ–çš„æœ€åæƒ…å†µç”Ÿæˆæ¡†æž¶ï¼Œç”¨äºŽè¯„ä¼°ç³»ç»Ÿåœ¨åˆ†å¸ƒåç§»ä¸‹çš„é²æ£’æ€§ã€‚**

**å…³é”®è¯**: `æœ€åæƒ…å†µç”Ÿæˆ` `Wassersteinç©ºé—´` `æžå°æžå¤§ä¼˜åŒ–` `åˆ†å¸ƒé²æ£’ä¼˜åŒ–` `æ¢¯åº¦ä¸‹é™ä¸Šå‡` `ç¥žç»ç½‘ç»œå‚æ•°åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿç¦»æ•£åˆ†å¸ƒé²æ£’ä¼˜åŒ–æ–¹æ³•å­˜åœ¨å¯æ‰©å±•æ€§å·®ã€æ³›åŒ–æœ‰é™å’Œæœ€åæƒ…å†µæŽ¨æ–­æˆæœ¬é«˜çš„é—®é¢˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨Brenierå®šç†å°†æœ€ååˆ†å¸ƒè¡¨å¾ä¸ºè¿žç»­å‚è€ƒæµ‹åº¦çš„æŽ¨å‰æ˜ å°„ï¼Œå®žçŽ°è¿žç»­ä¸”è¡¨è¾¾æ€§å¼ºçš„é£Žé™©è¯±å¯¼ç”Ÿæˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šé€šè¿‡åˆæˆå’Œå›¾åƒæ•°æ®å®žéªŒéªŒè¯äº†æ–¹æ³•ä½œä¸ºé£Žé™©è¯±å¯¼æœ€åæƒ…å†µç”Ÿæˆå™¨çš„æ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Worst-case generation plays a critical role in evaluating robustness and stress-testing systems under distribution shifts, in applications ranging from machine learning models to power grids and medical prediction systems. We develop a generative modeling framework for worst-case generation for a pre-specified risk, based on min-max optimization over continuous probability distributions, namely the Wasserstein space. Unlike traditional discrete distributionally robust optimization approaches, which often suffer from scalability issues, limited generalization, and costly worst-case inference, our framework exploits the Brenier theorem to characterize the least favorable (worst-case) distribution as the pushforward of a transport map from a continuous reference measure, enabling a continuous and expressive notion of risk-induced generation beyond classical discrete DRO formulations. Based on the min-max formulation, we propose a Gradient Descent Ascent (GDA)-type scheme that updates the decision model and the transport map in a single loop, establishing global convergence guarantees under mild regularity assumptions and possibly without convexity-concavity. We also propose to parameterize the transport map using a neural network that can be trained simultaneously with the GDA iterations by matching the transported training samples, thereby achieving a simulation-free approach. The efficiency of the proposed method as a risk-induced worst-case generator is validated by numerical experiments on synthetic and image data.

