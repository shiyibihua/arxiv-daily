---
layout: default
title: Thinking with Images via Self-Calling Agent
---

# Thinking with Images via Self-Calling Agent

**arXiv**: [2512.08511v1](https://arxiv.org/abs/2512.08511) | [PDF](https://arxiv.org/pdf/2512.08511.pdf)

**ä½œè€…**: Wenxi Yang, Yuzhong Zhao, Fang Wan, Qixiang Ye

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªè°ƒç”¨æ€ç»´é“¾ä»¥ä¼˜åŒ–è§†è§‰æŽ¨ç†ï¼Œé€šè¿‡è¯­è¨€åŒ–å¤„ç†æå‡è®­ç»ƒæ•ˆçŽ‡ä¸Žæ€§èƒ½ã€‚**

**å…³é”®è¯**: `è§†è§‰æŽ¨ç†` `æ€ç»´é“¾` `è‡ªè°ƒç”¨ä»£ç†` `å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–` `å¤šæ¨¡æ€å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šæ¨¡æ€æ€ç»´é“¾ä¾èµ–é«˜è´¨é‡æ•°æ®ï¼Œå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å›°éš¾ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†è§†è§‰æŽ¨ç†é‡æž„ä¸ºçº¯è¯­è¨€æ€ç»´é“¾ï¼Œä½¿ç”¨è‡ªè°ƒç”¨ä»£ç†åˆ†è§£ä»»åŠ¡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨HR-Bench 4Kä¸Šæ€§èƒ½æå‡1.9%ï¼ŒGPUæ—¶é—´å‡å°‘çº¦75%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Thinking-with-images paradigms have showcased remarkable visual reasoning capability by integrating visual information as dynamic elements into the Chain-of-Thought (CoT). However, optimizing interleaved multimodal CoT (iMCoT) through reinforcement learning remains challenging, as it relies on scarce high-quality reasoning data. In this study, we propose Self-Calling Chain-of-Thought (sCoT), a novel visual reasoning paradigm that reformulates iMCoT as a language-only CoT with self-calling. Specifically, a main agent decomposes the complex visual reasoning task to atomic subtasks and invokes its virtual replicas, i.e. parameter-sharing subagents, to solve them in isolated context. sCoT enjoys substantial training effectiveness and efficiency, as it requires no explicit interleaving between modalities. sCoT employs group-relative policy optimization to reinforce effective reasoning behavior to enhance optimization. Experiments on HR-Bench 4K show that sCoT improves the overall reasoning performance by up to $1.9\%$ with $\sim 75\%$ fewer GPU hours compared to strong baseline approaches. Code is available at https://github.com/YWenxi/think-with-images-through-self-calling.

