---
layout: default
title: LoFA: Learning to Predict Personalized Priors for Fast Adaptation of Visual Generative Models
---

# LoFA: Learning to Predict Personalized Priors for Fast Adaptation of Visual Generative Models

**arXiv**: [2512.08785v1](https://arxiv.org/abs/2512.08785) | [PDF](https://arxiv.org/pdf/2512.08785.pdf)

**ä½œè€…**: Yiming Hao, Mutian Xu, Chongjie Ye, Jie Qin, Shunlin Lu, Yipeng Qin, Xiaoguang Han

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLoFAæ¡†æž¶ä»¥å¿«é€Ÿé¢„æµ‹ä¸ªæ€§åŒ–å…ˆéªŒï¼Œå®žçŽ°è§†è§‰ç”Ÿæˆæ¨¡åž‹çš„é«˜æ•ˆé€‚é…**

**å…³é”®è¯**: `è§†è§‰ç”Ÿæˆæ¨¡åž‹` `ä¸ªæ€§åŒ–é€‚é…` `è¶…ç½‘ç»œ` `å¿«é€Ÿä¼˜åŒ–` `LoRAåˆ†å¸ƒé¢„æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•å¦‚LoRAéœ€ä»»åŠ¡ç‰¹å®šæ•°æ®å’Œé•¿æ—¶é—´ä¼˜åŒ–ï¼Œè¶…ç½‘ç»œæ–¹æ³•éš¾ä»¥æ˜ å°„ç»†ç²’åº¦æç¤ºåˆ°å¤æ‚LoRAåˆ†å¸ƒ
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽLoRAå‚æ•°ç›¸å¯¹å˜åŒ–çš„ç»“æž„åŒ–åˆ†å¸ƒæ¨¡å¼ï¼Œè®¾è®¡ä¸¤é˜¶æ®µè¶…ç½‘ç»œé¢„æµ‹ç›¸å¯¹åˆ†å¸ƒæ¨¡å¼å¹¶æŒ‡å¯¼æœ€ç»ˆæƒé‡é¢„æµ‹
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªä»»åŠ¡å’Œç”¨æˆ·æç¤ºä¸‹ï¼Œç§’çº§é¢„æµ‹é«˜è´¨é‡ä¸ªæ€§åŒ–å…ˆéªŒï¼Œæ€§èƒ½ä¼˜äºŽéœ€æ•°å°æ—¶å¤„ç†çš„ä¼ ç»ŸLoRA

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Personalizing visual generative models to meet specific user needs has gained increasing attention, yet current methods like Low-Rank Adaptation (LoRA) remain impractical due to their demand for task-specific data and lengthy optimization. While a few hypernetwork-based approaches attempt to predict adaptation weights directly, they struggle to map fine-grained user prompts to complex LoRA distributions, limiting their practical applicability. To bridge this gap, we propose LoFA, a general framework that efficiently predicts personalized priors for fast model adaptation. We first identify a key property of LoRA: structured distribution patterns emerge in the relative changes between LoRA and base model parameters. Building on this, we design a two-stage hypernetwork: first predicting relative distribution patterns that capture key adaptation regions, then using these to guide final LoRA weight prediction. Extensive experiments demonstrate that our method consistently predicts high-quality personalized priors within seconds, across multiple tasks and user prompts, even outperforming conventional LoRA that requires hours of processing. Project page: https://jaeger416.github.io/lofa/.

