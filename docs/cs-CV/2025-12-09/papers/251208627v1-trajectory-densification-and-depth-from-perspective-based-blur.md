---
layout: default
title: Trajectory Densification and Depth from Perspective-based Blur
---

# Trajectory Densification and Depth from Perspective-based Blur

**arXiv**: [2512.08627v1](https://arxiv.org/abs/2512.08627) | [PDF](https://arxiv.org/pdf/2512.08627.pdf)

**ä½œè€…**: Tianchen Qiu, Qirun Zhang, Jiajian He, Zhengyue Zhuge, Jiahui Xu, Yueting Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽé€è§†æ¨¡ç³Šçš„æ·±åº¦ä¼°è®¡ä¸Žè½¨è¿¹ç¨ å¯†åŒ–æ–¹æ³•ï¼Œç”¨äºŽæ‰‹æŒé•¿æ›å…‰è§†é¢‘åœºæ™¯ã€‚**

**å…³é”®è¯**: `æ·±åº¦ä¼°è®¡` `é€è§†æ¨¡ç³Š` `è½¨è¿¹ç¨ å¯†åŒ–` `æ‰‹æŒè§†é¢‘` `è§†è§‰è¯­è¨€æ¨¡åž‹` `å¤šçª—å£èšåˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‰‹æŒç›¸æœºæ—‹è½¬å¯¼è‡´é€è§†æ¨¡ç³Šï¼Œå…¶ç¨‹åº¦ä¾èµ–ç‰©ä½“æ·±åº¦ï¼Œå½±å“è§†é¢‘è´¨é‡ä¸Žæ·±åº¦ä¼°è®¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆè§†è§‰ç¼–ç å™¨ä¸Žç‚¹è·Ÿè¸ªå™¨æå–ä¿¡æ¯ï¼Œé€šè¿‡çª—å£åµŒå…¥å’Œå¤šçª—å£èšåˆä¼°è®¡æ·±åº¦å›¾ï¼Œå¹¶åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡åž‹ç¨ å¯†åŒ–ç¨€ç–è½¨è¿¹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªæ·±åº¦æ•°æ®é›†ä¸Šè¡¨çŽ°ä¼˜å¼‚ï¼Œæ³›åŒ–èƒ½åŠ›å¼ºï¼Œè½¨è¿¹é‡å»ºç²¾åº¦é«˜ï¼Œä¼˜äºŽçœŸå®žæ‰‹æŒæ‹æ‘„è½¨è¿¹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In the absence of a mechanical stabilizer, the camera undergoes inevitable rotational dynamics during capturing, which induces perspective-based blur especially under long-exposure scenarios. From an optical standpoint, perspective-based blur is depth-position-dependent: objects residing at distinct spatial locations incur different blur levels even under the same imaging settings. Inspired by this, we propose a novel method that estimate metric depth by examining the blur pattern of a video stream and dense trajectory via joint optical design algorithm. Specifically, we employ off-the-shelf vision encoder and point tracker to extract video information. Then, we estimate depth map via windowed embedding and multi-window aggregation, and densify the sparse trajectory from the optical algorithm using a vision-language model. Evaluations on multiple depth datasets demonstrate that our method attains strong performance over large depth range, while maintaining favorable generalization. Relative to the real trajectory in handheld shooting settings, our optical algorithm achieves superior precision and the dense reconstruction maintains strong accuracy.

