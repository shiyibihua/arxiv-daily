---
layout: default
title: PaintFlow: A Unified Framework for Interactive Oil Paintings Editing and Generation
---

# PaintFlow: A Unified Framework for Interactive Oil Paintings Editing and Generation

**arXiv**: [2512.08534v1](https://arxiv.org/abs/2512.08534) | [PDF](https://arxiv.org/pdf/2512.08534.pdf)

**ä½œè€…**: Zhangli Hu, Ye Chen, Jiajun Yao, Bingbing Ni

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPaintFlowç»Ÿä¸€æ¡†æž¶ï¼Œé€šè¿‡å¤šæ¨¡æ€äº¤äº’å®žçŽ°æ²¹ç”»ç”Ÿæˆä¸Žç¼–è¾‘ï¼Œè§£å†³é£Žæ ¼ä¸€è‡´æ€§å’Œè¯­ä¹‰æŽ§åˆ¶éš¾é¢˜ã€‚**

**å…³é”®è¯**: `æ²¹ç”»ç”Ÿæˆ` `äº¤äº’ç¼–è¾‘` `å¤šæ¨¡æ€æ¡†æž¶` `é£Žæ ¼è¿ç§»` `è¯­ä¹‰æŽ§åˆ¶` `è‡ªç›‘ç£å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ²¹ç”»æ•°å­—ç”Ÿæˆä¸Žç¼–è¾‘å› å¤æ‚ç¬”è§¦å’Œé£Žæ ¼åŒ–ç‰¹æ€§è€Œå—é™ï¼ŒçŽ°æœ‰æ–¹æ³•ä¾èµ–è®­ç»ƒæ•°æ®åˆ†å¸ƒä¸”å¤šé’ˆå¯¹çœŸå®žç…§ç‰‡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆç©ºé—´å¯¹é½ä¸Žè¯­ä¹‰å¢žå¼ºæ¡ä»¶ç­–ç•¥ã€åŸºäºŽSBRçš„è‡ªç›‘ç£é£Žæ ¼è¿ç§»ç®¡é“ï¼Œä»¥åŠAdaINç‰¹å¾èžåˆï¼Œå®žçŽ°å¤šæ¨¡æ€äº¤äº’æŽ§åˆ¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç³»ç»Ÿæ”¯æŒå‚è€ƒå›¾åƒã€æ‰‹ç»˜è‰å›¾å’Œè‡ªç„¶è¯­è¨€æç¤ºï¼Œä¿æŒç»Ÿä¸€æ²¹ç”»é£Žæ ¼ï¼Œå®žéªŒè¯æ˜Žèƒ½ç²¾ç»†ç¼–è¾‘å¹¶ä¿ç•™è‰ºæœ¯å“è´¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Oil painting, as a high-level medium that blends human abstract thinking with artistic expression, poses substantial challenges for digital generation and editing due to its intricate brushstroke dynamics and stylized characteristics. Existing generation and editing techniques are often constrained by the distribution of training data and primarily focus on modifying real photographs. In this work, we introduce a unified multimodal framework for oil painting generation and editing. The proposed system allows users to incorporate reference images for precise semantic control, hand-drawn sketches for spatial structure alignment, and natural language prompts for high-level semantic guidance, while consistently maintaining a unified painting style across all outputs. Our method achieves interactive oil painting creation through three crucial technical advancements. First, we enhance the training stage with spatial alignment and semantic enhancement conditioning strategy, which map masks and sketches into spatial constraints, and encode contextual embedding from reference images and text into feature constraints, enabling object-level semantic alignment. Second, to overcome data scarcity, we propose a self-supervised style transfer pipeline based on Stroke-Based Rendering (SBR), which simulates the inpainting dynamics of oil painting restoration, converting real images into stylized oil paintings with preserved brushstroke textures to construct a large-scale paired training dataset. Finally, during inference, we integrate features using the AdaIN operator to ensure stylistic consistency. Extensive experiments demonstrate that our interactive system enables fine-grained editing while preserving the artistic qualities of oil paintings, achieving an unprecedented level of imagination realization in stylized oil paintings generation and editing.

