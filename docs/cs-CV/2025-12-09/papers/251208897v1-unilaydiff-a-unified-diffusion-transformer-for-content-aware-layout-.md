---
layout: default
title: UniLayDiff: A Unified Diffusion Transformer for Content-Aware Layout Generation
---

# UniLayDiff: A Unified Diffusion Transformer for Content-Aware Layout Generation

**arXiv**: [2512.08897v1](https://arxiv.org/abs/2512.08897) | [PDF](https://arxiv.org/pdf/2512.08897.pdf)

**ä½œè€…**: Zeyang Liu, Le Wang, Sanping Zhou, Yuxuan Wu, Xiaolong Sun, Gang Hua, Haoxiang Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUniLayDiffç»Ÿä¸€æ‰©æ•£Transformerï¼Œä»¥å•æ¨¡åž‹è§£å†³å†…å®¹æ„ŸçŸ¥å¸ƒå±€ç”Ÿæˆçš„å¤šä»»åŠ¡æŒ‘æˆ˜ã€‚**

**å…³é”®è¯**: `å†…å®¹æ„ŸçŸ¥å¸ƒå±€ç”Ÿæˆ` `æ‰©æ•£Transformer` `å¤šæ¨¡æ€å­¦ä¹ ` `ç»Ÿä¸€æ¨¡åž‹` `æ¡ä»¶ç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•æ— æ³•ç»Ÿä¸€å¤„ç†å…ƒç´ ç±»åž‹ã€å°ºå¯¸æˆ–å…³ç³»ç­‰å¤šæ ·çº¦æŸçš„å¸ƒå±€ç”Ÿæˆå­ä»»åŠ¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†å¸ƒå±€çº¦æŸä½œä¸ºç‹¬ç«‹æ¨¡æ€ï¼Œé‡‡ç”¨å¤šæ¨¡æ€æ‰©æ•£Transformeræ¡†æž¶æ•èŽ·èƒŒæ™¯ã€å…ƒç´ ä¸Žçº¦æŸçš„äº¤äº’ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ— æ¡ä»¶åˆ°å¤šç§æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸­è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œé¦–æ¬¡ç»Ÿä¸€å…¨èŒƒå›´å†…å®¹æ„ŸçŸ¥å¸ƒå±€ç”Ÿæˆã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Content-aware layout generation is a critical task in graphic design automation, focused on creating visually appealing arrangements of elements that seamlessly blend with a given background image. The variety of real-world applications makes it highly challenging to develop a single model capable of unifying the diverse range of input-constrained generation sub-tasks, such as those conditioned by element types, sizes, or their relationships. Current methods either address only a subset of these tasks or necessitate separate model parameters for different conditions, failing to offer a truly unified solution. In this paper, we propose UniLayDiff: a Unified Diffusion Transformer, that for the first time, addresses various content-aware layout generation tasks with a single, end-to-end trainable model. Specifically, we treat layout constraints as a distinct modality and employ Multi-Modal Diffusion Transformer framework to capture the complex interplay between the background image, layout elements, and diverse constraints. Moreover, we integrate relation constraints through fine-tuning the model with LoRA after pretraining the model on other tasks. Such a schema not only achieves unified conditional generation but also enhances overall layout quality. Extensive experiments demonstrate that UniLayDiff achieves state-of-the-art performance across from unconditional to various conditional generation tasks and, to the best of our knowledge, is the first model to unify the full range of content-aware layout generation tasks.

