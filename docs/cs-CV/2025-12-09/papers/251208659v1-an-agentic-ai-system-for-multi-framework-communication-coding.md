---
layout: default
title: An Agentic AI System for Multi-Framework Communication Coding
---

# An Agentic AI System for Multi-Framework Communication Coding

**arXiv**: [2512.08659v1](https://arxiv.org/abs/2512.08659) | [PDF](https://arxiv.org/pdf/2512.08659.pdf)

**ä½œè€…**: Bohao Yang, Rui Yang, Joshua M. Biro, Haoyuan Wang, Jessica L. Handley, Brianna Richardson, Sophia Bessias, Nicoleta Economou-Zavlanos, Armando D. Bedoya, Monica Agrawal, Michael M. Zavlanos, Anand Chowdhury, Raj M. Ratwani, Kai Sun, Kathryn I. Pollak, Michael J. Pencina, Chuan Hong

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå¤šæ™ºèƒ½ä½“æž¶æž„çš„MOSAICç³»ç»Ÿï¼Œç”¨äºŽä¸´åºŠæ²Ÿé€šç¼–ç ä»¥è§£å†³æ ‡æ³¨å¯æ‰©å±•æ€§é—®é¢˜ã€‚**

**å…³é”®è¯**: `ä¸´åºŠæ²Ÿé€šç¼–ç ` `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `æ£€ç´¢å¢žå¼ºç”Ÿæˆ` `åŠ¨æ€å°‘æ ·æœ¬æç¤º` `LangGraphæž¶æž„`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¸´åºŠæ²Ÿé€šæ ‡æ³¨ä¾èµ–äººå·¥ï¼Œå­˜åœ¨åŠ³åŠ¨å¯†é›†ã€ä¸ä¸€è‡´å’Œéš¾ä»¥æ‰©å±•çš„æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨LangGraphæž¶æž„åè°ƒå››ä¸ªæ ¸å¿ƒæ™ºèƒ½ä½“ï¼Œç»“åˆæ£€ç´¢å¢žå¼ºç”Ÿæˆå’ŒåŠ¨æ€å°‘æ ·æœ¬æç¤ºè¿›è¡Œç¼–ç ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨é£Žæ¹¿ç—…å’Œå¦‡äº§ç§‘é¢†åŸŸæµ‹è¯•ï¼Œæ•´ä½“F1åˆ†æ•°è¾¾0.928ï¼Œä¼˜äºŽåŸºå‡†æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Clinical communication is central to patient outcomes, yet large-scale human annotation of patient-provider conversation remains labor-intensive, inconsistent, and difficult to scale. Existing approaches based on large language models typically rely on single-task models that lack adaptability, interpretability, and reliability, especially when applied across various communication frameworks and clinical domains. In this study, we developed a Multi-framework Structured Agentic AI system for Clinical Communication (MOSAIC), built on a LangGraph-based architecture that orchestrates four core agents, including a Plan Agent for codebook selection and workflow planning, an Update Agent for maintaining up-to-date retrieval databases, a set of Annotation Agents that applies codebook-guided retrieval-augmented generation (RAG) with dynamic few-shot prompting, and a Verification Agent that provides consistency checks and feedback. To evaluate performance, we compared MOSAIC outputs against gold-standard annotations created by trained human coders. We developed and evaluated MOSAIC using 26 gold standard annotated transcripts for training and 50 transcripts for testing, spanning rheumatology and OB/GYN domains. On the test set, MOSAIC achieved an overall F1 score of 0.928. Performance was highest in the Rheumatology subset (F1 = 0.962) and strongest for Patient Behavior (e.g., patients asking questions, expressing preferences, or showing assertiveness). Ablations revealed that MOSAIC outperforms baseline benchmarking.

