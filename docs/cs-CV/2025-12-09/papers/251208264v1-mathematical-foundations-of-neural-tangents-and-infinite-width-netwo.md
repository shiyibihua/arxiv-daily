---
layout: default
title: Mathematical Foundations of Neural Tangents and Infinite-Width Networks
---

# Mathematical Foundations of Neural Tangents and Infinite-Width Networks

**arXiv**: [2512.08264v1](https://arxiv.org/abs/2512.08264) | [PDF](https://arxiv.org/pdf/2512.08264.pdf)

**ä½œè€…**: Rachana Mysore, Preksha Girish, Kavitha Jayaram, Shrey Kumar, Preksha Girish, Shravan Sanjeev Bagal, Kavitha Jayaram, Shreya Aravind Shastry

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNTK-ECRNæž¶æž„ä»¥åˆ†æžæ— é™å®½åº¦ç¥žç»ç½‘ç»œä¸­çš„æ ¸æ¼”åŒ–**

**å…³é”®è¯**: `ç¥žç»æ­£åˆ‡æ ¸` `æ— é™å®½åº¦ç½‘ç»œ` `æ ¸æ¼”åŒ–åˆ†æž` `è®­ç»ƒç¨³å®šæ€§` `æ³›åŒ–ç†è®º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç ”ç©¶æ— é™å®½åº¦ç¥žç»ç½‘ç»œä¸­ç¥žç»æ­£åˆ‡æ ¸çš„æ•°å­¦åŸºç¡€
2. æå‡ºNTK-ECRNæž¶æž„ï¼Œé›†æˆå‚…é‡Œå¶ç‰¹å¾åµŒå…¥å’Œæ®‹å·®è¿žæŽ¥
3. ç†è®ºæŽ¨å¯¼NTKåŠ¨æ€è¾¹ç•Œï¼Œå®žéªŒéªŒè¯è®­ç»ƒç¨³å®šæ€§å’Œæ³›åŒ–æå‡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We investigate the mathematical foundations of neural networks in the infinite-width regime through the Neural Tangent Kernel (NTK). We propose the NTK-Eigenvalue-Controlled Residual Network (NTK-ECRN), an architecture integrating Fourier feature embeddings, residual connections with layerwise scaling, and stochastic depth to enable rigorous analysis of kernel evolution during training. Our theoretical contributions include deriving bounds on NTK dynamics, characterizing eigenvalue evolution, and linking spectral properties to generalization and optimization stability. Empirical results on synthetic and benchmark datasets validate the predicted kernel behavior and demonstrate improved training stability and generalization. This work provides a comprehensive framework bridging infinite-width theory and practical deep-learning architectures.

