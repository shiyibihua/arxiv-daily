---
layout: default
title: Bridging Scale Discrepancies in Robotic Control via Language-Based Action Representations
---

# Bridging Scale Discrepancies in Robotic Control via Language-Based Action Representations

**arXiv**: [2512.08548v1](https://arxiv.org/abs/2512.08548) | [PDF](https://arxiv.org/pdf/2512.08548.pdf)

**ä½œè€…**: Yuchi Zhang, Churui Sun, Shiqi Liang, Diyuan Liu, Chao Ji, Wei-Nan Zhang, Ting Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè¯­è¨€çš„åŠ¨ä½œè¡¨ç¤ºä»¥è§£å†³æœºå™¨äººæŽ§åˆ¶ä¸­çš„å°ºåº¦å·®å¼‚é—®é¢˜**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `åŠ¨ä½œè¡¨ç¤º` `é¢„è®­ç»ƒ` `æ³›åŒ–æ€§èƒ½` `è¯­è¨€æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨äººåŠ¨ä½œæ•°æ®å› å¹³å°å’Œä»»åŠ¡å·®å¼‚å¯¼è‡´æ•°å€¼å°ºåº¦å˜åŒ–ï¼Œé˜»ç¢é¢„è®­ç»ƒçŸ¥è¯†è¿ç§»ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨è¯­ä¹‰åŸºç¡€çš„è¯­è¨€è¡¨ç¤ºï¼Œå¿½ç•¥æ•°å€¼å°ºåº¦ï¼Œå¼ºè°ƒæ–¹å‘æ€§ï¼Œä»¥å½’ä¸€åŒ–åŠ¨ä½œã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡æœºå™¨äººæ“ä½œä»»åŠ¡çš„æ³›åŒ–æ€§èƒ½å’Œå¯è½¬ç§»æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent end-to-end robotic manipulation research increasingly adopts architectures inspired by large language models to enable robust manipulation. However, a critical challenge arises from severe distribution shifts between robotic action data, primarily due to substantial numerical variations in action commands across diverse robotic platforms and tasks, hindering the effective transfer of pretrained knowledge. To address this limitation, we propose a semantically grounded linguistic representation to normalize actions for efficient pretraining. Unlike conventional discretized action representations that are sensitive to numerical scales, the motion representation specifically disregards numeric scale effects, emphasizing directionality instead. This abstraction mitigates distribution shifts, yielding a more generalizable pretraining representation. Moreover, using the motion representation narrows the feature distance between action tokens and standard vocabulary tokens, mitigating modality gaps. Multi-task experiments on two benchmarks demonstrate that the proposed method significantly improves generalization performance and transferability in robotic manipulation tasks.

