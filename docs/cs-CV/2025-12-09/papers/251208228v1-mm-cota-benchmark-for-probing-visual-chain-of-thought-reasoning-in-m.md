---
layout: default
title: MM-CoT:A Benchmark for Probing Visual Chain-of-Thought Reasoning in Multimodal Models
---

# MM-CoT:A Benchmark for Probing Visual Chain-of-Thought Reasoning in Multimodal Models

**arXiv**: [2512.08228v1](https://arxiv.org/abs/2512.08228) | [PDF](https://arxiv.org/pdf/2512.08228.pdf)

**ä½œè€…**: Jusheng Zhang, Kaitong Cai, Xiaoyang Guo, Sidi Liu, Qinhan Lv, Ruiqi Chen, Jing Yang, Yijia Fan, Xiaofei Sun, Jian Wang, Ziliang Chen, Liang Lin, Keze Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMM-CoTåŸºå‡†ä»¥è¯„ä¼°å¤šæ¨¡æ€æ¨¡åž‹è§†è§‰æ€ç»´é“¾æŽ¨ç†çš„è§†è§‰ä¸€è‡´æ€§ä¸Žé€»è¾‘è¿žè´¯æ€§**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨¡åž‹` `æ€ç»´é“¾æŽ¨ç†` `è§†è§‰ä¸€è‡´æ€§` `é€»è¾‘è¿žè´¯æ€§` `è¯Šæ–­åŸºå‡†` `è§†è§‰è¯­è¨€æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰åŸºå‡†å¿½è§†éªŒè¯ï¼Œæ— æ³•è¯„ä¼°å¤šæ¨¡æ€æ¨¡åž‹æ€ç»´é“¾æŽ¨ç†æ˜¯å¦åŸºäºŽè§†è§‰è¯æ®ä¸”é€»è¾‘è¿žè´¯
2. æ–¹æ³•è¦ç‚¹ï¼šè®¾è®¡è¯Šæ–­åŸºå‡†ï¼Œè¦æ±‚æ¨¡åž‹é€‰æ‹©æ»¡è¶³è§†è§‰ä¸€è‡´æ€§å’Œé€»è¾‘è¿žè´¯æ€§çº¦æŸçš„å”¯ä¸€äº‹ä»¶é“¾
3. å®žéªŒæˆ–æ•ˆæžœï¼šè¯„ä¼°é¢†å…ˆæ¨¡åž‹å‘çŽ°å…¶è¡¨çŽ°ä¸ä½³ï¼Œæ­ç¤ºç”Ÿæˆæµç•…æ€§ä¸ŽçœŸå®žæŽ¨ç†ä¿çœŸåº¦é—´çš„å·®è·

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The ability to perform Chain-of-Thought (CoT) reasoning marks a major milestone for multimodal models (MMs), enabling them to solve complex visual reasoning problems. Yet a critical question remains: is such reasoning genuinely grounded in visual evidence and logically coherent? Existing benchmarks emphasize generation but neglect verification, i.e., the capacity to assess whether a reasoning chain is both visually consistent and logically valid. To fill this gap, we introduce MM-CoT, a diagnostic benchmark specifically designed to probe the visual grounding and logical coherence of CoT reasoning in MMs. Instead of generating free-form explanations, models must select the sole event chain that satisfies two orthogonal constraints: (i) visual consistency, ensuring all steps are anchored in observable evidence, and (ii) logical coherence, ensuring causal and commonsense validity. Adversarial distractors are engineered to violate one of these constraints, exposing distinct reasoning failures. We evaluate leading vision-language models on MM-CoT and find that even the most advanced systems struggle, revealing a sharp discrepancy between generative fluency and true reasoning fidelity. MM-CoT shows low correlation with existing benchmarks, confirming that it measures a unique combination of visual grounding and logical reasoning. This benchmark provides a foundation for developing future models that reason not just plausibly, but faithfully and coherently within the visual world.

