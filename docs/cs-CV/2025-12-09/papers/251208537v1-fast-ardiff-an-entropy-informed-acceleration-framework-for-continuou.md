---
layout: default
title: Fast-ARDiff: An Entropy-informed Acceleration Framework for Continuous Space Autoregressive Generation
---

# Fast-ARDiff: An Entropy-informed Acceleration Framework for Continuous Space Autoregressive Generation

**arXiv**: [2512.08537v1](https://arxiv.org/abs/2512.08537) | [PDF](https://arxiv.org/pdf/2512.08537.pdf)

**ä½œè€…**: Zhen Zou, Xiaoxiao Ma, Jie Huang, Zichao Yu, Feng Zhao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFast-ARDiffæ¡†æž¶ï¼Œé€šè¿‡ç†µå¼•å¯¼ç­–ç•¥å’Œè”åˆä¼˜åŒ–åŠ é€Ÿè‡ªå›žå½’-æ‰©æ•£æ··åˆç”Ÿæˆ**

**å…³é”®è¯**: `è‡ªå›žå½’-æ‰©æ•£æ··åˆç”Ÿæˆ` `ç†µå¼•å¯¼åŠ é€Ÿ` `æŽ¨æµ‹è§£ç ` `è”åˆè’¸é¦è®­ç»ƒ` `åŠ¨æ€è°ƒåº¦å™¨` `å›¾åƒç”ŸæˆåŠ é€Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‡ªå›žå½’-æ‰©æ•£æ··åˆèŒƒå¼å› é¡ºåºç”Ÿæˆå’Œè¿­ä»£åŽ»å™ªå¯¼è‡´é«˜å»¶è¿Ÿ
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ç†µå¼•å¯¼æŽ¨æµ‹è§£ç å’ŒåŠ¨æ€è°ƒåº¦å™¨è”åˆä¼˜åŒ–è‡ªå›žå½’ä¸Žæ‰©æ•£ç»„ä»¶
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ImageNet 256Ã—256ä¸Šå®žçŽ°4.3å€æ— æŸåŠ é€Ÿï¼Œæ–‡æœ¬æ¡ä»¶ç”ŸæˆåŠ é€Ÿ3å€

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Autoregressive(AR)-diffusion hybrid paradigms combine AR's structured modeling with diffusion's photorealistic synthesis, yet suffer from high latency due to sequential AR generation and iterative denoising. In this work, we tackle this bottleneck and propose a unified AR-diffusion framework Fast-ARDiff that jointly optimizes both components, accelerating AR speculative decoding while simultaneously facilitating faster diffusion decoding. Specifically: (1) The entropy-informed speculative strategy encourages draft model to produce higher-entropy representations aligned with target model's entropy characteristics, mitigating entropy mismatch and high rejection rates caused by draft overconfidence. (2) For diffusion decoding, rather than treating it as an independent module, we integrate it into the same end-to-end framework using a dynamic scheduler that prioritizes AR optimization to guide the diffusion part in further steps. The diffusion part is optimized through a joint distillation framework combining trajectory and distribution matching, ensuring stable training and high-quality synthesis with extremely few steps. During inference, shallow feature entropy from AR module is used to pre-filter low-entropy drafts, avoiding redundant computation and improving latency. Fast-ARDiff achieves state-of-the-art acceleration across diverse models: on ImageNet 256$\times$256, TransDiff attains 4.3$\times$ lossless speedup, and NextStep-1 achieves 3$\times$ acceleration on text-conditioned generation. Code will be available at https://github.com/aSleepyTree/Fast-ARDiff.

