---
layout: default
title: Refining Visual Artifacts in Diffusion Models via Explainable AI-based Flaw Activation Maps
---

# Refining Visual Artifacts in Diffusion Models via Explainable AI-based Flaw Activation Maps

**arXiv**: [2512.08774v1](https://arxiv.org/abs/2512.08774) | [PDF](https://arxiv.org/pdf/2512.08774.pdf)

**‰ΩúËÄÖ**: Seoyeon Lee, Gwangyeol Yu, Chaewon Kim, Jonghyuk Park

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂèØËß£ÈáäAIÁöÑËá™Á≤æÁÇºÊâ©Êï£Ê°ÜÊû∂Ôºå‰ª•Ê£ÄÊµãÂπ∂‰øÆÂ§çÊâ©Êï£Ê®°Âûã‰∏≠ÁöÑËßÜËßâ‰º™ÂΩ±Âíå‰∏çÁúüÂÆûÂå∫Âüü„ÄÇ**

**ÂÖ≥ÈîÆËØç**: `Êâ©Êï£Ê®°Âûã` `ÂõæÂÉèÂêàÊàê` `ÂèØËß£ÈáäAI` `Áº∫Èô∑Ê£ÄÊµã` `ÂõæÂÉèÁ≤æÁÇº`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Êâ©Êï£Ê®°ÂûãÂú®ÂõæÂÉèÂêàÊàê‰∏≠Èù¢‰∏¥‰º™ÂΩ±Âíå‰∏çÁúüÂÆûÂå∫ÂüüÁöÑÂÖ≥ÈîÆÊåëÊàò„ÄÇ
2. Âà©Áî®ÂèØËß£ÈáäAIÁîüÊàêÁº∫Èô∑ÊøÄÊ¥ªÂõæÔºåÂú®Ê≠£ÂêëËøáÁ®ãÊîæÂ§ßÂô™Â£∞ÔºåÂèçÂêëËøáÁ®ãËÅöÁÑ¶‰øÆÂ§ç„ÄÇ
3. Âú®Â§öÁßçÊ®°ÂûãÂíå‰ªªÂä°‰∏äÂÆûÁé∞Fr√©chet inceptionË∑ùÁ¶ªÊèêÂçáÔºåÊúÄÈ´òËææ27.3%„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Diffusion models have achieved remarkable success in image synthesis. However, addressing artifacts and unrealistic regions remains a critical challenge. We propose self-refining diffusion, a novel framework that enhances image generation quality by detecting these flaws. The framework employs an explainable artificial intelligence (XAI)-based flaw highlighter to produce flaw activation maps (FAMs) that identify artifacts and unrealistic regions. These FAMs improve reconstruction quality by amplifying noise in flawed regions during the forward process and by focusing on these regions during the reverse process. The proposed approach achieves up to a 27.3% improvement in Fr√©chet inception distance across various diffusion-based models, demonstrating consistently strong performance on diverse datasets. It also shows robust effectiveness across different tasks, including image generation, text-to-image generation, and inpainting. These results demonstrate that explainable AI techniques can extend beyond interpretability to actively contribute to image refinement. The proposed framework offers a versatile and effective approach applicable to various diffusion models and tasks, significantly advancing the field of image synthesis.

