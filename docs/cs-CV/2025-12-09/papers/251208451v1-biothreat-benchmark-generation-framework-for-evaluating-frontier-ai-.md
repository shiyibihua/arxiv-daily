---
layout: default
title: Biothreat Benchmark Generation Framework for Evaluating Frontier AI Models II: Benchmark Generation Process
---

# Biothreat Benchmark Generation Framework for Evaluating Frontier AI Models II: Benchmark Generation Process

**arXiv**: [2512.08451v1](https://arxiv.org/abs/2512.08451) | [PDF](https://arxiv.org/pdf/2512.08451.pdf)

**ä½œè€…**: Gary Ackerman, Zachary Kallenborn, Anna Wetzel, Hayley Peterson, Jenna LaTourette, Olivia Shoemaker, Brandon Behlendorf, Sheriff Almakki, Doug Clifford, Noah Sheinbaum

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»†èŒç”Ÿç‰©å¨èƒåŸºå‡†ç”Ÿæˆæ¡†æž¶ï¼Œç”¨äºŽè¯„ä¼°å‰æ²¿AIæ¨¡åž‹çš„ç”Ÿç‰©å®‰å…¨é£Žé™©**

**å…³é”®è¯**: `ç”Ÿç‰©å®‰å…¨åŸºå‡†` `å‰æ²¿AIè¯„ä¼°` `çº¢é˜Ÿæµ‹è¯•` `åŸºå‡†ç”Ÿæˆæ¡†æž¶` `ç”Ÿç‰©å¨èƒåˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå‰æ²¿AIæ¨¡åž‹å¯èƒ½è¢«ç”¨äºŽç”Ÿç‰©ææ€–ä¸»ä¹‰ï¼Œéœ€é‡åŒ–å…¶ç”Ÿç‰©å®‰å…¨é£Žé™©
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡ç½‘é¡µæç¤ºç”Ÿæˆã€çº¢é˜Ÿæµ‹è¯•å’ŒæŒ–æŽ˜çŽ°æœ‰è¯­æ–™åº“ï¼Œç”Ÿæˆè¶…è¿‡7,000ä¸ªæ½œåœ¨åŸºå‡†
3. å®žéªŒæˆ–æ•ˆæžœï¼šç»è¿‡åŽ»é‡å’Œè¯Šæ–­æ€§è¯„ä¼°ï¼Œæœ€ç»ˆç­›é€‰å‡º1,010ä¸ªåŸºå‡†ï¼Œç¡®ä¿å…¶è¯Šæ–­æ€§ã€ç›¸å…³æ€§å’Œåˆ†æžå±‚æ¬¡å¯¹é½

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The potential for rapidly-evolving frontier artificial intelligence (AI) models, especially large language models (LLMs), to facilitate bioterrorism or access to biological weapons has generated significant policy, academic, and public concern. Both model developers and policymakers seek to quantify and mitigate any risk, with an important element of such efforts being the development of model benchmarks that can assess the biosecurity risk posed by a particular model. This paper, the second in a series of three, describes the second component of a novel Biothreat Benchmark Generation (BBG) framework: the generation of the Bacterial Biothreat Benchmark (B3) dataset. The development process involved three complementary approaches: 1) web-based prompt generation, 2) red teaming, and 3) mining existing benchmark corpora, to generate over 7,000 potential benchmarks linked to the Task-Query Architecture that was developed during the first component of the project. A process of de-duplication, followed by an assessment of uplift diagnosticity, and general quality control measures, reduced the candidates to a set of 1,010 final benchmarks. This procedure ensured that these benchmarks are a) diagnostic in terms of providing uplift; b) directly relevant to biosecurity threats; and c) are aligned with a larger biosecurity architecture permitting nuanced analysis at different levels of analysis.

