---
layout: default
title: Leveraging Multispectral Sensors for Color Correction in Mobile Cameras
---

# Leveraging Multispectral Sensors for Color Correction in Mobile Cameras

**arXiv**: [2512.08441v1](https://arxiv.org/abs/2512.08441) | [PDF](https://arxiv.org/pdf/2512.08441.pdf)

**ä½œè€…**: Luca Cogo, Marco Buzzelli, Simone Bianco, Javier Vazquez-Corral, Raimondo Schettini

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€å­¦ä¹ æ¡†æž¶ï¼Œåˆ©ç”¨å¤šå…‰è°±ä¼ æ„Ÿå™¨æå‡ç§»åŠ¨ç›¸æœºè‰²å½©æ ¡æ­£ç²¾åº¦**

**å…³é”®è¯**: `å¤šå…‰è°±æˆåƒ` `è‰²å½©æ ¡æ­£` `ç«¯åˆ°ç«¯å­¦ä¹ ` `ç§»åŠ¨ç›¸æœº` `ä¼ æ„Ÿå™¨èžåˆ` `å›¾åƒå¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•å¤šé˜¶æ®µå¤„ç†è‰²å½©æ ¡æ­£ï¼Œæ—©æœŸä¸¢å¼ƒå¤šå…‰è°±æ•°æ®ï¼Œå¯¼è‡´ä¿¡æ¯åˆ©ç”¨ä¸è¶³
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºç«¯åˆ°ç«¯å­¦ä¹ æ¡†æž¶ï¼Œè”åˆé«˜åˆ†è¾¨çŽ‡RGBä¸Žä½Žåˆ†è¾¨çŽ‡å¤šå…‰è°±ä¼ æ„Ÿå™¨æ•°æ®ï¼Œç»Ÿä¸€æ¨¡åž‹å¤„ç†
3. å®žéªŒæˆ–æ•ˆæžœï¼šé€šè¿‡é‡æž„ä¸¤ç§å…ˆè¿›æž¶æž„éªŒè¯ï¼Œåœ¨è‡ªå»ºæ•°æ®é›†ä¸Šå®žéªŒï¼Œè‰²å½©è¯¯å·®é™ä½Žè¾¾50%

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in snapshot multispectral (MS) imaging have enabled compact, low-cost spectral sensors for consumer and mobile devices. By capturing richer spectral information than conventional RGB sensors, these systems can enhance key imaging tasks, including color correction. However, most existing methods treat the color correction pipeline in separate stages, often discarding MS data early in the process. We propose a unified, learning-based framework that (i) performs end-to-end color correction and (ii) jointly leverages data from a high-resolution RGB sensor and an auxiliary low-resolution MS sensor. Our approach integrates the full pipeline within a single model, producing coherent and color-accurate outputs. We demonstrate the flexibility and generality of our framework by refactoring two different state-of-the-art image-to-image architectures. To support training and evaluation, we construct a dedicated dataset by aggregating and repurposing publicly available spectral datasets, rendering under multiple RGB camera sensitivities. Extensive experiments show that our approach improves color accuracy and stability, reducing error by up to 50% compared to RGB-only and MS-driven baselines. Datasets, code, and models will be made available upon acceptance.

