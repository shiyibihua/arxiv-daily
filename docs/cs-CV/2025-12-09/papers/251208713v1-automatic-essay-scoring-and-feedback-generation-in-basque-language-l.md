---
layout: default
title: Automatic Essay Scoring and Feedback Generation in Basque Language Learning
---

# Automatic Essay Scoring and Feedback Generation in Basque Language Learning

**arXiv**: [2512.08713v1](https://arxiv.org/abs/2512.08713) | [PDF](https://arxiv.org/pdf/2512.08713.pdf)

**ä½œè€…**: Ekhi Azurmendi, Xabier Arregi, Oier Lopez de Lacalle

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé¦–ä¸ªå·´æ–¯å…‹è¯­è‡ªåŠ¨ä½œæ–‡è¯„åˆ†ä¸Žåé¦ˆç”Ÿæˆæ•°æ®é›†åŠæ¨¡åž‹ï¼Œæå‡ä½Žèµ„æºè¯­è¨€æ•™è‚²NLPç ”ç©¶åŸºç¡€ã€‚**

**å…³é”®è¯**: `è‡ªåŠ¨ä½œæ–‡è¯„åˆ†` `åé¦ˆç”Ÿæˆ` `å·´æ–¯å…‹è¯­å¤„ç†` `ä½Žèµ„æºè¯­è¨€NLP` `æ¨¡åž‹å¾®è°ƒ` `æ•™è‚²æŠ€æœ¯`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå·´æ–¯å…‹è¯­ç­‰ä½Žèµ„æºè¯­è¨€ç¼ºä¹å…¬å¼€çš„è‡ªåŠ¨ä½œæ–‡è¯„åˆ†æ•°æ®é›†ä¸Žåé¦ˆç”ŸæˆåŸºå‡†ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºåŒ…å«3200ç¯‡C1æ°´å¹³ä½œæ–‡çš„æ•°æ®é›†ï¼Œå¹¶å¾®è°ƒRoBERTa-EusCrawlå’ŒLatxaæ¨¡åž‹è¿›è¡Œè¯„åˆ†ä¸Žè§£é‡Šç”Ÿæˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå¾®è°ƒLatxaæ¨¡åž‹åœ¨è¯„åˆ†ä¸€è‡´æ€§å’Œåé¦ˆè´¨é‡ä¸Šè¶…è¶ŠGPT-5ç­‰é—­æºç³»ç»Ÿï¼Œå¹¶å»ºç«‹æ–°è¯„ä¼°æ–¹æ³•éªŒè¯åé¦ˆæœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper introduces the first publicly available dataset for Automatic Essay Scoring (AES) and feedback generation in Basque, targeting the CEFR C1 proficiency level. The dataset comprises 3,200 essays from HABE, each annotated by expert evaluators with criterion specific scores covering correctness, richness, coherence, cohesion, and task alignment enriched with detailed feedback and error examples. We fine-tune open-source models, including RoBERTa-EusCrawl and Latxa 8B/70B, for both scoring and explanation generation. Our experiments show that encoder models remain highly reliable for AES, while supervised fine-tuning (SFT) of Latxa significantly enhances performance, surpassing state-of-the-art (SoTA) closed-source systems such as GPT-5 and Claude Sonnet 4.5 in scoring consistency and feedback quality. We also propose a novel evaluation methodology for assessing feedback generation, combining automatic consistency metrics with expert-based validation of extracted learner errors. Results demonstrate that the fine-tuned Latxa model produces criterion-aligned, pedagogically meaningful feedback and identifies a wider range of error types than proprietary models. This resource and benchmark establish a foundation for transparent, reproducible, and educationally grounded NLP research in low-resource languages such as Basque.

