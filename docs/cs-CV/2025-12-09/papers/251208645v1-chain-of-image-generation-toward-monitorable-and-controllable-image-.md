---
layout: default
title: Chain-of-Image Generation: Toward Monitorable and Controllable Image Generation
---

# Chain-of-Image Generation: Toward Monitorable and Controllable Image Generation

**arXiv**: [2512.08645v1](https://arxiv.org/abs/2512.08645) | [PDF](https://arxiv.org/pdf/2512.08645.pdf)

**ä½œè€…**: Young Kyung Kim, Oded Schlesinger, Yuzhou Zhao, J. Matias Di Martino, Guillermo Sapiro

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé“¾å¼å›¾åƒç”Ÿæˆæ¡†æž¶ä»¥å¢žå¼ºå›¾åƒç”Ÿæˆçš„å¯ç›‘æŽ§æ€§å’Œå¯æŽ§æ€§**

**å…³é”®è¯**: `å›¾åƒç”Ÿæˆ` `å¯ç›‘æŽ§æ€§` `å¯æŽ§æ€§` `é“¾å¼æŽ¨ç†` `è¯­ä¹‰åˆ†è§£` `æ¨¡åž‹æ— å…³æ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰å›¾åƒç”Ÿæˆæ¨¡åž‹å†…éƒ¨è¿‡ç¨‹ä¸é€æ˜Žï¼Œé™åˆ¶ç›‘æŽ§ã€å¹²é¢„å’Œå¯é æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡åž‹åˆ†è§£æç¤ºä¸ºé€æ­¥æŒ‡ä»¤ï¼Œå®žçŽ°è¯­ä¹‰åºåˆ—åŒ–ç”Ÿæˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šé€šè¿‡æ–°æŒ‡æ ‡è¯„ä¼°ç›‘æŽ§æ€§ï¼Œæå‡ç»„åˆé²æ£’æ€§ï¼Œæ¡†æž¶æ¨¡åž‹æ— å…³ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While state-of-the-art image generation models achieve remarkable visual quality, their internal generative processes remain a "black box." This opacity limits human observation and intervention, and poses a barrier to ensuring model reliability, safety, and control. Furthermore, their non-human-like workflows make them difficult for human observers to interpret. To address this, we introduce the Chain-of-Image Generation (CoIG) framework, which reframes image generation as a sequential, semantic process analogous to how humans create art. Similar to the advantages in monitorability and performance that Chain-of-Thought (CoT) brought to large language models (LLMs), CoIG can produce equivalent benefits in text-to-image generation. CoIG utilizes an LLM to decompose a complex prompt into a sequence of simple, step-by-step instructions. The image generation model then executes this plan by progressively generating and editing the image. Each step focuses on a single semantic entity, enabling direct monitoring. We formally assess this property using two novel metrics: CoIG Readability, which evaluates the clarity of each intermediate step via its corresponding output; and Causal Relevance, which quantifies the impact of each procedural step on the final generated image. We further show that our framework mitigates entity collapse by decomposing the complex generation task into simple subproblems, analogous to the procedural reasoning employed by CoT. Our experimental results indicate that CoIG substantially enhances quantitative monitorability while achieving competitive compositional robustness compared to established baseline models. The framework is model-agnostic and can be integrated with any image generation model.

