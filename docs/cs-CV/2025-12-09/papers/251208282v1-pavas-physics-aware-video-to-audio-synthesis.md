---
layout: default
title: PAVAS: Physics-Aware Video-to-Audio Synthesis
---

# PAVAS: Physics-Aware Video-to-Audio Synthesis

**arXiv**: [2512.08282v1](https://arxiv.org/abs/2512.08282) | [PDF](https://arxiv.org/pdf/2512.08282.pdf)

**ä½œè€…**: Oh Hyun-Bin, Yuhta Takida, Toshimitsu Uesaka, Tae-Hyun Oh, Yuki Mitsufuji

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPAVASæ–¹æ³•ï¼Œé€šè¿‡ç‰©ç†æ„ŸçŸ¥é€‚é…å™¨å°†ç‰©ç†æŽ¨ç†èžå…¥è§†é¢‘åˆ°éŸ³é¢‘åˆæˆï¼Œä»¥æå‡å£°éŸ³çš„ç‰©ç†çœŸå®žæ€§ã€‚**

**å…³é”®è¯**: `è§†é¢‘åˆ°éŸ³é¢‘åˆæˆ` `ç‰©ç†æ„ŸçŸ¥ç”Ÿæˆ` `æ‰©æ•£æ¨¡åž‹` `ç‰©ä½“äº¤äº’` `éŸ³é¢‘ç‰©ç†ä¸€è‡´æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†é¢‘åˆ°éŸ³é¢‘ç”Ÿæˆæ¨¡åž‹å¤šåŸºäºŽå¤–è§‚é©±åŠ¨ï¼Œå¿½ç•¥ç‰©ç†å› ç´ å¯¹å£°éŸ³çš„å½±å“ã€‚
2. PAVASå¼•å…¥ç‰©ç†é©±åŠ¨éŸ³é¢‘é€‚é…å™¨ï¼Œåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡åž‹å’Œ3Dé‡å»ºä¼°è®¡ç‰©ä½“è´¨é‡ä¸Žé€Ÿåº¦ï¼ŒæŒ‡å¯¼éŸ³é¢‘åˆæˆã€‚
3. å®žéªŒåŸºäºŽVGG-ImpactåŸºå‡†å’ŒAPCCæŒ‡æ ‡ï¼Œæ˜¾ç¤ºPAVASåœ¨ç‰©ç†åˆç†æ€§å’Œæ„ŸçŸ¥ä¸€è‡´æ€§ä¸Šä¼˜äºŽçŽ°æœ‰æ¨¡åž‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in Video-to-Audio (V2A) generation have achieved impressive perceptual quality and temporal synchronization, yet most models remain appearance-driven, capturing visual-acoustic correlations without considering the physical factors that shape real-world sounds. We present Physics-Aware Video-to-Audio Synthesis (PAVAS), a method that incorporates physical reasoning into a latent diffusion-based V2A generation through the Physics-Driven Audio Adapter (Phy-Adapter). The adapter receives object-level physical parameters estimated by the Physical Parameter Estimator (PPE), which uses a Vision-Language Model (VLM) to infer the moving-object mass and a segmentation-based dynamic 3D reconstruction module to recover its motion trajectory for velocity computation. These physical cues enable the model to synthesize sounds that reflect underlying physical factors. To assess physical realism, we curate VGG-Impact, a benchmark focusing on object-object interactions, and introduce Audio-Physics Correlation Coefficient (APCC), an evaluation metric that measures consistency between physical and auditory attributes. Comprehensive experiments show that PAVAS produces physically plausible and perceptually coherent audio, outperforming existing V2A models in both quantitative and qualitative evaluations. Visit https://physics-aware-video-to-audio-synthesis.github.io for demo videos.

