---
layout: default
title: Learning and Editing Universal Graph Prompt Tuning via Reinforcement Learning
---

# Learning and Editing Universal Graph Prompt Tuning via Reinforcement Learning

**arXiv**: [2512.08763v1](https://arxiv.org/abs/2512.08763) | [PDF](https://arxiv.org/pdf/2512.08763.pdf)

**ä½œè€…**: Jinfeng Xu, Zheyu Chen, Shuo Yang, Jinze Li, Hewei Wang, Yijie Li, Edith C. H. Ngai

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLEAPæ¨¡åž‹ä»¥å¼ºåŒ–é€šç”¨å›¾æç¤ºè°ƒä¼˜çš„ç†è®ºåŸºç¡€å¹¶æå‡æ€§èƒ½**

**å…³é”®è¯**: `å›¾ç¥žç»ç½‘ç»œ` `æç¤ºè°ƒä¼˜` `å¼ºåŒ–å­¦ä¹ ` `é€šç”¨å›¾æç¤º` `èŠ‚ç‚¹é€‰æ‹©` `å°‘æ ·æœ¬å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ—©æœŸå›¾æç¤ºè°ƒä¼˜ä¾èµ–ä»»åŠ¡ç‰¹å®šè®¾è®¡ï¼Œé™åˆ¶è·¨é¢„è®­ç»ƒç­–ç•¥çš„é€‚åº”æ€§
2. LEAPé€šè¿‡å…¨èŠ‚ç‚¹æç¤ºä¿æŒç†è®ºåŸºç¡€ï¼Œå¹¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç¼–è¾‘æç¤º
3. å®žéªŒè¡¨æ˜ŽLEAPåœ¨å…¨æ ·æœ¬å’Œå°‘æ ·æœ¬åœºæ™¯ä¸‹ä¼˜äºŽå¾®è°ƒå’Œå…¶ä»–æç¤ºæ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Early graph prompt tuning approaches relied on task-specific designs for Graph Neural Networks (GNNs), limiting their adaptability across diverse pre-training strategies. In contrast, another promising line of research has investigated universal graph prompt tuning, which operates directly in the input graph's feature space and builds a theoretical foundation that universal graph prompt tuning can theoretically achieve an equivalent effect of any prompting function, eliminating dependence on specific pre-training strategies. Recent works propose selective node-based graph prompt tuning to pursue more ideal prompts. However, we argue that selective node-based graph prompt tuning inevitably compromises the theoretical foundation of universal graph prompt tuning. In this paper, we strengthen the theoretical foundation of universal graph prompt tuning by introducing stricter constraints, demonstrating that adding prompts to all nodes is a necessary condition for achieving the universality of graph prompts. To this end, we propose a novel model and paradigm, Learning and Editing Universal GrAph Prompt Tuning (LEAP), which preserves the theoretical foundation of universal graph prompt tuning while pursuing more ideal prompts. Specifically, we first build the basic universal graph prompts to preserve the theoretical foundation and then employ actor-critic reinforcement learning to select nodes and edit prompts. Extensive experiments on graph- and node-level tasks across various pre-training strategies in both full-shot and few-shot scenarios show that LEAP consistently outperforms fine-tuning and other prompt-based approaches.

