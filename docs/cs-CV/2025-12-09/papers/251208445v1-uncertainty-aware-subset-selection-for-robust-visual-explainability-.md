---
layout: default
title: Uncertainty-Aware Subset Selection for Robust Visual Explainability under Distribution Shifts
---

# Uncertainty-Aware Subset Selection for Robust Visual Explainability under Distribution Shifts

**arXiv**: [2512.08445v1](https://arxiv.org/abs/2512.08445) | [PDF](https://arxiv.org/pdf/2512.08445.pdf)

**ä½œè€…**: Madhav Gupta, Vishak Prasad C, Ganesh Ramakrishnan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸ç¡®å®šæ€§æ„ŸçŸ¥å­é›†é€‰æ‹©æ¡†æž¶ï¼Œä»¥æå‡è§†è§‰å¯è§£é‡Šæ€§åœ¨åˆ†å¸ƒåç§»ä¸‹çš„é²æ£’æ€§ã€‚**

**å…³é”®è¯**: `è§†è§‰å¯è§£é‡Šæ€§` `å­é›†é€‰æ‹©` `åˆ†å¸ƒåç§»` `ä¸ç¡®å®šæ€§ä¼°è®¡` `é²æ£’æ€§` `æ¢¯åº¦æ–¹æ³•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰åŸºäºŽå­é›†é€‰æ‹©çš„å¯è§£é‡Šæ–¹æ³•åœ¨åˆ†å¸ƒå¤–åœºæ™¯ä¸­å¯é æ€§ä¸‹é™ï¼Œäº§ç”Ÿå†—ä½™ã€ä¸ç¨³å®šè§£é‡Šã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆå­æ¨¡å­é›†é€‰æ‹©ä¸ŽåŸºäºŽæ¢¯åº¦çš„å±‚é—´ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œé€šè¿‡è‡ªé€‚åº”æƒé‡æ‰°åŠ¨å¼•å¯¼ä¼˜åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåˆ†å¸ƒå†…å¤–æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæ¡†æž¶æå‡é²æ£’æ€§å’Œä¿çœŸåº¦ï¼Œä¸”åœ¨åˆ†å¸ƒå†…åœºæ™¯ä¹Ÿæœ‰æ”¹è¿›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Subset selection-based methods are widely used to explain deep vision models: they attribute predictions by highlighting the most influential image regions and support object-level explanations. While these methods perform well in in-distribution (ID) settings, their behavior under out-of-distribution (OOD) conditions remains poorly understood. Through extensive experiments across multiple ID-OOD sets, we find that reliability of the existing subset based methods degrades markedly, yielding redundant, unstable, and uncertainty-sensitive explanations. To address these shortcomings, we introduce a framework that combines submodular subset selection with layer-wise, gradient-based uncertainty estimation to improve robustness and fidelity without requiring additional training or auxiliary models. Our approach estimates uncertainty via adaptive weight perturbations and uses these estimates to guide submodular optimization, ensuring diverse and informative subset selection. Empirical evaluations show that, beyond mitigating the weaknesses of existing methods under OOD scenarios, our framework also yields improvements in ID settings. These findings highlight limitations of current subset-based approaches and demonstrate how uncertainty-driven optimization can enhance attribution and object-level interpretability, paving the way for more transparent and trustworthy AI in real-world vision applications.

