---
layout: default
title: Efficiently Reconstructing Dynamic Scenes One D4RT at a Time
---

# Efficiently Reconstructing Dynamic Scenes One D4RT at a Time

**arXiv**: [2512.08924v1](https://arxiv.org/abs/2512.08924) | [PDF](https://arxiv.org/pdf/2512.08924.pdf)

**ä½œè€…**: Chuhan Zhang, Guillaume Le Moing, Skanda Koppula, Ignacio Rocco, Liliane Momeni, Junyu Xie, Shuyang Sun, Rahul Sukthankar, JoÃ«lle K Barral, Raia Hadsell, Zoubin Ghahramani, Andrew Zisserman, Junlin Zhang, Mehdi SM Sajjadi

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºD4RTå‰é¦ˆæ¨¡åž‹ï¼Œé€šè¿‡ç»Ÿä¸€Transformeræž¶æž„é«˜æ•ˆé‡å»ºåŠ¨æ€åœºæ™¯çš„4Då‡ ä½•ä¸Žè¿åŠ¨ã€‚**

**å…³é”®è¯**: `åŠ¨æ€åœºæ™¯é‡å»º` `4Dé‡å»º` `Transformeræž¶æž„` `æ·±åº¦ä¼°è®¡` `ç›¸æœºå‚æ•°ä¼°è®¡` `æ—¶ç©ºå¯¹åº”`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä»Žè§†é¢‘ä¸­é«˜æ•ˆé‡å»ºåŠ¨æ€åœºæ™¯çš„å¤æ‚å‡ ä½•å’Œè¿åŠ¨ä»å…·æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ç»Ÿä¸€Transformeræž¶æž„ï¼Œé€šè¿‡æ–°é¢–æŸ¥è¯¢æœºåˆ¶è”åˆæŽ¨æ–­æ·±åº¦ã€æ—¶ç©ºå¯¹åº”å’Œç›¸æœºå‚æ•°ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šç§4Dé‡å»ºä»»åŠ¡ä¸­è¶…è¶Šå…ˆå‰æ–¹æ³•ï¼Œå®žçŽ°è½»é‡çº§ã€å¯æ‰©å±•çš„é«˜æ•ˆè®­ç»ƒä¸ŽæŽ¨ç†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Understanding and reconstructing the complex geometry and motion of dynamic scenes from video remains a formidable challenge in computer vision. This paper introduces D4RT, a simple yet powerful feedforward model designed to efficiently solve this task. D4RT utilizes a unified transformer architecture to jointly infer depth, spatio-temporal correspondence, and full camera parameters from a single video. Its core innovation is a novel querying mechanism that sidesteps the heavy computation of dense, per-frame decoding and the complexity of managing multiple, task-specific decoders. Our decoding interface allows the model to independently and flexibly probe the 3D position of any point in space and time. The result is a lightweight and highly scalable method that enables remarkably efficient training and inference. We demonstrate that our approach sets a new state of the art, outperforming previous methods across a wide spectrum of 4D reconstruction tasks. We refer to the project webpage for animated results: https://d4rt-paper.github.io/.

