---
layout: default
title: Systematization of Knowledge: Security and Safety in the Model Context Protocol Ecosystem
---

# Systematization of Knowledge: Security and Safety in the Model Context Protocol Ecosystem

**arXiv**: [2512.08290v1](https://arxiv.org/abs/2512.08290) | [PDF](https://arxiv.org/pdf/2512.08290.pdf)

**ä½œè€…**: Shiva Gaire, Srijan Gyawali, Saroj Mishra, Suman Niroula, Dilip Thakur, Umesh Yadav

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç³»ç»ŸåŒ–åˆ†æžæ¨¡åž‹ä¸Šä¸‹æ–‡åè®®ç”Ÿæ€ä¸­çš„å®‰å…¨ä¸Žå®‰å…¨é£Žé™©ï¼Œæå‡ºåˆ†ç±»ä¸Žé˜²å¾¡è·¯çº¿å›¾**

**å…³é”®è¯**: `æ¨¡åž‹ä¸Šä¸‹æ–‡åè®®` `å®‰å…¨é£Žé™©åˆ†ç±»` `å¯¹æŠ—æ€§å¨èƒ` `è®¤çŸ¥æ€§å±å®³` `å¤šä»£ç†çŽ¯å¢ƒ` `é˜²å¾¡è·¯çº¿å›¾`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ¨¡åž‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ä½œä¸ºLLMè¿žæŽ¥å¤–éƒ¨æ•°æ®å’Œå·¥å…·çš„æ ‡å‡†ï¼Œæ¨¡ç³Šäº†å¹»è§‰ä¸Žå®‰å…¨æ¼æ´žçš„è¾¹ç•Œï¼Œå¼•å…¥æ–°å¨èƒã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå»ºç«‹é£Žé™©åˆ†ç±»å­¦ï¼ŒåŒºåˆ†å¯¹æŠ—æ€§å®‰å…¨å¨èƒï¼ˆå¦‚é—´æŽ¥æç¤ºæ³¨å…¥ï¼‰å’Œè®¤çŸ¥æ€§å®‰å…¨å±å®³ï¼ˆå¦‚åˆ†å¸ƒå¼å·¥å…·å§”æ‰˜ä¸­çš„å¯¹é½å¤±è´¥ï¼‰ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåˆ†æžMCPåŽŸè¯­ï¼ˆèµ„æºã€æç¤ºã€å·¥å…·ï¼‰çš„ç»“æž„æ€§æ¼æ´žï¼Œå¹¶è°ƒæŸ¥ä»ŽåŠ å¯†æ¥æºåˆ°è¿è¡Œæ—¶æ„å›¾éªŒè¯çš„å…ˆè¿›é˜²å¾¡æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The Model Context Protocol (MCP) has emerged as the de facto standard for connecting Large Language Models (LLMs) to external data and tools, effectively functioning as the "USB-C for Agentic AI." While this decoupling of context and execution solves critical interoperability challenges, it introduces a profound new threat landscape where the boundary between epistemic errors (hallucinations) and security breaches (unauthorized actions) dissolves. This Systematization of Knowledge (SoK) aims to provide a comprehensive taxonomy of risks in the MCP ecosystem, distinguishing between adversarial security threats (e.g., indirect prompt injection, tool poisoning) and epistemic safety hazards (e.g., alignment failures in distributed tool delegation). We analyze the structural vulnerabilities of MCP primitives, specifically Resources, Prompts, and Tools, and demonstrate how "context" can be weaponized to trigger unauthorized operations in multi-agent environments. Furthermore, we survey state-of-the-art defenses, ranging from cryptographic provenance (ETDI) to runtime intent verification, and conclude with a roadmap for securing the transition from conversational chatbots to autonomous agentic operating systems.

