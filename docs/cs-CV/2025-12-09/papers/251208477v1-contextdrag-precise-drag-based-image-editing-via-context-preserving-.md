---
layout: default
title: ContextDrag: Precise Drag-Based Image Editing via Context-Preserving Token Injection and Position-Consistent Attention
---

# ContextDrag: Precise Drag-Based Image Editing via Context-Preserving Token Injection and Position-Consistent Attention

**arXiv**: [2512.08477v1](https://arxiv.org/abs/2512.08477) | [PDF](https://arxiv.org/pdf/2512.08477.pdf)

**ä½œè€…**: Huiguo He, Pengyu Yan, Ziqi Yi, Weizhi Zhong, Zheng Liu, Yejun Tang, Huan Yang, Kun Gai, Guanbin Li, Lianwen Jin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºContextDragï¼Œé€šè¿‡ä¸Šä¸‹æ–‡ä¿ç•™ä»¤ç‰Œæ³¨å…¥å’Œä½ç½®ä¸€è‡´æ³¨æ„åŠ›å®žçŽ°ç²¾ç¡®æ‹–æ‹½å¼å›¾åƒç¼–è¾‘**

**å…³é”®è¯**: `æ‹–æ‹½å¼å›¾åƒç¼–è¾‘` `ä¸Šä¸‹æ–‡å»ºæ¨¡` `ä»¤ç‰Œæ³¨å…¥` `æ³¨æ„åŠ›æœºåˆ¶` `å›¾åƒä¿çœŸåº¦`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ‹–æ‹½å¼ç¼–è¾‘æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨å‚è€ƒå›¾åƒçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯¼è‡´ç¼–è¾‘è¿žè´¯æ€§å’Œä¿çœŸåº¦ä¸è¶³
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥ä¸Šä¸‹æ–‡ä¿ç•™ä»¤ç‰Œæ³¨å…¥ï¼ˆCTIï¼‰å’Œä½ç½®ä¸€è‡´æ³¨æ„åŠ›ï¼ˆPCAï¼‰ï¼Œæ— éœ€å¾®è°ƒå³å¯ä¿ç•™ç»†ç²’åº¦ç»†èŠ‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨DragBench-SRå’ŒDragBench-DRä¸Šè¶…è¶Šæ‰€æœ‰çŽ°æœ‰SOTAæ–¹æ³•ï¼Œä»£ç å°†å…¬å¼€

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Drag-based image editing aims to modify visual content followed by user-specified drag operations. Despite existing methods having made notable progress, they still fail to fully exploit the contextual information in the reference image, including fine-grained texture details, leading to edits with limited coherence and fidelity. To address this challenge, we introduce ContextDrag, a new paradigm for drag-based editing that leverages the strong contextual modeling capability of editing models, such as FLUX-Kontext. By incorporating VAE-encoded features from the reference image, ContextDrag can leverage rich contextual cues and preserve fine-grained details, without the need for finetuning or inversion. Specifically, ContextDrag introduced a novel Context-preserving Token Injection (CTI) that injects noise-free reference features into their correct destination locations via a Latent-space Reverse Mapping (LRM) algorithm. This strategy enables precise drag control while preserving consistency in both semantics and texture details. Second, ContextDrag adopts a novel Position-Consistent Attention (PCA), which positional re-encodes the reference tokens and applies overlap-aware masking to eliminate interference from irrelevant reference features. Extensive experiments on DragBench-SR and DragBench-DR demonstrate that our approach surpasses all existing SOTA methods. Code will be publicly available.

