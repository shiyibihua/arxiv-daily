---
layout: default
title: Generation is Required for Data-Efficient Perception
---

# Generation is Required for Data-Efficient Perception

**arXiv**: [2512.08854v1](https://arxiv.org/abs/2512.08854) | [PDF](https://arxiv.org/pdf/2512.08854.pdf)

**ä½œè€…**: Jack Brady, Bernhard SchÃ¶lkopf, Thomas Kipf, Simon Buchholz, Wieland Brendel

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç”Ÿæˆæ–¹æ³•é€šè¿‡è§£ç å™¨å½’çº³åç½®å®žçŽ°ç»„åˆæ³›åŒ–ï¼Œè§£å†³æ•°æ®é«˜æ•ˆæ„ŸçŸ¥é—®é¢˜**

**å…³é”®è¯**: `ç»„åˆæ³›åŒ–` `ç”Ÿæˆæ¨¡åž‹` `è§†è§‰æ„ŸçŸ¥` `å½’çº³åç½®` `æ•°æ®é«˜æ•ˆå­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç”Ÿæˆä¸Žéžç”Ÿæˆæ–¹æ³•åœ¨ç»„åˆæ³›åŒ–èƒ½åŠ›ä¸Šçš„å·®å¼‚ï¼Œä»¥è¯„ä¼°äººç±»çº§è§†è§‰æ„ŸçŸ¥çš„å¿…è¦æ€§
2. æ–¹æ³•è¦ç‚¹ï¼šç†è®ºåˆ†æžè§£ç å™¨ä¸Žç¼–ç å™¨çš„å½’çº³åç½®ï¼Œç”Ÿæˆæ–¹æ³•é€šè¿‡è§£ç å™¨çº¦æŸå’Œåè½¬å®žçŽ°ç»„åˆæ³›åŒ–
3. å®žéªŒæˆ–æ•ˆæžœï¼šç”Ÿæˆæ–¹æ³•åœ¨çœŸå®žå›¾åƒæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡ç»„åˆæ³›åŒ–ï¼Œæ— éœ€é¢å¤–æ•°æ®æˆ–ç›‘ç£

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> It has been hypothesized that human-level visual perception requires a generative approach in which internal representations result from inverting a decoder. Yet today's most successful vision models are non-generative, relying on an encoder that maps images to representations without decoder inversion. This raises the question of whether generation is, in fact, necessary for machines to achieve human-level visual perception. To address this, we study whether generative and non-generative methods can achieve compositional generalization, a hallmark of human perception. Under a compositional data generating process, we formalize the inductive biases required to guarantee compositional generalization in decoder-based (generative) and encoder-based (non-generative) methods. We then show theoretically that enforcing these inductive biases on encoders is generally infeasible using regularization or architectural constraints. In contrast, for generative methods, the inductive biases can be enforced straightforwardly, thereby enabling compositional generalization by constraining a decoder and inverting it. We highlight how this inversion can be performed efficiently, either online through gradient-based search or offline through generative replay. We examine the empirical implications of our theory by training a range of generative and non-generative methods on photorealistic image datasets. We find that, without the necessary inductive biases, non-generative methods often fail to generalize compositionally and require large-scale pretraining or added supervision to improve generalization. By comparison, generative methods yield significant improvements in compositional generalization, without requiring additional data, by leveraging suitable inductive biases on a decoder along with search and replay.

