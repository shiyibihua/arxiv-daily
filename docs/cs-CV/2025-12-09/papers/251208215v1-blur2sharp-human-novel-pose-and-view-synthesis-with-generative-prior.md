---
layout: default
title: Blur2Sharp: Human Novel Pose and View Synthesis with Generative Prior Refinement
---

# Blur2Sharp: Human Novel Pose and View Synthesis with Generative Prior Refinement

**arXiv**: [2512.08215v1](https://arxiv.org/abs/2512.08215) | [PDF](https://arxiv.org/pdf/2512.08215.pdf)

**ä½œè€…**: Chia-Hern Lai, I-Hsuan Lo, Yen-Ku Yeh, Thanh-Nguyen Truong, Ching-Chun Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBlur2Sharpæ¡†æž¶ï¼Œé€šè¿‡ç”Ÿæˆå…ˆéªŒç»†åŒ–ä»Žå•è§†å›¾ç”Ÿæˆå‡ ä½•ä¸€è‡´ä¸”æ¸…æ™°çš„æ–°å§¿æ€å’Œè§†è§’å›¾åƒã€‚**

**å…³é”®è¯**: `äººç±»å§¿æ€åˆæˆ` `æ–°è§†è§’ç”Ÿæˆ` `ç¥žç»æ¸²æŸ“` `æ‰©æ•£æ¨¡åž‹` `å‡ ä½•ä¸€è‡´æ€§` `SMPLå…ˆéªŒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆäººç±»æ–°å§¿æ€å’Œè§†è§’æ—¶ï¼Œå¸¸å¯¼è‡´å‡ ä½•ä¸ä¸€è‡´æˆ–æ¨¡ç³Šè¾“å‡ºï¼Œå°¤å…¶åœ¨å¤æ‚è¿åŠ¨å’Œè§†è§’ä¸‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆHuman NeRFå’Œæ‰©æ•£æ¨¡åž‹ï¼Œå…ˆç”Ÿæˆå‡ ä½•ä¸€è‡´çš„å¤šè§†å›¾æ¸²æŸ“ï¼Œå†é€šè¿‡æ¡ä»¶æ‰©æ•£æ¨¡åž‹ç»†åŒ–ç»†èŠ‚ï¼Œå¹¶èžåˆSMPLå…ˆéªŒæå‡è´¨é‡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æŒ‘æˆ˜æ€§åœºæ™¯å¦‚å®½æ¾è¡£ç‰©å’Œé®æŒ¡ä¸‹ï¼ŒBlur2Sharpè¶…è¶ŠçŽ°æœ‰æŠ€æœ¯ï¼Œç”Ÿæˆæ›´æ¸…æ™°ã€å‡ ä½•ä¸€è‡´çš„æ–°å§¿æ€å’Œè§†è§’å›¾åƒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The creation of lifelike human avatars capable of realistic pose variation and viewpoint flexibility remains a fundamental challenge in computer vision and graphics. Current approaches typically yield either geometrically inconsistent multi-view images or sacrifice photorealism, resulting in blurry outputs under diverse viewing angles and complex motions. To address these issues, we propose Blur2Sharp, a novel framework integrating 3D-aware neural rendering and diffusion models to generate sharp, geometrically consistent novel-view images from only a single reference view. Our method employs a dual-conditioning architecture: initially, a Human NeRF model generates geometrically coherent multi-view renderings for target poses, explicitly encoding 3D structural guidance. Subsequently, a diffusion model conditioned on these renderings refines the generated images, preserving fine-grained details and structural fidelity. We further enhance visual quality through hierarchical feature fusion, incorporating texture, normal, and semantic priors extracted from parametric SMPL models to simultaneously improve global coherence and local detail accuracy. Extensive experiments demonstrate that Blur2Sharp consistently surpasses state-of-the-art techniques in both novel pose and view generation tasks, particularly excelling under challenging scenarios involving loose clothing and occlusions.

