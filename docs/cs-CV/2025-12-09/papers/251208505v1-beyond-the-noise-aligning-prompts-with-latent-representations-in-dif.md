---
layout: default
title: Beyond the Noise: Aligning Prompts with Latent Representations in Diffusion Models
---

# Beyond the Noise: Aligning Prompts with Latent Representations in Diffusion Models

**arXiv**: [2512.08505v1](https://arxiv.org/abs/2512.08505) | [PDF](https://arxiv.org/pdf/2512.08505.pdf)

**ä½œè€…**: Vasco Ramos, Regev Cohen, Idan Szpektor, Joao Magalhaes

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNoisyCLIPæ–¹æ³•ï¼Œåœ¨åŽ»å™ªè¿‡ç¨‹ä¸­æ—©æœŸæ£€æµ‹æ–‡æœ¬-å›¾åƒé”™ä½ï¼Œå®žçŽ°å®žæ—¶å¯¹é½è¯„ä¼°ã€‚**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹` `æ–‡æœ¬-å›¾åƒå¯¹é½` `å™ªå£°æ½œåœ¨ç©ºé—´` `å®žæ—¶æ£€æµ‹` `è®¡ç®—æˆæœ¬ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ¡ä»¶æ‰©æ•£æ¨¡åž‹ä¸­æ–‡æœ¬-å›¾åƒé”™ä½å’Œå¹»è§‰å¸¸è§ï¼Œä¼ ç»ŸåŽç”Ÿæˆå¯¹é½æ£€æµ‹æˆæœ¬é«˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåœ¨å™ªå£°æ½œåœ¨ç©ºé—´ä½¿ç”¨åŒç¼–ç å™¨æµ‹é‡è¯­ä¹‰å¯¹é½ï¼ŒæŽ¢ç´¢åå‘æ‰©æ•£è¿‡ç¨‹ä¸­çš„é”™ä½æ£€æµ‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨BoNè®¾ç½®ä¸­å‡å°‘50%è®¡ç®—æˆæœ¬ï¼Œè¾¾åˆ°CLIPå¯¹é½æ€§èƒ½çš„98%ï¼Œæ”¯æŒå®žæ—¶è¯„ä¼°ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Conditional diffusion models rely on language-to-image alignment methods to steer the generation towards semantically accurate outputs. Despite the success of this architecture, misalignment and hallucinations remain common issues and require automatic misalignment detection tools to improve quality, for example by applying them in a Best-of-N (BoN) post-generation setting. Unfortunately, measuring the alignment after the generation is an expensive step since we need to wait for the overall generation to finish to determine prompt adherence. In contrast, this work hypothesizes that text/image misalignments can be detected early in the denoising process, enabling real-time alignment assessment without waiting for the complete generation. In particular, we propose NoisyCLIP a method that measures semantic alignment in the noisy latent space. This work is the first to explore and benchmark prompt-to-latent misalignment detection during image generation using dual encoders in the reverse diffusion process. We evaluate NoisyCLIP qualitatively and quantitatively and find it reduces computational cost by 50% while achieving 98% of CLIP alignment performance in BoN settings. This approach enables real-time alignment assessment during generation, reducing costs without sacrificing semantic fidelity.

