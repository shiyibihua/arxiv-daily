---
layout: default
title: Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents
---

# Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents

**arXiv**: [2512.08870v1](https://arxiv.org/abs/2512.08870) | [PDF](https://arxiv.org/pdf/2512.08870.pdf)

**ä½œè€…**: Xiang Chen, Yuling Shi, Qizhen Lan, Yuchao Qiu, Xiaodong Gu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFed-SEè”é‚¦è‡ªè¿›åŒ–æ¡†æž¶ï¼Œä»¥è§£å†³éšç§çº¦æŸä¸‹å¤šçŽ¯å¢ƒLLMä»£ç†çš„æ¢¯åº¦å†²çªä¸Žè´Ÿè¿ç§»é—®é¢˜ã€‚**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡åž‹ä»£ç†` `è‡ªè¿›åŒ–` `éšç§ä¿æŠ¤` `æ¢¯åº¦å†²çª` `è´Ÿè¿ç§»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šéšç§é™åˆ¶ä¸‹ï¼ŒLLMä»£ç†åœ¨å¤šçŽ¯å¢ƒä¸­çš„å¼‚è´¨ä»»åŠ¡å’Œç¨€ç–å¥–åŠ±å¯¼è‡´æ¢¯åº¦å†²çªï¼Œé˜»ç¢è”é‚¦ä¼˜åŒ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæœ¬åœ°åŸºäºŽé«˜å›žæŠ¥è½¨è¿¹è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼Œå…¨å±€åœ¨ä½Žç§©å­ç©ºé—´èšåˆæ›´æ–°ä»¥è§£è€¦çŽ¯å¢ƒåŠ¨æ€ã€‚
3. å®žéªŒæ•ˆæžœï¼šåœ¨äº”ä¸ªå¼‚è´¨çŽ¯å¢ƒä¸­ï¼ŒFed-SEç›¸æ¯”è”é‚¦åŸºçº¿å¹³å‡ä»»åŠ¡æˆåŠŸçŽ‡æå‡çº¦18%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> LLM agents are widely deployed in complex interactive tasks, yet privacy constraints often preclude centralized optimization and co-evolution across dynamic environments. While Federated Learning (FL) has proven effective on static datasets, its extension to the open-ended self-evolution of agents remains underexplored. Directly applying standard FL is challenging: heterogeneous tasks and sparse, trajectory-level rewards introduce severe gradient conflicts, destabilizing the global optimization process. To bridge this gap, we propose Fed-SE, a Federated Self-Evolution framework for LLM agents. Fed-SE establishes a local evolution-global aggregation paradigm. Locally, agents employ parameter-efficient fine-tuning on filtered, high-return trajectories to achieve stable gradient updates. Globally, Fed-SE aggregates updates within a low-rank subspace that disentangles environment-specific dynamics, effectively reducing negative transfer across clients. Experiments across five heterogeneous environments demonstrate that Fed-SE improves average task success rates by approximately 18% over federated baselines, validating its effectiveness in robust cross-environment knowledge transfer in privacy-constrained deployments.

