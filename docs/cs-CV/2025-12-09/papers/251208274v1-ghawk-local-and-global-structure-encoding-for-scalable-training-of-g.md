---
layout: default
title: gHAWK: Local and Global Structure Encoding for Scalable Training of Graph Neural Networks on Knowledge Graphs
---

# gHAWK: Local and Global Structure Encoding for Scalable Training of Graph Neural Networks on Knowledge Graphs

**arXiv**: [2512.08274v1](https://arxiv.org/abs/2512.08274) | [PDF](https://arxiv.org/pdf/2512.08274.pdf)

**ä½œè€…**: Humera Sabir, Fatima Farooq, Ashraf Aboulnaga

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºgHAWKæ¡†æž¶ï¼Œé€šè¿‡é¢„è®¡ç®—å±€éƒ¨ä¸Žå…¨å±€ç»“æž„ç‰¹å¾ï¼Œè§£å†³çŸ¥è¯†å›¾è°±ä¸Šå¤§è§„æ¨¡å›¾ç¥žç»ç½‘ç»œè®­ç»ƒçš„å¯æ‰©å±•æ€§é—®é¢˜ã€‚**

**å…³é”®è¯**: `çŸ¥è¯†å›¾è°±` `å›¾ç¥žç»ç½‘ç»œ` `å¯æ‰©å±•è®­ç»ƒ` `ç»“æž„ç¼–ç ` `é¢„è®¡ç®—ç‰¹å¾` `Open Graph Benchmark`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ¶ˆæ¯ä¼ é€’å›¾ç¥žç»ç½‘ç»œåœ¨å¤§è§„æ¨¡çŸ¥è¯†å›¾è°±ä¸Šè®­ç»ƒæ•ˆçŽ‡ä½Žï¼Œå—é™äºŽè¿­ä»£æ¶ˆæ¯ä¼ é€’è¿‡ç¨‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé¢„å¤„ç†é˜¶æ®µè®¡ç®—Bloomè¿‡æ»¤å™¨ç¼–ç å±€éƒ¨é‚»åŸŸç»“æž„ï¼ŒTransEåµŒå…¥è¡¨ç¤ºå…¨å±€ä½ç½®ï¼Œèžåˆç‰¹å¾ä»¥å¢žå¼ºGNNè®­ç»ƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Open Graph Benchmarkæ•°æ®é›†ä¸Šå®žçŽ°æœ€ä¼˜å‡†ç¡®çŽ‡å’Œæ›´ä½Žè®­ç»ƒæ—¶é—´ï¼Œæå‡èŠ‚ç‚¹å±žæ€§é¢„æµ‹å’Œé“¾æŽ¥é¢„æµ‹ä»»åŠ¡æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Knowledge Graphs (KGs) are a rich source of structured, heterogeneous data, powering a wide range of applications. A common approach to leverage this data is to train a graph neural network (GNN) on the KG. However, existing message-passing GNNs struggle to scale to large KGs because they rely on the iterative message passing process to learn the graph structure, which is inefficient, especially under mini-batch training, where a node sees only a partial view of its neighborhood. In this paper, we address this problem and present gHAWK, a novel and scalable GNN training framework for large KGs. The key idea is to precompute structural features for each node that capture its local and global structure before GNN training even begins. Specifically, gHAWK introduces a preprocessing step that computes: (a)~Bloom filters to compactly encode local neighborhood structure, and (b)~TransE embeddings to represent each node's global position in the graph. These features are then fused with any domain-specific features (e.g., text embeddings), producing a node feature vector that can be incorporated into any GNN technique. By augmenting message-passing training with structural priors, gHAWK significantly reduces memory usage, accelerates convergence, and improves model accuracy. Extensive experiments on large datasets from the Open Graph Benchmark (OGB) demonstrate that gHAWK achieves state-of-the-art accuracy and lower training time on both node property prediction and link prediction tasks, topping the OGB leaderboard for three graphs.

