---
layout: default
title: Gradient-Informed Monte Carlo Fine-Tuning of Diffusion Models for Low-Thrust Trajectory Design
---

# Gradient-Informed Monte Carlo Fine-Tuning of Diffusion Models for Low-Thrust Trajectory Design

**arXiv**: [2512.08705v1](https://arxiv.org/abs/2512.08705) | [PDF](https://arxiv.org/pdf/2512.08705.pdf)

**ä½œè€…**: Jannik Graebner, Ryne Beeson

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¢¯åº¦ä¿¡æ¯è’™ç‰¹å¡æ´›å¾®è°ƒæ‰©æ•£æ¨¡åž‹ä»¥ä¼˜åŒ–ä½ŽæŽ¨åŠ›è½¨è¿¹è®¾è®¡**

**å…³é”®è¯**: `ä½ŽæŽ¨åŠ›è½¨è¿¹è®¾è®¡` `æ‰©æ•£æ¨¡åž‹` `é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›` `æ¢¯åº¦ä¿¡æ¯é‡‡æ ·` `å¸•ç´¯æ‰˜ä¼˜åŒ–` `è‡ªç›‘ç£å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä½ŽæŽ¨åŠ›è½¨è¿¹è®¾è®¡åœ¨å¤æ‚ç›®æ ‡æ™¯è§‚ä¸­é¢ä¸´å…¨å±€æœç´¢å›°éš¾ï¼Œå­˜åœ¨å¤šä¸ªå±€éƒ¨æœ€ä¼˜è§£ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæ‰©å±•è‡ªç›‘ç£æ‰©æ•£æ¨¡åž‹å¾®è°ƒæ¡†æž¶ï¼Œç»“åˆæ¢¯åº¦ä¿¡æ¯é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›ç®—æ³•ï¼ˆMALAå’ŒHMCï¼‰åŠ é€Ÿæ”¶æ•›ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åœŸå«å…­ç³»ç»Ÿå¤šåœˆè½¬ç§»ä»»åŠ¡ä¸­ï¼ŒMALAå°†å¯è¡Œæ€§çŽ‡ä»Ž17.34%æå‡è‡³63.01ï¼Œå¹¶ç”Ÿæˆæ›´å¯†é›†ã€å¤šæ ·åŒ–çš„å¸•ç´¯æ‰˜å‰æ²¿ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Preliminary mission design of low-thrust spacecraft trajectories in the Circular Restricted Three-Body Problem is a global search characterized by a complex objective landscape and numerous local minima. Formulating the problem as sampling from an unnormalized distribution supported on neighborhoods of locally optimal solutions, provides the opportunity to deploy Markov chain Monte Carlo methods and generative machine learning. In this work, we extend our previous self-supervised diffusion model fine-tuning framework to employ gradient-informed Markov chain Monte Carlo. We compare two algorithms - the Metropolis-Adjusted Langevin Algorithm and Hamiltonian Monte Carlo - both initialized from a distribution learned by a diffusion model. Derivatives of an objective function that balances fuel consumption, time of flight and constraint violations are computed analytically using state transition matrices. We show that incorporating the gradient drift term accelerates mixing and improves convergence of the Markov chain for a multi-revolution transfer in the Saturn-Titan system. Among the evaluated methods, MALA provides the best trade-off between performance and computational cost. Starting from samples generated by a baseline diffusion model trained on a related transfer, MALA explicitly targets Pareto-optimal solutions. Compared to a random walk Metropolis algorithm, it increases the feasibility rate from 17.34% to 63.01% and produces a denser, more diverse coverage of the Pareto front. By fine-tuning a diffusion model on the generated samples and associated reward values with reward-weighted likelihood maximization, we learn the global solution structure of the problem and eliminate the need for a tedious separate data generation phase.

