---
layout: default
title: SDT-6D: Fully Sparse Depth-Transformer for Staged End-to-End 6D Pose Estimation in Industrial Multi-View Bin Picking
---

# SDT-6D: Fully Sparse Depth-Transformer for Staged End-to-End 6D Pose Estimation in Industrial Multi-View Bin Picking

**arXiv**: [2512.08430v1](https://arxiv.org/abs/2512.08430) | [PDF](https://arxiv.org/pdf/2512.08430.pdf)

**ä½œè€…**: Nico Leuze, Maximilian Hoh, Samed DoÄŸan, Nicolas R. -PeÃ±a, Alfred Schoettl

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå…¨ç¨€ç–æ·±åº¦Transformerï¼Œç”¨äºŽå·¥ä¸šå¤šè§†è§’ç®±æ‹£ä¸­åˆ†é˜¶æ®µç«¯åˆ°ç«¯6Då§¿æ€ä¼°è®¡**

**å…³é”®è¯**: `6Då§¿æ€ä¼°è®¡` `ç¨€ç–Transformer` `å¤šè§†è§’æ·±åº¦èžåˆ` `å·¥ä¸šç®±æ‹£` `ç«¯åˆ°ç«¯å­¦ä¹ ` `ç‚¹äº‘å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå·¥ä¸šç®±æ‹£ä¸­å¯†é›†é®æŒ¡ã€åå°„å’Œæ— çº¹ç†éƒ¨ä»¶å¯¼è‡´6Då§¿æ€ä¼°è®¡å›°éš¾
2. æ–¹æ³•è¦ç‚¹ï¼šèžåˆå¤šè§†è§’æ·±åº¦å›¾ï¼Œé‡‡ç”¨åˆ†é˜¶æ®µçƒ­å›¾æœºåˆ¶å’Œå¯†åº¦æ„ŸçŸ¥ç¨€ç–Transformerå—
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨IPDå’ŒMV-YCBæ•°æ®é›†ä¸ŠéªŒè¯ï¼Œåœ¨æ‚ä¹±åœºæ™¯ä¸­è¡¨çŽ°ç«žäº‰æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Accurately recovering 6D poses in densely packed industrial bin-picking environments remain a serious challenge, owing to occlusions, reflections, and textureless parts. We introduce a holistic depth-only 6D pose estimation approach that fuses multi-view depth maps into either a fine-grained 3D point cloud in its vanilla version, or a sparse Truncated Signed Distance Field (TSDF). At the core of our framework lies a staged heatmap mechanism that yields scene-adaptive attention priors across different resolutions, steering computation toward foreground regions, thus keeping memory requirements at high resolutions feasible. Along, we propose a density-aware sparse transformer block that dynamically attends to (self-) occlusions and the non-uniform distribution of 3D data. While sparse 3D approaches has proven effective for long-range perception, its potential in close-range robotic applications remains underexplored. Our framework operates fully sparse, enabling high-resolution volumetric representations to capture fine geometric details crucial for accurate pose estimation in clutter. Our method processes the entire scene integrally, predicting the 6D pose via a novel per-voxel voting strategy, allowing simultaneous pose predictions for an arbitrary number of target objects. We validate our method on the recently published IPD and MV-YCB multi-view datasets, demonstrating competitive performance in heavily cluttered industrial and household bin picking scenarios.

