---
layout: default
title: Robust Finetuning of Vision-Language-Action Robot Policies via Parameter Merging
---

# Robust Finetuning of Vision-Language-Action Robot Policies via Parameter Merging

**arXiv**: [2512.08333v1](https://arxiv.org/abs/2512.08333) | [PDF](https://arxiv.org/pdf/2512.08333.pdf)

**ä½œè€…**: Yajat Yadav, Zhiyuan Zhou, Andrew Wagenmaker, Karl Pertsch, Sergey Levine

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå‚æ•°åˆå¹¶æ–¹æ³•ä»¥è§£å†³æœºå™¨äººç­–ç•¥å¾®è°ƒä¸­çš„è¿‡æ‹Ÿåˆä¸Žæ³›åŒ–èƒ½åŠ›ä¸§å¤±é—®é¢˜**

**å…³é”®è¯**: `æœºå™¨äººç­–ç•¥` `å‚æ•°åˆå¹¶` `å¾®è°ƒæ³›åŒ–` `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡åž‹` `ç»ˆèº«å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé€šç”¨æœºå™¨äººç­–ç•¥å¾®è°ƒæ–°ä»»åŠ¡æ—¶æ˜“è¿‡æ‹Ÿåˆï¼Œä¸§å¤±åŽŸæœ‰æ³›åŒ–èƒ½åŠ›
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡åˆå¹¶å¾®è°ƒæ¨¡åž‹ä¸Žé¢„è®­ç»ƒæ¨¡åž‹çš„æƒé‡ï¼Œå®žçŽ°æ–°æŠ€èƒ½ç¨³å¥èžå…¥
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ¨¡æ‹Ÿä¸ŽçœŸå®žå®žéªŒä¸­ï¼Œåˆå¹¶æ¨¡åž‹åœ¨æ–°ä»»åŠ¡åˆ†å¸ƒå¤–å˜ä½“ä¸Šä¼˜äºŽé¢„è®­ç»ƒå’Œå¾®è°ƒæ¨¡åž‹

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generalist robot policies, trained on large and diverse datasets, have demonstrated the ability to generalize across a wide spectrum of behaviors, enabling a single policy to act in varied real-world environments. However, they still fall short on new tasks not covered in the training data. When finetuned on limited demonstrations of a new task, these policies often overfit to the specific demonstrations--not only losing their prior abilities to solve a wide variety of generalist tasks but also failing to generalize within the new task itself. In this work, we aim to develop a method that preserves the generalization capabilities of the generalist policy during finetuning, allowing a single policy to robustly incorporate a new skill into its repertoire. Our goal is a single policy that both learns to generalize to variations of the new task and retains the broad competencies gained from pretraining. We show that this can be achieved through a simple yet effective strategy: interpolating the weights of a finetuned model with that of the pretrained model. We show, across extensive simulated and real-world experiments, that such model merging produces a single model that inherits the generalist abilities of the base model and learns to solve the new task robustly, outperforming both the pretrained and finetuned model on out-of-distribution variations of the new task. Moreover, we show that model merging enables continual acquisition of new skills in a lifelong learning setting, without sacrificing previously learned generalist abilities.

