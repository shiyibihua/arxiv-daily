---
layout: default
title: Distilling Future Temporal Knowledge with Masked Feature Reconstruction for 3D Object Detection
---

# Distilling Future Temporal Knowledge with Masked Feature Reconstruction for 3D Object Detection

**arXiv**: [2512.08247v1](https://arxiv.org/abs/2512.08247) | [PDF](https://arxiv.org/pdf/2512.08247.pdf)

**ä½œè€…**: Haowen Zheng, Hu Zhu, Lu Deng, Weihao Gu, Yang Yang, Yanyan Liang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæœªæ¥æ—¶åºçŸ¥è¯†è’¸é¦æ–¹æ³•ï¼Œé€šè¿‡æŽ©ç ç‰¹å¾é‡å»ºè§£å†³åœ¨çº¿3Dç›®æ ‡æ£€æµ‹ä¸­æœªæ¥å¸§çŸ¥è¯†è¿ç§»é—®é¢˜ã€‚**

**å…³é”®è¯**: `3Dç›®æ ‡æ£€æµ‹` `çŸ¥è¯†è’¸é¦` `æ—¶åºå»ºæ¨¡` `è‡ªåŠ¨é©¾é©¶` `ç‰¹å¾é‡å»º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰çŸ¥è¯†è’¸é¦æ–¹æ³•å¿½è§†æœªæ¥å¸§ï¼Œéš¾ä»¥è®©åœ¨çº¿æ¨¡åž‹æœ‰æ•ˆå­¦ä¹ æœªæ¥çŸ¥è¯†ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ç¨€ç–æŸ¥è¯¢å’Œæœªæ¥æ„ŸçŸ¥ç‰¹å¾é‡å»ºç­–ç•¥ï¼Œæ— éœ€ä¸¥æ ¼å¸§å¯¹é½å³å¯è¿ç§»æœªæ¥ç‰¹å¾ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨nuScenesæ•°æ®é›†ä¸Šæå‡mAPå’ŒNDSè¾¾1.3ï¼Œå®žçŽ°æœ€å‡†ç¡®é€Ÿåº¦ä¼°è®¡ï¼ŒæŽ¨ç†æˆæœ¬ä¸å˜ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Camera-based temporal 3D object detection has shown impressive results in autonomous driving, with offline models improving accuracy by using future frames. Knowledge distillation (KD) can be an appealing framework for transferring rich information from offline models to online models. However, existing KD methods overlook future frames, as they mainly focus on spatial feature distillation under strict frame alignment or on temporal relational distillation, thereby making it challenging for online models to effectively learn future knowledge. To this end, we propose a sparse query-based approach, Future Temporal Knowledge Distillation (FTKD), which effectively transfers future frame knowledge from an offline teacher model to an online student model. Specifically, we present a future-aware feature reconstruction strategy to encourage the student model to capture future features without strict frame alignment. In addition, we further introduce future-guided logit distillation to leverage the teacher's stable foreground and background context. FTKD is applied to two high-performing 3D object detection baselines, achieving up to 1.3 mAP and 1.3 NDS gains on the nuScenes dataset, as well as the most accurate velocity estimation, without increasing inference cost.

