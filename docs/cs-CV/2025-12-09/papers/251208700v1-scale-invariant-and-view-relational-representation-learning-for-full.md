---
layout: default
title: Scale-invariant and View-relational Representation Learning for Full Surround Monocular Depth
---

# Scale-invariant and View-relational Representation Learning for Full Surround Monocular Depth

**arXiv**: [2512.08700v1](https://arxiv.org/abs/2512.08700) | [PDF](https://arxiv.org/pdf/2512.08700.pdf)

**ä½œè€…**: Kyumin Hwang, Wonhyeok Choi, Kiljoon Han, Wonjoon Choi, Minwoo Choi, Yongcheon Na, Minwoo Park, Sunghoon Im

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè·¨äº¤äº’ä¸Žè§†å›¾å…³ç³»çŸ¥è¯†è’¸é¦ç­–ç•¥ï¼Œä»¥è§£å†³å…¨çŽ¯ç»•å•ç›®æ·±åº¦ä¼°è®¡ä¸­çš„è®¡ç®—æˆæœ¬é«˜å’Œå°ºåº¦ä¼°è®¡éš¾é—®é¢˜ã€‚**

**å…³é”®è¯**: `å…¨çŽ¯ç»•å•ç›®æ·±åº¦ä¼°è®¡` `çŸ¥è¯†è’¸é¦` `å°ºåº¦ä¸å˜è¡¨ç¤º` `è§†å›¾å…³ç³»å­¦ä¹ ` `å®žæ—¶æ€§èƒ½ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰åŸºç¡€æ¨¡åž‹åœ¨å…¨çŽ¯ç»•å•ç›®æ·±åº¦ä¼°è®¡ä¸­è®¡ç®—æˆæœ¬é«˜ä¸”éš¾ä»¥é¢„æµ‹åº¦é‡å°ºåº¦æ·±åº¦ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ··åˆå›žå½’æ¡†æž¶ï¼Œç»“åˆçŸ¥è¯†è’¸é¦å’Œæ·±åº¦åˆ†ç®±æ¨¡å—ï¼Œé€šè¿‡è·¨äº¤äº’å’Œè§†å›¾å…³ç³»è’¸é¦æå‡å°ºåº¦ä¸€è‡´æ€§å’Œè·¨è§†å›¾æ·±åº¦ä¸€è‡´æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨DDADå’ŒnuScenesæ•°æ®é›†ä¸ŠéªŒè¯æœ‰æ•ˆæ€§ï¼Œå®žçŽ°æ€§èƒ½ä¸Žæ•ˆçŽ‡çš„å¹³è¡¡ï¼Œæ»¡è¶³å®žæ—¶éœ€æ±‚ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent foundation models demonstrate strong generalization capabilities in monocular depth estimation. However, directly applying these models to Full Surround Monocular Depth Estimation (FSMDE) presents two major challenges: (1) high computational cost, which limits real-time performance, and (2) difficulty in estimating metric-scale depth, as these models are typically trained to predict only relative depth. To address these limitations, we propose a novel knowledge distillation strategy that transfers robust depth knowledge from a foundation model to a lightweight FSMDE network. Our approach leverages a hybrid regression framework combining the knowledge distillation scheme--traditionally used in classification--with a depth binning module to enhance scale consistency. Specifically, we introduce a cross-interaction knowledge distillation scheme that distills the scale-invariant depth bin probabilities of a foundation model into the student network while guiding it to infer metric-scale depth bin centers from ground-truth depth. Furthermore, we propose view-relational knowledge distillation, which encodes structural relationships among adjacent camera views and transfers them to enhance cross-view depth consistency. Experiments on DDAD and nuScenes demonstrate the effectiveness of our method compared to conventional supervised methods and existing knowledge distillation approaches. Moreover, our method achieves a favorable trade-off between performance and efficiency, meeting real-time requirements.

