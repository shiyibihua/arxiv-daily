---
layout: default
title: The Urban Vision Hackathon Dataset and Models: Towards Image Annotations and Accurate Vision Models for Indian Traffic
---

# The Urban Vision Hackathon Dataset and Models: Towards Image Annotations and Accurate Vision Models for Indian Traffic

**arXiv**: [2511.02563v1](https://arxiv.org/abs/2511.02563) | [PDF](https://arxiv.org/pdf/2511.02563.pdf)

**ä½œè€…**: Akash Sharma, Chinmay Mhatre, Sankalp Gawali, Ruthvik Bokkasam, Brij Kishore, Vishwajeet Pattanaik, Tarun Rambha, Abdul R. Pinjari, Vijay Kovvali, Anirban Chakraborty, Punit Rathore, Raghu Krishnapuram, Yogesh Simmhan

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUVH-26æ•°æ®é›†å’Œæ¨¡åž‹ï¼Œä»¥æå‡å°åº¦äº¤é€šåœºæ™¯ä¸‹çš„ç›®æ ‡æ£€æµ‹å‡†ç¡®æ€§ã€‚**

**å…³é”®è¯**: `ç›®æ ‡æ£€æµ‹` `äº¤é€šç›‘æŽ§` `ä¼—åŒ…æ ‡æ³¨` `å°åº¦è½¦è¾†æ•°æ®é›†` `æ¨¡åž‹å¾®è°ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æ•°æ®é›†ç¼ºä¹å°åº¦äº¤é€šå¤šæ ·æ€§ï¼Œå½±å“æ™ºèƒ½äº¤é€šç³»ç»Ÿéƒ¨ç½²ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡ä¼—åŒ…æ ‡æ³¨26,646å¼ å›¾åƒï¼Œç”Ÿæˆ1.8ç™¾ä¸‡è¾¹ç•Œæ¡†è¦†ç›–14ç±»å°åº¦è½¦è¾†ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè®­ç»ƒYOLOå’ŒDETRæ¨¡åž‹ï¼ŒmAP50:95æœ€é«˜è¾¾0.67ï¼Œä¼˜äºŽCOCOåŸºçº¿8.4-31.5%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This report describes the UVH-26 dataset, the first public release by
> AIM@IISc of a large-scale dataset of annotated traffic-camera images from
> India. The dataset comprises 26,646 high-resolution (1080p) images sampled from
> 2800 Bengaluru's Safe-City CCTV cameras over a 4-week period, and subsequently
> annotated through a crowdsourced hackathon involving 565 college students from
> across India. In total, 1.8 million bounding boxes were labeled across 14
> vehicle classes specific to India: Cycle, 2-Wheeler (Motorcycle), 3-Wheeler
> (Auto-rickshaw), LCV (Light Commercial Vehicles), Van, Tempo-traveller,
> Hatchback, Sedan, SUV, MUV, Mini-bus, Bus, Truck and Other. Of these, 283k-316k
> consensus ground truth bounding boxes and labels were derived for distinct
> objects in the 26k images using Majority Voting and STAPLE algorithms. Further,
> we train multiple contemporary detectors, including YOLO11-S/X, RT-DETR-S/X,
> and DAMO-YOLO-T/L using these datasets, and report accuracy based on mAP50,
> mAP75 and mAP50:95. Models trained on UVH-26 achieve 8.4-31.5% improvements in
> mAP50:95 over equivalent baseline models trained on COCO dataset, with
> RT-DETR-X showing the best performance at 0.67 (mAP50:95) as compared to 0.40
> for COCO-trained weights for common classes (Car, Bus, and Truck). This
> demonstrates the benefits of domain-specific training data for Indian traffic
> scenarios. The release package provides the 26k images with consensus
> annotations based on Majority Voting (UVH-26-MV) and STAPLE (UVH-26-ST) and the
> 6 fine-tuned YOLO and DETR models on each of these datasets. By capturing the
> heterogeneity of Indian urban mobility directly from operational traffic-camera
> streams, UVH-26 addresses a critical gap in existing global benchmarks, and
> offers a foundation for advancing detection, classification, and deployment of
> intelligent transportation systems in emerging nations with complex traffic
> conditions.

