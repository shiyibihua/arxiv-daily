---
layout: default
title: ChartM$^3$: A Multi-Stage Code-Driven Pipeline for Constructing Multi-Dimensional and Multi-Step Visual Reasoning Data in Chart Comprehension
---

# ChartM$^3$: A Multi-Stage Code-Driven Pipeline for Constructing Multi-Dimensional and Multi-Step Visual Reasoning Data in Chart Comprehension

**arXiv**: [2511.02415v1](https://arxiv.org/abs/2511.02415) | [PDF](https://arxiv.org/pdf/2511.02415.pdf)

**ä½œè€…**: Duo Xu, Hao Cheng, Xin Lin, Zhen Xie, Hao Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºChartMÂ³å¤šé˜¶æ®µä»£ç é©±åŠ¨ç®¡é“ï¼Œä»¥è§£å†³å¤æ‚å›¾è¡¨ç†è§£ä¸­æ•°æ®ä¸è¶³é—®é¢˜ã€‚**

**å…³é”®è¯**: `å›¾è¡¨ç†è§£` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `æ£€ç´¢å¢žå¼ºç”Ÿæˆ` `æ€ç»´é“¾` `ç›‘ç£å¾®è°ƒ` `å¼ºåŒ–å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ç ”ç©¶å¯¹å¤æ‚å›¾è¡¨åœºæ™¯å’Œè®¡ç®—å¯†é›†åž‹æŽ¨ç†ä»»åŠ¡è¦†ç›–ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨æ£€ç´¢å¢žå¼ºç”Ÿæˆå’Œæ€ç»´é“¾ç­–ç•¥ï¼Œè‡ªåŠ¨ç”Ÿæˆå›¾è¡¨å’ŒæŽ¨ç†æ•°æ®ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæ•°æ®é›†æ˜¾è‘—æå‡æ¨¡åž‹æŽ¨ç†èƒ½åŠ›å’Œè·¨åŸŸæ³›åŒ–æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Complex chart understanding tasks demand advanced visual recognition and
> reasoning capabilities from multimodal large language models (MLLMs). However,
> current research provides limited coverage of complex chart scenarios and
> computation-intensive reasoning tasks prevalent in real-world applications.
> This study proposes an automated multi-stage code-driven pipeline for
> systematically generating visual reasoning datasets to address these
> limitations. The pipeline integrates retrieval-augmented generation (RAG) to
> retrieve professional chart templates and employs chain-of-thought (CoT)
> strategies to generate reasoning codes that simulate real data distributions,
> thereby driving chart rendering and question-related statistical computations.
> Through model-based evaluation, the pipeline enhances chart diversity and data
> quality. Using this framework, we construct ChartM$^3$, a multi-dimensional and
> multi-step dataset containing 38K charts and 142K Q&A pairs for training, along
> with 2,871 high-quality evaluation samples for enabling practical performance
> assessment. Supervised fine-tuning (SFT) and reinforcement learning (RL)
> experiments demonstrate that our dataset significantly improves reasoning
> capabilities and cross-domain generalization performance, enabling smaller
> models to achieve performance comparable to larger-scale models in complex
> chart comprehension.

