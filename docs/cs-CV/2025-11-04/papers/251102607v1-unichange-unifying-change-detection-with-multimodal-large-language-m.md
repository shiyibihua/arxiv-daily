---
layout: default
title: UniChange: Unifying Change Detection with Multimodal Large Language Model
---

# UniChange: Unifying Change Detection with Multimodal Large Language Model

**arXiv**: [2511.02607v1](https://arxiv.org/abs/2511.02607) | [PDF](https://arxiv.org/pdf/2511.02607.pdf)

**ä½œè€…**: Xu Zhang, Danyang Li, Xiaohang Dong, Tianhao Wu, Hualong Yu, Jianye Wang, Qicheng Li, Xiang Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUniChangeæ¨¡åž‹ï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ç»Ÿä¸€å˜åŒ–æ£€æµ‹ä»»åŠ¡ã€‚**

**å…³é”®è¯**: `å˜åŒ–æ£€æµ‹` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `ç»Ÿä¸€æ¡†æž¶` `è¯­ä¹‰å˜åŒ–æ£€æµ‹` `äºŒè¿›åˆ¶å˜åŒ–æ£€æµ‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰å˜åŒ–æ£€æµ‹æ¨¡åž‹æ³›åŒ–æ€§å·®ï¼Œæ— æ³•ç»Ÿä¸€åˆ©ç”¨å¤šæºæ•°æ®é›†ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥ç‰¹æ®Šä»¤ç‰Œå’Œæ–‡æœ¬æç¤ºï¼Œç»Ÿä¸€äºŒè¿›åˆ¶å’Œè¯­ä¹‰å˜åŒ–æ£€æµ‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å››ä¸ªåŸºå‡†æµ‹è¯•ä¸­å®žçŽ°SOTAæ€§èƒ½ï¼ŒIoUå¾—åˆ†æ˜¾è‘—æå‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Change detection (CD) is a fundamental task for monitoring and analyzing land
> cover dynamics. While recent high performance models and high quality datasets
> have significantly advanced the field, a critical limitation persists. Current
> models typically acquire limited knowledge from single-type annotated data and
> cannot concurrently leverage diverse binary change detection (BCD) and semantic
> change detection (SCD) datasets. This constraint leads to poor generalization
> and limited versatility. The recent advancements in Multimodal Large Language
> Models (MLLMs) introduce new possibilities for a unified CD framework. We
> leverage the language priors and unification capabilities of MLLMs to develop
> UniChange, the first MLLM-based unified change detection model. UniChange
> integrates generative language abilities with specialized CD functionalities.
> Our model successfully unifies both BCD and SCD tasks through the introduction
> of three special tokens: [T1], [T2], and [CHANGE]. Furthermore, UniChange
> utilizes text prompts to guide the identification of change categories,
> eliminating the reliance on predefined classification heads. This design allows
> UniChange to effectively acquire knowledge from multi-source datasets, even
> when their class definitions conflict. Experiments on four public benchmarks
> (WHU-CD, S2Looking, LEVIR-CD+, and SECOND) demonstrate SOTA performance,
> achieving IoU scores of 90.41, 53.04, 78.87, and 57.62, respectively,
> surpassing all previous methods. The code is available at
> https://github.com/Erxucomeon/UniChange.

