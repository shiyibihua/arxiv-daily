---
layout: default
title: Text to Robotic Assembly of Multi Component Objects using 3D Generative AI and Vision Language Models
---

# Text to Robotic Assembly of Multi Component Objects using 3D Generative AI and Vision Language Models

**arXiv**: [2511.02162v1](https://arxiv.org/abs/2511.02162) | [PDF](https://arxiv.org/pdf/2511.02162.pdf)

**ä½œè€…**: Alexander Htet Kyaw, Richa Gupta, Dhruv Shah, Anoop Sinha, Kory Mathewson, Stefanie Pender, Sachin Chitta, Yotto Koga, Faez Ahmed, Lawrence Sass, Randall Davis

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé›†æˆ3Dç”ŸæˆAIä¸Žè§†è§‰è¯­è¨€æ¨¡åž‹çš„ç®¡é“ï¼Œå®žçŽ°å¤šç»„ä»¶å¯¹è±¡çš„æœºå™¨äººç»„è£…**

**å…³é”®è¯**: `3Dç”ŸæˆAI` `è§†è§‰è¯­è¨€æ¨¡åž‹` `æœºå™¨äººç»„è£…` `å¤šç»„ä»¶å¯¹è±¡` `é›¶æ ·æœ¬æŽ¨ç†` `äººæœºäº¤äº’`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼š3Dç”ŸæˆAIéš¾ä»¥åˆ›å»ºæ¶‰åŠå¤šç»„ä»¶ç±»åž‹çš„ç‰©ç†å¯¹è±¡
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡åž‹è¿›è¡Œé›¶æ ·æœ¬å¤šæ¨¡æ€æŽ¨ç†ï¼Œåˆ†è§£AIç”Ÿæˆç½‘æ ¼ä¸ºå¤šç»„ä»¶3Dæ¨¡åž‹
3. å®žéªŒæˆ–æ•ˆæžœï¼šç”¨æˆ·åå¥½VLMç”Ÿæˆåˆ†é…è¾¾90.6%ï¼Œä¼˜äºŽè§„åˆ™å’Œéšæœºæ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Advances in 3D generative AI have enabled the creation of physical objects
> from text prompts, but challenges remain in creating objects involving multiple
> component types. We present a pipeline that integrates 3D generative AI with
> vision-language models (VLMs) to enable the robotic assembly of multi-component
> objects from natural language. Our method leverages VLMs for zero-shot,
> multi-modal reasoning about geometry and functionality to decompose
> AI-generated meshes into multi-component 3D models using predefined structural
> and panel components. We demonstrate that a VLM is capable of determining which
> mesh regions need panel components in addition to structural components, based
> on object functionality. Evaluation across test objects shows that users
> preferred the VLM-generated assignments 90.6% of the time, compared to 59.4%
> for rule-based and 2.5% for random assignment. Lastly, the system allows users
> to refine component assignments through conversational feedback, enabling
> greater human control and agency in making physical objects with generative AI
> and robotics.

