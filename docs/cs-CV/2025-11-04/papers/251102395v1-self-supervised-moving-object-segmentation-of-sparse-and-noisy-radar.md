---
layout: default
title: Self-Supervised Moving Object Segmentation of Sparse and Noisy Radar Point Clouds
---

# Self-Supervised Moving Object Segmentation of Sparse and Noisy Radar Point Clouds

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.02395" target="_blank" class="toolbar-btn">arXiv: 2511.02395v1</a>
    <a href="https://arxiv.org/pdf/2511.02395.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.02395v1" 
            onclick="toggleFavorite(this, '2511.02395v1', 'Self-Supervised Moving Object Segmentation of Sparse and Noisy Radar Point Clouds')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Leon Schwarzer, Matthias Zeller, Daniel Casado Herraez, Simon Dierl, Michael Heidingsfeld, Cyrill Stachniss

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-04

**å¤‡æ³¨**: Accepted for publication at IEEE International Conference on Intelligent Transportation Systems (ITSC 2025), 8 pages, 3 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§è‡ªç›‘ç£é›·è¾¾ç‚¹äº‘ç§»åŠ¨ç‰©ä½“åˆ†å‰²æ–¹æ³•ï¼Œæå‡ç¨€ç–å™ªå£°æ•°æ®çš„åˆ†å‰²æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `é›·è¾¾ç‚¹äº‘` `ç§»åŠ¨ç‰©ä½“åˆ†å‰²` `è‡ªç›‘ç£å­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `èšç±»` `è‡ªåŠ¨é©¾é©¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç›¸æœºå’Œæ¿€å…‰é›·è¾¾çš„ç§»åŠ¨ç‰©ä½“åˆ†å‰²æ–¹æ³•ä¾èµ–æ—¶é—´åºåˆ—ï¼Œå¯¼è‡´å»¶è¿Ÿå¢åŠ ï¼Œè€Œé›·è¾¾æ•°æ®è™½èƒ½ç›´æ¥æµ‹é‡å¤šæ™®å‹’é€Ÿåº¦ï¼Œä½†å…¶ç¨€ç–æ€§å’Œå™ªå£°ç»™æœ‰ç›‘ç£å­¦ä¹ å¸¦æ¥æŒ‘æˆ˜ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§åŸºäºèšç±»çš„å¯¹æ¯”è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€ç‚¹å»é™¤è¿›è¡Œèšç±»ç»†åŒ–ï¼Œä»è€Œé¢„è®­ç»ƒç½‘ç»œä»¥è·å¾—é›·è¾¾æ•°æ®çš„è¿åŠ¨æ„ŸçŸ¥è¡¨å¾ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¾®è°ƒåæé«˜äº†æ ‡ç­¾æ•ˆç‡ï¼Œå¹¶é€šè¿‡è‡ªç›‘ç£é¢„è®­ç»ƒæœ‰æ•ˆæå‡äº†ç°æœ‰æŠ€æœ¯çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç§»åŠ¨ç‰©ä½“åˆ†å‰²å¯¹äºè‡ªåŠ¨é©¾é©¶ç­‰è‡ªä¸»ç§»åŠ¨ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§è‡³å…³é‡è¦ï¼Œèƒ½å¤Ÿæå‡SLAMæˆ–è·¯å¾„è§„åˆ’ç­‰åç»­ä»»åŠ¡çš„å¯é æ€§å’Œé²æ£’æ€§ã€‚è™½ç„¶ç›¸æœºæˆ–æ¿€å…‰é›·è¾¾æ•°æ®çš„åˆ†å‰²ç ”ç©¶å¹¿æ³›ä¸”æˆæœæ˜¾è‘—ï¼Œä½†é€šå¸¸éœ€è¦ç§¯ç´¯æ—¶é—´åºåˆ—ä»¥è·å¾—å¿…è¦çš„æ—¶é—´ä¸Šä¸‹æ–‡ï¼Œä»è€Œå¢åŠ äº†å»¶è¿Ÿã€‚é›·è¾¾ä¼ æ„Ÿå™¨é€šè¿‡ç›´æ¥æµ‹é‡ç‚¹çš„å¤šæ™®å‹’é€Ÿåº¦å…‹æœäº†è¿™ä¸ªé—®é¢˜ï¼Œå¯ç”¨äºå•æ¬¡æ‰«æçš„ç§»åŠ¨ç‰©ä½“åˆ†å‰²ã€‚ç„¶è€Œï¼Œé›·è¾¾ç‚¹äº‘é€šå¸¸ç¨€ç–ä¸”å™ªå£°å¤§ï¼Œä½¿å¾—æœ‰ç›‘ç£å­¦ä¹ çš„æ•°æ®æ ‡æ³¨éå¸¸ç¹çã€è€—æ—¶ä¸”æˆæœ¬é«˜æ˜‚ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é’ˆå¯¹ç¨€ç–å’Œå™ªå£°é›·è¾¾ç‚¹äº‘çš„è‡ªç›‘ç£ç§»åŠ¨ç‰©ä½“åˆ†å‰²æ–¹æ³•ã€‚æˆ‘ä»¬é‡‡ç”¨å¯¹æ¯”è‡ªç›‘ç£è¡¨å¾å­¦ä¹ ä¸åç»­ä½¿ç”¨å°‘é‡æ ‡æ³¨æ•°æ®è¿›è¡Œç›‘ç£å¾®è°ƒçš„ä¸¤æ­¥æ–¹æ³•ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºèšç±»çš„å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œè¯¥å‡½æ•°åŸºäºåŠ¨æ€ç‚¹å»é™¤è¿›è¡Œèšç±»ç»†åŒ–ï¼Œä»¥é¢„è®­ç»ƒç½‘ç»œæ¥ç”Ÿæˆé›·è¾¾æ•°æ®çš„è¿åŠ¨æ„ŸçŸ¥è¡¨å¾ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¾®è°ƒåæé«˜äº†æ ‡ç­¾æ•ˆç‡ï¼Œé€šè¿‡è‡ªç›‘ç£é¢„è®­ç»ƒæœ‰æ•ˆåœ°æå‡äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç¨€ç–å’Œå™ªå£°é›·è¾¾ç‚¹äº‘ä¸­ç§»åŠ¨ç‰©ä½“åˆ†å‰²çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ä¾èµ–æœ‰ç›‘ç£å­¦ä¹ çš„æ–¹æ³•ï¼Œåœ¨é›·è¾¾æ•°æ®ä¸Šè¡¨ç°ä¸ä½³ï¼Œå› ä¸ºé›·è¾¾ç‚¹äº‘çš„æ ‡æ³¨æˆæœ¬é«˜æ˜‚ä¸”å®¹æ˜“å‡ºé”™ã€‚æ­¤å¤–ï¼Œç›´æ¥åˆ©ç”¨é›·è¾¾çš„å¤šæ™®å‹’ä¿¡æ¯è¿›è¡Œåˆ†å‰²ä¹Ÿé¢ä¸´å™ªå£°å¹²æ‰°å¤§çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ æ¥é¢„è®­ç»ƒä¸€ä¸ªèƒ½å¤Ÿæå–è¿åŠ¨æ„ŸçŸ¥ç‰¹å¾çš„ç¥ç»ç½‘ç»œã€‚é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œç½‘ç»œå¯ä»¥å­¦ä¹ åˆ°åŒºåˆ†ä¸åŒè¿åŠ¨æ¨¡å¼çš„ç‚¹äº‘è¡¨å¾ï¼Œä»è€Œåœ¨åç»­çš„ç›‘ç£å¾®è°ƒé˜¶æ®µï¼Œä»…éœ€å°‘é‡æ ‡æ³¨æ•°æ®å³å¯è¾¾åˆ°è‰¯å¥½çš„åˆ†å‰²æ•ˆæœã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨é™ä½å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œæé«˜é›·è¾¾æ•°æ®åˆ†å‰²çš„æ•ˆç‡å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š(1) è‡ªç›‘ç£é¢„è®­ç»ƒé˜¶æ®µï¼šåˆ©ç”¨æå‡ºçš„åŸºäºèšç±»çš„å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œè®­ç»ƒç½‘ç»œå­¦ä¹ é›·è¾¾ç‚¹äº‘çš„è¿åŠ¨æ„ŸçŸ¥è¡¨å¾ã€‚(2) ç›‘ç£å¾®è°ƒé˜¶æ®µï¼šä½¿ç”¨å°‘é‡æ ‡æ³¨æ•°æ®ï¼Œå¯¹é¢„è®­ç»ƒçš„ç½‘ç»œè¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶é€‚åº”ç‰¹å®šçš„åˆ†å‰²ä»»åŠ¡ã€‚æ•´ä½“æµç¨‹æ˜¯å…ˆé€šè¿‡è‡ªç›‘ç£å­¦ä¹ æå–æœ‰ç”¨çš„ç‰¹å¾ï¼Œå†é€šè¿‡ç›‘ç£å­¦ä¹ è¿›è¡Œç²¾ç»†è°ƒæ•´ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„åŸºäºèšç±»çš„å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œå¹¶ç»“åˆäº†åŠ¨æ€ç‚¹å»é™¤çš„èšç±»ç»†åŒ–ç­–ç•¥ã€‚ä¼ ç»Ÿçš„å¯¹æ¯”å­¦ä¹ æ–¹æ³•å¯èƒ½éš¾ä»¥å¤„ç†é›·è¾¾ç‚¹äº‘çš„ç¨€ç–æ€§å’Œå™ªå£°ã€‚é€šè¿‡èšç±»ï¼Œå¯ä»¥å°†ç›¸ä¼¼è¿åŠ¨æ¨¡å¼çš„ç‚¹äº‘èšé›†åœ¨ä¸€èµ·ï¼Œä»è€Œæé«˜å¯¹æ¯”å­¦ä¹ çš„æ•ˆç‡ã€‚åŠ¨æ€ç‚¹å»é™¤åˆ™å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–èšç±»ç»“æœï¼Œå‡å°‘å™ªå£°çš„å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è‡ªç›‘ç£é¢„è®­ç»ƒé˜¶æ®µï¼Œé¦–å…ˆå¯¹é›·è¾¾ç‚¹äº‘è¿›è¡Œèšç±»ï¼Œç„¶ååŸºäºèšç±»ç»“æœæ„å»ºæ­£è´Ÿæ ·æœ¬å¯¹ã€‚æ­£æ ·æœ¬å¯¹æ¥è‡ªåŒä¸€èšç±»ï¼Œè´Ÿæ ·æœ¬å¯¹æ¥è‡ªä¸åŒèšç±»ã€‚å¯¹æ¯”æŸå¤±å‡½æ•°çš„ç›®æ ‡æ˜¯æ‹‰è¿‘æ­£æ ·æœ¬å¯¹çš„è·ç¦»ï¼Œæ¨è¿œè´Ÿæ ·æœ¬å¯¹çš„è·ç¦»ã€‚åŠ¨æ€ç‚¹å»é™¤ç­–ç•¥åˆ™æ˜¯åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œç§»é™¤èšç±»ä¸­ç½®ä¿¡åº¦è¾ƒä½çš„ç‚¹ï¼Œä»è€Œä¼˜åŒ–èšç±»ç»“æœã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°å½¢å¼åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥è®ºæ–‡æå‡ºçš„è‡ªç›‘ç£æ–¹æ³•åœ¨é›·è¾¾ç‚¹äº‘ç§»åŠ¨ç‰©ä½“åˆ†å‰²ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚é€šè¿‡ä¸ç°æœ‰æ–¹æ³•è¿›è¡Œå¯¹æ¯”ï¼Œè¯æ˜äº†è‡ªç›‘ç£é¢„è®­ç»ƒèƒ½å¤Ÿæœ‰æ•ˆæé«˜æ ‡ç­¾æ•ˆç‡ï¼Œå³åœ¨å°‘é‡æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½è¾¾åˆ°ç”šè‡³è¶…è¿‡ç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡çš„å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†å±•ç¤ºï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½äº¤é€šç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜é›·è¾¾æ•°æ®çš„ç§»åŠ¨ç‰©ä½“åˆ†å‰²ç²¾åº¦ï¼Œå¯ä»¥å¢å¼ºè‡ªåŠ¨é©¾é©¶è½¦è¾†å¯¹å‘¨å›´ç¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œæé«˜è¡Œé©¶å®‰å…¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºæœºå™¨äººå¯¼èˆªï¼Œå¸®åŠ©æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­è¯†åˆ«å’Œé¿å¼€ç§»åŠ¨éšœç¢ç‰©ã€‚åœ¨æ™ºèƒ½äº¤é€šé¢†åŸŸï¼Œè¯¥æŠ€æœ¯å¯ä»¥ç”¨äºäº¤é€šæµé‡ç›‘æ§å’Œå¼‚å¸¸äº‹ä»¶æ£€æµ‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Moving object segmentation is a crucial task for safe and reliable autonomous mobile systems like self-driving cars, improving the reliability and robustness of subsequent tasks like SLAM or path planning. While the segmentation of camera or LiDAR data is widely researched and achieves great results, it often introduces an increased latency by requiring the accumulation of temporal sequences to gain the necessary temporal context. Radar sensors overcome this problem with their ability to provide a direct measurement of a point's Doppler velocity, which can be exploited for single-scan moving object segmentation. However, radar point clouds are often sparse and noisy, making data annotation for use in supervised learning very tedious, time-consuming, and cost-intensive. To overcome this problem, we address the task of self-supervised moving object segmentation of sparse and noisy radar point clouds. We follow a two-step approach of contrastive self-supervised representation learning with subsequent supervised fine-tuning using limited amounts of annotated data. We propose a novel clustering-based contrastive loss function with cluster refinement based on dynamic points removal to pretrain the network to produce motion-aware representations of the radar data. Our method improves label efficiency after fine-tuning, effectively boosting state-of-the-art performance by self-supervised pretraining.

