---
layout: default
title: Self-Supervised Moving Object Segmentation of Sparse and Noisy Radar Point Clouds
---

# Self-Supervised Moving Object Segmentation of Sparse and Noisy Radar Point Clouds

**arXiv**: [2511.02395v1](https://arxiv.org/abs/2511.02395) | [PDF](https://arxiv.org/pdf/2511.02395.pdf)

**ä½œè€…**: Leon Schwarzer, Matthias Zeller, Daniel Casado Herraez, Simon Dierl, Michael Heidingsfeld, Cyrill Stachniss

**åˆ†ç±»**: cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-04

**å¤‡æ³¨**: Accepted for publication at IEEE International Conference on Intelligent Transportation Systems (ITSC 2025), 8 pages, 3 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§è‡ªç›‘ç£é›·è¾¾ç‚¹äº‘ç§»åŠ¨ç‰©ä½“åˆ†å‰²æ–¹æ³•ï¼Œæå‡ç¨€ç–å™ªå£°æ•°æ®çš„åˆ†å‰²æ€§èƒ½ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `é›·è¾¾ç‚¹äº‘` `ç§»åŠ¨ç‰©ä½“åˆ†å‰²` `è‡ªç›‘ç£å­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `èšç±»` `è‡ªåŠ¨é©¾é©¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰ç›¸æœºå’Œæ¿€å…‰é›·è¾¾çš„ç§»åŠ¨ç‰©ä½“åˆ†å‰²æ–¹æ³•ä¾èµ–æ—¶é—´åºåˆ—ï¼Œå¯¼è‡´å»¶è¿Ÿå¢žåŠ ï¼Œè€Œé›·è¾¾æ•°æ®è™½èƒ½ç›´æŽ¥æµ‹é‡å¤šæ™®å‹’é€Ÿåº¦ï¼Œä½†å…¶ç¨€ç–æ€§å’Œå™ªå£°ç»™æœ‰ç›‘ç£å­¦ä¹ å¸¦æ¥æŒ‘æˆ˜ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§åŸºäºŽèšç±»çš„å¯¹æ¯”è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€ç‚¹åŽ»é™¤è¿›è¡Œèšç±»ç»†åŒ–ï¼Œä»Žè€Œé¢„è®­ç»ƒç½‘ç»œä»¥èŽ·å¾—é›·è¾¾æ•°æ®çš„è¿åŠ¨æ„ŸçŸ¥è¡¨å¾ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨å¾®è°ƒåŽæé«˜äº†æ ‡ç­¾æ•ˆçŽ‡ï¼Œå¹¶é€šè¿‡è‡ªç›‘ç£é¢„è®­ç»ƒæœ‰æ•ˆæå‡äº†çŽ°æœ‰æŠ€æœ¯çš„æ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç§»åŠ¨ç‰©ä½“åˆ†å‰²å¯¹äºŽè‡ªåŠ¨é©¾é©¶ç­‰è‡ªä¸»ç§»åŠ¨ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§è‡³å…³é‡è¦ï¼Œèƒ½å¤Ÿæå‡SLAMæˆ–è·¯å¾„è§„åˆ’ç­‰åŽç»­ä»»åŠ¡çš„å¯é æ€§å’Œé²æ£’æ€§ã€‚è™½ç„¶ç›¸æœºæˆ–æ¿€å…‰é›·è¾¾æ•°æ®çš„åˆ†å‰²ç ”ç©¶å¹¿æ³›ä¸”æˆæžœæ˜¾è‘—ï¼Œä½†é€šå¸¸éœ€è¦ç§¯ç´¯æ—¶é—´åºåˆ—ä»¥èŽ·å¾—å¿…è¦çš„æ—¶é—´ä¸Šä¸‹æ–‡ï¼Œä»Žè€Œå¢žåŠ äº†å»¶è¿Ÿã€‚é›·è¾¾ä¼ æ„Ÿå™¨é€šè¿‡ç›´æŽ¥æµ‹é‡ç‚¹çš„å¤šæ™®å‹’é€Ÿåº¦å…‹æœäº†è¿™ä¸ªé—®é¢˜ï¼Œå¯ç”¨äºŽå•æ¬¡æ‰«æçš„ç§»åŠ¨ç‰©ä½“åˆ†å‰²ã€‚ç„¶è€Œï¼Œé›·è¾¾ç‚¹äº‘é€šå¸¸ç¨€ç–ä¸”å™ªå£°å¤§ï¼Œä½¿å¾—æœ‰ç›‘ç£å­¦ä¹ çš„æ•°æ®æ ‡æ³¨éžå¸¸ç¹çã€è€—æ—¶ä¸”æˆæœ¬é«˜æ˜‚ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é’ˆå¯¹ç¨€ç–å’Œå™ªå£°é›·è¾¾ç‚¹äº‘çš„è‡ªç›‘ç£ç§»åŠ¨ç‰©ä½“åˆ†å‰²æ–¹æ³•ã€‚æˆ‘ä»¬é‡‡ç”¨å¯¹æ¯”è‡ªç›‘ç£è¡¨å¾å­¦ä¹ ä¸ŽåŽç»­ä½¿ç”¨å°‘é‡æ ‡æ³¨æ•°æ®è¿›è¡Œç›‘ç£å¾®è°ƒçš„ä¸¤æ­¥æ–¹æ³•ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºŽèšç±»çš„å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œè¯¥å‡½æ•°åŸºäºŽåŠ¨æ€ç‚¹åŽ»é™¤è¿›è¡Œèšç±»ç»†åŒ–ï¼Œä»¥é¢„è®­ç»ƒç½‘ç»œæ¥ç”Ÿæˆé›·è¾¾æ•°æ®çš„è¿åŠ¨æ„ŸçŸ¥è¡¨å¾ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¾®è°ƒåŽæé«˜äº†æ ‡ç­¾æ•ˆçŽ‡ï¼Œé€šè¿‡è‡ªç›‘ç£é¢„è®­ç»ƒæœ‰æ•ˆåœ°æå‡äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç¨€ç–å’Œå™ªå£°é›·è¾¾ç‚¹äº‘ä¸­ç§»åŠ¨ç‰©ä½“åˆ†å‰²çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ä¾èµ–æœ‰ç›‘ç£å­¦ä¹ çš„æ–¹æ³•ï¼Œåœ¨é›·è¾¾æ•°æ®ä¸Šè¡¨çŽ°ä¸ä½³ï¼Œå› ä¸ºé›·è¾¾ç‚¹äº‘çš„æ ‡æ³¨æˆæœ¬é«˜æ˜‚ä¸”å®¹æ˜“å‡ºé”™ã€‚æ­¤å¤–ï¼Œç›´æŽ¥åˆ©ç”¨é›·è¾¾çš„å¤šæ™®å‹’ä¿¡æ¯è¿›è¡Œåˆ†å‰²ä¹Ÿé¢ä¸´å™ªå£°å¹²æ‰°å¤§çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ æ¥é¢„è®­ç»ƒä¸€ä¸ªèƒ½å¤Ÿæå–è¿åŠ¨æ„ŸçŸ¥ç‰¹å¾çš„ç¥žç»ç½‘ç»œã€‚é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œç½‘ç»œå¯ä»¥å­¦ä¹ åˆ°åŒºåˆ†ä¸åŒè¿åŠ¨æ¨¡å¼çš„ç‚¹äº‘è¡¨å¾ï¼Œä»Žè€Œåœ¨åŽç»­çš„ç›‘ç£å¾®è°ƒé˜¶æ®µï¼Œä»…éœ€å°‘é‡æ ‡æ³¨æ•°æ®å³å¯è¾¾åˆ°è‰¯å¥½çš„åˆ†å‰²æ•ˆæžœã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨é™ä½Žå¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œæé«˜é›·è¾¾æ•°æ®åˆ†å‰²çš„æ•ˆçŽ‡å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š(1) è‡ªç›‘ç£é¢„è®­ç»ƒé˜¶æ®µï¼šåˆ©ç”¨æå‡ºçš„åŸºäºŽèšç±»çš„å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œè®­ç»ƒç½‘ç»œå­¦ä¹ é›·è¾¾ç‚¹äº‘çš„è¿åŠ¨æ„ŸçŸ¥è¡¨å¾ã€‚(2) ç›‘ç£å¾®è°ƒé˜¶æ®µï¼šä½¿ç”¨å°‘é‡æ ‡æ³¨æ•°æ®ï¼Œå¯¹é¢„è®­ç»ƒçš„ç½‘ç»œè¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶é€‚åº”ç‰¹å®šçš„åˆ†å‰²ä»»åŠ¡ã€‚æ•´ä½“æµç¨‹æ˜¯å…ˆé€šè¿‡è‡ªç›‘ç£å­¦ä¹ æå–æœ‰ç”¨çš„ç‰¹å¾ï¼Œå†é€šè¿‡ç›‘ç£å­¦ä¹ è¿›è¡Œç²¾ç»†è°ƒæ•´ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„åŸºäºŽèšç±»çš„å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œå¹¶ç»“åˆäº†åŠ¨æ€ç‚¹åŽ»é™¤çš„èšç±»ç»†åŒ–ç­–ç•¥ã€‚ä¼ ç»Ÿçš„å¯¹æ¯”å­¦ä¹ æ–¹æ³•å¯èƒ½éš¾ä»¥å¤„ç†é›·è¾¾ç‚¹äº‘çš„ç¨€ç–æ€§å’Œå™ªå£°ã€‚é€šè¿‡èšç±»ï¼Œå¯ä»¥å°†ç›¸ä¼¼è¿åŠ¨æ¨¡å¼çš„ç‚¹äº‘èšé›†åœ¨ä¸€èµ·ï¼Œä»Žè€Œæé«˜å¯¹æ¯”å­¦ä¹ çš„æ•ˆçŽ‡ã€‚åŠ¨æ€ç‚¹åŽ»é™¤åˆ™å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–èšç±»ç»“æžœï¼Œå‡å°‘å™ªå£°çš„å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è‡ªç›‘ç£é¢„è®­ç»ƒé˜¶æ®µï¼Œé¦–å…ˆå¯¹é›·è¾¾ç‚¹äº‘è¿›è¡Œèšç±»ï¼Œç„¶åŽåŸºäºŽèšç±»ç»“æžœæž„å»ºæ­£è´Ÿæ ·æœ¬å¯¹ã€‚æ­£æ ·æœ¬å¯¹æ¥è‡ªåŒä¸€èšç±»ï¼Œè´Ÿæ ·æœ¬å¯¹æ¥è‡ªä¸åŒèšç±»ã€‚å¯¹æ¯”æŸå¤±å‡½æ•°çš„ç›®æ ‡æ˜¯æ‹‰è¿‘æ­£æ ·æœ¬å¯¹çš„è·ç¦»ï¼ŒæŽ¨è¿œè´Ÿæ ·æœ¬å¯¹çš„è·ç¦»ã€‚åŠ¨æ€ç‚¹åŽ»é™¤ç­–ç•¥åˆ™æ˜¯åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œç§»é™¤èšç±»ä¸­ç½®ä¿¡åº¦è¾ƒä½Žçš„ç‚¹ï¼Œä»Žè€Œä¼˜åŒ–èšç±»ç»“æžœã€‚å…·ä½“çš„ç½‘ç»œç»“æž„å’ŒæŸå¤±å‡½æ•°å½¢å¼åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è¯¥è®ºæ–‡æå‡ºçš„è‡ªç›‘ç£æ–¹æ³•åœ¨é›·è¾¾ç‚¹äº‘ç§»åŠ¨ç‰©ä½“åˆ†å‰²ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚é€šè¿‡ä¸ŽçŽ°æœ‰æ–¹æ³•è¿›è¡Œå¯¹æ¯”ï¼Œè¯æ˜Žäº†è‡ªç›‘ç£é¢„è®­ç»ƒèƒ½å¤Ÿæœ‰æ•ˆæé«˜æ ‡ç­¾æ•ˆçŽ‡ï¼Œå³åœ¨å°‘é‡æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½è¾¾åˆ°ç”šè‡³è¶…è¿‡çŽ°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡çš„å®žéªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†å±•ç¤ºï¼ˆæœªçŸ¥ï¼‰ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½äº¤é€šç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜é›·è¾¾æ•°æ®çš„ç§»åŠ¨ç‰©ä½“åˆ†å‰²ç²¾åº¦ï¼Œå¯ä»¥å¢žå¼ºè‡ªåŠ¨é©¾é©¶è½¦è¾†å¯¹å‘¨å›´çŽ¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œæé«˜è¡Œé©¶å®‰å…¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºŽæœºå™¨äººå¯¼èˆªï¼Œå¸®åŠ©æœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸­è¯†åˆ«å’Œé¿å¼€ç§»åŠ¨éšœç¢ç‰©ã€‚åœ¨æ™ºèƒ½äº¤é€šé¢†åŸŸï¼Œè¯¥æŠ€æœ¯å¯ä»¥ç”¨äºŽäº¤é€šæµé‡ç›‘æŽ§å’Œå¼‚å¸¸äº‹ä»¶æ£€æµ‹ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Moving object segmentation is a crucial task for safe and reliable autonomous mobile systems like self-driving cars, improving the reliability and robustness of subsequent tasks like SLAM or path planning. While the segmentation of camera or LiDAR data is widely researched and achieves great results, it often introduces an increased latency by requiring the accumulation of temporal sequences to gain the necessary temporal context. Radar sensors overcome this problem with their ability to provide a direct measurement of a point's Doppler velocity, which can be exploited for single-scan moving object segmentation. However, radar point clouds are often sparse and noisy, making data annotation for use in supervised learning very tedious, time-consuming, and cost-intensive. To overcome this problem, we address the task of self-supervised moving object segmentation of sparse and noisy radar point clouds. We follow a two-step approach of contrastive self-supervised representation learning with subsequent supervised fine-tuning using limited amounts of annotated data. We propose a novel clustering-based contrastive loss function with cluster refinement based on dynamic points removal to pretrain the network to produce motion-aware representations of the radar data. Our method improves label efficiency after fine-tuning, effectively boosting state-of-the-art performance by self-supervised pretraining.

