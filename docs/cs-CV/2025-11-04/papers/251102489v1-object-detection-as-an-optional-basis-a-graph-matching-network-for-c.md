---
layout: default
title: Object Detection as an Optional Basis: A Graph Matching Network for Cross-View UAV Localization
---

# Object Detection as an Optional Basis: A Graph Matching Network for Cross-View UAV Localization

**arXiv**: [2511.02489v1](https://arxiv.org/abs/2511.02489) | [PDF](https://arxiv.org/pdf/2511.02489.pdf)

**ä½œè€…**: Tao Liu, Kan Ren, Qian Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå¯¹è±¡æ£€æµ‹å’Œå›¾ç¥žç»ç½‘ç»œçš„è·¨è§†è§’æ— äººæœºå®šä½æ–¹æ³•ï¼Œä»¥è§£å†³GNSSç¼ºå¤±åŒºåŸŸçš„å›¾åƒåŒ¹é…é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ— äººæœºå®šä½` `è·¨è§†è§’åŒ¹é…` `å¯¹è±¡æ£€æµ‹` `å›¾ç¥žç»ç½‘ç»œ` `å›¾åƒæ£€ç´¢` `å¼‚æž„å›¾åƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåœ¨GNSSç¼ºå¤±åŒºåŸŸï¼Œæ— äººæœºè§†è§‰å®šä½é¢ä¸´è·¨è§†è§’ã€è·¨æ—¶ç›¸å’Œå¼‚æž„å›¾åƒåŒ¹é…çš„æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨å¯¹è±¡æ£€æµ‹æå–æ˜¾è‘—å®žä¾‹ï¼Œç»“åˆå›¾ç¥žç»ç½‘ç»œæŽ¨ç†èŠ‚ç‚¹å…³ç³»ï¼Œå®žçŽ°ç²¾ç»†åŒ¹é…ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å…¬å¼€å’ŒçœŸå®žæ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæœ‰æ•ˆå¤„ç†å¼‚æž„å¤–è§‚å·®å¼‚ï¼Œæ³›åŒ–èƒ½åŠ›å¼ºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> With the rapid growth of the low-altitude economy, UAVs have become crucial
> for measurement and tracking in patrol systems. However, in GNSS-denied areas,
> satellite-based localization methods are prone to failure. This paper presents
> a cross-view UAV localization framework that performs map matching via object
> detection, aimed at effectively addressing cross-temporal, cross-view,
> heterogeneous aerial image matching. In typical pipelines, UAV visual
> localization is formulated as an image-retrieval problem: features are
> extracted to build a localization map, and the pose of a query image is
> estimated by matching it to a reference database with known poses. Because
> publicly available UAV localization datasets are limited, many approaches
> recast localization as a classification task and rely on scene labels in these
> datasets to ensure accuracy. Other methods seek to reduce cross-domain
> differences using polar-coordinate reprojection, perspective transformations,
> or generative adversarial networks; however, they can suffer from misalignment,
> content loss, and limited realism. In contrast, we leverage modern object
> detection to accurately extract salient instances from UAV and satellite
> images, and integrate a graph neural network to reason about inter-image and
> intra-image node relationships. Using a fine-grained, graph-based
> node-similarity metric, our method achieves strong retrieval and localization
> performance. Extensive experiments on public and real-world datasets show that
> our approach handles heterogeneous appearance differences effectively and
> generalizes well, making it applicable to scenarios with larger modality gaps,
> such as infrared-visible image matching. Our dataset will be publicly available
> at the following URL: https://github.com/liutao23/ODGNNLoc.git.

