---
layout: default
title: SigmaCollab: An Application-Driven Dataset for Physically Situated Collaboration
---

# SigmaCollab: An Application-Driven Dataset for Physically Situated Collaboration

**arXiv**: [2511.02560v1](https://arxiv.org/abs/2511.02560) | [PDF](https://arxiv.org/pdf/2511.02560.pdf)

**ä½œè€…**: Dan Bohus, Sean Andrist, Ann Paradiso, Nick Saw, Tim Schoonbeek, Maia Stiber

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSigmaCollabæ•°æ®é›†ä»¥æ”¯æŒç‰©ç†æƒ…å¢ƒä¸‹çš„äººæœºåä½œç ”ç©¶**

**å…³é”®è¯**: `äººæœºåä½œ` `å¤šæ¨¡æ€æ•°æ®é›†` `æ··åˆçŽ°å®ž` `ç‰©ç†æƒ…å¢ƒä»»åŠ¡` `AIè¾…åŠ©ç³»ç»Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç‰©ç†æƒ…å¢ƒä¸‹äººæœºåä½œç¼ºä¹çœŸå®žå¤šæ¨¡æ€æ•°æ®æ”¯æŒ
2. æ–¹æ³•è¦ç‚¹ï¼šæ”¶é›†85ä¸ªä¼šè¯ï¼ŒåŒ…å«éŸ³é¢‘ã€è§†è§‰ã€è¿½è¸ªç­‰å¤šæ¨¡æ€æ•°æ®
3. å®žéªŒæˆ–æ•ˆæžœï¼šæä¾›çº¦14å°æ—¶æ•°æ®ï¼Œç”¨äºŽæž„å»ºæ··åˆçŽ°å®žä»»åŠ¡åŸºå‡†

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce SigmaCollab, a dataset enabling research on physically situated
> human-AI collaboration. The dataset consists of a set of 85 sessions in which
> untrained participants were guided by a mixed-reality assistive AI agent in
> performing procedural tasks in the physical world. SigmaCollab includes a set
> of rich, multimodal data streams, such as the participant and system audio,
> egocentric camera views from the head-mounted device, depth maps, head, hand
> and gaze tracking information, as well as additional annotations performed
> post-hoc. While the dataset is relatively small in size (~ 14 hours), its
> application-driven and interactive nature brings to the fore novel research
> challenges for human-AI collaboration, and provides more realistic testing
> grounds for various AI models operating in this space. In future work, we plan
> to use the dataset to construct a set of benchmarks for physically situated
> collaboration in mixed-reality task assistive scenarios. SigmaCollab is
> available at https://github.com/microsoft/SigmaCollab.

