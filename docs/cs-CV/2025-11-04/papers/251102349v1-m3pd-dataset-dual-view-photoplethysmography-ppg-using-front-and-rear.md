---
layout: default
title: M3PD Dataset: Dual-view Photoplethysmography (PPG) Using Front-and-rear Cameras of Smartphones in Lab and Clinical Settings
---

# M3PD Dataset: Dual-view Photoplethysmography (PPG) Using Front-and-rear Cameras of Smartphones in Lab and Clinical Settings

**arXiv**: [2511.02349v1](https://arxiv.org/abs/2511.02349) | [PDF](https://arxiv.org/pdf/2511.02349.pdf)

**ä½œè€…**: Jiankai Tang, Tao Zhang, Jia Li, Yiru Zhang, Mingyu Zhang, Kegang Wang, Yuming Hao, Bolin Wang, Haiyang Li, Xingyao Wang, Yuanchun Shi, Yuntao Wang, Sichong Qian

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºM3PDæ•°æ®é›†å’ŒF3Mambaæ¨¡åž‹ï¼Œé€šè¿‡åŒè§†å›¾PPGæå‡æ™ºèƒ½æ‰‹æœºå¿ƒçŽ‡ç›‘æµ‹çš„é²æ£’æ€§ã€‚**

**å…³é”®è¯**: `åŒè§†å›¾å…‰ç”µå®¹ç§¯æè®°` `æ™ºèƒ½æ‰‹æœºç”Ÿç†ç›‘æµ‹` `Mambaæ—¶åºå»ºæ¨¡` `å¿ƒè¡€ç®¡æ‚£è€…æ•°æ®é›†` `å¿ƒçŽ‡ä¼°è®¡` `è¿åŠ¨ä¼ªå½±é²æ£’æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ™ºèƒ½æ‰‹æœºå•è§†å›¾PPGæ˜“å—è¿åŠ¨ä¼ªå½±ã€å…‰ç…§å˜åŒ–å½±å“ï¼Œç¼ºä¹å¿ƒè¡€ç®¡æ‚£è€…å¯é æ•°æ®é›†ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºé¦–ä¸ªå…¬å¼€åŒè§†å›¾PPGæ•°æ®é›†ï¼Œèžåˆé¢éƒ¨å’ŒæŒ‡å°–è§†é¢‘ï¼Œä½¿ç”¨Mambaè¿›è¡Œæ—¶åºå»ºæ¨¡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨60åå‚ä¸Žè€…ä¸­ï¼Œå¿ƒçŽ‡è¯¯å·®é™ä½Ž21.9-30.2%ï¼Œå¢žå¼ºçœŸå®žåœºæ™¯é²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Portable physiological monitoring is essential for early detection and
> management of cardiovascular disease, but current methods often require
> specialized equipment that limits accessibility or impose impractical postures
> that patients cannot maintain. Video-based photoplethysmography on smartphones
> offers a convenient noninvasive alternative, yet it still faces reliability
> challenges caused by motion artifacts, lighting variations, and single-view
> constraints. Few studies have demonstrated reliable application to
> cardiovascular patients, and no widely used open datasets exist for
> cross-device accuracy. To address these limitations, we introduce the M3PD
> dataset, the first publicly available dual-view mobile photoplethysmography
> dataset, comprising synchronized facial and fingertip videos captured
> simultaneously via front and rear smartphone cameras from 60 participants
> (including 47 cardiovascular patients). Building on this dual-view setting, we
> further propose F3Mamba, which fuses the facial and fingertip views through
> Mamba-based temporal modeling. The model reduces heart-rate error by 21.9 to
> 30.2 percent over existing single-view baselines while improving robustness in
> challenging real-world scenarios. Data and code:
> https://github.com/Health-HCI-Group/F3Mamba.

