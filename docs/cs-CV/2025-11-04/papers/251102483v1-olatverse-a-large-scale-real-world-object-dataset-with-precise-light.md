---
layout: default
title: OLATverse: A Large-scale Real-world Object Dataset with Precise Lighting Control
---

# OLATverse: A Large-scale Real-world Object Dataset with Precise Lighting Control

**arXiv**: [2511.02483v1](https://arxiv.org/abs/2511.02483) | [PDF](https://arxiv.org/pdf/2511.02483.pdf)

**ä½œè€…**: Xilong Zhou, Jianchun Chen, Pramod Rao, Timo Teufel, Linjie Lyu, Tigran Minasian, Oleksandr Sotnychenko, Xiaoxiao Long, Marc Habermann, Christian Theobalt

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOLATverseå¤§è§„æ¨¡çœŸå®žç‰©ä½“æ•°æ®é›†ï¼Œä»¥è§£å†³é€†æ¸²æŸ“å’Œé‡å…‰ç…§æ–¹æ³•å¯¹åˆæˆæ•°æ®ä¾èµ–çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `é€†æ¸²æŸ“` `é‡å…‰ç…§` `çœŸå®žç‰©ä½“æ•°æ®é›†` `å…‰ç…§æŽ§åˆ¶` `å¤šè§†è§’æ•èŽ·` `åŸºå‡†è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰é€†æ¸²æŸ“å’Œé‡å…‰ç…§æ–¹æ³•ä¾èµ–åˆæˆæ•°æ®é›†ï¼Œé™åˆ¶çœŸå®žæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŒ…å«765ä¸ªçœŸå®žç‰©ä½“ï¼Œåœ¨ç²¾ç¡®æŽ§åˆ¶å…‰ç…§ä¸‹ä»Žå¤šè§†è§’æ•èŽ·çº¦900ä¸‡å¼ å›¾åƒã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæä¾›æ ¡å‡†ç›¸æœºå‚æ•°ã€ç‰©ä½“æŽ©ç ç­‰èµ„æºï¼Œå¹¶å»ºç«‹é¦–ä¸ªçœŸå®žä¸–ç•Œç‰©ä½“ä¸­å¿ƒåŸºå‡†ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce OLATverse, a large-scale dataset comprising around 9M images of
> 765 real-world objects, captured from multiple viewpoints under a diverse set
> of precisely controlled lighting conditions. While recent advances in
> object-centric inverse rendering, novel view synthesis and relighting have
> shown promising results, most techniques still heavily rely on the synthetic
> datasets for training and small-scale real-world datasets for benchmarking,
> which limits their realism and generalization. To address this gap, OLATverse
> offers two key advantages over existing datasets: large-scale coverage of real
> objects and high-fidelity appearance under precisely controlled illuminations.
> Specifically, OLATverse contains 765 common and uncommon real-world objects,
> spanning a wide range of material categories. Each object is captured using 35
> DSLR cameras and 331 individually controlled light sources, enabling the
> simulation of diverse illumination conditions. In addition, for each object, we
> provide well-calibrated camera parameters, accurate object masks, photometric
> surface normals, and diffuse albedo as auxiliary resources. We also construct
> an extensive evaluation set, establishing the first comprehensive real-world
> object-centric benchmark for inverse rendering and normal estimation. We
> believe that OLATverse represents a pivotal step toward integrating the next
> generation of inverse rendering and relighting methods with real-world data.
> The full dataset, along with all post-processing workflows, will be publicly
> released at https://vcai.mpi-inf.mpg.de/projects/OLATverse/.

