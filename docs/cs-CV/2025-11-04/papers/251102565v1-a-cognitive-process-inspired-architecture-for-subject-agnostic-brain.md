---
layout: default
title: A Cognitive Process-Inspired Architecture for Subject-Agnostic Brain Visual Decoding
---

# A Cognitive Process-Inspired Architecture for Subject-Agnostic Brain Visual Decoding

**arXiv**: [2511.02565v1](https://arxiv.org/abs/2511.02565) | [PDF](https://arxiv.org/pdf/2511.02565.pdf)

**ä½œè€…**: Jingyu Lu, Haonan Wang, Qixiang Zhang, Xiaomeng Li

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVCFlowæž¶æž„ä»¥è§£å†³è·¨è¢«è¯•è„‘è§†è§‰è§£ç çš„æ³›åŒ–é—®é¢˜**

**å…³é”®è¯**: `è„‘è§†è§‰è§£ç ` `è·¨è¢«è¯•æ³›åŒ–` `è§†è§‰ç³»ç»Ÿå»ºæ¨¡` `å¯¹æ¯”å­¦ä¹ ` `å¿«é€Ÿé‡å»º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè·¨è¢«è¯•è„‘ä¿¡å·è§£ç æ³›åŒ–éš¾ï¼Œéœ€å¤§é‡ä¸ªä½“æ•°æ®ä¸Žè®¡ç®—
2. æ–¹æ³•è¦ç‚¹ï¼šæ¨¡æ‹Ÿè§†è§‰ç³»ç»Ÿè…¹èƒŒæµï¼Œè§£è€¦ç‰¹å¾å¹¶é‡‡ç”¨å¯¹æ¯”å­¦ä¹ 
3. å®žéªŒæˆ–æ•ˆæžœï¼šç‰ºç‰²7%ç²¾åº¦ï¼Œ10ç§’ç”Ÿæˆè§†é¢‘ï¼Œæ— éœ€é‡è®­ç»ƒ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Subject-agnostic brain decoding, which aims to reconstruct continuous visual
> experiences from fMRI without subject-specific training, holds great potential
> for clinical applications. However, this direction remains underexplored due to
> challenges in cross-subject generalization and the complex nature of brain
> signals. In this work, we propose Visual Cortex Flow Architecture (VCFlow), a
> novel hierarchical decoding framework that explicitly models the ventral-dorsal
> architecture of the human visual system to learn multi-dimensional
> representations. By disentangling and leveraging features from early visual
> cortex, ventral, and dorsal streams, VCFlow captures diverse and complementary
> cognitive information essential for visual reconstruction. Furthermore, we
> introduce a feature-level contrastive learning strategy to enhance the
> extraction of subject-invariant semantic representations, thereby enhancing
> subject-agnostic applicability to previously unseen subjects. Unlike
> conventional pipelines that need more than 12 hours of per-subject data and
> heavy computation, VCFlow sacrifices only 7\% accuracy on average yet generates
> each reconstructed video in 10 seconds without any retraining, offering a fast
> and clinically scalable solution. The source code will be released upon
> acceptance of the paper.

