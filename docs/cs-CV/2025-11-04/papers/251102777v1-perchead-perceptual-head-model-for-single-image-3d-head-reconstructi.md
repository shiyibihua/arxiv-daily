---
layout: default
title: PercHead: Perceptual Head Model for Single-Image 3D Head Reconstruction & Editing
---

# PercHead: Perceptual Head Model for Single-Image 3D Head Reconstruction & Editing

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.02777" target="_blank" class="toolbar-btn">arXiv: 2511.02777v1</a>
    <a href="https://arxiv.org/pdf/2511.02777.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.02777v1" 
            onclick="toggleFavorite(this, '2511.02777v1', 'PercHead: Perceptual Head Model for Single-Image 3D Head Reconstruction & Editing')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Antonio Oroz, Matthias NieÃŸner, Tobias Kirschstein

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-04

**å¤‡æ³¨**: Project Page: https://antoniooroz.github.io/PercHead/ Video: https://www.youtube.com/watch?v=4hFybgTk4kE

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://antoniooroz.github.io/PercHead)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PercHeadï¼šæå‡ºåŸºäºæ„ŸçŸ¥çš„å¤´éƒ¨æ¨¡å‹ï¼Œç”¨äºå•å›¾åƒ3Då¤´éƒ¨é‡å»ºä¸ç¼–è¾‘**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `3Då¤´éƒ¨é‡å»º` `è¯­ä¹‰ç¼–è¾‘` `å•å›¾åƒé‡å»º` `æ„ŸçŸ¥ç›‘ç£` `é«˜æ–¯æº…å°„` `ViTè§£ç å™¨` `DINOv2` `SAM2.1`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å•å›¾åƒ3Då¤´éƒ¨é‡å»ºå’Œç¼–è¾‘é¢ä¸´è§†è§’é®æŒ¡ã€å¼±ç›‘ç£å’Œç¼–è¾‘æ¨¡ç³Šæ€§ç­‰æŒ‘æˆ˜ã€‚
2. PercHeadåˆ©ç”¨åŒåˆ†æ”¯ç¼–ç å™¨å’ŒViTè§£ç å™¨ï¼Œç»“åˆDINOv2å’ŒSAM2.1çš„æ„ŸçŸ¥ç›‘ç£ï¼Œå®ç°é«˜è´¨é‡é‡å»ºã€‚
3. å®éªŒè¡¨æ˜ï¼ŒPercHeadåœ¨novel-view synthesisä¸­è¾¾åˆ°SOTAï¼Œå¹¶å…·å¤‡å¼ºå¤§çš„3Dè¯­ä¹‰ç¼–è¾‘èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºPercHeadï¼Œä¸€ç§ç”¨äºå•å›¾åƒ3Då¤´éƒ¨é‡å»ºå’Œè¯­ä¹‰3Dç¼–è¾‘çš„æ–¹æ³•ã€‚ç”±äºä¸¥é‡çš„è§†è§’é®æŒ¡ã€å¼±æ„ŸçŸ¥ç›‘ç£ä»¥åŠ3Dç©ºé—´ç¼–è¾‘çš„æ¨¡ç³Šæ€§ï¼Œè¿™ä¸¤é¡¹ä»»åŠ¡éƒ½æå…·æŒ‘æˆ˜æ€§ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç»Ÿä¸€çš„åŸºç¡€æ¨¡å‹ï¼Œç”¨äºä»å•ä¸ªè¾“å…¥å›¾åƒé‡å»ºè§†è§’ä¸€è‡´çš„3Då¤´éƒ¨ã€‚è¯¥æ¨¡å‹é‡‡ç”¨åŒåˆ†æ”¯ç¼–ç å™¨ï¼Œåæ¥åŸºäºViTçš„è§£ç å™¨ï¼Œé€šè¿‡è¿­ä»£äº¤å‰æ³¨æ„åŠ›å°†2Dç‰¹å¾æå‡åˆ°3Dç©ºé—´ã€‚æ¸²æŸ“ä½¿ç”¨é«˜æ–¯æº…å°„ã€‚æˆ‘ä»¬æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ä¸€ç§åŸºäºDINOv2å’ŒSAM2.1çš„æ–°å‹æ„ŸçŸ¥ç›‘ç£ç­–ç•¥ï¼Œå®ƒä¸ºå‡ ä½•å’Œå¤–è§‚ä¿çœŸåº¦æä¾›äº†ä¸°å¯Œçš„ã€æ³›åŒ–çš„ä¿¡å·ã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨novel-view synthesisä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”ä¸å·²å»ºç«‹çš„åŸºçº¿ç›¸æ¯”ï¼Œå¯¹æç«¯è§†è§’çš„é²æ£’æ€§è¡¨ç°å‡ºè‰²ã€‚æ­¤å¤–ï¼Œé€šè¿‡äº¤æ¢ç¼–ç å™¨å¹¶å¾®è°ƒç½‘ç»œï¼Œè¿™ä¸ªåŸºç¡€æ¨¡å‹å¯ä»¥æ— ç¼æ‰©å±•ç”¨äºè¯­ä¹‰3Dç¼–è¾‘ã€‚åœ¨è¿™ç§å˜ä½“ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä¸¤ç§ä¸åŒçš„è¾“å…¥æ¨¡æ€æ¥è§£è€¦å‡ ä½•å’Œé£æ ¼ï¼šåˆ†å‰²å›¾ç”¨äºæ§åˆ¶å‡ ä½•ï¼Œæ–‡æœ¬æç¤ºæˆ–å‚è€ƒå›¾åƒç”¨äºæŒ‡å®šå¤–è§‚ã€‚æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªè½»é‡çº§çš„äº¤äº’å¼GUIçªå‡ºäº†æˆ‘ä»¬æ¨¡å‹ç›´è§‚è€Œå¼ºå¤§çš„3Dç¼–è¾‘èƒ½åŠ›ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ç»˜åˆ¶åˆ†å‰²å›¾è½»æ¾åœ°é›•åˆ»å‡ ä½•å½¢çŠ¶ï¼Œå¹¶é€šè¿‡è‡ªç„¶è¯­è¨€æˆ–å›¾åƒæç¤ºæ¥è®¾è®¡å¤–è§‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å•å¼ å›¾åƒ3Då¤´éƒ¨é‡å»ºå’Œè¯­ä¹‰ç¼–è¾‘é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è§†è§’é®æŒ¡ã€ç¼ºä¹æœ‰æ•ˆçš„æ„ŸçŸ¥ç›‘ç£ä»¥åŠ3Dç¼–è¾‘çš„æ¨¡ç³Šæ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´é‡å»ºè´¨é‡å’Œç¼–è¾‘æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç»“åˆæ–°å‹çš„æ„ŸçŸ¥ç›‘ç£ç­–ç•¥ï¼Œä»å•å¼ å›¾åƒä¸­æ¨æ–­å‡ºé«˜è´¨é‡çš„3Då¤´éƒ¨æ¨¡å‹ï¼Œå¹¶å®ç°å¯æ§çš„è¯­ä¹‰ç¼–è¾‘ã€‚é€šè¿‡è§£è€¦å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚é£æ ¼ï¼Œç”¨æˆ·å¯ä»¥ç›´è§‚åœ°ä¿®æ”¹3Då¤´éƒ¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPercHeadæ¨¡å‹åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) åŒåˆ†æ”¯ç¼–ç å™¨ï¼šæå–è¾“å…¥å›¾åƒçš„ç‰¹å¾ã€‚2) åŸºäºViTçš„è§£ç å™¨ï¼šé€šè¿‡è¿­ä»£äº¤å‰æ³¨æ„åŠ›å°†2Dç‰¹å¾æå‡åˆ°3Dç©ºé—´ï¼Œç”Ÿæˆ3Då¤´éƒ¨è¡¨ç¤ºã€‚3) é«˜æ–¯æº…å°„æ¸²æŸ“å™¨ï¼šå°†3Då¤´éƒ¨è¡¨ç¤ºæ¸²æŸ“æˆå›¾åƒã€‚4) æ„ŸçŸ¥ç›‘ç£æ¨¡å—ï¼šåˆ©ç”¨DINOv2å’ŒSAM2.1æä¾›å‡ ä½•å’Œå¤–è§‚ä¿çœŸåº¦çš„ç›‘ç£ä¿¡å·ã€‚åœ¨è¯­ä¹‰ç¼–è¾‘æ¨¡å¼ä¸‹ï¼Œç¼–ç å™¨è¢«æ›¿æ¢ï¼Œè¾“å…¥å˜ä¸ºåˆ†å‰²å›¾ï¼ˆæ§åˆ¶å‡ ä½•ï¼‰å’Œæ–‡æœ¬/å›¾åƒæç¤ºï¼ˆæ§åˆ¶å¤–è§‚ï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†åŸºäºDINOv2å’ŒSAM2.1çš„æ„ŸçŸ¥ç›‘ç£ç­–ç•¥ã€‚ä¸ä¼ ç»Ÿçš„åƒç´ çº§æˆ–ç‰¹å¾çº§ç›‘ç£ç›¸æ¯”ï¼Œè¿™ç§ç­–ç•¥èƒ½å¤Ÿæä¾›æ›´ä¸°å¯Œã€æ›´æ³›åŒ–çš„ç›‘ç£ä¿¡å·ï¼Œä»è€Œæé«˜é‡å»ºè´¨é‡å’Œç¼–è¾‘æ•ˆæœã€‚æ­¤å¤–ï¼Œæ¨¡å‹è§£è€¦äº†å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚é£æ ¼ï¼Œä½¿å¾—è¯­ä¹‰ç¼–è¾‘æ›´åŠ çµæ´»å’Œå¯æ§ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹ä½¿ç”¨åŒåˆ†æ”¯ç¼–ç å™¨æå–å›¾åƒç‰¹å¾ï¼ŒViTè§£ç å™¨é€šè¿‡äº¤å‰æ³¨æ„åŠ›å°†2Dç‰¹å¾æå‡åˆ°3Dç©ºé—´ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é‡å»ºæŸå¤±ã€æ„ŸçŸ¥æŸå¤±ï¼ˆåŸºäºDINOv2å’ŒSAM2.1ï¼‰ç­‰ã€‚é«˜æ–¯æº…å°„æ¸²æŸ“å™¨ç”¨äºç”Ÿæˆæœ€ç»ˆå›¾åƒã€‚åœ¨è¯­ä¹‰ç¼–è¾‘æ¨¡å¼ä¸‹ï¼Œåˆ†å‰²å›¾å’Œæ–‡æœ¬/å›¾åƒæç¤ºè¢«åˆ†åˆ«ç¼–ç ï¼Œç”¨äºæ§åˆ¶å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚é£æ ¼ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PercHeadåœ¨novel-view synthesisä»»åŠ¡ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPercHeadåœ¨æç«¯è§†è§’ä¸‹å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„3Då¤´éƒ¨æ¨¡å‹ã€‚é€šè¿‡äº¤äº’å¼GUIï¼Œç”¨æˆ·å¯ä»¥è½»æ¾åœ°è¿›è¡Œ3Då¤´éƒ¨è¯­ä¹‰ç¼–è¾‘ï¼Œä¾‹å¦‚æ”¹å˜å‘å‹ã€è¡¨æƒ…ç­‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PercHeadå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬è™šæ‹Ÿç°å®/å¢å¼ºç°å®ã€æ¸¸æˆå¼€å‘ã€æ•°å­—å†…å®¹åˆ›ä½œã€ä¸ªæ€§åŒ–å¤´åƒç”Ÿæˆã€ä»¥åŠäººè„¸è¯†åˆ«å’Œåˆ†æç­‰é¢†åŸŸã€‚è¯¥æŠ€æœ¯å¯ä»¥ç”¨äºåˆ›å»ºé€¼çœŸçš„3Dè™šæ‹Ÿå½¢è±¡ï¼Œä¸ºç”¨æˆ·æä¾›æ›´æ²‰æµ¸å¼çš„ä½“éªŒï¼Œå¹¶ä¿ƒè¿›ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present PercHead, a method for single-image 3D head reconstruction and semantic 3D editing - two tasks that are inherently challenging due to severe view occlusions, weak perceptual supervision, and the ambiguity of editing in 3D space. We develop a unified base model for reconstructing view-consistent 3D heads from a single input image. The model employs a dual-branch encoder followed by a ViT-based decoder that lifts 2D features into 3D space through iterative cross-attention. Rendering is performed using Gaussian Splatting. At the heart of our approach is a novel perceptual supervision strategy based on DINOv2 and SAM2.1, which provides rich, generalized signals for both geometric and appearance fidelity. Our model achieves state-of-the-art performance in novel-view synthesis and, furthermore, exhibits exceptional robustness to extreme viewing angles compared to established baselines. Furthermore, this base model can be seamlessly extended for semantic 3D editing by swapping the encoder and finetuning the network. In this variant, we disentangle geometry and style through two distinct input modalities: a segmentation map to control geometry and either a text prompt or a reference image to specify appearance. We highlight the intuitive and powerful 3D editing capabilities of our model through a lightweight, interactive GUI, where users can effortlessly sculpt geometry by drawing segmentation maps and stylize appearance via natural language or image prompts.
>   Project Page: https://antoniooroz.github.io/PercHead Video: https://www.youtube.com/watch?v=4hFybgTk4kE

