---
layout: default
title: PercHead: Perceptual Head Model for Single-Image 3D Head Reconstruction & Editing
---

# PercHead: Perceptual Head Model for Single-Image 3D Head Reconstruction & Editing

**arXiv**: [2511.02777v1](https://arxiv.org/abs/2511.02777) | [PDF](https://arxiv.org/pdf/2511.02777.pdf)

**ä½œè€…**: Antonio Oroz, Matthias NieÃŸner, Tobias Kirschstein

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPercHeadæ–¹æ³•ï¼Œç”¨äºŽå•å›¾åƒ3Då¤´éƒ¨é‡å»ºä¸Žè¯­ä¹‰ç¼–è¾‘ï¼Œè§£å†³é®æŒ¡å’Œç¼–è¾‘æ¨¡ç³Šé—®é¢˜ã€‚**

**å…³é”®è¯**: `3Då¤´éƒ¨é‡å»º` `è¯­ä¹‰ç¼–è¾‘` `æ„ŸçŸ¥ç›‘ç£` `é«˜æ–¯æº…å°„` `å•å›¾åƒå¤„ç†` `ViTè§£ç å™¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå•å›¾åƒ3Då¤´éƒ¨é‡å»ºé¢ä¸´ä¸¥é‡é®æŒ¡ã€å¼±æ„ŸçŸ¥ç›‘ç£å’Œ3Dç¼–è¾‘æ¨¡ç³Šæ€§æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åŒåˆ†æ”¯ç¼–ç å™¨å’ŒViTè§£ç å™¨ï¼Œç»“åˆDINOv2ä¸ŽSAM2.1è¿›è¡Œæ„ŸçŸ¥ç›‘ç£ï¼Œä½¿ç”¨é«˜æ–¯æº…å°„æ¸²æŸ“ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨è§†è§’åˆæˆä¸­è¾¾åˆ°SOTAï¼Œå¯¹æžç«¯è§†è§’é²æ£’ï¼Œæ”¯æŒé€šè¿‡åˆ†å‰²å›¾å’Œæ–‡æœ¬/å›¾åƒè¿›è¡Œè¯­ä¹‰ç¼–è¾‘ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We present PercHead, a method for single-image 3D head reconstruction and
> semantic 3D editing - two tasks that are inherently challenging due to severe
> view occlusions, weak perceptual supervision, and the ambiguity of editing in
> 3D space. We develop a unified base model for reconstructing view-consistent 3D
> heads from a single input image. The model employs a dual-branch encoder
> followed by a ViT-based decoder that lifts 2D features into 3D space through
> iterative cross-attention. Rendering is performed using Gaussian Splatting. At
> the heart of our approach is a novel perceptual supervision strategy based on
> DINOv2 and SAM2.1, which provides rich, generalized signals for both geometric
> and appearance fidelity. Our model achieves state-of-the-art performance in
> novel-view synthesis and, furthermore, exhibits exceptional robustness to
> extreme viewing angles compared to established baselines. Furthermore, this
> base model can be seamlessly extended for semantic 3D editing by swapping the
> encoder and finetuning the network. In this variant, we disentangle geometry
> and style through two distinct input modalities: a segmentation map to control
> geometry and either a text prompt or a reference image to specify appearance.
> We highlight the intuitive and powerful 3D editing capabilities of our model
> through a lightweight, interactive GUI, where users can effortlessly sculpt
> geometry by drawing segmentation maps and stylize appearance via natural
> language or image prompts.
>   Project Page: https://antoniooroz.github.io/PercHead Video:
> https://www.youtube.com/watch?v=4hFybgTk4kE

