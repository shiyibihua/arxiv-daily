---
layout: default
title: FBA$^2$D: Frequency-based Black-box Attack for AI-generated Image Detection
---

# FBA$^2$D: Frequency-based Black-box Attack for AI-generated Image Detection

**arXiv**: [2512.09264v1](https://arxiv.org/abs/2512.09264) | [PDF](https://arxiv.org/pdf/2512.09264.pdf)

**ä½œè€…**: Xiaojing Chen, Dan Li, Lijun Peng, Jun YanÅetter, Zhiqing Guo, Junyang Chen, Xiao Lan, Zhongjie Ba, Yunfeng DiaoÅetter

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽé¢‘çŽ‡çš„é»‘ç›’æ”»å‡»æ–¹æ³•FBAÂ²Dï¼Œä»¥è§£å†³AIç”Ÿæˆå›¾åƒæ£€æµ‹å™¨çš„å†³ç­–åž‹æ”»å‡»é—®é¢˜ã€‚**

**å…³é”®è¯**: `AIç”Ÿæˆå›¾åƒæ£€æµ‹` `é»‘ç›’æ”»å‡»` `é¢‘çŽ‡åŸŸæ”»å‡»` `å†³ç­–åž‹æ”»å‡»` `å¯¹æŠ—æ ·æœ¬`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šAIç”Ÿæˆå†…å®¹æ£€æµ‹å™¨åœ¨çœŸå®žé»‘ç›’åœºæ™¯ä¸‹æ˜“å—å†³ç­–åž‹æ”»å‡»ï¼ŒçŽ°æœ‰ç ”ç©¶å¤šå‡è®¾æ¨¡åž‹ä¿¡æ¯å·²çŸ¥ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨ç¦»æ•£ä½™å¼¦å˜æ¢è¿›è¡Œé¢‘åŸŸåˆ’åˆ†ï¼Œé€‰æ‹©é¢‘å¸¦ä½œä¸ºæŸ¥è¯¢å­ç©ºé—´ï¼Œç»“åˆå¯¹æŠ—æ ·æœ¬æ±¤æ–¹æ³•åŠ é€Ÿæ”»å‡»ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨Synthetic LSUNå’ŒGenImageæ•°æ®é›†ä¸ŠéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæå‡äº†æŸ¥è¯¢æ•ˆçŽ‡å’Œå›¾åƒè´¨é‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The prosperous development of Artificial Intelligence-Generated Content (AIGC) has brought people's anxiety about the spread of false information on social media. Designing detectors for filtering is an effective defense method, but most detectors will be compromised by adversarial samples. Currently, most studies exposing AIGC security issues assume information on model structure and data distribution. In real applications, attackers query and interfere with models that provide services in the form of application programming interfaces (APIs), which constitutes the black-box decision-based attack paradigm. However, to the best of our knowledge, decision-based attacks on AIGC detectors remain unexplored. In this study, we propose \textbf{FBA$^2$D}: a frequency-based black-box attack method for AIGC detection to fill the research gap. Motivated by frequency-domain discrepancies between generated and real images, we develop a decision-based attack that leverages the Discrete Cosine Transform (DCT) for fine-grained spectral partitioning and selects frequency bands as query subspaces, improving both query efficiency and image quality. Moreover, attacks on AIGC detectors should mitigate initialization failures, preserve image quality, and operate under strict query budgets. To address these issues, we adopt an ``adversarial example soup'' method, averaging candidates from successive surrogate iterations and using the result as the initialization to accelerate the query-based attack. The empirical study on the Synthetic LSUN dataset and GenImage dataset demonstrate the effectiveness of our prosed method. This study shows the urgency of addressing practical AIGC security problems.

