---
layout: default
title: FoundIR-v2: Optimizing Pre-Training Data Mixtures for Image Restoration Foundation Model
---

# FoundIR-v2: Optimizing Pre-Training Data Mixtures for Image Restoration Foundation Model

**arXiv**: [2512.09282v1](https://arxiv.org/abs/2512.09282) | [PDF](https://arxiv.org/pdf/2512.09282.pdf)

**ä½œè€…**: Xiang Chen, Jinshan Pan, Jiangxin Dong, Jian Yang, Jinhui Tang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFoundIR-v2ï¼Œé€šè¿‡æ•°æ®å‡è¡¡è°ƒåº¦ä¼˜åŒ–é¢„è®­ç»ƒæ•°æ®æ··åˆæ¯”ä¾‹ä»¥æå‡å›¾åƒä¿®å¤åŸºç¡€æ¨¡åž‹æ€§èƒ½**

**å…³é”®è¯**: `å›¾åƒä¿®å¤åŸºç¡€æ¨¡åž‹` `æ•°æ®æ··åˆä¼˜åŒ–` `æ‰©æ•£æ¨¡åž‹` `æ··åˆä¸“å®¶è°ƒåº¦` `ä»»åŠ¡è‡ªé€‚åº”å…ˆéªŒ` `å¤šä»»åŠ¡æ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå›¾åƒä¿®å¤åŸºç¡€æ¨¡åž‹ä¸­ï¼Œä¸åŒä»»åŠ¡æ•°æ®æ··åˆæ¯”ä¾‹ç›´æŽ¥å½±å“æ•´ä½“æ€§èƒ½ï¼Œéœ€ä¼˜åŒ–ä»¥å¹³è¡¡æ³›åŒ–èƒ½åŠ›
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æ•°æ®å‡è¡¡è°ƒåº¦èŒƒå¼åŠ¨æ€ä¼˜åŒ–æ··åˆæ¯”ä¾‹ï¼Œå¹¶å¼•å…¥MoEé©±åŠ¨çš„è°ƒåº¦å™¨åˆ†é…ä»»åŠ¡è‡ªé€‚åº”æ‰©æ•£å…ˆéªŒ
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨è¶…è¿‡50ä¸ªå­ä»»åŠ¡ä¸­éªŒè¯ï¼Œåœ¨å¹¿æ³›çœŸå®žåœºæ™¯ä¸‹å®žçŽ°ä¸€è‡´æ³›åŒ–ï¼Œæ€§èƒ½ä¼˜äºŽå…ˆè¿›æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent studies have witnessed significant advances in image restoration foundation models driven by improvements in the scale and quality of pre-training data. In this work, we find that the data mixture proportions from different restoration tasks are also a critical factor directly determining the overall performance of all-in-one image restoration models. To this end, we propose a high-capacity diffusion-based image restoration foundation model, FoundIR-v2, which adopts a data equilibrium scheduling paradigm to dynamically optimize the proportions of mixed training datasets from different tasks. By leveraging the data mixing law, our method ensures a balanced dataset composition, enabling the model to achieve consistent generalization and comprehensive performance across diverse tasks. Furthermore, we introduce an effective Mixture-of-Experts (MoE)-driven scheduler into generative pre-training to flexibly allocate task-adaptive diffusion priors for each restoration task, accounting for the distinct degradation forms and levels exhibited by different tasks. Extensive experiments demonstrate that our method can address over 50 sub-tasks across a broader scope of real-world scenarios and achieves favorable performance against state-of-the-art approaches.

