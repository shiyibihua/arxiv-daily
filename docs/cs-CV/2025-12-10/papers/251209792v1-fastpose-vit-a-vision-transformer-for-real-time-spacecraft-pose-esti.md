---
layout: default
title: FastPose-ViT: A Vision Transformer for Real-Time Spacecraft Pose Estimation
---

# FastPose-ViT: A Vision Transformer for Real-Time Spacecraft Pose Estimation

**arXiv**: [2512.09792v1](https://arxiv.org/abs/2512.09792) | [PDF](https://arxiv.org/pdf/2512.09792.pdf)

**ä½œè€…**: Pierre Ancey, Andrew Price, Saqib Javed, Mathieu Salzmann

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFastPose-ViTä»¥è§£å†³èˆªå¤©å™¨å®žæ—¶å§¿æ€ä¼°è®¡é—®é¢˜ï¼ŒåŸºäºŽVision Transformerç›´æŽ¥å›žå½’6DoFå§¿æ€ã€‚**

**å…³é”®è¯**: `èˆªå¤©å™¨å§¿æ€ä¼°è®¡` `Vision Transformer` `å®žæ—¶è®¡ç®—` `è¾¹ç¼˜éƒ¨ç½²` `6DoFå›žå½’` `æŠ•å½±å‡ ä½•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šèˆªå¤©å™¨6DoFå§¿æ€ä¼°è®¡å¯¹è‡ªä¸»æ“ä½œè‡³å…³é‡è¦ï¼ŒçŽ°æœ‰PnPæ–¹æ³•è®¡ç®—é‡å¤§ï¼Œä¸é€‚åˆèµ„æºå—é™è¾¹ç¼˜è®¾å¤‡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨Vision Transformeræž¶æž„ï¼Œé€šè¿‡è£å‰ªå›¾åƒå’Œæ–°é¢–æ•°å­¦å½¢å¼ä¸»ä¹‰ï¼ŒåŸºäºŽæŠ•å½±å‡ ä½•å’Œè¡¨è§‚æ—‹è½¬ç›´æŽ¥å›žå½’å§¿æ€ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨SPEEDæ•°æ®é›†ä¸Šæ€§èƒ½ä¼˜äºŽéžPnPæ–¹æ³•ï¼Œä¸ŽPnPæ–¹æ³•ç«žäº‰ï¼Œé‡åŒ–åŽåœ¨NVIDIA Jetson Orin Nanoä¸Šå®žçŽ°çº¦75mså»¶è¿Ÿå’Œ33FPSåžåé‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Estimating the 6-degrees-of-freedom (6DoF) pose of a spacecraft from a single image is critical for autonomous operations like in-orbit servicing and space debris removal. Existing state-of-the-art methods often rely on iterative Perspective-n-Point (PnP)-based algorithms, which are computationally intensive and ill-suited for real-time deployment on resource-constrained edge devices. To overcome these limitations, we propose FastPose-ViT, a Vision Transformer (ViT)-based architecture that directly regresses the 6DoF pose. Our approach processes cropped images from object bounding boxes and introduces a novel mathematical formalism to map these localized predictions back to the full-image scale. This formalism is derived from the principles of projective geometry and the concept of "apparent rotation", where the model predicts an apparent rotation matrix that is then corrected to find the true orientation. We demonstrate that our method outperforms other non-PnP strategies and achieves performance competitive with state-of-the-art PnP-based techniques on the SPEED dataset. Furthermore, we validate our model's suitability for real-world space missions by quantizing it and deploying it on power-constrained edge hardware. On the NVIDIA Jetson Orin Nano, our end-to-end pipeline achieves a latency of ~75 ms per frame under sequential execution, and a non-blocking throughput of up to 33 FPS when stages are scheduled concurrently.

