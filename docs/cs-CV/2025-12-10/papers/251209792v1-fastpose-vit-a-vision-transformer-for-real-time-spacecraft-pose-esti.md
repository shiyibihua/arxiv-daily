---
layout: default
title: FastPose-ViT: A Vision Transformer for Real-Time Spacecraft Pose Estimation
---

# FastPose-ViT: A Vision Transformer for Real-Time Spacecraft Pose Estimation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.09792" target="_blank" class="toolbar-btn">arXiv: 2512.09792v1</a>
    <a href="https://arxiv.org/pdf/2512.09792.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.09792v1" 
            onclick="toggleFavorite(this, '2512.09792v1', 'FastPose-ViT: A Vision Transformer for Real-Time Spacecraft Pose Estimation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Pierre Ancey, Andrew Price, Saqib Javed, Mathieu Salzmann

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-10

**Â§áÊ≥®**: Accepted to WACV 2026. Preprint version

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫FastPose-ViTÔºåÁî®‰∫éËµÑÊ∫êÂèóÈôêÂπ≥Âè∞‰∏äÁöÑËà™Â§©Âô®ÂÆûÊó∂ÂßøÊÄÅ‰º∞ËÆ°**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Ëà™Â§©Âô®ÂßøÊÄÅ‰º∞ËÆ°` `Vision Transformer` `ÂÆûÊó∂ÊÄß` `ËæπÁºòËÆ°ÁÆó` `6DoFÂßøÊÄÅ‰º∞ËÆ°`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËà™Â§©Âô®ÂßøÊÄÅ‰º∞ËÆ°ÊñπÊ≥ï‰æùËµñËø≠‰ª£PnPÁÆóÊ≥ïÔºåËÆ°ÁÆóÈáèÂ§ßÔºåÈöæ‰ª•Âú®ËµÑÊ∫êÂèóÈôêËÆæÂ§á‰∏äÂÆûÊó∂ÈÉ®ÁΩ≤„ÄÇ
2. FastPose-ViTÂü∫‰∫éViTÁõ¥Êé•ÂõûÂΩí6DoFÂßøÊÄÅÔºåÂπ∂ÊèêÂá∫Êñ∞ÁöÑÊï∞Â≠¶ÂΩ¢ÂºèÔºåÂ∞ÜÂ±ÄÈÉ®È¢ÑÊµãÊò†Â∞ÑÂà∞ÂÖ®Â±Ä„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåFastPose-ViTÊÄßËÉΩ‰ºò‰∫éÈùûPnPÊñπÊ≥ïÔºå‰∏éPnPÊñπÊ≥ïÁõ∏ÂΩìÔºåÂπ∂Âú®ËæπÁºòËÆæÂ§á‰∏äÂÆûÁé∞ÂÆûÊó∂ÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éVision Transformer (ViT)ÁöÑFastPose-ViTÊû∂ÊûÑÔºåÁî®‰∫éÁõ¥Êé•ÂõûÂΩíËà™Â§©Âô®ÁöÑ6Ëá™Áî±Â∫¶(6DoF)ÂßøÊÄÅÔºåÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÂü∫‰∫éËø≠‰ª£Perspective-n-Point (PnP)ÁÆóÊ≥ïËÆ°ÁÆóÂØÜÈõÜ„ÄÅ‰∏çÈÄÇÁî®‰∫éËµÑÊ∫êÂèóÈôêËæπÁºòËÆæÂ§áÂÆûÊó∂ÈÉ®ÁΩ≤ÁöÑÈóÆÈ¢ò„ÄÇËØ•ÊñπÊ≥ïÂ§ÑÁêÜÊù•Ëá™ÁõÆÊ†áËæπÁïåÊ°ÜÁöÑË£ÅÂâ™ÂõæÂÉèÔºåÂπ∂ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊï∞Â≠¶ÂΩ¢ÂºèÔºåÂ∞ÜËøô‰∫õÂ±ÄÈÉ®È¢ÑÊµãÊò†Â∞ÑÂõûÂÆåÊï¥ÂõæÂÉèÂ∞∫Â∫¶„ÄÇËØ•ÂΩ¢ÂºèÊ∫ê‰∫éÂ∞ÑÂΩ±Âá†‰ΩïÂéüÁêÜÂíå‚ÄúËßÜÂú®ÊóãËΩ¨‚ÄùÁöÑÊ¶ÇÂøµÔºåÊ®°ÂûãÈ¢ÑÊµã‰∏Ä‰∏™ËßÜÂú®ÊóãËΩ¨Áü©ÈòµÔºåÁÑ∂ÂêéÂØπÂÖ∂ËøõË°åÊ†°Ê≠£‰ª•ÊâæÂà∞ÁúüÂÆûÁöÑÂßøÊÄÅ„ÄÇÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ï‰ºò‰∫éÂÖ∂‰ªñÈùûPnPÁ≠ñÁï•ÔºåÂπ∂Âú®SPEEDÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫Ü‰∏éÊúÄÂÖàËøõÁöÑPnPÊñπÊ≥ïÁõ∏Â™≤ÁæéÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÈÄöËøáÈáèÂåñÊ®°ÂûãÂπ∂Â∞ÜÂÖ∂ÈÉ®ÁΩ≤Âú®ÂäüËÄóÂèóÈôêÁöÑËæπÁºòÁ°¨‰ª∂‰∏äÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÁ©∫Èó¥‰ªªÂä°‰∏≠ÁöÑÈÄÇÁî®ÊÄß„ÄÇÂú®NVIDIA Jetson Orin Nano‰∏äÔºåÁ´ØÂà∞Á´ØÊµÅÊ∞¥Á∫øÂú®È°∫Â∫èÊâßË°å‰∏ãÂÆûÁé∞‰∫ÜÁ∫¶75ÊØ´Áßí/Â∏ßÁöÑÂª∂ËøüÔºåÂú®Âπ∂ÂèëË∞ÉÂ∫¶Èò∂ÊÆµÂÆûÁé∞‰∫ÜÈ´òËææ33 FPSÁöÑÈùûÈòªÂ°ûÂêûÂêêÈáè„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Ëà™Â§©Âô®6DoFÂßøÊÄÅ‰º∞ËÆ°ÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÊòØÂú®ËµÑÊ∫êÂèóÈôêÁöÑËæπÁºòËÆæÂ§á‰∏äËøõË°åÂÆûÊó∂ÂßøÊÄÅ‰º∞ËÆ°„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÁâπÂà´ÊòØÂü∫‰∫éËø≠‰ª£PnPÁÆóÊ≥ïÁöÑÊñπÊ≥ïÔºåËÆ°ÁÆóÂ§çÊùÇÂ∫¶È´òÔºåÈöæ‰ª•Êª°Ë∂≥ÂÆûÊó∂ÊÄßË¶ÅÊ±ÇÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÁ©∫Èó¥‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Vision Transformer (ViT)Áõ¥Êé•ÂõûÂΩí6DoFÂßøÊÄÅÔºåÈÅøÂÖçËø≠‰ª£ËÆ°ÁÆó„ÄÇÈÄöËøáÂ≠¶‰π†ÂõæÂÉèÁâπÂæÅ‰∏éÂßøÊÄÅ‰πãÈó¥ÁöÑÁõ¥Êé•Êò†Â∞ÑÂÖ≥Á≥ªÔºåÈôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÔºåÊèêÈ´òÊé®ÁêÜÈÄüÂ∫¶„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÂºïÂÖ•‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊï∞Â≠¶ÂΩ¢ÂºèÔºåÂ∞ÜË£ÅÂâ™ÂõæÂÉèÁöÑÂ±ÄÈÉ®ÂßøÊÄÅÈ¢ÑÊµãÊò†Â∞ÑÂõûÂÆåÊï¥ÂõæÂÉèÁöÑÂÖ®Â±ÄÂßøÊÄÅ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöFastPose-ViTÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) ËæìÂÖ•Ë£ÅÂâ™ÂêéÁöÑËà™Â§©Âô®ÂõæÂÉèÔºõ2) ‰ΩøÁî®ViTÊèêÂèñÂõæÂÉèÁâπÂæÅÔºõ3) ÈÄöËøáÂõûÂΩíÂ§¥È¢ÑÊµãËßÜÂú®ÊóãËΩ¨Áü©ÈòµÔºõ4) Âà©Áî®ÊèêÂá∫ÁöÑÊï∞Â≠¶ÂΩ¢ÂºèÔºåÂ∞ÜËßÜÂú®ÊóãËΩ¨Áü©ÈòµÊ†°Ê≠£‰∏∫ÁúüÂÆûÁöÑÊóãËΩ¨Áü©ÈòµÔºåÂπ∂È¢ÑÊµãÂπ≥ÁßªÂêëÈáè„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØÁ´ØÂà∞Á´ØÂèØËÆ≠ÁªÉÁöÑ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊï∞Â≠¶ÂΩ¢ÂºèÔºåÁî®‰∫éÂ∞ÜË£ÅÂâ™ÂõæÂÉèÁöÑÂ±ÄÈÉ®ÂßøÊÄÅÈ¢ÑÊµãÊò†Â∞ÑÂõûÂÆåÊï¥ÂõæÂÉèÁöÑÂÖ®Â±ÄÂßøÊÄÅ„ÄÇËøôÁßçÊñπÊ≥ïÂü∫‰∫éÂ∞ÑÂΩ±Âá†‰ΩïÂíå‚ÄúËßÜÂú®ÊóãËΩ¨‚ÄùÁöÑÊ¶ÇÂøµÔºåÈÄöËøáÈ¢ÑÊµã‰∏Ä‰∏™ËßÜÂú®ÊóãËΩ¨Áü©ÈòµÔºåÁÑ∂ÂêéÂØπÂÖ∂ËøõË°åÊ†°Ê≠£Ôºå‰ªéËÄåÂæóÂà∞ÁúüÂÆûÁöÑÊóãËΩ¨Áü©Èòµ„ÄÇËøôÁßçÊñπÊ≥ïÈÅøÂÖç‰∫ÜÁõ¥Êé•ÂõûÂΩíÂÖ®Â±ÄÂßøÊÄÅÁöÑÂõ∞ÈöæÔºåÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÁ≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöFastPose-ViT‰ΩøÁî®Ê†áÂáÜÁöÑViTÊû∂ÊûÑ‰Ωú‰∏∫ÁâπÂæÅÊèêÂèñÂô®„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÊóãËΩ¨ÊçüÂ§±ÂíåÂπ≥ÁßªÊçüÂ§±„ÄÇÊóãËΩ¨ÊçüÂ§±ÂèØ‰ª•‰ΩøÁî®ÂõõÂÖÉÊï∞ÊçüÂ§±ÊàñÊóãËΩ¨Áü©ÈòµÊçüÂ§±„ÄÇÂπ≥ÁßªÊçüÂ§±ÂèØ‰ª•‰ΩøÁî®L1ÊàñL2ÊçüÂ§±„ÄÇÂÖ≥ÈîÆÂèÇÊï∞ÂåÖÊã¨ViTÁöÑÂ±ÇÊï∞„ÄÅÂ§¥Êï∞„ÄÅÂµåÂÖ•Áª¥Â∫¶Á≠â„ÄÇÊ≠§Â§ñÔºåËßÜÂú®ÊóãËΩ¨Áü©ÈòµÁöÑÊ†°Ê≠£ËøáÁ®ã‰πüÈúÄË¶Å‰ªîÁªÜËÆæËÆ°Ôºå‰ª•‰øùËØÅÊ†°Ê≠£ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

FastPose-ViTÂú®SPEEDÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Ü‰∏éÊúÄÂÖàËøõÁöÑPnPÊñπÊ≥ïÁõ∏Â™≤ÁæéÁöÑÊÄßËÉΩÔºåÂêåÊó∂ÊòæËëóÈôç‰Ωé‰∫ÜËÆ°ÁÆóÂ§çÊùÇÂ∫¶„ÄÇÂú®NVIDIA Jetson Orin Nano‰∏äÔºåËØ•ÊñπÊ≥ïÂÆûÁé∞‰∫ÜÁ∫¶75ÊØ´Áßí/Â∏ßÁöÑÂª∂ËøüÔºå‰ª•ÂèäÈ´òËææ33 FPSÁöÑÈùûÈòªÂ°ûÂêûÂêêÈáèÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®ËµÑÊ∫êÂèóÈôêËæπÁºòËÆæÂ§á‰∏äÁöÑÂÆûÊó∂ÊÄßËÉΩ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåFastPose-ViTÊòØ‰∏ÄÁßçÈ´òÊïà„ÄÅÂáÜÁ°ÆÁöÑËà™Â§©Âô®ÂßøÊÄÅ‰º∞ËÆ°ÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂú®ËΩ®ÊúçÂä°„ÄÅÁ©∫Èó¥Á¢éÁâáÁßªÈô§„ÄÅËá™‰∏ªÂØºËà™Á≠âËà™Â§©‰ªªÂä°‰∏≠„ÄÇÈÄöËøáÂú®ËµÑÊ∫êÂèóÈôêÁöÑËæπÁºòËÆæÂ§á‰∏äÂÆûÁé∞ÂÆûÊó∂ÂßøÊÄÅ‰º∞ËÆ°ÔºåÂèØ‰ª•ÊèêÈ´òËà™Â§©Âô®ÁöÑËá™‰∏ªÊÄßÂíåÊô∫ËÉΩÂåñÊ∞¥Âπ≥ÔºåÈôç‰ΩéÂØπÂú∞Èù¢Á´ôÁöÑ‰æùËµñÔºå‰ªéËÄåÈôç‰Ωé‰ªªÂä°ÊàêÊú¨ÔºåÊèêÈ´ò‰ªªÂä°ÊïàÁéá„ÄÇËØ•ÊñπÊ≥ïËøòÂèØÊé®ÂπøÂà∞ÂÖ∂‰ªñÈúÄË¶ÅÂÆûÊó∂ÂßøÊÄÅ‰º∞ËÆ°ÁöÑÂú∫ÊôØÔºåÂ¶ÇÊú∫Âô®‰∫∫ÂØºËà™„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Estimating the 6-degrees-of-freedom (6DoF) pose of a spacecraft from a single image is critical for autonomous operations like in-orbit servicing and space debris removal. Existing state-of-the-art methods often rely on iterative Perspective-n-Point (PnP)-based algorithms, which are computationally intensive and ill-suited for real-time deployment on resource-constrained edge devices. To overcome these limitations, we propose FastPose-ViT, a Vision Transformer (ViT)-based architecture that directly regresses the 6DoF pose. Our approach processes cropped images from object bounding boxes and introduces a novel mathematical formalism to map these localized predictions back to the full-image scale. This formalism is derived from the principles of projective geometry and the concept of "apparent rotation", where the model predicts an apparent rotation matrix that is then corrected to find the true orientation. We demonstrate that our method outperforms other non-PnP strategies and achieves performance competitive with state-of-the-art PnP-based techniques on the SPEED dataset. Furthermore, we validate our model's suitability for real-world space missions by quantizing it and deploying it on power-constrained edge hardware. On the NVIDIA Jetson Orin Nano, our end-to-end pipeline achieves a latency of ~75 ms per frame under sequential execution, and a non-blocking throughput of up to 33 FPS when stages are scheduled concurrently.

