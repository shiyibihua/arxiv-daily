---
layout: default
title: Knowledge Diversion for Efficient Morphology Control and Policy Transfer
---

# Knowledge Diversion for Efficient Morphology Control and Policy Transfer

**arXiv**: [2512.09796v1](https://arxiv.org/abs/2512.09796) | [PDF](https://arxiv.org/pdf/2512.09796.pdf)

**ä½œè€…**: Fu Feng, Ruixiao Shi, Yucheng Xie, Jianlu Shen, Jing Wang, Xin Geng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDivMorphï¼Œé€šè¿‡çŸ¥è¯†åˆ†æµå®žçŽ°é«˜æ•ˆå½¢æ€æŽ§åˆ¶å’Œç­–ç•¥è¿ç§»**

**å…³é”®è¯**: `é€šç”¨å½¢æ€æŽ§åˆ¶` `çŸ¥è¯†åˆ†æµ` `TransformeræŽ§åˆ¶å™¨` `ç­–ç•¥è¿ç§»` `æ¨¡å—åŒ–è®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé€šç”¨å½¢æ€æŽ§åˆ¶ä¸­TransformeræŽ§åˆ¶å™¨è®¡ç®—æˆæœ¬é«˜ï¼Œè·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›æœ‰é™
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨SVDåˆ†è§£æƒé‡ä¸ºå› å­å•å…ƒï¼Œé€šè¿‡åŠ¨æ€è½¯é—¨æŽ§åˆ†ç¦»å…±äº«å’Œç‰¹å®šçŸ¥è¯†
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨è·¨ä»»åŠ¡è¿ç§»ä¸­æ ·æœ¬æ•ˆçŽ‡æå‡3å€ï¼Œå•æ™ºèƒ½ä½“éƒ¨ç½²æ¨¡åž‹å¤§å°å‡å°‘17å€

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Universal morphology control aims to learn a universal policy that generalizes across heterogeneous agent morphologies, with Transformer-based controllers emerging as a popular choice. However, such architectures incur substantial computational costs, resulting in high deployment overhead, and existing methods exhibit limited cross-task generalization, necessitating training from scratch for each new task. To this end, we propose \textbf{DivMorph}, a modular training paradigm that leverages knowledge diversion to learn decomposable controllers. DivMorph factorizes randomly initialized Transformer weights into factor units via SVD prior to training and employs dynamic soft gating to modulate these units based on task and morphology embeddings, separating them into shared \textit{learngenes} and morphology- and task-specific \textit{tailors}, thereby achieving knowledge disentanglement. By selectively activating relevant components, DivMorph enables scalable and efficient policy deployment while supporting effective policy transfer to novel tasks. Extensive experiments demonstrate that DivMorph achieves state-of-the-art performance, achieving a 3$\times$ improvement in sample efficiency over direct finetuning for cross-task transfer and a 17$\times$ reduction in model size for single-agent deployment.

