---
layout: default
title: Visual Categorization Across Minds and Models: Cognitive Analysis of Human Labeling and Neuro-Symbolic Integration
---

# Visual Categorization Across Minds and Models: Cognitive Analysis of Human Labeling and Neuro-Symbolic Integration

**arXiv**: [2512.09340v1](https://arxiv.org/abs/2512.09340) | [PDF](https://arxiv.org/pdf/2512.09340.pdf)

**ä½œè€…**: Chethana Prasad Kabgere

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å¯¹æ¯”äººç±»ä¸ŽAIåœ¨æ¨¡ç³Šè§†è§‰åˆºæ¿€ä¸‹çš„æ ‡æ³¨è¡¨çŽ°ï¼Œæå‡ºç¥žç»ç¬¦å·æ•´åˆæž¶æž„ä»¥æå‡AIå¯è§£é‡Šæ€§ä¸Žè®¤çŸ¥å¯¹é½**

**å…³é”®è¯**: `è§†è§‰åˆ†ç±»` `è®¤çŸ¥åˆ†æž` `ç¥žç»ç¬¦å·æ•´åˆ` `äººç±»æ ‡æ³¨` `æ¨¡åž‹æ³¨æ„åŠ›` `å¯è§£é‡ŠAI`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šäººç±»ä¸ŽAIç³»ç»Ÿå¦‚ä½•è§£é‡Šä½Žåˆ†è¾¨çŽ‡ã€æ„ŸçŸ¥é€€åŒ–çš„è§†è§‰åˆºæ¿€ï¼Œæ­ç¤ºæ„ŸçŸ¥ä¸Žå†³ç­–çš„å¼‚åŒ
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆè®¡ç®—è®¤çŸ¥ç§‘å­¦ã€è®¤çŸ¥æž¶æž„å’Œè¿žæŽ¥ä¸»ä¹‰-ç¬¦å·æ··åˆæ¨¡åž‹ï¼Œåˆ†æžäººç±»ç±»æ¯”æŽ¨ç†ä¸ŽAIç‰¹å¾å¤„ç†
3. å®žéªŒæˆ–æ•ˆæžœï¼šé€šè¿‡Grad-CAMå¯è§†åŒ–æ¨¡åž‹æ³¨æ„åŠ›ï¼Œå¯¹æ¯”äººç±»å“åº”ï¼Œå‘çŽ°è¡¨ç¤ºã€æŽ¨ç†å’Œç½®ä¿¡åº¦æ ¡å‡†çš„å¹³è¡Œä¸Žåˆ†æ­§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Understanding how humans and AI systems interpret ambiguous visual stimuli offers critical insight into the nature of perception, reasoning, and decision-making. This paper examines image labeling performance across human participants and deep neural networks, focusing on low-resolution, perceptually degraded stimuli. Drawing from computational cognitive science, cognitive architectures, and connectionist-symbolic hybrid models, we contrast human strategies such as analogical reasoning, shape-based recognition, and confidence modulation with AI's feature-based processing. Grounded in Marr's tri-level hypothesis, Simon's bounded rationality, and Thagard's frameworks of representation and emotion, we analyze participant responses in relation to Grad-CAM visualizations of model attention. Human behavior is further interpreted through cognitive principles modeled in ACT-R and Soar, revealing layered and heuristic decision strategies under uncertainty. Our findings highlight key parallels and divergences between biological and artificial systems in representation, inference, and confidence calibration. The analysis motivates future neuro-symbolic architectures that unify structured symbolic reasoning with connectionist representations. Such architectures, informed by principles of embodiment, explainability, and cognitive alignment, offer a path toward AI systems that are not only performant but also interpretable and cognitively grounded.

