---
layout: default
title: Federated Distillation Assisted Vehicle Edge Caching Scheme Based on Lightweight DDPM
---

# Federated Distillation Assisted Vehicle Edge Caching Scheme Based on Lightweight DDPM

**arXiv**: [2512.09378v1](https://arxiv.org/abs/2512.09378) | [PDF](https://arxiv.org/pdf/2512.09378.pdf)

**ä½œè€…**: Xun Li, Qiong Wu, Pingyi Fan, Kezhi Wang, Wen Chen, Khaled B. Letaief

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè½»é‡DDPMçš„è”é‚¦è’¸é¦è¾…åŠ©è½¦è¾†è¾¹ç¼˜ç¼“å­˜æ–¹æ¡ˆï¼Œä»¥é™ä½Žé€šä¿¡å¼€é”€å¹¶æå‡ç¼“å­˜å‘½ä¸­çŽ‡ã€‚**

**å…³é”®è¯**: `è½¦è¾†è¾¹ç¼˜ç¼“å­˜` `è”é‚¦è’¸é¦` `è½»é‡åŽ»å™ªæ‰©æ•£æ¦‚çŽ‡æ¨¡åž‹` `é€šä¿¡å¼€é”€ä¼˜åŒ–` `éšç§ä¿æŠ¤`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿè”é‚¦å­¦ä¹ åœ¨è½¦è¾†è¾¹ç¼˜ç¼“å­˜ä¸­é€šä¿¡å¼€é”€å¤§ä¸”æ˜“å› è½¦è¾†ç§»åŠ¨å¯¼è‡´è®­ç»ƒå¤±è´¥ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆè”é‚¦è’¸é¦ä¸Žè½»é‡åŽ»å™ªæ‰©æ•£æ¦‚çŽ‡æ¨¡åž‹ï¼Œä¿æŠ¤éšç§å¹¶å‡å°‘æ¨¡åž‹ä¼ è¾“ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šä»¿çœŸæ˜¾ç¤ºæ–¹æ¡ˆå¯¹è½¦é€Ÿå˜åŒ–é²æ£’ï¼Œæ˜¾è‘—é™ä½Žé€šä¿¡å¼€é”€å¹¶æé«˜ç¼“å­˜å‘½ä¸­ç™¾åˆ†æ¯”ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vehicle edge caching is a promising technology that can significantly reduce the latency for vehicle users (VUs) to access content by pre-caching user-interested content at edge nodes. It is crucial to accurately predict the content that VUs are interested in without exposing their privacy. Traditional federated learning (FL) can protect user privacy by sharing models rather than raw data. However, the training of FL requires frequent model transmission, which can result in significant communication overhead. Additionally, vehicles may leave the road side unit (RSU) coverage area before training is completed, leading to training failures. To address these issues, in this letter, we propose a federated distillation-assisted vehicle edge caching scheme based on lightweight denoising diffusion probabilistic model (LDPM). The simulation results demonstrate that the proposed vehicle edge caching scheme has good robustness to variations in vehicle speed, significantly reducing communication overhead and improving cache hit percentage.

