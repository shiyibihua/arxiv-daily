---
layout: default
title: Efficient Continual Learning in Neural Machine Translation: A Low-Rank Adaptation Approach
---

# Efficient Continual Learning in Neural Machine Translation: A Low-Rank Adaptation Approach

**arXiv**: [2512.09910v1](https://arxiv.org/abs/2512.09910) | [PDF](https://arxiv.org/pdf/2512.09910.pdf)

**ä½œè€…**: Salvador CarriÃ³n, Francisco Casacuberta

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽä½Žç§©é€‚é…çš„æŒç»­å­¦ä¹ æ–¹æ³•ï¼Œä»¥è§£å†³ç¥žç»æœºå™¨ç¿»è¯‘ä¸­çš„ç¾éš¾æ€§é—å¿˜å’Œé«˜è®¡ç®—æˆæœ¬é—®é¢˜ã€‚**

**å…³é”®è¯**: `ç¥žç»æœºå™¨ç¿»è¯‘` `æŒç»­å­¦ä¹ ` `ä½Žç§©é€‚é…` `ç¾éš¾æ€§é—å¿˜` `å‚æ•°é«˜æ•ˆå­¦ä¹ ` `äº¤äº’å¼è°ƒæ•´`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç¥žç»æœºå™¨ç¿»è¯‘æŒç»­å­¦ä¹ é¢ä¸´ç¾éš¾æ€§é—å¿˜å’Œé‡è®­ç»ƒè®¡ç®—æˆæœ¬é«˜çš„åŒé‡æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨ä½Žç§©é€‚é…æ¡†æž¶ï¼Œç»“åˆäº¤äº’å¼æ¨¡å—ç»„åˆå’ŒåŸºäºŽæ¢¯åº¦çš„æ­£åˆ™åŒ–ç­–ç•¥ï¼Œå®žçŽ°å‚æ•°é«˜æ•ˆè°ƒæ•´ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå®žéªŒè¡¨æ˜Žæ–¹æ³•åœ¨æ€§èƒ½åª²ç¾Žå…¨å‚æ•°æŠ€æœ¯çš„åŒæ—¶ï¼Œæœ‰æ•ˆä¿ç•™æ—§çŸ¥è¯†å¹¶æ”¯æŒæ–°ä»»åŠ¡å­¦ä¹ ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Continual learning in Neural Machine Translation (NMT) faces the dual challenges of catastrophic forgetting and the high computational cost of retraining. This study establishes Low-Rank Adaptation (LoRA) as a parameter-efficient framework to address these challenges in dedicated NMT architectures. We first demonstrate that LoRA-based fine-tuning adapts NMT models to new languages and domains with performance on par with full-parameter techniques, while utilizing only a fraction of the parameter space. Second, we propose an interactive adaptation method using a calibrated linear combination of LoRA modules. This approach functions as a gate-free mixture of experts, enabling real-time, user-controllable adjustments to domain and style without retraining. Finally, to mitigate catastrophic forgetting, we introduce a novel gradient-based regularization strategy specifically designed for low-rank decomposition matrices. Unlike methods that regularize the full parameter set, our approach weights the penalty on the low-rank updates using historical gradient information. Experimental results indicate that this strategy efficiently preserves prior domain knowledge while facilitating the acquisition of new tasks, offering a scalable paradigm for interactive and continual NMT.

