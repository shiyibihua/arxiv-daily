---
layout: default
title: Video-QTR: Query-Driven Temporal Reasoning Framework for Lightweight Video Understanding
---

# Video-QTR: Query-Driven Temporal Reasoning Framework for Lightweight Video Understanding

**arXiv**: [2512.09354v1](https://arxiv.org/abs/2512.09354) | [PDF](https://arxiv.org/pdf/2512.09354.pdf)

**ä½œè€…**: Xinkui Zhao, Zuxin Wang, Yifan Zhang, Guanjie Cheng, Yueshen Xu, Shuiguang Deng, Chang Liu, Naibo Wang, Jianwei Yin

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVideo-QTRæ¡†æž¶ï¼Œé€šè¿‡æŸ¥è¯¢é©±åŠ¨çš„æ—¶é—´æŽ¨ç†è§£å†³é•¿è§†é¢‘ç†è§£çš„è®¡ç®—æ•ˆçŽ‡é—®é¢˜ã€‚**

**å…³é”®è¯**: `é•¿è§†é¢‘ç†è§£` `æŸ¥è¯¢é©±åŠ¨æŽ¨ç†` `è½»é‡çº§æ¡†æž¶` `æ—¶é—´æŽ¨ç†` `è®¡ç®—æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿæ–¹æ³•åœ¨é•¿è§†é¢‘ç†è§£ä¸­å› å¯†é›†å¸§ç¼–ç å¯¼è‡´é«˜è®¡ç®—å’Œå†…å­˜å¼€é”€ï¼Œé™åˆ¶å®žé™…åº”ç”¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨æŸ¥è¯¢é©±åŠ¨çš„æ—¶é—´æŽ¨ç†ï¼ŒåŠ¨æ€åˆ†é…æ„ŸçŸ¥èµ„æºï¼Œå½¢æˆæŽ¨ç†ä¸Žæ„ŸçŸ¥çš„è‡ªé€‚åº”åé¦ˆå¾ªçŽ¯ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°å…ˆè¿›æ€§èƒ½ï¼ŒåŒæ—¶å‡å°‘è¾“å…¥å¸§æ¶ˆè€—é«˜è¾¾73%ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The rapid development of multimodal large-language models (MLLMs) has significantly expanded the scope of visual language reasoning, enabling unified systems to interpret and describe complex visual content. However, applying these models to long-video understanding remains computationally intensive. Dense frame encoding generates excessive visual tokens, leading to high memory consumption, redundant computation, and limited scalability in real-world applications. This inefficiency highlights a key limitation of the traditional process-then-reason paradigm, which analyzes visual streams exhaustively before semantic reasoning. To address this challenge, we introduce Video-QTR (Query-Driven Temporal Reasoning), a lightweight framework that redefines video comprehension as a query-guided reasoning process. Instead of encoding every frame, Video-QTR dynamically allocates perceptual resources based on the semantic intent of the query, creating an adaptive feedback loop between reasoning and perception. Extensive experiments across five benchmarks: MSVD-QA, Activity Net-QA, Movie Chat, and Video MME demonstrate that Video-QTR achieves state-of-the-art performance while reducing input frame consumption by up to 73%. These results confirm that query-driven temporal reasoning provides an efficient and scalable solution for video understanding.

