---
layout: default
title: One-Shot Real-World Demonstration Synthesis for Scalable Bimanual Manipulation
---

# One-Shot Real-World Demonstration Synthesis for Scalable Bimanual Manipulation

**arXiv**: [2512.09297v1](https://arxiv.org/abs/2512.09297) | [PDF](https://arxiv.org/pdf/2512.09297.pdf)

**ä½œè€…**: Huayi Zhou, Kui Jia

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBiDemoSynæ¡†æž¶ï¼Œä»Žå•æ¬¡çœŸå®žæ¼”ç¤ºåˆæˆå¤§è§„æ¨¡åŒæ‰‹æœºå™¨äººæ“ä½œæ•°æ®ä»¥è§£å†³æ•ˆçŽ‡ä¸ŽçœŸå®žæ€§çš„æƒè¡¡é—®é¢˜ã€‚**

**å…³é”®è¯**: `åŒæ‰‹æœºå™¨äººæ“ä½œ` `æ¼”ç¤ºåˆæˆ` `æ¨¡ä»¿å­¦ä¹ ` `è½¨è¿¹ä¼˜åŒ–` `ç‰©ç†å¯è¡Œæ€§` `æ³›åŒ–èƒ½åŠ›`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŒæ‰‹æœºå™¨äººæ“ä½œå­¦ä¹ ä¾èµ–å¤§è§„æ¨¡é«˜è´¨é‡æ¼”ç¤ºï¼Œä½†çŽ°æœ‰æ–¹æ³•åœ¨æ•ˆçŽ‡ä¸ŽçœŸå®žæ€§é—´å­˜åœ¨æƒè¡¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†ä»»åŠ¡åˆ†è§£ä¸ºä¸å˜åè°ƒå—å’Œå¯å˜è°ƒæ•´ï¼Œé€šè¿‡è§†è§‰å¯¹é½å’Œè½»é‡è½¨è¿¹ä¼˜åŒ–åˆæˆç‰©ç†å¯è¡Œçš„æ¼”ç¤ºã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å…­ä¸ªä»»åŠ¡ä¸­ï¼ŒåŸºäºŽåˆæˆæ•°æ®çš„ç­–ç•¥å¯¹æ–°ç‰©ä½“å§¿æ€å’Œå½¢çŠ¶å…·æœ‰é²æ£’æ³›åŒ–èƒ½åŠ›ï¼Œä¼˜äºŽåŸºçº¿æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Learning dexterous bimanual manipulation policies critically depends on large-scale, high-quality demonstrations, yet current paradigms face inherent trade-offs: teleoperation provides physically grounded data but is prohibitively labor-intensive, while simulation-based synthesis scales efficiently but suffers from sim-to-real gaps. We present BiDemoSyn, a framework that synthesizes contact-rich, physically feasible bimanual demonstrations from a single real-world example. The key idea is to decompose tasks into invariant coordination blocks and variable, object-dependent adjustments, then adapt them through vision-guided alignment and lightweight trajectory optimization. This enables the generation of thousands of diverse and feasible demonstrations within several hour, without repeated teleoperation or reliance on imperfect simulation. Across six dual-arm tasks, we show that policies trained on BiDemoSyn data generalize robustly to novel object poses and shapes, significantly outperforming recent baselines. By bridging the gap between efficiency and real-world fidelity, BiDemoSyn provides a scalable path toward practical imitation learning for complex bimanual manipulation without compromising physical grounding.

