---
layout: default
title: Generalizable Collaborative Search-and-Capture in Cluttered Environments via Path-Guided MAPPO and Directional Frontier Allocation
---

# Generalizable Collaborative Search-and-Capture in Cluttered Environments via Path-Guided MAPPO and Directional Frontier Allocation

**arXiv**: [2512.09410v1](https://arxiv.org/abs/2512.09410) | [PDF](https://arxiv.org/pdf/2512.09410.pdf)

**ä½œè€…**: Jialin Ying, Zhihao Li, Zicheng Dong, Guohua Wu, Yihuan Liao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPGF-MAPPOæ¡†æž¶ï¼Œé€šè¿‡è·¯å¾„å¼•å¯¼å’Œæ–¹å‘æ€§å‰æ²¿åˆ†é…è§£å†³æ‚ä¹±çŽ¯å¢ƒä¸­åä½œæœç´¢ä¸Žæ•èŽ·çš„ç¨€ç–å¥–åŠ±é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ` `åä½œæœç´¢ä¸Žæ•èŽ·` `ç¨€ç–å¥–åŠ±å¡‘å½¢` `é›¶æ ·æœ¬æ³›åŒ–` `æœºå™¨äººé›†ç¾¤æŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ‚ä¹±çŽ¯å¢ƒä¸­åä½œè¿½é€ƒé¢ä¸´ç¨€ç–å¥–åŠ±å’Œå—é™è§†é‡Žï¼Œå¯¼è‡´æ ‡å‡†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æŽ¢ç´¢æ•ˆçŽ‡ä½Žä¸”éš¾ä»¥æ‰©å±•ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆA*åŠ¿åœºè¿›è¡Œå¯†é›†å¥–åŠ±å¡‘å½¢ï¼Œå¹¶å¼•å…¥æ–¹å‘æ€§å‰æ²¿åˆ†é…ä»¥å¼ºåˆ¶ç©ºé—´åˆ†æ•£ï¼ŒåŠ é€Ÿè¦†ç›–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨10x10åœ°å›¾è®­ç»ƒçš„ç­–ç•¥èƒ½é›¶æ ·æœ¬æ³›åŒ–åˆ°20x20çŽ¯å¢ƒï¼Œæ•èŽ·æ•ˆçŽ‡ä¼˜äºŽåŸºçº¿æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Collaborative pursuit-evasion in cluttered environments presents significant challenges due to sparse rewards and constrained Fields of View (FOV). Standard Multi-Agent Reinforcement Learning (MARL) often suffers from inefficient exploration and fails to scale to large scenarios. We propose PGF-MAPPO (Path-Guided Frontier MAPPO), a hierarchical framework bridging topological planning with reactive control. To resolve local minima and sparse rewards, we integrate an A*-based potential field for dense reward shaping. Furthermore, we introduce Directional Frontier Allocation, combining Farthest Point Sampling (FPS) with geometric angle suppression to enforce spatial dispersion and accelerate coverage. The architecture employs a parameter-shared decentralized critic, maintaining O(1) model complexity suitable for robotic swarms. Experiments demonstrate that PGF-MAPPO achieves superior capture efficiency against faster evaders. Policies trained on 10x10 maps exhibit robust zero-shot generalization to unseen 20x20 environments, significantly outperforming rule-based and learning-based baselines.

