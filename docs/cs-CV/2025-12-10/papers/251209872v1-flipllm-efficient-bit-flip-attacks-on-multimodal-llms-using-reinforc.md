---
layout: default
title: FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning
---

# FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning

**arXiv**: [2512.09872v1](https://arxiv.org/abs/2512.09872) | [PDF](https://arxiv.org/pdf/2512.09872.pdf)

**ä½œè€…**: Khurram Khalil, Khaza Anuarul Hoque

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFlipLLMæ¡†æž¶ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ é«˜æ•ˆå‘çŽ°å¤šæ¨¡æ€å¤§æ¨¡åž‹çš„ä½ç¿»è½¬æ”»å‡»æ¼æ´žã€‚**

**å…³é”®è¯**: `ä½ç¿»è½¬æ”»å‡»` `å¼ºåŒ–å­¦ä¹ ` `å¤šæ¨¡æ€å¤§æ¨¡åž‹` `ç¡¬ä»¶å®‰å…¨` `æ¼æ´žå‘çŽ°` `Qå­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ä½ç¿»è½¬æ”»å‡»å‘çŽ°æ–¹æ³•æ³›åŒ–æ€§å·®ã€éš¾ä»¥æ‰©å±•ï¼Œæ— æ³•é«˜æ•ˆåˆ†æžå¤§æ¨¡åž‹å‚æ•°ç©ºé—´ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆæ•æ„Ÿåº¦å¼•å¯¼çš„å±‚å‰ªæžä¸ŽQå­¦ä¹ ï¼Œå°†æ”»å‡»å‘çŽ°å»ºæ¨¡ä¸ºåºåˆ—å†³ç­–é—®é¢˜ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨LLaMA 3.1 8Bå’ŒLLaVAç­‰æ¨¡åž‹ä¸Šï¼Œä»…ç¿»è½¬å°‘é‡ä½å³å¯ä½¿å‡†ç¡®çŽ‡éª¤é™ï¼Œé€Ÿåº¦æ¯”çŽ°æœ‰æ–¹æ³•å¿«2.5å€ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generative Artificial Intelligence models, such as Large Language Models (LLMs) and Large Vision Models (VLMs), exhibit state-of-the-art performance but remain vulnerable to hardware-based threats, specifically bit-flip attacks (BFAs). Existing BFA discovery methods lack generalizability and struggle to scale, often failing to analyze the vast parameter space and complex interdependencies of modern foundation models in a reasonable time. This paper proposes FlipLLM, a reinforcement learning (RL) architecture-agnostic framework that formulates BFA discovery as a sequential decision-making problem. FlipLLM combines sensitivity-guided layer pruning with Q-learning to efficiently identify minimal, high-impact bit sets that can induce catastrophic failure. We demonstrate the effectiveness and generalizability of FlipLLM by applying it to a diverse set of models, including prominent text-only LLMs (GPT-2 Large, LLaMA 3.1 8B, and DeepSeek-V2 7B), VLMs such as LLaVA 1.6, and datasets, such as MMLU, MMLU-Pro, VQAv2, and TextVQA. Our results show that FlipLLM can identify critical bits that are vulnerable to BFAs up to 2.5x faster than SOTA methods. We demonstrate that flipping the FlipLLM-identified bits plummets the accuracy of LLaMA 3.1 8B from 69.9% to ~0.2%, and for LLaVA's VQA score from 78% to almost 0%, by flipping as few as 5 and 7 bits, respectively. Further analysis reveals that applying standard hardware protection mechanisms, such as ECC SECDED, to the FlipLLM-identified bit locations completely mitigates the BFA impact, demonstrating the practical value of our framework in guiding hardware-level defenses. FlipLLM offers the first scalable and adaptive methodology for exploring the BFA vulnerability of both language and multimodal foundation models, paving the way for comprehensive hardware-security evaluation.

