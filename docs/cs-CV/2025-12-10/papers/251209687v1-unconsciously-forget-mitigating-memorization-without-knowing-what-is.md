---
layout: default
title: Unconsciously Forget: Mitigating Memorization; Without Knowing What is being Memorized
---

# Unconsciously Forget: Mitigating Memorization; Without Knowing What is being Memorized

**arXiv**: [2512.09687v1](https://arxiv.org/abs/2512.09687) | [PDF](https://arxiv.org/pdf/2512.09687.pdf)

**ä½œè€…**: Er Jin, Yang Zhang, Yongli Mou, Yanfei Dong, Stefan Decker, Kenji Kawaguchi, Johannes Stegmaier

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUniForgetæ–¹æ³•ï¼Œé€šè¿‡æ¨¡åž‹å‰ªæžç¼“è§£ç”Ÿæˆæ¨¡åž‹è®°å¿†è®­ç»ƒæ•°æ®é—®é¢˜ï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šæ¦‚å¿µã€‚**

**å…³é”®è¯**: `ç”Ÿæˆæ¨¡åž‹` `è®°å¿†ç¼“è§£` `æ¨¡åž‹å‰ªæž` `ç‰ˆæƒä¿æŠ¤` `åŽ»è®°å¿†æŠ€æœ¯` `æ— ç›‘ç£å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç”Ÿæˆæ¨¡åž‹æ˜“è®°å¿†è®­ç»ƒæ•°æ®ï¼Œå¯¼è‡´ç‰ˆæƒä¾µæƒç­‰æ³•å¾‹é£Žé™©ï¼ŒçŽ°æœ‰æ–¹æ³•è®¡ç®—å¼€é”€å¤§æˆ–å¯æ‰©å±•æ€§å·®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè¯†åˆ«æ¨¡åž‹ä¸­å¯¹å—ç‰ˆæƒå†…å®¹ç”Ÿæˆè´Ÿè´£çš„éƒ¨åˆ†ï¼Œåº”ç”¨æ¨¡åž‹å‰ªæžæŠ‘åˆ¶ç”Ÿæˆæ¦‚çŽ‡ï¼Œä¿æŒä¸€èˆ¬ç”Ÿæˆèƒ½åŠ›ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæœ‰æ•ˆé™ä½Žå—ç‰ˆæƒå†…å®¹ç”Ÿæˆæ¦‚çŽ‡ï¼Œä¸ŽçŽ°æœ‰é—å¿˜æ–¹æ³•æ­£äº¤äº’è¡¥ï¼Œæå‡åŽ»è®°å¿†æŠ€æœ¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in generative models have demonstrated an exceptional ability to produce highly realistic images. However, previous studies show that generated images often resemble the training data, and this problem becomes more severe as the model size increases. Memorizing training data can lead to legal challenges, including copyright infringement, violations of portrait rights, and trademark violations. Existing approaches to mitigating memorization mainly focus on manipulating the denoising sampling process to steer image embeddings away from the memorized embedding space or employ unlearning methods that require training on datasets containing specific sets of memorized concepts. However, existing methods often incur substantial computational overhead during sampling, or focus narrowly on removing one or more groups of target concepts, imposing a significant limitation on their scalability. To understand and mitigate these problems, our work, UniForget, offers a new perspective on understanding the root cause of memorization. Our work demonstrates that specific parts of the model are responsible for copyrighted content generation. By applying model pruning, we can effectively suppress the probability of generating copyrighted content without targeting specific concepts while preserving the general generative capabilities of the model. Additionally, we show that our approach is both orthogonal and complementary to existing unlearning methods, thereby highlighting its potential to improve current unlearning and de-memorization techniques.

