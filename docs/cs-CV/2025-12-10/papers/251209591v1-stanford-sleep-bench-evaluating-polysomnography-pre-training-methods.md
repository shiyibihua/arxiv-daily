---
layout: default
title: Stanford Sleep Bench: Evaluating Polysomnography Pre-training Methods for Sleep Foundation Models
---

# Stanford Sleep Bench: Evaluating Polysomnography Pre-training Methods for Sleep Foundation Models

**arXiv**: [2512.09591v1](https://arxiv.org/abs/2512.09591) | [PDF](https://arxiv.org/pdf/2512.09591.pdf)

**ä½œè€…**: Magnus Ruud Kjaer, Rahul Thapa, Gauri Ganjoo, Hyatt Moore, Poul Joergen Jennum, Brandon M. Westover, James Zou, Emmanuel Mignot, Bryan He, Andreas Brink-Kjaer

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºStanford Sleep Benchæ•°æ®é›†ä¸ŽåŸºå‡†ï¼Œä»¥è¯„ä¼°å¤šå¯¼ç¡çœ å›¾è‡ªç›‘ç£é¢„è®­ç»ƒæ–¹æ³•åœ¨ç¡çœ åŸºç¡€æ¨¡åž‹ä¸­çš„åº”ç”¨ã€‚**

**å…³é”®è¯**: `å¤šå¯¼ç¡çœ å›¾` `è‡ªç›‘ç£å­¦ä¹ ` `ç¡çœ åŸºç¡€æ¨¡åž‹` `ä¸´åºŠé¢„æµ‹` `å¯¹æ¯”å­¦ä¹ ` `æ•°æ®é›†åŸºå‡†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç¡çœ åŸºç¡€æ¨¡åž‹å‘å±•å—é™ï¼Œç¼ºä¹å…±äº«æ•°æ®é›†å’Œç³»ç»Ÿè¯„ä¼°è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥å¤§è§„æ¨¡å¤šå¯¼ç¡çœ å›¾æ•°æ®é›†ï¼ŒåŒ…å«17,467æ¡è®°å½•å’Œ13ä¸ªä¸´åºŠä»»åŠ¡ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šå¯¹æ¯”å­¦ä¹ åœ¨ç–¾ç—…å’Œæ­»äº¡çŽ‡é¢„æµ‹ä»»åŠ¡ä¸­è¡¨çŽ°æ˜¾è‘—ä¼˜äºŽå…¶ä»–æ–¹æ³•ï¼Œæ”¶æ•›æ›´å¿«ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Polysomnography (PSG), the gold standard test for sleep analysis, generates vast amounts of multimodal clinical data, presenting an opportunity to leverage self-supervised representation learning (SSRL) for pre-training foundation models to enhance sleep analysis. However, progress in sleep foundation models is hindered by two key limitations: (1) the lack of a shared dataset and benchmark with diverse tasks for training and evaluation, and (2) the absence of a systematic evaluation of SSRL approaches across sleep-related tasks. To address these gaps, we introduce Stanford Sleep Bench, a large-scale PSG dataset comprising 17,467 recordings totaling over 163,000 hours from a major sleep clinic, including 13 clinical disease prediction tasks alongside canonical sleep-related tasks such as sleep staging, apnea diagnosis, and age estimation. We systematically evaluate SSRL pre-training methods on Stanford Sleep Bench, assessing downstream performance across four tasks: sleep staging, apnea diagnosis, age estimation, and disease and mortality prediction. Our results show that multiple pretraining methods achieve comparable performance for sleep staging, apnea diagnosis, and age estimation. However, for mortality and disease prediction, contrastive learning significantly outperforms other approaches while also converging faster during pretraining. To facilitate reproducibility and advance sleep research, we will release Stanford Sleep Bench along with pretrained model weights, training pipelines, and evaluation code.

