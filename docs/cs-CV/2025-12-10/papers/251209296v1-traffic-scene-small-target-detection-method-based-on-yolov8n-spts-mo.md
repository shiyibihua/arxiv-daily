---
layout: default
title: Traffic Scene Small Target Detection Method Based on YOLOv8n-SPTS Model for Autonomous Driving
---

# Traffic Scene Small Target Detection Method Based on YOLOv8n-SPTS Model for Autonomous Driving

**arXiv**: [2512.09296v1](https://arxiv.org/abs/2512.09296) | [PDF](https://arxiv.org/pdf/2512.09296.pdf)

**ä½œè€…**: Songhan Wu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºYOLOv8n-SPTSæ¨¡åž‹ä»¥æå‡è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­å°ç›®æ ‡æ£€æµ‹æ€§èƒ½**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `å°ç›®æ ‡æ£€æµ‹` `YOLOv8æ”¹è¿›` `ç‰¹å¾èžåˆ` `å¤šå°ºåº¦ç‰¹å¾`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè‡ªåŠ¨é©¾é©¶åŠ¨æ€æ„ŸçŸ¥ä¸­å°ç›®æ ‡è¯†åˆ«å›°éš¾ï¼ŒçŽ°æœ‰ç®—æ³•å› ä¿¡æ¯ä¸¢å¤±ã€å°ºåº¦ä¸å¹³è¡¡å’Œé®æŒ¡å¯¼è‡´æ£€æµ‹æ€§èƒ½å·®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡SPD-Convæ¨¡å—ä¼˜åŒ–ç‰¹å¾æå–ï¼Œå¼•å…¥SPPFCSPCæ¨¡å—å¢žå¼ºç‰¹å¾èžåˆï¼Œè®¾è®¡TSFPç»“æž„ä¸“æ³¨å°ç›®æ ‡æ£€æµ‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨VisDrone2019-DETæ•°æ®é›†ä¸Šï¼Œæ¨¡åž‹åœ¨ç²¾åº¦ã€å¬å›žçŽ‡å’ŒmAPæŒ‡æ ‡ä¸ŠæŽ’åç¬¬ä¸€ï¼Œå¯è§†åŒ–æ˜¾ç¤ºé®æŒ¡å¯†é›†åœºæ™¯ä¸­å°ç›®æ ‡æ¼æ£€çŽ‡æ˜¾è‘—é™ä½Žã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper focuses on the key issue in autonomous driving: small target recognition in dynamic perception. Existing algorithms suffer from poor detection performance due to missing small target information, scale imbalance, and occlusion. We propose an improved YOLOv8n-SPTS model, which enhances the detection accuracy of small traffic targets through three key innovations: First, optimizing the feature extraction module. In the Backbone Bottleneck structure of YOLOv8n, 4 traditional convolution modules are replaced with Space-to-Depth Convolution (SPD-Conv) modules. This module retains fine-grained information through space-to-depth conversion, reduces information loss, and enhances the ability to capture features of low-resolution small targets. Second, enhancing feature fusion capability. The Spatial Pyramid Pooling - Fast Cross Stage Partial Connection (SPPFCSPC) module is introduced to replace the original SPPF module, integrating the multi-scale feature extraction from Spatial Pyramid Pooling (SPP) and the feature fusion mechanism of Cross Stage Partial Connection (CSP), thereby improving the model's contextual understanding of complex scenes and multi-scale feature expression ability. Third, designing a dedicated detection structure for small targets. A Triple-Stage Feature Pyramid (TSFP) structure is proposed, which adds a 160*160 small target detection head to the original detection heads to fully utilize high-resolution features in shallow layers; meanwhile, redundant large target detection heads are removed to balance computational efficiency. Comparative experiments on the VisDrone2019-DET dataset show that YOLOv8n-SPTS model ranks first in precision (61.9%), recall (48.3%), mAP@0.5 (52.6%), and mAP@0.5:0.95 (32.6%). Visualization results verify that the miss rate of small targets such as pedestrians and bicycles in occluded and dense scenes is significantly reduced.

