---
layout: default
title: LISN: Language-Instructed Social Navigation with VLM-based Controller Modulating
---

# LISN: Language-Instructed Social Navigation with VLM-based Controller Modulating

**arXiv**: [2512.09920v1](https://arxiv.org/abs/2512.09920) | [PDF](https://arxiv.org/pdf/2512.09920.pdf)

**ä½œè€…**: Junting Chen, Yunchuan Li, Panfeng Jiang, Jiacheng Du, Zixuan Chen, Chenrui Tie, Jiajun Deng, Lin Shao

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLISN-BenchåŸºå‡†ä¸ŽSocial-Nav-Modulatorç³»ç»Ÿï¼Œä»¥è§£å†³è¯­è¨€æŒ‡ä»¤ç¤¾äº¤å¯¼èˆªé—®é¢˜ã€‚**

**å…³é”®è¯**: `ç¤¾äº¤å¯¼èˆª` `è¯­è¨€æŒ‡ä»¤` `è§†è§‰è¯­è¨€æ¨¡åž‹` `åŸºå‡†æµ‹è¯•` `æœºå™¨äººæŽ§åˆ¶` `åŠ¨æ€é¿éšœ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ç¤¾äº¤å¯¼èˆªç ”ç©¶ä¸»è¦å…³æ³¨è·¯å¾„æ•ˆçŽ‡å’Œé¿éšœï¼Œç¼ºä¹å¯¹ç”¨æˆ·è¯­è¨€æŒ‡ä»¤çš„éµå¾ªå’Œåœºæ™¯ç†è§£ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åŸºäºŽVLMçš„å¿«é€Ÿ-æ…¢é€Ÿåˆ†å±‚ç³»ç»Ÿï¼Œé€šè¿‡VLMä»£ç†è°ƒåˆ¶æˆæœ¬å›¾å’ŒæŽ§åˆ¶å™¨å‚æ•°ï¼Œè§£è€¦ä½Žçº§åŠ¨ä½œç”Ÿæˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨LISN-Benchä¸Šå¹³å‡æˆåŠŸçŽ‡91.3%ï¼Œæ¯”æœ€å¼ºåŸºçº¿æå‡è¶…è¿‡63%ï¼Œå°¤å…¶åœ¨äººç¾¤è·Ÿéšå’Œé¿ç¦åŒºåŸŸä»»åŠ¡ä¸­è¡¨çŽ°ä¼˜å¼‚ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Towards human-robot coexistence, socially aware navigation is significant for mobile robots. Yet existing studies on this area focus mainly on path efficiency and pedestrian collision avoidance, which are essential but represent only a fraction of social navigation. Beyond these basics, robots must also comply with user instructions, aligning their actions to task goals and social norms expressed by humans. In this work, we present LISN-Bench, the first simulation-based benchmark for language-instructed social navigation. Built on Rosnav-Arena 3.0, it is the first standardized social navigation benchmark to incorporate instruction following and scene understanding across diverse contexts. To address this task, we further propose Social-Nav-Modulator, a fast-slow hierarchical system where a VLM agent modulates costmaps and controller parameters. Decoupling low-level action generation from the slower VLM loop reduces reliance on high-frequency VLM inference while improving dynamic avoidance and perception adaptability. Our method achieves an average success rate of 91.3%, which is greater than 63% than the most competitive baseline, with most of the improvements observed in challenging tasks such as following a person in a crowd and navigating while strictly avoiding instruction-forbidden regions. The project website is at: https://social-nav.github.io/LISN-project/

