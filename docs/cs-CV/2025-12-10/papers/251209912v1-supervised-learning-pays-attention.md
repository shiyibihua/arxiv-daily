---
layout: default
title: Supervised learning pays attention
---

# Supervised learning pays attention

**arXiv**: [2512.09912v1](https://arxiv.org/abs/2512.09912) | [PDF](https://arxiv.org/pdf/2512.09912.pdf)

**ä½œè€…**: Erin Craig, Robert Tibshirani

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ³¨æ„åŠ›åŠ æƒæ–¹æ³•ï¼Œå°†ç›‘ç£å­¦ä¹ é€‚é…äºŽè¡¨æ ¼æ•°æ®ä»¥æå‡é¢„æµ‹æ€§èƒ½ä¸Žå¯è§£é‡Šæ€§ã€‚**

**å…³é”®è¯**: `æ³¨æ„åŠ›åŠ æƒ` `ç›‘ç£å­¦ä¹ ` `è¡¨æ ¼æ•°æ®` `å¯è§£é‡Šæ€§` `å±€éƒ¨æ¨¡åž‹` `å¼‚è´¨æ•°æ®`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿç›‘ç£å­¦ä¹ åœ¨å¼‚è´¨æ•°æ®ä¸­éš¾ä»¥çµæ´»æ‹Ÿåˆä¸ªæ€§åŒ–æ¨¡åž‹ï¼Œä¸”ç¼ºä¹å¯è§£é‡Šæ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æ³¨æ„åŠ›åŠ æƒè®­ç»ƒæ•°æ®ï¼Œä¸ºæ¯ä¸ªæµ‹è¯•ç‚¹æ‹Ÿåˆå±€éƒ¨æ¨¡åž‹ï¼Œå¼ºè°ƒé¢„æµ‹æ€§ç‰¹å¾å’Œäº¤äº’ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨çœŸå®žå’Œæ¨¡æ‹Ÿæ•°æ®é›†ä¸­ï¼Œè¯¥æ–¹æ³•æé«˜é¢„æµ‹æ€§èƒ½ï¼Œç†è®ºè¯æ˜Žåœ¨å·²çŸ¥å­ç¾¤ç»“æž„ä¸‹é™ä½Žå‡æ–¹è¯¯å·®ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In-context learning with attention enables large neural networks to make context-specific predictions by selectively focusing on relevant examples. Here, we adapt this idea to supervised learning procedures such as lasso regression and gradient boosting, for tabular data. Our goals are to (1) flexibly fit personalized models for each prediction point and (2) retain model simplicity and interpretability.
>   Our method fits a local model for each test observation by weighting the training data according to attention, a supervised similarity measure that emphasizes features and interactions that are predictive of the outcome. Attention weighting allows the method to adapt to heterogeneous data in a data-driven way, without requiring cluster or similarity pre-specification. Further, our approach is uniquely interpretable: for each test observation, we identify which features are most predictive and which training observations are most relevant. We then show how to use attention weighting for time series and spatial data, and we present a method for adapting pretrained tree-based models to distributional shift using attention-weighted residual corrections. Across real and simulated datasets, attention weighting improves predictive performance while preserving interpretability, and theory shows that attention-weighting linear models attain lower mean squared error than the standard linear model under mixture-of-models data-generating processes with known subgroup structure.

