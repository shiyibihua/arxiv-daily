---
layout: default
title: LoGoColor: Local-Global 3D Colorization for 360Â° Scenes
---

# LoGoColor: Local-Global 3D Colorization for 360Â° Scenes

**arXiv**: [2512.09278v1](https://arxiv.org/abs/2512.09278) | [PDF](https://arxiv.org/pdf/2512.09278.pdf)

**ä½œè€…**: Yeonjin Chang, Juhwan Cho, Seunghyeon Seo, Wonsik Shin, Nojun Kwak

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLoGoColorä»¥è§£å†³360Â°åœºæ™¯3Dç€è‰²ä¸­é¢œè‰²å¤šæ ·æ€§ä¸Žå¤šè§†å›¾ä¸€è‡´æ€§é—®é¢˜**

**å…³é”®è¯**: `3Dç€è‰²` `å¤šè§†å›¾ä¸€è‡´æ€§` `é¢œè‰²å¤šæ ·æ€§` `360Â°åœºæ™¯` `å±€éƒ¨-å…¨å±€æ–¹æ³•` `å¤šè§†å›¾æ‰©æ•£æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰3Dç€è‰²æ–¹æ³•å› è’¸é¦2Då›¾åƒæ¨¡åž‹å¯¼è‡´é¢œè‰²å¹³å‡åŒ–ï¼Œåœ¨å¤æ‚360Â°åœºæ™¯ä¸­äº§ç”Ÿå•è°ƒç»“æžœ
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨å±€éƒ¨-å…¨å±€æ–¹æ³•ï¼Œåˆ†åŒºå¤„ç†åœºæ™¯å¹¶ä½¿ç”¨å¾®è°ƒå¤šè§†å›¾æ‰©æ•£æ¨¡åž‹ç¡®ä¿å­åœºæ™¯å†…å’Œå­åœºæ™¯é—´ä¸€è‡´æ€§
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤æ‚360Â°åœºæ™¯ä¸Šå®žçŽ°æ›´ä¸€è‡´å’Œåˆç†çš„3Dç€è‰²ï¼Œå¹¶é€šè¿‡æ–°é¢œè‰²å¤šæ ·æ€§æŒ‡æ•°éªŒè¯é¢œè‰²å¤šæ ·æ€§

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Single-channel 3D reconstruction is widely used in fields such as robotics and medical imaging. While this line of work excels at reconstructing 3D geometry, the outputs are not colored 3D models, thus 3D colorization is required for visualization. Recent 3D colorization studies address this problem by distilling 2D image colorization models. However, these approaches suffer from an inherent inconsistency of 2D image models. This results in colors being averaged during training, leading to monotonous and oversimplified results, particularly in complex 360Â° scenes. In contrast, we aim to preserve color diversity by generating a new set of consistently colorized training views, thereby bypassing the averaging process. Nevertheless, eliminating the averaging process introduces a new challenge: ensuring strict multi-view consistency across these colorized views. To achieve this, we propose LoGoColor, a pipeline designed to preserve color diversity by eliminating this guidance-averaging process with a `Local-Global' approach: we partition the scene into subscenes and explicitly tackle both inter-subscene and intra-subscene consistency using a fine-tuned multi-view diffusion model. We demonstrate that our method achieves quantitatively and qualitatively more consistent and plausible 3D colorization on complex 360Â° scenes than existing methods, and validate its superior color diversity using a novel Color Diversity Index.

