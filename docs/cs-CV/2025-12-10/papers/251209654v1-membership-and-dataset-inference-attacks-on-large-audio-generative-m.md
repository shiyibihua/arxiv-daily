---
layout: default
title: Membership and Dataset Inference Attacks on Large Audio Generative Models
---

# Membership and Dataset Inference Attacks on Large Audio Generative Models

**arXiv**: [2512.09654v1](https://arxiv.org/abs/2512.09654) | [PDF](https://arxiv.org/pdf/2512.09654.pdf)

**ä½œè€…**: Jakub Proboszcz, PaweÅ‚ Kochanski, Karol Korszun, Donato Crisostomi, Giorgio Strano, Emanuele RodolÃ , Kamil Deja, Jan Dubinski

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ•°æ®é›†æŽ¨ç†æ”»å‡»ä»¥è¯„ä¼°éŸ³é¢‘ç”Ÿæˆæ¨¡åž‹è®­ç»ƒæ•°æ®ç‰ˆæƒå½’å±ž**

**å…³é”®è¯**: `éŸ³é¢‘ç”Ÿæˆæ¨¡åž‹` `æˆå‘˜æŽ¨ç†æ”»å‡»` `æ•°æ®é›†æŽ¨ç†æ”»å‡»` `ç‰ˆæƒä¿æŠ¤` `è®­ç»ƒæ•°æ®éªŒè¯`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šéªŒè¯éŸ³é¢‘ç”Ÿæˆæ¨¡åž‹æ˜¯å¦ä½¿ç”¨ç‰¹å®šè‰ºæœ¯å®¶çš„ä½œå“è¿›è¡Œè®­ç»ƒï¼Œä»¥åº”å¯¹ç‰ˆæƒä¿æŠ¤æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåœ¨æˆå‘˜æŽ¨ç†æ”»å‡»åŸºç¡€ä¸Šï¼Œé€šè¿‡èšåˆå¤šä¸ªæ ·æœ¬è¯æ®ï¼Œå®žæ–½æ•°æ®é›†æŽ¨ç†æ”»å‡»ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šæˆå‘˜æŽ¨ç†åœ¨å¤§åž‹æ•°æ®é›†ä¸Šæ•ˆæžœæœ‰é™ï¼Œä½†æ•°æ®é›†æŽ¨ç†åœ¨éŸ³é¢‘é¢†åŸŸæˆåŠŸï¼Œæä¾›å®žç”¨è¯„ä¼°æœºåˆ¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generative audio models, based on diffusion and autoregressive architectures, have advanced rapidly in both quality and expressiveness. This progress, however, raises pressing copyright concerns, as such models are often trained on vast corpora of artistic and commercial works. A central question is whether one can reliably verify if an artist's material was included in training, thereby providing a means for copyright holders to protect their content. In this work, we investigate the feasibility of such verification through membership inference attacks (MIA) on open-source generative audio models, which attempt to determine whether a specific audio sample was part of the training set. Our empirical results show that membership inference alone is of limited effectiveness at scale, as the per-sample membership signal is weak for models trained on large and diverse datasets. However, artists and media owners typically hold collections of works rather than isolated samples. Building on prior work in text and vision domains, in this work we focus on dataset inference (DI), which aggregates diverse membership evidence across multiple samples. We find that DI is successful in the audio domain, offering a more practical mechanism for assessing whether an artist's works contributed to model training. Our results suggest DI as a promising direction for copyright protection and dataset accountability in the era of large audio generative models.

