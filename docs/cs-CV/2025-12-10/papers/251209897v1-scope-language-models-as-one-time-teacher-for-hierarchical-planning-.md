---
layout: default
title: SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments
---

# SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments

**arXiv**: [2512.09897v1](https://arxiv.org/abs/2512.09897) | [PDF](https://arxiv.org/pdf/2512.09897.pdf)

**ä½œè€…**: Haoye Lu, Pavan Seshadri, Kaheer Suleman

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSCOPEæ–¹æ³•ï¼Œåˆ©ç”¨LLMç”Ÿæˆå­ç›®æ ‡ä¸€æ¬¡æ€§é¢„è®­ç»ƒè½»é‡æ¨¡åž‹ï¼Œä»¥é«˜æ•ˆè§£å†³æ–‡æœ¬çŽ¯å¢ƒä¸­çš„åˆ†å±‚è§„åˆ’é—®é¢˜ã€‚**

**å…³é”®è¯**: `åˆ†å±‚è§„åˆ’` `æ–‡æœ¬çŽ¯å¢ƒ` `è¯­è¨€æ¨¡åž‹è’¸é¦` `å­ç›®æ ‡ç”Ÿæˆ` `é«˜æ•ˆæŽ¨ç†` `é¢„è®­ç»ƒæ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæ–‡æœ¬çŽ¯å¢ƒä¸­é•¿æœŸè§„åˆ’é¢ä¸´å¼€æ”¾åŠ¨ä½œç©ºé—´ã€æ¨¡ç³Šè§‚å¯Ÿå’Œç¨€ç–åé¦ˆï¼ŒçŽ°æœ‰æ–¹æ³•ä¾èµ–é‡å¤æŸ¥è¯¢LLMï¼Œè®¡ç®—æˆæœ¬é«˜ä¸”ç¼ºä¹é€‚åº”æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šSCOPEé€šè¿‡LLMç”Ÿæˆå­ç›®æ ‡ä»…ç”¨äºŽåˆå§‹åŒ–ï¼Œé¢„è®­ç»ƒå­¦ç”Ÿæ¨¡åž‹ï¼Œé¿å…è®­ç»ƒå’ŒæŽ¨ç†ä¸­çš„é‡å¤æŸ¥è¯¢ï¼Œæå‡æ•ˆçŽ‡ä½†å¯èƒ½ç‰ºç‰²è§£é‡Šæ€§å’Œå­ç›®æ ‡æœ€ä¼˜æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨TextCraftçŽ¯å¢ƒä¸­ï¼ŒSCOPEè¾¾åˆ°0.56æˆåŠŸçŽ‡ï¼Œä¼˜äºŽADaPTçš„0.52ï¼ŒæŽ¨ç†æ—¶é—´ä»Ž164.4ç§’é™è‡³3.0ç§’ï¼Œæ˜¾è‘—æå‡æ•ˆçŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for guiding agents in high-level reasoning and planning across both embodied and purely textual settings. However, existing approaches often depend heavily on querying LLMs during training and inference, making them computationally expensive and difficult to deploy efficiently. In addition, these methods typically employ a pretrained, unaltered LLM whose parameters remain fixed throughout training, providing no opportunity for adaptation to the target task. To address these limitations, we introduce SCOPE (Subgoal-COnditioned Pretraining for Efficient planning), a one-shot hierarchical planner that leverages LLM-generated subgoals only at initialization to pretrain a lightweight student model. Unlike prior approaches that distill LLM knowledge by repeatedly prompting the model to adaptively generate subgoals during training, our method derives subgoals directly from example trajectories. This design removes the need for repeated LLM queries, significantly improving efficiency, though at the cost of reduced explainability and potentially suboptimal subgoals. Despite their suboptimality, our results on the TextCraft environment show that LLM-generated subgoals can still serve as a strong starting point for hierarchical goal decomposition in text-based planning tasks. Compared to the LLM-based hierarchical agent ADaPT (Prasad et al., 2024), which achieves a 0.52 success rate, our method reaches 0.56 and reduces inference time from 164.4 seconds to just 3.0 seconds.

