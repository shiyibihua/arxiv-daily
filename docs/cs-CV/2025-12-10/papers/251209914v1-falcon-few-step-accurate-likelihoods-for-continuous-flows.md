---
layout: default
title: FALCON: Few-step Accurate Likelihoods for Continuous Flows
---

# FALCON: Few-step Accurate Likelihoods for Continuous Flows

**arXiv**: [2512.09914v1](https://arxiv.org/abs/2512.09914) | [PDF](https://arxiv.org/pdf/2512.09914.pdf)

**ä½œè€…**: Danyal Rehman, Tara Akhound-Sadegh, Artem Gazizov, Yoshua Bengio, Alexander Tong

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFALCONæ–¹æ³•ä»¥è§£å†³è¿žç»­æµæ¨¡åž‹åœ¨åˆ†å­çŽ»å°”å…¹æ›¼é‡‡æ ·ä¸­ä¼¼ç„¶è®¡ç®—æˆæœ¬é«˜çš„é—®é¢˜**

**å…³é”®è¯**: `åˆ†å­çŽ»å°”å…¹æ›¼é‡‡æ ·` `è¿žç»­å½’ä¸€åŒ–æµ` `é‡è¦æ€§é‡‡æ ·` `å¯é€†æ€§è®­ç»ƒ` `å°‘æ­¥é‡‡æ ·`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè¿žç»­å½’ä¸€åŒ–æµæ¨¡åž‹åœ¨åˆ†å­çƒ­åŠ›å­¦å¹³è¡¡æ€é‡‡æ ·ä¸­ï¼Œä¼¼ç„¶è®¡ç®—éœ€æ•°åƒæ¬¡å‡½æ•°è¯„ä¼°ï¼Œæˆæœ¬æžé«˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥æ··åˆè®­ç»ƒç›®æ ‡ï¼Œä¿ƒè¿›æ¨¡åž‹å¯é€†æ€§ï¼Œå®žçŽ°å°‘æ­¥é‡‡æ ·ä¸”ä¼¼ç„¶è¶³å¤Ÿç²¾ç¡®ç”¨äºŽé‡è¦æ€§é‡‡æ ·ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šFALCONåœ¨åˆ†å­çŽ»å°”å…¹æ›¼é‡‡æ ·ä¸­ä¼˜äºŽå½“å‰æœ€ä¼˜å½’ä¸€åŒ–æµæ¨¡åž‹ï¼Œæ¯”ç­‰æ•ˆCNFæ¨¡åž‹å¿«ä¸¤ä¸ªæ•°é‡çº§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Scalable sampling of molecular states in thermodynamic equilibrium is a long-standing challenge in statistical physics. Boltzmann Generators tackle this problem by pairing a generative model, capable of exact likelihood computation, with importance sampling to obtain consistent samples under the target distribution. Current Boltzmann Generators primarily use continuous normalizing flows (CNFs) trained with flow matching for efficient training of powerful models. However, likelihood calculation for these models is extremely costly, requiring thousands of function evaluations per sample, severely limiting their adoption. In this work, we propose Few-step Accurate Likelihoods for Continuous Flows (FALCON), a method which allows for few-step sampling with a likelihood accurate enough for importance sampling applications by introducing a hybrid training objective that encourages invertibility. We show FALCON outperforms state-of-the-art normalizing flow models for molecular Boltzmann sampling and is two orders of magnitude faster than the equivalently performing CNF model.

