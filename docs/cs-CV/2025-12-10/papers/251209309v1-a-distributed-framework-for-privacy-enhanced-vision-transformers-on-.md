---
layout: default
title: A Distributed Framework for Privacy-Enhanced Vision Transformers on the Edge
---

# A Distributed Framework for Privacy-Enhanced Vision Transformers on the Edge

**arXiv**: [2512.09309v1](https://arxiv.org/abs/2512.09309) | [PDF](https://arxiv.org/pdf/2512.09309.pdf)

**ä½œè€…**: Zihao Ding, Mufeng Zhu, Zhongze Tang, Sheng Wei, Yao Liu

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆ†å¸ƒå¼éšç§å¢žå¼ºè§†è§‰Transformerè¾¹ç¼˜æ¡†æž¶ï¼Œä»¥è§£å†³èµ„æºå—é™è®¾å¤‡è§†è§‰ä»»åŠ¡ä¸­çš„éšç§æ³„éœ²é—®é¢˜ã€‚**

**å…³é”®è¯**: `éšç§ä¿æŠ¤` `è¾¹ç¼˜è®¡ç®—` `è§†è§‰Transformer` `åˆ†å¸ƒå¼æ¡†æž¶` `æ•°æ®åˆ†ç‰‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§‰æ™ºèƒ½å·¥å…·è®¡ç®—éœ€æ±‚é«˜ï¼Œäº‘ç«¯å¸è½½æ˜“å¯¼è‡´ä¼ è¾“å’ŒæœåŠ¡å™¨ç«¯éšç§æ¼æ´žã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨å¯ä¿¡è¾¹ç¼˜è®¾å¤‡ä½œä¸ºåè°ƒå™¨ï¼Œå°†è§†è§‰æ•°æ®åˆ†ç‰‡åˆ†å‘è‡³å¤šä¸ªç‹¬ç«‹äº‘æœåŠ¡å™¨ï¼Œé˜²æ­¢å•æœåŠ¡å™¨å®Œæ•´é‡å»ºã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šä»¥Segment Anything Modelä¸ºä¾‹ï¼Œä¿æŒè¿‘åŸºçº¿åˆ†å‰²æ€§èƒ½ï¼Œæ˜¾è‘—é™ä½Žå†…å®¹é‡å»ºå’Œç”¨æˆ·æ•°æ®æš´éœ²é£Žé™©ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Nowadays, visual intelligence tools have become ubiquitous, offering all kinds of convenience and possibilities. However, these tools have high computational requirements that exceed the capabilities of resource-constrained mobile and wearable devices. While offloading visual data to the cloud is a common solution, it introduces significant privacy vulnerabilities during transmission and server-side computation. To address this, we propose a novel distributed, hierarchical offloading framework for Vision Transformers (ViTs) that addresses these privacy challenges by design. Our approach uses a local trusted edge device, such as a mobile phone or an Nvidia Jetson, as the edge orchestrator. This orchestrator partitions the user's visual data into smaller portions and distributes them across multiple independent cloud servers. By design, no single external server possesses the complete image, preventing comprehensive data reconstruction. The final data merging and aggregation computation occurs exclusively on the user's trusted edge device. We apply our framework to the Segment Anything Model (SAM) as a practical case study, which demonstrates that our method substantially enhances content privacy over traditional cloud-based approaches. Evaluations show our framework maintains near-baseline segmentation performance while substantially reducing the risk of content reconstruction and user data exposure. Our framework provides a scalable, privacy-preserving solution for vision tasks in the edge-cloud continuum.

