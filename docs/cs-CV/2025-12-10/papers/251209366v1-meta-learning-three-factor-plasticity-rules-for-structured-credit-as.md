---
layout: default
title: Meta-learning three-factor plasticity rules for structured credit assignment with sparse feedback
---

# Meta-learning three-factor plasticity rules for structured credit assignment with sparse feedback

**arXiv**: [2512.09366v1](https://arxiv.org/abs/2512.09366) | [PDF](https://arxiv.org/pdf/2512.09366.pdf)

**ä½œè€…**: Dimitra Maoutsa

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå…ƒå­¦ä¹ æ¡†æž¶ä»¥å‘çŽ°ç”¨äºŽç¨€ç–åé¦ˆä¸‹å¾ªçŽ¯ç½‘ç»œç»“æž„åŒ–ä¿¡ç”¨åˆ†é…çš„å±€éƒ¨å¯å¡‘æ€§è§„åˆ™**

**å…³é”®è¯**: `å…ƒå­¦ä¹ ` `ç»“æž„åŒ–ä¿¡ç”¨åˆ†é…` `ç¨€ç–åé¦ˆ` `å±€éƒ¨å¯å¡‘æ€§è§„åˆ™` `å¾ªçŽ¯ç¥žç»ç½‘ç»œ` `ç”Ÿç‰©å¯ä¿¡å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç”Ÿç‰©ç¥žç»ç½‘ç»œå¦‚ä½•ä»Žç¨€ç–å»¶è¿Ÿåé¦ˆä¸­å®žçŽ°ç»“æž„åŒ–ä¿¡ç”¨åˆ†é…ï¼ŒçŽ°æœ‰äººå·¥æ–¹æ³•ä¾èµ–éžç”Ÿç‰©å¯ä¿¡çš„å…¨å±€è§„åˆ™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å…ƒå­¦ä¹ æ¡†æž¶ï¼Œç»“åˆå±€éƒ¨ç±»æ–°èµ«å¸ƒæ›´æ–°å’ŒåŸºäºŽåˆ‡çº¿ä¼ æ’­çš„å¤–å¾ªçŽ¯ä¼˜åŒ–ï¼Œå‘çŽ°ä¸‰å› å­å¯å¡‘æ€§è§„åˆ™ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè§„åˆ™ä»…ä½¿ç”¨å±€éƒ¨ä¿¡æ¯å’Œå»¶è¿Ÿå¥–åŠ±æ”¯æŒé•¿æ—¶ç¨‹ä¿¡ç”¨åˆ†é…ï¼Œä¸ºå¾ªçŽ¯ç”µè·¯å­¦ä¹ æä¾›ç”Ÿç‰©åŸºç¡€æœºåˆ¶æ–°è§è§£ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Biological neural networks learn complex behaviors from sparse, delayed feedback using local synaptic plasticity, yet the mechanisms enabling structured credit assignment remain elusive. In contrast, artificial recurrent networks solving similar tasks typically rely on biologically implausible global learning rules or hand-crafted local updates. The space of local plasticity rules capable of supporting learning from delayed reinforcement remains largely unexplored. Here, we present a meta-learning framework that discovers local learning rules for structured credit assignment in recurrent networks trained with sparse feedback. Our approach interleaves local neo-Hebbian-like updates during task execution with an outer loop that optimizes plasticity parameters via \textbf{tangent-propagation through learning}. The resulting three-factor learning rules enable long-timescale credit assignment using only local information and delayed rewards, offering new insights into biologically grounded mechanisms for learning in recurrent circuits.

