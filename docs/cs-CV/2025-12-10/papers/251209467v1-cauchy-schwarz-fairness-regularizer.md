---
layout: default
title: Cauchy-Schwarz Fairness Regularizer
---

# Cauchy-Schwarz Fairness Regularizer

**arXiv**: [2512.09467v1](https://arxiv.org/abs/2512.09467) | [PDF](https://arxiv.org/pdf/2512.09467.pdf)

**ä½œè€…**: Yezi Liu, Hanning Chen, Wenjun Huang, Yang Ni, Mohsen Imani

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæŸ¯è¥¿-æ–½ç“¦èŒ¨å…¬å¹³æ­£åˆ™å™¨ä»¥æå‡æœºå™¨å­¦ä¹ ä¸­çš„ç¾¤ä½“å…¬å¹³æ€§**

**å…³é”®è¯**: `ç¾¤ä½“å…¬å¹³` `æ­£åˆ™åŒ–æ–¹æ³•` `æŸ¯è¥¿-æ–½ç“¦èŒ¨æ•£åº¦` `æœºå™¨å­¦ä¹ å…¬å¹³æ€§` `æ•æ„Ÿå±žæ€§å¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å…¬å¹³æ­£åˆ™å™¨åŸºäºŽå¼‚æž„è·ç¦»åº¦é‡ï¼Œå¯¼è‡´è¡Œä¸ºéš¾ä»¥è§£é‡Šä¸”æ€§èƒ½ä¸ä¸€è‡´
2. åŸºäºŽæŸ¯è¥¿-æ–½ç“¦èŒ¨æ•£åº¦è®¾è®¡æ­£åˆ™å™¨ï¼Œå…·æœ‰ç´§è‡´æ³›åŒ–ç•Œå’Œå°ºåº¦é²æ£’æ€§
3. åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®žéªŒï¼Œæ”¹å–„å…¬å¹³æŒ‡æ ‡å¹¶ä¿æŒå‡†ç¡®åº¦ï¼Œå®žçŽ°æ›´ç¨³å®šçš„æ•ˆç”¨-å…¬å¹³æƒè¡¡

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Group fairness in machine learning is often enforced by adding a regularizer that reduces the dependence between model predictions and sensitive attributes. However, existing regularizers are built on heterogeneous distance measures and design choices, which makes their behavior hard to reason about and their performance inconsistent across tasks. This raises a basic question: what properties make a good fairness regularizer? We address this question by first organizing existing in-process methods into three families: (i) matching prediction statistics across sensitive groups, (ii) aligning latent representations, and (iii) directly minimizing dependence between predictions and sensitive attributes. Through this lens, we identify desirable properties of the underlying distance measure, including tight generalization bounds, robustness to scale differences, and the ability to handle arbitrary prediction distributions. Motivated by these properties, we propose a Cauchy-Schwarz (CS) fairness regularizer that penalizes the empirical CS divergence between prediction distributions conditioned on sensitive groups. Under a Gaussian comparison, we show that CS divergence yields a tighter bound than Kullback-Leibler divergence, Maximum Mean Discrepancy, and the mean disparity used in Demographic Parity, and we discuss how these advantages translate to a distribution-free, kernel-based estimator that naturally extends to multiple sensitive attributes. Extensive experiments on four tabular benchmarks and one image dataset demonstrate that the proposed CS regularizer consistently improves Demographic Parity and Equal Opportunity metrics while maintaining competitive accuracy, and achieves a more stable utility-fairness trade-off across hyperparameter settings compared to prior regularizers.

