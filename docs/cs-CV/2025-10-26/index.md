---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-10-26
---

# cs.CVï¼ˆ2025-10-26ï¼‰

ğŸ“Š å…± **20** ç¯‡è®ºæ–‡
 | ğŸ”— **4** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (12 ğŸ”—4)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (4)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (12 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251022694v1-windsock-is-dancing-adaptive-multimodal-retrieval-augmented-generati.html">Windsock is Dancing: Adaptive Multimodal Retrieval-Augmented Generation</a></td>
  <td>Windsockï¼šè‡ªé€‚åº”å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ³•ï¼Œæå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22694v1" onclick="toggleFavorite(this, '2510.22694v1', 'Windsock is Dancing: Adaptive Multimodal Retrieval-Augmented Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251022665v2-sarvlm-a-vision-language-foundation-model-for-semantic-understanding.html">SARVLM: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery</a></td>
  <td>æå‡ºSARVLMï¼šé¢å‘SARå›¾åƒè¯­ä¹‰ç†è§£å’Œç›®æ ‡è¯†åˆ«çš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22665v2" onclick="toggleFavorite(this, '2510.22665v2', 'SARVLM: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251022622v1-deepfakebench-mm-a-comprehensive-benchmark-for-multimodal-deepfake-d.html">DeepfakeBench-MM: A Comprehensive Benchmark for Multimodal Deepfake Detection</a></td>
  <td>æ„å»ºå¤šæ¨¡æ€æ·±åº¦ä¼ªé€ æ£€æµ‹åŸºå‡†ï¼Œåº”å¯¹ä¼ªé€ éŸ³è§†é¢‘å†…å®¹å¸¦æ¥çš„ç¤¾ä¼šé£é™©ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22622v1" onclick="toggleFavorite(this, '2510.22622v1', 'DeepfakeBench-MM: A Comprehensive Benchmark for Multimodal Deepfake Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251022521v1-open-multimodal-retrieval-augmented-factual-image-generation.html">Open Multimodal Retrieval-Augmented Factual Image Generation</a></td>
  <td>æå‡ºORIGæ¡†æ¶ï¼Œé€šè¿‡å¼€æ”¾å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºï¼Œè§£å†³äº‹å®æ€§å›¾åƒç”Ÿæˆä¸­çŸ¥è¯†ä¸å‡†ç¡®é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22521v1" onclick="toggleFavorite(this, '2510.22521v1', 'Open Multimodal Retrieval-Augmented Factual Image Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251022507v1-gatefusenet-an-adaptive-3d-multimodal-neuroimaging-fusion-network-fo.html">GateFuseNet: An Adaptive 3D Multimodal Neuroimaging Fusion Network for Parkinson's Disease Diagnosis</a></td>
  <td>GateFuseNetï¼šä¸€ç§è‡ªé€‚åº”3Då¤šæ¨¡æ€ç¥ç»å½±åƒèåˆç½‘ç»œï¼Œç”¨äºå¸•é‡‘æ£®ç—…è¯Šæ–­</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22507v1" onclick="toggleFavorite(this, '2510.22507v1', 'GateFuseNet: An Adaptive 3D Multimodal Neuroimaging Fusion Network for Parkinson&#39;s Disease Diagnosis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251022827v2-fairjudge-mllm-judging-for-social-attributes-and-prompt-image-alignm.html">FairJudge: MLLM Judging for Social Attributes and Prompt Image Alignment</a></td>
  <td>FairJudgeï¼šåˆ©ç”¨å¤šæ¨¡æ€LLMè¯„ä¼°ç¤¾ä¼šå±æ€§å’Œæç¤ºå›¾åƒå¯¹é½ï¼Œæå‡å…¬å¹³æ€§å®¡è®¡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22827v2" onclick="toggleFavorite(this, '2510.22827v2', 'FairJudge: MLLM Judging for Social Attributes and Prompt Image Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251022603v2-mitigating-attention-sinks-and-massive-activations-in-audio-visual-s.html">Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMs</a></td>
  <td>é’ˆå¯¹AVSRä¸­LLMçš„Attention Sinké—®é¢˜ï¼Œæå‡ºè§£è€¦æŸå¤±ä»¥æå‡è¯†åˆ«ç²¾åº¦</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22603v2" onclick="toggleFavorite(this, '2510.22603v2', 'Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251022829v1-llm-based-fusion-of-multi-modal-features-for-commercial-memorability.html">LLM-based Fusion of Multi-modal Features for Commercial Memorability Prediction</a></td>
  <td>æå‡ºåŸºäºLLMçš„å¤šæ¨¡æ€èåˆæ–¹æ³•ï¼Œç”¨äºæå‡å•†ä¸šå¹¿å‘Šè®°å¿†åº¦é¢„æµ‹çš„é²æ£’æ€§å’Œæ³›åŒ–æ€§ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22829v1" onclick="toggleFavorite(this, '2510.22829v1', 'LLM-based Fusion of Multi-modal Features for Commercial Memorability Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251022693v2-vadtree-explainable-training-free-video-anomaly-detection-via-hierar.html">VADTree: Explainable Training-Free Video Anomaly Detection via Hierarchical Granularity-Aware Tree</a></td>
  <td>VADTreeï¼šé€šè¿‡åˆ†å±‚ç²’åº¦æ„ŸçŸ¥æ ‘å®ç°å¯è§£é‡Šçš„æ— è®­ç»ƒè§†é¢‘å¼‚å¸¸æ£€æµ‹</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22693v2" onclick="toggleFavorite(this, '2510.22693v2', 'VADTree: Explainable Training-Free Video Anomaly Detection via Hierarchical Granularity-Aware Tree')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251022684v1-robosvg-a-unified-framework-for-interactive-svg-generation-with-mult.html">RoboSVG: A Unified Framework for Interactive SVG Generation with Multi-modal Guidance</a></td>
  <td>RoboSVGï¼šå¤šæ¨¡æ€å¼•å¯¼çš„äº¤äº’å¼SVGç»Ÿä¸€ç”Ÿæˆæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22684v1" onclick="toggleFavorite(this, '2510.22684v1', 'RoboSVG: A Unified Framework for Interactive SVG Generation with Multi-modal Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251022589v2-psscreen-v2-partially-supervised-multiple-retinal-disease-screening.html">PSScreen V2: Partially Supervised Multiple Retinal Disease Screening</a></td>
  <td>PSScreen V2ï¼šä¸€ç§ç”¨äºå¤šè§†ç½‘è†œç–¾ç—…ç­›æŸ¥çš„åŠç›‘ç£è‡ªè®­ç»ƒæ¡†æ¶</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22589v2" onclick="toggleFavorite(this, '2510.22589v2', 'PSScreen V2: Partially Supervised Multiple Retinal Disease Screening')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251022571v1-status-bench-a-rigorous-benchmark-for-evaluating-object-state-unders.html">STATUS Bench: A Rigorous Benchmark for Evaluating Object State Understanding in Vision-Language Models</a></td>
  <td>STATUS Benchï¼šç”¨äºè¯„ä¼°è§†è§‰-è¯­è¨€æ¨¡å‹ç‰©ä½“çŠ¶æ€ç†è§£èƒ½åŠ›çš„ä¸¥æ ¼åŸºå‡†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22571v1" onclick="toggleFavorite(this, '2510.22571v1', 'STATUS Bench: A Rigorous Benchmark for Evaluating Object State Understanding in Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/251022669v1-lvd-gs-gaussian-splatting-slam-for-dynamic-scenes-via-hierarchical-e.html">LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical Explicit-Implicit Representation Collaboration Rendering</a></td>
  <td>LVD-GSï¼šé¢å‘åŠ¨æ€åœºæ™¯ï¼ŒåŸºäºåˆ†å±‚æ˜¾éšå¼è¡¨è¾¾ååŒæ¸²æŸ“çš„Gaussian Splatting SLAM</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22669v1" onclick="toggleFavorite(this, '2510.22669v1', 'LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical Explicit-Implicit Representation Collaboration Rendering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251022672v2-look-and-tell-a-dataset-for-multimodal-grounding-across-egocentric-a.html">Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views</a></td>
  <td>æå‡ºLook and Tellæ•°æ®é›†ï¼Œç”¨äºç ”ç©¶ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒå’Œä»¥å¤–éƒ¨ä¸ºä¸­å¿ƒè§†è§’ä¸‹çš„å¤šæ¨¡æ€æŒ‡ç¤ºäº¤æµã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22672v2" onclick="toggleFavorite(this, '2510.22672v2', 'Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251022473v1-dynapose4d-high-quality-4d-dynamic-content-generation-via-pose-align.html">DynaPose4D: High-Quality 4D Dynamic Content Generation via Pose Alignment Loss</a></td>
  <td>DynaPose4Dï¼šæå‡ºåŸºäºå§¿æ€å¯¹é½æŸå¤±çš„é«˜è´¨é‡4DåŠ¨æ€å†…å®¹ç”Ÿæˆæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22473v1" onclick="toggleFavorite(this, '2510.22473v1', 'DynaPose4D: High-Quality 4D Dynamic Content Generation via Pose Alignment Loss')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251022868v1-seeing-the-unseen-towards-zero-shot-inspection-for-wind-turbine-blad.html">Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models</a></td>
  <td>æå‡ºåŸºäºçŸ¥è¯†å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹çš„é›¶æ ·æœ¬é£åŠ›æ¶¡è½®æœºå¶ç‰‡ç¼ºé™·æ£€æµ‹æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22868v1" onclick="toggleFavorite(this, '2510.22868v1', 'Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/251022718v1-edge-collaborative-gaussian-splatting-with-integrated-rendering-and-.html">Edge Collaborative Gaussian Splatting with Integrated Rendering and Communication</a></td>
  <td>æå‡ºECO-GSï¼Œé€šè¿‡è¾¹ç¼˜ååŒé«˜æ–¯æº…å°„æå‡ä½æˆæœ¬è®¾å¤‡æ¸²æŸ“è´¨é‡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22718v1" onclick="toggleFavorite(this, '2510.22718v1', 'Edge Collaborative Gaussian Splatting with Integrated Rendering and Communication')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251100028v1-mutual-information-guided-visual-contrastive-learning.html">Mutual Information guided Visual Contrastive Learning</a></td>
  <td>æå‡ºäº’ä¿¡æ¯å¼•å¯¼çš„è§†è§‰å¯¹æ¯”å­¦ä¹ ï¼Œæå‡è¡¨å¾å­¦ä¹ åœ¨å¼€æ”¾ç¯å¢ƒä¸‹çš„æ³›åŒ–æ€§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.00028v1" onclick="toggleFavorite(this, '2511.00028v1', 'Mutual Information guided Visual Contrastive Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251022673v1-alias-free-vit-fractional-shift-invariance-via-linear-attention.html">Alias-Free ViT: Fractional Shift Invariance via Linear Attention</a></td>
  <td>æå‡ºAlias-Free ViTï¼Œé€šè¿‡çº¿æ€§æ³¨æ„åŠ›å®ç°åˆ†æ•°å¹³ç§»ä¸å˜æ€§ï¼Œæå‡ViTçš„é²æ£’æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22673v1" onclick="toggleFavorite(this, '2510.22673v1', 'Alias-Free ViT: Fractional Shift Invariance via Linear Attention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251022480v1-single-teacher-view-augmentation-boosting-knowledge-distillation-via.html">Single-Teacher View Augmentation: Boosting Knowledge Distillation via Angular Diversity</a></td>
  <td>æå‡ºåŸºäºå•æ•™å¸ˆè§†è§’å¢å¼ºçš„çŸ¥è¯†è’¸é¦æ–¹æ³•ï¼Œé€šè¿‡è§’åº¦å¤šæ ·æ€§æå‡å­¦ç”Ÿæ¨¡å‹æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.22480v1" onclick="toggleFavorite(this, '2510.22480v1', 'Single-Teacher View Augmentation: Boosting Knowledge Distillation via Angular Diversity')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)