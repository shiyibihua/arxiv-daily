---
layout: default
title: Structured Prompting and Multi-Agent Knowledge Distillation for Traffic Video Interpretation and Risk Inference
---

# Structured Prompting and Multi-Agent Knowledge Distillation for Traffic Video Interpretation and Risk Inference

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13439" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13439v1</a>
  <a href="https://arxiv.org/pdf/2508.13439.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13439v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13439v1', 'Structured Prompting and Multi-Agent Knowledge Distillation for Traffic Video Interpretation and Risk Inference')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yunxiang Yang, Ningning Xu, Jidong J. Yang

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL, eess.IV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19

**å¤‡æ³¨**: 16 pages, 10 figures, 1 table

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“æ„åŒ–æç¤ºä¸å¤šæ™ºèƒ½ä½“çŸ¥è¯†è’¸é¦ä»¥è§£å†³äº¤é€šè§†é¢‘ç†è§£é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äº¤é€šè§†é¢‘ç†è§£` `çŸ¥è¯†è’¸é¦` `ç»“æ„åŒ–æç¤º` `å¤šæ™ºèƒ½ä½“ç›‘ç£` `æ™ºèƒ½äº¤é€šç³»ç»Ÿ` `è‡ªåŠ¨é©¾é©¶` `ä½åˆ†è¾¨ç‡è§†é¢‘` `é£é™©æ¨æ–­`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸‹çš„å¯æ‰©å±•æ€§å’Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œéš¾ä»¥æ»¡è¶³æ™ºèƒ½äº¤é€šç³»ç»Ÿçš„éœ€æ±‚ã€‚
2. æå‡ºçš„æ¡†æ¶é€šè¿‡ç»“æ„åŒ–æç¤ºå’ŒçŸ¥è¯†è’¸é¦ï¼Œåˆ©ç”¨å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„äº¤é€šåœºæ™¯æ³¨é‡Šã€‚
3. VISTAæ¨¡å‹åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå°½ç®¡å‚æ•°æ•°é‡æ˜¾è‘—å‡å°‘ï¼Œä¾ç„¶èƒ½å¤Ÿå®ç°å®æ—¶é£é™©ç›‘æµ‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…¨é¢çš„é«˜é€Ÿå…¬è·¯åœºæ™¯ç†è§£å’Œç¨³å¥çš„äº¤é€šé£é™©æ¨æ–­å¯¹äºæ¨è¿›æ™ºèƒ½äº¤é€šç³»ç»Ÿå’Œè‡ªåŠ¨é©¾é©¶è‡³å…³é‡è¦ã€‚ä¼ ç»Ÿæ–¹æ³•åœ¨å¤æ‚åŠ¨æ€çš„ç°å®ç¯å¢ƒä¸­å¾€å¾€é¢ä¸´å¯æ‰©å±•æ€§å’Œæ³›åŒ–èƒ½åŠ›çš„æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç»“æ„åŒ–æç¤ºå’ŒçŸ¥è¯†è’¸é¦æ¡†æ¶ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„äº¤é€šåœºæ™¯æ³¨é‡Šå’Œä¸Šä¸‹æ–‡é£é™©è¯„ä¼°ã€‚è¯¥æ¡†æ¶åè°ƒäº†ä¸¤ä¸ªå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ï¼Œé€šè¿‡ç»“æ„åŒ–çš„æ€ç»´é“¾ç­–ç•¥ç”Ÿæˆä¸°å¯Œçš„å¤šè§†è§’è¾“å‡ºï¼Œä½œä¸ºç›‘ç£å¾®è°ƒå°å‹å­¦ç”Ÿæ¨¡å‹çš„çŸ¥è¯†å¢å¼ºä¼ªæ³¨é‡Šã€‚æœ€ç»ˆå¾—åˆ°çš„ç´§å‡‘å‹3Bè§„æ¨¡æ¨¡å‹VISTAèƒ½å¤Ÿç†è§£ä½åˆ†è¾¨ç‡äº¤é€šè§†é¢‘å¹¶ç”Ÿæˆè¯­ä¹‰å‡†ç¡®ã€é£é™©æ„è¯†å¼ºçš„æè¿°ã€‚å°½ç®¡å‚æ•°æ•°é‡æ˜¾è‘—å‡å°‘ï¼ŒVISTAåœ¨å¤šä¸ªæ ‡å‡†è¯„ä¼°æŒ‡æ ‡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå±•ç¤ºäº†æœ‰æ•ˆçš„çŸ¥è¯†è’¸é¦å’Œç»“æ„åŒ–å¤šæ™ºèƒ½ä½“ç›‘ç£èƒ½å¤Ÿèµ‹èƒ½è½»é‡çº§VLMæ•æ‰å¤æ‚æ¨ç†èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿäº¤é€šè§†é¢‘ç†è§£æ–¹æ³•åœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸‹çš„å¯æ‰©å±•æ€§å’Œæ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä½åˆ†è¾¨ç‡è§†é¢‘æ—¶å¸¸å¸¸æ— æ³•æä¾›å‡†ç¡®çš„åœºæ™¯ç†è§£å’Œé£é™©è¯„ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„ç»“æ„åŒ–æç¤ºå’ŒçŸ¥è¯†è’¸é¦æ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸°å¯Œçš„å¤šè§†è§’è¾“å‡ºï¼Œä½œä¸ºå°å‹å­¦ç”Ÿæ¨¡å‹çš„çŸ¥è¯†å¢å¼ºä¼ªæ³¨é‡Šï¼Œä»è€Œæå‡å…¶ç†è§£èƒ½åŠ›å’Œæ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆGPT-4oå’Œo3-miniï¼‰ï¼Œé€šè¿‡ç»“æ„åŒ–çš„æ€ç»´é“¾ç­–ç•¥ç”Ÿæˆè¾“å‡ºï¼Œéšåå°†è¿™äº›è¾“å‡ºç”¨äºå¾®è°ƒä¸€ä¸ª3Bè§„æ¨¡çš„å­¦ç”Ÿæ¨¡å‹VISTAã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé€šè¿‡ç»“æ„åŒ–çš„å¤šæ™ºèƒ½ä½“ç›‘ç£å®ç°çŸ¥è¯†è’¸é¦ï¼Œä½¿å¾—è½»é‡çº§æ¨¡å‹èƒ½å¤Ÿæ•æ‰å¤æ‚çš„æ¨ç†èƒ½åŠ›ï¼Œè¿™åœ¨ç°æœ‰æ–¹æ³•ä¸­æ˜¯è¾ƒä¸ºç½•è§çš„ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç”Ÿæˆçš„ä¼ªæ³¨é‡Šè´¨é‡ï¼Œå¹¶é€šè¿‡ç²¾å¿ƒé€‰æ‹©çš„å‚æ•°è®¾ç½®æ¥ç¡®ä¿æ¨¡å‹åœ¨ä½åˆ†è¾¨ç‡è§†é¢‘ä¸Šçš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVISTAåœ¨BLEU-4ã€METEORã€ROUGE-Lå’ŒCIDErç­‰å¤šä¸ªæ ‡å‡†è¯„ä¼°æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå°½ç®¡å…¶å‚æ•°æ•°é‡æ˜¾è‘—å‡å°‘ï¼Œä¾ç„¶èƒ½å¤Ÿä¸æ•™å¸ˆæ¨¡å‹ç›¸åª²ç¾ï¼Œå±•ç¤ºäº†çŸ¥è¯†è’¸é¦çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½äº¤é€šç³»ç»Ÿã€è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„å®æ—¶ç›‘æ§å’Œé£é™©è¯„ä¼°ã€‚VISTAæ¨¡å‹çš„ç´§å‡‘æ¶æ„ä½¿å…¶èƒ½å¤Ÿåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šé«˜æ•ˆéƒ¨ç½²ï¼Œæ¨åŠ¨äº¤é€šå®‰å…¨å’Œæ™ºèƒ½åŒ–çš„å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Comprehensive highway scene understanding and robust traffic risk inference are vital for advancing Intelligent Transportation Systems (ITS) and autonomous driving. Traditional approaches often struggle with scalability and generalization, particularly under the complex and dynamic conditions of real-world environments. To address these challenges, we introduce a novel structured prompting and knowledge distillation framework that enables automatic generation of high-quality traffic scene annotations and contextual risk assessments. Our framework orchestrates two large Vision-Language Models (VLMs): GPT-4o and o3-mini, using a structured Chain-of-Thought (CoT) strategy to produce rich, multi-perspective outputs. These outputs serve as knowledge-enriched pseudo-annotations for supervised fine-tuning of a much smaller student VLM. The resulting compact 3B-scale model, named VISTA (Vision for Intelligent Scene and Traffic Analysis), is capable of understanding low-resolution traffic videos and generating semantically faithful, risk-aware captions. Despite its significantly reduced parameter count, VISTA achieves strong performance across established captioning metrics (BLEU-4, METEOR, ROUGE-L, and CIDEr) when benchmarked against its teacher models. This demonstrates that effective knowledge distillation and structured multi-agent supervision can empower lightweight VLMs to capture complex reasoning capabilities. The compact architecture of VISTA facilitates efficient deployment on edge devices, enabling real-time risk monitoring without requiring extensive infrastructure upgrades.

