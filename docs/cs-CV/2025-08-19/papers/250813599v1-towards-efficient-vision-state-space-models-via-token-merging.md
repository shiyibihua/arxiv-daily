---
layout: default
title: Towards Efficient Vision State Space Models via Token Merging
---

# Towards Efficient Vision State Space Models via Token Merging

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13599" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13599v1</a>
  <a href="https://arxiv.org/pdf/2508.13599.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13599v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13599v1', 'Towards Efficient Vision State Space Models via Token Merging')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jinyoung Park, Minseok Son, Changick Kim

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19

**å¤‡æ³¨**: under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMaMeä»¥è§£å†³SSMæ¨¡å‹è®¡ç®—æ•ˆç‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `çŠ¶æ€ç©ºé—´æ¨¡å‹` `è®¡ç®—æ•ˆç‡` `ä»¤ç‰Œåˆå¹¶` `åºåˆ—å»ºæ¨¡` `è®¡ç®—æœºè§†è§‰` `å¤šæ¨¡æ€åº”ç”¨` `æ€§èƒ½ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„çŠ¶æ€ç©ºé—´æ¨¡å‹åœ¨è®¡ç®—æ•ˆç‡ä¸Šå­˜åœ¨ä¸è¶³ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯æ‰©å±•æ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„MaMeç­–ç•¥é€šè¿‡é‡åŒ–ä»¤ç‰Œé‡è¦æ€§å’Œä¿æŒåºåˆ—ä¿¡æ¯æµæ¥æå‡SSMæ¨¡å‹çš„æ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMaMeåœ¨å¤šä¸ªä»»åŠ¡ä¸­å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨æ¿€è¿›çš„ä»¤ç‰Œå‡å°‘æƒ…å†µä¸‹è¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†æé«˜å…¶è®¡ç®—æ•ˆç‡å¯¹äºå®é™…åº”ç”¨è‡³å…³é‡è¦ã€‚è™½ç„¶ä»¤ç‰Œå‡å°‘æ˜¯ä¸€ç§æœ‰æ•ˆçš„æ¨¡å‹æ•ˆç‡æå‡æ–¹æ³•ï¼Œä½†åœ¨SSMsä¸­åº”ç”¨æ—¶éœ€è°¨æ…è€ƒè™‘å…¶ç‹¬ç‰¹çš„åºåˆ—å»ºæ¨¡èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºäº†MaMeï¼Œä¸€ç§é’ˆå¯¹SSMè§†è§‰æ¨¡å‹çš„ä»¤ç‰Œåˆå¹¶ç­–ç•¥ï¼Œè§£å†³äº†é‡åŒ–ä»¤ç‰Œé‡è¦æ€§å’Œä¿æŒåºåˆ—å±æ€§çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„æ–¹æ¡ˆåˆ©ç”¨çŠ¶æ€è½¬ç§»å‚æ•°ä½œä¸ºä¿¡æ¯åº¦é‡ï¼Œå¹¶å¼•å…¥æˆ˜ç•¥æ€§ä»¤ç‰Œæ’åˆ—ä»¥ä¿æŒåºåˆ—ä¿¡æ¯æµã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMaMeåœ¨å¾®è°ƒå’Œç°æˆæ¨¡å‹ä¸­å‡å®ç°äº†ä¼˜è¶Šçš„æ•ˆç‡-æ€§èƒ½æƒè¡¡ï¼Œå°¤å…¶åœ¨æ¿€è¿›çš„ä»¤ç‰Œå‡å°‘ä¸‹ï¼Œä¿æŒäº†é²æ£’æ€§ï¼Œé¿å…äº†ç°æœ‰æ–¹æ³•çš„æ˜¾è‘—æ€§èƒ½ä¸‹é™ã€‚æ­¤å¤–ï¼ŒMaMeåœ¨è§†é¢‘å’ŒéŸ³é¢‘é¢†åŸŸä¹Ÿå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºå¤šç§SSMåº”ç”¨æå‡æ•ˆç‡æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰åœ¨è®¡ç®—æ•ˆç‡ä¸Šçš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•åœ¨ä»¤ç‰Œå‡å°‘æ—¶å¾€å¾€å¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMaMeç­–ç•¥é€šè¿‡é‡åŒ–ä»¤ç‰Œçš„é‡è¦æ€§ï¼Œå¹¶è®¾è®¡æˆ˜ç•¥æ€§ä»¤ç‰Œæ’åˆ—ï¼Œä»¥ä¿æŒåºåˆ—ä¿¡æ¯æµï¼Œä»è€Œæå‡æ¨¡å‹çš„è®¡ç®—æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMaMeçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯ä»¤ç‰Œé‡è¦æ€§é‡åŒ–æ¨¡å—ï¼Œåˆ©ç”¨çŠ¶æ€è½¬ç§»å‚æ•°ä½œä¸ºä¿¡æ¯åº¦é‡ï¼›å…¶æ¬¡æ˜¯ä»¤ç‰Œåˆå¹¶æ¨¡å—ï¼Œé€šè¿‡ä¼˜åŒ–æ’åˆ—æ¥ä¿æŒåºåˆ—ç‰¹æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šMaMeçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶ç‹¬ç‰¹çš„ä»¤ç‰Œåˆå¹¶ç­–ç•¥ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒåºåˆ—ä¿¡æ¯çš„åŒæ—¶æœ‰æ•ˆå‡å°‘ä»¤ç‰Œæ•°é‡ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ•ˆç‡å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒçŠ¶æ€è½¬ç§»å‚æ•°è¢«ç”¨ä½œä¿¡æ¯åº¦é‡ï¼Œä»¤ç‰Œçš„æ’åˆ—ç­–ç•¥ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿ä¿¡æ¯æµçš„è¿ç»­æ€§å’Œå®Œæ•´æ€§ã€‚æ­¤å¤–ï¼Œæ¨¡å‹çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ä¹Ÿç»è¿‡è°ƒæ•´ï¼Œä»¥é€‚åº”æ–°çš„ä»¤ç‰Œåˆå¹¶ç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMaMeåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºç°æœ‰çš„ä»¤ç‰Œå‡å°‘æ–¹æ³•ï¼Œå°¤å…¶åœ¨æ¿€è¿›çš„ä»¤ç‰Œå‡å°‘æƒ…å†µä¸‹ï¼Œæ€§èƒ½ä¸‹é™å¹…åº¦å°äº20%ï¼Œè€Œå…¶ä»–æ–¹æ³•åˆ™å¯èƒ½è¾¾åˆ°50%ä»¥ä¸Šçš„æ€§èƒ½æŸå¤±ã€‚è¿™è¡¨æ˜MaMeåœ¨æ•ˆç‡å’Œæ€§èƒ½ä¹‹é—´å®ç°äº†æ›´å¥½çš„å¹³è¡¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ä¸­çš„å›¾åƒåˆ†ç±»ã€è§†é¢‘åˆ†æå’ŒéŸ³é¢‘å¤„ç†ç­‰ã€‚é€šè¿‡æå‡çŠ¶æ€ç©ºé—´æ¨¡å‹çš„è®¡ç®—æ•ˆç‡ï¼ŒMaMeå¯ä»¥åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„æ¨¡å‹éƒ¨ç½²ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> State Space Models (SSMs) have emerged as powerful architectures in computer vision, yet improving their computational efficiency remains crucial for practical and scalable deployment.While token reduction serves as an effective approach for model efficiency, applying it to SSMs requires careful consideration of their unique sequential modeling capabilities.In this work, we propose MaMe, a token-merging strategy tailored for SSM-based vision models.MaMe addresses two key challenges: quantifying token importance and preserving sequential properties. Our approach leverages the state transition parameter $\mathbfÎ”$ as an informativeness measure and introduces strategic token arrangements to preserve sequential information flow.Extensive experiments demonstrate that MaMe achieves superior efficiency-performance trade-offs for both fine-tuned and off-the-shelf models. Particularly, our approach maintains robustness even under aggressive token reduction where existing methods undergo significant performance degradation.Beyond image classification, MaMe shows strong generalization capabilities across video and audio domains, establishing an effective approach for enhancing efficiency in diverse SSM applications.

