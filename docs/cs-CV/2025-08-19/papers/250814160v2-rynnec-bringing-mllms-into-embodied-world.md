---
layout: default
title: RynnEC: Bringing MLLMs into Embodied World
---

# RynnEC: Bringing MLLMs into Embodied World

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14160" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14160v2</a>
  <a href="https://arxiv.org/pdf/2508.14160.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14160v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14160v2', 'RynnEC: Bringing MLLMs into Embodied World')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ronghao Dang, Yuqian Yuan, Yunxuan Mao, Kehan Li, Jiangpin Liu, Zhikai Wang, Xin Li, Fan Wang, Deli Zhao

**åˆ†ç±»**: cs.CV, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19 (æ›´æ–°: 2025-11-18)

**å¤‡æ³¨**: The technical report of RynnEC, an embodied cognition MLLM

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/alibaba-damo-academy/RynnEC)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRynnECä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å…·èº«è®¤çŸ¥ä¸­çš„åº”ç”¨é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å…·èº«è®¤çŸ¥` `è§†é¢‘ç†è§£` `åŒºåŸŸç¼–ç å™¨` `æ©ç è§£ç å™¨` `ç‰©ä½“åˆ†å‰²` `ç©ºé—´æ¨ç†` `åŸºå‡†è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å…·èº«è®¤çŸ¥ä»»åŠ¡ä¸­ç¼ºä¹æœ‰æ•ˆçš„å¤šæ¨¡æ€è§†é¢‘ç†è§£èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨ç‰©ä½“å±æ€§ç†è§£å’Œç©ºé—´æ¨ç†æ–¹é¢ã€‚
2. RynnECé€šè¿‡å¼•å…¥åŒºåŸŸç¼–ç å™¨å’Œæ©ç è§£ç å™¨ï¼Œæ„å»ºäº†ä¸€ä¸ªåŒºåŸŸä¸­å¿ƒçš„è§†é¢‘äº¤äº’æ¨¡å‹ï¼Œæå‡äº†å¯¹ç‰©ç†ä¸–ç•Œçš„æ„ŸçŸ¥èƒ½åŠ›ã€‚
3. RynnECåœ¨ç‰©ä½“å±æ€§ç†è§£ã€ç‰©ä½“åˆ†å‰²å’Œç©ºé—´æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†å…·èº«è®¤çŸ¥çš„æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†RynnECï¼Œä¸€ç§ä¸ºå…·èº«è®¤çŸ¥è®¾è®¡çš„è§†é¢‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ã€‚RynnECåŸºäºé€šç”¨çš„è§†è§‰-è¯­è¨€åŸºç¡€æ¨¡å‹ï¼Œç»“åˆåŒºåŸŸç¼–ç å™¨å’Œæ©ç è§£ç å™¨ï¼Œå®ç°çµæ´»çš„åŒºåŸŸçº§è§†é¢‘äº¤äº’ã€‚å°½ç®¡å…¶æ¶æ„ç´§å‡‘ï¼ŒRynnECåœ¨ç‰©ä½“å±æ€§ç†è§£ã€ç‰©ä½“åˆ†å‰²å’Œç©ºé—´æ¨ç†æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¯¥æ¨¡å‹ä¸ºå…·èº«ä»£ç†çš„â€œå¤§è„‘â€æä¾›äº†åŒºåŸŸä¸­å¿ƒçš„è§†é¢‘èŒƒå¼ï¼Œèƒ½å¤Ÿæ›´ç²¾ç»†åœ°æ„ŸçŸ¥ç‰©ç†ä¸–ç•Œå¹¶å®ç°æ›´ç²¾å‡†çš„äº¤äº’ã€‚ä¸ºç¼“è§£æ ‡æ³¨3Dæ•°æ®é›†çš„ç¨€ç¼ºæ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè‡ªæˆ‘ä¸­å¿ƒè§†é¢‘çš„æ•°æ®ç”Ÿæˆç®¡é“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¨å‡ºäº†RynnEC-Benchï¼Œä¸€ä¸ªç”¨äºè¯„ä¼°å…·èº«è®¤çŸ¥èƒ½åŠ›çš„åŒºåŸŸä¸­å¿ƒåŸºå‡†ã€‚æˆ‘ä»¬æœŸå¾…RynnECèƒ½æ¨åŠ¨å…·èº«ä»£ç†é€šç”¨è®¤çŸ¥æ ¸å¿ƒçš„å‘å±•ï¼Œå¹¶ä¿ƒè¿›åœ¨å¤šæ ·åŒ–å…·èº«ä»»åŠ¡ä¸­çš„æ³›åŒ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å…·èº«è®¤çŸ¥ä¸­çš„åº”ç”¨é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨ç‰©ä½“å±æ€§ç†è§£å’Œç©ºé—´æ¨ç†ç­‰ä»»åŠ¡ä¸­çš„ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆå¤„ç†è§†é¢‘æ•°æ®çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ï¼Œå¯¼è‡´æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRynnECçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥åŒºåŸŸç¼–ç å™¨å’Œæ©ç è§£ç å™¨ï¼Œæ„å»ºä¸€ä¸ªåŒºåŸŸä¸­å¿ƒçš„è§†é¢‘äº¤äº’æ¨¡å‹ï¼Œä»è€Œå®ç°å¯¹ç‰©ç†ä¸–ç•Œçš„ç»†è‡´æ„ŸçŸ¥å’Œæ›´ç²¾å‡†çš„äº¤äº’ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨åŒºåŸŸçº§åˆ«ä¸Šè¿›è¡Œçµæ´»çš„æ“ä½œå’Œç†è§£ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRynnECçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªé€šç”¨çš„è§†è§‰-è¯­è¨€åŸºç¡€æ¨¡å‹ï¼Œç»“åˆåŒºåŸŸç¼–ç å™¨å’Œæ©ç è§£ç å™¨ã€‚è¯¥æ¨¡å‹é¦–å…ˆå¯¹è¾“å…¥è§†é¢‘è¿›è¡ŒåŒºåŸŸç¼–ç ï¼Œç„¶åé€šè¿‡æ©ç è§£ç å™¨å®ç°å¯¹ç‰¹å®šåŒºåŸŸçš„ç†è§£å’Œäº¤äº’ã€‚

**å…³é”®åˆ›æ–°**ï¼šRynnECçš„æœ€é‡è¦åˆ›æ–°åœ¨äºå…¶åŒºåŸŸä¸­å¿ƒçš„è§†é¢‘èŒƒå¼ï¼Œè¿™ä¸€è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å…·èº«è®¤çŸ¥ä»»åŠ¡ä¸­å®ç°æ›´é«˜çš„ç²¾åº¦å’Œçµæ´»æ€§ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†å¯¹ç‰©ä½“å’Œç©ºé—´å…³ç³»çš„ç†è§£èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼ŒRynnECé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–åŒºåŸŸç†è§£çš„å‡†ç¡®æ€§ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ç²¾ç»†è°ƒæ•´ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å¤„ç†ä¸åŒç±»å‹è§†é¢‘æ—¶çš„é²æ£’æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

RynnECåœ¨ç‰©ä½“å±æ€§ç†è§£ã€ç‰©ä½“åˆ†å‰²å’Œç©ºé—´æ¨ç†ä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ç›¸è¾ƒäºç°æœ‰æ–¹æ³•æå‡äº†çº¦15%-20%çš„å‡†ç¡®ç‡ã€‚è¿™ä¸€æˆæœå±•ç¤ºäº†å…¶åœ¨å…·èº«è®¤çŸ¥é¢†åŸŸçš„å¼ºå¤§èƒ½åŠ›å’Œåº”ç”¨å‰æ™¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RynnECåœ¨å…·èº«è®¤çŸ¥é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ç­‰åœºæ™¯ä¸­ã€‚é€šè¿‡æå‡å¯¹ç‰©ç†ä¸–ç•Œçš„ç†è§£èƒ½åŠ›ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿä¸ºæ™ºèƒ½ä»£ç†æä¾›æ›´ç²¾å‡†çš„å†³ç­–æ”¯æŒï¼Œæ¨åŠ¨äººæœºäº¤äº’çš„è¿›æ­¥ã€‚æ­¤å¤–ï¼ŒRynnECçš„åŒºåŸŸä¸­å¿ƒåŸºå‡†ä¹Ÿä¸ºåç»­ç ”ç©¶æä¾›äº†é‡è¦çš„è¯„ä¼°å·¥å…·ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce RynnEC, a video multimodal large language model designed for embodied cognition. Built upon a general-purpose vision-language foundation model, RynnEC incorporates a region encoder and a mask decoder, enabling flexible region-level video interaction. Despite its compact architecture, RynnEC achieves state-of-the-art performance in object property understanding, object segmentation, and spatial reasoning. Conceptually, it offers a region-centric video paradigm for the brain of embodied agents, providing fine-grained perception of the physical world and enabling more precise interactions. To mitigate the scarcity of annotated 3D datasets, we propose an egocentric video based pipeline for generating embodied cognition data. Furthermore, we introduce RynnEC-Bench, a region-centered benchmark for evaluating embodied cognitive capabilities. We anticipate that RynnEC will advance the development of general-purpose cognitive cores for embodied agents and facilitate generalization across diverse embodied tasks. The code, model checkpoints, and benchmark are available at: https://github.com/alibaba-damo-academy/RynnEC

