---
layout: default
title: Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency
---

# Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13518" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13518v1</a>
  <a href="https://arxiv.org/pdf/2508.13518.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13518v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13518v1', 'Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yanbiao Ma, Wei Dai, Bowei Liu, Jiayi Chen, Wenke Huang, Guancheng Wan, Zhiwu Lu, Junchi Yan

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19

**å¤‡æ³¨**: 15 pages, CVPR Oral

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå‡ ä½•çŸ¥è¯†å¼•å¯¼çš„åˆ†å¸ƒæ ¡å‡†æ–¹æ³•ä»¥è§£å†³æ ·æœ¬åå·®é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å‡ ä½•çŸ¥è¯†` `åˆ†å¸ƒæ ¡å‡†` `è”é‚¦å­¦ä¹ ` `é•¿å°¾è¯†åˆ«` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é¢ä¸´çš„æ ¸å¿ƒé—®é¢˜æ˜¯è§‚å¯Ÿåˆ°çš„è®­ç»ƒæ ·æœ¬ä¸çœŸå®åˆ†å¸ƒä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®è·ï¼Œä¸»è¦ç”±äºé‡‡æ ·åå·®å’Œå™ªå£°ç­‰å› ç´ é€ æˆã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§å‡ ä½•çŸ¥è¯†å¼•å¯¼çš„åˆ†å¸ƒæ ¡å‡†æ¡†æ¶ï¼Œé€šè¿‡åˆ©ç”¨åŸºç¡€æ¨¡å‹æå–çš„ç‰¹å¾å‡ ä½•å½¢çŠ¶ï¼Œæ¥å¼¥è¡¥å±€éƒ¨å’Œå…¨å±€è§‚å¯Ÿä¹‹é—´çš„å·®è·ã€‚
3. ç»¼åˆå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è”é‚¦å­¦ä¹ å’Œé•¿å°¾è¯†åˆ«ä»»åŠ¡ä¸­æœ‰æ•ˆæå‡äº†æ€§èƒ½ï¼Œå…‹æœäº†æ•°æ®å¼‚è´¨æ€§å’Œæ ·æœ¬ä¸å¹³è¡¡å¸¦æ¥çš„æŒ‘æˆ˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡æ·±åº¦å­¦ä¹ å–å¾—äº†å¿«é€Ÿè¿›å±•ï¼Œä½†è§‚å¯Ÿåˆ°çš„è®­ç»ƒæ ·æœ¬ä¸çœŸå®åˆ†å¸ƒä¹‹é—´çš„å·®è·ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚é€ æˆè¿™ä¸€å·®è·çš„åŸå› åŒ…æ‹¬é‡‡æ ·åå·®å’Œå™ªå£°ç­‰ã€‚åœ¨åŸºç¡€æ¨¡å‹æ—¶ä»£ï¼Œæœ¬æ–‡å±•ç¤ºäº†åˆ©ç”¨ç°æˆçš„è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆå¦‚CLIPã€DINOv2ï¼‰è¿›è¡Œç‰¹å¾æå–æ—¶ï¼Œç‰¹å¾åˆ†å¸ƒçš„å‡ ä½•å½¢çŠ¶åœ¨ä¸åŒé¢†åŸŸå’Œæ•°æ®é›†ä¹‹é—´å…·æœ‰æ˜¾è‘—çš„å¯è½¬ç§»æ€§ã€‚ä¸ºéªŒè¯å…¶å®ç”¨æ€§ï¼Œæœ¬æ–‡å°†å‡ ä½•çŸ¥è¯†å¼•å¯¼çš„åˆ†å¸ƒæ ¡å‡†æ¡†æ¶åº”ç”¨äºè”é‚¦å­¦ä¹ å’Œé•¿å°¾è¯†åˆ«ä¸¤ä¸ªæµè¡Œä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•æœ‰æ•ˆå…‹æœäº†æ•°æ®å¼‚è´¨æ€§å’Œæ ·æœ¬ä¸å¹³è¡¡å¸¦æ¥çš„ä¿¡æ¯ä¸è¶³ï¼Œåœ¨å„åŸºå‡†æµ‹è¯•ä¸­æ€§èƒ½å¾—åˆ°äº†æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§‚å¯Ÿåˆ°çš„è®­ç»ƒæ ·æœ¬ä¸çœŸå®åˆ†å¸ƒä¹‹é—´çš„å·®è·é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ ·æœ¬åå·®å’Œæ•°æ®å¼‚è´¨æ€§æ—¶æ•ˆæœä¸ä½³ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å‡ ä½•çŸ¥è¯†æ¥å¼•å¯¼åˆ†å¸ƒæ ¡å‡†ï¼Œé€šè¿‡æå–åŸºç¡€æ¨¡å‹çš„ç‰¹å¾å‡ ä½•å½¢çŠ¶ï¼Œæ¥ç”Ÿæˆæ–°çš„æ ·æœ¬ï¼Œä»è€Œå¼¥è¡¥å±€éƒ¨å’Œå…¨å±€è§‚å¯Ÿä¹‹é—´çš„å·®è·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç‰¹å¾æå–ã€å‡ ä½•å½¢çŠ¶è·å–å’Œæ ·æœ¬ç”Ÿæˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚åœ¨è”é‚¦å­¦ä¹ ä¸­ï¼Œé¦–å…ˆåœ¨éšç§çº¦æŸä¸‹è·å–å…¨å±€å‡ ä½•å½¢çŠ¶ï¼Œç„¶ååˆ©ç”¨è¯¥çŸ¥è¯†ä¸ºå®¢æˆ·ç«¯ç”Ÿæˆæ–°æ ·æœ¬ï¼›åœ¨é•¿å°¾å­¦ä¹ ä¸­ï¼Œä»æ ·æœ¬ä¸°å¯Œçš„ç±»åˆ«ä¸­è½¬ç§»å‡ ä½•çŸ¥è¯†ï¼Œä»¥æ¢å¤æ ·æœ¬ç¨€ç¼ºçš„å°¾éƒ¨ç±»åˆ«çš„çœŸå®åˆ†å¸ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†å‡ ä½•çŸ¥è¯†å¼•å¯¼çš„åˆ†å¸ƒæ ¡å‡†æ¡†æ¶ï¼Œåˆ©ç”¨åŸºç¡€æ¨¡å‹çš„ç‰¹å¾å‡ ä½•å½¢çŠ¶è¿›è¡Œè·¨åŸŸè½¬ç§»ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†æ ·æœ¬ç¨€ç¼ºç±»åˆ«çš„è¯†åˆ«èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ä»¥å¹³è¡¡ä¸åŒç±»åˆ«çš„æ ·æœ¬å½±å“ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†å‡ ä½•å½¢çŠ¶çš„çº¦æŸï¼Œä»¥ç¡®ä¿ç”Ÿæˆæ ·æœ¬çš„å¤šæ ·æ€§å’ŒçœŸå®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„å‡ ä½•çŸ¥è¯†å¼•å¯¼çš„åˆ†å¸ƒæ ¡å‡†æ–¹æ³•åœ¨è”é‚¦å­¦ä¹ å’Œé•¿å°¾è¯†åˆ«ä»»åŠ¡ä¸­å‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚åœ¨é•¿å°¾è¯†åˆ«ä¸­ï¼Œæ¨¡å‹åœ¨å°¾éƒ¨ç±»åˆ«çš„è¯†åˆ«å‡†ç¡®ç‡æå‡äº†15%ï¼Œåœ¨è”é‚¦å­¦ä¹ ä¸­ï¼Œæ¨¡å‹çš„å…¨å±€æ€§èƒ½æå‡äº†10%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è”é‚¦å­¦ä¹ å’Œé•¿å°¾è¯†åˆ«ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹åœ¨æ•°æ®ä¸å¹³è¡¡å’Œæ ·æœ¬ç¨€ç¼ºæƒ…å†µä¸‹çš„æ€§èƒ½ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¤šå®é™…åº”ç”¨ä¸­æ¨å¹¿ï¼Œå¸®åŠ©è§£å†³æ•°æ®åˆ†å¸ƒä¸å‡çš„é—®é¢˜ï¼Œæå‡æ™ºèƒ½ç³»ç»Ÿçš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite the fast progress of deep learning, one standing challenge is the gap of the observed training samples and the underlying true distribution. There are multiple reasons for the causing of this gap e.g. sampling bias, noise etc. In the era of foundation models, we show that when leveraging the off-the-shelf (vision) foundation models (e.g., CLIP, DINOv2) for feature extraction, the geometric shapes of the resulting feature distributions exhibit remarkable transferability across domains and datasets. To verify its practical usefulness, we embody our geometric knowledge-guided distribution calibration framework in two popular and challenging settings: federated learning and long-tailed recognition. In the federated setting, we devise a technique of acquiring the global geometric shape under privacy constraints, then leverage this knowledge to generate new samples for clients, in the aim of bridging the gap between local and global observations. In long-tailed learning, it utilizes the geometric knowledge transferred from sample-rich categories to recover the true distribution for sample-scarce tail classes. Comprehensive experiments show that our proposed geometric knowledge-guided distribution calibration effectively overcomes information deficits caused by data heterogeneity and sample imbalance, with boosted performance across benchmarks.

