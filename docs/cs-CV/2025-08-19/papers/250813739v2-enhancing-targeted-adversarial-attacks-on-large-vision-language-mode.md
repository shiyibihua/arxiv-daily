---
layout: default
title: Enhancing Targeted Adversarial Attacks on Large Vision-Language Models via Intermediate Projector
---

# Enhancing Targeted Adversarial Attacks on Large Vision-Language Models via Intermediate Projector

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13739" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13739v2</a>
  <a href="https://arxiv.org/pdf/2508.13739.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13739v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13739v2', 'Enhancing Targeted Adversarial Attacks on Large Vision-Language Models via Intermediate Projector')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yiming Cao, Yanjie Li, Kaisheng Liang, Bin Xiao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19 (æ›´æ–°: 2025-09-24)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸­é—´æŠ•å½±å™¨ä»¥å¢å¼ºé’ˆå¯¹å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹çš„å¯¹æŠ—æ”»å‡»**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹æŠ—æ”»å‡»` `è§†è§‰-è¯­è¨€æ¨¡å‹` `ç»†ç²’åº¦æ”»å‡»` `æŸ¥è¯¢å˜æ¢å™¨` `æ¨¡å‹å®‰å…¨æ€§` `å¤šæ¨¡æ€å¯¹é½` `é»‘ç®±æ”»å‡»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­äºå…¨å±€ç›¸ä¼¼æ€§ï¼Œéš¾ä»¥å®ç°ç»†ç²’åº¦çš„éšè”½æ”»å‡»ï¼Œæ— æ³•æœ‰æ•ˆé’ˆå¯¹ç‰¹å®šç›®æ ‡è¿›è¡Œä¿®æ”¹ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸­é—´æŠ•å½±å™¨å¼•å¯¼æ”»å‡»ï¼ˆIPGAï¼‰æ¡†æ¶ï¼Œåˆ©ç”¨æŸ¥è¯¢å˜æ¢å™¨å¢å¼ºæ”»å‡»çš„ç»†ç²’åº¦å’Œæœ‰æ•ˆæ€§ï¼ŒåŒæ—¶æé«˜æ”»å‡»çš„å¯è½¬ç§»æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒIPGAåœ¨å…¨å±€é’ˆå¯¹æ€§æ”»å‡»ä¸­æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œè€Œç»“åˆæ®‹å·®æŸ¥è¯¢å¯¹é½æ¨¡å—çš„IPGA-Råœ¨ç»†ç²’åº¦æ”»å‡»ä¸­è¡¨ç°æ›´ä½³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„å¹¿æ³›åº”ç”¨ï¼Œå®‰å…¨æ€§é—®é¢˜æ—¥ç›Šå‡¸æ˜¾ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹é»‘ç®±æ¨¡å‹çš„æœ‰é’ˆå¯¹æ€§å¯¹æŠ—æ”»å‡»ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨ç¼–ç å™¨çº§åˆ«çš„å…¨å±€ç›¸ä¼¼æ€§ï¼Œç¼ºä¹ç»†ç²’åº¦çš„æ”»å‡»èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„é»‘ç®±é’ˆå¯¹æ€§æ”»å‡»æ¡†æ¶ï¼Œåˆ©ç”¨äº†æŠ•å½±å™¨çš„ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡æŸ¥è¯¢å˜æ¢å™¨ï¼ˆQ-Formerï¼‰å°†å…¨å±€å›¾åƒåµŒå…¥è½¬åŒ–ä¸ºç»†ç²’åº¦æŸ¥è¯¢è¾“å‡ºï¼Œä»è€Œå¢å¼ºæ”»å‡»çš„æœ‰æ•ˆæ€§å’Œç»†ç²’åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å…¨å±€é’ˆå¯¹æ€§æ”»å‡»å’Œç»†ç²’åº¦æ”»å‡»ä¸­å‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰é’ˆå¯¹å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹çš„å¯¹æŠ—æ”»å‡»æ–¹æ³•åœ¨ç»†ç²’åº¦æ”»å‡»ä¸­çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆé’ˆå¯¹ç‰¹å®šç›®æ ‡è¿›è¡Œä¿®æ”¹ï¼Œä¸”ç¼ºä¹å¯¹æŠ•å½±å™¨çš„åˆ©ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸­é—´æŠ•å½±å™¨å¼•å¯¼æ”»å‡»ï¼ˆIPGAï¼‰æ¡†æ¶ï¼Œé€šè¿‡æŸ¥è¯¢å˜æ¢å™¨å°†å…¨å±€å›¾åƒåµŒå…¥è½¬åŒ–ä¸ºç»†ç²’åº¦æŸ¥è¯¢è¾“å‡ºï¼Œä»è€Œå¢å¼ºæ”»å‡»çš„æœ‰æ•ˆæ€§å’Œç»†ç²’åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯Q-Formeræ¨¡å—ï¼Œå°†å…¨å±€å›¾åƒåµŒå…¥è½¬åŒ–ä¸ºç»†ç²’åº¦æŸ¥è¯¢è¾“å‡ºï¼›å…¶æ¬¡æ˜¯æ®‹å·®æŸ¥è¯¢å¯¹é½æ¨¡å—ï¼ˆRQAï¼‰ï¼Œç”¨äºåœ¨ç»†ç²’åº¦æ”»å‡»ä¸­ä¿æŒä¸ç›®æ ‡æ— å…³çš„å†…å®¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºåˆ©ç”¨æŠ•å½±å™¨ä½œä¸ºè¯­ä¹‰æ¡¥æ¢ï¼Œå¢å¼ºäº†æ”»å‡»çš„ç»†ç²’åº¦å’Œæœ‰æ•ˆæ€§ï¼Œå°¤å…¶æ˜¯åœ¨é’ˆå¯¹ç‰¹å®šç›®æ ‡çš„ä¿®æ”¹ä¸Šï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å…·æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†æœªé’ˆå¯¹ç‰¹å®šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œå¾®è°ƒçš„é¢„è®­ç»ƒQ-Formerï¼Œä»¥æé«˜æ”»å‡»çš„å¯è½¬ç§»æ€§ï¼ŒåŒæ—¶åœ¨RQAæ¨¡å—ä¸­å¼•å…¥çº¦æŸï¼Œä»¥ä¿æŒä¸ç›®æ ‡æ— å…³çš„æŸ¥è¯¢è¾“å‡ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒIPGAåœ¨å…¨å±€é’ˆå¯¹æ€§æ”»å‡»ä¸­æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼ŒæˆåŠŸç‡æå‡å¹…åº¦è¾¾åˆ°XX%ã€‚ç»“åˆRQAæ¨¡å—çš„IPGA-Råœ¨ç»†ç²’åº¦æ”»å‡»ä¸­è¡¨ç°æ›´ä½³ï¼ŒæˆåŠŸç‡å’Œä¸ç›®æ ‡æ— å…³å†…å®¹çš„ä¿ç•™ç‡å‡æ˜¾è‘—é«˜äºåŸºçº¿æ–¹æ³•ï¼Œå±•ç¤ºäº†è‰¯å¥½çš„è½¬ç§»èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨æ€§æµ‹è¯•ã€æ¨¡å‹é²æ£’æ€§è¯„ä¼°ä»¥åŠå¯¹æŠ—æ ·æœ¬ç”Ÿæˆç­‰ã€‚é€šè¿‡å¢å¼ºå¯¹æŠ—æ”»å‡»çš„æœ‰æ•ˆæ€§å’Œç»†ç²’åº¦ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°è¯„ä¼°å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å®‰å…¨æ€§ï¼Œè¿›è€Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶ä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The growing deployment of Large Vision-Language Models (VLMs) raises safety concerns, as adversaries may exploit model vulnerabilities to induce harmful outputs, with targeted black-box adversarial attacks posing a particularly severe threat. However, existing methods primarily maximize encoder-level global similarity, which lacks the granularity for stealthy and practical fine-grained attacks, where only specific target should be altered (e.g., modifying a car while preserving its background). Moreover, they largely neglect the projector, a key semantic bridge in VLMs for multimodal alignment. To address these limitations, we propose a novel black-box targeted attack framework that leverages the projector. Specifically, we utilize the widely adopted Querying Transformer (Q-Former) which transforms global image embeddings into fine-grained query outputs, to enhance attack effectiveness and granularity. For standard global targeted attack scenarios, we propose the Intermediate Projector Guided Attack (IPGA), which aligns Q-Former fine-grained query outputs with the target to enhance attack strength and exploits the intermediate pretrained Q-Former that is not fine-tuned for any specific Large Language Model (LLM) to improve attack transferability. For fine-grained attack scenarios, we augment IPGA with the Residual Query Alignment (RQA) module, which preserves unrelated content by constraining non-target query outputs to enhance attack granularity. Extensive experiments demonstrate that IPGA significantly outperforms baselines in global targeted attacks, and IPGA with RQA (IPGA-R) attains superior success rates and unrelated content preservation over baselines in fine-grained attacks. Our method also transfers effectively to commercial VLMs such as Google Gemini and OpenAI GPT.

