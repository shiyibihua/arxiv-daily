---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CV - 2025-07-01
---

# cs.CVï¼ˆ2025-07-01ï¼‰

ğŸ“Š å…± **5** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (3)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250700363v1-gdgs-3d-gaussian-splatting-via-geometry-guided-initialization-and-dy.html">GDGS: 3D Gaussian Splatting Via Geometry-Guided Initialization And Dynamic Density Control</a></td>
  <td>æå‡ºå‡ ä½•å¼•å¯¼åˆå§‹åŒ–ä¸åŠ¨æ€å¯†åº¦æ§åˆ¶ä»¥è§£å†³3Dé«˜æ–¯ç‚¹äº‘æ¸²æŸ“é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">3DGS</span> <span class="paper-tag">gaussian splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2507.00363v1" data-paper-url="./papers/250700363v1-gdgs-3d-gaussian-splatting-via-geometry-guided-initialization-and-dy.html" onclick="toggleFavorite(this, '2507.00363v1', 'GDGS: 3D Gaussian Splatting Via Geometry-Guided Initialization And Dynamic Density Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250700334v1-populate-a-scene-affordance-aware-human-video-generation.html">Populate-A-Scene: Affordance-Aware Human Video Generation</a></td>
  <td>æå‡ºåŸºäºåœºæ™¯å›¾åƒçš„äººç±»è§†é¢‘ç”Ÿæˆæ¨¡å‹ä»¥è§£å†³äº¤äº’æ¨¡æ‹Ÿé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">affordance</span> <span class="paper-tag">affordance-aware</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2507.00334v1" data-paper-url="./papers/250700334v1-populate-a-scene-affordance-aware-human-video-generation.html" onclick="toggleFavorite(this, '2507.00334v1', 'Populate-A-Scene: Affordance-Aware Human Video Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250700371v3-plantsegnerf-a-few-shot-cross-species-method-for-plant-3d-instance-p.html">PlantSegNeRF: A few-shot, cross-species method for plant 3D instance point cloud reconstruction via joint-channel NeRF with multi-view image instance matching</a></td>
  <td>æå‡ºPlantSegNeRFä»¥è§£å†³æ¤ç‰©ç‚¹äº‘å®ä¾‹åˆ†å‰²ç²¾åº¦ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">NeRF</span> <span class="paper-tag">neural radiance field</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2507.00371v3" data-paper-url="./papers/250700371v3-plantsegnerf-a-few-shot-cross-species-method-for-plant-3d-instance-p.html" onclick="toggleFavorite(this, '2507.00371v3', 'PlantSegNeRF: A few-shot, cross-species method for plant 3D instance point cloud reconstruction via joint-channel NeRF with multi-view image instance matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>4</td>
  <td><a href="./papers/250700356v1-cgeartheyea-high-resolution-remote-sensing-vision-foundation-model-b.html">CGEarthEye:A High-Resolution Remote Sensing Vision Foundation Model Based on the Jilin-1 Satellite Constellation</a></td>
  <td>æå‡ºCGEarthEyeä»¥è§£å†³é«˜åˆ†è¾¨ç‡é¥æ„Ÿå›¾åƒè§£è¯»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">spatiotemporal</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2507.00356v1" data-paper-url="./papers/250700356v1-cgeartheyea-high-resolution-remote-sensing-vision-foundation-model-b.html" onclick="toggleFavorite(this, '2507.00356v1', 'CGEarthEye:A High-Resolution Remote Sensing Vision Foundation Model Based on the Jilin-1 Satellite Constellation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>5</td>
  <td><a href="./papers/250700392v2-learning-dense-feature-matching-via-lifting-single-2d-image-to-3d-sp.html">Learning Dense Feature Matching via Lifting Single 2D Image to 3D Space</a></td>
  <td>æå‡ºL2Mæ¡†æ¶ä»¥è§£å†³å•è§†å›¾å›¾åƒç‰¹å¾åŒ¹é…é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">feature matching</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2507.00392v2" data-paper-url="./papers/250700392v2-learning-dense-feature-matching-via-lifting-single-2d-image-to-3d-sp.html" onclick="toggleFavorite(this, '2507.00392v2', 'Learning Dense Feature Matching via Lifting Single 2D Image to 3D Space')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CV é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)