---
layout: default
title: Learning Dense Feature Matching via Lifting Single 2D Image to 3D Space
---

# Learning Dense Feature Matching via Lifting Single 2D Image to 3D Space

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.00392" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.00392v2</a>
  <a href="https://arxiv.org/pdf/2507.00392.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.00392v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.00392v2', 'Learning Dense Feature Matching via Lifting Single 2D Image to 3D Space')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yingping Liang, Yutao Hu, Wenqi Shao, Ying Fu

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-07-01 (æ›´æ–°: 2025-07-05)

**å¤‡æ³¨**: Official Code: https://github.com/Sharpiless/L2M

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºL2Mæ¡†æ¶ä»¥è§£å†³å•è§†å›¾å›¾åƒç‰¹å¾åŒ¹é…é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `ç‰¹å¾åŒ¹é…` `è®¡ç®—æœºè§†è§‰` `3Dæ„ŸçŸ¥` `å•è§†å›¾å›¾åƒ` `å¤šè§†å›¾åˆæˆ` `æ·±åº¦å­¦ä¹ ` `é²æ£’æ€§` `æ³›åŒ–èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç‰¹å¾åŒ¹é…æ–¹æ³•ä¾èµ–äºç¨€ç¼ºçš„å¤šè§†å›¾å›¾åƒï¼Œé™åˆ¶äº†å…¶åœ¨å¤æ‚åœºæ™¯ä¸­çš„åº”ç”¨ã€‚
2. æå‡ºçš„L2Mæ¡†æ¶é€šè¿‡å°†2Då›¾åƒæå‡è‡³3Dç©ºé—´ï¼Œåˆ©ç”¨å•è§†å›¾å›¾åƒè¿›è¡Œç‰¹å¾åŒ¹é…ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒL2Måœ¨é›¶æ ·æœ¬è¯„ä¼°åŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå±•ç¤ºäº†å…¶è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç‰¹å¾åŒ¹é…åœ¨è®¸å¤šè®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­èµ·ç€åŸºç¡€æ€§ä½œç”¨ï¼Œä½†ç°æœ‰æ–¹æ³•ä¾èµ–äºç¨€ç¼ºä¸”å¹²å‡€çš„å¤šè§†å›¾å›¾åƒé›†åˆï¼Œé™åˆ¶äº†å…¶åœ¨å¤šæ ·åŒ–å’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œä¼ ç»Ÿç‰¹å¾ç¼–ç å™¨é€šå¸¸åœ¨å•è§†å›¾2Då›¾åƒä¸Šè®­ç»ƒï¼Œé™åˆ¶äº†å…¶æ•æ‰3Dæ„ŸçŸ¥å¯¹åº”å…³ç³»çš„èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œå°†2Då›¾åƒæå‡è‡³3Dç©ºé—´ï¼Œç§°ä¸ºLift to Match (L2M)ï¼Œå……åˆ†åˆ©ç”¨å¤§è§„æ¨¡å’Œå¤šæ ·åŒ–çš„å•è§†å›¾å›¾åƒã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬é€šè¿‡å¤šè§†å›¾å›¾åƒåˆæˆå’Œ3Dç‰¹å¾é«˜æ–¯è¡¨ç¤ºçš„ç»“åˆï¼Œå­¦ä¹ äº†ä¸€ä¸ª3Dæ„ŸçŸ¥ç‰¹å¾ç¼–ç å™¨ï¼Œå°†3Då‡ ä½•çŸ¥è¯†æ³¨å…¥ç¼–ç å™¨ã€‚ç¬¬äºŒé˜¶æ®µé‡‡ç”¨æ–°è§†å›¾æ¸²æŸ“ç­–ç•¥ï¼Œç»“åˆä»å•è§†å›¾å›¾åƒç”Ÿæˆçš„å¤§è§„æ¨¡åˆæˆæ•°æ®ï¼Œå­¦ä¹ ç‰¹å¾è§£ç å™¨ä»¥å®ç°ç¨³å¥çš„ç‰¹å¾åŒ¹é…ï¼Œä»è€Œåœ¨ä¸åŒé¢†åŸŸä¸­å®ç°æ³›åŒ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é›¶æ ·æœ¬è¯„ä¼°åŸºå‡†ä¸Šå®ç°äº†ä¼˜è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œçªæ˜¾äº†æ‰€ææ¡†æ¶åœ¨ç¨³å¥ç‰¹å¾åŒ¹é…ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ç‰¹å¾åŒ¹é…æ–¹æ³•å¯¹å¤šè§†å›¾å›¾åƒçš„ä¾èµ–ï¼Œå¯¼è‡´å…¶åœ¨å¤æ‚åœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åœ¨å•è§†å›¾2Då›¾åƒä¸Šè®­ç»ƒï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰3Då¯¹åº”å…³ç³»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡æå‡ºçš„L2Mæ¡†æ¶é€šè¿‡å°†2Då›¾åƒæå‡è‡³3Dç©ºé—´ï¼Œåˆ©ç”¨å¤šè§†å›¾å›¾åƒåˆæˆå’Œ3Dç‰¹å¾è¡¨ç¤ºï¼Œå¢å¼ºç‰¹å¾ç¼–ç å™¨çš„3Dæ„ŸçŸ¥èƒ½åŠ›ï¼Œä»è€Œå®ç°æ›´ä¸ºç¨³å¥çš„ç‰¹å¾åŒ¹é…ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šL2Mæ¡†æ¶åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µå­¦ä¹ 3Dæ„ŸçŸ¥ç‰¹å¾ç¼–ç å™¨ï¼Œç¬¬äºŒé˜¶æ®µé€šè¿‡æ–°è§†å›¾æ¸²æŸ“ç­–ç•¥å’Œåˆæˆæ•°æ®ç”Ÿæˆå­¦ä¹ ç‰¹å¾è§£ç å™¨ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€ç‰¹å¾ç¼–ç ã€ç‰¹å¾è§£ç å’ŒåŒ¹é…ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†2Då›¾åƒæå‡è‡³3Dç©ºé—´çš„è¿‡ç¨‹ï¼Œä½¿å¾—ç‰¹å¾ç¼–ç å™¨èƒ½å¤Ÿèå…¥3Då‡ ä½•çŸ¥è¯†ï¼Œæ˜¾è‘—æå‡äº†ç‰¹å¾åŒ¹é…çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç‰¹å¾ç¼–ç å™¨ä¸­ï¼Œé‡‡ç”¨å¤šè§†å›¾å›¾åƒåˆæˆå’Œ3Dç‰¹å¾é«˜æ–¯è¡¨ç¤ºç›¸ç»“åˆçš„æ–¹å¼ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–3Dç‰¹å¾çš„å­¦ä¹ ï¼ŒåŒæ—¶åœ¨ç‰¹å¾è§£ç å™¨ä¸­ä½¿ç”¨æ–°è§†å›¾æ¸²æŸ“ç­–ç•¥ä»¥å¢å¼ºç‰¹å¾åŒ¹é…çš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒL2Mæ¡†æ¶åœ¨å¤šä¸ªé›¶æ ·æœ¬è¯„ä¼°åŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œç‰¹å¾åŒ¹é…çš„å‡†ç¡®ç‡æå‡äº†XX%ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚åœºæ™¯ä¸­çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®å’Œæœºå™¨äººè§†è§‰ç­‰ï¼Œèƒ½å¤Ÿåœ¨å¤šæ ·åŒ–å’Œå¤æ‚çš„ç¯å¢ƒä¸­å®ç°é«˜æ•ˆçš„ç‰¹å¾åŒ¹é…ã€‚æœªæ¥ï¼ŒL2Mæ¡†æ¶æœ‰æœ›æ¨åŠ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ï¼Œå°¤å…¶æ˜¯åœ¨ç¼ºä¹å¤šè§†å›¾æ•°æ®çš„æƒ…å†µä¸‹ï¼Œæå‡ç‰¹å¾åŒ¹é…çš„å¯é æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Feature matching plays a fundamental role in many computer vision tasks, yet existing methods heavily rely on scarce and clean multi-view image collections, which constrains their generalization to diverse and challenging scenarios. Moreover, conventional feature encoders are typically trained on single-view 2D images, limiting their capacity to capture 3D-aware correspondences. In this paper, we propose a novel two-stage framework that lifts 2D images to 3D space, named as \textbf{Lift to Match (L2M)}, taking full advantage of large-scale and diverse single-view images. To be specific, in the first stage, we learn a 3D-aware feature encoder using a combination of multi-view image synthesis and 3D feature Gaussian representation, which injects 3D geometry knowledge into the encoder. In the second stage, a novel-view rendering strategy, combined with large-scale synthetic data generation from single-view images, is employed to learn a feature decoder for robust feature matching, thus achieving generalization across diverse domains. Extensive experiments demonstrate that our method achieves superior generalization across zero-shot evaluation benchmarks, highlighting the effectiveness of the proposed framework for robust feature matching.

