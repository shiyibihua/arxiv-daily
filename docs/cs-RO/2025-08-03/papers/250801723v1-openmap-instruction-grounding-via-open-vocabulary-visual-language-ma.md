---
layout: default
title: OpenMap: Instruction Grounding via Open-Vocabulary Visual-Language Mapping
---

# OpenMap: Instruction Grounding via Open-Vocabulary Visual-Language Mapping

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.01723" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.01723v1</a>
  <a href="https://arxiv.org/pdf/2508.01723.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.01723v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.01723v1', 'OpenMap: Instruction Grounding via Open-Vocabulary Visual-Language Mapping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Danyang Li, Zenghui Yang, Guangpeng Qi, Songtao Pang, Guangyong Shang, Qiang Ma, Zheng Yang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-03

**å¤‡æ³¨**: ACM MM '25

**DOI**: [10.1145/3746027.3754887](https://doi.org/10.1145/3746027.3754887)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOpenMapä»¥è§£å†³è‡ªç„¶è¯­è¨€æŒ‡ä»¤ä¸è§†è§‰è§‚å¯Ÿå¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€æ˜ å°„` `è‡ªç„¶è¯­è¨€å¤„ç†` `3Dæ„ŸçŸ¥` `æŒ‡ä»¤å¯¹é½` `ç»“æ„-è¯­ä¹‰ä¸€è‡´æ€§` `å¤§å‹è¯­è¨€æ¨¡å‹` `å…·èº«æ™ºèƒ½ä½“`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰-è¯­è¨€æ˜ å°„æ–¹æ³•åœ¨è‡ªç”±å½¢å¼è¯­è¨€å‘½ä»¤ä¸å…·ä½“åœºæ™¯å®ä¾‹å¯¹é½æ–¹é¢å­˜åœ¨è¯­ä¹‰ä¸€è‡´æ€§å’ŒæŒ‡ä»¤è§£é‡Šçš„ä¸è¶³ã€‚
2. æå‡ºOpenMapï¼Œé€šè¿‡ç»“æ„-è¯­ä¹‰ä¸€è‡´æ€§çº¦æŸå’ŒLLMè¾…åŠ©çš„æŒ‡ä»¤åˆ°å®ä¾‹å¯¹é½æ¨¡å—ï¼Œæå‡æŒ‡ä»¤çš„ç†è§£å’Œå®ä¾‹é€‰æ‹©èƒ½åŠ›ã€‚
3. åœ¨ScanNet200å’ŒMatterport3Dæ•°æ®é›†ä¸Šï¼ŒOpenMapåœ¨é›¶-shotè®¾ç½®ä¸‹è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„åŸºçº¿ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤ä¸è§†è§‰è§‚å¯Ÿå¯¹é½æ˜¯å¼€æ”¾ä¸–ç•Œç¯å¢ƒä¸­å…·èº«æ™ºèƒ½ä½“çš„åŸºç¡€ä»»åŠ¡ã€‚å°½ç®¡è¿‘å¹´æ¥è§†è§‰-è¯­è¨€æ˜ å°„çš„è¿›å±•ä½¿å¾—è¯­ä¹‰è¡¨ç¤ºæ›´å…·æ™®é€‚æ€§ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨å°†è‡ªç”±å½¢å¼çš„è¯­è¨€å‘½ä»¤ä¸ç‰¹å®šåœºæ™¯å®ä¾‹å¯¹é½æ—¶ä»å­˜åœ¨ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†OpenMapï¼Œä¸€ä¸ªé›¶-shotå¼€æ”¾è¯æ±‡è§†è§‰-è¯­è¨€æ˜ å°„ï¼Œæ—¨åœ¨æé«˜å¯¼èˆªä»»åŠ¡ä¸­çš„æŒ‡ä»¤å¯¹é½ç²¾åº¦ã€‚æˆ‘ä»¬å¼•å…¥äº†ç»“æ„-è¯­ä¹‰ä¸€è‡´æ€§çº¦æŸï¼Œç»¼åˆè€ƒè™‘å…¨å±€å‡ ä½•ç»“æ„å’Œè§†è§‰-è¯­è¨€ç›¸ä¼¼æ€§ï¼Œä»¥æŒ‡å¯¼ç¨³å¥çš„3Då®ä¾‹çº§èšåˆã€‚æ­¤å¤–ï¼Œæå‡ºäº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤åˆ°å®ä¾‹å¯¹é½æ¨¡å—ï¼Œé€šè¿‡ç»“åˆç©ºé—´ä¸Šä¸‹æ–‡å’Œç›®æ ‡æè¿°ï¼Œå®ç°ç»†ç²’åº¦çš„å®ä¾‹é€‰æ‹©ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOpenMapåœ¨ScanNet200å’ŒMatterport3Dæ•°æ®é›†ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„åŸºçº¿ï¼Œè¯æ˜äº†å…¶åœ¨è‡ªç”±å½¢å¼è¯­è¨€ä¸3Dæ„ŸçŸ¥ä¹‹é—´æ¶èµ·æ¡¥æ¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è‡ªç„¶è¯­è¨€æŒ‡ä»¤ä¸è§†è§‰è§‚å¯Ÿä¹‹é—´çš„å¯¹é½é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å®ä¾‹çº§è¯­ä¹‰ä¸€è‡´æ€§å’ŒæŒ‡ä»¤ç†è§£ä¸Šå­˜åœ¨å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥ç»“æ„-è¯­ä¹‰ä¸€è‡´æ€§çº¦æŸå’ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤åˆ°å®ä¾‹å¯¹é½æ¨¡å—ï¼Œå¢å¼ºæŒ‡ä»¤çš„ç†è§£å’Œå®ä¾‹é€‰æ‹©çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOpenMapçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç»“æ„-è¯­ä¹‰ä¸€è‡´æ€§çº¦æŸæ¨¡å—å’ŒLLMè¾…åŠ©çš„æŒ‡ä»¤åˆ°å®ä¾‹å¯¹é½æ¨¡å—ï¼Œå‰è€…ç”¨äºå¤„ç†è¯­ä¹‰ä¸€è‡´æ€§ï¼Œåè€…ç”¨äºç»†ç²’åº¦å®ä¾‹é€‰æ‹©ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†ç»“æ„-è¯­ä¹‰ä¸€è‡´æ€§çº¦æŸï¼Œèƒ½å¤ŸåŒæ—¶è€ƒè™‘å…¨å±€å‡ ä½•ç»“æ„å’Œè§†è§‰-è¯­è¨€ç›¸ä¼¼æ€§ï¼Œä»è€Œå®ç°æ›´ç¨³å¥çš„3Då®ä¾‹èšåˆã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç»“æ„-è¯­ä¹‰ä¸€è‡´æ€§ï¼Œå¹¶é€šè¿‡ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å¢å¼ºæŒ‡ä»¤åˆ°å®ä¾‹çš„å¯¹é½èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOpenMapåœ¨ScanNet200å’ŒMatterport3Dæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸è¾ƒäºæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ï¼Œå‡†ç¡®ç‡æé«˜äº†XX%ï¼ŒéªŒè¯äº†å…¶åœ¨é›¶-shotè®¾ç½®ä¸‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½åŠ©æ‰‹å’Œå¢å¼ºç°å®ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å…·èº«æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è‡ªä¸»å†³ç­–èƒ½åŠ›ã€‚æœªæ¥ï¼ŒOpenMapæœ‰æœ›åœ¨å¤šæ¨¡æ€äº¤äº’å’Œäººæœºåä½œä¸­å‘æŒ¥æ›´å¤§ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Grounding natural language instructions to visual observations is fundamental for embodied agents operating in open-world environments. Recent advances in visual-language mapping have enabled generalizable semantic representations by leveraging vision-language models (VLMs). However, these methods often fall short in aligning free-form language commands with specific scene instances, due to limitations in both instance-level semantic consistency and instruction interpretation. We present OpenMap, a zero-shot open-vocabulary visual-language map designed for accurate instruction grounding in navigation tasks. To address semantic inconsistencies across views, we introduce a Structural-Semantic Consensus constraint that jointly considers global geometric structure and vision-language similarity to guide robust 3D instance-level aggregation. To improve instruction interpretation, we propose an LLM-assisted Instruction-to-Instance Grounding module that enables fine-grained instance selection by incorporating spatial context and expressive target descriptions. We evaluate OpenMap on ScanNet200 and Matterport3D, covering both semantic mapping and instruction-to-target retrieval tasks. Experimental results show that OpenMap outperforms state-of-the-art baselines in zero-shot settings, demonstrating the effectiveness of our method in bridging free-form language and 3D perception for embodied navigation.

