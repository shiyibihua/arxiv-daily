---
layout: default
title: EGM: Efficiently Learning General Motion Tracking Policy for High Dynamic Humanoid Whole-Body Control
---

# EGM: Efficiently Learning General Motion Tracking Policy for High Dynamic Humanoid Whole-Body Control

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.19043" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.19043v1</a>
  <a href="https://arxiv.org/pdf/2512.19043.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.19043v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.19043v1', 'EGM: Efficiently Learning General Motion Tracking Policy for High Dynamic Humanoid Whole-Body Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chao Yang, Yingkai Sun, Peng Ye, Xin Chen, Chong Yu, Tao Chen

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-22

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EGMï¼šé«˜æ•ˆå­¦ä¹ é€šç”¨è¿åŠ¨è·Ÿè¸ªç­–ç•¥ï¼Œç”¨äºé«˜åŠ¨æ€äººå½¢æœºå™¨äººå…¨èº«æ§åˆ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `äººå½¢æœºå™¨äºº` `å…¨èº«æ§åˆ¶` `è¿åŠ¨è·Ÿè¸ª` `å¼ºåŒ–å­¦ä¹ ` `æ··åˆä¸“å®¶ç½‘ç»œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨äººå½¢æœºå™¨äººè¿åŠ¨è·Ÿè¸ªç­–ç•¥å­¦ä¹ ä¸­ï¼Œå­˜åœ¨æ•°æ®åˆ©ç”¨ç‡ä½ã€è®­ç»ƒæ•ˆç‡ä¸é«˜ä»¥åŠéš¾ä»¥è·Ÿè¸ªé«˜åŠ¨æ€è¿åŠ¨ç­‰é—®é¢˜ã€‚
2. EGMæ¡†æ¶é€šè¿‡Bin-basedè‡ªé€‚åº”é‡‡æ ·ã€CDMoEæ¶æ„ä»¥åŠä¸‰é˜¶æ®µè¯¾ç¨‹è®­ç»ƒï¼Œæå‡æ•°æ®åˆ©ç”¨ç‡ï¼Œå¢å¼ºæ¨¡å‹æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒEGMä»…ä½¿ç”¨å°‘é‡è®­ç»ƒæ•°æ®ï¼Œå³å¯åœ¨å¤§é‡æµ‹è¯•æ•°æ®ä¸Šå®ç°ä¼˜å¼‚çš„è¿åŠ¨è·Ÿè¸ªæ€§èƒ½ï¼Œè¶…è¶Šç°æœ‰åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºEGMçš„æ¡†æ¶ï¼Œæ—¨åœ¨é«˜æ•ˆå­¦ä¹ é€šç”¨è¿åŠ¨è·Ÿè¸ªç­–ç•¥ï¼Œç”¨äºäººå½¢æœºå™¨äººå…¨èº«æ§åˆ¶ã€‚ä¼ ç»Ÿæ–¹æ³•åœ¨æ•°æ®åˆ©ç”¨ç‡å’Œè®­ç»ƒæ•ˆç‡æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œä¸”åœ¨è·Ÿè¸ªé«˜åŠ¨æ€è¿åŠ¨æ—¶æ€§èƒ½å—é™ã€‚EGMé›†æˆäº†å››ä¸ªæ ¸å¿ƒè®¾è®¡ï¼šåŸºäºBinçš„è·¨è¿åŠ¨è¯¾ç¨‹è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ï¼ŒåŠ¨æ€è°ƒæ•´é‡‡æ ·æ¦‚ç‡ï¼Œå¹³è¡¡ä¸åŒéš¾åº¦å’Œæ—¶é•¿çš„è¿åŠ¨è®­ç»ƒï¼›å¤åˆè§£è€¦æ··åˆä¸“å®¶(CDMoE)æ¶æ„ï¼Œé€šè¿‡å¯¹ä¸Šä¸‹èº«åˆ†åˆ«åˆ†ç»„ä¸“å®¶ï¼Œå¹¶è§£è€¦æ­£äº¤ä¸“å®¶å¤„ç†ä¸“ç”¨å’Œé€šç”¨ç‰¹å¾ï¼Œä»è€Œå¢å¼ºè·Ÿè¸ªä¸åŒåˆ†å¸ƒè¿åŠ¨çš„èƒ½åŠ›ï¼›å¼ºè°ƒæ•°æ®è´¨é‡å’Œå¤šæ ·æ€§å¯¹äºè®­ç»ƒé€šç”¨è¿åŠ¨è·Ÿè¸ªç­–ç•¥è‡³å…³é‡è¦ï¼›ä¸‰é˜¶æ®µè¯¾ç¨‹è®­ç»ƒæµç¨‹ï¼Œé€æ­¥å¢å¼ºç­–ç•¥å¯¹æ‰°åŠ¨çš„é²æ£’æ€§ã€‚ä»…ä½¿ç”¨4.08å°æ—¶çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼ŒEGMåœ¨49.25å°æ—¶çš„æµ‹è¯•è¿åŠ¨ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨å¸¸è§„å’Œé«˜åŠ¨æ€ä»»åŠ¡ä¸­ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³äººå½¢æœºå™¨äººå…¨èº«æ§åˆ¶ä¸­ï¼Œé€šç”¨è¿åŠ¨è·Ÿè¸ªç­–ç•¥å­¦ä¹ æ•ˆç‡ä½ã€éš¾ä»¥è·Ÿè¸ªé«˜åŠ¨æ€è¿åŠ¨çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸æ•°æ®åˆ©ç”¨ç‡ä¸é«˜ï¼Œè®­ç»ƒè¿‡ç¨‹è€—æ—¶ï¼Œä¸”åœ¨é«˜åŠ¨æ€è¿åŠ¨è·Ÿè¸ªä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æé«˜æ•°æ®è´¨é‡å’Œå¤šæ ·æ€§ï¼Œå¹¶è®¾è®¡é«˜æ•ˆçš„è®­ç»ƒæ¡†æ¶ï¼Œä»è€Œæå‡é€šç”¨è¿åŠ¨è·Ÿè¸ªç­–ç•¥çš„å­¦ä¹ æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“è€Œè¨€ï¼Œé€šè¿‡è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥å¹³è¡¡ä¸åŒéš¾åº¦è¿åŠ¨çš„è®­ç»ƒï¼Œå¹¶åˆ©ç”¨å¤åˆè§£è€¦æ··åˆä¸“å®¶ç½‘ç»œæå–è¿åŠ¨ç‰¹å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEGMæ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œä½¿ç”¨Bin-based Cross-motion Curriculum Adaptive Samplingç­–ç•¥ï¼Œæ ¹æ®è¿åŠ¨è·Ÿè¸ªè¯¯å·®åŠ¨æ€è°ƒæ•´é‡‡æ ·æ¦‚ç‡ï¼Œå¹³è¡¡ä¸åŒè¿åŠ¨çš„è®­ç»ƒã€‚ç„¶åï¼Œå°†é‡‡æ ·æ•°æ®è¾“å…¥åˆ°Composite Decoupled Mixture-of-Experts (CDMoE)æ¶æ„ä¸­ï¼Œè¯¥æ¶æ„åˆ†åˆ«å¯¹ä¸Šä¸‹èº«è¿›è¡Œä¸“å®¶åˆ†ç»„ï¼Œå¹¶è§£è€¦æ­£äº¤ä¸“å®¶å¤„ç†ä¸“ç”¨å’Œé€šç”¨ç‰¹å¾ã€‚æœ€åï¼Œé‡‡ç”¨ä¸‰é˜¶æ®µè¯¾ç¨‹è®­ç»ƒæµç¨‹ï¼Œé€æ­¥æé«˜ç­–ç•¥å¯¹æ‰°åŠ¨çš„é²æ£’æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šEGMçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) Bin-based Cross-motion Curriculum Adaptive Samplingç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡ä¸åŒéš¾åº¦å’Œæ—¶é•¿çš„è¿åŠ¨è®­ç»ƒï¼Œæé«˜æ•°æ®åˆ©ç”¨ç‡ã€‚2) Composite Decoupled Mixture-of-Experts (CDMoE)æ¶æ„ï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°æå–è¿åŠ¨ç‰¹å¾ï¼Œå¢å¼ºæ¨¡å‹å¯¹ä¸åŒè¿åŠ¨åˆ†å¸ƒçš„é€‚åº”æ€§ã€‚3) ä¸‰é˜¶æ®µè¯¾ç¨‹è®­ç»ƒæµç¨‹ï¼Œé€æ­¥æé«˜ç­–ç•¥çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šBin-basedé‡‡æ ·ç­–ç•¥å°†è¿åŠ¨æ•°æ®åˆ’åˆ†ä¸ºå¤šä¸ªbinï¼Œæ ¹æ®æ¯ä¸ªbinçš„è·Ÿè¸ªè¯¯å·®åŠ¨æ€è°ƒæ•´é‡‡æ ·æ¦‚ç‡ã€‚CDMoEæ¶æ„ä¸­ï¼Œä¸“å®¶ç½‘ç»œè¢«åˆ†ä¸ºä¸Šä¸‹èº«ä¸¤ç»„ï¼Œå¹¶é‡‡ç”¨è§£è€¦è®¾è®¡ï¼Œåˆ†åˆ«å¤„ç†ä¸“ç”¨å’Œé€šç”¨ç‰¹å¾ã€‚ä¸‰é˜¶æ®µè¯¾ç¨‹è®­ç»ƒæµç¨‹åŒ…æ‹¬ï¼šç¬¬ä¸€é˜¶æ®µï¼Œä½¿ç”¨æ— æ‰°åŠ¨æ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼›ç¬¬äºŒé˜¶æ®µï¼Œå¼•å…¥è½»å¾®æ‰°åŠ¨ï¼Œæé«˜ç­–ç•¥çš„é²æ£’æ€§ï¼›ç¬¬ä¸‰é˜¶æ®µï¼Œå¼•å…¥æ›´å¼ºçš„æ‰°åŠ¨ï¼Œè¿›ä¸€æ­¥å¢å¼ºç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œå¯èƒ½åŒ…å«è·Ÿè¸ªè¯¯å·®ã€å…³èŠ‚åŠ›çŸ©æƒ©ç½šç­‰ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19043v1/x2.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19043v1/x3.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19043v1/x4.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

EGMæ¡†æ¶ä»…ä½¿ç”¨4.08å°æ—¶çš„è®­ç»ƒæ•°æ®ï¼Œå³å¯åœ¨49.25å°æ—¶çš„æµ‹è¯•æ•°æ®ä¸Šå®ç°ä¼˜å¼‚çš„è¿åŠ¨è·Ÿè¸ªæ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚å°¤å…¶æ˜¯åœ¨é«˜åŠ¨æ€è¿åŠ¨è·Ÿè¸ªä»»åŠ¡ä¸­ï¼ŒEGMè¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEGMèƒ½å¤Ÿæœ‰æ•ˆæé«˜æ•°æ®åˆ©ç”¨ç‡å’Œè®­ç»ƒæ•ˆç‡ï¼Œä¸ºäººå½¢æœºå™¨äººå…¨èº«æ§åˆ¶æä¾›äº†ä¸€ç§é«˜æ•ˆå¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§äººå½¢æœºå™¨äººå…¨èº«æ§åˆ¶ä»»åŠ¡ï¼Œä¾‹å¦‚è¿åŠ¨æ¨¡ä»¿ã€äººæœºåä½œã€åº·å¤è®­ç»ƒç­‰ã€‚é€šè¿‡å­¦ä¹ é€šç”¨çš„è¿åŠ¨è·Ÿè¸ªç­–ç•¥ï¼Œæœºå™¨äººèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒçš„è¿åŠ¨åœºæ™¯å’Œä»»åŠ¡éœ€æ±‚ï¼Œæé«˜å…¶æ™ºèƒ½åŒ–æ°´å¹³å’Œåº”ç”¨èŒƒå›´ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ›´å¤æ‚çš„æœºå™¨äººç³»ç»Ÿï¼Œä¾‹å¦‚åŒè¶³è¡Œèµ°æœºå™¨äººã€æœåŠ¡æœºå™¨äººç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Learning a general motion tracking policy from human motions shows great potential for versatile humanoid whole-body control. Conventional approaches are not only inefficient in data utilization and training processes but also exhibit limited performance when tracking highly dynamic motions. To address these challenges, we propose EGM, a framework that enables efficient learning of a general motion tracking policy. EGM integrates four core designs. Firstly, we introduce a Bin-based Cross-motion Curriculum Adaptive Sampling strategy to dynamically orchestrate the sampling probabilities based on tracking error of each motion bin, eficiently balancing the training process across motions with varying dificulty and durations. The sampled data is then processed by our proposed Composite Decoupled Mixture-of-Experts (CDMoE) architecture, which efficiently enhances the ability to track motions from different distributions by grouping experts separately for upper and lower body and decoupling orthogonal experts from shared experts to separately handle dedicated features and general features. Central to our approach is a key insight we identified: for training a general motion tracking policy, data quality and diversity are paramount. Building on these designs, we develop a three-stage curriculum training flow to progressively enhance the policy's robustness against disturbances. Despite training on only 4.08 hours of data, EGM generalized robustly across 49.25 hours of test motions, outperforming baselines on both routine and highly dynamic tasks.

