---
layout: default
title: Vision-Language-Policy Model for Dynamic Robot Task Planning
---

# Vision-Language-Policy Model for Dynamic Robot Task Planning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.19178" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.19178v1</a>
  <a href="https://arxiv.org/pdf/2512.19178.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.19178v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.19178v1', 'Vision-Language-Policy Model for Dynamic Robot Task Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jin Wang, Kim Tien Ly, Jacques Cloete, Nikos Tsagarakis, Ioannis Havoutis

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-22

**å¤‡æ³¨**: Manuscript under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè§†è§‰-è¯­è¨€-ç­–ç•¥æ¨¡å‹çš„åŠ¨æ€æœºå™¨äººä»»åŠ¡è§„åˆ’æ–¹æ³•ï¼Œæå‡å¤æ‚ç¯å¢ƒä¸‹çš„è‡ªä¸»æ‰§è¡Œèƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `æœºå™¨äººä»»åŠ¡è§„åˆ’` `è§†è§‰è¯­è¨€æ¨¡å‹` `åŠ¨æ€ç­–ç•¥è°ƒæ•´` `è‡ªä¸»å¯¼èˆª` `è·¨å…·èº«æ³›åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿæœºå™¨äººä»»åŠ¡è§„åˆ’éš¾ä»¥å°†åº•å±‚æ‰§è¡Œä¸é«˜å±‚ä»»åŠ¡æ¨ç†ç»“åˆï¼Œä¸”æ— æ³•åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­åŠ¨æ€æ›´æ–°ç­–ç•¥ï¼Œé™åˆ¶äº†å…¶é€šç”¨æ€§å’Œé€‚åº”æ€§ã€‚
2. è®ºæ–‡æå‡ºVLPæ¨¡å‹ï¼Œé€šè¿‡è§†è§‰-è¯­è¨€æ¨¡å‹ç†è§£æŒ‡ä»¤å’Œåœºæ™¯ï¼Œç”Ÿæˆè¡Œä¸ºç­–ç•¥æ§åˆ¶æœºå™¨äººï¼Œå¹¶èƒ½æ ¹æ®ä»»åŠ¡å˜åŒ–åŠ¨æ€è°ƒæ•´ç­–ç•¥ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹èƒ½æœ‰æ•ˆé€‚åº”æ–°åœºæ™¯å¹¶åŠ¨æ€æ›´æ–°ç­–ç•¥ï¼Œå±•ç°å‡ºå¼ºå¤§çš„è§„åˆ’è‡ªä¸»æ€§å’Œè·¨å…·èº«æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¯­è¨€æ¨¡å‹çš„åŠ¨æ€æœºå™¨äººä»»åŠ¡è§„åˆ’æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªè§†è§‰-è¯­è¨€-ç­–ç•¥ï¼ˆVLPï¼‰æ¨¡å‹ï¼Œå®ƒåŸºäºåœ¨çœŸå®ä¸–ç•Œæ•°æ®ä¸Šå¾®è°ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿç†è§£è¯­ä¹‰æŒ‡ä»¤ï¼Œå¹¶ç»“åˆå¯¹å½“å‰ä»»åŠ¡åœºæ™¯çš„æ¨ç†ï¼Œç”Ÿæˆæ§åˆ¶æœºå™¨äººå®Œæˆä»»åŠ¡çš„è¡Œä¸ºç­–ç•¥ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹èƒ½å¤ŸåŠ¨æ€è°ƒæ•´ä»»åŠ¡ç­–ç•¥ä»¥å“åº”ä»»åŠ¡å˜åŒ–ï¼Œä»è€Œçµæ´»é€‚åº”ä¸æ–­å˜åŒ–çš„ä»»åŠ¡éœ€æ±‚ã€‚åœ¨ä¸åŒæœºå™¨äººå’Œå„ç§çœŸå®ä¸–ç•Œä»»åŠ¡ä¸­è¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°é€‚åº”æ–°åœºæ™¯å¹¶åŠ¨æ€æ›´æ–°å…¶ç­–ç•¥ï¼Œå±•ç¤ºäº†å¼ºå¤§çš„è§„åˆ’è‡ªä¸»æ€§å’Œè·¨å…·èº«æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººå¦‚ä½•åœ¨éç»“æ„åŒ–ç¯å¢ƒä¸­ï¼Œæ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤è‡ªä¸»æ‰§è¡Œä»»åŠ¡çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥å°†é«˜å±‚ä»»åŠ¡ç†è§£ä¸åº•å±‚åŠ¨ä½œæ‰§è¡Œæœ‰æ•ˆç»“åˆï¼Œå¹¶ä¸”åœ¨ä»»åŠ¡æŒ‡ä»¤å‘ç”Ÿå˜åŒ–æ—¶ï¼Œæ— æ³•åŠ¨æ€è°ƒæ•´è§„åˆ’ç­–ç•¥ï¼Œå¯¼è‡´æœºå™¨äººé€‚åº”æ€§å’Œé€šç”¨æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹ç†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œæ„ŸçŸ¥ç¯å¢ƒä¿¡æ¯ï¼Œå¹¶å°†å…¶èåˆä»¥ç”Ÿæˆæœºå™¨äººæ‰§è¡Œç­–ç•¥ã€‚é€šè¿‡åœ¨çœŸå®ä¸–ç•Œæ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å®é™…åœºæ™¯çš„å¤æ‚æ€§å’Œä¸ç¡®å®šæ€§ã€‚æ­¤å¤–ï¼Œæ¨¡å‹è¢«è®¾è®¡æˆèƒ½å¤ŸåŠ¨æ€å“åº”ä»»åŠ¡å˜åŒ–ï¼Œä»è€Œå®ç°çµæ´»çš„ä»»åŠ¡è§„åˆ’ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯è§†è§‰-è¯­è¨€-ç­–ç•¥ï¼ˆVLPï¼‰æ¨¡å‹ã€‚æ•´ä½“æµç¨‹å¦‚ä¸‹ï¼š1) æœºå™¨äººé€šè¿‡è§†è§‰ä¼ æ„Ÿå™¨è·å–ç¯å¢ƒä¿¡æ¯ï¼›2) VLPæ¨¡å‹æ¥æ”¶è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œç¯å¢ƒä¿¡æ¯ä½œä¸ºè¾“å…¥ï¼›3) VLPæ¨¡å‹å¯¹æŒ‡ä»¤å’Œåœºæ™¯è¿›è¡Œç†è§£å’Œæ¨ç†ï¼Œç”Ÿæˆç›¸åº”çš„è¡Œä¸ºç­–ç•¥ï¼›4) æœºå™¨äººæ ¹æ®ç”Ÿæˆçš„ç­–ç•¥æ‰§è¡ŒåŠ¨ä½œï¼›5) å¦‚æœä»»åŠ¡æŒ‡ä»¤å‘ç”Ÿå˜åŒ–ï¼ŒVLPæ¨¡å‹ä¼šåŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼Œå¹¶æŒ‡å¯¼æœºå™¨äººç»§ç»­æ‰§è¡Œã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†è§†è§‰-è¯­è¨€æ¨¡å‹ä¸æœºå™¨äººä»»åŠ¡è§„åˆ’ç›¸ç»“åˆï¼Œå¹¶ä½¿å…¶å…·å¤‡åŠ¨æ€è°ƒæ•´ç­–ç•¥çš„èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œå¹¶æ ¹æ®ç¯å¢ƒå˜åŒ–å’Œä»»åŠ¡éœ€æ±‚è¿›è¡Œçµæ´»çš„ä»»åŠ¡è§„åˆ’ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹å±•ç°å‡ºè¾ƒå¼ºçš„è·¨å…·èº«æ³›åŒ–èƒ½åŠ›ï¼Œå³åœ¨ä¸åŒæœºå™¨äººå¹³å°ä¸Šä¹Ÿèƒ½æœ‰æ•ˆå·¥ä½œã€‚

**å…³é”®è®¾è®¡**ï¼šVLPæ¨¡å‹åŸºäºé¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œæœºå™¨äººä»»åŠ¡æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°ç»†èŠ‚æœªçŸ¥ï¼Œä½†å¯ä»¥æ¨æµ‹ä½¿ç”¨äº†Transformerç­‰ç»“æ„æ¥å¤„ç†åºåˆ—åŒ–çš„è¯­è¨€å’Œè§†è§‰ä¿¡æ¯ï¼Œå¹¶å¯èƒ½é‡‡ç”¨äº†å¼ºåŒ–å­¦ä¹ æˆ–æ¨¡ä»¿å­¦ä¹ ç­‰æ–¹æ³•æ¥è®­ç»ƒç­–ç•¥ç”Ÿæˆæ¨¡å—ã€‚åŠ¨æ€ç­–ç•¥è°ƒæ•´æœºåˆ¶çš„å…·ä½“å®ç°æ–¹å¼æœªçŸ¥ï¼Œå¯èƒ½æ¶‰åŠåˆ°æ³¨æ„åŠ›æœºåˆ¶æˆ–åŠ¨æ€è§„åˆ’ç­‰æŠ€æœ¯ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19178v1/images/figure2.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19178v1/images/figure3.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19178v1/images/figure4.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥VLPæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°é€‚åº”æ–°åœºæ™¯å¹¶åŠ¨æ€æ›´æ–°å…¶ç­–ç•¥ï¼Œå±•ç°äº†å¼ºå¤§çš„è§„åˆ’è‡ªä¸»æ€§å’Œè·¨å…·èº«æ³›åŒ–èƒ½åŠ›ã€‚è™½ç„¶è®ºæ–‡ä¸­æ²¡æœ‰ç»™å‡ºå…·ä½“çš„æ€§èƒ½æŒ‡æ ‡å’Œå¯¹æ¯”åŸºçº¿ï¼Œä½†å¼ºè°ƒäº†æ¨¡å‹åœ¨ä¸åŒæœºå™¨äººå’Œå„ç§çœŸå®ä¸–ç•Œä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦æœºå™¨äººè‡ªä¸»æ‰§è¡Œä»»åŠ¡çš„åœºæ™¯ï¼Œä¾‹å¦‚å®¶åº­æœåŠ¡ã€å·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—è¾…åŠ©ã€ç¾éš¾æ•‘æ´ç­‰ã€‚é€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œç”¨æˆ·å¯ä»¥è½»æ¾åœ°æŒ‡æŒ¥æœºå™¨äººå®Œæˆå¤æ‚ä»»åŠ¡ï¼Œæ— éœ€ä¸“ä¸šçš„ç¼–ç¨‹çŸ¥è¯†ã€‚è¯¥æŠ€æœ¯æœ‰æœ›æå‡æœºå™¨äººçš„æ™ºèƒ½åŒ–æ°´å¹³ï¼Œä½¿å…¶æ›´å¥½åœ°æœåŠ¡äºäººç±»ç¤¾ä¼šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Bridging the gap between natural language commands and autonomous execution in unstructured environments remains an open challenge for robotics. This requires robots to perceive and reason over the current task scene through multiple modalities, and to plan their behaviors to achieve their intended goals. Traditional robotic task-planning approaches often struggle to bridge low-level execution with high-level task reasoning, and cannot dynamically update task strategies when instructions change during execution, which ultimately limits their versatility and adaptability to new tasks. In this work, we propose a novel language model-based framework for dynamic robot task planning. Our Vision-Language-Policy (VLP) model, based on a vision-language model fine-tuned on real-world data, can interpret semantic instructions and integrate reasoning over the current task scene to generate behavior policies that control the robot to accomplish the task. Moreover, it can dynamically adjust the task strategy in response to changes in the task, enabling flexible adaptation to evolving task requirements. Experiments conducted with different robots and a variety of real-world tasks show that the trained model can efficiently adapt to novel scenarios and dynamically update its policy, demonstrating strong planning autonomy and cross-embodiment generalization. Videos: https://robovlp.github.io/

