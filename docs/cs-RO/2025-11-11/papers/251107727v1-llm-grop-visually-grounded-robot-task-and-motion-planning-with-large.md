---
layout: default
title: LLM-GROP: Visually Grounded Robot Task and Motion Planning with Large Language Models
---

# LLM-GROP: Visually Grounded Robot Task and Motion Planning with Large Language Models

**arXiv**: [2511.07727v1](https://arxiv.org/abs/2511.07727) | [PDF](https://arxiv.org/pdf/2511.07727.pdf)

**ä½œè€…**: Xiaohan Zhang, Yan Ding, Yohei Hayamizu, Zainab Altaweel, Yifeng Zhu, Yuke Zhu, Peter Stone, Chris Paxton, Shiqi Zhang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11

**æœŸåˆŠ**: The International Journal of Robotics Research, 2025, Vol. 0(0), pp. 1-19

**DOI**: [10.1177/02783649251378196](https://doi.org/10.1177/02783649251378196)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**LLM-GROPï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡åž‹å®žçŽ°è§†è§‰å¼•å¯¼çš„æœºå™¨äººä»»åŠ¡ä¸Žè¿åŠ¨è§„åˆ’**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æœºå™¨äºº` `ä»»åŠ¡ä¸Žè¿åŠ¨è§„åˆ’` `å¤§è¯­è¨€æ¨¡åž‹` `è§†è§‰å¼•å¯¼` `ç§»åŠ¨æ“ä½œ` `å¸¸è¯†æŽ¨ç†` `ç‰©ä½“é‡æŽ’åˆ—`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç§»åŠ¨æ“ä½œï¼ˆMoMaï¼‰ä¸­çš„ä»»åŠ¡ä¸Žè¿åŠ¨è§„åˆ’ï¼ˆTAMPï¼‰éœ€è¦äº¤é”™å¯¼èˆªå’Œæ“ä½œåŠ¨ä½œï¼ŒçŽ°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨å¸¸è¯†çŸ¥è¯†ã€‚
2. LLM-GROPåˆ©ç”¨LLMçš„å¸¸è¯†çŸ¥è¯†è¾…åŠ©ä»»åŠ¡çº§å’Œè¿åŠ¨çº§è§„åˆ’ï¼Œå¹¶ç»“åˆè§†è§‰æ–¹æ³•å­¦ä¹ æœºå™¨äººåŸºåº§ä½ç½®é€‰æ‹©ç­–ç•¥ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨çœŸå®žå’Œæ¨¡æ‹ŸçŽ¯å¢ƒä¸­å‡èƒ½æœ‰æ•ˆå®Œæˆé•¿æ—¶ç¨‹ç‰©ä½“é‡æŽ’åˆ—ä»»åŠ¡ï¼ŒæˆåŠŸçŽ‡è¾¾åˆ°84.4%ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºŽå¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰çš„è§†è§‰å¼•å¯¼æœºå™¨äººä»»åŠ¡ä¸Žè¿åŠ¨è§„åˆ’ï¼ˆTAMPï¼‰æ¡†æž¶ï¼Œç”¨äºŽè§£å†³å¤šç‰©ä½“ç§»åŠ¨æ“ä½œï¼ˆMoMaï¼‰é—®é¢˜ã€‚è¯¥æ¡†æž¶åˆ©ç”¨LLMä¸°å¯Œçš„å¸¸è¯†çŸ¥è¯†ï¼Œä¾‹å¦‚é¤å…·çš„æ‘†æ”¾æ–¹å¼ï¼Œæ¥è¾…åŠ©ä»»åŠ¡çº§å’Œè¿åŠ¨çº§è§„åˆ’ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨è®¡ç®—æœºè§†è§‰æ–¹æ³•å­¦ä¹ é€‰æ‹©æœºå™¨äººåŸºåº§ä½ç½®çš„ç­–ç•¥ï¼Œä»¥ä¿ƒè¿›MoMaè¡Œä¸ºã€‚è¯¥æ¡†æž¶é€‚ç”¨äºŽåŒ…å«å¤šä¸ªå¾…ç§»åŠ¨ç‰©ä½“çš„æ–°åœºæ™¯ã€‚åœ¨çœŸå®žçŽ¯å¢ƒå’Œæ¨¡æ‹ŸçŽ¯å¢ƒä¸­è¿›è¡Œäº†å®šé‡å®žéªŒï¼Œè¯„ä¼°äº†å®Œæˆé•¿æ—¶ç¨‹ç‰©ä½“é‡æŽ’åˆ—ä»»åŠ¡çš„æˆåŠŸçŽ‡å’Œæ•ˆçŽ‡ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæœºå™¨äººå®Œæˆäº†84.4%çš„çœŸå®žç‰©ä½“é‡æŽ’åˆ—è¯•éªŒï¼Œä½†ä¸»è§‚äººç±»è¯„ä¼°è¡¨æ˜Žï¼Œæœºå™¨äººçš„æ€§èƒ½ä»ä½ŽäºŽç»éªŒä¸°å¯Œçš„äººç±»æœåŠ¡å‘˜ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç§»åŠ¨æ“ä½œï¼ˆMoMaï¼‰åœºæ™¯ä¸‹çš„ä»»åŠ¡ä¸Žè¿åŠ¨è§„åˆ’ï¼ˆTAMPï¼‰é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯æ¶‰åŠå¤šä¸ªç‰©ä½“é‡æŽ’åˆ—çš„å¤æ‚ä»»åŠ¡ã€‚çŽ°æœ‰æ–¹æ³•åœ¨å¤„ç†æ­¤ç±»é—®é¢˜æ—¶ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨å¸¸è¯†çŸ¥è¯†ï¼Œå¯¼è‡´è§„åˆ’æ•ˆçŽ‡ä½Žä¸‹æˆ–æ— æ³•ç”Ÿæˆåˆç†çš„è§£å†³æ–¹æ¡ˆã€‚ä¾‹å¦‚ï¼Œå¦‚ä½•æ ¹æ®â€œæ‘†æ”¾é¤æ¡Œâ€è¿™ä¸€é«˜å±‚æŒ‡ä»¤ï¼Œåˆç†åœ°å®‰æŽ’é¤å…·çš„ä½ç½®å’Œé¡ºåºï¼Œå¹¶è§„åˆ’å‡ºå¯è¡Œçš„æœºå™¨äººè¿åŠ¨è½¨è¿¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰è•´å«çš„ä¸°å¯Œå¸¸è¯†çŸ¥è¯†ï¼Œæ¥æŒ‡å¯¼ä»»åŠ¡çº§å’Œè¿åŠ¨çº§è§„åˆ’ã€‚LLMå¯ä»¥æä¾›å…³äºŽç‰©ä½“ä¹‹é—´å…³ç³»çš„å…ˆéªŒçŸ¥è¯†ï¼Œä¾‹å¦‚é¤å…·çš„æ‘†æ”¾è§„åˆ™ï¼Œä»Žè€Œå¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£ä»»åŠ¡ç›®æ ‡å¹¶ç”Ÿæˆåˆç†çš„è§„åˆ’æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ç»“åˆè®¡ç®—æœºè§†è§‰æŠ€æœ¯ï¼Œå­¦ä¹ é€‰æ‹©æœºå™¨äººåŸºåº§ä½ç½®çš„ç­–ç•¥ï¼Œä»¥ä¼˜åŒ–æœºå™¨äººçš„è¿åŠ¨æ•ˆçŽ‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šLLM-GROPæ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) **LLMå¸¸è¯†æŽ¨ç†æ¨¡å—**ï¼šåˆ©ç”¨LLMå¯¹ä»»åŠ¡ç›®æ ‡è¿›è¡Œè§£æžï¼Œæå–ç‰©ä½“ä¹‹é—´çš„å…³ç³»å’Œçº¦æŸï¼Œç”Ÿæˆä»»åŠ¡çº§çš„è§„åˆ’æ–¹æ¡ˆã€‚2) **è§†è§‰æ„ŸçŸ¥æ¨¡å—**ï¼šåˆ©ç”¨è®¡ç®—æœºè§†è§‰æŠ€æœ¯æ„ŸçŸ¥çŽ¯å¢ƒä¸­çš„ç‰©ä½“ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç‰©ä½“çš„ä½ç½®ã€å½¢çŠ¶å’Œç±»åˆ«ç­‰ã€‚3) **åŸºåº§ä½ç½®é€‰æ‹©æ¨¡å—**ï¼šå­¦ä¹ é€‰æ‹©åˆé€‚çš„æœºå™¨äººåŸºåº§ä½ç½®ï¼Œä»¥ä¼˜åŒ–æœºå™¨äººçš„è¿åŠ¨æ•ˆçŽ‡å’Œæ“ä½œèƒ½åŠ›ã€‚4) **è¿åŠ¨è§„åˆ’æ¨¡å—**ï¼šæ ¹æ®ä»»åŠ¡çº§è§„åˆ’æ–¹æ¡ˆå’Œè§†è§‰æ„ŸçŸ¥ä¿¡æ¯ï¼Œç”Ÿæˆå¯è¡Œçš„æœºå™¨äººè¿åŠ¨è½¨è¿¹ã€‚è¿™äº›æ¨¡å—ååŒå·¥ä½œï¼Œå®žçŽ°ç«¯åˆ°ç«¯çš„ä»»åŠ¡ä¸Žè¿åŠ¨è§„åˆ’ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽå°†å¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰çš„å¸¸è¯†çŸ¥è¯†å¼•å…¥åˆ°æœºå™¨äººä»»åŠ¡ä¸Žè¿åŠ¨è§„åˆ’ä¸­ã€‚ä¸Žä¼ ç»Ÿçš„åŸºäºŽè§„åˆ™æˆ–ä¼˜åŒ–çš„TAMPæ–¹æ³•ç›¸æ¯”ï¼ŒLLM-GROPèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ä»»åŠ¡ç›®æ ‡ï¼Œå¹¶ç”Ÿæˆæ›´ç¬¦åˆäººç±»å¸¸è¯†çš„è§„åˆ’æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§åŸºäºŽè§†è§‰çš„åŸºåº§ä½ç½®é€‰æ‹©ç­–ç•¥ï¼Œè¿›ä¸€æ­¥æé«˜äº†æœºå™¨äººçš„è¿åŠ¨æ•ˆçŽ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­ä¸€ä¸ªå…³é”®çš„è®¾è®¡æ˜¯åˆ©ç”¨LLMç”Ÿæˆç‰©ä½“ä¹‹é—´çš„å…³ç³»å›¾ï¼Œè¯¥å›¾è¡¨ç¤ºäº†ç‰©ä½“ä¹‹é—´çš„ä¾èµ–å…³ç³»å’Œçº¦æŸã€‚ä¾‹å¦‚ï¼Œåœ¨â€œæ‘†æ”¾é¤æ¡Œâ€ä»»åŠ¡ä¸­ï¼ŒLLMå¯ä»¥ç”Ÿæˆä¸€ä¸ªå…³ç³»å›¾ï¼Œè¡¨ç¤ºç›˜å­åº”è¯¥æ”¾åœ¨æ¡Œå­ä¸Šï¼Œåˆ€å‰åº”è¯¥æ”¾åœ¨ç›˜å­æ—è¾¹ç­‰ã€‚è¯¥å…³ç³»å›¾è¢«ç”¨äºŽæŒ‡å¯¼ä»»åŠ¡çº§è§„åˆ’å’Œè¿åŠ¨è§„åˆ’ï¼Œç¡®ä¿ç”Ÿæˆçš„è§„åˆ’æ–¹æ¡ˆç¬¦åˆäººç±»å¸¸è¯†ã€‚æ­¤å¤–ï¼ŒåŸºåº§ä½ç½®é€‰æ‹©æ¨¡å—é‡‡ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡å­¦ä¹ å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œé¢„æµ‹æœ€ä½³çš„æœºå™¨äººåŸºåº§ä½ç½®ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒLLM-GROPåœ¨çœŸå®žçŽ¯å¢ƒå’Œæ¨¡æ‹ŸçŽ¯å¢ƒä¸­å‡èƒ½æœ‰æ•ˆå®Œæˆé•¿æ—¶ç¨‹ç‰©ä½“é‡æŽ’åˆ—ä»»åŠ¡ã€‚åœ¨çœŸå®žçŽ¯å¢ƒä¸­ï¼Œæœºå™¨äººå®Œæˆäº†84.4%çš„ç‰©ä½“é‡æŽ’åˆ—è¯•éªŒã€‚ä¸»è§‚äººç±»è¯„ä¼°è¡¨æ˜Žï¼Œè™½ç„¶æœºå™¨äººçš„æ€§èƒ½ä»ä½ŽäºŽç»éªŒä¸°å¯Œçš„äººç±»æœåŠ¡å‘˜ï¼Œä½†å·²ç»å±•çŽ°å‡ºè‰¯å¥½çš„åº”ç”¨æ½œåŠ›ã€‚è¯¥ç ”ç©¶è¯æ˜Žäº†åˆ©ç”¨LLMè¾…åŠ©æœºå™¨äººä»»åŠ¡ä¸Žè¿åŠ¨è§„åˆ’çš„å¯è¡Œæ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§éœ€è¦æœºå™¨äººè¿›è¡Œç‰©ä½“é‡æŽ’åˆ—çš„åœºæ™¯ï¼Œä¾‹å¦‚å®¶åº­æœåŠ¡ã€é¤åŽ…æœåŠ¡ã€ä»“å‚¨ç‰©æµç­‰ã€‚é€šè¿‡åˆ©ç”¨LLMçš„å¸¸è¯†çŸ¥è¯†ï¼Œæœºå™¨äººå¯ä»¥æ›´å¥½åœ°ç†è§£äººç±»æŒ‡ä»¤ï¼Œå¹¶å®Œæˆå¤æ‚çš„ä»»åŠ¡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æŽ¨å¹¿åˆ°æ›´å¹¿æ³›çš„æœºå™¨äººåº”ç”¨é¢†åŸŸï¼Œä¾‹å¦‚æ™ºèƒ½åˆ¶é€ ã€åŒ»ç–—æœåŠ¡ç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Task planning and motion planning are two of the most important problems in robotics, where task planning methods help robots achieve high-level goals and motion planning methods maintain low-level feasibility. Task and motion planning (TAMP) methods interleave the two processes of task planning and motion planning to ensure goal achievement and motion feasibility. Within the TAMP context, we are concerned with the mobile manipulation (MoMa) of multiple objects, where it is necessary to interleave actions for navigation and manipulation.
>   In particular, we aim to compute where and how each object should be placed given underspecified goals, such as ``set up dinner table with a fork, knife and plate.'' We leverage the rich common sense knowledge from large language models (LLMs), e.g., about how tableware is organized, to facilitate both task-level and motion-level planning. In addition, we use computer vision methods to learn a strategy for selecting base positions to facilitate MoMa behaviors, where the base position corresponds to the robot's ``footprint'' and orientation in its operating space. Altogether, this article provides a principled TAMP framework for MoMa tasks that accounts for common sense about object rearrangement and is adaptive to novel situations that include many objects that need to be moved. We performed quantitative experiments in both real-world settings and simulated environments. We evaluated the success rate and efficiency in completing long-horizon object rearrangement tasks. While the robot completed 84.4\% real-world object rearrangement trials, subjective human evaluations indicated that the robot's performance is still lower than experienced human waiters.

