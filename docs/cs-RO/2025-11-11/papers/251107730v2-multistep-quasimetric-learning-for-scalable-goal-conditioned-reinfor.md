---
layout: default
title: Multistep Quasimetric Learning for Scalable Goal-conditioned Reinforcement Learning
---

# Multistep Quasimetric Learning for Scalable Goal-conditioned Reinforcement Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.07730" target="_blank" class="toolbar-btn">arXiv: 2511.07730v2</a>
    <a href="https://arxiv.org/pdf/2511.07730.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.07730v2" 
            onclick="toggleFavorite(this, '2511.07730v2', 'Multistep Quasimetric Learning for Scalable Goal-conditioned Reinforcement Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Bill Chunyuan Zheng, Vivek Myers, Benjamin Eysenbach, Sergey Levine

**ÂàÜÁ±ª**: cs.LG, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-11 (Êõ¥Êñ∞: 2025-11-14)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Â§öÊ≠•ÂáÜÂ∫¶ÈáèÂ≠¶‰π†ÔºåËß£ÂÜ≥ÂèØÊâ©Â±ïÁöÑ„ÄÅÈïøÊó∂Á®ãÁõÆÊ†áÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÁõÆÊ†áÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†` `ÂáÜÂ∫¶ÈáèÂ≠¶‰π†` `Â§öÊ≠•ÂõûÊä•` `ÈïøÊó∂Á®ã‰ªªÂä°` `Êú∫Âô®‰∫∫Êìç‰Ωú`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁõÆÊ†áÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†ÔºàGCRLÔºâÊñπÊ≥ïÂú®ÈïøÊó∂Á®ã‰ªªÂä°‰∏≠Èù¢‰∏¥ÊåëÊàòÔºåÈöæ‰ª•ÂáÜÁ°Æ‰º∞ËÆ°ËßÇÊµãÈó¥ÁöÑÊó∂Èó¥Ë∑ùÁ¶ª„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßçÂü∫‰∫éÂ§öÊ≠•ËíôÁâπÂç°Ê¥õÂõûÊä•ÁöÑÂáÜÂ∫¶ÈáèÂ≠¶‰π†ÊñπÊ≥ïÔºåÊó®Âú®Êõ¥ÊúâÊïàÂú∞Â≠¶‰π†ËßÇÊµãÈó¥ÁöÑË∑ùÁ¶ªÂ∫¶Èáè„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®ÈïøÊó∂Á®ãÊ®°Êãü‰ªªÂä°ÂíåÁúüÂÆûÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÔºåÂùá‰ºò‰∫éÁé∞ÊúâGCRLÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®ÁéØÂ¢É‰∏≠Â≠¶‰π†Â¶Ç‰ΩïËææÂà∞ÁõÆÊ†áÊòØ‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüü‰∏Ä‰∏™ÈïøÊúüÂ≠òÂú®ÁöÑÊåëÊàòÔºåÁÑ∂ËÄåÔºåÂØπ‰∫éÁé∞‰ª£ÊñπÊ≥ïÊù•ËØ¥ÔºåÂú®ÈïøÊó∂Á®ã‰∏äËøõË°åÊé®ÁêÜ‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÈöæÈ¢ò„ÄÇÂÖ≥ÈîÆÈóÆÈ¢òÊòØÂ¶Ç‰Ωï‰º∞ËÆ°ËßÇÊµãÂØπ‰πãÈó¥ÁöÑÊó∂Èó¥Ë∑ùÁ¶ª„ÄÇËôΩÁÑ∂Êó∂Â∫èÂ∑ÆÂàÜÊñπÊ≥ïÂà©Áî®Â±ÄÈÉ®Êõ¥Êñ∞Êù•Êèê‰æõÊúÄ‰ºòÊÄß‰øùËØÅÔºå‰ΩÜÂÆÉ‰ª¨ÈÄöÂ∏∏ÊØîÊâßË°åÂÖ®Â±ÄÊõ¥Êñ∞ÁöÑËíôÁâπÂç°Ê¥õÊñπÊ≥ïÔºà‰æãÂ¶ÇÔºå‰ΩøÁî®Â§öÊ≠•ÂõûÊä•ÔºâË°®Áé∞Êõ¥Â∑ÆÔºåËÄåËíôÁâπÂç°Ê¥õÊñπÊ≥ïÁº∫‰πèËøôÁßç‰øùËØÅ„ÄÇÊàë‰ª¨Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞ÜËøô‰∫õÊñπÊ≥ïÈõÜÊàêÂà∞‰∏Ä‰∏™ÂÆûÁî®ÁöÑGCRLÊñπÊ≥ï‰∏≠ÔºåËØ•ÊñπÊ≥ï‰ΩøÁî®Â§öÊ≠•ËíôÁâπÂç°Ê¥õÂõûÊä•Êù•ÊãüÂêàÂáÜÂ∫¶ÈáèË∑ùÁ¶ª„ÄÇÊàë‰ª¨Ë°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ÈïøÊó∂Á®ãÊ®°Êãü‰ªªÂä°ÔºàÊúÄÂ§ö4000Ê≠•Ôºâ‰∏ä‰ºò‰∫éÁé∞ÊúâÁöÑGCRLÊñπÊ≥ïÔºåÂç≥‰Ωø‰ΩøÁî®ËßÜËßâËßÇÊµã‰πüÊòØÂ¶ÇÊ≠§„ÄÇÊàë‰ª¨ËøòËØÅÊòé‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÂèØ‰ª•Âú®ÁúüÂÆû‰∏ñÁïåÁöÑÊú∫Âô®‰∫∫Êìç‰ΩúÈ¢ÜÂüüÔºàBridgeËÆæÁΩÆÔºâ‰∏≠ÂÆûÁé∞ÊãºÊé•„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÊòØÁ¨¨‰∏Ä‰∏™Á´ØÂà∞Á´ØÁöÑGCRLÊñπÊ≥ïÔºåÂèØ‰ª•Âú®Ëøô‰∏™ÁúüÂÆû‰∏ñÁïåÁöÑÊìç‰ΩúÈ¢ÜÂüü‰∏≠Ôºå‰ªéËßÜËßâËßÇÊµãÁöÑÊó†Ê†áÁ≠æÁ¶ªÁ∫øÊï∞ÊçÆÈõÜ‰∏≠ÂÆûÁé∞Â§öÊ≠•ÊãºÊé•„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÁõÆÊ†áÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†ÔºàGCRLÔºâ‰∏≠ÔºåÊô∫ËÉΩ‰ΩìÂú®ÈïøÊó∂Á®ã‰ªªÂä°‰∏≠Èöæ‰ª•ÊúâÊïàÂ≠¶‰π†ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÂ¶ÇÊó∂Â∫èÂ∑ÆÂàÜÊñπÊ≥ïÔºåËôΩÁÑ∂ÂÖ∑ÊúâÂ±ÄÈÉ®ÊúÄ‰ºòÊÄß‰øùËØÅÔºå‰ΩÜÂú®ÈïøÊó∂Á®ã‰ªªÂä°‰∏≠Ë°®Áé∞‰∏ç‰Ω≥„ÄÇËÄåËíôÁâπÂç°Ê¥õÊñπÊ≥ïËôΩÁÑ∂ËÉΩËøõË°åÂÖ®Â±ÄÊõ¥Êñ∞Ôºå‰ΩÜÁº∫‰πèÁêÜËÆ∫‰øùËØÅÔºå‰∏îÊñπÂ∑ÆËæÉÈ´ò„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÁªìÂêà‰∏§ËÄÖÁöÑ‰ºòÁÇπÔºåËÆæËÆ°‰∏ÄÁßçÊó¢ËÉΩÊúâÊïàÂà©Áî®ÂÖ®Â±Ä‰ø°ÊÅØÔºåÂèàËÉΩ‰øùËØÅÂ≠¶‰π†Á®≥ÂÆöÊÄßÁöÑGCRLÊñπÊ≥ïÊòØÊú¨ËÆ∫ÊñáË¶ÅËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÊó∂Â∫èÂ∑ÆÂàÜÊñπÊ≥ïÁöÑÂ±ÄÈÉ®Êõ¥Êñ∞ÂíåËíôÁâπÂç°Ê¥õÊñπÊ≥ïÁöÑÂ§öÊ≠•ÂõûÊä•Áõ∏ÁªìÂêàÔºåÈÄöËøáÂ§öÊ≠•ËíôÁâπÂç°Ê¥õÂõûÊä•Êù•Â≠¶‰π†‰∏Ä‰∏™ÂáÜÂ∫¶ÈáèË∑ùÁ¶ªÂáΩÊï∞„ÄÇËØ•ÂáÜÂ∫¶ÈáèË∑ùÁ¶ªÂáΩÊï∞ËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞‰º∞ËÆ°ËßÇÊµã‰πãÈó¥ÁöÑÊó∂Â∫èË∑ùÁ¶ªÔºå‰ªéËÄåÊåáÂØºÊô∫ËÉΩ‰ΩìÊõ¥Â•ΩÂú∞ÂÆåÊàêÈïøÊó∂Á®ã‰ªªÂä°„ÄÇËøôÁßçÁªìÂêàÂà©Áî®‰∫ÜËíôÁâπÂç°Ê¥õÊñπÊ≥ïÁöÑÂÖ®Â±Ä‰ø°ÊÅØÔºåÂêåÊó∂ÈÄöËøáÂáÜÂ∫¶ÈáèÂ≠¶‰π†Êù•Á∫¶ÊùüÂ≠¶‰π†ËøáÁ®ãÔºåÊèêÈ´òÂ≠¶‰π†ÁöÑÁ®≥ÂÆöÊÄßÂíåÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ï‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1Ôºâ‰ªéÁ¶ªÁ∫øÊï∞ÊçÆÈõÜ‰∏≠ÈááÊ†∑Áä∂ÊÄÅ„ÄÅÁõÆÊ†áÂíåÂä®‰ΩúÂ∫èÂàóÔºõ2Ôºâ‰ΩøÁî®Â§öÊ≠•ËíôÁâπÂç°Ê¥õÂõûÊä•ËÆ°ÁÆóÁä∂ÊÄÅÂíåÁõÆÊ†á‰πãÈó¥ÁöÑÂõûÊä•Ôºõ3Ôºâ‰ΩøÁî®ÂáÜÂ∫¶ÈáèÂ≠¶‰π†ÊñπÊ≥ïÔºåËÆ≠ÁªÉ‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÊù•È¢ÑÊµãÁä∂ÊÄÅÂíåÁõÆÊ†á‰πãÈó¥ÁöÑË∑ùÁ¶ªÔºåËØ•Ë∑ùÁ¶ª‰∏éÂ§öÊ≠•ËíôÁâπÂç°Ê¥õÂõûÊä•Áõ∏‰∏ÄËá¥Ôºõ4Ôºâ‰ΩøÁî®Â≠¶‰π†Âà∞ÁöÑË∑ùÁ¶ªÂáΩÊï∞‰Ωú‰∏∫Â•ñÂä±ÂáΩÊï∞ÔºåËÆ≠ÁªÉÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•„ÄÇÊï¥‰ΩìÊ°ÜÊû∂ÊòØ‰∏Ä‰∏™Á´ØÂà∞Á´ØÁöÑGCRLÊµÅÁ®ãÔºåÂèØ‰ª•‰ªéÊó†Ê†áÁ≠æÁöÑÁ¶ªÁ∫øÊï∞ÊçÆÈõÜ‰∏≠Â≠¶‰π†„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÂ§öÊ≠•ËíôÁâπÂç°Ê¥õÂõûÊä•ÂºïÂÖ•Âà∞ÂáÜÂ∫¶ÈáèÂ≠¶‰π†‰∏≠ÔºåÂπ∂Â∞ÜÂÖ∂Â∫îÁî®‰∫éGCRL„ÄÇ‰∏é‰º†ÁªüÁöÑÂáÜÂ∫¶ÈáèÂ≠¶‰π†ÊñπÊ≥ï‰∏çÂêåÔºåËØ•ÊñπÊ≥ïÂà©Áî®Â§öÊ≠•ÂõûÊä•Êù•Êèê‰æõÊõ¥‰∏∞ÂØåÁöÑÁõëÁù£‰ø°Âè∑Ôºå‰ªéËÄåÂ≠¶‰π†Âà∞Êõ¥ÂáÜÁ°ÆÁöÑË∑ùÁ¶ªÂ∫¶Èáè„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÊòØÁ¨¨‰∏Ä‰∏™Á´ØÂà∞Á´ØÁöÑGCRLÊñπÊ≥ïÔºåÂèØ‰ª•Âú®ÁúüÂÆû‰∏ñÁïåÁöÑÊú∫Âô®‰∫∫Êìç‰ΩúÈ¢ÜÂüü‰∏≠Ôºå‰ªéËßÜËßâËßÇÊµãÁöÑÊó†Ê†áÁ≠æÁ¶ªÁ∫øÊï∞ÊçÆÈõÜ‰∏≠ÂÆûÁé∞Â§öÊ≠•ÊãºÊé•„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰ΩøÁî®Á•ûÁªèÁΩëÁªúÊù•Ë°®Á§∫ÂáÜÂ∫¶ÈáèË∑ùÁ¶ªÂáΩÊï∞ÔºåÊçüÂ§±ÂáΩÊï∞ÈááÁî®ÂùáÊñπËØØÂ∑ÆÊçüÂ§±ÔºåÁî®‰∫éË°°ÈáèÈ¢ÑÊµãË∑ùÁ¶ª‰∏éÂ§öÊ≠•ËíôÁâπÂç°Ê¥õÂõûÊä•‰πãÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇÂ§öÊ≠•ÂõûÊä•ÁöÑÊ≠•Êï∞ÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÂèÇÊï∞ÔºåÈúÄË¶ÅÊ†πÊçÆ‰ªªÂä°ÁöÑÈïøÂ∫¶ËøõË°åË∞ÉÊï¥„ÄÇÁΩëÁªúÁªìÊûÑÁöÑÈÄâÊã©‰πüÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰Ωì‰ªªÂä°ËøõË°åË∞ÉÊï¥Ôºå‰æãÂ¶ÇÔºåÂØπ‰∫éËßÜËßâ‰ªªÂä°ÔºåÂèØ‰ª•‰ΩøÁî®Âç∑ÁßØÁ•ûÁªèÁΩëÁªúÊù•ÊèêÂèñÂõæÂÉèÁâπÂæÅ„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫ÜÊèêÈ´òÂ≠¶‰π†ÁöÑÁ®≥ÂÆöÊÄßÔºåÂèØ‰ª•‰ΩøÁî®‰∏Ä‰∫õÊ≠£ÂàôÂåñÊäÄÊúØÔºå‰æãÂ¶ÇÊùÉÈáçË°∞ÂáèÂíådropout„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËØ•ÊñπÊ≥ïÂú®ÈïøÊó∂Á®ãÊ®°Êãü‰ªªÂä°ÔºàÊúÄÈïø4000Ê≠•Ôºâ‰∏≠ÔºåÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑGCRLÊñπÊ≥ï„ÄÇÂú®ÁúüÂÆû‰∏ñÁïåÁöÑÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°ÔºàBridge setupÔºâ‰∏≠ÔºåËØ•ÊñπÊ≥ïÊàêÂäüÂÆûÁé∞‰∫ÜÂ§öÊ≠•ÊãºÊé•ÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™Á´ØÂà∞Á´ØÁöÑGCRLÊñπÊ≥ïÂú®ËØ•È¢ÜÂüüÂèñÂæóÁöÑÊàêÊûú„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞Â≠¶‰π†ÁéØÂ¢É‰∏≠ÁöÑË∑ùÁ¶ªÂ∫¶ÈáèÔºåÂπ∂Â∞ÜÂÖ∂Â∫îÁî®‰∫éÈïøÊó∂Á®ã‰ªªÂä°„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊ∏∏ÊàèAIÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÂ≠¶‰π†ÁéØÂ¢É‰∏≠ÁöÑË∑ùÁ¶ªÂ∫¶ÈáèÔºåÊô∫ËÉΩ‰ΩìÂèØ‰ª•Êõ¥Â•ΩÂú∞ËßÑÂàíË∑ØÂæÑ„ÄÅÂÆåÊàêÂ§çÊùÇ‰ªªÂä°„ÄÇÁâπÂà´ÊòØÂú®ÁúüÂÆûÊú∫Âô®‰∫∫Êìç‰ΩúÈ¢ÜÂüüÔºåËØ•ÊñπÊ≥ïËÉΩÂ§ü‰ªéÊó†Ê†áÁ≠æÁöÑÁ¶ªÁ∫øÊï∞ÊçÆ‰∏≠Â≠¶‰π†ÔºåÈôç‰Ωé‰∫ÜÊï∞ÊçÆÊî∂ÈõÜÁöÑÊàêÊú¨ÔºåÂä†ÈÄü‰∫ÜÊú∫Âô®‰∫∫Êô∫ËÉΩÂåñÁöÑËøõÁ®ã„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÂ∫îÁî®‰∫éÊõ¥Â§çÊùÇÁöÑÁéØÂ¢ÉÂíå‰ªªÂä°Ôºå‰æãÂ¶ÇÂ§öÊô∫ËÉΩ‰ΩìÂçè‰Ωú„ÄÅ‰∫∫Êú∫‰∫§‰∫íÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Learning how to reach goals in an environment is a longstanding challenge in AI, yet reasoning over long horizons remains a challenge for modern methods. The key question is how to estimate the temporal distance between pairs of observations. While temporal difference methods leverage local updates to provide optimality guarantees, they often perform worse than Monte Carlo methods that perform global updates (e.g., with multi-step returns), which lack such guarantees. We show how these approaches can be integrated into a practical GCRL method that fits a quasimetric distance using a multistep Monte-Carlo return. We show our method outperforms existing GCRL methods on long-horizon simulated tasks with up to 4000 steps, even with visual observations. We also demonstrate that our method can enable stitching in the real-world robotic manipulation domain (Bridge setup). Our approach is the first end-to-end GCRL method that enables multistep stitching in this real-world manipulation domain from an unlabeled offline dataset of visual observations.

