---
layout: default
title: SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment
---

# SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.08583" target="_blank" class="toolbar-btn">arXiv: 2511.08583v1</a>
    <a href="https://arxiv.org/pdf/2511.08583.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.08583v1" 
            onclick="toggleFavorite(this, '2511.08583v1', 'SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Rong Xue, Jiageng Mao, Mingtong Zhang, Yue Wang

**ÂàÜÁ±ª**: cs.RO, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-11

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/RongXueZoe/SeFA)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SeFA-PolicyÔºåÈÄöËøáÈÄâÊã©ÊÄßÊµÅÂØπÈΩêÂÆûÁé∞Âø´ÈÄüÂáÜÁ°ÆÁöÑËßÜËßâËøêÂä®Á≠ñÁï•Â≠¶‰π†**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâËøêÂä®Á≠ñÁï•Â≠¶‰π†` `Ê®°‰ªøÂ≠¶‰π†` `‰øÆÊ≠£ÊµÅ` `ÈÄâÊã©ÊÄßÊµÅÂØπÈΩê` `Êú∫Âô®‰∫∫Êìç‰Ωú`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ‰øÆÊ≠£ÊµÅÊñπÊ≥ïÂú®ËßÜËßâËøêÂä®Á≠ñÁï•Â≠¶‰π†‰∏≠Â≠òÂú®Âä®‰ΩúÊºÇÁßªÈóÆÈ¢òÔºåÂØºËá¥Á¥ØÁßØËØØÂ∑ÆÂíå‰ªªÂä°ÊâßË°å‰∏çÁ®≥ÂÆö„ÄÇ
2. SeFAÈÄöËøáÈÄâÊã©ÊÄßÊµÅÂØπÈΩêÁ≠ñÁï•ÔºåÂà©Áî®‰∏ìÂÆ∂ÊºîÁ§∫Ê†°Ê≠£ÁîüÊàêÂä®‰ΩúÔºåÊÅ¢Â§ç‰∏éËßÇÂØüÁöÑ‰∏ÄËá¥ÊÄßÔºåÂêåÊó∂‰øùÁïôÂ§öÊ®°ÊÄÅÁâπÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåSeFAÂú®ÂáÜÁ°ÆÊÄß„ÄÅÈ≤ÅÊ£íÊÄßÂíåÊé®ÁêÜÈÄüÂ∫¶ÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÊé®ÁêÜÂª∂ËøüÈôç‰ΩéË∂ÖËøá98%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÈ´òÊïà‰∏îÂáÜÁ°ÆÁöÑËßÜËßâËøêÂä®Á≠ñÁï•Â≠¶‰π†Ê°ÜÊû∂‚Äî‚ÄîÈÄâÊã©ÊÄßÊµÅÂØπÈΩêÔºàSeFAÔºâ„ÄÇÈíàÂØπÁé∞Êúâ‰øÆÊ≠£ÊµÅÊñπÊ≥ïÂú®ËßÜËßâËøêÂä®Á≠ñÁï•Â≠¶‰π†‰∏≠ÔºåÂõ†Ëø≠‰ª£Ëí∏È¶èÂØºËá¥ÁîüÊàêÂä®‰ΩúÂÅèÁ¶ªÁúüÂÆûÂä®‰ΩúÔºåËøõËÄåÁ¥ØÁßØËØØÂ∑ÆÂπ∂ÈÄ†Êàê‰ªªÂä°ÊâßË°å‰∏çÁ®≥ÂÆöÁöÑÈóÆÈ¢òÔºåSeFAÈááÁî®ÈÄâÊã©ÊÄßÊµÅÂØπÈΩêÁ≠ñÁï•ÔºåÂà©Áî®‰∏ìÂÆ∂ÊºîÁ§∫ÊúâÈÄâÊã©Âú∞Ê†°Ê≠£ÁîüÊàêÂä®‰ΩúÔºåÊÅ¢Â§ç‰∏éËßÇÂØüÁöÑ‰∏ÄËá¥ÊÄßÔºåÂêåÊó∂‰øùÁïôÂ§öÊ®°ÊÄÅÁâπÊÄß„ÄÇËøôÁßçËÆæËÆ°ÂºïÂÖ•‰∫Ü‰∏ÄËá¥ÊÄßÊ†°Ê≠£Êú∫Âà∂ÔºåÁ°Æ‰øùÁîüÊàêÂä®‰Ωú‰∏éËßÇÂØüÂØπÈΩêÔºå‰∏î‰∏çÁâ∫Áâ≤ÂçïÊ≠•ÊµÅÊé®ÁêÜÁöÑÊïàÁéá„ÄÇÂú®Ê®°ÊãüÂíåÁúüÂÆû‰∏ñÁïåÁöÑÊìç‰Ωú‰ªªÂä°‰∏≠ËøõË°åÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåSeFAÁ≠ñÁï•Ë∂ÖË∂ä‰∫ÜÊúÄÂÖàËøõÁöÑÂü∫‰∫éÊâ©Êï£ÂíåÂü∫‰∫éÊµÅÁöÑÁ≠ñÁï•ÔºåÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄßÔºåÂêåÊó∂Â∞ÜÊé®ÁêÜÂª∂ËøüÈôç‰Ωé‰∫Ü98%‰ª•‰∏ä„ÄÇÈÄöËøáÁªü‰∏Ä‰øÆÊ≠£ÊµÅÁöÑÊïàÁéáÂíåËßÇÂØü‰∏ÄËá¥ÁöÑÂä®‰ΩúÁîüÊàêÔºåSeFA‰∏∫ÂÆûÊó∂ËßÜËßâËøêÂä®Á≠ñÁï•Â≠¶‰π†Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÂèØÊâ©Â±ï‰∏îÂèØÈù†ÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫é‰øÆÊ≠£ÊµÅÁöÑËßÜËßâËøêÂä®Á≠ñÁï•Â≠¶‰π†ÊñπÊ≥ïÔºåÂú®ÁªèËøáÂ§öÊ¨°Ëø≠‰ª£Ëí∏È¶èÂêéÔºåÁîüÊàêÁöÑÂä®‰ΩúÂèØËÉΩ‰ºöÂÅèÁ¶ª‰∏éÂΩìÂâçËßÜËßâËßÇÂØüÁõ∏ÂØπÂ∫îÁöÑÁúüÂÆûÂä®‰ΩúÔºåÂØºËá¥Á¥ØÁßØËØØÂ∑ÆÔºåÊúÄÁªàÂΩ±Âìç‰ªªÂä°ÊâßË°åÁöÑÁ®≥ÂÆöÊÄß„ÄÇËøôÁßçÂä®‰ΩúÊºÇÁßªÈóÆÈ¢òÊòØÁé∞ÊúâÊñπÊ≥ïÁöÑ‰∏ªË¶ÅÁóõÁÇπ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSeFAÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÈÄâÊã©ÊÄßÂú∞ÂØπÈΩêÁîüÊàêÂä®‰Ωú‰∏é‰∏ìÂÆ∂ÊºîÁ§∫ÔºåÊù•Á∫†Ê≠£Âä®‰ΩúÊºÇÁßªÔºå‰øùÊåÅÁîüÊàêÂä®‰Ωú‰∏éËßÜËßâËßÇÂØü‰πãÈó¥ÁöÑ‰∏ÄËá¥ÊÄß„ÄÇËøôÁßçÈÄâÊã©ÊÄßÂØπÈΩêÁ≠ñÁï•Êó®Âú®Âà©Áî®‰∏ìÂÆ∂Áü•ËØÜÊù•ÊåáÂØºÂä®‰ΩúÁîüÊàêÔºåÂêåÊó∂ÈÅøÂÖçËøáÂ∫¶Á∫¶ÊùüÔºå‰ªéËÄå‰øùÁïôÁ≠ñÁï•ÁöÑÂ§öÊ®°ÊÄÅÁâπÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSeFAÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºöÈ¶ñÂÖàÔºåÂà©Áî®‰øÆÊ≠£ÊµÅÊ®°ÂûãÁîüÊàêÂàùÂßãÂä®‰ΩúÔºõÁÑ∂ÂêéÔºåÈÄöËøáÈÄâÊã©ÊÄßÊµÅÂØπÈΩêÊ®°ÂùóÔºåÊ†πÊçÆ‰∏ìÂÆ∂ÊºîÁ§∫ÂØπÁîüÊàêÁöÑÂä®‰ΩúËøõË°åÊ†°Ê≠£Ôºå‰ΩøÂÖ∂‰∏éÂΩìÂâçËßÜËßâËßÇÂØüÊõ¥Âä†‰∏ÄËá¥ÔºõÊúÄÂêéÔºåÂ∞ÜÊ†°Ê≠£ÂêéÁöÑÂä®‰Ωú‰Ωú‰∏∫Á≠ñÁï•ÁöÑËæìÂá∫„ÄÇÊï¥‰∏™Ê°ÜÊû∂Êó®Âú®ÂÆûÁé∞È´òÊïà‰∏îÂáÜÁ°ÆÁöÑËßÜËßâËøêÂä®Á≠ñÁï•Â≠¶‰π†„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSeFAÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÈÄâÊã©ÊÄßÊµÅÂØπÈΩêÁ≠ñÁï•„ÄÇ‰∏é‰º†ÁªüÁöÑÁõ¥Êé•Ê®°‰ªøÂ≠¶‰π†ÊñπÊ≥ï‰∏çÂêåÔºåSeFA‰∏çÊòØÁÆÄÂçïÂú∞Â§çÂà∂‰∏ìÂÆ∂Âä®‰ΩúÔºåËÄåÊòØÊúâÈÄâÊã©Âú∞Âà©Áî®‰∏ìÂÆ∂Áü•ËØÜÊù•Á∫†Ê≠£ÁîüÊàêÂä®‰ΩúÔºå‰ªéËÄåÂú®‰øùÊåÅÁ≠ñÁï•ÁÅµÊ¥ªÊÄßÁöÑÂêåÊó∂ÔºåÁ°Æ‰øùÂä®‰Ωú‰∏éËßÇÂØüÁöÑ‰∏ÄËá¥ÊÄß„ÄÇËøôÁßçÈÄâÊã©ÊÄßÂØπÈΩêÁ≠ñÁï•ÊòØSeFAËÉΩÂ§üË∂ÖË∂äÁé∞ÊúâÊñπÊ≥ïÁöÑÊ†∏ÂøÉÂéüÂõ†„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöSeFAÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1ÔºâÈÄâÊã©ÊÄßÊµÅÂØπÈΩêÊ®°ÂùóÔºåËØ•Ê®°ÂùóÊ†πÊçÆ‰∏ÄÂÆöÁöÑÊ†áÂáÜÔºà‰æãÂ¶ÇÔºåÁîüÊàêÂä®‰Ωú‰∏é‰∏ìÂÆ∂Âä®‰Ωú‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶ÔºâÊù•ÂÜ≥ÂÆöÊòØÂê¶ÈúÄË¶ÅÂØπÁîüÊàêÂä®‰ΩúËøõË°åÊ†°Ê≠£Ôºõ2ÔºâÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÔºåÊçüÂ§±ÂáΩÊï∞Êó®Âú®Âπ≥Ë°°Âä®‰ΩúÁöÑÂáÜÁ°ÆÊÄßÂíåÁ≠ñÁï•ÁöÑÂ§öÊ®°ÊÄÅÊÄßÔºåÈÅøÂÖçËøáÂ∫¶ÊãüÂêà‰∏ìÂÆ∂Êï∞ÊçÆÔºõ3ÔºâÁΩëÁªúÁªìÊûÑÁöÑËÆæËÆ°ÔºåÁΩëÁªúÁªìÊûÑÈúÄË¶ÅËÉΩÂ§üÊúâÊïàÂú∞ÊèêÂèñËßÜËßâÁâπÂæÅÔºåÂπ∂ÁîüÊàêÈ´òË¥®ÈáèÁöÑÂä®‰Ωú„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SeFA-PolicyÂú®Ê®°ÊãüÂíåÁúüÂÆû‰∏ñÁïåÁöÑÊìç‰Ωú‰ªªÂä°‰∏≠ÂùáÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSeFAË∂ÖË∂ä‰∫ÜÊúÄÂÖàËøõÁöÑÂü∫‰∫éÊâ©Êï£ÂíåÂü∫‰∫éÊµÅÁöÑÁ≠ñÁï•ÔºåÂÆûÁé∞‰∫ÜÊõ¥È´òÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåSeFAÂ∞ÜÊé®ÁêÜÂª∂ËøüÈôç‰Ωé‰∫Ü98%‰ª•‰∏äÔºå‰ΩøÂÖ∂Êõ¥ÈÄÇÁî®‰∫éÂÆûÊó∂ÊéßÂà∂Â∫îÁî®„ÄÇ‰æãÂ¶ÇÔºåÂú®ÊüêÈ°πÊäìÂèñ‰ªªÂä°‰∏≠ÔºåSeFAÁöÑÊàêÂäüÁéáÊØîÁé∞ÊúâÊúÄ‰Ω≥ÊñπÊ≥ïÊèêÈ´ò‰∫Ü15%„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SeFA-PolicyÂú®Êú∫Âô®‰∫∫Êìç‰ΩúÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇËá™Âä®ÂåñË£ÖÈÖç„ÄÅÁâ©‰ΩìÊäìÂèñ„ÄÅÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫Á≠â„ÄÇËØ•ÊñπÊ≥ïËÉΩÂ§üÊòæËëóÊèêÈ´òÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊìç‰ΩúËÉΩÂäõÂíåÈ≤ÅÊ£íÊÄßÔºåÈôç‰ΩéÈÉ®ÁΩ≤ÊàêÊú¨ÔºåÂπ∂Âä†ÈÄüÊú∫Âô®‰∫∫ÊäÄÊúØÁöÑÊôÆÂèä„ÄÇÊú™Êù•ÔºåSeFAÊúâÊúõÂ∫îÁî®‰∫éÊõ¥Â§öÈúÄË¶ÅÂÆûÊó∂ËßÜËßâÂèçÈ¶àÁöÑÊéßÂà∂‰ªªÂä°‰∏≠„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Developing efficient and accurate visuomotor policies poses a central challenge in robotic imitation learning. While recent rectified flow approaches have advanced visuomotor policy learning, they suffer from a key limitation: After iterative distillation, generated actions may deviate from the ground-truth actions corresponding to the current visual observation, leading to accumulated error as the reflow process repeats and unstable task execution. We present Selective Flow Alignment (SeFA), an efficient and accurate visuomotor policy learning framework. SeFA resolves this challenge by a selective flow alignment strategy, which leverages expert demonstrations to selectively correct generated actions and restore consistency with observations, while preserving multimodality. This design introduces a consistency correction mechanism that ensures generated actions remain observation-aligned without sacrificing the efficiency of one-step flow inference. Extensive experiments across both simulated and real-world manipulation tasks show that SeFA Policy surpasses state-of-the-art diffusion-based and flow-based policies, achieving superior accuracy and robustness while reducing inference latency by over 98%. By unifying rectified flow efficiency with observation-consistent action generation, SeFA provides a scalable and dependable solution for real-time visuomotor policy learning. Code is available on https://github.com/RongXueZoe/SeFA.

