---
layout: default
title: Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks
---

# Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks

**arXiv**: [2511.08086v2](https://arxiv.org/abs/2511.08086) | [PDF](https://arxiv.org/pdf/2511.08086.pdf)

**ä½œè€…**: Muthukumar Pandaram, Jakob Hollenstein, David Drexel, Samuele Tosatto, Antonio RodrÃ­guez-SÃ¡nchez, Justus Piater

**åˆ†ç±»**: cs.LG, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11 (æ›´æ–°: 2025-11-14)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºæœºå™¨äººå¼ºåŒ–å­¦ä¹ çŽ¯å¢ƒåŠ¨æ€ç¨€ç–æ€§çš„æŒ‘æˆ˜ä¸Žç‰¹æ€§ï¼Œä¸ºä¸–ç•Œæ¨¡åž‹å­¦ä¹ æä¾›æ–°è§†è§’**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `ä¸–ç•Œæ¨¡åž‹` `åŠ¨æ€ç¨€ç–æ€§` `æœºå™¨äººå¼ºåŒ–å­¦ä¹ ` `MuJoCo` `å½’çº³åç½®`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰ä¸–ç•Œæ¨¡åž‹å­¦ä¹ æ–¹æ³•å¸¸ä¾èµ–äºŽåŠ¨æ€ç³»ç»Ÿçš„ç¨€ç–æ€§å‡è®¾ï¼Œä½†ç¼ºä¹å¯¹çœŸå®žæœºå™¨äººçŽ¯å¢ƒåŠ¨æ€ç‰¹æ€§çš„æ·±å…¥åˆ†æžã€‚
2. æœ¬ç ”ç©¶é€šè¿‡åˆ†æž MuJoCo Playground çŽ¯å¢ƒï¼Œæ­ç¤ºäº†åŠ¨æ€ç¨€ç–æ€§å¹¶éžå…¨å±€æ€§è´¨ï¼Œè€Œæ˜¯å±€éƒ¨ä¸”çŠ¶æ€ç›¸å…³çš„ã€‚
3. ç ”ç©¶ç»“æžœè¡¨æ˜Žï¼Œåº”è®¾è®¡æ›´ç¬¦åˆçœŸå®žçŽ¯å¢ƒåŠ¨æ€ç‰¹æ€§çš„å½’çº³åç½®ï¼Œä»¥æå‡ä¸–ç•Œæ¨¡åž‹å­¦ä¹ çš„æ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ è¯„ä¼°äº†æœºå™¨äººå¼ºåŒ–å­¦ä¹ ä¸­ä¸–ç•Œæ¨¡åž‹å­¦ä¹ çš„å¸¸è§ç¨€ç–æ€§å‡è®¾ã€‚é€šè¿‡åˆ†æž MuJoCo Playground åŸºå‡†æµ‹è¯•å¥—ä»¶ä¸­çœŸå®žçŽ¯å¢ƒçš„åŠ¨æ€ç‰¹æ€§ï¼ŒæŽ¢ç©¶äº†çŽ¯å¢ƒåŠ¨æ€çš„å› æžœå›¾æ˜¯å¦ç¨€ç–ã€è¿™ç§ç¨€ç–æ€§æ˜¯å¦ä¾èµ–äºŽçŠ¶æ€ï¼Œä»¥åŠå±€éƒ¨ç³»ç»ŸåŠ¨æ€æ˜¯å¦ç¨€ç–å˜åŒ–ã€‚ç»“æžœè¡¨æ˜Žï¼Œå…¨å±€ç¨€ç–æ€§å¾ˆå°‘è§ï¼Œä»»åŠ¡è¡¨çŽ°å‡ºå±€éƒ¨ã€çŠ¶æ€ç›¸å…³çš„ç¨€ç–æ€§ï¼Œå¹¶ä¸”è¿™ç§ç¨€ç–æ€§å‘ˆçŽ°å‡ºç‹¬ç‰¹çš„ç»“æž„ï¼Œä¾‹å¦‚åœ¨æŽ¥è§¦äº‹ä»¶æœŸé—´ä»¥æ—¶é—´å±€éƒ¨åŒ–çš„ç°‡å½¢å¼å‡ºçŽ°ï¼Œå¹¶å½±å“çŠ¶æ€ç»´åº¦çš„ç‰¹å®šå­é›†ã€‚è¿™äº›å‘çŽ°æŒ‘æˆ˜äº†åŠ¨æ€å­¦ä¹ ä¸­å¸¸è§çš„ç¨€ç–æ€§å…ˆéªŒå‡è®¾ï¼Œå¼ºè°ƒéœ€è¦åæ˜ çœŸå®žä¸–ç•ŒåŠ¨æ€çš„çŠ¶æ€ç›¸å…³ç¨€ç–æ€§ç»“æž„çš„å½’çº³åç½®ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰ä¸–ç•Œæ¨¡åž‹å­¦ä¹ æ–¹æ³•é€šå¸¸å‡è®¾çŽ¯å¢ƒåŠ¨æ€å…·æœ‰å…¨å±€ç¨€ç–æ€§æˆ–æ—¶é—´ç¨€ç–æ€§ï¼Œå³æœªæ¥çš„çŠ¶æ€å˜é‡ä»…ä¾èµ–äºŽå½“å‰çŠ¶æ€å˜é‡çš„ä¸€ä¸ªå°å­é›†ï¼Œæˆ–è€…å±€éƒ¨åŠ¨æ€å˜åŒ–ç¨€ç–ä¸”çªç„¶ã€‚ç„¶è€Œï¼Œè¿™äº›å‡è®¾æ˜¯å¦é€‚ç”¨äºŽçœŸå®žçš„æœºå™¨äººå¼ºåŒ–å­¦ä¹ çŽ¯å¢ƒå°šä¸æ˜Žç¡®ã€‚çŽ°æœ‰æ–¹æ³•å¯èƒ½å› ä¸ºä½¿ç”¨äº†ä¸åˆé€‚çš„ç¨€ç–æ€§å…ˆéªŒè€Œé™åˆ¶äº†æ¨¡åž‹çš„å­¦ä¹ èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬ç ”ç©¶çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åˆ†æžçœŸå®žæœºå™¨äººå¼ºåŒ–å­¦ä¹ çŽ¯å¢ƒçš„åŠ¨æ€ç‰¹æ€§ï¼ŒéªŒè¯çŽ°æœ‰ç¨€ç–æ€§å‡è®¾çš„æœ‰æ•ˆæ€§ï¼Œå¹¶æ­ç¤ºçœŸå®žçŽ¯å¢ƒåŠ¨æ€çš„ç¨€ç–æ€§ç»“æž„ã€‚é€šè¿‡å¯¹ MuJoCo Playground çŽ¯å¢ƒçš„ ground-truth åŠ¨æ€è¿›è¡Œåˆ†æžï¼ŒæŽ¢ç©¶çŽ¯å¢ƒåŠ¨æ€çš„å› æžœå›¾æ˜¯å¦ç¨€ç–ï¼Œè¿™ç§ç¨€ç–æ€§æ˜¯å¦ä¾èµ–äºŽçŠ¶æ€ï¼Œä»¥åŠå±€éƒ¨ç³»ç»ŸåŠ¨æ€æ˜¯å¦ç¨€ç–å˜åŒ–ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæœ¬ç ”ç©¶çš„æŠ€æœ¯æ¡†æž¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) é€‰æ‹© MuJoCo Playground åŸºå‡†æµ‹è¯•å¥—ä»¶ä¸­çš„å¤šä¸ªæœºå™¨äººå¼ºåŒ–å­¦ä¹ çŽ¯å¢ƒï¼›2) èŽ·å–æ¯ä¸ªçŽ¯å¢ƒçš„ ground-truth åŠ¨æ€æ•°æ®ï¼›3) åˆ†æžçŽ¯å¢ƒåŠ¨æ€çš„å› æžœå›¾ï¼Œè¯„ä¼°å…¶ç¨€ç–æ€§ï¼›4) åˆ†æžç¨€ç–æ€§ä¸ŽçŠ¶æ€çš„ä¾èµ–å…³ç³»ï¼›5) åˆ†æžå±€éƒ¨ç³»ç»ŸåŠ¨æ€çš„å˜åŒ–æƒ…å†µï¼Œè¯„ä¼°å…¶æ—¶é—´ç¨€ç–æ€§ã€‚ç ”ç©¶ä½¿ç”¨äº†çŽ°æœ‰çš„å›¾åˆ†æžå’Œæ—¶é—´åºåˆ—åˆ†æžæ–¹æ³•æ¥å®Œæˆä¸Šè¿°æ­¥éª¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºŽå¯¹æœºå™¨äººå¼ºåŒ–å­¦ä¹ çŽ¯å¢ƒä¸­åŠ¨æ€ç¨€ç–æ€§çš„æ·±å…¥åˆ†æžã€‚ç ”ç©¶å‘çŽ°ï¼Œå…¨å±€ç¨€ç–æ€§å¾ˆå°‘è§ï¼Œä»»åŠ¡è¡¨çŽ°å‡ºå±€éƒ¨ã€çŠ¶æ€ç›¸å…³çš„ç¨€ç–æ€§ï¼Œå¹¶ä¸”è¿™ç§ç¨€ç–æ€§å‘ˆçŽ°å‡ºç‹¬ç‰¹çš„ç»“æž„ã€‚è¿™ä¸€å‘çŽ°æŒ‘æˆ˜äº†åŠ¨æ€å­¦ä¹ ä¸­å¸¸è§çš„ç¨€ç–æ€§å…ˆéªŒå‡è®¾ï¼Œä¸ºè®¾è®¡æ›´ç¬¦åˆçœŸå®žçŽ¯å¢ƒåŠ¨æ€ç‰¹æ€§çš„å½’çº³åç½®æä¾›äº†æ–°çš„æ€è·¯ã€‚

**å…³é”®è®¾è®¡**ï¼šæœ¬ç ”ç©¶çš„å…³é”®è®¾è®¡åœ¨äºŽé€‰æ‹© MuJoCo Playground ä½œä¸ºåˆ†æžå¯¹è±¡ï¼Œå› ä¸ºå®ƒæä¾›äº† ground-truth çš„åŠ¨æ€ä¿¡æ¯ï¼Œé¿å…äº†ä»Žæ•°æ®ä¸­å­¦ä¹ åŠ¨æ€æ¨¡åž‹å¸¦æ¥çš„è¯¯å·®ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜ä½¿ç”¨äº†å¤šç§åˆ†æžæ–¹æ³•æ¥è¯„ä¼°ç¨€ç–æ€§ï¼ŒåŒ…æ‹¬å›¾åˆ†æžã€çŠ¶æ€ä¾èµ–æ€§åˆ†æžå’Œæ—¶é—´åºåˆ—åˆ†æžã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æž„å–å†³äºŽæ‰€ä½¿ç”¨çš„åˆ†æžæ–¹æ³•ï¼Œè®ºæ–‡ä¸­æœªè¯¦ç»†æè¿°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

ç ”ç©¶ç»“æžœè¡¨æ˜Žï¼Œå…¨å±€ç¨€ç–æ€§åœ¨ MuJoCo Playground çŽ¯å¢ƒä¸­å¾ˆå°‘è§ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯å±€éƒ¨ã€çŠ¶æ€ç›¸å…³çš„ç¨€ç–æ€§ã€‚è¿™ç§ç¨€ç–æ€§å‘ˆçŽ°å‡ºç‹¬ç‰¹çš„ç»“æž„ï¼Œä¾‹å¦‚åœ¨æŽ¥è§¦äº‹ä»¶æœŸé—´ä»¥æ—¶é—´å±€éƒ¨åŒ–çš„ç°‡å½¢å¼å‡ºçŽ°ï¼Œå¹¶å½±å“çŠ¶æ€ç»´åº¦çš„ç‰¹å®šå­é›†ã€‚è¿™äº›å‘çŽ°æŒ‘æˆ˜äº†çŽ°æœ‰æ–¹æ³•ä¸­å¸¸ç”¨çš„å…¨å±€ç¨€ç–æ€§å‡è®¾ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæœºå™¨äººå¼ºåŒ–å­¦ä¹ é¢†åŸŸï¼Œé€šè¿‡è®¾è®¡æ›´ç¬¦åˆçœŸå®žçŽ¯å¢ƒåŠ¨æ€ç‰¹æ€§çš„å½’çº³åç½®ï¼Œæå‡ä¸–ç•Œæ¨¡åž‹çš„å­¦ä¹ æ•ˆçŽ‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥è®¾è®¡çŠ¶æ€ç›¸å…³çš„ç¨€ç–è¿žæŽ¥ç½‘ç»œï¼Œæˆ–è€…ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥åŠ¨æ€åœ°é€‰æ‹©é‡è¦çš„çŠ¶æ€å˜é‡ã€‚è¿™æœ‰åŠ©äºŽæœºå™¨äººæ›´å¥½åœ°ç†è§£å’Œé¢„æµ‹çŽ¯å¢ƒåŠ¨æ€ï¼Œä»Žè€Œå®žçŽ°æ›´é«˜æ•ˆçš„æŽ§åˆ¶å’Œå†³ç­–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The use of learned dynamics models, also known as world models, can improve the sample efficiency of reinforcement learning. Recent work suggests that the underlying causal graphs of such dynamics models are sparsely connected, with each of the future state variables depending only on a small subset of the current state variables, and that learning may therefore benefit from sparsity priors. Similarly, temporal sparsity, i.e. sparsely and abruptly changing local dynamics, has also been proposed as a useful inductive bias.
>   In this work, we critically examine these assumptions by analyzing ground-truth dynamics from a set of robotic reinforcement learning environments in the MuJoCo Playground benchmark suite, aiming to determine whether the proposed notions of state and temporal sparsity actually tend to hold in typical reinforcement learning tasks.
>   We study (i) whether the causal graphs of environment dynamics are sparse, (ii) whether such sparsity is state-dependent, and (iii) whether local system dynamics change sparsely.
>   Our results indicate that global sparsity is rare, but instead the tasks show local, state-dependent sparsity in their dynamics and this sparsity exhibits distinct structures, appearing in temporally localized clusters (e.g., during contact events) and affecting specific subsets of state dimensions. These findings challenge common sparsity prior assumptions in dynamics learning, emphasizing the need for grounded inductive biases that reflect the state-dependent sparsity structure of real-world dynamics.

