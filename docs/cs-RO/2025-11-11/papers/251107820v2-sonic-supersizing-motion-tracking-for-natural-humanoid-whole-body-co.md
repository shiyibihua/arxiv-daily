---
layout: default
title: SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control
---

# SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control

**arXiv**: [2511.07820v2](https://arxiv.org/abs/2511.07820) | [PDF](https://arxiv.org/pdf/2511.07820.pdf)

**ä½œè€…**: Zhengyi Luo, Ye Yuan, Tingwu Wang, Chenran Li, Sirui Chen, Fernando CastaÃ±eda, Zi-Ang Cao, Jiefeng Li, David Minor, Qingwei Ben, Xingye Da, Runyu Ding, Cyrus Hogg, Lina Song, Edy Lim, Eugene Jeong, Tairan He, Haoru Xue, Wenli Xiao, Zi Wang, Simon Yuen, Jan Kautz, Yan Chang, Umar Iqbal, Linxi "Jim" Fan, Yuke Zhu

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV, cs.GR, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-11-11 (æ›´æ–°: 2025-12-04)

**å¤‡æ³¨**: Project page: https://nvlabs.github.io/SONIC/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SONICï¼šé€šè¿‡å¤§è§„æ¨¡è¿åŠ¨è·Ÿè¸ªå®žçŽ°è‡ªç„¶çš„äººå½¢å…¨èº«æŽ§åˆ¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `äººå½¢æœºå™¨äººæŽ§åˆ¶` `è¿åŠ¨è·Ÿè¸ª` `å¤§è§„æ¨¡å­¦ä¹ ` `Transformer` `è¿åŠ¨æ•æ‰` `å…¨èº«è¿åŠ¨` `é€šç”¨æŽ§åˆ¶å™¨`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰çš„äººå½¢æœºå™¨äººç¥žç»æŽ§åˆ¶å™¨è§„æ¨¡è¾ƒå°ï¼Œè¡Œä¸ºé›†æœ‰é™ï¼Œè®­ç»ƒè€—æ—¶ï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨å¤§è§„æ¨¡æ•°æ®å’Œç®—åŠ›ã€‚
2. è®ºæ–‡æå‡ºå°†è¿åŠ¨è·Ÿè¸ªä½œä¸ºäººå½¢æœºå™¨äººæŽ§åˆ¶çš„åŸºç¡€ä»»åŠ¡ï¼Œé€šè¿‡å¤§è§„æ¨¡æ•°æ®å’Œç®—åŠ›è®­ç»ƒé€šç”¨æŽ§åˆ¶å™¨ï¼Œæ— éœ€æ‰‹åŠ¨è®¾è®¡å¥–åŠ±å‡½æ•°ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨è¿åŠ¨è·Ÿè¸ªä»»åŠ¡ä¸Šè¡¨çŽ°å‡ºè‰¯å¥½çš„æ‰©å±•æ€§ï¼Œæ€§èƒ½éšæ•°æ®å’Œç®—åŠ›å¢žåŠ è€Œæå‡ï¼Œå¹¶èƒ½æ³›åŒ–åˆ°æœªè§è¿‡çš„è¿åŠ¨ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§é€šç”¨äººå½¢æœºå™¨äººæŽ§åˆ¶å™¨ï¼Œé€šè¿‡æ‰©å±•æ¨¡åž‹å®¹é‡ã€æ•°æ®é‡å’Œè®¡ç®—èµ„æºï¼Œå®žçŽ°äº†è‡ªç„¶ä¸”é²æ£’çš„å…¨èº«è¿åŠ¨æŽ§åˆ¶ã€‚è®ºæ–‡å°†è¿åŠ¨è·Ÿè¸ªè§†ä¸ºäººå½¢æœºå™¨äººæŽ§åˆ¶çš„ä¸€ä¸ªè‡ªç„¶ä¸”å¯æ‰©å±•çš„ä»»åŠ¡ï¼Œåˆ©ç”¨æ¥è‡ªå¤šæ ·åŒ–è¿åŠ¨æ•æ‰æ•°æ®çš„å¯†é›†ç›‘ç£ï¼Œæ— éœ€æ‰‹åŠ¨è®¾è®¡å¥–åŠ±å‡½æ•°å³å¯èŽ·å–äººç±»è¿åŠ¨å…ˆéªŒçŸ¥è¯†ã€‚é€šè¿‡æ‰©å±•ç½‘ç»œè§„æ¨¡ï¼ˆä»Ž120ä¸‡åˆ°4200ä¸‡å‚æ•°ï¼‰ã€æ•°æ®é›†å¤§å°ï¼ˆè¶…è¿‡1äº¿å¸§ï¼Œ700å°æ—¶é«˜è´¨é‡è¿åŠ¨æ•°æ®ï¼‰å’Œè®¡ç®—èµ„æºï¼ˆ9000 GPUå°æ—¶ï¼‰ï¼Œæž„å»ºäº†ä¸€ä¸ªç”¨äºŽè¿åŠ¨è·Ÿè¸ªçš„åŸºç¡€æ¨¡åž‹ã€‚è¯¥æ¨¡åž‹é€šè¿‡å®žæ—¶é€šç”¨è¿åŠ¨å­¦è§„åˆ’å™¨å°†è¿åŠ¨è·Ÿè¸ªè¿žæŽ¥åˆ°ä¸‹æ¸¸ä»»åŠ¡æ‰§è¡Œï¼Œå®žçŽ°è‡ªç„¶å’Œäº¤äº’å¼æŽ§åˆ¶ï¼Œå¹¶ä½¿ç”¨ç»Ÿä¸€çš„tokenç©ºé—´æ”¯æŒå„ç§è¿åŠ¨è¾“å…¥æŽ¥å£ï¼Œå¦‚VRé¥æ“ä½œè®¾å¤‡ã€äººç±»è§†é¢‘å’Œè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹ã€‚å®žéªŒè¡¨æ˜Žï¼Œå¤§è§„æ¨¡è¿åŠ¨è·Ÿè¸ªå…·æœ‰è‰¯å¥½çš„ç‰¹æ€§ï¼šæ€§èƒ½éšç€è®¡ç®—èµ„æºå’Œæ•°æ®å¤šæ ·æ€§çš„å¢žåŠ è€Œç¨³æ­¥æé«˜ï¼Œå¹¶ä¸”å­¦ä¹ åˆ°çš„è¡¨ç¤ºå¯ä»¥æ³›åŒ–åˆ°æœªè§è¿‡çš„è¿åŠ¨ï¼Œä»Žè€Œä¸ºäººå½¢æœºå™¨äººæŽ§åˆ¶å¥ å®šäº†åšå®žçš„åŸºç¡€ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„äººå½¢æœºå™¨äººæŽ§åˆ¶æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäºŽå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œé€šå¸¸éœ€è¦æ‰‹åŠ¨è®¾è®¡å¤æ‚çš„å¥–åŠ±å‡½æ•°ï¼Œå¹¶ä¸”éš¾ä»¥æ³›åŒ–åˆ°ä¸åŒçš„ä»»åŠ¡å’ŒçŽ¯å¢ƒã€‚æ­¤å¤–ï¼ŒçŽ°æœ‰æ¨¡åž‹çš„è§„æ¨¡å’Œè®­ç»ƒæ•°æ®é‡ç›¸å¯¹è¾ƒå°ï¼Œé™åˆ¶äº†å…¶æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚å› æ­¤ï¼Œå¦‚ä½•åˆ©ç”¨å¤§è§„æ¨¡æ•°æ®å’Œç®—åŠ›ï¼Œæž„å»ºä¸€ä¸ªé€šç”¨ä¸”é²æ£’çš„äººå½¢æœºå™¨äººæŽ§åˆ¶å™¨æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è¿åŠ¨è·Ÿè¸ªä½œä¸ºäººå½¢æœºå™¨äººæŽ§åˆ¶çš„ä¸€ä¸ªåŸºç¡€ä»»åŠ¡ã€‚é€šè¿‡å­¦ä¹ äººç±»è¿åŠ¨çš„å…ˆéªŒçŸ¥è¯†ï¼Œæœºå™¨äººå¯ä»¥æ›´å¥½åœ°ç†è§£å’Œæ¨¡ä»¿äººç±»çš„åŠ¨ä½œï¼Œä»Žè€Œå®žçŽ°æ›´è‡ªç„¶å’Œé²æ£’çš„æŽ§åˆ¶ã€‚è¿™ç§æ–¹æ³•é¿å…äº†æ‰‹åŠ¨è®¾è®¡å¥–åŠ±å‡½æ•°çš„å¤æ‚æ€§ï¼Œå¹¶ä¸”å¯ä»¥åˆ©ç”¨å¤§è§„æ¨¡çš„è¿åŠ¨æ•æ‰æ•°æ®è¿›è¡Œè®­ç»ƒã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•æž„å»ºäº†ä¸€ä¸ªç”¨äºŽè¿åŠ¨è·Ÿè¸ªçš„åŸºç¡€æ¨¡åž‹ï¼Œè¯¥æ¨¡åž‹é€šè¿‡æ‰©å±•ç½‘ç»œè§„æ¨¡ã€æ•°æ®é›†å¤§å°å’Œè®¡ç®—èµ„æºè¿›è¡Œè®­ç»ƒã€‚æ•´ä½“æž¶æž„åŒ…å«ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1) è¿åŠ¨æ•æ‰æ•°æ®é¢„å¤„ç†ï¼Œå°†åŽŸå§‹æ•°æ®è½¬æ¢ä¸ºæ¨¡åž‹å¯ä»¥å¤„ç†çš„æ ¼å¼ï¼›2) è¿åŠ¨è·Ÿè¸ªæ¨¡åž‹è®­ç»ƒï¼Œä½¿ç”¨å¤§è§„æ¨¡æ•°æ®è®­ç»ƒæ¨¡åž‹ï¼Œä½¿å…¶èƒ½å¤Ÿå‡†ç¡®åœ°è·Ÿè¸ªäººç±»è¿åŠ¨ï¼›3) è¿åŠ¨è§„åˆ’å’ŒæŽ§åˆ¶ï¼Œåˆ©ç”¨è®­ç»ƒå¥½çš„æ¨¡åž‹è¿›è¡Œè¿åŠ¨è§„åˆ’å’ŒæŽ§åˆ¶ï¼Œå®žçŽ°äººå½¢æœºå™¨äººçš„å…¨èº«è¿åŠ¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå°†è¿åŠ¨è·Ÿè¸ªä½œä¸ºäººå½¢æœºå™¨äººæŽ§åˆ¶çš„åŸºç¡€ä»»åŠ¡ï¼Œå¹¶åˆ©ç”¨å¤§è§„æ¨¡æ•°æ®å’Œç®—åŠ›è¿›è¡Œè®­ç»ƒã€‚è¿™ç§æ–¹æ³•é¿å…äº†æ‰‹åŠ¨è®¾è®¡å¥–åŠ±å‡½æ•°çš„å¤æ‚æ€§ï¼Œå¹¶ä¸”å¯ä»¥å­¦ä¹ åˆ°æ›´ä¸°å¯Œçš„è¿åŠ¨å…ˆéªŒçŸ¥è¯†ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„tokenç©ºé—´ï¼Œå¯ä»¥æ”¯æŒå„ç§è¿åŠ¨è¾“å…¥æŽ¥å£ï¼Œå¦‚VRé¥æ“ä½œè®¾å¤‡ã€äººç±»è§†é¢‘å’Œè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­ä½¿ç”¨äº†Transformeræž¶æž„ä½œä¸ºè¿åŠ¨è·Ÿè¸ªæ¨¡åž‹çš„åŸºç¡€ã€‚æŸå¤±å‡½æ•°ä¸»è¦åŒ…æ‹¬è¿åŠ¨å­¦æŸå¤±å’ŒåŠ¨åŠ›å­¦æŸå¤±ï¼Œç”¨äºŽçº¦æŸæ¨¡åž‹çš„è¾“å‡ºã€‚ç½‘ç»œè§„æ¨¡ä»Ž120ä¸‡åˆ°4200ä¸‡å‚æ•°ä¸ç­‰ï¼Œæ•°æ®é›†å¤§å°è¶…è¿‡1äº¿å¸§ï¼Œè®¡ç®—èµ„æºè¾¾åˆ°9000 GPUå°æ—¶ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸€ä¸ªå®žæ—¶é€šç”¨è¿åŠ¨å­¦è§„åˆ’å™¨ï¼Œç”¨äºŽå°†è¿åŠ¨è·Ÿè¸ªè¿žæŽ¥åˆ°ä¸‹æ¸¸ä»»åŠ¡æ‰§è¡Œã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è¯¥ç ”ç©¶é€šè¿‡æ‰©å±•æ¨¡åž‹è§„æ¨¡ã€æ•°æ®é‡å’Œè®¡ç®—èµ„æºï¼Œåœ¨è¿åŠ¨è·Ÿè¸ªä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•å¯ä»¥å‡†ç¡®åœ°è·Ÿè¸ªäººç±»è¿åŠ¨ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ³›åŒ–åˆ°æœªè§è¿‡çš„è¿åŠ¨ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜èƒ½å¤Ÿæ”¯æŒå„ç§è¿åŠ¨è¾“å…¥æŽ¥å£ï¼Œå¦‚VRé¥æ“ä½œè®¾å¤‡ã€äººç±»è§†é¢‘å’Œè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å…·æœ‰æ›´é«˜çš„ç²¾åº¦å’Œæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§äººå½¢æœºå™¨äººæŽ§åˆ¶åœºæ™¯ï¼Œå¦‚å®¶åº­æœåŠ¡ã€åŒ»ç–—åº·å¤ã€å·¥ä¸šè‡ªåŠ¨åŒ–ç­‰ã€‚é€šè¿‡å­¦ä¹ äººç±»è¿åŠ¨çš„å…ˆéªŒçŸ¥è¯†ï¼Œæœºå™¨äººå¯ä»¥æ›´å¥½åœ°ç†è§£å’Œæ¨¡ä»¿äººç±»çš„åŠ¨ä½œï¼Œä»Žè€Œå®žçŽ°æ›´è‡ªç„¶å’Œé²æ£’çš„æŽ§åˆ¶ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºŽè™šæ‹ŸçŽ°å®žå’Œå¢žå¼ºçŽ°å®žç­‰é¢†åŸŸï¼Œä¸ºç”¨æˆ·æä¾›æ›´é€¼çœŸçš„äº¤äº’ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æœ‰æœ›æŽ¨åŠ¨äººå½¢æœºå™¨äººæŠ€æœ¯çš„å‘å±•ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°æœåŠ¡äºŽäººç±»ç¤¾ä¼šã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite the rise of billion-parameter foundation models trained across thousands of GPUs, similar scaling gains have not been shown for humanoid control. Current neural controllers for humanoids remain modest in size, target a limited set of behaviors, and are trained on a handful of GPUs over several days. We show that scaling up model capacity, data, and compute yields a generalist humanoid controller capable of creating natural and robust whole-body movements. Specifically, we posit motion tracking as a natural and scalable task for humanoid control, leveraging dense supervision from diverse motion-capture data to acquire human motion priors without manual reward engineering. We build a foundation model for motion tracking by scaling along three axes: network size (from 1.2M to 42M parameters), dataset volume (over 100M frames, 700 hours of high-quality motion data), and compute (9k GPU hours). Beyond demonstrating the benefits of scale, we show the practical utility of our model through two mechanisms: (1) a real-time universal kinematic planner that bridges motion tracking to downstream task execution, enabling natural and interactive control, and (2) a unified token space that supports various motion input interfaces, such as VR teleoperation devices, human videos, and vision-language-action (VLA) models, all using the same policy. Scaling motion tracking exhibits favorable properties: performance improves steadily with increased compute and data diversity, and learned representations generalize to unseen motions, establishing motion tracking at scale as a practical foundation for humanoid control.

