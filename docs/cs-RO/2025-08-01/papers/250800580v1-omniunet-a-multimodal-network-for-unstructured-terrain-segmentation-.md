---
layout: default
title: OmniUnet: A Multimodal Network for Unstructured Terrain Segmentation on Planetary Rovers Using RGB, Depth, and Thermal Imagery
---

# OmniUnet: A Multimodal Network for Unstructured Terrain Segmentation on Planetary Rovers Using RGB, Depth, and Thermal Imagery

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.00580" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.00580v1</a>
  <a href="https://arxiv.org/pdf/2508.00580.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.00580v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.00580v1', 'OmniUnet: A Multimodal Network for Unstructured Terrain Segmentation on Planetary Rovers Using RGB, Depth, and Thermal Imagery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Raul Castilla-Arquillo, Carlos Perez-del-Pulgar, Levin Gerdes, Alfonso Garcia-Cerezo, Miguel A. Olivares-Mendez

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-01

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmniUnetä»¥è§£å†³è¡Œæ˜Ÿæ¢æµ‹å™¨åœ¨éç»“æ„åŒ–åœ°å½¢åˆ†å‰²é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ„ŸçŸ¥` `è¯­ä¹‰åˆ†å‰²` `è¡Œæ˜Ÿæ¢æµ‹` `æ·±åº¦å­¦ä¹ ` `çƒ­æˆåƒ` `æœºå™¨äººå¯¼èˆª` `å˜æ¢å™¨ç½‘ç»œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æœºå™¨äººå¯¼èˆªæ–¹æ³•åœ¨å¤„ç†éç»“æ„åŒ–ç¯å¢ƒæ—¶é¢ä¸´å¤šæ¨¡æ€ä¿¡æ¯æ•´åˆçš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ç«æ˜Ÿæ¢æµ‹ä¸­ã€‚
2. è®ºæ–‡æå‡ºOmniUnetï¼Œä¸€ç§åŸºäºå˜æ¢å™¨çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•´åˆRGBã€æ·±åº¦å’Œçƒ­æˆåƒæ•°æ®è¿›è¡Œè¯­ä¹‰åˆ†å‰²ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOmniUnetåœ¨å¤æ‚åœ°å½¢åˆ†å‰²ä¸­å–å¾—äº†80.37%çš„åƒç´ å‡†ç¡®ç‡ï¼Œä¸”åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šè¡¨ç°è‰¯å¥½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœºå™¨äººåœ¨éç»“æ„åŒ–ç¯å¢ƒä¸­çš„å¯¼èˆªéœ€è¦å¤šæ¨¡æ€æ„ŸçŸ¥ç³»ç»Ÿä»¥æ”¯æŒå®‰å…¨å¯¼èˆªã€‚å¤šæ¨¡æ€æ€§ä½¿å¾—ä¸åŒä¼ æ„Ÿå™¨æ”¶é›†çš„äº’è¡¥ä¿¡æ¯å¾—ä»¥æ•´åˆã€‚ç„¶è€Œï¼Œè¿™äº›ä¿¡æ¯å¿…é¡»é€šè¿‡ä¸“é—¨è®¾è®¡çš„æœºå™¨å­¦ä¹ ç®—æ³•è¿›è¡Œå¤„ç†ï¼Œä»¥å……åˆ†åˆ©ç”¨å¼‚æ„æ•°æ®ã€‚æ­¤å¤–ï¼Œè¿˜éœ€è¯†åˆ«å“ªäº›ä¼ æ„Ÿå™¨æ¨¡æ€å¯¹ç›®æ ‡ç¯å¢ƒçš„å¯¼èˆªæœ€å…·ä¿¡æ¯é‡ã€‚åœ¨ç«æ˜Ÿæ¢æµ‹ä¸­ï¼Œçƒ­æˆåƒå› åœŸå£¤ç±»å‹çš„çƒ­è¡Œä¸ºå·®å¼‚è€Œè¢«è¯æ˜å¯¹è¯„ä¼°åœ°å½¢å®‰å…¨æ€§å…·æœ‰é‡è¦ä»·å€¼ã€‚æœ¬ç ”ç©¶æå‡ºäº†OmniUnetï¼Œä¸€ç§åŸºäºå˜æ¢å™¨çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œåˆ©ç”¨RGBã€æ·±åº¦å’Œçƒ­æˆåƒï¼ˆRGB-D-Tï¼‰è¿›è¡Œè¯­ä¹‰åˆ†å‰²ã€‚é€šè¿‡3Dæ‰“å°å¼€å‘äº†å®šåˆ¶çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨å¤–å£³ï¼Œå¹¶å®‰è£…åœ¨ç«æ˜Ÿæ¢æµ‹å™¨è‡ªä¸»æµ‹è¯•å¹³å°ï¼ˆMaRTAï¼‰ä¸Šï¼Œä»¥åœ¨è¥¿ç­ç‰™åŒ—éƒ¨çš„BardenasåŠæ²™æ¼ æ”¶é›†å¤šæ¨¡æ€æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†çš„å­é›†ç»è¿‡æ‰‹åŠ¨æ ‡æ³¨ï¼Œä»¥æ”¯æŒç½‘ç»œçš„ç›‘ç£è®­ç»ƒã€‚æ¨¡å‹ç»è¿‡å®šé‡å’Œå®šæ€§è¯„ä¼°ï¼Œåƒç´ å‡†ç¡®ç‡è¾¾åˆ°80.37%ï¼Œåœ¨åˆ†å‰²å¤æ‚éç»“æ„åŒ–åœ°å½¢æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚æ¨ç†æµ‹è¯•åœ¨èµ„æºå—é™çš„è®¡ç®—æœºï¼ˆJetson Orin Nanoï¼‰ä¸Šå¹³å‡é¢„æµ‹æ—¶é—´ä¸º673æ¯«ç§’ï¼Œç¡®è®¤å…¶é€‚åˆåœ¨æœºå™¨äººä¸Šéƒ¨ç½²ã€‚ç½‘ç»œçš„è½¯ä»¶å®ç°å’Œæ ‡æ³¨æ•°æ®é›†å·²å…¬å¼€ï¼Œä»¥æ”¯æŒæœªæ¥åœ¨è¡Œæ˜Ÿæœºå™¨äººå¤šæ¨¡æ€åœ°å½¢æ„ŸçŸ¥æ–¹é¢çš„ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è¡Œæ˜Ÿæ¢æµ‹å™¨åœ¨éç»“æ„åŒ–åœ°å½¢ä¸­è¿›è¡Œè¯­ä¹‰åˆ†å‰²çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆæ•´åˆä¸åŒæ¥æºçš„ä¿¡æ¯ï¼Œå¯¼è‡´å¯¼èˆªå®‰å…¨æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„OmniUnetç½‘ç»œæ¶æ„é€šè¿‡å˜æ¢å™¨æ¨¡å‹ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†RGBã€æ·±åº¦å’Œçƒ­æˆåƒæ•°æ®ï¼Œå……åˆ†åˆ©ç”¨å„æ¨¡æ€çš„äº’è¡¥ä¿¡æ¯ï¼Œä»è€Œæé«˜åœ°å½¢åˆ†å‰²çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOmniUnetçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†æ¨¡å—ã€ç‰¹å¾æå–æ¨¡å—å’Œè¯­ä¹‰åˆ†å‰²æ¨¡å—ã€‚æ•°æ®é¢„å¤„ç†æ¨¡å—è´Ÿè´£å¯¹RGBã€æ·±åº¦å’Œçƒ­æˆåƒæ•°æ®è¿›è¡Œæ ‡å‡†åŒ–å’Œèåˆï¼Œç‰¹å¾æå–æ¨¡å—ä½¿ç”¨å˜æ¢å™¨ç½‘ç»œæå–å¤šæ¨¡æ€ç‰¹å¾ï¼Œæœ€åè¯­ä¹‰åˆ†å‰²æ¨¡å—ç”Ÿæˆæœ€ç»ˆçš„åœ°å½¢åˆ†å‰²ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šOmniUnetçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å¤šæ¨¡æ€èåˆèƒ½åŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•´åˆä¸åŒä¼ æ„Ÿå™¨çš„æ•°æ®ï¼Œå°¤å…¶æ˜¯çƒ­æˆåƒåœ¨åœŸå£¤ç±»å‹è¯†åˆ«ä¸­çš„åº”ç”¨ï¼Œè¿™åœ¨ç°æœ‰æ–¹æ³•ä¸­è¾ƒä¸ºå°‘è§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œè®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¤šæ¨¡æ€ç‰¹å¾çš„èåˆæ•ˆæœï¼Œå¹¶é€šè¿‡æ‰‹åŠ¨æ ‡æ³¨çš„æ•°æ®é›†è¿›è¡Œç›‘ç£è®­ç»ƒï¼Œç¡®ä¿æ¨¡å‹åœ¨å¤æ‚åœ°å½¢ä¸­çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒOmniUnetåœ¨å¤æ‚éç»“æ„åŒ–åœ°å½¢çš„åˆ†å‰²ä»»åŠ¡ä¸­å–å¾—äº†80.37%çš„åƒç´ å‡†ç¡®ç‡ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æœ‰æ˜¾è‘—æå‡ã€‚æ­¤å¤–ï¼Œåœ¨èµ„æºå—é™çš„Jetson Orin Nanoä¸Šï¼Œæ¨¡å‹çš„å¹³å‡æ¨ç†æ—¶é—´ä¸º673æ¯«ç§’ï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„å®æ—¶å¤„ç†èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è¡Œæ˜Ÿæ¢æµ‹ã€è‡ªåŠ¨é©¾é©¶å’Œæ— äººæœºå¯¼èˆªç­‰ã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ„ŸçŸ¥èƒ½åŠ›ï¼ŒOmniUnetèƒ½å¤Ÿæ˜¾è‘—æå‡æ¢æµ‹ä»»åŠ¡çš„å®‰å…¨æ€§å’Œæ•ˆç‡ï¼Œæ¨åŠ¨æœªæ¥çš„è¡Œæ˜Ÿæ¢ç´¢å’Œå…¶ä»–é«˜é£é™©ç¯å¢ƒçš„è‡ªåŠ¨åŒ–æŠ€æœ¯å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Robot navigation in unstructured environments requires multimodal perception systems that can support safe navigation. Multimodality enables the integration of complementary information collected by different sensors. However, this information must be processed by machine learning algorithms specifically designed to leverage heterogeneous data. Furthermore, it is necessary to identify which sensor modalities are most informative for navigation in the target environment. In Martian exploration, thermal imagery has proven valuable for assessing terrain safety due to differences in thermal behaviour between soil types. This work presents OmniUnet, a transformer-based neural network architecture for semantic segmentation using RGB, depth, and thermal (RGB-D-T) imagery. A custom multimodal sensor housing was developed using 3D printing and mounted on the Martian Rover Testbed for Autonomy (MaRTA) to collect a multimodal dataset in the Bardenas semi-desert in northern Spain. This location serves as a representative environment of the Martian surface, featuring terrain types such as sand, bedrock, and compact soil. A subset of this dataset was manually labeled to support supervised training of the network. The model was evaluated both quantitatively and qualitatively, achieving a pixel accuracy of 80.37% and demonstrating strong performance in segmenting complex unstructured terrain. Inference tests yielded an average prediction time of 673 ms on a resource-constrained computer (Jetson Orin Nano), confirming its suitability for on-robot deployment. The software implementation of the network and the labeled dataset have been made publicly available to support future research in multimodal terrain perception for planetary robotics.

