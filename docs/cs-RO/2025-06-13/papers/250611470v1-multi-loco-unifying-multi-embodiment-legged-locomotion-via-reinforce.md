---
layout: default
title: Multi-Loco: Unifying Multi-Embodiment Legged Locomotion via Reinforcement Learning Augmented Diffusion
---

# Multi-Loco: Unifying Multi-Embodiment Legged Locomotion via Reinforcement Learning Augmented Diffusion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11470" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11470v1</a>
  <a href="https://arxiv.org/pdf/2506.11470.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11470v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11470v1', 'Multi-Loco: Unifying Multi-Embodiment Legged Locomotion via Reinforcement Learning Augmented Diffusion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shunpeng Yang, Zhen Fu, Zhefeng Cao, Guo Junde, Patrick Wensing, Wei Zhang, Hua Chen

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

**å¤‡æ³¨**: 19 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMulti-Locoä»¥è§£å†³å¤šç§å½¢æ€æœºå™¨äººè¿åŠ¨ç­–ç•¥æ³›åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `å¤šå½¢æ€æœºå™¨äºº` `è¿åŠ¨ç­–ç•¥æ³›åŒ–` `ç”Ÿæˆæ‰©æ•£æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `æ®‹å·®ç­–ç•¥` `é²æ£’æ€§` `å››è¶³æœºå™¨äºº` `è·¨å½¢æ€æ•°æ®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šç§å½¢æ€çš„æœºå™¨äººä¸­æ³›åŒ–è¿åŠ¨ç­–ç•¥é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦ç”±äºè§‚å¯Ÿå’ŒåŠ¨ä½œç»´åº¦çš„å·®å¼‚ã€‚
2. æœ¬æ–‡æå‡ºMulti-Locoæ¡†æ¶ï¼Œç»“åˆç”Ÿæˆæ‰©æ•£æ¨¡å‹ä¸æ®‹å·®ç­–ç•¥ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ï¼Œå®ç°å½¢æ€æ— å…³çš„è¿åŠ¨ç­–ç•¥å­¦ä¹ ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å¤šç§å››è¶³æœºå™¨äººä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºæ ‡å‡†PPOæ¡†æ¶ï¼Œå¹³å‡å›æŠ¥æå‡10.35%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤šç§å½¢æ€çš„å››è¶³æœºå™¨äººä¸­ï¼Œè¿åŠ¨ç­–ç•¥çš„æ³›åŒ–æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œä¸»è¦ç”±äºè§‚å¯Ÿ/åŠ¨ä½œç»´åº¦å’Œç³»ç»ŸåŠ¨æ€çš„å·®å¼‚ã€‚æœ¬æ–‡æå‡ºäº†Multi-Locoï¼Œä¸€ä¸ªç»“åˆå½¢æ€æ— å…³ç”Ÿæˆæ‰©æ•£æ¨¡å‹ä¸è½»é‡çº§æ®‹å·®ç­–ç•¥çš„ç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œä¼˜åŒ–ã€‚ç”Ÿæˆæ¨¡å‹ä»å¤šæ ·çš„è·¨å½¢æ€æ•°æ®é›†ä¸­æ•æ‰è¿åŠ¨æ¨¡å¼ï¼Œæé«˜äº†æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚æ®‹å·®ç­–ç•¥åœ¨æ‰€æœ‰å½¢æ€ä¸­å…±äº«ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„åŠ¨ä½œï¼Œå¢å¼ºäº†ä»»åŠ¡æ„ŸçŸ¥æ€§èƒ½å’Œå®é™…éƒ¨ç½²çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æ ‡å‡†çš„PPOå¼ºåŒ–å­¦ä¹ æ¡†æ¶ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œå®éªŒä¸­å®ç°äº†10.35%çš„å¹³å‡å›æŠ¥æå‡ï¼Œè½®å¼åŒè¶³è¿åŠ¨ä»»åŠ¡çš„æå‡å¹…åº¦è¾¾åˆ°13.57%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šç§å½¢æ€æœºå™¨äººè¿åŠ¨ç­–ç•¥çš„æ³›åŒ–é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä¸åŒå½¢æ€æœºå™¨äººä¹‹é—´ç¼ºä¹æœ‰æ•ˆçš„ç­–ç•¥å…±äº«ï¼Œå¯¼è‡´è¿åŠ¨ç­–ç•¥éš¾ä»¥è¿ç§»å’Œé€‚åº”ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMulti-Locoæ¡†æ¶é€šè¿‡ç»“åˆå½¢æ€æ— å…³çš„ç”Ÿæˆæ‰©æ•£æ¨¡å‹ä¸è½»é‡çº§çš„æ®‹å·®ç­–ç•¥ï¼Œæ—¨åœ¨æ•æ‰å’Œä¼˜åŒ–å¤šæ ·åŒ–çš„è¿åŠ¨æ¨¡å¼ï¼Œä»è€Œæé«˜ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªæ¨¡å—ï¼šç”Ÿæˆæ‰©æ•£æ¨¡å‹ç”¨äºå­¦ä¹ å½¢æ€æ— å…³çš„è¿åŠ¨æ¨¡å¼ï¼Œæ®‹å·®ç­–ç•¥ç”¨äºä¼˜åŒ–ç”Ÿæˆçš„åŠ¨ä½œã€‚ç”Ÿæˆæ¨¡å‹ä»è·¨å½¢æ€æ•°æ®é›†ä¸­æå–è¿åŠ¨ç‰¹å¾ï¼Œæ®‹å·®ç­–ç•¥åˆ™åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œç»†åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†ç”Ÿæˆæ‰©æ•£æ¨¡å‹ä¸æ®‹å·®ç­–ç•¥ç›¸ç»“åˆï¼Œæ›¿ä»£ä¼ ç»Ÿçš„é«˜æ–¯ç­–ç•¥ï¼Œæ˜¾è‘—æå‡äº†è¿åŠ¨ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›å’Œå®é™…åº”ç”¨çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡ç”Ÿæˆæ¨¡å‹ä¸æ®‹å·®ç­–ç•¥çš„ä¼˜åŒ–ç›®æ ‡ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è½»é‡åŒ–è®¾è®¡ï¼Œä»¥é€‚åº”ä¸åŒå½¢æ€æœºå™¨äººçš„éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMulti-Locoæ–¹æ³•åœ¨å››è¶³æœºå™¨äººä¸Šå®ç°äº†10.35%çš„å¹³å‡å›æŠ¥æå‡ï¼Œè½®å¼åŒè¶³è¿åŠ¨ä»»åŠ¡çš„æå‡å¹…åº¦è¾¾åˆ°13.57%ã€‚è¿™äº›ç»“æœæ˜¾ç¤ºäº†è·¨å½¢æ€æ•°æ®å’Œå¤åˆç”Ÿæˆæ¶æ„åœ¨å­¦ä¹ é²æ£’ã€é€šç”¨è¿åŠ¨æŠ€èƒ½æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šç§å½¢æ€çš„æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨åŒ–ç‰©æµã€æ•‘æ´æœºå™¨äººç­‰ã€‚é€šè¿‡å®ç°è¿åŠ¨ç­–ç•¥çš„æ³›åŒ–ï¼ŒMulti-Locoèƒ½å¤Ÿåœ¨ä¸åŒç¯å¢ƒå’Œä»»åŠ¡ä¸­çµæ´»é€‚åº”ï¼Œæå‡æœºå™¨äººåœ¨å¤æ‚åœºæ™¯ä¸‹çš„æ“ä½œèƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generalizing locomotion policies across diverse legged robots with varying morphologies is a key challenge due to differences in observation/action dimensions and system dynamics. In this work, we propose Multi-Loco, a novel unified framework combining a morphology-agnostic generative diffusion model with a lightweight residual policy optimized via reinforcement learning (RL). The diffusion model captures morphology-invariant locomotion patterns from diverse cross-embodiment datasets, improving generalization and robustness. The residual policy is shared across all embodiments and refines the actions generated by the diffusion model, enhancing task-aware performance and robustness for real-world deployment. We evaluated our method with a rich library of four legged robots in both simulation and real-world experiments. Compared to a standard RL framework with PPO, our approach -- replacing the Gaussian policy with a diffusion model and residual term -- achieves a 10.35% average return improvement, with gains up to 13.57% in wheeled-biped locomotion tasks. These results highlight the benefits of cross-embodiment data and composite generative architectures in learning robust, generalized locomotion skills.

