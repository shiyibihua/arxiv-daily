---
layout: default
title: RLBind: Adversarial-Invariant Cross-Modal Alignment for Unified Robust Embeddings
---

# RLBind: Adversarial-Invariant Cross-Modal Alignment for Unified Robust Embeddings

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14383" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14383v1</a>
  <a href="https://arxiv.org/pdf/2509.14383.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14383v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14383v1', 'RLBind: Adversarial-Invariant Cross-Modal Alignment for Unified Robust Embeddings')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuhong Lu

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-17

**å¤‡æ³¨**: This paper is submitted to IEEE International Conference on Robotics and Automation (ICRA) 2026

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**RLBindï¼šå¯¹æŠ—ä¸å˜è·¨æ¨¡æ€å¯¹é½ï¼Œç”¨äºç»Ÿä¸€é²æ£’åµŒå…¥**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€èåˆ` `å¯¹æŠ—é²æ£’æ€§` `è·¨æ¨¡æ€å¯¹é½` `æœºå™¨äººæ„ŸçŸ¥` `å¯¹æ¯”å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨CLIPç±»ç¼–ç å™¨ä¸­å¯¹é½å¹²å‡€å’Œå¯¹æŠ—æ ·æœ¬çš„è§†è§‰ç‰¹å¾ï¼Œå¿½ç•¥äº†è·¨æ¨¡æ€ä¿¡æ¯ï¼Œé²æ£’æ€§æå‡æœ‰é™ã€‚
2. RLBindé€šè¿‡ä¸¤é˜¶æ®µçš„å¯¹æŠ—ä¸å˜è·¨æ¨¡æ€å¯¹é½ï¼Œé¦–å…ˆå¢å¼ºè§†è§‰ç¼–ç å™¨ï¼Œç„¶ååˆ©ç”¨æ–‡æœ¬é”šç‚¹è¿›è¡Œè·¨æ¨¡æ€å¯¹é½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒRLBindåœ¨å¤šç§æ¨¡æ€æ•°æ®ä¸Šï¼Œç›¸æ¯”LanguageBindå’Œå¾®è°ƒåŸºçº¿ï¼Œæ˜¾è‘—æå‡äº†å¹²å‡€å‡†ç¡®æ€§å’Œå¯¹æŠ—é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç»Ÿä¸€çš„å¤šæ¨¡æ€ç¼–ç å™¨å°†è§†è§‰ã€éŸ³é¢‘å’Œå…¶ä»–ä¼ æ„Ÿå™¨ç»‘å®šåˆ°å…±äº«çš„åµŒå…¥ç©ºé—´ä¸­ï¼Œæ˜¯æœºå™¨äººæ„ŸçŸ¥å’Œå†³ç­–çš„ç†æƒ³æ„å»ºå—ã€‚ç„¶è€Œï¼Œåœ¨æœºå™¨äººä¸Šçš„éƒ¨ç½²ä½¿è§†è§‰åˆ†æ”¯æš´éœ²äºå¯¹æŠ—æ€§å’Œè‡ªç„¶æŸåï¼Œä½¿å¾—é²æ£’æ€§æˆä¸ºå®‰å…¨æ€§çš„å…ˆå†³æ¡ä»¶ã€‚å…ˆå‰çš„é˜²å¾¡é€šå¸¸åœ¨CLIPé£æ ¼çš„ç¼–ç å™¨ä¸­å¯¹é½å¹²å‡€å’Œå¯¹æŠ—æ€§ç‰¹å¾ï¼Œè€Œå¿½ç•¥äº†æ›´å¹¿æ³›çš„è·¨æ¨¡æ€å¯¹åº”å…³ç³»ï¼Œå¯¼è‡´å¢ç›Šæœ‰é™ï¼Œå¹¶ä¸”å¸¸å¸¸é™ä½é›¶æ ·æœ¬è¿ç§»æ€§èƒ½ã€‚æˆ‘ä»¬å¼•å…¥äº†RLBindï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé²æ£’ç»Ÿä¸€åµŒå…¥çš„ä¸¤é˜¶æ®µå¯¹æŠ—ä¸å˜è·¨æ¨¡æ€å¯¹é½æ¡†æ¶ã€‚ç¬¬ä¸€é˜¶æ®µå¯¹å¹²å‡€-å¯¹æŠ—æ ·æœ¬å¯¹è¿›è¡Œæ— ç›‘ç£å¾®è°ƒï¼Œä»¥å¢å¼ºè§†è§‰ç¼–ç å™¨ã€‚ç¬¬äºŒé˜¶æ®µé€šè¿‡æœ€å°åŒ–å¹²å‡€/å¯¹æŠ—ç‰¹å¾ä¸æ–‡æœ¬é”šç‚¹ä¹‹é—´çš„å·®å¼‚ï¼ŒåŒæ—¶å¼ºåˆ¶è·¨æ¨¡æ€çš„ç±»åˆ«åˆ†å¸ƒå¯¹é½ï¼Œæ¥åˆ©ç”¨è·¨æ¨¡æ€å¯¹åº”å…³ç³»ã€‚åœ¨å›¾åƒã€éŸ³é¢‘ã€çƒ­æˆåƒå’Œè§†é¢‘æ•°æ®ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒRLBindåœ¨å¹²å‡€å‡†ç¡®æ€§å’ŒèŒƒæ•°æœ‰ç•Œå¯¹æŠ—é²æ£’æ€§æ–¹é¢å§‹ç»ˆä¼˜äºLanguageBindéª¨å¹²ç½‘ç»œå’Œæ ‡å‡†å¾®è°ƒåŸºçº¿ã€‚é€šè¿‡åœ¨ä¸ç‰ºç‰²æ³›åŒ–èƒ½åŠ›çš„æƒ…å†µä¸‹æé«˜å¼¹æ€§ï¼ŒRLBindä¸ºå¯¼èˆªã€æ“ä½œå’Œå…¶ä»–è‡ªä¸»è®¾ç½®ä¸­å…·èº«æœºå™¨äººçš„æ›´å®‰å…¨çš„å¤šä¼ æ„Ÿå™¨æ„ŸçŸ¥å †æ ˆæä¾›äº†ä¸€æ¡å®ç”¨çš„é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€æœºå™¨äººæ„ŸçŸ¥ç³»ç»Ÿä¸­ï¼Œè§†è§‰åˆ†æ”¯æ˜“å—å¯¹æŠ—æ”»å‡»å½±å“ï¼Œå¯¼è‡´æ•´ä½“ç³»ç»Ÿé²æ£’æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨è§†è§‰æ¨¡æ€å†…éƒ¨çš„å¯¹æŠ—é˜²å¾¡ï¼Œå¿½ç•¥äº†è·¨æ¨¡æ€ä¿¡æ¯ï¼Œå¯¼è‡´é˜²å¾¡æ•ˆæœæœ‰é™ï¼Œä¸”å¯èƒ½æŸå®³é›¶æ ·æœ¬è¿ç§»èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è·¨æ¨¡æ€ä¿¡æ¯æ¥å¢å¼ºè§†è§‰æ¨¡æ€çš„å¯¹æŠ—é²æ£’æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡å°†è§†è§‰ç‰¹å¾ä¸æ–‡æœ¬é”šç‚¹å¯¹é½ï¼Œå¹¶å¼ºåˆ¶è·¨æ¨¡æ€çš„ç±»åˆ«åˆ†å¸ƒä¸€è‡´ï¼Œä»è€Œæé«˜è§†è§‰ç¼–ç å™¨åœ¨å¯¹æŠ—æ”»å‡»ä¸‹çš„ä¸å˜æ€§ã€‚è¿™ç§æ–¹æ³•å……åˆ†åˆ©ç”¨äº†ä¸åŒæ¨¡æ€ä¹‹é—´çš„äº’è¡¥ä¿¡æ¯ï¼Œä»è€Œæå‡äº†æ•´ä½“çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRLBindæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯æ— ç›‘ç£çš„è§†è§‰ç¼–ç å™¨å¼ºåŒ–ï¼Œé€šè¿‡åœ¨å¹²å‡€-å¯¹æŠ—æ ·æœ¬å¯¹ä¸Šè¿›è¡Œå¾®è°ƒï¼Œæé«˜è§†è§‰ç¼–ç å™¨è‡ªèº«çš„é²æ£’æ€§ã€‚ç¬¬äºŒé˜¶æ®µæ˜¯è·¨æ¨¡æ€å¯¹é½ï¼Œé€šè¿‡æœ€å°åŒ–å¹²å‡€/å¯¹æŠ—è§†è§‰ç‰¹å¾ä¸æ–‡æœ¬é”šç‚¹ä¹‹é—´çš„å·®å¼‚ï¼Œå¹¶å¼ºåˆ¶è·¨æ¨¡æ€çš„ç±»åˆ«åˆ†å¸ƒå¯¹é½ï¼Œè¿›ä¸€æ­¥å¢å¼ºè§†è§‰ç‰¹å¾çš„å¯¹æŠ—ä¸å˜æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šRLBindçš„å…³é”®åˆ›æ–°åœ¨äºå…¶è·¨æ¨¡æ€å¯¹é½ç­–ç•¥ã€‚ä¸ä»¥å¾€ä»…å…³æ³¨è§†è§‰æ¨¡æ€å†…éƒ¨å¯¹æŠ—é˜²å¾¡çš„æ–¹æ³•ä¸åŒï¼ŒRLBindå……åˆ†åˆ©ç”¨äº†æ–‡æœ¬æ¨¡æ€ä½œä¸ºé”šç‚¹ï¼Œé€šè¿‡è·¨æ¨¡æ€å¯¹é½æ¥æé«˜è§†è§‰ç‰¹å¾çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œä¸¤é˜¶æ®µçš„è®­ç»ƒç­–ç•¥ä¹Ÿä¿è¯äº†è§†è§‰ç¼–ç å™¨åœ¨å¯¹æŠ—æ”»å‡»ä¸‹çš„ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç¬¬ä¸€é˜¶æ®µï¼Œä½¿ç”¨è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼ˆå…·ä½“æ–¹æ³•æœªçŸ¥ï¼‰åœ¨å¹²å‡€-å¯¹æŠ—æ ·æœ¬å¯¹ä¸Šå¾®è°ƒè§†è§‰ç¼–ç å™¨ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œä½¿ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±æ¥æœ€å°åŒ–å¹²å‡€/å¯¹æŠ—è§†è§‰ç‰¹å¾ä¸æ–‡æœ¬é”šç‚¹ä¹‹é—´çš„è·ç¦»ã€‚åŒæ—¶ï¼Œä½¿ç”¨åˆ†å¸ƒå¯¹é½æŸå¤±ï¼ˆå…·ä½“å½¢å¼æœªçŸ¥ï¼‰æ¥å¼ºåˆ¶è·¨æ¨¡æ€çš„ç±»åˆ«åˆ†å¸ƒä¸€è‡´ã€‚æ–‡æœ¬é”šç‚¹å¯èƒ½æ˜¯é€šè¿‡æ–‡æœ¬ç¼–ç å™¨è·å¾—çš„ç±»åˆ«æè¿°åµŒå…¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRLBindåœ¨å›¾åƒã€éŸ³é¢‘ã€çƒ­æˆåƒå’Œè§†é¢‘æ•°æ®ä¸Šï¼Œç›¸æ¯”LanguageBindéª¨å¹²ç½‘ç»œå’Œæ ‡å‡†å¾®è°ƒåŸºçº¿ï¼Œåœ¨å¹²å‡€å‡†ç¡®æ€§å’ŒèŒƒæ•°æœ‰ç•Œå¯¹æŠ—é²æ£’æ€§æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­è¯¦ç»†ç»™å‡ºï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RLBindå¯åº”ç”¨äºå„ç§éœ€è¦å¤šä¼ æ„Ÿå™¨èåˆçš„æœºå™¨äººåº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚å¯¼èˆªã€æ“ä½œå’Œè‡ªä¸»ç³»ç»Ÿã€‚é€šè¿‡æé«˜å¤šæ¨¡æ€æ„ŸçŸ¥çš„é²æ£’æ€§ï¼Œå¯ä»¥æå‡æœºå™¨äººåœ¨å¤æ‚å’Œä¸ç¡®å®šç¯å¢ƒä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚è¯¥ç ”ç©¶å¯¹äºæ¨åŠ¨æœºå™¨äººæŠ€æœ¯åœ¨ç°å®ä¸–ç•Œä¸­çš„å¹¿æ³›åº”ç”¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Unified multi-modal encoders that bind vision, audio, and other sensors into a shared embedding space are attractive building blocks for robot perception and decision-making. However, on-robot deployment exposes the vision branch to adversarial and natural corruptions, making robustness a prerequisite for safety. Prior defenses typically align clean and adversarial features within CLIP-style encoders and overlook broader cross-modal correspondence, yielding modest gains and often degrading zero-shot transfer. We introduce RLBind, a two-stage adversarial-invariant cross-modal alignment framework for robust unified embeddings. Stage 1 performs unsupervised fine-tuning on clean-adversarial pairs to harden the visual encoder. Stage 2 leverages cross-modal correspondence by minimizing the discrepancy between clean/adversarial features and a text anchor, while enforcing class-wise distributional alignment across modalities. Extensive experiments on Image, Audio, Thermal, and Video data show that RLBind consistently outperforms the LanguageBind backbone and standard fine-tuning baselines in both clean accuracy and norm-bounded adversarial robustness. By improving resilience without sacrificing generalization, RLBind provides a practical path toward safer multi-sensor perception stacks for embodied robots in navigation, manipulation, and other autonomy settings.

