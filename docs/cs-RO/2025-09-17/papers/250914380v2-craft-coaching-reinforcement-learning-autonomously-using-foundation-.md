---
layout: default
title: CRAFT: Coaching Reinforcement Learning Autonomously using Foundation Models for Multi-Robot Coordination Tasks
---

# CRAFT: Coaching Reinforcement Learning Autonomously using Foundation Models for Multi-Robot Coordination Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14380" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.14380v2</a>
  <a href="https://arxiv.org/pdf/2509.14380.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14380v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14380v2', 'CRAFT: Coaching Reinforcement Learning Autonomously using Foundation Models for Multi-Robot Coordination Tasks')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Seoyeon Choi, Kanghyun Ryu, Jonghoon Ock, Negar Mehr

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-17 (Êõ¥Êñ∞: 2025-10-01)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**CRAFTÔºöÂà©Áî®ÂÖ∑Ë∫´Êô∫ËÉΩËá™‰∏ªÊåáÂØºÂ§öÊú∫Âô®‰∫∫Âº∫ÂåñÂ≠¶‰π†ÔºåËß£ÂÜ≥Â§çÊùÇÂçè‰Ωú‰ªªÂä°**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†` `ÂÖ∑Ë∫´Êô∫ËÉΩ` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `Êú∫Âô®‰∫∫Âçè‰Ωú` `Ëá™‰∏ªÂ≠¶‰π†` `ËØæÁ®ãÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Â§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†Âú®Êú∫Âô®‰∫∫Âçè‰Ωú‰∏≠Èù¢‰∏¥È´òÁª¥Âä®‰ΩúÁ©∫Èó¥„ÄÅÂ§çÊùÇÂ•ñÂä±ËÆæËÆ°ÂíåÁéØÂ¢ÉÈùûÂπ≥Á®≥ÊÄßÁ≠âÊåëÊàò„ÄÇ
2. CRAFTÂà©Áî®ÂÖ∑Ë∫´Êô∫ËÉΩ‰Ωú‰∏∫‚ÄúÊïôÁªÉ‚ÄùÔºåÈÄöËøáLLMÂàÜËß£‰ªªÂä°ÂíåÁîüÊàêÂ•ñÂä±ÔºåVLMÁªÜÂåñÂ•ñÂä±ÔºåÂÆûÁé∞Ëá™‰∏ªËØæÁ®ãÂ≠¶‰π†„ÄÇ
3. ÂÆûÈ™åË°®ÊòéCRAFTÂú®Â§öË∂≥Êú∫Âô®‰∫∫ÂØºËà™ÂíåÂèåÊâãÊìç‰Ωú‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂπ∂Âú®ÁúüÂÆûÊú∫Âô®‰∫∫‰∏äÈ™åËØÅ‰∫ÜÂØºËà™Á≠ñÁï•„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†(MARL)‰∏∫Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªü‰∏≠ÁöÑÂçè‰ΩúÂ≠¶‰π†Êèê‰æõ‰∫Ü‰∏Ä‰∏™Âº∫Â§ßÁöÑÊ°ÜÊû∂„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÈ´òÁª¥ËøûÁª≠ËÅîÂêàÂä®‰ΩúÁ©∫Èó¥„ÄÅÂ§çÊùÇÁöÑÂõûÊä•ÂáΩÊï∞ËÆæËÆ°‰ª•ÂèäÂéª‰∏≠ÂøÉÂåñËÆæÁΩÆ‰∏≠Âõ∫ÊúâÁöÑÈùûÂπ≥Á®≥ËΩ¨ÁßªÔºåÂ∞ÜMARLÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊàòÊÄß„ÄÇÂè¶‰∏ÄÊñπÈù¢Ôºå‰∫∫Á±ªÈÄöËøáÂàÜÈò∂ÊÆµÁöÑËØæÁ®ãÂ≠¶‰π†Â§çÊùÇÁöÑÂçè‰ΩúÔºåÂÖ∂‰∏≠ÈïøÊúüË°å‰∏∫ÈÄêÊ≠•Âª∫Á´ãÂú®Êõ¥ÁÆÄÂçïÁöÑÊäÄËÉΩ‰πã‰∏ä„ÄÇÂèóÊ≠§ÂêØÂèëÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜCRAFTÔºöÂà©Áî®ÂÖ∑Ë∫´Êô∫ËÉΩËá™‰∏ªÊåáÂØºÂ§öÊú∫Âô®‰∫∫Âº∫ÂåñÂ≠¶‰π†ÔºåÁî®‰∫éÂ§öÊú∫Âô®‰∫∫Âçè‰Ωú‰ªªÂä°ÔºåËØ•Ê°ÜÊû∂Âà©Áî®ÂÖ∑Ë∫´Êô∫ËÉΩÁöÑÊé®ÁêÜËÉΩÂäõ‰Ωú‰∏∫Â§öÊú∫Âô®‰∫∫Âçè‰ΩúÁöÑ‚ÄúÊïôÁªÉ‚Äù„ÄÇCRAFT‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã(LLM)ÁöÑËßÑÂàíËÉΩÂäõËá™Âä®Â∞ÜÈïøÊúüÂçè‰Ωú‰ªªÂä°ÂàÜËß£‰∏∫Â≠ê‰ªªÂä°Â∫èÂàó„ÄÇÊé•‰∏ãÊù•ÔºåCRAFT‰ΩøÁî®LLMÁîüÊàêÁöÑÂõûÊä•ÂáΩÊï∞ËÆ≠ÁªÉÊØè‰∏™Â≠ê‰ªªÂä°ÔºåÂπ∂ÈÄöËøáËßÜËßâËØ≠Ë®ÄÊ®°Âûã(VLM)ÂºïÂØºÁöÑÂõûÊä•ÁªÜÂåñÂæ™ÁéØÊù•ÊîπËøõÂÆÉ‰ª¨„ÄÇÊàë‰ª¨Âú®Â§öË∂≥Êú∫Âô®‰∫∫ÂØºËà™ÂíåÂèåÊâãÊìç‰Ωú‰ªªÂä°‰∏äËØÑ‰º∞CRAFTÔºåËØÅÊòé‰∫ÜÂÖ∂Â≠¶‰π†Â§çÊùÇÂçè‰ΩúË°å‰∏∫ÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Âú®ÁúüÂÆûÁ°¨‰ª∂ÂÆûÈ™å‰∏≠È™åËØÅ‰∫ÜÂ§öË∂≥Êú∫Âô®‰∫∫ÂØºËà™Á≠ñÁï•„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂ§öÊú∫Âô®‰∫∫Âçè‰Ωú‰ªªÂä°ÈÄöÂ∏∏Ê∂âÂèäÂ§çÊùÇÁöÑÈïøÊúüË°å‰∏∫ÔºåÁõ¥Êé•Â∫îÁî®Âº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÈöæÂ∫¶Â§ßÔºåÈúÄË¶Å‰∫∫Â∑•ËÆæËÆ°Â§çÊùÇÁöÑÂ•ñÂä±ÂáΩÊï∞Ôºå‰∏îÈöæ‰ª•ÈÄÇÂ∫îÁéØÂ¢ÉÂèòÂåñ„ÄÇÁé∞ÊúâÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÊòØÂú®È´òÁª¥ËøûÁª≠Âä®‰ΩúÁ©∫Èó¥ÂíåÈùûÂπ≥Á®≥ÁéØÂ¢É‰∏≠„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöCRAFTÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊ®°‰ªø‰∫∫Á±ªÂ≠¶‰π†ËøáÁ®ãÔºåÂ∞ÜÂ§çÊùÇÁöÑÈïøÊúü‰ªªÂä°ÂàÜËß£‰∏∫‰∏ÄÁ≥ªÂàóÁÆÄÂçïÁöÑÂ≠ê‰ªªÂä°ÔºåÂπ∂Âà©Áî®ÂÖ∑Ë∫´Êô∫ËÉΩËá™Âä®ÁîüÊàêÂíå‰ºòÂåñÊØè‰∏™Â≠ê‰ªªÂä°ÁöÑÂ•ñÂä±ÂáΩÊï∞„ÄÇÈÄöËøáËøôÁßçÂàÜÈò∂ÊÆµÁöÑËØæÁ®ãÂ≠¶‰π†ÊñπÂºèÔºåÈôç‰Ωé‰∫ÜÂ≠¶‰π†ÈöæÂ∫¶ÔºåÊèêÈ´ò‰∫ÜÂ≠¶‰π†ÊïàÁéáÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCRAFTÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö
1. **‰ªªÂä°ÂàÜËß£Ê®°Âùó**Ôºö‰ΩøÁî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã(LLM)Â∞ÜÈïøÊúü‰ªªÂä°ÂàÜËß£‰∏∫‰∏ÄÁ≥ªÂàóÂ≠ê‰ªªÂä°„ÄÇ
2. **Â•ñÂä±ÁîüÊàêÊ®°Âùó**Ôºö‰ΩøÁî®LLM‰∏∫ÊØè‰∏™Â≠ê‰ªªÂä°ÁîüÊàêÂàùÂßãÂ•ñÂä±ÂáΩÊï∞„ÄÇ
3. **Â•ñÂä±ÁªÜÂåñÊ®°Âùó**Ôºö‰ΩøÁî®ËßÜËßâËØ≠Ë®ÄÊ®°Âûã(VLM)ËØÑ‰º∞ÂΩìÂâçÁ≠ñÁï•Âú®Â≠ê‰ªªÂä°‰∏≠ÁöÑË°®Áé∞ÔºåÂπ∂Ê†πÊçÆËØÑ‰º∞ÁªìÊûúË∞ÉÊï¥Â•ñÂä±ÂáΩÊï∞„ÄÇ
4. **Âº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÊ®°Âùó**Ôºö‰ΩøÁî®MARLÁÆóÊ≥ïËÆ≠ÁªÉÊØè‰∏™Â≠ê‰ªªÂä°ÁöÑÁ≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöCRAFTÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂà©Áî®ÂÖ∑Ë∫´Êô∫ËÉΩËá™Âä®ÁîüÊàêÂíå‰ºòÂåñÂ•ñÂä±ÂáΩÊï∞ÔºåÈÅøÂÖç‰∫Ü‰∫∫Â∑•ËÆæËÆ°ÁöÑÁπÅÁêêÂíå‰∏ªËßÇÊÄß„ÄÇÈÄöËøáLLMËøõË°å‰ªªÂä°ÂàÜËß£ÂíåÂ•ñÂä±ÁîüÊàêÔºåVLMËøõË°åÂ•ñÂä±ÁªÜÂåñÔºåÂÆûÁé∞‰∫ÜËá™‰∏ªÁöÑËØæÁ®ãÂ≠¶‰π†ËøáÁ®ã„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂ§çÊùÇÁéØÂ¢ÉÂíå‰ªªÂä°ÂèòÂåñÔºåÊèêÈ´òÂ§öÊú∫Âô®‰∫∫Âçè‰ΩúÁöÑÂ≠¶‰π†ÊïàÁéáÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**Ôºö
1. **LLM‰ªªÂä°ÂàÜËß£**Ôºö‰ΩøÁî®Prompt EngineeringÔºåËÆæËÆ°ÂêàÈÄÇÁöÑPromptÔºåÂºïÂØºLLMÂ∞ÜÂ§çÊùÇ‰ªªÂä°ÂàÜËß£‰∏∫ÂêàÁêÜÁöÑÂ≠ê‰ªªÂä°Â∫èÂàó„ÄÇ
2. **LLMÂ•ñÂä±ÁîüÊàê**Ôºö‰ΩøÁî®LLMÁîüÊàêÂü∫‰∫éÊñáÊú¨ÊèèËø∞ÁöÑÂ•ñÂä±ÂáΩÊï∞Ôºå‰æãÂ¶Ç‚ÄúÊú∫Âô®‰∫∫Èù†ËøëÁõÆÊ†á‚ÄùÁ≠â„ÄÇ
3. **VLMÂ•ñÂä±ÁªÜÂåñ**Ôºö‰ΩøÁî®VLMËØÑ‰º∞Êú∫Âô®‰∫∫Ë°å‰∏∫‰∏éÊúüÊúõË°å‰∏∫ÁöÑÂ∑ÆÂºÇÔºåÂπ∂Ê†πÊçÆÂ∑ÆÂºÇË∞ÉÊï¥Â•ñÂä±ÂáΩÊï∞„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÊú∫Âô®‰∫∫ÂÅèÁ¶ª‰∫ÜÈ¢ÑÂÆöË∑ØÁ∫øÔºåÂàôÈôç‰ΩéÂ•ñÂä±„ÄÇ
4. **MARLÁÆóÊ≥ï**ÔºöÂèØ‰ª•‰ΩøÁî®‰ªª‰ΩïÂêàÈÄÇÁöÑMARLÁÆóÊ≥ïÔºå‰æãÂ¶ÇMADDPG„ÄÅTD3Á≠â„ÄÇËÆ∫Êñá‰∏≠ÂÖ∑‰Ωì‰ΩøÁî®ÁöÑÁÆóÊ≥ïÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

CRAFTÂú®Â§öË∂≥Êú∫Âô®‰∫∫ÂØºËà™ÂíåÂèåÊâãÊìç‰Ωú‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÊàêÊûú„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCRAFTËÉΩÂ§üÂ≠¶‰π†Âà∞Â§çÊùÇÁöÑÂçè‰ΩúË°å‰∏∫ÔºåÂπ∂Âú®ÁúüÂÆûÊú∫Âô®‰∫∫‰∏äÈ™åËØÅ‰∫ÜÂØºËà™Á≠ñÁï•ÁöÑÊúâÊïàÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÂØπÊØîÂü∫Á∫øÂú®ËÆ∫Êñá‰∏≠Êú™ÊòéÁ°ÆÁªôÂá∫Ôºå‰ΩÜÂº∫Ë∞É‰∫ÜCRAFTÂú®Â§çÊùÇÂçè‰Ωú‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

CRAFTÂú®Â§öÊú∫Âô®‰∫∫Âçè‰ΩúÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÔºöÂçèÂêåÊê¨Ëøê„ÄÅÂçèÂêåË£ÖÈÖç„ÄÅÂçèÂêåÊêúÁ¥¢ÊïëÊè¥Á≠â„ÄÇËØ•ÊñπÊ≥ïÂèØ‰ª•Èôç‰ΩéÂ§öÊú∫Âô®‰∫∫Á≥ªÁªüÂºÄÂèëÁöÑÈöæÂ∫¶ÔºåÊèêÈ´òÁ≥ªÁªüÁöÑËá™‰∏ªÊÄßÂíåÈÄÇÂ∫îÊÄßÔºå‰ªéËÄåÂú®Â∑•‰∏öËá™Âä®Âåñ„ÄÅÁâ©ÊµÅ„ÄÅÂåªÁñóÁ≠âÈ¢ÜÂüüÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇÊú™Êù•ÔºåCRAFTÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞Êõ¥Â§çÊùÇÁöÑ‰ªªÂä°ÂíåÁéØÂ¢ÉÔºå‰æãÂ¶ÇÔºöÂºÇÊûÑÊú∫Âô®‰∫∫Âçè‰Ωú„ÄÅ‰∫∫Êú∫Âçè‰ΩúÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multi-Agent Reinforcement Learning (MARL) provides a powerful framework for learning coordination in multi-agent systems. However, applying MARL to robotics still remains challenging due to high-dimensional continuous joint action spaces, complex reward design, and non-stationary transitions inherent to decentralized settings. On the other hand, humans learn complex coordination through staged curricula, where long-horizon behaviors are progressively built upon simpler skills. Motivated by this, we propose CRAFT: Coaching Reinforcement learning Autonomously using Foundation models for multi-robot coordination Tasks, a framework that leverages the reasoning capabilities of foundation models to act as a "coach" for multi-robot coordination. CRAFT automatically decomposes long-horizon coordination tasks into sequences of subtasks using the planning capability of Large Language Models (LLMs). In what follows, CRAFT trains each subtask using reward functions generated by LLM, and refines them through a Vision Language Model (VLM)-guided reward-refinement loop. We evaluate CRAFT on multi-quadruped navigation and bimanual manipulation tasks, demonstrating its capability to learn complex coordination behaviors. In addition, we validate the multi-quadruped navigation policy in real hardware experiments.

