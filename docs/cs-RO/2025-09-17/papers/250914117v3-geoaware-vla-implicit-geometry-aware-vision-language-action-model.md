---
layout: default
title: GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model
---

# GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14117" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14117v3</a>
  <a href="https://arxiv.org/pdf/2509.14117.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14117v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14117v3', 'GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ali Abouzeid, Malak Mansour, Zezhou Sun, Dezhen Song

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-17 (æ›´æ–°: 2025-11-07)

**å¤‡æ³¨**: Under Review, Project Page https://alisharey.github.io/GeoAware-VLA/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**GeoAware-VLAï¼šåˆ©ç”¨å‡ ä½•å…ˆéªŒæå‡VLAæ¨¡å‹è§†è§’æ³›åŒ–èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹` `å‡ ä½•å…ˆéªŒ` `è§†è§’æ³›åŒ–` `æœºå™¨äººå­¦ä¹ ` `é¢„è®­ç»ƒæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. VLAæ¨¡å‹åœ¨è§†è§’æ³›åŒ–æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥ä»2Då›¾åƒä¸­å‡†ç¡®æ¨æ–­3Då‡ ä½•ä¿¡æ¯ã€‚
2. GeoAware-VLAåˆ©ç”¨é¢„è®­ç»ƒçš„å‡ ä½•è§†è§‰æ¨¡å‹æå–å‡ ä½•ç‰¹å¾ï¼Œå¹¶ç”¨å¯è®­ç»ƒæŠ•å½±å±‚é€‚é…ç­–ç•¥è§£ç å™¨ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGeoAware-VLAåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººç¯å¢ƒä¸­å‡æ˜¾è‘—æå‡äº†è§†è§’æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹å¸¸å¸¸éš¾ä»¥æ³›åŒ–åˆ°æ–°çš„ç›¸æœºè§†è§’ï¼Œè¿™æºäºå®ƒä»¬éš¾ä»¥ä»2Då›¾åƒä¸­æ¨æ–­å‡ºé²æ£’çš„3Då‡ ä½•ä¿¡æ¯ã€‚æˆ‘ä»¬æå‡ºäº†GeoAware-VLAï¼Œä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œé€šè¿‡å°†å¼ºå‡ ä½•å…ˆéªŒé›†æˆåˆ°è§†è§‰éª¨å¹²ç½‘ç»œä¸­æ¥å¢å¼ºè§†è§’ä¸å˜æ€§ã€‚æˆ‘ä»¬æ²¡æœ‰è®­ç»ƒè§†è§‰ç¼–ç å™¨æˆ–ä¾èµ–æ˜¾å¼çš„3Dæ•°æ®ï¼Œè€Œæ˜¯åˆ©ç”¨ä¸€ä¸ªå†»ç»“çš„ã€é¢„è®­ç»ƒçš„å‡ ä½•è§†è§‰æ¨¡å‹ä½œä¸ºç‰¹å¾æå–å™¨ã€‚ç„¶åï¼Œä¸€ä¸ªå¯è®­ç»ƒçš„æŠ•å½±å±‚è°ƒæ•´è¿™äº›å¯Œå«å‡ ä½•ä¿¡æ¯çš„ç‰¹å¾ï¼Œä»¥ä¾›ç­–ç•¥è§£ç å™¨ä½¿ç”¨ï¼Œä»è€Œå‡è½»äº†å®ƒä»å¤´å¼€å§‹å­¦ä¹ 3Dä¸€è‡´æ€§çš„è´Ÿæ‹…ã€‚é€šè¿‡åœ¨LIBEROåŸºå‡†å­é›†ä¸Šè¿›è¡Œçš„å¤§é‡è¯„ä¼°ï¼Œæˆ‘ä»¬è¡¨æ˜GeoAware-VLAåœ¨é›¶æ ·æœ¬æ³›åŒ–åˆ°æ–°çš„ç›¸æœºå§¿æ€æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œåœ¨æ¨¡æ‹Ÿä¸­å°†æˆåŠŸç‡æé«˜äº†2å€ä»¥ä¸Šã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼Œè¿™äº›ä¼˜åŠ¿è½¬åŒ–ä¸ºç‰©ç†ä¸–ç•Œï¼›æˆ‘ä»¬çš„æ¨¡å‹åœ¨çœŸå®æœºå™¨äººä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨ä»çœ‹ä¸è§çš„ç›¸æœºè§’åº¦è¿›è¡Œè¯„ä¼°æ—¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨è¿ç»­å’Œç¦»æ•£åŠ¨ä½œç©ºé—´ä¸­éƒ½è¯æ˜æ˜¯æœ‰æ•ˆçš„ï¼Œçªå‡ºäº†é²æ£’çš„å‡ ä½•åŸºç¡€æ˜¯åˆ›å»ºæ›´å…·æ³›åŒ–èƒ½åŠ›çš„æœºå™¨äººä»£ç†çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹åœ¨é¢å¯¹æ–°çš„ç›¸æœºè§†è§’æ—¶ï¼Œæ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚è¿™æ˜¯å› ä¸ºè¿™äº›æ¨¡å‹éš¾ä»¥ä»2Då›¾åƒä¸­å­¦ä¹ åˆ°é²æ£’çš„3Då‡ ä½•ä¿¡æ¯ï¼Œå¯¼è‡´å…¶å¯¹è§†è§’å˜åŒ–æ•æ„Ÿã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦ä»å¤´è®­ç»ƒè§†è§‰ç¼–ç å™¨ï¼Œæˆ–è€…ä¾èµ–æ˜¾å¼çš„3Dæ•°æ®ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ä¸”æ•ˆæœæœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGeoAware-VLAçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„å‡ ä½•è§†è§‰æ¨¡å‹ï¼Œæå–å›¾åƒä¸­è•´å«çš„ä¸°å¯Œå‡ ä½•ç‰¹å¾ï¼Œå¹¶å°†è¿™äº›ç‰¹å¾èå…¥åˆ°VLAæ¨¡å‹çš„è§†è§‰éª¨å¹²ç½‘ç»œä¸­ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å¯ä»¥ç›´æ¥åˆ©ç”¨å·²æœ‰çš„å‡ ä½•çŸ¥è¯†ï¼Œè€Œæ— éœ€ä»å¤´å­¦ä¹ 3Dä¸€è‡´æ€§ï¼Œä»è€Œæé«˜å…¶å¯¹è§†è§’å˜åŒ–çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGeoAware-VLAçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¢„è®­ç»ƒçš„å‡ ä½•è§†è§‰æ¨¡å‹ã€å¯è®­ç»ƒçš„æŠ•å½±å±‚å’Œç­–ç•¥è§£ç å™¨ã€‚é¦–å…ˆï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„å‡ ä½•è§†è§‰æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼ŒåŸºäºæ·±åº¦ä¼°è®¡æˆ–ä¸‰ç»´é‡å»ºçš„æ¨¡å‹ï¼‰æå–è¾“å…¥å›¾åƒçš„å‡ ä½•ç‰¹å¾ã€‚ç„¶åï¼Œé€šè¿‡ä¸€ä¸ªå¯è®­ç»ƒçš„æŠ•å½±å±‚ï¼Œå°†è¿™äº›å‡ ä½•ç‰¹å¾æ˜ å°„åˆ°ç­–ç•¥è§£ç å™¨å¯ä»¥ç†è§£çš„ç‰¹å¾ç©ºé—´ã€‚æœ€åï¼Œç­–ç•¥è§£ç å™¨æ ¹æ®æŠ•å½±åçš„ç‰¹å¾ï¼Œç”Ÿæˆç›¸åº”çš„åŠ¨ä½œæŒ‡ä»¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šGeoAware-VLAçš„å…³é”®åˆ›æ–°åœ¨äºå°†é¢„è®­ç»ƒçš„å‡ ä½•è§†è§‰æ¨¡å‹ä½œä¸ºç‰¹å¾æå–å™¨ï¼Œç›´æ¥ä¸ºVLAæ¨¡å‹æä¾›å‡ ä½•å…ˆéªŒçŸ¥è¯†ã€‚è¿™ç§æ–¹æ³•é¿å…äº†ä»å¤´è®­ç»ƒè§†è§‰ç¼–ç å™¨æˆ–ä¾èµ–æ˜¾å¼3Dæ•°æ®ï¼Œå¤§å¤§é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œå¹¶æé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒGeoAware-VLAèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨å·²æœ‰çš„å‡ ä½•çŸ¥è¯†ï¼Œä»è€Œæ›´å¥½åœ°é€‚åº”æ–°çš„ç›¸æœºè§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šGeoAware-VLAçš„å…³é”®è®¾è®¡åŒ…æ‹¬é€‰æ‹©åˆé€‚çš„é¢„è®­ç»ƒå‡ ä½•è§†è§‰æ¨¡å‹ï¼Œä»¥åŠè®¾è®¡æœ‰æ•ˆçš„æŠ•å½±å±‚ã€‚é¢„è®­ç»ƒæ¨¡å‹çš„é€‰æ‹©å–å†³äºå…·ä½“çš„ä»»åŠ¡å’Œæ•°æ®é›†ï¼Œå¯ä»¥é€‰æ‹©åŸºäºæ·±åº¦ä¼°è®¡ã€ä¸‰ç»´é‡å»ºæˆ–SLAMçš„æ¨¡å‹ã€‚æŠ•å½±å±‚å¯ä»¥ä½¿ç”¨ç®€å•çš„çº¿æ€§å±‚æˆ–æ›´å¤æ‚çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œå…¶ç›®æ ‡æ˜¯å°†å‡ ä½•ç‰¹å¾æ˜ å°„åˆ°ç­–ç•¥è§£ç å™¨å¯ä»¥ç†è§£çš„ç‰¹å¾ç©ºé—´ã€‚æŸå¤±å‡½æ•°é€šå¸¸åŒ…æ‹¬ç­–ç•¥å­¦ä¹ çš„æŸå¤±å‡½æ•°ï¼ˆä¾‹å¦‚ï¼Œå¼ºåŒ–å­¦ä¹ ä¸­çš„å¥–åŠ±å‡½æ•°ï¼‰ä»¥åŠå¯é€‰çš„å‡ ä½•ä¸€è‡´æ€§æŸå¤±å‡½æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

GeoAware-VLAåœ¨LIBEROåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­ï¼Œè¯¥æ¨¡å‹åœ¨é›¶æ ·æœ¬æ³›åŒ–åˆ°æ–°çš„ç›¸æœºå§¿æ€æ–¹é¢ï¼ŒæˆåŠŸç‡æé«˜äº†2å€ä»¥ä¸Šã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè¿™äº›ä¼˜åŠ¿ä¹ŸæˆåŠŸåœ°è½¬åŒ–åˆ°äº†çœŸå®æœºå™¨äººç¯å¢ƒä¸­ï¼Œå°¤å…¶æ˜¯åœ¨ä»æœªè§è¿‡çš„ç›¸æœºè§’åº¦è¿›è¡Œè¯„ä¼°æ—¶ï¼Œæ€§èƒ½æå‡å°¤ä¸ºæ˜æ˜¾ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒGeoAware-VLAèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜VLAæ¨¡å‹åœ¨çœŸå®ä¸–ç•Œä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GeoAware-VLAå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰é¢†åŸŸã€‚è¯¥æ–¹æ³•å¯ä»¥æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è‡ªä¸»æ€§å’Œé€‚åº”æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œå“åº”å‘¨å›´ç¯å¢ƒçš„å˜åŒ–ã€‚æ­¤å¤–ï¼ŒGeoAware-VLAè¿˜å¯ä»¥åº”ç”¨äºè™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®åº”ç”¨ä¸­ï¼Œæé«˜è™šæ‹Ÿåœºæ™¯çš„çœŸå®æ„Ÿå’Œäº¤äº’æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models often fail to generalize to novel camera viewpoints, a limitation stemming from their difficulty in inferring robust 3D geometry from 2D images. We introduce GeoAware-VLA, a simple yet effective approach that enhances viewpoint invariance by integrating strong geometric priors into the vision backbone. Instead of training a visual encoder or relying on explicit 3D data, we leverage a frozen, pretrained geometric vision model as a feature extractor. A trainable projection layer then adapts these geometrically-rich features for the policy decoder, relieving it of the burden of learning 3D consistency from scratch. Through extensive evaluations on LIBERO benchmark subsets, we show GeoAware-VLA achieves substantial improvements in zero-shot generalization to novel camera poses, boosting success rates by over 2x in simulation. Crucially, these benefits translate to the physical world; our model shows a significant performance gain on a real robot, especially when evaluated from unseen camera angles. Our approach proves effective across both continuous and discrete action spaces, highlighting that robust geometric grounding is a key component for creating more generalizable robotic agents.

