---
layout: default
title: Pre-Manipulation Alignment Prediction with Parallel Deep State-Space and Transformer Models
---

# Pre-Manipulation Alignment Prediction with Parallel Deep State-Space and Transformer Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.13839" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.13839v1</a>
  <a href="https://arxiv.org/pdf/2509.13839.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.13839v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.13839v1', 'Pre-Manipulation Alignment Prediction with Parallel Deep State-Space and Transformer Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Motonari Kambara, Komei Sugiura

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-17

**å¤‡æ³¨**: Published in Advanced Robotics

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¹¶è¡Œæ·±åº¦çŠ¶æ€ç©ºé—´æ¨¡å‹ä¸Transformerçš„é¢„æ“ä½œå¯¹é½é¢„æµ‹æ–¹æ³•ï¼Œæå‡æœºå™¨äººæ“ä½œæˆåŠŸç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `é¢„æ“ä½œé¢„æµ‹` `æ·±åº¦çŠ¶æ€ç©ºé—´æ¨¡å‹` `Transformer` `è½¨è¿¹èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººæ“ä½œæ–¹æ³•ä¾èµ–åŠ¨ä½œæ‰§è¡Œåçš„ç»“æœåˆ¤æ–­ï¼Œæ— æ³•æå‰é¢„çŸ¥é£é™©ï¼Œæ•ˆç‡è¾ƒä½ã€‚
2. æå‡ºä¸€ç§é¢„æµ‹é¢„æ“ä½œå›¾åƒã€è½¨è¿¹å’ŒæŒ‡ä»¤å¯¹é½ç¨‹åº¦çš„æ¨¡å‹ï¼Œæå‰é¢„æµ‹æ“ä½œæˆåŠŸç‡ã€‚
3. é‡‡ç”¨æ·±åº¦çŠ¶æ€ç©ºé—´æ¨¡å‹å’ŒTransformerå¹¶è¡Œèåˆè½¨è¿¹ä¿¡æ¯ï¼Œå®éªŒç»“æœä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ—¨åœ¨è§£å†³å¼€æ”¾è¯æ±‡ç‰©ä½“æ“ä½œä»»åŠ¡ä¸­é¢„æµ‹æœªæ¥æ“ä½œæˆåŠŸç‡çš„é—®é¢˜ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸åœ¨åŠ¨ä½œæ‰§è¡Œåæ‰åˆ¤æ–­æˆåŠŸä¸å¦ï¼Œéš¾ä»¥é¢„é˜²æ½œåœ¨é£é™©ï¼Œä¸”ä¾èµ–å¤±è´¥æ¥è§¦å‘é‡è§„åˆ’ï¼Œé™ä½äº†ç‰©ä½“æ“ä½œåºåˆ—çš„æ•ˆç‡ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é¢„æµ‹é¢„æ“ä½œçš„ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„å›¾åƒä¸è§„åˆ’è½¨è¿¹ä»¥åŠç»™å®šçš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ä¹‹é—´çš„å¯¹é½ç¨‹åº¦ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¤šçº§è½¨è¿¹èåˆæ¨¡å—ï¼Œè¯¥æ¨¡å—å¹¶è¡Œé‡‡ç”¨æœ€å…ˆè¿›çš„æ·±åº¦çŠ¶æ€ç©ºé—´æ¨¡å‹å’ŒTransformerç¼–ç å™¨ï¼Œä»¥æ•è·æœ«ç«¯æ‰§è¡Œå™¨è½¨è¿¹ä¸­çš„å¤šçº§æ—¶é—´åºåˆ—è‡ªç›¸å…³æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•ä¼˜äºåŒ…æ‹¬åŸºç¡€æ¨¡å‹åœ¨å†…çš„ç°æœ‰æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæ“ä½œä¸­ï¼Œå¦‚ä½•æå‰é¢„æµ‹æ“ä½œæˆåŠŸç‡çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºæ‰§è¡Œåçš„ç»“æœåé¦ˆï¼Œæ— æ³•åœ¨æ“ä½œå‰è¿›è¡Œè¯„ä¼°å’Œè°ƒæ•´ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ï¼Œç”šè‡³å¯èƒ½å¼•å‘å®‰å…¨é—®é¢˜ã€‚å°¤å…¶æ˜¯åœ¨å¼€æ”¾è¯æ±‡ç‰©ä½“æ“ä½œä»»åŠ¡ä¸­ï¼Œç”±äºç‰©ä½“ç§ç±»ç¹å¤šã€æ“ä½œå¤æ‚ï¼Œæå‰é¢„æµ‹æ“ä½œæˆåŠŸç‡å˜å¾—å°¤ä¸ºé‡è¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ï¼Œé€šè¿‡åˆ†æé¢„æ“ä½œé˜¶æ®µçš„è§†è§‰ä¿¡æ¯ï¼ˆä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„å›¾åƒï¼‰ã€è§„åˆ’è½¨è¿¹å’Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œé¢„æµ‹å®ƒä»¬ä¹‹é—´çš„å¯¹é½ç¨‹åº¦ï¼Œä»è€Œåˆ¤æ–­æ“ä½œçš„æ½œåœ¨æˆåŠŸç‡ã€‚å¦‚æœé¢„æµ‹å¯¹é½ç¨‹åº¦è¾ƒä½ï¼Œåˆ™å¯ä»¥åŠæ—¶è¿›è¡Œé‡è§„åˆ’ï¼Œé¿å…ä¸å¿…è¦çš„å¤±è´¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è¾“å…¥æ¨¡å—ï¼šæ¥æ”¶é¢„æ“ä½œçš„ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„å›¾åƒã€è§„åˆ’è½¨è¿¹å’Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤ä½œä¸ºè¾“å…¥ã€‚2) ç‰¹å¾æå–æ¨¡å—ï¼šåˆ†åˆ«æå–å›¾åƒã€è½¨è¿¹å’ŒæŒ‡ä»¤çš„ç‰¹å¾ã€‚3) å¤šçº§è½¨è¿¹èåˆæ¨¡å—ï¼šè¿™æ˜¯è®ºæ–‡çš„å…³é”®æ¨¡å—ï¼Œå¹¶è¡Œä½¿ç”¨æ·±åº¦çŠ¶æ€ç©ºé—´æ¨¡å‹å’ŒTransformerç¼–ç å™¨æ¥æ•è·è½¨è¿¹ä¸­çš„å¤šçº§æ—¶é—´åºåˆ—è‡ªç›¸å…³æ€§ã€‚4) å¯¹é½é¢„æµ‹æ¨¡å—ï¼šåŸºäºæå–çš„ç‰¹å¾ï¼Œé¢„æµ‹å›¾åƒã€è½¨è¿¹å’ŒæŒ‡ä»¤ä¹‹é—´çš„å¯¹é½ç¨‹åº¦ï¼Œè¾“å‡ºæ“ä½œæˆåŠŸç‡çš„é¢„æµ‹ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¤šçº§è½¨è¿¹èåˆæ¨¡å—çš„è®¾è®¡ã€‚ä¼ ç»Ÿæ–¹æ³•å¯èƒ½åªå…³æ³¨è½¨è¿¹çš„æ•´ä½“ç‰¹å¾ï¼Œè€Œå¿½ç•¥äº†è½¨è¿¹å†…éƒ¨çš„æ—¶é—´åºåˆ—å…³ç³»ã€‚è®ºæ–‡é€šè¿‡å¹¶è¡Œä½¿ç”¨æ·±åº¦çŠ¶æ€ç©ºé—´æ¨¡å‹å’ŒTransformerç¼–ç å™¨ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°æ•è·è½¨è¿¹ä¸­çš„é•¿æœŸä¾èµ–å…³ç³»å’Œå±€éƒ¨ç»†èŠ‚ï¼Œä»è€Œæé«˜å¯¹é½é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¤šçº§è½¨è¿¹èåˆæ¨¡å—ä¸­ï¼Œæ·±åº¦çŠ¶æ€ç©ºé—´æ¨¡å‹ç”¨äºæ•æ‰è½¨è¿¹çš„åŠ¨æ€å˜åŒ–ï¼ŒTransformerç¼–ç å™¨ç”¨äºæ•æ‰è½¨è¿¹çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾æå–å™¨çš„å…·ä½“æ¶æ„ä¹Ÿæœªæ˜ç¡®è¯´æ˜ï¼Œå¯èƒ½æ˜¯ä½¿ç”¨äº†é¢„è®­ç»ƒæ¨¡å‹æˆ–è‡ªå®šä¹‰ç½‘ç»œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ–¹æ³•åœ¨é¢„æ“ä½œå¯¹é½é¢„æµ‹ä»»åŠ¡ä¸­ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒ…æ‹¬ä¸€äº›åŸºç¡€æ¨¡å‹ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨æ‘˜è¦ä¸­æœªç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚ä½†è®ºæ–‡å¼ºè°ƒï¼Œé€šè¿‡å¤šçº§è½¨è¿¹èåˆæ¨¡å—ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°é¢„æµ‹æ“ä½œæˆåŠŸç‡ï¼Œä»è€ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§æœºå™¨äººæ“ä½œåœºæ™¯ï¼Œä¾‹å¦‚å·¥ä¸šè‡ªåŠ¨åŒ–ã€å®¶åº­æœåŠ¡æœºå™¨äººã€åŒ»ç–—æœºå™¨äººç­‰ã€‚é€šè¿‡æå‰é¢„æµ‹æ“ä½œæˆåŠŸç‡ï¼Œå¯ä»¥æé«˜æœºå™¨äººæ“ä½œçš„æ•ˆç‡å’Œå®‰å…¨æ€§ï¼Œé™ä½æ“ä½œå¤±è´¥çš„é£é™©ï¼Œå¹¶å®ç°æ›´æ™ºèƒ½åŒ–çš„æœºå™¨äººæ§åˆ¶ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›ä¸å¼ºåŒ–å­¦ä¹ ç­‰æ–¹æ³•ç»“åˆï¼Œå®ç°æ›´è‡ªä¸»ã€æ›´é²æ£’çš„æœºå™¨äººæ“ä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this work, we address the problem of predicting the future success of open-vocabulary object manipulation tasks. Conventional approaches typically determine success or failure after the action has been carried out. However, they make it difficult to prevent potential hazards and rely on failures to trigger replanning, thereby reducing the efficiency of object manipulation sequences. To overcome these challenges, we propose a model, which predicts the alignment between a pre-manipulation egocentric image with the planned trajectory and a given natural language instruction. We introduce a Multi-Level Trajectory Fusion module, which employs a state-of-the-art deep state-space model and a transformer encoder in parallel to capture multi-level time-series self-correlation within the end effector trajectory. Our experimental results indicate that the proposed method outperformed existing methods, including foundation models.

