---
layout: default
title: SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model
---

# SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14138" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14138v1</a>
  <a href="https://arxiv.org/pdf/2509.14138.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14138v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14138v1', 'SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ran Yang, Zijian An, Lifeng ZHou, Yiming Feng

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-17

**å¤‡æ³¨**: 8 pages, 9 figures, 1 table

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SeqVLAï¼šç”¨äºé•¿æ—¶ç¨‹æ“ä½œçš„å…·æœ‰å®Œæˆæ„ŸçŸ¥èƒ½åŠ›çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼Œè§£å†³åºåˆ—ä»»åŠ¡æ‰§è¡Œé—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹` `åºåˆ—ä»»åŠ¡æ‰§è¡Œ` `å®Œæˆæ„ŸçŸ¥` `é•¿æ—¶ç¨‹ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLAæ¨¡å‹åœ¨é•¿æ—¶ç¨‹åºåˆ—æ“ä½œä»»åŠ¡ä¸­ï¼Œç¼ºä¹å­ä»»åŠ¡å®ŒæˆçŠ¶æ€çš„å†…éƒ¨ä¿¡å·ï¼Œå¯¼è‡´ä»»åŠ¡å¤±è´¥ã€‚
2. SeqVLAé€šè¿‡å¢åŠ ä¸€ä¸ªè½»é‡çº§çš„æ£€æµ‹å¤´æ¥æ„ŸçŸ¥å­ä»»åŠ¡å®ŒæˆçŠ¶æ€ï¼Œä»è€Œå®ç°è‡ªä¸»å­ä»»åŠ¡åˆ‡æ¢ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSeqVLAåœ¨æ²™æ‹‰å’Œç³–æœåŒ…è£…ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œæå‡äº†æ•´ä½“æˆåŠŸç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é•¿æ—¶ç¨‹æœºå™¨äººæ“ä½œä»»åŠ¡éœ€è¦åœ¨ä¸¥æ ¼çš„åºåˆ—ä¸­æ‰§è¡Œå¤šä¸ªç›¸äº’ä¾èµ–çš„å­ä»»åŠ¡ï¼Œè€Œæ£€æµ‹å­ä»»åŠ¡å®Œæˆæƒ…å†µæ—¶å‡ºç°çš„é”™è¯¯å¯èƒ½ä¼šå¯¼è‡´ä¸‹æ¸¸ä»»åŠ¡å¤±è´¥ã€‚ç°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ï¼Œå¦‚$Ï€_0$ï¼Œæ“…é•¿è¿ç»­çš„ä½çº§æ§åˆ¶ï¼Œä½†ç¼ºä¹è¯†åˆ«å­ä»»åŠ¡ä½•æ—¶å®Œæˆçš„å†…éƒ¨ä¿¡å·ï¼Œè¿™ä½¿å¾—å®ƒä»¬åœ¨åºåˆ—è®¾ç½®ä¸­æ˜¾å¾—è„†å¼±ã€‚æˆ‘ä»¬æå‡ºäº†SeqVLAï¼Œå®ƒæ˜¯$Ï€_0$çš„ä¸€ä¸ªå®Œæˆæ„ŸçŸ¥æ‰©å±•ï¼Œé€šè¿‡å¢åŠ ä¸€ä¸ªè½»é‡çº§çš„æ£€æµ‹å¤´æ¥æ„ŸçŸ¥å½“å‰å­ä»»åŠ¡æ˜¯å¦å®Œæˆï¼Œä»è€Œå¢å¼ºäº†åŸºç¡€æ¶æ„ã€‚è¿™ç§åŒå¤´è®¾è®¡ä½¿SeqVLAä¸ä»…èƒ½å¤Ÿç”Ÿæˆæ“ä½œåŠ¨ä½œï¼Œè¿˜èƒ½å¤Ÿè‡ªä¸»åœ°è§¦å‘å­ä»»åŠ¡ä¹‹é—´çš„è½¬æ¢ã€‚æˆ‘ä»¬ç ”ç©¶äº†å››ç§å¾®è°ƒç­–ç•¥ï¼Œè¿™äº›ç­–ç•¥åœ¨å¦‚ä½•ä¼˜åŒ–åŠ¨ä½œå¤´å’Œæ£€æµ‹å¤´ï¼ˆè”åˆå¾®è°ƒä¸é¡ºåºå¾®è°ƒï¼‰ä»¥åŠå¦‚ä½•ä¿ç•™é¢„è®­ç»ƒçŸ¥è¯†ï¼ˆå®Œå…¨å¾®è°ƒä¸å†»ç»“éª¨å¹²ç½‘ç»œï¼‰æ–¹é¢æœ‰æ‰€ä¸åŒã€‚åœ¨ä¸¤ä¸ªå¤šé˜¶æ®µä»»åŠ¡ï¼ˆåŒ…å«ä¸ƒä¸ªä¸åŒå­ä»»åŠ¡çš„æ²™æ‹‰åŒ…è£…å’ŒåŒ…å«å››ä¸ªä¸åŒå­ä»»åŠ¡çš„ç³–æœåŒ…è£…ï¼‰ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒSeqVLAåœ¨æ€»ä½“æˆåŠŸç‡æ–¹é¢æ˜¾è‘—ä¼˜äºåŸºçº¿$Ï€_0$å’Œå…¶ä»–å¼ºå¤§çš„åŸºçº¿ã€‚ç‰¹åˆ«æ˜¯ï¼Œå…·æœ‰æœªå†»ç»“éª¨å¹²ç½‘ç»œçš„è”åˆå¾®è°ƒäº§ç”Ÿäº†æœ€æœæ–­å’Œç»Ÿè®¡ä¸Šå¯é çš„å®Œæˆé¢„æµ‹ï¼Œæ¶ˆé™¤äº†ä¸åºåˆ—ç›¸å…³çš„å¤±è´¥ï¼Œå¹¶å®ç°äº†ç¨³å¥çš„é•¿æ—¶ç¨‹æ‰§è¡Œã€‚æˆ‘ä»¬çš„ç»“æœå¼ºè°ƒäº†å°†åŠ¨ä½œç”Ÿæˆä¸å­ä»»åŠ¡æ„ŸçŸ¥æ£€æµ‹ç›¸ç»“åˆå¯¹äºå¯æ‰©å±•çš„åºåˆ—æ“ä½œçš„é‡è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ï¼Œä¾‹å¦‚$Ï€_0$ï¼Œåœ¨è¿ç»­çš„ä½çº§æ§åˆ¶æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†ç¼ºä¹åˆ¤æ–­å­ä»»åŠ¡ä½•æ—¶å®Œæˆçš„å†…éƒ¨ä¿¡å·ã€‚è¿™å¯¼è‡´å®ƒä»¬åœ¨éœ€è¦æŒ‰é¡ºåºæ‰§è¡Œå¤šä¸ªå­ä»»åŠ¡çš„é•¿æ—¶ç¨‹æ“ä½œä»»åŠ¡ä¸­è¡¨ç°è„†å¼±ï¼Œå­ä»»åŠ¡å®ŒæˆçŠ¶æ€åˆ¤æ–­é”™è¯¯ä¼šä¼ é€’åˆ°åç»­ä»»åŠ¡ï¼Œé€ æˆçº§è”å¤±è´¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSeqVLAçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨ç°æœ‰çš„VLAæ¨¡å‹åŸºç¡€ä¸Šï¼Œå¢åŠ ä¸€ä¸ªä¸“é—¨ç”¨äºæ£€æµ‹å½“å‰å­ä»»åŠ¡æ˜¯å¦å®Œæˆçš„æ£€æµ‹å¤´ã€‚é€šè¿‡è¿™ä¸ªæ£€æµ‹å¤´ï¼Œæ¨¡å‹å¯ä»¥è‡ªä¸»åˆ¤æ–­ä½•æ—¶ä»ä¸€ä¸ªå­ä»»åŠ¡åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå­ä»»åŠ¡ï¼Œä»è€Œæé«˜åœ¨åºåˆ—ä»»åŠ¡ä¸­çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSeqVLAçš„æ•´ä½“æ¶æ„æ˜¯åœ¨åŸæœ‰VLAæ¨¡å‹ï¼ˆå¦‚$Ï€_0$ï¼‰çš„åŸºç¡€ä¸Šå¢åŠ ä¸€ä¸ªè½»é‡çº§çš„æ£€æµ‹å¤´ã€‚è¯¥æ£€æµ‹å¤´æ¥æ”¶ä¸åŠ¨ä½œç”Ÿæˆå¤´ç›¸åŒçš„è¾“å…¥ï¼ˆè§†è§‰å’Œè¯­è¨€ä¿¡æ¯ï¼‰ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªè¡¨ç¤ºå½“å‰å­ä»»åŠ¡æ˜¯å¦å®Œæˆçš„ä¿¡å·ã€‚æ•´ä¸ªæ¨¡å‹åŒ…å«ä¸¤ä¸ªå¤´ï¼šåŠ¨ä½œç”Ÿæˆå¤´å’Œå®Œæˆæ£€æµ‹å¤´ã€‚æ¨¡å‹é€šè¿‡è”åˆæˆ–é¡ºåºå¾®è°ƒçš„æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šSeqVLAçš„å…³é”®åˆ›æ–°åœ¨äºå°†åŠ¨ä½œç”Ÿæˆå’Œå­ä»»åŠ¡å®ŒæˆçŠ¶æ€æ£€æµ‹ç›¸ç»“åˆã€‚ä»¥å¾€çš„VLAæ¨¡å‹åªå…³æ³¨åŠ¨ä½œç”Ÿæˆï¼Œè€Œå¿½ç•¥äº†å¯¹ä»»åŠ¡çŠ¶æ€çš„æ„ŸçŸ¥ã€‚é€šè¿‡å¢åŠ å®Œæˆæ£€æµ‹å¤´ï¼ŒSeqVLAèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ä»»åŠ¡çš„è¿›å±•ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°æ‰§è¡Œåºåˆ—ä»»åŠ¡ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ç ”ç©¶äº†å››ç§å¾®è°ƒç­–ç•¥ï¼š(1) è”åˆå¾®è°ƒä¸”éª¨å¹²ç½‘ç»œä¸å†»ç»“ï¼›(2) è”åˆå¾®è°ƒä¸”éª¨å¹²ç½‘ç»œå†»ç»“ï¼›(3) é¡ºåºå¾®è°ƒä¸”éª¨å¹²ç½‘ç»œä¸å†»ç»“ï¼›(4) é¡ºåºå¾®è°ƒä¸”éª¨å¹²ç½‘ç»œå†»ç»“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè”åˆå¾®è°ƒä¸”éª¨å¹²ç½‘ç»œä¸å†»ç»“çš„ç­–ç•¥æ•ˆæœæœ€ä½³ã€‚æ£€æµ‹å¤´çš„è®¾è®¡é‡‡ç”¨è½»é‡çº§ç»“æ„ï¼Œä»¥å‡å°‘è®¡ç®—è´Ÿæ‹…ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦å¹³è¡¡åŠ¨ä½œç”Ÿæˆå’Œå®Œæˆæ£€æµ‹ä¸¤ä¸ªä»»åŠ¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SeqVLAåœ¨æ²™æ‹‰åŒ…è£…å’Œç³–æœåŒ…è£…ä¸¤ä¸ªå¤šé˜¶æ®µä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ï¼ŒSeqVLAåœ¨æ€»ä½“æˆåŠŸç‡æ–¹é¢æ˜¾è‘—ä¼˜äºåŸºçº¿$Ï€_0$å’Œå…¶ä»–å¼ºå¤§çš„åŸºçº¿ã€‚ç‰¹åˆ«æ˜¯ï¼Œé‡‡ç”¨è”åˆå¾®è°ƒä¸”éª¨å¹²ç½‘ç»œä¸å†»ç»“çš„ç­–ç•¥æ—¶ï¼ŒSeqVLAèƒ½å¤Ÿäº§ç”Ÿæœ€å¯é çš„å®Œæˆé¢„æµ‹ï¼Œä»è€Œæ¶ˆé™¤äº†ä¸åºåˆ—ç›¸å…³çš„å¤±è´¥ï¼Œå¹¶å®ç°äº†ç¨³å¥çš„é•¿æ—¶ç¨‹æ‰§è¡Œã€‚å…·ä½“æ€§èƒ½æ•°æ®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SeqVLAå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨æ™ºèƒ½åˆ¶é€ ã€è‡ªåŠ¨åŒ–è£…é…ã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥åº”ç”¨äºéœ€è¦æ‰§è¡Œå¤šä¸ªæ­¥éª¤æ‰èƒ½å®Œæˆçš„å¤æ‚ä»»åŠ¡ï¼Œä¾‹å¦‚äº§å“ç»„è£…ã€é£Ÿå“åˆ¶ä½œã€å®¶å±…æ¸…æ´ç­‰ã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨åºåˆ—ä»»åŠ¡ä¸­çš„é²æ£’æ€§å’Œæ•ˆç‡ï¼ŒSeqVLAå¯ä»¥é™ä½äººå·¥æˆæœ¬ï¼Œæé«˜ç”Ÿäº§æ•ˆç‡ï¼Œå¹¶æ”¹å–„ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Long-horizon robotic manipulation tasks require executing multiple interdependent subtasks in strict sequence, where errors in detecting subtask completion can cascade into downstream failures. Existing Vision-Language-Action (VLA) models such as $Ï€_0$ excel at continuous low-level control but lack an internal signal for identifying when a subtask has finished, making them brittle in sequential settings. We propose SeqVLA, a completion-aware extension of $Ï€_0$ that augments the base architecture with a lightweight detection head perceiving whether the current subtask is complete. This dual-head design enables SeqVLA not only to generate manipulation actions but also to autonomously trigger transitions between subtasks. We investigate four finetuning strategies that vary in how the action and detection heads are optimized (joint vs. sequential finetuning) and how pretrained knowledge is preserved (full finetuning vs. frozen backbone). Experiments are performed on two multi-stage tasks: salad packing with seven distinct subtasks and candy packing with four distinct subtasks. Results show that SeqVLA significantly outperforms the baseline $Ï€_0$ and other strong baselines in overall success rate. In particular, joint finetuning with an unfrozen backbone yields the most decisive and statistically reliable completion predictions, eliminating sequence-related failures and enabling robust long-horizon execution. Our results highlight the importance of coupling action generation with subtask-aware detection for scalable sequential manipulation.

