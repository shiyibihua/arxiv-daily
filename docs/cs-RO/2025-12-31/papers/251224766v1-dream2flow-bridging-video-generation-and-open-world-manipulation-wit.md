---
layout: default
title: "Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow"
---

# Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.24766" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.24766v1</a>
  <a href="https://arxiv.org/pdf/2512.24766.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.24766v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.24766v1', 'Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Karthik Dharmarajan, Wenlong Huang, Jiajun Wu, Li Fei-Fei, Ruohan Zhang

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-31

**å¤‡æ³¨**: Project website: https://dream2flow.github.io/

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://dream2flow.github.io/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Dream2Flowï¼šåˆ©ç”¨3Dç‰©ä½“æµæ¡¥æ¥è§†é¢‘ç”Ÿæˆä¸å¼€æ”¾ä¸–ç•Œæ“ä½œ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `æœºå™¨äººæ“ä½œ` `3Dç‰©ä½“æµ` `é›¶æ ·æœ¬å­¦ä¹ ` `è½¨è¿¹ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥å°†ç”Ÿæˆè§†é¢‘ä¸­çš„ç‰©ä½“è¿åŠ¨è½¬åŒ–ä¸ºæœºå™¨äººå¯æ‰§è¡Œçš„åº•å±‚åŠ¨ä½œï¼Œå­˜åœ¨â€œå…·èº«å·®è·â€ã€‚
2. Dream2Flowé€šè¿‡3Dç‰©ä½“æµä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œå°†è§†é¢‘ç”Ÿæˆä¸æœºå™¨äººæ§åˆ¶è¿æ¥ï¼Œå®ç°é›¶æ ·æœ¬æ“ä½œæŒ‡å¯¼ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDream2Flowèƒ½å¤Ÿæ“ä½œå„ç§ç±»å‹çš„ç‰©ä½“ï¼Œå¹¶é€šè¿‡è½¨è¿¹ä¼˜åŒ–æˆ–å¼ºåŒ–å­¦ä¹ ç”Ÿæˆå¯æ‰§è¡Œçš„æœºå™¨äººæŒ‡ä»¤ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”Ÿæˆå¼è§†é¢‘å»ºæ¨¡å·²æˆä¸ºä¸€ç§å¼•äººæ³¨ç›®çš„å·¥å…·ï¼Œå¯ä»¥å¯¹å¼€æ”¾ä¸–ç•Œæ“ä½œä¸­åˆç†çš„ç‰©ç†äº¤äº’è¿›è¡Œé›¶æ ·æœ¬æ¨ç†ã€‚ç„¶è€Œï¼Œå°†è¿™ç§äººä¸ºå¼•å¯¼çš„è¿åŠ¨è½¬åŒ–ä¸ºæœºå™¨äººç³»ç»Ÿæ‰€éœ€çš„åº•å±‚åŠ¨ä½œä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œç»™å®šåˆå§‹å›¾åƒå’Œä»»åŠ¡æŒ‡ä»¤ï¼Œè¿™äº›æ¨¡å‹æ“…é•¿åˆæˆåˆç†çš„ç‰©ä½“è¿åŠ¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†Dream2Flowï¼Œä¸€ä¸ªé€šè¿‡3Dç‰©ä½“æµä½œä¸ºä¸­é—´è¡¨ç¤ºæ¥æ¡¥æ¥è§†é¢‘ç”Ÿæˆå’Œæœºå™¨äººæ§åˆ¶çš„æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä»ç”Ÿæˆçš„è§†é¢‘ä¸­é‡å»º3Dç‰©ä½“è¿åŠ¨ï¼Œå¹¶å°†æ“ä½œå®šä¹‰ä¸ºç‰©ä½“è½¨è¿¹è·Ÿè¸ªã€‚é€šè¿‡å°†çŠ¶æ€å˜åŒ–ä¸å®ç°è¿™äº›å˜åŒ–çš„æ‰§è¡Œå™¨åˆ†ç¦»ï¼ŒDream2Flowå…‹æœäº†å…·èº«å·®è·ï¼Œå¹¶å®ç°äº†ä»é¢„è®­ç»ƒè§†é¢‘æ¨¡å‹åˆ°æ“ä½œå„ç§ç±»åˆ«ç‰©ä½“çš„é›¶æ ·æœ¬æŒ‡å¯¼ï¼ŒåŒ…æ‹¬åˆšæ€§ã€é“°æ¥ã€å¯å˜å½¢å’Œé¢—ç²’çŠ¶ç‰©ä½“ã€‚é€šè¿‡è½¨è¿¹ä¼˜åŒ–æˆ–å¼ºåŒ–å­¦ä¹ ï¼ŒDream2Flowå°†é‡å»ºçš„3Dç‰©ä½“æµè½¬æ¢ä¸ºå¯æ‰§è¡Œçš„åº•å±‚å‘½ä»¤ï¼Œè€Œæ— éœ€ç‰¹å®šäºä»»åŠ¡çš„æ¼”ç¤ºã€‚ä»¿çœŸå’ŒçœŸå®ä¸–ç•Œçš„å®éªŒçªå‡ºäº†3Dç‰©ä½“æµä½œä¸ºä¸€ç§é€šç”¨ä¸”å¯æ‰©å±•çš„æ¥å£ï¼Œç”¨äºå°†è§†é¢‘ç”Ÿæˆæ¨¡å‹é€‚é…åˆ°å¼€æ”¾ä¸–ç•Œæœºå™¨äººæ“ä½œã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ç”Ÿæˆå¼è§†é¢‘æ¨¡å‹æ“…é•¿ç”Ÿæˆç‰©ä½“è¿åŠ¨ï¼Œä½†éš¾ä»¥ç›´æ¥æ§åˆ¶æœºå™¨äººæ‰§è¡Œè¿™äº›è¿åŠ¨ï¼Œå› ä¸ºè§†é¢‘æ¨¡å‹è¾“å‡ºçš„æ˜¯é«˜å±‚è¯­ä¹‰ä¿¡æ¯ï¼Œè€Œæœºå™¨äººéœ€è¦åº•å±‚æ§åˆ¶æŒ‡ä»¤ã€‚è¿™ç§ä»é«˜å±‚è¯­ä¹‰åˆ°ä½å±‚æ§åˆ¶çš„è½¬æ¢å­˜åœ¨â€œå…·èº«å·®è·â€ï¼Œé˜»ç¢äº†è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨æœºå™¨äººæ“ä½œä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDream2Flowçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è§†é¢‘ç”Ÿæˆæ¨¡å‹ç”Ÿæˆçš„ç‰©ä½“è¿åŠ¨ä¿¡æ¯æå–å‡ºæ¥ï¼Œç”¨3Dç‰©ä½“æµæ¥è¡¨ç¤ºï¼Œç„¶åå°†æœºå™¨äººæ“ä½œä»»åŠ¡è½¬åŒ–ä¸ºå¯¹3Dç‰©ä½“è½¨è¿¹çš„è·Ÿè¸ªé—®é¢˜ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå°†é«˜å±‚è¯­ä¹‰çš„ç‰©ä½“è¿åŠ¨ä¸åº•å±‚æ§åˆ¶æŒ‡ä»¤è§£è€¦ï¼Œä»è€Œå…‹æœâ€œå…·èº«å·®è·â€ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDream2Flowæ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) ç»™å®šåˆå§‹å›¾åƒå’Œä»»åŠ¡æŒ‡ä»¤ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ç”Ÿæˆè§†é¢‘ï¼›2) ä»ç”Ÿæˆçš„è§†é¢‘ä¸­é‡å»º3Dç‰©ä½“è¿åŠ¨ï¼Œå¾—åˆ°3Dç‰©ä½“æµï¼›3) å°†æœºå™¨äººæ“ä½œä»»åŠ¡å®šä¹‰ä¸ºå¯¹3Dç‰©ä½“è½¨è¿¹çš„è·Ÿè¸ªé—®é¢˜ï¼›4) ä½¿ç”¨è½¨è¿¹ä¼˜åŒ–æˆ–å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå°†3Dç‰©ä½“æµè½¬æ¢ä¸ºå¯æ‰§è¡Œçš„åº•å±‚æœºå™¨äººæ§åˆ¶æŒ‡ä»¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šDream2Flowçš„å…³é”®åˆ›æ–°åœ¨äºä½¿ç”¨3Dç‰©ä½“æµä½œä¸ºè§†é¢‘ç”Ÿæˆå’Œæœºå™¨äººæ§åˆ¶ä¹‹é—´çš„ä¸­é—´è¡¨ç¤ºã€‚è¿™ç§è¡¨ç¤ºæ–¹å¼èƒ½å¤Ÿæœ‰æ•ˆåœ°æå–è§†é¢‘ä¸­çš„ç‰©ä½“è¿åŠ¨ä¿¡æ¯ï¼Œå¹¶å°†é«˜å±‚è¯­ä¹‰çš„ç‰©ä½“è¿åŠ¨ä¸åº•å±‚æ§åˆ¶æŒ‡ä»¤è§£è€¦ï¼Œä»è€Œå…‹æœâ€œå…·èº«å·®è·â€ï¼Œå®ç°é›¶æ ·æœ¬æœºå™¨äººæ“ä½œã€‚

**å…³é”®è®¾è®¡**ï¼šDream2Flowçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ç°æœ‰çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œæ— éœ€é‡æ–°è®­ç»ƒï¼›2) ä½¿ç”¨ç°æœ‰çš„3Dé‡å»ºç®—æ³•ä»è§†é¢‘ä¸­é‡å»º3Dç‰©ä½“è¿åŠ¨ï¼›3) ä½¿ç”¨è½¨è¿¹ä¼˜åŒ–æˆ–å¼ºåŒ–å­¦ä¹ æ–¹æ³•å°†3Dç‰©ä½“æµè½¬æ¢ä¸ºå¯æ‰§è¡Œçš„æœºå™¨äººæ§åˆ¶æŒ‡ä»¤ã€‚å…·ä½“ä½¿ç”¨çš„è½¨è¿¹ä¼˜åŒ–ç®—æ³•å’Œå¼ºåŒ–å­¦ä¹ ç®—æ³•å¯ä»¥æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œé€‰æ‹©ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Dream2Flowåœ¨ä»¿çœŸå’ŒçœŸå®ä¸–ç•Œç¯å¢ƒä¸­è¿›è¡Œäº†å®éªŒéªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDream2Flowèƒ½å¤ŸæˆåŠŸåœ°æ“ä½œå„ç§ç±»å‹çš„ç‰©ä½“ï¼ŒåŒ…æ‹¬åˆšæ€§ã€é“°æ¥ã€å¯å˜å½¢å’Œé¢—ç²’çŠ¶ç‰©ä½“ã€‚ä¸ç°æœ‰çš„æ–¹æ³•ç›¸æ¯”ï¼ŒDream2Flowæ— éœ€ç‰¹å®šäºä»»åŠ¡çš„æ¼”ç¤ºï¼Œå³å¯å®ç°é›¶æ ·æœ¬æœºå™¨äººæ“ä½œï¼Œå…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Dream2Flowå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚å®¶åº­æœåŠ¡æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—æœºå™¨äººç­‰ã€‚å®ƒå¯ä»¥ä½¿æœºå™¨äººèƒ½å¤Ÿç†è§£äººç±»çš„æŒ‡ä»¤ï¼Œå¹¶æ ¹æ®æŒ‡ä»¤æ“ä½œå„ç§ç‰©ä½“ï¼Œä»è€Œæé«˜æœºå™¨äººçš„æ™ºèƒ½åŒ–æ°´å¹³å’Œåº”ç”¨èŒƒå›´ã€‚æœªæ¥ï¼ŒDream2Flowå¯ä»¥ä¸å…¶ä»–æŠ€æœ¯ç»“åˆï¼Œä¾‹å¦‚è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰ï¼Œå®ç°æ›´å¤æ‚çš„æœºå™¨äººæ“ä½œä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generative video modeling has emerged as a compelling tool to zero-shot reason about plausible physical interactions for open-world manipulation. Yet, it remains a challenge to translate such human-led motions into the low-level actions demanded by robotic systems. We observe that given an initial image and task instruction, these models excel at synthesizing sensible object motions. Thus, we introduce Dream2Flow, a framework that bridges video generation and robotic control through 3D object flow as an intermediate representation. Our method reconstructs 3D object motions from generated videos and formulates manipulation as object trajectory tracking. By separating the state changes from the actuators that realize those changes, Dream2Flow overcomes the embodiment gap and enables zero-shot guidance from pre-trained video models to manipulate objects of diverse categories-including rigid, articulated, deformable, and granular. Through trajectory optimization or reinforcement learning, Dream2Flow converts reconstructed 3D object flow into executable low-level commands without task-specific demonstrations. Simulation and real-world experiments highlight 3D object flow as a general and scalable interface for adapting video generation models to open-world robotic manipulation. Videos and visualizations are available at https://dream2flow.github.io/.

