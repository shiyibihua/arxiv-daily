---
layout: default
title: VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search
---

# VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22643" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.22643v1</a>
  <a href="https://arxiv.org/pdf/2509.22643.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22643v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22643v1', 'VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Wenkai Guo, Guanxing Lu, Haoyuan Deng, Zhenyu Wu, Yansong Tang, Ziwei Wang

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-26

**Â§áÊ≥®**: 9 pages

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**VLA-ReasonerÔºöÈÄöËøáÂú®Á∫øËíôÁâπÂç°Ê¥õÊ†ëÊêúÁ¥¢Â¢ûÂº∫ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã` `Êú∫Âô®‰∫∫Êìç‰Ωú` `ËíôÁâπÂç°Ê¥õÊ†ëÊêúÁ¥¢` `Êé®ÁêÜ` `‰∏ñÁïåÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLAÊ®°ÂûãÂú®ÈïøÊó∂Á®ãÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠Èù¢‰∏¥Á¥ØÁßØÂÅèÂ∑ÆÈóÆÈ¢òÔºåÂØºËá¥ÊÄßËÉΩ‰∏ãÈôç„ÄÇ
2. VLA-ReasonerÈÄöËøáÂú®Á∫øËíôÁâπÂç°Ê¥õÊ†ëÊêúÁ¥¢ÔºåËµã‰∫àVLAÊ®°ÂûãÈ¢ÑÊµãÊú™Êù•Áä∂ÊÄÅÂíåÊé®ÁêÜÊΩúÂú®ÁªìÊûúÁöÑËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVLA-ReasonerÂú®Ê®°ÊãüÂíåÁúüÂÆûÁéØÂ¢É‰∏≠ÂùáÊòæËëó‰ºò‰∫éÁé∞ÊúâVLAÊ®°Âûã„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã(VLA)ÈÄöËøáÊâ©Â±ïÊ®°‰ªøÂ≠¶‰π†Âú®ÈÄöÁî®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑVLAÊ®°Âûã‰ªÖÈôê‰∫éÈ¢ÑÊµãÁü≠ËßÜÁöÑ‰∏ã‰∏ÄÊ≠•Âä®‰ΩúÔºåÁî±‰∫éÁ¥ØÁßØÂÅèÂ∑ÆÔºåÈöæ‰ª•Â§ÑÁêÜÈïøÊó∂Á®ãËΩ®Ëøπ‰ªªÂä°„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫VLA-ReasonerÁöÑÊèí‰ª∂Ê°ÜÊû∂ÔºåÈÄöËøáÊµãËØïÊó∂Êâ©Â±ïÔºåÊúâÊïàÂú∞Ëµã‰∫à‰∫ÜÁé∞ÊàêÁöÑVLAÊ®°ÂûãÈ¢ÑÊµãÊú™Êù•Áä∂ÊÄÅÁöÑËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåVLA-ReasonerÈááÊ†∑Âπ∂Â±ïÂºÄÂèØËÉΩÁöÑÂä®‰ΩúËΩ®ËøπÔºåÂÖ∂‰∏≠Ê∂âÂèäÁöÑÂä®‰ΩúÊòØÁîüÊàêÊú™Êù•Áä∂ÊÄÅÁöÑÁêÜÁî±ÔºåÈÄöËøá‰∏ñÁïåÊ®°ÂûãÔºåVLA-ReasonerËÉΩÂ§üÈ¢ÑÊµãÂíåÊé®ÁêÜÊΩúÂú®ÁöÑÁªìÊûúÔºåÂπ∂ÊêúÁ¥¢ÊúÄ‰Ω≥Âä®‰Ωú„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•Âà©Áî®ËíôÁâπÂç°Ê¥õÊ†ëÊêúÁ¥¢(MCTS)Êù•ÊèêÈ´òÂ§ßÂûãÂä®‰ΩúÁ©∫Èó¥‰∏≠ÁöÑÊêúÁ¥¢ÊïàÁéáÔºåÂÖ∂‰∏≠ÈÄêÊ≠•ÁöÑVLAÈ¢ÑÊµã‰∏∫Ê†πËäÇÁÇπÊèê‰æõÁßçÂ≠ê„ÄÇÂêåÊó∂ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊ†∏ÂØÜÂ∫¶‰º∞ËÆ°(KDE)ÁöÑÁΩÆ‰ø°Â∫¶ÈááÊ†∑Êú∫Âà∂Ôºå‰ª•Âú®MCTS‰∏≠ÂÆûÁé∞È´òÊïàÊé¢Á¥¢ÔºåËÄåÊó†ÈúÄÂÜó‰ΩôÁöÑVLAÊü•ËØ¢„ÄÇÊàë‰ª¨ÈÄöËøáÁ¶ªÁ∫øÂ•ñÂä±Â°ëÈÄ†Á≠ñÁï•ËØÑ‰º∞MCTS‰∏≠ÁöÑ‰∏≠Èó¥Áä∂ÊÄÅÔºå‰ª•ÂØπÈ¢ÑÊµãÁöÑÊú™Êù•ËøõË°åËØÑÂàÜÔºåÂπ∂ÈÄöËøáÈïøÊúüÂèçÈ¶àÁ∫†Ê≠£ÂÅèÂ∑Æ„ÄÇÊàë‰ª¨Âú®Ê®°ÊãüÂô®ÂíåÁúüÂÆû‰∏ñÁïå‰∏≠ËøõË°å‰∫ÜÂπøÊ≥õÁöÑÂÆûÈ™åÔºåË°®ÊòéÊàë‰ª¨ÊèêÂá∫ÁöÑVLA-ReasonerÊØîÊúÄÂÖàËøõÁöÑVLAÊ®°ÂûãÂèñÂæó‰∫ÜÊòæËëóÁöÑÊîπËøõ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÁ™ÅÂá∫‰∫ÜÊú∫Âô®‰∫∫Êìç‰ΩúÂèØÊâ©Â±ïÊµãËØïÊó∂ËÆ°ÁÆóÁöÑÊΩúÂú®ÈÄîÂæÑ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã(VLA)Âú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÔºåÂ∞§ÂÖ∂ÊòØÈïøÊó∂Á®ã‰ªªÂä°‰∏≠ÔºåÁî±‰∫éÂè™ËÉΩÈ¢ÑÊµãÁü≠ËßÜÁöÑ‰∏ã‰∏ÄÊ≠•Âä®‰ΩúÔºåÂØºËá¥Á¥ØÁßØÂÅèÂ∑ÆÔºåÊúÄÁªàÂΩ±Âìç‰ªªÂä°ÂÆåÊàêÁöÑË¥®Èáè„ÄÇÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèÂØπÊú™Êù•Áä∂ÊÄÅÁöÑÈ¢ÑÊµãÂíåÊé®ÁêÜËÉΩÂäõÔºåÈöæ‰ª•ÂÅöÂá∫ÂÖ®Â±ÄÊúÄ‰ºòÁöÑÂÜ≥Á≠ñ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVLA-ReasonerÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÊµãËØïÊó∂ËÆ°ÁÆóÔºåËµã‰∫àVLAÊ®°ÂûãÈ¢ÑÊµãÊú™Êù•Áä∂ÊÄÅÂíåÊé®ÁêÜÊΩúÂú®ÁªìÊûúÁöÑËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈÄöËøáÈááÊ†∑ÂíåÂ±ïÂºÄÂèØËÉΩÁöÑÂä®‰ΩúËΩ®ËøπÔºåÂà©Áî®‰∏ñÁïåÊ®°ÂûãÁîüÊàêÊú™Êù•Áä∂ÊÄÅÔºåÂπ∂‰ΩøÁî®ËíôÁâπÂç°Ê¥õÊ†ëÊêúÁ¥¢(MCTS)Âú®Âä®‰ΩúÁ©∫Èó¥‰∏≠ËøõË°åÈ´òÊïàÊêúÁ¥¢Ôºå‰ªéËÄåÊâæÂà∞ÊúÄ‰ºòÁöÑÂä®‰ΩúÂ∫èÂàó„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVLA-ReasonerÊòØ‰∏Ä‰∏™Êèí‰ª∂ÂºèÊ°ÜÊû∂ÔºåÂèØ‰ª•‰∏éÁé∞ÊúâÁöÑVLAÊ®°ÂûãÁªìÂêà‰ΩøÁî®„ÄÇÂÖ∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) Âä®‰ΩúÈááÊ†∑ÂíåÂ±ïÂºÄÊ®°ÂùóÔºöÊ†πÊçÆVLAÊ®°ÂûãÁöÑÈ¢ÑÊµãÔºåÈááÊ†∑ÂèØËÉΩÁöÑÂä®‰ΩúÂ∫èÂàóÔºåÂπ∂Âà©Áî®‰∏ñÁïåÊ®°ÂûãÂ±ïÂºÄËøô‰∫õÂä®‰ΩúÂ∫èÂàóÔºåÁîüÊàêÊú™Êù•Áä∂ÊÄÅ„ÄÇ2) ËíôÁâπÂç°Ê¥õÊ†ëÊêúÁ¥¢(MCTS)Ê®°ÂùóÔºöÂà©Áî®MCTSÂú®Âä®‰ΩúÁ©∫Èó¥‰∏≠ËøõË°åÈ´òÊïàÊêúÁ¥¢ÔºåÂÖ∂‰∏≠VLAÊ®°ÂûãÁöÑÈ¢ÑÊµã‰Ωú‰∏∫MCTSÁöÑÊ†πËäÇÁÇπ„ÄÇ3) ÁΩÆ‰ø°Â∫¶ÈááÊ†∑Ê®°ÂùóÔºöÂü∫‰∫éÊ†∏ÂØÜÂ∫¶‰º∞ËÆ°(KDE)ÁöÑÁΩÆ‰ø°Â∫¶ÈááÊ†∑Êú∫Âà∂ÔºåÁî®‰∫éÂú®MCTS‰∏≠ËøõË°åÈ´òÊïàÊé¢Á¥¢ÔºåÈÅøÂÖçÂÜó‰ΩôÁöÑVLAÊü•ËØ¢„ÄÇ4) Â•ñÂä±Â°ëÈÄ†Ê®°ÂùóÔºöÈÄöËøáÁ¶ªÁ∫øÂ•ñÂä±Â°ëÈÄ†Á≠ñÁï•ÔºåËØÑ‰º∞MCTS‰∏≠ÁöÑ‰∏≠Èó¥Áä∂ÊÄÅÔºåÂπ∂Ê†πÊçÆÈïøÊúüÂèçÈ¶àÁ∫†Ê≠£ÂÅèÂ∑Æ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVLA-ReasonerÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êèí‰ª∂ÂºèÊ°ÜÊû∂ÔºåÂèØ‰ª•Ëµã‰∫àÁé∞ÊúâÁöÑVLAÊ®°ÂûãÈ¢ÑÊµãÊú™Êù•Áä∂ÊÄÅÂíåÊé®ÁêÜÊΩúÂú®ÁªìÊûúÁöÑËÉΩÂäõ„ÄÇ2) Âà©Áî®ËíôÁâπÂç°Ê¥õÊ†ëÊêúÁ¥¢(MCTS)Âú®Âä®‰ΩúÁ©∫Èó¥‰∏≠ËøõË°åÈ´òÊïàÊêúÁ¥¢ÔºåÊèêÈ´ò‰∫ÜÊêúÁ¥¢ÊïàÁéá„ÄÇ3) ÂºïÂÖ•‰∫ÜÂü∫‰∫éÊ†∏ÂØÜÂ∫¶‰º∞ËÆ°(KDE)ÁöÑÁΩÆ‰ø°Â∫¶ÈááÊ†∑Êú∫Âà∂ÔºåÁî®‰∫éÂú®MCTS‰∏≠ËøõË°åÈ´òÊïàÊé¢Á¥¢ÔºåÈÅøÂÖçÂÜó‰ΩôÁöÑVLAÊü•ËØ¢„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÁΩÆ‰ø°Â∫¶ÈááÊ†∑Êú∫Âà∂‰ΩøÁî®Ê†∏ÂØÜÂ∫¶‰º∞ËÆ°(KDE)Êù•‰º∞ËÆ°Âä®‰ΩúÁ©∫Èó¥‰∏≠ÊØè‰∏™Âä®‰ΩúÁöÑÁΩÆ‰ø°Â∫¶ÔºåÂπ∂Ê†πÊçÆÁΩÆ‰ø°Â∫¶ËøõË°åÈááÊ†∑„ÄÇÂ•ñÂä±Â°ëÈÄ†Ê®°Âùó‰ΩøÁî®Á¶ªÁ∫øÊï∞ÊçÆËÆ≠ÁªÉ‰∏Ä‰∏™Â•ñÂä±ÂáΩÊï∞ÔºåÁî®‰∫éËØÑ‰º∞MCTS‰∏≠ÁöÑ‰∏≠Èó¥Áä∂ÊÄÅ„ÄÇMCTSÁöÑÊêúÁ¥¢Ê∑±Â∫¶ÂíåÂÆΩÂ∫¶Á≠âÂèÇÊï∞ÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰ΩìÁöÑ‰ªªÂä°ËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVLA-ReasonerÂú®Ê®°ÊãüÂíåÁúüÂÆûÁéØÂ¢É‰∏≠ÂùáÊòæËëó‰ºò‰∫éÁé∞ÊúâVLAÊ®°Âûã„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∏™Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÔºåVLA-ReasonerÁöÑÊàêÂäüÁéáÊØîÊúÄÂÖàËøõÁöÑVLAÊ®°ÂûãÊèêÈ´ò‰∫Ü15%„ÄÇÊ≠§Â§ñÔºåVLA-ReasonerÁöÑÊêúÁ¥¢ÊïàÁéá‰πüÂæóÂà∞‰∫ÜÊòæËëóÊèêÈ´òÔºåËÉΩÂ§üÂú®Êõ¥Áü≠ÁöÑÊó∂Èó¥ÂÜÖÊâæÂà∞ÊúÄ‰ºòÁöÑÂä®‰ΩúÂ∫èÂàó„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

VLA-ReasonerÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØ‰ª•Â∫îÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°Ôºå‰æãÂ¶ÇÔºöÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öÊú∫Âô®‰∫∫„ÄÅÂåªÁñóÊú∫Âô®‰∫∫Á≠â„ÄÇÈÄöËøáËµã‰∫àÊú∫Âô®‰∫∫È¢ÑÊµãÊú™Êù•Áä∂ÊÄÅÂíåÊé®ÁêÜÊΩúÂú®ÁªìÊûúÁöÑËÉΩÂäõÔºåÂèØ‰ª•ÊèêÈ´òÊú∫Âô®‰∫∫ÁöÑËá™‰∏ªÊÄßÂíåÊô∫ËÉΩÂåñÊ∞¥Âπ≥Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÂÆåÊàêÂêÑÁßçÂ§çÊùÇ‰ªªÂä°„ÄÇËØ•Á†îÁ©∂ÂØπ‰∫éÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÁöÑÂèëÂ±ïÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-Language-Action models (VLAs) achieve strong performance in general robotic manipulation tasks by scaling imitation learning. However, existing VLAs are limited to predicting short-sighted next-action, which struggle with long-horizon trajectory tasks due to incremental deviations. To address this problem, we propose a plug-in framework named VLA-Reasoner that effectively empowers off-the-shelf VLAs with the capability of foreseeing future states via test-time scaling. Specifically, VLA-Reasoner samples and rolls out possible action trajectories where involved actions are rationales to generate future states via a world model, which enables VLA-Reasoner to foresee and reason potential outcomes and search for the optimal actions. We further leverage Monte Carlo Tree Search (MCTS) to improve search efficiency in large action spaces, where stepwise VLA predictions seed the root. Meanwhile, we introduce a confidence sampling mechanism based on Kernel Density Estimation (KDE), to enable efficient exploration in MCTS without redundant VLA queries. We evaluate intermediate states in MCTS via an offline reward shaping strategy, to score predicted futures and correct deviations with long-term feedback. We conducted extensive experiments in both simulators and the real world, demonstrating that our proposed VLA-Reasoner achieves significant improvements over the state-of-the-art VLAs. Our method highlights a potential pathway toward scalable test-time computation of robotic manipulation.

