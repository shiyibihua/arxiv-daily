---
layout: default
title: Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting
---

# Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22195" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22195v1</a>
  <a href="https://arxiv.org/pdf/2509.22195.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22195v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22195v1', 'Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Asher J. Hancock, Xindi Wu, Lihan Zha, Olga Russakovsky, Anirudha Majumdar

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVLM2VLAä»¥è§£å†³æœºå™¨äººé¥æ§ä¸­çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `æœºå™¨äººé¥æ§` `ç¾éš¾æ€§é—å¿˜` `ä½ç§©é€‚åº”` `å¤šæ¨¡æ€å­¦ä¹ ` `é›¶-shotæ³›åŒ–` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æœºå™¨äººé¥æ§æ•°æ®ä¸Šå¾®è°ƒæ—¶ï¼Œå®¹æ˜“å¯¼è‡´åŸºç¡€æ¨ç†å’Œå¤šæ¨¡æ€ç†è§£èƒ½åŠ›çš„ä¸‹é™ã€‚
2. æå‡ºVLM2VLAï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€è¡¨ç¤ºä½çº§åŠ¨ä½œï¼Œè§£å†³VLMä¸æœºå™¨äººæ•°æ®ä¹‹é—´çš„åˆ†å¸ƒä¸åŒ¹é…é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒVLM2VLAåœ¨ä¿æŒVLMæ ¸å¿ƒèƒ½åŠ›çš„åŒæ—¶ï¼Œå®ç°äº†å¯¹æ–°ä»»åŠ¡çš„é›¶-shotæ³›åŒ–ï¼Œå…·æœ‰è‰¯å¥½çš„å®é™…åº”ç”¨æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶é’ˆå¯¹åœ¨æœºå™¨äººé¥æ§æ•°æ®ä¸Šå¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä»¥åˆ›å»ºè§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹æ—¶ï¼Œé¢ä¸´çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜è¿›è¡Œäº†æ¢è®¨ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œè¿™ç§é—å¿˜æºäºVLMçš„äº’è”ç½‘è§„æ¨¡é¢„è®­ç»ƒè¯­æ–™ä¸æœºå™¨äººå¾®è°ƒæ•°æ®ä¹‹é—´çš„åˆ†å¸ƒä¸åŒ¹é…ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†VLM2VLAè®­ç»ƒèŒƒå¼ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€è¡¨ç¤ºä½çº§åŠ¨ä½œï¼Œä»æ•°æ®å±‚é¢è§£å†³åˆ†å¸ƒä¸åŒ¹é…ã€‚è¯¥æ–¹æ³•ä»…ä½¿ç”¨ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰å¯¹VLMè¿›è¡Œå¾®è°ƒï¼Œé¿å…äº†å¯¹åŸºç¡€æ¶æ„çš„é‡å¤§ä¿®æ”¹ã€‚é€šè¿‡å¤§é‡çš„è§†è§‰é—®ç­”ï¼ˆVQAï¼‰ç ”ç©¶å’Œ800å¤šä¸ªçœŸå®ä¸–ç•Œçš„æœºå™¨äººå®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†VLM2VLAèƒ½å¤Ÿä¿æŒVLMçš„æ ¸å¿ƒèƒ½åŠ›ï¼Œå®ç°å¯¹æ–°ä»»åŠ¡çš„é›¶-shotæ³›åŒ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³åœ¨æœºå™¨äººé¥æ§æ•°æ®ä¸Šå¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æ—¶å‡ºç°çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å­¦ä¹ ç”ŸæˆåŠ¨ä½œæ—¶ï¼Œå¾€å¾€ä¼šå‰Šå¼±VLMçš„åŸºç¡€æ¨ç†å’Œå¤šæ¨¡æ€ç†è§£èƒ½åŠ›ï¼Œå½±å“å…¶åœ¨æ–°åœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„VLM2VLAè®­ç»ƒèŒƒå¼ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€å¯¹ä½çº§åŠ¨ä½œè¿›è¡Œè¡¨ç¤ºï¼Œä»è€Œåœ¨æ•°æ®å±‚é¢è§£å†³VLMä¸æœºå™¨äººå¾®è°ƒæ•°æ®ä¹‹é—´çš„åˆ†å¸ƒä¸åŒ¹é…ã€‚è¿™ç§å¯¹é½æ–¹å¼ä½¿å¾—å¯ä»¥ä»…é€šè¿‡ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰å¯¹VLMè¿›è¡Œå¾®è°ƒï¼Œé¿å…äº†å¯¹åŸºç¡€æ¶æ„çš„é‡å¤§ä¿®æ”¹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVLM2VLAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€è‡ªç„¶è¯­è¨€è¡¨ç¤ºç”Ÿæˆã€ä½ç§©é€‚åº”å¾®è°ƒå’Œè¯„ä¼°æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€å¯¹ä½çº§åŠ¨ä½œè¿›è¡Œè¡¨ç¤ºï¼Œç„¶åä½¿ç”¨LoRAå¯¹VLMè¿›è¡Œå¾®è°ƒï¼Œæœ€ååœ¨çœŸå®ä¸–ç•Œçš„æœºå™¨äººä»»åŠ¡ä¸­è¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šVLM2VLAçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºé€šè¿‡è‡ªç„¶è¯­è¨€è¡¨ç¤ºä½çº§åŠ¨ä½œï¼Œä»è€Œè§£å†³äº†VLMä¸æœºå™¨äººæ•°æ®ä¹‹é—´çš„åˆ†å¸ƒä¸åŒ¹é…é—®é¢˜ã€‚è¿™ä¸€æ–¹æ³•ä¸ç°æœ‰çš„ç›´æ¥å¾®è°ƒæ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œé¿å…äº†ç¾éš¾æ€§é—å¿˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒVLM2VLAä½¿ç”¨äº†ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰ä½œä¸ºå¾®è°ƒç­–ç•¥ï¼Œç¡®ä¿å¯¹VLMçš„åŸºç¡€æ¶æ„è¿›è¡Œæœ€å°ä¿®æ”¹ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†å¤šæ¨¡æ€æ•°æ®çš„ç‰¹æ€§ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVLM2VLAåœ¨è§†è§‰é—®ç­”ï¼ˆVQAï¼‰ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿåœ¨ä¸è¿›è¡Œæ˜‚è´µçš„å…±åŒè®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œä¿æŒVLMçš„æ ¸å¿ƒèƒ½åŠ›ã€‚é€šè¿‡800å¤šä¸ªçœŸå®ä¸–ç•Œçš„æœºå™¨äººå®éªŒï¼ŒVLM2VLAå®ç°äº†å¯¹æ–°ä»»åŠ¡çš„é›¶-shotæ³›åŒ–ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„å®é™…åº”ç”¨èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººé¥æ§ã€æ™ºèƒ½å®¶å±…ã€è‡ªåŠ¨åŒ–ç”Ÿäº§ç­‰ã€‚é€šè¿‡ä¿æŒVLMçš„æ ¸å¿ƒèƒ½åŠ›ï¼ŒVLM2VLAå¯ä»¥åœ¨å¤šç§æ–°ä»»åŠ¡ä¸­å®ç°é›¶-shotæ³›åŒ–ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“åŠ›ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Fine-tuning vision-language models (VLMs) on robot teleoperation data to create vision-language-action (VLA) models is a promising paradigm for training generalist policies, but it suffers from a fundamental tradeoff: learning to produce actions often diminishes the VLM's foundational reasoning and multimodal understanding, hindering generalization to novel scenarios, instruction following, and semantic understanding. We argue that this catastrophic forgetting is due to a distribution mismatch between the VLM's internet-scale pretraining corpus and the robotics fine-tuning data. Inspired by this observation, we introduce VLM2VLA: a VLA training paradigm that first resolves this mismatch at the data level by representing low-level actions with natural language. This alignment makes it possible to train VLAs solely with Low-Rank Adaptation (LoRA), thereby minimally modifying the VLM backbone and averting catastrophic forgetting. As a result, the VLM can be fine-tuned on robot teleoperation data without fundamentally altering the underlying architecture and without expensive co-training on internet-scale VLM datasets. Through extensive Visual Question Answering (VQA) studies and over 800 real-world robotics experiments, we demonstrate that VLM2VLA preserves the VLM's core capabilities, enabling zero-shot generalization to novel tasks that require open-world semantic reasoning and multilingual instruction following.

