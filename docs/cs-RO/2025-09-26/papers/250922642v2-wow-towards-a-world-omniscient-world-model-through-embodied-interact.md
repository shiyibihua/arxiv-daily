---
layout: default
title: WoW: Towards a World omniscient World model Through Embodied Interaction
---

# WoW: Towards a World omniscient World model Through Embodied Interaction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22642" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22642v2</a>
  <a href="https://arxiv.org/pdf/2509.22642.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22642v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22642v2', 'WoW: Towards a World omniscient World model Through Embodied Interaction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaowei Chi, Peidong Jia, Chun-Kai Fan, Xiaozhu Ju, Weishi Mi, Kevin Zhang, Zhiyuan Qin, Wanxin Tian, Kuangzhi Ge, Hao Li, Zezhong Qian, Anthony Chen, Qiang Zhou, Yueru Jia, Jiaming Liu, Yong Dai, Qingpo Wuwu, Chengyu Bai, Yu-Kai Wang, Ying Li, Lizhang Chen, Yong Bao, Zhiyuan Jiang, Jiacheng Zhu, Kai Tang, Ruichuan An, Yulin Luo, Qiuxuan Feng, Siyuan Zhou, Chi-min Chan, Chengkai Hou, Wei Xue, Sirui Han, Yike Guo, Shanghang Zhang, Jian Tang

**åˆ†ç±»**: cs.RO, cs.CV, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26 (æ›´æ–°: 2025-10-16)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**WoWï¼šé€šè¿‡å…·èº«äº¤äº’æ„å»ºå…·å¤‡ç‰©ç†ç›´è§‰çš„ä¸–ç•Œæ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ä¸–ç•Œæ¨¡å‹` `å…·èº«æ™ºèƒ½` `ç‰©ç†ç›´è§‰` `æœºå™¨äººäº¤äº’` `ç”Ÿæˆå¼æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘æ¨¡å‹ä¾èµ–è¢«åŠ¨è§‚å¯Ÿï¼Œéš¾ä»¥ç†è§£ç‰©ç†å› æœå…³ç³»ï¼Œé˜»ç¢äº†å¯¹ä¸–ç•Œçš„æ·±å…¥ç†è§£ã€‚
2. WoWé€šè¿‡å¤§è§„æ¨¡æœºå™¨äººäº¤äº’å­¦ä¹ ï¼Œæ„å»ºç”Ÿæˆå¼ä¸–ç•Œæ¨¡å‹ï¼Œæå‡å¯¹ç‰©ç†ä¸–ç•Œçš„ç†è§£èƒ½åŠ›ã€‚
3. WoWåœ¨ç‰©ç†ä¸€è‡´æ€§å’Œå› æœæ¨ç†åŸºå‡†ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…·èº«äº¤äº’å¯¹å‘å±•ç‰©ç†ç›´è§‰çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†WoWï¼Œä¸€ä¸ªåŸºäº2ç™¾ä¸‡æœºå™¨äººäº¤äº’è½¨è¿¹è®­ç»ƒçš„140äº¿å‚æ•°ç”Ÿæˆå¼ä¸–ç•Œæ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å½“å‰è§†é¢‘æ¨¡å‹ï¼ˆå¦‚Soraï¼‰åœ¨ç†è§£ç‰©ç†å› æœå…³ç³»æ–¹é¢çš„ä¸è¶³ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒWoWå¯¹ç‰©ç†çš„ç†è§£æ˜¯åŸºäºå¯¹åˆç†ç»“æœçš„æ¦‚ç‡åˆ†å¸ƒï¼Œè¿™å¯èƒ½å¯¼è‡´éšæœºä¸ç¨³å®šæ€§å’Œç‰©ç†å¹»è§‰ã€‚ä¸ºäº†çº¦æŸæ¨¡å‹å‘ç‰©ç†çœŸå®æ€§é æ‹¢ï¼Œå¼•å…¥äº†SOPHIAï¼Œåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹è¯„ä¼°DiTç”Ÿæˆçš„è¾“å‡ºï¼Œå¹¶é€šè¿‡è¿­ä»£æ¼”åŒ–è¯­è¨€æŒ‡ä»¤æ¥æŒ‡å¯¼æ”¹è¿›ã€‚æ­¤å¤–ï¼Œå…±åŒè®­ç»ƒçš„é€†åŠ¨åŠ›å­¦æ¨¡å‹å°†è¿™äº›æ”¹è¿›çš„è®¡åˆ’è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„æœºå™¨äººåŠ¨ä½œï¼Œä»è€Œé—­åˆäº†ä»æƒ³è±¡åˆ°è¡ŒåŠ¨çš„å¾ªç¯ã€‚WoWåœ¨WoWBenchï¼ˆä¸€ä¸ªå…³æ³¨è§†é¢‘ä¸­ç‰©ç†ä¸€è‡´æ€§å’Œå› æœæ¨ç†çš„æ–°åŸºå‡†ï¼‰ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨ç‰©ç†å› æœå…³ç³»ã€ç¢°æ’åŠ¨åŠ›å­¦å’Œç‰©ä½“æ°¸å­˜æ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ã€‚è¯¥ç ”ç©¶ç³»ç»Ÿåœ°è¯æ˜äº†å¤§è§„æ¨¡çœŸå®ä¸–ç•Œäº¤äº’æ˜¯å‘å±•äººå·¥æ™ºèƒ½ç‰©ç†ç›´è§‰çš„åŸºçŸ³ã€‚æ¨¡å‹ã€æ•°æ®å’ŒåŸºå‡†å°†å¼€æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå½“å‰è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œä¾‹å¦‚Soraï¼Œä¸»è¦ä¾èµ–äºè¢«åŠ¨è§‚å¯Ÿå­¦ä¹ ï¼Œç¼ºä¹ä¸çœŸå®ä¸–ç•Œçš„äº¤äº’ï¼Œå› æ­¤åœ¨ç†è§£ç‰©ç†ä¸–ç•Œçš„å› æœå…³ç³»æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå®¹æ˜“äº§ç”Ÿä¸ç¬¦åˆç‰©ç†è§„å¾‹çš„å¹»è§‰ã€‚è®ºæ–‡æ—¨åœ¨é€šè¿‡è®©AIæ¨¡å‹ä¸çœŸå®ä¸–ç•Œè¿›è¡Œå¤§è§„æ¨¡äº¤äº’ï¼Œä»è€Œå­¦ä¹ åˆ°æ›´çœŸå®çš„ç‰©ç†ç›´è§‰ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¤§è§„æ¨¡çš„æœºå™¨äººäº¤äº’æ•°æ®è®­ç»ƒä¸€ä¸ªç”Ÿæˆå¼ä¸–ç•Œæ¨¡å‹ï¼ˆWoWï¼‰ï¼Œä½¿å…¶èƒ½å¤Ÿåƒäººç±»ä¸€æ ·é€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’æ¥å­¦ä¹ ç‰©ç†è§„å¾‹ã€‚æ­¤å¤–ï¼Œå¼•å…¥SOPHIAæ¡†æ¶ï¼Œåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹å¯¹ç”Ÿæˆç»“æœè¿›è¡Œè¯„ä¼°å’ŒæŒ‡å¯¼ï¼Œä»è€Œçº¦æŸæ¨¡å‹å‘ç‰©ç†çœŸå®æ€§é æ‹¢ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) **WoW (World Model)**ï¼šä¸€ä¸ªåŸºäºæ‰©æ•£Transformer (DiT) çš„ç”Ÿæˆå¼ä¸–ç•Œæ¨¡å‹ï¼Œé€šè¿‡2ç™¾ä¸‡æœºå™¨äººäº¤äº’è½¨è¿¹è¿›è¡Œè®­ç»ƒã€‚2) **SOPHIA (Self-Refinement with Physical Intuition Augmentation)**ï¼šåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹è¯„ä¼°WoWç”Ÿæˆçš„è§†é¢‘ï¼Œå¹¶ç”Ÿæˆè¯­è¨€æŒ‡ä»¤æ¥æŒ‡å¯¼WoWè¿›è¡Œæ”¹è¿›ã€‚3) **Inverse Dynamics Model (IDM)**ï¼šä¸€ä¸ªé€†åŠ¨åŠ›å­¦æ¨¡å‹ï¼Œå°†SOPHIAç”Ÿæˆçš„æ”¹è¿›è®¡åˆ’è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„æœºå™¨äººåŠ¨ä½œï¼Œä»è€Œå®ç°ä»æƒ³è±¡åˆ°è¡ŒåŠ¨çš„é—­ç¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) å¼ºè°ƒäº†å¤§è§„æ¨¡çœŸå®ä¸–ç•Œäº¤äº’å¯¹äºå‘å±•AIç‰©ç†ç›´è§‰çš„é‡è¦æ€§ï¼Œå¹¶æ„å»ºäº†ç›¸åº”çš„è®­ç»ƒæ¡†æ¶ã€‚2) æå‡ºäº†SOPHIAæ¡†æ¶ï¼Œåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹å¯¹ç”Ÿæˆç»“æœè¿›è¡Œç‰©ç†ä¸€è‡´æ€§è¯„ä¼°å’ŒæŒ‡å¯¼ï¼Œä»è€Œæœ‰æ•ˆæå‡äº†ç”Ÿæˆè§†é¢‘çš„ç‰©ç†çœŸå®æ€§ã€‚3) æ„å»ºäº†WoWBenchï¼Œä¸€ä¸ªæ–°çš„ç”¨äºè¯„ä¼°è§†é¢‘ä¸­ç‰©ç†ä¸€è‡´æ€§å’Œå› æœæ¨ç†èƒ½åŠ›çš„åŸºå‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šWoWæ¨¡å‹åŸºäºæ‰©æ•£Transformer (DiT) æ¶æ„ï¼Œä½¿ç”¨å¤§è§„æ¨¡æœºå™¨äººäº¤äº’æ•°æ®è¿›è¡Œè®­ç»ƒã€‚SOPHIAæ¡†æ¶ä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆå…·ä½“æ¨¡å‹æœªçŸ¥ï¼‰æ¥è¯„ä¼°ç”Ÿæˆè§†é¢‘çš„ç‰©ç†åˆç†æ€§ï¼Œå¹¶ç”Ÿæˆè‡ªç„¶è¯­è¨€æŒ‡ä»¤æ¥æŒ‡å¯¼æ¨¡å‹è¿›è¡Œæ”¹è¿›ã€‚é€†åŠ¨åŠ›å­¦æ¨¡å‹ï¼ˆIDMï¼‰çš„å…·ä½“ç»“æ„å’Œè®­ç»ƒæ–¹æ³•æœªçŸ¥ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹ŸæœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

WoWåœ¨WoWBenchåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨ç‰©ç†å› æœå…³ç³»ã€ç¢°æ’åŠ¨åŠ›å­¦å’Œç‰©ä½“æ°¸å­˜æ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ã€‚é€šè¿‡äººç±»å’Œè‡ªä¸»è¯„ä¼°ï¼ŒWoWåœ¨ç‰©ç†ä¸€è‡´æ€§å’Œå› æœæ¨ç†æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨æ‘˜è¦ä¸­æœªæ˜ç¡®ç»™å‡ºï¼Œéœ€è¦å‚è€ƒè®ºæ–‡æ­£æ–‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰é¢†åŸŸã€‚é€šè¿‡è®©AIæ¨¡å‹å…·å¤‡æ›´å¼ºçš„ç‰©ç†ç›´è§‰ï¼Œå¯ä»¥æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œå†³ç­–èƒ½åŠ›ï¼Œä¾‹å¦‚ï¼Œåœ¨æœªçŸ¥ç¯å¢ƒä¸­è¿›è¡Œå¯¼èˆªå’Œæ“ä½œï¼Œæˆ–åœ¨è™šæ‹Ÿç¯å¢ƒä¸­åˆ›å»ºæ›´é€¼çœŸçš„ç‰©ç†äº¤äº’æ•ˆæœã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æœ‰æœ›æ¨åŠ¨é€šç”¨äººå·¥æ™ºèƒ½çš„å‘å±•ï¼Œä½¿AIèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œé€‚åº”çœŸå®ä¸–ç•Œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Humans develop an understanding of intuitive physics through active interaction with the world. This approach is in stark contrast to current video models, such as Sora, which rely on passive observation and therefore struggle with grasping physical causality. This observation leads to our central hypothesis: authentic physical intuition of the world model must be grounded in extensive, causally rich interactions with the real world. To test this hypothesis, we present WoW, a 14-billion-parameter generative world model trained on 2 million robot interaction trajectories. Our findings reveal that the model's understanding of physics is a probabilistic distribution of plausible outcomes, leading to stochastic instabilities and physical hallucinations. Furthermore, we demonstrate that this emergent capability can be actively constrained toward physical realism by SOPHIA, where vision-language model agents evaluate the DiT-generated output and guide its refinement by iteratively evolving the language instructions. In addition, a co-trained Inverse Dynamics Model translates these refined plans into executable robotic actions, thus closing the imagination-to-action loop. We establish WoWBench, a new benchmark focused on physical consistency and causal reasoning in video, where WoW achieves state-of-the-art performance in both human and autonomous evaluation, demonstrating strong ability in physical causality, collision dynamics, and object permanence. Our work provides systematic evidence that large-scale, real-world interaction is a cornerstone for developing physical intuition in AI. Models, data, and benchmarks will be open-sourced.

