---
layout: default
title: ARMimic: Learning Robotic Manipulation from Passive Human Demonstrations in Augmented Reality
---

# ARMimic: Learning Robotic Manipulation from Passive Human Demonstrations in Augmented Reality

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22914" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22914v1</a>
  <a href="https://arxiv.org/pdf/2509.22914.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22914v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22914v1', 'ARMimic: Learning Robotic Manipulation from Passive Human Demonstrations in Augmented Reality')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rohan Walia, Yusheng Wang, Ralf RÃ¶mer, Masahiro Nishio, Angela P. Schoellig, Jun Ota

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ARMimicï¼šåˆ©ç”¨å¢å¼ºç°å®ä¸­çš„è¢«åŠ¨äººç±»æ¼”ç¤ºå­¦ä¹ æœºå™¨äººæ“ä½œ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `æ¨¡ä»¿å­¦ä¹ ` `å¢å¼ºç°å®` `äººæœºäº¤äº’` `æœºå™¨äººç¤ºæ•™`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººæ¨¡ä»¿å­¦ä¹ æ–¹æ³•ä¾èµ–ç¹ççš„åŠ¨è§‰ç¤ºæ•™æˆ–é¥æ“ä½œï¼Œå­˜åœ¨ç¡¬ä»¶ä¾èµ–æ€§å¼ºã€æ“ä½œå¤æ‚ç­‰é—®é¢˜ã€‚
2. ARMimicåˆ©ç”¨æ¶ˆè´¹çº§XRå¤´æ˜¾å’Œæ‘„åƒå¤´ï¼Œç»“åˆæ‰‹éƒ¨è·Ÿè¸ªã€ARæœºå™¨äººå åŠ å’Œæ·±åº¦æ„ŸçŸ¥ï¼Œå®ç°è½»é‡çº§ã€å¯æ‰©å±•çš„æ•°æ®æ”¶é›†ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒARMimicåœ¨æ“ä½œä»»åŠ¡ä¸­ï¼Œç›¸æ¯”é¥æ“ä½œå‡å°‘50%æ¼”ç¤ºæ—¶é—´ï¼Œä»»åŠ¡æˆåŠŸç‡æ¯”åŸºçº¿ACTæé«˜11%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¨¡ä»¿å­¦ä¹ æ˜¯æœºå™¨äººæŠ€èƒ½è·å–çš„å¼ºå¤§èŒƒä¾‹ï¼Œä½†ä¼ ç»Ÿçš„ç¤ºæ•™æ–¹æ³•ï¼ˆå¦‚åŠ¨è§‰ç¤ºæ•™å’Œé¥æ“ä½œï¼‰ç¹çã€ç¡¬ä»¶ä¾èµ–æ€§å¼ºä¸”ä¼šä¸­æ–­å·¥ä½œæµç¨‹ã€‚æœ€è¿‘ï¼Œä½¿ç”¨æ‰©å±•ç°å®ï¼ˆXRï¼‰å¤´æ˜¾çš„è¢«åŠ¨è§‚å¯Ÿåœ¨ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„æ¼”ç¤ºæ”¶é›†æ–¹é¢æ˜¾ç¤ºå‡ºå‰æ™¯ï¼Œä½†å½“å‰çš„æ–¹æ³•éœ€è¦é¢å¤–çš„ç¡¬ä»¶ã€å¤æ‚çš„æ ¡å‡†æˆ–å—é™çš„è®°å½•æ¡ä»¶ï¼Œä»è€Œé™åˆ¶äº†å¯æ‰©å±•æ€§å’Œå¯ç”¨æ€§ã€‚æˆ‘ä»¬æå‡ºäº†ARMimicï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œå®ƒé€šè¿‡è½»é‡çº§å’Œç¡¬ä»¶æœ€å°åŒ–çš„è®¾ç½®ï¼Œä»…ä½¿ç”¨æ¶ˆè´¹çº§XRå¤´æ˜¾å’Œå›ºå®šå·¥ä½œåœºæ‰€æ‘„åƒå¤´ï¼Œå®ç°å¯æ‰©å±•çš„ã€æ— éœ€æœºå™¨äººçš„æ•°æ®æ”¶é›†ã€‚ARMimicé›†æˆäº†ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„æ‰‹éƒ¨è·Ÿè¸ªã€å¢å¼ºç°å®ï¼ˆARï¼‰æœºå™¨äººå åŠ å’Œå®æ—¶æ·±åº¦æ„ŸçŸ¥ï¼Œä»¥ç¡®ä¿å…·æœ‰ç¢°æ’æ„è¯†çš„ã€è¿åŠ¨å­¦ä¸Šå¯è¡Œçš„æ¼”ç¤ºã€‚ç»Ÿä¸€çš„æ¨¡ä»¿å­¦ä¹ ç®¡é“æ˜¯æˆ‘ä»¬æ–¹æ³•çš„æ ¸å¿ƒï¼Œå°†äººç±»å’Œè™šæ‹Ÿæœºå™¨äººè½¨è¿¹è§†ä¸ºå¯äº’æ¢çš„ï¼Œä»è€Œå®ç°å¯ä»¥æ¨å¹¿åˆ°ä¸åŒå½¢æ€å’Œç¯å¢ƒçš„ç­–ç•¥ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªæ“ä½œä»»åŠ¡ï¼ˆåŒ…æ‹¬å…·æœ‰æŒ‘æˆ˜æ€§çš„é•¿æ—¶ç¨‹ç¢—å †å ï¼‰ä¸ŠéªŒè¯äº†ARMimicã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œä¸é¥æ“ä½œç›¸æ¯”ï¼ŒARMimicå°†æ¼”ç¤ºæ—¶é—´å‡å°‘äº†50ï¼…ï¼Œå¹¶ä¸”æ¯”åœ¨é¥æ“ä½œæ•°æ®ä¸Šè®­ç»ƒçš„æœ€æ–°åŸºçº¿ACTçš„ä»»åŠ¡æˆåŠŸç‡æé«˜äº†11ï¼…ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒARMimicèƒ½å¤Ÿå®ç°å®‰å…¨ã€æ— ç¼å’Œé‡å¤–æ•°æ®æ”¶é›†ï¼Œä¸ºåœ¨å„ç§ç°å®ä¸–ç•Œç¯å¢ƒä¸­è¿›è¡Œå¯æ‰©å±•çš„æœºå™¨äººå­¦ä¹ æä¾›äº†å·¨å¤§çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æœºå™¨äººæ¨¡ä»¿å­¦ä¹ æ–¹æ³•ï¼Œå¦‚åŠ¨è§‰ç¤ºæ•™å’Œé¥æ“ä½œï¼Œå­˜åœ¨ç¡¬ä»¶æˆæœ¬é«˜ã€æ“ä½œå¤æ‚ã€æ˜“ä¸­æ–­å·¥ä½œæµç¨‹ç­‰é—®é¢˜ã€‚å°¤å…¶æ˜¯åœ¨å¤æ‚æ“ä½œä»»åŠ¡ä¸­ï¼Œæ•°æ®æ”¶é›†æ•ˆç‡å’Œå®‰å…¨æ€§éš¾ä»¥ä¿è¯ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ›´è½»é‡çº§ã€æ›´å®‰å…¨ã€æ›´é«˜æ•ˆçš„æœºå™¨äººç¤ºæ•™æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šARMimicçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¢å¼ºç°å®ï¼ˆARï¼‰æŠ€æœ¯ï¼Œè®©äººç±»åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿›è¡Œæœºå™¨äººæ“ä½œçš„æ¼”ç¤ºï¼Œå¹¶å°†äººç±»çš„åŠ¨ä½œè½¨è¿¹å’Œè™šæ‹Ÿæœºå™¨äººçš„è½¨è¿¹è§†ä¸ºå¯äº’æ¢çš„æ•°æ®ï¼Œä»è€Œè®­ç»ƒæœºå™¨äººç­–ç•¥ã€‚é€šè¿‡ARå åŠ ï¼Œäººç±»å¯ä»¥ç›´æ¥åœ¨çœŸå®ç¯å¢ƒä¸­â€œçœ‹åˆ°â€è™šæ‹Ÿæœºå™¨äººï¼Œå¹¶è¿›è¡Œäº¤äº’ï¼Œé¿å…äº†ç›´æ¥æ“ä½œçœŸå®æœºå™¨äººçš„é£é™©å’Œå¤æ‚æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šARMimicç³»ç»Ÿä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) ä½¿ç”¨æ¶ˆè´¹çº§XRå¤´æ˜¾è¿›è¡Œä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„æ‰‹éƒ¨è·Ÿè¸ªï¼›2) åœ¨ARç¯å¢ƒä¸­å åŠ è™šæ‹Ÿæœºå™¨äººæ¨¡å‹ï¼›3) ä½¿ç”¨å›ºå®šæ‘„åƒå¤´è¿›è¡Œå®æ—¶æ·±åº¦æ„ŸçŸ¥ï¼Œä»¥å®ç°ç¢°æ’æ£€æµ‹å’Œç¯å¢ƒç†è§£ï¼›4) ç»Ÿä¸€çš„æ¨¡ä»¿å­¦ä¹ ç®¡é“ï¼Œç”¨äºè®­ç»ƒæœºå™¨äººç­–ç•¥ã€‚äººç±»åœ¨ARç¯å¢ƒä¸­è¿›è¡Œæ“ä½œæ¼”ç¤ºï¼Œç³»ç»Ÿè®°å½•äººç±»æ‰‹éƒ¨å’Œè™šæ‹Ÿæœºå™¨äººçš„è½¨è¿¹ï¼Œå¹¶å°†å…¶ä½œä¸ºè®­ç»ƒæ•°æ®è¾“å…¥æ¨¡ä»¿å­¦ä¹ æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šARMimicçš„å…³é”®åˆ›æ–°åœ¨äºå…¶è½»é‡çº§ã€ç¡¬ä»¶æœ€å°åŒ–çš„æ•°æ®æ”¶é›†æ–¹å¼ï¼Œä»¥åŠå°†äººç±»å’Œè™šæ‹Ÿæœºå™¨äººè½¨è¿¹è§†ä¸ºå¯äº’æ¢æ•°æ®çš„ç»Ÿä¸€æ¨¡ä»¿å­¦ä¹ æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„é¥æ“ä½œæˆ–åŠ¨è§‰ç¤ºæ•™ç›¸æ¯”ï¼ŒARMimicæ— éœ€å¤æ‚çš„ç¡¬ä»¶è®¾å¤‡å’Œæ ¡å‡†è¿‡ç¨‹ï¼Œé™ä½äº†æ•°æ®æ”¶é›†çš„æˆæœ¬å’Œéš¾åº¦ã€‚åŒæ—¶ï¼Œé€šè¿‡ARå åŠ ï¼Œäººç±»å¯ä»¥åœ¨å®‰å…¨çš„ç¯å¢ƒä¸­è¿›è¡Œæ“ä½œæ¼”ç¤ºï¼Œé¿å…äº†ç›´æ¥æ“ä½œçœŸå®æœºå™¨äººçš„é£é™©ã€‚

**å…³é”®è®¾è®¡**ï¼šARMimicçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨æ¶ˆè´¹çº§XRå¤´æ˜¾è¿›è¡Œæ‰‹éƒ¨è·Ÿè¸ªï¼Œé™ä½äº†ç¡¬ä»¶æˆæœ¬ï¼›2) ä½¿ç”¨å®æ—¶æ·±åº¦æ„ŸçŸ¥è¿›è¡Œç¢°æ’æ£€æµ‹ï¼Œä¿è¯äº†æ“ä½œçš„å®‰å…¨æ€§ï¼›3) è®¾è®¡äº†ç»Ÿä¸€çš„æ¨¡ä»¿å­¦ä¹ ç®¡é“ï¼Œå°†äººç±»å’Œè™šæ‹Ÿæœºå™¨äººçš„è½¨è¿¹è§†ä¸ºå¯äº’æ¢çš„æ•°æ®ï¼Œä»è€Œè®­ç»ƒå¯ä»¥æ³›åŒ–åˆ°ä¸åŒæœºå™¨äººå½¢æ€å’Œç¯å¢ƒçš„ç­–ç•¥ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒARMimicåœ¨ä¸¤ä¸ªæ“ä½œä»»åŠ¡ï¼ˆåŒ…æ‹¬å…·æœ‰æŒ‘æˆ˜æ€§çš„é•¿æ—¶ç¨‹ç¢—å †å ï¼‰ä¸Šè¡¨ç°å‡ºè‰²ã€‚ä¸é¥æ“ä½œç›¸æ¯”ï¼ŒARMimicå°†æ¼”ç¤ºæ—¶é—´å‡å°‘äº†50ï¼…ï¼Œå¹¶ä¸”æ¯”åœ¨é¥æ“ä½œæ•°æ®ä¸Šè®­ç»ƒçš„æœ€æ–°åŸºçº¿ACTçš„ä»»åŠ¡æˆåŠŸç‡æé«˜äº†11ï¼…ã€‚è¿™äº›ç»“æœéªŒè¯äº†ARMimicåœ¨æ•°æ®æ”¶é›†æ•ˆç‡å’Œä»»åŠ¡æ€§èƒ½æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ARMimicå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºå·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—æœºå™¨äººã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸã€‚é€šè¿‡è¯¥æ–¹æ³•ï¼Œå¯ä»¥å¿«é€Ÿã€å®‰å…¨åœ°æ”¶é›†æœºå™¨äººæ“ä½œæ•°æ®ï¼Œå¹¶è®­ç»ƒå‡ºé«˜æ€§èƒ½çš„æœºå™¨äººç­–ç•¥ï¼Œä»è€Œæé«˜æœºå™¨äººçš„æ™ºèƒ½åŒ–æ°´å¹³å’Œåº”ç”¨èŒƒå›´ã€‚æœªæ¥ï¼ŒARMimicæœ‰æœ›æˆä¸ºä¸€ç§é€šç”¨çš„æœºå™¨äººç¤ºæ•™å·¥å…·ï¼Œä¿ƒè¿›æœºå™¨äººæŠ€æœ¯çš„æ™®åŠå’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Imitation learning is a powerful paradigm for robot skill acquisition, yet conventional demonstration methods--such as kinesthetic teaching and teleoperation--are cumbersome, hardware-heavy, and disruptive to workflows. Recently, passive observation using extended reality (XR) headsets has shown promise for egocentric demonstration collection, yet current approaches require additional hardware, complex calibration, or constrained recording conditions that limit scalability and usability. We present ARMimic, a novel framework that overcomes these limitations with a lightweight and hardware-minimal setup for scalable, robot-free data collection using only a consumer XR headset and a stationary workplace camera. ARMimic integrates egocentric hand tracking, augmented reality (AR) robot overlays, and real-time depth sensing to ensure collision-aware, kinematically feasible demonstrations. A unified imitation learning pipeline is at the core of our method, treating both human and virtual robot trajectories as interchangeable, which enables policies that generalize across different embodiments and environments. We validate ARMimic on two manipulation tasks, including challenging long-horizon bowl stacking. In our experiments, ARMimic reduces demonstration time by 50% compared to teleoperation and improves task success by 11% over ACT, a state-of-the-art baseline trained on teleoperated data. Our results demonstrate that ARMimic enables safe, seamless, and in-the-wild data collection, offering great potential for scalable robot learning in diverse real-world settings.

