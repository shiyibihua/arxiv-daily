---
layout: default
title: In-Hand Object Pose Estimation via Visual-Tactile Fusion
---

# In-Hand Object Pose Estimation via Visual-Tactile Fusion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10787" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10787v1</a>
  <a href="https://arxiv.org/pdf/2506.10787.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10787v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10787v1', 'In-Hand Object Pose Estimation via Visual-Tactile Fusion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Felix NonnengieÃŸer, Alap Kshirsagar, Boris Belousov, Jan Peters

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12

**å¤‡æ³¨**: 8 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§†è§‰-è§¦è§‰èåˆæ–¹æ³•ä»¥è§£å†³æ‰‹ä¸­ç‰©ä½“å§¿æ€ä¼°è®¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `ç‰©ä½“å§¿æ€ä¼°è®¡` `è§†è§‰è§¦è§‰èåˆ` `æœºå™¨äººæ“ä½œ` `ä¼ æ„Ÿå™¨èåˆ` `åŠ æƒICPç®—æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰çš„è§†è§‰æ–¹æ³•åœ¨ç‰©ä½“å§¿æ€ä¼°è®¡ä¸­å—åˆ°è§†è§‰é®æŒ¡çš„ä¸¥é‡å½±å“ï¼Œå¯¼è‡´å‡†ç¡®æ€§ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºäº†ä¸€ç§è§†è§‰ä¸è§¦è§‰ä¿¡æ¯èåˆçš„æ–¹æ³•ï¼Œé€šè¿‡åŠ æƒå’Œä¼ æ„Ÿå™¨èåˆæ¨¡å—æ¥æé«˜å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®éªŒè¡¨æ˜ï¼Œç»“åˆè§¦è§‰ä¿¡æ¯åï¼Œå§¿æ€ä¼°è®¡çš„å¹³å‡è¯¯å·®æ˜¾è‘—é™ä½ï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜é®æŒ¡æƒ…å†µä¸‹è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‡†ç¡®çš„æ‰‹ä¸­ç‰©ä½“å§¿æ€ä¼°è®¡å¯¹æœºå™¨äººç‰©ä½“æ“ä½œè‡³å…³é‡è¦ï¼Œä½†è§†è§‰é®æŒ¡ä»ç„¶æ˜¯åŸºäºè§†è§‰çš„æ–¹æ³•é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆè§†è§‰å’Œè§¦è§‰ä¿¡æ¯çš„æœºå™¨äººæ‰‹ä¸­ç‰©ä½“å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œæ—¨åœ¨å‡†ç¡®ç¡®å®šè¢«æœºå™¨äººæ‰‹æŠ“å–ç‰©ä½“çš„ä½ç½®å’Œæ–¹å‘ã€‚æˆ‘ä»¬é€šè¿‡èåˆæ¥è‡ªè…•éƒ¨RGB-Dç›¸æœºçš„è§†è§‰ä¿¡æ¯ä¸å®‰è£…åœ¨æœºå™¨äººæŠ“æ‰‹æŒ‡å°–çš„è§†è§‰è§¦è§‰ä¼ æ„Ÿå™¨çš„è§¦è§‰ä¿¡æ¯ï¼Œè§£å†³äº†è§†è§‰é®æŒ¡çš„é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»“åˆè§¦è§‰ä¿¡æ¯æ˜¾è‘—æé«˜äº†å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œå°¤å…¶åœ¨é®æŒ¡ä¸¥é‡æ—¶ã€‚æˆ‘ä»¬çš„å¹³å‡å§¿æ€ä¼°è®¡è¯¯å·®ä¸º7.5æ¯«ç±³å’Œ16.7åº¦ï¼Œç›¸è¾ƒäºä»…ä½¿ç”¨è§†è§‰çš„æ–¹æ³•æé«˜äº†20%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæ‰‹ä¸­ç‰©ä½“å§¿æ€ä¼°è®¡ä¸­çš„è§†è§‰é®æŒ¡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹é®æŒ¡æ—¶ï¼Œä¾èµ–å•ä¸€è§†è§‰ä¿¡æ¯ï¼Œå¯¼è‡´å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§æ˜¾è‘—ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡èåˆè§†è§‰å’Œè§¦è§‰ä¿¡æ¯æ¥å¢å¼ºå§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚é€šè¿‡ç»“åˆæ¥è‡ªä¸åŒä¼ æ„Ÿå™¨çš„æ•°æ®ï¼Œå¯ä»¥åœ¨è§†è§‰ä¿¡æ¯ä¸è¶³çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨è§¦è§‰ä¿¡æ¯è¿›è¡Œè¡¥å……ï¼Œä»è€Œæé«˜æ•´ä½“ä¼°è®¡æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ–¹æ³•åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨è…•éƒ¨RGB-Dç›¸æœºè·å–è§†è§‰ä¿¡æ¯ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨å®‰è£…åœ¨æŠ“æ‰‹æŒ‡å°–çš„è§¦è§‰ä¼ æ„Ÿå™¨è·å–è§¦è§‰ä¿¡æ¯ï¼›ç„¶åï¼Œé€šè¿‡åŠ æƒå’Œä¼ æ„Ÿå™¨èåˆæ¨¡å—å°†ä¸¤ç§ä¿¡æ¯è¿›è¡Œæ•´åˆï¼Œæœ€åä½¿ç”¨å¢å¼ºçš„è¿­ä»£æœ€è¿‘ç‚¹ï¼ˆICPï¼‰ç®—æ³•è¿›è¡Œå§¿æ€ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†åŠ æƒçš„ä¼ æ„Ÿå™¨èåˆæ¨¡å—ï¼Œèƒ½å¤Ÿæ ¹æ®ä¸åŒä¼ æ„Ÿå™¨çš„è´¡çŒ®åŠ¨æ€è°ƒæ•´å…¶æƒé‡ï¼Œä»è€Œä¼˜åŒ–å§¿æ€ä¼°è®¡è¿‡ç¨‹ã€‚è¿™ä¸€æ–¹æ³•åœ¨å¤„ç†è§†è§‰é®æŒ¡æ—¶è¡¨ç°å‡ºæ˜æ˜¾ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†åŠ æƒçš„ç‚¹äº‘èåˆæ–¹æ³•ï¼Œå¹¶å¯¹ICPç®—æ³•è¿›è¡Œäº†å¢å¼ºï¼Œä»¥é€‚åº”åŠ æƒç‚¹äº‘çš„å¤„ç†ã€‚æ­¤å¤–ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆåœ°æ•´åˆæ¥è‡ªä¸åŒä¼ æ„Ÿå™¨çš„ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»“åˆè§¦è§‰ä¿¡æ¯åï¼Œå§¿æ€ä¼°è®¡çš„å¹³å‡è¯¯å·®ä¸º7.5æ¯«ç±³å’Œ16.7åº¦ï¼Œç›¸è¾ƒäºä»…ä½¿ç”¨è§†è§‰çš„æ–¹æ³•ï¼Œå‡†ç¡®æ€§æé«˜äº†20%ã€‚è¯¥æ–¹æ³•åœ¨é«˜é®æŒ¡æƒ…å†µä¸‹çš„è¡¨ç°å°¤ä¸ºçªå‡ºï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…æ“ä½œä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæŠ“å–ã€ç‰©ä½“æ“ä½œå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„ç‰©ä½“å§¿æ€ä¼°è®¡èƒ½åŠ›ï¼Œèƒ½å¤Ÿå®ç°æ›´ç²¾ç¡®çš„æ“ä½œå’Œæ›´é«˜æ•ˆçš„ä»»åŠ¡æ‰§è¡Œï¼Œæœªæ¥å¯èƒ½åœ¨è‡ªåŠ¨åŒ–ä»“å‚¨ã€æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸäº§ç”Ÿé‡è¦å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate in-hand pose estimation is crucial for robotic object manipulation, but visual occlusion remains a major challenge for vision-based approaches. This paper presents an approach to robotic in-hand object pose estimation, combining visual and tactile information to accurately determine the position and orientation of objects grasped by a robotic hand. We address the challenge of visual occlusion by fusing visual information from a wrist-mounted RGB-D camera with tactile information from vision-based tactile sensors mounted on the fingertips of a robotic gripper. Our approach employs a weighting and sensor fusion module to combine point clouds from heterogeneous sensor types and control each modality's contribution to the pose estimation process. We use an augmented Iterative Closest Point (ICP) algorithm adapted for weighted point clouds to estimate the 6D object pose. Our experiments show that incorporating tactile information significantly improves pose estimation accuracy, particularly when occlusion is high. Our method achieves an average pose estimation error of 7.5 mm and 16.7 degrees, outperforming vision-only baselines by up to 20%. We also demonstrate the ability of our method to perform precise object manipulation in a real-world insertion task.

