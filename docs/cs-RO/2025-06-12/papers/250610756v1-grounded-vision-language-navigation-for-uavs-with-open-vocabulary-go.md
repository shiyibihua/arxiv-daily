---
layout: default
title: Grounded Vision-Language Navigation for UAVs with Open-Vocabulary Goal Understanding
---

# Grounded Vision-Language Navigation for UAVs with Open-Vocabulary Goal Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10756" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10756v1</a>
  <a href="https://arxiv.org/pdf/2506.10756.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10756v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10756v1', 'Grounded Vision-Language Navigation for UAVs with Open-Vocabulary Goal Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuhang Zhang, Haosheng Yu, Jiaping Xiao, Mir Feroskhan

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVLFlyæ¡†æ¶ä»¥è§£å†³æ— äººæœºçš„è¯­è¨€å¼•å¯¼å¯¼èˆªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰ä¸è¯­è¨€å¯¼èˆª` `æ— äººæœº` `å¼€æ”¾è¯æ±‡ç†è§£` `è¿ç»­åŠ¨ä½œç©ºé—´` `å¤šæ¨¡æ€èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰ä¸è¯­è¨€å¯¼èˆªæ–¹æ³•åœ¨å¤„ç†åˆ†å¸ƒå¤–ç¯å¢ƒæ—¶æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œä¸”ä¾èµ–å›ºå®šçš„ç¦»æ•£åŠ¨ä½œç©ºé—´ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºçš„VLFlyæ¡†æ¶é€šè¿‡é›†æˆæŒ‡ä»¤ç¼–ç ã€ç›®æ ‡æ£€ç´¢å’Œèˆªç‚¹è§„åˆ’æ¨¡å—ï¼Œå®ç°äº†æ— äººæœºçš„è¯­è¨€å¼•å¯¼é£è¡Œã€‚
3. VLFlyåœ¨å¤šç§ä»¿çœŸç¯å¢ƒä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¸”åœ¨çœŸå®å®¤å†…å¤–ç¯å¢ƒä¸­å±•ç¤ºäº†å¼ºå¤§çš„å¼€æ”¾è¯æ±‡ç›®æ ‡ç†è§£å’Œæ³›åŒ–å¯¼èˆªèƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰ä¸è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰æ˜¯è‡ªä¸»æœºå™¨äººé¢†åŸŸçš„ä¸€ä¸ªé•¿æœŸæŒ‘æˆ˜ï¼Œæ—¨åœ¨ä½¿ä»£ç†èƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­éµå¾ªäººç±»æŒ‡ä»¤è¿›è¡Œå¯¼èˆªã€‚è¯¥é¢†åŸŸé¢ä¸´ä¸¤ä¸ªä¸»è¦ç“¶é¢ˆï¼šå¯¹åˆ†å¸ƒå¤–ç¯å¢ƒçš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ä»¥åŠå¯¹å›ºå®šç¦»æ•£åŠ¨ä½œç©ºé—´çš„ä¾èµ–ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Vision-Language Flyï¼ˆVLFlyï¼‰æ¡†æ¶ï¼Œä¸“ä¸ºæ— äººæœºè®¾è®¡ï¼Œèƒ½å¤Ÿæ‰§è¡Œè¯­è¨€å¼•å¯¼çš„é£è¡Œã€‚VLFlyé€šè¿‡æœºè½½å•ç›®ç›¸æœºæ•è·çš„è‡ªæˆ‘ä¸­å¿ƒè§‚å¯Ÿï¼Œè¾“å‡ºè¿ç»­çš„é€Ÿåº¦æŒ‡ä»¤ï¼Œæ— éœ€å®šä½æˆ–ä¸»åŠ¨æµ‹è·ä¼ æ„Ÿå™¨ã€‚è¯¥æ¡†æ¶é›†æˆäº†ä¸‰ä¸ªæ¨¡å—ï¼šåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤ç¼–ç å™¨ã€ç”±è§†è§‰-è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ç›®æ ‡æ£€ç´¢å™¨ï¼Œä»¥åŠç”Ÿæˆå¯æ‰§è¡Œè½¨è¿¹çš„èˆªç‚¹è§„åˆ’å™¨ã€‚VLFlyåœ¨å¤šæ ·åŒ–çš„ä»¿çœŸç¯å¢ƒä¸­è¿›è¡Œè¯„ä¼°ï¼Œæ— éœ€é¢å¤–å¾®è°ƒï¼Œä¸”å§‹ç»ˆä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ— äººæœºåœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œè¯­è¨€å¼•å¯¼å¯¼èˆªçš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æ³›åŒ–èƒ½åŠ›å’ŒåŠ¨ä½œç©ºé—´ä¸Šå­˜åœ¨æ˜æ˜¾ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVLFlyæ¡†æ¶é€šè¿‡ä¸ä¾èµ–å®šä½æˆ–ä¸»åŠ¨æµ‹è·ä¼ æ„Ÿå™¨ï¼Œåˆ©ç”¨æœºè½½å•ç›®ç›¸æœºçš„è‡ªæˆ‘ä¸­å¿ƒè§‚å¯Ÿï¼Œè¾“å‡ºè¿ç»­çš„é€Ÿåº¦æŒ‡ä»¤ï¼Œä»è€Œå®ç°çµæ´»çš„å¯¼èˆªã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVLFlyæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæŒ‡ä»¤ç¼–ç å™¨ã€ç›®æ ‡æ£€ç´¢å™¨å’Œèˆªç‚¹è§„åˆ’å™¨ã€‚æŒ‡ä»¤ç¼–ç å™¨å°†é«˜å±‚è¯­è¨€è½¬åŒ–ä¸ºç»“æ„åŒ–æç¤ºï¼Œç›®æ ‡æ£€ç´¢å™¨é€šè¿‡è§†è§‰-è¯­è¨€ç›¸ä¼¼æ€§åŒ¹é…æç¤ºä¸ç›®æ ‡å›¾åƒï¼Œèˆªç‚¹è§„åˆ’å™¨ç”Ÿæˆå¯æ‰§è¡Œçš„é£è¡Œè½¨è¿¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šVLFlyçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å¼€æ”¾è¯æ±‡ç›®æ ‡ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿå¤„ç†æŠ½è±¡è¯­è¨€è¾“å…¥å¹¶åœ¨å¤šæ ·åŒ–ç¯å¢ƒä¸­å®ç°æœ‰æ•ˆå¯¼èˆªï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„å›ºå®šåŠ¨ä½œç©ºé—´è®¾è®¡å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šVLFlyé‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡ŒæŒ‡ä»¤ç¼–ç ï¼Œè§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œç›®æ ‡åŒ¹é…ï¼Œèˆªç‚¹è§„åˆ’å™¨åˆ™åŸºäºå®æ—¶åé¦ˆç”Ÿæˆè½¨è¿¹ï¼Œç¡®ä¿æ— äººæœºèƒ½å¤Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­çµæ´»åº”å¯¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VLFlyåœ¨å¤šæ ·åŒ–çš„ä»¿çœŸç¯å¢ƒä¸­è¡¨ç°å‡ºè‰²ï¼Œå§‹ç»ˆä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•ï¼Œä¸”åœ¨çœŸå®ç¯å¢ƒä¸­çš„å®éªŒç»“æœæ˜¾ç¤ºå…¶åœ¨å¼€æ”¾è¯æ±‡ç›®æ ‡ç†è§£å’Œå¯¼èˆªèƒ½åŠ›ä¸Šå…·æœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªè¯¦è¿°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ— äººæœºåœ¨æœç´¢ä¸æ•‘æ´ã€ç¯å¢ƒç›‘æµ‹ã€ç‰©æµé…é€ç­‰åœºæ™¯ä¸­çš„è‡ªä¸»å¯¼èˆªã€‚VLFlyæ¡†æ¶çš„å¼€æ”¾è¯æ±‡ç†è§£èƒ½åŠ›ä½¿å…¶åœ¨å¤„ç†å¤æ‚æŒ‡ä»¤æ—¶å…·æœ‰æ›´é«˜çš„çµæ´»æ€§å’Œé€‚åº”æ€§ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ— äººæœºæŠ€æœ¯åœ¨æ›´å¹¿æ³›é¢†åŸŸçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-and-language navigation (VLN) is a long-standing challenge in autonomous robotics, aiming to empower agents with the ability to follow human instructions while navigating complex environments. Two key bottlenecks remain in this field: generalization to out-of-distribution environments and reliance on fixed discrete action spaces. To address these challenges, we propose Vision-Language Fly (VLFly), a framework tailored for Unmanned Aerial Vehicles (UAVs) to execute language-guided flight. Without the requirement for localization or active ranging sensors, VLFly outputs continuous velocity commands purely from egocentric observations captured by an onboard monocular camera. The VLFly integrates three modules: an instruction encoder based on a large language model (LLM) that reformulates high-level language into structured prompts, a goal retriever powered by a vision-language model (VLM) that matches these prompts to goal images via vision-language similarity, and a waypoint planner that generates executable trajectories for real-time UAV control. VLFly is evaluated across diverse simulation environments without additional fine-tuning and consistently outperforms all baselines. Moreover, real-world VLN tasks in indoor and outdoor environments under direct and indirect instructions demonstrate that VLFly achieves robust open-vocabulary goal understanding and generalized navigation capabilities, even in the presence of abstract language input.

