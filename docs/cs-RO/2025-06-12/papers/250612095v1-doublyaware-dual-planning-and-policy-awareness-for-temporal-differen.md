---
layout: default
title: DoublyAware: Dual Planning and Policy Awareness for Temporal Difference Learning in Humanoid Locomotion
---

# DoublyAware: Dual Planning and Policy Awareness for Temporal Difference Learning in Humanoid Locomotion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.12095" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.12095v1</a>
  <a href="https://arxiv.org/pdf/2506.12095.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.12095v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.12095v1', 'DoublyAware: Dual Planning and Policy Awareness for Temporal Difference Learning in Humanoid Locomotion')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Khang Nguyen, An T. Le, Jan Peters, Minh Nhat Vu

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-12

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫DoublyAware‰ª•Ëß£ÂÜ≥‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ËøêÂä®‰∏≠ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `‰∫∫ÂΩ¢Êú∫Âô®‰∫∫` `Âº∫ÂåñÂ≠¶‰π†` `‰∏çÁ°ÆÂÆöÊÄßÂª∫Ê®°` `ËøêÂä®ÊéßÂà∂` `Ê®°ÂûãÈ¢ÑÊµãÊéßÂà∂` `Ê†∑Êú¨ÊïàÁéá` `Âä®ÊÄÅÁéØÂ¢É`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®È´òÁª¥Âä®‰ΩúÁ©∫Èó¥‰∏≠Èù¢‰∏¥ÁéØÂ¢ÉÈöèÊú∫ÊÄßÂíå‰∏çÁ°ÆÂÆöÊÄßÔºåÂØºËá¥Â≠¶‰π†ÊïàÁéá‰Ωé‰∏ãÂíåÁ®≥ÂÆöÊÄßÂ∑Æ„ÄÇ
2. DoublyAwareÈÄöËøáÂ∞Ü‰∏çÁ°ÆÂÆöÊÄßÂàÜËß£‰∏∫ËßÑÂàíÂíåÁ≠ñÁï•‰∏§ÈÉ®ÂàÜÔºåÁªìÂêàÁ¨¶ÂêàÈ¢ÑÊµãÂíåÁªìÊûÑÂåñÊîøÁ≠ñÂõûÊªöÊù•ÊèêÂçáÂ≠¶‰π†ÊïàÊûú„ÄÇ
3. Âú®HumanoidBench‰∏äÊµãËØïÂêéÔºåDoublyAwareÊòæÁ§∫Âá∫ÊØî‰º†ÁªüÂº∫ÂåñÂ≠¶‰π†Âü∫Á∫øÊõ¥È´òÁöÑÊ†∑Êú¨ÊïàÁéáÂíåÊõ¥Âø´ÁöÑÊî∂ÊïõÈÄüÂ∫¶„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂÆûÁé∞‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ËøêÂä®ÁöÑÁ®≥ÂÅ•Â≠¶‰π†ÊòØÂü∫‰∫éÊ®°ÂûãÁöÑÂº∫ÂåñÂ≠¶‰π†‰∏≠ÁöÑ‰∏ÄÈ°πÂü∫Êú¨ÊåëÊàòÔºåÁéØÂ¢É‰∏≠ÁöÑÈöèÊú∫ÊÄßÂíå‰∏çÁ°ÆÂÆöÊÄß‰ºöÈòªÁ¢çÊúâÊïàÁöÑÊé¢Á¥¢ÂíåÂ≠¶‰π†Á®≥ÂÆöÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫DoublyAwareÔºåËøôÊòØ‰∏Ä‰∏™‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•ÁöÑÊó∂Èó¥Â∑ÆÊ®°ÂûãÈ¢ÑÊµãÊéßÂà∂ÔºàTD-MPCÔºâÊâ©Â±ïÔºåÊòéÁ°ÆÂ∞Ü‰∏çÁ°ÆÂÆöÊÄßÂàÜËß£‰∏∫ËßÑÂàíÂíåÁ≠ñÁï•‰∏§ÈÉ®ÂàÜ„ÄÇDoublyAwareÈÄöËøá‰ΩøÁî®ÈáèÂåñÊ†°ÂáÜÁöÑÈ£éÈô©ÁïåÈôêÔºåÂà©Áî®Á¨¶ÂêàÈ¢ÑÊµãÊù•Â§ÑÁêÜËßÑÂàí‰∏çÁ°ÆÂÆöÊÄßÔºåÂêåÊó∂ÈÄöËøáÁªìÊûÑÂåñÁöÑÊîøÁ≠ñÂõûÊªö‰Ωú‰∏∫‰ø°ÊÅØÂÖàÈ™åÔºåÊîØÊåÅÂ≠¶‰π†Èò∂ÊÆµ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåDoublyAwareÂú®HumanoidBenchËøêÂä®Â•ó‰ª∂‰∏äË°®Áé∞Âá∫Êõ¥È´òÁöÑÊ†∑Êú¨ÊïàÁéá„ÄÅÂä†Âø´ÁöÑÊî∂ÊïõÈÄüÂ∫¶ÂíåÂ¢ûÂº∫ÁöÑËøêÂä®ÂèØË°åÊÄß„ÄÇËØ•Á†îÁ©∂Âº∫Ë∞É‰∫ÜÁªìÊûÑÂåñ‰∏çÁ°ÆÂÆöÊÄßÂª∫Ê®°Âú®Âü∫‰∫éTD-MPCÁöÑ‰∫∫ÂΩ¢ËøêÂä®Â≠¶‰π†‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ËøêÂä®Â≠¶‰π†‰∏≠ÁöÑÁéØÂ¢ÉÈöèÊú∫ÊÄßÂíå‰∏çÁ°ÆÂÆöÊÄßÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®È´òÁª¥Âä®‰ΩúÁ©∫Èó¥‰∏≠Èöæ‰ª•ÊúâÊïàÊé¢Á¥¢ÔºåÂØºËá¥Â≠¶‰π†ÊïàÁéá‰Ωé‰∏ãÂíåÁ®≥ÂÆöÊÄß‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöDoublyAwareÈÄöËøáÂ∞Ü‰∏çÁ°ÆÂÆöÊÄßÂàÜËß£‰∏∫ËßÑÂàí‰∏çÁ°ÆÂÆöÊÄßÂíåÁ≠ñÁï•‰∏çÁ°ÆÂÆöÊÄßÔºåÂà©Áî®Á¨¶ÂêàÈ¢ÑÊµãÊù•ËøáÊª§ÂÄôÈÄâËΩ®ËøπÔºåÂπ∂ÈÄöËøáÁªìÊûÑÂåñÊîøÁ≠ñÂõûÊªöÊèê‰æõ‰ø°ÊÅØÂÖàÈ™åÔºå‰ªéËÄåÊèêÂçáÂ≠¶‰π†ÁöÑÁ®≥ÂÅ•ÊÄßÂíåÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöDoublyAwareÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈ¶ñÂÖàÊòØËßÑÂàíÊ®°ÂùóÔºå‰ΩøÁî®Á¨¶ÂêàÈ¢ÑÊµãÊù•Â§ÑÁêÜËßÑÂàí‰∏çÁ°ÆÂÆöÊÄßÔºõÂÖ∂Ê¨°ÊòØÁ≠ñÁï•Ê®°ÂùóÔºåÂà©Áî®Group-Relative Policy Constraint (GRPC)‰ºòÂåñÂô®Êù•ÊîØÊåÅÁ≠ñÁï•Â≠¶‰π†ÔºåÁ°Æ‰øùÂú®ÊΩúÂú®Âä®‰ΩúÁ©∫Èó¥‰∏≠ÁöÑÈÄÇÂ∫îÊÄß‰ø°‰ªªÂå∫Âüü„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöDoublyAwareÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÊòéÁ°ÆÂàÜËß£‰∏çÁ°ÆÂÆöÊÄß‰∏∫‰∏§ÈÉ®ÂàÜÔºåÂπ∂ÁªìÂêàÁ¨¶ÂêàÈ¢ÑÊµãÂíåÁªìÊûÑÂåñÊîøÁ≠ñÂõûÊªöÔºåÊòæËëóÊèêÂçá‰∫ÜÊú∫Âô®‰∫∫Âú®Â§çÊùÇÂä®ÊÄÅÁéØÂ¢É‰∏≠ÁöÑÂÜ≥Á≠ñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÈááÁî®ÈáèÂåñÊ†°ÂáÜÁöÑÈ£éÈô©ÁïåÈôêÊù•Á°Æ‰øùÁªüËÆ°‰∏ÄËá¥ÊÄßÔºåÂπ∂ÈÄöËøáGRPC‰ºòÂåñÂô®ËÆæÁΩÆÈÄÇÂ∫îÊÄß‰ø°‰ªªÂå∫ÂüüÔºå‰ª•ÊîØÊåÅÈ´òÁΩÆ‰ø°Â∫¶ÂíåÈ´òÂ•ñÂä±Ë°å‰∏∫ÁöÑ‰ºòÂÖàÁ∫ß„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåDoublyAwareÂú®HumanoidBenchËøêÂä®Â•ó‰ª∂‰∏äÁõ∏ÊØî‰∫é‰º†ÁªüÂº∫ÂåñÂ≠¶‰π†Âü∫Á∫øÔºåÊ†∑Êú¨ÊïàÁéáÊèêÈ´ò‰∫ÜÊòæËëóÁöÑÊØî‰æãÔºåÊî∂ÊïõÈÄüÂ∫¶Âä†Âø´ÔºåËøêÂä®ÂèØË°åÊÄßÂ¢ûÂº∫ÔºåÈ™åËØÅ‰∫ÜÁªìÊûÑÂåñ‰∏çÁ°ÆÂÆöÊÄßÂª∫Ê®°ÁöÑÈáçË¶ÅÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑËá™‰∏ªÂØºËà™„ÄÅËøêÂä®ÊéßÂà∂Âíå‰∫∫Êú∫‰∫§‰∫íÁ≠âÂú∫ÊôØ„ÄÇÈÄöËøáÊèêÂçáÊú∫Âô®‰∫∫Âú®Âä®ÊÄÅÁéØÂ¢É‰∏≠ÁöÑÂÜ≥Á≠ñËÉΩÂäõÔºåDoublyAwareÊúâÊúõÂú®Êô∫ËÉΩÂà∂ÈÄ†„ÄÅÊúçÂä°Êú∫Âô®‰∫∫ÂíåÂ®±‰πêÁ≠âÂ§ö‰∏™È¢ÜÂüü‰∫ßÁîüÂÆûÈôÖ‰ª∑ÂÄºÔºåÂπ∂Êé®Âä®Áõ∏ÂÖ≥ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Achieving robust robot learning for humanoid locomotion is a fundamental challenge in model-based reinforcement learning (MBRL), where environmental stochasticity and randomness can hinder efficient exploration and learning stability. The environmental, so-called aleatoric, uncertainty can be amplified in high-dimensional action spaces with complex contact dynamics, and further entangled with epistemic uncertainty in the models during learning phases. In this work, we propose DoublyAware, an uncertainty-aware extension of Temporal Difference Model Predictive Control (TD-MPC) that explicitly decomposes uncertainty into two disjoint interpretable components, i.e., planning and policy uncertainties. To handle the planning uncertainty, DoublyAware employs conformal prediction to filter candidate trajectories using quantile-calibrated risk bounds, ensuring statistical consistency and robustness against stochastic dynamics. Meanwhile, policy rollouts are leveraged as structured informative priors to support the learning phase with Group-Relative Policy Constraint (GRPC) optimizers that impose a group-based adaptive trust-region in the latent action space. This principled combination enables the robot agent to prioritize high-confidence, high-reward behavior while maintaining effective, targeted exploration under uncertainty. Evaluated on the HumanoidBench locomotion suite with the Unitree 26-DoF H1-2 humanoid, DoublyAware demonstrates improved sample efficiency, accelerated convergence, and enhanced motion feasibility compared to RL baselines. Our simulation results emphasize the significance of structured uncertainty modeling for data-efficient and reliable decision-making in TD-MPC-based humanoid locomotion learning.

