---
layout: default
title: No More Marching: Learning Humanoid Locomotion for Short-Range SE(2) Targets
---

# No More Marching: Learning Humanoid Locomotion for Short-Range SE(2) Targets

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14098" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14098v1</a>
  <a href="https://arxiv.org/pdf/2508.14098.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14098v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14098v1', 'No More Marching: Learning Humanoid Locomotion for Short-Range SE(2) Targets')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pranay Dugar, Mohitvishnu S. Gadde, Jonah Siekmann, Yesh Godse, Aayam Shrestha, Alan Fern

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„çŸ­è·ç¦»äººå½¢æœºå™¨äººè¿åŠ¨ä¼˜åŒ–æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `äººå½¢æœºå™¨äºº` `å¼ºåŒ–å­¦ä¹ ` `è¿åŠ¨ä¼˜åŒ–` `SE(2)ç›®æ ‡` `èƒ½æ•ˆ` `å¥–åŠ±å‡½æ•°è®¾è®¡` `çŸ­è·ç¦»è¿åŠ¨` `ä»¿çœŸä¸ç¡¬ä»¶è½¬ç§»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦ä¼˜åŒ–é€Ÿåº¦è·Ÿè¸ªï¼Œå¯¼è‡´çŸ­è·ç¦»ä»»åŠ¡ä¸­è¡¨ç°å‡ºä½æ•ˆçš„è¡Œè¿›é£æ ¼ï¼Œéš¾ä»¥æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œç›´æ¥ä¼˜åŒ–äººå½¢æœºå™¨äººå¯¹SE(2)ç›®æ ‡çš„è¿åŠ¨ï¼Œé‡‡ç”¨æ–°è®¾è®¡çš„æ˜Ÿåº§å¥–åŠ±å‡½æ•°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨èƒ½è€—ã€åˆ°è¾¾æ—¶é—´å’Œæ­¥ä¼æ•°é‡ä¸Šå‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå¹¶æˆåŠŸå®ç°äº†ä»ä»¿çœŸåˆ°ç¡¬ä»¶çš„è½¬ç§»ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººå½¢æœºå™¨äººåœ¨å®é™…å·¥ä½œç¯å¢ƒä¸­éœ€è¦é¢‘ç¹æ‰§è¡Œä»»åŠ¡é©±åŠ¨çš„çŸ­è·ç¦»è¿åŠ¨ä»¥è¾¾åˆ°SE(2)ç›®æ ‡å§¿æ€ã€‚ä¸ºäº†å®ç”¨æ€§ï¼Œè¿™äº›è¿‡æ¸¡å¿…é¡»å¿«é€Ÿã€ç¨³å¥ä¸”èƒ½æ•ˆé«˜ã€‚å°½ç®¡åŸºäºå­¦ä¹ çš„è¿åŠ¨æ–¹æ³•å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•å¤§å¤šä¼˜åŒ–é€Ÿåº¦è·Ÿè¸ªè€Œéç›´æ¥å§¿æ€åˆ°è¾¾ï¼Œå¯¼è‡´åœ¨çŸ­è·ç¦»ä»»åŠ¡ä¸­è¡¨ç°å‡ºä½æ•ˆçš„è¡Œè¿›é£æ ¼ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç›´æ¥ä¼˜åŒ–äººå½¢æœºå™¨äººçš„SE(2)ç›®æ ‡è¿åŠ¨ï¼Œæ ¸å¿ƒåœ¨äºè®¾è®¡äº†ä¸€ç§æ–°çš„æ˜Ÿåº§å¥–åŠ±å‡½æ•°ï¼Œé¼“åŠ±è‡ªç„¶ä¸”é«˜æ•ˆçš„ç›®æ ‡å¯¼å‘è¿åŠ¨ã€‚é€šè¿‡å¼•å…¥åŸºå‡†æ¡†æ¶è¯„ä¼°èƒ½è€—ã€åˆ°è¾¾æ—¶é—´å’Œæ­¥ä¼æ•°é‡ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¼˜äºæ ‡å‡†æ–¹æ³•ï¼Œå¹¶æˆåŠŸå®ç°äº†ä»ä»¿çœŸåˆ°ç¡¬ä»¶çš„è½¬ç§»ï¼Œå¼ºè°ƒäº†é’ˆå¯¹æ€§å¥–åŠ±è®¾è®¡åœ¨å®é™…çŸ­è·ç¦»äººå½¢æœºå™¨äººè¿åŠ¨ä¸­çš„é‡è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³äººå½¢æœºå™¨äººåœ¨çŸ­è·ç¦»ä»»åŠ¡ä¸­è¿åŠ¨æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾§é‡äºé€Ÿåº¦è·Ÿè¸ªï¼Œå¯¼è‡´åœ¨å®é™…åº”ç”¨ä¸­è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç›´æ¥ä¼˜åŒ–äººå½¢æœºå™¨äººå¯¹SE(2)ç›®æ ‡çš„è¿åŠ¨ï¼Œè®¾è®¡äº†æ˜Ÿåº§å¥–åŠ±å‡½æ•°ä»¥é¼“åŠ±è‡ªç„¶ä¸”é«˜æ•ˆçš„è¿åŠ¨æ–¹å¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç¯å¢ƒå»ºæ¨¡ã€å¥–åŠ±å‡½æ•°è®¾è®¡ã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒå’Œæ€§èƒ½è¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚é€šè¿‡è¿™äº›æ¨¡å—çš„ååŒå·¥ä½œï¼Œæœºå™¨äººèƒ½å¤Ÿå­¦ä¹ åˆ°æ›´ä¼˜çš„è¿åŠ¨ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæ˜Ÿåº§å¥–åŠ±å‡½æ•°çš„è®¾è®¡ï¼Œè¯¥å‡½æ•°èƒ½å¤Ÿæœ‰æ•ˆå¼•å¯¼æœºå™¨äººæœå‘ç›®æ ‡ç§»åŠ¨ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„é€Ÿåº¦è·Ÿè¸ªæ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œå¥–åŠ±å‡½æ•°çš„æƒé‡ç»è¿‡è°ƒä¼˜ï¼Œä»¥å¹³è¡¡èƒ½è€—å’Œè¿åŠ¨æ•ˆç‡ï¼›ç½‘ç»œç»“æ„é‡‡ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œç»“åˆäº†ç­–ç•¥æ¢¯åº¦å’Œä»·å€¼å‡½æ•°çš„ä¼˜åŒ–æ–¹æ³•ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°è®¾è®¡ä¹Ÿç»è¿‡å®éªŒéªŒè¯ï¼Œä»¥ç¡®ä¿å­¦ä¹ è¿‡ç¨‹çš„ç¨³å®šæ€§å’Œæ”¶æ•›æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ–¹æ³•åœ¨èƒ½è€—ã€åˆ°è¾¾æ—¶é—´å’Œæ­¥ä¼æ•°é‡ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œèƒ½è€—é™ä½äº†çº¦20%ï¼Œåˆ°è¾¾æ—¶é—´ç¼©çŸ­äº†15%ï¼Œæ­¥ä¼æ•°é‡å‡å°‘äº†30%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•æˆåŠŸå®ç°äº†ä»ä»¿çœŸåˆ°ç¡¬ä»¶çš„è½¬ç§»ï¼ŒéªŒè¯äº†å…¶å®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å·¥ä¸šè‡ªåŠ¨åŒ–ã€æœåŠ¡æœºå™¨äººå’Œäººå½¢æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¯¼èˆªç­‰ã€‚é€šè¿‡ä¼˜åŒ–çŸ­è·ç¦»è¿åŠ¨ï¼Œèƒ½å¤Ÿæé«˜æœºå™¨äººåœ¨å®é™…ä»»åŠ¡ä¸­çš„æ‰§è¡Œæ•ˆç‡å’Œèƒ½æ•ˆï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Humanoids operating in real-world workspaces must frequently execute task-driven, short-range movements to SE(2) target poses. To be practical, these transitions must be fast, robust, and energy efficient. While learning-based locomotion has made significant progress, most existing methods optimize for velocity-tracking rather than direct pose reaching, resulting in inefficient, marching-style behavior when applied to short-range tasks. In this work, we develop a reinforcement learning approach that directly optimizes humanoid locomotion for SE(2) targets. Central to this approach is a new constellation-based reward function that encourages natural and efficient target-oriented movement. To evaluate performance, we introduce a benchmarking framework that measures energy consumption, time-to-target, and footstep count on a distribution of SE(2) goals. Our results show that the proposed approach consistently outperforms standard methods and enables successful transfer from simulation to hardware, highlighting the importance of targeted reward design for practical short-range humanoid locomotion.

