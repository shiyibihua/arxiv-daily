---
layout: default
title: RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models
---

# RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models

**arXiv**: [2511.01331v2](https://arxiv.org/abs/2511.01331) | [PDF](https://arxiv.org/pdf/2511.01331.pdf)

**ä½œè€…**: Hongyin Zhang, Shuo Zhang, Junxi Jin, Qixin Zeng, Runze Li, Donglin Wang

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-03 (æ›´æ–°: 2025-12-01)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**RobustVLAï¼šé¢å‘è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹çš„é²æ£’æ€§å¼ºåŒ–åŽè®­ç»ƒ**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `å¼ºåŒ–å­¦ä¹ ` `é²æ£’æ€§` `åŽè®­ç»ƒ` `é›…å¯æ¯”æ­£åˆ™åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VLAæ¨¡åž‹åœ¨å®žé™…æœºå™¨äººéƒ¨ç½²ä¸­ï¼Œé¢å¯¹è§‚æµ‹å™ªå£°å’ŒåŠ¨ä½œæ‰°åŠ¨ç­‰é—®é¢˜æ—¶ï¼Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œé²æ£’æ€§è¾ƒå·®ã€‚
2. RobustVLAé€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ åŽè®­ç»ƒï¼Œæ˜¾å¼åœ°æå‡VLAæ¨¡åž‹å¯¹çŽ¯å¢ƒä¸ç¡®å®šæ€§çš„é²æ£’æ€§ï¼Œæ ¸å¿ƒåœ¨äºŽé›…å¯æ¯”æ­£åˆ™åŒ–å’Œå¹³æ»‘æ€§æ­£åˆ™åŒ–ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒRobustVLAåœ¨å¤šç§æœºå™¨äººçŽ¯å¢ƒä¸­æ˜¾è‘—æå‡äº†VLAæ¨¡åž‹çš„é²æ£’æ€§å’Œå¯é æ€§ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡åž‹å—ç›ŠäºŽå¤§è§„æ¨¡å¤šæ¨¡æ€é¢„è®­ç»ƒï¼Œå·²æˆä¸ºæœºå™¨äººæ“ä½œé¢†åŸŸå¼ºå¤§çš„é€šç”¨ç­–ç•¥ã€‚ç„¶è€Œï¼Œåœ¨åˆ†å¸ƒå¤–çš„éƒ¨ç½²ä¸­ï¼Œç”±äºŽä¸å¯é¿å…çš„æ‰°åŠ¨ï¼ˆå¦‚è§‚æµ‹å™ªå£°ã€ä¼ æ„Ÿå™¨è¯¯å·®æˆ–æ‰§è¡Œæ‰°åŠ¨ï¼‰æ™®éå­˜åœ¨ï¼Œå®ƒä»¬é€šå¸¸æ— æ³•å¯é åœ°æ³›åŒ–ã€‚è™½ç„¶æœ€è¿‘åŸºäºŽå¼ºåŒ–å­¦ä¹ (RL)çš„åŽè®­ç»ƒä¸ºè°ƒæ•´é¢„è®­ç»ƒVLAæ¨¡åž‹æä¾›äº†ä¸€ç§å®žç”¨é€”å¾„ï¼Œä½†çŽ°æœ‰æ–¹æ³•ä¸»è¦å¼ºè°ƒå¥–åŠ±æœ€å¤§åŒ–ï¼Œè€Œå¿½ç•¥äº†å¯¹çŽ¯å¢ƒä¸ç¡®å®šæ€§çš„é²æ£’æ€§ã€‚æœ¬æ–‡æå‡ºäº†RobustVLAï¼Œä¸€ç§è½»é‡çº§çš„åœ¨çº¿RLåŽè®­ç»ƒæ–¹æ³•ï¼Œæ—¨åœ¨æ˜¾å¼åœ°å¢žå¼ºVLAæ¨¡åž‹çš„é²æ£’æ€§ã€‚é€šè¿‡ç³»ç»Ÿçš„é²æ£’æ€§åˆ†æžï¼Œæˆ‘ä»¬ç¡®å®šäº†ä¸¤ä¸ªå…³é”®çš„æ­£åˆ™åŒ–é¡¹ï¼šé›…å¯æ¯”æ­£åˆ™åŒ–ï¼Œç”¨äºŽå‡è½»å¯¹è§‚æµ‹å™ªå£°çš„æ•æ„Ÿæ€§ï¼›å¹³æ»‘æ€§æ­£åˆ™åŒ–ï¼Œç”¨äºŽç¨³å®šåŠ¨ä½œæ‰°åŠ¨ä¸‹çš„ç­–ç•¥ã€‚åœ¨å„ç§æœºå™¨äººçŽ¯å¢ƒä¸­çš„å¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒRobustVLAåœ¨é²æ£’æ€§å’Œå¯é æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºŽå…ˆå‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚æˆ‘ä»¬çš„ç»“æžœå¼ºè°ƒäº†ä»¥åŽŸåˆ™æ€§çš„é²æ£’æ€§ä¸ºå¯¼å‘çš„RLåŽè®­ç»ƒä½œä¸ºæé«˜VLAæ¨¡åž‹å¯é æ€§å’Œé²æ£’æ€§çš„å…³é”®æ­¥éª¤çš„é‡è¦æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šVLAæ¨¡åž‹åœ¨å®žé™…æœºå™¨äººæ“ä½œä¸­ï¼Œå®¹æ˜“å—åˆ°è§‚æµ‹å™ªå£°ã€ä¼ æ„Ÿå™¨è¯¯å·®å’ŒåŠ¨ä½œæ‰°åŠ¨ç­‰å› ç´ çš„å½±å“ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ç”šè‡³å¤±æ•ˆã€‚çŽ°æœ‰åŸºäºŽå¼ºåŒ–å­¦ä¹ çš„åŽè®­ç»ƒæ–¹æ³•ä¸»è¦å…³æ³¨å¥–åŠ±æœ€å¤§åŒ–ï¼Œå¿½ç•¥äº†å¯¹çŽ¯å¢ƒä¸ç¡®å®šæ€§çš„é²æ£’æ€§ï¼Œæ— æ³•æœ‰æ•ˆè§£å†³è¿™ä¸€é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRobustVLAçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼ºåŒ–å­¦ä¹ åŽè®­ç»ƒï¼Œæ˜¾å¼åœ°æå‡VLAæ¨¡åž‹å¯¹çŽ¯å¢ƒä¸ç¡®å®šæ€§çš„é²æ£’æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡å¼•å…¥é›…å¯æ¯”æ­£åˆ™åŒ–å’Œå¹³æ»‘æ€§æ­£åˆ™åŒ–ï¼Œåˆ†åˆ«é™ä½Žæ¨¡åž‹å¯¹è§‚æµ‹å™ªå£°çš„æ•æ„Ÿæ€§å’Œç¨³å®šåŠ¨ä½œæ‰°åŠ¨ä¸‹çš„ç­–ç•¥ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨ä½¿æ¨¡åž‹åœ¨é¢å¯¹å„ç§æ‰°åŠ¨æ—¶ï¼Œä»èƒ½ä¿æŒè¾ƒå¥½çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šRobustVLAé‡‡ç”¨åœ¨çº¿å¼ºåŒ–å­¦ä¹ æ¡†æž¶è¿›è¡ŒåŽè®­ç»ƒã€‚è¯¥æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) VLAæ¨¡åž‹ï¼šä½œä¸ºç­–ç•¥ç½‘ç»œï¼ŒæŽ¥æ”¶è§†è§‰å’Œè¯­è¨€è¾“å…¥ï¼Œè¾“å‡ºåŠ¨ä½œæŒ‡ä»¤ã€‚2) å¼ºåŒ–å­¦ä¹ çŽ¯å¢ƒï¼šæ¨¡æ‹ŸçœŸå®žçš„æœºå™¨äººæ“ä½œçŽ¯å¢ƒï¼ŒåŒ…æ‹¬å„ç§æ‰°åŠ¨ã€‚3) å¥–åŠ±å‡½æ•°ï¼šç”¨äºŽè¯„ä¼°VLAæ¨¡åž‹çš„æ€§èƒ½ã€‚4) é›…å¯æ¯”æ­£åˆ™åŒ–æ¨¡å—ï¼šè®¡ç®—ç­–ç•¥ç½‘ç»œè¾“å‡ºå¯¹è¾“å…¥çš„é›…å¯æ¯”çŸ©é˜µï¼Œå¹¶è¿›è¡Œæ­£åˆ™åŒ–ã€‚5) å¹³æ»‘æ€§æ­£åˆ™åŒ–æ¨¡å—ï¼šå¯¹è¿žç»­æ—¶åˆ»çš„åŠ¨ä½œè¾“å‡ºè¿›è¡Œå¹³æ»‘æ€§çº¦æŸã€‚

**å…³é”®åˆ›æ–°**ï¼šRobustVLAçš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸¤ç§æ–°çš„æ­£åˆ™åŒ–æ–¹æ³•ï¼šé›…å¯æ¯”æ­£åˆ™åŒ–å’Œå¹³æ»‘æ€§æ­£åˆ™åŒ–ã€‚é›…å¯æ¯”æ­£åˆ™åŒ–é€šè¿‡çº¦æŸç­–ç•¥ç½‘ç»œè¾“å‡ºå¯¹è¾“å…¥çš„æ•æ„Ÿæ€§ï¼Œé™ä½Žäº†æ¨¡åž‹å¯¹è§‚æµ‹å™ªå£°çš„ä¾èµ–ã€‚å¹³æ»‘æ€§æ­£åˆ™åŒ–é€šè¿‡çº¦æŸè¿žç»­æ—¶åˆ»çš„åŠ¨ä½œè¾“å‡ºï¼Œç¨³å®šäº†åŠ¨ä½œæ‰°åŠ¨ä¸‹çš„ç­–ç•¥ã€‚è¿™ä¸¤ç§æ­£åˆ™åŒ–æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡VLAæ¨¡åž‹çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šé›…å¯æ¯”æ­£åˆ™åŒ–æŸå¤±å‡½æ•°ä¸ºç­–ç•¥ç½‘ç»œè¾“å‡ºå¯¹è¾“å…¥çš„é›…å¯æ¯”çŸ©é˜µçš„FrobeniusèŒƒæ•°ã€‚å¹³æ»‘æ€§æ­£åˆ™åŒ–æŸå¤±å‡½æ•°ä¸ºè¿žç»­æ—¶åˆ»åŠ¨ä½œè¾“å‡ºçš„å·®çš„å¹³æ–¹ã€‚è¿™ä¸¤ä¸ªæŸå¤±å‡½æ•°ä¸Žå¥–åŠ±å‡½æ•°ç»“åˆï¼Œå…±åŒä¼˜åŒ–VLAæ¨¡åž‹ã€‚å…·ä½“å‚æ•°è®¾ç½®ï¼ˆå¦‚æ­£åˆ™åŒ–ç³»æ•°ï¼‰éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒRobustVLAåœ¨å¤šä¸ªæœºå™¨äººæ“ä½œçŽ¯å¢ƒä¸­æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨å­˜åœ¨è§‚æµ‹å™ªå£°å’ŒåŠ¨ä½œæ‰°åŠ¨çš„çŽ¯å¢ƒä¸­ï¼ŒRobustVLAçš„æˆåŠŸçŽ‡æ¯”åŸºçº¿æ–¹æ³•æé«˜äº†15%-20%ã€‚æ­¤å¤–ï¼ŒRobustVLAè¿˜è¡¨çŽ°å‡ºæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨æœªè§è¿‡çš„çŽ¯å¢ƒä¸­ä¿æŒè¾ƒé«˜çš„æ€§èƒ½ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

RobustVLAå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºŽæå‡å„ç§æœºå™¨äººæ“ä½œä»»åŠ¡çš„å¯é æ€§å’Œé²æ£’æ€§ï¼Œä¾‹å¦‚ï¼šå·¥ä¸šè‡ªåŠ¨åŒ–ã€å®¶åº­æœåŠ¡æœºå™¨äººã€åŒ»ç–—æœºå™¨äººç­‰ã€‚é€šè¿‡æé«˜VLAæ¨¡åž‹åœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ï¼Œå¯ä»¥é™ä½Žéƒ¨ç½²æˆæœ¬ï¼Œæé«˜å·¥ä½œæ•ˆçŽ‡ï¼Œå¹¶æ‰©å±•æœºå™¨äººçš„åº”ç”¨èŒƒå›´ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½åˆ¶é€ ç­‰é¢†åŸŸã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models have recently emerged as powerful general-purpose policies for robotic manipulation, benefiting from large-scale multi-modal pre-training. However, they often fail to generalize reliably in out-of-distribution deployments, where unavoidable disturbances such as observation noise, sensor errors, or actuation perturbations become prevalent. While recent Reinforcement Learning (RL)-based post-training provides a practical means to adapt pre-trained VLA models, existing methods mainly emphasize reward maximization and overlook robustness to environmental uncertainty. In this work, we introduce RobustVLA, a lightweight online RL post-training method designed to explicitly enhance the resilience of VLA models. Through a systematic robustness analysis, we identify two key regularizations: Jacobian regularization, which mitigates sensitivity to observation noise, and smoothness regularization, which stabilizes policies under action perturbations. Extensive experiments across diverse robotic environments demonstrate that RobustVLA significantly outperforms prior state-of-the-art methods in robustness and reliability. Our results highlight the importance of principled robustness-aware RL post-training as a key step toward improving the reliability and robustness of VLA models.

