---
layout: default
title: Kinematify: Open-Vocabulary Synthesis of High-DoF Articulated Objects
---

# Kinematify: Open-Vocabulary Synthesis of High-DoF Articulated Objects

**arXiv**: [2511.01294v2](https://arxiv.org/abs/2511.01294) | [PDF](https://arxiv.org/pdf/2511.01294.pdf)

**ä½œè€…**: Jiawei Wang, Dingyou Wang, Jiaming Hu, Qixuan Zhang, Jingyi Yu, Lan Xu

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-03 (æ›´æ–°: 2025-11-04)

**å¤‡æ³¨**: project page: https://sites.google.com/deemos.com/kinematify

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Kinematifyï¼šå¼€æ”¾è¯æ±‡é«˜è‡ªç”±åº¦é“°æŽ¥ç‰©ä½“è‡ªåŠ¨åˆæˆæ¡†æž¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `é“°æŽ¥ç‰©ä½“` `è¿åŠ¨å­¦ç»“æž„` `è’™ç‰¹å¡æ´›æ ‘æœç´¢` `å‡ ä½•é©±åŠ¨ä¼˜åŒ–` `æœºå™¨äººæ“ä½œ` `ç‰©ç†æ¨¡æ‹Ÿ` `å¼€æ”¾è¯æ±‡` `é«˜è‡ªç”±åº¦`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰é“°æŽ¥ç‰©ä½“å»ºæ¨¡æ–¹æ³•ä¾èµ–è¿åŠ¨åºåˆ—æˆ–äººå·¥æ ‡æ³¨æ•°æ®é›†ï¼Œéš¾ä»¥æ‰©å±•åˆ°é«˜è‡ªç”±åº¦ç‰©ä½“ã€‚
2. Kinematify ç»“åˆ MCTS æœç´¢è¿›è¡Œç»“æž„æŽ¨ç†ï¼Œå¹¶åˆ©ç”¨å‡ ä½•é©±åŠ¨ä¼˜åŒ–è¿›è¡Œå…³èŠ‚å‚æ•°ä¼°è®¡ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒKinematify åœ¨åˆæˆå’ŒçœŸå®žæ•°æ®ä¸Šï¼Œé…å‡†å’Œè¿åŠ¨å­¦æ‹“æ‰‘ç²¾åº¦å‡ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯¹è¿åŠ¨å­¦ç»“æž„å’Œå¯ç§»åŠ¨éƒ¨ä»¶çš„æ·±åˆ»ç†è§£å¯¹äºŽæœºå™¨äººæ“ä½œç‰©ä½“å’Œå»ºæ¨¡è‡ªèº«é“°æŽ¥å½¢æ€è‡³å…³é‡è¦ã€‚è¿™ç§ç†è§£é€šè¿‡é“°æŽ¥ç‰©ä½“æ¥æ•èŽ·ï¼Œè¿™å¯¹äºŽç‰©ç†æ¨¡æ‹Ÿã€è¿åŠ¨è§„åˆ’å’Œç­–ç•¥å­¦ä¹ ç­‰ä»»åŠ¡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œåˆ›å»ºè¿™äº›æ¨¡åž‹ï¼Œç‰¹åˆ«æ˜¯å¯¹äºŽå…·æœ‰é«˜è‡ªç”±åº¦ï¼ˆDoFï¼‰çš„ç‰©ä½“ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºŽè¿åŠ¨åºåˆ—æˆ–æ¥è‡ªæ‰‹åŠ¨ç®¡ç†æ•°æ®é›†çš„å¼ºå‡è®¾ï¼Œè¿™é˜»ç¢äº†å¯æ‰©å±•æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç» Kinematifyï¼Œè¿™æ˜¯ä¸€ä¸ªè‡ªåŠ¨æ¡†æž¶ï¼Œå¯ä»¥ç›´æŽ¥ä»Žä»»æ„ RGB å›¾åƒæˆ–æ–‡æœ¬æè¿°ä¸­åˆæˆé“°æŽ¥ç‰©ä½“ã€‚æˆ‘ä»¬çš„æ–¹æ³•è§£å†³äº†ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼šï¼ˆiï¼‰æŽ¨æ–­é«˜è‡ªç”±åº¦ç‰©ä½“çš„è¿åŠ¨å­¦æ‹“æ‰‘ï¼›ï¼ˆiiï¼‰ä»Žé™æ€å‡ ä½•ä½“ä¼°è®¡å…³èŠ‚å‚æ•°ã€‚ä¸ºäº†å®žçŽ°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬ç»“åˆäº†ç”¨äºŽç»“æž„æŽ¨ç†çš„ MCTS æœç´¢å’Œç”¨äºŽå…³èŠ‚æŽ¨ç†çš„å‡ ä½•é©±åŠ¨ä¼˜åŒ–ï¼Œä»Žè€Œäº§ç”Ÿç‰©ç†ä¸Šä¸€è‡´ä¸”åŠŸèƒ½ä¸Šæœ‰æ•ˆçš„æè¿°ã€‚æˆ‘ä»¬åœ¨æ¥è‡ªåˆæˆå’ŒçœŸå®žçŽ¯å¢ƒçš„å„ç§è¾“å…¥ä¸Šè¯„ä¼° Kinematifyï¼Œè¯æ˜Žäº†åœ¨é…å‡†å’Œè¿åŠ¨å­¦æ‹“æ‰‘ç²¾åº¦æ–¹é¢ä¼˜äºŽçŽ°æœ‰æŠ€æœ¯ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰æ–¹æ³•åœ¨æž„å»ºé«˜è‡ªç”±åº¦é“°æŽ¥ç‰©ä½“æ¨¡åž‹æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦ç—›ç‚¹åœ¨äºŽä¾èµ–å¤§é‡çš„è¿åŠ¨åºåˆ—æ•°æ®æˆ–å¼ºå…ˆéªŒå‡è®¾ï¼Œè¿™é™åˆ¶äº†å…¶å¯æ‰©å±•æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ç‰¹åˆ«æ˜¯å¯¹äºŽå¼€æ”¾è¯æ±‡åœºæ™¯ï¼Œç¼ºä¹é’ˆå¯¹å„ç§ç‰©ä½“ç±»åž‹çš„è¿åŠ¨æ•°æ®ï¼Œä½¿å¾—è‡ªåŠ¨æž„å»ºç²¾ç¡®çš„é“°æŽ¥æ¨¡åž‹å˜å¾—å›°éš¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šKinematify çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†é“°æŽ¥ç‰©ä½“çš„åˆæˆé—®é¢˜åˆ†è§£ä¸ºä¸¤ä¸ªå­é—®é¢˜ï¼šè¿åŠ¨å­¦æ‹“æ‰‘æŽ¨æ–­å’Œå…³èŠ‚å‚æ•°ä¼°è®¡ã€‚é€šè¿‡ç»“åˆè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰è¿›è¡Œç»“æž„æŽ¨ç†ï¼Œå¹¶åˆ©ç”¨å‡ ä½•é©±åŠ¨çš„ä¼˜åŒ–æ–¹æ³•è¿›è¡Œå…³èŠ‚å‚æ•°ä¼°è®¡ï¼Œä»Žè€Œåœ¨æ²¡æœ‰å¤§é‡è¿åŠ¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œä»Žé™æ€å‡ ä½•ä¿¡æ¯ä¸­æŽ¨æ–­å‡ºåˆç†çš„é“°æŽ¥ç»“æž„ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šKinematify çš„æ•´ä½“æ¡†æž¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) è¾“å…¥ï¼šæŽ¥æ”¶ RGB å›¾åƒæˆ–æ–‡æœ¬æè¿°ä½œä¸ºè¾“å…¥ã€‚2) ç»“æž„æŽ¨ç†ï¼šä½¿ç”¨ MCTS æœç´¢ç®—æ³•æŽ¢ç´¢å¯èƒ½çš„è¿åŠ¨å­¦æ‹“æ‰‘ç»“æž„ã€‚3) å…³èŠ‚å‚æ•°ä¼°è®¡ï¼šåˆ©ç”¨å‡ ä½•é©±åŠ¨çš„ä¼˜åŒ–æ–¹æ³•ï¼Œæ ¹æ®é™æ€å‡ ä½•ä¿¡æ¯ä¼°è®¡å…³èŠ‚çš„ä½ç½®ã€æ–¹å‘å’Œè¿åŠ¨èŒƒå›´ã€‚4) æ¨¡åž‹ç”Ÿæˆï¼šå°†æŽ¨æ–­å‡ºçš„æ‹“æ‰‘ç»“æž„å’Œå…³èŠ‚å‚æ•°ç»„åˆæˆå®Œæ•´çš„é“°æŽ¥ç‰©ä½“æ¨¡åž‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šKinematify çš„å…³é”®åˆ›æ–°åœ¨äºŽå°† MCTS æœç´¢åº”ç”¨äºŽè¿åŠ¨å­¦æ‹“æ‰‘çš„æŽ¨æ–­ï¼Œè¿™ä½¿å¾—å®ƒèƒ½å¤Ÿåœ¨æ²¡æœ‰å¤§é‡è¿åŠ¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆåœ°æŽ¢ç´¢å¤æ‚çš„é“°æŽ¥ç»“æž„ç©ºé—´ã€‚æ­¤å¤–ï¼Œå‡ ä½•é©±åŠ¨çš„ä¼˜åŒ–æ–¹æ³•èƒ½å¤Ÿä»Žé™æ€å‡ ä½•ä¿¡æ¯ä¸­æå–æœ‰ç”¨çš„çº¿ç´¢ï¼Œä»Žè€Œæ›´å‡†ç¡®åœ°ä¼°è®¡å…³èŠ‚å‚æ•°ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒKinematify èƒ½å¤Ÿå¤„ç†æ›´å¹¿æ³›çš„ç‰©ä½“ç±»åž‹ï¼Œå¹¶ä¸”ä¸éœ€è¦å¤§é‡çš„è¿åŠ¨æ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ MCTS æœç´¢ä¸­ï¼Œéœ€è¦å®šä¹‰åˆé€‚çš„å¥–åŠ±å‡½æ•°æ¥å¼•å¯¼æœç´¢è¿‡ç¨‹ã€‚å¥–åŠ±å‡½æ•°çš„è®¾è®¡éœ€è¦è€ƒè™‘ç»“æž„çš„åˆç†æ€§ã€å…³èŠ‚çš„è¿åŠ¨èŒƒå›´ä»¥åŠä¸Žè¾“å…¥å‡ ä½•çš„åŒ¹é…ç¨‹åº¦ã€‚åœ¨å‡ ä½•é©±åŠ¨çš„ä¼˜åŒ–ä¸­ï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„å‡ ä½•ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œè¡¨é¢æ³•çº¿ã€æ›²çŽ‡ç­‰ï¼‰æ¥çº¦æŸå…³èŠ‚å‚æ•°çš„ä¼°è®¡ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿéœ€è¦è€ƒè™‘ç‰©ç†ä¸€è‡´æ€§ï¼Œä¾‹å¦‚é¿å…å…³èŠ‚ä¹‹é—´çš„ç¢°æ’žã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

Kinematify åœ¨åˆæˆå’ŒçœŸå®žæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨é…å‡†ç²¾åº¦å’Œè¿åŠ¨å­¦æ‹“æ‰‘ç²¾åº¦æ–¹é¢å‡ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼ŒKinematify åœ¨é«˜è‡ªç”±åº¦é“°æŽ¥ç‰©ä½“çš„å»ºæ¨¡æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æå‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†å¤æ‚çš„é“°æŽ¥ç»“æž„ï¼Œå¹¶ä¸”å¯¹å™ªå£°å’Œé®æŒ¡å…·æœ‰ä¸€å®šçš„é²æ£’æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

Kinematify æœ‰æ½œåŠ›åº”ç”¨äºŽæœºå™¨äººæ“ä½œã€ç‰©ç†æ¨¡æ‹Ÿã€æ¸¸æˆå¼€å‘å’Œè™šæ‹ŸçŽ°å®žç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººç†è§£å’Œæ“ä½œå„ç§é“°æŽ¥ç‰©ä½“ï¼Œæé«˜æœºå™¨äººçš„è‡ªä¸»æ€§å’Œé€‚åº”æ€§ã€‚åœ¨ç‰©ç†æ¨¡æ‹Ÿä¸­ï¼Œå®ƒå¯ä»¥ç”¨äºŽåˆ›å»ºæ›´é€¼çœŸçš„é“°æŽ¥ç‰©ä½“æ¨¡åž‹ï¼Œä»Žè€Œæé«˜æ¨¡æ‹Ÿçš„å‡†ç¡®æ€§ã€‚åœ¨æ¸¸æˆå¼€å‘å’Œè™šæ‹ŸçŽ°å®žä¸­ï¼Œå®ƒå¯ä»¥ç”¨äºŽåˆ›å»ºæ›´ä¸°å¯Œçš„äº¤äº’ä½“éªŒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> A deep understanding of kinematic structures and movable components is essential for enabling robots to manipulate objects and model their own articulated forms. Such understanding is captured through articulated objects, which are essential for tasks such as physical simulation, motion planning, and policy learning. However, creating these models, particularly for objects with high degrees of freedom (DoF), remains a significant challenge. Existing methods typically rely on motion sequences or strong assumptions from hand-curated datasets, which hinders scalability. In this paper, we introduce Kinematify, an automated framework that synthesizes articulated objects directly from arbitrary RGB images or textual descriptions. Our method addresses two core challenges: (i) inferring kinematic topologies for high-DoF objects and (ii) estimating joint parameters from static geometry. To achieve this, we combine MCTS search for structural inference with geometry-driven optimization for joint reasoning, producing physically consistent and functionally valid descriptions. We evaluate Kinematify on diverse inputs from both synthetic and real-world environments, demonstrating improvements in registration and kinematic topology accuracy over prior work.

