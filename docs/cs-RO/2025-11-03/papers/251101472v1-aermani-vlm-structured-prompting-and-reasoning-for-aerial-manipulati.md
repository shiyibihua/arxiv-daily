---
layout: default
title: AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models
---

# AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.01472" target="_blank" class="toolbar-btn">arXiv: 2511.01472v1</a>
    <a href="https://arxiv.org/pdf/2511.01472.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.01472v1" 
            onclick="toggleFavorite(this, '2511.01472v1', 'AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Sarthak Mishra, Rishabh Dev Yadav, Avirup Das, Saksham Gupta, Wei Pan, Spandan Roy

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-03

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**AERMANI-VLMÔºöÂü∫‰∫éÁªìÊûÑÂåñÊèêÁ§∫ÂíåÊé®ÁêÜÁöÑËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®Êó†‰∫∫Êú∫Êìç‰Ωú‰∏≠ÁöÑÂ∫îÁî®**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâËØ≠Ë®ÄÊ®°Âûã` `Êó†‰∫∫Êú∫Êìç‰Ωú` `ÁªìÊûÑÂåñÊèêÁ§∫` `Êú∫Âô®‰∫∫ÊéßÂà∂` `È´òÁ∫ßÊé®ÁêÜ` `‰ΩéÁ∫ßÊéßÂà∂` `ÂÆâÂÖ®ÊäÄËÉΩ` `Â§öÊ≠•È™§‰ªªÂä°`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLMÁõ¥Êé•Â∫îÁî®‰∫éÊó†‰∫∫Êú∫Êìç‰ΩúÊó∂ÔºåÂ≠òÂú®Âä®‰Ωú‰∏ç‰∏ÄËá¥„ÄÅÊòì‰∫ßÁîüÂπªËßâ‰ª•ÂèäÂä®ÊÄÅÂèØË°åÊÄßÂ∑ÆÁ≠âÈóÆÈ¢òÔºåÂØºËá¥‰∏çÂÆâÂÖ®Âíå‰∏çÂèØÈù†„ÄÇ
2. AERMANI-VLMÈÄöËøáÁªìÊûÑÂåñÊèêÁ§∫ÂºïÂØºVLMÁîüÊàêÊé®ÁêÜËΩ®ËøπÔºåÂπ∂‰ªé‰∏≠ÈÄâÊã©È¢ÑÂÆö‰πâÁöÑÈ£ûË°åÂÆâÂÖ®ÊäÄËÉΩÔºåÂÆûÁé∞È´òÁ∫ßÊé®ÁêÜ‰∏é‰ΩéÁ∫ßÊéßÂà∂ÂàÜÁ¶ª„ÄÇ
3. ËØ•Ê°ÜÊû∂Âú®Ê®°ÊãüÂíåÁ°¨‰ª∂ÂÆûÈ™å‰∏≠ÔºåÂØπÊú™ËßÅËøáÁöÑÂëΩ‰ª§„ÄÅÂØπË±°ÂíåÁéØÂ¢ÉË°®Áé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÔºåÈ™åËØÅ‰∫ÜÂÖ∂Âú®Â§öÊ≠•È™§ÊãæÂèñÂíåÊîæÁΩÆ‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâÁöÑÂø´ÈÄüÂèëÂ±ïÊøÄÂèë‰∫Ü‰∫∫‰ª¨ÂØπÊú∫Âô®‰∫∫ÊéßÂà∂ÁöÑÂÖ¥Ë∂£ÔºåÂÖ∂‰∏≠Ëá™ÁÑ∂ËØ≠Ë®ÄÂèØ‰ª•Ë°®ËææÊìç‰ΩúÁõÆÊ†áÔºåËÄåËßÜËßâÂèçÈ¶àÂ∞ÜÊÑüÁü•‰∏éÂä®‰ΩúËÅîÁ≥ªËµ∑Êù•„ÄÇÁÑ∂ËÄåÔºåÁõ¥Êé•Âú®Êó†‰∫∫Êú∫Êìç‰ΩúÂô®‰∏äÈÉ®ÁΩ≤VLMÈ©±Âä®ÁöÑÁ≠ñÁï•‰ªçÁÑ∂‰∏çÂÆâÂÖ®‰∏î‰∏çÂèØÈù†ÔºåÂõ†‰∏∫ÁîüÊàêÁöÑÂä®‰ΩúÈÄöÂ∏∏‰∏ç‰∏ÄËá¥ÔºåÂÆπÊòì‰∫ßÁîüÂπªËßâÔºåÂπ∂‰∏îÂú®Âä®ÊÄÅ‰∏äÂØπ‰∫éÈ£ûË°åÊòØ‰∏çÂèØË°åÁöÑ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜAERMANI-VLMÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™ÈÄöËøáÂ∞ÜÈ´òÁ∫ßÊé®ÁêÜ‰∏é‰ΩéÁ∫ßÊéßÂà∂ÂàÜÁ¶ªÊù•Ë∞ÉÊï¥È¢ÑËÆ≠ÁªÉVLM‰ª•ËøõË°åÊó†‰∫∫Êú∫Êìç‰ΩúÁöÑÊ°ÜÊû∂ÔºåÊó†ÈúÄ‰ªª‰ΩïÁâπÂÆö‰∫é‰ªªÂä°ÁöÑÂæÆË∞É„ÄÇÊàë‰ª¨ÁöÑÊ°ÜÊû∂Â∞ÜËá™ÁÑ∂ËØ≠Ë®ÄÊåá‰ª§„ÄÅ‰ªªÂä°‰∏ä‰∏ãÊñáÂíåÂÆâÂÖ®Á∫¶ÊùüÁºñÁ†Å‰∏∫ÁªìÊûÑÂåñÊèêÁ§∫ÔºåÂºïÂØºÊ®°ÂûãÁîüÊàêËá™ÁÑ∂ËØ≠Ë®ÄÁöÑÈÄêÊ≠•Êé®ÁêÜËΩ®Ëøπ„ÄÇÊ≠§Êé®ÁêÜËæìÂá∫Áî®‰∫é‰ªéÈ¢ÑÂÆö‰πâÁöÑÁ¶ªÊï£„ÄÅÈ£ûË°åÂÆâÂÖ®ÊäÄËÉΩÂ∫ì‰∏≠ËøõË°åÈÄâÊã©Ôºå‰ªéËÄåÁ°Æ‰øùÂèØËß£Èáä‰∏îÊó∂Èó¥‰∏ä‰∏ÄËá¥ÁöÑÊâßË°å„ÄÇÈÄöËøáÂ∞ÜÁ¨¶Âè∑Êé®ÁêÜ‰∏éÁâ©ÁêÜÂä®‰ΩúÂàÜÁ¶ªÔºåAERMANI-VLMÂáèËΩª‰∫ÜÂπªËßâÂëΩ‰ª§Âπ∂Èò≤Ê≠¢‰∫Ü‰∏çÂÆâÂÖ®Ë°å‰∏∫Ôºå‰ªéËÄåÂÆûÁé∞‰∫ÜÁ®≥ÂÅ•ÁöÑ‰ªªÂä°ÂÆåÊàê„ÄÇÊàë‰ª¨Âú®Ê®°ÊãüÂíåÁ°¨‰ª∂‰∏≠È™åËØÅ‰∫ÜËØ•Ê°ÜÊû∂Âú®ÂêÑÁßçÂ§öÊ≠•È™§ÊãæÂèñÂíåÊîæÁΩÆ‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÂ±ïÁ§∫‰∫ÜÂØπÂÖàÂâçÊú™ËßÅËøáÁöÑÂëΩ‰ª§„ÄÅÂØπË±°ÂíåÁéØÂ¢ÉÁöÑÂº∫Â§ßÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â∞ÜËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâÁõ¥Êé•Â∫îÁî®‰∫éÊó†‰∫∫Êú∫Êìç‰ΩúÊó∂Â≠òÂú®ÁöÑÂÆâÂÖ®ÊÄß‰∏éÂèØÈù†ÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÁîüÊàêÁöÑÂä®‰ΩúÂ∏∏Â∏∏‰∏ç‰∏ÄËá¥ÔºåÂÆπÊòì‰∫ßÁîüÂπªËßâÔºåÂπ∂‰∏îÂú®Âä®ÊÄÅ‰∏äÂØπ‰∫éÊó†‰∫∫Êú∫È£ûË°åÊòØ‰∏çÂèØË°åÁöÑÔºåÂØºËá¥‰ªªÂä°ÊâßË°åÂ§±Ë¥•ÁîöËá≥ÂÆâÂÖ®‰∫ãÊïÖ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÈ´òÁ∫ßÊé®ÁêÜ‰∏é‰ΩéÁ∫ßÊéßÂà∂Ëß£ËÄ¶„ÄÇÈÄöËøáÁªìÊûÑÂåñÁöÑÊèêÁ§∫ÔºàPromptingÔºâÂºïÂØºVLMËøõË°åÁ¨¶Âè∑Êé®ÁêÜÔºåÁîüÊàêÂèØËß£ÈáäÁöÑÊ≠•È™§Â∫èÂàóÔºåÁÑ∂ÂêéÂ∞ÜËøô‰∫õÊ≠•È™§Êò†Â∞ÑÂà∞È¢ÑÂÆö‰πâÁöÑ„ÄÅÈ£ûË°åÂÆâÂÖ®ÁöÑÁ¶ªÊï£ÊäÄËÉΩÂ∫ì‰∏≠ÁöÑÂä®‰Ωú„ÄÇËøôÊ†∑ÂèØ‰ª•ÈÅøÂÖçVLMÁõ¥Êé•ÁîüÊàê‰∏çÂèØÈù†ÁöÑÊéßÂà∂Êåá‰ª§Ôºå‰ªéËÄåÊèêÈ´òÁ≥ªÁªüÁöÑÂÆâÂÖ®ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAERMANI-VLMÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) **ÁªìÊûÑÂåñÊèêÁ§∫Ê®°Âùó**ÔºöÂ∞ÜËá™ÁÑ∂ËØ≠Ë®ÄÊåá‰ª§„ÄÅ‰ªªÂä°‰∏ä‰∏ãÊñáÂíåÂÆâÂÖ®Á∫¶ÊùüÁºñÁ†Å‰∏∫ÁªìÊûÑÂåñÊèêÁ§∫„ÄÇ2) **VLMÊé®ÁêÜÊ®°Âùó**ÔºöÂà©Áî®VLMÂØπÁªìÊûÑÂåñÊèêÁ§∫ËøõË°åÊé®ÁêÜÔºåÁîüÊàêËá™ÁÑ∂ËØ≠Ë®ÄÁöÑÊ≠•È™§Â∫èÂàó„ÄÇ3) **ÊäÄËÉΩÈÄâÊã©Ê®°Âùó**ÔºöÂ∞ÜÊé®ÁêÜÂá∫ÁöÑÊ≠•È™§Â∫èÂàóÊò†Â∞ÑÂà∞È¢ÑÂÆö‰πâÁöÑÁ¶ªÊï£ÊäÄËÉΩÂ∫ì‰∏≠ÁöÑÂä®‰Ωú„ÄÇ4) **‰ΩéÁ∫ßÊéßÂà∂Ê®°Âùó**ÔºöÊâßË°åÈÄâÂÆöÁöÑÂä®‰ΩúÔºåÂÆåÊàê‰ªªÂä°„ÄÇÊï¥‰∏™ÊµÅÁ®ãÂÆûÁé∞‰∫Ü‰ªéËá™ÁÑ∂ËØ≠Ë®ÄÊåá‰ª§Âà∞ÂÆâÂÖ®ÂèØÈù†ÁöÑÊó†‰∫∫Êú∫Êìç‰ΩúÁöÑËΩ¨Êç¢„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫ÜÂ∞ÜVLMÂ∫îÁî®‰∫éÊó†‰∫∫Êú∫Êìç‰ΩúÁöÑÁªìÊûÑÂåñÊèêÁ§∫ÊñπÊ≥ïÔºåÊúâÊïàÂºïÂØºVLMËøõË°åÊé®ÁêÜ„ÄÇ2) Â∞ÜÈ´òÁ∫ßÊé®ÁêÜ‰∏é‰ΩéÁ∫ßÊéßÂà∂Ëß£ËÄ¶ÔºåÈÅøÂÖç‰∫ÜVLMÁõ¥Êé•ÁîüÊàê‰∏çÂèØÈù†ÁöÑÊéßÂà∂Êåá‰ª§„ÄÇ3) ‰ΩøÁî®È¢ÑÂÆö‰πâÁöÑÈ£ûË°åÂÆâÂÖ®ÊäÄËÉΩÂ∫ìÔºå‰øùËØÅ‰∫ÜÊó†‰∫∫Êú∫Êìç‰ΩúÁöÑÂÆâÂÖ®ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÁªìÊûÑÂåñÊèêÁ§∫ÁöÑËÆæËÆ°ÊòØÂÖ≥ÈîÆ„ÄÇÊèêÁ§∫‰∏≠ÂåÖÂê´‰∫ÜËá™ÁÑ∂ËØ≠Ë®ÄÊåá‰ª§„ÄÅ‰ªªÂä°‰∏ä‰∏ãÊñáÔºà‰æãÂ¶ÇÔºåÂΩìÂâçÂú∫ÊôØÁöÑËßÜËßâ‰ø°ÊÅØÔºâÂíåÂÆâÂÖ®Á∫¶ÊùüÔºà‰æãÂ¶ÇÔºåÈÅøÂÖçÁ¢∞ÊíûÔºâ„ÄÇVLMÈááÁî®È¢ÑËÆ≠ÁªÉÁöÑÈÄöÁî®VLMÔºåÊó†ÈúÄÈíàÂØπÁâπÂÆö‰ªªÂä°ËøõË°åÂæÆË∞É„ÄÇÊäÄËÉΩÂ∫ì‰∏≠ÁöÑÊØè‰∏™ÊäÄËÉΩÈÉΩÁªèËøáÁ≤æÂøÉËÆæËÆ°Ôºå‰ª•Á°Æ‰øùÈ£ûË°åÂÆâÂÖ®Âíå‰ªªÂä°ÁöÑÊúâÊïàÊâßË°å„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËØ•Á†îÁ©∂Âú®Ê®°ÊãüÂíåÁ°¨‰ª∂ÂÆûÈ™å‰∏≠È™åËØÅ‰∫ÜAERMANI-VLMÁöÑÊúâÊïàÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Ê°ÜÊû∂ËÉΩÂ§üÊàêÂäüÂÆåÊàêÂêÑÁßçÂ§öÊ≠•È™§ÊãæÂèñÂíåÊîæÁΩÆ‰ªªÂä°ÔºåÂπ∂‰∏îÂØπÂÖàÂâçÊú™ËßÅËøáÁöÑÂëΩ‰ª§„ÄÅÂØπË±°ÂíåÁéØÂ¢ÉÂÖ∑ÊúâÂº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ‰∏éÁõ¥Êé•‰ΩøÁî®VLMÊéßÂà∂Êó†‰∫∫Êú∫ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåAERMANI-VLMÊòæËëóÊèêÈ´ò‰∫Ü‰ªªÂä°ÂÆåÊàêÁöÑÊàêÂäüÁéáÂíåÂÆâÂÖ®ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

AERMANI-VLMÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÂú®Áâ©ÊµÅÈÖçÈÄÅ„ÄÅÁÅæÂÆ≥ÊïëÊè¥„ÄÅÂü∫Á°ÄËÆæÊñΩÂ∑°Ê£ÄÁ≠âÈ¢ÜÂüüÔºåÂèØ‰ª•ÈÄöËøáËá™ÁÑ∂ËØ≠Ë®ÄÊåá‰ª§ÊéßÂà∂Êó†‰∫∫Êú∫ÂÆåÊàêÂ§çÊùÇÁöÑ‰ªªÂä°„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÊé®Âä®Êó†‰∫∫Êú∫Êô∫ËÉΩÂåñÂèëÂ±ïÔºåÊèêÈ´òÊó†‰∫∫Êú∫Êìç‰ΩúÁöÑÊïàÁéáÂíåÂÆâÂÖ®ÊÄßÔºåÂπ∂Èôç‰ΩéÊìç‰ΩúÈöæÂ∫¶Ôºå‰ΩøÂæóÈùû‰∏ì‰∏ö‰∫∫Âëò‰πüËÉΩËΩªÊùæÊìçÊéßÊó†‰∫∫Êú∫„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The rapid progress of vision--language models (VLMs) has sparked growing interest in robotic control, where natural language can express the operation goals while visual feedback links perception to action. However, directly deploying VLM-driven policies on aerial manipulators remains unsafe and unreliable since the generated actions are often inconsistent, hallucination-prone, and dynamically infeasible for flight. In this work, we present AERMANI-VLM, the first framework to adapt pretrained VLMs for aerial manipulation by separating high-level reasoning from low-level control, without any task-specific fine-tuning. Our framework encodes natural language instructions, task context, and safety constraints into a structured prompt that guides the model to generate a step-by-step reasoning trace in natural language. This reasoning output is used to select from a predefined library of discrete, flight-safe skills, ensuring interpretable and temporally consistent execution. By decoupling symbolic reasoning from physical action, AERMANI-VLM mitigates hallucinated commands and prevents unsafe behavior, enabling robust task completion. We validate the framework in both simulation and hardware on diverse multi-step pick-and-place tasks, demonstrating strong generalization to previously unseen commands, objects, and environments.

