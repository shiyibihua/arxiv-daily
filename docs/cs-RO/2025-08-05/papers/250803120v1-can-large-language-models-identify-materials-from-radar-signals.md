---
layout: default
title: Can Large Language Models Identify Materials from Radar Signals?
---

# Can Large Language Models Identify Materials from Radar Signals?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03120" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03120v1</a>
  <a href="https://arxiv.org/pdf/2508.03120.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03120v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03120v1', 'Can Large Language Models Identify Materials from Radar Signals?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiangyou Zhu, Hongyu Deng, He Chen

**åˆ†ç±»**: eess.SP, cs.ET, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

**DOI**: [10.1145/3714394.3756289](https://doi.org/10.1145/3714394.3756289)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLLMaterialä»¥è§£å†³é›·è¾¾ä¿¡å·ææ–™è¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é›·è¾¾ä¿¡å·` `ææ–™è¯†åˆ«` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç‰©ç†ä¿¡æ¯é©±åŠ¨` `æ·±åº¦å­¦ä¹ ` `å¼€æ”¾é›†è¯†åˆ«` `æ£€ç´¢å¢å¼ºç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é›·è¾¾æŠ€æœ¯åœ¨ææ–™è¯†åˆ«ä¸­é€šå¸¸å±€é™äºå°é—­é›†å¯¹è±¡ç±»åˆ«ï¼Œä¸”éœ€ç‰¹å®šæ•°æ®æ”¶é›†ï¼Œé™åˆ¶äº†åº”ç”¨èŒƒå›´ã€‚
2. æå‡ºLLMaterialï¼Œé€šè¿‡ç‰©ç†ä¿¡æ¯é©±åŠ¨çš„ä¿¡å·å¤„ç†ç®¡é“å’ŒRAGç­–ç•¥ï¼Œç›´æ¥ä»é›·è¾¾ä¿¡å·ä¸­è¯†åˆ«ææ–™ã€‚
3. åˆæ­¥å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMaterialèƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†å¤šç§ææ–™ï¼Œå±•ç°å‡ºåœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‡†ç¡®è¯†åˆ«ç‰©ä½“çš„ææ–™æˆåˆ†æ˜¯AIæœºå™¨äººè¿›è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥æ“ä½œçš„å…³é”®èƒ½åŠ›ã€‚é›·è¾¾æŠ€æœ¯ä¸ºææ–™è¯†åˆ«ä»»åŠ¡æä¾›äº†æœ‰å‰æ™¯çš„ä¼ æ„Ÿæ–¹å¼ã€‚ç°æœ‰çš„é›·è¾¾è§£å†³æ–¹æ¡ˆé€šå¸¸å±€é™äºå°é—­é›†å¯¹è±¡ç±»åˆ«ï¼Œå¹¶ä¸”éœ€è¦ç‰¹å®šä»»åŠ¡çš„æ•°æ®æ”¶é›†æ¥è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚æœ¬æ–‡æå‡ºLLMaterialï¼Œé¦–æ¬¡æ¢è®¨åˆ©ç”¨é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç›´æ¥ä»åŸå§‹é›·è¾¾ä¿¡å·ä¸­æ¨æ–­ææ–™æˆåˆ†ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç‰©ç†ä¿¡æ¯é©±åŠ¨çš„ä¿¡å·å¤„ç†ç®¡é“ï¼Œå°†é«˜å†—ä½™çš„é›·è¾¾åŸå§‹æ•°æ®æç‚¼ä¸ºä¸€ç»„ç´§å‡‘çš„ä¸­é—´å‚æ•°ï¼Œå¹¶é‡‡ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç­–ç•¥ä¸ºLLMæä¾›é¢†åŸŸç‰¹å®šçŸ¥è¯†ï¼Œä½¿å…¶èƒ½å¤Ÿå¯¹æå–çš„ä¸­é—´å‚æ•°è¿›è¡Œè§£é‡Šå’Œæ¨ç†ã€‚åˆæ­¥ç»“æœè¡¨æ˜ï¼ŒLLMaterialèƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†å¤šç§å¸¸è§ææ–™ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å®é™…ææ–™è¯†åˆ«åº”ç”¨ä¸­çš„å¼ºå¤§æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•ä»åŸå§‹é›·è¾¾ä¿¡å·ä¸­ç›´æ¥è¯†åˆ«ææ–™æˆåˆ†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºç‰¹å®šçš„ä»»åŠ¡æ•°æ®é›†ï¼Œé™åˆ¶äº†å…¶åœ¨å¼€æ”¾åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„LLMç»“åˆç‰©ç†ä¿¡æ¯é©±åŠ¨çš„ä¿¡å·å¤„ç†ï¼Œæå–é›·è¾¾ä¿¡å·ä¸­çš„ææ–™ç‰¹å¾ï¼Œä»è€Œå®ç°å¼€æ”¾é›†ææ–™è¯†åˆ«ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯ç‰©ç†ä¿¡æ¯é©±åŠ¨çš„ä¿¡å·å¤„ç†ç®¡é“ï¼Œå°†é«˜å†—ä½™çš„é›·è¾¾æ•°æ®è½¬åŒ–ä¸ºç´§å‡‘çš„ä¸­é—´å‚æ•°ï¼›å…¶æ¬¡æ˜¯RAGç­–ç•¥ï¼Œä¸ºLLMæä¾›é¢†åŸŸçŸ¥è¯†ï¼Œä½¿å…¶èƒ½å¤Ÿå¯¹ä¸­é—´å‚æ•°è¿›è¡Œæ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé¦–æ¬¡å°†LLMåº”ç”¨äºé›·è¾¾ä¿¡å·çš„ææ–™è¯†åˆ«ï¼Œçªç ´äº†ä¼ ç»Ÿæ–¹æ³•å¯¹ç‰¹å®šæ•°æ®é›†çš„ä¾èµ–ï¼Œå®ç°äº†å¼€æ”¾é›†è¯†åˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ä¿¡å·å¤„ç†é˜¶æ®µï¼Œè®¾è®¡äº†é«˜æ•ˆçš„å‚æ•°æå–ç®—æ³•ï¼Œç¡®ä¿ä¸­é—´å‚æ•°èƒ½å¤Ÿå……åˆ†åæ˜ ææ–™ç‰¹æ€§ï¼›åœ¨LLMçš„è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†æ£€ç´¢å¢å¼ºç”Ÿæˆç­–ç•¥ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹é¢†åŸŸçŸ¥è¯†çš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMaterialåœ¨å¤šç§å¸¸è§ææ–™çš„è¯†åˆ«ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†ä¸åŒææ–™ï¼Œåˆæ­¥æµ‹è¯•ä¸­è¯†åˆ«å‡†ç¡®ç‡è¶…è¿‡80%ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå±•ç°å‡ºå¼ºå¤§çš„å®é™…åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æœºå™¨äººã€è‡ªåŠ¨åŒ–åˆ¶é€ ã€æ— äººé©¾é©¶ç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œææ–™è¯†åˆ«å’Œæ“ä½œï¼Œæå‡å…¶è‡ªä¸»å†³ç­–èƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨å·¥ä¸šæ£€æµ‹ã€ç¯å¢ƒç›‘æµ‹ç­‰å¤šä¸ªé¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurately identifying the material composition of objects is a critical capability for AI robots powered by large language models (LLMs) to perform context-aware manipulation. Radar technologies offer a promising sensing modality for material recognition task. When combined with deep learning, radar technologies have demonstrated strong potential in identifying the material of various objects. However, existing radar-based solutions are often constrained to closed-set object categories and typically require task-specific data collection to train deep learning models, largely limiting their practical applicability. This raises an important question: Can we leverage the powerful reasoning capabilities of pre-trained LLMs to directly infer material composition from raw radar signals? Answering this question is non-trivial due to the inherent redundancy of radar signals and the fact that pre-trained LLMs have no prior exposure to raw radar data during training. To address this, we introduce LLMaterial, the first study to investigate the feasibility of using LLM to identify materials directly from radar signals. First, we introduce a physics-informed signal processing pipeline that distills high-redundancy radar raw data into a set of compact intermediate parameters that encapsulate the material's intrinsic characteristics. Second, we adopt a retrieval-augmented generation (RAG) strategy to provide the LLM with domain-specific knowledge, enabling it to interpret and reason over the extracted intermediate parameters. Leveraging this integration, the LLM is empowered to perform step-by-step reasoning on the condensed radar features, achieving open-set material recognition directly from raw radar signals. Preliminary results show that LLMaterial can effectively distinguish among a variety of common materials, highlighting its strong potential for real-world material identification applications.

