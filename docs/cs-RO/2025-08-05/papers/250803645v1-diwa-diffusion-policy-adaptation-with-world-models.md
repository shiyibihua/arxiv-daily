---
layout: default
title: DiWA: Diffusion Policy Adaptation with World Models
---

# DiWA: Diffusion Policy Adaptation with World Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03645" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.03645v1</a>
  <a href="https://arxiv.org/pdf/2508.03645.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03645v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03645v1', 'DiWA: Diffusion Policy Adaptation with World Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Akshay L Chandra, Iman Nematollahi, Chenguang Huang, Tim Welschehold, Wolfram Burgard, Abhinav Valada

**ÂàÜÁ±ª**: cs.RO, cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-05

**Â§áÊ≥®**: Accepted at the 2025 Conference on Robot Learning (CoRL)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫DiWAÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥Á¶ªÁ∫øÂº∫ÂåñÂ≠¶‰π†‰∏≠ÁöÑÊ†∑Êú¨ÊïàÁéáÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Êâ©Êï£Á≠ñÁï•` `Âº∫ÂåñÂ≠¶‰π†` `‰∏ñÁïåÊ®°Âûã` `Á¶ªÁ∫øÂ≠¶‰π†` `Ê†∑Êú¨ÊïàÁéá` `Êú∫Âô®‰∫∫ÊäÄËÉΩ` `CALVINÂü∫ÂáÜÊµãËØï`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ÂæÆË∞ÉÊâ©Êï£Á≠ñÁï•Êó∂Èù¢‰∏¥ÈïøÂéªÂô™Â∫èÂàóÂíåÂ§ßÈáèÁéØÂ¢É‰∫§‰∫íÁöÑÊåëÊàòÔºåÂØºËá¥Ê†∑Êú¨ÊïàÁéá‰Ωé‰∏ã„ÄÇ
2. DiWAÊ°ÜÊû∂ÈÄöËøáÂà©Áî®‰∏ñÁïåÊ®°ÂûãÂÆûÁé∞Á¶ªÁ∫øÂæÆË∞ÉÔºåÂáèÂ∞ëÂØπÁúüÂÆûÁéØÂ¢É‰∫§‰∫íÁöÑ‰æùËµñÔºåÊèêÂçáÊ†∑Êú¨ÊïàÁéá„ÄÇ
3. Âú®CALVINÂü∫ÂáÜÊµãËØï‰∏≠ÔºåDiWAÂú®ÂÖ´‰∏™‰ªªÂä°‰∏äË°®Áé∞‰ºòÂºÇÔºåÊòæËëóÂáèÂ∞ë‰∫ÜÁâ©ÁêÜ‰∫§‰∫íÈúÄÊ±ÇÔºåÊèêÂçá‰∫ÜÂ≠¶‰π†ÊïàÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂæÆË∞ÉÊâ©Êï£Á≠ñÁï•‰∏éÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÁªìÂêàÈù¢‰∏¥ÈáçÂ§ßÊåëÊàòÔºåÈïøÊó∂Èó¥ÂéªÂô™Â∫èÂàóÂΩ±ÂìçÊúâÊïàÂ•ñÂä±‰º†Êí≠Ôºå‰∏îÊ†áÂáÜRLÊñπÊ≥ïÈúÄÊï∞Áôæ‰∏áÊ¨°ÁúüÂÆûÁéØÂ¢É‰∫§‰∫íÔºåÊàê‰∏∫ÂÆûÈôÖÂæÆË∞ÉÁöÑÁì∂È¢à„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫DiWAÊ°ÜÊû∂ÔºåÂà©Áî®‰∏ñÁïåÊ®°ÂûãÂú®Á¶ªÁ∫øÁéØÂ¢É‰∏≠ÂÆåÂÖ®ÂæÆË∞ÉÂü∫‰∫éÊâ©Êï£ÁöÑÊú∫Âô®‰∫∫ÊäÄËÉΩ„ÄÇ‰∏éÈúÄË¶ÅÂ§ßÈáèÁéØÂ¢É‰∫§‰∫íÁöÑÊó†Ê®°ÂûãÊñπÊ≥ï‰∏çÂêåÔºåDiWAÈÄöËøáÂú®Êï∞ÂçÅ‰∏áÊ¨°Á¶ªÁ∫ø‰∫§‰∫í‰∏äËÆ≠ÁªÉÁöÑ‰∏ñÁïåÊ®°ÂûãÔºåÂÆûÁé∞‰∫ÜÈ´òÊïàÁöÑÈÄÇÂ∫îÊÄßÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊ†∑Êú¨ÊïàÁéáÔºå‰ΩøÂæóÂÆûÈôÖÊú∫Âô®‰∫∫Â≠¶‰π†Êõ¥Âä†ÂÆâÂÖ®ÂíåÂèØË°å„ÄÇÂú®CALVINÂü∫ÂáÜÊµãËØï‰∏≠ÔºåDiWAÂú®ÂÖ´‰∏™‰ªªÂä°‰∏äË°®Áé∞Âá∫Ëâ≤Ôºå‰ªÖÈúÄÁ¶ªÁ∫øÈÄÇÂ∫îÔºå‰∏îÁâ©ÁêÜ‰∫§‰∫íÊ¨°Êï∞Ëøú‰Ωé‰∫éÊó†Ê®°ÂûãÂü∫Á∫ø„ÄÇËá≥‰ªä‰∏∫Ê≠¢ÔºåËøôÊòØÈ¶ñÊ¨°Â±ïÁ§∫‰ΩøÁî®Á¶ªÁ∫ø‰∏ñÁïåÊ®°ÂûãÂæÆË∞ÉÊâ©Êï£Á≠ñÁï•‰ª•ÂÆûÁé∞ÁúüÂÆû‰∏ñÁïåÊú∫Âô®‰∫∫ÊäÄËÉΩÁöÑÁ†îÁ©∂„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÂæÆË∞ÉÊâ©Êï£Á≠ñÁï•Êó∂ÁöÑÊ†∑Êú¨ÊïàÁéá‰Ωé‰∏ãÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ï‰æùËµñÂ§ßÈáèÁúüÂÆûÁéØÂ¢É‰∫§‰∫íÔºåÂØºËá¥ÊïàÁéá‰Ωé‰∏ãÂíåÂÆâÂÖ®ÈöêÊÇ£„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöDiWAÊ°ÜÊû∂ÈÄöËøáÊûÑÂª∫‰∏Ä‰∏™Á¶ªÁ∫ø‰∏ñÁïåÊ®°ÂûãÔºåÂà©Áî®ËØ•Ê®°ÂûãËøõË°åÂº∫ÂåñÂ≠¶‰π†ÂæÆË∞ÉÔºåÈÅøÂÖç‰∫ÜÂØπÁúüÂÆûÁéØÂ¢ÉÁöÑÈ¢ëÁπÅ‰∫§‰∫íÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊ†∑Êú¨ÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöDiWAÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈ¶ñÂÖàÊòØ‰∏ñÁïåÊ®°ÂûãÁöÑËÆ≠ÁªÉÔºåÂü∫‰∫éÊï∞ÂçÅ‰∏áÊ¨°Á¶ªÁ∫ø‰∫§‰∫íÔºõÂÖ∂Ê¨°ÊòØÂà©Áî®ËØ•Ê®°ÂûãËøõË°åÁ≠ñÁï•ÂæÆË∞ÉÔºõÊúÄÂêéÊòØËØÑ‰º∞ÂæÆË∞ÉÂêéÁöÑÁ≠ñÁï•Âú®ÁúüÂÆûÁéØÂ¢É‰∏≠ÁöÑË°®Áé∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöDiWAÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÈ¶ñÊ¨°Â∞ÜÁ¶ªÁ∫ø‰∏ñÁïåÊ®°ÂûãÂ∫îÁî®‰∫éÊâ©Êï£Á≠ñÁï•ÁöÑÂæÆË∞ÉÔºåÊòæËëóÂáèÂ∞ë‰∫ÜÂØπÁúüÂÆûÁéØÂ¢É‰∫§‰∫íÁöÑÈúÄÊ±ÇÔºå‰∏é‰º†ÁªüÁöÑÊó†Ê®°ÂûãÊñπÊ≥ïÂΩ¢ÊàêÈ≤úÊòéÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåDiWAÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞Êù•‰ºòÂåñÁ≠ñÁï•ÔºåÂêåÊó∂Á°Æ‰øù‰∏ñÁïåÊ®°ÂûãÁöÑÂáÜÁ°ÆÊÄßÔºåÁΩëÁªúÁªìÊûÑÂàôÂü∫‰∫éÁé∞ÊúâÁöÑÊ∑±Â∫¶Â≠¶‰π†Ê°ÜÊû∂ËøõË°å‰ºòÂåñÔºå‰ª•ÈÄÇÂ∫îÁ¶ªÁ∫øÂ≠¶‰π†ÁöÑÈúÄÊ±Ç„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®CALVINÂü∫ÂáÜÊµãËØï‰∏≠ÔºåDiWAÂú®ÂÖ´‰∏™‰ªªÂä°‰∏äÂÆûÁé∞‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÁâ©ÁêÜ‰∫§‰∫íÊ¨°Êï∞ÊØîÊó†Ê®°ÂûãÂü∫Á∫øÂáèÂ∞ë‰∫ÜÂá†‰∏™Êï∞ÈáèÁ∫ßÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®Á¶ªÁ∫øÈÄÇÂ∫î‰∏≠ÁöÑÈ´òÊïàÊÄßÂíåÂÆûÁî®ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

DiWAÊ°ÜÊû∂Âú®Êú∫Âô®‰∫∫Â≠¶‰π†È¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÈ´òÊïàÂ≠¶‰π†ÂíåÈÄÇÂ∫îÁöÑÂú∫ÊôØÔºåÂ¶ÇËá™‰∏ªÂØºËà™„ÄÅÊú∫Âô®‰∫∫ÊìçÊéßÁ≠â„ÄÇÈÄöËøáÂáèÂ∞ëÂØπÁúüÂÆûÁéØÂ¢ÉÁöÑ‰æùËµñÔºåDiWAÂèØ‰ª•Âä†ÈÄüÊú∫Âô®‰∫∫ÊäÄËÉΩÁöÑÂºÄÂèëÂíåÈÉ®ÁΩ≤ÔºåÊèêÈ´òÂÆâÂÖ®ÊÄßÂíåÂèØÈù†ÊÄßÔºåÊú™Êù•ÂèØËÉΩÂú®Êô∫ËÉΩÂà∂ÈÄ†„ÄÅÊúçÂä°Êú∫Âô®‰∫∫Á≠âÈ¢ÜÂüü‰∫ßÁîüÊ∑±ËøúÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Fine-tuning diffusion policies with reinforcement learning (RL) presents significant challenges. The long denoising sequence for each action prediction impedes effective reward propagation. Moreover, standard RL methods require millions of real-world interactions, posing a major bottleneck for practical fine-tuning. Although prior work frames the denoising process in diffusion policies as a Markov Decision Process to enable RL-based updates, its strong dependence on environment interaction remains highly inefficient. To bridge this gap, we introduce DiWA, a novel framework that leverages a world model for fine-tuning diffusion-based robotic skills entirely offline with reinforcement learning. Unlike model-free approaches that require millions of environment interactions to fine-tune a repertoire of robot skills, DiWA achieves effective adaptation using a world model trained once on a few hundred thousand offline play interactions. This results in dramatically improved sample efficiency, making the approach significantly more practical and safer for real-world robot learning. On the challenging CALVIN benchmark, DiWA improves performance across eight tasks using only offline adaptation, while requiring orders of magnitude fewer physical interactions than model-free baselines. To our knowledge, this is the first demonstration of fine-tuning diffusion policies for real-world robotic skills using an offline world model. We make the code publicly available at https://diwa.cs.uni-freiburg.de.

