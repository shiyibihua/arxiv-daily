---
layout: default
title: Vision-based Perception System for Automated Delivery Robot-Pedestrians Interactions
---

# Vision-based Perception System for Automated Delivery Robot-Pedestrians Interactions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03541" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03541v1</a>
  <a href="https://arxiv.org/pdf/2508.03541.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03541v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03541v1', 'Vision-based Perception System for Automated Delivery Robot-Pedestrians Interactions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ergi Tushe, Bilal Farooq

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

**æœŸåˆŠ**: In the proceedings of 11th IEEE International Smart Cities Conference (ISC2), Patras, Greece, October 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè§†è§‰çš„æ„ŸçŸ¥ç³»ç»Ÿä»¥è§£å†³è‡ªåŠ¨é€è´§æœºå™¨äººä¸è¡Œäººäº¤äº’é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è‡ªåŠ¨é€è´§æœºå™¨äºº` `è¡Œäººæ£€æµ‹` `å§¿æ€ä¼°è®¡` `æ·±åº¦æ„ŸçŸ¥` `å¤šç›®æ ‡è·Ÿè¸ª` `åŸå¸‚ç‰©æµ` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¡Œäººå¯†é›†ç¯å¢ƒä¸­ï¼Œé¢ä¸´å®‰å…¨å¯¼èˆªå’Œèº«ä»½ä¿æŒçš„æŒ‘æˆ˜ï¼Œå°¤å…¶åœ¨é®æŒ¡å’Œäººç¾¤å¯†é›†æƒ…å†µä¸‹ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå•ä¸ªè§†è§‰ä¼ æ„Ÿå™¨çš„å¤šè¡Œäººæ£€æµ‹ä¸è·Ÿè¸ªç³»ç»Ÿï¼Œç»“åˆå§¿æ€ä¼°è®¡å’Œæ·±åº¦ä¿¡æ¯ï¼Œæå‡è¡Œäººè½¨è¿¹é¢„æµ‹èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç³»ç»Ÿåœ¨èº«ä»½ä¿æŒå’Œå¤šç›®æ ‡è·Ÿè¸ªç²¾åº¦ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œæ£€æµ‹ç²¾åº¦åœ¨å¤æ‚åœºæ™¯ä¸­ä¹Ÿä¿æŒåœ¨85%ä»¥ä¸Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°†è‡ªåŠ¨é€è´§æœºå™¨äººï¼ˆADRï¼‰æ•´åˆåˆ°è¡Œäººå¯†é›†çš„åŸå¸‚ç©ºé—´ä¸­ï¼Œå¸¦æ¥äº†å®‰å…¨ã€é«˜æ•ˆå’Œç¤¾ä¼šå¯æ¥å—å¯¼èˆªçš„ç‹¬ç‰¹æŒ‘æˆ˜ã€‚æœ¬æ–‡å¼€å‘äº†ä¸€å¥—å®Œæ•´çš„ç®¡é“ï¼Œåˆ©ç”¨å•ä¸ªè§†è§‰ä¼ æ„Ÿå™¨è¿›è¡Œå¤šè¡Œäººæ£€æµ‹ä¸è·Ÿè¸ªã€å§¿æ€ä¼°è®¡å’Œå•ç›®æ·±åº¦æ„ŸçŸ¥ã€‚é€šè¿‡åˆ©ç”¨çœŸå®ä¸–ç•Œçš„MOT17æ•°æ®é›†ï¼Œç ”ç©¶å±•ç¤ºäº†äººç±»å§¿æ€ä¼°è®¡ä¸æ·±åº¦çº¿ç´¢çš„ç»“åˆå¦‚ä½•å¢å¼ºè¡Œäººè½¨è¿¹é¢„æµ‹å’Œèº«ä»½ç»´æŠ¤ï¼Œå³ä½¿åœ¨é®æŒ¡å’Œå¯†é›†äººç¾¤ä¸­ã€‚ç»“æœæ˜¾ç¤ºï¼Œèº«ä»½ä¿æŒï¼ˆIDF1ï¼‰æé«˜äº†10%ï¼Œå¤šç›®æ ‡è·Ÿè¸ªç²¾åº¦ï¼ˆMOTAï¼‰æå‡äº†7%ï¼Œåœ¨æŒ‘æˆ˜åœºæ™¯ä¸­æ£€æµ‹ç²¾åº¦å§‹ç»ˆè¶…è¿‡85%ã€‚è¯¥ç³»ç»Ÿè¿˜èƒ½å¤Ÿè¯†åˆ«è„†å¼±çš„è¡Œäººç¾¤ä½“ï¼Œæ”¯æŒæ›´å…·ç¤¾ä¼šæ„è¯†å’ŒåŒ…å®¹æ€§çš„æœºå™¨äººè¡Œä¸ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è‡ªåŠ¨é€è´§æœºå™¨äººåœ¨è¡Œäººå¯†é›†ç¯å¢ƒä¸­å®‰å…¨å¯¼èˆªå’Œèº«ä»½ä¿æŒçš„éš¾é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é®æŒ¡å’Œäººç¾¤å¯†é›†æƒ…å†µä¸‹è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´æœºå™¨äººæ— æ³•æœ‰æ•ˆè¯†åˆ«å’Œè·Ÿè¸ªè¡Œäººã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç»“åˆäººç±»å§¿æ€ä¼°è®¡å’Œæ·±åº¦ä¿¡æ¯ï¼Œæå‡è¡Œäººè½¨è¿¹é¢„æµ‹çš„å‡†ç¡®æ€§å’Œèº«ä»½ç»´æŠ¤èƒ½åŠ›ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹å¤æ‚çš„è¡Œäººäº¤äº’åœºæ™¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šè¡Œäººæ£€æµ‹ä¸è·Ÿè¸ªã€å§¿æ€ä¼°è®¡å’Œå•ç›®æ·±åº¦æ„ŸçŸ¥ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œåˆ©ç”¨è§†è§‰ä¼ æ„Ÿå™¨è¿›è¡Œè¡Œäººæ£€æµ‹ï¼Œç„¶åè¿›è¡Œå§¿æ€ä¼°è®¡ï¼Œæœ€åç»“åˆæ·±åº¦ä¿¡æ¯è¿›è¡Œè½¨è¿¹é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†äººç±»å§¿æ€ä¼°è®¡ä¸æ·±åº¦ä¿¡æ¯ç»“åˆï¼Œæ˜¾è‘—æå‡äº†åœ¨é®æŒ¡å’Œå¯†é›†äººç¾¤ä¸­çš„è¡Œäººèº«ä»½ä¿æŒèƒ½åŠ›ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„åŸºäºè§†è§‰çš„è·Ÿè¸ªæ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰æ›´é«˜çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é’ˆå¯¹å¤šç›®æ ‡è·Ÿè¸ªçš„ç‰¹å®šæŸå¤±å‡½æ•°ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§å¼ºçš„ç½‘ç»œç»“æ„ï¼Œä»¥æé«˜åœ¨å¤æ‚åœºæ™¯ä¸‹çš„æ£€æµ‹ç²¾åº¦å’Œè·Ÿè¸ªç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç³»ç»Ÿåœ¨èº«ä»½ä¿æŒï¼ˆIDF1ï¼‰ä¸Šæé«˜äº†10%ï¼Œå¤šç›®æ ‡è·Ÿè¸ªç²¾åº¦ï¼ˆMOTAï¼‰æå‡äº†7%ã€‚åœ¨å¤æ‚åœºæ™¯ä¸‹ï¼Œæ£€æµ‹ç²¾åº¦å§‹ç»ˆè¶…è¿‡85%ï¼Œè¡¨æ˜è¯¥ç³»ç»Ÿåœ¨è¡Œäººå¯†é›†ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŸå¸‚é…é€ã€æ™ºèƒ½äº¤é€šç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡è‡ªåŠ¨é€è´§æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ï¼Œå¯ä»¥æœ‰æ•ˆæé«˜åŸå¸‚ç‰©æµæ•ˆç‡ï¼Œå‡å°‘äº¤é€šäº‹æ•…é£é™©ï¼Œå¹¶ä¿ƒè¿›äººæœºåä½œçš„ç¤¾ä¼šæ¥å—åº¦ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨æ›´å¤šæ™ºèƒ½åŸå¸‚åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The integration of Automated Delivery Robots (ADRs) into pedestrian-heavy urban spaces introduces unique challenges in terms of safe, efficient, and socially acceptable navigation. We develop the complete pipeline for a single vision sensor based multi-pedestrian detection and tracking, pose estimation, and monocular depth perception. Leveraging the real-world MOT17 dataset sequences, this study demonstrates how integrating human-pose estimation and depth cues enhances pedestrian trajectory prediction and identity maintenance, even under occlusions and dense crowds. Results show measurable improvements, including up to a 10% increase in identity preservation (IDF1), a 7% improvement in multiobject tracking accuracy (MOTA), and consistently high detection precision exceeding 85%, even in challenging scenarios. Notably, the system identifies vulnerable pedestrian groups supporting more socially aware and inclusive robot behaviour.

