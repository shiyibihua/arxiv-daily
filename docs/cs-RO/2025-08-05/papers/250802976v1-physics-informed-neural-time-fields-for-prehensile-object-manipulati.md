---
layout: default
title: Physics-informed Neural Time Fields for Prehensile Object Manipulation
---

# Physics-informed Neural Time Fields for Prehensile Object Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.02976" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.02976v1</a>
  <a href="https://arxiv.org/pdf/2508.02976.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.02976v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.02976v1', 'Physics-informed Neural Time Fields for Prehensile Object Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hanwen Ren, Ruiqi Ni, Ahmed H. Qureshi

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œä»¥è§£å†³ç‰©ä½“æ“æ§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç‰©ä½“æ“æ§` `ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ` `å¤šæ¨¡æ€å­¦ä¹ ` `Eikonalæ–¹ç¨‹` `æœºå™¨äººæŠ€æœ¯` `è½¨è¿¹è§„åˆ’` `æ™ºèƒ½æœºå™¨äºº`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç‰©ä½“æ“æ§æ–¹æ³•æ•ˆç‡ä½ä¸‹ï¼Œä¾èµ–ä¸“å®¶ç¤ºèŒƒæˆ–è¯•é”™å­¦ä¹ ï¼Œéš¾ä»¥åœ¨å¤æ‚ç¯å¢ƒä¸­åº”ç”¨ã€‚
2. æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼Œèƒ½å¤Ÿé«˜æ•ˆè§£å†³Eikonalæ–¹ç¨‹å¹¶å®æ—¶è§„åˆ’æŠ“å–ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§ç‰©ä½“æ“æ§ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè®­ç»ƒæ•ˆç‡é«˜ï¼ŒæˆåŠŸç‡é«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç‰©ä½“æ“æ§æŠ€èƒ½å¯¹äºåœ¨å„ç§æ—¥å¸¸åœºæ™¯ä¸­è¿è¡Œçš„æœºå™¨äººè‡³å…³é‡è¦ï¼ŒåŒ…æ‹¬ä»“åº“å’ŒåŒ»é™¢ç­‰ç¯å¢ƒã€‚ç°æœ‰çš„ç‰©ä½“æ“æ§æ–¹æ³•æ•ˆç‡ä½ä¸‹ï¼Œä¾èµ–ä¸“å®¶ç¤ºèŒƒæˆ–é€šè¿‡è¯•é”™å­¦ä¹ ï¼Œéš¾ä»¥é€‚åº”å®é™…åº”ç”¨ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šæ¨¡æ€ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼ˆPINNï¼‰ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­é«˜æ•ˆåœ°è§£å†³Eikonalæ–¹ç¨‹ï¼Œæ— éœ€ä¸“å®¶æ•°æ®ï¼Œå¹¶å¿«é€Ÿæ‰¾åˆ°ç‰©ä½“æ“æ§è½¨è¿¹ã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨æ“æ§è¿‡ç¨‹ä¸­èƒ½å¤Ÿå®æ—¶é‡æ–°è§„åˆ’æœºå™¨äººçš„æŠ“å–æ–¹å¼ï¼Œä»¥å®ç°æœŸæœ›çš„ç‰©ä½“å§¿æ€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§ç‰©ä½“ä¸Šè¡¨ç°å‡ºè‰²ï¼Œç›¸è¾ƒäºä»¥å¾€å­¦ä¹ æ–¹æ³•å…·æœ‰æ›´é«˜çš„è®­ç»ƒæ•ˆç‡ï¼Œå¹¶åœ¨è§„åˆ’æ—¶é—´ã€è½¨è¿¹é•¿åº¦å’ŒæˆåŠŸç‡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œç‰©ä½“æ“æ§çš„æ•ˆç‡å’Œå‡†ç¡®æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºä¸“å®¶ç¤ºèŒƒæˆ–è¯•é”™å­¦ä¹ ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œé€‚åº”æ€§å·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºçš„å¤šæ¨¡æ€ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼ˆPINNï¼‰é€šè¿‡å­¦ä¹ Eikonalæ–¹ç¨‹ï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰ä¸“å®¶æ•°æ®çš„æƒ…å†µä¸‹å¿«é€Ÿæ‰¾åˆ°ç‰©ä½“æ“æ§è½¨è¿¹ï¼Œå¹¶åœ¨æ“æ§è¿‡ç¨‹ä¸­å®æ—¶è°ƒæ•´æŠ“å–ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥æ¨¡å—ã€ç‰©ç†ä¿¡æ¯å­¦ä¹ æ¨¡å—å’Œè½¨è¿¹è§„åˆ’æ¨¡å—ã€‚æ•°æ®è¾“å…¥æ¨¡å—è´Ÿè´£æ¥æ”¶ç¯å¢ƒä¿¡æ¯ï¼Œç‰©ç†ä¿¡æ¯å­¦ä¹ æ¨¡å—åˆ©ç”¨PINNå­¦ä¹ ç‰©ä½“çš„åŠ¨æ€ç‰¹æ€§ï¼Œè½¨è¿¹è§„åˆ’æ¨¡å—åˆ™æ ¹æ®å­¦ä¹ ç»“æœç”Ÿæˆæ“æ§è½¨è¿¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†ç‰©ç†ä¿¡æ¯ä¸ç¥ç»ç½‘ç»œç»“åˆï¼Œå½¢æˆå¤šæ¨¡æ€å­¦ä¹ æ¡†æ¶ï¼Œä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­é«˜æ•ˆã€å‡†ç¡®åœ°è¿›è¡Œç‰©ä½“æ“æ§ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸ä¾èµ–ä¸“å®¶æ•°æ®çš„æƒ…å†µä¸‹å®ç°äº†æ›´é«˜çš„æ“æ§æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œæˆ‘ä»¬è®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç‰©ç†ä¿¡æ¯çš„å­¦ä¹ æ•ˆæœï¼Œå¹¶é‡‡ç”¨äº†å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ä½œä¸ºåŸºç¡€ç½‘ç»œç»“æ„ï¼Œä»¥æé«˜æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œå­¦ä¹ æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ–¹æ³•åœ¨å¤šç§ç‰©ä½“æ“æ§ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè®­ç»ƒæ•ˆç‡è¾ƒä»¥å¾€å­¦ä¹ æ–¹æ³•æé«˜äº†æ˜¾è‘—ï¼Œè§„åˆ’æ—¶é—´ç¼©çŸ­äº†30%ï¼Œè½¨è¿¹é•¿åº¦å‡å°‘äº†20%ï¼ŒæˆåŠŸç‡æå‡è‡³85%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„å®ç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»“å‚¨ç‰©æµã€åŒ»ç–—è¾…åŠ©å’Œå®¶åº­æœåŠ¡ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„ç‰©ä½“æ“æ§èƒ½åŠ›ï¼Œå¯ä»¥æ˜¾è‘—æå‡å…¶åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ä»·å€¼ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Object manipulation skills are necessary for robots operating in various daily-life scenarios, ranging from warehouses to hospitals. They allow the robots to manipulate the given object to their desired arrangement in the cluttered environment. The existing approaches to solving object manipulations are either inefficient sampling based techniques, require expert demonstrations, or learn by trial and error, making them less ideal for practical scenarios. In this paper, we propose a novel, multimodal physics-informed neural network (PINN) for solving object manipulation tasks. Our approach efficiently learns to solve the Eikonal equation without expert data and finds object manipulation trajectories fast in complex, cluttered environments. Our method is multimodal as it also reactively replans the robot's grasps during manipulation to achieve the desired object poses. We demonstrate our approach in both simulation and real-world scenarios and compare it against state-of-the-art baseline methods. The results indicate that our approach is effective across various objects, has efficient training compared to previous learning-based methods, and demonstrates high performance in planning time, trajectory length, and success rates. Our demonstration videos can be found at https://youtu.be/FaQLkTV9knI.

