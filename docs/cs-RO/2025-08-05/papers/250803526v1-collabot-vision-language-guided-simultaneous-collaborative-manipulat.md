---
layout: default
title: CollaBot: Vision-Language Guided Simultaneous Collaborative Manipulation
---

# CollaBot: Vision-Language Guided Simultaneous Collaborative Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03526" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03526v1</a>
  <a href="https://arxiv.org/pdf/2508.03526.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03526v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03526v1', 'CollaBot: Vision-Language Guided Simultaneous Collaborative Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kun Song, Shentao Ma, Gaoming Chen, Ninglong Jin, Guangbao Zhao, Mingyu Ding, Zhenhua Xiong, Jia Pan

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

**å¤‡æ³¨**: 9 pages,5 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCollaBotä»¥è§£å†³å¤šæœºå™¨äººåä½œæ“æ§å¤§ç‰©ä½“é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å¤šæœºå™¨äººåä½œ` `å¤§å‹ç‰©ä½“æ“æ§` `åœºæ™¯åˆ†å‰²` `åä½œæŠ“å–` `è½¨è¿¹è§„åˆ’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å°ç‰©ä½“çš„æ“æ§ï¼Œç¼ºä¹é’ˆå¯¹å¤§å‹ç‰©ä½“çš„å¤šæœºå™¨äººåä½œæ¡†æ¶ï¼Œé™åˆ¶äº†å®é™…åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºCollaBotæ¡†æ¶ï¼Œé€šè¿‡SEEMè¿›è¡Œåœºæ™¯åˆ†å‰²ï¼Œç»“åˆå±€éƒ¨æŠ“å–å’Œå…¨å±€åä½œï¼Œè§£å†³å¤§å‹ç‰©ä½“çš„åä½œæ“æ§é—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCollaBotåœ¨ä¸åŒæœºå™¨äººæ•°é‡å’Œä»»åŠ¡ä¸­æˆåŠŸç‡è¾¾åˆ°52%ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨æœºå™¨äººç ”ç©¶ä¸­ï¼Œå¦‚ä½•ä½¿ç³»ç»Ÿä¸ç‰©ç†ä¸–ç•Œäº’åŠ¨æ˜¯ä¸€ä¸ªæ ¸å¿ƒè¯¾é¢˜ã€‚ä¼ ç»Ÿçš„æ“æ§ä»»åŠ¡ä¸»è¦é›†ä¸­åœ¨å°ç‰©ä½“ä¸Šï¼Œè€Œåœ¨å·¥å‚æˆ–å®¶åº­ç¯å¢ƒä¸­ï¼Œå¸¸å¸¸éœ€è¦ç§»åŠ¨å¤§å‹ç‰©ä½“ï¼Œå¦‚æ¡Œå­ã€‚è¿™äº›ä»»åŠ¡é€šå¸¸éœ€è¦å¤šæœºå™¨äººç³»ç»ŸååŒå·¥ä½œã€‚ä»¥å¾€çš„ç ”ç©¶ç¼ºä¹ä¸€ä¸ªèƒ½å¤Ÿé€‚åº”ä»»æ„å¤§å°æœºå™¨äººå¹¶æ³›åŒ–åˆ°å„ç§ä»»åŠ¡çš„æ¡†æ¶ã€‚æœ¬æ–‡æå‡ºäº†CollaBotï¼Œä¸€ä¸ªç”¨äºåŒæ—¶åä½œæ“æ§çš„é€šç”¨æ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨SEEMè¿›è¡Œåœºæ™¯åˆ†å‰²å’Œç›®æ ‡ç‰©ä½“çš„ç‚¹äº‘æå–ã€‚ç„¶åï¼Œæå‡ºäº†ä¸€ç§åä½œæŠ“å–æ¡†æ¶ï¼Œå°†ä»»åŠ¡åˆ†è§£ä¸ºå±€éƒ¨æŠ“å–å§¿æ€ç”Ÿæˆå’Œå…¨å±€åä½œã€‚æœ€åï¼Œè®¾è®¡äº†ä¸€ä¸ªä¸¤é˜¶æ®µè§„åˆ’æ¨¡å—ï¼Œèƒ½å¤Ÿç”Ÿæˆæ— ç¢°æ’çš„è½¨è¿¹ä»¥å®Œæˆä»»åŠ¡ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨ä¸åŒæ•°é‡çš„æœºå™¨äººã€ç‰©ä½“å’Œä»»åŠ¡ä¸­ï¼ŒæˆåŠŸç‡è¾¾åˆ°52%ï¼ŒéªŒè¯äº†æ‰€ææ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæœºå™¨äººåä½œæ“æ§å¤§å‹ç‰©ä½“çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šé›†ä¸­äºå°ç‰©ä½“ï¼Œç¼ºä¹é€‚åº”ä¸åŒè§„æ¨¡å’Œä»»åŠ¡çš„æ¡†æ¶ï¼Œå¯¼è‡´åœ¨å®é™…åº”ç”¨ä¸­æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCollaBotæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å°†ä»»åŠ¡åˆ†è§£ä¸ºå±€éƒ¨æŠ“å–å’Œå…¨å±€åä½œï¼Œåˆ©ç”¨SEEMè¿›è¡Œåœºæ™¯åˆ†æï¼Œä»è€Œå®ç°é«˜æ•ˆçš„åä½œæ“æ§ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿçµæ´»åº”å¯¹ä¸åŒå¤§å°å’Œå½¢çŠ¶çš„ç‰©ä½“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯åœºæ™¯åˆ†å‰²å’Œç‚¹äº‘æå–æ¨¡å—ï¼Œä½¿ç”¨SEEMæŠ€æœ¯ï¼›å…¶æ¬¡æ˜¯åä½œæŠ“å–æ¡†æ¶ï¼Œè´Ÿè´£ç”Ÿæˆå±€éƒ¨æŠ“å–å§¿æ€ï¼›æœ€åæ˜¯ä¸¤é˜¶æ®µè§„åˆ’æ¨¡å—ï¼Œè´Ÿè´£ç”Ÿæˆæ— ç¢°æ’çš„è¿åŠ¨è½¨è¿¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªé€šç”¨çš„åä½œæ¡†æ¶ï¼Œèƒ½å¤Ÿé€‚åº”ä¸åŒè§„æ¨¡çš„æœºå™¨äººå’Œå¤šæ ·åŒ–çš„æ“æ§ä»»åŠ¡ã€‚è¿™ä¸€æ¡†æ¶çš„è®¾è®¡ä½¿å¾—å¤šæœºå™¨äººç³»ç»Ÿèƒ½å¤Ÿæ›´é«˜æ•ˆåœ°ååŒå·¥ä½œã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æŠ“å–å§¿æ€ç”Ÿæˆï¼ŒåŒæ—¶åœ¨è§„åˆ’æ¨¡å—ä¸­å¼•å…¥äº†ç¢°æ’æ£€æµ‹æœºåˆ¶ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„è½¨è¿¹å®‰å…¨æœ‰æ•ˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCollaBotåœ¨ä¸åŒæ•°é‡çš„æœºå™¨äººå’Œä»»åŠ¡ä¸­æˆåŠŸç‡è¾¾åˆ°52%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¡†æ¶åœ¨å¤šæœºå™¨äººåä½œæ“æ§ä»»åŠ¡ä¸­å…·æœ‰æ˜¾è‘—çš„æœ‰æ•ˆæ€§ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æœ‰æ˜æ˜¾æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å·¥ä¸šè‡ªåŠ¨åŒ–ã€å®¶åº­æœåŠ¡æœºå™¨äººä»¥åŠç‰©æµæ¬è¿ç­‰åœºæ™¯ã€‚CollaBotæ¡†æ¶çš„è®¾è®¡å¯ä»¥æ˜¾è‘—æå‡å¤šæœºå™¨äººç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çš„åä½œèƒ½åŠ›ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A central research topic in robotics is how to use this system to interact with the physical world. Traditional manipulation tasks primarily focus on small objects. However, in factory or home environments, there is often a need for the movement of large objects, such as moving tables. These tasks typically require multi-robot systems to work collaboratively. Previous research lacks a framework that can scale to arbitrary sizes of robots and generalize to various kinds of tasks. In this work, we propose CollaBot, a generalist framework for simultaneous collaborative manipulation. First, we use SEEM for scene segmentation and point cloud extraction of the target object. Then, we propose a collaborative grasping framework, which decomposes the task into local grasp pose generation and global collaboration. Finally, we design a 2-stage planning module that can generate collision-free trajectories to achieve this task. Experiments show a success rate of 52% across different numbers of robots, objects, and tasks, indicating the effectiveness of the proposed framework.

