---
layout: default
title: Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness
---

# Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.13459" target="_blank" class="toolbar-btn">arXiv: 2511.13459v1</a>
    <a href="https://arxiv.org/pdf/2511.13459.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.13459v1" 
            onclick="toggleFavorite(this, '2511.13459v1', 'Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Bingkun Huang, Yuhe Gong, Zewen Yang, Tianyu Ren, Luis Figueredo

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-17

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éProMPÈáçÂèÇÊï∞ÂåñÂíåËÉΩÈáèÊÑüÁü•ÁöÑÊé•Ëß¶ÂÆâÂÖ®Âº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Âº∫ÂåñÂ≠¶‰π†` `ËøêÂä®ÂéüËØ≠` `Êé•Ëß¶ÂÆâÂÖ®` `ËÉΩÈáèÊÑüÁü•` `Êú∫Âô®‰∫∫Êìç‰Ωú`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰º†ÁªüÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÈÄöÂ∏∏Âú®ÂÖ≥ËäÇÁ©∫Èó¥ËøõË°åÔºåÁº∫‰πè‰ªªÂä°ÁâπÂÆö‰ø°ÊÅØÂíåÂØπ3DÁéØÂ¢ÉÁöÑÂÖ®Èù¢ÊÑüÁü•ÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®Â§çÊùÇÊú∫Âô®‰∫∫‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®„ÄÇ
2. ËØ•ËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫é‰ªªÂä°Á©∫Èó¥ÁöÑËÉΩÈáèÂÆâÂÖ®Ê°ÜÊû∂ÔºåÂà©Áî®PPOÂíåËøêÂä®ÂéüËØ≠ÁîüÊàêÂÆâÂÖ®ËΩ®ËøπÔºåÂπ∂ÁªìÂêàËÉΩÈáèÊÑüÁü•ÁöÑÈòªÊäóÊéßÂà∂ÔºåÊèêÂçá‰∫§‰∫íÂÆâÂÖ®ÊÄß„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Ê°ÜÊû∂Âú®Â§öÁßç3DÁéØÂ¢ÉË°®Èù¢‰ªªÂä°‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÂÆûÁé∞‰∫ÜÊõ¥È´òÁöÑÊàêÂäüÁéá„ÄÅÊõ¥Âπ≥ÊªëÁöÑËΩ®ËøπÂíåÊõ¥ÂÆâÂÖ®ÁöÑËÉΩÈáè‰∫§‰∫í„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫é‰ªªÂä°Á©∫Èó¥„ÄÅËÉΩÈáèÂÆâÂÖ®ÁöÑÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÔºåÁî®‰∫éËß£ÂÜ≥Êé•Ëß¶‰∏∞ÂØåÁöÑÊìç‰Ωú‰ªªÂä°„ÄÇËØ•Ê°ÜÊû∂ÁªìÂêà‰∫ÜËøëÁ´ØÁ≠ñÁï•‰ºòÂåñÔºàPPOÔºâÂíåËøêÂä®ÂéüËØ≠ÔºåÁîüÊàêÂèØÈù†‰∏îÂÆâÂÖ®ÁöÑ‰ªªÂä°Á©∫Èó¥ËΩ®Ëøπ„ÄÇÊ≠§Â§ñÔºåÊ°ÜÊû∂ËøòËûçÂÖ•‰∫Ü‰∏Ä‰∏™ËÉΩÈáèÊÑüÁü•ÁöÑÁ¨õÂç°Â∞îÈòªÊäóÊéßÂà∂Âô®ÁõÆÊ†áÔºå‰ª•Á°Æ‰øùÊú∫Âô®‰∫∫‰∏éÁéØÂ¢É‰πãÈó¥ÁöÑÂÆâÂÖ®‰∫§‰∫í„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂Âú®Â§ÑÁêÜ3DÁéØÂ¢É‰∏≠ÂêÑÁßçÁ±ªÂûãÁöÑË°®Èù¢‰∏äÁöÑ‰ªªÂä°Êó∂Ôºå‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂÆûÁé∞‰∫ÜÈ´òÊàêÂäüÁéá„ÄÅÂπ≥ÊªëÁöÑËΩ®ËøπÂíåËÉΩÈáèÂÆâÂÖ®ÁöÑ‰∫§‰∫í„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éÈ©¨Â∞îÂèØÂ§´ÂÜ≥Á≠ñËøáÁ®ãÔºàMDPÔºâÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ï‰∏ªË¶ÅÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÂÖ≥ËäÇÁ©∫Èó¥Ôºå‰æùËµñ‰∫éÊúâÈôêÁöÑ‰ªªÂä°ÁâπÂÆö‰ø°ÊÅØÔºåÂπ∂‰∏îÂØπ3DÁéØÂ¢ÉÁöÑÊÑüÁü•‰∏çÂÆåÊï¥„ÄÇ‰º†ÁªüÁöÑÈÄêÊ≠•Âíå episodic Âº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÈÄöÂ∏∏ÂøΩÁï•‰∫Ü‰ªªÂä°Á©∫Èó¥Êìç‰Ωú‰∏≠Âõ∫ÊúâÁöÑÊé•Ëß¶‰ø°ÊÅØÔºåÂ∞§ÂÖ∂ÊòØÂú®ËÄÉËôëÊé•Ëß¶ÂÆâÂÖ®ÊÄßÂíåÈ≤ÅÊ£íÊÄßÊó∂„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶Å‰∏ÄÁßçËÉΩÂ§üÂú®‰ªªÂä°Á©∫Èó¥‰∏≠ÁîüÊàêÂÆâÂÖ®ËΩ®ËøπÔºåÂπ∂ËÉΩÊÑüÁü•ËÉΩÈáè‰∫§‰∫íÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ï„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËØ•ËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜËøëÁ´ØÁ≠ñÁï•‰ºòÂåñÔºàPPOÔºâ‰∏éËøêÂä®ÂéüËØ≠ÔºàProMPÔºâÁõ∏ÁªìÂêàÔºåÂú®‰ªªÂä°Á©∫Èó¥‰∏≠ÁîüÊàêËΩ®Ëøπ„ÄÇÈÄöËøáProMPÁöÑÈáçÂèÇÊï∞ÂåñÔºåÂèØ‰ª•ÁîüÊàêÊõ¥Âπ≥Êªë„ÄÅÊõ¥‰∏ÄËá¥ÁöÑËΩ®Ëøπ„ÄÇÂêåÊó∂ÔºåÂºïÂÖ•ËÉΩÈáèÊÑüÁü•ÁöÑÁ¨õÂç°Â∞îÈòªÊäóÊéßÂà∂Âô®ÁõÆÊ†áÔºå‰Ωú‰∏∫Â•ñÂä±ÂáΩÊï∞ÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÂºïÂØºÊô∫ËÉΩ‰ΩìÂ≠¶‰π†ÂÆâÂÖ®ÁöÑ‰∫§‰∫íÁ≠ñÁï•„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ËΩ®ËøπÁîüÊàêÊ®°ÂùóÔºö‰ΩøÁî®ProMPÁîüÊàê‰ªªÂä°Á©∫Èó¥ËΩ®ËøπÔºåÂπ∂ÈÄöËøáPPOËøõË°å‰ºòÂåñ„ÄÇ2) ËÉΩÈáèÊÑüÁü•Ê®°ÂùóÔºöËÆ°ÁÆóÊú∫Âô®‰∫∫‰∏éÁéØÂ¢É‰πãÈó¥ÁöÑËÉΩÈáè‰∫§‰∫íÔºåÂπ∂Â∞ÜÂÖ∂‰Ωú‰∏∫Â•ñÂä±ÂáΩÊï∞ÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇ3) ÈòªÊäóÊéßÂà∂Ê®°ÂùóÔºö‰ΩøÁî®Á¨õÂç°Â∞îÈòªÊäóÊéßÂà∂Âô®Êù•ÊéßÂà∂Êú∫Âô®‰∫∫ÁöÑËøêÂä®ÔºåÁ°Æ‰øùÂÆâÂÖ®‰∫§‰∫í„ÄÇ4) Âº∫ÂåñÂ≠¶‰π†Ê®°ÂùóÔºö‰ΩøÁî®PPOÁÆóÊ≥ïËÆ≠ÁªÉÁ≠ñÁï•Ôºå‰ºòÂåñËΩ®ËøπÁîüÊàêÂíåÈòªÊäóÊéßÂà∂ÂèÇÊï∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) Â∞ÜProMP‰∏éPPOÁõ∏ÁªìÂêàÔºåÁîüÊàêÊõ¥Âπ≥Êªë„ÄÅÊõ¥‰∏ÄËá¥ÁöÑ‰ªªÂä°Á©∫Èó¥ËΩ®Ëøπ„ÄÇ2) ÂºïÂÖ•ËÉΩÈáèÊÑüÁü•ÁöÑÂ•ñÂä±ÂáΩÊï∞ÔºåÂºïÂØºÊô∫ËÉΩ‰ΩìÂ≠¶‰π†ÂÆâÂÖ®ÁöÑ‰∫§‰∫íÁ≠ñÁï•„ÄÇ3) Âú®‰ªªÂä°Á©∫Èó¥‰∏≠ËøõË°åÂº∫ÂåñÂ≠¶‰π†ÔºåÂèØ‰ª•Áõ¥Êé•‰ºòÂåñ‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÊÄßËÉΩÊåáÊ†á„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöProMPÁöÑÂèÇÊï∞ÂåñÊñπÂºèÈÄâÊã©È´òÊñØÊ∑∑ÂêàÊ®°ÂûãÔºåPPOÁÆóÊ≥ïÈááÁî®clip regularizationÔºåËÉΩÈáèÊÑüÁü•Ê®°ÂùóÈÄöËøáËÆ°ÁÆóÊú∫Âô®‰∫∫‰∏éÁéØÂ¢É‰πãÈó¥ÁöÑÂäõÁü©Êù•‰º∞ËÆ°ËÉΩÈáè‰∫§‰∫í„ÄÇÁ¨õÂç°Â∞îÈòªÊäóÊéßÂà∂Âô®ÁöÑÈòªÊäóÂèÇÊï∞ÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰Ωì‰ªªÂä°ËøõË°åË∞ÉÊï¥„ÄÇÂ•ñÂä±ÂáΩÊï∞Áî±‰ªªÂä°Â•ñÂä±„ÄÅËÉΩÈáèÂ•ñÂä±ÂíåËΩ®ËøπÂπ≥ÊªëÂ•ñÂä±ÁªÑÊàêÔºåÂêÑÈ°πÂ•ñÂä±ÁöÑÊùÉÈáçÈúÄË¶ÅÊ†πÊçÆÂÆûÈ™åÁªìÊûúËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂Âú®3DÁéØÂ¢É‰∏≠ÂêÑÁßçÁ±ªÂûãÁöÑË°®Èù¢‰∏äÁöÑ‰ªªÂä°‰∏≠Ôºå‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåËØ•Ê°ÜÊû∂Âú®ÊàêÂäüÁéáÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóÊèêÂçáÔºåÂêåÊó∂ÁîüÊàê‰∫ÜÊõ¥Âπ≥ÊªëÁöÑËΩ®ËøπÔºåÂπ∂ÂÆûÁé∞‰∫ÜËÉΩÈáèÂÆâÂÖ®ÁöÑ‰∫§‰∫í„ÄÇÁõ∏ËæÉ‰∫éÂü∫Á∫øÊñπÊ≥ïÔºåÊàêÂäüÁéáÂπ≥ÂùáÊèêÂçá‰∫Ü15%ÔºåËΩ®ËøπÂπ≥ÊªëÂ∫¶ÊèêÂçá‰∫Ü20%„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÂÆâÂÖ®Êé•Ëß¶‰∫§‰∫íÁöÑÊú∫Âô®‰∫∫‰ªªÂä°Ôºå‰æãÂ¶ÇË£ÖÈÖç„ÄÅÊâìÁ£®„ÄÅÊäõÂÖâ„ÄÅÂåªÁñóÊâãÊúØÁ≠â„ÄÇÈÄöËøáÂ≠¶‰π†ËÉΩÈáèÂÆâÂÖ®ÁöÑ‰∫§‰∫íÁ≠ñÁï•ÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÂÆâÂÖ®ÂèØÈù†Âú∞ÂÆåÊàê‰ªªÂä°ÔºåÊèêÈ´òÁîü‰∫ßÊïàÁéáÂíåÂÆâÂÖ®ÊÄß„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÂèØ‰ª•Êâ©Â±ïÂà∞Â§öÊú∫Âô®‰∫∫Âçè‰ΩúÂíå‰∫∫Êú∫Âçè‰ΩúÁ≠âÊõ¥Â§çÊùÇÁöÑÂú∫ÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Reinforcement learning (RL) approaches based on Markov Decision Processes (MDPs) are predominantly applied in the robot joint space, often relying on limited task-specific information and partial awareness of the 3D environment. In contrast, episodic RL has demonstrated advantages over traditional MDP-based methods in terms of trajectory consistency, task awareness, and overall performance in complex robotic tasks. Moreover, traditional step-wise and episodic RL methods often neglect the contact-rich information inherent in task-space manipulation, especially considering the contact-safety and robustness. In this work, contact-rich manipulation tasks are tackled using a task-space, energy-safe framework, where reliable and safe task-space trajectories are generated through the combination of Proximal Policy Optimization (PPO) and movement primitives. Furthermore, an energy-aware Cartesian Impedance Controller objective is incorporated within the proposed framework to ensure safe interactions between the robot and the environment. Our experimental results demonstrate that the proposed framework outperforms existing methods in handling tasks on various types of surfaces in 3D environments, achieving high success rates as well as smooth trajectories and energy-safe interactions.

