---
layout: default
title: Towards High-Consistency Embodied World Model with Multi-View Trajectory Videos
---

# Towards High-Consistency Embodied World Model with Multi-View Trajectory Videos

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.12882" target="_blank" class="toolbar-btn">arXiv: 2511.12882v2</a>
    <a href="https://arxiv.org/pdf/2511.12882.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.12882v2" 
            onclick="toggleFavorite(this, '2511.12882v2', 'Towards High-Consistency Embodied World Model with Multi-View Trajectory Videos')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Taiyi Su, Jian Zhu, Yaxuan Li, Chong Ma, Zitai Huang, Hanli Wang, Yi Xu

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-17 (Êõ¥Êñ∞: 2025-11-19)

**Â§áÊ≥®**: 15 pages, 23 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MTV-WorldÔºåÂà©Áî®Â§öËßÜËßíËΩ®ËøπËßÜÈ¢ëÂÆûÁé∞È´ò‰∏ÄËá¥ÊÄßÁöÑÂÖ∑Ë∫´‰∏ñÁïåÊ®°Âûã**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÂÖ∑Ë∫´‰∏ñÁïåÊ®°Âûã` `Â§öËßÜËßíÂ≠¶‰π†` `ËΩ®ËøπËßÜÈ¢ë` `ËßÜËßâËøêÂä®È¢ÑÊµã` `Êú∫Âô®‰∫∫ÊéßÂà∂` `Áâ©ÁêÜ‰∫§‰∫í` `Ëá™Âä®ËØÑ‰º∞`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂÖ∑Ë∫´‰∏ñÁïåÊ®°ÂûãÂú®Â∞Ü‰ΩéÁ∫ßÂä®‰ΩúËΩ¨Âåñ‰∏∫Á≤æÁ°ÆÊú∫Âô®‰∫∫ËøêÂä®Êó∂Â≠òÂú®Âõ∞ÈöæÔºåÂØºËá¥È¢ÑÊµã‰∏éÁúüÂÆûÁâ©ÁêÜ‰∫§‰∫í‰∏ç‰∏ÄËá¥„ÄÇ
2. MTV-WorldÂà©Áî®Â§öËßÜËßíËΩ®ËøπËßÜÈ¢ë‰Ωú‰∏∫ÊéßÂà∂‰ø°Âè∑ÔºåË°•ÂÅøÁ©∫Èó¥‰ø°ÊÅØÊçüÂ§±ÔºåÂÆûÁé∞Êõ¥Á≤æÁ°ÆÁöÑËßÜËßâËøêÂä®È¢ÑÊµã„ÄÇ
3. ËÆ∫ÊñáÊèêÂá∫Ëá™Âä®ËØÑ‰º∞ÊµÅÁ®ãÔºåÂπ∂‰ΩøÁî®JaccardÊåáÊï∞ËØÑ‰º∞Á©∫Èó¥‰∏ÄËá¥ÊÄßÔºåÂÆûÈ™åËØÅÊòéÊ®°ÂûãÂú®ÂèåËáÇÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂÖ∑Ë∫´‰∏ñÁïåÊ®°ÂûãÊó®Âú®ÈÄöËøáËßÜËßâËßÇÂØüÂíåÂä®‰ΩúÊù•È¢ÑÊµãÁâ©ÁêÜ‰∏ñÁïåÂπ∂‰∏é‰πã‰∫§‰∫í„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊ®°ÂûãÈöæ‰ª•Â∞Ü‰ΩéÁ∫ßÂä®‰ΩúÔºà‰æãÂ¶ÇÔºåÂÖ≥ËäÇ‰ΩçÁΩÆÔºâÂáÜÁ°ÆÂú∞ËΩ¨Âåñ‰∏∫È¢ÑÊµãÂ∏ß‰∏≠Á≤æÁ°ÆÁöÑÊú∫Âô®‰∫∫ËøêÂä®ÔºåÂØºËá¥‰∏éÁúüÂÆûÁâ©ÁêÜ‰∫§‰∫íÁöÑ‰∏ç‰∏ÄËá¥„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈôêÂà∂ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜMTV-WorldÔºå‰∏ÄÁßçÂÖ∑Ë∫´‰∏ñÁïåÊ®°ÂûãÔºåÂÆÉÂºïÂÖ•‰∫ÜÂ§öËßÜËßíËΩ®ËøπËßÜÈ¢ëÊéßÂà∂Ôºå‰ª•ÂÆûÁé∞Á≤æÁ°ÆÁöÑËßÜËßâËøêÂä®È¢ÑÊµã„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Ê≤°ÊúâÁõ¥Êé•‰ΩøÁî®‰ΩéÁ∫ßÂä®‰ΩúËøõË°åÊéßÂà∂ÔºåËÄåÊòØÈááÁî®ÈÄöËøáÁõ∏Êú∫ÂÜÖÂèÇÂíåÂ§ñÂèÇ‰ª•ÂèäÁ¨õÂç°Â∞îÁ©∫Èó¥ÂèòÊç¢Ëé∑ÂæóÁöÑËΩ®ËøπËßÜÈ¢ë‰Ωú‰∏∫ÊéßÂà∂‰ø°Âè∑„ÄÇÁÑ∂ËÄåÔºåÂ∞Ü3DÂéüÂßãÂä®‰ΩúÊäïÂΩ±Âà∞2DÂõæÂÉè‰∏ä‰∏çÂèØÈÅøÂÖçÂú∞‰ºöÂØºËá¥Á©∫Èó¥‰ø°ÊÅØÁöÑ‰∏¢Â§±Ôºå‰ΩøÂæóÂçïËßÜËßí‰∏çË∂≥‰ª•ËøõË°åÁ≤æÁ°ÆÁöÑ‰∫§‰∫íÂª∫Ê®°„ÄÇ‰∏∫‰∫ÜÂÖãÊúçËøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Â§öËßÜËßíÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂Ë°•ÂÅø‰∫ÜÁ©∫Èó¥‰ø°ÊÅØÁöÑ‰∏¢Â§±ÔºåÂπ∂Á°Æ‰øù‰∏éÁâ©ÁêÜ‰∏ñÁïåÁöÑÈ´òÂ∫¶‰∏ÄËá¥ÊÄß„ÄÇMTV-WorldÂü∫‰∫éÂ§öËßÜËßíËΩ®ËøπËßÜÈ¢ë‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂‰ª•ÊØè‰∏™ËßÜËßíÁöÑÂàùÂßãÂ∏ß‰∏∫Êù°‰ª∂Êù•È¢ÑÊµãÊú™Êù•Â∏ß„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫ÜÁ≥ªÁªüÂú∞ËØÑ‰º∞Êú∫Âô®‰∫∫ËøêÂä®Á≤æÂ∫¶ÂíåÁâ©‰Ωì‰∫§‰∫íÂáÜÁ°ÆÊÄßÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∏™Ëá™Âä®ËØÑ‰º∞ÊµÅÁ®ãÔºåÂà©Áî®Â§öÊ®°ÊÄÅÂ§ßÂûãÊ®°ÂûãÂíåÂèÇËÄÉËßÜÈ¢ëÂØπË±°ÂàÜÂâ≤Ê®°Âûã„ÄÇ‰∏∫‰∫ÜË°°ÈáèÁ©∫Èó¥‰∏ÄËá¥ÊÄßÔºåÊàë‰ª¨Â∞ÜÂÖ∂ÂÆö‰πâ‰∏∫‰∏Ä‰∏™Áâ©‰Ωì‰ΩçÁΩÆÂåπÈÖçÈóÆÈ¢òÔºåÂπ∂ÈááÁî®JaccardÊåáÊï∞‰Ωú‰∏∫ËØÑ‰º∞ÊåáÊ†á„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åË°®ÊòéÔºåMTV-WorldÂú®Â§çÊùÇÁöÑÂèåËáÇÂú∫ÊôØ‰∏≠ÂÆûÁé∞‰∫ÜÁ≤æÁ°ÆÁöÑÊéßÂà∂ÊâßË°åÂíåÂáÜÁ°ÆÁöÑÁâ©ÁêÜ‰∫§‰∫íÂª∫Ê®°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂÖ∑Ë∫´‰∏ñÁïåÊ®°ÂûãÈöæ‰ª•ÂáÜÁ°ÆÂú∞Â∞Ü‰ΩéÁ∫ßÂä®‰ΩúÊåá‰ª§ÔºàÂ¶ÇÂÖ≥ËäÇ‰ΩçÁΩÆÔºâËΩ¨Âåñ‰∏∫È¢ÑÊµãËßÜÈ¢ëÂ∏ß‰∏≠Á≤æÁ°ÆÁöÑÊú∫Âô®‰∫∫ËøêÂä®ÔºåÂØºËá¥È¢ÑÊµãÁöÑÁâ©ÁêÜ‰∫§‰∫í‰∏éÁúüÂÆû‰∏ñÁïå‰∏ç‰∏ÄËá¥„ÄÇËøôÁßç‰∏ç‰∏ÄËá¥ÊÄßÈôêÂà∂‰∫ÜÊ®°ÂûãÂú®Â§çÊùÇÊú∫Âô®‰∫∫‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®Ôºå‰æãÂ¶ÇÂèåËáÇÂçèÂêåÊìç‰Ωú„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØ‰ΩøÁî®Â§öËßÜËßíËΩ®ËøπËßÜÈ¢ë‰Ωú‰∏∫ÊéßÂà∂‰ø°Âè∑ÔºåÊõø‰ª£Áõ¥Êé•‰ΩøÁî®‰ΩéÁ∫ßÂä®‰Ωú„ÄÇËΩ®ËøπËßÜÈ¢ëÂåÖÂê´‰∫ÜÊõ¥‰∏∞ÂØåÁöÑÁ©∫Èó¥‰ø°ÊÅØÔºåËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞ÊèèËø∞Êú∫Âô®‰∫∫ÁöÑËøêÂä®ËΩ®Ëøπ„ÄÇÂ§öËßÜËßíÁöÑËÆæËÆ°Âº•Ë°•‰∫ÜÂçïËßÜËßíÊäïÂΩ±ÈÄ†ÊàêÁöÑÁ©∫Èó¥‰ø°ÊÅØÊçüÂ§±Ôºå‰ªéËÄåÊèêÈ´òÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMTV-WorldÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Â§öËßÜËßíËΩ®ËøπËßÜÈ¢ëÁîüÊàêÊ®°ÂùóÔºöÂà©Áî®Áõ∏Êú∫ÂèÇÊï∞ÂíåÁ¨õÂç°Â∞îÁ©∫Èó¥ÂèòÊç¢Â∞ÜÊú∫Âô®‰∫∫Âä®‰ΩúËΩ¨Âåñ‰∏∫Â§öËßÜËßíËΩ®ËøπËßÜÈ¢ë„ÄÇ2) ËßÜÈ¢ëÈ¢ÑÊµãÊ®°ÂùóÔºöÂü∫‰∫éÂ§öËßÜËßíËΩ®ËøπËßÜÈ¢ëÂíåÂàùÂßãÂ∏ßÔºåÈ¢ÑÊµãÊú™Êù•ÁöÑËßÜÈ¢ëÂ∏ß„ÄÇ3) Ëá™Âä®ËØÑ‰º∞Ê®°ÂùóÔºöÂà©Áî®Â§öÊ®°ÊÄÅÂ§ßÂûãÊ®°ÂûãÂíåÂèÇËÄÉËßÜÈ¢ëÂØπË±°ÂàÜÂâ≤Ê®°ÂûãÔºåËá™Âä®ËØÑ‰º∞Êú∫Âô®‰∫∫ËøêÂä®Á≤æÂ∫¶ÂíåÁâ©‰Ωì‰∫§‰∫íÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ‰ΩøÁî®Â§öËßÜËßíËΩ®ËøπËßÜÈ¢ë‰Ωú‰∏∫ÊéßÂà∂‰ø°Âè∑ÔºåÊèêÈ´ò‰∫ÜËßÜËßâËøêÂä®È¢ÑÊµãÁöÑÁ≤æÂ∫¶Âíå‰∏ÄËá¥ÊÄß„ÄÇ2) ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Ëá™Âä®ËØÑ‰º∞ÊµÅÁ®ãÔºåËÉΩÂ§üÁ≥ªÁªüÂú∞ËØÑ‰º∞Êú∫Âô®‰∫∫ËøêÂä®Á≤æÂ∫¶ÂíåÁâ©‰Ωì‰∫§‰∫íÂáÜÁ°ÆÊÄß„ÄÇ3) Â∞ÜÁ©∫Èó¥‰∏ÄËá¥ÊÄßÂÆö‰πâ‰∏∫‰∏Ä‰∏™Áâ©‰Ωì‰ΩçÁΩÆÂåπÈÖçÈóÆÈ¢òÔºåÂπ∂ÈááÁî®JaccardÊåáÊï∞‰Ωú‰∏∫ËØÑ‰º∞ÊåáÊ†á„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËΩ®ËøπËßÜÈ¢ëÁöÑÁîüÊàê‰æùËµñ‰∫éÁ≤æÁ°ÆÁöÑÁõ∏Êú∫Ê†áÂÆöÂíåÂùêÊ†áÁ≥ªËΩ¨Êç¢„ÄÇËßÜÈ¢ëÈ¢ÑÊµãÊ®°ÂùóÂèØËÉΩÈááÁî®TransformerÊàñRNNÁ≠âÂ∫èÂàóÊ®°Âûã„ÄÇËá™Âä®ËØÑ‰º∞Ê®°ÂùóÈúÄË¶ÅÈÄâÊã©ÂêàÈÄÇÁöÑËßÜËßâÂàÜÂâ≤Ê®°ÂûãÂíåÂ§öÊ®°ÊÄÅÂ§ßÊ®°Âûã„ÄÇJaccardÊåáÊï∞Áî®‰∫éË°°ÈáèÈ¢ÑÊµãÁâ©‰Ωì‰ΩçÁΩÆ‰∏éÁúüÂÆûÁâ©‰Ωì‰ΩçÁΩÆÁöÑÈáçÂè†Á®ãÂ∫¶„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMTV-WorldÂú®Â§çÊùÇÁöÑÂèåËáÇÂú∫ÊôØ‰∏≠ÂÆûÁé∞‰∫ÜÁ≤æÁ°ÆÁöÑÊéßÂà∂ÊâßË°åÂíåÂáÜÁ°ÆÁöÑÁâ©ÁêÜ‰∫§‰∫íÂª∫Ê®°„ÄÇËÆ∫ÊñáÊèêÂá∫ÁöÑËá™Âä®ËØÑ‰º∞ÊµÅÁ®ãËÉΩÂ§üÊúâÊïàÂú∞ËØÑ‰º∞Ê®°ÂûãÁöÑÊÄßËÉΩÔºåÂπ∂‰∏∫Êú™Êù•ÁöÑÁ†îÁ©∂Êèê‰æõÂèÇËÄÉ„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜËÆ∫ÊñáÂº∫Ë∞É‰∫ÜÂú®Á©∫Èó¥‰∏ÄËá¥ÊÄßÊñπÈù¢ÁöÑÊòæËëóÊèêÂçá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÁ≤æÁ°ÆÊéßÂà∂ÂíåÁâ©ÁêÜ‰∫§‰∫íÁöÑÊú∫Âô®‰∫∫‰ªªÂä°Ôºå‰æãÂ¶ÇÔºöÂ∑•‰∏öËá™Âä®Âåñ„ÄÅÂåªÁñóÊâãÊúØÊú∫Âô®‰∫∫„ÄÅÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫Á≠â„ÄÇÈÄöËøáÊèêÈ´òÊú∫Âô®‰∫∫ÂØπÁéØÂ¢ÉÁöÑÁêÜËß£ÂíåÈ¢ÑÊµãËÉΩÂäõÔºåÂèØ‰ª•ÂÆûÁé∞Êõ¥ÂÆâÂÖ®„ÄÅÊõ¥È´òÊïàÁöÑ‰∫∫Êú∫Âçè‰ΩúÔºåÂπ∂ÊãìÂ±ïÊú∫Âô®‰∫∫ÁöÑÂ∫îÁî®ËåÉÂõ¥„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Embodied world models aim to predict and interact with the physical world through visual observations and actions. However, existing models struggle to accurately translate low-level actions (e.g., joint positions) into precise robotic movements in predicted frames, leading to inconsistencies with real-world physical interactions. To address these limitations, we propose MTV-World, an embodied world model that introduces Multi-view Trajectory-Video control for precise visuomotor prediction. Specifically, instead of directly using low-level actions for control, we employ trajectory videos obtained through camera intrinsic and extrinsic parameters and Cartesian-space transformation as control signals. However, projecting 3D raw actions onto 2D images inevitably causes a loss of spatial information, making a single view insufficient for accurate interaction modeling. To overcome this, we introduce a multi-view framework that compensates for spatial information loss and ensures high-consistency with physical world. MTV-World forecasts future frames based on multi-view trajectory videos as input and conditioning on an initial frame per view. Furthermore, to systematically evaluate both robotic motion precision and object interaction accuracy, we develop an auto-evaluation pipeline leveraging multimodal large models and referring video object segmentation models. To measure spatial consistency, we formulate it as an object location matching problem and adopt the Jaccard Index as the evaluation metric. Extensive experiments demonstrate that MTV-World achieves precise control execution and accurate physical interaction modeling in complex dual-arm scenarios.

