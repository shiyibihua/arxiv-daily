---
layout: default
title: FiLM-Nav: Efficient and Generalizable Navigation via VLM Fine-tuning
---

# FiLM-Nav: Efficient and Generalizable Navigation via VLM Fine-tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16445" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16445v1</a>
  <a href="https://arxiv.org/pdf/2509.16445.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16445v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16445v1', 'FiLM-Nav: Efficient and Generalizable Navigation via VLM Fine-tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Naoki Yokoyama, Sehoon Ha

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**FiLM-Navï¼šé€šè¿‡VLMå¾®è°ƒå®ç°é«˜æ•ˆä¸”æ³›åŒ–çš„å¯¼èˆª**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `å…·èº«å¯¼èˆª` `è¿ç§»å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `æœºå™¨äºº` `è¯­ä¹‰ç†è§£` `å¼€æ”¾è¯æ±‡` `å¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥å°†è§†è§‰-è¯­è¨€æ¨¡å‹(VLM)çš„å¼ºå¤§è¯­ä¹‰ç†è§£èƒ½åŠ›æœ‰æ•ˆåº”ç”¨äºå…·èº«å†³ç­–ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚ç¯å¢ƒå¯¼èˆªä¸­ã€‚
2. FiLM-Navç›´æ¥å¾®è°ƒé¢„è®­ç»ƒVLMä½œä¸ºå¯¼èˆªç­–ç•¥ï¼Œé€šè¿‡è§†è§‰è½¨è¿¹å’Œå¯¼èˆªç›®æ ‡å­¦ä¹ é€‰æ‹©æœ€ä½³æ¢ç´¢å‰æ²¿ã€‚
3. åœ¨ObjectNavã€OVONç­‰ä»»åŠ¡æ··åˆæ•°æ®é›†ä¸Šå¾®è°ƒï¼ŒFiLM-Navåœ¨HM3Dæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå±•ç¤ºäº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºFiLM-Navï¼Œä¸€ç§ç›´æ¥å¾®è°ƒé¢„è®­ç»ƒè§†è§‰-è¯­è¨€æ¨¡å‹(VLM)ä½œä¸ºå¯¼èˆªç­–ç•¥çš„æ–¹æ³•ï¼Œæ—¨åœ¨ä½¿æœºå™¨äººåŠ©æ‰‹èƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­å¯¼èˆªå¹¶å®šä½è‡ªç”±æ–‡æœ¬æè¿°çš„ç‰©ä½“ã€‚ä¸ä¸»è¦ä»¥é›¶æ ·æœ¬æ–¹å¼æˆ–ç”¨äºåœ°å›¾æ ‡æ³¨çš„æ–¹æ³•ä¸åŒï¼ŒFiLM-Navé€šè¿‡ç›´æ¥è°ƒèŠ‚åŸå§‹è§†è§‰è½¨è¿¹å†å²å’Œå¯¼èˆªç›®æ ‡æ¥å­¦ä¹ é€‰æ‹©æœ€ä½³æ¢ç´¢å‰æ²¿ã€‚åˆ©ç”¨æœ‰é’ˆå¯¹æ€§çš„æ¨¡æ‹Ÿå…·èº«ç»éªŒï¼ŒVLMèƒ½å¤Ÿå°†å…¶å¼ºå¤§çš„é¢„è®­ç»ƒè¡¨ç¤ºä¸ç›®æ ‡é©±åŠ¨å¯¼èˆªç›¸å…³çš„ç‰¹å®šåŠ¨æ€å’Œè§†è§‰æ¨¡å¼ç›¸ç»“åˆã€‚å…³é”®åœ¨äºï¼Œç»“åˆObjectNavã€OVONã€ImageNavå’Œè¾…åŠ©ç©ºé—´æ¨ç†ä»»åŠ¡çš„å¤šå…ƒæ•°æ®æ··åˆè¿›è¡Œå¾®è°ƒï¼Œå¯¹äºå®ç°é²æ£’æ€§å’Œå¹¿æ³›çš„æ³›åŒ–è‡³å…³é‡è¦ã€‚FiLM-Navåœ¨å¼€æ”¾è¯æ±‡æ–¹æ³•ä¸­ï¼ŒäºHM3D ObjectNavä¸Šå®ç°äº†SPLå’ŒæˆåŠŸç‡çš„æ–°SOTAï¼Œå¹¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„HM3D-OVONåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†SOTA SPLï¼Œå±•ç¤ºäº†å¯¹æœªè§è¿‡çš„ç‰©ä½“ç±»åˆ«çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œéªŒè¯äº†åœ¨å¤šæ ·åŒ–çš„æ¨¡æ‹Ÿå…·èº«æ•°æ®ä¸Šç›´æ¥å¾®è°ƒVLMæ˜¯å®ç°å¯æ³›åŒ–å’Œé«˜æ•ˆçš„è¯­ä¹‰å¯¼èˆªèƒ½åŠ›çš„ä¸€ç§éå¸¸æœ‰æ•ˆçš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººå¦‚ä½•åœ¨å¤æ‚ç¯å¢ƒä¸­ï¼Œæ ¹æ®è‡ªç”±æ–‡æœ¬æè¿°çš„ç›®æ ‡ï¼Œè¿›è¡Œé«˜æ•ˆä¸”æ³›åŒ–çš„å¯¼èˆªé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºé›¶æ ·æœ¬è¿ç§»æˆ–å°†VLMç”¨äºåœ°å›¾æ ‡æ³¨ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨VLMçš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œä¸”æ³›åŒ–æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç›´æ¥å°†é¢„è®­ç»ƒçš„VLMå¾®è°ƒä¸ºå¯¼èˆªç­–ç•¥ã€‚é€šè¿‡åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„å…·èº«å­¦ä¹ ï¼Œä½¿VLMèƒ½å¤Ÿå°†é¢„è®­ç»ƒçš„çŸ¥è¯†ä¸å¯¼èˆªä»»åŠ¡ä¸­çš„è§†è§‰æ¨¡å¼å’Œç¯å¢ƒåŠ¨æ€ç›¸ç»“åˆï¼Œä»è€Œå®ç°æ›´é«˜æ•ˆå’Œæ³›åŒ–çš„å¯¼èˆªã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFiLM-Navçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1) è§†è§‰è¾“å…¥æ¨¡å—ï¼Œç”¨äºå¤„ç†æ¥è‡ªæœºå™¨äººçš„è§†è§‰è½¨è¿¹å†å²ï¼›2) è¯­è¨€è¾“å…¥æ¨¡å—ï¼Œç”¨äºå¤„ç†å¯¼èˆªç›®æ ‡çš„æ–‡æœ¬æè¿°ï¼›3) VLMï¼Œä½œä¸ºæ ¸å¿ƒå†³ç­–æ¨¡å—ï¼Œæ¥æ”¶è§†è§‰å’Œè¯­è¨€è¾“å…¥ï¼Œå¹¶è¾“å‡ºä¸‹ä¸€æ­¥çš„å¯¼èˆªåŠ¨ä½œï¼›4) è®­ç»ƒæ¨¡å—ï¼Œé€šè¿‡åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è¿›è¡Œå¼ºåŒ–å­¦ä¹ æˆ–ç›‘ç£å­¦ä¹ ï¼Œå¾®è°ƒVLMçš„å‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºç›´æ¥å°†VLMä½œä¸ºå¯¼èˆªç­–ç•¥è¿›è¡Œå¾®è°ƒã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒFiLM-Navèƒ½å¤Ÿæ›´å……åˆ†åœ°åˆ©ç”¨VLMçš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œå¹¶å°†å…¶ä¸å¯¼èˆªä»»åŠ¡çš„ç‰¹å®šéœ€æ±‚ç›¸ç»“åˆã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨å¤šæ ·åŒ–çš„æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼ŒFiLM-Navèƒ½å¤Ÿå®ç°æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨Transformeræ¶æ„çš„VLMä½œä¸ºå¯¼èˆªç­–ç•¥ï¼›2) è®¾è®¡åˆé€‚çš„è§†è§‰å’Œè¯­è¨€è¾“å…¥è¡¨ç¤ºï¼Œä»¥ä¾¿VLMèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†è¿™äº›ä¿¡æ¯ï¼›3) ä½¿ç”¨å¤šæ ·åŒ–çš„æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼ŒåŒ…æ‹¬ObjectNavã€OVONã€ImageNavå’Œè¾…åŠ©ç©ºé—´æ¨ç†ä»»åŠ¡ï¼›4) é‡‡ç”¨åˆé€‚çš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•ï¼Œä»¥æœ‰æ•ˆåœ°è®­ç»ƒVLMã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

FiLM-Navåœ¨HM3D ObjectNavä»»åŠ¡ä¸Šï¼Œç›¸è¾ƒäºå¼€æ”¾è¯æ±‡æ–¹æ³•ï¼Œå–å¾—äº†SPLå’ŒæˆåŠŸç‡çš„æ–°SOTAã€‚åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„HM3D-OVONåŸºå‡†æµ‹è¯•ä¸­ï¼ŒFiLM-Navä¹Ÿå®ç°äº†SOTA SPLï¼Œè¯æ˜äº†å…¶åœ¨æœªè§è¿‡çš„ç‰©ä½“ç±»åˆ«ä¸Šçš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼Œç›´æ¥å¾®è°ƒVLMæ˜¯ä¸€ç§æœ‰æ•ˆçš„è¯­ä¹‰å¯¼èˆªæ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FiLM-NavæŠ€æœ¯å¯åº”ç”¨äºå®¶åº­æœåŠ¡æœºå™¨äººã€ä»“å‚¨ç‰©æµæœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå®¶åº­æœåŠ¡æœºå™¨äººå¯ä»¥æ ¹æ®ç”¨æˆ·çš„è¯­éŸ³æŒ‡ä»¤ï¼Œåœ¨å®¤å†…ç¯å¢ƒä¸­æ‰¾åˆ°æŒ‡å®šçš„ç‰©å“ã€‚è¯¥ç ”ç©¶çš„å®é™…ä»·å€¼åœ¨äºæå‡äº†æœºå™¨äººçš„è‡ªä¸»å¯¼èˆªèƒ½åŠ›å’Œç¯å¢ƒé€‚åº”æ€§ï¼Œæœªæ¥æœ‰æœ›å®ç°æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„æœºå™¨äººæœåŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Enabling robotic assistants to navigate complex environments and locate objects described in free-form language is a critical capability for real-world deployment. While foundation models, particularly Vision-Language Models (VLMs), offer powerful semantic understanding, effectively adapting their web-scale knowledge for embodied decision-making remains a key challenge. We present FiLM-Nav (Fine-tuned Language Model for Navigation), an approach that directly fine-tunes pre-trained VLM as the navigation policy. In contrast to methods that use foundation models primarily in a zero-shot manner or for map annotation, FiLM-Nav learns to select the next best exploration frontier by conditioning directly on raw visual trajectory history and the navigation goal. Leveraging targeted simulated embodied experience allows the VLM to ground its powerful pre-trained representations in the specific dynamics and visual patterns relevant to goal-driven navigation. Critically, fine-tuning on a diverse data mixture combining ObjectNav, OVON, ImageNav, and an auxiliary spatial reasoning task proves essential for achieving robustness and broad generalization. FiLM-Nav sets a new state-of-the-art in both SPL and success rate on HM3D ObjectNav among open-vocabulary methods, and sets a state-of-the-art SPL on the challenging HM3D-OVON benchmark, demonstrating strong generalization to unseen object categories. Our work validates that directly fine-tuning VLMs on diverse simulated embodied data is a highly effective pathway towards generalizable and efficient semantic navigation capabilities.

