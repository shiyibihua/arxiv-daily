---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-09-19
---

# cs.ROï¼ˆ2025-09-19ï¼‰

ğŸ“Š å…± **24** ç¯‡è®ºæ–‡
 | ğŸ”— **5** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (17 ğŸ”—4)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (17 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250915607v2-primt-preference-based-reinforcement-learning-with-multimodal-feedba.html">PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models</a></td>
  <td>PRIMTï¼šåˆ©ç”¨å¤šæ¨¡æ€åé¦ˆå’Œè½¨è¿¹åˆæˆï¼Œæå‡åŸºäºåå¥½çš„å¼ºåŒ–å­¦ä¹ æ•ˆæœ</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span> <span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15607v2" data-paper-url="./papers/250915607v2-primt-preference-based-reinforcement-learning-with-multimodal-feedba.html" onclick="toggleFavorite(this, '2509.15607v2', 'PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250916061v1-latent-conditioned-loco-manipulation-using-motion-priors.html">Latent Conditioned Loco-Manipulation Using Motion Priors</a></td>
  <td>æå‡ºåŸºäºè¿åŠ¨å…ˆéªŒçš„æ½œåœ¨æ¡ä»¶Loco-Manipulationæ–¹æ³•ï¼Œç”¨äºäººå½¢å’Œå››è¶³æœºå™¨äººçš„å¤æ‚ä»»åŠ¡æ§åˆ¶</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">humanoid</span> <span class="paper-tag">manipulation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16061v1" data-paper-url="./papers/250916061v1-latent-conditioned-loco-manipulation-using-motion-priors.html" onclick="toggleFavorite(this, '2509.16061v1', 'Latent Conditioned Loco-Manipulation Using Motion Priors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250915937v1-a-vision-language-action-critic-model-for-robotic-real-world-reinfor.html">A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning</a></td>
  <td>æå‡ºåŸºäºè§†è§‰-è¯­è¨€-åŠ¨ä½œ-è¯„ä»·æ¨¡å‹çš„VLACï¼Œç”¨äºæå‡æœºå™¨äººçœŸå®ä¸–ç•Œå¼ºåŒ–å­¦ä¹ çš„æ•ˆç‡å’ŒæˆåŠŸç‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">vision-language-action</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15937v1" data-paper-url="./papers/250915937v1-a-vision-language-action-critic-model-for-robotic-real-world-reinfor.html" onclick="toggleFavorite(this, '2509.15937v1', 'A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250915600v1-orb-operating-room-bot-automating-operating-room-logistics-through-m.html">ORB: Operating Room Bot, Automating Operating Room Logistics through Mobile Manipulation</a></td>
  <td>ORBï¼šæå‡ºä¸€ç§åŸºäºç§»åŠ¨æ“ä½œçš„æœºå™¨äººç³»ç»Ÿï¼Œç”¨äºè‡ªåŠ¨åŒ–æ‰‹æœ¯å®¤ç‰©æµã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">mobile manipulation</span> <span class="paper-tag">trajectory optimization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15600v1" data-paper-url="./papers/250915600v1-orb-operating-room-bot-automating-operating-room-logistics-through-m.html" onclick="toggleFavorite(this, '2509.15600v1', 'ORB: Operating Room Bot, Automating Operating Room Logistics through Mobile Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250916398v1-dynamic-objects-relocalization-in-changing-environments-with-flow-ma.html">Dynamic Objects Relocalization in Changing Environments with Flow Matching</a></td>
  <td>æå‡ºåŸºäºFlow Matchingçš„FlowMapsæ¨¡å‹ï¼Œç”¨äºåŠ¨æ€ç¯å¢ƒä¸­ç‰©ä½“é‡å®šä½</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span> <span class="paper-tag">flow matching</span> <span class="paper-tag">human-object interaction</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16398v1" data-paper-url="./papers/250916398v1-dynamic-objects-relocalization-in-changing-environments-with-flow-ma.html" onclick="toggleFavorite(this, '2509.16398v1', 'Dynamic Objects Relocalization in Changing Environments with Flow Matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250915582v2-momentum-constrained-hybrid-heuristic-trajectory-optimization-framew.html">Momentum-constrained Hybrid Heuristic Trajectory Optimization Framework with Residual-enhanced DRL for Visually Impaired Scenarios</a></td>
  <td>é’ˆå¯¹è§†éšœäººå£«ï¼Œæå‡ºåŠ¨é‡çº¦æŸæ··åˆå¯å‘å¼è½¨è¿¹ä¼˜åŒ–æ¡†æ¶ï¼Œç»“åˆæ®‹å·®å¢å¼ºDRLã€‚</td>
  <td class="tags-cell"><span class="paper-tag">trajectory optimization</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15582v2" data-paper-url="./papers/250915582v2-momentum-constrained-hybrid-heuristic-trajectory-optimization-framew.html" onclick="toggleFavorite(this, '2509.15582v2', 'Momentum-constrained Hybrid Heuristic Trajectory Optimization Framework with Residual-enhanced DRL for Visually Impaired Scenarios')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250916469v1-a-framework-for-optimal-ankle-design-of-humanoid-robots.html">A Framework for Optimal Ankle Design of Humanoid Robots</a></td>
  <td>æå‡ºäººå½¢æœºå™¨äººè¸å…³èŠ‚ä¼˜åŒ–æ¡†æ¶ï¼Œæå‡åœ°é¢äº¤äº’çš„å®‰å…¨æ€§å’Œæ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16469v1" data-paper-url="./papers/250916469v1-a-framework-for-optimal-ankle-design-of-humanoid-robots.html" onclick="toggleFavorite(this, '2509.16469v1', 'A Framework for Optimal Ankle Design of Humanoid Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250916063v2-dspv2-improved-dense-policy-for-effective-and-generalizable-whole-bo.html">DSPv2: Improved Dense Policy for Effective and Generalizable Whole-body Mobile Manipulation</a></td>
  <td>DSPv2ï¼šæ”¹è¿›çš„å¯†é›†ç­–ç•¥ï¼Œç”¨äºæœ‰æ•ˆä¸”æ³›åŒ–çš„å…¨èº«ç§»åŠ¨æ“ä½œ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">mobile manipulation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16063v2" data-paper-url="./papers/250916063v2-dspv2-improved-dense-policy-for-effective-and-generalizable-whole-bo.html" onclick="toggleFavorite(this, '2509.16063v2', 'DSPv2: Improved Dense Policy for Effective and Generalizable Whole-body Mobile Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250915880v1-improving-robotic-manipulation-with-efficient-geometry-aware-vision-.html">Improving Robotic Manipulation with Efficient Geometry-Aware Vision Encoder</a></td>
  <td>æå‡ºé«˜æ•ˆå‡ ä½•æ„ŸçŸ¥è§†è§‰ç¼–ç å™¨eVGGTï¼Œæå‡æœºå™¨äººæ“ä½œæ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">bi-manual</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15880v1" data-paper-url="./papers/250915880v1-improving-robotic-manipulation-with-efficient-geometry-aware-vision-.html" onclick="toggleFavorite(this, '2509.15880v1', 'Improving Robotic Manipulation with Efficient Geometry-Aware Vision Encoder')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250916136v1-reward-evolution-with-graph-of-thoughts-a-bi-level-language-model-fr.html">Reward Evolution with Graph-of-Thoughts: A Bi-Level Language Model Framework for Reinforcement Learning</a></td>
  <td>æå‡ºRE-GoTæ¡†æ¶ï¼Œåˆ©ç”¨å›¾æ¨ç†å’Œè§†è§‰åé¦ˆå®ç°å¼ºåŒ–å­¦ä¹ ä¸­å¥–åŠ±å‡½æ•°çš„è‡ªåŠ¨è¿›åŒ–ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">reward design</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16136v1" data-paper-url="./papers/250916136v1-reward-evolution-with-graph-of-thoughts-a-bi-level-language-model-fr.html" onclick="toggleFavorite(this, '2509.16136v1', 'Reward Evolution with Graph-of-Thoughts: A Bi-Level Language Model Framework for Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250915953v1-right-side-out-learning-zero-shot-sim-to-real-garment-reversal.html">Right-Side-Out: Learning Zero-Shot Sim-to-Real Garment Reversal</a></td>
  <td>æå‡ºRight-Side-Outæ¡†æ¶ï¼Œè§£å†³æœè£…ç¿»è½¬ä¸­é›¶æ ·æœ¬Sim-to-Realéš¾é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">bi-manual</span> <span class="paper-tag">sim-to-real</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15953v1" data-paper-url="./papers/250915953v1-right-side-out-learning-zero-shot-sim-to-real-garment-reversal.html" onclick="toggleFavorite(this, '2509.15953v1', 'Right-Side-Out: Learning Zero-Shot Sim-to-Real Garment Reversal')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250915917v1-an-mpc-framework-for-efficient-navigation-of-mobile-robots-in-clutte.html">An MPC framework for efficient navigation of mobile robots in cluttered environments</a></td>
  <td>æå‡ºä¸€ç§MPCæ¡†æ¶ï¼Œç”¨äºç§»åŠ¨æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­é«˜æ•ˆå¯¼èˆª</td>
  <td class="tags-cell"><span class="paper-tag">MPC</span> <span class="paper-tag">model predictive control</span> <span class="paper-tag">trajectory optimization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15917v1" data-paper-url="./papers/250915917v1-an-mpc-framework-for-efficient-navigation-of-mobile-robots-in-clutte.html" onclick="toggleFavorite(this, '2509.15917v1', 'An MPC framework for efficient navigation of mobile robots in cluttered environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250915733v1-gp3-a-3d-geometry-aware-policy-with-multi-view-images-for-robotic-ma.html">GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation</a></td>
  <td>GP3ï¼šä¸€ç§åˆ©ç”¨å¤šè§†è§’å›¾åƒè¿›è¡Œæœºå™¨äººæ“ä½œçš„3Då‡ ä½•æ„ŸçŸ¥ç­–ç•¥</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15733v1" data-paper-url="./papers/250915733v1-gp3-a-3d-geometry-aware-policy-with-multi-view-images-for-robotic-ma.html" onclick="toggleFavorite(this, '2509.15733v1', 'GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250915717v1-imagination-at-inference-synthesizing-in-hand-views-for-robust-visuo.html">Imagination at Inference: Synthesizing In-Hand Views for Robust Visuomotor Policy Inference</a></td>
  <td>æå‡ºåŸºäºæ‰©æ•£æ¨¡å‹çš„æ¨ç†æœŸè§†è§’åˆæˆæ–¹æ³•ï¼Œæå‡æœºå™¨äººæ“ä½œç­–ç•¥çš„é²æ£’æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">Unitree</span> <span class="paper-tag">egocentric</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15717v1" data-paper-url="./papers/250915717v1-imagination-at-inference-synthesizing-in-hand-views-for-robust-visuo.html" onclick="toggleFavorite(this, '2509.15717v1', 'Imagination at Inference: Synthesizing In-Hand Views for Robust Visuomotor Policy Inference')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250916072v2-i-failsense-towards-general-robotic-failure-detection-with-vision-la.html">I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models</a></td>
  <td>I-FailSenseï¼šåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹å®ç°é€šç”¨æœºå™¨äººæ•…éšœæ£€æµ‹</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">language conditioned</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16072v2" data-paper-url="./papers/250916072v2-i-failsense-towards-general-robotic-failure-detection-with-vision-la.html" onclick="toggleFavorite(this, '2509.16072v2', 'I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250916032v1-a-matter-of-height-the-impact-of-a-robotic-object-on-human-complianc.html">A Matter of Height: The Impact of a Robotic Object on Human Compliance</a></td>
  <td>ç ”ç©¶æœºå™¨äººé«˜åº¦å¯¹äººç±»é¡ºä»æ€§çš„å½±å“ï¼Œå‘ç°ä¸äººé™…äº’åŠ¨ç›¸åçš„æ¨¡å¼ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16032v1" data-paper-url="./papers/250916032v1-a-matter-of-height-the-impact-of-a-robotic-object-on-human-complianc.html" onclick="toggleFavorite(this, '2509.16032v1', 'A Matter of Height: The Impact of a Robotic Object on Human Compliance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250916053v1-compose-by-focus-scene-graph-based-atomic-skills.html">Compose by Focus: Scene Graph-based Atomic Skills</a></td>
  <td>æå‡ºåŸºäºåœºæ™¯å›¾çš„åŸå­æŠ€èƒ½å­¦ä¹ æ¡†æ¶ï¼Œæå‡æœºå™¨äººç»„åˆæ³›åŒ–èƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16053v1" data-paper-url="./papers/250916053v1-compose-by-focus-scene-graph-based-atomic-skills.html" onclick="toggleFavorite(this, '2509.16053v1', 'Compose by Focus: Scene Graph-based Atomic Skills')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>18</td>
  <td><a href="./papers/250916176v1-agentic-aerial-cinematography-from-dialogue-cues-to-cinematic-trajec.html">Agentic Aerial Cinematography: From Dialogue Cues to Cinematic Trajectories</a></td>
  <td>ACDCï¼šæå‡ºä¸€ç§åŸºäºå¯¹è¯æç¤ºçš„è‡ªä¸»æ— äººæœºç”µå½±æ‘„å½±ç³»ç»Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span> <span class="paper-tag">embodied AI</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16176v1" data-paper-url="./papers/250916176v1-agentic-aerial-cinematography-from-dialogue-cues-to-cinematic-trajec.html" onclick="toggleFavorite(this, '2509.16176v1', 'Agentic Aerial Cinematography: From Dialogue Cues to Cinematic Trajectories')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250916445v1-film-nav-efficient-and-generalizable-navigation-via-vlm-fine-tuning.html">FiLM-Nav: Efficient and Generalizable Navigation via VLM Fine-tuning</a></td>
  <td>FiLM-Navï¼šé€šè¿‡VLMå¾®è°ƒå®ç°é«˜æ•ˆä¸”æ³›åŒ–çš„å¯¼èˆª</td>
  <td class="tags-cell"><span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16445v1" data-paper-url="./papers/250916445v1-film-nav-efficient-and-generalizable-navigation-via-vlm-fine-tuning.html" onclick="toggleFavorite(this, '2509.16445v1', 'FiLM-Nav: Efficient and Generalizable Navigation via VLM Fine-tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250915673v2-omni-livo-robust-rgb-colored-multi-camera-visual-inertial-lidar-odom.html">Omni-LIVO: Robust RGB-Colored Multi-Camera Visual-Inertial-LiDAR Odometry via Photometric Migration and ESIKF Fusion</a></td>
  <td>Omni-LIVOï¼šåŸºäºå…‰åº¦è¿ç§»å’ŒESIKFèåˆçš„é²æ£’RGBå½©è‰²å¤šç›¸æœºè§†è§‰-æƒ¯æ€§-æ¿€å…‰é›·è¾¾é‡Œç¨‹è®¡</td>
  <td class="tags-cell"><span class="paper-tag">visual odometry</span> <span class="paper-tag">LIO</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15673v2" data-paper-url="./papers/250915673v2-omni-livo-robust-rgb-colored-multi-camera-visual-inertial-lidar-odom.html" onclick="toggleFavorite(this, '2509.15673v2', 'Omni-LIVO: Robust RGB-Colored Multi-Camera Visual-Inertial-LiDAR Odometry via Photometric Migration and ESIKF Fusion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/250915968v1-corevla-a-dual-stage-end-to-end-autonomous-driving-framework-for-lon.html">CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine</a></td>
  <td>CoReVLAï¼šé€šè¿‡æ”¶é›†ä¸ä¼˜åŒ–åŒé˜¶æ®µå­¦ä¹ ï¼Œæå‡é•¿å°¾åœºæ™¯ä¸‹ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">DPO</span> <span class="paper-tag">direct preference optimization</span> <span class="paper-tag">VLA</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15968v1" data-paper-url="./papers/250915968v1-corevla-a-dual-stage-end-to-end-autonomous-driving-framework-for-lon.html" onclick="toggleFavorite(this, '2509.15968v1', 'CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250916434v1-end-to-end-rl-improves-dexterous-grasping-policies.html">End-to-end RL Improves Dexterous Grasping Policies</a></td>
  <td>æå‡ºè§£è€¦æ¨¡æ‹Ÿå™¨ä¸å¼ºåŒ–å­¦ä¹ çš„æ¶æ„ï¼Œæå‡çµå·§æŠ“å–çš„ç«¯åˆ°ç«¯ç­–ç•¥å­¦ä¹ æ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">PPO</span> <span class="paper-tag">distillation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16434v1" data-paper-url="./papers/250916434v1-end-to-end-rl-improves-dexterous-grasping-policies.html" onclick="toggleFavorite(this, '2509.16434v1', 'End-to-end RL Improves Dexterous Grasping Policies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>23</td>
  <td><a href="./papers/250916006v1-defining-and-monitoring-complex-robot-activities-via-llms-and-symbol.html">Defining and Monitoring Complex Robot Activities via LLMs and Symbolic Reasoning</a></td>
  <td>æå‡ºåŸºäºLLMå’Œç¬¦å·æ¨ç†çš„æœºå™¨äººæ´»åŠ¨å®šä¹‰ä¸ç›‘æ§æ¡†æ¶ï¼Œåº”ç”¨äºå†œä¸šåœºæ™¯ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16006v1" data-paper-url="./papers/250916006v1-defining-and-monitoring-complex-robot-activities-via-llms-and-symbol.html" onclick="toggleFavorite(this, '2509.16006v1', 'Defining and Monitoring Complex Robot Activities via LLMs and Symbolic Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250915565v1-distribution-estimation-for-global-data-association-via-approximate-.html">Distribution Estimation for Global Data Association via Approximate Bayesian Inference</a></td>
  <td>æå‡ºåŸºäºè¿‘ä¼¼è´å¶æ–¯æ¨æ–­çš„å…¨å±€æ•°æ®å…³è”æ–¹æ³•ï¼Œè§£å†³å¤šæ¨¡æ€åˆ†å¸ƒä¸‹çš„åŒ¹é…é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15565v1" data-paper-url="./papers/250915565v1-distribution-estimation-for-global-data-association-via-approximate-.html" onclick="toggleFavorite(this, '2509.15565v1', 'Distribution Estimation for Global Data Association via Approximate Bayesian Inference')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)