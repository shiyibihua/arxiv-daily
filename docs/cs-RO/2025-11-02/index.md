---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-11-02
---

# cs.ROï¼ˆ2025-11-02ï¼‰

ğŸ“Š å…± **11** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (8)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (8 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251100840v2-heuristic-step-planning-for-learning-dynamic-bipedal-locomotion-a-co.html">Heuristic Step Planning for Learning Dynamic Bipedal Locomotion: A Comparative Study of Model-Based and Model-Free Approaches</a></td>
  <td>æå‡ºåŸºäºå¯å‘å¼æ­¥æ€è§„åˆ’çš„åŠ¨æ€åŒè¶³è¿åŠ¨å­¦ä¹ æ¡†æ¶ï¼Œæå‡é²æ£’æ€§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.00840v2" onclick="toggleFavorite(this, '2511.00840v2', 'Heuristic Step Planning for Learning Dynamic Bipedal Locomotion: A Comparative Study of Model-Based and Model-Free Approaches')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251100998v1-gaudp-reinventing-multi-agent-collaboration-through-gaussian-image-s.html">GauDP: Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies</a></td>
  <td>GauDPï¼šé€šè¿‡é«˜æ–¯å›¾åƒååŒçš„æ‰©æ•£ç­–ç•¥é‡å¡‘å¤šæ™ºèƒ½ä½“åä½œ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.00998v1" onclick="toggleFavorite(this, '2511.00998v1', 'GauDP: Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251100814v1-real-time-learning-of-predictive-dynamic-obstacle-models-for-robotic.html">Real-Time Learning of Predictive Dynamic Obstacle Models for Robotic Motion Planning</a></td>
  <td>æå‡ºä¸€ç§åŸºäºHankel-DMDçš„å®æ—¶åŠ¨æ€éšœç¢ç‰©é¢„æµ‹æ¨¡å‹ï¼Œç”¨äºæœºå™¨äººè¿åŠ¨è§„åˆ’ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.00814v1" onclick="toggleFavorite(this, '2511.00814v1', 'Real-Time Learning of Predictive Dynamic Obstacle Models for Robotic Motion Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251100783v2-when-semantics-connect-the-swarm-llm-driven-fuzzy-control-for-cooper.html">When Semantics Connect the Swarm: LLM-Driven Fuzzy Control for Cooperative Multi-Robot Underwater Coverage</a></td>
  <td>æå‡ºåŸºäºLLMçš„æ¨¡ç³Šæ§åˆ¶æ¡†æ¶ï¼Œè§£å†³æ°´ä¸‹å¤šæœºå™¨äººååŒè¦†ç›–é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.00783v2" onclick="toggleFavorite(this, '2511.00783v2', 'When Semantics Connect the Swarm: LLM-Driven Fuzzy Control for Cooperative Multi-Robot Underwater Coverage')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251100940v1-urdf-anything-constructing-articulated-objects-with-3d-multimodal-la.html">URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model</a></td>
  <td>URDF-Anythingï¼šåŸºäº3Då¤šæ¨¡æ€è¯­è¨€æ¨¡å‹æ„å»ºå¯åŠ¨å¯¹è±¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.00940v1" onclick="toggleFavorite(this, '2511.00940v1', 'URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251100917v2-maestro-orchestrating-robotics-modules-with-vision-language-models-f.html">Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots</a></td>
  <td>Maestroï¼šåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹ç¼–æ’æœºå™¨äººæ¨¡å—ï¼Œå®ç°é›¶æ ·æœ¬é€šç”¨æœºå™¨äºº</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.00917v2" onclick="toggleFavorite(this, '2511.00917v2', 'Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251101107v1-slap-shortcut-learning-for-abstract-planning.html">SLAP: Shortcut Learning for Abstract Planning</a></td>
  <td>SLAPï¼šé€šè¿‡å­¦ä¹ æŠ½è±¡è§„åˆ’æ·å¾„ï¼Œæå‡æœºå™¨äººé•¿æ—¶ç¨‹å†³ç­–èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.01107v1" onclick="toggleFavorite(this, '2511.01107v1', 'SLAP: Shortcut Learning for Abstract Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251200022v1-xflowmp-task-conditioned-motion-fields-for-generative-robot-planning.html">XFlowMP: Task-Conditioned Motion Fields for Generative Robot Planning with Schrodinger Bridges</a></td>
  <td>æå‡ºXFlowMPï¼Œåˆ©ç”¨è–›å®šè°”æ¡¥è§£å†³ä»»åŠ¡æ¡ä»¶ä¸‹çš„ç”Ÿæˆå¼æœºå™¨äººè¿åŠ¨è§„åˆ’é—®é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00022v1" onclick="toggleFavorite(this, '2512.00022v1', 'XFlowMP: Task-Conditioned Motion Fields for Generative Robot Planning with Schrodinger Bridges')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>9</td>
  <td><a href="./papers/251100933v1-fast-smartway-panoramic-free-end-to-end-zero-shot-vision-and-languag.html">Fast-SmartWay: Panoramic-Free End-to-End Zero-Shot Vision-and-Language Navigation</a></td>
  <td>æå‡ºFast-SmartWayï¼Œè§£å†³é›¶æ ·æœ¬è§†è§‰è¯­è¨€å¯¼èˆªä¸­å®æ—¶æ€§å’Œå…¨å±€è§„åˆ’é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.00933v1" onclick="toggleFavorite(this, '2511.00933v1', 'Fast-SmartWay: Panoramic-Free End-to-End Zero-Shot Vision-and-Language Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251100934v1-pacstl-pac-bounded-signal-temporal-logic-from-data-driven-reachabili.html">pacSTL: PAC-Bounded Signal Temporal Logic from Data-Driven Reachability Analysis</a></td>
  <td>æå‡ºpacSTLæ¡†æ¶ï¼Œç»“åˆPACç•Œå®šé›†åˆé¢„æµ‹ä¸STLåŒºé—´æ‰©å±•ï¼Œè§£å†³ä¸ç¡®å®šæ€§ä¸‹çš„æœºå™¨äººç³»ç»Ÿå®‰å…¨éœ€æ±‚é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.00934v1" onclick="toggleFavorite(this, '2511.00934v1', 'pacSTL: PAC-Bounded Signal Temporal Logic from Data-Driven Reachability Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>11</td>
  <td><a href="./papers/251101083v1-deployable-vision-driven-uav-river-navigation-via-human-in-the-loop-.html">Deployable Vision-driven UAV River Navigation via Human-in-the-loop Preference Alignment</a></td>
  <td>æå‡ºSPAR-Hç®—æ³•ï¼Œé€šè¿‡äººæœºååŒåå¥½å¯¹é½å®ç°è§†è§‰é©±åŠ¨çš„æ— äººæœºæ²³æµå¯¼èˆª</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.01083v1" onclick="toggleFavorite(this, '2511.01083v1', 'Deployable Vision-driven UAV River Navigation via Human-in-the-loop Preference Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)