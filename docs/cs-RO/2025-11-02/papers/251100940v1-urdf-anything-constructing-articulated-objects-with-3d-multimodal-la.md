---
layout: default
title: URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model
---

# URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model

**arXiv**: [2511.00940v1](https://arxiv.org/abs/2511.00940) | [PDF](https://arxiv.org/pdf/2511.00940.pdf)

**ä½œè€…**: Zhe Li, Xiang Bai, Jieyu Zhang, Zhuangzhe Wu, Che Xu, Ying Li, Chengkai Hou, Shanghang Zhang

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-02

**å¤‡æ³¨**: Accepted to the 39th Conference on Neural Information Processing Systems (NeurIPS 2025)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**URDF-Anythingï¼šåŸºäºŽ3Då¤šæ¨¡æ€è¯­è¨€æ¨¡åž‹æž„å»ºå¯åŠ¨å¯¹è±¡**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å¯åŠ¨å¯¹è±¡` `æ•°å­—å­ªç”Ÿ` `3Då¤šæ¨¡æ€LLM` `ç‚¹äº‘å¤„ç†` `è¿åŠ¨å­¦å‚æ•°ä¼°è®¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨æž„å»ºå¯åŠ¨å¯¹è±¡æ•°å­—å­ªç”Ÿæ—¶ï¼Œéœ€è¦è€—æ—¶çš„äººå·¥å»ºæ¨¡æˆ–å¤æ‚çš„å¤šé˜¶æ®µæµç¨‹ï¼Œæ•ˆçŽ‡ä½Žä¸‹ã€‚
2. URDF-Anythingåˆ©ç”¨3Då¤šæ¨¡æ€LLMï¼Œé€šè¿‡ç‚¹äº‘å’Œæ–‡æœ¬è¾“å…¥ï¼Œè‡ªå›žå½’é¢„æµ‹å‡ ä½•åˆ†å‰²å’Œè¿åŠ¨å­¦å‚æ•°ï¼Œå®žçŽ°ç«¯åˆ°ç«¯è‡ªåŠ¨é‡å»ºã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒURDF-Anythingåœ¨å‡ ä½•åˆ†å‰²ã€è¿åŠ¨å­¦å‚æ•°é¢„æµ‹å’Œç‰©ç†å¯æ‰§è¡Œæ€§æ–¹é¢å‡æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºURDF-Anythingï¼Œä¸€ä¸ªåŸºäºŽ3Då¤šæ¨¡æ€å¤§åž‹è¯­è¨€æ¨¡åž‹(MLLM)çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é‡å»ºæ¡†æž¶ï¼Œç”¨äºŽæž„å»ºå¯åŠ¨å¯¹è±¡çš„ç²¾ç¡®æ•°å­—å­ªç”Ÿã€‚è¯¥æ¡†æž¶é‡‡ç”¨åŸºäºŽç‚¹äº‘å’Œæ–‡æœ¬å¤šæ¨¡æ€è¾“å…¥çš„è‡ªå›žå½’é¢„æµ‹ï¼Œè”åˆä¼˜åŒ–å‡ ä½•åˆ†å‰²å’Œè¿åŠ¨å­¦å‚æ•°é¢„æµ‹ã€‚å®ƒå®žçŽ°äº†ä¸€ç§ç‰¹æ®Šçš„$[SEG]$ tokenæœºåˆ¶ï¼Œç›´æŽ¥ä¸Žç‚¹äº‘ç‰¹å¾äº¤äº’ï¼Œå®žçŽ°ç»†ç²’åº¦çš„éƒ¨ä»¶çº§åˆ†å‰²ï¼ŒåŒæ—¶ä¿æŒä¸Žè¿åŠ¨å­¦å‚æ•°é¢„æµ‹çš„ä¸€è‡´æ€§ã€‚åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨å‡ ä½•åˆ†å‰²ï¼ˆmIoUæå‡17%ï¼‰ã€è¿åŠ¨å­¦å‚æ•°é¢„æµ‹ï¼ˆå¹³å‡è¯¯å·®é™ä½Ž29%ï¼‰å’Œç‰©ç†å¯æ‰§è¡Œæ€§ï¼ˆè¶…è¿‡åŸºçº¿50%ï¼‰æ–¹é¢æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚è¯¥æ–¹æ³•è¡¨çŽ°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå³ä½¿åœ¨è®­ç»ƒé›†ä¹‹å¤–çš„å¯¹è±¡ä¸Šä¹Ÿèƒ½è¡¨çŽ°è‰¯å¥½ã€‚è¿™é¡¹å·¥ä½œä¸ºæœºå™¨äººä»¿çœŸæž„å»ºæ•°å­—å­ªç”Ÿæä¾›äº†ä¸€ç§æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œæ˜¾è‘—å¢žå¼ºäº†sim-to-realçš„è¿ç§»èƒ½åŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¯åŠ¨å¯¹è±¡æ•°å­—å­ªç”Ÿæž„å»ºçš„é—®é¢˜ï¼ŒçŽ°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºŽäººå·¥å»ºæ¨¡æˆ–å¤æ‚çš„å¤šé˜¶æ®µæµç¨‹ï¼Œæˆæœ¬é«˜æ˜‚ä¸”æ•ˆçŽ‡ä½Žä¸‹ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥è‡ªåŠ¨ã€ç²¾ç¡®åœ°é‡å»ºå¯¹è±¡çš„å‡ ä½•ç»“æž„å’Œè¿åŠ¨å­¦å‚æ•°ï¼Œé™åˆ¶äº†æœºå™¨äººåœ¨ä»¿çœŸçŽ¯å¢ƒä¸­çš„è®­ç»ƒå’Œå…·èº«æ™ºèƒ½ä¸–ç•Œæ¨¡åž‹çš„æž„å»ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨3Då¤šæ¨¡æ€å¤§åž‹è¯­è¨€æ¨¡åž‹(MLLM)ï¼Œå°†å‡ ä½•ä¿¡æ¯ï¼ˆç‚¹äº‘ï¼‰å’Œè¯­ä¹‰ä¿¡æ¯ï¼ˆæ–‡æœ¬æè¿°ï¼‰èžåˆï¼Œé€šè¿‡è‡ªå›žå½’é¢„æµ‹çš„æ–¹å¼ï¼ŒåŒæ—¶ä¼˜åŒ–å‡ ä½•åˆ†å‰²å’Œè¿åŠ¨å­¦å‚æ•°é¢„æµ‹ã€‚è¿™ç§ç«¯åˆ°ç«¯çš„æ–¹æ³•é¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­å¤æ‚çš„ä¸­é—´æ­¥éª¤ï¼Œæé«˜äº†é‡å»ºæ•ˆçŽ‡å’Œç²¾åº¦ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šURDF-Anythingçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¤šæ¨¡æ€è¾“å…¥æ¨¡å—ï¼šæŽ¥æ”¶ç‚¹äº‘å’Œæ–‡æœ¬æè¿°ä½œä¸ºè¾“å…¥ï¼›2) ç‰¹å¾æå–æ¨¡å—ï¼šæå–ç‚¹äº‘å’Œæ–‡æœ¬çš„ç‰¹å¾è¡¨ç¤ºï¼›3) è‡ªå›žå½’é¢„æµ‹æ¨¡å—ï¼šåŸºäºŽæå–çš„ç‰¹å¾ï¼Œè‡ªå›žå½’åœ°é¢„æµ‹éƒ¨ä»¶åˆ†å‰²ç»“æžœå’Œè¿åŠ¨å­¦å‚æ•°ï¼›4) $[SEG]$ tokenæœºåˆ¶ï¼šé€šè¿‡ç‰¹æ®Šçš„tokenä¸Žç‚¹äº‘ç‰¹å¾äº¤äº’ï¼Œå®žçŽ°ç»†ç²’åº¦çš„éƒ¨ä»¶çº§åˆ†å‰²ã€‚æ•´ä¸ªæµç¨‹æ˜¯ç«¯åˆ°ç«¯å¯è®­ç»ƒçš„ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå°†3Då¤šæ¨¡æ€LLMåº”ç”¨äºŽå¯åŠ¨å¯¹è±¡çš„æ•°å­—å­ªç”Ÿæž„å»ºï¼Œå¹¶æå‡ºäº†$[SEG]$ tokenæœºåˆ¶ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤ŸåŒæ—¶å¤„ç†å‡ ä½•å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œå®žçŽ°æ›´ç²¾ç¡®çš„éƒ¨ä»¶åˆ†å‰²å’Œè¿åŠ¨å­¦å‚æ•°é¢„æµ‹ã€‚$[SEG]$ tokenæœºåˆ¶å…è®¸æ¨¡åž‹ç›´æŽ¥æ“ä½œç‚¹äº‘ç‰¹å¾ï¼Œä»Žè€Œå®žçŽ°ç»†ç²’åº¦çš„åˆ†å‰²æŽ§åˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚æ–¹é¢ï¼Œè®ºæ–‡å¯èƒ½é‡‡ç”¨äº†Transformeræž¶æž„ä½œä¸ºLLMçš„åŸºç¡€ï¼Œå¹¶è®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥è”åˆä¼˜åŒ–å‡ ä½•åˆ†å‰²å’Œè¿åŠ¨å­¦å‚æ•°é¢„æµ‹ã€‚$[SEG]$ tokençš„å…·ä½“å®žçŽ°æ–¹å¼ï¼ˆä¾‹å¦‚ï¼Œå¦‚ä½•ä¸Žç‚¹äº‘ç‰¹å¾è¿›è¡Œäº¤äº’ï¼Œå¦‚ä½•å½±å“åˆ†å‰²ç»“æžœï¼‰æ˜¯å…³é”®çš„è®¾è®¡ç»†èŠ‚ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æž„éœ€è¦åœ¨è®ºæ–‡ä¸­è¿›ä¸€æ­¥æŸ¥æ‰¾ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

URDF-Anythingåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žä¸–ç•Œæ•°æ®é›†ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨å‡ ä½•åˆ†å‰²æ–¹é¢ï¼ŒmIoUæŒ‡æ ‡æå‡äº†17%ã€‚åœ¨è¿åŠ¨å­¦å‚æ•°é¢„æµ‹æ–¹é¢ï¼Œå¹³å‡è¯¯å·®é™ä½Žäº†29%ã€‚åœ¨ç‰©ç†å¯æ‰§è¡Œæ€§æ–¹é¢ï¼Œè¶…è¿‡åŸºçº¿æ–¹æ³•50%ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒURDF-Anythingèƒ½å¤Ÿæœ‰æ•ˆåœ°æž„å»ºå¯åŠ¨å¯¹è±¡çš„ç²¾ç¡®æ•°å­—å­ªç”Ÿï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

URDF-Anythingåœ¨æœºå™¨äººä»¿çœŸè®­ç»ƒã€å…·èº«æ™ºèƒ½ä¸–ç•Œæ¨¡åž‹æž„å»ºç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºŽå¿«é€Ÿæž„å»ºå„ç§å¯åŠ¨å¯¹è±¡çš„æ•°å­—å­ªç”Ÿï¼Œä»Žè€ŒåŠ é€Ÿæœºå™¨äººçš„å¼€å‘å’Œéƒ¨ç½²ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºŽè™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žç­‰é¢†åŸŸï¼Œä¸ºç”¨æˆ·æä¾›æ›´é€¼çœŸçš„äº¤äº’ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤æ‚çš„åœºæ™¯å’Œå¯¹è±¡ï¼Œä¾‹å¦‚äººä½“å»ºæ¨¡ã€å·¥ä¸šè‡ªåŠ¨åŒ–ç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Constructing accurate digital twins of articulated objects is essential for robotic simulation training and embodied AI world model building, yet historically requires painstaking manual modeling or multi-stage pipelines. In this work, we propose \textbf{URDF-Anything}, an end-to-end automatic reconstruction framework based on a 3D multimodal large language model (MLLM). URDF-Anything utilizes an autoregressive prediction framework based on point-cloud and text multimodal input to jointly optimize geometric segmentation and kinematic parameter prediction. It implements a specialized $[SEG]$ token mechanism that interacts directly with point cloud features, enabling fine-grained part-level segmentation while maintaining consistency with the kinematic parameter predictions. Experiments on both simulated and real-world datasets demonstrate that our method significantly outperforms existing approaches regarding geometric segmentation (mIoU 17\% improvement), kinematic parameter prediction (average error reduction of 29\%), and physical executability (surpassing baselines by 50\%). Notably, our method exhibits excellent generalization ability, performing well even on objects outside the training set. This work provides an efficient solution for constructing digital twins for robotic simulation, significantly enhancing the sim-to-real transfer capability.

