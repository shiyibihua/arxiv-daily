---
layout: default
title: World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training
---

# World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.24948" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.24948v3</a>
  <a href="https://arxiv.org/pdf/2509.24948.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.24948v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.24948v3', 'World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junjin Xiao, Yandan Yang, Xinyuan Chang, Ronghan Chen, Feng Xiong, Mu Xu, Wei-Shi Zheng, Qing Zhang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29 (æ›´æ–°: 2025-11-01)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/amap-cvlab/world-env)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWorld-Envï¼Œåˆ©ç”¨ä¸–ç•Œæ¨¡å‹ä½œä¸ºVLAæ¨¡å‹åè®­ç»ƒçš„è™šæ‹Ÿç¯å¢ƒï¼Œè§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹` `ä¸–ç•Œæ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `åè®­ç»ƒ` `æœºå™¨äººæ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. VLAæ¨¡å‹åœ¨æ•°æ®ç¨€ç¼ºæ—¶æ€§èƒ½ä¸‹é™ï¼Œä¸”çœŸå®ç¯å¢ƒäº¤äº’æˆæœ¬é«˜ã€é£é™©å¤§ï¼Œéš¾ä»¥è¿›è¡Œå¼ºåŒ–å­¦ä¹ åè®­ç»ƒã€‚
2. World-Envåˆ©ç”¨ä¸–ç•Œæ¨¡å‹æ„å»ºè™šæ‹Ÿç¯å¢ƒï¼Œé€šè¿‡VLMå¼•å¯¼çš„åå°„å™¨æä¾›å¥–åŠ±å’ŒåŠ¨ä½œç»ˆæ­¢ä¿¡å·ï¼Œå®ç°å®‰å…¨é«˜æ•ˆçš„åè®­ç»ƒã€‚
3. å®éªŒè¡¨æ˜ï¼ŒWorld-Envä»…éœ€å°‘é‡ä¸“å®¶æ¼”ç¤ºå³å¯æ˜¾è‘—æå‡VLAæ¨¡å‹åœ¨å¤æ‚æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹é€šè¿‡æ¨¡ä»¿å­¦ä¹ è®­ç»ƒï¼Œä½†åœ¨æ•°æ®ç¨€ç¼ºåœºæ™¯ä¸­ï¼Œç”±äºä¾èµ–å¤§è§„æ¨¡æ¼”ç¤ºæ•°æ®é›†ï¼Œæ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚è™½ç„¶åŸºäºå¼ºåŒ–å­¦ä¹ (RL)çš„åè®­ç»ƒå·²è¢«è¯æ˜èƒ½æœ‰æ•ˆè§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œä½†å…¶åœ¨VLAæ¨¡å‹ä¸Šçš„åº”ç”¨å—åˆ°çœŸå®ç¯å¢ƒä¸å¯é‡ç½®æ€§çš„é˜»ç¢ã€‚è¿™ç§é™åˆ¶åœ¨å·¥ä¸šè‡ªåŠ¨åŒ–ç­‰é«˜é£é™©é¢†åŸŸå°¤ä¸ºå…³é”®ï¼Œå› ä¸ºäº¤äº’é€šå¸¸ä¼šå¯¼è‡´çŠ¶æ€å˜åŒ–ï¼Œè€Œè¿™äº›å˜åŒ–çš„æ¢å¤æˆæœ¬é«˜æ˜‚æˆ–ä¸å¯è¡Œã€‚æ­¤å¤–ï¼Œç°æœ‰çš„VLAæ–¹æ³•ç¼ºä¹å¯é çš„ä»»åŠ¡å®Œæˆæ£€æµ‹æœºåˆ¶ï¼Œå¯¼è‡´å†—ä½™åŠ¨ä½œï¼Œé™ä½äº†æ•´ä½“ä»»åŠ¡æˆåŠŸç‡ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†World-Envï¼Œä¸€ä¸ªåŸºäºRLçš„åè®­ç»ƒæ¡†æ¶ï¼Œç”¨ä½æˆæœ¬çš„ã€åŸºäºä¸–ç•Œæ¨¡å‹çš„è™šæ‹Ÿæ¨¡æ‹Ÿå™¨å–ä»£ç‰©ç†äº¤äº’ã€‚World-EnvåŒ…å«ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼š(1)ä¸€ä¸ªåŸºäºè§†é¢‘çš„ä¸–ç•Œæ¨¡æ‹Ÿå™¨ï¼Œç”Ÿæˆæ—¶é—´ä¸Šä¸€è‡´çš„æœªæ¥è§†è§‰è§‚å¯Ÿï¼›(2)ä¸€ä¸ªè§†è§‰-è¯­è¨€æ¨¡å‹(VLM)å¼•å¯¼çš„å³æ—¶åå°„å™¨ï¼Œæä¾›è¿ç»­çš„å¥–åŠ±ä¿¡å·å¹¶é¢„æµ‹åŠ¨ä½œç»ˆæ­¢ã€‚è¿™ç§æ¨¡æ‹Ÿç¯å¢ƒä½¿VLAæ¨¡å‹èƒ½å¤Ÿå®‰å…¨åœ°æ¢ç´¢å¹¶æ³›åŒ–åˆ°å…¶åˆå§‹æ¨¡ä»¿å­¦ä¹ åˆ†å¸ƒä¹‹å¤–ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä»…éœ€æ¯ä¸ªä»»åŠ¡äº”ä¸ªä¸“å®¶æ¼”ç¤ºå³å¯å®ç°æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨å¤æ‚çš„æœºå™¨äººæ“ä½œä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒWorld-Envæœ‰æ•ˆåœ°å…‹æœäº†ä¼ ç»ŸVLAæ¨¡å‹ä¾èµ–çœŸå®ä¸–ç•Œäº¤äº’çš„æ•°æ®æ•ˆç‡ä½ã€å®‰å…¨çº¦æŸå’Œæ‰§è¡Œæ•ˆç‡ä½çš„é—®é¢˜ï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒä¸­çš„åè®­ç»ƒæä¾›äº†ä¸€ç§å®ç”¨ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šVLAæ¨¡å‹ä¾èµ–å¤§é‡æ¼”ç¤ºæ•°æ®ï¼Œåœ¨æ•°æ®ç¨€ç¼ºåœºæ™¯ä¸‹æ³›åŒ–èƒ½åŠ›å·®ã€‚ç›´æ¥åœ¨çœŸå®ç¯å¢ƒä¸­è¿›è¡Œå¼ºåŒ–å­¦ä¹ åè®­ç»ƒæˆæœ¬é«˜æ˜‚ï¼Œä¸”å­˜åœ¨å®‰å…¨é£é™©ï¼Œéš¾ä»¥é‡ç½®ç¯å¢ƒçŠ¶æ€ã€‚æ­¤å¤–ï¼Œç°æœ‰VLAæ¨¡å‹ç¼ºä¹æœ‰æ•ˆçš„ä»»åŠ¡å®Œæˆæ£€æµ‹æœºåˆ¶ï¼Œå¯¼è‡´åŠ¨ä½œå†—ä½™ï¼Œæ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šåˆ©ç”¨ä¸–ç•Œæ¨¡å‹æ„å»ºä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒï¼Œè¯¥ç¯å¢ƒèƒ½å¤Ÿæ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„è§†è§‰è§‚å¯Ÿï¼Œå¹¶æä¾›å¯é‡ç½®çš„çŠ¶æ€ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ åœ¨è¯¥è™šæ‹Ÿç¯å¢ƒä¸­è¿›è¡Œåè®­ç»ƒï¼Œå¯ä»¥å®‰å…¨ã€é«˜æ•ˆåœ°æå‡VLAæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œä»»åŠ¡å®Œæˆæ•ˆç‡ã€‚VLMå¼•å¯¼çš„åå°„å™¨ç”¨äºæä¾›å¥–åŠ±ä¿¡å·å’Œé¢„æµ‹åŠ¨ä½œç»ˆæ­¢ï¼Œä»è€Œè§£å†³ä»»åŠ¡å®Œæˆæ£€æµ‹é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šWorld-Envæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼š1) åŸºäºè§†é¢‘çš„ä¸–ç•Œæ¨¡æ‹Ÿå™¨ï¼šè¯¥æ¨¡å—è´Ÿè´£ç”Ÿæˆæ—¶é—´ä¸Šä¸€è‡´çš„æœªæ¥è§†è§‰è§‚å¯Ÿï¼Œæ¨¡æ‹ŸçœŸå®ç¯å¢ƒçš„åŠ¨æ€å˜åŒ–ã€‚2) VLMå¼•å¯¼çš„å³æ—¶åå°„å™¨ï¼šè¯¥æ¨¡å—åˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œæ ¹æ®å½“å‰çŠ¶æ€å’Œä»»åŠ¡æè¿°ï¼Œæä¾›è¿ç»­çš„å¥–åŠ±ä¿¡å·ï¼Œå¹¶é¢„æµ‹åŠ¨ä½œç»ˆæ­¢ï¼Œä»è€Œå¼•å¯¼å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ã€‚VLAæ¨¡å‹åœ¨è™šæ‹Ÿç¯å¢ƒä¸­ä¸ç¯å¢ƒäº¤äº’ï¼Œæ ¹æ®åå°„å™¨æä¾›çš„å¥–åŠ±ä¿¡å·è¿›è¡Œå­¦ä¹ ï¼Œå¹¶ä¸æ–­ä¼˜åŒ–å…¶ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæ ¸å¿ƒåˆ›æ–°åœ¨äºåˆ©ç”¨ä¸–ç•Œæ¨¡å‹æ„å»ºè™šæ‹Ÿç¯å¢ƒï¼Œå¹¶ç»“åˆVLMå¼•å¯¼çš„åå°„å™¨ï¼Œå®ç°VLAæ¨¡å‹çš„å®‰å…¨ã€é«˜æ•ˆåè®­ç»ƒã€‚ä¸ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼ŒWorld-Envæ— éœ€ä¸çœŸå®ç¯å¢ƒäº¤äº’ï¼Œé™ä½äº†æˆæœ¬å’Œé£é™©ã€‚ä¸ç°æœ‰çš„VLAæ–¹æ³•ç›¸æ¯”ï¼ŒWorld-Envèƒ½å¤Ÿæœ‰æ•ˆæ£€æµ‹ä»»åŠ¡å®Œæˆï¼Œé¿å…åŠ¨ä½œå†—ä½™ã€‚

**å…³é”®è®¾è®¡**ï¼šä¸–ç•Œæ¨¡æ‹Ÿå™¨é‡‡ç”¨åŸºäºè§†é¢‘ç”Ÿæˆçš„æ¨¡å‹ï¼Œä¾‹å¦‚å˜åˆ†è‡ªç¼–ç å™¨(VAE)æˆ–ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ï¼Œä»¥ç”Ÿæˆé€¼çœŸçš„æœªæ¥è§†è§‰è§‚å¯Ÿã€‚VLMå¼•å¯¼çš„åå°„å™¨åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œä¾‹å¦‚CLIPæˆ–ALIGNï¼Œæå–è§†è§‰å’Œè¯­è¨€ç‰¹å¾ï¼Œå¹¶æ ¹æ®è¿™äº›ç‰¹å¾é¢„æµ‹å¥–åŠ±ä¿¡å·å’ŒåŠ¨ä½œç»ˆæ­¢æ¦‚ç‡ã€‚å¥–åŠ±å‡½æ•°çš„è®¾è®¡éœ€è¦ä»”ç»†è€ƒè™‘ï¼Œä»¥é¼“åŠ±æ¨¡å‹å®Œæˆä»»åŠ¡å¹¶é¿å…ä¸å¿…è¦çš„åŠ¨ä½œã€‚å¼ºåŒ–å­¦ä¹ ç®—æ³•å¯ä»¥é€‰æ‹©å¸¸è§çš„ç®—æ³•ï¼Œä¾‹å¦‚PPOæˆ–SACã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒWorld-Envä»…ä½¿ç”¨æ¯ä¸ªä»»åŠ¡äº”ä¸ªä¸“å®¶æ¼”ç¤ºï¼Œå³å¯æ˜¾è‘—æå‡VLAæ¨¡å‹åœ¨å¤æ‚æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚ä¸ç›´æ¥åœ¨çœŸå®ç¯å¢ƒä¸­è¿›è¡Œå¼ºåŒ–å­¦ä¹ ç›¸æ¯”ï¼ŒWorld-Envèƒ½å¤Ÿæ›´å®‰å…¨ã€æ›´é«˜æ•ˆåœ°æå‡æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒWorld-Envèƒ½å¤Ÿæœ‰æ•ˆæ£€æµ‹ä»»åŠ¡å®Œæˆï¼Œé¿å…åŠ¨ä½œå†—ä½™ï¼Œæé«˜äº†æ•´ä½“ä»»åŠ¡æˆåŠŸç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

World-Envå¯åº”ç”¨äºå„ç§éœ€è¦VLAæ¨¡å‹ä¸”æ•°æ®ç¨€ç¼ºæˆ–ç¯å¢ƒäº¤äº’æˆæœ¬é«˜çš„åœºæ™¯ï¼Œä¾‹å¦‚å·¥ä¸šè‡ªåŠ¨åŒ–ã€æœºå™¨äººæ“ä½œã€åŒ»ç–—æ‰‹æœ¯ç­‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—é™ä½VLAæ¨¡å‹çš„è®­ç»ƒæˆæœ¬å’Œé£é™©ï¼Œæé«˜å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œæ•ˆç‡ã€‚æœªæ¥ï¼Œå¯ä»¥å°†World-Envæ‰©å±•åˆ°æ›´å¤æ‚çš„ä»»åŠ¡å’Œç¯å¢ƒï¼Œä¾‹å¦‚å¤šæ™ºèƒ½ä½“åä½œå’ŒåŠ¨æ€ç¯å¢ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models trained via imitation learning suffer from significant performance degradation in data-scarce scenarios due to their reliance on large-scale demonstration datasets. Although reinforcement learning (RL)-based post-training has proven effective in addressing data scarcity, its application to VLA models is hindered by the non-resettable nature of real-world environments. This limitation is particularly critical in high-risk domains such as industrial automation, where interactions often induce state changes that are costly or infeasible to revert. Furthermore, existing VLA approaches lack a reliable mechanism for detecting task completion, leading to redundant actions that reduce overall task success rates. To address these challenges, we propose World-Env, an RL-based post-training framework that replaces physical interaction with a low-cost, world model-based virtual simulator. World-Env consists of two key components: (1) a video-based world simulator that generates temporally consistent future visual observations, and (2) a vision-language model (VLM)-guided instant reflector that provides continuous reward signals and predicts action termination. This simulated environment enables VLA models to safely explore and generalize beyond their initial imitation learning distribution. Our method achieves notable performance gains with as few as five expert demonstrations per task. Experiments on complex robotic manipulation tasks demonstrate that World-Env effectively overcomes the data inefficiency, safety constraints, and inefficient execution of conventional VLA models that rely on real-world interaction, offering a practical and scalable solution for post-training in resource-constrained settings. Our code is available at https://github.com/amap-cvlab/world-env.

