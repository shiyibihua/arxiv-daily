---
layout: default
title: JuggleRL: Mastering Ball Juggling with a Quadrotor via Deep Reinforcement Learning
---

# JuggleRL: Mastering Ball Juggling with a Quadrotor via Deep Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.24892" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.24892v1</a>
  <a href="https://arxiv.org/pdf/2509.24892.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.24892v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.24892v1', 'JuggleRL: Mastering Ball Juggling with a Quadrotor via Deep Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shilong Ji, Yinuo Chen, Chuqi Wang, Jiayu Chen, Ruize Zhang, Feng Gao, Wenhao Tang, Shu'ang Yu, Sirui Xiang, Xinlei Chen, Chao Yu, Yu Wang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**JuggleRLï¼šåŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„å››æ—‹ç¿¼é£è¡Œå™¨ç©ºä¸­æ‚è€æ§åˆ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å››æ—‹ç¿¼é£è¡Œå™¨` `ç©ºä¸­æ‚è€` `æœºå™¨äººæ§åˆ¶` `åŸŸéšæœºåŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨ä¸ç¡®å®šæ€§ä¸‹æ§åˆ¶å››æ—‹ç¿¼é£è¡Œå™¨è¿›è¡Œç²¾ç¡®çš„ç©ºä¸­æ‚è€ç­‰å¯Œå«æ¥è§¦çš„åŠ¨æ€æ“ä½œã€‚
2. JuggleRLé€šè¿‡å¼ºåŒ–å­¦ä¹ åœ¨ä»¿çœŸç¯å¢ƒä¸­å­¦ä¹ é—­ç¯ç­–ç•¥ï¼Œå¹¶ç»“åˆåŸŸéšæœºåŒ–å’Œå¥–åŠ±å¡‘é€ æ¥æå‡é²æ£’æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒJuggleRLåœ¨çœŸå®ç¯å¢ƒä¸­å®ç°äº†æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•çš„æ•ˆæœï¼Œå¹¶å…·å¤‡ä¸€å®šçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†ä½¿ç”¨é…å¤‡çƒæ‹çš„å››æ—‹ç¿¼é£è¡Œå™¨è¿›è¡Œç©ºä¸­æ‚è€çš„é—®é¢˜ï¼Œè¿™æ˜¯ä¸€ä¸ªéœ€è¦åœ¨ä¸ç¡®å®šæ€§ä¸‹æ‰§è¡Œç²¾ç¡®ã€å¯Œå«æ¥è§¦çš„åŠ¨ä½œçš„ä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºäº†JuggleRLï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„ç©ºä¸­æ‚è€ç³»ç»Ÿã€‚å®ƒé€šè¿‡å¯¹å››æ—‹ç¿¼é£è¡Œå™¨å’Œçƒä½“åŠ¨åŠ›å­¦è¿›è¡Œç³»ç»Ÿæ ¡å‡†ï¼Œåœ¨å¤§å‹ä»¿çœŸä¸­å­¦ä¹ é—­ç¯ç­–ç•¥ï¼Œä»¥ç¼©å°sim-to-realå·®è·ã€‚è®­ç»ƒè¿‡ç¨‹ç»“åˆäº†å¥–åŠ±å¡‘é€ ï¼Œä»¥é¼“åŠ±ä»¥çƒæ‹ä¸ºä¸­å¿ƒçš„å‡»æ‰“å’ŒæŒç»­çš„æ‚è€ï¼Œä»¥åŠå¯¹çƒçš„ä½ç½®å’Œæ¢å¤ç³»æ•°çš„åŸŸéšæœºåŒ–ï¼Œä»¥å¢å¼ºé²æ£’æ€§å’Œå¯è¿ç§»æ€§ã€‚å­¦ä¹ åˆ°çš„ç­–ç•¥è¾“å‡ºç”±ä½çº§æ§åˆ¶å™¨æ‰§è¡Œçš„ä¸­çº§å‘½ä»¤ï¼Œå¹¶é›¶æ ·æœ¬éƒ¨ç½²åœ¨çœŸå®ç¡¬ä»¶ä¸Šï¼Œå…¶ä¸­å…·æœ‰è½»é‡çº§é€šä¿¡åè®®çš„å¢å¼ºå‹æ„ŸçŸ¥æ¨¡å—å‡å°‘äº†é«˜é¢‘çŠ¶æ€ä¼°è®¡çš„å»¶è¿Ÿï¼Œå¹¶ç¡®ä¿äº†å®æ—¶æ§åˆ¶ã€‚å®éªŒè¡¨æ˜ï¼ŒJuggleRLåœ¨çœŸå®ç¯å¢ƒä¸­è¿ç»­10æ¬¡è¯•éªŒä¸­å¹³å‡è¾¾åˆ°311æ¬¡å‡»æ‰“ï¼Œè§‚å¯Ÿåˆ°çš„æœ€å¤§å‡»æ‰“æ¬¡æ•°ä¸º462æ¬¡ï¼Œè¿œè¿œè¶…è¿‡äº†åŸºäºæ¨¡å‹çš„åŸºçº¿ï¼Œåè€…æœ€å¤šè¾¾åˆ°14æ¬¡å‡»æ‰“ï¼Œå¹³å‡ä¸º3.1æ¬¡ã€‚æ­¤å¤–ï¼Œè¯¥ç­–ç•¥æ¨å¹¿åˆ°æœªè§æ¡ä»¶ï¼ŒæˆåŠŸåœ°æ‚è€äº†ä¸€ä¸ªè¾ƒè½»çš„5å…‹çƒï¼Œå¹³å‡å‡»æ‰“æ¬¡æ•°ä¸º145.9æ¬¡ã€‚è¿™é¡¹å·¥ä½œè¡¨æ˜ï¼Œå¼ºåŒ–å­¦ä¹ å¯ä»¥ä½¿ç©ºä¸­æœºå™¨äººåœ¨åŠ¨æ€äº¤äº’ä»»åŠ¡ä¸­å®ç°é²æ£’å’Œç¨³å®šçš„æ§åˆ¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å››æ—‹ç¿¼é£è¡Œå™¨åœ¨ç©ºä¸­è¿›è¡Œçƒä½“æ‚è€æ§åˆ¶çš„é—®é¢˜ã€‚ç°æœ‰çš„åŸºäºæ¨¡å‹çš„æ–¹æ³•éš¾ä»¥åº”å¯¹çœŸå®ä¸–ç•Œä¸­å­˜åœ¨çš„å„ç§ä¸ç¡®å®šæ€§ï¼Œä¾‹å¦‚åŠ¨åŠ›å­¦å‚æ•°çš„ç²¾ç¡®å»ºæ¨¡ã€ç¯å¢ƒå¹²æ‰°ç­‰ï¼Œå¯¼è‡´æ§åˆ¶æ€§èƒ½ä¸ä½³ï¼Œéš¾ä»¥å®ç°ç¨³å®šå’ŒæŒä¹…çš„æ‚è€ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼Œé€šè¿‡åœ¨ä»¿çœŸç¯å¢ƒä¸­è®­ç»ƒï¼Œå­¦ä¹ ä¸€ä¸ªèƒ½å¤Ÿç›´æ¥ä»çŠ¶æ€ä¼°è®¡åˆ°æ§åˆ¶æŒ‡ä»¤çš„é—­ç¯ç­–ç•¥ã€‚é€šè¿‡åŸŸéšæœºåŒ–å’Œå¥–åŠ±å¡‘é€ ï¼Œæé«˜ç­–ç•¥çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œä»è€Œå®ç°ä»ä»¿çœŸåˆ°çœŸå®çš„é›¶æ ·æœ¬è¿ç§»ã€‚è¿™æ ·é¿å…äº†å¯¹å¤æ‚åŠ¨åŠ›å­¦æ¨¡å‹çš„ç²¾ç¡®ä¾èµ–ï¼Œå¹¶èƒ½å¤Ÿè‡ªé€‚åº”åœ°å­¦ä¹ æ§åˆ¶ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šJuggleRLçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ä»¿çœŸç¯å¢ƒï¼šç”¨äºè®­ç»ƒå¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼ŒåŒ…å«å››æ—‹ç¿¼é£è¡Œå™¨å’Œçƒä½“çš„åŠ¨åŠ›å­¦æ¨¡å‹ã€‚2) å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼šä½¿ç”¨PPOç­‰ç®—æ³•è®­ç»ƒç­–ç•¥ç½‘ç»œï¼Œè¾“å‡ºä¸­çº§æ§åˆ¶æŒ‡ä»¤ã€‚3) å¥–åŠ±å‡½æ•°ï¼šè®¾è®¡å¥–åŠ±å‡½æ•°ï¼Œé¼“åŠ±ä»¥çƒæ‹ä¸ºä¸­å¿ƒçš„å‡»æ‰“å’ŒæŒç»­çš„æ‚è€ã€‚4) åŸŸéšæœºåŒ–ï¼šå¯¹çƒçš„ä½ç½®ã€æ¢å¤ç³»æ•°ç­‰å‚æ•°è¿›è¡ŒéšæœºåŒ–ï¼Œæé«˜ç­–ç•¥çš„é²æ£’æ€§ã€‚5) ä½çº§æ§åˆ¶å™¨ï¼šå°†ä¸­çº§æ§åˆ¶æŒ‡ä»¤è½¬åŒ–ä¸ºç”µæœºæ§åˆ¶ä¿¡å·ï¼Œå®ç°å¯¹å››æ—‹ç¿¼é£è¡Œå™¨çš„ç²¾ç¡®æ§åˆ¶ã€‚6) æ„ŸçŸ¥æ¨¡å—ï¼šä½¿ç”¨è§†è§‰æˆ–å…¶ä»–ä¼ æ„Ÿå™¨è¿›è¡ŒçŠ¶æ€ä¼°è®¡ï¼Œä¸ºç­–ç•¥ç½‘ç»œæä¾›è¾“å…¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ç¬¬ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„ç©ºä¸­æ‚è€ç³»ç»ŸJuggleRLã€‚2) é€šè¿‡ç³»ç»Ÿæ ¡å‡†å››æ—‹ç¿¼é£è¡Œå™¨å’Œçƒä½“åŠ¨åŠ›å­¦ï¼Œæœ‰æ•ˆå‡å°äº†sim-to-realçš„å·®è·ã€‚3) ç»“åˆå¥–åŠ±å¡‘é€ å’ŒåŸŸéšæœºåŒ–ï¼Œæé«˜äº†ç­–ç•¥çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚4) å®ç°äº†ä»ä»¿çœŸåˆ°çœŸå®çš„é›¶æ ·æœ¬è¿ç§»ï¼Œæ— éœ€é¢å¤–çš„çœŸå®ä¸–ç•Œè®­ç»ƒã€‚

**å…³é”®è®¾è®¡**ï¼šå¥–åŠ±å‡½æ•°çš„è®¾è®¡æ˜¯å…³é”®ï¼ŒåŒ…æ‹¬é¼“åŠ±å‡»æ‰“çƒçš„å¥–åŠ±ã€é¼“åŠ±çƒä¿æŒåœ¨ç›®æ ‡é«˜åº¦çš„å¥–åŠ±ã€ä»¥åŠæƒ©ç½šä¸å¿…è¦åŠ¨ä½œçš„æƒ©ç½šé¡¹ã€‚åŸŸéšæœºåŒ–æ–¹é¢ï¼Œå¯¹çƒçš„åˆå§‹ä½ç½®ã€é€Ÿåº¦ã€æ¢å¤ç³»æ•°ç­‰å‚æ•°è¿›è¡ŒéšæœºåŒ–ï¼Œä»¥å¢åŠ ç­–ç•¥çš„é²æ£’æ€§ã€‚ç­–ç•¥ç½‘ç»œé‡‡ç”¨å¤šå±‚æ„ŸçŸ¥æœºç»“æ„ï¼Œè¾“å…¥ä¸ºçŠ¶æ€ä¼°è®¡ï¼Œè¾“å‡ºä¸ºä¸­çº§æ§åˆ¶æŒ‡ä»¤ã€‚ä½çº§æ§åˆ¶å™¨é‡‡ç”¨PIDæ§åˆ¶ï¼Œå®ç°å¯¹å››æ—‹ç¿¼é£è¡Œå™¨çš„ç²¾ç¡®æ§åˆ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

JuggleRLåœ¨çœŸå®ç¯å¢ƒä¸­å®ç°äº†å¹³å‡311æ¬¡å‡»æ‰“ï¼Œæœ€é«˜è¾¾åˆ°462æ¬¡ï¼Œæ˜¾è‘—ä¼˜äºåŸºäºæ¨¡å‹çš„åŸºçº¿æ–¹æ³•ï¼ˆå¹³å‡3.1æ¬¡ï¼Œæœ€é«˜14æ¬¡ï¼‰ã€‚æ­¤å¤–ï¼Œè¯¥ç­–ç•¥è¿˜æˆåŠŸæ³›åŒ–åˆ°æœªè§è¿‡çš„åœºæ™¯ï¼Œä¾‹å¦‚æ‚è€ä¸€ä¸ªæ›´è½»çš„5å…‹çƒï¼Œå¹³å‡å‡»æ‰“æ¬¡æ•°è¾¾åˆ°145.9æ¬¡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒJuggleRLå…·æœ‰å¾ˆå¼ºçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºç©ºä¸­æœºå™¨äººä¸ç¯å¢ƒæˆ–ç‰©ä½“çš„äº¤äº’ä»»åŠ¡ï¼Œä¾‹å¦‚ç©ºä¸­æ“ä½œã€ç©ºä¸­è£…é…ã€ç©ºä¸­ç‰©æµç­‰ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¾—åˆ°çš„æ§åˆ¶ç­–ç•¥ï¼Œå¯ä»¥ä½¿ç©ºä¸­æœºå™¨äººåœ¨å¤æ‚å’Œä¸ç¡®å®šçš„ç¯å¢ƒä¸­æ‰§è¡Œç²¾ç¡®çš„æ“ä½œï¼Œæé«˜å…¶è‡ªä¸»æ€§å’Œé€‚åº”æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºç¾éš¾æ•‘æ´ã€åŸºç¡€è®¾æ–½å·¡æ£€ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Aerial robots interacting with objects must perform precise, contact-rich maneuvers under uncertainty. In this paper, we study the problem of aerial ball juggling using a quadrotor equipped with a racket, a task that demands accurate timing, stable control, and continuous adaptation. We propose JuggleRL, the first reinforcement learning-based system for aerial juggling. It learns closed-loop policies in large-scale simulation using systematic calibration of quadrotor and ball dynamics to reduce the sim-to-real gap. The training incorporates reward shaping to encourage racket-centered hits and sustained juggling, as well as domain randomization over ball position and coefficient of restitution to enhance robustness and transferability. The learned policy outputs mid-level commands executed by a low-level controller and is deployed zero-shot on real hardware, where an enhanced perception module with a lightweight communication protocol reduces delays in high-frequency state estimation and ensures real-time control. Experiments show that JuggleRL achieves an average of $311$ hits over $10$ consecutive trials in the real world, with a maximum of $462$ hits observed, far exceeding a model-based baseline that reaches at most $14$ hits with an average of $3.1$. Moreover, the policy generalizes to unseen conditions, successfully juggling a lighter $5$ g ball with an average of $145.9$ hits. This work demonstrates that reinforcement learning can empower aerial robots with robust and stable control in dynamic interaction tasks.

