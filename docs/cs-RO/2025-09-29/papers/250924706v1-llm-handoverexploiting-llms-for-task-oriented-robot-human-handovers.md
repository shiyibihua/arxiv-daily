---
layout: default
title: LLM-Handover:Exploiting LLMs for Task-Oriented Robot-Human Handovers
---

# LLM-Handover:Exploiting LLMs for Task-Oriented Robot-Human Handovers

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.24706" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.24706v1</a>
  <a href="https://arxiv.org/pdf/2509.24706.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.24706v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.24706v1', 'LLM-Handover:Exploiting LLMs for Task-Oriented Robot-Human Handovers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Andreea Tulbure, Rene Zurbruegg, Timm Grigat, Marco Hutter

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

**å¤‡æ³¨**: Accepted to IEEE Robotics and Automation Letters (RA-L)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**LLM-Handoverï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å®ç°é¢å‘ä»»åŠ¡çš„äººæœºç‰©ä½“äº¤æ¥**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äººæœºåä½œ` `ç‰©ä½“äº¤æ¥` `å¤§è¯­è¨€æ¨¡å‹` `éƒ¨ä»¶åˆ†å‰²` `ä¸Šä¸‹æ–‡æ„ŸçŸ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„äººæœºç‰©ä½“äº¤æ¥æ–¹æ³•é€šå¸¸å¿½ç•¥äººç±»åœ¨äº¤æ¥åçš„åŠ¨ä½œï¼Œä¾èµ–äºé™åˆ¶æ³›åŒ–èƒ½åŠ›çš„å‡è®¾ã€‚
2. LLM-Handoveræ¡†æ¶ç»“åˆLLMæ¨ç†å’Œéƒ¨ä»¶åˆ†å‰²ï¼Œæ ¹æ®ä»»åŠ¡æè¿°æ¨æ–­ç›¸å…³éƒ¨ä»¶ï¼Œä¼˜åŒ–äº¤æ¥åçš„å¯ç”¨æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æé«˜äº†æŠ“å–æˆåŠŸç‡ï¼Œé€‚åº”äº¤æ¥åä»»åŠ¡çº¦æŸï¼Œå¹¶åœ¨ç¡¬ä»¶å®éªŒå’Œç”¨æˆ·ç ”ç©¶ä¸­è¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†å®ç°æœ‰æ•ˆçš„äººæœºåä½œï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶LLM-Handoverï¼Œè¯¥æ¡†æ¶ç»“åˆäº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›å’Œéƒ¨ä»¶åˆ†å‰²æŠ€æœ¯ï¼Œä»è€Œå®ç°ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æŠ“å–é€‰æ‹©å’Œæ‰§è¡Œã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæ ¹æ®RGB-Då›¾åƒå’Œä»»åŠ¡æè¿°ï¼Œæ¨æ–­å‡ºç›¸å…³çš„ç‰©ä½“éƒ¨ä»¶ï¼Œå¹¶é€‰æ‹©èƒ½å¤Ÿä¼˜åŒ–äº¤æ¥åå¯ç”¨æ€§çš„æŠ“å–æ–¹å¼ã€‚ä¸ºäº†æ”¯æŒè¯„ä¼°ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«60ä¸ªå®¶åº­ç‰©å“çš„æ•°æ®é›†ï¼Œæ¶µç›–12ä¸ªç±»åˆ«ï¼Œå¹¶å¯¹æ¯ä¸ªç‰©å“è¿›è¡Œäº†è¯¦ç»†çš„éƒ¨ä»¶æ ‡æ³¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLM-Handoveræé«˜äº†éƒ¨ä»¶åˆ†å‰²çš„æ€§èƒ½ï¼Œå®ç°äº†æ›´é«˜çš„æŠ“å–æˆåŠŸç‡ï¼Œå¹¶èƒ½æ›´å¥½åœ°é€‚åº”äº¤æ¥åçš„ä»»åŠ¡çº¦æŸã€‚åœ¨ç¡¬ä»¶å®éªŒä¸­ï¼Œé’ˆå¯¹ä¼ ç»Ÿå’Œéä¼ ç»Ÿçš„äº¤æ¥åä»»åŠ¡ï¼Œè¯¥æ–¹æ³•åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹å®ç°äº†83%çš„æˆåŠŸç‡ã€‚ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒLLM-Handoverèƒ½å¤Ÿå®ç°æ›´ç›´è§‚ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„äº¤æ¥ï¼Œ86%çš„å‚ä¸è€…æ›´å–œæ¬¢è¿™ç§æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„äººæœºç‰©ä½“äº¤æ¥æ–¹æ³•ä¸»è¦ç—›ç‚¹åœ¨äºç¼ºä¹å¯¹äº¤æ¥åäººç±»è¡Œä¸ºçš„è€ƒè™‘ï¼Œé€šå¸¸åŸºäºé¢„è®¾çš„æŠ“å–æ–¹å¼ï¼Œæ— æ³•æ ¹æ®å…·ä½“çš„ä»»åŠ¡éœ€æ±‚è¿›è¡Œè°ƒæ•´ï¼Œå¯¼è‡´äº¤æ¥æ•ˆç‡å’Œç”¨æˆ·ä½“éªŒä¸ä½³ã€‚è¿™ç§æ–¹æ³•çš„å±€é™æ€§åœ¨äºéš¾ä»¥æ³›åŒ–åˆ°ä¸åŒçš„ä»»åŠ¡åœºæ™¯å’Œç‰©ä½“ç±»å‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLLM-Handoverçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼ºå¤§æ¨ç†èƒ½åŠ›ï¼Œç»“åˆç‰©ä½“éƒ¨ä»¶åˆ†å‰²ä¿¡æ¯ï¼Œå®ç°ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æŠ“å–é€‰æ‹©ã€‚é€šè¿‡åˆ†æä»»åŠ¡æè¿°ï¼ŒLLMèƒ½å¤Ÿæ¨æ–­å‡ºä¸ä»»åŠ¡ç›¸å…³çš„ç‰©ä½“éƒ¨ä»¶ï¼Œå¹¶æŒ‡å¯¼æœºå™¨äººé€‰æ‹©æœ€åˆé€‚çš„æŠ“å–æ–¹å¼ï¼Œä»è€Œä¼˜åŒ–äº¤æ¥åçš„å¯ç”¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLLM-Handoveræ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) è¾“å…¥RGB-Då›¾åƒå’Œä»»åŠ¡æè¿°ï¼›2) ä½¿ç”¨éƒ¨ä»¶åˆ†å‰²ç®—æ³•è¯†åˆ«ç‰©ä½“éƒ¨ä»¶ï¼›3) åˆ©ç”¨LLMæ ¹æ®ä»»åŠ¡æè¿°æ¨ç†å‡ºä¸ä»»åŠ¡ç›¸å…³çš„éƒ¨ä»¶ï¼›4) æ ¹æ®æ¨ç†ç»“æœé€‰æ‹©åˆé€‚çš„æŠ“å–ç‚¹å’ŒæŠ“å–å§¿æ€ï¼›5) æ‰§è¡ŒæŠ“å–åŠ¨ä½œï¼Œå°†ç‰©ä½“äº¤æ¥ç»™äººç±»ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†LLMçš„æ¨ç†èƒ½åŠ›å¼•å…¥åˆ°äººæœºç‰©ä½“äº¤æ¥ä»»åŠ¡ä¸­ï¼Œå®ç°äº†ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æŠ“å–é€‰æ‹©ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºé¢„è®¾è§„åˆ™æˆ–å­¦ä¹ çš„æŠ“å–æ–¹æ³•ä¸åŒï¼ŒLLM-Handoverèƒ½å¤Ÿæ ¹æ®å…·ä½“çš„ä»»åŠ¡éœ€æ±‚åŠ¨æ€è°ƒæ•´æŠ“å–ç­–ç•¥ï¼Œä»è€Œæé«˜äº¤æ¥çš„æ•ˆç‡å’Œç”¨æˆ·ä½“éªŒã€‚

**å…³é”®è®¾è®¡**ï¼šLLM-Handoverçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é«˜è´¨é‡çš„éƒ¨ä»¶åˆ†å‰²ç®—æ³•ï¼Œå‡†ç¡®è¯†åˆ«ç‰©ä½“éƒ¨ä»¶ï¼›2) è®¾è®¡åˆé€‚çš„LLMæç¤ºè¯­ï¼Œå¼•å¯¼LLMæ¨ç†å‡ºä¸ä»»åŠ¡ç›¸å…³çš„éƒ¨ä»¶ï¼›3) å®šä¹‰æŠ“å–è¯„ä¼°æŒ‡æ ‡ï¼Œæ ¹æ®éƒ¨ä»¶ç›¸å…³æ€§å’ŒæŠ“å–ç¨³å®šæ€§é€‰æ‹©æœ€ä½³æŠ“å–ç‚¹å’Œå§¿æ€ã€‚å…·ä½“çš„LLMé€‰æ‹©å’Œæç¤ºå·¥ç¨‹ç»†èŠ‚å¯èƒ½å½±å“æœ€ç»ˆæ€§èƒ½ï¼Œä½†è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

LLM-Handoveråœ¨å®éªŒä¸­è¡¨ç°å‡ºè‰²ã€‚åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹ï¼Œé’ˆå¯¹ä¼ ç»Ÿå’Œéä¼ ç»Ÿçš„äº¤æ¥åä»»åŠ¡ï¼Œè¯¥æ–¹æ³•å®ç°äº†83%çš„æŠ“å–æˆåŠŸç‡ã€‚ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œ86%çš„å‚ä¸è€…æ›´å–œæ¬¢LLM-Handoveræä¾›çš„äº¤æ¥æ–¹å¼ï¼Œè®¤ä¸ºå…¶æ›´ç›´è§‚ã€æ›´ç¬¦åˆä»»åŠ¡éœ€æ±‚ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æé«˜äº†éƒ¨ä»¶åˆ†å‰²çš„æ€§èƒ½ï¼Œä¸ºåç»­çš„æŠ“å–é€‰æ‹©æä¾›äº†æ›´å‡†ç¡®çš„ä¿¡æ¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LLM-Handoverå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨æ™ºèƒ½å®¶å±…ä¸­ï¼Œæœºå™¨äººå¯ä»¥æ ¹æ®ç”¨æˆ·çš„æŒ‡ä»¤ï¼Œä»¥æœ€æ–¹ä¾¿çš„æ–¹å¼é€’é€ç‰©å“ã€‚åœ¨åŒ»ç–—é¢†åŸŸï¼Œæœºå™¨äººå¯ä»¥è¾…åŠ©åŒ»æŠ¤äººå‘˜è¿›è¡Œæ‰‹æœ¯å™¨æ¢°çš„äº¤æ¥ï¼Œæé«˜æ‰‹æœ¯æ•ˆç‡å’Œå®‰å…¨æ€§ã€‚åœ¨å·¥ä¸šç”Ÿäº§ä¸­ï¼Œæœºå™¨äººå¯ä»¥æ ¹æ®å·¥äººçš„æ“ä½œä¹ æƒ¯ï¼Œä»¥æœ€ä½³æ–¹å¼é€’é€å·¥å…·æˆ–é›¶éƒ¨ä»¶ï¼Œæé«˜ç”Ÿäº§æ•ˆç‡ã€‚è¯¥ç ”ç©¶æœ‰æœ›æ¨åŠ¨äººæœºåä½œæŠ€æœ¯çš„å‘å±•ï¼Œå®ç°æ›´åŠ æ™ºèƒ½ã€é«˜æ•ˆã€å®‰å…¨çš„äººæœºäº¤äº’ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Effective human-robot collaboration depends on task-oriented handovers, where robots present objects in ways that support the partners intended use. However, many existing approaches neglect the humans post-handover action, relying on assumptions that limit generalizability. To address this gap, we propose LLM-Handover, a novel framework that integrates large language model (LLM)-based reasoning with part segmentation to enable context-aware grasp selection and execution. Given an RGB-D image and a task description, our system infers relevant object parts and selects grasps that optimize post-handover usability. To support evaluation, we introduce a new dataset of 60 household objects spanning 12 categories, each annotated with detailed part labels. We first demonstrate that our approach improves the performance of the used state-of-the-art part segmentation method, in the context of robot-human handovers. Next, we show that LLM-Handover achieves higher grasp success rates and adapts better to post-handover task constraints. During hardware experiments, we achieve a success rate of 83% in a zero-shot setting over conventional and unconventional post-handover tasks. Finally, our user study underlines that our method enables more intuitive, context-aware handovers, with participants preferring it in 86% of cases.

