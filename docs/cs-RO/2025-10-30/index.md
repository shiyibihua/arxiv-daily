---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-10-30
---

# cs.ROï¼ˆ2025-10-30ï¼‰

ğŸ“Š å…± **25** ç¯‡è®ºæ–‡
 | ğŸ”— **5** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (16 ğŸ”—3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3 ğŸ”—2)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (16 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251027048v1-spikeatac-a-multimodal-tactile-finger-with-taxelized-dynamic-sensing.html">SpikeATac: A Multimodal Tactile Finger with Taxelized Dynamic Sensing for Dexterous Manipulation</a></td>
  <td>SpikeATacï¼šç”¨äºçµå·§æ“ä½œçš„å¤šæ¨¡æ€è§¦è§‰æ‰‹æŒ‡ï¼Œå…·æœ‰å¯åˆ†å‰²çš„åŠ¨æ€ä¼ æ„Ÿ</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.27048v1" onclick="toggleFavorite(this, '2510.27048v1', 'SpikeATac: A Multimodal Tactile Finger with Taxelized Dynamic Sensing for Dexterous Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251026236v1-phuma-physically-grounded-humanoid-locomotion-dataset.html">PHUMA: Physically-Grounded Humanoid Locomotion Dataset</a></td>
  <td>æå‡ºPHUMAï¼šä¸€ä¸ªç‰©ç†çº¦æŸçš„äººå½¢æœºå™¨äººè¿åŠ¨æ•°æ®é›†ï¼Œæå‡è¿åŠ¨æ¨¡ä»¿æ€§èƒ½ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26236v1" onclick="toggleFavorite(this, '2510.26236v1', 'PHUMA: Physically-Grounded Humanoid Locomotion Dataset')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251026139v1-kinodynamic-task-and-motion-planning-using-vlm-guided-and-interleave.html">Kinodynamic Task and Motion Planning using VLM-guided and Interleaved Sampling</a></td>
  <td>æå‡ºåŸºäºVLMå¼•å¯¼å’Œäº¤é”™é‡‡æ ·çš„è¿åŠ¨å­¦ä»»åŠ¡ä¸è¿åŠ¨è§„åˆ’æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26139v1" onclick="toggleFavorite(this, '2510.26139v1', 'Kinodynamic Task and Motion Planning using VLM-guided and Interleaved Sampling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251026362v1-cooperative-task-spaces-for-multi-arm-manipulation-control-based-on-.html">Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations</a></td>
  <td>æå‡ºåŸºäºç›¸ä¼¼å˜æ¢çš„åä½œä»»åŠ¡ç©ºé—´ï¼Œç”¨äºå¤šè‡‚æ“ä½œæ§åˆ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26362v1" onclick="toggleFavorite(this, '2510.26362v1', 'Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251026670v1-hybrid-consistency-policy-decoupling-multi-modal-diversity-and-real-.html">Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation</a></td>
  <td>æå‡ºæ··åˆä¸€è‡´æ€§ç­–ç•¥HCPï¼Œè§£è€¦æœºå™¨äººæ“ä½œä¸­çš„å¤šæ¨¡æ€å¤šæ ·æ€§å’Œå®æ—¶æ•ˆç‡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26670v1" onclick="toggleFavorite(this, '2510.26670v1', 'Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251026406v1-human-in-the-loop-online-rejection-sampling-for-robotic-manipulation.html">Human-in-the-loop Online Rejection Sampling for Robotic Manipulation</a></td>
  <td>æå‡ºHi-ORSï¼Œé€šè¿‡åœ¨çº¿æ‹’ç»é‡‡æ ·æå‡æœºå™¨äººæ“ä½œçš„å¼ºåŒ–å­¦ä¹ ç¨³å®šæ€§ä¸é²æ£’æ€§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26406v1" onclick="toggleFavorite(this, '2510.26406v1', 'Human-in-the-loop Online Rejection Sampling for Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251026067v1-morphology-aware-graph-reinforcement-learning-for-tensegrity-robot-l.html">Morphology-Aware Graph Reinforcement Learning for Tensegrity Robot Locomotion</a></td>
  <td>æå‡ºä¸€ç§å½¢æ€æ„ŸçŸ¥å›¾å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºå¼ æ‹‰æ•´ä½“æœºå™¨äººè¿åŠ¨æ§åˆ¶ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26067v1" onclick="toggleFavorite(this, '2510.26067v1', 'Morphology-Aware Graph Reinforcement Learning for Tensegrity Robot Locomotion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251100112v1-real-drl-teach-and-learn-in-reality.html">Real-DRL: Teach and Learn in Reality</a></td>
  <td>Real-DRLæ¡†æ¶ï¼šåœ¨çœŸå®ç¯å¢ƒä¸­å®‰å…¨åœ°è®­ç»ƒæ·±åº¦å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.00112v1" onclick="toggleFavorite(this, '2511.00112v1', 'Real-DRL: Teach and Learn in Reality')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251026855v1-leveraging-foundation-models-for-enhancing-robot-perception-and-acti.html">Leveraging Foundation Models for Enhancing Robot Perception and Action</a></td>
  <td>åˆ©ç”¨Foundationæ¨¡å‹å¢å¼ºæœºå™¨äººæ„ŸçŸ¥ä¸è¡ŒåŠ¨èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26855v1" onclick="toggleFavorite(this, '2510.26855v1', 'Leveraging Foundation Models for Enhancing Robot Perception and Action')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251202022v1-reinforcement-learning-for-robotic-safe-control-with-force-sensing.html">Reinforcement Learning for Robotic Safe Control with Force Sensing</a></td>
  <td>æå‡ºåŸºäºåŠ›æ„ŸçŸ¥çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæå‡æœºå™¨äººå®‰å…¨æ§åˆ¶å’ŒSim2Realè¿ç§»èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.02022v1" onclick="toggleFavorite(this, '2512.02022v1', 'Reinforcement Learning for Robotic Safe Control with Force Sensing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251026280v2-thor-towards-human-level-whole-body-reactions-for-intense-contact-ri.html">Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments</a></td>
  <td>Thoræ¡†æ¶ï¼šå®ç°äººå‹æœºå™¨äººåœ¨å¼ºæ¥è§¦ç¯å¢ƒä¸­ç±»äººå…¨èº«ååº”</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26280v2" onclick="toggleFavorite(this, '2510.26280v2', 'Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251026551v1-adaptive-inverse-kinematics-framework-for-learning-variable-length-t.html">Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics</a></td>
  <td>æå‡ºè‡ªé€‚åº”é€†è¿åŠ¨å­¦æ¡†æ¶ï¼Œç”¨äºæœºå™¨äººå­¦ä¹ å˜é•¿å·¥å…·æ“ä½œ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26551v1" onclick="toggleFavorite(this, '2510.26551v1', 'Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251026082v2-beyond-the-uncanny-valley-a-mixed-method-investigation-of-anthropomo.html">Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse</a></td>
  <td>ç ”ç©¶ç±»äººæœºå™¨äººå—è™å¾…æ—¶ï¼Œä¸åŒç¨‹åº¦çš„æ‹ŸäººåŒ–å¦‚ä½•å½±å“äººç±»çš„ä¿æŠ¤ååº”ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26082v2" onclick="toggleFavorite(this, '2510.26082v2', 'Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251026909v2-navitrace-evaluating-embodied-navigation-of-vision-language-models.html">NaviTrace: Evaluating Embodied Navigation of Vision-Language Models</a></td>
  <td>NaviTraceï¼šæå‡ºè§†è§‰-è¯­è¨€æ¨¡å‹å…·èº«å¯¼èˆªè¯„æµ‹åŸºå‡†ï¼Œè§£å†³çœŸå®æœºå™¨äººå¯¼èˆªè¯„ä¼°éš¾é¢˜</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26909v2" onclick="toggleFavorite(this, '2510.26909v2', 'NaviTrace: Evaluating Embodied Navigation of Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251026656v2-heuristic-adaptation-of-potentially-misspecified-domain-support-for-.html">Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems</a></td>
  <td>æå‡ºä¸‰ç§å¯å‘å¼LFIå˜ä½“ï¼Œè‡ªé€‚åº”è°ƒæ•´é¢†åŸŸæ”¯æŒï¼Œæå‡éšæœºåŠ¨åŠ›ç³»ç»Ÿä¸­çš„æ— ä¼¼ç„¶æ¨ç†æ€§èƒ½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26656v2" onclick="toggleFavorite(this, '2510.26656v2', 'Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251026132v1-embodied-intelligence-for-advanced-bioinspired-microrobotics-example.html">Embodied Intelligence for Advanced Bioinspired Microrobotics: Examples and Insights</a></td>
  <td>åŸºäºå…·èº«æ™ºèƒ½çš„å¾®å‹æœºå™¨äººè®¾è®¡ï¼Œå®ç°é«˜æ•ˆè‡ªä¸»è¿åŠ¨ä¸å¯¼èˆª</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26132v1" onclick="toggleFavorite(this, '2510.26132v1', 'Embodied Intelligence for Advanced Bioinspired Microrobotics: Examples and Insights')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/251026646v1-hybrid-dqn-td3-reinforcement-learning-for-autonomous-navigation-in-d.html">Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments</a></td>
  <td>æå‡ºæ··åˆDQN-TD3å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºåŠ¨æ€ç¯å¢ƒä¸­è‡ªä¸»å¯¼èˆªã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26646v1" onclick="toggleFavorite(this, '2510.26646v1', 'Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251100088v1-alpamayo-r1-bridging-reasoning-and-action-prediction-for-generalizab.html">Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail</a></td>
  <td>æå‡ºAlpamayo-R1ï¼Œé€šè¿‡å› æœæ¨ç†å’Œè½¨è¿¹è§„åˆ’æå‡é•¿å°¾åœºæ™¯ä¸‹è‡ªåŠ¨é©¾é©¶çš„æ³›åŒ–èƒ½åŠ›ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.00088v1" onclick="toggleFavorite(this, '2511.00088v1', 'Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/251026363v1-towards-reinforcement-learning-based-log-loading-automation.html">Towards Reinforcement Learning Based Log Loading Automation</a></td>
  <td>æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„æœ¨æè£…è½½è‡ªåŠ¨åŒ–æ–¹æ³•ï¼Œæå‡æ—ä¸šä½œä¸šæ•ˆç‡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26363v1" onclick="toggleFavorite(this, '2510.26363v1', 'Towards Reinforcement Learning Based Log Loading Automation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251026040v1-accelerating-real-world-overtaking-in-f1tenth-racing-employing-reinf.html">Accelerating Real-World Overtaking in F1TENTH Racing Employing Reinforcement Learning Methods</a></td>
  <td>æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„F1TENTHèµ›è½¦è¶…è½¦ç®—æ³•ï¼Œæå‡çœŸå®åœºæ™¯è¶…è½¦æˆåŠŸç‡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26040v1" onclick="toggleFavorite(this, '2510.26040v1', 'Accelerating Real-World Overtaking in F1TENTH Racing Employing Reinforcement Learning Methods')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/251027033v1-a-multi-modal-neuro-symbolic-approach-for-spatial-reasoning-based-vi.html">A Multi-Modal Neuro-Symbolic Approach for Spatial Reasoning-Based Visual Grounding in Robotics</a></td>
  <td>æå‡ºä¸€ç§å¤šæ¨¡æ€ç¥ç»ç¬¦å·æ–¹æ³•ï¼Œç”¨äºæœºå™¨äººä¸­åŸºäºç©ºé—´æ¨ç†çš„è§†è§‰å®šä½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.27033v1" onclick="toggleFavorite(this, '2510.27033v1', 'A Multi-Modal Neuro-Symbolic Approach for Spatial Reasoning-Based Visual Grounding in Robotics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251026536v1-roboos-next-a-unified-memory-based-framework-for-lifelong-scalable-a.html">RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration</a></td>
  <td>RoboOS-NeXTï¼šé¢å‘ç»ˆèº«å­¦ä¹ ã€å¯æ‰©å±•å’Œé²æ£’å¤šæœºå™¨äººåä½œçš„ç»Ÿä¸€å†…å­˜æ¡†æ¶</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26536v1" onclick="toggleFavorite(this, '2510.26536v1', 'RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/251026742v1-running-vlas-at-real-time-speed.html">Running VLAs at Real-time Speed</a></td>
  <td>æå‡ºåŠ é€Ÿç­–ç•¥ï¼Œå•GPUå®ç°30Hzå¤šè§†è§’VLAå®æ—¶è¿è¡Œï¼Œèµ‹èƒ½åŠ¨æ€æœºå™¨äººä»»åŠ¡</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26742v1" onclick="toggleFavorite(this, '2510.26742v1', 'Running VLAs at Real-time Speed')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>24</td>
  <td><a href="./papers/251026358v1-agrigs-slam-orchard-mapping-across-seasons-via-multi-view-gaussian-s.html">AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM</a></td>
  <td>AgriGS-SLAMï¼šåŸºäºå¤šè§†è§’é«˜æ–¯æº…å°„çš„æœå›­è·¨å­£èŠ‚å»ºå›¾SLAM</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26358v1" onclick="toggleFavorite(this, '2510.26358v1', 'AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>25</td>
  <td><a href="./papers/251026142v1-adaptive-trajectory-refinement-for-optimization-based-local-planning.html">Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages</a></td>
  <td>æå‡ºè‡ªé€‚åº”è½¨è¿¹ä¼˜åŒ–ç®—æ³•ï¼Œè§£å†³ç§»åŠ¨æœºå™¨äººåœ¨ç‹­çª„é€šé“ä¸­çš„å±€éƒ¨è§„åˆ’é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26142v1" onclick="toggleFavorite(this, '2510.26142v1', 'Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)