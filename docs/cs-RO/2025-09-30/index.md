---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-09-30
---

# cs.ROï¼ˆ2025-09-30ï¼‰

ğŸ“Š å…± **29** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (22 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (22 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250926633v2-omniretarget-interaction-preserving-data-generation-for-humanoid-who.html">OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction</a></td>
  <td>OmniRetargetï¼šäº¤äº’ä¿æŒçš„äººå½¢æœºå™¨äººå…¨èº«è¿åŠ¨æ“ä½œä¸åœºæ™¯äº¤äº’æ•°æ®ç”Ÿæˆå¼•æ“</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.26633v2" data-paper-url="./papers/250926633v2-omniretarget-interaction-preserving-data-generation-for-humanoid-who.html" onclick="toggleFavorite(this, '2509.26633v2', 'OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251000182v1-a-systematic-study-of-large-language-models-for-task-and-motion-plan.html">A Systematic Study of Large Language Models for Task and Motion Planning With PDDLStream</a></td>
  <td>æå‡ºåŸºäºLLMçš„TAMPç³»ç»Ÿä»¥è§£å†³å¤æ‚æœºå™¨äººä»»åŠ¡è§„åˆ’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span> <span class="paper-tag">large language model</span> <span class="paper-tag">task and motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.00182v1" data-paper-url="./papers/251000182v1-a-systematic-study-of-large-language-models-for-task-and-motion-plan.html" onclick="toggleFavorite(this, '2510.00182v1', 'A Systematic Study of Large Language Models for Task and Motion Planning With PDDLStream')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250926642v1-mla-a-multisensory-language-action-model-for-multimodal-understandin.html">MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation</a></td>
  <td>æå‡ºMLAå¤šæ„Ÿå®˜è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼Œå¢å¼ºæœºå™¨äººæ“ä½œä¸­å¤šæ¨¡æ€ç†è§£ä¸é¢„æµ‹èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">world model</span> <span class="paper-tag">vision-language-action</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.26642v1" data-paper-url="./papers/250926642v1-mla-a-multisensory-language-action-model-for-multimodal-understandin.html" onclick="toggleFavorite(this, '2509.26642v1', 'MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250925852v1-reinforced-embodied-planning-with-verifiable-reward-for-real-world-r.html">Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation</a></td>
  <td>REVERï¼šåŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å…·èº«è§„åˆ’ï¼Œç”¨äºçœŸå®ä¸–ç•Œæœºå™¨äººæ“ä½œ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">physically plausible</span> <span class="paper-tag">embodied AI</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25852v1" data-paper-url="./papers/250925852v1-reinforced-embodied-planning-with-verifiable-reward-for-real-world-r.html" onclick="toggleFavorite(this, '2509.25852v1', 'Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250926236v1-isyhand-a-dexterous-multi-finger-robot-hand-with-an-articulated-palm.html">ISyHand: A Dexterous Multi-finger Robot Hand with an Articulated Palm</a></td>
  <td>ISyHandï¼šä¸€ç§å…·æœ‰é“°æ¥å¼æ‰‹æŒçš„é«˜çµå·§åº¦å¤šæŒ‡æœºå™¨äººæ‰‹</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.26236v1" data-paper-url="./papers/250926236v1-isyhand-a-dexterous-multi-finger-robot-hand-with-an-articulated-palm.html" onclick="toggleFavorite(this, '2509.26236v1', 'ISyHand: A Dexterous Multi-finger Robot Hand with an Articulated Palm')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251000329v1-learning-human-reaching-optimality-principles-from-minimal-observati.html">Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning</a></td>
  <td>æå‡ºåŸºäºæœ€å°è§‚æµ‹é€†å¼ºåŒ–å­¦ä¹ çš„äººä½“æ‰‹è‡‚è¿åŠ¨æœ€ä¼˜æ€§å»ºæ¨¡æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.00329v1" data-paper-url="./papers/251000329v1-learning-human-reaching-optimality-principles-from-minimal-observati.html" onclick="toggleFavorite(this, '2510.00329v1', 'Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250925756v2-sac-flow-sample-efficient-reinforcement-learning-of-flow-based-polic.html">SAC Flow: Sample-Efficient Reinforcement Learning of Flow-Based Policies via Velocity-Reparameterized Sequential Modeling</a></td>
  <td>æå‡ºSAC Flowç®—æ³•ï¼Œé€šè¿‡é€Ÿåº¦é‡å‚æ•°åŒ–åºåˆ—å»ºæ¨¡å®ç°Flow-Basedç­–ç•¥é«˜æ•ˆå¼ºåŒ–å­¦ä¹ </td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">SAC</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25756v2" data-paper-url="./papers/250925756v2-sac-flow-sample-efficient-reinforcement-learning-of-flow-based-polic.html" onclick="toggleFavorite(this, '2509.25756v2', 'SAC Flow: Sample-Efficient Reinforcement Learning of Flow-Based Policies via Velocity-Reparameterized Sequential Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250926339v1-kinodynamic-motion-planning-for-mobile-robot-navigation-across-incon.html">Kinodynamic Motion Planning for Mobile Robot Navigation across Inconsistent World Models</a></td>
  <td>é’ˆå¯¹ä¸ä¸€è‡´ç¯å¢ƒæ¨¡å‹çš„ç§»åŠ¨æœºå™¨äººè¿åŠ¨è§„åˆ’æ–¹æ³•GEGRH</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span> <span class="paper-tag">world model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.26339v1" data-paper-url="./papers/250926339v1-kinodynamic-motion-planning-for-mobile-robot-navigation-across-incon.html" onclick="toggleFavorite(this, '2509.26339v1', 'Kinodynamic Motion Planning for Mobile Robot Navigation across Inconsistent World Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250926308v1-anomaly-detection-for-generic-failure-monitoring-in-robotic-assembly.html">Anomaly detection for generic failure monitoring in robotic assembly, screwing and manipulation</a></td>
  <td>æå‡ºåŸºäºè‡ªç¼–ç å™¨çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ï¼Œç”¨äºæœºå™¨äººè£…é…ã€æ‹§èºä¸å’Œæ“ä½œä¸­çš„é€šç”¨æ•…éšœç›‘æ§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">diffusion policy</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.26308v1" data-paper-url="./papers/250926308v1-anomaly-detection-for-generic-failure-monitoring-in-robotic-assembly.html" onclick="toggleFavorite(this, '2509.26308v1', 'Anomaly detection for generic failure monitoring in robotic assembly, screwing and manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250926082v1-evolutionary-continuous-adaptive-rl-powered-co-design-for-humanoid-c.html">Evolutionary Continuous Adaptive RL-Powered Co-Design for Humanoid Chin-Up Performance</a></td>
  <td>æå‡ºEA-CoRLæ¡†æ¶ï¼Œè§£å†³äººå‹æœºå™¨äººååŒè®¾è®¡ä¸­æ§åˆ¶ç­–ç•¥å¯¹ç¡¬ä»¶çš„æŒç»­é€‚åº”é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.26082v1" data-paper-url="./papers/250926082v1-evolutionary-continuous-adaptive-rl-powered-co-design-for-humanoid-c.html" onclick="toggleFavorite(this, '2509.26082v1', 'Evolutionary Continuous Adaptive RL-Powered Co-Design for Humanoid Chin-Up Performance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250925822v4-act-to-see-see-to-act-diffusion-driven-perception-action-interplay-f.html">Act to See, See to Act: Diffusion-Driven Perception-Action Interplay for Adaptive Policies</a></td>
  <td>æå‡ºAction-Guided Diffusion Policyï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹é©±åŠ¨çš„æ„ŸçŸ¥-åŠ¨ä½œäº¤äº’å®ç°è‡ªé€‚åº”ç­–ç•¥ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">policy learning</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25822v4" data-paper-url="./papers/250925822v4-act-to-see-see-to-act-diffusion-driven-perception-action-interplay-f.html" onclick="toggleFavorite(this, '2509.25822v4', 'Act to See, See to Act: Diffusion-Driven Perception-Action Interplay for Adaptive Policies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251000225v1-tgpo-temporal-grounded-policy-optimization-for-signal-temporal-logic.html">TGPO: Temporal Grounded Policy Optimization for Signal Temporal Logic Tasks</a></td>
  <td>TGPOï¼šæ—¶åºçº¦æŸä¸‹çš„ç­–ç•¥ä¼˜åŒ–ï¼Œè§£å†³æœºå™¨äººå¤æ‚æ—¶åºé€»è¾‘ä»»åŠ¡</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">locomotion</span> <span class="paper-tag">manipulation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.00225v1" data-paper-url="./papers/251000225v1-tgpo-temporal-grounded-policy-optimization-for-signal-temporal-logic.html" onclick="toggleFavorite(this, '2510.00225v1', 'TGPO: Temporal Grounded Policy Optimization for Signal Temporal Logic Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251000154v1-robopilot-generalizable-dynamic-robotic-manipulation-with-dual-think.html">RoboPilot: Generalizable Dynamic Robotic Manipulation with Dual-thinking Modes</a></td>
  <td>RoboPilotï¼šåŒé‡æ€ç»´æ¨¡å¼å®ç°é€šç”¨åŠ¨æ€æœºå™¨äººæ“ä½œ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.00154v1" data-paper-url="./papers/251000154v1-robopilot-generalizable-dynamic-robotic-manipulation-with-dual-think.html" onclick="toggleFavorite(this, '2510.00154v1', 'RoboPilot: Generalizable Dynamic Robotic Manipulation with Dual-thinking Modes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250926459v1-analytic-conditions-for-differentiable-collision-detection-in-trajec.html">Analytic Conditions for Differentiable Collision Detection in Trajectory Optimization</a></td>
  <td>æå‡ºå¯å¾®ç¢°æ’æ£€æµ‹è§£ææ¡ä»¶ï¼ŒåŠ é€Ÿè½¨è¿¹ä¼˜åŒ–ä¸­çš„éç©¿é€çº¦æŸ</td>
  <td class="tags-cell"><span class="paper-tag">trajectory optimization</span> <span class="paper-tag">penetration</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.26459v1" data-paper-url="./papers/250926459v1-analytic-conditions-for-differentiable-collision-detection-in-trajec.html" onclick="toggleFavorite(this, '2509.26459v1', 'Analytic Conditions for Differentiable Collision Detection in Trajectory Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250926575v1-the-trajectory-bundle-method-unifying-sequential-convex-programming-.html">The Trajectory Bundle Method: Unifying Sequential-Convex Programming and Sampling-Based Trajectory Optimization</a></td>
  <td>æå‡ºè½¨è¿¹æŸæ–¹æ³•ï¼Œç»Ÿä¸€åºåˆ—å‡¸è§„åˆ’ä¸é‡‡æ ·è½¨è¿¹ä¼˜åŒ–ï¼Œè§£å†³æ— å¯¼æ•°è½¨è¿¹ä¼˜åŒ–é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">trajectory optimization</span> <span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.26575v1" data-paper-url="./papers/250926575v1-the-trajectory-bundle-method-unifying-sequential-convex-programming-.html" onclick="toggleFavorite(this, '2509.26575v1', 'The Trajectory Bundle Method: Unifying Sequential-Convex Programming and Sampling-Based Trajectory Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250925747v1-best-of-sim-and-real-decoupled-visuomotor-manipulation-via-learning-.html">Best of Sim and Real: Decoupled Visuomotor Manipulation via Learning Control in Simulation and Perception in Real</a></td>
  <td>æå‡ºè§£è€¦çš„è§†è§‰è¿åŠ¨æ“ä½œæ¡†æ¶ï¼Œæå‡Sim-to-Realè¿ç§»æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">sim-to-real</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25747v1" data-paper-url="./papers/250925747v1-best-of-sim-and-real-decoupled-visuomotor-manipulation-via-learning-.html" onclick="toggleFavorite(this, '2509.25747v1', 'Best of Sim and Real: Decoupled Visuomotor Manipulation via Learning Control in Simulation and Perception in Real')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250925999v1-on-the-conic-complementarity-of-planar-contacts.html">On the Conic Complementarity of Planar Contacts</a></td>
  <td>æå‡ºå¹³é¢Signoriniæ¡ä»¶ï¼Œç»Ÿä¸€ç¦»æ•£ä¸è¿ç»­æ¥è§¦æ¨¡å‹ï¼Œæ‰©å±•å‹åŠ›ä¸­å¿ƒæ¦‚å¿µã€‚</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span> <span class="paper-tag">manipulation</span> <span class="paper-tag">penetration</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25999v1" data-paper-url="./papers/250925999v1-on-the-conic-complementarity-of-planar-contacts.html" onclick="toggleFavorite(this, '2509.25999v1', 'On the Conic Complementarity of Planar Contacts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251021732v1-a-robotic-stirring-method-with-trajectory-optimization-and-adaptive-.html">A Robotic Stirring Method with Trajectory Optimization and Adaptive Speed Control for Accurate Pest Counting in Water Traps</a></td>
  <td>æå‡ºåŸºäºè½¨è¿¹ä¼˜åŒ–å’Œè‡ªé€‚åº”é€Ÿåº¦æ§åˆ¶çš„æœºå™¨äººæ…æ‹Œæ–¹æ³•ï¼Œç”¨äºæ°´ä½“é™·é˜±ä¸­å®³è™«çš„ç²¾ç¡®è®¡æ•°ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">trajectory optimization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.21732v1" data-paper-url="./papers/251021732v1-a-robotic-stirring-method-with-trajectory-optimization-and-adaptive-.html" onclick="toggleFavorite(this, '2510.21732v1', 'A Robotic Stirring Method with Trajectory Optimization and Adaptive Speed Control for Accurate Pest Counting in Water Traps')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250925685v1-hierarchical-diffusion-motion-planning-with-task-conditioned-uncerta.html">Hierarchical Diffusion Motion Planning with Task-Conditioned Uncertainty-Aware Priors</a></td>
  <td>æå‡ºå±‚çº§æ‰©æ•£è¿åŠ¨è§„åˆ’æ–¹æ³•ï¼Œåˆ©ç”¨ä»»åŠ¡æ¡ä»¶çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥å…ˆéªŒæå‡è§„åˆ’æ•ˆæœã€‚</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25685v1" data-paper-url="./papers/250925685v1-hierarchical-diffusion-motion-planning-with-task-conditioned-uncerta.html" onclick="toggleFavorite(this, '2509.25685v1', 'Hierarchical Diffusion Motion Planning with Task-Conditioned Uncertainty-Aware Priors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251000188v1-a-novel-robust-control-method-combining-dnn-based-nmpc-approximation.html">A Novel Robust Control Method Combining DNN-Based NMPC Approximation and PI Control: Application to Exoskeleton Squat Movements</a></td>
  <td>æå‡ºåŸºäºDNN-NMPCè¿‘ä¼¼ä¸PIæ§åˆ¶çš„æ··åˆæ§åˆ¶æ–¹æ³•ï¼Œæå‡å¤–éª¨éª¼æœºå™¨äººä¸‹è¹²è¿åŠ¨çš„é²æ£’æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">model predictive control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.00188v1" data-paper-url="./papers/251000188v1-a-novel-robust-control-method-combining-dnn-based-nmpc-approximation.html" onclick="toggleFavorite(this, '2510.00188v1', 'A Novel Robust Control Method Combining DNN-Based NMPC Approximation and PI Control: Application to Exoskeleton Squat Movements')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250926513v1-learning-from-hallucinating-critical-points-for-navigation-in-dynami.html">Learning from Hallucinating Critical Points for Navigation in Dynamic Environments</a></td>
  <td>æå‡ºLfH-CPæ¡†æ¶ï¼Œé€šè¿‡å¹»è§‰å…³é”®ç‚¹å­¦ä¹ åŠ¨æ€ç¯å¢ƒå¯¼èˆª</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.26513v1" data-paper-url="./papers/250926513v1-learning-from-hallucinating-critical-points-for-navigation-in-dynami.html" onclick="toggleFavorite(this, '2509.26513v1', 'Learning from Hallucinating Critical Points for Navigation in Dynamic Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250925945v2-state-estimation-for-compliant-and-morphologically-adaptive-robots.html">State Estimation for Compliant and Morphologically Adaptive Robots</a></td>
  <td>é’ˆå¯¹æŸ”é¡ºå’Œå½¢æ€è‡ªé€‚åº”æœºå™¨äººï¼Œæå‡ºä¸€ç§åŸºäºç¥ç»ç½‘ç»œçš„çŠ¶æ€ä¼°è®¡æ–¹æ³•ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25945v2" data-paper-url="./papers/250925945v2-state-estimation-for-compliant-and-morphologically-adaptive-robots.html" onclick="toggleFavorite(this, '2509.25945v2', 'State Estimation for Compliant and Morphologically Adaptive Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>23</td>
  <td><a href="./papers/250925681v1-dvla-diffusion-vision-language-action-model-with-multimodal-chain-of.html">dVLA: Diffusion Vision-Language-Action Model with Multimodal Chain-of-Thought</a></td>
  <td>æå‡ºdVLAï¼šåŸºäºæ‰©æ•£æ¨¡å‹å’Œå¤šæ¨¡æ€CoTçš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæœºå™¨äººæ§åˆ¶</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25681v1" data-paper-url="./papers/250925681v1-dvla-diffusion-vision-language-action-model-with-multimodal-chain-of.html" onclick="toggleFavorite(this, '2509.25681v1', 'dVLA: Diffusion Vision-Language-Action Model with Multimodal Chain-of-Thought')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250926324v2-llm-mcox-large-language-model-based-multi-robot-coordinated-explorat.html">LLM-MCoX: Large Language Model-based Multi-robot Coordinated Exploration and Search</a></td>
  <td>LLM-MCoXï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šæœºå™¨äººååŒæ¢ç´¢ä¸æœç´¢æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.26324v2" data-paper-url="./papers/250926324v2-llm-mcox-large-language-model-based-multi-robot-coordinated-explorat.html" onclick="toggleFavorite(this, '2509.26324v2', 'LLM-MCoX: Large Language Model-based Multi-robot Coordinated Exploration and Search')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/250925746v1-tacrefinenet-tactile-only-grasp-refinement-between-arbitrary-in-hand.html">TacRefineNet: Tactile-Only Grasp Refinement Between Arbitrary In-Hand Object Poses</a></td>
  <td>TacRefineNetï¼šæå‡ºä¸€ç§ä»… tactile çš„å¤šæŒ‡çµå·§æ‰‹æœ«ç«¯ä½å§¿ç²¾ç¡®è°ƒæ•´æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25746v1" data-paper-url="./papers/250925746v1-tacrefinenet-tactile-only-grasp-refinement-between-arbitrary-in-hand.html" onclick="toggleFavorite(this, '2509.25746v1', 'TacRefineNet: Tactile-Only Grasp Refinement Between Arbitrary In-Hand Object Poses')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>26</td>
  <td><a href="./papers/251000358v1-disa-iql-offline-reinforcement-learning-for-robust-soft-robot-contro.html">DiSA-IQL: Offline Reinforcement Learning for Robust Soft Robot Control under Distribution Shifts</a></td>
  <td>DiSA-IQLï¼šé¢å‘åˆ†å¸ƒåç§»ä¸‹æŸ”æ€§æœºå™¨äººé²æ£’æ§åˆ¶çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">DRL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.00358v1" data-paper-url="./papers/251000358v1-disa-iql-offline-reinforcement-learning-for-robust-soft-robot-contro.html" onclick="toggleFavorite(this, '2510.00358v1', 'DiSA-IQL: Offline Reinforcement Learning for Robust Soft Robot Control under Distribution Shifts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/250925718v1-vla-model-post-training-via-action-chunked-ppo-and-self-behavior-clo.html">VLA Model Post-Training via Action-Chunked PPO and Self Behavior Cloning</a></td>
  <td>æå‡ºåŸºäºåŠ¨ä½œå—PPOå’Œè‡ªè¡Œä¸ºå…‹éš†çš„VLAæ¨¡å‹åè®­ç»ƒæ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">PPO</span> <span class="paper-tag">behavior cloning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25718v1" data-paper-url="./papers/250925718v1-vla-model-post-training-via-action-chunked-ppo-and-self-behavior-clo.html" onclick="toggleFavorite(this, '2509.25718v1', 'VLA Model Post-Training via Action-Chunked PPO and Self Behavior Cloning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>28</td>
  <td><a href="./papers/250925966v1-muvla-learning-to-explore-object-navigation-via-map-understanding.html">MUVLA: Learning to Explore Object Navigation via Map Understanding</a></td>
  <td>MUVLAï¼šé€šè¿‡åœ°å›¾ç†è§£å­¦ä¹ ç‰©ä½“å¯¼èˆªï¼Œæå‡æ¢ç´¢èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">semantic map</span> <span class="paper-tag">vision-language-action</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25966v1" data-paper-url="./papers/250925966v1-muvla-learning-to-explore-object-navigation-via-map-understanding.html" onclick="toggleFavorite(this, '2509.25966v1', 'MUVLA: Learning to Explore Object Navigation via Map Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/250926222v1-terrain-awared-lidar-inertial-odometry-for-legged-wheel-robots-based.html">Terrain-Awared LiDAR-Inertial Odometry for Legged-Wheel Robots Based on Radial Basis Function Approximation</a></td>
  <td>æå‡ºåŸºäºå¾„å‘åŸºå‡½æ•°è¿‘ä¼¼çš„åœ°å½¢æ„ŸçŸ¥æ¿€å…‰æƒ¯æ€§é‡Œç¨‹è®¡ï¼Œç”¨äºè…¿è½®æœºå™¨äººã€‚</td>
  <td class="tags-cell"><span class="paper-tag">LIO</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.26222v1" data-paper-url="./papers/250926222v1-terrain-awared-lidar-inertial-odometry-for-legged-wheel-robots-based.html" onclick="toggleFavorite(this, '2509.26222v1', 'Terrain-Awared LiDAR-Inertial Odometry for Legged-Wheel Robots Based on Radial Basis Function Approximation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)