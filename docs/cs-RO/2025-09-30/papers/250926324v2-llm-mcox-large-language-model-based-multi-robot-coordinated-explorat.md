---
layout: default
title: LLM-MCoX: Large Language Model-based Multi-robot Coordinated Exploration and Search
---

# LLM-MCoX: Large Language Model-based Multi-robot Coordinated Exploration and Search

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26324" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26324v2</a>
  <a href="https://arxiv.org/pdf/2509.26324.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26324v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26324v2', 'LLM-MCoX: Large Language Model-based Multi-robot Coordinated Exploration and Search')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ruiyang Wang, Hao-Lun Hsu, David Hunt, Shaocheng Luo, Jiwoo Kim, Miroslav Pajic

**åˆ†ç±»**: cs.RO, cs.AI, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30 (æ›´æ–°: 2025-10-04)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**LLM-MCoXï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šæœºå™¨äººååŒæ¢ç´¢ä¸æœç´¢æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæœºå™¨äººç³»ç»Ÿ` `ååŒæ¢ç´¢` `ç›®æ ‡æœç´¢` `å¤§å‹è¯­è¨€æ¨¡å‹` `æœºå™¨äººå¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæœºå™¨äººç³»ç»Ÿåœ¨æœªçŸ¥å®¤å†…ç¯å¢ƒä¸­çš„è‡ªä¸»æ¢ç´¢å’Œç›®æ ‡æœç´¢é¢ä¸´æŒ‘æˆ˜ï¼Œä¼ ç»Ÿæ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„æœºå™¨äººé—´åè°ƒã€‚
2. LLM-MCoXåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ™ºèƒ½åè°ƒï¼Œç»“åˆæ¿€å…‰é›·è¾¾æ‰«æå’Œå¤šæ¨¡æ€LLMæ¨ç†ï¼Œç”ŸæˆååŒèˆªç‚¹åˆ†é…ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLLM-MCoXåœ¨æ¢ç´¢é€Ÿåº¦å’Œæœç´¢æ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶æ”¯æŒè‡ªç„¶è¯­è¨€å¼•å¯¼çš„ç›®æ ‡æœç´¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºLLM-MCoXçš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ™ºèƒ½åœ°åè°ƒåŒæ„å’Œå¼‚æ„æœºå™¨äººå›¢é˜Ÿï¼Œä»¥å®ç°é«˜æ•ˆçš„æ¢ç´¢å’Œç›®æ ‡å¯¹è±¡æœç´¢ã€‚è¯¥æ–¹æ³•ç»“åˆäº†å®æ—¶æ¿€å…‰é›·è¾¾æ‰«æå¤„ç†ï¼Œç”¨äºæå–å‰æ²¿èšç±»å’Œæ£€æµ‹é—¨å£ï¼Œä»¥åŠå¤šæ¨¡æ€LLMæ¨ç†ï¼ˆä¾‹å¦‚GPT-4oï¼‰ï¼Œä»¥åŸºäºå…±äº«ç¯å¢ƒåœ°å›¾å’Œæœºå™¨äººçŠ¶æ€ç”Ÿæˆåè°ƒçš„èˆªç‚¹åˆ†é…ã€‚ä¸ç°æœ‰çš„æ–¹æ³•ï¼ˆåŒ…æ‹¬è´ªå©ªå’ŒåŸºäºVoronoiçš„è§„åˆ’å™¨ï¼‰ç›¸æ¯”ï¼ŒLLM-MCoXè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œåœ¨å…·æœ‰6ä¸ªæœºå™¨äººçš„å¤§å‹ç¯å¢ƒä¸­ï¼Œæ¢ç´¢æ—¶é—´ç¼©çŸ­äº†22.7ï¼…ï¼Œæœç´¢æ•ˆç‡æé«˜äº†50ï¼…ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒLLM-MCoXå®ç°äº†åŸºäºè‡ªç„¶è¯­è¨€çš„å¯¹è±¡æœç´¢åŠŸèƒ½ï¼Œå…è®¸äººç±»æ“ä½œå‘˜æä¾›ä¼ ç»Ÿç®—æ³•æ— æ³•è§£é‡Šçš„é«˜çº§è¯­ä¹‰æŒ‡å¯¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤šæœºå™¨äººååŒæ¢ç´¢å’Œæœç´¢ä»»åŠ¡æ—¨åœ¨é«˜æ•ˆåœ°è¦†ç›–æœªçŸ¥ç¯å¢ƒå¹¶å®šä½ç‰¹å®šç›®æ ‡ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚è´ªå©ªç®—æ³•å’ŒåŸºäºVoronoiå›¾çš„è§„åˆ’å™¨ï¼Œé€šå¸¸ä¾èµ–äºå±€éƒ¨ä¿¡æ¯ï¼Œç¼ºä¹å…¨å±€ååŒï¼Œå¯¼è‡´æ¢ç´¢æ•ˆç‡ä½ä¸‹ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚ç¯å¢ƒä¸­ã€‚æ­¤å¤–ï¼Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥ç†è§£å’Œåˆ©ç”¨äººç±»æ“ä½œå‘˜æä¾›çš„è¯­ä¹‰ä¿¡æ¯è¿›è¡Œç›®æ ‡æœç´¢ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLLM-MCoXçš„æ ¸å¿ƒåœ¨äºåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼ºå¤§æ¨ç†èƒ½åŠ›ï¼Œå¯¹å¤šæœºå™¨äººç³»ç»Ÿçš„æ¢ç´¢å’Œæœç´¢è¿‡ç¨‹è¿›è¡Œå…¨å±€ä¼˜åŒ–å’ŒååŒã€‚LLMèƒ½å¤Ÿç†è§£ç¯å¢ƒä¿¡æ¯ã€æœºå™¨äººçŠ¶æ€ä»¥åŠäººç±»æŒ‡ä»¤ï¼Œå¹¶ç”Ÿæˆåè°ƒçš„èˆªç‚¹åˆ†é…æ–¹æ¡ˆï¼Œä»è€Œæé«˜æ¢ç´¢æ•ˆç‡å’Œæœç´¢ç²¾åº¦ã€‚è¿™ç§æ–¹æ³•å°†ä¼ ç»Ÿçš„å‡ ä½•è§„åˆ’ä¸LLMçš„è¯­ä¹‰ç†è§£èƒ½åŠ›ç›¸ç»“åˆï¼Œå®ç°äº†æ›´æ™ºèƒ½çš„æœºå™¨äººååŒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLLM-MCoXæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) **ç¯å¢ƒæ„ŸçŸ¥æ¨¡å—**ï¼šåˆ©ç”¨æ¿€å…‰é›·è¾¾æ‰«æè·å–ç¯å¢ƒä¿¡æ¯ï¼Œæå–å‰æ²¿èšç±»å’Œæ£€æµ‹é—¨å£ç­‰å…³é”®ç‰¹å¾ã€‚2) **LLMæ¨ç†æ¨¡å—**ï¼šå°†ç¯å¢ƒä¿¡æ¯ã€æœºå™¨äººçŠ¶æ€å’Œäººç±»æŒ‡ä»¤è¾“å…¥LLMï¼ˆå¦‚GPT-4oï¼‰ï¼ŒLLMæ ¹æ®è¿™äº›ä¿¡æ¯ç”Ÿæˆåè°ƒçš„èˆªç‚¹åˆ†é…æ–¹æ¡ˆã€‚3) **è¿åŠ¨è§„åˆ’æ¨¡å—**ï¼šæ ¹æ®LLMç”Ÿæˆçš„èˆªç‚¹ï¼Œä¸ºæ¯ä¸ªæœºå™¨äººè§„åˆ’å…·ä½“çš„è¿åŠ¨è½¨è¿¹ã€‚4) **æ‰§è¡Œæ¨¡å—**ï¼šæœºå™¨äººæ‰§è¡Œè§„åˆ’çš„è½¨è¿¹ï¼Œå¹¶å®æ—¶æ›´æ–°ç¯å¢ƒåœ°å›¾å’Œæœºå™¨äººçŠ¶æ€ã€‚æ•´ä¸ªæµç¨‹æ˜¯ä¸€ä¸ªå¾ªç¯è¿­ä»£çš„è¿‡ç¨‹ï¼Œæœºå™¨äººä¸æ–­æ¢ç´¢æ–°çš„åŒºåŸŸï¼Œå¹¶æ ¹æ®LLMçš„æŒ‡ä»¤è¿›è¡ŒååŒæœç´¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šLLM-MCoXçš„å…³é”®åˆ›æ–°åœ¨äºå°†å¤§å‹è¯­è¨€æ¨¡å‹å¼•å…¥å¤šæœºå™¨äººååŒæ¢ç´¢å’Œæœç´¢ä»»åŠ¡ä¸­ï¼Œåˆ©ç”¨LLMçš„è¯­ä¹‰ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œå®ç°äº†æ›´æ™ºèƒ½çš„æœºå™¨äººååŒã€‚ä¸ä¼ ç»Ÿçš„å‡ ä½•è§„åˆ’æ–¹æ³•ç›¸æ¯”ï¼ŒLLM-MCoXèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç¯å¢ƒä¿¡æ¯å’Œäººç±»æŒ‡ä»¤ï¼Œå¹¶ç”Ÿæˆæ›´ä¼˜çš„èˆªç‚¹åˆ†é…æ–¹æ¡ˆã€‚æ­¤å¤–ï¼ŒLLM-MCoXè¿˜æ”¯æŒè‡ªç„¶è¯­è¨€å¼•å¯¼çš„ç›®æ ‡æœç´¢ï¼Œå…è®¸äººç±»æ“ä½œå‘˜æä¾›é«˜çº§è¯­ä¹‰æŒ‡å¯¼ï¼Œè¿™æ˜¯ä¼ ç»Ÿç®—æ³•æ— æ³•å®ç°çš„ã€‚

**å…³é”®è®¾è®¡**ï¼šLLM-MCoXçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) **å¤šæ¨¡æ€è¾“å…¥**ï¼šLLMæ¥æ”¶æ¥è‡ªæ¿€å…‰é›·è¾¾æ‰«æçš„ç¯å¢ƒä¿¡æ¯ã€æœºå™¨äººçŠ¶æ€å’Œäººç±»æŒ‡ä»¤ç­‰å¤šæ¨¡æ€è¾“å…¥ã€‚2) **æç¤ºå·¥ç¨‹**ï¼šè®¾è®¡åˆé€‚çš„æç¤ºè¯­ï¼Œå¼•å¯¼LLMç”Ÿæˆç¬¦åˆè¦æ±‚çš„èˆªç‚¹åˆ†é…æ–¹æ¡ˆã€‚3) **å¥–åŠ±å‡½æ•°**ï¼šè®¾è®¡å¥–åŠ±å‡½æ•°ï¼Œé¼“åŠ±LLMç”Ÿæˆèƒ½å¤Ÿæœ€å¤§åŒ–æ¢ç´¢æ•ˆç‡å’Œæœç´¢ç²¾åº¦çš„èˆªç‚¹åˆ†é…æ–¹æ¡ˆã€‚4) **è¿­ä»£ä¼˜åŒ–**ï¼šé€šè¿‡è¿­ä»£ä¼˜åŒ–ï¼Œä¸æ–­æ”¹è¿›LLMç”Ÿæˆçš„èˆªç‚¹åˆ†é…æ–¹æ¡ˆï¼Œæé«˜æœºå™¨äººååŒçš„æ•ˆç‡å’Œç²¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLM-MCoXåœ¨å¤§å‹ç¯å¢ƒä¸­ï¼Œä¸è´ªå©ªç®—æ³•å’ŒåŸºäºVoronoiå›¾çš„è§„åˆ’å™¨ç›¸æ¯”ï¼Œæ¢ç´¢æ—¶é—´ç¼©çŸ­äº†22.7ï¼…ï¼Œæœç´¢æ•ˆç‡æé«˜äº†50ï¼…ã€‚æ­¤å¤–ï¼ŒLLM-MCoXè¿˜å®ç°äº†è‡ªç„¶è¯­è¨€å¼•å¯¼çš„ç›®æ ‡æœç´¢åŠŸèƒ½ï¼Œå…è®¸äººç±»æ“ä½œå‘˜æä¾›é«˜çº§è¯­ä¹‰æŒ‡å¯¼ï¼Œè¿™æ˜¯ä¼ ç»Ÿç®—æ³•æ— æ³•å®ç°çš„ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒLLM-MCoXåœ¨å¤šæœºå™¨äººååŒæ¢ç´¢å’Œæœç´¢ä»»åŠ¡ä¸­å…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LLM-MCoXå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨ç¾éš¾æ•‘æ´ä¸­ï¼Œå¯ä»¥åˆ©ç”¨å¤šæœºå™¨äººç³»ç»Ÿå¿«é€Ÿæ¢ç´¢å—ç¾åŒºåŸŸï¼Œå®šä½å¹¸å­˜è€…ï¼›åœ¨ä»“åº“ç®¡ç†ä¸­ï¼Œå¯ä»¥åˆ©ç”¨å¤šæœºå™¨äººç³»ç»Ÿé«˜æ•ˆåœ°è¿›è¡Œè´§ç‰©ç›˜ç‚¹å’Œæ¬è¿ï¼›åœ¨å®‰é˜²å·¡é€»ä¸­ï¼Œå¯ä»¥åˆ©ç”¨å¤šæœºå™¨äººç³»ç»Ÿè¿›è¡Œå…¨æ–¹ä½ç›‘æ§å’Œå¼‚å¸¸æ£€æµ‹ã€‚è¯¥ç ”ç©¶çš„å®é™…ä»·å€¼åœ¨äºæé«˜äº†å¤šæœºå™¨äººç³»ç»Ÿçš„è‡ªä¸»æ€§å’ŒååŒèƒ½åŠ›ï¼Œæœªæ¥æœ‰æœ›åº”ç”¨äºæ›´å¤æ‚çš„ç¯å¢ƒå’Œä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autonomous exploration and object search in unknown indoor environments remain challenging for multi-robot systems (MRS). Traditional approaches often rely on greedy frontier assignment strategies with limited inter-robot coordination. In this work, we introduce LLM-MCoX (LLM-based Multi-robot Coordinated Exploration and Search), a novel framework that leverages Large Language Models (LLMs) for intelligent coordination of both homogeneous and heterogeneous robot teams tasked with efficient exploration and target object search. Our approach combines real-time LiDAR scan processing for frontier cluster extraction and doorway detection with multimodal LLM reasoning (e.g., GPT-4o) to generate coordinated waypoint assignments based on shared environment maps and robot states. LLM-MCoX demonstrates superior performance compared to existing methods, including greedy and Voronoi-based planners, achieving 22.7% faster exploration times and 50% improved search efficiency in large environments with 6 robots. Notably, LLM-MCoX enables natural language-based object search capabilities, allowing human operators to provide high-level semantic guidance that traditional algorithms cannot interpret.

