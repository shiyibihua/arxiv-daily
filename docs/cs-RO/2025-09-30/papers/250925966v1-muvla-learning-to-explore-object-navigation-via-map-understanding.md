---
layout: default
title: MUVLA: Learning to Explore Object Navigation via Map Understanding
---

# MUVLA: Learning to Explore Object Navigation via Map Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25966" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25966v1</a>
  <a href="https://arxiv.org/pdf/2509.25966.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25966v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25966v1', 'MUVLA: Learning to Explore Object Navigation via Map Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Peilong Han, Fan Jia, Min Zhang, Yutao Qiu, Hongyao Tang, Yan Zheng, Tiancai Wang, Jianye Hao

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MUVLAï¼šé€šè¿‡åœ°å›¾ç†è§£å­¦ä¹ ç‰©ä½“å¯¼èˆªï¼Œæå‡æ¢ç´¢èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç‰©ä½“å¯¼èˆª` `è¯­ä¹‰åœ°å›¾` `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `æ¨¡ä»¿å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç‰©ä½“å¯¼èˆªæ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨å†å²ä¿¡æ¯ï¼Œå¯¼è‡´æ¢ç´¢æ•ˆç‡ä½ä¸‹ã€‚
2. MUVLAé€šè¿‡è¯­ä¹‰åœ°å›¾æŠ½è±¡ç»Ÿä¸€å†å²ä¿¡æ¯ï¼Œå¹¶ç»“åˆè§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œä¿¡æ¯è¿›è¡Œå»ºæ¨¡ã€‚
3. MUVLAåœ¨HM3Då’ŒGibsonæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶èƒ½ä»ä½è´¨é‡è½¨è¿¹ä¸­å­¦ä¹ ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†MUVLAï¼Œä¸€ä¸ªä¸“ä¸ºç‰©ä½“å¯¼èˆªè®¾è®¡çš„åœ°å›¾ç†è§£è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ã€‚å®ƒåˆ©ç”¨è¯­ä¹‰åœ°å›¾æŠ½è±¡æ¥ç»Ÿä¸€å’Œç»“æ„åŒ–å†å²ä¿¡æ¯ï¼Œä»¥ç´§å‡‘ä¸”ä¸€è‡´çš„å½¢å¼ç¼–ç ç©ºé—´ä¸Šä¸‹æ–‡ã€‚MUVLAå°†å½“å‰å’Œå†å²è§‚æµ‹ä»¥åŠè¯­ä¹‰åœ°å›¾ä½œä¸ºè¾“å…¥ï¼Œå¹¶æ ¹æ®ç›®æ ‡ç‰©ä½“çš„æè¿°é¢„æµ‹åŠ¨ä½œåºåˆ—ã€‚æ­¤å¤–ï¼Œå®ƒé€šè¿‡åŸºäºå¯†é›†çŸ­ç¨‹è¿›å±•ä¿¡å·çš„å¥–åŠ±å¼•å¯¼å›æŠ¥å»ºæ¨¡æ¥æ”¾å¤§ç›‘ç£ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå‘å±•å¯¹å¥–åŠ±æœ€å¤§åŒ–çš„åŠ¨ä½œå€¼çš„è¯¦ç»†ç†è§£ã€‚MUVLAé‡‡ç”¨ä¸‰é˜¶æ®µè®­ç»ƒæµç¨‹ï¼šå­¦ä¹ åœ°å›¾çº§ç©ºé—´ç†è§£ã€æ¨¡ä»¿æ··åˆè´¨é‡æ¼”ç¤ºçš„è¡Œä¸ºä»¥åŠå¥–åŠ±æ”¾å¤§ã€‚è¿™ç§ç­–ç•¥ä½¿MUVLAèƒ½å¤Ÿå°†ä¸åŒçš„æ¼”ç¤ºç»Ÿä¸€ä¸ºé²æ£’çš„ç©ºé—´è¡¨ç¤ºï¼Œå¹¶ç”Ÿæˆæ›´åˆç†çš„æ¢ç´¢ç­–ç•¥ã€‚åœ¨HM3Då’ŒGibsonåŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMUVLAå®ç°äº†è‰¯å¥½çš„æ³›åŒ–ï¼Œå³ä½¿ä»ä½è´¨é‡æˆ–éƒ¨åˆ†æˆåŠŸçš„è½¨è¿¹ä¸­ä¹Ÿèƒ½å­¦ä¹ åˆ°æœ‰æ•ˆçš„æ¢ç´¢è¡Œä¸ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç‰©ä½“å¯¼èˆªä»»åŠ¡æ—¨åœ¨è®©æ™ºèƒ½ä½“åœ¨æœªçŸ¥ç¯å¢ƒä¸­æ‰¾åˆ°æŒ‡å®šçš„ç›®æ ‡ç‰©ä½“ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥æœ‰æ•ˆåœ°æ•´åˆå†å²è§‚æµ‹ä¿¡æ¯ï¼Œå¯¼è‡´æ¢ç´¢è¿‡ç¨‹æ•ˆç‡ä½ä¸‹ï¼Œå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚æ­¤å¤–ï¼Œå¦‚ä½•ä»ä¸åŒè´¨é‡çš„æ¼”ç¤ºæ•°æ®ä¸­å­¦ä¹ ä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMUVLAçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è¯­ä¹‰åœ°å›¾æŠ½è±¡æ¥ç»Ÿä¸€å’Œç»“æ„åŒ–å†å²ä¿¡æ¯ï¼Œä»è€Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç¯å¢ƒçš„ç©ºé—´ç»“æ„ã€‚é€šè¿‡å°†è§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œä¿¡æ¯ä¸è¯­ä¹‰åœ°å›¾ç›¸ç»“åˆï¼ŒMUVLAèƒ½å¤Ÿé¢„æµ‹æ›´åˆç†çš„å¯¼èˆªç­–ç•¥ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¥–åŠ±å¼•å¯¼çš„å›æŠ¥å»ºæ¨¡ï¼ŒMUVLAèƒ½å¤Ÿä»ä½è´¨é‡çš„æ¼”ç¤ºæ•°æ®ä¸­å­¦ä¹ ï¼Œå¹¶æå‡æ¢ç´¢èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMUVLAçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1) åœ°å›¾çº§ç©ºé—´ç†è§£å­¦ä¹ ï¼šåˆ©ç”¨å†å²è§‚æµ‹æ„å»ºè¯­ä¹‰åœ°å›¾ï¼Œå¹¶å­¦ä¹ åœ°å›¾çš„ç©ºé—´è¡¨ç¤ºã€‚2) è¡Œä¸ºæ¨¡ä»¿å­¦ä¹ ï¼šåˆ©ç”¨æ··åˆè´¨é‡çš„æ¼”ç¤ºæ•°æ®ï¼Œæ¨¡ä»¿äººç±»çš„å¯¼èˆªè¡Œä¸ºã€‚3) å¥–åŠ±æ”¾å¤§ï¼šé€šè¿‡å¥–åŠ±å¼•å¯¼çš„å›æŠ¥å»ºæ¨¡ï¼Œæå‡æ™ºèƒ½ä½“çš„æ¢ç´¢èƒ½åŠ›ã€‚MUVLAæ¨¡å‹ä»¥å½“å‰å’Œå†å²è§‚æµ‹ä»¥åŠè¯­ä¹‰åœ°å›¾ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºåŠ¨ä½œåºåˆ—ã€‚

**å…³é”®åˆ›æ–°**ï¼šMUVLAçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) åˆ©ç”¨è¯­ä¹‰åœ°å›¾æŠ½è±¡æ¥ç»Ÿä¸€å’Œç»“æ„åŒ–å†å²ä¿¡æ¯ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£ç¯å¢ƒçš„ç©ºé—´ç»“æ„ã€‚2) é‡‡ç”¨å¥–åŠ±å¼•å¯¼çš„å›æŠ¥å»ºæ¨¡ï¼Œä»ä½è´¨é‡çš„æ¼”ç¤ºæ•°æ®ä¸­å­¦ä¹ ï¼Œå¹¶æå‡æ¢ç´¢èƒ½åŠ›ã€‚3) ä¸‰é˜¶æ®µè®­ç»ƒæµç¨‹ï¼Œé€æ­¥æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMUVLAèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨å†å²ä¿¡æ¯ï¼Œå¹¶ä»ä¸åŒè´¨é‡çš„æ¼”ç¤ºæ•°æ®ä¸­å­¦ä¹ ã€‚

**å…³é”®è®¾è®¡**ï¼šMUVLAä½¿ç”¨Transformerç½‘ç»œæ¥ç¼–ç è§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œä¿¡æ¯ã€‚è¯­ä¹‰åœ°å›¾é‡‡ç”¨æ …æ ¼åœ°å›¾è¡¨ç¤ºï¼Œæ¯ä¸ªæ …æ ¼åŒ…å«è¯­ä¹‰ä¿¡æ¯ã€‚å¥–åŠ±å¼•å¯¼çš„å›æŠ¥å»ºæ¨¡ä½¿ç”¨Q-learningç®—æ³•ï¼Œé€šè¿‡å¯†é›†çŸ­ç¨‹è¿›å±•ä¿¡å·æ¥è®¡ç®—å¥–åŠ±ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æ¨¡ä»¿å­¦ä¹ æŸå¤±å’ŒQ-learningæŸå¤±ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MUVLAåœ¨HM3Då’ŒGibsonåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMUVLAèƒ½å¤Ÿä»ä½è´¨é‡æˆ–éƒ¨åˆ†æˆåŠŸçš„è½¨è¿¹ä¸­å­¦ä¹ åˆ°æœ‰æ•ˆçš„æ¢ç´¢è¡Œä¸ºï¼Œå¹¶ä¸”å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚ç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼ŒMUVLAåœ¨å¯¼èˆªæˆåŠŸç‡å’Œè·¯å¾„é•¿åº¦æ–¹é¢å‡æœ‰æ˜æ˜¾æ”¹å–„ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MUVLAæŠ€æœ¯å¯åº”ç”¨äºå®¶åº­æœåŠ¡æœºå™¨äººã€ä»“å‚¨ç‰©æµæœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ï¼Œå¯ä»¥å®ç°æ›´é«˜æ•ˆã€æ›´æ™ºèƒ½çš„è‡ªåŠ¨åŒ–æœåŠ¡ï¼Œä¾‹å¦‚å®¶åº­æ¸…æ´ã€ç‰©å“æ¬è¿ã€è‡ªåŠ¨é©¾é©¶å¯¼èˆªç­‰ï¼Œå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯å’Œå®é™…ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this paper, we present MUVLA, a Map Understanding Vision-Language-Action model tailored for object navigation. It leverages semantic map abstractions to unify and structure historical information, encoding spatial context in a compact and consistent form. MUVLA takes the current and history observations, as well as the semantic map, as inputs and predicts the action sequence based on the description of goal object. Furthermore, it amplifies supervision through reward-guided return modeling based on dense short-horizon progress signals, enabling the model to develop a detailed understanding of action value for reward maximization. MUVLA employs a three-stage training pipeline: learning map-level spatial understanding, imitating behaviors from mixed-quality demonstrations, and reward amplification. This strategy allows MUVLA to unify diverse demonstrations into a robust spatial representation and generate more rational exploration strategies. Experiments on HM3D and Gibson benchmarks demonstrate that MUVLA achieves great generalization and learns effective exploration behaviors even from low-quality or partially successful trajectories.

