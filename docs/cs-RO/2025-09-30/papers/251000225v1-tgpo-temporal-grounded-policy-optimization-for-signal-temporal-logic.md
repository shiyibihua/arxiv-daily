---
layout: default
title: TGPO: Temporal Grounded Policy Optimization for Signal Temporal Logic Tasks
---

# TGPO: Temporal Grounded Policy Optimization for Signal Temporal Logic Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00225" class="toolbar-btn" target="_blank">üìÑ arXiv: 2510.00225v1</a>
  <a href="https://arxiv.org/pdf/2510.00225.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00225v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00225v1', 'TGPO: Temporal Grounded Policy Optimization for Signal Temporal Logic Tasks')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yue Meng, Fei Chen, Chuchu Fan

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.LG, cs.LO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-30

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/mengyuest/TGPO)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**TGPOÔºöÊó∂Â∫èÁ∫¶Êùü‰∏ãÁöÑÁ≠ñÁï•‰ºòÂåñÔºåËß£ÂÜ≥Êú∫Âô®‰∫∫Â§çÊùÇÊó∂Â∫èÈÄªËæë‰ªªÂä°**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Âº∫ÂåñÂ≠¶‰π†` `‰ø°Âè∑Êó∂Â∫èÈÄªËæë` `ÂàÜÂ±ÇÁ≠ñÁï•` `Êó∂Èó¥Á∫¶Êùü` `Êú∫Âô®‰∫∫ÊéßÂà∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰º†ÁªüÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÈöæ‰ª•Ëß£ÂÜ≥ÂÖ∑ÊúâÈùûÈ©¨Â∞îÂèØÂ§´ÊÄßÂíåÁ®ÄÁñèÂ•ñÂä±ÁöÑÂ§çÊùÇ‰ø°Âè∑Êó∂Â∫èÈÄªËæëÔºàSTLÔºâ‰ªªÂä°„ÄÇ
2. TGPOÂ∞ÜSTL‰ªªÂä°ÂàÜËß£‰∏∫Â∏¶Êó∂Èó¥Á∫¶ÊùüÁöÑÂ≠êÁõÆÊ†áÔºåÈÄöËøáÂàÜÂ±ÇÊ°ÜÊû∂ÂíåÊó∂Èó¥Êù°‰ª∂Á≠ñÁï•Â≠¶‰π†ÂÆûÁé∞È´òÊïàÊ±ÇËß£„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåTGPOÂú®Â§öÁßçÊú∫Âô®‰∫∫‰ªªÂä°‰∏≠ÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂ∞§ÂÖ∂Âú®È´òÁª¥ÂíåÈïøÊó∂Á®ã‰ªªÂä°‰∏≠„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫Êó∂Â∫èÁ∫¶Êùü‰∏ãÁöÑÁ≠ñÁï•‰ºòÂåñÔºàTGPOÔºâÁÆóÊ≥ïÔºåÁî®‰∫éËß£ÂÜ≥ÈÄöÁî®‰ø°Âè∑Êó∂Â∫èÈÄªËæëÔºàSTLÔºâ‰ªªÂä°‰∏≠ÁöÑÊú∫Âô®‰∫∫ÊéßÂà∂Á≠ñÁï•Â≠¶‰π†ÈóÆÈ¢ò„ÄÇSTLÊòØ‰∏ÄÁßçÂº∫Â§ßÁöÑËØ≠Ë®ÄÔºåÂèØ‰ª•Ë°®ËææÂ§çÊùÇÁöÑ„ÄÅÈïøÊó∂Á®ãÁöÑ‰ªªÂä°Ôºå‰ΩÜÂÖ∂ÈùûÈ©¨Â∞îÂèØÂ§´ÊÄßÂíåÁ®ÄÁñèÂ•ñÂä±ÁâπÊÄß‰ΩøÂæóÊ†áÂáÜÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÁÆóÊ≥ïÈöæ‰ª•Â∫îÁî®„ÄÇTGPOÂ∞ÜSTL‰ªªÂä°ÂàÜËß£‰∏∫Â∏¶Êó∂Èó¥Á∫¶ÊùüÁöÑÂ≠êÁõÆÊ†áÂíå‰∏çÂèòÁ∫¶ÊùüÔºåÂπ∂Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÂàÜÂ±ÇÊ°ÜÊû∂Êù•Ëß£ÂÜ≥ËØ•ÈóÆÈ¢ò„ÄÇTGPOÁöÑÈ´òÂ±ÇÁªÑ‰ª∂‰∏∫Ëøô‰∫õÂ≠êÁõÆÊ†áÊèêÂá∫ÂÖ∑‰ΩìÁöÑÊó∂Â∫èÂàÜÈÖçÔºåËÄå‰ΩéÂ±ÇÁöÑÊó∂Èó¥Êù°‰ª∂Á≠ñÁï•Â≠¶‰π†‰ΩøÁî®ÂØÜÈõÜÁöÑ„ÄÅÈò∂ÊÆµÊÄßÁöÑÂ•ñÂä±‰ø°Âè∑Êù•ÂÆûÁé∞Â∫èÂàóÂåñÁöÑÂ≠êÁõÆÊ†á„ÄÇÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÔºåÊàë‰ª¨ÈááÊ†∑ÂêÑÁßçÊó∂Â∫èÂàÜÈÖçÔºåÂπ∂ÈÄâÊã©ÊúÄÊúâÂ∏åÊúõÁöÑÂàÜÈÖçÔºåËÆ©Á≠ñÁï•ÁΩëÁªúÂ±ïÂºÄËß£ÂÜ≥ÊñπÊ°àËΩ®Ëøπ„ÄÇ‰∏∫‰∫Ü‰øÉËøõÂ§çÊùÇSTL‰ªªÂä°ÁöÑÈ´òÊïàÁ≠ñÁï•Â≠¶‰π†ÔºåÊàë‰ª¨Âà©Áî®Â≠¶‰π†Âà∞ÁöÑËØÑËÆ∫ÂÆ∂ÁΩëÁªúÔºåÈÄöËøáMetropolis-HastingsÈááÊ†∑Êù•ÊåáÂØºÈ´òÂ±ÇÊó∂Â∫èÊêúÁ¥¢ÔºåÂ∞ÜÊé¢Á¥¢ÈáçÁÇπÊîæÂú®Êó∂Èó¥‰∏äÂèØË°åÁöÑËß£ÂÜ≥ÊñπÊ°à‰∏ä„ÄÇÂú®‰∫î‰∏™ÁéØÂ¢É‰∏≠ËøõË°åÁöÑÂÆûÈ™åË°®ÊòéÔºåTGPOÂú®ÂêÑÁßçSTL‰ªªÂä°‰∏ãÊòæËëó‰ºò‰∫éÊúÄÂÖàËøõÁöÑÂü∫Á∫øÊñπÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÂú®È´òÁª¥ÂíåÈïøÊó∂Á®ãÊÉÖÂÜµ‰∏ãÔºå‰ªªÂä°ÊàêÂäüÁéáÂπ≥ÂùáÊèêÈ´ò‰∫Ü31.6%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Êú∫Âô®‰∫∫ÂíåËá™‰∏ªÁ≥ªÁªü‰∏≠ÔºåÂ¶Ç‰ΩïÂ≠¶‰π†Êª°Ë∂≥Â§çÊùÇ„ÄÅÈïøÊó∂Á®ã‰ø°Âè∑Êó∂Â∫èÈÄªËæëÔºàSTLÔºâ‰ªªÂä°ÁöÑÊéßÂà∂Á≠ñÁï•ÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïË¶Å‰πàÂè™ËÉΩÂ§ÑÁêÜÊúâÈôêÁöÑSTLÁâáÊÆµÔºåË¶Å‰πà‰ªÖ‰ΩøÁî®STLÈ≤ÅÊ£íÊÄßÂæóÂàÜ‰Ωú‰∏∫Á®ÄÁñèÁöÑÁªàÁ´ØÂ•ñÂä±ÔºåÂØºËá¥Â≠¶‰π†ÊïàÁéá‰Ωé‰∏ãÔºåÈöæ‰ª•Â§ÑÁêÜÂ§çÊùÇ‰ªªÂä°„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöTGPOÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÂ§çÊùÇÁöÑSTL‰ªªÂä°ÂàÜËß£‰∏∫‰∏ÄÁ≥ªÂàóÂ∏¶Êó∂Èó¥Á∫¶ÊùüÁöÑÂ≠êÁõÆÊ†áÂíå‰∏çÂèòÁ∫¶Êùü„ÄÇÈÄöËøáÂàÜÂ±ÇÁ≠ñÁï•ÔºåÈ´òÂ±ÇË¥üË¥£ËßÑÂàíÂ≠êÁõÆÊ†áÁöÑÊó∂Èó¥ÂàÜÈÖçÔºå‰ΩéÂ±ÇÂ≠¶‰π†Âú®ÁªôÂÆöÊó∂Èó¥Á∫¶Êùü‰∏ãÂÆåÊàêÂ≠êÁõÆÊ†áÁöÑÁ≠ñÁï•„ÄÇËøôÁßçÂàÜËß£ÂíåÂàÜÂ±ÇÂ≠¶‰π†ÁöÑÊñπÂºèÔºåËÉΩÂ§üÂ∞ÜÁ®ÄÁñèÂ•ñÂä±ÈóÆÈ¢òËΩ¨Âåñ‰∏∫ÂØÜÈõÜÁöÑÈò∂ÊÆµÊÄßÂ•ñÂä±Ôºå‰ªéËÄåÂä†ÈÄüÂ≠¶‰π†ËøáÁ®ã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöTGPOÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÁªÑ‰ª∂ÔºöÈ´òÂ±ÇÊó∂Â∫èËßÑÂàíÂô®Âíå‰ΩéÂ±ÇÊó∂Èó¥Êù°‰ª∂Á≠ñÁï•Â≠¶‰π†Âô®„ÄÇÈ´òÂ±ÇËßÑÂàíÂô®‰ΩøÁî®Metropolis-HastingsÈááÊ†∑ÊñπÊ≥ïÔºåÂü∫‰∫éËØÑËÆ∫ÂÆ∂ÁΩëÁªúÁöÑÊåáÂØºÔºåÊêúÁ¥¢ÂèØË°åÁöÑÂ≠êÁõÆÊ†áÊó∂Èó¥ÂàÜÈÖçÊñπÊ°à„ÄÇ‰ΩéÂ±ÇÁ≠ñÁï•Â≠¶‰π†Âô®ÂàôÊòØ‰∏Ä‰∏™Êó∂Èó¥Êù°‰ª∂Á≠ñÁï•ÁΩëÁªúÔºåÂÆÉÊ†πÊçÆÈ´òÂ±ÇËßÑÂàíÂô®ÁªôÂÆöÁöÑÊó∂Èó¥Á∫¶ÊùüÔºåÂ≠¶‰π†Â¶Ç‰ΩïËææÂà∞Áõ∏Â∫îÁöÑÂ≠êÁõÆÊ†á„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÔºöÈ¶ñÂÖàÔºåÈ´òÂ±ÇËßÑÂàíÂô®ÊèêÂá∫‰∏Ä‰∏™Êó∂Èó¥ÂàÜÈÖçÊñπÊ°àÔºõÁÑ∂ÂêéÔºå‰ΩéÂ±ÇÁ≠ñÁï•Â≠¶‰π†Âô®Ê†πÊçÆËØ•ÊñπÊ°àÊâßË°åÂä®‰ΩúÔºõÊúÄÂêéÔºåÊ†πÊçÆÊâßË°åÁªìÊûúÂíåSTLËßÑËåÉÔºåËÆ°ÁÆóÂ•ñÂä±Âπ∂Êõ¥Êñ∞È´òÂ±ÇËßÑÂàíÂô®Âíå‰ΩéÂ±ÇÁ≠ñÁï•Â≠¶‰π†Âô®„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöTGPOÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜSTL‰ªªÂä°ÂàÜËß£‰∏∫Â∏¶Êó∂Èó¥Á∫¶ÊùüÁöÑÂ≠êÁõÆÊ†áÔºåÂπ∂‰ΩøÁî®ÂàÜÂ±ÇÁ≠ñÁï•ËøõË°åÂ≠¶‰π†„ÄÇËøôÁßçÂàÜËß£ÊñπÂºèÂ∞ÜÂ§çÊùÇÁöÑÂÖ®Â±Ä‰ºòÂåñÈóÆÈ¢òËΩ¨Âåñ‰∏∫‰∏ÄÁ≥ªÂàóÁõ∏ÂØπÁÆÄÂçïÁöÑÂ±ÄÈÉ®‰ºòÂåñÈóÆÈ¢òÔºå‰ªéËÄåÈôç‰Ωé‰∫ÜÂ≠¶‰π†ÈöæÂ∫¶„ÄÇÊ≠§Â§ñÔºåÂà©Áî®ËØÑËÆ∫ÂÆ∂ÁΩëÁªúÊåáÂØºÈ´òÂ±ÇÊó∂Â∫èÊêúÁ¥¢ÔºåËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Êé¢Á¥¢ÂèØË°åÁöÑÊó∂Èó¥ÂàÜÈÖçÊñπÊ°à„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÈ´òÂ±ÇËßÑÂàíÂô®‰ΩøÁî®Metropolis-HastingsÈááÊ†∑ÔºåÂÖ∂Êé•ÂèóÊ¶ÇÁéáÂü∫‰∫éËØÑËÆ∫ÂÆ∂ÁΩëÁªúÂØπÂΩìÂâçÊó∂Èó¥ÂàÜÈÖçÊñπÊ°àÁöÑËØÑ‰º∞„ÄÇ‰ΩéÂ±ÇÁ≠ñÁï•Â≠¶‰π†Âô®ÈááÁî®Êó∂Èó¥Êù°‰ª∂Á≠ñÁï•ÁΩëÁªúÔºåÂÖ∂ËæìÂÖ•ÂåÖÊã¨ÂΩìÂâçÁä∂ÊÄÅÂíåÂâ©‰ΩôÊó∂Èó¥„ÄÇÂ•ñÂä±ÂáΩÊï∞ÁöÑËÆæËÆ°Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÊó¢Ë¶Å‰øùËØÅÂ≠êÁõÆÊ†áÁöÑÂÆåÊàêÔºåÂèàË¶ÅÊª°Ë∂≥STLËßÑËåÉÁöÑÁ∫¶Êùü„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÔºàÂ¶ÇÈááÊ†∑Ê≠•Êï∞„ÄÅÂ≠¶‰π†ÁéáÁ≠âÔºâÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰Ωì‰ªªÂä°ËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåTGPOÂú®‰∫î‰∏™‰∏çÂêåÁöÑÁéØÂ¢É‰∏≠ÔºåÂåÖÊã¨‰ΩéÁª¥ÂØºËà™„ÄÅÊú∫Ê¢∞ËáÇÊìç‰Ωú„ÄÅÊó†‰∫∫Êú∫ÊéßÂà∂ÂíåÂõõË∂≥Êú∫Âô®‰∫∫ËøêÂä®ÔºåÂùáÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÂü∫Á∫øÊñπÊ≥ï„ÄÇÂú®È´òÁª¥ÂíåÈïøÊó∂Á®ã‰ªªÂä°‰∏≠ÔºåTGPOÁöÑ‰ºòÂäøÊõ¥Âä†ÊòéÊòæÔºå‰ªªÂä°ÊàêÂäüÁéáÂπ≥ÂùáÊèêÈ´ò‰∫Ü31.6%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåTGPOÊòØ‰∏ÄÁßçÊúâÊïàÁöÑËß£ÂÜ≥Â§çÊùÇSTL‰ªªÂä°ÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

TGPOÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇËá™‰∏ªÂØºËà™„ÄÅÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÅÊó†‰∫∫Êú∫ÊéßÂà∂ÂíåÂõõË∂≥Êú∫Âô®‰∫∫ËøêÂä®Á≠â„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÂºÄÂèëËÉΩÂ§üÊâßË°åÂ§çÊùÇ‰ªªÂä°ÁöÑÊô∫ËÉΩ‰ΩìÔºå‰æãÂ¶ÇÂú®‰ªìÂ∫ì‰∏≠ÊåâÁÖßÁâπÂÆöÈ°∫Â∫èÊã£ÈÄâÁâ©ÂìÅ„ÄÅÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ËøõË°åËá™‰∏ªÂ∑°ÈÄª„ÄÅÊàñËÄÖÂú®ÁÅæÈöæÁé∞Âú∫ËøõË°åÊêúÊïëÁ≠â„ÄÇTGPOÁöÑÊú™Êù•ÂèëÂ±ïÊñπÂêëÂåÖÊã¨Ëøõ‰∏ÄÊ≠•ÊèêÈ´òÂ≠¶‰π†ÊïàÁéá„ÄÅÊâ©Â±ïÂà∞Êõ¥Â§çÊùÇÁöÑSTLËßÑËåÉ„ÄÅ‰ª•Âèä‰∏éÂÖ∂‰ªñÊÑüÁü•ÂíåËßÑÂàíÊ®°ÂùóÁöÑÈõÜÊàê„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Learning control policies for complex, long-horizon tasks is a central challenge in robotics and autonomous systems. Signal Temporal Logic (STL) offers a powerful and expressive language for specifying such tasks, but its non-Markovian nature and inherent sparse reward make it difficult to be solved via standard Reinforcement Learning (RL) algorithms. Prior RL approaches focus only on limited STL fragments or use STL robustness scores as sparse terminal rewards. In this paper, we propose TGPO, Temporal Grounded Policy Optimization, to solve general STL tasks. TGPO decomposes STL into timed subgoals and invariant constraints and provides a hierarchical framework to tackle the problem. The high-level component of TGPO proposes concrete time allocations for these subgoals, and the low-level time-conditioned policy learns to achieve the sequenced subgoals using a dense, stage-wise reward signal. During inference, we sample various time allocations and select the most promising assignment for the policy network to rollout the solution trajectory. To foster efficient policy learning for complex STL with multiple subgoals, we leverage the learned critic to guide the high-level temporal search via Metropolis-Hastings sampling, focusing exploration on temporally feasible solutions. We conduct experiments on five environments, ranging from low-dimensional navigation to manipulation, drone, and quadrupedal locomotion. Under a wide range of STL tasks, TGPO significantly outperforms state-of-the-art baselines (especially for high-dimensional and long-horizon cases), with an average of 31.6% improvement in task success rate compared to the best baseline. The code will be available at https://github.com/mengyuest/TGPO

