---
layout: default
title: Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation
---

# Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25852" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.25852v1</a>
  <a href="https://arxiv.org/pdf/2509.25852.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25852v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25852v1', 'Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zitong Bo, Yue Hu, Jinming Ma, Mingliang Zhou, Junhui Yin, Yachen Kang, Yuqi Liu, Tong Wu, Diyun Xiang, Hao Chen

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-30

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**REVERÔºöÂü∫‰∫éÂèØÈ™åËØÅÂ•ñÂä±ÁöÑÂº∫ÂåñÂÖ∑Ë∫´ËßÑÂàíÔºåÁî®‰∫éÁúüÂÆû‰∏ñÁïåÊú∫Âô®‰∫∫Êìç‰Ωú**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂÖ∑Ë∫´Êô∫ËÉΩ` `Êú∫Âô®‰∫∫Êìç‰Ωú` `ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã` `Âº∫ÂåñÂ≠¶‰π†` `ÈïøÁ®ãËßÑÂàí` `ÂèØÈ™åËØÅÂ•ñÂä±` `ÈìæÂºèÊÄùËÄÉ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÁº∫‰πèÂ§ßËßÑÊ®°„ÄÅÂ∫èÂàóÂåñÁöÑÊìç‰ΩúÊï∞ÊçÆÔºåÈöæ‰ª•ËÆ≠ÁªÉËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã(VLM)ËøõË°åÈïøÁ®ãÊìç‰Ωú‰ªªÂä°ËßÑÂàí„ÄÇ
2. REVERÊ°ÜÊû∂ÈÄöËøáËá™Âä®ÂåñÊ†áÊ≥®ÂºïÊìéÁîüÊàêËßÜËßâ-Êåá‰ª§-ËÆ°Âàí‰∏âÂÖÉÁªÑÊï∞ÊçÆÔºåÂπ∂ËÆæËÆ°ÂèØÈ™åËØÅÂ•ñÂä±Êù•ÂæÆË∞ÉVLM„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåRoboFarseerÂú®ÈïøÁ®ã‰ªªÂä°‰∏≠ÊòæËëóÊèêÂçá‰∫ÜÊú∫Âô®‰∫∫Êìç‰ΩúÁöÑÊàêÂäüÁéáÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫REVERÊ°ÜÊû∂ÔºåÊó®Âú®Ëß£ÂÜ≥ÂÖ∑Ë∫´AI‰∏≠Êú∫Âô®‰∫∫ÊâßË°åËá™Áî±ÂΩ¢ÂºèËØ≠Ë®ÄÊåá‰ª§ÁöÑÈïøÁ®ãÊìç‰Ωú‰ªªÂä°ÁöÑÊåëÊàò„ÄÇREVERËµãËÉΩËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã(VLM)Âú®ÁúüÂÆû‰∏ñÁïåÂú∫ÊôØ‰∏≠ÁîüÊàêÂíåÈ™åËØÅÈïøÁ®ãÊìç‰ΩúËÆ°Âàí„ÄÇËØ•Ê°ÜÊû∂ËÆ≠ÁªÉÂπ∂ÂèëÂ∏É‰∫ÜRoboFarseerÔºå‰∏Ä‰∏™VLMÔºåÂÆÉË¢´ÊøÄÂä±ÂèëÂá∫ÈìæÂºèÊÄùËÄÉÔºåÊâßË°åÊó∂Èó¥ÂíåÁ©∫Èó¥Êé®ÁêÜÔºåÁ°Æ‰øùÁâ©ÁêÜ‰∏äÂêàÁêÜÂíåÈÄªËæë‰∏äËøûË¥ØÁöÑËÆ°Âàí„ÄÇ‰∏∫‰∫ÜËé∑ÂæóËÆ≠ÁªÉÊï∞ÊçÆÔºåÂà©Áî®ÈÄöÁî®Êìç‰ΩúÁïåÈù¢Ê°ÜÊû∂ÊçïËé∑Á°¨‰ª∂Êó†ÂÖ≥ÁöÑÂéüÂ≠êÊäÄËÉΩÊºîÁ§∫ÔºåÂπ∂‰ΩøÁî®Ëá™Âä®Ê†áÊ≥®ÂºïÊìéÂ∞ÜÊØè‰∏™ÊºîÁ§∫ËΩ¨Êç¢‰∏∫ËßÜËßâ-Êåá‰ª§-ËÆ°Âàí‰∏âÂÖÉÁªÑ„ÄÇÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂèØÈ™åËØÅÂ•ñÂä±ÔºåÈÄöËøáÂÖ∂‰∏éÁúüÂÆûÊäÄËÉΩÂ∫èÂàóÁöÑÊúâÂ∫è‰∫åÂàÜÂåπÈÖçÈáçÂè†Êù•ÂØπÁîüÊàêÁöÑËÆ°ÂàíËøõË°åËØÑÂàÜ„ÄÇÂú®ËøêË°åÊó∂ÔºåÂæÆË∞ÉÂêéÁöÑVLMÊó¢ÂÖÖÂΩìËßÑÂàíÂô®ÂèàÂÖÖÂΩìÁõëËßÜÂô®ÔºåÈ™åËØÅÈÄêÊ≠•ÂÆåÊàêÊÉÖÂÜµ„ÄÇRoboFarseerÁöÑÊÄßËÉΩ‰∏éÂ§ßÂá†‰∏™Êï∞ÈáèÁ∫ßÁöÑ‰∏ìÊúâÊ®°ÂûãÁõ∏ÂåπÈÖçÊàñË∂ÖËøáÔºåÂπ∂‰∏îÂú®ÂºÄÊîæÂºèËßÑÂàí‰∏≠Ë∂ÖËøá‰∫ÜÊúÄ‰Ω≥Âü∫Á∫ø40%‰ª•‰∏ä„ÄÇÂú®ÁúüÂÆû‰∏ñÁïåÁöÑÈïøÁ®ã‰ªªÂä°‰∏≠Ôºå‰∏éÊ≤°ÊúâËßÑÂàíÂô®ÁöÑÁõ∏Âêå‰ΩéÁ∫ßÊéßÂà∂Âô®Áõ∏ÊØîÔºåÂÆåÊï¥ÁöÑÁ≥ªÁªüÂ∞ÜÊï¥‰ΩìÊàêÂäüÁéáÊèêÈ´ò‰∫ÜÁ∫¶60%„ÄÇÊï∞ÊçÆÈõÜÂíåËÆ≠ÁªÉÊ®°ÂûãÂ∞ÜÂú®ÂèëË°®ÂêéÂºÄÊ∫ê„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú∫Âô®‰∫∫ÊâßË°åÈïøÁ®ãÊìç‰Ωú‰ªªÂä°ÔºåÈúÄË¶ÅÊ†πÊçÆËá™Áî±ÂΩ¢ÂºèÁöÑËØ≠Ë®ÄÊåá‰ª§ÁîüÊàêÂ§öÊ≠•Âä®‰ΩúËÆ°Âàí„ÄÇÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèË∂≥Â§üËßÑÊ®°ÁöÑ„ÄÅÂåÖÂê´Ëá™ÁÑ∂ËØ≠Ë®ÄÂíåÂ§öÊ≠•Âä®‰ΩúËÆ°ÂàíÁöÑÂ∫èÂàóÊìç‰ΩúÊï∞ÊçÆÔºåÂπ∂‰∏îÁº∫‰πèÂØÜÈõÜ„ÄÅÂèØËß£ÈáäÁöÑÂ•ñÂä±Êù•ÂæÆË∞ÉVLMÔºåÂØºËá¥VLMÈöæ‰ª•Âú®ÁúüÂÆû‰∏ñÁïå‰∏≠ÈÉ®ÁΩ≤„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÂà©Áî®VLMËøõË°åÈ´òÂ±ÇËßÑÂàíÔºåÁîüÊàêÊìç‰ΩúËÆ°ÂàíÔºåÂπ∂ÈÄöËøáÂèØÈ™åËØÅÁöÑÂ•ñÂä±ÂáΩÊï∞Êù•ËØÑ‰º∞Âíå‰ºòÂåñÁîüÊàêÁöÑËÆ°Âàí„ÄÇÈÄöËøáÈìæÂºèÊÄùËÄÉ(Chain-of-Thought)ÁöÑÊñπÂºèÔºåËÆ©VLMËøõË°åÊó∂Èó¥ÂíåÁ©∫Èó¥Êé®ÁêÜÔºåÁîüÊàêÁâ©ÁêÜ‰∏äÂèØË°åÂíåÈÄªËæë‰∏äËøûË¥ØÁöÑËÆ°Âàí„ÄÇ‰ΩøÁî®ÈÄöÁî®Êìç‰ΩúÁïåÈù¢Ê°ÜÊû∂Ëé∑ÂèñÂéüÂ≠êÊäÄËÉΩÊºîÁ§∫ÔºåÂπ∂Ëá™Âä®Ê†áÊ≥®ÁîüÊàêËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöREVERÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Êï∞ÊçÆÊî∂ÈõÜÊ®°ÂùóÔºöÂà©Áî®ÈÄöÁî®Êìç‰ΩúÁïåÈù¢Ê°ÜÊû∂ÊçïËé∑ÂéüÂ≠êÊäÄËÉΩÊºîÁ§∫ÔºåÂπ∂‰ΩøÁî®Ëá™Âä®Ê†áÊ≥®ÂºïÊìéÂ∞ÜÊØè‰∏™ÊºîÁ§∫ËΩ¨Êç¢‰∏∫ËßÜËßâ-Êåá‰ª§-ËÆ°Âàí‰∏âÂÖÉÁªÑ„ÄÇ2) VLMËÆ≠ÁªÉÊ®°ÂùóÔºöËÆ≠ÁªÉRoboFarseerÔºå‰∏Ä‰∏™VLMÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊ†πÊçÆËØ≠Ë®ÄÊåá‰ª§ÁîüÊàêÊìç‰ΩúËÆ°Âàí„ÄÇ3) Â•ñÂä±ÂáΩÊï∞Ê®°ÂùóÔºöËÆæËÆ°ÂèØÈ™åËØÅÂ•ñÂä±ÔºåÈÄöËøáÂÖ∂‰∏éÁúüÂÆûÊäÄËÉΩÂ∫èÂàóÁöÑÊúâÂ∫è‰∫åÂàÜÂåπÈÖçÈáçÂè†Êù•ÂØπÁîüÊàêÁöÑËÆ°ÂàíËøõË°åËØÑÂàÜ„ÄÇ4) ËßÑÂàí‰∏éÁõëÊéßÊ®°ÂùóÔºöÂæÆË∞ÉÂêéÁöÑVLMÊó¢ÂÖÖÂΩìËßÑÂàíÂô®ÂèàÂÖÖÂΩìÁõëËßÜÂô®ÔºåÈ™åËØÅÈÄêÊ≠•ÂÆåÊàêÊÉÖÂÜµ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**Ôºö1) ÊèêÂá∫‰∫ÜREVERÊ°ÜÊû∂ÔºåÂ∞ÜVLMÂ∫îÁî®‰∫éÈïøÁ®ãÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°ËßÑÂàí„ÄÇ2) ËÆæËÆ°‰∫ÜÂèØÈ™åËØÅÂ•ñÂä±ÔºåËÉΩÂ§üÂØπÁîüÊàêÁöÑËÆ°ÂàíËøõË°åÊúâÊïàËØÑ‰º∞Âíå‰ºòÂåñ„ÄÇ3) ÊûÑÂª∫‰∫ÜRoboFarseerÔºå‰∏Ä‰∏™ËÉΩÂ§üËøõË°åÊó∂Èó¥ÂíåÁ©∫Èó¥Êé®ÁêÜÁöÑVLMÔºåÁîüÊàêÁâ©ÁêÜ‰∏äÂèØË°åÂíåÈÄªËæë‰∏äËøûË¥ØÁöÑËÆ°Âàí„ÄÇ4) Ëá™Âä®ÂåñÊ†áÊ≥®ÂºïÊìéÔºåËÉΩÂ§üÈ´òÊïàÂú∞ÁîüÊàêËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**Ôºö1) ‰ΩøÁî®ÈìæÂºèÊÄùËÄÉ(Chain-of-Thought)ÊèêÁ§∫VLMËøõË°åÊé®ÁêÜ„ÄÇ2) ÂèØÈ™åËØÅÂ•ñÂä±Âü∫‰∫éÁîüÊàêÁöÑËÆ°Âàí‰∏éÁúüÂÆûÊäÄËÉΩÂ∫èÂàóÁöÑÊúâÂ∫è‰∫åÂàÜÂåπÈÖçÈáçÂè†Á®ãÂ∫¶„ÄÇ3) RoboFarseerÁöÑËÆ≠ÁªÉÁõÆÊ†áÊòØÊúÄÂ§ßÂåñÂèØÈ™åËØÅÂ•ñÂä±Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÁîüÊàêÈ´òË¥®ÈáèÁöÑÊìç‰ΩúËÆ°Âàí„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

RoboFarseerÂú®ÂºÄÊîæÂºèËßÑÂàí‰ªªÂä°‰∏≠Ë∂ÖËøá‰∫ÜÊúÄ‰Ω≥Âü∫Á∫ø40%‰ª•‰∏äÔºåÂπ∂‰∏îÊÄßËÉΩ‰∏éÂ§ßÂá†‰∏™Êï∞ÈáèÁ∫ßÁöÑ‰∏ìÊúâÊ®°ÂûãÁõ∏ÂåπÈÖçÊàñË∂ÖËøá„ÄÇÂú®ÁúüÂÆû‰∏ñÁïåÁöÑÈïøÁ®ã‰ªªÂä°‰∏≠Ôºå‰∏éÊ≤°ÊúâËßÑÂàíÂô®ÁöÑÁõ∏Âêå‰ΩéÁ∫ßÊéßÂà∂Âô®Áõ∏ÊØîÔºåÂÆåÊï¥ÁöÑÁ≥ªÁªüÂ∞ÜÊï¥‰ΩìÊàêÂäüÁéáÊèêÈ´ò‰∫ÜÁ∫¶60%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåREVERÊ°ÜÊû∂ÂíåRoboFarseerÂú®ÈïøÁ®ãÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÂÖ∑ÊúâÊòæËëó‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°Ôºå‰æãÂ¶ÇÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öËá™Âä®ÂåñÊú∫Âô®‰∫∫Á≠â„ÄÇÈÄöËøáÂ∞ÜËá™ÁÑ∂ËØ≠Ë®ÄÊåá‰ª§ËΩ¨Âåñ‰∏∫ÂèØÊâßË°åÁöÑÊú∫Âô®‰∫∫Âä®‰ΩúËÆ°ÂàíÔºåÂèØ‰ª•ÊòæËëóÊèêÈ´òÊú∫Âô®‰∫∫ÁöÑÊô∫ËÉΩÂåñÊ∞¥Âπ≥ÂíåÊìç‰ΩúÊïàÁéáÔºåÈôç‰Ωé‰∫∫Â∑•Âπ≤È¢ÑÁöÑÈúÄÊ±Ç„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂú®Êô∫ËÉΩÂÆ∂Â±Ö„ÄÅÊô∫ËÉΩÂà∂ÈÄ†Á≠âÈ¢ÜÂüüÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Enabling robots to execute long-horizon manipulation tasks from free-form language instructions remains a fundamental challenge in embodied AI. While vision-language models (VLMs) have shown promise as high-level planners, their deployment in the real world is hindered by two gaps: (i) the scarcity of large-scale, sequential manipulation data that couples natural language with multi-step action plans, and (ii) the absence of dense, interpretable rewards for fine-tuning VLMs on planning objectives. To address these issues, we propose REVER, a framework that empowers VLMs to generate and validate long-horizon manipulation plans from natural language instructions in real-world scenarios. Under REVER we train and release RoboFarseer, a VLM incentivized to emit chain-of-thought that perform temporal and spatial reasoning, ensuring physically plausible and logically coherent plans. To obtain training data, we leverage the Universal Manipulation Interface framework to capture hardware-agnostic demonstrations of atomic skills. An automated annotation engine converts each demonstration into vision-instruction-plan triplet. We introduce a verifiable reward that scores the generated plan by its ordered bipartite matching overlap with the ground-truth skill sequence. At run time, the fine-tuned VLM functions both as a planner and as a monitor, verifying step-wise completion. RoboFarseer matches or exceeds the performance of proprietary models that are orders of magnitude larger, while on open-ended planning it surpasses the best baseline by more than 40%. In real-world, long-horizon tasks, the complete system boosts overall success by roughly 60% compared with the same low-level controller without the planner. We will open-source both the dataset and the trained model upon publication.

