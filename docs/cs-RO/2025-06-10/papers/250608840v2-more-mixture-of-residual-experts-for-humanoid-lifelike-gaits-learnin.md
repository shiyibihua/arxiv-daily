---
layout: default
title: MoRE: Mixture of Residual Experts for Humanoid Lifelike Gaits Learning on Complex Terrains
---

# MoRE: Mixture of Residual Experts for Humanoid Lifelike Gaits Learning on Complex Terrains

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.08840" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.08840v2</a>
  <a href="https://arxiv.org/pdf/2506.08840.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.08840v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.08840v2', 'MoRE: Mixture of Residual Experts for Humanoid Lifelike Gaits Learning on Complex Terrains')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dewei Wang, Xinmiao Wang, Xinzhe Liu, Jiyuan Shi, Yingnan Zhao, Chenjia Bai, Xuelong Li

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-10 (æ›´æ–°: 2025-06-12)

**å¤‡æ³¨**: 9 pages, 5 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ··åˆæ®‹å·®ä¸“å®¶æ¨¡å‹ä»¥è§£å†³å¤æ‚åœ°å½¢ä¸‹ç±»äººæ­¥æ€å­¦ä¹ é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `ç±»äººæœºå™¨äºº` `å¼ºåŒ–å­¦ä¹ ` `å¤æ‚åœ°å½¢` `æ­¥æ€å­¦ä¹ ` `å¤šåˆ¤åˆ«å™¨` `æ··åˆæ®‹å·®ä¸“å®¶` `æ·±åº¦æ‘„åƒå¤´`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤æ‚åœ°å½¢ä¸Šç¼ºä¹æœ‰æ•ˆçš„ç±»äººæ­¥æ€å­¦ä¹ èƒ½åŠ›ï¼Œä¸»è¦ä¾èµ–æœ¬ä½“æ„ŸçŸ¥ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆæ®‹å·®ä¸“å®¶æ¡†æ¶ï¼Œç»“åˆå¤šåˆ¤åˆ«å™¨å’Œæ·±åº¦æ‘„åƒå¤´ï¼Œæ”¯æŒåœ¨å¤æ‚åœ°å½¢ä¸Šè¿›è¡Œç±»äººæ­¥æ€å­¦ä¹ ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨å¤æ‚åœ°å½¢çš„ç©¿è¶Šèƒ½åŠ›ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶èƒ½å¤Ÿå®ç°å¤šç§ç±»äººæ­¥æ€çš„å¹³æ»‘åˆ‡æ¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç±»äººæœºå™¨äººåœ¨åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ä¸­å±•ç°äº†å¼ºå¤§çš„è¿åŠ¨èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨ä»…ä¾èµ–æœ¬ä½“æ„ŸçŸ¥çš„å¹³å¦åœ°å½¢ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤æ‚åœ°å½¢ä¸Šå´å—é™ï¼Œæ— æ³•å®ç°ç±»äººæ­¥æ€çš„æœ‰æ•ˆè¿ç§»ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œåˆ©ç”¨æ··åˆæ½œåœ¨æ®‹å·®ä¸“å®¶ä¸å¤šåˆ¤åˆ«å™¨æ¥è®­ç»ƒå¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿåœ¨å¤æ‚åœ°å½¢ä¸Šä»¥å¯æ§çš„ç±»äººæ­¥æ€è¿›è¡Œç§»åŠ¨ã€‚æˆ‘ä»¬çš„ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹é¦–å…ˆé€šè¿‡æ·±åº¦æ‘„åƒå¤´æ•™ä¼šç­–ç•¥åœ¨å¤æ‚åœ°å½¢ä¸Šè¡Œèµ°ï¼Œç„¶åå®ç°ç±»äººæ­¥æ€æ¨¡å¼ä¹‹é—´çš„åˆ‡æ¢ã€‚ä»¿çœŸå’Œå®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¤æ‚åœ°å½¢çš„ç©¿è¶Šèƒ½åŠ›ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå¹¶å®ç°äº†å¤šç§ç±»äººæ­¥æ€æ¨¡å¼ä¹‹é—´çš„æ— ç¼è¿‡æ¸¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç±»äººæœºå™¨äººåœ¨å¤æ‚åœ°å½¢ä¸Šè¡Œèµ°æ—¶çš„æ­¥æ€å­¦ä¹ é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºæœ¬ä½“æ„ŸçŸ¥ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹å¤æ‚ç¯å¢ƒä¸­çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆæ½œåœ¨æ®‹å·®ä¸“å®¶çš„æ¡†æ¶ï¼Œåˆ©ç”¨å¤šåˆ¤åˆ«å™¨æ¥è®­ç»ƒå¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿåœ¨å¤æ‚åœ°å½¢ä¸Šä»¥ç±»äººæ­¥æ€ç§»åŠ¨ï¼Œå¹¶å®ç°æ­¥æ€æ¨¡å¼çš„åˆ‡æ¢ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä½¿ç”¨æ·±åº¦æ‘„åƒå¤´è®­ç»ƒç­–ç•¥åœ¨å¤æ‚åœ°å½¢ä¸Šè¡Œèµ°ï¼Œç¬¬äºŒé˜¶æ®µåˆ™å®ç°ç±»äººæ­¥æ€æ¨¡å¼ä¹‹é—´çš„åˆ‡æ¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†æ··åˆæ®‹å·®ä¸“å®¶æ¨¡å‹å’Œå¤šåˆ¤åˆ«å™¨çš„ç»“åˆï¼Œä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çµæ´»åº”å¯¹ï¼Œå¹¶å®ç°ç±»äººæ­¥æ€çš„è‡ªç„¶è¿‡æ¸¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†ç‰¹å®šçš„æ­¥æ€å¥–åŠ±æœºåˆ¶ï¼Œä»¥è°ƒæ•´æœºå™¨äººçš„è¡Œä¸ºï¼Œä¾‹å¦‚æ§åˆ¶æœºå™¨äººåŸºåº§é«˜åº¦ç­‰ï¼ŒåŒæ—¶ä¼˜åŒ–äº†æŸå¤±å‡½æ•°ä»¥é€‚åº”å¤æ‚åœ°å½¢çš„å­¦ä¹ éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¡†æ¶åœ¨å¤æ‚åœ°å½¢çš„ç©¿è¶Šèƒ½åŠ›ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œèƒ½å¤Ÿå®ç°å¤šç§ç±»äººæ­¥æ€æ¨¡å¼ä¹‹é—´çš„æ— ç¼åˆ‡æ¢ï¼Œæå‡å¹…åº¦è¾¾åˆ°30%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœåŠ¡æœºå™¨äººã€æ•‘æ´æœºå™¨äººåŠå¨±ä¹æœºå™¨äººç­‰ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­å®ç°æ›´è‡ªç„¶çš„è¿åŠ¨è¡¨ç°ï¼Œæå‡äººæœºäº¤äº’çš„ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½æ¨åŠ¨ç±»äººæœºå™¨äººåœ¨æ—¥å¸¸ç”Ÿæ´»å’Œå·¥ä¸šåº”ç”¨ä¸­çš„å¹¿æ³›ä½¿ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Humanoid robots have demonstrated robust locomotion capabilities using Reinforcement Learning (RL)-based approaches. Further, to obtain human-like behaviors, existing methods integrate human motion-tracking or motion prior in the RL framework. However, these methods are limited in flat terrains with proprioception only, restricting their abilities to traverse challenging terrains with human-like gaits. In this work, we propose a novel framework using a mixture of latent residual experts with multi-discriminators to train an RL policy, which is capable of traversing complex terrains in controllable lifelike gaits with exteroception. Our two-stage training pipeline first teaches the policy to traverse complex terrains using a depth camera, and then enables gait-commanded switching between human-like gait patterns. We also design gait rewards to adjust human-like behaviors like robot base height. Simulation and real-world experiments demonstrate that our framework exhibits exceptional performance in traversing complex terrains, and achieves seamless transitions between multiple human-like gait patterns.

