---
layout: default
title: Re4MPC: Reactive Nonlinear MPC for Multi-model Motion Planning via Deep Reinforcement Learning
---

# Re4MPC: Reactive Nonlinear MPC for Multi-model Motion Planning via Deep Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.08344" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.08344v1</a>
  <a href="https://arxiv.org/pdf/2506.08344.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.08344v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.08344v1', 'Re4MPC: Reactive Nonlinear MPC for Multi-model Motion Planning via Deep Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: NeÅŸet Ãœnver Akmandor, Sarvesh Prajapati, Mark Zolotas, TaÅŸkÄ±n PadÄ±r

**åˆ†ç±»**: cs.RO, cs.AI, cs.LG, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-06-10

**å¤‡æ³¨**: Accepted to the 2025 IEEE International Conference on Automation Science and Engineering (CASE)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRe4MPCä»¥è§£å†³å¤šæ¨¡å‹è¿åŠ¨è§„åˆ’çš„è®¡ç®—æ•ˆç‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è¿åŠ¨è§„åˆ’` `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `éçº¿æ€§æ¨¡å‹é¢„æµ‹æ§åˆ¶` `å¤šæ¨¡å‹ç³»ç»Ÿ` `æœºå™¨äººæŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¿åŠ¨è§„åˆ’æ–¹æ³•åœ¨å¤„ç†é«˜è‡ªç”±åº¦æœºå™¨äººæ—¶ï¼Œè®¡ç®—å¤æ‚åº¦é«˜ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶åº”ç”¨éœ€æ±‚ã€‚
2. Re4MPCé€šè¿‡åŠ¨æ€é€‰æ‹©æ¨¡å‹å’Œçº¦æŸï¼Œç»“åˆæ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼Œæå‡äº†éçº¿æ€§æ¨¡å‹é¢„æµ‹æ§åˆ¶çš„è®¡ç®—æ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRe4MPCåœ¨è¾¾åˆ°æœ«ç«¯æ‰§è¡Œå™¨ç›®æ ‡æ—¶ï¼ŒæˆåŠŸç‡å’Œè®¡ç®—æ•ˆç‡å‡ä¼˜äºä¼ ç»ŸNMPCæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¼ ç»Ÿçš„æœºå™¨äººè¿åŠ¨è§„åˆ’æ–¹æ³•åœ¨å¤„ç†å…·æœ‰å¤šä¸ªè‡ªç”±åº¦çš„ç§»åŠ¨æ“çºµå™¨æ—¶ï¼Œå¾€å¾€é¢ä¸´è®¡ç®—å¼€é”€è¿‡å¤§çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šæ¨¡å‹è¿åŠ¨è§„åˆ’ç®¡é“Re4MPCï¼Œé€šè¿‡éçº¿æ€§æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆNMPCï¼‰è®¡ç®—è½¨è¿¹ã€‚Re4MPCé€šè¿‡æ ¹æ®ä»»åŠ¡å¤æ‚æ€§å’Œæœºå™¨äººçŠ¶æ€åŠ¨æ€é€‰æ‹©æ¨¡å‹ã€æˆæœ¬å’Œçº¦æŸï¼Œä»è€Œä»¥è®¡ç®—é«˜æ•ˆçš„æ–¹å¼ç”Ÿæˆè½¨è¿¹ã€‚è¯¥ååº”å¼å†³ç­–çš„ç­–ç•¥é€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰æ¡†æ¶è¿›è¡Œå­¦ä¹ ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†æ•°å­¦å…¬å¼ï¼Œå°†NMPCé›†æˆåˆ°DRLæ¡†æ¶ä¸­ã€‚é€šè¿‡åœ¨ç‰©ç†ä»¿çœŸä¸­è¯„ä¼°ç§»åŠ¨æ“çºµå™¨çš„DRLè®­ç»ƒå’Œæµ‹è¯•ç»“æœï¼Œå®éªŒç»“æœè¡¨æ˜ï¼ŒRe4MPCåœ¨è®¡ç®—æ•ˆç‡å’ŒæˆåŠŸç‡ä¸Šå‡ä¼˜äºä¸ä½¿ç”¨å­¦ä¹ æœºåˆ¶çš„NMPCåŸºçº¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é«˜è‡ªç”±åº¦æœºå™¨äººåœ¨å®é™…åº”ç”¨ä¸­è¿åŠ¨è§„åˆ’çš„è®¡ç®—æ•ˆç‡é—®é¢˜ã€‚ç°æœ‰çš„NMPCæ–¹æ³•åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶ï¼Œè®¡ç®—å¼€é”€è¿‡å¤§ï¼Œéš¾ä»¥å®æ—¶å“åº”ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRe4MPCçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ åŠ¨æ€é€‰æ‹©é€‚åˆçš„æ¨¡å‹ã€æˆæœ¬å’Œçº¦æŸï¼Œä»è€Œåœ¨ä¸åŒä»»åŠ¡å¤æ‚åº¦ä¸‹é«˜æ•ˆç”Ÿæˆè½¨è¿¹ã€‚è¿™ç§è®¾è®¡ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®å®æ—¶çŠ¶æ€åšå‡ºååº”ï¼Œæå‡äº†æ•´ä½“æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRe4MPCçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å—ï¼Œç”¨äºå­¦ä¹ ååº”å¼å†³ç­–ç­–ç•¥ï¼›2) éçº¿æ€§æ¨¡å‹é¢„æµ‹æ§åˆ¶æ¨¡å—ï¼Œè´Ÿè´£è½¨è¿¹ç”Ÿæˆï¼›3) ä»»åŠ¡å¤æ‚æ€§è¯„ä¼°æ¨¡å—ï¼ŒåŠ¨æ€è°ƒæ•´æ¨¡å‹å’Œçº¦æŸã€‚

**å…³é”®åˆ›æ–°**ï¼šRe4MPCçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸éçº¿æ€§æ¨¡å‹é¢„æµ‹æ§åˆ¶ç›¸ç»“åˆï¼Œä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­é«˜æ•ˆè§„åˆ’è¿åŠ¨è½¨è¿¹ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»ŸNMPCçš„æœ¬è´¨åŒºåˆ«åœ¨äºå…¶åŠ¨æ€é€‚åº”æ€§å’Œè®¡ç®—æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–è½¨è¿¹ç”Ÿæˆçš„å‡†ç¡®æ€§ï¼Œå¹¶é€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œç»“æ„æ¥å®ç°æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„ç­–ç•¥å­¦ä¹ ã€‚å…³é”®å‚æ•°è®¾ç½®åŒ…æ‹¬å­¦ä¹ ç‡ã€æŠ˜æ‰£å› å­ç­‰ï¼Œè¿™äº›éƒ½å¯¹æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œæ€§èƒ½æœ‰æ˜¾è‘—å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRe4MPCåœ¨è¾¾åˆ°æœ«ç«¯æ‰§è¡Œå™¨ç›®æ ‡æ—¶ï¼ŒæˆåŠŸç‡é«˜äºä¼ ç»ŸNMPCåŸºçº¿ï¼Œä¸”è®¡ç®—æ•ˆç‡æå‡æ˜¾è‘—ã€‚å…·ä½“è€Œè¨€ï¼ŒRe4MPCåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è®¡ç®—æ—¶é—´å‡å°‘äº†çº¦30%ï¼ŒæˆåŠŸç‡æé«˜äº†15%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨åŒ–åˆ¶é€ ã€æœåŠ¡æœºå™¨äººä»¥åŠå¤æ‚ç¯å¢ƒä¸‹çš„è‡ªä¸»å¯¼èˆªç­‰ã€‚é€šè¿‡æå‡æœºå™¨äººè¿åŠ¨è§„åˆ’çš„æ•ˆç‡ï¼ŒRe4MPCèƒ½å¤Ÿåœ¨å®æ—¶ä»»åŠ¡ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººåœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Traditional motion planning methods for robots with many degrees-of-freedom, such as mobile manipulators, are often computationally prohibitive for real-world settings. In this paper, we propose a novel multi-model motion planning pipeline, termed Re4MPC, which computes trajectories using Nonlinear Model Predictive Control (NMPC). Re4MPC generates trajectories in a computationally efficient manner by reactively selecting the model, cost, and constraints of the NMPC problem depending on the complexity of the task and robot state. The policy for this reactive decision-making is learned via a Deep Reinforcement Learning (DRL) framework. We introduce a mathematical formulation to integrate NMPC into this DRL framework. To validate our methodology and design choices, we evaluate DRL training and test outcomes in a physics-based simulation involving a mobile manipulator. Experimental results demonstrate that Re4MPC is more computationally efficient and achieves higher success rates in reaching end-effector goals than the NMPC baseline, which computes whole-body trajectories without our learning mechanism.

