---
layout: default
title: Expand Your SCOPE: Semantic Cognition over Potential-Based Exploration for Embodied Visual Navigation
---

# Expand Your SCOPE: Semantic Cognition over Potential-Based Exploration for Embodied Visual Navigation

**arXiv**: [2511.08935v1](https://arxiv.org/abs/2511.08935) | [PDF](https://arxiv.org/pdf/2511.08935.pdf)

**ä½œè€…**: Ningnan Wang, Weihuang Chen, Liming Chen, Haoxuan Ji, Zhongyu Guo, Xuchong Zhang, Hongbin Sun

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-12

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSCOPEæ¡†æž¶ä»¥æå‡å…·èº«è§†è§‰å¯¼èˆªçš„å†³ç­–èƒ½åŠ›**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å…·èº«è§†è§‰å¯¼èˆª` `æ½œåŠ›é©±åŠ¨æŽ¢ç´¢` `è§†è§‰-è¯­è¨€æ¨¡åž‹` `æ—¶ç©ºæ½œåŠ›å›¾` `è‡ªæˆ‘åæ€æœºåˆ¶` `é•¿æ—¶é—´è§„åˆ’` `å†³ç­–ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨å…·èº«è§†è§‰å¯¼èˆªä¸­æœªèƒ½æœ‰æ•ˆåˆ©ç”¨è§†è§‰è¾¹ç•Œä¿¡æ¯ï¼Œå¯¼è‡´å†³ç­–è´¨é‡ä¸è¶³ã€‚
2. æå‡ºçš„SCOPEæ¡†æž¶é€šè¿‡æ½œåŠ›é©±åŠ¨çš„æŽ¢ç´¢ï¼Œç»“åˆè§†è§‰-è¯­è¨€æ¨¡åž‹å’Œæ—¶ç©ºæ½œåŠ›å›¾ï¼Œå¢žå¼ºäº†å†³ç­–çš„ç›®æ ‡ç›¸å…³æ€§ã€‚
3. å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒSCOPEåœ¨å‡†ç¡®çŽ‡ä¸Šè¶…è¶Šäº†çŽ°æœ‰åŸºçº¿ï¼Œè¡¨æ˜Žå…¶åœ¨é•¿æ—¶é—´è§„åˆ’å’Œå†³ç­–è´¨é‡ä¸Šçš„æ˜¾è‘—æå‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…·èº«è§†è§‰å¯¼èˆªä»ç„¶æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä»£ç†å¿…é¡»åœ¨æœ‰é™çŸ¥è¯†ä¸‹æŽ¢ç´¢æœªçŸ¥çŽ¯å¢ƒã€‚çŽ°æœ‰çš„é›¶æ ·æœ¬ç ”ç©¶è¡¨æ˜Žï¼Œç»“åˆè®°å¿†æœºåˆ¶ä»¥æ”¯æŒç›®æ ‡å¯¼å‘è¡Œä¸ºå¯ä»¥æ”¹å–„é•¿æ—¶é—´è§„åˆ’æ€§èƒ½ã€‚ç„¶è€Œï¼Œå®ƒä»¬å¿½è§†äº†è§†è§‰è¾¹ç•Œï¼Œè¿™åœ¨æ ¹æœ¬ä¸Šå†³å®šäº†æœªæ¥çš„è½¨è¿¹å’Œè§‚å¯Ÿï¼Œå¹¶æœªèƒ½æŽ¨æ–­éƒ¨åˆ†è§†è§‰è§‚å¯Ÿä¸Žå¯¼èˆªç›®æ ‡ä¹‹é—´çš„å…³ç³»ã€‚æœ¬æ–‡æå‡ºäº†åŸºäºŽæ½œåŠ›çš„è¯­ä¹‰è®¤çŸ¥æ¡†æž¶SCOPEï¼Œæ˜Žç¡®åˆ©ç”¨è¾¹ç•Œä¿¡æ¯é©±åŠ¨æ½œåŠ›æŽ¢ç´¢ï¼Œä»Žè€Œå®žçŽ°æ›´ä¸ºçŸ¥æƒ…å’Œä¸Žç›®æ ‡ç›¸å…³çš„å†³ç­–ã€‚SCOPEé€šè¿‡è§†è§‰-è¯­è¨€æ¨¡åž‹ä¼°è®¡æŽ¢ç´¢æ½œåŠ›ï¼Œå¹¶å°†å…¶ç»„ç»‡æˆæ—¶ç©ºæ½œåŠ›å›¾ï¼Œæ•æ‰è¾¹ç•ŒåŠ¨æ€ä»¥æ”¯æŒé•¿æ—¶é—´è§„åˆ’ã€‚æ­¤å¤–ï¼ŒSCOPEè¿˜ç»“åˆè‡ªæˆ‘åæ€æœºåˆ¶ï¼Œé‡æ–°å®¡è§†å’Œä¼˜åŒ–å…ˆå‰å†³ç­–ï¼Œæé«˜å¯é æ€§å¹¶å‡å°‘è¿‡åº¦è‡ªä¿¡çš„é”™è¯¯ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒSCOPEåœ¨ä¸¤ä¸ªä¸åŒçš„å…·èº«å¯¼èˆªä»»åŠ¡ä¸­ï¼Œå‡†ç¡®çŽ‡æ¯”æœ€å…ˆè¿›çš„åŸºçº¿æé«˜äº†4.6%ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å…·èº«è§†è§‰å¯¼èˆªä¸­çŽ°æœ‰æ–¹æ³•å¯¹è§†è§‰è¾¹ç•Œä¿¡æ¯çš„å¿½è§†ï¼Œå¯¼è‡´çš„å†³ç­–ä¸å‡†ç¡®å’Œè§„åˆ’æ€§èƒ½ä¸è¶³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSCOPEæ¡†æž¶é€šè¿‡å¼•å…¥æ½œåŠ›é©±åŠ¨çš„æŽ¢ç´¢æœºåˆ¶ï¼Œç»“åˆè§†è§‰-è¯­è¨€æ¨¡åž‹ï¼Œåˆ©ç”¨è¾¹ç•Œä¿¡æ¯æ¥æŒ‡å¯¼å†³ç­–ï¼Œä»Žè€Œæå‡å¯¼èˆªçš„æœ‰æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šSCOPEçš„æ•´ä½“æž¶æž„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè§†è§‰-è¯­è¨€æ¨¡åž‹ç”¨äºŽæ½œåŠ›ä¼°è®¡ï¼Œæ—¶ç©ºæ½œåŠ›å›¾ç”¨äºŽåŠ¨æ€è¾¹ç•Œæ•æ‰ï¼Œä»¥åŠè‡ªæˆ‘åæ€æœºåˆ¶ç”¨äºŽä¼˜åŒ–å†³ç­–ã€‚

**å…³é”®åˆ›æ–°**ï¼šSCOPEçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºŽå°†è§†è§‰è¾¹ç•Œä¿¡æ¯ä¸Žæ½œåŠ›æŽ¢ç´¢ç›¸ç»“åˆï¼Œå½¢æˆæ—¶ç©ºæ½œåŠ›å›¾ï¼Œä»Žè€Œæ˜¾è‘—æå‡äº†é•¿æ—¶é—´è§„åˆ’çš„èƒ½åŠ›ï¼Œä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”å…·æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒSCOPEé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ½œåŠ›ä¼°è®¡ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§å‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡åž‹åœ¨ä¸åŒçŽ¯å¢ƒä¸‹çš„é²æ£’æ€§å’Œå¯é æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒSCOPEåœ¨ä¸¤ä¸ªå…·èº«å¯¼èˆªä»»åŠ¡ä¸­ç›¸è¾ƒäºŽæœ€å…ˆè¿›çš„åŸºçº¿æé«˜äº†4.6%çš„å‡†ç¡®çŽ‡ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å†³ç­–è´¨é‡å’Œè§„åˆ’èƒ½åŠ›ä¸Šçš„æ˜¾è‘—ä¼˜åŠ¿ã€‚è¿›ä¸€æ­¥åˆ†æžè¡¨æ˜Žï¼ŒSCOPEçš„æ ¸å¿ƒç»„ä»¶æœ‰æ•ˆæå‡äº†æ¨¡åž‹çš„æ ¡å‡†èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹ŸçŽ°å®žç­‰ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚çŽ¯å¢ƒä¸­å®žçŽ°æ›´é«˜æ•ˆçš„è‡ªä¸»æŽ¢ç´¢ä¸Žå†³ç­–ã€‚é€šè¿‡æå‡å…·èº«è§†è§‰å¯¼èˆªçš„æ€§èƒ½ï¼ŒSCOPEæ¡†æž¶æœ‰æœ›æŽ¨åŠ¨æ™ºèƒ½ä½“åœ¨æœªçŸ¥çŽ¯å¢ƒä¸­çš„åº”ç”¨ï¼Œå…·æœ‰é‡è¦çš„å®žé™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Embodied visual navigation remains a challenging task, as agents must explore unknown environments with limited knowledge. Existing zero-shot studies have shown that incorporating memory mechanisms to support goal-directed behavior can improve long-horizon planning performance. However, they overlook visual frontier boundaries, which fundamentally dictate future trajectories and observations, and fall short of inferring the relationship between partial visual observations and navigation goals. In this paper, we propose Semantic Cognition Over Potential-based Exploration (SCOPE), a zero-shot framework that explicitly leverages frontier information to drive potential-based exploration, enabling more informed and goal-relevant decisions. SCOPE estimates exploration potential with a Vision-Language Model and organizes it into a spatio-temporal potential graph, capturing boundary dynamics to support long-horizon planning. In addition, SCOPE incorporates a self-reconsideration mechanism that revisits and refines prior decisions, enhancing reliability and reducing overconfident errors. Experimental results on two diverse embodied navigation tasks show that SCOPE outperforms state-of-the-art baselines by 4.6\% in accuracy. Further analysis demonstrates that its core components lead to improved calibration, stronger generalization, and higher decision quality.

