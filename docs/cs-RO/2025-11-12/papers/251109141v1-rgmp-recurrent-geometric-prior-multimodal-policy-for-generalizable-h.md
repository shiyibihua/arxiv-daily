---
layout: default
title: RGMP: Recurrent Geometric-prior Multimodal Policy for Generalizable Humanoid Robot Manipulation
---

# RGMP: Recurrent Geometric-prior Multimodal Policy for Generalizable Humanoid Robot Manipulation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.09141" target="_blank" class="toolbar-btn">arXiv: 2511.09141v1</a>
    <a href="https://arxiv.org/pdf/2511.09141.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.09141v1" 
            onclick="toggleFavorite(this, '2511.09141v1', 'RGMP: Recurrent Geometric-prior Multimodal Policy for Generalizable Humanoid Robot Manipulation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xuetao Li, Wenke Huang, Nengyuan Pan, Kaiyan Zhao, Songhua Yang, Yiming Wang, Mengde Li, Mang Ye, Jifeng Xuan, Miao Li

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-12

**ÊúüÂàä**: Proceedings of the AAAI conference on artificial intelligence, 2026

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫RGMPÔºåËûçÂêàÂá†‰ΩïÂÖàÈ™å‰∏éÈÄíÂΩíÈ´òÊñØËøáÁ®ãÔºåÊèêÂçá‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Êìç‰ΩúÁöÑÊ≥õÂåñÊÄßÂíåÊï∞ÊçÆÊïàÁéá„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)**

**ÂÖ≥ÈîÆËØç**: `‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Êìç‰Ωú` `Âá†‰ΩïÂÖàÈ™å` `Â§öÊ®°ÊÄÅÁ≠ñÁï•` `ÈÄíÂΩíÈ´òÊñØËøáÁ®ã` `Êï∞ÊçÆÈ´òÊïà` `ËßÜËßâËøêÂä®ÊéßÂà∂` `Ê≥õÂåñËÉΩÂäõ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊï∞ÊçÆÈ©±Âä®ÊñπÊ≥ï‰æùËµñÂ§ßÈáèËÆ≠ÁªÉÊï∞ÊçÆÔºåÂøΩÁï•‰∫ÜÂá†‰ΩïÊé®ÁêÜÔºå‰∏îÊú∫Âô®‰∫∫-ÁõÆÊ†áÂÖ≥Á≥ªÂª∫Ê®°ÊïàÁéá‰ΩéÔºåÂØºËá¥Ê≥õÂåñÊÄßÂ∑Æ„ÄÇ
2. RGMPÊ°ÜÊû∂ËûçÂêàÂá†‰ΩïËØ≠‰πâÊäÄËÉΩÊé®ÁêÜ‰∏éÊï∞ÊçÆÈ´òÊïàËßÜËßâËøêÂä®ÊéßÂà∂ÔºåÊèêÂçáÂú®Êú™ËßÅÂú∫ÊôØ‰∏ãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåRGMPÂú®Ê≥õÂåñÊµãËØï‰∏≠ÊàêÂäüÁéáËææ87%ÔºåÊï∞ÊçÆÊïàÁéáÊØîÁé∞ÊúâÊñπÊ≥ïÊèêÂçá5ÂÄçÔºåÈ™åËØÅ‰∫ÜÂÖ∂‰ºòË∂äÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫ÈÄíÂΩíÂá†‰ΩïÂÖàÈ™åÂ§öÊ®°ÊÄÅÁ≠ñÁï•ÔºàRGMPÔºâÁöÑÁ´ØÂà∞Á´ØÊ°ÜÊû∂ÔºåÊó®Âú®Áªü‰∏ÄÂá†‰ΩïËØ≠‰πâÊäÄËÉΩÊé®ÁêÜ‰∏éÊï∞ÊçÆÈ´òÊïàÁöÑËßÜËßâËøêÂä®ÊéßÂà∂Ôºå‰ªéËÄåÊèêÂçá‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÁöÑÊìç‰ΩúËÉΩÂäõ„ÄÇËØ•ÊñπÊ≥ïÈÄöËøáÂá†‰ΩïÂÖàÈ™åÊäÄËÉΩÈÄâÊã©Âô®ÔºåÂ∞ÜÂá†‰ΩïÂΩíÁ∫≥ÂÅèÁΩÆÊ≥®ÂÖ•ËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºå‰∏∫Êú™ËßÅÂú∫ÊôØÁîüÊàêËá™ÈÄÇÂ∫îÊäÄËÉΩÂ∫èÂàó„ÄÇÂêåÊó∂ÔºåÂºïÂÖ•Ëá™ÈÄÇÂ∫îÈÄíÂΩíÈ´òÊñØÁΩëÁªúÔºåÂ∞ÜÊú∫Âô®‰∫∫-ÁõÆÊ†á‰∫§‰∫íÂèÇÊï∞Âåñ‰∏∫Á¥ßÂáëÁöÑÈ´òÊñØËøáÁ®ãÂ±ÇÁ∫ßÁªìÊûÑÔºåÈÄíÂΩíÁºñÁ†ÅÂ§öÂ∞∫Â∫¶Á©∫Èó¥ÂÖ≥Á≥ªÔºåÂÆûÁé∞Êï∞ÊçÆÈ´òÊïàÁöÑÁÅµÂ∑ßËøêÂä®ÂêàÊàê„ÄÇÂú®‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂíåÊ°åÈù¢ÂèåËáÇÊú∫Âô®‰∫∫‰∏äÁöÑËØÑ‰º∞Ë°®ÊòéÔºåRGMPÂú®Ê≥õÂåñÊµãËØï‰∏≠ÂÆûÁé∞‰∫Ü87%ÁöÑ‰ªªÂä°ÊàêÂäüÁéáÔºåÂπ∂‰∏îÊØîÊúÄÂÖàËøõÁöÑÊ®°ÂûãÊèêÈ´ò‰∫Ü5ÂÄçÁöÑÊï∞ÊçÆÊïàÁéá„ÄÇËøôÁ™ÅÊòæ‰∫ÜÂÖ∂Áî±Âá†‰ΩïËØ≠‰πâÊé®ÁêÜÂíåÈÄíÂΩíÈ´òÊñØËá™ÈÄÇÂ∫îÊâÄÊîØÊåÅÁöÑÂçìË∂äË∑®ÂüüÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Êìç‰ΩúÊñπÊ≥ï‰∏•Èáç‰æùËµñÂ§ßÈáèÁöÑÊï∞ÊçÆÈ©±Âä®ÔºåËøôÂØºËá¥‰∫Ü‰∏§‰∏™‰∏ªË¶ÅÈóÆÈ¢òÔºö‰∏ÄÊòØÂøΩÁï•‰∫ÜÂú®Êú™ËßÅÂú∫ÊôØ‰∏≠ÁöÑÂá†‰ΩïÊé®ÁêÜËÉΩÂäõÔºå‰∫åÊòØËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Êú∫Âô®‰∫∫‰∏éÁõÆÊ†áÂÖ≥Á≥ªÁöÑÂª∫Ê®°ÊïàÁéá‰Ωé‰∏ãÔºåÈÄ†Êàê‰∫ÜËÆ≠ÁªÉËµÑÊ∫êÁöÑÊµ™Ë¥π„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÊèêÂçá‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âú®Êñ∞Âú∫ÊôØ‰∏ãÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂπ∂Èôç‰ΩéÂØπÂ§ßÈáèËÆ≠ÁªÉÊï∞ÊçÆÁöÑ‰æùËµñÔºåÊòØÊú¨ÊñáË¶ÅËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöRGMPÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÂá†‰ΩïÂÖàÈ™åÁü•ËØÜËûçÂÖ•Âà∞Â§öÊ®°ÊÄÅÁ≠ñÁï•‰∏≠Ôºå‰ªéËÄåÊèêÂçáÊ®°ÂûãÂØπÂú∫ÊôØÁöÑÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÈÄöËøáÂá†‰ΩïÂÖàÈ™åÊäÄËÉΩÈÄâÊã©Âô®Êù•ÂºïÂØºËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊ†πÊçÆÂú∫ÊôØÁöÑÂá†‰ΩïÁâπÂæÅÈÄâÊã©ÂêàÈÄÇÁöÑÊäÄËÉΩÂ∫èÂàó„ÄÇÂêåÊó∂ÔºåÂà©Áî®Ëá™ÈÄÇÂ∫îÈÄíÂΩíÈ´òÊñØÁΩëÁªúÊù•È´òÊïàÂú∞Âª∫Ê®°Êú∫Âô®‰∫∫‰∏éÁõÆÊ†á‰πãÈó¥ÁöÑÂ§çÊùÇÂÖ≥Á≥ªÔºå‰ªéËÄåÂÆûÁé∞Êï∞ÊçÆÈ´òÊïàÁöÑËøêÂä®ÂêàÊàê„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRGMPÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™Ê†∏ÂøÉÊ®°ÂùóÔºöÂá†‰ΩïÂÖàÈ™åÊäÄËÉΩÈÄâÊã©Âô®ÔºàGeometric-prior Skill SelectorÔºâÂíåËá™ÈÄÇÂ∫îÈÄíÂΩíÈ´òÊñØÁΩëÁªúÔºàAdaptive Recursive Gaussian NetworkÔºâ„ÄÇÈ¶ñÂÖàÔºåÂá†‰ΩïÂÖàÈ™åÊäÄËÉΩÈÄâÊã©Âô®Âà©Áî®ËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÊèêÂèñÂú∫ÊôØÁöÑËØ≠‰πâ‰ø°ÊÅØÔºåÂπ∂ÁªìÂêàÂá†‰ΩïÂÖàÈ™åÁü•ËØÜÈÄâÊã©ÂêàÈÄÇÁöÑÊäÄËÉΩÂ∫èÂàó„ÄÇÁÑ∂ÂêéÔºåËá™ÈÄÇÂ∫îÈÄíÂΩíÈ´òÊñØÁΩëÁªúÊ†πÊçÆÈÄâÊã©ÁöÑÊäÄËÉΩÂ∫èÂàóÔºåÈÄíÂΩíÂú∞ÁºñÁ†ÅÂ§öÂ∞∫Â∫¶Á©∫Èó¥ÂÖ≥Á≥ªÔºåÁîüÊàêÊú∫Âô®‰∫∫ÁöÑËøêÂä®ËΩ®Ëøπ„ÄÇÊï¥‰∏™Ê°ÜÊû∂ÊòØ‰∏Ä‰∏™Á´ØÂà∞Á´ØÁöÑËÆ≠ÁªÉÊµÅÁ®ãÔºåÂèØ‰ª•Áõ¥Êé•‰ªéËßÜËßâËæìÂÖ•Âà∞ËøêÂä®ËæìÂá∫„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöRGMPÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÂá†‰ΩïÂÖàÈ™åÁü•ËØÜËûçÂÖ•Âà∞Â§öÊ®°ÊÄÅÁ≠ñÁï•‰∏≠ÔºåÂπ∂Âà©Áî®ÈÄíÂΩíÈ´òÊñØÁΩëÁªúÈ´òÊïàÂú∞Âª∫Ê®°Êú∫Âô®‰∫∫‰∏éÁõÆÊ†á‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåRGMP‰∏çÈúÄË¶ÅÂ§ßÈáèÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºåÂπ∂‰∏îËÉΩÂ§üÊõ¥Â•ΩÂú∞Ê≥õÂåñÂà∞Êú™ËßÅÂú∫ÊôØ„ÄÇÊ≠§Â§ñÔºåËá™ÈÄÇÂ∫îÈÄíÂΩíÈ´òÊñØÁΩëÁªúËÉΩÂ§ü‰ª•Á¥ßÂáëÁöÑÊñπÂºèË°®Á§∫Â§çÊùÇÁöÑÁ©∫Èó¥ÂÖ≥Á≥ªÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜËøêÂä®ÂêàÊàêÁöÑÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂá†‰ΩïÂÖàÈ™åÊäÄËÉΩÈÄâÊã©Âô®ÈÄöËøáÂºïÂÖ•Âá†‰ΩïÂΩíÁ∫≥ÂÅèÁΩÆÊù•ÂºïÂØºËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£Âú∫ÊôØÁöÑÂá†‰ΩïÁâπÂæÅ„ÄÇËá™ÈÄÇÂ∫îÈÄíÂΩíÈ´òÊñØÁΩëÁªúÂàôÈÄöËøáÈÄíÂΩíÂú∞ÁºñÁ†ÅÂ§öÂ∞∫Â∫¶Á©∫Èó¥ÂÖ≥Á≥ªÔºåÊù•È´òÊïàÂú∞Âª∫Ê®°Êú∫Âô®‰∫∫‰∏éÁõÆÊ†á‰πãÈó¥ÁöÑÂ§çÊùÇÂÖ≥Á≥ª„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÊçüÂ§±ÂáΩÊï∞Á≠âÊäÄÊúØÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÁöÑÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

RGMPÊ°ÜÊû∂Âú®‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂíåÊ°åÈù¢ÂèåËáÇÊú∫Âô®‰∫∫‰∏äËøõË°å‰∫ÜËØÑ‰º∞ÔºåÁªìÊûúË°®ÊòéÂÖ∂Âú®Ê≥õÂåñÊµãËØï‰∏≠ÂÆûÁé∞‰∫Ü87%ÁöÑ‰ªªÂä°ÊàêÂäüÁéáÔºåÂπ∂‰∏îÊØîÊúÄÂÖàËøõÁöÑÊ®°ÂûãÊèêÈ´ò‰∫Ü5ÂÄçÁöÑÊï∞ÊçÆÊïàÁéá„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåRGMPÊ°ÜÊû∂ÂÖ∑Êúâ‰ºòË∂äÁöÑË∑®ÂüüÊ≥õÂåñËÉΩÂäõÂíåÊï∞ÊçÆÊïàÁéáÔºåËÉΩÂ§üÊúâÊïàÂú∞Ëß£ÂÜ≥Áé∞ÊúâÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

RGMPÊ°ÜÊû∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÂ∫îÁî®‰∫éÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öËá™Âä®Âåñ„ÄÅÂåªÁñóÂ∫∑Â§çÁ≠âÈ¢ÜÂüü„ÄÇËØ•ÊäÄÊúØËÉΩÂ§ü‰Ωø‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âú®Â§çÊùÇÂíåÂä®ÊÄÅÁöÑÁéØÂ¢É‰∏≠ÊâßË°åÂêÑÁßç‰ªªÂä°Ôºå‰æãÂ¶ÇÁâ©ÂìÅÊäìÂèñ„ÄÅË£ÖÈÖç„ÄÅÊ∏ÖÊ¥ÅÁ≠â„ÄÇÈÄöËøáÊèêÂçáÊú∫Âô®‰∫∫ÁöÑÊ≥õÂåñËÉΩÂäõÂíåÊï∞ÊçÆÊïàÁéáÔºåÂèØ‰ª•Èôç‰ΩéÊú∫Âô®‰∫∫ÁöÑÈÉ®ÁΩ≤ÊàêÊú¨ÔºåÂπ∂‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫î‰∏çÂêåÁöÑÂ∫îÁî®Âú∫ÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Humanoid robots exhibit significant potential in executing diverse human-level skills. However, current research predominantly relies on data-driven approaches that necessitate extensive training datasets to achieve robust multimodal decision-making capabilities and generalizable visuomotor control. These methods raise concerns due to the neglect of geometric reasoning in unseen scenarios and the inefficient modeling of robot-target relationships within the training data, resulting in significant waste of training resources. To address these limitations, we present the Recurrent Geometric-prior Multimodal Policy (RGMP), an end-to-end framework that unifies geometric-semantic skill reasoning with data-efficient visuomotor control. For perception capabilities, we propose the Geometric-prior Skill Selector, which infuses geometric inductive biases into a vision language model, producing adaptive skill sequences for unseen scenes with minimal spatial common sense tuning. To achieve data-efficient robotic motion synthesis, we introduce the Adaptive Recursive Gaussian Network, which parameterizes robot-object interactions as a compact hierarchy of Gaussian processes that recursively encode multi-scale spatial relationships, yielding dexterous, data-efficient motion synthesis even from sparse demonstrations. Evaluated on both our humanoid robot and desktop dual-arm robot, the RGMP framework achieves 87% task success in generalization tests and exhibits 5x greater data efficiency than the state-of-the-art model. This performance underscores its superior cross-domain generalization, enabled by geometric-semantic reasoning and recursive-Gaussion adaptation.

