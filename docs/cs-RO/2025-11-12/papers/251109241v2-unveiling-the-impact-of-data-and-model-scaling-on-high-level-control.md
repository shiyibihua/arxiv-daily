---
layout: default
title: Unveiling the Impact of Data and Model Scaling on High-Level Control for Humanoid Robots
---

# Unveiling the Impact of Data and Model Scaling on High-Level Control for Humanoid Robots

**arXiv**: [2511.09241v2](https://arxiv.org/abs/2511.09241) | [PDF](https://arxiv.org/pdf/2511.09241.pdf)

**ä½œè€…**: Yuxi Wei, Zirui Wang, Kangning Yin, Yue Hu, Jingbo Wang, Siheng Chen

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-12 (æ›´æ–°: 2025-12-07)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSCHURæ¡†æž¶ä¸ŽHumanoid-Unionæ•°æ®é›†ï¼Œæå‡äººå½¢æœºå™¨äººé«˜å±‚æŽ§åˆ¶çš„æ•°æ®ä¸Žæ¨¡åž‹å¯æ‰©å±•æ€§ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `äººå½¢æœºå™¨äºº` `é«˜å±‚æŽ§åˆ¶` `è¿åŠ¨ç”Ÿæˆ` `æ–‡æœ¬-è¿åŠ¨å¯¹é½` `å¤§è§„æ¨¡æ•°æ®é›†` `å¯æ‰©å±•å­¦ä¹ ` `Transformer`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. äººå½¢æœºå™¨äººå­¦ä¹ é¢ä¸´æ•°æ®ç“¶é¢ˆï¼ŒçŽ°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨å¤§è§„æ¨¡äººç±»è¿åŠ¨è§†é¢‘æ•°æ®ã€‚
2. æå‡ºSCHURæ¡†æž¶ï¼Œç»“åˆHumanoid-Unionæ•°æ®é›†ï¼Œå®žçŽ°äººå½¢æœºå™¨äººé«˜å±‚æŽ§åˆ¶çš„å¯æ‰©å±•å­¦ä¹ ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒSCHURåœ¨è¿åŠ¨ç”Ÿæˆè´¨é‡å’Œæ–‡æœ¬-è¿åŠ¨å¯¹é½æ–¹é¢æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨çœŸå®žæœºå™¨äººä¸ŠéªŒè¯äº†æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ•°æ®è§„æ¨¡ä¸€ç›´æ˜¯æœºå™¨äººå­¦ä¹ çš„å…³é”®ç“¶é¢ˆã€‚å¯¹äºŽäººå½¢æœºå™¨äººï¼Œäººç±»è§†é¢‘å’Œè¿åŠ¨æ•°æ®ä¸°å¯Œä¸”æ˜“äºŽèŽ·å–ï¼Œæä¾›äº†å…è´¹çš„å¤§è§„æ¨¡æ•°æ®æ¥æºã€‚æ­¤å¤–ï¼Œä¸Žè¿åŠ¨ç›¸å…³çš„è¯­ä¹‰ä¿¡æ¯èƒ½å¤Ÿå®žçŽ°æ¨¡æ€å¯¹é½å’Œé«˜å±‚æœºå™¨äººæŽ§åˆ¶å­¦ä¹ ã€‚ç„¶è€Œï¼Œå¦‚ä½•æœ‰æ•ˆåœ°æŒ–æŽ˜åŽŸå§‹è§†é¢‘ï¼Œæå–æœºå™¨äººå¯å­¦ä¹ çš„è¡¨ç¤ºï¼Œå¹¶åˆ©ç”¨å®ƒä»¬è¿›è¡Œå¯æ‰©å±•å­¦ä¹ ä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Humanoid-Unionï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡è‡ªä¸»æµç¨‹ç”Ÿæˆçš„å¤§è§„æ¨¡æ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡260å°æ—¶çš„å¤šæ ·åŒ–ã€é«˜è´¨é‡çš„äººå½¢æœºå™¨äººè¿åŠ¨æ•°æ®ï¼Œä»¥åŠä»Žäººç±»è¿åŠ¨è§†é¢‘ä¸­æå–çš„è¯­ä¹‰æ ‡æ³¨ã€‚è¯¥æ•°æ®é›†å¯ä»¥é€šè¿‡ç›¸åŒçš„æµç¨‹è¿›ä¸€æ­¥æ‰©å±•ã€‚åœ¨æ­¤æ•°æ®èµ„æºçš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†SCHURï¼Œä¸€ä¸ªå¯æ‰©å±•çš„å­¦ä¹ æ¡†æž¶ï¼Œæ—¨åœ¨æŽ¢ç´¢å¤§è§„æ¨¡æ•°æ®å¯¹äººå½¢æœºå™¨äººé«˜å±‚æŽ§åˆ¶çš„å½±å“ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œåœ¨æ•°æ®å’Œæ¨¡åž‹æ‰©å±•ä¸‹ï¼ŒSCHURå®žçŽ°äº†é«˜è´¨é‡çš„æœºå™¨äººè¿åŠ¨ç”Ÿæˆå’Œå¼ºå¤§çš„æ–‡æœ¬-è¿åŠ¨å¯¹é½ï¼Œä¸Žå…ˆå‰æ–¹æ³•ç›¸æ¯”ï¼ŒMPJPEæŒ‡æ ‡ä¸‹é‡å»ºæ•ˆæžœæå‡37%ï¼ŒFIDæŒ‡æ ‡ä¸‹å¯¹é½æ•ˆæžœæå‡25%ã€‚å…¶å®žé™…æ•ˆæžœå·²é€šè¿‡åœ¨çœŸå®žäººå½¢æœºå™¨äººä¸Šçš„éƒ¨ç½²å¾—åˆ°è¿›ä¸€æ­¥éªŒè¯ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šäººå½¢æœºå™¨äººé«˜å±‚æŽ§åˆ¶çš„å­¦ä¹ é¢ä¸´æ•°æ®è§„æ¨¡çš„é™åˆ¶ã€‚è™½ç„¶äººç±»è¿åŠ¨è§†é¢‘æ•°æ®ä¸°å¯Œï¼Œä½†å¦‚ä½•æœ‰æ•ˆåœ°ä»Žè¿™äº›åŽŸå§‹è§†é¢‘ä¸­æå–æœºå™¨äººå¯å­¦ä¹ çš„è¡¨ç¤ºï¼Œå¹¶å°†å…¶ç”¨äºŽå¯æ‰©å±•çš„å­¦ä¹ ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚çŽ°æœ‰æ–¹æ³•éš¾ä»¥å……åˆ†åˆ©ç”¨è¿™äº›æ•°æ®ï¼Œå¯¼è‡´æœºå™¨äººè¿åŠ¨ç”Ÿæˆè´¨é‡å’Œæ–‡æœ¬-è¿åŠ¨å¯¹é½æ•ˆæžœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æž„å»ºä¸€ä¸ªå¤§è§„æ¨¡çš„äººå½¢æœºå™¨äººè¿åŠ¨æ•°æ®é›†ï¼ˆHumanoid-Unionï¼‰ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè®¾è®¡ä¸€ä¸ªå¯æ‰©å±•çš„å­¦ä¹ æ¡†æž¶ï¼ˆSCHURï¼‰ã€‚é€šè¿‡è‡ªä¸»æµç¨‹ç”Ÿæˆé«˜è´¨é‡çš„æœºå™¨äººè¿åŠ¨æ•°æ®ï¼Œå¹¶åˆ©ç”¨äººç±»è¿åŠ¨è§†é¢‘çš„è¯­ä¹‰ä¿¡æ¯è¿›è¡Œæ ‡æ³¨ï¼Œä»Žè€Œå®žçŽ°æ¨¡æ€å¯¹é½å’Œé«˜å±‚æŽ§åˆ¶å­¦ä¹ ã€‚é€šè¿‡æ•°æ®å’Œæ¨¡åž‹è§„æ¨¡çš„æ‰©å±•ï¼Œæå‡æœºå™¨äººè¿åŠ¨ç”Ÿæˆè´¨é‡å’Œæ–‡æœ¬-è¿åŠ¨å¯¹é½æ•ˆæžœã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šSCHURæ¡†æž¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) æ•°æ®ç”Ÿæˆç®¡é“ï¼šç”¨äºŽä»Žäººç±»è¿åŠ¨è§†é¢‘ä¸­è‡ªåŠ¨ç”Ÿæˆäººå½¢æœºå™¨äººè¿åŠ¨æ•°æ®ï¼Œå¹¶è¿›è¡Œè¯­ä¹‰æ ‡æ³¨ã€‚2) è¿åŠ¨ç”Ÿæˆæ¨¡åž‹ï¼šåŸºäºŽTransformeræž¶æž„ï¼Œç”¨äºŽå­¦ä¹ ä»Žæ–‡æœ¬åˆ°è¿åŠ¨çš„æ˜ å°„å…³ç³»ã€‚3) è®­ç»ƒç­–ç•¥ï¼šé‡‡ç”¨å¤§è§„æ¨¡æ•°æ®è®­ç»ƒå’Œæ¨¡åž‹æ‰©å±•ç­–ç•¥ï¼Œä»¥æå‡æ¨¡åž‹æ€§èƒ½ã€‚æ•´ä½“æµç¨‹æ˜¯ä»Žäººç±»è§†é¢‘æ•°æ®å¼€å§‹ï¼Œç»è¿‡æ•°æ®ç”Ÿæˆç®¡é“å¾—åˆ°æœºå™¨äººè¿åŠ¨æ•°æ®å’Œè¯­ä¹‰æ ‡æ³¨ï¼Œç„¶åŽåˆ©ç”¨è¿™äº›æ•°æ®è®­ç»ƒè¿åŠ¨ç”Ÿæˆæ¨¡åž‹ï¼Œæœ€ç»ˆå®žçŽ°é«˜å±‚æŽ§åˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºŽï¼š1) æå‡ºäº†Humanoid-Unionæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„äººå½¢æœºå™¨äººè¿åŠ¨æ•°æ®é›†ï¼Œä¸ºå¯æ‰©å±•å­¦ä¹ æä¾›äº†æ•°æ®åŸºç¡€ã€‚2) è®¾è®¡äº†SCHURæ¡†æž¶ï¼Œè¯¥æ¡†æž¶èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨å¤§è§„æ¨¡æ•°æ®ï¼Œå®žçŽ°é«˜è´¨é‡çš„æœºå™¨äººè¿åŠ¨ç”Ÿæˆå’Œå¼ºå¤§çš„æ–‡æœ¬-è¿åŠ¨å¯¹é½ã€‚3) éªŒè¯äº†æ•°æ®å’Œæ¨¡åž‹è§„æ¨¡å¯¹äººå½¢æœºå™¨äººé«˜å±‚æŽ§åˆ¶çš„å½±å“ï¼Œå¹¶è¯æ˜Žäº†å¤§è§„æ¨¡æ•°æ®å’Œæ¨¡åž‹æ‰©å±•èƒ½å¤Ÿæ˜¾è‘—æå‡æ¨¡åž‹æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šHumanoid-Unionæ•°æ®é›†åŒ…å«è¶…è¿‡260å°æ—¶çš„æœºå™¨äººè¿åŠ¨æ•°æ®ï¼Œå¹¶é‡‡ç”¨è‡ªä¸»æµç¨‹ç”Ÿæˆï¼Œä¿è¯äº†æ•°æ®çš„å¤šæ ·æ€§å’Œè´¨é‡ã€‚SCHURæ¡†æž¶ä¸­çš„è¿åŠ¨ç”Ÿæˆæ¨¡åž‹åŸºäºŽTransformeræž¶æž„ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰æ–‡æœ¬å’Œè¿åŠ¨ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†å¤§è§„æ¨¡æ•°æ®è®­ç»ƒå’Œæ¨¡åž‹æ‰©å±•ç­–ç•¥ï¼Œä¾‹å¦‚å¢žåŠ Transformerçš„å±‚æ•°å’Œéšè—å•å…ƒæ•°ï¼Œä»¥æå‡æ¨¡åž‹å®¹é‡ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬è¿åŠ¨é‡å»ºæŸå¤±å’Œæ–‡æœ¬-è¿åŠ¨å¯¹é½æŸå¤±ï¼Œç”¨äºŽä¼˜åŒ–è¿åŠ¨ç”Ÿæˆè´¨é‡å’Œå¯¹é½æ•ˆæžœã€‚å…·ä½“å‚æ•°è®¾ç½®æœªçŸ¥ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒSCHURæ¡†æž¶åœ¨æ•°æ®å’Œæ¨¡åž‹æ‰©å±•ä¸‹ï¼Œå®žçŽ°äº†é«˜è´¨é‡çš„æœºå™¨äººè¿åŠ¨ç”Ÿæˆå’Œå¼ºå¤§çš„æ–‡æœ¬-è¿åŠ¨å¯¹é½ã€‚ä¸Žå…ˆå‰æ–¹æ³•ç›¸æ¯”ï¼ŒMPJPEæŒ‡æ ‡ä¸‹é‡å»ºæ•ˆæžœæå‡37%ï¼ŒFIDæŒ‡æ ‡ä¸‹å¯¹é½æ•ˆæžœæå‡25%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å·²åœ¨çœŸå®žäººå½¢æœºå™¨äººä¸ŠæˆåŠŸéƒ¨ç½²ï¼ŒéªŒè¯äº†å…¶åœ¨å®žé™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§äººå½¢æœºå™¨äººåº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚å®¶åº­æœåŠ¡ã€åŒ»ç–—è¾…åŠ©ã€å·¥ä¸šåˆ¶é€ ç­‰ã€‚é€šè¿‡é«˜å±‚æŽ§åˆ¶ï¼Œæœºå™¨äººå¯ä»¥æ ¹æ®äººç±»æŒ‡ä»¤æ‰§è¡Œå¤æ‚çš„ä»»åŠ¡ï¼Œæé«˜å·¥ä½œæ•ˆçŽ‡å’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›å®žçŽ°æ›´æ™ºèƒ½ã€æ›´è‡ªä¸»çš„äººå½¢æœºå™¨äººï¼Œæ›´å¥½åœ°æœåŠ¡äºŽäººç±»ç¤¾ä¼šã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Data scaling has long remained a critical bottleneck in robot learning. For humanoid robots, human videos and motion data are abundant and widely available, offering a free and large-scale data source. Besides, the semantics related to the motions enable modality alignment and high-level robot control learning. However, how to effectively mine raw video, extract robot-learnable representations, and leverage them for scalable learning remains an open problem. To address this, we introduce Humanoid-Union, a large-scale dataset generated through an autonomous pipeline, comprising over 260 hours of diverse, high-quality humanoid robot motion data with semantic annotations derived from human motion videos. The dataset can be further expanded via the same pipeline. Building on this data resource, we propose SCHUR, a scalable learning framework designed to explore the impact of large-scale data on high-level control in humanoid robots. Experimental results demonstrate that SCHUR achieves high robot motion generation quality and strong text-motion alignment under data and model scaling, with 37\% reconstruction improvement under MPJPE and 25\% alignment improvement under FID comparing with previous methods. Its effectiveness is further validated through deployment in real-world humanoid robot.

