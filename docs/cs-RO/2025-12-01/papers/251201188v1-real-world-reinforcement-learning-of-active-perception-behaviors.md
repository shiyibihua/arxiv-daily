---
layout: default
title: Real-World Reinforcement Learning of Active Perception Behaviors
---

# Real-World Reinforcement Learning of Active Perception Behaviors

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.01188" target="_blank" class="toolbar-btn">arXiv: 2512.01188v1</a>
    <a href="https://arxiv.org/pdf/2512.01188.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.01188v1" 
            onclick="toggleFavorite(this, '2512.01188v1', 'Real-World Reinforcement Learning of Active Perception Behaviors')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Edward S. Hu, Jie Wang, Xingfang Yuan, Fiona Luo, Muyao Li, Gaspard Lambrechts, Oleh Rybkin, Dinesh Jayaraman

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-01

**Â§áÊ≥®**: NeurIPS 2025 camera ready

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://penn-pal-lab.github.io/aawr/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ÈùûÂØπÁß∞‰ºòÂäøÂä†ÊùÉÂõûÂΩí(AAWR)ÔºåËß£ÂÜ≥Êú∫Âô®‰∫∫‰∏ªÂä®ÊÑüÁü•Ë°å‰∏∫ÁöÑÁé∞ÂÆûÂº∫ÂåñÂ≠¶‰π†ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Âº∫ÂåñÂ≠¶‰π†` `‰∏ªÂä®ÊÑüÁü•` `Êú∫Âô®‰∫∫Â≠¶‰π†` `ÈÉ®ÂàÜÂèØËßÇÊµãÊÄß` `‰ºòÂäøÂä†ÊùÉÂõûÂΩí`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊú∫Âô®‰∫∫Â≠¶‰π†ÊñπÊ≥ïÈöæ‰ª•Âú®ÈÉ®ÂàÜÂèØËßÇÊµãÁéØÂ¢É‰∏ãÁîüÊàê‰∏ªÂä®ÊÑüÁü•Ë°å‰∏∫ÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®Â§çÊùÇ‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®„ÄÇ
2. AAWRÂà©Áî®ËÆ≠ÁªÉÊó∂ÂèØÁî®ÁöÑÁâπÊùÉ‰º†ÊÑüÂô®‰ø°ÊÅØÔºåÂ≠¶‰π†È´òË¥®ÈáèÁöÑ‰ª∑ÂÄºÂáΩÊï∞Ôºå‰ªéËÄåÊåáÂØºÁ≠ñÁï•Â≠¶‰π†ÔºåÂÖãÊúçÈÉ®ÂàÜÂèØËßÇÊµãÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåAAWRÂú®Â§ö‰∏™Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÔºåËÉΩÂ§üÊúâÊïàÂêàÊàê‰∏ªÂä®ÊÑüÁü•Ë°å‰∏∫ÔºåÊòæËëóÊèêÂçá‰ªªÂä°ÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú∫Âô®‰∫∫ÁöÑÁû¨Êó∂ÊÑüÁü•ËßÇÊµãÂπ∂‰∏çÊÄªÊòØËÉΩÊè≠Á§∫‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÁä∂ÊÄÅ‰ø°ÊÅØ„ÄÇÂú®ËøôÊ†∑ÁöÑÈÉ®ÂàÜÂèØËßÇÊµãÊÄß‰∏ãÔºåÊúÄ‰ºòË°å‰∏∫ÈÄöÂ∏∏Ê∂âÂèä‰∏ªÂä®ÈááÂèñË°åÂä®‰ª•Ëé∑ÂèñÁº∫Â§±ÁöÑ‰ø°ÊÅØ„ÄÇÁé∞ÊúâÁöÑÊú∫Âô®‰∫∫Â≠¶‰π†ÊäÄÊúØÈöæ‰ª•‰∫ßÁîüËøôÁßç‰∏ªÂä®ÊÑüÁü•Ë°å‰∏∫„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆÄÂçïÁöÑÁé∞ÂÆûÊú∫Âô®‰∫∫Â≠¶‰π†ÊñπÊ≥ïÔºå‰ª•È´òÊïàÂú∞ËÆ≠ÁªÉ‰∏ªÂä®ÊÑüÁü•Á≠ñÁï•„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÔºåÈùûÂØπÁß∞‰ºòÂäøÂä†ÊùÉÂõûÂΩí(AAWR)ÔºåÂà©Áî®ËÆ≠ÁªÉÊó∂ÂØπ‚ÄúÁâπÊùÉ‚ÄùÈ¢ùÂ§ñ‰º†ÊÑüÂô®ÁöÑËÆøÈóÆ„ÄÇËøô‰∫õÁâπÊùÉ‰º†ÊÑüÂô®ËÉΩÂ§üËÆ≠ÁªÉÈ´òË¥®ÈáèÁöÑÁâπÊùÉ‰ª∑ÂÄºÂáΩÊï∞Ôºå‰ªéËÄåÊúâÂä©‰∫é‰º∞ËÆ°ÁõÆÊ†áÁ≠ñÁï•ÁöÑ‰ºòÂäø„ÄÇ‰ªéÂ∞ëÈáèÂèØËÉΩÊ¨°‰ºòÁöÑÊºîÁ§∫Âíå‰∏Ä‰∏™Êòì‰∫éËé∑ÂæóÁöÑÁ≤óÁï•Á≠ñÁï•ÂàùÂßãÂåñÂºÄÂßãÔºåAAWRËøÖÈÄüËé∑Âæó‰∏ªÂä®ÊÑüÁü•Ë°å‰∏∫Âπ∂ÊèêÈ´ò‰ªªÂä°ÊÄßËÉΩ„ÄÇÂú®3‰∏™Êú∫Âô®‰∫∫‰∏äÁöÑ8‰∏™Êìç‰Ωú‰ªªÂä°ÁöÑËØÑ‰º∞‰∏≠ÔºåËøô‰∫õ‰ªªÂä°Ë∑®Ë∂ä‰∫Ü‰∏çÂêåÁ®ãÂ∫¶ÁöÑÈÉ®ÂàÜÂèØËßÇÊµãÊÄßÔºåAAWRÂêàÊàê‰∫ÜÂèØÈù†ÁöÑ‰∏ªÂä®ÊÑüÁü•Ë°å‰∏∫Ôºå‰ºò‰∫éÊâÄÊúâÂÖàÂâçÁöÑÊñπÊ≥ï„ÄÇÂΩì‰ΩøÁî®‰∏Ä‰∏™Âú®‰∏ªÂä®ÊÑüÁü•‰ªªÂä°‰∏≠Ë°®Áé∞‰∏ç‰Ω≥ÁöÑ‚ÄúÈÄöÁî®‚ÄùÊú∫Âô®‰∫∫Á≠ñÁï•ÂàùÂßãÂåñÊó∂ÔºåAAWRÊúâÊïàÂú∞ÁîüÊàê‰ø°ÊÅØÊî∂ÈõÜË°å‰∏∫Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÂú®‰∏•ÈáçÁöÑÈÉ®ÂàÜÂèØËßÇÊµãÊÄß‰∏ãËøõË°åÊìç‰Ωú‰ªªÂä°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Êú∫Âô®‰∫∫Âº∫ÂåñÂ≠¶‰π†‰∏≠ÔºåÁî±‰∫éÈÉ®ÂàÜÂèØËßÇÊµãÊÄßÂØºËá¥Êú∫Âô®‰∫∫Èöæ‰ª•ÊúâÊïàÊâßË°å‰ªªÂä°ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÈÉ®ÂàÜÂèØËßÇÊµãÁéØÂ¢É‰∏ãÁöÑ‰∏ªÂä®ÊÑüÁü•Ë°å‰∏∫Êó∂Ë°®Áé∞‰∏ç‰Ω≥ÔºåÊó†Ê≥ïÊúâÊïàÂú∞Â≠¶‰π†Â¶Ç‰Ωï‰∏ªÂä®Ëé∑ÂèñÁº∫Â§±ÁöÑ‰ø°ÊÅØÔºå‰ªéËÄåÂΩ±Âìç‰ªªÂä°ÂÆåÊàêÁöÑË¥®ÈáèÂíåÊïàÁéá„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ÈùûÂØπÁß∞‰ºòÂäøÂä†ÊùÉÂõûÂΩí(AAWR)ÁÆóÊ≥ïÔºåÂú®ËÆ≠ÁªÉÈò∂ÊÆµÂºïÂÖ•‚ÄúÁâπÊùÉ‚Äù‰º†ÊÑüÂô®‰ø°ÊÅØÔºåÂ≠¶‰π†‰∏Ä‰∏™È´òË¥®ÈáèÁöÑ‰ª∑ÂÄºÂáΩÊï∞„ÄÇËØ•‰ª∑ÂÄºÂáΩÊï∞ËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞ËØÑ‰º∞Á≠ñÁï•ÁöÑ‰ºòÂä£Ôºå‰ªéËÄåÊåáÂØºÁ≠ñÁï•Â≠¶‰π†Ôºå‰ΩøÊú∫Âô®‰∫∫ËÉΩÂ§üÂ≠¶‰ºö‰∏ªÂä®ÊÑüÁü•ÁéØÂ¢ÉÔºåËé∑ÂèñÂÆåÊàê‰ªªÂä°ÊâÄÈúÄÁöÑ‰ø°ÊÅØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAAWRÁÆóÊ≥ïÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) ‰ΩøÁî®Â∞ëÈáèÊºîÁ§∫Êï∞ÊçÆÂíå‰∏Ä‰∏™Á≤óÁï•ÁöÑÁ≠ñÁï•ÂàùÂßãÂåñ‰Ωú‰∏∫ÂºïÂØº„ÄÇ2) Âú®ËÆ≠ÁªÉÈò∂ÊÆµÔºåÂà©Áî®ÁâπÊùÉ‰º†ÊÑüÂô®Êèê‰æõÈ¢ùÂ§ñÁöÑ‰ø°ÊÅØÔºåËÆ≠ÁªÉ‰∏Ä‰∏™ÁâπÊùÉ‰ª∑ÂÄºÂáΩÊï∞„ÄÇ3) ‰ΩøÁî®ÁâπÊùÉ‰ª∑ÂÄºÂáΩÊï∞‰º∞ËÆ°ÁõÆÊ†áÁ≠ñÁï•ÁöÑ‰ºòÂäøÂáΩÊï∞„ÄÇ4) ‰ΩøÁî®‰ºòÂäøÂä†ÊùÉÂõûÂΩíÊñπÊ≥ïÊõ¥Êñ∞ÁõÆÊ†áÁ≠ñÁï•Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÊâßË°å‰ªªÂä°Âπ∂‰∏ªÂä®ÊÑüÁü•ÁéØÂ¢É„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAAWRÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂà©Áî®‰∫ÜËÆ≠ÁªÉÈò∂ÊÆµÁöÑÁâπÊùÉ‰ø°ÊÅØÊù•Â≠¶‰π†È´òË¥®ÈáèÁöÑ‰ª∑ÂÄºÂáΩÊï∞„ÄÇ‰∏é‰º†ÁªüÊñπÊ≥ï‰∏çÂêåÔºåAAWRÂπ∂‰∏çÁõ¥Êé•‰æùËµñ‰∫éÈÉ®ÂàÜÂèØËßÇÊµãÁöÑ‰º†ÊÑüÂô®Êï∞ÊçÆÊù•Â≠¶‰π†‰ª∑ÂÄºÂáΩÊï∞ÔºåËÄåÊòØÈÄöËøáÁâπÊùÉ‰º†ÊÑüÂô®Êèê‰æõÊõ¥ÂÖ®Èù¢ÁöÑÁéØÂ¢É‰ø°ÊÅØÔºå‰ªéËÄåÊõ¥ÂáÜÁ°ÆÂú∞ËØÑ‰º∞Á≠ñÁï•ÁöÑ‰ºòÂä£„ÄÇËøôÁßçÈùûÂØπÁß∞ÁöÑÂ≠¶‰π†ÊñπÂºèËÉΩÂ§üÊúâÊïàÂú∞ÂÖãÊúçÈÉ®ÂàÜÂèØËßÇÊµãÊÄßÂ∏¶Êù•ÁöÑÊåëÊàò„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAAWRÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®ÈùûÂØπÁß∞ÁöÑÊñπÂºèÂ§ÑÁêÜËÆ≠ÁªÉÂíåÊµãËØïÈò∂ÊÆµÁöÑ‰º†ÊÑüÂô®‰ø°ÊÅØÔºåËÆ≠ÁªÉÈò∂ÊÆµ‰ΩøÁî®ÁâπÊùÉ‰º†ÊÑüÂô®ÔºåÊµãËØïÈò∂ÊÆµÂè™‰ΩøÁî®ÊôÆÈÄö‰º†ÊÑüÂô®„ÄÇ2) ‰ΩøÁî®‰ºòÂäøÂä†ÊùÉÂõûÂΩíÊñπÊ≥ïÊù•Êõ¥Êñ∞Á≠ñÁï•ÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊ†πÊçÆ‰ºòÂäøÂáΩÊï∞ÁöÑÂÄºÊù•Ë∞ÉÊï¥Á≠ñÁï•ÁöÑÊõ¥Êñ∞ÂπÖÂ∫¶Ôºå‰ªéËÄåÊõ¥ÊúâÊïàÂú∞Â≠¶‰π†ÊúÄ‰ºòÁ≠ñÁï•„ÄÇ3) ‰ª∑ÂÄºÂáΩÊï∞ÁöÑÁΩëÁªúÁªìÊûÑÂíåÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÔºåÊó®Âú®ÊúÄÂ§ßÂåñÁâπÊùÉ‰ø°ÊÅØÁöÑ‰ΩøÁî®ÊïàÁéáÔºåÂπ∂‰øùËØÅ‰ª∑ÂÄºÂáΩÊï∞ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAAWRÂú®8‰∏™‰∏çÂêåÁöÑÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÔºåÂùá‰ºò‰∫éÁé∞ÊúâÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ï„ÄÇÁâπÂà´ÊòØÂú®ÈÉ®ÂàÜÂèØËßÇÊµãÊÄßËæÉÂº∫ÁöÑ‰ªªÂä°‰∏≠ÔºåAAWRËÉΩÂ§üÊòæËëóÊèêÈ´ò‰ªªÂä°ÂÆåÊàêÁöÑÊàêÂäüÁéáÂíåÊïàÁéá„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∫õ‰ªªÂä°‰∏≠ÔºåAAWRËÉΩÂ§üÂ∞ÜÊàêÂäüÁéá‰ªéÂü∫Á∫øÁöÑ20%ÊèêÈ´òÂà∞80%‰ª•‰∏äÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®‰∏ªÂä®ÊÑüÁü•Ë°å‰∏∫Â≠¶‰π†ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÊú∫Âô®‰∫∫ËøõË°å‰∏ªÂä®ÊÑüÁü•ÁöÑÂú∫ÊôØÔºå‰æãÂ¶ÇÂ§çÊùÇÁéØÂ¢É‰∏ãÁöÑÁâ©‰ΩìÊìç‰Ωú„ÄÅÊú™Áü•ÁéØÂ¢ÉÁöÑÊé¢Á¥¢„ÄÅ‰ª•ÂèäÈúÄË¶ÅÊú∫Âô®‰∫∫Ëá™‰∏ªËøõË°å‰ø°ÊÅØÊî∂ÈõÜÁöÑ‰ªªÂä°„ÄÇËØ•ÊñπÊ≥ïËÉΩÂ§üÊèêÈ´òÊú∫Âô®‰∫∫Âú®ÈÉ®ÂàÜÂèØËßÇÊµãÁéØÂ¢É‰∏ãÁöÑ‰ªªÂä°ÂÆåÊàêËÉΩÂäõÂíåÊïàÁéáÔºåÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÊô∫ËÉΩÂà∂ÈÄ†„ÄÅ‰ªìÂÇ®Áâ©ÊµÅ„ÄÅÂÆ∂Â∫≠ÊúçÂä°Á≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> A robot's instantaneous sensory observations do not always reveal task-relevant state information. Under such partial observability, optimal behavior typically involves explicitly acting to gain the missing information. Today's standard robot learning techniques struggle to produce such active perception behaviors. We propose a simple real-world robot learning recipe to efficiently train active perception policies. Our approach, asymmetric advantage weighted regression (AAWR), exploits access to "privileged" extra sensors at training time. The privileged sensors enable training high-quality privileged value functions that aid in estimating the advantage of the target policy. Bootstrapping from a small number of potentially suboptimal demonstrations and an easy-to-obtain coarse policy initialization, AAWR quickly acquires active perception behaviors and boosts task performance. In evaluations on 8 manipulation tasks on 3 robots spanning varying degrees of partial observability, AAWR synthesizes reliable active perception behaviors that outperform all prior approaches. When initialized with a "generalist" robot policy that struggles with active perception tasks, AAWR efficiently generates information-gathering behaviors that allow it to operate under severe partial observability for manipulation tasks. Website: https://penn-pal-lab.github.io/aawr/

