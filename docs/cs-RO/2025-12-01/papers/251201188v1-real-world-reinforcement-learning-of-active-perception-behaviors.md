---
layout: default
title: Real-World Reinforcement Learning of Active Perception Behaviors
---

# Real-World Reinforcement Learning of Active Perception Behaviors

**arXiv**: [2512.01188v1](https://arxiv.org/abs/2512.01188) | [PDF](https://arxiv.org/pdf/2512.01188.pdf)

**ä½œè€…**: Edward S. Hu, Jie Wang, Xingfang Yuan, Fiona Luo, Muyao Li, Gaspard Lambrechts, Oleh Rybkin, Dinesh Jayaraman

**åˆ†ç±»**: cs.RO, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-01

**å¤‡æ³¨**: NeurIPS 2025 camera ready

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://penn-pal-lab.github.io/aawr/)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéžå¯¹ç§°ä¼˜åŠ¿åŠ æƒå›žå½’(AAWR)ï¼Œè§£å†³æœºå™¨äººä¸»åŠ¨æ„ŸçŸ¥è¡Œä¸ºçš„çŽ°å®žå¼ºåŒ–å­¦ä¹ é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `ä¸»åŠ¨æ„ŸçŸ¥` `æœºå™¨äººå­¦ä¹ ` `éƒ¨åˆ†å¯è§‚æµ‹æ€§` `ä¼˜åŠ¿åŠ æƒå›žå½’`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æœºå™¨äººå­¦ä¹ æ–¹æ³•éš¾ä»¥åœ¨éƒ¨åˆ†å¯è§‚æµ‹çŽ¯å¢ƒä¸‹ç”Ÿæˆä¸»åŠ¨æ„ŸçŸ¥è¡Œä¸ºï¼Œé™åˆ¶äº†å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚
2. AAWRåˆ©ç”¨è®­ç»ƒæ—¶å¯ç”¨çš„ç‰¹æƒä¼ æ„Ÿå™¨ä¿¡æ¯ï¼Œå­¦ä¹ é«˜è´¨é‡çš„ä»·å€¼å‡½æ•°ï¼Œä»Žè€ŒæŒ‡å¯¼ç­–ç•¥å­¦ä¹ ï¼Œå…‹æœéƒ¨åˆ†å¯è§‚æµ‹æ€§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒAAWRåœ¨å¤šä¸ªæœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆæˆä¸»åŠ¨æ„ŸçŸ¥è¡Œä¸ºï¼Œæ˜¾è‘—æå‡ä»»åŠ¡æ€§èƒ½ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœºå™¨äººçš„çž¬æ—¶æ„ŸçŸ¥è§‚æµ‹å¹¶ä¸æ€»æ˜¯èƒ½æ­ç¤ºä»»åŠ¡ç›¸å…³çš„çŠ¶æ€ä¿¡æ¯ã€‚åœ¨è¿™æ ·çš„éƒ¨åˆ†å¯è§‚æµ‹æ€§ä¸‹ï¼Œæœ€ä¼˜è¡Œä¸ºé€šå¸¸æ¶‰åŠä¸»åŠ¨é‡‡å–è¡ŒåŠ¨ä»¥èŽ·å–ç¼ºå¤±çš„ä¿¡æ¯ã€‚çŽ°æœ‰çš„æœºå™¨äººå­¦ä¹ æŠ€æœ¯éš¾ä»¥äº§ç”Ÿè¿™ç§ä¸»åŠ¨æ„ŸçŸ¥è¡Œä¸ºã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•çš„çŽ°å®žæœºå™¨äººå­¦ä¹ æ–¹æ³•ï¼Œä»¥é«˜æ•ˆåœ°è®­ç»ƒä¸»åŠ¨æ„ŸçŸ¥ç­–ç•¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•ï¼Œéžå¯¹ç§°ä¼˜åŠ¿åŠ æƒå›žå½’(AAWR)ï¼Œåˆ©ç”¨è®­ç»ƒæ—¶å¯¹â€œç‰¹æƒâ€é¢å¤–ä¼ æ„Ÿå™¨çš„è®¿é—®ã€‚è¿™äº›ç‰¹æƒä¼ æ„Ÿå™¨èƒ½å¤Ÿè®­ç»ƒé«˜è´¨é‡çš„ç‰¹æƒä»·å€¼å‡½æ•°ï¼Œä»Žè€Œæœ‰åŠ©äºŽä¼°è®¡ç›®æ ‡ç­–ç•¥çš„ä¼˜åŠ¿ã€‚ä»Žå°‘é‡å¯èƒ½æ¬¡ä¼˜çš„æ¼”ç¤ºå’Œä¸€ä¸ªæ˜“äºŽèŽ·å¾—çš„ç²—ç•¥ç­–ç•¥åˆå§‹åŒ–å¼€å§‹ï¼ŒAAWRè¿…é€ŸèŽ·å¾—ä¸»åŠ¨æ„ŸçŸ¥è¡Œä¸ºå¹¶æé«˜ä»»åŠ¡æ€§èƒ½ã€‚åœ¨3ä¸ªæœºå™¨äººä¸Šçš„8ä¸ªæ“ä½œä»»åŠ¡çš„è¯„ä¼°ä¸­ï¼Œè¿™äº›ä»»åŠ¡è·¨è¶Šäº†ä¸åŒç¨‹åº¦çš„éƒ¨åˆ†å¯è§‚æµ‹æ€§ï¼ŒAAWRåˆæˆäº†å¯é çš„ä¸»åŠ¨æ„ŸçŸ¥è¡Œä¸ºï¼Œä¼˜äºŽæ‰€æœ‰å…ˆå‰çš„æ–¹æ³•ã€‚å½“ä½¿ç”¨ä¸€ä¸ªåœ¨ä¸»åŠ¨æ„ŸçŸ¥ä»»åŠ¡ä¸­è¡¨çŽ°ä¸ä½³çš„â€œé€šç”¨â€æœºå™¨äººç­–ç•¥åˆå§‹åŒ–æ—¶ï¼ŒAAWRæœ‰æ•ˆåœ°ç”Ÿæˆä¿¡æ¯æ”¶é›†è¡Œä¸ºï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨ä¸¥é‡çš„éƒ¨åˆ†å¯è§‚æµ‹æ€§ä¸‹è¿›è¡Œæ“ä½œä»»åŠ¡ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººå¼ºåŒ–å­¦ä¹ ä¸­ï¼Œç”±äºŽéƒ¨åˆ†å¯è§‚æµ‹æ€§å¯¼è‡´æœºå™¨äººéš¾ä»¥æœ‰æ•ˆæ‰§è¡Œä»»åŠ¡çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•åœ¨å¤„ç†éƒ¨åˆ†å¯è§‚æµ‹çŽ¯å¢ƒä¸‹çš„ä¸»åŠ¨æ„ŸçŸ¥è¡Œä¸ºæ—¶è¡¨çŽ°ä¸ä½³ï¼Œæ— æ³•æœ‰æ•ˆåœ°å­¦ä¹ å¦‚ä½•ä¸»åŠ¨èŽ·å–ç¼ºå¤±çš„ä¿¡æ¯ï¼Œä»Žè€Œå½±å“ä»»åŠ¡å®Œæˆçš„è´¨é‡å’Œæ•ˆçŽ‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨éžå¯¹ç§°ä¼˜åŠ¿åŠ æƒå›žå½’(AAWR)ç®—æ³•ï¼Œåœ¨è®­ç»ƒé˜¶æ®µå¼•å…¥â€œç‰¹æƒâ€ä¼ æ„Ÿå™¨ä¿¡æ¯ï¼Œå­¦ä¹ ä¸€ä¸ªé«˜è´¨é‡çš„ä»·å€¼å‡½æ•°ã€‚è¯¥ä»·å€¼å‡½æ•°èƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°ç­–ç•¥çš„ä¼˜åŠ£ï¼Œä»Žè€ŒæŒ‡å¯¼ç­–ç•¥å­¦ä¹ ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿå­¦ä¼šä¸»åŠ¨æ„ŸçŸ¥çŽ¯å¢ƒï¼ŒèŽ·å–å®Œæˆä»»åŠ¡æ‰€éœ€çš„ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šAAWRç®—æ³•çš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) ä½¿ç”¨å°‘é‡æ¼”ç¤ºæ•°æ®å’Œä¸€ä¸ªç²—ç•¥çš„ç­–ç•¥åˆå§‹åŒ–ä½œä¸ºå¼•å¯¼ã€‚2) åœ¨è®­ç»ƒé˜¶æ®µï¼Œåˆ©ç”¨ç‰¹æƒä¼ æ„Ÿå™¨æä¾›é¢å¤–çš„ä¿¡æ¯ï¼Œè®­ç»ƒä¸€ä¸ªç‰¹æƒä»·å€¼å‡½æ•°ã€‚3) ä½¿ç”¨ç‰¹æƒä»·å€¼å‡½æ•°ä¼°è®¡ç›®æ ‡ç­–ç•¥çš„ä¼˜åŠ¿å‡½æ•°ã€‚4) ä½¿ç”¨ä¼˜åŠ¿åŠ æƒå›žå½’æ–¹æ³•æ›´æ–°ç›®æ ‡ç­–ç•¥ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°æ‰§è¡Œä»»åŠ¡å¹¶ä¸»åŠ¨æ„ŸçŸ¥çŽ¯å¢ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šAAWRçš„å…³é”®åˆ›æ–°åœ¨äºŽåˆ©ç”¨äº†è®­ç»ƒé˜¶æ®µçš„ç‰¹æƒä¿¡æ¯æ¥å­¦ä¹ é«˜è´¨é‡çš„ä»·å€¼å‡½æ•°ã€‚ä¸Žä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒAAWRå¹¶ä¸ç›´æŽ¥ä¾èµ–äºŽéƒ¨åˆ†å¯è§‚æµ‹çš„ä¼ æ„Ÿå™¨æ•°æ®æ¥å­¦ä¹ ä»·å€¼å‡½æ•°ï¼Œè€Œæ˜¯é€šè¿‡ç‰¹æƒä¼ æ„Ÿå™¨æä¾›æ›´å…¨é¢çš„çŽ¯å¢ƒä¿¡æ¯ï¼Œä»Žè€Œæ›´å‡†ç¡®åœ°è¯„ä¼°ç­–ç•¥çš„ä¼˜åŠ£ã€‚è¿™ç§éžå¯¹ç§°çš„å­¦ä¹ æ–¹å¼èƒ½å¤Ÿæœ‰æ•ˆåœ°å…‹æœéƒ¨åˆ†å¯è§‚æµ‹æ€§å¸¦æ¥çš„æŒ‘æˆ˜ã€‚

**å…³é”®è®¾è®¡**ï¼šAAWRçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨éžå¯¹ç§°çš„æ–¹å¼å¤„ç†è®­ç»ƒå’Œæµ‹è¯•é˜¶æ®µçš„ä¼ æ„Ÿå™¨ä¿¡æ¯ï¼Œè®­ç»ƒé˜¶æ®µä½¿ç”¨ç‰¹æƒä¼ æ„Ÿå™¨ï¼Œæµ‹è¯•é˜¶æ®µåªä½¿ç”¨æ™®é€šä¼ æ„Ÿå™¨ã€‚2) ä½¿ç”¨ä¼˜åŠ¿åŠ æƒå›žå½’æ–¹æ³•æ¥æ›´æ–°ç­–ç•¥ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ ¹æ®ä¼˜åŠ¿å‡½æ•°çš„å€¼æ¥è°ƒæ•´ç­–ç•¥çš„æ›´æ–°å¹…åº¦ï¼Œä»Žè€Œæ›´æœ‰æ•ˆåœ°å­¦ä¹ æœ€ä¼˜ç­–ç•¥ã€‚3) ä»·å€¼å‡½æ•°çš„ç½‘ç»œç»“æž„å’ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ï¼Œæ—¨åœ¨æœ€å¤§åŒ–ç‰¹æƒä¿¡æ¯çš„ä½¿ç”¨æ•ˆçŽ‡ï¼Œå¹¶ä¿è¯ä»·å€¼å‡½æ•°çš„å‡†ç¡®æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒAAWRåœ¨8ä¸ªä¸åŒçš„æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼Œå‡ä¼˜äºŽçŽ°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯åœ¨éƒ¨åˆ†å¯è§‚æµ‹æ€§è¾ƒå¼ºçš„ä»»åŠ¡ä¸­ï¼ŒAAWRèƒ½å¤Ÿæ˜¾è‘—æé«˜ä»»åŠ¡å®Œæˆçš„æˆåŠŸçŽ‡å’Œæ•ˆçŽ‡ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›ä»»åŠ¡ä¸­ï¼ŒAAWRèƒ½å¤Ÿå°†æˆåŠŸçŽ‡ä»ŽåŸºçº¿çš„20%æé«˜åˆ°80%ä»¥ä¸Šï¼Œè¯æ˜Žäº†å…¶åœ¨ä¸»åŠ¨æ„ŸçŸ¥è¡Œä¸ºå­¦ä¹ æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§éœ€è¦æœºå™¨äººè¿›è¡Œä¸»åŠ¨æ„ŸçŸ¥çš„åœºæ™¯ï¼Œä¾‹å¦‚å¤æ‚çŽ¯å¢ƒä¸‹çš„ç‰©ä½“æ“ä½œã€æœªçŸ¥çŽ¯å¢ƒçš„æŽ¢ç´¢ã€ä»¥åŠéœ€è¦æœºå™¨äººè‡ªä¸»è¿›è¡Œä¿¡æ¯æ”¶é›†çš„ä»»åŠ¡ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæé«˜æœºå™¨äººåœ¨éƒ¨åˆ†å¯è§‚æµ‹çŽ¯å¢ƒä¸‹çš„ä»»åŠ¡å®Œæˆèƒ½åŠ›å’Œæ•ˆçŽ‡ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½åˆ¶é€ ã€ä»“å‚¨ç‰©æµã€å®¶åº­æœåŠ¡ç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> A robot's instantaneous sensory observations do not always reveal task-relevant state information. Under such partial observability, optimal behavior typically involves explicitly acting to gain the missing information. Today's standard robot learning techniques struggle to produce such active perception behaviors. We propose a simple real-world robot learning recipe to efficiently train active perception policies. Our approach, asymmetric advantage weighted regression (AAWR), exploits access to "privileged" extra sensors at training time. The privileged sensors enable training high-quality privileged value functions that aid in estimating the advantage of the target policy. Bootstrapping from a small number of potentially suboptimal demonstrations and an easy-to-obtain coarse policy initialization, AAWR quickly acquires active perception behaviors and boosts task performance. In evaluations on 8 manipulation tasks on 3 robots spanning varying degrees of partial observability, AAWR synthesizes reliable active perception behaviors that outperform all prior approaches. When initialized with a "generalist" robot policy that struggles with active perception tasks, AAWR efficiently generates information-gathering behaviors that allow it to operate under severe partial observability for manipulation tasks. Website: https://penn-pal-lab.github.io/aawr/

