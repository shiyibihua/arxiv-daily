---
layout: default
title: SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning
---

# SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09674" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.09674v1</a>
  <a href="https://arxiv.org/pdf/2509.09674.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09674v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09674v1', 'SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Haozhan Li, Yuxin Zuo, Jiale Yu, Yuhao Zhang, Zhaohui Yang, Kaiyan Zhang, Xuekai Zhu, Yuchen Zhang, Tianxing Chen, Ganqu Cui, Dehui Wang, Dingxiang Luo, Yuchen Fan, Youbang Sun, Jia Zeng, Jiangmiao Pang, Shanghang Zhang, Yu Wang, Yao Mu, Bowen Zhou, Ning Ding

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.CL, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-11

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/PRIME-RL/SimpleVLA-RL)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**SimpleVLA-RLÔºöÈÄöËøáÂº∫ÂåñÂ≠¶‰π†Êâ©Â±ïVLAÊ®°ÂûãËÆ≠ÁªÉÔºåÊèêÂçáÊú∫Âô®‰∫∫Êìç‰ΩúÊÄßËÉΩ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `VLAÊ®°Âûã` `Âº∫ÂåñÂ≠¶‰π†` `Êú∫Âô®‰∫∫Êìç‰Ωú` `ÈïøÊúüÂä®‰ΩúËßÑÂàí` `Ê≥õÂåñËÉΩÂäõ` `ËΩ®ËøπÈááÊ†∑` `Âπ∂Ë°åÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. VLAÊ®°Âûã‰æùËµñÂ§ßÈáè‰∫∫Â∑•Ê†áÊ≥®ÁöÑÊú∫Âô®‰∫∫ËΩ®ËøπËøõË°åÁõëÁù£ÂæÆË∞ÉÔºåÊï∞ÊçÆËé∑ÂèñÊàêÊú¨È´òÊòÇ‰∏îÊ≥õÂåñÊÄßÂèóÈôê„ÄÇ
2. SimpleVLA-RLÂà©Áî®Âº∫ÂåñÂ≠¶‰π†ÔºåÈÄöËøáVLAÁâπÂÆöÁöÑËΩ®ËøπÈááÊ†∑ÂíåÂπ∂Ë°åÂåñÁ≠âÊäÄÊúØÔºåÊèêÂçáVLAÊ®°ÂûãÁöÑÈïøÊúüÂä®‰ΩúËßÑÂàíËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåSimpleVLA-RLÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏äË∂ÖË∂ä‰∫ÜÁõëÁù£ÂæÆË∞ÉÔºåÂπ∂ÂèëÁé∞‰∫ÜÊñ∞ÁöÑÁ≠ñÁï•Ê®°ÂºèÔºåÊèêÂçá‰∫ÜÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãÂ∑≤Êàê‰∏∫Êú∫Âô®‰∫∫Êìç‰ΩúÁöÑÂº∫Â§ßËåÉ‰æã„ÄÇÂ∞ΩÁÆ°Â§ßËßÑÊ®°È¢ÑËÆ≠ÁªÉÂíåÁõëÁù£ÂæÆË∞É(SFT)ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜËøô‰∫õÊ®°ÂûãÈù¢‰∏¥‰∏§‰∏™Ê†πÊú¨ÊåëÊàòÔºö(i)Áî®‰∫éSFTÊâ©Â±ïÁöÑÂ§ßËßÑÊ®°‰∫∫Â∑•Êìç‰ΩúÊú∫Âô®‰∫∫ËΩ®ËøπÁöÑÁ®ÄÁº∫ÊÄßÂíåÈ´òÊàêÊú¨Ôºå‰ª•Âèä(ii)ÂØπÊ∂âÂèäÂàÜÂ∏ÉËΩ¨ÁßªÁöÑ‰ªªÂä°ÁöÑÊ≥õÂåñËÉΩÂäõÊúâÈôê„ÄÇÂ§ßÂûãÊé®ÁêÜÊ®°Âûã(LRM)ÁöÑÊúÄÊñ∞Á™ÅÁ†¥Ë°®ÊòéÔºåÂº∫ÂåñÂ≠¶‰π†(RL)ÂèØ‰ª•ÊòæËëóÂ¢ûÂº∫ÈÄêÊ≠•Êé®ÁêÜËÉΩÂäõÔºåËøôÂºïÂá∫‰∫Ü‰∏Ä‰∏™Ëá™ÁÑ∂ÁöÑÈóÆÈ¢òÔºöRLËÉΩÂê¶Á±ª‰ººÂú∞ÊîπÂñÑVLAÁöÑÈïøÊúüÈÄêÊ≠•Âä®‰ΩúËßÑÂàíÔºüÊú¨ÊñáÊèêÂá∫‰∫ÜSimpleVLA-RLÔºåËøôÊòØ‰∏Ä‰∏™‰∏∫VLAÊ®°ÂûãÈáèË∫´ÂÆöÂà∂ÁöÑÈ´òÊïàRLÊ°ÜÊû∂„ÄÇÂü∫‰∫éveRLÔºåÂºïÂÖ•‰∫ÜVLAÁâπÂÆöÁöÑËΩ®ËøπÈááÊ†∑„ÄÅÂèØÊâ©Â±ïÁöÑÂπ∂Ë°åÂåñ„ÄÅÂ§öÁéØÂ¢ÉÊ∏≤ÊüìÂíå‰ºòÂåñÁöÑÊçüÂ§±ËÆ°ÁÆó„ÄÇÂ∫îÁî®‰∫éOpenVLA-OFTÊó∂ÔºåSimpleVLA-RLÂú®LIBERO‰∏äÂÆûÁé∞‰∫ÜSoTAÊÄßËÉΩÔºåÁîöËá≥ÈÄöËøáÂºïÂÖ•ÁöÑÊé¢Á¥¢Â¢ûÂº∫Á≠ñÁï•Âú®RoboTwin 1.0Âíå2.0‰∏ä‰ºò‰∫é$œÄ_0$„ÄÇSimpleVLA-RL‰∏ç‰ªÖÂáèÂ∞ë‰∫ÜÂØπÂ§ßËßÑÊ®°Êï∞ÊçÆÁöÑ‰æùËµñÔºåÂÆûÁé∞‰∫ÜÂº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÔºåËÄå‰∏îÂú®ÂÆûÈôÖ‰ªªÂä°‰∏≠ÊòæËëóË∂ÖË∂ä‰∫ÜSFT„ÄÇÊ≠§Â§ñÔºåËøòÂèëÁé∞‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÁé∞Ë±°‚Äúpushcut‚ÄùÔºåÂç≥Á≠ñÁï•ÂèëÁé∞‰∫ÜÂÖàÂâçËÆ≠ÁªÉËøáÁ®ã‰∏≠Êú™ËßÅËøáÁöÑÊ®°Âºè„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöVLAÊ®°ÂûãÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠Èù¢‰∏¥Êï∞ÊçÆ‰æùËµñÂíåÊ≥õÂåñÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰æùËµñ‰∫éÂ§ßËßÑÊ®°‰∫∫Â∑•Ê†áÊ≥®ÁöÑÊú∫Âô®‰∫∫ËΩ®ËøπËøõË°åÁõëÁù£ÂæÆË∞ÉÔºåÊï∞ÊçÆËé∑ÂèñÊàêÊú¨È´òÊòÇÔºå‰∏îÊ®°ÂûãÈöæ‰ª•Ê≥õÂåñÂà∞Êñ∞ÁöÑÁéØÂ¢ÉÂíå‰ªªÂä°„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶Å‰∏ÄÁßçÊõ¥ÊúâÊïàÁöÑÊñπÊ≥ïÊù•ËÆ≠ÁªÉVLAÊ®°ÂûãÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ËøõË°åÈïøÊúüÂä®‰ΩúËßÑÂàíÔºåÂπ∂ÂÖ∑Â§áÊõ¥Âº∫ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Âº∫ÂåñÂ≠¶‰π†Êù•ËÆ≠ÁªÉVLAÊ®°ÂûãÔºå‰ª•ÂÖãÊúçÁõëÁù£ÂæÆË∞ÉÁöÑÂ±ÄÈôêÊÄß„ÄÇÂº∫ÂåñÂ≠¶‰π†ÂÖÅËÆ∏Ê®°ÂûãÈÄöËøá‰∏éÁéØÂ¢ÉÁöÑ‰∫§‰∫íÊù•Â≠¶‰π†ÊúÄ‰ºòÁ≠ñÁï•Ôºå‰ªéËÄåÂáèÂ∞ëÂØπÂ§ßËßÑÊ®°‰∫∫Â∑•Ê†áÊ≥®Êï∞ÊçÆÁöÑ‰æùËµñÔºåÂπ∂ÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÈÄöËøáËÆæËÆ°ÂêàÈÄÇÁöÑÂ•ñÂä±ÂáΩÊï∞ÂíåÊé¢Á¥¢Á≠ñÁï•ÔºåÂºïÂØºÊ®°ÂûãÂ≠¶‰π†Êõ¥ÊúâÊïàÁöÑÈïøÊúüÂä®‰ΩúËßÑÂàí„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSimpleVLA-RLÊ°ÜÊû∂Âü∫‰∫éveRLÔºåÂπ∂ÈíàÂØπVLAÊ®°ÂûãËøõË°å‰∫Ü‰ºòÂåñ„ÄÇ‰∏ªË¶ÅÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) VLAÁâπÂÆöÁöÑËΩ®ËøπÈááÊ†∑ÔºöÊ†πÊçÆVLAÊ®°ÂûãÁöÑÁâπÁÇπÔºåËÆæËÆ°È´òÊïàÁöÑËΩ®ËøπÈááÊ†∑ÊñπÊ≥ïÔºå‰ª•ÊèêÈ´òÂ≠¶‰π†ÊïàÁéá„ÄÇ2) ÂèØÊâ©Â±ïÁöÑÂπ∂Ë°åÂåñÔºöÂà©Áî®Âπ∂Ë°åËÆ°ÁÆóËµÑÊ∫êÔºåÂä†ÈÄüÂº∫ÂåñÂ≠¶‰π†ÁöÑËÆ≠ÁªÉËøáÁ®ã„ÄÇ3) Â§öÁéØÂ¢ÉÊ∏≤ÊüìÔºöÂú®Â§ö‰∏™‰∏çÂêåÁöÑÁéØÂ¢É‰∏≠ËøõË°åËÆ≠ÁªÉÔºå‰ª•ÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ4) ‰ºòÂåñÁöÑÊçüÂ§±ËÆ°ÁÆóÔºöËÆæËÆ°ÂêàÈÄÇÁöÑÊçüÂ§±ÂáΩÊï∞Ôºå‰ª•ÂºïÂØºÊ®°ÂûãÂ≠¶‰π†ÊúÄ‰ºòÁ≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSimpleVLA-RLÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÂº∫ÂåñÂ≠¶‰π†Â∫îÁî®‰∫éVLAÊ®°ÂûãÁöÑËÆ≠ÁªÉÔºåÂπ∂ÈíàÂØπVLAÊ®°ÂûãÁöÑÁâπÁÇπËøõË°å‰∫Ü‰ºòÂåñ„ÄÇÈÄöËøáVLAÁâπÂÆöÁöÑËΩ®ËøπÈááÊ†∑„ÄÅÂèØÊâ©Â±ïÁöÑÂπ∂Ë°åÂåñ„ÄÅÂ§öÁéØÂ¢ÉÊ∏≤ÊüìÂíå‰ºòÂåñÁöÑÊçüÂ§±ËÆ°ÁÆóÔºåÊòæËëóÊèêÈ´ò‰∫ÜVLAÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåËøòÂèëÁé∞‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÁé∞Ë±°‚Äúpushcut‚ÄùÔºåÂç≥Á≠ñÁï•ÂèëÁé∞‰∫ÜÂÖàÂâçËÆ≠ÁªÉËøáÁ®ã‰∏≠Êú™ËßÅËøáÁöÑÊ®°ÂºèÔºåË°®ÊòéÂº∫ÂåñÂ≠¶‰π†ÂèØ‰ª•Â∏ÆÂä©Ê®°ÂûãÂèëÁé∞Êñ∞ÁöÑÁ≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰∏≠ÂÖ≥ÈîÆÁöÑËÆæËÆ°ÂåÖÊã¨Ôºö1) Â•ñÂä±ÂáΩÊï∞ÁöÑËÆæËÆ°ÔºöËÆæËÆ°ÂêàÈÄÇÁöÑÂ•ñÂä±ÂáΩÊï∞Ôºå‰ª•ÂºïÂØºÊ®°ÂûãÂ≠¶‰π†ÊúüÊúõÁöÑÂä®‰ΩúÂ∫èÂàó„ÄÇ2) Êé¢Á¥¢Á≠ñÁï•ÁöÑËÆæËÆ°ÔºöÈááÁî®ÂêàÈÄÇÁöÑÊé¢Á¥¢Á≠ñÁï•Ôºå‰ª•ÈºìÂä±Ê®°ÂûãÊé¢Á¥¢Êñ∞ÁöÑÂä®‰ΩúÁ©∫Èó¥„ÄÇ3) VLAÁâπÂÆöÁöÑËΩ®ËøπÈááÊ†∑ÊñπÊ≥ïÔºöÊ†πÊçÆVLAÊ®°ÂûãÁöÑÁâπÁÇπÔºåËÆæËÆ°È´òÊïàÁöÑËΩ®ËøπÈááÊ†∑ÊñπÊ≥ïÔºå‰æãÂ¶ÇÔºå‰ºòÂÖàÈááÊ†∑ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑËΩ®Ëøπ„ÄÇ4) Âπ∂Ë°åÂåñÁ≠ñÁï•ÔºöÈááÁî®Êï∞ÊçÆÂπ∂Ë°åÂíåÊ®°ÂûãÂπ∂Ë°åÁ≠âÊäÄÊúØÔºåÂä†ÈÄüÂº∫ÂåñÂ≠¶‰π†ÁöÑËÆ≠ÁªÉËøáÁ®ã„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SimpleVLA-RLÂú®LIBERO‰∏äÂÆûÁé∞‰∫ÜSoTAÊÄßËÉΩÔºåÂπ∂Âú®RoboTwin 1.0Âíå2.0‰∏ä‰ºò‰∫é$œÄ_0$ÔºåËØÅÊòé‰∫ÜÂº∫ÂåñÂ≠¶‰π†Âú®VLAÊ®°ÂûãËÆ≠ÁªÉ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèëÁé∞‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÁé∞Ë±°‚Äúpushcut‚ÄùÔºåÂç≥Á≠ñÁï•ÂèëÁé∞‰∫ÜÂÖàÂâçËÆ≠ÁªÉËøáÁ®ã‰∏≠Êú™ËßÅËøáÁöÑÊ®°ÂºèÔºåË°®ÊòéÂº∫ÂåñÂ≠¶‰π†ÂèØ‰ª•Â∏ÆÂä©Ê®°ÂûãÂèëÁé∞Êñ∞ÁöÑÁ≠ñÁï•„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SimpleVLA-RLÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÂ∫îÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°ÔºåÂ¶ÇÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öÊú∫Âô®‰∫∫„ÄÅÂåªÁñóÊú∫Âô®‰∫∫Á≠â„ÄÇËØ•Á†îÁ©∂ÂèØ‰ª•Èôç‰ΩéÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°ÂØπÂ§ßËßÑÊ®°‰∫∫Â∑•Ê†áÊ≥®Êï∞ÊçÆÁöÑ‰æùËµñÔºåÊèêÈ´òÊú∫Âô®‰∫∫ÁöÑËá™‰∏ªÊÄßÂíåÊ≥õÂåñËÉΩÂäõÔºå‰ªéËÄåÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÁöÑÂèëÂ±ïÂíåÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-Language-Action (VLA) models have recently emerged as a powerful paradigm for robotic manipulation. Despite substantial progress enabled by large-scale pretraining and supervised fine-tuning (SFT), these models face two fundamental challenges: (i) the scarcity and high cost of large-scale human-operated robotic trajectories required for SFT scaling, and (ii) limited generalization to tasks involving distribution shift. Recent breakthroughs in Large Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can dramatically enhance step-by-step reasoning capabilities, raising a natural question: Can RL similarly improve the long-horizon step-by-step action planning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL framework tailored for VLA models. Building upon veRL, we introduce VLA-specific trajectory sampling, scalable parallelization, multi-environment rendering, and optimized loss computation. When applied to OpenVLA-OFT, SimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $œÄ_0$ on RoboTwin 1.0\&2.0 with the exploration-enhancing strategies we introduce. SimpleVLA-RL not only reduces dependence on large-scale data and enables robust generalization, but also remarkably surpasses SFT in real-world tasks. Moreover, we identify a novel phenomenon ``pushcut'' during RL training, wherein the policy discovers previously unseen patterns beyond those seen in the previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL

