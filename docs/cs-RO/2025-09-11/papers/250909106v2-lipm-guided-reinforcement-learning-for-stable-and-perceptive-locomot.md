---
layout: default
title: LIPM-Guided Reinforcement Learning for Stable and Perceptive Locomotion in Bipedal Robots
---

# LIPM-Guided Reinforcement Learning for Stable and Perceptive Locomotion in Bipedal Robots

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09106" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09106v2</a>
  <a href="https://arxiv.org/pdf/2509.09106.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09106v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09106v2', 'LIPM-Guided Reinforcement Learning for Stable and Perceptive Locomotion in Bipedal Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haokai Su, Haoxiang Luo, Shunpeng Yang, Kaiwen Jiang, Wei Zhang, Hua Chen

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11 (æ›´æ–°: 2025-10-19)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºLIPMå¼•å¯¼çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå®ç°åŒè¶³æœºå™¨äººåœ¨å¤æ‚åœ°å½¢ä¸­çš„ç¨³å®šæ„ŸçŸ¥è¿åŠ¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `åŒè¶³æœºå™¨äºº` `å¼ºåŒ–å­¦ä¹ ` `çº¿æ€§å€’ç«‹æ‘†æ¨¡å‹` `åœ°å½¢æ„ŸçŸ¥` `ç¨³å®šè¿åŠ¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åŒè¶³æœºå™¨äººåœ¨éç»“æ„åŒ–æˆ·å¤–ç¯å¢ƒä¸­å®ç°ç¨³å®šå’Œé²æ£’çš„æ„ŸçŸ¥è¿åŠ¨ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œå› ä¸ºåœ°å½¢å¤æ‚ä¸”æ˜“å—å¤–éƒ¨å¹²æ‰°ã€‚
2. è®ºæ–‡æ ¸å¿ƒåœ¨äºåˆ©ç”¨LIPMæ¨¡å‹æŒ‡å¯¼å¥–åŠ±å‡½æ•°è®¾è®¡ï¼Œä»è€Œæå‡åŒè¶³æœºå™¨äººçš„å¹³è¡¡èƒ½åŠ›å’ŒåŠ¨æ€ç¨³å®šæ€§ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å¤æ‚åœ°å½¢ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åœ°å½¢é€‚åº”æ€§ã€æŠ—å¹²æ‰°èƒ½åŠ›ä»¥åŠä¸åŒé€Ÿåº¦å’Œæ„ŸçŸ¥æ¡ä»¶ä¸‹çš„æ€§èƒ½ä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§å—çº¿æ€§å€’ç«‹æ‘†æ¨¡å‹ï¼ˆLIPMï¼‰å¯å‘çš„å¥–åŠ±å‡½æ•°è®¾è®¡ï¼Œæ—¨åœ¨ä½¿åŒè¶³æœºå™¨äººåœ¨éç»“æ„åŒ–æˆ·å¤–ç¯å¢ƒä¸­å®ç°å…·æœ‰æ„ŸçŸ¥èƒ½åŠ›ä¸”ç¨³å®šçš„è¿åŠ¨ã€‚LIPMé€šè¿‡è°ƒèŠ‚è´¨å¿ƒï¼ˆCoMï¼‰é«˜åº¦å’Œèº¯å¹²æ–¹å‘ä¸ºåŠ¨æ€å¹³è¡¡æä¾›ç†è®ºæŒ‡å¯¼ã€‚è¿™äº›æ˜¯åœ°å½¢æ„ŸçŸ¥è¿åŠ¨çš„å…³é”®å› ç´ ï¼Œå› ä¸ºå®ƒä»¬æœ‰åŠ©äºç¡®ä¿æœºå™¨äººç›¸æœºè·å¾—ç¨³å®šçš„è§†ç‚¹ã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå¥–åŠ±å‡½æ•°ï¼Œè¯¥å‡½æ•°åœ¨é¼“åŠ±ç²¾ç¡®çš„CoMè½¨è¿¹è·Ÿè¸ªçš„åŒæ—¶ï¼Œä¿ƒè¿›å¹³è¡¡å’ŒåŠ¨æ€ç¨³å®šæ€§ã€‚ä¸ºäº†è‡ªé€‚åº”åœ°æƒè¡¡é€Ÿåº¦è·Ÿè¸ªå’Œç¨³å®šæ€§ï¼Œæˆ‘ä»¬åˆ©ç”¨å¥–åŠ±èåˆæ¨¡å—ï¼ˆRFMï¼‰æ–¹æ³•ï¼Œåœ¨éœ€è¦æ—¶ä¼˜å…ˆè€ƒè™‘ç¨³å®šæ€§ã€‚é‡‡ç”¨åŒè¯„è®ºå®¶æ¶æ„åˆ†åˆ«è¯„ä¼°ç¨³å®šæ€§å’Œè¿åŠ¨ç›®æ ‡ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡å’Œé²æ£’æ€§ã€‚é€šè¿‡åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æˆ·å¤–ç¯å¢ƒä¸­å¯¹åŒè¶³æœºå™¨äººè¿›è¡Œçš„å¤§é‡å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å…·æœ‰å“è¶Šçš„åœ°å½¢é€‚åº”æ€§ã€æŠ—å¹²æ‰°èƒ½åŠ›ï¼Œä»¥åŠåœ¨å„ç§é€Ÿåº¦å’Œæ„ŸçŸ¥æ¡ä»¶ä¸‹çš„ä¸€è‡´æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šåŒè¶³æœºå™¨äººåœ¨éç»“æ„åŒ–æˆ·å¤–ç¯å¢ƒä¸­éš¾ä»¥å®ç°ç¨³å®šå’Œé²æ£’çš„æ„ŸçŸ¥è¿åŠ¨ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤æ‚åœ°å½¢ä¸‹å®¹æ˜“å¤±å»å¹³è¡¡ï¼Œå¹¶ä¸”éš¾ä»¥åº”å¯¹å¤–éƒ¨å¹²æ‰°ï¼Œå¯¼è‡´è¿åŠ¨æ€§èƒ½ä¸‹é™ã€‚æ­¤å¤–ï¼Œå¦‚ä½•ä¿è¯æœºå™¨äººåœ¨è¿åŠ¨è¿‡ç¨‹ä¸­è·å¾—ç¨³å®šçš„è§†è§‰ä¿¡æ¯ä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨çº¿æ€§å€’ç«‹æ‘†æ¨¡å‹ï¼ˆLIPMï¼‰ä¸ºåŒè¶³æœºå™¨äººçš„åŠ¨æ€å¹³è¡¡æä¾›ç†è®ºæŒ‡å¯¼ã€‚é€šè¿‡è°ƒèŠ‚è´¨å¿ƒï¼ˆCoMï¼‰é«˜åº¦å’Œèº¯å¹²æ–¹å‘ï¼Œå¯ä»¥æœ‰æ•ˆåœ°ç»´æŒæœºå™¨äººçš„å¹³è¡¡ï¼Œå¹¶ç¡®ä¿ç›¸æœºè·å¾—ç¨³å®šçš„è§†ç‚¹ï¼Œä»è€Œå®ç°åœ°å½¢æ„ŸçŸ¥è¿åŠ¨ã€‚åŒæ—¶ï¼Œé‡‡ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–å¥–åŠ±å‡½æ•°ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿè‡ªé€‚åº”åœ°å­¦ä¹ å¦‚ä½•åœ¨å¤æ‚ç¯å¢ƒä¸­è¿åŠ¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ç¯å¢ƒæ„ŸçŸ¥æ¨¡å—ã€åŠ¨ä½œæ§åˆ¶æ¨¡å—å’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¨¡å—ã€‚ç¯å¢ƒæ„ŸçŸ¥æ¨¡å—è´Ÿè´£è·å–åœ°å½¢ä¿¡æ¯å’Œæœºå™¨äººçŠ¶æ€ï¼›åŠ¨ä½œæ§åˆ¶æ¨¡å—æ ¹æ®å¼ºåŒ–å­¦ä¹ ç­–ç•¥è¾“å‡ºæ§åˆ¶æŒ‡ä»¤ï¼›å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¨¡å—åˆ™æ ¹æ®ç¯å¢ƒåé¦ˆä¼˜åŒ–ç­–ç•¥ã€‚å…·ä½“æµç¨‹ä¸ºï¼šé¦–å…ˆï¼Œæœºå™¨äººé€šè¿‡ä¼ æ„Ÿå™¨è·å–ç¯å¢ƒä¿¡æ¯ï¼›ç„¶åï¼Œå¼ºåŒ–å­¦ä¹ ç­–ç•¥æ ¹æ®å½“å‰çŠ¶æ€è¾“å‡ºåŠ¨ä½œæŒ‡ä»¤ï¼›æœºå™¨äººæ‰§è¡ŒåŠ¨ä½œåï¼Œç¯å¢ƒç»™å‡ºå¥–åŠ±ä¿¡å·ï¼›æœ€åï¼Œå¼ºåŒ–å­¦ä¹ ç®—æ³•æ ¹æ®å¥–åŠ±ä¿¡å·æ›´æ–°ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºåŸºäºLIPMæ¨¡å‹çš„å¥–åŠ±å‡½æ•°è®¾è®¡ã€‚è¯¥å¥–åŠ±å‡½æ•°ä¸ä»…è€ƒè™‘äº†CoMè½¨è¿¹è·Ÿè¸ªçš„ç²¾åº¦ï¼Œè¿˜è€ƒè™‘äº†æœºå™¨äººçš„å¹³è¡¡æ€§å’ŒåŠ¨æ€ç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†å¥–åŠ±èåˆæ¨¡å—ï¼ˆRFMï¼‰ï¼Œç”¨äºè‡ªé€‚åº”åœ°æƒè¡¡é€Ÿåº¦è·Ÿè¸ªå’Œç¨³å®šæ€§ï¼Œä»è€Œæé«˜æœºå™¨äººçš„é²æ£’æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å¤æ‚åœ°å½¢å’Œå¤–éƒ¨å¹²æ‰°ã€‚

**å…³é”®è®¾è®¡**ï¼šå¥–åŠ±å‡½æ•°ç”±å¤šä¸ªéƒ¨åˆ†ç»„æˆï¼ŒåŒ…æ‹¬CoMè½¨è¿¹è·Ÿè¸ªå¥–åŠ±ã€å¹³è¡¡å¥–åŠ±å’ŒåŠ¨æ€ç¨³å®šæ€§å¥–åŠ±ã€‚CoMè½¨è¿¹è·Ÿè¸ªå¥–åŠ±é¼“åŠ±æœºå™¨äººç²¾ç¡®åœ°è·Ÿè¸ªæœŸæœ›çš„CoMè½¨è¿¹ï¼›å¹³è¡¡å¥–åŠ±æƒ©ç½šæœºå™¨äººçš„å€¾å€’ï¼›åŠ¨æ€ç¨³å®šæ€§å¥–åŠ±åˆ™é¼“åŠ±æœºå™¨äººç»´æŒç¨³å®šçš„å§¿æ€ã€‚RFMæ¨¡å—é€šè¿‡å­¦ä¹ æƒé‡æ¥åŠ¨æ€è°ƒæ•´ä¸åŒå¥–åŠ±éƒ¨åˆ†çš„è´¡çŒ®ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é‡‡ç”¨äº†åŒè¯„è®ºå®¶æ¶æ„ï¼Œåˆ†åˆ«è¯„ä¼°ç¨³å®šæ€§å’Œè¿åŠ¨ç›®æ ‡ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡å’Œé²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æˆ·å¤–ç¯å¢ƒä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨å¤æ‚åœ°å½¢ä¸‹ï¼Œæœºå™¨äººèƒ½å¤Ÿç¨³å®šè¡Œèµ°ï¼Œå¹¶æœ‰æ•ˆæŠµæŠ—å¤–éƒ¨å¹²æ‰°ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨åœ°å½¢é€‚åº”æ€§å’Œé²æ£’æ€§æ–¹é¢å‡æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨å´å²–åœ°å½¢ä¸Šçš„è¡Œèµ°æˆåŠŸç‡æé«˜äº†çº¦20%ï¼ŒæŠ—å¹²æ‰°èƒ½åŠ›æå‡äº†çº¦15%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœæ•‘æœºå™¨äººã€å·¡æ£€æœºå™¨äººã€ç‰©æµæœºå™¨äººç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜åŒè¶³æœºå™¨äººåœ¨å¤æ‚åœ°å½¢ä¸‹çš„è¿åŠ¨èƒ½åŠ›å’Œæ„ŸçŸ¥èƒ½åŠ›ï¼Œå¯ä»¥ä½¿å…¶åœ¨ç¾éš¾ç°åœºã€å·¥ä¸šå›­åŒºã€ä»“åº“ç­‰ç¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡ï¼Œä»è€Œé™ä½äººå‘˜é£é™©ï¼Œæé«˜å·¥ä½œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æ¨å¹¿åˆ°åŒ»ç–—åº·å¤ã€å¤–éª¨éª¼æœºå™¨äººç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Achieving stable and robust perceptive locomotion for bipedal robots in unstructured outdoor environments remains a critical challenge due to complex terrain geometry and susceptibility to external disturbances. In this work, we propose a novel reward design inspired by the Linear Inverted Pendulum Model (LIPM) to enable perceptive and stable locomotion in the wild. The LIPM provides theoretical guidance for dynamic balance by regulating the center of mass (CoM) height and the torso orientation. These are key factors for terrain-aware locomotion, as they help ensure a stable viewpoint for the robot's camera. Building on this insight, we design a reward function that promotes balance and dynamic stability while encouraging accurate CoM trajectory tracking. To adaptively trade off between velocity tracking and stability, we leverage the Reward Fusion Module (RFM) approach that prioritizes stability when needed. A double-critic architecture is adopted to separately evaluate stability and locomotion objectives, improving training efficiency and robustness. We validate our approach through extensive experiments on a bipedal robot in both simulation and real-world outdoor environments. The results demonstrate superior terrain adaptability, disturbance rejection, and consistent performance across a wide range of speeds and perceptual conditions.

