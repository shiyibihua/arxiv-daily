---
layout: default
title: X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations
---

# X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations

**arXiv**: [2511.04671v1](https://arxiv.org/abs/2511.04671) | [PDF](https://arxiv.org/pdf/2511.04671.pdf)

**ä½œè€…**: Maximus A. Pace, Prithwish Dan, Chuanruo Ning, Atiksh Bhardwaj, Audrey Du, Edward W. Duan, Wei-Chiu Ma, Kushal Kedia

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-06

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://portal-cornell.github.io/X-Diffusion/)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**X-Diffusionï¼šåˆ©ç”¨è·¨å…·èº«äººç±»æ¼”ç¤ºè®­ç»ƒæ‰©æ•£ç­–ç•¥ï¼Œæå‡æœºå™¨äººæ“ä½œæ€§èƒ½**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹` `æœºå™¨äººå­¦ä¹ ` `æ¨¡ä»¿å­¦ä¹ ` `è·¨å…·èº«` `äººç±»æ¼”ç¤º` `ç­–ç•¥è®­ç»ƒ` `å…·èº«å·®å¼‚`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ç›´æŽ¥åˆ©ç”¨äººç±»æ¼”ç¤ºæ•°æ®è®­ç»ƒæœºå™¨äººç­–ç•¥ï¼Œå¿½ç•¥äº†äººç±»ä¸Žæœºå™¨äººåœ¨å…·èº«æ–¹é¢çš„å·®å¼‚ï¼Œå¯¼è‡´ç­–ç•¥æ€§èƒ½ä¸‹é™ã€‚
2. X-Diffusionçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹ï¼Œé€šè¿‡å‘åŠ¨ä½œæ·»åŠ å™ªå£°æ¥æ¶ˆé™¤ä½Žå±‚æ¬¡çš„æ‰§è¡Œå·®å¼‚ï¼Œä¿ç•™é«˜å±‚æ¬¡çš„ä»»åŠ¡æŒ‡å¯¼ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒX-Diffusionåœ¨äº”ä¸ªæ“ä½œä»»åŠ¡ä¸­ï¼Œç›¸æ¯”æœ€ä½³åŸºçº¿ï¼Œå¹³å‡æˆåŠŸçŽ‡æé«˜äº†16%ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»è§†é¢‘å¯ä»¥å¿«é€Ÿä¸”å¤§è§„æ¨¡åœ°è®°å½•ï¼Œä½¿å…¶æˆä¸ºæœºå™¨äººå­¦ä¹ ä¸­æžå…·å¸å¼•åŠ›çš„è®­ç»ƒæ•°æ®æ¥æºã€‚ç„¶è€Œï¼Œäººç±»å’Œæœºå™¨äººåœ¨å…·èº«æ–¹é¢å­˜åœ¨æ ¹æœ¬å·®å¼‚ï¼Œå¯¼è‡´åŠ¨ä½œæ‰§è¡Œä¸åŒ¹é…ã€‚ç›´æŽ¥å¯¹äººç±»æ‰‹éƒ¨è¿åŠ¨è¿›è¡Œè¿åŠ¨å­¦é‡å®šå‘å¯èƒ½ä¼šäº§ç”Ÿæœºå™¨äººæ— æ³•å®žé™…æ‰§è¡Œçš„åŠ¨ä½œã€‚å°½ç®¡å­˜åœ¨è¿™äº›ä½Žå±‚æ¬¡çš„å·®å¼‚ï¼Œäººç±»æ¼”ç¤ºä»ç„¶æä¾›äº†å…³äºŽå¦‚ä½•æ“ä½œå’Œä¸Žç‰©ä½“äº¤äº’çš„æœ‰ä»·å€¼çš„è¿åŠ¨çº¿ç´¢ã€‚æˆ‘ä»¬çš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨å‰å‘æ‰©æ•£è¿‡ç¨‹ï¼šéšç€å™ªå£°è¢«æ·»åŠ åˆ°åŠ¨ä½œä¸­ï¼Œä½Žå±‚æ¬¡çš„æ‰§è¡Œå·®å¼‚ä¼šé€æ¸æ¶ˆå¤±ï¼Œè€Œé«˜å±‚æ¬¡çš„ä»»åŠ¡æŒ‡å¯¼å¾—ä»¥ä¿ç•™ã€‚æˆ‘ä»¬æå‡ºäº†X-Diffusionï¼Œä¸€ä¸ªç”¨äºŽè®­ç»ƒæ‰©æ•£ç­–ç•¥çš„åŽŸåˆ™æ€§æ¡†æž¶ï¼Œå®ƒæœ€å¤§é™åº¦åœ°åˆ©ç”¨äººç±»æ•°æ®ï¼ŒåŒæ—¶é¿å…å­¦ä¹ åŠ¨æ€ä¸Šä¸å¯è¡Œçš„è¿åŠ¨ã€‚X-Diffusioné¦–å…ˆè®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨æ¥é¢„æµ‹å™ªå£°åŠ¨ä½œæ˜¯ç”±äººç±»è¿˜æ˜¯æœºå™¨äººæ‰§è¡Œçš„ã€‚ç„¶åŽï¼Œåªæœ‰åœ¨æ·»åŠ äº†è¶³å¤Ÿçš„å™ªå£°ï¼Œä½¿å¾—åˆ†ç±»å™¨æ— æ³•åŒºåˆ†å…¶å…·èº«æ—¶ï¼Œäººç±»åŠ¨ä½œæ‰ä¼šè¢«çº³å…¥ç­–ç•¥è®­ç»ƒä¸­ã€‚ä¸Žæœºå™¨äººæ‰§è¡Œä¸€è‡´çš„åŠ¨ä½œåœ¨é«˜å™ªå£°æ°´å¹³ä¸‹ç›‘ç£ç»†ç²’åº¦çš„åŽ»å™ªï¼Œè€Œä¸åŒ¹é…çš„äººç±»åŠ¨ä½œä»…åœ¨é«˜å™ªå£°æ°´å¹³ä¸‹æä¾›ç²—ç•¥çš„æŒ‡å¯¼ã€‚æˆ‘ä»¬çš„å®žéªŒè¡¨æ˜Žï¼Œåœ¨æ‰§è¡Œä¸åŒ¹é…çš„æƒ…å†µä¸‹è¿›è¡Œæœ´ç´ çš„å…±åŒè®­ç»ƒä¼šé™ä½Žç­–ç•¥æ€§èƒ½ï¼Œè€ŒX-Diffusionå§‹ç»ˆå¯ä»¥æé«˜ç­–ç•¥æ€§èƒ½ã€‚åœ¨äº”ä¸ªæ“ä½œä»»åŠ¡ä¸­ï¼ŒX-Diffusionçš„å¹³å‡æˆåŠŸçŽ‡æ¯”æœ€ä½³åŸºçº¿é«˜16%ã€‚é¡¹ç›®ç½‘ç«™ä½äºŽhttps://portal-cornell.github.io/X-Diffusion/ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•æœ‰æ•ˆåœ°åˆ©ç”¨äººç±»æ¼”ç¤ºæ•°æ®æ¥è®­ç»ƒæœºå™¨äººç­–ç•¥çš„é—®é¢˜ã€‚ç›´æŽ¥ä½¿ç”¨äººç±»æ¼”ç¤ºæ•°æ®è¿›è¡Œè®­ç»ƒä¼šå¯¼è‡´æœºå™¨äººå­¦ä¹ åˆ°æ— æ³•æ‰§è¡Œçš„åŠ¨ä½œï¼Œå› ä¸ºäººç±»å’Œæœºå™¨äººåœ¨å…·èº«æ–¹é¢å­˜åœ¨å·®å¼‚ï¼Œä¾‹å¦‚è¿åŠ¨èŒƒå›´ã€å…³èŠ‚ç»“æž„ç­‰ã€‚çŽ°æœ‰çš„æ–¹æ³•é€šå¸¸å¿½ç•¥è¿™äº›å·®å¼‚ï¼Œå¯¼è‡´è®­ç»ƒå‡ºçš„ç­–ç•¥æ€§èƒ½ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ‰©æ•£æ¨¡åž‹ï¼Œé€šè¿‡é€æ­¥å‘åŠ¨ä½œæ·»åŠ å™ªå£°ï¼Œæ¥æ¶ˆé™¤äººç±»å’Œæœºå™¨äººåœ¨ä½Žå±‚æ¬¡æ‰§è¡Œä¸Šçš„å·®å¼‚ï¼ŒåŒæ—¶ä¿ç•™é«˜å±‚æ¬¡çš„ä»»åŠ¡æŒ‡å¯¼ä¿¡æ¯ã€‚éšç€å™ªå£°çš„å¢žåŠ ï¼ŒåŠ¨ä½œçš„ç²¾ç»†æ‰§è¡Œç»†èŠ‚é€æ¸æ¨¡ç³Šï¼Œè€ŒåŠ¨ä½œçš„ç›®çš„å’Œç­–ç•¥åˆ™å¾—ä»¥ä¿ç•™ã€‚è¿™æ ·ï¼Œæœºå™¨äººå°±å¯ä»¥ä»Žäººç±»æ¼”ç¤ºä¸­å­¦ä¹ åˆ°æœ‰ç”¨çš„ç­–ç•¥ï¼Œè€Œä¸ä¼šå—åˆ°å…·èº«å·®å¼‚çš„å¹²æ‰°ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šX-Diffusionçš„æ•´ä½“æ¡†æž¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) æ•°æ®æ”¶é›†ï¼šæ”¶é›†äººç±»æ¼”ç¤ºæ•°æ®å’Œæœºå™¨äººæ¼”ç¤ºæ•°æ®ã€‚2) å™ªå£°æ·»åŠ ï¼šä½¿ç”¨æ‰©æ•£æ¨¡åž‹ï¼Œé€æ­¥å‘åŠ¨ä½œæ·»åŠ å™ªå£°ï¼Œç”Ÿæˆä¸åŒå™ªå£°æ°´å¹³çš„åŠ¨ä½œã€‚3) å…·èº«åˆ†ç±»å™¨è®­ç»ƒï¼šè®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ï¼Œç”¨äºŽåŒºåˆ†å™ªå£°åŠ¨ä½œæ˜¯ç”±äººç±»è¿˜æ˜¯æœºå™¨äººæ‰§è¡Œçš„ã€‚4) ç­–ç•¥è®­ç»ƒï¼šä½¿ç”¨æ‰©æ•£æ¨¡åž‹è¿›è¡Œç­–ç•¥è®­ç»ƒï¼Œæ ¹æ®å™ªå£°æ°´å¹³å’Œå…·èº«åˆ†ç±»å™¨çš„ç»“æžœï¼Œé€‰æ‹©æ€§åœ°åˆ©ç”¨äººç±»å’Œæœºå™¨äººæ•°æ®ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨é«˜å™ªå£°æ°´å¹³ä¸‹ï¼Œäººç±»æ•°æ®æä¾›ç²—ç•¥çš„æŒ‡å¯¼ï¼›åœ¨ä½Žå™ªå£°æ°´å¹³ä¸‹ï¼Œæœºå™¨äººæ•°æ®æä¾›ç»†ç²’åº¦çš„ç›‘ç£ã€‚

**å…³é”®åˆ›æ–°**ï¼šX-Diffusionçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶åˆ©ç”¨æ‰©æ•£æ¨¡åž‹æ¥æ¡¥æŽ¥äººç±»å’Œæœºå™¨äººåœ¨å…·èº«æ–¹é¢çš„å·®å¼‚ã€‚é€šè¿‡æŽ§åˆ¶å™ªå£°æ°´å¹³ï¼Œå¯ä»¥çµæ´»åœ°åˆ©ç”¨äººç±»æ•°æ®ä¸­çš„é«˜å±‚æ¬¡ç­–ç•¥ä¿¡æ¯ï¼ŒåŒæ—¶é¿å…å­¦ä¹ åˆ°æ— æ³•æ‰§è¡Œçš„ä½Žå±‚æ¬¡åŠ¨ä½œã€‚æ­¤å¤–ï¼Œå…·èº«åˆ†ç±»å™¨çš„å¼•å…¥ä½¿å¾—å¯ä»¥æ ¹æ®åŠ¨ä½œçš„å™ªå£°æ°´å¹³å’Œå…·èº«ç±»åž‹ï¼Œè‡ªé€‚åº”åœ°è°ƒæ•´è®­ç»ƒç­–ç•¥ã€‚

**å…³é”®è®¾è®¡**ï¼šX-Diffusionçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ‰©æ•£æ¨¡åž‹çš„é€‰æ‹©ï¼šè®ºæ–‡ä½¿ç”¨äº†æ ‡å‡†çš„æ‰©æ•£æ¨¡åž‹ï¼Œä¾‹å¦‚DDPMã€‚2) å™ªå£°è°ƒåº¦ï¼šè®ºæ–‡ä½¿ç”¨äº†çº¿æ€§å™ªå£°è°ƒåº¦ï¼ŒæŽ§åˆ¶å™ªå£°æ·»åŠ çš„é€Ÿåº¦ã€‚3) å…·èº«åˆ†ç±»å™¨çš„ç½‘ç»œç»“æž„ï¼šè®ºæ–‡ä½¿ç”¨äº†ç®€å•çš„MLPç½‘ç»œä½œä¸ºå…·èº«åˆ†ç±»å™¨ã€‚4) æŸå¤±å‡½æ•°ï¼šè®ºæ–‡ä½¿ç”¨äº†æ··åˆæŸå¤±å‡½æ•°ï¼ŒåŒ…æ‹¬é‡æž„æŸå¤±ã€åˆ†ç±»æŸå¤±å’Œç­–ç•¥æŸå¤±ã€‚ç­–ç•¥æŸå¤±æ ¹æ®å™ªå£°æ°´å¹³å’Œå…·èº«åˆ†ç±»å™¨çš„ç»“æžœè¿›è¡ŒåŠ æƒï¼Œä»¥å®žçŽ°é€‰æ‹©æ€§åœ°åˆ©ç”¨äººç±»å’Œæœºå™¨äººæ•°æ®ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

X-Diffusionåœ¨äº”ä¸ªæœºå™¨äººæ“ä½œä»»åŠ¡ä¸­è¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬å¼€æŠ½å±‰ã€å…³æŠ½å±‰ã€æ”¾ç½®ç‰©ä½“ç­‰ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒX-Diffusionçš„å¹³å‡æˆåŠŸçŽ‡æ¯”æœ€ä½³åŸºçº¿é«˜16%ã€‚æ­¤å¤–ï¼Œå®žéªŒè¿˜éªŒè¯äº†æœ´ç´ çš„å…±åŒè®­ç»ƒä¼šå¯¼è‡´ç­–ç•¥æ€§èƒ½ä¸‹é™ï¼Œè€ŒX-Diffusionå¯ä»¥æœ‰æ•ˆåœ°è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

X-Diffusionå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ä»¥åº”ç”¨äºŽå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚ç‰©ä½“æŠ“å–ã€è£…é…ã€å¯¼èˆªç­‰ã€‚é€šè¿‡åˆ©ç”¨å¤§é‡çš„äººç±»æ¼”ç¤ºæ•°æ®ï¼Œå¯ä»¥æ˜¾è‘—é™ä½Žæœºå™¨äººå­¦ä¹ çš„æˆæœ¬ï¼Œæé«˜æœºå™¨äººçš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºŽè™šæ‹ŸçŽ°å®žã€å¢žå¼ºçŽ°å®žç­‰é¢†åŸŸï¼Œå®žçŽ°äººæœºåä½œå’Œè¿œç¨‹æŽ§åˆ¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Human videos can be recorded quickly and at scale, making them an appealing source of training data for robot learning. However, humans and robots differ fundamentally in embodiment, resulting in mismatched action execution. Direct kinematic retargeting of human hand motion can therefore produce actions that are physically infeasible for robots. Despite these low-level differences, human demonstrations provide valuable motion cues about how to manipulate and interact with objects. Our key idea is to exploit the forward diffusion process: as noise is added to actions, low-level execution differences fade while high-level task guidance is preserved. We present X-Diffusion, a principled framework for training diffusion policies that maximally leverages human data without learning dynamically infeasible motions. X-Diffusion first trains a classifier to predict whether a noisy action is executed by a human or robot. Then, a human action is incorporated into policy training only after adding sufficient noise such that the classifier cannot discern its embodiment. Actions consistent with robot execution supervise fine-grained denoising at low noise levels, while mismatched human actions provide only coarse guidance at higher noise levels. Our experiments show that naive co-training under execution mismatches degrades policy performance, while X-Diffusion consistently improves it. Across five manipulation tasks, X-Diffusion achieves a 16% higher average success rate than the best baseline. The project website is available at https://portal-cornell.github.io/X-Diffusion/.

