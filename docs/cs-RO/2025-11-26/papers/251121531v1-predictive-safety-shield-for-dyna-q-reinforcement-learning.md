---
layout: default
title: Predictive Safety Shield for Dyna-Q Reinforcement Learning
---

# Predictive Safety Shield for Dyna-Q Reinforcement Learning

**arXiv**: [2511.21531v1](https://arxiv.org/abs/2511.21531) | [PDF](https://arxiv.org/pdf/2511.21531.pdf)

**ä½œè€…**: Jin Pin, Krasowski Hanna, Vanneaux Elena

**åˆ†ç±»**: cs.LG, cs.AI, cs.RO, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-11-26

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽé¢„æµ‹çš„å®‰å…¨ç›¾ï¼Œæå‡Dyna-Qå¼ºåŒ–å­¦ä¹ åœ¨ç¦»æ•£ç©ºé—´çš„å®‰å…¨æ€§å’Œæ€§èƒ½**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å®‰å…¨ç›¾` `æ¨¡åž‹é¢„æµ‹` `Dyna-Q` `å®‰å…¨æ€§` `ç¦»æ•£ç©ºé—´` `æœºå™¨äººå¯¼èˆª`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å®‰å…¨ç›¾æ–¹æ³•ä¾èµ–éšæœºæŠ½æ ·æˆ–å›ºå®šæŽ§åˆ¶å™¨ï¼Œå¿½ç•¥äº†å®‰å…¨åŠ¨ä½œå¯¹æœªæ¥æ€§èƒ½çš„å½±å“ï¼Œé™åˆ¶äº†å¼ºåŒ–å­¦ä¹ çš„åº”ç”¨ã€‚
2. æå‡ºä¸€ç§é¢„æµ‹å®‰å…¨ç›¾ï¼Œé€šè¿‡çŽ¯å¢ƒæ¨¡åž‹çš„å®‰å…¨æ¨¡æ‹Ÿè¿›è¡Œå®‰å…¨é¢„æµ‹ï¼Œå¹¶å±€éƒ¨æ›´æ–°Qå‡½æ•°ï¼Œä»Žè€Œä¼˜åŒ–å®‰å…¨åŠ¨ä½œçš„é€‰æ‹©ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨ç½‘æ ¼ä¸–ç•Œä¸­å³ä½¿ä½¿ç”¨çŸ­é¢„æµ‹èŒƒå›´ä¹Ÿèƒ½æ‰¾åˆ°æœ€ä¼˜è·¯å¾„ï¼Œä¸”å¯¹æ¨¡æ‹Ÿä¸ŽçŽ°å®žçš„åˆ†å¸ƒåç§»å…·æœ‰é²æ£’æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºå¼ºåŒ–å­¦ä¹ æä¾›å®‰å…¨ä¿éšœæ˜¯å®žçŽ°å…¶åœ¨çŽ°å®žä¸–ç•Œä»»åŠ¡ä¸­åº”ç”¨çš„å…³é”®æŒ‘æˆ˜ã€‚å®‰å…¨ç›¾æ‰©å±•äº†æ ‡å‡†å¼ºåŒ–å­¦ä¹ ï¼Œå®žçŽ°äº†ç¡¬æ€§å®‰å…¨ä¿è¯ã€‚ç„¶è€Œï¼ŒçŽ°æœ‰çš„å®‰å…¨ç›¾é€šå¸¸ä½¿ç”¨å®‰å…¨åŠ¨ä½œçš„éšæœºæŠ½æ ·æˆ–å›ºå®šçš„å›žé€€æŽ§åˆ¶å™¨ï¼Œå› æ­¤å¿½ç•¥äº†ä¸åŒå®‰å…¨åŠ¨ä½œå¯¹æœªæ¥æ€§èƒ½çš„å½±å“ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºŽç¦»æ•£ç©ºé—´ä¸­åŸºäºŽæ¨¡åž‹çš„å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“çš„é¢„æµ‹å®‰å…¨ç›¾ã€‚æˆ‘ä»¬çš„å®‰å…¨ç›¾åŸºäºŽå®‰å…¨é¢„æµ‹å±€éƒ¨æ›´æ–°Qå‡½æ•°ï¼Œè¿™äº›é¢„æµ‹æºäºŽçŽ¯å¢ƒæ¨¡åž‹çš„å®‰å…¨æ¨¡æ‹Ÿã€‚è¿™ç§å±è”½æ–¹æ³•åœ¨ä¿æŒç¡¬æ€§å®‰å…¨ä¿è¯çš„åŒæ—¶æé«˜äº†æ€§èƒ½ã€‚åœ¨ç½‘æ ¼ä¸–ç•ŒçŽ¯å¢ƒä¸­çš„å®žéªŒè¡¨æ˜Žï¼Œå³ä½¿æ˜¯çŸ­çš„é¢„æµ‹èŒƒå›´ä¹Ÿè¶³ä»¥è¯†åˆ«æœ€ä½³è·¯å¾„ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯¹åˆ†å¸ƒåç§»ï¼ˆä¾‹å¦‚ï¼Œæ¨¡æ‹Ÿå’ŒçŽ°å®žä¹‹é—´ï¼‰å…·æœ‰é²æ£’æ€§ï¼Œè€Œæ— éœ€é¢å¤–çš„è®­ç»ƒã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¼ºåŒ–å­¦ä¹ åœ¨å®žé™…åº”ç”¨ä¸­é¢ä¸´å®‰å…¨é—®é¢˜ï¼Œéœ€è¦ä¿è¯æ™ºèƒ½ä½“çš„è¡Œä¸ºå§‹ç»ˆå¤„äºŽå®‰å…¨çŠ¶æ€ã€‚çŽ°æœ‰çš„å®‰å…¨ç›¾æ–¹æ³•ï¼Œå¦‚éšæœºé‡‡æ ·å®‰å…¨åŠ¨ä½œæˆ–ä½¿ç”¨å›ºå®šå›žé€€ç­–ç•¥ï¼Œè™½ç„¶èƒ½ä¿è¯å®‰å…¨æ€§ï¼Œä½†å¾€å¾€ä¼šç‰ºç‰²æ€§èƒ½ï¼Œå› ä¸ºå®ƒä»¬æ²¡æœ‰å……åˆ†è€ƒè™‘ä¸åŒå®‰å…¨åŠ¨ä½œå¯¹æœªæ¥å›žæŠ¥çš„å½±å“ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¿è¯å®‰å…¨æ€§çš„å‰æä¸‹ï¼Œæå‡å¼ºåŒ–å­¦ä¹ çš„æ€§èƒ½æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨çŽ¯å¢ƒæ¨¡åž‹è¿›è¡Œé¢„æµ‹ï¼Œä»Žè€Œé€‰æ‹©æ›´ä¼˜çš„å®‰å…¨åŠ¨ä½œã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡å¯¹çŽ¯å¢ƒæ¨¡åž‹è¿›è¡Œå®‰å…¨æ¨¡æ‹Ÿï¼Œé¢„æµ‹ä¸åŒå®‰å…¨åŠ¨ä½œçš„æœªæ¥çŠ¶æ€å’Œå›žæŠ¥ï¼Œå¹¶åŸºäºŽè¿™äº›é¢„æµ‹æ¥å±€éƒ¨æ›´æ–°Qå‡½æ•°ã€‚è¿™æ ·ï¼Œå®‰å…¨ç›¾ä¸ä»…èƒ½ä¿è¯å®‰å…¨æ€§ï¼Œè¿˜èƒ½é€‰æ‹©æ›´æœ‰åˆ©äºŽé•¿æœŸå›žæŠ¥çš„åŠ¨ä½œï¼Œä»Žè€Œæå‡æ•´ä½“æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) åŸºäºŽæ¨¡åž‹çš„å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼Œä½¿ç”¨Dyna-Qç®—æ³•è¿›è¡Œå­¦ä¹ ï¼›2) çŽ¯å¢ƒæ¨¡åž‹ï¼Œç”¨äºŽæ¨¡æ‹ŸçŽ¯å¢ƒçš„åŠ¨æ€å˜åŒ–ï¼›3) å®‰å…¨ç›¾ï¼Œè´Ÿè´£åˆ¤æ–­å½“å‰åŠ¨ä½œæ˜¯å¦å®‰å…¨ï¼Œå¹¶é€‰æ‹©å®‰å…¨åŠ¨ä½œï¼›4) é¢„æµ‹æ¨¡å—ï¼ŒåŸºäºŽçŽ¯å¢ƒæ¨¡åž‹è¿›è¡Œå®‰å…¨é¢„æµ‹ï¼Œè¯„ä¼°ä¸åŒå®‰å…¨åŠ¨ä½œçš„æœªæ¥å›žæŠ¥ï¼›5) Qå‡½æ•°æ›´æ–°æ¨¡å—ï¼Œæ ¹æ®é¢„æµ‹ç»“æžœå±€éƒ¨æ›´æ–°Qå‡½æ•°ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼šæ™ºèƒ½ä½“æ ¹æ®å½“å‰çŠ¶æ€é€‰æ‹©åŠ¨ä½œï¼Œå®‰å…¨ç›¾åˆ¤æ–­åŠ¨ä½œæ˜¯å¦å®‰å…¨ï¼Œå¦‚æžœå®‰å…¨åˆ™æ‰§è¡Œï¼Œå¦åˆ™ä½¿ç”¨é¢„æµ‹æ¨¡å—é€‰æ‹©æ›´ä¼˜çš„å®‰å…¨åŠ¨ä½œï¼Œå¹¶æ›´æ–°Qå‡½æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽå°†é¢„æµ‹å¼•å…¥å®‰å…¨ç›¾ä¸­ã€‚ä¼ ç»Ÿçš„å®‰å…¨ç›¾åªå…³æ³¨å½“å‰åŠ¨ä½œçš„å®‰å…¨æ€§ï¼Œè€Œå¿½ç•¥äº†æœªæ¥å›žæŠ¥ã€‚é€šè¿‡ä½¿ç”¨çŽ¯å¢ƒæ¨¡åž‹è¿›è¡Œé¢„æµ‹ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿè¯„ä¼°ä¸åŒå®‰å…¨åŠ¨ä½œçš„é•¿æœŸå½±å“ï¼Œä»Žè€Œé€‰æ‹©æ›´æœ‰åˆ©äºŽé•¿æœŸå›žæŠ¥çš„åŠ¨ä½œã€‚è¿™ç§é¢„æµ‹èƒ½åŠ›ä½¿å¾—å®‰å…¨ç›¾ä¸ä»…èƒ½ä¿è¯å®‰å…¨æ€§ï¼Œè¿˜èƒ½æå‡æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ–¹æ³•çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨Dyna-Qç®—æ³•è¿›è¡Œå­¦ä¹ ï¼ŒDyna-Qç®—æ³•æ˜¯ä¸€ç§åŸºäºŽæ¨¡åž‹çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œé€‚åˆäºŽç¦»æ•£ç©ºé—´ï¼›2) ä½¿ç”¨çŽ¯å¢ƒæ¨¡åž‹è¿›è¡Œå®‰å…¨é¢„æµ‹ï¼ŒçŽ¯å¢ƒæ¨¡åž‹å¯ä»¥æ˜¯å­¦ä¹ å¾—åˆ°çš„ï¼Œä¹Ÿå¯ä»¥æ˜¯é¢„å…ˆå®šä¹‰çš„ï¼›3) å±€éƒ¨æ›´æ–°Qå‡½æ•°ï¼Œåªæ›´æ–°ä¸Žå®‰å…¨é¢„æµ‹ç›¸å…³çš„Qå€¼ï¼Œé¿å…å½±å“å…¶ä»–Qå€¼çš„å‡†ç¡®æ€§ï¼›4) é¢„æµ‹èŒƒå›´çš„é€‰æ‹©ï¼Œé¢„æµ‹èŒƒå›´è¶Šé•¿ï¼Œé¢„æµ‹è¶Šå‡†ç¡®ï¼Œä½†è®¡ç®—æˆæœ¬ä¹Ÿè¶Šé«˜ï¼Œéœ€è¦æ ¹æ®å…·ä½“é—®é¢˜è¿›è¡Œæƒè¡¡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨ç½‘æ ¼ä¸–ç•ŒçŽ¯å¢ƒä¸­èƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡å¼ºåŒ–å­¦ä¹ çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿è¯å®‰å…¨æ€§ã€‚å³ä½¿ä½¿ç”¨è¾ƒçŸ­çš„é¢„æµ‹èŒƒå›´ï¼Œè¯¥æ–¹æ³•ä¹Ÿèƒ½æ‰¾åˆ°æœ€ä¼˜è·¯å¾„ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¯¹æ¨¡æ‹Ÿä¸ŽçŽ°å®žä¹‹é—´çš„åˆ†å¸ƒåç§»å…·æœ‰é²æ£’æ€§ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨æŸäº›å®žéªŒä¸­ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿè¾¾åˆ°ä¸Žæ— å®‰å…¨ç›¾çš„Dyna-Qç®—æ³•ç›¸è¿‘çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿è¯äº†100%çš„å®‰å…¨æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰é¢†åŸŸï¼Œå°¤å…¶é€‚ç”¨äºŽå¯¹å®‰å…¨æ€§è¦æ±‚è¾ƒé«˜çš„åœºæ™¯ã€‚ä¾‹å¦‚ï¼Œåœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•ä¿è¯æœºå™¨äººåœ¨é¿å¼€éšœç¢ç‰©çš„åŒæ—¶ï¼Œå°½å¯èƒ½å¿«åœ°åˆ°è¾¾ç›®æ ‡ä½ç½®ã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥ä¿è¯è½¦è¾†åœ¨è¡Œé©¶è¿‡ç¨‹ä¸­å§‹ç»ˆå¤„äºŽå®‰å…¨çŠ¶æ€ï¼Œé¿å…å‘ç”Ÿäº¤é€šäº‹æ•…ã€‚è¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºŽæ¸¸æˆAIä¸­ï¼Œä½¿AIåœ¨ä¿è¯æ¸¸æˆè§„åˆ™çš„å‰æä¸‹ï¼Œåšå‡ºæ›´æ™ºèƒ½çš„å†³ç­–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Obtaining safety guarantees for reinforcement learning is a major challenge to achieve applicability for real-world tasks. Safety shields extend standard reinforcement learning and achieve hard safety guarantees. However, existing safety shields commonly use random sampling of safe actions or a fixed fallback controller, therefore disregarding future performance implications of different safe actions. In this work, we propose a predictive safety shield for model-based reinforcement learning agents in discrete space. Our safety shield updates the Q-function locally based on safe predictions, which originate from a safe simulation of the environment model. This shielding approach improves performance while maintaining hard safety guarantees. Our experiments on gridworld environments demonstrate that even short prediction horizons can be sufficient to identify the optimal path. We observe that our approach is robust to distribution shifts, e.g., between simulation and reality, without requiring additional training.

