---
layout: default
title: Dual-Agent Reinforcement Learning for Adaptive and Cost-Aware Visual-Inertial Odometry
---

# Dual-Agent Reinforcement Learning for Adaptive and Cost-Aware Visual-Inertial Odometry

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.21083" target="_blank" class="toolbar-btn">arXiv: 2511.21083v1</a>
    <a href="https://arxiv.org/pdf/2511.21083.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.21083v1" 
            onclick="toggleFavorite(this, '2511.21083v1', 'Dual-Agent Reinforcement Learning for Adaptive and Cost-Aware Visual-Inertial Odometry')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Feiyang Pan, Shenghe Zheng, Chunyan Yin, Guangbin Dou

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-26

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂèåÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†ÁöÑËá™ÈÄÇÂ∫î„ÄÅ‰ΩéÊàêÊú¨ËßÜËßâÊÉØÊÄßÈáåÁ®ãËÆ°**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâÊÉØÊÄßÈáåÁ®ãËÆ°` `Âº∫ÂåñÂ≠¶‰π†` `Ëá™‰∏ªÂØºËà™` `ËµÑÊ∫êÂèóÈôêÂπ≥Âè∞` `Ëá™ÈÄÇÂ∫îÁ≥ªÁªü`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVIOÊñπÊ≥ïÂú®Á≤æÂ∫¶ÂíåËÆ°ÁÆóÊïàÁéá‰πãÈó¥Â≠òÂú®ÊùÉË°°Ôºå‰ºòÂåñÊñπÊ≥ïÁ≤æÂ∫¶È´ò‰ΩÜËÆ°ÁÆóÈáèÂ§ßÔºåÊª§Ê≥¢ÊñπÊ≥ïÊïàÁéáÈ´ò‰ΩÜÊòìÊºÇÁßª„ÄÇ
2. ÊèêÂá∫‰∏ÄÁßçÂü∫‰∫éÂèåÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†ÁöÑVIOÊ°ÜÊû∂ÔºåËá™ÈÄÇÂ∫îÂú∞ÊéßÂà∂ËßÜËßâÂâçÁ´ØÁöÑËøêË°åÂíå‰ø°ÊÅØËûçÂêàÔºå‰ª•Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Á≤æÂ∫¶„ÄÅÊïàÁéáÂíåÂÜÖÂ≠òÂç†Áî®ÊñπÈù¢ÂèñÂæó‰∫ÜÊõ¥Â•ΩÁöÑÂπ≥Ë°°ÔºåÂπ∂Âú®EuRoC MAVÂíåTUM-VIÊï∞ÊçÆÈõÜ‰∏äÈ™åËØÅ‰∫ÜÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâÊÉØÊÄßÈáåÁ®ãËÆ°(VIO)ÊòØÂÆûÁé∞È≤ÅÊ£íÁöÑËá™ËøêÂä®‰º∞ËÆ°ÁöÑÂÖ≥ÈîÆÁªÑ‰ª∂Ôºå‰∏∫Êú∫Âô®‰∫∫Ëá™‰∏ªÂØºËà™ÂíåÂ¢ûÂº∫Áé∞ÂÆûÁöÑÂÆûÊó∂6Ëá™Áî±Â∫¶Ë∑üË∏™Á≠âÂü∫Á°ÄËÉΩÂäõÊèê‰æõÊîØÊåÅ„ÄÇÁé∞ÊúâÊñπÊ≥ïÈù¢‰∏¥‰∏Ä‰∏™‰ºóÊâÄÂë®Áü•ÁöÑÊùÉË°°ÔºöÂü∫‰∫éÊª§Ê≥¢ÁöÑÊñπÊ≥ïÊïàÁéáÈ´ò‰ΩÜÂÆπÊòìÊºÇÁßªÔºåËÄåÂü∫‰∫é‰ºòÂåñÁöÑÊñπÊ≥ïËôΩÁÑ∂ÂáÜÁ°ÆÔºå‰ΩÜ‰æùËµñ‰∫éËÆ°ÁÆóÈáèÂ∑®Â§ßÁöÑËßÜËßâÊÉØÊÄßÊçÜÁªëË∞ÉÊï¥(VIBA)ÔºåÈöæ‰ª•Âú®ËµÑÊ∫êÂèóÈôêÁöÑÂπ≥Âè∞‰∏äËøêË°å„ÄÇÊú¨ÊñáÊó®Âú®ÂáèÂ∞ëVIBAÁöÑË∞ÉÁî®È¢ëÁéáÂíåÂº∫Â∫¶ÔºåËÄå‰∏çÊòØÂÆåÂÖ®ÁßªÈô§ÂÆÉ„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨Â∞ÜÁé∞‰ª£VIO‰∏≠ÁöÑ‰∏§‰∏™ÂÖ≥ÈîÆËÆæËÆ°ÈÄâÊã©Ôºà‰ΩïÊó∂ËøêË°åËßÜËßâÂâçÁ´Ø‰ª•ÂèäÂØπÂÆÉÁöÑËæìÂá∫‰ø°‰ªªÂ∫¶ÔºâËΩ¨Âåñ‰∏∫Â∫èÂàóÂÜ≥Á≠ñÈóÆÈ¢òÔºåÂπ∂‰ΩøÁî®ËΩªÈáèÁ∫ßÂº∫ÂåñÂ≠¶‰π†(RL)Êô∫ËÉΩ‰ΩìËß£ÂÜ≥ÂÆÉ‰ª¨„ÄÇÊú¨ÊñáÊ°ÜÊû∂ÂºïÂÖ•‰∫Ü‰∏ÄÁßçËΩªÈáèÁ∫ßÁöÑÂèåÁÆ°ÈΩê‰∏ãÁöÑRLÁ≠ñÁï•Ôºå‰Ωú‰∏∫Ê†∏ÂøÉË¥°ÁåÆÔºö(1)‰∏Ä‰∏™ÈÄâÊã©Êô∫ËÉΩ‰ΩìÔºå‰ªÖÂü∫‰∫éÈ´òÈ¢ëIMUÊï∞ÊçÆÊô∫ËÉΩÂú∞ÊéßÂà∂Êï¥‰∏™VOÊµÅÁ®ãÔºõ(2)‰∏Ä‰∏™Â§çÂêàËûçÂêàÊô∫ËÉΩ‰ΩìÔºåÈ¶ñÂÖàÈÄöËøáÁõëÁù£ÁΩëÁªú‰º∞ËÆ°‰∏Ä‰∏™È≤ÅÊ£íÁöÑÈÄüÂ∫¶Áä∂ÊÄÅÔºåÁÑ∂ÂêéÈÄöËøáRLÁ≠ñÁï•Ëá™ÈÄÇÂ∫îÂú∞ËûçÂêàÂÆåÊï¥ÁöÑ(p, v, q)Áä∂ÊÄÅ„ÄÇÂú®EuRoC MAVÂíåTUM-VIÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåÂú®Áªü‰∏ÄËØÑ‰º∞‰∏≠ÔºåËØ•ÊñπÊ≥ïÊØî‰πãÂâçÁöÑÂü∫‰∫éGPUÁöÑVO/VIOÁ≥ªÁªüÂÆûÁé∞‰∫ÜÊõ¥ÊúâÂà©ÁöÑÁ≤æÂ∫¶-ÊïàÁéá-ÂÜÖÂ≠òÊùÉË°°ÔºöÂú®ËøêË°åÈÄüÂ∫¶ÊèêÈ´ò1.77ÂÄçÂπ∂‰ΩøÁî®Êõ¥Â∞ëGPUÂÜÖÂ≠òÁöÑÂêåÊó∂ÔºåËé∑Âæó‰∫ÜÊúÄ‰Ω≥ÁöÑÂπ≥ÂùáATE„ÄÇ‰∏éÁªèÂÖ∏ÁöÑÂü∫‰∫é‰ºòÂåñÁöÑVIOÁ≥ªÁªüÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÂú®‰øùÊåÅÊúâÁ´û‰∫âÂäõÁöÑËΩ®ËøπÁ≤æÂ∫¶ÁöÑÂêåÊó∂ÔºåÊòæËëóÈôç‰Ωé‰∫ÜËÆ°ÁÆóË¥üËΩΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâVIOÊñπÊ≥ïÈúÄË¶ÅÂú®Á≤æÂ∫¶ÂíåËÆ°ÁÆóÊïàÁéá‰πãÈó¥ËøõË°åÊùÉË°°„ÄÇÂü∫‰∫é‰ºòÂåñÁöÑÊñπÊ≥ïÔºåÂ¶ÇVIBAÔºåËôΩÁÑ∂ËÉΩÊèê‰æõÈ´òÁ≤æÂ∫¶ÁöÑ‰ΩçÂßø‰º∞ËÆ°Ôºå‰ΩÜËÆ°ÁÆóÂ§çÊùÇÂ∫¶È´òÔºåÈöæ‰ª•Âú®ËµÑÊ∫êÂèóÈôêÁöÑÁßªÂä®Âπ≥Âè∞‰∏äÂÆûÊó∂ËøêË°å„ÄÇÂü∫‰∫éÊª§Ê≥¢ÁöÑÊñπÊ≥ïËôΩÁÑ∂ËÆ°ÁÆóÊïàÁéáÈ´òÔºå‰ΩÜÁ≤æÂ∫¶Áõ∏ÂØπËæÉ‰ΩéÔºåÂÆπÊòì‰∫ßÁîüÊºÇÁßª„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÂú®‰øùËØÅÁ≤æÂ∫¶ÁöÑÂâçÊèê‰∏ãÔºåÈôç‰ΩéVIOÁöÑËÆ°ÁÆóÊàêÊú¨ÔºåÊòØÊú¨ÊñáË¶ÅËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜVIO‰∏≠ÁöÑ‰∏§‰∏™ÂÖ≥ÈîÆÂÜ≥Á≠ñËøáÁ®ãÔºåÂç≥‚Äú‰ΩïÊó∂ËøêË°åËßÜËßâÂâçÁ´Ø‚ÄùÂíå‚ÄúÂ¶Ç‰ΩïËûçÂêàËßÜËßâÂíåÊÉØÊÄß‰ø°ÊÅØ‚ÄùÔºåÂª∫Ê®°‰∏∫Â∫èÂàóÂÜ≥Á≠ñÈóÆÈ¢òÔºåÂπ∂Âà©Áî®Âº∫ÂåñÂ≠¶‰π†(RL)Êù•Â≠¶‰π†ÊúÄ‰ºòÁ≠ñÁï•„ÄÇÈÄöËøáÊô∫ËÉΩÂú∞ÊéßÂà∂ËßÜËßâÂâçÁ´ØÁöÑËøêË°åÈ¢ëÁéáÂíåËá™ÈÄÇÂ∫îÂú∞ËûçÂêàËßÜËßâÂíåÊÉØÊÄß‰ø°ÊÅØÔºåÂèØ‰ª•Âú®‰øùËØÅÁ≤æÂ∫¶ÁöÑÂâçÊèê‰∏ãÔºåÊòæËëóÈôç‰ΩéËÆ°ÁÆóÊàêÊú¨„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•VIOÊ°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÁöÑRLÊô∫ËÉΩ‰ΩìÔºöÈÄâÊã©Êô∫ËÉΩ‰Ωì(Select Agent)ÂíåËûçÂêàÊô∫ËÉΩ‰Ωì(Fusion Agent)„ÄÇÈÄâÊã©Êô∫ËÉΩ‰ΩìÂü∫‰∫éÈ´òÈ¢ëIMUÊï∞ÊçÆÔºåÂÜ≥ÂÆöÊòØÂê¶ËøêË°åËßÜËßâÂâçÁ´Ø„ÄÇËûçÂêàÊô∫ËÉΩ‰ΩìÈ¶ñÂÖàÈÄöËøá‰∏Ä‰∏™ÁõëÁù£ÁΩëÁªú‰º∞ËÆ°È≤ÅÊ£íÁöÑÈÄüÂ∫¶Áä∂ÊÄÅÔºåÁÑ∂Âêé‰ΩøÁî®RLÁ≠ñÁï•Ëá™ÈÄÇÂ∫îÂú∞ËûçÂêàËßÜËßâ‰ø°ÊÅØÂíåÊÉØÊÄß‰ø°ÊÅØÔºåÂæóÂà∞ÊúÄÁªàÁöÑ‰ΩçÂßø‰º∞ËÆ°„ÄÇÊï¥‰∏™Ê°ÜÊû∂ÂèØ‰ª•Áúã‰ΩúÊòØ‰∏Ä‰∏™Ëá™ÈÄÇÂ∫îÁöÑVIOÁ≥ªÁªüÔºåËÉΩÂ§üÊ†πÊçÆÁéØÂ¢ÉÂíåËá™Ë∫´Áä∂ÊÄÅÂä®ÊÄÅË∞ÉÊï¥ËÆ°ÁÆóËµÑÊ∫êÁöÑ‰ΩøÁî®„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜVIO‰∏≠ÁöÑÂÜ≥Á≠ñËøáÁ®ãÂª∫Ê®°‰∏∫Â∫èÂàóÂÜ≥Á≠ñÈóÆÈ¢òÔºåÂπ∂Âà©Áî®Âº∫ÂåñÂ≠¶‰π†Êù•Â≠¶‰π†ÊúÄ‰ºòÁ≠ñÁï•„ÄÇ‰∏é‰º†ÁªüÁöÑVIOÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊõ¥Âä†Êô∫ËÉΩÂú∞ÊéßÂà∂ËÆ°ÁÆóËµÑÊ∫êÁöÑÂàÜÈÖçÔºå‰ªéËÄåÂú®Á≤æÂ∫¶ÂíåÊïàÁéá‰πãÈó¥ÂèñÂæóÊõ¥Â•ΩÁöÑÂπ≥Ë°°„ÄÇÂèåÊô∫ËÉΩ‰ΩìÁöÑËÆæËÆ°‰πüÊòØ‰∏Ä‰∏™ÂàõÊñ∞ÔºåÈÄâÊã©Êô∫ËÉΩ‰ΩìË¥üË¥£ÊéßÂà∂ËßÜËßâÂâçÁ´ØÁöÑËøêË°åÔºåËûçÂêàÊô∫ËÉΩ‰ΩìË¥üË¥£‰ø°ÊÅØËûçÂêàÔºå‰∏§‰∏™Êô∫ËÉΩ‰ΩìÂçèÂêåÂ∑•‰ΩúÔºåÂÖ±Âêå‰ºòÂåñVIOÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÈÄâÊã©Êô∫ËÉΩ‰ΩìÁöÑËæìÂÖ•ÊòØÈ´òÈ¢ëIMUÊï∞ÊçÆÔºåËæìÂá∫ÊòØÊòØÂê¶ËøêË°åËßÜËßâÂâçÁ´ØÁöÑÂÜ≥Á≠ñ„ÄÇËûçÂêàÊô∫ËÉΩ‰ΩìÂåÖÂê´‰∏Ä‰∏™ÁõëÁù£ÁΩëÁªúÂíå‰∏Ä‰∏™RLÁ≠ñÁï•„ÄÇÁõëÁù£ÁΩëÁªúÁî®‰∫é‰º∞ËÆ°È≤ÅÊ£íÁöÑÈÄüÂ∫¶Áä∂ÊÄÅÔºåRLÁ≠ñÁï•Áî®‰∫éËá™ÈÄÇÂ∫îÂú∞ËûçÂêàËßÜËßâ‰ø°ÊÅØÂíåÊÉØÊÄß‰ø°ÊÅØ„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÈúÄË¶ÅËÄÉËôëÁ≤æÂ∫¶ÂíåËÆ°ÁÆóÊàêÊú¨ÔºåÂ•ñÂä±ÂáΩÊï∞ÁöÑËÆæËÆ°ÈúÄË¶ÅÈºìÂä±Êô∫ËÉΩ‰ΩìÂú®‰øùËØÅÁ≤æÂ∫¶ÁöÑÂâçÊèê‰∏ãÔºåÂ∞ΩÂèØËÉΩÂú∞ÂáèÂ∞ëËÆ°ÁÆóÈáè„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÈúÄË¶ÅÊ†πÊçÆÂÆûÈôÖÂ∫îÁî®Âú∫ÊôØËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®EuRoC MAVÂíåTUM-VIÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰∏é‰πãÂâçÁöÑÂü∫‰∫éGPUÁöÑVO/VIOÁ≥ªÁªüÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÂú®ËøêË°åÈÄüÂ∫¶ÊèêÈ´ò1.77ÂÄçÂπ∂‰ΩøÁî®Êõ¥Â∞ëGPUÂÜÖÂ≠òÁöÑÂêåÊó∂ÔºåËé∑Âæó‰∫ÜÊúÄ‰Ω≥ÁöÑÂπ≥ÂùáATE„ÄÇ‰∏éÁªèÂÖ∏ÁöÑÂü∫‰∫é‰ºòÂåñÁöÑVIOÁ≥ªÁªüÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÂú®‰øùÊåÅÊúâÁ´û‰∫âÂäõÁöÑËΩ®ËøπÁ≤æÂ∫¶ÁöÑÂêåÊó∂ÔºåÊòæËëóÈôç‰Ωé‰∫ÜËÆ°ÁÆóË¥üËΩΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫Ëá™‰∏ªÂØºËà™„ÄÅÂ¢ûÂº∫Áé∞ÂÆû„ÄÅÊó†‰∫∫Êú∫Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÈôç‰ΩéVIOÁöÑËÆ°ÁÆóÊàêÊú¨ÔºåÂèØ‰ª•‰ΩøËøô‰∫õÂ∫îÁî®Âú®ËµÑÊ∫êÂèóÈôêÁöÑÁßªÂä®Âπ≥Âè∞‰∏äËøêË°åÔºå‰ªéËÄåÊâ©Â±ïÂÖ∂Â∫îÁî®ËåÉÂõ¥„ÄÇÊ≠§Â§ñÔºåËá™ÈÄÇÂ∫îÁöÑVIOÁ≥ªÁªüËÉΩÂ§üÊ†πÊçÆÁéØÂ¢ÉÂíåËá™Ë∫´Áä∂ÊÄÅÂä®ÊÄÅË∞ÉÊï¥ËÆ°ÁÆóËµÑÊ∫êÁöÑ‰ΩøÁî®Ôºå‰ªéËÄåÊèêÈ´òÁ≥ªÁªüÁöÑÈ≤ÅÊ£íÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Visual-Inertial Odometry (VIO) is a critical component for robust ego-motion estimation, enabling foundational capabilities such as autonomous navigation in robotics and real-time 6-DoF tracking for augmented reality. Existing methods face a well-known trade-off: filter-based approaches are efficient but prone to drift, while optimization-based methods, though accurate, rely on computationally prohibitive Visual-Inertial Bundle Adjustment (VIBA) that is difficult to run on resource-constrained platforms. Rather than removing VIBA altogether, we aim to reduce how often and how heavily it must be invoked. To this end, we cast two key design choices in modern VIO, when to run the visual frontend and how strongly to trust its output, as sequential decision problems, and solve them with lightweight reinforcement learning (RL) agents. Our framework introduces a lightweight, dual-pronged RL policy that serves as our core contribution: (1) a Select Agent intelligently gates the entire VO pipeline based only on high-frequency IMU data; and (2) a composite Fusion Agent that first estimates a robust velocity state via a supervised network, before an RL policy adaptively fuses the full (p, v, q) state. Experiments on the EuRoC MAV and TUM-VI datasets show that, in our unified evaluation, the proposed method achieves a more favorable accuracy-efficiency-memory trade-off than prior GPU-based VO/VIO systems: it attains the best average ATE while running up to 1.77 times faster and using less GPU memory. Compared to classical optimization-based VIO systems, our approach maintains competitive trajectory accuracy while substantially reducing computational load.

