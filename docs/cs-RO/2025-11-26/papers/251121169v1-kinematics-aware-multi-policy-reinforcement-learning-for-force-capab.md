---
layout: default
title: Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation
---

# Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation

**arXiv**: [2511.21169v1](https://arxiv.org/abs/2511.21169) | [PDF](https://arxiv.org/pdf/2511.21169.pdf)

**ä½œè€…**: Kaiyan Xiao, Zihan Xu, Cheng Zhe, Chengju Liu, Qijun Chen

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-26

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§åŸºäºŽè¿åŠ¨å­¦æ„ŸçŸ¥çš„å¤šç­–ç•¥å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºŽäººå½¢æœºå™¨äººåŠ›æŽ§æ“ä½œ**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `äººå½¢æœºå™¨äºº` `åŠ›æŽ§æ“ä½œ` `å¼ºåŒ–å­¦ä¹ ` `è¿åŠ¨å­¦æ„ŸçŸ¥` `å¤šç­–ç•¥å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰çš„äººå½¢æœºå™¨äººæ“ä½œæ–¹æ³•ä¸»è¦å…³æ³¨çµå·§æ“ä½œï¼Œéš¾ä»¥æ»¡è¶³é«˜è´Ÿè½½å·¥ä¸šåœºæ™¯ä¸­çµå·§æ€§å’Œä¸»åŠ¨åŠ›äº¤äº’çš„ç»¼åˆéœ€æ±‚ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§è§£è€¦çš„ä¸‰é˜¶æ®µå¼ºåŒ–å­¦ä¹ æ¡†æž¶ï¼Œåˆ†åˆ«è®­ç»ƒä¸Šè‚¢ã€ä¸‹è‚¢å’Œdelta-commandç­–ç•¥ï¼Œå®žçŽ°åŠ›æŽ§æ“ä½œã€‚
3. é€šè¿‡å¯å‘å¼å¥–åŠ±å‡½æ•°åŠ é€Ÿä¸Šè‚¢è®­ç»ƒï¼Œå¹¶è®¾è®¡åŸºäºŽåŠ›çš„è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿä¸»åŠ¨è°ƒèŠ‚ä¸ŽçŽ¯å¢ƒçš„äº¤äº’åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºŽå¼ºåŒ–å­¦ä¹ çš„æ¡†æž¶ï¼Œç”¨äºŽå®žçŽ°äººå½¢æœºå™¨äººåœ¨å·¥ä¸šåœºæ™¯ä¸‹çš„åŠ›æŽ§æ“ä½œã€‚è¯¥æ¡†æž¶é‡‡ç”¨è§£è€¦çš„ä¸‰é˜¶æ®µè®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬ä¸Šè‚¢ç­–ç•¥ã€ä¸‹è‚¢ç­–ç•¥å’Œdelta-commandç­–ç•¥ã€‚ä¸ºäº†åŠ é€Ÿä¸Šè‚¢è®­ç»ƒï¼Œè®¾è®¡äº†ä¸€ç§å¯å‘å¼å¥–åŠ±å‡½æ•°ï¼Œé€šè¿‡éšå¼åµŒå…¥æ­£å‘è¿åŠ¨å­¦å…ˆéªŒçŸ¥è¯†ï¼Œä½¿ç­–ç•¥èƒ½å¤Ÿæ›´å¿«åœ°æ”¶æ•›å¹¶èŽ·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚å¯¹äºŽä¸‹è‚¢ï¼Œå¼€å‘äº†ä¸€ç§åŸºäºŽåŠ›çš„è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿä¸»åŠ¨æ–½åŠ å’Œè°ƒèŠ‚ä¸ŽçŽ¯å¢ƒçš„äº¤äº’åŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„äººå½¢æœºå™¨äººæ“ä½œæ–¹æ³•åœ¨é«˜è´Ÿè½½å·¥ä¸šåœºæ™¯ä¸­ï¼Œæ— æ³•åŒæ—¶æ»¡è¶³çµå·§æ“ä½œå’Œä¸»åŠ¨åŠ›äº¤äº’çš„éœ€æ±‚ã€‚å®ƒä»¬é€šå¸¸ä¾§é‡äºŽç²¾ç»†çš„åŠ¨ä½œæŽ§åˆ¶ï¼Œè€Œå¿½ç•¥äº†æœºå™¨äººä¸ŽçŽ¯å¢ƒä¹‹é—´çš„åŠ›å­¦å…³ç³»ï¼Œå¯¼è‡´åœ¨éœ€è¦ä¸»åŠ¨æ–½åŠ æˆ–è°ƒèŠ‚åŠ›çš„ä»»åŠ¡ä¸­è¡¨çŽ°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†äººå½¢æœºå™¨äººçš„æ“ä½œä»»åŠ¡åˆ†è§£ä¸ºä¸Šè‚¢å’Œä¸‹è‚¢çš„ç‹¬ç«‹æŽ§åˆ¶ï¼Œå¹¶åˆ†åˆ«è®¾è®¡ç›¸åº”çš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥ã€‚é€šè¿‡è§£è€¦è®­ç»ƒï¼Œå¯ä»¥é’ˆå¯¹æ€§åœ°ä¼˜åŒ–ä¸Šè‚¢çš„çµå·§æ€§å’Œä¸‹è‚¢çš„åŠ›æŽ§èƒ½åŠ›ã€‚åŒæ—¶ï¼Œå¼•å…¥delta-commandç­–ç•¥æ¥åè°ƒä¸Šä¸‹è‚¢çš„è¿åŠ¨ï¼Œå®žçŽ°æ•´ä½“çš„åŠ›æŽ§æ“ä½œã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ¡†æž¶åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1) ä¸Šè‚¢ç­–ç•¥è®­ç»ƒï¼šä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸Šè‚¢ç­–ç•¥ï¼Œä½¿å…¶èƒ½å¤Ÿå®Œæˆç‰¹å®šçš„æ“ä½œä»»åŠ¡ã€‚2) ä¸‹è‚¢ç­–ç•¥è®­ç»ƒï¼šä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸‹è‚¢ç­–ç•¥ï¼Œä½¿å…¶èƒ½å¤Ÿä¸»åŠ¨æ–½åŠ å’Œè°ƒèŠ‚ä¸ŽçŽ¯å¢ƒçš„äº¤äº’åŠ›ã€‚3) delta-commandç­–ç•¥è®­ç»ƒï¼šä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒdelta-commandç­–ç•¥ï¼Œç”¨äºŽåè°ƒä¸Šä¸‹è‚¢çš„è¿åŠ¨ï¼Œå®žçŽ°æ•´ä½“çš„åŠ›æŽ§æ“ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) æå‡ºäº†ä¸€ä¸ªè§£è€¦çš„ä¸‰é˜¶æ®µå¼ºåŒ–å­¦ä¹ æ¡†æž¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°è®­ç»ƒäººå½¢æœºå™¨äººçš„åŠ›æŽ§æ“ä½œç­–ç•¥ã€‚2) è®¾è®¡äº†ä¸€ç§å¯å‘å¼å¥–åŠ±å‡½æ•°ï¼Œé€šè¿‡éšå¼åµŒå…¥æ­£å‘è¿åŠ¨å­¦å…ˆéªŒçŸ¥è¯†ï¼ŒåŠ é€Ÿäº†ä¸Šè‚¢ç­–ç•¥çš„è®­ç»ƒã€‚3) å¼€å‘äº†ä¸€ç§åŸºäºŽåŠ›çš„è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿä¸»åŠ¨æ–½åŠ å’Œè°ƒèŠ‚ä¸ŽçŽ¯å¢ƒçš„äº¤äº’åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šä¸Šè‚¢ç­–ç•¥çš„å¯å‘å¼å¥–åŠ±å‡½æ•°è®¾è®¡ï¼Œè€ƒè™‘äº†ç›®æ ‡ä½ç½®ã€å§¿æ€ä»¥åŠå…³èŠ‚åŠ›çŸ©ç­‰å› ç´ ï¼Œæ—¨åœ¨å¼•å¯¼ç­–ç•¥æ›´å¿«åœ°æ”¶æ•›åˆ°æœ€ä¼˜è§£ã€‚ä¸‹è‚¢ç­–ç•¥çš„è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œä»Žç®€å•çš„åŠ›æŽ§ä»»åŠ¡å¼€å§‹ï¼Œé€æ­¥å¢žåŠ éš¾åº¦ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿé€æ­¥æŽŒæ¡å¤æ‚çš„åŠ›æŽ§æŠ€èƒ½ã€‚delta-commandç­–ç•¥çš„ç½‘ç»œç»“æž„å’ŒæŸå¤±å‡½æ•°è®¾è®¡ï¼Œæ—¨åœ¨å®žçŽ°ä¸Šä¸‹è‚¢è¿åŠ¨çš„å¹³æ»‘è¿‡æ¸¡å’Œåè°ƒã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡ä»¿çœŸå®žéªŒéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä½¿äººå½¢æœºå™¨äººæˆåŠŸå®ŒæˆåŠ›æŽ§æ“ä½œä»»åŠ¡ï¼Œå¹¶ä¸”åœ¨æ”¶æ•›é€Ÿåº¦å’Œæ€§èƒ½æ–¹é¢ä¼˜äºŽä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œå¯å‘å¼å¥–åŠ±å‡½æ•°åŠ é€Ÿäº†ä¸Šè‚¢ç­–ç•¥çš„è®­ç»ƒï¼ŒåŸºäºŽåŠ›çš„è¯¾ç¨‹å­¦ä¹ ç­–ç•¥æé«˜äº†ä¸‹è‚¢çš„åŠ›æŽ§èƒ½åŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽé«˜è´Ÿè½½å·¥ä¸šåœºæ™¯ï¼Œä¾‹å¦‚é‡åž‹é›¶éƒ¨ä»¶çš„è£…é…ã€æ‰“ç£¨å’ŒæŠ›å…‰ç­‰ä»»åŠ¡ã€‚é€šè¿‡åŠ›æŽ§æ“ä½œï¼Œäººå½¢æœºå™¨äººå¯ä»¥æ›´å¥½åœ°é€‚åº”çŽ¯å¢ƒå˜åŒ–ï¼Œæé«˜æ“ä½œçš„ç²¾åº¦å’Œæ•ˆçŽ‡ï¼Œé™ä½ŽæŸåå·¥ä»¶çš„é£Žé™©ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–éœ€è¦åŠ›äº¤äº’çš„åœºæ™¯ï¼Œä¾‹å¦‚åŒ»ç–—åº·å¤ã€å®¶åº­æœåŠ¡ç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Humanoid robots, with their human-like morphology, hold great potential for industrial applications. However, existing loco-manipulation methods primarily focus on dexterous manipulation, falling short of the combined requirements for dexterity and proactive force interaction in high-load industrial scenarios. To bridge this gap, we propose a reinforcement learning-based framework with a decoupled three-stage training pipeline, consisting of an upper-body policy, a lower-body policy, and a delta-command policy. To accelerate upper-body training, a heuristic reward function is designed. By implicitly embedding forward kinematics priors, it enables the policy to converge faster and achieve superior performance. For the lower body, a force-based curriculum learning strategy is developed, enabling the robot to actively exert and regulate interaction forces with the environment.

