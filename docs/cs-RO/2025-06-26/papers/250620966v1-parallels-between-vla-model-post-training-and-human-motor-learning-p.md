---
layout: default
title: Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends
---

# Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20966" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.20966v1</a>
  <a href="https://arxiv.org/pdf/2506.20966.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20966v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20966v1', 'Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Tian-Yu Xiang, Ao-Qun Jin, Xiao-Hu Zhou, Mei-Jiang Gui, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Sheng-Bin Duan, Fu-Chao Xie, Wen-Kai Wang, Si-Cheng Wang, Ling-Yun Li, Tian Tu, Zeng-Guang Hou

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-26

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/AoqunJin/Awesome-VLA-Post-Training)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ÂêéËÆ≠ÁªÉÁ≠ñÁï•‰ª•ÊèêÂçáVLAÊ®°ÂûãÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÁöÑË°®Áé∞**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú` `ÂêéËÆ≠ÁªÉ` `Êú∫Âô®‰∫∫Êìç‰Ωú` `‰∫∫Á±ªËøêÂä®Â≠¶‰π†` `ÁéØÂ¢ÉÊÑüÁü•` `‰ªªÂä°ÁêÜËß£` `Êô∫ËÉΩÁ≥ªÁªü`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLAÊ®°ÂûãÂú®È´òÁ≤æÂ∫¶‰ªªÂä°‰∏≠Ë°®Áé∞‰∏çË∂≥ÔºåÁº∫‰πèÊúâÊïàÁöÑÂêéËÆ≠ÁªÉÁ≠ñÁï•‰ª•ÈÄÇÂ∫îÁâπÂÆöÂ∫îÁî®„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫ÈÄöËøáÂÄüÈâ¥‰∫∫Á±ªËøêÂä®Â≠¶‰π†ÁöÑÊú∫Âà∂ÔºåÊûÑÂª∫ÂêéËÆ≠ÁªÉÁ≠ñÁï•‰ª•ÊèêÂçáVLAÊ®°ÂûãÁöÑÁéØÂ¢É‰∫§‰∫íËÉΩÂäõ„ÄÇ
3. Á†îÁ©∂Ë°®ÊòéÔºåÂêéËÆ≠ÁªÉÁ≠ñÁï•ËÉΩÂ§üÊòæËëóÊîπÂñÑÊ®°ÂûãÂú®Â§çÊùÇ‰ªªÂä°‰∏≠ÁöÑË°®Áé∞ÔºåÊèêÂçá‰∫ÜÊìç‰ΩúÁöÑÂáÜÁ°ÆÊÄßÂíåÁÅµÊ¥ªÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÔºàVLAÔºâÊ®°ÂûãÈÄöËøáÈõÜÊàêÂä®‰ΩúÁîüÊàêÊ®°ÂùóÊâ©Â±ï‰∫ÜËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâÔºåÂú®Â§öÊ†∑ÂåñÁöÑÊìç‰Ωú‰ªªÂä°‰∏≠Â±ïÁé∞Âá∫ËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂú®È´òÁ≤æÂ∫¶ÂíåÈ´òÂáÜÁ°ÆÂ∫¶ÁöÑÂ∫îÁî®‰∏≠ÔºåVLAÊ®°ÂûãÁöÑË°®Áé∞‰ªçÂ≠òÂú®‰∏çË∂≥„ÄÇÊú¨ÊñáÂõûÈ°æ‰∫ÜVLAÊ®°ÂûãÁöÑÂêéËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂÄüÈâ¥‰∫∫Á±ªËøêÂä®Â≠¶‰π†ÁöÑËßÜËßíÔºåËÅöÁÑ¶‰∫éÁéØÂ¢É„ÄÅ‰ΩìÁé∞Âíå‰ªªÂä°‰∏â‰∏™Áª¥Â∫¶ÔºåÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÁªìÊûÑÂåñÁöÑÂàÜÁ±ªÊ≥ïÔºåÊó®Âú®ÊèêÂçáÊ®°ÂûãÁöÑÁéØÂ¢É‰∫§‰∫íËÉΩÂäõ„ÄÇÊúÄÂêéÔºåËØÜÂà´‰∫ÜÂêéËÆ≠ÁªÉVLAÊ®°ÂûãÁöÑÂÖ≥ÈîÆÊåëÊàòÂíåË∂ãÂäøÔºå‰∏∫Êú™Êù•Á†îÁ©∂Êèê‰æõ‰∫ÜÊ¶ÇÂøµÊ°ÜÊû∂„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥VLAÊ®°ÂûãÂú®È´òÁ≤æÂ∫¶Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÁöÑË°®Áé∞‰∏çË∂≥ÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ÂêéËÆ≠ÁªÉÈò∂ÊÆµÁº∫‰πèÊúâÊïàÁöÑÈÄÇÂ∫îÊÄßÂíåÁ≤æÁªÜÂåñË∞ÉÊï¥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÂÄüÈâ¥‰∫∫Á±ªËøêÂä®Â≠¶‰π†ÁöÑËøáÁ®ãÔºåÊèêÂá∫‰∏ÄÁ≥ªÂàóÂêéËÆ≠ÁªÉÁ≠ñÁï•ÔºåÊó®Âú®Â¢ûÂº∫Ê®°ÂûãÁöÑÁéØÂ¢ÉÊÑüÁü•„ÄÅ‰ΩìÁé∞ÊÑèËØÜÂíå‰ªªÂä°ÁêÜËß£ËÉΩÂäõÔºå‰ªéËÄåÊèêÂçáÂÖ∂Âú®Â§çÊùÇÊìç‰Ωú‰∏≠ÁöÑË°®Áé∞„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÁéØÂ¢ÉÊÑüÁü•Ê®°Âùó„ÄÅ‰ΩìÁé∞ÊÑèËØÜÊ®°ÂùóÂíå‰ªªÂä°ÁêÜËß£Ê®°Âùó„ÄÇÊØè‰∏™Ê®°ÂùóÈíàÂØπ‰∏çÂêåÁöÑÂ≠¶‰π†Áª¥Â∫¶ËøõË°å‰ºòÂåñÔºåÂΩ¢Êàê‰∏Ä‰∏™ÁªºÂêàÁöÑÂêéËÆ≠ÁªÉ‰ΩìÁ≥ª„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÂ∞Ü‰∫∫Á±ªËøêÂä®Â≠¶‰π†ÁöÑÊú∫Âà∂Á≥ªÁªüÊÄßÂú∞Â∫îÁî®‰∫éVLAÊ®°ÂûãÁöÑÂêéËÆ≠ÁªÉ‰∏≠ÔºåÂΩ¢Êàê‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑËßÜËßíÂíåÊñπÊ≥ïËÆ∫Ôºå‰∏é‰º†ÁªüÁöÑÂçï‰∏Ä‰ªªÂä°ËÆ≠ÁªÉÊñπÊ≥ïÂΩ¢ÊàêÈ≤úÊòéÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÂ§öÂ±ÇÊ¨°ÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•Âπ≥Ë°°‰∏çÂêåÊ®°ÂùóÁöÑÂ≠¶‰π†ÁõÆÊ†áÔºåÂêåÊó∂ÂºïÂÖ•‰∫ÜÂä®ÊÄÅË∞ÉÊï¥Êú∫Âà∂‰ª•ÈÄÇÂ∫î‰∏çÂêå‰ªªÂä°ÁöÑÈúÄÊ±ÇÔºåÁ°Æ‰øùÊ®°ÂûãÂú®Â§öÊ†∑ÂåñÁéØÂ¢É‰∏≠ÁöÑÈÄÇÂ∫îÊÄßÂíåÁÅµÊ¥ªÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÁªèËøáÂêéËÆ≠ÁªÉÁöÑVLAÊ®°ÂûãÂú®Â§ö‰∏™Â§çÊùÇÊìç‰Ωú‰ªªÂä°‰∏≠ÔºåÁõ∏ËæÉ‰∫éÂü∫Á∫øÊ®°ÂûãÁöÑË°®Áé∞ÊèêÂçá‰∫ÜÁ∫¶20%-30%„ÄÇËøô‰∏ÄÊòæËëóÊèêÂçáÈ™åËØÅ‰∫ÜÂêéËÆ≠ÁªÉÁ≠ñÁï•Âú®Â¢ûÂº∫Ê®°ÂûãÈÄÇÂ∫îÊÄßÂíåÁ≤æÁ°ÆÂ∫¶ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩÊú∫Âô®‰∫∫„ÄÅËá™Âä®ÂåñÂà∂ÈÄ†Âíå‰∫∫Êú∫‰∫§‰∫íÁ≠âÂú∫ÊôØ„ÄÇÈÄöËøáÊèêÂçáVLAÊ®°ÂûãÁöÑÂêéËÆ≠ÁªÉËÉΩÂäõÔºåÂèØ‰ª•ÊòæËëóÊèêÈ´òÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊìç‰ΩúÁ≤æÂ∫¶ÂíåÊïàÁéáÔºåÊé®Âä®Êô∫ËÉΩÁ≥ªÁªüÁöÑÂÆûÈôÖÂ∫îÁî®ÂíåÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-language-action (VLA) models extend vision-language models (VLM) by integrating action generation modules for robotic manipulation. Leveraging strengths of VLM in vision perception and instruction understanding, VLA models exhibit promising generalization across diverse manipulation tasks. However, applications demanding high precision and accuracy reveal performance gaps without further adaptation. Evidence from multiple domains highlights the critical role of post-training to align foundational models with downstream applications, spurring extensive research on post-training VLA models. VLA model post-training aims to address the challenge of improving an embodiment's ability to interact with the environment for the given tasks, analogous to the process of humans motor skills acquisition. Accordingly, this paper reviews post-training strategies for VLA models through the lens of human motor learning, focusing on three dimensions: environments, embodiments, and tasks. A structured taxonomy is introduced aligned with human learning mechanisms: (1) enhancing environmental perception, (2) improving embodiment awareness, (3) deepening task comprehension, and (4) multi-component integration. Finally, key challenges and trends in post-training VLA models are identified, establishing a conceptual framework to guide future research. This work delivers both a comprehensive overview of current VLA model post-training methods from a human motor learning perspective and practical insights for VLA model development. (Project website: https://github.com/AoqunJin/Awesome-VLA-Post-Training)

