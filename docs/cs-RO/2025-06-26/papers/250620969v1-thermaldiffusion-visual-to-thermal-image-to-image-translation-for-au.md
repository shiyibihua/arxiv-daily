---
layout: default
title: ThermalDiffusion: Visual-to-Thermal Image-to-Image Translation for Autonomous Navigation
---

# ThermalDiffusion: Visual-to-Thermal Image-to-Image Translation for Autonomous Navigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20969" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20969v1</a>
  <a href="https://arxiv.org/pdf/2506.20969.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20969v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20969v1', 'ThermalDiffusion: Visual-to-Thermal Image-to-Image Translation for Autonomous Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shruti Bansal, Wenshan Wang, Yifei Liu, Parv Maheshwari

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

**å¤‡æ³¨**: Accepted at Thermal Infrared in Robotics (TIRO) Workshop, ICRA 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºThermalDiffusionä»¥è§£å†³çƒ­æˆåƒæ•°æ®ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `çƒ­æˆåƒ` `å›¾åƒè½¬æ¢` `æ¡ä»¶æ‰©æ•£æ¨¡å‹` `è‡ªä¸»å¯¼èˆª` `å¤šæ¨¡æ€æ•°æ®é›†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€æ•°æ®é›†åœ¨çƒ­æˆåƒå›¾åƒæ–¹é¢ä¸¥é‡ä¸è¶³ï¼Œé™åˆ¶äº†çƒ­æˆåƒç›¸æœºåœ¨æœºå™¨äººé¢†åŸŸçš„åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨æ¡ä»¶æ‰©æ•£æ¨¡å‹å°†RGBå›¾åƒè½¬æ¢ä¸ºçƒ­å›¾åƒçš„æ–¹æ³•ï¼Œæ—¨åœ¨åˆæˆçƒ­æˆåƒæ•°æ®ä»¥å¢å¼ºæ•°æ®é›†ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆç”Ÿæˆé«˜è´¨é‡çš„çƒ­å›¾åƒï¼Œæå‡äº†çƒ­æˆåƒåœ¨è‡ªä¸»å¯¼èˆªä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªä¸»ç³»ç»Ÿä¾èµ–ä¼ æ„Ÿå™¨æ¥ä¼°è®¡å‘¨å›´ç¯å¢ƒï¼Œä½†åœ¨å¤œé—´æˆ–æ¶åŠ£ç¯å¢ƒä¸‹ï¼Œçƒ­æˆåƒç›¸æœºèƒ½å¤Ÿæä¾›æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚æœ¬æ–‡èšç„¦äºçƒ­æˆåƒç›¸æœºåœ¨æœºå™¨äººå’Œè‡ªåŠ¨åŒ–ä¸­çš„åº”ç”¨ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨æ¡ä»¶æ‰©æ•£æ¨¡å‹å°†ç°æœ‰RGBå›¾åƒè½¬æ¢ä¸ºçƒ­å›¾åƒçš„æ–¹æ³•ï¼Œä»¥è§£å†³çƒ­æˆåƒæ•°æ®ä¸è¶³çš„é—®é¢˜ã€‚é€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œæ¨¡å‹èƒ½å¤Ÿå­¦ä¹ ç°å®ä¸–ç•Œç‰©ä½“çš„çƒ­ç‰¹æ€§ï¼Œä»è€Œå¢å¼ºç°æœ‰å¤šæ¨¡æ€æ•°æ®é›†ï¼Œä¿ƒè¿›çƒ­æˆåƒç›¸æœºçš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³çƒ­æˆåƒæ•°æ®ä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰çš„å¤šæ¨¡æ€æ•°æ®é›†ç¼ºä¹çƒ­æˆåƒå›¾åƒï¼Œé™åˆ¶äº†çƒ­æˆåƒç›¸æœºåœ¨è‡ªä¸»ç³»ç»Ÿä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œå°†ç°æœ‰çš„RGBå›¾åƒè½¬æ¢ä¸ºçƒ­å›¾åƒï¼Œåˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶å­¦ä¹ ç‰©ä½“çš„çƒ­ç‰¹æ€§ï¼Œä»è€Œç”Ÿæˆåˆæˆçš„çƒ­æˆåƒæ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¡ä»¶æ‰©æ•£æ¨¡å‹è®­ç»ƒå’Œçƒ­å›¾åƒç”Ÿæˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œå¯¹RGBå›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼Œç„¶åè®­ç»ƒæ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œæœ€åç”Ÿæˆçƒ­å›¾åƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºä½¿ç”¨æ¡ä»¶æ‰©æ•£æ¨¡å‹è¿›è¡Œå›¾åƒè½¬æ¢ï¼Œè¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰ç‰©ä½“çš„çƒ­ç‰¹æ€§ï¼Œä¸ä¼ ç»Ÿçš„å›¾åƒè½¬æ¢æ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰æ›´é«˜çš„ç”Ÿæˆè´¨é‡å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†è‡ªæ³¨æ„åŠ›æœºåˆ¶ä»¥å¢å¼ºç‰¹å¾å­¦ä¹ ï¼ŒæŸå¤±å‡½æ•°åˆ™ç»“åˆäº†é‡å»ºæŸå¤±å’Œå¯¹æŠ—æŸå¤±ï¼Œä»¥ç¡®ä¿ç”Ÿæˆå›¾åƒçš„è´¨é‡å’ŒçœŸå®æ„Ÿã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„ThermalDiffusionæ–¹æ³•åœ¨çƒ­å›¾åƒç”Ÿæˆè´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œç”Ÿæˆçš„çƒ­å›¾åƒåœ¨ç›®æ ‡è¯†åˆ«å’Œç¯å¢ƒæ„ŸçŸ¥ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§ï¼Œæå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ— äººé©¾é©¶ã€å®‰é˜²ç›‘æ§å’Œæœç´¢æ•‘æ´ç­‰åœºæ™¯ã€‚é€šè¿‡åˆæˆçƒ­æˆåƒæ•°æ®ï¼Œèƒ½å¤Ÿæå‡è‡ªä¸»ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ï¼Œå¢å¼ºå…¶å¯¹ç›®æ ‡çš„è¯†åˆ«å’Œå®šä½èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autonomous systems rely on sensors to estimate the environment around them. However, cameras, LiDARs, and RADARs have their own limitations. In nighttime or degraded environments such as fog, mist, or dust, thermal cameras can provide valuable information regarding the presence of objects of interest due to their heat signature. They make it easy to identify humans and vehicles that are usually at higher temperatures compared to their surroundings. In this paper, we focus on the adaptation of thermal cameras for robotics and automation, where the biggest hurdle is the lack of data. Several multi-modal datasets are available for driving robotics research in tasks such as scene segmentation, object detection, and depth estimation, which are the cornerstone of autonomous systems. However, they are found to be lacking in thermal imagery. Our paper proposes a solution to augment these datasets with synthetic thermal data to enable widespread and rapid adaptation of thermal cameras. We explore the use of conditional diffusion models to convert existing RGB images to thermal images using self-attention to learn the thermal properties of real-world objects.

