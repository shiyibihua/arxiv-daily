---
layout: default
title: WorldVLA: Towards Autoregressive Action World Model
---

# WorldVLA: Towards Autoregressive Action World Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21539" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21539v1</a>
  <a href="https://arxiv.org/pdf/2506.21539.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21539v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21539v1', 'WorldVLA: Towards Autoregressive Action World Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jun Cen, Chaohui Yu, Hangjie Yuan, Yuming Jiang, Siteng Huang, Jiayan Guo, Xin Li, Yibing Song, Hao Luo, Fan Wang, Deli Zhao, Hao Chen

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

**å¤‡æ³¨**: Code: https://github.com/alibaba-damo-academy/WorldVLA

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWorldVLAä»¥è§£å†³åŠ¨ä½œç”Ÿæˆä¸å›¾åƒç†è§£çš„ç»Ÿä¸€é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªå›å½’æ¨¡å‹` `åŠ¨ä½œç”Ÿæˆ` `å›¾åƒç†è§£` `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `æ³¨æ„åŠ›æœºåˆ¶` `ä¸–ç•Œæ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŠ¨ä½œç”Ÿæˆå’Œå›¾åƒç†è§£æ¨¡å‹é€šå¸¸æ˜¯ç‹¬ç«‹çš„ï¼Œç¼ºä¹æœ‰æ•ˆçš„èåˆï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚
2. WorldVLAé€šè¿‡å°†è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ä¸ä¸–ç•Œæ¨¡å‹ç»“åˆï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è‡ªå›å½’æ¡†æ¶ï¼Œå¢å¼ºäº†åŠ¨ä½œç”Ÿæˆä¸å›¾åƒç†è§£çš„ç›¸äº’ä½œç”¨ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWorldVLAåœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¶…è¶Šäº†ä¼ ç»Ÿæ¨¡å‹ï¼Œå¹¶é€šè¿‡æ³¨æ„åŠ›æ©ç ç­–ç•¥æ˜¾è‘—æå‡äº†åŠ¨ä½œç”Ÿæˆçš„å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†WorldVLAï¼Œè¿™æ˜¯ä¸€ç§è‡ªå›å½’åŠ¨ä½œä¸–ç•Œæ¨¡å‹ï¼Œæ—¨åœ¨ç»Ÿä¸€åŠ¨ä½œä¸å›¾åƒçš„ç†è§£å’Œç”Ÿæˆã€‚WorldVLAå°†è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ä¸ä¸–ç•Œæ¨¡å‹æ•´åˆä¸ºä¸€ä¸ªå•ä¸€æ¡†æ¶ã€‚è¯¥æ¨¡å‹é€šè¿‡ç»“åˆåŠ¨ä½œå’Œå›¾åƒç†è§£æ¥é¢„æµ‹æœªæ¥å›¾åƒï¼Œæ—¨åœ¨å­¦ä¹ ç¯å¢ƒçš„åŸºæœ¬ç‰©ç†è§„å¾‹ï¼Œä»è€Œæ”¹å–„åŠ¨ä½œç”Ÿæˆã€‚åŒæ—¶ï¼ŒåŠ¨ä½œæ¨¡å‹åŸºäºå›¾åƒè§‚å¯Ÿç”Ÿæˆåç»­åŠ¨ä½œï¼Œä¿ƒè¿›è§†è§‰ç†è§£ï¼Œå¹¶åè¿‡æ¥å¸®åŠ©ä¸–ç•Œæ¨¡å‹çš„è§†è§‰ç”Ÿæˆã€‚å®éªŒè¡¨æ˜ï¼ŒWorldVLAåœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†ç‹¬ç«‹çš„åŠ¨ä½œå’Œä¸–ç•Œæ¨¡å‹ï¼Œçªæ˜¾äº†ä¸¤è€…ä¹‹é—´çš„ç›¸äº’å¢å¼ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°ï¼Œåœ¨è‡ªå›å½’æ–¹å¼ç”ŸæˆåŠ¨ä½œåºåˆ—æ—¶ï¼ŒåŠ¨ä½œæ¨¡å‹çš„æ€§èƒ½ä¼šä¸‹é™ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºæ¨¡å‹åœ¨åŠ¨ä½œé¢„æµ‹ä¸Šçš„æœ‰é™æ³›åŒ–èƒ½åŠ›ï¼Œå¯¼è‡´æ—©æœŸåŠ¨ä½œçš„é”™è¯¯ä¼ æ’­åˆ°åç»­åŠ¨ä½œã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ³¨æ„åŠ›æ©ç ç­–ç•¥ï¼Œåœ¨ç”Ÿæˆå½“å‰åŠ¨ä½œæ—¶é€‰æ‹©æ€§åœ°æ©ç›–å…ˆå‰åŠ¨ä½œï¼Œä»è€Œåœ¨åŠ¨ä½œå—ç”Ÿæˆä»»åŠ¡ä¸­æ˜¾è‘—æé«˜äº†æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰åŠ¨ä½œç”Ÿæˆä¸å›¾åƒç†è§£æ¨¡å‹ä¹‹é—´çš„å­¤ç«‹æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ç¯å¢ƒæ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆèåˆåŠ¨ä½œä¸è§†è§‰ä¿¡æ¯ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šWorldVLAçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ä¸ä¸–ç•Œæ¨¡å‹æ•´åˆä¸ºä¸€ä¸ªè‡ªå›å½’æ¡†æ¶ï¼Œé€šè¿‡ç›¸äº’ä¿ƒè¿›çš„æ–¹å¼æå‡åŠ¨ä½œç”Ÿæˆå’Œå›¾åƒç†è§£çš„èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ ç¯å¢ƒçš„ç‰©ç†è§„å¾‹ï¼Œä»è€Œç”Ÿæˆæ›´å‡†ç¡®çš„åŠ¨ä½œå’Œå›¾åƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šWorldVLAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸–ç•Œæ¨¡å‹å’ŒåŠ¨ä½œæ¨¡å‹ã€‚ä¸–ç•Œæ¨¡å‹è´Ÿè´£åŸºäºå½“å‰çŠ¶æ€é¢„æµ‹æœªæ¥å›¾åƒï¼Œè€ŒåŠ¨ä½œæ¨¡å‹åˆ™æ ¹æ®å›¾åƒè§‚å¯Ÿç”Ÿæˆåç»­åŠ¨ä½œã€‚ä¸¤è€…é€šè¿‡ç›¸äº’åé¦ˆæœºåˆ¶è¿›è¡Œä¿¡æ¯äº¤äº’ï¼Œå½¢æˆé—­ç¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†æ³¨æ„åŠ›æ©ç ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨ç”Ÿæˆå½“å‰åŠ¨ä½œæ—¶é€‰æ‹©æ€§åœ°æ©ç›–å…ˆå‰åŠ¨ä½œï¼Œä»è€Œå‡å°‘é”™è¯¯ä¼ æ’­ï¼Œæ˜¾è‘—æå‡äº†åŠ¨ä½œç”Ÿæˆçš„æ€§èƒ½ã€‚è¿™ä¸€æ–¹æ³•åœ¨è‡ªå›å½’ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡åŠ¨ä½œç”Ÿæˆä¸å›¾åƒé¢„æµ‹çš„è¯¯å·®ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šå¼•å…¥äº†å¤šå±‚æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹é‡è¦ä¿¡æ¯çš„æ•æ‰èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒWorldVLAåœ¨å¤šä¸ªåŸºå‡†ä»»åŠ¡ä¸Šå‡ä¼˜äºä¼ ç»Ÿçš„ç‹¬ç«‹æ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨åŠ¨ä½œç”Ÿæˆä»»åŠ¡ä¸­ï¼Œä½¿ç”¨æ³¨æ„åŠ›æ©ç ç­–ç•¥åï¼Œæ¨¡å‹æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œæ˜¾è‘—æ”¹å–„äº†ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

WorldVLAçš„ç ”ç©¶æˆæœåœ¨æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡å®ç°æ›´é«˜æ•ˆçš„åŠ¨ä½œç”Ÿæˆå’Œç¯å¢ƒç†è§£ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæå‡æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å†³ç­–èƒ½åŠ›ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present WorldVLA, an autoregressive action world model that unifies action and image understanding and generation. Our WorldVLA intergrates Vision-Language-Action (VLA) model and world model in one single framework. The world model predicts future images by leveraging both action and image understanding, with the purpose of learning the underlying physics of the environment to improve action generation. Meanwhile, the action model generates the subsequent actions based on image observations, aiding in visual understanding and in turn helps visual generation of the world model. We demonstrate that WorldVLA outperforms standalone action and world models, highlighting the mutual enhancement between the world model and the action model. In addition, we find that the performance of the action model deteriorates when generating sequences of actions in an autoregressive manner. This phenomenon can be attributed to the model's limited generalization capability for action prediction, leading to the propagation of errors from earlier actions to subsequent ones. To address this issue, we propose an attention mask strategy that selectively masks prior actions during the generation of the current action, which shows significant performance improvement in the action chunk generation task.

