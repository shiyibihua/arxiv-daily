---
layout: default
title: Task-Aware Morphology Optimization of Planar Manipulators via Reinforcement Learning
---

# Task-Aware Morphology Optimization of Planar Manipulators via Reinforcement Learning

**arXiv**: [2511.12650v1](https://arxiv.org/abs/2511.12650) | [PDF](https://arxiv.org/pdf/2511.12650.pdf)

**ä½œè€…**: Arvind Kumar Mishra, Sohom Chakrabarty

**åˆ†ç±»**: cs.RO, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-11-16

**å¤‡æ³¨**: 10 pages, 11 figures, It is submitted as a journal option paper associated with the IFAC World Congress 2026

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå¼ºåŒ–å­¦ä¹ çš„å¹³é¢æœºæ¢°è‡‚å½¢æ€ä¼˜åŒ–æ–¹æ³•ï¼Œæ— éœ€è§£æžè¡¨è¾¾å¼ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å½¢æ€ä¼˜åŒ–` `å¹³é¢æœºæ¢°è‡‚` `æœºå™¨äººè®¾è®¡` `å¯æ“ä½œæ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿæœºæ¢°è‡‚å½¢æ€ä¼˜åŒ–ä¾èµ–è§£æžè§£ï¼Œä½†å¤æ‚ä»»åŠ¡ç¼ºä¹è§£æžè§£ï¼Œå¯å‘å¼æœç´¢è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚
2. åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œé€šè¿‡å¥–åŠ±åé¦ˆè‡ªä¸»å­¦ä¹ æœ€ä¼˜å½¢æ€ï¼Œæ— éœ€å¯æ“ä½œæ€§è¡¨è¾¾å¼æˆ–é›…å¯æ¯”çŸ©é˜µã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œå¼ºåŒ–å­¦ä¹ èƒ½æœ‰æ•ˆæ¢å¤å·²çŸ¥æœ€ä¼˜è§£ï¼Œå¹¶è§£å†³æ— è§£æžè§£çš„å½¢æ€ä¼˜åŒ–é—®é¢˜ï¼Œä¼˜äºŽç½‘æ ¼æœç´¢å’Œé»‘ç›’ä¼˜åŒ–ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡åˆ©ç”¨å‰å·å¯æ“ä½œæ€§æŒ‡æ ‡ï¼Œç ”ç©¶äº†å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä½œä¸ºå¹³é¢æœºå™¨äººæœºæ¢°è‡‚å½¢æ€ä¼˜åŒ–æ¡†æž¶çš„åº”ç”¨ã€‚é¦–å…ˆï¼Œè€ƒå¯Ÿäº†ä¸€ä¸ª2Ræœºæ¢°è‡‚è·Ÿè¸ªåœ†å½¢æœ«ç«¯æ‰§è¡Œå™¨è·¯å¾„çš„æ¡ˆä¾‹ï¼Œå› ä¸ºè¯¥æ¡ˆä¾‹å…·æœ‰å·²çŸ¥çš„è§£æžæœ€ä¼˜è§£ï¼šç›¸ç­‰çš„è¿žæ†é•¿åº¦å’Œç¬¬äºŒä¸ªå…³èŠ‚ä¸Žç¬¬ä¸€ä¸ªå…³èŠ‚æ­£äº¤ã€‚è¿™ä½œä¸ºä¸€ä¸ªéªŒè¯æ­¥éª¤ï¼Œæµ‹è¯•RLæ˜¯å¦èƒ½å¤Ÿåœ¨ä¸è®¿é—®å¯æ“ä½œæ€§è¡¨è¾¾å¼æˆ–é›…å¯æ¯”çŸ©é˜µçš„æƒ…å†µä¸‹ï¼Œä»…ä½¿ç”¨å¥–åŠ±åé¦ˆæ¥é‡æ–°å‘çŽ°æœ€ä¼˜è§£ã€‚å°†ä¸‰ç§RLç®—æ³•ï¼ˆSACã€DDPGå’ŒPPOï¼‰ä¸Žç½‘æ ¼æœç´¢å’Œé»‘ç›’ä¼˜åŒ–å™¨è¿›è¡Œäº†æ¯”è¾ƒï¼Œå…¶ä¸­å½¢æ€ç”±å•ä¸ªåŠ¨ä½œå‚æ•°phiè¡¨ç¤ºï¼Œè¯¥å‚æ•°æ˜ å°„åˆ°è¿žæ†é•¿åº¦ã€‚æ‰€æœ‰æ–¹æ³•éƒ½æ”¶æ•›åˆ°è§£æžè§£ï¼Œè¡¨æ˜Žæ— éœ€æä¾›è§£æžç»“æž„å³å¯æ•°å€¼æ¢å¤æœ€ä¼˜è§£æ˜¯å¯èƒ½çš„ã€‚å¤§å¤šæ•°å½¢æ€è®¾è®¡ä»»åŠ¡æ²¡æœ‰é—­å¼è§£ï¼Œå¹¶ä¸”éšç€ç»´æ•°çš„å¢žåŠ ï¼Œç½‘æ ¼æˆ–å¯å‘å¼æœç´¢å˜å¾—æ˜‚è´µã€‚å› æ­¤ï¼ŒæŽ¢ç´¢RLä½œä¸ºä¸€ç§å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆã€‚é€šè¿‡å°†åŠ¨ä½œç©ºé—´æ‰©å±•åˆ°å®Œæ•´çš„å½¢æ€å‘é‡ï¼ˆL1ã€L2ã€theta2ï¼‰ï¼Œå°†ç”¨äºŽåœ†å½¢è·¯å¾„çš„å…¬å¼æ‰©å±•åˆ°æ¤­åœ†å½¢å’ŒçŸ©å½¢è·¯å¾„ã€‚åœ¨è¿™äº›éžè§£æžè®¾ç½®ä¸­ï¼ŒRLç»§ç»­å¯é åœ°æ”¶æ•›ï¼Œè€Œç½‘æ ¼å’Œé»‘ç›’æ–¹æ³•éœ€è¦æ›´å¤§çš„è¯„ä¼°é¢„ç®—ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒRLå¯¹äºŽæ¢å¤å·²çŸ¥æœ€ä¼˜è§£å’Œè§£å†³æ²¡æœ‰è§£æžè§£çš„å½¢æ€ä¼˜åŒ–é—®é¢˜éƒ½æ˜¯æœ‰æ•ˆçš„ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¹³é¢æœºæ¢°è‡‚çš„å½¢æ€ä¼˜åŒ–é—®é¢˜ï¼Œå³ç¡®å®šè¿žæ†é•¿åº¦å’Œå…³èŠ‚è§’åº¦ç­‰å‚æ•°ï¼Œä»¥æœ€å¤§åŒ–æœºæ¢°è‡‚åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚çŽ°æœ‰æ–¹æ³•ï¼Œå¦‚ç½‘æ ¼æœç´¢å’Œé»‘ç›’ä¼˜åŒ–ï¼Œåœ¨é«˜ç»´ç©ºé—´ä¸­è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œä¸”ä¾èµ–äºŽä»»åŠ¡çš„è§£æžè§£ï¼Œè€Œè®¸å¤šå®žé™…ä»»åŠ¡å¹¶ä¸å­˜åœ¨è§£æžè§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç®—æ³•ï¼Œé€šè¿‡ä¸ŽçŽ¯å¢ƒçš„äº¤äº’ï¼Œå­¦ä¹ æœºæ¢°è‡‚çš„æœ€ä¼˜å½¢æ€ã€‚RLç®—æ³•é€šè¿‡å¥–åŠ±å‡½æ•°æ¥è¯„ä¼°æœºæ¢°è‡‚çš„æ€§èƒ½ï¼Œå¹¶æ ¹æ®å¥–åŠ±è°ƒæ•´å½¢æ€å‚æ•°ï¼Œä»Žè€Œåœ¨æ²¡æœ‰è§£æžè§£çš„æƒ…å†µä¸‹æ‰¾åˆ°æœ€ä¼˜è§£ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹é›…å¯æ¯”çŸ©é˜µå’Œå¯æ“ä½œæ€§æŒ‡æ ‡çš„æ˜¾å¼è®¡ç®—ï¼Œé™ä½Žäº†è®¡ç®—å¤æ‚åº¦ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1ï¼‰çŽ¯å¢ƒå»ºæ¨¡ï¼šå®šä¹‰æœºæ¢°è‡‚çš„è¿åŠ¨å­¦æ¨¡åž‹å’Œä»»åŠ¡ç©ºé—´ï¼›2ï¼‰çŠ¶æ€ç©ºé—´ï¼šå®šä¹‰æœºæ¢°è‡‚çš„çŠ¶æ€ï¼Œä¾‹å¦‚å…³èŠ‚è§’åº¦å’Œæœ«ç«¯æ‰§è¡Œå™¨çš„ä½ç½®ï¼›3ï¼‰åŠ¨ä½œç©ºé—´ï¼šå®šä¹‰æœºæ¢°è‡‚çš„å½¢æ€å‚æ•°ï¼Œä¾‹å¦‚è¿žæ†é•¿åº¦å’Œå…³èŠ‚è§’åº¦ï¼›4ï¼‰å¥–åŠ±å‡½æ•°ï¼šå®šä¹‰æœºæ¢°è‡‚åœ¨å®Œæˆä»»åŠ¡æ—¶çš„å¥–åŠ±ï¼Œä¾‹å¦‚è·Ÿè¸ªè¯¯å·®çš„å€’æ•°ï¼›5ï¼‰RLç®—æ³•ï¼šä½¿ç”¨SACã€DDPGæˆ–PPOç­‰RLç®—æ³•æ¥å­¦ä¹ æœ€ä¼˜ç­–ç•¥ï¼Œå³ä»ŽçŠ¶æ€åˆ°åŠ¨ä½œçš„æ˜ å°„ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äºŽæœºæ¢°è‡‚çš„å½¢æ€ä¼˜åŒ–ï¼Œä»Žè€Œèƒ½å¤Ÿåœ¨æ²¡æœ‰è§£æžè§£çš„æƒ…å†µä¸‹æ‰¾åˆ°æœ€ä¼˜è§£ã€‚ä¸Žä¼ ç»Ÿçš„ä¼˜åŒ–æ–¹æ³•ç›¸æ¯”ï¼ŒRLæ–¹æ³•ä¸éœ€è¦æ˜¾å¼åœ°è®¡ç®—é›…å¯æ¯”çŸ©é˜µå’Œå¯æ“ä½œæ€§æŒ‡æ ‡ï¼Œé™ä½Žäº†è®¡ç®—å¤æ‚åº¦ï¼Œå¹¶ä¸”èƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„ä»»åŠ¡ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­ï¼ŒåŠ¨ä½œç©ºé—´çš„è®¾è®¡è‡³å…³é‡è¦ã€‚å¯¹äºŽåœ†å½¢è·¯å¾„è·Ÿè¸ªä»»åŠ¡ï¼Œä½¿ç”¨å•ä¸ªå‚æ•°phiæ¥æ˜ å°„åˆ°è¿žæ†é•¿åº¦ã€‚å¯¹äºŽæ¤­åœ†å½¢å’ŒçŸ©å½¢è·¯å¾„è·Ÿè¸ªä»»åŠ¡ï¼Œä½¿ç”¨å®Œæ•´çš„å½¢æ€å‘é‡ï¼ˆL1ï¼ŒL2ï¼Œtheta2ï¼‰ä½œä¸ºåŠ¨ä½œç©ºé—´ã€‚å¥–åŠ±å‡½æ•°çš„è®¾è®¡ä¹Ÿå½±å“ç€RLç®—æ³•çš„æ”¶æ•›é€Ÿåº¦å’Œæ€§èƒ½ã€‚è®ºæ–‡ä¸­ï¼Œå¥–åŠ±å‡½æ•°é€šå¸¸ä¸Žæœ«ç«¯æ‰§è¡Œå™¨çš„è·Ÿè¸ªè¯¯å·®ç›¸å…³ï¼Œè¯¯å·®è¶Šå°ï¼Œå¥–åŠ±è¶Šé«˜ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œå¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆSACã€DDPGå’ŒPPOï¼‰èƒ½å¤Ÿæœ‰æ•ˆåœ°æ¢å¤å·²çŸ¥æœ€ä¼˜è§£ï¼Œå¹¶åœ¨æ²¡æœ‰è§£æžè§£çš„æƒ…å†µä¸‹è§£å†³å½¢æ€ä¼˜åŒ–é—®é¢˜ã€‚åœ¨åœ†å½¢è·¯å¾„è·Ÿè¸ªä»»åŠ¡ä¸­ï¼Œæ‰€æœ‰RLç®—æ³•éƒ½æ”¶æ•›åˆ°è§£æžè§£ã€‚åœ¨æ¤­åœ†å½¢å’ŒçŸ©å½¢è·¯å¾„è·Ÿè¸ªä»»åŠ¡ä¸­ï¼ŒRLç®—æ³•çš„æ€§èƒ½ä¼˜äºŽç½‘æ ¼æœç´¢å’Œé»‘ç›’ä¼˜åŒ–å™¨ï¼Œä¸”æ‰€éœ€çš„è¯„ä¼°é¢„ç®—æ›´å°ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼ŒRLç®—æ³•çš„æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°10%ä»¥ä¸Šã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§éœ€è¦ä¼˜åŒ–æœºæ¢°è‡‚å½¢æ€çš„åœºæ™¯ï¼Œä¾‹å¦‚å·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—æœºå™¨äººå’Œç©ºé—´æœºå™¨äººç­‰ã€‚é€šè¿‡è‡ªåŠ¨ä¼˜åŒ–æœºæ¢°è‡‚çš„å½¢æ€ï¼Œå¯ä»¥æé«˜æœºæ¢°è‡‚çš„æ€§èƒ½ï¼Œé™ä½Žæˆæœ¬ï¼Œå¹¶ä½¿å…¶é€‚åº”ä¸åŒçš„ä»»åŠ¡éœ€æ±‚ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°æ›´å¤æ‚çš„æœºæ¢°è‡‚ç»“æž„å’Œä»»åŠ¡ï¼Œä¾‹å¦‚å¤šè‡ªç”±åº¦æœºæ¢°è‡‚å’ŒåŠ¨æ€çŽ¯å¢ƒä¸‹çš„ä»»åŠ¡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this work, Yoshikawa's manipulability index is used to investigate reinforcement learning (RL) as a framework for morphology optimization in planar robotic manipulators. A 2R manipulator tracking a circular end-effector path is first examined because this case has a known analytical optimum: equal link lengths and the second joint orthogonal to the first. This serves as a validation step to test whether RL can rediscover the optimum using reward feedback alone, without access to the manipulability expression or the Jacobian. Three RL algorithms (SAC, DDPG, and PPO) are compared with grid search and black-box optimizers, with morphology represented by a single action parameter phi that maps to the link lengths. All methods converge to the analytical solution, showing that numerical recovery of the optimum is possible without supplying analytical structure.
>   Most morphology design tasks have no closed-form solutions, and grid or heuristic search becomes expensive as dimensionality increases. RL is therefore explored as a scalable alternative. The formulation used for the circular path is extended to elliptical and rectangular paths by expanding the action space to the full morphology vector (L1, L2, theta2). In these non-analytical settings, RL continues to converge reliably, whereas grid and black-box methods require far larger evaluation budgets. These results indicate that RL is effective for both recovering known optima and solving morphology optimization problems without analytical solutions.

