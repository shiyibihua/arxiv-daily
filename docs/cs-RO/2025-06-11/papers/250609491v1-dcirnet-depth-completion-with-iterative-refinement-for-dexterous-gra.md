---
layout: default
title: DCIRNet: Depth Completion with Iterative Refinement for Dexterous Grasping of Transparent and Reflective Objects
---

# DCIRNet: Depth Completion with Iterative Refinement for Dexterous Grasping of Transparent and Reflective Objects

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09491" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09491v1</a>
  <a href="https://arxiv.org/pdf/2506.09491.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09491v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09491v1', 'DCIRNet: Depth Completion with Iterative Refinement for Dexterous Grasping of Transparent and Reflective Objects')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Guanghu Xie, Zhiduo Jiang, Yonglong Zhang, Yang Liu, Zongwu Xie, Baoshi Cao, Hong Liu

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDCIRNetä»¥è§£å†³é€æ˜å’Œåå°„ç‰©ä½“çš„æ·±åº¦è¡¥å…¨é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ·±åº¦è¡¥å…¨` `å¤šæ¨¡æ€èåˆ` `ç‰¹å¾æå–` `æœºå™¨äººæŠ“å–` `é€æ˜ç‰©ä½“` `åå°„ç‰©ä½“` `æ·±åº¦ä¼°è®¡` `è§†è§‰ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ·±åº¦ä¼ æ„Ÿå™¨åœ¨å¤„ç†é€æ˜å’Œåå°„ç‰©ä½“æ—¶é¢ä¸´ä¸¥é‡çš„æ·±åº¦ä¼°è®¡ä¸å‡†ç¡®é—®é¢˜ï¼Œå½±å“åç»­è§†è§‰ä»»åŠ¡çš„è¡¨ç°ã€‚
2. DCIRNeté€šè¿‡èåˆRGBå›¾åƒå’Œæ·±åº¦å›¾ï¼Œé‡‡ç”¨å¤šæ¨¡æ€ç‰¹å¾èåˆæ¨¡å—å’Œå¤šé˜¶æ®µç›‘ç£ç­–ç•¥ï¼Œæå‡æ·±åº¦è¡¥å…¨æ•ˆæœã€‚
3. åœ¨å…¬å¼€æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒDCIRNetçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒæŠ“å–æˆåŠŸç‡æ˜¾è‘—æé«˜ï¼ŒéªŒè¯äº†å…¶å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é€æ˜å’Œåå°„ç‰©ä½“åœ¨æ—¥å¸¸ç¯å¢ƒä¸­å¯¹æ·±åº¦ä¼ æ„Ÿå™¨æ„æˆäº†é‡å¤§æŒ‘æˆ˜ï¼Œå› å…¶ç‹¬ç‰¹çš„è§†è§‰ç‰¹æ€§ï¼Œå¦‚é•œé¢åå°„å’Œå…‰ä¼ è¾“ï¼Œå¯¼è‡´æ·±åº¦ä¼°è®¡ä¸å®Œæ•´æˆ–ä¸å‡†ç¡®ï¼Œä»è€Œä¸¥é‡å½±å“åŸºäºå‡ ä½•çš„è§†è§‰ä»»åŠ¡ã€‚ä¸ºäº†è§£å†³é€æ˜å’Œåå°„ç‰©ä½“çš„æ·±åº¦ä¿¡æ¯ç¼ºå¤±é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†DCIRNetï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„å¤šæ¨¡æ€æ·±åº¦è¡¥å…¨ç½‘ç»œï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•´åˆRGBå›¾åƒå’Œæ·±åº¦å›¾ä»¥æå‡æ·±åº¦ä¼°è®¡è´¨é‡ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†åˆ›æ–°çš„å¤šæ¨¡æ€ç‰¹å¾èåˆæ¨¡å—ï¼Œæå–RGBå›¾åƒå’Œä¸å®Œæ•´æ·±åº¦å›¾ä¹‹é—´çš„äº’è¡¥ä¿¡æ¯ï¼Œå¹¶é‡‡ç”¨å¤šé˜¶æ®µç›‘ç£å’Œæ·±åº¦ç²¾ç‚¼ç­–ç•¥ï¼Œé€æ­¥æ”¹å–„æ·±åº¦è¡¥å…¨ï¼Œå‡è½»ç‰©ä½“è¾¹ç•Œæ¨¡ç³Šçš„é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDCIRNetåœ¨é€æ˜å’Œåå°„ç‰©ä½“çš„æŠ“å–æˆåŠŸç‡ä¸Šæé«˜äº†44%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é€æ˜å’Œåå°„ç‰©ä½“çš„æ·±åº¦ä¿¡æ¯ç¼ºå¤±é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¿™äº›ç‰©ä½“æ—¶ï¼Œå› å…¶ç‰¹æ®Šçš„è§†è§‰ç‰¹æ€§ï¼Œå¯¼è‡´æ·±åº¦ä¼°è®¡ç»“æœä¸å®Œæ•´æˆ–ä¸å‡†ç¡®ï¼Œå½±å“åç»­çš„è§†è§‰ä»»åŠ¡å¦‚ç‰©ä½“è¯†åˆ«å’Œæœºå™¨äººæ“ä½œã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDCIRNetçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¤šæ¨¡æ€èåˆRGBå›¾åƒä¸æ·±åº¦å›¾ï¼Œæå–äº’è¡¥ä¿¡æ¯ï¼Œä»è€Œæå‡æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚é€šè¿‡å¼•å…¥å¤šé˜¶æ®µçš„ç›‘ç£å’Œæ·±åº¦ç²¾ç‚¼ç­–ç•¥ï¼Œé€æ­¥æ”¹å–„æ·±åº¦è¡¥å…¨æ•ˆæœï¼Œå°¤å…¶æ˜¯åœ¨ç‰©ä½“è¾¹ç•Œçš„æ¸…æ™°åº¦ä¸Šã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDCIRNetçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯å¤šæ¨¡æ€ç‰¹å¾èåˆæ¨¡å—ï¼Œç”¨äºæå–RGBå›¾åƒå’Œæ·±åº¦å›¾çš„ç‰¹å¾ï¼›å…¶æ¬¡æ˜¯å¤šé˜¶æ®µç›‘ç£æ¨¡å—ï¼Œé€šè¿‡é€æ­¥ä¼˜åŒ–æ·±åº¦ä¼°è®¡ï¼›æœ€åæ˜¯æ·±åº¦ç²¾ç‚¼æ¨¡å—ï¼Œä¸“æ³¨äºæ”¹å–„ç‰©ä½“è¾¹ç•Œçš„æ¸…æ™°åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†å¤šæ¨¡æ€ç‰¹å¾èåˆæ¨¡å—å’Œå¤šé˜¶æ®µç›‘ç£ç­–ç•¥ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€æ¨¡æ€å¤„ç†æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ï¼Œæ˜¾è‘—æå‡äº†æ·±åº¦è¡¥å…¨çš„æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œè®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡RGBå›¾åƒå’Œæ·±åº¦å›¾çš„è´¡çŒ®ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿ç‰¹å¾æå–çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒDCIRNetåœ¨é€æ˜å’Œåå°„ç‰©ä½“çš„æŠ“å–ä»»åŠ¡ä¸­å®ç°äº†44%çš„æˆåŠŸç‡æå‡ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½ä¼˜åŠ¿ã€‚è¿™ä¸€ç»“æœéªŒè¯äº†æ¨¡å‹åœ¨å¤æ‚è§†è§‰ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§å’Œå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DCIRNetçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æœºå™¨äººæŠ“å–ã€å¢å¼ºç°å®å’Œè‡ªåŠ¨é©¾é©¶ç­‰åœºæ™¯ä¸­ã€‚é€šè¿‡æé«˜é€æ˜å’Œåå°„ç‰©ä½“çš„æ·±åº¦ä¼°è®¡ç²¾åº¦ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è¿™äº›ç³»ç»Ÿçš„æ“ä½œèƒ½åŠ›å’Œå®‰å…¨æ€§ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Transparent and reflective objects in everyday environments pose significant challenges for depth sensors due to their unique visual properties, such as specular reflections and light transmission. These characteristics often lead to incomplete or inaccurate depth estimation, which severely impacts downstream geometry-based vision tasks, including object recognition, scene reconstruction, and robotic manipulation. To address the issue of missing depth information in transparent and reflective objects, we propose DCIRNet, a novel multimodal depth completion network that effectively integrates RGB images and depth maps to enhance depth estimation quality. Our approach incorporates an innovative multimodal feature fusion module designed to extract complementary information between RGB images and incomplete depth maps. Furthermore, we introduce a multi-stage supervision and depth refinement strategy that progressively improves depth completion and effectively mitigates the issue of blurred object boundaries. We integrate our depth completion model into dexterous grasping frameworks and achieve a $44\%$ improvement in the grasp success rate for transparent and reflective objects. We conduct extensive experiments on public datasets, where DCIRNet demonstrates superior performance. The experimental results validate the effectiveness of our approach and confirm its strong generalization capability across various transparent and reflective objects.

