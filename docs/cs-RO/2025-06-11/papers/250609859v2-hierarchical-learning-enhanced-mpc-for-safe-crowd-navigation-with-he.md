---
layout: default
title: Hierarchical Learning-Enhanced MPC for Safe Crowd Navigation with Heterogeneous Constraints
---

# Hierarchical Learning-Enhanced MPC for Safe Crowd Navigation with Heterogeneous Constraints

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09859" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09859v2</a>
  <a href="https://arxiv.org/pdf/2506.09859.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09859v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09859v2', 'Hierarchical Learning-Enhanced MPC for Safe Crowd Navigation with Heterogeneous Constraints')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Huajian Liu, Yixuan Feng, Wei Dong, Kunpeng Fan, Chao Wang, Yongzhuo Gao

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11 (æ›´æ–°: 2025-07-23)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå±‚æ¬¡å­¦ä¹ å¢å¼ºçš„MPCä»¥è§£å†³åŠ¨æ€ç¯å¢ƒä¸­çš„å®‰å…¨äººç¾¤å¯¼èˆªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æœºå™¨äººå¯¼èˆª` `å›¾ç¥ç»ç½‘ç»œ` `å¼ºåŒ–å­¦ä¹ ` `åŠ¨æ€ç¯å¢ƒ` `è·¯å¾„è§„åˆ’` `å¢é‡åŠ¨ä½œå±è”½` `ç‰¹æƒå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€ç¯å¢ƒä¸­è¿›è¡Œå®‰å…¨å¯¼èˆªæ—¶ï¼Œå¾€å¾€é¢ä¸´é«˜ä¿çœŸä»¿çœŸç¯å¢ƒä¾èµ–å’Œè®¡ç®—æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºçš„å±‚æ¬¡æ¡†æ¶ç»“åˆå›¾ç¥ç»ç½‘ç»œå’Œæ—¶ç©ºè·¯å¾„æœç´¢æ¨¡å—ï¼Œæœ‰æ•ˆè§£å†³äº†åŠ¨æ€ç¯å¢ƒä¸­çš„å¯¼èˆªé—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†å±€éƒ¨è§„åˆ’çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å±‚æ¬¡æ¡†æ¶ï¼Œç”¨äºåœ¨å…·æœ‰å¼‚æ„çº¦æŸçš„åŠ¨æ€ç¯å¢ƒä¸­è¿›è¡Œæœºå™¨äººå¯¼èˆªã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„å›¾ç¥ç»ç½‘ç»œï¼Œæ¥é«˜æ•ˆä¼°è®¡æœºå™¨äººçš„æˆæœ¬å‡½æ•°ï¼Œå¹¶å°†å…¶å½¢å¼åŒ–ä¸ºå±€éƒ¨ç›®æ ‡æ¨èã€‚æ¥ç€ï¼Œé‡‡ç”¨è€ƒè™‘è¿åŠ¨å­¦çº¦æŸçš„æ—¶ç©ºè·¯å¾„æœç´¢æ¨¡å—ï¼Œç”Ÿæˆå‚è€ƒè½¨è¿¹ä»¥è§£å†³ç”¨äºæ˜¾å¼çº¦æŸæ‰§è¡Œçš„éå‡¸ä¼˜åŒ–é—®é¢˜ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¢é‡åŠ¨ä½œå±è”½æœºåˆ¶å’Œç‰¹æƒå­¦ä¹ ç­–ç•¥ï¼Œå®ç°äº†æ‰€æè§„åˆ’å™¨çš„ç«¯åˆ°ç«¯è®­ç»ƒã€‚ä»¿çœŸå’Œå®é™…å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåº”å¯¹å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­çš„å±€éƒ¨è§„åˆ’ï¼Œè¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä¸ç°æœ‰çš„å­¦ä¹ -ä¼˜åŒ–æ··åˆæ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ¶ˆé™¤äº†å¯¹é«˜ä¿çœŸä»¿çœŸç¯å¢ƒçš„ä¾èµ–ï¼Œåœ¨è®¡ç®—æ•ˆç‡å’Œè®­ç»ƒå¯æ‰©å±•æ€§æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººåœ¨åŠ¨æ€ç¯å¢ƒä¸­è¿›è¡Œå®‰å…¨å¯¼èˆªæ—¶çš„å±€éƒ¨è§„åˆ’é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–é«˜ä¿çœŸä»¿çœŸç¯å¢ƒï¼Œå¯¼è‡´è®¡ç®—æ•ˆç‡ä½ä¸‹å’Œè®­ç»ƒéš¾åº¦å¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºçš„å±‚æ¬¡æ¡†æ¶é€šè¿‡å›¾ç¥ç»ç½‘ç»œä¼°è®¡æˆæœ¬å‡½æ•°ï¼Œå¹¶ç»“åˆæ—¶ç©ºè·¯å¾„æœç´¢æ¨¡å—ï¼Œç”Ÿæˆå‚è€ƒè½¨è¿¹ï¼Œä»è€Œæœ‰æ•ˆåº”å¯¹å¤æ‚çš„åŠ¨æ€çº¦æŸã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å›¾ç¥ç»ç½‘ç»œç”¨äºæˆæœ¬ä¼°è®¡ã€æ—¶ç©ºè·¯å¾„æœç´¢æ¨¡å—ç”¨äºè½¨è¿¹ç”Ÿæˆï¼Œä»¥åŠå¢é‡åŠ¨ä½œå±è”½æœºåˆ¶å’Œç‰¹æƒå­¦ä¹ ç­–ç•¥ä»¥å®ç°ç«¯åˆ°ç«¯è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥å¢é‡åŠ¨ä½œå±è”½æœºåˆ¶å’Œç‰¹æƒå­¦ä¹ ç­–ç•¥ï¼Œä½¿å¾—è§„åˆ’å™¨èƒ½å¤Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­é«˜æ•ˆè®­ç»ƒï¼Œè€Œæ— éœ€ä¾èµ–é«˜ä¿çœŸä»¿çœŸã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨å›¾ç¥ç»ç½‘ç»œè¿›è¡Œæˆæœ¬ä¼°è®¡ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡è€ƒè™‘äº†è¿åŠ¨å­¦çº¦æŸï¼Œç¡®ä¿ç”Ÿæˆçš„è½¨è¿¹ç¬¦åˆå®é™…è¿åŠ¨èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­çš„å±€éƒ¨è§„åˆ’ä»»åŠ¡ä¸­ï¼Œè¾ƒç°æœ‰åŸºçº¿æ–¹æ³•æå‡äº†çº¦20%çš„æ•ˆç‡ï¼Œä¸”åœ¨å¤šç§åœºæ™¯ä¸‹å‡è¡¨ç°å‡ºè‰²ï¼Œå±•ç¤ºäº†è¾ƒå¼ºçš„é€‚åº”æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ™ºèƒ½äº¤é€šã€æ— äººé©¾é©¶ã€æœºå™¨äººåä½œç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡äººæœºåä½œçš„å®‰å…¨æ€§å’Œæ•ˆç‡ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„å®é™…åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this paper, we propose a novel hierarchical framework for robot navigation in dynamic environments with heterogeneous constraints. Our approach leverages a graph neural network trained via reinforcement learning (RL) to efficiently estimate the robot's cost-to-go, formulated as local goal recommendations. A spatio-temporal path-searching module, which accounts for kinematic constraints, is then employed to generate a reference trajectory to facilitate solving the non-convex optimization problem used for explicit constraint enforcement. More importantly, we introduce an incremental action-masking mechanism and a privileged learning strategy, enabling end-to-end training of the proposed planner. Both simulation and real-world experiments demonstrate that the proposed method effectively addresses local planning in complex dynamic environments, achieving state-of-the-art (SOTA) performance. Compared with existing learning-optimization hybrid methods, our approach eliminates the dependency on high-fidelity simulation environments, offering significant advantages in computational efficiency and training scalability. The code will be released as open-source upon acceptance of the paper.

