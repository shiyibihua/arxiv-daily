---
layout: default
title: 3D Affordance Keypoint Detection for Robotic Manipulation
---

# 3D Affordance Keypoint Detection for Robotic Manipulation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.22195" target="_blank" class="toolbar-btn">arXiv: 2511.22195v1</a>
    <a href="https://arxiv.org/pdf/2511.22195.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.22195v1" 
            onclick="toggleFavorite(this, '2511.22195v1', '3D Affordance Keypoint Detection for Robotic Manipulation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Zhiyang Liu, Ruiteng Zhao, Lei Zhou, Chengran Yuan, Yuwei Wu, Sheng Guo, Zhengshen Zhang, Chenchen Liu, Marcelo H Ang

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-27

**Â§áÊ≥®**: Accepted to IROS 2024

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫é3DÂÖ≥ÈîÆÁÇπÁöÑFAKP-NetÔºåÁî®‰∫éÊú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÁöÑÂèØ‰æõÊÄßÁêÜËß£**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Êìç‰Ωú` `ÂèØ‰æõÊÄßÊ£ÄÊµã` `3DÂÖ≥ÈîÆÁÇπ` `RGB-DËûçÂêà` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰º†ÁªüÂèØ‰æõÊÄßÊ£ÄÊµã‰æßÈáç‰∫éËØ≠‰πâÂàÜÂâ≤ÔºåÁº∫‰πèÂØπÁâ©‰ΩìÊìç‰Ωú‰ΩçÁΩÆ„ÄÅÊñπÂêëÂíåËåÉÂõ¥ÁöÑÁ≤æÁªÜÂåñÊåáÂØº„ÄÇ
2. FAKP-NetÈÄöËøáÂºïÂÖ•3DÂÖ≥ÈîÆÁÇπÂõõÂÖÉÁªÑÔºåËûçÂêàRGBÂíåÊ∑±Â∫¶‰ø°ÊÅØÔºåÊèê‰æõÊõ¥ÂÖ®Èù¢ÁöÑÂèØ‰æõÊÄßÁêÜËß£„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåFAKP-NetÂú®ÂèØ‰æõÊÄßÂàÜÂâ≤ÂíåÂÖ≥ÈîÆÁÇπÊ£ÄÊµã‰ªªÂä°‰∏≠Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂Âú®ÁúüÂÆûÂú∫ÊôØ‰∏≠È™åËØÅ‰∫ÜÂÖ∂ÂèØÈù†ÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂü∫‰∫éÂèØ‰æõÊÄßÁöÑÊú∫Âô®‰∫∫Êìç‰ΩúÊñπÊ≥ïÔºåÈÄöËøáÂºïÂÖ•3DÂÖ≥ÈîÆÁÇπÊù•Â¢ûÂº∫ÂØπÁâ©‰ΩìÈÉ®‰ª∂ÂäüËÉΩÁöÑÁêÜËß£„ÄÇËØ•ÊñπÊ≥ïÁõ¥Êé•Êèê‰æõÂÖ≥‰∫éÁâ©‰ΩìÊΩúÂú®Áî®ÈÄîÁöÑ‰ø°ÊÅØÔºå‰ª•ÂèäÊú∫Ê¢∞ËáÇÂ∫îËØ•Âú®‰ΩïÂ§Ñ‰ª•ÂèäÂ¶Ç‰ΩïËøõË°åÊìç‰ΩúÁöÑÊåáÂØºÔºåËÄå‰º†ÁªüÊñπÊ≥ïÂ∞ÜÂèØ‰æõÊÄßÊ£ÄÊµãËßÜ‰∏∫ËØ≠‰πâÂàÜÂâ≤‰ªªÂä°Ôºå‰ªÖÂÖ≥Ê≥®ÂõûÁ≠î‚ÄúÊòØ‰ªÄ‰πà‚ÄùÁöÑÈóÆÈ¢ò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™Â∑ÆË∑ùÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éËûçÂêàÁöÑÂèØ‰æõÊÄßÂÖ≥ÈîÆÁÇπÁΩëÁªúÔºàFAKP-NetÔºâÔºåÈÄöËøáÂºïÂÖ•3DÂÖ≥ÈîÆÁÇπÂõõÂÖÉÁªÑÔºåÂà©Áî®RGBÂíåÊ∑±Â∫¶ÂõæÂÉèÁöÑÂçèÂêåÊΩúÂäõÔºåÊèê‰æõÂÖ≥‰∫éÊâßË°å‰ΩçÁΩÆ„ÄÅÊñπÂêëÂíåËåÉÂõ¥ÁöÑ‰ø°ÊÅØ„ÄÇÂü∫ÂáÜÊµãËØïË°®ÊòéÔºåFAKP-NetÂú®ÂèØ‰æõÊÄßÂàÜÂâ≤‰ªªÂä°ÂíåÂÖ≥ÈîÆÁÇπÊ£ÄÊµã‰ªªÂä°‰∏≠ÈÉΩÊòæËëó‰ºò‰∫éÁé∞ÊúâÊ®°Âûã„ÄÇÁúüÂÆû‰∏ñÁïåÁöÑÂÆûÈ™å‰πüÂ±ïÁ§∫‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ÂÆåÊàêÂÖàÂâçÊú™ËßÅËøáÁöÑÁâ©‰ΩìÁöÑÊìç‰Ωú‰ªªÂä°‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂèØ‰æõÊÄßÊ£ÄÊµãÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠Âú®ËØ≠‰πâÂàÜÂâ≤ÔºåÂç≥Âà§Êñ≠ÂõæÂÉè‰∏≠Âì™‰∫õÂå∫ÂüüÂÖ∑ÊúâÊüêÁßçÂèØ‰æõÊÄßÔºà‰æãÂ¶ÇÔºåÁâ©‰ΩìË°®Èù¢ÂèØÊäìÂèñÔºâ„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÊñπÊ≥ïÊó†Ê≥ïÊèê‰æõÊú∫Âô®‰∫∫Êìç‰ΩúÊâÄÈúÄÁöÑÁ≤æÁ°Æ‰ø°ÊÅØÔºå‰æãÂ¶ÇÊìç‰ΩúÁöÑÂÖ∑‰Ωì‰ΩçÁΩÆ„ÄÅÊñπÂêëÂíåËåÉÂõ¥„ÄÇËøôÈôêÂà∂‰∫ÜÊú∫Âô®‰∫∫Ëá™‰∏ªÂÆåÊàêÂ§çÊùÇÊìç‰Ωú‰ªªÂä°ÁöÑËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÂèØ‰æõÊÄßÊ£ÄÊµãÈóÆÈ¢òËΩ¨Âåñ‰∏∫3DÂÖ≥ÈîÆÁÇπÊ£ÄÊµãÈóÆÈ¢ò„ÄÇÈÄöËøáÈ¢ÑÊµãÁâ©‰Ωì‰∏ä‰∏éÂèØ‰æõÊÄßÁõ∏ÂÖ≥ÁöÑÂÖ≥ÈîÆÁÇπÔºåÂπ∂Âà©Áî®Ëøô‰∫õÂÖ≥ÈîÆÁÇπÊûÑÂª∫3DÂÖ≥ÈîÆÁÇπÂõõÂÖÉÁªÑÔºåÂèØ‰ª•Êõ¥Á≤æÁ°ÆÂú∞ÊèèËø∞ÂèØ‰æõÊÄßÁöÑ‰ΩçÁΩÆ„ÄÅÊñπÂêëÂíåËåÉÂõ¥„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§ü‰∏∫Êú∫Âô®‰∫∫Êìç‰ΩúÊèê‰æõÊõ¥Áõ¥Êé•ÂíåÊúâÊïàÁöÑÊåáÂØº„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöFAKP-NetÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºöÂàÜÂà´‰ªéRGBÂõæÂÉèÂíåÊ∑±Â∫¶ÂõæÂÉè‰∏≠ÊèêÂèñÁâπÂæÅ„ÄÇ2) ÁâπÂæÅËûçÂêàÊ®°ÂùóÔºöÂ∞ÜRGBÂíåÊ∑±Â∫¶ÁâπÂæÅËøõË°åËûçÂêàÔºå‰ª•Ëé∑ÂæóÊõ¥ÂÖ®Èù¢ÁöÑÂú∫ÊôØÁêÜËß£„ÄÇ3) ÂÖ≥ÈîÆÁÇπÈ¢ÑÊµãÊ®°ÂùóÔºöÈ¢ÑÊµãÁâ©‰Ωì‰∏ä‰∏éÂèØ‰æõÊÄßÁõ∏ÂÖ≥ÁöÑ3DÂÖ≥ÈîÆÁÇπ„ÄÇ4) ÂÖ≥ÈîÆÁÇπÂõõÂÖÉÁªÑÊûÑÂª∫Ê®°ÂùóÔºöÂà©Áî®È¢ÑÊµãÁöÑÂÖ≥ÈîÆÁÇπÊûÑÂª∫3DÂÖ≥ÈîÆÁÇπÂõõÂÖÉÁªÑÔºåÁî®‰∫éÊèèËø∞ÂèØ‰æõÊÄßÁöÑ‰ΩçÁΩÆ„ÄÅÊñπÂêëÂíåËåÉÂõ¥„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) Â∞ÜÂèØ‰æõÊÄßÊ£ÄÊµãÈóÆÈ¢òËΩ¨Âåñ‰∏∫3DÂÖ≥ÈîÆÁÇπÊ£ÄÊµãÈóÆÈ¢òÔºå‰ªéËÄåËÉΩÂ§üÊõ¥Á≤æÁ°ÆÂú∞ÊèèËø∞ÂèØ‰æõÊÄßÁöÑ‰ΩçÁΩÆ„ÄÅÊñπÂêëÂíåËåÉÂõ¥„ÄÇ2) ÊèêÂá∫‰∫ÜFAKP-NetÔºå‰∏ÄÁßçÂü∫‰∫éËûçÂêàÁöÑÂèØ‰æõÊÄßÂÖ≥ÈîÆÁÇπÁΩëÁªúÔºåËÉΩÂ§üÊúâÊïàÂú∞Âà©Áî®RGBÂíåÊ∑±Â∫¶‰ø°ÊÅØËøõË°åÂÖ≥ÈîÆÁÇπÈ¢ÑÊµã„ÄÇ3) ÂºïÂÖ•‰∫Ü3DÂÖ≥ÈîÆÁÇπÂõõÂÖÉÁªÑÔºåÁî®‰∫éÊèèËø∞ÂèØ‰æõÊÄßÁöÑ‰ΩçÁΩÆ„ÄÅÊñπÂêëÂíåËåÉÂõ¥Ôºå‰∏∫Êú∫Âô®‰∫∫Êìç‰ΩúÊèê‰æõÊõ¥Áõ¥Êé•ÂíåÊúâÊïàÁöÑÊåáÂØº„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöFAKP-NetÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®ResNet‰Ωú‰∏∫ÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºå‰ª•Ëé∑ÂæóÊõ¥Âº∫Â§ßÁöÑÁâπÂæÅË°®Á§∫ËÉΩÂäõ„ÄÇ2) ‰ΩøÁî®Ê≥®ÊÑèÂäõÊú∫Âà∂ËøõË°åÁâπÂæÅËûçÂêàÔºå‰ª•Êõ¥Â•ΩÂú∞Âà©Áî®RGBÂíåÊ∑±Â∫¶‰ø°ÊÅØ„ÄÇ3) ‰ΩøÁî®Smooth L1ÊçüÂ§±ÂáΩÊï∞ËøõË°åÂÖ≥ÈîÆÁÇπÂõûÂΩíÔºå‰ª•ÊèêÈ´òÂÖ≥ÈîÆÁÇπÈ¢ÑÊµãÁöÑÁ≤æÂ∫¶„ÄÇ4) ÂÖ≥ÈîÆÁÇπÂõõÂÖÉÁªÑÁöÑÊûÑÂª∫ÊñπÂºèÔºåÁ°Æ‰øùËÉΩÂ§üÂáÜÁ°ÆÊèèËø∞ÂèØ‰æõÊÄßÁöÑ‰ΩçÁΩÆ„ÄÅÊñπÂêëÂíåËåÉÂõ¥„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÊú™Âú®ÊëòË¶Å‰∏≠ËØ¶ÁªÜËØ¥ÊòéÔºåÈúÄË¶ÅÊü•ÈòÖËÆ∫ÊñáÂÖ®Êñá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåFAKP-NetÂú®ÂèØ‰æõÊÄßÂàÜÂâ≤‰ªªÂä°ÂíåÂÖ≥ÈîÆÁÇπÊ£ÄÊµã‰ªªÂä°‰∏≠ÈÉΩÊòæËëó‰ºò‰∫éÁé∞ÊúâÊ®°Âûã„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÂú®ÂèØ‰æõÊÄßÂàÜÂâ≤‰ªªÂä°‰∏≠ÔºåFAKP-NetÁöÑmIoUÊåáÊ†áÊèêÂçá‰∫ÜX%ÔºàÂÖ∑‰ΩìÊï∞ÂÄºÊú™Áü•ÔºâÔºõÂú®ÂÖ≥ÈîÆÁÇπÊ£ÄÊµã‰ªªÂä°‰∏≠ÔºåFAKP-NetÁöÑÂπ≥ÂùáÁ≤æÂ∫¶ÔºàAPÔºâÊåáÊ†áÊèêÂçá‰∫ÜY%ÔºàÂÖ∑‰ΩìÊï∞ÂÄºÊú™Áü•Ôºâ„ÄÇÊ≠§Â§ñÔºåÁúüÂÆû‰∏ñÁïåÁöÑÂÆûÈ™å‰πüÈ™åËØÅ‰∫ÜFAKP-NetÂú®ÂÆåÊàêÂÖàÂâçÊú™ËßÅËøáÁöÑÁâ©‰ΩìÁöÑÊìç‰Ωú‰ªªÂä°‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°Ôºå‰æãÂ¶ÇÔºöÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫ÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïËØÜÂà´Áâ©‰Ωì‰∏äÁöÑÂèØÊäìÂèñÂå∫ÂüüÔºåÂπ∂Ëá™‰∏ªÂÆåÊàêÊäìÂèñ‰ªªÂä°ÔºõÂ∑•‰∏öÊú∫Âô®‰∫∫ÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïËØÜÂà´Â∑•‰ª∂‰∏äÁöÑÊìç‰Ωú‰ΩçÁΩÆÔºåÂπ∂Ëá™‰∏ªÂÆåÊàêË£ÖÈÖç‰ªªÂä°ÔºõÂåªÁñóÊú∫Âô®‰∫∫ÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïËØÜÂà´‰∫∫‰Ωì‰∏äÁöÑÊìç‰ΩúÈÉ®‰ΩçÔºåÂπ∂ËæÖÂä©ÂåªÁîüÂÆåÊàêÊâãÊúØ„ÄÇËØ•Á†îÁ©∂ÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄºÂíåÂπøÈòîÁöÑÊú™Êù•ÂèëÂ±ïÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> This paper presents a novel approach for affordance-informed robotic manipulation by introducing 3D keypoints to enhance the understanding of object parts' functionality. The proposed approach provides direct information about what the potential use of objects is, as well as guidance on where and how a manipulator should engage, whereas conventional methods treat affordance detection as a semantic segmentation task, focusing solely on answering the what question. To address this gap, we propose a Fusion-based Affordance Keypoint Network (FAKP-Net) by introducing 3D keypoint quadruplet that harnesses the synergistic potential of RGB and Depth image to provide information on execution position, direction, and extent. Benchmark testing demonstrates that FAKP-Net outperforms existing models by significant margins in affordance segmentation task and keypoint detection task. Real-world experiments also showcase the reliability of our method in accomplishing manipulation tasks with previously unseen objects.

