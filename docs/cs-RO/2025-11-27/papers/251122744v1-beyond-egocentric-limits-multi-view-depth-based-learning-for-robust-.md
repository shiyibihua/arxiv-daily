---
layout: default
title: Beyond Egocentric Limits: Multi-View Depth-Based Learning for Robust Quadrupedal Locomotion
---

# Beyond Egocentric Limits: Multi-View Depth-Based Learning for Robust Quadrupedal Locomotion

**arXiv**: [2511.22744v1](https://arxiv.org/abs/2511.22744) | [PDF](https://arxiv.org/pdf/2511.22744.pdf)

**ä½œè€…**: RÃ©my Rahem, Wael Suleiman

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-27

**å¤‡æ³¨**: 12 pages, 6 figures, code available at https://anonymous.4open.science/r/multiview-parkour-6FB8

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå¤šè§†è§’æ·±åº¦ä¿¡æ¯çš„å››è¶³æœºå™¨äººè¿åŠ¨å­¦ä¹ æ¡†æž¶ï¼Œæå‡é²æ£’æ€§ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `å››è¶³æœºå™¨äºº` `å¤šè§†è§’å­¦ä¹ ` `æ·±åº¦ä¿¡æ¯` `è¿åŠ¨æŽ§åˆ¶` `é¢†åŸŸéšæœºåŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å››è¶³æœºå™¨äººè¿åŠ¨æ–¹æ³•ä¸»è¦ä¾èµ–è‡ªä¸­å¿ƒè§†è§’ï¼Œåœ¨æœºå™¨äººè§†è§’è¢«é®æŒ¡æ—¶æ€§èƒ½å—é™ã€‚
2. æå‡ºä¸€ç§å¤šè§†è§’æ·±åº¦å­¦ä¹ æ¡†æž¶ï¼Œèžåˆè‡ªä¸­å¿ƒå’Œå¤–éƒ¨è§†è§’ä¿¡æ¯ï¼Œå¢žå¼ºçŽ¯å¢ƒæ„ŸçŸ¥ã€‚
3. é€šè¿‡æ•™å¸ˆ-å­¦ç”Ÿè’¸é¦å’Œé¢†åŸŸéšæœºåŒ–ï¼Œæå‡ç­–ç•¥å¯¹æ„ŸçŸ¥å™ªå£°å’Œè§†è§’å˜åŒ–çš„é²æ£’æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºŽå¤šè§†è§’æ·±åº¦ä¿¡æ¯çš„å››è¶³æœºå™¨äººè¿åŠ¨æ¡†æž¶ï¼Œæ—¨åœ¨é€šè¿‡èžåˆè‡ªä¸­å¿ƒè§†è§’å’Œå¤–éƒ¨è§†è§’è§‚æµ‹ï¼Œä¸ºæ•æ·è¿åŠ¨æä¾›æ›´ä¸°å¯Œçš„çŽ¯å¢ƒä¿¡æ¯ã€‚è¯¥æ–¹æ³•é‡‡ç”¨æ•™å¸ˆ-å­¦ç”Ÿè’¸é¦æ–¹æ³•ï¼Œä½¿å­¦ç”Ÿç­–ç•¥å­¦ä¹ èžåˆæœ¬ä½“æ„Ÿå—å’ŒåŒæ·±åº¦æµï¼ŒåŒæ—¶å¯¹çœŸå®žä¸–ç•Œçš„æ„ŸçŸ¥ç¼ºé™·ä¿æŒé²æ£’æ€§ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜é²æ£’æ€§ï¼Œå¼•å…¥äº†å¹¿æ³›çš„é¢†åŸŸéšæœºåŒ–ï¼ŒåŒ…æ‹¬éšæœºè¿œç¨‹ç›¸æœºä¸¢å¤±å’Œæ¨¡æ‹Ÿç©ºä¸­-åœ°é¢ååŒæ„ŸçŸ¥çš„3Dä½ç½®æ‰°åŠ¨ã€‚ä»¿çœŸç»“æžœè¡¨æ˜Žï¼Œå¤šè§†è§’ç­–ç•¥åœ¨è·¨è¶Šé—´éš™ã€ä¸‹å°é˜¶å’Œå…¶ä»–åŠ¨æ€æ“ä½œä¸­ä¼˜äºŽå•è§†è§’åŸºçº¿ï¼ŒåŒæ—¶åœ¨å¤–éƒ¨ç›¸æœºéƒ¨åˆ†æˆ–å®Œå…¨ä¸å¯ç”¨æ—¶ä¿æŒç¨³å®šæ€§ã€‚å…¶ä»–å®žéªŒè¡¨æ˜Žï¼Œåœ¨è®­ç»ƒä¸­åŠ å…¥é€‚åº¦çš„è§†è§’ä¸å¯¹é½å¯ä»¥å¾ˆå¥½åœ°å®¹å¿ã€‚è¿™é¡¹ç ”ç©¶è¡¨æ˜Žï¼Œå¼‚æž„è§†è§‰åé¦ˆæé«˜äº†å››è¶³è¿åŠ¨çš„é²æ£’æ€§å’Œæ•æ·æ€§ã€‚ä¸ºäº†æ”¯æŒå¯é‡å¤æ€§ï¼Œæœ¬æ–‡çš„å®žçŽ°å·²å…¬å¼€å‘å¸ƒã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰å››è¶³æœºå™¨äººè¿åŠ¨æ–¹æ³•ä¸»è¦ä¾èµ–äºŽè‡ªä¸­å¿ƒè§†è§’ï¼ˆç¬¬ä¸€äººç§°è§†è§’ï¼‰çš„æ„ŸçŸ¥ï¼Œè¿™é™åˆ¶äº†æœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„è¿åŠ¨èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æœºå™¨äººè§†è§’è¢«é®æŒ¡çš„æƒ…å†µä¸‹ã€‚ä¾‹å¦‚ï¼Œå½“æœºå™¨äººéœ€è¦è·¨è¶Šéšœç¢ç‰©æˆ–ä¸‹å°é˜¶æ—¶ï¼Œå¦‚æžœè‡ªä¸­å¿ƒè§†è§’æ— æ³•æä¾›è¶³å¤Ÿçš„çŽ¯å¢ƒä¿¡æ¯ï¼Œæœºå™¨äººå°±éš¾ä»¥åšå‡ºæ­£ç¡®çš„å†³ç­–ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿæä¾›æ›´å…¨é¢çŽ¯å¢ƒä¿¡æ¯çš„æ„ŸçŸ¥æ–¹æ³•ï¼Œä»¥æé«˜æœºå™¨äººçš„è¿åŠ¨é²æ£’æ€§å’Œæ•æ·æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šä¸ªè§†è§’çš„æ·±åº¦ä¿¡æ¯æ¥å¢žå¼ºæœºå™¨äººå¯¹çŽ¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œé™¤äº†æœºå™¨äººè‡ªèº«çš„è‡ªä¸­å¿ƒè§†è§’å¤–ï¼Œè¿˜å¼•å…¥äº†å¤–éƒ¨è§†è§’ï¼ˆä¾‹å¦‚ï¼Œæ¥è‡ªæ— äººæœºçš„ä¿¯è§†è§†è§’ï¼‰ã€‚é€šè¿‡èžåˆæ¥è‡ªä¸åŒè§†è§’çš„æ·±åº¦ä¿¡æ¯ï¼Œæœºå™¨äººå¯ä»¥èŽ·å¾—æ›´å…¨é¢çš„çŽ¯å¢ƒä¿¡æ¯ï¼Œä»Žè€Œæ›´å¥½åœ°è§„åˆ’å’Œæ‰§è¡Œè¿åŠ¨ã€‚è¿™ç§å¤šè§†è§’æ„ŸçŸ¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°è§£å†³è‡ªä¸­å¿ƒè§†è§’è¢«é®æŒ¡çš„é—®é¢˜ï¼Œæé«˜æœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„è¿åŠ¨èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ¡†æž¶é‡‡ç”¨æ•™å¸ˆ-å­¦ç”Ÿè’¸é¦çš„æ–¹æ³•ã€‚æ•™å¸ˆç­–ç•¥ä½¿ç”¨å®Œæ•´çš„å¤šè§†è§’æ·±åº¦ä¿¡æ¯è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ æœ€ä¼˜çš„è¿åŠ¨ç­–ç•¥ã€‚ç„¶åŽï¼Œå­¦ç”Ÿç­–ç•¥å­¦ä¹ æ¨¡ä»¿æ•™å¸ˆç­–ç•¥çš„è¡Œä¸ºï¼Œä½†åªä½¿ç”¨éƒ¨åˆ†è§†è§’çš„ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œè‡ªä¸­å¿ƒè§†è§’å’Œéƒ¨åˆ†å¤–éƒ¨è§†è§’ï¼‰ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå­¦ç”Ÿç­–ç•¥å¯ä»¥å­¦ä¹ åˆ°å¦‚ä½•èžåˆæ¥è‡ªä¸åŒè§†è§’çš„æ·±åº¦ä¿¡æ¯ï¼Œå¹¶å¯¹æ„ŸçŸ¥å™ªå£°å’Œè§†è§’å˜åŒ–å…·æœ‰é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æž¶è¿˜é‡‡ç”¨äº†é¢†åŸŸéšæœºåŒ–æŠ€æœ¯ï¼Œé€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥éšæœºçš„ç›¸æœºä¸¢å¤±å’Œä½ç½®æ‰°åŠ¨ï¼Œè¿›ä¸€æ­¥æé«˜ç­–ç•¥çš„é²æ£’æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ä¸ªåŸºäºŽå¤šè§†è§’æ·±åº¦ä¿¡æ¯çš„å››è¶³æœºå™¨äººè¿åŠ¨å­¦ä¹ æ¡†æž¶ï¼Œè¯¥æ¡†æž¶èƒ½å¤Ÿæœ‰æ•ˆåœ°èžåˆæ¥è‡ªä¸åŒè§†è§’çš„æ·±åº¦ä¿¡æ¯ï¼Œå¹¶å¯¹æ„ŸçŸ¥å™ªå£°å’Œè§†è§’å˜åŒ–å…·æœ‰é²æ£’æ€§ã€‚ä¸Žä¼ ç»Ÿçš„è‡ªä¸­å¿ƒè§†è§’æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å¯ä»¥æä¾›æ›´å…¨é¢çš„çŽ¯å¢ƒä¿¡æ¯ï¼Œä»Žè€Œæé«˜æœºå™¨äººçš„è¿åŠ¨èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥è®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„é¢†åŸŸéšæœºåŒ–æ–¹æ³•ï¼Œé€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥éšæœºçš„ç›¸æœºä¸¢å¤±å’Œä½ç½®æ‰°åŠ¨ï¼Œè¿›ä¸€æ­¥æé«˜äº†ç­–ç•¥çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ¡†æž¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨æ·±åº¦ä¿¡æ¯ä½œä¸ºè¾“å…¥ï¼Œé¿å…äº†å¤æ‚çš„å›¾åƒå¤„ç†ï¼›2) é‡‡ç”¨æ•™å¸ˆ-å­¦ç”Ÿè’¸é¦æ–¹æ³•ï¼Œä½¿å­¦ç”Ÿç­–ç•¥èƒ½å¤Ÿå­¦ä¹ æ¨¡ä»¿æ•™å¸ˆç­–ç•¥çš„è¡Œä¸ºï¼Œå¹¶å¯¹æ„ŸçŸ¥å™ªå£°å’Œè§†è§’å˜åŒ–å…·æœ‰é²æ£’æ€§ï¼›3) å¼•å…¥é¢†åŸŸéšæœºåŒ–æŠ€æœ¯ï¼Œé€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥éšæœºçš„ç›¸æœºä¸¢å¤±å’Œä½ç½®æ‰°åŠ¨ï¼Œè¿›ä¸€æ­¥æé«˜ç­–ç•¥çš„é²æ£’æ€§ï¼›4) ä½¿ç”¨åˆé€‚çš„æŸå¤±å‡½æ•°æ¥è®­ç»ƒå­¦ç”Ÿç­–ç•¥ï¼Œä¾‹å¦‚ï¼Œè¡Œä¸ºå…‹éš†æŸå¤±å’ŒçŠ¶æ€åŒ¹é…æŸå¤±ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

ä»¿çœŸå®žéªŒè¡¨æ˜Žï¼Œå¤šè§†è§’ç­–ç•¥åœ¨è·¨è¶Šé—´éš™ã€ä¸‹å°é˜¶ç­‰åŠ¨æ€æ“ä½œä¸­æ˜¾è‘—ä¼˜äºŽå•è§†è§’åŸºçº¿ã€‚å³ä½¿å¤–éƒ¨ç›¸æœºéƒ¨åˆ†æˆ–å®Œå…¨ä¸å¯ç”¨ï¼Œå¤šè§†è§’ç­–ç•¥ä»èƒ½ä¿æŒè¾ƒå¥½çš„ç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œå®žéªŒè¿˜è¡¨æ˜Žï¼Œåœ¨è®­ç»ƒä¸­åŠ å…¥é€‚åº¦çš„è§†è§’ä¸å¯¹é½å¯ä»¥æé«˜ç­–ç•¥å¯¹è§†è§’å˜åŒ–çš„é²æ£’æ€§ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼Œå¤šè§†è§’æ„ŸçŸ¥èƒ½å¤Ÿæœ‰æ•ˆæé«˜å››è¶³æœºå™¨äººçš„è¿åŠ¨èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæœæ•‘ã€å‹˜æŽ¢ã€å·¡æ£€ç­‰é¢†åŸŸã€‚å¤šè§†è§’æ„ŸçŸ¥èƒ½å¤Ÿæå‡å››è¶³æœºå™¨äººåœ¨å¤æ‚åœ°å½¢å’Œé®æŒ¡çŽ¯å¢ƒä¸‹çš„è¿åŠ¨èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°å®Œæˆä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œåœ¨ç¾åŽæœæ•‘ä¸­ï¼Œæ— äººæœºå¯ä»¥æä¾›ä¿¯è§†è§†è§’ï¼Œå¸®åŠ©æœºå™¨äººé¿å¼€éšœç¢ç‰©å’Œå¯»æ‰¾å¹¸å­˜è€…ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºŽæ›´å¹¿æ³›çš„æœºå™¨äººé¢†åŸŸï¼Œä¾‹å¦‚äººå½¢æœºå™¨äººå’Œç§»åŠ¨æœºå™¨äººã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent progress in legged locomotion has allowed highly dynamic and parkour-like behaviors for robots, similar to their biological counterparts. Yet, these methods mostly rely on egocentric (first-person) perception, limiting their performance, especially when the viewpoint of the robot is occluded. A promising solution would be to enhance the robot's environmental awareness by using complementary viewpoints, such as multiple actors exchanging perceptual information. Inspired by this idea, this work proposes a multi-view depth-based locomotion framework that combines egocentric and exocentric observations to provide richer environmental context during agile locomotion. Using a teacher-student distillation approach, the student policy learns to fuse proprioception with dual depth streams while remaining robust to real-world sensing imperfections. To further improve robustness, we introduce extensive domain randomization, including stochastic remote-camera dropouts and 3D positional perturbations that emulate aerial-ground cooperative sensing. Simulation results show that multi-viewpoints policies outperform single-viewpoint baseline in gap crossing, step descent, and other dynamic maneuvers, while maintaining stability when the exocentric camera is partially or completely unavailable. Additional experiments show that moderate viewpoint misalignment is well tolerated when incorporated during training. This study demonstrates that heterogeneous visual feedback improves robustness and agility in quadrupedal locomotion. Furthermore, to support reproducibility, the implementation accompanying this work is publicly available at https://anonymous.4open.science/r/multiview-parkour-6FB8

