---
layout: default
title: Nonholonomic Narrow Dead-End Escape with Deep Reinforcement Learning
---

# Nonholonomic Narrow Dead-End Escape with Deep Reinforcement Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.22338" target="_blank" class="toolbar-btn">arXiv: 2511.22338v1</a>
    <a href="https://arxiv.org/pdf/2511.22338.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.22338v1" 
            onclick="toggleFavorite(this, '2511.22338v1', 'Nonholonomic Narrow Dead-End Escape with Deep Reinforcement Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Denghan Xiong, Yanzhe Zhao, Yutong Chen, Zichun Wang

**ÂàÜÁ±ª**: cs.RO, eess.SY

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-27

**Â§áÊ≥®**: 14 pages, 5 figures, 1 table, submitted to arXiv

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/gitagitty/cisDRL-RobotNav.git)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ï‰ª•Ëß£ÂÜ≥ÈùûÂÆåÊï¥Á∫¶Êùü‰∏ãÁöÑÁã≠Á™ÑÊ≠ªËÉ°ÂêåÈÄÉÈÄ∏ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†` `Ë∑ØÂæÑËßÑÂàí` `ÈùûÂÆåÊï¥Á∫¶Êùü` `AckermannËΩ¶ËæÜ` `Êú∫Âô®‰∫∫ÂØºËà™` `Ëá™Âä®È©æÈ©∂` `ËøêÂä®Â≠¶Á∫¶Êùü`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÁªèÂÖ∏ËßÑÂàíÊñπÊ≥ïÂú®Áã≠Á™ÑÊ≠ªËÉ°ÂêåÈÄÉÈÄ∏‰∏≠Èù¢‰∏¥ÊåëÊàòÔºåÂõ†ÂÖ∂‰ΩéÊµãÂ∫¶Âå∫ÂüüÂíåÈùûÂÆåÊï¥ÂèØËææÊÄßÈôêÂà∂‰∫ÜÊúâÊïàË∑ØÂæÑÁöÑÈááÊ†∑ÊïàÁéá„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÁöÑÊñπÊ≥ïÔºåÈÄöËøáÁîüÊàê‰∏éAckermannËøêÂä®Â≠¶ÂÖºÂÆπÁöÑËΩ®ËøπÂπ∂ËÆ≠ÁªÉÁ≠ñÁï•Êù•Ëß£ÂÜ≥ÈÄÉÈÄ∏ÈóÆÈ¢ò„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂ≠¶‰π†ÁöÑÁ≠ñÁï•Âú®Ëß£ÂÜ≥ÂÆû‰æãÁöÑÊØî‰æã„ÄÅÊìç‰ΩúÊ¨°Êï∞‰∏äÂùá‰ºò‰∫éÁªèÂÖ∏ËßÑÂàíÊñπÊ≥ïÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜË∑ØÂæÑÈïøÂ∫¶ÂíåËßÑÂàíÊó∂Èó¥ÁöÑÂèØÊØîÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈùûÂÆåÊï¥Á∫¶ÊùüÈôêÂà∂‰∫ÜÂèØË°åÈÄüÂ∫¶ËÄå‰∏çÂáèÂ∞ëÈÖçÁΩÆÁ©∫Èó¥Áª¥Â∫¶ÔºåËøô‰ΩøÂæóÂØπ‰∫éÁ±ªÊ±ΩËΩ¶Êú∫Âô®‰∫∫ËÄåË®ÄÔºåÁ¢∞ÊíûËá™Áî±ÁöÑÂá†‰ΩïË∑ØÂæÑÈÄöÂ∏∏Êó†Ê≥ïÊâßË°å„ÄÇAckermannËΩ¨ÂêëËøõ‰∏ÄÊ≠•ÊñΩÂä†‰∫ÜÊõ≤ÁéáÈôêÂà∂Âπ∂Á¶ÅÊ≠¢ÂéüÂú∞ÊóãËΩ¨ÔºåÂõ†Ê≠§‰ªéÁã≠Á™ÑÊ≠ªËÉ°ÂêåÈÄÉÈÄ∏ÈÄöÂ∏∏ÈúÄË¶ÅÁ¥ßÂØÜÂ∫èÂàóÁöÑÂâçËøõÂíåÂêéÈÄÄÊìç‰Ωú„ÄÇÁé∞ÊúâÁöÑÁªèÂÖ∏ËßÑÂàíÊñπÊ≥ïÂú®Ëøô‰∫õÊÉÖÂÜµ‰∏ãË°®Áé∞‰∏ç‰Ω≥ÔºåÂõ†‰∏∫Áã≠Á™ÑÈÄöÈÅìÂç†ÊçÆ‰ΩéÊµãÂ∫¶Âå∫ÂüüÔºåÈùûÂÆåÊï¥ÂèØËææÊÄßÁº©Â∞è‰∫ÜÊúâÊïàËøûÊé•ÁöÑÈõÜÂêàÔºåÈôç‰Ωé‰∫ÜÈááÊ†∑ÊïàÁéáÂπ∂Â¢ûÂä†‰∫ÜÂØπÈó¥ÈöôÁöÑÊïèÊÑüÊÄß„ÄÇÊú¨ÊñáÁ†îÁ©∂‰∫ÜAckermannËΩ¶ËæÜÁöÑÈùûÂÆåÊï¥Áã≠Á™ÑÊ≠ªËÉ°ÂêåÈÄÉÈÄ∏ÈóÆÈ¢òÔºåÊèêÂá∫‰∫Ü‰∏âÈ°πË¥°ÁåÆÔºöÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÁîüÊàêÂô®‰ª•ÈááÊ†∑‰∏éAckermannËøêÂä®Â≠¶ÂÖºÂÆπÁöÑÂ§öÈò∂ÊÆµÂâçÂêéËΩ®ËøπÔºõÂª∫Á´ã‰∫Ü‰∏Ä‰∏™ËÆ≠ÁªÉÁéØÂ¢É‰ª•Âº∫Âà∂ÊâßË°åËøêÂä®Â≠¶Á∫¶ÊùüÔºåÂπ∂‰ΩøÁî®ËΩØÊºîÂëò-ËØÑËÆ∫ÂÆ∂ÁÆóÊ≥ïËÆ≠ÁªÉÁ≠ñÁï•Ôºõ‰∏éÁªìÂêàÂÖ®Â±ÄÊêúÁ¥¢‰∏éÈùûÂÆåÊï¥ËΩ¨ÂêëÁöÑÁªèÂÖ∏ËßÑÂàíÂô®ËøõË°åËØÑ‰º∞ÔºåÂ≠¶‰π†ÁöÑÁ≠ñÁï•Âú®ÂèÇÊï∞ÂåñÁöÑÊ≠ªËÉ°ÂêåÂÆ∂Êóè‰∏≠Ëß£ÂÜ≥‰∫ÜÊõ¥Â§ßÊØî‰æãÁöÑÂÆû‰æãÔºåÂáèÂ∞ë‰∫ÜÊìç‰ΩúÊ¨°Êï∞ÔºåÂπ∂Âú®Áõ∏ÂêåÁöÑÊÑüÁü•ÂíåÊéßÂà∂ÈôêÂà∂‰∏ã‰øùÊåÅ‰∫ÜÂèØÊØîÁöÑË∑ØÂæÑÈïøÂ∫¶ÂíåËßÑÂàíÊó∂Èó¥„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥AckermannËΩ¶ËæÜÂú®Áã≠Á™ÑÊ≠ªËÉ°Âêå‰∏≠ÁöÑÈÄÉÈÄ∏ÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÁî±‰∫é‰ΩéÊµãÂ∫¶Âå∫ÂüüÂíåÈùûÂÆåÊï¥Á∫¶ÊùüÔºåÂØºËá¥Ë∑ØÂæÑËßÑÂàíÊïàÁéá‰Ωé‰∏ã„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÊûÑÂª∫‰∏Ä‰∏™ÁîüÊàêÂô®Êù•ÈááÊ†∑Â§öÈò∂ÊÆµÂâçÂêéËΩ®ËøπÔºåÂπ∂ËÆ≠ÁªÉ‰∏Ä‰∏™Âº∫ÂåñÂ≠¶‰π†Á≠ñÁï•Ôºå‰ª•ÈÄÇÂ∫îAckermannËøêÂä®Â≠¶ÁöÑÁ∫¶ÊùüÔºå‰ªéËÄåÊèêÈ´òÈÄÉÈÄ∏ÊàêÂäüÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöËΩ®ËøπÁîüÊàêÂô®„ÄÅËÆ≠ÁªÉÁéØÂ¢ÉÂíåÁ≠ñÁï•ËØÑ‰º∞„ÄÇËΩ®ËøπÁîüÊàêÂô®Ë¥üË¥£ÁîüÊàêÁ¨¶ÂêàËøêÂä®Â≠¶Á∫¶ÊùüÁöÑËΩ®ËøπÔºåËÆ≠ÁªÉÁéØÂ¢ÉÁî®‰∫éËÆ≠ÁªÉÁ≠ñÁï•ÔºåËÄåÁ≠ñÁï•ËØÑ‰º∞Âàô‰∏éÁªèÂÖ∏ËßÑÂàíÂô®ËøõË°åÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ËÉΩÂ§üÁîüÊàêÂ§öÈò∂ÊÆµËΩ®ËøπÁöÑÁîüÊàêÂô®ÔºåÂπ∂ÈÄöËøáÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÁ≠ñÁï•ÔºåÊòæËëóÊèêÈ´ò‰∫ÜÁã≠Á™ÑÊ≠ªËÉ°ÂêåÈÄÉÈÄ∏ÁöÑÊàêÂäüÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÈááÁî®‰∫ÜËΩØÊºîÂëò-ËØÑËÆ∫ÂÆ∂ÁÆóÊ≥ïÔºåËÆæËÆ°‰∫ÜÈÄÇÂ∫îAckermannËΩ¶ËæÜËøêÂä®Â≠¶ÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÔºå‰ª•Á°Æ‰øùÁîüÊàêÁöÑËΩ®ËøπÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÂèØË°åÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÂ≠¶‰π†ÁöÑÁ≠ñÁï•Âú®ÂèÇÊï∞ÂåñÁöÑÊ≠ªËÉ°ÂêåÂÆ∂Êóè‰∏≠Ëß£ÂÜ≥‰∫ÜÊõ¥Â§ßÊØî‰æãÁöÑÂÆû‰æãÔºåÊìç‰ΩúÊ¨°Êï∞ÂáèÂ∞ë‰∫ÜÔºåÂêåÊó∂Âú®Ë∑ØÂæÑÈïøÂ∫¶ÂíåËßÑÂàíÊó∂Èó¥‰∏ä‰∏éÁªèÂÖ∏ËßÑÂàíÊñπÊ≥ï‰øùÊåÅ‰∫ÜÂèØÊØîÊÄßÔºåÂ±ïÁ§∫‰∫ÜÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†Âú®Â§çÊùÇË∑ØÂæÑËßÑÂàí‰∏≠ÁöÑ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™ÂíåÊô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªüÁ≠â„ÄÇÈÄöËøáÊèêÈ´òÁã≠Á™ÑÁéØÂ¢É‰∏≠ÁöÑÈÄÉÈÄ∏ËÉΩÂäõÔºåËÉΩÂ§üÊòæËëóÊèêÂçáËá™Âä®È©æÈ©∂ËΩ¶ËæÜÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÂÆâÂÖ®ÊÄßÂíåÊïàÁéáÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Nonholonomic constraints restrict feasible velocities without reducing configuration-space dimension, which makes collision-free geometric paths generally non-executable for car-like robots. Ackermann steering further imposes curvature bounds and forbids in-place rotation, so escaping from narrow dead ends typically requires tightly sequenced forward and reverse maneuvers. Classical planners that decouple global search and local steering struggle in these settings because narrow passages occupy low-measure regions and nonholonomic reachability shrinks the set of valid connections, which degrades sampling efficiency and increases sensitivity to clearances. We study nonholonomic narrow dead-end escape for Ackermann vehicles and contribute three components. First, we construct a generator that samples multi-phase forward-reverse trajectories compatible with Ackermann kinematics and inflates their envelopes to synthesize families of narrow dead ends that are guaranteed to admit at least one feasible escape. Second, we construct a training environment that enforces kinematic constraints and train a policy using the soft actor-critic algorithm. Third, we evaluate against representative classical planners that combine global search with nonholonomic steering. Across parameterized dead-end families, the learned policy solves a larger fraction of instances, reduces maneuver count, and maintains comparable path length and planning time while under the same sensing and control limits. We provide our project as open source at https://github.com/gitagitty/cisDRL-RobotNav.git

