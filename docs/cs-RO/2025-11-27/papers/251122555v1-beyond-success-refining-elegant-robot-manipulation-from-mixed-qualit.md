---
layout: default
title: Beyond Success: Refining Elegant Robot Manipulation from Mixed-Quality Data via Just-in-Time Intervention
---

# Beyond Success: Refining Elegant Robot Manipulation from Mixed-Quality Data via Just-in-Time Intervention

**arXiv**: [2511.22555v1](https://arxiv.org/abs/2511.22555) | [PDF](https://arxiv.org/pdf/2511.22555.pdf)

**ä½œè€…**: Yanbo Mao, Jianlong Fu, Ruoxuan Zhang, Hongxia Xie, Meibao Yao

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-27

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**LIBERO-Elegantï¼šé€šè¿‡å³æ—¶å¹²é¢„ï¼Œä»Žæ··åˆè´¨é‡æ•°æ®ä¸­æå‡æœºå™¨äººæ“ä½œçš„ä¼˜é›…æ€§**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡åž‹` `ä¼˜é›…æ‰§è¡Œ` `å³æ—¶å¹²é¢„` `ç¦»çº¿å¼ºåŒ–å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VLAæ¨¡åž‹åœ¨æœºå™¨äººæ“ä½œä¸­å­˜åœ¨æ‰§è¡Œè´¨é‡ä¸ç¨³å®šçš„é—®é¢˜ï¼ŒæºäºŽäººç±»æ¼”ç¤ºæ•°æ®è´¨é‡å‚å·®ä¸é½ï¼Œç¼ºä¹å¯¹â€œä¼˜é›…â€æ‰§è¡Œçš„æ˜Žç¡®æŒ‡å¯¼ã€‚
2. è®ºæ–‡æå‡ºè§£è€¦çš„ä¼˜åŒ–æ¡†æž¶ï¼Œé€šè¿‡ç¦»çº¿å­¦ä¹ ä¼˜é›…è¯„è®ºå™¨è¯„ä¼°åŠ¨ä½œè´¨é‡ï¼Œå¹¶åœ¨å…³é”®æ—¶åˆ»è¿›è¡Œå³æ—¶å¹²é¢„ï¼Œæå‡æ“ä½œçš„ä¼˜é›…æ€§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨LIBERO-ElegantåŸºå‡†å’ŒçœŸå®žåœºæ™¯ä¸­ï¼Œæ˜¾è‘—æé«˜äº†æœºå™¨äººæ“ä½œçš„æ‰§è¡Œè´¨é‡ï¼Œå³ä½¿é¢å¯¹æœªè§è¿‡çš„ä»»åŠ¡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹åœ¨é€šç”¨æœºå™¨äººæ“ä½œæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å…¶å­¦ä¹ åˆ°çš„ç­–ç•¥é€šå¸¸è¡¨çŽ°å‡ºæ‰§è¡Œè´¨é‡çš„å¯å˜æ€§ã€‚è¿™ç§å¯å˜æ€§å½’å› äºŽäººç±»æ¼”ç¤ºçš„æ··åˆè´¨é‡ç‰¹æ€§ï¼Œå…¶ä¸­æŽ§åˆ¶åŠ¨ä½œæ‰§è¡Œæ–¹å¼çš„éšå¼åŽŸåˆ™ä»…è¢«éƒ¨åˆ†æ»¡è¶³ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†LIBERO-ElegantåŸºå‡†ï¼Œè¯¥åŸºå‡†å…·æœ‰ç”¨äºŽè¯„ä¼°æ‰§è¡Œè´¨é‡çš„æ˜Žç¡®æ ‡å‡†ã€‚åŸºäºŽè¿™äº›æ ‡å‡†ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªè§£è€¦çš„ä¼˜åŒ–æ¡†æž¶ï¼Œè¯¥æ¡†æž¶å¯ä»¥åœ¨ä¸ä¿®æ”¹æˆ–é‡æ–°è®­ç»ƒåŸºç¡€VLAç­–ç•¥çš„æƒ…å†µä¸‹æé«˜æ‰§è¡Œè´¨é‡ã€‚æˆ‘ä»¬å°†ä¼˜é›…æ‰§è¡Œå½¢å¼åŒ–ä¸ºéšå¼ä»»åŠ¡çº¦æŸï¼ˆITCï¼‰çš„æ»¡è¶³ï¼Œå¹¶é€šè¿‡ç¦»çº¿æ ¡å‡†Qå­¦ä¹ è®­ç»ƒä¸€ä¸ªä¼˜é›…è¯„è®ºå™¨ï¼Œä»¥ä¼°è®¡å€™é€‰åŠ¨ä½œçš„é¢„æœŸè´¨é‡ã€‚åœ¨æŽ¨ç†æ—¶ï¼Œå³æ—¶å¹²é¢„ï¼ˆJITIï¼‰æœºåˆ¶ä¼šç›‘æŽ§è¯„è®ºå™¨çš„ç½®ä¿¡åº¦ï¼Œå¹¶ä¸”ä»…åœ¨å†³ç­–å…³é”®æ—¶åˆ»è¿›è¡Œå¹²é¢„ï¼Œä»Žè€Œæä¾›é€‰æ‹©æ€§çš„æŒ‰éœ€ä¼˜åŒ–ã€‚åœ¨LIBERO-Elegantå’ŒçœŸå®žä¸–ç•Œæ“ä½œä»»åŠ¡ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œå­¦ä¹ åˆ°çš„ä¼˜é›…è¯„è®ºå™¨å¯ä»¥æ˜¾è‘—æé«˜æ‰§è¡Œè´¨é‡ï¼Œå³ä½¿åœ¨æœªè§è¿‡çš„ä»»åŠ¡ä¸Šä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¯¥æ¨¡åž‹ä½¿æœºå™¨äººæŽ§åˆ¶ä¸ä»…é‡è§†ä»»åŠ¡æ˜¯å¦æˆåŠŸï¼Œè€Œä¸”é‡è§†ä»»åŠ¡çš„æ‰§è¡Œæ–¹å¼ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹åœ¨æœºå™¨äººæ“ä½œä¸­å–å¾—äº†è¿›å±•ï¼Œä½†å…¶æ‰§è¡Œè´¨é‡ä¸ç¨³å®šï¼Œéƒ¨åˆ†åŽŸå› æ˜¯è®­ç»ƒæ•°æ®ï¼ˆäººç±»æ¼”ç¤ºï¼‰çš„è´¨é‡å‚å·®ä¸é½ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸åªå…³æ³¨ä»»åŠ¡æ˜¯å¦æˆåŠŸï¼Œè€Œå¿½ç•¥äº†æ“ä½œçš„â€œä¼˜é›…æ€§â€ï¼Œå³åŠ¨ä½œæ˜¯å¦ç¬¦åˆæŸäº›éšå¼çš„ä»»åŠ¡çº¦æŸï¼ˆImplicit Task Constraints, ITCsï¼‰ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ–¹æ³•æ¥æå‡æœºå™¨äººæ“ä½œçš„æ‰§è¡Œè´¨é‡ï¼Œä½¿å…¶ä¸ä»…æˆåŠŸï¼Œè€Œä¸”ä¼˜é›…ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†â€œä¼˜é›…æ‰§è¡Œâ€å®šä¹‰ä¸ºæ»¡è¶³éšå¼ä»»åŠ¡çº¦æŸï¼ˆITCsï¼‰ï¼Œå¹¶è®­ç»ƒä¸€ä¸ªâ€œä¼˜é›…è¯„è®ºå™¨â€æ¥è¯„ä¼°åŠ¨ä½œçš„è´¨é‡ã€‚è¯¥è¯„è®ºå™¨é€šè¿‡ç¦»çº¿å­¦ä¹ ï¼Œå­¦ä¹ å¦‚ä½•åˆ¤æ–­ä¸€ä¸ªåŠ¨ä½œæ˜¯å¦ç¬¦åˆITCsã€‚åœ¨æŽ¨ç†é˜¶æ®µï¼Œé€šè¿‡â€œå³æ—¶å¹²é¢„ï¼ˆJust-in-Time Intervention, JITIï¼‰â€æœºåˆ¶ï¼Œä»…åœ¨å…³é”®å†³ç­–æ—¶åˆ»å¯¹VLAæ¨¡åž‹çš„è¾“å‡ºè¿›è¡Œä¿®æ­£ï¼Œä»Žè€Œæå‡æ•´ä½“æ‰§è¡Œè´¨é‡ã€‚è¿™ç§æ–¹æ³•é¿å…äº†ç›´æŽ¥ä¿®æ”¹æˆ–é‡æ–°è®­ç»ƒVLAæ¨¡åž‹ï¼Œè€Œæ˜¯é€šè¿‡ä¸€ä¸ªç‹¬ç«‹çš„æ¨¡å—è¿›è¡Œä¼˜åŒ–ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…å«ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1) åŸºç¡€VLAç­–ç•¥ï¼šè´Ÿè´£ç”Ÿæˆåˆå§‹çš„åŠ¨ä½œåºåˆ—ã€‚2) ä¼˜é›…è¯„è®ºå™¨ï¼šé€šè¿‡ç¦»çº¿æ ¡å‡†Qå­¦ä¹ ï¼ˆCalibrated Q-Learningï¼‰è®­ç»ƒï¼Œç”¨äºŽè¯„ä¼°å€™é€‰åŠ¨ä½œçš„è´¨é‡ï¼ˆæ˜¯å¦ç¬¦åˆITCsï¼‰ã€‚3) å³æ—¶å¹²é¢„ï¼ˆJITIï¼‰æœºåˆ¶ï¼šç›‘æŽ§ä¼˜é›…è¯„è®ºå™¨çš„ç½®ä¿¡åº¦ï¼Œå¹¶åœ¨ç½®ä¿¡åº¦è¾ƒä½Žçš„å…³é”®æ—¶åˆ»ï¼Œä½¿ç”¨è¯„è®ºå™¨æŽ¨èçš„åŠ¨ä½œæ¥æ›¿ä»£VLAç­–ç•¥çš„è¾“å‡ºã€‚JITIæœºåˆ¶çš„ç›®æ ‡æ˜¯åœ¨ä¿è¯ä»»åŠ¡æˆåŠŸçŽ‡çš„å‰æä¸‹ï¼Œå°½å¯èƒ½æå‡æ‰§è¡Œçš„ä¼˜é›…æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) æå‡ºäº†LIBERO-ElegantåŸºå‡†ï¼Œç”¨äºŽè¯„ä¼°æœºå™¨äººæ“ä½œçš„æ‰§è¡Œè´¨é‡ã€‚2) å°†â€œä¼˜é›…æ‰§è¡Œâ€å½¢å¼åŒ–ä¸ºéšå¼ä»»åŠ¡çº¦æŸï¼ˆITCsï¼‰çš„æ»¡è¶³ã€‚3) æå‡ºäº†è§£è€¦çš„ä¼˜åŒ–æ¡†æž¶ï¼Œé€šè¿‡ç¦»çº¿å­¦ä¹ ä¼˜é›…è¯„è®ºå™¨å’Œå³æ—¶å¹²é¢„æœºåˆ¶ï¼Œæå‡æ‰§è¡Œè´¨é‡ï¼Œè€Œæ— éœ€ä¿®æ”¹æˆ–é‡æ–°è®­ç»ƒåŸºç¡€VLAç­–ç•¥ã€‚4) æå‡ºäº†å³æ—¶å¹²é¢„æœºåˆ¶ï¼Œåªåœ¨å…³é”®æ—¶åˆ»è¿›è¡Œå¹²é¢„ï¼Œé¿å…è¿‡åº¦å¹²é¢„å½±å“ä»»åŠ¡æˆåŠŸçŽ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šä¼˜é›…è¯„è®ºå™¨ä½¿ç”¨æ ¡å‡†Qå­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œç›®æ ‡æ˜¯å‡†ç¡®ä¼°è®¡åŠ¨ä½œçš„é¢„æœŸè´¨é‡ã€‚JITIæœºåˆ¶çš„å…³é”®åœ¨äºŽç¡®å®šä½•æ—¶è¿›è¡Œå¹²é¢„ã€‚è®ºæ–‡ä½¿ç”¨è¯„è®ºå™¨çš„ç½®ä¿¡åº¦ä½œä¸ºå¹²é¢„çš„è§¦å‘æ¡ä»¶ï¼Œå½“è¯„è®ºå™¨çš„ç½®ä¿¡åº¦ä½ŽäºŽæŸä¸ªé˜ˆå€¼æ—¶ï¼Œåˆ™è¿›è¡Œå¹²é¢„ã€‚å…·ä½“è€Œè¨€ï¼Œç½®ä¿¡åº¦å¯ä»¥é€šè¿‡Qå€¼çš„æ–¹å·®æˆ–ç†µæ¥è¡¡é‡ã€‚è®ºæ–‡è¿˜è®¾è®¡äº†LIBERO-ElegantåŸºå‡†ï¼Œè¯¥åŸºå‡†åŒ…å«å¤šä¸ªæœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œå¹¶ä¸ºæ¯ä¸ªä»»åŠ¡å®šä¹‰äº†æ˜Žç¡®çš„æ‰§è¡Œè´¨é‡è¯„ä¼°æ ‡å‡†ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨LIBERO-ElegantåŸºå‡†ä¸Šæ˜¾è‘—æé«˜äº†æœºå™¨äººæ“ä½œçš„æ‰§è¡Œè´¨é‡ã€‚ä¸ŽåŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ˜Žæ˜¾çš„æå‡ï¼Œå°¤å…¶æ˜¯åœ¨æœªè§è¿‡çš„ä»»åŠ¡ä¸Šï¼Œä»ç„¶èƒ½å¤Ÿä¿æŒè¾ƒé«˜çš„æ‰§è¡Œè´¨é‡ã€‚æ­¤å¤–ï¼Œåœ¨çœŸå®žä¸–ç•Œçš„æ“ä½œä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•ä¹Ÿèƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡æ‰§è¡Œçš„ä¼˜é›…æ€§ï¼ŒéªŒè¯äº†å…¶åœ¨å®žé™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜ç²¾åº¦å’Œé«˜è´¨é‡æ‰§è¡Œçš„åœºæ™¯ä¸­ï¼Œä¾‹å¦‚åŒ»ç–—æ‰‹æœ¯æœºå™¨äººã€ç²¾å¯†è£…é…æœºå™¨äººç­‰ã€‚é€šè¿‡æå‡æœºå™¨äººæ“ä½œçš„ä¼˜é›…æ€§ï¼Œå¯ä»¥æé«˜æ“ä½œçš„å¯é æ€§ã€å®‰å…¨æ€§ï¼Œå¹¶å‡å°‘å¯¹çŽ¯å¢ƒçš„å¹²æ‰°ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°æ›´å¤æ‚çš„ä»»åŠ¡å’ŒçŽ¯å¢ƒï¼Œå®žçŽ°æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„æœºå™¨äººæ“ä½œã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models have enabled notable progress in general-purpose robotic manipulation, yet their learned policies often exhibit variable execution quality. We attribute this variability to the mixed-quality nature of human demonstrations, where the implicit principles that govern how actions should be carried out are only partially satisfied. To address this challenge, we introduce the LIBERO-Elegant benchmark with explicit criteria for evaluating execution quality. Using these criteria, we develop a decoupled refinement framework that improves execution quality without modifying or retraining the base VLA policy. We formalize Elegant Execution as the satisfaction of Implicit Task Constraints (ITCs) and train an Elegance Critic via offline Calibrated Q-Learning to estimate the expected quality of candidate actions. At inference time, a Just-in-Time Intervention (JITI) mechanism monitors critic confidence and intervenes only at decision-critical moments, providing selective, on-demand refinement. Experiments on LIBERO-Elegant and real-world manipulation tasks show that the learned Elegance Critic substantially improves execution quality, even on unseen tasks. The proposed model enables robotic control that values not only whether tasks succeed, but also how they are performed.

