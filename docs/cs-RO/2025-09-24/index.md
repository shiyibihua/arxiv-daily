---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-09-24
---

# cs.ROï¼ˆ2025-09-24ï¼‰

ğŸ“Š å…± **30** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (19 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (6 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (3)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (19 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250920322v2-visualmimic-visual-humanoid-loco-manipulation-via-motion-tracking-an.html">VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation</a></td>
  <td>VisualMimicï¼šåŸºäºè¿åŠ¨è·Ÿè¸ªå’Œç”Ÿæˆå®ç°è§†è§‰äººå‹æœºå™¨äººLoco-Manipulation</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">whole-body control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20322v2" data-paper-url="./papers/250920322v2-visualmimic-visual-humanoid-loco-manipulation-via-motion-tracking-an.html" onclick="toggleFavorite(this, '2509.20322v2', 'VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250920036v2-marg-mastering-risky-gap-terrains-for-legged-robots-with-elevation-m.html">MARG: MAstering Risky Gap Terrains for Legged Robots with Elevation Mapping</a></td>
  <td>MARGï¼šåŸºäºé«˜ç¨‹åœ°å›¾çš„å››è¶³æœºå™¨äººå´å²–åœ°å½¢ï¼ˆé—´éš™ï¼‰å®‰å…¨ç©¿è¶Š</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">legged robot</span> <span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20036v2" data-paper-url="./papers/250920036v2-marg-mastering-risky-gap-terrains-for-legged-robots-with-elevation-m.html" onclick="toggleFavorite(this, '2509.20036v2', 'MARG: MAstering Risky Gap Terrains for Legged Robots with Elevation Mapping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250919752v2-beyond-human-demonstrations-diffusion-based-reinforcement-learning-t.html">Beyond Human Demonstrations: Diffusion-Based Reinforcement Learning to Generate Data for VLA Training</a></td>
  <td>æå‡ºåŸºäºæ‰©æ•£æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œä¸ºVLAæ¨¡å‹ç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">diffusion policy</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.19752v2" data-paper-url="./papers/250919752v2-beyond-human-demonstrations-diffusion-based-reinforcement-learning-t.html" onclick="toggleFavorite(this, '2509.19752v2', 'Beyond Human Demonstrations: Diffusion-Based Reinforcement Learning to Generate Data for VLA Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250919696v2-diffusion-based-impedance-learning-for-contact-rich-manipulation-tas.html">Diffusion-Based Impedance Learning for Contact-Rich Manipulation Tasks</a></td>
  <td>æå‡ºåŸºäºæ‰©æ•£æ¨¡å‹çš„é˜»æŠ—å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºæ¥è§¦ä¸°å¯Œçš„æ“ä½œä»»åŠ¡</td>
  <td class="tags-cell"><span class="paper-tag">parkour</span> <span class="paper-tag">manipulation</span> <span class="paper-tag">teleoperation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.19696v2" data-paper-url="./papers/250919696v2-diffusion-based-impedance-learning-for-contact-rich-manipulation-tas.html" onclick="toggleFavorite(this, '2509.19696v2', 'Diffusion-Based Impedance Learning for Contact-Rich Manipulation Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250920286v1-parse-augment-distill-learning-generalizable-bimanual-visuomotor-pol.html">Parse-Augment-Distill: Learning Generalizable Bimanual Visuomotor Policies from Single Human Video</a></td>
  <td>PADï¼šä»å•ä¸ªäººç±»è§†é¢‘å­¦ä¹ å¯æ³›åŒ–çš„åŒè‡‚è§†è§‰è¿åŠ¨ç­–ç•¥</td>
  <td class="tags-cell"><span class="paper-tag">bi-manual</span> <span class="paper-tag">sim-to-real</span> <span class="paper-tag">motion planning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20286v1" data-paper-url="./papers/250920286v1-parse-augment-distill-learning-generalizable-bimanual-visuomotor-pol.html" onclick="toggleFavorite(this, '2509.20286v1', 'Parse-Augment-Distill: Learning Generalizable Bimanual Visuomotor Policies from Single Human Video')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250919804v2-dynaflow-dynamics-embedded-flow-matching-for-physically-consistent-m.html">DynaFlow: Dynamics-embedded Flow Matching for Physically Consistent Motion Generation from State-only Demonstrations</a></td>
  <td>DynaFlowï¼šåµŒå…¥åŠ¨åŠ›å­¦çš„Flow Matchingç”¨äºä»çŠ¶æ€æ¼”ç¤ºä¸­ç”Ÿæˆç‰©ç†ä¸€è‡´çš„è¿åŠ¨</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">flow matching</span> <span class="paper-tag">motion generation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.19804v2" data-paper-url="./papers/250919804v2-dynaflow-dynamics-embedded-flow-matching-for-physically-consistent-m.html" onclick="toggleFavorite(this, '2509.19804v2', 'DynaFlow: Dynamics-embedded Flow Matching for Physically Consistent Motion Generation from State-only Demonstrations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250919954v1-robot-trajectron-v2-a-probabilistic-shared-control-framework-for-nav.html">Robot Trajectron V2: A Probabilistic Shared Control Framework for Navigation</a></td>
  <td>æå‡ºRobot Trajectron V2ï¼Œç”¨äºå¯¼èˆªçš„æ¦‚ç‡å…±äº«æ§åˆ¶æ¡†æ¶ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">shared control</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.19954v1" data-paper-url="./papers/250919954v1-robot-trajectron-v2-a-probabilistic-shared-control-framework-for-nav.html" onclick="toggleFavorite(this, '2509.19954v1', 'Robot Trajectron V2: A Probabilistic Shared Control Framework for Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250922421v1-learning-based-collaborative-control-for-bi-manual-tactile-reactive-.html">Learning-Based Collaborative Control for Bi-Manual Tactile-Reactive Grasping</a></td>
  <td>æå‡ºåŸºäºå­¦ä¹ çš„è§¦è§‰åé¦ˆåŒè‡‚åä½œæ§åˆ¶ï¼Œç”¨äºæŠ“å–ä¸åŒè½¯ç¡¬ç¨‹åº¦çš„ç‰©ä½“ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">bi-manual</span> <span class="paper-tag">MPC</span> <span class="paper-tag">model predictive control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.22421v1" data-paper-url="./papers/250922421v1-learning-based-collaborative-control-for-bi-manual-tactile-reactive-.html" onclick="toggleFavorite(this, '2509.22421v1', 'Learning-Based Collaborative Control for Bi-Manual Tactile-Reactive Grasping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250920263v2-hl-ik-a-lightweight-implementation-of-human-like-inverse-kinematics-.html">HL-IK: A Lightweight Implementation of Human-Like Inverse Kinematics in Humanoid Arms</a></td>
  <td>æå‡ºHL-IKæ¡†æ¶ä»¥å®ç°ç±»äººé€†å‘è¿åŠ¨å­¦</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">teleoperation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20263v2" data-paper-url="./papers/250920263v2-hl-ik-a-lightweight-implementation-of-human-like-inverse-kinematics-.html" onclick="toggleFavorite(this, '2509.20263v2', 'HL-IK: A Lightweight Implementation of Human-Like Inverse Kinematics in Humanoid Arms')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250919958v1-generalist-robot-manipulation-beyond-action-labeled-data.html">Generalist Robot Manipulation beyond Action Labeled Data</a></td>
  <td>æå‡ºä¸€ç§åˆ©ç”¨æ— åŠ¨ä½œæ ‡ç­¾æ•°æ®çš„é€šç”¨æœºå™¨äººæ“ä½œæ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.19958v1" data-paper-url="./papers/250919958v1-generalist-robot-manipulation-beyond-action-labeled-data.html" onclick="toggleFavorite(this, '2509.19958v1', 'Generalist Robot Manipulation beyond Action Labeled Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250919712v1-topocut-learning-multi-step-cutting-with-spectral-rewards-and-discre.html">TopoCut: Learning Multi-Step Cutting with Spectral Rewards and Discrete Diffusion Policies</a></td>
  <td>TopoCutï¼šæå‡ºåŸºäºè°±å¥–åŠ±å’Œç¦»æ•£æ‰©æ•£ç­–ç•¥çš„å¤šæ­¥åˆ‡å‰²å­¦ä¹ æ¡†æ¶ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">policy learning</span> <span class="paper-tag">diffusion policy</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.19712v1" data-paper-url="./papers/250919712v1-topocut-learning-multi-step-cutting-with-spectral-rewards-and-discre.html" onclick="toggleFavorite(this, '2509.19712v1', 'TopoCut: Learning Multi-Step Cutting with Spectral Rewards and Discrete Diffusion Policies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250920516v1-action-informed-estimation-and-planning-clearing-clutter-on-staircas.html">Action-Informed Estimation and Planning: Clearing Clutter on Staircases via Quadrupedal Pedipulation</a></td>
  <td>æå‡ºäº¤äº’æ„ŸçŸ¥çš„çŠ¶æ€ä¼°è®¡ä¸è§„åˆ’æ–¹æ³•ï¼Œè§£å†³å››è¶³æœºå™¨äººæ¥¼æ¢¯æ‚ç‰©æ¸…ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20516v1" data-paper-url="./papers/250920516v1-action-informed-estimation-and-planning-clearing-clutter-on-staircas.html" onclick="toggleFavorite(this, '2509.20516v1', 'Action-Informed Estimation and Planning: Clearing Clutter on Staircases via Quadrupedal Pedipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250920333v1-bboe-leveraging-bundle-of-edges-for-kinodynamic-bidirectional-motion.html">BBoE: Leveraging Bundle of Edges for Kinodynamic Bidirectional Motion Planning</a></td>
  <td>BBoEï¼šåˆ©ç”¨è¾¹æŸçš„è¿åŠ¨å­¦åŒå‘è¿åŠ¨è§„åˆ’ï¼Œæå‡å¤æ‚ç¯å¢ƒä¸‹çš„è§„åˆ’æ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20333v1" data-paper-url="./papers/250920333v1-bboe-leveraging-bundle-of-edges-for-kinodynamic-bidirectional-motion.html" onclick="toggleFavorite(this, '2509.20333v1', 'BBoE: Leveraging Bundle of Edges for Kinodynamic Bidirectional Motion Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250920084v1-c-3to-continuous-3d-trajectory-optimization-on-neural-euclidean-sign.html">C-3TO: Continuous 3D Trajectory Optimization on Neural Euclidean Signed Distance Fields</a></td>
  <td>C-3TOï¼šåŸºäºç¥ç»æ¬§å‡ é‡Œå¾·ç¬¦å·è·ç¦»åœºçš„è¿ç»­3Dè½¨è¿¹ä¼˜åŒ–</td>
  <td class="tags-cell"><span class="paper-tag">trajectory optimization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20084v1" data-paper-url="./papers/250920084v1-c-3to-continuous-3d-trajectory-optimization-on-neural-euclidean-sign.html" onclick="toggleFavorite(this, '2509.20084v1', 'C-3TO: Continuous 3D Trajectory Optimization on Neural Euclidean Signed Distance Fields')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250920297v3-mindmap-spatial-memory-in-deep-feature-maps-for-3d-action-policies.html">mindmap: Spatial Memory in Deep Feature Maps for 3D Action Policies</a></td>
  <td>æå‡ºMindmapï¼Œåˆ©ç”¨æ·±åº¦ç‰¹å¾å›¾ä¸­çš„ç©ºé—´è®°å¿†å®ç°3DåŠ¨ä½œç­–ç•¥ï¼Œè§£å†³æœºå™¨äººæ“ä½œä¸­è§†é‡å¤–ç‰©ä½“äº¤äº’é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">diffusion policy</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20297v3" data-paper-url="./papers/250920297v3-mindmap-spatial-memory-in-deep-feature-maps-for-3d-action-policies.html" onclick="toggleFavorite(this, '2509.20297v3', 'mindmap: Spatial Memory in Deep Feature Maps for 3D Action Policies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250919972v3-an-effective-control-of-large-systems-of-active-particles-an-applica.html">An effective control of large systems of active particles: An application to evacuation problem</a></td>
  <td>ç»“åˆå¼ºåŒ–å­¦ä¹ ä¸äººå·¥åŠ¿åœºçš„é¢†å¯¼è€…æ§åˆ¶ç­–ç•¥ï¼Œè§£å†³å¤§è§„æ¨¡ä¸»åŠ¨ç²’å­ç³»ç»Ÿçš„ç–æ•£é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.19972v3" data-paper-url="./papers/250919972v3-an-effective-control-of-large-systems-of-active-particles-an-applica.html" onclick="toggleFavorite(this, '2509.19972v3', 'An effective control of large systems of active particles: An application to evacuation problem')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250919853v1-sagestate-aware-guided-end-to-end-policy-for-multi-stage-sequential-.html">SAGE:State-Aware Guided End-to-End Policy for Multi-Stage Sequential Tasks via Hidden Markov Decision Process</a></td>
  <td>SAGEï¼šåŸºäºéšé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹çš„çŠ¶æ€æ„ŸçŸ¥å¼•å¯¼ç«¯åˆ°ç«¯å¤šé˜¶æ®µåºåˆ—ä»»åŠ¡ç­–ç•¥</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.19853v1" data-paper-url="./papers/250919853v1-sagestate-aware-guided-end-to-end-policy-for-multi-stage-sequential-.html" onclick="toggleFavorite(this, '2509.19853v1', 'SAGE:State-Aware Guided End-to-End Policy for Multi-Stage Sequential Tasks via Hidden Markov Decision Process')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250920219v1-a-biomimetic-vertebraic-soft-robotic-tail-for-high-speed-high-force-.html">A Biomimetic Vertebraic Soft Robotic Tail for High-Speed, High-Force Dynamic Maneuvering</a></td>
  <td>æå‡ºä»¿ç”Ÿæ¤éª¨è½¯ä½“æœºå™¨äººå°¾éƒ¨ï¼Œç”¨äºé«˜é€Ÿé«˜åŠ›åŠ¨æ€æ“æ§</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20219v1" data-paper-url="./papers/250920219v1-a-biomimetic-vertebraic-soft-robotic-tail-for-high-speed-high-force-.html" onclick="toggleFavorite(this, '2509.20219v1', 'A Biomimetic Vertebraic Soft Robotic Tail for High-Speed, High-Force Dynamic Maneuvering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250919732v1-simultaneous-estimation-of-contact-position-and-tool-shape-with-high.html">Simultaneous estimation of contact position and tool shape with high-dimensional parameters using force measurements and particle filtering</a></td>
  <td>æå‡ºåŸºäºåŠ›æµ‹é‡å’Œç²’å­æ»¤æ³¢çš„åŒæ—¶ä¼°è®¡æ¥è§¦ä½ç½®å’Œé«˜ç»´å·¥å…·å½¢çŠ¶å‚æ•°æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.19732v1" data-paper-url="./papers/250919732v1-simultaneous-estimation-of-contact-position-and-tool-shape-with-high.html" onclick="toggleFavorite(this, '2509.19732v1', 'Simultaneous estimation of contact position and tool shape with high-dimensional parameters using force measurements and particle filtering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (6 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>20</td>
  <td><a href="./papers/250920109v1-discrete-diffusion-for-reflective-vision-language-action-models-in-a.html">Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving</a></td>
  <td>ReflectDriveï¼šæå‡ºåŸºäºç¦»æ•£æ‰©æ•£å’Œåå°„æœºåˆ¶çš„è‡ªåŠ¨é©¾é©¶åå°„å¼è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">imitation learning</span> <span class="paper-tag">vision-language-action</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20109v1" data-paper-url="./papers/250920109v1-discrete-diffusion-for-reflective-vision-language-action-models-in-a.html" onclick="toggleFavorite(this, '2509.20109v1', 'Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250919892v1-d3grasp-diverse-and-deformable-dexterous-grasping-for-general-object.html">D3Grasp: Diverse and Deformable Dexterous Grasping for General Objects</a></td>
  <td>D3Graspï¼šé¢å‘é€šç”¨ç‰©ä½“çš„å¤šæ ·åŒ–å’Œå¯å˜å½¢çµå·§æŠ“å–</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">privileged information</span> <span class="paper-tag">penetration</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.19892v1" data-paper-url="./papers/250919892v1-d3grasp-diverse-and-deformable-dexterous-grasping-for-general-object.html" onclick="toggleFavorite(this, '2509.19892v1', 'D3Grasp: Diverse and Deformable Dexterous Grasping for General Objects')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250920623v1-latent-activation-editing-inference-time-refinement-of-learned-polic.html">Latent Activation Editing: Inference-Time Refinement of Learned Policies for Safer Multirobot Navigation</a></td>
  <td>æå‡ºLatent Activation Editingï¼Œç”¨äºå¤šæœºå™¨äººå¯¼èˆªä¸­å¼ºåŒ–å­¦ä¹ ç­–ç•¥çš„æ¨ç†æ—¶å®‰å…¨ä¼˜åŒ–ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">world model</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20623v1" data-paper-url="./papers/250920623v1-latent-activation-editing-inference-time-refinement-of-learned-polic.html" onclick="toggleFavorite(this, '2509.20623v1', 'Latent Activation Editing: Inference-Time Refinement of Learned Policies for Safer Multirobot Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/250919658v1-robossm-scalable-in-context-imitation-learning-via-state-space-model.html">RoboSSM: Scalable In-context Imitation Learning via State-Space Models</a></td>
  <td>RoboSSMï¼šåŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹å®ç°å¯æ‰©å±•çš„ä¸Šä¸‹æ–‡æ¨¡ä»¿å­¦ä¹ </td>
  <td class="tags-cell"><span class="paper-tag">imitation learning</span> <span class="paper-tag">SSM</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.19658v1" data-paper-url="./papers/250919658v1-robossm-scalable-in-context-imitation-learning-via-state-space-model.html" onclick="toggleFavorite(this, '2509.19658v1', 'RoboSSM: Scalable In-context Imitation Learning via State-Space Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250920541v1-selective-progress-aware-querying-for-human-in-the-loop-reinforcemen.html">Selective Progress-Aware Querying for Human-in-the-Loop Reinforcement Learning</a></td>
  <td>æå‡ºSPARQï¼šä¸€ç§é€‰æ‹©æ€§è¿›åº¦æ„ŸçŸ¥æŸ¥è¯¢ç­–ç•¥ï¼Œç”¨äºé™ä½äººæœºååŒå¼ºåŒ–å­¦ä¹ ä¸­çš„äººå·¥åé¦ˆæˆæœ¬ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20541v1" data-paper-url="./papers/250920541v1-selective-progress-aware-querying-for-human-in-the-loop-reinforcemen.html" onclick="toggleFavorite(this, '2509.20541v1', 'Selective Progress-Aware Querying for Human-in-the-Loop Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/250920070v1-llm-trainer-automated-robotic-data-generating-via-demonstration-augm.html">LLM Trainer: Automated Robotic Data Generating via Demonstration Augmentation using LLMs</a></td>
  <td>æå‡ºLLM Trainerä»¥è§£å†³æœºå™¨äººæ¨¡ä»¿å­¦ä¹ æ•°æ®ç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">imitation learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20070v1" data-paper-url="./papers/250920070v1-llm-trainer-automated-robotic-data-generating-via-demonstration-augm.html" onclick="toggleFavorite(this, '2509.20070v1', 'LLM Trainer: Automated Robotic Data Generating via Demonstration Augmentation using LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>26</td>
  <td><a href="./papers/250919851v1-where-did-i-leave-my-glasses-open-vocabulary-semantic-exploration-in.html">Where Did I Leave My Glasses? Open-Vocabulary Semantic Exploration in Real-World Semi-Static Environments</a></td>
  <td>æå‡ºä¸€ç§å¼€æ”¾è¯æ±‡è¯­ä¹‰æ¢ç´¢ç³»ç»Ÿï¼Œç”¨äºçœŸå®åŠé™æ€ç¯å¢ƒä¸­è¿›è¡Œå¯¹è±¡çº§åˆ«çš„é•¿æœŸè·Ÿè¸ªå’Œå¯¼èˆªã€‚</td>
  <td class="tags-cell"><span class="paper-tag">semantic map</span> <span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.19851v1" data-paper-url="./papers/250919851v1-where-did-i-leave-my-glasses-open-vocabulary-semantic-exploration-in.html" onclick="toggleFavorite(this, '2509.19851v1', 'Where Did I Leave My Glasses? Open-Vocabulary Semantic Exploration in Real-World Semi-Static Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/250920486v1-boosting-lidar-based-localization-with-semantic-insight-camera-proje.html">Boosting LiDAR-Based Localization with Semantic Insight: Camera Projection versus Direct LiDAR Segmentation</a></td>
  <td>æå‡ºèåˆè¯­ä¹‰ä¿¡æ¯çš„LiDARå®šä½æ–¹æ³•ï¼Œæå‡å¤æ‚ç¯å¢ƒä¸‹ç§»åŠ¨æœºå™¨äººçš„å®šä½ç²¾åº¦ä¸é²æ£’æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">Depth Anything</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20486v1" data-paper-url="./papers/250920486v1-boosting-lidar-based-localization-with-semantic-insight-camera-proje.html" onclick="toggleFavorite(this, '2509.20486v1', 'Boosting LiDAR-Based Localization with Semantic Insight: Camera Projection versus Direct LiDAR Segmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/250920077v1-queryable-3d-scene-representation-a-multi-modal-framework-for-semant.html">Queryable 3D Scene Representation: A Multi-Modal Framework for Semantic Reasoning and Robotic Task Planning</a></td>
  <td>æå‡º3Då¯æŸ¥è¯¢åœºæ™¯è¡¨ç¤ºï¼Œèåˆå¤šæ¨¡æ€æ•°æ®ï¼Œèµ‹èƒ½æœºå™¨äººè¯­ä¹‰æ¨ç†ä¸ä»»åŠ¡è§„åˆ’ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">scene understanding</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20077v1" data-paper-url="./papers/250920077v1-queryable-3d-scene-representation-a-multi-modal-framework-for-semant.html" onclick="toggleFavorite(this, '2509.20077v1', 'Queryable 3D Scene Representation: A Multi-Modal Framework for Semantic Reasoning and Robotic Task Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>29</td>
  <td><a href="./papers/250920499v1-boosting-zero-shot-vln-via-abstract-obstacle-map-based-waypoint-pred.html">Boosting Zero-Shot VLN via Abstract Obstacle Map-Based Waypoint Prediction with TopoGraph-and-VisitInfo-Aware Prompting</a></td>
  <td>æå‡ºåŸºäºæŠ½è±¡éšœç¢åœ°å›¾é›¶æ ·æœ¬VLNæ¡†æ¶ï¼Œç»“åˆæ‹“æ‰‘å›¾å’Œè®¿é—®ä¿¡æ¯æç¤ºï¼Œå®ç°æ›´ä¼˜å¯¼èˆªã€‚</td>
  <td class="tags-cell"><span class="paper-tag">VLN</span> <span class="paper-tag">large language model</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20499v1" data-paper-url="./papers/250920499v1-boosting-zero-shot-vln-via-abstract-obstacle-map-based-waypoint-pred.html" onclick="toggleFavorite(this, '2509.20499v1', 'Boosting Zero-Shot VLN via Abstract Obstacle Map-Based Waypoint Prediction with TopoGraph-and-VisitInfo-Aware Prompting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>30</td>
  <td><a href="./papers/250922716v1-large-language-models-for-3d-ic-space-planning.html">Large Language Models for 3D IC Space Planning</a></td>
  <td>æå‡ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„3D ICç©ºé—´è§„åˆ’æ–¹æ³•ï¼Œä¼˜åŒ–èŠ¯ç‰‡å¸ƒå±€ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.22716v1" data-paper-url="./papers/250922716v1-large-language-models-for-3d-ic-space-planning.html" onclick="toggleFavorite(this, '2509.22716v1', 'Large Language Models for 3D IC Space Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)