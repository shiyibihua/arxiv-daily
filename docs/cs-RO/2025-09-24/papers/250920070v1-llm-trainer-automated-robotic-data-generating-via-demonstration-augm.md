---
layout: default
title: LLM Trainer: Automated Robotic Data Generating via Demonstration Augmentation using LLMs
---

# LLM Trainer: Automated Robotic Data Generating via Demonstration Augmentation using LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.20070" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.20070v1</a>
  <a href="https://arxiv.org/pdf/2509.20070.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.20070v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.20070v1', 'LLM Trainer: Automated Robotic Data Generating via Demonstration Augmentation using LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Abraham George, Amir Barati Farimani

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-24

**å¤‡æ³¨**: 9 pages, 5 figures, 4 tables. Submitted to ICRA 2026

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLLM Trainerä»¥è§£å†³æœºå™¨äººæ¨¡ä»¿å­¦ä¹ æ•°æ®ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººæ¨¡ä»¿å­¦ä¹ ` `æ•°æ®ç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªåŠ¨åŒ–` `ç¤ºèŒƒå­¦ä¹ ` `æ±¤æ™®æ£®é‡‡æ ·` `å…³é”®å¸§æå–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æœºå™¨äººæ¨¡ä»¿å­¦ä¹ ä¸­ä¾èµ–å¤§é‡äººç±»ç¤ºèŒƒï¼Œå¯¼è‡´æ•°æ®ç”Ÿæˆæ•ˆç‡ä½ä¸‹ã€‚
2. è®ºæ–‡æå‡ºçš„LLM Traineré€šè¿‡å°‘é‡ç¤ºèŒƒç”Ÿæˆå¤§é‡æ•°æ®ï¼Œé‡‡ç”¨ç¦»çº¿æ³¨é‡Šå’Œåœ¨çº¿é‡å®šå‘çš„åŒæ­¥éª¤æ–¹æ³•ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLM Traineråœ¨å¤šé¡¹ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„ä¸“å®¶è®¾è®¡åŸºçº¿ï¼ŒæˆåŠŸç‡æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†LLM Trainerï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œå…¨è‡ªåŠ¨åŒ–çš„ç®¡é“ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä¸–ç•ŒçŸ¥è¯†ï¼Œå°†å°‘é‡äººç±»ç¤ºèŒƒï¼ˆå°‘è‡³ä¸€ä¸ªï¼‰è½¬åŒ–ä¸ºå¤§é‡æœºå™¨äººæ¨¡ä»¿å­¦ä¹ æ•°æ®é›†ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†ç¤ºèŒƒç”Ÿæˆåˆ†ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼šç¦»çº¿ç¤ºèŒƒæ³¨é‡Šï¼Œæå–å…³é”®å¸§ã€æ˜¾è‘—å¯¹è±¡å’Œå§¿æ€-å¯¹è±¡å…³ç³»ï¼›åœ¨çº¿å…³é”®å§¿æ€é‡å®šå‘ï¼Œæ ¹æ®åˆå§‹è§‚å¯Ÿå°†è¿™äº›å…³é”®å¸§é€‚åº”åˆ°æ–°åœºæ™¯ã€‚åˆ©ç”¨è¿™äº›ä¿®æ”¹åçš„å…³é”®ç‚¹ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿæ‰­æ›²åŸå§‹ç¤ºèŒƒä»¥ç”Ÿæˆæ–°è½¨è¿¹ï¼Œå¹¶åœ¨æˆåŠŸæ‰§è¡Œåä¿å­˜ç»“æœã€‚ç”±äºæ³¨é‡Šå¯åœ¨ä¸åŒåœºæ™¯é—´é‡ç”¨ï¼Œæˆ‘ä»¬ä½¿ç”¨æ±¤æ™®æ£®é‡‡æ ·ä¼˜åŒ–æ³¨é‡Šï¼Œæ˜¾è‘—æé«˜ç”ŸæˆæˆåŠŸç‡ã€‚æˆ‘ä»¬åœ¨å¤šé¡¹ä»»åŠ¡ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œå‘ç°å…¶æ•°æ®æ³¨é‡Šæ–¹æ³•å§‹ç»ˆä¼˜äºä¸“å®¶è®¾è®¡çš„åŸºçº¿ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨Franka Emika Pandaæœºå™¨äººä¸Šå±•ç¤ºäº†ç¡¬ä»¶å¯è¡Œæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæ¨¡ä»¿å­¦ä¹ ä¸­æ•°æ®ç”Ÿæˆçš„ä½æ•ˆç‡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡äººç±»ç¤ºèŒƒï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´å’Œçµæ´»æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLLM Traineré€šè¿‡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†ï¼Œå°†å°‘é‡äººç±»ç¤ºèŒƒè½¬åŒ–ä¸ºä¸°å¯Œçš„æœºå™¨äººæ•°æ®é›†ã€‚è¯¥æ–¹æ³•çš„è®¾è®¡æ—¨åœ¨æé«˜æ•°æ®ç”Ÿæˆçš„æ•ˆç‡å’ŒæˆåŠŸç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯ç¦»çº¿ç¤ºèŒƒæ³¨é‡Šï¼Œæå–å…³é”®å¸§ã€æ˜¾è‘—å¯¹è±¡å’Œå§¿æ€-å¯¹è±¡å…³ç³»ï¼›ç¬¬äºŒé˜¶æ®µæ˜¯åœ¨çº¿å…³é”®å§¿æ€é‡å®šå‘ï¼Œå°†å…³é”®å¸§é€‚åº”åˆ°æ–°åœºæ™¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†ç¤ºèŒƒç”Ÿæˆè¿‡ç¨‹åˆ†ä¸ºæ³¨é‡Šå’Œé‡å®šå‘ä¸¤ä¸ªæ­¥éª¤ï¼Œå¹¶ä¸”æ³¨é‡Šå¯ä»¥åœ¨ä¸åŒåœºæ™¯ä¸­é‡ç”¨ï¼Œæ˜¾è‘—æé«˜äº†ç”Ÿæˆæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šé‡‡ç”¨æ±¤æ™®æ£®é‡‡æ ·ä¼˜åŒ–æ³¨é‡Šè¿‡ç¨‹ï¼Œç¡®ä¿ç”Ÿæˆçš„ç¤ºèŒƒåœ¨å¤šç§åœºæ™¯ä¸‹éƒ½èƒ½æœ‰æ•ˆåº”ç”¨ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œéœ€å‚è€ƒåŸæ–‡è·å–æ›´å¤šæŠ€æœ¯ç»†èŠ‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLM Trainerçš„æ³¨é‡Šæ–¹æ³•åœ¨å¤šé¡¹ä»»åŠ¡ä¸­å§‹ç»ˆä¼˜äºä¸“å®¶è®¾è®¡çš„åŸºçº¿ï¼Œç”ŸæˆæˆåŠŸç‡æ˜¾è‘—æé«˜ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿çš„è¯¦ç»†ä¿¡æ¯å¯åœ¨åŸæ–‡ä¸­æŸ¥é˜…ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººè‡ªåŠ¨åŒ–ã€æ™ºèƒ½åˆ¶é€ å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æé«˜æ¨¡ä»¿å­¦ä¹ çš„æ•°æ®ç”Ÿæˆæ•ˆç‡ï¼ŒLLM Trainerèƒ½å¤ŸåŠ é€Ÿæœºå™¨äººå­¦ä¹ è¿‡ç¨‹ï¼Œé™ä½å¯¹äººç±»ç¤ºèŒƒçš„ä¾èµ–ï¼Œè¿›è€Œæ¨åŠ¨æœºå™¨äººæŠ€æœ¯çš„æ™®åŠå’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present LLM Trainer, a fully automated pipeline that leverages the world knowledge of Large Language Models (LLMs) to transform a small number of human demonstrations (as few as one) into a large robot dataset for imitation learning. Our approach decomposes demonstration generation into two steps: (1) offline demonstration annotation that extracts keyframes, salient objects, and pose-object relations; and (2) online keypose retargeting that adapts those keyframes to a new scene, given an initial observation. Using these modified keypoints, our system warps the original demonstration to generate a new trajectory, which is then executed, and the resulting demo, if successful, is saved. Because the annotation is reusable across scenes, we use Thompson sampling to optimize the annotation, significantly improving generation success rate. We evaluate our method on a range of tasks, and find that our data annotation method consistently outperforms expert-engineered baselines. We further show an ensemble policy that combines the optimized LLM feed-forward plan with a learned feedback imitation learning controller. Finally, we demonstrate hardware feasibility on a Franka Emika Panda robot. For additional materials and demonstration videos, please see the project website: https://sites.google.com/andrew.cmu.edu/llm-trainer

