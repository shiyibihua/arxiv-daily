---
layout: default
title: VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation
---

# VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.20322" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.20322v2</a>
  <a href="https://arxiv.org/pdf/2509.20322.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.20322v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.20322v2', 'VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shaofeng Yin, Yanjie Ze, Hong-Xing Yu, C. Karen Liu, Jiajun Wu

**åˆ†ç±»**: cs.RO, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-24 (æ›´æ–°: 2025-11-13)

**å¤‡æ³¨**: Website: https://visualmimic.github.io

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VisualMimicï¼šåŸºäºè¿åŠ¨è·Ÿè¸ªå’Œç”Ÿæˆå®ç°è§†è§‰äººå‹æœºå™¨äººLoco-Manipulation**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äººå‹æœºå™¨äºº` `Loco-manipulation` `è§†è§‰æ§åˆ¶` `è¿åŠ¨è·Ÿè¸ª` `Sim-to-real` `å¼ºåŒ–å­¦ä¹ ` `å…³é”®ç‚¹æ£€æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„äººå½¢æœºå™¨äººloco-manipulationæ–¹æ³•ä¾èµ–å¤–éƒ¨åŠ¨æ•ç³»ç»Ÿæˆ–æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œéš¾ä»¥åœ¨éç»“æ„åŒ–ç¯å¢ƒä¸­æœ‰æ•ˆå·¥ä½œã€‚
2. VisualMimicé€šè¿‡ç»“åˆä»»åŠ¡æ— å…³çš„ä½çº§å…³é”®ç‚¹è·Ÿè¸ªå™¨å’Œä»»åŠ¡ç‰¹å®šçš„é«˜çº§ç­–ç•¥ï¼Œå®ç°äº†è§†è§‰å’Œå…¨èº«æ§åˆ¶çš„ç»Ÿä¸€ã€‚
3. è¯¥æ–¹æ³•å®ç°äº†æ¨¡æ‹Ÿåˆ°çœŸå®çš„é›¶æ ·æœ¬è¿ç§»ï¼Œå¹¶åœ¨å¤šç§loco-manipulationä»»åŠ¡å’Œæˆ·å¤–ç¯å¢ƒä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºVisualMimicï¼Œä¸€ä¸ªè§†è§‰sim-to-realæ¡†æ¶ï¼Œç”¨äºç»Ÿä¸€ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†è§‰æ„ŸçŸ¥å’Œäººå‹æœºå™¨äººçš„å…¨èº«æ§åˆ¶ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–å¤–éƒ¨è¿åŠ¨æ•æ‰ç³»ç»Ÿæˆ–æ— æ³•æ³›åŒ–åˆ°ä¸åŒä»»åŠ¡ã€‚VisualMimicç»“åˆäº†ä¸€ä¸ªä»»åŠ¡æ— å…³çš„ä½çº§å…³é”®ç‚¹è·Ÿè¸ªå™¨ï¼ˆé€šè¿‡teacher-studentæ–¹æ¡ˆä»äººç±»è¿åŠ¨æ•°æ®ä¸­è®­ç»ƒï¼‰å’Œä¸€ä¸ªä»»åŠ¡ç‰¹å®šçš„é«˜çº§ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ä»è§†è§‰å’Œæœ¬ä½“æ„Ÿè§‰è¾“å…¥ç”Ÿæˆå…³é”®ç‚¹å‘½ä»¤ã€‚ä¸ºäº†ç¡®ä¿è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œæˆ‘ä»¬å°†å™ªå£°æ³¨å…¥åˆ°ä½çº§ç­–ç•¥ä¸­ï¼Œå¹¶ä½¿ç”¨äººç±»è¿åŠ¨ç»Ÿè®¡æ•°æ®æ¥è£å‰ªé«˜çº§åŠ¨ä½œã€‚VisualMimicå®ç°äº†åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è®­ç»ƒçš„è§†è§‰è¿åŠ¨ç­–ç•¥åˆ°çœŸå®äººå‹æœºå™¨äººçš„é›¶æ ·æœ¬è¿ç§»ï¼Œä»è€Œå®Œæˆäº†ä¸€ç³»åˆ—loco-manipulationä»»åŠ¡ï¼Œä¾‹å¦‚ç®±å­æ¬è¿ã€æ¨ç®±å­ã€è¶³çƒè¿çƒå’Œè¸¢çƒã€‚é™¤äº†å—æ§çš„å®éªŒå®¤ç¯å¢ƒå¤–ï¼Œæˆ‘ä»¬çš„ç­–ç•¥è¿˜å¯ä»¥ç¨³å¥åœ°æ³›åŒ–åˆ°æˆ·å¤–ç¯å¢ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„äººå½¢æœºå™¨äººloco-manipulationæ–¹æ³•ä¸»è¦é¢ä¸´ä¸¤ä¸ªç—›ç‚¹ï¼šä¸€æ˜¯ä¾èµ–å¤–éƒ¨è¿åŠ¨æ•æ‰ç³»ç»Ÿï¼Œé™åˆ¶äº†å…¶åœ¨çœŸå®ç¯å¢ƒä¸­çš„åº”ç”¨ï¼›äºŒæ˜¯éš¾ä»¥æ³›åŒ–åˆ°ä¸åŒçš„ä»»åŠ¡ï¼Œéœ€è¦é’ˆå¯¹æ¯ä¸ªä»»åŠ¡è¿›è¡Œå•ç‹¬è®­ç»ƒã€‚è¿™ä½¿å¾—äººå½¢æœºå™¨äººåœ¨éç»“æ„åŒ–ç¯å¢ƒä¸­çš„åº”ç”¨å—åˆ°é™åˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVisualMimicçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†loco-manipulationä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªå±‚æ¬¡ï¼šä½çº§çš„å…³é”®ç‚¹è·Ÿè¸ªå’Œé«˜çº§çš„ç­–ç•¥æ§åˆ¶ã€‚ä½çº§å…³é”®ç‚¹è·Ÿè¸ªå™¨è´Ÿè´£ä»è§†è§‰è¾“å…¥ä¸­æå–äººä½“å…³é”®ç‚¹ä¿¡æ¯ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºæœºå™¨äººå¯æ‰§è¡Œçš„åŠ¨ä½œã€‚é«˜çº§ç­–ç•¥åˆ™æ ¹æ®è§†è§‰å’Œæœ¬ä½“æ„Ÿè§‰è¾“å…¥ï¼Œç”Ÿæˆå…³é”®ç‚¹å‘½ä»¤ï¼ŒæŒ‡å¯¼ä½çº§è·Ÿè¸ªå™¨å®Œæˆä»»åŠ¡ã€‚è¿™ç§åˆ†å±‚ç»“æ„ä½¿å¾—ç³»ç»Ÿå¯ä»¥æ›´å¥½åœ°è§£è€¦æ„ŸçŸ¥å’Œæ§åˆ¶ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVisualMimicçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) ä½çº§å…³é”®ç‚¹è·Ÿè¸ªå™¨ï¼šä½¿ç”¨teacher-studentå­¦ä¹ æ–¹æ¡ˆï¼Œä»äººç±»è¿åŠ¨æ•°æ®ä¸­è®­ç»ƒå¾—åˆ°ï¼Œè´Ÿè´£å°†è§†è§‰è¾“å…¥è½¬åŒ–ä¸ºå…³é”®ç‚¹åŠ¨ä½œï¼›2) é«˜çº§ç­–ç•¥ï¼šæ ¹æ®è§†è§‰å’Œæœ¬ä½“æ„Ÿè§‰è¾“å…¥ï¼Œç”Ÿæˆå…³é”®ç‚¹å‘½ä»¤ï¼ŒæŒ‡å¯¼ä½çº§è·Ÿè¸ªå™¨å®Œæˆä»»åŠ¡ï¼›3) æ¨¡æ‹Ÿç¯å¢ƒï¼šç”¨äºè®­ç»ƒé«˜çº§ç­–ç•¥ï¼Œå¹¶é€šè¿‡å™ªå£°æ³¨å…¥å’ŒåŠ¨ä½œè£å‰ªç­‰æŠ€æœ¯ï¼Œæé«˜sim-to-realçš„è¿ç§»èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šVisualMimicçš„å…³é”®åˆ›æ–°åœ¨äºå…¶åˆ†å±‚æ§åˆ¶ç»“æ„å’Œsim-to-realè¿ç§»ç­–ç•¥ã€‚åˆ†å±‚æ§åˆ¶ç»“æ„å°†loco-manipulationä»»åŠ¡åˆ†è§£ä¸ºä½çº§å…³é”®ç‚¹è·Ÿè¸ªå’Œé«˜çº§ç­–ç•¥æ§åˆ¶ï¼Œé™ä½äº†ä»»åŠ¡çš„å¤æ‚æ€§ï¼Œæé«˜äº†æ³›åŒ–èƒ½åŠ›ã€‚sim-to-realè¿ç§»ç­–ç•¥é€šè¿‡å™ªå£°æ³¨å…¥å’ŒåŠ¨ä½œè£å‰ªç­‰æŠ€æœ¯ï¼Œå‡å°äº†æ¨¡æ‹Ÿç¯å¢ƒå’ŒçœŸå®ç¯å¢ƒä¹‹é—´çš„å·®å¼‚ï¼Œå®ç°äº†é›¶æ ·æœ¬è¿ç§»ã€‚

**å…³é”®è®¾è®¡**ï¼šä½çº§å…³é”®ç‚¹è·Ÿè¸ªå™¨ä½¿ç”¨Transformerç½‘ç»œç»“æ„ï¼Œä»¥æé«˜è·Ÿè¸ªç²¾åº¦ã€‚é«˜çº§ç­–ç•¥ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•è¿›è¡Œè®­ç»ƒï¼Œå¥–åŠ±å‡½æ•°çš„è®¾è®¡è€ƒè™‘äº†ä»»åŠ¡ç›®æ ‡å’Œè¿åŠ¨çš„è‡ªç„¶æ€§ã€‚ä¸ºäº†æé«˜è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œè®ºæ–‡è¿˜é‡‡ç”¨äº†å™ªå£°æ³¨å…¥å’ŒåŠ¨ä½œè£å‰ªç­‰æŠ€æœ¯ã€‚å™ªå£°æ³¨å…¥é€šè¿‡åœ¨ä½çº§ç­–ç•¥ä¸­æ·»åŠ éšæœºå™ªå£°ï¼Œå¢åŠ äº†ç­–ç•¥çš„é²æ£’æ€§ã€‚åŠ¨ä½œè£å‰ªåˆ™é€šè¿‡é™åˆ¶é«˜çº§åŠ¨ä½œçš„èŒƒå›´ï¼Œé¿å…äº†ä¸è‡ªç„¶çš„è¿åŠ¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VisualMimicå®ç°äº†åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è®­ç»ƒçš„è§†è§‰è¿åŠ¨ç­–ç•¥åˆ°çœŸå®äººå‹æœºå™¨äººçš„é›¶æ ·æœ¬è¿ç§»ï¼Œå¹¶åœ¨å¤šç§loco-manipulationä»»åŠ¡ï¼ˆå¦‚ç®±å­æ¬è¿ã€æ¨ç®±å­ã€è¶³çƒè¿çƒå’Œè¸¢çƒï¼‰å’Œæˆ·å¤–ç¯å¢ƒä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ— éœ€å¤–éƒ¨è¿åŠ¨æ•æ‰ç³»ç»Ÿï¼Œä¸”èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”éç»“æ„åŒ–ç¯å¢ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VisualMimicåœ¨äººå½¢æœºå™¨äººé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨ç‰©æµã€ä»“å‚¨ã€å®¶åº­æœåŠ¡ç­‰åœºæ™¯ä¸­ï¼Œå¯ä»¥ç”¨äºå®Œæˆç‰©å“æ¬è¿ã€ç¯å¢ƒæ¸…æ´ç­‰ä»»åŠ¡ã€‚è¯¥ç ”ç©¶çš„å®é™…ä»·å€¼åœ¨äºé™ä½äº†äººå½¢æœºå™¨äººçš„å¼€å‘å’Œéƒ¨ç½²æˆæœ¬ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”çœŸå®ç¯å¢ƒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ›´å¤æ‚çš„ä»»åŠ¡ï¼Œä¾‹å¦‚ç¾éš¾æ•‘æ´ã€åŒ»ç–—è¾…åŠ©ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Humanoid loco-manipulation in unstructured environments demands tight integration of egocentric perception and whole-body control. However, existing approaches either depend on external motion capture systems or fail to generalize across diverse tasks. We introduce VisualMimic, a visual sim-to-real framework that unifies egocentric vision with hierarchical whole-body control for humanoid robots. VisualMimic combines a task-agnostic low-level keypoint tracker -- trained from human motion data via a teacher-student scheme -- with a task-specific high-level policy that generates keypoint commands from visual and proprioceptive input. To ensure stable training, we inject noise into the low-level policy and clip high-level actions using human motion statistics. VisualMimic enables zero-shot transfer of visuomotor policies trained in simulation to real humanoid robots, accomplishing a wide range of loco-manipulation tasks such as box lifting, pushing, football dribbling, and kicking. Beyond controlled laboratory settings, our policies also generalize robustly to outdoor environments. Videos are available at: https://visualmimic.github.io .

