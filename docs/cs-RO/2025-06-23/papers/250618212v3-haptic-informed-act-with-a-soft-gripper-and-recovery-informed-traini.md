---
layout: default
title: Haptic-Informed ACT with a Soft Gripper and Recovery-Informed Training for Pseudo Oocyte Manipulation
---

# Haptic-Informed ACT with a Soft Gripper and Recovery-Informed Training for Pseudo Oocyte Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.18212" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.18212v3</a>
  <a href="https://arxiv.org/pdf/2506.18212.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.18212v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.18212v3', 'Haptic-Informed ACT with a Soft Gripper and Recovery-Informed Training for Pseudo Oocyte Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pedro Miguel Uriguen Eljuri, Hironobu Shibata, Maeyama Katsuyoshi, Yuanyuan Jia, Tadahiro Taniguchi

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-23 (æ›´æ–°: 2025-07-16)

**å¤‡æ³¨**: Accepted at IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2025) Project website https://tanichu-laboratory.github.io/pedro_haptic_act_iros2025/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHaptic-Informed ACTä»¥è§£å†³ä¼ªåµæ¯ç»†èƒæ“ä½œä¸­çš„è‡ªåŠ¨åŒ–æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¼ªåµæ¯ç»†èƒæ“ä½œ` `è§¦è§‰åé¦ˆ` `åŠ¨ä½œåˆ†å—` `å¤šæ¨¡æ€å­¦ä¹ ` `ç”Ÿç‰©åŒ»å­¦è‡ªåŠ¨åŒ–` `æœºå™¨äººæŠ€æœ¯` `3Dæ‰“å°` `è½¯æŠ“æ‰‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åµæ¯ç»†èƒè½¬ç§»è‡ªåŠ¨åŒ–æ–¹æ³•è¿‡äºä¾èµ–è§†è§‰ï¼Œéš¾ä»¥åº”å¯¹ç”Ÿç‰©å˜å¼‚å’Œç¯å¢ƒå¹²æ‰°ï¼Œå¯¼è‡´éœ€è¦äººå·¥å¹²é¢„ã€‚
2. è®ºæ–‡æå‡ºHaptic-Informed ACTï¼Œé€šè¿‡å¼•å…¥è§¦è§‰åé¦ˆå’Œ3Dæ‰“å°è½¯æŠ“æ‰‹ï¼Œå¢å¼ºäº†æœºå™¨äººåœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„æ“ä½œèƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHaptic-Informed ACTåœ¨ä»»åŠ¡æˆåŠŸç‡å’Œé€‚åº”æ€§ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå°¤å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­è¡¨ç°çªå‡ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†ä¸€ç§å…ˆè¿›çš„æœºå™¨äººç³»ç»ŸHaptic-Informed ACTï¼Œç”¨äºä¼ªåµæ¯ç»†èƒæ“ä½œï¼Œç»“åˆäº†å¤šæ¨¡æ€ä¿¡æ¯å’ŒåŸºäºå˜æ¢å™¨çš„åŠ¨ä½œåˆ†å—ï¼ˆACTï¼‰ã€‚ä¼ ç»Ÿçš„åµæ¯ç»†èƒè½¬ç§»è‡ªåŠ¨åŒ–æ–¹æ³•è¿‡äºä¾èµ–è§†è§‰æ„ŸçŸ¥ï¼Œå¸¸å¸¸éœ€è¦äººå·¥ç›‘ç£ä»¥åº”å¯¹ç”Ÿç‰©å˜å¼‚å’Œç¯å¢ƒå¹²æ‰°ã€‚Haptic-Informed ACTé€šè¿‡å¼•å…¥è§¦è§‰åé¦ˆï¼Œå¢å¼ºäº†ACTçš„èƒ½åŠ›ï¼Œå®ç°äº†å®æ—¶æŠ“å–å¤±è´¥æ£€æµ‹å’Œè‡ªé€‚åº”ä¿®æ­£ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ä»‹ç»äº†ä¸€ç§3Dæ‰“å°çš„TPUè½¯æŠ“æ‰‹ï¼Œä»¥ä¾¿äºç²¾ç»†æ“ä½œã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHaptic-Informed ACTåœ¨åŠ¨æ€ç¯å¢ƒä¸­ç›¸æ¯”ä¼ ç»ŸACTæ˜¾è‘—æé«˜äº†ä»»åŠ¡æˆåŠŸç‡ã€é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚è¿™äº›å‘ç°çªæ˜¾äº†å¤šæ¨¡æ€å­¦ä¹ åœ¨ç”Ÿç‰©åŒ»å­¦è‡ªåŠ¨åŒ–ä¸­çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ªåµæ¯ç»†èƒæ“ä½œä¸­ä¼ ç»Ÿè‡ªåŠ¨åŒ–æ–¹æ³•çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯å¯¹è§†è§‰ä¾èµ–çš„ä¸è¶³å’Œç”Ÿç‰©å˜å¼‚å¸¦æ¥çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ï¼Œå¸¸éœ€äººå·¥å¹²é¢„ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHaptic-Informed ACTçš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆè§¦è§‰åé¦ˆä¸åŠ¨ä½œåˆ†å—ï¼ˆACTï¼‰ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿå®æ—¶æ£€æµ‹æŠ“å–å¤±è´¥å¹¶è¿›è¡Œè‡ªé€‚åº”ä¿®æ­£ï¼Œä»è€Œæé«˜æ“ä½œçš„ç²¾ç¡®æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç³»ç»ŸåŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆæ˜¯ä¼ æ„Ÿå™¨æ¨¡å—ï¼Œæ”¶é›†è§¦è§‰å’Œè§†è§‰ä¿¡æ¯ï¼›å…¶æ¬¡æ˜¯å†³ç­–æ¨¡å—ï¼ŒåŸºäºå¤šæ¨¡æ€ä¿¡æ¯è¿›è¡Œå®æ—¶å†³ç­–ï¼›æœ€åæ˜¯æ‰§è¡Œæ¨¡å—ï¼Œåˆ©ç”¨3Dæ‰“å°çš„TPUè½¯æŠ“æ‰‹è¿›è¡Œç²¾ç»†æ“ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†è§¦è§‰åé¦ˆé›†æˆåˆ°åŠ¨ä½œåˆ†å—æ¡†æ¶ä¸­ï¼Œä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåœ¨å¤æ‚å’ŒåŠ¨æ€ç¯å¢ƒä¸­è‡ªé€‚åº”è°ƒæ•´æ“ä½œç­–ç•¥ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„å•ä¸€è§†è§‰ä¾èµ–å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æŠ“å–æˆåŠŸç‡ï¼Œå¹¶é€šè¿‡è°ƒæ•´ç½‘ç»œç»“æ„ä»¥é€‚åº”å¤šæ¨¡æ€è¾“å…¥ï¼Œç¡®ä¿ç³»ç»Ÿåœ¨ä¸åŒç¯å¢ƒä¸‹çš„é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚å®éªŒä¸­ä½¿ç”¨çš„TPUè½¯æŠ“æ‰‹è®¾è®¡ä¹Ÿä¸ºç²¾ç»†æ“ä½œæä¾›äº†é‡è¦æ”¯æŒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒHaptic-Informed ACTåœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„ä»»åŠ¡æˆåŠŸç‡æé«˜äº†çº¦30%ï¼Œé²æ£’æ€§å’Œé€‚åº”æ€§æ˜¾è‘—å¢å¼ºï¼Œå°¤å…¶åœ¨å¤æ‚æ“ä½œåœºæ™¯ä¸­è¡¨ç°ä¼˜äºä¼ ç»ŸACTæ–¹æ³•ã€‚è¿™äº›ç»“æœéªŒè¯äº†å¤šæ¨¡æ€å­¦ä¹ åœ¨ç”Ÿç‰©åŒ»å­¦è‡ªåŠ¨åŒ–ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”Ÿç‰©åŒ»å­¦è‡ªåŠ¨åŒ–ã€ç»†èƒæ“ä½œå’Œå®éªŒå®¤æœºå™¨äººç­‰ã€‚é€šè¿‡æé«˜ä¼ªåµæ¯ç»†èƒæ“ä½œçš„è‡ªåŠ¨åŒ–ç¨‹åº¦ï¼ŒHaptic-Informed ACTæœ‰æœ›å‡å°‘äººå·¥å¹²é¢„ï¼Œæé«˜å®éªŒæ•ˆç‡ï¼Œæ¨åŠ¨ç”Ÿç‰©åŒ»å­¦ç ”ç©¶çš„å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½æ‰©å±•åˆ°å…¶ä»–éœ€è¦ç²¾ç»†æ“ä½œçš„é¢†åŸŸï¼Œå¦‚å¾®åˆ›æ‰‹æœ¯å’Œç»†èƒå·¥ç¨‹ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this paper, we introduce Haptic-Informed ACT, an advanced robotic system for pseudo oocyte manipulation, integrating multimodal information and Action Chunking with Transformers (ACT). Traditional automation methods for oocyte transfer rely heavily on visual perception, often requiring human supervision due to biological variability and environmental disturbances. Haptic-Informed ACT enhances ACT by incorporating haptic feedback, enabling real-time grasp failure detection and adaptive correction. Additionally, we introduce a 3D-printed TPU soft gripper to facilitate delicate manipulations. Experimental results demonstrate that Haptic-Informed ACT improves the task success rate, robustness, and adaptability compared to conventional ACT, particularly in dynamic environments. These findings highlight the potential of multimodal learning in robotics for biomedical automation.

