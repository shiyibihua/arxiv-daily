---
layout: default
title: Multimodal Anomaly Detection with a Mixture-of-Experts
---

# Multimodal Anomaly Detection with a Mixture-of-Experts

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.19077" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.19077v1</a>
  <a href="https://arxiv.org/pdf/2506.19077.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.19077v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.19077v1', 'Multimodal Anomaly Detection with a Mixture-of-Experts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Christoph Willibald, Daniel Sliwowski, Dongheui Lee

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-23

**å¤‡æ³¨**: 8 pages, 5 figures, 1 table, the paper has been accepted for publication in the Proceedings of the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ··åˆä¸“å®¶æ¨¡å‹ä»¥è§£å†³å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹` `æ··åˆä¸“å®¶æ¨¡å‹` `è§†è§‰-è¯­è¨€æ¨¡å‹` `é«˜æ–¯æ··åˆå›å½’` `æœºå™¨äººæ“ä½œ` `ç¯å¢ƒç›‘æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•é€šå¸¸åªå…³æ³¨æœºå™¨äººé©±åŠ¨æˆ–ç¯å¢ƒé©±åŠ¨çš„å¼‚å¸¸ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰ä¸¤è€…çš„ç»¼åˆå½±å“ã€‚
2. æœ¬æ–‡æå‡ºçš„æ··åˆä¸“å®¶æ¡†æ¶æ•´åˆäº†è§†è§‰-è¯­è¨€æ¨¡å‹ä¸é«˜æ–¯æ··åˆå›å½’æ£€æµ‹å™¨ï¼Œä»¥å®ç°å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ£€æµ‹å»¶è¿Ÿä¸Šå‡å°‘äº†60%ï¼Œå¹¶ä¸”åœ¨é€å¸§å¼‚å¸¸æ£€æµ‹æ€§èƒ½ä¸Šä¼˜äºå•ä¸€æ£€æµ‹å™¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€æœºå™¨äººåœ¨å¤šç§åº”ç”¨ä¸­çš„å¹¿æ³›éƒ¨ç½²ï¼Œç¨³å¥çš„å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹å˜å¾—æ„ˆå‘é‡è¦ã€‚åœ¨æœºå™¨äººæ“ä½œä¸­ï¼Œæ•…éšœé€šå¸¸æºäºæœºå™¨äººé©±åŠ¨çš„å¼‚å¸¸å’Œç¯å¢ƒé©±åŠ¨çš„å¼‚å¸¸ã€‚ä¼ ç»Ÿçš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•é€šå¸¸åªå…³æ³¨å…¶ä¸­ä¸€ç§æ¥æºï¼Œå¯¼è‡´æ— æ³•å…¨é¢æ•æ‰å¼‚å¸¸ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆä¸“å®¶æ¡†æ¶ï¼Œç»“åˆè§†è§‰-è¯­è¨€æ¨¡å‹å’ŒåŸºäºé«˜æ–¯æ··åˆå›å½’çš„æ£€æµ‹å™¨ï¼ŒåŠ¨æ€é€‰æ‹©æœ€å¯é çš„æ£€æµ‹å™¨è¿›è¡Œèåˆã€‚é€šè¿‡åœ¨å®¶åº­å’Œå·¥ä¸šä»»åŠ¡ä¸Šçš„è¯„ä¼°ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨æ£€æµ‹å»¶è¿Ÿå’Œæ€§èƒ½ä¸Šçš„æ˜¾è‘—æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹ä¸­çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€åªå…³æ³¨æœºå™¨äººé©±åŠ¨æˆ–ç¯å¢ƒé©±åŠ¨çš„å¼‚å¸¸ï¼Œå¯¼è‡´æ— æ³•å…¨é¢æ•æ‰å¼‚å¸¸æƒ…å†µã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„æ··åˆä¸“å®¶æ¡†æ¶é€šè¿‡ç»“åˆä¸åŒçš„æ£€æµ‹æœºåˆ¶ï¼Œåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹ç›‘æµ‹ç¯å¢ƒå˜åŒ–ï¼ŒåŒæ—¶ä½¿ç”¨é«˜æ–¯æ··åˆå›å½’æ£€æµ‹å™¨è·Ÿè¸ªæœºå™¨äººè¿åŠ¨å’Œäº¤äº’åŠ›çš„åå·®ï¼Œä»è€Œå®ç°æ›´å…¨é¢çš„å¼‚å¸¸æ£€æµ‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè§†è§‰-è¯­è¨€æ¨¡å‹ç”¨äºç¯å¢ƒç›‘æµ‹ï¼Œå’Œé«˜æ–¯æ··åˆå›å½’æ£€æµ‹å™¨ç”¨äºè·Ÿè¸ªæœºå™¨äººè¡Œä¸ºã€‚é€šè¿‡ä¿¡å¿ƒåŸºç¡€çš„èåˆæœºåˆ¶ï¼ŒåŠ¨æ€é€‰æ‹©æœ€å¯é çš„æ£€æµ‹å™¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†ä¿¡å¿ƒåŸºç¡€çš„èåˆæœºåˆ¶ï¼Œä½¿å¾—åœ¨ä¸åŒæƒ…å†µä¸‹èƒ½å¤Ÿé€‰æ‹©æœ€é€‚åˆçš„æ£€æµ‹å™¨ï¼Œæå‡äº†æ£€æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†é«˜æ–¯æ··åˆæ¨¡å‹è¿›è¡Œå¼‚å¸¸æ£€æµ‹ï¼Œç»“åˆäº†å¤šæ¨¡æ€æ•°æ®çš„ç‰¹å¾ï¼Œç¡®ä¿äº†æ¨¡å‹åœ¨ä¸åŒç¯å¢ƒå’Œä»»åŠ¡ä¸‹çš„é€‚åº”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„æ–¹æ³•åœ¨å®¶åº­å’Œå·¥ä¸šä»»åŠ¡ä¸­ç›¸æ¯”äºå•ä¸€æ£€æµ‹å™¨ï¼Œæ£€æµ‹å»¶è¿Ÿå‡å°‘äº†60%ï¼Œå¹¶ä¸”åœ¨é€å¸§å¼‚å¸¸æ£€æµ‹æ€§èƒ½ä¸Šæœ‰æ˜¾è‘—æå‡ï¼Œè¯æ˜äº†æ··åˆä¸“å®¶æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®¶åº­è‡ªåŠ¨åŒ–ã€å·¥ä¸šæœºå™¨äººæ“ä½œåŠå…¶ä»–éœ€è¦å®æ—¶ç›‘æµ‹å’Œå¼‚å¸¸æ£€æµ‹çš„åœºæ™¯ã€‚é€šè¿‡æé«˜å¼‚å¸¸æ£€æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œå®‰å…¨æ€§å’Œå¯é æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With a growing number of robots being deployed across diverse applications, robust multimodal anomaly detection becomes increasingly important. In robotic manipulation, failures typically arise from (1) robot-driven anomalies due to an insufficient task model or hardware limitations, and (2) environment-driven anomalies caused by dynamic environmental changes or external interferences. Conventional anomaly detection methods focus either on the first by low-level statistical modeling of proprioceptive signals or the second by deep learning-based visual environment observation, each with different computational and training data requirements. To effectively capture anomalies from both sources, we propose a mixture-of-experts framework that integrates the complementary detection mechanisms with a visual-language model for environment monitoring and a Gaussian-mixture regression-based detector for tracking deviations in interaction forces and robot motions. We introduce a confidence-based fusion mechanism that dynamically selects the most reliable detector for each situation. We evaluate our approach on both household and industrial tasks using two robotic systems, demonstrating a 60% reduction in detection delay while improving frame-wise anomaly detection performance compared to individual detectors.

