---
layout: default
title: Symmetry-Breaking in Multi-Agent Navigation: Winding Number-Aware MPC with a Learned Topological Strategy
---

# Symmetry-Breaking in Multi-Agent Navigation: Winding Number-Aware MPC with a Learned Topological Strategy

**arXiv**: [2511.15239v1](https://arxiv.org/abs/2511.15239) | [PDF](https://arxiv.org/pdf/2511.15239.pdf)

**ä½œè€…**: Tomoki Nakao, Kazumi Kasaura, Tadashi Kozuno

**åˆ†ç±»**: cs.RO, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-11-19

**å¤‡æ³¨**: 11 pages, 5 figures

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/omron-sinicx/WNumMPC)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽç»•æ•°æ„ŸçŸ¥çš„MPCæ–¹æ³•ï¼Œè§£å†³å¤šæ™ºèƒ½ä½“å¯¼èˆªä¸­çš„å¯¹ç§°æ€§ç ´ç¼ºé—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“å¯¼èˆª` `å¯¹ç§°æ€§ç ´ç¼º` `ç»•æ•°` `å¼ºåŒ–å­¦ä¹ ` `æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ™ºèƒ½ä½“å¯¼èˆªä¸­ï¼Œå¯¹ç§°æ€§å¯¼è‡´çš„æ­»é”é—®é¢˜æ˜¯æŒ‘æˆ˜ï¼Œæ™ºèƒ½ä½“éš¾ä»¥è‡ªä¸»å†³å®šé¿è®©æ–¹å¼ã€‚
2. åˆ©ç”¨ç»•æ•°è¿™ä¸€æ‹“æ‰‘ä¸å˜é‡é‡åŒ–åä½œç­–ç•¥ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ å­¦ä¹ å¯¹ç§°æ€§ç ´ç¼ºç­–ç•¥ã€‚
3. åˆ†å±‚ç­–ç•¥ç»“åˆå­¦ä¹ çš„å†³ç­–èƒ½åŠ›å’Œæ¨¡åž‹çš„å¯é æ€§ï¼Œåœ¨å¯†é›†çŽ¯å¢ƒä¸­è¡¨çŽ°ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åˆ†å±‚å¯¼èˆªæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³åˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“å¯¼èˆªä¸­ç”±å¯¹ç§°æ€§å¼•èµ·çš„æ­»é”è¿™ä¸€æ ¹æœ¬æŒ‘æˆ˜ã€‚å½“å¤šä¸ªæ™ºèƒ½ä½“äº¤äº’æ—¶ï¼Œè‡ªä¸»æ‰“ç ´ç›¸äº’é¿è®©æ–¹å¼çš„å¯¹ç§°æ€§éžå¸¸å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ç§°ä¸ºç»•æ•°çš„æ‹“æ‰‘ä¸å˜é‡æ¥é‡åŒ–åä½œå¯¹ç§°æ€§ç ´ç¼ºç­–ç•¥ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥å­¦ä¹ è¿™äº›ç­–ç•¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨åˆ†å±‚ç­–ç•¥ï¼ŒåŒ…æ‹¬ä¸€ä¸ªåŸºäºŽå­¦ä¹ çš„è§„åˆ’å™¨ï¼ˆPlannerï¼‰å’Œä¸€ä¸ªåŸºäºŽæ¨¡åž‹çš„æŽ§åˆ¶å™¨ï¼ˆControllerï¼‰ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œè§„åˆ’å™¨å­¦ä¹ ä¸ºæŽ§åˆ¶å™¨ç”Ÿæˆä¸¤ç§ç±»åž‹çš„å‚æ•°ï¼šä¸€ç§æ˜¯ç”±ç»•æ•°è¡¨ç¤ºçš„æ‹“æ‰‘åä½œç­–ç•¥ï¼Œå¦ä¸€ç§æ˜¯åŠ¨æ€æƒé‡é›†ï¼Œç”¨äºŽç¡®å®šåœ¨å¤šä¸ªæ™ºèƒ½ä½“åŒæ—¶äº¤å‰çš„å¯†é›†åœºæ™¯ä¸­ä¼˜å…ˆè€ƒè™‘å“ªä¸ªæ™ºèƒ½ä½“äº¤äº’ã€‚ç„¶åŽï¼ŒæŽ§åˆ¶å™¨æ ¹æ®è§„åˆ’å™¨æä¾›çš„ç­–ç•¥å’Œæƒé‡ç”Ÿæˆæ— ç¢°æ’žä¸”é«˜æ•ˆçš„è¿åŠ¨ã€‚è¿™ç§åˆ†å±‚ç»“æž„ç»“åˆäº†åŸºäºŽå­¦ä¹ çš„æ–¹æ³•çš„çµæ´»å†³ç­–èƒ½åŠ›å’ŒåŸºäºŽæ¨¡åž‹çš„æ–¹æ³•çš„å¯é æ€§ã€‚ä»¿çœŸå’ŒçœŸå®žæœºå™¨äººå®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºŽçŽ°æœ‰çš„åŸºçº¿ï¼Œå°¤å…¶æ˜¯åœ¨å¯†é›†çŽ¯å¢ƒä¸­ï¼Œé€šè¿‡æœ‰æ•ˆåœ°é¿å…ç¢°æ’žå’Œæ­»é”ï¼ŒåŒæ—¶å®žçŽ°å“è¶Šçš„å¯¼èˆªæ€§èƒ½ã€‚å®žéªŒä»£ç å·²åœ¨GitHubä¸Šå¼€æºã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“å¯¼èˆªä¸­ï¼Œç”±äºŽå¯¹ç§°æ€§å¯¼è‡´çš„æ­»é”é—®é¢˜ã€‚å½“å¤šä¸ªæ™ºèƒ½ä½“éœ€è¦åœ¨åŒä¸€åŒºåŸŸå†…ç§»åŠ¨æ—¶ï¼Œå®ƒä»¬å¯èƒ½ä¼šé™·å…¥äº’ç›¸ç­‰å¾…çš„çŠ¶æ€ï¼Œæ— æ³•è‡ªä¸»å†³å®šå¦‚ä½•é¿è®©ï¼Œä»Žè€Œå¯¼è‡´å¯¼èˆªå¤±è´¥ã€‚çŽ°æœ‰çš„æ–¹æ³•é€šå¸¸éš¾ä»¥æœ‰æ•ˆåœ°æ‰“ç ´è¿™ç§å¯¹ç§°æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æ™ºèƒ½ä½“å¯†åº¦è¾ƒé«˜çš„çŽ¯å¢ƒä¸­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ‹“æ‰‘ä¸å˜é‡â€œç»•æ•°â€æ¥é‡åŒ–æ™ºèƒ½ä½“ä¹‹é—´çš„åä½œç­–ç•¥ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥å­¦ä¹ è¿™äº›ç­–ç•¥ã€‚ç»•æ•°å¯ä»¥æè¿°æ™ºèƒ½ä½“å›´ç»•å½¼æ­¤è¿åŠ¨çš„åœˆæ•°ï¼Œä»Žè€Œåæ˜ äº†æ™ºèƒ½ä½“ä¹‹é—´çš„ç›¸å¯¹è¿åŠ¨å…³ç³»ã€‚é€šè¿‡å­¦ä¹ ä¸åŒçš„ç»•æ•°ç­–ç•¥ï¼Œæ™ºèƒ½ä½“å¯ä»¥æœ‰æ•ˆåœ°æ‰“ç ´å¯¹ç§°æ€§ï¼Œé¿å…æ­»é”ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•é‡‡ç”¨åˆ†å±‚ç­–ç•¥ï¼ŒåŒ…æ‹¬ä¸€ä¸ªåŸºäºŽå­¦ä¹ çš„è§„åˆ’å™¨ï¼ˆPlannerï¼‰å’Œä¸€ä¸ªåŸºäºŽæ¨¡åž‹çš„æŽ§åˆ¶å™¨ï¼ˆControllerï¼‰ã€‚è§„åˆ’å™¨è´Ÿè´£ç”Ÿæˆæ‹“æ‰‘åä½œç­–ç•¥ï¼ˆç»•æ•°ï¼‰å’ŒåŠ¨æ€æƒé‡ï¼ŒæŽ§åˆ¶å™¨åˆ™æ ¹æ®è¿™äº›ä¿¡æ¯ç”Ÿæˆæ— ç¢°æ’žçš„è¿åŠ¨è½¨è¿¹ã€‚è§„åˆ’å™¨ä½¿ç”¨å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œä»¥å­¦ä¹ æœ€ä¼˜çš„åä½œç­–ç•¥ã€‚æŽ§åˆ¶å™¨é‡‡ç”¨æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶ï¼ˆMPCï¼‰æ–¹æ³•ï¼Œæ ¹æ®è§„åˆ’å™¨æä¾›çš„ç­–ç•¥å’Œæƒé‡ï¼Œç”Ÿæˆæ»¡è¶³çº¦æŸæ¡ä»¶çš„è¿åŠ¨è½¨è¿¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽå°†æ‹“æ‰‘ä¸å˜é‡â€œç»•æ•°â€å¼•å…¥åˆ°å¤šæ™ºèƒ½ä½“å¯¼èˆªä¸­ï¼Œå¹¶å°†å…¶ä¸Žå¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œä»Žè€Œå®žçŽ°äº†å¯¹åä½œç­–ç•¥çš„æœ‰æ•ˆå­¦ä¹ ã€‚ä¸Žä¼ ç»Ÿçš„åŸºäºŽè§„åˆ™æˆ–ä¼˜åŒ–çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å¤æ‚çš„çŽ¯å¢ƒå’ŒåŠ¨æ€çš„æ™ºèƒ½ä½“äº¤äº’ã€‚

**å…³é”®è®¾è®¡**ï¼šè§„åˆ’å™¨ä½¿ç”¨æ·±åº¦ç¥žç»ç½‘ç»œä½œä¸ºç­–ç•¥ç½‘ç»œï¼Œè¾“å…¥æ˜¯æ™ºèƒ½ä½“çš„çŠ¶æ€ä¿¡æ¯ï¼Œè¾“å‡ºæ˜¯ç»•æ•°å’ŒåŠ¨æ€æƒé‡ã€‚å¼ºåŒ–å­¦ä¹ é‡‡ç”¨Actor-Criticç®—æ³•è¿›è¡Œè®­ç»ƒï¼Œå¥–åŠ±å‡½æ•°çš„è®¾è®¡æ—¨åœ¨é¼“åŠ±æ™ºèƒ½ä½“é¿å…ç¢°æ’žã€å°½å¿«åˆ°è¾¾ç›®æ ‡ç‚¹ï¼Œå¹¶ä¿æŒä¸€å®šçš„åä½œæ€§ã€‚æŽ§åˆ¶å™¨é‡‡ç”¨æ¨¡åž‹é¢„æµ‹æŽ§åˆ¶ï¼ˆMPCï¼‰æ–¹æ³•ï¼Œç›®æ ‡å‡½æ•°åŒ…æ‹¬åˆ°è¾¾ç›®æ ‡ç‚¹çš„æ—¶é—´ã€é¿å…ç¢°æ’žçš„ä»£ä»·å’ŒæŽ§åˆ¶è¾“å…¥çš„ä»£ä»·ã€‚åŠ¨æ€æƒé‡ç”¨äºŽè°ƒæ•´ä¸åŒæ™ºèƒ½ä½“ä¹‹é—´çš„ä¼˜å…ˆçº§ï¼Œä»Žè€Œåœ¨å¯†é›†çŽ¯å¢ƒä¸­æ›´å¥½åœ°é¿å…ç¢°æ’žã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨å¯†é›†çŽ¯å¢ƒä¸­æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰åŸºçº¿æ–¹æ³•ã€‚åœ¨ä»¿çœŸå’ŒçœŸå®žæœºå™¨äººå®žéªŒä¸­ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°é¿å…ç¢°æ’žå’Œæ­»é”ï¼Œå¹¶å®žçŽ°æ›´é«˜çš„å¯¼èˆªæˆåŠŸçŽ‡å’Œæ›´çŸ­çš„å¯¼èˆªæ—¶é—´ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•åœ¨æŸäº›åœºæ™¯ä¸‹å¯ä»¥å°†å¯¼èˆªæˆåŠŸçŽ‡æé«˜10%-20%ï¼Œå¯¼èˆªæ—¶é—´ç¼©çŸ­5%-10%ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽä»“å‚¨ç‰©æµã€è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººç¼–é˜Ÿç­‰é¢†åŸŸã€‚åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œå¤šä¸ªæ™ºèƒ½ä½“éœ€è¦åœ¨å¤æ‚çš„çŽ¯å¢ƒä¸­ååŒå®Œæˆä»»åŠ¡ï¼Œé¿å…ç¢°æ’žå’Œæ­»é”è‡³å…³é‡è¦ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæé«˜å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ•ˆçŽ‡å’Œå®‰å…¨æ€§ï¼Œé™ä½Žäººå·¥å¹²é¢„çš„éœ€æ±‚ï¼Œå…·æœ‰é‡è¦çš„å®žé™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We address the fundamental challenge of resolving symmetry-induced deadlocks in distributed multi-agent navigation by proposing a new hierarchical navigation method. When multiple agents interact, it is inherently difficult for them to autonomously break the symmetry of deciding how to pass each other. To tackle this problem, we introduce an approach that quantifies cooperative symmetry-breaking strategies using a topological invariant called the winding number, and learns the strategies themselves through reinforcement learning. Our method features a hierarchical policy consisting of a learning-based Planner, which plans topological cooperative strategies, and a model-based Controller, which executes them. Through reinforcement learning, the Planner learns to produce two types of parameters for the Controller: one is the topological cooperative strategy represented by winding numbers, and the other is a set of dynamic weights that determine which agent interaction to prioritize in dense scenarios where multiple agents cross simultaneously. The Controller then generates collision-free and efficient motions based on the strategy and weights provided by the Planner. This hierarchical structure combines the flexible decision-making ability of learning-based methods with the reliability of model-based approaches. Simulation and real-world robot experiments demonstrate that our method outperforms existing baselines, particularly in dense environments, by efficiently avoiding collisions and deadlocks while achieving superior navigation performance. The code for the experiments is available at https://github.com/omron-sinicx/WNumMPC.

