---
layout: default
title: Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception
---

# Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception

**arXiv**: [2511.15279v1](https://arxiv.org/abs/2511.15279) | [PDF](https://arxiv.org/pdf/2511.15279.pdf)

**ä½œè€…**: Jiashu Yang, Yifan Han, Yucheng Xie, Ning Guo, Wenzhao Lian

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-19

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEyeVLAï¼šä¸€ç§ç”¨äºŽå…·èº«æ„ŸçŸ¥çš„æœºå™¨äººçœ¼çƒï¼Œå®žçŽ°ä¸»åŠ¨è§†è§‰ä¿¡æ¯èŽ·å–ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æœºå™¨äººè§†è§‰` `å…·èº«æ™ºèƒ½` `è§†è§‰è¯­è¨€æ¨¡åž‹` `ä¸»åŠ¨æ„ŸçŸ¥` `å¼ºåŒ–å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è§†è§‰æ¨¡åž‹å’Œå›ºå®šç›¸æœºéš¾ä»¥å…¼é¡¾å¹¿åŸŸåœºæ™¯ç†è§£å’Œç²¾ç»†ç›®æ ‡è§‚å¯Ÿï¼Œé™åˆ¶äº†æœºå™¨äººåœ¨å¼€æ”¾çŽ¯å¢ƒä¸­çš„åº”ç”¨ã€‚
2. EyeVLAé€šè¿‡é›†æˆè§†è§‰-è¯­è¨€æ¨¡åž‹å’ŒåŠ¨ä½œtokenï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ ¹æ®æŒ‡ä»¤ä¸»åŠ¨è°ƒæ•´è§†è§’å’Œç¼©æ”¾ï¼ŒèŽ·å–æ›´æœ‰æ•ˆçš„ä¿¡æ¯ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒEyeVLAåœ¨çœŸå®žçŽ¯å¢ƒä¸­èƒ½æ ¹æ®æŒ‡ä»¤æ‰§è¡Œåœºæ™¯ï¼Œå¹¶é€šè¿‡ä¸»åŠ¨è°ƒæ•´è§†è§’èŽ·å–æ›´å‡†ç¡®çš„è§†è§‰ä¿¡æ¯ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å…·èº«AIæ„ŸçŸ¥ç³»ç»Ÿä¸­ï¼Œè§†è§‰æ„ŸçŸ¥åº”è¯¥æ˜¯ä¸»åŠ¨çš„ï¼šç›®æ ‡ä¸æ˜¯è¢«åŠ¨åœ°å¤„ç†é™æ€å›¾åƒï¼Œè€Œæ˜¯åœ¨åƒç´ å’Œç©ºé—´é¢„ç®—çº¦æŸå†…ä¸»åŠ¨èŽ·å–æ›´å¤šä¿¡æ¯æ•°æ®ã€‚çŽ°æœ‰çš„è§†è§‰æ¨¡åž‹å’Œå›ºå®šçš„RGB-Dç›¸æœºç³»ç»Ÿæ— æ³•å…¼é¡¾å¹¿åŸŸè¦†ç›–å’Œç²¾ç»†ç»†èŠ‚èŽ·å–ï¼Œä¸¥é‡é™åˆ¶äº†å®ƒä»¬åœ¨å¼€æ”¾ä¸–ç•Œæœºå™¨äººåº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºŽä¸»åŠ¨è§†è§‰æ„ŸçŸ¥çš„æœºå™¨äººçœ¼çƒEyeVLAï¼Œå®ƒå¯ä»¥æ ¹æ®æŒ‡ä»¤é‡‡å–ä¸»åŠ¨è¡ŒåŠ¨ï¼Œä»Žè€Œæ¸…æ™°åœ°è§‚å¯Ÿç²¾ç»†çš„ç›®æ ‡å¯¹è±¡å’Œå¹¿é˜”ç©ºé—´èŒƒå›´å†…çš„è¯¦ç»†ä¿¡æ¯ã€‚EyeVLAå°†åŠ¨ä½œè¡Œä¸ºç¦»æ•£åŒ–ä¸ºåŠ¨ä½œtokenï¼Œå¹¶å°†å®ƒä»¬ä¸Žå…·æœ‰å¼ºå¤§å¼€æ”¾ä¸–ç•Œç†è§£èƒ½åŠ›çš„è§†è§‰è¯­è¨€æ¨¡åž‹ï¼ˆVLMï¼‰é›†æˆï¼Œä»Žè€Œåœ¨å•ä¸ªè‡ªå›žå½’åºåˆ—ä¸­å®žçŽ°è§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œçš„è”åˆå»ºæ¨¡ã€‚é€šè¿‡ä½¿ç”¨2Dè¾¹ç•Œæ¡†åæ ‡æ¥æŒ‡å¯¼æŽ¨ç†é“¾ï¼Œå¹¶åº”ç”¨å¼ºåŒ–å­¦ä¹ æ¥ä¼˜åŒ–è§†ç‚¹é€‰æ‹©ç­–ç•¥ï¼Œæˆ‘ä»¬ä»…ä½¿ç”¨æœ€å°‘çš„çœŸå®žä¸–ç•Œæ•°æ®ï¼Œå°±å°†VLMçš„å¼€æ”¾ä¸–ç•Œåœºæ™¯ç†è§£èƒ½åŠ›è½¬ç§»åˆ°è§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰ç­–ç•¥ã€‚å®žéªŒè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿèƒ½å¤Ÿåœ¨çœŸå®žä¸–ç•ŒçŽ¯å¢ƒä¸­é«˜æ•ˆåœ°æ‰§è¡ŒæŒ‡ä»¤åœºæ™¯ï¼Œå¹¶é€šè¿‡æ—‹è½¬å’Œç¼©æ”¾çš„æŒ‡ä»¤é©±åŠ¨åŠ¨ä½œä¸»åŠ¨èŽ·å–æ›´å‡†ç¡®çš„è§†è§‰ä¿¡æ¯ï¼Œä»Žè€Œå®žçŽ°å¼ºå¤§çš„çŽ¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ã€‚EyeVLAå¼•å…¥äº†ä¸€ç§æ–°é¢–çš„æœºå™¨äººè§†è§‰ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨è¯¦ç»†ä¸”ç©ºé—´ä¸°å¯Œçš„ã€å¤§è§„æ¨¡å…·èº«æ•°æ®ï¼Œå¹¶ä¸»åŠ¨èŽ·å–ä¿¡æ¯é‡å¤§çš„è§†è§‰è§‚å¯Ÿç»“æžœï¼Œç”¨äºŽä¸‹æ¸¸å…·èº«ä»»åŠ¡ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰æœºå™¨äººè§†è§‰ç³»ç»Ÿéš¾ä»¥åŒæ—¶æ»¡è¶³å¹¿é˜”è§†é‡Žå’Œç²¾ç»†è§‚å¯Ÿçš„éœ€æ±‚ã€‚å›ºå®šç›¸æœºæ— æ³•ä¸»åŠ¨è°ƒæ•´è§†è§’ä»¥èŽ·å–æ›´ä½³çš„è§‚æµ‹ä¿¡æ¯ï¼Œè€Œä¼ ç»Ÿè§†è§‰æ¨¡åž‹ç¼ºä¹å¯¹åœºæ™¯çš„æ•´ä½“ç†è§£å’Œæ ¹æ®æŒ‡ä»¤è¿›è¡Œæ“ä½œçš„èƒ½åŠ›ã€‚è¿™é™åˆ¶äº†æœºå™¨äººåœ¨å¤æ‚å¼€æ”¾çŽ¯å¢ƒä¸­çš„åº”ç”¨ï¼Œä¾‹å¦‚åœ¨éœ€è¦å¯»æ‰¾ç‰¹å®šç‰©ä½“æˆ–æ£€æŸ¥ç»†èŠ‚æ—¶ï¼Œæ•ˆçŽ‡ä½Žä¸‹ç”šè‡³æ— æ³•å®Œæˆä»»åŠ¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEyeVLAçš„æ ¸å¿ƒåœ¨äºŽå°†è§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œè¿›è¡Œç»Ÿä¸€å»ºæ¨¡ï¼Œåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡åž‹ï¼ˆVLMï¼‰å¼ºå¤§çš„åœºæ™¯ç†è§£èƒ½åŠ›ï¼Œå¹¶å°†å…¶ä¸Žå¯æŽ§çš„æœºå™¨äººçœ¼çƒç›¸ç»“åˆã€‚é€šè¿‡å°†åŠ¨ä½œç¦»æ•£åŒ–ä¸ºåŠ¨ä½œtokenï¼Œå¹¶å°†å…¶èžå…¥VLMçš„è‡ªå›žå½’åºåˆ—ä¸­ï¼Œä½¿å¾—æœºå™¨äººèƒ½å¤Ÿæ ¹æ®æŒ‡ä»¤ï¼Œä¸»åŠ¨è°ƒæ•´è§†è§’å’Œç¼©æ”¾ï¼Œä»Žè€ŒèŽ·å–æ›´æœ‰æ•ˆçš„ç›®æ ‡ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šEyeVLAç³»ç»Ÿä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) æœºå™¨äººçœ¼çƒï¼šè´Ÿè´£æ‰§è¡Œæ—‹è½¬å’Œç¼©æ”¾ç­‰åŠ¨ä½œï¼ŒèŽ·å–ä¸åŒè§†è§’çš„å›¾åƒã€‚2) è§†è§‰è¯­è¨€æ¨¡åž‹ï¼ˆVLMï¼‰ï¼šç”¨äºŽç†è§£åœºæ™¯å’ŒæŒ‡ä»¤ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„åŠ¨ä½œåºåˆ—ã€‚3) åŠ¨ä½œtokenåŒ–æ¨¡å—ï¼šå°†è¿žç»­çš„åŠ¨ä½œç©ºé—´ç¦»æ•£åŒ–ä¸ºä¸€ç³»åˆ—åŠ¨ä½œtokenï¼Œæ–¹ä¾¿VLMè¿›è¡Œå¤„ç†ã€‚4) å¼ºåŒ–å­¦ä¹ æ¨¡å—ï¼šç”¨äºŽä¼˜åŒ–è§†ç‚¹é€‰æ‹©ç­–ç•¥ï¼Œæé«˜åŠ¨ä½œçš„æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼šæŽ¥æ”¶æŒ‡ä»¤ -> VLMç”ŸæˆåŠ¨ä½œåºåˆ— -> æœºå™¨äººçœ¼çƒæ‰§è¡ŒåŠ¨ä½œ -> èŽ·å–æ–°çš„å›¾åƒ -> VLMæ›´æ–°çŠ¶æ€ -> é‡å¤æ‰§è¡Œç›´åˆ°å®Œæˆä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šEyeVLAçš„å…³é”®åˆ›æ–°åœ¨äºŽå°†è§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œè¿›è¡Œç»Ÿä¸€å»ºæ¨¡ï¼Œå¹¶åˆ©ç”¨VLMå¼ºå¤§çš„åœºæ™¯ç†è§£èƒ½åŠ›æ¥æŒ‡å¯¼æœºå™¨äººçš„åŠ¨ä½œã€‚ä¸Žä¼ ç»Ÿçš„æœºå™¨äººè§†è§‰ç³»ç»Ÿç›¸æ¯”ï¼ŒEyeVLAèƒ½å¤Ÿæ ¹æ®æŒ‡ä»¤ä¸»åŠ¨è°ƒæ•´è§†è§’ï¼Œä»Žè€ŒèŽ·å–æ›´æœ‰æ•ˆçš„ç›®æ ‡ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œé€šè¿‡ä½¿ç”¨2Dè¾¹ç•Œæ¡†åæ ‡æ¥æŒ‡å¯¼æŽ¨ç†é“¾ï¼Œå¹¶åº”ç”¨å¼ºåŒ–å­¦ä¹ æ¥ä¼˜åŒ–è§†ç‚¹é€‰æ‹©ç­–ç•¥ï¼ŒEyeVLAèƒ½å¤Ÿä»…ä½¿ç”¨æœ€å°‘çš„çœŸå®žä¸–ç•Œæ•°æ®ï¼Œå°±å°†VLMçš„å¼€æ”¾ä¸–ç•Œåœºæ™¯ç†è§£èƒ½åŠ›è½¬ç§»åˆ°è§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰ç­–ç•¥ã€‚

**å…³é”®è®¾è®¡**ï¼šEyeVLAä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡åž‹ä½œä¸ºåŸºç¡€æ¨¡åž‹ï¼Œå¹¶å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”æœºå™¨äººçœ¼çƒçš„æŽ§åˆ¶ä»»åŠ¡ã€‚åŠ¨ä½œtokençš„è®¾è®¡éœ€è¦ä»”ç»†è€ƒè™‘ï¼Œæ—¢è¦ä¿è¯åŠ¨ä½œçš„ç²¾åº¦ï¼Œåˆè¦é¿å…åŠ¨ä½œç©ºé—´è¿‡äºŽåºžå¤§ã€‚å¼ºåŒ–å­¦ä¹ æ¨¡å—ä½¿ç”¨å¥–åŠ±å‡½æ•°æ¥å¼•å¯¼æœºå™¨äººå­¦ä¹ å¦‚ä½•é€‰æ‹©æœ€ä½³çš„è§†ç‚¹ã€‚å¥–åŠ±å‡½æ•°çš„è®¾è®¡éœ€è¦è€ƒè™‘ä»»åŠ¡çš„ç›®æ ‡ï¼Œä¾‹å¦‚ï¼Œå¦‚æžœä»»åŠ¡æ˜¯å¯»æ‰¾ç‰¹å®šç‰©ä½“ï¼Œåˆ™å¥–åŠ±å‡½æ•°å¯ä»¥è®¾ç½®ä¸ºç‰©ä½“å‡ºçŽ°åœ¨è§†é‡Žä¸­çš„æ¦‚çŽ‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®žéªŒéªŒè¯äº†EyeVLAçš„æœ‰æ•ˆæ€§ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒEyeVLAèƒ½å¤Ÿåœ¨çœŸå®žä¸–ç•ŒçŽ¯å¢ƒä¸­é«˜æ•ˆåœ°æ‰§è¡ŒæŒ‡ä»¤åœºæ™¯ï¼Œå¹¶é€šè¿‡æ—‹è½¬å’Œç¼©æ”¾çš„æŒ‡ä»¤é©±åŠ¨åŠ¨ä½œä¸»åŠ¨èŽ·å–æ›´å‡†ç¡®çš„è§†è§‰ä¿¡æ¯ï¼Œä»Žè€Œå®žçŽ°å¼ºå¤§çš„çŽ¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­æœªæ˜Žç¡®ç»™å‡ºï¼Œä½†æ‘˜è¦å¼ºè°ƒäº†å…¶åœ¨ä¸»åŠ¨èŽ·å–è§†è§‰ä¿¡æ¯æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

EyeVLAå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨æ™ºèƒ½å®‰é˜²é¢†åŸŸï¼Œå¯ä»¥ç”¨äºŽç›‘æŽ§å’Œè¯†åˆ«å¯ç–‘ç›®æ ‡ï¼›åœ¨å·¥ä¸šæ£€æµ‹é¢†åŸŸï¼Œå¯ä»¥ç”¨äºŽæ£€æµ‹äº§å“è¡¨é¢çš„ç¼ºé™·ï¼›åœ¨åŒ»ç–—è¯Šæ–­é¢†åŸŸï¼Œå¯ä»¥ç”¨äºŽè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œç—…ç¶çš„è§‚å¯Ÿå’Œè¯Šæ–­ã€‚è¯¥ç ”ç©¶çš„çªç ´å°†æŽ¨åŠ¨æœºå™¨äººè§†è§‰æŠ€æœ¯çš„å‘å±•ï¼Œå¹¶ä¸ºæœºå™¨äººåº”ç”¨äºŽæ›´å¹¿æ³›çš„é¢†åŸŸå¥ å®šåŸºç¡€ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In embodied AI perception systems, visual perception should be active: the goal is not to passively process static images, but to actively acquire more informative data within pixel and spatial budget constraints. Existing vision models and fixed RGB-D camera systems fundamentally fail to reconcile wide-area coverage with fine-grained detail acquisition, severely limiting their efficacy in open-world robotic applications. To address this issue, we propose EyeVLA, a robotic eyeball for active visual perception that can take proactive actions based on instructions, enabling clear observation of fine-grained target objects and detailed information across a wide spatial extent. EyeVLA discretizes action behaviors into action tokens and integrates them with vision-language models (VLMs) that possess strong open-world understanding capabilities, enabling joint modeling of vision, language, and actions within a single autoregressive sequence. By using the 2D bounding box coordinates to guide the reasoning chain and applying reinforcement learning to refine the viewpoint selection policy, we transfer the open-world scene understanding capability of the VLM to a vision language action (VLA) policy using only minimal real-world data. Experiments show that our system efficiently performs instructed scenes in real-world environments and actively acquires more accurate visual information through instruction-driven actions of rotation and zoom, thereby achieving strong environmental perception capabilities. EyeVLA introduces a novel robotic vision system that leverages detailed and spatially rich, large-scale embodied data, and actively acquires highly informative visual observations for downstream embodied tasks.

