---
layout: default
title: AssemMate: Graph-Based LLM for Robotic Assembly Assistance
---

# AssemMate: Graph-Based LLM for Robotic Assembly Assistance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.11617" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.11617v1</a>
  <a href="https://arxiv.org/pdf/2509.11617.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.11617v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.11617v1', 'AssemMate: Graph-Based LLM for Robotic Assembly Assistance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qi Zheng, Chaoran Zhang, Zijian Liang, EnTe Lin, Shubo Cui, Qinghongbing Xie, Zhaobo Xu, Long Zeng

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-15

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/cristina304/AssemMate.git)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAssemMateï¼Œåˆ©ç”¨å›¾ç»“æ„LLMè¾…åŠ©æœºå™¨äººè¿›è¡Œè£…é…ä»»åŠ¡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººè£…é…` `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†å›¾è°±` `å›¾å·ç§¯ç½‘ç»œ` `äººæœºäº¤äº’` `è§†è§‰æ„ŸçŸ¥` `è‡ªç›‘ç£å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºLLMçš„æœºå™¨äººè£…é…è¾…åŠ©æ–¹æ³•ä¾èµ–è‡ªç„¶è¯­è¨€æ–‡æœ¬è¡¨ç¤ºçŸ¥è¯†ï¼Œå­˜åœ¨ä¸Šä¸‹æ–‡è¿‡é•¿å’Œå†—ä½™çš„é—®é¢˜ï¼Œéš¾ä»¥æ»¡è¶³æœºå™¨äººå®æ—¶ç²¾ç¡®æ¨ç†çš„éœ€æ±‚ã€‚
2. AssemMateåˆ©ç”¨å›¾ç»“æ„ä½œä¸ºçŸ¥è¯†è¡¨ç¤ºï¼Œé€šè¿‡å›¾å·ç§¯ç½‘ç»œå°†çŸ¥è¯†å›¾è°±ä¿¡æ¯ç¼–ç å¹¶ä¸LLMå¯¹é½ï¼Œå®ç°é«˜æ•ˆçš„çŸ¥è¯†æ¨ç†å’Œäººæœºäº¤äº’ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒAssemMateåœ¨å‡†ç¡®ç‡ã€æ¨ç†é€Ÿåº¦å’Œä¸Šä¸‹æ–‡é•¿åº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­éªŒè¯äº†å…¶æœºå™¨äººæŠ“å–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœºå™¨äººè£…é…è¾…åŠ©å·²è·å¾—æ˜¾è‘—çš„ç ”ç©¶å…³æ³¨ã€‚å®ƒéœ€è¦æ³¨å…¥é¢†åŸŸç‰¹å®šçŸ¥è¯†ï¼Œé€šè¿‡ä¸äººç±»çš„è‡ªç„¶è¯­è¨€äº¤äº’æ¥æŒ‡å¯¼è£…é…è¿‡ç¨‹ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä»¥è‡ªç„¶è¯­è¨€æ–‡æœ¬å½¢å¼è¡¨ç¤ºçŸ¥è¯†ï¼Œç”±äºä¸Šä¸‹æ–‡è¿‡é•¿å’Œå†…å®¹å†—ä½™ï¼Œéš¾ä»¥æ»¡è¶³æœºå™¨äººå¯¹å®æ—¶å’Œç²¾ç¡®æ¨ç†çš„éœ€æ±‚ã€‚ä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†AssemMateï¼Œå®ƒåˆ©ç”¨å›¾â€”â€”ä¸€ç§ç®€æ´è€Œå‡†ç¡®çš„çŸ¥è¯†è¡¨ç¤ºå½¢å¼â€”â€”ä½œä¸ºè¾“å…¥ã€‚è¿™ç§åŸºäºå›¾çš„LLMæ”¯æŒçŸ¥è¯†å›¾è°±é—®ç­”ï¼ˆKGQAï¼‰ï¼Œä»è€Œæ”¯æŒäººæœºäº¤äº’å’Œç‰¹å®šäº§å“çš„è£…é…ä»»åŠ¡è§„åˆ’ã€‚é™¤äº†äº¤äº’å¼é—®ç­”ï¼ŒAssemMateè¿˜æ”¯æŒæ„ŸçŸ¥å †å åœºæ™¯å¹¶æ‰§è¡ŒæŠ“å–ä»¥è¾…åŠ©è£…é…ã€‚å…·ä½“æ¥è¯´ï¼Œä¸€ç§è‡ªç›‘ç£å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰å°†çŸ¥è¯†å›¾è°±å®ä½“å’Œå…³ç³»ç¼–ç åˆ°æ½œåœ¨ç©ºé—´ä¸­ï¼Œå¹¶å°†å…¶ä¸LLMçš„è¡¨ç¤ºå¯¹é½ï¼Œä½¿LLMèƒ½å¤Ÿç†è§£å›¾ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨äº†ä¸€ç§è§†è§‰å¢å¼ºç­–ç•¥æ¥è§£å†³æŠ“å–ä¸­çš„å †å åœºæ™¯ã€‚é€šè¿‡è®­ç»ƒå’Œè¯„ä¼°ï¼ŒAssemMateä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†6.4%çš„æ›´é«˜å‡†ç¡®ç‡ï¼Œ3å€çš„æ›´å¿«æ¨ç†é€Ÿåº¦å’Œ28å€çš„æ›´çŸ­ä¸Šä¸‹æ–‡é•¿åº¦ï¼ŒåŒæ—¶åœ¨éšæœºå›¾ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¿˜é€šè¿‡æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­çš„æœºå™¨äººæŠ“å–å®éªŒè¿›ä¸€æ­¥è¯æ˜äº†ä¼˜è¶Šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºLLMçš„æœºå™¨äººè£…é…è¾…åŠ©ç³»ç»Ÿï¼Œä¸»è¦ä¾èµ–äºè‡ªç„¶è¯­è¨€æ–‡æœ¬æ¥è¡¨ç¤ºè£…é…çŸ¥è¯†ã€‚è¿™ç§æ–¹å¼å­˜åœ¨ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯è‡ªç„¶è¯­è¨€æ–‡æœ¬å†—é•¿ï¼Œå¯¼è‡´LLMæ¨ç†æ•ˆç‡ä½ä¸‹ï¼›äºŒæ˜¯è‡ªç„¶è¯­è¨€æ–‡æœ¬çš„æ¨¡ç³Šæ€§å¯èƒ½å¯¼è‡´æœºå™¨äººæ‰§è¡Œé”™è¯¯çš„æ“ä½œã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ›´ç®€æ´ã€æ›´ç²¾ç¡®çš„çŸ¥è¯†è¡¨ç¤ºæ–¹æ³•ï¼Œä»¥æé«˜LLMçš„æ¨ç†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAssemMateçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è£…é…çŸ¥è¯†è¡¨ç¤ºä¸ºçŸ¥è¯†å›¾è°±ï¼Œåˆ©ç”¨å›¾ç»“æ„æ¥è¡¨è¾¾é›¶ä»¶ä¹‹é—´çš„å…³ç³»å’Œè£…é…æ­¥éª¤ã€‚é€šè¿‡å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰å°†çŸ¥è¯†å›¾è°±çš„å®ä½“å’Œå…³ç³»ç¼–ç æˆå‘é‡è¡¨ç¤ºï¼Œå¹¶ä¸LLMçš„åµŒå…¥ç©ºé—´å¯¹é½ï¼Œä½¿LLMèƒ½å¤Ÿç†è§£å’Œåˆ©ç”¨å›¾ç»“æ„ä¿¡æ¯è¿›è¡Œæ¨ç†å’Œè§„åˆ’ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆå‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæé«˜æ¨ç†é€Ÿåº¦ï¼Œå¹¶æé«˜è£…é…ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAssemMateçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) çŸ¥è¯†å›¾è°±æ„å»ºæ¨¡å—ï¼šå°†è£…é…çŸ¥è¯†è¡¨ç¤ºä¸ºçŸ¥è¯†å›¾è°±ï¼ŒåŒ…æ‹¬é›¶ä»¶ã€è£…é…æ­¥éª¤å’Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚2) å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰ç¼–ç æ¨¡å—ï¼šä½¿ç”¨è‡ªç›‘ç£GCNå°†çŸ¥è¯†å›¾è°±çš„å®ä½“å’Œå…³ç³»ç¼–ç æˆå‘é‡è¡¨ç¤ºã€‚3) LLMå¯¹é½æ¨¡å—ï¼šå°†GCNç¼–ç çš„å‘é‡è¡¨ç¤ºä¸LLMçš„åµŒå…¥ç©ºé—´å¯¹é½ï¼Œä½¿LLMèƒ½å¤Ÿç†è§£å›¾ç»“æ„ä¿¡æ¯ã€‚4) äººæœºäº¤äº’æ¨¡å—ï¼šé€šè¿‡è‡ªç„¶è¯­è¨€ä¸äººç±»äº¤äº’ï¼Œæ¥æ”¶æŒ‡ä»¤å¹¶è¿›è¡Œè£…é…ä»»åŠ¡è§„åˆ’ã€‚5) è§†è§‰æ„ŸçŸ¥æ¨¡å—ï¼šåˆ©ç”¨è§†è§‰ä¿¡æ¯æ„ŸçŸ¥å †å åœºæ™¯ï¼Œè¾…åŠ©æœºå™¨äººè¿›è¡ŒæŠ“å–ã€‚6) æœºå™¨äººæ§åˆ¶æ¨¡å—ï¼šæ§åˆ¶æœºå™¨äººæ‰§è¡Œè£…é…ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šAssemMateçš„å…³é”®åˆ›æ–°åœ¨äºä½¿ç”¨å›¾ç»“æ„ä½œä¸ºLLMçš„è¾“å…¥ï¼Œå°†çŸ¥è¯†å›¾è°±ä¸LLMç›¸ç»“åˆï¼Œä»è€Œå®ç°é«˜æ•ˆçš„çŸ¥è¯†æ¨ç†å’Œè£…é…ä»»åŠ¡è§„åˆ’ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒAssemMateèƒ½å¤Ÿæ˜¾è‘—å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæé«˜æ¨ç†é€Ÿåº¦ï¼Œå¹¶æé«˜è£…é…ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒAssemMateè¿˜é‡‡ç”¨äº†è§†è§‰å¢å¼ºç­–ç•¥æ¥è§£å†³å †å åœºæ™¯ä¸­çš„æŠ“å–é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šGCNé‡‡ç”¨è‡ªç›‘ç£å­¦ä¹ çš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼ŒæŸå¤±å‡½æ•°åŒ…æ‹¬èŠ‚ç‚¹åˆ†ç±»æŸå¤±å’Œé“¾æ¥é¢„æµ‹æŸå¤±ï¼Œä»¥æé«˜GCNçš„ç¼–ç èƒ½åŠ›ã€‚LLMå¯¹é½æ¨¡å—ä½¿ç”¨å¯¹æ¯”å­¦ä¹ çš„æ–¹å¼ï¼Œå°†GCNç¼–ç çš„å‘é‡è¡¨ç¤ºä¸LLMçš„åµŒå…¥ç©ºé—´å¯¹é½ã€‚è§†è§‰å¢å¼ºç­–ç•¥ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹æ¥åˆ†å‰²å’Œè¯†åˆ«å †å çš„é›¶ä»¶ï¼Œå¹¶ä¼°è®¡å…¶ä½å§¿ï¼Œä»è€Œè¾…åŠ©æœºå™¨äººè¿›è¡ŒæŠ“å–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

AssemMateåœ¨å®éªŒä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„ä¼˜åŠ¿ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒAssemMateåœ¨è£…é…ä»»åŠ¡ä¸­å®ç°äº†6.4%çš„æ›´é«˜å‡†ç¡®ç‡ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº†3å€ï¼Œä¸Šä¸‹æ–‡é•¿åº¦ç¼©çŸ­äº†28å€ã€‚æ­¤å¤–ï¼ŒAssemMateåœ¨éšæœºå›¾ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­çš„æœºå™¨äººæŠ“å–å®éªŒä¸­éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AssemMateå¯åº”ç”¨äºå„ç§éœ€è¦äººæœºåä½œçš„è£…é…åœºæ™¯ï¼Œä¾‹å¦‚ç”µå­äº§å“ç»„è£…ã€æ±½è½¦é›¶éƒ¨ä»¶è£…é…ã€èˆªç©ºèˆªå¤©è®¾å¤‡è£…é…ç­‰ã€‚è¯¥ç ”ç©¶èƒ½å¤Ÿæé«˜è£…é…æ•ˆç‡ã€é™ä½é”™è¯¯ç‡ï¼Œå¹¶é™ä½å¯¹äººå·¥æ“ä½œå‘˜çš„æŠ€èƒ½è¦æ±‚ã€‚æœªæ¥ï¼ŒAssemMateæœ‰æœ›æ‰©å±•åˆ°æ›´å¤æ‚çš„è£…é…ä»»åŠ¡ï¼Œå¹¶ä¸å…¶ä»–æœºå™¨äººæŠ€æœ¯ç›¸ç»“åˆï¼Œå®ç°æ›´æ™ºèƒ½åŒ–çš„è‡ªåŠ¨åŒ–è£…é…ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Model (LLM)-based robotic assembly assistance has gained significant research attention. It requires the injection of domain-specific knowledge to guide the assembly process through natural language interaction with humans. Despite some progress, existing methods represent knowledge in the form of natural language text. Due to the long context and redundant content, they struggle to meet the robots' requirements for real-time and precise reasoning. In order to bridge this gap, we present AssemMate, which utilizes the graph\textemdash a concise and accurate form of knowledge representation\textemdash as input. This graph-based LLM enables knowledge graph question answering (KGQA), supporting human-robot interaction and assembly task planning for specific products. Beyond interactive QA, AssemMate also supports sensing stacked scenes and executing grasping to assist with assembly. Specifically, a self-supervised Graph Convolutional Network (GCN) encodes knowledge graph entities and relations into a latent space and aligns them with LLM's representation, enabling the LLM to understand graph information. In addition, a vision-enhanced strategy is employed to address stacked scenes in grasping. Through training and evaluation, AssemMate outperforms existing methods, achieving 6.4\% higher accuracy, 3 times faster inference, and 28 times shorter context length, while demonstrating strong generalization ability on random graphs. And our approach further demonstrates superiority through robotic grasping experiments in both simulated and real-world settings. More details can be found on the project page: https://github.com/cristina304/AssemMate.git

