---
layout: default
title: Igniting VLMs toward the Embodied Space
---

# Igniting VLMs toward the Embodied Space

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.11766" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.11766v1</a>
  <a href="https://arxiv.org/pdf/2509.11766.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.11766v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.11766v1', 'Igniting VLMs toward the Embodied Space')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Andy Zhai, Brae Liu, Bruno Fang, Chalse Cai, Ellie Ma, Ethan Yin, Hao Wang, Hugo Zhou, James Wang, Lights Shi, Lucy Liang, Make Wang, Qian Wang, Roy Gan, Ryan Yu, Shalfun Li, Starrick Liu, Sylas Chen, Vincent Chen, Zach Xu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-15

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWALL-OSSï¼Œå¢å¼ºVLMsåœ¨å…·èº«ç¯å¢ƒä¸­çš„ç©ºé—´ç†è§£ä¸æ“ä½œèƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å…·èº«æ™ºèƒ½` `è§†è§‰è¯­è¨€æ¨¡å‹` `æœºå™¨äººæ“ä½œ` `å¤šæ¨¡æ€å­¦ä¹ ` `æŒ‡ä»¤éµå¾ª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLMsåœ¨å…·èº«ç¯å¢ƒä¸‹çš„ç©ºé—´ç†è§£å’ŒåŠ¨ä½œç”Ÿæˆèƒ½åŠ›ä¸è¶³ï¼Œé˜»ç¢äº†å…¶åœ¨æœºå™¨äººç­‰é¢†åŸŸçš„åº”ç”¨ã€‚
2. WALL-OSSé€šè¿‡ç´§è€¦åˆæ¶æ„å’Œå¤šç­–ç•¥è®­ç»ƒï¼Œç»Ÿä¸€æŒ‡ä»¤æ¨ç†ã€å­ç›®æ ‡åˆ†è§£å’ŒåŠ¨ä½œåˆæˆï¼Œæå‡äº†å…·èº«æ„ŸçŸ¥èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒWALL-OSSåœ¨å¤æ‚æ“ä½œä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†ç°æœ‰åŸºçº¿ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨ç©ºé—´å’Œå…·èº«ç†è§£æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚å°†VLMsè¿ç§»åˆ°å…·èº«é¢†åŸŸæ­ç¤ºäº†æ¨¡æ€ã€é¢„è®­ç»ƒåˆ†å¸ƒå’Œè®­ç»ƒç›®æ ‡ä¹‹é—´çš„æ ¹æœ¬ä¸åŒ¹é…ï¼Œä½¿å¾—åŠ¨ä½œç†è§£å’Œç”Ÿæˆæˆä¸ºé€šå‘é€šç”¨äººå·¥æ™ºèƒ½çš„å…³é”®ç“¶é¢ˆã€‚æœ¬æ–‡æå‡ºäº†WALL-OSSï¼Œä¸€ä¸ªç«¯åˆ°ç«¯çš„å…·èº«åŸºç¡€æ¨¡å‹ï¼Œå®ƒåˆ©ç”¨å¤§è§„æ¨¡å¤šæ¨¡æ€é¢„è®­ç»ƒæ¥å®ç°ï¼šï¼ˆ1ï¼‰å…·èº«æ„ŸçŸ¥çš„è§†è§‰è¯­è¨€ç†è§£ï¼Œï¼ˆ2ï¼‰å¼ºå¤§çš„è¯­è¨€-åŠ¨ä½œå…³è”ï¼Œä»¥åŠï¼ˆ3ï¼‰é²æ£’çš„æ“ä½œèƒ½åŠ›ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ç´§è€¦åˆæ¶æ„å’Œå¤šç­–ç•¥è®­ç»ƒè¯¾ç¨‹ï¼Œå®ç°äº†ç»Ÿä¸€çš„è·¨å±‚CoTï¼Œä»è€Œåœ¨ä¸€ä¸ªå¯å¾®æ¡†æ¶å†…æ— ç¼åœ°ç»Ÿä¸€äº†æŒ‡ä»¤æ¨ç†ã€å­ç›®æ ‡åˆ†è§£å’Œç»†ç²’åº¦çš„åŠ¨ä½œåˆæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWALL-OSSåœ¨å¤æ‚çš„é•¿æ—¶ç¨‹æ“ä½œä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆé«˜çš„æˆåŠŸç‡ï¼Œå±•ç¤ºäº†å¼ºå¤§çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€å¤æ‚çš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œå¹¶ä¼˜äºå¼ºå¤§çš„åŸºçº¿æ¨¡å‹ï¼Œä»è€Œä¸ºä»VLMsåˆ°å…·èº«åŸºç¡€æ¨¡å‹æä¾›äº†ä¸€æ¡å¯é ä¸”å¯æ‰©å±•çš„è·¯å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å…·èº«ç¯å¢ƒä¸‹çš„åº”ç”¨é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦ä½“ç°åœ¨å¯¹ç©ºé—´å…³ç³»çš„ç†è§£ä¸è¶³ã€è¯­è¨€ä¸åŠ¨ä½œçš„å…³è”æ€§è¾ƒå¼±ï¼Œä»¥åŠæ“ä½œèƒ½åŠ›æœ‰é™ã€‚è¿™äº›é—®é¢˜å¯¼è‡´VLMséš¾ä»¥èƒœä»»å¤æ‚çš„é•¿æ—¶ç¨‹æ“ä½œä»»åŠ¡ï¼Œé˜»ç¢äº†å…¶åœ¨æœºå™¨äººç­‰é¢†åŸŸçš„å®é™…åº”ç”¨ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥æœ‰æ•ˆæ•´åˆæŒ‡ä»¤æ¨ç†ã€å­ç›®æ ‡åˆ†è§£å’Œç»†ç²’åº¦åŠ¨ä½œåˆæˆï¼Œå¯¼è‡´æ€§èƒ½ç“¶é¢ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šWALL-OSSçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªç«¯åˆ°ç«¯çš„å…·èº«åŸºç¡€æ¨¡å‹ï¼Œé€šè¿‡å¤§è§„æ¨¡å¤šæ¨¡æ€é¢„è®­ç»ƒæ¥å¢å¼ºæ¨¡å‹å¯¹å…·èº«ç¯å¢ƒçš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¹¶å»ºç«‹å¼ºå¤§çš„è¯­è¨€-åŠ¨ä½œå…³è”ã€‚è¯¥æ¨¡å‹é‡‡ç”¨ç´§è€¦åˆæ¶æ„ï¼Œæ—¨åœ¨å®ç°æŒ‡ä»¤æ¨ç†ã€å­ç›®æ ‡åˆ†è§£å’ŒåŠ¨ä½œåˆæˆçš„æ— ç¼è¡”æ¥ï¼Œä»è€Œæå‡æ¨¡å‹åœ¨å¤æ‚æ“ä½œä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šWALL-OSSé‡‡ç”¨ç«¯åˆ°ç«¯çš„æ¶æ„ï¼ŒåŒ…å«è§†è§‰ç¼–ç å™¨ã€è¯­è¨€ç¼–ç å™¨ã€åŠ¨ä½œè§£ç å™¨ç­‰æ¨¡å—ã€‚è§†è§‰ç¼–ç å™¨è´Ÿè´£æå–ç¯å¢ƒå›¾åƒçš„ç‰¹å¾ï¼Œè¯­è¨€ç¼–ç å™¨è´Ÿè´£ç†è§£ç”¨æˆ·æŒ‡ä»¤ï¼ŒåŠ¨ä½œè§£ç å™¨åˆ™æ ¹æ®è§†è§‰å’Œè¯­è¨€ä¿¡æ¯ç”Ÿæˆç›¸åº”çš„åŠ¨ä½œåºåˆ—ã€‚æ•´ä¸ªæ¡†æ¶é‡‡ç”¨å¯å¾®è®¾è®¡ï¼Œä»¥ä¾¿è¿›è¡Œç«¯åˆ°ç«¯çš„è®­ç»ƒå’Œä¼˜åŒ–ã€‚æ¨¡å‹é€šè¿‡å¤šç­–ç•¥è®­ç»ƒè¯¾ç¨‹è¿›è¡Œè®­ç»ƒï¼ŒåŒ…æ‹¬æ¨¡ä»¿å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ç­‰ï¼Œä»¥æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šWALL-OSSçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»Ÿä¸€çš„è·¨å±‚CoTï¼ˆChain-of-Thoughtï¼‰æœºåˆ¶ï¼Œè¯¥æœºåˆ¶èƒ½å¤Ÿåœ¨ä¸€ä¸ªå¯å¾®æ¡†æ¶å†…æ— ç¼åœ°æ•´åˆæŒ‡ä»¤æ¨ç†ã€å­ç›®æ ‡åˆ†è§£å’Œç»†ç²’åº¦çš„åŠ¨ä½œåˆæˆã€‚è¿™ç§ç»Ÿä¸€çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç”¨æˆ·æŒ‡ä»¤ï¼Œå¹¶å°†å…¶åˆ†è§£ä¸ºä¸€ç³»åˆ—å¯æ‰§è¡Œçš„å­ç›®æ ‡ï¼Œæœ€ç»ˆç”Ÿæˆç²¾ç¡®çš„åŠ¨ä½œåºåˆ—ã€‚æ­¤å¤–ï¼ŒWALL-OSSè¿˜é‡‡ç”¨äº†ç´§è€¦åˆæ¶æ„ï¼Œä½¿å¾—è§†è§‰å’Œè¯­è¨€ä¿¡æ¯èƒ½å¤Ÿæ›´å¥½åœ°èåˆï¼Œä»è€Œæå‡æ¨¡å‹çš„å…·èº«æ„ŸçŸ¥èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šWALL-OSSçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) ç´§è€¦åˆçš„è§†è§‰-è¯­è¨€ç¼–ç å™¨ï¼Œç”¨äºæå–å¤šæ¨¡æ€ç‰¹å¾ï¼›(2) ç»Ÿä¸€çš„è·¨å±‚CoTæœºåˆ¶ï¼Œç”¨äºæŒ‡ä»¤æ¨ç†ã€å­ç›®æ ‡åˆ†è§£å’ŒåŠ¨ä½œåˆæˆï¼›(3) å¤šç­–ç•¥è®­ç»ƒè¯¾ç¨‹ï¼ŒåŒ…æ‹¬æ¨¡ä»¿å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ï¼Œä»¥æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ï¼›(4) æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼Œæ—¨åœ¨å¹³è¡¡æŒ‡ä»¤éµå¾ªã€åŠ¨ä½œç²¾åº¦å’Œç¯å¢ƒäº¤äº’ç­‰å¤šä¸ªç›®æ ‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

WALL-OSSåœ¨å¤æ‚é•¿æ—¶ç¨‹æ“ä½œä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æˆæœï¼ŒæˆåŠŸç‡è¿œè¶…ç°æœ‰åŸºçº¿æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWALL-OSSä¸ä»…èƒ½å¤Ÿå‡†ç¡®ç†è§£ç”¨æˆ·æŒ‡ä»¤ï¼Œè¿˜èƒ½å°†å…¶åˆ†è§£ä¸ºä¸€ç³»åˆ—å¯æ‰§è¡Œçš„å­ç›®æ ‡ï¼Œå¹¶ç”Ÿæˆç²¾ç¡®çš„åŠ¨ä½œåºåˆ—ã€‚æ­¤å¤–ï¼ŒWALL-OSSè¿˜å±•ç¤ºäº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒçš„ç¯å¢ƒå’Œä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

WALL-OSSå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬æœºå™¨äººæ“ä½œã€è‡ªåŠ¨åŒ–è£…é…ã€æ™ºèƒ½å®¶å±…ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºå¼€å‘èƒ½å¤Ÿç†è§£äººç±»æŒ‡ä»¤å¹¶æ‰§è¡Œå¤æ‚ä»»åŠ¡çš„æ™ºèƒ½æœºå™¨äººï¼Œä¾‹å¦‚åœ¨å®¶åº­ç¯å¢ƒä¸­è¿›è¡Œæ¸…æ´ã€çƒ¹é¥ªç­‰æ“ä½œï¼Œæˆ–åœ¨å·¥ä¸šç¯å¢ƒä¸­è¿›è¡Œè‡ªåŠ¨åŒ–è£…é…å’Œç»´æŠ¤ã€‚è¯¥ç ”ç©¶çš„æˆæœæœ‰æœ›æ¨åŠ¨å…·èº«æ™ºèƒ½çš„å‘å±•ï¼Œå¹¶ä¸ºäººç±»åˆ›é€ æ›´åŠ ä¾¿æ·å’Œæ™ºèƒ½çš„ç”Ÿæ´»ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While foundation models show remarkable progress in language and vision, existing vision-language models (VLMs) still have limited spatial and embodiment understanding. Transferring VLMs to embodied domains reveals fundamental mismatches between modalities, pretraining distributions, and training objectives, leaving action comprehension and generation as a central bottleneck on the path to AGI.
>   We introduce WALL-OSS, an end-to-end embodied foundation model that leverages large-scale multimodal pretraining to achieve (1) embodiment-aware vision-language understanding, (2) strong language-action association, and (3) robust manipulation capability.
>   Our approach employs a tightly coupled architecture and multi-strategies training curriculum that enables Unified Cross-Level CoT-seamlessly unifying instruction reasoning, subgoal decomposition, and fine-grained action synthesis within a single differentiable framework.
>   Our results show that WALL-OSS attains high success on complex long-horizon manipulations, demonstrates strong instruction-following capabilities, complex understanding and reasoning, and outperforms strong baselines, thereby providing a reliable and scalable path from VLMs to embodied foundation models.

