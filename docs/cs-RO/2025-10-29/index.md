---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-10-29
---

# cs.ROï¼ˆ2025-10-29ï¼‰

ğŸ“Š å…± **13** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (11)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (11 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251025754v1-get-use-learning-generalized-tool-usage-for-bimanual-mobile-manipula.html">GET-USE: Learning Generalized Tool Usage for Bimanual Mobile Manipulation via Simulated Embodiment Extensions</a></td>
  <td>GeT-USEï¼šé€šè¿‡æ¨¡æ‹Ÿå…·èº«æ‰©å±•å­¦ä¹ é€šç”¨åŒè‡‚ç§»åŠ¨æ“ä½œå·¥å…·ä½¿ç”¨</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25754v1" onclick="toggleFavorite(this, '2510.25754v1', 'GET-USE: Learning Generalized Tool Usage for Bimanual Mobile Manipulation via Simulated Embodiment Extensions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251025548v1-using-vlm-reasoning-to-constrain-task-and-motion-planning.html">Using VLM Reasoning to Constrain Task and Motion Planning</a></td>
  <td>VIZ-COASTï¼šåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹æ¨ç†çº¦æŸä»»åŠ¡ä¸è¿åŠ¨è§„åˆ’ï¼Œæå‡è§„åˆ’æ•ˆç‡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25548v1" onclick="toggleFavorite(this, '2510.25548v1', 'Using VLM Reasoning to Constrain Task and Motion Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251025268v1-synhlmasynthesizing-hand-language-manipulation-for-articulated-objec.html">SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation</a></td>
  <td>SynHLMAï¼šåˆæˆç”¨äºæ“ä½œé“°æ¥ç‰©ä½“çš„å¸¦ç¦»æ•£äºº-ç‰©äº¤äº’è¡¨ç¤ºçš„æ‰‹è¯­</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25268v1" onclick="toggleFavorite(this, '2510.25268v1', 'SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251025405v1-sim-to-real-gentle-manipulation-of-deformable-and-fragile-objects-wi.html">Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning</a></td>
  <td>æå‡ºåŸºäºåº”åŠ›å¼•å¯¼å¼ºåŒ–å­¦ä¹ çš„æŸ”æ€§ç‰©ä½“è½»æŸ”æ“ä½œæ–¹æ³•ï¼Œå®ç°Sim-to-Realè¿ç§»</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25405v1" onclick="toggleFavorite(this, '2510.25405v1', 'Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251025850v1-debate2create-robot-co-design-via-large-language-model-debates.html">Debate2Create: Robot Co-design via Large Language Model Debates</a></td>
  <td>Debate2Createï¼šé€šè¿‡å¤§è¯­è¨€æ¨¡å‹è¾©è®ºå®ç°æœºå™¨äººååŒè®¾è®¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25850v1" onclick="toggleFavorite(this, '2510.25850v1', 'Debate2Create: Robot Co-design via Large Language Model Debates')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251025634v1-learning-to-plan-schedule-with-reinforcement-learned-bimanual-robot-.html">Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills</a></td>
  <td>æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ åŒè‡‚æœºå™¨äººæŠ€èƒ½åº“çš„è§„åˆ’ä¸è°ƒåº¦æ¡†æ¶ï¼Œè§£å†³å¤æ‚æ“ä½œä»»åŠ¡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25634v1" onclick="toggleFavorite(this, '2510.25634v1', 'Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251025241v1-one-shot-humanoid-whole-body-motion-learning.html">One-shot Humanoid Whole-body Motion Learning</a></td>
  <td>æå‡ºåŸºäºå•æ ·æœ¬å­¦ä¹ çš„äººå½¢æœºå™¨äººå…¨èº«è¿åŠ¨ç­–ç•¥è®­ç»ƒæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25241v1" onclick="toggleFavorite(this, '2510.25241v1', 'One-shot Humanoid Whole-body Motion Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251026837v1-force-characterization-of-insect-scale-aquatic-propulsion-based-on-f.html">Force Characterization of Insect-Scale Aquatic Propulsion Based on Fluid-Structure Interaction</a></td>
  <td>åŸºäºæµå›ºè€¦åˆï¼Œç ”ç©¶äººå‘˜å¯¹æ˜†è™«å°ºåº¦æ°´ä¸‹æ¨è¿›å™¨çš„æ¨åŠ›ç‰¹æ€§è¿›è¡Œäº†è¡¨å¾</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.26837v1" onclick="toggleFavorite(this, '2510.26837v1', 'Force Characterization of Insect-Scale Aquatic Propulsion Based on Fluid-Structure Interaction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251025335v1-an-approach-for-combining-transparency-and-motion-assistance-of-a-lo.html">An approach for combining transparency and motion assistance of a lower body exoskeleton</a></td>
  <td>æå‡ºä¸€ç§ç»“åˆé€æ˜æ¨¡å¼ä¸è¿åŠ¨è¾…åŠ©çš„ä¸‹è‚¢å¤–éª¨éª¼æ§åˆ¶æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25335v1" onclick="toggleFavorite(this, '2510.25335v1', 'An approach for combining transparency and motion assistance of a lower body exoskeleton')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251025280v1-development-of-implicit-explicit-control-based-amphibious-centipede-.html">Development of Implicit-Explicit Control Based Amphibious Centipede-Type Robot and Evaluation of its Mobile Performance</a></td>
  <td>æå‡ºåŸºäºéšå¼-æ˜¾å¼æ§åˆ¶çš„èœˆèš£å‹ä¸¤æ –æœºå™¨äººï¼Œå¹¶è¯„ä¼°å…¶ç§»åŠ¨æ€§èƒ½</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25280v1" onclick="toggleFavorite(this, '2510.25280v1', 'Development of Implicit-Explicit Control Based Amphibious Centipede-Type Robot and Evaluation of its Mobile Performance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251025233v1-hybrid-vision-servoing-with-depp-alignment-and-gru-based-occlusion-r.html">Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery</a></td>
  <td>æå‡ºä¸€ç§æ··åˆè§†è§‰ä¼ºæœæ–¹æ³•ï¼Œç»“åˆæ·±åº¦å¯¹é½å’ŒGRUçš„é®æŒ¡æ¢å¤ï¼Œæå‡æœºå™¨äººæ“ä½œçš„é²æ£’æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25233v1" onclick="toggleFavorite(this, '2510.25233v1', 'Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>12</td>
  <td><a href="./papers/251025713v1-robotic-assistant-completing-collaborative-tasks-with-dexterous-visi.html">Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models</a></td>
  <td>æå‡ºåŸºäºè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„æœºå™¨äººåŠ©æ‰‹ï¼Œç”¨äºçµå·§çš„äººæœºåä½œä»»åŠ¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25713v1" onclick="toggleFavorite(this, '2510.25713v1', 'Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251025211v1-roadsens-4m-a-multimodal-smartphone-camera-dataset-for-holistic-road.html">RoadSens-4M: A Multimodal Smartphone & Camera Dataset for Holistic Road-way Analysis</a></td>
  <td>RoadSens-4Mï¼šæå‡ºä¸€ä¸ªå¤šæ¨¡æ€æ™ºèƒ½æ‰‹æœºä¸ç›¸æœºæ•°æ®é›†ï¼Œç”¨äºæ•´ä½“é“è·¯åˆ†æã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.25211v1" onclick="toggleFavorite(this, '2510.25211v1', 'RoadSens-4M: A Multimodal Smartphone & Camera Dataset for Holistic Road-way Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)