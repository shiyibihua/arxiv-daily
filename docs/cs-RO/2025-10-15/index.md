---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-10-15
---

# cs.ROï¼ˆ2025-10-15ï¼‰

ğŸ“Š å…± **14** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (12 ğŸ”—2)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (12 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251014065v1-optimistic-reinforcement-learning-based-skill-insertions-for-task-an.html">Optimistic Reinforcement Learning-Based Skill Insertions for Task and Motion Planning</a></td>
  <td>æå‡ºåŸºäºä¹è§‚å¼ºåŒ–å­¦ä¹ çš„æŠ€èƒ½æ’å…¥æ–¹æ³•ï¼Œè§£å†³ä»»åŠ¡å’Œè¿åŠ¨è§„åˆ’ä¸­æ¦‚ç‡åŠ¨ä½œçš„æŒ‘æˆ˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.14065v1" onclick="toggleFavorite(this, '2510.14065v1', 'Optimistic Reinforcement Learning-Based Skill Insertions for Task and Motion Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251013488v1-bridge-the-gap-enhancing-quadruped-locomotion-with-vertical-ground-p.html">Bridge the Gap: Enhancing Quadruped Locomotion with Vertical Ground Perturbations</a></td>
  <td>æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„å››è¶³æœºå™¨äººæ§åˆ¶æ–¹æ³•ï¼Œæå‡å…¶åœ¨å‚ç›´åœ°é¢æ‰°åŠ¨ä¸‹çš„è¿åŠ¨èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.13488v1" onclick="toggleFavorite(this, '2510.13488v1', 'Bridge the Gap: Enhancing Quadruped Locomotion with Vertical Ground Perturbations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251013594v1-development-of-an-intuitive-gui-for-non-expert-teleoperation-of-huma.html">Development of an Intuitive GUI for Non-Expert Teleoperation of Humanoid Robots</a></td>
  <td>ä¸ºäººå½¢æœºå™¨äººéä¸“å®¶é¥æ“ä½œè®¾è®¡ç›´è§‚å›¾å½¢ç”¨æˆ·ç•Œé¢</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.13594v1" onclick="toggleFavorite(this, '2510.13594v1', 'Development of an Intuitive GUI for Non-Expert Teleoperation of Humanoid Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251013626v2-libero-plus-in-depth-robustness-analysis-of-vision-language-action-m.html">LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models</a></td>
  <td>LIBERO-Plusï¼šå¯¹è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹è¿›è¡Œæ·±åº¦é²æ£’æ€§åˆ†æ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.13626v2" onclick="toggleFavorite(this, '2510.13626v2', 'LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251013284v1-aloha2-robot-kitchen-application-scenario-reproduction-report.html">ALOHA2 Robot Kitchen Application Scenario Reproduction Report</a></td>
  <td>ALOHA2ï¼šä¸€ç§é«˜æ€§èƒ½ã€é«˜é²æ£’æ€§ä¸”æ›´ç¬¦åˆäººä½“å·¥ç¨‹å­¦çš„åŒè‡‚é¥æ“ä½œæœºå™¨äºº</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.13284v1" onclick="toggleFavorite(this, '2510.13284v1', 'ALOHA2 Robot Kitchen Application Scenario Reproduction Report')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251013625v1-a-modular-object-detection-system-for-humanoid-robots-using-yolo.html">A Modular Object Detection System for Humanoid Robots Using YOLO</a></td>
  <td>é’ˆå¯¹äººå‹æœºå™¨äººï¼Œæå‡ºåŸºäºYOLOv9çš„æ¨¡å—åŒ–ç›®æ ‡æ£€æµ‹ç³»ç»Ÿï¼Œæå‡è®¡ç®—æ•ˆç‡å’Œé²æ£’æ€§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.13625v1" onclick="toggleFavorite(this, '2510.13625v1', 'A Modular Object Detection System for Humanoid Robots Using YOLO')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251013324v1-tactile-conditioned-diffusion-policy-for-force-aware-robotic-manipul.html">Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation</a></td>
  <td>æå‡ºFARMæ¡†æ¶ï¼Œåˆ©ç”¨è§¦è§‰ä¿¡æ¯å’ŒåŠ›æ§åˆ¶å®ç°åŠ›æ„ŸçŸ¥çš„æœºå™¨äººæ“ä½œ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.13324v1" onclick="toggleFavorite(this, '2510.13324v1', 'Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251013149v1-robohiman-a-hierarchical-evaluation-paradigm-for-compositional-gener.html">RoboHiMan: A Hierarchical Evaluation Paradigm for Compositional Generalization in Long-Horizon Manipulation</a></td>
  <td>æå‡ºRoboHiManï¼Œç”¨äºè¯„ä¼°é•¿æ—¶ç¨‹æ“ä½œä¸­ç»„åˆæ³›åŒ–çš„åˆ†å±‚è¯„ä¼°èŒƒå¼ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.13149v1" onclick="toggleFavorite(this, '2510.13149v1', 'RoboHiMan: A Hierarchical Evaluation Paradigm for Compositional Generalization in Long-Horizon Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251013358v1-adversarial-fine-tuning-in-offline-to-online-reinforcement-learning-.html">Adversarial Fine-tuning in Offline-to-Online Reinforcement Learning for Robust Robot Control</a></td>
  <td>æå‡ºç¦»çº¿åˆ°åœ¨çº¿çš„å¯¹æŠ—å¾®è°ƒæ–¹æ³•ï¼Œæå‡æœºå™¨äººæ§åˆ¶å¯¹æ‰°åŠ¨çš„é²æ£’æ€§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.13358v1" onclick="toggleFavorite(this, '2510.13358v1', 'Adversarial Fine-tuning in Offline-to-Online Reinforcement Learning for Robust Robot Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251014117v2-vitacgen-robotic-pushing-with-vision-to-touch-generation.html">ViTacGen: Robotic Pushing with Vision-to-Touch Generation</a></td>
  <td>ViTacGenï¼šåŸºäºè§†è§‰åˆ°è§¦è§‰ç”Ÿæˆçš„æœºå™¨äººæ¨ç‰©æ“ä½œæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.14117v2" onclick="toggleFavorite(this, '2510.14117v2', 'ViTacGen: Robotic Pushing with Vision-to-Touch Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251013595v1-active-tactile-exploration-for-rigid-body-pose-and-shape-estimation.html">Active Tactile Exploration for Rigid Body Pose and Shape Estimation</a></td>
  <td>æå‡ºåŸºäºä¸»åŠ¨è§¦è§‰æ¢ç´¢çš„åˆšä½“ä½å§¿ä¸å½¢çŠ¶ä¼°è®¡æ–¹æ³•</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.13595v1" onclick="toggleFavorite(this, '2510.13595v1', 'Active Tactile Exploration for Rigid Body Pose and Shape Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251013553v2-hoecken-d-hand-a-novel-robotic-hand-for-linear-parallel-pinching-and.html">Hoecken-D Hand: A Novel Robotic Hand for Linear Parallel Pinching and Self-Adaptive Grasping</a></td>
  <td>æå‡ºHoecken-Dæ‰‹çˆªï¼Œå®ç°çº¿æ€§å¹³è¡Œå¤¹æŒå’Œè‡ªé€‚åº”æŠ“å–çš„æœºå™¨äººæ‰‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.13553v2" onclick="toggleFavorite(this, '2510.13553v2', 'Hoecken-D Hand: A Novel Robotic Hand for Linear Parallel Pinching and Self-Adaptive Grasping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/251013778v1-internvla-m1-a-spatially-guided-vision-language-action-framework-for.html">InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy</a></td>
  <td>InternVLA-M1ï¼šé¢å‘é€šç”¨æœºå™¨äººç­–ç•¥çš„ç©ºé—´å¼•å¯¼è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¡†æ¶</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.13778v1" onclick="toggleFavorite(this, '2510.13778v1', 'InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>14</td>
  <td><a href="./papers/251014000v1-a-diffusion-refined-planner-with-reinforcement-learning-priors-for-c.html">A Diffusion-Refined Planner with Reinforcement Learning Priors for Confined-Space Parking</a></td>
  <td>æå‡ºDRIPä»¥è§£å†³å—é™ç©ºé—´åœè½¦è§„åˆ’é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.14000v1" onclick="toggleFavorite(this, '2510.14000v1', 'A Diffusion-Refined Planner with Reinforcement Learning Priors for Confined-Space Parking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)