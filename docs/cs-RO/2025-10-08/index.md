---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-10-08
---

# cs.ROï¼ˆ2025-10-08ï¼‰

ğŸ“Š å…± **16** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (10 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (4)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (10 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251007152v2-dpl-depth-only-perceptive-humanoid-locomotion-via-realistic-depth-sy.html">DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction</a></td>
  <td>æå‡ºDPLæ¡†æ¶ï¼Œé€šè¿‡æ·±åº¦ä¿¡æ¯å®ç°ç±»äººæœºå™¨äººåœ¨å¤æ‚åœ°å½¢ä¸Šçš„ç¨³å¥è¿åŠ¨</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.07152v2" onclick="toggleFavorite(this, '2510.07152v2', 'DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251007094v1-sampling-strategies-for-robust-universal-quadrupedal-locomotion-poli.html">Sampling Strategies for Robust Universal Quadrupedal Locomotion Policies</a></td>
  <td>æå‡ºåŸºäºé…ç½®é‡‡æ ·çš„é€šç”¨å››è¶³æœºå™¨äººé²æ£’è¿åŠ¨ç­–ç•¥ï¼Œå®ç°é›¶æ ·æœ¬è¿ç§»</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.07094v1" onclick="toggleFavorite(this, '2510.07094v1', 'Sampling Strategies for Robust Universal Quadrupedal Locomotion Policies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251007625v1-gato-gpu-accelerated-and-batched-trajectory-optimization-for-scalabl.html">GATO: GPU-Accelerated and Batched Trajectory Optimization for Scalable Edge Model Predictive Control</a></td>
  <td>GATOï¼šç”¨äºå¯æ‰©å±•è¾¹ç¼˜æ¨¡å‹é¢„æµ‹æ§åˆ¶çš„GPUåŠ é€Ÿæ‰¹é‡è½¨è¿¹ä¼˜åŒ–</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.07625v1" onclick="toggleFavorite(this, '2510.07625v1', 'GATO: GPU-Accelerated and Batched Trajectory Optimization for Scalable Edge Model Predictive Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251007030v1-diffusing-trajectory-optimization-problems-for-recovery-during-multi.html">Diffusing Trajectory Optimization Problems for Recovery During Multi-Finger Manipulation</a></td>
  <td>æå‡ºåŸºäºæ‰©æ•£æ¨¡å‹çš„è½¨è¿¹ä¼˜åŒ–æ–¹æ³•ï¼Œç”¨äºå¤šæŒ‡çµå·§æ“ä½œä¸­çš„æ¢å¤è¡Œä¸º</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.07030v1" onclick="toggleFavorite(this, '2510.07030v1', 'Diffusing Trajectory Optimization Problems for Recovery During Multi-Finger Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251007548v1-avo-amortized-value-optimization-for-contact-mode-switching-in-multi.html">AVO: Amortized Value Optimization for Contact Mode Switching in Multi-Finger Manipulation</a></td>
  <td>AVOï¼šåŸºäºå€¼å‡½æ•°ä¼˜åŒ–çš„å¤šæŒ‡çµå·§æ“ä½œæ¥è§¦æ¨¡å¼åˆ‡æ¢æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.07548v1" onclick="toggleFavorite(this, '2510.07548v1', 'AVO: Amortized Value Optimization for Contact Mode Switching in Multi-Finger Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251006754v1-uniffield-a-generalizable-unified-neural-feature-field-for-visual-se.html">UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene</a></td>
  <td>UniFFieldï¼šé€šç”¨ã€ç»Ÿä¸€ä¸”èƒ½æ„ŸçŸ¥ä¸ç¡®å®šæ€§çš„ç¥ç»ç‰¹å¾åœºï¼Œé€‚ç”¨äºä»»æ„åœºæ™¯</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.06754v1" onclick="toggleFavorite(this, '2510.06754v1', 'UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251007417v1-fleet-formal-language-grounded-scheduling-for-heterogeneous-robot-te.html">FLEET: Formal Language-Grounded Scheduling for Heterogeneous Robot Teams</a></td>
  <td>FLEETï¼šé¢å‘å¼‚æ„æœºå™¨äººå›¢é˜Ÿçš„åŸºäºå½¢å¼è¯­è¨€çš„è°ƒåº¦æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.07417v1" onclick="toggleFavorite(this, '2510.07417v1', 'FLEET: Formal Language-Grounded Scheduling for Heterogeneous Robot Teams')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251007181v2-tiger-tool-integrated-geometric-reasoning-in-vision-language-models-.html">TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics</a></td>
  <td>TIGeRï¼šé€šè¿‡å·¥å…·é›†æˆå‡ ä½•æ¨ç†ï¼Œæå‡è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨æœºå™¨äººé¢†åŸŸçš„ç²¾åº¦</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.07181v2" onclick="toggleFavorite(this, '2510.07181v2', 'TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251007611v1-inspection-planning-primitives-with-implicit-models.html">Inspection Planning Primitives with Implicit Models</a></td>
  <td>æå‡ºIPIMï¼Œåˆ©ç”¨éšå¼æ¨¡å‹é«˜æ•ˆè¿›è¡Œå¤æ‚ç»“æ„å·¡æ£€è§„åˆ’ï¼Œæ˜¾è‘—é™ä½å†…å­˜å ç”¨ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.07611v1" onclick="toggleFavorite(this, '2510.07611v1', 'Inspection Planning Primitives with Implicit Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251007027v1-tailoring-materials-into-kirigami-robots.html">Tailoring materials into kirigami robots</a></td>
  <td>åˆ©ç”¨å‰ªçº¸å·¥è‰ºå®šåˆ¶ææ–™ï¼Œå®ç°å¤šåŠŸèƒ½è½»é‡åŒ–æœºå™¨äºº</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.07027v1" onclick="toggleFavorite(this, '2510.07027v1', 'Tailoring materials into kirigami robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>11</td>
  <td><a href="./papers/251007067v1-bring-the-apple-not-the-sofa-impact-of-irrelevant-context-in-embodie.html">Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models</a></td>
  <td>ç ”ç©¶æ— å…³ä¸Šä¸‹æ–‡å¯¹å…·èº«AIä¸­VLAæ¨¡å‹æŒ‡ä»¤ç†è§£çš„å½±å“ï¼Œå¹¶æå‡ºLLMè¿‡æ»¤æ¡†æ¶ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.07067v1" onclick="toggleFavorite(this, '2510.07067v1', 'Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251007077v1-vision-language-action-models-for-robotics-a-review-towards-real-wor.html">Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications</a></td>
  <td>ç»¼è¿°ï¼šé¢å‘çœŸå®æœºå™¨äººåº”ç”¨çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ç ”ç©¶è¿›å±•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.07077v1" onclick="toggleFavorite(this, '2510.07077v1', 'Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251006717v1-sandra-safe-large-language-model-based-decision-making-for-automated.html">SanDRA: Safe Large-Language-Model-Based Decision Making for Automated Vehicles Using Reachability Analysis</a></td>
  <td>SanDRAï¼šåŸºäºå¯è¾¾æ€§åˆ†æçš„è‡ªåŠ¨é©¾é©¶è½¦è¾†å®‰å…¨å¤§è¯­è¨€æ¨¡å‹å†³ç­–æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.06717v1" onclick="toggleFavorite(this, '2510.06717v1', 'SanDRA: Safe Large-Language-Model-Based Decision Making for Automated Vehicles Using Reachability Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251006633v1-assist-as-needed-adaptive-multimodal-robotic-assistance-for-medicati.html">Assist-As-Needed: Adaptive Multimodal Robotic Assistance for Medication Management in Dementia Care</a></td>
  <td>æå‡ºAssist-As-Neededè‡ªé€‚åº”å¤šæ¨¡æ€æœºå™¨äººè¾…åŠ©ç³»ç»Ÿï¼Œç”¨äºç—´å‘†ç—‡æ‚£è€…çš„è¯ç‰©ç®¡ç†ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.06633v1" onclick="toggleFavorite(this, '2510.06633v1', 'Assist-As-Needed: Adaptive Multimodal Robotic Assistance for Medication Management in Dementia Care')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>15</td>
  <td><a href="./papers/251006710v1-rlinf-vla-a-unified-and-efficient-framework-for-vlarl-training.html">RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training</a></td>
  <td>RLinf-VLAï¼šç”¨äºVLA+RLè®­ç»ƒçš„ç»Ÿä¸€é«˜æ•ˆæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.06710v1" onclick="toggleFavorite(this, '2510.06710v1', 'RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>16</td>
  <td><a href="./papers/251007134v1-trackvla-unleashing-reasoning-and-memory-capabilities-in-vla-models-.html">TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking</a></td>
  <td>TrackVLA++ï¼šåˆ©ç”¨VLAæ¨¡å‹ä¸­çš„æ¨ç†å’Œè®°å¿†èƒ½åŠ›å®ç°å…·èº«è§†è§‰è·Ÿè¸ª</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.07134v1" onclick="toggleFavorite(this, '2510.07134v1', 'TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)