---
layout: default
title: Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments
---

# Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.06953" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.06953v1</a>
  <a href="https://arxiv.org/pdf/2509.06953.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.06953v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.06953v1', 'Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiahui Yang, Jason Jingzhou Liu, Yulong Li, Youssef Khaky, Kenneth Shaw, Deepak Pathak

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV, cs.LG, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-09-08

**å¤‡æ³¨**: Website at \url{deep-reactive-policy.com}

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ·±åº¦ååº”ç­–ç•¥DRPï¼Œè§£å†³åŠ¨æ€ç¯å¢ƒä¸­æœºå™¨äººæ“ä½œè‡‚çš„ååº”å¼è¿åŠ¨è§„åˆ’é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œè‡‚` `è¿åŠ¨è§„åˆ’` `æ·±åº¦å­¦ä¹ ` `Transformer` `åŠ¨æ€ç¯å¢ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿè¿åŠ¨è§„åˆ’å™¨éœ€è¦å®Œå…¨çš„ç¯å¢ƒçŸ¥è¯†ï¼Œä¸”é€Ÿåº¦æ…¢ï¼Œéš¾ä»¥é€‚åº”åŠ¨æ€ç¯å¢ƒï¼›ç¥ç»è¿åŠ¨ç­–ç•¥è™½ç„¶èƒ½ç›´æ¥å¤„ç†åŸå§‹æ„Ÿå®˜è¾“å…¥ï¼Œä½†åœ¨å¤æ‚æˆ–åŠ¨æ€ç¯å¢ƒä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºDRPï¼Œæ ¸å¿ƒæ˜¯åŸºäºTransformerçš„ç¥ç»è¿åŠ¨ç­–ç•¥IMPACTï¼Œé€šè¿‡å¤§é‡ä¸“å®¶è½¨è¿¹é¢„è®­ç»ƒï¼Œå¹¶ç»“åˆå¸ˆç”Ÿå¾®è°ƒå’Œå±€éƒ¨ååº”å¼ç›®æ ‡æè®®æ¨¡å—DCP-RMPï¼Œæå‡åŠ¨æ€ç¯å¢ƒé€‚åº”æ€§ã€‚
3. DRPåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œçš„å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­è¡¨ç°å‡ºè‰²ï¼ŒæˆåŠŸç‡è¶…è¶Šäº†ä¼ ç»Ÿçš„å’Œç¥ç»æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œååº”å¼è¿åŠ¨è§„åˆ’èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºæ·±åº¦ååº”ç­–ç•¥ï¼ˆDRPï¼‰çš„è§†è§‰-è¿åŠ¨ç¥ç»è¿åŠ¨ç­–ç•¥ï¼Œæ—¨åœ¨ä¸ºå„ç§åŠ¨æ€ç¯å¢ƒä¸­çš„ååº”å¼è¿åŠ¨ç”Ÿæˆæä¾›è§£å†³æ–¹æ¡ˆï¼Œè¯¥ç­–ç•¥ç›´æ¥ä½œç”¨äºç‚¹äº‘æ„Ÿå®˜è¾“å…¥ã€‚DRPçš„æ ¸å¿ƒæ˜¯IMPACTï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºTransformerçš„ç¥ç»è¿åŠ¨ç­–ç•¥ï¼Œé€šè¿‡åœ¨å„ç§æ¨¡æ‹Ÿåœºæ™¯ä¸­ç”Ÿæˆçš„1000ä¸‡æ¡ä¸“å®¶è½¨è¿¹è¿›è¡Œé¢„è®­ç»ƒã€‚é€šè¿‡è¿­ä»£çš„å¸ˆç”Ÿå¾®è°ƒï¼Œè¿›ä¸€æ­¥æé«˜äº†IMPACTåœ¨é™æ€éšœç¢ç‰©è§„é¿æ–¹é¢çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œåœ¨æ¨ç†æ—¶ï¼Œä½¿ç”¨DCP-RMPï¼ˆä¸€ä¸ªå±€éƒ¨ååº”å¼ç›®æ ‡æè®®æ¨¡å—ï¼‰å¢å¼ºäº†ç­–ç•¥åœ¨åŠ¨æ€éšœç¢ç‰©è§„é¿æ–¹é¢çš„èƒ½åŠ›ã€‚åœ¨å…·æœ‰æ‚ä¹±åœºæ™¯ã€åŠ¨æ€ç§»åŠ¨éšœç¢ç‰©å’Œç›®æ ‡é˜»å¡ç­‰æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸­å¯¹DRPè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDRPå…·æœ‰å¾ˆå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­ï¼Œå…¶æˆåŠŸç‡å‡ä¼˜äºä»¥å¾€çš„ç»å…¸æ–¹æ³•å’Œç¥ç»æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šåœ¨åŠ¨æ€ã€éƒ¨åˆ†å¯è§‚æµ‹çš„ç¯å¢ƒä¸­ï¼Œæœºå™¨äººæ“ä½œè‡‚ç”Ÿæˆæ— ç¢°æ’è¿åŠ¨è½¨è¿¹æ˜¯ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚ä¼ ç»Ÿè¿åŠ¨è§„åˆ’æ–¹æ³•è™½ç„¶å¯ä»¥è®¡ç®—å…¨å±€æœ€ä¼˜è½¨è¿¹ï¼Œä½†éœ€è¦å®Œæ•´çš„ç¯å¢ƒä¿¡æ¯ï¼Œå¹¶ä¸”è®¡ç®—é€Ÿåº¦é€šå¸¸è¾ƒæ…¢ï¼Œéš¾ä»¥é€‚åº”åŠ¨æ€åœºæ™¯ã€‚ç°æœ‰çš„ç¥ç»è¿åŠ¨ç­–ç•¥è™½ç„¶å¯ä»¥ç›´æ¥ä»åŸå§‹ä¼ æ„Ÿå™¨è¾“å…¥è¿›è¡Œé—­ç¯æ“ä½œï¼Œä½†å¾€å¾€éš¾ä»¥åœ¨å¤æ‚æˆ–åŠ¨æ€ç¯å¢ƒä¸­æ³›åŒ–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿç›´æ¥ä»ç‚¹äº‘æ•°æ®è¿›è¡Œååº”å¼è¿åŠ¨è§„åˆ’çš„ç¥ç»ç­–ç•¥ã€‚é€šè¿‡é¢„è®­ç»ƒå­¦ä¹ é€šç”¨çš„è¿åŠ¨æ¨¡å¼ï¼Œç„¶åé€šè¿‡å¾®è°ƒå’Œå±€éƒ¨ååº”å¼æ¨¡å—æ¥å¢å¼ºç­–ç•¥åœ¨ç‰¹å®šç¯å¢ƒä¸‹çš„é€‚åº”æ€§å’ŒåŠ¨æ€é¿éšœèƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•ç»“åˆäº†ç¦»çº¿å­¦ä¹ çš„æ³›åŒ–èƒ½åŠ›å’Œåœ¨çº¿ååº”çš„çµæ´»æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDRPçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1) åŸºäºTransformerçš„ç¥ç»è¿åŠ¨ç­–ç•¥IMPACTï¼Œç”¨äºå­¦ä¹ é€šç”¨çš„è¿åŠ¨æ¨¡å¼ï¼›2) è¿­ä»£çš„å¸ˆç”Ÿå¾®è°ƒï¼Œç”¨äºæé«˜é™æ€éšœç¢ç‰©è§„é¿èƒ½åŠ›ï¼›3) å±€éƒ¨ååº”å¼ç›®æ ‡æè®®æ¨¡å—DCP-RMPï¼Œç”¨äºå¢å¼ºåŠ¨æ€éšœç¢ç‰©è§„é¿èƒ½åŠ›ã€‚IMPACTé¦–å…ˆåœ¨å¤§è§„æ¨¡æ¨¡æ‹Ÿæ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åé€šè¿‡å¸ˆç”Ÿå­¦ä¹ è¿›è¡Œå¾®è°ƒï¼Œæœ€ååœ¨æ¨ç†æ—¶ç»“åˆDCP-RMPè¿›è¡ŒåŠ¨æ€é¿éšœã€‚

**å…³é”®åˆ›æ–°**ï¼šDRPçš„å…³é”®åˆ›æ–°åœ¨äºå°†Transformeræ¶æ„åº”ç”¨äºç¥ç»è¿åŠ¨ç­–ç•¥ï¼Œå¹¶ç»“åˆé¢„è®­ç»ƒã€å¾®è°ƒå’Œå±€éƒ¨ååº”å¼æ¨¡å—ï¼Œä»è€Œå®ç°äº†åœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­å…·æœ‰å¼ºå¤§æ³›åŒ–èƒ½åŠ›å’Œååº”èƒ½åŠ›çš„è¿åŠ¨è§„åˆ’ã€‚ä¸ä¼ ç»Ÿçš„è¿åŠ¨è§„åˆ’æ–¹æ³•ç›¸æ¯”ï¼ŒDRPå¯ä»¥ç›´æ¥ä»åŸå§‹ä¼ æ„Ÿå™¨æ•°æ®è¿›è¡Œè§„åˆ’ï¼Œæ— éœ€å®Œæ•´çš„ç¯å¢ƒæ¨¡å‹ã€‚ä¸ç°æœ‰çš„ç¥ç»è¿åŠ¨ç­–ç•¥ç›¸æ¯”ï¼ŒDRPé€šè¿‡é¢„è®­ç»ƒå’Œå¾®è°ƒæé«˜äº†æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶é€šè¿‡DCP-RMPå¢å¼ºäº†åŠ¨æ€é¿éšœèƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šIMPACTä½¿ç”¨Transformerç¼–ç å™¨-è§£ç å™¨ç»“æ„ï¼Œè¾“å…¥ä¸ºç‚¹äº‘æ•°æ®ï¼Œè¾“å‡ºä¸ºæ“ä½œè‡‚çš„è¿åŠ¨æŒ‡ä»¤ã€‚é¢„è®­ç»ƒæ•°æ®åŒ…å«1000ä¸‡æ¡ä¸“å®¶è½¨è¿¹ï¼Œæ¶µç›–å„ç§æ¨¡æ‹Ÿåœºæ™¯ã€‚å¸ˆç”Ÿå¾®è°ƒé‡‡ç”¨è¿­ä»£çš„æ–¹å¼ï¼Œå­¦ç”Ÿç½‘ç»œå­¦ä¹ æ•™å¸ˆç½‘ç»œçš„è¾“å‡ºï¼Œå¹¶ä¸æ–­æé«˜è‡ªèº«çš„æ€§èƒ½ã€‚DCP-RMPåŸºäºè·ç¦»ä¸€è‡´æ€§æƒ©ç½šï¼ˆDistance Consistency Penaltyï¼‰æ¥ç”Ÿæˆå±€éƒ¨ç›®æ ‡ï¼Œå¼•å¯¼æ“ä½œè‡‚é¿å¼€åŠ¨æ€éšœç¢ç‰©ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DRPåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œçš„å®éªŒä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æˆæœã€‚åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­ï¼ŒDRPåœ¨å„ç§å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸­ï¼Œå…¶æˆåŠŸç‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„RRT-Connectå’Œç°æœ‰çš„ç¥ç»è¿åŠ¨ç­–ç•¥ã€‚åœ¨çœŸå®ä¸–ç•Œçš„å®éªŒä¸­ï¼ŒDRPä¹Ÿè¡¨ç°å‡ºäº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼ŒæˆåŠŸåœ°å®Œæˆäº†å¤æ‚çš„ç‰©ä½“æ“ä½œä»»åŠ¡ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚å…·ä½“æ€§èƒ½æ•°æ®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DRPåœ¨æœºå™¨äººæ“ä½œè‡‚çš„è¿åŠ¨è§„åˆ’é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨æ‹¥æŒ¤çš„ä»“åº“ç¯å¢ƒä¸­è¿›è¡Œæ‹£é€‰å’Œæ”¾ç½®æ“ä½œï¼Œåœ¨åŠ¨æ€çš„ç”Ÿäº§çº¿ä¸Šè¿›è¡Œè£…é…ä»»åŠ¡ï¼Œä»¥åŠåœ¨å®¶åº­æœåŠ¡æœºå™¨äººä¸­è¿›è¡Œç‰©ä½“æ“ä½œã€‚è¯¥ç ”ç©¶çš„å®é™…ä»·å€¼åœ¨äºæé«˜äº†æœºå™¨äººåœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡çš„æ•ˆç‡å’Œå¯é æ€§ã€‚æœªæ¥ï¼ŒDRPå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„æœºå™¨äººï¼Œä¾‹å¦‚ç§»åŠ¨æœºå™¨äººå’Œæ— äººæœºï¼Œä»è€Œå®ç°æ›´å¹¿æ³›çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generating collision-free motion in dynamic, partially observable environments is a fundamental challenge for robotic manipulators. Classical motion planners can compute globally optimal trajectories but require full environment knowledge and are typically too slow for dynamic scenes. Neural motion policies offer a promising alternative by operating in closed-loop directly on raw sensory inputs but often struggle to generalize in complex or dynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural motion policy designed for reactive motion generation in diverse dynamic environments, operating directly on point cloud sensory input. At its core is IMPACT, a transformer-based neural motion policy pretrained on 10 million generated expert trajectories across diverse simulation scenarios. We further improve IMPACT's static obstacle avoidance through iterative student-teacher finetuning. We additionally enhance the policy's dynamic obstacle avoidance at inference time using DCP-RMP, a locally reactive goal-proposal module. We evaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving obstacles, and goal obstructions. DRP achieves strong generalization, outperforming prior classical and neural methods in success rate across both simulated and real-world settings. Video results and code available at https://deep-reactive-policy.com

