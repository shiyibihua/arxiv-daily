---
layout: default
title: Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots
---

# Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.06768" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.06768v1</a>
  <a href="https://arxiv.org/pdf/2509.06768.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.06768v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.06768v1', 'Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Oluwadamilola Sotomi, Devika Kodi, Kiruthiga Chandra Shekar, Aliasghar Arab

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-08

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè§†è§‰-è¯­è¨€æ¨¡å‹çš„è‡ªä¸»ç§»åŠ¨æœºå™¨äººå±é™©ç¼“è§£ç³»ç»Ÿ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªä¸»æœºå™¨äºº` `è§†è§‰-è¯­è¨€æ¨¡å‹` `å¼‚å¸¸æ£€æµ‹` `å±é™©ç¼“è§£` `å¤šæ¨¡æ€èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªä¸»æœºå™¨äººåœ¨åŠ¨æ€ç¯å¢ƒä¸­ç¼ºä¹æœ‰æ•ˆè¯†åˆ«å’Œåº”å¯¹å¼‚å¸¸æƒ…å†µçš„èƒ½åŠ›ï¼Œé™åˆ¶äº†å…¶å®‰å…¨æ€§å’Œè¿è¡Œè¿ç»­æ€§ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§é›†æˆäº†è§†è§‰-è¯­è¨€æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šæ¨¡æ€ç³»ç»Ÿï¼Œç”¨äºè‡ªä¸»æ£€æµ‹ã€æŠ¥å‘Šå’Œç¼“è§£å±é™©æƒ…å†µã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨å¼‚å¸¸æ£€æµ‹æ–¹é¢è¾¾åˆ°äº† 91.2% çš„é¢„æµ‹å‡†ç¡®ç‡ï¼Œå¹¶å…·æœ‰è¾ƒä½çš„å»¶è¿Ÿï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹å’Œç¼“è§£ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿé›†æˆäº†è§†è§‰-è¯­è¨€æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç”¨äºå®æ—¶è¯†åˆ«å’ŒæŠ¥å‘Šå±é™©æƒ…å†µå’Œå†²çªã€‚è¯¥ç³»ç»Ÿä½¿æœºå™¨äººèƒ½å¤Ÿé€šè¿‡ä¸»åŠ¨æ£€æµ‹æœºåˆ¶å’Œè‡ªåŠ¨ç¼“è§£æªæ–½æ¥æ„ŸçŸ¥ã€è§£é‡Šã€æŠ¥å‘Šï¼Œå¹¶åœ¨å¯èƒ½çš„æƒ…å†µä¸‹å“åº”åŸå¸‚å’Œç¯å¢ƒå¼‚å¸¸ã€‚æœ¬æ–‡çš„ä¸€ä¸ªå…³é”®è´¡çŒ®æ˜¯å°†å±é™©å’Œå†²çªçŠ¶æ€é›†æˆåˆ°æœºå™¨äººçš„å†³ç­–æ¡†æ¶ä¸­ï¼Œå…¶ä¸­æ¯ç§å¼‚å¸¸ç±»å‹éƒ½å¯ä»¥è§¦å‘ç‰¹å®šçš„ç¼“è§£ç­–ç•¥ã€‚ç”¨æˆ·ç ”ç©¶ï¼ˆn = 30ï¼‰è¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨å¼‚å¸¸æ£€æµ‹æ–¹é¢çš„æœ‰æ•ˆæ€§ä¸º 91.2% çš„é¢„æµ‹å‡†ç¡®ç‡ï¼Œå¹¶ä¸”ä½¿ç”¨è¾¹ç¼˜äººå·¥æ™ºèƒ½æ¶æ„å®ç°äº†ç›¸å¯¹è¾ƒä½çš„å»¶è¿Ÿå“åº”æ—¶é—´ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè‡ªä¸»ç§»åŠ¨æœºå™¨äººåœ¨åŠ¨æ€ç¯å¢ƒä¸­è¿è¡Œæ—¶ï¼Œéœ€è¦èƒ½å¤Ÿè¯†åˆ«å¹¶æŠ¥å‘Šå¼‚å¸¸æƒ…å†µï¼Œä¾‹å¦‚æ½œåœ¨çš„å±é™©æˆ–å†²çªã€‚ç°æœ‰çš„æ–¹æ³•å¯èƒ½æ— æ³•æœ‰æ•ˆåœ°å°†è§†è§‰ä¿¡æ¯å’Œè¯­è¨€ä¿¡æ¯ç»“åˆèµ·æ¥ï¼Œä»è€Œå¯¼è‡´å¯¹ç¯å¢ƒç†è§£çš„ä¸è¶³ï¼Œä»¥åŠæ— æ³•åŠæ—¶é‡‡å–é€‚å½“çš„ç¼“è§£æªæ–½ã€‚å› æ­¤ï¼Œå¦‚ä½•è®©æœºå™¨äººèƒ½å¤Ÿåƒäººç±»ä¸€æ ·æ„ŸçŸ¥ã€ç†è§£å¹¶å“åº”ç¯å¢ƒä¸­çš„å¼‚å¸¸æƒ…å†µæ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è§†è§‰-è¯­è¨€æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹ç›¸ç»“åˆï¼Œæ„å»ºä¸€ä¸ªå¤šæ¨¡æ€çš„å¼‚å¸¸æ£€æµ‹å’Œç¼“è§£ç³»ç»Ÿã€‚é€šè¿‡è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œæœºå™¨äººå¯ä»¥ç†è§£å›¾åƒä¸­çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæœºå™¨äººå¯ä»¥ç”Ÿæˆè‡ªç„¶è¯­è¨€æŠ¥å‘Šï¼Œå¹¶æ ¹æ®å¼‚å¸¸ç±»å‹è§¦å‘ç›¸åº”çš„ç¼“è§£ç­–ç•¥ã€‚è¿™ç§ç»“åˆä½¿å¾—æœºå™¨äººèƒ½å¤Ÿæ›´å…¨é¢åœ°ç†è§£ç¯å¢ƒï¼Œå¹¶åšå‡ºæ›´æ™ºèƒ½çš„å†³ç­–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç³»ç»Ÿçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è§†è§‰æ„ŸçŸ¥æ¨¡å—ï¼šç”¨äºä»æ‘„åƒå¤´è·å–å›¾åƒæ•°æ®ã€‚2) è§†è§‰-è¯­è¨€æ¨¡å‹ï¼šç”¨äºåˆ†æå›¾åƒå¹¶æå–è¯­ä¹‰ä¿¡æ¯ã€‚3) å¤§å‹è¯­è¨€æ¨¡å‹ï¼šç”¨äºç”ŸæˆæŠ¥å‘Šå’Œåˆ¶å®šç¼“è§£ç­–ç•¥ã€‚4) å†³ç­–æ¨¡å—ï¼šæ ¹æ®å¼‚å¸¸ç±»å‹è§¦å‘ç›¸åº”çš„ç¼“è§£æªæ–½ã€‚5) è¿åŠ¨æ§åˆ¶æ¨¡å—ï¼šæ‰§è¡Œç¼“è§£æªæ–½ï¼Œä¾‹å¦‚é¿å¼€éšœç¢ç‰©æˆ–å‘å‡ºè­¦å‘Šã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†å±é™©å’Œå†²çªçŠ¶æ€é›†æˆåˆ°æœºå™¨äººçš„å†³ç­–æ¡†æ¶ä¸­ã€‚è¿™æ„å‘³ç€ç³»ç»Ÿä¸ä»…èƒ½å¤Ÿæ£€æµ‹åˆ°å¼‚å¸¸æƒ…å†µï¼Œè¿˜èƒ½æ ¹æ®å¼‚å¸¸çš„ç±»å‹é‡‡å–ä¸åŒçš„åº”å¯¹æªæ–½ã€‚è¿™ç§æ–¹æ³•ä½¿å¾—æœºå™¨äººèƒ½å¤Ÿæ›´æ™ºèƒ½åœ°é€‚åº”ä¸åŒçš„ç¯å¢ƒï¼Œå¹¶æé«˜å…¶å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­æåˆ°ä½¿ç”¨äº†è¾¹ç¼˜äººå·¥æ™ºèƒ½æ¶æ„ï¼Œè¿™è¡¨æ˜æ¨¡å‹å¯èƒ½ç»è¿‡äº†ä¼˜åŒ–ï¼Œä»¥ä¾¿åœ¨èµ„æºå—é™çš„æœºå™¨äººå¹³å°ä¸Šè¿è¡Œã€‚å…·ä½“ä½¿ç”¨çš„è§†è§‰-è¯­è¨€æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„é€‰æ‹©ä»¥åŠè®­ç»ƒæ–¹æ³•æœªçŸ¥ã€‚ç¼“è§£ç­–ç•¥çš„è®¾è®¡ä¹Ÿä¾èµ–äºå…·ä½“çš„åº”ç”¨åœºæ™¯å’Œæœºå™¨äººèƒ½åŠ›ï¼Œå…·ä½“ç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨å¼‚å¸¸æ£€æµ‹æ–¹é¢è¾¾åˆ°äº† 91.2% çš„é¢„æµ‹å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿè¿˜å®ç°äº†ç›¸å¯¹è¾ƒä½çš„å»¶è¿Ÿå“åº”æ—¶é—´ï¼Œè¿™å¾—ç›Šäºè¾¹ç¼˜äººå·¥æ™ºèƒ½æ¶æ„çš„åº”ç”¨ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰å¾ˆé«˜çš„å¯è¡Œæ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦è‡ªä¸»ç§»åŠ¨æœºå™¨äººçš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å·¡æ£€ã€å®‰é˜²ç›‘æ§ã€ç‰©æµé…é€å’Œç¾å®³æ•‘æ´ã€‚é€šè¿‡æé«˜æœºå™¨äººå¯¹ç¯å¢ƒå¼‚å¸¸çš„æ„ŸçŸ¥å’Œå“åº”èƒ½åŠ›ï¼Œå¯ä»¥æ˜¾è‘—æå‡å…¶å·¥ä½œæ•ˆç‡å’Œå®‰å…¨æ€§ï¼Œé™ä½äº‹æ•…å‘ç”Ÿçš„é£é™©ï¼Œå¹¶ä¸ºæœªæ¥çš„æ™ºèƒ½åŸå¸‚å»ºè®¾æä¾›æŠ€æœ¯æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autonomous robots operating in dynamic environments should identify and report anomalies. Embodying proactive mitigation improves safety and operational continuity. This paper presents a multimodal anomaly detection and mitigation system that integrates vision-language models and large language models to identify and report hazardous situations and conflicts in real-time. The proposed system enables robots to perceive, interpret, report, and if possible respond to urban and environmental anomalies through proactive detection mechanisms and automated mitigation actions. A key contribution in this paper is the integration of Hazardous and Conflict states into the robot's decision-making framework, where each anomaly type can trigger specific mitigation strategies. User studies (n = 30) demonstrated the effectiveness of the system in anomaly detection with 91.2% prediction accuracy and relatively low latency response times using edge-ai architecture.

