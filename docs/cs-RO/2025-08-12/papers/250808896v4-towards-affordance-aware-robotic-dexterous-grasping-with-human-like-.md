---
layout: default
title: Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors
---

# Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08896" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08896v4</a>
  <a href="https://arxiv.org/pdf/2508.08896.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08896v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08896v4', 'Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haoyu Zhao, Linghao Zhuang, Xingyue Zhao, Cheng Zeng, Haoran Xu, Yuming Jiang, Jun Cen, Kexiang Wang, Jiayan Guo, Siteng Huang, Xin Li, Deli Zhao, Hua Zou

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12 (æ›´æ–°: 2025-11-11)

**å¤‡æ³¨**: AAAI 2026

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAffordDexä»¥è§£å†³æœºå™¨äººçµå·§æŠ“å–ä¸­çš„äººç±»å§¿æ€ä¸åŠŸèƒ½é€‚åº”æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çµå·§æŠ“å–` `åŠŸèƒ½æ„ŸçŸ¥` `äººç±»å§¿æ€` `æœºå™¨äººå­¦ä¹ ` `è’¸é¦è®­ç»ƒ` `è¿åŠ¨å…ˆéªŒ` `æ®‹å·®å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä½çº§æŠ“å–ç¨³å®šæ€§æŒ‡æ ‡ï¼Œå¿½è§†äº†ç‰©ä½“åŠŸèƒ½æ„ŸçŸ¥å’Œäººç±»å§¿æ€çš„é€‚åº”æ€§ï¼Œé™åˆ¶äº†çµå·§æŠ“å–çš„æœ‰æ•ˆæ€§ã€‚
2. AffordDexæ¡†æ¶é€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒï¼Œé¦–å…ˆåœ¨å¤§é‡äººç±»æ‰‹éƒ¨åŠ¨ä½œä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åé€šè¿‡æ®‹å·®æ¨¡å—é€‚åº”ç‰¹å®šç‰©ä½“å®ä¾‹ï¼Œæå‡æŠ“å–ç­–ç•¥çš„è‡ªç„¶æ€§å’Œé€‚åº”æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAffordDexåœ¨å·²è§ç‰©ä½“ã€æœªè§å®ä¾‹å’Œå…¨æ–°ç±»åˆ«ä¸Šå‡æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›åŸºçº¿ï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šçš„æŠ“å–èƒ½åŠ›å’Œäººç±»ç‰¹å¾ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çµå·§æ‰‹èƒ½å¤Ÿå¯¹ç‰©ä½“è¿›è¡Œé€šç”¨æŠ“å–æ˜¯é€šç”¨åµŒå…¥å¼äººå·¥æ™ºèƒ½å‘å±•çš„åŸºç¡€ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•è¿‡äºå…³æ³¨ä½çº§æŠ“å–ç¨³å®šæ€§æŒ‡æ ‡ï¼Œå¿½è§†äº†å¯¹ç‰©ä½“åŠŸèƒ½çš„ç†è§£å’Œäººç±»å§¿æ€çš„é‡è¦æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†AffordDexï¼Œä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œé€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒå­¦ä¹ å…·æœ‰è¿åŠ¨å…ˆéªŒå’Œç‰©ä½“åŠŸèƒ½ç†è§£çš„é€šç”¨æŠ“å–ç­–ç•¥ã€‚ç¬¬ä¸€é˜¶æ®µï¼Œè½¨è¿¹æ¨¡ä»¿å™¨åœ¨å¤§é‡äººç±»æ‰‹éƒ¨åŠ¨ä½œä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥å»ºç«‹è‡ªç„¶è¿åŠ¨çš„å¼ºå…ˆéªŒã€‚ç¬¬äºŒé˜¶æ®µï¼Œæ®‹å·®æ¨¡å—è¢«è®­ç»ƒä»¥å°†è¿™äº›é€šç”¨çš„äººç±»åŠ¨ä½œé€‚åº”äºç‰¹å®šç‰©ä½“å®ä¾‹ã€‚è¯¥è¿‡ç¨‹ç”±è´Ÿå‘åŠŸèƒ½æ„ŸçŸ¥åˆ†å‰²æ¨¡å—å’Œç‰¹æƒæ•™å¸ˆ-å­¦ç”Ÿè’¸é¦è¿‡ç¨‹æŒ‡å¯¼ï¼Œç¡®ä¿æœ€ç»ˆçš„è§†è§‰åŸºç¡€ç­–ç•¥æˆåŠŸã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒAffordDexä¸ä»…å®ç°äº†é€šç”¨çµå·§æŠ“å–ï¼Œè¿˜åœ¨å§¿æ€ä¸Šä¿æŒäº†äººç±»ç‰¹å¾ï¼Œå¹¶åœ¨æ¥è§¦ä½ç½®ä¸ŠåŠŸèƒ½é€‚å½“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººçµå·§æŠ“å–ä¸­å¯¹ç‰©ä½“åŠŸèƒ½æ„ŸçŸ¥å’Œäººç±»å§¿æ€é€‚åº”æ€§çš„ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•è¿‡äºå…³æ³¨æŠ“å–çš„ç¨³å®šæ€§ï¼Œæœªèƒ½æœ‰æ•ˆè€ƒè™‘æŠ“å–åŠ¨ä½œçš„è‡ªç„¶æ€§å’Œé€‚ç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„AffordDexæ¡†æ¶é€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒï¼Œé¦–å…ˆåˆ©ç”¨äººç±»æ‰‹éƒ¨åŠ¨ä½œçš„å…ˆéªŒçŸ¥è¯†è¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åé€šè¿‡æ®‹å·®æ¨¡å—å°†è¿™äº›åŠ¨ä½œé€‚åº”äºç‰¹å®šç‰©ä½“å®ä¾‹ï¼Œä»è€Œæå‡æŠ“å–çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯è½¨è¿¹æ¨¡ä»¿å™¨çš„é¢„è®­ç»ƒï¼Œç¬¬äºŒé˜¶æ®µæ˜¯æ®‹å·®æ¨¡å—çš„è®­ç»ƒã€‚å…³é”®æ¨¡å—åŒ…æ‹¬è´Ÿå‘åŠŸèƒ½æ„ŸçŸ¥åˆ†å‰²æ¨¡å—å’Œæ•™å¸ˆ-å­¦ç”Ÿè’¸é¦è¿‡ç¨‹ï¼Œç¡®ä¿æŠ“å–ç­–ç•¥çš„æˆåŠŸã€‚

**å…³é”®åˆ›æ–°**ï¼šAffordDexçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºç»“åˆäº†äººç±»åŠ¨ä½œçš„å…ˆéªŒçŸ¥è¯†å’Œç‰©ä½“åŠŸèƒ½æ„ŸçŸ¥ï¼Œé€šè¿‡è´Ÿå‘åŠŸèƒ½æ„ŸçŸ¥åˆ†å‰²æ¨¡å—è¯†åˆ«ä¸é€‚åˆçš„æ¥è§¦åŒºåŸŸï¼Œæ˜¾è‘—æå‡äº†æŠ“å–çš„è‡ªç„¶æ€§å’Œæœ‰æ•ˆæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œä½¿ç”¨äº†å¤§é‡äººç±»æ‰‹éƒ¨åŠ¨ä½œæ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼ŒæŸå¤±å‡½æ•°ç»“åˆäº†æŠ“å–æˆåŠŸç‡å’Œæ¥è§¦åŒºåŸŸçš„é€‚å½“æ€§ï¼Œç½‘ç»œç»“æ„é‡‡ç”¨äº†æ®‹å·®å­¦ä¹ ä»¥å¢å¼ºæ¨¡å‹çš„é€‚åº”èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAffordDexåœ¨çµå·§æŠ“å–ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨å¤„ç†æœªè§å®ä¾‹å’Œå…¨æ–°ç±»åˆ«æ—¶ï¼ŒæŠ“å–æˆåŠŸç‡æ˜¾è‘—æé«˜ï¼Œè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„åŸºçº¿ï¼Œå±•ç¤ºäº†å…¶åœ¨é€šç”¨æ€§å’Œé€‚åº”æ€§æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æœºå™¨äººæŠ“å–ã€è‡ªåŠ¨åŒ–åˆ¶é€ å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡æœºå™¨äººå¯¹ç‰©ä½“åŠŸèƒ½çš„ç†è§£å’Œè‡ªç„¶æŠ“å–èƒ½åŠ›ï¼ŒAffordDexèƒ½å¤Ÿæ¨åŠ¨æ™ºèƒ½æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„åº”ç”¨ï¼Œæå‡å…¶æ“ä½œçš„çµæ´»æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A dexterous hand capable of generalizable grasping objects is fundamental for the development of general-purpose embodied AI. However, previous methods focus narrowly on low-level grasp stability metrics, neglecting affordance-aware positioning and human-like poses which are crucial for downstream manipulation. To address these limitations, we propose AffordDex, a novel framework with two-stage training that learns a universal grasping policy with an inherent understanding of both motion priors and object affordances. In the first stage, a trajectory imitator is pre-trained on a large corpus of human hand motions to instill a strong prior for natural movement. In the second stage, a residual module is trained to adapt these general human-like motions to specific object instances. This refinement is critically guided by two components: our Negative Affordance-aware Segmentation (NAA) module, which identifies functionally inappropriate contact regions, and a privileged teacher-student distillation process that ensures the final vision-based policy is highly successful. Extensive experiments demonstrate that AffordDex not only achieves universal dexterous grasping but also remains remarkably human-like in posture and functionally appropriate in contact location. As a result, AffordDex significantly outperforms state-of-the-art baselines across seen objects, unseen instances, and even entirely novel categories.

