---
layout: default
title: DeGuV: Depth-Guided Visual Reinforcement Learning for Generalization and Interpretability in Manipulation
---

# DeGuV: Depth-Guided Visual Reinforcement Learning for Generalization and Interpretability in Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04970" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04970v1</a>
  <a href="https://arxiv.org/pdf/2509.04970.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04970v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04970v1', 'DeGuV: Depth-Guided Visual Reinforcement Learning for Generalization and Interpretability in Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tien Pham, Xinyun Chi, Khang Nguyen, Manfred Huber, Angelo Cangelosi

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DeGuVï¼šæ·±åº¦å¼•å¯¼çš„è§†è§‰å¼ºåŒ–å­¦ä¹ ï¼Œæå‡æ“ä½œä»»åŠ¡çš„æ³›åŒ–æ€§å’Œå¯è§£é‡Šæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰å¼ºåŒ–å­¦ä¹ ` `æ·±åº¦å­¦ä¹ ` `æœºå™¨äººæ“ä½œ` `æ³›åŒ–æ€§` `å¯è§£é‡Šæ€§` `æ·±åº¦ä¿¡æ¯` `å¯¹æ¯”å­¦ä¹ ` `æ•°æ®å¢å¼º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†è§‰å¼ºåŒ–å­¦ä¹ åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­é¢ä¸´æ³›åŒ–æ€§æŒ‘æˆ˜ï¼Œç°æœ‰æ•°æ®å¢å¼ºæ–¹æ³•å¸¸ç‰ºç‰²æ ·æœ¬æ•ˆç‡å’Œè®­ç»ƒç¨³å®šæ€§ã€‚
2. DeGuVé€šè¿‡æ·±åº¦ä¿¡æ¯å¼•å¯¼çš„æ©ç ç½‘ç»œï¼Œä½¿æ™ºèƒ½ä½“å…³æ³¨å…³é”®è§†è§‰ç‰¹å¾ï¼Œæå‡æ•°æ®å¢å¼ºä¸‹çš„é²æ£’æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDeGuVåœ¨RL-ViGenåŸºå‡†æµ‹è¯•ä¸­ï¼Œå®ç°äº†æ›´å¥½çš„æ³›åŒ–æ€§å’Œæ ·æœ¬æ•ˆç‡ï¼Œå¹¶æå‡äº†å¯è§£é‡Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºDeGuVçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æå‡è§†è§‰å¼ºåŒ–å­¦ä¹ åœ¨æ“ä½œä»»åŠ¡ä¸­çš„æ³›åŒ–æ€§å’Œæ ·æœ¬æ•ˆç‡ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨æ•°æ®å¢å¼ºæ—¶æ ·æœ¬æ•ˆç‡ä½å’Œè®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ï¼ŒDeGuVåˆ©ç”¨ä¸€ä¸ªå¯å­¦ä¹ çš„æ©ç ç½‘ç»œï¼Œä»æ·±åº¦è¾“å…¥ä¸­ç”Ÿæˆæ©ç ï¼Œä»…ä¿ç•™å…³é”®è§†è§‰ä¿¡æ¯ï¼Œå»é™¤ä¸ç›¸å…³çš„åƒç´ ã€‚è¿™ç¡®ä¿äº†å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ä¸“æ³¨äºé‡è¦ç‰¹å¾ï¼Œå¢å¼ºäº†æ•°æ®å¢å¼ºä¸‹çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼ŒDeGuVè¿˜ç»“åˆäº†å¯¹æ¯”å­¦ä¹ ï¼Œå¹¶ç¨³å®šäº†å¢å¼ºä¸‹çš„Qå€¼ä¼°è®¡ï¼Œè¿›ä¸€æ­¥æé«˜äº†æ ·æœ¬æ•ˆç‡å’Œè®­ç»ƒç¨³å®šæ€§ã€‚åœ¨RL-ViGenåŸºå‡†æµ‹è¯•ä¸­ï¼Œä½¿ç”¨Franka Emikaæœºå™¨äººå¯¹æ‰€æå‡ºçš„æ–¹æ³•è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜DeGuVåœ¨é›¶æ ·æœ¬sim-to-realè¿ç§»ä¸­ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶åœ¨æ³›åŒ–æ€§å’Œæ ·æœ¬æ•ˆç‡æ–¹é¢å‡æœ‰æå‡ï¼ŒåŒæ—¶é€šè¿‡çªå‡ºæ˜¾ç¤ºè§†è§‰è¾“å…¥ä¸­æœ€ç›¸å…³çš„åŒºåŸŸï¼Œæé«˜äº†å¯è§£é‡Šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†è§‰å¼ºåŒ–å­¦ä¹ åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼Œéš¾ä»¥å°†æ¨¡æ‹Ÿç¯å¢ƒä¸­å­¦ä¹ åˆ°çš„ç­–ç•¥æ³›åŒ–åˆ°çœŸå®ä¸–ç•Œã€‚ç°æœ‰æ–¹æ³•ä¾èµ–å¤§é‡æ•°æ®å¢å¼ºï¼Œä½†ä¼šé™ä½æ ·æœ¬æ•ˆç‡ï¼Œå¹¶å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼Œéš¾ä»¥å¹³è¡¡æ³›åŒ–æ€§å’Œè®­ç»ƒæ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDeGuVçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ·±åº¦ä¿¡æ¯å¼•å¯¼æ™ºèƒ½ä½“å…³æ³¨åœºæ™¯ä¸­çš„å…³é”®ç‰¹å¾ï¼Œå¿½ç•¥ä¸ç›¸å…³ä¿¡æ¯ï¼Œä»è€Œæé«˜å¯¹æ•°æ®å¢å¼ºçš„é²æ£’æ€§ï¼Œå¹¶æå‡æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡å¯å­¦ä¹ çš„æ©ç ç½‘ç»œï¼Œä»æ·±åº¦å›¾åƒä¸­æå–é‡è¦åŒºåŸŸï¼Œå‡å°‘è§†è§‰è¾“å…¥çš„å¤æ‚æ€§ï¼Œä½¿æ™ºèƒ½ä½“æ›´å®¹æ˜“å­¦ä¹ åˆ°é€šç”¨çš„ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDeGuVæ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ·±åº¦æ©ç ç½‘ç»œï¼šç”¨äºä»æ·±åº¦å›¾åƒä¸­ç”Ÿæˆæ©ç ï¼Œçªå‡ºæ˜¾ç¤ºé‡è¦çš„è§†è§‰åŒºåŸŸã€‚2) å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼šä½¿ç”¨æ·±åº¦æ©ç åçš„è§†è§‰è¾“å…¥è¿›è¡Œç­–ç•¥å­¦ä¹ ã€‚3) å¯¹æ¯”å­¦ä¹ æ¨¡å—ï¼šç”¨äºå­¦ä¹ æ›´é²æ£’çš„è§†è§‰è¡¨å¾ã€‚4) Qå€¼ç¨³å®šæ¨¡å—ï¼šç”¨äºç¨³å®šæ•°æ®å¢å¼ºä¸‹çš„Qå€¼ä¼°è®¡ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼Œé¦–å…ˆé€šè¿‡æ·±åº¦æ©ç ç½‘ç»œå¤„ç†æ·±åº¦å›¾åƒï¼Œç„¶åå°†æ©ç åçš„å›¾åƒè¾“å…¥åˆ°å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ä¸­è¿›è¡Œè®­ç»ƒï¼ŒåŒæ—¶ä½¿ç”¨å¯¹æ¯”å­¦ä¹ å’ŒQå€¼ç¨³å®šæ¨¡å—æ¥æé«˜æ³›åŒ–æ€§å’Œè®­ç»ƒç¨³å®šæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šDeGuVçš„å…³é”®åˆ›æ–°åœ¨äºåˆ©ç”¨æ·±åº¦ä¿¡æ¯å¼•å¯¼çš„è§†è§‰ç‰¹å¾é€‰æ‹©ã€‚ä¸ä¼ ç»Ÿçš„æ•°æ®å¢å¼ºæ–¹æ³•ä¸åŒï¼ŒDeGuVä¸æ˜¯ç®€å•åœ°å¯¹æ‰€æœ‰è§†è§‰ä¿¡æ¯è¿›è¡Œå¢å¼ºï¼Œè€Œæ˜¯æœ‰é€‰æ‹©æ€§åœ°ä¿ç•™é‡è¦çš„è§†è§‰ç‰¹å¾ï¼Œå»é™¤ä¸ç›¸å…³çš„åƒç´ ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æé«˜æ™ºèƒ½ä½“å¯¹ç¯å¢ƒå˜åŒ–çš„é²æ£’æ€§ï¼Œå¹¶å‡å°‘å­¦ä¹ çš„å¤æ‚æ€§ã€‚æ­¤å¤–ï¼Œç»“åˆå¯¹æ¯”å­¦ä¹ å’ŒQå€¼ç¨³å®šæ¨¡å—ï¼Œè¿›ä¸€æ­¥æé«˜äº†æ ·æœ¬æ•ˆç‡å’Œè®­ç»ƒç¨³å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šæ·±åº¦æ©ç ç½‘ç»œé‡‡ç”¨å·ç§¯ç¥ç»ç½‘ç»œç»“æ„ï¼Œè¾“å…¥ä¸ºæ·±åº¦å›¾åƒï¼Œè¾“å‡ºä¸ºæ©ç å›¾åƒã€‚æ©ç å›¾åƒä¸åŸå§‹RGBå›¾åƒç›¸ä¹˜ï¼Œå¾—åˆ°æ©ç åçš„è§†è§‰è¾“å…¥ã€‚å¯¹æ¯”å­¦ä¹ æ¨¡å—ä½¿ç”¨InfoNCEæŸå¤±å‡½æ•°ï¼Œé¼“åŠ±ç›¸ä¼¼çš„è§†è§‰è¡¨å¾èšé›†åœ¨ä¸€èµ·ï¼Œä¸åŒçš„è§†è§‰è¡¨å¾åˆ†æ•£å¼€æ¥ã€‚Qå€¼ç¨³å®šæ¨¡å—é€šè¿‡å¯¹Qå€¼è¿›è¡Œæ­£åˆ™åŒ–ï¼Œé˜²æ­¢Qå€¼åœ¨æ•°æ®å¢å¼ºä¸‹å‘ç”Ÿå‰§çƒˆå˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DeGuVåœ¨RL-ViGenåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆæœï¼Œåœ¨é›¶æ ·æœ¬sim-to-realè¿ç§»ä»»åŠ¡ä¸­ï¼ŒDeGuVçš„æ€§èƒ½ä¼˜äºç°æœ‰çš„state-of-the-artæ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼ŒDeGuVåœ¨æˆåŠŸç‡æ–¹é¢å–å¾—äº†æ˜¾è‘—æå‡ï¼Œå¹¶ä¸”åœ¨æ ·æœ¬æ•ˆç‡æ–¹é¢ä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿåœ¨æ›´å°‘çš„è®­ç»ƒæ ·æœ¬ä¸‹è¾¾åˆ°æ›´é«˜çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¯è§†åŒ–æ·±åº¦æ©ç ï¼Œå¯ä»¥æ¸…æ™°åœ°çœ‹åˆ°DeGuVå…³æ³¨çš„è§†è§‰åŒºåŸŸï¼ŒéªŒè¯äº†å…¶å¯è§£é‡Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DeGuVåœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚å·¥ä¸šè‡ªåŠ¨åŒ–ã€å®¶åº­æœåŠ¡æœºå™¨äººã€åŒ»ç–—æœºå™¨äººç­‰ã€‚é€šè¿‡æé«˜æœºå™¨äººçš„æ³›åŒ–èƒ½åŠ›å’Œæ ·æœ¬æ•ˆç‡ï¼Œå¯ä»¥é™ä½æœºå™¨äººçš„éƒ¨ç½²æˆæœ¬ï¼Œå¹¶ä½¿å…¶èƒ½å¤Ÿé€‚åº”æ›´åŠ å¤æ‚å’ŒåŠ¨æ€çš„ç¯å¢ƒã€‚æ­¤å¤–ï¼ŒDeGuVçš„å¯è§£é‡Šæ€§ä¹Ÿä½¿å…¶æ›´å®¹æ˜“è¢«äººç±»ç†è§£å’Œä¿¡ä»»ï¼Œæœ‰åŠ©äºäººæœºåä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement learning (RL) agents can learn to solve complex tasks from visual inputs, but generalizing these learned skills to new environments remains a major challenge in RL application, especially robotics. While data augmentation can improve generalization, it often compromises sample efficiency and training stability. This paper introduces DeGuV, an RL framework that enhances both generalization and sample efficiency. In specific, we leverage a learnable masker network that produces a mask from the depth input, preserving only critical visual information while discarding irrelevant pixels. Through this, we ensure that our RL agents focus on essential features, improving robustness under data augmentation. In addition, we incorporate contrastive learning and stabilize Q-value estimation under augmentation to further enhance sample efficiency and training stability. We evaluate our proposed method on the RL-ViGen benchmark using the Franka Emika robot and demonstrate its effectiveness in zero-shot sim-to-real transfer. Our results show that DeGuV outperforms state-of-the-art methods in both generalization and sample efficiency while also improving interpretability by highlighting the most relevant regions in the visual input

