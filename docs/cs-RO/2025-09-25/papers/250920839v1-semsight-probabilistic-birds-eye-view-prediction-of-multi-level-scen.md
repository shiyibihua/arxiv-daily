---
layout: default
title: SemSight: Probabilistic Bird's-Eye-View Prediction of Multi-Level Scene Semantics for Navigation
---

# SemSight: Probabilistic Bird's-Eye-View Prediction of Multi-Level Scene Semantics for Navigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.20839" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.20839v1</a>
  <a href="https://arxiv.org/pdf/2509.20839.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.20839v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.20839v1', 'SemSight: Probabilistic Bird\'s-Eye-View Prediction of Multi-Level Scene Semantics for Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiaxuan He, Jiamei Ren, Chongshang Yan, Wenjie Song

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SemSightï¼šç”¨äºå¯¼èˆªçš„å¤šå±‚æ¬¡åœºæ™¯è¯­ä¹‰æ¦‚ç‡é¸Ÿç°å›¾é¢„æµ‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `é¸Ÿç°å›¾é¢„æµ‹` `è¯­ä¹‰åœ°å›¾` `æœºå™¨äººå¯¼èˆª` `åœºæ™¯ç†è§£` `æ©ç çº¦æŸå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¯¼èˆªæ–¹æ³•ä¾§é‡äºå•ä¸ªç‰©ä½“æˆ–å‡ ä½•å ç”¨ï¼Œå¿½ç•¥äº†æˆ¿é—´çº§è¯­ä¹‰ç»“æ„ï¼Œé™åˆ¶äº†ç¯å¢ƒç†è§£ã€‚
2. SemSighté€šè¿‡è”åˆæ¨æ–­ç»“æ„å¸ƒå±€ã€åœºæ™¯ä¸Šä¸‹æ–‡å’Œç›®æ ‡åŒºåŸŸåˆ†å¸ƒï¼Œé¢„æµ‹æœªæ¢ç´¢åŒºåŸŸçš„å¤šå±‚æ¬¡è¯­ä¹‰ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSemSightåœ¨è¯­ä¹‰é¢„æµ‹å’Œå¯¼èˆªæ•ˆç‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨ç»“æ„ä¸€è‡´æ€§å’ŒåŒºåŸŸè¯†åˆ«æ–¹é¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ç›®æ ‡é©±åŠ¨å¯¼èˆªå’Œè‡ªä¸»æ¢ç´¢ä¸­ï¼Œå¯¹æœªçŸ¥åŒºåŸŸçš„åˆç†é¢„æµ‹å¯¹äºé«˜æ•ˆå¯¼èˆªå’Œç¯å¢ƒç†è§£è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å•ä¸ªå¯¹è±¡æˆ–å‡ ä½•å ç”¨å›¾ï¼Œç¼ºä¹å»ºæ¨¡æˆ¿é—´çº§è¯­ä¹‰ç»“æ„çš„èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†SemSightï¼Œä¸€ä¸ªç”¨äºå¤šå±‚æ¬¡åœºæ™¯è¯­ä¹‰çš„æ¦‚ç‡é¸Ÿç°å›¾é¢„æµ‹æ¨¡å‹ã€‚è¯¥æ¨¡å‹è”åˆæ¨æ–­ç»“æ„å¸ƒå±€ã€å…¨å±€åœºæ™¯ä¸Šä¸‹æ–‡å’Œç›®æ ‡åŒºåŸŸåˆ†å¸ƒï¼Œå®Œæˆæœªæ¢ç´¢åŒºåŸŸçš„è¯­ä¹‰åœ°å›¾ï¼ŒåŒæ—¶ä¼°è®¡ç›®æ ‡ç±»åˆ«çš„æ¦‚ç‡å›¾ã€‚ä¸ºäº†è®­ç»ƒSemSightï¼Œæˆ‘ä»¬åœ¨2000ä¸ªå®¤å†…å¸ƒå±€å›¾ä¸Šæ¨¡æ‹Ÿäº†å‰æ²¿é©±åŠ¨çš„æ¢ç´¢ï¼Œæ„å»ºäº†ä¸€ä¸ªåŒ…å«40000ä¸ªè¿ç»­è‡ªæˆ‘ä¸­å¿ƒè§‚æµ‹ä¸å®Œæ•´è¯­ä¹‰åœ°å›¾é…å¯¹çš„å¤šæ ·åŒ–æ•°æ®é›†ã€‚æˆ‘ä»¬é‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨ç½‘ç»œä½œä¸ºæ ¸å¿ƒæ¶æ„ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ©ç çº¦æŸç›‘ç£ç­–ç•¥ã€‚è¿™ç§ç­–ç•¥åº”ç”¨æœªæ¢ç´¢åŒºåŸŸçš„äºŒå…ƒæ©ç ï¼Œä½¿ç›‘ç£åªå…³æ³¨æœªçŸ¥åŒºåŸŸï¼Œè¿«ä½¿æ¨¡å‹ä»è§‚å¯Ÿåˆ°çš„ä¸Šä¸‹æ–‡ä¸­æ¨æ–­è¯­ä¹‰ç»“æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSemSightæé«˜äº†æœªæ¢ç´¢åŒºåŸŸå…³é”®åŠŸèƒ½ç±»åˆ«çš„é¢„æµ‹æ€§èƒ½ï¼Œå¹¶åœ¨ç»“æ„ä¸€è‡´æ€§ï¼ˆSCï¼‰å’ŒåŒºåŸŸè¯†åˆ«å‡†ç¡®ç‡ï¼ˆPAï¼‰ç­‰æŒ‡æ ‡ä¸Šä¼˜äºéæ©ç ç›‘ç£æ–¹æ³•ã€‚å®ƒè¿˜æé«˜äº†é—­ç¯æ¨¡æ‹Ÿä¸­çš„å¯¼èˆªæ•ˆç‡ï¼Œå‡å°‘äº†å¼•å¯¼æœºå™¨äººæœå‘ç›®æ ‡åŒºåŸŸçš„æœç´¢æ­¥éª¤ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºè§†è§‰çš„å¯¼èˆªæ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨æœªçŸ¥ç¯å¢ƒä¸­ï¼Œé€šå¸¸ä¾èµ–äºå¯¹å•ä¸ªç‰©ä½“æˆ–å‡ ä½•å ç”¨æƒ…å†µçš„é¢„æµ‹ã€‚è¿™äº›æ–¹æ³•å¿½ç•¥äº†åœºæ™¯çš„ç»“æ„åŒ–è¯­ä¹‰ä¿¡æ¯ï¼Œä¾‹å¦‚æˆ¿é—´å¸ƒå±€å’ŒåŠŸèƒ½åŒºåŸŸï¼Œå¯¼è‡´å¯¼èˆªæ•ˆç‡ä½ä¸‹ï¼Œéš¾ä»¥ç†è§£ç¯å¢ƒçš„æ•´ä½“ç»“æ„ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿé¢„æµ‹æœªæ¢ç´¢åŒºåŸŸå¤šå±‚æ¬¡è¯­ä¹‰ä¿¡æ¯çš„æ–¹æ³•ï¼Œä»è€Œæå‡å¯¼èˆªæ€§èƒ½å’Œç¯å¢ƒç†è§£èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSemSightçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ¦‚ç‡é¸Ÿç°å›¾é¢„æµ‹æ¨¡å‹ï¼Œè”åˆæ¨æ–­åœºæ™¯çš„ç»“æ„å¸ƒå±€ã€å…¨å±€åœºæ™¯ä¸Šä¸‹æ–‡å’Œç›®æ ‡åŒºåŸŸåˆ†å¸ƒã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹ä¸ä»…å¯ä»¥é¢„æµ‹æœªæ¢ç´¢åŒºåŸŸçš„è¯­ä¹‰ä¿¡æ¯ï¼Œè¿˜å¯ä»¥ä¼°è®¡ç›®æ ‡ç±»åˆ«çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä»è€ŒæŒ‡å¯¼å¯¼èˆªã€‚è¿™ç§è”åˆæ¨æ–­çš„æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨å·²è§‚å¯Ÿåˆ°çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæé«˜é¢„æµ‹çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSemSighté‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨ç½‘ç»œä½œä¸ºæ ¸å¿ƒæ¶æ„ã€‚ç¼–ç å™¨è´Ÿè´£æå–è‡ªæˆ‘ä¸­å¿ƒè§‚æµ‹çš„ç‰¹å¾ï¼Œè§£ç å™¨åˆ™è´Ÿè´£ç”Ÿæˆé¸Ÿç°å›¾è§†è§’çš„è¯­ä¹‰åœ°å›¾å’Œç›®æ ‡æ¦‚ç‡å›¾ã€‚æ•´ä¸ªæ¡†æ¶é€šè¿‡æ¨¡æ‹Ÿå‰æ²¿é©±åŠ¨çš„æ¢ç´¢è¿‡ç¨‹è¿›è¡Œè®­ç»ƒï¼Œæ„å»ºåŒ…å«è¿ç»­è‡ªæˆ‘ä¸­å¿ƒè§‚æµ‹å’Œå®Œæ•´è¯­ä¹‰åœ°å›¾çš„æ•°æ®é›†ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨æ©ç çº¦æŸç›‘ç£ç­–ç•¥ï¼Œåªå¯¹æœªæ¢ç´¢åŒºåŸŸè¿›è¡Œç›‘ç£ï¼Œè¿«ä½¿æ¨¡å‹ä»å·²è§‚å¯Ÿåˆ°çš„ä¸Šä¸‹æ–‡ä¸­æ¨æ–­è¯­ä¹‰ç»“æ„ã€‚

**å…³é”®åˆ›æ–°**ï¼šSemSightçš„å…³é”®åˆ›æ–°åœ¨äºå…¶æ¦‚ç‡é¸Ÿç°å›¾é¢„æµ‹æ¨¡å‹å’Œæ©ç çº¦æŸç›‘ç£ç­–ç•¥ã€‚æ¦‚ç‡é¸Ÿç°å›¾é¢„æµ‹æ¨¡å‹èƒ½å¤Ÿè”åˆæ¨æ–­åœºæ™¯çš„ç»“æ„å¸ƒå±€ã€å…¨å±€åœºæ™¯ä¸Šä¸‹æ–‡å’Œç›®æ ‡åŒºåŸŸåˆ†å¸ƒï¼Œä»è€Œæ›´å…¨é¢åœ°ç†è§£åœºæ™¯è¯­ä¹‰ã€‚æ©ç çº¦æŸç›‘ç£ç­–ç•¥åˆ™èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨æœªæ¢ç´¢åŒºåŸŸçš„ä¿¡æ¯ï¼Œæé«˜æ¨¡å‹å¯¹æœªçŸ¥åŒºåŸŸçš„é¢„æµ‹èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šSemSightçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ç¼–ç å™¨-è§£ç å™¨ç½‘ç»œè¿›è¡Œç‰¹å¾æå–å’Œè¯­ä¹‰é¢„æµ‹ï¼›2) é‡‡ç”¨æ©ç çº¦æŸç›‘ç£ç­–ç•¥ï¼Œåªå¯¹æœªæ¢ç´¢åŒºåŸŸè¿›è¡Œç›‘ç£ï¼›3) é€šè¿‡æ¨¡æ‹Ÿå‰æ²¿é©±åŠ¨çš„æ¢ç´¢è¿‡ç¨‹ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼›4) ä½¿ç”¨ç»“æ„ä¸€è‡´æ€§ï¼ˆSCï¼‰å’ŒåŒºåŸŸè¯†åˆ«å‡†ç¡®ç‡ï¼ˆPAï¼‰ç­‰æŒ‡æ ‡è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SemSightåœ¨æœªæ¢ç´¢åŒºåŸŸçš„å…³é”®åŠŸèƒ½ç±»åˆ«é¢„æµ‹æ€§èƒ½ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSemSightåœ¨ç»“æ„ä¸€è‡´æ€§ï¼ˆSCï¼‰å’ŒåŒºåŸŸè¯†åˆ«å‡†ç¡®ç‡ï¼ˆPAï¼‰ç­‰æŒ‡æ ‡ä¸Šä¼˜äºéæ©ç ç›‘ç£æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒSemSightè¿˜æé«˜äº†é—­ç¯æ¨¡æ‹Ÿä¸­çš„å¯¼èˆªæ•ˆç‡ï¼Œå‡å°‘äº†å¼•å¯¼æœºå™¨äººæœå‘ç›®æ ‡åŒºåŸŸçš„æœç´¢æ­¥éª¤ã€‚è¿™äº›ç»“æœè¡¨æ˜SemSightèƒ½å¤Ÿæœ‰æ•ˆåœ°é¢„æµ‹æœªæ¢ç´¢åŒºåŸŸçš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶æå‡å¯¼èˆªæ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SemSightå¯åº”ç”¨äºæœºå™¨äººè‡ªä¸»å¯¼èˆªã€è™šæ‹Ÿç°å®ç¯å¢ƒæ„å»ºã€æ™ºèƒ½å®¶å±…ç­‰é¢†åŸŸã€‚åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼ŒSemSightå¯ä»¥å¸®åŠ©æœºå™¨äººåœ¨æœªçŸ¥ç¯å¢ƒä¸­æ›´é«˜æ•ˆåœ°æ¢ç´¢å’Œå®šä½ç›®æ ‡ã€‚åœ¨è™šæ‹Ÿç°å®ä¸­ï¼ŒSemSightå¯ä»¥ç”¨äºç”Ÿæˆæ›´é€¼çœŸçš„åœºæ™¯ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚åœ¨æ™ºèƒ½å®¶å±…ä¸­ï¼ŒSemSightå¯ä»¥å¸®åŠ©è®¾å¤‡ç†è§£å®¶åº­ç¯å¢ƒï¼Œæä¾›æ›´æ™ºèƒ½çš„æœåŠ¡ã€‚è¯¥ç ”ç©¶çš„æœªæ¥å½±å“åœ¨äºæå‡æœºå™¨äººå’Œäººå·¥æ™ºèƒ½ç³»ç»Ÿçš„ç¯å¢ƒç†è§£å’Œäº¤äº’èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In target-driven navigation and autonomous exploration, reasonable prediction of unknown regions is crucial for efficient navigation and environment understanding. Existing methods mostly focus on single objects or geometric occupancy maps, lacking the ability to model room-level semantic structures. We propose SemSight, a probabilistic bird's-eye-view prediction model for multi-level scene semantics. The model jointly infers structural layouts, global scene context, and target area distributions, completing semantic maps of unexplored areas while estimating probability maps for target categories. To train SemSight, we simulate frontier-driven exploration on 2,000 indoor layout graphs, constructing a diverse dataset of 40,000 sequential egocentric observations paired with complete semantic maps. We adopt an encoder-decoder network as the core architecture and introduce a mask-constrained supervision strategy. This strategy applies a binary mask of unexplored areas so that supervision focuses only on unknown regions, forcing the model to infer semantic structures from the observed context. Experimental results show that SemSight improves prediction performance for key functional categories in unexplored regions and outperforms non-mask-supervised approaches on metrics such as Structural Consistency (SC) and Region Recognition Accuracy (PA). It also enhances navigation efficiency in closed-loop simulations, reducing the number of search steps when guiding robots toward target areas.

