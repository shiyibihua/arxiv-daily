---
layout: default
title: AnywhereVLA: Language-Conditioned Exploration and Mobile Manipulation
---

# AnywhereVLA: Language-Conditioned Exploration and Mobile Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21006" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21006v1</a>
  <a href="https://arxiv.org/pdf/2509.21006.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21006v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21006v1', 'AnywhereVLA: Language-Conditioned Exploration and Mobile Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Konstantin Gubernatorov, Artem Voronov, Roman Voronov, Sergei Pasynkov, Stepan Perminov, Ziang Guo, Dzmitry Tsetserukou

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**AnywhereVLAï¼šé¢å‘æœªè§ç¯å¢ƒçš„è¯­è¨€æ¡ä»¶ç§»åŠ¨æ“ä½œæ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç§»åŠ¨æ“ä½œ` `è‡ªç„¶è¯­è¨€å¼•å¯¼` `SLAM` `è§†è§‰è¯­è¨€æ¨¡å‹` `ä»»åŠ¡å›¾` `æœºå™¨äºº` `è‡ªä¸»æ¢ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç§»åŠ¨æ“ä½œæ–¹æ³•åœ¨å¤æ‚ã€æœªçŸ¥çš„å®¤å†…ç¯å¢ƒä¸­ï¼Œéš¾ä»¥å®ç°è‡ªç„¶è¯­è¨€å¼•å¯¼çš„å¯é æ“ä½œã€‚
2. AnywhereVLAæ¡†æ¶ç»“åˆç»å…¸SLAMä¸è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œåˆ©ç”¨ä»»åŠ¡å›¾é©±åŠ¨æ¢ç´¢å’Œæ“ä½œï¼Œæå‡æ³›åŒ–æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒAnywhereVLAåœ¨çœŸå®åœºæ™¯ä¸­å®ç°äº†46%çš„ä»»åŠ¡æˆåŠŸç‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå®æ—¶æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

AnywhereVLAæ˜¯ä¸€ä¸ªæ¨¡å—åŒ–çš„ç§»åŠ¨æ“ä½œæ¡†æ¶ï¼Œç”¨äºè§£å†³åœ¨æœªè§è¿‡çš„ã€ä¸å¯é¢„æµ‹çš„å®¤å†…ç¯å¢ƒä¸­è¿›è¡Œè‡ªç„¶è¯­è¨€å¼•å¯¼çš„æ‹¾å–å’Œæ”¾ç½®ä»»åŠ¡ã€‚ç”¨æˆ·æ–‡æœ¬æç¤ºä½œä¸ºå…¥å£ï¼Œè¢«è§£ææˆç»“æ„åŒ–çš„ä»»åŠ¡å›¾ï¼Œç”¨äºè°ƒèŠ‚åŸºäºæ¿€å…‰é›·è¾¾å’Œç›¸æœºçš„ç»å…¸SLAMã€åº¦é‡è¯­ä¹‰åœ°å›¾ä»¥åŠä»»åŠ¡æ„ŸçŸ¥çš„è¾¹ç•Œæ¢ç´¢ç­–ç•¥ã€‚ç„¶åï¼Œæ–¹æ³•è§„åˆ’å™¨é€‰æ‹©å¯è§æ€§å’Œå¯è¾¾æ€§æ„ŸçŸ¥çš„é¢„æŠ“å–åŸºä½å§¿ã€‚å¯¹äºäº¤äº’ï¼Œä¸€ä¸ªç´§å‡‘çš„SmolVLAæ“ä½œå¤´åœ¨TheRobotStudioçš„SO-101å¹³å°ä¸Šè¿›è¡Œå¾®è°ƒï¼Œç”¨äºå¹³å°æ‹¾å–å’Œæ”¾ç½®è½¨è¿¹ï¼Œå°†å±€éƒ¨è§†è§‰ä¸Šä¸‹æ–‡å’Œå­ç›®æ ‡èå…¥åˆ°æŠ“å–å’Œæ”¾ç½®æè®®ä¸­ã€‚æ•´ä¸ªç³»ç»Ÿå®Œå…¨åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šè¿è¡Œï¼ŒJetson Orin NXç”¨äºæ„ŸçŸ¥å’ŒVLAï¼ŒIntel NUCç”¨äºSLAMã€æ¢ç´¢å’Œæ§åˆ¶ï¼Œä¿æŒå®æ—¶è¿è¡Œã€‚æˆ‘ä»¬åœ¨é™æ€åœºæ™¯å’Œæ­£å¸¸äººä½“è¿åŠ¨ä¸‹çš„å¤šæˆ¿é—´å®éªŒå®¤ä¸­è¯„ä¼°äº†AnywhereVLAã€‚åœ¨è¿™ç§è®¾ç½®ä¸‹ï¼Œç³»ç»Ÿå®ç°äº†46%çš„æ€»ä½“ä»»åŠ¡æˆåŠŸç‡ï¼ŒåŒæ—¶ä¿æŒäº†åµŒå…¥å¼è®¡ç®—çš„ååé‡ã€‚é€šè¿‡å°†ç»å…¸å †æ ˆä¸å¾®è°ƒçš„VLAæ“ä½œç›¸ç»“åˆï¼Œè¯¥ç³»ç»Ÿç»§æ‰¿äº†å‡ ä½•å¯¼èˆªçš„å¯é æ€§ä»¥åŠè¯­è¨€æ¡ä»¶æ“ä½œçš„æ•æ·æ€§å’Œä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨å¤æ‚ã€æœªçŸ¥çš„å®¤å†…ç¯å¢ƒä¸­ï¼Œå¦‚ä½•å®ç°è‡ªç„¶è¯­è¨€å¼•å¯¼çš„ç§»åŠ¨æ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚â€œæŠŠè‹¹æœä»å¨æˆ¿æ‹¿åˆ°å§å®¤â€ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºé¢„å®šä¹‰çš„åœ°å›¾æˆ–ç¯å¢ƒï¼Œæ³›åŒ–èƒ½åŠ›è¾ƒå·®ï¼Œéš¾ä»¥é€‚åº”åŠ¨æ€å˜åŒ–çš„ç¯å¢ƒã€‚æ­¤å¤–ï¼Œå°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„æœºå™¨äººåŠ¨ä½œä¹Ÿé¢ä¸´æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAnywhereVLAçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤è§£æä¸ºç»“æ„åŒ–çš„ä»»åŠ¡å›¾ï¼Œå¹¶åˆ©ç”¨è¯¥ä»»åŠ¡å›¾æ¥æŒ‡å¯¼æœºå™¨äººçš„æ¢ç´¢ã€å¯¼èˆªå’Œæ“ä½œã€‚é€šè¿‡ç»“åˆç»å…¸çš„SLAMå’Œåº¦é‡è¯­ä¹‰åœ°å›¾æ„å»ºï¼Œä»¥åŠä»»åŠ¡æ„ŸçŸ¥çš„è¾¹ç•Œæ¢ç´¢ç­–ç•¥ï¼Œæœºå™¨äººèƒ½å¤Ÿè‡ªä¸»åœ°æ¢ç´¢æœªçŸ¥ç¯å¢ƒï¼Œå¹¶æ‰¾åˆ°åˆé€‚çš„æŠ“å–å’Œæ”¾ç½®ä½ç½®ã€‚åŒæ—¶ï¼Œåˆ©ç”¨å¾®è°ƒçš„VLAæ“ä½œå¤´ï¼Œå°†å±€éƒ¨è§†è§‰ä¸Šä¸‹æ–‡å’Œå­ç›®æ ‡èå…¥åˆ°æŠ“å–å’Œæ”¾ç½®æè®®ä¸­ï¼Œæé«˜æ“ä½œçš„æˆåŠŸç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAnywhereVLAæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) ä»»åŠ¡å›¾è§£æå™¨ï¼šå°†ç”¨æˆ·è¾“å…¥çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤è§£æä¸ºç»“æ„åŒ–çš„ä»»åŠ¡å›¾ã€‚2) SLAMå’Œåº¦é‡è¯­ä¹‰åœ°å›¾æ„å»ºï¼šåˆ©ç”¨æ¿€å…‰é›·è¾¾å’Œç›¸æœºæ•°æ®æ„å»ºç¯å¢ƒçš„SLAMåœ°å›¾å’Œåº¦é‡è¯­ä¹‰åœ°å›¾ã€‚3) ä»»åŠ¡æ„ŸçŸ¥çš„è¾¹ç•Œæ¢ç´¢ç­–ç•¥ï¼šæ ¹æ®ä»»åŠ¡å›¾ï¼Œè‡ªä¸»åœ°æ¢ç´¢æœªçŸ¥ç¯å¢ƒï¼Œå¯»æ‰¾ç›®æ ‡ç‰©ä½“å’Œæ”¾ç½®ä½ç½®ã€‚4) æ–¹æ³•è§„åˆ’å™¨ï¼šé€‰æ‹©å¯è§æ€§å’Œå¯è¾¾æ€§æ„ŸçŸ¥çš„é¢„æŠ“å–åŸºä½å§¿ã€‚5) VLAæ“ä½œå¤´ï¼šæ‰§è¡ŒæŠ“å–å’Œæ”¾ç½®æ“ä½œã€‚æ•´ä¸ªç³»ç»Ÿåœ¨Jetson Orin NXå’ŒIntel NUCä¸Šè¿è¡Œï¼Œå®ç°å®æ—¶æ“ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šAnywhereVLAçš„å…³é”®åˆ›æ–°åœ¨äºå°†ç»å…¸çš„SLAMå’Œåº¦é‡è¯­ä¹‰åœ°å›¾æ„å»ºä¸è§†è§‰è¯­è¨€æ¨¡å‹ç›¸ç»“åˆï¼Œåˆ©ç”¨ä»»åŠ¡å›¾æ¥é©±åŠ¨æœºå™¨äººçš„æ¢ç´¢å’Œæ“ä½œã€‚è¿™ç§æ–¹æ³•ä¸ä»…æé«˜äº†æœºå™¨äººåœ¨æœªçŸ¥ç¯å¢ƒä¸­çš„è‡ªä¸»å¯¼èˆªèƒ½åŠ›ï¼Œè¿˜å¢å¼ºäº†å…¶å¯¹è‡ªç„¶è¯­è¨€æŒ‡ä»¤çš„ç†è§£å’Œæ‰§è¡Œèƒ½åŠ›ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¾®è°ƒVLAæ“ä½œå¤´ï¼Œå°†å±€éƒ¨è§†è§‰ä¸Šä¸‹æ–‡èå…¥åˆ°æŠ“å–å’Œæ”¾ç½®æè®®ä¸­ï¼Œæé«˜äº†æ“ä½œçš„æˆåŠŸç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šä»»åŠ¡å›¾è§£æå™¨çš„å…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ã€‚ä»»åŠ¡æ„ŸçŸ¥çš„è¾¹ç•Œæ¢ç´¢ç­–ç•¥å¯èƒ½ä½¿ç”¨äº†å¼ºåŒ–å­¦ä¹ æˆ–åŸºäºè§„åˆ™çš„æ–¹æ³•ã€‚VLAæ“ä½œå¤´çš„å¾®è°ƒä½¿ç”¨äº†å¹³å°æ‹¾å–å’Œæ”¾ç½®è½¨è¿¹ï¼ŒæŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„æœªçŸ¥ã€‚ç³»ç»Ÿåœ¨Jetson Orin NXä¸Šè¿è¡Œæ„ŸçŸ¥å’ŒVLAï¼Œåœ¨Intel NUCä¸Šè¿è¡ŒSLAMã€æ¢ç´¢å’Œæ§åˆ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

AnywhereVLAåœ¨å¤šæˆ¿é—´å®éªŒå®¤ç¯å¢ƒä¸­è¿›è¡Œäº†è¯„ä¼°ï¼Œå®ç°äº†46%çš„æ€»ä½“ä»»åŠ¡æˆåŠŸç‡ã€‚è¯¥ç³»ç»Ÿåœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šè¿è¡Œï¼Œä¿æŒäº†åµŒå…¥å¼è®¡ç®—çš„ååé‡ï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºå‡ ä½•çš„å¯¼èˆªæ–¹æ³•ç›¸æ¯”ï¼ŒAnywhereVLAå…·æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›å’Œå¯¹è‡ªç„¶è¯­è¨€æŒ‡ä»¤çš„ç†è§£èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AnywhereVLAå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚å®¶åº­æœåŠ¡æœºå™¨äººã€ä»“åº“è‡ªåŠ¨åŒ–ã€åŒ»ç–—è¾…åŠ©æœºå™¨äººç­‰ã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººåœ¨å¤æ‚ã€åŠ¨æ€çš„ç¯å¢ƒä¸­è‡ªä¸»åœ°å®Œæˆå„ç§ä»»åŠ¡ï¼Œä¾‹å¦‚ç‰©å“æ‹¾å–ã€æ•´ç†ã€æ¸…æ´ç­‰ï¼Œä»è€Œæé«˜å·¥ä½œæ•ˆç‡å’Œç”Ÿæ´»è´¨é‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ›´å¹¿æ³›çš„é¢†åŸŸï¼Œä¾‹å¦‚ç¾éš¾æ•‘æ´ã€å¤ªç©ºæ¢ç´¢ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We address natural language pick-and-place in unseen, unpredictable indoor environments with AnywhereVLA, a modular framework for mobile manipulation. A user text prompt serves as an entry point and is parsed into a structured task graph that conditions classical SLAM with LiDAR and cameras, metric semantic mapping, and a task-aware frontier exploration policy. An approach planner then selects visibility and reachability aware pre grasp base poses. For interaction, a compact SmolVLA manipulation head is fine tuned on platform pick and place trajectories for the SO-101 by TheRobotStudio, grounding local visual context and sub-goals into grasp and place proposals. The full system runs fully onboard on consumer-level hardware, with Jetson Orin NX for perception and VLA and an Intel NUC for SLAM, exploration, and control, sustaining real-time operation. We evaluated AnywhereVLA in a multi-room lab under static scenes and normal human motion. In this setting, the system achieves a $46\%$ overall task success rate while maintaining throughput on embedded compute. By combining a classical stack with a fine-tuned VLA manipulation, the system inherits the reliability of geometry-based navigation with the agility and task generalization of language-conditioned manipulation.

