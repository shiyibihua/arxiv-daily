---
layout: default
title: Efficient Construction of Implicit Surface Models From a Single Image for Motion Generation
---

# Efficient Construction of Implicit Surface Models From a Single Image for Motion Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.20681" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.20681v1</a>
  <a href="https://arxiv.org/pdf/2509.20681.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.20681v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.20681v1', 'Efficient Construction of Implicit Surface Models From a Single Image for Motion Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wei-Teng Chu, Tianyi Zhang, Matthew Johnson-Roberson, Weiming Zhi

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**FINSï¼šä¸€ç§åŸºäºå•å¼ å›¾åƒå¿«é€Ÿæ„å»ºéšå¼è¡¨é¢æ¨¡å‹çš„æ–¹æ³•ï¼Œç”¨äºæœºå™¨äººè¿åŠ¨ç”Ÿæˆã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éšå¼è¡¨é¢é‡å»º` `å•å›¾åƒé‡å»º` `ç¥ç»è¾å°„åœº` `æœºå™¨äººè¿åŠ¨è§„åˆ’` `æ·±åº¦å­¦ä¹ ` `å“ˆå¸Œç¼–ç ` `SDFåœº`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰éšå¼è¡¨é¢é‡å»ºæ–¹æ³•ï¼Œå¦‚NeuSï¼Œä¾èµ–å¤§é‡å¤šè§†è§’å›¾åƒä¸”è®­ç»ƒè€—æ—¶ï¼Œé™åˆ¶äº†å…¶åœ¨å®æ—¶æœºå™¨äººåº”ç”¨ä¸­çš„æ½œåŠ›ã€‚
2. FINSé€šè¿‡ç»“åˆå¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼ç¼–ç å™¨å’Œè½»é‡çº§ç½‘ç»œï¼Œå¹¶åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œå®ç°äº†ä»å•å¼ å›¾åƒå¿«é€Ÿé‡å»ºé«˜ç²¾åº¦éšå¼è¡¨é¢ã€‚
3. å®éªŒè¯æ˜ï¼ŒFINSåœ¨é‡å»ºç²¾åº¦å’Œé€Ÿåº¦ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶æˆåŠŸåº”ç”¨äºæœºå™¨äººè¡¨é¢è·Ÿè¸ªä»»åŠ¡ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ¢è®¨äº†ä»å•å¼ å›¾åƒæ„å»ºéšå¼è·ç¦»è¡¨ç¤ºçš„é—®é¢˜ã€‚ç°æœ‰çš„éšå¼è¡¨é¢é‡å»ºæ–¹æ³•ï¼Œå¦‚NeuSåŠå…¶å˜ä½“ï¼Œé€šå¸¸éœ€è¦å¤§é‡çš„å¤šè§†è§’å›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶ä¸”è®­ç»ƒæ—¶é—´å¾ˆé•¿ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§è½»é‡çº§æ¡†æ¶Fast Image-to-Neural Surface (FINS)ï¼Œå®ƒå¯ä»¥åŸºäºå•å¼ æˆ–å°‘é‡å›¾åƒé‡å»ºé«˜ä¿çœŸè¡¨é¢å’ŒSDFåœºã€‚FINSé›†æˆäº†å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼ç¼–ç å™¨ä¸è½»é‡çº§çš„å‡ ä½•å’Œé¢œè‰²å¤´ï¼Œé€šè¿‡è¿‘ä¼¼äºŒé˜¶ä¼˜åŒ–å™¨è¿›è¡Œè®­ç»ƒï¼Œä½¿å…¶éå¸¸é«˜æ•ˆï¼Œå¹¶èƒ½åœ¨å‡ ç§’é’Ÿå†…æ”¶æ•›ã€‚æ­¤å¤–ï¼Œé€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒçš„åŸºç¡€æ¨¡å‹æ¥ä¼°è®¡å›¾åƒä¸­å›ºæœ‰çš„å‡ ä½•ä¿¡æ¯ï¼Œæˆ‘ä»¬ä»…ä½¿ç”¨å•å¼ RGBå›¾åƒå³å¯æ„å»ºç¥ç»è¡¨é¢ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨ç›¸åŒæ¡ä»¶ä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¡¨é¢é‡å»ºå’ŒSDFåœºä¼°è®¡æ–¹é¢çš„æ”¶æ•›é€Ÿåº¦å’Œç²¾åº¦å‡ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†FINSåœ¨æœºå™¨äººè¡¨é¢è·Ÿè¸ªä»»åŠ¡ä¸­çš„é€‚ç”¨æ€§ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨å„ç§åŸºå‡†æ•°æ®é›†ä¸Šçš„å¯æ‰©å±•æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»å•å¼ RGBå›¾åƒå¿«é€Ÿä¸”å‡†ç¡®åœ°é‡å»ºéšå¼è¡¨é¢æ¨¡å‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚NeuSåŠå…¶å˜ä½“ï¼Œé€šå¸¸éœ€è¦å¤šè§†è§’å›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶ä¸”è®­ç»ƒæ—¶é—´é•¿ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨éœ€è¦å¿«é€Ÿå“åº”çš„æœºå™¨äººåº”ç”¨ä¸­çš„åº”ç”¨ã€‚è¿™äº›æ–¹æ³•è®¡ç®—é‡å¤§ï¼Œéš¾ä»¥éƒ¨ç½²åœ¨èµ„æºå—é™çš„å¹³å°ä¸Šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFINSçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼ç¼–ç å™¨æ¥é«˜æ•ˆåœ°è¡¨ç¤ºåœºæ™¯å‡ ä½•ï¼Œå¹¶ç»“åˆè½»é‡çº§çš„å‡ ä½•å’Œé¢œè‰²é¢„æµ‹ç½‘ç»œï¼Œä»è€Œå‡å°‘è®¡ç®—é‡å’Œè®­ç»ƒæ—¶é—´ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰åŸºç¡€æ¨¡å‹æ¥æå–å•å¼ å›¾åƒä¸­çš„å‡ ä½•ä¿¡æ¯ï¼Œå¼¥è¡¥å•è§†è§’ä¿¡æ¯ä¸è¶³çš„é—®é¢˜ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å®ç°é«˜ç²¾åº¦å’Œé«˜æ•ˆç‡çš„å¹³è¡¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFINSçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼ç¼–ç å™¨ï¼šç”¨äºå°†ä¸‰ç»´åæ ‡ç¼–ç æˆé«˜ç»´ç‰¹å¾å‘é‡ã€‚2) å‡ ä½•é¢„æµ‹å¤´ï¼šåŸºäºç¼–ç åçš„ç‰¹å¾é¢„æµ‹SDFå€¼ã€‚3) é¢œè‰²é¢„æµ‹å¤´ï¼šåŸºäºç¼–ç åçš„ç‰¹å¾å’Œè§†è§’æ–¹å‘é¢„æµ‹é¢œè‰²ã€‚4) é¢„è®­ç»ƒè§†è§‰åŸºç¡€æ¨¡å‹ï¼šç”¨äºæå–å•å¼ å›¾åƒçš„æ·±åº¦ä¿¡æ¯ä½œä¸ºå‡ ä½•å…ˆéªŒã€‚è®­ç»ƒè¿‡ç¨‹ä½¿ç”¨è¿‘ä¼¼äºŒé˜¶ä¼˜åŒ–å™¨åŠ é€Ÿæ”¶æ•›ã€‚

**å…³é”®åˆ›æ–°**ï¼šFINSçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) è½»é‡çº§ç½‘ç»œç»“æ„ï¼šé€šè¿‡ä½¿ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼ç¼–ç å™¨å’Œè½»é‡çº§çš„å‡ ä½•/é¢œè‰²é¢„æµ‹å¤´ï¼Œæ˜¾è‘—å‡å°‘äº†å‚æ•°é‡å’Œè®¡ç®—é‡ã€‚2) å•å›¾åƒé‡å»ºèƒ½åŠ›ï¼šåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹æå–å‡ ä½•å…ˆéªŒï¼Œå®ç°äº†ä»…ä½¿ç”¨å•å¼ RGBå›¾åƒè¿›è¡Œé«˜è´¨é‡éšå¼è¡¨é¢é‡å»ºã€‚3) é«˜æ•ˆè®­ç»ƒï¼šé‡‡ç”¨è¿‘ä¼¼äºŒé˜¶ä¼˜åŒ–å™¨ï¼ŒåŠ é€Ÿäº†è®­ç»ƒè¿‡ç¨‹ï¼Œå®ç°äº†ç§’çº§æ”¶æ•›ã€‚

**å…³é”®è®¾è®¡**ï¼šå¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼ç¼–ç å™¨å°†ç©ºé—´åˆ’åˆ†ä¸ºä¸åŒåˆ†è¾¨ç‡çš„ç½‘æ ¼ï¼Œæ¯ä¸ªç½‘æ ¼é¡¶ç‚¹å…³è”ä¸€ä¸ªå¯å­¦ä¹ çš„ç‰¹å¾å‘é‡ã€‚å‡ ä½•é¢„æµ‹å¤´å’Œé¢œè‰²é¢„æµ‹å¤´é€šå¸¸æ˜¯å°å‹MLPç½‘ç»œã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬SDFæŸå¤±ï¼ˆä¾‹å¦‚L1æŸå¤±æˆ–HuberæŸå¤±ï¼‰å’Œé¢œè‰²æŸå¤±ï¼ˆä¾‹å¦‚L1æŸå¤±æˆ–MSEï¼‰ã€‚é¢„è®­ç»ƒæ¨¡å‹æä¾›çš„æ·±åº¦ä¿¡æ¯è¢«ç”¨ä½œæ­£åˆ™åŒ–é¡¹ï¼Œä»¥çº¦æŸé‡å»ºçš„å‡ ä½•å½¢çŠ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨è¡¨é¢é‡å»ºå’ŒSDFåœºä¼°è®¡ä»»åŠ¡ä¸­ï¼ŒFINSåœ¨æ”¶æ•›é€Ÿåº¦å’Œç²¾åº¦ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨ç›¸åŒçš„å®éªŒæ¡ä»¶ä¸‹ï¼ŒFINSçš„è®­ç»ƒæ—¶é—´æ¯”NeuSå¿«å‡ ä¸ªæ•°é‡çº§ï¼Œå¹¶ä¸”é‡å»ºç²¾åº¦æ›´é«˜ã€‚æ­¤å¤–ï¼ŒFINSæˆåŠŸåº”ç”¨äºæœºå™¨äººè¡¨é¢è·Ÿè¸ªä»»åŠ¡ï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FINSåœ¨æœºå™¨äººé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚ï¼šæœºå™¨äººå¯¼èˆªã€é¿éšœã€ç‰©ä½“æŠ“å–ã€è¡¨é¢è·Ÿè¸ªç­‰ã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººå¿«é€Ÿç†è§£å‘¨å›´ç¯å¢ƒï¼Œå¹¶ç”Ÿæˆå®‰å…¨çš„è¿åŠ¨è½¨è¿¹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰é¢†åŸŸï¼Œç”¨äºå¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„ä¸‰ç»´æ¨¡å‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Implicit representations have been widely applied in robotics for obstacle avoidance and path planning. In this paper, we explore the problem of constructing an implicit distance representation from a single image. Past methods for implicit surface reconstruction, such as \emph{NeuS} and its variants generally require a large set of multi-view images as input, and require long training times. In this work, we propose Fast Image-to-Neural Surface (FINS), a lightweight framework that can reconstruct high-fidelity surfaces and SDF fields based on a single or a small set of images. FINS integrates a multi-resolution hash grid encoder with lightweight geometry and color heads, making the training via an approximate second-order optimizer highly efficient and capable of converging within a few seconds. Additionally, we achieve the construction of a neural surface requiring only a single RGB image, by leveraging pre-trained foundation models to estimate the geometry inherent in the image. Our experiments demonstrate that under the same conditions, our method outperforms state-of-the-art baselines in both convergence speed and accuracy on surface reconstruction and SDF field estimation. Moreover, we demonstrate the applicability of FINS for robot surface following tasks and show its scalability to a variety of benchmark datasets.

