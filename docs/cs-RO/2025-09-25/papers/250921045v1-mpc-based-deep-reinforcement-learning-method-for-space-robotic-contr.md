---
layout: default
title: MPC-based Deep Reinforcement Learning Method for Space Robotic Control with Fuel Sloshing Mitigation
---

# MPC-based Deep Reinforcement Learning Method for Space Robotic Control with Fuel Sloshing Mitigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21045" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21045v1</a>
  <a href="https://arxiv.org/pdf/2509.21045.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21045v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21045v1', 'MPC-based Deep Reinforcement Learning Method for Space Robotic Control with Fuel Sloshing Mitigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mahya Ramezani, M. Amin Alandihallaj, BarÄ±ÅŸ Can YalÃ§Ä±n, Miguel Angel Olivares Mendez, Holger Voos

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25

**å¤‡æ³¨**: Pre-print version submitted to IEEE IROS

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºMPCçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºæŠ‘åˆ¶ç‡ƒæ–™æ™ƒåŠ¨ç©ºé—´æœºå™¨äººæ§åˆ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç©ºé—´æœºå™¨äºº` `ç‡ƒæ–™æ™ƒåŠ¨` `æ¨¡å‹é¢„æµ‹æ§åˆ¶` `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `å«æ˜Ÿå¯¹æ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç‡ƒæ–™æ™ƒåŠ¨æ˜¯ç©ºé—´æœºå™¨äººå¯¹æ¥ä¸­çš„éš¾é¢˜ï¼Œä¼šäº§ç”Ÿéš¾ä»¥é¢„æµ‹çš„åŠ›ï¼Œå½±å“ç³»ç»Ÿç¨³å®šæ€§ã€‚
2. è®ºæ–‡å°†MPCä¸PPOå’ŒSACç­‰RLç®—æ³•ç»“åˆï¼Œåˆ©ç”¨MPCçš„é¢„æµ‹èƒ½åŠ›åŠ é€ŸRLè®­ç»ƒï¼Œæé«˜æ§åˆ¶é²æ£’æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSAC-MPCåœ¨å¯¹æ¥ç²¾åº¦ã€æˆåŠŸç‡å’Œæ§åˆ¶åŠ›æ–¹é¢ä¼˜äºå•ç‹¬çš„RLå’ŒPPO-MPCæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§é›†æˆäº†å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œæ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰çš„æ¡†æ¶ï¼Œç”¨äºè‡ªä¸»å«æ˜Ÿå¯¹æ¥ï¼Œå°¤å…¶é’ˆå¯¹éƒ¨åˆ†å¡«å……ç‡ƒæ–™ç®±çš„æƒ…å†µã€‚ä¼ ç»Ÿçš„å¯¹æ¥æ§åˆ¶é¢ä¸´å¾®é‡åŠ›ä¸‹ç‡ƒæ–™æ™ƒåŠ¨å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œè¿™ç§æ™ƒåŠ¨ä¼šäº§ç”Ÿä¸å¯é¢„æµ‹çš„åŠ›ï¼Œå½±å“ç¨³å®šæ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰å’Œè½¯æ¼”å‘˜-è¯„è®ºå®¶ï¼ˆSACï¼‰RLç®—æ³•ä¸MPCç›¸ç»“åˆï¼Œåˆ©ç”¨MPCçš„é¢„æµ‹èƒ½åŠ›æ¥åŠ é€ŸRLè®­ç»ƒå¹¶æé«˜æ§åˆ¶é²æ£’æ€§ã€‚é€šè¿‡SnTçš„Zero-Gå®éªŒå®¤çš„å¹³é¢ç¨³å®šå®éªŒå’Œé«˜ä¿çœŸæ•°å€¼æ¨¡æ‹Ÿï¼ˆ6è‡ªç”±åº¦å¯¹æ¥ï¼ŒåŒ…å«ç‡ƒæ–™æ™ƒåŠ¨åŠ¨åŠ›å­¦ï¼‰éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼ŒSAC-MPCåœ¨å¯¹æ¥ç²¾åº¦ã€æˆåŠŸç‡å’Œæ§åˆ¶åŠ›æ–¹é¢å‡ä¼˜äºç‹¬ç«‹çš„RLå’ŒPPO-MPCæ–¹æ³•ã€‚è¿™é¡¹ç ”ç©¶æ¨è¿›äº†ç‡ƒæ–™æ•ˆç‡é«˜ä¸”æŠ—å¹²æ‰°çš„å«æ˜Ÿå¯¹æ¥æŠ€æœ¯ï¼Œå¢å¼ºäº†åœ¨è½¨åŠ æ²¹å’Œç»´ä¿®ä»»åŠ¡çš„å¯è¡Œæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³éƒ¨åˆ†å¡«å……ç‡ƒæ–™ç®±çš„å«æ˜Ÿåœ¨å¾®é‡åŠ›ç¯å¢ƒä¸‹è‡ªä¸»å¯¹æ¥æ—¶ï¼Œç”±äºç‡ƒæ–™æ™ƒåŠ¨å¼•èµ·çš„æ§åˆ¶éš¾é¢˜ã€‚ç‡ƒæ–™æ™ƒåŠ¨ä¼šäº§ç”Ÿéš¾ä»¥é¢„æµ‹çš„åŠ›å’ŒåŠ›çŸ©ï¼Œä¸¥é‡å½±å“å«æ˜Ÿçš„å§¿æ€ç¨³å®šæ€§å’Œå¯¹æ¥ç²¾åº¦ã€‚ä¼ ç»Ÿçš„æ§åˆ¶æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæŠ‘åˆ¶ç‡ƒæ–™æ™ƒåŠ¨å¸¦æ¥çš„å¹²æ‰°ï¼Œå¯¼è‡´å¯¹æ¥å¤±è´¥æˆ–éœ€è¦æ¶ˆè€—å¤§é‡ç‡ƒæ–™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰ä¸æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰ç›¸ç»“åˆã€‚MPCèƒ½å¤Ÿåˆ©ç”¨ç³»ç»ŸåŠ¨åŠ›å­¦æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œä»è€Œæå‰è§„åˆ’æ§åˆ¶åŠ¨ä½œï¼Œè€ŒDRLåˆ™å¯ä»¥é€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’å­¦ä¹ æœ€ä¼˜ç­–ç•¥ã€‚é€šè¿‡å°†ä¸¤è€…ç»“åˆï¼Œå¯ä»¥åˆ©ç”¨MPCçš„é¢„æµ‹èƒ½åŠ›æ¥åŠ é€ŸDRLçš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶æé«˜æ§åˆ¶å™¨çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼šMPCæ§åˆ¶å™¨å’ŒDRLç­–ç•¥ç½‘ç»œã€‚MPCæ§åˆ¶å™¨åŸºäºå«æ˜Ÿçš„åŠ¨åŠ›å­¦æ¨¡å‹å’Œç‡ƒæ–™æ™ƒåŠ¨æ¨¡å‹ï¼Œé¢„æµ‹æœªæ¥ä¸€æ®µæ—¶é—´å†…çš„ç³»ç»ŸçŠ¶æ€ï¼Œå¹¶ä¼˜åŒ–æ§åˆ¶è¾“å…¥ã€‚DRLç­–ç•¥ç½‘ç»œåˆ™æ ¹æ®å½“å‰ç³»ç»ŸçŠ¶æ€ï¼Œè¾“å‡ºMPCæ§åˆ¶å™¨çš„å‚è€ƒè½¨è¿¹ã€‚DRLç­–ç•¥ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹ç”±MPCæ§åˆ¶å™¨æä¾›å¥–åŠ±ä¿¡å·ï¼Œå¥–åŠ±ä¿¡å·çš„è®¾è®¡æ—¨åœ¨é¼“åŠ±å«æ˜Ÿå¿«é€Ÿã€å‡†ç¡®åœ°å®Œæˆå¯¹æ¥ä»»åŠ¡ï¼Œå¹¶æŠ‘åˆ¶ç‡ƒæ–™æ™ƒåŠ¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†MPCçš„é¢„æµ‹èƒ½åŠ›ä¸DRLçš„å­¦ä¹ èƒ½åŠ›ç›¸ç»“åˆï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„æ§åˆ¶æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„DRLæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¿«åœ°å­¦ä¹ åˆ°æœ€ä¼˜ç­–ç•¥ï¼Œå¹¶å…·æœ‰æ›´å¥½çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é’ˆå¯¹ç‡ƒæ–™æ™ƒåŠ¨é—®é¢˜ï¼Œè®¾è®¡äº†ç‰¹å®šçš„å¥–åŠ±å‡½æ•°ï¼Œä»¥é¼“åŠ±æ§åˆ¶å™¨æŠ‘åˆ¶ç‡ƒæ–™æ™ƒåŠ¨ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡é‡‡ç”¨äº†ä¸¤ç§DRLç®—æ³•ï¼šè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰å’Œè½¯æ¼”å‘˜-è¯„è®ºå®¶ï¼ˆSACï¼‰ã€‚MPCæ§åˆ¶å™¨é‡‡ç”¨äº†çº¿æ€§æ—¶å˜MPCï¼ˆLTV-MPCï¼‰ï¼Œå…¶é¢„æµ‹æ¨¡å‹åŸºäºå«æ˜Ÿçš„çº¿æ€§åŒ–åŠ¨åŠ›å­¦æ¨¡å‹å’Œç‡ƒæ–™æ™ƒåŠ¨æ¨¡å‹ã€‚å¥–åŠ±å‡½æ•°çš„è®¾è®¡åŒ…æ‹¬å¯¹æ¥ç²¾åº¦ã€å¯¹æ¥é€Ÿåº¦ã€ç‡ƒæ–™æ¶ˆè€—å’Œç‡ƒæ–™æ™ƒåŠ¨æŠ‘åˆ¶ç­‰å¤šä¸ªæ–¹é¢ã€‚ç½‘ç»œç»“æ„æ–¹é¢ï¼Œä½¿ç”¨äº†å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ä½œä¸ºç­–ç•¥ç½‘ç»œå’Œä»·å€¼ç½‘ç»œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡ä»¿çœŸå®éªŒéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSAC-MPCæ–¹æ³•åœ¨å¯¹æ¥ç²¾åº¦ã€æˆåŠŸç‡å’Œæ§åˆ¶åŠ›æ–¹é¢å‡ä¼˜äºå•ç‹¬çš„RLå’ŒPPO-MPCæ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼ŒSAC-MPCæ–¹æ³•èƒ½å¤Ÿå®ç°æ›´é«˜çš„å¯¹æ¥æˆåŠŸç‡ï¼Œå¹¶æ˜¾è‘—é™ä½æ§åˆ¶æ‰€éœ€çš„ç‡ƒæ–™æ¶ˆè€—ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜èƒ½å¤Ÿæœ‰æ•ˆæŠ‘åˆ¶ç‡ƒæ–™æ™ƒåŠ¨ï¼Œæé«˜ç³»ç»Ÿçš„ç¨³å®šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåœ¨è½¨æœåŠ¡ã€åœ¨è½¨åŠ æ²¹ã€ç©ºé—´ç¢ç‰‡æ¸…é™¤ç­‰ä»»åŠ¡ã€‚é€šè¿‡æé«˜å«æ˜Ÿå¯¹æ¥çš„è‡ªä¸»æ€§å’Œé²æ£’æ€§ï¼Œé™ä½å¯¹åœ°é¢æ§åˆ¶çš„ä¾èµ–ï¼Œä»è€Œé™ä½ä»»åŠ¡æˆæœ¬ï¼Œæé«˜ä»»åŠ¡æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ¨å¹¿åˆ°å…¶ä»–å…·æœ‰å¤æ‚åŠ¨åŠ›å­¦ç‰¹æ€§çš„ç©ºé—´æœºå™¨äººæ§åˆ¶é—®é¢˜ï¼Œä¾‹å¦‚ç©ºé—´æœºæ¢°è‡‚æ“ä½œç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents an integrated Reinforcement Learning (RL) and Model Predictive Control (MPC) framework for autonomous satellite docking with a partially filled fuel tank. Traditional docking control faces challenges due to fuel sloshing in microgravity, which induces unpredictable forces affecting stability. To address this, we integrate Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC) RL algorithms with MPC, leveraging MPC's predictive capabilities to accelerate RL training and improve control robustness. The proposed approach is validated through Zero-G Lab of SnT experiments for planar stabilization and high-fidelity numerical simulations for 6-DOF docking with fuel sloshing dynamics. Simulation results demonstrate that SAC-MPC achieves superior docking accuracy, higher success rates, and lower control effort, outperforming standalone RL and PPO-MPC methods. This study advances fuel-efficient and disturbance-resilient satellite docking, enhancing the feasibility of on-orbit refueling and servicing missions.

