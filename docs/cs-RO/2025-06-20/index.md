---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-06-20
---

# cs.ROï¼ˆ2025-06-20ï¼‰

ğŸ“Š å…± **15** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (10 ğŸ”—2)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (10 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250617198v1-dex1b-learning-with-1b-demonstrations-for-dexterous-manipulation.html">Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation</a></td>
  <td>æå‡ºDex1Bä»¥è§£å†³å¤§è§„æ¨¡æ‰‹éƒ¨çµå·§æ“ä½œç¤ºèŒƒç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous hand</span> <span class="paper-tag">dexterous manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17198v1" data-paper-url="./papers/250617198v1-dex1b-learning-with-1b-demonstrations-for-dexterous-manipulation.html" onclick="toggleFavorite(this, '2506.17198v1', 'Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250617110v1-monocular-one-shot-metric-depth-alignment-for-rgb-based-robot-graspi.html">Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping</a></td>
  <td>æå‡ºå•ç›®ä¸€æ¬¡æ€§åº¦é‡æ·±åº¦å¯¹é½æ–¹æ³•ä»¥è§£å†³æœºå™¨äººæŠ“å–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">depth estimation</span> <span class="paper-tag">monocular depth</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17110v1" data-paper-url="./papers/250617110v1-monocular-one-shot-metric-depth-alignment-for-rgb-based-robot-graspi.html" onclick="toggleFavorite(this, '2506.17110v1', 'Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250617184v1-judo-a-user-friendly-open-source-package-for-sampling-based-model-pr.html">Judo: A User-Friendly Open-Source Package for Sampling-Based Model Predictive Control</a></td>
  <td>æå‡ºJudoä»¥è§£å†³é‡‡æ ·åŸºç¡€æ¨¡å‹é¢„æµ‹æ§åˆ¶å·¥å…·ç¼ºä¹çš„é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">MPC</span> <span class="paper-tag">model predictive control</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17184v1" data-paper-url="./papers/250617184v1-judo-a-user-friendly-open-source-package-for-sampling-based-model-pr.html" onclick="toggleFavorite(this, '2506.17184v1', 'Judo: A User-Friendly Open-Source Package for Sampling-Based Model Predictive Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250622473v1-unsupervised-discovery-of-behavioral-primitives-from-sensorimotor-dy.html">Unsupervised Discovery of Behavioral Primitives from Sensorimotor Dynamic Functional Connectivity</a></td>
  <td>æå‡ºæ— ç›‘ç£å­¦ä¹ æ¡†æ¶ä»¥å‘ç°æœºå™¨äººè¡Œä¸ºåŸè¯­</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.22473v1" data-paper-url="./papers/250622473v1-unsupervised-discovery-of-behavioral-primitives-from-sensorimotor-dy.html" onclick="toggleFavorite(this, '2506.22473v1', 'Unsupervised Discovery of Behavioral Primitives from Sensorimotor Dynamic Functional Connectivity')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250617458v1-kinematic-model-optimization-via-differentiable-contact-manifold-for.html">Kinematic Model Optimization via Differentiable Contact Manifold for In-Space Manipulation</a></td>
  <td>æå‡ºåŸºäºå¯å¾®æ¥è§¦æµå½¢çš„è¿åŠ¨å­¦æ¨¡å‹ä¼˜åŒ–ä»¥è§£å†³å¤ªç©ºæ“ä½œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17458v1" data-paper-url="./papers/250617458v1-kinematic-model-optimization-via-differentiable-contact-manifold-for.html" onclick="toggleFavorite(this, '2506.17458v1', 'Kinematic Model Optimization via Differentiable Contact Manifold for In-Space Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250616685v4-compliant-residual-dagger-improving-real-world-contact-rich-manipula.html">Compliant Residual DAgger: Improving Real-World Contact-Rich Manipulation with Human Corrections</a></td>
  <td>æå‡ºCompliant Residual DAggerä»¥è§£å†³çœŸå®ç¯å¢ƒä¸­æ¥è§¦ä¸°å¯Œçš„æ“ä½œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.16685v4" data-paper-url="./papers/250616685v4-compliant-residual-dagger-improving-real-world-contact-rich-manipula.html" onclick="toggleFavorite(this, '2506.16685v4', 'Compliant Residual DAgger: Improving Real-World Contact-Rich Manipulation with Human Corrections')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250617486v2-distilling-on-device-language-models-for-robot-planning-with-minimal.html">Distilling On-device Language Models for Robot Planning with Minimal Human Intervention</a></td>
  <td>æå‡ºPRISMæ¡†æ¶ä»¥å®ç°æœºå™¨äººè§„åˆ’çš„æœ¬åœ°è¯­è¨€æ¨¡å‹è’¸é¦</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17486v2" data-paper-url="./papers/250617486v2-distilling-on-device-language-models-for-robot-planning-with-minimal.html" onclick="toggleFavorite(this, '2506.17486v2', 'Distilling On-device Language Models for Robot Planning with Minimal Human Intervention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250616986v3-learning-accurate-whole-body-throwing-with-high-frequency-residual-p.html">Learning Accurate Whole-body Throwing with High-frequency Residual Policy and Pullback Tube Acceleration</a></td>
  <td>æå‡ºé«˜é¢‘æ®‹å·®ç­–ç•¥ä¸æ‹‰å›ç®¡åŠ é€Ÿçš„æ•´ä½“æŠ•æ·æ§åˆ¶æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">whole-body manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.16986v3" data-paper-url="./papers/250616986v3-learning-accurate-whole-body-throwing-with-high-frequency-residual-p.html" onclick="toggleFavorite(this, '2506.16986v3', 'Learning Accurate Whole-body Throwing with High-frequency Residual Policy and Pullback Tube Acceleration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250616710v3-experimental-setup-and-software-pipeline-to-evaluate-optimization-ba.html">Experimental Setup and Software Pipeline to Evaluate Optimization based Autonomous Multi-Robot Search Algorithms</a></td>
  <td>æå‡ºå®éªŒå¹³å°ä¸è½¯ä»¶ç®¡é“ä»¥è¯„ä¼°å¤šæœºå™¨äººæœç´¢ç®—æ³•</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span> <span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.16710v3" data-paper-url="./papers/250616710v3-experimental-setup-and-software-pipeline-to-evaluate-optimization-ba.html" onclick="toggleFavorite(this, '2506.16710v3', 'Experimental Setup and Software Pipeline to Evaluate Optimization based Autonomous Multi-Robot Search Algorithms')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250617488v3-online-adaptation-for-flying-quadrotors-in-tight-formations.html">Online Adaptation for Flying Quadrotors in Tight Formations</a></td>
  <td>æå‡ºL1 KNODE-DW MPCä»¥è§£å†³å››æ—‹ç¿¼ç´§å¯†ç¼–é˜Ÿé£è¡Œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">MPC</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17488v3" data-paper-url="./papers/250617488v3-online-adaptation-for-flying-quadrotors-in-tight-formations.html" onclick="toggleFavorite(this, '2506.17488v3', 'Online Adaptation for Flying Quadrotors in Tight Formations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>11</td>
  <td><a href="./papers/250617462v2-general-purpose-robotic-navigation-via-lvlm-orchestrated-perception-.html">General-Purpose Robotic Navigation via LVLM-Orchestrated Perception, Reasoning, and Acting</a></td>
  <td>æå‡ºARNAæ¡†æ¶ä»¥è§£å†³æœªçŸ¥ç¯å¢ƒä¸­çš„é€šç”¨å¯¼èˆªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17462v2" data-paper-url="./papers/250617462v2-general-purpose-robotic-navigation-via-lvlm-orchestrated-perception-.html" onclick="toggleFavorite(this, '2506.17462v2', 'General-Purpose Robotic Navigation via LVLM-Orchestrated Perception, Reasoning, and Acting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250617378v1-a-workflow-for-generating-synthetic-lidar-datasets-in-simulation-env.html">A workflow for generating synthetic LiDAR datasets in simulation environments</a></td>
  <td>æå‡ºåˆæˆLiDARæ•°æ®é›†ç”Ÿæˆå·¥ä½œæµä»¥æ”¯æŒè‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17378v1" data-paper-url="./papers/250617378v1-a-workflow-for-generating-synthetic-lidar-datasets-in-simulation-env.html" onclick="toggleFavorite(this, '2506.17378v1', 'A workflow for generating synthetic LiDAR datasets in simulation environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250616677v1-pptp-performance-guided-physiological-signal-based-trust-prediction-.html">PPTP: Performance-Guided Physiological Signal-Based Trust Prediction in Human-Robot Collaboration</a></td>
  <td>æå‡ºPPTPæ¡†æ¶ä»¥è§£å†³äººæœºåä½œä¸­çš„ä¿¡ä»»é¢„æµ‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.16677v1" data-paper-url="./papers/250616677v1-pptp-performance-guided-physiological-signal-based-trust-prediction-.html" onclick="toggleFavorite(this, '2506.16677v1', 'PPTP: Performance-Guided Physiological Signal-Based Trust Prediction in Human-Robot Collaboration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>14</td>
  <td><a href="./papers/250617516v1-ease-embodied-active-event-perception-via-self-supervised-energy-min.html">EASE: Embodied Active Event Perception via Self-Supervised Energy Minimization</a></td>
  <td>æå‡ºEASEæ¡†æ¶ä»¥è§£å†³åŠ¨æ€äº‹ä»¶æ„ŸçŸ¥é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span> <span class="paper-tag">spatiotemporal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17516v1" data-paper-url="./papers/250617516v1-ease-embodied-active-event-perception-via-self-supervised-energy-min.html" onclick="toggleFavorite(this, '2506.17516v1', 'EASE: Embodied Active Event Perception via Self-Supervised Energy Minimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>15</td>
  <td><a href="./papers/250622472v1-optical-waveguide-based-spider-web-enables-resilient-impact-detectio.html">Optical Waveguide-based Spider Web Enables Resilient Impact Detection and Localization</a></td>
  <td>æå‡ºå…‰æ³¢å¯¼èœ˜è››ç½‘ä»¥è§£å†³å†²å‡»æ£€æµ‹ä¸å®šä½é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">PULSE</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.22472v1" data-paper-url="./papers/250622472v1-optical-waveguide-based-spider-web-enables-resilient-impact-detectio.html" onclick="toggleFavorite(this, '2506.22472v1', 'Optical Waveguide-based Spider Web Enables Resilient Impact Detection and Localization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)