---
layout: default
title: Distilling On-device Language Models for Robot Planning with Minimal Human Intervention
---

# Distilling On-device Language Models for Robot Planning with Minimal Human Intervention

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17486" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17486v2</a>
  <a href="https://arxiv.org/pdf/2506.17486.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17486v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17486v2', 'Distilling On-device Language Models for Robot Planning with Minimal Human Intervention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zachary Ravichandran, Ignacio Hounie, Fernando Cladera, Alejandro Ribeiro, George J. Pappas, Vijay Kumar

**åˆ†ç±»**: cs.RO, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20 (æ›´æ–°: 2025-10-06)

**å¤‡æ³¨**: Accepted to the Conference on Robot Learning (CoRL) 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://zacravichandran.github.io/PRISM)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPRISMæ¡†æ¶ä»¥å®ç°æœºå™¨äººè§„åˆ’çš„æœ¬åœ°è¯­è¨€æ¨¡å‹è’¸é¦**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `æœºå™¨äººè§„åˆ’` `æ¨¡å‹è’¸é¦` `è‡ªä¸»ç³»ç»Ÿ` `åˆæˆæ•°æ®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMé©±åŠ¨æœºå™¨äººä¾èµ–äº‘ç«¯æ¨¡å‹ï¼Œé™åˆ¶äº†åœ¨ä¸å¯é é€šä¿¡ç¯å¢ƒä¸­çš„åº”ç”¨ã€‚
2. PRISMæ¡†æ¶é€šè¿‡åˆæˆä»»åŠ¡å’Œç¯å¢ƒï¼Œè‡ªåŠ¨ä»LLMä¸­æå–è§„åˆ’ï¼Œè’¸é¦å‡ºå°å‹è¯­è¨€æ¨¡å‹ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒPRISMæ˜¾è‘—æå‡äº†Llama-3.2-3Bçš„æ€§èƒ½ï¼Œä»10-20%æå‡è‡³93%ä»¥ä¸Šï¼Œä¸”å…·æœ‰è‰¯å¥½çš„è·¨å¹³å°æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸ºæœºå™¨äººæä¾›äº†å¼ºå¤§çš„ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›å’Œè‡ªç„¶çš„äººæœºæ¥å£ã€‚ç„¶è€Œï¼Œå½“å‰çš„LLMé©±åŠ¨æœºå™¨äººé€šå¸¸ä¾èµ–äºäº‘ç«¯æ¨¡å‹ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨é€šä¿¡åŸºç¡€è®¾æ–½ä¸å¯é çš„ç¯å¢ƒä¸­çš„å¯ç”¨æ€§ï¼Œå¦‚æˆ·å¤–æˆ–å·¥ä¸šåœºæ™¯ã€‚æœ¬æ–‡æå‡ºäº†PRISMæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æœ€å°çš„äººç±»ç›‘ç£ï¼Œè’¸é¦å‡ºèƒ½å¤Ÿåœ¨è®¾å¤‡ä¸Šè¿è¡Œçš„å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰ä»¥è¿›è¡Œæœºå™¨äººè§„åˆ’ã€‚PRISMä»ç°æœ‰çš„LLMé©±åŠ¨è§„åˆ’å™¨å‡ºå‘ï¼Œè‡ªåŠ¨åˆæˆå¤šæ ·çš„ä»»åŠ¡å’Œç¯å¢ƒï¼Œä»LLMä¸­å¼•å‡ºè§„åˆ’ï¼Œå¹¶åˆ©ç”¨åˆæˆæ•°æ®é›†è’¸é¦å‡ºç´§å‡‘çš„SLMï¼Œä½œä¸ºæºæ¨¡å‹çš„æ›¿ä»£å“ã€‚æˆ‘ä»¬å°†PRISMåº”ç”¨äºä¸‰ç§LLMé©±åŠ¨çš„è§„åˆ’å™¨ï¼Œå¹¶å±•ç¤ºå…¶åœ¨æ€§èƒ½ä¸Šçš„æ˜¾è‘—æå‡ã€‚æ‰€æœ‰è½¯ä»¶ã€è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†å·²åœ¨https://zacravichandran.github.io/PRISMå‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰LLMé©±åŠ¨æœºå™¨äººåœ¨ä¸å¯é ç¯å¢ƒä¸­æ— æ³•ç‹¬ç«‹è¿è¡Œçš„é—®é¢˜ã€‚å½“å‰æ–¹æ³•ä¾èµ–äºäº‘ç«¯æ¨¡å‹ï¼Œå¯¼è‡´åœ¨æˆ·å¤–æˆ–å·¥ä¸šç¯å¢ƒä¸­åº”ç”¨å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPRISMæ¡†æ¶é€šè¿‡è‡ªåŠ¨åˆæˆå¤šæ ·çš„ä»»åŠ¡å’Œç¯å¢ƒï¼Œåˆ©ç”¨åˆæˆæ•°æ®é›†ä»å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æå–è§„åˆ’ï¼Œä»è€Œè’¸é¦å‡ºå°å‹è¯­è¨€æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨è®¾å¤‡ä¸Šç‹¬ç«‹è¿è¡Œã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPRISMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä»»åŠ¡åˆæˆæ¨¡å—ã€ç¯å¢ƒåˆæˆæ¨¡å—ã€è§„åˆ’æå–æ¨¡å—å’Œæ¨¡å‹è’¸é¦æ¨¡å—ã€‚é¦–å…ˆåˆæˆå¤šæ ·åŒ–çš„ä»»åŠ¡å’Œç¯å¢ƒï¼Œç„¶åä»LLMä¸­æå–è§„åˆ’ï¼Œæœ€ååˆ©ç”¨è¿™äº›æ•°æ®è¿›è¡Œæ¨¡å‹è’¸é¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šPRISMçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶èƒ½å¤Ÿåœ¨æ²¡æœ‰äººç±»å¹²é¢„çš„æƒ…å†µä¸‹ï¼Œè‡ªåŠ¨ç”Ÿæˆåˆæˆæ•°æ®å¹¶è¿›è¡Œæ¨¡å‹è’¸é¦ï¼Œè¿™ä¸ä¼ ç»Ÿçš„ä¾èµ–äººå·¥æ ‡æ³¨æ•°æ®çš„æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è’¸é¦è¿‡ç¨‹ä¸­ï¼ŒPRISMé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿è’¸é¦åçš„æ¨¡å‹åœ¨æ€§èƒ½ä¸Šæ¥è¿‘æºæ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒè®¡ç®—æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPRISMæ˜¾è‘—æå‡äº†Llama-3.2-3Bçš„æ€§èƒ½ï¼Œä»10-20%æå‡è‡³93%ä»¥ä¸Šï¼Œä¸”åœ¨ä¸åŒçš„æœºå™¨äººå¹³å°å’Œç¯å¢ƒä¸­å‡è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™ä¸€æˆæœè¡¨æ˜ï¼ŒPRISMèƒ½å¤Ÿæœ‰æ•ˆåœ°å°†å¤§å‹è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›è½¬ç§»åˆ°å°å‹æ¨¡å‹ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªä¸»æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–å’Œå®¶åº­åŠ©ç†ç­‰åœºæ™¯ã€‚é€šè¿‡å®ç°æœ¬åœ°è¯­è¨€æ¨¡å‹ï¼Œæœºå™¨äººèƒ½å¤Ÿåœ¨æ²¡æœ‰ç½‘ç»œè¿æ¥çš„æƒ…å†µä¸‹æ‰§è¡Œå¤æ‚ä»»åŠ¡ï¼Œæå‡äº†å…¶åœ¨å„ç§ç¯å¢ƒä¸­çš„é€‚ç”¨æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼ŒPRISMæ¡†æ¶å¯èƒ½æ¨åŠ¨æ›´å¤šæ™ºèƒ½è®¾å¤‡çš„ç‹¬ç«‹è¿è¡Œï¼Œå‡å°‘å¯¹äº‘è®¡ç®—èµ„æºçš„ä¾èµ–ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) provide robots with powerful contextual reasoning abilities and a natural human interface. Yet, current LLM-enabled robots typically depend on cloud-hosted models, limiting their usability in environments with unreliable communication infrastructure, such as outdoor or industrial settings. We present PRISM, a framework for distilling small language model (SLM)-enabled robot planners that run on-device with minimal human supervision. Starting from an existing LLM-enabled planner, PRISM automatically synthesizes diverse tasks and environments, elicits plans from the LLM, and uses this synthetic dataset to distill a compact SLM as a drop-in replacement of the source model. We apply PRISM to three LLM-enabled planners for mapping and exploration, manipulation, and household assistance, and we demonstrate that PRISM improves the performance of Llama-3.2-3B from 10-20% of GPT-4o's performance to over 93% - using only synthetic data. We further demonstrate that the distilled planners generalize across heterogeneous robotic platforms (ground and aerial) and diverse environments (indoor and outdoor). We release all software, trained models, and datasets at https://zacravichandran.github.io/PRISM.

