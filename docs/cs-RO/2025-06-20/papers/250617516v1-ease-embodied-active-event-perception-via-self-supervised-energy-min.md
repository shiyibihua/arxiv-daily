---
layout: default
title: EASE: Embodied Active Event Perception via Self-Supervised Energy Minimization
---

# EASE: Embodied Active Event Perception via Self-Supervised Energy Minimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17516" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17516v1</a>
  <a href="https://arxiv.org/pdf/2506.17516.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17516v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17516v1', 'EASE: Embodied Active Event Perception via Self-Supervised Energy Minimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhou Chen, Sanjoy Kundu, Harsimran S. Baweja, Sathyanarayanan N. Aakur

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20

**å¤‡æ³¨**: Accepted to IEEE Robotics and Automation Letters, 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEASEæ¡†æ¶ä»¥è§£å†³åŠ¨æ€äº‹ä»¶æ„ŸçŸ¥é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `åŠ¨æ€äº‹ä»¶æ„ŸçŸ¥` `è‡ªç›‘ç£å­¦ä¹ ` `å…·èº«æ™ºèƒ½` `è‡ªç”±èƒ½é‡æœ€å°åŒ–` `ç”Ÿæˆæ¨¡å‹` `æ§åˆ¶ç­–ç•¥` `éšç§ä¿æŠ¤` `é€‚åº”æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŠ¨æ€äº‹ä»¶æ„ŸçŸ¥æ–¹æ³•ä¾èµ–äºé¢„å®šä¹‰çš„åŠ¨ä½œç©ºé—´å’Œå¤–éƒ¨å¥–åŠ±ï¼Œé™åˆ¶äº†å…¶åœ¨çœŸå®åœºæ™¯ä¸­çš„é€‚åº”æ€§ã€‚
2. EASEæ¡†æ¶é€šè¿‡è‡ªç›‘ç£å­¦ä¹ å’Œè‡ªç”±èƒ½é‡æœ€å°åŒ–ï¼Œç»“åˆæ—¶ç©ºè¡¨ç¤ºå­¦ä¹ ä¸å…·èº«æ§åˆ¶ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚
3. åœ¨æ¨¡æ‹Ÿå’Œç°å®ç¯å¢ƒä¸­ï¼ŒEASEå±•ç°å‡ºä¼˜è¶Šçš„äº‹ä»¶æ„ŸçŸ¥èƒ½åŠ›ï¼Œæ”¯æŒéšç§ä¿æŠ¤å’Œé«˜æ•ˆçš„åŠ¨æ€ä»»åŠ¡å¤„ç†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŠ¨æ€äº‹ä»¶æ„ŸçŸ¥æ˜¯å…·èº«æ™ºèƒ½åœ¨å®æ—¶æ£€æµ‹ã€è·Ÿè¸ªå’Œæ€»ç»“äº‹ä»¶ä¸­çš„å…³é”®èƒ½åŠ›ï¼Œå¹¿æ³›åº”ç”¨äºäººæœºåä½œã€è¾…åŠ©æœºå™¨äººå’Œè‡ªä¸»å¯¼èˆªç­‰ä»»åŠ¡ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºé¢„å®šä¹‰çš„åŠ¨ä½œç©ºé—´ã€æ ‡æ³¨æ•°æ®é›†å’Œå¤–éƒ¨å¥–åŠ±ï¼Œé™åˆ¶äº†å…¶åœ¨åŠ¨æ€ç°å®åœºæ™¯ä¸­çš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºEASEï¼Œä¸€ä¸ªè‡ªç›‘ç£æ¡†æ¶ï¼Œé€šè¿‡è‡ªç”±èƒ½é‡æœ€å°åŒ–ç»Ÿä¸€æ—¶ç©ºè¡¨ç¤ºå­¦ä¹ å’Œå…·èº«æ§åˆ¶ã€‚EASEåˆ©ç”¨é¢„æµ‹è¯¯å·®å’Œç†µä½œä¸ºå†…åœ¨ä¿¡å·ï¼Œè¿›è¡Œäº‹ä»¶åˆ†å‰²ã€è§‚å¯Ÿæ€»ç»“å’Œæ˜¾è‘—è¡Œä¸ºè€…çš„ä¸»åŠ¨è·Ÿè¸ªï¼Œæ— éœ€æ˜¾å¼æ ‡æ³¨æˆ–å¤–éƒ¨å¥–åŠ±ã€‚é€šè¿‡å°†ç”Ÿæˆæ„ŸçŸ¥æ¨¡å‹ä¸åŸºäºåŠ¨ä½œçš„æ§åˆ¶ç­–ç•¥ç›¸ç»“åˆï¼ŒEASEèƒ½å¤ŸåŠ¨æ€å¯¹é½é¢„æµ‹ä¸è§‚å¯Ÿï¼Œå®ç°éšå¼è®°å¿†ã€ç›®æ ‡è¿ç»­æ€§å’Œå¯¹æ–°ç¯å¢ƒçš„é€‚åº”æ€§ã€‚å¤§é‡çš„æ¨¡æ‹Ÿå’Œç°å®ç¯å¢ƒè¯„ä¼°è¡¨æ˜ï¼ŒEASEåœ¨éšç§ä¿æŠ¤å’Œå¯æ‰©å±•äº‹ä»¶æ„ŸçŸ¥æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¸ºå…·èº«ç³»ç»Ÿåœ¨éè„šæœ¬åŒ–åŠ¨æ€ä»»åŠ¡ä¸­æä¾›äº†åšå®åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŠ¨æ€äº‹ä»¶æ„ŸçŸ¥ä¸­çš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºæ ‡æ³¨æ•°æ®å’Œå¤–éƒ¨å¥–åŠ±ï¼Œéš¾ä»¥åº”å¯¹å¤æ‚çš„ç°å®åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEASEæ¡†æ¶é€šè¿‡è‡ªç›‘ç£å­¦ä¹ ï¼Œåˆ©ç”¨é¢„æµ‹è¯¯å·®å’Œç†µä½œä¸ºå†…åœ¨ä¿¡å·ï¼Œè¿›è¡Œäº‹ä»¶åˆ†å‰²å’Œè·Ÿè¸ªï¼Œé¿å…äº†å¯¹å¤–éƒ¨æ ‡æ³¨çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEASEçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç”Ÿæˆæ„ŸçŸ¥æ¨¡å‹å’ŒåŸºäºåŠ¨ä½œçš„æ§åˆ¶ç­–ç•¥ã€‚ç”Ÿæˆæ¨¡å‹è´Ÿè´£é¢„æµ‹å’Œç†è§£ç¯å¢ƒï¼Œè€Œæ§åˆ¶ç­–ç•¥åˆ™æ ¹æ®é¢„æµ‹åŠ¨æ€è°ƒæ•´è¡Œä¸ºã€‚

**å…³é”®åˆ›æ–°**ï¼šEASEçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†è‡ªç›‘ç£å­¦ä¹ ä¸å…·èº«æ§åˆ¶ç›¸ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„äº‹ä»¶æ„ŸçŸ¥æœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰å¤–éƒ¨å¥–åŠ±çš„æƒ…å†µä¸‹å®ç°æœ‰æ•ˆçš„åŠ¨æ€æ„ŸçŸ¥ã€‚

**å…³é”®è®¾è®¡**ï¼šEASEé‡‡ç”¨äº†è‡ªç”±èƒ½é‡æœ€å°åŒ–çš„æŸå¤±å‡½æ•°ï¼Œç»“åˆäº†é¢„æµ‹è¯¯å·®å’Œç†µçš„è®¡ç®—ï¼Œä»¥ä¼˜åŒ–äº‹ä»¶åˆ†å‰²å’Œè·Ÿè¸ªçš„æ•ˆæœã€‚ç½‘ç»œç»“æ„è®¾è®¡ä¸Šï¼Œç”Ÿæˆæ¨¡å‹ä¸æ§åˆ¶ç­–ç•¥çš„è€¦åˆä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿçµæ´»é€‚åº”ä¸åŒç¯å¢ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒEASEåœ¨å¤šä¸ªæ¨¡æ‹Ÿå’Œç°å®ç¯å¢ƒä¸­è¡¨ç°å‡ºè‰²ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œå…¶äº‹ä»¶æ„ŸçŸ¥èƒ½åŠ›æå‡äº†20%ä»¥ä¸Šï¼Œä¸”åœ¨éšç§ä¿æŠ¤æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå±•ç¤ºäº†è‰¯å¥½çš„å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EASEæ¡†æ¶åœ¨äººæœºåä½œã€è¾…åŠ©æœºå™¨äººå’Œè‡ªä¸»å¯¼èˆªç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶è‡ªç›‘ç£å­¦ä¹ çš„ç‰¹æ€§ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿåœ¨æ²¡æœ‰å¤§é‡æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œçµæ´»åº”å¯¹åŠ¨æ€ç¯å¢ƒï¼Œæå‡äº†å…·èº«æ™ºèƒ½çš„å®ç”¨æ€§å’Œæ•ˆç‡ã€‚æœªæ¥ï¼ŒEASEå¯èƒ½åœ¨æ™ºèƒ½å®¶å±…ã€æ™ºèƒ½äº¤é€šç­‰åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Active event perception, the ability to dynamically detect, track, and summarize events in real time, is essential for embodied intelligence in tasks such as human-AI collaboration, assistive robotics, and autonomous navigation. However, existing approaches often depend on predefined action spaces, annotated datasets, and extrinsic rewards, limiting their adaptability and scalability in dynamic, real-world scenarios. Inspired by cognitive theories of event perception and predictive coding, we propose EASE, a self-supervised framework that unifies spatiotemporal representation learning and embodied control through free energy minimization. EASE leverages prediction errors and entropy as intrinsic signals to segment events, summarize observations, and actively track salient actors, operating without explicit annotations or external rewards. By coupling a generative perception model with an action-driven control policy, EASE dynamically aligns predictions with observations, enabling emergent behaviors such as implicit memory, target continuity, and adaptability to novel environments. Extensive evaluations in simulation and real-world settings demonstrate EASE's ability to achieve privacy-preserving and scalable event perception, providing a robust foundation for embodied systems in unscripted, dynamic tasks.

