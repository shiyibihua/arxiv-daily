---
layout: default
title: Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation
---

# Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17198" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17198v1</a>
  <a href="https://arxiv.org/pdf/2506.17198.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17198v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17198v1', 'Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jianglong Ye, Keyi Wang, Chengjing Yuan, Ruihan Yang, Yiquan Li, Jiyue Zhu, Yuzhe Qin, Xueyan Zou, Xiaolong Wang

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20

**å¤‡æ³¨**: Accepted to RSS 2025. Project page: https://jianglongye.com/dex1b

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDex1Bä»¥è§£å†³å¤§è§„æ¨¡æ‰‹éƒ¨çµå·§æ“ä½œç¤ºèŒƒç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `æ‰‹éƒ¨çµå·§æ“ä½œ` `ç”Ÿæˆæ¨¡å‹` `ç¤ºèŒƒæ•°æ®é›†` `å‡ ä½•çº¦æŸ` `æœºå™¨äººå®éªŒ` `å¤šæ ·æ€§å¢å¼º` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆå¤§è§„æ¨¡æ‰‹éƒ¨çµå·§æ“ä½œç¤ºèŒƒæ—¶é¢ä¸´æ•ˆç‡ä½å’Œå¤šæ ·æ€§ä¸è¶³çš„æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºDex1Bæ•°æ®é›†ï¼Œåˆ©ç”¨ç”Ÿæˆæ¨¡å‹ç»“åˆå‡ ä½•çº¦æŸå’Œå¤šæ ·æ€§æ¡ä»¶ï¼Œæå‡ç¤ºèŒƒç”Ÿæˆçš„è´¨é‡å’Œæ•°é‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDex1Båœ¨å¤šä¸ªä»¿çœŸåŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨çœŸå®æœºå™¨äººå®éªŒä¸­éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”Ÿæˆå¤§è§„æ¨¡çš„æ‰‹éƒ¨çµå·§æ“ä½œç¤ºèŒƒä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œè¿‘å¹´æ¥æå‡ºäº†å¤šç§æ–¹æ³•æ¥åº”å¯¹è¿™ä¸€é—®é¢˜ã€‚å…¶ä¸­ï¼Œç”Ÿæˆæ¨¡å‹ä½œä¸ºä¸€ç§æœ‰å‰æ™¯çš„èŒƒå¼ï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°åˆ›å»ºå¤šæ ·ä¸”ç‰©ç†ä¸Šåˆç†çš„ç¤ºèŒƒã€‚æœ¬æ–‡ä»‹ç»äº†Dex1Bï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡ç”Ÿæˆæ¨¡å‹äº§ç”Ÿçš„å¤§è§„æ¨¡ã€å¤šæ ·ä¸”é«˜è´¨é‡çš„ç¤ºèŒƒæ•°æ®é›†ï¼ŒåŒ…å«åäº¿ä¸ªç¤ºèŒƒï¼Œæ¶µç›–æŠ“å–å’Œå…³èŠ‚è¿åŠ¨ä¸¤ä¸ªåŸºæœ¬ä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§é›†æˆå‡ ä½•çº¦æŸçš„ç”Ÿæˆæ¨¡å‹ï¼Œä»¥æé«˜å¯è¡Œæ€§ï¼Œå¹¶åº”ç”¨é¢å¤–æ¡ä»¶ä»¥å¢å¼ºå¤šæ ·æ€§ã€‚é€šè¿‡åœ¨æ—¢æœ‰å’Œæ–°å¼•å…¥çš„ä»¿çœŸåŸºå‡†ä¸ŠéªŒè¯ï¼Œè¯¥æ¨¡å‹æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡çœŸå®ä¸–ç•Œçš„æœºå™¨äººå®éªŒå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”Ÿæˆå¤§è§„æ¨¡æ‰‹éƒ¨çµå·§æ“ä½œç¤ºèŒƒçš„éš¾é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ç¤ºèŒƒçš„å¤šæ ·æ€§å’Œç‰©ç†åˆç†æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆå‡ ä½•çº¦æŸä»¥æé«˜ç”Ÿæˆç¤ºèŒƒçš„å¯è¡Œæ€§ï¼Œå¹¶å¼•å…¥é¢å¤–æ¡ä»¶ä»¥å¢å¼ºç¤ºèŒƒçš„å¤šæ ·æ€§ï¼Œä»è€Œå®ç°é«˜è´¨é‡çš„ç¤ºèŒƒç”Ÿæˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®ç”Ÿæˆæ¨¡å—ã€å‡ ä½•çº¦æŸæ¨¡å—å’Œå¤šæ ·æ€§å¢å¼ºæ¨¡å—ã€‚æ•°æ®ç”Ÿæˆæ¨¡å—è´Ÿè´£ç”Ÿæˆåˆæ­¥ç¤ºèŒƒï¼Œå‡ ä½•çº¦æŸæ¨¡å—ç¡®ä¿ç¤ºèŒƒçš„ç‰©ç†åˆç†æ€§ï¼Œè€Œå¤šæ ·æ€§å¢å¼ºæ¨¡å—åˆ™é€šè¿‡æ¡ä»¶ç”ŸæˆæŠ€æœ¯æå‡ç¤ºèŒƒçš„å¤šæ ·æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†å‡ ä½•çº¦æŸä¸ç”Ÿæˆæ¨¡å‹ç›¸ç»“åˆï¼Œè¿™ä¸€è®¾è®¡ä½¿å¾—ç”Ÿæˆçš„ç¤ºèŒƒä¸ä»…å¤šæ ·åŒ–ä¸”ç¬¦åˆç‰©ç†è§„å¾‹ï¼Œæ˜¾è‘—åŒºåˆ«äºä¼ ç»Ÿç”Ÿæˆæ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡ç”Ÿæˆç¤ºèŒƒçš„è´¨é‡ä¸å¤šæ ·æ€§ï¼Œå¹¶é‡‡ç”¨äº†æ·±åº¦ç¥ç»ç½‘ç»œæ¶æ„æ¥å®ç°å¤æ‚çš„ç”Ÿæˆä»»åŠ¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDex1Båœ¨å¤šä¸ªä»¿çœŸåŸºå‡†ä¸Šæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°XX%ï¼Œå¹¶åœ¨çœŸå®æœºå™¨äººå®éªŒä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ï¼ŒéªŒè¯äº†å…¶å®é™…åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæŠ“å–ã€è‡ªåŠ¨åŒ–è£…é…å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æä¾›é«˜è´¨é‡çš„ç¤ºèŒƒæ•°æ®ï¼ŒDex1Bå¯ä»¥å¸®åŠ©æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œèƒ½åŠ›ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generating large-scale demonstrations for dexterous hand manipulation remains challenging, and several approaches have been proposed in recent years to address this. Among them, generative models have emerged as a promising paradigm, enabling the efficient creation of diverse and physically plausible demonstrations. In this paper, we introduce Dex1B, a large-scale, diverse, and high-quality demonstration dataset produced with generative models. The dataset contains one billion demonstrations for two fundamental tasks: grasping and articulation. To construct it, we propose a generative model that integrates geometric constraints to improve feasibility and applies additional conditions to enhance diversity. We validate the model on both established and newly introduced simulation benchmarks, where it significantly outperforms prior state-of-the-art methods. Furthermore, we demonstrate its effectiveness and robustness through real-world robot experiments. Our project page is at https://jianglongye.com/dex1b

