---
layout: default
title: Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping
---

# Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17110" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17110v1</a>
  <a href="https://arxiv.org/pdf/2506.17110.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17110v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17110v1', 'Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Teng Guo, Baichuan Huang, Jingjin Yu

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20

**å¤‡æ³¨**: Accepted to IROS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå•ç›®ä¸€æ¬¡æ€§åº¦é‡æ·±åº¦å¯¹é½æ–¹æ³•ä»¥è§£å†³æœºå™¨äººæŠ“å–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å•ç›®æ·±åº¦ä¼°è®¡` `æœºå™¨äººæŠ“å–` `6Då§¿æ€ä¼°è®¡` `æ·±åº¦å¯¹é½` `é€æ˜ç‰©ä½“å¤„ç†` `æœºå™¨å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„6Då§¿æ€ä¼°è®¡æ–¹æ³•ä¾èµ–æ·±åº¦ä¼ æ„Ÿå™¨ï¼Œæˆæœ¬é«˜ä¸”æ— æ³•å¤„ç†é€æ˜ç‰©ä½“ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºçš„MOMAæ¡†æ¶é€šè¿‡ä¸€æ¬¡æ€§é€‚åº”MDEMæŠ€æœ¯ï¼Œä»å•å¼ RGBå›¾åƒä¸­æ¢å¤åº¦é‡æ·±åº¦ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•çš„å±€é™ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMOMAåœ¨å¤šç§ä»»åŠ¡ä¸­å®ç°äº†é«˜æˆåŠŸç‡ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‡†ç¡®çš„6Dç‰©ä½“å§¿æ€ä¼°è®¡æ˜¯æˆåŠŸå®Œæˆæœºå™¨äººæŠ“å–å’ŒéæŠ“å–æ“ä½œçš„å‰æã€‚ç›®å‰ï¼Œæœºå™¨äººæ“ä½œçš„6Då§¿æ€ä¼°è®¡é€šå¸¸ä¾èµ–äºæ·±åº¦ä¼ æ„Ÿå™¨ï¼Œè¿™äº›ä¼ æ„Ÿå™¨æˆæœ¬é«˜ã€è¾“å‡ºå™ªå£°å¤§ï¼Œå¹¶ä¸”æ— æ³•å¤„ç†é€æ˜ç‰©ä½“ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶â€”â€”å•ç›®ä¸€æ¬¡æ€§åº¦é‡æ·±åº¦å¯¹é½ï¼ˆMOMAï¼‰ï¼Œé€šè¿‡ä¸€æ¬¡æ€§é€‚åº”åŸºäºå•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹ï¼ˆMDEMï¼‰æŠ€æœ¯ï¼Œä»å•å¼ RGBå›¾åƒä¸­æ¢å¤åº¦é‡æ·±åº¦ã€‚MOMAåœ¨ç›¸æœºæ ‡å®šè¿‡ç¨‹ä¸­æ‰§è¡Œå°ºåº¦-æ—‹è½¬-å¹³ç§»å¯¹é½ï¼Œå€ŸåŠ©ç¨€ç–çš„çœŸå®æ·±åº¦ç‚¹æŒ‡å¯¼ï¼Œä»è€Œå®ç°å‡†ç¡®çš„æ·±åº¦ä¼°è®¡ï¼Œè€Œæ— éœ€åœ¨æµ‹è¯•ç¯å¢ƒä¸­è¿›è¡Œé¢å¤–çš„æ•°æ®æ”¶é›†æˆ–æ¨¡å‹é‡è®­ç»ƒã€‚MOMAæ”¯æŒåœ¨é€æ˜ç‰©ä½“ä¸Šå¾®è°ƒMDEMï¼Œå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚å®é™…å®éªŒè¡¨æ˜ï¼ŒMOMAåœ¨æ¡Œé¢åŒæŒ‡æŠ“å–å’ŒåŸºäºå¸åŠ›çš„ç‰©å“æ‹¾å–ä»»åŠ¡ä¸­å–å¾—äº†é«˜æˆåŠŸç‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæŠ“å–ä»»åŠ¡ä¸­6Dç‰©ä½“å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºæ·±åº¦ä¼ æ„Ÿå™¨ï¼Œå­˜åœ¨æˆæœ¬é«˜ã€è¾“å‡ºå™ªå£°å¤§åŠæ— æ³•å¤„ç†é€æ˜ç‰©ä½“ç­‰ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMOMAæ¡†æ¶é€šè¿‡ä¸€æ¬¡æ€§é€‚åº”MDEMæŠ€æœ¯ï¼Œä»å•å¼ RGBå›¾åƒä¸­æ¢å¤åº¦é‡æ·±åº¦ï¼Œåˆ©ç”¨ç¨€ç–çš„çœŸå®æ·±åº¦ç‚¹è¿›è¡Œç›¸æœºæ ‡å®šï¼Œæ‰§è¡Œå°ºåº¦ã€æ—‹è½¬å’Œä½ç§»å¯¹é½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMOMAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥ã€ç›¸æœºæ ‡å®šã€æ·±åº¦ä¼°è®¡å’Œè¾“å‡ºé˜¶æ®µã€‚é¦–å…ˆè¾“å…¥RGBå›¾åƒï¼Œç„¶åé€šè¿‡æ ‡å®šæ¨¡å—è¿›è¡Œå°ºåº¦-æ—‹è½¬-å¹³ç§»å¯¹é½ï¼Œæœ€åè¾“å‡ºå‡†ç¡®çš„åº¦é‡æ·±åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šMOMAçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ä¸€æ¬¡æ€§é€‚åº”èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¸éœ€è¦é¢å¤–æ•°æ®æ”¶é›†æˆ–æ¨¡å‹é‡è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œç›´æ¥ä»RGBå›¾åƒä¸­æ¢å¤åº¦é‡æ·±åº¦ï¼Œæ˜¾è‘—æå‡äº†æ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒMOMAé‡‡ç”¨äº†ç¨€ç–çœŸå®æ·±åº¦ç‚¹ä½œä¸ºæŒ‡å¯¼ï¼Œä¼˜åŒ–äº†ç›¸æœºæ ‡å®šè¿‡ç¨‹ï¼Œå¹¶é€šè¿‡å¾®è°ƒMDEMæ¥é€‚åº”é€æ˜ç‰©ä½“çš„æŠ“å–ï¼Œç¡®ä¿äº†åœ¨ä¸åŒåœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMOMAåœ¨æ¡Œé¢åŒæŒ‡æŠ“å–å’Œå¸åŠ›ç‰©å“æ‹¾å–ä»»åŠ¡ä¸­å®ç°äº†é«˜è¾¾90%çš„æˆåŠŸç‡ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æå‡äº†çº¦20%çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨æœºå™¨äººæŠ“å–ã€ç‰©å“æ‹¾å–å’Œè‡ªåŠ¨åŒ–ä»“å‚¨ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜6Dç‰©ä½“å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ï¼ŒMOMAèƒ½å¤Ÿæ˜¾è‘—æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œèƒ½åŠ›ï¼Œæ¨åŠ¨æ™ºèƒ½åˆ¶é€ å’ŒæœåŠ¡æœºå™¨äººæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate 6D object pose estimation is a prerequisite for successfully completing robotic prehensile and non-prehensile manipulation tasks. At present, 6D pose estimation for robotic manipulation generally relies on depth sensors based on, e.g., structured light, time-of-flight, and stereo-vision, which can be expensive, produce noisy output (as compared with RGB cameras), and fail to handle transparent objects. On the other hand, state-of-the-art monocular depth estimation models (MDEMs) provide only affine-invariant depths up to an unknown scale and shift. Metric MDEMs achieve some successful zero-shot results on public datasets, but fail to generalize. We propose a novel framework, Monocular One-shot Metric-depth Alignment (MOMA), to recover metric depth from a single RGB image, through a one-shot adaptation building on MDEM techniques. MOMA performs scale-rotation-shift alignments during camera calibration, guided by sparse ground-truth depth points, enabling accurate depth estimation without additional data collection or model retraining on the testing setup. MOMA supports fine-tuning the MDEM on transparent objects, demonstrating strong generalization capabilities. Real-world experiments on tabletop 2-finger grasping and suction-based bin-picking applications show MOMA achieves high success rates in diverse tasks, confirming its effectiveness.

