---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-08-15
---

# cs.ROï¼ˆ2025-08-15ï¼‰

ğŸ“Š å…± **14** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (9)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250811275v1-learning-differentiable-reachability-maps-for-optimization-based-hum.html">Learning Differentiable Reachability Maps for Optimization-based Humanoid Motion Generation</a></td>
  <td>æå‡ºå¯å¾®åˆ†å¯è¾¾æ€§å›¾ä»¥ä¼˜åŒ–ç±»äººæœºå™¨äººè¿åŠ¨ç”Ÿæˆ</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11275v1" data-paper-url="./papers/250811275v1-learning-differentiable-reachability-maps-for-optimization-based-hum.html" onclick="toggleFavorite(this, '2508.11275v1', 'Learning Differentiable Reachability Maps for Optimization-based Humanoid Motion Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250811802v1-anticipatory-and-adaptive-footstep-streaming-for-teleoperated-bipeda.html">Anticipatory and Adaptive Footstep Streaming for Teleoperated Bipedal Robots</a></td>
  <td>æå‡ºå®æ—¶æ­¥æ€ä¼ è¾“æ–¹æ³•ä»¥è§£å†³é¥æ“ä½œåŒè¶³æœºå™¨äººåŒæ­¥é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">bipedal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11802v1" data-paper-url="./papers/250811802v1-anticipatory-and-adaptive-footstep-streaming-for-teleoperated-bipeda.html" onclick="toggleFavorite(this, '2508.11802v1', 'Anticipatory and Adaptive Footstep Streaming for Teleoperated Bipedal Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250811520v1-a-comparative-study-of-floating-base-space-parameterizations-for-agi.html">A Comparative Study of Floating-Base Space Parameterizations for Agile Whole-Body Motion Planning</a></td>
  <td>æå‡ºæµ®åŠ¨åŸºç©ºé—´å‚æ•°åŒ–æ–¹æ³•ä»¥ä¼˜åŒ–çµæ´»å…¨èº«è¿åŠ¨è§„åˆ’</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">trajectory optimization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11520v1" data-paper-url="./papers/250811520v1-a-comparative-study-of-floating-base-space-parameterizations-for-agi.html" onclick="toggleFavorite(this, '2508.11520v1', 'A Comparative Study of Floating-Base Space Parameterizations for Agile Whole-Body Motion Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250811204v1-multi-group-equivariant-augmentation-for-reinforcement-learning-in-r.html">Multi-Group Equivariant Augmentation for Reinforcement Learning in Robot Manipulation</a></td>
  <td>æå‡ºå¤šç»„ç­‰å˜å¢å¼ºæ–¹æ³•ä»¥æå‡æœºå™¨äººæ“ä½œä¸­çš„é‡‡æ ·æ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">offline reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11204v1" data-paper-url="./papers/250811204v1-multi-group-equivariant-augmentation-for-reinforcement-learning-in-r.html" onclick="toggleFavorite(this, '2508.11204v1', 'Multi-Group Equivariant Augmentation for Reinforcement Learning in Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250811200v1-visuomotor-grasping-with-world-models-for-surgical-robots.html">Visuomotor Grasping with World Models for Surgical Robots</a></td>
  <td>æå‡ºGASv2ä»¥è§£å†³å¤–ç§‘æœºå™¨äººæŠ“å–ä¸­çš„è§†è§‰è¿åŠ¨å­¦ä¹ é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span> <span class="paper-tag">domain randomization</span> <span class="paper-tag">world model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11200v1" data-paper-url="./papers/250811200v1-visuomotor-grasping-with-world-models-for-surgical-robots.html" onclick="toggleFavorite(this, '2508.11200v1', 'Visuomotor Grasping with World Models for Surgical Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250811588v1-investigating-sensors-and-methods-in-grasp-state-classification-in-a.html">Investigating Sensors and Methods in Grasp State Classification in Agricultural Manipulation</a></td>
  <td>æå‡ºä¼ æ„Ÿå™¨ä¸æ–¹æ³•ä»¥è§£å†³å†œä¸šæ“ä½œä¸­çš„æŠ“å–çŠ¶æ€åˆ†ç±»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11588v1" data-paper-url="./papers/250811588v1-investigating-sensors-and-methods-in-grasp-state-classification-in-a.html" onclick="toggleFavorite(this, '2508.11588v1', 'Investigating Sensors and Methods in Grasp State Classification in Agricultural Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250811426v1-reachvox-clutter-free-reachability-visualization-for-robot-motion-pl.html">ReachVox: Clutter-free Reachability Visualization for Robot Motion Planning in Virtual Reality</a></td>
  <td>æå‡ºReachVoxä»¥è§£å†³æœºå™¨äººè¿åŠ¨è§„åˆ’ä¸­çš„å¯è¾¾æ€§å¯è§†åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11426v1" data-paper-url="./papers/250811426v1-reachvox-clutter-free-reachability-visualization-for-robot-motion-pl.html" onclick="toggleFavorite(this, '2508.11426v1', 'ReachVox: Clutter-free Reachability Visualization for Robot Motion Planning in Virtual Reality')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250811396v1-pedestrian-dead-reckoning-using-invariant-extended-kalman-filter.html">Pedestrian Dead Reckoning using Invariant Extended Kalman Filter</a></td>
  <td>æå‡ºä¸€ç§åŸºäºä¸å˜æ‰©å±•å¡å°”æ›¼æ»¤æ³¢çš„è¡Œäººæ­»ç®—æ–¹æ³•ä»¥è§£å†³GPSç¼ºå¤±é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">bipedal</span> <span class="paper-tag">biped</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11396v1" data-paper-url="./papers/250811396v1-pedestrian-dead-reckoning-using-invariant-extended-kalman-filter.html" onclick="toggleFavorite(this, '2508.11396v1', 'Pedestrian Dead Reckoning using Invariant Extended Kalman Filter')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250811503v2-sim2dust-mastering-dynamic-waypoint-tracking-on-granular-media.html">Sim2Dust: Mastering Dynamic Waypoint Tracking on Granular Media</a></td>
  <td>æå‡ºSim2Dustæ¡†æ¶ä»¥è§£å†³åŠ¨æ€èˆªç‚¹è·Ÿè¸ªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11503v2" data-paper-url="./papers/250811503v2-sim2dust-mastering-dynamic-waypoint-tracking-on-granular-media.html" onclick="toggleFavorite(this, '2508.11503v2', 'Sim2Dust: Mastering Dynamic Waypoint Tracking on Granular Media')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>10</td>
  <td><a href="./papers/250811759v2-using-natural-language-for-human-robot-collaboration-in-the-real-wor.html">Using Natural Language for Human-Robot Collaboration in the Real World</a></td>
  <td>æå‡ºè‡ªç„¶è¯­è¨€å¤„ç†æ–¹æ³•ä»¥æå‡äººæœºåä½œèƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11759v2" data-paper-url="./papers/250811759v2-using-natural-language-for-human-robot-collaboration-in-the-real-wor.html" onclick="toggleFavorite(this, '2508.11759v2', 'Using Natural Language for Human-Robot Collaboration in the Real World')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250811584v2-visual-perception-engine-fast-and-flexible-multi-head-inference-for-.html">Visual Perception Engine: Fast and Flexible Multi-Head Inference for Robotic Vision Tasks</a></td>
  <td>æå‡ºè§†è§‰æ„ŸçŸ¥å¼•æ“ä»¥è§£å†³æœºå™¨äººè§†è§‰ä»»åŠ¡ä¸­çš„è®¡ç®—å†—ä½™é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11584v2" data-paper-url="./papers/250811584v2-visual-perception-engine-fast-and-flexible-multi-head-inference-for-.html" onclick="toggleFavorite(this, '2508.11584v2', 'Visual Perception Engine: Fast and Flexible Multi-Head Inference for Robotic Vision Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250811485v2-i2nav-robot-a-large-scale-indoor-outdoor-robot-dataset-for-multi-sen.html">i2Nav-Robot: A Large-Scale Indoor-Outdoor Robot Dataset for Multi-Sensor Fusion Navigation and Mapping</a></td>
  <td>æå‡ºi2Nav-Robotæ•°æ®é›†ä»¥è§£å†³UGVå¯¼èˆªä¸æ˜ å°„çš„å¤šä¼ æ„Ÿå™¨èåˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">TAMP</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11485v2" data-paper-url="./papers/250811485v2-i2nav-robot-a-large-scale-indoor-outdoor-robot-dataset-for-multi-sen.html" onclick="toggleFavorite(this, '2508.11485v2', 'i2Nav-Robot: A Large-Scale Indoor-Outdoor Robot Dataset for Multi-Sensor Fusion Navigation and Mapping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/250811479v1-ovsegdt-segmenting-transformer-for-open-vocabulary-object-goal-navig.html">OVSegDT: Segmenting Transformer for Open-Vocabulary Object Goal Navigation</a></td>
  <td>æå‡ºOVSegDTä»¥è§£å†³å¼€æ”¾è¯æ±‡ç›®æ ‡å¯¼èˆªä¸­çš„æ³›åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">transformer policy</span> <span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11479v1" data-paper-url="./papers/250811479v1-ovsegdt-segmenting-transformer-for-open-vocabulary-object-goal-navig.html" onclick="toggleFavorite(this, '2508.11479v1', 'OVSegDT: Segmenting Transformer for Open-Vocabulary Object Goal Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250811537v1-multipark-multimodal-parking-transformer-with-next-segment-predictio.html">MultiPark: Multimodal Parking Transformer with Next-Segment Prediction</a></td>
  <td>æå‡ºMultiParkä»¥è§£å†³å¤æ‚åœè½¦è¡Œä¸ºçš„å¤šæ¨¡æ€é¢„æµ‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">imitation learning</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.11537v1" data-paper-url="./papers/250811537v1-multipark-multimodal-parking-transformer-with-next-segment-predictio.html" onclick="toggleFavorite(this, '2508.11537v1', 'MultiPark: Multimodal Parking Transformer with Next-Segment Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)