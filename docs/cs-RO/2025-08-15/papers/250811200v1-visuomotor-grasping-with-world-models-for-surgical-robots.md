---
layout: default
title: Visuomotor Grasping with World Models for Surgical Robots
---

# Visuomotor Grasping with World Models for Surgical Robots

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.11200" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.11200v1</a>
  <a href="https://arxiv.org/pdf/2508.11200.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.11200v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.11200v1', 'Visuomotor Grasping with World Models for Surgical Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hongbin Lin, Bin Li, Kwok Wai Samuel Au

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-15

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGASv2ä»¥è§£å†³å¤–ç§‘æœºå™¨äººæŠ“å–ä¸­çš„è§†è§‰è¿åŠ¨å­¦ä¹ é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æœºå™¨äººæŠ“å–` `è§†è§‰è¿åŠ¨å­¦ä¹ ` `å¤–ç§‘æœºå™¨äºº` `ä¸–ç•Œæ¨¡å‹` `æ··åˆæ§åˆ¶ç³»ç»Ÿ` `é¢†åŸŸéšæœºåŒ–` `è‡ªåŠ¨åŒ–æ‰‹æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¾èµ–äºç‰©ä½“å§¿æ€è·Ÿè¸ªå’Œæ‰‹å·¥ç‰¹å¾ï¼Œé™åˆ¶äº†å¯¹æ–°ç‰©ä½“çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚
2. æå‡ºGASv2æ¡†æ¶ï¼Œåˆ©ç”¨ä¸–ç•Œæ¨¡å‹å’Œå•ä¸€ç«‹ä½“ç›¸æœºè¿›è¡Œè§†è§‰è¿åŠ¨å­¦ä¹ ï¼Œè§£å†³æŠ“å–ä»»åŠ¡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGASv2åœ¨ä¸åŒå¤–ç§‘è®¾ç½®ä¸‹æˆåŠŸç‡è¾¾åˆ°65%ï¼Œå¹¶èƒ½é€‚åº”æœªè§ç‰©ä½“å’Œå¹²æ‰°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŠ“å–æ˜¯æœºå™¨äººè¾…åŠ©å¤–ç§‘æ‰‹æœ¯ä¸­çš„åŸºæœ¬ä»»åŠ¡ï¼Œè‡ªåŠ¨åŒ–æŠ“å–å¯ä»¥å‡è½»å¤–ç§‘åŒ»ç”Ÿçš„å·¥ä½œè´Ÿæ‹…ï¼Œæé«˜æ•ˆç‡ã€å®‰å…¨æ€§å’Œä¸€è‡´æ€§ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºæ˜¾å¼çš„ç‰©ä½“å§¿æ€è·Ÿè¸ªæˆ–æ‰‹å·¥è®¾è®¡çš„è§†è§‰ç‰¹å¾ï¼Œé™åˆ¶äº†å…¶å¯¹æ–°ç‰©ä½“çš„æ³›åŒ–èƒ½åŠ›å’Œå¯¹è§†è§‰å¹²æ‰°çš„é²æ£’æ€§ã€‚æœ¬æ–‡æå‡ºäº†GASv2ï¼Œä¸€ä¸ªåŸºäºä¸–ç•Œæ¨¡å‹çš„è§†è§‰è¿åŠ¨å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤–ç§‘åœºæ™¯ä¸­çš„æŠ“å–é—®é¢˜ã€‚GASv2é€šè¿‡å•ä¸€ç«‹ä½“ç›¸æœºå¯¹è¿›è¡Œè§†è§‰è§‚å¯Ÿï¼Œç»“åˆæ··åˆæ§åˆ¶ç³»ç»Ÿå®ç°å®‰å…¨æ‰§è¡Œã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ”¿ç­–åœ¨ä¸åŒè®¾ç½®ä¸‹çš„æˆåŠŸç‡è¾¾åˆ°65%ï¼Œå¹¶èƒ½é€‚åº”æœªè§ç‰©ä½“å’Œä¸åŒå¹²æ‰°ï¼Œå±•ç°å‡ºå¼ºå¤§çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯å¤–ç§‘æœºå™¨äººæŠ“å–ä»»åŠ¡ä¸­çš„è§†è§‰è¿åŠ¨å­¦ä¹ é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºç‰©ä½“å§¿æ€è·Ÿè¸ªå’Œæ‰‹å·¥ç‰¹å¾ï¼Œå¯¼è‡´åœ¨æ–°ç‰©ä½“å’Œè§†è§‰å¹²æ‰°ä¸‹çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGASv2æ¡†æ¶é€šè¿‡ä½¿ç”¨ä¸–ç•Œæ¨¡å‹å’Œå•ä¸€ç«‹ä½“ç›¸æœºï¼Œç®€åŒ–äº†è§†è§‰è§‚å¯Ÿè¿‡ç¨‹ï¼Œå¹¶ç»“åˆæ··åˆæ§åˆ¶ç³»ç»Ÿä»¥ç¡®ä¿æŠ“å–çš„å®‰å…¨æ€§å’Œç²¾ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGASv2çš„æ•´ä½“æ¶æ„åŒ…æ‹¬è§†è§‰æ„ŸçŸ¥æ¨¡å—ã€ä¸–ç•Œæ¨¡å‹æ„å»ºã€ç­–ç•¥è®­ç»ƒå’Œæ··åˆæ§åˆ¶ç³»ç»Ÿã€‚é¦–å…ˆï¼Œé€šè¿‡ç«‹ä½“ç›¸æœºè·å–è§†è§‰ä¿¡æ¯ï¼Œç„¶ååˆ©ç”¨ä¸–ç•Œæ¨¡å‹è¿›è¡Œç­–ç•¥è®­ç»ƒï¼Œæœ€ååœ¨å®é™…ç¯å¢ƒä¸­æ‰§è¡ŒæŠ“å–ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šGASv2çš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶èƒ½å¤Ÿåœ¨ä¸éœ€è¦é‡è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨å•ä¸€ç­–ç•¥å®ç°å¯¹å¤šæ ·åŒ–ã€æœªè§å¤–ç§‘ç‰©ä½“çš„æŠ“å–ã€‚è¿™ä¸€ç‰¹æ€§æ˜¾è‘—æé«˜äº†ç³»ç»Ÿçš„é€šç”¨æ€§å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨é¢†åŸŸéšæœºåŒ–æŠ€æœ¯ä»¥å®ç°ä»æ¨¡æ‹Ÿåˆ°ç°å®çš„è¿ç§»ã€‚æŸå¤±å‡½æ•°è®¾è®¡è€ƒè™‘äº†æŠ“å–æˆåŠŸç‡å’Œå®‰å…¨æ€§ï¼Œç½‘ç»œç»“æ„åˆ™åŸºäºæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œä¼˜åŒ–äº†è§†è§‰ç‰¹å¾æå–å’Œå†³ç­–è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

GASv2åœ¨ä¸åŒçš„å¤–ç§‘è®¾ç½®ä¸‹å®ç°äº†65%çš„æˆåŠŸç‡ï¼Œå±•ç¤ºäº†å…¶åœ¨æœªè§ç‰©ä½“å’Œå¤šæ ·åŒ–å¹²æ‰°ä¸‹çš„å¼ºå¤§é€‚åº”èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—æé«˜äº†æŠ“å–ä»»åŠ¡çš„é²æ£’æ€§å’Œé€šç”¨æ€§ï¼Œæ ‡å¿—ç€è§†è§‰è¿åŠ¨å­¦ä¹ åœ¨å¤–ç§‘æœºå™¨äººä¸­çš„æˆåŠŸåº”ç”¨ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æœºå™¨äººè¾…åŠ©å¤–ç§‘æ‰‹æœ¯ä¸­ã€‚é€šè¿‡æé«˜æŠ“å–çš„è‡ªåŠ¨åŒ–æ°´å¹³ï¼ŒGASv2å¯ä»¥æ˜¾è‘—å‡è½»å¤–ç§‘åŒ»ç”Ÿçš„å·¥ä½œè´Ÿæ‹…ï¼Œæé«˜æ‰‹æœ¯çš„å®‰å…¨æ€§å’Œæ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯çš„é€šç”¨æ€§ä½¿å…¶èƒ½å¤Ÿé€‚åº”ä¸åŒç±»å‹çš„å¤–ç§‘ç‰©ä½“ï¼Œæœªæ¥å¯èƒ½æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸçš„æœºå™¨äººæ“ä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Grasping is a fundamental task in robot-assisted surgery (RAS), and automating it can reduce surgeon workload while enhancing efficiency, safety, and consistency beyond teleoperated systems. Most prior approaches rely on explicit object pose tracking or handcrafted visual features, limiting their generalization to novel objects, robustness to visual disturbances, and the ability to handle deformable objects. Visuomotor learning offers a promising alternative, but deploying it in RAS presents unique challenges, such as low signal-to-noise ratio in visual observations, demands for high safety and millimeter-level precision, as well as the complex surgical environment. This paper addresses three key challenges: (i) sim-to-real transfer of visuomotor policies to ex vivo surgical scenes, (ii) visuomotor learning using only a single stereo camera pair -- the standard RAS setup, and (iii) object-agnostic grasping with a single policy that generalizes to diverse, unseen surgical objects without retraining or task-specific models. We introduce Grasp Anything for Surgery V2 (GASv2), a visuomotor learning framework for surgical grasping. GASv2 leverages a world-model-based architecture and a surgical perception pipeline for visual observations, combined with a hybrid control system for safe execution. We train the policy in simulation using domain randomization for sim-to-real transfer and deploy it on a real robot in both phantom-based and ex vivo surgical settings, using only a single pair of endoscopic cameras. Extensive experiments show our policy achieves a 65% success rate in both settings, generalizes to unseen objects and grippers, and adapts to diverse disturbances, demonstrating strong performance, generality, and robustness.

