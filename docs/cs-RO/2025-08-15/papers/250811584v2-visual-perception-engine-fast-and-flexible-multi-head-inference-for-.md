---
layout: default
title: Visual Perception Engine: Fast and Flexible Multi-Head Inference for Robotic Vision Tasks
---

# Visual Perception Engine: Fast and Flexible Multi-Head Inference for Robotic Vision Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.11584" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.11584v2</a>
  <a href="https://arxiv.org/pdf/2508.11584.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.11584v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.11584v2', 'Visual Perception Engine: Fast and Flexible Multi-Head Inference for Robotic Vision Tasks')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Jakub ≈Åucki, Jonathan Becktor, Georgios Georgakis, Rob Royce, Shehryar Khattak

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-15 (Êõ¥Êñ∞: 2025-08-18)

**Â§áÊ≥®**: 8 pages, 6 figures, 2 tables

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ËßÜËßâÊÑüÁü•ÂºïÊìé‰ª•Ëß£ÂÜ≥Êú∫Âô®‰∫∫ËßÜËßâ‰ªªÂä°‰∏≠ÁöÑËÆ°ÁÆóÂÜó‰ΩôÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâÊÑüÁü•` `Â§ö‰ªªÂä°Â§ÑÁêÜ` `GPU‰ºòÂåñ` `Êú∫Âô®‰∫∫ËßÜËßâ` `Ê∑±Â∫¶Â≠¶‰π†` `Ê®°ÂùóÂåñÊ°ÜÊû∂` `ÂÆûÊó∂ÊÄßËÉΩ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ËµÑÊ∫êÂèóÈôêÁöÑÊú∫Âô®‰∫∫Âπ≥Âè∞‰∏äÈÉ®ÁΩ≤Â§ö‰∏™Ê®°ÂûãÊó∂ÔºåÈù¢‰∏¥ËÆ°ÁÆóÂÜó‰ΩôÂíåÂÜÖÂ≠òÂç†Áî®Â§ßÁöÑÈóÆÈ¢ò„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑVPEngineÊ°ÜÊû∂ÈÄöËøáÂÖ±‰∫´Âü∫Á°ÄÊ®°ÂûãÂíåÂπ∂Ë°å‰ªªÂä°Â§¥ËÆæËÆ°ÔºåÂáèÂ∞ë‰∫ÜÂÜó‰ΩôËÆ°ÁÆóÂπ∂ÊèêÈ´ò‰∫ÜGPUÂà©Áî®Áéá„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVPEngineÂú®NVIDIA Jetson Orin AGX‰∏äÂÆûÁé∞‰∫Ü‚â•50 HzÁöÑÂÆûÊó∂ÊÄßËÉΩÔºåÁõ∏ÊØî‰º†ÁªüÈ°∫Â∫èÊâßË°åÈÄüÂ∫¶ÊèêÂçá‰∫Ü3ÂÄç„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®ËµÑÊ∫êÂèóÈôêÁöÑÊú∫Âô®‰∫∫Âπ≥Âè∞‰∏äÈÉ®ÁΩ≤Â§ö‰∏™Êú∫Âô®Â≠¶‰π†Ê®°ÂûãËøõË°å‰∏çÂêåÁöÑÊÑüÁü•‰ªªÂä°ÔºåÂ∏∏Â∏∏ÂØºËá¥ÂÜó‰ΩôËÆ°ÁÆó„ÄÅÂ§ßÈáèÂÜÖÂ≠òÂç†Áî®ÂíåÂ§çÊùÇÁöÑÈõÜÊàêÊåëÊàò„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜËßÜËßâÊÑüÁü•ÂºïÊìéÔºàVPEngineÔºâÔºå‰∏Ä‰∏™Ê®°ÂùóÂåñÊ°ÜÊû∂ÔºåÊó®Âú®È´òÊïàÂà©Áî®GPUËøõË°åËßÜËßâÂ§ö‰ªªÂä°Â§ÑÁêÜÔºåÂêåÊó∂‰øùÊåÅÂèØÊâ©Â±ïÊÄßÂíåÂºÄÂèëËÄÖÁöÑÂèØËÆøÈóÆÊÄß„ÄÇËØ•Ê°ÜÊû∂Êû∂ÊûÑÂà©Áî®ÂÖ±‰∫´ÁöÑÂü∫Á°ÄÊ®°ÂûãÈ™®Âπ≤ÊèêÂèñÂõæÂÉèË°®Á§∫ÔºåËÉΩÂ§üÈ´òÊïàÂÖ±‰∫´ÔºåÈÅøÂÖç‰∏çÂøÖË¶ÅÁöÑGPU-CPUÂÜÖÂ≠ò‰º†ËæìÔºåÊîØÊåÅÂ§ö‰∏™‰∏ìÁî®‰ªªÂä°Ê®°ÂûãÂ§¥Âπ∂Ë°åËøêË°å„ÄÇÈÄöËøá‰ΩøÁî®DINOv2‰Ωú‰∏∫Âü∫Á°ÄÊ®°ÂûãÁöÑÁ§∫‰æãÂÆûÁé∞ÔºåVPEngineÂú®Ê∑±Â∫¶‰º∞ËÆ°„ÄÅÁâ©‰ΩìÊ£ÄÊµãÂíåËØ≠‰πâÂàÜÂâ≤Á≠â‰ªªÂä°‰∏äÂÆûÁé∞‰∫ÜÊúÄÈ´ò3ÂÄçÁöÑÈÄüÂ∫¶ÊèêÂçá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂΩìÂâçÂú®ËµÑÊ∫êÂèóÈôêÁöÑÊú∫Âô®‰∫∫Âπ≥Âè∞‰∏äÔºåÈÉ®ÁΩ≤Â§ö‰∏™Êú∫Âô®Â≠¶‰π†Ê®°ÂûãËøõË°åËßÜËßâÊÑüÁü•‰ªªÂä°Êó∂ÔºåÂ∏∏Â∏∏‰ºöÂá∫Áé∞ËÆ°ÁÆóÂÜó‰ΩôÂíåÂÜÖÂ≠òÂç†Áî®ËøáÂ§ßÁöÑÈóÆÈ¢òÔºåÂØºËá¥ÊïàÁéá‰Ωé‰∏ãÂíåÈõÜÊàêÂ§çÊùÇ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVPEngineÊ°ÜÊû∂ÈÄöËøá‰ΩøÁî®ÂÖ±‰∫´ÁöÑÂü∫Á°ÄÊ®°ÂûãÈ™®Âπ≤Êù•ÊèêÂèñÂõæÂÉèÁâπÂæÅÔºåÂπ∂ÂÖÅËÆ∏Â§ö‰∏™‰ªªÂä°ÁâπÂÆöÁöÑÊ®°ÂûãÂ§¥Âπ∂Ë°åËøêË°åÔºå‰ªéËÄåÊ∂àÈô§‰º†ÁªüÈ°∫Â∫èÊ®°Âûã‰∏≠ÁöÑÂÜó‰ΩôËÆ°ÁÆóÔºåÂπ∂Ê†πÊçÆÂ∫îÁî®ÈúÄÊ±ÇÂä®ÊÄÅË∞ÉÊï¥‰ªªÂä°‰ºòÂÖàÁ∫ß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂ÂåÖÊã¨‰∏Ä‰∏™ÂÖ±‰∫´ÁöÑÂü∫Á°ÄÊ®°ÂûãÁî®‰∫éÁâπÂæÅÊèêÂèñÔºåÂ§ö‰∏™Âπ∂Ë°åÁöÑ‰ªªÂä°Â§¥ÔºàÂ¶ÇÊ∑±Â∫¶‰º∞ËÆ°„ÄÅÁâ©‰ΩìÊ£ÄÊµãÂíåËØ≠‰πâÂàÜÂâ≤ÔºâÔºåÂπ∂Âü∫‰∫éCUDAÂ§öËøõÁ®ãÊúçÂä°ÔºàMPSÔºâÂÆûÁé∞È´òÊïàÁöÑGPUÂà©Áî®„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVPEngineÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂Ê®°ÂùóÂåñËÆæËÆ°ÂíåÂä®ÊÄÅ‰ªªÂä°‰ºòÂÖàÁ∫ßË∞ÉÊï¥ËÉΩÂäõÔºåÊòæËëóÊèêÈ´ò‰∫ÜGPUÁöÑ‰ΩøÁî®ÊïàÁéáÔºåÂπ∂‰øùÊåÅ‰∫ÜÊÅíÂÆöÁöÑÂÜÖÂ≠òÂç†Áî®Ôºå‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåËÉΩÂ§üÊúâÊïàÂáèÂ∞ëËÆ°ÁÆóÂÜó‰Ωô„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊ°ÜÊû∂ÈááÁî®PythonÁºñÂÜôÔºåÂπ∂Êèê‰æõROS2 C++ÔºàHumbleÔºâÁªëÂÆöÔºåÊñπ‰æøÊú∫Âô®‰∫∫Á§æÂå∫‰ΩøÁî®„ÄÇÊ®°ÂûãÁöÑÂÆûÁé∞‰ΩøÁî®‰∫ÜTensorRTËøõË°å‰ºòÂåñÔºåÁ°Æ‰øùÂú®NVIDIA Jetson Orin AGX‰∏äÂÆûÁé∞‚â•50 HzÁöÑÂÆûÊó∂ÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫Ôºå‰ΩøÁî®VPEngineÊ°ÜÊû∂ÁöÑÊ®°ÂûãÂú®NVIDIA Jetson Orin AGX‰∏äÂÆûÁé∞‰∫Ü‚â•50 HzÁöÑÂÆûÊó∂ÊÄßËÉΩÔºåÁõ∏ÊØî‰∫é‰º†ÁªüÁöÑÈ°∫Â∫èÊâßË°åÊñπÊ≥ïÔºåÈÄüÂ∫¶ÊèêÂçáÈ´òËææ3ÂÄç„ÄÇËøô‰∏ÄÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáË°®Êòé‰∫ÜËØ•Ê°ÜÊû∂Âú®ËßÜËßâÂ§ö‰ªªÂä°Â§ÑÁêÜ‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÂÆûÁî®ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™‰∏ªÊú∫Âô®‰∫∫„ÄÅÊó†‰∫∫È©æÈ©∂Ê±ΩËΩ¶ÂíåÊô∫ËÉΩÁõëÊéßÁ≥ªÁªüÁ≠âÔºåËÉΩÂ§üÊúâÊïàÊèêÂçáËøô‰∫õÁ≥ªÁªüÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑËßÜËßâÊÑüÁü•ËÉΩÂäõ„ÄÇVPEngineÁöÑÊ®°ÂùóÂåñËÆæËÆ°ÂíåÈ´òÊïàÊÄßËÉΩÂ∞Ü‰∏∫Êú∫Âô®‰∫∫ËßÜËßâ‰ªªÂä°ÁöÑÂ§öÊ†∑ÂåñÂ∫îÁî®Êèê‰æõÂº∫ÊúâÂäõÁöÑÊîØÊåÅÔºåÊé®Âä®Êô∫ËÉΩÊú∫Âô®‰∫∫ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Deploying multiple machine learning models on resource-constrained robotic platforms for different perception tasks often results in redundant computations, large memory footprints, and complex integration challenges. In response, this work presents Visual Perception Engine (VPEngine), a modular framework designed to enable efficient GPU usage for visual multitasking while maintaining extensibility and developer accessibility. Our framework architecture leverages a shared foundation model backbone that extracts image representations, which are efficiently shared, without any unnecessary GPU-CPU memory transfers, across multiple specialized task-specific model heads running in parallel. This design eliminates the computational redundancy inherent in feature extraction component when deploying traditional sequential models while enabling dynamic task prioritization based on application demands. We demonstrate our framework's capabilities through an example implementation using DINOv2 as the foundation model with multiple task (depth, object detection and semantic segmentation) heads, achieving up to 3x speedup compared to sequential execution. Building on CUDA Multi-Process Service (MPS), VPEngine offers efficient GPU utilization and maintains a constant memory footprint while allowing per-task inference frequencies to be adjusted dynamically during runtime. The framework is written in Python and is open source with ROS2 C++ (Humble) bindings for ease of use by the robotics community across diverse robotic platforms. Our example implementation demonstrates end-to-end real-time performance at $\geq$50 Hz on NVIDIA Jetson Orin AGX for TensorRT optimized models.

