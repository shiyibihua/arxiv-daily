---
layout: default
title: i2Nav-Robot: A Large-Scale Indoor-Outdoor Robot Dataset for Multi-Sensor Fusion Navigation and Mapping
---

# i2Nav-Robot: A Large-Scale Indoor-Outdoor Robot Dataset for Multi-Sensor Fusion Navigation and Mapping

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.11485" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.11485v2</a>
  <a href="https://arxiv.org/pdf/2508.11485.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.11485v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.11485v2', 'i2Nav-Robot: A Large-Scale Indoor-Outdoor Robot Dataset for Multi-Sensor Fusion Navigation and Mapping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hailiang Tang, Tisheng Zhang, Liqiang Wang, Xin Ding, Man Yuan, Zhiyu Xiang, Jujin Chen, Yuhan Bian, Shuangyan Liu, Yuqing Wang, Guan Wang, Xiaoji Niu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-15 (æ›´æ–°: 2025-08-27)

**å¤‡æ³¨**: 10 pages, 12 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºi2Nav-Robotæ•°æ®é›†ä»¥è§£å†³UGVå¯¼èˆªä¸æ˜ å°„çš„å¤šä¼ æ„Ÿå™¨èåˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šä¼ æ„Ÿå™¨èåˆ` `æ— äººé©¾é©¶` `æ•°æ®é›†` `å¯¼èˆªä¸æ˜ å°„` `æ¿€å…‰é›·è¾¾` `å®¤å†…å¤–ç¯å¢ƒ` `é«˜ç²¾åº¦å®šä½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰UGVæ•°æ®é›†åœ¨ä¼ æ„Ÿå™¨é…ç½®å’Œåœºæ™¯å¤šæ ·æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œé™åˆ¶äº†å¯¼èˆªå’Œæ˜ å°„æŠ€æœ¯çš„è¿›æ­¥ã€‚
2. æœ¬æ–‡æå‡ºi2Nav-Robotæ•°æ®é›†ï¼Œé›†æˆå¤šç§ä¼ æ„Ÿå™¨å¹¶å®ç°é«˜ç²¾åº¦æ—¶é—´åŒæ­¥ï¼Œä»¥æ”¯æŒå¤šä¼ æ„Ÿå™¨èåˆå¯¼èˆªã€‚
3. i2Nav-Robotæ•°æ®é›†ç»è¿‡å¤šä¸ªç³»ç»Ÿè¯„ä¼°ï¼Œæ˜¾ç¤ºå‡ºä¼˜è¶Šçš„æ•°æ®è´¨é‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å¯¼èˆªç²¾åº¦å’Œå¯é æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‡†ç¡®å¯é çš„å¯¼èˆªå¯¹äºè‡ªä¸»æ— äººåœ°é¢è½¦è¾†ï¼ˆUGVï¼‰è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰UGVæ•°æ®é›†åœ¨ä¼ æ„Ÿå™¨é…ç½®ã€æ—¶é—´åŒæ­¥ã€çœŸå®å€¼å’Œåœºæ™¯å¤šæ ·æ€§ç­‰æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†i2Nav-Robotï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºå®¤å†…å¤–ç¯å¢ƒä¸­çš„å¤šä¼ æ„Ÿå™¨èåˆå¯¼èˆªå’Œæ˜ å°„è€Œè®¾è®¡çš„å¤§è§„æ¨¡æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†æ•´åˆäº†æœ€æ–°çš„å‰è§†å’Œ360åº¦å›ºæ€æ¿€å…‰é›·è¾¾ã€å››ç»´é›·è¾¾ã€ç«‹ä½“ç›¸æœºã€é‡Œç¨‹è®¡ã€å…¨çƒå¯¼èˆªå«æ˜Ÿç³»ç»Ÿï¼ˆGNSSï¼‰æ¥æ”¶å™¨å’Œæƒ¯æ€§æµ‹é‡å•å…ƒï¼ˆIMUï¼‰ã€‚é€šè¿‡åœ¨çº¿ç¡¬ä»¶åŒæ­¥å’Œç¦»çº¿æ ¡å‡†è·å¾—å‡†ç¡®çš„æ—¶é—´æˆ³ï¼Œæ•°æ®é›†åŒ…å«åä¸ªå¤§è§„æ¨¡åºåˆ—ï¼Œè¦†ç›–å¤šæ ·çš„UGVæ“ä½œåœºæ™¯ï¼Œæ€»é•¿åº¦çº¦ä¸º17060ç±³ã€‚é«˜é¢‘çœŸå®å€¼é€šè¿‡åå¤„ç†é›†æˆå¯¼èˆªæ–¹æ³•è·å¾—ï¼Œä½ç½®ç²¾åº¦è¾¾åˆ°å˜ç±³çº§ã€‚i2Nav-Robotæ•°æ®é›†ç»è¿‡åå¤šä¸ªå¼€æºå¤šä¼ æ„Ÿå™¨èåˆç³»ç»Ÿçš„è¯„ä¼°ï¼Œè¯æ˜å…¶æ•°æ®è´¨é‡ä¼˜è¶Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰UGVæ•°æ®é›†åœ¨ä¼ æ„Ÿå™¨é…ç½®ã€æ—¶é—´åŒæ­¥å’Œåœºæ™¯å¤šæ ·æ€§ç­‰æ–¹é¢çš„ä¸è¶³ï¼Œä»¥æ»¡è¶³å¤šä¼ æ„Ÿå™¨èåˆå¯¼èˆªå’Œæ˜ å°„çš„éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªé›†æˆå¤šç§ä¼ æ„Ÿå™¨çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œæä¾›é«˜é¢‘ã€å‡†ç¡®çš„æ—¶é—´æˆ³å’ŒçœŸå®å€¼ï¼Œæ”¯æŒæ›´ä¸ºç²¾ç¡®çš„å¯¼èˆªå’Œæ˜ å°„æŠ€æœ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•°æ®é›†ç”±å¤šä¸ªæ¨¡å—ç»„æˆï¼ŒåŒ…æ‹¬å‰è§†å’Œ360åº¦æ¿€å…‰é›·è¾¾ã€å››ç»´é›·è¾¾ã€ç«‹ä½“ç›¸æœºã€é‡Œç¨‹è®¡ã€GNSSæ¥æ”¶å™¨å’ŒIMUï¼Œæ‰€æœ‰ä¼ æ„Ÿå™¨é€šè¿‡åœ¨çº¿åŒæ­¥å’Œç¦»çº¿æ ¡å‡†ç¡®ä¿æ—¶é—´ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼ši2Nav-Robotæ•°æ®é›†çš„åˆ›æ–°åœ¨äºå…¶å¤šæ¨¡æ€ä¼ æ„Ÿå™¨çš„é›†æˆå’Œé«˜ç²¾åº¦çš„æ—¶é—´åŒæ­¥ï¼Œæ˜¾è‘—æå‡äº†æ•°æ®çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œä¸ç°æœ‰æ•°æ®é›†ç›¸æ¯”å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šæ•°æ®é›†çš„è®¾è®¡åŒ…æ‹¬é«˜é¢‘é‡‡æ ·å’Œå˜ç±³çº§ä½ç½®ç²¾åº¦çš„çœŸå®å€¼ç”Ÿæˆï¼Œé‡‡ç”¨å¯¼èˆªçº§IMUè¿›è¡Œåå¤„ç†é›†æˆå¯¼èˆªï¼Œç¡®ä¿æ•°æ®çš„é«˜è´¨é‡å’Œé€‚ç”¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œi2Nav-Robotæ•°æ®é›†åœ¨è¶…è¿‡åä¸ªå¼€æºå¤šä¼ æ„Ÿå™¨èåˆç³»ç»Ÿä¸­è¡¨ç°å‡ºè‰²ï¼Œæ•°æ®è´¨é‡æ˜¾è‘—ä¼˜äºç°æœ‰æ•°æ®é›†ï¼Œå°¤å…¶åœ¨å¯¼èˆªç²¾åº¦ä¸Šå®ç°äº†å˜ç±³çº§çš„æå‡ï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

i2Nav-Robotæ•°æ®é›†å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªä¸»é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œæ™ºèƒ½äº¤é€šç³»ç»Ÿç­‰é¢†åŸŸã€‚å…¶é«˜è´¨é‡çš„æ•°æ®æ”¯æŒç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆå¼€å‘æ›´ä¸ºå…ˆè¿›çš„å¯¼èˆªç®—æ³•å’Œç³»ç»Ÿï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate and reliable navigation is crucial for autonomous unmanned ground vehicle (UGV). However, current UGV datasets fall short in meeting the demands for advancing navigation and mapping techniques due to limitations in sensor configuration, time synchronization, ground truth, and scenario diversity. To address these challenges, we present i2Nav-Robot, a large-scale dataset designed for multi-sensor fusion navigation and mapping in indoor-outdoor environments. We integrate multi-modal sensors, including the newest front-view and 360-degree solid-state LiDARs, 4-dimensional (4D) radar, stereo cameras, odometer, global navigation satellite system (GNSS) receiver, and inertial measurement units (IMU) on an omnidirectional wheeled robot. Accurate timestamps are obtained through both online hardware synchronization and offline calibration for all sensors. The dataset includes ten larger-scale sequences covering diverse UGV operating scenarios, such as outdoor streets, and indoor parking lots, with a total length of about 17060 meters. High-frequency ground truth, with centimeter-level accuracy for position, is derived from post-processing integrated navigation methods using a navigation-grade IMU. The proposed i2Nav-Robot dataset is evaluated by more than ten open-sourced multi-sensor fusion systems, and it has proven to have superior data quality.

