---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-12-24
---

# cs.ROï¼ˆ2025-12-24ï¼‰

ğŸ“Š å…± **14** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (9)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ğŸ”—1)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251221233v1-unitachand-unified-spatio-tactile-representation-for-human-to-roboti.html">UniTacHand: Unified Spatio-Tactile Representation for Human to Robotic Hand Skill Transfer</a></td>
  <td>UniTacHandï¼šç”¨äºäºº-æœºå™¨äººæ‰‹æŠ€èƒ½è¿ç§»çš„ç»Ÿä¸€æ—¶ç©ºè§¦è§‰è¡¨ç¤º</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous hand</span> <span class="paper-tag">dexterous manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21233v1" data-paper-url="./papers/251221233v1-unitachand-unified-spatio-tactile-representation-for-human-to-roboti.html" onclick="toggleFavorite(this, '2512.21233v1', 'UniTacHand: Unified Spatio-Tactile Representation for Human to Robotic Hand Skill Transfer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251221293v1-quadrupped-legged-robot-movement-plan-generation-using-large-languag.html">Quadrupped-Legged Robot Movement Plan Generation using Large Language Model</a></td>
  <td>æå‡ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å››è¶³æœºå™¨äººè‡ªç„¶è¯­è¨€è¿åŠ¨è§„åˆ’æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">legged robot</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21293v1" data-paper-url="./papers/251221293v1-quadrupped-legged-robot-movement-plan-generation-using-large-languag.html" onclick="toggleFavorite(this, '2512.21293v1', 'Quadrupped-Legged Robot Movement Plan Generation using Large Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251221219v1-wireless-center-of-pressure-feedback-system-for-humanoid-robot-balan.html">Wireless Center of Pressure Feedback System for Humanoid Robot Balance Control using ESP32-C3</a></td>
  <td>é’ˆå¯¹äººå½¢æœºå™¨äººï¼Œæå‡ºåŸºäºESP32-C3çš„æ— çº¿å‹åŠ›ä¸­å¿ƒåé¦ˆå¹³è¡¡æ§åˆ¶ç³»ç»Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21219v1" data-paper-url="./papers/251221219v1-wireless-center-of-pressure-feedback-system-for-humanoid-robot-balan.html" onclick="toggleFavorite(this, '2512.21219v1', 'Wireless Center of Pressure Feedback System for Humanoid Robot Balance Control using ESP32-C3')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251221065v1-language-guided-grasp-detection-with-coarse-to-fine-learning-for-rob.html">Language-Guided Grasp Detection with Coarse-to-Fine Learning for Robotic Manipulation</a></td>
  <td>æå‡ºåŸºäºç²—åˆ°ç²¾å­¦ä¹ çš„è¯­è¨€å¼•å¯¼æŠ“å–æ£€æµ‹æ–¹æ³•ï¼Œç”¨äºæœºå™¨äººæ“ä½œ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">grasp prediction</span> <span class="paper-tag">language conditioned</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21065v1" data-paper-url="./papers/251221065v1-language-guided-grasp-detection-with-coarse-to-fine-learning-for-rob.html" onclick="toggleFavorite(this, '2512.21065v1', 'Language-Guided Grasp Detection with Coarse-to-Fine Learning for Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251221109v1-robust-and-efficient-mujoco-based-model-predictive-control-via-web-o.html">Robust and Efficient MuJoCo-based Model Predictive Control via Web of Affine Spaces Derivatives</a></td>
  <td>æå‡ºåŸºäºä»¿å°„ç©ºé—´ç½‘ç»œå¯¼æ•°çš„MuJoCoæ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼Œæå‡æ•ˆç‡ä¸é²æ£’æ€§</td>
  <td class="tags-cell"><span class="paper-tag">MPC</span> <span class="paper-tag">model predictive control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21109v1" data-paper-url="./papers/251221109v1-robust-and-efficient-mujoco-based-model-predictive-control-via-web-o.html" onclick="toggleFavorite(this, '2512.21109v1', 'Robust and Efficient MuJoCo-based Model Predictive Control via Web of Affine Spaces Derivatives')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251221085v1-global-end-effector-pose-control-of-an-underactuated-aerial-manipula.html">Global End-Effector Pose Control of an Underactuated Aerial Manipulator via Reinforcement Learning</a></td>
  <td>æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¬ é©±åŠ¨ç©ºä¸­æœºæ¢°è‡‚å…¨å±€æœ«ç«¯å§¿æ€æ§åˆ¶æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">PPO</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21085v1" data-paper-url="./papers/251221085v1-global-end-effector-pose-control-of-an-underactuated-aerial-manipula.html" onclick="toggleFavorite(this, '2512.21085v1', 'Global End-Effector Pose Control of an Underactuated Aerial Manipulator via Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251221235v1-robocade-gamifying-robot-data-collection.html">RoboCade: Gamifying Robot Data Collection</a></td>
  <td>RoboCadeï¼šé€šè¿‡æ¸¸æˆåŒ–æ–¹å¼æ‰©å±•æœºå™¨äººæ•°æ®æ”¶é›†ï¼Œæå‡æ¨¡ä»¿å­¦ä¹ ç­–ç•¥ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">teleoperation</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21235v1" data-paper-url="./papers/251221235v1-robocade-gamifying-robot-data-collection.html" onclick="toggleFavorite(this, '2512.21235v1', 'RoboCade: Gamifying Robot Data Collection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251221201v1-schrÃ¶dingers-navigator-imagining-an-ensemble-of-futures-for-zero-sho.html">SchrÃ¶dinger's Navigator: Imagining an Ensemble of Futures for Zero-Shot Object Navigation</a></td>
  <td>æå‡ºSchrÃ¶dinger's Navigatorï¼Œé€šè¿‡æœªæ¥ä¸–ç•Œæƒ³è±¡å¢å¼ºé›¶æ ·æœ¬ç‰©ä½“å¯¼èˆª</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">world model</span> <span class="paper-tag">egocentric</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21201v1" data-paper-url="./papers/251221201v1-schrÃ¶dingers-navigator-imagining-an-ensemble-of-futures-for-zero-sho.html" onclick="toggleFavorite(this, '2512.21201v1', 'SchrÃ¶dinger&#39;s Navigator: Imagining an Ensemble of Futures for Zero-Shot Object Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251221043v1-tracing-energy-flow-learning-tactile-based-grasping-force-control-to.html">Tracing Energy Flow: Learning Tactile-based Grasping Force Control to Prevent Slippage in Dynamic Object Interaction</a></td>
  <td>æå‡ºåŸºäºè§¦è§‰èƒ½é‡æµçš„æŠ“å–åŠ›æ§åˆ¶æ–¹æ³•ï¼Œé˜²æ­¢åŠ¨æ€ç‰©ä½“äº¤äº’ä¸­çš„æ»‘ç§»</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21043v1" data-paper-url="./papers/251221043v1-tracing-energy-flow-learning-tactile-based-grasping-force-control-to.html" onclick="toggleFavorite(this, '2512.21043v1', 'Tracing Energy Flow: Learning Tactile-based Grasping Force Control to Prevent Slippage in Dynamic Object Interaction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>10</td>
  <td><a href="./papers/251220992v1-multimodal-sensing-for-robot-assisted-sub-tissue-feature-detection-i.html">Multimodal Sensing for Robot-Assisted Sub-Tissue Feature Detection in Physiotherapy Palpation</a></td>
  <td>æå‡ºä¸€ç§å¤šæ¨¡æ€è§¦è§‰ä¼ æ„Ÿå™¨ï¼Œç”¨äºæœºå™¨äººè¾…åŠ©çš„ç†ç–—è§¦è¯Šä¸­äºšç»„ç»‡ç‰¹å¾æ£€æµ‹ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20992v1" data-paper-url="./papers/251220992v1-multimodal-sensing-for-robot-assisted-sub-tissue-feature-detection-i.html" onclick="toggleFavorite(this, '2512.20992v1', 'Multimodal Sensing for Robot-Assisted Sub-Tissue Feature Detection in Physiotherapy Palpation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251220940v1-etp-r1-evolving-topological-planning-with-reinforcement-fine-tuning-.html">ETP-R1: Evolving Topological Planning with Reinforcement Fine-tuning for Vision-Language Navigation in Continuous Environments</a></td>
  <td>ETP-R1ï¼šé€šè¿‡å¼ºåŒ–å¾®è°ƒæ¼”åŒ–æ‹“æ‰‘è§„åˆ’ï¼Œè§£å†³è¿ç»­ç¯å¢ƒä¸‹çš„è§†è§‰-è¯­è¨€å¯¼èˆªé—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">VLN</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20940v1" data-paper-url="./papers/251220940v1-etp-r1-evolving-topological-planning-with-reinforcement-fine-tuning-.html" onclick="toggleFavorite(this, '2512.20940v1', 'ETP-R1: Evolving Topological Planning with Reinforcement Fine-tuning for Vision-Language Navigation in Continuous Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>12</td>
  <td><a href="./papers/251221243v1-lookplangraph-embodied-instruction-following-method-with-vlm-graph-a.html">LookPlanGraph: Embodied Instruction Following Method with VLM Graph Augmentation</a></td>
  <td>æå‡ºLookPlanGraphï¼Œé€šè¿‡VLMå›¾å¢å¼ºå®ç°å…·èº«æŒ‡ä»¤è·Ÿéšä»»åŠ¡</td>
  <td class="tags-cell"><span class="paper-tag">egocentric</span> <span class="paper-tag">large language model</span> <span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21243v1" data-paper-url="./papers/251221243v1-lookplangraph-embodied-instruction-following-method-with-vlm-graph-a.html" onclick="toggleFavorite(this, '2512.21243v1', 'LookPlanGraph: Embodied Instruction Following Method with VLM Graph Augmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/251220876v1-proprioception-enhances-vision-language-model-in-generating-captions.html">Proprioception Enhances Vision Language Model in Generating Captions and Subtask Segmentations for Robot Task</a></td>
  <td>æå‡ºä¸€ç§èåˆæœºå™¨äººè¿åŠ¨ä¿¡æ¯çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œç”¨äºæœºå™¨äººä»»åŠ¡çš„è‡ªåŠ¨æè¿°å’Œåˆ†å‰²ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">imitation learning</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20876v1" data-paper-url="./papers/251220876v1-proprioception-enhances-vision-language-model-in-generating-captions.html" onclick="toggleFavorite(this, '2512.20876v1', 'Proprioception Enhances Vision Language Model in Generating Captions and Subtask Segmentations for Robot Task')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>14</td>
  <td><a href="./papers/251221226v1-relative-localization-system-design-for-snailbot-a-modular-self-reco.html">Relative Localization System Design for SnailBot: A Modular Self-reconfigurable Robot</a></td>
  <td>ä¸ºæ¨¡å—åŒ–è‡ªé‡æ„æœºå™¨äººSnailBotè®¾è®¡ç›¸å¯¹å®šä½ç³»ç»Ÿï¼Œå®ç°ååŒä»»åŠ¡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">optical flow</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21226v1" data-paper-url="./papers/251221226v1-relative-localization-system-design-for-snailbot-a-modular-self-reco.html" onclick="toggleFavorite(this, '2512.21226v1', 'Relative Localization System Design for SnailBot: A Modular Self-reconfigurable Robot')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)