---
layout: default
title: Language-Guided Grasp Detection with Coarse-to-Fine Learning for Robotic Manipulation
---

# Language-Guided Grasp Detection with Coarse-to-Fine Learning for Robotic Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.21065" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.21065v1</a>
  <a href="https://arxiv.org/pdf/2512.21065.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.21065v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.21065v1', 'Language-Guided Grasp Detection with Coarse-to-Fine Learning for Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zebin Jiang, Tianle Jin, Xiangtong Yao, Alois Knoll, Hu Cao

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-24

**å¤‡æ³¨**: Submitted to IEEE Journal

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºç²—åˆ°ç²¾å­¦ä¹ çš„è¯­è¨€å¼•å¯¼æŠ“å–æ£€æµ‹æ–¹æ³•ï¼Œç”¨äºæœºå™¨äººæ“ä½œ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººæŠ“å–` `è¯­è¨€å¼•å¯¼` `è·¨æ¨¡æ€èåˆ` `ç²—åˆ°ç²¾å­¦ä¹ ` `åŠ¨æ€å·ç§¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­è¨€å¼•å¯¼çš„æŠ“å–æ–¹æ³•ä¾èµ–æµ…å±‚èåˆï¼Œå­˜åœ¨è¯­ä¹‰åŸºç¡€è–„å¼±å’Œè¯­è¨€æ„å›¾ä¸è§†è§‰æ¨ç†å¯¹é½ä¸è¶³çš„é—®é¢˜ã€‚
2. æå‡ºä¸€ç§ç²—åˆ°ç²¾çš„è¯­è¨€å¼•å¯¼æŠ“å–æ£€æµ‹ï¼ˆLGGDï¼‰æ–¹æ³•ï¼Œé€šè¿‡åˆ†å±‚è·¨æ¨¡æ€èåˆé€æ­¥æ³¨å…¥è¯­è¨€çº¿ç´¢ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLGGDåœ¨æ³›åŒ–æ€§å’Œé²æ£’æ€§ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨çœŸå®æœºå™¨äººå¹³å°ä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŠ“å–æ˜¯æœºå™¨äººæ“ä½œä¸­æœ€å…·æŒ‘æˆ˜æ€§çš„åŸºæœ¬èƒ½åŠ›ä¹‹ä¸€ï¼Œå°¤å…¶æ˜¯åœ¨éç»“æ„åŒ–ã€æ‚ä¹±å’Œè¯­ä¹‰å¤šæ ·çš„ç¯å¢ƒä¸­ã€‚æœ€è¿‘çš„ç ”ç©¶è¶Šæ¥è¶Šå¤šåœ°æ¢ç´¢è¯­è¨€å¼•å¯¼çš„æ“ä½œï¼Œæœºå™¨äººä¸ä»…æ„ŸçŸ¥åœºæ™¯ï¼Œè¿˜èƒ½ç†è§£ä»»åŠ¡ç›¸å…³çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è¯­è¨€æ¡ä»¶æŠ“å–æ–¹æ³•é€šå¸¸ä¾èµ–äºæµ…å±‚èåˆç­–ç•¥ï¼Œå¯¼è‡´æœ‰é™çš„è¯­ä¹‰åŸºç¡€å’Œè¯­è¨€æ„å›¾ä¸è§†è§‰æŠ“å–æ¨ç†ä¹‹é—´çš„å¼±å¯¹é½ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç²—åˆ°ç²¾å­¦ä¹ èŒƒå¼çš„è¯­è¨€å¼•å¯¼æŠ“å–æ£€æµ‹ï¼ˆLGGDï¼‰æ–¹æ³•ï¼Œç”¨äºæœºå™¨äººæ“ä½œã€‚LGGDåˆ©ç”¨åŸºäºCLIPçš„è§†è§‰å’Œæ–‡æœ¬åµŒå…¥ï¼Œåœ¨åˆ†å±‚è·¨æ¨¡æ€èåˆç®¡é“ä¸­é€æ­¥å°†è¯­è¨€çº¿ç´¢æ³¨å…¥åˆ°è§†è§‰ç‰¹å¾é‡å»ºè¿‡ç¨‹ä¸­ã€‚è¿™ç§è®¾è®¡å®ç°äº†ç»†ç²’åº¦çš„è§†è§‰-è¯­ä¹‰å¯¹é½ï¼Œå¹¶æé«˜äº†é¢„æµ‹æŠ“å–ç›¸å¯¹äºä»»åŠ¡æŒ‡ä»¤çš„å¯è¡Œæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è¯­è¨€æ¡ä»¶åŠ¨æ€å·ç§¯å¤´ï¼ˆLDCHï¼‰ï¼Œå®ƒåŸºäºå¥å­çº§ç‰¹å¾æ··åˆå¤šä¸ªå·ç§¯ä¸“å®¶ï¼Œä»è€Œå®ç°æŒ‡ä»¤è‡ªé€‚åº”çš„ç²—æ©ç å’ŒæŠ“å–é¢„æµ‹ã€‚æœ€ç»ˆçš„ç»†åŒ–æ¨¡å—è¿›ä¸€æ­¥å¢å¼ºäº†å¤æ‚åœºæ™¯ä¸­çš„æŠ“å–ä¸€è‡´æ€§å’Œé²æ£’æ€§ã€‚åœ¨OCID-VLGå’ŒGrasp-Anything++æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒLGGDè¶…è¶Šäº†ç°æœ‰çš„è¯­è¨€å¼•å¯¼æŠ“å–æ–¹æ³•ï¼Œå¯¹æœªè§è¿‡çš„ç‰©ä½“å’Œä¸åŒçš„è¯­è¨€æŸ¥è¯¢è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œåœ¨çœŸå®æœºå™¨äººå¹³å°ä¸Šçš„éƒ¨ç½²è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ‰§è¡Œç²¾ç¡®çš„ã€æŒ‡ä»¤æ¡ä»¶ä¸‹çš„æŠ“å–åŠ¨ä½œæ–¹é¢çš„å®é™…æœ‰æ•ˆæ€§ã€‚ä»£ç å°†åœ¨æ¥æ”¶åå…¬å¼€å‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæ“ä½œä¸­ï¼Œå¦‚ä½•åˆ©ç”¨è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ›´å‡†ç¡®ã€æ›´é²æ£’åœ°è¿›è¡Œç‰©ä½“æŠ“å–çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨æµ…å±‚èåˆç­–ç•¥ï¼Œæ— æ³•å……åˆ†ç†è§£è¯­è¨€æŒ‡ä»¤ä¸­çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´æŠ“å–ä½ç½®ä¸å‡†ç¡®ï¼Œå¯¹å¤æ‚ç¯å¢ƒçš„é€‚åº”æ€§è¾ƒå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸€ç§ç²—åˆ°ç²¾çš„å­¦ä¹ èŒƒå¼ï¼Œé€æ­¥å°†è¯­è¨€ä¿¡æ¯èå…¥åˆ°è§†è§‰ç‰¹å¾ä¸­ï¼Œå®ç°ç»†ç²’åº¦çš„è§†è§‰-è¯­ä¹‰å¯¹é½ã€‚é¦–å…ˆè¿›è¡Œç²—ç•¥çš„æŠ“å–åŒºåŸŸé¢„æµ‹ï¼Œç„¶åé€æ­¥ç»†åŒ–æŠ“å–å§¿æ€ï¼Œä»è€Œæé«˜æŠ“å–çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLGGDçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) åŸºäºCLIPçš„è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾æå–æ¨¡å—ï¼Œç”¨äºæå–è§†è§‰å’Œè¯­è¨€çš„åµŒå…¥è¡¨ç¤ºï¼›2) åˆ†å±‚è·¨æ¨¡æ€èåˆæ¨¡å—ï¼Œé€æ­¥å°†è¯­è¨€ä¿¡æ¯æ³¨å…¥åˆ°è§†è§‰ç‰¹å¾é‡å»ºè¿‡ç¨‹ä¸­ï¼›3) è¯­è¨€æ¡ä»¶åŠ¨æ€å·ç§¯å¤´ï¼ˆLDCHï¼‰ï¼Œç”¨äºç”ŸæˆæŒ‡ä»¤è‡ªé€‚åº”çš„ç²—æ©ç å’ŒæŠ“å–é¢„æµ‹ï¼›4) æŠ“å–ç»†åŒ–æ¨¡å—ï¼Œè¿›ä¸€æ­¥å¢å¼ºæŠ“å–çš„ä¸€è‡´æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ç²—åˆ°ç²¾çš„å­¦ä¹ èŒƒå¼ï¼Œå®ç°äº†ç»†ç²’åº¦çš„è§†è§‰-è¯­ä¹‰å¯¹é½ï¼›2) å¼•å…¥äº†è¯­è¨€æ¡ä»¶åŠ¨æ€å·ç§¯å¤´ï¼ˆLDCHï¼‰ï¼Œèƒ½å¤Ÿæ ¹æ®ä¸åŒçš„è¯­è¨€æŒ‡ä»¤åŠ¨æ€è°ƒæ•´å·ç§¯æ ¸çš„å‚æ•°ï¼Œä»è€Œå®ç°æŒ‡ä»¤è‡ªé€‚åº”çš„æŠ“å–é¢„æµ‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åˆ†å±‚è·¨æ¨¡æ€èåˆæ¨¡å—ä¸­ï¼Œé‡‡ç”¨äº†å¤šå±‚Transformerç»“æ„ï¼Œé€æ­¥å°†è¯­è¨€ç‰¹å¾èå…¥åˆ°è§†è§‰ç‰¹å¾ä¸­ã€‚LDCHæ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†å¤šä¸ªå·ç§¯ä¸“å®¶ï¼Œæ¯ä¸ªä¸“å®¶è´Ÿè´£å¤„ç†ä¸åŒç±»å‹çš„è¯­è¨€æŒ‡ä»¤ã€‚é€šè¿‡å¥å­çº§åˆ«çš„ç‰¹å¾æ¥æ··åˆè¿™äº›ä¸“å®¶ï¼Œä»è€Œå®ç°æŒ‡ä»¤è‡ªé€‚åº”çš„æŠ“å–é¢„æµ‹ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æŠ“å–åˆ†ç±»æŸå¤±ã€æŠ“å–å›å½’æŸå¤±å’Œæ©ç é¢„æµ‹æŸå¤±ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.21065v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.21065v1/Images/rectangular_grasp.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.21065v1/x2.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

LGGDåœ¨OCID-VLGå’ŒGrasp-Anything++æ•°æ®é›†ä¸Šè¶…è¶Šäº†ç°æœ‰çš„è¯­è¨€å¼•å¯¼æŠ“å–æ–¹æ³•ï¼Œå±•ç°å‡ºå¯¹æœªè§ç‰©ä½“çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›å’Œå¯¹å¤šæ ·è¯­è¨€æŸ¥è¯¢çš„é€‚åº”æ€§ã€‚åœ¨çœŸå®æœºå™¨äººå¹³å°ä¸Šçš„éƒ¨ç½²éªŒè¯äº†å…¶åœ¨æ‰§è¡Œç²¾ç¡®ã€æŒ‡ä»¤æ¡ä»¶ä¸‹çš„æŠ“å–åŠ¨ä½œæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®å°†åœ¨è®ºæ–‡å…¬å¼€å‘å¸ƒåæä¾›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½ä»“å‚¨ã€æ™ºèƒ½åˆ¶é€ ã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸã€‚é€šè¿‡ç»“åˆè‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œæœºå™¨äººå¯ä»¥æ›´çµæ´»ã€æ›´æ™ºèƒ½åœ°å®Œæˆå„ç§æŠ“å–ä»»åŠ¡ï¼Œä¾‹å¦‚æ ¹æ®ç”¨æˆ·æŒ‡ä»¤æŠ“å–ç‰¹å®šç‰©å“ã€åœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œç‰©ä½“æ•´ç†ç­‰ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„å‘å±•å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Grasping is one of the most fundamental challenging capabilities in robotic manipulation, especially in unstructured, cluttered, and semantically diverse environments. Recent researches have increasingly explored language-guided manipulation, where robots not only perceive the scene but also interpret task-relevant natural language instructions. However, existing language-conditioned grasping methods typically rely on shallow fusion strategies, leading to limited semantic grounding and weak alignment between linguistic intent and visual grasp reasoning.In this work, we propose Language-Guided Grasp Detection (LGGD) with a coarse-to-fine learning paradigm for robotic manipulation. LGGD leverages CLIP-based visual and textual embeddings within a hierarchical cross-modal fusion pipeline, progressively injecting linguistic cues into the visual feature reconstruction process. This design enables fine-grained visual-semantic alignment and improves the feasibility of the predicted grasps with respect to task instructions. In addition, we introduce a language-conditioned dynamic convolution head (LDCH) that mixes multiple convolution experts based on sentence-level features, enabling instruction-adaptive coarse mask and grasp predictions. A final refinement module further enhances grasp consistency and robustness in complex scenes.Experiments on the OCID-VLG and Grasp-Anything++ datasets show that LGGD surpasses existing language-guided grasping methods, exhibiting strong generalization to unseen objects and diverse language queries. Moreover, deployment on a real robotic platform demonstrates the practical effectiveness of our approach in executing accurate, instruction-conditioned grasp actions. The code will be released publicly upon acceptance.

