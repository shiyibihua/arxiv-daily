---
layout: default
title: Sim2Real Reinforcement Learning for Soccer skills
---

# Sim2Real Reinforcement Learning for Soccer skills

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.12437" target="_blank" class="toolbar-btn">arXiv: 2512.12437v1</a>
    <a href="https://arxiv.org/pdf/2512.12437.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.12437v1" 
            onclick="toggleFavorite(this, '2512.12437v1', 'Sim2Real Reinforcement Learning for Soccer skills')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Jonathan Spraggett

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-13

**å¤‡æ³¨**: Undergrad Thesis

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè¯¾ç¨‹å­¦ä¹ å’Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºè®­ç»ƒäººå½¢æœºå™¨äººè¶³çƒæŠ€èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `äººå½¢æœºå™¨äºº` `è¯¾ç¨‹å­¦ä¹ ` `å¯¹æŠ—è¿åŠ¨å…ˆéªŒ` `è¿åŠ¨æ§åˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨äººå½¢æœºå™¨äººæ§åˆ¶ä»»åŠ¡ä¸­ï¼Œéš¾ä»¥é€‚åº”çœŸå®ç¯å¢ƒçš„å¤æ‚æ€§å’Œå®ç°è‡ªç„¶è¿åŠ¨ã€‚
2. è®ºæ–‡æå‡ºç»“åˆè¯¾ç¨‹å­¦ä¹ å’Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒï¼ˆAMPï¼‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæå‡ç­–ç•¥çš„åŠ¨æ€æ€§å’Œé€‚åº”æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è®­ç»ƒçš„è¸¢çƒã€è¡Œèµ°å’Œè·³è·ƒç­–ç•¥ä¼˜äºä»¥å¾€æ–¹æ³•ï¼Œä½†è¿ç§»åˆ°çœŸå®ç¯å¢ƒå¤±è´¥ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ›´é«˜æ•ˆã€æ›´æœ‰æ•ˆçš„æ–¹æ³•ï¼Œç”¨äºè®­ç»ƒäººå½¢æœºå™¨äººçš„æ§åˆ¶ç›¸å…³ä»»åŠ¡ï¼Œè¯¥æ–¹æ³•åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ã€‚ä¼ ç»Ÿçš„RLæ–¹æ³•åœ¨é€‚åº”çœŸå®ç¯å¢ƒã€å¤æ‚æ€§å’Œè‡ªç„¶è¿åŠ¨æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚æœ¬æ–‡æå‡ºçš„æ–¹æ³•é€šè¿‡ä½¿ç”¨è¯¾ç¨‹è®­ç»ƒå’Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒï¼ˆAMPï¼‰æŠ€æœ¯å…‹æœäº†è¿™äº›é™åˆ¶ã€‚ç»“æœè¡¨æ˜ï¼Œæ‰€å¼€å‘çš„ç”¨äºè¸¢çƒã€è¡Œèµ°å’Œè·³è·ƒçš„RLç­–ç•¥æ›´å…·åŠ¨æ€æ€§å’Œé€‚åº”æ€§ï¼Œå¹¶ä¸”ä¼˜äºä»¥å¾€çš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œå­¦ä¹ åˆ°çš„ç­–ç•¥ä»æ¨¡æ‹Ÿåˆ°çœŸå®ä¸–ç•Œçš„è¿ç§»å¹¶ä¸æˆåŠŸï¼Œçªå‡ºäº†å½“å‰RLæ–¹æ³•åœ¨å®Œå…¨é€‚åº”çœŸå®åœºæ™¯æ–¹é¢çš„å±€é™æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³äººå½¢æœºå™¨äººæ§åˆ¶ä»»åŠ¡ä¸­ï¼Œå¼ºåŒ–å­¦ä¹ ç­–ç•¥éš¾ä»¥é€‚åº”çœŸå®ç¯å¢ƒï¼ŒåŠ¨ä½œä¸å¤Ÿè‡ªç„¶æµç•…çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤æ‚ç¯å¢ƒå’Œè‡ªç„¶è¿åŠ¨æ–¹é¢çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œå¯¼è‡´æ¨¡æ‹Ÿç¯å¢ƒè®­ç»ƒçš„ç­–ç•¥éš¾ä»¥ç›´æ¥åº”ç”¨äºçœŸå®æœºå™¨äººã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è¯¾ç¨‹å­¦ä¹ é€æ­¥å¢åŠ è®­ç»ƒéš¾åº¦ï¼Œå¹¶å¼•å…¥å¯¹æŠ—è¿åŠ¨å…ˆéªŒï¼ˆAMPï¼‰æ¥å­¦ä¹ æ›´è‡ªç„¶çš„è¿åŠ¨æ¨¡å¼ã€‚é€šè¿‡è¯¾ç¨‹å­¦ä¹ ï¼Œæœºå™¨äººå¯ä»¥ä»ç®€å•çš„ä»»åŠ¡å¼€å§‹ï¼Œé€æ­¥æŒæ¡æ›´å¤æ‚çš„æŠ€èƒ½ã€‚AMPåˆ™é€šè¿‡æ¨¡ä»¿çœŸå®è¿åŠ¨æ•°æ®ï¼Œå¼•å¯¼æœºå™¨äººå­¦ä¹ æ›´é€¼çœŸçš„åŠ¨ä½œã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«æ¨¡æ‹Ÿç¯å¢ƒã€å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€è¯¾ç¨‹å­¦ä¹ æ¨¡å—å’Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒæ¨¡å—ã€‚é¦–å…ˆï¼Œåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•è®­ç»ƒæœºå™¨äººã€‚ç„¶åï¼Œè¯¾ç¨‹å­¦ä¹ æ¨¡å—æ ¹æ®æœºå™¨äººçš„å­¦ä¹ è¿›åº¦ï¼Œé€æ­¥å¢åŠ ä»»åŠ¡çš„éš¾åº¦ã€‚åŒæ—¶ï¼Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒæ¨¡å—åˆ©ç”¨çœŸå®è¿åŠ¨æ•°æ®ï¼Œè®­ç»ƒä¸€ä¸ªåˆ¤åˆ«å™¨æ¥åŒºåˆ†æœºå™¨äººç”Ÿæˆçš„è¿åŠ¨å’ŒçœŸå®è¿åŠ¨ï¼Œå¹¶åˆ©ç”¨åˆ¤åˆ«å™¨çš„æ¢¯åº¦æ¥æŒ‡å¯¼æœºå™¨äººçš„ç­–ç•¥å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†è¯¾ç¨‹å­¦ä¹ å’Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒç›¸ç»“åˆï¼Œç”¨äºäººå½¢æœºå™¨äººçš„å¼ºåŒ–å­¦ä¹ æ§åˆ¶ã€‚è¯¾ç¨‹å­¦ä¹ å¯ä»¥æœ‰æ•ˆåœ°å¼•å¯¼æœºå™¨äººå­¦ä¹ å¤æ‚çš„æŠ€èƒ½ï¼Œè€Œå¯¹æŠ—è¿åŠ¨å…ˆéªŒå¯ä»¥æé«˜æœºå™¨äººè¿åŠ¨çš„è‡ªç„¶æ€§å’ŒçœŸå®æ„Ÿã€‚è¿™ç§ç»“åˆä½¿å¾—æœºå™¨äººèƒ½å¤Ÿå­¦ä¹ åˆ°æ›´é²æ£’ã€æ›´è‡ªç„¶çš„æ§åˆ¶ç­–ç•¥ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­ï¼Œè¯¾ç¨‹å­¦ä¹ çš„å…·ä½“å®ç°æ–¹å¼æ˜¯é€æ­¥å¢åŠ ä»»åŠ¡çš„éš¾åº¦ï¼Œä¾‹å¦‚ï¼Œä»ç®€å•çš„ç«™ç«‹ä»»åŠ¡å¼€å§‹ï¼Œé€æ­¥è¿‡æ¸¡åˆ°è¡Œèµ°ã€è·‘æ­¥å’Œè·³è·ƒç­‰æ›´å¤æ‚çš„ä»»åŠ¡ã€‚å¯¹æŠ—è¿åŠ¨å…ˆéªŒæ¨¡å—ä½¿ç”¨ä¸€ä¸ªåˆ¤åˆ«å™¨ç½‘ç»œï¼Œè¯¥ç½‘ç»œè¾“å…¥æœºå™¨äººçš„è¿åŠ¨çŠ¶æ€ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªæ¦‚ç‡å€¼ï¼Œè¡¨ç¤ºè¯¥è¿åŠ¨æ˜¯çœŸå®çš„è¿˜æ˜¯ç”±æœºå™¨äººç”Ÿæˆçš„ã€‚åˆ¤åˆ«å™¨çš„æŸå¤±å‡½æ•°é‡‡ç”¨å¯¹æŠ—æŸå¤±ï¼Œé¼“åŠ±æœºå™¨äººç”Ÿæˆæ›´é€¼çœŸçš„è¿åŠ¨ã€‚å¼ºåŒ–å­¦ä¹ ç®—æ³•é‡‡ç”¨TRPOæˆ–PPOç­‰ç­–ç•¥æ¢¯åº¦ç®—æ³•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­éªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è®­ç»ƒçš„è¸¢çƒã€è¡Œèµ°å’Œè·³è·ƒç­–ç•¥æ¯”ä»¥å¾€æ–¹æ³•æ›´å…·åŠ¨æ€æ€§å’Œé€‚åº”æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæœºå™¨äººèƒ½å¤Ÿå®Œæˆæ›´å¤æ‚çš„è¿åŠ¨ï¼Œå¹¶ä¸”å¯¹ç¯å¢ƒå˜åŒ–çš„é²æ£’æ€§æ›´é«˜ã€‚ç„¶è€Œï¼Œæ¨¡æ‹Ÿåˆ°çœŸå®çš„è¿ç§»ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œè¡¨æ˜éœ€è¦è¿›ä¸€æ­¥ç ”ç©¶å¦‚ä½•ç¼©å°æ¨¡æ‹Ÿç¯å¢ƒå’ŒçœŸå®ç¯å¢ƒä¹‹é—´çš„å·®è·ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºäººå½¢æœºå™¨äººçš„è¿åŠ¨æ§åˆ¶ã€ä½“è‚²ç«æŠ€æœºå™¨äººã€ä»¥åŠå…¶ä»–éœ€è¦å¤æ‚è¿åŠ¨æŠ€èƒ½çš„æœºå™¨äººé¢†åŸŸã€‚é€šè¿‡æ¨¡æ‹Ÿç¯å¢ƒè®­ç»ƒï¼Œå¯ä»¥é™ä½çœŸå®æœºå™¨äººè®­ç»ƒçš„æˆæœ¬å’Œé£é™©ï¼ŒåŠ é€Ÿæœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºç¾éš¾æ•‘æ´ã€åŒ»ç–—è¾…åŠ©ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This thesis work presents a more efficient and effective approach to training control-related tasks for humanoid robots using Reinforcement Learning (RL). The traditional RL methods are limited in adapting to real-world environments, complexity, and natural motions, but the proposed approach overcomes these limitations by using curriculum training and Adversarial Motion Priors (AMP) technique. The results show that the developed RL policies for kicking, walking, and jumping are more dynamic, and adaptive, and outperformed previous methods. However, the transfer of the learned policy from simulation to the real world was unsuccessful, highlighting the limitations of current RL methods in fully adapting to real-world scenarios.

