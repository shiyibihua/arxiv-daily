---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-10-18
---

# cs.ROï¼ˆ2025-10-18ï¼‰

ğŸ“Š å…± **6** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (2)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251016281v1-do-what-you-say-steering-vision-language-action-models-via-runtime-r.html">Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification</a></td>
  <td>æå‡ºåŸºäºè¿è¡Œæ—¶æ¨ç†-è¡ŒåŠ¨å¯¹é½éªŒè¯çš„ç­–ç•¥å¼•å¯¼æ–¹æ³•ï¼Œæå‡VLAæ¨¡å‹åœ¨æœºå™¨äººä»»åŠ¡ä¸­çš„æ³›åŒ–æ€§ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.16281v1" onclick="toggleFavorite(this, '2510.16281v1', 'Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251016524v1-semi-peaucellier-linkage-and-differential-mechanism-for-linear-pinch.html">Semi-Peaucellier Linkage and Differential Mechanism for Linear Pinching and Self-Adaptive Grasping</a></td>
  <td>æå‡ºSP-Diffå¹³è¡Œå¤¹çˆªç³»ç»Ÿï¼Œé€šè¿‡åŠåæ¼”è¿æ†å’Œå·®åŠ¨æœºæ„å®ç°çº¿æ€§å¤¹å–å’Œè‡ªé€‚åº”æŠ“å–ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.16524v1" onclick="toggleFavorite(this, '2510.16524v1', 'Semi-Peaucellier Linkage and Differential Mechanism for Linear Pinching and Self-Adaptive Grasping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251016435v1-what-questions-should-robots-be-able-to-answer-a-dataset-of-user-que.html">What Questions Should Robots Be Able to Answer? A Dataset of User Questions for Explainable Robotics</a></td>
  <td>æ„å»ºé¢å‘å¯è§£é‡Šæœºå™¨äººçš„ç”¨æˆ·é—®é¢˜æ•°æ®é›†ï¼ŒåŠ©åŠ›æå‡äººæœºäº¤äº’èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.16435v1" onclick="toggleFavorite(this, '2510.16435v1', 'What Questions Should Robots Be Able to Answer? A Dataset of User Questions for Explainable Robotics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>4</td>
  <td><a href="./papers/251016617v1-mos-vla-a-vision-language-action-model-with-one-shot-skill-adaptatio.html">MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation</a></td>
  <td>MoS-VLAï¼šåŸºäºæŠ€èƒ½ç»„åˆçš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼Œå®ç°æœºå™¨äººå•æ ·æœ¬æŠ€èƒ½è¿ç§»</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.16617v1" onclick="toggleFavorite(this, '2510.16617v1', 'MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251016308v1-spot-sensing-augmented-trajectory-planning-via-obstacle-threat-model.html">SPOT: Sensing-augmented Trajectory Planning via Obstacle Threat Modeling</a></td>
  <td>SPOTï¼šåŸºäºéšœç¢ç‰©å¨èƒå»ºæ¨¡çš„æ„ŸçŸ¥å¢å¼ºæ— äººæœºè½¨è¿¹è§„åˆ’</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.16308v1" onclick="toggleFavorite(this, '2510.16308v1', 'SPOT: Sensing-augmented Trajectory Planning via Obstacle Threat Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>6</td>
  <td><a href="./papers/251016518v1-div-nav-open-vocabulary-spatial-relationships-for-multi-object-navig.html">DIV-Nav: Open-Vocabulary Spatial Relationships for Multi-Object Navigation</a></td>
  <td>DIV-Navï¼šåˆ©ç”¨å¼€æ”¾è¯æ±‡ç©ºé—´å…³ç³»è¿›è¡Œå¤šç›®æ ‡å¯¼èˆª</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.16518v1" onclick="toggleFavorite(this, '2510.16518v1', 'DIV-Nav: Open-Vocabulary Spatial Relationships for Multi-Object Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)