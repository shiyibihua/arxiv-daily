---
layout: default
title: Fast Trajectory Planner with a Reinforcement Learning-based Controller for Robotic Manipulators
---

# Fast Trajectory Planner with a Reinforcement Learning-based Controller for Robotic Manipulators

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.17381" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.17381v1</a>
  <a href="https://arxiv.org/pdf/2509.17381.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.17381v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.17381v1', 'Fast Trajectory Planner with a Reinforcement Learning-based Controller for Robotic Manipulators')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yongliang Wang, Hamidreza Kasaei

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-22

**Â§áÊ≥®**: Project page available at: https://sites.google.com/view/ftp4rm/home

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÊéßÂà∂Âô®ÁöÑÂø´ÈÄüËΩ®ËøπËßÑÂàíÂô®ÔºåÁî®‰∫éÊú∫Âô®‰∫∫Êìç‰ΩúËáÇÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ËøõË°åÂÆûÊó∂ÈÅøÈöú„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Êìç‰ΩúËáÇ` `ËΩ®ËøπËßÑÂàí` `Âº∫ÂåñÂ≠¶‰π†` `ËøëÁ´ØÁ≠ñÁï•‰ºòÂåñ` `ËßÜËßâ‰º∫Êúç`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËøêÂä®ËßÑÂàíÊñπÊ≥ïÂú®ÁîüÊàêÊú∫Âô®‰∫∫Êìç‰ΩúËáÇËΩ®ËøπÊó∂ÔºåÈÄöÂ∏∏ÈúÄË¶ÅÈ¢ùÂ§ñÁöÑËÆ°ÁÆóÈáèÊù•Ê±ÇËß£ËøêÂä®Â≠¶ÊàñÂä®ÂäõÂ≠¶ÊñπÁ®ãÔºåÊïàÁéáËæÉ‰Ωé„ÄÇ
2. ËØ•ËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁªìÂêàËßÜËßâË∑ØÂæÑËßÑÂàíÂíåÂº∫ÂåñÂ≠¶‰π†ÊéßÂà∂ÁöÑÂø´ÈÄüËΩ®ËøπËßÑÂàíÁ≥ªÁªüÔºåÂú®‰ªªÂä°Á©∫Èó¥ÂíåÂÖ≥ËäÇÁ©∫Èó¥ÂàÜÂà´ËøõË°åËßÑÂàíÂíåÈÅøÈöú„ÄÇ
3. ÈÄöËøáÊîπËøõPPOÁÆóÊ≥ïÔºåÈõÜÊàêÂä®‰ΩúÈõÜÊàêÂíåÁ≠ñÁï•ÂèçÈ¶àÔºåÊèêÂçá‰∫ÜÁÆóÊ≥ïÂú®Â§çÊùÇÁéØÂ¢É‰∏ãÁöÑÈÅøÈöúÊïàÁéáÂíåÁõÆÊ†áÂà∞ËææÁ≤æÂ∫¶ÔºåÂπ∂È™åËØÅ‰∫ÜÂÖ∂Âú®‰ªøÁúüÂíåÁúüÂÆûÁéØÂ¢É‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÈíàÂØπÊú∫Âô®‰∫∫Êìç‰ΩúËáÇÂú®ÈùûÁªìÊûÑÂåñÂíåÂ§çÊùÇÁéØÂ¢É‰∏≠ÁîüÊàêÊó†Á¢∞ÊíûËΩ®ËøπÁöÑÈöæÈ¢òÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÂø´ÈÄüËΩ®ËøπËßÑÂàíÁ≥ªÁªü„ÄÇËØ•Á≥ªÁªüÁªìÂêà‰∫ÜÂü∫‰∫éËßÜËßâÁöÑ‰ªªÂä°Á©∫Èó¥Ë∑ØÂæÑËßÑÂàíÂíåÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÂÖ≥ËäÇÁ©∫Èó¥ÈÅøÈöú„ÄÇÈ¶ñÂÖàÔºåÂà©Áî®Â§ßËßÑÊ®°Âø´ÈÄüÂàÜÂâ≤Ê®°ÂûãÔºàFSAÔºâÂíåBÊ†∑Êù°‰ºòÂåñÁöÑËøêÂä®Â≠¶Ë∑ØÂæÑÊêúÁ¥¢ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÂàõÊñ∞ÁöÑÂü∫‰∫éËßÜËßâÁöÑ‰ªªÂä°Á©∫Èó¥ËΩ®ËøπËßÑÂàíÂô®„ÄÇÂÖ∂Ê¨°ÔºåÈÄöËøáÈõÜÊàêÂä®‰ΩúÈõÜÊàêÔºàAEÔºâÂíåÁ≠ñÁï•ÂèçÈ¶àÔºàPFÔºâÊù•Â¢ûÂº∫ËøëÁ´ØÁ≠ñÁï•‰ºòÂåñÔºàPPOÔºâÁÆóÊ≥ïÔºå‰ªéËÄåÊòæËëóÊèêÈ´òÂÖ≥ËäÇÁ©∫Èó¥‰∏≠ÁõÆÊ†áÂà∞ËææÂíåÈÅøÈöúÁöÑÁ≤æÂ∫¶ÂíåÁ®≥ÂÆöÊÄß„ÄÇËøô‰∫õPPOÂ¢ûÂº∫ÂäüËÉΩÊèêÈ´ò‰∫ÜÁÆóÊ≥ïÂú®ÂêÑÁßçÊú∫Âô®‰∫∫‰ªªÂä°‰∏≠ÁöÑÈÄÇÂ∫îÊÄßÔºåÁ°Æ‰øùÊìç‰ΩúËáÇ‰∏ÄËá¥Âú∞ÊâßË°åÊù•Ëá™Á¨¨‰∏ÄÈÉ®ÂàÜÁöÑÂëΩ‰ª§ÔºåÂêåÊó∂ÊèêÈ´òÈÅøÈöúÊïàÁéáÂíåÂà∞ËææÁ≤æÂ∫¶„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPPOÂ¢ûÂº∫ÂäüËÉΩ‰ª•Âèä‰ªøÁúüÂà∞‰ªøÁúüÔºàSim-to-SimÔºâÂíå‰ªøÁúüÂà∞Áé∞ÂÆûÔºàSim-to-RealÔºâÁöÑËøÅÁßªÔºåÊúâÊïàÂú∞ÊèêÈ´ò‰∫ÜÂ§çÊùÇÂú∫ÊôØ‰∏≠Ê®°ÂûãÁöÑÈ≤ÅÊ£íÊÄßÂíåËßÑÂàíÂô®ÁöÑÊïàÁéáÔºå‰ΩøÊú∫Âô®‰∫∫ËÉΩÂ§üÂú®ÂèóÈòªÁéØÂ¢É‰∏≠ÊâßË°åÈÅøÈöúÂíåÂÆûÊó∂ËΩ®ËøπËßÑÂàí„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Êú∫Âô®‰∫∫Êìç‰ΩúËáÇÂú®Â§çÊùÇ„ÄÅÈùûÁªìÊûÑÂåñÁéØÂ¢É‰∏≠ËøõË°åÂø´ÈÄü„ÄÅÂÆûÊó∂ÁöÑÊó†Á¢∞ÊíûËΩ®ËøπËßÑÂàíÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ËÆ°ÁÆóÊàêÊú¨È´òÊòÇÔºåÈöæ‰ª•Êª°Ë∂≥ÂÆûÊó∂ÊÄßË¶ÅÊ±ÇÔºåÂπ∂‰∏îÂú®Â§çÊùÇÁéØÂ¢É‰∏≠È≤ÅÊ£íÊÄß‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜËΩ®ËøπËßÑÂàíÂàÜËß£‰∏∫‰∏§‰∏™Èò∂ÊÆµÔºöÈ¶ñÂÖàÂú®‰ªªÂä°Á©∫Èó¥Âà©Áî®ËßÜËßâ‰ø°ÊÅØËøõË°åÂÖ®Â±ÄË∑ØÂæÑËßÑÂàíÔºåÁÑ∂ÂêéÂú®ÂÖ≥ËäÇÁ©∫Èó¥Âà©Áî®Âº∫ÂåñÂ≠¶‰π†ËøõË°åÂ±ÄÈÉ®ÈÅøÈöúÂíåËΩ®Ëøπ‰ºòÂåñ„ÄÇËøôÁßçÂàÜËß£Èôç‰Ωé‰∫ÜÈóÆÈ¢òÁöÑÂ§çÊùÇÂ∫¶ÔºåÂπ∂ÂÖÅËÆ∏Âà©Áî®Âº∫ÂåñÂ≠¶‰π†ÁöÑËá™ÈÄÇÂ∫îËÉΩÂäõÊù•Â§ÑÁêÜÂ§çÊùÇÁéØÂ¢É„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Á≥ªÁªüÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Âü∫‰∫éËßÜËßâÁöÑ‰ªªÂä°Á©∫Èó¥ËΩ®ËøπËßÑÂàíÂô®ÔºöÂà©Áî®Âø´ÈÄüÂàÜÂâ≤Ê®°ÂûãÔºàFSAÔºâÊèêÂèñÁéØÂ¢É‰ø°ÊÅØÔºåÂπ∂ÁªìÂêàBÊ†∑Êù°‰ºòÂåñÁöÑËøêÂä®Â≠¶Ë∑ØÂæÑÊêúÁ¥¢ÁîüÊàêÂàùÂßãËΩ®Ëøπ„ÄÇ2) Âü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÂÖ≥ËäÇÁ©∫Èó¥ÊéßÂà∂Âô®Ôºö‰ΩøÁî®ÊîπËøõÁöÑËøëÁ´ØÁ≠ñÁï•‰ºòÂåñÔºàPPOÔºâÁÆóÊ≥ïÔºåÈÄöËøáÂä®‰ΩúÈõÜÊàêÔºàAEÔºâÂíåÁ≠ñÁï•ÂèçÈ¶àÔºàPFÔºâÊù•ÊèêÈ´òÈÅøÈöúÂíåÁõÆÊ†áÂà∞ËææÁöÑÁ≤æÂ∫¶ÂíåÁ®≥ÂÆöÊÄß„ÄÇ‰∏§‰∏™Ê®°ÂùóÂçèÂêåÂ∑•‰ΩúÔºåÂÆûÁé∞Âø´ÈÄü„ÄÅÈ≤ÅÊ£íÁöÑËΩ®ËøπËßÑÂàí„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) Â∞ÜËßÜËßâ‰ø°ÊÅØËûçÂÖ•ËΩ®ËøπËßÑÂàíÔºåÂà©Áî®FSAÂø´ÈÄüÊèêÂèñÁéØÂ¢É‰ø°ÊÅØ„ÄÇ2) ÊîπËøõPPOÁÆóÊ≥ïÔºåÈÄöËøáÂä®‰ΩúÈõÜÊàêÂíåÁ≠ñÁï•ÂèçÈ¶àÊòæËëóÊèêÂçá‰∫ÜÂº∫ÂåñÂ≠¶‰π†ÊéßÂà∂Âô®ÁöÑÊÄßËÉΩ„ÄÇ3) ÁªìÂêà‰ªªÂä°Á©∫Èó¥ËßÑÂàíÂíåÂÖ≥ËäÇÁ©∫Èó¥ÊéßÂà∂ÔºåÂÆûÁé∞‰∫ÜÂÖ®Â±ÄË∑ØÂæÑËßÑÂàíÂíåÂ±ÄÈÉ®ÈÅøÈöúÁöÑÊúâÊïàÂçèÂêå„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®‰ªªÂä°Á©∫Èó¥ËßÑÂàí‰∏≠Ôºå‰ΩøÁî®BÊ†∑Êù°Êõ≤Á∫ø‰ºòÂåñÂàùÂßãË∑ØÂæÑÔºå‰øùËØÅËΩ®ËøπÁöÑÂÖâÊªëÊÄß„ÄÇÂú®Âº∫ÂåñÂ≠¶‰π†ÊéßÂà∂‰∏≠ÔºåÂä®‰ΩúÈõÜÊàêÔºàAEÔºâÈÄöËøáÈõÜÊàêÂ§ö‰∏™Âä®‰ΩúÂª∫ËÆÆÊù•ÊèêÈ´òÊé¢Á¥¢ÊïàÁéáÔºåÁ≠ñÁï•ÂèçÈ¶àÔºàPFÔºâÂàôÂà©Áî®ÂéÜÂè≤Á≠ñÁï•‰ø°ÊÅØÊù•Á®≥ÂÆöËÆ≠ÁªÉËøáÁ®ã„ÄÇPPOÁÆóÊ≥ïÁöÑÂ•ñÂä±ÂáΩÊï∞ËÆæËÆ°ËÄÉËôë‰∫ÜÁõÆÊ†áÂà∞Ëææ„ÄÅÈÅøÈöúÂíåÂä®‰ΩúÊÉ©ÁΩöÁ≠âÂõ†Á¥†Ôºå‰ª•ÂºïÂØºÊú∫Âô®‰∫∫Â≠¶‰π†ÊúüÊúõÁöÑË°å‰∏∫„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑPPOÂ¢ûÂº∫ÁÆóÊ≥ïÂú®ÈÅøÈöúÊïàÁéáÂíåÁõÆÊ†áÂà∞ËææÁ≤æÂ∫¶ÊñπÈù¢Âùá‰ºò‰∫é‰º†ÁªüPPOÁÆóÊ≥ï„ÄÇ‰ªøÁúüÂÆûÈ™åÈ™åËØÅ‰∫ÜËØ•ÊñπÊ≥ïÂú®Â§çÊùÇÁéØÂ¢É‰∏ãÁöÑÈ≤ÅÊ£íÊÄßÔºåÂπ∂ÊàêÂäüÂÆûÁé∞‰∫Ü‰ªé‰ªøÁúüÂà∞Áé∞ÂÆûÁöÑËøÅÁßªÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÂèØË°åÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÔºàÂ¶ÇÊàêÂäüÁéá„ÄÅËΩ®ËøπÈïøÂ∫¶„ÄÅËøêË°åÊó∂Èó¥Á≠âÔºâÊú™Âú®ÊëòË¶Å‰∏≠ÊòéÁ°ÆÁªôÂá∫Ôºå‰ΩÜÂº∫Ë∞É‰∫ÜPPOÂ¢ûÂº∫Âú®ÊèêÂçáÊ®°ÂûãÈ≤ÅÊ£íÊÄßÂíåËßÑÂàíÂô®ÊïàÁéáÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂ∑•‰∏öÊú∫Âô®‰∫∫„ÄÅÊúçÂä°Êú∫Âô®‰∫∫Á≠âÈ¢ÜÂüüÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂú®Â§çÊùÇ„ÄÅÂä®ÊÄÅÁöÑÁéØÂ¢É‰∏≠ÂÆâÂÖ®„ÄÅÈ´òÊïàÂú∞ÂÆåÊàê‰ªªÂä°Ôºå‰æãÂ¶ÇËá™Âä®ÂåñË£ÖÈÖç„ÄÅÁâ©ÊµÅÊê¨Ëøê„ÄÅÂåªÁñóËæÖÂä©Á≠â„ÄÇÈÄöËøáÁªìÂêàËßÜËßâÊÑüÁü•ÂíåÂº∫ÂåñÂ≠¶‰π†ÊéßÂà∂ÔºåÊú∫Âô®‰∫∫ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÊú™Áü•ÁéØÂ¢ÉÔºåÊèêÈ´òÂÖ∂Êô∫ËÉΩÂåñÊ∞¥Âπ≥ÂíåÂ∫îÁî®ËåÉÂõ¥„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõËøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞Â§öÊú∫Âô®‰∫∫ÂçèÂêå„ÄÅ‰∫∫Êú∫Âçè‰ΩúÁ≠âÊõ¥Â§çÊùÇÁöÑÂú∫ÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Generating obstacle-free trajectories for robotic manipulators in unstructured and cluttered environments remains a significant challenge. Existing motion planning methods often require additional computational effort to generate the final trajectory by solving kinematic or dynamic equations. This paper highlights the strong potential of model-free reinforcement learning methods over model-based approaches for obstacle-free trajectory planning in joint space. We propose a fast trajectory planning system for manipulators that combines vision-based path planning in task space with reinforcement learning-based obstacle avoidance in joint space. We divide the framework into two key components. The first introduces an innovative vision-based trajectory planner in task space, leveraging the large-scale fast segment anything (FSA) model in conjunction with basis spline (B-spline)-optimized kinodynamic path searching. The second component enhances the proximal policy optimization (PPO) algorithm by integrating action ensembles (AE) and policy feedback (PF), which greatly improve precision and stability in goal-reaching and obstacle avoidance within the joint space. These PPO enhancements increase the algorithm's adaptability across diverse robotic tasks, ensuring consistent execution of commands from the first component by the manipulator, while also enhancing both obstacle avoidance efficiency and reaching accuracy. The experimental results demonstrate the effectiveness of PPO enhancements, as well as simulation-to-simulation (Sim-to-Sim) and simulation-to-reality (Sim-to-Real) transfer, in improving model robustness and planner efficiency in complex scenarios. These enhancements allow the robot to perform obstacle avoidance and real-time trajectory planning in obstructed environments. Project page available at: https://sites.google.com/view/ftp4rm/home

