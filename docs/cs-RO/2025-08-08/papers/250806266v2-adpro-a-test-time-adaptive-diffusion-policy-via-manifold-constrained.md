---
layout: default
title: ADPro: a Test-time Adaptive Diffusion Policy via Manifold-constrained Denoising and Task-aware Initialization for Robotic Manipulation
---

# ADPro: a Test-time Adaptive Diffusion Policy via Manifold-constrained Denoising and Task-aware Initialization for Robotic Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.06266" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.06266v2</a>
  <a href="https://arxiv.org/pdf/2508.06266.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.06266v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.06266v2', 'ADPro: a Test-time Adaptive Diffusion Policy via Manifold-constrained Denoising and Task-aware Initialization for Robotic Manipulation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zezeng Li, Rui Yang, Ruochen Chen, ZhongXuan Luo, Liming Chen

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-08 (Êõ¥Êñ∞: 2025-09-30)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Ëá™ÈÄÇÂ∫îÊâ©Êï£Á≠ñÁï•‰ª•Ëß£ÂÜ≥Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÁöÑÂä®‰ΩúÁîüÊàêÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ëá™ÈÄÇÂ∫îÊâ©Êï£Á≠ñÁï•` `Êú∫Âô®‰∫∫Êìç‰Ωú` `Âä®‰ΩúÁîüÊàê` `Âá†‰ΩïÁ∫¶Êùü` `‰ªªÂä°ÊÑüÁü•ÂàùÂßãÂåñ` `ÊÄßËÉΩÊèêÂçá` `Êô∫ËÉΩÊú∫Âô®‰∫∫`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÊâ©Êï£Á≠ñÁï•Âú®Âä®‰ΩúÁîüÊàêÊó∂Êú™ËÉΩÊúâÊïàÂà©Áî®Âá†‰ΩïÂíåÊéßÂà∂ÁªìÊûÑÁöÑÂÖàÈ™åÁü•ËØÜÔºåÂØºËá¥ÊÄßËÉΩÂèóÈôê„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑËá™ÈÄÇÂ∫îÊâ©Êï£Á≠ñÁï•ÈÄöËøáÂºïÂÖ•Âá†‰ΩïÊµÅÂΩ¢Á∫¶ÊùüÂíå‰ªªÂä°ÊÑüÁü•ÂàùÂßãÂåñÔºå‰ºòÂåñ‰∫ÜÂéªÂô™ËøáÁ®ãÔºåÊèêÂçá‰∫ÜÂä®‰ΩúÁîüÊàêÁöÑÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåADProÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÁõ∏ËæÉ‰∫éÂº∫Âü∫Á∫øÊèêÂçá‰∫ÜÊàêÂäüÁéáÂíåÈááÊ†∑ÊïàÁéáÔºåÊâßË°åÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü25%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êâ©Êï£Á≠ñÁï•ÊúÄËøëÊàê‰∏∫Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠Âº∫Â§ßÁöÑËßÜËßâËøêÂä®ÊéßÂà∂Âô®ÔºåÊèê‰æõÁ®≥ÂÆöÁöÑËÆ≠ÁªÉÂíåÂ§öÊ®°ÊÄÅÂä®‰ΩúÂª∫Ê®°„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Â∞ÜÂä®‰ΩúÁîüÊàêËßÜ‰∏∫Êó†Á∫¶ÊùüÁöÑÂéªÂô™ËøáÁ®ãÔºåÂøΩËßÜ‰∫ÜÂá†‰ΩïÂíåÊéßÂà∂ÁªìÊûÑÁöÑÂÖàÈ™åÁü•ËØÜ„ÄÇÊú¨ÊñáÊèêÂá∫Ëá™ÈÄÇÂ∫îÊâ©Êï£Á≠ñÁï•ÔºàADPÔºâÔºåÂú®ÊµãËØïÊó∂ÂºïÂÖ•Âá†‰ΩïÊµÅÂΩ¢Á∫¶ÊùüÂíå‰ªªÂä°ÊÑüÁü•ÂàùÂßãÂåñÔºå‰ºòÂåñÂéªÂô™ËøáÁ®ã„ÄÇADPÂÖºÂÆπÈ¢ÑËÆ≠ÁªÉÁöÑÊâ©Êï£Á≠ñÁï•ÔºåÊó†ÈúÄÈáçÊñ∞ËÆ≠ÁªÉÔºåËÉΩÂ§üÈíàÂØπÁâπÂÆö‰ªªÂä°ËøõË°åÈÄÇÂ∫îÔºå‰ªéËÄåÊèêÈ´òÂú®Êñ∞‰ªªÂä°ÂíåÁéØÂ¢É‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåADProÔºàADPÁöÑÂÆûÁé∞ÔºâÂú®RLBench„ÄÅCALVINÂíåÁúüÂÆûÊï∞ÊçÆÈõÜ‰∏äÊòæËëóÊèêÈ´ò‰∫ÜÊàêÂäüÁéáÂíåÈááÊ†∑ÊïàÁéáÔºåÊâßË°åÈÄüÂ∫¶ÊèêÂçáÈ´òËææ25%ÔºåÊàêÂäüÁéáÊèêÈ´ò9%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÊâ©Êï£Á≠ñÁï•Âú®Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠Âä®‰ΩúÁîüÊàêÊó∂Áº∫‰πèÂá†‰ΩïÂíåÊéßÂà∂ÁªìÊûÑÂÖàÈ™åÁü•ËØÜÁöÑÈóÆÈ¢òÔºåÂØºËá¥ÊÄßËÉΩ‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫Ëá™ÈÄÇÂ∫îÊâ©Êï£Á≠ñÁï•ÔºàADPÔºâÔºåÈÄöËøáÂºïÂÖ•Âá†‰ΩïÊµÅÂΩ¢Á∫¶ÊùüÂíå‰ªªÂä°ÊÑüÁü•ÂàùÂßãÂåñÊù•‰ºòÂåñÂéªÂô™ËøáÁ®ãÔºåÁ°Æ‰øùÁîüÊàêÁöÑÂä®‰Ωú‰∏é‰ªªÂä°Áõ∏ÂÖ≥„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöADPÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂá†‰ΩïÊµÅÂΩ¢Á∫¶ÊùüÊ®°ÂùóÂíå‰ªªÂä°ÊÑüÁü•ÂàùÂßãÂåñÊ®°Âùó„ÄÇÂâçËÄÖÈÄöËøáÂØπÂéªÂô™Êõ¥Êñ∞ËøõË°åÁ∫¶ÊùüÔºåÂêéËÄÖÂàôÈÄöËøáÁ≤óÁï•ÈÖçÂáÜÁîüÊàêÂàùÂßãÂô™Â£∞Âä®‰Ωú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöADPÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÂºïÂÖ•Âá†‰ΩïÊµÅÂΩ¢Á∫¶ÊùüÔºå‰ΩøÂæóÂéªÂô™ËøáÁ®ãÊ≤øÁùÄÊìç‰ΩúÊµÅÂΩ¢ÁöÑÊµãÂú∞Á∫øËøõË°åÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÂä®‰ΩúÁîüÊàêÁöÑÊúâÊïàÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÂü∫‰∫éÁõ∏ÂØπÂßøÊÄÅÁöÑÂá†‰ΩïÁ∫¶ÊùüÂíåÁ≤óÁï•ÈÖçÂáÜÁöÑ‰ªªÂä°ÊÑüÁü•ÂàùÂßãÂåñÔºåÁ°Æ‰øù‰∫ÜÁîüÊàêÁöÑÂä®‰ΩúÊõ¥ÂÖ∑ÈíàÂØπÊÄßÔºåÂáèÂ∞ë‰∫Ü‰∏çÂøÖË¶ÅÁöÑÊé¢Á¥¢„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåADProÂú®RLBench„ÄÅCALVINÂíåÁúüÂÆûÊï∞ÊçÆÈõÜ‰∏äÁõ∏ËæÉ‰∫éÂº∫Âü∫Á∫øÊèêÂçá‰∫ÜÊàêÂäüÁéáÂíåÈááÊ†∑ÊïàÁéáÔºåÊâßË°åÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü25%ÔºåÊàêÂäüÁéáÊèêÂçá‰∫Ü9‰∏™ÁôæÂàÜÁÇπÔºåÊòæÁ§∫Âá∫ÊòæËëóÁöÑÊÄßËÉΩ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Â∑•‰∏öÊú∫Âô®‰∫∫„ÄÅÊúçÂä°Êú∫Âô®‰∫∫ÂèäÂÖ∂‰ªñÈúÄË¶ÅÁ≤æÁ°ÆÊìç‰ΩúÁöÑËá™Âä®ÂåñÁ≥ªÁªü„ÄÇÈÄöËøáÊèêÈ´òÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÈÄÇÂ∫îËÉΩÂäõÔºåADPÊúâÊúõÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÊòæËëóÊèêÂçáÊìç‰ΩúÊïàÁéáÂíåÊàêÂäüÁéáÔºåÊé®Âä®Êô∫ËÉΩÊú∫Âô®‰∫∫ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Diffusion policies have recently emerged as a powerful class of visuomotor controllers for robot manipulation, offering stable training and expressive multi-modal action modeling. However, existing approaches typically treat action generation as an unconstrained denoising process, ignoring valuable a priori knowledge about geometry and control structure. In this work, we propose the Adaptive Diffusion Policy (ADP), a test-time adaptation method that introduces two key inductive biases into the diffusion. First, we embed a geometric manifold constraint that aligns denoising updates with task-relevant subspaces, leveraging the fact that the relative pose between the end-effector and target scene provides a natural gradient direction, and guiding denoising along the geodesic path of the manipulation manifold. Then, to reduce unnecessary exploration and accelerate convergence, we propose an analytically guided initialization: rather than sampling from an uninformative prior, we compute a rough registration between the gripper and target scenes to propose a structured initial noisy action. ADP is compatible with pre-trained diffusion policies and requires no retraining, enabling test-time adaptation that tailors the policy to specific tasks, thereby enhancing generalization across novel tasks and environments. Experiments on RLBench, CALVIN, and real-world datasets show that ADPro, an implementation of ADP, improves success rates, generalization, and sampling efficiency, achieving up to 25% faster execution and 9% points over strong diffusion baselines.

