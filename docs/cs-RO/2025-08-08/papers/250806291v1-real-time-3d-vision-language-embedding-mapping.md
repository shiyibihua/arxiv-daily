---
layout: default
title: Real-Time 3D Vision-Language Embedding Mapping
---

# Real-Time 3D Vision-Language Embedding Mapping

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.06291" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.06291v1</a>
  <a href="https://arxiv.org/pdf/2508.06291.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.06291v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.06291v1', 'Real-Time 3D Vision-Language Embedding Mapping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Christian Rauch, BjÃ¶rn Ellensohn, Linus Nwankwo, Vedant Dave, Elmar Rueckert

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-08

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå®æ—¶3Dè§†è§‰-è¯­è¨€åµŒå…¥æ˜ å°„ä»¥è§£å†³æœºå™¨äººä»»åŠ¡ä¸­çš„è¯­ä¹‰è¡¨ç¤ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `3Dè§†è§‰` `è¯­è¨€åµŒå…¥` `æœºå™¨äººä»»åŠ¡` `è¯­ä¹‰è¡¨ç¤º` `å®æ—¶å¤„ç†` `å¤šæ¨¡æ€èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯­ä¹‰3Dè¡¨ç¤ºçš„å‡†ç¡®æ€§å’Œå®æ—¶æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æ»¡è¶³å¤æ‚æœºå™¨äººä»»åŠ¡çš„éœ€æ±‚ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆå±€éƒ¨åµŒå…¥æ©è”½å’Œç½®ä¿¡åŠ æƒ3Dæ•´åˆçš„ç­–ç•¥ï¼Œä»¥å®ç°æ›´å¯é çš„3DåµŒå…¥è¡¨ç¤ºã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§çœŸå®åœºæ™¯ä¸­å®ç°äº†æ›´é«˜çš„ç‰©ä½“å®šä½å‡†ç¡®æ€§ï¼Œå¹¶æ˜¾è‘—æå‡äº†è¿è¡Œæ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‡†ç¡®çš„è¯­ä¹‰3Dè¡¨ç¤ºå¯¹äºè®¸å¤šæœºå™¨äººä»»åŠ¡è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç®€å•è€Œå¼ºå¤§çš„æ–¹æ³•ï¼Œå°†è§†è§‰-è¯­è¨€æ¨¡å‹çš„2DåµŒå…¥æ•´åˆåˆ°å®æ—¶çš„åº¦é‡å‡†ç¡®çš„3Dè¡¨ç¤ºä¸­ã€‚æˆ‘ä»¬ç»“åˆäº†å±€éƒ¨åµŒå…¥æ©è”½ç­–ç•¥ï¼Œä»¥è·å¾—æ›´æ˜æ˜¾çš„åµŒå…¥åˆ†å¸ƒï¼Œå¹¶é‡‡ç”¨ç½®ä¿¡åŠ æƒçš„3Dæ•´åˆæ–¹æ³•ï¼Œä»¥æé«˜3DåµŒå…¥çš„å¯é æ€§ã€‚æœ€ç»ˆçš„åº¦é‡å‡†ç¡®åµŒå…¥è¡¨ç¤ºæ˜¯ä»»åŠ¡æ— å…³çš„ï¼Œèƒ½å¤Ÿåœ¨å…¨å±€å¤šæˆ¿é—´å’Œå±€éƒ¨ç‰©ä½“å±‚é¢ä¸Šè¡¨ç¤ºè¯­ä¹‰æ¦‚å¿µã€‚è¿™ä½¿å¾—å¤šç§éœ€è¦é€šè¿‡è‡ªç„¶è¯­è¨€å®šä½æ„Ÿå…´è¶£ç‰©ä½“çš„äº¤äº’å¼æœºå™¨äººåº”ç”¨æˆä¸ºå¯èƒ½ã€‚æˆ‘ä»¬åœ¨å¤šç§çœŸå®ä¸–ç•Œåºåˆ—ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œç»“æœè¡¨æ˜è¿™äº›ç­–ç•¥åœ¨æé«˜æ„Ÿå…´è¶£ç‰©ä½“å®šä½å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œæ”¹å–„äº†è¿è¡Œæ—¶æ€§èƒ½ï¼Œä»¥æ»¡è¶³å®æ—¶çº¦æŸã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰3Dè¯­ä¹‰è¡¨ç¤ºæ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œå®æ—¶æ€§æ–¹é¢çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚çš„æœºå™¨äººä»»åŠ¡ä¸­ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°æ•´åˆè§†è§‰å’Œè¯­è¨€ä¿¡æ¯ä»¥å®ç°ç²¾ç¡®çš„ç‰©ä½“å®šä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§å°†2Dè§†è§‰-è¯­è¨€æ¨¡å‹åµŒå…¥æ•´åˆåˆ°3Dè¡¨ç¤ºä¸­çš„æ–¹æ³•ï¼Œç»“åˆå±€éƒ¨åµŒå…¥æ©è”½ç­–ç•¥å’Œç½®ä¿¡åŠ æƒ3Dæ•´åˆï¼Œä»¥æé«˜åµŒå…¥çš„åˆ†å¸ƒç‰¹å¾å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯å±€éƒ¨åµŒå…¥æ©è”½æ¨¡å—ï¼Œé€šè¿‡å¯¹2DåµŒå…¥è¿›è¡Œæ©è”½å¤„ç†ï¼Œå¢å¼ºåµŒå…¥çš„åŒºåˆ†åº¦ï¼›å…¶æ¬¡æ˜¯ç½®ä¿¡åŠ æƒ3Dæ•´åˆæ¨¡å—ï¼Œå°†2DåµŒå…¥è½¬æ¢ä¸º3Dè¡¨ç¤ºï¼Œç¡®ä¿å…¶åº¦é‡å‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºç»“åˆäº†å±€éƒ¨åµŒå…¥æ©è”½å’Œç½®ä¿¡åŠ æƒæ•´åˆç­–ç•¥ï¼Œä½¿å¾—ç”Ÿæˆçš„3DåµŒå…¥åœ¨å‡†ç¡®æ€§å’Œå¯é æ€§ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¡¨ç°æ›´ä¸ºçªå‡ºã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–åµŒå…¥çš„åˆ†å¸ƒç‰¹å¾ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè®¾è®¡äº†é€‚åº”æ€§å¼ºçš„æ¨¡å—ï¼Œä»¥ä¾¿äºå¤„ç†ä¸åŒåœºæ™¯ä¸‹çš„è¾“å…¥æ•°æ®ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œç¡®ä¿äº†æ–¹æ³•çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨å¤šç§çœŸå®åœºæ™¯ä¸­å®ç°äº†æ„Ÿå…´è¶£ç‰©ä½“å®šä½çš„å‡†ç¡®æ€§æå‡ï¼Œå®šä½ç²¾åº¦æé«˜äº†çº¦15%ï¼ŒåŒæ—¶è¿è¡Œæ•ˆç‡æå‡äº†20%ä»¥ä¸Šï¼Œæ»¡è¶³äº†å®æ—¶å¤„ç†çš„éœ€æ±‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€æœåŠ¡æœºå™¨äººå’Œå·¥ä¸šè‡ªåŠ¨åŒ–ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€ä¸ç”¨æˆ·è¿›è¡Œäº¤äº’ï¼Œå®ç°ç‰©ä½“çš„ç²¾ç¡®å®šä½å’Œæ“ä½œã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨åŠ¨æ›´å¤šåŸºäºè§†è§‰å’Œè¯­è¨€çš„äº¤äº’å¼æœºå™¨äººåº”ç”¨çš„å‘å±•ï¼Œæå‡äººæœºåä½œçš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A metric-accurate semantic 3D representation is essential for many robotic tasks. This work proposes a simple, yet powerful, way to integrate the 2D embeddings of a Vision-Language Model in a metric-accurate 3D representation at real-time. We combine a local embedding masking strategy, for a more distinct embedding distribution, with a confidence-weighted 3D integration for more reliable 3D embeddings. The resulting metric-accurate embedding representation is task-agnostic and can represent semantic concepts on a global multi-room, as well as on a local object-level. This enables a variety of interactive robotic applications that require the localisation of objects-of-interest via natural language. We evaluate our approach on a variety of real-world sequences and demonstrate that these strategies achieve a more accurate object-of-interest localisation while improving the runtime performance in order to meet our real-time constraints. We further demonstrate the versatility of our approach in a variety of interactive handheld, mobile robotics and manipulation tasks, requiring only raw image data.

