---
layout: default
title: Bootstrap Dynamic-Aware 3D Visual Representation for Scalable Robot Learning
---

# Bootstrap Dynamic-Aware 3D Visual Representation for Scalable Robot Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.00074" target="_blank" class="toolbar-btn">arXiv: 2512.00074v2</a>
    <a href="https://arxiv.org/pdf/2512.00074.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.00074v2" 
            onclick="toggleFavorite(this, '2512.00074v2', 'Bootstrap Dynamic-Aware 3D Visual Representation for Scalable Robot Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Qiwei Liang, Boyang Cai, Minghao Lai, Sitong Zhuang, Tao Lin, Yan Qin, Yixuan Ye, Jiaming Liang, Renjing Xu

**ÂàÜÁ±ª**: cs.RO, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-25 (Êõ¥Êñ∞: 2025-12-04)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://kolakivy.github.io/AFRO/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**AFROÔºöÁî®‰∫éÂèØÊâ©Â±ïÊú∫Âô®‰∫∫Â≠¶‰π†ÁöÑÂä®ÊÄÅÊÑüÁü•3DËßÜËßâË°®ÂæÅËá™ÁõëÁù£Ê°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `3DËßÜËßâË°®ÂæÅÂ≠¶‰π†` `Êú∫Âô®‰∫∫Â≠¶‰π†` `Âä®ÊÄÅÂª∫Ê®°` `Ëá™ÁõëÁù£Â≠¶‰π†` `Êâ©Êï£Ê®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ3DËßÜËßâÈ¢ÑËÆ≠ÁªÉÊñπÊ≥ïÁº∫‰πèÂØπÊú∫Âô®‰∫∫Êìç‰Ωú‰∏≠Áä∂ÊÄÅ-Âä®‰Ωú-Áä∂ÊÄÅÂä®ÂäõÂ≠¶ÁöÑÂª∫Ê®°Ôºå‰∏îÂá†‰ΩïÈáçÂª∫Â≠òÂú®ÂÜó‰Ωô„ÄÇ
2. AFROÈÄöËøáÂ∞ÜÁä∂ÊÄÅÈ¢ÑÊµãÂª∫Ê®°‰∏∫Êâ©Êï£ËøáÁ®ãÔºåËÅîÂêàÂ≠¶‰π†ÂâçÂêëÂíåÈÄÜÂêëÂä®ÂäõÂ≠¶Ôºå‰ªéËÄåÂ≠¶‰π†Âä®ÊÄÅÊÑüÁü•ÁöÑ3DË°®ÂæÅ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåAFROÊòæËëóÊèêÂçá‰∫ÜÊú∫Âô®‰∫∫Êìç‰ΩúÁöÑÊàêÂäüÁéáÔºåÂπ∂Âú®Ê®°ÊãüÂíåÁúüÂÆû‰∏ñÁïå‰ªªÂä°‰∏≠‰ºò‰∫éÁé∞ÊúâÈ¢ÑËÆ≠ÁªÉÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂΩìÂâç3DËßÜËßâÈ¢ÑËÆ≠ÁªÉÊñπÊ≥ïÂú®ËØÜÂà´ÂíåÂàÜÂâ≤‰∏äË°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂú®Êú∫Âô®‰∫∫Êìç‰ΩúÊñπÈù¢Ë°®Áé∞Ê¨†‰Ω≥„ÄÇËøôÁßçÂ∑ÆË∑ùÂΩíÂõ†‰∫éÁº∫‰πèÁä∂ÊÄÅ-Âä®‰Ωú-Áä∂ÊÄÅÂä®ÂäõÂ≠¶Âª∫Ê®°‰ª•ÂèäÊòæÂºèÂá†‰ΩïÈáçÂª∫ÁöÑ‰∏çÂøÖË¶ÅÂÜó‰Ωô„ÄÇËÆ∫ÊñáÊèêÂá∫‰∫ÜAFROÔºå‰∏Ä‰∏™Ëá™ÁõëÁù£Ê°ÜÊû∂ÔºåÊó†ÈúÄÂä®‰ΩúÊàñÈáçÂª∫ÁõëÁù£Âç≥ÂèØÂ≠¶‰π†Âä®ÊÄÅÊÑüÁü•ÁöÑ3DË°®ÂæÅ„ÄÇAFROÂ∞ÜÁä∂ÊÄÅÈ¢ÑÊµãËßÜ‰∏∫ÁîüÊàêÊâ©Êï£ËøáÁ®ãÔºåÂπ∂Âú®ÂÖ±‰∫´ÊΩúÂú®Á©∫Èó¥‰∏≠ËÅîÂêàÂª∫Ê®°ÂâçÂêëÂíåÈÄÜÂêëÂä®ÂäõÂ≠¶Ôºå‰ª•ÊçïËé∑Âõ†ÊûúËΩ¨Êç¢ÁªìÊûÑ„ÄÇ‰∏∫‰∫ÜÈò≤Ê≠¢Âä®‰ΩúÂ≠¶‰π†‰∏≠ÁöÑÁâπÂæÅÊ≥ÑÈú≤ÔºåÈááÁî®‰∫ÜÁâπÂæÅÂ∑ÆÂàÜÂíåÈÄÜ‰∏ÄËá¥ÊÄßÁõëÁù£Ôºå‰ªéËÄåÊèêÈ´ò‰∫ÜËßÜËßâÁâπÂæÅÁöÑË¥®ÈáèÂíåÁ®≥ÂÆöÊÄß„ÄÇÁªìÂêàDiffusion PolicyÔºåAFROÂú®16‰∏™Ê®°ÊãüÂíå4‰∏™ÁúüÂÆû‰∏ñÁïå‰ªªÂä°‰∏≠ÊòæËëóÊèêÈ´ò‰∫ÜÊìç‰ΩúÊàêÂäüÁéáÔºå‰ºò‰∫éÁé∞ÊúâÁöÑÈ¢ÑËÆ≠ÁªÉÊñπÊ≥ï„ÄÇËØ•Ê°ÜÊû∂ËøòÈöèÁùÄÊï∞ÊçÆÈáèÂíå‰ªªÂä°Â§çÊùÇÊÄßÁöÑÂ¢ûÂä†ËÄåË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÂèØÊâ©Â±ïÊÄß„ÄÇÂÆöÊÄßÂèØËßÜÂåñË°®ÊòéÔºåAFROÂ≠¶‰π†‰∫ÜËØ≠‰πâ‰∏∞ÂØå„ÄÅÂå∫ÂàÜÊÄßÂº∫ÁöÑÁâπÂæÅÔºå‰∏∫Êú∫Âô®‰∫∫ÊäÄÊúØ‰∏≠ÁöÑ3DË°®ÂæÅÂ≠¶‰π†Êèê‰æõ‰∫Ü‰∏ÄÁßçÊúâÊïàÁöÑÈ¢ÑËÆ≠ÁªÉËß£ÂÜ≥ÊñπÊ°à„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞Êúâ3DËßÜËßâÈ¢ÑËÆ≠ÁªÉÊñπÊ≥ïÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠Ë°®Áé∞‰∏ç‰Ω≥Ôºå‰∏ªË¶ÅÂéüÂõ†ÊòØÂÆÉ‰ª¨ÂøΩÁï•‰∫ÜÊú∫Âô®‰∫∫Êìç‰ΩúËøáÁ®ã‰∏≠ÁöÑÁä∂ÊÄÅËΩ¨ÁßªÂä®ÂäõÂ≠¶ÔºåÂπ∂‰∏î‰æùËµñ‰∫éÊòæÂºèÁöÑÂá†‰ΩïÈáçÂª∫ÔºåËøôÂºïÂÖ•‰∫Ü‰∏çÂøÖË¶ÅÁöÑÂÜó‰Ωô‰ø°ÊÅØ„ÄÇËøô‰∫õÊñπÊ≥ïÊó†Ê≥ïÊúâÊïàÂú∞ÊçïÊçâÊú∫Âô®‰∫∫‰∏éÁéØÂ¢É‰∫§‰∫íÁöÑÂõ†ÊûúÂÖ≥Á≥ªÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®Â§çÊùÇÊìç‰Ωú‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöAFROÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáËá™ÁõëÁù£Â≠¶‰π†ÁöÑÊñπÂºèÔºåËÆ©Ê®°ÂûãÂ≠¶‰π†Âà∞ËÉΩÂ§üÊÑüÁü•ÁéØÂ¢ÉÂä®ÊÄÅÂèòÂåñÁöÑ3DËßÜËßâË°®ÂæÅ„ÄÇÂÆÉÂ∞ÜÁä∂ÊÄÅÈ¢ÑÊµãÂª∫Ê®°‰∏∫‰∏Ä‰∏™ÁîüÊàêÊâ©Êï£ËøáÁ®ãÔºåÂπ∂ÂêåÊó∂Â≠¶‰π†ÂâçÂêëÂíåÈÄÜÂêëÂä®ÂäõÂ≠¶Ê®°Âûã„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÊ®°ÂûãÂèØ‰ª•Â≠¶‰π†Âà∞Áä∂ÊÄÅ‰πãÈó¥ÁöÑÂõ†ÊûúÂÖ≥Á≥ªÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÈ¢ÑÊµãÊú∫Âô®‰∫∫ÁöÑË°å‰∏∫„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAFROÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) 3DËßÜËßâÁºñÁ†ÅÂô®ÔºöÂ∞ÜÂéüÂßã3DËßÜËßâËæìÂÖ•Ôºà‰æãÂ¶ÇÁÇπ‰∫ëÊàñ‰ΩìÁ¥†ÔºâÁºñÁ†Å‰∏∫ÊΩúÂú®ÁâπÂæÅÂêëÈáè„ÄÇ2) ÂâçÂêëÂä®ÂäõÂ≠¶Ê®°ÂûãÔºöÈ¢ÑÊµãÁªôÂÆöÂΩìÂâçÁä∂ÊÄÅÂíåÂä®‰ΩúÁöÑ‰∏ã‰∏Ä‰∏™Áä∂ÊÄÅ„ÄÇ3) ÈÄÜÂêëÂä®ÂäõÂ≠¶Ê®°ÂûãÔºöÈ¢ÑÊµãÁªôÂÆöÂΩìÂâçÁä∂ÊÄÅÂíå‰∏ã‰∏Ä‰∏™Áä∂ÊÄÅÁöÑÂä®‰Ωú„ÄÇ4) Êâ©Êï£Ê®°ÂûãÔºöÁî®‰∫éÂª∫Ê®°Áä∂ÊÄÅËΩ¨ÁßªÁöÑÊ¶ÇÁéáÂàÜÂ∏ÉÔºåÂπ∂ÁîüÊàêÊñ∞ÁöÑÁä∂ÊÄÅ„ÄÇ5) ÁâπÂæÅÂ∑ÆÂàÜÊ®°ÂùóÔºöÁî®‰∫éÈò≤Ê≠¢Âä®‰ΩúÂ≠¶‰π†‰∏≠ÁöÑÁâπÂæÅÊ≥ÑÈú≤„ÄÇ6) ÈÄÜ‰∏ÄËá¥ÊÄßÁõëÁù£Ê®°ÂùóÔºöÁî®‰∫éÊèêÈ´òËßÜËßâÁâπÂæÅÁöÑË¥®ÈáèÂíåÁ®≥ÂÆöÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAFROÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÂºïÂÖ•‰∫ÜÂä®ÊÄÅÊÑüÁü•ÁöÑ3DËßÜËßâË°®ÂæÅÂ≠¶‰π†ÔºåËÉΩÂ§üÊõ¥Â•ΩÂú∞ÊçïÊçâÊú∫Âô®‰∫∫Êìç‰ΩúËøáÁ®ã‰∏≠ÁöÑÁä∂ÊÄÅËΩ¨ÁßªÂä®ÂäõÂ≠¶„ÄÇ2) ‰ΩøÁî®ÁîüÊàêÊâ©Êï£Ê®°ÂûãÊù•Âª∫Ê®°Áä∂ÊÄÅËΩ¨ÁßªÁöÑÊ¶ÇÁéáÂàÜÂ∏ÉÔºå‰ªéËÄåËÉΩÂ§üÁîüÊàêÊõ¥Âä†ÁúüÂÆûÂíåÂ§öÊ†∑ÂåñÁöÑÁä∂ÊÄÅ„ÄÇ3) ÊèêÂá∫‰∫ÜÁâπÂæÅÂ∑ÆÂàÜÂíåÈÄÜ‰∏ÄËá¥ÊÄßÁõëÁù£ÊñπÊ≥ïÔºåÊúâÊïàÂú∞Èò≤Ê≠¢‰∫ÜÂä®‰ΩúÂ≠¶‰π†‰∏≠ÁöÑÁâπÂæÅÊ≥ÑÈú≤ÔºåÊèêÈ´ò‰∫ÜËßÜËßâÁâπÂæÅÁöÑË¥®ÈáèÂíåÁ®≥ÂÆöÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAFRO‰ΩøÁî®TransformerÁΩëÁªú‰Ωú‰∏∫3DËßÜËßâÁºñÁ†ÅÂô®ÔºåÂπ∂‰ΩøÁî®Êâ©Êï£Ê®°ÂûãÊù•Âª∫Ê®°Áä∂ÊÄÅËΩ¨ÁßªÁöÑÊ¶ÇÁéáÂàÜÂ∏É„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÂâçÂêëÂä®ÂäõÂ≠¶È¢ÑÊµãÊçüÂ§±„ÄÅÈÄÜÂêëÂä®ÂäõÂ≠¶È¢ÑÊµãÊçüÂ§±„ÄÅÊâ©Êï£Ê®°ÂûãÊçüÂ§±ÂíåÈÄÜ‰∏ÄËá¥ÊÄßÊçüÂ§±„ÄÇÁâπÂæÅÂ∑ÆÂàÜÊ®°ÂùóÈÄöËøáËÆ°ÁÆóÂΩìÂâçÁä∂ÊÄÅÂíå‰∏ã‰∏Ä‰∏™Áä∂ÊÄÅÁöÑÁâπÂæÅÂ∑ÆÂºÇÊù•ÊèêÂèñÂä®‰ΩúÁõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØ„ÄÇÈÄÜ‰∏ÄËá¥ÊÄßÁõëÁù£Ê®°ÂùóÈÄöËøáÁ∫¶ÊùüÂâçÂêëÂíåÈÄÜÂêëÂä®ÂäõÂ≠¶Ê®°ÂûãÁöÑËæìÂá∫‰∏ÄËá¥ÊÄßÊù•ÊèêÈ´òËßÜËßâÁâπÂæÅÁöÑË¥®Èáè„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

AFROÂú®16‰∏™Ê®°Êãü‰ªªÂä°Âíå4‰∏™ÁúüÂÆû‰∏ñÁïå‰ªªÂä°‰∏≠ËøõË°å‰∫ÜËØÑ‰º∞ÔºåÁªìÊûúË°®ÊòéÔºåAFROÊòæËëóÊèêÈ´ò‰∫ÜÊú∫Âô®‰∫∫Êìç‰ΩúÁöÑÊàêÂäüÁéáÔºå‰ºò‰∫éÁé∞ÊúâÁöÑÈ¢ÑËÆ≠ÁªÉÊñπÊ≥ï„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∫õ‰ªªÂä°‰∏≠ÔºåAFROÁöÑÊàêÂäüÁéáÊØîÁé∞ÊúâÊñπÊ≥ïÊèêÈ´ò‰∫Ü20%‰ª•‰∏ä„ÄÇÊ≠§Â§ñÔºåAFROËøòË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÂèØÊâ©Â±ïÊÄßÔºåËÉΩÂ§üÈöèÁùÄÊï∞ÊçÆÈáèÂíå‰ªªÂä°Â§çÊùÇÂ∫¶ÁöÑÂ¢ûÂä†ËÄå‰∏çÊñ≠ÊèêÂçáÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

AFROÊ°ÜÊû∂ÂèØÂ∫îÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°Ôºå‰æãÂ¶ÇÁâ©‰ΩìÊäìÂèñ„ÄÅË£ÖÈÖç„ÄÅÂØºËà™Á≠â„ÄÇÈÄöËøáÂ≠¶‰π†Âä®ÊÄÅÊÑüÁü•ÁöÑ3DËßÜËßâË°®ÂæÅÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÈ¢ÑÊµãÁéØÂ¢ÉÁöÑÂèòÂåñÔºå‰ªéËÄåÊèêÈ´òÊìç‰ΩúÁöÑÊàêÂäüÁéáÂíåÈ≤ÅÊ£íÊÄß„ÄÇËØ•Á†îÁ©∂ÂØπ‰∫éÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÂú®Â∑•‰∏öËá™Âä®Âåñ„ÄÅÂåªÁñó‰øùÂÅ•„ÄÅÂÆ∂Â∫≠ÊúçÂä°Á≠âÈ¢ÜÂüüÁöÑÂ∫îÁî®ÂÖ∑ÊúâÈáçË¶ÅÊÑè‰πâ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Despite strong results on recognition and segmentation, current 3D visual pre-training methods often underperform on robotic manipulation. We attribute this gap to two factors: the lack of state-action-state dynamics modeling and the unnecessary redundancy of explicit geometric reconstruction. We introduce AFRO, a self-supervised framework that learns dynamics-aware 3D representations without action or reconstruction supervision. AFRO casts state prediction as a generative diffusion process and jointly models forward and inverse dynamics in a shared latent space to capture causal transition structure. To prevent feature leakage in action learning, we employ feature differencing and inverse-consistency supervision, improving the quality and stability of visual features. When combined with Diffusion Policy, AFRO substantially increases manipulation success rates across 16 simulated and 4 real-world tasks, outperforming existing pre-training approaches. The framework also scales favorably with data volume and task complexity. Qualitative visualizations indicate that AFRO learns semantically rich, discriminative features, offering an effective pre-training solution for 3D representation learning in robotics. Project page: https://kolakivy.github.io/AFRO/

