---
layout: default
title: Efficient Greedy Algorithms for Feature Selection in Robot Visual Localization
---

# Efficient Greedy Algorithms for Feature Selection in Robot Visual Localization

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.20894" target="_blank" class="toolbar-btn">arXiv: 2511.20894v1</a>
    <a href="https://arxiv.org/pdf/2511.20894.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.20894v1" 
            onclick="toggleFavorite(this, '2511.20894v1', 'Efficient Greedy Algorithms for Feature Selection in Robot Visual Localization')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Vivek Pandey, Amirhossein Mollaei, Nader Motee

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-25

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫È´òÊïàË¥™Â©™ÁÆóÊ≥ïÔºåÂä†ÈÄüÊú∫Âô®‰∫∫ËßÜËßâÂÆö‰Ωç‰∏≠ÁöÑÁâπÂæÅÈÄâÊã©**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫ÂÆö‰Ωç` `ËßÜËßâÁâπÂæÅÈÄâÊã©` `Ë¥™Â©™ÁÆóÊ≥ï` `Ëá™‰∏ªÂØºËà™` `ËÆ°ÁÆóÊïàÁéá`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜËßâÂÆö‰ΩçÊñπÊ≥ïÂ§ÑÁêÜÂ§ßÈáèÂÜó‰ΩôÁâπÂæÅÔºåÂØºËá¥ËÆ°ÁÆóÂª∂ËøüÂíåÊïàÁéá‰Ωé‰∏ãÔºåÈöæ‰ª•Êª°Ë∂≥ÂÆûÊó∂ÊÄßÈúÄÊ±Ç„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏§ÁßçÂø´ÈÄü‰∏îÂÜÖÂ≠òÈ´òÊïàÁöÑË¥™Â©™ÁâπÂæÅÈÄâÊã©ÁÆóÊ≥ïÔºåÊó®Âú®ÂÆûÊó∂ËØÑ‰º∞ËßÜËßâÁâπÂæÅÂØπÂÆö‰ΩçÁöÑÊïàÁî®„ÄÇ
3. ËØ•ÊñπÊ≥ïÂú®Èôç‰ΩéËÆ°ÁÆóÂíåÂÜÖÂ≠òÂ§çÊùÇÂ∫¶ÁöÑÂêåÊó∂ÔºåÂÆûÁé∞‰∫ÜËÆ°ÁÆóÊïàÁéáÂíåÂÆö‰ΩçÁ≤æÂ∫¶‰πãÈó¥ÁöÑËâØÂ•ΩÂπ≥Ë°°„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú∫Âô®‰∫∫ÂÆö‰ΩçÊòØÊú™Áü•ÁéØÂ¢É‰∏≠Ëá™‰∏ªÂØºËà™ÁöÑÂÖ≥ÈîÆÁªÑÊàêÈÉ®ÂàÜ„ÄÇÂú®ÂêÑÁßç‰º†ÊÑüÊñπÂºè‰∏≠ÔºåÊù•Ëá™Áõ∏Êú∫ÁöÑËßÜËßâËæìÂÖ•Ëµ∑ÁùÄÊ†∏ÂøÉ‰ΩúÁî®Ôºå‰ΩøÊú∫Âô®‰∫∫ËÉΩÂ§üÈÄöËøáË∑üË∏™ÂõæÂÉèÂ∏ß‰∏≠ÁöÑÁÇπÁâπÂæÅÊù•‰º∞ËÆ°ÂÖ∂‰ΩçÁΩÆ„ÄÇÁÑ∂ËÄåÔºåÂõæÂÉèÂ∏ßÈÄöÂ∏∏ÂåÖÂê´Â§ßÈáèÁâπÂæÅÔºåÂÖ∂‰∏≠ËÆ∏Â§öÁâπÂæÅÂØπ‰∫éÂÆö‰ΩçËÄåË®ÄÊòØÂÜó‰ΩôÊàñÊó†‰ø°ÊÅØÁöÑ„ÄÇÂ§ÑÁêÜÊâÄÊúâÁâπÂæÅ‰ºöÂºïÂÖ•ÊòæËëóÁöÑËÆ°ÁÆóÂª∂ËøüÂíå‰ΩéÊïàÁéá„ÄÇËøô‰øÉ‰ΩøÊàë‰ª¨ÈúÄË¶ÅÊô∫ËÉΩÁâπÂæÅÈÄâÊã©ÔºåËØÜÂà´Âú®È¢ÑÊµãËåÉÂõ¥ÂÜÖÂØπÂÆö‰ΩçÊúÄÊúâÁî®ÁöÑÁâπÂæÅÂ≠êÈõÜ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏§ÁßçÂø´ÈÄü‰∏îÂÜÖÂ≠òÈ´òÊïàÁöÑÁâπÂæÅÈÄâÊã©ÁÆóÊ≥ïÔºå‰ΩøÊú∫Âô®‰∫∫ËÉΩÂ§üÂÆûÊó∂‰∏ªÂä®ËØÑ‰º∞ËßÜËßâÁâπÂæÅÁöÑÊïàÁî®„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Èôç‰ΩéÊó∂Èó¥ÂíåÂÜÖÂ≠òÂ§çÊùÇÂ∫¶ÁöÑÂêåÊó∂ÔºåÂú®ËÆ°ÁÆóÊïàÁéáÂíåÂÆö‰ΩçÁ≤æÂ∫¶‰πãÈó¥ÂÆûÁé∞‰∫ÜËâØÂ•ΩÁöÑÊùÉË°°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú∫Âô®‰∫∫ËßÜËßâÂÆö‰Ωç‰∏≠ÔºåÂ¶Ç‰Ωï‰ªéÂ§ßÈáèÂõæÂÉèÁâπÂæÅ‰∏≠ÈÄâÊã©ÊúÄÂÖ∑‰ø°ÊÅØÈáèÁöÑÁâπÂæÅÂ≠êÈõÜÔºå‰ª•Âú®‰øùËØÅÂÆö‰ΩçÁ≤æÂ∫¶ÁöÑÂâçÊèê‰∏ãÔºåÈôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÂíåÂÜÖÂ≠òÂç†Áî®ÔºåÂÆûÁé∞ÂÆûÊó∂ÂÆö‰ΩçÔºüÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ËÆ°ÁÆóÈáèÂ§ßÔºåÂÜÖÂ≠òÈúÄÊ±ÇÈ´òÔºåÈöæ‰ª•Êª°Ë∂≥ÂÆûÊó∂ÊÄßË¶ÅÊ±Ç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØËÆæËÆ°È´òÊïàÁöÑË¥™Â©™ÁÆóÊ≥ïÔºåÈÄöËøáËø≠‰ª£Âú∞ÈÄâÊã©ÂØπÂÆö‰ΩçÁ≤æÂ∫¶Ë¥°ÁåÆÊúÄÂ§ßÁöÑÁâπÂæÅÔºåÈÄêÊ≠•ÊûÑÂª∫ÊúÄ‰ºòÁâπÂæÅÂ≠êÈõÜ„ÄÇË¥™Â©™ÁÆóÊ≥ïÁöÑ‰ºòÂäøÂú®‰∫éÂÖ∂ËÆ°ÁÆóÂ§çÊùÇÂ∫¶ËæÉ‰ΩéÔºåÊòì‰∫éÂÆûÁé∞ÔºåÂπ∂‰∏îËÉΩÂ§üÂú®ÂèØÊé•ÂèóÁöÑÊó∂Èó¥ÂÜÖÊâæÂà∞Ëøë‰ººÊúÄ‰ºòËß£„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑÁâπÂæÅÈÄâÊã©ÁÆóÊ≥ïÈÄöÂ∏∏ÂµåÂÖ•Âà∞ËßÜËßâÂÆö‰ΩçÁ≥ªÁªüÁöÑÂâçÁ´Ø„ÄÇÊï¥‰ΩìÊµÅÁ®ãÂåÖÊã¨Ôºö1) ÊèêÂèñÂõæÂÉèÁâπÂæÅÔºõ2) ‰ΩøÁî®Ë¥™Â©™ÁÆóÊ≥ïÈÄâÊã©ÁâπÂæÅÂ≠êÈõÜÔºõ3) Âà©Áî®ÈÄâÂÆöÁöÑÁâπÂæÅËøõË°å‰ΩçÂßø‰º∞ËÆ°Ôºõ4) Ê†πÊçÆÂÆö‰ΩçÁªìÊûúËØÑ‰º∞ÁâπÂæÅÁöÑÊïàÁî®ÔºåÂπ∂Êõ¥Êñ∞ÁâπÂæÅÂ≠êÈõÜ„ÄÇËØ•Ê°ÜÊû∂ÂÖÅËÆ∏Êú∫Âô®‰∫∫ÂÆûÊó∂ËØÑ‰º∞ÂíåÈÄâÊã©ÂØπÂÆö‰ΩçÊúÄÊúâÁî®ÁöÑËßÜËßâÁâπÂæÅ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éËÆæËÆ°‰∫Ü‰∏§ÁßçÂø´ÈÄü‰∏îÂÜÖÂ≠òÈ´òÊïàÁöÑË¥™Â©™ÁâπÂæÅÈÄâÊã©ÁÆóÊ≥ï„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËøô‰∫õÁÆóÊ≥ïÂú®ËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÂíåÂÜÖÂ≠òÂç†Áî®ÊñπÈù¢ÂÖ∑ÊúâÊòæËëó‰ºòÂäøÔºåËÉΩÂ§üÂú®ËµÑÊ∫êÂèóÈôêÁöÑÊú∫Âô®‰∫∫Âπ≥Âè∞‰∏äÂÆûÁé∞ÂÆûÊó∂ÁâπÂæÅÈÄâÊã©„ÄÇÁÆóÊ≥ïËÆæËÆ°ÁöÑÊ†∏ÂøÉÂú®‰∫éÈôç‰ΩéÊØèÊ¨°Ëø≠‰ª£ÁöÑËÆ°ÁÆóÈáèÔºåÂπ∂ÊúâÊïàÂú∞ÁÆ°ÁêÜÂÜÖÂ≠ò‰ΩøÁî®„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰∏≠ÂèØËÉΩÊ∂âÂèäÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ÁâπÂæÅÊïàÁî®ËØÑ‰º∞ÊåáÊ†áÔºöÂ¶Ç‰ΩïÈáèÂåñÊØè‰∏™ÁâπÂæÅÂØπÂÆö‰ΩçÁ≤æÂ∫¶ÁöÑË¥°ÁåÆÔºü‰æãÂ¶ÇÔºåÂèØ‰ª•‰ΩøÁî®‰ø°ÊÅØÂ¢ûÁõä„ÄÅÊñπÂ∑ÆÁ≠âÊåáÊ†á„ÄÇ2) Ë¥™Â©™ÈÄâÊã©Á≠ñÁï•ÔºöÂ¶Ç‰ΩïÈÄâÊã©‰∏ã‰∏Ä‰∏™Ë¶ÅÂä†ÂÖ•ÁâπÂæÅÂ≠êÈõÜÁöÑÁâπÂæÅÔºü‰æãÂ¶ÇÔºåÂèØ‰ª•ÈÄâÊã©ÊïàÁî®ÊúÄÈ´òÁöÑÁâπÂæÅ„ÄÇ3) ÂÅúÊ≠¢ÂáÜÂàôÔºö‰ΩïÊó∂ÂÅúÊ≠¢ÁâπÂæÅÈÄâÊã©ËøáÁ®ãÔºü‰æãÂ¶ÇÔºåÂèØ‰ª•ËÆæÁΩÆÊúÄÂ§ßÁâπÂæÅÊï∞ÈáèÊàñÂÆö‰ΩçÁ≤æÂ∫¶ÈòàÂÄº„ÄÇ4) ÂÜÖÂ≠òÁÆ°ÁêÜÁ≠ñÁï•ÔºöÂ¶Ç‰ΩïÊúâÊïàÂú∞ÁÆ°ÁêÜÁâπÂæÅÊï∞ÊçÆÔºåÈÅøÂÖçÂÜÖÂ≠òÊ∫¢Âá∫ÔºüÂÖ∑‰ΩìÁöÑÊäÄÊúØÁªÜËäÇÊú™Áü•ÔºåÈúÄË¶ÅÊü•ÈòÖËÆ∫ÊñáÂÖ®Êñá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÊëòË¶Å‰∏≠ÊèêÂà∞ÔºåËØ•ÊñπÊ≥ïÂú®Èôç‰ΩéÊó∂Èó¥ÂíåÂÜÖÂ≠òÂ§çÊùÇÂ∫¶ÁöÑÂêåÊó∂ÔºåÂú®ËÆ°ÁÆóÊïàÁéáÂíåÂÆö‰ΩçÁ≤æÂ∫¶‰πãÈó¥ÂÆûÁé∞‰∫ÜËâØÂ•ΩÁöÑÊùÉË°°„ÄÇÂÖ∑‰ΩìÁöÑÂÆûÈ™åÁªìÊûúÔºà‰æãÂ¶ÇÔºåÂú®ÁâπÂÆöÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆö‰ΩçÁ≤æÂ∫¶ÊèêÂçá„ÄÅËÆ°ÁÆóÊó∂Èó¥Áº©Áü≠„ÄÅÂÜÖÂ≠òÂç†Áî®Èôç‰ΩéÁ≠âÔºâÊú™Áü•ÔºåÈúÄË¶ÅÊü•ÈòÖËÆ∫ÊñáÂÖ®Êñá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅËá™‰∏ªÂØºËà™ÁöÑÊú∫Âô®‰∫∫Â∫îÁî®‰∏≠Ôºå‰æãÂ¶ÇÔºöÊó†‰∫∫È©æÈ©∂Ê±ΩËΩ¶„ÄÅÊó†‰∫∫Êú∫„ÄÅÊúçÂä°Êú∫Âô®‰∫∫ÂíåÂ∑•‰∏öÊú∫Âô®‰∫∫„ÄÇÈÄöËøáÈôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÂíåÂÜÖÂ≠òÂç†Áî®ÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊèêÈ´òÊú∫Âô®‰∫∫Âú®ËµÑÊ∫êÂèóÈôêÁéØÂ¢É‰∏≠ÁöÑÂÆö‰ΩçÁ≤æÂ∫¶ÂíåÂÆûÊó∂ÊÄßÔºå‰ªéËÄåÊèêÂçáÊú∫Âô®‰∫∫ÁöÑÊï¥‰ΩìÊÄßËÉΩÂíåÂèØÈù†ÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Â∫îÁî®‰∫éÂ¢ûÂº∫Áé∞ÂÆûÂíåËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüüÔºåÊèêÈ´òÂÆö‰ΩçËøΩË∏™ÁöÑÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Robot localization is a fundamental component of autonomous navigation in unknown environments. Among various sensing modalities, visual input from cameras plays a central role, enabling robots to estimate their position by tracking point features across image frames. However, image frames often contain a large number of features, many of which are redundant or uninformative for localization. Processing all features can introduce significant computational latency and inefficiency. This motivates the need for intelligent feature selection, identifying a subset of features that are most informative for localization over a prediction horizon. In this work, we propose two fast and memory-efficient feature selection algorithms that enable robots to actively evaluate the utility of visual features in real time. Unlike existing approaches with high computational and memory demands, the proposed methods are explicitly designed to reduce both time and memory complexity while achieving a favorable trade-off between computational efficiency and localization accuracy.

