---
layout: default
title: Reinforcing Action Policies by Prophesying
---

# Reinforcing Action Policies by Prophesying

**arXiv**: [2511.20633v1](https://arxiv.org/abs/2511.20633) | [PDF](https://arxiv.org/pdf/2511.20633.pdf)

**ä½œè€…**: Jiahui Zhang, Ze Huang, Chun Gu, Zipei Ma, Li Zhang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25

**å¤‡æ³¨**: https://LogosRoboticsGroup.github.io/ProphRL

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ProphRLï¼šé€šè¿‡é¢„æµ‹è¿›è¡Œè§†è§‰-è¯­è¨€-åŠ¨ä½œç­–ç•¥çš„å¼ºåŒ–å­¦ä¹ ï¼Œæå‡æœºå™¨äººæŽ§åˆ¶æ€§èƒ½ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€åŠ¨ä½œ` `å¼ºåŒ–å­¦ä¹ ` `ä¸–ç•Œæ¨¡åž‹` `æœºå™¨äººæŽ§åˆ¶` `æ¨¡ä»¿å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VLAç­–ç•¥ä¾èµ–æ¨¡ä»¿å­¦ä¹ ï¼Œæ˜“è¿‡æ‹Ÿåˆä¸”æ³›åŒ–æ€§å·®ï¼ŒçœŸå®žæœºå™¨äººå¼ºåŒ–å­¦ä¹ æˆæœ¬é«˜ï¼Œä¼ ç»Ÿæ¨¡æ‹Ÿå™¨éš¾ä»¥è¿ç§»ã€‚
2. æå‡ºProphRLï¼Œåˆ©ç”¨é¢„è®­ç»ƒä¸–ç•Œæ¨¡åž‹Prophetå­¦ä¹ åŠ¨ä½œ-ç»“æžœåŠ¨æ€ï¼Œå¹¶ç»“åˆFA-GRPOå’ŒFlowScaleè¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒProphRLåœ¨å…¬å…±åŸºå‡†å’ŒçœŸå®žæœºå™¨äººå®žéªŒä¸­å‡æ˜¾è‘—æå‡äº†VLAç­–ç•¥çš„æˆåŠŸçŽ‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰ç­–ç•¥åœ¨å¯¹é½è¯­è¨€ã€æ„ŸçŸ¥å’Œæœºå™¨äººæŽ§åˆ¶æ–¹é¢è¡¨çŽ°å‡ºè‰²ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°VLAç­–ç•¥ä»…é€šè¿‡æ¨¡ä»¿å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œè¿™ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆæ¼”ç¤ºæ•°æ®ï¼Œå¹¶ä¸”åœ¨åˆ†å¸ƒåç§»ä¸‹è¡¨çŽ°è„†å¼±ã€‚å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç›´æŽ¥ä¼˜åŒ–ä»»åŠ¡å¥–åŠ±ï¼Œä»Žè€Œè§£å†³è¿™ç§ä¸ä¸€è‡´æ€§ï¼Œä½†çœŸå®žæœºå™¨äººäº¤äº’æˆæœ¬é«˜æ˜‚ï¼Œä¸”ä¼ ç»Ÿæ¨¡æ‹Ÿå™¨éš¾ä»¥è®¾è®¡å’Œè¿ç§»ã€‚æˆ‘ä»¬é€šè¿‡å­¦ä¹ çš„ä¸–ç•Œæ¨¡åž‹å’Œä¸ºåŸºäºŽæµçš„åŠ¨ä½œå¤´å®šåˆ¶çš„RLè¿‡ç¨‹ï¼Œè§£å†³äº†VLAåŽè®­ç»ƒä¸­çš„æ•°æ®æ•ˆçŽ‡å’Œä¼˜åŒ–ç¨³å®šæ€§é—®é¢˜ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å¼•å…¥äº†Prophetï¼Œä¸€ä¸ªç»Ÿä¸€çš„åŠ¨ä½œåˆ°è§†é¢‘çš„æœºå™¨äººé©±åŠ¨é¢„è®­ç»ƒæ¨¡åž‹ï¼Œå®ƒè·¨å¤§è§„æ¨¡å¼‚æž„æœºå™¨äººæ•°æ®å­¦ä¹ å¯é‡ç”¨çš„åŠ¨ä½œ-ç»“æžœåŠ¨æ€ã€‚å®ƒèƒ½å¤Ÿå°‘é‡æ ·æœ¬é€‚åº”æ–°çš„æœºå™¨äººã€å¯¹è±¡å’ŒçŽ¯å¢ƒï¼Œä»Žè€Œäº§ç”Ÿä¸€ä¸ªå¯ç›´æŽ¥ç”¨äºŽrolloutçš„æ¨¡æ‹Ÿå™¨ã€‚åœ¨Prophetçš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬ä½¿ç”¨Flow-action-GRPOï¼ˆFA-GRPOï¼‰å¼ºåŒ–åŠ¨ä½œç­–ç•¥ï¼Œè¯¥æ–¹æ³•ä½¿Flow-GRPOèƒ½å¤Ÿå¯¹VLAåŠ¨ä½œè¿›è¡Œæ“ä½œï¼Œå¹¶ä½¿ç”¨FlowScaleï¼Œä¸€ç§é€æ­¥é‡æ–°åŠ æƒçš„æ–¹æ³•ï¼Œå¯ä»¥é‡æ–°è°ƒæ•´æµå¤´ä¸­æ¯ä¸€æ­¥çš„æ¢¯åº¦ã€‚Prophetã€FA-GRPOå’ŒFlowScaleå…±åŒæž„æˆäº†ProphRLï¼Œè¿™æ˜¯ä¸€ç§å®žç”¨ã€æ•°æ®å’Œè®¡ç®—é«˜æ•ˆçš„VLAåŽè®­ç»ƒæ–¹æ³•ã€‚å®žéªŒè¡¨æ˜Žï¼Œåœ¨å…¬å…±åŸºå‡†æµ‹è¯•ä¸­æˆåŠŸçŽ‡æé«˜äº†5-17%ï¼Œåœ¨ä¸åŒVLAå˜ä½“ä¸Šçš„çœŸå®žæœºå™¨äººå®žéªŒä¸­æˆåŠŸçŽ‡æé«˜äº†24-30%ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰ç­–ç•¥ä¸»è¦ä¾èµ–æ¨¡ä»¿å­¦ä¹ ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œå¯¼è‡´åœ¨çœŸå®žçŽ¯å¢ƒä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚ç›´æŽ¥åœ¨çœŸå®žæœºå™¨äººä¸Šè¿›è¡Œå¼ºåŒ–å­¦ä¹ æˆæœ¬é«˜æ˜‚ï¼Œè€Œä¼ ç»Ÿæ¨¡æ‹Ÿå™¨éš¾ä»¥å‡†ç¡®æ¨¡æ‹ŸçœŸå®žä¸–ç•Œçš„å¤æ‚æ€§ï¼Œå¯¼è‡´ç­–ç•¥è¿ç§»å›°éš¾ã€‚å› æ­¤ï¼Œå¦‚ä½•é«˜æ•ˆã€ç¨³å®šåœ°å¯¹VLAç­–ç•¥è¿›è¡ŒåŽè®­ç»ƒï¼Œæå‡å…¶åœ¨çœŸå®žçŽ¯å¢ƒä¸­çš„æ€§èƒ½ï¼Œæ˜¯ä¸€ä¸ªäºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šProphRLçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„ä¸–ç•Œæ¨¡åž‹ï¼ˆProphetï¼‰æ¥å­¦ä¹ æœºå™¨äººåŠ¨ä½œä¸ŽçŽ¯å¢ƒå˜åŒ–ä¹‹é—´çš„åŠ¨æ€å…³ç³»ï¼Œä»Žè€Œæž„å»ºä¸€ä¸ªå¯ç”¨äºŽå¼ºåŒ–å­¦ä¹ çš„æ¨¡æ‹ŸçŽ¯å¢ƒã€‚é€šè¿‡åœ¨è¿™ä¸ªæ¨¡æ‹ŸçŽ¯å¢ƒä¸­è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œå¯ä»¥é¿å…ç›´æŽ¥åœ¨çœŸå®žæœºå™¨äººä¸Šè¿›è¡Œæ˜‚è´µçš„äº¤äº’ï¼Œå¹¶æé«˜æ•°æ®æ•ˆçŽ‡ã€‚åŒæ—¶ï¼Œé’ˆå¯¹VLAç­–ç•¥çš„ç‰¹ç‚¹ï¼Œè®¾è®¡äº†FA-GRPOå’ŒFlowScaleï¼Œä»¥ä¼˜åŒ–å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šProphRLä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼š1) Prophetï¼šä¸€ä¸ªé¢„è®­ç»ƒçš„åŠ¨ä½œåˆ°è§†é¢‘çš„æœºå™¨äººé©±åŠ¨æ¨¡åž‹ï¼Œç”¨äºŽå­¦ä¹ åŠ¨ä½œ-ç»“æžœåŠ¨æ€ã€‚2) FA-GRPOï¼šå°†Flow-GRPOç®—æ³•é€‚é…åˆ°VLAåŠ¨ä½œç©ºé—´ï¼Œç”¨äºŽå¼ºåŒ–å­¦ä¹ ã€‚3) FlowScaleï¼šä¸€ç§é€æ­¥é‡æ–°åŠ æƒçš„æ–¹æ³•ï¼Œç”¨äºŽè°ƒæ•´æµå¤´ä¸­çš„æ¢¯åº¦ï¼Œæé«˜ä¼˜åŒ–ç¨³å®šæ€§ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼šé¦–å…ˆä½¿ç”¨Prophetæž„å»ºæ¨¡æ‹ŸçŽ¯å¢ƒï¼Œç„¶åŽåœ¨è¯¥çŽ¯å¢ƒä¸­åˆ©ç”¨FA-GRPOå’ŒFlowScaleè¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªä¼˜åŒ–åŽçš„VLAç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šProphRLçš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) æå‡ºäº†Prophetï¼Œä¸€ä¸ªå¯ä»¥å­¦ä¹ åŠ¨ä½œ-ç»“æžœåŠ¨æ€çš„é¢„è®­ç»ƒä¸–ç•Œæ¨¡åž‹ï¼Œèƒ½å¤Ÿå°‘é‡æ ·æœ¬é€‚åº”æ–°çš„æœºå™¨äººã€å¯¹è±¡å’ŒçŽ¯å¢ƒã€‚2) è®¾è®¡äº†FA-GRPOï¼Œå°†Flow-GRPOç®—æ³•é€‚é…åˆ°VLAåŠ¨ä½œç©ºé—´ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†è§†è§‰å’Œè¯­è¨€ä¿¡æ¯ã€‚3) æå‡ºäº†FlowScaleï¼Œä¸€ç§é€æ­¥é‡æ–°åŠ æƒçš„æ–¹æ³•ï¼Œç”¨äºŽè°ƒæ•´æµå¤´ä¸­çš„æ¢¯åº¦ï¼Œæé«˜ä¼˜åŒ–ç¨³å®šæ€§ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒProphRLèƒ½å¤Ÿæ›´é«˜æ•ˆã€ç¨³å®šåœ°å¯¹VLAç­–ç•¥è¿›è¡ŒåŽè®­ç»ƒã€‚

**å…³é”®è®¾è®¡**ï¼šProphetä½¿ç”¨å¤§è§„æ¨¡å¼‚æž„æœºå™¨äººæ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼Œå­¦ä¹ åŠ¨ä½œä¸Žè§†é¢‘å¸§ä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚FA-GRPOåˆ©ç”¨Flow-GRPOçš„ä¼˜åŠ¿ï¼Œç»“åˆVLAç­–ç•¥çš„ç‰¹ç‚¹ï¼Œè®¾è®¡äº†ç‰¹å®šçš„ç½‘ç»œç»“æž„å’ŒæŸå¤±å‡½æ•°ã€‚FlowScaleé€šè¿‡é€æ­¥è°ƒæ•´æµå¤´ä¸­æ¯ä¸€æ­¥çš„æ¢¯åº¦æƒé‡ï¼Œæ¥å¹³è¡¡ä¸åŒæ—¶é—´æ­¥çš„å½±å“ï¼Œæé«˜ä¼˜åŒ–ç¨³å®šæ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æž„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒProphRLåœ¨å…¬å…±åŸºå‡†æµ‹è¯•ä¸­æˆåŠŸçŽ‡æé«˜äº†5-17%ï¼Œåœ¨ä¸åŒVLAå˜ä½“ä¸Šçš„çœŸå®žæœºå™¨äººå®žéªŒä¸­æˆåŠŸçŽ‡æé«˜äº†24-30%ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒProphRLèƒ½å¤Ÿæ˜¾è‘—æå‡VLAç­–ç•¥çš„æ€§èƒ½ï¼Œå¹¶ä¸”å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

ProphRLå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºŽæå‡å„ç§æœºå™¨äººä»»åŠ¡çš„æ€§èƒ½ï¼Œä¾‹å¦‚ç‰©ä½“æŠ“å–ã€è£…é…ã€å¯¼èˆªç­‰ã€‚è¯¥æ–¹æ³•å¯ä»¥é™ä½Žæœºå™¨äººå¼ºåŒ–å­¦ä¹ çš„æˆæœ¬ï¼ŒåŠ é€Ÿæœºå™¨äººæŠ€æœ¯çš„è½åœ°åº”ç”¨ã€‚æ­¤å¤–ï¼ŒProphRLè¿˜å¯ä»¥åº”ç”¨äºŽè™šæ‹ŸçŽ°å®žã€æ¸¸æˆç­‰é¢†åŸŸï¼Œç”¨äºŽç”Ÿæˆæ›´é€¼çœŸçš„æœºå™¨äººè¡Œä¸ºã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language-Action (VLA) policies excel in aligning language, perception, and robot control. However, most VLAs are trained purely by imitation, which overfits to demonstrations, and is brittle under distribution shift. Reinforcement learning (RL) directly optimizes task reward and thus addresses this misalignment, but real-robot interaction is expensive and conventional simulators are hard to engineer and transfer. We address both data efficiency and optimization stability in VLA post-training via a learned world model and an RL procedure tailored to flow-based action heads. Specifically, we introduce Prophet, a unified action-to-video robot actuation pretrained across large-scale, heterogeneous robot data to learn reusable action-outcome dynamics. It is able to few-shot adapt to new robots, objects, and environments, yielding a rollout-ready simulator. Upon Prophet, we reinforce action policies with Flow-action-GRPO (FA-GRPO), which adapts Flow-GRPO to operate on VLA actions, and with FlowScale, a stepwise reweighting that rescales per-step gradients in the flow head. Together, Prophet, FA-GRPO, and FlowScale constitute ProphRL, a practical, data- and compute-efficient path to VLA post-training. Experiments show 5-17% success gains on public benchmarks and 24-30% gains on real robots across different VLA variants.

