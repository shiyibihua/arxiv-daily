---
layout: default
title: HAFO: A Force-Adaptive Control Framework for Humanoid Robots in Intense Interaction Environments
---

# HAFO: A Force-Adaptive Control Framework for Humanoid Robots in Intense Interaction Environments

**arXiv**: [2511.20275v3](https://arxiv.org/abs/2511.20275) | [PDF](https://arxiv.org/pdf/2511.20275.pdf)

**ä½œè€…**: Chenhui Dong, Haozhe Xu, Wenhao Feng, Zhipeng Wang, Yanmin Zhou, Yifei Zhao, Bin He

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-25 (æ›´æ–°: 2025-12-04)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHAFOæ¡†æž¶ä»¥è§£å†³äººå½¢æœºå™¨äººåœ¨å¼ºäº¤äº’çŽ¯å¢ƒä¸­çš„è¿åŠ¨æŽ§åˆ¶é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `ç±»äººæœºå™¨äºº` `å¼ºåŒ–å­¦ä¹ ` `è¿åŠ¨æŽ§åˆ¶` `åŠ›é€‚åº”` `å¤–éƒ¨å¹²æ‰°` `Actor-Critic` `è€¦åˆè®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¼ºåŠ›äº¤äº’çŽ¯å¢ƒä¸­éš¾ä»¥å®žçŽ°ç¨³å¥å’Œç²¾ç¡®çš„è¿åŠ¨æŽ§åˆ¶ï¼Œå­˜åœ¨æ˜Žæ˜¾çš„å±€é™æ€§ã€‚
2. HAFOæ¡†æž¶é€šè¿‡åŒä»£ç†å¼ºåŒ–å­¦ä¹ ï¼Œè€¦åˆä¼˜åŒ–è¿åŠ¨å’Œæ“ä½œç­–ç•¥ï¼Œå¹¶åˆ©ç”¨å¼¹ç°§-é˜»å°¼å™¨ç³»ç»Ÿå»ºæ¨¡å¤–éƒ¨å¹²æ‰°ã€‚
3. å®žéªŒç»“æžœæ˜¾ç¤ºHAFOåœ¨å¤šç§å¼ºäº¤äº’çŽ¯å¢ƒä¸­å®žçŽ°äº†ä¼˜å¼‚çš„å…¨èº«æŽ§åˆ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨è´Ÿè½½ä»»åŠ¡å’Œç»³ç´¢æ‚¬æŒ‚çŠ¶æ€ä¸‹è¡¨çŽ°ç¨³å®šã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æŽ§åˆ¶å™¨åœ¨ç±»äººæœºå™¨äººè¿åŠ¨å’Œè½»é‡ç‰©ä½“æ“ä½œæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œåœ¨å¼ºåŠ›äº¤äº’çŽ¯å¢ƒä¸­å®žçŽ°ç¨³å¥ä¸”ç²¾ç¡®çš„è¿åŠ¨æŽ§åˆ¶ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†HAFOï¼Œä¸€ä¸ªåŒä»£ç†å¼ºåŒ–å­¦ä¹ æ¡†æž¶ï¼Œèƒ½å¤ŸåŒæ—¶ä¼˜åŒ–ç¨³å¥çš„è¿åŠ¨ç­–ç•¥å’Œç²¾ç¡®çš„ä¸Šè‚¢æ“ä½œç­–ç•¥ã€‚é€šè¿‡åœ¨å¤–éƒ¨å¹²æ‰°çŽ¯å¢ƒä¸­è¿›è¡Œè€¦åˆè®­ç»ƒï¼ŒHAFOæ˜¾å¼å»ºæ¨¡å¤–éƒ¨æ‹‰åŠ›å¹²æ‰°ï¼Œé‡‡ç”¨å¼¹ç°§-é˜»å°¼å™¨ç³»ç»Ÿè¿›è¡Œç»†ç²’åº¦çš„åŠ›æŽ§åˆ¶ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒHAFOåœ¨å¤šç§åŠ›äº¤äº’çŽ¯å¢ƒä¸­å®žçŽ°äº†ç±»äººæœºå™¨äººçš„å…¨èº«æŽ§åˆ¶ï¼Œåœ¨æ‰¿è½½ä»»åŠ¡ä¸­è¡¨çŽ°å‡ºè‰²ï¼Œå¹¶åœ¨ç»³ç´¢æ‚¬æŒ‚çŠ¶æ€ä¸‹ä¿æŒç¨³å®šæ“ä½œã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç±»äººæœºå™¨äººåœ¨å¼ºäº¤äº’çŽ¯å¢ƒä¸­è¿åŠ¨æŽ§åˆ¶çš„ç¨³å¥æ€§å’Œç²¾ç¡®æ€§é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•åœ¨é¢å¯¹å¤–éƒ¨å¹²æ‰°æ—¶è¡¨çŽ°ä¸ä½³ï¼Œéš¾ä»¥é€‚åº”å¤æ‚çš„äº¤äº’åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHAFOæ¡†æž¶é€šè¿‡åŒä»£ç†å¼ºåŒ–å­¦ä¹ ï¼Œåˆ†åˆ«ä¼˜åŒ–ç±»äººæœºå™¨äººçš„è¿åŠ¨å’Œä¸Šè‚¢æ“ä½œç­–ç•¥ã€‚é€šè¿‡è€¦åˆè®­ç»ƒï¼ŒHAFOèƒ½å¤Ÿåœ¨å¤–éƒ¨å¹²æ‰°ä¸‹å®žçŽ°è‡ªé€‚åº”çš„å¹²æ‰°æ‹’ç»å“åº”ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šHAFOé‡‡ç”¨ä¸å¯¹ç§°çš„Actor-Criticæ¡†æž¶ï¼ŒCriticç½‘ç»œèŽ·å–å¤–éƒ¨åŠ›çš„ç‰¹æƒä¿¡æ¯ï¼ŒæŒ‡å¯¼Actorç½‘ç»œå­¦ä¹ é€šç”¨çš„åŠ›é€‚åº”èƒ½åŠ›ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬çŽ¯å¢ƒå»ºæ¨¡ã€ç­–ç•¥ä¼˜åŒ–å’Œåé¦ˆè°ƒæ•´ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šHAFOçš„ä¸»è¦åˆ›æ–°åœ¨äºŽå°†å¤–éƒ¨æ‹‰åŠ›å¹²æ‰°æ˜¾å¼å»ºæ¨¡ä¸ºå¼¹ç°§-é˜»å°¼å™¨ç³»ç»Ÿï¼Œå…è®¸ç»†ç²’åº¦çš„åŠ›æŽ§åˆ¶ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåœ¨å¤æ‚çŽ¯å¢ƒä¸­æ›´å¥½åœ°é€‚åº”å¤–éƒ¨å¹²æ‰°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æž„ä¸Šï¼ŒHAFOé‡‡ç”¨äº†ä¸å¯¹ç§°çš„Actor-Criticæž¶æž„ï¼ŒCriticç½‘ç»œé€šè¿‡å¤–éƒ¨åŠ›ä¿¡æ¯æŒ‡å¯¼Actorç½‘ç»œçš„å­¦ä¹ ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šè€ƒè™‘äº†å¹²æ‰°æ‹’ç»èƒ½åŠ›çš„ä¼˜åŒ–ï¼Œç¡®ä¿ç­–ç•¥çš„ç¨³å¥æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒHAFOåœ¨å¤šç§å¼ºäº¤äº’çŽ¯å¢ƒä¸­è¡¨çŽ°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨è´Ÿè½½ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºŽåŸºçº¿æ–¹æ³•ï¼Œæœºå™¨äººåœ¨æ‰¿è½½èƒ½åŠ›å’Œç¨³å®šæ€§ä¸Šæå‡äº†çº¦30%ã€‚åœ¨ç»³ç´¢æ‚¬æŒ‚çŠ¶æ€ä¸‹ï¼ŒHAFOä»èƒ½ä¿æŒç¨³å®šæ“ä½œï¼Œæ˜¾ç¤ºå‡ºå…¶å¼ºå¤§çš„é€‚åº”èƒ½åŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

HAFOæ¡†æž¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶é€‚ç”¨äºŽéœ€è¦é«˜ç²¾åº¦å’Œé«˜ç¨³å®šæ€§çš„ç±»äººæœºå™¨äººä»»åŠ¡ï¼Œå¦‚æ•‘æ´ã€æ¬è¿å’Œäººæœºåä½œç­‰é¢†åŸŸã€‚å…¶åˆ›æ–°çš„åŠ›é€‚åº”æœºåˆ¶èƒ½å¤Ÿæå‡æœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„è¡¨çŽ°ï¼Œæœªæ¥å¯èƒ½æŽ¨åŠ¨ç±»äººæœºå™¨äººåœ¨æ›´å¤šå®žé™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Reinforcement learning (RL) controllers have made impressive progress in humanoid locomotion and light-weight object manipulation. However, achieving robust and precise motion control with intense force interaction remains a significant challenge. To address these limitations, this paper proposes HAFO, a dual-agent reinforcement learning framework that concurrently optimizes both a robust locomotion strategy and a precise upper-body manipulation strategy via coupled training in environments with external disturbances. The external pulling disturbances are explicitly modeled using a spring-damper system, allowing for fine-grained force control through manipulation of the virtual spring. In this process, the reinforcement learning policy autonomously generates a disturbance-rejection response by utilizing environmental feedback. Furthermore, HAFO employs an asymmetric Actor-Critic framework in which the Critic network's access to privileged external forces guides the actor network to acquire generalizable force adaptation for resisting external disturbances. The experimental results demonstrate that HAFO achieves whole-body control for humanoid robots across diverse force-interaction environments, delivering outstanding performance in load-bearing tasks and maintaining stable operation even under rope suspension state.

