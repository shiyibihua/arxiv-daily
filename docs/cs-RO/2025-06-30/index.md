---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-06-30
---

# cs.ROï¼ˆ2025-06-30ï¼‰

ğŸ“Š å…± **12** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (10 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (10 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250623919v2-goal-vla-image-generative-vlms-as-object-centric-world-models-empowe.html">Goal-VLA: Image-Generative VLMs as Object-Centric World Models Empowering Zero-shot Robot Manipulation</a></td>
  <td>æå‡ºGoal-VLAä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­çš„æ³›åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">world model</span> <span class="paper-tag">vision-language-action</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.23919v2" data-paper-url="./papers/250623919v2-goal-vla-image-generative-vlms-as-object-centric-world-models-empowe.html" onclick="toggleFavorite(this, '2506.23919v2', 'Goal-VLA: Image-Generative VLMs as Object-Centric World Models Empowering Zero-shot Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250623725v1-pac-bench-do-foundation-models-understand-prerequisites-for-executin.html">PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?</a></td>
  <td>æå‡ºPAC Benchä»¥è¯„ä¼°åŸºç¡€æ¨¡å‹å¯¹æ“ä½œç­–ç•¥æ‰§è¡Œå‰æçš„ç†è§£èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">manipulation</span> <span class="paper-tag">affordance</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.23725v1" data-paper-url="./papers/250623725v1-pac-bench-do-foundation-models-understand-prerequisites-for-executin.html" onclick="toggleFavorite(this, '2506.23725v1', 'PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250700273v3-mechanical-intelligence-aware-curriculum-reinforcement-learning-for-.html">Mechanical Intelligence-Aware Curriculum Reinforcement Learning for Humanoids with Parallel Actuation</a></td>
  <td>æå‡ºæœºæ¢°æ™ºèƒ½æ„ŸçŸ¥çš„è¯¾ç¨‹å¼ºåŒ–å­¦ä¹ ä»¥ä¼˜åŒ–ç±»äººæœºå™¨äººè¿åŠ¨æ§åˆ¶</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">locomotion</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2507.00273v3" data-paper-url="./papers/250700273v3-mechanical-intelligence-aware-curriculum-reinforcement-learning-for-.html" onclick="toggleFavorite(this, '2507.00273v3', 'Mechanical Intelligence-Aware Curriculum Reinforcement Learning for Humanoids with Parallel Actuation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250623624v2-towards-universal-shared-control-in-teleoperation-without-haptic-fee.html">Towards Universal Shared Control in Teleoperation Without Haptic Feedback</a></td>
  <td>æå‡ºå¤šç›®æ ‡ä¼˜åŒ–æ–¹æ³•ä»¥è§£å†³æ— è§¦è§‰åé¦ˆçš„é¥æ“ä½œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">teleoperation</span> <span class="paper-tag">shared control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.23624v2" data-paper-url="./papers/250623624v2-towards-universal-shared-control-in-teleoperation-without-haptic-fee.html" onclick="toggleFavorite(this, '2506.23624v2', 'Towards Universal Shared Control in Teleoperation Without Haptic Feedback')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250700319v1-when-digital-twins-meet-large-language-models-realistic-interactive-.html">When Digital Twins Meet Large Language Models: Realistic, Interactive, and Editable Simulation for Autonomous Driving</a></td>
  <td>æå‡ºç»Ÿä¸€æ¡†æ¶ä»¥è§£å†³è‡ªä¸»é©¾é©¶ä»¿çœŸä¸­çš„å¤šé‡æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">real2sim</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2507.00319v1" data-paper-url="./papers/250700319v1-when-digital-twins-meet-large-language-models-realistic-interactive-.html" onclick="toggleFavorite(this, '2507.00319v1', 'When Digital Twins Meet Large Language Models: Realistic, Interactive, and Editable Simulation for Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250700236v3-sim2real-diffusion-leveraging-foundation-vision-language-models-for-.html">Sim2Real Diffusion: Leveraging Foundation Vision Language Models for Adaptive Automated Driving</a></td>
  <td>æå‡ºç»Ÿä¸€æ¡†æ¶ä»¥è§£å†³è‡ªåŠ¨é©¾é©¶çš„sim2realè½¬ç§»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">sim2real</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2507.00236v3" data-paper-url="./papers/250700236v3-sim2real-diffusion-leveraging-foundation-vision-language-models-for-.html" onclick="toggleFavorite(this, '2507.00236v3', 'Sim2Real Diffusion: Leveraging Foundation Vision Language Models for Adaptive Automated Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250623768v1-motion-tracking-with-muscles-predictive-control-of-a-parametric-musc.html">Motion Tracking with Muscles: Predictive Control of a Parametric Musculoskeletal Canine Model</a></td>
  <td>æå‡ºåŸºäºè‚Œè‚‰çš„è¿åŠ¨è¿½è¸ªæ¨¡å‹ä»¥è§£å†³çŠ¬ç±»è¿åŠ¨æ§åˆ¶é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span> <span class="paper-tag">motion tracking</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.23768v1" data-paper-url="./papers/250623768v1-motion-tracking-with-muscles-predictive-control-of-a-parametric-musc.html" onclick="toggleFavorite(this, '2506.23768v1', 'Motion Tracking with Muscles: Predictive Control of a Parametric Musculoskeletal Canine Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250623944v2-adapt-your-body-mitigating-proprioception-shifts-in-imitation-learni.html">Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning</a></td>
  <td>æå‡ºé¢†åŸŸé€‚åº”æ¡†æ¶ä»¥è§£å†³æ¨¡ä»¿å­¦ä¹ ä¸­çš„æœ¬ä½“æ„ŸçŸ¥åç§»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.23944v2" data-paper-url="./papers/250623944v2-adapt-your-body-mitigating-proprioception-shifts-in-imitation-learni.html" onclick="toggleFavorite(this, '2506.23944v2', 'Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250623723v1-a-comprehensive-control-architecture-for-semi-autonomous-dual-arm-ro.html">A comprehensive control architecture for semi-autonomous dual-arm robots in agriculture settings</a></td>
  <td>æå‡ºä¸€ç§ç»¼åˆæ§åˆ¶æ¶æ„ä»¥è§£å†³å†œä¸šç¯å¢ƒä¸­åŒè‡‚æœºå™¨äººä»»åŠ¡ç®¡ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">dual-arm</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.23723v1" data-paper-url="./papers/250623723v1-a-comprehensive-control-architecture-for-semi-autonomous-dual-arm-ro.html" onclick="toggleFavorite(this, '2506.23723v1', 'A comprehensive control architecture for semi-autonomous dual-arm robots in agriculture settings')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250700166v1-novel-design-of-3d-printed-tumbling-microrobots-for-in-vivo-targeted.html">Novel Design of 3D Printed Tumbling Microrobots for in vivo Targeted Drug Delivery</a></td>
  <td>æå‡º3Dæ‰“å°ç¿»æ»šå¾®å‹æœºå™¨äººä»¥è§£å†³é¶å‘è¯ç‰©é€’é€é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2507.00166v1" data-paper-url="./papers/250700166v1-novel-design-of-3d-printed-tumbling-microrobots-for-in-vivo-targeted.html" onclick="toggleFavorite(this, '2507.00166v1', 'Novel Design of 3D Printed Tumbling Microrobots for in vivo Targeted Drug Delivery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>11</td>
  <td><a href="./papers/250700268v1-control-optimized-deep-reinforcement-learning-for-artificially-intel.html">Control-Optimized Deep Reinforcement Learning for Artificially Intelligent Autonomous Systems</a></td>
  <td>æå‡ºæ§åˆ¶ä¼˜åŒ–æ·±åº¦å¼ºåŒ–å­¦ä¹ ä»¥è§£å†³æ‰§è¡Œä¸åŒ¹é…é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">DRL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2507.00268v1" data-paper-url="./papers/250700268v1-control-optimized-deep-reinforcement-learning-for-artificially-intel.html" onclick="toggleFavorite(this, '2507.00268v1', 'Control-Optimized Deep Reinforcement Learning for Artificially Intelligent Autonomous Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250623771v3-multi-timescale-hierarchical-reinforcement-learning-for-unified-beha.html">Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving</a></td>
  <td>æå‡ºå¤šæ—¶é—´å°ºåº¦å±‚æ¬¡å¼ºåŒ–å­¦ä¹ ä»¥è§£å†³è‡ªåŠ¨é©¾é©¶è¡Œä¸ºä¸æ§åˆ¶ç»Ÿä¸€é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.23771v3" data-paper-url="./papers/250623771v3-multi-timescale-hierarchical-reinforcement-learning-for-unified-beha.html" onclick="toggleFavorite(this, '2506.23771v3', 'Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)