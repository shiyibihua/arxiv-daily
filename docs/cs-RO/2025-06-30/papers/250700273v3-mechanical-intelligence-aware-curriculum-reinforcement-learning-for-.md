---
layout: default
title: Mechanical Intelligence-Aware Curriculum Reinforcement Learning for Humanoids with Parallel Actuation
---

# Mechanical Intelligence-Aware Curriculum Reinforcement Learning for Humanoids with Parallel Actuation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.00273" class="toolbar-btn" target="_blank">üìÑ arXiv: 2507.00273v3</a>
  <a href="https://arxiv.org/pdf/2507.00273.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.00273v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.00273v3', 'Mechanical Intelligence-Aware Curriculum Reinforcement Learning for Humanoids with Parallel Actuation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yusuke Tanaka, Alvin Zhu, Quanyou Wang, Yeting Liu, Dennis Hong

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-30 (Êõ¥Êñ∞: 2025-10-30)

**Â§áÊ≥®**: Proceeding to the IEEE Humanoid Conference 2025

**DOI**: [10.1109/Humanoids65713.2025.11203130](https://doi.org/10.1109/Humanoids65713.2025.11203130)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/alvister88/og_bruce)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Êú∫Ê¢∞Êô∫ËÉΩÊÑüÁü•ÁöÑËØæÁ®ãÂº∫ÂåñÂ≠¶‰π†‰ª•‰ºòÂåñÁ±ª‰∫∫Êú∫Âô®‰∫∫ËøêÂä®ÊéßÂà∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Á±ª‰∫∫Êú∫Âô®‰∫∫` `Âº∫ÂåñÂ≠¶‰π†` `Âπ∂ËÅîÊú∫Âà∂` `ËøêÂä®ÊéßÂà∂` `ËØæÁ®ãÂ≠¶‰π†` `MuJoCo` `Êú∫Ê¢∞Êô∫ËÉΩ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÊú™ËÉΩÂÖÖÂàÜËÄÉËôëÂπ∂ËÅîÈ©±Âä®Êú∫Âà∂‰∏≠ÁöÑÊú∫Ê¢∞Êô∫ËÉΩÔºåÂØºËá¥ËøêÂä®Âª∫Ê®°‰∏çÂáÜÁ°ÆÂíåÁ≠ñÁï•Ê¨°‰ºò„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑËØæÁ®ãÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÔºåËÉΩÂ§üÂéüÁîüÊ®°ÊãüÂπ∂ËÅîÊú∫Âà∂ÁöÑÈó≠ÈìæÁ∫¶ÊùüÔºå‰ªéËÄåÊèêÈ´òÁ±ª‰∫∫Êú∫Âô®‰∫∫ÁöÑËøêÂä®ÊéßÂà∂ÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÁúüÂÆûÁéØÂ¢É‰∏≠ÂÆûÁé∞‰∫Ü‰ºò‰∫éÊ®°ÂûãÈ¢ÑÊµãÊéßÂà∂Âô®ÁöÑË°®Èù¢Ê≥õÂåñÂíåÊÄßËÉΩÔºåÂ±ïÁ§∫‰∫ÜÊòæËëóÁöÑÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÊé®Âä®‰∫ÜÁ±ª‰∫∫Êú∫Âô®‰∫∫ËøêÂä®ÁöÑËøõÊ≠•Ôºå‰ΩÜÂ§ßÂ§öÊï∞Â≠¶‰π†Ê°ÜÊû∂Êú™ËÄÉËôëÂπ∂ËÅîÈ©±Âä®Êú∫Âà∂‰∏≠ÁöÑÊú∫Ê¢∞Êô∫ËÉΩÔºåÂØºËá¥ËøêÂä®Âª∫Ê®°‰∏çÂáÜÁ°ÆÂíåÁ≠ñÁï•Ê¨°‰ºò„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏âÁßçÂπ∂ËÅîÊú∫Âà∂ÁöÑÈÄöÁî®ÂÖ¨ÂºèÂíå‰ªøÁúüÊñπÊ≥ïÔºåÂπ∂ÈÄöËøáÁ´ØÂà∞Á´ØÁöÑËØæÁ®ãRLÊ°ÜÊû∂ËÆ≠ÁªÉ‰∫Ü‰∏Ä‰∏™ÊÑüÁü•Âπ∂ËÅîÊú∫Âà∂ÁöÑÁ≠ñÁï•ÔºåÂ∫îÁî®‰∫éÂÑøÁ´•Á±ª‰∫∫Êú∫Âô®‰∫∫BRUCE„ÄÇ‰∏é‰æùËµñÁÆÄÂåñ‰∏≤ËÅîËøë‰ººÁöÑÂÖàÂâçÊñπÊ≥ï‰∏çÂêåÔºåÊàë‰ª¨‰ΩøÁî®GPUÂä†ÈÄüÁöÑMuJoCoÔºàMJXÔºâÂéüÁîüÊ®°ÊãüÊâÄÊúâÈó≠ÈìæÁ∫¶ÊùüÔºå‰øùÁïô‰∫ÜÁ°¨‰ª∂ÁöÑÊú∫Ê¢∞ÈùûÁ∫øÊÄßÁâπÊÄß„ÄÇÈÄöËøá‰∏éÊ®°ÂûãÈ¢ÑÊµãÊéßÂà∂Âô®ÔºàMPCÔºâËøõË°åÂü∫ÂáÜÊµãËØïÔºåÊàë‰ª¨Â±ïÁ§∫‰∫ÜÂú®ÁúüÂÆû‰∏ñÁïåÈõ∂Ê†∑Êú¨ÈÉ®ÁΩ≤‰∏≠ÁöÑÊõ¥Â•ΩË°®Èù¢Ê≥õÂåñÂíåÊÄßËÉΩ„ÄÇÊ≠§Á†îÁ©∂Á™ÅÂá∫‰∫ÜÂú®ËÖøÈÉ®Á±ª‰∫∫Êú∫Âô®‰∫∫Á´ØÂà∞Á´ØÂ≠¶‰π†ÊµÅÁ®ã‰∏≠ÂÆåÂÖ®Ê®°ÊãüÂπ∂ËÅîÊú∫Âà∂ÁöÑËÆ°ÁÆóÊñπÊ≥ïÂíåÊÄßËÉΩ‰ºòÂäø„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂Êú™ËÉΩËÄÉËôëÂπ∂ËÅîÈ©±Âä®Êú∫Âà∂‰∏≠ÁöÑÊú∫Ê¢∞Êô∫ËÉΩÈóÆÈ¢òÔºåÂØºËá¥Á±ª‰∫∫Êú∫Âô®‰∫∫ËøêÂä®ÊéßÂà∂ÁöÑÂª∫Ê®°‰∏çÂáÜÁ°ÆÂíåÁ≠ñÁï•Ê¨°‰ºò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÂºïÂÖ•ËØæÁ®ãÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÔºåÁªìÂêàGPUÂä†ÈÄüÁöÑMuJoCo‰ªøÁúüÔºåÂéüÁîüÊ®°ÊãüÂπ∂ËÅîÊú∫Âà∂ÁöÑÈó≠ÈìæÁ∫¶ÊùüÔºå‰ªéËÄåÊèêÂçáËøêÂä®ÊéßÂà∂ÁöÑÁ≤æÁ°ÆÊÄßÂíåÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂπ∂ËÅîÊú∫Âà∂ÁöÑÂª∫Ê®°‰∏é‰ªøÁúü„ÄÅËØæÁ®ãÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÁöÑËÆ≠ÁªÉ‰ª•ÂèäÊÄßËÉΩËØÑ‰º∞„ÄÇÈ¶ñÂÖàÔºåÂª∫Á´ãÂπ∂ËÅîÊú∫Âà∂ÁöÑÊï∞Â≠¶Ê®°ÂûãÔºõÂÖ∂Ê¨°ÔºåÂà©Áî®MuJoCoËøõË°åÈ´òÊïà‰ªøÁúüÔºõÊúÄÂêéÔºåËÆ≠ÁªÉÂíåËØÑ‰º∞Á≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÂéüÁîüÊ®°ÊãüÈó≠ÈìæÁ∫¶ÊùüÔºå‰øùÁïô‰∫ÜÊú∫Ê¢∞ÈùûÁ∫øÊÄßÁâπÊÄßÔºåËøô‰∏é‰ª•ÂæÄ‰æùËµñÁÆÄÂåñ‰∏≤ËÅîËøë‰ººÁöÑÊñπÊ≥ïÊúâÊú¨Ë¥®Âå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äÔºåÈááÁî®‰∫ÜÈÄÇÂ∫îÊÄßÂ≠¶‰π†ÁéáÂíåÂ§öÈò∂ÊÆµËÆ≠ÁªÉÁ≠ñÁï•ÔºõÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°ËÄÉËôë‰∫ÜËøêÂä®Á≤æÂ∫¶ÂíåËÉΩÈáèÊïàÁéáÔºõÁΩëÁªúÁªìÊûÑÂàôÂü∫‰∫éÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂Ôºå‰ºòÂåñ‰∫ÜÁ≠ñÁï•ÁöÑÊî∂ÊïõÊÄßÂíåÁ®≥ÂÆöÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÊâÄÊèêÂá∫ÁöÑËØæÁ®ãÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂú®ÁúüÂÆû‰∏ñÁïåÁöÑÈõ∂Ê†∑Êú¨ÈÉ®ÁΩ≤‰∏≠ÔºåÁõ∏ËæÉ‰∫éÊ®°ÂûãÈ¢ÑÊµãÊéßÂà∂Âô®ÔºàMPCÔºâÔºåÂÆûÁé∞‰∫ÜÊõ¥Â•ΩÁöÑË°®Èù¢Ê≥õÂåñÂíåÊÄßËÉΩÔºåÂÖ∑‰ΩìÊèêÂçáÂπÖÂ∫¶Êú™Áü•ÔºåÂ±ïÁ§∫‰∫ÜÊòæËëóÁöÑ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÊïëÊè¥Êú∫Âô®‰∫∫Âíå‰∫∫Êú∫‰∫§‰∫íÁ≠âÂú∫ÊôØ„ÄÇÈÄöËøá‰ºòÂåñÁ±ª‰∫∫Êú∫Âô®‰∫∫ÁöÑËøêÂä®ÊéßÂà∂ÔºåËÉΩÂ§üÊèêÂçáÂÖ∂Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÈÄÇÂ∫îËÉΩÂäõÂíåÊâßË°åÊïàÁéáÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Reinforcement learning (RL) has enabled advances in humanoid robot locomotion, yet most learning frameworks do not account for mechanical intelligence embedded in parallel actuation mechanisms due to limitations in simulator support for closed kinematic chains. This omission can lead to inaccurate motion modeling and suboptimal policies, particularly for robots with high actuation complexity. This paper presents general formulations and simulation methods for three types of parallel mechanisms: a differential pulley, a five-bar linkage, and a four-bar linkage, and trains a parallel-mechanism aware policy through an end-to-end curriculum RL framework for BRUCE, a kid-sized humanoid robot. Unlike prior approaches that rely on simplified serial approximations, we simulate all closed-chain constraints natively using GPU-accelerated MuJoCo (MJX), preserving the hardware's mechanical nonlinear properties during training. We benchmark our RL approach against a model predictive controller (MPC), demonstrating better surface generalization and performance in real-world zero-shot deployment. This work highlights the computational approaches and performance benefits of fully simulating parallel mechanisms in end-to-end learning pipelines for legged humanoids. Project codes with parallel mechanisms: https://github.com/alvister88/og_bruce

