---
layout: default
title: Particle-Grid Neural Dynamics for Learning Deformable Object Models from RGB-D Videos
---

# Particle-Grid Neural Dynamics for Learning Deformable Object Models from RGB-D Videos

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15680" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15680v2</a>
  <a href="https://arxiv.org/pdf/2506.15680.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15680v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15680v2', 'Particle-Grid Neural Dynamics for Learning Deformable Object Models from RGB-D Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kaifeng Zhang, Baoyu Li, Kris Hauser, Yunzhu Li

**åˆ†ç±»**: cs.RO, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18 (æ›´æ–°: 2025-11-06)

**å¤‡æ³¨**: Project page: https://kywind.github.io/pgnd

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://kywind.github.io/pgnd)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç²’å­-ç½‘æ ¼ç¥ç»åŠ¨åŠ›å­¦ä»¥è§£å†³å¯å˜å½¢ç‰©ä½“å»ºæ¨¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¯å˜å½¢ç‰©ä½“å»ºæ¨¡` `ç²’å­-ç½‘æ ¼æ¨¡å‹` `ç¥ç»åŠ¨åŠ›å­¦` `æœºå™¨äººäº¤äº’` `é«˜æ–¯æ¸²æŸ“`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å»ºæ¨¡å¯å˜å½¢ç‰©ä½“åŠ¨æ€æ—¶é¢ä¸´ç‰©ç†å±æ€§å¤šæ ·æ€§å’Œè§†è§‰ä¿¡æ¯ä¸è¶³çš„æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºçš„ç²’å­-ç½‘æ ¼æ¨¡å‹é€šè¿‡ç»“åˆç²’å­å’Œç©ºé—´ç½‘æ ¼ï¼Œæ•æ‰ç‰©ä½“çš„å…¨å±€å½¢çŠ¶å’Œè¿åŠ¨ä¿¡æ¯ï¼Œæå‡å­¦ä¹ æ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤šç§ç‰©ä½“ï¼ˆå¦‚ç»³å­ã€å¸ƒæ–™ç­‰ï¼‰çš„åŠ¨æ€å­¦ä¹ ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨è§†è§’æœ‰é™çš„æƒ…å†µä¸‹è¡¨ç°çªå‡ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å»ºæ¨¡å¯å˜å½¢ç‰©ä½“çš„åŠ¨æ€ç‰¹æ€§é¢ä¸´å¤šæ ·çš„ç‰©ç†å±æ€§å’Œæœ‰é™è§†è§‰ä¿¡æ¯å¸¦æ¥çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆç‰©ä½“ç²’å­å’Œç©ºé—´ç½‘æ ¼çš„æ··åˆè¡¨ç¤ºçš„ç¥ç»åŠ¨åŠ›å­¦æ¡†æ¶ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿæ•æ‰å…¨å±€å½¢çŠ¶å’Œè¿åŠ¨ä¿¡æ¯ï¼ŒåŒæ—¶é¢„æµ‹å¯†é›†çš„ç²’å­è¿åŠ¨ï¼Œä»è€Œå®ç°å¯¹å½¢çŠ¶å’Œææ–™å„å¼‚çš„ç‰©ä½“å»ºæ¨¡ã€‚é€šè¿‡å®éªŒï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¯¥æ¨¡å‹åœ¨ä»ç¨€ç–è§†è§’RGB-Då½•åˆ¶çš„æœºå™¨äºº-ç‰©ä½“äº¤äº’ä¸­å­¦ä¹ å¤šæ ·ç‰©ä½“åŠ¨æ€çš„èƒ½åŠ›ï¼Œå¹¶åœ¨ç±»åˆ«å±‚é¢ä¸Šå¯¹æœªè§å®ä¾‹è¿›è¡Œæ³›åŒ–ã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨æœ‰é™ç›¸æœºè§†è§’çš„åœºæ™¯ä¸­è¶…è¶Šäº†ç°æœ‰çš„å­¦ä¹ å’Œç‰©ç†æ¨¡æ‹Ÿå™¨ï¼Œå±•ç¤ºäº†åœ¨åŸºäºæ¨¡å‹çš„è§„åˆ’ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¯å˜å½¢ç‰©ä½“åŠ¨æ€å»ºæ¨¡ä¸­çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šæ ·ç‰©ç†å±æ€§å’Œæœ‰é™è§†è§‰ä¿¡æ¯æ—¶æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„ç²’å­-ç½‘æ ¼æ¨¡å‹é€šè¿‡ç²’å­è¡¨ç¤ºç‰©ä½“å½¢çŠ¶ï¼Œç©ºé—´ç½‘æ ¼ç¦»æ•£åŒ–ä¸‰ç»´ç©ºé—´ï¼Œä»¥ç¡®ä¿ç©ºé—´è¿ç»­æ€§å¹¶å¢å¼ºå­¦ä¹ æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç²’å­è¡¨ç¤ºæ¨¡å—ã€ç©ºé—´ç½‘æ ¼æ¨¡å—å’Œé«˜æ–¯æ¸²æŸ“æ¨¡å—ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„å­¦ä¹ æ¡†æ¶ï¼Œèƒ½å¤Ÿç”Ÿæˆ3DåŠ¨ä½œæ¡ä»¶è§†é¢‘ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†ç²’å­ä¸ç©ºé—´ç½‘æ ¼ç»“åˆï¼Œå½¢æˆæ··åˆè¡¨ç¤ºï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰ç‰©ä½“çš„åŠ¨æ€ç‰¹æ€§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹è®¾è®¡ä¸­é‡‡ç”¨äº†é«˜æ–¯æ¸²æŸ“æŠ€æœ¯ï¼Œç¡®ä¿è§†è§‰æ•ˆæœçš„çœŸå®æ„Ÿï¼ŒåŒæ—¶åœ¨æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥æé«˜å­¦ä¹ æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ¨¡å‹åœ¨å¤šæ ·ç‰©ä½“åŠ¨æ€å­¦ä¹ ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„å­¦ä¹ å’Œç‰©ç†æ¨¡æ‹Ÿå™¨ï¼Œå°¤å…¶åœ¨æœ‰é™ç›¸æœºè§†è§’ä¸‹ï¼Œæ¨¡å‹åœ¨å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªæä¾›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæŠ“å–ã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰ï¼Œèƒ½å¤Ÿä¸ºç‰©ä½“æ“ä½œå’Œäº¤äº’æä¾›æ›´ä¸ºç²¾ç¡®çš„åŠ¨æ€æ¨¡å‹ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½åœ¨æ™ºèƒ½åˆ¶é€ å’Œè‡ªåŠ¨åŒ–é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ï¼Œæå‡æœºå™¨äººä¸ç¯å¢ƒçš„äº¤äº’èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Modeling the dynamics of deformable objects is challenging due to their diverse physical properties and the difficulty of estimating states from limited visual information. We address these challenges with a neural dynamics framework that combines object particles and spatial grids in a hybrid representation. Our particle-grid model captures global shape and motion information while predicting dense particle movements, enabling the modeling of objects with varied shapes and materials. Particles represent object shapes, while the spatial grid discretizes the 3D space to ensure spatial continuity and enhance learning efficiency. Coupled with Gaussian Splattings for visual rendering, our framework achieves a fully learning-based digital twin of deformable objects and generates 3D action-conditioned videos. Through experiments, we demonstrate that our model learns the dynamics of diverse objects -- such as ropes, cloths, stuffed animals, and paper bags -- from sparse-view RGB-D recordings of robot-object interactions, while also generalizing at the category level to unseen instances. Our approach outperforms state-of-the-art learning-based and physics-based simulators, particularly in scenarios with limited camera views. Furthermore, we showcase the utility of our learned models in model-based planning, enabling goal-conditioned object manipulation across a range of tasks. The project page is available at https://kywind.github.io/pgnd .

