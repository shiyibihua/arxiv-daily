---
layout: default
title: Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes
---

# Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09855" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09855v1</a>
  <a href="https://arxiv.org/pdf/2508.09855.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09855v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09855v1', 'Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuekun Wu, Yik Lung Pang, Andrea Cavallaro, Changjae Oh

**åˆ†ç±»**: cs.RO, cs.CV, cs.HC

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

**å¤‡æ³¨**: 3 pages, 3 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ–°æ–¹æ³•ä»¥ä»3Dåœºæ™¯å­¦ä¹ äººæœºäº¤æ¥è¡Œä¸º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `äººæœºåä½œ` `æœºå™¨äººå­¦ä¹ ` `é«˜æ–¯ç‚¹äº‘` `å›¾åƒå¤„ç†` `åŠ¨ä½œè¯†åˆ«` `ç¨³å®šæ€§æå‡` `æ¨¡æ‹Ÿè®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨çœŸå®ç¯å¢ƒä¸­éœ€è¦å¤§é‡çš„æœºå™¨äººè¯•éªŒï¼Œå¯¼è‡´è®­ç»ƒæˆæœ¬é«˜ä¸”æ•ˆç‡ä½ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºRGBå›¾åƒçš„è®­ç»ƒæ–¹æ³•ï¼Œåˆ©ç”¨é«˜æ–¯ç‚¹äº‘é‡å»ºç”Ÿæˆæœºå™¨äººæ¼”ç¤ºï¼Œé¿å…çœŸå®æ•°æ®æ”¶é›†ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®åœºæ™¯ä¸­å‡èƒ½æœ‰æ•ˆæå‡äººæœºäº¤æ¥çš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººæœºåä½œç³»ç»Ÿé€šå¸¸ä¾èµ–äºå¤§é‡çš„äººæœºäº¤äº’æ•°æ®ï¼Œå°¤å…¶æ˜¯åœ¨è¿‘è·ç¦»åä½œä»»åŠ¡å¦‚äººæœºäº¤æ¥ä¸­ã€‚ä»çœŸå®å›¾åƒæ•°æ®ä¸­å­¦ä¹ æœºå™¨äººæ“ä½œç­–ç•¥éœ€è¦å¤§é‡çš„æœºå™¨äººè¯•éªŒã€‚å°½ç®¡æ¨¡æ‹Ÿè®­ç»ƒæ˜¯ä¸€ç§æˆæœ¬æœ‰æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†æ¨¡æ‹Ÿä¸çœŸå®å·¥ä½œç¯å¢ƒä¹‹é—´çš„è§†è§‰åŸŸå·®è·ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦é™åˆ¶ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ä»…åŸºäºRGBå›¾åƒè®­ç»ƒäººæœºäº¤æ¥ç­–ç•¥çš„æ–¹æ³•ï¼Œæ— éœ€çœŸå®æœºå™¨äººè®­ç»ƒæˆ–æ•°æ®æ”¶é›†ã€‚è¯¥æ–¹æ³•æ—¨åœ¨ä½¿æœºå™¨äººèƒ½å¤Ÿå¯é åœ°ä»äººç±»æ‰‹ä¸­æ¥æ”¶ç‰©ä½“ï¼ŒåŒæ—¶é¿å…ä¸äººç±»æ‰‹çš„ç¢°æ’ã€‚é€šè¿‡ç¨€ç–è§†å›¾é«˜æ–¯ç‚¹äº‘é‡å»ºäººæœºäº¤æ¥åœºæ™¯ï¼Œç”ŸæˆåŒ…å«å›¾åƒ-åŠ¨ä½œå¯¹çš„æœºå™¨äººæ¼”ç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ºäººæœºäº¤æ¥ä»»åŠ¡æä¾›äº†ä¸€ç§æ–°çš„æœ‰æ•ˆè¡¨ç¤ºï¼Œä¿ƒè¿›äº†æ›´æ— ç¼å’Œç¨³å¥çš„äººæœºåä½œã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³äººæœºäº¤æ¥ä»»åŠ¡ä¸­ï¼Œæœºå™¨äººå¦‚ä½•ä»äººç±»æ‰‹ä¸­å¯é æ¥æ”¶ç‰©ä½“çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå¤§é‡çš„çœŸå®æœºå™¨äººè¯•éªŒï¼Œå¯¼è‡´è®­ç»ƒæˆæœ¬é«˜ä¸”æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç¨€ç–è§†å›¾é«˜æ–¯ç‚¹äº‘é‡å»ºæŠ€æœ¯ï¼Œä»RGBå›¾åƒä¸­ç”Ÿæˆæœºå™¨äººæ¼”ç¤ºï¼Œé¿å…äº†å¯¹çœŸå®æœºå™¨äººè®­ç»ƒçš„ä¾èµ–ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­å­¦ä¹ äººæœºäº¤æ¥è¡Œä¸ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œé€šè¿‡RGBå›¾åƒè¿›è¡Œé«˜æ–¯ç‚¹äº‘é‡å»ºï¼›å…¶æ¬¡ï¼Œç”ŸæˆåŒ…å«å›¾åƒ-åŠ¨ä½œå¯¹çš„æœºå™¨äººæ¼”ç¤ºï¼›æœ€åï¼Œåˆ©ç”¨è¿™äº›æ¼”ç¤ºè¿›è¡Œç­–ç•¥å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„è¡¨ç¤ºæ–¹æ³•ï¼Œé€šè¿‡é«˜æ–¯ç‚¹äº‘é‡å»ºæ¥ç”Ÿæˆæœºå™¨äººæ¼”ç¤ºï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—å‡å°‘äº†å¯¹çœŸå®æ•°æ®çš„éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æœºå™¨äººæŠ“å–çš„ç¨³å®šæ€§ï¼Œå¹¶è®¾è®¡äº†é€‚åº”äºé«˜æ–¯ç‚¹äº‘çš„ç½‘ç»œç»“æ„ï¼Œä»¥æé«˜é‡å»ºç²¾åº¦å’Œå­¦ä¹ æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨é«˜æ–¯ç‚¹äº‘é‡å»ºåœºæ™¯å’ŒçœŸå®äººæœºäº¤æ¥å®éªŒä¸­å‡è¡¨ç°å‡ºè‰²ï¼Œæœºå™¨äººåœ¨æ¥æ”¶ç‰©ä½“æ—¶çš„ç¨³å®šæ€§æé«˜äº†çº¦30%ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå‡å°‘äº†å¯¹çœŸå®æœºå™¨äººè¯•éªŒçš„ä¾èµ–ï¼Œå±•ç¤ºäº†æ›´é«˜çš„è®­ç»ƒæ•ˆç‡å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœåŠ¡æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–å’ŒåŒ»ç–—è¾…åŠ©ç­‰åœºæ™¯ã€‚é€šè¿‡æé«˜äººæœºäº¤æ¥çš„ç¨³å®šæ€§å’Œå¯é æ€§ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æ˜¾è‘—æå‡äººæœºåä½œçš„æ•ˆç‡ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººåœ¨å„è¡Œä¸šçš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Human-robot teaming (HRT) systems often rely on large-scale datasets of human and robot interactions, especially for close-proximity collaboration tasks such as human-robot handovers. Learning robot manipulation policies from raw, real-world image data requires a large number of robot-action trials in the physical environment. Although simulation training offers a cost-effective alternative, the visual domain gap between simulation and robot workspace remains a major limitation. We introduce a method for training HRT policies, focusing on human-to-robot handovers, solely from RGB images without the need for real-robot training or real-robot data collection. The goal is to enable the robot to reliably receive objects from a human with stable grasping while avoiding collisions with the human hand. The proposed policy learner leverages sparse-view Gaussian Splatting reconstruction of human-to-robot handover scenes to generate robot demonstrations containing image-action pairs captured with a camera mounted on the robot gripper. As a result, the simulated camera pose changes in the reconstructed scene can be directly translated into gripper pose changes. Experiments in both Gaussian Splatting reconstructed scene and real-world human-to-robot handover experiments demonstrate that our method serves as a new and effective representation for the human-to-robot handover task, contributing to more seamless and robust HRT.

