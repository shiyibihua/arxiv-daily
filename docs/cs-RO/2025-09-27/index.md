---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-09-27
---

# cs.ROï¼ˆ2025-09-27ï¼‰

ğŸ“Š å…± **17** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (12 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (12 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250923107v2-open-vocabulary-spatio-temporal-scene-graph-for-robot-perception-and.html">Open-Vocabulary Spatio-Temporal Scene Graph for Robot Perception and Teleoperation Planning</a></td>
  <td>æå‡ºæ—¶ç©ºå¼€æ”¾è¯æ±‡åœºæ™¯å›¾(ST-OVSG)ï¼Œå¢å¼ºæœºå™¨äººè¿œç¨‹æ“ä½œåœ¨æ—¶å»¶ä¸‹çš„è§„åˆ’é²æ£’æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">teleoperation</span> <span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23107v2" data-paper-url="./papers/250923107v2-open-vocabulary-spatio-temporal-scene-graph-for-robot-perception-and.html" onclick="toggleFavorite(this, '2509.23107v2', 'Open-Vocabulary Spatio-Temporal Scene Graph for Robot Perception and Teleoperation Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250923223v1-sac-loco-safe-and-adjustable-compliant-quadrupedal-locomotion.html">SAC-Loco: Safe and Adjustable Compliant Quadrupedal Locomotion</a></td>
  <td>æå‡ºSAC-Locoï¼Œå®ç°å››è¶³æœºå™¨äººå®‰å…¨å¯è°ƒçš„æŸ”é¡ºæ­¥æ€æ§åˆ¶</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">locomotion</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23223v1" data-paper-url="./papers/250923223v1-sac-loco-safe-and-adjustable-compliant-quadrupedal-locomotion.html" onclick="toggleFavorite(this, '2509.23223v1', 'SAC-Loco: Safe and Adjustable Compliant Quadrupedal Locomotion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250923075v2-in-hand-manipulation-of-articulated-tools-with-dexterous-robot-hands.html">In-Hand Manipulation of Articulated Tools with Dexterous Robot Hands with Sim-to-Real Transfer</a></td>
  <td>æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ å’Œè§¦è§‰åé¦ˆçš„çµå·§æ‰‹å·¥å…·æ“ä½œSim-to-Realè¿ç§»æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">in-hand manipulation</span> <span class="paper-tag">sim-to-real</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23075v2" data-paper-url="./papers/250923075v2-in-hand-manipulation-of-articulated-tools-with-dexterous-robot-hands.html" onclick="toggleFavorite(this, '2509.23075v2', 'In-Hand Manipulation of Articulated Tools with Dexterous Robot Hands with Sim-to-Real Transfer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250923203v2-ce-nav-flow-guided-reinforcement-refinement-for-cross-embodiment-loc.html">CE-Nav: Flow-Guided Reinforcement Refinement for Cross-Embodiment Local Navigation</a></td>
  <td>CE-Navï¼šé¢å‘è·¨å½¢æ€æœºå™¨äººå±€éƒ¨å¯¼èˆªçš„æµå¼•å¯¼å¼ºåŒ–ç²¾ç‚¼æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">biped</span> <span class="paper-tag">reinforcement learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23203v2" data-paper-url="./papers/250923203v2-ce-nav-flow-guided-reinforcement-refinement-for-cross-embodiment-loc.html" onclick="toggleFavorite(this, '2509.23203v2', 'CE-Nav: Flow-Guided Reinforcement Refinement for Cross-Embodiment Local Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250923281v1-preventing-robotic-jailbreaking-via-multimodal-domain-adaptation.html">Preventing Robotic Jailbreaking via Multimodal Domain Adaptation</a></td>
  <td>æå‡ºJ-DAPTæ¡†æ¶ï¼Œé€šè¿‡å¤šæ¨¡æ€é¢†åŸŸè‡ªé€‚åº”é˜²å¾¡æœºå™¨äººè¶Šç‹±æ”»å‡»</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23281v1" data-paper-url="./papers/250923281v1-preventing-robotic-jailbreaking-via-multimodal-domain-adaptation.html" onclick="toggleFavorite(this, '2509.23281v1', 'Preventing Robotic Jailbreaking via Multimodal Domain Adaptation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250923155v1-lagea-language-guided-embodied-agents-for-robotic-manipulation.html">LAGEA: Language Guided Embodied Agents for Robotic Manipulation</a></td>
  <td>LAGEAï¼šä¸€ç§åŸºäºè¯­è¨€å¼•å¯¼çš„å…·èº«æ™ºèƒ½ä½“ç”¨äºæœºå™¨äººæ“ä½œ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23155v1" data-paper-url="./papers/250923155v1-lagea-language-guided-embodied-agents-for-robotic-manipulation.html" onclick="toggleFavorite(this, '2509.23155v1', 'LAGEA: Language Guided Embodied Agents for Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250923185v1-physically-feasible-reactive-synthesis-for-terrain-adaptive-locomoti.html">Physically-Feasible Reactive Synthesis for Terrain-Adaptive Locomotion</a></td>
  <td>æå‡ºä¸€ç§åœ°å½¢è‡ªé€‚åº”å››è¶³æœºå™¨äººè¿åŠ¨çš„ç‰©ç†å¯è¡Œååº”å¼ç»¼åˆæ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">locomotion</span> <span class="paper-tag">trajectory optimization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23185v1" data-paper-url="./papers/250923185v1-physically-feasible-reactive-synthesis-for-terrain-adaptive-locomoti.html" onclick="toggleFavorite(this, '2509.23185v1', 'Physically-Feasible Reactive Synthesis for Terrain-Adaptive Locomotion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250923468v2-multi-modal-manipulation-via-multi-modal-policy-consensus.html">Multi-Modal Manipulation via Multi-Modal Policy Consensus</a></td>
  <td>æå‡ºåŸºäºå¤šæ¨¡æ€ç­–ç•¥å…±è¯†çš„å¤šæ¨¡æ€æ“ä½œæ–¹æ³•ï¼Œæå‡æœºå™¨äººæ“ä½œçš„é²æ£’æ€§å’Œçµæ´»æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23468v2" data-paper-url="./papers/250923468v2-multi-modal-manipulation-via-multi-modal-policy-consensus.html" onclick="toggleFavorite(this, '2509.23468v2', 'Multi-Modal Manipulation via Multi-Modal Policy Consensus')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250923112v1-ftact-force-torque-aware-action-chunking-transformer-for-pick-and-re.html">FTACT: Force Torque aware Action Chunking Transformer for Pick-and-Reorient Bottle Task</a></td>
  <td>FTACTï¼šåŠ›/åŠ›çŸ©æ„ŸçŸ¥çš„åŠ¨ä½œåˆ†å—Transformerç”¨äºç“¶å­æŠ“å–ä¸é‡å®šå‘ä»»åŠ¡</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">teleoperation</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23112v1" data-paper-url="./papers/250923112v1-ftact-force-torque-aware-action-chunking-transformer-for-pick-and-re.html" onclick="toggleFavorite(this, '2509.23112v1', 'FTACT: Force Torque aware Action Chunking Transformer for Pick-and-Reorient Bottle Task')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250923021v1-uniprototype-humn-robot-skill-learning-with-uniform-prototypes.html">UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes</a></td>
  <td>UniPrototypeï¼šåˆ©ç”¨ç»Ÿä¸€åŸå‹å®ç°äºº-æœºå™¨äººæŠ€èƒ½å­¦ä¹ </td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">human-to-robot</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23021v1" data-paper-url="./papers/250923021v1-uniprototype-humn-robot-skill-learning-with-uniform-prototypes.html" onclick="toggleFavorite(this, '2509.23021v1', 'UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250923328v1-space-robotics-bench-robot-learning-beyond-earth.html">Space Robotics Bench: Robot Learning Beyond Earth</a></td>
  <td>æå‡ºSpace Robotics Benchï¼Œç”¨äºå¤ªç©ºæœºå™¨äººå­¦ä¹ çš„å¼€æºä»¿çœŸæ¡†æ¶ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23328v1" data-paper-url="./papers/250923328v1-space-robotics-bench-robot-learning-beyond-earth.html" onclick="toggleFavorite(this, '2509.23328v1', 'Space Robotics Bench: Robot Learning Beyond Earth')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250923308v1-distributed-multi-robot-multi-target-simultaneous-search-and-trackin.html">Distributed Multi-Robot Multi-Target Simultaneous Search and Tracking in an Unknown Non-convex Environment</a></td>
  <td>æå‡ºä¸€ç§åˆ†å¸ƒå¼å¤šæœºå™¨äººåŒæ­¥æœç´¢ä¸è·Ÿè¸ªç®—æ³•ï¼Œè§£å†³æœªçŸ¥éå‡¸ç¯å¢ƒä¸‹çš„ç›®æ ‡æœç´¢ä¸è·Ÿè¸ªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23308v1" data-paper-url="./papers/250923308v1-distributed-multi-robot-multi-target-simultaneous-search-and-trackin.html" onclick="toggleFavorite(this, '2509.23308v1', 'Distributed Multi-Robot Multi-Target Simultaneous Search and Tracking in an Unknown Non-convex Environment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/250923224v1-leave-no-observation-behind-real-time-correction-for-vla-action-chun.html">Leave No Observation Behind: Real-time Correction for VLA Action Chunks</a></td>
  <td>æå‡ºA2C2å®æ—¶ä¿®æ­£VLAæ¨¡å‹åŠ¨ä½œå—ï¼Œæå‡é•¿æ—¶åºä»»åŠ¡çš„ååº”æ€§å’Œé²æ£’æ€§</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23224v1" data-paper-url="./papers/250923224v1-leave-no-observation-behind-real-time-correction-for-vla-action-chun.html" onclick="toggleFavorite(this, '2509.23224v1', 'Leave No Observation Behind: Real-time Correction for VLA Action Chunks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250923506v1-ask-reason-assist-decentralized-robot-collaboration-via-language-and.html">Ask, Reason, Assist: Decentralized Robot Collaboration via Language and Logic</a></td>
  <td>æå‡ºä¸€ç§åŸºäºè¯­è¨€å’Œé€»è¾‘çš„å»ä¸­å¿ƒåŒ–æœºå™¨äººåä½œæ¡†æ¶ï¼Œè§£å†³ä»“åº“ç­‰åœºæ™¯ä¸‹çš„å†²çªé—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23506v1" data-paper-url="./papers/250923506v1-ask-reason-assist-decentralized-robot-collaboration-via-language-and.html" onclick="toggleFavorite(this, '2509.23506v1', 'Ask, Reason, Assist: Decentralized Robot Collaboration via Language and Logic')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>15</td>
  <td><a href="./papers/250923111v1-liaohe-cobotmagic-pnp-an-imitation-learning-dataset-of-intelligent-r.html">Liaohe-CobotMagic-PnP: an Imitation Learning Dataset of Intelligent Robot for Industrial Applications</a></td>
  <td>Liaohe-CobotMagic-PnPï¼šé¢å‘å·¥ä¸šåº”ç”¨çš„æ™ºèƒ½æœºå™¨äººæ¨¡ä»¿å­¦ä¹ æ•°æ®é›†</td>
  <td class="tags-cell"><span class="paper-tag">imitation learning</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23111v1" data-paper-url="./papers/250923111v1-liaohe-cobotmagic-pnp-an-imitation-learning-dataset-of-intelligent-r.html" onclick="toggleFavorite(this, '2509.23111v1', 'Liaohe-CobotMagic-PnP: an Imitation Learning Dataset of Intelligent Robot for Industrial Applications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250923220v1-glue-global-local-unified-encoding-for-imitation-learning-via-key-pa.html">GLUE: Global-Local Unified Encoding for Imitation Learning via Key-Patch Tracking</a></td>
  <td>æå‡ºGLUEï¼Œé€šè¿‡å…³é”®åŒºåŸŸè·Ÿè¸ªå®ç°æ¨¡ä»¿å­¦ä¹ çš„å…¨å±€-å±€éƒ¨ç»Ÿä¸€ç¼–ç ï¼Œæå‡å¤æ‚ç¯å¢ƒä¸‹çš„ç­–ç•¥æ€§èƒ½ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">imitation learning</span> <span class="paper-tag">representation learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23220v1" data-paper-url="./papers/250923220v1-glue-global-local-unified-encoding-for-imitation-learning-via-key-pa.html" onclick="toggleFavorite(this, '2509.23220v1', 'GLUE: Global-Local Unified Encoding for Imitation Learning via Key-Patch Tracking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/250923118v1-ekf-based-fusion-of-wi-filidarimu-for-indoor-localization-and-naviga.html">EKF-Based Fusion of Wi-Fi/LiDAR/IMU for Indoor Localization and Navigation</a></td>
  <td>æå‡ºåŸºäºEKFçš„Wi-Fi/LiDAR/IMUèåˆå®¤å†…å®šä½å¯¼èˆªæ¡†æ¶ï¼Œæå‡å®šä½ç²¾åº¦å’Œé²æ£’æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">occupancy grid</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23118v1" data-paper-url="./papers/250923118v1-ekf-based-fusion-of-wi-filidarimu-for-indoor-localization-and-naviga.html" onclick="toggleFavorite(this, '2509.23118v1', 'EKF-Based Fusion of Wi-Fi/LiDAR/IMU for Indoor Localization and Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)