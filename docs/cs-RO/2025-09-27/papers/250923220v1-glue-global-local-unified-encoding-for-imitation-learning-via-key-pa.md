---
layout: default
title: GLUE: Global-Local Unified Encoding for Imitation Learning via Key-Patch Tracking
---

# GLUE: Global-Local Unified Encoding for Imitation Learning via Key-Patch Tracking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23220" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23220v1</a>
  <a href="https://arxiv.org/pdf/2509.23220.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23220v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23220v1', 'GLUE: Global-Local Unified Encoding for Imitation Learning via Key-Patch Tracking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ye Chen, Zichen Zhou, Jianyu Dou, Te Cui, Yi Yang, Yufeng Yue

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

**å¤‡æ³¨**: 8 pages, 5 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://GLUE666.github.io/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGLUEï¼Œé€šè¿‡å…³é”®åŒºåŸŸè·Ÿè¸ªå®ç°æ¨¡ä»¿å­¦ä¹ çš„å…¨å±€-å±€éƒ¨ç»Ÿä¸€ç¼–ç ï¼Œæå‡å¤æ‚ç¯å¢ƒä¸‹çš„ç­–ç•¥æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ¨¡ä»¿å­¦ä¹ ` `æœºå™¨äººè§†è§‰` `å…¨å±€-å±€éƒ¨ç¼–ç ` `å…³é”®åŒºåŸŸè·Ÿè¸ª` `åˆ†å¸ƒå¤–æ³›åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤æ‚OODç¯å¢ƒä¸‹çš„æ¨¡ä»¿å­¦ä¹ ï¼Œå…¨å±€è§†è§‰è¡¨å¾æ˜“å—å¹²æ‰°ï¼Œå¯¼è‡´ç­–ç•¥æ€§èƒ½ä¸‹é™ï¼Œå±€éƒ¨è¡¨å¾çš„åˆ©ç”¨æ˜¯å…³é”®ã€‚
2. GLUEé€šè¿‡æ–‡æœ¬å¼•å¯¼æœºåˆ¶é€‰æ‹©å’Œè·Ÿè¸ªå…³é”®åŒºåŸŸï¼Œèåˆå…¨å±€å’Œå±€éƒ¨ç‰¹å¾ï¼Œå¼•å¯¼è§†è§‰æ³¨æ„åŠ›å¹¶ä¿ç•™å…¨å±€ä¸Šä¸‹æ–‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒGLUEåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­å‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨çœŸå®ç¯å¢ƒæ³›åŒ–èƒ½åŠ›ä¸Šæå‡æ˜¾è‘—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè§†è§‰è¡¨å¾å­¦ä¹ åœ¨æœºå™¨äººæ¨¡ä»¿å­¦ä¹ ä¸­å—åˆ°äº†å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œåœ¨ä»¥æ‚ä¹±å’Œé®æŒ¡ä¸ºç‰¹å¾çš„å¤æ‚åˆ†å¸ƒå¤–(OOD)ç¯å¢ƒä¸­ï¼Œå…¨å±€è§†è§‰è¡¨å¾çš„æ³¨æ„åŠ›å¯èƒ½ä¼šè¢«ç¨€é‡Šæˆ–å¹²æ‰°ï¼Œå¯¼è‡´ç­–ç•¥æ€§èƒ½ä¸‹é™ã€‚ä»»åŠ¡ç›¸å…³å¯¹è±¡çš„å±€éƒ¨è¡¨å¾çš„ä¸å˜æ€§æä¾›äº†ä¸€ç§è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡æœ‰æ•ˆåœ°åˆ©ç”¨è¿™äº›å±€éƒ¨è¡¨å¾ï¼Œå¯ä»¥å°†è®­ç»ƒå’Œæµ‹è¯•æ•°æ®æ˜ å°„åˆ°æ›´ç›¸ä¼¼çš„ç‰¹å¾ç©ºé—´ï¼Œä»è€Œç¼“è§£åå˜é‡åç§»é—®é¢˜ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºGLUEï¼Œä¸€ç§åŸºäºå…³é”®åŒºåŸŸè·Ÿè¸ªçš„æ¨¡ä»¿å­¦ä¹ å…¨å±€-å±€éƒ¨ç»Ÿä¸€ç¼–ç æ¡†æ¶ã€‚GLUEé€šè¿‡é‡‡ç”¨æ–‡æœ¬å¼•å¯¼æœºåˆ¶é€‰æ‹©å’Œè·Ÿè¸ªå…³é”®åŒºåŸŸä½œä¸ºå…³é”®å±€éƒ¨è¡¨å¾ã€‚å®ƒé‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„èåˆæ¡†æ¶ï¼Œå…¶ä¸­å…¨å±€patchç‰¹å¾æŸ¥è¯¢å±€éƒ¨patchä»¥æå–å…³é”®ä¿¡æ¯ï¼Œä»è€Œäº§ç”Ÿç›¸å¯¹äºå…¨å±€ä¸Šä¸‹æ–‡å…·æœ‰ä½å¼‚è´¨æ€§çš„ç»†ç²’åº¦å±€éƒ¨ç‰¹å¾ã€‚è¿™ç§èåˆçš„è¡¨å¾å¼•å¯¼æœºå™¨äººçš„è§†è§‰æ³¨æ„åŠ›é›†ä¸­äºä»»åŠ¡ç›¸å…³çš„å¯¹è±¡ï¼Œå¹¶ä¿ç•™ç²¾ç¡®çš„å…¨å±€ä¸Šä¸‹æ–‡ï¼Œä»è€Œå°†è®­ç»ƒå’Œæµ‹è¯•åˆ†å¸ƒå¯¹é½åˆ°ç›¸ä¼¼ä¸”å…·æœ‰ä»»åŠ¡ä¿¡æ¯çš„ç‰¹å¾ç©ºé—´ä¸­ï¼Œæœ€ç»ˆå¢å¼ºæ¨¡ä»¿å­¦ä¹ ç­–ç•¥çš„é²æ£’æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒGLUEåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­çš„å„ç§ä»»åŠ¡ä¸­éƒ½å–å¾—äº†å¼ºå¤§çš„æ€§èƒ½ï¼Œåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­ä¼˜äºæœ€å¼ºçš„åŸºçº¿17.6%ï¼Œåœ¨çœŸå®ç¯å¢ƒä¸­ä¼˜äº36.3%ï¼Œåœ¨çœŸå®ç¯å¢ƒæ³›åŒ–è®¾ç½®ä¸­ä¼˜äº58.3%ã€‚GLUEçš„é¡¹ç›®ç½‘ç«™å¯åœ¨https://GLUE666.github.io/ä¸Šæ‰¾åˆ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤æ‚ç¯å¢ƒä¸­æ¨¡ä»¿å­¦ä¹ ç­–ç•¥æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å­˜åœ¨æ‚ä¹±ã€é®æŒ¡ç­‰å¹²æ‰°å› ç´ çš„åˆ†å¸ƒå¤–(OOD)åœºæ™¯ä¸‹ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–çš„å…¨å±€è§†è§‰è¡¨å¾å®¹æ˜“å—åˆ°å¹²æ‰°ï¼Œå¯¼è‡´ç­–ç•¥æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å±€éƒ¨è¡¨å¾çš„ä¸å˜æ€§æ¥ç¼“è§£åå˜é‡åç§»é—®é¢˜ã€‚é€šè¿‡é€‰æ‹©å’Œè·Ÿè¸ªå…³é”®åŒºåŸŸï¼ˆKey-Patchesï¼‰ï¼Œå¹¶å°†å…¶ä¸å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯èåˆï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿä¸“æ³¨äºä»»åŠ¡ç›¸å…³çš„å¯¹è±¡ï¼Œå¹¶å‡å°‘è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ä¹‹é—´çš„å·®å¼‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGLUEæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) **å…³é”®åŒºåŸŸé€‰æ‹©ä¸è·Ÿè¸ª**ï¼šä½¿ç”¨æ–‡æœ¬å¼•å¯¼æœºåˆ¶é€‰æ‹©å’Œè·Ÿè¸ªå›¾åƒä¸­çš„å…³é”®åŒºåŸŸï¼Œè¿™äº›åŒºåŸŸè¢«è®¤ä¸ºæ˜¯ä¸ä»»åŠ¡æœ€ç›¸å…³çš„å±€éƒ¨ç‰¹å¾ã€‚2) **å…¨å±€-å±€éƒ¨ç‰¹å¾èåˆ**ï¼šè®¾è®¡äº†ä¸€ç§æ–°é¢–çš„èåˆæ¡†æ¶ï¼Œå…¶ä¸­å…¨å±€patchç‰¹å¾æŸ¥è¯¢å±€éƒ¨patchï¼Œä»¥æå–å…³é”®ä¿¡æ¯ï¼Œç”Ÿæˆç»†ç²’åº¦çš„å±€éƒ¨ç‰¹å¾ã€‚3) **ç­–ç•¥å­¦ä¹ **ï¼šä½¿ç”¨èåˆåçš„å…¨å±€-å±€éƒ¨ç‰¹å¾è®­ç»ƒæ¨¡ä»¿å­¦ä¹ ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šGLUEçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å…¨å±€-å±€éƒ¨ç»Ÿä¸€ç¼–ç æ¡†æ¶ï¼Œç‰¹åˆ«æ˜¯æ–‡æœ¬å¼•å¯¼çš„å…³é”®åŒºåŸŸé€‰æ‹©å’Œè·Ÿè¸ªæœºåˆ¶ï¼Œä»¥åŠå…¨å±€ç‰¹å¾æŸ¥è¯¢å±€éƒ¨ç‰¹å¾çš„èåˆæ–¹å¼ã€‚è¿™ç§èåˆæ–¹å¼èƒ½å¤Ÿæœ‰æ•ˆåœ°æå–ä»»åŠ¡ç›¸å…³çš„å±€éƒ¨ä¿¡æ¯ï¼Œå¹¶å°†å…¶ä¸å…¨å±€ä¸Šä¸‹æ–‡ç›¸ç»“åˆï¼Œä»è€Œæé«˜ç­–ç•¥çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒGLUEæ›´å…³æ³¨äºæå–å’Œåˆ©ç”¨å›¾åƒä¸­çš„å…³é”®å±€éƒ¨ä¿¡æ¯ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–äºå…¨å±€è¡¨å¾ã€‚

**å…³é”®è®¾è®¡**ï¼šæ–‡æœ¬å¼•å¯¼æœºåˆ¶çš„å…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ï¼Œä½†æ¨æµ‹å¯èƒ½ä½¿ç”¨äº†é¢„è®­ç»ƒçš„æ–‡æœ¬-å›¾åƒæ¨¡å‹ï¼ˆå¦‚CLIPï¼‰æ¥æŒ‡å¯¼å…³é”®åŒºåŸŸçš„é€‰æ‹©ã€‚èåˆæ¡†æ¶çš„å…·ä½“ç½‘ç»œç»“æ„ä¹ŸæœªçŸ¥ï¼Œä½†å¯ä»¥æ¨æµ‹ä½¿ç”¨äº†æ³¨æ„åŠ›æœºåˆ¶æˆ–ç±»ä¼¼çš„query-key-valueç»“æ„æ¥å®ç°å…¨å±€ç‰¹å¾å¯¹å±€éƒ¨ç‰¹å¾çš„æŸ¥è¯¢ã€‚æŸå¤±å‡½æ•°æ–¹é¢ï¼Œé™¤äº†æ ‡å‡†çš„æ¨¡ä»¿å­¦ä¹ æŸå¤±å¤–ï¼Œå¯èƒ½è¿˜ä½¿ç”¨äº†é¢å¤–çš„æŸå¤±å‡½æ•°æ¥é¼“åŠ±å…³é”®åŒºåŸŸçš„ç¨³å®šè·Ÿè¸ªå’Œç‰¹å¾çš„æœ‰æ•ˆèåˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

GLUEåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­çš„å¤šä¸ªä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­ï¼ŒGLUEä¼˜äºæœ€å¼ºçš„åŸºçº¿17.6%ï¼›åœ¨çœŸå®ç¯å¢ƒä¸­ï¼ŒGLUEä¼˜äºæœ€å¼ºçš„åŸºçº¿36.3%ï¼›åœ¨çœŸå®ç¯å¢ƒæ³›åŒ–è®¾ç½®ä¸­ï¼ŒGLUEä¼˜äºæœ€å¼ºçš„åŸºçº¿58.3%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒGLUEèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜æ¨¡ä»¿å­¦ä¹ ç­–ç•¥çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨çœŸå®ä¸–ç•Œçš„å¤æ‚ç¯å¢ƒä¸­ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GLUEæ¡†æ¶å¯åº”ç”¨äºå„ç§æœºå™¨äººæ¨¡ä»¿å­¦ä¹ ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚ã€åŠ¨æ€å’Œåˆ†å¸ƒå¤–ç¯å¢ƒä¸­ã€‚ä¾‹å¦‚ï¼Œå®ƒå¯ä»¥ç”¨äºå®¶åº­æœåŠ¡æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€å·¥ä¸šè‡ªåŠ¨åŒ–ç­‰é¢†åŸŸï¼Œæé«˜æœºå™¨äººåœ¨çœŸå®ä¸–ç•Œä¸­çš„é€‚åº”æ€§å’Œé²æ£’æ€§ã€‚è¯¥ç ”ç©¶å¯¹äºæå‡æœºå™¨äººæ™ºèƒ½æ°´å¹³ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œæ‰§è¡Œå¤æ‚ä»»åŠ¡å…·æœ‰é‡è¦æ„ä¹‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In recent years, visual representation learning has gained widespread attention in robotic imitation learning. However, in complex Out-of-Distribution(OOD) settings characterized by clutter and occlusion, the attention of global visual representations can be diluted or interfered, leading to degraded policy performance. The invariance of local representations for task-relevant objects offers a solution. By efficiently utilizing these local representations, training and testing data can be mapped to a more similar feature space, thereby mitigating the covariate shift problem. Accordingly, we propose GLUE, a global-local unified encoding framework for imitation learning based on key-patch tracking. GLUE selects and tracks key-patches as critical local representations by employing a text-guided mechanism. It features a novel fusion framework where global patch features query local patches to distill essential information, yielding fine-grained local features with low heterogeneity relative to the global context. This fused representation steers the robot's visual attention toward task-relevant objects and preserves precise global context, which together align the training and testing distributions into a similar and task-informative feature space, ultimately enhancing the robustness of the imitation learning policy. Experiments demonstrate that GLUE achieves strong performance across diverse tasks in both simulation and real-world settings, outperforming the strongest baseline by 17.6% in simulation, 36.3% in real-world environments, and 58.3% on real-world generalization settings. The project website of GLUE is available at https://GLUE666.github.io/.

