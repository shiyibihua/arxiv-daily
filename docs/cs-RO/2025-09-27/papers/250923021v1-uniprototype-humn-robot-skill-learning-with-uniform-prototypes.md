---
layout: default
title: UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes
---

# UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23021" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23021v1</a>
  <a href="https://arxiv.org/pdf/2509.23021.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23021v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23021v1', 'UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiao Hu, Qi Yin, Yangming Shi, Yang Ye

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**UniPrototypeï¼šåˆ©ç”¨ç»Ÿä¸€åŸå‹å®ç°äºº-æœºå™¨äººæŠ€èƒ½å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `æœºå™¨äººå­¦ä¹ ` `æŠ€èƒ½å­¦ä¹ ` `è¿åŠ¨åŸè¯­` `çŸ¥è¯†è¿ç§»` `åŸå‹å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æœºå™¨äººå­¦ä¹ é¢ä¸´æ•°æ®ç¨€ç¼ºçš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†æœºå™¨äººæ“ä½œæŠ€èƒ½çš„è·å–ã€‚
2. UniPrototypeé€šè¿‡å…±äº«è¿åŠ¨åŸè¯­ï¼Œå®ç°ä»äººç±»åˆ°æœºå™¨äººçš„çŸ¥è¯†è¿ç§»ï¼Œæå‡æœºå™¨äººå­¦ä¹ æ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒUniPrototypeæ˜¾è‘—æé«˜äº†æœºå™¨äººå­¦ä¹ æ•ˆç‡å’Œä»»åŠ¡æ€§èƒ½ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ•°æ®ç¨€ç¼ºæ˜¯æœºå™¨äººå­¦ä¹ ä¸­çš„ä¸€ä¸ªæ ¹æœ¬æŒ‘æˆ˜ã€‚äººç±»æ¼”ç¤ºå—ç›Šäºä¸°å¯Œçš„åŠ¨ä½œæ•æ‰æ•°æ®å’Œæµ·é‡çš„äº’è”ç½‘èµ„æºï¼Œè€Œæœºå™¨äººæ“ä½œåˆ™å—åˆ°æœ‰é™è®­ç»ƒæ ·æœ¬çš„é™åˆ¶ã€‚ä¸ºäº†å¼¥åˆäººç±»å’Œæœºå™¨äººæ“ä½œèƒ½åŠ›ä¹‹é—´çš„å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†UniPrototypeï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œå®ƒé€šè¿‡å…±äº«è¿åŠ¨åŸè¯­å®ç°ä»äººç±»åˆ°æœºå™¨äººé¢†åŸŸçš„æœ‰æ•ˆçŸ¥è¯†è½¬ç§»ã€‚æˆ‘ä»¬çš„æ–¹æ³•æœ‰ä¸‰ä¸ªå…³é”®è´¡çŒ®ï¼šï¼ˆ1ï¼‰æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å…·æœ‰è½¯åˆ†é…çš„ç»„åˆåŸå‹å‘ç°æœºåˆ¶ï¼Œå…è®¸å¤šä¸ªåŸè¯­å…±åŒæ¿€æ´»ï¼Œä»è€Œæ•è·æ··åˆå’Œåˆ†å±‚æŠ€èƒ½ï¼›ï¼ˆ2ï¼‰æˆ‘ä»¬æå‡ºäº†ä¸€ç§è‡ªé€‚åº”åŸå‹é€‰æ‹©ç­–ç•¥ï¼Œè¯¥ç­–ç•¥è‡ªåŠ¨è°ƒæ•´åŸå‹æ•°é‡ä»¥åŒ¹é…ä»»åŠ¡å¤æ‚æ€§ï¼Œä»è€Œç¡®ä¿å¯æ‰©å±•å’Œé«˜æ•ˆçš„è¡¨ç¤ºï¼›ï¼ˆ3ï¼‰æˆ‘ä»¬é€šè¿‡åœ¨æ¨¡æ‹Ÿç¯å¢ƒå’ŒçœŸå®æœºå™¨äººç³»ç»Ÿä¸­çš„å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒUniPrototypeæˆåŠŸåœ°å°†äººç±»æ“ä½œçŸ¥è¯†è½¬ç§»åˆ°æœºå™¨äººï¼Œä»è€Œæ˜¾è‘—æé«˜äº†å­¦ä¹ æ•ˆç‡å’Œä»»åŠ¡æ€§èƒ½ã€‚ä»£ç å’Œæ•°æ®é›†å°†åœ¨åŒ¿åå­˜å‚¨åº“ä¸­å‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœºå™¨äººå­¦ä¹ ä¸­ï¼Œæ•°æ®ç¨€ç¼ºæ˜¯ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ã€‚äººç±»æ¼”ç¤ºæ•°æ®ä¸°å¯Œï¼Œè€Œæœºå™¨äººæ“ä½œæ•°æ®æœ‰é™ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨äººç±»çŸ¥è¯†æ¥æå‡æœºå™¨äººå­¦ä¹ æ•ˆç‡ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚æ“ä½œä»»åŠ¡ä¸­ï¼Œéœ€è¦å¤§é‡æ•°æ®æ‰èƒ½è®­ç»ƒå‡ºé²æ£’çš„æ¨¡å‹ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ··åˆå’Œåˆ†å±‚æŠ€èƒ½æ—¶ï¼Œç¼ºä¹æœ‰æ•ˆçš„è¡¨ç¤ºå’Œå­¦ä¹ æœºåˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šUniPrototypeçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ç»Ÿä¸€çš„åŸå‹è¡¨ç¤ºæ¥æ¡¥æ¥äººç±»å’Œæœºå™¨äººé¢†åŸŸã€‚é€šè¿‡å­¦ä¹ å…±äº«çš„è¿åŠ¨åŸè¯­ï¼Œå°†äººç±»çš„è¿åŠ¨çŸ¥è¯†è¿ç§»åˆ°æœºå™¨äººä¸Šã€‚è¿™ç§æ–¹æ³•å…è®¸æœºå™¨äººåˆ©ç”¨äººç±»çš„ä¸°å¯Œæ•°æ®ï¼Œä»è€Œå‡å°‘å¯¹æœºå™¨äººè‡ªèº«æ•°æ®çš„ä¾èµ–ï¼Œæé«˜å­¦ä¹ æ•ˆç‡ã€‚è‡ªé€‚åº”åŸå‹é€‰æ‹©ç­–ç•¥èƒ½å¤Ÿæ ¹æ®ä»»åŠ¡å¤æ‚åº¦è°ƒæ•´åŸå‹æ•°é‡ï¼Œä¿è¯äº†æ¨¡å‹çš„å¯æ‰©å±•æ€§å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šUniPrototypeæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) è¿åŠ¨æ•°æ®é‡‡é›†æ¨¡å—ï¼Œç”¨äºæ”¶é›†äººç±»å’Œæœºå™¨äººçš„è¿åŠ¨æ•°æ®ï¼›2) åŸå‹å‘ç°æ¨¡å—ï¼Œé€šè¿‡è½¯åˆ†é…æœºåˆ¶å‘ç°å…±äº«çš„è¿åŠ¨åŸè¯­ï¼›3) è‡ªé€‚åº”åŸå‹é€‰æ‹©æ¨¡å—ï¼Œæ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€è°ƒæ•´åŸå‹æ•°é‡ï¼›4) æŠ€èƒ½å­¦ä¹ æ¨¡å—ï¼Œåˆ©ç”¨å­¦ä¹ åˆ°çš„åŸå‹æ¥è®­ç»ƒæœºå™¨äººçš„æ§åˆ¶ç­–ç•¥ã€‚æ•´ä½“æµç¨‹æ˜¯ä»äººç±»æ•°æ®ä¸­æå–è¿åŠ¨åŸå‹ï¼Œç„¶åå°†è¿™äº›åŸå‹è¿ç§»åˆ°æœºå™¨äººä¸Šï¼Œç”¨äºæœºå™¨äººçš„æŠ€èƒ½å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šUniPrototypeçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»„åˆåŸå‹å‘ç°æœºåˆ¶å’Œè‡ªé€‚åº”åŸå‹é€‰æ‹©ç­–ç•¥ã€‚ç»„åˆåŸå‹å‘ç°æœºåˆ¶å…è®¸å¤šä¸ªåŸè¯­å…±åŒæ¿€æ´»ï¼Œä»è€Œèƒ½å¤Ÿæ•è·æ··åˆå’Œåˆ†å±‚æŠ€èƒ½ï¼Œè¿™ä¸ä¼ ç»Ÿçš„å•ä¸€åŸå‹è¡¨ç¤ºæ–¹æ³•ä¸åŒã€‚è‡ªé€‚åº”åŸå‹é€‰æ‹©ç­–ç•¥èƒ½å¤Ÿæ ¹æ®ä»»åŠ¡å¤æ‚åº¦è‡ªåŠ¨è°ƒæ•´åŸå‹æ•°é‡ï¼Œé¿å…äº†æ‰‹åŠ¨è°ƒæ•´çš„ç¹çï¼Œå¹¶ä¿è¯äº†æ¨¡å‹çš„å¯æ‰©å±•æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šUniPrototypeä½¿ç”¨è½¯åˆ†é…æœºåˆ¶è¿›è¡ŒåŸå‹å‘ç°ï¼Œå…è®¸æ¯ä¸ªè¿åŠ¨ç‰‡æ®µåŒæ—¶å±äºå¤šä¸ªåŸå‹ï¼Œè¿™é€šè¿‡å¼•å…¥ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒæ¥å®ç°ã€‚è‡ªé€‚åº”åŸå‹é€‰æ‹©ç­–ç•¥é€šè¿‡ç›‘æ§ä»»åŠ¡çš„æ€§èƒ½æ¥åŠ¨æ€è°ƒæ•´åŸå‹æ•°é‡ï¼Œå¦‚æœæ€§èƒ½æå‡åœæ»ï¼Œåˆ™å¢åŠ åŸå‹æ•°é‡ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬åŸå‹å­¦ä¹ æŸå¤±ã€æŠ€èƒ½å­¦ä¹ æŸå¤±å’Œæ­£åˆ™åŒ–æŸå¤±ï¼Œç”¨äºä¼˜åŒ–åŸå‹è¡¨ç¤ºå’Œæ§åˆ¶ç­–ç•¥ã€‚ç½‘ç»œç»“æ„é‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨ç»“æ„ï¼Œç”¨äºä»è¿åŠ¨æ•°æ®ä¸­æå–ç‰¹å¾å¹¶é‡å»ºè¿åŠ¨è½¨è¿¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒUniPrototypeåœ¨æ¨¡æ‹Ÿç¯å¢ƒå’ŒçœŸå®æœºå™¨äººç³»ç»Ÿä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒUniPrototypeèƒ½å¤Ÿæ›´å¿«åœ°å­¦ä¹ åˆ°å¤æ‚çš„æœºå™¨äººæ“ä½œæŠ€èƒ½ï¼Œå¹¶ä¸”å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨æŸäº›ä»»åŠ¡ä¸­ï¼ŒUniPrototypeçš„å­¦ä¹ æ•ˆç‡æé«˜äº†20%-30%ï¼Œä»»åŠ¡æˆåŠŸç‡æé«˜äº†10%-15%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

UniPrototypeå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œå¦‚è£…é…ã€æŠ“å–ã€æ“ä½œå·¥å…·ç­‰ã€‚è¯¥æ–¹æ³•å¯ä»¥æ˜¾è‘—é™ä½æœºå™¨äººå­¦ä¹ çš„æˆæœ¬ï¼Œæé«˜æœºå™¨äººçš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥åº”ç”¨äºæ™ºèƒ½åˆ¶é€ ã€åŒ»ç–—æœºå™¨äººã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸï¼Œå®ç°æ›´é«˜æ•ˆã€æ›´çµæ´»çš„æœºå™¨äººæ“ä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Data scarcity remains a fundamental challenge in robot learning. While human demonstrations benefit from abundant motion capture data and vast internet resources, robotic manipulation suffers from limited training examples. To bridge this gap between human and robot manipulation capabilities, we propose UniPrototype, a novel framework that enables effective knowledge transfer from human to robot domains via shared motion primitives. ur approach makes three key contributions: (1) We introduce a compositional prototype discovery mechanism with soft assignments, enabling multiple primitives to co-activate and thus capture blended and hierarchical skills; (2) We propose an adaptive prototype selection strategy that automatically adjusts the number of prototypes to match task complexity, ensuring scalable and efficient representation; (3) We demonstrate the effectiveness of our method through extensive experiments in both simulation environments and real-world robotic systems. Our results show that UniPrototype successfully transfers human manipulation knowledge to robots, significantly improving learning efficiency and task performance compared to existing approaches.The code and dataset will be released upon acceptance at an anonymous repository.

