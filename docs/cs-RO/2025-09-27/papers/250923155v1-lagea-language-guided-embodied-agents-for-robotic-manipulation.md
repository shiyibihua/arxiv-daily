---
layout: default
title: LAGEA: Language Guided Embodied Agents for Robotic Manipulation
---

# LAGEA: Language Guided Embodied Agents for Robotic Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23155" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23155v1</a>
  <a href="https://arxiv.org/pdf/2509.23155.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23155v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23155v1', 'LAGEA: Language Guided Embodied Agents for Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Abdul Monaf Chowdhury, Akm Moshiur Rahman Mazumder, Rabeya Akter, Safaeid Hossain Arib

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**LAGEAï¼šä¸€ç§åŸºäºè¯­è¨€å¼•å¯¼çš„å…·èº«æ™ºèƒ½ä½“ç”¨äºæœºå™¨äººæ“ä½œ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `å…·èº«æ™ºèƒ½ä½“` `å¼ºåŒ–å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡å‹` `è¯­è¨€å¼•å¯¼` `é”™è¯¯çº æ­£` `Meta-World` `å¥–åŠ±å¡‘é€ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººæ“ä½œæ–¹æ³•ç¼ºä¹ä»è‡ªèº«é”™è¯¯ä¸­å­¦ä¹ çš„æœ‰æ•ˆæœºåˆ¶ï¼Œé˜»ç¢äº†å…¶æ€§èƒ½æå‡ã€‚
2. LAGEAæ¡†æ¶åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ç”Ÿæˆåé¦ˆï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå¼ºåŒ–å­¦ä¹ çš„æŒ‡å¯¼ä¿¡å·ï¼Œå¸®åŠ©æ™ºèƒ½ä½“çº æ­£é”™è¯¯ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLAGEAåœ¨Meta-World MT10åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æˆåŠŸç‡ï¼Œå¹¶åŠ å¿«äº†æ”¶æ•›é€Ÿåº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœºå™¨äººæ“ä½œå—ç›Šäºæè¿°ç›®æ ‡çš„åŸºç¡€æ¨¡å‹ï¼Œä½†ç›®å‰çš„æ™ºèƒ½ä½“ä»ç„¶ç¼ºä¹ä»è‡ªèº«é”™è¯¯ä¸­å­¦ä¹ çš„æœ‰æ•ˆæ–¹æ³•ã€‚æœ¬æ–‡æ¢è®¨äº†è‡ªç„¶è¯­è¨€æ˜¯å¦å¯ä»¥ä½œä¸ºåé¦ˆï¼Œä¸€ç§é”™è¯¯æ¨ç†ä¿¡å·ï¼Œå¸®åŠ©å…·èº«æ™ºèƒ½ä½“è¯Šæ–­é”™è¯¯å¹¶çº æ­£æ–¹å‘ã€‚æˆ‘ä»¬æå‡ºäº†LAGEAï¼ˆLanguage Guided Embodied Agentsï¼‰ï¼Œä¸€ä¸ªå°†æ¥è‡ªè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„æƒ…æ™¯åŒ–ã€æ¨¡å¼çº¦æŸçš„åé¦ˆè½¬åŒ–ä¸ºå¼ºåŒ–å­¦ä¹ çš„æ—¶é—´å¯¹é½æŒ‡å¯¼çš„æ¡†æ¶ã€‚LAGEAç”¨ç®€æ´çš„è¯­è¨€æ€»ç»“æ¯æ¬¡å°è¯•ï¼Œå®šä½è½¨è¿¹ä¸­çš„å…³é”®æ—¶åˆ»ï¼Œåœ¨å…±äº«è¡¨ç¤ºä¸­å°†åé¦ˆä¸è§†è§‰çŠ¶æ€å¯¹é½ï¼Œå¹¶å°†ç›®æ ‡è¿›åº¦å’Œåé¦ˆä¸€è‡´æ€§è½¬åŒ–ä¸ºæœ‰ç•Œçš„ã€é€æ­¥çš„å¡‘é€ å¥–åŠ±ï¼Œå…¶å½±å“ç”±è‡ªé€‚åº”çš„ã€æ„ŸçŸ¥å¤±è´¥çš„ç³»æ•°è°ƒèŠ‚ã€‚è¿™ç§è®¾è®¡åœ¨æ¢ç´¢éœ€è¦æŒ‡å¯¼æ—¶ï¼Œå°½æ—©äº§ç”Ÿå¯†é›†çš„ä¿¡å·ï¼Œå¹¶åœ¨èƒ½åŠ›å¢é•¿æ—¶ä¼˜é›…åœ°æ¶ˆé€€ã€‚åœ¨Meta-World MT10å…·èº«æ“ä½œåŸºå‡†æµ‹è¯•ä¸­ï¼ŒLAGEAåœ¨éšæœºç›®æ ‡ä¸Šçš„å¹³å‡æˆåŠŸç‡æ¯”æœ€å…ˆè¿›ï¼ˆSOTAï¼‰æ–¹æ³•æé«˜äº†9.0%ï¼Œåœ¨å›ºå®šç›®æ ‡ä¸Šæé«˜äº†5.3%ï¼ŒåŒæ—¶æ”¶æ•›é€Ÿåº¦æ›´å¿«ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æˆ‘ä»¬çš„å‡è®¾ï¼šå½“è¯­è¨€è¢«ç»“æ„åŒ–å¹¶ä¸æ—¶é—´å¯¹é½æ—¶ï¼Œå®ƒæ˜¯ä¸€ç§æœ‰æ•ˆçš„æœºåˆ¶ï¼Œå¯ä»¥æ•™å¯¼æœºå™¨äººè‡ªæˆ‘åæ€é”™è¯¯å¹¶åšå‡ºæ›´å¥½çš„é€‰æ‹©ã€‚ä»£ç å³å°†å‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæ“ä½œä¸­æ™ºèƒ½ä½“éš¾ä»¥ä»è‡ªèº«é”™è¯¯ä¸­å­¦ä¹ çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºç¨€ç–çš„å¥–åŠ±ä¿¡å·æˆ–äººå·¥è®¾è®¡çš„å¯å‘å¼è§„åˆ™ï¼Œéš¾ä»¥æœ‰æ•ˆåœ°æŒ‡å¯¼æ™ºèƒ½ä½“è¿›è¡Œæ¢ç´¢å’Œå­¦ä¹ ã€‚è¿™å¯¼è‡´äº†è®­ç»ƒæ•ˆç‡ä½ä¸‹ï¼Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ç­‰é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è‡ªç„¶è¯­è¨€ä½œä¸ºåé¦ˆä¿¡å·ï¼Œå¼•å¯¼æ™ºèƒ½ä½“è¿›è¡Œé”™è¯¯åˆ†æå’Œè¡Œä¸ºçº æ­£ã€‚é€šè¿‡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å¯¹æ™ºèƒ½ä½“çš„è¡Œä¸ºè¿›è¡Œè¯„ä»·ï¼Œç”Ÿæˆç®€æ´çš„è¯­è¨€æè¿°ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå¼ºåŒ–å­¦ä¹ çš„æŒ‡å¯¼ä¿¡å·ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæä¾›æ›´ä¸°å¯Œã€æ›´å…·è§£é‡Šæ€§çš„åé¦ˆä¿¡æ¯ï¼Œä»è€Œå¸®åŠ©æ™ºèƒ½ä½“æ›´å¥½åœ°ç†è§£è‡ªèº«çš„é”™è¯¯å¹¶æ”¹è¿›ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLAGEAæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼šç”¨äºå¯¹æ™ºèƒ½ä½“çš„è¡Œä¸ºè¿›è¡Œè¯„ä»·ï¼Œç”Ÿæˆè¯­è¨€æè¿°ã€‚2) æ—¶é—´å¯¹é½æ¨¡å—ï¼šç”¨äºå°†è¯­è¨€åé¦ˆä¸æ™ºèƒ½ä½“çš„è§†è§‰çŠ¶æ€è¿›è¡Œå¯¹é½ï¼Œç¡®å®šè½¨è¿¹ä¸­çš„å…³é”®æ—¶åˆ»ã€‚3) å¥–åŠ±å¡‘é€ æ¨¡å—ï¼šç”¨äºå°†è¯­è¨€åé¦ˆè½¬åŒ–ä¸ºå¼ºåŒ–å­¦ä¹ çš„å¡‘é€ å¥–åŠ±ï¼Œå¼•å¯¼æ™ºèƒ½ä½“è¿›è¡Œå­¦ä¹ ã€‚4) è‡ªé€‚åº”ç³»æ•°æ¨¡å—ï¼šç”¨äºæ ¹æ®æ™ºèƒ½ä½“çš„å­¦ä¹ è¿›åº¦ï¼ŒåŠ¨æ€è°ƒæ•´å¡‘é€ å¥–åŠ±çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šLAGEAçš„å…³é”®åˆ›æ–°åœ¨äºå°†è§†è§‰è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„è¯­è¨€åé¦ˆä¸å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æœºå™¨äººæ“ä½œå­¦ä¹ æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºç¨€ç–å¥–åŠ±æˆ–äººå·¥è§„åˆ™çš„æ–¹æ³•ç›¸æ¯”ï¼ŒLAGEAèƒ½å¤Ÿæä¾›æ›´ä¸°å¯Œã€æ›´å…·è§£é‡Šæ€§çš„åé¦ˆä¿¡æ¯ï¼Œä»è€Œæé«˜å­¦ä¹ æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒLAGEAè¿˜å¼•å…¥äº†è‡ªé€‚åº”ç³»æ•°æ¨¡å—ï¼Œèƒ½å¤Ÿæ ¹æ®æ™ºèƒ½ä½“çš„å­¦ä¹ è¿›åº¦åŠ¨æ€è°ƒæ•´å¡‘é€ å¥–åŠ±çš„å½±å“ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–å­¦ä¹ è¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šLAGEAä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆå¦‚CLIPï¼‰æ¥ç”Ÿæˆè¯­è¨€åé¦ˆã€‚æ—¶é—´å¯¹é½æ¨¡å—ä½¿ç”¨åŠ¨æ€æ—¶é—´è§„æ•´ï¼ˆDTWï¼‰ç®—æ³•å°†è¯­è¨€åé¦ˆä¸è§†è§‰çŠ¶æ€è¿›è¡Œå¯¹é½ã€‚å¥–åŠ±å¡‘é€ æ¨¡å—å°†ç›®æ ‡è¿›åº¦å’Œåé¦ˆä¸€è‡´æ€§è½¬åŒ–ä¸ºæœ‰ç•Œçš„ã€é€æ­¥çš„å¡‘é€ å¥–åŠ±ã€‚è‡ªé€‚åº”ç³»æ•°æ¨¡å—ä½¿ç”¨sigmoidå‡½æ•°æ¥è°ƒèŠ‚å¡‘é€ å¥–åŠ±çš„å½±å“ï¼Œä½¿å…¶åœ¨æ¢ç´¢åˆæœŸå‘æŒ¥æ›´å¤§çš„ä½œç”¨ï¼Œå¹¶åœ¨èƒ½åŠ›å¢é•¿æ—¶é€æ¸å‡å°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

LAGEAåœ¨Meta-World MT10å…·èº«æ“ä½œåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨éšæœºç›®æ ‡ä¸Šï¼ŒLAGEAçš„å¹³å‡æˆåŠŸç‡æ¯”æœ€å…ˆè¿›æ–¹æ³•æé«˜äº†9.0%ï¼›åœ¨å›ºå®šç›®æ ‡ä¸Šï¼ŒLAGEAçš„å¹³å‡æˆåŠŸç‡æ¯”æœ€å…ˆè¿›æ–¹æ³•æé«˜äº†5.3%ã€‚æ­¤å¤–ï¼ŒLAGEAè¿˜è¡¨ç°å‡ºæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ï¼Œè¡¨æ˜å…¶å…·æœ‰æ›´é«˜çš„å­¦ä¹ æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LAGEAæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œå¦‚ç‰©ä½“æŠ“å–ã€è£…é…ã€å¯¼èˆªç­‰ã€‚è¯¥ç ”ç©¶æˆæœæœ‰åŠ©äºæé«˜æœºå™¨äººçš„è‡ªä¸»æ€§å’Œæ™ºèƒ½åŒ–æ°´å¹³ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å¤æ‚å¤šå˜çš„ç¯å¢ƒï¼Œå¹¶åœ¨å·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—åº·å¤ã€å®¶åº­æœåŠ¡ç­‰é¢†åŸŸå‘æŒ¥æ›´å¤§çš„ä½œç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„å…·èº«æ™ºèƒ½ä½“ï¼Œå¦‚æ— äººæœºã€è‡ªåŠ¨é©¾é©¶æ±½è½¦ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Robotic manipulation benefits from foundation models that describe goals, but today's agents still lack a principled way to learn from their own mistakes. We ask whether natural language can serve as feedback, an error reasoning signal that helps embodied agents diagnose what went wrong and correct course. We introduce LAGEA (Language Guided Embodied Agents), a framework that turns episodic, schema-constrained reflections from a vision language model (VLM) into temporally grounded guidance for reinforcement learning. LAGEA summarizes each attempt in concise language, localizes the decisive moments in the trajectory, aligns feedback with visual state in a shared representation, and converts goal progress and feedback agreement into bounded, step-wise shaping rewardswhose influence is modulated by an adaptive, failure-aware coefficient. This design yields dense signals early when exploration needs direction and gracefully recedes as competence grows. On the Meta-World MT10 embodied manipulation benchmark, LAGEA improves average success over the state-of-the-art (SOTA) methods by 9.0% on random goals and 5.3% on fixed goals, while converging faster. These results support our hypothesis: language, when structured and grounded in time, is an effective mechanism for teaching robots to self-reflect on mistakes and make better choices. Code will be released soon.

