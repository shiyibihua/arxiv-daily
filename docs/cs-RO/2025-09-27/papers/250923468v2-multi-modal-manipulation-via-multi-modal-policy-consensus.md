---
layout: default
title: Multi-Modal Manipulation via Multi-Modal Policy Consensus
---

# Multi-Modal Manipulation via Multi-Modal Policy Consensus

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23468" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23468v2</a>
  <a href="https://arxiv.org/pdf/2509.23468.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23468v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23468v2', 'Multi-Modal Manipulation via Multi-Modal Policy Consensus')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haonan Chen, Jiaming Xu, Hongyu Chen, Kaiwen Hong, Binghao Huang, Chaoqi Liu, Jiayuan Mao, Yunzhu Li, Yilun Du, Katherine Driggs-Campbell

**åˆ†ç±»**: cs.RO, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27 (æ›´æ–°: 2025-10-13)

**å¤‡æ³¨**: 9 pages, 7 figures. Project website: https://policyconsensus.github.io

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¤šæ¨¡æ€ç­–ç•¥å…±è¯†çš„å¤šæ¨¡æ€æ“ä½œæ–¹æ³•ï¼Œæå‡æœºå™¨äººæ“ä½œçš„é²æ£’æ€§å’Œçµæ´»æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€èåˆ` `æœºå™¨äººæ“ä½œ` `æ‰©æ•£æ¨¡å‹` `ç­–ç•¥å­¦ä¹ ` `ä¼ æ„Ÿå™¨èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººæ“ä½œæ–¹æ³•éš¾ä»¥æœ‰æ•ˆèåˆä¸åŒæ¨¡æ€ä¿¡æ¯ï¼Œä¸»å¯¼æ¨¡æ€æ˜“æ·¹æ²¡å…³é”®ä¿¡æ¯ï¼Œä¸”ç¼ºä¹çµæ´»æ€§ã€‚
2. è¯¥æ–¹æ³•å°†ç­–ç•¥åˆ†è§£ä¸ºå¤šä¸ªæ¨¡æ€ä¸“å±çš„æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡è·¯ç”±ç½‘ç»œå­¦ä¹ å…±è¯†æƒé‡è‡ªé€‚åº”èåˆã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æ“ä½œä»»åŠ¡ä¸­å‡ä¼˜äºç‰¹å¾æ‹¼æ¥æ–¹æ³•ï¼Œå¹¶å¯¹æ‰°åŠ¨å’Œä¼ æ„Ÿå™¨æŸåå…·æœ‰é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ‰æ•ˆæ•´åˆå¤šæ ·åŒ–çš„ä¼ æ„Ÿå™¨æ¨¡æ€å¯¹äºæœºå™¨äººæ“ä½œè‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„ç‰¹å¾æ‹¼æ¥æ–¹æ³•å¾€å¾€å¹¶éæœ€ä¼˜ï¼šè§†è§‰ç­‰ä¸»å¯¼æ¨¡æ€å¯èƒ½ä¼šæ·¹æ²¡æ¥è§¦ç±»ä»»åŠ¡ä¸­ç¨€ç–ä½†å…³é”®çš„è§¦è§‰ä¿¡å·ï¼Œå¹¶ä¸”å•ä½“æ¶æ„æ— æ³•çµæ´»åœ°æ•´åˆæ–°çš„æˆ–ç¼ºå¤±çš„æ¨¡æ€è€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–¹æ³•ï¼Œå°†ç­–ç•¥åˆ†è§£ä¸ºä¸€ç»„æ‰©æ•£æ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹ä¸“é—¨é’ˆå¯¹å•ä¸ªè¡¨å¾ï¼ˆä¾‹å¦‚ï¼Œè§†è§‰æˆ–è§¦è§‰ï¼‰ï¼Œå¹¶é‡‡ç”¨ä¸€ä¸ªè·¯ç”±ç½‘ç»œï¼Œè¯¥ç½‘ç»œå­¦ä¹ å…±è¯†æƒé‡ä»¥è‡ªé€‚åº”åœ°ç»„åˆå®ƒä»¬çš„è´¡çŒ®ï¼Œä»è€Œèƒ½å¤Ÿå¢é‡åœ°æ·»åŠ æ–°çš„è¡¨å¾ã€‚æˆ‘ä»¬åœ¨{RLBench}ä¸­çš„æ¨¡æ‹Ÿæ“ä½œä»»åŠ¡ä»¥åŠçœŸå®ä¸–ç•Œçš„ä»»åŠ¡ï¼ˆå¦‚é®æŒ¡ç‰©ä½“æ‹¾å–ã€æ‰‹ä¸­å‹ºå­é‡æ–°å®šå‘å’Œæ‹¼å›¾æ’å…¥ï¼‰ä¸­è¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œåœ¨éœ€è¦å¤šæ¨¡æ€æ¨ç†çš„åœºæ™¯ä¸­ï¼Œè¯¥æ–¹æ³•æ˜æ˜¾ä¼˜äºç‰¹å¾æ‹¼æ¥åŸºçº¿ã€‚æˆ‘ä»¬çš„ç­–ç•¥è¿›ä¸€æ­¥è¯æ˜äº†å¯¹ç‰©ç†æ‰°åŠ¨å’Œä¼ æ„Ÿå™¨æŸåçš„é²æ£’æ€§ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¿›è¡Œäº†åŸºäºæ‰°åŠ¨çš„é‡è¦æ€§åˆ†æï¼Œæ­ç¤ºäº†æ¨¡æ€ä¹‹é—´çš„è‡ªé€‚åº”è½¬ç§»ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æœºå™¨äººæ“ä½œæ–¹æ³•åœ¨å¤„ç†å¤šæ¨¡æ€ä¿¡æ¯æ—¶ï¼Œé€šå¸¸é‡‡ç”¨ç‰¹å¾æ‹¼æ¥çš„æ–¹å¼ã€‚è¿™ç§æ–¹å¼çš„ç¼ºç‚¹åœ¨äºï¼Œå®¹æ˜“å—åˆ°ä¸»å¯¼æ¨¡æ€ï¼ˆå¦‚è§†è§‰ï¼‰çš„å½±å“ï¼Œè€Œå¿½ç•¥äº†å…¶ä»–æ¨¡æ€ï¼ˆå¦‚è§¦è§‰ï¼‰ä¸­ç¨€ç–ä½†å…³é”®çš„ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œä¼ ç»Ÿçš„å•ä½“æ¶æ„éš¾ä»¥çµæ´»åœ°æ·»åŠ æˆ–ç§»é™¤æ¨¡æ€ï¼Œæ¯æ¬¡æ›´æ”¹éƒ½éœ€è¦é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ã€‚å› æ­¤ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°èåˆå¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¹¶æé«˜æ¨¡å‹çš„çµæ´»æ€§å’Œé²æ£’æ€§ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ç­–ç•¥åˆ†è§£ä¸ºå¤šä¸ªæ¨¡æ€ä¸“å±çš„å­ç­–ç•¥ï¼Œæ¯ä¸ªå­ç­–ç•¥è´Ÿè´£å¤„ç†ä¸€ç§æ¨¡æ€çš„ä¿¡æ¯ã€‚ç„¶åï¼Œé€šè¿‡ä¸€ä¸ªè·¯ç”±ç½‘ç»œå­¦ä¹ ä¸åŒå­ç­–ç•¥çš„æƒé‡ï¼Œè‡ªé€‚åº”åœ°èåˆå®ƒä»¬çš„è¾“å‡ºã€‚è¿™ç§æ–¹å¼å¯ä»¥é¿å…ä¸»å¯¼æ¨¡æ€å¯¹å…¶ä»–æ¨¡æ€çš„æ·¹æ²¡ï¼Œå¹¶ä¸”å¯ä»¥çµæ´»åœ°æ·»åŠ æˆ–ç§»é™¤æ¨¡æ€ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ã€‚æ­¤å¤–ï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹ä½œä¸ºå­ç­–ç•¥ï¼Œå¯ä»¥ç”Ÿæˆæ›´åŠ å¤šæ ·åŒ–çš„åŠ¨ä½œï¼Œæé«˜æ¨¡å‹çš„æ¢ç´¢èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«å¤šä¸ªæ¨¡æ€ä¸“å±çš„æ‰©æ•£æ¨¡å‹å’Œä¸€ä¸ªè·¯ç”±ç½‘ç»œã€‚æ¯ä¸ªæ‰©æ•£æ¨¡å‹æ¥æ”¶ä¸€ç§æ¨¡æ€çš„è¾“å…¥ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªåŠ¨ä½œåˆ†å¸ƒã€‚è·¯ç”±ç½‘ç»œæ¥æ”¶æ‰€æœ‰æ‰©æ•£æ¨¡å‹çš„è¾“å‡ºï¼Œå¹¶å­¦ä¹ ä¸€ä¸ªæƒé‡å‘é‡ï¼Œç”¨äºåŠ æƒèåˆè¿™äº›è¾“å‡ºã€‚æœ€ç»ˆçš„åŠ¨ä½œåˆ†å¸ƒæ˜¯æ‰€æœ‰æ‰©æ•£æ¨¡å‹è¾“å‡ºçš„åŠ æƒå¹³å‡ã€‚è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œç‹¬ç«‹è®­ç»ƒæ¯ä¸ªæ‰©æ•£æ¨¡å‹ï¼›ç„¶åï¼Œå›ºå®šæ‰©æ•£æ¨¡å‹çš„å‚æ•°ï¼Œè®­ç»ƒè·¯ç”±ç½‘ç»œã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†ç­–ç•¥åˆ†è§£ä¸ºå¤šä¸ªæ¨¡æ€ä¸“å±çš„å­ç­–ç•¥ï¼Œå¹¶é€šè¿‡è·¯ç”±ç½‘ç»œè‡ªé€‚åº”åœ°èåˆå®ƒä»¬çš„è¾“å‡ºã€‚è¿™ç§æ–¹å¼å¯ä»¥æœ‰æ•ˆåœ°èåˆå¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¹¶æé«˜æ¨¡å‹çš„çµæ´»æ€§å’Œé²æ£’æ€§ã€‚ä¸ä¼ ç»Ÿçš„ç‰¹å¾æ‹¼æ¥æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å¯ä»¥é¿å…ä¸»å¯¼æ¨¡æ€å¯¹å…¶ä»–æ¨¡æ€çš„æ·¹æ²¡ï¼Œå¹¶ä¸”å¯ä»¥çµæ´»åœ°æ·»åŠ æˆ–ç§»é™¤æ¨¡æ€ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¯ä¸ªæ‰©æ•£æ¨¡å‹é‡‡ç”¨U-Netç»“æ„ï¼Œè¾“å…¥ä¸ºå½“å‰çŠ¶æ€å’Œç›®æ ‡çŠ¶æ€ï¼Œè¾“å‡ºä¸ºåŠ¨ä½œåˆ†å¸ƒçš„å‡å€¼å’Œæ–¹å·®ã€‚è·¯ç”±ç½‘ç»œé‡‡ç”¨å¤šå±‚æ„ŸçŸ¥æœºï¼Œè¾“å…¥ä¸ºæ‰€æœ‰æ‰©æ•£æ¨¡å‹çš„è¾“å‡ºï¼Œè¾“å‡ºä¸ºæƒé‡å‘é‡ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬ä¸¤éƒ¨åˆ†ï¼šä¸€éƒ¨åˆ†æ˜¯æ‰©æ•£æ¨¡å‹çš„é‡æ„æŸå¤±ï¼Œå¦ä¸€éƒ¨åˆ†æ˜¯è·¯ç”±ç½‘ç»œçš„ç­–ç•¥æ¢¯åº¦æŸå¤±ã€‚åœ¨è®­ç»ƒè·¯ç”±ç½‘ç»œæ—¶ï¼Œé‡‡ç”¨REINFORCEç®—æ³•è¿›è¡Œç­–ç•¥æ¢¯åº¦ä¼°è®¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨RLBenchæ¨¡æ‹Ÿç¯å¢ƒå’ŒçœŸå®ä¸–ç•Œçš„æ“ä½œä»»åŠ¡ä¸­è¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬é®æŒ¡ç‰©ä½“æ‹¾å–ã€æ‰‹ä¸­å‹ºå­é‡æ–°å®šå‘å’Œæ‹¼å›¾æ’å…¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨éœ€è¦å¤šæ¨¡æ€æ¨ç†çš„åœºæ™¯ä¸­ï¼Œæ˜¾è‘—ä¼˜äºç‰¹å¾æ‹¼æ¥åŸºçº¿ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜è¡¨ç°å‡ºå¯¹ç‰©ç†æ‰°åŠ¨å’Œä¼ æ„Ÿå™¨æŸåçš„é²æ£’æ€§ã€‚æ‰°åŠ¨åˆ†ææ­ç¤ºäº†æ¨¡æ€ä¹‹é—´çš„è‡ªé€‚åº”è½¬ç§»ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å¤šæ¨¡æ€ä¿¡æ¯èåˆçš„æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚ï¼šåœ¨é®æŒ¡ç¯å¢ƒä¸‹è¿›è¡Œç‰©ä½“æŠ“å–ï¼Œéœ€è¦ç»“åˆè§†è§‰å’Œè§¦è§‰ä¿¡æ¯ï¼›åœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œè£…é…ï¼Œéœ€è¦ç»“åˆè§†è§‰ã€åŠ›è§‰å’Œå¬è§‰ä¿¡æ¯ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æ“ä½œèƒ½åŠ›ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Effectively integrating diverse sensory modalities is crucial for robotic manipulation. However, the typical approach of feature concatenation is often suboptimal: dominant modalities such as vision can overwhelm sparse but critical signals like touch in contact-rich tasks, and monolithic architectures cannot flexibly incorporate new or missing modalities without retraining. Our method factorizes the policy into a set of diffusion models, each specialized for a single representation (e.g., vision or touch), and employs a router network that learns consensus weights to adaptively combine their contributions, enabling incremental of new representations. We evaluate our approach on simulated manipulation tasks in {RLBench}, as well as real-world tasks such as occluded object picking, in-hand spoon reorientation, and puzzle insertion, where it significantly outperforms feature-concatenation baselines on scenarios requiring multimodal reasoning. Our policy further demonstrates robustness to physical perturbations and sensor corruption. We further conduct perturbation-based importance analysis, which reveals adaptive shifts between modalities.

