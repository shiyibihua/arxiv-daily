---
layout: default
title: Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control
---

# Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control

**arXiv**: [2511.03181v1](https://arxiv.org/abs/2511.03181) | [PDF](https://arxiv.org/pdf/2511.03181.pdf)

**ä½œè€…**: Rewida Ali, Cristian C. Beltran-Hernandez, Weiwei Wan, Kensuke Harada

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-05

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå­¦ä¹ çš„åä½œæœºå™¨äººçº¸å¼ åŒ…è£…æ–¹æ³•ï¼Œç»“åˆæ®‹å·®åŠ›æŽ§åˆ¶å®žçŽ°é«˜æˆåŠŸçŽ‡ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `æœºå™¨äººåä½œ` `å˜å½¢ç‰©ä½“æ“ä½œ` `çº¸å¼ åŒ…è£…` `æ¨¡ä»¿å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `Transformer` `åŠ›æŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. äººæœºåä½œå¤„ç†çº¸å¼ ç­‰å˜å½¢ç‰©ä½“æ—¶ï¼Œç”±äºŽå…¶åŠ¨æ€ç‰¹æ€§éš¾ä»¥é¢„æµ‹ï¼Œä¸”éœ€è¦è‡ªé€‚åº”åŠ›æŽ§åˆ¶ï¼Œåè°ƒæœºå™¨äººåŠ¨ä½œé¢ä¸´æŒ‘æˆ˜ã€‚
2. æå‡ºä¸€ç§åŸºäºŽå­¦ä¹ çš„æ¡†æž¶ï¼Œåˆ©ç”¨å¤§åž‹è¯­è¨€æ¨¡åž‹è¿›è¡Œä»»åŠ¡è§„åˆ’ï¼Œå¹¶ç»“åˆæ¨¡ä»¿å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒç»Ÿä¸€ç­–ç•¥ï¼Œå®žçŽ°çº¸å¼ åŒ…è£…ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ¡†æž¶åœ¨çœŸå®žåŒ…è£…ä»»åŠ¡ä¸­è¾¾åˆ°97%çš„æˆåŠŸçŽ‡ï¼ŒéªŒè¯äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å‡å°‘äº†å¯¹ä¸“ç”¨æ¨¡åž‹çš„éœ€æ±‚ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºŽå­¦ä¹ çš„æ¡†æž¶ï¼Œç”¨äºŽè§£å†³äººæœºåä½œå®Œæˆçº¸å¼ åŒ…è£…ä»»åŠ¡çš„éš¾é¢˜ã€‚è¯¥æ¡†æž¶å°†å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰é©±åŠ¨çš„é«˜çº§ä»»åŠ¡è§„åˆ’å™¨ä¸Žæ··åˆæ¨¡ä»¿å­¦ä¹ ï¼ˆILï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„ä½Žçº§ç­–ç•¥ç›¸ç»“åˆã€‚æ ¸å¿ƒæ˜¯ä¸€ä¸ªåä¸ºSub-task Aware Robotic Transformer (START) çš„æ¨¡åž‹ï¼Œå®ƒä»Žäººç±»æ¼”ç¤ºä¸­å­¦ä¹ ç»Ÿä¸€ç­–ç•¥ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨å•ä¸ªæ¨¡åž‹ä¸­æ•èŽ·æ•´ä¸ªåŒ…è£…åºåˆ—ä¸­çš„é•¿ç¨‹æ—¶é—´ä¾èµ–æ€§æ¥å®žçŽ°åˆ›æ–°ã€‚ä¸Žé€šå¸¸åº”ç”¨äºŽçŸ­ä»»åŠ¡çš„Action Chunking with Transformer (ACT) ä¸åŒï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†å­ä»»åŠ¡IDï¼Œæä¾›äº†æ˜¾å¼çš„æ—¶é—´åŸºç¡€ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ¡†æž¶åœ¨çœŸå®žä¸–ç•Œçš„åŒ…è£…ä»»åŠ¡ä¸­å®žçŽ°äº†97%çš„æˆåŠŸçŽ‡ï¼Œå¹¶å‡å°‘äº†å¯¹ä¸“ç”¨æ¨¡åž‹çš„éœ€æ±‚ï¼Œå®žçŽ°äº†å—æŽ§çš„äººå·¥ç›‘ç£ï¼Œå¹¶æœ‰æ•ˆåœ°æ¡¥æŽ¥äº†é«˜çº§æ„å›¾ä¸Žå˜å½¢ç‰©ä½“æ“ä½œæ‰€éœ€çš„ç²¾ç»†åŠ›æŽ§åˆ¶ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³äººæœºåä½œå®Œæˆå¤æ‚å˜å½¢ç‰©ä½“ï¼ˆå¦‚çº¸å¼ ï¼‰åŒ…è£…ä»»åŠ¡çš„éš¾é¢˜ã€‚çŽ°æœ‰æ–¹æ³•éš¾ä»¥å¤„ç†çº¸å¼ çš„ä¸å¯é¢„æµ‹çš„åŠ¨æ€ç‰¹æ€§ï¼Œå¹¶ä¸”ç¼ºä¹æœ‰æ•ˆçš„åŠ›æŽ§åˆ¶ç­–ç•¥ï¼Œå¯¼è‡´åŒ…è£…è´¨é‡éš¾ä»¥ä¿è¯ã€‚æ­¤å¤–ï¼ŒçŽ°æœ‰æ–¹æ³•é€šå¸¸é’ˆå¯¹ç‰¹å®šä»»åŠ¡è®¾è®¡ï¼Œæ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†é«˜çº§ä»»åŠ¡è§„åˆ’ä¸Žä½Žçº§åŠ›æŽ§åˆ¶ç›¸ç»“åˆï¼Œåˆ©ç”¨å¤§åž‹è¯­è¨€æ¨¡åž‹è¿›è¡Œä»»åŠ¡åˆ†è§£å’Œè§„åˆ’ï¼Œç„¶åŽé€šè¿‡æ¨¡ä»¿å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸€ä¸ªç»Ÿä¸€çš„ç­–ç•¥ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ¨¡ä»¿äººç±»çš„åŒ…è£…åŠ¨ä½œï¼Œå¹¶æ ¹æ®çŽ¯å¢ƒåé¦ˆè¿›è¡Œè°ƒæ•´ã€‚é€šè¿‡å¼•å…¥å­ä»»åŠ¡IDï¼Œæ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ä»»åŠ¡çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»Žè€Œæé«˜åŒ…è£…çš„æˆåŠŸçŽ‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) åŸºäºŽå¤§åž‹è¯­è¨€æ¨¡åž‹çš„ä»»åŠ¡è§„åˆ’å™¨ï¼Œç”¨äºŽå°†åŒ…è£…ä»»åŠ¡åˆ†è§£ä¸ºä¸€ç³»åˆ—å­ä»»åŠ¡ï¼›2) Sub-task Aware Robotic Transformer (START) æ¨¡åž‹ï¼Œç”¨äºŽå­¦ä¹ ç»Ÿä¸€çš„æŽ§åˆ¶ç­–ç•¥ï¼›3) æ®‹å·®åŠ›æŽ§åˆ¶æ¨¡å—ï¼Œç”¨äºŽå®žçŽ°ç²¾ç»†çš„åŠ›æŽ§åˆ¶ã€‚é¦–å…ˆï¼Œä»»åŠ¡è§„åˆ’å™¨æ ¹æ®ç”¨æˆ·æŒ‡ä»¤ç”Ÿæˆå­ä»»åŠ¡åºåˆ—ã€‚ç„¶åŽï¼ŒSTARTæ¨¡åž‹æ ¹æ®å½“å‰çŠ¶æ€å’Œå­ä»»åŠ¡IDç”ŸæˆåŠ¨ä½œæŒ‡ä»¤ã€‚æœ€åŽï¼Œæ®‹å·®åŠ›æŽ§åˆ¶æ¨¡å—æ ¹æ®åŠ¨ä½œæŒ‡ä»¤å’ŒåŠ›ä¼ æ„Ÿå™¨åé¦ˆï¼Œè°ƒæ•´æœºå™¨äººçš„åŠ›è¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†Sub-task Aware Robotic Transformer (START) æ¨¡åž‹ï¼Œè¯¥æ¨¡åž‹èƒ½å¤Ÿæ•èŽ·æ•´ä¸ªåŒ…è£…åºåˆ—ä¸­çš„é•¿ç¨‹æ—¶é—´ä¾èµ–æ€§ï¼Œå¹¶åˆ©ç”¨å­ä»»åŠ¡IDæä¾›æ˜¾å¼çš„æ—¶é—´åŸºç¡€ã€‚ä¸Žä¼ ç»Ÿçš„Action Chunking with Transformer (ACT) æ–¹æ³•ç›¸æ¯”ï¼ŒSTARTæ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ä»»åŠ¡çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»Žè€Œæé«˜åŒ…è£…çš„æˆåŠŸçŽ‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜ç»“åˆäº†æ¨¡ä»¿å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿä»Žäººç±»æ¼”ç¤ºä¸­å­¦ä¹ ï¼Œå¹¶æ ¹æ®çŽ¯å¢ƒåé¦ˆè¿›è¡Œè°ƒæ•´ã€‚

**å…³é”®è®¾è®¡**ï¼šSTARTæ¨¡åž‹é‡‡ç”¨Transformeræž¶æž„ï¼Œè¾“å…¥åŒ…æ‹¬å½“å‰çŠ¶æ€ã€å­ä»»åŠ¡IDå’ŒåŽ†å²åŠ¨ä½œåºåˆ—ã€‚æ¨¡åž‹è¾“å‡ºä¸ºæœºå™¨äººçš„åŠ¨ä½œæŒ‡ä»¤ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬æ¨¡ä»¿å­¦ä¹ æŸå¤±å’Œå¼ºåŒ–å­¦ä¹ å¥–åŠ±ã€‚æ¨¡ä»¿å­¦ä¹ æŸå¤±ç”¨äºŽä½¿æœºå™¨äººæ¨¡ä»¿äººç±»çš„åŒ…è£…åŠ¨ä½œï¼Œå¼ºåŒ–å­¦ä¹ å¥–åŠ±ç”¨äºŽé¼“åŠ±æœºå™¨äººå®ŒæˆåŒ…è£…ä»»åŠ¡ã€‚æ®‹å·®åŠ›æŽ§åˆ¶æ¨¡å—é‡‡ç”¨PIDæŽ§åˆ¶å™¨ï¼Œæ ¹æ®åŠ¨ä½œæŒ‡ä»¤å’ŒåŠ›ä¼ æ„Ÿå™¨åé¦ˆï¼Œè°ƒæ•´æœºå™¨äººçš„åŠ›è¾“å‡ºã€‚å­ä»»åŠ¡IDé‡‡ç”¨one-hotç¼–ç ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œæ‰€æå‡ºçš„æ¡†æž¶åœ¨çœŸå®žä¸–ç•Œçš„åŒ…è£…ä»»åŠ¡ä¸­å®žçŽ°äº†97%çš„æˆåŠŸçŽ‡ã€‚ä¸Žä¼ ç»Ÿçš„Action Chunking with Transformer (ACT) æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ä»»åŠ¡çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»Žè€Œæé«˜åŒ…è£…çš„æˆåŠŸçŽ‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜èƒ½å¤Ÿå®žçŽ°å—æŽ§çš„äººå·¥ç›‘ç£ï¼Œå¹¶æœ‰æ•ˆåœ°æ¡¥æŽ¥äº†é«˜çº§æ„å›¾ä¸Žå˜å½¢ç‰©ä½“æ“ä½œæ‰€éœ€çš„ç²¾ç»†åŠ›æŽ§åˆ¶ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽä»“å‚¨ã€é›¶å”®ç­‰é¢†åŸŸï¼Œå®žçŽ°è‡ªåŠ¨åŒ–åŒ…è£…ï¼Œæé«˜æ•ˆçŽ‡å¹¶é™ä½Žäººå·¥æˆæœ¬ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯æ‰©å±•åˆ°å…¶ä»–å˜å½¢ç‰©ä½“çš„æ“ä½œä»»åŠ¡ï¼Œå¦‚æœè£…æŠ˜å ã€é£Ÿå“åŒ…è£…ç­‰ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºŽæ›´å¤æ‚çš„æœºå™¨äººåä½œä»»åŠ¡ï¼Œä¾‹å¦‚åŒ»ç–—æ‰‹æœ¯ã€ç¾éš¾æ•‘æ´ç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Human-robot cooperation is essential in environments such as warehouses and retail stores, where workers frequently handle deformable objects like paper, bags, and fabrics. Coordinating robotic actions with human assistance remains difficult due to the unpredictable dynamics of deformable materials and the need for adaptive force control. To explore this challenge, we focus on the task of gift wrapping, which exemplifies a long-horizon manipulation problem involving precise folding, controlled creasing, and secure fixation of paper. Success is achieved when the robot completes the sequence to produce a neatly wrapped package with clean folds and no tears.
>   We propose a learning-based framework that integrates a high-level task planner powered by a large language model (LLM) with a low-level hybrid imitation learning (IL) and reinforcement learning (RL) policy. At its core is a Sub-task Aware Robotic Transformer (START) that learns a unified policy from human demonstrations. The key novelty lies in capturing long-range temporal dependencies across the full wrapping sequence within a single model. Unlike vanilla Action Chunking with Transformer (ACT), typically applied to short tasks, our method introduces sub-task IDs that provide explicit temporal grounding. This enables robust performance across the entire wrapping process and supports flexible execution, as the policy learns sub-goals rather than merely replicating motion sequences.
>   Our framework achieves a 97% success rate on real-world wrapping tasks. We show that the unified transformer-based policy reduces the need for specialized models, allows controlled human supervision, and effectively bridges high-level intent with the fine-grained force control required for deformable object manipulation.

