---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-09-03
---

# cs.ROï¼ˆ2025-09-03ï¼‰

ğŸ“Š å…± **6** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (4 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250903222v1-the-role-of-embodiment-in-intuitive-whole-body-teleoperation-for-mob.html">The Role of Embodiment in Intuitive Whole-Body Teleoperation for Mobile Manipulation</a></td>
  <td>ç ”ç©¶å…·èº«æ€§åœ¨ç§»åŠ¨æ“ä½œæœºå™¨äººç›´è§‰å¼å…¨èº«é¥æ“ä½œä¸­çš„ä½œç”¨ï¼Œæå‡æ•°æ®è´¨é‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">WBC</span> <span class="paper-tag">manipulation</span> <span class="paper-tag">mobile manipulation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03222v1" data-paper-url="./papers/250903222v1-the-role-of-embodiment-in-intuitive-whole-body-teleoperation-for-mob.html" onclick="toggleFavorite(this, '2509.03222v1', 'The Role of Embodiment in Intuitive Whole-Body Teleoperation for Mobile Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250902986v2-ctbc-contact-triggered-blind-climbing-for-wheeled-bipedal-robots-wit.html">CTBC: Contact-Triggered Blind Climbing for Wheeled Bipedal Robots with Instruction Learning and Reinforcement Learning</a></td>
  <td>æå‡ºåŸºäºæ¥è§¦è§¦å‘çš„ç›²çˆ¬è¡Œæ¡†æ¶ï¼Œæå‡è½®å¼åŒè¶³æœºå™¨äººå¤æ‚åœ°å½¢é€‚åº”æ€§</td>
  <td class="tags-cell"><span class="paper-tag">legged robot</span> <span class="paper-tag">bipedal</span> <span class="paper-tag">biped</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02986v2" data-paper-url="./papers/250902986v2-ctbc-contact-triggered-blind-climbing-for-wheeled-bipedal-robots-wit.html" onclick="toggleFavorite(this, '2509.02986v2', 'CTBC: Contact-Triggered Blind Climbing for Wheeled Bipedal Robots with Instruction Learning and Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250903261v1-parallel-constraint-model-predictive-control-exploiting-parallel-com.html">Parallel-Constraint Model Predictive Control: Exploiting Parallel Computation for Improving Safety</a></td>
  <td>æå‡ºå¹¶è¡Œçº¦æŸæ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼Œåˆ©ç”¨å¹¶è¡Œè®¡ç®—æå‡æœºå™¨äººå®‰å…¨æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">MPC</span> <span class="paper-tag">model predictive control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03261v1" data-paper-url="./papers/250903261v1-parallel-constraint-model-predictive-control-exploiting-parallel-com.html" onclick="toggleFavorite(this, '2509.03261v1', 'Parallel-Constraint Model Predictive Control: Exploiting Parallel Computation for Improving Safety')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250903690v1-low-cost-open-source-ambidextrous-robotic-hand-with-23-direct-drive-.html">Low-Cost Open-Source Ambidextrous Robotic Hand with 23 Direct-Drive servos for American Sign Language Alphabet</a></td>
  <td>VulcanV3ï¼šä½æˆæœ¬å¼€æºçµå·§æ‰‹ï¼Œé€šè¿‡23ä¸ªç›´é©±èˆµæœºå®ç°ç¾å›½æ‰‹è¯­å­—æ¯</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03690v1" data-paper-url="./papers/250903690v1-low-cost-open-source-ambidextrous-robotic-hand-with-23-direct-drive-.html" onclick="toggleFavorite(this, '2509.03690v1', 'Low-Cost Open-Source Ambidextrous Robotic Hand with 23 Direct-Drive servos for American Sign Language Alphabet')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>5</td>
  <td><a href="./papers/250903012v1-uncertainty-aware-test-time-training-ut3-for-efficient-on-the-fly-do.html">Uncertainty-aware Test-Time Training (UT$^3$) for Efficient On-the-fly Domain Adaptive Dense Regression</a></td>
  <td>æå‡ºä¸ç¡®å®šæ€§æ„ŸçŸ¥æµ‹è¯•æ—¶è®­ç»ƒ(UTÂ³)ï¼ŒåŠ é€Ÿé¢†åŸŸè‡ªé€‚åº”ç¨ å¯†å›å½’ï¼Œé€‚ç”¨äºèµ„æºå—é™çš„æœºå™¨äººåº”ç”¨ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">depth estimation</span> <span class="paper-tag">monocular depth</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03012v1" data-paper-url="./papers/250903012v1-uncertainty-aware-test-time-training-ut3-for-efficient-on-the-fly-do.html" onclick="toggleFavorite(this, '2509.03012v1', 'Uncertainty-aware Test-Time Training (UT$^3$) for Efficient On-the-fly Domain Adaptive Dense Regression')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250903211v1-efficient-active-training-for-deep-lidar-odometry.html">Efficient Active Training for Deep LiDAR Odometry</a></td>
  <td>æå‡ºä¸»åŠ¨å­¦ä¹ æ¡†æ¶ï¼Œé«˜æ•ˆè®­ç»ƒæ·±åº¦LiDARé‡Œç¨‹è®¡ï¼Œæå‡æ³›åŒ–æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">scene reconstruction</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03211v1" data-paper-url="./papers/250903211v1-efficient-active-training-for-deep-lidar-odometry.html" onclick="toggleFavorite(this, '2509.03211v1', 'Efficient Active Training for Deep LiDAR Odometry')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)