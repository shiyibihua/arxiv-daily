---
layout: default
title: Uncertainty-aware Test-Time Training (UT$^3$) for Efficient On-the-fly Domain Adaptive Dense Regression
---

# Uncertainty-aware Test-Time Training (UT$^3$) for Efficient On-the-fly Domain Adaptive Dense Regression

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.03012" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.03012v1</a>
  <a href="https://arxiv.org/pdf/2509.03012.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.03012v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.03012v1', 'Uncertainty-aware Test-Time Training (UT$^3$) for Efficient On-the-fly Domain Adaptive Dense Regression')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Uddeshya Upadhyay

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-03

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸ç¡®å®šæ€§æ„ŸçŸ¥æµ‹è¯•æ—¶è®­ç»ƒ(UTÂ³)ï¼ŒåŠ é€Ÿé¢†åŸŸè‡ªé€‚åº”ç¨ å¯†å›å½’ï¼Œé€‚ç”¨äºèµ„æºå—é™çš„æœºå™¨äººåº”ç”¨ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `æµ‹è¯•æ—¶è®­ç»ƒ` `é¢†åŸŸè‡ªé€‚åº”` `ä¸ç¡®å®šæ€§ä¼°è®¡` `è‡ªç›‘ç£å­¦ä¹ ` `ç¨ å¯†å›å½’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æµ‹è¯•æ—¶è®­ç»ƒæ–¹æ³•åœ¨é¢†åŸŸåç§»ä¸‹è™½èƒ½æå‡æ€§èƒ½ï¼Œä½†æ¨ç†æ—¶é—´æ˜¾è‘—å¢åŠ ï¼Œä¸é€‚ç”¨äºèµ„æºå—é™çš„æœºå™¨äººåº”ç”¨ã€‚
2. UTÂ³æ¡†æ¶åˆ©ç”¨ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„è‡ªç›‘ç£å­¦ä¹ ï¼Œé€‰æ‹©æ€§åœ°è¿›è¡Œæµ‹è¯•æ—¶è®­ç»ƒï¼Œåœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶é™ä½æ¨ç†æ—¶é—´ã€‚
3. è¯¥æ–¹æ³•åœ¨å•ç›®æ·±åº¦ä¼°è®¡ä»»åŠ¡ä¸ŠéªŒè¯äº†æœ‰æ•ˆæ€§ï¼Œå¹¶å…è®¸ç”¨æˆ·æ§åˆ¶æµ‹è¯•æ—¶è®­ç»ƒçš„åº”ç”¨é¢‘ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ·±åº¦ç¥ç»ç½‘ç»œ(DNNs)åœ¨è‡ªä¸»ç³»ç»Ÿä¸­åº”ç”¨æ—¥ç›Šå¹¿æ³›ï¼Œä½†å…¶æ³›åŒ–èƒ½åŠ›åœ¨é¢†åŸŸåç§»ä¸‹è¡¨ç°ä¸ä½³ã€‚é€‚åº”ä¸æ–­å˜åŒ–çš„ç¯å¢ƒæ˜¯éƒ¨ç½²åœ¨ç°å®ä¸–ç•Œä¸­çš„æ‰€æœ‰è‡ªä¸»ç³»ç»Ÿéƒ½ä¸å¯é¿å…åœ°é¢ä¸´çš„å…³é”®å®‰å…¨æŒ‘æˆ˜ã€‚æœ€è¿‘çš„æµ‹è¯•æ—¶è®­ç»ƒå·¥ä½œæå‡ºäº†é€šè¿‡ä½¿ç”¨è‡ªç›‘ç£ä¸ºæ¯ä¸ªæµ‹è¯•è¾“å…¥ä¼˜åŒ–DNNæ¨¡å‹æ¥é€‚åº”æ–°çš„æµ‹è¯•åˆ†å¸ƒçš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œè¿™äº›æŠ€æœ¯å¯¼è‡´æ¨ç†æ—¶é—´æ€¥å‰§å¢åŠ ï¼Œå› ä¸ºåœ¨åŸºäºå¾®è°ƒçš„ç‰¹å¾è¿›è¡Œæœ€ç»ˆé¢„æµ‹ä¹‹å‰ï¼Œå•ä¸ªæµ‹è¯•æ ·æœ¬éœ€è¦å¤šæ¬¡å‰å‘å’Œåå‘ä¼ é€’ï¼ˆç”¨äºæµ‹è¯•æ—¶è®­ç»ƒï¼‰ã€‚è¿™å¯¹äºå®é™…æœºå™¨äººåº”ç”¨æ¥è¯´æ˜¯ä¸å¯å–çš„ï¼Œå› ä¸ºè¿™äº›æ¨¡å‹å¯èƒ½éƒ¨ç½²åœ¨å…·æœ‰ä¸¥æ ¼å»¶è¿Ÿè¦æ±‚çš„èµ„æºå—é™ç¡¬ä»¶ä¸Šã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼ˆç§°ä¸ºUTÂ³ï¼‰ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨æµ‹è¯•æ—¶è®­ç»ƒæ¥æé«˜åœ¨å­˜åœ¨è¿ç»­é¢†åŸŸåç§»æ—¶çš„æ€§èƒ½ï¼ŒåŒæ—¶å‡å°‘æ¨ç†æ—¶é—´ï¼Œä½¿å…¶é€‚ç”¨äºå®é™…åº”ç”¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•æå‡ºäº†ä¸€ç§ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„è‡ªç›‘ç£ä»»åŠ¡ï¼Œç”¨äºé«˜æ•ˆçš„æµ‹è¯•æ—¶è®­ç»ƒï¼Œè¯¥ä»»åŠ¡åˆ©ç”¨é‡åŒ–çš„ä¸ç¡®å®šæ€§æ¥é€‰æ‹©æ€§åœ°åº”ç”¨è®­ç»ƒï¼Œä»è€Œæ˜¾ç€æé«˜æ¨ç†æ—¶é—´ï¼ŒåŒæ—¶è¡¨ç°ä¸æ ‡å‡†æµ‹è¯•æ—¶è®­ç»ƒåè®®ç›¸å½“ã€‚æˆ‘ä»¬æå‡ºçš„åè®®æä¾›äº†ä¸€ä¸ªè¿ç»­è®¾ç½®æ¥è¯†åˆ«é€‰å®šçš„å…³é”®å¸§ï¼Œå…è®¸æœ€ç»ˆç”¨æˆ·æ§åˆ¶åº”ç”¨æµ‹è¯•æ—¶è®­ç»ƒçš„é¢‘ç‡ã€‚æˆ‘ä»¬é€šè¿‡å•ç›®æ·±åº¦ä¼°è®¡è¿™ä¸€ç¨ å¯†å›å½’ä»»åŠ¡è¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ·±åº¦ç¥ç»ç½‘ç»œåœ¨é¢å¯¹æŒç»­é¢†åŸŸåç§»æ—¶ï¼Œæµ‹è¯•æ—¶è®­ç»ƒæ–¹æ³•æ¨ç†æ—¶é—´è¿‡é•¿çš„é—®é¢˜ã€‚ç°æœ‰çš„æµ‹è¯•æ—¶è®­ç»ƒæ–¹æ³•è™½ç„¶èƒ½æå‡æ¨¡å‹åœ¨ç›®æ ‡é¢†åŸŸçš„æ€§èƒ½ï¼Œä½†éœ€è¦å¯¹æ¯ä¸ªè¾“å…¥æ ·æœ¬è¿›è¡Œå¤šæ¬¡å‰å‘å’Œåå‘ä¼ æ’­ï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬æ˜¾è‘—å¢åŠ ï¼Œæ— æ³•æ»¡è¶³å®æ—¶æ€§è¦æ±‚é«˜çš„æœºå™¨äººåº”ç”¨åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ¨¡å‹é¢„æµ‹çš„ä¸ç¡®å®šæ€§æ¥æŒ‡å¯¼æµ‹è¯•æ—¶è®­ç»ƒè¿‡ç¨‹ã€‚é€šè¿‡é‡åŒ–æ¨¡å‹å¯¹å½“å‰è¾“å…¥çš„ä¸ç¡®å®šç¨‹åº¦ï¼Œé€‰æ‹©æ€§åœ°å¯¹ä¸ç¡®å®šæ€§é«˜çš„æ ·æœ¬è¿›è¡Œæµ‹è¯•æ—¶è®­ç»ƒï¼Œè€Œå¯¹ç¡®å®šæ€§é«˜çš„æ ·æœ¬åˆ™ç›´æ¥è¿›è¡Œé¢„æµ‹ã€‚è¿™æ ·å¯ä»¥åœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘æµ‹è¯•æ—¶è®­ç»ƒçš„è®¡ç®—é‡ï¼Œä»è€Œé™ä½æ¨ç†æ—¶é—´ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šUTÂ³æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) åŸå§‹DNNæ¨¡å‹ï¼›2) ä¸ç¡®å®šæ€§ä¼°è®¡æ¨¡å—ï¼Œç”¨äºé‡åŒ–æ¨¡å‹é¢„æµ‹çš„ä¸ç¡®å®šæ€§ï¼›3) è‡ªç›‘ç£è®­ç»ƒæ¨¡å—ï¼Œç”¨äºå¯¹é€‰å®šçš„æ ·æœ¬è¿›è¡Œæµ‹è¯•æ—¶è®­ç»ƒã€‚æ•´ä½“æµç¨‹æ˜¯ï¼šé¦–å…ˆï¼ŒDNNæ¨¡å‹å¯¹è¾“å…¥æ ·æœ¬è¿›è¡Œé¢„æµ‹ï¼›ç„¶åï¼Œä¸ç¡®å®šæ€§ä¼°è®¡æ¨¡å—è¯„ä¼°é¢„æµ‹ç»“æœçš„ä¸ç¡®å®šæ€§ï¼›æœ€åï¼Œæ ¹æ®ä¸ç¡®å®šæ€§é˜ˆå€¼ï¼Œé€‰æ‹©æ€§åœ°å¯¹æ ·æœ¬è¿›è¡Œè‡ªç›‘ç£è®­ç»ƒï¼Œå¹¶æ›´æ–°DNNæ¨¡å‹å‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šUTÂ³çš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„è‡ªç›‘ç£å­¦ä¹ æœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„æµ‹è¯•æ—¶è®­ç»ƒæ–¹æ³•ä¸åŒï¼ŒUTÂ³ä¸æ˜¯å¯¹æ‰€æœ‰æ ·æœ¬éƒ½è¿›è¡Œè®­ç»ƒï¼Œè€Œæ˜¯æ ¹æ®æ¨¡å‹è‡ªèº«çš„ä¸ç¡®å®šæ€§è¿›è¡Œé€‰æ‹©æ€§è®­ç»ƒã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨è®¡ç®—èµ„æºï¼Œåœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½æ¨ç†æ—¶é—´ã€‚

**å…³é”®è®¾è®¡**ï¼šUTÂ³çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä¸ç¡®å®šæ€§åº¦é‡æ–¹å¼çš„é€‰æ‹©ï¼Œä¾‹å¦‚å¯ä»¥ä½¿ç”¨æ¨¡å‹è¾“å‡ºçš„æ–¹å·®æˆ–ç†µæ¥è¡¡é‡ä¸ç¡®å®šæ€§ï¼›2) ä¸ç¡®å®šæ€§é˜ˆå€¼çš„è®¾å®šï¼Œç”¨äºæ§åˆ¶æµ‹è¯•æ—¶è®­ç»ƒçš„åº”ç”¨é¢‘ç‡ï¼›3) è‡ªç›‘ç£ä»»åŠ¡çš„è®¾è®¡ï¼Œä¾‹å¦‚å¯ä»¥ä½¿ç”¨å›¾åƒé‡å»ºã€æ·±åº¦ä¸€è‡´æ€§ç­‰ä»»åŠ¡æ¥è®­ç»ƒæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ä¸ªè¿ç»­è®¾ç½®ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´æµ‹è¯•æ—¶è®­ç»ƒçš„é¢‘ç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æå‡ºçš„UTÂ³æ¡†æ¶åœ¨å•ç›®æ·±åº¦ä¼°è®¡ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒUTÂ³åœ¨ä¿è¯ä¸æ ‡å‡†æµ‹è¯•æ—¶è®­ç»ƒåè®®ç›¸å½“çš„æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†æ¨ç†æ—¶é—´ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å…è®¸ç”¨æˆ·çµæ´»æ§åˆ¶æµ‹è¯•æ—¶è®­ç»ƒçš„åº”ç”¨é¢‘ç‡ï¼Œä»è€Œæ›´å¥½åœ°é€‚åº”ä¸åŒçš„åº”ç”¨åœºæ™¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å®æ—¶é¢†åŸŸè‡ªé€‚åº”çš„æœºå™¨äººåº”ç”¨ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€æ— äººæœºå¯¼èˆªã€æœºå™¨äººæŠ“å–ç­‰ã€‚é€šè¿‡é™ä½æ¨ç†æ—¶é—´ï¼ŒUTÂ³æ¡†æ¶ä½¿å¾—æ·±åº¦ç¥ç»ç½‘ç»œèƒ½å¤Ÿéƒ¨ç½²åœ¨èµ„æºå—é™çš„åµŒå…¥å¼å¹³å°ä¸Šï¼Œä»è€Œæ‰©å±•äº†å…¶åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨èŒƒå›´ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºå…¶ä»–é¢†åŸŸçš„ç¨ å¯†å›å½’ä»»åŠ¡ï¼Œä¾‹å¦‚åŒ»å­¦å›¾åƒåˆ†æã€é¥æ„Ÿå›¾åƒå¤„ç†ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deep neural networks (DNNs) are increasingly being used in autonomous systems. However, DNNs do not generalize well to domain shift. Adapting to a continuously evolving environment is a safety-critical challenge inevitably faced by all autonomous systems deployed to the real world. Recent work on test-time training proposes methods that adapt to a new test distribution on the fly by optimizing the DNN model for each test input using self-supervision. However, these techniques result in a sharp increase in inference time as multiple forward and backward passes are required for a single test sample (for test-time training) before finally making the prediction based on the fine-tuned features. This is undesirable for real-world robotics applications where these models may be deployed to resource constraint hardware with strong latency requirements. In this work, we propose a new framework (called UT$^3$) that leverages test-time training for improved performance in the presence of continuous domain shift while also decreasing the inference time, making it suitable for real-world applications. Our method proposes an uncertainty-aware self-supervision task for efficient test-time training that leverages the quantified uncertainty to selectively apply the training leading to sharp improvements in the inference time while performing comparably to standard test-time training protocol. Our proposed protocol offers a continuous setting to identify the selected keyframes, allowing the end-user to control how often to apply test-time training. We demonstrate the efficacy of our method on a dense regression task - monocular depth estimation.

