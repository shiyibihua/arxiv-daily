---
layout: default
title: Data Retrieval with Importance Weights for Few-Shot Imitation Learning
---

# Data Retrieval with Importance Weights for Few-Shot Imitation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01657" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01657v1</a>
  <a href="https://arxiv.org/pdf/2509.01657.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01657v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01657v1', 'Data Retrieval with Importance Weights for Few-Shot Imitation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Amber Xie, Rahul Chand, Dorsa Sadigh, Joey Hejna

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01

**å¤‡æ³¨**: Conference on Robot Learning 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé‡è¦æ€§åŠ æƒæ£€ç´¢(IWR)æ–¹æ³•ï¼Œæå‡å°‘æ ·æœ¬æ¨¡ä»¿å­¦ä¹ ä¸­æ•°æ®æ£€ç´¢çš„æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å°‘æ ·æœ¬å­¦ä¹ ` `æ¨¡ä»¿å­¦ä¹ ` `æ•°æ®æ£€ç´¢` `é‡è¦æ€§åŠ æƒ` `é«˜æ–¯æ ¸å¯†åº¦ä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºæ£€ç´¢çš„æ¨¡ä»¿å­¦ä¹ æ–¹æ³•ä¾èµ–äºæœ€è¿‘é‚»ä¼°è®¡ï¼Œæ˜“å—å™ªå£°å½±å“ï¼Œä¸”å¿½ç•¥äº†å…ˆéªŒæ•°æ®åˆ†å¸ƒã€‚
2. è®ºæ–‡æå‡ºé‡è¦æ€§åŠ æƒæ£€ç´¢(IWR)æ–¹æ³•ï¼Œé€šè¿‡é«˜æ–¯æ ¸å¯†åº¦ä¼°è®¡ç›®æ ‡æ•°æ®å’Œå…ˆéªŒæ•°æ®åˆ†å¸ƒçš„æ¯”ç‡ï¼Œä½œä¸ºé‡è¦æ€§æƒé‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒIWRåœ¨æ¨¡æ‹Ÿç¯å¢ƒå’ŒçœŸå®æœºå™¨äººæ•°æ®é›†ä¸Šï¼Œå‡èƒ½æœ‰æ•ˆæå‡ç°æœ‰æ£€ç´¢æ–¹æ³•çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è§„æ¨¡æœºå™¨äººæ•°æ®é›†æ¨åŠ¨äº†æ¨¡ä»¿å­¦ä¹ çš„æœ€æ–°è¿›å±•ï¼Œä½†ä»è¾ƒå°çš„ç‰¹å®šä»»åŠ¡æ•°æ®é›†å­¦ä¹ å¯¹äºåœ¨æ–°ç¯å¢ƒå’Œæœªè§ä»»åŠ¡ä¸­çš„éƒ¨ç½²ä»ç„¶è‡³å…³é‡è¦ã€‚ä¸€ç§å°‘æ ·æœ¬æ¨¡ä»¿å­¦ä¹ æ–¹æ³•æ˜¯åŸºäºæ£€ç´¢çš„æ¨¡ä»¿å­¦ä¹ ï¼Œå®ƒä»å¤§å‹ã€å¹¿æ³›å¯ç”¨çš„å…ˆéªŒæ•°æ®é›†ä¸­æå–ç›¸å…³æ ·æœ¬ï¼Œä»¥æ‰©å……æœ‰é™çš„æ¼”ç¤ºæ•°æ®é›†ã€‚ä¸ºäº†ç¡®å®šæ¥è‡ªå…ˆéªŒæ•°æ®é›†çš„ç›¸å…³æ•°æ®ï¼ŒåŸºäºæ£€ç´¢çš„æ–¹æ³•æœ€å¸¸è®¡ç®—å…ˆéªŒæ•°æ®ç‚¹åˆ°ç›®æ ‡æ•°æ®é›†ä¸­ç‚¹çš„æ½œåœ¨ç©ºé—´ä¸­çš„æœ€å°è·ç¦»ã€‚è™½ç„¶åŸºäºæ£€ç´¢çš„æ–¹æ³•å·²ç»è¯æ˜äº†ä½¿ç”¨è¿™ç§åº¦é‡è¿›è¡Œæ•°æ®é€‰æ‹©çš„æˆåŠŸï¼Œä½†æˆ‘ä»¬è¯æ˜äº†å®ƒç­‰ä»·äºç›®æ ‡æ•°æ®åˆ†å¸ƒçš„é«˜æ–¯æ ¸å¯†åº¦ä¼°è®¡(KDE)çš„æé™ã€‚è¿™æ­ç¤ºäº†å…ˆå‰å·¥ä½œä¸­ä½¿ç”¨çš„æ£€ç´¢è§„åˆ™çš„ä¸¤ä¸ªç¼ºç‚¹ã€‚é¦–å…ˆï¼Œå®ƒä¾èµ–äºæ˜“å—å™ªå£°å½±å“çš„é«˜æ–¹å·®æœ€è¿‘é‚»ä¼°è®¡ã€‚å…¶æ¬¡ï¼Œå®ƒåœ¨æ£€ç´¢æ•°æ®æ—¶æ²¡æœ‰è€ƒè™‘å…ˆéªŒæ•°æ®çš„åˆ†å¸ƒã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†é‡è¦æ€§åŠ æƒæ£€ç´¢(IWR)ï¼Œå®ƒä½¿ç”¨é«˜æ–¯KDEä¼°è®¡é‡è¦æ€§æƒé‡ï¼Œå³ç›®æ ‡æ•°æ®å’Œå…ˆéªŒæ•°æ®åˆ†å¸ƒä¹‹é—´çš„æ¯”ç‡ï¼Œç”¨äºæ£€ç´¢ã€‚é€šè¿‡è€ƒè™‘æ¦‚ç‡æ¯”ç‡ï¼ŒIWRè¯•å›¾å‡è½»å…ˆå‰é€‰æ‹©è§„åˆ™çš„åå·®ï¼Œå¹¶ä¸”é€šè¿‡ä½¿ç”¨åˆç†çš„å»ºæ¨¡å‚æ•°ï¼ŒIWRæœ‰æ•ˆåœ°ä½¿ç”¨æ‰€æœ‰æ•°æ®ç‚¹æ¥å¹³æ»‘ä¼°è®¡ã€‚åœ¨æ¨¡æ‹Ÿç¯å¢ƒå’ŒBridgeæ•°æ®é›†çš„çœŸå®è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬å‘ç°æˆ‘ä»¬çš„æ–¹æ³•IWRå§‹ç»ˆæé«˜ç°æœ‰åŸºäºæ£€ç´¢çš„æ–¹æ³•çš„æ€§èƒ½ï¼Œå°½ç®¡åªéœ€è¦è¿›è¡Œå°‘é‡ä¿®æ”¹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å°‘æ ·æœ¬æ¨¡ä»¿å­¦ä¹ ä¸­ï¼Œå¦‚ä½•ä»å¤§é‡å…ˆéªŒæ•°æ®é›†ä¸­æ£€ç´¢åˆ°ä¸ç›®æ ‡ä»»åŠ¡æœ€ç›¸å…³çš„æ•°æ®ï¼Œä»¥æå‡æ¨¡ä»¿å­¦ä¹ çš„æ€§èƒ½ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦åŸºäºæœ€è¿‘é‚»æœç´¢ï¼Œå®¹æ˜“å—åˆ°å™ªå£°æ•°æ®çš„å½±å“ï¼Œå¹¶ä¸”æ²¡æœ‰å……åˆ†åˆ©ç”¨å…ˆéªŒæ•°æ®çš„åˆ†å¸ƒä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é‡è¦æ€§åŠ æƒçš„æ€æƒ³ï¼Œé€šè¿‡ä¼°è®¡ç›®æ ‡æ•°æ®åˆ†å¸ƒå’Œå…ˆéªŒæ•°æ®åˆ†å¸ƒçš„æ¯”å€¼ï¼Œä½œä¸ºæ£€ç´¢æ•°æ®æ—¶çš„æƒé‡ã€‚è¿™æ ·å¯ä»¥å‡è½»ç”±äºå…ˆéªŒæ•°æ®åˆ†å¸ƒä¸å‡åŒ€å¸¦æ¥çš„åå·®ï¼Œå¹¶åˆ©ç”¨æ‰€æœ‰æ•°æ®ç‚¹è¿›è¡Œå¹³æ»‘ä¼°è®¡ï¼Œé™ä½å™ªå£°çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šIWRæ–¹æ³•çš„æ•´ä½“æ¡†æ¶å¦‚ä¸‹ï¼š1) ä½¿ç”¨é«˜æ–¯æ ¸å¯†åº¦ä¼°è®¡(KDE)åˆ†åˆ«ä¼°è®¡ç›®æ ‡æ•°æ®é›†å’Œå…ˆéªŒæ•°æ®é›†çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ã€‚2) è®¡ç®—æ¯ä¸ªå…ˆéªŒæ•°æ®ç‚¹çš„é‡è¦æ€§æƒé‡ï¼Œå³ç›®æ ‡æ•°æ®æ¦‚ç‡å¯†åº¦ä¸å…ˆéªŒæ•°æ®æ¦‚ç‡å¯†åº¦çš„æ¯”å€¼ã€‚3) åœ¨æ£€ç´¢æ•°æ®æ—¶ï¼Œä½¿ç”¨è®¡ç®—å¾—åˆ°çš„é‡è¦æ€§æƒé‡å¯¹å…ˆéªŒæ•°æ®è¿›è¡ŒåŠ æƒï¼Œé€‰æ‹©æƒé‡è¾ƒé«˜çš„æ ·æœ¬ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†é‡è¦æ€§åŠ æƒæœºåˆ¶ï¼Œå°†æ•°æ®æ£€ç´¢é—®é¢˜è½¬åŒ–ä¸ºæ¦‚ç‡å¯†åº¦æ¯”å€¼ä¼°è®¡é—®é¢˜ã€‚é€šè¿‡è€ƒè™‘ç›®æ ‡æ•°æ®å’Œå…ˆéªŒæ•°æ®çš„åˆ†å¸ƒå·®å¼‚ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°é€‰æ‹©ä¸ç›®æ ‡ä»»åŠ¡ç›¸å…³çš„æ•°æ®ï¼Œä»è€Œæå‡æ¨¡ä»¿å­¦ä¹ çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šIWRæ–¹æ³•ä¸­ï¼Œé«˜æ–¯æ ¸å¯†åº¦ä¼°è®¡çš„å¸¦å®½å‚æ•°æ˜¯å…³é”®çš„è®¾è®¡ã€‚è®ºæ–‡ä¸­æåˆ°ä½¿ç”¨åˆç†çš„å»ºæ¨¡å‚æ•°ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å¹³æ»‘ä¼°è®¡ï¼Œé™ä½å™ªå£°çš„å½±å“ã€‚æ­¤å¤–ï¼Œé‡è¦æ€§æƒé‡çš„è®¡ç®—æ–¹å¼ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦ä¿è¯æ•°å€¼ç¨³å®šæ€§ï¼Œé¿å…å‡ºç°é™¤é›¶é”™è¯¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒIWRæ–¹æ³•åœ¨æ¨¡æ‹Ÿç¯å¢ƒå’ŒçœŸå®æœºå™¨äººæ•°æ®é›†ï¼ˆBridge datasetï¼‰ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸ç°æœ‰çš„åŸºäºæ£€ç´¢çš„æ–¹æ³•ç›¸æ¯”ï¼ŒIWRèƒ½å¤Ÿæ›´å‡†ç¡®åœ°é€‰æ‹©ä¸ç›®æ ‡ä»»åŠ¡ç›¸å…³çš„æ•°æ®ï¼Œä»è€Œæå‡æ¨¡ä»¿å­¦ä¹ çš„æ€§èƒ½ã€‚å…·ä½“æå‡å¹…åº¦åœ¨ä¸åŒä»»åŠ¡å’Œæ•°æ®é›†ä¸Šæœ‰æ‰€ä¸åŒï¼Œä½†æ€»ä½“ä¸Šå‡ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººæ¨¡ä»¿å­¦ä¹ ã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰é¢†åŸŸã€‚åœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œå¾€å¾€éš¾ä»¥è·å–å¤§é‡çš„ç›®æ ‡ä»»åŠ¡æ•°æ®ï¼Œè€Œå­˜åœ¨å¤§é‡çš„å…ˆéªŒæ•°æ®ã€‚é€šè¿‡IWRæ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨è¿™äº›å…ˆéªŒæ•°æ®ï¼Œæå‡æ¨¡å‹åœ¨ç›®æ ‡ä»»åŠ¡ä¸Šçš„æ³›åŒ–èƒ½åŠ›å’Œå­¦ä¹ æ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚è¿ç§»å­¦ä¹ ã€é¢†åŸŸè‡ªé€‚åº”ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While large-scale robot datasets have propelled recent progress in imitation learning, learning from smaller task specific datasets remains critical for deployment in new environments and unseen tasks. One such approach to few-shot imitation learning is retrieval-based imitation learning, which extracts relevant samples from large, widely available prior datasets to augment a limited demonstration dataset. To determine the relevant data from prior datasets, retrieval-based approaches most commonly calculate a prior data point's minimum distance to a point in the target dataset in latent space. While retrieval-based methods have shown success using this metric for data selection, we demonstrate its equivalence to the limit of a Gaussian kernel density (KDE) estimate of the target data distribution. This reveals two shortcomings of the retrieval rule used in prior work. First, it relies on high-variance nearest neighbor estimates that are susceptible to noise. Second, it does not account for the distribution of prior data when retrieving data. To address these issues, we introduce Importance Weighted Retrieval (IWR), which estimates importance weights, or the ratio between the target and prior data distributions for retrieval, using Gaussian KDEs. By considering the probability ratio, IWR seeks to mitigate the bias of previous selection rules, and by using reasonable modeling parameters, IWR effectively smooths estimates using all data points. Across both simulation environments and real-world evaluations on the Bridge dataset we find that our method, IWR, consistently improves performance of existing retrieval-based methods, despite only requiring minor modifications.

