---
layout: default
title: Vision-Guided Grasp Planning for Prosthetic Hands in Unstructured Environments
---

# Vision-Guided Grasp Planning for Prosthetic Hands in Unstructured Environments

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.06517" target="_blank" class="toolbar-btn">arXiv: 2512.06517v1</a>
    <a href="https://arxiv.org/pdf/2512.06517.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.06517v1" 
            onclick="toggleFavorite(this, '2512.06517v1', 'Vision-Guided Grasp Planning for Prosthetic Hands in Unstructured Environments')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Shifa Sulaiman, Akash Bachhar, Ming Shen, Simon BÃ¸gh

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§è§†è§‰å¼•å¯¼çš„å‡è‚¢æ‰‹æŠ“å–è§„åˆ’ç®—æ³•ï¼Œé€‚ç”¨äºéç»“æ„åŒ–ç¯å¢ƒã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å‡è‚¢æ‰‹` `æŠ“å–è§„åˆ’` `è§†è§‰å¼•å¯¼` `RRT*` `é€†è¿åŠ¨å­¦` `éç»“æ„åŒ–ç¯å¢ƒ` `æœºå™¨äººæ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å‡è‚¢æŠ€æœ¯åœ¨å¤æ‚ç¯å¢ƒä¸‹ä¸ç‰©ä½“çš„è‡ªç„¶äº¤äº’èƒ½åŠ›ä¸è¶³ï¼Œç¼ºä¹è¶³å¤Ÿçš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§è§†è§‰å¼•å¯¼çš„æŠ“å–ç®—æ³•ï¼Œé€šè¿‡æ„ŸçŸ¥ã€è§„åˆ’å’Œæ§åˆ¶çš„é›†æˆï¼Œå®ç°å‡è‚¢æ‰‹çš„çµå·§æ“ä½œã€‚
3. è¯¥æ–¹æ³•åœ¨ä»¿çœŸå’ŒLinker Hand O7å¹³å°ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œè¯æ˜äº†å…¶åœ¨éç»“æ„åŒ–ç¯å¢ƒä¸­å®æ—¶é€‚åº”æ€§çš„èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§è§†è§‰å¼•å¯¼çš„å‡è‚¢æ‰‹æŠ“å–ç®—æ³•ï¼Œæ—¨åœ¨æå‡å‡è‚¢åœ¨åŠ¨æ€ç¯å¢ƒä¸­ä¸å„ç§ç‰©ä½“äº¤äº’çš„è‡ªç„¶æ€§ã€‚è¯¥ç®—æ³•é›†æˆäº†æ„ŸçŸ¥ã€è§„åˆ’å’Œæ§åˆ¶ï¼Œä»¥å®ç°çµå·§çš„æ“ä½œã€‚ç³»ç»Ÿé€šè¿‡ç›¸æœºæ•è·åœºæ™¯ï¼Œå¹¶é‡‡ç”¨åŸºäºåŒ…å›´ç›’å±‚æ¬¡ç»“æ„ï¼ˆBVHï¼‰çš„è§†è§‰ç®—æ³•åˆ†å‰²ç›®æ ‡ç‰©ä½“å¹¶ç¡®å®šå…¶åŒ…å›´ç›’ã€‚ç„¶åï¼Œé€šè¿‡ä½¿ç”¨å¿«é€Ÿæ¢ç´¢éšæœºæ ‘æ˜Ÿç®—æ³•ï¼ˆRRT*ï¼‰ç”Ÿæˆå€™é€‰è½¨è¿¹æ¥è®¡ç®—æŠ“å–æ¥è§¦ç‚¹ï¼Œå¹¶åŸºäºè½¨è¿¹ä¸ç‰©ä½“ç‚¹äº‘ä¹‹é—´çš„æœ€å°æ¬§å‡ é‡Œå¾—è·ç¦»é€‰æ‹©æŒ‡å°–æœ«ç«¯å§¿åŠ¿ã€‚æ¯ä¸ªæ‰‹æŒ‡çš„æŠ“å–å§¿åŠ¿ç‹¬ç«‹ç¡®å®šï¼Œä»è€Œå®ç°è‡ªé€‚åº”çš„ã€ç‰¹å®šäºç‰©ä½“çš„é…ç½®ã€‚é‡‡ç”¨åŸºäºé˜»å°¼æœ€å°äºŒä¹˜ï¼ˆDLSï¼‰çš„é€†è¿åŠ¨å­¦æ±‚è§£å™¨æ¥è®¡ç®—ç›¸åº”çš„å…³èŠ‚è§’åº¦ï¼Œéšåå°†å…¶ä¼ è¾“åˆ°æ‰‹æŒ‡æ‰§è¡Œå™¨ä»¥æ‰§è¡ŒæŠ“å–åŠ¨ä½œã€‚è¯¥æ¨¡å—åŒ–æµç¨‹æ”¯æŒæ¯ä¸ªæ‰‹æŒ‡çš„æŠ“å–è§„åˆ’ï¼Œå¹¶æ”¯æŒåœ¨éç»“æ„åŒ–ç¯å¢ƒä¸­çš„å®æ—¶é€‚åº”æ€§ã€‚è¯¥æ–¹æ³•å·²åœ¨ä»¿çœŸä¸­éªŒè¯ï¼Œå¹¶åœ¨Linker Hand O7å¹³å°ä¸Šè¿›è¡Œäº†å®éªŒé›†æˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰å‡è‚¢æ‰‹åœ¨éç»“æ„åŒ–ç¯å¢ƒä¸­éš¾ä»¥å‡†ç¡®ã€é«˜æ•ˆåœ°æŠ“å–ç‰©ä½“ã€‚ä¸»è¦ç—›ç‚¹åœ¨äºç¼ºä¹å¯¹ç¯å¢ƒå’Œç‰©ä½“å½¢çŠ¶çš„æœ‰æ•ˆæ„ŸçŸ¥ï¼Œä»¥åŠéš¾ä»¥è§„åˆ’å‡ºé€‚åº”ä¸åŒç‰©ä½“çš„æŠ“å–å§¿åŠ¿ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸ä¾èµ–äºé¢„å®šä¹‰çš„æŠ“å–ç­–ç•¥ï¼Œéš¾ä»¥åº”å¯¹å¤æ‚å¤šå˜çš„åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è§†è§‰ä¿¡æ¯å¼•å¯¼å‡è‚¢æ‰‹çš„æŠ“å–è§„åˆ’ã€‚é€šè¿‡è§†è§‰æ„ŸçŸ¥è·å–ç‰©ä½“çš„ä¿¡æ¯ï¼Œç„¶ååŸºäºè¿™äº›ä¿¡æ¯è§„åˆ’å‡ºæ¯ä¸ªæ‰‹æŒ‡çš„æŠ“å–å§¿åŠ¿ï¼Œä»è€Œå®ç°è‡ªé€‚åº”çš„æŠ“å–ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ ¹æ®ç‰©ä½“çš„å½¢çŠ¶å’Œç¯å¢ƒçš„çº¦æŸï¼ŒåŠ¨æ€è°ƒæ•´æŠ“å–ç­–ç•¥ï¼Œæé«˜æŠ“å–çš„æˆåŠŸç‡å’Œç¨³å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è§†è§‰æ„ŸçŸ¥æ¨¡å—ï¼šä½¿ç”¨ç›¸æœºæ•è·åœºæ™¯ï¼Œå¹¶åˆ©ç”¨åŸºäºBVHçš„ç®—æ³•åˆ†å‰²ç›®æ ‡ç‰©ä½“ï¼Œç¡®å®šå…¶åŒ…å›´ç›’ã€‚2) æŠ“å–è§„åˆ’æ¨¡å—ï¼šä½¿ç”¨RRT*ç®—æ³•ç”Ÿæˆå€™é€‰è½¨è¿¹ï¼Œå¹¶åŸºäºè½¨è¿¹ä¸ç‰©ä½“ç‚¹äº‘ä¹‹é—´çš„æœ€å°è·ç¦»é€‰æ‹©æŒ‡å°–æœ«ç«¯å§¿åŠ¿ã€‚æ¯ä¸ªæ‰‹æŒ‡çš„æŠ“å–å§¿åŠ¿ç‹¬ç«‹è§„åˆ’ã€‚3) é€†è¿åŠ¨å­¦æ±‚è§£æ¨¡å—ï¼šä½¿ç”¨DLSç®—æ³•è®¡ç®—å¯¹åº”äºæŒ‡å°–å§¿åŠ¿çš„å…³èŠ‚è§’åº¦ã€‚4) æ§åˆ¶æ¨¡å—ï¼šå°†å…³èŠ‚è§’åº¦å‘é€ç»™æ‰‹æŒ‡æ‰§è¡Œå™¨ï¼Œæ§åˆ¶å‡è‚¢æ‰‹å®ŒæˆæŠ“å–åŠ¨ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§åŸºäºè§†è§‰ä¿¡æ¯çš„ã€ per-finger çš„æŠ“å–è§„åˆ’æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ ¹æ®ç‰©ä½“çš„å½¢çŠ¶å’Œç¯å¢ƒçš„çº¦æŸï¼Œç‹¬ç«‹åœ°è§„åˆ’æ¯ä¸ªæ‰‹æŒ‡çš„æŠ“å–å§¿åŠ¿ï¼Œä»è€Œå®ç°æ›´çµæ´»ã€æ›´ç¨³å®šçš„æŠ“å–ã€‚æ­¤å¤–ï¼Œä½¿ç”¨BVHåŠ é€Ÿç‰©ä½“åˆ†å‰²ï¼ŒRRT*ç”Ÿæˆå€™é€‰è½¨è¿¹ï¼ŒDLSæ±‚è§£é€†è¿åŠ¨å­¦ï¼Œä¿è¯äº†ç®—æ³•çš„å®æ—¶æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ“å–è§„åˆ’æ¨¡å—ä¸­ï¼ŒRRT*ç®—æ³•çš„å‚æ•°è®¾ç½®ä¼šå½±å“è½¨è¿¹çš„ç”Ÿæˆæ•ˆç‡å’Œè´¨é‡ã€‚é€‰æ‹©åˆé€‚çš„æ­¥é•¿å’Œé‡‡æ ·ç­–ç•¥è‡³å…³é‡è¦ã€‚åœ¨é€†è¿åŠ¨å­¦æ±‚è§£æ¨¡å—ä¸­ï¼ŒDLSç®—æ³•çš„é˜»å°¼ç³»æ•°éœ€è¦æ ¹æ®å‡è‚¢æ‰‹çš„å…·ä½“ç»“æ„å’Œè¿åŠ¨èŒƒå›´è¿›è¡Œè°ƒæ•´ï¼Œä»¥é¿å…å…³èŠ‚è¶…å‡ºè¿åŠ¨èŒƒå›´æˆ–äº§ç”Ÿå¥‡å¼‚ç‚¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥è®ºæ–‡åœ¨ä»¿çœŸå’ŒLinker Hand O7å¹³å°ä¸ŠéªŒè¯äº†æ‰€æå‡ºçš„è§†è§‰å¼•å¯¼æŠ“å–ç®—æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•èƒ½å¤ŸæˆåŠŸåœ°è§„åˆ’å‡ºé€‚åº”ä¸åŒç‰©ä½“çš„æŠ“å–å§¿åŠ¿ï¼Œå¹¶åœ¨éç»“æ„åŒ–ç¯å¢ƒä¸­å®ç°ç¨³å®šçš„æŠ“å–ã€‚è™½ç„¶è®ºæ–‡ä¸­æ²¡æœ‰ç»™å‡ºå…·ä½“çš„æ€§èƒ½æ•°æ®ï¼Œä½†å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦çµå·§æ“ä½œçš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼šæ®‹ç–¾äººè¾…åŠ©ã€è¿œç¨‹æ“ä½œã€è‡ªåŠ¨åŒ–è£…é…ç­‰ã€‚é€šè¿‡è§†è§‰å¼•å¯¼çš„æŠ“å–è§„åˆ’ï¼Œå‡è‚¢æ‰‹èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å¤æ‚ç¯å¢ƒï¼Œå®Œæˆå„ç§ç²¾ç»†çš„æ“ä½œä»»åŠ¡ï¼Œæé«˜ç”Ÿæ´»è´¨é‡å’Œå·¥ä½œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›ä¸è§¦è§‰åé¦ˆã€åŠ›æ§åˆ¶ç­‰æŠ€æœ¯ç›¸ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡å‡è‚¢æ‰‹çš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in prosthetic technology have increasingly focused on enhancing dexterity and autonomy through intelligent control systems. Vision-based approaches offer promising results for enabling prosthetic hands to interact more naturally with diverse objects in dynamic environments. Building on this foundation, the paper presents a vision-guided grasping algorithm for a prosthetic hand, integrating perception, planning, and control for dexterous manipulation. A camera mounted on the set up captures the scene, and a Bounding Volume Hierarchy (BVH)-based vision algorithm is employed to segment an object for grasping and define its bounding box. Grasp contact points are then computed by generating candidate trajectories using Rapidly-exploring Random Tree Star algorithm, and selecting fingertip end poses based on the minimum Euclidean distance between these trajectories and the objects point cloud. Each finger grasp pose is determined independently, enabling adaptive, object-specific configurations. Damped Least Square (DLS) based Inverse kinematics solver is used to compute the corresponding joint angles, which are subsequently transmitted to the finger actuators for execution. This modular pipeline enables per-finger grasp planning and supports real-time adaptability in unstructured environments. The proposed method is validated in simulation, and experimental integration on a Linker Hand O7 platform.

