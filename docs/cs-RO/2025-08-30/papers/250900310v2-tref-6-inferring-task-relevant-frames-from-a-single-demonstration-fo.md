---
layout: default
title: TReF-6: Inferring Task-Relevant Frames from a Single Demonstration for One-Shot Skill Generalization
---

# TReF-6: Inferring Task-Relevant Frames from a Single Demonstration for One-Shot Skill Generalization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00310" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00310v2</a>
  <a href="https://arxiv.org/pdf/2509.00310.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00310v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00310v2', 'TReF-6: Inferring Task-Relevant Frames from a Single Demonstration for One-Shot Skill Generalization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuxuan Ding, Shuangge Wang, Tesca Fitzgerald

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30 (æ›´æ–°: 2025-09-28)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTReF-6ä»¥è§£å†³æœºå™¨äººå•æ¬¡ç¤ºèŒƒæ³›åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ä»»åŠ¡ç›¸å…³æ¡†æ¶` `åŠ¨æ€è¿åŠ¨åŸè¯­` `ä¸€æ¬¡æ€§æ¨¡ä»¿å­¦ä¹ ` `è½¨è¿¹å‡ ä½•` `æœºå™¨äººæ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ä»å•æ¬¡ç¤ºèŒƒä¸­æ³›åŒ–æ—¶ç¼ºä¹æœ‰æ•ˆçš„ç©ºé—´è¡¨ç¤ºï¼Œå¯¼è‡´æœºå™¨äººéš¾ä»¥ç†è§£å’Œæ‰§è¡Œå¤æ‚ä»»åŠ¡ã€‚
2. TReF-6é€šè¿‡ä»è½¨è¿¹å‡ ä½•ä¸­è¯†åˆ«å½±å“ç‚¹ï¼Œæ¨æ–­å‡ºä»»åŠ¡ç›¸å…³æ¡†æ¶ï¼Œè¿›è€Œä¸ºåŠ¨æ€è¿åŠ¨åŸè¯­æä¾›å‚æ•°åŒ–å‚è€ƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒTReF-6åœ¨ä»¿çœŸä¸­å¯¹è½¨è¿¹å™ªå£°è¡¨ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§ï¼Œå¹¶åœ¨å®é™…æ“ä½œä¸­å®ç°äº†ä¸€æ¬¡æ€§æ¨¡ä»¿å­¦ä¹ ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœºå™¨äººåœ¨ä»å•æ¬¡ç¤ºèŒƒä¸­æ³›åŒ–æ—¶å¸¸é¢ä¸´ç¼ºä¹å¯è½¬ç§»å’Œå¯è§£é‡Šçš„ç©ºé—´è¡¨ç¤ºçš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºTReF-6ï¼Œä¸€ç§ä»å•ä¸€è½¨è¿¹æ¨æ–­ç®€åŒ–çš„å…­è‡ªç”±åº¦ä»»åŠ¡ç›¸å…³æ¡†æ¶çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡è½¨è¿¹å‡ ä½•ç‰¹å¾è¯†åˆ«å½±å“ç‚¹ï¼Œå®šä¹‰å±€éƒ¨æ¡†æ¶çš„åŸç‚¹ï¼Œå¹¶ä½œä¸ºå‚æ•°åŒ–åŠ¨æ€è¿åŠ¨åŸè¯­ï¼ˆDMPï¼‰çš„å‚è€ƒã€‚æ¨æ–­å‡ºçš„æ¡†æ¶é€šè¿‡è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œè¯­ä¹‰åŸºç¡€åŒ–ï¼Œå¹¶é€šè¿‡Grounded-SAMåœ¨æ–°åœºæ™¯ä¸­è¿›è¡Œå®šä½ï¼Œä»è€Œå®ç°åŠŸèƒ½ä¸€è‡´çš„æŠ€èƒ½æ³›åŒ–ã€‚æˆ‘ä»¬åœ¨ä»¿çœŸä¸­éªŒè¯äº†TReF-6ï¼Œå¹¶å±•ç¤ºäº†å…¶å¯¹è½¨è¿¹å™ªå£°çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨å®é™…æ“ä½œä»»åŠ¡ä¸­éƒ¨ç½²äº†ç«¯åˆ°ç«¯çš„ç®¡é“ï¼Œè¯æ˜TReF-6æ”¯æŒåœ¨å¤šæ ·ç‰©ä½“é…ç½®ä¸‹ä¿æŒä»»åŠ¡æ„å›¾çš„ä¸€æ¬¡æ€§æ¨¡ä»¿å­¦ä¹ ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººåœ¨å•æ¬¡ç¤ºèŒƒä¸­éš¾ä»¥æ³›åŒ–çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„ç©ºé—´è¡¨ç¤ºï¼Œå¯¼è‡´æœºå™¨äººæ— æ³•å‡†ç¡®ç†è§£ä»»åŠ¡çš„ç©ºé—´ç»“æ„ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTReF-6çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è½¨è¿¹å‡ ä½•ç‰¹å¾è¯†åˆ«å½±å“ç‚¹ï¼Œå®šä¹‰å±€éƒ¨æ¡†æ¶çš„åŸç‚¹ï¼Œä»è€Œä¸ºåŠ¨æ€è¿åŠ¨åŸè¯­æä¾›ä¸€ä¸ªå¯è½¬ç§»çš„å‚æ•°åŒ–å‚è€ƒã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æœºå™¨äººèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ä»»åŠ¡çš„ç©ºé—´ç»“æ„ï¼Œè¶…è¶Šä¼ ç»Ÿçš„èµ·å§‹-ç›®æ ‡æ¨¡ä»¿ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTReF-6çš„æ•´ä½“æ¶æ„åŒ…æ‹¬å½±å“ç‚¹è¯†åˆ«ã€ä»»åŠ¡ç›¸å…³æ¡†æ¶æ¨æ–­ã€è¯­ä¹‰åŸºç¡€åŒ–å’Œæ–°åœºæ™¯å®šä½ç­‰ä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œä»è½¨è¿¹ä¸­æå–å‡ ä½•ç‰¹å¾ï¼Œè¯†åˆ«å½±å“ç‚¹ï¼›ç„¶åï¼ŒåŸºäºå½±å“ç‚¹æ¨æ–­ä»»åŠ¡ç›¸å…³æ¡†æ¶ï¼›æ¥ç€ï¼Œé€šè¿‡è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œè¯­ä¹‰åŸºç¡€åŒ–ï¼›æœ€åï¼Œåˆ©ç”¨Grounded-SAMåœ¨æ–°åœºæ™¯ä¸­è¿›è¡Œå®šä½ã€‚

**å…³é”®åˆ›æ–°**ï¼šTReF-6çš„ä¸»è¦åˆ›æ–°åœ¨äºé€šè¿‡è½¨è¿¹å‡ ä½•æ¨æ–­ä»»åŠ¡ç›¸å…³æ¡†æ¶ï¼Œæä¾›äº†ä¸€ç§æ–°çš„ç©ºé—´è¡¨ç¤ºæ–¹å¼ï¼Œä½¿å¾—åŠ¨æ€è¿åŠ¨åŸè¯­çš„åº”ç”¨æ›´åŠ çµæ´»å’Œæœ‰æ•ˆã€‚è¿™ä¸€æ–¹æ³•ä¸ç°æœ‰çš„åŸºäºèµ·å§‹-ç›®æ ‡æ¨¡ä»¿çš„æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œå½±å“ç‚¹çš„è¯†åˆ«ç®—æ³•æ˜¯å…³é”®ï¼Œç¡®ä¿å…¶èƒ½å¤Ÿå‡†ç¡®åæ˜ ä»»åŠ¡çš„ç©ºé—´ç»“æ„ã€‚æ­¤å¤–ï¼ŒåŠ¨æ€è¿åŠ¨åŸè¯­çš„å‚æ•°åŒ–è®¾è®¡å’ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©ä¹Ÿè‡³å…³é‡è¦ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å¤šæ ·ç‰©ä½“é…ç½®ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTReF-6åœ¨ä»¿çœŸç¯å¢ƒä¸­å¯¹è½¨è¿¹å™ªå£°å…·æœ‰è‰¯å¥½çš„é²æ£’æ€§ï¼Œå¹¶åœ¨å®é™…æ“ä½œä¸­å®ç°äº†ä¸€æ¬¡æ€§æ¨¡ä»¿å­¦ä¹ ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒç‰©ä½“é…ç½®ä¸‹ä¿æŒä»»åŠ¡æ„å›¾ï¼Œæ˜¾è‘—æå‡äº†æœºå™¨äººæ“ä½œçš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TReF-6åœ¨æœºå™¨äººæ“ä½œé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¿«é€Ÿé€‚åº”æ–°ç¯å¢ƒå’Œç‰©ä½“é…ç½®çš„ä»»åŠ¡ä¸­ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæé«˜æœºå™¨äººåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„çµæ´»æ€§å’Œæ•ˆç‡ï¼Œæœªæ¥å¯èƒ½åœ¨æœåŠ¡æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–å’Œå®¶åº­åŠ©ç†ç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Robots often struggle to generalize from a single demonstration due to the lack of a transferable and interpretable spatial representation. In this work, we introduce TReF-6, a method that infers a simplified, abstracted 6DoF Task-Relevant Frame from a single trajectory. Our approach identifies an influence point purely from the trajectory geometry to define the origin for a local frame, which serves as a reference for parameterizing a Dynamic Movement Primitive (DMP). This influence point captures the task's spatial structure, extending the standard DMP formulation beyond start-goal imitation. The inferred frame is semantically grounded via a vision-language model and localized in novel scenes by Grounded-SAM, enabling functionally consistent skill generalization. We validate TReF-6 in simulation and demonstrate robustness to trajectory noise. We further deploy an end-to-end pipeline on real-world manipulation tasks, showing that TReF-6 supports one-shot imitation learning that preserves task intent across diverse object configurations.

