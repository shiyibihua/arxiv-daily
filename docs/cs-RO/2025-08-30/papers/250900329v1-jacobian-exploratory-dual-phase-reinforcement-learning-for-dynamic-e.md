---
layout: default
title: Jacobian Exploratory Dual-Phase Reinforcement Learning for Dynamic Endoluminal Navigation of Deformable Continuum Robots
---

# Jacobian Exploratory Dual-Phase Reinforcement Learning for Dynamic Endoluminal Navigation of Deformable Continuum Robots

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00329" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00329v1</a>
  <a href="https://arxiv.org/pdf/2509.00329.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00329v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00329v1', 'Jacobian Exploratory Dual-Phase Reinforcement Learning for Dynamic Endoluminal Navigation of Deformable Continuum Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yu Tian, Chi Kit Ng, Hongliang Ren

**åˆ†ç±»**: cs.RO, cs.AI, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºJacobianæ¢ç´¢åŒç›¸å¼ºåŒ–å­¦ä¹ ä»¥è§£å†³å¯å˜å½¢è¿ç»­æœºå™¨äººå¯¼èˆªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¯å˜å½¢æœºå™¨äºº` `å¼ºåŒ–å­¦ä¹ ` `é›…å¯æ¯”ä¼°è®¡` `åŠ¨æ€å¯¼èˆª` `åŒ»ç–—æœºå™¨äºº` `ç­–ç•¥ä¼˜åŒ–` `ä»¿çœŸæµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¯å˜å½¢è¿ç»­æœºå™¨äººå¯¼èˆªä¸­é¢ä¸´éçº¿æ€§å˜å½¢å’Œéƒ¨åˆ†å¯è§‚æµ‹æ€§çš„é—®é¢˜ï¼Œå¯¼è‡´å¼ºåŒ–å­¦ä¹ æ•ˆæœä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºçš„JEDP-RLæ¡†æ¶é€šè¿‡åˆ†é˜¶æ®µçš„é›…å¯æ¯”ä¼°è®¡å’Œç­–ç•¥æ‰§è¡Œï¼Œå¢å¼ºäº†çŠ¶æ€è¡¨ç¤ºçš„é©¬å°”å¯å¤«æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒJEDP-RLåœ¨æ”¶æ•›é€Ÿåº¦ä¸Šæ¯”PPOå¿«3.2å€ï¼Œå¯¼èˆªæ•ˆç‡æé«˜25%ï¼Œåœ¨æœªè§ç»„ç»‡ç¯å¢ƒä¸­æˆåŠŸç‡æé«˜33%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯å˜å½¢è¿ç»­æœºå™¨äººï¼ˆDCRsï¼‰ç”±äºéçº¿æ€§å˜å½¢åŠ›å­¦å’Œéƒ¨åˆ†çŠ¶æ€å¯è§‚æµ‹æ€§ï¼Œç»™è§„åˆ’å¸¦æ¥äº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼Œè¿åäº†ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•çš„é©¬å°”å¯å¤«å‡è®¾ã€‚å°½ç®¡åŸºäºé›…å¯æ¯”çš„æ–¹æ³•ä¸ºåˆšæ€§æ“çºµå™¨æä¾›äº†ç†è®ºåŸºç¡€ï¼Œä½†ç”±äºæ—¶å˜è¿åŠ¨å­¦å’Œæ¬ é©±åŠ¨å˜å½¢åŠ¨åŠ›å­¦ï¼Œå…¶åœ¨DCRsä¸­çš„ç›´æ¥åº”ç”¨ä»ç„¶æœ‰é™ã€‚æœ¬æ–‡æå‡ºäº†Jacobianæ¢ç´¢åŒç›¸å¼ºåŒ–å­¦ä¹ ï¼ˆJEDP-RLï¼‰æ¡†æ¶ï¼Œå°†è§„åˆ’åˆ†è§£ä¸ºç›¸ä½é›…å¯æ¯”ä¼°è®¡å’Œç­–ç•¥æ‰§è¡Œã€‚åœ¨æ¯ä¸ªè®­ç»ƒæ­¥éª¤ä¸­ï¼Œé¦–å…ˆæ‰§è¡Œå°è§„æ¨¡å±€éƒ¨æ¢ç´¢åŠ¨ä½œä»¥ä¼°è®¡å˜å½¢é›…å¯æ¯”çŸ©é˜µï¼Œç„¶åé€šè¿‡é›…å¯æ¯”ç‰¹å¾å¢å¼ºçŠ¶æ€è¡¨ç¤ºï¼Œä»¥æ¢å¤è¿‘ä¼¼é©¬å°”å¯å¤«æ€§ã€‚å¤§é‡SOFAå¤–ç§‘åŠ¨æ€ä»¿çœŸå®éªŒè¡¨æ˜ï¼ŒJEDP-RLåœ¨æ”¶æ•›é€Ÿåº¦ã€å¯¼èˆªæ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ä¸Šå‡ä¼˜äºè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰åŸºçº¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¯å˜å½¢è¿ç»­æœºå™¨äººåœ¨åŠ¨æ€å¯¼èˆªä¸­çš„è§„åˆ’é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å› éçº¿æ€§å˜å½¢å’Œéƒ¨åˆ†å¯è§‚æµ‹æ€§è€Œéš¾ä»¥æœ‰æ•ˆåº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šJEDP-RLæ¡†æ¶é€šè¿‡åˆ†è§£è§„åˆ’è¿‡ç¨‹ä¸ºé›…å¯æ¯”ä¼°è®¡å’Œç­–ç•¥æ‰§è¡Œï¼Œåˆ©ç”¨å±€éƒ¨æ¢ç´¢åŠ¨ä½œæ¥ä¼°è®¡é›…å¯æ¯”çŸ©é˜µï¼Œä»è€Œå¢å¼ºçŠ¶æ€è¡¨ç¤ºçš„é©¬å°”å¯å¤«æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯å°è§„æ¨¡å±€éƒ¨æ¢ç´¢ä»¥ä¼°è®¡å˜å½¢é›…å¯æ¯”çŸ©é˜µï¼Œç¬¬äºŒé˜¶æ®µæ˜¯åŸºäºå¢å¼ºçŠ¶æ€è¡¨ç¤ºçš„ç­–ç•¥æ‰§è¡Œã€‚

**å…³é”®åˆ›æ–°**ï¼šJEDP-RLçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºé€šè¿‡é›…å¯æ¯”ç‰¹å¾çš„å¼•å…¥ï¼Œå…‹æœäº†ä¼ ç»ŸRLæ–¹æ³•åœ¨DCRsä¸­çš„å±€é™æ€§ï¼Œæ˜¾è‘—æé«˜äº†å­¦ä¹ æ•ˆç‡å’Œå¯¼èˆªæ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§å­¦ä¹ ç‡å’Œç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–é›…å¯æ¯”çŸ©é˜µçš„ä¼°è®¡ï¼Œç½‘ç»œç»“æ„åˆ™ç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œå’Œå¼ºåŒ–å­¦ä¹ ç­–ç•¥ç½‘ç»œï¼Œä»¥å®ç°é«˜æ•ˆçš„çŠ¶æ€è¡¨ç¤ºå’Œå†³ç­–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒJEDP-RLåœ¨æ”¶æ•›é€Ÿåº¦ä¸Šæ¯”PPOå¿«3.2å€ï¼Œå¯¼èˆªæ•ˆç‡æé«˜25%ï¼Œåœ¨ææ–™å±æ€§å˜åŒ–ä¸‹æˆåŠŸç‡è¾¾åˆ°92%ï¼Œåœ¨æœªè§ç»„ç»‡ç¯å¢ƒä¸­çš„æˆåŠŸç‡ä¸º83%ï¼Œæ¯”PPOé«˜å‡º33%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨åŒ»ç–—æœºå™¨äººã€å¾®åˆ›æ‰‹æœ¯å’Œå¤æ‚ç¯å¢ƒä¸‹çš„è‡ªåŠ¨å¯¼èˆªç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜å¯å˜å½¢æœºå™¨äººåœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æ‰‹æœ¯çš„å®‰å…¨æ€§å’Œæ•ˆç‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deformable continuum robots (DCRs) present unique planning challenges due to nonlinear deformation mechanics and partial state observability, violating the Markov assumptions of conventional reinforcement learning (RL) methods. While Jacobian-based approaches offer theoretical foundations for rigid manipulators, their direct application to DCRs remains limited by time-varying kinematics and underactuated deformation dynamics. This paper proposes Jacobian Exploratory Dual-Phase RL (JEDP-RL), a framework that decomposes planning into phased Jacobian estimation and policy execution. During each training step, we first perform small-scale local exploratory actions to estimate the deformation Jacobian matrix, then augment the state representation with Jacobian features to restore approximate Markovianity. Extensive SOFA surgical dynamic simulations demonstrate JEDP-RL's three key advantages over proximal policy optimization (PPO) baselines: 1) Convergence speed: 3.2x faster policy convergence, 2) Navigation efficiency: requires 25% fewer steps to reach the target, and 3) Generalization ability: achieve 92% success rate under material property variations and achieve 83% (33% higher than PPO) success rate in the unseen tissue environment.

