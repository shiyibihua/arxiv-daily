---
layout: default
title: Generative Visual Foresight Meets Task-Agnostic Pose Estimation in Robotic Table-Top Manipulation
---

# Generative Visual Foresight Meets Task-Agnostic Pose Estimation in Robotic Table-Top Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00361" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00361v1</a>
  <a href="https://arxiv.org/pdf/2509.00361.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00361v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00361v1', 'Generative Visual Foresight Meets Task-Agnostic Pose Estimation in Robotic Table-Top Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chuye Zhang, Xiaoxiong Zhang, Wei Pan, Linfang Zheng, Wei Zhang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30

**å¤‡æ³¨**: 9th Conference on Robot Learning (CoRL 2025), Seoul, Korea

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGVF-TAPEä»¥è§£å†³æœºå™¨äººå¤šä»»åŠ¡æ“ä½œä¸­çš„æ³›åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `ç”Ÿæˆè§†è§‰å‰ç»` `ä»»åŠ¡æ— å…³å§¿æ€ä¼°è®¡` `æœºå™¨äººæ“ä½œ` `é—­ç¯æ¡†æ¶` `å¤šä»»åŠ¡æ³›åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æœºå™¨äººæ“ä½œæ–¹æ³•åœ¨é¢å¯¹å¤šæ ·åŒ–ä»»åŠ¡æ—¶ï¼Œå¾€å¾€ä¾èµ–äºç‰¹å®šçš„åŠ¨ä½œæ•°æ®ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. GVF-TAPEæ¡†æ¶é€šè¿‡ç»“åˆç”Ÿæˆè§†è§‰å‰ç»ä¸ä»»åŠ¡æ— å…³çš„å§¿æ€ä¼°è®¡ï¼Œæä¾›äº†ä¸€ç§æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œèƒ½å¤Ÿåœ¨å¤šä»»åŠ¡ç¯å¢ƒä¸­è‡ªé€‚åº”æ“ä½œã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGVF-TAPEåœ¨ä»¿çœŸå’Œç°å®ç¯å¢ƒä¸­å‡è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—é™ä½äº†å¯¹ç‰¹å®šä»»åŠ¡æ•°æ®çš„ä¾èµ–ï¼Œæå‡äº†æ“ä½œçš„çµæ´»æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨éç»“æ„åŒ–ç¯å¢ƒä¸­ï¼Œæœºå™¨äººæ“ä½œéœ€è¦èƒ½å¤Ÿåœ¨å¤šæ ·åŒ–ä»»åŠ¡ä¸­ä¿æŒç¨³å¥å’Œå¯é çš„æ€§èƒ½ã€‚æœ¬æ–‡æå‡ºäº†GVF-TAPEï¼Œä¸€ä¸ªç»“åˆç”Ÿæˆè§†è§‰å‰ç»ä¸ä»»åŠ¡æ— å…³å§¿æ€ä¼°è®¡çš„é—­ç¯æ¡†æ¶ï¼Œä»¥å®ç°å¯æ‰©å±•çš„æœºå™¨äººæ“ä½œã€‚GVF-TAPEåˆ©ç”¨ç”Ÿæˆè§†é¢‘æ¨¡å‹ä»å•ä¸€ä¾§è§†RGBå›¾åƒå’Œä»»åŠ¡æè¿°ä¸­é¢„æµ‹æœªæ¥çš„RGB-Då¸§ï¼Œæä¾›æŒ‡å¯¼æœºå™¨äººåŠ¨ä½œçš„è§†è§‰è®¡åˆ’ã€‚é€šè¿‡è§£è€¦çš„å§¿æ€ä¼°è®¡æ¨¡å‹ï¼Œä»é¢„æµ‹å¸§ä¸­æå–æœ«ç«¯æ‰§è¡Œå™¨å§¿æ€ï¼Œå¹¶é€šè¿‡ä½çº§æ§åˆ¶å™¨å°†å…¶è½¬åŒ–ä¸ºå¯æ‰§è¡Œå‘½ä»¤ã€‚é€šè¿‡åœ¨é—­ç¯ä¸­è¿­ä»£æ•´åˆè§†é¢‘å‰ç»ä¸å§¿æ€ä¼°è®¡ï¼ŒGVF-TAPEå®ç°äº†å®æ—¶ã€è‡ªé€‚åº”çš„æ“ä½œï¼Œå¹¿æ³›é€‚ç”¨äºå¤šç§ä»»åŠ¡ã€‚å¤§é‡çš„ä»¿çœŸå’Œç°å®ç¯å¢ƒå®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å‡å°‘äº†å¯¹ç‰¹å®šä»»åŠ¡åŠ¨ä½œæ•°æ®çš„ä¾èµ–ï¼Œå¹¶æœ‰æ•ˆåœ°å®ç°äº†æ³›åŒ–ï¼Œä¸ºæ™ºèƒ½æœºå™¨äººç³»ç»Ÿæä¾›äº†å®ç”¨ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººåœ¨å¤šä»»åŠ¡æ“ä½œä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºç‰¹å®šä»»åŠ¡çš„æ•°æ®ï¼Œå¯¼è‡´åœ¨æ–°ä»»åŠ¡ä¸­çš„è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGVF-TAPEæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯ç»“åˆç”Ÿæˆè§†è§‰å‰ç»ä¸ä»»åŠ¡æ— å…³çš„å§¿æ€ä¼°è®¡ï¼Œé€šè¿‡é¢„æµ‹æœªæ¥çš„è§†è§‰ä¿¡æ¯æ¥æŒ‡å¯¼æœºå™¨äººæ“ä½œï¼Œä»è€Œå®ç°æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGVF-TAPEçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç”Ÿæˆè§†é¢‘æ¨¡å‹å’Œè§£è€¦çš„å§¿æ€ä¼°è®¡æ¨¡å‹ã€‚ç”Ÿæˆè§†é¢‘æ¨¡å‹ä»å•ä¸€çš„RGBå›¾åƒå’Œä»»åŠ¡æè¿°ä¸­é¢„æµ‹æœªæ¥çš„RGB-Då¸§ï¼Œè€Œå§¿æ€ä¼°è®¡æ¨¡å‹åˆ™ä»è¿™äº›é¢„æµ‹å¸§ä¸­æå–æœ«ç«¯æ‰§è¡Œå™¨çš„å§¿æ€ã€‚

**å…³é”®åˆ›æ–°**ï¼šGVF-TAPEçš„åˆ›æ–°ä¹‹å¤„åœ¨äºå…¶é—­ç¯è®¾è®¡ï¼Œé€šè¿‡è¿­ä»£æ•´åˆè§†é¢‘å‰ç»ä¸å§¿æ€ä¼°è®¡ï¼Œå®ç°äº†å®æ—¶çš„è‡ªé€‚åº”æ“ä½œã€‚è¿™ç§è®¾è®¡ä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåœ¨å¤šæ ·åŒ–ä»»åŠ¡ä¸­çµæ´»åº”å¯¹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒGVF-TAPEé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç”Ÿæˆæ¨¡å‹çš„é¢„æµ‹ç²¾åº¦ï¼Œå¹¶è®¾è®¡äº†é«˜æ•ˆçš„ç½‘ç»œç»“æ„ä»¥æ”¯æŒå®æ—¶å¤„ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGVF-TAPEåœ¨å¤šç§ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œå‡å°‘äº†å¯¹ç‰¹å®šä»»åŠ¡æ•°æ®çš„ä¾èµ–ï¼Œæå‡äº†æ“ä½œçš„çµæ´»æ€§å’Œæ•ˆç‡ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€å·¥ä¸šè‡ªåŠ¨åŒ–å’ŒæœåŠ¡æœºå™¨äººç­‰ã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨å¤šä»»åŠ¡ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ï¼ŒGVF-TAPEèƒ½å¤Ÿæ˜¾è‘—æå‡æœºå™¨äººåœ¨å®é™…æ“ä½œä¸­çš„æ•ˆç‡å’Œçµæ´»æ€§ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Robotic manipulation in unstructured environments requires systems that can generalize across diverse tasks while maintaining robust and reliable performance. We introduce {GVF-TAPE}, a closed-loop framework that combines generative visual foresight with task-agnostic pose estimation to enable scalable robotic manipulation. GVF-TAPE employs a generative video model to predict future RGB-D frames from a single side-view RGB image and a task description, offering visual plans that guide robot actions. A decoupled pose estimation model then extracts end-effector poses from the predicted frames, translating them into executable commands via low-level controllers. By iteratively integrating video foresight and pose estimation in a closed loop, GVF-TAPE achieves real-time, adaptive manipulation across a broad range of tasks. Extensive experiments in both simulation and real-world settings demonstrate that our approach reduces reliance on task-specific action data and generalizes effectively, providing a practical and scalable solution for intelligent robotic systems.

