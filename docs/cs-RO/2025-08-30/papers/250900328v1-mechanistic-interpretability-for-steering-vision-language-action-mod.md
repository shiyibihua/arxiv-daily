---
layout: default
title: Mechanistic interpretability for steering vision-language-action models
---

# Mechanistic interpretability for steering vision-language-action models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00328" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00328v1</a>
  <a href="https://arxiv.org/pdf/2509.00328.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00328v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00328v1', 'Mechanistic interpretability for steering vision-language-action models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Bear HÃ¤on, Kaylene Stocking, Ian Chuang, Claire Tomlin

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30

**å¤‡æ³¨**: CoRL 2025. Project website: https://vla-mech-interp.github.io/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæœºåˆ¶å¯è§£é‡Šæ€§æ¡†æ¶ä»¥å¼•å¯¼è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `æœºåˆ¶å¯è§£é‡Šæ€§` `æ¿€æ´»å¼•å¯¼` `æœºå™¨äººæ§åˆ¶` `æ™ºèƒ½ä½“é€‚åº”æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨è§£é‡Šå’Œå¼•å¯¼æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œç¼ºä¹å¯¹æ¨¡å‹å†…éƒ¨æœºåˆ¶çš„æ·±å…¥ç†è§£ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œé€šè¿‡å†…éƒ¨è¡¨ç¤ºå¯¹VLAè¿›è¡Œè§£é‡Šå’Œå¼•å¯¼ï¼Œå…è®¸åœ¨æ¨ç†æ—¶ç›´æ¥å¹²é¢„æ¨¡å‹è¡Œä¸ºã€‚
3. åœ¨å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•åœ¨ä¸¤ä¸ªå¼€æºVLAä¸Šå®ç°äº†é›¶-shotè¡Œä¸ºæ§åˆ¶ï¼Œå±•ç¤ºäº†å…¶åœ¨æ¨¡æ‹Ÿå’Œç‰©ç†ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹æ˜¯å®ç°é€šç”¨åµŒå…¥å¼æ™ºèƒ½ä½“çš„æœ‰å‰æ™¯çš„è·¯å¾„ï¼Œèƒ½å¤Ÿå¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡ã€æ¨¡æ€å’Œç¯å¢ƒã€‚ç„¶è€Œï¼Œç›®å‰å¯¹VLAçš„è§£é‡Šå’Œå¼•å¯¼æ–¹æ³•è¿œä¸åŠç»å…¸æœºå™¨äººç®¡é“ï¼Œç¼ºä¹å¯¹è¿åŠ¨å­¦ã€åŠ¨åŠ›å­¦å’Œæ§åˆ¶çš„æ˜ç¡®æ¨¡å‹ï¼Œè¿™åœ¨ç°å®æœºå™¨äººä¸­éƒ¨ç½²å­¦ä¹ ç­–ç•¥æ—¶æ„æˆäº†ä¸»è¦æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ç¬¬ä¸€ä¸ªé€šè¿‡å†…éƒ¨è¡¨ç¤ºè§£é‡Šå’Œå¼•å¯¼VLAçš„æ¡†æ¶ï¼Œä½¿å¾—åœ¨æ¨ç†æ—¶èƒ½å¤Ÿç›´æ¥å¹²é¢„æ¨¡å‹è¡Œä¸ºã€‚æˆ‘ä»¬å°†å‰é¦ˆæ¿€æ´»æŠ•å½±åˆ°ä»¤ç‰ŒåµŒå…¥åŸºä¸Šï¼Œè¯†åˆ«å‡ºä¸åŠ¨ä½œé€‰æ‹©å› æœç›¸å…³çš„ç¨€ç–è¯­ä¹‰æ–¹å‘ï¼Œå¦‚é€Ÿåº¦å’Œæ–¹å‘ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§é€šç”¨çš„æ¿€æ´»å¼•å¯¼æ–¹æ³•ï¼Œèƒ½å¤Ÿå®æ—¶è°ƒèŠ‚è¡Œä¸ºï¼Œæ— éœ€å¾®è°ƒã€å¥–åŠ±ä¿¡å·æˆ–ç¯å¢ƒäº¤äº’ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªå¼€æºVLAï¼ˆPi0å’ŒOpenVLAï¼‰ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œå¹¶åœ¨æ¨¡æ‹Ÿç¯å¢ƒï¼ˆLIBEROï¼‰å’Œç‰©ç†æœºå™¨äººï¼ˆUR5ï¼‰ä¸Šå±•ç¤ºäº†é›¶-shotè¡Œä¸ºæ§åˆ¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼ˆVLAï¼‰åœ¨è§£é‡Šå’Œå¼•å¯¼æ–¹é¢çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹æ¨¡å‹å†…éƒ¨æœºåˆ¶çš„æ·±å…¥ç†è§£ï¼Œå¯¼è‡´åœ¨å®é™…æœºå™¨äººåº”ç”¨ä¸­çš„é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¯¹VLAçš„å†…éƒ¨è¡¨ç¤ºè¿›è¡Œåˆ†æï¼Œè¯†åˆ«å‡ºä¸åŠ¨ä½œé€‰æ‹©ç›¸å…³çš„ç¨€ç–è¯­ä¹‰æ–¹å‘ï¼Œä»è€Œå®ç°å¯¹æ¨¡å‹è¡Œä¸ºçš„å®æ—¶è°ƒèŠ‚ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—åœ¨ä¸éœ€è¦å¾®è°ƒæˆ–é¢å¤–å¥–åŠ±ä¿¡å·çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¼•å¯¼æ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹Transformerå±‚çš„å‰é¦ˆæ¿€æ´»è¿›è¡ŒæŠ•å½±ï¼Œè¯†åˆ«å‡ºä¸åŠ¨ä½œé€‰æ‹©ç›¸å…³çš„è¯­ä¹‰æ–¹å‘ï¼Œå¹¶åŸºäºè¿™äº›æ–¹å‘è®¾è®¡æ¿€æ´»å¼•å¯¼æ–¹æ³•ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ¿€æ´»æŠ•å½±ã€è¯­ä¹‰æ–¹å‘è¯†åˆ«å’Œè¡Œä¸ºè°ƒèŠ‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé¦–æ¬¡å°†æœºåˆ¶å¯è§£é‡Šæ€§å¼•å…¥VLAæ¨¡å‹ï¼Œé€šè¿‡å†…éƒ¨è¡¨ç¤ºçš„åˆ†æå®ç°å¯¹æ¨¡å‹è¡Œä¸ºçš„ç›´æ¥å¹²é¢„ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„åŸºäºå¥–åŠ±ä¿¡å·çš„å¼•å¯¼æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œæä¾›äº†æ›´é«˜çš„é€æ˜åº¦å’Œå¯æ§æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŠ•å½±ç®—æ³•å°†æ¿€æ´»æ˜ å°„åˆ°ä»¤ç‰ŒåµŒå…¥åŸºä¸Šï¼Œè¯†åˆ«å‡ºç¨€ç–çš„è¯­ä¹‰æ–¹å‘ã€‚æ­¤å¤–ï¼Œæ¿€æ´»å¼•å¯¼æ–¹æ³•çš„è®¾è®¡ç¡®ä¿äº†å®æ—¶æ€§ï¼Œèƒ½å¤Ÿåœ¨ä¸å½±å“æ¨¡å‹ç¨³å®šæ€§çš„æƒ…å†µä¸‹è¿›è¡Œè¡Œä¸ºè°ƒèŠ‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¿€æ´»å¼•å¯¼æ–¹æ³•åœ¨ä¸¤ä¸ªå¼€æºVLAï¼ˆPi0å’ŒOpenVLAï¼‰ä¸Šå®ç°äº†é›¶-shotè¡Œä¸ºæ§åˆ¶ã€‚åœ¨æ¨¡æ‹Ÿç¯å¢ƒLIBEROå’Œç‰©ç†æœºå™¨äººUR5ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®æ—¶æ€§ï¼Œä¸ºVLAæ¨¡å‹çš„å®é™…åº”ç”¨æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€æ™ºèƒ½åŠ©æ‰‹å’Œè‡ªåŠ¨åŒ–ç³»ç»Ÿç­‰ã€‚é€šè¿‡æä¾›å¯¹VLAæ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œå¯æ§æ€§ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„ä»»åŠ¡æ‰§è¡Œï¼Œæå‡æœºå™¨äººåœ¨åŠ¨æ€åœºæ™¯ä¸­çš„é€‚åº”èƒ½åŠ›å’Œå†³ç­–è´¨é‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šæ¨åŠ¨æ›´å¹¿æ³›çš„æ™ºèƒ½ä½“åº”ç”¨ï¼Œä¿ƒè¿›äººæœºåä½œçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models are a promising path to realizing generalist embodied agents that can quickly adapt to new tasks, modalities, and environments. However, methods for interpreting and steering VLAs fall far short of classical robotics pipelines, which are grounded in explicit models of kinematics, dynamics, and control. This lack of mechanistic insight is a central challenge for deploying learned policies in real-world robotics, where robustness and explainability are critical. Motivated by advances in mechanistic interpretability for large language models, we introduce the first framework for interpreting and steering VLAs via their internal representations, enabling direct intervention in model behavior at inference time. We project feedforward activations within transformer layers onto the token embedding basis, identifying sparse semantic directions - such as speed and direction - that are causally linked to action selection. Leveraging these findings, we introduce a general-purpose activation steering method that modulates behavior in real time, without fine-tuning, reward signals, or environment interaction. We evaluate this method on two recent open-source VLAs, Pi0 and OpenVLA, and demonstrate zero-shot behavioral control in simulation (LIBERO) and on a physical robot (UR5). This work demonstrates that interpretable components of embodied VLAs can be systematically harnessed for control - establishing a new paradigm for transparent and steerable foundation models in robotics.

