---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-09-13
---

# cs.ROï¼ˆ2025-09-13ï¼‰

ğŸ“Š å…± **6** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (4 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250910796v3-follow-bench-a-unified-motion-planning-benchmark-for-socially-aware-.html">Follow-Bench: A Unified Motion Planning Benchmark for Socially-Aware Robot Person Following</a></td>
  <td>æå‡ºFollow-Benchï¼Œç”¨äºè¯„ä¼°å’Œæå‡ç¤¾äº¤æ„ŸçŸ¥æœºå™¨äººè·Ÿéšçš„è¿åŠ¨è§„åˆ’ç®—æ³•ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10796v3" data-paper-url="./papers/250910796v3-follow-bench-a-unified-motion-planning-benchmark-for-socially-aware-.html" onclick="toggleFavorite(this, '2509.10796v3', 'Follow-Bench: A Unified Motion Planning Benchmark for Socially-Aware Robot Person Following')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250910771v1-rsl-rl-a-learning-library-for-robotics-research.html">RSL-RL: A Learning Library for Robotics Research</a></td>
  <td>RSL-RLï¼šä¸ºæœºå™¨äººç ”ç©¶å®šåˆ¶çš„è½»é‡çº§ã€å¯æ‰©å±•å¼ºåŒ–å­¦ä¹ åº“</td>
  <td class="tags-cell"><span class="paper-tag">legged robot</span> <span class="paper-tag">reinforcement learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10771v1" data-paper-url="./papers/250910771v1-rsl-rl-a-learning-library-for-robotics-research.html" onclick="toggleFavorite(this, '2509.10771v1', 'RSL-RL: A Learning Library for Robotics Research')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250910968v1-pogosim-a-simulator-for-pogobot-robots.html">Pogosim -- a Simulator for Pogobot robots</a></td>
  <td>Pogosimï¼šç”¨äºPogobotæœºå™¨äººé›†ç¾¤æ™ºèƒ½ç ”ç©¶çš„é«˜æ•ˆå¯æ‰©å±•ä»¿çœŸå™¨</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10968v1" data-paper-url="./papers/250910968v1-pogosim-a-simulator-for-pogobot-robots.html" onclick="toggleFavorite(this, '2509.10968v1', 'Pogosim -- a Simulator for Pogobot robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250910952v1-immimic-cross-domain-imitation-from-human-videos-via-mapping-and-int.html">ImMimic: Cross-Domain Imitation from Human Videos via Mapping and Interpolation</a></td>
  <td>ImMimicï¼šé€šè¿‡æ˜ å°„å’Œæ’å€¼å®ç°ä»äººç±»è§†é¢‘åˆ°æœºå™¨äººçš„è·¨åŸŸæ¨¡ä»¿å­¦ä¹ </td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10952v1" data-paper-url="./papers/250910952v1-immimic-cross-domain-imitation-from-human-videos-via-mapping-and-int.html" onclick="toggleFavorite(this, '2509.10952v1', 'ImMimic: Cross-Domain Imitation from Human Videos via Mapping and Interpolation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>5</td>
  <td><a href="./papers/250910757v1-fasttrack-gpu-accelerated-tracking-for-visual-slam.html">FastTrack: GPU-Accelerated Tracking for Visual SLAM</a></td>
  <td>FastTrackï¼šåˆ©ç”¨GPUåŠ é€Ÿè§†è§‰SLAMçš„è·Ÿè¸ªæ¨¡å—ï¼Œæå‡å®æ—¶æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">visual SLAM</span> <span class="paper-tag">feature matching</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10757v1" data-paper-url="./papers/250910757v1-fasttrack-gpu-accelerated-tracking-for-visual-slam.html" onclick="toggleFavorite(this, '2509.10757v1', 'FastTrack: GPU-Accelerated Tracking for Visual SLAM')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>6</td>
  <td><a href="./papers/250910884v1-nav-r1-reasoning-and-navigation-in-embodied-scenes.html">Nav-R1: Reasoning and Navigation in Embodied Scenes</a></td>
  <td>Nav-R1ï¼šå…·èº«ç¯å¢ƒä¸­èåˆæ¨ç†ä¸å¯¼èˆªçš„åŸºåº§æ¨¡å‹</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">embodied AI</span> <span class="paper-tag">foundation model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10884v1" data-paper-url="./papers/250910884v1-nav-r1-reasoning-and-navigation-in-embodied-scenes.html" onclick="toggleFavorite(this, '2509.10884v1', 'Nav-R1: Reasoning and Navigation in Embodied Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)