---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€»ï¼ˆwith DeepSeekï¼‰ - cs.RO - 2025-12-16
---

# cs.ROï¼ˆ2025-12-16ï¼‰

ğŸ“Š å…± **9** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#è§†è§‰é‡Œç¨‹è®¡-visual-odometry" class="interest-badge">è§†è§‰é‡Œç¨‹è®¡ (Visual Odometry) (3)</a>
<a href="#å››è¶³ç§»åŠ¨-quadruped-locomotion" class="interest-badge">å››è¶³ç§»åŠ¨ (Quadruped Locomotion) (1 ğŸ”—1)</a>
<a href="#é¥æ“ä½œä¸æ¨¡ä»¿-teleoperation-imitation" class="interest-badge">é¥æ“ä½œä¸æ¨¡ä»¿ (Teleoperation & Imitation) (1)</a>
<a href="#äººå½¢ç§»åŠ¨-humanoid-locomotion" class="interest-badge">äººå½¢ç§»åŠ¨ (Humanoid Locomotion) (1)</a>
<a href="#å…·èº«æ™ºèƒ½-embodied-ai" class="interest-badge">å…·èº«æ™ºèƒ½ (Embodied AI) (1)</a>
<a href="#çµå·§æ‰‹æ“ä½œ-dexterous-manipulation" class="interest-badge">çµå·§æ‰‹æ“ä½œ (Dexterous Manipulation) (1)</a>
<a href="#æ·±åº¦ä¼°è®¡-depth-estimation" class="interest-badge">æ·±åº¦ä¼°è®¡ (Depth Estimation) (1 ğŸ”—1)</a>
</div>

---


<h2 id="è§†è§‰é‡Œç¨‹è®¡-visual-odometry">ğŸ”¬ è§†è§‰é‡Œç¨‹è®¡ (Visual Odometry) (3 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 1 | [SUPER -- A Framework for Sensitivity-based Uncertainty-aware Performance and Risk Assessment in Visual Inertial Odometry](./papers/251214189v1-super-a-framework-for-sensitivity-based-uncertainty-aware-performanc.html) | SUPERï¼šåŸºäºæ•æ„Ÿåº¦çš„è§†è§‰æƒ¯æ€§é‡Œç¨‹è®¡æ€§èƒ½ä¸é£é™©è¯„ä¼°æ¡†æ¶ |  |
| 2 | [Odyssey: An Automotive Lidar-Inertial Odometry Dataset for GNSS-denied situations](./papers/251214428v1-odyssey-an-automotive-lidar-inertial-odometry-dataset-for-gnss-denie.html) | Odysseyï¼šä¸ºGNSSæ‹’æ­¢ç¯å¢ƒæä¾›é«˜ç²¾åº¦æ¿€å…‰é›·è¾¾æƒ¯æ€§é‡Œç¨‹è®¡æ•°æ®é›† |  |
| 3 | [Field evaluation and optimization of a lightweight lidar-based UAV navigation system for dense boreal forest environments](./papers/251214340v1-field-evaluation-and-optimization-of-a-lightweight-lidar-based-uav-n.html) | æå‡ºä¸€ç§è½»é‡çº§æ¿€å…‰é›·è¾¾æ— äººæœºå¯¼èˆªç³»ç»Ÿï¼Œç”¨äºå¤æ‚åŒ—æ–¹æ£®æ—ç¯å¢ƒä¸‹çš„è‡ªä¸»é£è¡Œã€‚ |  |


<h2 id="å››è¶³ç§»åŠ¨-quadruped-locomotion">ğŸ”¬ å››è¶³ç§»åŠ¨ (Quadruped Locomotion) (1 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 4 | [CaFe-TeleVision: A Coarse-to-Fine Teleoperation System with Immersive Situated Visualization for Enhanced Ergonomics](./papers/251214270v1-cafe-television-a-coarse-to-fine-teleoperation-system-with-immersive.html) | CaFe-TeleVisionï¼šåŸºäºç²—ç»†ç²’åº¦æ§åˆ¶å’Œæ²‰æµ¸å¼å¯è§†åŒ–çš„äººå½¢æœºå™¨äººé¥æ“ä½œç³»ç»Ÿï¼Œæå‡äººæœºå·¥æ•ˆ | âœ… |


<h2 id="é¥æ“ä½œä¸æ¨¡ä»¿-teleoperation-imitation">ğŸ”¬ é¥æ“ä½œä¸æ¨¡ä»¿ (Teleoperation & Imitation) (1 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 5 | [Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model](./papers/251214031v1-sample-efficient-robot-skill-learning-for-construction-tasks-benchma.html) | å¯¹æ¯”VLAæ¨¡å‹ä¸å¼ºåŒ–å­¦ä¹ ï¼Œæå‡å»ºç­‘æœºå™¨äººæ“ä½œæŠ€èƒ½å¹¶å®ç°é«˜æ•ˆæ ·æœ¬åˆ©ç”¨ |  |


<h2 id="äººå½¢ç§»åŠ¨-humanoid-locomotion">ğŸ”¬ äººå½¢ç§»åŠ¨ (Humanoid Locomotion) (1 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 6 | [CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation](./papers/251214689v1-chip-adaptive-compliance-for-humanoid-control-through-hindsight-pert.html) | æå‡ºCHIPè‡ªé€‚åº”æŸ”é¡ºæ§åˆ¶ï¼Œæå‡äººå½¢æœºå™¨äººåŠ›æ“ä½œä»»åŠ¡æ€§èƒ½ |  |


<h2 id="å…·èº«æ™ºèƒ½-embodied-ai">ğŸ”¬ å…·èº«æ™ºèƒ½ (Embodied AI) (1 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 7 | [EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models](./papers/251214666v1-evolve-vla-test-time-training-from-environment-feedback-for-vision-l.html) | EVOLVE-VLAï¼šé¢å‘VLAæ¨¡å‹çš„ç¯å¢ƒåé¦ˆæµ‹è¯•æ—¶è®­ç»ƒæ¡†æ¶ |  |


<h2 id="çµå·§æ‰‹æ“ä½œ-dexterous-manipulation">ğŸ”¬ çµå·§æ‰‹æ“ä½œ (Dexterous Manipulation) (1 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 8 | [Interactive Motion Planning for Human-Robot Collaboration Based on Human-Centric Configuration Space Ergonomic Field](./papers/251214111v1-interactive-motion-planning-for-human-robot-collaboration-based-on-h.html) | æå‡ºåŸºäºäººæœºåä½œæ„å‹ç©ºé—´äººä½“å·¥å­¦åœºçš„äº¤äº’å¼æœºå™¨äººè¿åŠ¨è§„åˆ’æ–¹æ³• |  |


<h2 id="æ·±åº¦ä¼°è®¡-depth-estimation">ğŸ”¬ æ·±åº¦ä¼°è®¡ (Depth Estimation) (1 ç¯‡)</h2>

| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |
|---:|---|---|:---:|
| 9 | [CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth](./papers/251214001v1-claim-camera-lidar-alignment-with-intensity-and-monodepth.html) | CLAIMï¼šåˆ©ç”¨å•ç›®æ·±åº¦å’Œå¼ºåº¦ä¿¡æ¯å®ç°ç›¸æœº-æ¿€å…‰é›·è¾¾æ ‡å®š | âœ… |


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)