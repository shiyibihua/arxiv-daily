---
layout: default
title: Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning
---

# Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.14057" target="_blank" class="toolbar-btn">arXiv: 2512.14057v1</a>
    <a href="https://arxiv.org/pdf/2512.14057.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14057v1" 
            onclick="toggleFavorite(this, '2512.14057v1', 'Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Amir M. Soufi Enayati, Homayoun Honari, Homayoun Najjaran

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-16

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫CRAFTÔºö‰∏ÄÁßçÂü∫‰∫éÊó†Âä®‰ΩúTransformerÁöÑÂÖÉÂº∫ÂåñÂ≠¶‰π†‰∏ä‰∏ãÊñáË°®Á§∫ÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÂÖÉÂº∫ÂåñÂ≠¶‰π†` `‰∏ä‰∏ãÊñáË°®Á§∫` `Transformer` `Êó†Âä®‰ΩúÂ≠¶‰π†` `Êú∫Âô®‰∫∫ÊéßÂà∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰º†ÁªüÂÖÉÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ï‰æùËµñÂä®‰Ωú‰ø°ÊÅØËøõË°å‰ªªÂä°Êé®Êñ≠ÔºåÂØºËá¥‰ªªÂä°Êé®Êñ≠‰∏éÁâπÂÆöÁ≠ñÁï•ÁªëÂÆöÔºåÊ≥õÂåñËÉΩÂäõÂèóÈôê„ÄÇ
2. CRAFTÈÄöËøáÊó†Âä®‰ΩúTransformerÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®Ôºå‰ªÖ‰ªéÁä∂ÊÄÅÂíåÂ•ñÂä±Â∫èÂàóÊé®Êñ≠‰ªªÂä°Ë°®Á§∫ÔºåËß£ËÄ¶‰ªªÂä°Êé®Êñ≠‰∏éÁ≠ñÁï•‰ºòÂåñ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåCRAFTÂú®MetaWorld ML-10‰∏äÂÆûÁé∞‰∫ÜÊõ¥Âø´ÁöÑÈÄÇÂ∫î„ÄÅÊõ¥Â•ΩÁöÑÊ≥õÂåñÂíåÊõ¥ÊúâÊïàÁöÑÊé¢Á¥¢„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âº∫ÂåñÂ≠¶‰π†(RL)‰ΩøÊú∫Âô®‰∫∫ËÉΩÂ§üÂú®‰∏çÁ°ÆÂÆöÁéØÂ¢É‰∏≠ËøêË°åÔºå‰ΩÜÊ†áÂáÜÊñπÊ≥ïÈÄöÂ∏∏Èöæ‰ª•Ê≥õÂåñÂà∞Êú™ËßÅËøáÁöÑ‰ªªÂä°„ÄÇ‰∏ä‰∏ãÊñáËá™ÈÄÇÂ∫îÂÖÉÂº∫ÂåñÂ≠¶‰π†ÈÄöËøáË∞ÉËäÇ‰ªªÂä°Ë°®Á§∫Êù•Ëß£ÂÜ≥Ëøô‰∫õÈôêÂà∂Ôºå‰ΩÜÂÆÉ‰ª¨‰∏ªË¶Å‰æùËµñ‰∫éÁªèÈ™å‰∏≠ÁöÑÂÆåÊï¥Âä®‰Ωú‰ø°ÊÅØÔºå‰ΩøÂæó‰ªªÂä°Êé®Êñ≠‰∏éÁâπÂÆöÁ≠ñÁï•Á¥ßÂØÜËÄ¶Âêà„ÄÇÊú¨Êñá‰ªãÁªç‰∫Ü‰∏ÄÁßçÈÄöËøáÊó†Âä®‰ΩúTransformerÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®(CRAFT)ËøõË°å‰∏ä‰∏ãÊñáË°®Á§∫ÁöÑÊñπÊ≥ïÔºåËøôÊòØ‰∏ÄÁßç‰ªÖ‰ªéÁä∂ÊÄÅÂíåÂ•ñÂä±Â∫èÂàóÊé®Êñ≠‰ªªÂä°Ë°®Á§∫ÁöÑ‰ø°ÂøµÊ®°Âûã„ÄÇÈÄöËøáÊ∂àÈô§ÂØπÂä®‰ΩúÁöÑ‰æùËµñÔºåCRAFTÂ∞Ü‰ªªÂä°Êé®Êñ≠‰∏éÁ≠ñÁï•‰ºòÂåñËß£ËÄ¶ÔºåÊîØÊåÅÊ®°ÂùóÂåñËÆ≠ÁªÉÔºåÂπ∂Âà©Áî®ÊëäÈîÄÂèòÂàÜÊé®Êñ≠ËøõË°åÂèØÊâ©Â±ïÁöÑ‰ø°ÂøµÊõ¥Êñ∞„ÄÇËØ•Ê®°ÂûãÂª∫Á´ãÂú®ÂÖ∑ÊúâÊóãËΩ¨‰ΩçÁΩÆÂµåÂÖ•ÁöÑTransformerÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®‰πã‰∏äÔºåÊçïËé∑ÈïøÁ®ãÊó∂Èó¥‰æùËµñÊÄßÔºåÂπ∂Á®≥ÂÅ•Âú∞ÁºñÁ†ÅÂèÇÊï∞ÂíåÈùûÂèÇÊï∞‰ªªÂä°ÂèòÂåñ„ÄÇÂú®MetaWorld ML-10Êú∫Âô®‰∫∫Êìç‰ΩúÂü∫ÂáÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºå‰∏é‰∏ä‰∏ãÊñáËá™ÈÄÇÂ∫îÂÖÉÂº∫ÂåñÂ≠¶‰π†Âü∫Á∫øÁõ∏ÊØîÔºåCRAFTÂÆûÁé∞‰∫ÜÊõ¥Âø´ÁöÑÈÄÇÂ∫î„ÄÅÊîπËøõÁöÑÊ≥õÂåñÂíåÊõ¥ÊúâÊïàÁöÑÊé¢Á¥¢„ÄÇËøô‰∫õÂèëÁé∞Á™ÅÂá∫‰∫ÜÊó†Âä®‰ΩúÊé®Êñ≠‰Ωú‰∏∫Êú∫Âô®‰∫∫ÊéßÂà∂‰∏≠ÂèØÊâ©Â±ïRLÁöÑÂü∫Á°ÄÁöÑÊΩúÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂÖÉÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂú®ËøõË°å‰ªªÂä°Êé®Êñ≠Êó∂ÔºåÈÄöÂ∏∏ÈúÄË¶Å‰æùËµñÂÆåÊï¥ÁöÑÂä®‰Ωú‰ø°ÊÅØÔºåËøô‰ΩøÂæó‰ªªÂä°Êé®Êñ≠ËøáÁ®ã‰∏éÁâπÂÆöÁöÑÁ≠ñÁï•Á¥ßÂØÜËÄ¶Âêà„ÄÇËøôÁßçËÄ¶ÂêàÈôêÂà∂‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®Èù¢ÂØπÊú™ËßÅËøáÁöÑ‰ªªÂä°Êó∂ÔºåÊ®°ÂûãÈöæ‰ª•Âø´ÈÄüÈÄÇÂ∫î„ÄÇÊ≠§Â§ñÔºå‰æùËµñÂä®‰Ωú‰ø°ÊÅØ‰πü‰ΩøÂæóÊ®°ÂûãÈöæ‰ª•ËøõË°åÊ®°ÂùóÂåñËÆ≠ÁªÉÔºå‰∏çÂà©‰∫éÊâ©Â±ïÂà∞Êõ¥Â§çÊùÇÁöÑ‰ªªÂä°„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöCRAFTÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØËÆæËÆ°‰∏Ä‰∏™Êó†Âä®‰ΩúÁöÑ‰ø°ÂøµÊ®°ÂûãÔºåËØ•Ê®°Âûã‰ªÖÈÄöËøáËßÇÂØüÁä∂ÊÄÅÂíåÂ•ñÂä±Â∫èÂàóÊù•Êé®Êñ≠‰ªªÂä°Ë°®Á§∫„ÄÇÈÄöËøáÊ∂àÈô§ÂØπÂä®‰ΩúÁöÑ‰æùËµñÔºåCRAFTÂ∞Ü‰ªªÂä°Êé®Êñ≠‰∏éÁ≠ñÁï•‰ºòÂåñËß£ËÄ¶Ôºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÂíåÂèØÊâ©Â±ïÊÄß„ÄÇËøôÁßçËß£ËÄ¶‰πü‰ΩøÂæóÊ®°ÂûãÂèØ‰ª•ËøõË°åÊ®°ÂùóÂåñËÆ≠ÁªÉÔºå‰æãÂ¶ÇÂèØ‰ª•ÂÖàËÆ≠ÁªÉ‰ªªÂä°Êé®Êñ≠Ê®°ÂûãÔºåÁÑ∂ÂêéÂÜçËÆ≠ÁªÉÁ≠ñÁï•‰ºòÂåñÊ®°Âûã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCRAFTÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰∏Ä‰∏™TransformerÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®ÁªìÊûÑ„ÄÇÁºñÁ†ÅÂô®Êé•Êî∂Áä∂ÊÄÅÂíåÂ•ñÂä±Â∫èÂàó‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂Â∞ÜÂÖ∂ÁºñÁ†ÅÊàê‰∏Ä‰∏™‰∏ä‰∏ãÊñáÂêëÈáèÔºåËØ•ÂêëÈáè‰ª£Ë°®‰∫ÜÂØπÂΩìÂâç‰ªªÂä°ÁöÑ‰ø°Âøµ„ÄÇËß£Á†ÅÂô®Êé•Êî∂ËØ•‰∏ä‰∏ãÊñáÂêëÈáèÔºåÂπ∂ËæìÂá∫‰∏Ä‰∏™‰ªªÂä°Ë°®Á§∫„ÄÇËØ•‰ªªÂä°Ë°®Á§∫ÂèØ‰ª•Ë¢´Áî®‰∫éÊåáÂØºÁ≠ñÁï•‰ºòÂåñ„ÄÇCRAFT‰ΩøÁî®ÊëäÈîÄÂèòÂàÜÊé®Êñ≠Êù•Êõ¥Êñ∞‰ø°ÂøµÔºå‰ªéËÄåÂÆûÁé∞ÂèØÊâ©Â±ïÁöÑ‰ø°ÂøµÊõ¥Êñ∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöCRAFTÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂÖ∂Êó†Âä®‰ΩúÁöÑ‰ªªÂä°Êé®Êñ≠ÊñπÊ≥ï„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåCRAFT‰∏çÈúÄË¶Å‰æùËµñÂä®‰Ωú‰ø°ÊÅØÔºå‰ªéËÄåÂÆûÁé∞‰∫Ü‰ªªÂä°Êé®Êñ≠‰∏éÁ≠ñÁï•‰ºòÂåñÁöÑËß£ËÄ¶„ÄÇËøôÁßçËß£ËÄ¶ÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÂíåÂèØÊâ©Â±ïÊÄß„ÄÇÊ≠§Â§ñÔºåCRAFTËøò‰ΩøÁî®‰∫ÜTransformerÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®ÁªìÊûÑÔºåÂèØ‰ª•ÊúâÊïàÂú∞ÊçïËé∑ÈïøÁ®ãÊó∂Èó¥‰æùËµñÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöCRAFTÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®ÊóãËΩ¨‰ΩçÁΩÆÂµåÂÖ•ÁöÑTransformerÁºñÁ†ÅÂô®-Ëß£Á†ÅÂô®Ôºå‰ª•ÊçïËé∑ÈïøÁ®ãÊó∂Èó¥‰æùËµñÊÄßÔºõ2) ‰ΩøÁî®ÊëäÈîÄÂèòÂàÜÊé®Êñ≠ËøõË°åÂèØÊâ©Â±ïÁöÑ‰ø°ÂøµÊõ¥Êñ∞Ôºõ3) ËÆæËÆ°ÊçüÂ§±ÂáΩÊï∞Ôºå‰ª•ÈºìÂä±Ê®°ÂûãÂ≠¶‰π†Âà∞È≤ÅÊ£íÁöÑ‰ªªÂä°Ë°®Á§∫„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÈáçÊûÑÊçüÂ§±ÂíåKLÊï£Â∫¶ÊçüÂ§±„ÄÇÈáçÊûÑÊçüÂ§±Áî®‰∫éÈºìÂä±Ê®°ÂûãËÉΩÂ§ü‰ªé‰ªªÂä°Ë°®Á§∫‰∏≠ÈáçÊûÑÂá∫ÂéüÂßãÁöÑÁä∂ÊÄÅÂíåÂ•ñÂä±Â∫èÂàóÔºåKLÊï£Â∫¶ÊçüÂ§±Áî®‰∫éÁ∫¶Êùü‰ªªÂä°Ë°®Á§∫ÁöÑÂàÜÂ∏É„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

CRAFTÂú®MetaWorld ML-10Êú∫Âô®‰∫∫Êìç‰ΩúÂü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰∏é‰∏ä‰∏ãÊñáËá™ÈÄÇÂ∫îÂÖÉÂº∫ÂåñÂ≠¶‰π†Âü∫Á∫øÁõ∏ÊØîÔºåÂÆûÁé∞‰∫ÜÊõ¥Âø´ÁöÑÈÄÇÂ∫îÈÄüÂ∫¶„ÄÅÊõ¥Â•ΩÁöÑÊ≥õÂåñËÉΩÂäõÂíåÊõ¥ÊúâÊïàÁöÑÊé¢Á¥¢„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜËÆ∫ÊñáÂº∫Ë∞É‰∫ÜCRAFTÂú®Â§ö‰∏™ÊåáÊ†á‰∏äÂùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

CRAFTÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êú∫Âô®‰∫∫ÊéßÂà∂„ÄÅÊ∏∏ÊàèAIÂíåËá™Âä®È©æÈ©∂Á≠â„ÄÇÈÄöËøáÂ≠¶‰π†‰ªÖÂü∫‰∫éÁä∂ÊÄÅÂíåÂ•ñÂä±ÁöÑ‰ªªÂä°Ë°®Á§∫ÔºåCRAFTÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫Âú®Êú™Áü•ÁöÑÁéØÂ¢É‰∏≠Âø´ÈÄüÈÄÇÂ∫îÂíåÂ≠¶‰π†Êñ∞ÁöÑ‰ªªÂä°„ÄÇËøôÂØπ‰∫éÈúÄË¶ÅÂú®Â§çÊùÇÂíåÂä®ÊÄÅÁéØÂ¢É‰∏≠ËøêË°åÁöÑÊú∫Âô®‰∫∫Êù•ËØ¥Â∞§ÂÖ∂ÈáçË¶Å„ÄÇÊ≠§Â§ñÔºåCRAFTÁöÑÊ®°ÂùóÂåñËÆæËÆ°‰πü‰ΩøÂÖ∂Êòì‰∫éÊâ©Â±ïÂà∞Êõ¥Â§çÊùÇÁöÑ‰ªªÂä°„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Reinforcement learning (RL) enables robots to operate in uncertain environments, but standard approaches often struggle with poor generalization to unseen tasks. Context-adaptive meta reinforcement learning addresses these limitations by conditioning on the task representation, yet they mostly rely on complete action information in the experience making task inference tightly coupled to a specific policy. This paper introduces Context Representation via Action Free Transformer encoder decoder (CRAFT), a belief model that infers task representations solely from sequences of states and rewards. By removing the dependence on actions, CRAFT decouples task inference from policy optimization, supports modular training, and leverages amortized variational inference for scalable belief updates. Built on a transformer encoder decoder with rotary positional embeddings, the model captures long range temporal dependencies and robustly encodes both parametric and non-parametric task variations. Experiments on the MetaWorld ML-10 robotic manipulation benchmark show that CRAFT achieves faster adaptation, improved generalization, and more effective exploration compared to context adaptive meta--RL baselines. These findings highlight the potential of action-free inference as a foundation for scalable RL in robotic control.

