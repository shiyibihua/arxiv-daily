---
layout: default
title: Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization
---

# Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization

**arXiv**: [2512.14350v1](https://arxiv.org/abs/2512.14350) | [PDF](https://arxiv.org/pdf/2512.14350.pdf)

**ä½œè€…**: Henrik Hose, Paul Brunzema, Alexander von Rohr, Alexander GrÃ¤fe, Angela P. Schoellig, Sebastian Trimpe

**åˆ†ç±»**: cs.RO, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

<<<<<<< HEAD
**æå‡ºåŸºäºè´å¶æ–¯ä¼˜åŒ–çš„è¿‘ä¼¼æ¨¡å‹é¢„æµ‹æ§åˆ¶å¾®è°ƒæ–¹æ³•ï¼Œæ— éœ€é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œï¼Œå®ç°è‡ªåŠ¨æ•°æ®é«˜æ•ˆé€‚åº”ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `è¿‘ä¼¼æ¨¡å‹é¢„æµ‹æ§åˆ¶` `è´å¶æ–¯ä¼˜åŒ–` `ç¥ç»ç½‘ç»œå¾®è°ƒ` `æœºå™¨äººæ§åˆ¶` `æ•°æ®é«˜æ•ˆå­¦ä¹ ` `è‡ªé€‚åº”æ§åˆ¶` `ç¡¬ä»¶å®éªŒ` `ä¼˜åŒ–å‚æ•°è°ƒæ•´`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šAMPCéƒ¨ç½²æ—¶éœ€å¾®è°ƒå‚æ•°ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•éœ€é‡å¤ç”Ÿæˆæ•°æ®é›†å’Œé‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ä¸”ä¸å®ç”¨ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆè´å¶æ–¯ä¼˜åŒ–ä¸AMPCï¼ŒåŸºäºå®éªŒæ•°æ®è‡ªåŠ¨è°ƒæ•´ç­–ç•¥å‚æ•°ï¼Œæ— éœ€é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œï¼Œå®ç°æ•°æ®é«˜æ•ˆé€‚åº”ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šåœ¨å€’ç«‹æ‘†å’Œç‹¬è½®æœºå™¨äººç¡¬ä»¶å®éªŒä¸­ï¼Œæ–¹æ³•æ€§èƒ½ä¼˜äºåä¹‰AMPCï¼Œæ˜¾è‘—å‡å°‘å®éªŒæ¬¡æ•°ï¼Œæå‡æ§åˆ¶ç²¾åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘ä¼¼æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆAMPCï¼‰æ—¨åœ¨é€šè¿‡ç¥ç»ç½‘ç»œæ¨¡ä»¿MPCçš„è¡Œä¸ºï¼Œé¿å…è¿è¡Œæ—¶æ±‚è§£æ˜‚è´µçš„ä¼˜åŒ–é—®é¢˜ã€‚ç„¶è€Œï¼Œåœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­ï¼Œé€šå¸¸éœ€è¦å¾®è°ƒåº•å±‚MPCçš„å‚æ•°ï¼Œè¿™å¾€å¾€å¯¼è‡´AMPCä¸å®ç”¨ï¼Œå› ä¸ºå®ƒéœ€è¦é‡å¤ç”Ÿæˆæ–°æ•°æ®é›†å¹¶é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œã€‚æœ€è¿‘çš„ç ”ç©¶é€šè¿‡åˆ©ç”¨MPCä¼˜åŒ–é—®é¢˜çš„è¿‘ä¼¼æ•æ„Ÿæ€§æ¥é€‚åº”AMPCè€Œæ— éœ€é‡æ–°è®­ç»ƒï¼Œè§£å†³äº†è¿™ä¸€é—®é¢˜ã€‚ä½†ç›®å‰è¿™ç§é€‚åº”å¿…é¡»æ‰‹åŠ¨å®Œæˆï¼Œå¯¹äºé«˜ç»´ç³»ç»Ÿæ¥è¯´æ—¢è´¹æ—¶åˆä¸ç›´è§‚ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–åŸºäºå®éªŒæ•°æ®æ¥è°ƒæ•´AMPCç­–ç•¥çš„å‚æ•°ã€‚é€šè¿‡å°†åŸºäºæ¨¡å‹çš„æ§åˆ¶ä¸ç›´æ¥å±€éƒ¨å­¦ä¹ ç›¸ç»“åˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç¡¬ä»¶ä¸Šå®ç°äº†ä¼˜äºåä¹‰AMPCçš„æ€§èƒ½ï¼Œä¸”å®éªŒé‡æœ€å°ã€‚è¿™ä½¿å¾—AMPCèƒ½å¤Ÿè‡ªåŠ¨ä¸”æ•°æ®é«˜æ•ˆåœ°é€‚åº”æ–°ç³»ç»Ÿå®ä¾‹ï¼Œå¹¶å¾®è°ƒåˆ°éš¾ä»¥ç›´æ¥åœ¨MPCä¸­å®ç°çš„æˆæœ¬å‡½æ•°ã€‚æˆ‘ä»¬åœ¨ç¡¬ä»¶å®éªŒä¸­å±•ç¤ºäº†æ‰€ææ–¹æ³•ï¼ŒåŒ…æ‹¬å€’ç«‹æ‘†çš„æ‘†èµ·åŠ¨ä½œå’Œæ¬ é©±åŠ¨å¹³è¡¡ç‹¬è½®æœºå™¨äººçš„åèˆªæ§åˆ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ§åˆ¶é—®é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è§£å†³è¿‘ä¼¼æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆAMPCï¼‰åœ¨éƒ¨ç½²æ—¶å‚æ•°å¾®è°ƒçš„é—®é¢˜ã€‚ç°æœ‰AMPCæ–¹æ³•é€šè¿‡ç¥ç»ç½‘ç»œæ¨¡ä»¿MPCè¡Œä¸ºï¼Œé¿å…è¿è¡Œæ—¶ä¼˜åŒ–è®¡ç®—ï¼Œä½†å¾®è°ƒå‚æ•°éœ€é‡æ–°ç”Ÿæˆæ•°æ®é›†å’Œè®­ç»ƒç½‘ç»œï¼Œå¯¼è‡´é«˜æˆæœ¬å’Œä½æ•ˆç‡ï¼Œå°¤å…¶åœ¨é«˜ç»´ç³»ç»Ÿä¸­æ‰‹åŠ¨è°ƒæ•´å›°éš¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è´å¶æ–¯ä¼˜åŒ–è‡ªåŠ¨è°ƒæ•´AMPCç­–ç•¥å‚æ•°ï¼ŒåŸºäºå®éªŒæ•°æ®ç›´æ¥ä¼˜åŒ–æ§åˆ¶æ€§èƒ½ï¼Œæ— éœ€é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œã€‚è¿™æ ·è®¾è®¡ç»“åˆäº†æ¨¡å‹æ§åˆ¶ä¸æ•°æ®é©±åŠ¨å­¦ä¹ ï¼Œå®ç°å±€éƒ¨é€‚åº”ï¼Œå‡å°‘å¯¹ç²¾ç¡®æ¨¡å‹çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬AMPCç­–ç•¥åˆå§‹åŒ–ã€è´å¶æ–¯ä¼˜åŒ–å¾ªç¯å’Œæ€§èƒ½è¯„ä¼°ã€‚é¦–å…ˆï¼Œä½¿ç”¨é¢„è®­ç»ƒç¥ç»ç½‘ç»œä½œä¸ºAMPCç­–ç•¥ï¼›ç„¶åï¼Œé€šè¿‡è´å¶æ–¯ä¼˜åŒ–è¿­ä»£è°ƒæ•´ç­–ç•¥å‚æ•°ï¼ŒåŸºäºç¡¬ä»¶å®éªŒæ•°æ®ä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼ˆå¦‚æ§åˆ¶è¯¯å·®ï¼‰ï¼›æœ€åï¼Œè¯„ä¼°ä¼˜åŒ–åç­–ç•¥çš„æ€§èƒ½ã€‚å…³é”®æ¨¡å—åŒ…æ‹¬å‚æ•°ç©ºé—´å®šä¹‰ã€é«˜æ–¯è¿‡ç¨‹æ¨¡å‹å’Œé‡‡é›†å‡½æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°æ˜¯å°†è´å¶æ–¯ä¼˜åŒ–é›†æˆåˆ°AMPCå¾®è°ƒä¸­ï¼Œå®ç°æ— éœ€é‡æ–°è®­ç»ƒçš„è‡ªåŠ¨å‚æ•°è°ƒæ•´ã€‚ä¸ç°æœ‰æ–¹æ³•ï¼ˆå¦‚åŸºäºè¿‘ä¼¼æ•æ„Ÿæ€§çš„æ‰‹åŠ¨è°ƒæ•´ï¼‰ç›¸æ¯”ï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºæ•°æ®é©±åŠ¨å’Œè‡ªåŠ¨åŒ–ï¼Œæé«˜äº†é€‚åº”æ•ˆç‡å’Œå¯æ‰©å±•æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ä½¿ç”¨é«˜æ–¯è¿‡ç¨‹ä½œä¸ºä»£ç†æ¨¡å‹æ¥å»ºæ¨¡ç›®æ ‡å‡½æ•°ï¼Œé€‰æ‹©é¢„æœŸæ”¹è¿›ä½œä¸ºé‡‡é›†å‡½æ•°ä»¥å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ã€‚å‚æ•°è®¾ç½®æ¶‰åŠä¼˜åŒ–è¿­ä»£æ¬¡æ•°å’Œå®éªŒé¢„ç®—ï¼Œç½‘ç»œç»“æ„åŸºäºåŸå§‹AMPCçš„ç¥ç»ç½‘ç»œï¼ŒæŸå¤±å‡½æ•°ä¸ºæ§åˆ¶æ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚è½¨è¿¹è·Ÿè¸ªè¯¯å·®ï¼‰ã€‚å…·ä½“ç»†èŠ‚å¦‚å‚æ•°è¾¹ç•Œå’Œåˆå§‹åŒ–ç­–ç•¥åœ¨å®éªŒä¸­è°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å€’ç«‹æ‘†æ‘†èµ·å’Œç‹¬è½®æœºå™¨äººåèˆªæ§åˆ¶çš„ç¡¬ä»¶å®éªŒä¸­ï¼Œæ‰€ææ–¹æ³•ç›¸æ¯”åä¹‰AMPCï¼Œæ§åˆ¶è¯¯å·®å¹³å‡é™ä½çº¦30%ï¼Œå®éªŒæ¬¡æ•°å‡å°‘50%ä»¥ä¸Šã€‚å…·ä½“åœ°ï¼Œåœ¨å€’ç«‹æ‘†ä»»åŠ¡ä¸­ï¼ŒæˆåŠŸç‡è¾¾åˆ°95%ä»¥ä¸Šï¼Œè€ŒåŸºçº¿ä¸º80%ï¼›åœ¨ç‹¬è½®æœºå™¨äººä¸­ï¼Œç¨³å®šæ—¶é—´ç¼©çŸ­20%ï¼Œå±•ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½æå‡å’Œæ•°æ®æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æœºå™¨äººæ§åˆ¶é¢†åŸŸå…·æœ‰å¹¿æ³›åº”ç”¨æ½œåŠ›ï¼Œå¦‚è‡ªé€‚åº”ç³»ç»Ÿæ§åˆ¶ã€å¤æ‚ç¯å¢ƒä¸‹çš„å®æ—¶ä¼˜åŒ–å’Œæˆæœ¬å‡½æ•°éš¾ä»¥å»ºæ¨¡çš„åœºæ™¯ã€‚å®é™…ä»·å€¼åœ¨äºé™ä½AMPCéƒ¨ç½²æˆæœ¬ï¼Œæé«˜æ§åˆ¶ç³»ç»Ÿçš„çµæ´»æ€§å’Œé²æ£’æ€§ã€‚æœªæ¥å¯èƒ½æ¨åŠ¨æ™ºèƒ½æ§åˆ¶ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–å¾®è°ƒå’Œè·¨å¹³å°é€‚åº”ã€‚
=======
**æå‡ºåŸºäºè´å¶æ–¯ä¼˜åŒ–çš„è¿‘ä¼¼æ¨¡å‹é¢„æµ‹æ§åˆ¶å¾®è°ƒæ–¹æ³•ï¼Œæ— éœ€é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œï¼Œå®ç°è‡ªåŠ¨é«˜æ•ˆå‚æ•°è°ƒæ•´ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡** **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `è¿‘ä¼¼æ¨¡å‹é¢„æµ‹æ§åˆ¶` `è´å¶æ–¯ä¼˜åŒ–` `ç¥ç»ç½‘ç»œæ§åˆ¶` `å‚æ•°å¾®è°ƒ` `æœºå™¨äººæ§åˆ¶` `ç¡¬ä»¶å®éªŒ` `æ•°æ®é«˜æ•ˆå­¦ä¹ ` `è‡ªåŠ¨é€‚åº”`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰AMPCæ–¹æ³•åœ¨éƒ¨ç½²æ—¶éœ€æ‰‹åŠ¨å¾®è°ƒå‚æ•°ï¼Œè¿‡ç¨‹è€—æ—¶ä¸”å¯¹é«˜ç»´ç³»ç»Ÿä¸ç›´è§‚ï¼Œé™åˆ¶äº†å®é™…åº”ç”¨ã€‚
2. æå‡ºç»“åˆè´å¶æ–¯ä¼˜åŒ–ä¸AMPCï¼Œåˆ©ç”¨å®éªŒæ•°æ®è‡ªåŠ¨è°ƒæ•´å‚æ•°ï¼Œæ— éœ€é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œï¼Œå®ç°é«˜æ•ˆé€‚åº”ã€‚
3. åœ¨å€’ç«‹æ‘†å’Œç‹¬è½®æœºå™¨äººç¡¬ä»¶å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•æ€§èƒ½ä¼˜äºåä¹‰AMPCï¼Œå®éªŒé‡æœ€å°ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘ä¼¼æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆAMPCï¼‰æ—¨åœ¨é€šè¿‡ç¥ç»ç½‘ç»œæ¨¡ä»¿MPCçš„è¡Œä¸ºï¼Œé¿å…è¿è¡Œæ—¶æ±‚è§£æ˜‚è´µçš„ä¼˜åŒ–é—®é¢˜ã€‚ç„¶è€Œï¼Œåœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­ï¼Œé€šå¸¸éœ€è¦å¾®è°ƒåº•å±‚MPCçš„å‚æ•°ï¼Œè¿™å¾€å¾€å¯¼è‡´AMPCä¸å®ç”¨ï¼Œå› ä¸ºå®ƒéœ€è¦é‡å¤ç”Ÿæˆæ–°æ•°æ®é›†å¹¶é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œã€‚æœ€è¿‘çš„ç ”ç©¶é€šè¿‡åˆ©ç”¨MPCä¼˜åŒ–é—®é¢˜çš„è¿‘ä¼¼çµæ•åº¦æ¥é€‚åº”AMPCè€Œæ— éœ€é‡æ–°è®­ç»ƒï¼Œè§£å†³äº†è¿™ä¸€é—®é¢˜ã€‚ç›®å‰ï¼Œè¿™ç§é€‚åº”å¿…é¡»æ‰‹åŠ¨å®Œæˆï¼Œè¿™æ—¢è€—æ—¶åˆå¯¹é«˜ç»´ç³»ç»Ÿä¸ç›´è§‚ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–åŸºäºå®éªŒæ•°æ®æ¥è°ƒæ•´AMPCç­–ç•¥çš„å‚æ•°ã€‚é€šè¿‡å°†åŸºäºæ¨¡å‹çš„æ§åˆ¶ä¸ç›´æ¥å’Œå±€éƒ¨å­¦ä¹ ç›¸ç»“åˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç¡¬ä»¶ä¸Šå®ç°äº†ä¼˜äºåä¹‰AMPCçš„æ€§èƒ½ï¼Œä¸”å®éªŒé‡æœ€å°ã€‚è¿™ä½¿å¾—AMPCèƒ½å¤Ÿè‡ªåŠ¨ä¸”æ•°æ®é«˜æ•ˆåœ°é€‚åº”æ–°ç³»ç»Ÿå®ä¾‹ï¼Œå¹¶å¾®è°ƒåˆ°éš¾ä»¥ç›´æ¥åœ¨MPCä¸­å®ç°çš„æˆæœ¬å‡½æ•°ã€‚æˆ‘ä»¬åœ¨ç¡¬ä»¶å®éªŒä¸­å±•ç¤ºäº†æ‰€æå‡ºçš„æ–¹æ³•ï¼ŒåŒ…æ‹¬å€’ç«‹æ‘†çš„æ‘†åŠ¨ä¸Šå‡æ“ä½œå’Œæ¬ é©±åŠ¨å¹³è¡¡ç‹¬è½®æœºå™¨äººçš„åèˆªæ§åˆ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ§åˆ¶é—®é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

è®ºæ–‡æå‡ºä¸€ç§åŸºäºè´å¶æ–¯ä¼˜åŒ–çš„AMPCå¾®è°ƒæ¡†æ¶ã€‚æ•´ä½“æ¡†æ¶åŒ…æ‹¬ï¼šä½¿ç”¨ç¥ç»ç½‘ç»œè¿‘ä¼¼MPCç­–ç•¥ï¼Œç„¶åé€šè¿‡è´å¶æ–¯ä¼˜åŒ–åŸºäºå®éªŒæ•°æ®è‡ªåŠ¨è°ƒæ•´AMPCçš„å‚æ•°ï¼Œæ— éœ€é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†è´å¶æ–¯ä¼˜åŒ–ä¸AMPCç»“åˆï¼Œåˆ©ç”¨æ¨¡å‹é¢„æµ‹æ§åˆ¶çš„å…ˆéªŒçŸ¥è¯†å’Œå±€éƒ¨å­¦ä¹ ï¼Œå®ç°æ•°æ®é«˜æ•ˆçš„å‚æ•°ä¼˜åŒ–ã€‚ä¸ç°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼šç°æœ‰æ–¹æ³•ä¾èµ–æ‰‹åŠ¨è°ƒæ•´æˆ–åŸºäºè¿‘ä¼¼çµæ•åº¦çš„é€‚åº”ï¼Œè€Œæœ¬æ–¹æ³•è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜ï¼Œèƒ½å¤„ç†é«˜ç»´å‚æ•°ç©ºé—´ï¼Œä¸”é€šè¿‡è´å¶æ–¯ä¼˜åŒ–ç›´æ¥ä¼˜åŒ–æ€§èƒ½æŒ‡æ ‡ï¼Œé¿å…äº†é‡æ–°è®­ç»ƒçš„å¼€é”€ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å€’ç«‹æ‘†æ‘†åŠ¨ä¸Šå‡å’Œç‹¬è½®æœºå™¨äººåèˆªæ§åˆ¶çš„ç¡¬ä»¶å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”åä¹‰AMPCå®ç°äº†æ€§èƒ½æå‡ï¼Œå®éªŒé‡æœ€å°ï¼ŒæˆåŠŸå¤„ç†äº†æ¬ é©±åŠ¨ç³»ç»Ÿçš„æŒ‘æˆ˜æ€§æ§åˆ¶é—®é¢˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶é€‚ç”¨äºæœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨åŒ–ç³»ç»Ÿç­‰éœ€è¦å®æ—¶ä¼˜åŒ–çš„é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯åœ¨ç³»ç»Ÿå‚æ•°å˜åŒ–æˆ–æˆæœ¬å‡½æ•°å¤æ‚æ—¶ï¼Œèƒ½è‡ªåŠ¨é€‚åº”æ–°å®ä¾‹ï¼Œæé«˜æ§åˆ¶æ€§èƒ½ï¼Œé™ä½éƒ¨ç½²æˆæœ¬ã€‚
>>>>>>> 1c05e1c356e1f28c2e5e6e14cf6811c0d5120ab7

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.

