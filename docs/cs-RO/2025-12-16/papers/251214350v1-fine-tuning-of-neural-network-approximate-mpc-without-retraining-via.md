---
layout: default
title: Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization
---

# Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.14350" target="_blank" class="toolbar-btn">arXiv: 2512.14350v1</a>
    <a href="https://arxiv.org/pdf/2512.14350.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14350v1" 
            onclick="toggleFavorite(this, '2512.14350v1', 'Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Henrik Hose, Paul Brunzema, Alexander von Rohr, Alexander Gr√§fe, Angela P. Schoellig, Sebastian Trimpe

**ÂàÜÁ±ª**: cs.RO, eess.SY

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-16

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éË¥ùÂè∂ÊñØ‰ºòÂåñÁöÑAMPCË∞ÉÂèÇÊñπÊ≥ïÔºåÊó†ÈúÄÈáçËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªú**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `Ëøë‰ººÊ®°ÂûãÈ¢ÑÊµãÊéßÂà∂` `Ë¥ùÂè∂ÊñØ‰ºòÂåñ` `Á•ûÁªèÁΩëÁªú` `ÂèÇÊï∞Ë∞É‰ºò` `Êú∫Âô®‰∫∫ÊéßÂà∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰º†ÁªüAMPCÂú®MPCÂèÇÊï∞Ë∞ÉÊï¥ÂêéÈúÄÈáçÊñ∞ËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªúÔºåËÄóÊó∂‰∏î‰ΩéÊïàÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÈÉ®ÁΩ≤‰∏≠ÁöÑÂ∫îÁî®„ÄÇ
2. Âà©Áî®Ë¥ùÂè∂ÊñØ‰ºòÂåñËá™Âä®Ë∞ÉÊï¥AMPCÁ≠ñÁï•ÂèÇÊï∞ÔºåÁªìÂêàÊ®°ÂûãÊéßÂà∂‰∏éÂ±ÄÈÉ®Â≠¶‰π†ÔºåÂÆûÁé∞Êï∞ÊçÆÈ´òÊïàÁöÑÂèÇÊï∞‰ºòÂåñ„ÄÇ
3. Á°¨‰ª∂ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®ÂÄíÁ´ãÊëÜÂíåÂπ≥Ë°°Áã¨ËΩÆËΩ¶ÊéßÂà∂‰∏ä‰ºò‰∫é‰º†ÁªüAMPCÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ëøë‰ººÊ®°ÂûãÈ¢ÑÊµãÊéßÂà∂(AMPC)Êó®Âú®Áî®Á•ûÁªèÁΩëÁªúÊ®°‰ªøMPCÁöÑË°å‰∏∫Ôºå‰ªéËÄåÈÅøÂÖçÂú®ËøêË°åÊó∂Ê±ÇËß£ÊòÇË¥µÁöÑ‰ºòÂåñÈóÆÈ¢ò„ÄÇÁÑ∂ËÄåÔºåÂú®ÈÉ®ÁΩ≤ÊúüÈó¥ÔºåÈÄöÂ∏∏ÈúÄË¶ÅÂØπÂ∫ïÂ±ÇMPCÁöÑÂèÇÊï∞ËøõË°åÂæÆË∞É„ÄÇËøô‰ΩøÂæóAMPCÂú®ÂÆûË∑µ‰∏≠ÂèòÂæó‰∏çÂàáÂÆûÈôÖÔºåÂõ†‰∏∫ÂÆÉÈúÄË¶ÅÈáçÂ§çÁîüÊàêÊñ∞ÁöÑÊï∞ÊçÆÈõÜÂπ∂ÈáçÊñ∞ËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªú„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÈÄöËøá‰ΩøÁî®MPC‰ºòÂåñÈóÆÈ¢òÁöÑËøë‰ººÊïèÊÑüÊÄßÊù•Ë∞ÉÊï¥AMPCÔºåËÄåÊó†ÈúÄÈáçÊñ∞ËÆ≠ÁªÉ„ÄÇÁõÆÂâçÔºåËøôÁßçË∞ÉÊï¥ÂøÖÈ°ªÊâãÂä®ÂÆåÊàêÔºåËøôÊó¢Ë¥πÂäõÔºåÂØπ‰∫éÈ´òÁª¥Á≥ªÁªüÊù•ËØ¥‰πüÂèØËÉΩ‰∏çÁõ¥ËßÇ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰ΩøÁî®Ë¥ùÂè∂ÊñØ‰ºòÂåñÊù•Ê†πÊçÆÂÆûÈ™åÊï∞ÊçÆË∞ÉÊï¥AMPCÁ≠ñÁï•ÁöÑÂèÇÊï∞„ÄÇÈÄöËøáÂ∞ÜÂü∫‰∫éÊ®°ÂûãÁöÑÊéßÂà∂‰∏éÁõ¥Êé•ÂíåÂ±ÄÈÉ®Â≠¶‰π†Áõ∏ÁªìÂêàÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Á°¨‰ª∂‰∏äÂÆûÁé∞‰∫Ü‰ºò‰∫éÊ†áÁß∞AMPCÁöÑÊÄßËÉΩÔºåÂπ∂‰∏îÂè™ÈúÄÊúÄÂ∞ëÁöÑÂÆûÈ™å„ÄÇËøôÂÖÅËÆ∏AMPCËá™Âä®‰∏îÊï∞ÊçÆÈ´òÊïàÂú∞ÈÄÇÂ∫îÊñ∞ÁöÑÁ≥ªÁªüÂÆû‰æãÔºåÂπ∂ÂæÆË∞ÉÈöæ‰ª•Áõ¥Êé•Âú®MPC‰∏≠ÂÆûÁé∞ÁöÑÊàêÊú¨ÂáΩÊï∞„ÄÇÊàë‰ª¨Âú®ÂÄíÁ´ãÊëÜÂ∞èËΩ¶‰∏äÁöÑÊëÜÂä®Êìç‰ΩúÂíåÊ¨†È©±Âä®Âπ≥Ë°°Áã¨ËΩÆËΩ¶Êú∫Âô®‰∫∫ÁöÑÂÅèËà™ÊéßÂà∂Ôºà‰∏Ä‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊéßÂà∂ÈóÆÈ¢òÔºâÁöÑÁ°¨‰ª∂ÂÆûÈ™å‰∏≠Â±ïÁ§∫‰∫ÜÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑËøë‰ººÊ®°ÂûãÈ¢ÑÊµãÊéßÂà∂(AMPC)ÊñπÊ≥ïÂú®ÂÆûÈôÖÈÉ®ÁΩ≤‰∏≠ÔºåÂΩìÂ∫ïÂ±ÇMPCÁöÑÂèÇÊï∞ÈúÄË¶ÅË∞ÉÊï¥Êó∂ÔºåÈúÄË¶ÅÈáçÊñ∞ÁîüÊàêÊï∞ÊçÆÈõÜÂπ∂ÈáçÊñ∞ËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªúÔºåËøô‰ΩøÂæóAMPCÁöÑÈÉ®ÁΩ≤ÂíåÁª¥Êä§ÊàêÊú¨ÂæàÈ´òÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®ËåÉÂõ¥„ÄÇÊâãÂä®Ë∞ÉÊï¥AMPCÁ≠ñÁï•ÂèÇÊï∞Êó¢Ë¥πÊó∂ÂèàÂÆπÊòìÂá∫ÈîôÔºåÂ∞§ÂÖ∂ÊòØÂú®È´òÁª¥Á≥ªÁªü‰∏≠„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Ë¥ùÂè∂ÊñØ‰ºòÂåñ(Bayesian Optimization)Êù•Ëá™Âä®Ë∞ÉÊï¥AMPCÁ≠ñÁï•ÁöÑÂèÇÊï∞ÔºåËÄåÊó†ÈúÄÈáçÊñ∞ËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªú„ÄÇË¥ùÂè∂ÊñØ‰ºòÂåñÊòØ‰∏ÄÁßçÈ´òÊïàÁöÑÂÖ®Â±Ä‰ºòÂåñÁÆóÊ≥ïÔºåÁâπÂà´ÈÄÇÁî®‰∫éÁõÆÊ†áÂáΩÊï∞ËØÑ‰º∞ÊàêÊú¨È´òÊòÇÁöÑÊÉÖÂÜµ„ÄÇÈÄöËøáÂ∞ÜÊ®°ÂûãÈ¢ÑÊµãÊéßÂà∂‰∏éÁõ¥Êé•ÂíåÂ±ÄÈÉ®Â≠¶‰π†Áõ∏ÁªìÂêàÔºåÂèØ‰ª•ÂÆûÁé∞Êï∞ÊçÆÈ´òÊïàÁöÑÂèÇÊï∞Ë∞ÉÊï¥„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ïÁöÑÊäÄÊúØÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™Ê≠•È™§Ôºö1) ÂàùÂßãÂåñAMPCÁ≠ñÁï•Ôºõ2) Âú®ÂÆûÈôÖÁ≥ªÁªü‰∏≠ËøêË°åAMPCÁ≠ñÁï•Âπ∂Êî∂ÈõÜÂÆûÈ™åÊï∞ÊçÆÔºõ3) ‰ΩøÁî®ÂÆûÈ™åÊï∞ÊçÆÊûÑÂª∫ÁõÆÊ†áÂáΩÊï∞ÔºåËØ•ÁõÆÊ†áÂáΩÊï∞ÂèçÊò†‰∫ÜAMPCÁ≠ñÁï•ÁöÑÊÄßËÉΩÔºõ4) ‰ΩøÁî®Ë¥ùÂè∂ÊñØ‰ºòÂåñÁÆóÊ≥ï‰ºòÂåñAMPCÁ≠ñÁï•ÁöÑÂèÇÊï∞Ôºå‰ª•ÊúÄÂ§ßÂåñÁõÆÊ†áÂáΩÊï∞Ôºõ5) ÈáçÂ§çÊ≠•È™§2-4ÔºåÁõ¥Âà∞AMPCÁ≠ñÁï•ÁöÑÊÄßËÉΩËææÂà∞ÊúüÊúõÊ∞¥Âπ≥„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜË¥ùÂè∂ÊñØ‰ºòÂåñÂ∫îÁî®‰∫éAMPCÁ≠ñÁï•ÁöÑÂèÇÊï∞Ë∞ÉÊï¥Ôºå‰ªéËÄåÂÆûÁé∞‰∫ÜËá™Âä®„ÄÅÊï∞ÊçÆÈ´òÊïàÁöÑÂèÇÊï∞‰ºòÂåñÔºåÈÅøÂÖç‰∫ÜÈáçÊñ∞ËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªúÁöÑÈúÄË¶Å„ÄÇ‰∏éÊâãÂä®Ë∞ÉÊï¥ÂèÇÊï∞Áõ∏ÊØîÔºåË¥ùÂè∂ÊñØ‰ºòÂåñÂèØ‰ª•Êõ¥ÊúâÊïàÂú∞Êé¢Á¥¢ÂèÇÊï∞Á©∫Èó¥ÔºåÊâæÂà∞Êõ¥‰ºòÁöÑÂèÇÊï∞ÁªÑÂêà„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÁªìÂêà‰∫ÜÊ®°ÂûãÈ¢ÑÊµãÊéßÂà∂ÂíåÁõ¥Êé•Â≠¶‰π†ÔºåÂèØ‰ª•ÂÖÖÂàÜÂà©Áî®ÂÖàÈ™åÁü•ËØÜÂíåÂÆûÈ™åÊï∞ÊçÆ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ë¥ùÂè∂ÊñØ‰ºòÂåñ‰∏≠ÔºåÈúÄË¶ÅÈÄâÊã©ÂêàÈÄÇÁöÑ‰ª£ÁêÜÊ®°Âûã(surrogate model)ÂíåÈááÈõÜÂáΩÊï∞(acquisition function)„ÄÇÊú¨ÊñáÂèØËÉΩÈááÁî®‰∫ÜÈ´òÊñØËøáÁ®ã(Gaussian Process)‰Ωú‰∏∫‰ª£ÁêÜÊ®°ÂûãÔºåÂπ∂‰ΩøÁî®ÊúüÊúõÊèêÂçá(Expected Improvement)ÊàñÁΩÆ‰ø°‰∏äÈôê(Upper Confidence Bound)‰Ωú‰∏∫ÈááÈõÜÂáΩÊï∞„ÄÇÁõÆÊ†áÂáΩÊï∞ÁöÑËÆæËÆ°ÈúÄË¶ÅÊ†πÊçÆÂÖ∑‰ΩìÁöÑÊéßÂà∂‰ªªÂä°ËøõË°åË∞ÉÊï¥Ôºå‰æãÂ¶ÇÔºåÂèØ‰ª•ÈááÁî®Ë∑üË∏™ËØØÂ∑Æ„ÄÅÊéßÂà∂ËæìÂÖ•ËÉΩÈáèÁ≠âÊåáÊ†á„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËØ•ËÆ∫ÊñáÂú®ÂÄíÁ´ãÊëÜÂ∞èËΩ¶ÂíåÂπ≥Ë°°Áã¨ËΩÆËΩ¶ÁöÑÁ°¨‰ª∂ÂÆûÈ™å‰∏≠È™åËØÅ‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Á°¨‰ª∂‰∏äÂÆûÁé∞‰∫Ü‰ºò‰∫éÊ†áÁß∞AMPCÁöÑÊÄßËÉΩÔºåÂπ∂‰∏îÂè™ÈúÄÊúÄÂ∞ëÁöÑÂÆûÈ™å„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üËá™Âä®Ë∞ÉÊï¥AMPCÁ≠ñÁï•ÁöÑÂèÇÊï∞Ôºå‰ΩøÂÖ∂ÈÄÇÂ∫îÊñ∞ÁöÑÁ≥ªÁªüÂÆû‰æãÔºåÂπ∂ÂæÆË∞ÉÈöæ‰ª•Áõ¥Êé•Âú®MPC‰∏≠ÂÆûÁé∞ÁöÑÊàêÊú¨ÂáΩÊï∞„ÄÇËøô‰∫õÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂÖ∑ÊúâÂæàÂº∫ÁöÑÂÆûÁî®‰ª∑ÂÄº„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÊéßÂà∂„ÄÅËá™Âä®È©æÈ©∂„ÄÅËøáÁ®ãÊéßÂà∂Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáËá™Âä®Ë∞ÉÊï¥AMPCÁ≠ñÁï•ÂèÇÊï∞ÔºåÂèØ‰ª•‰ΩøÁ≥ªÁªüÂø´ÈÄüÈÄÇÂ∫îÊñ∞ÁöÑÁéØÂ¢ÉÂíå‰ªªÂä°ÔºåÊèêÈ´òÊéßÂà∂ÊÄßËÉΩÂíåÈ≤ÅÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Áî®‰∫éÂæÆË∞ÉÈöæ‰ª•Áõ¥Êé•Âú®MPC‰∏≠ÂÆûÁé∞ÁöÑÊàêÊú¨ÂáΩÊï∞Ôºå‰æãÂ¶ÇÔºåËÄÉËôëËÉΩËÄó„ÄÅÁ£®ÊçüÁ≠âÂõ†Á¥†ÁöÑÊàêÊú¨ÂáΩÊï∞„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÂ∫îÁî®‰∫éÊõ¥Â§çÊùÇÁöÑÊéßÂà∂Á≥ªÁªüÔºå‰æãÂ¶ÇÔºåÂ§öÊú∫Âô®‰∫∫ÂçèÂêåÊéßÂà∂„ÄÅÊô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªüÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.

