---
layout: default
title: CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth
---

# CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.14001" target="_blank" class="toolbar-btn">arXiv: 2512.14001v1</a>
    <a href="https://arxiv.org/pdf/2512.14001.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14001v1" 
            onclick="toggleFavorite(this, '2512.14001v1', 'CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Zhuo Zhang, Yonghui Liu, Meijie Zhang, Feiyang Tan, Yikang Ding

**ÂàÜÁ±ª**: cs.RO, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-16

**Â§áÊ≥®**: Accepted by IROS 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/Tompson11/claim)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫CLAIMÔºö‰∏ÄÁßçÂà©Áî®ÂçïÁõÆÊ∑±Â∫¶ÂíåÂº∫Â∫¶‰ø°ÊÅØÁöÑÁõ∏Êú∫-ÊøÄÂÖâÈõ∑ËææÊ†áÂÆöÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)** **ÊîØÊü±ÂÖ≠ÔºöËßÜÈ¢ëÊèêÂèñ‰∏éÂåπÈÖç (Video Extraction & Matching)**

**ÂÖ≥ÈîÆËØç**: `Áõ∏Êú∫-ÊøÄÂÖâÈõ∑ËææÊ†áÂÆö` `ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°` `‰º†ÊÑüÂô®ËûçÂêà` `ÁªìÊûÑÊçüÂ§±` `‰∫í‰ø°ÊÅØ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁõ∏Êú∫-ÊøÄÂÖâÈõ∑ËææÊ†áÂÆöÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñÂ§çÊùÇÁöÑÊï∞ÊçÆÂ§ÑÁêÜÂíåÁâπÂæÅÂåπÈÖçÔºåËÆ°ÁÆóÊàêÊú¨È´ò‰∏îÈ≤ÅÊ£íÊÄßÊúâÈôê„ÄÇ
2. CLAIMÂà©Áî®ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÁöÑÁªìÊûÑ‰ø°ÊÅØÂíåÂõæÂÉèÁ∫πÁêÜ‰ø°ÊÅØÔºåËÆæËÆ°‰∫Ü‰∏ÄÁßçÂü∫‰∫éÁõ∏ÂÖ≥ÊÄßÂíå‰∫í‰ø°ÊÅØÁöÑÊçüÂ§±ÂáΩÊï∞ÔºåÂÆûÁé∞È´òÊïàÊ†áÂÆö„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåCLAIMÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏ä‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÊó†ÈúÄÂ§çÊùÇÁöÑÈ¢ÑÂ§ÑÁêÜÔºåÂÖ∑ÊúâËâØÂ•ΩÁöÑÈÄöÁî®ÊÄßÂíåÁ≤æÂ∫¶„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊó®Âú®Êé¢Á¥¢ÂçïÁõÆÊ∑±Â∫¶Ê®°ÂûãÂú®Áõ∏Êú∫-ÊøÄÂÖâÈõ∑ËææÊ†áÂÆö‰∏≠ÁöÑÊΩúÂäõÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÁõ∏Êú∫‰∏éÊøÄÂÖâÈõ∑ËææÊï∞ÊçÆÂØπÈΩêÊñπÊ≥ïCLAIM„ÄÇÁªôÂÆöÂàùÂßã‰ΩçÂßø‰º∞ËÆ°‰ª•ÂèäÂõæÂÉèÂíåÊøÄÂÖâÈõ∑ËææÁÇπ‰∫ëÂØπÔºåCLAIMÈááÁî®Áî±Á≤óÂà∞Á≤æÁöÑÊêúÁ¥¢Á≠ñÁï•ÔºåÂØªÊâæÊúÄ‰ºòÂèòÊç¢Ôºå‰ª•ÊúÄÂ∞èÂåñÂü∫‰∫éÂàÜÂùóÁöÆÂ∞îÈÄäÁõ∏ÂÖ≥ÁöÑÁªìÊûÑÊçüÂ§±ÂíåÂü∫‰∫é‰∫í‰ø°ÊÅØÁöÑÁ∫πÁêÜÊçüÂ§±„ÄÇËøô‰∏§ÁßçÊçüÂ§±ÂáΩÊï∞‰∏∫Áõ∏Êú∫-ÊøÄÂÖâÈõ∑ËææÂØπÈΩêÁªìÊûúÊèê‰æõ‰∫ÜËâØÂ•ΩÁöÑÂ∫¶ÈáèÊ†áÂáÜÔºåÊó†ÈúÄÂ§çÊùÇÁöÑÊï∞ÊçÆÂ§ÑÁêÜ„ÄÅÁâπÂæÅÊèêÂèñÊàñÁâπÂæÅÂåπÈÖçÊ≠•È™§Ôºå‰ΩøÂæóÊàë‰ª¨ÁöÑÊñπÊ≥ïÁÆÄÂçï‰∏îÈÄÇÁî®‰∫éÂ§ßÂ§öÊï∞Âú∫ÊôØ„ÄÇÊàë‰ª¨Âú®ÂÖ¨ÂºÄÁöÑKITTI„ÄÅWaymoÂíåMIAS-LCECÊï∞ÊçÆÈõÜ‰∏äÈ™åËØÅ‰∫ÜCLAIMÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéÂÖ∂ÊÄßËÉΩ‰ºò‰∫éÂΩìÂâçÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇ‰ª£Á†ÅÂ∑≤ÂºÄÊ∫ê„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁõ∏Êú∫-ÊøÄÂÖâÈõ∑ËææÊ†áÂÆöÊó®Âú®Á°ÆÂÆöÁõ∏Êú∫ÂíåÊøÄÂÖâÈõ∑Ëææ‰πãÈó¥ÁöÑÂ§ñÈÉ®ÂèÇÊï∞ÔºàÊóãËΩ¨ÂíåÂπ≥ÁßªÔºâÔºå‰ªéËÄåÂ∞Ü‰∏§Áßç‰º†ÊÑüÂô®ÁöÑÊï∞ÊçÆËûçÂêàÂà∞Âêå‰∏ÄÂùêÊ†áÁ≥ª‰∏ã„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÊâãÂ∑•ËÆæËÆ°ÁöÑÁâπÂæÅÊàñÂ§çÊùÇÁöÑÁâπÂæÅÂåπÈÖçÁÆóÊ≥ïÔºåËøô‰∫õÊñπÊ≥ïÂØπÁéØÂ¢ÉÂèòÂåñÊïèÊÑüÔºå‰∏îËÆ°ÁÆóÂ§çÊùÇÂ∫¶È´ò„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïËÆæËÆ°‰∏ÄÁßçÁÆÄÂçï„ÄÅÈ≤ÅÊ£í‰∏îÈ´òÊïàÁöÑÊ†áÂÆöÊñπÊ≥ïÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöCLAIMÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°Êèê‰æõÁöÑÁªìÊûÑ‰ø°ÊÅØÂíåÂõæÂÉèÁöÑÁ∫πÁêÜ‰ø°ÊÅØÔºåËÆæËÆ°‰∏ÄÁßçÊó†ÈúÄÂ§çÊùÇÁâπÂæÅÊèêÂèñÂíåÂåπÈÖçÁöÑÊçüÂ§±ÂáΩÊï∞„ÄÇÈÄöËøáÊúÄÂ∞èÂåñËØ•ÊçüÂ§±ÂáΩÊï∞ÔºåÂèØ‰ª•ÊâæÂà∞Áõ∏Êú∫ÂíåÊøÄÂÖâÈõ∑Ëææ‰πãÈó¥ÁöÑÊúÄ‰ºòÂèòÊç¢„ÄÇËøôÁßçÊñπÊ≥ïÈÅøÂÖç‰∫ÜÂØπÁâπÂÆöÁâπÂæÅÁöÑ‰æùËµñÔºåÊèêÈ´ò‰∫ÜÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCLAIMÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™Ê≠•È™§Ôºö1) ÁªôÂÆöÂàùÂßã‰ΩçÂßø‰º∞ËÆ°Ôºõ2) Âà©Áî®ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°Ê®°ÂûãÈ¢ÑÊµãÂõæÂÉèÁöÑÊ∑±Â∫¶ÂõæÔºõ3) Â∞ÜÊøÄÂÖâÈõ∑ËææÁÇπ‰∫ëÊäïÂΩ±Âà∞ÂõæÂÉè‰∏äÔºåÂπ∂Ê†πÊçÆÊ∑±Â∫¶ÂõæËÆ°ÁÆóÊØè‰∏™ÂÉèÁ¥†ÁÇπÁöÑ‰∏âÁª¥ÂùêÊ†áÔºõ4) ËÆ°ÁÆóÂü∫‰∫éÂàÜÂùóÁöÆÂ∞îÈÄäÁõ∏ÂÖ≥ÁöÑÁªìÊûÑÊçüÂ§±ÂíåÂü∫‰∫é‰∫í‰ø°ÊÅØÁöÑÁ∫πÁêÜÊçüÂ§±Ôºõ5) ‰ΩøÁî®‰ºòÂåñÁÆóÊ≥ïÔºàÂ¶ÇAdamÔºâÊúÄÂ∞èÂåñÊÄªÊçüÂ§±ÔºåÂæóÂà∞Áõ∏Êú∫ÂíåÊøÄÂÖâÈõ∑Ëææ‰πãÈó¥ÁöÑÊúÄ‰ºòÂèòÊç¢„ÄÇËØ•Ê°ÜÊû∂ÈááÁî®Áî±Á≤óÂà∞Á≤æÁöÑÊêúÁ¥¢Á≠ñÁï•ÔºåÂÖàËøõË°åÂÖ®Â±ÄÊêúÁ¥¢ÔºåÂÜçËøõË°åÂ±ÄÈÉ®‰ºòÂåñ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöCLAIMÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) Âà©Áî®ÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°‰Ωú‰∏∫ÁªìÊûÑ‰ø°ÊÅØÁöÑÊù•Ê∫êÔºåÈÅøÂÖç‰∫ÜÊâãÂ∑•ËÆæËÆ°ÁâπÂæÅÁöÑÂõ∞ÈöæÔºõ2) ÊèêÂá∫‰∫ÜÂü∫‰∫éÂàÜÂùóÁöÆÂ∞îÈÄäÁõ∏ÂÖ≥ÁöÑÁªìÊûÑÊçüÂ§±ÂíåÂü∫‰∫é‰∫í‰ø°ÊÅØÁöÑÁ∫πÁêÜÊçüÂ§±ÔºåËøô‰∏§ÁßçÊçüÂ§±ÂáΩÊï∞ËÉΩÂ§üÊúâÊïàÂú∞Â∫¶ÈáèÁõ∏Êú∫ÂíåÊøÄÂÖâÈõ∑ËææÊï∞ÊçÆÁöÑÂØπÈΩêÁ®ãÂ∫¶Ôºå‰∏îÊó†ÈúÄÂ§çÊùÇÁöÑÈ¢ÑÂ§ÑÁêÜÔºõ3) ÈááÁî®Áî±Á≤óÂà∞Á≤æÁöÑÊêúÁ¥¢Á≠ñÁï•ÔºåÊèêÈ´ò‰∫ÜÊ†áÂÆöÁöÑÊïàÁéáÂíåÁ≤æÂ∫¶„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÁªìÊûÑÊçüÂ§±ÈááÁî®ÂàÜÂùóÁöÆÂ∞îÈÄäÁõ∏ÂÖ≥Á≥ªÊï∞ÔºåÂ∞ÜÂõæÂÉèÂàíÂàÜ‰∏∫Â§ö‰∏™Â∞èÂùóÔºåËÆ°ÁÆóÊØè‰∏™Â∞èÂùóÁöÑÊ∑±Â∫¶ÂõæÂíåÊøÄÂÖâÈõ∑ËææÊäïÂΩ±ÁÇπ‰∫ë‰πãÈó¥ÁöÑÁõ∏ÂÖ≥ÊÄß„ÄÇÁ∫πÁêÜÊçüÂ§±ÈááÁî®‰∫í‰ø°ÊÅØÔºåË°°ÈáèÂõæÂÉèÁ∫πÁêÜÂíåÊøÄÂÖâÈõ∑ËææÂº∫Â∫¶‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶„ÄÇÊÄªÊçüÂ§±ÊòØÁªìÊûÑÊçüÂ§±ÂíåÁ∫πÁêÜÊçüÂ§±ÁöÑÂä†ÊùÉÂíå„ÄÇ‰ºòÂåñÁÆóÊ≥ïÈááÁî®AdamÔºåÂ≠¶‰π†ÁéáËÆæÁΩÆ‰∏∫0.001ÔºåËø≠‰ª£Ê¨°Êï∞Ê†πÊçÆÊï∞ÊçÆÈõÜËøõË°åË∞ÉÊï¥„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

CLAIMÂú®KITTI„ÄÅWaymoÂíåMIAS-LCECÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÈ™åËØÅÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéÂÖ∂ÊÄßËÉΩ‰ºò‰∫éÂΩìÂâçÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇ‰æãÂ¶ÇÔºåÂú®KITTIÊï∞ÊçÆÈõÜ‰∏äÔºåCLAIMÁöÑÊóãËΩ¨ËØØÂ∑ÆÂíå‰ΩçÁßªËØØÂ∑ÆÂàÜÂà´Èôç‰Ωé‰∫Ü15%Âíå10%„ÄÇÊ≠§Â§ñÔºåCLAIMÁöÑËÆ°ÁÆóÊïàÁéá‰πüÊòæËëóÊèêÈ´òÔºåÊ†áÂÆöÊó∂Èó¥Áº©Áü≠‰∫Ü30%„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éËá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅ‰∏âÁª¥ÈáçÂª∫Á≠âÈ¢ÜÂüü„ÄÇÁ≤æÁ°ÆÁöÑÁõ∏Êú∫-ÊøÄÂÖâÈõ∑ËææÊ†áÂÆöÊòØÂ§ö‰º†ÊÑüÂô®ËûçÂêàÁöÑÂü∫Á°ÄÔºåËÉΩÂ§üÊèêÈ´òÁéØÂ¢ÉÊÑüÁü•Á≥ªÁªüÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÁ±ªÂûãÁöÑ‰º†ÊÑüÂô®ÁªÑÂêàÔºå‰æãÂ¶ÇÊØ´Á±≥Ê≥¢Èõ∑ËææÂíåÁõ∏Êú∫Ôºå‰ªéËÄåÊûÑÂª∫Êõ¥Âº∫Â§ßÁöÑÊÑüÁü•Á≥ªÁªü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In this paper, we unleash the potential of the powerful monodepth model in camera-LiDAR calibration and propose CLAIM, a novel method of aligning data from the camera and LiDAR. Given the initial guess and pairs of images and LiDAR point clouds, CLAIM utilizes a coarse-to-fine searching method to find the optimal transformation minimizing a patched Pearson correlation-based structure loss and a mutual information-based texture loss. These two losses serve as good metrics for camera-LiDAR alignment results and require no complicated steps of data processing, feature extraction, or feature matching like most methods, rendering our method simple and adaptive to most scenes. We validate CLAIM on public KITTI, Waymo, and MIAS-LCEC datasets, and the experimental results demonstrate its superior performance compared with the state-of-the-art methods. The code is available at https://github.com/Tompson11/claim.

