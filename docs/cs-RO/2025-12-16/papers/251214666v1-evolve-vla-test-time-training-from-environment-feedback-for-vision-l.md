---
layout: default
title: EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models
---

# EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models

**arXiv**: [2512.14666v1](https://arxiv.org/abs/2512.14666) | [PDF](https://arxiv.org/pdf/2512.14666.pdf)

**ä½œè€…**: Zechen Bai, Chen Gao, Mike Zheng Shou

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 15 pages

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EVOLVE-VLAï¼šé¢å‘VLAæ¨¡åž‹çš„çŽ¯å¢ƒåé¦ˆæµ‹è¯•æ—¶è®­ç»ƒæ¡†æž¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **å…·èº«æ™ºèƒ½ (Embodied AI)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡åž‹` `æµ‹è¯•æ—¶è®­ç»ƒ` `çŽ¯å¢ƒåé¦ˆ` `å…·èº«æ™ºèƒ½` `æœºå™¨äººå­¦ä¹ ` `è‡ªä¸»é€‚åº”` `å¼ºåŒ–å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VLAæ¨¡åž‹ä¾èµ–å¤§é‡ä»»åŠ¡æ¼”ç¤ºè¿›è¡Œç›‘ç£å¾®è°ƒï¼Œæ³›åŒ–æ€§å’Œé€‚åº”æ€§ä¸è¶³ï¼Œéš¾ä»¥åº”å¯¹çœŸå®žçŽ¯å¢ƒå˜åŒ–ã€‚
2. EVOLVE-VLAæå‡ºä¸€ç§æµ‹è¯•æ—¶è®­ç»ƒæ¡†æž¶ï¼Œé€šè¿‡çŽ¯å¢ƒäº¤äº’å’Œè‡ªä¸»åé¦ˆï¼Œä½¿VLAæ¨¡åž‹æŒç»­é€‚åº”æ–°ä»»åŠ¡ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒEVOLVE-VLAåœ¨é•¿æ—¶ä»»åŠ¡ã€å•æ ·æœ¬å­¦ä¹ å’Œè·¨ä»»åŠ¡æ³›åŒ–æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ï¼Œå¹¶æ¶ŒçŽ°å‡ºé”™è¯¯æ¢å¤ç­‰æ–°èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†å®žçŽ°çœŸæ­£è‡ªé€‚åº”çš„å…·èº«æ™ºèƒ½ï¼Œæ™ºèƒ½ä½“ä¸ä»…éœ€è¦æ¨¡ä»¿é™æ€æ¼”ç¤ºè¿›è¡Œå­¦ä¹ ï¼Œè¿˜éœ€è¦é€šè¿‡ä¸ŽçŽ¯å¢ƒçš„æŒç»­äº¤äº’æ¥ä¸æ–­æ”¹è¿›ï¼Œè¿™ç±»ä¼¼äºŽäººç±»é€šè¿‡å®žè·µæŽŒæ¡æŠ€èƒ½çš„æ–¹å¼ã€‚è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹é€šè¿‡åˆ©ç”¨å¤§åž‹è¯­è¨€æ¨¡åž‹æŽ¨åŠ¨äº†æœºå™¨äººæ“ä½œçš„å‘å±•ï¼Œä½†ä»ç„¶å—åˆ°ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰çš„æ ¹æœ¬é™åˆ¶ï¼šæ¯ä¸ªä»»åŠ¡éœ€è¦æ•°ç™¾ä¸ªæ¼”ç¤ºï¼Œåˆšæ€§åœ°è®°å¿†è½¨è¿¹ï¼Œå¹¶ä¸”åœ¨éƒ¨ç½²æ¡ä»¶åç¦»è®­ç»ƒæ—¶æ— æ³•é€‚åº”ã€‚æˆ‘ä»¬å¼•å…¥äº†EVOLVE-VLAï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ—¶è®­ç»ƒæ¡†æž¶ï¼Œä½¿VLAèƒ½å¤Ÿé€šè¿‡çŽ¯å¢ƒäº¤äº’æŒç»­é€‚åº”ï¼Œè€Œåªéœ€æžå°‘æˆ–é›¶ä»»åŠ¡ç‰¹å®šæ¼”ç¤ºã€‚å…³é”®çš„æŠ€æœ¯æŒ‘æˆ˜æ˜¯ç”¨è‡ªä¸»åé¦ˆå–ä»£ï¼ˆæµ‹è¯•æ—¶ä¸å¯ç”¨çš„ï¼‰oracleå¥–åŠ±ä¿¡å·ã€‚æˆ‘ä»¬é€šè¿‡å­¦ä¹ åˆ°çš„è¿›åº¦ä¼°è®¡å™¨æä¾›å¯†é›†åé¦ˆæ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¹¶ä¸”è‡³å…³é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬è®¾è®¡æˆ‘ä»¬çš„æ¡†æž¶é€šè¿‡ä¸¤ç§æœºåˆ¶æ¥â€œé©¯æœâ€è¿™ç§å›ºæœ‰çš„å™ªå£°ä¿¡å·ï¼šï¼ˆ1ï¼‰ç´¯ç§¯è¿›åº¦ä¼°è®¡æœºåˆ¶ï¼Œå¹³æ»‘å™ªå£°ç‚¹ä¼°è®¡ï¼Œä»¥åŠï¼ˆ2ï¼‰æ¸è¿›å¼horizonæ‰©å±•ç­–ç•¥ï¼Œå®žçŽ°é€æ­¥çš„ç­–ç•¥æ¼”è¿›ã€‚EVOLVE-VLAå–å¾—äº†æ˜¾è‘—çš„æ”¶ç›Šï¼šåœ¨é•¿horizonä»»åŠ¡ä¸Š+8.6ï¼…ï¼Œåœ¨å•æ ·æœ¬å­¦ä¹ ä¸­+22.0ï¼…ï¼Œå¹¶å®žçŽ°äº†è·¨ä»»åŠ¡æ³›åŒ–â€”â€”åœ¨æ²¡æœ‰ä»»åŠ¡ç‰¹å®šæ¼”ç¤ºè®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œåœ¨æœªè§ä»»åŠ¡ä¸Šå®žçŽ°äº†20.8ï¼…çš„æˆåŠŸçŽ‡ï¼ˆè€Œçº¯SFTä¸º0ï¼…ï¼‰ã€‚å®šæ€§åˆ†æžæ­ç¤ºäº†æ¼”ç¤ºä¸­ä¸å­˜åœ¨çš„æ–°å…´èƒ½åŠ›ï¼ŒåŒ…æ‹¬é”™è¯¯æ¢å¤å’Œæ–°é¢–ç­–ç•¥ã€‚è¿™é¡¹å·¥ä½œä»£è¡¨äº†æœç€çœŸæ­£å­¦ä¹ å’Œé€‚åº”çš„VLAè¿ˆå‡ºçš„å…³é”®ä¸€æ­¥ï¼Œä»Žé™æ€æ¨¡ä»¿è½¬å‘æŒç»­çš„è‡ªæˆ‘æ”¹è¿›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹ä¸»è¦ä¾èµ–äºŽç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œéœ€è¦å¤§é‡ç‰¹å®šä»»åŠ¡çš„æ¼”ç¤ºæ•°æ®ã€‚è¿™ç§æ–¹æ³•æ³›åŒ–èƒ½åŠ›å·®ï¼Œéš¾ä»¥é€‚åº”éƒ¨ç½²çŽ¯å¢ƒä¸­ä¸Žè®­ç»ƒæ•°æ®ä¸åŒçš„æƒ…å†µï¼Œä¾‹å¦‚çŽ¯å¢ƒå™ªå£°ã€ç›®æ ‡å˜åŒ–ç­‰ã€‚æ­¤å¤–ï¼ŒSFTæ¨¡åž‹å€¾å‘äºŽè®°å¿†è®­ç»ƒè½¨è¿¹ï¼Œç¼ºä¹æŽ¢ç´¢å’Œåˆ›æ–°èƒ½åŠ›ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ç¼ºä¹å¤§é‡æ¼”ç¤ºæ•°æ®çš„æƒ…å†µä¸‹ï¼Œä½¿VLAæ¨¡åž‹èƒ½å¤ŸæŒç»­å­¦ä¹ å’Œé€‚åº”æ–°çŽ¯å¢ƒæ˜¯äºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEVOLVE-VLAçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨æµ‹è¯•æ—¶åˆ©ç”¨çŽ¯å¢ƒåé¦ˆè¿›è¡ŒæŒç»­è®­ç»ƒï¼Œä»Žè€Œä½¿VLAæ¨¡åž‹èƒ½å¤Ÿè‡ªä¸»é€‚åº”æ–°ä»»åŠ¡å’ŒçŽ¯å¢ƒã€‚è¯¥æ–¹æ³•é€šè¿‡å­¦ä¹ ä¸€ä¸ªè¿›åº¦ä¼°è®¡å™¨æ¥æ›¿ä»£oracleå¥–åŠ±ä¿¡å·ï¼Œä¸ºæ¨¡åž‹æä¾›å¯†é›†çš„åé¦ˆã€‚ä¸ºäº†åº”å¯¹è¿›åº¦ä¼°è®¡å™¨äº§ç”Ÿçš„å™ªå£°ï¼ŒEVOLVE-VLAé‡‡ç”¨äº†ç´¯ç§¯è¿›åº¦ä¼°è®¡å’Œå¹³æ»‘æœºåˆ¶ï¼Œä»¥åŠæ¸è¿›å¼horizonæ‰©å±•ç­–ç•¥ï¼Œä»Žè€Œç¨³å®šç­–ç•¥çš„æ¼”è¿›è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šEVOLVE-VLAæ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) VLAæ¨¡åž‹ï¼šä½œä¸ºæ™ºèƒ½ä½“çš„å†³ç­–æ ¸å¿ƒï¼ŒæŽ¥æ”¶è§†è§‰å’Œè¯­è¨€è¾“å…¥ï¼Œè¾“å‡ºåŠ¨ä½œæŒ‡ä»¤ã€‚2) è¿›åº¦ä¼°è®¡å™¨ï¼šç”¨äºŽè¯„ä¼°æ™ºèƒ½ä½“åœ¨ä»»åŠ¡ä¸­çš„è¿›å±•ç¨‹åº¦ï¼Œæä¾›å¯†é›†çš„åé¦ˆä¿¡å·ã€‚3) ç´¯ç§¯è¿›åº¦ä¼°è®¡æ¨¡å—ï¼šå¯¹è¿›åº¦ä¼°è®¡å™¨çš„è¾“å‡ºè¿›è¡Œå¹³æ»‘å¤„ç†ï¼Œå‡å°‘å™ªå£°çš„å½±å“ã€‚4) æ¸è¿›å¼Horizonæ‰©å±•æ¨¡å—ï¼šé€æ­¥å¢žåŠ è®­ç»ƒçš„horizoné•¿åº¦ï¼Œä½¿æ¨¡åž‹èƒ½å¤Ÿå­¦ä¹ æ›´é•¿æœŸçš„ç­–ç•¥ã€‚æ•´ä¸ªæµç¨‹å¦‚ä¸‹ï¼šVLAæ¨¡åž‹ä¸ŽçŽ¯å¢ƒäº¤äº’ï¼Œè¿›åº¦ä¼°è®¡å™¨è¯„ä¼°è¿›å±•ï¼Œç´¯ç§¯è¿›åº¦ä¼°è®¡æ¨¡å—å¹³æ»‘åé¦ˆï¼Œç„¶åŽåˆ©ç”¨è¯¥åé¦ˆæ›´æ–°VLAæ¨¡åž‹ï¼Œå¹¶é€æ­¥æ‰©å±•horizonã€‚

**å…³é”®åˆ›æ–°**ï¼šEVOLVE-VLAçš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ä¸€ä¸ªæµ‹è¯•æ—¶è®­ç»ƒæ¡†æž¶ï¼Œè¯¥æ¡†æž¶æ— éœ€å¤§é‡ä»»åŠ¡ç‰¹å®šæ¼”ç¤ºï¼Œè€Œæ˜¯é€šè¿‡çŽ¯å¢ƒäº¤äº’å’Œè‡ªä¸»åé¦ˆæ¥æŒç»­æ”¹è¿›VLAæ¨¡åž‹ã€‚ä¸Žä¼ ç»Ÿçš„SFTæ–¹æ³•ç›¸æ¯”ï¼ŒEVOLVE-VLAèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”æ–°çŽ¯å¢ƒå’Œä»»åŠ¡ï¼Œå¹¶å…·å¤‡æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç´¯ç§¯è¿›åº¦ä¼°è®¡å’Œæ¸è¿›å¼horizonæ‰©å±•ç­–ç•¥æœ‰æ•ˆåœ°è§£å†³äº†å™ªå£°åé¦ˆå¸¦æ¥çš„é—®é¢˜ï¼Œä¿è¯äº†è®­ç»ƒçš„ç¨³å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šç´¯ç§¯è¿›åº¦ä¼°è®¡æ¨¡å—é‡‡ç”¨æ»‘åŠ¨å¹³å‡çš„æ–¹å¼å¯¹è¿›åº¦ä¼°è®¡å™¨çš„è¾“å‡ºè¿›è¡Œå¹³æ»‘å¤„ç†ï¼Œå‡å°‘å™ªå£°çš„å½±å“ã€‚æ¸è¿›å¼horizonæ‰©å±•ç­–ç•¥ä»Žè¾ƒçŸ­çš„horizonå¼€å§‹ï¼Œé€æ­¥å¢žåŠ horizonçš„é•¿åº¦ï¼Œä½¿æ¨¡åž‹èƒ½å¤Ÿé€æ­¥å­¦ä¹ æ›´é•¿æœŸçš„ç­–ç•¥ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°è®¾è®¡ä¸ºåŸºäºŽè¿›åº¦ä¼°è®¡çš„å¥–åŠ±æœ€å¤§åŒ–ï¼Œå¯ä»¥ä½¿ç”¨å¸¸è§çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•è¿›è¡Œä¼˜åŒ–ã€‚è¿›åº¦ä¼°è®¡å™¨çš„è®­ç»ƒå¯ä»¥ä½¿ç”¨ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œåˆ©ç”¨å°‘é‡æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

EVOLVE-VLAåœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨é•¿horizonä»»åŠ¡ä¸Šï¼ŒæˆåŠŸçŽ‡æé«˜äº†8.6%ã€‚åœ¨å•æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸‹ï¼ŒæˆåŠŸçŽ‡æé«˜äº†22.0%ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒEVOLVE-VLAåœ¨æœªè§è¿‡çš„ä»»åŠ¡ä¸Šå®žçŽ°äº†20.8%çš„æˆåŠŸçŽ‡ï¼Œè€Œçº¯SFTæ–¹æ³•åœ¨è¯¥åœºæ™¯ä¸‹çš„æˆåŠŸçŽ‡ä¸º0%ã€‚è¿™äº›å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒEVOLVE-VLAå…·æœ‰å¾ˆå¼ºçš„æ³›åŒ–èƒ½åŠ›å’Œé€‚åº”æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

EVOLVE-VLAå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨å®¶åº­æœåŠ¡æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚è¯¥æ–¹æ³•å¯ä»¥ä½¿æœºå™¨äººèƒ½å¤Ÿè‡ªä¸»å­¦ä¹ å’Œé€‚åº”æ–°çŽ¯å¢ƒï¼Œæ— éœ€äººå·¥å¹²é¢„ï¼Œä»Žè€Œé™ä½Žéƒ¨ç½²æˆæœ¬å’Œæé«˜æ•ˆçŽ‡ã€‚æ­¤å¤–ï¼ŒEVOLVE-VLAè¿˜å¯ä»¥ç”¨äºŽå¼€å‘æ›´æ™ºèƒ½çš„è™šæ‹ŸåŠ©æ‰‹ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç”¨æˆ·æ„å›¾å¹¶æä¾›ä¸ªæ€§åŒ–æœåŠ¡ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æœ‰æœ›æŽ¨åŠ¨å…·èº«æ™ºèƒ½çš„å‘å±•ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ›´å¥½åœ°èžå…¥äººç±»ç¤¾ä¼šã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Achieving truly adaptive embodied intelligence requires agents that learn not just by imitating static demonstrations, but by continuously improving through environmental interaction, which is akin to how humans master skills through practice. Vision-Language-Action (VLA) models have advanced robotic manipulation by leveraging large language models, yet remain fundamentally limited by Supervised Finetuning (SFT): requiring hundreds of demonstrations per task, rigidly memorizing trajectories, and failing to adapt when deployment conditions deviate from training. We introduce EVOLVE-VLA, a test-time training framework enabling VLAs to continuously adapt through environment interaction with minimal or zero task-specific demonstrations. The key technical challenge is replacing oracle reward signals (unavailable at test time) with autonomous feedback. We address this through a learned progress estimator providing dense feedback, and critically, we design our framework to ``tame'' this inherently noisy signal via two mechanisms: (1) an accumulative progress estimation mechanism smoothing noisy point-wise estimates, and (2) a progressive horizon extension strategy enabling gradual policy evolution. EVOLVE-VLA achieves substantial gains: +8.6\% on long-horizon tasks, +22.0\% in 1-shot learning, and enables cross-task generalization -- achieving 20.8\% success on unseen tasks without task-specific demonstrations training (vs. 0\% for pure SFT). Qualitative analysis reveals emergent capabilities absent in demonstrations, including error recovery and novel strategies. This work represents a critical step toward VLAs that truly learn and adapt, moving beyond static imitation toward continuous self-improvements.

