---
layout: default
title: Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future
---

# Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16760" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16760v1</a>
  <a href="https://arxiv.org/pdf/2512.16760.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16760v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16760v1', 'Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tianshuai Hu, Xiaolu Liu, Song Wang, Yiyao Zhu, Ao Liang, Lingdong Kong, Guoyang Zhao, Zeying Gong, Jun Cen, Zhiyu Huang, Xiaoshuai Hao, Linfeng Li, Hang Song, Xiangtai Li, Jun Ma, Shaojie Shen, Jianke Zhu, Dacheng Tao, Ziwei Liu, Junwei Liang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

**å¤‡æ³¨**: Preprint; 40 pages, 7 figures, 9 tables; GitHub at https://github.com/worldbench/awesome-vla-for-ad

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»¼è¿°æ€§è®ºæ–‡ï¼šé¢å‘è‡ªåŠ¨é©¾é©¶çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ç ”ç©¶è¿›å±•ä¸æœªæ¥å±•æœ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç«¯åˆ°ç«¯å­¦ä¹ ` `åŒç³»ç»Ÿæ¶æ„` `ç»¼è¿°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿè‡ªåŠ¨é©¾é©¶ä¾èµ–â€œæ„ŸçŸ¥-å†³ç­–-è¡ŒåŠ¨â€æ¨¡å—åŒ–æµç¨‹ï¼Œæ˜“å—æ„ŸçŸ¥è¯¯å·®å½±å“ï¼Œä¸”éš¾ä»¥å¤„ç†å¤æ‚åœºæ™¯ã€‚
2. è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹é€šè¿‡æ•´åˆè§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œï¼Œå®ç°æ›´å¯è§£é‡Šå’Œé€šç”¨çš„é©¾é©¶ç­–ç•¥ã€‚
3. è®ºæ–‡ç»¼è¿°äº†VLAåœ¨è‡ªåŠ¨é©¾é©¶ä¸­çš„åº”ç”¨ï¼Œåˆ†æäº†ç«¯åˆ°ç«¯å’ŒåŒç³»ç»Ÿä¸¤ç§èŒƒä¾‹ï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥ç ”ç©¶æ–¹å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªåŠ¨é©¾é©¶é•¿æœŸä»¥æ¥ä¾èµ–äºæ¨¡å—åŒ–çš„â€œæ„ŸçŸ¥-å†³ç­–-è¡ŒåŠ¨â€æµç¨‹ï¼Œä½†æ‰‹å·¥è®¾è®¡çš„æ¥å£å’ŒåŸºäºè§„åˆ™çš„ç»„ä»¶åœ¨å¤æ‚æˆ–é•¿å°¾åœºæ™¯ä¸­ç»å¸¸å¤±æ•ˆã€‚å…¶çº§è”è®¾è®¡è¿›ä¸€æ­¥ä¼ æ’­æ„ŸçŸ¥è¯¯å·®ï¼Œé™ä½ä¸‹æ¸¸è§„åˆ’å’Œæ§åˆ¶çš„æ€§èƒ½ã€‚è§†è§‰-åŠ¨ä½œï¼ˆVAï¼‰æ¨¡å‹é€šè¿‡å­¦ä¹ ä»è§†è§‰è¾“å…¥åˆ°åŠ¨ä½œçš„ç›´æ¥æ˜ å°„æ¥è§£å†³ä¸€äº›å±€é™æ€§ï¼Œä½†å®ƒä»¬ä»ç„¶ä¸é€æ˜ï¼Œå¯¹åˆ†å¸ƒåç§»æ•æ„Ÿï¼Œå¹¶ä¸”ç¼ºä¹ç»“æ„åŒ–æ¨ç†æˆ–æŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå¤šæ¨¡æ€å­¦ä¹ çš„æœ€æ–°è¿›å±•æ¨åŠ¨äº†è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¡†æ¶çš„å‡ºç°ï¼Œè¯¥æ¡†æ¶å°†æ„ŸçŸ¥ä¸åŸºäºè¯­è¨€çš„å†³ç­–ç›¸ç»“åˆã€‚é€šè¿‡ç»Ÿä¸€è§†è§‰ç†è§£ã€è¯­è¨€æ¨ç†å’Œå¯æ“ä½œçš„è¾“å‡ºï¼ŒVLAä¸ºæ›´å¯è§£é‡Šã€æ›´é€šç”¨å’Œæ›´ç¬¦åˆäººç±»ä¹ æƒ¯çš„é©¾é©¶ç­–ç•¥æä¾›äº†ä¸€æ¡é€”å¾„ã€‚æœ¬æ–‡å¯¹æ–°å…´çš„è‡ªåŠ¨é©¾é©¶VLAé¢†åŸŸè¿›è¡Œäº†ç»“æ„åŒ–æè¿°ï¼Œè¿½æº¯äº†ä»æ—©æœŸVAæ–¹æ³•åˆ°ç°ä»£VLAæ¡†æ¶çš„æ¼”å˜ï¼Œå¹¶å°†ç°æœ‰æ–¹æ³•ç»„ç»‡æˆä¸¤ç§ä¸»è¦èŒƒä¾‹ï¼šç«¯åˆ°ç«¯VLAå’ŒåŒç³»ç»ŸVLAã€‚æ€»ç»“äº†ç”¨äºè¯„ä¼°VLAé©¾é©¶ç³»ç»Ÿçš„ä»£è¡¨æ€§æ•°æ®é›†å’ŒåŸºå‡†ï¼Œå¹¶å¼ºè°ƒäº†å…³é”®æŒ‘æˆ˜å’Œå¼€æ”¾æ–¹å‘ï¼ŒåŒ…æ‹¬é²æ£’æ€§ã€å¯è§£é‡Šæ€§å’ŒæŒ‡ä»¤ä¿çœŸåº¦ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™é¡¹å·¥ä½œæ—¨åœ¨ä¸ºæ¨è¿›ä¸äººç±»å…¼å®¹çš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿå¥ å®šè¿è´¯çš„åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šä¼ ç»Ÿè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¾èµ–äºæ¨¡å—åŒ–çš„â€œæ„ŸçŸ¥-å†³ç­–-è¡ŒåŠ¨â€æµç¨‹ï¼Œè¿™äº›æµç¨‹å­˜åœ¨å¤šä¸ªé—®é¢˜ã€‚é¦–å…ˆï¼Œæ‰‹å·¥è®¾è®¡çš„æ¥å£å’Œè§„åˆ™åœ¨å¤æ‚æˆ–é•¿å°¾åœºæ™¯ä¸­å®¹æ˜“å¤±æ•ˆã€‚å…¶æ¬¡ï¼Œçº§è”çš„è®¾è®¡ä¼šå¯¼è‡´æ„ŸçŸ¥è¯¯å·®å‘ä¸‹æ¸¸ä¼ æ’­ï¼Œå½±å“è§„åˆ’å’Œæ§åˆ¶çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œæ—©æœŸçš„è§†è§‰-åŠ¨ä½œï¼ˆVAï¼‰æ¨¡å‹è™½ç„¶èƒ½å¤Ÿç›´æ¥ä»è§†è§‰è¾“å…¥æ˜ å°„åˆ°åŠ¨ä½œï¼Œä½†ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œå¯¹æ•°æ®åˆ†å¸ƒçš„å˜åŒ–éå¸¸æ•æ„Ÿï¼Œå¹¶ä¸”ç¼ºä¹ç»“æ„åŒ–çš„æ¨ç†èƒ½åŠ›å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå¤šæ¨¡æ€å­¦ä¹ çš„æœ€æ–°è¿›å±•ï¼Œæ„å»ºè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¡†æ¶ï¼Œå°†è§†è§‰æ„ŸçŸ¥ä¸åŸºäºè¯­è¨€çš„å†³ç­–ç›¸ç»“åˆã€‚é€šè¿‡ç»Ÿä¸€è§†è§‰ç†è§£ã€è¯­è¨€æ¨ç†å’Œå¯æ‰§è¡Œçš„åŠ¨ä½œè¾“å‡ºï¼ŒVLAæ—¨åœ¨å®ç°æ›´å¯è§£é‡Šã€æ›´é€šç”¨ã€æ›´ç¬¦åˆäººç±»ä¹ æƒ¯çš„è‡ªåŠ¨é©¾é©¶ç­–ç•¥ã€‚è¿™ç§æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºåˆ©ç”¨è¯­è¨€ä½œä¸ºæ¡¥æ¢ï¼Œè¿æ¥è§†è§‰æ„ŸçŸ¥å’ŒåŠ¨ä½œæ‰§è¡Œï¼Œä»è€Œæé«˜ç³»ç»Ÿçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡å°†ç°æœ‰çš„VLAæ–¹æ³•ç»„ç»‡æˆä¸¤ç§ä¸»è¦çš„èŒƒä¾‹ï¼šç«¯åˆ°ç«¯VLAå’ŒåŒç³»ç»ŸVLAã€‚ç«¯åˆ°ç«¯VLAå°†æ„ŸçŸ¥ã€æ¨ç†å’Œè§„åˆ’æ•´åˆåˆ°ä¸€ä¸ªå•ä¸€çš„æ¨¡å‹ä¸­ï¼Œç›´æ¥ä»è§†è§‰è¾“å…¥ç”ŸæˆåŠ¨ä½œã€‚åŒç³»ç»ŸVLAåˆ™å°†æ…¢é€Ÿçš„æ¨ç†ï¼ˆé€šè¿‡è§†è§‰è¯­è¨€æ¨¡å‹ï¼‰ä¸å¿«é€Ÿã€å®‰å…¨å…³é”®çš„æ‰§è¡Œï¼ˆé€šè¿‡è§„åˆ’å™¨ï¼‰åˆ†ç¦»ã€‚åœ¨è¿™äº›èŒƒä¾‹ä¸­ï¼Œåˆè¿›ä¸€æ­¥åŒºåˆ†äº†æ–‡æœ¬åŠ¨ä½œç”Ÿæˆå™¨ä¸æ•°å€¼åŠ¨ä½œç”Ÿæˆå™¨ï¼Œä»¥åŠæ˜¾å¼æŒ‡å¯¼æœºåˆ¶ä¸éšå¼æŒ‡å¯¼æœºåˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¯¹è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„VLAæ¨¡å‹è¿›è¡Œäº†ç³»ç»Ÿçš„åˆ†ç±»å’Œåˆ†æï¼Œå¹¶æå‡ºäº†ç«¯åˆ°ç«¯VLAå’ŒåŒç³»ç»ŸVLAä¸¤ç§ä¸»è¦èŒƒä¾‹ã€‚è¿™ç§åˆ†ç±»æ–¹æ³•æœ‰åŠ©äºç ”ç©¶äººå‘˜æ›´å¥½åœ°ç†è§£ä¸åŒVLAæ¨¡å‹çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†æŒ‡å¯¼ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å¼ºè°ƒäº†VLAæ¨¡å‹åœ¨å¯è§£é‡Šæ€§ã€é€šç”¨æ€§å’ŒæŒ‡ä»¤ä¿çœŸåº¦æ–¹é¢çš„ä¼˜åŠ¿ï¼Œè¿™äº›ä¼˜åŠ¿æ˜¯ä¼ ç»Ÿè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿæ‰€ä¸å…·å¤‡çš„ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡æ²¡æœ‰æ¶‰åŠå…·ä½“çš„æ¨¡å‹è®¾è®¡ç»†èŠ‚ï¼Œè€Œä¾§é‡äºå¯¹ç°æœ‰VLAæ¡†æ¶çš„ç»¼è¿°å’Œåˆ†ç±»ã€‚å› æ­¤ï¼Œæ²¡æœ‰å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚å¯ä»¥æè¿°ã€‚è®ºæ–‡ä¸»è¦å…³æ³¨çš„æ˜¯ä¸åŒVLAæ¡†æ¶çš„æ•´ä½“æ¶æ„å’Œæµç¨‹ï¼Œä»¥åŠå®ƒä»¬åœ¨è‡ªåŠ¨é©¾é©¶ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16760v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16760v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16760v1/figures/fig3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥è®ºæ–‡æ˜¯ä¸€ç¯‡ç»¼è¿°æ€§æ–‡ç« ï¼Œæ²¡æœ‰å…·ä½“çš„å®éªŒç»“æœã€‚å…¶äº®ç‚¹åœ¨äºå¯¹ç°æœ‰VLAæ¨¡å‹è¿›è¡Œäº†ç³»ç»Ÿçš„åˆ†ç±»å’Œåˆ†æï¼Œæå‡ºäº†ç«¯åˆ°ç«¯VLAå’ŒåŒç³»ç»ŸVLAä¸¤ç§ä¸»è¦èŒƒä¾‹ï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥ç ”ç©¶çš„å…³é”®æŒ‘æˆ˜å’Œå¼€æ”¾æ–¹å‘ï¼Œä¾‹å¦‚é²æ£’æ€§ã€å¯è§£é‡Šæ€§å’ŒæŒ‡ä»¤ä¿çœŸåº¦ã€‚è¯¥ç»¼è¿°ä¸ºç ”ç©¶äººå‘˜æä¾›äº†ä¸€ä¸ªå…¨é¢çš„VLAæ¨¡å‹å‘å±•æ¦‚å†µï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†æŒ‡å¯¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯¹è‡ªåŠ¨é©¾é©¶é¢†åŸŸå…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ã€‚VLAæ¨¡å‹èƒ½å¤Ÿæå‡è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å¯è§£é‡Šæ€§ã€é€šç”¨æ€§å’Œé²æ£’æ€§ï¼Œä½¿å…¶åœ¨å¤æ‚å’ŒæœªçŸ¥çš„ç¯å¢ƒä¸­æ›´å¥½åœ°è¿è¡Œã€‚æœªæ¥çš„å‘å±•æ–¹å‘åŒ…æ‹¬æé«˜VLAæ¨¡å‹çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€å¢å¼ºå…¶å¯¹é•¿å°¾åœºæ™¯çš„å¤„ç†èƒ½åŠ›ï¼Œä»¥åŠå®ç°æ›´å®‰å…¨å¯é çš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿã€‚è¿™é¡¹ç ”ç©¶ä¹Ÿå°†æ¨åŠ¨äººæœºäº¤äº’åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„åº”ç”¨ï¼Œä½¿è½¦è¾†èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œå“åº”äººç±»çš„æŒ‡ä»¤ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autonomous driving has long relied on modular "Perception-Decision-Action" pipelines, where hand-crafted interfaces and rule-based components often break down in complex or long-tailed scenarios. Their cascaded design further propagates perception errors, degrading downstream planning and control. Vision-Action (VA) models address some limitations by learning direct mappings from visual inputs to actions, but they remain opaque, sensitive to distribution shifts, and lack structured reasoning or instruction-following capabilities. Recent progress in Large Language Models (LLMs) and multimodal learning has motivated the emergence of Vision-Language-Action (VLA) frameworks, which integrate perception with language-grounded decision making. By unifying visual understanding, linguistic reasoning, and actionable outputs, VLAs offer a pathway toward more interpretable, generalizable, and human-aligned driving policies. This work provides a structured characterization of the emerging VLA landscape for autonomous driving. We trace the evolution from early VA approaches to modern VLA frameworks and organize existing methods into two principal paradigms: End-to-End VLA, which integrates perception, reasoning, and planning within a single model, and Dual-System VLA, which separates slow deliberation (via VLMs) from fast, safety-critical execution (via planners). Within these paradigms, we further distinguish subclasses such as textual vs. numerical action generators and explicit vs. implicit guidance mechanisms. We also summarize representative datasets and benchmarks for evaluating VLA-based driving systems and highlight key challenges and open directions, including robustness, interpretability, and instruction fidelity. Overall, this work aims to establish a coherent foundation for advancing human-compatible autonomous driving systems.

