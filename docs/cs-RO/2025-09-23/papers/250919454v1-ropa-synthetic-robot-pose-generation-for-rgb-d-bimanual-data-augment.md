---
layout: default
title: ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation
---

# ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.19454" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.19454v1</a>
  <a href="https://arxiv.org/pdf/2509.19454.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.19454v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.19454v1', 'ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jason Chen, I-Chun Arthur Liu, Gaurav Sukhatme, Daniel Seita

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-23

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://ropaaug.github.io/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ROPAï¼šç”¨äºRGB-DåŒè‡‚æ“ä½œæ•°æ®å¢å¼ºçš„åˆæˆæœºå™¨äººå§¿æ€ç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `æ•°æ®å¢å¼º` `æ¨¡ä»¿å­¦ä¹ ` `Stable Diffusion` `RGB-Då›¾åƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ¨¡ä»¿å­¦ä¹ è®­ç»ƒé²æ£’çš„åŒè‡‚æ“ä½œç­–ç•¥éœ€è¦è¦†ç›–å¹¿æ³›æœºå™¨äººå§¿æ€çš„æ•°æ®ï¼Œè€Œæ”¶é›†å¤šæ ·ä¸”ç²¾ç¡®çš„çœŸå®æ•°æ®æˆæœ¬é«˜æ˜‚ã€‚
2. ROPAé€šè¿‡å¾®è°ƒStable Diffusionåˆæˆæ–°çš„æœºå™¨äººå§¿æ€ï¼Œå¹¶ä½¿ç”¨çº¦æŸä¼˜åŒ–ä¿è¯åŒè‡‚æ“ä½œçš„ç‰©ç†ä¸€è‡´æ€§ï¼Œç”Ÿæˆå¯¹åº”çš„åŠ¨ä½œæ ‡ç­¾ã€‚
3. åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­çš„å®éªŒè¡¨æ˜ï¼ŒROPAä¼˜äºå…¶ä»–æ•°æ®å¢å¼ºæ–¹æ³•ï¼ŒéªŒè¯äº†å…¶åœ¨åŒè‡‚æ“ä½œæ•°æ®å¢å¼ºæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºROPAï¼ˆSynthetic Robot Pose Generation for RGB-D Bimanual Data Augmentationï¼‰çš„ç¦»çº¿æ¨¡ä»¿å­¦ä¹ æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œç”¨äºåˆæˆæ–°çš„æœºå™¨äººå§¿æ€çš„RGBå’ŒRGB-Dè§‚æµ‹ã€‚è¯¥æ–¹æ³•é€šè¿‡å¾®è°ƒStable Diffusionï¼Œå¹¶åŒæ—¶ç”Ÿæˆå¯¹åº”çš„å…³èŠ‚ç©ºé—´åŠ¨ä½œæ ‡ç­¾ï¼Œåˆ©ç”¨çº¦æŸä¼˜åŒ–åœ¨åŒè‡‚åœºæ™¯ä¸­å®æ–½åˆé€‚çš„å¤¹çˆª-ç‰©ä½“æ¥è§¦çº¦æŸï¼Œä»è€Œä¿è¯ç‰©ç†ä¸€è‡´æ€§ã€‚æˆ‘ä»¬åœ¨5ä¸ªæ¨¡æ‹Ÿä»»åŠ¡å’Œ3ä¸ªçœŸå®ä¸–ç•Œä»»åŠ¡ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨2625æ¬¡æ¨¡æ‹Ÿè¯•éªŒå’Œ300æ¬¡çœŸå®ä¸–ç•Œè¯•éªŒä¸­ï¼ŒROPAä¼˜äºåŸºçº¿æ–¹æ³•å’Œæ¶ˆèå®éªŒï¼Œå±•ç¤ºäº†å…¶åœ¨eye-to-handåŒè‡‚æ“ä½œä¸­å¯æ‰©å±•çš„RGBå’ŒRGB-Dæ•°æ®å¢å¼ºçš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„æ¨¡ä»¿å­¦ä¹ æ–¹æ³•åœ¨è®­ç»ƒåŒè‡‚æ“ä½œä»»åŠ¡æ—¶ï¼Œéœ€è¦å¤§é‡çš„çœŸå®ä¸–ç•Œæ•°æ®ï¼Œè€Œæ”¶é›†è¿™äº›æ•°æ®éå¸¸è€—æ—¶ä¸”æˆæœ¬é«˜æ˜‚ã€‚è™½ç„¶æ•°æ®å¢å¼ºæŠ€æœ¯å¯ä»¥ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨eye-in-handï¼ˆè…•éƒ¨ç›¸æœºï¼‰è®¾ç½®ä¸‹çš„RGBå›¾åƒå¢å¼ºï¼Œæˆ–è€…ç”Ÿæˆæ²¡æœ‰é…å¯¹åŠ¨ä½œçš„æ–°å›¾åƒï¼Œç¼ºä¹é’ˆå¯¹eye-to-handï¼ˆç¬¬ä¸‰äººç§°è§†è§’ï¼‰RGB-Dæ•°æ®çš„æœ‰æ•ˆå¢å¼ºæ–¹æ³•ï¼Œå°¤å…¶æ˜¯ç¼ºä¹èƒ½å¤Ÿç”Ÿæˆæ–°åŠ¨ä½œæ ‡ç­¾çš„æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šROPAçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Stable Diffusionå¼ºå¤§çš„å›¾åƒç”Ÿæˆèƒ½åŠ›ï¼Œé€šè¿‡å¾®è°ƒä½¿å…¶èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ä¸åŒæœºå™¨äººå§¿æ€çš„RGBå’ŒRGB-Då›¾åƒã€‚åŒæ—¶ï¼Œä¸ºäº†ä¿è¯ç”Ÿæˆå›¾åƒçš„ç‰©ç†åˆç†æ€§ï¼ŒROPAé‡‡ç”¨çº¦æŸä¼˜åŒ–æ–¹æ³•ï¼Œåœ¨ç”Ÿæˆå›¾åƒçš„åŒæ—¶ï¼Œç”Ÿæˆå¯¹åº”çš„å…³èŠ‚ç©ºé—´åŠ¨ä½œæ ‡ç­¾ï¼Œå¹¶å¼ºåˆ¶æ‰§è¡Œå¤¹çˆªä¸ç‰©ä½“ä¹‹é—´çš„æ¥è§¦çº¦æŸã€‚è¿™æ ·ï¼ŒROPAä¸ä»…èƒ½å¤Ÿç”Ÿæˆæ–°çš„å›¾åƒï¼Œè¿˜èƒ½å¤Ÿç”Ÿæˆä¸å›¾åƒå¯¹åº”çš„åˆç†åŠ¨ä½œï¼Œä»è€Œå®ç°æœ‰æ•ˆçš„æ•°æ®å¢å¼ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šROPAçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) ä½¿ç”¨ç°æœ‰çš„æ•°æ®é›†å¯¹Stable Diffusionæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶èƒ½å¤Ÿç”ŸæˆåŒ…å«æœºå™¨äººçš„åœºæ™¯å›¾åƒï¼›2) é€šè¿‡é‡‡æ ·æ–°çš„æœºå™¨äººå§¿æ€ï¼Œå¹¶ä½¿ç”¨å¾®è°ƒåçš„Stable Diffusionæ¨¡å‹ç”Ÿæˆå¯¹åº”çš„RGBå’ŒRGB-Då›¾åƒï¼›3) ä½¿ç”¨çº¦æŸä¼˜åŒ–æ–¹æ³•ï¼Œæ ¹æ®ç”Ÿæˆçš„å›¾åƒï¼Œè®¡ç®—å‡ºå¯¹åº”çš„å…³èŠ‚ç©ºé—´åŠ¨ä½œæ ‡ç­¾ï¼Œå¹¶å¼ºåˆ¶æ‰§è¡Œå¤¹çˆªä¸ç‰©ä½“ä¹‹é—´çš„æ¥è§¦çº¦æŸï¼›4) å°†ç”Ÿæˆçš„å›¾åƒå’ŒåŠ¨ä½œæ ‡ç­¾æ·»åŠ åˆ°è®­ç»ƒæ•°æ®é›†ä¸­ï¼Œç”¨äºè®­ç»ƒæ¨¡ä»¿å­¦ä¹ æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šROPAçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) å°†Stable Diffusionåº”ç”¨äºæœºå™¨äººæ“ä½œçš„æ•°æ®å¢å¼ºï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„å›¾åƒç”Ÿæˆèƒ½åŠ›ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„æœºå™¨äººå§¿æ€ï¼›2) æå‡ºäº†åŸºäºçº¦æŸä¼˜åŒ–çš„åŠ¨ä½œæ ‡ç­¾ç”Ÿæˆæ–¹æ³•ï¼Œä¿è¯äº†ç”Ÿæˆå›¾åƒå’ŒåŠ¨ä½œçš„ç‰©ç†ä¸€è‡´æ€§ï¼›3) é’ˆå¯¹åŒè‡‚æ“ä½œåœºæ™¯ï¼Œè®¾è®¡äº†å¤¹çˆªä¸ç‰©ä½“ä¹‹é—´çš„æ¥è§¦çº¦æŸï¼Œæé«˜äº†ç”Ÿæˆæ•°æ®çš„åˆç†æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šROPAçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) Stable Diffusionçš„å¾®è°ƒç­–ç•¥ï¼ŒåŒ…æ‹¬ä½¿ç”¨å“ªäº›æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œä»¥åŠå¦‚ä½•è°ƒæ•´æ¨¡å‹çš„å‚æ•°ï¼›2) çº¦æŸä¼˜åŒ–æ–¹æ³•çš„è®¾è®¡ï¼ŒåŒ…æ‹¬é€‰æ‹©å“ªäº›çº¦æŸæ¡ä»¶ï¼Œä»¥åŠå¦‚ä½•æ±‚è§£ä¼˜åŒ–é—®é¢˜ï¼›3) å¤¹çˆªä¸ç‰©ä½“ä¹‹é—´çš„æ¥è§¦çº¦æŸçš„å…·ä½“å½¢å¼ï¼Œä»¥åŠå¦‚ä½•å°†å…¶èå…¥åˆ°ä¼˜åŒ–é—®é¢˜ä¸­ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦å¹³è¡¡å›¾åƒè´¨é‡ã€åŠ¨ä½œåˆç†æ€§å’Œç‰©ç†ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ROPAåœ¨5ä¸ªæ¨¡æ‹Ÿä»»åŠ¡å’Œ3ä¸ªçœŸå®ä¸–ç•Œä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ROPAæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•å’Œæ¶ˆèå®éªŒã€‚åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­ï¼ŒROPAåœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æœ€ä½³æ€§èƒ½ã€‚åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­ï¼ŒROPAä¹Ÿè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜æœºå™¨äººçš„æ“ä½œæ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼ŒROPAåœ¨æŸäº›ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡æ¯”åŸºçº¿æ–¹æ³•æé«˜äº†10%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ROPAå¯åº”ç”¨äºå„ç§éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®çš„æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚ç‰©ä½“æŠ“å–ã€è£…é…ã€æ“ä½œå·¥å…·ç­‰ã€‚é€šè¿‡ç”Ÿæˆæ›´å¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®ï¼Œå¯ä»¥æé«˜æœºå™¨äººçš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”çœŸå®ä¸–ç•Œçš„å¤æ‚ç¯å¢ƒã€‚è¯¥æ–¹æ³•è¿˜å¯ä»¥é™ä½æ•°æ®é‡‡é›†çš„æˆæœ¬ï¼ŒåŠ é€Ÿæœºå™¨äººæŠ€æœ¯çš„ç ”å‘å’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Training robust bimanual manipulation policies via imitation learning requires demonstration data with broad coverage over robot poses, contacts, and scene contexts. However, collecting diverse and precise real-world demonstrations is costly and time-consuming, which hinders scalability. Prior works have addressed this with data augmentation, typically for either eye-in-hand (wrist camera) setups with RGB inputs or for generating novel images without paired actions, leaving augmentation for eye-to-hand (third-person) RGB-D training with new action labels less explored. In this paper, we propose Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation (ROPA), an offline imitation learning data augmentation method that fine-tunes Stable Diffusion to synthesize third-person RGB and RGB-D observations of novel robot poses. Our approach simultaneously generates corresponding joint-space action labels while employing constrained optimization to enforce physical consistency through appropriate gripper-to-object contact constraints in bimanual scenarios. We evaluate our method on 5 simulated and 3 real-world tasks. Our results across 2625 simulation trials and 300 real-world trials demonstrate that ROPA outperforms baselines and ablations, showing its potential for scalable RGB and RGB-D data augmentation in eye-to-hand bimanual manipulation. Our project website is available at: https://ropaaug.github.io/.

