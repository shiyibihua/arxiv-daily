---
layout: default
title: PIE: Perception and Interaction Enhanced End-to-End Motion Planning for Autonomous Driving
---

# PIE: Perception and Interaction Enhanced End-to-End Motion Planning for Autonomous Driving

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.18609" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.18609v1</a>
  <a href="https://arxiv.org/pdf/2509.18609.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.18609v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.18609v1', 'PIE: Perception and Interaction Enhanced End-to-End Motion Planning for Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chengran Yuan, Zijian Lu, Zhanqi Zhang, Yimin Zhao, Zefan Huang, Shuo Sun, Jiawei Sun, Jiahui Li, Christina Dao Wen Lee, Dongen Li, Marcelo H. Ang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-23

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PIEï¼šé¢å‘è‡ªåŠ¨é©¾é©¶ï¼Œæå‡ºæ„ŸçŸ¥äº¤äº’å¢å¼ºçš„ç«¯åˆ°ç«¯è¿åŠ¨è§„åˆ’æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªåŠ¨é©¾é©¶` `ç«¯åˆ°ç«¯è¿åŠ¨è§„åˆ’` `å¤šæ¨¡æ€èåˆ` `Mamba` `æ„å›¾é¢„æµ‹` `åœºæ™¯ç†è§£` `è½¨è¿¹è§„åˆ’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç«¯åˆ°ç«¯è¿åŠ¨è§„åˆ’é¢ä¸´åœºæ™¯ç†è§£å’Œæœ‰æ•ˆé¢„æµ‹çš„æŒ‘æˆ˜ï¼Œé˜»ç¢äº†å…¶å¤§è§„æ¨¡éƒ¨ç½²ã€‚
2. PIEæ¡†æ¶é€šè¿‡é›†æˆå…ˆè¿›çš„æ„ŸçŸ¥ã€æ¨ç†å’Œæ„å›¾å»ºæ¨¡ï¼ŒåŠ¨æ€æ•æ‰è‡ªè½¦ä¸å‘¨å›´è½¦è¾†çš„äº¤äº’ã€‚
3. PIEåœ¨NAVSIMåŸºå‡†æµ‹è¯•ä¸­ï¼Œæ— éœ€é›†æˆå’Œæ•°æ®å¢å¼ºï¼Œè¶…è¶Šäº†ç°æœ‰æœ€ä½³æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºPIEï¼Œä¸€ç§å¼€åˆ›æ€§çš„æ¡†æ¶ï¼Œé›†æˆäº†å…ˆè¿›çš„æ„ŸçŸ¥ã€æ¨ç†å’Œæ„å›¾å»ºæ¨¡ï¼Œä»¥åŠ¨æ€æ•æ‰è‡ªè½¦ä¸å‘¨å›´è½¦è¾†ä¹‹é—´çš„äº¤äº’ã€‚å®ƒåŒ…å«ä¸€ä¸ªåŒå‘Mambaèåˆæ¨¡å—ï¼Œè§£å†³äº†ç›¸æœºå’Œæ¿€å…‰é›·è¾¾å¤šæ¨¡æ€èåˆä¸­çš„æ•°æ®å‹ç¼©æŸå¤±ã€‚åŒæ—¶ï¼Œä¸€ä¸ªæ–°é¢–çš„æ¨ç†å¢å¼ºè§£ç å™¨é›†æˆäº†Mambaå’Œæ··åˆä¸“å®¶æ¨¡å‹ï¼Œä»¥ä¿ƒè¿›ç¬¦åˆåœºæ™¯çš„é”šç‚¹é€‰æ‹©å’Œä¼˜åŒ–è‡ªé€‚åº”è½¨è¿¹æ¨ç†ã€‚PIEé‡‡ç”¨åŠ¨ä½œ-è¿åŠ¨äº¤äº’æ¨¡å—ï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨å‘¨å›´è½¦è¾†çš„çŠ¶æ€é¢„æµ‹æ¥æ”¹è¿›è‡ªè½¦è§„åˆ’ã€‚è¯¥æ¡†æ¶åœ¨NAVSIMåŸºå‡†ä¸Šè¿›è¡Œäº†å…¨é¢éªŒè¯ã€‚PIEåœ¨ä¸ä½¿ç”¨ä»»ä½•é›†æˆå’Œæ•°æ®å¢å¼ºæŠ€æœ¯çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†88.9çš„PDMåˆ†æ•°å’Œ85.6çš„EPDMåˆ†æ•°ï¼Œè¶…è¿‡äº†ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•çš„æ€§èƒ½ã€‚å…¨é¢çš„å®šé‡å’Œå®šæ€§åˆ†æè¡¨æ˜ï¼ŒPIEèƒ½å¤Ÿå¯é åœ°ç”Ÿæˆå¯è¡Œä¸”é«˜è´¨é‡çš„è‡ªè½¦è½¨è¿¹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç«¯åˆ°ç«¯è¿åŠ¨è§„åˆ’æ—¨åœ¨ç®€åŒ–è‡ªåŠ¨é©¾é©¶æµç¨‹ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ç†è§£å’Œå‘¨å›´è½¦è¾†è¡Œä¸ºé¢„æµ‹æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´å†³ç­–è´¨é‡ä¸‹é™ï¼Œéš¾ä»¥åº”å¯¹çœŸå®äº¤é€šç¯å¢ƒä¸­çš„å¤æ‚äº¤äº’ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆèåˆå¤šæ¨¡æ€æ•°æ®ï¼Œä¸”æ¨ç†èƒ½åŠ›æœ‰é™ï¼Œæ— æ³•å‡†ç¡®é¢„æµ‹å‘¨å›´è½¦è¾†çš„æ„å›¾ï¼Œä»è€Œå½±å“è‡ªè½¦è½¨è¿¹è§„åˆ’çš„å®‰å…¨æ€§ä¸æ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPIEçš„æ ¸å¿ƒåœ¨äºé€šè¿‡èåˆå…ˆè¿›çš„æ„ŸçŸ¥ã€æ¨ç†å’Œæ„å›¾å»ºæ¨¡æŠ€æœ¯ï¼Œæå‡ç«¯åˆ°ç«¯è¿åŠ¨è§„åˆ’çš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œå®ƒåˆ©ç”¨åŒå‘Mambaèåˆæ¨¡å—è§£å†³å¤šæ¨¡æ€æ•°æ®èåˆä¸­çš„ä¿¡æ¯æŸå¤±é—®é¢˜ï¼Œå¹¶é‡‡ç”¨æ¨ç†å¢å¼ºè§£ç å™¨æå‡åœºæ™¯ç†è§£å’Œè½¨è¿¹é¢„æµ‹èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒPIEè¿˜å¼•å…¥åŠ¨ä½œ-è¿åŠ¨äº¤äº’æ¨¡å—ï¼Œåˆ©ç”¨å‘¨å›´è½¦è¾†çš„çŠ¶æ€é¢„æµ‹æ¥ä¼˜åŒ–è‡ªè½¦è½¨è¿¹è§„åˆ’ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPIEæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) åŒå‘Mambaèåˆæ¨¡å—ï¼šç”¨äºèåˆç›¸æœºå’Œæ¿€å…‰é›·è¾¾ç­‰å¤šæ¨¡æ€è¾“å…¥æ•°æ®ï¼Œå‡å°‘ä¿¡æ¯æŸå¤±ã€‚2) æ¨ç†å¢å¼ºè§£ç å™¨ï¼šé›†æˆäº†Mambaå’Œæ··åˆä¸“å®¶æ¨¡å‹ï¼Œç”¨äºåœºæ™¯ç†è§£ã€é”šç‚¹é€‰æ‹©å’Œè½¨è¿¹æ¨ç†ã€‚3) åŠ¨ä½œ-è¿åŠ¨äº¤äº’æ¨¡å—ï¼šåˆ©ç”¨å‘¨å›´è½¦è¾†çš„çŠ¶æ€é¢„æµ‹æ¥ä¼˜åŒ–è‡ªè½¦è½¨è¿¹è§„åˆ’ã€‚æ•´ä½“æµç¨‹æ˜¯ä»å¤šæ¨¡æ€æ„ŸçŸ¥è¾“å…¥å¼€å§‹ï¼Œç»è¿‡èåˆå’Œæ¨ç†ï¼Œæœ€ç»ˆç”Ÿæˆè‡ªè½¦çš„è¿åŠ¨è½¨è¿¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šPIEçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) åŒå‘Mambaèåˆï¼šç›¸æ¯”äºä¼ ç»Ÿçš„èåˆæ–¹æ³•ï¼ŒåŒå‘Mambaèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°ä¿ç•™å¤šæ¨¡æ€æ•°æ®ä¸­çš„å…³é”®ä¿¡æ¯ï¼Œå‡å°‘ä¿¡æ¯å‹ç¼©å¸¦æ¥çš„æŸå¤±ã€‚2) æ¨ç†å¢å¼ºè§£ç å™¨ï¼šé€šè¿‡é›†æˆMambaå’Œæ··åˆä¸“å®¶æ¨¡å‹ï¼Œæå‡äº†æ¨¡å‹å¯¹å¤æ‚åœºæ™¯çš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œä»è€Œæ›´å‡†ç¡®åœ°é¢„æµ‹å‘¨å›´è½¦è¾†çš„æ„å›¾å’Œè¡Œä¸ºã€‚3) åŠ¨ä½œ-è¿åŠ¨äº¤äº’æ¨¡å—ï¼šå°†å‘¨å›´è½¦è¾†çš„çŠ¶æ€é¢„æµ‹çº³å…¥è‡ªè½¦è§„åˆ’ä¸­ï¼Œå®ç°äº†æ›´å®‰å…¨ã€æ›´é«˜æ•ˆçš„è¿åŠ¨è§„åˆ’ã€‚

**å…³é”®è®¾è®¡**ï¼šåŒå‘Mambaèåˆæ¨¡å—çš„å…·ä½“ç»“æ„æœªçŸ¥ï¼Œä½†å…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨Mambaæ¶æ„çš„åºåˆ—å»ºæ¨¡èƒ½åŠ›ï¼Œå¯¹å¤šæ¨¡æ€æ•°æ®è¿›è¡ŒåŒå‘å¤„ç†ï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰æ•°æ®ä¹‹é—´çš„å…³è”æ€§ã€‚æ¨ç†å¢å¼ºè§£ç å™¨ä¸­ï¼ŒMambaç”¨äºåºåˆ—å»ºæ¨¡ï¼Œæ··åˆä¸“å®¶æ¨¡å‹ç”¨äºå¤„ç†ä¸åŒåœºæ™¯ä¸‹çš„è½¨è¿¹é¢„æµ‹ã€‚åŠ¨ä½œ-è¿åŠ¨äº¤äº’æ¨¡å—çš„å…·ä½“å®ç°æ–¹å¼æœªçŸ¥ï¼Œä½†å…¶ç›®æ ‡æ˜¯æ ¹æ®å‘¨å›´è½¦è¾†çš„é¢„æµ‹çŠ¶æ€ï¼Œè°ƒæ•´è‡ªè½¦çš„è¿åŠ¨è½¨è¿¹ï¼Œä»¥é¿å…ç¢°æ’æˆ–æé«˜é€šè¡Œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PIEåœ¨NAVSIMåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œåœ¨ä¸ä½¿ç”¨ä»»ä½•é›†æˆå’Œæ•°æ®å¢å¼ºæŠ€æœ¯çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†88.9çš„PDMåˆ†æ•°å’Œ85.6çš„EPDMåˆ†æ•°ï¼Œè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™è¡¨æ˜PIEæ¡†æ¶åœ¨å¤æ‚åœºæ™¯ç†è§£å’Œè½¨è¿¹è§„åˆ’æ–¹é¢å…·æœ‰å¼ºå¤§çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿç”Ÿæˆå¯è¡Œä¸”é«˜è´¨é‡çš„è‡ªè½¦è½¨è¿¹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PIEæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºå„ç§è‡ªåŠ¨é©¾é©¶åœºæ™¯ï¼ŒåŒ…æ‹¬åŸå¸‚é“è·¯ã€é«˜é€Ÿå…¬è·¯å’Œåœè½¦åœºç­‰ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿæå‡è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§ã€æ•ˆç‡å’Œèˆ’é€‚æ€§ï¼Œå¹¶æœ‰æœ›åŠ é€Ÿè‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„å•†ä¸šåŒ–è½åœ°ã€‚æ­¤å¤–ï¼ŒPIEçš„è®¾è®¡æ€è·¯ä¹Ÿå¯ä»¥åº”ç”¨äºå…¶ä»–éœ€è¦å¤šæ¨¡æ€æ„ŸçŸ¥å’Œå¤æ‚æ¨ç†çš„æœºå™¨äººåº”ç”¨ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> End-to-end motion planning is promising for simplifying complex autonomous driving pipelines. However, challenges such as scene understanding and effective prediction for decision-making continue to present substantial obstacles to its large-scale deployment. In this paper, we present PIE, a pioneering framework that integrates advanced perception, reasoning, and intention modeling to dynamically capture interactions between the ego vehicle and surrounding agents. It incorporates a bidirectional Mamba fusion that addresses data compression losses in multimodal fusion of camera and LiDAR inputs, alongside a novel reasoning-enhanced decoder integrating Mamba and Mixture-of-Experts to facilitate scene-compliant anchor selection and optimize adaptive trajectory inference. PIE adopts an action-motion interaction module to effectively utilize state predictions of surrounding agents to refine ego planning. The proposed framework is thoroughly validated on the NAVSIM benchmark. PIE, without using any ensemble and data augmentation techniques, achieves an 88.9 PDM score and 85.6 EPDM score, surpassing the performance of prior state-of-the-art methods. Comprehensive quantitative and qualitative analyses demonstrate that PIE is capable of reliably generating feasible and high-quality ego trajectories.

