---
layout: default
title: Lang2Morph: Language-Driven Morphological Design of Robotic Hands
---

# Lang2Morph: Language-Driven Morphological Design of Robotic Hands

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.18937" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.18937v1</a>
  <a href="https://arxiv.org/pdf/2509.18937.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.18937v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.18937v1', 'Lang2Morph: Language-Driven Morphological Design of Robotic Hands')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yanyuan Qiao, Kieran Gilday, Yutong Xie, Josie Hughes

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-23

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Lang2Morphï¼šæå‡ºä¸€ç§åŸºäºè¯­è¨€é©±åŠ¨çš„æœºå™¨äººæ‰‹éƒ¨å½¢æ€è‡ªåŠ¨è®¾è®¡æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººæ‰‹éƒ¨è®¾è®¡` `å¤§å‹è¯­è¨€æ¨¡å‹` `å½¢æ€ç”Ÿæˆ` `ä»»åŠ¡é©±åŠ¨` `é›¶æ ·æœ¬å­¦ä¹ ` `å‚æ•°åŒ–è®¾è®¡` `OPH` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººæ‰‹éƒ¨å½¢æ€è®¾è®¡ä¾èµ–ä¸“å®¶ç»éªŒå’Œæ‰‹åŠ¨è°ƒæ•´ï¼Œè‡ªåŠ¨åŒ–æ–¹æ³•è®¡ç®—æˆæœ¬é«˜ï¼Œä¸”ä¾èµ–ä»¿çœŸç¯å¢ƒã€‚
2. Lang2Morphåˆ©ç”¨LLMç†è§£ä»»åŠ¡æè¿°ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºæœºå™¨äººæ‰‹éƒ¨å½¢æ€è®¾è®¡çš„å‚æ•°ï¼Œå®ç°é›¶æ ·æœ¬è®¾è®¡æ¨ç†ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLang2Morphèƒ½å¤Ÿä¸ºä¸åŒä»»åŠ¡ç”Ÿæˆå¤šæ ·ä¸”ç›¸å…³çš„æœºå™¨äººæ‰‹éƒ¨å½¢æ€ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„å¯è¡Œæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é’ˆå¯¹æœºå™¨äººæ‰‹éƒ¨å½¢æ€è®¾è®¡åœ¨çµå·§æ€§ã€å¯åˆ¶é€ æ€§å’Œä»»åŠ¡ç‰¹å®šåŠŸèƒ½ä¹‹é—´éš¾ä»¥å¹³è¡¡çš„é—®é¢˜ï¼Œä»¥åŠç°æœ‰æ–¹æ³•ä¾èµ–ä¸“å®¶ç»éªŒã€è®¡ç®—å¯†é›†å’Œä»¿çœŸä¾èµ–çš„å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºLang2Morphçš„è¯­è¨€é©±åŠ¨çš„æœºå™¨äººæ‰‹éƒ¨è®¾è®¡æµç¨‹ã€‚è¯¥æµç¨‹åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å°†è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°è½¬åŒ–ä¸ºç¬¦å·ç»“æ„å’Œä¸OPHå…¼å®¹çš„å‚æ•°ï¼Œä»è€Œå®ç°å¯3Dæ‰“å°çš„ã€ä»»åŠ¡ç‰¹å®šçš„æ‰‹éƒ¨å½¢æ€ã€‚Lang2MorphåŒ…å«å½¢æ€è®¾è®¡å’Œé€‰æ‹©ä¸ä¼˜åŒ–ä¸¤ä¸ªé˜¶æ®µã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå¤šæ ·ä¸”ä¸ä»»åŠ¡ç›¸å…³çš„å½¢æ€ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡å°è¯•å¼€å‘åŸºäºLLMçš„ã€ä»»åŠ¡æ¡ä»¶ä¸‹çš„æœºå™¨äººæ‰‹éƒ¨è®¾è®¡æ¡†æ¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœºå™¨äººæ‰‹éƒ¨å½¢æ€è®¾è®¡éœ€è¦åœ¨çµå·§æ€§ã€å¯åˆ¶é€ æ€§å’Œä»»åŠ¡ç‰¹å®šåŠŸèƒ½ä¹‹é—´å–å¾—å¹³è¡¡ã€‚ç°æœ‰çš„è®¾è®¡æ–¹æ³•é€šå¸¸ä¾èµ–äºä¸“å®¶ç»éªŒå’Œæ‰‹åŠ¨è°ƒæ•´ï¼Œè¿™æ—¢è€—æ—¶åˆéš¾ä»¥æ¨å¹¿ã€‚è‡ªåŠ¨åŒ–æ–¹æ³•ï¼Œå¦‚ä¼˜åŒ–ç®—æ³•ï¼Œå¾€å¾€è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œå¹¶ä¸”ä¸¥é‡ä¾èµ–ä»¿çœŸç¯å¢ƒï¼Œéš¾ä»¥ç›´æ¥åº”ç”¨äºçœŸå®ä¸–ç•Œçš„æœºå™¨äººæ‰‹éƒ¨è®¾è®¡ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å¾ˆå°‘èƒ½ç›´æ¥ç”Ÿæˆå…·æœ‰é«˜çµå·§æ€§çš„æ‰‹éƒ¨è®¾è®¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLang2Morphçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼ºå¤§è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œå°†è‡ªç„¶è¯­è¨€æè¿°çš„ä»»åŠ¡éœ€æ±‚è½¬åŒ–ä¸ºæœºå™¨äººæ‰‹éƒ¨å½¢æ€è®¾è®¡çš„å‚æ•°ã€‚é€šè¿‡å°†ä»»åŠ¡æè¿°è½¬åŒ–ä¸ºç»“æ„åŒ–çš„ç¬¦å·è¡¨ç¤ºï¼Œå¹¶è¿›ä¸€æ­¥æ˜ å°„åˆ°å¯ç”¨äºå‚æ•°åŒ–æ‰‹éƒ¨è®¾è®¡çš„å‚æ•°ï¼ŒLang2Morphå®ç°äº†ä»ä»»åŠ¡åˆ°å½¢æ€çš„ç›´æ¥æ˜ å°„ï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLang2MorphåŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š(1) å½¢æ€è®¾è®¡ï¼šè¯¥é˜¶æ®µå°†ä»»åŠ¡æè¿°æ˜ å°„ä¸ºè¯­ä¹‰æ ‡ç­¾ã€ç»“æ„è¯­æ³•å’Œä¸OPHï¼ˆOpen Hand Projectï¼‰å…¼å®¹çš„å‚æ•°ã€‚LLMé¦–å…ˆåˆ†æä»»åŠ¡æè¿°ï¼Œæå–å…³é”®çš„è¯­ä¹‰ä¿¡æ¯ï¼Œç„¶åæ ¹æ®é¢„å®šä¹‰çš„ç»“æ„è¯­æ³•ç”Ÿæˆæ‰‹éƒ¨å½¢æ€çš„ç»“æ„åŒ–æè¿°ï¼Œæœ€åå°†è¿™äº›ç»“æ„åŒ–æè¿°è½¬åŒ–ä¸ºOPHå‚æ•°ã€‚(2) é€‰æ‹©ä¸ä¼˜åŒ–ï¼šè¯¥é˜¶æ®µè¯„ä¼°å€™é€‰è®¾è®¡ï¼ŒåŸºäºè¯­ä¹‰å¯¹é½å’Œå°ºå¯¸å…¼å®¹æ€§è¿›è¡Œç­›é€‰ï¼Œå¹¶å¯é€‰æ‹©æ€§åœ°åº”ç”¨LLMå¼•å¯¼çš„ä¼˜åŒ–ã€‚å¦‚æœåˆå§‹è®¾è®¡ä¸æ»¡è¶³è¦æ±‚ï¼ŒLLMå¯ä»¥æ ¹æ®è¯„ä¼°ç»“æœè¿›è¡Œè¿­ä»£ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šLang2Morphçš„å…³é”®åˆ›æ–°åœ¨äºå°†LLMå¼•å…¥æœºå™¨äººæ‰‹éƒ¨å½¢æ€è®¾è®¡æµç¨‹ï¼Œå®ç°äº†ä»è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°åˆ°å¯æ‰§è¡Œè®¾è®¡å‚æ•°çš„ç›´æ¥è½¬æ¢ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºä¼˜åŒ–æˆ–ä»¿çœŸçš„æ–¹æ³•ç›¸æ¯”ï¼ŒLang2Morphæ— éœ€å¤§é‡çš„è®¡ç®—èµ„æºå’Œä»¿çœŸç¯å¢ƒï¼Œå¹¶ä¸”èƒ½å¤Ÿåˆ©ç”¨LLMçš„çŸ¥è¯†è¿›è¡Œé›¶æ ·æœ¬è®¾è®¡æ¨ç†ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•é€šè¿‡ç»“æ„åŒ–è¯­æ³•å’ŒOPHå‚æ•°çš„ç»“åˆï¼Œä¿è¯äº†ç”Ÿæˆè®¾è®¡çš„å¯åˆ¶é€ æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šLang2Morphçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) è¯­ä¹‰æ ‡ç­¾çš„å®šä¹‰ï¼šå®šä¹‰äº†ä¸€ç³»åˆ—ä¸æœºå™¨äººæ‰‹éƒ¨è®¾è®¡ç›¸å…³çš„è¯­ä¹‰æ ‡ç­¾ï¼Œç”¨äºæè¿°ä»»åŠ¡éœ€æ±‚ã€‚(2) ç»“æ„è¯­æ³•çš„æ„å»ºï¼šæ„å»ºäº†ä¸€å¥—ç»“æ„è¯­æ³•ï¼Œç”¨äºæè¿°æ‰‹éƒ¨å½¢æ€çš„ç»“æ„ç»„æˆå’Œè¿æ¥å…³ç³»ã€‚(3) OPHå‚æ•°çš„æ˜ å°„ï¼šå»ºç«‹äº†è¯­ä¹‰æ ‡ç­¾å’Œç»“æ„è¯­æ³•åˆ°OPHå‚æ•°çš„æ˜ å°„å…³ç³»ï¼Œä½¿å¾—LLMèƒ½å¤Ÿç”Ÿæˆä¸OPHå…¼å®¹çš„è®¾è®¡å‚æ•°ã€‚(4) LLMå¼•å¯¼çš„ä¼˜åŒ–ï¼šåˆ©ç”¨LLMæ ¹æ®è¯„ä¼°ç»“æœå¯¹è®¾è®¡å‚æ•°è¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œä»¥æé«˜è®¾è®¡çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Lang2Morphåœ¨ä¸åŒä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå¤šæ ·ä¸”ä¸ä»»åŠ¡ç›¸å…³çš„æœºå™¨äººæ‰‹éƒ¨å½¢æ€ã€‚é€šè¿‡å°†è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„è®¾è®¡å‚æ•°ï¼ŒLang2Morphå®ç°äº†é›¶æ ·æœ¬çš„æ‰‹éƒ¨è®¾è®¡ï¼Œæ— éœ€å¤§é‡çš„è®¡ç®—èµ„æºå’Œä»¿çœŸç¯å¢ƒã€‚è¯¥ç ”ç©¶ä¸ºåŸºäºLLMçš„æœºå™¨äººè®¾è®¡å¼€è¾Ÿäº†æ–°çš„æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Lang2Morphå¯åº”ç”¨äºå¿«é€Ÿå®šåˆ¶æœºå™¨äººæ‰‹éƒ¨å½¢æ€ä»¥é€‚åº”å„ç§æ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚åœ¨åˆ¶é€ ä¸šä¸­ä¸ºç‰¹å®šé›¶ä»¶æŠ“å–è®¾è®¡ä¸“ç”¨æ‰‹çˆªï¼Œæˆ–åœ¨å®¶åº­æœåŠ¡æœºå™¨äººä¸­è®¾è®¡ç”¨äºå¤„ç†ä¸åŒç‰©å“çš„æ‰‹éƒ¨ã€‚è¯¥ç ”ç©¶æœ‰æœ›åŠ é€Ÿæœºå™¨äººæ‰‹éƒ¨è®¾è®¡çš„è¿­ä»£è¿‡ç¨‹ï¼Œé™ä½è®¾è®¡æˆæœ¬ï¼Œå¹¶ä¿ƒè¿›æœºå™¨äººæŠ€æœ¯åœ¨æ›´å¹¿æ³›é¢†åŸŸçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Designing robotic hand morphologies for diverse manipulation tasks requires balancing dexterity, manufacturability, and task-specific functionality. While open-source frameworks and parametric tools support reproducible design, they still rely on expert heuristics and manual tuning. Automated methods using optimization are often compute-intensive, simulation-dependent, and rarely target dexterous hands. Large language models (LLMs), with their broad knowledge of human-object interactions and strong generative capabilities, offer a promising alternative for zero-shot design reasoning. In this paper, we present Lang2Morph, a language-driven pipeline for robotic hand design. It uses LLMs to translate natural-language task descriptions into symbolic structures and OPH-compatible parameters, enabling 3D-printable task-specific morphologies. The pipeline consists of: (i) Morphology Design, which maps tasks into semantic tags, structural grammars, and OPH-compatible parameters; and (ii) Selection and Refinement, which evaluates design candidates based on semantic alignment and size compatibility, and optionally applies LLM-guided refinement when needed. We evaluate Lang2Morph across varied tasks, and results show that our approach can generate diverse, task-relevant morphologies. To our knowledge, this is the first attempt to develop an LLM-based framework for task-conditioned robotic hand design.

