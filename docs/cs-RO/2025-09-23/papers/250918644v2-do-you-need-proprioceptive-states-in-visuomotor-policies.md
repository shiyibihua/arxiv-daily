---
layout: default
title: Do You Need Proprioceptive States in Visuomotor Policies?
---

# Do You Need Proprioceptive States in Visuomotor Policies?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.18644" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.18644v2</a>
  <a href="https://arxiv.org/pdf/2509.18644.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.18644v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.18644v2', 'Do You Need Proprioceptive States in Visuomotor Policies?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Juntu Zhao, Wenbo Lu, Di Zhang, Yufeng Liu, Yushen Liang, Tianluo Zhang, Yifeng Cao, Junyuan Xie, Yingdong Hu, Shengjie Wang, Junliang Guo, Dequan Wang, Yang Gao

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-23 (æ›´æ–°: 2025-09-24)

**å¤‡æ³¨**: Project page: https://statefreepolicy.github.io

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºState-freeç­–ç•¥ï¼Œè§£å†³åŸºäºæ¨¡ä»¿å­¦ä¹ çš„æœºå™¨äººæ“ä½œä¸­å¯¹æœ¬ä½“æ„Ÿå—çŠ¶æ€çš„è¿‡åº¦ä¾èµ–é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `æ¨¡ä»¿å­¦ä¹ ` `è§†è§‰ä¼ºæœ` `ç©ºé—´æ³›åŒ–` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿæ¨¡ä»¿å­¦ä¹ æœºå™¨äººç­–ç•¥è¿‡åº¦ä¾èµ–æœ¬ä½“æ„Ÿå—çŠ¶æ€ï¼Œå¯¼è‡´ç©ºé—´æ³›åŒ–èƒ½åŠ›å·®ï¼Œæ˜“è¿‡æ‹Ÿåˆã€‚
2. æå‡ºState-freeç­–ç•¥ï¼Œä»…ä¾èµ–è§†è§‰ä¿¡æ¯é¢„æµ‹åŠ¨ä½œï¼Œé¿å…å¯¹æœ¬ä½“æ„Ÿå—çŠ¶æ€çš„ä¾èµ–ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒState-freeç­–ç•¥åœ¨çœŸå®æœºå™¨äººä»»åŠ¡ä¸­æ˜¾è‘—æå‡ç©ºé—´æ³›åŒ–èƒ½åŠ›å’Œæ•°æ®æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºæ¨¡ä»¿å­¦ä¹ çš„è§†è§‰è¿åŠ¨ç­–ç•¥å·²å¹¿æ³›åº”ç”¨äºæœºå™¨äººæ“ä½œä¸­ï¼Œé€šå¸¸è§†è§‰è§‚æµ‹å’Œæœ¬ä½“æ„Ÿå—çŠ¶æ€è¢«å…±åŒç”¨äºç²¾ç¡®æ§åˆ¶ã€‚ç„¶è€Œï¼Œæœ¬ç ”ç©¶å‘ç°ï¼Œè¿™ç§å¸¸è§åšæ³•ä½¿å¾—ç­–ç•¥è¿‡åº¦ä¾èµ–äºæœ¬ä½“æ„Ÿå—çŠ¶æ€è¾“å…¥ï¼Œå¯¼è‡´å¯¹è®­ç»ƒè½¨è¿¹çš„è¿‡æ‹Ÿåˆï¼Œå¹¶å¯¼è‡´è¾ƒå·®çš„ç©ºé—´æ³›åŒ–èƒ½åŠ›ã€‚ç›¸åï¼Œæˆ‘ä»¬æå‡ºäº†State-freeç­–ç•¥ï¼Œç§»é™¤äº†æœ¬ä½“æ„Ÿå—çŠ¶æ€è¾“å…¥ï¼Œä»…æ ¹æ®è§†è§‰è§‚æµ‹é¢„æµ‹åŠ¨ä½œã€‚State-freeç­–ç•¥æ„å»ºåœ¨ç›¸å¯¹æœ«ç«¯æ‰§è¡Œå™¨åŠ¨ä½œç©ºé—´ä¸­ï¼Œå¹¶åº”ç¡®ä¿æ‰€æœ‰ä»»åŠ¡ç›¸å…³çš„è§†è§‰è§‚æµ‹ï¼Œè¿™é‡Œç”±åŒå¹¿è§’è…•éƒ¨ç›¸æœºæä¾›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒState-freeç­–ç•¥å®ç°äº†æ¯”åŸºäºçŠ¶æ€çš„ç­–ç•¥æ˜¾è‘—æ›´å¼ºçš„ç©ºé—´æ³›åŒ–èƒ½åŠ›ï¼šåœ¨ç°å®ä¸–ç•Œçš„ä»»åŠ¡ä¸­ï¼Œå¦‚æŠ“å–æ”¾ç½®ã€å…·æœ‰æŒ‘æˆ˜æ€§çš„è¡¬è¡«æŠ˜å å’Œå¤æ‚çš„å…¨èº«æ“ä½œï¼Œè·¨è¶Šå¤šä¸ªæœºå™¨äººå®ä½“ï¼Œå¹³å‡æˆåŠŸç‡åœ¨é«˜åº¦æ³›åŒ–æ–¹é¢ä»0%æé«˜åˆ°85%ï¼Œåœ¨æ°´å¹³æ³›åŒ–æ–¹é¢ä»6%æé«˜åˆ°64%ã€‚æ­¤å¤–ï¼Œå®ƒä»¬è¿˜æ˜¾ç¤ºå‡ºåœ¨æ•°æ®æ•ˆç‡å’Œè·¨å®ä½“é€‚åº”æ–¹é¢çš„ä¼˜åŠ¿ï¼Œå¢å¼ºäº†å®ƒä»¬åœ¨ç°å®ä¸–ç•Œéƒ¨ç½²ä¸­çš„å®ç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºæ¨¡ä»¿å­¦ä¹ çš„æœºå™¨äººæ“ä½œç­–ç•¥é€šå¸¸åŒæ—¶ä½¿ç”¨è§†è§‰è§‚æµ‹å’Œæœ¬ä½“æ„Ÿå—çŠ¶æ€è¿›è¡Œæ§åˆ¶ã€‚ç„¶è€Œï¼Œè¿™ç§åšæ³•å¯¼è‡´ç­–ç•¥è¿‡åº¦ä¾èµ–æœ¬ä½“æ„Ÿå—çŠ¶æ€ï¼Œä½¿å¾—æ¨¡å‹å®¹æ˜“è¿‡æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œåœ¨æ–°çš„ç©ºé—´ä½ç½®æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚å°¤å…¶æ˜¯åœ¨çœŸå®æœºå™¨äººä»»åŠ¡ä¸­ï¼Œæœ¬ä½“æ„Ÿå—å™¨çš„å™ªå£°å’Œæ ¡å‡†è¯¯å·®ä¼šè¿›ä¸€æ­¥é™ä½ç­–ç•¥çš„æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç§»é™¤æœ¬ä½“æ„Ÿå—çŠ¶æ€çš„è¾“å…¥ï¼Œä»…ä½¿ç”¨è§†è§‰ä¿¡æ¯æ¥é¢„æµ‹æœºå™¨äººçš„åŠ¨ä½œã€‚ä½œè€…è®¤ä¸ºï¼Œå¦‚æœè§†è§‰ä¿¡æ¯è¶³å¤Ÿä¸°å¯Œï¼Œå¹¶ä¸”ç­–ç•¥èƒ½å¤Ÿå­¦ä¹ åˆ°è§†è§‰ä¿¡æ¯å’ŒåŠ¨ä½œä¹‹é—´çš„æ­£ç¡®æ˜ å°„å…³ç³»ï¼Œå°±å¯ä»¥å®ç°è‰¯å¥½çš„æ§åˆ¶æ•ˆæœå’Œæ³›åŒ–èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•å¯ä»¥é¿å…æ¨¡å‹å¯¹æœ¬ä½“æ„Ÿå—çŠ¶æ€çš„è¿‡åº¦ä¾èµ–ï¼Œä»è€Œæé«˜æ¨¡å‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šState-freeç­–ç•¥çš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1) åŒå¹¿è§’è…•éƒ¨ç›¸æœºæä¾›ä¸°å¯Œçš„è§†è§‰è§‚æµ‹ï¼›2) ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æå–è§†è§‰ç‰¹å¾ï¼›3) ä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å¤„ç†æ—¶åºè§†è§‰ç‰¹å¾ï¼›4) ä½¿ç”¨å…¨è¿æ¥å±‚é¢„æµ‹ç›¸å¯¹æœ«ç«¯æ‰§è¡Œå™¨åŠ¨ä½œã€‚æ•´ä¸ªæ¡†æ¶é‡‡ç”¨ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œç›´æ¥ä»è§†è§‰è¾“å…¥åˆ°åŠ¨ä½œè¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå®Œå…¨ç§»é™¤äº†æœ¬ä½“æ„Ÿå—çŠ¶æ€çš„è¾“å…¥ï¼Œä»…ä¾èµ–è§†è§‰ä¿¡æ¯è¿›è¡Œæ§åˆ¶ã€‚è¿™ä¸ä¼ ç»Ÿçš„æ¨¡ä»¿å­¦ä¹ æ–¹æ³•å½¢æˆäº†é²œæ˜å¯¹æ¯”ï¼Œä¼ ç»Ÿæ–¹æ³•é€šå¸¸éœ€è¦åŒæ—¶ä½¿ç”¨è§†è§‰å’Œæœ¬ä½“æ„Ÿå—ä¿¡æ¯ã€‚State-freeç­–ç•¥çš„è®¾è®¡ç†å¿µæ˜¯ï¼Œå¦‚æœè§†è§‰ä¿¡æ¯è¶³å¤Ÿå……åˆ†ï¼Œå°±å¯ä»¥å­¦ä¹ åˆ°æœ‰æ•ˆçš„æ§åˆ¶ç­–ç•¥ï¼Œè€Œæ— éœ€ä¾èµ–æœ¬ä½“æ„Ÿå—çŠ¶æ€ã€‚

**å…³é”®è®¾è®¡**ï¼šState-freeç­–ç•¥çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨åŒå¹¿è§’è…•éƒ¨ç›¸æœºæä¾›å…¨é¢çš„è§†è§‰è§‚æµ‹ï¼Œç¡®ä¿ç­–ç•¥èƒ½å¤Ÿè·å–æ‰€æœ‰ä»»åŠ¡ç›¸å…³çš„è§†è§‰ä¿¡æ¯ï¼›2) åœ¨ç›¸å¯¹æœ«ç«¯æ‰§è¡Œå™¨åŠ¨ä½œç©ºé—´ä¸­è¿›è¡ŒåŠ¨ä½œé¢„æµ‹ï¼Œé¿å…ç»å¯¹åæ ‡å¸¦æ¥çš„è¯¯å·®ï¼›3) ä½¿ç”¨æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œä¾‹å¦‚éšæœºè£å‰ªã€æ—‹è½¬å’Œç¼©æ”¾ï¼Œæ¥æé«˜æ¨¡å‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼›4) ä½¿ç”¨è¡Œä¸ºå…‹éš†ï¼ˆBehavior Cloningï¼‰ç®—æ³•è¿›è¡Œè®­ç»ƒï¼Œæœ€å°åŒ–é¢„æµ‹åŠ¨ä½œå’Œä¸“å®¶åŠ¨ä½œä¹‹é—´çš„å·®å¼‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒState-freeç­–ç•¥åœ¨çœŸå®æœºå™¨äººä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨é«˜åº¦æ³›åŒ–æ–¹é¢ï¼ŒæˆåŠŸç‡ä»0%æé«˜åˆ°85%ï¼›åœ¨æ°´å¹³æ³›åŒ–æ–¹é¢ï¼ŒæˆåŠŸç‡ä»6%æé«˜åˆ°64%ã€‚æ­¤å¤–ï¼ŒState-freeç­–ç•¥è¿˜è¡¨ç°å‡ºæ›´å¥½çš„æ•°æ®æ•ˆç‡å’Œè·¨å®ä½“é€‚åº”èƒ½åŠ›ï¼Œè¿™æ„å‘³ç€å®ƒå¯ä»¥ä½¿ç”¨æ›´å°‘çš„æ•°æ®è®­ç»ƒå‡ºæ›´å¥½çš„æ¨¡å‹ï¼Œå¹¶ä¸”å¯ä»¥æ›´å®¹æ˜“åœ°è¿ç§»åˆ°ä¸åŒçš„æœºå™¨äººå¹³å°ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜ç²¾åº¦å’Œå¼ºæ³›åŒ–èƒ½åŠ›çš„åœºæ™¯ä¸­ï¼Œä¾‹å¦‚å·¥ä¸šè‡ªåŠ¨åŒ–ã€å®¶åº­æœåŠ¡æœºå™¨äººã€åŒ»ç–—æœºå™¨äººç­‰ã€‚é€šè¿‡å‡å°‘å¯¹æœ¬ä½“æ„Ÿå—å™¨çš„ä¾èµ–ï¼Œå¯ä»¥é™ä½æœºå™¨äººç³»ç»Ÿçš„æˆæœ¬å’Œå¤æ‚æ€§ï¼Œæé«˜å…¶å¯é æ€§å’Œæ˜“ç”¨æ€§ï¼ŒåŠ é€Ÿæœºå™¨äººåœ¨ç°å®ä¸–ç•Œä¸­çš„éƒ¨ç½²ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Imitation-learning-based visuomotor policies have been widely used in robot manipulation, where both visual observations and proprioceptive states are typically adopted together for precise control. However, in this study, we find that this common practice makes the policy overly reliant on the proprioceptive state input, which causes overfitting to the training trajectories and results in poor spatial generalization. On the contrary, we propose the State-free Policy, removing the proprioceptive state input and predicting actions only conditioned on visual observations. The State-free Policy is built in the relative end-effector action space, and should ensure the full task-relevant visual observations, here provided by dual wide-angle wrist cameras. Empirical results demonstrate that the State-free policy achieves significantly stronger spatial generalization than the state-based policy: in real-world tasks such as pick-and-place, challenging shirt-folding, and complex whole-body manipulation, spanning multiple robot embodiments, the average success rate improves from 0% to 85% in height generalization and from 6% to 64% in horizontal generalization. Furthermore, they also show advantages in data efficiency and cross-embodiment adaptation, enhancing their practicality for real-world deployment. Discover more by visiting: https://statefreepolicy.github.io.

