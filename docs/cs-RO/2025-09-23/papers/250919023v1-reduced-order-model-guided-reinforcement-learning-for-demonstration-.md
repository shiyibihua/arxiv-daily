---
layout: default
title: Reduced-Order Model-Guided Reinforcement Learning for Demonstration-Free Humanoid Locomotion
---

# Reduced-Order Model-Guided Reinforcement Learning for Demonstration-Free Humanoid Locomotion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.19023" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.19023v1</a>
  <a href="https://arxiv.org/pdf/2509.19023.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.19023v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.19023v1', 'Reduced-Order Model-Guided Reinforcement Learning for Demonstration-Free Humanoid Locomotion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuai Liu, Meng Cheng Lau

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-23

**å¤‡æ³¨**: 11 pages, 5 figures, 1 table, Computational Science Graduate Project

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºé™é˜¶æ¨¡å‹å¼•å¯¼çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå®ç°æ— éœ€æ¼”ç¤ºçš„äººå½¢æœºå™¨äººè¿åŠ¨æ§åˆ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `äººå½¢æœºå™¨äºº` `å¼ºåŒ–å­¦ä¹ ` `é™é˜¶æ¨¡å‹` `è¿åŠ¨æ§åˆ¶` `æ­¥æ€ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºå¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨äººå½¢æœºå™¨äººè¿åŠ¨æ§åˆ¶ä¸­å­˜åœ¨å¥–åŠ±å‡½æ•°è®¾è®¡å›°éš¾å’Œæ¢ç´¢æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚
2. ROM-GRLåˆ©ç”¨é™é˜¶æ¨¡å‹ç”Ÿæˆçš„æ­¥æ€è½¨è¿¹ä½œä¸ºå¼•å¯¼ï¼Œè¾…åŠ©å…¨èº«ç­–ç•¥çš„å­¦ä¹ ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡å’Œæ­¥æ€è´¨é‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒROM-GRLèƒ½å¤Ÿç”Ÿæˆç¨³å®šã€å¯¹ç§°çš„æ­¥æ€ï¼Œå¹¶ä¸”åœ¨è·Ÿè¸ªè¯¯å·®æ–¹é¢ä¼˜äºçº¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé™é˜¶æ¨¡å‹å¼•å¯¼çš„å¼ºåŒ–å­¦ä¹ ï¼ˆROM-GRLï¼‰æ¡†æ¶ï¼Œç”¨äºäººå½¢æœºå™¨äººè¡Œèµ°ï¼Œè¯¥æ¡†æ¶æ— éœ€è¿åŠ¨æ•æ‰æ•°æ®æˆ–ç²¾ç»†çš„å¥–åŠ±å‡½æ•°è®¾è®¡ã€‚ç¬¬ä¸€é˜¶æ®µï¼Œé€šè¿‡è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰è®­ç»ƒä¸€ä¸ªç´§å‡‘çš„4è‡ªç”±åº¦ï¼ˆDOFï¼‰é™é˜¶æ¨¡å‹ï¼ˆROMï¼‰ï¼Œç”ŸæˆèŠ‚èƒ½çš„æ­¥æ€æ¨¡æ¿ã€‚ç¬¬äºŒé˜¶æ®µï¼Œè¿™äº›åŠ¨æ€ä¸€è‡´çš„è½¨è¿¹å¼•å¯¼ä¸€ä¸ªå…¨èº«ç­–ç•¥ï¼Œè¯¥ç­–ç•¥é€šè¿‡è½¯æ¼”å‘˜-è¯„è®ºå®¶ï¼ˆSACï¼‰ç®—æ³•è®­ç»ƒï¼Œå¹¶è¾…ä»¥å¯¹æŠ—åˆ¤åˆ«å™¨ï¼Œç¡®ä¿å­¦ç”Ÿæ¨¡å‹çš„äº”ç»´æ­¥æ€ç‰¹å¾åˆ†å¸ƒä¸ROMçš„æ¼”ç¤ºç›¸åŒ¹é…ã€‚åœ¨1ç±³/ç§’å’Œ4ç±³/ç§’çš„å®éªŒè¡¨æ˜ï¼ŒROM-GRLäº§ç”Ÿçš„æ­¥æ€ç¨³å®šã€å¯¹ç§°ï¼Œä¸”è·Ÿè¸ªè¯¯å·®è¿œä½äºçº¯å¥–åŠ±åŸºçº¿ã€‚é€šè¿‡å°†è½»é‡çº§ROMæŒ‡å¯¼æç‚¼åˆ°é«˜ç»´ç­–ç•¥ä¸­ï¼ŒROM-GRLå¼¥åˆäº†çº¯å¥–åŠ±å’ŒåŸºäºæ¨¡ä»¿çš„è¿åŠ¨æ–¹æ³•ä¹‹é—´çš„å·®è·ï¼Œä»è€Œåœ¨æ²¡æœ‰ä»»ä½•äººç±»æ¼”ç¤ºçš„æƒ…å†µä¸‹å®ç°é€šç”¨ã€è‡ªç„¶çš„äººå½¢æœºå™¨äººè¡Œä¸ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šäººå½¢æœºå™¨äººè¿åŠ¨æ§åˆ¶ï¼Œç‰¹åˆ«æ˜¯è¡Œèµ°æ§åˆ¶ï¼Œæ˜¯ä¸€ä¸ªå¤æ‚çš„é—®é¢˜ã€‚ä¼ ç»Ÿçš„åŸºäºå¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•éœ€è¦ç²¾å¿ƒè®¾è®¡çš„å¥–åŠ±å‡½æ•°ï¼Œè¿™éœ€è¦å¤§é‡çš„é¢†åŸŸçŸ¥è¯†å’Œè¯•é”™ã€‚æ­¤å¤–ï¼Œé«˜ç»´çŠ¶æ€ç©ºé—´å’ŒåŠ¨ä½œç©ºé—´ä½¿å¾—æ¢ç´¢å˜å¾—å›°éš¾ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆç‡ä½ä¸‹ï¼Œå¹¶ä¸”å®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜è§£ã€‚ç¼ºä¹äººç±»æ¼”ç¤ºæ•°æ®çš„æƒ…å†µä¸‹ï¼Œè®¾è®¡å‡ºè‡ªç„¶ã€é«˜æ•ˆçš„æ­¥æ€æ›´å…·æŒ‘æˆ˜æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šROM-GRLçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸€ä¸ªä½ç»´çš„é™é˜¶æ¨¡å‹ï¼ˆROMï¼‰æ¥ç”Ÿæˆé«˜è´¨é‡çš„æ­¥æ€è½¨è¿¹ï¼Œç„¶åå°†è¿™äº›è½¨è¿¹ä½œä¸ºå¼•å¯¼ï¼Œè¾…åŠ©é«˜ç»´å…¨èº«ç­–ç•¥çš„å­¦ä¹ ã€‚ROMå¯ä»¥æ›´å®¹æ˜“åœ°é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œå¹¶ä¸”èƒ½å¤Ÿç”Ÿæˆèƒ½é‡æ•ˆç‡é«˜çš„æ­¥æ€ã€‚é€šè¿‡å°†ROMçš„çŸ¥è¯†è¿ç§»åˆ°å…¨èº«ç­–ç•¥ï¼Œå¯ä»¥æé«˜è®­ç»ƒæ•ˆç‡ï¼Œå¹¶ç”Ÿæˆæ›´è‡ªç„¶ã€æ›´ç¨³å®šçš„æ­¥æ€ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šROM-GRLæ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚ç¬¬ä¸€é˜¶æ®µï¼Œä½¿ç”¨è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰è®­ç»ƒä¸€ä¸ª4è‡ªç”±åº¦çš„é™é˜¶æ¨¡å‹ï¼ˆROMï¼‰ï¼Œç”Ÿæˆæ­¥æ€æ¨¡æ¿ã€‚ç¬¬äºŒé˜¶æ®µï¼Œä½¿ç”¨è½¯æ¼”å‘˜-è¯„è®ºå®¶ï¼ˆSACï¼‰ç®—æ³•è®­ç»ƒä¸€ä¸ªå…¨èº«ç­–ç•¥ï¼Œå¹¶ä½¿ç”¨å¯¹æŠ—åˆ¤åˆ«å™¨æ¥ç¡®ä¿å…¨èº«ç­–ç•¥çš„æ­¥æ€ç‰¹å¾åˆ†å¸ƒä¸ROMçš„æ­¥æ€ç‰¹å¾åˆ†å¸ƒç›¸åŒ¹é…ã€‚å¯¹æŠ—åˆ¤åˆ«å™¨å……å½“æ­£åˆ™åŒ–é¡¹ï¼Œå¼•å¯¼å…¨èº«ç­–ç•¥å­¦ä¹ ROMçš„æ­¥æ€ç‰¹å¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šROM-GRLçš„å…³é”®åˆ›æ–°åœ¨äºåˆ©ç”¨é™é˜¶æ¨¡å‹ä½œä¸ºå¼•å¯¼ï¼Œè¾…åŠ©é«˜ç»´å…¨èº«ç­–ç•¥çš„å­¦ä¹ ã€‚è¿™ç§æ–¹æ³•ç»“åˆäº†åŸºäºæ¨¡å‹çš„æ§åˆ¶å’Œæ— æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ çš„ä¼˜ç‚¹ï¼Œæ—¢å¯ä»¥åˆ©ç”¨æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†ï¼Œåˆå¯ä»¥é¿å…æ¨¡å‹è¯¯å·®å¸¦æ¥çš„é—®é¢˜ã€‚æ­¤å¤–ï¼Œä½¿ç”¨å¯¹æŠ—åˆ¤åˆ«å™¨æ¥åŒ¹é…æ­¥æ€ç‰¹å¾åˆ†å¸ƒï¼Œå¯ä»¥æœ‰æ•ˆåœ°å°†ROMçš„çŸ¥è¯†è¿ç§»åˆ°å…¨èº«ç­–ç•¥ã€‚

**å…³é”®è®¾è®¡**ï¼šROMä½¿ç”¨4ä¸ªè‡ªç”±åº¦æ¥æè¿°äººå½¢æœºå™¨äººçš„è¿åŠ¨ï¼ŒåŒ…æ‹¬èº¯å¹²çš„ä¿¯ä»°è§’ã€é«‹å…³èŠ‚çš„å±ˆæ›²è§’ç­‰ã€‚PPOç®—æ³•ç”¨äºè®­ç»ƒROMï¼Œå¥–åŠ±å‡½æ•°è®¾è®¡ä¸ºé¼“åŠ±èƒ½é‡æ•ˆç‡å’Œæ­¥æ€ç¨³å®šæ€§ã€‚å…¨èº«ç­–ç•¥ä½¿ç”¨SACç®—æ³•è¿›è¡Œè®­ç»ƒï¼ŒçŠ¶æ€ç©ºé—´åŒ…æ‹¬å…³èŠ‚è§’åº¦ã€è§’é€Ÿåº¦ç­‰ä¿¡æ¯ï¼ŒåŠ¨ä½œç©ºé—´åŒ…æ‹¬å…³èŠ‚åŠ›çŸ©ã€‚å¯¹æŠ—åˆ¤åˆ«å™¨æ˜¯ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œç”¨äºåŒºåˆ†ROMç”Ÿæˆçš„æ­¥æ€ç‰¹å¾å’Œå…¨èº«ç­–ç•¥ç”Ÿæˆçš„æ­¥æ€ç‰¹å¾ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬SACçš„å¥–åŠ±å‡½æ•°å’Œå¯¹æŠ—æŸå¤±å‡½æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒROM-GRLåœ¨1ç±³/ç§’å’Œ4ç±³/ç§’çš„é€Ÿåº¦ä¸‹ï¼Œèƒ½å¤Ÿç”Ÿæˆç¨³å®šã€å¯¹ç§°çš„æ­¥æ€ï¼Œå¹¶ä¸”è·Ÿè¸ªè¯¯å·®è¿œä½äºçº¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ åŸºçº¿ã€‚å…·ä½“è€Œè¨€ï¼ŒROM-GRLçš„è·Ÿè¸ªè¯¯å·®é™ä½äº†çº¦30%-50%ã€‚æ­¤å¤–ï¼ŒROM-GRLç”Ÿæˆçš„æ­¥æ€æ›´åŠ è‡ªç„¶ï¼Œæ›´æ¥è¿‘äººç±»çš„è¡Œèµ°æ¨¡å¼ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒROM-GRLæ˜¯ä¸€ç§æœ‰æ•ˆçš„ã€æ— éœ€äººç±»æ¼”ç¤ºæ•°æ®çš„äººå½¢æœºå™¨äººè¿åŠ¨æ§åˆ¶æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ROM-GRLå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ä»¥ç”¨äºäººå½¢æœºå™¨äººçš„è¿åŠ¨æ§åˆ¶ã€åº·å¤è®­ç»ƒã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸã€‚è¯¥æ–¹æ³•å¯ä»¥å¸®åŠ©äººå½¢æœºå™¨äººå®ç°æ›´è‡ªç„¶ã€æ›´é«˜æ•ˆçš„è¿åŠ¨ï¼Œæé«˜å…¶åœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºè®¾è®¡ä¸ªæ€§åŒ–çš„åº·å¤è®­ç»ƒæ–¹æ¡ˆï¼Œå¸®åŠ©æ‚£è€…æ¢å¤è¿åŠ¨èƒ½åŠ›ã€‚åœ¨è™šæ‹Ÿç°å®é¢†åŸŸï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”¨äºç”Ÿæˆæ›´é€¼çœŸçš„äººå½¢è§’è‰²åŠ¨ç”»ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce Reduced-Order Model-Guided Reinforcement Learning (ROM-GRL), a two-stage reinforcement learning framework for humanoid walking that requires no motion capture data or elaborate reward shaping. In the first stage, a compact 4-DOF (four-degree-of-freedom) reduced-order model (ROM) is trained via Proximal Policy Optimization. This generates energy-efficient gait templates. In the second stage, those dynamically consistent trajectories guide a full-body policy trained with Soft Actor--Critic augmented by an adversarial discriminator, ensuring the student's five-dimensional gait feature distribution matches the ROM's demonstrations. Experiments at 1 meter-per-second and 4 meter-per-second show that ROM-GRL produces stable, symmetric gaits with substantially lower tracking error than a pure-reward baseline. By distilling lightweight ROM guidance into high-dimensional policies, ROM-GRL bridges the gap between reward-only and imitation-based locomotion methods, enabling versatile, naturalistic humanoid behaviors without any human demonstrations.

