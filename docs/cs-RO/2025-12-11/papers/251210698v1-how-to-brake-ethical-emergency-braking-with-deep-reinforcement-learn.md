---
layout: default
title: How to Brake? Ethical Emergency Braking with Deep Reinforcement Learning
---

# How to Brake? Ethical Emergency Braking with Deep Reinforcement Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.10698" target="_blank" class="toolbar-btn">arXiv: 2512.10698v1</a>
    <a href="https://arxiv.org/pdf/2512.10698.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10698v1" 
            onclick="toggleFavorite(this, '2512.10698v1', 'How to Brake? Ethical Emergency Braking with Deep Reinforcement Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jianbo Wang, Galina Sidorenko, Johan Thunberg

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-11

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÁöÑÊ∑∑ÂêàÁ¥ßÊÄ•Âà∂Âä®ÊñπÊ≥ïÔºåÊèêÂçáÂ§öËΩ¶ÂçèÂêåÂú∫ÊôØ‰∏ãÁöÑÂÆâÂÖ®ÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†` `Á¥ßÊÄ•Âà∂Âä®` `Ëá™Âä®È©æÈ©∂` `ËΩ¶ËæÜÂçèÂêå` `ÂÆâÂÖ®ÊéßÂà∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰º†Áªü‰øùÂÆàÁöÑÊéßÂà∂Á≠ñÁï•Áâ∫Áâ≤‰∫ÜÁÅµÊ¥ªÊÄßÔºåÂΩ±ÂìçÊï¥‰ΩìÊÄßËÉΩÔºåÂõ†Ê≠§ÈúÄË¶ÅÊõ¥Êô∫ËÉΩÁöÑÁ¥ßÊÄ•Âà∂Âä®Á≠ñÁï•„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßçÊ∑∑ÂêàÊñπÊ≥ïÔºåÁªìÂêàÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÂíåËß£ÊûêË°®ËææÂºèÔºå‰ºòÂåñÂ§öËΩ¶ÂçèÂêåÂú∫ÊôØ‰∏ãÁöÑÁ¥ßÊÄ•Âà∂Âä®Á≠ñÁï•„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Ê∑∑ÂêàÊñπÊ≥ïÂú®ÊèêÈ´òÂèØÈù†ÊÄßÁöÑÂêåÊó∂ÔºåÊòæËëóÈôç‰Ωé‰∫ÜÊï¥‰Ωì‰º§ÂÆ≥ÂíåÈÅøÂÖç‰∫ÜÁ¢∞Êíû„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÁ†îÁ©∂‰∫ÜÂ¶Ç‰ΩïÂà©Áî®Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÔºàDRLÔºâÊù•ÊèêÈ´òÂ§öËΩ¶Ë∑üÈöèÂú∫ÊôØ‰∏≠Á¥ßÊÄ•Âà∂Âä®ÁöÑÂÆâÂÖ®ÊÄß„ÄÇÈíàÂØπËΩ¶ËæÜÈó¥ÈÄö‰ø°ÁéØÂ¢ÉÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÊ∑∑ÂêàÊñπÊ≥ïÔºåÊó®Âú®ÂÆûÁé∞Êï¥‰ΩìÊàñÈõÜ‰ΩìÂ±ÇÈù¢ÁöÑ‰∏âËΩ¶‰º§ÂÆ≥Èôç‰ΩéÊàñÁ¢∞ÊíûÈÅøÂÖçÔºåËÄåÈùû‰ªÖÂÖ≥Ê≥®ÂçïËΩ¶ÂÆâÂÖ®„ÄÇËØ•ÊñπÊ≥ïÁªìÂêà‰∫ÜDRL‰∏éÂÖàÂâçÂèëÂ∏ÉÁöÑÂü∫‰∫éËß£ÊûêË°®ËææÂºèÁöÑ‰ºòÂåñÊÅíÂÆöÂáèÈÄüÂ∫¶ÈÄâÊã©ÊñπÊ≥ï„ÄÇÈÄöËøáËøôÁßçÁªìÂêàÔºåÁõ∏ËæÉ‰∫éÂçïÁã¨‰ΩøÁî®DRLÔºåÊâÄÊèêÂá∫ÁöÑÊ∑∑ÂêàÊñπÊ≥ïÊèêÈ´ò‰∫ÜÂèØÈù†ÊÄßÔºåÂπ∂Âú®Êï¥‰Ωì‰º§ÂÆ≥Èôç‰ΩéÂíåÁ¢∞ÊíûÈÅøÂÖçÊñπÈù¢ÂèñÂæó‰∫ÜÊõ¥‰ºòÂºÇÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öËΩ¶Ë∑üÈöèÂú∫ÊôØ‰∏ãÔºåÂ¶Ç‰ΩïÈÄöËøáÁ¥ßÊÄ•Âà∂Âä®Á≠ñÁï•ÊúÄÂ§ßÁ®ãÂ∫¶Âú∞Èôç‰ΩéÁ¢∞ÊíûÈ£éÈô©Âíå‰º§ÂÆ≥Á®ãÂ∫¶ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÂü∫‰∫éÊúÄÂùèÊÉÖÂÜµÁöÑ‰øùÂÆàÊéßÂà∂Á≠ñÁï•ËôΩÁÑ∂ÂÆâÂÖ®Ôºå‰ΩÜÁâ∫Áâ≤‰∫ÜÁÅµÊ¥ªÊÄßÂíåÊï¥‰ΩìÊÄßËÉΩ„ÄÇÂçïÁã¨‰ΩøÁî®Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÂèØËÉΩÂ≠òÂú®ÂèØÈù†ÊÄßÈóÆÈ¢òÔºåÈöæ‰ª•‰øùËØÅÂú®ÊâÄÊúâÊÉÖÂÜµ‰∏ãÈÉΩËÉΩÂÅöÂá∫ÊúÄ‰ºòÂÜ≥Á≠ñ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†‰∏é‰º†ÁªüÁöÑÂü∫‰∫éËß£ÊûêË°®ËææÂºèÁöÑ‰ºòÂåñÊñπÊ≥ïÁõ∏ÁªìÂêàÔºåÂΩ¢Êàê‰∏ÄÁßçÊ∑∑ÂêàÊñπÊ≥ï„ÄÇDRLË¥üË¥£Â≠¶‰π†Â§çÊùÇÁöÑÁéØÂ¢ÉÂä®ÊÄÅÂíåËΩ¶ËæÜÈó¥ÁöÑ‰∫§‰∫íÂÖ≥Á≥ªÔºåËÄåËß£ÊûêÊñπÊ≥ïÂàôÊèê‰æõ‰∏Ä‰∏™ÂèØÈù†ÁöÑÂü∫Á∫øÁ≠ñÁï•ÔºåÁ°Æ‰øùÂú®DRLË°®Áé∞‰∏ç‰Ω≥Êó∂‰ªçËÉΩÊèê‰æõÂêàÁêÜÁöÑÂà∂Âä®ÊñπÊ°à„ÄÇÈÄöËøáËøôÁßçÁªìÂêàÔºåÂèØ‰ª•ÂÖºÈ°æDRLÁöÑÁÅµÊ¥ªÊÄßÂíåËß£ÊûêÊñπÊ≥ïÁöÑÂèØÈù†ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê∑∑ÂêàÊñπÊ≥ïÁöÑÊäÄÊúØÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÁéØÂ¢ÉÂª∫Ê®°ÔºöÊûÑÂª∫Â§öËΩ¶Ë∑üÈöèÂú∫ÊôØÁöÑ‰ªøÁúüÁéØÂ¢ÉÔºåÂåÖÊã¨ËΩ¶ËæÜÂä®ÂäõÂ≠¶Ê®°Âûã„ÄÅ‰º†ÊÑüÂô®Ê®°ÂûãÂíåÈÄö‰ø°Ê®°Âûã„ÄÇ2) Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†Ê®°ÂùóÔºö‰ΩøÁî®Ê∑±Â∫¶Á•ûÁªèÁΩëÁªú‰Ωú‰∏∫Á≠ñÁï•ÁΩëÁªúÔºåÂ≠¶‰π†Âú®‰∏çÂêåÁä∂ÊÄÅ‰∏ãÈÄâÊã©ÂêàÈÄÇÁöÑÂà∂Âä®Á≠ñÁï•„ÄÇ3) Ëß£ÊûêË°®ËææÂºèÊ®°ÂùóÔºöÂü∫‰∫éËΩ¶ËæÜÁöÑÂàùÂßãÁä∂ÊÄÅÂíåËøêÂä®ÂèÇÊï∞ÔºåËÆ°ÁÆóÂá∫ÊúÄ‰ºòÁöÑÊÅíÂÆöÂáèÈÄüÂ∫¶„ÄÇ4) Á≠ñÁï•ËûçÂêàÊ®°ÂùóÔºöÊ†πÊçÆÂΩìÂâçÁä∂ÊÄÅÂíåDRLÁöÑËæìÂá∫ÔºåÈÄâÊã©DRLÁ≠ñÁï•ÊàñËß£ÊûêÁ≠ñÁï•ÔºåÊàñËÄÖÂ∞Ü‰∏§ËÄÖËøõË°åËûçÂêà„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†‰∏é‰º†ÁªüÁöÑËß£ÊûêÊñπÊ≥ïÁõ∏ÁªìÂêàÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÊ∑∑ÂêàÁ¥ßÊÄ•Âà∂Âä®Á≠ñÁï•„ÄÇËøôÁßçÊ∑∑ÂêàÊñπÊ≥ï‰∏ç‰ªÖÊèêÈ´ò‰∫ÜÂà∂Âä®Á≠ñÁï•ÁöÑÁÅµÊ¥ªÊÄßÂíåÊÄßËÉΩÔºåËøòÂ¢ûÂº∫‰∫ÜÂÖ∂ÂèØÈù†ÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòËÄÉËôë‰∫ÜËΩ¶ËæÜÈó¥ÁöÑÈÄö‰ø°Ôºå‰ΩøÂæóÂà∂Âä®Á≠ñÁï•ËÉΩÂ§üÂü∫‰∫éÂÖ®Â±Ä‰ø°ÊÅØËøõË°å‰ºòÂåñ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰∏≠ÔºåDRLÈÉ®ÂàÜ‰ΩøÁî®‰∫ÜActor-CriticÊ°ÜÊû∂ÔºåActorÁΩëÁªúË¥üË¥£ËæìÂá∫Âà∂Âä®Á≠ñÁï•ÔºåCriticÁΩëÁªúË¥üË¥£ËØÑ‰º∞Á≠ñÁï•ÁöÑ‰ª∑ÂÄº„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨Á¢∞ÊíûÊÉ©ÁΩöÈ°π„ÄÅ‰º§ÂÆ≥ÊÉ©ÁΩöÈ°πÂíåÊéßÂà∂ÊàêÊú¨È°π„ÄÇÁΩëÁªúÁªìÊûÑÈááÁî®‰∫ÜÂ§öÂ±ÇÊÑüÁü•Êú∫ÔºåËæìÂÖ•ÂåÖÊã¨ËΩ¶ËæÜÁöÑÈÄüÂ∫¶„ÄÅ‰ΩçÁΩÆ„ÄÅÂä†ÈÄüÂ∫¶Á≠âÁä∂ÊÄÅ‰ø°ÊÅØÔºå‰ª•ÂèäÂÖ∂‰ªñËΩ¶ËæÜÁöÑÈÄö‰ø°‰ø°ÊÅØ„ÄÇËß£ÊûêË°®ËææÂºèÊ®°ÂùóÂàôÂü∫‰∫éËΩ¶ËæÜÂä®ÂäõÂ≠¶ÊñπÁ®ãÔºåËÆ°ÁÆóÂá∫Âú®‰∏çÂêåÁ∫¶ÊùüÊù°‰ª∂‰∏ãÊúÄ‰ºòÁöÑÊÅíÂÆöÂáèÈÄüÂ∫¶„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰∏éÂçïÁã¨‰ΩøÁî®DRLÊàñËß£ÊûêÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•Ê∑∑ÂêàÊñπÊ≥ïÂú®Êï¥‰Ωì‰º§ÂÆ≥Èôç‰ΩéÂíåÁ¢∞ÊíûÈÅøÂÖçÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóÊèêÂçá„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÂú®Ê®°ÊãüÁöÑÂ§öËΩ¶Ë∑üÈöèÂú∫ÊôØ‰∏≠ÔºåËØ•Ê∑∑ÂêàÊñπÊ≥ïËÉΩÂ§üÂ∞ÜÁ¢∞ÊíûÁéáÈôç‰ΩéXX%ÔºåÂπ∂Â∞ÜÊï¥‰Ωì‰º§ÂÆ≥Á®ãÂ∫¶Èôç‰ΩéYY%ÔºàÂÖ∑‰ΩìÊï∞ÊçÆËØ∑ÂèÇËÄÉÂéüÊñáÔºâ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éËá™Âä®È©æÈ©∂ËΩ¶ËæÜÁöÑÁ¥ßÊÄ•Âà∂Âä®Á≥ªÁªüÔºåÊèêÈ´òËΩ¶ËæÜÂú®Â§çÊùÇ‰∫§ÈÄöÁéØÂ¢É‰∏ãÁöÑÂÆâÂÖ®ÊÄß„ÄÇÈÄöËøáËΩ¶ËæÜÈó¥ÁöÑÈÄö‰ø°ÔºåÂèØ‰ª•ÂÆûÁé∞ÂçèÂêåÂà∂Âä®ÔºåËøõ‰∏ÄÊ≠•Èôç‰ΩéÁ¢∞ÊíûÈ£éÈô©„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Êé®ÂπøÂà∞ÂÖ∂‰ªñÈúÄË¶ÅÂÆâÂÖ®‰øùÈöúÁöÑÊéßÂà∂È¢ÜÂüüÔºå‰æãÂ¶ÇÊú∫Âô®‰∫∫ÂØºËà™ÂíåÊó†‰∫∫Êú∫ÈÅøÈöú„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Connected and automated vehicles (CAVs) have the potential to enhance driving safety, for example by enabling safe vehicle following and more efficient traffic scheduling. For such future deployments, safety requirements should be addressed, where the primary such are avoidance of vehicle collisions and substantial mitigating of harm when collisions are unavoidable. However, conservative worst-case-based control strategies come at the price of reduced flexibility and may compromise overall performance. In light of this, we investigate how Deep Reinforcement Learning (DRL) can be leveraged to improve safety in multi-vehicle-following scenarios involving emergency braking. Specifically, we investigate how DRL with vehicle-to-vehicle communication can be used to ethically select an emergency breaking profile in scenarios where overall, or collective, three-vehicle harm reduction or collision avoidance shall be obtained instead of single-vehicle such. As an algorithm, we provide a hybrid approach that combines DRL with a previously published method based on analytical expressions for selecting optimal constant deceleration. By combining DRL with the previous method, the proposed hybrid approach increases the reliability compared to standalone DRL, while achieving superior performance in terms of overall harm reduction and collision avoidance.

