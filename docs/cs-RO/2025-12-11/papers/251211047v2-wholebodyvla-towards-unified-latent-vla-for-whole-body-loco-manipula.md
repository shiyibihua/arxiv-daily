---
layout: default
title: WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control
---

# WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.11047" target="_blank" class="toolbar-btn">arXiv: 2512.11047v2</a>
    <a href="https://arxiv.org/pdf/2512.11047.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.11047v2" 
            onclick="toggleFavorite(this, '2512.11047v2', 'WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Haoran Jiang, Jin Chen, Qingwen Bu, Li Chen, Modi Shi, Yanjie Zhang, Delong Li, Chuanzhe Suo, Chuang Wang, Zhihui Peng, Hongyang Li

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-11 (Êõ¥Êñ∞: 2025-12-15)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫WholeBodyVLAÔºåÂÆûÁé∞Âü∫‰∫éÁªü‰∏ÄÈöêÁ©∫Èó¥VLAÁöÑÂ§ßËåÉÂõ¥ÂÖ®Ë∫´Loco-ManipulationÊéßÂà∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `‰∫∫ÂΩ¢Êú∫Âô®‰∫∫` `Loco-Manipulation` `ËßÜËßâËØ≠Ë®ÄÂä®‰Ωú` `Âº∫ÂåñÂ≠¶‰π†` `ÈöêÁ©∫Èó¥Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Êìç‰ΩúÊÑüÁü•ÁöÑËøêÂä®ÊéßÂà∂ÊñπÈù¢‰∏çË∂≥ÔºåÈôêÂà∂‰∫Ü‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âú®Â§ßËåÉÂõ¥Âú∫ÊôØ‰∏ãÁöÑLoco-ManipulationËÉΩÂäõ„ÄÇ
2. ÊèêÂá∫WholeBodyVLAÊ°ÜÊû∂ÔºåÂà©Áî®Áªü‰∏ÄÈöêÁ©∫Èó¥Â≠¶‰π†VLAÁ≥ªÁªüÔºå‰ªéÊó†Âä®‰ΩúËßÜÈ¢ë‰∏≠Â≠¶‰π†ÔºåÂπ∂ÁªìÂêàLMO-RLÁ≠ñÁï•ÊèêÂçáËøêÂä®Á≤æÂ∫¶„ÄÇ
3. Âú®AgiBot X2‰∏äÂÆûÈ™åÈ™åËØÅÔºåWholeBodyVLAÊÄßËÉΩË∂ÖË∂äÂü∫Á∫ø21.3%ÔºåÂ±ïÁé∞Âá∫ËâØÂ•ΩÁöÑÊ≥õÂåñÊÄßÂíåÂèØÊâ©Â±ïÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÈúÄË¶ÅÁ≤æÁ°ÆÁöÑËøêÂä®ÂíåÁÅµÂ∑ßÁöÑÊìç‰ΩúÊù•ÊâßË°åÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑLoco-Manipulation‰ªªÂä°„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÊ®°ÂùóÂåñÊàñÁ´ØÂà∞Á´ØÊñπÊ≥ïÂú®Êìç‰ΩúÊÑüÁü•ÁöÑËøêÂä®ÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåËøôÈôêÂà∂‰∫ÜÊú∫Âô®‰∫∫ÁöÑÂ∑•‰ΩúÁ©∫Èó¥ÔºåÈòªÁ¢ç‰∫ÜÂÖ∂ÊâßË°åÂ§ßËåÉÂõ¥ÁöÑLoco-Manipulation‰ªªÂä°„ÄÇÊàë‰ª¨ËÆ§‰∏∫ËøôÊòØÁî±‰∫éÔºö(1)Áº∫‰πè‰∫∫ÂΩ¢ÈÅ•Êìç‰ΩúÊï∞ÊçÆÂØºËá¥Èöæ‰ª•Ëé∑ÂèñLoco-ManipulationÁü•ËØÜÔºõ(2)Áé∞ÊúâRLÊéßÂà∂Âô®ÁöÑÁ≤æÂ∫¶ÂíåÁ®≥ÂÆöÊÄßÊúâÈôêÔºåÂØºËá¥Èöæ‰ª•Âø†ÂÆûÂèØÈù†Âú∞ÊâßË°åËøêÂä®ÂëΩ‰ª§„ÄÇ‰∏∫‰∫ÜËé∑ÂèñÊõ¥‰∏∞ÂØåÁöÑLoco-ManipulationÁü•ËØÜÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÈöêÁ©∫Èó¥Â≠¶‰π†Ê°ÜÊû∂Ôºå‰ΩøËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Á≥ªÁªüËÉΩÂ§ü‰ªé‰ΩéÊàêÊú¨ÁöÑÊó†Âä®‰ΩúËá™Êàë‰∏≠ÂøÉËßÜÈ¢ë‰∏≠Â≠¶‰π†„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™È´òÊïàÁöÑ‰∫∫Â∑•Êï∞ÊçÆÊî∂ÈõÜÊµÅÁ®ãÊù•Êâ©ÂÖÖÊï∞ÊçÆÈõÜÂπ∂Êâ©Â§ßÊî∂Áõä„ÄÇ‰∏∫‰∫ÜÊõ¥Á≤æÁ°ÆÂú∞ÊâßË°åÊâÄÈúÄÁöÑËøêÂä®ÂëΩ‰ª§ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™‰∏ìÈó®‰∏∫Á≤æÁ°ÆÂíåÁ®≥ÂÆöÁöÑÊ†∏ÂøÉLoco-ManipulationËøêÂä®ÔºàÂ¶ÇÂâçËøõ„ÄÅËΩ¨ÂºØÂíå‰∏ãËπ≤ÔºâÈáèË∫´ÂÆöÂà∂ÁöÑÈù¢ÂêëLoco-Manipulation(LMO)ÁöÑRLÁ≠ñÁï•„ÄÇÂü∫‰∫éËøô‰∫õÁªÑ‰ª∂ÔºåÊàë‰ª¨Êé®Âá∫‰∫ÜWholeBodyVLAÔºå‰∏Ä‰∏™Áî®‰∫é‰∫∫ÂΩ¢Loco-ManipulationÁöÑÁªü‰∏ÄÊ°ÜÊû∂„ÄÇÊçÆÊàë‰ª¨ÊâÄÁü•ÔºåWholeBodyVLAÊòØÂêåÁ±ª‰∫ßÂìÅ‰∏≠È¶ñ‰∏™ÂÆûÁé∞Â§ßËåÉÂõ¥‰∫∫ÂΩ¢Loco-ManipulationÁöÑÊ°ÜÊû∂„ÄÇÈÄöËøáÂú®AgiBot X2‰∫∫ÂΩ¢Êú∫Âô®‰∫∫‰∏äÁöÑÂÖ®Èù¢ÂÆûÈ™åÈ™åËØÅÔºåÂÖ∂ÊÄßËÉΩ‰ºò‰∫é‰πãÂâçÁöÑÂü∫Á∫ø21.3%ÔºåÂπ∂‰∏îÂú®ÂπøÊ≥õÁöÑ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÂíåÈ´òÂ∫¶ÁöÑÂèØÊâ©Â±ïÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Loco-ManipulationÊñπÊ≥ïÔºåÊó†ËÆ∫ÊòØÊ®°ÂùóÂåñËøòÊòØÁ´ØÂà∞Á´ØÔºåÈÉΩÁº∫‰πèÂØπÊìç‰ΩúÁöÑÊÑüÁü•ÔºåÂØºËá¥Êú∫Âô®‰∫∫Èöæ‰ª•Âú®ËæÉÂ§ßÁöÑÁ©∫Èó¥ËåÉÂõ¥ÂÜÖÂÆåÊàêÂ§çÊùÇÁöÑ‰ªªÂä°„ÄÇ‰∏ªË¶ÅÁóõÁÇπÂú®‰∫éÁº∫‰πèÈ´òË¥®ÈáèÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºå‰ª•ÂèäÁé∞ÊúâÂº∫ÂåñÂ≠¶‰π†ÊéßÂà∂Âô®Âú®ËøêÂä®ÊéßÂà∂ÊñπÈù¢ÁöÑÁ≤æÂ∫¶ÂíåÁ®≥ÂÆöÊÄß‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™Áªü‰∏ÄÁöÑÈöêÁ©∫Èó¥Â≠¶‰π†Ê°ÜÊû∂Ôºå‰ΩøÊú∫Âô®‰∫∫ËÉΩÂ§ü‰ªé‰ΩéÊàêÊú¨ÁöÑ„ÄÅÊó†Âä®‰ΩúÁöÑËá™Êàë‰∏≠ÂøÉËßÜÈ¢ë‰∏≠Â≠¶‰π†Loco-ManipulationÁü•ËØÜ„ÄÇÂêåÊó∂ÔºåËÆæËÆ°‰∏Ä‰∏™Èù¢ÂêëLoco-ManipulationÁöÑÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•Ôºå‰ª•ÊèêÈ´òËøêÂä®ÊéßÂà∂ÁöÑÁ≤æÂ∫¶ÂíåÁ®≥ÂÆöÊÄß„ÄÇÈÄöËøáÁªìÂêàËßÜËßâ„ÄÅËØ≠Ë®ÄÂíåÂä®‰Ωú‰ø°ÊÅØÔºåÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥ÁÅµÊ¥ªÁöÑÂÖ®Ë∫´ÊéßÂà∂„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöWholeBodyVLAÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™Ê†∏ÂøÉÊ®°ÂùóÔºö‰∏ÄÊòØÂü∫‰∫éËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)ÁöÑÈöêÁ©∫Èó¥Â≠¶‰π†Ê®°ÂùóÔºåÁî®‰∫é‰ªéÊó†Âä®‰ΩúËßÜÈ¢ë‰∏≠Â≠¶‰π†Loco-ManipulationÁü•ËØÜÔºõ‰∫åÊòØÈù¢ÂêëLoco-Manipulation(LMO)ÁöÑÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÔºåÁî®‰∫éÁ≤æÁ°ÆÊéßÂà∂Êú∫Âô®‰∫∫ÁöÑËøêÂä®„ÄÇÊï¥‰∏™ÊµÅÁ®ãÂåÖÊã¨Êï∞ÊçÆÊî∂ÈõÜ„ÄÅÈöêÁ©∫Èó¥Â≠¶‰π†„ÄÅÁ≠ñÁï•ËÆ≠ÁªÉÂíåËøêÂä®ÊéßÂà∂Âõõ‰∏™Èò∂ÊÆµ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÈöêÁ©∫Èó¥Â≠¶‰π†Ê°ÜÊû∂ÔºåËÉΩÂ§ü‰ªé‰ΩéÊàêÊú¨ÁöÑÊó†Âä®‰ΩúËßÜÈ¢ë‰∏≠Â≠¶‰π†Loco-ManipulationÁü•ËØÜÔºå‰ªéËÄåÂÖãÊúç‰∫ÜÊï∞ÊçÆÁ®ÄÁº∫ÁöÑÈóÆÈ¢ò„ÄÇÊ≠§Â§ñÔºåLMO-RLÁ≠ñÁï•ÁöÑËÆæËÆ°‰πüÈíàÂØπÊÄßÂú∞ÊèêÈ´ò‰∫ÜËøêÂä®ÊéßÂà∂ÁöÑÁ≤æÂ∫¶ÂíåÁ®≥ÂÆöÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöVLAÊ®°Âùó‰ΩøÁî®Ëá™ÁºñÁ†ÅÂô®ÁªìÊûÑÂ≠¶‰π†ËßÜËßâÂíåËØ≠Ë®Ä‰ø°ÊÅØÁöÑËÅîÂêàÈöêÁ©∫Èó¥Ë°®Á§∫„ÄÇLMO-RLÁ≠ñÁï•ÈááÁî®Actor-CriticÊû∂ÊûÑÔºåÂ•ñÂä±ÂáΩÊï∞ÁöÑËÆæËÆ°‰æßÈáç‰∫éËøêÂä®ÁöÑÁ≤æÁ°ÆÊÄßÂíåÁ®≥ÂÆöÊÄßÔºå‰æãÂ¶ÇÔºåÂØπÂâçËøõ„ÄÅËΩ¨ÂºØÂíå‰∏ãËπ≤Á≠âÊ†∏ÂøÉÂä®‰ΩúËøõË°åÁ≤æÁªÜÁöÑÂ•ñÂä±Â°ëÈÄ†„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåWholeBodyVLAÂú®AgiBot X2‰∫∫ÂΩ¢Êú∫Âô®‰∫∫‰∏äÁöÑÊÄßËÉΩ‰ºò‰∫é‰πãÂâçÁöÑÂü∫Á∫ø21.3%„ÄÇÊ≠§Â§ñÔºåËØ•Ê°ÜÊû∂Âú®‰∏çÂêåÁöÑ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÂíåÈ´òÂ∫¶ÁöÑÂèØÊâ©Â±ïÊÄßÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊΩúÂäõ„ÄÇËøô‰∫õÁªìÊûúÈ™åËØÅ‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫é‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏ãÁöÑËá™‰∏ªÊìç‰ΩúÔºå‰æãÂ¶ÇÂÆ∂Â∫≠ÊúçÂä°„ÄÅÁâ©ÊµÅÈÖçÈÄÅ„ÄÅÁÅæÈöæÊïëÊè¥Á≠â„ÄÇÈÄöËøáÂ≠¶‰π†‰∫∫Á±ªÁöÑÂä®‰ΩúÂíåË°å‰∏∫Ê®°ÂºèÔºåÊú∫Âô®‰∫∫ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£ÁéØÂ¢ÉÔºåÊâßË°åÂêÑÁßç‰ªªÂä°ÔºåÊèêÈ´òÂ∑•‰ΩúÊïàÁéáÂíåÂÆâÂÖ®ÊÄß„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÊé®Âä®‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âú®Êõ¥ÂπøÊ≥õÈ¢ÜÂüüÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Humanoid robots require precise locomotion and dexterous manipulation to perform challenging loco-manipulation tasks. Yet existing approaches, modular or end-to-end, are deficient in manipulation-aware locomotion. This confines the robot to a limited workspace, preventing it from performing large-space loco-manipulation. We attribute this to: (1) the challenge of acquiring loco-manipulation knowledge due to the scarcity of humanoid teleoperation data, and (2) the difficulty of faithfully and reliably executing locomotion commands, stemming from the limited precision and stability of existing RL controllers. To acquire richer loco-manipulation knowledge, we propose a unified latent learning framework that enables Vision-Language-Action (VLA) system to learn from low-cost action-free egocentric videos. Moreover, an efficient human data collection pipeline is devised to augment the dataset and scale the benefits. To execute the desired locomotion commands more precisely, we present a loco-manipulation-oriented (LMO) RL policy specifically tailored for accurate and stable core loco-manipulation movements, such as advancing, turning, and squatting. Building on these components, we introduce WholeBodyVLA, a unified framework for humanoid loco-manipulation. To the best of our knowledge, WholeBodyVLA is one of its kind enabling large-space humanoid loco-manipulation. It is verified via comprehensive experiments on the AgiBot X2 humanoid, outperforming prior baseline by 21.3%. It also demonstrates strong generalization and high extensibility across a broad range of tasks.

