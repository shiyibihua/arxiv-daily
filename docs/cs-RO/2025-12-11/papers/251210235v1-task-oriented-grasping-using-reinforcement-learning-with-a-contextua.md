---
layout: default
title: Task-Oriented Grasping Using Reinforcement Learning with a Contextual Reward Machine
---

# Task-Oriented Grasping Using Reinforcement Learning with a Contextual Reward Machine

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.10235" target="_blank" class="toolbar-btn">arXiv: 2512.10235v1</a>
    <a href="https://arxiv.org/pdf/2512.10235.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.10235v1" 
            onclick="toggleFavorite(this, '2512.10235v1', 'Task-Oriented Grasping Using Reinforcement Learning with a Contextual Reward Machine')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Hui Li, Akhlak Uz Zaman, Fujian Yan, Hongsheng He

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-11

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫é‰∏ä‰∏ãÊñáÂ•ñÂä±Êú∫Âà∂ÁöÑÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂‰ª•Ëß£ÂÜ≥‰ªªÂä°ÂØºÂêëÊäìÂèñÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Âº∫ÂåñÂ≠¶‰π†` `‰∏ä‰∏ãÊñáÂ•ñÂä±Êú∫Âà∂` `‰ªªÂä°ÂØºÂêëÊäìÂèñ` `Êú∫Âô®‰∫∫ÊäÄÊúØ` `Â≠¶‰π†ÊïàÁéá` `Áä∂ÊÄÅÊäΩË±°` `ËøáÊ∏°Â•ñÂä±`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÊäìÂèñÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§çÊùÇ‰ªªÂä°Êó∂Â∏∏Â∏∏Èù¢‰∏¥‰ªªÂä°Â§çÊùÇÊÄßÈ´ò„ÄÅÂ≠¶‰π†ÊïàÁéá‰ΩéÁöÑÈóÆÈ¢ò„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑÊ°ÜÊû∂ÈÄöËøá‰∏ä‰∏ãÊñáÂ•ñÂä±Êú∫Âà∂Â∞ÜÊäìÂèñ‰ªªÂä°ÂàÜËß£‰∏∫Â§ö‰∏™Â≠ê‰ªªÂä°Ôºå‰ªéËÄåÁÆÄÂåñÂ≠¶‰π†ËøáÁ®ãÂπ∂ÊèêÈ´òÊïàÁéá„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Ê®°ÊãüÁéØÂ¢É‰∏≠ÊàêÂäüÁéáËææÂà∞95%ÔºåÂú®ÁúüÂÆûÊú∫Âô®‰∫∫‰∏äÊàêÂäüÁéá‰∏∫83.3%ÔºåÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁªìÂêà‰∏ä‰∏ãÊñáÂ•ñÂä±Êú∫Âà∂ÁöÑÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÔºåÁî®‰∫é‰ªªÂä°ÂØºÂêëÁöÑÊäìÂèñ„ÄÇ‰∏ä‰∏ãÊñáÂ•ñÂä±Êú∫Âà∂ÈÄöËøáÂ∞ÜÊäìÂèñ‰ªªÂä°ÂàÜËß£‰∏∫ÂèØÁÆ°ÁêÜÁöÑÂ≠ê‰ªªÂä°ÔºåÈôç‰Ωé‰∫Ü‰ªªÂä°Â§çÊùÇÊÄß„ÄÇÊØè‰∏™Â≠ê‰ªªÂä°ÈÉΩ‰∏éÁâπÂÆöÈò∂ÊÆµÁöÑ‰∏ä‰∏ãÊñáÁõ∏ÂÖ≥ËÅîÔºåÂåÖÊã¨Â•ñÂä±ÂáΩÊï∞„ÄÅÂä®‰ΩúÁ©∫Èó¥ÂíåÁä∂ÊÄÅÊäΩË±°ÂáΩÊï∞„ÄÇËøôÁßç‰∏ä‰∏ãÊñá‰ø°ÊÅØËÉΩÂ§üÊúâÊïàÊåáÂØºÈò∂ÊÆµÂÜÖÁöÑÂ≠¶‰π†ÔºåÊèêÈ´òÂ≠¶‰π†ÊïàÁéáÔºåÂáèÂ∞ëÁä∂ÊÄÅ-Âä®‰ΩúÁ©∫Èó¥ÔºåÂπ∂Âú®ÊòéÁ°ÆÁöÑËæπÁïåÂÜÖÂºïÂØºÊé¢Á¥¢„ÄÇÊ≠§Â§ñÔºåÂºïÂÖ•‰∫ÜËøáÊ∏°Â•ñÂä±‰ª•ÈºìÂä±ÊàñÊÉ©ÁΩöÈò∂ÊÆµÈó¥ÁöÑËøáÊ∏°Ôºå‰ªéËÄåÂºïÂØºÊ®°ÂûãÊúùÂêëÁêÜÊÉ≥ÁöÑÈò∂ÊÆµÂ∫èÂàóÔºåÂä†ÈÄüÊî∂Êïõ„ÄÇ‰∏éËøëÁ´ØÁ≠ñÁï•‰ºòÂåñÁÆóÊ≥ïÁªìÂêàÂêéÔºåËØ•ÊñπÊ≥ïÂú®1000‰∏™Ê®°ÊãüÊäìÂèñ‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫Ü95%ÁöÑÊàêÂäüÁéáÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÔºåÂπ∂Âú®ÁúüÂÆûÊú∫Âô®‰∫∫‰∏äÂÆûÁé∞‰∫Ü83.3%ÁöÑÊàêÂäüÁéá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥‰ªªÂä°ÂØºÂêëÊäìÂèñ‰∏≠ÁöÑÂ§çÊùÇÊÄßÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§öÊ†∑Âåñ‰ªªÂä°Êó∂Â∏∏Â∏∏ÊïàÁéá‰Ωé‰∏ãÔºåÈöæ‰ª•Âø´ÈÄüÊî∂Êïõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÂºïÂÖ•‰∏ä‰∏ãÊñáÂ•ñÂä±Êú∫Âà∂ÔºåÂ∞ÜÂ§çÊùÇÁöÑÊäìÂèñ‰ªªÂä°ÂàÜËß£‰∏∫Â§ö‰∏™Èò∂ÊÆµÊÄßÂ≠ê‰ªªÂä°ÔºåÂà©Áî®Èò∂ÊÆµÁâπÂÆöÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØÊù•ÊåáÂØºÂ≠¶‰π†ÂíåÊé¢Á¥¢„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ªªÂä°ÂàÜËß£„ÄÅ‰∏ä‰∏ãÊñáÂ•ñÂä±Êú∫Âà∂„ÄÅÁä∂ÊÄÅÊäΩË±°„ÄÅÂä®‰ΩúÁ©∫Èó¥ÂÆö‰πâÂèäËøáÊ∏°Â•ñÂä±ËÆæËÆ°„ÄÇÊØè‰∏™Â≠ê‰ªªÂä°Âú®ÁâπÂÆöÈò∂ÊÆµÂÜÖËøõË°åÂ≠¶‰π†ÔºåËøáÊ∏°Â•ñÂä±ÂàôÂºïÂØºÈò∂ÊÆµÈó¥ÁöÑÊúâÊïàËΩ¨Êç¢„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫é‰∏ä‰∏ãÊñáÂ•ñÂä±Êú∫Âà∂ÁöÑÂºïÂÖ•ÔºåÂÆÉÈÄöËøáÈò∂ÊÆµÊÄßÂàÜËß£ÂíåÊòéÁ°ÆÁöÑÂ•ñÂä±ËÆæËÆ°ÔºåÊòæËëóÊèêÈ´ò‰∫ÜÂ≠¶‰π†ÊïàÁéáÂíåÊàêÂäüÁéá„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•Êú∫Âà∂Êèê‰æõ‰∫ÜÊõ¥Ê∏ÖÊô∞ÁöÑÂ≠¶‰π†ÁõÆÊ†áÂíåÊé¢Á¥¢ËæπÁïå„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äÔºåÂ•ñÂä±ÂáΩÊï∞ÂíåÁä∂ÊÄÅÊäΩË±°ÂáΩÊï∞ÁªèËøáÁ≤æÂøÉËÆæËÆ°Ôºå‰ª•Á°Æ‰øùÂú®ÊØè‰∏™Èò∂ÊÆµÂÜÖÁöÑÊúâÊïàÂ≠¶‰π†„ÄÇÂêåÊó∂ÔºåÁªìÂêàËøëÁ´ØÁ≠ñÁï•‰ºòÂåñÁÆóÊ≥ïÔºå‰ºòÂåñ‰∫ÜÁ≠ñÁï•Êõ¥Êñ∞ËøáÁ®ãÔºåÊèêÂçá‰∫ÜÊï¥‰ΩìÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®1000‰∏™Ê®°ÊãüÊäìÂèñ‰ªªÂä°‰∏≠ÂèñÂæó‰∫Ü95%ÁöÑÊàêÂäüÁéáÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÔºå‰∏îÂú®ÁúüÂÆûÊú∫Âô®‰∫∫‰∏äÂÆûÁé∞‰∫Ü83.3%ÁöÑÊàêÂäüÁéáÔºåÂ±ïÁé∞Âá∫ÂçìË∂äÁöÑÂ≠¶‰π†ÈÄüÂ∫¶ÂíåÊï∞ÊçÆÊïàÁéá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êú∫Âô®‰∫∫ÊäìÂèñ„ÄÅËá™Âä®ÂåñÁîü‰∫ßÁ∫ø„ÄÅÊô∫ËÉΩÂÆ∂Â±ÖÁ≠â„ÄÇÈÄöËøáÊèêÈ´òÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊäìÂèñËÉΩÂäõÔºåËÉΩÂ§üÊòæËëóÊèêÂçáËá™Âä®ÂåñÁ≥ªÁªüÁöÑÊïàÁéáÂíåÁÅµÊ¥ªÊÄßÔºåÂÖ∑ÊúâÂπøÊ≥õÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> This paper presents a reinforcement learning framework that incorporates a Contextual Reward Machine for task-oriented grasping. The Contextual Reward Machine reduces task complexity by decomposing grasping tasks into manageable sub-tasks. Each sub-task is associated with a stage-specific context, including a reward function, an action space, and a state abstraction function. This contextual information enables efficient intra-stage guidance and improves learning efficiency by reducing the state-action space and guiding exploration within clearly defined boundaries. In addition, transition rewards are introduced to encourage or penalize transitions between stages which guides the model toward desirable stage sequences and further accelerates convergence. When integrated with the Proximal Policy Optimization algorithm, the proposed method achieved a 95% success rate across 1,000 simulated grasping tasks encompassing diverse objects, affordances, and grasp topologies. It outperformed the state-of-the-art methods in both learning speed and success rate. The approach was transferred to a real robot, where it achieved a success rate of 83.3% in 60 grasping tasks over six affordances. These experimental results demonstrate superior accuracy, data efficiency, and learning efficiency. They underscore the model's potential to advance task-oriented grasping in both simulated and real-world settings.

