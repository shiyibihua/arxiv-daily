---
layout: default
title: HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation
---

# HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18802" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18802v3</a>
  <a href="https://arxiv.org/pdf/2508.18802.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18802v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18802v3', 'HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Li Sun, Jiefeng Wu, Feng Chen, Ruizhe Liu, Yanchao Yang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26 (æ›´æ–°: 2025-09-20)

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://lisunphil.github.io/HyperTASR_projectpage/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHyperTASRä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­çš„åœºæ™¯è¡¨ç¤ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `åœºæ™¯è¡¨ç¤º` `è¶…ç½‘ç»œ` `ä»»åŠ¡ç›¸å…³æ€§` `åŠ¨æ€é€‚åº”æ€§` `ç­–ç•¥å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨ä¸ä»»åŠ¡æ— å…³çš„è¡¨ç¤ºæå–ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰ä»»åŠ¡ç›¸å…³çš„ç¯å¢ƒç‰¹å¾ï¼Œå¯¼è‡´å­¦ä¹ æ•ˆç‡ä½ä¸‹ã€‚
2. HyperTASRé€šè¿‡è¶…ç½‘ç»œåŠ¨æ€ç”Ÿæˆä¸ä»»åŠ¡ç›®æ ‡å’Œæ‰§è¡Œé˜¶æ®µç›¸å…³çš„åœºæ™¯è¡¨ç¤ºï¼Œæå‡äº†è¡¨ç¤ºçš„ä¸Šä¸‹æ–‡é€‚åº”æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHyperTASRåœ¨å¤šç§è¡¨ç¤ºèŒƒå¼ä¸‹å‡æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ‰æ•ˆçš„æœºå™¨äººæ“ä½œç­–ç•¥å­¦ä¹ éœ€è¦èƒ½å¤Ÿé€‰æ‹©æ€§æ•æ‰ä¸ä»»åŠ¡ç›¸å…³çš„ç¯å¢ƒç‰¹å¾çš„åœºæ™¯è¡¨ç¤ºã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨ä¸ä»»åŠ¡æ— å…³çš„è¡¨ç¤ºæå–ï¼Œæœªèƒ½æ¨¡æ‹Ÿäººç±»è®¤çŸ¥ä¸­è§‚å¯Ÿåˆ°çš„åŠ¨æ€æ„ŸçŸ¥é€‚åº”æ€§ã€‚æœ¬æ–‡æå‡ºäº†HyperTASRï¼Œä¸€ä¸ªåŸºäºè¶…ç½‘ç»œçš„æ¡†æ¶ï¼Œæ ¹æ®ä»»åŠ¡ç›®æ ‡å’Œæ‰§è¡Œé˜¶æ®µè°ƒèŠ‚åœºæ™¯è¡¨ç¤ºã€‚è¯¥æ¶æ„åŠ¨æ€ç”Ÿæˆè¡¨ç¤ºè½¬æ¢å‚æ•°ï¼Œä½¿è¡¨ç¤ºåœ¨ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­èƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡ä¸æ–­æ¼”å˜ã€‚ä¸ç®€å•åœ°å°†ä»»åŠ¡åµŒå…¥ä¸æ— å…³è¡¨ç¤ºè¿æ¥æˆ–èåˆçš„æ–¹æ³•ä¸åŒï¼ŒHyperTASRåœ¨ä»»åŠ¡ä¸Šä¸‹æ–‡å’ŒçŠ¶æ€ä¾èµ–å¤„ç†è·¯å¾„ä¹‹é—´å»ºç«‹äº†è®¡ç®—åˆ†ç¦»ï¼Œæå‡äº†å­¦ä¹ æ•ˆç‡å’Œè¡¨ç¤ºè´¨é‡ã€‚ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼Œåœ¨ä¸åŒè¡¨ç¤ºèŒƒå¼ä¸‹ï¼ŒHyperTASRåœ¨æ¨¡æ‹Ÿå’Œç°å®ç¯å¢ƒä¸­å‡è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæ“ä½œä¸­åœºæ™¯è¡¨ç¤ºçš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆæ•æ‰ä¸ä»»åŠ¡ç›¸å…³çš„ç¯å¢ƒç‰¹å¾ï¼Œå¯¼è‡´ç­–ç•¥å­¦ä¹ çš„æ•ˆç‡å’Œæ•ˆæœå—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHyperTASRçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è¶…ç½‘ç»œæ ¹æ®ä»»åŠ¡ç›®æ ‡å’Œæ‰§è¡Œé˜¶æ®µåŠ¨æ€è°ƒèŠ‚åœºæ™¯è¡¨ç¤ºï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­é€‚åº”ä¸åŒçš„ä¸Šä¸‹æ–‡ã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿæ›´å¥½åœ°æ¨¡æ‹Ÿäººç±»çš„æ„ŸçŸ¥é€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHyperTASRçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä»»åŠ¡ç›®æ ‡è¾“å…¥ã€æ‰§è¡Œé˜¶æ®µè¾“å…¥å’Œè¶…ç½‘ç»œæ¨¡å—ï¼Œåè€…è´Ÿè´£ç”Ÿæˆè¡¨ç¤ºè½¬æ¢å‚æ•°ï¼Œè¿›è€Œè°ƒèŠ‚åœºæ™¯è¡¨ç¤ºçš„ç”Ÿæˆå’Œå¤„ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šHyperTASRçš„ä¸»è¦åˆ›æ–°åœ¨äºåœ¨ä»»åŠ¡ä¸Šä¸‹æ–‡å’ŒçŠ¶æ€ä¾èµ–å¤„ç†è·¯å¾„ä¹‹é—´å»ºç«‹äº†è®¡ç®—åˆ†ç¦»ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„ç®€å•è¿æ¥æˆ–èåˆæ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ï¼Œæ˜¾è‘—æå‡äº†è¡¨ç¤ºçš„è´¨é‡å’Œå­¦ä¹ æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒHyperTASRé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ä»»åŠ¡ç›¸å…³æ€§ï¼Œå¹¶é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶æ¥é€‰æ‹©æ€§åœ°å…³æ³¨ä»»åŠ¡ç›¸å…³çš„åœºæ™¯ä¿¡æ¯ï¼Œç¡®ä¿è¡¨ç¤ºçš„æœ‰æ•ˆæ€§ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨å®éªŒä¸­ç»è¿‡å¤šæ¬¡è°ƒä¼˜ï¼Œä»¥è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒHyperTASRåœ¨å¤šç§ä»»åŠ¡åœºæ™¯ä¸‹çš„æ€§èƒ½æå‡æ˜¾è‘—ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”æ—¶ï¼Œä»»åŠ¡æˆåŠŸç‡æé«˜äº†20%ä»¥ä¸Šï¼Œä¸”åœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”æ€§è¡¨ç°æ›´ä¸ºçªå‡ºï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æœºå™¨äººã€è‡ªåŠ¨åŒ–ç”Ÿäº§çº¿å’Œäººæœºäº¤äº’ç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œèƒ½åŠ›ï¼ŒHyperTASRèƒ½å¤Ÿæ˜¾è‘—æé«˜ç”Ÿäº§æ•ˆç‡å’Œå®‰å…¨æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Effective policy learning for robotic manipulation requires scene representations that selectively capture task-relevant environmental features. Current approaches typically employ task-agnostic representation extraction, failing to emulate the dynamic perceptual adaptation observed in human cognition. We present HyperTASR, a hypernetwork-driven framework that modulates scene representations based on both task objectives and the execution phase. Our architecture dynamically generates representation transformation parameters conditioned on task specifications and progression state, enabling representations to evolve contextually throughout task execution. This approach maintains architectural compatibility with existing policy learning frameworks while fundamentally reconfiguring how visual features are processed. Unlike methods that simply concatenate or fuse task embeddings with task-agnostic representations, HyperTASR establishes computational separation between task-contextual and state-dependent processing paths, enhancing learning efficiency and representational quality. Comprehensive evaluations in both simulation and real-world environments demonstrate substantial performance improvements across different representation paradigms. Through ablation studies and attention visualization, we confirm that our approach selectively prioritizes task-relevant scene information, closely mirroring human adaptive perception during manipulation tasks. The project website is at https://lisunphil.github.io/HyperTASR_projectpage/.

