---
layout: default
title: ZeST: an LLM-based Zero-Shot Traversability Navigation for Unknown Environments
---

# ZeST: an LLM-based Zero-Shot Traversability Navigation for Unknown Environments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19131" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19131v2</a>
  <a href="https://arxiv.org/pdf/2508.19131.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19131v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19131v2', 'ZeST: an LLM-based Zero-Shot Traversability Navigation for Unknown Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shreya Gummadi, Mateus V. Gasparino, Gianluca Capezzuto, Marcelo Becker, Girish Chowdhary

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26 (æ›´æ–°: 2025-10-17)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºZeSTä»¥è§£å†³æœªçŸ¥ç¯å¢ƒä¸­çš„å¯¼èˆªå¯è¾¾æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯è¾¾æ€§é¢„æµ‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `è§†è§‰æ¨ç†` `è‡ªä¸»å¯¼èˆª` `æœºå™¨äººæŠ€æœ¯` `é›¶-shotå­¦ä¹ ` `å®‰å…¨å¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆå¯è¾¾æ€§é¢„æµ‹æ¨¡å‹çš„æ•°æ®é›†æ—¶ï¼Œå¾€å¾€éœ€è¦å°†æœºå™¨äººç½®äºå±é™©ç¯å¢ƒä¸­ï¼Œå­˜åœ¨å®‰å…¨éšæ‚£ã€‚
2. ZeSTé€šè¿‡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„è§†è§‰æ¨ç†èƒ½åŠ›ï¼Œå®ç°äº†å®æ—¶çš„å¯è¾¾æ€§åœ°å›¾ç”Ÿæˆï¼Œé¿å…äº†æœºå™¨äººæš´éœ²äºå±é™©ä¸­ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒZeSTåœ¨å®¤å†…å’Œæˆ·å¤–ç¯å¢ƒä¸­å‡è¡¨ç°å‡ºæ›´å®‰å…¨çš„å¯¼èˆªèƒ½åŠ›ï¼Œç›¸æ¯”å…¶ä»–æ–¹æ³•æ›´èƒ½æœ‰æ•ˆåˆ°è¾¾ç›®æ ‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœºå™¨äººå’Œè‡ªä¸»å¯¼èˆªç³»ç»Ÿçš„å‘å±•ä¾èµ–äºå‡†ç¡®é¢„æµ‹åœ°å½¢å¯è¾¾æ€§çš„èƒ½åŠ›ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸éœ€è¦å°†æœºå™¨äººç½®äºæ½œåœ¨å±é™©çš„ç¯å¢ƒä¸­ï¼Œå­˜åœ¨è®¾å¤‡å’Œå®‰å…¨é£é™©ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ZeSTï¼Œä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è§†è§‰æ¨ç†èƒ½åŠ›çš„åˆ›æ–°æ–¹æ³•ï¼Œèƒ½å¤Ÿå®æ—¶åˆ›å»ºå¯è¾¾æ€§åœ°å›¾ï¼Œè€Œæ— éœ€å°†æœºå™¨äººæš´éœ²äºå±é™©ä¸­ã€‚è¯¥æ–¹æ³•ä¸ä»…å®ç°äº†é›¶-shotå¯è¾¾æ€§é¢„æµ‹ï¼Œé™ä½äº†çœŸå®æ•°æ®æ”¶é›†çš„é£é™©ï¼Œè¿˜åŠ é€Ÿäº†å…ˆè¿›å¯¼èˆªç³»ç»Ÿçš„å¼€å‘ï¼Œæä¾›äº†ä¸€ç§å…·æœ‰æˆæœ¬æ•ˆç›Šå’Œå¯æ‰©å±•æ€§çš„è§£å†³æ–¹æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å—æ§çš„å®¤å†…å’Œéç»“æ„åŒ–çš„æˆ·å¤–ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç›¸æ¯”å…¶ä»–å…ˆè¿›æ–¹æ³•æä¾›äº†æ›´å®‰å…¨çš„å¯¼èˆªï¼Œå§‹ç»ˆèƒ½å¤Ÿåˆ°è¾¾æœ€ç»ˆç›®æ ‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨æœªçŸ¥ç¯å¢ƒä¸­è¿›è¡Œå®‰å…¨å¯¼èˆªçš„å¯è¾¾æ€§é¢„æµ‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºåœ¨å±é™©ç¯å¢ƒä¸­æ”¶é›†æ•°æ®ï¼Œå­˜åœ¨è®¾å¤‡æŸåå’Œå®‰å…¨é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šZeSTçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„è§†è§‰æ¨ç†èƒ½åŠ›ï¼Œå®æ—¶ç”Ÿæˆå¯è¾¾æ€§åœ°å›¾ï¼Œä»è€Œé¿å…æœºå™¨äººåœ¨çœŸå®ç¯å¢ƒä¸­è¿›è¡Œå±é™©çš„æ•°æ®æ”¶é›†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥æ¨¡å—ã€LLMæ¨ç†æ¨¡å—å’Œå¯è¾¾æ€§åœ°å›¾ç”Ÿæˆæ¨¡å—ã€‚æ•°æ®è¾“å…¥æ¨¡å—è´Ÿè´£æ”¶é›†ç¯å¢ƒä¿¡æ¯ï¼ŒLLMæ¨ç†æ¨¡å—è¿›è¡Œè§†è§‰æ¨ç†ï¼Œæœ€åç”Ÿæˆå¯è¾¾æ€§åœ°å›¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šZeSTçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†å¤§å‹è¯­è¨€æ¨¡å‹åº”ç”¨äºå¯è¾¾æ€§é¢„æµ‹ï¼Œçªç ´äº†ä¼ ç»Ÿæ–¹æ³•å¯¹çœŸå®ç¯å¢ƒæ•°æ®çš„ä¾èµ–ï¼Œå®ç°äº†é›¶-shotå­¦ä¹ èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒZeSTé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¯è¾¾æ€§é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œå¹¶ç»“åˆäº†å¤šå±‚æ¬¡çš„ç½‘ç»œç»“æ„ä»¥å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒZeSTåœ¨å—æ§å®¤å†…å’Œéç»“æ„åŒ–æˆ·å¤–ç¯å¢ƒä¸­çš„å¯¼èˆªæˆåŠŸç‡æ˜¾è‘—é«˜äºå…¶ä»–å…ˆè¿›æ–¹æ³•ï¼Œå§‹ç»ˆèƒ½å¤Ÿå®‰å…¨åˆ°è¾¾ç›®æ ‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æ— äººæœºå¯¼èˆªå’Œæœºå™¨äººæ¢ç´¢ç­‰ã€‚é€šè¿‡æä¾›å®‰å…¨çš„å¯¼èˆªè§£å†³æ–¹æ¡ˆï¼ŒZeSTèƒ½å¤Ÿåœ¨æœªçŸ¥ç¯å¢ƒä¸­æœ‰æ•ˆåœ°è¿›è¡Œä»»åŠ¡æ‰§è¡Œï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„æœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The advancement of robotics and autonomous navigation systems hinges on the ability to accurately predict terrain traversability. Traditional methods for generating datasets to train these prediction models often involve putting robots into potentially hazardous environments, posing risks to equipment and safety. To solve this problem, we present ZeST, a novel approach leveraging visual reasoning capabilities of Large Language Models (LLMs) to create a traversability map in real-time without exposing robots to danger. Our approach not only performs zero-shot traversability and mitigates the risks associated with real-world data collection but also accelerates the development of advanced navigation systems, offering a cost-effective and scalable solution. To support our findings, we present navigation results, in both controlled indoor and unstructured outdoor environments. As shown in the experiments, our method provides safer navigation when compared to other state-of-the-art methods, constantly reaching the final goal.

