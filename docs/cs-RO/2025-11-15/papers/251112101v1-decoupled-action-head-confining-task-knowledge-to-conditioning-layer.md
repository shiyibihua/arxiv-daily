---
layout: default
title: Decoupled Action Head: Confining Task Knowledge to Conditioning Layers
---

# Decoupled Action Head: Confining Task Knowledge to Conditioning Layers

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.12101" target="_blank" class="toolbar-btn">arXiv: 2511.12101v1</a>
    <a href="https://arxiv.org/pdf/2511.12101.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.12101v1" 
            onclick="toggleFavorite(this, '2511.12101v1', 'Decoupled Action Head: Confining Task Knowledge to Conditioning Layers')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Jian Zhou, Sihao Lin, Shuai Fu, Qi WU

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-15

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Ëß£ËÄ¶Ë°å‰∏∫ÂÖãÈöÜËÆ≠ÁªÉÊñπÊ≥ïÔºåÊèêÂçáÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°ÁöÑËÆ≠ÁªÉÊïàÁéá‰∏éÊ≥õÂåñÊÄß„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ë°å‰∏∫ÂÖãÈöÜ` `Êú∫Âô®‰∫∫Êìç‰Ωú` `Ëß£ËÄ¶ËÆ≠ÁªÉ` `Êâ©Êï£Á≠ñÁï•` `Âä®‰ΩúÁîüÊàê` `ÁâπÂæÅË∞ÉÂà∂` `Ê®°ÂûãÂä†ÈÄü`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Ë°å‰∏∫ÂÖãÈöÜÊñπÊ≥ïÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÂèóÈôê‰∫éÈÖçÂØπËÆ≠ÁªÉÊï∞ÊçÆÁöÑÁ®ÄÁº∫Ôºå‰∏îÂÜÖÈÉ®Êú∫Âà∂‰∏çÂ§üÊòéÁ°ÆÔºåÂØºËá¥Ê≥õÂåñÊÄß‰∏çË∂≥„ÄÇ
2. ÊèêÂá∫Ëß£ËÄ¶ËÆ≠ÁªÉÊñπÊ°àÔºåÂà©Áî®ËøêÂä®Â≠¶ÁîüÊàêÁöÑËΩ®ËøπÈ¢ÑËÆ≠ÁªÉÈÄöÁî®Âä®‰ΩúÂ§¥ÔºåÁÑ∂ÂêéÂÜªÁªìÂπ∂ÈÄÇÂ∫îÊñ∞‰ªªÂä°ÔºåÂÆûÁé∞Áü•ËØÜËøÅÁßª„ÄÇ
3. ÂÆûÈ™åË°®ÊòéËØ•ÊñπÊ≥ïÂú®ÂêåÂàÜÂ∏ÉÂíåÂºÇÂàÜÂ∏ÉÂú∫ÊôØ‰∏≠ÂèØË°åÔºåÂπ∂ÊòæËëóÊèêÂçáËÆ≠ÁªÉÊïàÁéáÔºåÂêåÊó∂È™åËØÅ‰∫ÜÂä®‰ΩúÁîüÊàêÈ™®Âπ≤ÁΩëÁªúÁöÑÈáçË¶ÅÊÄßËæÉ‰Ωé„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ë°å‰∏∫ÂÖãÈöÜ(BC)ÊòØ‰∏ÄÁßçÊï∞ÊçÆÈ©±Âä®ÁöÑÁõëÁù£Â≠¶‰π†ÊñπÊ≥ïÔºåÈöèÁùÄËØ≠Ë®ÄÂíåËßÜËßâÈ¢ÜÂüüÁº©ÊîæÂÆöÂæãÁöÑÊàêÂäüÔºåÂÆÉÂèóÂà∞‰∫ÜË∂äÊù•Ë∂äÂ§öÁöÑÂÖ≥Ê≥®„ÄÇÂú®Êú∫Âô®‰∫∫Êìç‰ΩúÁöÑÂÆûÁé∞‰∏≠ÔºåÊâ©Êï£Á≠ñÁï•(DP)ÂèäÂÖ∂‰∏§‰∏™Âèò‰ΩìDP-CNN (DP-C)ÂíåDP-Transformer (DP-T)ÊòØÊúÄÊúâÊïàÂíåÂπøÊ≥õÈááÁî®ÁöÑÊ®°Âûã‰πã‰∏ÄÔºåÂ±ïÁ§∫‰∫ÜÈ¢ÑÊµãËøûÁª≠Âä®‰ΩúÂ∫èÂàóÁöÑ‰ºòÂäø„ÄÇÁÑ∂ËÄåÔºåDPÂíåÂÖ∂‰ªñBCÊñπÊ≥ï‰ªçÁÑ∂ÂèóÂà∞ÈÖçÂØπËÆ≠ÁªÉÊï∞ÊçÆÁ®ÄÁº∫ÁöÑÈôêÂà∂ÔºåÂπ∂‰∏îDPÊúâÊïàÊÄßÁöÑÂÜÖÈÉ®Êú∫Âà∂‰ªçÁÑ∂‰∏çÂ§üÊòéÁ°ÆÔºåÂØºËá¥Ê≥õÂåñËÉΩÂäõÊúâÈôêÔºåÂπ∂‰∏îÂú®Ê®°ÂûãÂºÄÂèë‰∏≠Áº∫‰πèÂéüÂàôÊÄßËÆæËÆ°„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçËß£ËÄ¶ËÆ≠ÁªÉÊñπÊ°àÔºåËØ•ÊñπÊ°àÂà©Áî®Âá†‰πéÊó†ÊàêÊú¨ÁöÑËøêÂä®Â≠¶ÁîüÊàêÁöÑËΩ®Ëøπ‰Ωú‰∏∫Êó†ËßÇÂØüÊï∞ÊçÆÊù•È¢ÑËÆ≠ÁªÉÈÄöÁî®Âä®‰ΩúÂ§¥(Âä®‰ΩúÁîüÊàêÂô®)„ÄÇÁÑ∂ÂêéÔºåÂÜªÁªìÈ¢ÑËÆ≠ÁªÉÁöÑÂä®‰ΩúÂ§¥ÔºåÂπ∂ÈÄöËøáÁâπÂæÅË∞ÉÂà∂‰ΩøÂÖ∂ÈÄÇÂ∫îÊñ∞ÁöÑ‰ªªÂä°„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åËØÅÊòé‰∫ÜËøôÁßçÊñπÊ≥ïÂú®ÂêåÂàÜÂ∏ÉÂíåÂºÇÂàÜÂ∏ÉÂú∫ÊôØ‰∏≠ÁöÑÂèØË°åÊÄß„ÄÇ‰Ωú‰∏∫È¢ùÂ§ñÁöÑÂ•ΩÂ§ÑÔºåËß£ËÄ¶ÊèêÈ´ò‰∫ÜËÆ≠ÁªÉÊïàÁéáÔºõ‰æãÂ¶ÇÔºåDP-CÂÆûÁé∞‰∫ÜÈ´òËææ41%ÁöÑÂä†ÈÄü„ÄÇÊ≠§Â§ñÔºåÂú®Ëß£ËÄ¶‰∏ãÔºå‰ªªÂä°ÁâπÂÆöÁü•ËØÜË¢´ÈôêÂà∂Âú®Ë∞ÉËäÇÁªÑ‰ª∂‰∏≠ÔºåÂÜçÂä†‰∏äDP-CÂú®Ê≠£Â∏∏ÂíåËß£ËÄ¶ËÆ≠ÁªÉ‰∏≠Âá†‰πéÁõ∏ÂêåÁöÑÊÄßËÉΩÔºåË°®ÊòéÂä®‰ΩúÁîüÊàêÈ™®Âπ≤Âú®Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠Ëµ∑Âà∞ÁöÑ‰ΩúÁî®ÊúâÈôê„ÄÇÂèóÊ≠§ËßÇÂØüÁöÑÂêØÂèëÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜDP-MLPÔºåÂÆÉÁî®‰ªÖ4MÂèÇÊï∞ÁöÑÁÆÄÂçïMLPÂùóÊõøÊç¢‰∫ÜDP-CÁöÑ244MÂèÇÊï∞U-NetÈ™®Âπ≤ÔºåÂú®Ê≠£Â∏∏ËÆ≠ÁªÉ‰∏ãÂÆûÁé∞‰∫Ü83.9%ÁöÑÊõ¥Âø´ËÆ≠ÁªÉÈÄüÂ∫¶ÔºåÂú®Ëß£ËÄ¶‰∏ãÂÆûÁé∞‰∫Ü89.1%ÁöÑÊõ¥Âø´ËÆ≠ÁªÉÈÄüÂ∫¶„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑË°å‰∏∫ÂÖãÈöÜÊñπÊ≥ïÔºåÂ¶ÇDiffusion Policy (DP)ÔºåÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠Èù¢‰∏¥ËÆ≠ÁªÉÊï∞ÊçÆÁ®ÄÁº∫ÁöÑÈóÆÈ¢òÔºåÂØºËá¥Ê®°ÂûãÊ≥õÂåñËÉΩÂäõÂèóÈôê„ÄÇÂêåÊó∂ÔºåDPÂÜÖÈÉ®ÊúâÊïàÊÄßÁöÑÊú∫Âà∂Â∞ö‰∏çÊòéÁ°ÆÔºåÁº∫‰πèÊåáÂØºÊ®°ÂûãËÆæËÆ°ÁöÑÁêÜËÆ∫Âü∫Á°Ä„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÂä®‰ΩúÁîüÊàê‰∏é‰ªªÂä°ÁâπÂÆöÁü•ËØÜËß£ËÄ¶„ÄÇÈÄöËøáÈ¢ÑËÆ≠ÁªÉ‰∏Ä‰∏™ÈÄöÁî®ÁöÑÂä®‰ΩúÁîüÊàêÂô®Ôºå‰ΩøÂÖ∂Â≠¶‰π†ÁîüÊàêÂêàÁêÜÁöÑÂä®‰ΩúÂ∫èÂàóÔºåÁÑ∂ÂêéÈÄöËøáÁâπÂæÅË∞ÉÂà∂ÁöÑÊñπÂºèÂ∞ÜËØ•Âä®‰ΩúÁîüÊàêÂô®ÈÄÇÈÖçÂà∞‰∏çÂêåÁöÑ‰ªªÂä°‰∏≠„ÄÇËøôÊ†∑ÂèØ‰ª•Âà©Áî®Â§ßÈáèÁöÑÊó†ÁõëÁù£Êï∞ÊçÆÔºàËøêÂä®Â≠¶ÁîüÊàêÁöÑËΩ®ËøπÔºâÊù•ÊèêÂçáÂä®‰ΩúÁîüÊàêÂô®ÁöÑÊÄßËÉΩÔºåÂπ∂ÂáèÂ∞ëÂØπÈÖçÂØπÊï∞ÊçÆÁöÑ‰æùËµñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ïÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) Âä®‰ΩúÂ§¥È¢ÑËÆ≠ÁªÉÈò∂ÊÆµÔºö‰ΩøÁî®Êó†ËßÇÂØüÊï∞ÊçÆÁöÑËøêÂä®Â≠¶ËΩ®ËøπÈ¢ÑËÆ≠ÁªÉ‰∏Ä‰∏™ÈÄöÁî®ÁöÑÂä®‰ΩúÁîüÊàêÂô®ÔºàÂä®‰ΩúÂ§¥Ôºâ„ÄÇ2) ‰ªªÂä°ÈÄÇÈÖçÈò∂ÊÆµÔºöÂÜªÁªìÈ¢ÑËÆ≠ÁªÉÁöÑÂä®‰ΩúÂ§¥ÔºåÂπ∂ÈÄöËøáÁâπÂæÅË∞ÉÂà∂ÁöÑÊñπÂºèÔºåÂ∞Ü‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÁâπÂæÅ‰ø°ÊÅØËûçÂÖ•Âà∞Âä®‰ΩúÁîüÊàêËøáÁ®ã‰∏≠Ôºå‰ªéËÄå‰ΩøÂä®‰ΩúÂ§¥ÈÄÇÂ∫îÁâπÂÆöÁöÑ‰ªªÂä°„ÄÇDP-MLP‰ΩøÁî®MLPÊõø‰ª£DP-CÁöÑU-NetÈ™®Âπ≤ÁΩëÁªú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éËß£ËÄ¶ËÆ≠ÁªÉÁöÑÊÄùÊÉ≥ÔºåÂ∞ÜÂä®‰ΩúÁîüÊàê‰∏é‰ªªÂä°ÁâπÂÆöÁü•ËØÜÂàÜÁ¶ª„ÄÇËøô‰ΩøÂæóÂèØ‰ª•Âà©Áî®Â§ßÈáèÁöÑÊó†ÁõëÁù£Êï∞ÊçÆÊù•ÊèêÂçáÂä®‰ΩúÁîüÊàêÂô®ÁöÑÊÄßËÉΩÔºåÂπ∂ÂáèÂ∞ëÂØπÈÖçÂØπÊï∞ÊçÆÁöÑ‰æùËµñ„ÄÇÊ≠§Â§ñÔºåÈÄöËøáÂÆûÈ™åÈ™åËØÅ‰∫ÜÂä®‰ΩúÁîüÊàêÈ™®Âπ≤ÁΩëÁªúÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠ÁöÑ‰ΩúÁî®ÊúâÈôêÔºå‰ªéËÄåÊèêÂá∫‰∫ÜÊõ¥ËΩªÈáèÁ∫ßÁöÑDP-MLPÊ®°Âûã„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂä®‰ΩúÂ§¥ÂèØ‰ª•‰ΩøÁî®ÂêÑÁßçÁîüÊàêÊ®°ÂûãÔºå‰æãÂ¶ÇÊâ©Êï£Ê®°Âûã„ÄÇÁâπÂæÅË∞ÉÂà∂ÂèØ‰ª•ÈÄöËøáÂêÑÁßçÊñπÂºèÂÆûÁé∞Ôºå‰æãÂ¶ÇÊù°‰ª∂ÂΩí‰∏ÄÂåñÔºàConditional NormalizationÔºâ„ÄÇËÆ∫Êñá‰∏≠‰ΩøÁî®‰∫ÜDP-CNNÂíåDP-Transformer‰Ωú‰∏∫Âü∫Á∫øÊ®°ÂûãÔºåÂπ∂ÊèêÂá∫‰∫ÜDP-MLPÔºåÂ∞ÜU-NetÊõøÊç¢‰∏∫MLPÔºåÊòæËëóÂáèÂ∞ë‰∫ÜÂèÇÊï∞Èáè„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËß£ËÄ¶ËÆ≠ÁªÉÂèØ‰ª•ÊòæËëóÊèêÂçáËÆ≠ÁªÉÊïàÁéáÔºå‰æãÂ¶ÇDP-CÂÆûÁé∞‰∫ÜÈ´òËææ41%ÁöÑÂä†ÈÄü„ÄÇÊ≠§Â§ñÔºåDP-MLPÈÄöËøáÂ∞ÜDP-CÁöÑ244MÂèÇÊï∞U-NetÈ™®Âπ≤ÊõøÊç¢‰∏∫4MÂèÇÊï∞ÁöÑMLPÔºåÂú®Ê≠£Â∏∏ËÆ≠ÁªÉ‰∏ãÂÆûÁé∞‰∫Ü83.9%ÁöÑÊõ¥Âø´ËÆ≠ÁªÉÈÄüÂ∫¶ÔºåÂú®Ëß£ËÄ¶‰∏ãÂÆûÁé∞‰∫Ü89.1%ÁöÑÊõ¥Âø´ËÆ≠ÁªÉÈÄüÂ∫¶ÔºåÂêåÊó∂‰øùÊåÅ‰∫Ü‰∏éDP-CÁõ∏ÂΩìÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°Ôºå‰æãÂ¶ÇÊäìÂèñ„ÄÅÊîæÁΩÆ„ÄÅË£ÖÈÖçÁ≠â„ÄÇÈÄöËøáËß£ËÄ¶ËÆ≠ÁªÉÔºåÂèØ‰ª•Èôç‰ΩéÂØπÂ§ßÈáèÈÖçÂØπÊï∞ÊçÆÁöÑ‰æùËµñÔºå‰ªéËÄåÂä†ÈÄüÊú∫Âô®‰∫∫Â≠¶‰π†ËøáÁ®ãÔºåÂπ∂ÊèêÂçáÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇËØ•ÊñπÊ≥ïËøòÊúâÊΩúÂäõÂ∫îÁî®‰∫éÂÖ∂‰ªñÈúÄË¶ÅÁîüÊàêËøûÁª≠Âä®‰ΩúÂ∫èÂàóÁöÑ‰ªªÂä°Ôºå‰æãÂ¶ÇËá™Âä®È©æÈ©∂„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Behavior Cloning (BC) is a data-driven supervised learning approach that has gained increasing attention with the success of scaling laws in language and vision domains. Among its implementations in robotic manipulation, Diffusion Policy (DP), with its two variants DP-CNN (DP-C) and DP-Transformer (DP-T), is one of the most effective and widely adopted models, demonstrating the advantages of predicting continuous action sequences. However, both DP and other BC methods remain constrained by the scarcity of paired training data, and the internal mechanisms underlying DP's effectiveness remain insufficiently understood, leading to limited generalization and a lack of principled design in model development. In this work, we propose a decoupled training recipe that leverages nearly cost-free kinematics-generated trajectories as observation-free data to pretrain a general action head (action generator). The pretrained action head is then frozen and adapted to novel tasks through feature modulation. Our experiments demonstrate the feasibility of this approach in both in-distribution and out-of-distribution scenarios. As an additional benefit, decoupling improves training efficiency; for instance, DP-C achieves up to a 41% speedup. Furthermore, the confinement of task-specific knowledge to the conditioning components under decoupling, combined with the near-identical performance of DP-C in both normal and decoupled training, indicates that the action generation backbone plays a limited role in robotic manipulation. Motivated by this observation, we introduce DP-MLP, which replaces the 244M-parameter U-Net backbone of DP-C with only 4M parameters of simple MLP blocks, achieving a 83.9% faster training speed under normal training and 89.1% under decoupling.

