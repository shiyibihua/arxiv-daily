---
layout: default
title: Decoupled Action Head: Confining Task Knowledge to Conditioning Layers
---

# Decoupled Action Head: Confining Task Knowledge to Conditioning Layers

**arXiv**: [2511.12101v1](https://arxiv.org/abs/2511.12101) | [PDF](https://arxiv.org/pdf/2511.12101.pdf)

**ä½œè€…**: Jian Zhou, Sihao Lin, Shuai Fu, Qi WU

**åˆ†ç±»**: cs.RO, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-15

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§£è€¦è¡Œä¸ºå…‹éš†è®­ç»ƒæ–¹æ³•ï¼Œæå‡æœºå™¨äººæ“ä½œä»»åŠ¡çš„è®­ç»ƒæ•ˆçŽ‡ä¸Žæ³›åŒ–æ€§ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è¡Œä¸ºå…‹éš†` `æœºå™¨äººæ“ä½œ` `è§£è€¦è®­ç»ƒ` `æ‰©æ•£ç­–ç•¥` `åŠ¨ä½œç”Ÿæˆ` `ç‰¹å¾è°ƒåˆ¶` `æ¨¡åž‹åŠ é€Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è¡Œä¸ºå…‹éš†æ–¹æ³•åœ¨æœºå™¨äººæ“ä½œä¸­å—é™äºŽé…å¯¹è®­ç»ƒæ•°æ®çš„ç¨€ç¼ºï¼Œä¸”å†…éƒ¨æœºåˆ¶ä¸å¤Ÿæ˜Žç¡®ï¼Œå¯¼è‡´æ³›åŒ–æ€§ä¸è¶³ã€‚
2. æå‡ºè§£è€¦è®­ç»ƒæ–¹æ¡ˆï¼Œåˆ©ç”¨è¿åŠ¨å­¦ç”Ÿæˆçš„è½¨è¿¹é¢„è®­ç»ƒé€šç”¨åŠ¨ä½œå¤´ï¼Œç„¶åŽå†»ç»“å¹¶é€‚åº”æ–°ä»»åŠ¡ï¼Œå®žçŽ°çŸ¥è¯†è¿ç§»ã€‚
3. å®žéªŒè¡¨æ˜Žè¯¥æ–¹æ³•åœ¨åŒåˆ†å¸ƒå’Œå¼‚åˆ†å¸ƒåœºæ™¯ä¸­å¯è¡Œï¼Œå¹¶æ˜¾è‘—æå‡è®­ç»ƒæ•ˆçŽ‡ï¼ŒåŒæ—¶éªŒè¯äº†åŠ¨ä½œç”Ÿæˆéª¨å¹²ç½‘ç»œçš„é‡è¦æ€§è¾ƒä½Žã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¡Œä¸ºå…‹éš†(BC)æ˜¯ä¸€ç§æ•°æ®é©±åŠ¨çš„ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œéšç€è¯­è¨€å’Œè§†è§‰é¢†åŸŸç¼©æ”¾å®šå¾‹çš„æˆåŠŸï¼Œå®ƒå—åˆ°äº†è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚åœ¨æœºå™¨äººæ“ä½œçš„å®žçŽ°ä¸­ï¼Œæ‰©æ•£ç­–ç•¥(DP)åŠå…¶ä¸¤ä¸ªå˜ä½“DP-CNN (DP-C)å’ŒDP-Transformer (DP-T)æ˜¯æœ€æœ‰æ•ˆå’Œå¹¿æ³›é‡‡ç”¨çš„æ¨¡åž‹ä¹‹ä¸€ï¼Œå±•ç¤ºäº†é¢„æµ‹è¿žç»­åŠ¨ä½œåºåˆ—çš„ä¼˜åŠ¿ã€‚ç„¶è€Œï¼ŒDPå’Œå…¶ä»–BCæ–¹æ³•ä»ç„¶å—åˆ°é…å¯¹è®­ç»ƒæ•°æ®ç¨€ç¼ºçš„é™åˆ¶ï¼Œå¹¶ä¸”DPæœ‰æ•ˆæ€§çš„å†…éƒ¨æœºåˆ¶ä»ç„¶ä¸å¤Ÿæ˜Žç¡®ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›æœ‰é™ï¼Œå¹¶ä¸”åœ¨æ¨¡åž‹å¼€å‘ä¸­ç¼ºä¹åŽŸåˆ™æ€§è®¾è®¡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è§£è€¦è®­ç»ƒæ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆåˆ©ç”¨å‡ ä¹Žæ— æˆæœ¬çš„è¿åŠ¨å­¦ç”Ÿæˆçš„è½¨è¿¹ä½œä¸ºæ— è§‚å¯Ÿæ•°æ®æ¥é¢„è®­ç»ƒé€šç”¨åŠ¨ä½œå¤´(åŠ¨ä½œç”Ÿæˆå™¨)ã€‚ç„¶åŽï¼Œå†»ç»“é¢„è®­ç»ƒçš„åŠ¨ä½œå¤´ï¼Œå¹¶é€šè¿‡ç‰¹å¾è°ƒåˆ¶ä½¿å…¶é€‚åº”æ–°çš„ä»»åŠ¡ã€‚æˆ‘ä»¬çš„å®žéªŒè¯æ˜Žäº†è¿™ç§æ–¹æ³•åœ¨åŒåˆ†å¸ƒå’Œå¼‚åˆ†å¸ƒåœºæ™¯ä¸­çš„å¯è¡Œæ€§ã€‚ä½œä¸ºé¢å¤–çš„å¥½å¤„ï¼Œè§£è€¦æé«˜äº†è®­ç»ƒæ•ˆçŽ‡ï¼›ä¾‹å¦‚ï¼ŒDP-Cå®žçŽ°äº†é«˜è¾¾41%çš„åŠ é€Ÿã€‚æ­¤å¤–ï¼Œåœ¨è§£è€¦ä¸‹ï¼Œä»»åŠ¡ç‰¹å®šçŸ¥è¯†è¢«é™åˆ¶åœ¨è°ƒèŠ‚ç»„ä»¶ä¸­ï¼Œå†åŠ ä¸ŠDP-Cåœ¨æ­£å¸¸å’Œè§£è€¦è®­ç»ƒä¸­å‡ ä¹Žç›¸åŒçš„æ€§èƒ½ï¼Œè¡¨æ˜ŽåŠ¨ä½œç”Ÿæˆéª¨å¹²åœ¨æœºå™¨äººæ“ä½œä¸­èµ·åˆ°çš„ä½œç”¨æœ‰é™ã€‚å—æ­¤è§‚å¯Ÿçš„å¯å‘ï¼Œæˆ‘ä»¬å¼•å…¥äº†DP-MLPï¼Œå®ƒç”¨ä»…4Må‚æ•°çš„ç®€å•MLPå—æ›¿æ¢äº†DP-Cçš„244Må‚æ•°U-Netéª¨å¹²ï¼Œåœ¨æ­£å¸¸è®­ç»ƒä¸‹å®žçŽ°äº†83.9%çš„æ›´å¿«è®­ç»ƒé€Ÿåº¦ï¼Œåœ¨è§£è€¦ä¸‹å®žçŽ°äº†89.1%çš„æ›´å¿«è®­ç»ƒé€Ÿåº¦ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„è¡Œä¸ºå…‹éš†æ–¹æ³•ï¼Œå¦‚Diffusion Policy (DP)ï¼Œåœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­é¢ä¸´è®­ç»ƒæ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œå¯¼è‡´æ¨¡åž‹æ³›åŒ–èƒ½åŠ›å—é™ã€‚åŒæ—¶ï¼ŒDPå†…éƒ¨æœ‰æ•ˆæ€§çš„æœºåˆ¶å°šä¸æ˜Žç¡®ï¼Œç¼ºä¹æŒ‡å¯¼æ¨¡åž‹è®¾è®¡çš„ç†è®ºåŸºç¡€ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†åŠ¨ä½œç”Ÿæˆä¸Žä»»åŠ¡ç‰¹å®šçŸ¥è¯†è§£è€¦ã€‚é€šè¿‡é¢„è®­ç»ƒä¸€ä¸ªé€šç”¨çš„åŠ¨ä½œç”Ÿæˆå™¨ï¼Œä½¿å…¶å­¦ä¹ ç”Ÿæˆåˆç†çš„åŠ¨ä½œåºåˆ—ï¼Œç„¶åŽé€šè¿‡ç‰¹å¾è°ƒåˆ¶çš„æ–¹å¼å°†è¯¥åŠ¨ä½œç”Ÿæˆå™¨é€‚é…åˆ°ä¸åŒçš„ä»»åŠ¡ä¸­ã€‚è¿™æ ·å¯ä»¥åˆ©ç”¨å¤§é‡çš„æ— ç›‘ç£æ•°æ®ï¼ˆè¿åŠ¨å­¦ç”Ÿæˆçš„è½¨è¿¹ï¼‰æ¥æå‡åŠ¨ä½œç”Ÿæˆå™¨çš„æ€§èƒ½ï¼Œå¹¶å‡å°‘å¯¹é…å¯¹æ•°æ®çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ–¹æ³•åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1) åŠ¨ä½œå¤´é¢„è®­ç»ƒé˜¶æ®µï¼šä½¿ç”¨æ— è§‚å¯Ÿæ•°æ®çš„è¿åŠ¨å­¦è½¨è¿¹é¢„è®­ç»ƒä¸€ä¸ªé€šç”¨çš„åŠ¨ä½œç”Ÿæˆå™¨ï¼ˆåŠ¨ä½œå¤´ï¼‰ã€‚2) ä»»åŠ¡é€‚é…é˜¶æ®µï¼šå†»ç»“é¢„è®­ç»ƒçš„åŠ¨ä½œå¤´ï¼Œå¹¶é€šè¿‡ç‰¹å¾è°ƒåˆ¶çš„æ–¹å¼ï¼Œå°†ä»»åŠ¡ç›¸å…³çš„ç‰¹å¾ä¿¡æ¯èžå…¥åˆ°åŠ¨ä½œç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä»Žè€Œä½¿åŠ¨ä½œå¤´é€‚åº”ç‰¹å®šçš„ä»»åŠ¡ã€‚DP-MLPä½¿ç”¨MLPæ›¿ä»£DP-Cçš„U-Netéª¨å¹²ç½‘ç»œã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽè§£è€¦è®­ç»ƒçš„æ€æƒ³ï¼Œå°†åŠ¨ä½œç”Ÿæˆä¸Žä»»åŠ¡ç‰¹å®šçŸ¥è¯†åˆ†ç¦»ã€‚è¿™ä½¿å¾—å¯ä»¥åˆ©ç”¨å¤§é‡çš„æ— ç›‘ç£æ•°æ®æ¥æå‡åŠ¨ä½œç”Ÿæˆå™¨çš„æ€§èƒ½ï¼Œå¹¶å‡å°‘å¯¹é…å¯¹æ•°æ®çš„ä¾èµ–ã€‚æ­¤å¤–ï¼Œé€šè¿‡å®žéªŒéªŒè¯äº†åŠ¨ä½œç”Ÿæˆéª¨å¹²ç½‘ç»œåœ¨æœºå™¨äººæ“ä½œä¸­çš„ä½œç”¨æœ‰é™ï¼Œä»Žè€Œæå‡ºäº†æ›´è½»é‡çº§çš„DP-MLPæ¨¡åž‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåŠ¨ä½œå¤´å¯ä»¥ä½¿ç”¨å„ç§ç”Ÿæˆæ¨¡åž‹ï¼Œä¾‹å¦‚æ‰©æ•£æ¨¡åž‹ã€‚ç‰¹å¾è°ƒåˆ¶å¯ä»¥é€šè¿‡å„ç§æ–¹å¼å®žçŽ°ï¼Œä¾‹å¦‚æ¡ä»¶å½’ä¸€åŒ–ï¼ˆConditional Normalizationï¼‰ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†DP-CNNå’ŒDP-Transformerä½œä¸ºåŸºçº¿æ¨¡åž‹ï¼Œå¹¶æå‡ºäº†DP-MLPï¼Œå°†U-Netæ›¿æ¢ä¸ºMLPï¼Œæ˜¾è‘—å‡å°‘äº†å‚æ•°é‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè§£è€¦è®­ç»ƒå¯ä»¥æ˜¾è‘—æå‡è®­ç»ƒæ•ˆçŽ‡ï¼Œä¾‹å¦‚DP-Cå®žçŽ°äº†é«˜è¾¾41%çš„åŠ é€Ÿã€‚æ­¤å¤–ï¼ŒDP-MLPé€šè¿‡å°†DP-Cçš„244Må‚æ•°U-Netéª¨å¹²æ›¿æ¢ä¸º4Må‚æ•°çš„MLPï¼Œåœ¨æ­£å¸¸è®­ç»ƒä¸‹å®žçŽ°äº†83.9%çš„æ›´å¿«è®­ç»ƒé€Ÿåº¦ï¼Œåœ¨è§£è€¦ä¸‹å®žçŽ°äº†89.1%çš„æ›´å¿«è®­ç»ƒé€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†ä¸ŽDP-Cç›¸å½“çš„æ€§èƒ½ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚æŠ“å–ã€æ”¾ç½®ã€è£…é…ç­‰ã€‚é€šè¿‡è§£è€¦è®­ç»ƒï¼Œå¯ä»¥é™ä½Žå¯¹å¤§é‡é…å¯¹æ•°æ®çš„ä¾èµ–ï¼Œä»Žè€ŒåŠ é€Ÿæœºå™¨äººå­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶æå‡æœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¥æ–¹æ³•è¿˜æœ‰æ½œåŠ›åº”ç”¨äºŽå…¶ä»–éœ€è¦ç”Ÿæˆè¿žç»­åŠ¨ä½œåºåˆ—çš„ä»»åŠ¡ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Behavior Cloning (BC) is a data-driven supervised learning approach that has gained increasing attention with the success of scaling laws in language and vision domains. Among its implementations in robotic manipulation, Diffusion Policy (DP), with its two variants DP-CNN (DP-C) and DP-Transformer (DP-T), is one of the most effective and widely adopted models, demonstrating the advantages of predicting continuous action sequences. However, both DP and other BC methods remain constrained by the scarcity of paired training data, and the internal mechanisms underlying DP's effectiveness remain insufficiently understood, leading to limited generalization and a lack of principled design in model development. In this work, we propose a decoupled training recipe that leverages nearly cost-free kinematics-generated trajectories as observation-free data to pretrain a general action head (action generator). The pretrained action head is then frozen and adapted to novel tasks through feature modulation. Our experiments demonstrate the feasibility of this approach in both in-distribution and out-of-distribution scenarios. As an additional benefit, decoupling improves training efficiency; for instance, DP-C achieves up to a 41% speedup. Furthermore, the confinement of task-specific knowledge to the conditioning components under decoupling, combined with the near-identical performance of DP-C in both normal and decoupled training, indicates that the action generation backbone plays a limited role in robotic manipulation. Motivated by this observation, we introduce DP-MLP, which replaces the 244M-parameter U-Net backbone of DP-C with only 4M parameters of simple MLP blocks, achieving a 83.9% faster training speed under normal training and 89.1% under decoupling.

