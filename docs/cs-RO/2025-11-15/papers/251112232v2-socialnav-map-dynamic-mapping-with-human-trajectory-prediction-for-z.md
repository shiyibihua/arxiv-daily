---
layout: default
title: SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation
---

# SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.12232" target="_blank" class="toolbar-btn">arXiv: 2511.12232v2</a>
    <a href="https://arxiv.org/pdf/2511.12232.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.12232v2" 
            onclick="toggleFavorite(this, '2511.12232v2', 'SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Lingfeng Zhang, Erjia Xiao, Xiaoshuai Hao, Haoxiang Fu, Zeying Gong, Long Chen, Xiaojun Liang, Renjing Xu, Hangjun Ye, Wenbo Ding

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-15 (Êõ¥Êñ∞: 2025-11-18)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/linglingxiansen/SocialNav-Map)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**SocialNav-MapÔºöÁªìÂêàÂä®ÊÄÅÂú∞Âõæ‰∏éËΩ®ËøπÈ¢ÑÊµãÁöÑÈõ∂Ê†∑Êú¨Á§æ‰∫§ÂØºËà™**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Á§æ‰∫§ÂØºËà™` `Èõ∂Ê†∑Êú¨Â≠¶‰π†` `ËΩ®ËøπÈ¢ÑÊµã` `Âä®ÊÄÅÂú∞Âõæ` `Êú∫Âô®‰∫∫ÂØºËà™`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÁ§æ‰∫§ÂØºËà™ÊñπÊ≥ïÈúÄË¶ÅÂ§ßÈáèËÆ≠ÁªÉÔºå‰∏îÊ≥õÂåñËÉΩÂäõÂ∑ÆÔºåÈöæ‰ª•ÈÄÇÂ∫îÊñ∞ÁéØÂ¢É„ÄÇ
2. SocialNav-MapÈÄöËøáÁªìÂêàÂä®ÊÄÅ‰∫∫Á±ªËΩ®ËøπÈ¢ÑÊµãÂíåÂç†ÊçÆÊ†ÖÊ†ºÂú∞ÂõæÔºåÂÆûÁé∞Èõ∂Ê†∑Êú¨Á§æ‰∫§ÂØºËà™„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåSocialNav-MapÊó†ÈúÄËÆ≠ÁªÉÂç≥ÂèØÊòæËëóÈôç‰ΩéÁ¢∞ÊíûÁéáÔºå‰ºò‰∫éÁé∞ÊúâÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫SocialNav-MapÁöÑÈõ∂Ê†∑Êú¨Á§æ‰∫§ÂØºËà™Ê°ÜÊû∂ÔºåÊó®Âú®Ëß£ÂÜ≥‰∫∫Áæ§ÂØÜÈõÜÂä®ÊÄÅÁéØÂ¢É‰∏≠Ëá™‰∏ªÁßªÂä®Êú∫Âô®‰∫∫ÁöÑÂÆâÂÖ®ÂØºËà™ÈóÆÈ¢ò„ÄÇËØ•Ê°ÜÊû∂ÁªìÂêà‰∫ÜÂä®ÊÄÅ‰∫∫Á±ªËΩ®ËøπÈ¢ÑÊµãÂíåÂç†ÊçÆÊ†ÖÊ†ºÂú∞ÂõæÊûÑÂª∫ÔºåÊó†ÈúÄÈíàÂØπÁâπÂÆöÁéØÂ¢ÉËøõË°åËÆ≠ÁªÉÂç≥ÂèØÂÆûÁé∞ÂÆâÂÖ®È´òÊïàÁöÑÂØºËà™„ÄÇSocialNav-MapÈ¶ñÂÖàÂ∞ÜÁõÆÊ†á‰ΩçÁΩÆËΩ¨Êç¢Âà∞Âú∞ÂõæÂùêÊ†áÁ≥ª‰∏≠ÔºåÁÑ∂ÂêéÂàõÂª∫‰∏Ä‰∏™Âä®ÊÄÅÂç†ÊçÆÊ†ÖÊ†ºÂú∞ÂõæÔºåÂ∞ÜÈ¢ÑÊµãÁöÑ‰∫∫Á±ªËøêÂä®‰Ωú‰∏∫Âä®ÊÄÅÈöúÁ¢çÁâ©Á∫≥ÂÖ•ÂÖ∂‰∏≠„ÄÇËØ•Ê°ÜÊû∂ÈááÁî®ÂéÜÂè≤È¢ÑÊµãÂíåÊñπÂêëÈ¢ÑÊµã‰∏§Áßç‰∫íË°•ÊñπÊ≥ïËøõË°å‰∫∫Á±ªËΩ®ËøπÈ¢ÑÊµã„ÄÇÈÄöËøáÂ∞ÜËøô‰∫õÈ¢ÑÊµãËΩ®ËøπÊï¥ÂêàÂà∞Âç†ÊçÆÊ†ÖÊ†ºÂú∞Âõæ‰∏≠ÔºåÊú∫Âô®‰∫∫ËÉΩÂ§ü‰∏ªÂä®ÈÅøÂºÄ‰∏é‰∫∫Á±ªÁöÑÊΩúÂú®Á¢∞ÊíûÔºåÂêåÊó∂È´òÊïàÂú∞ÂØºËà™Âà∞ÁõÆÁöÑÂú∞„ÄÇÂú®Social-HM3DÂíåSocial-MP3DÊï∞ÊçÆÈõÜ‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåSocialNav-MapÊòæËëó‰ºò‰∫éÈúÄË¶Å2396 GPUÂ∞èÊó∂ËÆ≠ÁªÉÁöÑÁé∞ÊúâÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÊñπÊ≥ïÔºåÂπ∂‰∏îÂú®Êñ∞ÁöÑÁéØÂ¢É‰∏≠Êó†ÈúÄ‰ªª‰ΩïËÆ≠ÁªÉÂç≥ÂèØÂ∞Ü‰∫∫Á±ªÁ¢∞ÊíûÁéáÈôç‰Ωé10%‰ª•‰∏ä„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂú®‰∫∫Áæ§ÂØÜÈõÜÁöÑÂä®ÊÄÅÁéØÂ¢É‰∏≠ÔºåÂ¶Ç‰Ωï‰ΩøÊú∫Âô®‰∫∫ÂÆâÂÖ®„ÄÅÈ´òÊïàÂú∞ÂØºËà™Âà∞ÁõÆÊ†á‰ΩçÁΩÆÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇÁé∞ÊúâÁöÑÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÊñπÊ≥ïÈúÄË¶ÅÂ§ßÈáèÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºåÂπ∂‰∏îÂú®Êñ∞ÁöÑÁéØÂ¢É‰∏≠Ê≥õÂåñËÉΩÂäõËæÉÂ∑ÆÔºåÈúÄË¶ÅËøõË°åÈ¢ùÂ§ñÁöÑÂæÆË∞ÉÔºåËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSocialNav-MapÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®‰∫∫Á±ªËΩ®ËøπÈ¢ÑÊµãÊù•ÊûÑÂª∫Âä®ÊÄÅÁöÑÂç†ÊçÆÊ†ÖÊ†ºÂú∞ÂõæÔºåÂ∞ÜÈ¢ÑÊµãÁöÑ‰∫∫Á±ªËøêÂä®‰Ωú‰∏∫Âä®ÊÄÅÈöúÁ¢çÁâ©Ôºå‰ªéËÄå‰ΩøÊú∫Âô®‰∫∫ËÉΩÂ§üÊèêÂâçËßÑÂàíË∑ØÂæÑÔºåÈÅøÂÖçÁ¢∞Êíû„ÄÇËøôÁßçÊñπÊ≥ïÈÅøÂÖç‰∫ÜÂØπÁâπÂÆöÁéØÂ¢ÉÁöÑËÆ≠ÁªÉÔºåÂÆûÁé∞‰∫ÜÈõ∂Ê†∑Êú¨ÁöÑÁ§æ‰∫§ÂØºËà™„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSocialNav-MapÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ≠•È™§Ôºö1) Â∞ÜÁõÆÊ†á‰ΩçÁΩÆËΩ¨Êç¢Âà∞Âú∞ÂõæÂùêÊ†áÁ≥ª‰∏≠Ôºõ2) Âà©Áî®ÂéÜÂè≤È¢ÑÊµãÂíåÊñπÂêëÈ¢ÑÊµã‰∏§ÁßçÊñπÊ≥ïÈ¢ÑÊµã‰∫∫Á±ªÁöÑÊú™Êù•ËΩ®ËøπÔºõ3) Â∞ÜÈ¢ÑÊµãÁöÑËΩ®ËøπÊï¥ÂêàÂà∞Âç†ÊçÆÊ†ÖÊ†ºÂú∞Âõæ‰∏≠ÔºåÁîüÊàêÂä®ÊÄÅÂç†ÊçÆÊ†ÖÊ†ºÂú∞ÂõæÔºõ4) Âà©Áî®Ë∑ØÂæÑËßÑÂàíÁÆóÊ≥ïÂú®Âä®ÊÄÅÂç†ÊçÆÊ†ÖÊ†ºÂú∞Âõæ‰∏äËßÑÂàíÂá∫ÂÆâÂÖ®„ÄÅÈ´òÊïàÁöÑË∑ØÂæÑ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSocialNav-MapÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞Ü‰∫∫Á±ªËΩ®ËøπÈ¢ÑÊµã‰∏éÂç†ÊçÆÊ†ÖÊ†ºÂú∞ÂõæÁõ∏ÁªìÂêàÔºåÊûÑÂª∫‰∫ÜÂä®ÊÄÅÁöÑÂØºËà™ÁéØÂ¢ÉË°®Á§∫„ÄÇ‰∏é‰º†ÁªüÁöÑÈùôÊÄÅÂú∞ÂõæÁõ∏ÊØîÔºåÂä®ÊÄÅÂç†ÊçÆÊ†ÖÊ†ºÂú∞ÂõæËÉΩÂ§üÂèçÊò†‰∫∫Áæ§ÁöÑËøêÂä®Ë∂ãÂäøÔºå‰ΩøÊú∫Âô®‰∫∫ËÉΩÂ§üÊõ¥Â•ΩÂú∞È¢ÑÊµãÊΩúÂú®ÁöÑÁ¢∞ÊíûÈ£éÈô©Ôºå‰ªéËÄåÂÅöÂá∫Êõ¥ÂêàÁêÜÁöÑÂØºËà™ÂÜ≥Á≠ñ„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÂÆûÁé∞‰∫ÜÈõ∂Ê†∑Êú¨Â≠¶‰π†ÔºåÊó†ÈúÄÈíàÂØπÁâπÂÆöÁéØÂ¢ÉËøõË°åËÆ≠ÁªÉ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®‰∫∫Á±ªËΩ®ËøπÈ¢ÑÊµãÊñπÈù¢ÔºåSocialNav-MapÈááÁî®‰∫ÜÂéÜÂè≤È¢ÑÊµãÂíåÊñπÂêëÈ¢ÑÊµã‰∏§Áßç‰∫íË°•ÁöÑÊñπÊ≥ï„ÄÇÂéÜÂè≤È¢ÑÊµãÂü∫‰∫é‰∫∫Á±ªËøáÂéªÁöÑËøêÂä®ËΩ®ËøπÊù•È¢ÑÊµãÊú™Êù•ÁöÑ‰ΩçÁΩÆÔºåËÄåÊñπÂêëÈ¢ÑÊµãÂàôÂü∫‰∫é‰∫∫Á±ªÂΩìÂâçÁöÑÊúùÂêëÂíåÈÄüÂ∫¶Êù•È¢ÑÊµãÊú™Êù•ÁöÑ‰ΩçÁΩÆ„ÄÇËøô‰∏§ÁßçÊñπÊ≥ïÂèØ‰ª•Áõ∏‰∫íË°•ÂÖÖÔºåÊèêÈ´òËΩ®ËøπÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂú®Âä®ÊÄÅÂç†ÊçÆÊ†ÖÊ†ºÂú∞ÂõæÁöÑÊûÑÂª∫ÊñπÈù¢ÔºåSocialNav-MapÊ†πÊçÆÈ¢ÑÊµãËΩ®ËøπÁöÑ‰∏çÁ°ÆÂÆöÊÄßÔºåÂØπÂç†ÊçÆÊ†ÖÊ†ºËøõË°åÂä†ÊùÉÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÂèçÊò†‰∫∫Áæ§ÁöÑËøêÂä®È£éÈô©„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SocialNav-MapÂú®Social-HM3DÂíåSocial-MP3DÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂπøÊ≥õÁöÑÂÆûÈ™åÔºåÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÊñπÊ≥ïÔºåÂêéËÄÖÈúÄË¶Å2396 GPUÂ∞èÊó∂ÁöÑËÆ≠ÁªÉ„ÄÇSocialNav-MapÂú®Êñ∞ÁöÑÁéØÂ¢É‰∏≠Êó†ÈúÄ‰ªª‰ΩïËÆ≠ÁªÉÂç≥ÂèØÂ∞Ü‰∫∫Á±ªÁ¢∞ÊíûÁéáÈôç‰Ωé10%‰ª•‰∏äÔºåËØÅÊòé‰∫ÜÂÖ∂‰ºòË∂äÁöÑÊ≥õÂåñËÉΩÂäõÂíåÂÆûÁî®‰ª∑ÂÄº„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SocialNav-MapÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶Å‰∏é‰∫∫Á±ªËøõË°å‰∫§‰∫íÁöÑÊú∫Âô®‰∫∫ÂØºËà™Âú∫ÊôØÔºå‰æãÂ¶ÇÂïÜÂú∫ÂØºËßàÊú∫Âô®‰∫∫„ÄÅÂåªÈô¢ÈÖçÈÄÅÊú∫Âô®‰∫∫„ÄÅÈ§êÂéÖÊúçÂä°Êú∫Âô®‰∫∫Á≠â„ÄÇËØ•Á†îÁ©∂ÊàêÊûúÊúâÂä©‰∫éÊèêÂçáÊú∫Âô®‰∫∫Âú®Â§çÊùÇÂä®ÊÄÅÁéØÂ¢É‰∏≠ÁöÑËá™‰∏ªÂØºËà™ËÉΩÂäõÔºåÈôç‰ΩéÂÆâÂÖ®È£éÈô©ÔºåÊèêÈ´òÊúçÂä°ÊïàÁéáÔºåÂπ∂‰∏∫Êú™Êù•‰∫∫Êú∫Âçè‰ΩúÁ≥ªÁªüÁöÑÂèëÂ±ïÂ•†ÂÆöÂü∫Á°Ä„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Social navigation in densely populated dynamic environments poses a significant challenge for autonomous mobile robots, requiring advanced strategies for safe interaction. Existing reinforcement learning (RL)-based methods require over 2000+ hours of extensive training and often struggle to generalize to unfamiliar environments without additional fine-tuning, limiting their practical application in real-world scenarios. To address these limitations, we propose SocialNav-Map, a novel zero-shot social navigation framework that combines dynamic human trajectory prediction with occupancy mapping, enabling safe and efficient navigation without the need for environment-specific training. Specifically, SocialNav-Map first transforms the task goal position into the constructed map coordinate system. Subsequently, it creates a dynamic occupancy map that incorporates predicted human movements as dynamic obstacles. The framework employs two complementary methods for human trajectory prediction: history prediction and orientation prediction. By integrating these predicted trajectories into the occupancy map, the robot can proactively avoid potential collisions with humans while efficiently navigating to its destination. Extensive experiments on the Social-HM3D and Social-MP3D datasets demonstrate that SocialNav-Map significantly outperforms state-of-the-art (SOTA) RL-based methods, which require 2,396 GPU hours of training. Notably, it reduces human collision rates by over 10% without necessitating any training in novel environments. By eliminating the need for environment-specific training, SocialNav-Map achieves superior navigation performance, paving the way for the deployment of social navigation systems in real-world environments characterized by diverse human behaviors. The code is available at: https://github.com/linglingxiansen/SocialNav-Map.

