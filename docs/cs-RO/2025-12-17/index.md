---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-12-17
---

# cs.ROï¼ˆ2025-12-17ï¼‰

ğŸ“Š å…± **11** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (5)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (4)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251215692v1-mimic-video-video-action-models-for-generalizable-robot-control-beyo.html">mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs</a></td>
  <td>æå‡ºmimic-videoä»¥è§£å†³æœºå™¨äººæ§åˆ¶ä¸­çš„ç‰©ç†ç†è§£é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">flow matching</span> <span class="paper-tag">vision-language-action</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.15692v1" onclick="toggleFavorite(this, '2512.15692v1', 'mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251215020v1-iss-policy-scalable-diffusion-policy-with-implicit-scene-supervision.html">ISS Policy : Scalable Diffusion Policy with Implicit Scene Supervision</a></td>
  <td>æå‡ºéšå¼åœºæ™¯ç›‘ç£æ‰©æ•£ç­–ç•¥ï¼Œæå‡æœºå™¨äººæ“ä½œä»»åŠ¡çš„æ³›åŒ–æ€§å’Œè®­ç»ƒæ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous hand</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.15020v1" onclick="toggleFavorite(this, '2512.15020v1', 'ISS Policy : Scalable Diffusion Policy with Implicit Scene Supervision')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251215309v1-guangming-explorer-a-four-legged-robot-platform-for-autonomous-explo.html">GuangMing-Explorer: A Four-Legged Robot Platform for Autonomous Exploration in General Environments</a></td>
  <td>GuangMing-Explorerï¼šç”¨äºé€šç”¨ç¯å¢ƒè‡ªä¸»æ¢ç´¢çš„å››è¶³æœºå™¨äººå¹³å°</td>
  <td class="tags-cell"><span class="paper-tag">legged robot</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.15309v1" onclick="toggleFavorite(this, '2512.15309v1', 'GuangMing-Explorer: A Four-Legged Robot Platform for Autonomous Exploration in General Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251215476v1-quantgraph-a-receding-horizon-quantum-graph-solver.html">QuantGraph: A Receding-Horizon Quantum Graph Solver</a></td>
  <td>æå‡ºQuantGraphï¼Œä¸€ç§åŸºäºåé€€è§†ç•Œçš„é‡å­å›¾æ±‚è§£å™¨ï¼Œæå‡å›¾ä¼˜åŒ–æ•ˆç‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">model predictive control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.15476v1" onclick="toggleFavorite(this, '2512.15476v1', 'QuantGraph: A Receding-Horizon Quantum Graph Solver')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251215448v1-load-based-variable-transmission-mechanism-for-robotic-applications.html">Load-Based Variable Transmission Mechanism for Robotic Applications</a></td>
  <td>æå‡ºåŸºäºè´Ÿè½½çš„å¯å˜ä¼ åŠ¨æœºåˆ¶ï¼Œæå‡æœºå™¨äººå…³èŠ‚åœ¨åŠ¨æ€è´Ÿè½½ä¸‹çš„æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">legged robot</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.15448v1" onclick="toggleFavorite(this, '2512.15448v1', 'Load-Based Variable Transmission Mechanism for Robotic Applications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>6</td>
  <td><a href="./papers/251215258v1-vla-an-an-efficient-and-onboard-vision-language-action-framework-for.html">VLA-AN: An Efficient and Onboard Vision-Language-Action Framework for Aerial Navigation in Complex Environments</a></td>
  <td>æå‡ºVLA-ANï¼Œç”¨äºå¤æ‚ç¯å¢ƒä¸­æ— äººæœºé«˜æ•ˆã€å®‰å…¨çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œç«¯åˆ°ç«¯å¯¼èˆªã€‚</td>
  <td class="tags-cell"><span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">gaussian splatting</span> <span class="paper-tag">splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.15258v1" onclick="toggleFavorite(this, '2512.15258v1', 'VLA-AN: An Efficient and Onboard Vision-Language-Action Framework for Aerial Navigation in Complex Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251215557v1-omcl-open-vocabulary-monte-carlo-localization.html">OMCL: Open-vocabulary Monte Carlo Localization</a></td>
  <td>æå‡ºåŸºäºè§†è§‰-è¯­è¨€ç‰¹å¾çš„å¼€æ”¾è¯æ±‡è’™ç‰¹å¡æ´›å®šä½æ–¹æ³•ï¼Œæå‡è·¨æ¨¡æ€åœ°å›¾ç¯å¢ƒä¸‹çš„æœºå™¨äººå®šä½é²æ£’æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.15557v1" onclick="toggleFavorite(this, '2512.15557v1', 'OMCL: Open-vocabulary Monte Carlo Localization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251215080v1-nap3d-nerf-assisted-3d-3d-pose-alignment-for-autonomous-vehicles.html">NAP3D: NeRF Assisted 3D-3D Pose Alignment for Autonomous Vehicles</a></td>
  <td>NAP3Dï¼šNeRFè¾…åŠ©çš„3D-3Dä½å§¿å¯¹é½ï¼Œç”¨äºæå‡è‡ªåŠ¨é©¾é©¶è½¦è¾†å®šä½ç²¾åº¦</td>
  <td class="tags-cell"><span class="paper-tag">NeRF</span> <span class="paper-tag">neural radiance field</span> <span class="paper-tag">geometric consistency</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.15080v1" onclick="toggleFavorite(this, '2512.15080v1', 'NAP3D: NeRF Assisted 3D-3D Pose Alignment for Autonomous Vehicles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251215047v1-hero-hierarchical-traversable-3d-scene-graphs-for-embodied-navigatio.html">HERO: Hierarchical Traversable 3D Scene Graphs for Embodied Navigation Among Movable Obstacles</a></td>
  <td>æå‡ºHEROæ¡†æ¶ä»¥è§£å†³åŠ¨æ€éšœç¢ç‰©å¯¼èˆªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">traversability</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.15047v1" onclick="toggleFavorite(this, '2512.15047v1', 'HERO: Hierarchical Traversable 3D Scene Graphs for Embodied Navigation Among Movable Obstacles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>10</td>
  <td><a href="./papers/251215411v1-mivla-towards-generalizable-vision-language-action-model-with-human-.html">MiVLA: Towards Generalizable Vision-Language-Action Model with Human-Robot Mutual Imitation Pre-training</a></td>
  <td>MiVLAï¼šåŸºäºäºº-æœºäº’æ¨¡ä»¿é¢„è®­ç»ƒçš„é€šç”¨è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.15411v1" onclick="toggleFavorite(this, '2512.15411v1', 'MiVLA: Towards Generalizable Vision-Language-Action Model with Human-Robot Mutual Imitation Pre-training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>11</td>
  <td><a href="./papers/251215111v1-bev-patch-pf-particle-filtering-with-bev-aerial-feature-matching-for.html">BEV-Patch-PF: Particle Filtering with BEV-Aerial Feature Matching for Off-Road Geo-Localization</a></td>
  <td>æå‡ºBEV-Patch-PFï¼Œåˆ©ç”¨BEVç‰¹å¾åŒ¹é…çš„ç²’å­æ»¤æ³¢å®ç°è¶Šé‡ç¯å¢ƒæ— GPSå®šä½</td>
  <td class="tags-cell"><span class="paper-tag">feature matching</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.15111v1" onclick="toggleFavorite(this, '2512.15111v1', 'BEV-Patch-PF: Particle Filtering with BEV-Aerial Feature Matching for Off-Road Geo-Localization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)