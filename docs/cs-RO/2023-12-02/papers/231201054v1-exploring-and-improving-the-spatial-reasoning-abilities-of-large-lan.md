---
layout: default
title: Exploring and Improving the Spatial Reasoning Abilities of Large Language Models
---

# Exploring and Improving the Spatial Reasoning Abilities of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.01054" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.01054v1</a>
  <a href="https://arxiv.org/pdf/2312.01054.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.01054v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.01054v1', 'Exploring and Improving the Spatial Reasoning Abilities of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Manasi Sharma

**åˆ†ç±»**: cs.RO, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2023-12-02

**å¤‡æ³¨**: Published in NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢ç´¢å¹¶æå‡å¤§è¯­è¨€æ¨¡å‹åœ¨æœºå™¨äººè½¨è¿¹æ•°æ®ä¸Šçš„ç©ºé—´æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `ç©ºé—´æ¨ç†` `æœºå™¨äººè½¨è¿¹` `æç¤ºå·¥ç¨‹` `CALVINåŸºçº¿`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨æ•°å€¼è½¨è¿¹æ•°æ®çš„ç©ºé—´æ¨ç†èƒ½åŠ›ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨æœºå™¨äººä»»åŠ¡ä¸­ã€‚
2. æå‡ºä¸€ç§åŸºäºå‰ç¼€çš„æç¤ºæœºåˆ¶ï¼Œå¼•å¯¼LLMæ›´å¥½åœ°ç†è§£å’Œå¤„ç†ç©ºé—´ä¿¡æ¯ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨3Dè½¨è¿¹æ•°æ®å’ŒSpartQAä»»åŠ¡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œæœ€é«˜è¾¾33%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ˜¯å¼ºå¤§çš„åºåˆ—å»ºæ¨¡å·¥å…·ï¼Œå…·æœ‰å†…åœ¨çš„é€šç”¨æ¨¡å¼è¯†åˆ«èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬æ›´å¹¿æ³›çš„ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åº”ç”¨äºæ•°å€¼è½¨è¿¹æ•°æ®æ—¶ï¼Œä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡ç ”ç©¶äº†ChatGPT-3.5ã€ChatGPT-4å’ŒLlama 2 7Bæ¨¡å‹åœ¨å¤„ç†æ¥è‡ªCALVINåŸºçº¿çš„3Dæœºå™¨äººè½¨è¿¹æ•°æ®ä»¥åŠç›¸å…³ä»»åŠ¡ï¼ˆåŒ…æ‹¬2Dæ–¹å‘å’Œå½¢çŠ¶æ ‡è®°ï¼‰æ—¶çš„å³æ—¶æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„åŸºäºå‰ç¼€çš„æç¤ºæœºåˆ¶ï¼Œè¯¥æœºåˆ¶åœ¨3Dè½¨è¿¹æ•°æ®ä¸Šäº§ç”Ÿäº†33%çš„æ”¹è¿›ï¼Œå¹¶ä¸”åœ¨SpartQAä»»åŠ¡ä¸Šæ¯”é›¶æ ·æœ¬æç¤ºæé«˜äº†é«˜è¾¾10%ï¼ˆå…¶ä»–æç¤ºç±»å‹ä¹Ÿæœ‰æ‰€å¢ç›Šï¼‰ã€‚å¯¹3Dè½¨è¿¹æ•°æ®çš„å®éªŒä¸ºäº†è§£LLMå¦‚ä½•å¤„ç†æ•°å€¼å’Œç©ºé—´ä¿¡æ¯æä¾›äº†ä¸€ä¸ªæœ‰è¶£çš„è§†è§’ï¼Œä»è€Œä¸ºè¯†åˆ«æœªæ¥å¢å¼ºçš„ç›®æ ‡é¢†åŸŸå¥ å®šäº†åšå®çš„åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†3Dæœºå™¨äººè½¨è¿¹æ•°æ®æ—¶ï¼Œç©ºé—´æ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚é›¶æ ·æœ¬æç¤ºï¼Œæ— æ³•å……åˆ†åˆ©ç”¨LLMsçš„æ½œåœ¨èƒ½åŠ›ï¼Œå¯¼è‡´åœ¨è½¨è¿¹ç†è§£å’Œç›¸å…³ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¸ä½³ã€‚ç—›ç‚¹åœ¨äºLLMséš¾ä»¥æœ‰æ•ˆæå–å’Œåˆ©ç”¨è½¨è¿¹æ•°æ®ä¸­çš„ç©ºé—´ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å‰ç¼€æç¤ºï¼ˆprefix-based promptingï¼‰æ¥å¼•å¯¼LLMsæ›´å¥½åœ°ç†è§£å’Œå¤„ç†ç©ºé—´ä¿¡æ¯ã€‚é€šè¿‡åœ¨è¾“å…¥ä¸­æ·»åŠ ç‰¹å®šçš„å‰ç¼€ï¼Œå¯ä»¥å‘LLMsæä¾›å…³äºè½¨è¿¹æ•°æ®ç»“æ„å’Œä»»åŠ¡ç›®æ ‡çš„é¢å¤–ä¸Šä¸‹æ–‡ï¼Œä»è€Œæé«˜å…¶æ¨ç†èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨å¼¥åˆLLMsçš„é€šç”¨æ¨¡å¼è¯†åˆ«èƒ½åŠ›ä¸ç‰¹å®šç©ºé—´æ¨ç†ä»»åŠ¡ä¹‹é—´çš„å·®è·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®å‡†å¤‡ï¼šä½¿ç”¨CALVINåŸºçº¿çš„3Dæœºå™¨äººè½¨è¿¹æ•°æ®ï¼Œä»¥åŠç›¸å…³çš„2Dæ–¹å‘å’Œå½¢çŠ¶æ ‡è®°ä»»åŠ¡ã€‚2) æ¨¡å‹é€‰æ‹©ï¼šé€‰æ‹©ChatGPT-3.5ã€ChatGPT-4å’ŒLlama 2 7Bç­‰LLMsè¿›è¡Œå®éªŒã€‚3) æç¤ºå·¥ç¨‹ï¼šè®¾è®¡ä¸åŒçš„æç¤ºç­–ç•¥ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬æç¤ºå’ŒåŸºäºå‰ç¼€çš„æç¤ºã€‚4) è¯„ä¼°ï¼šä½¿ç”¨ç›¸å…³æŒ‡æ ‡è¯„ä¼°LLMsåœ¨ä¸åŒæç¤ºç­–ç•¥ä¸‹çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†åŸºäºå‰ç¼€çš„æç¤ºæœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„é›¶æ ·æœ¬æç¤ºç›¸æ¯”ï¼Œè¯¥æ–¹æ³•é€šè¿‡æä¾›é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ˜¾è‘—æé«˜äº†LLMsåœ¨ç©ºé—´æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚è¿™ç§æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œå®ƒä¸æ˜¯ç®€å•åœ°å°†è½¨è¿¹æ•°æ®è¾“å…¥LLMsï¼Œè€Œæ˜¯é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºæ¥å¼•å¯¼LLMsè¿›è¡Œæ¨ç†ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åœ¨äºå‰ç¼€æç¤ºçš„å…·ä½“å†…å®¹ã€‚è®ºæ–‡ä¸­è®¾è®¡äº†å¤šç§å‰ç¼€ï¼Œæ—¨åœ¨æä¾›å…³äºè½¨è¿¹æ•°æ®ç»“æ„ã€ä»»åŠ¡ç›®æ ‡å’ŒæœŸæœ›è¾“å‡ºæ ¼å¼çš„ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œå‰ç¼€å¯ä»¥åŒ…å«ä»»åŠ¡æè¿°ã€è¾“å…¥æ ¼å¼ç¤ºä¾‹å’Œè¾“å‡ºæ ¼å¼è¦æ±‚ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„å–å†³äºæ‰€ä½¿ç”¨çš„LLMï¼Œè®ºæ–‡ä¸»è¦å…³æ³¨æç¤ºç­–ç•¥çš„è®¾è®¡ï¼Œè€Œéæ¨¡å‹ç»“æ„çš„ä¿®æ”¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„åŸºäºå‰ç¼€çš„æç¤ºæœºåˆ¶åœ¨3Dè½¨è¿¹æ•°æ®ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¾¾åˆ°äº†33%ã€‚æ­¤å¤–ï¼Œåœ¨SpartQAä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•ä¹Ÿæ¯”é›¶æ ·æœ¬æç¤ºæé«˜äº†é«˜è¾¾10%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œé€šè¿‡æœ‰æ•ˆçš„æç¤ºå·¥ç¨‹ï¼Œå¯ä»¥æ˜¾è‘—æå‡LLMåœ¨ç©ºé—´æ¨ç†ä»»åŠ¡ä¸Šçš„èƒ½åŠ›ï¼Œä½¿å…¶æ›´å¥½åœ°åº”ç”¨äºå®é™…åœºæ™¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡LLMçš„ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥ä½¿æœºå™¨äººæ›´å¥½åœ°ç†è§£å’Œæ‰§è¡Œå¤æ‚ä»»åŠ¡ï¼Œæé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ï¼Œå¹¶å¢å¼ºè™šæ‹Ÿç°å®ç¯å¢ƒçš„äº¤äº’æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åº”ç”¨äºæ›´å¹¿æ³›çš„éœ€è¦ç©ºé—´ç†è§£å’Œæ¨ç†çš„åœºæ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) represent formidable tools for sequence modeling, boasting an innate capacity for general pattern recognition. Nevertheless, their broader spatial reasoning capabilities, especially applied to numerical trajectory data, remain insufficiently explored. In this paper, we investigate the out-of-the-box performance of ChatGPT-3.5, ChatGPT-4 and Llama 2 7B models when confronted with 3D robotic trajectory data from the CALVIN baseline and associated tasks, including 2D directional and shape labeling. Additionally, we introduce a novel prefix-based prompting mechanism, which yields a 33% improvement on the 3D trajectory data and an increase of up to 10% on SpartQA tasks over zero-shot prompting (with gains for other prompting types as well). The experimentation with 3D trajectory data offers an intriguing glimpse into the manner in which LLMs engage with numerical and spatial information, thus laying a solid foundation for the identification of target areas for future enhancements.

