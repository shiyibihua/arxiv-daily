---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-09-16
---

# cs.ROï¼ˆ2025-09-16ï¼‰

ğŸ“Š å…± **35** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (18 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (9)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (4 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (18 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250913534v1-embracing-bulky-objects-with-humanoid-robots-whole-body-manipulation.html">Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning</a></td>
  <td>æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„äººå½¢æœºå™¨äººå…¨èº«æ“ä½œæ¡†æ¶ï¼Œè§£å†³æ‹¥æŠ±å¤§ä½“ç§¯ç‰©ä½“çš„ç¨³å®šæ“ä½œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13534v1" data-paper-url="./papers/250913534v1-embracing-bulky-objects-with-humanoid-robots-whole-body-manipulation.html" onclick="toggleFavorite(this, '2509.13534v1', 'Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250912858v1-contrastive-representation-learning-for-robust-sim-to-real-transfer-.html">Contrastive Representation Learning for Robust Sim-to-Real Transfer of Adaptive Humanoid Locomotion</a></td>
  <td>æå‡ºå¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œæå‡äººå½¢æœºå™¨äººé€‚åº”æ€§æ­¥æ€çš„Sim-to-Realè¿ç§»é²æ£’æ€§</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid locomotion</span> <span class="paper-tag">locomotion</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12858v1" data-paper-url="./papers/250912858v1-contrastive-representation-learning-for-robust-sim-to-real-transfer-.html" onclick="toggleFavorite(this, '2509.12858v1', 'Contrastive Representation Learning for Robust Sim-to-Real Transfer of Adaptive Humanoid Locomotion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250912776v1-integrating-trajectory-optimization-and-reinforcement-learning-for-q.html">Integrating Trajectory Optimization and Reinforcement Learning for Quadrupedal Jumping with Terrain-Adaptive Landing</a></td>
  <td>æå‡ºç»“åˆè½¨è¿¹ä¼˜åŒ–ä¸å¼ºåŒ–å­¦ä¹ çš„å››è¶³æœºå™¨äººè·³è·ƒæ¡†æ¶ï¼Œå®ç°åœ°å½¢è‡ªé€‚åº”ç€é™†</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">locomotion</span> <span class="paper-tag">trajectory optimization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12776v1" data-paper-url="./papers/250912776v1-integrating-trajectory-optimization-and-reinforcement-learning-for-q.html" onclick="toggleFavorite(this, '2509.12776v1', 'Integrating Trajectory Optimization and Reinforcement Learning for Quadrupedal Jumping with Terrain-Adaptive Landing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250914178v1-textscgen2real-towards-demo-free-dexterous-manipulation-by-harnessin.html">\textsc{Gen2Real}: Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video</a></td>
  <td>Gen2Realï¼šåˆ©ç”¨ç”Ÿæˆè§†é¢‘å®ç°å…ç¤ºæ•™çš„çµå·§æ“ä½œ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span> <span class="paper-tag">trajectory optimization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14178v1" data-paper-url="./papers/250914178v1-textscgen2real-towards-demo-free-dexterous-manipulation-by-harnessin.html" onclick="toggleFavorite(this, '2509.14178v1', '\textsc{Gen2Real}: Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250913239v1-collaborative-loco-manipulation-for-pick-and-place-tasks-with-dynami.html">Collaborative Loco-Manipulation for Pick-and-Place Tasks with Dynamic Reward Curriculum</a></td>
  <td>æå‡ºåŸºäºåŠ¨æ€å¥–åŠ±è¯¾ç¨‹çš„åˆ†å±‚å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œè§£å†³å•/åŒè‡‚è…¿å¼æœºå™¨äººååŒæŠ“å–æ”¾ç½®ä»»åŠ¡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">legged robot</span> <span class="paper-tag">manipulation</span> <span class="paper-tag">loco-manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13239v1" data-paper-url="./papers/250913239v1-collaborative-loco-manipulation-for-pick-and-place-tasks-with-dynami.html" onclick="toggleFavorite(this, '2509.13239v1', 'Collaborative Loco-Manipulation for Pick-and-Place Tasks with Dynamic Reward Curriculum')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250913200v2-stageact-stage-conditioned-imitation-for-robust-humanoid-door-openin.html">StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening</a></td>
  <td>StageACTï¼šåŸºäºé˜¶æ®µæ¡ä»¶æ¨¡ä»¿å­¦ä¹ çš„é²æ£’äººå½¢æœºå™¨äººå¼€é—¨æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13200v2" data-paper-url="./papers/250913200v2-stageact-stage-conditioned-imitation-for-robust-humanoid-door-openin.html" onclick="toggleFavorite(this, '2509.13200v2', 'StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250912674v1-safety-filtering-of-robotic-manipulation-under-environment-uncertain.html">Safety filtering of robotic manipulation under environment uncertainty: a computational approach</a></td>
  <td>æå‡ºåŸºäºç‰©ç†ä»¿çœŸçš„æœºå™¨äººæ“ä½œå®‰å…¨è¿‡æ»¤æ–¹æ¡ˆï¼Œåº”å¯¹ç¯å¢ƒä¸ç¡®å®šæ€§</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">bi-manual</span> <span class="paper-tag">bimanual manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12674v1" data-paper-url="./papers/250912674v1-safety-filtering-of-robotic-manipulation-under-environment-uncertain.html" onclick="toggleFavorite(this, '2509.12674v1', 'Safety filtering of robotic manipulation under environment uncertainty: a computational approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250913126v1-hydrosoft-non-holonomic-hydroelastic-models-for-compliant-tactile-ma.html">Hydrosoft: Non-Holonomic Hydroelastic Models for Compliant Tactile Manipulation</a></td>
  <td>æå‡ºHydrosoftæ¨¡å‹ï¼Œè§£å†³æŸ”é¡ºè§¦è§‰æ“ä½œä¸­éå®Œæ•´çº¦æŸä¸‹çš„æ°´å¼¹æ€§å»ºæ¨¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">trajectory optimization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13126v1" data-paper-url="./papers/250913126v1-hydrosoft-non-holonomic-hydroelastic-models-for-compliant-tactile-ma.html" onclick="toggleFavorite(this, '2509.13126v1', 'Hydrosoft: Non-Holonomic Hydroelastic Models for Compliant Tactile Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250913109v1-model-predictive-control-with-reference-learning-for-soft-robotic-in.html">Model Predictive Control with Reference Learning for Soft Robotic Intracranial Pressure Waveform Modulation</a></td>
  <td>æå‡ºåŸºäºå‚è€ƒå­¦ä¹ çš„æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼Œç”¨äºè½¯ä½“æœºå™¨äººé¢…å†…å‹æ³¢å½¢è°ƒèŠ‚</td>
  <td class="tags-cell"><span class="paper-tag">MPC</span> <span class="paper-tag">model predictive control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13109v1" data-paper-url="./papers/250913109v1-model-predictive-control-with-reference-learning-for-soft-robotic-in.html" onclick="toggleFavorite(this, '2509.13109v1', 'Model Predictive Control with Reference Learning for Soft Robotic Intracranial Pressure Waveform Modulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250913095v2-empowering-multi-robot-cooperation-via-sequential-world-models.html">Empowering Multi-Robot Cooperation via Sequential World Models</a></td>
  <td>SeqWMï¼šåŸºäºåºåˆ—ä¸–ç•Œæ¨¡å‹èµ‹èƒ½å¤šæœºå™¨äººåä½œ</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">world model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13095v2" data-paper-url="./papers/250913095v2-empowering-multi-robot-cooperation-via-sequential-world-models.html" onclick="toggleFavorite(this, '2509.13095v2', 'Empowering Multi-Robot Cooperation via Sequential World Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250912620v1-perchmobi3-a-multi-modal-robot-with-power-reuse-quad-fan-mechanism-f.html">PerchMobi^3: A Multi-Modal Robot with Power-Reuse Quad-Fan Mechanism for Air-Ground-Wall Locomotion</a></td>
  <td>PerchMobi^3ï¼šä¸€ç§ç”¨äºç©º-åœ°-å¢™è¿åŠ¨çš„åŠ¨åŠ›å¤ç”¨å››é£æ‰‡å¤šæ¨¡æ€æœºå™¨äºº</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12620v1" data-paper-url="./papers/250912620v1-perchmobi3-a-multi-modal-robot-with-power-reuse-quad-fan-mechanism-f.html" onclick="toggleFavorite(this, '2509.12620v1', 'PerchMobi^3: A Multi-Modal Robot with Power-Reuse Quad-Fan Mechanism for Air-Ground-Wall Locomotion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250913591v1-object-pose-estimation-through-dexterous-touch.html">Object Pose Estimation through Dexterous Touch</a></td>
  <td>æå‡ºåŸºäºçµå·§è§¦è§‰çš„ä¸»åŠ¨æ¢ç´¢ç‰©ä½“å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œè§£å†³è§†è§‰å—é™åœºæ™¯ä¸‹çš„å§¿æ€ä¼°è®¡é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">bi-manual</span> <span class="paper-tag">reinforcement learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13591v1" data-paper-url="./papers/250913591v1-object-pose-estimation-through-dexterous-touch.html" onclick="toggleFavorite(this, '2509.13591v1', 'Object Pose Estimation through Dexterous Touch')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250913074v2-beyond-anthropomorphism-enhancing-grasping-and-eliminating-a-degree-.html">Beyond Anthropomorphism: Enhancing Grasping and Eliminating a Degree of Freedom by Fusing the Abduction of Digits Four and Five</a></td>
  <td>SABDæ‰‹ï¼šèåˆå››æŒ‡å’Œäº”æŒ‡å¤–å±•/å†…æ”¶è‡ªç”±åº¦ï¼Œæå‡æŠ“å–èƒ½åŠ›å¹¶ç®€åŒ–æœºæ¢°ç»“æ„</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13074v2" data-paper-url="./papers/250913074v2-beyond-anthropomorphism-enhancing-grasping-and-eliminating-a-degree-.html" onclick="toggleFavorite(this, '2509.13074v2', 'Beyond Anthropomorphism: Enhancing Grasping and Eliminating a Degree of Freedom by Fusing the Abduction of Digits Four and Five')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250912813v1-bridging-perception-and-planning-towards-end-to-end-planning-for-sig.html">Bridging Perception and Planning: Towards End-to-End Planning for Signal Temporal Logic Tasks</a></td>
  <td>æå‡ºS-MSPï¼Œç”¨äºè§£å†³æœºå™¨äººä¿¡å·æ—¶åºé€»è¾‘ä»»åŠ¡çš„ç«¯åˆ°ç«¯æ„ŸçŸ¥ä¸è§„åˆ’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span> <span class="paper-tag">task and motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12813v1" data-paper-url="./papers/250912813v1-bridging-perception-and-planning-towards-end-to-end-planning-for-sig.html" onclick="toggleFavorite(this, '2509.12813v1', 'Bridging Perception and Planning: Towards End-to-End Planning for Signal Temporal Logic Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250913434v1-a-convex-formulation-of-compliant-contact-between-filaments-and-rigi.html">A Convex Formulation of Compliant Contact between Filaments and Rigid Bodies</a></td>
  <td>æå‡ºä¸€ç§åŸºäºå‡¸ä¼˜åŒ–çš„æŸ”æ€§ç»†ä¸ä¸åˆšä½“æ¥è§¦æ¨¡æ‹Ÿæ¡†æ¶ï¼Œé€‚ç”¨äºè½¯ä½“æœºå™¨äººå’Œå½¢å˜ç‰©ä½“æ“ä½œã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">PULSE</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13434v1" data-paper-url="./papers/250913434v1-a-convex-formulation-of-compliant-contact-between-filaments-and-rigi.html" onclick="toggleFavorite(this, '2509.13434v1', 'A Convex Formulation of Compliant Contact between Filaments and Rigid Bodies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250912714v1-moirÃ©tac-a-dual-mode-visuotactile-sensor-for-multidimensional-percep.html">MoirÃ©Tac: A Dual-Mode Visuotactile Sensor for Multidimensional Perception Using MoirÃ© Pattern Amplification</a></td>
  <td>MoirÃ©Tacï¼šåˆ©ç”¨è«å°”æ¡çº¹æ”¾å¤§å®ç°å¤šç»´æ„ŸçŸ¥çš„åŒæ¨¡æ€è§†è§‰è§¦è§‰ä¼ æ„Ÿå™¨</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12714v1" data-paper-url="./papers/250912714v1-moirÃ©tac-a-dual-mode-visuotactile-sensor-for-multidimensional-percep.html" onclick="toggleFavorite(this, '2509.12714v1', 'MoirÃ©Tac: A Dual-Mode Visuotactile Sensor for Multidimensional Perception Using MoirÃ© Pattern Amplification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250913595v1-leg-arm-coordinated-operation-for-curtain-wall-installation.html">Leg-Arm Coordinated Operation for Curtain Wall Installation</a></td>
  <td>é’ˆå¯¹å¹•å¢™å®‰è£…ï¼Œæå‡ºä¸€ç§åŸºäºå…­è¶³æœºå™¨äººè…¿-è‡‚ååŒçš„åˆ†å±‚ä¼˜åŒ–æ§åˆ¶æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">whole-body control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13595v1" data-paper-url="./papers/250913595v1-leg-arm-coordinated-operation-for-curtain-wall-installation.html" onclick="toggleFavorite(this, '2509.13595v1', 'Leg-Arm Coordinated Operation for Curtain Wall Installation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250912969v2-underactuated-robotic-hand-with-grasp-state-estimation-using-tendon-.html">Underactuated Robotic Hand with Grasp State Estimation Using Tendon-Based Proprioception</a></td>
  <td>æå‡ºåŸºäºè‚Œè…±æœ¬ä½“æ„Ÿå—çš„æ¬ é©±åŠ¨æœºæ¢°æ‰‹æŠ“å–çŠ¶æ€ä¼°è®¡æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12969v2" data-paper-url="./papers/250912969v2-underactuated-robotic-hand-with-grasp-state-estimation-using-tendon-.html" onclick="toggleFavorite(this, '2509.12969v2', 'Underactuated Robotic Hand with Grasp State Estimation Using Tendon-Based Proprioception')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>19</td>
  <td><a href="./papers/250913579v4-treeirl-safe-urban-driving-with-tree-search-and-inverse-reinforcemen.html">TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning</a></td>
  <td>TreeIRLï¼šç»“åˆè’™ç‰¹å¡æ´›æ ‘æœç´¢ä¸é€†å¼ºåŒ–å­¦ä¹ çš„å®‰å…¨åŸå¸‚è‡ªåŠ¨é©¾é©¶è§„åˆ’å™¨</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">imitation learning</span> <span class="paper-tag">inverse reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13579v4" data-paper-url="./papers/250913579v4-treeirl-safe-urban-driving-with-tree-search-and-inverse-reinforcemen.html" onclick="toggleFavorite(this, '2509.13579v4', 'TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250912863v1-grate-a-graph-transformer-based-deep-reinforcement-learning-approach.html">GRATE: a Graph transformer-based deep Reinforcement learning Approach for Time-efficient autonomous robot Exploration</a></td>
  <td>æå‡ºåŸºäºå›¾Transformerçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•GRATEï¼Œæå‡æœºå™¨äººè‡ªä¸»æ¢ç´¢çš„æ—¶é—´æ•ˆç‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">DRL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12863v1" data-paper-url="./papers/250912863v1-grate-a-graph-transformer-based-deep-reinforcement-learning-approach.html" onclick="toggleFavorite(this, '2509.12863v1', 'GRATE: a Graph transformer-based deep Reinforcement learning Approach for Time-efficient autonomous robot Exploration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250912618v1-activevln-towards-active-exploration-via-multi-turn-rl-in-vision-and.html">ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation</a></td>
  <td>ActiveVLNï¼šåŸºäºå¤šè½®å¼ºåŒ–å­¦ä¹ çš„ä¸»åŠ¨æ¢ç´¢è§†è§‰è¯­è¨€å¯¼èˆª</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">imitation learning</span> <span class="paper-tag">reward shaping</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12618v1" data-paper-url="./papers/250912618v1-activevln-towards-active-exploration-via-multi-turn-rl-in-vision-and.html" onclick="toggleFavorite(this, '2509.12618v1', 'ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250913132v1-an-uncertainty-weighted-decision-transformer-for-navigation-in-dense.html">An Uncertainty-Weighted Decision Transformer for Navigation in Dense, Complex Driving Scenarios</a></td>
  <td>æå‡ºä¸ç¡®å®šæ€§åŠ æƒå†³ç­–Transformerï¼Œæå‡å¤æ‚äº¤é€šåœºæ™¯è‡ªåŠ¨é©¾é©¶å†³ç­–å®‰å…¨æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">decision transformer</span> <span class="paper-tag">occupancy grid</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13132v1" data-paper-url="./papers/250913132v1-an-uncertainty-weighted-decision-transformer-for-navigation-in-dense.html" onclick="toggleFavorite(this, '2509.13132v1', 'An Uncertainty-Weighted Decision Transformer for Navigation in Dense, Complex Driving Scenarios')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/250912531v1-pre-trained-visual-representations-generalize-where-it-matters-in-mo.html">Pre-trained Visual Representations Generalize Where it Matters in Model-Based Reinforcement Learning</a></td>
  <td>é¢„è®­ç»ƒè§†è§‰è¡¨å¾æ˜¾è‘—æå‡æ¨¡å‹å¼ºåŒ–å­¦ä¹ åœ¨è§†è§‰åŸŸåç§»ä¸‹çš„æ³›åŒ–èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">policy learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12531v1" data-paper-url="./papers/250912531v1-pre-trained-visual-representations-generalize-where-it-matters-in-mo.html" onclick="toggleFavorite(this, '2509.12531v1', 'Pre-trained Visual Representations Generalize Where it Matters in Model-Based Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250913574v1-dense-jump-flow-matching-with-non-uniform-time-scheduling-for-roboti.html">Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation</a></td>
  <td>æå‡ºDense-Jump Flow Matchingæ–¹æ³•ï¼Œé€šè¿‡éå‡åŒ€æ—¶é—´è°ƒåº¦ä¼˜åŒ–æœºå™¨äººç­–ç•¥ï¼Œç¼“è§£å¤šæ­¥æ¨ç†é€€åŒ–é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">flow matching</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13574v1" data-paper-url="./papers/250913574v1-dense-jump-flow-matching-with-non-uniform-time-scheduling-for-roboti.html" onclick="toggleFavorite(this, '2509.13574v1', 'Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/250913386v1-vega-electric-vehicle-navigation-agent-via-physics-informed-neural-o.html">VEGA: Electric Vehicle Navigation Agent via Physics-Informed Neural Operator and Proximal Policy Optimization</a></td>
  <td>VEGAï¼šåŸºäºç‰©ç†ä¿¡æ¯ç¥ç»ç®—å­å’ŒPPOçš„ç”µåŠ¨æ±½è½¦å¯¼èˆªä»£ç†</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">PPO</span> <span class="paper-tag">teacher-student</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13386v1" data-paper-url="./papers/250913386v1-vega-electric-vehicle-navigation-agent-via-physics-informed-neural-o.html" onclick="toggleFavorite(this, '2509.13386v1', 'VEGA: Electric Vehicle Navigation Agent via Physics-Informed Neural Operator and Proximal Policy Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/250913380v2-astrea-introducing-agentic-intelligence-for-orbital-thermal-autonomy.html">ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy</a></td>
  <td>ASTREAï¼šé¢å‘è½¨é“çƒ­è‡ªä¸»æ€§çš„Agenticæ™ºèƒ½ç³»ç»Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13380v2" data-paper-url="./papers/250913380v2-astrea-introducing-agentic-intelligence-for-orbital-thermal-autonomy.html" onclick="toggleFavorite(this, '2509.13380v2', 'ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/250912562v1-robust-online-residual-refinement-via-koopman-guided-dynamics-modeli.html">Robust Online Residual Refinement via Koopman-Guided Dynamics Modeling</a></td>
  <td>æå‡ºKORRï¼šåˆ©ç”¨Koopmanå¼•å¯¼çš„åŠ¨æ€æ¨¡å‹å®ç°é²æ£’çš„åœ¨çº¿æ®‹å·®ç­–ç•¥ä¼˜åŒ–</td>
  <td class="tags-cell"><span class="paper-tag">policy learning</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12562v1" data-paper-url="./papers/250912562v1-robust-online-residual-refinement-via-koopman-guided-dynamics-modeli.html" onclick="toggleFavorite(this, '2509.12562v1', 'Robust Online Residual Refinement via Koopman-Guided Dynamics Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>28</td>
  <td><a href="./papers/250913177v1-room-a-physics-based-continuum-robot-simulator-for-photorealistic-me.html">ROOM: A Physics-Based Continuum Robot Simulator for Photorealistic Medical Datasets Generation</a></td>
  <td>ROOMï¼šç”¨äºç”Ÿæˆé€¼çœŸåŒ»å­¦æ•°æ®é›†çš„åŸºäºç‰©ç†çš„è¿ç»­ä½“æœºå™¨äººæ¨¡æ‹Ÿå™¨</td>
  <td class="tags-cell"><span class="paper-tag">depth estimation</span> <span class="paper-tag">monocular depth</span> <span class="paper-tag">metric depth</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13177v1" data-paper-url="./papers/250913177v1-room-a-physics-based-continuum-robot-simulator-for-photorealistic-me.html" onclick="toggleFavorite(this, '2509.13177v1', 'ROOM: A Physics-Based Continuum Robot Simulator for Photorealistic Medical Datasets Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/250912747v2-navmoe-hybrid-model-and-learning-based-traversability-estimation-for.html">NavMoE: Hybrid Model- and Learning-based Traversability Estimation for Local Navigation via Mixture of Experts</a></td>
  <td>æå‡ºNavMoEï¼Œé€šè¿‡æ··åˆä¸“å®¶æ¨¡å‹å®ç°æœºå™¨äººå±€éƒ¨å¯¼èˆªä¸­æ›´é«˜æ•ˆã€æ³›åŒ–çš„åœ°å½¢å¯é€šè¡Œæ€§ä¼°è®¡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">traversability</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12747v2" data-paper-url="./papers/250912747v2-navmoe-hybrid-model-and-learning-based-traversability-estimation-for.html" onclick="toggleFavorite(this, '2509.12747v2', 'NavMoE: Hybrid Model- and Learning-based Traversability Estimation for Local Navigation via Mixture of Experts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>30</td>
  <td><a href="./papers/250913069v1-practical-handling-of-dynamic-environments-in-decentralised-multi-ro.html">Practical Handling of Dynamic Environments in Decentralised Multi-Robot Patrol</a></td>
  <td>æå‡ºä¸€ç§å»ä¸­å¿ƒåŒ–å¤šæœºå™¨äººå·¡é€»æ–¹æ³•ï¼Œç”¨äºåŠ¨æ€ç¯å¢ƒä¸‹çš„æŒç»­ç›‘æ§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">traversability</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13069v1" data-paper-url="./papers/250913069v1-practical-handling-of-dynamic-environments-in-decentralised-multi-ro.html" onclick="toggleFavorite(this, '2509.13069v1', 'Practical Handling of Dynamic Environments in Decentralised Multi-Robot Patrol')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>31</td>
  <td><a href="./papers/250912702v1-udon-uncertainty-weighted-distributed-optimization-for-multi-robot-n.html">UDON: Uncertainty-weighted Distributed Optimization for Multi-Robot Neural Implicit Mapping under Extreme Communication Constraints</a></td>
  <td>UDONï¼šé¢å‘æç«¯é€šä¿¡çº¦æŸçš„å¤šæœºå™¨äººç¥ç»éšå¼åœ°å›¾ä¸ç¡®å®šæ€§åŠ æƒåˆ†å¸ƒå¼ä¼˜åŒ–</td>
  <td class="tags-cell"><span class="paper-tag">implicit representation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12702v1" data-paper-url="./papers/250912702v1-udon-uncertainty-weighted-distributed-optimization-for-multi-robot-n.html" onclick="toggleFavorite(this, '2509.12702v1', 'UDON: Uncertainty-weighted Distributed Optimization for Multi-Robot Neural Implicit Mapping under Extreme Communication Constraints')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>32</td>
  <td><a href="./papers/250912594v2-the-better-you-learn-the-smarter-you-prune-towards-efficient-vision-.html">The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning</a></td>
  <td>LightVLAï¼šé€šè¿‡å¯å¾®Tokenå‰ªææå‡è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„æ•ˆç‡ä¸æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12594v2" data-paper-url="./papers/250912594v2-the-better-you-learn-the-smarter-you-prune-towards-efficient-vision-.html" onclick="toggleFavorite(this, '2509.12594v2', 'The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>33</td>
  <td><a href="./papers/250912838v2-multi-robot-task-planning-for-multi-object-retrieval-tasks-with-dist.html">Multi-Robot Task Planning for Multi-Object Retrieval Tasks with Distributed On-Site Knowledge via Large Language Models</a></td>
  <td>æå‡ºåŸºäºLLMçš„å¤šæœºå™¨äººä»»åŠ¡è§„åˆ’æ¡†æ¶ï¼Œè§£å†³åˆ†å¸ƒå¼çŸ¥è¯†ä¸‹å¤šç›®æ ‡æ£€ç´¢ä»»åŠ¡</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12838v2" data-paper-url="./papers/250912838v2-multi-robot-task-planning-for-multi-object-retrieval-tasks-with-dist.html" onclick="toggleFavorite(this, '2509.12838v2', 'Multi-Robot Task Planning for Multi-Object Retrieval Tasks with Distributed On-Site Knowledge via Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>34</td>
  <td><a href="./papers/250912754v1-toward-ownership-understanding-of-objects-active-question-generation.html">Toward Ownership Understanding of Objects: Active Question Generation with Large Language Model and Probabilistic Generative Model</a></td>
  <td>ActOwLï¼šç»“åˆLLMä¸æ¦‚ç‡ç”Ÿæˆæ¨¡å‹çš„ä¸»åŠ¨é—®ç­”ï¼Œæå‡æœºå™¨äººå¯¹è±¡æ‰€æœ‰æƒç†è§£</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12754v1" data-paper-url="./papers/250912754v1-toward-ownership-understanding-of-objects-active-question-generation.html" onclick="toggleFavorite(this, '2509.12754v1', 'Toward Ownership Understanding of Objects: Active Question Generation with Large Language Model and Probabilistic Generative Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>35</td>
  <td><a href="./papers/250912928v2-spatiotemporal-calibration-for-laser-vision-sensor-in-hand-eye-syste.html">Spatiotemporal Calibration for Laser Vision Sensor in Hand-eye System Based on Straight-line Constraint</a></td>
  <td>æå‡ºåŸºäºç›´çº¿çº¦æŸçš„æ—¶ç©ºæ ‡å®šæ–¹æ³•ï¼Œè§£å†³æ¿€å…‰è§†è§‰æ‰‹çœ¼ç³»ç»Ÿä¸­æ—¶å»¶å’Œå¤–å‚æ¼‚ç§»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">spatiotemporal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12928v2" data-paper-url="./papers/250912928v2-spatiotemporal-calibration-for-laser-vision-sensor-in-hand-eye-syste.html" onclick="toggleFavorite(this, '2509.12928v2', 'Spatiotemporal Calibration for Laser Vision Sensor in Hand-eye System Based on Straight-line Constraint')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)