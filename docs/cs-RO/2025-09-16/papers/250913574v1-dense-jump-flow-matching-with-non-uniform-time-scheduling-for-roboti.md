---
layout: default
title: Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation
---

# Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.13574" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.13574v1</a>
  <a href="https://arxiv.org/pdf/2509.13574.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.13574v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.13574v1', 'Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zidong Chen, Zihao Guo, Peng Wang, ThankGod Itua Egbe, Yan Lyu, Chenghao Qian

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDense-Jump Flow Matchingæ–¹æ³•ï¼Œé€šè¿‡éå‡åŒ€æ—¶é—´è°ƒåº¦ä¼˜åŒ–æœºå™¨äººç­–ç•¥ï¼Œç¼“è§£å¤šæ­¥æ¨ç†é€€åŒ–é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æœºå™¨äººç­–ç•¥å­¦ä¹ ` `Flow Matching` `éå‡åŒ€æ—¶é—´è°ƒåº¦` `å¤šæ­¥æ¨ç†` `æ³›åŒ–èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰Flow Matchingæ–¹æ³•åœ¨æœºå™¨äººç­–ç•¥å­¦ä¹ ä¸­å­˜åœ¨æ³›åŒ–èƒ½åŠ›é¥±å’Œå’Œå¤šæ­¥æ¨ç†æ€§èƒ½é€€åŒ–çš„é—®é¢˜ã€‚
2. è®ºæ–‡æå‡ºDense-Jump Flow Matchingï¼Œé€šè¿‡éå‡åŒ€æ—¶é—´è°ƒåº¦è®­ç»ƒå’Œå¯†é›†è·³è·ƒç§¯åˆ†æ¨ç†æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæœºå™¨äººä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œæœ€é«˜å¯è¾¾23.7%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Flow Matchingå·²æˆä¸ºå­¦ä¹ é«˜è´¨é‡æœºå™¨äººç”Ÿæˆç­–ç•¥çš„æœ‰æ•ˆæ¡†æ¶ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°æ³›åŒ–èƒ½åŠ›æ²¿è½¨è¿¹å¿«é€Ÿé¥±å’Œã€‚æ­¤å¤–ï¼Œå¢åŠ æ¨ç†æœŸé—´çš„æ¬§æ‹‰ç§¯åˆ†æ­¥æ•°åè€Œä¼šé™ä½ç­–ç•¥æ€§èƒ½ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™æ˜¯ç”±äº(i)å‡åŒ€é—´éš”çš„ç§¯åˆ†æ­¥é•¿è¿‡åº¦é‡‡æ ·äº†åæœŸåŒºåŸŸï¼Œä»è€Œé™åˆ¶äº†åŠ¨ä½œå¹¶é™ä½äº†æ³›åŒ–èƒ½åŠ›ï¼›(ii)å­¦ä¹ åˆ°çš„é€Ÿåº¦åœºåœ¨ç§¯åˆ†æ—¶é—´æ¥è¿‘1æ—¶å˜ä¸ºéLipschitzè¿ç»­ï¼Œå¯¼è‡´ä¸ç¨³å®šã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨è®­ç»ƒæœŸé—´åˆ©ç”¨éå‡åŒ€æ—¶é—´è°ƒåº¦ï¼ˆä¾‹å¦‚ï¼ŒUå½¢ï¼‰ï¼Œå¼ºè°ƒæ—©æœŸå’Œæ™šæœŸé˜¶æ®µä»¥æ­£åˆ™åŒ–ç­–ç•¥è®­ç»ƒï¼Œå¹¶åœ¨æ¨ç†æ—¶é‡‡ç”¨å¯†é›†è·³è·ƒç§¯åˆ†è°ƒåº¦ï¼Œä½¿ç”¨å•æ­¥ç§¯åˆ†ä»£æ›¿è·³è·ƒç‚¹ä¹‹åçš„å¤šæ­¥ç§¯åˆ†ï¼Œä»¥é¿å…1é™„è¿‘çš„ä¸ç¨³å®šåŒºåŸŸã€‚æœ¬è´¨ä¸Šï¼Œæˆ‘ä»¬çš„ç­–ç•¥æ˜¯ä¸€ç§é«˜æ•ˆçš„å•æ­¥å­¦ä¹ å™¨ï¼Œä»ç„¶å¯ä»¥é€šè¿‡å¤šæ­¥ç§¯åˆ†æ¥æé«˜æ€§èƒ½ï¼Œåœ¨å„ç§æœºå™¨äººä»»åŠ¡ä¸­ï¼Œæ€§èƒ½æ¯”æœ€å…ˆè¿›çš„åŸºçº¿æé«˜äº†é«˜è¾¾23.7%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººç­–ç•¥å­¦ä¹ ä¸­ï¼ŒåŸºäºFlow Matchingçš„æ–¹æ³•åœ¨å¤šæ­¥æ¨ç†æ—¶æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é‡‡ç”¨å‡åŒ€æ—¶é—´é—´éš”è¿›è¡Œç§¯åˆ†ï¼Œå¯¼è‡´åæœŸè½¨è¿¹è¿‡åº¦é‡‡æ ·ï¼Œé™åˆ¶äº†æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”é€Ÿåº¦åœºåœ¨æ¥è¿‘ç§¯åˆ†ç»ˆç‚¹æ—¶å˜å¾—ä¸ç¨³å®šï¼Œå½±å“æ¨ç†æ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡éå‡åŒ€æ—¶é—´è°ƒåº¦æ¥ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶é‡‡ç”¨å¯†é›†è·³è·ƒç§¯åˆ†ç­–ç•¥æ¥ä¼˜åŒ–æ¨ç†è¿‡ç¨‹ã€‚éå‡åŒ€æ—¶é—´è°ƒåº¦å¼ºè°ƒè½¨è¿¹çš„æ—©æœŸå’Œæ™šæœŸé˜¶æ®µï¼Œä»¥æé«˜æ³›åŒ–èƒ½åŠ›å’Œç¨³å®šæ€§ã€‚å¯†é›†è·³è·ƒç§¯åˆ†åˆ™é¿å…åœ¨é€Ÿåº¦åœºä¸ç¨³å®šåŒºåŸŸè¿›è¡Œå¤šæ­¥ç§¯åˆ†ï¼Œä»è€Œæé«˜æ¨ç†æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼šéå‡åŒ€æ—¶é—´è°ƒåº¦è®­ç»ƒå’Œå¯†é›†è·³è·ƒç§¯åˆ†æ¨ç†ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨Uå½¢æ—¶é—´è°ƒåº¦ç­–ç•¥ï¼Œå¢åŠ å¯¹è½¨è¿¹èµ·å§‹å’Œç»“æŸé˜¶æ®µçš„é‡‡æ ·é¢‘ç‡ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œé¦–å…ˆè¿›è¡Œå¤šæ­¥ç§¯åˆ†ï¼Œç›´åˆ°è¾¾åˆ°ä¸€ä¸ªé¢„å®šä¹‰çš„è·³è·ƒç‚¹ï¼Œç„¶åä½¿ç”¨å•æ­¥ç§¯åˆ†å®Œæˆå‰©ä½™çš„è½¨è¿¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†å¯†é›†è·³è·ƒç§¯åˆ†ç­–ç•¥ï¼Œé€šè¿‡å•æ­¥ç§¯åˆ†é¿å…äº†é€Ÿåº¦åœºä¸ç¨³å®šåŒºåŸŸçš„å¤šæ­¥ç§¯åˆ†ï¼Œä»è€Œæé«˜äº†æ¨ç†çš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚æ­¤å¤–ï¼Œéå‡åŒ€æ—¶é—´è°ƒåº¦ç­–ç•¥ä¹Ÿæœ‰åŠ©äºæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šéå‡åŒ€æ—¶é—´è°ƒåº¦é‡‡ç”¨Uå½¢åˆ†å¸ƒï¼Œå…·ä½“å‚æ•°éœ€è¦æ ¹æ®ä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚è·³è·ƒç‚¹çš„ä½ç½®æ˜¯å½±å“æ€§èƒ½çš„å…³é”®å‚æ•°ï¼Œéœ€è¦åœ¨å®éªŒä¸­è¿›è¡Œä¼˜åŒ–ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨æ ‡å‡†çš„Flow MatchingæŸå¤±å‡½æ•°ï¼Œä½†å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ é¢å¤–çš„æ­£åˆ™åŒ–é¡¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDense-Jump Flow Matchingæ–¹æ³•åœ¨å¤šä¸ªæœºå™¨äººä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸé¡¹ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•æ¯”æœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•æé«˜äº†23.7%çš„æ€§èƒ½ã€‚å®éªŒè¿˜éªŒè¯äº†éå‡åŒ€æ—¶é—´è°ƒåº¦å’Œå¯†é›†è·³è·ƒç§¯åˆ†ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§æœºå™¨äººæ§åˆ¶ä»»åŠ¡ï¼Œä¾‹å¦‚æœºæ¢°è‡‚è¿åŠ¨è§„åˆ’ã€æ— äººæœºå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚é€šè¿‡æé«˜æœºå™¨äººç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›å’Œæ¨ç†æ•ˆç‡ï¼Œå¯ä»¥ä½¿æœºå™¨äººåœ¨æ›´å¤æ‚çš„ç¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡ï¼Œå¹¶é™ä½å¯¹è®­ç»ƒæ•°æ®çš„éœ€æ±‚ã€‚è¯¥æ–¹æ³•è¿˜å¯ç”¨äºç”Ÿæˆæ›´é€¼çœŸçš„æœºå™¨äººè¿åŠ¨è½¨è¿¹ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Flow matching has emerged as a competitive framework for learning high-quality generative policies in robotics; however, we find that generalisation arises and saturates early along the flow trajectory, in accordance with recent findings in the literature. We further observe that increasing the number of Euler integration steps during inference counter-intuitively and universally degrades policy performance. We attribute this to (i) additional, uniformly spaced integration steps oversample the late-time region, thereby constraining actions towards the training trajectories and reducing generalisation; and (ii) the learned velocity field becoming non-Lipschitz as integration time approaches 1, causing instability. To address these issues, we propose a novel policy that utilises non-uniform time scheduling (e.g., U-shaped) during training, which emphasises both early and late temporal stages to regularise policy training, and a dense-jump integration schedule at inference, which uses a single-step integration to replace the multi-step integration beyond a jump point, to avoid unstable areas around 1. Essentially, our policy is an efficient one-step learner that still pushes forward performance through multi-step integration, yielding up to 23.7% performance gains over state-of-the-art baselines across diverse robotic tasks.

