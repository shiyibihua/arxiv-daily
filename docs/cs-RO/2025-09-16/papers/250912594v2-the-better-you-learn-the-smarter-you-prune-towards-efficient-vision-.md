---
layout: default
title: The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning
---

# The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.12594" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.12594v2</a>
  <a href="https://arxiv.org/pdf/2509.12594.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.12594v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.12594v2', 'The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Titong Jiang, Xuefeng Jiang, Yuan Ma, Xin Wen, Bailin Li, Kun Zhan, Peng Jia, Yahui Liu, Sheng Sun, Xianpeng Lang

**ÂàÜÁ±ª**: cs.RO, cs.CL, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-16 (Êõ¥Êñ∞: 2025-09-21)

**Â§áÊ≥®**: Under review. Project site: https://liauto-research.github.io/LightVLA

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**LightVLAÔºöÈÄöËøáÂèØÂæÆTokenÂâ™ÊûùÊèêÂçáËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÁöÑÊïàÁéá‰∏éÊÄßËÉΩ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã` `TokenÂâ™Êûù` `ÂèØÂæÆÂ≠¶‰π†` `Êú∫Âô®‰∫∫ÊéßÂà∂` `Ê®°ÂûãÂéãÁº©`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLAÊ®°ÂûãËÆ°ÁÆóÈáèÂ§ßÔºåÈöæ‰ª•ÈÉ®ÁΩ≤Âú®ËµÑÊ∫êÂèóÈôêÁöÑÊú∫Âô®‰∫∫Âπ≥Âè∞‰∏äÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜÂ§ßÈáèËßÜËßâTokenÊó∂„ÄÇ
2. LightVLAÈÄöËøáÂä®ÊÄÅÊü•ËØ¢ËØÑ‰º∞TokenÈáçË¶ÅÊÄßÔºåÂπ∂‰ΩøÁî®Gumbel softmaxÂÆûÁé∞ÂèØÂæÆÂâ™ÊûùÔºåËá™ÈÄÇÂ∫îÂú∞‰øùÁïôÈáçË¶ÅToken„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåLightVLAÂú®Èôç‰ΩéFLOPsÂíåÂª∂ËøüÁöÑÂêåÊó∂ÔºåÊèêÈ´ò‰∫Ü‰ªªÂä°ÊàêÂäüÁéáÔºåÊó†ÈúÄÈ¢ùÂ§ñÂèÇÊï∞‰∏îÂÖºÂÆπÁé∞ÊúâÊ°ÜÊû∂„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆÄÂçïËÄåÊúâÊïàÁöÑÂèØÂæÆTokenÂâ™ÊûùÊ°ÜÊû∂LightVLAÔºåÁî®‰∫éÊèêÂçáËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãÁöÑÊïàÁéá„ÄÇVLAÊ®°ÂûãÂú®ÊâßË°åÁé∞ÂÆû‰∏ñÁïåÊú∫Âô®‰∫∫‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºå‰ΩÜÂÖ∂ÈÉ®ÁΩ≤Âú®ËµÑÊ∫êÂèóÈôêÁöÑÂπ≥Âè∞‰∏äÈÄöÂ∏∏ÂèóÂà∞Âü∫‰∫éÂ§ßÈáèËßÜËßâTokenÁöÑÁπÅÈáçÊ≥®ÊÑèÂäõËÆ°ÁÆóÁöÑÈôêÂà∂„ÄÇLightVLAÈÄöËøáËá™ÈÄÇÂ∫îÁöÑ„ÄÅÊÄßËÉΩÈ©±Âä®ÁöÑËßÜËßâTokenÂâ™ÊûùÊù•Ëß£ÂÜ≥Ëøô‰∏ÄÊåëÊàòÔºöÂÆÉÁîüÊàêÂä®ÊÄÅÊü•ËØ¢Êù•ËØÑ‰º∞ËßÜËßâTokenÁöÑÈáçË¶ÅÊÄßÔºåÂπ∂ÈááÁî®Gumbel softmaxÊù•ÂÆûÁé∞ÂèØÂæÆÁöÑTokenÈÄâÊã©„ÄÇÈÄöËøáÂæÆË∞ÉÔºåLightVLAÂ≠¶‰ºö‰øùÁïô‰ø°ÊÅØÈáèÊúÄÂ§ßÁöÑËßÜËßâTokenÔºåÂêåÊó∂Ââ™ÊûùÂØπ‰ªªÂä°ÊâßË°åÊ≤°ÊúâË¥°ÁåÆÁöÑTokenÔºå‰ªéËÄåÂêåÊó∂ÊèêÈ´òÊïàÁéáÂíåÊÄßËÉΩ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåLightVLA‰∏çÈúÄË¶ÅÂêØÂèëÂºèÈ≠îÊ≥ïÊï∞Â≠óÔºå‰πü‰∏çÂºïÂÖ•È¢ùÂ§ñÁöÑÂèØËÆ≠ÁªÉÂèÇÊï∞Ôºå‰ΩøÂÖ∂‰∏éÁé∞‰ª£Êé®ÁêÜÊ°ÜÊû∂ÂÖºÂÆπ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåLightVLAÂú®LIBEROÂü∫ÂáÜÊµãËØïÁöÑÂêÑÁßç‰ªªÂä°‰∏≠‰ºò‰∫é‰∏çÂêåÁöÑVLAÊ®°ÂûãÂíåÁé∞ÊúâÁöÑTokenÂâ™ÊûùÊñπÊ≥ïÔºå‰ª•ÊòæËëóÈôç‰ΩéÁöÑËÆ°ÁÆóÂºÄÈîÄÂÆûÁé∞‰∫ÜÊõ¥È´òÁöÑÊàêÂäüÁéá„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåLightVLAÂ∞ÜFLOPsÂíåÂª∂ËøüÂàÜÂà´Èôç‰Ωé‰∫Ü59.1%Âíå38.2%ÔºåÂêåÊó∂‰ªªÂä°ÊàêÂäüÁéáÊèêÈ´ò‰∫Ü2.6%„ÄÇÂêåÊó∂ÔºåÊàë‰ª¨ËøòÁ†îÁ©∂‰∫ÜÂü∫‰∫éÂèØÂ≠¶‰π†Êü•ËØ¢ÁöÑTokenÂâ™ÊûùÊñπÊ≥ïLightVLA*ÔºåËØ•ÊñπÊ≥ïÂÖ∑ÊúâÈ¢ùÂ§ñÁöÑÂèØËÆ≠ÁªÉÂèÇÊï∞Ôºå‰πüÂèñÂæó‰∫Ü‰ª§‰∫∫Êª°ÊÑèÁöÑÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰ΩúË°®ÊòéÔºåÈöèÁùÄVLAËøΩÊ±ÇÊúÄ‰Ω≥ÊÄßËÉΩÔºåLightVLAËá™ÂèëÂú∞Â≠¶‰ºö‰ªéÊÄßËÉΩÈ©±Âä®ÁöÑËßíÂ∫¶Ââ™ÊûùToken„ÄÇÊçÆÊàë‰ª¨ÊâÄÁü•ÔºåLightVLAÊòØÁ¨¨‰∏Ä‰∏™Â∞ÜËá™ÈÄÇÂ∫îËßÜËßâTokenÂâ™ÊûùÂ∫îÁî®‰∫éVLA‰ªªÂä°ÔºåÂπ∂ÂêåÊó∂ÂÆûÁé∞ÊïàÁéáÂíåÊÄßËÉΩÁõÆÊ†áÁöÑÔºåËøôÊ†áÂøóÁùÄÊúùÁùÄÊõ¥È´òÊïà„ÄÅÊõ¥Âº∫Â§ßÂíåÊõ¥ÂÆûÁî®ÁöÑÂÆûÊó∂Êú∫Âô®‰∫∫Á≥ªÁªüËøàÂá∫‰∫ÜÈáçË¶Å‰∏ÄÊ≠•„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãÂú®ËµÑÊ∫êÂèóÈôêÂπ≥Âè∞‰∏äÈÉ®ÁΩ≤Âõ∞ÈöæÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâVLAÊ®°ÂûãÈÄöÂ∏∏‰æùËµñ‰∫éÂØπÂ§ßÈáèËßÜËßâTokenËøõË°åÊ≥®ÊÑèÂäõËÆ°ÁÆóÔºåÂØºËá¥ËÆ°ÁÆóÈáèÂ∑®Â§ßÔºåÈöæ‰ª•Êª°Ë∂≥ÂÆûÊó∂ÊÄßË¶ÅÊ±Ç„ÄÇÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèÊúâÊïàÁöÑTokenÈÄâÊã©Êú∫Âà∂ÔºåÊó†Ê≥ïÂú®‰øùËØÅÊÄßËÉΩÁöÑÂêåÊó∂Èôç‰ΩéËÆ°ÁÆóÂºÄÈîÄ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØËá™ÈÄÇÂ∫îÂú∞Ââ™ÊûùÂØπ‰ªªÂä°ÊâßË°åË¥°ÁåÆËæÉÂ∞èÁöÑËßÜËßâTokenÔºå‰ªéËÄåÈôç‰ΩéËÆ°ÁÆóÈáèÂπ∂ÊèêÈ´òÊïàÁéá„ÄÇÈÄöËøáÂ≠¶‰π†Âä®ÊÄÅÊü•ËØ¢Êù•ËØÑ‰º∞TokenÁöÑÈáçË¶ÅÊÄßÔºåÂπ∂ÈááÁî®ÂèØÂæÆÁöÑTokenÈÄâÊã©Êú∫Âà∂Ôºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üËá™Âä®Â≠¶‰π†Âì™‰∫õTokenÂ∫îËØ•Ë¢´‰øùÁïôÔºåÂì™‰∫õÂ∫îËØ•Ë¢´Ââ™Êûù„ÄÇËøôÁßçÊÄßËÉΩÈ©±Âä®ÁöÑÂâ™ÊûùÊñπÊ≥ïÊó®Âú®Âú®‰∏çÊçüÂ§±ÁîöËá≥ÊèêÂçá‰ªªÂä°ÊÄßËÉΩÁöÑÂâçÊèê‰∏ãÔºåÊòæËëóÈôç‰ΩéËÆ°ÁÆóÂºÄÈîÄ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöLightVLAÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) ËæìÂÖ•ËßÜËßâÂíåËØ≠Ë®Ä‰ø°ÊÅØÔºõ2) ‰ΩøÁî®Âä®ÊÄÅÊü•ËØ¢ËØÑ‰º∞ËßÜËßâTokenÁöÑÈáçË¶ÅÊÄßÔºõ3) ‰ΩøÁî®Gumbel softmaxËøõË°åÂèØÂæÆÁöÑTokenÈÄâÊã©ÔºåÁ°ÆÂÆöÈúÄË¶Å‰øùÁïôÁöÑTokenÂ≠êÈõÜÔºõ4) Âü∫‰∫éÈÄâÊã©ÂêéÁöÑTokenÂ≠êÈõÜËøõË°åÂêéÁª≠ÁöÑVLA‰ªªÂä°Â§ÑÁêÜ„ÄÇÊï¥‰∏™ËøáÁ®ãÊòØÁ´ØÂà∞Á´ØÂèØËÆ≠ÁªÉÁöÑÔºåÂÖÅËÆ∏Ê®°ÂûãÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠Â≠¶‰π†ÊúÄ‰Ω≥ÁöÑTokenÈÄâÊã©Á≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöLightVLAÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Ëá™ÈÄÇÂ∫îÁöÑ„ÄÅÊÄßËÉΩÈ©±Âä®ÁöÑTokenÂâ™ÊûùÊñπÊ≥ï„ÄÇ‰∏é‰º†ÁªüÁöÑTokenÂâ™ÊûùÊñπÊ≥ï‰∏çÂêåÔºåLightVLA‰∏ç‰æùËµñ‰∫éÂêØÂèëÂºèËßÑÂàôÊàñÂõ∫ÂÆöÁöÑÈòàÂÄºÔºåËÄåÊòØÈÄöËøáÂ≠¶‰π†Âä®ÊÄÅÊü•ËØ¢Êù•ËØÑ‰º∞TokenÁöÑÈáçË¶ÅÊÄßÔºåÂπ∂‰ΩøÁî®ÂèØÂæÆÁöÑTokenÈÄâÊã©Êú∫Âà∂Êù•ÂÆûÁé∞Ëá™ÈÄÇÂ∫îÁöÑÂâ™Êûù„ÄÇÊ≠§Â§ñÔºåLightVLA‰∏çÈúÄË¶ÅÈ¢ùÂ§ñÁöÑÂèØËÆ≠ÁªÉÂèÇÊï∞Ôºå‰ΩøÂÖ∂Êòì‰∫éÈõÜÊàêÂà∞Áé∞ÊúâÁöÑVLAÊ®°Âûã‰∏≠„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöLightVLAÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Âä®ÊÄÅÊü•ËØ¢ÁîüÊàêÊ®°ÂùóÔºåÁî®‰∫éÊ†πÊçÆËæìÂÖ•‰ø°ÊÅØÁîüÊàê‰∏éTokenÁõ∏ÂÖ≥ÁöÑÊü•ËØ¢ÂêëÈáèÔºõ2) Âü∫‰∫éGumbel softmaxÁöÑÂèØÂæÆTokenÈÄâÊã©Ê®°ÂùóÔºåÁî®‰∫éÂÆûÁé∞TokenÁöÑÊ¶ÇÁéáÈÄâÊã©ÔºåÂπ∂ÂÖÅËÆ∏Ê¢ØÂ∫¶ÂèçÂêë‰º†Êí≠Ôºõ3) ÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÔºåÊó®Âú®Âπ≥Ë°°‰ªªÂä°ÊÄßËÉΩÂíåËÆ°ÁÆóÂºÄÈîÄÔºåÈºìÂä±Ê®°ÂûãÈÄâÊã©Êõ¥Â∞ëÁöÑTokenÔºåÂêåÊó∂‰øùÊåÅÊàñÊèêÈ´ò‰ªªÂä°ÊàêÂäüÁéá„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁöÑÈÄâÊã©ÂèñÂÜ≥‰∫éÂÖ∑‰ΩìÁöÑVLAÊ®°ÂûãÂíå‰ªªÂä°„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

LightVLAÂú®LIBEROÂü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÁõ∏ËæÉ‰∫éÁé∞ÊúâVLAÊ®°ÂûãÂíåTokenÂâ™ÊûùÊñπÊ≥ïÔºåÂú®‰ªªÂä°ÊàêÂäüÁéá‰∏äÊèêÂçá‰∫Ü2.6%ÁöÑÂêåÊó∂ÔºåÂ∞ÜFLOPsÈôç‰Ωé‰∫Ü59.1%ÔºåÂª∂ËøüÈôç‰Ωé‰∫Ü38.2%„ÄÇLightVLA*ÔºàÂ∏¶ÊúâÂèØÂ≠¶‰π†Êü•ËØ¢ÁöÑÁâàÊú¨Ôºâ‰πüÂèñÂæó‰∫Ü‰ª§‰∫∫Êª°ÊÑèÁöÑÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜËØ•ÊñπÊ≥ïÂú®‰∏çÂêåÈÖçÁΩÆ‰∏ãÁöÑÊúâÊïàÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåLightVLAËÉΩÂ§üÊúâÊïàÂú∞Âπ≥Ë°°ËÆ°ÁÆóÊïàÁéáÂíå‰ªªÂä°ÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

LightVLAÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂ∞§ÂÖ∂ÊòØÂú®ËµÑÊ∫êÂèóÈôêÁöÑÊú∫Âô®‰∫∫Â∫îÁî®‰∏≠ÔºåÂ¶ÇÁßªÂä®Êú∫Âô®‰∫∫„ÄÅÊó†‰∫∫Êú∫Á≠â„ÄÇÈÄöËøáÈôç‰ΩéVLAÊ®°ÂûãÁöÑËÆ°ÁÆóÂºÄÈîÄÔºåLightVLAÂèØ‰ª•‰ΩøËøô‰∫õÊ®°ÂûãËÉΩÂ§üÂú®‰ΩéÂäüËÄóËÆæÂ§á‰∏äÂÆûÊó∂ËøêË°åÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥È´òÊïàÁöÑÊú∫Âô®‰∫∫ÊéßÂà∂„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Â∫îÁî®‰∫éÂÖ∂‰ªñÈúÄË¶ÅÂ§ÑÁêÜÂ§ßÈáèËßÜËßâ‰ø°ÊÅØÁöÑ‰ªªÂä°ÔºåÂ¶ÇËßÜÈ¢ëÂàÜÊûê„ÄÅÂõæÂÉèÊêúÁ¥¢Á≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We present LightVLA, a simple yet effective differentiable token pruning framework for vision-language-action (VLA) models. While VLA models have shown impressive capability in executing real-world robotic tasks, their deployment on resource-constrained platforms is often bottlenecked by the heavy attention-based computation over large sets of visual tokens. LightVLA addresses this challenge through adaptive, performance-driven pruning of visual tokens: It generates dynamic queries to evaluate visual token importance, and adopts Gumbel softmax to enable differentiable token selection. Through fine-tuning, LightVLA learns to preserve the most informative visual tokens while pruning tokens which do not contribute to task execution, thereby improving efficiency and performance simultaneously. Notably, LightVLA requires no heuristic magic numbers and introduces no additional trainable parameters, making it compatible with modern inference frameworks. Experimental results demonstrate that LightVLA outperforms different VLA models and existing token pruning methods across diverse tasks on the LIBERO benchmark, achieving higher success rates with substantially reduced computational overhead. Specifically, LightVLA reduces FLOPs and latency by 59.1% and 38.2% respectively, with a 2.6% improvement in task success rate. Meanwhile, we also investigate the learnable query-based token pruning method LightVLA* with additional trainable parameters, which also achieves satisfactory performance. Our work reveals that as VLA pursues optimal performance, LightVLA spontaneously learns to prune tokens from a performance-driven perspective. To the best of our knowledge, LightVLA is the first work to apply adaptive visual token pruning to VLA tasks with the collateral goals of efficiency and performance, marking a significant step toward more efficient, powerful and practical real-time robotic systems.

