---
layout: default
title: Contrastive Representation Learning for Robust Sim-to-Real Transfer of Adaptive Humanoid Locomotion
---

# Contrastive Representation Learning for Robust Sim-to-Real Transfer of Adaptive Humanoid Locomotion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.12858" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.12858v1</a>
  <a href="https://arxiv.org/pdf/2509.12858.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.12858v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.12858v1', 'Contrastive Representation Learning for Robust Sim-to-Real Transfer of Adaptive Humanoid Locomotion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yidan Lu, Rurui Yang, Qiran Kou, Mengting Chen, Tao Fan, Peter Cui, Yinzhao Dong, Peng Lu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-16

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://lu-yidan.github.io/cra-loco)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œæå‡äººå½¢æœºå™¨äººé€‚åº”æ€§æ­¥æ€çš„Sim-to-Realè¿ç§»é²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `äººå½¢æœºå™¨äºº` `å¼ºåŒ–å­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `Sim-to-Real` `è¿åŠ¨æ§åˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨äººå½¢æœºå™¨äººè¿åŠ¨æ§åˆ¶ä¸­é¢ä¸´é²æ£’æ€§å’Œä¸»åŠ¨æ€§ä¹‹é—´çš„æƒè¡¡ï¼Œçº¯æœ¬ä½“æ„Ÿå—æ§åˆ¶é²æ£’ä½†ç¼ºä¹ä¸»åŠ¨æ€§ï¼Œæ„ŸçŸ¥é©±åŠ¨ç³»ç»Ÿä¸»åŠ¨ä½†è„†å¼±ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡è®©Actorçš„æ½œåœ¨çŠ¶æ€ç¼–ç æ¨¡æ‹Ÿç¯å¢ƒä¸­çš„ç‰¹æƒä¿¡æ¯ï¼Œèµ‹äºˆçº¯æœ¬ä½“æ„Ÿå—ç­–ç•¥ä¸»åŠ¨èƒ½åŠ›ï¼Œå®ç°â€œæç‚¼çš„æ„ŸçŸ¥â€ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å®ç°äº†é›¶æ ·æœ¬Sim-to-Realè¿ç§»ï¼Œåœ¨å¤æ‚åœ°å½¢ä¸Šè¡¨ç°å‡ºé«˜åº¦é²æ£’çš„è¿åŠ¨èƒ½åŠ›ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼ºåŒ–å­¦ä¹ åœ¨äººå½¢æœºå™¨äººè¿åŠ¨æ§åˆ¶æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å®é™…éƒ¨ç½²é¢ä¸´ä¸€ä¸ªæ ¹æœ¬å›°å¢ƒï¼šç­–ç•¥å¿…é¡»åœ¨ååº”å¼æœ¬ä½“æ„Ÿå—æ§åˆ¶çš„é²æ£’æ€§å’Œå¤æ‚ã€è„†å¼±çš„æ„ŸçŸ¥é©±åŠ¨ç³»ç»Ÿçš„ä¸»åŠ¨æ€§ä¹‹é—´åšå‡ºé€‰æ‹©ã€‚æœ¬æ–‡é€šè¿‡å¼•å…¥ä¸€ç§èŒƒä¾‹æ¥è§£å†³è¿™ä¸€å›°å¢ƒï¼Œè¯¥èŒƒä¾‹ä½¿çº¯æœ¬ä½“æ„Ÿå—ç­–ç•¥å…·å¤‡ä¸»åŠ¨èƒ½åŠ›ï¼Œä»è€Œåœ¨ä¸äº§ç”Ÿéƒ¨ç½²æ—¶æˆæœ¬çš„æƒ…å†µä¸‹å®ç°æ„ŸçŸ¥çš„è¿œè§ã€‚æˆ‘ä»¬çš„æ ¸å¿ƒè´¡çŒ®æ˜¯ä¸€ä¸ªå¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œå®ƒè¿«ä½¿Actorçš„æ½œåœ¨çŠ¶æ€ç¼–ç æ¥è‡ªæ¨¡æ‹Ÿç¯å¢ƒçš„ç‰¹æƒä¿¡æ¯ã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼Œè¿™ç§â€œæç‚¼çš„æ„ŸçŸ¥â€èµ‹äºˆè‡ªé€‚åº”æ­¥æ€æ—¶é’Ÿèƒ½åŠ›ï¼Œä½¿ç­–ç•¥èƒ½å¤Ÿæ ¹æ®å¯¹åœ°å½¢çš„æ¨æ–­ç†è§£ä¸»åŠ¨è°ƒæ•´å…¶èŠ‚å¥ã€‚è¿™ç§ååŒä½œç”¨è§£å†³äº†åˆšæ€§ã€æ—¶é’Ÿé©±åŠ¨æ­¥æ€å’Œä¸ç¨³å®šçš„æ— æ—¶é’Ÿç­–ç•¥ä¹‹é—´çš„ç»å…¸æƒè¡¡ã€‚æˆ‘ä»¬é€šè¿‡é›¶æ ·æœ¬Sim-to-Realè¿ç§»åˆ°å…¨å°ºå¯¸äººå½¢æœºå™¨äººæ¥éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå±•ç¤ºäº†åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°å½¢ï¼ˆåŒ…æ‹¬30å˜ç±³é«˜çš„å°é˜¶å’Œ26.5Â°çš„æ–œå¡ï¼‰ä¸Šçš„é«˜åº¦é²æ£’çš„è¿åŠ¨ï¼Œè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºå¼ºåŒ–å­¦ä¹ çš„äººå½¢æœºå™¨äººè¿åŠ¨æ§åˆ¶æ–¹æ³•ï¼Œè¦ä¹ˆä¾èµ–äºé²æ£’ä½†ç¼ºä¹ä¸»åŠ¨æ€§çš„æœ¬ä½“æ„Ÿå—æ§åˆ¶ï¼Œè¦ä¹ˆä¾èµ–äºä¸»åŠ¨ä½†è„†å¼±çš„æ„ŸçŸ¥é©±åŠ¨ç³»ç»Ÿã€‚å¦‚ä½•åœ¨ä¿è¯é²æ£’æ€§çš„å‰æä¸‹ï¼Œèµ‹äºˆæœºå™¨äººä¸»åŠ¨é€‚åº”ç¯å¢ƒçš„èƒ½åŠ›ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºï¼Œæ„ŸçŸ¥æ¨¡å—çš„å¼•å…¥ä¼šå¢åŠ ç³»ç»Ÿçš„å¤æ‚æ€§å’Œè„†å¼±æ€§ï¼Œéš¾ä»¥å®ç°å¯é çš„Sim-to-Realè¿ç§»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œå°†æ¨¡æ‹Ÿç¯å¢ƒä¸­çš„ç‰¹æƒä¿¡æ¯ï¼ˆä¾‹å¦‚åœ°å½¢ä¿¡æ¯ï¼‰â€œæç‚¼â€åˆ°Actorçš„æ½œåœ¨çŠ¶æ€ä¸­ã€‚è¿™æ ·ï¼Œå³ä½¿åœ¨çœŸå®ç¯å¢ƒä¸­æ²¡æœ‰æ„ŸçŸ¥æ¨¡å—ï¼Œæœºå™¨äººä¹Ÿèƒ½é€šè¿‡æ½œåœ¨çŠ¶æ€â€œæ„ŸçŸ¥â€ç¯å¢ƒï¼Œä»è€Œä¸»åŠ¨è°ƒæ•´æ­¥æ€ã€‚è¿™ç§æ–¹æ³•é¿å…äº†ç›´æ¥ä½¿ç”¨æ„ŸçŸ¥æ¨¡å—å¸¦æ¥çš„è„†å¼±æ€§ï¼ŒåŒæ—¶ä¿ç•™äº†ä¸»åŠ¨é€‚åº”ç¯å¢ƒçš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸€ä¸ªåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è®­ç»ƒçš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥ã€‚è¯¥ç­–ç•¥çš„Actorç½‘ç»œæ¥æ”¶æœ¬ä½“æ„Ÿå—ä¿¡æ¯ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºåŠ¨ä½œã€‚å…³é”®åœ¨äºï¼ŒActorç½‘ç»œçš„æ½œåœ¨çŠ¶æ€é€šè¿‡å¯¹æ¯”å­¦ä¹ ä¸æ¨¡æ‹Ÿç¯å¢ƒä¸­çš„ç‰¹æƒä¿¡æ¯å¯¹é½ã€‚å…·ä½“æ¥è¯´ï¼Œä½¿ç”¨ä¸€ä¸ªå¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œä½¿å¾—ç›¸ä¼¼ç¯å¢ƒçŠ¶æ€ä¸‹çš„æ½œåœ¨çŠ¶æ€æ›´åŠ æ¥è¿‘ï¼Œè€Œä¸åŒç¯å¢ƒçŠ¶æ€ä¸‹çš„æ½œåœ¨çŠ¶æ€æ›´åŠ è¿œç¦»ã€‚è®­ç»ƒå®Œæˆåï¼Œå°†è¯¥ç­–ç•¥ç›´æ¥éƒ¨ç½²åˆ°çœŸå®æœºå™¨äººä¸Šï¼Œæ— éœ€ä»»ä½•å¾®è°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºä½¿ç”¨å¯¹æ¯”å­¦ä¹ å°†æ¨¡æ‹Ÿç¯å¢ƒä¸­çš„ç‰¹æƒä¿¡æ¯â€œæç‚¼â€åˆ°Actorçš„æ½œåœ¨çŠ¶æ€ä¸­ã€‚ä¸ä¼ ç»Ÿçš„Sim-to-Realæ–¹æ³•ä¸åŒï¼Œæœ¬æ–‡ä¸éœ€è¦æ˜¾å¼åœ°æ¨¡æ‹ŸçœŸå®ç¯å¢ƒçš„å™ªå£°æˆ–ä½¿ç”¨åŸŸéšæœºåŒ–ï¼Œè€Œæ˜¯é€šè¿‡å¯¹æ¯”å­¦ä¹ éšå¼åœ°å­¦ä¹ ç¯å¢ƒçš„è¡¨ç¤ºã€‚è¿™ä½¿å¾—ç­–ç•¥æ›´åŠ é²æ£’ï¼Œæ›´å®¹æ˜“è¿ç§»åˆ°çœŸå®ç¯å¢ƒã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®çš„æŠ€æœ¯ç»†èŠ‚åŒ…æ‹¬ï¼š1) ä½¿ç”¨Transformerç½‘ç»œä½œä¸ºActorï¼Œä»¥æ›´å¥½åœ°æ•æ‰æ—¶é—´ä¾èµ–å…³ç³»ï¼›2) è®¾è®¡å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±ç›¸ä¼¼ç¯å¢ƒçŠ¶æ€ä¸‹çš„æ½œåœ¨çŠ¶æ€æ›´åŠ æ¥è¿‘ï¼›3) ä½¿ç”¨è‡ªé€‚åº”æ­¥æ€æ—¶é’Ÿï¼Œæ ¹æ®æ½œåœ¨çŠ¶æ€è°ƒæ•´æ­¥æ€èŠ‚å¥ï¼Œä»è€Œå®ç°ä¸»åŠ¨é€‚åº”ç¯å¢ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•å®ç°äº†é›¶æ ·æœ¬Sim-to-Realè¿ç§»ï¼Œåœ¨å…¨å°ºå¯¸äººå½¢æœºå™¨äººä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æœºå™¨äººèƒ½å¤Ÿåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ°å½¢ä¸Šå®ç°é«˜åº¦é²æ£’çš„è¿åŠ¨ï¼ŒåŒ…æ‹¬30å˜ç±³é«˜çš„å°é˜¶å’Œ26.5Â°çš„æ–œå¡ã€‚è¿™äº›ç»“æœæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„åŸºäºæœ¬ä½“æ„Ÿå—æ§åˆ¶çš„æ–¹æ³•ï¼Œè¯æ˜äº†å¯¹æ¯”å­¦ä¹ åœ¨æå‡Sim-to-Realè¿ç§»é²æ£’æ€§æ–¹é¢çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§å¤æ‚åœ°å½¢ä¸‹çš„äººå½¢æœºå™¨äººè¿åŠ¨æ§åˆ¶ï¼Œä¾‹å¦‚æœç´¢æ•‘æ´ã€ç¾åé‡å»ºã€å·¥ä¸šå·¡æ£€ç­‰åœºæ™¯ã€‚é€šè¿‡æå‡æœºå™¨äººçš„ç¯å¢ƒé€‚åº”æ€§å’Œè¿åŠ¨é²æ£’æ€§ï¼Œå¯ä»¥ä½¿å…¶åœ¨æ›´å¹¿æ³›çš„å®é™…åº”ç”¨ä¸­å‘æŒ¥ä½œç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„æœºå™¨äººå’Œä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚å››è¶³æœºå™¨äººã€æ— äººé©¾é©¶è½¦è¾†ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement learning has produced remarkable advances in humanoid locomotion, yet a fundamental dilemma persists for real-world deployment: policies must choose between the robustness of reactive proprioceptive control or the proactivity of complex, fragile perception-driven systems. This paper resolves this dilemma by introducing a paradigm that imbues a purely proprioceptive policy with proactive capabilities, achieving the foresight of perception without its deployment-time costs. Our core contribution is a contrastive learning framework that compels the actor's latent state to encode privileged environmental information from simulation. Crucially, this ``distilled awareness" empowers an adaptive gait clock, allowing the policy to proactively adjust its rhythm based on an inferred understanding of the terrain. This synergy resolves the classic trade-off between rigid, clocked gaits and unstable clock-free policies. We validate our approach with zero-shot sim-to-real transfer to a full-sized humanoid, demonstrating highly robust locomotion over challenging terrains, including 30 cm high steps and 26.5Â° slopes, proving the effectiveness of our method. Website: https://lu-yidan.github.io/cra-loco.

