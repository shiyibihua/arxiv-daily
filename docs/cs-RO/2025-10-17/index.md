---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-10-17
---

# cs.ROï¼ˆ2025-10-17ï¼‰

ğŸ“Š å…± **15** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (10)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (10 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251015626v2-adaptive-legged-locomotion-via-online-learning-for-model-predictive-.html">Adaptive Legged Locomotion via Online Learning for Model Predictive Control</a></td>
  <td>æå‡ºåŸºäºåœ¨çº¿å­¦ä¹ çš„è‡ªé€‚åº”è…¿è¶³æœºå™¨äººè¿åŠ¨æ§åˆ¶ç®—æ³•ï¼Œåº”å¯¹æœªçŸ¥æ‰°åŠ¨ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.15626v2" onclick="toggleFavorite(this, '2510.15626v2', 'Adaptive Legged Locomotion via Online Learning for Model Predictive Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251021773v2-real-time-qp-solvers-a-concise-review-and-practical-guide-towards-le.html">Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots</a></td>
  <td>é’ˆå¯¹è…¿è¶³æœºå™¨äººï¼Œå¯¹å®æ—¶äºŒæ¬¡è§„åˆ’æ±‚è§£å™¨è¿›è¡Œç»¼è¿°ä¸å®è·µæŒ‡å¯¼</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.21773v2" onclick="toggleFavorite(this, '2510.21773v2', 'Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251015530v4-vo-dp-semantic-geometric-adaptive-diffusion-policy-for-vision-only-r.html">VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation</a></td>
  <td>æå‡ºVO-DPï¼šä¸€ç§åŸºäºè§†è§‰çš„è¯­ä¹‰-å‡ ä½•è‡ªé€‚åº”æ‰©æ•£ç­–ç•¥ï¼Œç”¨äºæœºå™¨äººæ“ä½œ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.15530v4" onclick="toggleFavorite(this, '2510.15530v4', 'VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251015786v2-dexcanvas-bridging-human-demonstrations-and-robot-learning-for-dexte.html">DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation</a></td>
  <td>DexCanvasï¼šæ¡¥æ¥äººç±»æ¼”ç¤ºä¸æœºå™¨äººå­¦ä¹ çš„çµå·§æ“ä½œæ•°æ®é›†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.15786v2" onclick="toggleFavorite(this, '2510.15786v2', 'DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251016263v2-nebula-do-we-evaluate-vision-language-action-agents-correctly.html">NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?</a></td>
  <td>NEBULAï¼šç”¨äºè¯Šæ–­å’Œå¯å¤ç°è¯„ä¼°VLAæ™ºèƒ½ä½“çš„ç»Ÿä¸€ç”Ÿæ€ç³»ç»Ÿ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.16263v2" onclick="toggleFavorite(this, '2510.16263v2', 'NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251015352v1-gaussgym-an-open-source-real-to-sim-framework-for-learning-locomotio.html">GaussGym: An open-source real-to-sim framework for learning locomotion from pixels</a></td>
  <td>GaussGymï¼šä¸€ç§åŸºäºåƒç´ å­¦ä¹ æœºå™¨äººè¿åŠ¨çš„å¼€æºå®-è™šæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.15352v1" onclick="toggleFavorite(this, '2510.15352v1', 'GaussGym: An open-source real-to-sim framework for learning locomotion from pixels')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251021771v1-improving-the-performance-of-ai-powered-affordable-robotics-for-assi.html">Improving the performance of AI-powered Affordable Robotics for Assistive Tasks</a></td>
  <td>æå‡ºåŸºäºæ¨¡ä»¿å­¦ä¹ çš„ä½æˆæœ¬æœºå™¨äººè‡‚ï¼Œç”¨äºè¾…åŠ©ä»»åŠ¡å¹¶æ˜¾è‘—æå‡æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.21771v1" onclick="toggleFavorite(this, '2510.21771v1', 'Improving the performance of AI-powered Affordable Robotics for Assistive Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251015639v1-integration-of-a-variable-stiffness-link-for-long-reach-aerial-manip.html">Integration of a Variable Stiffness Link for Long-Reach Aerial Manipulation</a></td>
  <td>é›†æˆå˜åˆšåº¦è¿æ¥ä»¶ï¼Œå®ç°é•¿è‡‚ç©ºä¸­æ“ä½œçš„çµæ´»æ€§ä¸ç²¾ç¡®æ€§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.15639v1" onclick="toggleFavorite(this, '2510.15639v1', 'Integration of a Variable Stiffness Link for Long-Reach Aerial Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251015220v1-lvi-q-robust-lidar-visual-inertial-kinematic-odometry-for-quadruped-.html">LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization</a></td>
  <td>æå‡ºLVI-Qï¼šä¸€ç§é²æ£’çš„æ¿€å…‰é›·è¾¾-è§†è§‰-æƒ¯æ€§-è¿åŠ¨å­¦é‡Œç¨‹è®¡ï¼Œç”¨äºå››è¶³æœºå™¨äººã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.15220v1" onclick="toggleFavorite(this, '2510.15220v1', 'LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251015376v1-towards-automated-chicken-deboning-via-learning-based-dynamically-ad.html">Towards Automated Chicken Deboning via Learning-based Dynamically-Adaptive 6-DoF Multi-Material Cutting</a></td>
  <td>æå‡ºåŸºäºå­¦ä¹ çš„åŠ¨æ€è‡ªé€‚åº”å…­è‡ªç”±åº¦å¤šæè´¨åˆ‡å‰²æ–¹æ³•ï¼Œå®ç°è‡ªåŠ¨åŒ–é¸¡è‚©å‰”éª¨</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.15376v1" onclick="toggleFavorite(this, '2510.15376v1', 'Towards Automated Chicken Deboning via Learning-based Dynamically-Adaptive 6-DoF Multi-Material Cutting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>11</td>
  <td><a href="./papers/251015446v1-vdrive-leveraging-reinforced-vla-and-diffusion-policy-for-end-to-end.html">VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving</a></td>
  <td>VDRiveï¼šåˆ©ç”¨å¼ºåŒ–VLAå’Œæ‰©æ•£ç­–ç•¥å®ç°ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.15446v1" onclick="toggleFavorite(this, '2510.15446v1', 'VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251016240v2-cosmos-surg-dvrk-world-foundation-model-based-automated-online-evalu.html">Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning</a></td>
  <td>Cosmos-Surg-dVRKï¼šåŸºäºä¸–ç•ŒåŸºç¡€æ¨¡å‹çš„æœºå™¨äººæ‰‹æœ¯ç­–ç•¥åœ¨çº¿è‡ªåŠ¨è¯„ä¼°</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.16240v2" onclick="toggleFavorite(this, '2510.16240v2', 'Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251015679v1-header-hierarchical-robot-exploration-via-attention-based-deep-reinf.html">HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward</a></td>
  <td>HEADERï¼šåŸºäºæ³¨æ„åŠ›æ·±åº¦å¼ºåŒ–å­¦ä¹ å’Œä¸“å®¶å¼•å¯¼å¥–åŠ±çš„åˆ†å±‚æœºå™¨äººæ¢ç´¢æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.15679v1" onclick="toggleFavorite(this, '2510.15679v1', 'HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>14</td>
  <td><a href="./papers/251015319v1-traversability-aware-consistent-situational-graphs-for-indoor-locali.html">Traversability-aware Consistent Situational Graphs for Indoor Localization and Mapping</a></td>
  <td>æå‡ºå¯é€šè¡Œæ€§æ„ŸçŸ¥çš„åœºæ™¯å›¾æ„å»ºæ–¹æ³•ï¼Œæå‡å®¤å†…å®šä½ä¸åœ°å›¾æ„å»ºä¸€è‡´æ€§ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.15319v1" onclick="toggleFavorite(this, '2510.15319v1', 'Traversability-aware Consistent Situational Graphs for Indoor Localization and Mapping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251016205v1-var-slam-visual-adaptive-and-robust-slam-for-dynamic-environments.html">VAR-SLAM: Visual Adaptive and Robust SLAM for Dynamic Environments</a></td>
  <td>VAR-SLAMï¼šé¢å‘åŠ¨æ€ç¯å¢ƒçš„è§†è§‰è‡ªé€‚åº”é²æ£’SLAM</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.16205v1" onclick="toggleFavorite(this, '2510.16205v1', 'VAR-SLAM: Visual Adaptive and Robust SLAM for Dynamic Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)