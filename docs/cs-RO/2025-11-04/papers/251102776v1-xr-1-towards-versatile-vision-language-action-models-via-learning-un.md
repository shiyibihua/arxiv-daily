---
layout: default
title: XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations
---

# XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations

**arXiv**: [2511.02776v1](https://arxiv.org/abs/2511.02776) | [PDF](https://arxiv.org/pdf/2511.02776.pdf)

**ä½œè€…**: Shichao Fan, Kun Wu, Zhengping Che, Xinhua Wang, Di Wu, Fei Liao, Ning Liu, Yixue Zhang, Zhen Zhao, Zhiyuan Xu, Meng Li, Qingjie Liu, Shanghang Zhang, Min Wan, Jian Tang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-04

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://xr-1-vla.github.io/)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**XR-1ï¼šé€šè¿‡å­¦ä¹ ç»Ÿä¸€è§†è§‰-è¿åŠ¨è¡¨å¾ï¼Œå®žçŽ°é€šç”¨è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `æœºå™¨äººå­¦ä¹ ` `ç»Ÿä¸€è¡¨å¾å­¦ä¹ ` `å¤šæ¨¡æ€èžåˆ` `å¼‚æž„æ•°æ®` `VQ-VAE` `æœºå™¨äººæ“ä½œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰VLAæ¨¡åž‹éš¾ä»¥ä»Žé«˜ç»´è§‚æµ‹ç”Ÿæˆç²¾ç¡®åŠ¨ä½œï¼Œä¸”éš¾ä»¥å¼¥åˆä¸åŒæœºå™¨äººå½¢æ€å’Œäººç±»æ¼”ç¤ºæ•°æ®é—´çš„é¢†åŸŸå·®è·ã€‚
2. XR-1æå‡ºç»Ÿä¸€è§†è§‰-è¿åŠ¨ä»£ç ï¼ˆUVMCï¼‰ï¼Œé€šè¿‡åŒåˆ†æ”¯VQ-VAEè”åˆç¼–ç è§†è§‰åŠ¨æ€å’Œæœºå™¨äººè¿åŠ¨ï¼Œä½œä¸ºè§‚æµ‹å’ŒåŠ¨ä½œçš„ä¸­é—´è¡¨ç¤ºã€‚
3. åœ¨å…­ç§æœºå™¨äººå½¢æ€ä¸Šè¿›è¡Œäº†è¶…è¿‡14,000æ¬¡rolloutçš„å®žéªŒï¼ŒXR-1åœ¨120å¤šä¸ªæ“ä½œä»»åŠ¡ä¸­ä¼˜äºŽçŽ°æœ‰åŸºçº¿ï¼Œå¹¶å±•çŽ°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è§„æ¨¡æœºå™¨äººæ•°æ®é›†å’Œè§†è§‰-è¯­è¨€æ¨¡åž‹ï¼ˆVLMï¼‰çš„æœ€æ–°è¿›å±•æŽ¨åŠ¨äº†è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹çš„ç ”ç©¶ã€‚ç„¶è€Œï¼ŒçŽ°æœ‰çš„VLAæ¨¡åž‹ä»ç„¶é¢ä¸´ä¸¤ä¸ªæ ¹æœ¬æ€§çš„æŒ‘æˆ˜ï¼šï¼ˆiï¼‰ä»Žé«˜ç»´è§‚æµ‹ä¸­äº§ç”Ÿç²¾ç¡®çš„ä½Žçº§åŠ¨ä½œï¼Œï¼ˆiiï¼‰å¼¥åˆè·¨å¼‚æž„æ•°æ®æºçš„é¢†åŸŸå·®è·ï¼ŒåŒ…æ‹¬ä¸åŒçš„æœºå™¨äººå½¢æ€å’Œäººç±»æ¼”ç¤ºã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸ä»Žè§†è§‰åŠ¨æ€æˆ–æœºå™¨äººåŠ¨ä½œä¸­ç¼–ç æ½œåœ¨å˜é‡æ¥æŒ‡å¯¼ç­–ç•¥å­¦ä¹ ï¼Œä½†å®ƒä»¬æœªèƒ½å……åˆ†åˆ©ç”¨å¤§è§„æ¨¡å¼‚æž„æ•°æ®é›†ä¸­å­˜åœ¨çš„äº’è¡¥å¤šæ¨¡æ€çŸ¥è¯†ã€‚æœ¬æ–‡æå‡ºäº†X Robotic Model 1ï¼ˆXR-1ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºŽè·¨ä¸åŒæœºå™¨äººã€ä»»åŠ¡å’ŒçŽ¯å¢ƒè¿›è¡Œé€šç”¨ä¸”å¯æ‰©å±•çš„VLAå­¦ä¹ çš„æ–°æ¡†æž¶ã€‚XR-1å¼•å…¥äº†ç»Ÿä¸€è§†è§‰-è¿åŠ¨ä»£ç ï¼ˆUVMCï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡åŒåˆ†æ”¯VQ-VAEå­¦ä¹ çš„ç¦»æ•£æ½œåœ¨è¡¨ç¤ºï¼Œå®ƒè”åˆç¼–ç è§†è§‰åŠ¨æ€å’Œæœºå™¨äººè¿åŠ¨ã€‚UVMCé€šè¿‡ï¼ˆiï¼‰å……å½“è§‚æµ‹å’ŒåŠ¨ä½œä¹‹é—´çš„ä¸­é—´è¡¨ç¤ºï¼Œä»¥åŠï¼ˆiiï¼‰å¯¹é½æ¥è‡ªå¼‚æž„æ•°æ®æºçš„å¤šæ¨¡æ€åŠ¨æ€ä¿¡æ¯ä»¥æ•èŽ·äº’è¡¥çŸ¥è¯†æ¥è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚ä¸ºäº†æœ‰æ•ˆåœ°åˆ©ç”¨UVMCï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸‰é˜¶æ®µè®­ç»ƒèŒƒå¼ï¼šï¼ˆiï¼‰è‡ªç›‘ç£UVMCå­¦ä¹ ï¼Œï¼ˆiiï¼‰åœ¨å¤§åž‹è·¨å½¢æ€æœºå™¨äººæ•°æ®é›†ä¸Šè¿›è¡ŒUVMCå¼•å¯¼çš„é¢„è®­ç»ƒï¼Œä»¥åŠï¼ˆiiiï¼‰ç‰¹å®šäºŽä»»åŠ¡çš„åŽè®­ç»ƒã€‚æˆ‘ä»¬é€šè¿‡åœ¨å…­ç§ä¸åŒçš„æœºå™¨äººå½¢æ€ä¸Šè¿›è¡Œçš„è¶…è¿‡14,000æ¬¡rolloutçš„å¹¿æ³›çœŸå®žä¸–ç•Œå®žéªŒéªŒè¯äº†XR-1ï¼Œæ¶µç›–äº†120å¤šä¸ªä¸åŒçš„æ“ä½œä»»åŠ¡ã€‚XR-1å§‹ç»ˆä¼˜äºŽæœ€å…ˆè¿›çš„åŸºçº¿ï¼Œå¦‚$Ï€_{0.5}$ï¼Œ$Ï€_0$ï¼ŒRDTï¼ŒUniVLAå’ŒGR00T-N1.5ï¼ŒåŒæ—¶å±•ç¤ºäº†å¯¹æ–°é¢–å¯¹è±¡ã€èƒŒæ™¯å˜åŒ–ã€å¹²æ‰°ç‰©å’Œå…‰ç…§å˜åŒ–çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹åœ¨å¤„ç†é«˜ç»´è§†è§‰è¾“å…¥å¹¶ç”Ÿæˆç²¾ç¡®çš„ä½Žçº§åŠ¨ä½œæ—¶é¢ä¸´æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œç”±äºŽæœºå™¨äººå½¢æ€å’Œæ•°æ®æ¥æºçš„å¤šæ ·æ€§ï¼ŒVLAæ¨¡åž‹éš¾ä»¥åœ¨å¼‚æž„æ•°æ®ä¸Šè¿›è¡Œæœ‰æ•ˆè®­ç»ƒï¼Œä»Žè€Œé™åˆ¶äº†å…¶é€šç”¨æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºŽç¼–ç è§†è§‰åŠ¨æ€æˆ–æœºå™¨äººåŠ¨ä½œçš„æ½œåœ¨å˜é‡ï¼Œä½†æœªèƒ½å……åˆ†åˆ©ç”¨å¼‚æž„æ•°æ®é›†ä¸­è•´å«çš„äº’è¡¥å¤šæ¨¡æ€ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šXR-1çš„æ ¸å¿ƒæ€è·¯æ˜¯å­¦ä¹ ä¸€ç§ç»Ÿä¸€çš„è§†è§‰-è¿åŠ¨è¡¨å¾ï¼ˆUVMCï¼‰ï¼Œè¯¥è¡¨å¾èƒ½å¤ŸåŒæ—¶ç¼–ç è§†è§‰åŠ¨æ€å’Œæœºå™¨äººè¿åŠ¨ã€‚é€šè¿‡å°†è§†è§‰å’Œè¿åŠ¨ä¿¡æ¯æ˜ å°„åˆ°å…±äº«çš„ç¦»æ•£æ½œåœ¨ç©ºé—´ï¼ŒUVMCå¯ä»¥ä½œä¸ºè§‚æµ‹å’ŒåŠ¨ä½œä¹‹é—´çš„æ¡¥æ¢ï¼Œä»Žè€Œç®€åŒ–ç­–ç•¥å­¦ä¹ è¿‡ç¨‹ã€‚æ­¤å¤–ï¼ŒUVMCçš„è®¾è®¡æ—¨åœ¨å¯¹é½æ¥è‡ªä¸åŒæœºå™¨äººå½¢æ€å’Œæ•°æ®æ¥æºçš„å¤šæ¨¡æ€åŠ¨æ€ä¿¡æ¯ï¼Œä»Žè€Œä¿ƒè¿›çŸ¥è¯†è¿ç§»å’Œæ³›åŒ–ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šXR-1çš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š(1) è‡ªç›‘ç£UVMCå­¦ä¹ ï¼šä½¿ç”¨åŒåˆ†æ”¯VQ-VAEå­¦ä¹ ç»Ÿä¸€çš„è§†è§‰-è¿åŠ¨ä»£ç ï¼Œåˆ†åˆ«ç¼–ç è§†è§‰åŠ¨æ€å’Œæœºå™¨äººè¿åŠ¨ã€‚(2) UVMCå¼•å¯¼çš„é¢„è®­ç»ƒï¼šåœ¨å¤§è§„æ¨¡è·¨å½¢æ€æœºå™¨äººæ•°æ®é›†ä¸Šï¼Œåˆ©ç”¨UVMCä½œä¸ºä¸­é—´è¡¨ç¤ºè¿›è¡Œé¢„è®­ç»ƒï¼Œå­¦ä¹ é€šç”¨çš„æœºå™¨äººæ“ä½œæŠ€èƒ½ã€‚(3) ä»»åŠ¡ç‰¹å®šåŽè®­ç»ƒï¼šåœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä»¥ä¼˜åŒ–æ¨¡åž‹æ€§èƒ½ã€‚æ•´ä¸ªæ¡†æž¶æ—¨åœ¨å®žçŽ°è·¨ä¸åŒæœºå™¨äººã€ä»»åŠ¡å’ŒçŽ¯å¢ƒçš„é€šç”¨ä¸”å¯æ‰©å±•çš„VLAå­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šXR-1çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†ç»Ÿä¸€è§†è§‰-è¿åŠ¨ä»£ç ï¼ˆUVMCï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç¦»æ•£çš„æ½œåœ¨è¡¨å¾ï¼Œèƒ½å¤Ÿè”åˆç¼–ç è§†è§‰åŠ¨æ€å’Œæœºå™¨äººè¿åŠ¨ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒUVMCèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨å¼‚æž„æ•°æ®é›†ä¸­è•´å«çš„äº’è¡¥å¤šæ¨¡æ€ä¿¡æ¯ï¼Œä»Žè€Œæé«˜æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚æ­¤å¤–ï¼Œä¸‰é˜¶æ®µè®­ç»ƒèŒƒå¼ä¹Ÿä¸ºVLAæ¨¡åž‹çš„å­¦ä¹ æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯ã€‚

**å…³é”®è®¾è®¡**ï¼šUVMCé‡‡ç”¨åŒåˆ†æ”¯VQ-VAEç»“æž„ï¼Œåˆ†åˆ«å¤„ç†è§†è§‰å’Œè¿åŠ¨ä¿¡æ¯ã€‚æ¯ä¸ªåˆ†æ”¯åŒ…å«ç¼–ç å™¨ã€é‡åŒ–å™¨å’Œè§£ç å™¨ã€‚é‡åŒ–å™¨å°†è¿žç»­çš„æ½œåœ¨å‘é‡æ˜ å°„åˆ°ç¦»æ•£çš„ç æœ¬ä¸­ï¼Œä»Žè€Œå®žçŽ°ä¿¡æ¯çš„åŽ‹ç¼©å’Œå¯¹é½ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é‡æž„æŸå¤±ã€é‡åŒ–æŸå¤±å’Œä¸€è‡´æ€§æŸå¤±ï¼Œç”¨äºŽä¼˜åŒ–UVMCçš„è¡¨å¾èƒ½åŠ›ã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨UVMCä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œé€šè¿‡é¢„æµ‹æœªæ¥çš„çŠ¶æ€æˆ–åŠ¨ä½œæ¥å­¦ä¹ æœºå™¨äººæ“ä½œæŠ€èƒ½ã€‚åœ¨åŽè®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–ç›‘ç£å­¦ä¹ æ–¹æ³•å¯¹æ¨¡åž‹è¿›è¡Œå¾®è°ƒã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

XR-1åœ¨çœŸå®žä¸–ç•Œå®žéªŒä¸­è¡¨çŽ°å‡ºè‰²ï¼Œåœ¨å…­ç§ä¸åŒçš„æœºå™¨äººå½¢æ€ä¸Šè¿›è¡Œäº†è¶…è¿‡14,000æ¬¡rolloutï¼Œæ¶µç›–äº†120å¤šä¸ªä¸åŒçš„æ“ä½œä»»åŠ¡ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒXR-1å§‹ç»ˆä¼˜äºŽæœ€å…ˆè¿›çš„åŸºçº¿æ¨¡åž‹ï¼Œå¦‚$Ï€_{0.5}$ï¼Œ$Ï€_0$ï¼ŒRDTï¼ŒUniVLAå’ŒGR00T-N1.5ã€‚æ­¤å¤–ï¼ŒXR-1è¿˜å±•ç¤ºäº†å¯¹æ–°é¢–å¯¹è±¡ã€èƒŒæ™¯å˜åŒ–ã€å¹²æ‰°ç‰©å’Œå…‰ç…§å˜åŒ–çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ï¼Œè¯æ˜Žäº†å…¶åœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„é²æ£’æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

XR-1å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºŽå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œå¦‚ç‰©ä½“æŠ“å–ã€è£…é…ã€å¯¼èˆªç­‰ã€‚è¯¥æ¨¡åž‹å¯ä»¥åº”ç”¨äºŽå·¥ä¸šè‡ªåŠ¨åŒ–ã€å®¶åº­æœåŠ¡ã€åŒ»ç–—ä¿å¥ç­‰é¢†åŸŸï¼Œæé«˜æœºå™¨äººçš„æ™ºèƒ½åŒ–æ°´å¹³å’Œè‡ªä¸»æ€§ã€‚æ­¤å¤–ï¼ŒXR-1çš„ç ”ç©¶æˆæžœè¿˜å¯ä»¥ä¿ƒè¿›è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹çš„å‘å±•ï¼Œä¸ºå®žçŽ°æ›´é€šç”¨çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿå¥ å®šåŸºç¡€ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent progress in large-scale robotic datasets and vision-language models (VLMs) has advanced research on vision-language-action (VLA) models. However, existing VLA models still face two fundamental challenges: (i) producing precise low-level actions from high-dimensional observations, (ii) bridging domain gaps across heterogeneous data sources, including diverse robot embodiments and human demonstrations. Existing methods often encode latent variables from either visual dynamics or robotic actions to guide policy learning, but they fail to fully exploit the complementary multi-modal knowledge present in large-scale, heterogeneous datasets. In this work, we present X Robotic Model 1 (XR-1), a novel framework for versatile and scalable VLA learning across diverse robots, tasks, and environments. XR-1 introduces the \emph{Unified Vision-Motion Codes (UVMC)}, a discrete latent representation learned via a dual-branch VQ-VAE that jointly encodes visual dynamics and robotic motion. UVMC addresses these challenges by (i) serving as an intermediate representation between the observations and actions, and (ii) aligning multimodal dynamic information from heterogeneous data sources to capture complementary knowledge. To effectively exploit UVMC, we propose a three-stage training paradigm: (i) self-supervised UVMC learning, (ii) UVMC-guided pretraining on large-scale cross-embodiment robotic datasets, and (iii) task-specific post-training. We validate XR-1 through extensive real-world experiments with more than 14,000 rollouts on six different robot embodiments, spanning over 120 diverse manipulation tasks. XR-1 consistently outperforms state-of-the-art baselines such as $Ï€_{0.5}$, $Ï€_0$, RDT, UniVLA, and GR00T-N1.5 while demonstrating strong generalization to novel objects, background variations, distractors, and illumination changes. Our project is at https://xr-1-vla.github.io/.

