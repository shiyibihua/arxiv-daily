---
layout: default
title: LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation
---

# LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.02239" target="_blank" class="toolbar-btn">arXiv: 2511.02239v1</a>
    <a href="https://arxiv.org/pdf/2511.02239.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.02239v1" 
            onclick="toggleFavorite(this, '2511.02239v1', 'LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Youngjin Hong, Houjian Yu, Mingen Li, Changhyun Choi

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-04

**Â§áÊ≥®**: Preprint. Project page: https://vla2026.github.io/LACY/

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://vla2026.github.io/LACY/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**LACYÔºöÂü∫‰∫éËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÁöÑËØ≠Ë®Ä-Âä®‰ΩúÂæ™ÁéØÔºåÁî®‰∫éËá™ÊèêÂçáÁöÑÊú∫Âô®‰∫∫Êìç‰Ωú**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Êìç‰Ωú` `ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã` `ËØ≠Ë®Ä-Âä®‰ΩúÂæ™ÁéØ` `Ëá™ÁõëÁù£Â≠¶‰π†` `‰∏ªÂä®Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊú∫Âô®‰∫∫Êìç‰ΩúÁ≠ñÁï•Áº∫‰πè‰∏ä‰∏ãÊñáÁêÜËß£ÔºåÊ≥õÂåñËÉΩÂäõÂèóÈôêÔºå‰∏îÊó†Ê≥ïËß£ÈáäËá™Ë∫´Ë°å‰∏∫„ÄÇ
2. LACYÊ°ÜÊû∂ÈÄöËøáÂú®ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã‰∏≠Â≠¶‰π†ÂèåÂêëÊò†Â∞ÑÔºàL2AÂíåA2LÔºâÊù•Ëß£ÂÜ≥Ê≠§ÈóÆÈ¢ò„ÄÇ
3. LACYÈÄöËøáËá™ÁõëÁù£Âæ™ÁéØÁîüÊàêÂíåËøáÊª§ËÆ≠ÁªÉÊï∞ÊçÆÔºåÊó†ÈúÄÈ¢ùÂ§ñ‰∫∫Â∑•Ê†áÊ≥®Âç≥ÂèØÊèêÂçáÊ®°ÂûãÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∏∫‰∫ÜÂ≠¶‰π†Êú∫Âô®‰∫∫Êìç‰ΩúÁöÑÈÄöÁî®Á≠ñÁï•ÔºåË∂äÊù•Ë∂äÂ§öÂú∞‰æùËµñ‰∫éÂ∞ÜËØ≠Ë®ÄÊåá‰ª§Êò†Â∞ÑÂà∞Âä®‰Ωú(L2A)ÁöÑÂ§ßËßÑÊ®°Ê®°Âûã„ÄÇÁÑ∂ËÄåÔºåËøôÁßçÂçïÂêëËåÉÂºè‰∫ßÁîüÁöÑÁ≠ñÁï•ÈÄöÂ∏∏Âú®Ê≤°ÊúâÊõ¥Ê∑±Â±ÇÊ¨°ÁöÑ‰∏ä‰∏ãÊñáÁêÜËß£ÁöÑÊÉÖÂÜµ‰∏ãÊâßË°å‰ªªÂä°ÔºåÈôêÂà∂‰∫ÜÂÆÉ‰ª¨ÁöÑÊ≥õÂåñÊàñËß£ÈáäÂÖ∂Ë°å‰∏∫ÁöÑËÉΩÂäõ„ÄÇÊàë‰ª¨ËÆ§‰∏∫ÔºåÂ∞ÜÂä®‰ΩúÊò†Â∞ÑÂõûËØ≠Ë®Ä(A2L)ÁöÑ‰∫íË°•ÊäÄËÉΩÂØπ‰∫éÂºÄÂèëÊõ¥ÂÖ®Èù¢ÁöÑÂü∫Á°ÄËá≥ÂÖ≥ÈáçË¶Å„ÄÇ‰∏Ä‰∏™Êó¢ËÉΩË°åÂä®ÂèàËÉΩËß£ÈáäÂÖ∂Ë°åÂä®ÁöÑÊô∫ËÉΩ‰ΩìÂèØ‰ª•ÂΩ¢ÊàêÊõ¥‰∏∞ÂØåÁöÑÂÜÖÈÉ®Ë°®ÂæÅÔºåÂπ∂‰∏∫Ëá™ÁõëÁù£Â≠¶‰π†Ëß£ÈîÅÊñ∞ÁöÑËåÉÂºè„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫ÜLACY(ËØ≠Ë®Ä-Âä®‰ΩúÂæ™ÁéØ)ÔºåËøôÊòØ‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂ÔºåÂèØ‰ª•Âú®Âçï‰∏™ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã‰∏≠Â≠¶‰π†ËøôÁßçÂèåÂêëÊò†Â∞Ñ„ÄÇLACYÂú®‰∏â‰∏™ÂçèÂêå‰ªªÂä°‰∏äËøõË°åËÅîÂêàËÆ≠ÁªÉÔºö‰ªéËØ≠Ë®ÄÁîüÊàêÂèÇÊï∞ÂåñÂä®‰Ωú(L2A)ÔºåÁî®ËØ≠Ë®ÄËß£ÈáäËßÇÂØüÂà∞ÁöÑÂä®‰Ωú(A2L)Ôºå‰ª•ÂèäÈ™åËØÅ‰∏§‰∏™ËØ≠Ë®ÄÊèèËø∞‰πãÈó¥ÁöÑËØ≠‰πâ‰∏ÄËá¥ÊÄß(L2C)„ÄÇËøô‰ΩøÂæó‰∏Ä‰∏™Ëá™ÊàëÊîπËøõÁöÑÂæ™ÁéØËÉΩÂ§üÈÄöËøá‰∏ªÂä®Â¢ûÂº∫Á≠ñÁï•Ëá™‰∏ªÁîüÊàêÂíåËøáÊª§Êñ∞ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºå‰ªéËÄåÂú®Ê≤°ÊúâÈ¢ùÂ§ñ‰∫∫Â∑•Ê†áÁ≠æÁöÑÊÉÖÂÜµ‰∏ãÊîπËøõÊ®°Âûã„ÄÇÂú®Ê®°ÊãüÂíåÁúüÂÆû‰∏ñÁïå‰∏≠ÁöÑÊäìÂèñÊîæÁΩÆ‰ªªÂä°‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåLACYÂπ≥ÂùáÊèêÈ´ò‰∫Ü56.46%ÁöÑ‰ªªÂä°ÊàêÂäüÁéáÔºåÂπ∂‰∏∫Êú∫Âô®‰∫∫Êìç‰Ωú‰∫ßÁîü‰∫ÜÊõ¥Âº∫Â§ßÁöÑËØ≠Ë®Ä-Âä®‰ΩúÂü∫Á°Ä„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éËØ≠Ë®ÄÂà∞Âä®‰Ωú(L2A)ÁöÑÊú∫Âô®‰∫∫Êìç‰ΩúÊñπÊ≥ïÔºåÈÄöÂ∏∏Áº∫‰πèÂØπ‰ªªÂä°‰∏ä‰∏ãÊñáÁöÑÊ∑±ÂÖ•ÁêÜËß£ÔºåÂØºËá¥Ê≥õÂåñËÉΩÂäõ‰∏çË∂≥ÔºåÂπ∂‰∏îÈöæ‰ª•Ëß£ÈáäÂÖ∂Ë°å‰∏∫„ÄÇËøôÁßçÂçïÂêëÊò†Â∞ÑÂøΩÁï•‰∫ÜÂä®‰ΩúÂà∞ËØ≠Ë®Ä(A2L)ÁöÑÂèçÈ¶àÔºåÈôêÂà∂‰∫ÜÊô∫ËÉΩ‰ΩìÂΩ¢ÊàêÊõ¥‰∏∞ÂØåÁöÑÂÜÖÈÉ®Ë°®ÂæÅ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöLACYÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™Áªü‰∏ÄÁöÑËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºåÂêåÊó∂Â≠¶‰π†ËØ≠Ë®ÄÂà∞Âä®‰Ωú(L2A)ÂíåÂä®‰ΩúÂà∞ËØ≠Ë®Ä(A2L)ÁöÑÂèåÂêëÊò†Â∞Ñ„ÄÇÈÄöËøáËøôÁßçÂèåÂêëÂæ™ÁéØÔºåÊô∫ËÉΩ‰ΩìÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£‰ªªÂä°‰∏ä‰∏ãÊñáÔºåÂπ∂ÊèêÈ´òÊ≥õÂåñËÉΩÂäõÂíåÂèØËß£ÈáäÊÄß„ÄÇÊ≠§Â§ñÔºåLACYËøòÂºïÂÖ•‰∫ÜËØ≠Ë®Ä‰∏ÄËá¥ÊÄßÈ™åËØÅ(L2C)‰ªªÂä°ÔºåËøõ‰∏ÄÊ≠•Â¢ûÂº∫‰∫ÜÊ®°ÂûãÁöÑËØ≠‰πâÁêÜËß£ËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöLACYÁöÑÊäÄÊúØÊ°ÜÊû∂ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöËØ≠Ë®ÄÂà∞Âä®‰Ωú(L2A)Ê®°Âùó„ÄÅÂä®‰ΩúÂà∞ËØ≠Ë®Ä(A2L)Ê®°ÂùóÂíåËØ≠Ë®Ä‰∏ÄËá¥ÊÄßÈ™åËØÅ(L2C)Ê®°Âùó„ÄÇL2AÊ®°ÂùóË¥üË¥£Ê†πÊçÆËØ≠Ë®ÄÊåá‰ª§ÁîüÊàêÂèÇÊï∞ÂåñÁöÑÂä®‰ΩúÂ∫èÂàó„ÄÇA2LÊ®°ÂùóË¥üË¥£Ê†πÊçÆËßÇÂØüÂà∞ÁöÑÂä®‰ΩúÂ∫èÂàóÁîüÊàêËØ≠Ë®ÄÊèèËø∞„ÄÇL2CÊ®°ÂùóË¥üË¥£È™åËØÅ‰∏§‰∏™ËØ≠Ë®ÄÊèèËø∞‰πãÈó¥ÁöÑËØ≠‰πâ‰∏ÄËá¥ÊÄß„ÄÇËøô‰∏â‰∏™Ê®°ÂùóÂú®‰∏Ä‰∏™Áªü‰∏ÄÁöÑËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã‰∏≠ËøõË°åËÅîÂêàËÆ≠ÁªÉÔºåÂΩ¢Êàê‰∏Ä‰∏™ËØ≠Ë®Ä-Âä®‰ΩúÂæ™ÁéØ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöLACYÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂÖ∂ÂèåÂêëËØ≠Ë®Ä-Âä®‰ΩúÂæ™ÁéØÁöÑÂ≠¶‰π†ËåÉÂºè„ÄÇ‰∏é‰º†ÁªüÁöÑÂçïÂêëL2AÊñπÊ≥ïÁõ∏ÊØîÔºåLACYÈÄöËøáÂºïÂÖ•A2LÂíåL2C‰ªªÂä°ÔºåÂ¢ûÂº∫‰∫ÜÊ®°ÂûãÁöÑ‰∏ä‰∏ãÊñáÁêÜËß£ËÉΩÂäõÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåLACYËøòÊèêÂá∫‰∫Ü‰∏ÄÁßç‰∏ªÂä®Â¢ûÂº∫Á≠ñÁï•ÔºåÈÄöËøáËá™‰∏ªÁîüÊàêÂíåËøáÊª§Êñ∞ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºåÂÆûÁé∞‰∫ÜÊ®°ÂûãÁöÑËá™ÊèêÂçáÔºåÊó†ÈúÄÈ¢ùÂ§ñÁöÑ‰∫∫Â∑•Ê†áÊ≥®„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöLACYÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®TransformerÊû∂ÊûÑ‰Ωú‰∏∫ËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÁöÑÂü∫Á°ÄÔºå‰ª•ÂÆûÁé∞Êõ¥Â•ΩÁöÑÂ§öÊ®°ÊÄÅËûçÂêàÔºõ2) ËÆæËÆ°‰∫ÜÂèÇÊï∞ÂåñÁöÑÂä®‰ΩúË°®Á§∫Ôºå‰ª•‰æøL2AÊ®°ÂùóÁîüÊàêÂèØÊâßË°åÁöÑÂä®‰ΩúÂ∫èÂàóÔºõ3) ÈááÁî®‰∫ÜÂØπÊØîÂ≠¶‰π†ÊçüÂ§±ÂáΩÊï∞Êù•ËÆ≠ÁªÉA2LÊ®°ÂùóÔºå‰ª•ÊèêÈ´òËØ≠Ë®ÄÊèèËø∞ÁöÑÂáÜÁ°ÆÊÄßÔºõ4) ‰ΩøÁî®‰∫ÜÂü∫‰∫éÁΩÆ‰ø°Â∫¶ÁöÑËøáÊª§Á≠ñÁï•Êù•ÈÄâÊã©È´òË¥®ÈáèÁöÑËá™ÁîüÊàêËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

LACYÂú®Ê®°ÊãüÂíåÁúüÂÆû‰∏ñÁïåÁöÑÊäìÂèñÊîæÁΩÆ‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂú®Ê®°ÊãüÁéØÂ¢É‰∏≠ÔºåLACYÁöÑ‰ªªÂä°ÊàêÂäüÁéáÂπ≥ÂùáÊèêÈ´ò‰∫Ü56.46%„ÄÇÂú®ÁúüÂÆû‰∏ñÁïåÁéØÂ¢É‰∏≠ÔºåLACY‰πüË°®Áé∞Âá∫‰ºò‰∫éÂü∫Á∫øÊñπÊ≥ïÁöÑÊÄßËÉΩ„ÄÇËøô‰∫õÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåLACYÊ°ÜÊû∂ËÉΩÂ§üÊúâÊïàÂú∞ÊèêÈ´òÊú∫Âô®‰∫∫Êìç‰ΩúÁöÑÊ≥õÂåñËÉΩÂäõÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

LACYÊ°ÜÊû∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÂ∫îÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°Ôºå‰æãÂ¶ÇÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öËá™Âä®ÂåñÊú∫Âô®‰∫∫ÂíåÂåªÁñóÊú∫Âô®‰∫∫Á≠â„ÄÇÈÄöËøáÊèêÈ´òÊú∫Âô®‰∫∫ÁöÑÊ≥õÂåñËÉΩÂäõÂíåÂèØËß£ÈáäÊÄßÔºåLACYÂèØ‰ª•‰ΩøÊú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂ§çÊùÇÂíåÂä®ÊÄÅÁöÑÁéØÂ¢ÉÔºåÂπ∂‰∏é‰∫∫Á±ªËøõË°åÊõ¥Ëá™ÁÑ∂ÁöÑ‰∫§‰∫í„ÄÇÊ≠§Â§ñÔºåLACYÁöÑËá™ÊèêÂçáËÉΩÂäõÂèØ‰ª•Èôç‰ΩéÂØπ‰∫∫Â∑•Ê†áÊ≥®Êï∞ÊçÆÁöÑ‰æùËµñÔºå‰ªéËÄåÂä†ÈÄüÊú∫Âô®‰∫∫ÊäÄÊúØÁöÑÊôÆÂèä„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Learning generalizable policies for robotic manipulation increasingly relies on large-scale models that map language instructions to actions (L2A). However, this one-way paradigm often produces policies that execute tasks without deeper contextual understanding, limiting their ability to generalize or explain their behavior. We argue that the complementary skill of mapping actions back to language (A2L) is essential for developing more holistic grounding. An agent capable of both acting and explaining its actions can form richer internal representations and unlock new paradigms for self-supervised learning. We introduce LACY (Language-Action Cycle), a unified framework that learns such bidirectional mappings within a single vision-language model. LACY is jointly trained on three synergistic tasks: generating parameterized actions from language (L2A), explaining observed actions in language (A2L), and verifying semantic consistency between two language descriptions (L2C). This enables a self-improving cycle that autonomously generates and filters new training data through an active augmentation strategy targeting low-confidence cases, thereby improving the model without additional human labels. Experiments on pick-and-place tasks in both simulation and the real world show that LACY improves task success rates by 56.46% on average and yields more robust language-action grounding for robotic manipulation. Project page: https://vla2026.github.io/LACY/

