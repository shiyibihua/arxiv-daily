---
layout: default
title: Physically-based Lighting Generation for Robotic Manipulation
---

# Physically-based Lighting Generation for Robotic Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.01442" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.01442v2</a>
  <a href="https://arxiv.org/pdf/2508.01442.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.01442v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.01442v2', 'Physically-based Lighting Generation for Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shutong Jin, Lezhong Wang, Ben Temming, Florian T. Pokorny

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-02 (æ›´æ–°: 2025-09-17)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºç‰©ç†çš„é€†æ¸²æŸ“æ¡†æ¶ä»¥ç”Ÿæˆæœºå™¨äººæ“ä½œçš„æ–°ç…§æ˜æ•ˆæœ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `é€†æ¸²æŸ“` `æœºå™¨äººæ“ä½œ` `æ¨¡ä»¿å­¦ä¹ ` `å…‰ç…§ç”Ÿæˆ` `ç‰©ç†åŸºç¡€` `è§†é¢‘æ‰©æ•£` `è§†è§‰è´¨é‡` `ä¸‹æ¸¸åº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ç¼ºä¹æœ‰æ•ˆçš„ç…§æ˜ç”ŸæˆæŠ€æœ¯ï¼Œå¯¼è‡´æ¨¡ä»¿å­¦ä¹ æ€§èƒ½å—é™ã€‚
2. æœ¬æ–‡æå‡ºçš„æ¡†æ¶é€šè¿‡åŸºäºç‰©ç†çš„é€†æ¸²æŸ“æŠ€æœ¯ï¼Œæå–å‡ ä½•å’Œææ–™å±æ€§ä»¥ç”Ÿæˆæ–°ç…§æ˜æ•ˆæœã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç”Ÿæˆåºåˆ—çš„è§†è§‰è´¨é‡æ˜¾è‘—æå‡ï¼Œæ¨¡ä»¿å­¦ä¹ ç­–ç•¥æ€§èƒ½æé«˜äº†38.75%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ç¬¬ä¸€ä¸ªåˆ©ç”¨åŸºäºç‰©ç†çš„é€†æ¸²æŸ“æŠ€æœ¯ç”Ÿæˆæ–°ç…§æ˜æ•ˆæœçš„æ¡†æ¶ï¼Œåº”ç”¨äºç°æœ‰çœŸå®ä¸–ç•Œçš„äººç±»ç¤ºèŒƒçš„æœºå™¨äººæ“ä½œä»»åŠ¡ã€‚å…·ä½“è€Œè¨€ï¼Œé€†æ¸²æŸ“å°†æ¯ä¸ªç¤ºèŒƒçš„ç¬¬ä¸€å¸§åˆ†è§£ä¸ºå‡ ä½•ï¼ˆè¡¨é¢æ³•çº¿ã€æ·±åº¦ï¼‰å’Œææ–™ï¼ˆåç…§ç‡ã€ç²—ç³™åº¦ã€é‡‘å±åº¦ï¼‰å±æ€§ï¼Œè¿™äº›å±æ€§ç”¨äºåœ¨ä¸åŒå…‰æºä¸‹æ¸²æŸ“å¤–è§‚å˜åŒ–ã€‚ä¸ºäº†æé«˜æ•ˆç‡å¹¶ä¿æŒç”Ÿæˆåºåˆ—çš„ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬å¯¹æœºå™¨äººæ‰§è¡Œè§†é¢‘è¿›è¡Œäº†Stable Video Diffusionçš„å¾®è°ƒï¼Œä»¥å®ç°æ—¶é—´ä¸Šçš„å…‰ç…§ä¼ æ’­ã€‚é€šè¿‡è¯„ä¼°ç”Ÿæˆåºåˆ—çš„è§†è§‰è´¨é‡å’Œåœ¨å…­ç§æœªè§çœŸå®ä¸–ç•Œå…‰ç…§æ¡ä»¶ä¸‹æé«˜æ¨¡ä»¿å­¦ä¹ ç­–ç•¥æ€§èƒ½ï¼ˆ38.75%ï¼‰ï¼Œæˆ‘ä»¬éªŒè¯äº†æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å¯¹å„æ¨¡å—è¿›è¡Œäº†æ¶ˆèç ”ç©¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¯¥æ¡†æ¶æ”¯æŒçš„ä¸‰ç§ä¸‹æ¸¸åº”ç”¨ï¼šèƒŒæ™¯ç”Ÿæˆã€ç‰©ä½“çº¹ç†ç”Ÿæˆå’Œå¹²æ‰°ç‰©å®šä½ã€‚è¯¥æ¡†æ¶çš„ä»£ç å°†å…¬å¼€å‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ç…§æ˜ç”Ÿæˆä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆåº”å¯¹ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹çš„æ“ä½œè¡¨ç°ï¼Œå½±å“æ¨¡ä»¿å­¦ä¹ çš„æ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åŸºäºç‰©ç†çš„é€†æ¸²æŸ“æŠ€æœ¯ï¼Œå°†äººç±»ç¤ºèŒƒä¸­çš„ç¬¬ä¸€å¸§åˆ†è§£ä¸ºå‡ ä½•å’Œææ–™å±æ€§ï¼Œä»è€Œåœ¨ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹ç”ŸæˆçœŸå®æ„Ÿçš„è§†è§‰æ•ˆæœã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿæ›´å¥½åœ°æ¨¡æ‹ŸçœŸå®ç¯å¢ƒä¸­çš„å…‰ç…§å˜åŒ–ï¼Œæé«˜æœºå™¨äººåœ¨å¤šæ ·åŒ–ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬é€†æ¸²æŸ“æ¨¡å—ã€Stable Video Diffusionå¾®è°ƒæ¨¡å—å’Œç”Ÿæˆåºåˆ—è¯„ä¼°æ¨¡å—ã€‚é€†æ¸²æŸ“æ¨¡å—è´Ÿè´£æå–å‡ ä½•å’Œææ–™å±æ€§ï¼Œå¾®è°ƒæ¨¡å—ç”¨äºä¼˜åŒ–æ—¶é—´ä¸Šçš„å…‰ç…§ä¼ æ’­ï¼Œè€Œè¯„ä¼°æ¨¡å—åˆ™ç”¨äºæµ‹é‡ç”Ÿæˆåºåˆ—çš„è§†è§‰è´¨é‡å’Œæ¨¡ä»¿å­¦ä¹ æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†é€†æ¸²æŸ“ä¸Stable Video Diffusionç»“åˆï¼Œé¦–æ¬¡å®ç°äº†åœ¨çœŸå®äººç±»ç¤ºèŒƒä¸­ç”Ÿæˆæ–°ç…§æ˜æ•ˆæœçš„èƒ½åŠ›ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ç…§æ˜ç”ŸæˆæŠ€æœ¯ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°åæ˜ çœŸå®ç¯å¢ƒä¸­çš„å…‰ç…§å˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œè®ºæ–‡å¯¹é€†æ¸²æŸ“è¿‡ç¨‹ä¸­çš„å‚æ•°è®¾ç½®è¿›è¡Œäº†ä¼˜åŒ–ï¼Œç¡®ä¿å‡ ä½•å’Œææ–™å±æ€§çš„å‡†ç¡®æå–ã€‚åŒæ—¶ï¼ŒStable Video Diffusionçš„æŸå¤±å‡½æ•°è®¾è®¡ä¹Ÿç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥æé«˜ç”Ÿæˆåºåˆ—çš„æ—¶é—´ä¸€è‡´æ€§å’Œè§†è§‰è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç”Ÿæˆåºåˆ—çš„è§†è§‰è´¨é‡æ˜¾è‘—æé«˜ï¼Œæ¨¡ä»¿å­¦ä¹ ç­–ç•¥åœ¨å…­ç§æœªè§çš„çœŸå®ä¸–ç•Œå…‰ç…§æ¡ä»¶ä¸‹æ€§èƒ½æå‡äº†38.75%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ¡†æ¶åœ¨ç…§æ˜ç”Ÿæˆå’Œæœºå™¨äººæ“ä½œä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ“ä½œã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰åœºæ™¯ã€‚é€šè¿‡ç”ŸæˆçœŸå®æ„Ÿçš„ç…§æ˜æ•ˆæœï¼Œèƒ½å¤Ÿæå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œèƒ½åŠ›ï¼Œå¢å¼ºç”¨æˆ·åœ¨è™šæ‹Ÿç¯å¢ƒä¸­çš„æ²‰æµ¸æ„Ÿï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this paper, we propose the first framework that leverages physically-based inverse rendering for novel lighting generation on existing real-world human demonstrations of robotic manipulation tasks. Specifically, inverse rendering decomposes the first frame in each demonstration into geometric (surface normal, depth) and material (albedo, roughness, metallic) properties, which are then used to render appearance changes under different lighting sources. To improve efficiency and maintain consistency across each generated sequence, we fine-tune Stable Video Diffusion on robot execution videos for temporal lighting propagation. We evaluate our framework by measuring the visual quality of the generated sequences, assessing its effectiveness in improving the imitation learning policy performance (38.75\%) under six unseen real-world lighting conditions, and conduct ablation studies on individual modules of the proposed framework. We further showcase three downstream applications enabled by the proposed framework: background generation, object texture generation and distractor positioning. The code for the framework will be made publicly available.

