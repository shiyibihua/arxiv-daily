---
layout: default
title: VLH: Vision-Language-Haptics Foundation Model
---

# VLH: Vision-Language-Haptics Foundation Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.01361" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.01361v1</a>
  <a href="https://arxiv.org/pdf/2508.01361.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.01361v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.01361v1', 'VLH: Vision-Language-Haptics Foundation Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Luis Francisco Moreno Fuentes, Muhammad Haris Khan, Miguel Altamirano Cabrera, Valerii Serpiva, Dmitri Iarchuk, Yara Mahmoud, Issatay Tokmurziyev, Dzmitry Tsetserukou

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-02

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVLHæ¨¡å‹ä»¥å®ç°è§†è§‰ã€è¯­è¨€ä¸è§¦è§‰çš„ç»Ÿä¸€äº¤äº’**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-è§¦è§‰` `äººæœºäº¤äº’` `å¤šæ¨¡æ€èåˆ` `ç©ºä¸­æœºå™¨äºº` `è™šæ‹Ÿç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é€šå¸¸å°†è§¦è§‰åé¦ˆè§†ä¸ºæ¬¡è¦é€šé“ï¼Œæœªèƒ½æœ‰æ•ˆæ•´åˆè§†è§‰å’Œè¯­è¨€ä¿¡æ¯ï¼Œå¯¼è‡´äººæœºäº¤äº’çš„å±€é™æ€§ã€‚
2. VLHæ¨¡å‹é€šè¿‡å°†è§†è§‰ç†è§£ä¸è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç›¸ç»“åˆï¼Œç›´æ¥ç”Ÿæˆè§¦è§‰åé¦ˆï¼Œæå‡äº†äººæœºäº¤äº’çš„æ²‰æµ¸æ„Ÿå’Œè¡¨è¾¾èƒ½åŠ›ã€‚
3. åœ¨90æ¬¡äººæœºäº¤äº’å®éªŒä¸­ï¼ŒVLHå®ç°äº†56.7%çš„ç›®æ ‡è·å–æˆåŠŸç‡å’Œ100%çš„çº¹ç†è¾¨åˆ«å‡†ç¡®ç‡ï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†VLHï¼Œä¸€ä¸ªæ–°é¢–çš„è§†è§‰-è¯­è¨€-è§¦è§‰åŸºç¡€æ¨¡å‹ï¼Œæ—¨åœ¨ç»Ÿä¸€ç©ºä¸­æœºå™¨äººå’Œè™šæ‹Ÿç°å®ä¸­çš„æ„ŸçŸ¥ã€è¯­è¨€å’Œè§¦è§‰åé¦ˆã€‚ä¸ä»¥å¾€å°†è§¦è§‰è§†ä¸ºæ¬¡è¦ååº”é€šé“çš„ç ”ç©¶ä¸åŒï¼ŒVLHå°†ç©ºä¸­åŠ›å’ŒæŒ¯åŠ¨çº¿ç´¢ä½œä¸ºä¸Šä¸‹æ–‡è§†è§‰ç†è§£å’Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤çš„ç›´æ¥ç»“æœè¿›è¡Œåˆæˆã€‚è¯¥å¹³å°ç”±ä¸€æ¶é…å¤‡åŒé€†äº”æ†è¿æ†é˜µåˆ—çš„8è‹±å¯¸å››æ—‹ç¿¼æ— äººæœºã€ä¸€ä¸ªè‡ªæˆ‘ä¸­å¿ƒçš„è™šæ‹Ÿç°å®æ‘„åƒå¤´å’Œä¸€ä¸ªå¤–éƒ¨ä¿¯è§†è§†è§’ç»„æˆã€‚é€šè¿‡å¯¹450ä¸ªå¤šæ¨¡æ€åœºæ™¯çš„å®šåˆ¶æ•°æ®é›†è¿›è¡ŒLoRAé€‚é…ï¼Œä½¿ç”¨å¾®è°ƒçš„OpenVLAéª¨å¹²ç½‘ç»œå¤„ç†è§†è§‰è¾“å…¥å’Œè¯­è¨€æŒ‡ä»¤ï¼Œè¾“å‡º7ç»´åŠ¨ä½œå‘é‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVLHåœ¨ç›®æ ‡è·å–ä¸­å–å¾—äº†56.7%çš„æˆåŠŸç‡ï¼Œå¹¶åœ¨çº¹ç†è¾¨åˆ«ä¸­è¾¾åˆ°äº†100%çš„å‡†ç¡®ç‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å¢å¼ºäººæœºäº¤äº’ä¸­çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰ç©ºä¸­æœºå™¨äººå’Œè™šæ‹Ÿç°å®ä¸­è§¦è§‰åé¦ˆä¸è§†è§‰ã€è¯­è¨€ä¿¡æ¯æ•´åˆä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€å°†è§¦è§‰è§†ä¸ºæ¬¡è¦ååº”é€šé“ï¼Œé™åˆ¶äº†äººæœºäº¤äº’çš„è¡¨ç°åŠ›å’Œæ²‰æµ¸æ„Ÿã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVLHæ¨¡å‹çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†è§†è§‰ç†è§£ä¸è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç»“åˆï¼Œé€šè¿‡åˆæˆä¸Šä¸‹æ–‡ç›¸å…³çš„è§¦è§‰åé¦ˆï¼Œæå‡äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæœ‰æ•ˆæ€§ã€‚è¯¥è®¾è®¡ä½¿å¾—è§¦è§‰åé¦ˆä¸ä»…æ˜¯ååº”ï¼Œè€Œæ˜¯ä¸»åŠ¨ç”Ÿæˆçš„ç»“æœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVLHçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ª8è‹±å¯¸çš„å››æ—‹ç¿¼æ— äººæœºï¼Œé…å¤‡åŒé€†äº”æ†è¿æ†é˜µåˆ—ç”¨äºå±€éƒ¨è§¦è§‰æ¿€åŠ±ï¼Œä¸€ä¸ªè‡ªæˆ‘ä¸­å¿ƒçš„è™šæ‹Ÿç°å®æ‘„åƒå¤´ï¼Œä»¥åŠä¸€ä¸ªå¤–éƒ¨ä¿¯è§†è§†è§’ã€‚è§†è§‰è¾“å…¥å’Œè¯­è¨€æŒ‡ä»¤é€šè¿‡å¾®è°ƒçš„OpenVLAéª¨å¹²ç½‘ç»œå¤„ç†ï¼Œè¾“å‡º7ç»´åŠ¨ä½œå‘é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šVLHçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†è§¦è§‰åé¦ˆä¸è§†è§‰å’Œè¯­è¨€ä¿¡æ¯çš„ç†è§£ç´§å¯†ç»“åˆï¼Œå½¢æˆä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿã€‚è¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿæ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºè§¦è§‰åé¦ˆçš„ä¸»åŠ¨ç”Ÿæˆï¼Œè€Œéè¢«åŠ¨ååº”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œä½¿ç”¨LoRAå¯¹å®šåˆ¶æ•°æ®é›†è¿›è¡Œé€‚é…ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿå¤„ç†450ä¸ªå¤šæ¨¡æ€åœºæ™¯ã€‚é€šè¿‡INT8é‡åŒ–å’Œé«˜æ€§èƒ½æœåŠ¡å™¨ï¼Œç¡®ä¿æ¨¡å‹åœ¨4-5 Hzçš„å®æ—¶æ“ä½œèƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨90æ¬¡äººæœºäº¤äº’å®éªŒä¸­ï¼ŒVLHæ¨¡å‹å®ç°äº†56.7%çš„ç›®æ ‡è·å–æˆåŠŸç‡ï¼Œå¹³å‡åˆ°è¾¾æ—¶é—´ä¸º21.3ç§’ï¼Œå§¿æ€è¯¯å·®ä¸º0.24ç±³ã€‚åŒæ—¶ï¼Œåœ¨çº¹ç†è¾¨åˆ«ä»»åŠ¡ä¸­ï¼Œæ¨¡å‹è¾¾åˆ°äº†100%çš„å‡†ç¡®ç‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­çš„å¼ºå¤§èƒ½åŠ›å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VLHæ¨¡å‹åœ¨ç©ºä¸­æœºå™¨äººå’Œè™šæ‹Ÿç°å®é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å®ƒå¯ä»¥ç”¨äºå¢å¼ºç°å®ã€è¿œç¨‹æ“æ§ã€æ•™è‚²åŸ¹è®­ç­‰åœºæ™¯ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œäº¤äº’è´¨é‡ã€‚æœªæ¥ï¼Œè¯¥æ¨¡å‹çš„æŠ€æœ¯å¯ä»¥æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸï¼Œå¦‚åŒ»ç–—ã€å¨±ä¹å’Œæ™ºèƒ½å®¶å±…ç­‰ï¼Œæ¨åŠ¨äººæœºäº¤äº’çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present VLH, a novel Visual-Language-Haptic Foundation Model that unifies perception, language, and tactile feedback in aerial robotics and virtual reality. Unlike prior work that treats haptics as a secondary, reactive channel, VLH synthesizes mid-air force and vibration cues as a direct consequence of contextual visual understanding and natural language commands. Our platform comprises an 8-inch quadcopter equipped with dual inverse five-bar linkage arrays for localized haptic actuation, an egocentric VR camera, and an exocentric top-down view. Visual inputs and language instructions are processed by a fine-tuned OpenVLA backbone - adapted via LoRA on a bespoke dataset of 450 multimodal scenarios - to output a 7-dimensional action vector (Vx, Vy, Vz, Hx, Hy, Hz, Hv). INT8 quantization and a high-performance server ensure real-time operation at 4-5 Hz. In human-robot interaction experiments (90 flights), VLH achieved a 56.7% success rate for target acquisition (mean reach time 21.3 s, pose error 0.24 m) and 100% accuracy in texture discrimination. Generalization tests yielded 70.0% (visual), 54.4% (motion), 40.0% (physical), and 35.0% (semantic) performance on novel tasks. These results demonstrate VLH's ability to co-evolve haptic feedback with perceptual reasoning and intent, advancing expressive, immersive human-robot interactions.

