---
layout: default
title: Decentralized Aerial Manipulation of a Cable-Suspended Load using Multi-Agent Reinforcement Learning
---

# Decentralized Aerial Manipulation of a Cable-Suspended Load using Multi-Agent Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.01522" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.01522v3</a>
  <a href="https://arxiv.org/pdf/2508.01522.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.01522v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.01522v3', 'Decentralized Aerial Manipulation of a Cable-Suspended Load using Multi-Agent Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jack Zeng, Andreu Matoses Gimenez, Eugene Vinitsky, Javier Alonso-Mora, Sihao Sun

**åˆ†ç±»**: cs.RO, cs.AI, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-08-02 (æ›´æ–°: 2025-11-05)

**æœŸåˆŠ**: Proceedings of the 9th Conference on Robot Learning, PMLR 305:3850-3868, 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå»ä¸­å¿ƒåŒ–æ–¹æ³•ä»¥å®ç°å¤šæ— äººæœºå¯¹åŠè½½çš„6è‡ªç”±åº¦æ“æ§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ` `å»ä¸­å¿ƒåŒ–æ§åˆ¶` `å¾®å‹æ— äººæœº` `åŠè½½æ“æ§` `ä»¿çœŸåˆ°ç°å®è½¬ç§»` `åŠ¨æ€ç¯å¢ƒ` `åä½œèƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é›†ä¸­å¼æ§åˆ¶æ–¹æ³•åœ¨å¤šæ— äººæœºåä½œæ“æ§ä¸­é¢ä¸´é€šä¿¡éœ€æ±‚é«˜å’Œè®¡ç®—æˆæœ¬å¤§çš„æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºçš„å»ä¸­å¿ƒåŒ–MARLæ–¹æ³•å…è®¸æ— äººæœºé€šè¿‡è½½è·å§¿æ€è§‚å¯Ÿè¿›è¡Œéšå¼é€šä¿¡ï¼Œæå‡äº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œçµæ´»æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è´Ÿè½½æ¨¡å‹ä¸ç¡®å®šæ€§ä¸‹çš„å…¨å§¿æ€æ§åˆ¶æ€§èƒ½ä¸é›†ä¸­å¼æ–¹æ³•ç›¸å½“ï¼Œå¹¶å±•ç¤ºäº†å¯¹å•ä¸ªæ— äººæœºå¤±æ•ˆçš„é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§é¦–ä¸ªå»ä¸­å¿ƒåŒ–çš„æ–¹æ³•ï¼Œåˆ©ç”¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰å®ç°å¾®å‹æ— äººæœºï¼ˆMAVsï¼‰å¯¹åŠè½½çš„6è‡ªç”±åº¦æ“æ§ã€‚ä¸ç°æœ‰çš„é›†ä¸­å¼æ§åˆ¶å™¨ä¸åŒï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦å…¨å±€çŠ¶æ€ã€æ— äººæœºé—´çš„é€šä¿¡æˆ–é‚»è¿‘æ— äººæœºçš„ä¿¡æ¯ã€‚ç›¸åï¼Œæ™ºèƒ½ä½“ä»…é€šè¿‡è½½è·å§¿æ€è§‚å¯Ÿè¿›è¡Œéšå¼é€šä¿¡ï¼Œä»è€Œå®ç°é«˜å¯æ‰©å±•æ€§å’Œçµæ´»æ€§ï¼Œå¹¶æ˜¾è‘—é™ä½æ¨ç†æ—¶çš„è®¡ç®—æˆæœ¬ï¼Œæ”¯æŒæ”¿ç­–çš„æœºè½½éƒ¨ç½²ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è®¾è®¡äº†ä¸€ç§æ–°çš„åŠ¨ä½œç©ºé—´ï¼Œé‡‡ç”¨çº¿æ€§åŠ é€Ÿåº¦å’Œæœºä½“é€Ÿç‡çš„ç»„åˆï¼Œç»“åˆç¨³å¥çš„ä½çº§æ§åˆ¶å™¨ï¼Œç¡®ä¿åœ¨åŠ¨æ€ä¸‰ç»´è¿åŠ¨ä¸­å°½ç®¡å­˜åœ¨ç”±äºç¼†ç»³å¼ åŠ›å¼•èµ·çš„æ˜¾è‘—ä¸ç¡®å®šæ€§ï¼Œä»èƒ½å¯é åœ°å®ç°ä»¿çœŸåˆ°ç°å®çš„è½¬ç§»ã€‚é€šè¿‡å¤šé¡¹çœŸå®ä¸–ç•Œå®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç»“æœæ˜¾ç¤ºå…¶è®¾å®šç‚¹è·Ÿè¸ªæ€§èƒ½ä¸æœ€å…ˆè¿›çš„é›†ä¸­å¼æ–¹æ³•ç›¸å½“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ— äººæœºå¯¹åŠè½½è¿›è¡Œ6è‡ªç”±åº¦æ“æ§æ—¶ï¼Œç°æœ‰é›†ä¸­å¼æ§åˆ¶æ–¹æ³•åœ¨é€šä¿¡å’Œè®¡ç®—æˆæœ¬ä¸Šçš„ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•éœ€è¦å…¨å±€çŠ¶æ€å’Œæ— äººæœºé—´çš„å®æ—¶é€šä¿¡ï¼Œé™åˆ¶äº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§å»ä¸­å¿ƒåŒ–çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå…è®¸æ— äººæœºé€šè¿‡è½½è·å§¿æ€è§‚å¯Ÿè¿›è¡Œéšå¼é€šä¿¡ï¼Œä»è€Œæ¶ˆé™¤å¯¹å…¨å±€çŠ¶æ€å’Œé‚»è¿‘æ— äººæœºä¿¡æ¯çš„ä¾èµ–ã€‚è¿™ç§è®¾è®¡æé«˜äº†ç³»ç»Ÿçš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬å¤šä¸ªMAVsï¼Œæ¯ä¸ªMAVé€šè¿‡MARLè®­ç»ƒå¤–éƒ¨æ§åˆ¶ç­–ç•¥ã€‚ç³»ç»Ÿåˆ†ä¸ºé«˜å±‚ç­–ç•¥å’Œä½å±‚æ§åˆ¶å™¨ï¼Œå‰è€…è´Ÿè´£å†³ç­–ï¼Œåè€…ç¡®ä¿åŠ¨ä½œçš„æ‰§è¡Œã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå»ä¸­å¿ƒåŒ–çš„æ§åˆ¶ç­–ç•¥è®¾è®¡ï¼Œä½¿å¾—æ¯ä¸ªæ— äººæœºèƒ½å¤Ÿç‹¬ç«‹æ“ä½œè€Œæ— éœ€å…¨å±€ä¿¡æ¯ã€‚è¿™ä¸ä¼ ç»Ÿé›†ä¸­å¼æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œåè€…ä¾èµ–äºå…¨å±€çŠ¶æ€å’Œå®æ—¶é€šä¿¡ã€‚

**å…³é”®è®¾è®¡**ï¼šæœ¬æ–‡è®¾è®¡äº†æ–°çš„åŠ¨ä½œç©ºé—´ï¼Œé‡‡ç”¨çº¿æ€§åŠ é€Ÿåº¦å’Œæœºä½“é€Ÿç‡çš„ç»„åˆï¼Œç»“åˆç¨³å¥çš„ä½çº§æ§åˆ¶å™¨ï¼Œä»¥åº”å¯¹åŠ¨æ€ç¯å¢ƒä¸­çš„ä¸ç¡®å®šæ€§ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°å’Œè®­ç»ƒç­–ç•¥ä¹Ÿç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿åœ¨ä»¿çœŸåˆ°ç°å®çš„è½¬ç§»ä¸­ä¿æŒé«˜æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨è´Ÿè½½æ¨¡å‹ä¸ç¡®å®šæ€§ä¸‹çš„è®¾å®šç‚¹è·Ÿè¸ªæ€§èƒ½ä¸æœ€å…ˆè¿›çš„é›†ä¸­å¼æ–¹æ³•ç›¸å½“ï¼Œä¸”åœ¨å•ä¸ªæ— äººæœºå¤±æ•ˆæƒ…å†µä¸‹ä»èƒ½ä¿æŒè‰¯å¥½çš„åä½œèƒ½åŠ›ã€‚è¿™è¡¨æ˜è¯¥æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„é²æ£’æ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¾åæ•‘æ´ã€å»ºç­‘æ–½å·¥å’Œç‰©æµè¿è¾“ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å¤šæ— äººæœºç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çš„åä½œèƒ½åŠ›ã€‚æœªæ¥ï¼Œè¿™ç§å»ä¸­å¿ƒåŒ–çš„æ§åˆ¶æ–¹æ³•å¯èƒ½ä¼šåœ¨æ›´å¹¿æ³›çš„æ— äººæœºåº”ç”¨ä¸­å¾—åˆ°æ¨å¹¿ï¼Œæ¨åŠ¨æ™ºèƒ½ä½“åä½œæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents the first decentralized method to enable real-world 6-DoF manipulation of a cable-suspended load using a team of Micro-Aerial Vehicles (MAVs). Our method leverages multi-agent reinforcement learning (MARL) to train an outer-loop control policy for each MAV. Unlike state-of-the-art controllers that utilize a centralized scheme, our policy does not require global states, inter-MAV communications, nor neighboring MAV information. Instead, agents communicate implicitly through load pose observations alone, which enables high scalability and flexibility. It also significantly reduces computing costs during inference time, enabling onboard deployment of the policy. In addition, we introduce a new action space design for the MAVs using linear acceleration and body rates. This choice, combined with a robust low-level controller, enables reliable sim-to-real transfer despite significant uncertainties caused by cable tension during dynamic 3D motion. We validate our method in various real-world experiments, including full-pose control under load model uncertainties, showing setpoint tracking performance comparable to the state-of-the-art centralized method. We also demonstrate cooperation amongst agents with heterogeneous control policies, and robustness to the complete in-flight loss of one MAV. Videos of experiments: https://autonomousrobots.nl/paper_websites/aerial-manipulation-marl

