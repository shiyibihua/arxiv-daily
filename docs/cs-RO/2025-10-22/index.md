---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-10-22
---

# cs.ROï¼ˆ2025-10-22ï¼‰

ğŸ“Š å…± **11** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (5 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251019430v3-gigabrain-0-a-world-model-powered-vision-language-action-model.html">GigaBrain-0: A World Model-Powered Vision-Language-Action Model</a></td>
  <td>GigaBrain-0ï¼šåŸºäºä¸–ç•Œæ¨¡å‹èµ‹èƒ½çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œé€šç”¨æœºå™¨äººæ¨¡å‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.19430v3" onclick="toggleFavorite(this, '2510.19430v3', 'GigaBrain-0: A World Model-Powered Vision-Language-Action Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251019495v2-using-non-expert-data-to-robustify-imitation-learning-via-offline-re.html">Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning</a></td>
  <td>åˆ©ç”¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼Œé€šè¿‡éä¸“å®¶æ•°æ®å¢å¼ºæ¨¡ä»¿å­¦ä¹ çš„é²æ£’æ€§</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.19495v2" onclick="toggleFavorite(this, '2510.19495v2', 'Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251019974v1-push-anything-single-and-multi-object-pushing-from-first-sight-with-.html">Push Anything: Single- and Multi-Object Pushing From First Sight with Contact-Implicit MPC</a></td>
  <td>æå‡ºC3+ç®—æ³•ï¼Œé€šè¿‡æ¥è§¦éšå¼MPCå®ç°å¯¹å¤šç§ç‰©ä½“çš„å•/å¤šç›®æ ‡ç²¾å‡†æ¨ç§»æ“ä½œã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.19974v1" onclick="toggleFavorite(this, '2510.19974v1', 'Push Anything: Single- and Multi-Object Pushing From First Sight with Contact-Implicit MPC')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251019541v1-optimizing-prosthetic-wrist-movement-a-model-predictive-control-appr.html">Optimizing Prosthetic Wrist Movement: A Model Predictive Control Approach</a></td>
  <td>æå‡ºåŸºäºæ¨¡å‹é¢„æµ‹æ§åˆ¶çš„ä¹‰è‚¢è…•éƒ¨è¿åŠ¨ä¼˜åŒ–æ–¹æ¡ˆï¼Œæå‡çµæ´»æ€§å’Œç”¨æˆ·æ§åˆ¶ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.19541v1" onclick="toggleFavorite(this, '2510.19541v1', 'Optimizing Prosthetic Wrist Movement: A Model Predictive Control Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251019289v1-tarmac-a-taxonomy-for-robot-manipulation-in-chemistry.html">TARMAC: A Taxonomy for Robot Manipulation in Chemistry</a></td>
  <td>æå‡ºTARMACä»¥è§£å†³åŒ–å­¦å®éªŒå®¤æœºå™¨äººæ“ä½œæŠ€èƒ½ç¼ºä¹çš„é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.19289v1" onclick="toggleFavorite(this, '2510.19289v1', 'TARMAC: A Taxonomy for Robot Manipulation in Chemistry')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>6</td>
  <td><a href="./papers/251019766v2-sea-semantic-map-prediction-for-active-exploration-of-uncertain-area.html">SEA: Semantic Map Prediction for Active Exploration of Uncertain Areas</a></td>
  <td>SEAï¼šåŸºäºè¯­ä¹‰åœ°å›¾é¢„æµ‹çš„ä¸»åŠ¨æ¢ç´¢ä¸ç¡®å®šåŒºåŸŸæ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.19766v2" onclick="toggleFavorite(this, '2510.19766v2', 'SEA: Semantic Map Prediction for Active Exploration of Uncertain Areas')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251019356v1-imitation-learning-policy-based-on-multi-step-consistent-integration.html">Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model</a></td>
  <td>æå‡ºåŸºäºå¤šæ­¥ä¸€è‡´æ€§ç§¯åˆ†æ·å¾„æ¨¡å‹çš„æ¨¡ä»¿å­¦ä¹ ç­–ç•¥ï¼ŒåŠ é€Ÿæœºå™¨äººç­–ç•¥æ¨ç†ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.19356v1" onclick="toggleFavorite(this, '2510.19356v1', 'Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251019364v1-proterrain-probabilistic-physics-informed-rough-terrain-world-modeli.html">ProTerrain: Probabilistic Physics-Informed Rough Terrain World Modeling</a></td>
  <td>ProTerrainï¼šæå‡ºæ¦‚ç‡ç‰©ç†ä¿¡æ¯ç²—ç³™åœ°å½¢å»ºæ¨¡æ–¹æ³•ï¼Œæå‡æœºå™¨äººè½¨è¿¹é¢„æµ‹ç²¾åº¦ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.19364v1" onclick="toggleFavorite(this, '2510.19364v1', 'ProTerrain: Probabilistic Physics-Informed Rough Terrain World Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251019268v1-hierarchical-dlo-routing-with-reinforcement-learning-and-in-context-.html">Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models</a></td>
  <td>æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ å’Œè§†è§‰è¯­è¨€æ¨¡å‹çš„å±‚çº§DLOè·¯å¾„è§„åˆ’æ–¹æ³•</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.19268v1" onclick="toggleFavorite(this, '2510.19268v1', 'Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>10</td>
  <td><a href="./papers/251019752v1-learning-affordances-at-inference-time-for-vision-language-action-mo.html">Learning Affordances at Inference-Time for Vision-Language-Action Models</a></td>
  <td>æå‡ºLITENï¼Œé€šè¿‡æ¨ç†æ—¶å­¦ä¹ èƒ½åŠ›æå‡VLAæ¨¡å‹åœ¨å¤æ‚æœºå™¨äººä»»åŠ¡ä¸­çš„è¡¨ç°</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.19752v1" onclick="toggleFavorite(this, '2510.19752v1', 'Learning Affordances at Inference-Time for Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>11</td>
  <td><a href="./papers/251019655v1-lavira-language-vision-robot-actions-translation-for-zero-shot-visio.html">LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments</a></td>
  <td>LaViRAï¼šç”¨äºè¿ç»­ç¯å¢ƒé›¶æ ·æœ¬è§†è§‰è¯­è¨€å¯¼èˆªçš„è¯­è¨€-è§†è§‰-æœºå™¨äººåŠ¨ä½œç¿»è¯‘æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.19655v1" onclick="toggleFavorite(this, '2510.19655v1', 'LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)