---
layout: default
title: GRaD-Nav++: Vision-Language Model Enabled Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics
---

# GRaD-Nav++: Vision-Language Model Enabled Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.14009" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.14009v1</a>
  <a href="https://arxiv.org/pdf/2506.14009.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.14009v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.14009v1', 'GRaD-Nav++: Vision-Language Model Enabled Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qianzhong Chen, Naixiang Gao, Suning Huang, JunEn Low, Timothy Chen, Jiankai Sun, Mac Schwager

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGRaD-Nav++ä»¥è§£å†³æ— äººæœºè¯­è¨€æŒ‡ä»¤å¯¼èˆªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ— äººæœºå¯¼èˆª` `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `å¯å¾®å¼ºåŒ–å­¦ä¹ ` `ä¸“å®¶æ··åˆ` `å¤šä»»åŠ¡å­¦ä¹ ` `ç¯å¢ƒé€‚åº”æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¾èµ–æ‰‹å·¥æŠ€èƒ½å’Œå¤æ‚å‚æ•°è°ƒä¼˜ï¼Œéš¾ä»¥å®ç°é«˜æ•ˆçš„è‡ªä¸»æ— äººæœºå¯¼èˆªã€‚
2. GRaD-Nav++æ˜¯ä¸€ä¸ªè½»é‡çº§çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¡†æ¶ï¼Œèƒ½å¤Ÿå®æ—¶æ‰§è¡Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œè¿è¡Œäºæ— äººæœºæœºè½½ç³»ç»Ÿä¸Šã€‚
3. åœ¨å¤šä»»åŠ¡å’Œå¤šç¯å¢ƒå®éªŒä¸­ï¼ŒGRaD-Nav++åˆ†åˆ«åœ¨æ¨¡æ‹Ÿå’Œç°å®ç¯å¢ƒä¸­å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸç‡ï¼Œå±•ç¤ºäº†å…¶å¼ºå¤§çš„é€‚åº”èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªä¸»æ— äººæœºèƒ½å¤Ÿåœ¨éç»“æ„åŒ–ç¯å¢ƒä¸­ç†è§£å’Œæ‰§è¡Œé«˜å±‚è¯­è¨€æŒ‡ä»¤ä¸€ç›´æ˜¯ä¸€ä¸ªé•¿æœŸç›®æ ‡ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å—é™äºæ‰‹å·¥æŠ€èƒ½ã€å¹¿æ³›çš„å‚æ•°è°ƒä¼˜æˆ–ä¸é€‚åˆæœºè½½ä½¿ç”¨çš„è®¡ç®—å¯†é›†å‹æ¨¡å‹ã€‚æˆ‘ä»¬æå‡ºäº†GRaD-Nav++ï¼Œä¸€ä¸ªè½»é‡çº§çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¡†æ¶ï¼Œèƒ½å¤Ÿå®æ—¶æ‰§è¡Œè‡ªç„¶è¯­è¨€å‘½ä»¤ã€‚æˆ‘ä»¬çš„ç­–ç•¥åœ¨ä¸€ä¸ªå…‰ç…§çœŸå®çš„3Dé«˜æ–¯ç‚¹äº‘ï¼ˆ3DGSï¼‰æ¨¡æ‹Ÿå™¨ä¸­é€šè¿‡å¯å¾®å¼ºåŒ–å­¦ä¹ ï¼ˆDiffRLï¼‰è¿›è¡Œè®­ç»ƒï¼Œä»è§†è§‰å’Œè¯­è¨€è¾“å…¥ä¸­é«˜æ•ˆå­¦ä¹ ä½çº§æ§åˆ¶ã€‚æ ¸å¿ƒæ˜¯ä¸€ä¸ªä¸“å®¶æ··åˆï¼ˆMoEï¼‰åŠ¨ä½œå¤´ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”è·¯ç”±è®¡ç®—ä»¥æé«˜æ³›åŒ–èƒ½åŠ›å¹¶å‡è½»é—å¿˜ã€‚åœ¨å¤šä»»åŠ¡æ³›åŒ–å®éªŒä¸­ï¼ŒGRaD-Nav++åœ¨è®­ç»ƒä»»åŠ¡ä¸Šå–å¾—äº†83%çš„æˆåŠŸç‡ï¼Œåœ¨æœªè§ä»»åŠ¡ä¸Šä¸º75%ã€‚åœ¨å®é™…ç¡¬ä»¶ä¸Šéƒ¨ç½²æ—¶ï¼Œè®­ç»ƒä»»åŠ¡æˆåŠŸç‡ä¸º67%ï¼Œæœªè§ä»»åŠ¡ä¸º50%ã€‚åœ¨å¤šç¯å¢ƒé€‚åº”å®éªŒä¸­ï¼ŒGRaD-Nav++åœ¨å¤šæ ·åŒ–çš„æ¨¡æ‹Ÿç¯å¢ƒä¸­å¹³å‡æˆåŠŸç‡ä¸º81%ï¼Œåœ¨ä¸åŒçš„ç°å®ä¸–ç•Œç¯å¢ƒä¸­ä¸º67%ã€‚è¿™äº›ç»“æœä¸ºå®Œå…¨æœºè½½çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰é£è¡Œå»ºç«‹äº†æ–°çš„åŸºå‡†ï¼Œå¹¶è¯æ˜ç´§å‡‘é«˜æ•ˆçš„æ¨¡å‹èƒ½å¤Ÿå®ç°å¯é çš„è¯­è¨€å¼•å¯¼å¯¼èˆªï¼Œè€Œæ— éœ€ä¾èµ–å¤–éƒ¨åŸºç¡€è®¾æ–½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è‡ªä¸»æ— äººæœºåœ¨éç»“æ„åŒ–ç¯å¢ƒä¸­ç†è§£å’Œæ‰§è¡Œè¯­è¨€æŒ‡ä»¤çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºæ‰‹å·¥æŠ€èƒ½å’Œå¤æ‚çš„å‚æ•°è°ƒä¼˜ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œé€‚åº”æ€§å·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGRaD-Nav++é€šè¿‡å¼•å…¥è½»é‡çº§çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¡†æ¶ï¼Œç»“åˆå¯å¾®å¼ºåŒ–å­¦ä¹ ï¼Œèƒ½å¤Ÿå®æ—¶å¤„ç†è§†è§‰å’Œè¯­è¨€è¾“å…¥ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„ä½çº§æ§åˆ¶å­¦ä¹ ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªå…‰ç…§çœŸå®çš„3Dé«˜æ–¯ç‚¹äº‘æ¨¡æ‹Ÿå™¨å’Œä¸€ä¸ªä¸“å®¶æ··åˆï¼ˆMoEï¼‰åŠ¨ä½œå¤´ã€‚MoEç»“æ„èƒ½å¤Ÿæ ¹æ®ä»»åŠ¡éœ€æ±‚è‡ªé€‚åº”åœ°åˆ†é…è®¡ç®—èµ„æºï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†Mixture-of-Expertsï¼ˆMoEï¼‰æœºåˆ¶ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒä»»åŠ¡é—´æœ‰æ•ˆåˆ‡æ¢ï¼Œå‡å°‘é—å¿˜ç°è±¡ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”æ˜¾è‘—æå‡äº†é€‚åº”æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨å¯å¾®å¼ºåŒ–å­¦ä¹ ï¼ˆDiffRLï¼‰ç­–ç•¥ï¼Œç»“åˆç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„è®¾è®¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿåœ¨å¤šä»»åŠ¡å’Œå¤šç¯å¢ƒä¸­ä¿æŒé«˜æ•ˆçš„å­¦ä¹ èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä»»åŠ¡æ³›åŒ–å®éªŒä¸­ï¼ŒGRaD-Nav++åœ¨è®­ç»ƒä»»åŠ¡ä¸Šå–å¾—äº†83%çš„æˆåŠŸç‡ï¼Œåœ¨æœªè§ä»»åŠ¡ä¸Šä¸º75%ã€‚åœ¨å®é™…ç¡¬ä»¶ä¸Šï¼Œè®­ç»ƒä»»åŠ¡æˆåŠŸç‡ä¸º67%ï¼Œæœªè§ä»»åŠ¡ä¸º50%ã€‚åœ¨å¤šç¯å¢ƒé€‚åº”å®éªŒä¸­ï¼Œå¹³å‡æˆåŠŸç‡ä¸º81%ï¼Œå±•ç¤ºäº†å…¶åœ¨ä¸åŒç¯å¢ƒä¸­çš„å¼ºå¤§é€‚åº”èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ— äººæœºè‡ªåŠ¨åŒ–ã€æ™ºèƒ½ç‰©æµå’Œæœç´¢æ•‘æ´ç­‰åœºæ™¯ã€‚é€šè¿‡å®ç°è¯­è¨€å¼•å¯¼çš„è‡ªä¸»å¯¼èˆªï¼ŒGRaD-Nav++èƒ½å¤Ÿæ˜¾è‘—æé«˜æ— äººæœºåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œæ•ˆç‡ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autonomous drones capable of interpreting and executing high-level language instructions in unstructured environments remain a long-standing goal. Yet existing approaches are constrained by their dependence on hand-crafted skills, extensive parameter tuning, or computationally intensive models unsuitable for onboard use. We introduce GRaD-Nav++, a lightweight Vision-Language-Action (VLA) framework that runs fully onboard and follows natural-language commands in real time. Our policy is trained in a photorealistic 3D Gaussian Splatting (3DGS) simulator via Differentiable Reinforcement Learning (DiffRL), enabling efficient learning of low-level control from visual and linguistic inputs. At its core is a Mixture-of-Experts (MoE) action head, which adaptively routes computation to improve generalization while mitigating forgetting. In multi-task generalization experiments, GRaD-Nav++ achieves a success rate of 83% on trained tasks and 75% on unseen tasks in simulation. When deployed on real hardware, it attains 67% success on trained tasks and 50% on unseen ones. In multi-environment adaptation experiments, GRaD-Nav++ achieves an average success rate of 81% across diverse simulated environments and 67% across varied real-world settings. These results establish a new benchmark for fully onboard Vision-Language-Action (VLA) flight and demonstrate that compact, efficient models can enable reliable, language-guided navigation without relying on external infrastructure.

