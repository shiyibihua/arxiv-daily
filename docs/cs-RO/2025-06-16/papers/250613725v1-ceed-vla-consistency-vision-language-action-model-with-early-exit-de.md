---
layout: default
title: CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding
---

# CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.13725" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.13725v1</a>
  <a href="https://arxiv.org/pdf/2506.13725.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.13725v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.13725v1', 'CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenxuan Song, Jiayi Chen, Pengxiang Ding, Yuxin Huang, Han Zhao, Donglin Wang, Haoang Li

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-16

**å¤‡æ³¨**: 16 pages

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://irpn-eai.github.io/CEED-VLA/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCEED-VLAä»¥è§£å†³å¤šæ¨¡æ€å†³ç­–ä¸­çš„æ¨ç†é€Ÿåº¦ç“¶é¢ˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `è’¸é¦è®­ç»ƒ` `å¤šæ¨¡æ€å†³ç­–` `æ¨ç†åŠ é€Ÿ` `æœºå™¨äººæŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨é«˜é¢‘å’Œçµå·§æ“ä½œä»»åŠ¡ä¸­æ¨ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºä¸€è‡´æ€§è’¸é¦è®­ç»ƒå’Œæ—©æœŸé€€å‡ºè§£ç ç­–ç•¥ï¼Œä»¥æé«˜æ¨ç†æ•ˆç‡ï¼Œå‡è½»è¯¯å·®ç§¯ç´¯ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨ä¸åŒåŸºçº¿ä¸‹å®ç°äº†è¶…è¿‡4å€çš„æ¨ç†åŠ é€Ÿï¼Œä¸”ä»»åŠ¡æˆåŠŸç‡ä¿æŒé«˜æ°´å¹³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹åœ¨æœºå™¨äººé¢†åŸŸæˆä¸ºé‡è¦ç ”ç©¶æ–¹å‘ï¼Œå› å…¶å‡ºè‰²çš„å¤šæ¨¡æ€ç†è§£å’Œæ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®é™…åº”ç”¨å—åˆ°æ¨ç†é€Ÿåº¦ç“¶é¢ˆçš„ä¸¥é‡é™åˆ¶ï¼Œå°¤å…¶æ˜¯åœ¨é«˜é¢‘å’Œçµå·§æ“ä½œä»»åŠ¡ä¸­ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡å¼•å…¥ä¸€è‡´æ€§è’¸é¦è®­ç»ƒï¼Œä»¥åœ¨æ¯æ¬¡è¿­ä»£ä¸­é¢„æµ‹å¤šä¸ªæ­£ç¡®çš„åŠ¨ä½œæ ‡è®°ï¼Œä»è€ŒåŠ é€Ÿæ¨ç†ã€‚åŒæ—¶ï¼Œè®¾è®¡æ··åˆæ ‡ç­¾ç›‘ç£ä»¥å‡è½»è’¸é¦è¿‡ç¨‹ä¸­çš„è¯¯å·®ç§¯ç´¯ã€‚æ­¤å¤–ï¼Œæå‡ºçš„æ—©æœŸé€€å‡ºè§£ç ç­–ç•¥è¿›ä¸€æ­¥æé«˜äº†æ¨ç†æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒåŸºçº¿ä¸‹å®ç°äº†è¶…è¿‡4å€çš„æ¨ç†åŠ é€Ÿï¼ŒåŒæ—¶åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººä»»åŠ¡ä¸­ä¿æŒäº†é«˜ä»»åŠ¡æˆåŠŸç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨é«˜é¢‘å’Œçµå·§æ“ä½œä»»åŠ¡ä¸­çš„æ¨ç†é€Ÿåº¦ç“¶é¢ˆï¼Œç°æœ‰çš„è‡ªå›å½’è§£ç æ–¹æ³•æ•ˆç‡ä½ä¸‹ï¼Œè¿­ä»£è¿‡ç¨‹å†—é•¿ï¼Œå¯¼è‡´å®é™…åº”ç”¨å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ä¸€è‡´æ€§è’¸é¦è®­ç»ƒï¼Œé¢„æµ‹æ¯æ¬¡è¿­ä»£ä¸­çš„å¤šä¸ªæ­£ç¡®åŠ¨ä½œæ ‡è®°ï¼Œä»è€ŒåŠ é€Ÿæ¨ç†è¿‡ç¨‹ã€‚åŒæ—¶ï¼Œè®¾è®¡æ··åˆæ ‡ç­¾ç›‘ç£ä»¥å‡å°‘è’¸é¦è¿‡ç¨‹ä¸­çš„è¯¯å·®ç§¯ç´¯ï¼Œè¿›ä¸€æ­¥æé«˜æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€è‡´æ€§è’¸é¦è®­ç»ƒæ¨¡å—ã€æ··åˆæ ‡ç­¾ç›‘ç£æ¨¡å—å’Œæ—©æœŸé€€å‡ºè§£ç æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡ä¸€è‡´æ€§è’¸é¦è®­ç»ƒè¿›è¡Œå¤šæ ‡è®°é¢„æµ‹ï¼Œç„¶ååˆ©ç”¨æ··åˆæ ‡ç­¾ç›‘ç£ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ï¼Œæœ€åé€šè¿‡æ—©æœŸé€€å‡ºè§£ç ç­–ç•¥æé«˜æ¨ç†æ•ˆç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæå‡ºçš„æ—©æœŸé€€å‡ºè§£ç ç­–ç•¥æ˜¯æœ¬ç ”ç©¶çš„æ ¸å¿ƒåˆ›æ–°ï¼Œé€‚åº¦æ”¾å®½æ”¶æ•›æ¡ä»¶ï¼Œæ˜¾è‘—æé«˜äº†æ¨ç†æ•ˆç‡ï¼Œä¸ä¼ ç»Ÿçš„è‡ªå›å½’è§£ç æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¿«åœ°è¾¾åˆ°æœ‰æ•ˆå†³ç­–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è’¸é¦è®­ç»ƒä¸­ï¼Œé‡‡ç”¨å¤šæ ‡è®°é¢„æµ‹æŸå¤±å‡½æ•°ï¼Œç»“åˆæ··åˆæ ‡ç­¾ç›‘ç£ç­–ç•¥ï¼Œç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‡å°‘è¯¯å·®ç§¯ç´¯ã€‚æ­¤å¤–ï¼Œæ—©æœŸé€€å‡ºè§£ç çš„å…·ä½“å®ç°ä¾èµ–äºåŠ¨æ€è°ƒæ•´çš„æ”¶æ•›æ¡ä»¶ï¼Œä»¥ä¾¿åœ¨ä¿è¯å‡†ç¡®ç‡çš„åŒæ—¶åŠ é€Ÿæ¨ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCEED-VLAåœ¨ä¸åŒåŸºçº¿ä¸‹å®ç°äº†è¶…è¿‡4å€çš„æ¨ç†åŠ é€Ÿï¼ŒåŒæ—¶åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººä»»åŠ¡ä¸­ä¿æŒäº†é«˜è¾¾90%ä»¥ä¸Šçš„ä»»åŠ¡æˆåŠŸç‡ã€‚è¿™ä¸€æ˜¾è‘—æå‡éªŒè¯äº†æ‰€ææ–¹æ³•åœ¨å¤šæ¨¡æ€å†³ç­–ä¸­çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ“ä½œã€è‡ªåŠ¨åŒ–åˆ¶é€ å’Œäººæœºäº¤äº’ç­‰åœºæ™¯ã€‚é€šè¿‡æé«˜å¤šæ¨¡æ€å†³ç­–çš„æ¨ç†æ•ˆç‡ï¼ŒCEED-VLAå¯ä»¥åœ¨å®æ—¶ä»»åŠ¡ä¸­å®ç°æ›´é«˜çš„å“åº”é€Ÿåº¦å’Œå‡†ç¡®æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¤šé¢†åŸŸä¸­æ¨å¹¿ï¼Œæå‡æœºå™¨äººç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In recent years, Vision-Language-Action (VLA) models have become a vital research direction in robotics due to their impressive multimodal understanding and generalization capabilities. Despite the progress, their practical deployment is severely constrained by inference speed bottlenecks, particularly in high-frequency and dexterous manipulation tasks. While recent studies have explored Jacobi decoding as a more efficient alternative to traditional autoregressive decoding, its practical benefits are marginal due to the lengthy iterations. To address it, we introduce consistency distillation training to predict multiple correct action tokens in each iteration, thereby achieving acceleration. Besides, we design mixed-label supervision to mitigate the error accumulation during distillation. Although distillation brings acceptable speedup, we identify that certain inefficient iterations remain a critical bottleneck. To tackle this, we propose an early-exit decoding strategy that moderately relaxes convergence conditions, which further improves average inference efficiency. Experimental results show that the proposed method achieves more than 4 times inference acceleration across different baselines while maintaining high task success rates in both simulated and real-world robot tasks. These experiments validate that our approach provides an efficient and general paradigm for accelerating multimodal decision-making in robotics. Our project page is available at https://irpn-eai.github.io/CEED-VLA/.

