---
layout: default
title: Uncertainty-Informed Active Perception for Open Vocabulary Object Goal Navigation
---

# Uncertainty-Informed Active Perception for Open Vocabulary Object Goal Navigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.13367" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.13367v2</a>
  <a href="https://arxiv.org/pdf/2506.13367.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.13367v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.13367v2', 'Uncertainty-Informed Active Perception for Open Vocabulary Object Goal Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Utkarsh Bajpai, Julius RÃ¼ckin, Cyrill Stachniss, Marija PopoviÄ‡

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-16 (æ›´æ–°: 2025-07-13)

**å¤‡æ³¨**: 7 pages, 3 figures

**æœŸåˆŠ**: Proceedings of the 2025 European Conference on Mobile Robots (ECMR)

**DOI**: [10.1109/ECMR65884.2025.11162987](https://doi.org/10.1109/ECMR65884.2025.11162987)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­ä¹‰ä¸ç¡®å®šæ€§æ„ŸçŸ¥æ–¹æ³•ä»¥è§£å†³å¼€æ”¾è¯æ±‡ç›®æ ‡å¯¼èˆªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ç‰©ä½“ç›®æ ‡å¯¼èˆª` `è¯­ä¹‰ä¸ç¡®å®šæ€§` `ä¸»åŠ¨æ„ŸçŸ¥` `è§†è§‰-è¯­è¨€æ¨¡å‹` `å®¤å†…æœºå™¨äºº` `æ¢ç´¢è§„åˆ’` `å‡ ä½•-è¯­ä¹‰åœ°å›¾`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ObjectNavæ–¹æ³•è¿‡äºä¾èµ–æç¤ºå·¥ç¨‹ï¼Œæœªèƒ½æœ‰æ•ˆå¤„ç†è¯­ä¹‰ä¸ç¡®å®šæ€§ï¼Œå¯¼è‡´æ¢ç´¢æ•ˆç‡ä½ä¸‹ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¯­ä¹‰ä¸ç¡®å®šæ€§çš„ä¸»åŠ¨æ„ŸçŸ¥ç®¡é“ï¼Œåˆ©ç”¨æ¦‚ç‡æ¨¡å‹é‡åŒ–ä¸ç¡®å®šæ€§å¹¶å¢å¼ºç©ºé—´ç†è§£ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨ObjectNavä»»åŠ¡ä¸­çš„æˆåŠŸç‡ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“ï¼Œä¸”ç®€åŒ–äº†æç¤ºå·¥ç¨‹çš„éœ€æ±‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç§»åŠ¨æœºå™¨äººåœ¨å®¤å†…ç¯å¢ƒä¸­æ¢ç´¢æ—¶ï¼Œè¶Šæ¥è¶Šä¾èµ–è§†è§‰-è¯­è¨€æ¨¡å‹æ¥æ„ŸçŸ¥ç›¸æœºå›¾åƒä¸­çš„é«˜å±‚è¯­ä¹‰çº¿ç´¢ï¼Œå¦‚ç‰©ä½“ç±»åˆ«ã€‚è¿™äº›æ¨¡å‹æœ‰æ½œåŠ›æ˜¾è‘—æå‡æœºå™¨äººåœ¨ç‰©ä½“ç›®æ ‡å¯¼èˆªï¼ˆObjectNavï¼‰ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œåè€…è¦æ±‚æœºå™¨äººæ ¹æ®è‡ªç„¶è¯­è¨€å®šä½æŒ‡å®šç‰©ä½“ã€‚ç„¶è€Œï¼Œç°æœ‰ObjectNavæ–¹æ³•è¿‡äºä¾èµ–æç¤ºå·¥ç¨‹ï¼Œæœªèƒ½è§£å†³æç¤ºæªè¾å˜åŒ–å¼•å‘çš„è¯­ä¹‰ä¸ç¡®å®šæ€§ã€‚å¿½è§†è¯­ä¹‰ä¸ç¡®å®šæ€§å¯èƒ½å¯¼è‡´æ¬¡ä¼˜æ¢ç´¢ï¼Œä»è€Œé™åˆ¶æ€§èƒ½ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¯­ä¹‰ä¸ç¡®å®šæ€§çš„ä¸»åŠ¨æ„ŸçŸ¥ç®¡é“ï¼Œæ—¨åœ¨æå‡å®¤å†…ç¯å¢ƒä¸­çš„ObjectNavè¡¨ç°ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„æ¦‚ç‡ä¼ æ„Ÿå™¨æ¨¡å‹æ¥é‡åŒ–è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„è¯­ä¹‰ä¸ç¡®å®šæ€§ï¼Œå¹¶å°†å…¶æ•´åˆåˆ°æ¦‚ç‡å‡ ä½•-è¯­ä¹‰åœ°å›¾ä¸­ï¼Œä»¥å¢å¼ºç©ºé—´ç†è§£ã€‚åŸºäºè¯¥åœ°å›¾ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§å‰æ²¿æ¢ç´¢è§„åˆ’å™¨ï¼Œé‡‡ç”¨ä¸ç¡®å®šæ€§å¼•å¯¼çš„å¤šè‡‚èµŒåšæœºç›®æ ‡æ¥é«˜æ•ˆå¼•å¯¼ç‰©ä½“æœç´¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ObjectNavæˆåŠŸç‡ä¸Šä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“ï¼Œä¸”æ— éœ€å¤§é‡æç¤ºå·¥ç¨‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç§»åŠ¨æœºå™¨äººåœ¨ç‰©ä½“ç›®æ ‡å¯¼èˆªä»»åŠ¡ä¸­å› æç¤ºæªè¾å˜åŒ–å¼•å‘çš„è¯­ä¹‰ä¸ç¡®å®šæ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºæç¤ºå·¥ç¨‹ï¼Œæœªèƒ½æœ‰æ•ˆåº”å¯¹è¿™ç§ä¸ç¡®å®šæ€§ï¼Œå¯¼è‡´æ¢ç´¢æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§è¯­ä¹‰ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„ä¸»åŠ¨æ„ŸçŸ¥ç®¡é“ï¼Œé€šè¿‡å¼•å…¥æ¦‚ç‡ä¼ æ„Ÿå™¨æ¨¡å‹æ¥é‡åŒ–è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„ä¸ç¡®å®šæ€§ï¼Œå¹¶å°†å…¶æ•´åˆåˆ°å‡ ä½•-è¯­ä¹‰åœ°å›¾ä¸­ï¼Œä»¥æå‡ç©ºé—´ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯æ¦‚ç‡ä¼ æ„Ÿå™¨æ¨¡å‹ï¼Œç”¨äºé‡åŒ–è¯­ä¹‰ä¸ç¡®å®šæ€§ï¼›å…¶æ¬¡æ˜¯å‡ ä½•-è¯­ä¹‰åœ°å›¾ï¼Œç”¨äºå¢å¼ºç¯å¢ƒçš„ç©ºé—´ç†è§£ï¼›æœ€åæ˜¯åŸºäºä¸ç¡®å®šæ€§å¼•å¯¼çš„å‰æ²¿æ¢ç´¢è§„åˆ’å™¨ï¼Œè´Ÿè´£é«˜æ•ˆçš„ç‰©ä½“æœç´¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†æ¦‚ç‡ä¼ æ„Ÿå™¨æ¨¡å‹æ¥é‡åŒ–è¯­ä¹‰ä¸ç¡®å®šæ€§ï¼Œå¹¶å°†å…¶æ•´åˆåˆ°æ¢ç´¢è§„åˆ’ä¸­ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„æç¤ºå·¥ç¨‹ä¾èµ–å½¢æˆäº†æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡è¯¦ç»†æè¿°äº†æ¦‚ç‡ä¼ æ„Ÿå™¨æ¨¡å‹çš„æ„å»ºæ–¹æ³•ã€æŸå¤±å‡½æ•°çš„é€‰æ‹©ï¼Œä»¥åŠå¦‚ä½•åœ¨å‡ ä½•-è¯­ä¹‰åœ°å›¾ä¸­æœ‰æ•ˆæ•´åˆä¸ç¡®å®šæ€§ä¿¡æ¯ï¼Œä»¥æŒ‡å¯¼æ¢ç´¢è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨ObjectNavä»»åŠ¡ä¸­çš„æˆåŠŸç‡ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“ï¼Œå…·ä½“æˆåŠŸç‡è¾¾åˆ°äº†XX%ï¼Œè€Œä¸”æ˜¾è‘—å‡å°‘äº†å¯¹æç¤ºå·¥ç¨‹çš„ä¾èµ–ï¼Œæå‡äº†æ¢ç´¢æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®¤å†…æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½å®¶å±…ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–ä»“åº“ç®¡ç†ç­‰ã€‚é€šè¿‡æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è‡ªä¸»å¯¼èˆªèƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ•ˆç‡å’Œçµæ´»æ€§ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¤šæ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„è½åœ°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Mobile robots exploring indoor environments increasingly rely on vision-language models to perceive high-level semantic cues in camera images, such as object categories. Such models offer the potential to substantially advance robot behaviour for tasks such as object-goal navigation (ObjectNav), where the robot must locate objects specified in natural language by exploring the environment. Current ObjectNav methods heavily depend on prompt engineering for perception and do not address the semantic uncertainty induced by variations in prompt phrasing. Ignoring semantic uncertainty can lead to suboptimal exploration, which in turn limits performance. Hence, we propose a semantic uncertainty-informed active perception pipeline for ObjectNav in indoor environments. We introduce a novel probabilistic sensor model for quantifying semantic uncertainty in vision-language models and incorporate it into a probabilistic geometric-semantic map to enhance spatial understanding. Based on this map, we develop a frontier exploration planner with an uncertainty-informed multi-armed bandit objective to guide efficient object search. Experimental results demonstrate that our method achieves ObjectNav success rates comparable to those of state-of-the-art approaches, without requiring extensive prompt engineering.

