---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-06-16
---

# cs.ROï¼ˆ2025-06-16ï¼‰

ğŸ“Š å…± **25** ç¯‡è®ºæ–‡
 | ğŸ”— **4** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (20 ğŸ”—4)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (20 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250613725v1-ceed-vla-consistency-vision-language-action-model-with-early-exit-de.html">CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding</a></td>
  <td>æå‡ºCEED-VLAä»¥è§£å†³å¤šæ¨¡æ€å†³ç­–ä¸­çš„æ¨ç†é€Ÿåº¦ç“¶é¢ˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span> <span class="paper-tag">distillation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13725v1" data-paper-url="./papers/250613725v1-ceed-vla-consistency-vision-language-action-model-with-early-exit-de.html" onclick="toggleFavorite(this, '2506.13725v1', 'CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250613751v3-leverb-humanoid-whole-body-control-with-latent-vision-language-instr.html">LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction</a></td>
  <td>æå‡ºLeVERBä»¥è§£å†³äººå½¢æœºå™¨äººå…¨èº«æ§åˆ¶ä¸­çš„è§†è§‰è¯­è¨€æŒ‡ä»¤é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">whole-body control</span> <span class="paper-tag">WBC</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13751v3" data-paper-url="./papers/250613751v3-leverb-humanoid-whole-body-control-with-latent-vision-language-instr.html" onclick="toggleFavorite(this, '2506.13751v3', 'LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250613762v1-touch-begins-where-vision-ends-generalizable-policies-for-contact-ri.html">Touch begins where vision ends: Generalizable policies for contact-rich manipulation</a></td>
  <td>æå‡ºViTaLæ¡†æ¶ä»¥è§£å†³æ¥è§¦ä¸°å¯Œçš„æ“æ§ä»»åŠ¡</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">policy learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13762v1" data-paper-url="./papers/250613762v1-touch-begins-where-vision-ends-generalizable-policies-for-contact-ri.html" onclick="toggleFavorite(this, '2506.13762v1', 'Touch begins where vision ends: Generalizable policies for contact-rich manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250613189v2-multimodal-puppeteer-exploring-robot-teleoperation-via-virtual-count.html">Multimodal "Puppeteer": Exploring Robot Teleoperation Via Virtual Counterpart with LLM-Driven Voice and Gesture Interaction in Augmented Reality</a></td>
  <td>æå‡ºå¤šæ¨¡æ€â€œæ“æ§è€…â€æ¡†æ¶ä»¥æå‡æœºå™¨äººé¥æ§ä½“éªŒ</td>
  <td class="tags-cell"><span class="paper-tag">teleoperation</span> <span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13189v2" data-paper-url="./papers/250613189v2-multimodal-puppeteer-exploring-robot-teleoperation-via-virtual-count.html" onclick="toggleFavorite(this, '2506.13189v2', 'Multimodal &quot;Puppeteer&quot;: Exploring Robot Teleoperation Via Virtual Counterpart with LLM-Driven Voice and Gesture Interaction in Augmented Reality')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250613428v2-vlm-sfd-vlm-assisted-siamese-flow-diffusion-framework-for-dual-arm-c.html">VLM-SFD: VLM-Assisted Siamese Flow Diffusion Framework for Dual-Arm Cooperative Manipulation</a></td>
  <td>æå‡ºVLM-SFDæ¡†æ¶ä»¥è§£å†³åŒè‡‚åä½œæ“æ§ä¸­çš„é€‚åº”æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">bi-manual</span> <span class="paper-tag">dual-arm</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13428v2" data-paper-url="./papers/250613428v2-vlm-sfd-vlm-assisted-siamese-flow-diffusion-framework-for-dual-arm-c.html" onclick="toggleFavorite(this, '2506.13428v2', 'VLM-SFD: VLM-Assisted Siamese Flow Diffusion Framework for Dual-Arm Cooperative Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250613761v1-prompting-with-the-future-open-world-model-predictive-control-with-i.html">Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins</a></td>
  <td>æå‡ºåŸºäºäº¤äº’æ•°å­—åŒèƒèƒçš„å¼€æ”¾ä¸–ç•Œæ¨¡å‹é¢„æµ‹æ§åˆ¶æ–¹æ³•ä»¥è§£å†³ä½çº§æœºå™¨äººæ§åˆ¶é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">model predictive control</span> <span class="paper-tag">world model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13761v1" data-paper-url="./papers/250613761v1-prompting-with-the-future-open-world-model-predictive-control-with-i.html" onclick="toggleFavorite(this, '2506.13761v1', 'Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250613498v1-a-survey-on-imitation-learning-for-contact-rich-tasks-in-robotics.html">A Survey on Imitation Learning for Contact-Rich Tasks in Robotics</a></td>
  <td>ç»¼è¿°æ¨¡ä»¿å­¦ä¹ åœ¨æ¥è§¦ä¸°å¯Œä»»åŠ¡ä¸­çš„åº”ç”¨ä»¥åº”å¯¹æœºå™¨äººæŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">imitation learning</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13498v1" data-paper-url="./papers/250613498v1-a-survey-on-imitation-learning-for-contact-rich-tasks-in-robotics.html" onclick="toggleFavorite(this, '2506.13498v1', 'A Survey on Imitation Learning for Contact-Rich Tasks in Robotics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250613704v1-harmoni-haptic-guided-assistance-for-unified-robotic-tele-manipulati.html">HARMONI: Haptic-Guided Assistance for Unified Robotic Tele-Manipulation and Tele-Navigation</a></td>
  <td>æå‡ºç»Ÿä¸€çš„è§¦è§‰å¼•å¯¼å…±äº«æ§åˆ¶æ¡†æ¶ä»¥æå‡é¥æ“ä½œæ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">mobile manipulation</span> <span class="paper-tag">teleoperation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13704v1" data-paper-url="./papers/250613704v1-harmoni-haptic-guided-assistance-for-unified-robotic-tele-manipulati.html" onclick="toggleFavorite(this, '2506.13704v1', 'HARMONI: Haptic-Guided Assistance for Unified Robotic Tele-Manipulation and Tele-Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250613432v1-adaptive-model-base-control-of-quadrupeds-via-online-system-identifi.html">Adaptive Model-Base Control of Quadrupeds via Online System Identification using Kalman Filter</a></td>
  <td>æå‡ºåŸºäºå¡å°”æ›¼æ»¤æ³¢çš„å››è¶³æœºå™¨äººè‡ªé€‚åº”æ¨¡å‹æ§åˆ¶æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">legged robot</span> <span class="paper-tag">MPC</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13432v1" data-paper-url="./papers/250613432v1-adaptive-model-base-control-of-quadrupeds-via-online-system-identifi.html" onclick="toggleFavorite(this, '2506.13432v1', 'Adaptive Model-Base Control of Quadrupeds via Online System Identification using Kalman Filter')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250613867v2-atk-automatic-task-driven-keypoint-selection-for-robust-policy-learn.html">ATK: Automatic Task-driven Keypoint Selection for Robust Policy Learning</a></td>
  <td>æå‡ºATKä»¥è§£å†³è§†è§‰ç¯å¢ƒå˜åŒ–å¸¦æ¥çš„ç­–ç•¥å­¦ä¹ æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">sim-to-real</span> <span class="paper-tag">policy learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13867v2" data-paper-url="./papers/250613867v2-atk-automatic-task-driven-keypoint-selection-for-robust-policy-learn.html" onclick="toggleFavorite(this, '2506.13867v2', 'ATK: Automatic Task-driven Keypoint Selection for Robust Policy Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250613536v1-what-matters-in-learning-from-large-scale-datasets-for-robot-manipul.html">What Matters in Learning from Large-Scale Datasets for Robot Manipulation</a></td>
  <td>æå‡ºæ•°æ®ç”Ÿæˆæ¡†æ¶ä»¥ä¼˜åŒ–æœºå™¨äººæ“ä½œæ•°æ®é›†çš„å­¦ä¹ æ•ˆæœ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">policy learning</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13536v1" data-paper-url="./papers/250613536v1-what-matters-in-learning-from-large-scale-datasets-for-robot-manipul.html" onclick="toggleFavorite(this, '2506.13536v1', 'What Matters in Learning from Large-Scale Datasets for Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250613420v1-observability-aware-active-calibration-of-multi-sensor-extrinsics-fo.html">Observability-Aware Active Calibration of Multi-Sensor Extrinsics for Ground Robots via Online Trajectory Optimization</a></td>
  <td>æå‡ºä¸€ç§åŸºäºå¯è§‚æµ‹æ€§çš„ä¸»åŠ¨æ ¡å‡†æ–¹æ³•ä»¥è§£å†³å¤šä¼ æ„Ÿå™¨å¤–å‚é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">trajectory optimization</span> <span class="paper-tag">multimodal</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13420v1" data-paper-url="./papers/250613420v1-observability-aware-active-calibration-of-multi-sensor-extrinsics-fo.html" onclick="toggleFavorite(this, '2506.13420v1', 'Observability-Aware Active Calibration of Multi-Sensor Extrinsics for Ground Robots via Online Trajectory Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250613478v1-learning-swing-up-maneuvers-for-a-suspended-aerial-manipulation-plat.html">Learning Swing-up Maneuvers for a Suspended Aerial Manipulation Platform in a Hierarchical Control Framework</a></td>
  <td>æå‡ºåŸºäºå±‚æ¬¡æ§åˆ¶æ¡†æ¶çš„æ‚¬æŒ‚ç©ºä¸­æ“ä½œå¹³å°æ‘†åŠ¨æå‡ç­–ç•¥</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13478v1" data-paper-url="./papers/250613478v1-learning-swing-up-maneuvers-for-a-suspended-aerial-manipulation-plat.html" onclick="toggleFavorite(this, '2506.13478v1', 'Learning Swing-up Maneuvers for a Suspended Aerial Manipulation Platform in a Hierarchical Control Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250613933v1-tum-teleoperation-open-source-software-for-remote-driving-and-assist.html">TUM Teleoperation: Open Source Software for Remote Driving and Assistance of Automated Vehicles</a></td>
  <td>æå‡ºæ¨¡å—åŒ–å¼€æºé¥æ§è½¯ä»¶ä»¥è§£å†³è‡ªåŠ¨é©¾é©¶è½¦è¾†è¿œç¨‹æ“ä½œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">teleoperation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13933v1" data-paper-url="./papers/250613933v1-tum-teleoperation-open-source-software-for-remote-driving-and-assist.html" onclick="toggleFavorite(this, '2506.13933v1', 'TUM Teleoperation: Open Source Software for Remote Driving and Assistance of Automated Vehicles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250613915v1-sequence-modeling-for-time-optimal-quadrotor-trajectory-optimization.html">Sequence Modeling for Time-Optimal Quadrotor Trajectory Optimization with Sampling-based Robustness Analysis</a></td>
  <td>æå‡ºåŸºäºå­¦ä¹ çš„æ¨¡å‹ä»¥åŠ é€Ÿå››æ—‹ç¿¼æ—¶é—´æœ€ä¼˜è½¨è¿¹ç”Ÿæˆ</td>
  <td class="tags-cell"><span class="paper-tag">trajectory optimization</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13915v1" data-paper-url="./papers/250613915v1-sequence-modeling-for-time-optimal-quadrotor-trajectory-optimization.html" onclick="toggleFavorite(this, '2506.13915v1', 'Sequence Modeling for Time-Optimal Quadrotor Trajectory Optimization with Sampling-based Robustness Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250613753v1-edge-nearest-neighbor-in-sampling-based-motion-planning.html">Edge Nearest Neighbor in Sampling-Based Motion Planning</a></td>
  <td>æå‡ºè¾¹ç¼˜æœ€è¿‘é‚»ç®—æ³•ä»¥ä¼˜åŒ–é‡‡æ ·åŸºç¡€è¿åŠ¨è§„åˆ’</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13753v1" data-paper-url="./papers/250613753v1-edge-nearest-neighbor-in-sampling-based-motion-planning.html" onclick="toggleFavorite(this, '2506.13753v1', 'Edge Nearest Neighbor in Sampling-Based Motion Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250614039v1-quadrotor-morpho-transition-learning-vs-model-based-control-strategi.html">Quadrotor Morpho-Transition: Learning vs Model-Based Control Strategies</a></td>
  <td>æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„å››æ—‹ç¿¼å˜å½¢æ§åˆ¶ç­–ç•¥ä»¥è§£å†³å¤æ‚è¿‡æ¸¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">actuator dynamics</span> <span class="paper-tag">MPC</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14039v1" data-paper-url="./papers/250614039v1-quadrotor-morpho-transition-learning-vs-model-based-control-strategi.html" onclick="toggleFavorite(this, '2506.14039v1', 'Quadrotor Morpho-Transition: Learning vs Model-Based Control Strategies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250614066v1-a-point-cloud-completion-approach-for-the-grasping-of-partially-occl.html">A Point Cloud Completion Approach for the Grasping of Partially Occluded Objects and Its Applications in Robotic Strawberry Harvesting</a></td>
  <td>æå‡ºç‚¹äº‘è¡¥å…¨æ–¹æ³•ä»¥è§£å†³éƒ¨åˆ†é®æŒ¡ç‰©ä½“æŠ“å–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14066v1" data-paper-url="./papers/250614066v1-a-point-cloud-completion-approach-for-the-grasping-of-partially-occl.html" onclick="toggleFavorite(this, '2506.14066v1', 'A Point Cloud Completion Approach for the Grasping of Partially Occluded Objects and Its Applications in Robotic Strawberry Harvesting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250613622v1-disturbance-aware-minimum-time-planning-strategies-for-motorsport-ve.html">Disturbance-aware minimum-time planning strategies for motorsport vehicles with probabilistic safety certificates</a></td>
  <td>æå‡ºä¸€ç§è€ƒè™‘å¹²æ‰°çš„æœ€å°æ—¶é—´è§„åˆ’ç­–ç•¥ä»¥ä¼˜åŒ–èµ›è½¦è½¨è¿¹</td>
  <td class="tags-cell"><span class="paper-tag">trajectory optimization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13622v1" data-paper-url="./papers/250613622v1-disturbance-aware-minimum-time-planning-strategies-for-motorsport-ve.html" onclick="toggleFavorite(this, '2506.13622v1', 'Disturbance-aware minimum-time planning strategies for motorsport vehicles with probabilistic safety certificates')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250613087v3-ikdiffuser-a-generative-inverse-kinematics-solver-for-multi-arm-robo.html">IKDiffuser: A Generative Inverse Kinematics Solver for Multi-arm Robots via Diffusion Model</a></td>
  <td>æå‡ºIKDiffuserä»¥è§£å†³å¤šè‡‚æœºå™¨äººé€†å‘è¿åŠ¨å­¦é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13087v3" data-paper-url="./papers/250613087v3-ikdiffuser-a-generative-inverse-kinematics-solver-for-multi-arm-robo.html" onclick="toggleFavorite(this, '2506.13087v3', 'IKDiffuser: A Generative Inverse Kinematics Solver for Multi-arm Robots via Diffusion Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/250614009v1-grad-nav-vision-language-model-enabled-visual-drone-navigation-with-.html">GRaD-Nav++: Vision-Language Model Enabled Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics</a></td>
  <td>æå‡ºGRaD-Nav++ä»¥è§£å†³æ— äººæœºè¯­è¨€æŒ‡ä»¤å¯¼èˆªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">3DGS</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14009v1" data-paper-url="./papers/250614009v1-grad-nav-vision-language-model-enabled-visual-drone-navigation-with-.html" onclick="toggleFavorite(this, '2506.14009v1', 'GRaD-Nav++: Vision-Language Model Enabled Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250613100v1-a-novel-vidar-device-with-visual-inertial-encoder-odometry-and-reinf.html">A Novel ViDAR Device With Visual Inertial Encoder Odometry and Reinforcement Learning-Based Active SLAM Method</a></td>
  <td>æå‡ºViDARè®¾å¤‡ä¸è§†è§‰æƒ¯æ€§ç¼–ç å™¨ç»“åˆçš„ä¸»åŠ¨SLAMæ–¹æ³•ä»¥æå‡å®šä½ç²¾åº¦</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">DRL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13100v1" data-paper-url="./papers/250613100v1-a-novel-vidar-device-with-visual-inertial-encoder-odometry-and-reinf.html" onclick="toggleFavorite(this, '2506.13100v1', 'A Novel ViDAR Device With Visual Inertial Encoder Odometry and Reinforcement Learning-Based Active SLAM Method')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>23</td>
  <td><a href="./papers/250613679v1-rosa-harnessing-robot-states-for-vision-language-and-action-alignmen.html">ROSA: Harnessing Robot States for Vision-Language and Action Alignment</a></td>
  <td>æå‡ºROSAä»¥è§£å†³è§†è§‰è¯­è¨€ä¸æœºå™¨äººåŠ¨ä½œå¯¹é½é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13679v1" data-paper-url="./papers/250613679v1-rosa-harnessing-robot-states-for-vision-language-and-action-alignmen.html" onclick="toggleFavorite(this, '2506.13679v1', 'ROSA: Harnessing Robot States for Vision-Language and Action Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250613986v1-diffusion-based-inverse-observation-model-for-artificial-skin.html">Diffusion-based Inverse Observation Model for Artificial Skin</a></td>
  <td>æå‡ºåŸºäºæ‰©æ•£æ¨¡å‹çš„é€†è§‚å¯Ÿæ¨¡å‹ä»¥è§£å†³äººå·¥çš®è‚¤çš„æ¥è§¦å§¿æ€ä¼°è®¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13986v1" data-paper-url="./papers/250613986v1-diffusion-based-inverse-observation-model-for-artificial-skin.html" onclick="toggleFavorite(this, '2506.13986v1', 'Diffusion-based Inverse Observation Model for Artificial Skin')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>25</td>
  <td><a href="./papers/250613367v2-uncertainty-informed-active-perception-for-open-vocabulary-object-go.html">Uncertainty-Informed Active Perception for Open Vocabulary Object Goal Navigation</a></td>
  <td>æå‡ºè¯­ä¹‰ä¸ç¡®å®šæ€§æ„ŸçŸ¥æ–¹æ³•ä»¥è§£å†³å¼€æ”¾è¯æ±‡ç›®æ ‡å¯¼èˆªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">semantic map</span> <span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13367v2" data-paper-url="./papers/250613367v2-uncertainty-informed-active-perception-for-open-vocabulary-object-go.html" onclick="toggleFavorite(this, '2506.13367v2', 'Uncertainty-Informed Active Perception for Open Vocabulary Object Goal Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)