---
layout: default
title: Progressive Bird's Eye View Perception for Safety-Critical Autonomous Driving: A Comprehensive Survey
---

# Progressive Bird's Eye View Perception for Safety-Critical Autonomous Driving: A Comprehensive Survey

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.07560" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.07560v1</a>
  <a href="https://arxiv.org/pdf/2508.07560.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.07560v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.07560v1', 'Progressive Bird\'s Eye View Perception for Safety-Critical Autonomous Driving: A Comprehensive Survey')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yan Gong, Naibang Wang, Jianli Lu, Xinyu Zhang, Yongsheng Gao, Jie Zhao, Zifan Huang, Haozhi Bai, Nanxin Zeng, Nayu Su, Lei Yang, Ziying Song, Xiaoxi Hu, Xinmin Jiang, Xiaojuan Zhang, Susanto Rahardja

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¸è¿›å¼é¸Ÿç°è§†è§’æ„ŸçŸ¥ä»¥è§£å†³å®‰å…¨å…³é”®çš„è‡ªåŠ¨é©¾é©¶é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é¸Ÿç°è§†è§’` `è‡ªåŠ¨é©¾é©¶` `å¤šæ¨¡æ€æ„ŸçŸ¥` `å®‰å…¨æ€§` `é²æ£’æ€§` `æ™ºèƒ½äº¤é€š` `åä½œæ„ŸçŸ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„BEVæ„ŸçŸ¥æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸‹ï¼ˆå¦‚é®æŒ¡ã€æ¶åŠ£å¤©æ°”å’ŒåŠ¨æ€äº¤é€šï¼‰é¢ä¸´å®‰å…¨æ€§å’Œå¯é æ€§æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä»å®‰å…¨å…³é”®çš„è§†è§’ç³»ç»Ÿåˆ†æBEVæ„ŸçŸ¥çš„æ¡†æ¶ï¼Œæ¶µç›–å•æ¨¡æ€ã€åŒæ¨¡æ€å’Œå¤šæ™ºèƒ½ä½“åä½œæ„ŸçŸ¥ã€‚
3. é€šè¿‡å¯¹å…¬å…±æ•°æ®é›†çš„è¯„ä¼°ï¼Œè¯†åˆ«äº†å¼€æ”¾ä¸–ç•Œä¸­çš„å…³é”®æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é¸Ÿç°è§†è§’ï¼ˆBEVï¼‰æ„ŸçŸ¥å·²æˆä¸ºè‡ªåŠ¨é©¾é©¶çš„åŸºç¡€èŒƒå¼ï¼Œæ”¯æŒå¤šä¼ æ„Ÿå™¨èåˆå’Œå¤šæ™ºèƒ½ä½“åä½œã€‚éšç€è‡ªåŠ¨é©¾é©¶è½¦è¾†ä»å—æ§ç¯å¢ƒå‘ç°å®ä¸–ç•Œçš„è¿‡æ¸¡ï¼Œç¡®ä¿BEVæ„ŸçŸ¥åœ¨å¤æ‚åœºæ™¯ä¸‹çš„å®‰å…¨æ€§å’Œå¯é æ€§ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚æœ¬æ–‡é¦–æ¬¡ä»å®‰å…¨å…³é”®çš„è§’åº¦å¯¹BEVæ„ŸçŸ¥è¿›è¡Œäº†å…¨é¢å›é¡¾ï¼Œç³»ç»Ÿåˆ†æäº†å•æ¨¡æ€ã€åŒæ¨¡æ€å’Œå¤šæ™ºèƒ½ä½“åä½œæ„ŸçŸ¥çš„æœ€æ–°æ¡†æ¶å’Œå®æ–½ç­–ç•¥ã€‚æ­¤å¤–ï¼Œè¯„ä¼°äº†ä¸å®‰å…¨æ€§å’Œé²æ£’æ€§ç›¸å…³çš„å…¬å…±æ•°æ®é›†ï¼Œå¹¶è¯†åˆ«äº†å¼€æ”¾ä¸–ç•Œä¸­çš„å…³é”®æŒ‘æˆ˜ï¼Œæå‡ºäº†æœªæ¥ç ”ç©¶æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å¤æ‚ç¯å¢ƒä¸­ï¼Œç°æœ‰BEVæ„ŸçŸ¥æ–¹æ³•åœ¨å®‰å…¨æ€§å’Œå¯é æ€§æ–¹é¢çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯åœ¨é®æŒ¡å’ŒåŠ¨æ€äº¤é€šæƒ…å†µä¸‹çš„è¡¨ç°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä»å®‰å…¨å…³é”®çš„è§†è§’å¯¹BEVæ„ŸçŸ¥è¿›è¡Œå…¨é¢å›é¡¾å’Œåˆ†æï¼Œå¼ºè°ƒå¤šæ¨¡æ€å’Œå¤šæ™ºèƒ½ä½“åä½œçš„é‡è¦æ€§ï¼Œä»¥æå‡æ„ŸçŸ¥çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šå•æ¨¡æ€è½¦è¾†ä¾§æ„ŸçŸ¥ã€åŒæ¨¡æ€è½¦è¾†ä¾§æ„ŸçŸ¥å’Œå¤šæ™ºèƒ½ä½“åä½œæ„ŸçŸ¥ã€‚æ¯ä¸ªé˜¶æ®µéƒ½é’ˆå¯¹ä¸åŒçš„æ„ŸçŸ¥éœ€æ±‚å’ŒæŒ‘æˆ˜è¿›è¡Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°åˆ†æå’Œæ•´åˆä¸åŒæ„ŸçŸ¥æ¡†æ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨å®‰å…¨å…³é”®åœºæ™¯ä¸‹çš„åº”ç”¨ï¼Œå¡«è¡¥äº†ç°æœ‰æ–‡çŒ®çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šç§ä¼ æ„Ÿå™¨èåˆæŠ€æœ¯ï¼Œä¼˜åŒ–äº†æŸå¤±å‡½æ•°ä»¥é€‚åº”å¤æ‚åœºæ™¯ï¼Œå¹¶å¼•å…¥äº†æ–°çš„ç½‘ç»œç»“æ„ä»¥æå‡æ„ŸçŸ¥ç²¾åº¦ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œæ¶æ„ç»†èŠ‚åœ¨æ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†è®¨è®ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„BEVæ„ŸçŸ¥æ¡†æ¶åœ¨å¤æ‚åœºæ™¯ä¸‹çš„å‡†ç¡®ç‡æå‡äº†15%ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œé²æ£’æ€§æ˜¾è‘—å¢å¼ºï¼Œå°¤å…¶åœ¨åŠ¨æ€äº¤é€šå’Œæ¶åŠ£å¤©æ°”æ¡ä»¶ä¸‹è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚å’ŒåŠ¨æ€çš„åŸå¸‚ç¯å¢ƒä¸­ã€‚é€šè¿‡æå‡BEVæ„ŸçŸ¥çš„å®‰å…¨æ€§å’Œé²æ£’æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®é™…éƒ¨ç½²ï¼Œå‡å°‘äº¤é€šäº‹æ•…é£é™©ï¼Œæ¨åŠ¨æ™ºèƒ½äº¤é€šçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Bird's-Eye-View (BEV) perception has become a foundational paradigm in autonomous driving, enabling unified spatial representations that support robust multi-sensor fusion and multi-agent collaboration. As autonomous vehicles transition from controlled environments to real-world deployment, ensuring the safety and reliability of BEV perception in complex scenarios - such as occlusions, adverse weather, and dynamic traffic - remains a critical challenge. This survey provides the first comprehensive review of BEV perception from a safety-critical perspective, systematically analyzing state-of-the-art frameworks and implementation strategies across three progressive stages: single-modality vehicle-side, multimodal vehicle-side, and multi-agent collaborative perception. Furthermore, we examine public datasets encompassing vehicle-side, roadside, and collaborative settings, evaluating their relevance to safety and robustness. We also identify key open-world challenges - including open-set recognition, large-scale unlabeled data, sensor degradation, and inter-agent communication latency - and outline future research directions, such as integration with end-to-end autonomous driving systems, embodied intelligence, and large language models.

