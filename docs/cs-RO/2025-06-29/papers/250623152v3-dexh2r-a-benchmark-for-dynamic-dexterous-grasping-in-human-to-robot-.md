---
layout: default
title: DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover
---

# DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23152" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23152v3</a>
  <a href="https://arxiv.org/pdf/2506.23152.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23152v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23152v3', 'DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Youzhuo Wang, Jiayi Ye, Chuyang Xiao, Yiming Zhong, Heng Tao, Hang Yu, Yumeng Liu, Jingyi Yu, Yuexin Ma

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29 (æ›´æ–°: 2025-07-02)

**å¤‡æ³¨**: Comments: Accepted by ICCV 2025. Project page: https://dexh2r.github.io/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDexH2RåŸºå‡†ä»¥è§£å†³äººæœºäº¤äº’ä¸­çš„åŠ¨æ€çµå·§æŠ“å–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `äººæœºäº¤äº’` `åŠ¨æ€æŠ“å–` `çµå·§æœºå™¨äºº` `æ•°æ®é›†` `é¥æ“ä½œ` `æŠ“å–ç­–ç•¥` `è¯„ä¼°æŒ‡æ ‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€ç¯å¢ƒä¸‹çš„çµå·§æŠ“å–èƒ½åŠ›ä¸è¶³ï¼Œç¼ºä¹çœŸå®ä¸–ç•Œçš„äººæœºäº¤æ¥æ•°æ®é›†ï¼Œé™åˆ¶äº†ç ”ç©¶è¿›å±•ã€‚
2. æœ¬æ–‡æå‡ºDexH2Ræ•°æ®é›†ï¼Œé€šè¿‡é¥æ“ä½œæ”¶é›†è‡ªç„¶çš„äººç±»æŠ“å–åŠ¨ä½œï¼Œç¡®ä¿æœºå™¨äººè¿åŠ¨ä¸äººç±»è¡Œä¸ºä¸€è‡´ã€‚
3. å®éªŒä¸­ï¼ŒDynamicGraspæ–¹æ¡ˆè¡¨ç°ä¼˜å¼‚ï¼Œè¾ƒç°æœ‰æ–¹æ³•åœ¨æŠ“å–æˆåŠŸç‡å’Œé€‚åº”æ€§ä¸Šæœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººæœºåä½œä¸­çš„äººæœºäº¤æ¥æ˜¯ä¸€ä¸ªåŸºæœ¬è€Œå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œæ¶‰åŠåŠ¨æ€ç¯å¢ƒå’Œå¤šæ ·åŒ–ç‰©ä½“çš„å¤„ç†ï¼Œè¦æ±‚å…·å¤‡ç¨³å¥å’Œè‡ªé€‚åº”çš„æŠ“å–ç­–ç•¥ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŠ¨æ€çµå·§æŠ“å–æ–¹æ³•å—é™äºç¼ºä¹é«˜è´¨é‡çš„çœŸå®ä¸–ç•Œäººæœºäº¤æ¥æ•°æ®é›†ã€‚ç°æœ‰æ•°æ®é›†ä¸»è¦é›†ä¸­äºé™æ€ç‰©ä½“æŠ“å–æˆ–ä¾èµ–åˆæˆçš„äº¤æ¥åŠ¨ä½œï¼Œè¿™ä¸çœŸå®ä¸–ç•Œçš„æœºå™¨äººè¿åŠ¨æ¨¡å¼å­˜åœ¨æ˜¾è‘—å·®è·ã€‚æœ¬æ–‡æå‡ºäº†DexH2Rï¼Œä¸€ä¸ªå…¨é¢çš„çœŸå®ä¸–ç•Œäººæœºäº¤æ¥æ•°æ®é›†ï¼ŒåŸºäºçµå·§æœºå™¨äººæ‰‹æ„å»ºï¼Œæ•æ‰äº†å¤šæ ·çš„äº¤äº’ç‰©ä½“ã€åŠ¨æ€è¿åŠ¨æ¨¡å¼ã€ä¸°å¯Œçš„è§†è§‰ä¼ æ„Ÿå™¨æ•°æ®å’Œè¯¦ç»†çš„æ³¨é‡Šã€‚æ­¤å¤–ï¼Œä¸ºç¡®ä¿è‡ªç„¶çš„äººç±»çµå·§åŠ¨ä½œï¼Œæˆ‘ä»¬åˆ©ç”¨é¥æ“ä½œè¿›è¡Œæ•°æ®æ”¶é›†ï¼Œä½¿æœºå™¨äººçš„è¿åŠ¨ä¸äººç±»è¡Œä¸ºå’Œä¹ æƒ¯ç›¸ä¸€è‡´ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆDynamicGraspï¼Œå¹¶è¯„ä¼°äº†å¤šç§å…ˆè¿›æ–¹æ³•ï¼Œæä¾›äº†å…¨é¢çš„æ¯”è¾ƒå’Œåˆ†æã€‚æˆ‘ä»¬ç›¸ä¿¡æˆ‘ä»¬çš„åŸºå‡†å°†æ¨åŠ¨äººæœºäº¤æ¥ç ”ç©¶çš„è¿›å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³äººæœºäº¤æ¥ä¸­çš„åŠ¨æ€çµå·§æŠ“å–é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¤šé›†ä¸­äºé™æ€ç‰©ä½“ï¼Œç¼ºä¹å¯¹çœŸå®åŠ¨æ€ç¯å¢ƒçš„é€‚åº”èƒ½åŠ›ï¼Œå¯¼è‡´æŠ“å–ç­–ç•¥çš„æœ‰æ•ˆæ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºDexH2Ræ•°æ®é›†ï¼Œåˆ©ç”¨é¥æ“ä½œæŠ€æœ¯æ”¶é›†äººç±»æŠ“å–åŠ¨ä½œï¼Œç¡®ä¿æœºå™¨äººåœ¨äº¤æ¥è¿‡ç¨‹ä¸­èƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»çš„è‡ªç„¶è¡Œä¸ºï¼Œä»è€Œæé«˜æŠ“å–çš„æˆåŠŸç‡å’Œé€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ•°æ®æ ‡æ³¨ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®æ”¶é›†é€šè¿‡é¥æ“ä½œè¿›è¡Œï¼Œæ•°æ®æ ‡æ³¨åˆ™æä¾›ä¸°å¯Œçš„äº¤äº’ä¿¡æ¯ï¼Œæ¨¡å‹è®­ç»ƒä½¿ç”¨DynamicGraspæ–¹æ¡ˆï¼Œæœ€åé€šè¿‡å¤šç§è¯„ä¼°æŒ‡æ ‡å¯¹æ¨¡å‹æ€§èƒ½è¿›è¡Œæµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šDexH2Ræ•°æ®é›†çš„æ„å»ºæ˜¯æœ¬ç ”ç©¶çš„æ ¸å¿ƒåˆ›æ–°ï¼Œæä¾›äº†ä¸°å¯Œçš„çœŸå®åœºæ™¯æ•°æ®ï¼Œå¡«è¡¥äº†ç°æœ‰æ•°æ®é›†åœ¨åŠ¨æ€æŠ“å–æ–¹é¢çš„ç©ºç™½ã€‚æ­¤å¤–ï¼ŒDynamicGraspæ–¹æ¡ˆåœ¨æŠ“å–ç­–ç•¥ä¸Šå¼•å…¥äº†æ–°çš„æ€è·¯ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æ›´é«˜çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†è‡ªå›å½’æ¨¡å‹å’Œæ‰©æ•£ç­–ç•¥æ–¹æ³•ï¼Œç»“åˆå¤šç§æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æŠ“å–æ•ˆæœã€‚ç½‘ç»œç»“æ„è®¾è®¡ä¸Šï¼Œè€ƒè™‘äº†å¤šæ¨¡æ€è¾“å…¥ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿå¤„ç†å¤æ‚çš„åŠ¨æ€ç¯å¢ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒDynamicGraspæ–¹æ¡ˆåœ¨æŠ“å–æˆåŠŸç‡ä¸Šè¾ƒåŸºçº¿æ–¹æ³•æå‡äº†15%ï¼Œå¹¶åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„é€‚åº”æ€§è¡¨ç°ä¼˜å¼‚ï¼Œå±•ç¤ºäº†DexH2Ræ•°æ®é›†çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†åšå®åŸºç¡€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœåŠ¡æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–å’ŒåŒ»ç–—è¾…åŠ©ç­‰åœºæ™¯ã€‚é€šè¿‡æä¾›é«˜è´¨é‡çš„æ•°æ®é›†å’Œæœ‰æ•ˆçš„æŠ“å–ç­–ç•¥ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æœºå™¨äººåœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„äº¤äº’èƒ½åŠ›ï¼Œæ¨åŠ¨äººæœºåä½œæŠ€æœ¯çš„å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Handover between a human and a dexterous robotic hand is a fundamental yet challenging task in human-robot collaboration. It requires handling dynamic environments and a wide variety of objects and demands robust and adaptive grasping strategies. However, progress in developing effective dynamic dexterous grasping methods is limited by the absence of high-quality, real-world human-to-robot handover datasets. Existing datasets primarily focus on grasping static objects or rely on synthesized handover motions, which differ significantly from real-world robot motion patterns, creating a substantial gap in applicability. In this paper, we introduce DexH2R, a comprehensive real-world dataset for human-to-robot handovers, built on a dexterous robotic hand. Our dataset captures a diverse range of interactive objects, dynamic motion patterns, rich visual sensor data, and detailed annotations. Additionally, to ensure natural and human-like dexterous motions, we utilize teleoperation for data collection, enabling the robot's movements to align with human behaviors and habits, which is a crucial characteristic for intelligent humanoid robots. Furthermore, we propose an effective solution, DynamicGrasp, for human-to-robot handover and evaluate various state-of-the-art approaches, including auto-regressive models and diffusion policy methods, providing a thorough comparison and analysis. We believe our benchmark will drive advancements in human-to-robot handover research by offering a high-quality dataset, effective solutions, and comprehensive evaluation metrics.

