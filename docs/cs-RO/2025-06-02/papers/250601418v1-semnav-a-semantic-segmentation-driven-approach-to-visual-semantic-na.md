---
layout: default
title: SEMNAV: A Semantic Segmentation-Driven Approach to Visual Semantic Navigation
---

# SEMNAV: A Semantic Segmentation-Driven Approach to Visual Semantic Navigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.01418" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.01418v1</a>
  <a href="https://arxiv.org/pdf/2506.01418.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.01418v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.01418v1', 'SEMNAV: A Semantic Segmentation-Driven Approach to Visual Semantic Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rafael Flor-RodrÃ­guez, Carlos GutiÃ©rrez-Ãlvarez, Francisco Javier Acevedo-RodrÃ­guez, Sergio Lafuente-Arroyo, Roberto J. LÃ³pez-Sastre

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-02

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/gramuah/semnav)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSEMNAVä»¥è§£å†³è§†è§‰è¯­ä¹‰å¯¼èˆªä¸­çš„é¢†åŸŸé€‚åº”é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è§†è§‰è¯­ä¹‰å¯¼èˆª` `è¯­ä¹‰åˆ†å‰²` `æœºå™¨äººå¯¼èˆª` `é¢†åŸŸé€‚åº”` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰è¯­ä¹‰å¯¼èˆªæ–¹æ³•ä¸»è¦ä¾èµ–äºè™šæ‹Ÿåœºæ™¯çš„RGBæ•°æ®ï¼Œå¯¼è‡´åœ¨çœŸå®ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºSEMNAVï¼Œé€šè¿‡è¯­ä¹‰åˆ†å‰²å¢å¼ºç¯å¢ƒçš„è§†è§‰è¾“å…¥è¡¨ç¤ºï¼Œä»è€Œæå‡ä»£ç†çš„å¯¼èˆªå†³ç­–èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSEMNAVåœ¨Habitat 2.0æ¨¡æ‹Ÿç¯å¢ƒä¸­æˆåŠŸç‡é«˜äºç°æœ‰æ¨¡å‹ï¼Œå¹¶åœ¨çœŸå®ç¯å¢ƒä¸­æœ‰æ•ˆå‡å°äº†æ¨¡æ‹Ÿä¸ç°å®çš„å·®è·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¯­ä¹‰å¯¼èˆªï¼ˆVSNï¼‰æ˜¯æœºå™¨äººé¢†åŸŸä¸­çš„ä¸€ä¸ªåŸºæœ¬é—®é¢˜ï¼Œè¦æ±‚ä»£ç†åœ¨æœªçŸ¥ç¯å¢ƒä¸­ä½¿ç”¨è§†è§‰ä¿¡æ¯å¯¼èˆªè‡³ç›®æ ‡ç‰©ä½“ã€‚ç°æœ‰çš„VSNæ¨¡å‹é€šå¸¸åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è®­ç»ƒï¼Œä¾èµ–äºè™šæ‹Ÿåœºæ™¯çš„åŸå§‹RGBæ•°æ®ï¼Œè¿™é™åˆ¶äº†å…¶åœ¨çœŸå®ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†SEMNAVï¼Œä¸€ç§åˆ©ç”¨è¯­ä¹‰åˆ†å‰²ä½œä¸ºä¸»è¦è§†è§‰è¾“å…¥è¡¨ç¤ºçš„æ–¹æ³•ï¼Œä»¥å¢å¼ºä»£ç†çš„æ„ŸçŸ¥å’Œå†³ç­–èƒ½åŠ›ã€‚é€šè¿‡æ˜¾å¼åœ°å¼•å…¥é«˜å±‚æ¬¡çš„è¯­ä¹‰ä¿¡æ¯ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å­¦ä¹ åˆ°æ›´ä¸ºç¨³å¥çš„å¯¼èˆªç­–ç•¥ï¼Œæ”¹å–„äº†åœ¨æœªè§ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSEMNAVåœ¨Habitat 2.0æ¨¡æ‹Ÿç¯å¢ƒä¸­è¶…è¶Šäº†ç°æœ‰çš„VSNæ¨¡å‹ï¼ŒæˆåŠŸç‡æ˜¾è‘—æé«˜ï¼Œä¸”åœ¨çœŸå®ä¸–ç•Œå®éªŒä¸­æœ‰æ•ˆç¼©å°äº†æ¨¡æ‹Ÿä¸ç°å®ä¹‹é—´çš„å·®è·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰è¯­ä¹‰å¯¼èˆªä¸­ä»£ç†åœ¨æœªçŸ¥ç¯å¢ƒä¸­å¯¼èˆªè‡³ç›®æ ‡ç‰©ä½“çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºè™šæ‹Ÿåœºæ™¯çš„RGBæ•°æ®ï¼Œå¯¼è‡´åœ¨çœŸå®ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œå­˜åœ¨é¢†åŸŸé€‚åº”é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSEMNAVçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è¯­ä¹‰åˆ†å‰²ä½œä¸ºä¸»è¦çš„è§†è§‰è¾“å…¥è¡¨ç¤ºï¼Œæ˜¾å¼å¼•å…¥é«˜å±‚æ¬¡çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä»¥å¢å¼ºä»£ç†çš„æ„ŸçŸ¥å’Œå†³ç­–èƒ½åŠ›ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°ç†è§£ç¯å¢ƒï¼Œä»è€Œæé«˜å¯¼èˆªçš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSEMNAVçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¯­ä¹‰åˆ†å‰²æ¨¡å—å’Œå¯¼èˆªå†³ç­–æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡è¯­ä¹‰åˆ†å‰²ç½‘ç»œæå–ç¯å¢ƒçš„è¯­ä¹‰ä¿¡æ¯ï¼Œç„¶åå°†è¿™äº›ä¿¡æ¯è¾“å…¥åˆ°å¯¼èˆªå†³ç­–ç½‘ç»œä¸­ï¼Œç”Ÿæˆå¯¼èˆªç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šSEMNAVçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†è¯­ä¹‰åˆ†å‰²ä½œä¸ºæ ¸å¿ƒè¾“å…¥ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨æœªè§ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™ä¸ä¼ ç»Ÿä¾èµ–RGBæ•°æ®çš„æ¨¡å‹å½¢æˆäº†æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–è¯­ä¹‰åˆ†å‰²çš„å‡†ç¡®æ€§ï¼Œå¹¶é€šè¿‡æ•°æ®å¢å¼ºæŠ€æœ¯æé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œç½‘ç»œç»“æ„ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿åœ¨å¤æ‚ç¯å¢ƒä¸­ä»èƒ½æœ‰æ•ˆæå–è¯­ä¹‰ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSEMNAVåœ¨Habitat 2.0æ¨¡æ‹Ÿç¯å¢ƒä¸­æˆåŠŸç‡è¶…è¿‡ç°æœ‰çš„VSNæ¨¡å‹ï¼Œå…·ä½“è¡¨ç°ä¸ºæˆåŠŸç‡æå‡äº†XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ã€‚æ­¤å¤–ï¼ŒçœŸå®ä¸–ç•Œå®éªŒéªŒè¯äº†è¯­ä¹‰åˆ†å‰²åœ¨ç¼©å°æ¨¡æ‹Ÿä¸ç°å®ä¹‹é—´å·®è·æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œæ˜¾ç¤ºå‡ºè¯¥æ–¹æ³•çš„å®é™…åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªä¸»æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½å®¶å±…ç³»ç»Ÿä»¥åŠå¢å¼ºç°å®ç­‰ã€‚é€šè¿‡æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ï¼ŒSEMNAVæœ‰æœ›åœ¨å®é™…åº”ç”¨ä¸­å®ç°æ›´é«˜çš„æ•ˆç‡å’Œå®‰å…¨æ€§ï¼Œæ¨åŠ¨æœºå™¨äººæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual Semantic Navigation (VSN) is a fundamental problem in robotics, where an agent must navigate toward a target object in an unknown environment, mainly using visual information. Most state-of-the-art VSN models are trained in simulation environments, where rendered scenes of the real world are used, at best. These approaches typically rely on raw RGB data from the virtual scenes, which limits their ability to generalize to real-world environments due to domain adaptation issues. To tackle this problem, in this work, we propose SEMNAV, a novel approach that leverages semantic segmentation as the main visual input representation of the environment to enhance the agent's perception and decision-making capabilities. By explicitly incorporating high-level semantic information, our model learns robust navigation policies that improve generalization across unseen environments, both in simulated and real world settings. We also introduce a newly curated dataset, i.e. the SEMNAV dataset, designed for training semantic segmentation-aware navigation models like SEMNAV. Our approach is evaluated extensively in both simulated environments and with real-world robotic platforms. Experimental results demonstrate that SEMNAV outperforms existing state-of-the-art VSN models, achieving higher success rates in the Habitat 2.0 simulation environment, using the HM3D dataset. Furthermore, our real-world experiments highlight the effectiveness of semantic segmentation in mitigating the sim-to-real gap, making our model a promising solution for practical VSN-based robotic applications. We release SEMNAV dataset, code and trained models at https://github.com/gramuah/semnav

