---
layout: default
title: FreeTacMan: Robot-free Visuo-Tactile Data Collection System for Contact-rich Manipulation
---

# FreeTacMan: Robot-free Visuo-Tactile Data Collection System for Contact-rich Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.01941" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.01941v2</a>
  <a href="https://arxiv.org/pdf/2506.01941.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.01941v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.01941v2', 'FreeTacMan: Robot-free Visuo-Tactile Data Collection System for Contact-rich Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Longyan Wu, Checheng Yu, Jieji Ren, Li Chen, Yufei Jiang, Ran Huang, Guoying Gu, Hongyang Li

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-02 (æ›´æ–°: 2025-10-09)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFreeTacManä»¥è§£å†³æœºå™¨äººæ¥è§¦ä¸°å¯Œæ“ä½œçš„æ•°æ®æ”¶é›†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¥è§¦ä¸°å¯Œæ“ä½œ` `æ•°æ®æ”¶é›†` `å¯ç©¿æˆ´ä¼ æ„Ÿå™¨` `è§†è§‰-è§¦è§‰èåˆ` `æœºå™¨äººå­¦ä¹ ` `äººæœºäº¤äº’` `å¤šæ¨¡æ€æ•°æ®é›†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ¥è§¦ä¸°å¯Œçš„æ“ä½œä¸­é¢ä¸´æ•°æ®æ”¶é›†æ•ˆç‡ä½å’Œä¼ æ„Ÿå™¨è®¾ç½®æœ‰é™çš„é—®é¢˜ï¼Œå½±å“äº†æœºå™¨äººçš„å­¦ä¹ èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºFreeTacManï¼Œä¸€ä¸ªæ— æœºå™¨äººå¹²é¢„çš„å¯ç©¿æˆ´æ•°æ®æ”¶é›†ç³»ç»Ÿï¼Œåˆ©ç”¨åŒé‡è§†è§‰-è§¦è§‰ä¼ æ„Ÿå™¨å®ç°ç›´è§‚æ§åˆ¶ã€‚
3. FreeTacManæ”¶é›†äº†è¶…è¿‡300ä¸‡å¯¹è§†è§‰-è§¦è§‰å›¾åƒå’Œ10,000æ¡ç¤ºèŒƒè½¨è¿¹ï¼Œæ˜¾è‘—æå‡äº†æ•°æ®æ”¶é›†æ€§èƒ½ï¼Œæ”¯æŒæœ‰æ•ˆçš„ç­–ç•¥å­¦ä¹ ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å®ç°æœºå™¨äººæ¥è§¦ä¸°å¯Œçš„æ“ä½œä»ç„¶æ˜¯æœºå™¨äººå­¦ä¹ ä¸­çš„ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œä¸»è¦å—é™äºæ•°æ®æ”¶é›†çš„ä½æ•ˆå’Œä¼ æ„Ÿå™¨è®¾ç½®çš„å±€é™æ€§ã€‚ä»¥å¾€çš„æ‰‹æŒè®¾å¤‡è™½ç„¶æœ‰æ‰€æ¢ç´¢ï¼Œä½†å…¶åˆšæ€§ç»“æ„é™åˆ¶äº†è§¦è§‰åé¦ˆï¼Œç»™äººç±»æ“ä½œå‘˜å¸¦æ¥äº†æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†FreeTacManï¼Œä¸€ä¸ªä»¥äººä¸ºä¸­å¿ƒä¸”æ— æœºå™¨äººå¹²é¢„çš„æ•°æ®æ”¶é›†ç³»ç»Ÿï¼Œæ—¨åœ¨å®ç°å‡†ç¡®é«˜æ•ˆçš„æœºå™¨äººæ“ä½œã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å¯ç©¿æˆ´çš„å¤¹æŒå™¨ï¼Œé…å¤‡åŒé‡è§†è§‰-è§¦è§‰ä¼ æ„Ÿå™¨ï¼Œèƒ½å¤Ÿè¢«äººç±»æ‰‹æŒ‡ç©¿æˆ´ä»¥å®ç°ç›´è§‚æ§åˆ¶ã€‚åŒæ—¶ï¼Œå¼•å…¥é«˜ç²¾åº¦å…‰å­¦è¿½è¸ªç³»ç»Ÿä»¥åŒæ­¥æ•æ‰æœ«ç«¯æ‰§è¡Œå™¨å§¿æ€å’Œè§†è§‰è§¦è§‰åé¦ˆã€‚FreeTacManæ”¶é›†äº†ä¸€ä¸ªå¤§è§„æ¨¡çš„å¤šæ¨¡æ€æ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡300ä¸‡å¯¹è§†è§‰-è§¦è§‰å›¾åƒåŠ10,000æ¡ç¤ºèŒƒè½¨è¿¹ï¼Œæ¶µç›–50ç§å¤šæ ·çš„æ¥è§¦ä¸°å¯Œæ“ä½œä»»åŠ¡ã€‚ä¸ä»¥å¾€å·¥ä½œç›¸æ¯”ï¼ŒFreeTacManåœ¨æ•°æ®æ”¶é›†æ€§èƒ½ä¸Šå®ç°äº†å¤šé¡¹æå‡ï¼Œå¹¶æ”¯æŒåŸºäºè‡ªæ”¶é›†æ•°æ®é›†çš„æœ‰æ•ˆç­–ç•¥å­¦ä¹ ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººåœ¨æ¥è§¦ä¸°å¯Œæ“ä½œä¸­çš„æ•°æ®æ”¶é›†ä½æ•ˆå’Œä¼ æ„Ÿå™¨å±€é™æ€§çš„é—®é¢˜ã€‚ç°æœ‰çš„æ‰‹æŒè®¾å¤‡ç»“æ„åˆšæ€§ï¼Œè§¦è§‰åé¦ˆä¸è¶³ï¼Œç»™äººç±»æ“ä½œå‘˜å¸¦æ¥ä¸ä¾¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºFreeTacManï¼Œä¸€ä¸ªä»¥äººä¸ºä¸­å¿ƒçš„æ— æœºå™¨äººæ•°æ®æ”¶é›†ç³»ç»Ÿï¼Œè®¾è®¡å¯ç©¿æˆ´å¤¹æŒå™¨ä»¥å®ç°ç›´è§‚çš„æ§åˆ¶å’Œé«˜æ•ˆçš„æ•°æ®æ”¶é›†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFreeTacManç³»ç»ŸåŒ…æ‹¬å¯ç©¿æˆ´å¤¹æŒå™¨ã€åŒé‡è§†è§‰-è§¦è§‰ä¼ æ„Ÿå™¨å’Œé«˜ç²¾åº¦å…‰å­¦è¿½è¸ªç³»ç»Ÿã€‚å¤¹æŒå™¨ç”±äººç±»æ‰‹æŒ‡ç©¿æˆ´ï¼Œä¼ æ„Ÿå™¨ç”¨äºæ”¶é›†æ•°æ®ï¼Œå…‰å­¦ç³»ç»Ÿç”¨äºåŒæ­¥æ•æ‰å§¿æ€å’Œåé¦ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šFreeTacMançš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶äººæ€§åŒ–è®¾è®¡å’Œæ— æœºå™¨äººå¹²é¢„çš„æ•°æ®æ”¶é›†æ–¹å¼ï¼Œæ˜¾è‘—æé«˜äº†è§¦è§‰åé¦ˆçš„è´¨é‡å’Œæ•°æ®æ”¶é›†çš„æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šç³»ç»Ÿä¸­ä½¿ç”¨çš„åŒé‡ä¼ æ„Ÿå™¨è®¾è®¡ç¡®ä¿äº†è§†è§‰å’Œè§¦è§‰æ•°æ®çš„åŒæ­¥ï¼Œå…‰å­¦è¿½è¸ªç³»ç»Ÿçš„é«˜ç²¾åº¦è®¾ç½®ä½¿å¾—æœ«ç«¯æ‰§è¡Œå™¨çš„å§¿æ€æ•æ‰æ›´åŠ å‡†ç¡®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

FreeTacManåœ¨æ•°æ®æ”¶é›†æ€§èƒ½ä¸Šå®ç°äº†æ˜¾è‘—æå‡ï¼Œæ”¶é›†äº†è¶…è¿‡300ä¸‡å¯¹è§†è§‰-è§¦è§‰å›¾åƒå’Œ10,000æ¡ç¤ºèŒƒè½¨è¿¹ï¼Œæ”¯æŒ50ç§æ¥è§¦ä¸°å¯Œæ“ä½œä»»åŠ¡ï¼Œæå¤§åœ°ä¸°å¯Œäº†ç°æœ‰çš„æ•°æ®é›†ï¼Œä¸ºåç»­çš„ç­–ç•¥å­¦ä¹ æä¾›äº†åšå®åŸºç¡€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FreeTacMançš„ç ”ç©¶æˆæœåœ¨æœºå™¨äººæ“ä½œã€æ™ºèƒ½åˆ¶é€ å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æä¾›é«˜è´¨é‡çš„å¤šæ¨¡æ€æ•°æ®é›†ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿä¿ƒè¿›æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å­¦ä¹ ä¸é€‚åº”ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Enabling robots with contact-rich manipulation remains a pivotal challenge in robot learning, which is substantially hindered by the data collection gap, including its inefficiency and limited sensor setup. While prior work has explored handheld paradigms, their rod-based mechanical structures remain rigid and unintuitive, providing limited tactile feedback and posing challenges for human operators. Motivated by the dexterity and force feedback of human motion, we propose FreeTacMan, a human-centric and robot-free data collection system for accurate and efficient robot manipulation. Concretely, we design a wearable gripper with dual visuo-tactile sensors for data collection, which can be worn by human fingers for intuitive control. A high-precision optical tracking system is introduced to capture end-effector poses while synchronizing visual and tactile feedback simultaneously. We leverage FreeTacMan to collect a large-scale multimodal dataset, comprising over 3000k paired visual-tactile images with end-effector poses, 10k demonstration trajectories across 50 diverse contact-rich manipulation tasks. FreeTacMan achieves multiple improvements in data collection performance compared to prior works, and enables effective policy learning for contact-rich manipulation tasks with self-collected dataset. The full suite of hardware specifications and the dataset will be released to facilitate reproducibility and support research in visuo-tactile manipulation.

