---
layout: default
title: Hierarchical Intention-Aware Expressive Motion Generation for Humanoid Robots
---

# Hierarchical Intention-Aware Expressive Motion Generation for Humanoid Robots

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.01563" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.01563v4</a>
  <a href="https://arxiv.org/pdf/2506.01563.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.01563v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.01563v4', 'Hierarchical Intention-Aware Expressive Motion Generation for Humanoid Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lingfan Bao, Yan Pan, Tianhu Peng, Dimitrios Kanoulas, Chengxu Zhou

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-02 (æ›´æ–°: 2025-09-27)

**å¤‡æ³¨**: 7 pages, 2 figures, IEEE conference paper

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå±‚æ¬¡åŒ–æ„å›¾æ„ŸçŸ¥çš„ç”ŸåŠ¨åŠ¨ä½œç”Ÿæˆæ¡†æ¶ä»¥æå‡äººæœºäº¤äº’**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `äººæœºäº¤äº’` `æ„å›¾æ„ŸçŸ¥` `åŠ¨ä½œç”Ÿæˆ` `æ‰©æ•£æ¨¡å‹` `å±‚æ¬¡åŒ–æ¡†æ¶` `ç¤¾äº¤é€‚åº”æ€§` `å®æ—¶å“åº”`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„äººæœºäº¤äº’æ–¹æ³•å¾€å¾€ä¾èµ–äºå›ºå®šçš„åŠ¨ä½œåº“æˆ–å¤æ‚çš„ç”Ÿæˆæ¨¡å‹ï¼Œå¯¼è‡´å®æ—¶æ€§å’Œçµæ´»æ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºçš„å±‚æ¬¡åŒ–æ¡†æ¶ç»“åˆäº†æ„å›¾æ„ŸçŸ¥æ¨ç†å’ŒåŸºäºæ‰©æ•£æ¨¡å‹çš„å®æ—¶åŠ¨ä½œç”Ÿæˆï¼Œæå‡äº†äº¤äº’çš„è‡ªç„¶æ€§å’Œé€‚åº”æ€§ã€‚
3. åœ¨ç‰©ç†å¹³å°ä¸Šçš„å®éªŒéªŒè¯æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨çœŸå®åœºæ™¯ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§å’Œç¤¾ä¼šé€‚åº”æ€§ï¼Œæ˜¾è‘—æå‡äº†äººæœºäº¤äº’çš„æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ‰æ•ˆçš„äººæœºäº¤äº’è¦æ±‚æœºå™¨äººå®æ—¶è¯†åˆ«äººçš„æ„å›¾å¹¶ç”Ÿæˆç”ŸåŠ¨ã€ç¤¾ä¼šé€‚å®œçš„åŠ¨ä½œã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–å›ºå®šçš„åŠ¨ä½œåº“æˆ–è®¡ç®—æˆæœ¬é«˜æ˜‚çš„ç”Ÿæˆæ¨¡å‹ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å±‚æ¬¡åŒ–æ¡†æ¶ï¼Œç»“åˆäº†ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰çš„æ„å›¾æ„ŸçŸ¥æ¨ç†ä¸åŸºäºæ‰©æ•£æ¨¡å‹çš„å®æ—¶åŠ¨ä½œç”Ÿæˆã€‚è¯¥ç³»ç»Ÿå¼•å…¥äº†ç»“æ„åŒ–æç¤ºã€ç½®ä¿¡è¯„åˆ†ã€åå¤‡è¡Œä¸ºå’Œç¤¾ä¼šä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼Œä»¥å®ç°æ„å›¾çš„ç»†åŒ–å’Œè‡ªé€‚åº”å“åº”ã€‚é€šè¿‡åˆ©ç”¨å¤§è§„æ¨¡åŠ¨ä½œæ•°æ®é›†å’Œé«˜æ•ˆçš„æ½œåœ¨ç©ºé—´å»å™ªï¼Œè¯¥æ¡†æ¶ç”Ÿæˆå¤šæ ·ä¸”ç‰©ç†ä¸Šåˆç†çš„æ‰‹åŠ¿ï¼Œé€‚ç”¨äºåŠ¨æ€çš„äººå½¢äº¤äº’ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç°å®åœºæ™¯ä¸­å±•ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§å’Œç¤¾ä¼šé€‚åº”æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººåœ¨åŠ¨æ€äººæœºäº¤äº’ä¸­å®æ—¶è¯†åˆ«æ„å›¾å’Œç”Ÿæˆé€‚å½“åŠ¨ä½œçš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ç¼ºä¹çµæ´»æ€§å’Œå®æ—¶æ€§ï¼Œéš¾ä»¥é€‚åº”å¤æ‚çš„ç¤¾äº¤åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„å±‚æ¬¡åŒ–æ¡†æ¶é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰å®ç°æ„å›¾æ„ŸçŸ¥æ¨ç†ï¼Œå¹¶ç»“åˆæ‰©æ•£æ¨¡å‹è¿›è¡Œå®æ—¶åŠ¨ä½œç”Ÿæˆï¼Œä»¥æé«˜æœºå™¨äººçš„äº¤äº’èƒ½åŠ›å’Œç¤¾ä¼šé€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…æ‹¬æ„å›¾æ„ŸçŸ¥æ¨¡å—ã€åŠ¨ä½œç”Ÿæˆæ¨¡å—å’Œåé¦ˆæœºåˆ¶ã€‚æ„å›¾æ„ŸçŸ¥æ¨¡å—é€šè¿‡ç»“æ„åŒ–æç¤ºå’Œç½®ä¿¡è¯„åˆ†æ¥ç»†åŒ–ç”¨æˆ·æ„å›¾ï¼ŒåŠ¨ä½œç”Ÿæˆæ¨¡å—åˆ™åˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¤šæ ·çš„æ‰‹åŠ¿ï¼Œåé¦ˆæœºåˆ¶ç¡®ä¿æœºå™¨äººèƒ½å¤Ÿæ ¹æ®ç¤¾äº¤ä¸Šä¸‹æ–‡è¿›è¡Œè‡ªé€‚åº”å“åº”ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºå°†æ„å›¾æ„ŸçŸ¥ä¸åŠ¨ä½œç”Ÿæˆç›¸ç»“åˆï¼Œå½¢æˆä¸€ä¸ªå±‚æ¬¡åŒ–çš„æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†æœºå™¨äººåœ¨å¤æ‚ç¤¾äº¤åœºæ™¯ä¸­çš„è¡¨ç°ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå®æ—¶ç”Ÿæˆæ›´ä¸ºè‡ªç„¶å’Œé€‚å®œçš„åŠ¨ä½œã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†é«˜æ•ˆçš„æ½œåœ¨ç©ºé—´å»å™ªæŠ€æœ¯ï¼Œç¡®ä¿ç”Ÿæˆçš„åŠ¨ä½œåœ¨ç‰©ç†ä¸Šåˆç†ã€‚æ­¤å¤–ï¼Œç½®ä¿¡è¯„åˆ†å’Œåå¤‡è¡Œä¸ºçš„å¼•å…¥ä½¿å¾—æœºå™¨äººèƒ½å¤Ÿåœ¨ä¸ç¡®å®šæƒ…å†µä¸‹åšå‡ºæ›´ä¸ºåˆç†çš„ååº”ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨çœŸå®åœºæ™¯ä¸­å±•ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§å’Œç¤¾ä¼šé€‚åº”æ€§ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œç”Ÿæˆçš„åŠ¨ä½œåœ¨è‡ªç„¶æ€§å’Œé€‚å®œæ€§ä¸Šæœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®å°šæœªæŠ«éœ²ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœåŠ¡æœºå™¨äººã€ç¤¾äº¤æœºå™¨äººå’Œå¨±ä¹æœºå™¨äººç­‰ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æœºå™¨äººåœ¨å¤æ‚ç¤¾äº¤åœºæ™¯ä¸­çš„äº¤äº’èƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶æœ‰æœ›æ¨åŠ¨äººæœºäº¤äº’æŠ€æœ¯çš„å‘å±•ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ›´è‡ªç„¶åœ°èå…¥äººç±»ç¤¾ä¼šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Effective human-robot interaction requires robots to identify human intentions and generate expressive, socially appropriate motions in real-time. Existing approaches often rely on fixed motion libraries or computationally expensive generative models. We propose a hierarchical framework that combines intention-aware reasoning via in-context learning (ICL) with real-time motion generation using diffusion models. Our system introduces structured prompting with confidence scoring, fallback behaviors, and social context awareness to enable intention refinement and adaptive response. Leveraging large-scale motion datasets and efficient latent-space denoising, the framework generates diverse, physically plausible gestures suitable for dynamic humanoid interactions. Experimental validation on a physical platform demonstrates the robustness and social alignment of our method in realistic scenarios.

