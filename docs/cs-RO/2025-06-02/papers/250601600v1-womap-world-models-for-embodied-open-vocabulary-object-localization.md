---
layout: default
title: WoMAP: World Models For Embodied Open-Vocabulary Object Localization
---

# WoMAP: World Models For Embodied Open-Vocabulary Object Localization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.01600" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.01600v1</a>
  <a href="https://arxiv.org/pdf/2506.01600.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.01600v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.01600v1', 'WoMAP: World Models For Embodied Open-Vocabulary Object Localization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tenny Yin, Zhiting Mei, Tao Sun, Lihan Zha, Emily Zhou, Jeremy Bao, Miyu Yamane, Ola Shorinwa, Anirudha Majumdar

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-02

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWoMAPä»¥è§£å†³æœºå™¨äººå¼€æ”¾è¯æ±‡ç‰©ä½“å®šä½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å¼€æ”¾è¯æ±‡å®šä½` `ä¸»åŠ¨æ„ŸçŸ¥` `é«˜æ–¯ç‚¹äº‘` `ç‰©ä½“æ£€æµ‹` `æ½œåœ¨ä¸–ç•Œæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¼€æ”¾è¯æ±‡ç‰©ä½“å®šä½ä¸­éš¾ä»¥è¶…è¶Šæ¼”ç¤ºæ•°æ®é›†ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. WoMAPé€šè¿‡é«˜æ–¯ç‚¹äº‘ç”Ÿæˆæ•°æ®ï¼Œæå–å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨çš„å¥–åŠ±ä¿¡å·ï¼Œå¹¶åˆ©ç”¨æ½œåœ¨ä¸–ç•Œæ¨¡å‹è¿›è¡ŒåŠ¨æ€é¢„æµ‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWoMAPåœ¨é›¶-shotç‰©ä½“å®šä½ä»»åŠ¡ä¸­æˆåŠŸç‡æ˜¾è‘—æé«˜ï¼Œè¶…è¶Šäº†ç°æœ‰åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯­è¨€æŒ‡å¯¼çš„ä¸»åŠ¨ç‰©ä½“å®šä½æ˜¯æœºå™¨äººé¢ä¸´çš„ä¸€é¡¹é‡è¦æŒ‘æˆ˜ï¼Œè¦æ±‚åœ¨éƒ¨åˆ†å¯è§‚å¯Ÿç¯å¢ƒä¸­é«˜æ•ˆæ¢ç´¢ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨è¶…è¶Šæ¼”ç¤ºæ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ä¸Šå­˜åœ¨å›°éš¾ï¼Œæˆ–æ— æ³•ç”Ÿæˆç‰©ç†ä¸Šåˆç†çš„åŠ¨ä½œã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†WoMAPï¼ˆä¸–ç•Œæ¨¡å‹ç”¨äºä¸»åŠ¨æ„ŸçŸ¥ï¼‰ï¼šä¸€ç§è®­ç»ƒå¼€æ”¾è¯æ±‡ç‰©ä½“å®šä½ç­–ç•¥çš„æ–¹æ³•ï¼Œé‡‡ç”¨åŸºäºé«˜æ–¯ç‚¹äº‘çš„çœŸå®åˆ°æ¨¡æ‹Ÿå†åˆ°çœŸå®çš„ç®¡é“ï¼Œèƒ½å¤Ÿåœ¨ä¸éœ€è¦ä¸“å®¶æ¼”ç¤ºçš„æƒ…å†µä¸‹è¿›è¡Œå¯æ‰©å±•çš„æ•°æ®ç”Ÿæˆï¼Œå¹¶ä»å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨ä¸­æå–å¯†é›†å¥–åŠ±ä¿¡å·ï¼ŒåŒæ—¶åˆ©ç”¨æ½œåœ¨ä¸–ç•Œæ¨¡å‹è¿›è¡ŒåŠ¨æ€å’Œå¥–åŠ±é¢„æµ‹ï¼Œä»¥åœ¨æ¨ç†æ—¶ä¸ºé«˜å±‚æ¬¡åŠ¨ä½œææ¡ˆæä¾›åŸºç¡€ã€‚ä¸¥æ ¼çš„ä»¿çœŸå’Œç¡¬ä»¶å®éªŒè¡¨æ˜ï¼ŒWoMAPåœ¨å¹¿æ³›çš„é›¶-shotç‰©ä½“å®šä½ä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šï¼ŒæˆåŠŸç‡æ¯”VLMå’Œæ‰©æ•£ç­–ç•¥åŸºçº¿åˆ†åˆ«é«˜å‡º9å€å’Œ2å€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†WoMAPåœ¨TidyBotä¸Šçš„å¼ºæ³›åŒ–èƒ½åŠ›å’Œæ¨¡æ‹Ÿåˆ°çœŸå®çš„è¿ç§»æ•ˆæœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººåœ¨å¼€æ”¾è¯æ±‡ç‰©ä½“å®šä½ä¸­çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•å¦‚æ¨¡ä»¿å­¦ä¹ å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰åœ¨æ³›åŒ–å’Œç”Ÿæˆç‰©ç†åˆç†åŠ¨ä½œæ–¹é¢å­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šWoMAPæå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒæ¡†æ¶ï¼Œç»“åˆé«˜æ–¯ç‚¹äº‘ç”Ÿæˆã€å¥–åŠ±ä¿¡å·æå–å’Œæ½œåœ¨ä¸–ç•Œæ¨¡å‹ï¼Œæ—¨åœ¨æé«˜ç‰©ä½“å®šä½çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) é«˜æ–¯ç‚¹äº‘ç”Ÿæˆæ¨¡å—ç”¨äºæ•°æ®ç”Ÿæˆï¼›2) å¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹å™¨æå–å¥–åŠ±ä¿¡å·ï¼›3) æ½œåœ¨ä¸–ç•Œæ¨¡å‹ç”¨äºåŠ¨æ€å’Œå¥–åŠ±é¢„æµ‹ï¼Œç¡®ä¿é«˜å±‚æ¬¡åŠ¨ä½œçš„ç‰©ç†åˆç†æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šWoMAPçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶æ— éœ€ä¸“å®¶æ¼”ç¤ºçš„å¯æ‰©å±•æ•°æ®ç”Ÿæˆèƒ½åŠ›ï¼Œä»¥åŠé€šè¿‡æ½œåœ¨ä¸–ç•Œæ¨¡å‹å®ç°çš„åŠ¨æ€å’Œå¥–åŠ±é¢„æµ‹ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„ä¾èµ–äºæ¼”ç¤ºæ•°æ®çš„æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒWoMAPä¼˜åŒ–äº†é«˜æ–¯ç‚¹äº‘ç”Ÿæˆçš„å‚æ•°ï¼Œå¹¶è®¾è®¡äº†é€‚åˆå¼€æ”¾è¯æ±‡ç‰©ä½“æ£€æµ‹çš„æŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ ç‰©ä½“å®šä½çš„ç­–ç•¥ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œè®­ç»ƒç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒWoMAPåœ¨é›¶-shotç‰©ä½“å®šä½ä»»åŠ¡ä¸­çš„æˆåŠŸç‡æ¯”VLMé«˜å‡º9å€ï¼Œæ¯”æ‰©æ•£ç­–ç•¥åŸºçº¿é«˜å‡º2å€ï¼Œå±•ç¤ºäº†å…¶åœ¨å¼€æ”¾è¯æ±‡ç‰©ä½“å®šä½ä¸­çš„æ˜¾è‘—ä¼˜åŠ¿å’Œå¼ºæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

WoMAPçš„ç ”ç©¶æˆæœåœ¨æœºå™¨äººè‡ªä¸»å¯¼èˆªã€æ™ºèƒ½å®¶å±…ã€ä»“å‚¨è‡ªåŠ¨åŒ–ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„ç‰©ä½“å®šä½èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡å…¶è‡ªä¸»å†³ç­–å’Œæ‰§è¡Œä»»åŠ¡çš„æ•ˆç‡ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Language-instructed active object localization is a critical challenge for robots, requiring efficient exploration of partially observable environments. However, state-of-the-art approaches either struggle to generalize beyond demonstration datasets (e.g., imitation learning methods) or fail to generate physically grounded actions (e.g., VLMs). To address these limitations, we introduce WoMAP (World Models for Active Perception): a recipe for training open-vocabulary object localization policies that: (i) uses a Gaussian Splatting-based real-to-sim-to-real pipeline for scalable data generation without the need for expert demonstrations, (ii) distills dense rewards signals from open-vocabulary object detectors, and (iii) leverages a latent world model for dynamics and rewards prediction to ground high-level action proposals at inference time. Rigorous simulation and hardware experiments demonstrate WoMAP's superior performance in a broad range of zero-shot object localization tasks, with more than 9x and 2x higher success rates compared to VLM and diffusion policy baselines, respectively. Further, we show that WoMAP achieves strong generalization and sim-to-real transfer on a TidyBot.

