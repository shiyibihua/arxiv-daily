---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-06-02
---

# cs.ROï¼ˆ2025-06-02ï¼‰

ğŸ“Š å…± **17** ç¯‡è®ºæ–‡
 | ğŸ”— **5** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (13 ğŸ”—3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (13 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250602206v1-reinforcement-learning-with-data-bootstrapping-for-dynamic-subgoal-p.html">Reinforcement Learning with Data Bootstrapping for Dynamic Subgoal Pursuit in Humanoid Robot Navigation</a></td>
  <td>æå‡ºåŠ¨æ€å­ç›®æ ‡è¿½è¸ªæ–¹æ³•ä»¥è§£å†³äººå½¢æœºå™¨äººå¯¼èˆªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">bipedal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.02206v1" data-paper-url="./papers/250602206v1-reinforcement-learning-with-data-bootstrapping-for-dynamic-subgoal-p.html" onclick="toggleFavorite(this, '2506.02206v1', 'Reinforcement Learning with Data Bootstrapping for Dynamic Subgoal Pursuit in Humanoid Robot Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250601600v1-womap-world-models-for-embodied-open-vocabulary-object-localization.html">WoMAP: World Models For Embodied Open-Vocabulary Object Localization</a></td>
  <td>æå‡ºWoMAPä»¥è§£å†³æœºå™¨äººå¼€æ”¾è¯æ±‡ç‰©ä½“å®šä½é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span> <span class="paper-tag">imitation learning</span> <span class="paper-tag">diffusion policy</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01600v1" data-paper-url="./papers/250601600v1-womap-world-models-for-embodied-open-vocabulary-object-localization.html" onclick="toggleFavorite(this, '2506.01600v1', 'WoMAP: World Models For Embodied Open-Vocabulary Object Localization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250601563v4-hierarchical-intention-aware-expressive-motion-generation-for-humano.html">Hierarchical Intention-Aware Expressive Motion Generation for Humanoid Robots</a></td>
  <td>æå‡ºå±‚æ¬¡åŒ–æ„å›¾æ„ŸçŸ¥çš„ç”ŸåŠ¨åŠ¨ä½œç”Ÿæˆæ¡†æ¶ä»¥æå‡äººæœºäº¤äº’</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">motion generation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01563v4" data-paper-url="./papers/250601563v4-hierarchical-intention-aware-expressive-motion-generation-for-humano.html" onclick="toggleFavorite(this, '2506.01563v4', 'Hierarchical Intention-Aware Expressive Motion Generation for Humanoid Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250601953v1-fast-in-slow-a-dual-system-foundation-model-unifying-fast-manipulati.html">Fast-in-Slow: A Dual-System Foundation Model Unifying Fast Manipulation within Slow Reasoning</a></td>
  <td>æå‡ºFast-in-Slowæ¨¡å‹ä»¥è§£å†³æœºå™¨äººæ“æ§ä¸­çš„æ‰§è¡Œé¢‘ç‡ä¸æ¨ç†æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01953v1" data-paper-url="./papers/250601953v1-fast-in-slow-a-dual-system-foundation-model-unifying-fast-manipulati.html" onclick="toggleFavorite(this, '2506.01953v1', 'Fast-in-Slow: A Dual-System Foundation Model Unifying Fast Manipulation within Slow Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250602286v2-efficient-manipulation-enhanced-semantic-mapping-with-uncertainty-in.html">Efficient Manipulation-Enhanced Semantic Mapping With Uncertainty-Informed Action Selection</a></td>
  <td>æå‡ºåŸºäºæ“ä½œå¢å¼ºçš„è¯­ä¹‰æ˜ å°„æ¡†æ¶ä»¥è§£å†³ä¸ç¡®å®šæ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">semantic mapping</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.02286v2" data-paper-url="./papers/250602286v2-efficient-manipulation-enhanced-semantic-mapping-with-uncertainty-in.html" onclick="toggleFavorite(this, '2506.02286v2', 'Efficient Manipulation-Enhanced Semantic Mapping With Uncertainty-Informed Action Selection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250601756v1-learning-with-pycub-a-new-simulation-and-exercise-framework-for-huma.html">Learning with pyCub: A New Simulation and Exercise Framework for Humanoid Robotics</a></td>
  <td>æå‡ºpyCubæ¡†æ¶ä»¥ç®€åŒ–äººå½¢æœºå™¨äººæ•™å­¦ä¸ä»¿çœŸ</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01756v1" data-paper-url="./papers/250601756v1-learning-with-pycub-a-new-simulation-and-exercise-framework-for-huma.html" onclick="toggleFavorite(this, '2506.01756v1', 'Learning with pyCub: A New Simulation and Exercise Framework for Humanoid Robotics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250601362v1-generating-diverse-challenging-terrains-for-legged-robots-using-qual.html">Generating Diverse Challenging Terrains for Legged Robots Using Quality-Diversity Algorithm</a></td>
  <td>æå‡ºè´¨é‡å¤šæ ·æ€§ç®—æ³•ç”Ÿæˆå¤šæ ·åŒ–æŒ‘æˆ˜åœ°å½¢ä»¥æµ‹è¯•å››è¶³æœºå™¨äºº</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">legged robot</span> <span class="paper-tag">bipedal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01362v1" data-paper-url="./papers/250601362v1-generating-diverse-challenging-terrains-for-legged-robots-using-qual.html" onclick="toggleFavorite(this, '2506.01362v1', 'Generating Diverse Challenging Terrains for Legged Robots Using Quality-Diversity Algorithm')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250601941v2-freetacman-robot-free-visuo-tactile-data-collection-system-for-conta.html">FreeTacMan: Robot-free Visuo-Tactile Data Collection System for Contact-rich Manipulation</a></td>
  <td>æå‡ºFreeTacManä»¥è§£å†³æœºå™¨äººæ¥è§¦ä¸°å¯Œæ“ä½œçš„æ•°æ®æ”¶é›†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">policy learning</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01941v2" data-paper-url="./papers/250601941v2-freetacman-robot-free-visuo-tactile-data-collection-system-for-conta.html" onclick="toggleFavorite(this, '2506.01941v2', 'FreeTacMan: Robot-free Visuo-Tactile Data Collection System for Contact-rich Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250601759v2-adept-adaptive-diffusion-environment-for-policy-transfer-sim-to-real.html">ADEPT: Adaptive Diffusion Environment for Policy Transfer Sim-to-Real</a></td>
  <td>æå‡ºADEPTä»¥è§£å†³æ¨¡æ‹Ÿåˆ°ç°å®ä¸­çš„æ”¿ç­–è½¬ç§»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01759v2" data-paper-url="./papers/250601759v2-adept-adaptive-diffusion-environment-for-policy-transfer-sim-to-real.html" onclick="toggleFavorite(this, '2506.01759v2', 'ADEPT: Adaptive Diffusion Environment for Policy Transfer Sim-to-Real')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250602169v2-lol-nmpc-low-level-dynamics-integration-in-nonlinear-model-predictiv.html">LoL-NMPC: Low-Level Dynamics Integration in Nonlinear Model Predictive Control for Unmanned Aerial Vehicles</a></td>
  <td>æå‡ºLoL-NMPCä»¥è§£å†³æ— äººæœºé«˜é€Ÿåº¦è½¨è¿¹è·Ÿè¸ªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">model predictive control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.02169v2" data-paper-url="./papers/250602169v2-lol-nmpc-low-level-dynamics-integration-in-nonlinear-model-predictiv.html" onclick="toggleFavorite(this, '2506.02169v2', 'LoL-NMPC: Low-Level Dynamics Integration in Nonlinear Model Predictive Control for Unmanned Aerial Vehicles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250601583v2-freqpolicy-frequency-autoregressive-visuomotor-policy-with-continuou.html">FreqPolicy: Frequency Autoregressive Visuomotor Policy with Continuous Tokens</a></td>
  <td>æå‡ºFreqPolicyä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­çš„åŠ¨ä½œè¡¨ç¤ºä¸æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">policy learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01583v2" data-paper-url="./papers/250601583v2-freqpolicy-frequency-autoregressive-visuomotor-policy-with-continuou.html" onclick="toggleFavorite(this, '2506.01583v2', 'FreqPolicy: Frequency Autoregressive Visuomotor Policy with Continuous Tokens')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250601944v1-feel-the-force-contact-driven-learning-from-humans.html">Feel the Force: Contact-Driven Learning from Humans</a></td>
  <td>æå‡ºFeelTheForceä»¥è§£å†³æœºå™¨äººç²¾ç»†åŠ›æ§åˆ¶é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01944v1" data-paper-url="./papers/250601944v1-feel-the-force-contact-driven-learning-from-humans.html" onclick="toggleFavorite(this, '2506.01944v1', 'Feel the Force: Contact-Driven Learning from Humans')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250601418v1-semnav-a-semantic-segmentation-driven-approach-to-visual-semantic-na.html">SEMNAV: A Semantic Segmentation-Driven Approach to Visual Semantic Navigation</a></td>
  <td>æå‡ºSEMNAVä»¥è§£å†³è§†è§‰è¯­ä¹‰å¯¼èˆªä¸­çš„é¢†åŸŸé€‚åº”é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01418v1" data-paper-url="./papers/250601418v1-semnav-a-semantic-segmentation-driven-approach-to-visual-semantic-na.html" onclick="toggleFavorite(this, '2506.01418v1', 'SEMNAV: A Semantic Segmentation-Driven Approach to Visual Semantic Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>14</td>
  <td><a href="./papers/250601538v2-lamarl-llm-aided-multi-agent-reinforcement-learning-for-cooperative-.html">LAMARL: LLM-Aided Multi-Agent Reinforcement Learning for Cooperative Policy Generation</a></td>
  <td>æå‡ºLAMARLä»¥è§£å†³å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„æ ·æœ¬æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01538v2" data-paper-url="./papers/250601538v2-lamarl-llm-aided-multi-agent-reinforcement-learning-for-cooperative-.html" onclick="toggleFavorite(this, '2506.01538v2', 'LAMARL: LLM-Aided Multi-Agent Reinforcement Learning for Cooperative Policy Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250601628v2-a-hierarchical-bin-packing-framework-with-dual-manipulators-via-heur.html">A Hierarchical Bin Packing Framework with Dual Manipulators via Heuristic Search and Deep Reinforcement Learning</a></td>
  <td>æå‡ºåˆ†å±‚è£…ç®±æ¡†æ¶ä»¥è§£å†³åŒæ“çºµå™¨çš„è£…ç®±é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01628v2" data-paper-url="./papers/250601628v2-a-hierarchical-bin-packing-framework-with-dual-manipulators-via-heur.html" onclick="toggleFavorite(this, '2506.01628v2', 'A Hierarchical Bin Packing Framework with Dual Manipulators via Heuristic Search and Deep Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250601392v1-sparse-imagination-for-efficient-visual-world-model-planning.html">Sparse Imagination for Efficient Visual World Model Planning</a></td>
  <td>æå‡ºç¨€ç–æƒ³è±¡ä»¥è§£å†³è§†è§‰ä¸–ç•Œæ¨¡å‹è§„åˆ’ä¸­çš„è®¡ç®—æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">world model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01392v1" data-paper-url="./papers/250601392v1-sparse-imagination-for-efficient-visual-world-model-planning.html" onclick="toggleFavorite(this, '2506.01392v1', 'Sparse Imagination for Efficient Visual World Model Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/250601950v4-dualmap-online-open-vocabulary-semantic-mapping-for-natural-language.html">DualMap: Online Open-Vocabulary Semantic Mapping for Natural Language Navigation in Dynamic Changing Scenes</a></td>
  <td>æå‡ºDualMapä»¥è§£å†³åŠ¨æ€ç¯å¢ƒä¸­çš„è‡ªç„¶è¯­è¨€å¯¼èˆªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">semantic mapping</span> <span class="paper-tag">semantic map</span> <span class="paper-tag">open-vocabulary</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.01950v4" data-paper-url="./papers/250601950v4-dualmap-online-open-vocabulary-semantic-mapping-for-natural-language.html" onclick="toggleFavorite(this, '2506.01950v4', 'DualMap: Online Open-Vocabulary Semantic Mapping for Natural Language Navigation in Dynamic Changing Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)