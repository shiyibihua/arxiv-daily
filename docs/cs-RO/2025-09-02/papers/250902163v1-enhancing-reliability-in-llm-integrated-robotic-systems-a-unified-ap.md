---
layout: default
title: Enhancing Reliability in LLM-Integrated Robotic Systems: A Unified Approach to Security and Safety
---

# Enhancing Reliability in LLM-Integrated Robotic Systems: A Unified Approach to Security and Safety

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.02163" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.02163v1</a>
  <a href="https://arxiv.org/pdf/2509.02163.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.02163v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.02163v1', 'Enhancing Reliability in LLM-Integrated Robotic Systems: A Unified Approach to Security and Safety')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenxiao Zhang, Xiangrui Kong, Conan Dewitt, Thomas BrÃ¤unl, Jin B. Hong

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-02

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€æ¡†æ¶ï¼Œæå‡LLMé›†æˆæœºå™¨äººåœ¨å®‰å…¨å’Œå¤æ‚ç¯å¢ƒä¸‹çš„å¯é æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `LLMé›†æˆæœºå™¨äºº` `å®‰å…¨æ€§` `å¯é æ€§` `æç¤ºæ³¨å…¥æ”»å‡»` `å®‰å…¨éªŒè¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMé›†æˆæœºå™¨äººç³»ç»Ÿåœ¨å¯¹æŠ—æ”»å‡»å’Œå¤æ‚ç¯å¢ƒä¸­é¢ä¸´å®‰å…¨æ€§å’Œå¯é æ€§æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºç»Ÿä¸€æ¡†æ¶ï¼Œç»“åˆæç¤ºç»„è£…ã€çŠ¶æ€ç®¡ç†å’Œå®‰å…¨éªŒè¯ï¼Œæå‡ç³»ç»Ÿå®‰å…¨æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¯¹æŠ—æ”»å‡»å’Œå¤æ‚ç¯å¢ƒä¸­æ˜¾è‘—æå‡äº†LLMé›†æˆæœºå™¨äººçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é›†æˆæœºå™¨äººçš„å¯é æ€§ï¼ŒåŒ…æ‹¬é˜²å¾¡å¯¹æŠ—æ”»å‡»çš„å®‰å…¨æ€§å’Œåœ¨å¤æ‚ç¯å¢ƒä¸­è¿è¡Œçš„å®‰å…¨æ€§ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“åˆæç¤ºç»„è£…ã€çŠ¶æ€ç®¡ç†å’Œå®‰å…¨éªŒè¯æœºåˆ¶ï¼Œç¼“è§£æç¤ºæ³¨å…¥æ”»å‡»ï¼ŒåŒæ—¶ç¡®ä¿æ“ä½œå®‰å…¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ³¨å…¥æ”»å‡»ä¸‹æ€§èƒ½æå‡äº†30.8%ï¼Œåœ¨å¯¹æŠ—æ¡ä»¶ä¸‹å¤æ‚ç¯å¢ƒè®¾ç½®ä¸­æ€§èƒ½æå‡é«˜è¾¾325%ã€‚è¿™é¡¹å·¥ä½œå¼¥åˆäº†åŸºäºLLMçš„æœºå™¨äººç³»ç»Ÿä¸­å®‰å…¨æ€§å’Œå®‰å…¨æ€§ä¹‹é—´çš„å·®è·ï¼Œä¸ºåœ¨å®é™…ç¯å¢ƒä¸­éƒ¨ç½²å¯é çš„LLMé›†æˆç§»åŠ¨æœºå™¨äººæä¾›äº†å¯æ“ä½œçš„è§è§£ã€‚è¯¥æ¡†æ¶å·²å¼€æºï¼Œå¹¶æä¾›æ¨¡æ‹Ÿå’Œç‰©ç†éƒ¨ç½²æ¼”ç¤ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é›†æˆåˆ°æœºå™¨äººç³»ç»Ÿä¸­æ—¶ï¼Œé¢ä¸´çš„å®‰å…¨æ€§å’Œå¯é æ€§é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œç°æœ‰æ–¹æ³•å®¹æ˜“å—åˆ°æç¤ºæ³¨å…¥æ”»å‡»ï¼Œå¹¶ä¸”åœ¨å¤æ‚ç¯å¢ƒä¸­éš¾ä»¥ä¿è¯æ“ä½œå®‰å…¨ã€‚è¿™äº›é—®é¢˜é™åˆ¶äº†LLMé›†æˆæœºå™¨äººåœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼ŒåŒæ—¶è§£å†³å®‰å…¨æ€§å’Œå®‰å…¨æ€§é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡æ§åˆ¶LLMçš„è¾“å…¥ï¼ˆæç¤ºç»„è£…ï¼‰ï¼Œç®¡ç†æœºå™¨äººçŠ¶æ€ï¼Œå¹¶è¿›è¡Œå®‰å…¨éªŒè¯ï¼Œä»è€Œæé«˜ç³»ç»Ÿçš„æ•´ä½“å¯é æ€§ã€‚è¿™ç§ç»Ÿä¸€çš„æ–¹æ³•æ—¨åœ¨å¼¥åˆå®‰å…¨å’Œå®‰å…¨ä¹‹é—´çš„å·®è·ï¼Œæä¾›æ›´é²æ£’çš„LLMé›†æˆæœºå™¨äººç³»ç»Ÿã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæç¤ºç»„è£…ï¼ˆPrompt Assemblingï¼‰ã€çŠ¶æ€ç®¡ç†ï¼ˆState Managementï¼‰å’Œå®‰å…¨éªŒè¯ï¼ˆSafety Validationï¼‰ã€‚æç¤ºç»„è£…æ¨¡å—è´Ÿè´£æ„å»ºå®‰å…¨ä¸”æœ‰æ•ˆçš„æç¤ºï¼Œä»¥å‡å°‘æç¤ºæ³¨å…¥æ”»å‡»çš„é£é™©ã€‚çŠ¶æ€ç®¡ç†æ¨¡å—è·Ÿè¸ªæœºå™¨äººçš„çŠ¶æ€å’Œç¯å¢ƒä¿¡æ¯ï¼Œä¸ºå†³ç­–æä¾›ä¸Šä¸‹æ–‡ã€‚å®‰å…¨éªŒè¯æ¨¡å—åˆ™è´Ÿè´£æ£€æŸ¥æœºå™¨äººçš„åŠ¨ä½œæ˜¯å¦å®‰å…¨ï¼Œé˜²æ­¢å…¶è¿›å…¥å±é™©çŠ¶æ€ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ¡†æ¶çš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»Ÿä¸€æ€§ï¼Œå®ƒå°†å®‰å…¨æ€§å’Œå®‰å…¨æ€§é—®é¢˜è§†ä¸ºä¸€ä¸ªæ•´ä½“ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªç»¼åˆçš„è§£å†³æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶çš„æ¨¡å—åŒ–è®¾è®¡ä½¿å…¶æ˜“äºæ‰©å±•å’Œå®šåˆ¶ï¼Œä»¥é€‚åº”ä¸åŒçš„æœºå™¨äººåº”ç”¨åœºæ™¯ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶æ›´æ³¨é‡æ•´ä½“ç³»ç»Ÿçš„å¯é æ€§ï¼Œè€Œä¸ä»…ä»…æ˜¯å…³æ³¨å•ä¸ªæ–¹é¢çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šæç¤ºç»„è£…æ¨¡å—å¯èƒ½åŒ…å«ä¸€ä¸ªç™½åå•æœºåˆ¶ï¼Œåªå…è®¸ç‰¹å®šçš„æŒ‡ä»¤æˆ–å…³é”®è¯å‡ºç°åœ¨æç¤ºä¸­ã€‚çŠ¶æ€ç®¡ç†æ¨¡å—å¯èƒ½ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢å™¨æˆ–å…¶ä»–çŠ¶æ€ä¼°è®¡æŠ€æœ¯æ¥è·Ÿè¸ªæœºå™¨äººçš„ä½ç½®å’Œå§¿æ€ã€‚å®‰å…¨éªŒè¯æ¨¡å—å¯èƒ½ä½¿ç”¨ç¢°æ’æ£€æµ‹ç®—æ³•æˆ–è§„åˆ™å¼•æ“æ¥åˆ¤æ–­æœºå™¨äººçš„åŠ¨ä½œæ˜¯å¦å®‰å…¨ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç®—æ³•é€‰æ‹©å–å†³äºå…·ä½“çš„åº”ç”¨åœºæ™¯å’Œæœºå™¨äººå¹³å°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æç¤ºæ³¨å…¥æ”»å‡»ä¸‹æ€§èƒ½æå‡äº†30.8%ï¼Œè¡¨æ˜å…¶åœ¨é˜²å¾¡æ¶æ„æ”»å‡»æ–¹é¢å…·æœ‰æ˜¾è‘—æ•ˆæœã€‚åœ¨å¯¹æŠ—æ¡ä»¶ä¸‹ï¼Œå¤æ‚ç¯å¢ƒè®¾ç½®ä¸­æ€§èƒ½æå‡é«˜è¾¾325%ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶åœ¨ä¿è¯æœºå™¨äººå®‰å…¨è¿è¡Œæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™äº›æ•°æ®è¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ˜¾è‘—æé«˜LLMé›†æˆæœºå™¨äººçš„å¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦é«˜å¯é æ€§çš„LLMé›†æˆæœºå™¨äººç³»ç»Ÿï¼Œä¾‹å¦‚ï¼šåœ¨å¤æ‚ç¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡çš„ç§»åŠ¨æœºå™¨äººã€åœ¨å±é™©ç¯å¢ƒä¸­è¿›è¡Œä½œä¸šçš„å·¥ä¸šæœºå™¨äººã€ä»¥åŠä¸ºè€å¹´äººæˆ–æ®‹ç–¾äººæä¾›è¾…åŠ©æœåŠ¡çš„æœåŠ¡æœºå™¨äººã€‚è¯¥æ¡†æ¶çš„å¼€æºå®ç°å¯ä»¥åŠ é€ŸLLMé›†æˆæœºå™¨äººåœ¨å®é™…åœºæ™¯ä¸­çš„éƒ¨ç½²å’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Integrating large language models (LLMs) into robotic systems has revolutionised embodied artificial intelligence, enabling advanced decision-making and adaptability. However, ensuring reliability, encompassing both security against adversarial attacks and safety in complex environments, remains a critical challenge. To address this, we propose a unified framework that mitigates prompt injection attacks while enforcing operational safety through robust validation mechanisms. Our approach combines prompt assembling, state management, and safety validation, evaluated using both performance and security metrics. Experiments show a 30.8% improvement under injection attacks and up to a 325% improvement in complex environment settings under adversarial conditions compared to baseline scenarios. This work bridges the gap between safety and security in LLM-based robotic systems, offering actionable insights for deploying reliable LLM-integrated mobile robots in real-world settings. The framework is open-sourced with simulation and physical deployment demos at https://llmeyesim.vercel.app/

