---
layout: default
title: Acrobotics: A Generalist Approach to Quadrupedal Robots' Parkour
---

# Acrobotics: A Generalist Approach to Quadrupedal Robots' Parkour

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.02727" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.02727v2</a>
  <a href="https://arxiv.org/pdf/2509.02727.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.02727v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.02727v2', 'Acrobotics: A Generalist Approach to Quadrupedal Robots\' Parkour')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Guillaume GagnÃ©-Labelle, Vassil Atanassov, Ioannis Havoutis

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-02 (æ›´æ–°: 2025-09-14)

**å¤‡æ³¨**: Supplementary material can be found here: https://drive.google.com/drive/folders/18h25azbCFfPF4fhSsRfxKrnZo3dPKs_j?usp=sharing

**æœŸåˆŠ**: LNCS, volume 16045, 2025, p.124-138

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Acroboticsï¼šå››è¶³æœºå™¨äººè·‘é…·çš„é€šç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å››è¶³æœºå™¨äºº` `å¼ºåŒ–å­¦ä¹ ` `é€šç”¨ç­–ç•¥` `åŠ¨æ€è¿åŠ¨` `è·‘é…·`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿå››è¶³æœºå™¨äººæ§åˆ¶æ–¹æ³•éš¾ä»¥åº”å¯¹å¤æ‚åœ°å½¢å’ŒåŠ¨æ€è¿åŠ¨ï¼Œæ˜“å—æ»‘å€’å’Œç»Šå€’å½±å“ï¼Œå»ºæ¨¡æˆæœ¬é«˜æ˜‚ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§é€šç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œé€šè¿‡è¯•é”™å­¦ä¹ åŠ¨æ€è¿åŠ¨ç­–ç•¥ï¼Œæ— éœ€æ˜¾å¼å»ºæ¨¡ç¯å¢ƒäº¤äº’ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä»…ç”¨å°‘é‡æ™ºèƒ½ä½“è®­ç»ƒå³å¯åª²ç¾ä¸“å®¶ç­–ç•¥ï¼Œå¹¶æ­ç¤ºäº†é€šç”¨è¿åŠ¨ç­–ç•¥çš„å…³é”®è¦ç´ ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å››è¶³æœºå™¨äººç›¸æ¯”è½®å¼æœºå™¨äººï¼Œåœ¨æ”€çˆ¬ã€è¹²ä¼ã€è·¨è¶Šéšœç¢å’Œä¸Šä¸‹æ¥¼æ¢¯ç­‰æ–¹é¢å…·æœ‰ä¼˜åŠ¿ï¼Œæ›´é€‚åˆåœ¨å´å²–å’Œéç»“æ„åŒ–åœ°å½¢ä¸­å¯¼èˆªã€‚ç„¶è€Œï¼Œæ‰§è¡Œè¿™äº›åŠ¨ä½œéœ€è¦ç²¾ç¡®çš„æ—¶é—´åè°ƒå’Œå¤æ‚çš„äººæœºäº¤äº’ã€‚æ­¤å¤–ï¼Œè¶³å¼è¿åŠ¨å¤©ç”Ÿæ›´å®¹æ˜“æ‰“æ»‘å’Œç»Šå€’ï¼Œå› æ­¤å¯¹è¿™äº›æƒ…å†µè¿›è¡Œå»ºæ¨¡ä»¥è®¾è®¡é²æ£’æ§åˆ¶å™¨çš„ä¼ ç»Ÿæ–¹æ³•å¾ˆå¿«å˜å¾—ä¸åˆ‡å®é™…ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¼ºåŒ–å­¦ä¹ é€šè¿‡è¯•é”™å®ç°æœ€ä¼˜æ§åˆ¶ï¼Œæä¾›äº†ä¸€ä¸ªå¼•äººæ³¨ç›®çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºåŠ¨æ€è¿åŠ¨åœºæ™¯ä¸­å››è¶³æœºå™¨äººçš„é€šç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚æ‰€å­¦ä¹ çš„ç­–ç•¥å¯ä»¥ä¸ä½¿ç”¨ä¸“å®¶æ··åˆæ–¹æ³•è®­ç»ƒçš„æœ€å…ˆè¿›çš„ä¸“å®¶ç­–ç•¥ç›¸åª²ç¾ï¼ŒåŒæ—¶åœ¨è®­ç»ƒæœŸé—´ä»…ä½¿ç”¨ 25% çš„æ™ºèƒ½ä½“æ•°é‡ã€‚æˆ‘ä»¬çš„å®éªŒè¿˜å¼ºè°ƒäº†é€šç”¨è¿åŠ¨ç­–ç•¥çš„å…³é”®ç»„æˆéƒ¨åˆ†ä»¥åŠä¿ƒæˆå…¶æˆåŠŸçš„ä¸»è¦å› ç´ ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å››è¶³æœºå™¨äººåœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­è¿åŠ¨æ§åˆ¶çš„é—®é¢˜ï¼Œä¾‹å¦‚è·‘é…·åŠ¨ä½œã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºäººå·¥è®¾è®¡çš„æ§åˆ¶å™¨æˆ–ä¸“å®¶ç­–ç•¥ï¼Œè¿™äº›æ–¹æ³•æ³›åŒ–èƒ½åŠ›å·®ï¼Œéš¾ä»¥é€‚åº”æ–°çš„ç¯å¢ƒå’Œä»»åŠ¡ï¼Œå¹¶ä¸”éœ€è¦å¤§é‡çš„ä¸“å®¶çŸ¥è¯†å’Œæ‰‹åŠ¨è°ƒæ•´ã€‚æ­¤å¤–ï¼Œè¶³å¼è¿åŠ¨å›ºæœ‰çš„ä¸ç¨³å®šæ€§ï¼ˆå¦‚æ»‘å€’ã€ç»Šå€’ï¼‰ä½¿å¾—ç²¾ç¡®å»ºæ¨¡å˜å¾—å›°éš¾ï¼Œå¯¼è‡´æ§åˆ¶å™¨çš„é²æ£’æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œé€šè¿‡è¯•é”™çš„æ–¹å¼è®©å››è¶³æœºå™¨äººè‡ªä¸»å­¦ä¹ æœ€ä¼˜çš„è¿åŠ¨ç­–ç•¥ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹ç¯å¢ƒå’Œæœºå™¨äººåŠ¨åŠ›å­¦çš„æ˜¾å¼å»ºæ¨¡ï¼Œè€Œæ˜¯é€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’æ¥å­¦ä¹ ï¼Œä»è€Œæé«˜äº†ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚é€šç”¨æ€§ä½“ç°åœ¨ä½¿ç”¨å•ä¸€ç­–ç•¥æ¥å¤„ç†å¤šç§ä¸åŒçš„è¿åŠ¨ä»»åŠ¡ï¼Œè€Œä¸æ˜¯ä¸ºæ¯ä¸ªä»»åŠ¡è®­ç»ƒä¸€ä¸ªç‰¹å®šçš„ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•é‡‡ç”¨äº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒæ¡†æ¶ã€‚å…·ä½“æµç¨‹åŒ…æ‹¬ï¼š1)æ„å»ºä¸€ä¸ªåŒ…å«å„ç§åŠ¨æ€è¿åŠ¨åœºæ™¯çš„æ¨¡æ‹Ÿç¯å¢ƒï¼›2)è®¾è®¡ä¸€ä¸ªå¥–åŠ±å‡½æ•°ï¼Œé¼“åŠ±æœºå™¨äººå®Œæˆç‰¹å®šçš„è¿åŠ¨ä»»åŠ¡ï¼Œä¾‹å¦‚å‰è¿›ã€è½¬å¼¯ã€è·³è·ƒç­‰ï¼›3)ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå…·ä½“ç®—æ³•æœªçŸ¥ï¼Œè®ºæ–‡ä¸­æœªæ˜ç¡®è¯´æ˜ï¼‰è®­ç»ƒä¸€ä¸ªé€šç”¨çš„è¿åŠ¨ç­–ç•¥ï¼›4)å°†è®­ç»ƒå¥½çš„ç­–ç•¥éƒ¨ç½²åˆ°çœŸå®çš„å››è¶³æœºå™¨äººä¸Šè¿›è¡Œæµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§é€šç”¨çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œèƒ½å¤Ÿè®©å››è¶³æœºå™¨äººåœ¨å„ç§åŠ¨æ€è¿åŠ¨åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ã€‚ä¸ä»¥å¾€çš„ä¸“å®¶ç­–ç•¥æˆ–æ··åˆä¸“å®¶ç­–ç•¥ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åªéœ€è¦æ›´å°‘çš„è®­ç»ƒæ ·æœ¬ï¼ˆ25%çš„æ™ºèƒ½ä½“æ•°é‡ï¼‰ï¼Œå¹¶ä¸”èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´å…·æ³›åŒ–èƒ½åŠ›çš„è¿åŠ¨ç­–ç•¥ã€‚è¿™ç§é€šç”¨æ€§ä½¿å¾—æœºå™¨äººèƒ½å¤Ÿé€‚åº”æ–°çš„ç¯å¢ƒå’Œä»»åŠ¡ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜å…³é”®å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚ã€‚ä½†æ˜¯ï¼Œå¯ä»¥æ¨æµ‹ï¼Œå¥–åŠ±å‡½æ•°çš„è®¾è®¡è‡³å…³é‡è¦ï¼Œéœ€è¦ä»”ç»†å¹³è¡¡å„ç§è¿åŠ¨ç›®æ ‡ï¼Œä¾‹å¦‚é€Ÿåº¦ã€ç¨³å®šæ€§ã€èƒ½é‡æ¶ˆè€—ç­‰ã€‚æ­¤å¤–ï¼Œå¼ºåŒ–å­¦ä¹ ç®—æ³•çš„é€‰æ‹©å’Œè¶…å‚æ•°çš„è°ƒæ•´ä¹Ÿä¼šå¯¹æœ€ç»ˆçš„æ€§èƒ½äº§ç”Ÿå½±å“ã€‚ç½‘ç»œç»“æ„çš„è®¾è®¡ä¹Ÿå¯èƒ½é‡‡ç”¨äº†æŸç§å½¢å¼çš„å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰æˆ–Transformerï¼Œä»¥ä¾¿å¤„ç†æ—¶é—´åºåˆ—æ•°æ®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è®­ç»ƒçš„é€šç”¨ç­–ç•¥èƒ½å¤Ÿä¸æœ€å…ˆè¿›çš„ä¸“å®¶ç­–ç•¥ç›¸åª²ç¾ï¼ŒåŒæ—¶ä»…ä½¿ç”¨25%çš„è®­ç»ƒæ™ºèƒ½ä½“æ•°é‡ã€‚è¿™è¡¨æ˜è¯¥æ–¹æ³•å…·æœ‰æ›´é«˜çš„è®­ç»ƒæ•ˆç‡å’Œæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“çš„æ€§èƒ½æŒ‡æ ‡å’Œå¯¹æ¯”åŸºçº¿æœªçŸ¥ï¼Œéœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœæ•‘ã€å‹˜æ¢ã€ç‰©æµç­‰é¢†åŸŸã€‚å››è¶³æœºå™¨äººèƒ½å¤Ÿåœ¨å¤æ‚åœ°å½¢ä¸­çµæ´»ç§»åŠ¨ï¼Œæ‰§è¡Œäººç±»éš¾ä»¥å®Œæˆçš„ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œåœ¨ç¾éš¾ç°åœºæœå¯»å¹¸å­˜è€…ï¼Œåœ¨å±é™©ç¯å¢ƒä¸­è¿›è¡Œå‹˜æ¢ï¼Œæˆ–æ˜¯åœ¨ä»“åº“ä¸­è¿›è¡Œè´§ç‰©æ¬è¿ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼Œå››è¶³æœºå™¨äººå°†åœ¨æ›´å¤šé¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Climbing, crouching, bridging gaps, and walking up stairs are just a few of the advantages that quadruped robots have over wheeled robots, making them more suitable for navigating rough and unstructured terrain. However, executing such manoeuvres requires precise temporal coordination and complex agent-environment interactions. Moreover, legged locomotion is inherently more prone to slippage and tripping, and the classical approach of modeling such cases to design a robust controller thus quickly becomes impractical. In contrast, reinforcement learning offers a compelling solution by enabling optimal control through trial and error. We present a generalist reinforcement learning algorithm for quadrupedal agents in dynamic motion scenarios. The learned policy rivals state-of-the-art specialist policies trained using a mixture of experts approach, while using only 25% as many agents during training. Our experiments also highlight the key components of the generalist locomotion policy and the primary factors contributing to its success.

