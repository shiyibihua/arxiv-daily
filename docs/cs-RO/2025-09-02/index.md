---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-09-02
---

# cs.ROï¼ˆ2025-09-02ï¼‰

ğŸ“Š å…± **20** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (13 ğŸ”—2)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (13 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250902727v2-acrobotics-a-generalist-approach-to-quadrupedal-robots-parkour.html">Acrobotics: A Generalist Approach to Quadrupedal Robots' Parkour</a></td>
  <td>Acroboticsï¼šå››è¶³æœºå™¨äººè·‘é…·çš„é€šç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">legged locomotion</span> <span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02727v2" data-paper-url="./papers/250902727v2-acrobotics-a-generalist-approach-to-quadrupedal-robots-parkour.html" onclick="toggleFavorite(this, '2509.02727v2', 'Acrobotics: A Generalist Approach to Quadrupedal Robots&#39; Parkour')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250902815v1-multi-embodiment-locomotion-at-scale-with-extreme-embodiment-randomi.html">Multi-Embodiment Locomotion at Scale with extreme Embodiment Randomization</a></td>
  <td>æå‡ºåŸºäºæç«¯å½¢æ€éšæœºåŒ–çš„å¤šå½¢æ€é€šç”¨è¿åŠ¨ç­–ç•¥ï¼Œå®ç°é›¶æ ·æœ¬è¿ç§»</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">legged robot</span> <span class="paper-tag">humanoid</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02815v1" data-paper-url="./papers/250902815v1-multi-embodiment-locomotion-at-scale-with-extreme-embodiment-randomi.html" onclick="toggleFavorite(this, '2509.02815v1', 'Multi-Embodiment Locomotion at Scale with extreme Embodiment Randomization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250901996v1-mirage-multimodal-intention-recognition-and-admittance-guided-enhanc.html">MIRAGE: Multimodal Intention Recognition and Admittance-Guided Enhancement in VR-based Multi-object Teleoperation</a></td>
  <td>æå‡ºåŸºäºå¤šæ¨¡æ€æ„å›¾è¯†åˆ«å’Œè™šæ‹Ÿå®¹è®¸æ§åˆ¶çš„VRå¤šç‰©ä½“é¥æ“ä½œæ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">teleoperation</span> <span class="paper-tag">shared control</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.01996v1" data-paper-url="./papers/250901996v1-mirage-multimodal-intention-recognition-and-admittance-guided-enhanc.html" onclick="toggleFavorite(this, '2509.01996v1', 'MIRAGE: Multimodal Intention Recognition and Admittance-Guided Enhancement in VR-based Multi-object Teleoperation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250902324v1-language-guided-long-horizon-manipulation-with-llm-based-planning-an.html">Language-Guided Long Horizon Manipulation with LLM-based Planning and Visual Perception</a></td>
  <td>æå‡ºåŸºäºLLMè§„åˆ’å’Œè§†è§‰æ„ŸçŸ¥çš„è¯­è¨€å¼•å¯¼é•¿æ—¶ç¨‹æ“ä½œæ¡†æ¶ï¼Œè§£å†³å¯å˜å½¢ç‰©ä½“æ“ä½œéš¾é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">large language model</span> <span class="paper-tag">language conditioned</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02324v1" data-paper-url="./papers/250902324v1-language-guided-long-horizon-manipulation-with-llm-based-planning-an.html" onclick="toggleFavorite(this, '2509.02324v1', 'Language-Guided Long Horizon Manipulation with LLM-based Planning and Visual Perception')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250902876v1-generalizable-skill-learning-for-construction-robots-with-crowdsourc.html">Generalizable Skill Learning for Construction Robots with Crowdsourced Natural Language Instructions, Composable Skills Standardization, and Large Language Model</a></td>
  <td>æå‡ºåŸºäºä¼—åŒ…è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’ŒLLMçš„é€šç”¨å»ºç­‘æœºå™¨äººæŠ€èƒ½å­¦ä¹ æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">scene understanding</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02876v1" data-paper-url="./papers/250902876v1-generalizable-skill-learning-for-construction-robots-with-crowdsourc.html" onclick="toggleFavorite(this, '2509.02876v1', 'Generalizable Skill Learning for Construction Robots with Crowdsourced Natural Language Instructions, Composable Skills Standardization, and Large Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250902437v3-u-arm-ultra-low-cost-general-teleoperation-interface-for-robot-manip.html">U-ARM : Ultra low-cost general teleoperation interface for robot manipulation</a></td>
  <td>æå‡ºä½æˆæœ¬é€šç”¨é¥æ“ä½œç•Œé¢U-Armï¼Œç”¨äºæœºå™¨äººçµå·§æ“ä½œ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">teleoperation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02437v3" data-paper-url="./papers/250902437v3-u-arm-ultra-low-cost-general-teleoperation-interface-for-robot-manip.html" onclick="toggleFavorite(this, '2509.02437v3', 'U-ARM : Ultra low-cost general teleoperation interface for robot manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250902055v2-align-then-steer-adapting-the-vision-language-action-models-through-.html">Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance</a></td>
  <td>Align-Then-stEeræ¡†æ¶é€šè¿‡ç»Ÿä¸€æ½œåœ¨ç©ºé—´æŒ‡å¯¼ï¼Œå®ç°VLAæ¨¡å‹åœ¨æœºå™¨äººä»»åŠ¡ä¸Šçš„é«˜æ•ˆè¿ç§»ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">cross-embodiment</span> <span class="paper-tag">vision-language-action</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02055v2" data-paper-url="./papers/250902055v2-align-then-steer-adapting-the-vision-language-action-models-through-.html" onclick="toggleFavorite(this, '2509.02055v2', 'Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250902530v1-manipulation-as-in-simulation-enabling-accurate-geometry-perception-.html">Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots</a></td>
  <td>æå‡ºç›¸æœºæ·±åº¦æ¨¡å‹ï¼ˆCDMï¼‰ï¼Œæå‡æœºå™¨äººæ“ä½œä¸­æ·±åº¦æ„ŸçŸ¥çš„å‡†ç¡®æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">sim-to-real</span> <span class="paper-tag">metric depth</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02530v1" data-paper-url="./papers/250902530v1-manipulation-as-in-simulation-enabling-accurate-geometry-perception-.html" onclick="toggleFavorite(this, '2509.02530v1', 'Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250902343v1-physics-informed-machine-learning-with-adaptive-grids-for-optical-mi.html">Physics-Informed Machine Learning with Adaptive Grids for Optical Microrobot Depth Estimation</a></td>
  <td>æå‡ºåŸºäºè‡ªé€‚åº”ç½‘æ ¼çš„ç‰©ç†ä¿¡æ¯æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºå…‰é•Šå¾®å‹æœºå™¨äººçš„æ·±åº¦ä¼°è®¡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">depth estimation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02343v1" data-paper-url="./papers/250902343v1-physics-informed-machine-learning-with-adaptive-grids-for-optical-mi.html" onclick="toggleFavorite(this, '2509.02343v1', 'Physics-Informed Machine Learning with Adaptive Grids for Optical Microrobot Depth Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250902527v1-fault-tolerant-model-predictive-control-for-spacecraft.html">Fault-tolerant Model Predictive Control for Spacecraft</a></td>
  <td>æå‡ºä¸€ç§å®¹é”™æ¨¡å‹é¢„æµ‹æ§åˆ¶æ–¹æ³•ï¼Œç”¨äºèˆªå¤©å™¨åœ¨å¤šé‡æ‰§è¡Œå™¨æ•…éšœä¸‹çš„è½¨è¿¹å’Œå®šç‚¹ç¨³å®šã€‚</td>
  <td class="tags-cell"><span class="paper-tag">model predictive control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02527v1" data-paper-url="./papers/250902527v1-fault-tolerant-model-predictive-control-for-spacecraft.html" onclick="toggleFavorite(this, '2509.02527v1', 'Fault-tolerant Model Predictive Control for Spacecraft')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250902146v1-systematic-evaluation-of-trade-offs-in-motion-planning-algorithms-fo.html">Systematic Evaluation of Trade-Offs in Motion Planning Algorithms for Optimal Industrial Robotic Work Cell Design</a></td>
  <td>ç³»ç»Ÿè¯„ä¼°è¿åŠ¨è§„åˆ’ç®—æ³•æŠ˜è¡·æ–¹æ¡ˆï¼Œä¼˜åŒ–å·¥ä¸šæœºå™¨äººå·¥ä½œç«™è®¾è®¡</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02146v1" data-paper-url="./papers/250902146v1-systematic-evaluation-of-trade-offs-in-motion-planning-algorithms-fo.html" onclick="toggleFavorite(this, '2509.02146v1', 'Systematic Evaluation of Trade-Offs in Motion Planning Algorithms for Optimal Industrial Robotic Work Cell Design')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250905345v1-inf-3dp-implicit-neural-fields-for-collision-free-multi-axis-3d-prin.html">INF-3DP: Implicit Neural Fields for Collision-Free Multi-Axis 3D Printing</a></td>
  <td>INF-3DPï¼šåŸºäºéšå¼ç¥ç»åœºçš„æ— ç¢°æ’å¤šè½´3Dæ‰“å°æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05345v1" data-paper-url="./papers/250905345v1-inf-3dp-implicit-neural-fields-for-collision-free-multi-axis-3d-prin.html" onclick="toggleFavorite(this, '2509.05345v1', 'INF-3DP: Implicit Neural Fields for Collision-Free Multi-Axis 3D Printing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250902071v1-a-geometric-method-for-base-parameter-analysis-in-robot-inertia-iden.html">A Geometric Method for Base Parameter Analysis in Robot Inertia Identification Based on Projective Geometric Algebra</a></td>
  <td>æå‡ºåŸºäºå°„å½±å‡ ä½•ä»£æ•°çš„æœºå™¨äººæƒ¯æ€§å‚æ•°è¾¨è¯†å‡ ä½•æ–¹æ³•ï¼Œå®ç°åŸºå‚æ•°çš„è§£æç¡®å®šã€‚</td>
  <td class="tags-cell"><span class="paper-tag">Unitree</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02071v1" data-paper-url="./papers/250902071v1-a-geometric-method-for-base-parameter-analysis-in-robot-inertia-iden.html" onclick="toggleFavorite(this, '2509.02071v1', 'A Geometric Method for Base Parameter Analysis in Robot Inertia Identification Based on Projective Geometric Algebra')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>14</td>
  <td><a href="./papers/250902275v1-human-inspired-soft-anthropomorphic-hand-system-for-neuromorphic-obj.html">Human-Inspired Soft Anthropomorphic Hand System for Neuromorphic Object and Pose Recognition Using Multimodal Signals</a></td>
  <td>æå‡ºä¸€ç§å—äººç±»å¯å‘çš„è½¯ä½“æ‹Ÿäººæ‰‹ç³»ç»Ÿï¼Œåˆ©ç”¨å¤šæ¨¡æ€ä¿¡å·è¿›è¡Œç¥ç»å½¢æ€ç‰©ä½“å’Œå§¿æ€è¯†åˆ«ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02275v1" data-paper-url="./papers/250902275v1-human-inspired-soft-anthropomorphic-hand-system-for-neuromorphic-obj.html" onclick="toggleFavorite(this, '2509.02275v1', 'Human-Inspired Soft Anthropomorphic Hand System for Neuromorphic Object and Pose Recognition Using Multimodal Signals')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250902478v2-classification-of-vision-based-tactile-sensors-a-review.html">Classification of Vision-Based Tactile Sensors: A Review</a></td>
  <td>æå‡ºä¸€ç§åŸºäºè§†è§‰çš„è§¦è§‰ä¼ æ„Ÿå™¨åˆ†ç±»æ–¹æ³•ï¼Œæ—¨åœ¨ä¿ƒè¿›æœºå™¨äººè§¦è§‰æ„ŸçŸ¥æŠ€æœ¯çš„å‘å±•ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02478v2" data-paper-url="./papers/250902478v2-classification-of-vision-based-tactile-sensors-a-review.html" onclick="toggleFavorite(this, '2509.02478v2', 'Classification of Vision-Based Tactile Sensors: A Review')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250902163v1-enhancing-reliability-in-llm-integrated-robotic-systems-a-unified-ap.html">Enhancing Reliability in LLM-Integrated Robotic Systems: A Unified Approach to Security and Safety</a></td>
  <td>æå‡ºç»Ÿä¸€æ¡†æ¶ï¼Œæå‡LLMé›†æˆæœºå™¨äººåœ¨å®‰å…¨å’Œå¤æ‚ç¯å¢ƒä¸‹çš„å¯é æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02163v1" data-paper-url="./papers/250902163v1-enhancing-reliability-in-llm-integrated-robotic-systems-a-unified-ap.html" onclick="toggleFavorite(this, '2509.02163v1', 'Enhancing Reliability in LLM-Integrated Robotic Systems: A Unified Approach to Security and Safety')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/250902425v1-openguide-assistive-object-retrieval-in-indoor-spaces-for-individual.html">OpenGuide: Assistive Object Retrieval in Indoor Spaces for Individuals with Visual Impairments</a></td>
  <td>OpenGuideï¼šé¢å‘è§†éšœäººå£«çš„å®¤å†…è¾…åŠ©ç‰©ä½“æ£€ç´¢æœºå™¨äººç³»ç»Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02425v1" data-paper-url="./papers/250902425v1-openguide-assistive-object-retrieval-in-indoor-spaces-for-individual.html" onclick="toggleFavorite(this, '2509.02425v1', 'OpenGuide: Assistive Object Retrieval in Indoor Spaces for Individuals with Visual Impairments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250902870v1-robotic-3d-flower-pose-estimation-for-small-scale-urban-farms.html">Robotic 3D Flower Pose Estimation for Small-Scale Urban Farms</a></td>
  <td>æå‡ºä¸€ç§åŸºäºFarmBotçš„è‰è“èŠ±æœµä¸‰ç»´å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œç”¨äºå°å‹åŸå¸‚å†œåœºæœºå™¨äººæˆç²‰</td>
  <td class="tags-cell"><span class="paper-tag">occupancy grid</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02870v1" data-paper-url="./papers/250902870v1-robotic-3d-flower-pose-estimation-for-small-scale-urban-farms.html" onclick="toggleFavorite(this, '2509.02870v1', 'Robotic 3D Flower Pose Estimation for Small-Scale Urban Farms')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>19</td>
  <td><a href="./papers/250901944v2-autodrive-r2-incentivizing-reasoning-and-self-reflection-capacity-fo.html">AutoDrive-R$^2$: Incentivizing Reasoning and Self-Reflection Capacity for VLA Model in Autonomous Driving</a></td>
  <td>AutoDrive-RÂ²ï¼šé€šè¿‡æ¨ç†å’Œè‡ªåæ€èƒ½åŠ›æå‡è‡ªåŠ¨é©¾é©¶VLAæ¨¡å‹æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.01944v2" data-paper-url="./papers/250901944v2-autodrive-r2-incentivizing-reasoning-and-self-reflection-capacity-fo.html" onclick="toggleFavorite(this, '2509.01944v2', 'AutoDrive-R$^2$: Incentivizing Reasoning and Self-Reflection Capacity for VLA Model in Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>20</td>
  <td><a href="./papers/250902283v2-sem-radiff-diffusion-based-3d-radar-semantic-perception-in-cluttered.html">Sem-RaDiff: Diffusion-Based 3D Radar Semantic Perception in Cluttered Agricultural Environments</a></td>
  <td>æå‡ºåŸºäºé›·è¾¾çš„3Dç¯å¢ƒæ„ŸçŸ¥æ¡†æ¶ä»¥è§£å†³å†œä¸šç¯å¢ƒä¸­çš„æ„ŸçŸ¥æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">penetration</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02283v2" data-paper-url="./papers/250902283v2-sem-radiff-diffusion-based-3d-radar-semantic-perception-in-cluttered.html" onclick="toggleFavorite(this, '2509.02283v2', 'Sem-RaDiff: Diffusion-Based 3D Radar Semantic Perception in Cluttered Agricultural Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)