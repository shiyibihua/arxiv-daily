---
layout: default
title: FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction
---

# FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04018" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04018v2</a>
  <a href="https://arxiv.org/pdf/2509.04018.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04018v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04018v2', 'FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yifan Yang, Zhixiang Duan, Tianshi Xie, Fuyu Cao, Pinxi Shen, Peili Song, Piaopiao Jin, Guokang Sun, Shaoqing Xu, Yangwei You, Jingtai Liu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-04 (æ›´æ–°: 2025-12-03)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFPC-VLAæ¡†æ¶ï¼Œç”¨äºæœºå™¨äººæ“ä½œä¸­é¢„æµ‹å’Œçº æ­£å¤±è´¥**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `å¤±è´¥é¢„æµ‹` `å¤±è´¥çº æ­£` `è‡ªç›‘ç£å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `è‡ªä¸»ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿæœºå™¨äººæ“ä½œæµç¨‹åœ¨å¼€æ”¾ç¯å¢ƒä¸­çµæ´»æ€§ä¸è¶³ï¼Œéš¾ä»¥åº”å¯¹å¤æ‚ä»»åŠ¡ã€‚
2. FPC-VLAæ¡†æ¶é€šè¿‡å¼•å…¥ç›‘ç£å™¨é¢„æµ‹åŠ¨ä½œå¤±è´¥é£é™©å¹¶ç”Ÿæˆçº æ­£ç­–ç•¥ï¼Œæå‡ç³»ç»Ÿé²æ£’æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒFPC-VLAåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœºå™¨äººæ“ä½œæ˜¯è‡ªåŠ¨åŒ–çš„åŸºç¡€ç»„æˆéƒ¨åˆ†ã€‚ç„¶è€Œï¼Œç”±äºçµæ´»æ€§æœ‰é™ï¼Œä¼ ç»Ÿçš„æ„ŸçŸ¥-è§„åˆ’æµç¨‹åœ¨å¼€æ”¾å¼ä»»åŠ¡ä¸­å¸¸å¸¸è¡¨ç°ä¸ä½³ã€‚ç«¯åˆ°ç«¯çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¶æ„å±•ç°äº†è‰¯å¥½çš„æ½œåŠ›ï¼Œä½†ç¼ºä¹é¢„æµ‹å’Œçº æ­£å¤±è´¥çš„å…³é”®æœºåˆ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†FPC-VLAï¼Œä¸€ä¸ªé›†æˆäº†VLAå’Œç›‘ç£å™¨çš„åŒæ¨¡å‹æ¡†æ¶ï¼Œç”¨äºå¤±è´¥é¢„æµ‹å’Œçº æ­£ã€‚ç›‘ç£å™¨é€šè¿‡è§†è§‰-è¯­è¨€æŸ¥è¯¢è¯„ä¼°åŠ¨ä½œçš„å¯è¡Œæ€§ï¼Œå¹¶åœ¨é£é™©å‡ºç°æ—¶ç”Ÿæˆçº æ­£ç­–ç•¥ï¼Œæ— éœ€æ‰‹åŠ¨æ ‡æ³¨å³å¯é«˜æ•ˆè®­ç»ƒã€‚åŒæµèåˆæ¨¡å—é€šè¿‡åˆ©ç”¨è¿‡å»çš„é¢„æµ‹è¿›ä¸€æ­¥ä¼˜åŒ–åŠ¨ä½œã€‚åœ¨å¤šä¸ªæ¨¡æ‹Ÿå¹³å°ï¼ˆSIMPLERå’ŒLIBEROï¼‰å’Œæœºå™¨äººå®ä½“ï¼ˆWidowXã€Google Robotã€Frankaï¼‰ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒFPC-VLAåœ¨é›¶æ ·æœ¬å’Œå¾®è°ƒè®¾ç½®ä¸‹å‡ä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ã€‚åœ¨å„ç§é•¿æ—¶ç¨‹ä»»åŠ¡ä¸­çš„æˆåŠŸçœŸå®ä¸–ç•Œéƒ¨ç½²è¯å®äº†FPC-VLAåœ¨æ„å»ºæ›´å¯é çš„è‡ªä¸»ç³»ç»Ÿæ–¹é¢çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›å’Œå®ç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼Œä¼ ç»Ÿæ„ŸçŸ¥-è§„åˆ’æµç¨‹å’Œç«¯åˆ°ç«¯VLAæ¨¡å‹åœ¨å¼€æ”¾ç¯å¢ƒä¸­å®¹æ˜“å¤±è´¥çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹é¢„æµ‹å’Œçº æ­£å¤±è´¥çš„èƒ½åŠ›ï¼Œå¯¼è‡´ä»»åŠ¡å®Œæˆçš„å¯é æ€§è¾ƒä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥ä¸€ä¸ªç›‘ç£å™¨ï¼Œè¯¥ç›‘ç£å™¨èƒ½å¤Ÿé€šè¿‡è§†è§‰å’Œè¯­è¨€ä¿¡æ¯æ¥è¯„ä¼°å½“å‰åŠ¨ä½œçš„æ½œåœ¨é£é™©ï¼Œå¹¶åœ¨å¿…è¦æ—¶ç”Ÿæˆçº æ­£ç­–ç•¥ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œç³»ç»Ÿå¯ä»¥åœ¨å¤±è´¥å‘ç”Ÿä¹‹å‰è¿›è¡Œå¹²é¢„ï¼Œä»è€Œæé«˜ä»»åŠ¡çš„æˆåŠŸç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFPC-VLAæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šVLAæ¨¡å‹å’Œç›‘ç£å™¨ã€‚VLAæ¨¡å‹è´Ÿè´£æ ¹æ®è§†è§‰å’Œè¯­è¨€è¾“å…¥ç”ŸæˆåŠ¨ä½œåºåˆ—ã€‚ç›‘ç£å™¨åˆ™å¹¶è¡Œå·¥ä½œï¼Œé€šè¿‡è§†è§‰-è¯­è¨€æŸ¥è¯¢è¯„ä¼°VLAæ¨¡å‹ç”Ÿæˆçš„åŠ¨ä½œçš„å¯è¡Œæ€§ã€‚å¦‚æœç›‘ç£å™¨æ£€æµ‹åˆ°æ½œåœ¨çš„å¤±è´¥é£é™©ï¼Œå®ƒä¼šç”Ÿæˆçº æ­£ç­–ç•¥ï¼Œå¹¶å°†å…¶åé¦ˆç»™VLAæ¨¡å‹ï¼Œä»¥è°ƒæ•´åç»­çš„åŠ¨ä½œã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªåŒæµèåˆæ¨¡å—ï¼Œç”¨äºèåˆVLAæ¨¡å‹å’Œç›‘ç£å™¨çš„è¾“å‡ºï¼Œä»è€Œè¿›ä¸€æ­¥ä¼˜åŒ–æœ€ç»ˆçš„åŠ¨ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†ç›‘ç£å™¨è¿›è¡Œå¤±è´¥é¢„æµ‹å’Œçº æ­£ï¼Œå¹¶ä¸”è¯¥ç›‘ç£å™¨å¯ä»¥é€šè¿‡è‡ªç›‘ç£çš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€æ‰‹åŠ¨æ ‡æ³¨æ•°æ®ã€‚è¿™ç§è‡ªç›‘ç£è®­ç»ƒæ–¹å¼å¤§å¤§é™ä½äº†è®­ç»ƒæˆæœ¬ï¼Œå¹¶ä¸”ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒçš„ä»»åŠ¡å’Œç¯å¢ƒã€‚

**å…³é”®è®¾è®¡**ï¼šç›‘ç£å™¨ä½¿ç”¨è§†è§‰-è¯­è¨€æŸ¥è¯¢æ¥è¯„ä¼°åŠ¨ä½œçš„å¯è¡Œæ€§ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒä¼šæ ¹æ®å½“å‰çš„è§†è§‰è¾“å…¥å’Œè¯­è¨€æŒ‡ä»¤ï¼ŒæŸ¥è¯¢ä¸€ä¸ªé¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œä»¥åˆ¤æ–­å½“å‰åŠ¨ä½œæ˜¯å¦ç¬¦åˆé¢„æœŸã€‚å¦‚æœæŸ¥è¯¢ç»“æœè¡¨æ˜å½“å‰åŠ¨ä½œå­˜åœ¨é£é™©ï¼Œç›‘ç£å™¨ä¼šç”Ÿæˆä¸€ä¸ªçº æ­£ç­–ç•¥ï¼Œä¾‹å¦‚è°ƒæ•´åŠ¨ä½œçš„æ–¹å‘æˆ–åŠ›åº¦ã€‚åŒæµèåˆæ¨¡å—ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥èåˆVLAæ¨¡å‹å’Œç›‘ç£å™¨çš„è¾“å‡ºï¼Œä»è€Œæ›´å¥½åœ°åˆ©ç”¨ä¸¤è€…çš„ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

FPC-VLAåœ¨SIMPLERå’ŒLIBEROç­‰æ¨¡æ‹Ÿå¹³å°ä»¥åŠWidowXã€Google Robotå’ŒFrankaç­‰çœŸå®æœºå™¨äººä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFPC-VLAåœ¨é›¶æ ·æœ¬å’Œå¾®è°ƒè®¾ç½®ä¸‹å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚åœ¨çœŸå®ä¸–ç•Œéƒ¨ç½²ä¸­ï¼ŒFPC-VLAæˆåŠŸå®Œæˆäº†å„ç§é•¿æ—¶ç¨‹ä»»åŠ¡ï¼ŒéªŒè¯äº†å…¶å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œå®ç”¨æ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªåœ¨æ‘˜è¦ä¸­ç»™å‡ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FPC-VLAæ¡†æ¶å¯åº”ç”¨äºå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚å®¶åº­æœåŠ¡æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–æœºå™¨äººå’ŒåŒ»ç–—æœºå™¨äººç­‰ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿæé«˜æœºå™¨äººåœ¨å¤æ‚å’Œä¸ç¡®å®šç¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡çš„å¯é æ€§å’Œé²æ£’æ€§ï¼Œä»è€Œæ‰©å±•æœºå™¨äººçš„åº”ç”¨èŒƒå›´ï¼Œå¹¶æå‡å…¶åœ¨å®é™…åœºæ™¯ä¸­çš„å®ç”¨ä»·å€¼ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ›´å¹¿æ³›çš„è‡ªä¸»ç³»ç»Ÿï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶æ±½è½¦å’Œæ— äººæœºç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Robotic manipulation is a fundamental component of automation. However, traditional perception-planning pipelines often fall short in open-ended tasks due to limited flexibility, while the architecture of a single end-to-end Vision-Language-Action (VLA) offers promising capabilities but lacks crucial mechanisms for anticipating and recovering from failure. To address these challenges, we propose FPC-VLA, a dual-model framework that integrates VLA with a supervisor for failure prediction and correction. The supervisor evaluates action viability through vision-language queries and generates corrective strategies when risks arise, trained efficiently without manual labeling. A dual-stream fusion module further refines actions by leveraging past predictions. Evaluation results on multiple simulation platforms (SIMPLER and LIBERO) and robot embodiments (WidowX, Google Robot, Franka) show that FPC-VLA outperforms state-of-the-art models in both zero-shot and fine-tuned settings. Successful real-world deployments on diverse, long-horizon tasks confirm FPC-VLA's strong generalization and practical utility for building more reliable autonomous systems.

