---
layout: default
title: Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation
---

# Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19958" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19958v2</a>
  <a href="https://arxiv.org/pdf/2508.19958.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19958v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19958v2', 'Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yiguo Fan, Pengxiang Ding, Shuanghao Bai, Xinyang Tong, Yuyang Zhu, Hongchao Lu, Fengqi Dai, Wei Zhao, Yang Liu, Siteng Huang, Zhaoxin Fan, Badong Chen, Donglin Wang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27 (æ›´æ–°: 2025-08-28)

**å¤‡æ³¨**: Accepted to CoRL 2025; Github Page: https://long-vla.github.io

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLong-VLAä»¥è§£å†³é•¿æ—¶é—´æœºå™¨äººæ“æ§ä»»åŠ¡çš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿æ—¶é—´æ“æ§` `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `æœºå™¨äººå­¦ä¹ ` `å¤šæ¨¡æ€æ•°æ®` `é˜¶æ®µæ„ŸçŸ¥` `æŠ€èƒ½é“¾` `å­ä»»åŠ¡ä¾èµ–æ€§` `L-CALVINåŸºå‡†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ä¸»è¦é’ˆå¯¹çŸ­æœŸä»»åŠ¡ï¼Œéš¾ä»¥å¤„ç†é•¿æ—¶é—´ã€å¤šæ­¥éª¤çš„æœºå™¨äººæ“æ§ï¼Œå­˜åœ¨æŠ€èƒ½é“¾å’Œå­ä»»åŠ¡ä¾èµ–æ€§çš„é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºLong-VLAæ¨¡å‹ï¼Œé€šè¿‡é˜¶æ®µæ„ŸçŸ¥è¾“å…¥æ©è”½ç­–ç•¥ï¼Œå°†å­ä»»åŠ¡åˆ†ä¸ºç§»åŠ¨å’Œäº¤äº’é˜¶æ®µï¼Œå¢å¼ºæ¨¡å‹å¯¹æ„ŸçŸ¥çº¿ç´¢çš„å…³æ³¨ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLong-VLAåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä»»åŠ¡ä¸­å‡æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œå»ºç«‹äº†é•¿æ—¶é—´æ“æ§çš„æ–°åŸºå‡†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹å·²æˆä¸ºæœºå™¨äººç­–ç•¥å­¦ä¹ çš„åŸºçŸ³ï¼Œåˆ©ç”¨å¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®å®ç°ç¨³å¥å’Œå¯æ‰©å±•çš„æ§åˆ¶ã€‚ç„¶è€Œï¼Œç°æœ‰VLAæ¡†æ¶ä¸»è¦é’ˆå¯¹çŸ­æœŸä»»åŠ¡ï¼Œå…¶åœ¨é•¿æ—¶é—´ã€å¤šæ­¥éª¤çš„æœºå™¨äººæ“æ§ä¸­çš„æœ‰æ•ˆæ€§å—åˆ°æŠ€èƒ½é“¾å’Œå­ä»»åŠ¡ä¾èµ–æ€§ç­‰æŒ‘æˆ˜çš„é™åˆ¶ã€‚æœ¬æ–‡æå‡ºäº†Long-VLAï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸“ä¸ºé•¿æ—¶é—´æœºå™¨äººä»»åŠ¡è®¾è®¡çš„ç«¯åˆ°ç«¯VLAæ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„é˜¶æ®µæ„ŸçŸ¥è¾“å…¥æ©è”½ç­–ç•¥ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°å°†æ¯ä¸ªå­ä»»åŠ¡åˆ†æ®µä¸ºç§»åŠ¨å’Œäº¤äº’é˜¶æ®µï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä¸“æ³¨äºä¸é˜¶æ®µç›¸å…³çš„æ„ŸçŸ¥çº¿ç´¢ï¼Œä»è€Œå¢å¼ºå­ä»»åŠ¡çš„å…¼å®¹æ€§ã€‚æˆ‘ä»¬çš„æ¶æ„æ— å…³æ¨¡å—å¯ä»¥æ— ç¼é›†æˆåˆ°ç°æœ‰çš„VLAæ¨¡å‹ä¸­ï¼Œå¹¶æå‡ºäº†L-CALVINåŸºå‡†ï¼Œä»¥ç³»ç»Ÿè¯„ä¼°é•¿æ—¶é—´æ“æ§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒLong-VLAæ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä¸ºé•¿æ—¶é—´æœºå™¨äººæ§åˆ¶å»ºç«‹äº†æ–°çš„åŸºå‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨é•¿æ—¶é—´æœºå™¨äººæ“æ§ä»»åŠ¡ä¸­çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯åœ¨æŠ€èƒ½é“¾å’Œå­ä»»åŠ¡ä¾èµ–æ€§æ–¹é¢çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šæ­¥éª¤ä»»åŠ¡æ—¶è¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLong-VLAæ¨¡å‹é€šè¿‡å¼•å…¥é˜¶æ®µæ„ŸçŸ¥è¾“å…¥æ©è”½ç­–ç•¥ï¼ŒåŠ¨æ€åœ°å°†æ¯ä¸ªå­ä»»åŠ¡åˆ†ä¸ºç§»åŠ¨å’Œäº¤äº’ä¸¤ä¸ªé˜¶æ®µï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°èšç„¦äºä¸å½“å‰é˜¶æ®µç›¸å…³çš„æ„ŸçŸ¥ä¿¡æ¯ï¼Œä»è€Œæé«˜ä»»åŠ¡çš„æ‰§è¡Œæ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLong-VLAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥å¤„ç†æ¨¡å—ã€é˜¶æ®µè¯†åˆ«æ¨¡å—å’ŒåŠ¨ä½œç”Ÿæˆæ¨¡å—ã€‚è¾“å…¥å¤„ç†æ¨¡å—è´Ÿè´£æ¥æ”¶å¤šæ¨¡æ€æ•°æ®ï¼Œé˜¶æ®µè¯†åˆ«æ¨¡å—æ ¹æ®ä»»åŠ¡éœ€æ±‚åŠ¨æ€åˆ’åˆ†å­ä»»åŠ¡é˜¶æ®µï¼ŒåŠ¨ä½œç”Ÿæˆæ¨¡å—åˆ™åŸºäºå½“å‰é˜¶æ®µçš„è¾“å…¥ç”Ÿæˆç›¸åº”çš„æ§åˆ¶æŒ‡ä»¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé˜¶æ®µæ„ŸçŸ¥è¾“å…¥æ©è”½ç­–ç•¥çš„æå‡ºï¼Œè¯¥ç­–ç•¥ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿè‡ªé€‚åº”åœ°å¤„ç†ä¸åŒé˜¶æ®µçš„ä»»åŠ¡éœ€æ±‚ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†é•¿æ—¶é—´æ“æ§çš„èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–é˜¶æ®µè¯†åˆ«çš„å‡†ç¡®æ€§ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šå¼•å…¥äº†æ¨¡å—åŒ–è®¾è®¡ï¼Œä»¥ä¾¿äºä¸ç°æœ‰VLAæ¨¡å‹çš„é›†æˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤§é‡å®éªŒä¸­ï¼ŒLong-VLAæ¨¡å‹åœ¨é•¿æ—¶é—´æ“æ§ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œç›¸è¾ƒäºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¶…è¿‡20%ã€‚è¯¥æ¨¡å‹åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸‹å‡å±•ç°äº†ä¼˜è¶Šçš„é€‚åº”æ€§å’Œç¨³å®šæ€§ï¼Œä¸ºé•¿æ—¶é—´æœºå™¨äººæ§åˆ¶è®¾ç«‹äº†æ–°çš„åŸºå‡†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æœºå™¨äººã€è‡ªåŠ¨åŒ–ç”Ÿäº§çº¿å’Œå®¶åº­æœåŠ¡æœºå™¨äººç­‰ã€‚Long-VLAæ¨¡å‹çš„æå‡ºå°†æ¨åŠ¨æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è‡ªä¸»æ“ä½œèƒ½åŠ›ï¼Œæå‡æœºå™¨äººåœ¨å®é™…åº”ç”¨ä¸­çš„çµæ´»æ€§å’Œæ•ˆç‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models have become a cornerstone in robotic policy learning, leveraging large-scale multimodal data for robust and scalable control. However, existing VLA frameworks primarily address short-horizon tasks, and their effectiveness on long-horizon, multi-step robotic manipulation remains limited due to challenges in skill chaining and subtask dependencies. In this work, we introduce Long-VLA, the first end-to-end VLA model specifically designed for long-horizon robotic tasks. Our approach features a novel phase-aware input masking strategy that adaptively segments each subtask into moving and interaction phases, enabling the model to focus on phase-relevant sensory cues and enhancing subtask compatibility. This unified strategy preserves the scalability and data efficiency of VLA training, and our architecture-agnostic module can be seamlessly integrated into existing VLA models. We further propose the L-CALVIN benchmark to systematically evaluate long-horizon manipulation. Extensive experiments on both simulated and real-world tasks demonstrate that Long-VLA significantly outperforms prior state-of-the-art methods, establishing a new baseline for long-horizon robotic control.

