---
layout: default
title: HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation
---

# HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.20085" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.20085v3</a>
  <a href="https://arxiv.org/pdf/2508.20085.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.20085v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.20085v3', 'HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zhecheng Yuan, Tianming Wei, Langzhe Gu, Pu Hua, Tianhai Liang, Yuanpei Chen, Huazhe Xu

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-27 (Êõ¥Êñ∞: 2025-08-31)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://gemcollector.github.io/HERMES/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫HERMESÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥Â§öÊ∫ê‰∫∫Á±ªÂä®‰ΩúÊï∞ÊçÆËΩ¨Âåñ‰∏∫Êú∫Âô®‰∫∫Ë°å‰∏∫ÁöÑÊåëÊàò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±ÂõõÔºöÁîüÊàêÂºèÂä®‰Ωú (Generative Motion)** **ÊîØÊü±‰∏ÉÔºöÂä®‰ΩúÈáçÂÆöÂêë (Motion Retargeting)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `‰∫∫Êú∫Â≠¶‰π†` `Êú∫Âô®‰∫∫Êìç‰Ωú` `Â§öÊ∫êÊï∞ÊçÆ` `ÁÅµÂ∑ßÊâã` `Âº∫ÂåñÂ≠¶‰π†` `sim2real` `Ëá™‰∏ªÂØºËà™` `Ê∑±Â∫¶ÂõæÂÉè`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Â∞ÜÂ§öÊ∫ê‰∫∫Á±ªÊâãÈÉ®Âä®‰ΩúËΩ¨Âåñ‰∏∫Êú∫Âô®‰∫∫Ë°å‰∏∫Êó∂Èù¢‰∏¥ÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇÁöÑÈ´òÁª¥Âä®‰ΩúÁ©∫Èó¥‰∏≠„ÄÇ
2. HERMESÊ°ÜÊû∂ÈÄöËøáÁªü‰∏ÄÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåÂ∞ÜÂºÇÊûÑ‰∫∫Á±ªÊâãÈÉ®Âä®‰ΩúËΩ¨Âåñ‰∏∫Áâ©ÁêÜ‰∏äÂêàÁêÜÁöÑÊú∫Âô®‰∫∫Ë°å‰∏∫ÔºåÂπ∂ÂºïÂÖ•Ê∑±Â∫¶ÂõæÂÉèÁöÑsim2realËΩ¨ÁßªÊñπÊ≥ï„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåHERMESÂú®Â§öÊ†∑ÁöÑÂÆûÈôÖÂú∫ÊôØ‰∏≠Â±ïÁé∞Âá∫ËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõÔºåÊàêÂäüÂÆåÊàê‰∫ÜÂ§çÊùÇÁöÑÂèåÊâãÁÅµÂ∑ßÊìç‰Ωú‰ªªÂä°„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âà©Áî®‰∫∫Á±ªËøêÂä®Êï∞ÊçÆËµã‰∫àÊú∫Âô®‰∫∫Â§öÊ†∑ÂåñÁöÑÊìç‰ΩúÊäÄËÉΩÂ∑≤Êàê‰∏∫Êú∫Âô®‰∫∫Êìç‰ΩúÈ¢ÜÂüüÁöÑ‰∏Ä‰∏™ÊúâÂâçÊôØÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇÁÑ∂ËÄåÔºåÂ∞ÜÂ§öÊ∫ê‰∫∫Á±ªÊâãÈÉ®Âä®‰ΩúËΩ¨Âåñ‰∏∫ÂèØË°åÁöÑÊú∫Âô®‰∫∫Ë°å‰∏∫‰ªçÁÑ∂Èù¢‰∏¥ÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂØπ‰∫éÈÖçÂ§áÂ§öÊåáÁÅµÂ∑ßÊâãÁöÑÊú∫Âô®‰∫∫ÔºåÂÖ∂Âä®‰ΩúÁ©∫Èó¥Â§çÊùÇ‰∏îÁª¥Â∫¶È´ò„ÄÇÊ≠§Â§ñÔºåÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÈöæ‰ª•ÁîüÊàêËÉΩÂ§üÈÄÇÂ∫îÂ§öÊ†∑ÁéØÂ¢ÉÊù°‰ª∂ÁöÑÁ≠ñÁï•„ÄÇÊú¨ÊñáÊèêÂá∫HERMESÔºå‰∏Ä‰∏™Áî®‰∫éÁßªÂä®ÂèåÊâãÁÅµÂ∑ßÊìç‰ΩúÁöÑ‰∫∫Êú∫Â≠¶‰π†Ê°ÜÊû∂„ÄÇHERMESÈ¶ñÂÖàÂà∂ÂÆö‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåËÉΩÂ§üÊó†ÁºùÂú∞Â∞ÜÊù•Ëá™Â§ö‰∏™Ê∫êÁöÑÂºÇÊûÑ‰∫∫Á±ªÊâãÈÉ®Âä®‰ΩúËΩ¨Âåñ‰∏∫Áâ©ÁêÜ‰∏äÂêàÁêÜÁöÑÊú∫Âô®‰∫∫Ë°å‰∏∫„ÄÇ‰∏∫‰∫ÜÂáèÂ∞èÊ®°Êãü‰∏éÁé∞ÂÆû‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºåÊàë‰ª¨ËøòËÆæËÆ°‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊ∑±Â∫¶ÂõæÂÉèÁöÑÁ´ØÂà∞Á´Øsim2realËΩ¨ÁßªÊñπÊ≥ïÔºå‰ª•ÊèêÈ´òÂØπÁé∞ÂÆûÂú∫ÊôØÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊúÄÂêéÔºå‰∏∫‰∫ÜÂú®Â§öÂèòÂíåÈùûÁªìÊûÑÂåñÁéØÂ¢É‰∏≠ÂÆûÁé∞Ëá™‰∏ªÊìç‰ΩúÔºåÊàë‰ª¨Â¢ûÂº∫‰∫ÜÂØºËà™Âü∫Á°ÄÊ®°ÂûãÔºåÁªìÂêàÈó≠ÁéØÁöÑÈÄèËßÜ-n-ÁÇπ(PnP)ÂÆö‰ΩçÊú∫Âà∂ÔºåÁ°Æ‰øùËßÜËßâÁõÆÊ†áÁöÑÁ≤æÁ°ÆÂØπÈΩêÔºåÊúâÊïàÂú∞ËøûÊé•‰∫ÜËá™‰∏ªÂØºËà™‰∏éÁÅµÂ∑ßÊìç‰Ωú„ÄÇÂ§ßÈáèÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåHERMESÂú®Â§öÊ†∑ÁöÑÂÆûÈôÖÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫‰∏ÄËá¥ÁöÑÂèØÊ≥õÂåñË°å‰∏∫ÔºåÊàêÂäüÊâßË°å‰∫Ü‰ºóÂ§öÂ§çÊùÇÁöÑÁßªÂä®ÂèåÊâãÁÅµÂ∑ßÊìç‰Ωú‰ªªÂä°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â∞ÜÂ§öÊ∫ê‰∫∫Á±ªÊâãÈÉ®Âä®‰ΩúÊúâÊïàËΩ¨Âåñ‰∏∫Êú∫Âô®‰∫∫Ë°å‰∏∫ÁöÑÈöæÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ÈÄÇÂ∫îÂ§çÊùÇÈ´òÁª¥Âä®‰ΩúÁ©∫Èó¥ÂíåÂ§öÊ†∑ÁéØÂ¢ÉÊù°‰ª∂ÊñπÈù¢Â≠òÂú®‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöHERMESÊ°ÜÊû∂ÈÄöËøáÁªü‰∏ÄÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåËÉΩÂ§üÂ∞ÜÂºÇÊûÑÁöÑ‰∫∫Á±ªÊâãÈÉ®Âä®‰ΩúÊó†ÁºùËΩ¨Âåñ‰∏∫Êú∫Âô®‰∫∫Ë°å‰∏∫ÔºåÂêåÊó∂ÂºïÂÖ•Ê∑±Â∫¶ÂõæÂÉèÊäÄÊúØ‰ª•ÂáèÂ∞èÊ®°Êãü‰∏éÁé∞ÂÆû‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöHERMESÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈ¶ñÂÖàÊòØÂä®‰ΩúËΩ¨ÂåñÊ®°ÂùóÔºåÂà©Áî®Âº∫ÂåñÂ≠¶‰π†Â∞Ü‰∫∫Á±ªÂä®‰ΩúÊò†Â∞ÑÂà∞Êú∫Âô®‰∫∫Ë°å‰∏∫ÔºõÂÖ∂Ê¨°ÊòØsim2realËΩ¨ÁßªÊ®°ÂùóÔºåÈÄöËøáÊ∑±Â∫¶ÂõæÂÉèÂÆûÁé∞ÂØπÁé∞ÂÆûÂú∫ÊôØÁöÑÊ≥õÂåñÔºõÊúÄÂêéÊòØÂØºËà™‰∏éÊìç‰ΩúÊ®°ÂùóÔºåÁªìÂêàPnPÂÆö‰ΩçÊú∫Âà∂ÂÆûÁé∞Ëá™‰∏ªÂØºËà™‰∏éÁÅµÂ∑ßÊìç‰ΩúÁöÑÊúâÊïàÂØπÊé•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöHERMESÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂Áªü‰∏ÄÁöÑÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÂíåÊ∑±Â∫¶ÂõæÂÉèÁöÑsim2realËΩ¨ÁßªÊñπÊ≥ïÔºåËøô‰ΩøÂæóÊú∫Âô®‰∫∫ËÉΩÂ§üÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÂÆûÁé∞Êõ¥È´òÁöÑÊìç‰ΩúÁÅµÊ¥ªÊÄßÂíåÈÄÇÂ∫îÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåHERMESÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•‰ºòÂåñÂä®‰ΩúËΩ¨ÂåñÁöÑÂáÜÁ°ÆÊÄßÔºåÂπ∂ÈÄöËøáÊ∑±Â∫¶Â≠¶‰π†ÁΩëÁªúÁªìÊûÑÊù•Â§ÑÁêÜÈ´òÁª¥ËæìÂÖ•Êï∞ÊçÆÔºåÁ°Æ‰øùÊú∫Âô®‰∫∫Ë°å‰∏∫ÁöÑÁâ©ÁêÜÂêàÁêÜÊÄßÂíåÊìç‰ΩúÁöÑÊµÅÁïÖÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåHERMESÂú®Â§öÊ†∑ÁöÑÂÆûÈôÖÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÊàêÂäüÊâßË°å‰∫ÜÂ§öÈ°πÂ§çÊùÇÁöÑÁßªÂä®ÂèåÊâãÁÅµÂ∑ßÊìç‰Ωú‰ªªÂä°„ÄÇ‰∏éÂü∫Á∫øÊñπÊ≥ïÁõ∏ÊØîÔºåHERMESÂú®‰ªªÂä°ÊàêÂäüÁéáÂíåÊìç‰ΩúÁ≤æÂ∫¶‰∏äÂùáÊúâÊòæËëóÊèêÂçáÔºåÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Êèê‰æõÔºå‰ΩÜÂÆûÈ™åÁªìÊûúË°®ÊòéÂÖ∂ÂÖ∑ÊúâËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

HERMESÊ°ÜÊû∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÁâπÂà´ÊòØÂú®ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öËá™Âä®ÂåñÂíå‰∫∫Êú∫Âçè‰ΩúÁ≠âÈ¢ÜÂüü„ÄÇÂÖ∂ËÉΩÂ§üÊúâÊïàÂú∞Â∞Ü‰∫∫Á±ªÁöÑÁÅµÂ∑ßÊìç‰ΩúÊäÄËÉΩËΩ¨Âåñ‰∏∫Êú∫Âô®‰∫∫Ë°å‰∏∫ÔºåÊèêÂçáÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑËá™‰∏ªÊìç‰ΩúËÉΩÂäõÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Leveraging human motion data to impart robots with versatile manipulation skills has emerged as a promising paradigm in robotic manipulation. Nevertheless, translating multi-source human hand motions into feasible robot behaviors remains challenging, particularly for robots equipped with multi-fingered dexterous hands characterized by complex, high-dimensional action spaces. Moreover, existing approaches often struggle to produce policies capable of adapting to diverse environmental conditions. In this paper, we introduce HERMES, a human-to-robot learning framework for mobile bimanual dexterous manipulation. First, HERMES formulates a unified reinforcement learning approach capable of seamlessly transforming heterogeneous human hand motions from multiple sources into physically plausible robotic behaviors. Subsequently, to mitigate the sim2real gap, we devise an end-to-end, depth image-based sim2real transfer method for improved generalization to real-world scenarios. Furthermore, to enable autonomous operation in varied and unstructured environments, we augment the navigation foundation model with a closed-loop Perspective-n-Point (PnP) localization mechanism, ensuring precise alignment of visual goals and effectively bridging autonomous navigation and dexterous manipulation. Extensive experimental results demonstrate that HERMES consistently exhibits generalizable behaviors across diverse, in-the-wild scenarios, successfully performing numerous complex mobile bimanual dexterous manipulation tasks. Project Page:https://gemcollector.github.io/HERMES/.

