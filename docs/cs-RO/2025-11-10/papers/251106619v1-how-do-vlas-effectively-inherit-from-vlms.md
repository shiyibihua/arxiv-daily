---
layout: default
title: How Do VLAs Effectively Inherit from VLMs?
---

# How Do VLAs Effectively Inherit from VLMs?

**arXiv**: [2511.06619v1](https://arxiv.org/abs/2511.06619) | [PDF](https://arxiv.org/pdf/2511.06619.pdf)

**ä½œè€…**: Chuheng Zhang, Rushuai Yang, Xiaoyu Chen, Kaixin Wang, Li Zhao, Yi Chen, Jiang Bian

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-10

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGrinningFaceåŸºå‡†ï¼Œè¯Šæ–­VLAæ¨¡åž‹ä»ŽVLMæœ‰æ•ˆç»§æ‰¿çŸ¥è¯†çš„èƒ½åŠ›**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡åž‹` `çŸ¥è¯†è¿ç§»` `å…·èº«æ™ºèƒ½` `æœºå™¨äººæ“ä½œ` `è¯Šæ–­åŸºå‡†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. VLAæ¨¡åž‹ä¾èµ–VLMçš„å…ˆéªŒçŸ¥è¯†ï¼Œä½†å¦‚ä½•æœ‰æ•ˆç»§æ‰¿è¿™äº›çŸ¥è¯†ä»æ˜¯æŒ‘æˆ˜ï¼ŒçŽ°æœ‰æœºå™¨äººæ•°æ®é›†ç¼ºä¹VLMé¢„è®­ç»ƒä¸­å¸¸è§çš„è¯­ä¹‰ä¿¡æ¯ã€‚
2. è®ºæ–‡æå‡ºGrinningFaceåŸºå‡†ï¼Œåˆ©ç”¨æœºå™¨äººæ“ä½œemojiçš„ä»»åŠ¡ï¼Œè¯„ä¼°VLAæ¨¡åž‹ä»ŽVLMè¿ç§»çŸ¥è¯†çš„èƒ½åŠ›ï¼Œemojiä½œä¸ºVLMçŸ¥è¯†çš„ä»£ç†ã€‚
3. é€šè¿‡åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žæœºå™¨äººçŽ¯å¢ƒä¸­çš„å®žéªŒï¼Œç³»ç»Ÿè¯„ä¼°äº†å¤šç§çŸ¥è¯†è¿ç§»æŠ€æœ¯ï¼Œä¸ºVLAæ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›æä¾›äº†æŒ‡å¯¼ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡åž‹æœ‰æœ›å®žçŽ°é€šç”¨å…·èº«æŽ§åˆ¶ã€‚ä¸€ç§å¸¸è§èŒƒå¼æ˜¯åˆ©ç”¨å¤§åž‹è§†è§‰-è¯­è¨€æ¨¡åž‹(VLM)ä¸°å¯Œçš„è§†è§‰-è¯­ä¹‰å…ˆéªŒçŸ¥è¯†ã€‚ç„¶è€Œï¼Œä¸€ä¸ªæ ¹æœ¬é—®é¢˜ä¾ç„¶å­˜åœ¨ï¼šVLAå¦‚ä½•æœ‰æ•ˆåœ°ç»§æ‰¿VLMçš„å…ˆéªŒçŸ¥è¯†ï¼Ÿä¸ºäº†è§£å†³è¿™ä¸ªå…³é”®é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè¯Šæ–­åŸºå‡†GrinningFaceï¼Œè¿™æ˜¯ä¸€ä¸ªemojiæ¡Œé¢æ“ä½œä»»åŠ¡ï¼Œè¦æ±‚æœºå™¨äººæ‰‹è‡‚å°†ç‰©ä½“æ”¾ç½®åˆ°ä¸Žè¯­è¨€æŒ‡ä»¤ç›¸å¯¹åº”çš„æ‰“å°emojiä¸Šã€‚è¿™ç§ä»»åŠ¡è®¾è®¡ç‰¹åˆ«å…·æœ‰å¯å‘æ€§â€”â€”ä¸Žemojiç›¸å…³çš„çŸ¥è¯†åœ¨ç”¨äºŽVLMé¢„è®­ç»ƒçš„äº’è”ç½‘è§„æ¨¡æ•°æ®é›†ä¸­æ— å¤„ä¸åœ¨ï¼Œä½†emojiæœ¬èº«åœ¨æ ‡å‡†æœºå™¨äººæ•°æ®é›†ä¸­å´åŸºæœ¬ä¸å­˜åœ¨ã€‚å› æ­¤ï¼Œå®ƒä»¬æä¾›äº†ä¸€ä¸ªæ¸…æ™°çš„ä»£ç†ï¼šæˆåŠŸå®Œæˆä»»åŠ¡è¡¨æ˜ŽVLMå…ˆéªŒçŸ¥è¯†å·²æœ‰æ•ˆè½¬ç§»åˆ°å…·èº«æŽ§åˆ¶ã€‚æˆ‘ä»¬åœ¨æ¨¡æ‹ŸçŽ¯å¢ƒå’ŒçœŸå®žæœºå™¨äººä¸­éƒ½å®žçŽ°äº†è¿™ä¸ªè¯Šæ–­ä»»åŠ¡ï¼Œå¹¶æ¯”è¾ƒäº†å„ç§æœ‰å‰æ™¯çš„çŸ¥è¯†è½¬ç§»æŠ€æœ¯ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å‚æ•°é«˜æ•ˆå¾®è°ƒã€VLMå†»ç»“ã€ååŒè®­ç»ƒã€é¢„æµ‹ç¦»æ•£åŠ¨ä½œå’Œé¢„æµ‹æ½œåœ¨åŠ¨ä½œçš„æ•ˆæžœã€‚é€šè¿‡ç³»ç»Ÿè¯„ä¼°ï¼Œæˆ‘ä»¬çš„å·¥ä½œä¸ä»…è¯æ˜Žäº†ä¿ç•™VLMå…ˆéªŒçŸ¥è¯†å¯¹äºŽVLAæ³›åŒ–çš„é‡è¦æ€§ï¼Œè€Œä¸”ä¸ºæœªæ¥å¼€å‘çœŸæ­£é€šç”¨çš„å…·èº«AIç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šVLAæ¨¡åž‹æ—¨åœ¨å®žçŽ°é€šç”¨å…·èº«æŽ§åˆ¶ï¼Œä½†å¦‚ä½•æœ‰æ•ˆåˆ©ç”¨VLMä¸­é¢„è®­ç»ƒçš„çŸ¥è¯†æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•åœ¨å°†VLMçŸ¥è¯†è¿ç§»åˆ°VLAæ—¶ï¼Œç¼ºä¹æœ‰æ•ˆçš„è¯„ä¼°å’Œè¯Šæ–­å·¥å…·ï¼Œéš¾ä»¥ç†è§£å“ªäº›çŸ¥è¯†è¢«æˆåŠŸè¿ç§»ï¼Œä»¥åŠå“ªäº›è¿ç§»ç­–ç•¥æ›´æœ‰æ•ˆã€‚æ ‡å‡†æœºå™¨äººæ•°æ®é›†é€šå¸¸ä¸åŒ…å«VLMé¢„è®­ç»ƒä¸­å¸¸è§çš„è¯­ä¹‰ä¿¡æ¯ï¼Œè¿™ä½¿å¾—è¯„ä¼°VLAæ¨¡åž‹å¯¹æ–°æ¦‚å¿µçš„æ³›åŒ–èƒ½åŠ›å˜å¾—å›°éš¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªè¯Šæ–­åŸºå‡†ï¼Œè¯¥åŸºå‡†èƒ½å¤Ÿæ¸…æ™°åœ°åæ˜ VLAæ¨¡åž‹ä»ŽVLMç»§æ‰¿çŸ¥è¯†çš„èƒ½åŠ›ã€‚é€šè¿‡å¼•å…¥åŒ…å«VLMé¢„è®­ç»ƒçŸ¥è¯†ä½†æœºå™¨äººæ•°æ®é›†ç¼ºä¹çš„å…ƒç´ ï¼ˆå³emojiï¼‰ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªâ€œçŸ¥è¯†ä»£ç†â€ï¼ŒæˆåŠŸå®ŒæˆåŸºäºŽemojiçš„ä»»åŠ¡è¡¨æ˜ŽVLAæ¨¡åž‹å·²æœ‰æ•ˆåˆ©ç”¨VLMçš„å…ˆéªŒçŸ¥è¯†ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªå…³é”®éƒ¨åˆ†ï¼š1) **GrinningFaceåŸºå‡†**ï¼šå®šä¹‰äº†emojiæ¡Œé¢æ“ä½œä»»åŠ¡ï¼Œè¦æ±‚æœºå™¨äººæ ¹æ®è¯­è¨€æŒ‡ä»¤å°†ç‰©ä½“æ”¾ç½®åˆ°å¯¹åº”çš„emojiä¸Šã€‚2) **æ¨¡æ‹ŸçŽ¯å¢ƒå’ŒçœŸå®žæœºå™¨äººå¹³å°**ï¼šåœ¨ä¸¤ç§çŽ¯å¢ƒä¸‹å®žçŽ°è¯¥åŸºå‡†ï¼Œä»¥è¯„ä¼°ä¸åŒçŸ¥è¯†è¿ç§»ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚3) **å¤šç§çŸ¥è¯†è¿ç§»æŠ€æœ¯**ï¼šæ¯”è¾ƒäº†å‚æ•°é«˜æ•ˆå¾®è°ƒã€VLMå†»ç»“ã€ååŒè®­ç»ƒã€é¢„æµ‹ç¦»æ•£åŠ¨ä½œå’Œé¢„æµ‹æ½œåœ¨åŠ¨ä½œç­‰æ–¹æ³•ã€‚4) **ç³»ç»Ÿè¯„ä¼°**ï¼šé€šè¿‡å®žéªŒåˆ†æžä¸åŒæ–¹æ³•åœ¨GrinningFaceåŸºå‡†ä¸Šçš„æ€§èƒ½ï¼Œä»Žè€Œä¸ºVLAæ¨¡åž‹çš„çŸ¥è¯†è¿ç§»æä¾›æŒ‡å¯¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽæå‡ºäº†GrinningFaceåŸºå‡†ï¼Œå®ƒæä¾›äº†ä¸€ç§æ–°çš„è§†è§’æ¥è¯„ä¼°VLAæ¨¡åž‹ä»ŽVLMç»§æ‰¿çŸ¥è¯†çš„èƒ½åŠ›ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒGrinningFaceåŸºå‡†èƒ½å¤Ÿæ›´æ¸…æ™°åœ°è¯Šæ–­VLAæ¨¡åž‹å¯¹VLMå…ˆéªŒçŸ¥è¯†çš„åˆ©ç”¨æƒ…å†µï¼Œå¹¶ä¸ºçŸ¥è¯†è¿ç§»ç­–ç•¥çš„é€‰æ‹©æä¾›ä¾æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šGrinningFaceåŸºå‡†çš„å…³é”®è®¾è®¡åœ¨äºŽé€‰æ‹©emojiä½œä¸ºçŸ¥è¯†ä»£ç†ã€‚Emojiåœ¨äº’è”ç½‘è§„æ¨¡çš„æ•°æ®é›†ä¸­å¹¿æ³›å­˜åœ¨ï¼ŒVLMåœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­å·²ç»å­¦ä¹ äº†ç›¸å…³çš„è¯­ä¹‰çŸ¥è¯†ã€‚ç„¶è€Œï¼Œemojiåœ¨æ ‡å‡†æœºå™¨äººæ•°æ®é›†ä¸­å´å¾ˆå°‘å‡ºçŽ°ï¼Œè¿™ä½¿å¾—GrinningFaceåŸºå‡†èƒ½å¤Ÿæ¸…æ™°åœ°è¯„ä¼°VLAæ¨¡åž‹å¯¹VLMå…ˆéªŒçŸ¥è¯†çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æŽ¢ç´¢äº†ä¸åŒçš„åŠ¨ä½œè¡¨ç¤ºæ–¹æ³•ï¼ˆç¦»æ•£åŠ¨ä½œå’Œæ½œåœ¨åŠ¨ä½œï¼‰ï¼Œä»¥åŠä¸åŒçš„è®­ç»ƒç­–ç•¥ï¼ˆå‚æ•°é«˜æ•ˆå¾®è°ƒã€VLMå†»ç»“ã€ååŒè®­ç»ƒï¼‰ï¼Œä»¥ç ”ç©¶å®ƒä»¬å¯¹çŸ¥è¯†è¿ç§»çš„å½±å“ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œä¿ç•™VLMçš„å…ˆéªŒçŸ¥è¯†å¯¹äºŽVLAæ¨¡åž‹çš„æ³›åŒ–è‡³å…³é‡è¦ã€‚é€šè¿‡GrinningFaceåŸºå‡†çš„è¯„ä¼°ï¼Œè®ºæ–‡æ¯”è¾ƒäº†ä¸åŒçŸ¥è¯†è¿ç§»ç­–ç•¥çš„æ€§èƒ½ï¼Œä¸ºæœªæ¥VLAæ¨¡åž‹çš„è®¾è®¡æä¾›äº†æŒ‡å¯¼ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†ç³»ç»Ÿè¯„ä¼°çš„é‡è¦æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†æ˜Žç¡®çš„å»ºè®®ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽæœºå™¨äººé€šç”¨æŠ€èƒ½å­¦ä¹ ã€æ™ºèƒ½å®¶å±…æœåŠ¡æœºå™¨äººã€è‡ªåŠ¨åŒ–è£…é…ç­‰é¢†åŸŸã€‚é€šè¿‡æœ‰æ•ˆç»§æ‰¿VLMçš„çŸ¥è¯†ï¼Œæœºå™¨äººèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£äººç±»æŒ‡ä»¤ï¼Œå®Œæˆæ›´å¤æ‚çš„ä»»åŠ¡ï¼Œå¹¶å…·å¤‡æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥æŽ¨åŠ¨å…·èº«æ™ºèƒ½çš„å‘å±•ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”çœŸå®žä¸–ç•ŒçŽ¯å¢ƒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-language-action (VLA) models hold the promise to attain generalizable embodied control. To achieve this, a pervasive paradigm is to leverage the rich vision-semantic priors of large vision-language models (VLMs). However, the fundamental question persists: How do VLAs effectively inherit the prior knowledge from VLMs? To address this critical question, we introduce a diagnostic benchmark, GrinningFace, an emoji tabletop manipulation task where the robot arm is asked to place objects onto printed emojis corresponding to language instructions. This task design is particularly revealing -- knowledge associated with emojis is ubiquitous in Internet-scale datasets used for VLM pre-training, yet emojis themselves are largely absent from standard robotics datasets. Consequently, they provide a clean proxy: successful task completion indicates effective transfer of VLM priors to embodied control. We implement this diagnostic task in both simulated environment and a real robot, and compare various promising techniques for knowledge transfer. Specifically, we investigate the effects of parameter-efficient fine-tuning, VLM freezing, co-training, predicting discretized actions, and predicting latent actions. Through systematic evaluation, our work not only demonstrates the critical importance of preserving VLM priors for the generalization of VLA but also establishes guidelines for future research in developing truly generalizable embodied AI systems.

