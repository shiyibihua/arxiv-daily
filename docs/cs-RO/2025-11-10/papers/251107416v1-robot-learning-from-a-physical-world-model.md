---
layout: default
title: Robot Learning from a Physical World Model
---

# Robot Learning from a Physical World Model

**arXiv**: [2511.07416v1](https://arxiv.org/abs/2511.07416) | [PDF](https://arxiv.org/pdf/2511.07416.pdf)

**ä½œè€…**: Jiageng Mao, Sicheng He, Hao-Ning Wu, Yang You, Shuyang Sun, Zhicheng Wang, Yanan Bao, Huizhong Chen, Leonidas Guibas, Vitor Guizilini, Howard Zhou, Yue Wang

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-10

**å¤‡æ³¨**: Project page: https://pointscoder.github.io/PhysWorld_Web/

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://pointscoder.github.io/PhysWorld_Web/)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PhysWorldï¼šé€šè¿‡ç‰©ç†ä¸–ç•Œå»ºæ¨¡å®žçŽ°æœºå™¨äººä»Žè§†é¢‘ç”Ÿæˆä¸­å­¦ä¹ **

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸ŽåŒ¹é… (Video Extraction & Matching)**

**å…³é”®è¯**: `æœºå™¨äººå­¦ä¹ ` `è§†é¢‘ç”Ÿæˆ` `ç‰©ç†ä¸–ç•Œå»ºæ¨¡` `å¼ºåŒ–å­¦ä¹ ` `æœºå™¨äººæ“ä½œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ç›´æŽ¥å°†ç”Ÿæˆè§†é¢‘çš„åƒç´ è¿åŠ¨è¿ç§»åˆ°æœºå™¨äººï¼Œå¿½ç•¥äº†ç‰©ç†è§„å¾‹ï¼Œå¯¼è‡´æ“ä½œä¸å‡†ç¡®ã€‚
2. PhysWorldå°†è§†é¢‘ç”Ÿæˆä¸Žç‰©ç†ä¸–ç•Œé‡å»ºç›¸ç»“åˆï¼Œåˆ©ç”¨ç‰©ç†ä¸–ç•Œæ¨¡åž‹å°†è§†è§‰æŒ‡å¯¼è½¬åŒ–ä¸ºç‰©ç†ä¸Šå¯æ‰§è¡Œçš„æœºå™¨äººè½¨è¿¹ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒPhysWorldåœ¨å„ç§çœŸå®žä¸–ç•Œä»»åŠ¡ä¸­æ˜¾è‘—æé«˜äº†æ“ä½œç²¾åº¦ï¼Œå®žçŽ°äº†é›¶æ ·æœ¬æ³›åŒ–ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºPhysWorldæ¡†æž¶ï¼Œé€šè¿‡ç‰©ç†ä¸–ç•Œå»ºæ¨¡å®žçŽ°æœºå™¨äººä»Žè§†é¢‘ç”Ÿæˆä¸­å­¦ä¹ ã€‚çŽ°æœ‰çš„è§†é¢‘ç”Ÿæˆæ¨¡åž‹èƒ½å¤Ÿä»Žè¯­è¨€æŒ‡ä»¤å’Œå›¾åƒä¸­åˆæˆé€¼çœŸçš„è§†è§‰æ¼”ç¤ºï¼Œä¸ºæœºå™¨äººæŠ€æœ¯æä¾›äº†ä¸€ç§å¼ºå¤§ä½†æœªè¢«å……åˆ†åˆ©ç”¨çš„è®­ç»ƒä¿¡å·æ¥æºã€‚ç„¶è€Œï¼Œç›´æŽ¥å°†ç”Ÿæˆè§†é¢‘ä¸­çš„åƒç´ è¿åŠ¨é‡æ–°å®šå‘åˆ°æœºå™¨äººä¸Šä¼šå¿½ç•¥ç‰©ç†è§„å¾‹ï¼Œå¯¼è‡´æ“ä½œä¸å‡†ç¡®ã€‚PhysWorldé€šè¿‡å°†è§†é¢‘ç”Ÿæˆä¸Žç‰©ç†ä¸–ç•Œé‡å»ºç›¸ç»“åˆæ¥è§£å†³è¿™ä¸€å±€é™æ€§ã€‚ç»™å®šå•ä¸ªå›¾åƒå’Œä»»åŠ¡æŒ‡ä»¤ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆä»»åŠ¡ç›¸å…³çš„è§†é¢‘ï¼Œå¹¶ä»Žè§†é¢‘ä¸­é‡å»ºæ½œåœ¨çš„ç‰©ç†ä¸–ç•Œã€‚é€šè¿‡ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„æ®‹å·®å¼ºåŒ–å­¦ä¹ å’Œç‰©ç†ä¸–ç•Œæ¨¡åž‹ï¼Œç”Ÿæˆçš„è§†é¢‘è¿åŠ¨è¢«è½¬åŒ–ä¸ºç‰©ç†ä¸Šç²¾ç¡®çš„åŠ¨ä½œã€‚è¿™ç§ååŒä½œç”¨å°†éšå¼çš„è§†è§‰æŒ‡å¯¼è½¬åŒ–ä¸ºç‰©ç†ä¸Šå¯æ‰§è¡Œçš„æœºå™¨äººè½¨è¿¹ï¼Œæ— éœ€çœŸå®žæœºå™¨äººæ•°æ®æ”¶é›†ï¼Œå¹¶å®žçŽ°é›¶æ ·æœ¬æ³›åŒ–çš„æœºå™¨äººæ“ä½œã€‚åœ¨å„ç§çœŸå®žä¸–ç•Œä»»åŠ¡ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œä¸Žä»¥å‰çš„æ–¹æ³•ç›¸æ¯”ï¼ŒPhysWorldæ˜¾è‘—æé«˜äº†æ“ä½œç²¾åº¦ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•åˆ©ç”¨è§†é¢‘ç”Ÿæˆæ¨¡åž‹ä¸ºæœºå™¨äººæä¾›è®­ç»ƒæ•°æ®ï¼Œä½†çŽ°æœ‰æ–¹æ³•ç›´æŽ¥å°†ç”Ÿæˆè§†é¢‘çš„åƒç´ è¿åŠ¨è¿ç§»åˆ°æœºå™¨äººï¼Œå¿½ç•¥äº†ç‰©ç†è§„å¾‹ï¼Œå¯¼è‡´æ“ä½œä¸å‡†ç¡®ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ–¹æ³•èƒ½å¤Ÿå°†è§†é¢‘ä¸­çš„è§†è§‰ä¿¡æ¯è½¬åŒ–ä¸ºç‰©ç†ä¸Šå¯è¡Œçš„æœºå™¨äººåŠ¨ä½œã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è§†é¢‘ç”Ÿæˆä¸Žç‰©ç†ä¸–ç•Œé‡å»ºç›¸ç»“åˆã€‚é¦–å…ˆï¼Œåˆ©ç”¨è§†é¢‘ç”Ÿæˆæ¨¡åž‹ç”Ÿæˆä»»åŠ¡ç›¸å…³çš„è§†é¢‘ã€‚ç„¶åŽï¼Œä»Žè§†é¢‘ä¸­é‡å»ºæ½œåœ¨çš„ç‰©ç†ä¸–ç•Œæ¨¡åž‹ã€‚æœ€åŽï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼ŒåŸºäºŽç‰©ç†ä¸–ç•Œæ¨¡åž‹å°†è§†é¢‘ä¸­çš„è§†è§‰ä¿¡æ¯è½¬åŒ–ä¸ºæœºå™¨äººå¯ä»¥æ‰§è¡Œçš„åŠ¨ä½œã€‚è¿™æ ·ï¼Œå°±å¯ä»¥é¿å…ç›´æŽ¥å°†åƒç´ è¿åŠ¨è¿ç§»åˆ°æœºå™¨äººï¼Œä»Žè€Œæé«˜æ“ä½œçš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šPhysWorldæ¡†æž¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) ä»»åŠ¡æ¡ä»¶è§†é¢‘ç”Ÿæˆæ¨¡å—ï¼Œç”¨äºŽç”Ÿæˆä»»åŠ¡ç›¸å…³çš„è§†é¢‘ï¼›2) ç‰©ç†ä¸–ç•Œé‡å»ºæ¨¡å—ï¼Œç”¨äºŽä»Žè§†é¢‘ä¸­é‡å»ºç‰©ç†ä¸–ç•Œæ¨¡åž‹ï¼›3) ç‰©ä½“ä¸­å¿ƒæ®‹å·®å¼ºåŒ–å­¦ä¹ æ¨¡å—ï¼Œç”¨äºŽåŸºäºŽç‰©ç†ä¸–ç•Œæ¨¡åž‹å°†è§†é¢‘ä¸­çš„è§†è§‰ä¿¡æ¯è½¬åŒ–ä¸ºæœºå™¨äººå¯ä»¥æ‰§è¡Œçš„åŠ¨ä½œã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼šç»™å®šä¸€ä¸ªå›¾åƒå’Œä»»åŠ¡æŒ‡ä»¤ï¼Œè§†é¢‘ç”Ÿæˆæ¨¡å—ç”Ÿæˆè§†é¢‘ï¼Œç‰©ç†ä¸–ç•Œé‡å»ºæ¨¡å—ä»Žè§†é¢‘ä¸­é‡å»ºç‰©ç†ä¸–ç•Œæ¨¡åž‹ï¼Œå¼ºåŒ–å­¦ä¹ æ¨¡å—åŸºäºŽç‰©ç†ä¸–ç•Œæ¨¡åž‹å­¦ä¹ æŽ§åˆ¶ç­–ç•¥ï¼Œä»Žè€ŒæŽ§åˆ¶æœºå™¨äººå®Œæˆä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽå°†è§†é¢‘ç”Ÿæˆä¸Žç‰©ç†ä¸–ç•Œé‡å»ºç›¸ç»“åˆï¼Œå¹¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ å°†è§†è§‰ä¿¡æ¯è½¬åŒ–ä¸ºç‰©ç†ä¸Šå¯è¡Œçš„æœºå™¨äººåŠ¨ä½œã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒPhysWorldèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨è§†é¢‘ç”Ÿæˆæ¨¡åž‹æä¾›çš„è®­ç»ƒæ•°æ®ï¼Œå¹¶é¿å…äº†ç›´æŽ¥å°†åƒç´ è¿åŠ¨è¿ç§»åˆ°æœºå™¨äººå¸¦æ¥çš„é—®é¢˜ã€‚æ­¤å¤–ï¼Œä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„æ®‹å·®å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¹Ÿæé«˜äº†å­¦ä¹ æ•ˆçŽ‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç‰©ç†ä¸–ç•Œé‡å»ºæ¨¡å—ä¸­ï¼Œè®ºæ–‡ä½¿ç”¨äº†åŸºäºŽç‚¹äº‘çš„è¡¨ç¤ºæ–¹æ³•æ¥è¡¨ç¤ºç‰©ç†ä¸–ç•Œã€‚åœ¨å¼ºåŒ–å­¦ä¹ æ¨¡å—ä¸­ï¼Œè®ºæ–‡ä½¿ç”¨äº†ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„æ®‹å·®å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†æœºå™¨äººçš„åŠ¨ä½œåˆ†è§£ä¸ºå¤šä¸ªç‰©ä½“çš„åŠ¨ä½œï¼Œå¹¶å­¦ä¹ æ¯ä¸ªç‰©ä½“çš„æ®‹å·®åŠ¨ä½œã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬å¥–åŠ±å‡½æ•°å’Œæ­£åˆ™åŒ–é¡¹ï¼Œå¥–åŠ±å‡½æ•°ç”¨äºŽé¼“åŠ±æœºå™¨äººå®Œæˆä»»åŠ¡ï¼Œæ­£åˆ™åŒ–é¡¹ç”¨äºŽçº¦æŸæœºå™¨äººçš„åŠ¨ä½œã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒPhysWorldåœ¨å¤šä¸ªçœŸå®žä¸–ç•Œä»»åŠ¡ä¸­æ˜¾è‘—æé«˜äº†æ“ä½œç²¾åº¦ã€‚ä¾‹å¦‚ï¼Œåœ¨å †å ç§¯æœ¨ä»»åŠ¡ä¸­ï¼ŒPhysWorldçš„æˆåŠŸçŽ‡æ¯”åŸºçº¿æ–¹æ³•æé«˜äº†20%ä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒPhysWorldè¿˜å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¯ä»¥åœ¨ä¸åŒçš„åœºæ™¯å’Œç‰©ä½“ä¸Šè¿›è¡Œæ“ä½œã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒPhysWorldæ˜¯ä¸€ç§æœ‰æ•ˆçš„æœºå™¨äººå­¦ä¹ æ–¹æ³•ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

PhysWorldå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºŽå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚ç‰©ä½“æŠ“å–ã€è£…é…ã€å¯¼èˆªç­‰ã€‚è¯¥æ–¹æ³•å¯ä»¥é™ä½Žæœºå™¨äººå­¦ä¹ çš„æˆæœ¬ï¼Œæé«˜æœºå™¨äººçš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¿ƒè¿›æœºå™¨äººåœ¨åˆ¶é€ ä¸šã€ç‰©æµã€åŒ»ç–—ç­‰é¢†åŸŸçš„åº”ç”¨ã€‚æœªæ¥ï¼Œå¯ä»¥å°†PhysWorldä¸Žå…¶ä»–æŠ€æœ¯ç›¸ç»“åˆï¼Œä¾‹å¦‚æ¨¡ä»¿å­¦ä¹ ã€å…ƒå­¦ä¹ ç­‰ï¼Œè¿›ä¸€æ­¥æé«˜æœºå™¨äººçš„æ™ºèƒ½æ°´å¹³ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce PhysWorld, a framework that enables robot learning from video generation through physical world modeling. Recent video generation models can synthesize photorealistic visual demonstrations from language commands and images, offering a powerful yet underexplored source of training signals for robotics. However, directly retargeting pixel motions from generated videos to robots neglects physics, often resulting in inaccurate manipulations. PhysWorld addresses this limitation by coupling video generation with physical world reconstruction. Given a single image and a task command, our method generates task-conditioned videos and reconstructs the underlying physical world from the videos, and the generated video motions are grounded into physically accurate actions through object-centric residual reinforcement learning with the physical world model. This synergy transforms implicit visual guidance into physically executable robotic trajectories, eliminating the need for real robot data collection and enabling zero-shot generalizable robotic manipulation. Experiments on diverse real-world tasks demonstrate that PhysWorld substantially improves manipulation accuracy compared to previous approaches. Visit \href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage} for details.

