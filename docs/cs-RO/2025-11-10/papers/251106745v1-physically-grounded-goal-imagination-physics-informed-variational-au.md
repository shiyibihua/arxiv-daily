---
layout: default
title: Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning
---

# Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning

**arXiv**: [2511.06745v1](https://arxiv.org/abs/2511.06745) | [PDF](https://arxiv.org/pdf/2511.06745.pdf)

**ä½œè€…**: Lan Thi Ha Nguyen, Kien Ton Manh, Anh Do Duc, Nam Pham Hai

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-10

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç‰©ç†ä¿¡æ¯å¢žå¼ºçš„å˜åˆ†è‡ªç¼–ç å™¨ï¼Œæå‡è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ ä¸­ç›®æ ‡ç”Ÿæˆçš„ç‰©ç†åˆç†æ€§ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ ` `ç›®æ ‡ç”Ÿæˆ` `å˜åˆ†è‡ªç¼–ç å™¨` `ç‰©ç†ä¿¡æ¯` `æœºå™¨äººæ“ä½œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨ç›®æ ‡ç”Ÿæˆæ–¹é¢å­˜åœ¨ç¼ºé™·ï¼Œç”Ÿæˆçš„è™šæ‹Ÿç›®æ ‡å¯èƒ½ä¸ç¬¦åˆç‰©ç†è§„å¾‹ï¼Œå½±å“å­¦ä¹ æ•ˆçŽ‡ã€‚
2. è®ºæ–‡æå‡ºPI-RIGï¼Œé€šè¿‡å¢žå¼ºåž‹ç‰©ç†ä¿¡æ¯VAEï¼ˆEnhanced p3-VAEï¼‰å°†ç‰©ç†çº¦æŸèžå…¥ç›®æ ‡ç”Ÿæˆè¿‡ç¨‹ï¼Œç¡®ä¿ç›®æ ‡ç‰©ç†åˆç†æ€§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„ç‰©ç†åˆç†ç›®æ ‡èƒ½æ˜¾è‘—æå‡æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­çš„æŽ¢ç´¢æ•ˆçŽ‡å’ŒæŠ€èƒ½å­¦ä¹ æ•ˆæžœã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªç›‘ç£ç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹ ä½¿æœºå™¨äººèƒ½å¤Ÿåœ¨æ— äººä¸ºå¹²é¢„çš„æƒ…å†µä¸‹è‡ªä¸»å­¦ä¹ å„ç§æŠ€èƒ½ã€‚ç„¶è€Œï¼Œä¸€ä¸ªæ ¸å¿ƒæŒ‘æˆ˜æ˜¯ç›®æ ‡è®¾å®šé—®é¢˜ï¼šæœºå™¨äººå¿…é¡»æå‡ºåœ¨å…¶å½“å‰çŽ¯å¢ƒä¸­å¯å®žçŽ°çš„å¯è¡Œä¸”å¤šæ ·åŒ–çš„ç›®æ ‡ã€‚çŽ°æœ‰çš„æ–¹æ³•ï¼Œå¦‚RIGï¼ˆVisual Reinforcement Learning with Imagined Goalsï¼‰ï¼Œä½¿ç”¨å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰åœ¨å­¦ä¹ åˆ°çš„æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç›®æ ‡ï¼Œä½†å­˜åœ¨äº§ç”Ÿç‰©ç†ä¸Šä¸åˆç†çš„ç›®æ ‡çš„å±€é™æ€§ï¼Œè¿™é˜»ç¢äº†å­¦ä¹ æ•ˆçŽ‡ã€‚æˆ‘ä»¬æå‡ºäº†Physics-Informed RIGï¼ˆPI-RIGï¼‰ï¼Œå®ƒé€šè¿‡ä¸€ç§æ–°é¢–çš„å¢žå¼ºåž‹ç‰©ç†ä¿¡æ¯å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆEnhanced p3-VAEï¼‰å°†ç‰©ç†çº¦æŸç›´æŽ¥é›†æˆåˆ°VAEè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä»Žè€Œèƒ½å¤Ÿç”Ÿæˆç‰©ç†ä¸Šä¸€è‡´ä¸”å¯å®žçŽ°çš„ç›®æ ‡ã€‚æˆ‘ä»¬çš„å…³é”®åˆ›æ–°æ˜¯å°†æ½œåœ¨ç©ºé—´æ˜¾å¼åœ°åˆ†ç¦»ä¸ºæŽ§åˆ¶å¯¹è±¡åŠ¨åŠ›å­¦çš„ç‰©ç†å˜é‡å’Œæ•èŽ·è§†è§‰å¤–è§‚çš„çŽ¯å¢ƒå› ç´ ï¼ŒåŒæ—¶é€šè¿‡å¾®åˆ†æ–¹ç¨‹çº¦æŸå’Œå®ˆæ’å®šå¾‹æ¥å¼ºåˆ¶ç‰©ç†ä¸€è‡´æ€§ã€‚è¿™ä½¿å¾—èƒ½å¤Ÿç”Ÿæˆç¬¦åˆç‰©ä½“æ°¸å­˜æ€§ã€ç¢°æ’žçº¦æŸå’ŒåŠ¨æ€å¯è¡Œæ€§ç­‰åŸºæœ¬ç‰©ç†åŽŸç†çš„ç‰©ç†ä¸Šä¸€è‡´ä¸”å¯å®žçŽ°çš„ç›®æ ‡ã€‚é€šè¿‡å¹¿æ³›çš„å®žéªŒï¼Œæˆ‘ä»¬è¯æ˜Žäº†è¿™ç§ç‰©ç†ä¿¡æ¯ç›®æ ‡ç”Ÿæˆæ˜¾è‘—æé«˜äº†æ‰€æå‡ºç›®æ ‡çš„è´¨é‡ï¼Œä»Žè€Œåœ¨åŒ…æ‹¬æŠ“å–ã€æŽ¨åŠ¨å’Œæ‹¾å–æ”¾ç½®åœºæ™¯åœ¨å†…çš„è§†è§‰æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­å®žçŽ°äº†æ›´æœ‰æ•ˆçš„æŽ¢ç´¢å’Œæ›´å¥½çš„æŠ€èƒ½èŽ·å–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰åŸºäºŽVAEçš„ç›®æ ‡ç”Ÿæˆæ–¹æ³•ï¼Œå¦‚RIGï¼Œåœ¨è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ ä¸­å­˜åœ¨ç”Ÿæˆç‰©ç†ä¸Šä¸å¯è¡Œç›®æ ‡çš„ç¼ºé™·ã€‚è¿™äº›ä¸åˆ‡å®žé™…çš„ç›®æ ‡ä¼šè¯¯å¯¼æ™ºèƒ½ä½“çš„æŽ¢ç´¢ï¼Œé™ä½Žå­¦ä¹ æ•ˆçŽ‡ï¼Œé˜»ç¢å…¶æŽŒæ¡å¤æ‚æ“ä½œæŠ€èƒ½ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿç”Ÿæˆç¬¦åˆç‰©ç†è§„å¾‹ã€å¯å®žçŽ°çš„ç›®æ ‡çš„æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ç‰©ç†çŸ¥è¯†æ˜¾å¼åœ°èžå…¥åˆ°ç›®æ ‡ç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚å…·ä½“è€Œè¨€ï¼Œé€šè¿‡è®¾è®¡ä¸€ç§å¢žå¼ºåž‹ç‰©ç†ä¿¡æ¯VAEï¼ˆEnhanced p3-VAEï¼‰ï¼Œåœ¨VAEçš„è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥ç‰©ç†çº¦æŸï¼Œç¡®ä¿ç”Ÿæˆçš„æ½œåœ¨ç©ºé—´èƒ½å¤Ÿåæ˜ ç‰©ç†ä¸–ç•Œçš„è§„å¾‹ï¼Œä»Žè€Œç”Ÿæˆç‰©ç†ä¸Šåˆç†çš„ç›®æ ‡ã€‚è¿™ç§æ–¹æ³•é¿å…äº†æ™ºèƒ½ä½“åœ¨ä¸åˆ‡å®žé™…çš„ç›®æ ‡ä¸Šæµªè´¹æŽ¢ç´¢èµ„æºã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šPI-RIGçš„æ•´ä½“æ¡†æž¶åŸºäºŽRIGï¼Œä½†å…³é”®åœ¨äºŽç›®æ ‡ç”Ÿæˆæ¨¡å—çš„æ”¹è¿›ã€‚é¦–å…ˆï¼Œä½¿ç”¨ç¼–ç å™¨å°†å½“å‰çŽ¯å¢ƒçŠ¶æ€ç¼–ç åˆ°æ½œåœ¨ç©ºé—´ã€‚ç„¶åŽï¼Œå°†æ½œåœ¨ç©ºé—´æ˜¾å¼åœ°åˆ’åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼šç‰©ç†å˜é‡ï¼ˆä¾‹å¦‚ï¼Œç‰©ä½“çš„ä½ç½®ã€é€Ÿåº¦ï¼‰å’ŒçŽ¯å¢ƒå› ç´ ï¼ˆä¾‹å¦‚ï¼Œå…‰ç…§ã€çº¹ç†ï¼‰ã€‚æŽ¥ä¸‹æ¥ï¼Œä½¿ç”¨è§£ç å™¨ä»Žæ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç›®æ ‡çŠ¶æ€ã€‚åœ¨VAEçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé€šè¿‡å¼•å…¥ç‰©ç†çº¦æŸæŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚å¾®åˆ†æ–¹ç¨‹çº¦æŸå’Œå®ˆæ’å®šå¾‹ï¼Œæ¥å¼ºåˆ¶ç‰©ç†å˜é‡æ»¡è¶³ç‰©ç†è§„å¾‹ã€‚æœ€åŽï¼Œä½¿ç”¨ç”Ÿæˆçš„ç›®æ ‡çŠ¶æ€è®­ç»ƒå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽEnhanced p3-VAEçš„è®¾è®¡ï¼Œå®ƒæ˜¾å¼åœ°åˆ†ç¦»äº†æ½œåœ¨ç©ºé—´ï¼Œå¹¶å¼•å…¥äº†ç‰©ç†çº¦æŸæŸå¤±å‡½æ•°ã€‚è¿™ç§åˆ†ç¦»ä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç‰©ç†å˜é‡å’ŒçŽ¯å¢ƒå› ç´ ä¹‹é—´çš„å…³ç³»ï¼Œä»Žè€Œç”Ÿæˆæ›´å‡†ç¡®ã€æ›´åˆç†çš„ç‰©ç†ç›®æ ‡ã€‚ä¸Žä¼ ç»Ÿçš„VAEæ–¹æ³•ç›¸æ¯”ï¼ŒEnhanced p3-VAEèƒ½å¤Ÿç”Ÿæˆç¬¦åˆç‰©ä½“æ°¸å­˜æ€§ã€ç¢°æ’žçº¦æŸå’ŒåŠ¨æ€å¯è¡Œæ€§ç­‰åŸºæœ¬ç‰©ç†åŽŸç†çš„ç›®æ ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šEnhanced p3-VAEçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ½œåœ¨ç©ºé—´çš„åˆ†ç¦»ï¼Œä½¿ç”¨ä¸åŒçš„ç¼–ç å™¨å’Œè§£ç å™¨å¤„ç†ç‰©ç†å˜é‡å’ŒçŽ¯å¢ƒå› ç´ ï¼›2) ç‰©ç†çº¦æŸæŸå¤±å‡½æ•°ï¼ŒåŒ…æ‹¬åŸºäºŽå¾®åˆ†æ–¹ç¨‹çš„çº¦æŸï¼ˆä¾‹å¦‚ï¼Œç‰›é¡¿å®šå¾‹ï¼‰å’ŒåŸºäºŽå®ˆæ’å®šå¾‹çš„çº¦æŸï¼ˆä¾‹å¦‚ï¼Œèƒ½é‡å®ˆæ’ï¼‰ï¼›3) ç½‘ç»œç»“æž„çš„è®¾è®¡ï¼Œä¾‹å¦‚ï¼Œä½¿ç”¨å·ç§¯ç¥žç»ç½‘ç»œå¤„ç†è§†è§‰è¾“å…¥ï¼Œä½¿ç”¨å¾ªçŽ¯ç¥žç»ç½‘ç»œå¤„ç†æ—¶é—´åºåˆ—æ•°æ®ï¼›4) æŸå¤±å‡½æ•°çš„æƒé‡è®¾ç½®ï¼Œéœ€è¦ä»”ç»†è°ƒæ•´ç‰©ç†çº¦æŸæŸå¤±å‡½æ•°çš„æƒé‡ï¼Œä»¥å¹³è¡¡ç‰©ç†çº¦æŸå’Œæ•°æ®æ‹Ÿåˆä¹‹é—´çš„å…³ç³»ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒPI-RIGåœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºŽåŸºçº¿æ–¹æ³•ï¼Œä¾‹å¦‚RIGã€‚åœ¨æŠ“å–ã€æŽ¨åŠ¨å’Œæ‹¾å–æ”¾ç½®ç­‰ä»»åŠ¡ä¸­ï¼ŒPI-RIGèƒ½å¤Ÿæ›´å¿«åœ°å­¦ä¹ åˆ°æœ‰æ•ˆçš„ç­–ç•¥ï¼Œå¹¶è¾¾åˆ°æ›´é«˜çš„æˆåŠŸçŽ‡ã€‚å…·ä½“è€Œè¨€ï¼ŒPI-RIGåœ¨æŸäº›ä»»åŠ¡ä¸­çš„æ€§èƒ½æå‡é«˜è¾¾20%-30%ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼Œç‰©ç†ä¿¡æ¯ç›®æ ‡ç”Ÿæˆèƒ½å¤Ÿæ˜¾è‘—æé«˜è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ çš„æ•ˆçŽ‡å’Œæ•ˆæžœã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯å¹¿æ³›åº”ç”¨äºŽæœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰é¢†åŸŸã€‚é€šè¿‡ç”Ÿæˆç‰©ç†ä¸Šåˆç†çš„ç›®æ ‡ï¼Œå¯ä»¥æå‡æœºå™¨äººåœ¨å¤æ‚çŽ¯å¢ƒä¸­çš„æŽ¢ç´¢æ•ˆçŽ‡å’Œå­¦ä¹ èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°å®Œæˆå„ç§ä»»åŠ¡ï¼Œä¾‹å¦‚ç‰©ä½“æŠ“å–ã€è£…é…ã€å¯¼èˆªç­‰ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºŽè™šæ‹ŸçŽ¯å¢ƒçš„ç”Ÿæˆå’Œä»¿çœŸï¼Œä¸ºæœºå™¨äººå­¦ä¹ æä¾›æ›´çœŸå®žã€æ›´å¯é çš„è®­ç»ƒæ•°æ®ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Self-supervised goal-conditioned reinforcement learning enables robots to autonomously acquire diverse skills without human supervision. However, a central challenge is the goal setting problem: robots must propose feasible and diverse goals that are achievable in their current environment. Existing methods like RIG (Visual Reinforcement Learning with Imagined Goals) use variational autoencoder (VAE) to generate goals in a learned latent space but have the limitation of producing physically implausible goals that hinder learning efficiency. We propose Physics-Informed RIG (PI-RIG), which integrates physical constraints directly into the VAE training process through a novel Enhanced Physics-Informed Variational Autoencoder (Enhanced p3-VAE), enabling the generation of physically consistent and achievable goals. Our key innovation is the explicit separation of the latent space into physics variables governing object dynamics and environmental factors capturing visual appearance, while enforcing physical consistency through differential equation constraints and conservation laws. This enables the generation of physically consistent and achievable goals that respect fundamental physical principles such as object permanence, collision constraints, and dynamic feasibility. Through extensive experiments, we demonstrate that this physics-informed goal generation significantly improves the quality of proposed goals, leading to more effective exploration and better skill acquisition in visual robotic manipulation tasks including reaching, pushing, and pick-and-place scenarios.

