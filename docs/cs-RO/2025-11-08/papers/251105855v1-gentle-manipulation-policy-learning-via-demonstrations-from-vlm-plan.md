---
layout: default
title: Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills
---

# Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills

**arXiv**: [2511.05855v1](https://arxiv.org/abs/2511.05855) | [PDF](https://arxiv.org/pdf/2511.05855.pdf)

**ä½œè€…**: Jiayu Zhou, Qiwei Wu, Jian Li, Zhe Chen, Xiaogang Xiong, Renjing Xu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-08

**å¤‡æ³¨**: Accepted for the 40th Annual AAAI Conference on Artificial Intelligence (2026)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽVLMè§„åˆ’åŽŸå­æŠ€èƒ½çš„æŸ”æ€§æ“ä½œç­–ç•¥å­¦ä¹ æ¡†æž¶ï¼Œæ— éœ€äººå·¥æ¼”ç¤ºã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `æ“ä½œç­–ç•¥å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡åž‹` `å¼ºåŒ–å­¦ä¹ ` `çŸ¥è¯†è’¸é¦` `æœºå™¨äººæ“ä½œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é•¿æ—¶ç¨‹æ“ä½œä»»åŠ¡ä¾èµ–å¤§é‡çœŸå®žæ•°æ®å’Œäººå·¥è®¾è®¡ï¼Œæˆæœ¬é«˜ä¸”éš¾ä»¥æ‰©å±•ã€‚
2. åˆ©ç”¨VLMè¿›è¡Œä»»åŠ¡åˆ†è§£å’ŒæŠ€èƒ½è§„åˆ’ï¼Œç”Ÿæˆä¸“å®¶æ¼”ç¤ºï¼Œå†é€šè¿‡çŸ¥è¯†è’¸é¦å­¦ä¹ ç»Ÿä¸€ç­–ç•¥ã€‚
3. é€šè¿‡æ¨¡æ‹Ÿå’Œç‰©ç†å®žéªŒéªŒè¯ï¼Œè¯¥æ–¹æ³•æ— éœ€äººå·¥æ¼”ç¤ºå³å¯å­¦ä¹ é•¿æ—¶ç¨‹æ“ä½œç­–ç•¥ï¼Œå¹¶å…·å¤‡è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æž¶ï¼Œè¯¥æ¡†æž¶é›†æˆäº†åˆ†å±‚è¯­ä¹‰åˆ†è§£ã€å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ã€è§†è§‰è¯­è¨€æ¨¡åž‹ï¼ˆVLMï¼‰å’ŒçŸ¥è¯†è’¸é¦ï¼Œä»¥å…‹æœé•¿æ—¶ç¨‹ã€æŽ¥è§¦ä¸°å¯Œçš„æ“ä½œä»»åŠ¡ä¸­æ•°æ®éœ€æ±‚å’Œå·¥ç¨‹æŒ‘æˆ˜ã€‚å¤æ‚ä»»åŠ¡è¢«åˆ†è§£ä¸ºåŽŸå­æŠ€èƒ½ï¼Œæ¯ä¸ªåŽŸè¯­çš„ç­–ç•¥ä»…åœ¨æ¨¡æ‹ŸçŽ¯å¢ƒä¸­é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œå¹¶æ˜¾å¼åœ°åŠ å…¥åŠ›çº¦æŸä»¥é˜²æ­¢ç‰©ä½“æŸåã€‚è§†è§‰è¯­è¨€æ¨¡åž‹æ‰§è¡Œé«˜å±‚ä»»åŠ¡åˆ†è§£å’ŒæŠ€èƒ½è§„åˆ’ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„ä¸“å®¶æ¼”ç¤ºã€‚è¿™äº›æ¼”ç¤ºé€šè¿‡è§†è§‰-è§¦è§‰æ‰©æ•£ç­–ç•¥è¢«æç‚¼æˆç»Ÿä¸€çš„ç­–ç•¥ï¼Œç”¨äºŽç«¯åˆ°ç«¯æ‰§è¡Œã€‚é€šè¿‡æ¶ˆèžå®žéªŒæŽ¢ç´¢äº†ä¸åŒçš„åŸºäºŽVLMçš„ä»»åŠ¡è§„åˆ’å™¨ï¼Œä»¥ç¡®å®šæœ€ä½³çš„æ¼”ç¤ºç”Ÿæˆæµç¨‹ï¼Œå¹¶ç³»ç»Ÿåœ°æ¯”è¾ƒäº†ç”¨äºŽæŠ€èƒ½è’¸é¦çš„æ¨¡ä»¿å­¦ä¹ ç®—æ³•ã€‚å¤§é‡çš„æ¨¡æ‹Ÿå®žéªŒå’Œç‰©ç†éƒ¨ç½²éªŒè¯äº†è¯¥æ–¹æ³•å¯ä»¥åœ¨æ²¡æœ‰æ˜‚è´µçš„äººå·¥æ¼”ç¤ºçš„æƒ…å†µä¸‹å®žçŽ°é•¿æ—¶ç¨‹æ“ä½œçš„ç­–ç•¥å­¦ä¹ ï¼ŒåŒæ—¶VLMå¼•å¯¼çš„åŽŸå­æŠ€èƒ½æ¡†æž¶èƒ½å¤Ÿæ‰©å±•æ³›åŒ–åˆ°ä¸åŒçš„ä»»åŠ¡ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰é•¿æ—¶ç¨‹ã€æŽ¥è§¦ä¸°å¯Œçš„æ“ä½œä»»åŠ¡ï¼Œéœ€è¦å¤§é‡çœŸå®žä¸–ç•Œæ•°æ®å’Œä¸“å®¶å·¥ç¨‹ï¼Œå¯¼è‡´æˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥æ‰©å±•ã€‚å°¤å…¶æ˜¯åœ¨æŸ”æ€§æ“ä½œä¸­ï¼Œéœ€è¦ç²¾ç¡®æŽ§åˆ¶åŠ›ä»¥é¿å…æŸåç‰©ä½“ï¼Œè¿™è¿›ä¸€æ­¥å¢žåŠ äº†æ•°æ®æ”¶é›†çš„éš¾åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºä¸€ç³»åˆ—åŽŸå­æŠ€èƒ½ï¼Œæ¯ä¸ªæŠ€èƒ½é€šè¿‡å¼ºåŒ–å­¦ä¹ åœ¨æ¨¡æ‹ŸçŽ¯å¢ƒä¸­è®­ç»ƒã€‚åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡åž‹ï¼ˆVLMï¼‰è¿›è¡Œé«˜å±‚ä»»åŠ¡åˆ†è§£å’ŒæŠ€èƒ½è§„åˆ’ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„ä¸“å®¶æ¼”ç¤ºã€‚ç„¶åŽï¼Œé€šè¿‡æ¨¡ä»¿å­¦ä¹ å°†è¿™äº›æ¼”ç¤ºæç‚¼æˆä¸€ä¸ªç»Ÿä¸€çš„ç­–ç•¥ï¼Œå®žçŽ°ç«¯åˆ°ç«¯çš„ä»»åŠ¡æ‰§è¡Œã€‚æ ¸å¿ƒåœ¨äºŽåˆ©ç”¨VLMçš„å¼ºå¤§è¯­ä¹‰ç†è§£èƒ½åŠ›æ¥æŒ‡å¯¼æŠ€èƒ½è§„åˆ’ï¼Œä»Žè€Œé¿å…äº†å¯¹å¤§é‡äººå·¥æ¼”ç¤ºæ•°æ®çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1) **åŽŸå­æŠ€èƒ½å­¦ä¹ **ï¼šä½¿ç”¨å¼ºåŒ–å­¦ä¹ åœ¨æ¨¡æ‹ŸçŽ¯å¢ƒä¸­è®­ç»ƒæ¯ä¸ªåŽŸå­æŠ€èƒ½çš„ç­–ç•¥ï¼Œå¹¶åŠ å…¥åŠ›çº¦æŸã€‚2) **VLMä»»åŠ¡è§„åˆ’**ï¼šåˆ©ç”¨VLMè¿›è¡Œé«˜å±‚ä»»åŠ¡åˆ†è§£å’ŒæŠ€èƒ½è§„åˆ’ï¼Œç”Ÿæˆä¸€ç³»åˆ—åŽŸå­æŠ€èƒ½åºåˆ—ä½œä¸ºä¸“å®¶æ¼”ç¤ºã€‚3) **ç­–ç•¥è’¸é¦**ï¼šä½¿ç”¨æ¨¡ä»¿å­¦ä¹ å°†VLMç”Ÿæˆçš„ä¸“å®¶æ¼”ç¤ºæç‚¼æˆä¸€ä¸ªç»Ÿä¸€çš„ç­–ç•¥ï¼Œç”¨äºŽç«¯åˆ°ç«¯çš„ä»»åŠ¡æ‰§è¡Œã€‚è¯¥æ¡†æž¶é‡‡ç”¨åˆ†å±‚ç»“æž„ï¼Œå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºæ˜“äºŽå­¦ä¹ å’Œæ³›åŒ–çš„åŽŸå­æŠ€èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºŽå°†è§†è§‰è¯­è¨€æ¨¡åž‹ï¼ˆVLMï¼‰å¼•å…¥åˆ°æ“ä½œç­–ç•¥å­¦ä¹ ä¸­ï¼Œåˆ©ç”¨VLMçš„è¯­ä¹‰ç†è§£å’Œè§„åˆ’èƒ½åŠ›æ¥ç”Ÿæˆä¸“å®¶æ¼”ç¤ºï¼Œä»Žè€Œé¿å…äº†å¯¹å¤§é‡äººå·¥æ¼”ç¤ºæ•°æ®çš„ä¾èµ–ã€‚ä¸Žä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å­¦ä¹ é•¿æ—¶ç¨‹ã€æŽ¥è§¦ä¸°å¯Œçš„æ“ä½œä»»åŠ¡ã€‚æ­¤å¤–ï¼Œæ˜¾å¼çš„åŠ›çº¦æŸå¼ºåŒ–å­¦ä¹ è®­ç»ƒä¹Ÿä¿è¯äº†æŸ”æ€§æ“ä½œçš„å®‰å…¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åŽŸå­æŠ€èƒ½å­¦ä¹ é˜¶æ®µï¼Œä½¿ç”¨äº†å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå…·ä½“ç®—æ³•æœªçŸ¥ï¼‰å¹¶åŠ å…¥äº†åŠ›çº¦æŸï¼Œä»¥é˜²æ­¢ç‰©ä½“æŸåã€‚åœ¨VLMä»»åŠ¡è§„åˆ’é˜¶æ®µï¼ŒæŽ¢ç´¢äº†ä¸åŒçš„VLMæ¨¡åž‹å’Œæç¤ºå·¥ç¨‹æ–¹æ³•ï¼Œä»¥ç”Ÿæˆé«˜è´¨é‡çš„ä¸“å®¶æ¼”ç¤ºã€‚åœ¨ç­–ç•¥è’¸é¦é˜¶æ®µï¼Œä½¿ç”¨äº†è§†è§‰-è§¦è§‰æ‰©æ•£ç­–ç•¥ï¼ˆVisual-Tactile Diffusion Policyï¼‰ï¼Œå¹¶æ¯”è¾ƒäº†ä¸åŒçš„æ¨¡ä»¿å­¦ä¹ ç®—æ³•ï¼ˆå…·ä½“ç®—æ³•æœªçŸ¥ï¼‰ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ç›®æ ‡æ˜¯æœ€å°åŒ–æ¨¡ä»¿å­¦ä¹ çš„è¯¯å·®ï¼Œå¹¶ä¿è¯ç­–ç•¥çš„å¹³æ»‘æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“çš„ç½‘ç»œç»“æž„å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­å¯èƒ½æœ‰æ‰€æè¿°ï¼Œä½†æ­¤å¤„æœªçŸ¥ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ¨¡æ‹ŸçŽ¯å¢ƒä¸­æˆåŠŸå­¦ä¹ é•¿æ—¶ç¨‹æ“ä½œç­–ç•¥ï¼Œå¹¶åœ¨ç‰©ç†æœºå™¨äººä¸Šå®žçŽ°äº†æœ‰æ•ˆçš„éƒ¨ç½²ã€‚é€šè¿‡å¯¹æ¯”ä¸åŒçš„VLMä»»åŠ¡è§„åˆ’å™¨å’Œæ¨¡ä»¿å­¦ä¹ ç®—æ³•ï¼Œç¡®å®šäº†æœ€ä½³çš„æ¼”ç¤ºç”Ÿæˆå’Œç­–ç•¥è’¸é¦æµç¨‹ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†è¯¥æ–¹æ³•åœ¨æ— éœ€äººå·¥æ¼”ç¤ºçš„æƒ…å†µä¸‹ï¼Œå®žçŽ°äº†å¯¹å¤æ‚æ“ä½œä»»åŠ¡çš„æœ‰æ•ˆå­¦ä¹ å’Œæ³›åŒ–ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽè‡ªåŠ¨åŒ–è£…é…ã€ç²¾å¯†ä»ªå™¨æ“ä½œã€åŒ»ç–—æœºå™¨äººã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸã€‚é€šè¿‡VLMå¼•å¯¼çš„åŽŸå­æŠ€èƒ½å­¦ä¹ ï¼Œæœºå™¨äººèƒ½å¤Ÿæ›´çµæ´»ã€å®‰å…¨åœ°å®Œæˆå¤æ‚çš„æ“ä½œä»»åŠ¡ï¼Œé™ä½Žäº†å¯¹äººå·¥å¹²é¢„çš„ä¾èµ–ï¼Œæé«˜äº†ç”Ÿäº§æ•ˆçŽ‡å’ŒæœåŠ¡è´¨é‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æŽ¨åŠ¨æœºå™¨äººæ™ºèƒ½åŒ–æ°´å¹³çš„æå‡ï¼Œä½¿å…¶æ›´å¥½åœ°æœåŠ¡äºŽäººç±»ç¤¾ä¼šã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Autonomous execution of long-horizon, contact-rich manipulation tasks traditionally requires extensive real-world data and expert engineering, posing significant cost and scalability challenges. This paper proposes a novel framework integrating hierarchical semantic decomposition, reinforcement learning (RL), visual language models (VLMs), and knowledge distillation to overcome these limitations. Complex tasks are decomposed into atomic skills, with RL-trained policies for each primitive exclusively in simulation. Crucially, our RL formulation incorporates explicit force constraints to prevent object damage during delicate interactions. VLMs perform high-level task decomposition and skill planning, generating diverse expert demonstrations. These are distilled into a unified policy via Visual-Tactile Diffusion Policy for end-to-end execution. We conduct comprehensive ablation studies exploring different VLM-based task planners to identify optimal demonstration generation pipelines, and systematically compare imitation learning algorithms for skill distillation. Extensive simulation experiments and physical deployment validate that our approach achieves policy learning for long-horizon manipulation without costly human demonstrations, while the VLM-guided atomic skill framework enables scalable generalization to diverse tasks.

