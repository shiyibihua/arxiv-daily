---
layout: default
title: Sim-to-Real Transfer in Deep Reinforcement Learning for Bipedal Locomotion
---

# Sim-to-Real Transfer in Deep Reinforcement Learning for Bipedal Locomotion

**arXiv**: [2511.06465v1](https://arxiv.org/abs/2511.06465) | [PDF](https://arxiv.org/pdf/2511.06465.pdf)

**ä½œè€…**: Lingfan Bao, Tianhu Peng, Chengxu Zhou

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-09

**å¤‡æ³¨**: Sim-to-real for bipedal locomotion chapter

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é’ˆå¯¹åŒè¶³æœºå™¨äººæ­¥æ€ï¼Œæå‡ºåŸºäºŽæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„Sim-to-Realè¿ç§»æ–¹æ³•**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `Sim-to-Realè¿ç§»` `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `åŒè¶³æœºå™¨äºº` `æ­¥æ€æŽ§åˆ¶` `é²æ£’æ€§è®­ç»ƒ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨åŒè¶³æœºå™¨äººæ­¥æ€æŽ§åˆ¶ä¸­é¢ä¸´ä»¿çœŸä¸ŽçŽ°å®žçŽ¯å¢ƒå·®å¼‚å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œå³â€œä»¿çœŸè¯…å’’â€ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§ç»“åˆæ¨¡åž‹ä¼˜åŒ–å’Œç­–ç•¥å¼ºåŒ–çš„Sim-to-Realè¿ç§»æ–¹æ³•ï¼Œæé«˜ç­–ç•¥åœ¨çœŸå®žçŽ¯å¢ƒä¸­çš„é²æ£’æ€§ã€‚
3. è¯¥æ–¹æ³•é€šè¿‡æé«˜ä»¿çœŸå™¨ç²¾åº¦å’Œè®­ç»ƒç­–ç•¥å¯¹æ¨¡åž‹è¯¯å·®çš„å®¹å¿åº¦ï¼Œå®žçŽ°æœ‰æ•ˆçš„Sim-to-Realè¿ç§»ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç« æŽ¢è®¨äº†åŒè¶³æœºå™¨äººæ­¥æ€ä¸­æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰çš„ä»¿çœŸåˆ°çŽ°å®žï¼ˆsim-to-realï¼‰è¿ç§»è¿™ä¸€å…³é”®æŒ‘æˆ˜ã€‚åœ¨å°†é—®é¢˜ç½®äºŽå„ç§æŽ§åˆ¶æž¶æž„çš„èƒŒæ™¯ä¸‹åŽï¼Œæˆ‘ä»¬é€šè¿‡åˆ†æžsim-to-realå·®è·çš„ä¸»è¦æ¥æºæ¥å‰–æžâ€œä»¿çœŸè¯…å’’â€ï¼Œè¿™äº›æ¥æºåŒ…æ‹¬ï¼šæœºå™¨äººåŠ¨åŠ›å­¦ã€æŽ¥è§¦å»ºæ¨¡ã€çŠ¶æ€ä¼°è®¡å’Œæ•°å€¼æ±‚è§£å™¨ã€‚åœ¨æ­¤è¯Šæ–­çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å›´ç»•ä¸¤ç§äº’è¡¥çš„ç†å¿µæž„å»ºè§£å†³æ–¹æ¡ˆã€‚ç¬¬ä¸€ç§æ˜¯é€šè¿‡ä»¥æ¨¡åž‹ä¸ºä¸­å¿ƒçš„ç­–ç•¥æ¥ç¼©å°å·®è·ï¼Œè¿™äº›ç­–ç•¥ç³»ç»Ÿåœ°æé«˜äº†æ¨¡æ‹Ÿå™¨çš„ç‰©ç†ä¿çœŸåº¦ã€‚ç¬¬äºŒç§æ˜¯å¼ºåŒ–ç­–ç•¥ï¼Œè¿™æ˜¯ä¸€ç§äº’è¡¥çš„æ–¹æ³•ï¼Œå®ƒä½¿ç”¨ä»¿çœŸä¸­çš„é²æ£’æ€§è®­ç»ƒå’Œéƒ¨ç½²åŽçš„é€‚åº”æ¥ä½¿ç­–ç•¥æœ¬èº«å¯¹æ¨¡åž‹ä¸å‡†ç¡®å…·æœ‰å¼¹æ€§ã€‚æœ¬ç« æœ€åŽå°†è¿™äº›ç†å¿µç»¼åˆä¸ºä¸€ä¸ªæˆ˜ç•¥æ¡†æž¶ï¼Œä¸ºå¼€å‘å’Œè¯„ä¼°ç¨³å¥çš„sim-to-realè§£å†³æ–¹æ¡ˆæä¾›æ¸…æ™°çš„è·¯çº¿å›¾ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŒè¶³æœºå™¨äººæ­¥æ€æŽ§åˆ¶ä¸­ï¼Œç”±äºŽä»¿çœŸçŽ¯å¢ƒä¸ŽçœŸå®žçŽ¯å¢ƒå­˜åœ¨å·®å¼‚ï¼Œå¯¼è‡´åœ¨ä»¿çœŸçŽ¯å¢ƒä¸­è®­ç»ƒçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ç­–ç•¥éš¾ä»¥ç›´æŽ¥è¿ç§»åˆ°çœŸå®žæœºå™¨äººä¸Šçš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•å¾€å¾€éš¾ä»¥å…‹æœæœºå™¨äººåŠ¨åŠ›å­¦ã€æŽ¥è§¦å»ºæ¨¡ã€çŠ¶æ€ä¼°è®¡å’Œæ•°å€¼æ±‚è§£å™¨ç­‰æ–¹é¢çš„å·®å¼‚ï¼Œå¯¼è‡´ç­–ç•¥æ€§èƒ½ä¸‹é™ç”šè‡³å¤±æ•ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åŒç®¡é½ä¸‹ï¼Œä¸€æ–¹é¢å°½å¯èƒ½ç¼©å°ä»¿çœŸçŽ¯å¢ƒä¸ŽçœŸå®žçŽ¯å¢ƒçš„å·®è·ï¼Œå¦ä¸€æ–¹é¢å¢žå¼ºç­–ç•¥æœ¬èº«çš„é²æ£’æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿé€‚åº”çŽ¯å¢ƒå·®å¼‚ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡ä¼˜åŒ–ä»¿çœŸæ¨¡åž‹æé«˜å…¶ç‰©ç†ä¿çœŸåº¦ï¼ŒåŒæ—¶åœ¨ä»¿çœŸçŽ¯å¢ƒä¸­è¿›è¡Œé²æ£’æ€§è®­ç»ƒï¼Œä½¿ç­–ç•¥å¯¹æ¨¡åž‹è¯¯å·®å…·æœ‰ä¸€å®šçš„å®¹å¿èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¿˜è€ƒè™‘åœ¨çœŸå®žçŽ¯å¢ƒä¸­è¿›è¡Œéƒ¨ç½²åŽçš„é€‚åº”ï¼Œè¿›ä¸€æ­¥æå‡ç­–ç•¥æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼šæ¨¡åž‹ä¼˜åŒ–å’Œç­–ç•¥å¼ºåŒ–ã€‚æ¨¡åž‹ä¼˜åŒ–éƒ¨åˆ†æ—¨åœ¨æé«˜ä»¿çœŸå™¨çš„ç‰©ç†ä¿çœŸåº¦ï¼Œä¾‹å¦‚é€šè¿‡ç³»ç»Ÿè¾¨è¯†æ–¹æ³•ç²¾ç¡®å»ºæ¨¡æœºå™¨äººåŠ¨åŠ›å­¦å‚æ•°ï¼Œæ”¹è¿›æŽ¥è§¦æ¨¡åž‹ä»¥æ›´çœŸå®žåœ°æ¨¡æ‹Ÿåœ°é¢åä½œç”¨åŠ›ç­‰ã€‚ç­–ç•¥å¼ºåŒ–éƒ¨åˆ†åˆ™åŒ…æ‹¬åœ¨ä»¿çœŸçŽ¯å¢ƒä¸­è¿›è¡Œé²æ£’æ€§è®­ç»ƒï¼Œä¾‹å¦‚é€šè¿‡æ·»åŠ å™ªå£°ã€æ”¹å˜çŽ¯å¢ƒå‚æ•°ç­‰æ–¹å¼ï¼Œä½¿ç­–ç•¥å¯¹çŽ¯å¢ƒå˜åŒ–å…·æœ‰æ›´å¼ºçš„é€‚åº”èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¿˜å¯ä»¥åœ¨çœŸå®žçŽ¯å¢ƒä¸­è¿›è¡Œå¾®è°ƒï¼Œè¿›ä¸€æ­¥æå‡ç­–ç•¥æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽå°†æ¨¡åž‹ä¼˜åŒ–å’Œç­–ç•¥å¼ºåŒ–ç›¸ç»“åˆï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„Sim-to-Realè¿ç§»æ¡†æž¶ã€‚ä¸Žä»¥å¾€ä¾§é‡äºŽå•ä¸€æ–¹é¢çš„ç ”ç©¶ä¸åŒï¼Œè¯¥æ–¹æ³•åŒæ—¶è€ƒè™‘äº†ä»¿çœŸçŽ¯å¢ƒçš„å‡†ç¡®æ€§å’Œç­–ç•¥çš„é²æ£’æ€§ï¼Œä»Žè€Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è§£å†³Sim-to-Realè¿ç§»é—®é¢˜ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ä¸ªæˆ˜ç•¥æ¡†æž¶ï¼Œä¸ºå¼€å‘å’Œè¯„ä¼°ç¨³å¥çš„sim-to-realè§£å†³æ–¹æ¡ˆæä¾›æ¸…æ™°çš„è·¯çº¿å›¾ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­æ¶‰åŠçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) ä»¿çœŸæ¨¡åž‹çš„å‚æ•°è¾¨è¯†æ–¹æ³•ï¼Œç”¨äºŽæé«˜ä»¿çœŸå™¨çš„ç‰©ç†ä¿çœŸåº¦ï¼›(2) é²æ£’æ€§è®­ç»ƒç­–ç•¥ï¼Œä¾‹å¦‚ä½¿ç”¨å¯¹æŠ—è®­ç»ƒæˆ–åŸŸéšæœºåŒ–ç­‰æ–¹æ³•ï¼Œä½¿ç­–ç•¥å¯¹çŽ¯å¢ƒå˜åŒ–å…·æœ‰æ›´å¼ºçš„é€‚åº”èƒ½åŠ›ï¼›(3) çœŸå®žçŽ¯å¢ƒä¸­çš„å¾®è°ƒç­–ç•¥ï¼Œä¾‹å¦‚ä½¿ç”¨åœ¨çº¿å¼ºåŒ–å­¦ä¹ æˆ–è‡ªé€‚åº”æŽ§åˆ¶ç­‰æ–¹æ³•ï¼Œè¿›ä¸€æ­¥æå‡ç­–ç•¥æ€§èƒ½ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°ã€ç½‘ç»œç»“æž„ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜Žï¼Œå±žäºŽæœªçŸ¥ä¿¡æ¯ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

ç”±äºŽè®ºæ–‡ä¸ºç»¼è¿°æ€§è´¨ï¼Œå¹¶æœªæä¾›å…·ä½“çš„å®žéªŒç»“æžœã€‚å…¶äº®ç‚¹åœ¨äºŽæå‡ºäº†ä¸€ä¸ªå®Œæ•´çš„Sim-to-Realè¿ç§»æ¡†æž¶ï¼Œå¹¶ç»™å‡ºäº†æ¸…æ™°çš„è·¯çº¿å›¾ï¼Œä¸ºåŽç»­ç ”ç©¶æä¾›äº†æŒ‡å¯¼ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥åŸºäºŽè¯¥æ¡†æž¶ï¼ŒæŽ¢ç´¢æ›´æœ‰æ•ˆçš„æ¨¡åž‹ä¼˜åŒ–å’Œç­–ç•¥å¼ºåŒ–æ–¹æ³•ï¼Œå¹¶åœ¨çœŸå®žæœºå™¨äººå¹³å°ä¸Šè¿›è¡ŒéªŒè¯ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯å¹¿æ³›åº”ç”¨äºŽå„ç§åŒè¶³æœºå™¨äººåº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚ç¾éš¾æ•‘æ´ã€ç‰©æµè¿è¾“ã€å®¶åº­æœåŠ¡ç­‰ã€‚é€šè¿‡é™ä½ŽSim-to-Realè¿ç§»çš„éš¾åº¦ï¼Œå¯ä»¥åŠ é€ŸåŒè¶³æœºå™¨äººçš„ç ”å‘å’Œéƒ¨ç½²ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å¤æ‚å¤šå˜çš„çœŸå®žçŽ¯å¢ƒï¼Œä»Žè€Œå‘æŒ¥æ›´å¤§çš„ä½œç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This chapter addresses the critical challenge of simulation-to-reality (sim-to-real) transfer for deep reinforcement learning (DRL) in bipedal locomotion. After contextualizing the problem within various control architectures, we dissect the ``curse of simulation'' by analyzing the primary sources of sim-to-real gap: robot dynamics, contact modeling, state estimation, and numerical solvers. Building on this diagnosis, we structure the solutions around two complementary philosophies. The first is to shrink the gap through model-centric strategies that systematically improve the simulator's physical fidelity. The second is to harden the policy, a complementary approach that uses in-simulation robustness training and post-deployment adaptation to make the policy inherently resilient to model inaccuracies. The chapter concludes by synthesizing these philosophies into a strategic framework, providing a clear roadmap for developing and evaluating robust sim-to-real solutions.

