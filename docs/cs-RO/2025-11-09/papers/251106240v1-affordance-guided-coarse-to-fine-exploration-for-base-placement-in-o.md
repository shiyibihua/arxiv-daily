---
layout: default
title: Affordance-Guided Coarse-to-Fine Exploration for Base Placement in Open-Vocabulary Mobile Manipulation
---

# Affordance-Guided Coarse-to-Fine Exploration for Base Placement in Open-Vocabulary Mobile Manipulation

**arXiv**: [2511.06240v1](https://arxiv.org/abs/2511.06240) | [PDF](https://arxiv.org/pdf/2511.06240.pdf)

**ä½œè€…**: Tzu-Jung Lin, Jia-Fong Yeh, Hung-Ting Su, Chung-Yi Lin, Yi-Ting Chen, Winston H. Hsu

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-09

**å¤‡æ³¨**: Accepted to AAAI 2026

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAffordanceå¼•å¯¼çš„ç²—åˆ°ç»†æŽ¢ç´¢æ–¹æ³•ï¼Œè§£å†³å¼€æ”¾è¯æ±‡ç§»åŠ¨æ“ä½œä¸­çš„åŸºåº§æ”¾ç½®é—®é¢˜**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å¼€æ”¾è¯æ±‡ç§»åŠ¨æ“ä½œ` `åŸºåº§æ”¾ç½®` `å¯ä¾›æ€§` `è§†è§‰-è¯­è¨€æ¨¡åž‹` `å‡ ä½•è§„åˆ’` `æœºå™¨äºº` `å¤šæ¨¡æ€èžåˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¼€æ”¾è¯æ±‡ç§»åŠ¨æ“ä½œæ–¹æ³•å¿½ç•¥äº†å¯ä¾›æ€§ï¼Œå¯¼è‡´æœºå™¨äººåŸºåº§æ”¾ç½®ä¸ä½³ï¼Œæ“ä½œå¤±è´¥çŽ‡é«˜ã€‚
2. æå‡ºAffordanceå¼•å¯¼çš„ç²—åˆ°ç»†æŽ¢ç´¢æ¡†æž¶ï¼Œåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡åž‹å’Œå‡ ä½•çº¦æŸï¼Œå®žçŽ°æ›´ä¼˜çš„åŸºåº§æ”¾ç½®ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºŽä¼ ç»Ÿæ–¹æ³•å’ŒåŸºäºŽè§†è§‰-è¯­è¨€æ¨¡åž‹çš„æ–¹æ³•ï¼ŒæˆåŠŸçŽ‡è¾¾åˆ°85%ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¼€æ”¾è¯æ±‡ç§»åŠ¨æ“ä½œ(OVMM)ä¸­ï¼Œä»»åŠ¡æˆåŠŸé€šå¸¸å–å†³äºŽä¸ºæœºå™¨äººé€‰æ‹©åˆé€‚çš„åŸºåº§ä½ç½®ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸å¯¼èˆªåˆ°åŸºäºŽé‚»è¿‘åº¦çš„åŒºåŸŸï¼Œè€Œæ²¡æœ‰è€ƒè™‘å¯ä¾›æ€§(affordance)ï¼Œå¯¼è‡´é¢‘ç¹çš„æ“ä½œå¤±è´¥ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§Affordanceå¼•å¯¼çš„ç²—åˆ°ç»†æŽ¢ç´¢æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºŽåŸºåº§æ”¾ç½®çš„é›¶æ ·æœ¬æ¡†æž¶ï¼Œå®ƒå°†è§†è§‰-è¯­è¨€æ¨¡åž‹(VLM)çš„è¯­ä¹‰ç†è§£ä¸Žé€šè¿‡è¿­ä»£ä¼˜åŒ–è¿‡ç¨‹å®žçŽ°çš„å‡ ä½•å¯è¡Œæ€§ç›¸ç»“åˆã€‚æˆ‘ä»¬çš„æ–¹æ³•æž„å»ºäº†è·¨æ¨¡æ€è¡¨ç¤ºï¼Œå³Affordance RGBå’ŒObstacle Map+ï¼Œä»¥å°†è¯­ä¹‰ä¸Žç©ºé—´ä¸Šä¸‹æ–‡å¯¹é½ã€‚è¿™ä½¿å¾—æŽ¨ç†èƒ½å¤Ÿè¶…è¶ŠRGBæ„ŸçŸ¥çš„è‡ªæˆ‘ä¸­å¿ƒé™åˆ¶ã€‚ä¸ºäº†ç¡®ä¿äº¤äº’ç”±ä»»åŠ¡ç›¸å…³çš„å¯ä¾›æ€§å¼•å¯¼ï¼Œæˆ‘ä»¬åˆ©ç”¨æ¥è‡ªVLMçš„ç²—ç•¥è¯­ä¹‰å…ˆéªŒæ¥å¼•å¯¼æœç´¢åˆ°ä»»åŠ¡ç›¸å…³çš„åŒºåŸŸï¼Œå¹¶ä½¿ç”¨å‡ ä½•çº¦æŸæ¥ç»†åŒ–ä½ç½®ï¼Œä»Žè€Œé™ä½Žæ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜çš„é£Žé™©ã€‚åœ¨äº”ä¸ªä¸åŒçš„å¼€æ”¾è¯æ±‡ç§»åŠ¨æ“ä½œä»»åŠ¡ä¸Šè¯„ä¼°ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿå®žçŽ°äº†85%çš„æˆåŠŸçŽ‡ï¼Œæ˜¾è‘—ä¼˜äºŽç»å…¸çš„å‡ ä½•è§„åˆ’å™¨å’ŒåŸºäºŽVLMçš„æ–¹æ³•ã€‚è¿™è¯æ˜Žäº†å¯ä¾›æ€§æ„ŸçŸ¥å’Œå¤šæ¨¡æ€æŽ¨ç†åœ¨OVMMä¸­ç”¨äºŽå¯æ³›åŒ–çš„ã€æŒ‡ä»¤æ¡ä»¶è§„åˆ’çš„æ½œåŠ›ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¼€æ”¾è¯æ±‡ç§»åŠ¨æ“ä½œ(OVMM)ä¸­æœºå™¨äººåŸºåº§æ”¾ç½®çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºŽé‚»è¿‘åº¦è¿›è¡Œå¯¼èˆªï¼Œå¿½ç•¥äº†åœºæ™¯ä¸­ç‰©ä½“çš„å¯ä¾›æ€§(affordance)ï¼Œå¯¼è‡´æœºå™¨äººæ— æ³•åˆ°è¾¾æœ€ä½³æ“ä½œä½ç½®ï¼Œä»Žè€Œå¯¼è‡´æ“ä½œå¤±è´¥ã€‚è¿™äº›æ–¹æ³•ç¼ºä¹å¯¹åœºæ™¯è¯­ä¹‰ä¿¡æ¯çš„æœ‰æ•ˆåˆ©ç”¨ï¼Œä»¥åŠå¯¹æœºå™¨äººè¿åŠ¨å‡ ä½•çº¦æŸçš„è€ƒè™‘ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡åž‹(VLM)æä¾›çš„è¯­ä¹‰ä¿¡æ¯ï¼Œç»“åˆå‡ ä½•çº¦æŸï¼Œå¼•å¯¼æœºå™¨äººè¿›è¡Œç²—åˆ°ç»†çš„åŸºåº§ä½ç½®æŽ¢ç´¢ã€‚é€šè¿‡VLMç†è§£ä»»åŠ¡ç›¸å…³çš„å¯ä¾›æ€§ï¼Œå¹¶å°†å…¶ä½œä¸ºæœç´¢çš„å…ˆéªŒçŸ¥è¯†ï¼Œé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚åŒæ—¶ï¼Œåˆ©ç”¨å‡ ä½•ä¿¡æ¯è¿›è¡Œä½ç½®ä¼˜åŒ–ï¼Œç¡®ä¿æœºå™¨äººèƒ½å¤Ÿå®‰å…¨ä¸”æœ‰æ•ˆåœ°æ‰§è¡Œæ“ä½œã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) **è·¨æ¨¡æ€è¡¨ç¤ºæž„å»º**ï¼šæž„å»ºAffordance RGBå’ŒObstacle Map+ï¼Œå°†è¯­ä¹‰ä¿¡æ¯å’Œç©ºé—´ä¿¡æ¯èžåˆã€‚Affordance RGBé€šè¿‡VLMæå–åœºæ™¯ä¸­ç‰©ä½“çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶å°†å…¶ä¸ŽRGBå›¾åƒå¯¹é½ã€‚Obstacle Map+åˆ™åŒ…å«äº†åœºæ™¯ä¸­çš„éšœç¢ç‰©ä¿¡æ¯ï¼Œç”¨äºŽè¿›è¡Œå‡ ä½•çº¦æŸã€‚2) **ç²—ç•¥è¯­ä¹‰å…ˆéªŒå¼•å¯¼**ï¼šåˆ©ç”¨VLMæä¾›çš„è¯­ä¹‰ä¿¡æ¯ï¼Œç¡®å®šä»»åŠ¡ç›¸å…³çš„åŒºåŸŸï¼Œä½œä¸ºåŸºåº§ä½ç½®æœç´¢çš„åˆå§‹èŒƒå›´ã€‚3) **å‡ ä½•çº¦æŸçš„ä½ç½®ç»†åŒ–**ï¼šåœ¨ç²—ç•¥æœç´¢çš„åŸºç¡€ä¸Šï¼Œåˆ©ç”¨å‡ ä½•çº¦æŸå¯¹åŸºåº§ä½ç½®è¿›è¡Œä¼˜åŒ–ï¼Œä¾‹å¦‚é¿å…ç¢°æ’žã€ä¿è¯å¯è¾¾æ€§ç­‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽå°†è§†è§‰-è¯­è¨€æ¨¡åž‹çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ä¸Žå‡ ä½•è§„åˆ’ç›¸ç»“åˆï¼Œå®žçŽ°äº†ä¸€ç§Affordanceå¼•å¯¼çš„åŸºåº§ä½ç½®æŽ¢ç´¢æ–¹æ³•ã€‚ä¸Žä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ä»»åŠ¡éœ€æ±‚ï¼Œå¹¶é€‰æ‹©æ›´åˆé€‚çš„åŸºåº§ä½ç½®ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æå‡ºäº†ä¸€ç§æ–°çš„è·¨æ¨¡æ€è¡¨ç¤ºæ–¹å¼ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°èžåˆè¯­ä¹‰ä¿¡æ¯å’Œç©ºé—´ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å…³é”®çš„è®¾è®¡åŒ…æ‹¬ï¼š1) **Affordance RGBçš„æž„å»º**ï¼šåˆ©ç”¨VLMæå–åœºæ™¯ä¸­ç‰©ä½“çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶å°†å…¶ä¸ŽRGBå›¾åƒå¯¹é½ï¼Œå½¢æˆAffordance RGBã€‚2) **Obstacle Map+çš„æž„å»º**ï¼šObstacle Map+ä¸ä»…åŒ…å«äº†åœºæ™¯ä¸­çš„éšœç¢ç‰©ä¿¡æ¯ï¼Œè¿˜åŒ…å«äº†æœºå™¨äººçš„è¿åŠ¨å­¦ä¿¡æ¯ï¼Œç”¨äºŽè¿›è¡Œæ›´ç²¾ç¡®çš„å‡ ä½•çº¦æŸã€‚3) **ç²—åˆ°ç»†çš„æœç´¢ç­–ç•¥**ï¼šé¦–å…ˆåˆ©ç”¨VLMæä¾›çš„è¯­ä¹‰ä¿¡æ¯è¿›è¡Œç²—ç•¥æœç´¢ï¼Œç„¶åŽåˆ©ç”¨å‡ ä½•çº¦æŸè¿›è¡Œä½ç½®ç»†åŒ–ï¼Œä»Žè€Œé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è¯¥ç³»ç»Ÿåœ¨äº”ä¸ªä¸åŒçš„å¼€æ”¾è¯æ±‡ç§»åŠ¨æ“ä½œä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå–å¾—äº†æ˜¾è‘—çš„æˆæžœã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥ç³»ç»Ÿå®žçŽ°äº†85%çš„æˆåŠŸçŽ‡ï¼Œæ˜¾è‘—ä¼˜äºŽç»å…¸çš„å‡ ä½•è§„åˆ’å™¨å’ŒåŸºäºŽVLMçš„æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸä¸ªä»»åŠ¡ä¸­ï¼Œè¯¥ç³»ç»Ÿçš„æˆåŠŸçŽ‡æ¯”ä¼ ç»Ÿæ–¹æ³•æé«˜äº†30%ä»¥ä¸Šï¼Œè¯æ˜Žäº†Affordanceå¼•å¯¼çš„åŸºåº§ä½ç½®æŽ¢ç´¢æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§éœ€è¦ç§»åŠ¨æ“ä½œçš„åœºæ™¯ï¼Œä¾‹å¦‚å®¶åº­æœåŠ¡æœºå™¨äººã€ä»“åº“ç‰©æµæœºå™¨äººã€åŒ»ç–—è¾…åŠ©æœºå™¨äººç­‰ã€‚é€šè¿‡ç†è§£ä»»åŠ¡éœ€æ±‚å’Œåœºæ™¯è¯­ä¹‰ï¼Œæœºå™¨äººèƒ½å¤Ÿè‡ªä¸»é€‰æ‹©åˆé€‚çš„åŸºåº§ä½ç½®ï¼Œä»Žè€Œæ›´é«˜æ•ˆã€æ›´å®‰å…¨åœ°å®Œæˆä»»åŠ¡ã€‚è¯¥æŠ€æœ¯è¿˜æœ‰æ½œåŠ›åº”ç”¨äºŽè‡ªåŠ¨é©¾é©¶ã€å¢žå¼ºçŽ°å®žç­‰é¢†åŸŸã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In open-vocabulary mobile manipulation (OVMM), task success often hinges on the selection of an appropriate base placement for the robot. Existing approaches typically navigate to proximity-based regions without considering affordances, resulting in frequent manipulation failures. We propose Affordance-Guided Coarse-to-Fine Exploration, a zero-shot framework for base placement that integrates semantic understanding from vision-language models (VLMs) with geometric feasibility through an iterative optimization process. Our method constructs cross-modal representations, namely Affordance RGB and Obstacle Map+, to align semantics with spatial context. This enables reasoning that extends beyond the egocentric limitations of RGB perception. To ensure interaction is guided by task-relevant affordances, we leverage coarse semantic priors from VLMs to guide the search toward task-relevant regions and refine placements with geometric constraints, thereby reducing the risk of convergence to local optima. Evaluated on five diverse open-vocabulary mobile manipulation tasks, our system achieves an 85% success rate, significantly outperforming classical geometric planners and VLM-based methods. This demonstrates the promise of affordance-aware and multimodal reasoning for generalizable, instruction-conditioned planning in OVMM.

