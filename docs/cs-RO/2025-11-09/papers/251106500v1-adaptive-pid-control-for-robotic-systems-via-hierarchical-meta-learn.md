---
layout: default
title: Adaptive PID Control for Robotic Systems via Hierarchical Meta-Learning and Reinforcement Learning with Physics-Based Data Augmentation
---

# Adaptive PID Control for Robotic Systems via Hierarchical Meta-Learning and Reinforcement Learning with Physics-Based Data Augmentation

**arXiv**: [2511.06500v1](https://arxiv.org/abs/2511.06500) | [PDF](https://arxiv.org/pdf/2511.06500.pdf)

**ä½œè€…**: JiaHao Wu, ShengWen Yu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-09

**å¤‡æ³¨**: 21 pages,12 tables, 6 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå±‚çº§å…ƒå­¦ä¹ ä¸Žå¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”PIDæŽ§åˆ¶æ¡†æž¶ï¼Œæå‡æœºå™¨äººç³»ç»Ÿæ€§èƒ½ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `PIDæŽ§åˆ¶` `å…ƒå­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `æ•°æ®å¢žå¼º` `æœºå™¨äººæŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»ŸPIDæŽ§åˆ¶å™¨åœ¨æœºå™¨äººé¢†åŸŸåº”ç”¨å¹¿æ³›ï¼Œä½†é’ˆå¯¹ä¸åŒæœºå™¨äººå¹³å°æ‰‹åŠ¨è°ƒå‚è€—æ—¶ä¸”ä¾èµ–ä¸“å®¶ç»éªŒã€‚
2. æå‡ºä¸€ç§å±‚çº§æŽ§åˆ¶æ¡†æž¶ï¼Œåˆ©ç”¨å…ƒå­¦ä¹ åˆå§‹åŒ–PIDå‚æ•°ï¼Œå†é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œåœ¨çº¿è‡ªé€‚åº”è°ƒæ•´ã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨Franka Pandaæœºæ¢°è‡‚ä¸Šæ€§èƒ½æå‡æ˜¾è‘—ï¼Œå¹¶æ­ç¤ºäº†å¼ºåŒ–å­¦ä¹ æ•ˆæžœå—å…ƒå­¦ä¹ åŸºçº¿è´¨é‡å½±å“çš„â€œä¼˜åŒ–å¤©èŠ±æ¿æ•ˆåº”â€ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å±‚çº§æŽ§åˆ¶æ¡†æž¶ï¼Œè¯¥æ¡†æž¶ç»“åˆäº†ç”¨äºŽPIDå‚æ•°åˆå§‹åŒ–çš„å…ƒå­¦ä¹ å’Œç”¨äºŽåœ¨çº¿è‡ªé€‚åº”çš„å¼ºåŒ–å­¦ä¹ (RL)ã€‚ä¸ºäº†è§£å†³æ ·æœ¬æ•ˆçŽ‡é—®é¢˜ï¼Œå¼•å…¥äº†ä¸€ç§åŸºäºŽç‰©ç†çš„æ•°æ®å¢žå¼ºç­–ç•¥ï¼Œé€šè¿‡ç³»ç»Ÿåœ°æ‰°åŠ¨ç‰©ç†å‚æ•°æ¥ç”Ÿæˆè™šæ‹Ÿæœºå™¨äººé…ç½®ï¼Œä»Žè€Œåœ¨æœ‰é™çš„çœŸå®žæœºå™¨äººæ•°æ®ä¸‹å®žçŽ°æœ‰æ•ˆçš„å…ƒå­¦ä¹ ã€‚è¯¥æ–¹æ³•åœ¨Franka Pandaæœºæ¢°è‡‚(9è‡ªç”±åº¦)å’ŒLaikagoå››è¶³æœºå™¨äºº(12è‡ªç”±åº¦)ä¸¤ä¸ªå¼‚æž„å¹³å°ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨Franka Pandaä¸Šå®žçŽ°äº†16.6%çš„å¹³å‡æ”¹è¿›(6.26Â° MAE)ï¼Œåœ¨é«˜è´Ÿè½½å…³èŠ‚(J2)ä¸ŠèŽ·å¾—äº†æ˜¾è‘—çš„å¢žç›Š(ä»Ž12.36Â°æ”¹è¿›åˆ°2.42Â°ï¼Œæå‡80.4%)ã€‚é‡è¦çš„æ˜¯ï¼Œè¿™é¡¹å·¥ä½œå‘çŽ°äº†â€œä¼˜åŒ–å¤©èŠ±æ¿æ•ˆåº”â€ï¼šå½“å…ƒå­¦ä¹ è¡¨çŽ°å‡ºå±€éƒ¨é«˜è¯¯å·®å…³èŠ‚æ—¶ï¼ŒRLå®žçŽ°äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œä½†å½“åŸºçº¿æ€§èƒ½å‡åŒ€è‰¯å¥½æ—¶ï¼ŒRLæ²¡æœ‰æä¾›ä»»ä½•å¥½å¤„(0.0%)ï¼Œæ­£å¦‚åœ¨Laikagoä¸­è§‚å¯Ÿåˆ°çš„é‚£æ ·ã€‚è¯¥æ–¹æ³•åœ¨æ‰°åŠ¨ä¸‹è¡¨çŽ°å‡ºé²æ£’çš„æ€§èƒ½(å‚æ•°ä¸ç¡®å®šæ€§ï¼š+19.2%ï¼Œæ— æ‰°åŠ¨ï¼š+16.6%ï¼Œå¹³å‡ï¼š+10.0%)ï¼Œä¸”ä»…éœ€10åˆ†é’Ÿçš„è®­ç»ƒæ—¶é—´ã€‚è·¨100ä¸ªéšæœºåˆå§‹åŒ–çš„å¤šç§å­åˆ†æžè¯å®žäº†ç¨³å®šçš„æ€§èƒ½(å¹³å‡4.81+/-1.64%)ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼ŒRLçš„æœ‰æ•ˆæ€§é«˜åº¦ä¾èµ–äºŽå…ƒå­¦ä¹ åŸºçº¿çš„è´¨é‡å’Œè¯¯å·®åˆ†å¸ƒï¼Œä¸ºå±‚çº§æŽ§åˆ¶ç³»ç»Ÿçš„è®¾è®¡æä¾›äº†é‡è¦çš„æŒ‡å¯¼ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººç³»ç»Ÿä¸­PIDæŽ§åˆ¶å™¨å‚æ•°æ•´å®šçš„éš¾é¢˜ã€‚ä¼ ç»Ÿçš„æ‰‹åŠ¨è°ƒå‚æ–¹æ³•è€—æ—¶è´¹åŠ›ï¼Œä¸”éœ€è¦ä¸°å¯Œçš„é¢†åŸŸçŸ¥è¯†ã€‚çŽ°æœ‰çš„è‡ªåŠ¨åŒ–è°ƒå‚æ–¹æ³•ï¼Œå¦‚å¼ºåŒ–å­¦ä¹ ï¼Œé€šå¸¸éœ€è¦å¤§é‡çš„æ ·æœ¬æ•°æ®ï¼Œéš¾ä»¥åœ¨çœŸå®žæœºå™¨äººä¸Šç›´æŽ¥åº”ç”¨ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨æœ‰é™çš„çœŸå®žæœºå™¨äººæ•°æ®ä¸‹ï¼Œå¿«é€Ÿæœ‰æ•ˆåœ°æ•´å®šPIDå‚æ•°ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå…ƒå­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ çš„ä¼˜åŠ¿ï¼Œæž„å»ºä¸€ä¸ªå±‚çº§æŽ§åˆ¶æ¡†æž¶ã€‚é¦–å…ˆï¼Œåˆ©ç”¨å…ƒå­¦ä¹ ä»Žå°‘é‡æ•°æ®ä¸­å­¦ä¹ PIDå‚æ•°çš„åˆå§‹åŒ–ç­–ç•¥ï¼Œä½¿å¾—PIDæŽ§åˆ¶å™¨èƒ½å¤Ÿå¿«é€Ÿé€‚åº”ä¸åŒçš„æœºå™¨äººé…ç½®ã€‚ç„¶åŽï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ å¯¹PIDå‚æ•°è¿›è¡Œåœ¨çº¿è‡ªé€‚åº”è°ƒæ•´ï¼Œè¿›ä¸€æ­¥æå‡æŽ§åˆ¶æ€§èƒ½ã€‚æ­¤å¤–ï¼Œä¸ºäº†è§£å†³æ ·æœ¬æ•ˆçŽ‡é—®é¢˜ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§åŸºäºŽç‰©ç†çš„æ•°æ®å¢žå¼ºç­–ç•¥ï¼Œé€šè¿‡æ¨¡æ‹Ÿä¸åŒçš„æœºå™¨äººç‰©ç†å‚æ•°ï¼Œç”Ÿæˆå¤§é‡çš„è™šæ‹Ÿæ•°æ®ï¼Œä»Žè€ŒåŠ é€Ÿå…ƒå­¦ä¹ çš„è®­ç»ƒã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥å±‚çº§æŽ§åˆ¶æ¡†æž¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) **ç‰©ç†å‚æ•°æ‰°åŠ¨æ¨¡å—**ï¼šé€šè¿‡éšæœºæ‰°åŠ¨æœºå™¨äººçš„ç‰©ç†å‚æ•°ï¼ˆå¦‚è´¨é‡ã€æ‘©æ“¦ç³»æ•°ç­‰ï¼‰ï¼Œç”Ÿæˆä¸åŒçš„è™šæ‹Ÿæœºå™¨äººé…ç½®ã€‚2) **å…ƒå­¦ä¹ æ¨¡å—**ï¼šåˆ©ç”¨ç”Ÿæˆçš„å¤§é‡è™šæ‹Ÿæ•°æ®ï¼Œè®­ç»ƒä¸€ä¸ªå…ƒå­¦ä¹ æ¨¡åž‹ï¼Œè¯¥æ¨¡åž‹èƒ½å¤Ÿæ ¹æ®æœºå™¨äººé…ç½®ï¼Œå¿«é€Ÿåˆå§‹åŒ–PIDå‚æ•°ã€‚3) **å¼ºåŒ–å­¦ä¹ æ¨¡å—**ï¼šåˆ©ç”¨çœŸå®žæœºå™¨äººæ•°æ®ï¼Œè®­ç»ƒä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼Œè¯¥æ™ºèƒ½ä½“èƒ½å¤Ÿæ ¹æ®å½“å‰çŠ¶æ€ï¼Œå¯¹PIDå‚æ•°è¿›è¡Œåœ¨çº¿è‡ªé€‚åº”è°ƒæ•´ã€‚4) **PIDæŽ§åˆ¶æ¨¡å—**ï¼šåˆ©ç”¨æ•´å®šåŽçš„PIDå‚æ•°ï¼ŒæŽ§åˆ¶æœºå™¨äººæ‰§è¡Œä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽï¼š1) æå‡ºäº†ä¸€ç§åŸºäºŽç‰©ç†çš„æ•°æ®å¢žå¼ºç­–ç•¥ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†æ ·æœ¬æ•ˆçŽ‡é—®é¢˜ã€‚2) ç»“åˆå…ƒå­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ï¼Œæž„å»ºäº†ä¸€ä¸ªå±‚çº§æŽ§åˆ¶æ¡†æž¶ï¼Œå……åˆ†åˆ©ç”¨äº†ä¸¤ç§æ–¹æ³•çš„ä¼˜åŠ¿ã€‚3) å‘çŽ°äº†â€œä¼˜åŒ–å¤©èŠ±æ¿æ•ˆåº”â€ï¼Œæ­ç¤ºäº†å¼ºåŒ–å­¦ä¹ æ•ˆæžœå—å…ƒå­¦ä¹ åŸºçº¿è´¨é‡çš„å½±å“ï¼Œä¸ºå±‚çº§æŽ§åˆ¶ç³»ç»Ÿçš„è®¾è®¡æä¾›äº†é‡è¦çš„æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…ƒå­¦ä¹ æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†Model-Agnostic Meta-Learning (MAML)ç®—æ³•ï¼Œå­¦ä¹ PIDå‚æ•°çš„åˆå§‹åŒ–ç­–ç•¥ã€‚åœ¨å¼ºåŒ–å­¦ä¹ æ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†Proximal Policy Optimization (PPO)ç®—æ³•ï¼Œå¯¹PIDå‚æ•°è¿›è¡Œåœ¨çº¿è‡ªé€‚åº”è°ƒæ•´ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡è€ƒè™‘äº†ä½ç½®è¯¯å·®å’ŒæŽ§åˆ¶åŠ›çŸ©ï¼Œä»¥ä¿è¯æŽ§åˆ¶ç²¾åº¦å’Œç¨³å®šæ€§ã€‚ç½‘ç»œç»“æž„é‡‡ç”¨äº†å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ï¼Œè¾“å…¥ä¸ºæœºå™¨äººçŠ¶æ€ï¼Œè¾“å‡ºä¸ºPIDå‚æ•°çš„è°ƒæ•´é‡ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨Franka Pandaæœºæ¢°è‡‚ä¸Šå®žçŽ°äº†16.6%çš„å¹³å‡æ”¹è¿›(6.26Â° MAE)ï¼Œåœ¨é«˜è´Ÿè½½å…³èŠ‚(J2)ä¸ŠèŽ·å¾—äº†æ˜¾è‘—çš„å¢žç›Š(ä»Ž12.36Â°æ”¹è¿›åˆ°2.42Â°ï¼Œæå‡80.4%)ã€‚åœ¨æ‰°åŠ¨ä¸‹è¡¨çŽ°å‡ºé²æ£’çš„æ€§èƒ½(å‚æ•°ä¸ç¡®å®šæ€§ï¼š+19.2%ï¼Œæ— æ‰°åŠ¨ï¼š+16.6%ï¼Œå¹³å‡ï¼š+10.0%)ï¼Œä¸”ä»…éœ€10åˆ†é’Ÿçš„è®­ç»ƒæ—¶é—´ã€‚è·¨100ä¸ªéšæœºåˆå§‹åŒ–çš„å¤šç§å­åˆ†æžè¯å®žäº†ç¨³å®šçš„æ€§èƒ½(å¹³å‡4.81+/-1.64%)ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯å¹¿æ³›åº”ç”¨äºŽå·¥ä¸šæœºå™¨äººã€æœåŠ¡æœºå™¨äººã€å››è¶³æœºå™¨äººç­‰é¢†åŸŸã€‚é€šè¿‡è¯¥æ–¹æ³•ï¼Œå¯ä»¥æ˜¾è‘—é™ä½ŽPIDæŽ§åˆ¶å™¨å‚æ•°æ•´å®šçš„æ—¶é—´å’Œæˆæœ¬ï¼Œæé«˜æœºå™¨äººçš„æŽ§åˆ¶æ€§èƒ½å’Œé²æ£’æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æŽ¨å¹¿åˆ°æ›´å¤æ‚çš„æœºå™¨äººç³»ç»Ÿå’ŒæŽ§åˆ¶ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚å¤šæœºå™¨äººååŒæŽ§åˆ¶ã€è‡ªä¸»å¯¼èˆªç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Proportional-Integral-Derivative (PID) controllers remain the predominant choice in industrial robotics due to their simplicity and reliability. However, manual tuning of PID parameters for diverse robotic platforms is time-consuming and requires extensive domain expertise. This paper presents a novel hierarchical control framework that combines meta-learning for PID initialization and reinforcement learning (RL) for online adaptation. To address the sample efficiency challenge, a \textit{physics-based data augmentation} strategy is introduced that generates virtual robot configurations by systematically perturbing physical parameters, enabling effective meta-learning with limited real robot data. The proposed approach is evaluated on two heterogeneous platforms: a 9-DOF Franka Panda manipulator and a 12-DOF Laikago quadruped robot. Experimental results demonstrate that the proposed method achieves 16.6\% average improvement on Franka Panda (6.26Â° MAE), with exceptional gains in high-load joints (J2: 80.4\% improvement from 12.36Â° to 2.42Â°). Critically, this work discovers the \textit{optimization ceiling effect}: RL achieves dramatic improvements when meta-learning exhibits localized high-error joints, but provides no benefit (0.0\%) when baseline performance is uniformly strong, as observed in Laikago. The method demonstrates robust performance under disturbances (parameter uncertainty: +19.2\%, no disturbance: +16.6\%, average: +10.0\%) with only 10 minutes of training time. Multi-seed analysis across 100 random initializations confirms stable performance (4.81+/-1.64\% average). These results establish that RL effectiveness is highly dependent on meta-learning baseline quality and error distribution, providing important design guidance for hierarchical control systems.

