---
layout: default
title: Bootstrap Off-policy with World Model
---

# Bootstrap Off-policy with World Model

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.00423" target="_blank" class="toolbar-btn">arXiv: 2511.00423v2</a>
    <a href="https://arxiv.org/pdf/2511.00423.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.00423v2" 
            onclick="toggleFavorite(this, '2511.00423v2', 'Bootstrap Off-policy with World Model')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Guojian Zhan, Likun Wang, Xiangteng Zhang, Jiaxin Gao, Masayoshi Tomizuka, Shengbo Eben Li

**ÂàÜÁ±ª**: cs.LG, cs.AI, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-01 (Êõ¥Êñ∞: 2025-11-21)

**Â§áÊ≥®**: NeurIPS 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/molumitu/BOOM_MBRL)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**BOOMÔºöÈÄöËøá‰∏ñÁïåÊ®°ÂûãÂºïÂØºÁöÑÁ¶ªÁ≠ñÁï•Âº∫ÂåñÂ≠¶‰π†ÔºåÊèêÂçáÊ†∑Êú¨ÊïàÁéáÂíåÊÄßËÉΩ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Âº∫ÂåñÂ≠¶‰π†` `‰∏ñÁïåÊ®°Âûã` `Á¶ªÁ≠ñÁï•Â≠¶‰π†` `Âú®Á∫øËßÑÂàí` `Ë°å‰∏∫ÂØπÈΩê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Âú®Á∫øËßÑÂàíËôΩÁÑ∂ËÉΩÊèêÂçáÂº∫ÂåñÂ≠¶‰π†ÁöÑÊ†∑Êú¨ÊïàÁéáÔºå‰ΩÜÁéØÂ¢É‰∫§‰∫íÂºïÂÖ•ÁöÑÊï∞ÊçÆÂÅèÂ∑Æ‰ºöÊçüÂÆ≥Ê®°ÂûãÂ≠¶‰π†ÂíåÁ≠ñÁï•‰ºòÂåñ„ÄÇ
2. BOOMÊ°ÜÊû∂ÈÄöËøá‰∏ñÁïåÊ®°ÂûãËøûÊé•ËßÑÂàíÂíåÁ¶ªÁ≠ñÁï•Â≠¶‰π†ÔºåÂà©Áî®ËßÑÂàíÂô®‰ºòÂåñÂä®‰ΩúÊù•ÂºïÂØºÁ≠ñÁï•ÔºåÂÆûÁé∞Ë°å‰∏∫ÂØπÈΩê„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåBOOMÂú®DeepMind Control SuiteÂíåHumanoid-Bench‰∏äÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑËÆ≠ÁªÉÁ®≥ÂÆöÊÄßÂíåÊúÄÁªàÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®Á∫øËßÑÂàíÂ∑≤Ë¢´ËØÅÊòéÂú®Âº∫ÂåñÂ≠¶‰π†‰∏≠ËÉΩÊúâÊïàÊèêÈ´òÊ†∑Êú¨ÊïàÁéáÂíåÊúÄÁªàÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºå‰ΩøÁî®ËßÑÂàíËøõË°åÁéØÂ¢É‰∫§‰∫í‰∏çÂèØÈÅøÂÖçÂú∞‰ºöÂú®Êî∂ÈõÜÁöÑÊï∞ÊçÆ‰∏éÁ≠ñÁï•ÁöÑÂÆûÈôÖË°å‰∏∫‰πãÈó¥ÂºïÂÖ•Â∑ÆÂºÇÔºå‰ªéËÄåÈôç‰ΩéÊ®°ÂûãÂ≠¶‰π†ÂíåÁ≠ñÁï•ÊîπËøõÁöÑÊïàÊûú„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜBOOMÔºàBootstrap Off-policy with WOrld ModelÔºâÔºå‰∏Ä‰∏™ÈÄöËøáÂºïÂØºÂæ™ÁéØÁ¥ßÂØÜÈõÜÊàêËßÑÂàíÂíåÁ¶ªÁ≠ñÁï•Â≠¶‰π†ÁöÑÊ°ÜÊû∂ÔºöÁ≠ñÁï•ÂàùÂßãÂåñËßÑÂàíÂô®ÔºåËßÑÂàíÂô®ÈÄöËøáË°å‰∏∫ÂØπÈΩê‰ºòÂåñÂä®‰Ωú‰ª•ÂºïÂØºÁ≠ñÁï•„ÄÇËøôÁßçÂæ™ÁéØÁî±ËÅîÂêàÂ≠¶‰π†ÁöÑ‰∏ñÁïåÊ®°ÂûãÊîØÊåÅÔºåËØ•Ê®°Âûã‰ΩøËßÑÂàíÂô®ËÉΩÂ§üÊ®°ÊãüÊú™Êù•ÁöÑËΩ®ËøπÔºåÂπ∂Êèê‰æõ‰ª∑ÂÄºÁõÆÊ†á‰ª•‰øÉËøõÁ≠ñÁï•ÊîπËøõ„ÄÇBOOMÁöÑÊ†∏ÂøÉÊòØ‰∏Ä‰∏™Êó†‰ººÁÑ∂ÂØπÈΩêÊçüÂ§±ÔºåÂÆÉ‰ΩøÁî®ËßÑÂàíÂô®ÁöÑÈùûÂèÇÊï∞Âä®‰ΩúÂàÜÂ∏ÉÊù•ÂºïÂØºÁ≠ñÁï•ÔºåÂπ∂ÁªìÂêàËΩØ‰ª∑ÂÄºÂä†ÊùÉÊú∫Âà∂Ôºå‰ºòÂÖàËÄÉËôëÈ´òÂõûÊä•Ë°å‰∏∫ÔºåÂπ∂ÂáèËΩªÂõûÊîæÁºìÂÜ≤Âå∫‰∏≠ËßÑÂàíÂô®Âä®‰ΩúË¥®ÈáèÁöÑÂèØÂèòÊÄß„ÄÇÂú®DeepMind Control SuiteÂíåHumanoid-Bench‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåBOOMÂú®ËÆ≠ÁªÉÁ®≥ÂÆöÊÄßÂíåÊúÄÁªàÊÄßËÉΩÊñπÈù¢ÈÉΩËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÁªìÊûú„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂú®Á∫øËßÑÂàíÂú®Âº∫ÂåñÂ≠¶‰π†‰∏≠Èù¢‰∏¥Êï∞ÊçÆÂÅèÂ∑ÆÈóÆÈ¢òÔºåÂç≥Á≠ñÁï•ÂÆûÈôÖÊâßË°åÁöÑÂä®‰Ωú‰∏éËßÑÂàíÂô®‰∫ßÁîüÁöÑÂä®‰ΩúÂ≠òÂú®Â∑ÆÂºÇÔºåÂØºËá¥Ê®°ÂûãÂ≠¶‰π†ÂíåÁ≠ñÁï•ÊîπËøõÂèóÈòª„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂà©Áî®ËßÑÂàíÁöÑ‰ºòÂäøÔºåÂêåÊó∂ÈÅøÂÖçÊï∞ÊçÆÂÅèÂ∑ÆÂ∏¶Êù•ÁöÑË¥üÈù¢ÂΩ±Âìç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöBOOMÁöÑÊ†∏ÂøÉÂú®‰∫éÈÄöËøá‰∏Ä‰∏™ÂºïÂØºÂæ™ÁéØÔºåÂ∞ÜËßÑÂàíÂô®ÂíåÁ¶ªÁ≠ñÁï•Â≠¶‰π†Á¥ßÂØÜÁªìÂêà„ÄÇÁ≠ñÁï•ÂàùÂßãÂåñËßÑÂàíÂô®ÔºåËßÑÂàíÂô®ÈÄöËøá‰ºòÂåñÂä®‰ΩúÊù•ÂºïÂØºÁ≠ñÁï•Ôºå‰ªéËÄåÂÆûÁé∞Ë°å‰∏∫ÂØπÈΩê„ÄÇ‰∏ñÁïåÊ®°ÂûãÂàô‰∏∫ËßÑÂàíÂô®Êèê‰æõÊ®°ÊãüÁéØÂ¢ÉÔºåÂπ∂‰∏∫Á≠ñÁï•ÊîπËøõÊèê‰æõ‰ª∑ÂÄºÁõÆÊ†á„ÄÇËøôÁßçÂæ™ÁéØÊú∫Âà∂Êó®Âú®Âà©Áî®ËßÑÂàíÁöÑ‰ºòÂäøÔºåÂêåÊó∂ÂáèËΩªÊï∞ÊçÆÂÅèÂ∑ÆÁöÑÂΩ±Âìç„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöBOOMÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö‰∏ñÁïåÊ®°Âûã„ÄÅËßÑÂàíÂô®ÂíåÁ≠ñÁï•„ÄÇ‰∏ñÁïåÊ®°ÂûãË¥üË¥£Â≠¶‰π†ÁéØÂ¢ÉÁöÑÂä®ÊÄÅÁâπÊÄßÔºåËßÑÂàíÂô®Âà©Áî®‰∏ñÁïåÊ®°ÂûãËøõË°åÊú™Êù•ËΩ®ËøπÁöÑÊ®°ÊãüÂíåÂä®‰Ωú‰ºòÂåñÔºåÁ≠ñÁï•ÂàôÊ†πÊçÆËßÑÂàíÂô®ÁöÑËæìÂá∫ËøõË°åÊîπËøõ„ÄÇÊï¥‰∏™Ê°ÜÊû∂ÈÄöËøá‰∏Ä‰∏™ÂºïÂØºÂæ™ÁéØËøõË°åËø≠‰ª£Êõ¥Êñ∞ÔºåÁ≠ñÁï•ÁöÑËæìÂá∫‰Ωú‰∏∫ËßÑÂàíÂô®ÁöÑËæìÂÖ•ÔºåËßÑÂàíÂô®ÁöÑËæìÂá∫ÂèàÁî®‰∫éÁ≠ñÁï•ÁöÑÊîπËøõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöBOOMÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊó†‰ººÁÑ∂ÂØπÈΩêÊçüÂ§±ÂíåËΩØ‰ª∑ÂÄºÂä†ÊùÉÊú∫Âà∂„ÄÇÊó†‰ººÁÑ∂ÂØπÈΩêÊçüÂ§±Âà©Áî®ËßÑÂàíÂô®ÁöÑÈùûÂèÇÊï∞Âä®‰ΩúÂàÜÂ∏ÉÊù•ÂºïÂØºÁ≠ñÁï•ÔºåÈÅøÂÖç‰∫ÜÂØπÂä®‰ΩúÂàÜÂ∏ÉÁöÑÊòæÂºèÂª∫Ê®°„ÄÇËΩØ‰ª∑ÂÄºÂä†ÊùÉÊú∫Âà∂Âàô‰ºòÂÖàËÄÉËôëÈ´òÂõûÊä•Ë°å‰∏∫ÔºåÂπ∂ÂáèËΩªÂõûÊîæÁºìÂÜ≤Âå∫‰∏≠ËßÑÂàíÂô®Âä®‰ΩúË¥®ÈáèÁöÑÂèØÂèòÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöBOOM‰ΩøÁî®ËÅîÂêàÂ≠¶‰π†ÁöÑÊñπÂºèËÆ≠ÁªÉ‰∏ñÁïåÊ®°ÂûãÔºåËßÑÂàíÂô®ÂíåÁ≠ñÁï•„ÄÇÊó†‰ººÁÑ∂ÂØπÈΩêÊçüÂ§±ÁöÑÂÖ∑‰ΩìÂΩ¢Âºè‰∏∫ÊúÄÂ∞èÂåñÁ≠ñÁï•ËæìÂá∫Âä®‰Ωú‰∏éËßÑÂàíÂô®ËæìÂá∫Âä®‰Ωú‰πãÈó¥ÁöÑË∑ùÁ¶ªÔºåÂèØ‰ª•‰ΩøÁî®KLÊï£Â∫¶ÊàñJSÊï£Â∫¶Á≠âÂ∫¶ÈáèÊñπÂºè„ÄÇËΩØ‰ª∑ÂÄºÂä†ÊùÉÊú∫Âà∂ÂàôÊ†πÊçÆËßÑÂàíÂô®ËæìÂá∫Âä®‰ΩúÁöÑ‰ª∑ÂÄºÂØπÂõûÊîæÁºìÂÜ≤Âå∫‰∏≠ÁöÑÊ†∑Êú¨ËøõË°åÂä†ÊùÉÔºå‰ª∑ÂÄºË∂äÈ´òÔºåÊùÉÈáçË∂äÂ§ß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

BOOMÂú®DeepMind Control SuiteÂíåHumanoid-BenchÁ≠âÈ´òÁª¥ÊéßÂà∂‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåBOOMÂú®ËÆ≠ÁªÉÁ®≥ÂÆöÊÄßÂíåÊúÄÁªàÊÄßËÉΩÊñπÈù¢Âùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåËææÂà∞‰∫ÜÊúÄÂÖàËøõÊ∞¥Âπ≥„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∫õ‰ªªÂä°‰∏äÔºåBOOMÁöÑÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶Ë∂ÖËøá‰∫Ü20%„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

BOOMÊ°ÜÊû∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÊéßÂà∂„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊ∏∏ÊàèAIÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÁªìÂêàËßÑÂàíÂíåÁ¶ªÁ≠ñÁï•Â≠¶‰π†ÔºåBOOMËÉΩÂ§üÊúâÊïàÊèêÈ´òÊ†∑Êú¨ÊïàÁéáÂíåÊúÄÁªàÊÄßËÉΩÔºå‰ªéËÄåÈôç‰ΩéËÆ≠ÁªÉÊàêÊú¨ÔºåÂπ∂ÊèêÂçáÊô∫ËÉΩ‰ΩìÁöÑÂÜ≥Á≠ñËÉΩÂäõ„ÄÇËØ•Á†îÁ©∂ÂØπ‰∫éÊé®Âä®Âº∫ÂåñÂ≠¶‰π†Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÂ∫îÁî®ÂÖ∑ÊúâÈáçË¶ÅÊÑè‰πâ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Online planning has proven effective in reinforcement learning (RL) for improving sample efficiency and final performance. However, using planning for environment interaction inevitably introduces a divergence between the collected data and the policy's actual behaviors, degrading both model learning and policy improvement. To address this, we propose BOOM (Bootstrap Off-policy with WOrld Model), a framework that tightly integrates planning and off-policy learning through a bootstrap loop: the policy initializes the planner, and the planner refines actions to bootstrap the policy through behavior alignment. This loop is supported by a jointly learned world model, which enables the planner to simulate future trajectories and provides value targets to facilitate policy improvement. The core of BOOM is a likelihood-free alignment loss that bootstraps the policy using the planner's non-parametric action distribution, combined with a soft value-weighted mechanism that prioritizes high-return behaviors and mitigates variability in the planner's action quality within the replay buffer. Experiments on the high-dimensional DeepMind Control Suite and Humanoid-Bench show that BOOM achieves state-of-the-art results in both training stability and final performance. The code is accessible at https://github.com/molumitu/BOOM_MBRL.

