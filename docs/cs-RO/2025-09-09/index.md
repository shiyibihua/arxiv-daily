---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-09-09
---

# cs.ROï¼ˆ2025-09-09ï¼‰

ğŸ“Š å…± **16** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (9 ğŸ”—3)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250907957v1-graph-fused-vision-language-action-for-policy-reasoning-in-multi-arm.html">Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation</a></td>
  <td>æå‡ºGraph-Fused VLAæ¡†æ¶ï¼Œè§£å†³åŒè‡‚æœºå™¨äººä»äººç±»æ¼”ç¤ºä¸­å­¦ä¹ å¤æ‚æ“ä½œç­–ç•¥çš„é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">bi-manual</span> <span class="paper-tag">dual-arm</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.07957v1" data-paper-url="./papers/250907957v1-graph-fused-vision-language-action-for-policy-reasoning-in-multi-arm.html" onclick="toggleFavorite(this, '2509.07957v1', 'Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250907445v1-text2touch-tactile-in-hand-manipulation-with-llm-designed-reward-fun.html">Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions</a></td>
  <td>Text2Touchï¼šåˆ©ç”¨LLMè®¾è®¡çš„å¥–åŠ±å‡½æ•°å®ç°è§¦è§‰çµå·§æ‰‹å†…æ“ä½œ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span> <span class="paper-tag">in-hand manipulation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.07445v1" data-paper-url="./papers/250907445v1-text2touch-tactile-in-hand-manipulation-with-llm-designed-reward-fun.html" onclick="toggleFavorite(this, '2509.07445v1', 'Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250907962v1-ta-vla-elucidating-the-design-space-of-torque-aware-vision-language-.html">TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models</a></td>
  <td>æå‡ºæ‰­çŸ©æ„ŸçŸ¥è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹(TA-VLA)ï¼Œæå‡æœºå™¨äººæ“ä½œä¸­åŠ›è§‰åé¦ˆçš„åˆ©ç”¨ç‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.07962v1" data-paper-url="./papers/250907962v1-ta-vla-elucidating-the-design-space-of-torque-aware-vision-language-.html" onclick="toggleFavorite(this, '2509.07962v1', 'TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250907646v1-decoding-robkinet-insights-into-efficient-training-of-robotic-kinema.html">Decoding RobKiNet: Insights into Efficient Training of Robotic Kinematics Informed Neural Network</a></td>
  <td>RobKiNetï¼šä¸€ç§åŸºäºè¿åŠ¨å­¦çŸ¥è¯†çš„ç¥ç»ç½‘ç»œï¼Œç”¨äºæå‡æœºå™¨äººæ„å‹ç©ºé—´é‡‡æ ·æ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.07646v1" data-paper-url="./papers/250907646v1-decoding-robkinet-insights-into-efficient-training-of-robotic-kinema.html" onclick="toggleFavorite(this, '2509.07646v1', 'Decoding RobKiNet: Insights into Efficient Training of Robotic Kinematics Informed Neural Network')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250907500v1-omnimap-a-general-mapping-framework-integrating-optics-geometry-and-.html">OmniMap: A General Mapping Framework Integrating Optics, Geometry, and Semantics</a></td>
  <td>OmniMapï¼šæå‡ºä¸€ç§èåˆå…‰å­¦ã€å‡ ä½•å’Œè¯­ä¹‰ä¿¡æ¯çš„é€šç”¨å»ºå›¾æ¡†æ¶ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">3DGS</span> <span class="paper-tag">scene understanding</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.07500v1" data-paper-url="./papers/250907500v1-omnimap-a-general-mapping-framework-integrating-optics-geometry-and-.html" onclick="toggleFavorite(this, '2509.07500v1', 'OmniMap: A General Mapping Framework Integrating Optics, Geometry, and Semantics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250908160v1-diffusion-guided-multi-arm-motion-planning.html">Diffusion-Guided Multi-Arm Motion Planning</a></td>
  <td>æå‡ºæ‰©æ•£å¼•å¯¼çš„å¤šè‡‚è¿åŠ¨è§„åˆ’DG-MAPï¼Œè§£å†³é«˜ç»´çŠ¶æ€ç©ºé—´ä¸‹çš„å¤šè‡‚åä½œè§„åˆ’é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">dual-arm</span> <span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.08160v1" data-paper-url="./papers/250908160v1-diffusion-guided-multi-arm-motion-planning.html" onclick="toggleFavorite(this, '2509.08160v1', 'Diffusion-Guided Multi-Arm Motion Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250907381v1-transmpc-transformer-based-explicit-mpc-with-variable-prediction-hor.html">TransMPC: Transformer-based Explicit MPC with Variable Prediction Horizon</a></td>
  <td>TransMPCï¼šåŸºäºTransformerçš„å¯å˜é¢„æµ‹æ­¥é•¿æ˜¾å¼æ¨¡å‹é¢„æµ‹æ§åˆ¶</td>
  <td class="tags-cell"><span class="paper-tag">MPC</span> <span class="paper-tag">model predictive control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.07381v1" data-paper-url="./papers/250907381v1-transmpc-transformer-based-explicit-mpc-with-variable-prediction-hor.html" onclick="toggleFavorite(this, '2509.07381v1', 'TransMPC: Transformer-based Explicit MPC with Variable Prediction Horizon')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250907953v1-rac-robot-learning-for-long-horizon-tasks-by-scaling-recovery-and-co.html">RaC: Robot Learning for Long-Horizon Tasks by Scaling Recovery and Correction</a></td>
  <td>RaCï¼šé€šè¿‡æ‰©å±•æ¢å¤ä¸çº æ­£èƒ½åŠ›å®ç°æœºå™¨äººé•¿æ—¶ç¨‹ä»»åŠ¡å­¦ä¹ </td>
  <td class="tags-cell"><span class="paper-tag">bi-manual</span> <span class="paper-tag">teleoperation</span> <span class="paper-tag">imitation learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.07953v1" data-paper-url="./papers/250907953v1-rac-robot-learning-for-long-horizon-tasks-by-scaling-recovery-and-co.html" onclick="toggleFavorite(this, '2509.07953v1', 'RaC: Robot Learning for Long-Horizon Tasks by Scaling Recovery and Correction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250907464v1-safe-and-non-conservative-contingency-planning-for-autonomous-vehicl.html">Safe and Non-Conservative Contingency Planning for Autonomous Vehicles via Online Learning-Based Reachable Set Barriers</a></td>
  <td>æå‡ºåŸºäºåœ¨çº¿å­¦ä¹ å¯è¾¾é›†å±éšœçš„è‡ªåŠ¨é©¾é©¶è½¦è¾†å®‰å…¨åº”æ€¥è§„åˆ’æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">trajectory optimization</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.07464v1" data-paper-url="./papers/250907464v1-safe-and-non-conservative-contingency-planning-for-autonomous-vehicl.html" onclick="toggleFavorite(this, '2509.07464v1', 'Safe and Non-Conservative Contingency Planning for Autonomous Vehicles via Online Learning-Based Reachable Set Barriers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>10</td>
  <td><a href="./papers/250908159v1-zero-shot-metric-depth-estimation-via-monocular-visual-inertial-resc.html">Zero-Shot Metric Depth Estimation via Monocular Visual-Inertial Rescaling for Autonomous Aerial Navigation</a></td>
  <td>æå‡ºåŸºäºè§†è§‰æƒ¯æ€§é‡æ ‡å®šçš„é›¶æ ·æœ¬å•ç›®æ·±åº¦ä¼°è®¡æ–¹æ³•ï¼Œç”¨äºè‡ªä¸»é£è¡Œå™¨é¿éšœ</td>
  <td class="tags-cell"><span class="paper-tag">depth estimation</span> <span class="paper-tag">metric depth</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.08159v1" data-paper-url="./papers/250908159v1-zero-shot-metric-depth-estimation-via-monocular-visual-inertial-resc.html" onclick="toggleFavorite(this, '2509.08159v1', 'Zero-Shot Metric Depth Estimation via Monocular Visual-Inertial Rescaling for Autonomous Aerial Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250908126v1-attribute-based-object-grounding-and-robot-grasp-detection-with-spat.html">Attribute-based Object Grounding and Robot Grasp Detection with Spatial Reasoning</a></td>
  <td>æå‡ºåŸºäºå±æ€§çš„å¯¹è±¡å®šä½ä¸æœºå™¨äººæŠ“å–æ¡†æ¶OGRGï¼Œè§£å†³å¤æ‚åœºæ™¯ä¸‹çš„è¯­è¨€æŒ‡å®šæŠ“å–é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">affordance</span> <span class="paper-tag">grasp prediction</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.08126v1" data-paper-url="./papers/250908126v1-attribute-based-object-grounding-and-robot-grasp-detection-with-spat.html" onclick="toggleFavorite(this, '2509.08126v1', 'Attribute-based Object Grounding and Robot Grasp Detection with Spatial Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250907362v1-aerial-ground-cross-modal-localization-dataset-ground-truth-and-benc.html">Aerial-ground Cross-modal Localization: Dataset, Ground-truth, and Benchmark</a></td>
  <td>æå‡ºå¤§è§„æ¨¡è·¨æ¨¡æ€å®šä½æ•°æ®é›†ä¸åŸºå‡†ï¼Œä¿ƒè¿›èˆªç©º-åœ°é¢è§†è§‰å®šä½ç ”ç©¶</td>
  <td class="tags-cell"><span class="paper-tag">visual odometry</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.07362v1" data-paper-url="./papers/250907362v1-aerial-ground-cross-modal-localization-dataset-ground-truth-and-benc.html" onclick="toggleFavorite(this, '2509.07362v1', 'Aerial-ground Cross-modal Localization: Dataset, Ground-truth, and Benchmark')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/250907593v1-can-ssd-mamba2-unlock-reinforcement-learning-for-end-to-end-motion-c.html">Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion Control?</a></td>
  <td>æå‡ºåŸºäºSSD-Mamba2çš„è§†è§‰é©±åŠ¨å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºç«¯åˆ°ç«¯è¿åŠ¨æ§åˆ¶ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">Mamba</span> <span class="paper-tag">cross-embodiment</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.07593v1" data-paper-url="./papers/250907593v1-can-ssd-mamba2-unlock-reinforcement-learning-for-end-to-end-motion-c.html" onclick="toggleFavorite(this, '2509.07593v1', 'Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion Control?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250908177v1-quadrotor-navigation-using-reinforcement-learning-with-privileged-in.html">Quadrotor Navigation using Reinforcement Learning with Privileged Information</a></td>
  <td>æå‡ºä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ å’Œç‰¹æƒä¿¡æ¯çš„å››æ—‹ç¿¼å¯¼èˆªæ–¹æ³•ï¼Œè§£å†³å¤æ‚ç¯å¢ƒä¸‹è‡ªä¸»å¯¼èˆªé—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">privileged information</span> <span class="paper-tag">differentiable simulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.08177v1" data-paper-url="./papers/250908177v1-quadrotor-navigation-using-reinforcement-learning-with-privileged-in.html" onclick="toggleFavorite(this, '2509.08177v1', 'Quadrotor Navigation using Reinforcement Learning with Privileged Information')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250907707v1-fault-tolerant-control-of-a-quadcopter-using-reinforcement-learning.html">Fault Tolerant Control of a Quadcopter using Reinforcement Learning</a></td>
  <td>æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„å››æ—‹ç¿¼å®¹é”™æ§åˆ¶æ¡†æ¶ï¼Œæå‡å•æ¡¨å¤±æ•ˆä¸‹çš„é²æ£’æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.07707v1" data-paper-url="./papers/250907707v1-fault-tolerant-control-of-a-quadcopter-using-reinforcement-learning.html" onclick="toggleFavorite(this, '2509.07707v1', 'Fault Tolerant Control of a Quadcopter using Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>16</td>
  <td><a href="./papers/250908017v2-pysensors-20-a-python-package-for-sparse-sensor-placement.html">PySensors 2.0: A Python Package for Sparse Sensor Placement</a></td>
  <td>PySensors 2.0ï¼šç”¨äºç¨€ç–ä¼ æ„Ÿå™¨æ”¾ç½®çš„Pythonè½¯ä»¶åŒ…ï¼Œæ”¯æŒç©ºé—´çº¦æŸå’Œä¸ç¡®å®šæ€§é‡åŒ–ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">sparse sensors</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.08017v2" data-paper-url="./papers/250908017v2-pysensors-20-a-python-package-for-sparse-sensor-placement.html" onclick="toggleFavorite(this, '2509.08017v2', 'PySensors 2.0: A Python Package for Sparse Sensor Placement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)