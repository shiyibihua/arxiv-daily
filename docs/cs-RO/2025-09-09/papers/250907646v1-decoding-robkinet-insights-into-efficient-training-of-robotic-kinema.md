---
layout: default
title: Decoding RobKiNet: Insights into Efficient Training of Robotic Kinematics Informed Neural Network
---

# Decoding RobKiNet: Insights into Efficient Training of Robotic Kinematics Informed Neural Network

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07646" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07646v1</a>
  <a href="https://arxiv.org/pdf/2509.07646.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07646v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07646v1', 'Decoding RobKiNet: Insights into Efficient Training of Robotic Kinematics Informed Neural Network')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yanlong Peng, Zhigang Wang, Ziwen He, Pengxu Chang, Chuangchuang Zhou, Yu Yan, Ming Chen

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**RobKiNetï¼šä¸€ç§åŸºäºè¿åŠ¨å­¦çŸ¥è¯†çš„ç¥ç»ç½‘ç»œï¼Œç”¨äºæå‡æœºå™¨äººæ„å‹ç©ºé—´é‡‡æ ·æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººè¿åŠ¨è§„åˆ’` `æ„å‹ç©ºé—´é‡‡æ ·` `è¿åŠ¨å­¦çŸ¥è¯†` `ç¥ç»ç½‘ç»œ` `è‡ªä¸»ç§»åŠ¨æœºæ¢°è‡‚`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿæœºå™¨äººä»»åŠ¡è§„åˆ’ä¸­ï¼Œæ„å‹ç©ºé—´é‡‡æ ·æ•ˆç‡ä½ï¼Œéš¾ä»¥æ»¡è¶³å¤šçº¦æŸæ¡ä»¶ä¸‹çš„ä»»åŠ¡éœ€æ±‚ã€‚
2. RobKiNeté€šè¿‡å°†è¿åŠ¨å­¦çŸ¥è¯†èå…¥ç¥ç»ç½‘ç»œï¼Œå®ç°å¯¹è¿ç»­å¯è¡Œé›†ï¼ˆCFSï¼‰çš„ç«¯åˆ°ç«¯é«˜æ•ˆé‡‡æ ·ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒRobKiNetåœ¨è®­ç»ƒé€Ÿåº¦ã€é‡‡æ ·ç²¾åº¦å’Œä»»åŠ¡å®Œæˆç‡ä¸Šå‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•å’Œæ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¿åŠ¨å­¦çŸ¥è¯†çš„ç¥ç»ç½‘ç»œRobKiNetï¼Œç”¨äºåœ¨æœºå™¨äººä»»åŠ¡å’Œè¿åŠ¨è§„åˆ’ï¼ˆTAMPï¼‰ä¸­ï¼Œå¯¹æ»¡è¶³å¤šå±‚çº¦æŸçš„è¿ç»­å¯è¡Œé›†ï¼ˆCFSï¼‰è¿›è¡Œç«¯åˆ°ç«¯é‡‡æ ·ã€‚è¯¥æ–¹æ³•å»ºç«‹äº†ä¼˜åŒ–æœŸæœ›æ¨¡å‹ã€‚ä¸ä¼ ç»Ÿé‡‡æ ·å’ŒåŸºäºå­¦ä¹ çš„æ–¹æ³•ç›¸æ¯”ï¼ŒRobKiNeté€šè¿‡èå…¥è¿åŠ¨å­¦çŸ¥è¯†ï¼Œç¡®ä¿ç¨³å®šå’Œç²¾ç¡®çš„æ¢¯åº¦ä¼˜åŒ–ï¼Œä»è€Œæé«˜äº†è®­ç»ƒæ•ˆç‡ã€‚åœ¨2è‡ªç”±åº¦ç©ºé—´ä¸­çš„å¯è§†åŒ–å’Œå®šé‡åˆ†æéªŒè¯äº†å…¶ç†è®ºæ•ˆç‡ã€‚åœ¨9è‡ªç”±åº¦è‡ªä¸»ç§»åŠ¨æœºæ¢°è‡‚æœºå™¨äººï¼ˆAMMRï¼‰ä¸Šçš„åº”ç”¨è¡¨æ˜ï¼ŒRobKiNetåœ¨æ•´ä½“å’Œè§£è€¦æ§åˆ¶æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ˜¯åœ¨ç”µæ± æ‹†å¸ä»»åŠ¡ä¸­ã€‚RobKiNetçš„è®­ç»ƒé€Ÿåº¦æ¯”æ·±åº¦å¼ºåŒ–å­¦ä¹ å¿«74.29å€ï¼Œé‡‡æ ·ç²¾åº¦é«˜è¾¾99.25%ï¼Œåœ¨å®é™…åœºæ™¯ä¸­çš„ä»»åŠ¡å®Œæˆç‡è¾¾åˆ°97.33%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šåœ¨æœºå™¨äººä»»åŠ¡å’Œè¿åŠ¨è§„åˆ’ä¸­ï¼Œé«˜æ•ˆåœ°åœ¨æ»¡è¶³å¤šå±‚çº¦æŸçš„æœºå™¨äººæ„å‹ç©ºé—´å†…è¿›è¡Œé‡‡æ ·è‡³å…³é‡è¦ã€‚ä¼ ç»Ÿæ–¹æ³•ï¼Œå¦‚éšæœºé‡‡æ ·æˆ–åŸºäºä¼˜åŒ–çš„æ–¹æ³•ï¼Œåœ¨å¤„ç†å¤æ‚çº¦æŸæ—¶æ•ˆç‡ä½ä¸‹ã€‚ç°æœ‰çš„åŸºäºå­¦ä¹ çš„æ–¹æ³•è™½ç„¶å¯ä»¥åŠ é€Ÿé‡‡æ ·è¿‡ç¨‹ï¼Œä½†å¾€å¾€ç¼ºä¹å¯¹æœºå™¨äººè¿åŠ¨å­¦çŸ¥è¯†çš„æœ‰æ•ˆåˆ©ç”¨ï¼Œå¯¼è‡´è®­ç»ƒä¸ç¨³å®šæˆ–é‡‡æ ·ç²¾åº¦ä¸é«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRobKiNetçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æœºå™¨äººçš„è¿åŠ¨å­¦çŸ¥è¯†èå…¥åˆ°ç¥ç»ç½‘ç»œçš„è®¾è®¡å’Œè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä»è€Œå¼•å¯¼ç½‘ç»œå­¦ä¹ åˆ°æ›´ç¬¦åˆæœºå™¨äººè¿åŠ¨è§„å¾‹çš„é‡‡æ ·ç­–ç•¥ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒRobKiNetèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ¢ç´¢æ„å‹ç©ºé—´ï¼Œå¹¶ç”Ÿæˆæ»¡è¶³çº¦æŸæ¡ä»¶çš„é«˜è´¨é‡æ ·æœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRobKiNetçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è¿åŠ¨å­¦çŸ¥è¯†åµŒå…¥æ¨¡å—ï¼šå°†æœºå™¨äººçš„è¿åŠ¨å­¦å‚æ•°ï¼ˆå¦‚å…³èŠ‚è§’åº¦ã€è¿æ†é•¿åº¦ç­‰ï¼‰ç¼–ç åˆ°ç¥ç»ç½‘ç»œä¸­ã€‚2) è¿ç»­å¯è¡Œé›†ï¼ˆCFSï¼‰é¢„æµ‹æ¨¡å—ï¼šåŸºäºè¿åŠ¨å­¦çŸ¥è¯†ï¼Œé¢„æµ‹åœ¨ç»™å®šçº¦æŸæ¡ä»¶ä¸‹ï¼Œæœºå™¨äººæ„å‹ç©ºé—´ä¸­çš„å¯è¡ŒåŒºåŸŸã€‚3) é‡‡æ ·æ¨¡å—ï¼šåœ¨é¢„æµ‹çš„CFSå†…è¿›è¡Œé‡‡æ ·ï¼Œç”Ÿæˆæ»¡è¶³çº¦æŸæ¡ä»¶çš„æœºå™¨äººæ„å‹ã€‚4) ä¼˜åŒ–æ¨¡å—ï¼šé€šè¿‡ä¼˜åŒ–æœŸæœ›æ¨¡å‹ï¼Œä¸æ–­è°ƒæ•´ç½‘ç»œå‚æ•°ï¼Œæé«˜é‡‡æ ·æ•ˆç‡å’Œç²¾åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šRobKiNetæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå…¶è¿åŠ¨å­¦çŸ¥è¯†çš„æ³¨å…¥æ–¹å¼ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸å°†è¿åŠ¨å­¦çŸ¥è¯†ä½œä¸ºçº¦æŸæ¡ä»¶åŠ å…¥åˆ°ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œè€ŒRobKiNetåˆ™ç›´æ¥å°†è¿åŠ¨å­¦çŸ¥è¯†åµŒå…¥åˆ°ç¥ç»ç½‘ç»œçš„ç»“æ„å’Œå‚æ•°ä¸­ï¼Œä½¿å¾—ç½‘ç»œèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œåˆ©ç”¨è¿™äº›çŸ¥è¯†ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æé«˜è®­ç»ƒæ•ˆç‡å’Œé‡‡æ ·ç²¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šRobKiNetçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) è¿åŠ¨å­¦å‚æ•°çš„ç¼–ç æ–¹å¼ï¼šé‡‡ç”¨ç‰¹å®šçš„ç¼–ç æ–¹å¼å°†æœºå™¨äººçš„è¿åŠ¨å­¦å‚æ•°è½¬åŒ–ä¸ºç¥ç»ç½‘ç»œå¯ä»¥å¤„ç†çš„å‘é‡å½¢å¼ã€‚2) æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼šè®¾è®¡åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±ç½‘ç»œç”Ÿæˆæ»¡è¶³çº¦æŸæ¡ä»¶çš„æ„å‹ï¼Œå¹¶æé«˜é‡‡æ ·æ•ˆç‡ã€‚3) ç½‘ç»œç»“æ„çš„é€‰æ‹©ï¼šé€‰æ‹©åˆé€‚çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œå¦‚å¾ªç¯ç¥ç»ç½‘ç»œæˆ–å›¾ç¥ç»ç½‘ç»œï¼Œä»¥æ›´å¥½åœ°æ•æ‰æœºå™¨äººè¿åŠ¨çš„åºåˆ—æ€§å’Œæ‹“æ‰‘ç»“æ„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRobKiNetåœ¨9è‡ªç”±åº¦è‡ªä¸»ç§»åŠ¨æœºæ¢°è‡‚æœºå™¨äººï¼ˆAMMRï¼‰ä¸Šçš„ç”µæ± æ‹†å¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚ä¸æ·±åº¦å¼ºåŒ–å­¦ä¹ ç›¸æ¯”ï¼ŒRobKiNetçš„è®­ç»ƒé€Ÿåº¦æé«˜äº†74.29å€ï¼Œé‡‡æ ·ç²¾åº¦é«˜è¾¾99.25%ï¼Œåœ¨å®é™…åœºæ™¯ä¸­çš„ä»»åŠ¡å®Œæˆç‡è¾¾åˆ°97.33%ã€‚è¿™äº›æ•°æ®å……åˆ†è¯æ˜äº†RobKiNetåœ¨å¤æ‚æœºå™¨äººä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RobKiNetå¯åº”ç”¨äºå„ç§æœºå™¨äººä»»åŠ¡å’Œè¿åŠ¨è§„åˆ’åœºæ™¯ï¼Œä¾‹å¦‚è‡ªä¸»å¯¼èˆªã€ç‰©ä½“æŠ“å–ã€è£…é…å’Œæ‹†å¸ç­‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„ä»»åŠ¡å®Œæˆæ•ˆç‡å’Œå¯é æ€§ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦æ»¡è¶³å¤šé‡çº¦æŸçš„åœºæ™¯ä¸‹ã€‚æœªæ¥ï¼ŒRobKiNetæœ‰æœ›åº”ç”¨äºå·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—æœºå™¨äººã€æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸï¼Œæ¨åŠ¨æœºå™¨äººæŠ€æœ¯çš„æ™ºèƒ½åŒ–å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In robots task and motion planning (TAMP), it is crucial to sample within the robot's configuration space to meet task-level global constraints and enhance the efficiency of subsequent motion planning. Due to the complexity of joint configuration sampling under multi-level constraints, traditional methods often lack efficiency. This paper introduces the principle of RobKiNet, a kinematics-informed neural network, for end-to-end sampling within the Continuous Feasible Set (CFS) under multiple constraints in configuration space, establishing its Optimization Expectation Model. Comparisons with traditional sampling and learning-based approaches reveal that RobKiNet's kinematic knowledge infusion enhances training efficiency by ensuring stable and accurate gradient optimization.Visualizations and quantitative analyses in a 2-DOF space validate its theoretical efficiency, while its application on a 9-DOF autonomous mobile manipulator robot(AMMR) demonstrates superior whole-body and decoupled control, excelling in battery disassembly tasks. RobKiNet outperforms deep reinforcement learning with a training speed 74.29 times faster and a sampling accuracy of up to 99.25%, achieving a 97.33% task completion rate in real-world scenarios.

