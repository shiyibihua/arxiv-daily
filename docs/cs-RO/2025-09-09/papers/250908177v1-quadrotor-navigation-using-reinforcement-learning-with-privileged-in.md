---
layout: default
title: Quadrotor Navigation using Reinforcement Learning with Privileged Information
---

# Quadrotor Navigation using Reinforcement Learning with Privileged Information

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.08177" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.08177v1</a>
  <a href="https://arxiv.org/pdf/2509.08177.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.08177v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.08177v1', 'Quadrotor Navigation using Reinforcement Learning with Privileged Information')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jonathan Lee, Abhishek Rathod, Kshitij Goel, John Stecklein, Wennie Tabib

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ å’Œç‰¹æƒä¿¡æ¯çš„å››æ—‹ç¿¼å¯¼èˆªæ–¹æ³•ï¼Œè§£å†³å¤æ‚ç¯å¢ƒä¸‹è‡ªä¸»å¯¼èˆªé—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `å››æ—‹ç¿¼å¯¼èˆª` `å¼ºåŒ–å­¦ä¹ ` `ç‰¹æƒä¿¡æ¯` `åˆ°è¾¾æ—¶é—´å›¾` `è‡ªä¸»å¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºå­¦ä¹ çš„å¯¼èˆªæ–¹æ³•åœ¨å¤æ‚ç¯å¢ƒä¸‹ï¼ˆå¦‚å¤§å‹éšœç¢ç‰©é®æŒ¡ç›®æ ‡ï¼‰è¡¨ç°ä¸ä½³ï¼Œå¯¼èˆªæˆåŠŸç‡ä½ã€‚
2. åˆ©ç”¨åˆ°è¾¾æ—¶é—´ï¼ˆToAï¼‰å›¾ä½œä¸ºç‰¹æƒä¿¡æ¯ï¼Œå¹¶è®¾è®¡åèˆªå¯¹é½æŸå¤±ï¼Œå¼•å¯¼å››æ—‹ç¿¼ç»•è¿‡å¤§å‹éšœç¢ç‰©ã€‚
3. åœ¨é€¼çœŸä»¿çœŸå’ŒçœŸå®å®¤å¤–ç¯å¢ƒä¸­éªŒè¯ï¼Œå¯¼èˆªæˆåŠŸç‡è¾¾86%ï¼Œä¼˜äºåŸºçº¿æ–¹æ³•34%ï¼Œå¹¶æˆåŠŸå®Œæˆå¤šæ¬¡é£è¡Œæµ‹è¯•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„å››æ—‹ç¿¼å¯¼èˆªæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é«˜æ•ˆçš„å¯å¾®ä»¿çœŸã€æ–°é¢–çš„æŸå¤±å‡½æ•°å’Œç‰¹æƒä¿¡æ¯ï¼Œå®ç°åœ¨å¤§å‹éšœç¢ç‰©å‘¨å›´çš„å¯¼èˆªã€‚ç°æœ‰çš„åŸºäºå­¦ä¹ çš„æ–¹æ³•åœ¨ç‹­çª„éšœç¢ç‰©çš„åœºæ™¯ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ç›®æ ‡ä½ç½®è¢«å¤§å‹å¢™å£æˆ–åœ°å½¢é˜»æŒ¡æ—¶è¡¨ç°ä¸ä½³ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åˆ©ç”¨åˆ°è¾¾æ—¶é—´ï¼ˆToAï¼‰å›¾ä½œä¸ºç‰¹æƒä¿¡æ¯å’Œåèˆªå¯¹é½æŸå¤±æ¥å¼•å¯¼æœºå™¨äººç»•è¿‡å¤§å‹éšœç¢ç‰©ã€‚è¯¥ç­–ç•¥åœ¨åŒ…å«å¤§å‹éšœç¢ç‰©ã€å°–è§’å’Œæ­»èƒ¡åŒçš„ç…§ç‰‡çº§çœŸå®æ„Ÿä»¿çœŸç¯å¢ƒä¸­è¿›è¡Œäº†è¯„ä¼°ã€‚æˆ‘ä»¬çš„æ–¹æ³•å®ç°äº† 86% çš„æˆåŠŸç‡ï¼Œå¹¶ä¸”ä¼˜äºåŸºçº¿ç­–ç•¥ 34%ã€‚æˆ‘ä»¬å°†è¯¥ç­–ç•¥éƒ¨ç½²åœ¨å®šåˆ¶çš„å››æ—‹ç¿¼é£è¡Œå™¨ä¸Šï¼Œåœ¨ç™½å¤©å’Œå¤œæ™šçš„å®¤å¤–æ‚ä¹±ç¯å¢ƒä¸­è¿›è¡Œäº†éªŒè¯ã€‚è¯¥ç­–ç•¥åœ¨ 20 æ¬¡é£è¡Œä¸­å¾—åˆ°éªŒè¯ï¼Œä»¥é«˜è¾¾ 4 ç±³/ç§’çš„é€Ÿåº¦é£è¡Œäº† 589 ç±³ï¼Œæ²¡æœ‰å‘ç”Ÿç¢°æ’ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å››æ—‹ç¿¼é£è¡Œå™¨åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„è‡ªä¸»å¯¼èˆªé—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å­˜åœ¨å¤§å‹éšœç¢ç‰©ã€å°–è§’å’Œæ­»èƒ¡åŒç­‰æŒ‘æˆ˜æ€§åœºæ™¯ä¸­ã€‚ç°æœ‰åŸºäºå­¦ä¹ çš„å¯¼èˆªæ–¹æ³•é€šå¸¸åœ¨ç‹­çª„éšœç¢ç‰©ç¯å¢ƒä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†å½“ç›®æ ‡ä½ç½®è¢«å¤§å‹å¢™å£æˆ–åœ°å½¢é˜»æŒ¡æ—¶ï¼Œæ€§èƒ½ä¼šæ˜¾è‘—ä¸‹é™ï¼Œéš¾ä»¥å®ç°å¯é çš„å¯¼èˆªã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸€ä¸ªå¯¼èˆªç­–ç•¥ï¼Œå¹¶å¼•å…¥â€œç‰¹æƒä¿¡æ¯â€æ¥è¾…åŠ©è®­ç»ƒã€‚å…·ä½“æ¥è¯´ï¼Œä½¿ç”¨åˆ°è¾¾æ—¶é—´ï¼ˆToAï¼‰å›¾ä½œä¸ºç‰¹æƒä¿¡æ¯ï¼ŒToAå›¾æä¾›äº†å…³äºç¯å¢ƒçš„å…¨å±€ä¿¡æ¯ï¼Œå¯ä»¥å¸®åŠ©æ™ºèƒ½ä½“æ›´å¥½åœ°ç†è§£ç¯å¢ƒç»“æ„å’Œè§„åˆ’è·¯å¾„ã€‚æ­¤å¤–ï¼Œè¿˜è®¾è®¡äº†ä¸€ä¸ªåèˆªå¯¹é½æŸå¤±å‡½æ•°ï¼Œå¼•å¯¼å››æ—‹ç¿¼çš„æœå‘ä¸ç›®æ ‡æ–¹å‘å¯¹é½ï¼Œä»è€Œæé«˜å¯¼èˆªæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1) å¯å¾®ä»¿çœŸç¯å¢ƒï¼šç”¨äºè®­ç»ƒå¼ºåŒ–å­¦ä¹ ç­–ç•¥ã€‚2) å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼šä½¿ç”¨åˆé€‚çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå…·ä½“ç®—æ³•æœªçŸ¥ï¼‰è®­ç»ƒå¯¼èˆªç­–ç•¥ã€‚3) ç‰¹æƒä¿¡æ¯ï¼šä½¿ç”¨åˆ°è¾¾æ—¶é—´ï¼ˆToAï¼‰å›¾ä½œä¸ºç‰¹æƒä¿¡æ¯ï¼Œè¾“å…¥åˆ°ç­–ç•¥ç½‘ç»œä¸­ã€‚4) æŸå¤±å‡½æ•°ï¼šåŒ…æ‹¬å¯¼èˆªå¥–åŠ±ã€ç¢°æ’æƒ©ç½šå’Œåèˆªå¯¹é½æŸå¤±ç­‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†ç‰¹æƒä¿¡æ¯ï¼ˆToAå›¾ï¼‰å’Œåèˆªå¯¹é½æŸå¤±å‡½æ•°ã€‚ToAå›¾æä¾›äº†å…¨å±€ç¯å¢ƒä¿¡æ¯ï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¤§å‹éšœç¢ç‰©é®æŒ¡ä¸‹çš„å±€é™æ€§ã€‚åèˆªå¯¹é½æŸå¤±åˆ™æé«˜äº†å¯¼èˆªæ•ˆç‡å’Œç¨³å®šæ€§ã€‚è¿™ç§ç»“åˆç‰¹æƒä¿¡æ¯å’Œç‰¹å®šä»»åŠ¡æŸå¤±å‡½æ•°çš„æ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆæå‡å¼ºåŒ–å­¦ä¹ åœ¨å¤æ‚å¯¼èˆªä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³äºå…·ä½“çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®ï¼Œè®ºæ–‡æ‘˜è¦ä¸­æ²¡æœ‰è¯¦ç»†è¯´æ˜ã€‚ä½†å¯ä»¥æ¨æµ‹ï¼Œç­–ç•¥ç½‘ç»œå¯èƒ½åŒ…å«å·ç§¯å±‚ï¼ˆç”¨äºå¤„ç†è§†è§‰è¾“å…¥ï¼‰å’Œå¾ªç¯å±‚ï¼ˆç”¨äºå¤„ç†æ—¶é—´åºåˆ—ä¿¡æ¯ï¼‰ã€‚åèˆªå¯¹é½æŸå¤±çš„å…·ä½“å½¢å¼å¯èƒ½æ˜¯è¡¡é‡å½“å‰åèˆªè§’ä¸ç›®æ ‡åèˆªè§’ä¹‹é—´å·®å¼‚çš„å‡½æ•°ã€‚ToAå›¾çš„å…·ä½“è®¡ç®—æ–¹æ³•ä¹ŸæœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨ç…§ç‰‡çº§çœŸå®æ„Ÿä»¿çœŸç¯å¢ƒä¸­å®ç°äº†86%çš„å¯¼èˆªæˆåŠŸç‡ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿ç­–ç•¥ï¼ˆæå‡34%ï¼‰ã€‚åœ¨çœŸå®çš„å®¤å¤–ç¯å¢ƒä¸­ï¼Œè¯¥ç­–ç•¥æˆåŠŸå®Œæˆäº†20æ¬¡é£è¡Œæµ‹è¯•ï¼Œæ€»é£è¡Œè·ç¦»è¾¾åˆ°589ç±³ï¼Œæœ€é«˜é€Ÿåº¦è¾¾åˆ°4ç±³/ç§’ï¼Œä¸”æ²¡æœ‰å‘ç”Ÿç¢°æ’ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ— äººæœºè‡ªä¸»å·¡æ£€ã€ç‰©æµé…é€ã€æœç´¢æ•‘æ´ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡æ— äººæœºåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„å¯¼èˆªèƒ½åŠ›ï¼Œå¯ä»¥é™ä½äººå·¥å¹²é¢„çš„éœ€æ±‚ï¼Œæé«˜å·¥ä½œæ•ˆç‡å’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æ¨å¹¿åˆ°å…¶ä»–ç±»å‹çš„æœºå™¨äººï¼Œä¾‹å¦‚åœ°é¢æœºå™¨äººå’Œæ°´ä¸‹æœºå™¨äººã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents a reinforcement learning-based quadrotor navigation method that leverages efficient differentiable simulation, novel loss functions, and privileged information to navigate around large obstacles. Prior learning-based methods perform well in scenes that exhibit narrow obstacles, but struggle when the goal location is blocked by large walls or terrain. In contrast, the proposed method utilizes time-of-arrival (ToA) maps as privileged information and a yaw alignment loss to guide the robot around large obstacles. The policy is evaluated in photo-realistic simulation environments containing large obstacles, sharp corners, and dead-ends. Our approach achieves an 86% success rate and outperforms baseline strategies by 34%. We deploy the policy onboard a custom quadrotor in outdoor cluttered environments both during the day and night. The policy is validated across 20 flights, covering 589 meters without collisions at speeds up to 4 m/s.

