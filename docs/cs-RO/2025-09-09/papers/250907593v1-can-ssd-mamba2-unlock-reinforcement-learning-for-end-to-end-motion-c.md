---
layout: default
title: Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion Control?
---

# Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion Control?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07593" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07593v1</a>
  <a href="https://arxiv.org/pdf/2509.07593.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07593v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07593v1', 'Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion Control?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Gavin Tao, Yinuo Wang, Jinzhao Zhou

**åˆ†ç±»**: cs.RO, cs.AI, cs.CV, eess.IV, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09

**å¤‡æ³¨**: 4 figures and 6 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºSSD-Mamba2çš„è§†è§‰é©±åŠ¨å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºç«¯åˆ°ç«¯è¿åŠ¨æ§åˆ¶ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `ç«¯åˆ°ç«¯æ§åˆ¶` `å¼ºåŒ–å­¦ä¹ ` `è¿åŠ¨æ§åˆ¶` `SSD-Mamba2` `è·¨æ¨¡æ€èåˆ` `è§†è§‰æ„ŸçŸ¥` `æœºå™¨äºº`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¿åŠ¨æ§åˆ¶å™¨åœ¨æ„ŸçŸ¥èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ä¸Šå­˜åœ¨ä¸è¶³ï¼Œé™åˆ¶äº†ç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ åœ¨è¿åŠ¨æ§åˆ¶ä¸­çš„åº”ç”¨ã€‚
2. è®ºæ–‡æå‡ºåŸºäºSSD-Mamba2çš„è·¨æ¨¡æ€èåˆæ¡†æ¶ï¼Œåˆ©ç”¨å…¶è¿‘çº¿æ€§ç¼©æ”¾ç‰¹æ€§ï¼Œé«˜æ•ˆèåˆè§†è§‰å’Œæœ¬ä½“æ„Ÿå—ä¿¡æ¯ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§è¿åŠ¨æ§åˆ¶ä»»åŠ¡ä¸­ï¼Œæ˜¾è‘—æå‡äº†å›æŠ¥ã€å®‰å…¨æ€§å’Œæ ·æœ¬æ•ˆç‡ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºSSD-Mamba2çš„è§†è§‰é©±åŠ¨è·¨æ¨¡æ€å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºç«¯åˆ°ç«¯è¿åŠ¨æ§åˆ¶ã€‚ç°æœ‰æ§åˆ¶å™¨è¦ä¹ˆæ˜¯ä»…ä¾èµ–æœ¬ä½“æ„Ÿå—çš„â€œç›²â€æ§åˆ¶å™¨ï¼Œè¦ä¹ˆä¾èµ–äºè®¡ç®—-å†…å­˜æƒè¡¡ä¸ä½³çš„èåˆéª¨å¹²ç½‘ç»œã€‚å¾ªç¯æ§åˆ¶å™¨éš¾ä»¥å¤„ç†é•¿æ—¶ç¨‹ä¿¡ç”¨åˆ†é…ï¼Œè€ŒåŸºäºTransformerçš„èåˆåœ¨tokené•¿åº¦ä¸Šäº§ç”ŸäºŒæ¬¡æ–¹æˆæœ¬ï¼Œé™åˆ¶äº†æ—¶é—´å’Œç©ºé—´ä¸Šä¸‹æ–‡ã€‚è¯¥æ¡†æ¶åˆ©ç”¨SSD-Mamba2ï¼Œä¸€ç§é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´éª¨å¹²ç½‘ç»œï¼Œå®ƒåº”ç”¨çŠ¶æ€ç©ºé—´å¯¹å¶æ€§(SSD)ï¼Œä»¥å®ç°å…·æœ‰ç¡¬ä»¶æ„ŸçŸ¥æµå’Œè¿‘çº¿æ€§ç¼©æ”¾çš„å¾ªç¯å’Œå·ç§¯æ‰«æã€‚æœ¬ä½“æ„Ÿå—çŠ¶æ€å’Œå¤–éƒ¨æ„Ÿå—è§‚æµ‹(å¦‚æ·±åº¦token)è¢«ç¼–ç æˆç´§å‡‘çš„tokenï¼Œå¹¶é€šè¿‡å †å çš„SSD-Mamba2å±‚èåˆã€‚é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ›´æ–°ä¿ç•™äº†é•¿ç¨‹ä¾èµ–å…³ç³»ï¼Œä¸äºŒæ¬¡è‡ªæ³¨æ„åŠ›ç›¸æ¯”ï¼Œæ˜¾è‘—é™ä½äº†å»¶è¿Ÿå’Œå†…å­˜ä½¿ç”¨ï¼Œä»è€Œå®ç°äº†æ›´é•¿çš„é¢„æµ‹ã€æ›´é«˜çš„tokenåˆ†è¾¨ç‡ä»¥åŠåœ¨æœ‰é™è®¡ç®—ä¸‹ç¨³å®šçš„è®­ç»ƒã€‚ç­–ç•¥åœ¨éšæœºåŒ–åœ°å½¢å’Œå¤–è§‚å¹¶é€æ­¥å¢åŠ åœºæ™¯å¤æ‚æ€§çš„è¯¾ç¨‹ä¸‹è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒã€‚ç´§å‡‘çš„ã€ä»¥çŠ¶æ€ä¸ºä¸­å¿ƒçš„å¥–åŠ±å¹³è¡¡äº†ä»»åŠ¡è¿›åº¦ã€èƒ½æºæ•ˆç‡å’Œå®‰å…¨æ€§ã€‚åœ¨å„ç§è¿åŠ¨æ§åˆ¶åœºæ™¯ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨å›æŠ¥ã€å®‰å…¨æ€§(ç¢°æ’å’Œè·Œå€’)å’Œæ ·æœ¬æ•ˆç‡æ–¹é¢å§‹ç»ˆä¼˜äºå¼ºå¤§çš„æœ€å…ˆè¿›çš„åŸºçº¿ï¼ŒåŒæ—¶åœ¨ç›¸åŒçš„è®¡ç®—é¢„ç®—ä¸‹æ”¶æ•›æ›´å¿«ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒSSD-Mamba2ä¸ºå¯æ‰©å±•ã€æœ‰è¿œè§å’Œé«˜æ•ˆçš„ç«¯åˆ°ç«¯è¿åŠ¨æ§åˆ¶æä¾›äº†ä¸€ä¸ªå®ç”¨çš„èåˆéª¨å¹²ç½‘ç»œã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ç«¯åˆ°ç«¯è¿åŠ¨æ§åˆ¶æ–¹æ³•é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦ä½“ç°åœ¨ï¼š1) ä¼ ç»Ÿæ§åˆ¶å™¨è¦ä¹ˆä¾èµ–æœ‰é™çš„æœ¬ä½“æ„Ÿå—ä¿¡æ¯ï¼Œç¼ºä¹è§†è§‰æ„ŸçŸ¥èƒ½åŠ›ï¼›2) åŸºäºTransformerçš„èåˆæ–¹æ³•è®¡ç®—å¤æ‚åº¦é«˜ï¼Œéš¾ä»¥å¤„ç†é•¿æ—¶ç¨‹ä¾èµ–å…³ç³»ï¼›3) å¾ªç¯æ§åˆ¶å™¨åœ¨é•¿æ—¶ç¨‹ä¿¡ç”¨åˆ†é…æ–¹é¢å­˜åœ¨å›°éš¾ã€‚è¿™äº›é—®é¢˜é™åˆ¶äº†è¿åŠ¨æ§åˆ¶ç­–ç•¥çš„æ³›åŒ–æ€§å’Œæ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨SSD-Mamba2ä½œä¸ºè·¨æ¨¡æ€èåˆçš„éª¨å¹²ç½‘ç»œã€‚SSD-Mamba2é€šè¿‡çŠ¶æ€ç©ºé—´å¯¹å¶æ€§ï¼Œå…¼å…·å¾ªç¯å’Œå·ç§¯çš„ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°å¤„ç†é•¿æ—¶ç¨‹ä¾èµ–å…³ç³»ï¼Œå¹¶å®ç°è¿‘çº¿æ€§çš„è®¡ç®—å¤æ‚åº¦ã€‚é€šè¿‡å°†è§†è§‰å’Œæœ¬ä½“æ„Ÿå—ä¿¡æ¯ç¼–ç ä¸ºç´§å‡‘çš„tokenï¼Œå¹¶åˆ©ç”¨SSD-Mamba2è¿›è¡Œèåˆï¼Œå¯ä»¥æ„å»ºä¸€ä¸ªé«˜æ•ˆä¸”å…·æœ‰è¿œè§çš„è¿åŠ¨æ§åˆ¶ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ„ŸçŸ¥ç¼–ç å™¨ï¼šå°†è§†è§‰ï¼ˆå¦‚æ·±åº¦å›¾åƒï¼‰å’Œæœ¬ä½“æ„Ÿå—ä¿¡æ¯ç¼–ç ä¸ºtokenï¼›2) SSD-Mamba2èåˆå±‚ï¼šå †å å¤šå±‚SSD-Mamba2ï¼Œèåˆä¸åŒæ¨¡æ€çš„tokenï¼Œæå–æ—¶ç©ºç‰¹å¾ï¼›3) ç­–ç•¥ç½‘ç»œï¼šåŸºäºèåˆåçš„ç‰¹å¾ï¼Œè¾“å‡ºåŠ¨ä½œæŒ‡ä»¤ï¼›4) å¥–åŠ±å‡½æ•°ï¼šè®¾è®¡ä»¥çŠ¶æ€ä¸ºä¸­å¿ƒçš„å¥–åŠ±å‡½æ•°ï¼Œå¹³è¡¡ä»»åŠ¡è¿›åº¦ã€èƒ½æºæ•ˆç‡å’Œå®‰å…¨æ€§ã€‚æ•´ä¸ªæ¡†æ¶é‡‡ç”¨ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†SSD-Mamba2åº”ç”¨äºè·¨æ¨¡æ€å¼ºåŒ–å­¦ä¹ çš„è¿åŠ¨æ§åˆ¶ä»»åŠ¡ã€‚ä¸ä¼ ç»Ÿçš„Transformerç›¸æ¯”ï¼ŒSSD-Mamba2å…·æœ‰è¿‘çº¿æ€§çš„è®¡ç®—å¤æ‚åº¦ï¼Œèƒ½å¤Ÿå¤„ç†æ›´é•¿çš„åºåˆ—ï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰é•¿æ—¶ç¨‹ä¾èµ–å…³ç³»ã€‚æ­¤å¤–ï¼ŒSSD-Mamba2çš„é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ›´æ–°æœºåˆ¶ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°ä¿ç•™å…³é”®ä¿¡æ¯ï¼Œæé«˜ç­–ç•¥çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­ä¸€äº›å…³é”®çš„è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨æ·±åº¦å›¾åƒä½œä¸ºè§†è§‰è¾“å…¥ï¼Œæä¾›ä¸°å¯Œçš„ç¯å¢ƒä¿¡æ¯ï¼›2) è®¾è®¡ç´§å‡‘çš„tokenç¼–ç æ–¹å¼ï¼Œé™ä½è®¡ç®—è´Ÿæ‹…ï¼›3) é‡‡ç”¨è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œé€æ­¥å¢åŠ åœºæ™¯çš„å¤æ‚æ€§ï¼Œæé«˜ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›ï¼›4) è®¾è®¡ä»¥çŠ¶æ€ä¸ºä¸­å¿ƒçš„å¥–åŠ±å‡½æ•°ï¼Œé¼“åŠ±ç­–ç•¥åœ¨å®Œæˆä»»åŠ¡çš„åŒæ—¶ï¼Œä¿æŒå®‰å…¨å’ŒèŠ‚èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºSSD-Mamba2çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶åœ¨å¤šç§è¿åŠ¨æ§åˆ¶ä»»åŠ¡ä¸­ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨åœ°å½¢éšæœºåŒ–çš„ç¯å¢ƒä¸­ï¼Œè¯¥æ–¹æ³•åœ¨å›æŠ¥æ–¹é¢æå‡äº†20%ä»¥ä¸Šï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†ç¢°æ’å’Œè·Œå€’çš„æ¬¡æ•°ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨ç›¸åŒçš„è®¡ç®—é¢„ç®—ä¸‹ï¼Œæ”¶æ•›é€Ÿåº¦æ›´å¿«ï¼Œæ ·æœ¬æ•ˆç‡æ›´é«˜ï¼Œè¡¨æ˜SSD-Mamba2åœ¨ç«¯åˆ°ç«¯è¿åŠ¨æ§åˆ¶ä¸­å…·æœ‰å·¨å¤§çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€æ— äººæœºæ§åˆ¶ç­‰é¢†åŸŸã€‚é€šè¿‡èåˆè§†è§‰å’Œæœ¬ä½“æ„Ÿå—ä¿¡æ¯ï¼Œå¯ä»¥æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œé²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•çš„é«˜æ•ˆè®¡ç®—ç‰¹æ€§ä½¿å…¶æœ‰æœ›åœ¨èµ„æºå—é™çš„å¹³å°ä¸Šéƒ¨ç½²ï¼Œä¾‹å¦‚ç§»åŠ¨æœºå™¨äººå’ŒåµŒå…¥å¼ç³»ç»Ÿã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å¤šæ™ºèƒ½ä½“åä½œå’Œäººæœºäº¤äº’ç­‰æ›´å¤æ‚çš„åœºæ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> End-to-end reinforcement learning for motion control promises unified perception-action policies that scale across embodiments and tasks, yet most deployed controllers are either blind (proprioception-only) or rely on fusion backbones with unfavorable compute-memory trade-offs. Recurrent controllers struggle with long-horizon credit assignment, and Transformer-based fusion incurs quadratic cost in token length, limiting temporal and spatial context. We present a vision-driven cross-modal RL framework built on SSD-Mamba2, a selective state-space backbone that applies state-space duality (SSD) to enable both recurrent and convolutional scanning with hardware-aware streaming and near-linear scaling. Proprioceptive states and exteroceptive observations (e.g., depth tokens) are encoded into compact tokens and fused by stacked SSD-Mamba2 layers. The selective state-space updates retain long-range dependencies with markedly lower latency and memory use than quadratic self-attention, enabling longer look-ahead, higher token resolution, and stable training under limited compute. Policies are trained end-to-end under curricula that randomize terrain and appearance and progressively increase scene complexity. A compact, state-centric reward balances task progress, energy efficiency, and safety. Across diverse motion-control scenarios, our approach consistently surpasses strong state-of-the-art baselines in return, safety (collisions and falls), and sample efficiency, while converging faster at the same compute budget. These results suggest that SSD-Mamba2 provides a practical fusion backbone for scalable, foresightful, and efficient end-to-end motion control.

