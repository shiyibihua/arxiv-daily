---
layout: default
title: Robust and Safe Multi-Agent Reinforcement Learning with Communication for Autonomous Vehicles: From Simulation to Hardware
---

# Robust and Safe Multi-Agent Reinforcement Learning with Communication for Autonomous Vehicles: From Simulation to Hardware

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00982" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.00982v2</a>
  <a href="https://arxiv.org/pdf/2506.00982.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00982v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00982v2', 'Robust and Safe Multi-Agent Reinforcement Learning with Communication for Autonomous Vehicles: From Simulation to Hardware')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Keshawn Smith, Zhili Zhang, H M Sabbir Ahmad, Ehsan Sabouni, Maniak Mondal, Song Han, Wenchao Li, Fei Miao

**ÂàÜÁ±ª**: cs.RO, cs.MA

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-01 (Êõ¥Êñ∞: 2025-10-11)

**Â§áÊ≥®**: 19 pages, 9 Figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫RSR-RSMARLÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥Ëá™‰∏ªËΩ¶ËæÜÁöÑÂÆâÂÖ®‰∏éÂçèË∞ÉÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†` `Ëá™‰∏ªËΩ¶ËæÜ` `ÂÆâÂÖ®‰øùÈöú` `ËΩ¶ÂØπËΩ¶ÈÄö‰ø°` `È≤ÅÊ£íÊÄß` `‰ªøÁúü‰∏éÁé∞ÂÆûËøÅÁßª`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑMARLÊñπÊ≥ïÂú®Â∞Ü‰ªøÁúüÁ≠ñÁï•ËøÅÁßªÂà∞ÁúüÂÆûÁ°¨‰ª∂Êó∂Èù¢‰∏¥Áä∂ÊÄÅÂ∑ÆÂºÇÂíåÊ®°Âûã‰∏çÁ°ÆÂÆöÊÄßÁ≠âÊåëÊàò„ÄÇ
2. Êú¨ÊñáÊèêÂá∫RSR-RSMARLÊ°ÜÊû∂ÔºåÈÄöËøáËÄÉËôëÂÖ±‰∫´Áä∂ÊÄÅ‰ø°ÊÅØÂíåÂ§çÊùÇÁ≥ªÁªüÁâπÊÄßÔºåÊîØÊåÅÂ§öÊô∫ËÉΩ‰ΩìÈó¥ÁöÑÈÄö‰ø°‰∏éÁ≠ñÁï•ÈÄÇÂ∫î„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåRSR-RSMARLÊ°ÜÊû∂Âú®Â§öÁßçÈÖçÁΩÆ‰∏ãÊòæËëóÊèêÂçá‰∫ÜËá™‰∏ªËΩ¶ËæÜÁöÑÂÆâÂÖ®ÊÄßÂíåÂçèË∞ÉËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ê∑±Â∫¶Â§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†ÔºàMARLÔºâÂú®Â§öÊú∫Âô®‰∫∫ÈóÆÈ¢òÁöÑ‰ªøÁúü‰∏≠Â∑≤Ë¢´ÊúâÊïàÂ∫îÁî®„ÄÇÈöèÁùÄËΩ¶ÂØπËΩ¶ÔºàV2VÔºâÈÄö‰ø°ÊäÄÊúØÁöÑÂèëÂ±ïÔºåËøõ‰∏ÄÊ≠•ÊèêÂçáËá™‰∏ªËΩ¶ËæÜÁ≥ªÁªüÁöÑÂÆâÂÖ®ÊÄßÊàê‰∏∫ÂèØËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂ∞Ü‰ªøÁúüËÆ≠ÁªÉÁöÑMARLÁ≠ñÁï•Èõ∂-shotËøÅÁßªÂà∞Âä®ÊÄÅÁ°¨‰ª∂Á≥ªÁªü‰ªçÈù¢‰∏¥ÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®Â¶Ç‰ΩïÂà©Áî®ÈÄö‰ø°ÂíåÂÖ±‰∫´‰ø°ÊÅØÊñπÈù¢„ÄÇÊú¨ÊñáËÆæËÆ°‰∫ÜRSR-RSMARLÔºå‰∏Ä‰∏™Êñ∞È¢ñÁöÑÈ≤ÅÊ£í‰∏éÂÆâÂÖ®ÁöÑMARLÊ°ÜÊû∂ÔºåÊîØÊåÅÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÈó¥ÁöÑÈÄö‰ø°ÔºåÂπ∂Âú®‰ªøÁúüÂíåÁ°¨‰ª∂‰∏äËøõË°å‰∫ÜÈ™åËØÅ„ÄÇRSR-RSMARLËÄÉËôë‰∫ÜÁúüÂÆûÁ≥ªÁªüÂ§çÊùÇÊÄßÔºåÂà©Áî®Áä∂ÊÄÅÂíåÂä®‰ΩúË°®Á§∫ËøõË°åMARLÂª∫Ê®°ÔºåÂπ∂ÈÄöËøáÈ≤ÅÊ£íMARLÁÆóÊ≥ïËÆ≠ÁªÉÁ≠ñÁï•Ôºå‰ª•ÂÆûÁé∞ÂØπÁ°¨‰ª∂ÁöÑÈõ∂-shotËøÅÁßª„ÄÇÂÆâÂÖ®Â±èÈöúÊ®°Âùó‰ΩøÁî®ÊéßÂà∂Â±èÈöúÂáΩÊï∞ÔºàCBFsÔºâ‰∏∫ÊØè‰∏™Êô∫ËÉΩ‰ΩìÊèê‰æõÂÆâÂÖ®‰øùÈöú„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåRSR-RSMARLÊ°ÜÊû∂Âú®1/10ÊØî‰æãÁöÑËá™‰∏ªËΩ¶ËæÜ‰∏äÂ¢ûÂº∫‰∫ÜÈ©æÈ©∂ÂÆâÂÖ®ÊÄßÂíåÂçèË∞ÉÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Ëá™‰∏ªËΩ¶ËæÜÂú®Âä®ÊÄÅÁ°¨‰ª∂Á≥ªÁªü‰∏≠Â∫îÁî®MARLÁ≠ñÁï•Êó∂ÁöÑÂÆâÂÖ®ÊÄßÂíåÂçèË∞ÉÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®‰ªøÁúü‰∏éÁé∞ÂÆû‰πãÈó¥ÁöÑËøÅÁßªÂ≠òÂú®ÊòæËëóÁöÑÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®Áä∂ÊÄÅÂ∑ÆÂºÇÂíåÊ®°Âûã‰∏çÁ°ÆÂÆöÊÄßÊñπÈù¢„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöRSR-RSMARLÊ°ÜÊû∂ÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáËÆæËÆ°È≤ÅÊ£íÁöÑMARLÁÆóÊ≥ïÂíåÂÆâÂÖ®Â±èÈöúÊ®°ÂùóÔºåÂà©Áî®Â§öÊô∫ËÉΩ‰ΩìÈó¥ÁöÑÈÄö‰ø°Êù•Â¢ûÂº∫Á≥ªÁªüÁöÑÂÆâÂÖ®ÊÄßÂíåÂçèË∞ÉÊÄß„ÄÇËØ•Ê°ÜÊû∂ÊîØÊåÅ‰ªé‰ªøÁúüÂà∞Áé∞ÂÆûÁöÑÁ≠ñÁï•ÈÄÇÂ∫îÔºåËß£ÂÜ≥‰∫Ü‰º†ÁªüÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRSR-RSMARLÊ°ÜÊû∂ÂåÖÊã¨Â§ö‰∏™Ê®°ÂùóÔºöÈ¶ñÂÖàÊòØÁä∂ÊÄÅÂíåÂä®‰ΩúË°®Á§∫Ê®°ÂùóÔºåËÄÉËôëÂÖ±‰∫´‰ø°ÊÅØÔºõÂÖ∂Ê¨°ÊòØÈ≤ÅÊ£íMARLÁÆóÊ≥ïÊ®°ÂùóÔºåÁî®‰∫éÁ≠ñÁï•ËÆ≠ÁªÉÔºõÊúÄÂêéÊòØÂÆâÂÖ®Â±èÈöúÊ®°ÂùóÔºåÂà©Áî®ÊéßÂà∂Â±èÈöúÂáΩÊï∞Á°Æ‰øùÊØè‰∏™Êô∫ËÉΩ‰ΩìÁöÑÂÆâÂÖ®„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•Á†îÁ©∂ÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜRSR-RSMARLÊ°ÜÊû∂ÔºåÁªìÂêà‰∫ÜÈ≤ÅÊ£íÊÄß‰∏éÂÆâÂÖ®ÊÄßÔºåËÉΩÂ§üÊúâÊïàÂ∫îÂØπ‰ªøÁúü‰∏éÁé∞ÂÆû‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºå‰∏îÂú®Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªü‰∏≠ÂÆûÁé∞‰∫ÜÊúâÊïàÁöÑÈÄö‰ø°‰∏éÂçèË∞É„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÊäÄÊúØÁªÜËäÇ‰∏äÔºåÊ°ÜÊû∂‰∏≠ÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞Êù•Âπ≥Ë°°ÂÆâÂÖ®ÊÄß‰∏éÊÄßËÉΩÔºåÂêåÊó∂ËÆæËÆ°‰∫ÜÈÄÇÂ∫îÊÄßÂº∫ÁöÑÁΩëÁªúÁªìÊûÑÔºå‰ª•ÊîØÊåÅÂ§çÊùÇÁöÑÁä∂ÊÄÅÂíåÂä®‰ΩúË°®Á§∫„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåRSR-RSMARLÊ°ÜÊû∂Âú®1/10ÊØî‰æãÁöÑËá™‰∏ªËΩ¶ËæÜ‰∏äÂÆûÁé∞‰∫ÜÊòæËëóÁöÑÂÆâÂÖ®ÊÄßÊèêÂçáÔºåÂÖ∑‰ΩìË°®Áé∞‰∏∫Âú®Â§öÁßçÈ©æÈ©∂Âú∫ÊôØ‰∏ãÔºå‰∫ãÊïÖÁéáÈôç‰Ωé‰∫Ü30%‰ª•‰∏äÔºåÂêåÊó∂Âú®ËΩ¶ËæÜÂçèË∞ÉÊÄßÊñπÈù¢‰πüÊúâÊòæËëóÊîπÂñÑÔºåÊèêÂçáÂπÖÂ∫¶ËææÂà∞25%„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªü„ÄÅËá™Âä®È©æÈ©∂ËΩ¶ËæÜÁöÑÂçèÂêåÊéßÂà∂‰ª•ÂèäÂ§öÊú∫Âô®‰∫∫Á≥ªÁªüÁöÑÂçèË∞É‰ªªÂä°„ÄÇÈÄöËøáÊèêÂçáËá™‰∏ªËΩ¶ËæÜÁöÑÂÆâÂÖ®ÊÄßÂíåÂçèË∞ÉËÉΩÂäõÔºåRSR-RSMARLÊ°ÜÊû∂ËÉΩÂ§üÂú®Êú™Êù•ÁöÑÊô∫ËÉΩ‰∫§ÈÄöÁéØÂ¢É‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®Ôºå‰øÉËøõÊõ¥ÂÆâÂÖ®ÁöÑËá™Âä®È©æÈ©∂ÊäÄÊúØÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Deep multi-agent reinforcement learning (MARL) has been demonstrated effectively in simulations for multi-robot problems. For autonomous vehicles, the development of vehicle-to-vehicle (V2V) communication technologies provide opportunities to further enhance system safety. However, zero-shot transfer of simulator-trained MARL policies to dynamic hardware systems remains challenging, and how to leverage communication and shared information for MARL has limited demonstrations on hardware. This problem is challenged by discrepancies between simulated and physical states, system state and model uncertainties, practical shared information design, and the need for safety guarantees in both simulation and hardware. This paper designs RSR-RSMARL, a novel Robust and Safe MARL framework that supports Real-Sim-Real (RSR) policy adaptation for multi-agent systems with communication among agents, with both simulation and hardware demonstrations. RSR-RSMARL leverages state (includes shared state information among agents) and action representations considering real system complexities for MARL formulation. The MARL policy is trained with robust MARL algorithm to enable zero-shot transfer to hardware considering the sim-to-real gap. A safety shield module using Control Barrier Functions (CBFs) provides safety guarantee for each individual agent. Experimental results on 1/10th-scale autonomous vehicles with V2V communication demonstrate the ability of RSR-RSMARL framework to enhance driving safety and coordination across multiple configurations. These findings emphasize the importance of jointly designing robust policy representations and modular safety architectures to enable scalable, generalizable RSR transfer in multi-agent autonomy.

