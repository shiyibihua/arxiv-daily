---
layout: default
title: Humanoid World Models: Open World Foundation Models for Humanoid Robotics
---

# Humanoid World Models: Open World Foundation Models for Humanoid Robotics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.01182" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.01182v2</a>
  <a href="https://arxiv.org/pdf/2506.01182.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.01182v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.01182v2', 'Humanoid World Models: Open World Foundation Models for Humanoid Robotics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Muhammad Qasim Ali, Aditya Sridhar, Shahbuland Matiana, Alex Wong, Mohammad Al-Sharman

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-01 (æ›´æ–°: 2025-07-08)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç±»äººä¸–ç•Œæ¨¡å‹ä»¥è§£å†³ç±»äººæœºå™¨äººåœ¨å¼€æ”¾ä¸–ç•Œä¸­çš„è§„åˆ’é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç±»äººæœºå™¨äºº` `å¼€æ”¾ä¸–ç•Œ` `ä¸–ç•Œæ¨¡å‹` `é•¿è¿œè§„åˆ’` `ç”Ÿæˆæ¨¡å‹` `å‚æ•°å…±äº«` `æ©ç å˜æ¢å™¨` `æµåŒ¹é…`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤æ‚å¼€æ”¾ä¸–ç•Œç¯å¢ƒä¸­ï¼Œç±»äººæœºå™¨äººé¢ä¸´æ¨ç†å’Œè§„åˆ’èƒ½åŠ›ä¸è¶³çš„æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºç±»äººä¸–ç•Œæ¨¡å‹ï¼ˆHWMï¼‰ï¼Œé€šè¿‡é¢„æµ‹æœªæ¥è§†é¢‘æ¥æ”¯æŒç±»äººæœºå™¨äººçš„é•¿è¿œè§„åˆ’å’Œç­–ç•¥å­¦ä¹ ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒHWMåœ¨æ¨¡å‹å¤§å°ä¸Šå‡å°‘äº†33-53%ï¼Œä¸”å¯¹æ€§èƒ½å½±å“å¾®å°ï¼Œé€‚åˆå°å‹å®éªŒå®¤ä½¿ç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç±»äººæœºå™¨äººå› å…¶ç±»äººå½¢æ€ï¼Œç‰¹åˆ«é€‚åˆä¸ä¸ºäººç±»è®¾è®¡çš„ç¯å¢ƒè¿›è¡Œäº¤äº’ã€‚ç„¶è€Œï¼Œä½¿ç±»äººæœºå™¨äººèƒ½å¤Ÿåœ¨å¤æ‚çš„å¼€æ”¾ä¸–ç•Œç¯å¢ƒä¸­è¿›è¡Œæ¨ç†ã€è§„åˆ’å’Œè¡ŒåŠ¨ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ä¸–ç•Œæ¨¡å‹å¯ä»¥é€šè¿‡é¢„æµ‹ç»™å®šåŠ¨ä½œçš„æœªæ¥ç»“æœæ¥æ”¯æŒè¿™äº›èƒ½åŠ›ã€‚æœ¬æ–‡ä»‹ç»äº†ç±»äººä¸–ç•Œæ¨¡å‹ï¼ˆHWMï¼‰ï¼Œè¿™æ˜¯ä¸€ç³»åˆ—è½»é‡çº§çš„å¼€æºæ¨¡å‹ï¼Œèƒ½å¤Ÿé¢„æµ‹åŸºäºç±»äººæ§åˆ¶ä»¤ç‰Œçš„æœªæ¥è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘ã€‚æˆ‘ä»¬åœ¨100å°æ—¶çš„ç±»äººæ¼”ç¤ºä¸Šè®­ç»ƒäº†ä¸¤ç§ç”Ÿæˆæ¨¡å‹ï¼šæ©ç å˜æ¢å™¨å’ŒæµåŒ¹é…ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ¢ç´¢äº†ä¸åŒæ³¨æ„åŠ›æœºåˆ¶å’Œå‚æ•°å…±äº«ç­–ç•¥çš„æ¶æ„å˜ä½“ã€‚æˆ‘ä»¬çš„å‚æ•°å…±äº«æŠ€æœ¯å°†æ¨¡å‹å¤§å°å‡å°‘äº†33-53%ï¼Œå¯¹æ€§èƒ½æˆ–è§†è§‰ä¿çœŸåº¦çš„å½±å“æœ€å°ã€‚HWMæ—¨åœ¨èƒ½å¤Ÿåœ¨å®é™…çš„å­¦æœ¯å’Œå°å‹å®éªŒå®¤ç¯å¢ƒä¸­è¿›è¡Œè®­ç»ƒå’Œéƒ¨ç½²ï¼Œä¾‹å¦‚ä½¿ç”¨1-2ä¸ªGPUã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç±»äººæœºå™¨äººåœ¨å¼€æ”¾ä¸–ç•Œä¸­è¿›è¡Œæœ‰æ•ˆæ¨ç†å’Œè§„åˆ’çš„èƒ½åŠ›ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚åŠ¨æ€ç¯å¢ƒæ—¶å­˜åœ¨å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºç±»äººä¸–ç•Œæ¨¡å‹ï¼ˆHWMï¼‰ï¼Œé€šè¿‡ç”Ÿæˆæœªæ¥è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘æ¥æ”¯æŒé•¿è¿œè§„åˆ’å’Œç­–ç•¥å­¦ä¹ ï¼Œåˆ©ç”¨è½»é‡çº§çš„æ¨¡å‹è®¾è®¡ä»¥é€‚åº”å°å‹å®éªŒå®¤çš„è®¡ç®—èµ„æºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHWMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæ©ç å˜æ¢å™¨å’ŒæµåŒ¹é…æ¨¡å‹ï¼ŒäºŒè€…å‡åœ¨100å°æ—¶çš„ç±»äººæ¼”ç¤ºæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ¨¡å‹é€šè¿‡æ§åˆ¶ä»¤ç‰Œç”Ÿæˆæœªæ¥è§†é¢‘ã€‚

**å…³é”®åˆ›æ–°**ï¼šHWMçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è½»é‡çº§è®¾è®¡å’Œå‚æ•°å…±äº«ç­–ç•¥ï¼Œä½¿å¾—æ¨¡å‹åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶æ˜¾è‘—å‡å°‘äº†æ¨¡å‹å¤§å°ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´é«˜çš„è®¡ç®—æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ä¸åŒçš„æ³¨æ„åŠ›æœºåˆ¶å’Œå‚æ•°å…±äº«ç­–ç•¥ï¼Œç¡®ä¿åœ¨å‡å°‘æ¨¡å‹å¤§å°çš„åŒæ—¶ï¼Œä¿æŒè§†è§‰ä¿çœŸåº¦å’Œæ€§èƒ½çš„ç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHWMåœ¨æ¨¡å‹å¤§å°ä¸Šå‡å°‘äº†33-53%ï¼Œè€Œæ€§èƒ½å’Œè§†è§‰ä¿çœŸåº¦å‡ ä¹æœªå—å½±å“ã€‚è¿™ä¸€æˆæœè¡¨æ˜ï¼ŒHWMåœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­ä»èƒ½æœ‰æ•ˆæ”¯æŒç±»äººæœºå™¨äººçš„é•¿è¿œè§„åˆ’å’Œç­–ç•¥å­¦ä¹ ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€æœåŠ¡æœºå™¨äººå’Œäººæœºäº¤äº’ç­‰åœºæ™¯ã€‚é€šè¿‡æå‡ç±»äººæœºå™¨äººåœ¨å¼€æ”¾ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ï¼ŒHWMèƒ½å¤Ÿä¸ºæœªæ¥çš„æœºå™¨äººåº”ç”¨æä¾›æ›´ä¸ºçµæ´»å’Œé«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Humanoid robots, with their human-like form, are uniquely suited for interacting in environments built for people. However, enabling humanoids to reason, plan, and act in complex open-world settings remains a challenge. World models, models that predict the future outcome of a given action, can support these capabilities by serving as a dynamics model in long-horizon planning and generating synthetic data for policy learning. We introduce Humanoid World Models (HWM), a family of lightweight, open-source models that forecast future egocentric video conditioned on humanoid control tokens. We train two types of generative models, Masked Transformers and Flow-Matching, on 100 hours of humanoid demonstrations. Additionally, we explore architectural variants with different attention mechanisms and parameter-sharing strategies. Our parameter-sharing techniques reduce model size by 33-53% with minimal impact on performance or visual fidelity. HWMs are designed to be trained and deployed in practical academic and small-lab settings, such as 1-2 GPUs.

