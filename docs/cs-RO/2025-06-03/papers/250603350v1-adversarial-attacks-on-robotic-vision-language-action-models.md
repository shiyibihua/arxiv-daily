---
layout: default
title: Adversarial Attacks on Robotic Vision Language Action Models
---

# Adversarial Attacks on Robotic Vision Language Action Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.03350" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.03350v1</a>
  <a href="https://arxiv.org/pdf/2506.03350.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.03350v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.03350v1', 'Adversarial Attacks on Robotic Vision Language Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Eliot Krzysztof Jones, Alexander Robey, Andy Zou, Zachary Ravichandran, George J. Pappas, Hamed Hassani, Matt Fredrikson, J. Zico Kolter

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-03

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/eliotjones1/robogcg)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯¹æŠ—æ”»å‡»æ–¹æ³•ä»¥è§£å†³æœºå™¨äººè§†è§‰è¯­è¨€è¡ŒåŠ¨æ¨¡å‹çš„è„†å¼±æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹æŠ—æ”»å‡»` `è§†è§‰è¯­è¨€æ¨¡å‹` `æœºå™¨äººæ§åˆ¶` `å¤šæ¨¡æ€èåˆ` `å®‰å…¨æ€§ç ”ç©¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰è¯­è¨€è¡ŒåŠ¨æ¨¡å‹åœ¨é¢å¯¹å¯¹æŠ—æ€§æ”»å‡»æ—¶å­˜åœ¨æ˜¾è‘—è„†å¼±æ€§ï¼Œå¯èƒ½å¯¼è‡´æœºå™¨äººæ§åˆ¶å¤±æ•ˆã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å°†å¤§å‹è¯­è¨€æ¨¡å‹çš„è¶Šç‹±æ”»å‡»é€‚é…åˆ°VLAçš„æ–¹æ³•ï¼Œæ—¨åœ¨è·å–å¯¹VLAçš„å®Œå…¨æ§åˆ¶æƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ–‡æœ¬æ”»å‡»èƒ½å¤Ÿæœ‰æ•ˆè¦†ç›–VLAçš„åŠ¨ä½œç©ºé—´ï¼Œå¹¶åœ¨è¾ƒé•¿æ—¶é—´å†…ä¿æŒæ”»å‡»æ•ˆæœï¼Œæ˜¾ç¤ºå‡ºå…¶æ½œåœ¨é£é™©ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¯­è¨€è¡ŒåŠ¨æ¨¡å‹ï¼ˆVLAï¼‰çš„å‡ºç°æ­£åœ¨é‡å¡‘æœºå™¨äººé¢†åŸŸï¼Œä½¿å¾—å¤šæ¨¡æ€ä¼ æ„Ÿå™¨è¾“å…¥çš„èåˆæˆä¸ºå¯èƒ½ã€‚ç„¶è€Œï¼ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„VLAåœ¨é¢å¯¹å¯¹æŠ—æ€§æ”»å‡»æ—¶è¡¨ç°å‡ºè„†å¼±æ€§ã€‚æœ¬æ–‡é¦–æ¬¡ç ”ç©¶äº†é’ˆå¯¹VLAæ§åˆ¶æœºå™¨äººçš„å¯¹æŠ—æ”»å‡»ï¼Œæå‡ºäº†ä¸€ç§å°†LLMè¶Šç‹±æ”»å‡»é€‚åº”å¹¶åº”ç”¨äºVLAçš„æ–¹æ³•ã€‚ç ”ç©¶å‘ç°ï¼Œæ–‡æœ¬æ”»å‡»åœ¨æ‰§è¡ŒåˆæœŸæ–½åŠ åï¼Œå¯ä»¥å®ç°å¯¹å¸¸ç”¨VLAçš„å®Œæ•´åŠ¨ä½œç©ºé—´çš„è®¿é—®ï¼Œå¹¶ä¸”è¿™ç§æ”»å‡»æ•ˆæœåœ¨è¾ƒé•¿æ—¶é—´å†…æŒç»­å­˜åœ¨ã€‚æ‰€æœ‰ä»£ç å·²åœ¨GitHubä¸Šå…¬å¼€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€è¡ŒåŠ¨æ¨¡å‹ï¼ˆVLAï¼‰åœ¨é¢å¯¹å¯¹æŠ—æ€§æ”»å‡»æ—¶çš„è„†å¼±æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘æœºå™¨äººæ§åˆ¶ä¸­çš„ç‰©ç†é£é™©ï¼Œå¯¼è‡´VLAå¯èƒ½è¢«æ¶æ„åˆ©ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¶Šç‹±æ”»å‡»æ–¹æ³•é€‚é…åˆ°VLAä¸Šï¼Œé€šè¿‡æ–‡æœ¬æ”»å‡»å®ç°å¯¹VLAçš„å®Œå…¨æ§åˆ¶ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æ­ç¤ºVLAåœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåœ¨é£é™©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹VLAçš„æ”»å‡»æ¨¡å‹è®¾è®¡ï¼Œæ”»å‡»æµç¨‹åˆ†ä¸ºæ–‡æœ¬æ”»å‡»çš„æ–½åŠ å’Œåç»­åŠ¨ä½œç©ºé—´çš„è®¿é—®ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ”»å‡»ç”Ÿæˆæ¨¡å—å’ŒåŠ¨ä½œæ‰§è¡Œæ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†LLMè¶Šç‹±æ”»å‡»æ–¹æ³•æˆåŠŸåº”ç”¨äºVLAæ§åˆ¶çš„æœºå™¨äººï¼Œçªç ´äº†ä¼ ç»Ÿæ”»å‡»æ–¹æ³•çš„é™åˆ¶ï¼Œå±•ç¤ºäº†æ”»å‡»ä¸è¯­ä¹‰æ— å…³çš„ç‰¹æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæ”»å‡»æ–‡æœ¬çš„é€‰æ‹©å’Œæ–½åŠ æ—¶æœºè‡³å…³é‡è¦ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡è€ƒè™‘äº†æ”»å‡»çš„æœ‰æ•ˆæ€§å’ŒæŒä¹…æ€§ï¼Œç½‘ç»œç»“æ„åˆ™åŸºäºç°æœ‰çš„VLAæ¶æ„è¿›è¡Œè°ƒæ•´ä»¥é€‚åº”æ”»å‡»éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ–‡æœ¬æ”»å‡»èƒ½å¤Ÿå®ç°å¯¹å¸¸ç”¨VLAçš„å®Œæ•´åŠ¨ä½œç©ºé—´è®¿é—®ï¼Œä¸”æ”»å‡»æ•ˆæœåœ¨è¾ƒé•¿æ—¶é—´å†…æŒç»­å­˜åœ¨ã€‚è¿™ä¸€å‘ç°ä¸ç°æœ‰æ–‡çŒ®ä¸­çš„è¶Šç‹±æ”»å‡»æœ‰æ˜¾è‘—ä¸åŒï¼Œè¡¨æ˜åœ¨å®é™…åº”ç”¨ä¸­æ”»å‡»ä¸å¿…ä¸ä¼¤å®³æ¦‚å¿µè¯­ä¹‰ç›¸å…³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€æ™ºèƒ½å®¶å±…ã€è‡ªåŠ¨é©¾é©¶ç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©å¼€å‘æ›´å®‰å…¨çš„æœºå™¨äººç³»ç»Ÿï¼Œå‡å°‘å¯¹æŠ—æ”»å‡»å¸¦æ¥çš„é£é™©ã€‚æœªæ¥ï¼Œç ”ç©¶æˆæœå¯ç”¨äºæå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The emergence of vision-language-action models (VLAs) for end-to-end control is reshaping the field of robotics by enabling the fusion of multimodal sensory inputs at the billion-parameter scale. The capabilities of VLAs stem primarily from their architectures, which are often based on frontier large language models (LLMs). However, LLMs are known to be susceptible to adversarial misuse, and given the significant physical risks inherent to robotics, questions remain regarding the extent to which VLAs inherit these vulnerabilities. Motivated by these concerns, in this work we initiate the study of adversarial attacks on VLA-controlled robots. Our main algorithmic contribution is the adaptation and application of LLM jailbreaking attacks to obtain complete control authority over VLAs. We find that textual attacks, which are applied once at the beginning of a rollout, facilitate full reachability of the action space of commonly used VLAs and often persist over longer horizons. This differs significantly from LLM jailbreaking literature, as attacks in the real world do not have to be semantically linked to notions of harm. We make all code available at https://github.com/eliotjones1/robogcg .

