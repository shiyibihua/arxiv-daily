---
layout: default
title: Solving the Pod Repositioning Problem with Deep Reinforced Adaptive Large Neighborhood Search
---

# Solving the Pod Repositioning Problem with Deep Reinforced Adaptive Large Neighborhood Search

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.02746" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.02746v1</a>
  <a href="https://arxiv.org/pdf/2506.02746.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.02746v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.02746v1', 'Solving the Pod Repositioning Problem with Deep Reinforced Adaptive Large Neighborhood Search')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lin Xie, Hanyi Li

**åˆ†ç±»**: cs.RO, cs.AI, math.OC

**å‘å¸ƒæ—¥æœŸ**: 2025-06-03

**å¤‡æ³¨**: 14 pages, 2 figures, conference

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸è‡ªé€‚åº”å¤§é‚»åŸŸæœç´¢ç»“åˆçš„æ–¹æ³•è§£å†³Podé‡å®šä½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `è‡ªé€‚åº”å¤§é‚»åŸŸæœç´¢` `Podé‡å®šä½` `æœºå™¨äººç³»ç»Ÿ` `ç»„åˆä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. Podé‡å®šä½é—®é¢˜åœ¨ç°æœ‰æ–¹æ³•ä¸­é¢ä¸´æ•ˆç‡ä½ä¸‹å’Œé€‚åº”æ€§ä¸è¶³çš„æŒ‘æˆ˜ï¼Œå½±å“ä»“åº“ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½ã€‚
2. æœ¬æ–‡æå‡ºå°†æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸è‡ªé€‚åº”å¤§é‚»åŸŸæœç´¢ç›¸ç»“åˆï¼ŒåŠ¨æ€é€‰æ‹©æ“ä½œç¬¦å¹¶è°ƒæ•´å…³é”®å‚æ•°ï¼Œä»¥æé«˜æœç´¢æ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨è§£å†³Podé‡å®šä½é—®é¢˜ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæå‡äº†æ–¹æ¡ˆè´¨é‡å’Œé€‚åº”æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Podé‡å®šä½é—®é¢˜ï¼ˆPRPï¼‰åœ¨æœºå™¨äººç§»åŠ¨å±¥è¡Œç³»ç»Ÿä¸­æ¶‰åŠé€‰æ‹©æœ€ä½³å­˜å‚¨ä½ç½®ï¼Œä»¥ä¾¿ä»æ‹£è´§ç«™è¿”å›çš„Podèƒ½å¤Ÿé«˜æ•ˆå­˜æ”¾ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›çš„è§£å†³æ–¹æ³•ï¼Œå°†è‡ªé€‚åº”å¤§é‚»åŸŸæœç´¢ï¼ˆALNSï¼‰ä¸æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰ç›¸ç»“åˆã€‚DRLä»£ç†åŠ¨æ€é€‰æ‹©é”€æ¯å’Œä¿®å¤æ“ä½œç¬¦ï¼Œå¹¶åœ¨æœç´¢è¿‡ç¨‹ä¸­è°ƒæ•´å…³é”®å‚æ•°ï¼Œå¦‚é”€æ¯ç¨‹åº¦å’Œæ¥å—é˜ˆå€¼ã€‚ä¸ºè¿™ä¸¤ç§æ“ä½œç¬¦è®¾è®¡äº†ä¸“é—¨çš„å¯å‘å¼ç®—æ³•ï¼Œä»¥åæ˜ PRPç‰¹æœ‰çš„ç‰¹å¾ï¼ŒåŒ…æ‹¬Podä½¿ç”¨é¢‘ç‡å’Œç§»åŠ¨æˆæœ¬ã€‚è®¡ç®—ç»“æœè¡¨æ˜ï¼ŒåŸºäºDRLçš„ALNSæ–¹æ³•ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå¦‚æœ€ä¾¿å®œä½ç½®ã€å›ºå®šä½ç½®ã€äºŒè¿›åˆ¶æ•´æ•°è§„åˆ’å’Œé™æ€å¯å‘å¼ç®—æ³•ï¼Œå±•ç¤ºäº†å­¦ä¹ é©±åŠ¨æ§åˆ¶åœ¨ä»“åº“ç³»ç»Ÿç»„åˆä¼˜åŒ–ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡èšç„¦äºPodé‡å®šä½é—®é¢˜ï¼ˆPRPï¼‰ï¼Œç°æœ‰æ–¹æ³•å¦‚é™æ€å¯å‘å¼å’ŒäºŒè¿›åˆ¶æ•´æ•°è§„åˆ’åœ¨åŠ¨æ€ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œé€‚åº”æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç»“åˆæ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸è‡ªé€‚åº”å¤§é‚»åŸŸæœç´¢ï¼ŒåŠ¨æ€é€‰æ‹©é”€æ¯å’Œä¿®å¤æ“ä½œç¬¦ï¼Œå®æ—¶è°ƒæ•´æœç´¢å‚æ•°ï¼Œä»¥é€‚åº”PRPçš„ç‰¹å®šéœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬DRLä»£ç†ã€æ“ä½œç¬¦é€‰æ‹©æ¨¡å—å’Œå‚æ•°è°ƒæ•´æ¨¡å—ã€‚DRLä»£ç†è´Ÿè´£æ ¹æ®ç¯å¢ƒåé¦ˆé€‰æ‹©æœ€ä¼˜æ“ä½œï¼Œæ“ä½œç¬¦æ¨¡å—æ‰§è¡Œå…·ä½“çš„é”€æ¯å’Œä¿®å¤æ“ä½œï¼Œå‚æ•°è°ƒæ•´æ¨¡å—åˆ™ä¼˜åŒ–æœç´¢è¿‡ç¨‹ä¸­çš„å…³é”®å‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†æ·±åº¦å¼ºåŒ–å­¦ä¹ å¼•å…¥åˆ°ç»„åˆä¼˜åŒ–ä¸­ï¼Œä½¿å¾—æœç´¢è¿‡ç¨‹èƒ½å¤Ÿè‡ªé€‚åº”åœ°é€‰æ‹©æ“ä½œç¬¦å’Œè°ƒæ•´å‚æ•°ï¼Œæ˜¾è‘—æé«˜äº†æœç´¢æ•ˆç‡å’Œè§£çš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šè®¾è®¡äº†ä¸“é—¨çš„å¯å‘å¼ç®—æ³•æ¥å¤„ç†é”€æ¯å’Œä¿®å¤æ“ä½œï¼Œè€ƒè™‘äº†Podçš„ä½¿ç”¨é¢‘ç‡å’Œç§»åŠ¨æˆæœ¬ç­‰å› ç´ ï¼Œç¡®ä¿ç®—æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„DRLå¼•å¯¼çš„ALNSæ–¹æ³•åœ¨è§£å†³Podé‡å®šä½é—®é¢˜æ—¶ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¼ºå¤§æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æœºå™¨äººç§»åŠ¨å±¥è¡Œç³»ç»Ÿä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆä¼˜åŒ–ä»“åº“ç®¡ç†å’Œç‰©æµè°ƒåº¦ï¼Œæé«˜å­˜å‚¨æ•ˆç‡å’Œé™ä½è¿è¥æˆæœ¬ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯æ‰©å±•è‡³å…¶ä»–ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œå¦‚äº¤é€šè°ƒåº¦å’Œèµ„æºåˆ†é…ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The Pod Repositioning Problem (PRP) in Robotic Mobile Fulfillment Systems (RMFS) involves selecting optimal storage locations for pods returning from pick stations. This work presents an improved solution method that integrates Adaptive Large Neighborhood Search (ALNS) with Deep Reinforcement Learning (DRL). A DRL agent dynamically selects destroy and repair operators and adjusts key parameters such as destruction degree and acceptance thresholds during the search. Specialized heuristics for both operators are designed to reflect PRP-specific characteristics, including pod usage frequency and movement costs. Computational results show that this DRL-guided ALNS outperforms traditional approaches such as cheapest-place, fixed-place, binary integer programming, and static heuristics. The method demonstrates strong solution quality and illustrating the benefit of learning-driven control within combinatorial optimization for warehouse systems.

