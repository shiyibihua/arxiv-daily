---
layout: default
title: Tactile MNIST: Benchmarking Active Tactile Perception
---

# Tactile MNIST: Benchmarking Active Tactile Perception

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.06361" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.06361v2</a>
  <a href="https://arxiv.org/pdf/2506.06361.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.06361v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.06361v2', 'Tactile MNIST: Benchmarking Active Tactile Perception')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Tim Schneider, Guillaume Duret, Cristiana de Farias, Roberto Calandra, Liming Chen, Jan Peters

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-03 (Êõ¥Êñ∞: 2025-06-14)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Tactile MNISTÂü∫ÂáÜ‰ª•Ëß£ÂÜ≥‰∏ªÂä®Ëß¶ËßâÊÑüÁü•Ê†áÂáÜÂåñÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `Ëß¶ËßâÊÑüÁü•` `‰∏ªÂä®ÊÑüÁü•` `Êú∫Âô®‰∫∫Êìç‰Ωú` `Âü∫ÂáÜÂ•ó‰ª∂` `CycleGAN` `Êï∞ÊçÆÈõÜ` `Ê†áÂáÜÂåñËØÑ‰º∞`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑËß¶ËßâÊÑüÁü•Âíå‰∏ªÂä®ÊÑüÁü•ÊñπÊ≥ïÁº∫‰πèÊ†áÂáÜÂåñÁöÑÂü∫ÂáÜÔºåÈôêÂà∂‰∫ÜÁ†îÁ©∂ÁöÑÁ≥ªÁªüÊÄßÂíåÂèØÈáçÂ§çÊÄß„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫ÜTactile MNISTÂü∫ÂáÜÂ•ó‰ª∂ÔºåÈÄöËøáÊèê‰æõÂ§öÊ†∑ÂåñÁöÑ‰ªªÂä°ÂíåÊï∞ÊçÆÈõÜÔºå‰øÉËøõ‰∏ªÂä®Ëß¶ËßâÊÑüÁü•ÁöÑÁ†îÁ©∂„ÄÇ
3. Âü∫‰∫éÊèê‰æõÁöÑÊï∞ÊçÆÈõÜÔºå‰ΩøÁî®CycleGANËøõË°åÁúüÂÆûËß¶ËßâÊ®°ÊãüÊ∏≤ÊüìÔºåÊé®Âä®‰∫ÜËß¶ËßâÊÑüÁü•ÊäÄÊúØÁöÑËøõÊ≠•„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ëß¶ËßâÊÑüÁü•ÊúâÊΩúÂäõÊòæËëóÂ¢ûÂº∫ÁÅµÂ∑ßÊú∫Âô®‰∫∫Êìç‰ΩúÔºåÈÄöËøáÊèê‰æõ‰∏∞ÂØåÁöÑÂ±ÄÈÉ®‰ø°ÊÅØÊù•Ë°•ÂÖÖÊàñÊõø‰ª£ËßÜËßâÁ≠âÂÖ∂‰ªñÊÑüÁü•ÊñπÂºè„ÄÇÁÑ∂ËÄåÔºåËß¶Ëßâ‰º†ÊÑüÂô®ÁöÑÂ±ÄÈôêÊÄß‰ΩøÂÖ∂Âú®ÈúÄË¶ÅÂπøÊ≥õÁ©∫Èó¥ÊÑèËØÜÊàñÂÖ®Â±ÄÂú∫ÊôØÁêÜËß£ÁöÑ‰ªªÂä°‰∏≠Ë°®Áé∞‰∏ç‰Ω≥„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜTactile MNISTÂü∫ÂáÜÂ•ó‰ª∂ÔºåËøôÊòØ‰∏Ä‰∏™ÂºÄÊ∫ê„ÄÅÂÖºÂÆπGymnasiumÁöÑÂü∫ÂáÜÔºå‰∏ì‰∏∫‰∏ªÂä®Ëß¶ËßâÊÑüÁü•‰ªªÂä°ËÆæËÆ°ÔºåÂåÖÊã¨ÂÆö‰Ωç„ÄÅÂàÜÁ±ªÂíå‰ΩìÁßØ‰º∞ËÆ°„ÄÇËØ•Âü∫ÂáÜÂ•ó‰ª∂Êèê‰æõÂ§öÊ†∑ÂåñÁöÑÊ®°ÊãüÂú∫ÊôØÔºåÂπ∂ÂåÖÂê´13,500‰∏™ÂêàÊàê3D MNISTÊï∞Â≠óÊ®°ÂûãÂíå153,600‰∏™ÁúüÂÆûËß¶ËßâÊ†∑Êú¨ÔºåÊó®Âú®‰øÉËøõËß¶ËßâÊÑüÁü•Âíå‰∏ªÂä®ÊÑüÁü•È¢ÜÂüüÁöÑÁ≥ªÁªüÊÄßËøõÂ±ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Ëß¶ËßâÊÑüÁü•Âíå‰∏ªÂä®ÊÑüÁü•È¢ÜÂüüÁº∫‰πèÊ†áÂáÜÂåñÂü∫ÂáÜÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®‰ªªÂä°ËØÑ‰º∞ÂíåÊØîËæÉ‰∏äÂ≠òÂú®‰∏çË∂≥ÔºåÈôêÂà∂‰∫ÜÊäÄÊúØÁöÑËøõÊ≠•„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÂºïÂÖ•Tactile MNISTÂü∫ÂáÜÂ•ó‰ª∂ÔºåÊèê‰æõ‰∏Ä‰∏™ÂºÄÊîæÁöÑ„ÄÅÂÖºÂÆπGymnasiumÁöÑËØÑ‰º∞Ê°ÜÊû∂Ôºå‰∏ìÊ≥®‰∫é‰∏ªÂä®Ëß¶ËßâÊÑüÁü•‰ªªÂä°ÔºåÂ∏ÆÂä©Á†îÁ©∂ËÄÖÁ≥ªÁªüÊÄßÂú∞ËØÑ‰º∞ÂíåÊØîËæÉ‰∏çÂêåÊñπÊ≥ï„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂ÂåÖÊã¨Â§ö‰∏™Ê®°ÂùóÔºåÊ∂µÁõñ‰ªéÁÆÄÂçïÁöÑÁé©ÂÖ∑ÁéØÂ¢ÉÂà∞Â§çÊùÇÁöÑËß¶ËßâÊÑüÁü•‰ªªÂä°ÔºåÊîØÊåÅÂÆö‰Ωç„ÄÅÂàÜÁ±ªÂíå‰ΩìÁßØ‰º∞ËÆ°Á≠âÂ§öÁßç‰ªªÂä°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÁªºÂêàÊÄßÁöÑÂü∫ÂáÜÂ•ó‰ª∂ÔºåÂåÖÂê´‰∏∞ÂØåÁöÑÂêàÊàêÂíåÁúüÂÆûÊï∞ÊçÆÔºåÂ°´Ë°•‰∫ÜËß¶ËßâÊÑüÁü•È¢ÜÂüüÁöÑÊ†áÂáÜÂåñÁ©∫ÁôΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊï∞ÊçÆÈõÜ‰∏≠ÂåÖÂê´13,500‰∏™ÂêàÊàê3D MNISTÊï∞Â≠óÊ®°ÂûãÂíå153,600‰∏™ÁúüÂÆûËß¶ËßâÊ†∑Êú¨Ôºå‰ΩøÁî®CycleGANËøõË°åÁúüÂÆûÊÑüËß¶ËßâÊ®°ÊãüÊ∏≤ÊüìÔºåÁ°Æ‰øù‰∫ÜÊï∞ÊçÆÁöÑÂ§öÊ†∑ÊÄßÂíåÁúüÂÆûÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰ΩøÁî®Tactile MNISTÂü∫ÂáÜÂ•ó‰ª∂ËøõË°åÁöÑËØÑ‰º∞ËÉΩÂ§üÊòæËëóÊèêÂçáËß¶ËßâÊÑüÁü•ÁÆóÊ≥ïÁöÑÊÄßËÉΩ„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÂü∫‰∫éCycleGANÁöÑËß¶ËßâÊ®°ÊãüÊ∏≤ÊüìÂú®ÁúüÂÆûÊÑüÂíåÂáÜÁ°ÆÊÄß‰∏äÂùáÊúâÊòæËëóÊèêÂçáÔºå‰∏∫ÂêéÁª≠Á†îÁ©∂Êèê‰æõ‰∫ÜÂèØÈù†ÁöÑËØÑ‰º∞Ê†áÂáÜ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êú∫Âô®‰∫∫Êìç‰Ωú„ÄÅÊô∫ËÉΩÂà∂ÈÄ†Âíå‰∫∫Êú∫‰∫§‰∫íÁ≠â„ÄÇÈÄöËøáÊèêÂçáËß¶ËßâÊÑüÁü•ËÉΩÂäõÔºåÊú∫Âô®‰∫∫ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÊìç‰ΩúÂ§çÊùÇÁéØÂ¢ÉÔºåËøõËÄåÊèêÈ´òÂ∑•‰ΩúÊïàÁéáÂíåÂÆâÂÖ®ÊÄß„ÄÇÊú™Êù•ÔºåËØ•Âü∫ÂáÜÂèØËÉΩÊé®Âä®Ëß¶ËßâÊÑüÁü•ÊäÄÊúØÁöÑÂπøÊ≥õÂ∫îÁî®Ôºå‰øÉËøõÊô∫ËÉΩÁ≥ªÁªüÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Tactile perception has the potential to significantly enhance dexterous robotic manipulation by providing rich local information that can complement or substitute for other sensory modalities such as vision. However, because tactile sensing is inherently local, it is not well-suited for tasks that require broad spatial awareness or global scene understanding on its own. A human-inspired strategy to address this issue is to consider active perception techniques instead. That is, to actively guide sensors toward regions with more informative or significant features and integrate such information over time in order to understand a scene or complete a task. Both active perception and different methods for tactile sensing have received significant attention recently. Yet, despite advancements, both fields lack standardized benchmarks. To bridge this gap, we introduce the Tactile MNIST Benchmark Suite, an open-source, Gymnasium-compatible benchmark specifically designed for active tactile perception tasks, including localization, classification, and volume estimation. Our benchmark suite offers diverse simulation scenarios, from simple toy environments all the way to complex tactile perception tasks using vision-based tactile sensors. Furthermore, we also offer a comprehensive dataset comprising 13,500 synthetic 3D MNIST digit models and 153,600 real-world tactile samples collected from 600 3D printed digits. Using this dataset, we train a CycleGAN for realistic tactile simulation rendering. By providing standardized protocols and reproducible evaluation frameworks, our benchmark suite facilitates systematic progress in the fields of tactile sensing and active perception.

