---
layout: default
title: EDEN: Entorhinal Driven Egocentric Navigation Toward Robotic Deployment
---

# EDEN: Entorhinal Driven Egocentric Navigation Toward Robotic Deployment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.03046" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.03046v1</a>
  <a href="https://arxiv.org/pdf/2506.03046.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.03046v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.03046v1', 'EDEN: Entorhinal Driven Egocentric Navigation Toward Robotic Deployment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mikolaj Walczak, Romina Aalishah, Wyatt Mackey, Brittany Story, David L. Boothe, Nicholas Waytowich, Xiaomin Lin, Tinoosh Mohsenin

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-03

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEDENæ¡†æ¶ä»¥è§£å†³æ·±åº¦å¼ºåŒ–å­¦ä¹ å¯¼èˆªçš„è„†å¼±æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `è‡ªä¸»å¯¼èˆª` `ç”Ÿç‰©å¯å‘` `ç½‘æ ¼ç»†èƒ` `æœºå™¨äººæŠ€æœ¯` `è§†è§‰ä¼ æ„Ÿå™¨` `è¿åŠ¨ä¼ æ„Ÿå™¨` `PPOç®—æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨åŠ¨æ€å’Œå¤æ‚ç¯å¢ƒä¸­è¡¨ç°å‡ºè„†å¼±æ€§ï¼Œéš¾ä»¥é€‚åº”å˜åŒ–çš„å¯¼èˆªä»»åŠ¡ã€‚
2. EDENæ¡†æ¶é€šè¿‡ç”Ÿç‰©å¯å‘çš„ç½‘æ ¼ç»†èƒç¼–ç å™¨ï¼Œå°†ä¼ æ„Ÿå™¨æ•°æ®è½¬åŒ–ä¸ºå¯è§£é‡Šçš„ç©ºé—´è¡¨ç¤ºï¼Œç»“åˆå¼ºåŒ–å­¦ä¹ å®ç°è‡ªä¸»å¯¼èˆªã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEDENåœ¨ç®€å•åœºæ™¯ä¸­æˆåŠŸç‡è¾¾åˆ°99%ï¼Œåœ¨å¤æ‚ç¯å¢ƒä¸­è¶…è¿‡94%ï¼Œæ˜¾è‘—ä¼˜äºä½¿ç”¨åŸå§‹çŠ¶æ€è¾“å…¥çš„åŸºçº¿ä»£ç†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ·±åº¦å¼ºåŒ–å­¦ä¹ ä»£ç†é€šå¸¸åœ¨é¢å¯¹å˜åŒ–åœºæ™¯æ—¶è¡¨ç°è„†å¼±ï¼Œè€Œäººç±»åˆ™å±•ç°å‡ºé€‚åº”æ€§å’Œçµæ´»æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†EDENï¼Œä¸€ä¸ªç”Ÿç‰©å¯å‘çš„å¯¼èˆªæ¡†æ¶ï¼Œç»“åˆäº†å­¦ä¹ çš„å†…å—…çš®å±‚ç½‘æ ¼ç»†èƒè¡¨ç¤ºå’Œå¼ºåŒ–å­¦ä¹ ï¼Œä»¥å®ç°è‡ªä¸»å¯¼èˆªã€‚EDENå…è®¸ä»£ç†ä½¿ç”¨è§†è§‰å’Œè¿åŠ¨ä¼ æ„Ÿå™¨æ•°æ®è¿›è¡Œè·¯å¾„ç§¯åˆ†å’ŒåŸºäºå‘é‡çš„å¯¼èˆªã€‚æ ¸å¿ƒæ˜¯ç½‘æ ¼ç»†èƒç¼–ç å™¨ï¼Œå°†è‡ªæˆ‘ä¸­å¿ƒè¿åŠ¨è½¬åŒ–ä¸ºå‘¨æœŸæ€§ç©ºé—´ç¼–ç ï¼Œç”Ÿæˆä½ç»´ä¸”å¯è§£é‡Šçš„ä½ç½®åµŒå…¥ã€‚é€šè¿‡åœ¨MiniWorldå’ŒGazeboæ¨¡æ‹Ÿå™¨ä¸­è¯„ä¼°ï¼ŒEDENåœ¨ç®€å•åœºæ™¯ä¸­å®ç°äº†99%çš„æˆåŠŸç‡ï¼Œåœ¨å¤æ‚å¹³é¢å›¾ä¸­ä¹Ÿè¶…è¿‡94%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ·±åº¦å¼ºåŒ–å­¦ä¹ ä»£ç†åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„è„†å¼±æ€§ï¼Œç°æœ‰æ–¹æ³•å¤šä¾èµ–äºåŸå§‹çŠ¶æ€è¾“å…¥ï¼Œç¼ºä¹æœ‰æ•ˆçš„ç©ºé—´è¡¨ç¤ºèƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEDENæ¡†æ¶é€šè¿‡æ¨¡ä»¿ç”Ÿç‰©å†…å—…çš®å±‚çš„å¯¼èˆªæœºåˆ¶ï¼Œåˆ©ç”¨ç½‘æ ¼ç»†èƒç¼–ç å™¨å°†è¿åŠ¨æ•°æ®è½¬åŒ–ä¸ºå‘¨æœŸæ€§ç©ºé—´ç¼–ç ï¼Œä»è€Œæé«˜å¯¼èˆªçš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEDENçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç½‘æ ¼ç»†èƒç¼–ç å™¨ã€ä¼ æ„Ÿå™¨æ•°æ®å¤„ç†æ¨¡å—å’ŒåŸºäºPPOçš„ç­–ç•¥è®­ç»ƒæ¨¡å—ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•´åˆè§†è§‰å’Œè¿åŠ¨ä¼ æ„Ÿå™¨æ•°æ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šEDENçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†å¯è®­ç»ƒçš„ç½‘æ ¼ç»†èƒç¼–ç å™¨ï¼Œèƒ½å¤Ÿä»è§†è§‰å’Œè¿åŠ¨ä¼ æ„Ÿå™¨æ•°æ®ä¸­ç”Ÿæˆå‘¨æœŸæ€§ç½‘æ ¼çŠ¶æ¨¡å¼ï¼Œæ¨¡æ‹Ÿç”Ÿç‰©ä½“å†…çš„å¯¼èˆªæœºåˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†è½»é‡çº§çš„MiniWorldæ¨¡æ‹Ÿå™¨è¿›è¡Œå¿«é€ŸåŸå‹å¼€å‘ï¼Œå¹¶åœ¨é«˜ä¿çœŸçš„Gazeboæ¨¡æ‹Ÿå™¨ä¸­è¿›è¡ŒçœŸå®ç‰©ç†å’Œæ„ŸçŸ¥å™ªå£°çš„è¯„ä¼°ï¼Œç¡®ä¿äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒEDENåœ¨ç®€å•åœºæ™¯ä¸­å®ç°äº†99%çš„æˆåŠŸç‡ï¼Œåœ¨å¤æ‚çš„å¹³é¢å›¾ä¸­æˆåŠŸç‡è¶…è¿‡94%ï¼Œç›¸è¾ƒäºä½¿ç”¨åŸå§‹çŠ¶æ€è¾“å…¥çš„åŸºçº¿ä»£ç†ï¼Œè¡¨ç°å‡ºæ›´é«˜çš„æ•ˆç‡å’Œå¯é æ€§ï¼Œæ˜¾è‘—æå‡äº†æ­¥è¿›å¯¼èˆªçš„è¡¨ç°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EDENæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªä¸»æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½äº¤é€šç³»ç»Ÿå’Œå¢å¼ºç°å®ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ï¼ŒEDENèƒ½å¤Ÿæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„å®é™…éƒ¨ç½²å’Œåº”ç”¨ï¼Œæå‡äººæœºäº¤äº’çš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deep reinforcement learning agents are often fragile while humans remain adaptive and flexible to varying scenarios. To bridge this gap, we present EDEN, a biologically inspired navigation framework that integrates learned entorhinal-like grid cell representations and reinforcement learning to enable autonomous navigation. Inspired by the mammalian entorhinal-hippocampal system, EDEN allows agents to perform path integration and vector-based navigation using visual and motion sensor data. At the core of EDEN is a grid cell encoder that transforms egocentric motion into periodic spatial codes, producing low-dimensional, interpretable embeddings of position. To generate these activations from raw sensory input, we combine fiducial marker detections in the lightweight MiniWorld simulator and DINO-based visual features in the high-fidelity Gazebo simulator. These spatial representations serve as input to a policy trained with Proximal Policy Optimization (PPO), enabling dynamic, goal-directed navigation. We evaluate EDEN in both MiniWorld, for rapid prototyping, and Gazebo, which offers realistic physics and perception noise. Compared to baseline agents using raw state inputs (e.g., position, velocity) or standard convolutional image encoders, EDEN achieves a 99% success rate, within the simple scenarios, and >94% within complex floorplans with occluded paths with more efficient and reliable step-wise navigation. In addition, as a replacement of ground truth activations, we present a trainable Grid Cell encoder enabling the development of periodic grid-like patterns from vision and motion sensor data, emulating the development of such patterns within biological mammals. This work represents a step toward biologically grounded spatial intelligence in robotics, bridging neural navigation principles with reinforcement learning for scalable deployment.

