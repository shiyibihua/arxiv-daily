---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-12-04
---

# cs.ROï¼ˆ2025-12-04ï¼‰

ğŸ“Š å…± **18** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (15 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (3)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (15 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251204381v1-falcon-actively-decoupled-visuomotor-policies-for-loco-manipulation-.html">FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination</a></td>
  <td>FALCONï¼šåŸºäºåŸºç¡€æ¨¡å‹åè°ƒçš„ä¸»åŠ¨è§£è€¦å¼æ“ä½œ-ç§»åŠ¨æœºå™¨äººç­–ç•¥</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04381v1" onclick="toggleFavorite(this, '2512.04381v1', 'FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251204731v1-bridging-simulation-and-reality-cross-domain-transfer-with-semantic-.html">Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting</a></td>
  <td>æå‡ºè¯­ä¹‰2Dé«˜æ–¯æº…å°„(S2GS)ï¼Œæå‡æœºå™¨äººæ“ä½œä¸­æ¨¡æ‹Ÿåˆ°çœŸå®çš„è·¨åŸŸè¿ç§»èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04731v1" onclick="toggleFavorite(this, '2512.04731v1', 'Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251204884v1-hoi-a-multimodal-dataset-for-force-grounded-cross-view-articulated-m.html">Hoi! -- A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation</a></td>
  <td>Hoi!ï¼šæå‡ºä¸€ä¸ªåŠ›æ„ŸçŸ¥çš„ã€è·¨è§†è§’é“°æ¥æ“ä½œå¤šæ¨¡æ€æ•°æ®é›†ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04884v1" onclick="toggleFavorite(this, '2512.04884v1', 'Hoi! -- A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251205094v2-from-generated-human-videos-to-physically-plausible-robot-trajectori.html">From Generated Human Videos to Physically Plausible Robot Trajectories</a></td>
  <td>GenMimicï¼šåˆ©ç”¨ç”Ÿæˆè§†é¢‘å®ç°äººå½¢æœºå™¨äººé›¶æ ·æœ¬ç‰©ç†å¯è¡Œè½¨è¿¹æ§åˆ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05094v2" onclick="toggleFavorite(this, '2512.05094v2', 'From Generated Human Videos to Physically Plausible Robot Trajectories')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251204813v1-move-a-simple-motion-based-data-collection-paradigm-for-spatial-gene.html">MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation</a></td>
  <td>æå‡ºMOVEä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­çš„æ•°æ®ç¨€ç¼ºé—®é¢˜</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04813v1" onclick="toggleFavorite(this, '2512.04813v1', 'MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251206038v1-closed-loop-robotic-manipulation-of-transparent-substrates-for-self-.html">Closed-Loop Robotic Manipulation of Transparent Substrates for Self-Driving Laboratories using Deep Learning Micro-Error Correction</a></td>
  <td>æå‡ºåŸºäºæ·±åº¦å­¦ä¹ å¾®è¯¯å·®æ ¡æ­£çš„é€æ˜åŸºæ¿é—­ç¯æœºå™¨äººæ“ä½œæ–¹æ³•ï¼Œç”¨äºè‡ªé©±åŠ¨å®éªŒå®¤ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.06038v1" onclick="toggleFavorite(this, '2512.06038v1', 'Closed-Loop Robotic Manipulation of Transparent Substrates for Self-Driving Laboratories using Deep Learning Micro-Error Correction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251204399v1-development-of-a-15-degree-of-freedom-bionic-hand-with-cable-driven-.html">Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation</a></td>
  <td>æå‡ºä¸€ç§15è‡ªç”±åº¦ä»¿ç”Ÿçµå·§æ‰‹ï¼Œé‡‡ç”¨çº¿ç¼†é©±åŠ¨å’Œåˆ†å¸ƒå¼é©±åŠ¨ï¼Œé€‚ç”¨äºæœºå™¨äººæ“ä½œä»»åŠ¡ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04399v1" onclick="toggleFavorite(this, '2512.04399v1', 'Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251204960v1-hybrid-diffusion-models-combining-open-loop-routines-with-visuomotor.html">Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies</a></td>
  <td>Hybrid-Diffusionæ¨¡å‹ï¼šç»“åˆå¼€æ”¾å¾ªç¯ç¨‹åºå’Œè§†è§‰è¿åŠ¨æ‰©æ•£ç­–ç•¥ï¼Œæå‡æ“ä½œç²¾åº¦ä¸é€Ÿåº¦</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04960v1" onclick="toggleFavorite(this, '2512.04960v1', 'Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251205107v1-stare-vla-progressive-stage-aware-reinforcement-for-fine-tuning-visi.html">STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models</a></td>
  <td>æå‡ºSTARE-VLAï¼Œé€šè¿‡é˜¶æ®µæ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ å¾®è°ƒè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼Œæå‡æœºå™¨äººæ“ä½œæ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05107v1" onclick="toggleFavorite(this, '2512.05107v1', 'STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251205211v1-wake-vectoring-for-efficient-morphing-flight.html">Wake Vectoring for Efficient Morphing Flight</a></td>
  <td>æå‡ºè¢«åŠ¨å°¾æµå¯¼å‘æœºåˆ¶ï¼Œæå‡å˜å½¢é£è¡Œå™¨åœ¨å½¢æ€å˜åŒ–æœŸé—´çš„æ¨åŠ›æ•ˆç‡å’Œæ§åˆ¶èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05211v1" onclick="toggleFavorite(this, '2512.05211v1', 'Wake Vectoring for Efficient Morphing Flight')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251204973v1-preliminary-analysis-and-simulation-of-a-compact-variable-stiffness-.html">Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist</a></td>
  <td>æå‡ºä¸€ç§ç´§å‡‘å‹å˜åˆšåº¦è…•éƒ¨ï¼Œé€šè¿‡å†—ä½™å¼¹æ€§é©±åŠ¨å®ç°é«˜ç²¾åº¦ä½ç½®å’Œåˆšåº¦æ§åˆ¶ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04973v1" onclick="toggleFavorite(this, '2512.04973v1', 'Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251204446v1-vision-language-action-models-for-selective-robotic-disassembly-a-ca.html">Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops</a></td>
  <td>é’ˆå¯¹æ¡Œé¢ç”µè„‘å…³é”®éƒ¨ä»¶æ‹†å¸ï¼Œæ¢ç´¢è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„åº”ç”¨æ½œåŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04446v1" onclick="toggleFavorite(this, '2512.04446v1', 'Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251204404v1-bridging-probabilistic-inference-and-behavior-trees-an-interactive-f.html">Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation</a></td>
  <td>æå‡ºäº¤äº’å¼æ¨ç†è¡Œä¸ºæ ‘ï¼Œç”¨äºå¤šæœºå™¨äººè‡ªé€‚åº”ååŒ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04404v1" onclick="toggleFavorite(this, '2512.04404v1', 'Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251205008v1-contact-implicit-modeling-and-simulation-of-a-snake-robot-on-complia.html">Contact-Implicit Modeling and Simulation of a Snake Robot on Compliant and Granular Terrain</a></td>
  <td>é’ˆå¯¹è›‡å½¢æœºå™¨äººåœ¨å¤æ‚åœ°å½¢è¿åŠ¨ï¼Œæå‡ºæ¥è§¦éšå¼å»ºæ¨¡ä¸ä»¿çœŸæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05008v1" onclick="toggleFavorite(this, '2512.05008v1', 'Contact-Implicit Modeling and Simulation of a Snake Robot on Compliant and Granular Terrain')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251205171v1-two-stage-camera-calibration-method-for-multi-camera-systems-using-s.html">Two-Stage Camera Calibration Method for Multi-Camera Systems Using Scene Geometry</a></td>
  <td>æå‡ºä¸€ç§åŸºäºåœºæ™¯å‡ ä½•çš„å¤šç›¸æœºç³»ç»Ÿä¸¤é˜¶æ®µæ ‡å®šæ–¹æ³•ï¼Œæ— éœ€åŒæ­¥è§†é¢‘æµã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05171v1" onclick="toggleFavorite(this, '2512.05171v1', 'Two-Stage Camera Calibration Method for Multi-Camera Systems Using Scene Geometry')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>16</td>
  <td><a href="./papers/251204772v1-tempo-vine-a-multi-temporal-sensor-fusion-dataset-for-localization-a.html">TEMPO-VINE: A Multi-Temporal Sensor Fusion Dataset for Localization and Mapping in Vineyards</a></td>
  <td>TEMPO-VINEï¼šç”¨äºè‘¡è„å›­å®šä½ä¸å»ºå›¾çš„å¤šæ—¶åºä¼ æ„Ÿå™¨èåˆæ•°æ®é›†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04772v1" onclick="toggleFavorite(this, '2512.04772v1', 'TEMPO-VINE: A Multi-Temporal Sensor Fusion Dataset for Localization and Mapping in Vineyards')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251204373v1-vertical-planetary-landing-on-sloped-terrain-using-optical-flow-dive.html">Vertical Planetary Landing on Sloped Terrain Using Optical Flow Divergence Estimates</a></td>
  <td>æå‡ºåŸºäºå…‰æµæ•£åº¦ä¼°è®¡çš„éçº¿æ€§æ§åˆ¶ç­–ç•¥ï¼Œå®ç°æ–œå¡åœ°å½¢ä¸Šçš„å‚ç›´è¡Œæ˜Ÿç€é™†</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.04373v1" onclick="toggleFavorite(this, '2512.04373v1', 'Vertical Planetary Landing on Sloped Terrain Using Optical Flow Divergence Estimates')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251205303v1-seabed-to-sky-mapping-of-maritime-environments-with-a-dual-orthogona.html">Seabed-to-Sky Mapping of Maritime Environments with a Dual Orthogonal SONAR and LiDAR Sensor Suite</a></td>
  <td>æå‡ºä¸€ç§GNSSç‹¬ç«‹çš„æµ·æ´‹ç¯å¢ƒæ˜ å°„ç³»ç»Ÿä»¥è§£å†³ç°æœ‰æ–¹æ³•çš„å±€é™æ€§</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.05303v1" onclick="toggleFavorite(this, '2512.05303v1', 'Seabed-to-Sky Mapping of Maritime Environments with a Dual Orthogonal SONAR and LiDAR Sensor Suite')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)