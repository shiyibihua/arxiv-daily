---
layout: default
title: STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models
---

# STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.05107" target="_blank" class="toolbar-btn">arXiv: 2512.05107v1</a>
    <a href="https://arxiv.org/pdf/2512.05107.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.05107v1" 
            onclick="toggleFavorite(this, '2512.05107v1', 'STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Feng Xu, Guangyao Zhai, Xin Kong, Tingzhong Fu, Daniel F. N. Gordon, Xueli An, Benjamin Busam

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSTARE-VLAï¼Œé€šè¿‡é˜¶æ®µæ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ å¾®è°ƒè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼Œæå‡æœºå™¨äººæ“ä½œæ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `æœºå™¨äººæ“ä½œ` `é˜¶æ®µæ„ŸçŸ¥` `é•¿æ—¶ç¨‹ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLAæ¨¡å‹åœ¨é•¿æ—¶ç¨‹ä»»åŠ¡ä¸­é¢ä¸´ä¿¡ç”¨åˆ†é…ç²—ç³™å’Œè®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ã€‚
2. STARE-VLAå°†åŠ¨ä½œè½¨è¿¹åˆ†è§£ä¸ºè¯­ä¹‰é˜¶æ®µï¼Œæä¾›é˜¶æ®µå¯¹é½çš„å¼ºåŒ–ä¿¡å·ï¼Œå®ç°é˜¶æ®µæ„ŸçŸ¥ä¼˜åŒ–ã€‚
3. åœ¨SimplerEnvå’ŒManiSkill3ä¸Šï¼ŒSTARE-VLAæ˜¾è‘—æå‡äº†ä»»åŠ¡æˆåŠŸç‡ï¼Œè¾¾åˆ°SOTAæ°´å¹³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹å—ç›Šäºå¤§å‹è¯­è¨€æ¨¡å‹å’ŒåŸºäºå¼ºåŒ–å­¦ä¹ çš„å¾®è°ƒï¼Œåœ¨æœºå™¨äººæ“ä½œé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å°†é•¿æ—¶ç¨‹åŠ¨ä½œè§†ä¸ºè¯­è¨€åºåˆ—ï¼Œå¹¶åº”ç”¨è½¨è¿¹çº§ä¼˜åŒ–æ–¹æ³•ï¼Œå¦‚è½¨è¿¹åå¥½ä¼˜åŒ–(TPO)æˆ–è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(PPO)ï¼Œå¯¼è‡´ç²—ç³™çš„ä¿¡ç”¨åˆ†é…å’Œä¸ç¨³å®šçš„è®­ç»ƒã€‚ä¸è¯­è¨€ä¸åŒï¼ŒåŠ¨ä½œè½¨è¿¹é€šè¿‡å› æœé“¾è¿æ¥çš„ä¸åŒé˜¶æ®µï¼Œå…·æœ‰ä¸åŒçš„å­¦ä¹ éš¾åº¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†é˜¶æ®µæ„ŸçŸ¥å¼ºåŒ–(STARE)æ¨¡å—ï¼Œå°†é•¿æ—¶ç¨‹åŠ¨ä½œè½¨è¿¹åˆ†è§£ä¸ºè¯­ä¹‰ä¸Šæœ‰æ„ä¹‰çš„é˜¶æ®µï¼Œå¹¶æä¾›å¯†é›†ã€å¯è§£é‡Šä¸”é˜¶æ®µå¯¹é½çš„å¼ºåŒ–ä¿¡å·ã€‚é€šè¿‡å°†STAREé›†æˆåˆ°TPOå’ŒPPOä¸­ï¼Œæˆ‘ä»¬åˆ†åˆ«å¾—åˆ°äº†ç”¨äºç¦»çº¿é˜¶æ®µåå¥½çš„STA-TPOå’Œç”¨äºåœ¨çº¿é˜¶æ®µå†…äº¤äº’çš„STA-PPOã€‚æ­¤å¤–ï¼ŒåŸºäºç›‘ç£å¾®è°ƒä½œä¸ºåˆå§‹åŒ–ï¼Œæˆ‘ä»¬æå‡ºäº†æ¨¡ä»¿->åå¥½->äº¤äº’(IPI)çš„ä¸²è¡Œå¾®è°ƒæµç¨‹ï¼Œä»¥æé«˜VLAæ¨¡å‹ä¸­çš„åŠ¨ä½œå‡†ç¡®æ€§ã€‚åœ¨SimplerEnvå’ŒManiSkill3ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å–å¾—äº†æ˜¾è‘—çš„æå‡ï¼Œåœ¨SimplerEnvå’ŒManiSkill3ä»»åŠ¡ä¸Šåˆ†åˆ«è¾¾åˆ°äº†98.0%å’Œ96.4%çš„æœ€å…ˆè¿›æˆåŠŸç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰VLAæ¨¡å‹åœ¨å¤„ç†é•¿æ—¶ç¨‹æœºå™¨äººæ“ä½œä»»åŠ¡æ—¶ï¼Œé€šå¸¸å°†åŠ¨ä½œåºåˆ—è§†ä¸ºç»Ÿä¸€çš„æ•´ä½“è¿›è¡Œä¼˜åŒ–ï¼Œå¿½ç•¥äº†åŠ¨ä½œåºåˆ—ä¸­ä¸åŒé˜¶æ®µçš„è¯­ä¹‰å·®å¼‚å’Œå­¦ä¹ éš¾åº¦ã€‚è¿™ç§å¤„ç†æ–¹å¼å¯¼è‡´ä¿¡ç”¨åˆ†é…ä¸å‡†ç¡®ï¼Œéš¾ä»¥æœ‰æ•ˆå­¦ä¹ å„ä¸ªé˜¶æ®µçš„å…³é”®åŠ¨ä½œï¼Œæœ€ç»ˆå½±å“æ•´ä½“ä»»åŠ¡çš„æˆåŠŸç‡ã€‚ç°æœ‰æ–¹æ³•å¦‚TPOå’ŒPPOè™½ç„¶åœ¨ä¸€å®šç¨‹åº¦ä¸Šå¯ä»¥ä¼˜åŒ–è½¨è¿¹ï¼Œä½†æ— æ³•é’ˆå¯¹æ€§åœ°ä¼˜åŒ–ä¸åŒé˜¶æ®µçš„åŠ¨ä½œã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†é•¿æ—¶ç¨‹åŠ¨ä½œè½¨è¿¹åˆ†è§£ä¸ºå¤šä¸ªè¯­ä¹‰ä¸Šæœ‰æ„ä¹‰çš„é˜¶æ®µï¼Œå¹¶ä¸ºæ¯ä¸ªé˜¶æ®µæä¾›ç‹¬ç«‹çš„å¼ºåŒ–ä¿¡å·ã€‚é€šè¿‡è¿™ç§é˜¶æ®µæ„ŸçŸ¥çš„å¼ºåŒ–å­¦ä¹ ï¼Œæ¨¡å‹å¯ä»¥æ›´å‡†ç¡®åœ°å­¦ä¹ æ¯ä¸ªé˜¶æ®µçš„å…³é”®åŠ¨ä½œï¼Œä»è€Œæé«˜æ•´ä½“ä»»åŠ¡çš„æˆåŠŸç‡ã€‚è¿™ç§åˆ†è§£å’Œå¼ºåŒ–æ–¹å¼å€Ÿé‰´äº†äººç±»è§£å†³å¤æ‚ä»»åŠ¡çš„ä¹ æƒ¯ï¼Œå³å°†å¤§ä»»åŠ¡åˆ†è§£ä¸ºå°ä»»åŠ¡ï¼Œé€æ­¥å®Œæˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSTARE-VLAçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1) ç›‘ç£å¾®è°ƒ(SFT)åˆå§‹åŒ–æ¨¡å‹å‚æ•°ï¼›2) é˜¶æ®µæ„ŸçŸ¥å¼ºåŒ–(STARE)æ¨¡å—ï¼Œç”¨äºå°†åŠ¨ä½œè½¨è¿¹åˆ†è§£ä¸ºé˜¶æ®µå¹¶ç”Ÿæˆé˜¶æ®µå¯¹é½çš„å¼ºåŒ–ä¿¡å·ï¼›3) è½¨è¿¹åå¥½ä¼˜åŒ–(TPO)æˆ–è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(PPO)ï¼Œç”¨äºä¼˜åŒ–ç­–ç•¥ï¼›4) æ¨¡ä»¿->åå¥½->äº¤äº’(IPI)çš„ä¸²è¡Œå¾®è°ƒæµç¨‹ï¼Œè¿›ä¸€æ­¥æå‡æ¨¡å‹æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼ŒSTAREæ¨¡å—ä¼šæ ¹æ®é¢„å®šä¹‰çš„é˜¶æ®µåˆ’åˆ†è§„åˆ™æˆ–å­¦ä¹ åˆ°çš„é˜¶æ®µåˆ’åˆ†ç­–ç•¥ï¼Œå°†é•¿æ—¶ç¨‹åŠ¨ä½œè½¨è¿¹åˆ†å‰²æˆå¤šä¸ªé˜¶æ®µï¼Œå¹¶ä¸ºæ¯ä¸ªé˜¶æ®µè®¾è®¡ç›¸åº”çš„å¥–åŠ±å‡½æ•°ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹å­¦ä¹ æ¯ä¸ªé˜¶æ®µçš„å…³é”®åŠ¨ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šSTARE-VLAæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†é˜¶æ®µæ„ŸçŸ¥çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„è½¨è¿¹çº§ä¼˜åŒ–æ–¹æ³•ä¸åŒï¼ŒSTARE-VLAèƒ½å¤Ÿé’ˆå¯¹æ€§åœ°ä¼˜åŒ–åŠ¨ä½œåºåˆ—ä¸­çš„ä¸åŒé˜¶æ®µï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°å­¦ä¹ é•¿æ—¶ç¨‹ä»»åŠ¡ã€‚æ­¤å¤–ï¼ŒIPIä¸²è¡Œå¾®è°ƒæµç¨‹ä¹Ÿè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œé€šè¿‡æ¨¡ä»¿å­¦ä¹ åˆå§‹åŒ–æ¨¡å‹ï¼Œç„¶åé€šè¿‡åå¥½å­¦ä¹ å’Œäº¤äº’å­¦ä¹ é€æ­¥ä¼˜åŒ–æ¨¡å‹ã€‚

**å…³é”®è®¾è®¡**ï¼šSTAREæ¨¡å—çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é˜¶æ®µåˆ’åˆ†è§„åˆ™ï¼Œå¯ä»¥æ˜¯é¢„å®šä¹‰çš„æˆ–å­¦ä¹ åˆ°çš„ï¼›2) é˜¶æ®µå¥–åŠ±å‡½æ•°ï¼Œç”¨äºå¼•å¯¼æ¨¡å‹å­¦ä¹ æ¯ä¸ªé˜¶æ®µçš„å…³é”®åŠ¨ä½œï¼›3) IPIä¸²è¡Œå¾®è°ƒæµç¨‹ï¼ŒåŒ…æ‹¬æ¨¡ä»¿å­¦ä¹ ã€åå¥½å­¦ä¹ å’Œäº¤äº’å­¦ä¹ ä¸‰ä¸ªé˜¶æ®µã€‚å…·ä½“çš„å¥–åŠ±å‡½æ•°è®¾è®¡éœ€è¦æ ¹æ®å…·ä½“çš„ä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥æ ¹æ®åŠ¨ä½œçš„å®Œæˆç¨‹åº¦ã€ä¸ç›®æ ‡çš„è·ç¦»ç­‰å› ç´ æ¥è®¾è®¡å¥–åŠ±å‡½æ•°ã€‚æ­¤å¤–ï¼ŒIPIæµç¨‹ä¸­ï¼Œæ¨¡ä»¿å­¦ä¹ ä½¿ç”¨ä¸“å®¶æ•°æ®è¿›è¡Œåˆå§‹åŒ–ï¼Œåå¥½å­¦ä¹ ä½¿ç”¨äººå·¥æ ‡æ³¨çš„åå¥½æ•°æ®è¿›è¡Œä¼˜åŒ–ï¼Œäº¤äº’å­¦ä¹ åˆ™é€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’è¿›è¡Œè¿›ä¸€æ­¥çš„ä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

STARE-VLAåœ¨SimplerEnvå’ŒManiSkill3ä¸¤ä¸ªæœºå™¨äººæ“ä½œåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨SimplerEnvä¸Šï¼ŒSTARE-VLAè¾¾åˆ°äº†98.0%çš„æˆåŠŸç‡ï¼Œè¶…è¿‡äº†ç°æœ‰æ–¹æ³•çš„æœ€ä½³ç»“æœã€‚åœ¨ManiSkill3ä¸Šï¼ŒSTARE-VLAè¾¾åˆ°äº†96.4%çš„æˆåŠŸç‡ï¼ŒåŒæ ·å–å¾—äº†SOTAæ°´å¹³ã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒSTARE-VLAèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜VLAæ¨¡å‹åœ¨é•¿æ—¶ç¨‹æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

STARE-VLAåœ¨æœºå™¨äººæ“ä½œé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥åº”ç”¨äºå®¶åº­æœåŠ¡æœºå™¨äººã€å·¥ä¸šæœºå™¨äººã€åŒ»ç–—æœºå™¨äººç­‰ã€‚è¯¥æ–¹æ³•å¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°å®Œæˆå¤æ‚çš„é•¿æ—¶ç¨‹ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼Œç»„è£…å®¶å…·ã€çƒ¹é¥ªé£Ÿç‰©ã€æ¸…æ´æˆ¿é—´ç­‰ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºè™šæ‹Ÿç¯å¢ƒä¸­çš„æ™ºèƒ½ä½“æ§åˆ¶ï¼Œä¾‹å¦‚ï¼Œæ¸¸æˆAIã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in Vision-Language-Action (VLA) models, powered by large language models and reinforcement learning-based fine-tuning, have shown remarkable progress in robotic manipulation. Existing methods often treat long-horizon actions as linguistic sequences and apply trajectory-level optimization methods such as Trajectory-wise Preference Optimization (TPO) or Proximal Policy Optimization (PPO), leading to coarse credit assignment and unstable training. However, unlike language, where a unified semantic meaning is preserved despite flexible sentence order, action trajectories progress through causally chained stages with different learning difficulties. This motivates progressive stage optimization. Thereby, we present Stage-Aware Reinforcement (STARE), a module that decomposes a long-horizon action trajectory into semantically meaningful stages and provides dense, interpretable, and stage-aligned reinforcement signals. Integrating STARE into TPO and PPO, we yield Stage-Aware TPO (STA-TPO) and Stage-Aware PPO (STA-PPO) for offline stage-wise preference and online intra-stage interaction, respectively. Further building on supervised fine-tuning as initialization, we propose the Imitation -> Preference -> Interaction (IPI), a serial fine-tuning pipeline for improving action accuracy in VLA models. Experiments on SimplerEnv and ManiSkill3 demonstrate substantial gains, achieving state-of-the-art success rates of 98.0 percent on SimplerEnv and 96.4 percent on ManiSkill3 tasks.

