---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-06-09
---

# cs.ROï¼ˆ2025-06-09ï¼‰

ğŸ“Š å…± **13** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (10 ğŸ”—2)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (10 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250607530v1-bitvla-1-bit-vision-language-action-models-for-robotics-manipulation.html">BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation</a></td>
  <td>æå‡ºBitVLAä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­çš„æ¨¡å‹éƒ¨ç½²é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">distillation</span> <span class="paper-tag">vision-language-action</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.07530v1" data-paper-url="./papers/250607530v1-bitvla-1-bit-vision-language-action-models-for-robotics-manipulation.html" onclick="toggleFavorite(this, '2506.07530v1', 'BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250607876v2-versatile-loco-manipulation-through-flexible-interlimb-coordination.html">Versatile Loco-Manipulation through Flexible Interlimb Coordination</a></td>
  <td>æå‡ºReLICä»¥è§£å†³è‡ªä¸»æœºå™¨äººçµæ´»è¿åŠ¨ä¸æ“ä½œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span> <span class="paper-tag">manipulation</span> <span class="paper-tag">loco-manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.07876v2" data-paper-url="./papers/250607876v2-versatile-loco-manipulation-through-flexible-interlimb-coordination.html" onclick="toggleFavorite(this, '2506.07876v2', 'Versatile Loco-Manipulation through Flexible Interlimb Coordination')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250607490v1-rapid-hand-a-robust-affordable-perception-integrated-dexterous-manip.html">RAPID Hand: A Robust, Affordable, Perception-Integrated, Dexterous Manipulation Platform for Generalist Robot Autonomy</a></td>
  <td>æå‡ºRAPID Handä»¥è§£å†³ä½æˆæœ¬é«˜çµæ´»æ€§æœºå™¨äººæ“æ§æ•°æ®æ”¶é›†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span> <span class="paper-tag">teleoperation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.07490v1" data-paper-url="./papers/250607490v1-rapid-hand-a-robust-affordable-perception-integrated-dexterous-manip.html" onclick="toggleFavorite(this, '2506.07490v1', 'RAPID Hand: A Robust, Affordable, Perception-Integrated, Dexterous Manipulation Platform for Generalist Robot Autonomy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250608296v2-hibernac-hierarchical-brain-emulated-robotic-neural-agent-collective.html">HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation</a></td>
  <td>æå‡ºHiBerNACä»¥è§£å†³å¤æ‚æœºå™¨äººæ“æ§ä»»åŠ¡çš„æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.08296v2" data-paper-url="./papers/250608296v2-hibernac-hierarchical-brain-emulated-robotic-neural-agent-collective.html" onclick="toggleFavorite(this, '2506.08296v2', 'HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250607961v2-bridgevla-input-output-alignment-for-efficient-3d-manipulation-learn.html">BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models</a></td>
  <td>æå‡ºBridgeVLAä»¥è§£å†³3Dæ“æ§å­¦ä¹ ä¸­çš„ä½æ ·æœ¬æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">policy learning</span> <span class="paper-tag">vision-language-action</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.07961v2" data-paper-url="./papers/250607961v2-bridgevla-input-output-alignment-for-efficient-3d-manipulation-learn.html" onclick="toggleFavorite(this, '2506.07961v2', 'BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250608291v1-tensortouch-calibration-of-tactile-sensors-for-high-resolution-stres.html">TensorTouch: Calibration of Tactile Sensors for High Resolution Stress Tensor and Deformation for Dexterous Manipulation</a></td>
  <td>æå‡ºTensorTouchä»¥è§£å†³é«˜åˆ†è¾¨ç‡è§¦è§‰ä¼ æ„Ÿå™¨æ ‡å®šé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.08291v1" data-paper-url="./papers/250608291v1-tensortouch-calibration-of-tactile-sensors-for-high-resolution-stres.html" onclick="toggleFavorite(this, '2506.08291v1', 'TensorTouch: Calibration of Tactile Sensors for High Resolution Stress Tensor and Deformation for Dexterous Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250607823v3-primal-dual-ilqr-for-gpu-accelerated-learning-and-control-in-legged-.html">Primal-Dual iLQR for GPU-Accelerated Learning and Control in Legged Robots</a></td>
  <td>æå‡ºåŸºäºGPUåŠ é€Ÿçš„åŸå§‹-å¯¹å¶iLQRä»¥ä¼˜åŒ–å››è¶³æœºå™¨äººæ§åˆ¶</td>
  <td class="tags-cell"><span class="paper-tag">legged robot</span> <span class="paper-tag">locomotion</span> <span class="paper-tag">MPC</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.07823v3" data-paper-url="./papers/250607823v3-primal-dual-ilqr-for-gpu-accelerated-learning-and-control-in-legged-.html" onclick="toggleFavorite(this, '2506.07823v3', 'Primal-Dual iLQR for GPU-Accelerated Learning and Control in Legged Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250607454v2-language-grounded-hierarchical-planning-and-execution-with-multi-rob.html">Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs</a></td>
  <td>æå‡ºåŸºäºè¯­è¨€çš„å±‚æ¬¡è§„åˆ’ä¸æ‰§è¡Œæ–¹æ³•ä»¥è§£å†³å¤šæœºå™¨äººä»»åŠ¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span> <span class="paper-tag">large language model</span> <span class="paper-tag">task and motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.07454v2" data-paper-url="./papers/250607454v2-language-grounded-hierarchical-planning-and-execution-with-multi-rob.html" onclick="toggleFavorite(this, '2506.07454v2', 'Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250607509v1-taking-flight-with-dialogue-enabling-natural-language-control-for-px.html">Taking Flight with Dialogue: Enabling Natural Language Control for PX4-based Drone Agent</a></td>
  <td>æå‡ºå¼€æºæ¡†æ¶ä»¥å®ç°PX4æ— äººæœºçš„è‡ªç„¶è¯­è¨€æ§åˆ¶</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">scene understanding</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.07509v1" data-paper-url="./papers/250607509v1-taking-flight-with-dialogue-enabling-natural-language-control-for-px.html" onclick="toggleFavorite(this, '2506.07509v1', 'Taking Flight with Dialogue: Enabling Natural Language Control for PX4-based Drone Agent')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250607339v2-real-time-execution-of-action-chunking-flow-policies.html">Real-Time Execution of Action Chunking Flow Policies</a></td>
  <td>æå‡ºå®æ—¶åŠ¨ä½œåˆ†å—æµç­–ç•¥ä»¥è§£å†³å»¶è¿Ÿé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">bi-manual</span> <span class="paper-tag">bimanual manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.07339v2" data-paper-url="./papers/250607339v2-real-time-execution-of-action-chunking-flow-policies.html" onclick="toggleFavorite(this, '2506.07339v2', 'Real-Time Execution of Action Chunking Flow Policies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>11</td>
  <td><a href="./papers/250607639v2-fast-ecot-efficient-embodied-chain-of-thought-via-thoughts-reuse.html">Fast ECoT: Efficient Embodied Chain-of-Thought via Thoughts Reuse</a></td>
  <td>æå‡ºFast ECoTä»¥è§£å†³ECoTæ¨ç†å»¶è¿Ÿé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.07639v2" data-paper-url="./papers/250607639v2-fast-ecot-efficient-embodied-chain-of-thought-via-thoughts-reuse.html" onclick="toggleFavorite(this, '2506.07639v2', 'Fast ECoT: Efficient Embodied Chain-of-Thought via Thoughts Reuse')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>12</td>
  <td><a href="./papers/250607350v1-mapbert-bitwise-masked-modeling-for-real-time-semantic-mapping-gener.html">MapBERT: Bitwise Masked Modeling for Real-Time Semantic Mapping Generation</a></td>
  <td>æå‡ºMapBERTä»¥è§£å†³å®æ—¶è¯­ä¹‰æ˜ å°„ç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">semantic mapping</span> <span class="paper-tag">semantic map</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.07350v1" data-paper-url="./papers/250607350v1-mapbert-bitwise-masked-modeling-for-real-time-semantic-mapping-gener.html" onclick="toggleFavorite(this, '2506.07350v1', 'MapBERT: Bitwise Masked Modeling for Real-Time Semantic Mapping Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/250608149v1-ego-centric-learning-of-communicative-world-models-for-autonomous-dr.html">Ego-centric Learning of Communicative World Models for Autonomous Driving</a></td>
  <td>æå‡ºCALLä»¥è§£å†³å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„ä¿¡æ¯å…±äº«é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">world model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.08149v1" data-paper-url="./papers/250608149v1-ego-centric-learning-of-communicative-world-models-for-autonomous-dr.html" onclick="toggleFavorite(this, '2506.08149v1', 'Ego-centric Learning of Communicative World Models for Autonomous Driving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)