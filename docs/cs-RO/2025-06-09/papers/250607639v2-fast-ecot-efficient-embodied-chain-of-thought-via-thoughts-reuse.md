---
layout: default
title: Fast ECoT: Efficient Embodied Chain-of-Thought via Thoughts Reuse
---

# Fast ECoT: Efficient Embodied Chain-of-Thought via Thoughts Reuse

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.07639" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.07639v2</a>
  <a href="https://arxiv.org/pdf/2506.07639.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.07639v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.07639v2', 'Fast ECoT: Efficient Embodied Chain-of-Thought via Thoughts Reuse')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhekai Duan, Yuan Zhang, Shikai Geng, Gaowen Liu, Joschka Boedecker, Chris Xiaoxuan Lu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-09 (æ›´æ–°: 2025-09-21)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFast ECoTä»¥è§£å†³ECoTæ¨ç†å»¶è¿Ÿé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ECoTæ¨ç†` `å®æ—¶æ¨ç†` `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `æ¨ç†åŠ é€Ÿ` `æœºå™¨äººä»»åŠ¡` `å¼‚æ­¥è°ƒåº¦` `æ¨¡å—åŒ–æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ECoTæ¨ç†æ–¹æ³•åœ¨æ¨ç†è¿‡ç¨‹ä¸­å­˜åœ¨æ˜¾è‘—å»¶è¿Ÿï¼Œé™åˆ¶äº†å…¶åœ¨å®æ—¶åœºæ™¯ä¸­çš„åº”ç”¨ã€‚
2. Fast ECoTé€šè¿‡ç¼“å­˜é«˜å±‚æ¨ç†å’Œå¹¶è¡Œç”Ÿæˆæ¨ç†æ­¥éª¤ï¼Œæ˜¾è‘—åŠ é€Ÿäº†æ¨ç†è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFast ECoTåœ¨å»¶è¿Ÿä¸Šå‡å°‘äº†7.5%ï¼ŒåŒæ—¶ä¿æŒæˆ–æå‡äº†ä»»åŠ¡æˆåŠŸç‡å’Œæ¨ç†å¯ä¿¡åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Embodied Chain-of-Thought (ECoT)æ¨ç†é€šè¿‡ä¸­é—´æ¨ç†æ­¥éª¤æå‡äº†è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹çš„æ€§èƒ½å’Œå¯è§£é‡Šæ€§ã€‚ç„¶è€Œï¼Œå…¶é¡ºåºè‡ªå›å½’çš„æ ‡è®°ç”Ÿæˆå¼•å…¥äº†æ˜¾è‘—çš„æ¨ç†å»¶è¿Ÿï¼Œé™åˆ¶äº†å®æ—¶éƒ¨ç½²ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†Fast ECoTï¼Œä¸€ç§åˆ©ç”¨ECoTçš„ç»“æ„åŒ–å’Œé‡å¤ç‰¹æ€§æ¥åŠ é€Ÿæ¨ç†çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡ç¼“å­˜å’Œé‡ç”¨é«˜å±‚æ¨ç†ã€å¹¶è¡Œç”Ÿæˆæ¨¡å—åŒ–æ¨ç†æ­¥éª¤ï¼Œä»¥åŠå¼•å…¥å¼‚æ­¥è°ƒåº¦å™¨æ¥è§£è€¦æ¨ç†ä¸åŠ¨ä½œè§£ç ï¼Œä»è€Œæå‡å“åº”é€Ÿåº¦ã€‚Fast ECoTæ— éœ€æ¨¡å‹æ›´æ”¹æˆ–é¢å¤–è®­ç»ƒï¼Œæ˜“äºé›†æˆåˆ°ç°æœ‰VLAç®¡é“ä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººä»»åŠ¡ä¸­ï¼Œå»¶è¿Ÿå‡å°‘äº†7.5%ï¼ŒåŒæ—¶ä»»åŠ¡æˆåŠŸç‡å’Œæ¨ç†å¯ä¿¡åº¦ä¿æŒä¸å˜æˆ–æœ‰æ‰€æå‡ï¼Œä½¿ECoTç­–ç•¥æ›´æ¥è¿‘å®é™…å®æ—¶éƒ¨ç½²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ECoTæ¨ç†ä¸­çš„æ¨ç†å»¶è¿Ÿé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é‡‡ç”¨é¡ºåºè‡ªå›å½’çš„æ ‡è®°ç”Ÿæˆæ–¹å¼ï¼Œå¯¼è‡´æ¨ç†é€Ÿåº¦æ…¢ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶åº”ç”¨éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFast ECoTçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ECoTæ¨ç†çš„ç»“æ„åŒ–å’Œé‡å¤ç‰¹æ€§ï¼Œé€šè¿‡ç¼“å­˜å’Œé‡ç”¨æ¨ç†ç»“æœï¼Œä»¥åŠå¹¶è¡Œç”Ÿæˆæ¨ç†æ­¥éª¤ï¼Œæ¥åŠ é€Ÿæ¨ç†è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬é«˜å±‚æ¨ç†ç¼“å­˜æ¨¡å—ã€å¹¶è¡Œæ¨ç†ç”Ÿæˆæ¨¡å—å’Œå¼‚æ­¥è°ƒåº¦å™¨ã€‚é«˜å±‚æ¨ç†ç¼“å­˜æ¨¡å—è´Ÿè´£å­˜å‚¨å’Œé‡ç”¨ä¹‹å‰çš„æ¨ç†ç»“æœï¼Œè€Œå¹¶è¡Œæ¨ç†ç”Ÿæˆæ¨¡å—åˆ™åŒæ—¶ç”Ÿæˆå¤šä¸ªæ¨ç†æ­¥éª¤ï¼Œå¼‚æ­¥è°ƒåº¦å™¨åˆ™ä¼˜åŒ–äº†æ¨ç†ä¸åŠ¨ä½œè§£ç çš„åè°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†é«˜å±‚æ¨ç†ç¼“å­˜å’Œå¹¶è¡Œç”Ÿæˆæœºåˆ¶ï¼Œä½¿å¾—æ¨ç†è¿‡ç¨‹ä¸å†æ˜¯çº¿æ€§çš„ï¼Œè€Œæ˜¯å¯ä»¥åŒæ—¶è¿›è¡Œå¤šä¸ªæ¨ç†æ­¥éª¤ï¼Œä»è€Œæ˜¾è‘—é™ä½äº†æ¨ç†å»¶è¿Ÿã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒFast ECoTæ— éœ€å¯¹åŸæœ‰æ¨¡å‹è¿›è¡Œä¿®æ”¹æˆ–é¢å¤–è®­ç»ƒï¼Œé‡‡ç”¨äº†å¼‚æ­¥è°ƒåº¦ç­–ç•¥ä»¥æé«˜å“åº”é€Ÿåº¦ï¼Œç¡®ä¿äº†ä¸ç°æœ‰VLAç®¡é“çš„å…¼å®¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFast ECoTåœ¨å»¶è¿Ÿä¸Šå‡å°‘äº†7.5%ï¼ŒåŒæ—¶åœ¨ä»»åŠ¡æˆåŠŸç‡å’Œæ¨ç†å¯ä¿¡åº¦æ–¹é¢ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ä¿æŒä¸å˜æˆ–æœ‰æ‰€æå‡ã€‚è¿™è¡¨æ˜Fast ECoTåœ¨å®é™…åº”ç”¨ä¸­èƒ½å¤Ÿæœ‰æ•ˆæå‡ECoTç­–ç•¥çš„å®æ—¶æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½åŠ©æ‰‹å’Œè‡ªåŠ¨åŒ–æ§åˆ¶ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡ECoTæ¨ç†çš„å®æ—¶æ€§ï¼ŒFast ECoTèƒ½å¤Ÿä½¿å¾—è¿™äº›ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­æ›´é«˜æ•ˆåœ°æ‰§è¡Œä»»åŠ¡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Embodied Chain-of-Thought (ECoT) reasoning enhances vision-language-action (VLA) models by improving performance and interpretability through intermediate reasoning steps. However, its sequential autoregressive token generation introduces significant inference latency, limiting real-time deployment. We propose Fast ECoT, an inference-time acceleration method that exploits the structured and repetitive nature of ECoT to (1) cache and reuse high-level reasoning across timesteps and (2) parallelise the generation of modular reasoning steps. Additionally, we introduce an asynchronous scheduler that decouples reasoning from action decoding, further boosting responsiveness. Fast ECoT requires no model changes or additional training and integrates easily into existing VLA pipelines. Experiments in both simulation (LIBERO) and real-world robot tasks show up to a 7.5% reduction in latency with comparable or improved task success rate and reasoning faithfulness, bringing ECoT policies closer to practical real-time deployment.

