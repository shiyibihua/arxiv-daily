---
layout: default
title: Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion
---

# Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion

**arXiv**: [2511.14178v1](https://arxiv.org/abs/2511.14178) | [PDF](https://arxiv.org/pdf/2511.14178.pdf)

**ä½œè€…**: Zhuo Li, Junjia Liu, Zhipeng Dong, Tao Teng, Quentin Rouxel, Darwin Caldwell, Fei Chen

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-18

**å¤‡æ³¨**: 9 pages, 8 figures, submitted to IEEE RA-L

**ðŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://rip4kobe.github.io/vla-pilot/)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVLA-Pilotï¼Œæ— éœ€å¾®è°ƒå³å¯å®žçŽ°VLAæ¨¡åž‹åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­çš„å³æ’å³ç”¨ç­–ç•¥å¼•å¯¼ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹` `æœºå™¨äººæ“ä½œ` `é›¶æ ·æœ¬å­¦ä¹ ` `ç­–ç•¥å¼•å¯¼` `æ‰©æ•£æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é¢„è®­ç»ƒVLAç­–ç•¥åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­æ€§èƒ½ä¸‹é™æ˜Žæ˜¾ï¼Œè€Œå¾®è°ƒæˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†å…¶åœ¨å®žé™…æœºå™¨äººåº”ç”¨ä¸­çš„éƒ¨ç½²ã€‚
2. VLA-Piloté€šè¿‡æŽ¨ç†æ—¶ç­–ç•¥å¼•å¯¼ï¼Œæ— éœ€é¢å¤–æ•°æ®æˆ–å¾®è°ƒï¼Œå³å¯æå‡é¢„è®­ç»ƒVLAæ¨¡åž‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒVLA-Pilotæ˜¾è‘—æé«˜äº†VLAç­–ç•¥åœ¨ä¸åŒæœºå™¨äººå¹³å°å’Œä»»åŠ¡ä¸Šçš„æˆåŠŸçŽ‡ï¼Œå®žçŽ°é²æ£’çš„é›¶æ ·æœ¬æ³›åŒ–ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹åœ¨çŽ°å®žä¸–ç•Œæœºå™¨äººæ“ä½œä¸­å±•çŽ°å‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œé¢„è®­ç»ƒçš„VLAç­–ç•¥åœ¨ä¸‹æ¸¸éƒ¨ç½²ä¸­ä»ç„¶é¢ä¸´ä¸¥é‡çš„æ€§èƒ½ä¸‹é™ã€‚è™½ç„¶å¾®è°ƒå¯ä»¥ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œä½†å®ƒä¾èµ–äºŽæ˜‚è´µçš„æ¼”ç¤ºæ•°æ®æ”¶é›†å’Œå¤§é‡çš„è®¡ç®—ï¼Œè¿™åœ¨å®žé™…çŽ¯å¢ƒä¸­æ˜¯ä¸åˆ‡å®žé™…çš„ã€‚æœ¬æ–‡ä»‹ç»VLA-Pilotï¼Œä¸€ç§å³æ’å³ç”¨çš„æŽ¨ç†æ—¶ç­–ç•¥å¼•å¯¼æ–¹æ³•ï¼Œç”¨äºŽé¢„è®­ç»ƒVLAçš„é›¶æ ·æœ¬éƒ¨ç½²ï¼Œæ— éœ€ä»»ä½•é¢å¤–çš„å¾®è°ƒæˆ–æ•°æ®æ”¶é›†ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªä¸åŒçš„æœºå™¨äººå¹³å°ä¸Šï¼Œé’ˆå¯¹å…­ä¸ªçœŸå®žä¸–ç•Œçš„ä¸‹æ¸¸æ“ä½œä»»åŠ¡è¯„ä¼°äº†VLA-Pilotï¼Œæ¶µç›–äº†åˆ†å¸ƒå†…å’Œåˆ†å¸ƒå¤–åœºæ™¯ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒVLA-Pilotæ˜¾è‘—æé«˜äº†çŽ°æˆçš„é¢„è®­ç»ƒVLAç­–ç•¥çš„æˆåŠŸçŽ‡ï¼Œä»Žè€Œå®žçŽ°äº†å¯¹å„ç§ä»»åŠ¡å’Œå¹³å°çš„é²æ£’é›¶æ ·æœ¬æ³›åŒ–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡åž‹åœ¨éƒ¨ç½²åˆ°æ–°çš„æœºå™¨äººæ“ä½œä»»åŠ¡æ—¶ï¼Œå³ä½¿æ˜¯ç›¸ä¼¼çš„ä»»åŠ¡ï¼Œä¹Ÿä¼šå‡ºçŽ°æ˜¾è‘—çš„æ€§èƒ½ä¸‹é™ã€‚ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•è™½ç„¶å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†æ˜¯éœ€è¦å¤§é‡çš„ä»»åŠ¡ç›¸å…³æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œè¿™åœ¨å®žé™…åº”ç”¨ä¸­å¾€å¾€æ˜¯ä¸å¯è¡Œçš„ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¿«é€Ÿéƒ¨ç½²å’Œé€‚åº”æ–°çŽ¯å¢ƒçš„æƒ…å†µä¸‹ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¸è¿›è¡Œå¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œæå‡VLAæ¨¡åž‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œæ˜¯ä¸€ä¸ªäºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVLA-Pilotçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨æŽ¨ç†é˜¶æ®µï¼Œé€šè¿‡è¿›åŒ–ç­–ç•¥å¼•å¯¼VLAæ¨¡åž‹çš„åŠ¨ä½œè¾“å‡ºã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒåˆ©ç”¨ä¸€ä¸ªæ‰©æ•£æ¨¡åž‹æ¥ç”Ÿæˆå€™é€‰åŠ¨ä½œåºåˆ—ï¼Œç„¶åŽä½¿ç”¨VLAæ¨¡åž‹å¯¹è¿™äº›åŠ¨ä½œåºåˆ—è¿›è¡Œè¯„ä¼°ï¼Œé€‰æ‹©èƒ½å¤Ÿæœ€å¤§åŒ–ä»»åŠ¡å¥–åŠ±çš„åŠ¨ä½œåºåˆ—ã€‚è¿™ç§æ–¹æ³•ä¸éœ€è¦ä»»ä½•é¢å¤–çš„è®­ç»ƒæ•°æ®ï¼Œåªéœ€è¦åˆ©ç”¨é¢„è®­ç»ƒVLAæ¨¡åž‹çš„èƒ½åŠ›ï¼Œå°±å¯ä»¥åœ¨æ–°çš„ä»»åŠ¡ä¸­æ‰¾åˆ°åˆé€‚çš„åŠ¨ä½œç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šVLA-Pilotä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š1) æ‰©æ•£æ¨¡åž‹ï¼šç”¨äºŽç”Ÿæˆå€™é€‰åŠ¨ä½œåºåˆ—ã€‚è¯¥æ‰©æ•£æ¨¡åž‹ä»¥å½“å‰çŠ¶æ€å’Œç›®æ ‡ä¸ºæ¡ä»¶ï¼Œç”Ÿæˆä¸€ç³»åˆ—å¯èƒ½çš„åŠ¨ä½œåºåˆ—ã€‚2) ç­–ç•¥è¯„ä¼°æ¨¡å—ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„VLAæ¨¡åž‹å¯¹ç”Ÿæˆçš„åŠ¨ä½œåºåˆ—è¿›è¡Œè¯„ä¼°ï¼Œå¹¶æ ¹æ®è¯„ä¼°ç»“æžœé€‰æ‹©æœ€ä¼˜çš„åŠ¨ä½œåºåˆ—ã€‚æ•´ä¸ªæµç¨‹å¯ä»¥æ¦‚æ‹¬ä¸ºï¼šè¾“å…¥å½“å‰çŠ¶æ€å’Œç›®æ ‡ -> æ‰©æ•£æ¨¡åž‹ç”Ÿæˆå€™é€‰åŠ¨ä½œåºåˆ— -> VLAæ¨¡åž‹è¯„ä¼°åŠ¨ä½œåºåˆ— -> é€‰æ‹©æœ€ä¼˜åŠ¨ä½œ -> æ‰§è¡ŒåŠ¨ä½œ -> é‡å¤ä¸Šè¿°è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šVLA-Pilotçš„å…³é”®åˆ›æ–°åœ¨äºŽå°†è¿›åŒ–ç­–ç•¥ä¸Žæ‰©æ•£æ¨¡åž‹ç›¸ç»“åˆï¼Œå®žçŽ°äº†ä¸€ç§æ— éœ€å¾®è°ƒçš„ç­–ç•¥å¼•å¯¼æ–¹æ³•ã€‚ä¸Žä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼ŒVLA-Pilotä¸éœ€è¦ä»»ä½•é¢å¤–çš„è®­ç»ƒæ•°æ®ï¼Œåªéœ€è¦åˆ©ç”¨é¢„è®­ç»ƒVLAæ¨¡åž‹çš„èƒ½åŠ›ï¼Œå°±å¯ä»¥åœ¨æ–°çš„ä»»åŠ¡ä¸­æ‰¾åˆ°åˆé€‚çš„åŠ¨ä½œç­–ç•¥ã€‚ä¸Žä¼ ç»Ÿçš„è¿›åŒ–ç­–ç•¥ç›¸æ¯”ï¼ŒVLA-Pilotåˆ©ç”¨æ‰©æ•£æ¨¡åž‹ç”Ÿæˆå€™é€‰åŠ¨ä½œåºåˆ—ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°æŽ¢ç´¢åŠ¨ä½œç©ºé—´ï¼Œä»Žè€Œæé«˜ç­–ç•¥çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šæ‰©æ•£æ¨¡åž‹çš„è®¾è®¡è‡³å…³é‡è¦ï¼Œå®ƒéœ€è¦èƒ½å¤Ÿç”Ÿæˆå¤šæ ·ä¸”åˆç†çš„åŠ¨ä½œåºåˆ—ã€‚è®ºæ–‡ä¸­ä½¿ç”¨çš„æ‰©æ•£æ¨¡åž‹ä»¥å½“å‰çŠ¶æ€å’Œç›®æ ‡ä¸ºæ¡ä»¶ï¼Œé€šè¿‡è¿­ä»£åŽ»å™ªè¿‡ç¨‹ç”ŸæˆåŠ¨ä½œåºåˆ—ã€‚VLAæ¨¡åž‹çš„è¯„ä¼°å‡½æ•°ä¹Ÿéœ€è¦ç²¾å¿ƒè®¾è®¡ï¼Œä»¥å‡†ç¡®åæ˜ åŠ¨ä½œåºåˆ—çš„ä¼˜åŠ£ã€‚è®ºæ–‡ä¸­ä½¿ç”¨çš„è¯„ä¼°å‡½æ•°åŸºäºŽVLAæ¨¡åž‹çš„é¢„æµ‹å¥–åŠ±ï¼Œå¹¶ç»“åˆäº†ä¸€äº›å¯å‘å¼è§„åˆ™ï¼Œä»¥æé«˜è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¿›åŒ–ç­–ç•¥çš„å‚æ•°è®¾ç½®ï¼Œå¦‚ç§ç¾¤å¤§å°å’Œè¿­ä»£æ¬¡æ•°ï¼Œä¹Ÿä¼šå½±å“æœ€ç»ˆçš„ç­–ç•¥æ€§èƒ½ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

VLA-Pilotåœ¨å…­ä¸ªçœŸå®žä¸–ç•Œçš„æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­è¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬æŠ“å–ã€æ”¾ç½®å’Œç»„è£…ç­‰ä»»åŠ¡ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒVLA-Pilotæ˜¾è‘—æé«˜äº†é¢„è®­ç»ƒVLAç­–ç•¥çš„æˆåŠŸçŽ‡ï¼Œå¹³å‡æå‡å¹…åº¦è¶…è¿‡20%ã€‚æ­¤å¤–ï¼ŒVLA-Pilotåœ¨åˆ†å¸ƒå¤–ä»»åŠ¡ä¸­ä¹Ÿè¡¨çŽ°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¡¨æ˜Žè¯¥æ–¹æ³•å…·æœ‰å¾ˆå¼ºçš„é²æ£’æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

VLA-Pilotå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ä»¥åº”ç”¨äºŽå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚å®¶åº­æœåŠ¡æœºå™¨äººã€å·¥ä¸šæœºå™¨äººå’ŒåŒ»ç–—æœºå™¨äººã€‚è¯¥æ–¹æ³•å¯ä»¥å¸®åŠ©æœºå™¨äººå¿«é€Ÿé€‚åº”æ–°çš„ä»»åŠ¡å’ŒçŽ¯å¢ƒï¼Œæé«˜æœºå™¨äººçš„è‡ªä¸»æ€§å’Œæ™ºèƒ½åŒ–æ°´å¹³ã€‚æ­¤å¤–ï¼ŒVLA-Pilotè¿˜å¯ä»¥åº”ç”¨äºŽè™šæ‹ŸçŽ¯å¢ƒä¸­çš„æœºå™¨äººè®­ç»ƒï¼Œé€šè¿‡æ¨¡æ‹ŸçœŸå®žä¸–ç•Œçš„åœºæ™¯ï¼Œæé«˜æœºå™¨äººçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models have demonstrated significant potential in real-world robotic manipulation. However, pre-trained VLA policies still suffer from substantial performance degradation during downstream deployment. Although fine-tuning can mitigate this issue, its reliance on costly demonstration collection and intensive computation makes it impractical in real-world settings. In this work, we introduce VLA-Pilot, a plug-and-play inference-time policy steering method for zero-shot deployment of pre-trained VLA without any additional fine-tuning or data collection. We evaluate VLA-Pilot on six real-world downstream manipulation tasks across two distinct robotic embodiments, encompassing both in-distribution and out-of-distribution scenarios. Experimental results demonstrate that VLA-Pilot substantially boosts the success rates of off-the-shelf pre-trained VLA policies, enabling robust zero-shot generalization to diverse tasks and embodiments. Experimental videos and code are available at: https://rip4kobe.github.io/vla-pilot/.

