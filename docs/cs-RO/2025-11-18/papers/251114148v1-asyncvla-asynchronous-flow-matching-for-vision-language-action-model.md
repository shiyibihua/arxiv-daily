---
layout: default
title: AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models
---

# AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.14148" target="_blank" class="toolbar-btn">arXiv: 2511.14148v1</a>
    <a href="https://arxiv.org/pdf/2511.14148.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.14148v1" 
            onclick="toggleFavorite(this, '2511.14148v1', 'AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yuhua Jiang, Shuang Cheng, Yan Ding, Feifei Gao, Biqing Qi

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-18

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/YuhuaJiang2002/AsyncVLA)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**AsyncVLAÔºöÈù¢ÂêëËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÁöÑÂºÇÊ≠•ÊµÅÂåπÈÖçÔºåÊèêÂçáÈïøÊó∂‰ªªÂä°ÁöÑÁ®≥ÂÆöÊÄßÂíåËá™Á∫†ÈîôËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã` `ÊµÅÂåπÈÖç` `ÂºÇÊ≠•ÁîüÊàê` `Êú∫Âô®‰∫∫Êìç‰Ωú` `Ëá™Á∫†Èîô`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰º†ÁªüVLAÊ®°ÂûãÈááÁî®ÂêåÊ≠•ÊµÅÂåπÈÖçÔºåÁº∫‰πèÂä®‰Ωú‰∏ä‰∏ãÊñáÊÑüÁü•ÂíåÂºÇÊ≠•Á∫†ÈîôÔºåÂØºËá¥ÈïøÊó∂‰ªªÂä°‰∏≠ÂÆπÊòìÂá∫Èîô„ÄÇ
2. AsyncVLAÈÄöËøáÂºÇÊ≠•ÊµÅÂåπÈÖçÔºåÂºïÂÖ•Êó∂Èó¥ÁÅµÊ¥ªÊÄßÂíåÂä®‰Ωú‰∏ä‰∏ãÊñáÊÑüÁü•ÔºåÂÆûÁé∞Âä®‰ΩúÁîüÊàê‰∏≠ÁöÑËá™Á∫†Èîô„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåAsyncVLAÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏äË°®Áé∞Âá∫Êï∞ÊçÆÊïàÁéáÂíåËá™Á∫†ÈîôËÉΩÂäõÔºåËææÂà∞SOTAÊ∞¥Âπ≥„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãÂ∑≤Êàê‰∏∫ÊûÑÂª∫ÈÄöÁî®Êú∫Âô®‰∫∫ÁöÑÂº∫Â§ßËåÉ‰æã„ÄÇÁÑ∂ËÄåÔºå‰º†ÁªüÁöÑVLAÊ®°ÂûãÈÄöËøáÊµÅÂåπÈÖç(FM)ÁîüÊàêÂä®‰ΩúÔºåÈÄöÂ∏∏‰æùËµñ‰∫éÂàöÊÄßÂíåÁªü‰∏ÄÁöÑÊó∂Èó¥Ë°®ÔºåÂç≥ÂêåÊ≠•FM(SFM)„ÄÇÁî±‰∫éÁº∫‰πèÂä®‰Ωú‰∏ä‰∏ãÊñáÊÑüÁü•ÂíåÂºÇÊ≠•Ëá™Á∫†ÈîôËÉΩÂäõÔºåSFMÂú®ÈïøÊó∂‰ªªÂä°‰∏≠ÂèòÂæó‰∏çÁ®≥ÂÆöÔºåÂçï‰∏™Âä®‰ΩúÈîôËØØÂèØËÉΩÂØºËá¥Êï¥‰ΩìÂ§±Ë¥•„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜÂºÇÊ≠•ÊµÅÂåπÈÖçVLA(AsyncVLA)ÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊ°ÜÊû∂ÔºåÂÆÉÂú®ÂºÇÊ≠•FM(AFM)‰∏≠ÂºïÂÖ•‰∫ÜÊó∂Èó¥ÁÅµÊ¥ªÊÄßÔºåÂπ∂ÂÆûÁé∞‰∫ÜÂä®‰ΩúÁîüÊàê‰∏≠ÁöÑËá™Á∫†Èîô„ÄÇAsyncVLAÈÄöËøá‰ª•ÂÖ∑ÊúâÂä®‰Ωú‰∏ä‰∏ãÊñáÊÑüÁü•ÁöÑÈùûÂùáÂåÄÊó∂Èó¥Ë°®ÁîüÊàêÂä®‰ΩútokenÔºåÊâìÁ†¥‰∫ÜVLAÊ®°Âûã‰∏≠vanilla SFMÁöÑÈôêÂà∂„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÂºïÂÖ•‰∫ÜÁΩÆ‰ø°Â∫¶ËØÑ‰º∞Âô®Êù•ÊèêÂèñÂàùÂßãÁîüÊàêÂä®‰ΩúÁöÑÁΩÆ‰ø°Â∫¶Ôºå‰ΩøÊ®°ÂûãËÉΩÂ§üÂú®ÊâßË°åÂâçÈÄâÊã©ÊÄßÂú∞ÁªÜÂåñ‰∏çÂáÜÁ°ÆÁöÑÂä®‰Ωútoken„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜSFMÂíåAFMÁöÑÁªü‰∏ÄËÆ≠ÁªÉÁ®ãÂ∫èÔºå‰ΩøÂçï‰∏™Ê®°ÂûãÂêåÊó∂ÂÖ∑Â§á‰∏§ÁßçÊ®°ÂºèÔºå‰ªéËÄåÊèêÈ´òKV-cacheÁöÑÂà©Áî®Áéá„ÄÇÂú®Êú∫Âô®‰∫∫Êìç‰ΩúÂü∫ÂáÜ‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåAsyncVLAÂÖ∑ÊúâÊï∞ÊçÆÊïàÁéáÂíåËá™Á∫†ÈîôËÉΩÂäõ„ÄÇÁî±‰∫éAFM‰∏≠ÁöÑÂºÇÊ≠•ÁîüÊàêÔºåAsyncVLAÂú®ÈÄöÁî®ÂÖ∑Ë∫´ËØÑ‰º∞‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÁªìÊûú„ÄÇ‰ª£Á†ÅÂèØÂú®https://github.com/YuhuaJiang2002/AsyncVLAËé∑Âèñ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãÂú®ÁîüÊàêÂä®‰ΩúÊó∂ÔºåÈÄöÂ∏∏ÈááÁî®ÂêåÊ≠•ÊµÅÂåπÈÖç(SFM)ÔºåÂç≥ÊåâÁÖßÂõ∫ÂÆöÁöÑÊó∂Èó¥Ê≠•ÁîüÊàêÂä®‰ΩúÂ∫èÂàó„ÄÇËøôÁßçÊñπÊ≥ïÁº∫‰πèÂØπÂä®‰Ωú‰∏ä‰∏ãÊñáÁöÑÊÑüÁü•ÔºåÂπ∂‰∏îÊó†Ê≥ïËøõË°åÂºÇÊ≠•ÁöÑËá™ÊàëÁ∫†Ê≠£„ÄÇÂõ†Ê≠§ÔºåÂú®ÈïøÊó∂‰ªªÂä°‰∏≠Ôºå‰∏ÄÊó¶Âá∫Áé∞Âä®‰ΩúÈîôËØØÔºåÂ∞±ÂÆπÊòìÁ¥ØÁßØÂπ∂ÂØºËá¥‰ªªÂä°Â§±Ë¥•„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöAsyncVLAÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂºïÂÖ•ÂºÇÊ≠•ÊµÅÂåπÈÖç(AFM)ÔºåÂÖÅËÆ∏Ê®°Âûã‰ª•ÈùûÂùáÂåÄÁöÑÊó∂Èó¥Ë°®ÁîüÊàêÂä®‰Ωútoken„ÄÇÈÄöËøáÂä®‰Ωú‰∏ä‰∏ãÊñáÊÑüÁü•ÔºåÊ®°ÂûãÂèØ‰ª•Âä®ÊÄÅÂú∞Ë∞ÉÊï¥Âä®‰ΩúÁîüÊàêÁöÑÊó∂Èó¥Ê≠•ÈïøÔºåÂπ∂Âú®ÂøÖË¶ÅÊó∂ÂØπ‰∏çÂáÜÁ°ÆÁöÑÂä®‰ΩúËøõË°å‰øÆÊ≠£Ôºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÂú®ÈïøÊó∂‰ªªÂä°‰∏≠ÁöÑÁ®≥ÂÆöÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAsyncVLAÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) ÂºÇÊ≠•ÊµÅÂåπÈÖçÊ®°ÂùóÔºöË¥üË¥£‰ª•ÈùûÂùáÂåÄÁöÑÊó∂Èó¥Ë°®ÁîüÊàêÂä®‰Ωútoken„ÄÇ2) ÁΩÆ‰ø°Â∫¶ËØÑ‰º∞Âô®ÔºöÁî®‰∫éËØÑ‰º∞ÁîüÊàêÂä®‰ΩúÁöÑÁΩÆ‰ø°Â∫¶ÔºåÂπ∂ÈÄâÊã©ÊÄßÂú∞ÂØπ‰ΩéÁΩÆ‰ø°Â∫¶ÁöÑÂä®‰ΩúËøõË°å‰øÆÊ≠£„ÄÇ3) Áªü‰∏ÄËÆ≠ÁªÉÁ®ãÂ∫èÔºöÊîØÊåÅSFMÂíåAFM‰∏§ÁßçÊ®°ÂºèÁöÑËÅîÂêàËÆ≠ÁªÉÔºåÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÂíåKV-cacheÁöÑÂà©Áî®Áéá„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÔºåÊ®°ÂûãÈ¶ñÂÖàÊ†πÊçÆËßÜËßâÂíåËØ≠Ë®ÄËæìÂÖ•ÔºåÈÄöËøáÂºÇÊ≠•ÊµÅÂåπÈÖçÁîüÊàêÂàùÂßãÂä®‰ΩúÂ∫èÂàó„ÄÇÁÑ∂ÂêéÔºåÁΩÆ‰ø°Â∫¶ËØÑ‰º∞Âô®ËØÑ‰º∞ÊØè‰∏™Âä®‰ΩúÁöÑÁΩÆ‰ø°Â∫¶ÔºåÂπ∂ÂØπ‰ΩéÁΩÆ‰ø°Â∫¶ÁöÑÂä®‰ΩúËøõË°åËø≠‰ª£‰øÆÊ≠£„ÄÇÊúÄÂêéÔºåÊ®°ÂûãËæìÂá∫‰øÆÊ≠£ÂêéÁöÑÂä®‰ΩúÂ∫èÂàó„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAsyncVLAÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂºïÂÖ•‰∫ÜÂºÇÊ≠•ÊµÅÂåπÈÖç(AFM)ÔºåÊâìÁ†¥‰∫Ü‰º†ÁªüVLAÊ®°Âûã‰∏≠ÂêåÊ≠•ÊµÅÂåπÈÖç(SFM)ÁöÑÈôêÂà∂„ÄÇAFMÂÖÅËÆ∏Ê®°Âûã‰ª•ÈùûÂùáÂåÄÁöÑÊó∂Èó¥Ë°®ÁîüÊàêÂä®‰ΩútokenÔºåÂπ∂Ê†πÊçÆÂä®‰Ωú‰∏ä‰∏ãÊñáËøõË°åÂä®ÊÄÅË∞ÉÊï¥ÂíåËá™ÊàëÁ∫†Ê≠£Ôºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊ®°ÂûãÂú®ÈïøÊó∂‰ªªÂä°‰∏≠ÁöÑÁ®≥ÂÆöÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAsyncVLAÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ÈùûÂùáÂåÄÊó∂Èó¥Ë°®ÁöÑÁîüÊàêÁ≠ñÁï•ÔºöÊ†πÊçÆÂä®‰Ωú‰∏ä‰∏ãÊñáÂä®ÊÄÅË∞ÉÊï¥Êó∂Èó¥Ê≠•Èïø„ÄÇ2) ÁΩÆ‰ø°Â∫¶ËØÑ‰º∞Âô®ÁöÑËÆæËÆ°ÔºöÈááÁî®Á•ûÁªèÁΩëÁªúÈ¢ÑÊµãÂä®‰ΩúÁöÑÁΩÆ‰ø°Â∫¶„ÄÇ3) Áªü‰∏ÄËÆ≠ÁªÉÁ®ãÂ∫èÁöÑËÆæËÆ°ÔºöÈÄöËøáÂÖ±‰∫´ÂèÇÊï∞ÂíåÊçüÂ§±ÂáΩÊï∞ÔºåÂÆûÁé∞SFMÂíåAFMÁöÑËÅîÂêàËÆ≠ÁªÉ„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÊµÅÂåπÈÖçÊçüÂ§±ÂíåÁΩÆ‰ø°Â∫¶È¢ÑÊµãÊçüÂ§±„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

AsyncVLAÂú®Êú∫Âô®‰∫∫Êìç‰ΩúÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAsyncVLAÂú®Êï∞ÊçÆÊïàÁéáÂíåËá™Á∫†ÈîôËÉΩÂäõÊñπÈù¢Âùá‰ºò‰∫é‰º†ÁªüÁöÑÂêåÊ≠•ÊµÅÂåπÈÖçÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåAsyncVLAÂú®Â§ö‰∏™ÈïøÊó∂‰ªªÂä°‰∏äÁöÑÊàêÂäüÁéáÊèêÈ´ò‰∫ÜXX%ÔºåÂπ∂‰∏îËÉΩÂ§üÊúâÊïàÂú∞Á∫†Ê≠£ÂàùÂßãÂä®‰Ωú‰∏≠ÁöÑÈîôËØØÔºå‰ªéËÄåÈÅøÂÖç‰ªªÂä°Â§±Ë¥•„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

AsyncVLAÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÈïøÊó∂Èó¥ËßÑÂàíÂíåÁ®≥ÂÆöÊâßË°åÁöÑÊú∫Âô®‰∫∫‰ªªÂä°Ôºå‰æãÂ¶ÇÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öËá™Âä®ÂåñÊú∫Âô®‰∫∫„ÄÅËá™Âä®È©æÈ©∂Á≠â„ÄÇÈÄöËøáÊèêÈ´òÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÈÄÇÂ∫îÊÄßÂíåÈ≤ÅÊ£íÊÄßÔºåAsyncVLAÊúâÊúõÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ïÂíåÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-language-action (VLA) models have recently emerged as a powerful paradigm for building generalist robots. However, traditional VLA models that generate actions through flow matching (FM) typically rely on rigid and uniform time schedules, i.e., synchronous FM (SFM). Without action context awareness and asynchronous self-correction, SFM becomes unstable in long-horizon tasks, where a single action error can cascade into failure. In this work, we propose asynchronous flow matching VLA (AsyncVLA), a novel framework that introduces temporal flexibility in asynchronous FM (AFM) and enables self-correction in action generation. AsyncVLA breaks from the vanilla SFM in VLA models by generating the action tokens in a non-uniform time schedule with action context awareness. Besides, our method introduces the confidence rater to extract confidence of the initially generated actions, enabling the model to selectively refine inaccurate action tokens before execution. Moreover, we propose a unified training procedure for SFM and AFM that endows a single model with both modes, improving KV-cache utilization. Extensive experiments on robotic manipulation benchmarks demonstrate that AsyncVLA is data-efficient and exhibits self-correction ability. AsyncVLA achieves state-of-the-art results across general embodied evaluations due to its asynchronous generation in AFM. Our code is available at https://github.com/YuhuaJiang2002/AsyncVLA.

