---
layout: default
title: Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning
---

# Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning

**arXiv**: [2511.14427v1](https://arxiv.org/abs/2511.14427) | [PDF](https://arxiv.org/pdf/2511.14427.pdf)

**ä½œè€…**: Rickmer Krohn, Vignesh Prasad, Gabriele Tiboni, Georgia Chalvatzaki

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-18

**å¤‡æ³¨**: 9 pages, 10 figures, preprint

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMSDPï¼Œç”¨äºŽæŽ¥è§¦å¼æœºå™¨äººå¼ºåŒ–å­¦ä¹ çš„å¤šæ¨¡æ€è‡ªç›‘ç£é¢„è®­ç»ƒã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæŽ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `è‡ªç›‘ç£å­¦ä¹ ` `æœºå™¨äººå¼ºåŒ–å­¦ä¹ ` `æŽ¥è§¦å¼æ“ä½œ` `Transformer` `æŽ©ç è‡ªç¼–ç ` `ä¼ æ„Ÿå™¨èžåˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¤šæ¨¡æ€æœºå™¨äººæŽ§åˆ¶ä¸­ï¼Œéš¾ä»¥åº”å¯¹ä¼ æ„Ÿå™¨å™ªå£°å’ŒåŠ¨æ€å˜åŒ–ï¼Œå¯¼è‡´å­¦ä¹ æ•ˆçŽ‡ä½Žä¸‹ã€‚
2. MSDPé€šè¿‡æŽ©ç è‡ªç¼–ç å™¨ï¼Œä»Žéƒ¨åˆ†ä¼ æ„Ÿå™¨æ•°æ®é‡å»ºå®Œæ•´çš„å¤šæ¨¡æ€è§‚æµ‹ï¼Œå®žçŽ°è·¨æ¨¡æ€èžåˆå’Œé²æ£’çš„ç‰¹å¾æå–ã€‚
3. MSDPåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žæœºå™¨äººä»»åŠ¡ä¸­è¡¨çŽ°å‡ºåŠ é€Ÿå­¦ä¹ å’Œå¯¹æ‰°åŠ¨çš„é²æ£’æ€§ï¼Œä»…éœ€å°‘é‡äº¤äº’å³å¯å®žçŽ°é«˜æˆåŠŸçŽ‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ‰æ•ˆçš„æŽ¥è§¦å¼æ“ä½œéœ€è¦æœºå™¨äººååŒåˆ©ç”¨è§†è§‰ã€åŠ›è§‰å’Œæœ¬ä½“æ„Ÿè§‰ã€‚ç„¶è€Œï¼Œå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“åœ¨è¿™ç§å¤šæ¨¡æ€çŽ¯å¢ƒä¸­éš¾ä»¥å­¦ä¹ ï¼Œå°¤å…¶æ˜¯åœ¨å­˜åœ¨ä¼ æ„Ÿå™¨å™ªå£°å’ŒåŠ¨æ€å˜åŒ–çš„æƒ…å†µä¸‹ã€‚æˆ‘ä»¬æå‡ºäº†å¤šæ¨¡æ€åŠ¨æ€é¢„è®­ç»ƒï¼ˆMSDPï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æž¶ï¼Œç”¨äºŽå­¦ä¹ ä¸ºé¢å‘ä»»åŠ¡çš„ç­–ç•¥å­¦ä¹ é‡èº«å®šåˆ¶çš„è¡¨è¾¾æ€§å¤šæ¨¡æ€è¡¨ç¤ºã€‚MSDPåŸºäºŽæŽ©ç è‡ªç¼–ç ï¼Œå¹¶é€šè¿‡ä»…ä»Žä¼ æ„Ÿå™¨åµŒå…¥çš„å­é›†ä¸­é‡å»ºå¤šæ¨¡æ€è§‚æµ‹æ¥è®­ç»ƒåŸºäºŽTransformerçš„ç¼–ç å™¨ï¼Œä»Žè€Œå®žçŽ°è·¨æ¨¡æ€é¢„æµ‹å’Œä¼ æ„Ÿå™¨èžåˆã€‚å¯¹äºŽä¸‹æ¸¸ç­–ç•¥å­¦ä¹ ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„éžå¯¹ç§°æž¶æž„ï¼Œå…¶ä¸­äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å…è®¸è¯„è®ºå®¶ä»Žå†»ç»“çš„åµŒå…¥ä¸­æå–åŠ¨æ€çš„ã€ç‰¹å®šäºŽä»»åŠ¡çš„ç‰¹å¾ï¼Œè€Œæ¼”å‘˜æŽ¥æ”¶ç¨³å®šçš„æ± åŒ–è¡¨ç¤ºä»¥æŒ‡å¯¼å…¶åŠ¨ä½œã€‚æˆ‘ä»¬çš„æ–¹æ³•å±•ç¤ºäº†åœ¨å„ç§æ‰°åŠ¨ï¼ˆåŒ…æ‹¬ä¼ æ„Ÿå™¨å™ªå£°å’Œå¯¹è±¡åŠ¨æ€å˜åŒ–ï¼‰ä¸‹çš„åŠ é€Ÿå­¦ä¹ å’Œé²æ£’æ€§èƒ½ã€‚åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žä¸–ç•Œä¸­çš„å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ã€æŽ¥è§¦å¼æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­çš„è¯„ä¼°å±•ç¤ºäº†MSDPçš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¯¹æ‰°åŠ¨è¡¨çŽ°å‡ºå¾ˆå¼ºçš„é²æ£’æ€§ï¼Œå¹¶åœ¨çœŸå®žæœºå™¨äººä¸Šä»…é€šè¿‡6,000æ¬¡åœ¨çº¿äº¤äº’å°±å®žçŽ°äº†é«˜æˆåŠŸçŽ‡ï¼Œä¸ºå¤æ‚çš„å¤šæ¨¡æ€æœºå™¨äººæŽ§åˆ¶æä¾›äº†ä¸€ä¸ªç®€å•è€Œå¼ºå¤§çš„è§£å†³æ–¹æ¡ˆã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æŽ¥è§¦å¼æœºå™¨äººå¼ºåŒ–å­¦ä¹ ä¸­ï¼Œç”±äºŽå¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆè§†è§‰ã€åŠ›è§‰ã€æœ¬ä½“æ„Ÿè§‰ï¼‰çš„å™ªå£°å’ŒåŠ¨æ€å˜åŒ–ï¼Œå¯¼è‡´ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ ç®—æ³•éš¾ä»¥æœ‰æ•ˆå­¦ä¹ çš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥å……åˆ†åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¹¶ä¸”å¯¹çŽ¯å¢ƒæ‰°åŠ¨çš„é²æ£’æ€§è¾ƒå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œé¢„è®­ç»ƒä¸€ä¸ªèƒ½å¤Ÿæœ‰æ•ˆèžåˆå¤šæ¨¡æ€ä¼ æ„Ÿå™¨ä¿¡æ¯çš„ç¼–ç å™¨ã€‚é€šè¿‡æŽ©ç è‡ªç¼–ç çš„æ–¹å¼ï¼Œè¿«ä½¿æ¨¡åž‹ä»Žéƒ¨åˆ†ä¼ æ„Ÿå™¨æ•°æ®ä¸­é‡å»ºå®Œæ•´çš„å¤šæ¨¡æ€è§‚æµ‹ï¼Œä»Žè€Œå­¦ä¹ åˆ°è·¨æ¨¡æ€çš„å…³è”æ€§å’Œé²æ£’çš„ç‰¹å¾è¡¨ç¤ºã€‚è¿™ç§é¢„è®­ç»ƒçš„è¡¨ç¤ºå¯ä»¥åŠ é€Ÿä¸‹æ¸¸å¼ºåŒ–å­¦ä¹ ä»»åŠ¡çš„å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶æé«˜ç­–ç•¥çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šMSDPæ¡†æž¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¢„è®­ç»ƒé˜¶æ®µå’Œç­–ç•¥å­¦ä¹ é˜¶æ®µã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨ä¸€ä¸ªåŸºäºŽTransformerçš„ç¼–ç å™¨ï¼Œé€šè¿‡æŽ©ç è‡ªç¼–ç çš„æ–¹å¼å­¦ä¹ å¤šæ¨¡æ€è¡¨ç¤ºã€‚åœ¨ç­–ç•¥å­¦ä¹ é˜¶æ®µï¼Œé‡‡ç”¨ä¸€ç§éžå¯¹ç§°çš„Actor-Criticæž¶æž„ã€‚Criticç½‘ç»œä½¿ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»Žé¢„è®­ç»ƒçš„å†»ç»“åµŒå…¥ä¸­æå–åŠ¨æ€çš„ã€ç‰¹å®šäºŽä»»åŠ¡çš„ç‰¹å¾ã€‚Actorç½‘ç»œæŽ¥æ”¶ä¸€ä¸ªç¨³å®šçš„æ± åŒ–è¡¨ç¤ºï¼Œç”¨äºŽæŒ‡å¯¼åŠ¨ä½œçš„ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šMSDPçš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶å¤šæ¨¡æ€åŠ¨æ€é¢„è®­ç»ƒæ–¹æ³•å’Œéžå¯¹ç§°çš„Actor-Criticæž¶æž„ã€‚å¤šæ¨¡æ€åŠ¨æ€é¢„è®­ç»ƒé€šè¿‡æŽ©ç è‡ªç¼–ç çš„æ–¹å¼ï¼Œå®žçŽ°äº†è·¨æ¨¡æ€çš„ä¼ æ„Ÿå™¨èžåˆå’Œé²æ£’çš„ç‰¹å¾æå–ã€‚éžå¯¹ç§°çš„Actor-Criticæž¶æž„å…è®¸Criticç½‘ç»œåˆ©ç”¨åŠ¨æ€çš„ã€ç‰¹å®šäºŽä»»åŠ¡çš„ç‰¹å¾ï¼Œè€ŒActorç½‘ç»œåˆ™ä¿æŒç¨³å®šï¼Œä»Žè€Œæé«˜äº†å­¦ä¹ æ•ˆçŽ‡å’Œç­–ç•¥çš„é²æ£’æ€§ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMSDPèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¹¶ä¸”å¯¹çŽ¯å¢ƒæ‰°åŠ¨å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨Transformerç¼–ç å™¨ï¼Œè¾“å…¥ä¸ºæŽ©ç åŽçš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®åµŒå…¥ã€‚æŸå¤±å‡½æ•°ä¸ºé‡å»ºè¯¯å·®ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–é‡å»ºçš„å¤šæ¨¡æ€è§‚æµ‹ä¸ŽåŽŸå§‹è§‚æµ‹ä¹‹é—´çš„å·®å¼‚ã€‚åœ¨ç­–ç•¥å­¦ä¹ é˜¶æ®µï¼ŒCriticç½‘ç»œä½¿ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†çŠ¶æ€è¡¨ç¤ºä¸Žé¢„è®­ç»ƒçš„åµŒå…¥è¿›è¡Œèžåˆã€‚Actorç½‘ç»œä½¿ç”¨ä¸€ä¸ªç®€å•çš„å…¨è¿žæŽ¥ç½‘ç»œï¼Œè¾“å…¥ä¸ºæ± åŒ–åŽçš„é¢„è®­ç»ƒåµŒå…¥ã€‚è®ºæ–‡ä¸­æ²¡æœ‰æ˜Žç¡®ç»™å‡ºå…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æž„ç»†èŠ‚ï¼Œä½†å¼ºè°ƒäº†é¢„è®­ç»ƒåµŒå…¥çš„å†»ç»“ï¼Œä»¥ä¿è¯Actorç½‘ç»œçš„ç¨³å®šæ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

MSDPåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®žæœºå™¨äººä»»åŠ¡ä¸­éƒ½å–å¾—äº†æ˜¾è‘—çš„æˆæžœã€‚åœ¨çœŸå®žæœºå™¨äººå®žéªŒä¸­ï¼Œä»…ä½¿ç”¨6000æ¬¡åœ¨çº¿äº¤äº’ï¼ŒMSDPå°±å®žçŽ°äº†å¾ˆé«˜çš„æˆåŠŸçŽ‡ï¼Œå¹¶ä¸”è¡¨çŽ°å‡ºå¯¹ä¼ æ„Ÿå™¨å™ªå£°å’Œå¯¹è±¡åŠ¨æ€å˜åŒ–çš„é²æ£’æ€§ã€‚ä¸Žæ²¡æœ‰é¢„è®­ç»ƒçš„åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒMSDPæ˜¾è‘—æé«˜äº†å­¦ä¹ æ•ˆçŽ‡å’Œç­–ç•¥æ€§èƒ½ï¼Œè¯æ˜Žäº†å…¶åœ¨æŽ¥è§¦å¼æœºå™¨äººå¼ºåŒ–å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå„ç§éœ€è¦æŽ¥è§¦å¼æ“ä½œçš„æœºå™¨äººä»»åŠ¡ï¼Œä¾‹å¦‚è£…é…ã€æŠ“å–ã€æ“ä½œå·¥å…·ç­‰ã€‚é€šè¿‡é¢„è®­ç»ƒçš„å¤šæ¨¡æ€è¡¨ç¤ºï¼Œæœºå™¨äººå¯ä»¥æ›´å¥½åœ°ç†è§£çŽ¯å¢ƒï¼Œå¹¶åšå‡ºæ›´ç²¾ç¡®å’Œé²æ£’çš„åŠ¨ä½œã€‚è¯¥æ–¹æ³•åœ¨å·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—æœºå™¨äººã€å®¶åº­æœåŠ¡æœºå™¨äººç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œæœ‰åŠ©äºŽæå‡æœºå™¨äººçš„æ™ºèƒ½åŒ–æ°´å¹³å’Œé€‚åº”èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Effective contact-rich manipulation requires robots to synergistically leverage vision, force, and proprioception. However, Reinforcement Learning agents struggle to learn in such multisensory settings, especially amidst sensory noise and dynamic changes. We propose MultiSensory Dynamic Pretraining (MSDP), a novel framework for learning expressive multisensory representations tailored for task-oriented policy learning. MSDP is based on masked autoencoding and trains a transformer-based encoder by reconstructing multisensory observations from only a subset of sensor embeddings, leading to cross-modal prediction and sensor fusion. For downstream policy learning, we introduce a novel asymmetric architecture, where a cross-attention mechanism allows the critic to extract dynamic, task-specific features from the frozen embeddings, while the actor receives a stable pooled representation to guide its actions. Our method demonstrates accelerated learning and robust performance under diverse perturbations, including sensor noise, and changes in object dynamics. Evaluations in multiple challenging, contact-rich robot manipulation tasks in simulation and the real world showcase the effectiveness of MSDP. Our approach exhibits strong robustness to perturbations and achieves high success rates on the real robot with as few as 6,000 online interactions, offering a simple yet powerful solution for complex multisensory robotic control.

