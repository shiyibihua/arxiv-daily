---
layout: default
title: Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language
---

# Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.14565" target="_blank" class="toolbar-btn">arXiv: 2511.14565v1</a>
    <a href="https://arxiv.org/pdf/2511.14565.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.14565v1" 
            onclick="toggleFavorite(this, '2511.14565v1', 'Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Minyoung Hwang, Alexandra Forsey-Smerek, Nathaniel Dennler, Andreea Bobu

**ÂàÜÁ±ª**: cs.RO, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-18

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/MIT-CLEAR-Lab/Masked-IRL) | [PROJECT_PAGE](https://MIT-CLEAR-Lab.github.io/Masked-IRL)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Masked IRL‰ª•Ëß£ÂÜ≥Êú∫Âô®‰∫∫Â•ñÂä±ÂáΩÊï∞Ê®°Á≥äÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÈÄÜÂº∫ÂåñÂ≠¶‰π†` `Â§ßËØ≠Ë®ÄÊ®°Âûã` `Êú∫Âô®‰∫∫Â≠¶‰π†` `Â•ñÂä±ÂáΩÊï∞` `Ê®°Á≥äÊåá‰ª§` `Ê†∑Êú¨ÊïàÁéá` `‰∫∫Êú∫‰∫§‰∫í`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂ•ñÂä±Â≠¶‰π†ÊñπÊ≥ïÂú®Êï∞ÊçÆÊúâÈôêÊó∂ÂÆπÊòìËøáÊãüÂêàÔºåÂØºËá¥Ê®°ÂûãÊó†Ê≥ïÊúâÊïàÊ≥õÂåñÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜÊ®°Á≥äÊåá‰ª§Êó∂„ÄÇ
2. Masked IRLÊ°ÜÊû∂ÁªìÂêà‰∫ÜÁ§∫ËåÉÂíåËØ≠Ë®ÄÊåá‰ª§ÁöÑ‰ºòÂäøÔºåÈÄöËøáÊé®Êñ≠Áä∂ÊÄÅÁõ∏ÂÖ≥ÊÄßÊé©Á†ÅÊù•Â¢ûÂº∫Ê®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMasked IRLÂú®‰ΩøÁî®Êï∞ÊçÆÈáèÂáèÂ∞ëÁöÑÊÉÖÂÜµ‰∏ãÔºåÊÄßËÉΩÊèêÂçáÂèØËææ15%ÔºåÊòæÁ§∫Âá∫Êõ¥È´òÁöÑÊ†∑Êú¨ÊïàÁéáÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú∫Âô®‰∫∫ÂèØ‰ª•ÈÄöËøáÁ§∫ËåÉÂ≠¶‰π†Áî®Êà∑ÂÅèÂ•ΩÁöÑÂ•ñÂä±ÂáΩÊï∞Ôºå‰ΩÜÂú®Êï∞ÊçÆÊúâÈôêÁöÑÊÉÖÂÜµ‰∏ãÔºåÂ•ñÂä±Ê®°ÂûãÂæÄÂæÄ‰ºöËøáÊãüÂêà‰∫éËôöÂÅáÁõ∏ÂÖ≥ÊÄßÔºåÂØºËá¥Ê≥õÂåñËÉΩÂäõ‰∏çË∂≥„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Â∞ÜËØ≠Ë®ÄÊåá‰ª§ËßÜ‰∏∫ÁÆÄÂçïÁöÑÊù°‰ª∂‰ø°Âè∑ÔºåÊú™ËÉΩÂÖÖÂàÜÂà©Áî®ÂÖ∂Ê∂àÈô§Ê®°Á≥äÊÄßÁöÑÊΩúÂäõ„ÄÇÊú¨ÊñáÊèêÂá∫Masked Inverse Reinforcement Learning (Masked IRL)Ê°ÜÊû∂ÔºåÁªìÂêàÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂíåÁ§∫ËåÉÊï∞ÊçÆÔºåÊé®Êñ≠Áä∂ÊÄÅÁõ∏ÂÖ≥ÊÄßÊé©Á†ÅÔºå‰ªéËÄåÂ¢ûÂº∫Ê®°ÂûãÂØπÊó†ÂÖ≥Áä∂ÊÄÅÁªÑ‰ª∂ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂú®Ê®°ÊãüÂíåÁúüÂÆûÊú∫Âô®‰∫∫ÂÆûÈ™å‰∏≠ÔºåMasked IRLÂú®Êï∞ÊçÆ‰ΩøÁî®ÊïàÁéá„ÄÅÊ≥õÂåñËÉΩÂäõÂíåÂØπÊ®°Á≥äËØ≠Ë®ÄÁöÑÈ≤ÅÊ£íÊÄßÊñπÈù¢Âùá‰ºò‰∫éÂÖàÂâçÁöÑÊñπÊ≥ïÔºåÊèêÂçáÂπÖÂ∫¶ÂèØËææ15%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Êú∫Âô®‰∫∫Âú®Â≠¶‰π†Â•ñÂä±ÂáΩÊï∞Êó∂ÔºåÁî±‰∫éÊï∞ÊçÆÊúâÈôêËÄåÂØºËá¥ÁöÑËøáÊãüÂêàÂíåÊ≥õÂåñËÉΩÂäõ‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÊú™ËÉΩÊúâÊïàÂà©Áî®ËØ≠Ë®ÄÊåá‰ª§Êù•Ê∂àÈô§Ê®°Á≥äÊÄßÔºåÂØºËá¥Ê®°Âûã‰∏ìÊ≥®‰∫éÊó†ÂÖ≥Áä∂ÊÄÅÁªÜËäÇ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMasked IRLÈÄöËøáÁªìÂêàÁ§∫ËåÉÂíåËØ≠Ë®ÄÊåá‰ª§ÁöÑ‰∫íË°•‰ø°ÊÅØÔºåÊé®Êñ≠Âá∫Áä∂ÊÄÅÁõ∏ÂÖ≥ÊÄßÊé©Á†ÅÔºå‰ªéËÄåÂ¢ûÂº∫Ê®°ÂûãÂØπÊó†ÂÖ≥Áä∂ÊÄÅÁöÑÈ≤ÅÊ£íÊÄß„ÄÇËØ•ÊñπÊ≥ïÂà©Áî®Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÊù•ÊæÑÊ∏ÖÊ®°Á≥äÊåá‰ª§ÔºåÁ°Æ‰øùÊ®°ÂûãÂÖ≥Ê≥®ÈáçË¶ÅÁöÑÁä∂ÊÄÅ‰ø°ÊÅØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMasked IRLÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÁ§∫ËåÉÊï∞ÊçÆÂ§ÑÁêÜÊ®°ÂùóÂíåËØ≠Ë®ÄÊåá‰ª§Ëß£ÊûêÊ®°Âùó„ÄÇÂâçËÄÖÁî®‰∫éÊèêÂèñÁ§∫ËåÉ‰∏≠ÁöÑË°å‰∏∫‰ø°ÊÅØÔºåÂêéËÄÖÂàôÈÄöËøáÂ§ßËØ≠Ë®ÄÊ®°ÂûãËß£ÊûêÊåá‰ª§Âπ∂Êé®Êñ≠Áõ∏ÂÖ≥ÊÄßÊé©Á†Å„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨Á†îÁ©∂ÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂ∞ÜÂ§ßËØ≠Ë®ÄÊ®°Âûã‰∏éÈÄÜÂº∫ÂåñÂ≠¶‰π†Áõ∏ÁªìÂêàÔºåÂÖÖÂàÜÂà©Áî®ËØ≠Ë®ÄÊåá‰ª§ÁöÑÊΩúÂäõÊù•Ê∂àÈô§Â•ñÂä±ÂáΩÊï∞ÁöÑÊ®°Á≥äÊÄß„ÄÇËøô‰∏ÄÊñπÊ≥ï‰∏é‰º†ÁªüÁöÑËØ≠Ë®ÄÊù°‰ª∂ÂåñÂ•ñÂä±Â≠¶‰π†ÊñπÊ≥ïÊúâÊú¨Ë¥®Âå∫Âà´ÔºåÂêéËÄÖÈÄöÂ∏∏‰ªÖÂ∞ÜËØ≠Ë®Ä‰Ωú‰∏∫ÁÆÄÂçïÁöÑÊù°‰ª∂‰ø°Âè∑„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞Êù•‰ºòÂåñÁä∂ÊÄÅÁõ∏ÂÖ≥ÊÄßÊé©Á†ÅÁöÑÊé®Êñ≠ÔºåÂêåÊó∂Âú®ÁΩëÁªúÁªìÊûÑ‰∏äÁªìÂêà‰∫ÜÊ∑±Â∫¶Â≠¶‰π†ÊäÄÊúØÔºå‰ª•ÊèêÈ´òÊ®°ÂûãÁöÑÂ≠¶‰π†ÊïàÁéáÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåMasked IRLÂú®Ê®°ÊãüÂíåÁúüÂÆûÊú∫Âô®‰∫∫‰ªªÂä°‰∏≠ÔºåÁõ∏ËæÉ‰∫é‰º†ÁªüÁöÑËØ≠Ë®ÄÊù°‰ª∂ÂåñÈÄÜÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåÊÄßËÉΩÊèêÂçáÂèØËææ15%„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïÂú®Êï∞ÊçÆ‰ΩøÁî®ÊïàÁéá‰∏äË°®Áé∞Âá∫Ëâ≤Ôºå‰ΩøÁî®ÁöÑÊï∞ÊçÆÈáèÂáèÂ∞ëËá≥4.7ÂÄçÔºåÂ±ïÁé∞‰∫ÜÊõ¥È´òÁöÑÊ†∑Êú¨ÊïàÁéáÂíåÂØπÊ®°Á≥äËØ≠Ë®ÄÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÂ∞§ÂÖ∂Âú®‰∫∫Êú∫‰∫§‰∫í„ÄÅÊúçÂä°Êú∫Âô®‰∫∫ÂíåËá™‰∏ªÁ≥ªÁªüÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÈ´òÊú∫Âô®‰∫∫ÂØπÁî®Êà∑ÂÅèÂ•ΩÁöÑÁêÜËß£ËÉΩÂäõÔºåMasked IRLËÉΩÂ§ü‰ΩøÊú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂ§çÊùÇÁöÑ‰ªªÂä°ÁéØÂ¢ÉÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™å„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ï‰πüÂèØËÉΩÊé®Âä®Êô∫ËÉΩÊú∫Âô®‰∫∫Âú®Âä®ÊÄÅÂíå‰∏çÁ°ÆÂÆöÁéØÂ¢É‰∏≠ÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Robots can adapt to user preferences by learning reward functions from demonstrations, but with limited data, reward models often overfit to spurious correlations and fail to generalize. This happens because demonstrations show robots how to do a task but not what matters for that task, causing the model to focus on irrelevant state details. Natural language can more directly specify what the robot should focus on, and, in principle, disambiguate between many reward functions consistent with the demonstrations. However, existing language-conditioned reward learning methods typically treat instructions as simple conditioning signals, without fully exploiting their potential to resolve ambiguity. Moreover, real instructions are often ambiguous themselves, so naive conditioning is unreliable. Our key insight is that these two input types carry complementary information: demonstrations show how to act, while language specifies what is important. We propose Masked Inverse Reinforcement Learning (Masked IRL), a framework that uses large language models (LLMs) to combine the strengths of both input types. Masked IRL infers state-relevance masks from language instructions and enforces invariance to irrelevant state components. When instructions are ambiguous, it uses LLM reasoning to clarify them in the context of the demonstrations. In simulation and on a real robot, Masked IRL outperforms prior language-conditioned IRL methods by up to 15% while using up to 4.7 times less data, demonstrating improved sample-efficiency, generalization, and robustness to ambiguous language. Project page: https://MIT-CLEAR-Lab.github.io/Masked-IRL and Code: https://github.com/MIT-CLEAR-Lab/Masked-IRL

