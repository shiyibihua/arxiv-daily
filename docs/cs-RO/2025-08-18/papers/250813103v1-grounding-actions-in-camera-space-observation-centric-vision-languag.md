---
layout: default
title: Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy
---

# Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13103" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13103v1</a>
  <a href="https://arxiv.org/pdf/2508.13103.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13103v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13103v1', 'Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tianyi Zhang, Haonan Duan, Haoran Hao, Yu Qiao, Jifeng Dai, Zhi Hou

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§‚å¯Ÿä¸­å¿ƒçš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¡†æ¶ä»¥è§£å†³ç©ºé—´ä¸ä¸€è‡´é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `æœºå™¨äººæ“ä½œ` `ç›¸æœºåæ ‡ç³»` `ç©ºé—´ä¸€è‡´æ€§` `è·¨è§†è§’æ³›åŒ–` `æ¨¡å‹é²æ£’æ€§` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨çœŸå®ç¯å¢ƒä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œä¸»è¦ç”±äºè§‚å¯Ÿç©ºé—´ä¸åŠ¨ä½œç©ºé—´ä¹‹é—´çš„å·®å¼‚ã€‚
2. æœ¬æ–‡æå‡ºçš„OC-VLAæ¡†æ¶é€šè¿‡å°†åŠ¨ä½œé¢„æµ‹ç›´æ¥åŸºäºç›¸æœºè§‚å¯Ÿç©ºé—´ï¼Œè§£å†³äº†ç©ºé—´ä¸ä¸€è‡´çš„é—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOC-VLAåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®çš„æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­åŠ é€Ÿäº†æ”¶æ•›ï¼Œæé«˜äº†ä»»åŠ¡æˆåŠŸç‡ï¼Œå¹¶æ”¹å–„äº†è·¨è§†è§’çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹åœ¨çœŸå®ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›å¸¸å¸¸å—åˆ°è§‚å¯Ÿç©ºé—´ä¸åŠ¨ä½œç©ºé—´ä¹‹é—´å›ºæœ‰å·®å¼‚çš„æŒ‘æˆ˜ã€‚å°½ç®¡è®­ç»ƒæ•°æ®æ¥è‡ªå¤šç§ç›¸æœºè§†è§’ï¼Œæ¨¡å‹é€šå¸¸åœ¨æœºå™¨äººåŸºåæ ‡ç³»å†…é¢„æµ‹æœ«ç«¯æ‰§è¡Œå™¨å§¿æ€ï¼Œå¯¼è‡´ç©ºé—´ä¸ä¸€è‡´ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†è§‚å¯Ÿä¸­å¿ƒçš„VLAï¼ˆOC-VLAï¼‰æ¡†æ¶ï¼Œç›´æ¥åœ¨ç›¸æœºè§‚å¯Ÿç©ºé—´ä¸­è¿›è¡ŒåŠ¨ä½œé¢„æµ‹ã€‚é€šè¿‡åˆ©ç”¨ç›¸æœºçš„å¤–éƒ¨æ ‡å®šçŸ©é˜µï¼ŒOC-VLAå°†æœ«ç«¯æ‰§è¡Œå™¨å§¿æ€ä»æœºå™¨äººåŸºåæ ‡ç³»è½¬æ¢ä¸ºç›¸æœºåæ ‡ç³»ï¼Œä»è€Œç»Ÿä¸€äº†ä¸åŒè§†è§’ä¸‹çš„é¢„æµ‹ç›®æ ‡ã€‚è¯¥è½»é‡çº§çš„å³æ’å³ç”¨ç­–ç•¥ç¡®ä¿äº†æ„ŸçŸ¥ä¸åŠ¨ä½œä¹‹é—´çš„ç¨³å¥å¯¹é½ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹å¯¹ç›¸æœºè§†è§’å˜åŒ–çš„é²æ£’æ€§ã€‚ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒOC-VLAåŠ é€Ÿäº†æ”¶æ•›ï¼Œæé«˜äº†ä»»åŠ¡æˆåŠŸç‡ï¼Œå¹¶æ”¹å–„äº†è·¨è§†è§’æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨çœŸå®ç¯å¢ƒä¸­å› è§‚å¯Ÿç©ºé—´ä¸åŠ¨ä½œç©ºé—´ä¸ä¸€è‡´è€Œå¯¼è‡´çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åœ¨æœºå™¨äººåŸºåæ ‡ç³»å†…è¿›è¡Œé¢„æµ‹ï¼Œé€ æˆç©ºé—´ä¸Šçš„ä¸ä¸€è‡´æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOC-VLAæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†åŠ¨ä½œé¢„æµ‹ç›´æ¥åŸºäºç›¸æœºè§‚å¯Ÿç©ºé—´ï¼Œé€šè¿‡ç›¸æœºçš„å¤–éƒ¨æ ‡å®šçŸ©é˜µå°†æœ«ç«¯æ‰§è¡Œå™¨å§¿æ€è½¬æ¢ä¸ºç›¸æœºåæ ‡ç³»ï¼Œä»è€Œå®ç°ä¸åŒè§†è§’ä¸‹çš„ç»Ÿä¸€é¢„æµ‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOC-VLAæ¡†æ¶åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ç›¸æœºåæ ‡ç³»è½¬æ¢å’ŒåŠ¨ä½œé¢„æµ‹ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œåˆ©ç”¨ç›¸æœºçš„å¤–éƒ¨æ ‡å®šçŸ©é˜µè¿›è¡Œåæ ‡è½¬æ¢ï¼Œç„¶ååœ¨ç›¸æœºè§‚å¯Ÿç©ºé—´ä¸­è¿›è¡ŒåŠ¨ä½œé¢„æµ‹ï¼Œæœ€åå°†é¢„æµ‹ç»“æœåº”ç”¨äºæœºå™¨äººæ“ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šOC-VLAçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å°†åŠ¨ä½œé¢„æµ‹ç›´æ¥åŸºäºç›¸æœºè§‚å¯Ÿç©ºé—´ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•ä¸­å­˜åœ¨çš„ç©ºé—´ä¸ä¸€è‡´é—®é¢˜ã€‚è¿™ä¸€è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨ä¸åŒè§†è§’ä¸‹çš„é¢„æµ‹æ›´åŠ ä¸€è‡´å’Œå‡†ç¡®ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒOC-VLAé‡‡ç”¨äº†è½»é‡çº§çš„ç½‘ç»œç»“æ„ï¼Œç¡®ä¿äº†ä¸ç°æœ‰VLAæ¶æ„çš„å…¼å®¹æ€§ï¼Œä¸”æ— éœ€è¿›è¡Œå¤§å¹…åº¦ä¿®æ”¹ã€‚åŒæ—¶ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†ä¸åŒè§†è§’ä¸‹çš„é¢„æµ‹ä¸€è‡´æ€§ï¼Œä»¥æé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒOC-VLAæ¡†æ¶åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®çš„æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­æ˜¾è‘—åŠ é€Ÿäº†æ”¶æ•›ï¼Œä»»åŠ¡æˆåŠŸç‡æé«˜äº†çº¦20%ï¼Œå¹¶ä¸”åœ¨è·¨è§†è§’æ³›åŒ–èƒ½åŠ›ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æœ‰æ˜æ˜¾æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§ç­‰åœºæ™¯ã€‚é€šè¿‡æé«˜æ¨¡å‹åœ¨ä¸åŒè§†è§’ä¸‹çš„æ³›åŒ–èƒ½åŠ›ï¼ŒOC-VLAæ¡†æ¶èƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­å®ç°æ›´é«˜çš„ä»»åŠ¡æˆåŠŸç‡å’Œæ•ˆç‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-Language-Action (VLA) models frequently encounter challenges in generalizing to real-world environments due to inherent discrepancies between observation and action spaces. Although training data are collected from diverse camera perspectives, the models typically predict end-effector poses within the robot base coordinate frame, resulting in spatial inconsistencies. To mitigate this limitation, we introduce the Observation-Centric VLA (OC-VLA) framework, which grounds action predictions directly in the camera observation space. Leveraging the camera's extrinsic calibration matrix, OC-VLA transforms end-effector poses from the robot base coordinate system into the camera coordinate system, thereby unifying prediction targets across heterogeneous viewpoints. This lightweight, plug-and-play strategy ensures robust alignment between perception and action, substantially improving model resilience to camera viewpoint variations. The proposed approach is readily compatible with existing VLA architectures, requiring no substantial modifications. Comprehensive evaluations on both simulated and real-world robotic manipulation tasks demonstrate that OC-VLA accelerates convergence, enhances task success rates, and improves cross-view generalization. The code will be publicly available.

