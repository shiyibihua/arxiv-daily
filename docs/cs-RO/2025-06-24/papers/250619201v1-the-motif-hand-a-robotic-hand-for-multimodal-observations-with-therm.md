---
layout: default
title: The MOTIF Hand: A Robotic Hand for Multimodal Observations with Thermal, Inertial, and Force Sensors
---

# The MOTIF Hand: A Robotic Hand for Multimodal Observations with Thermal, Inertial, and Force Sensors

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.19201" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.19201v1</a>
  <a href="https://arxiv.org/pdf/2506.19201.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.19201v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.19201v1', 'The MOTIF Hand: A Robotic Hand for Multimodal Observations with Thermal, Inertial, and Force Sensors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hanyang Zhou, Haozhe Lou, Wenhao Liu, Enyu Zhao, Yue Wang, Daniel Seita

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-24

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMOTIFæ‰‹ä»¥è§£å†³å¤šæ¨¡æ€ä¼ æ„Ÿå™¨é›†æˆä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€ä¼ æ„Ÿå™¨` `æœºå™¨äººæ‰‹` `çƒ­æˆåƒ` `æ·±åº¦æ„ŸçŸ¥` `çµå·§æ“ä½œ` `å®‰å…¨æŠ“å–` `ç‰©ä½“è¯†åˆ«`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæŒ‡æœºå™¨äººæ‰‹åœ¨çƒ­ä¼ æ„Ÿå’Œæ‰­çŸ©æ„ŸçŸ¥æ–¹é¢èƒ½åŠ›ä¸è¶³ï¼Œé™åˆ¶äº†å…¶çµå·§æ“ä½œçš„åº”ç”¨ã€‚
2. MOTIFæ‰‹é€šè¿‡é›†æˆå¤šç§ä¼ æ„Ÿå™¨ï¼ˆå¦‚çƒ­æˆåƒã€æ·±åº¦ä¼ æ„Ÿå™¨ç­‰ï¼‰æ¥å¢å¼ºæœºå™¨äººæ‰‹çš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œä»¥å®ç°æ›´å¤æ‚çš„æ“ä½œã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒMOTIFæ‰‹åœ¨å®‰å…¨æŠ“å–å’Œç‰©ä½“è¯†åˆ«æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†å¤–è§‚ç›¸åŒä½†è´¨é‡ä¸åŒçš„ç‰©ä½“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤šæŒ‡æœºå™¨äººæ‰‹çš„çµå·§æ“ä½œéœ€æ±‚å¢åŠ ï¼Œç°æœ‰è®¾è®¡åœ¨çƒ­ä¼ æ„Ÿå’Œæ‰­çŸ©æ„ŸçŸ¥æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚æœ¬ç ”ç©¶æå‡ºäº†MOTIFæ‰‹ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„å¤šæ¨¡æ€æœºå™¨äººæ‰‹ï¼Œæ‰©å±•äº†LEAPæ‰‹çš„åŠŸèƒ½ï¼Œé›†æˆäº†å¯†é›†çš„è§¦è§‰ä¿¡æ¯ã€æ·±åº¦ä¼ æ„Ÿå™¨ã€çƒ­æˆåƒç›¸æœºã€IMUä¼ æ„Ÿå™¨å’Œè§†è§‰ä¼ æ„Ÿå™¨ã€‚MOTIFæ‰‹è®¾è®¡ç›¸å¯¹ä½æˆæœ¬ï¼ˆä½äº4000ç¾å…ƒï¼‰ä¸”æ˜“äºå¤åˆ¶ã€‚é€šè¿‡å®éªŒéªŒè¯äº†å…¶åœ¨ä¸¤ä¸ªä»£è¡¨æ€§ä»»åŠ¡ä¸­çš„å¤šæ¨¡æ€æ„ŸçŸ¥èƒ½åŠ›ï¼šé¦–å…ˆï¼Œå°†çƒ­æ„ŸçŸ¥é›†æˆåˆ°3Dé‡å»ºä¸­ï¼Œä»¥æŒ‡å¯¼æ¸©åº¦æ„ŸçŸ¥çš„å®‰å…¨æŠ“å–ï¼›å…¶æ¬¡ï¼Œå±•ç¤ºäº†è¯¥æ‰‹èƒ½å¤ŸåŒºåˆ†å¤–è§‚ç›¸åŒä½†è´¨é‡ä¸åŒçš„ç‰©ä½“ï¼Œè¶…è¶Šäº†ä»…ä¾èµ–è§†è§‰çš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæŒ‡æœºå™¨äººæ‰‹åœ¨çƒ­ä¼ æ„Ÿå’Œæ‰­çŸ©æ„ŸçŸ¥æ–¹é¢çš„ä¸è¶³ï¼Œå¯¼è‡´å…¶åœ¨å¤æ‚æ“ä½œä¸­çš„å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºMOTIFæ‰‹ï¼Œé€šè¿‡é›†æˆå¤šç§ä¼ æ„Ÿå™¨ï¼ˆå¦‚çƒ­æˆåƒã€æ·±åº¦ä¼ æ„Ÿå™¨ç­‰ï¼‰ï¼Œå¢å¼ºæœºå™¨äººæ‰‹çš„å¤šæ¨¡æ€æ„ŸçŸ¥èƒ½åŠ›ï¼Œä»¥å®ç°æ›´çµæ´»å’Œå®‰å…¨çš„æŠ“å–æ“ä½œã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMOTIFæ‰‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šå¯†é›†è§¦è§‰ä¼ æ„Ÿå™¨ã€æ·±åº¦ä¼ æ„Ÿå™¨ã€çƒ­æˆåƒç›¸æœºã€IMUä¼ æ„Ÿå™¨å’Œè§†è§‰ä¼ æ„Ÿå™¨ï¼Œå„æ¨¡å—ååŒå·¥ä½œä»¥æä¾›ä¸°å¯Œçš„ç¯å¢ƒä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šMOTIFæ‰‹çš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶å¤šæ¨¡æ€ä¼ æ„Ÿå™¨çš„é›†æˆï¼Œç‰¹åˆ«æ˜¯çƒ­æˆåƒå’Œæ·±åº¦æ„ŸçŸ¥çš„ç»“åˆï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œæ¸©åº¦æ„ŸçŸ¥çš„å®‰å…¨æŠ“å–ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿä»…ä¾èµ–è§†è§‰çš„æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒMOTIFæ‰‹çš„ä¼ æ„Ÿå™¨å¸ƒå±€ç»è¿‡ç²¾å¿ƒè§„åˆ’ï¼Œä»¥ç¡®ä¿å„ä¼ æ„Ÿå™¨ä¹‹é—´çš„ååŒå·¥ä½œï¼Œæ­¤å¤–ï¼Œé‡‡ç”¨äº†é€‚åˆçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ä¼˜åŒ–å¤šæ¨¡æ€æ•°æ®çš„èåˆå’Œå¤„ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMOTIFæ‰‹åœ¨å®‰å…¨æŠ“å–ä»»åŠ¡ä¸­ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨çƒ­ä¼ æ„Ÿä¿¡æ¯è¿›è¡Œ3Dé‡å»ºï¼Œæå‡äº†æŠ“å–çš„å®‰å…¨æ€§å’Œå‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒMOTIFæ‰‹åœ¨åŒºåˆ†å¤–è§‚ç›¸åŒä½†è´¨é‡ä¸åŒçš„ç‰©ä½“æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºä¼ ç»Ÿè§†è§‰æ–¹æ³•ï¼Œè¯†åˆ«å‡†ç¡®ç‡æ˜¾è‘—æé«˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MOTIFæ‰‹çš„è®¾è®¡å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦ç²¾ç»†æ“ä½œå’Œç¯å¢ƒæ„ŸçŸ¥çš„é¢†åŸŸï¼Œå¦‚åŒ»ç–—æœºå™¨äººã€æœåŠ¡æœºå™¨äººå’Œå·¥ä¸šè‡ªåŠ¨åŒ–ã€‚å…¶å¤šæ¨¡æ€æ„ŸçŸ¥èƒ½åŠ›å°†æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œå®‰å…¨æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Advancing dexterous manipulation with multi-fingered robotic hands requires rich sensory capabilities, while existing designs lack onboard thermal and torque sensing. In this work, we propose the MOTIF hand, a novel multimodal and versatile robotic hand that extends the LEAP hand by integrating: (i) dense tactile information across the fingers, (ii) a depth sensor, (iii) a thermal camera, (iv), IMU sensors, and (v) a visual sensor. The MOTIF hand is designed to be relatively low-cost (under 4000 USD) and easily reproducible. We validate our hand design through experiments that leverage its multimodal sensing for two representative tasks. First, we integrate thermal sensing into 3D reconstruction to guide temperature-aware, safe grasping. Second, we show how our hand can distinguish objects with identical appearance but different masses - a capability beyond methods that use vision only.

