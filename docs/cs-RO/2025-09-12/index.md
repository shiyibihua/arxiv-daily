---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-09-12
---

# cs.ROï¼ˆ2025-09-12ï¼‰

ğŸ“Š å…± **12** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (7 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting" class="interest-badge">æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (7 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250910416v1-tasc-task-aware-shared-control-for-teleoperated-manipulation.html">TASC: Task-Aware Shared Control for Teleoperated Manipulation</a></td>
  <td>TASCï¼šé¢å‘é¥æ“ä½œçš„ã€ä»»åŠ¡æ„ŸçŸ¥çš„å…±äº«æ§åˆ¶ï¼Œå®ç°é›¶æ ·æœ¬æ³›åŒ–</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">shared control</span> <span class="paper-tag">open-vocabulary</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10416v1" data-paper-url="./papers/250910416v1-tasc-task-aware-shared-control-for-teleoperated-manipulation.html" onclick="toggleFavorite(this, '2509.10416v1', 'TASC: Task-Aware Shared Control for Teleoperated Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250910128v2-efficient-learning-based-control-of-a-legged-robot-in-lunar-gravity.html">Efficient Learning-Based Control of a Legged Robot in Lunar Gravity</a></td>
  <td>æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„è…¿å¼æœºå™¨äººé‡åŠ›è‡ªé€‚åº”æ§åˆ¶æ–¹æ³•ï¼Œä¼˜åŒ–æœˆçƒç­‰ä½é‡åŠ›ç¯å¢ƒä¸‹çš„èƒ½è€—ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">legged robot</span> <span class="paper-tag">legged locomotion</span> <span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10128v2" data-paper-url="./papers/250910128v2-efficient-learning-based-control-of-a-legged-robot-in-lunar-gravity.html" onclick="toggleFavorite(this, '2509.10128v2', 'Efficient Learning-Based Control of a Legged Robot in Lunar Gravity')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250910692v1-stl-based-motion-planning-and-uncertainty-aware-risk-analysis-for-hu.html">STL-Based Motion Planning and Uncertainty-Aware Risk Analysis for Human-Robot Collaboration with a Multi-Rotor Aerial Vehicle</a></td>
  <td>æå‡ºåŸºäºSTLçš„å¤šæ—‹ç¿¼äººæœºåä½œè¿åŠ¨è§„åˆ’ä¸ä¸ç¡®å®šæ€§é£é™©åˆ†ææ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10692v1" data-paper-url="./papers/250910692v1-stl-based-motion-planning-and-uncertainty-aware-risk-analysis-for-hu.html" onclick="toggleFavorite(this, '2509.10692v1', 'STL-Based Motion Planning and Uncertainty-Aware Risk Analysis for Human-Robot Collaboration with a Multi-Rotor Aerial Vehicle')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250910444v1-coordinated-motion-planning-of-a-wearable-multi-limb-system-for-enha.html">Coordinated Motion Planning of a Wearable Multi-Limb System for Enhanced Human-Robot Interaction</a></td>
  <td>æå‡ºä¸€ç§å¯ç©¿æˆ´å¤šè‚¢æœºå™¨äººçš„ååŒè¿åŠ¨è§„åˆ’æ–¹æ³•ï¼Œé™ä½äººæœºäº¤äº’åŠ›çŸ©</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10444v1" data-paper-url="./papers/250910444v1-coordinated-motion-planning-of-a-wearable-multi-limb-system-for-enha.html" onclick="toggleFavorite(this, '2509.10444v1', 'Coordinated Motion Planning of a Wearable Multi-Limb System for Enhanced Human-Robot Interaction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250910065v2-prespecified-performance-kinematic-tracking-control-for-aerial-manip.html">Prespecified-Performance Kinematic Tracking Control for Aerial Manipulation</a></td>
  <td>é’ˆå¯¹ç©ºä¸­æœºæ¢°è‡‚ï¼Œæå‡ºé¢„è®¾æ€§èƒ½çš„æœ«ç«¯æ‰§è¡Œå™¨è¿åŠ¨å­¦è·Ÿè¸ªæ§åˆ¶æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10065v2" data-paper-url="./papers/250910065v2-prespecified-performance-kinematic-tracking-control-for-aerial-manip.html" onclick="toggleFavorite(this, '2509.10065v2', 'Prespecified-Performance Kinematic Tracking Control for Aerial Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250910032v1-design-and-evaluation-of-two-spherical-systems-for-mobile-3d-mapping.html">Design and Evaluation of Two Spherical Systems for Mobile 3D Mapping</a></td>
  <td>è®¾è®¡å¹¶è¯„ä¼°ä¸¤ç§ç”¨äºç§»åŠ¨3Dåœ°å›¾æ„å»ºçš„çƒå½¢æœºå™¨äººç³»ç»Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span> <span class="paper-tag">LIO</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10032v1" data-paper-url="./papers/250910032v1-design-and-evaluation-of-two-spherical-systems-for-mobile-3d-mapping.html" onclick="toggleFavorite(this, '2509.10032v1', 'Design and Evaluation of Two Spherical Systems for Mobile 3D Mapping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250910012v1-towards-simulation-based-optimization-of-compliant-fingers-for-high-.html">Towards simulation-based optimization of compliant fingers for high-speed connector assembly</a></td>
  <td>æå‡ºåŸºäºä»¿çœŸçš„æŸ”æ€§æ‰‹æŒ‡ä¼˜åŒ–æ–¹æ³•ï¼Œæå‡é«˜é€Ÿè¿æ¥å™¨è£…é…çš„é²æ£’æ€§</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10012v1" data-paper-url="./papers/250910012v1-towards-simulation-based-optimization-of-compliant-fingers-for-high-.html" onclick="toggleFavorite(this, '2509.10012v1', 'Towards simulation-based optimization of compliant fingers for high-speed connector assembly')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>8</td>
  <td><a href="./papers/250910247v1-diffaero-a-gpu-accelerated-differentiable-simulation-framework-for-e.html">DiffAero: A GPU-Accelerated Differentiable Simulation Framework for Efficient Quadrotor Policy Learning</a></td>
  <td>DiffAeroï¼šç”¨äºé«˜æ•ˆå››æ—‹ç¿¼ç­–ç•¥å­¦ä¹ çš„GPUåŠ é€Ÿå¯å¾®ä»¿çœŸæ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">policy learning</span> <span class="paper-tag">differentiable simulation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10247v1" data-paper-url="./papers/250910247v1-diffaero-a-gpu-accelerated-differentiable-simulation-framework-for-e.html" onclick="toggleFavorite(this, '2509.10247v1', 'DiffAero: A GPU-Accelerated Differentiable Simulation Framework for Efficient Quadrotor Policy Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250910305v1-gundamq-multi-scale-spatio-temporal-representation-learning-for-robu.html">GundamQ: Multi-Scale Spatio-Temporal Representation Learning for Robust Robot Path Planning</a></td>
  <td>GundamQï¼šå¤šå°ºåº¦æ—¶ç©ºè¡¨å¾å­¦ä¹ æå‡æœºå™¨äººé²æ£’è·¯å¾„è§„åˆ’èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">representation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10305v1" data-paper-url="./papers/250910305v1-gundamq-multi-scale-spatio-temporal-representation-learning-for-robu.html" onclick="toggleFavorite(this, '2509.10305v1', 'GundamQ: Multi-Scale Spatio-Temporal Representation Learning for Robust Robot Path Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting">ğŸ”¬ æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>10</td>
  <td><a href="./papers/250910454v1-gc-vln-instruction-as-graph-constraints-for-training-free-vision-and.html">GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation</a></td>
  <td>æå‡ºåŸºäºå›¾çº¦æŸä¼˜åŒ–çš„å…è®­ç»ƒè§†è§‰è¯­è¨€å¯¼èˆªæ¡†æ¶ï¼Œè§£å†³çœŸå®åœºæ™¯æ³›åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">spatial relationship</span> <span class="paper-tag">VLN</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10454v1" data-paper-url="./papers/250910454v1-gc-vln-instruction-as-graph-constraints-for-training-free-vision-and.html" onclick="toggleFavorite(this, '2509.10454v1', 'GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>11</td>
  <td><a href="./papers/250910405v1-self-supervised-learning-of-visual-pose-estimation-without-pose-labe.html">Self-supervised Learning Of Visual Pose Estimation Without Pose Labels By Classifying LED States</a></td>
  <td>æå‡ºä¸€ç§åŸºäºLEDçŠ¶æ€åˆ†ç±»çš„è‡ªç›‘ç£è§†è§‰ä½å§¿ä¼°è®¡æ–¹æ³•ï¼Œæ— éœ€ä½å§¿æ ‡ç­¾ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">depth estimation</span> <span class="paper-tag">monocular depth</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10405v1" data-paper-url="./papers/250910405v1-self-supervised-learning-of-visual-pose-estimation-without-pose-labe.html" onclick="toggleFavorite(this, '2509.10405v1', 'Self-supervised Learning Of Visual Pose Estimation Without Pose Labels By Classifying LED States')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>12</td>
  <td><a href="./papers/250910317v1-robot-guide-with-multi-agent-control-and-automatic-scenario-generati.html">Robot guide with multi-agent control and automatic scenario generation with LLM</a></td>
  <td>æå‡ºåŸºäºLLMè‡ªåŠ¨ç”Ÿæˆåœºæ™¯çš„å¤šæ™ºèƒ½ä½“å¯¼æ¸¸æœºå™¨äººæ§åˆ¶æ¶æ„</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10317v1" data-paper-url="./papers/250910317v1-robot-guide-with-multi-agent-control-and-automatic-scenario-generati.html" onclick="toggleFavorite(this, '2509.10317v1', 'Robot guide with multi-agent control and automatic scenario generation with LLM')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)