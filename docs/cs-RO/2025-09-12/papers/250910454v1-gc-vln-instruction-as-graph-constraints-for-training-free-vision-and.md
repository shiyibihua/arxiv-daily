---
layout: default
title: GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation
---

# GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10454" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.10454v1</a>
  <a href="https://arxiv.org/pdf/2509.10454.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10454v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10454v1', 'GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hang Yin, Haoyu Wei, Xiuwei Xu, Wenxuan Guo, Jie Zhou, Jiwen Lu

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-12

**å¤‡æ³¨**: Accepted to CoRL 2025. Project page: [this https URL](https://bagh2178.github.io/GC-VLN/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå›¾çº¦æŸä¼˜åŒ–çš„å…è®­ç»ƒè§†è§‰è¯­è¨€å¯¼èˆªæ¡†æ¶ï¼Œè§£å†³çœŸå®åœºæ™¯æ³›åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€å¯¼èˆª` `é›¶æ ·æœ¬å­¦ä¹ ` `å›¾çº¦æŸä¼˜åŒ–` `æœºå™¨äººå¯¼èˆª` `ç©ºé—´æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é›¶æ ·æœ¬VLNæ–¹æ³•éš¾ä»¥æ³›åŒ–åˆ°çœŸå®è¿ç»­ç¯å¢ƒï¼Œä¸»è¦åŸå› æ˜¯ä¾èµ–ç¦»æ•£ç¯å¢ƒæˆ–æ¨¡æ‹Ÿå™¨ä¸­çš„æ— ç›‘ç£è®­ç»ƒã€‚
2. è®ºæ–‡æå‡ºå°†å¯¼èˆªæŒ‡ä»¤åˆ†è§£ä¸ºç©ºé—´çº¦æŸï¼Œæ„å»ºå›¾çº¦æŸä¼˜åŒ–é—®é¢˜ï¼Œé€šè¿‡çº¦æŸæ±‚è§£å®ç°é›¶æ ·æœ¬å¯¼èˆªã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ ‡å‡†åŸºå‡†ä¸Šæ˜¾è‘—æå‡äº†æˆåŠŸç‡å’Œå¯¼èˆªæ•ˆç‡ï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§å…è®­ç»ƒçš„è§†è§‰è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰æ¡†æ¶ã€‚ç°æœ‰çš„é›¶æ ·æœ¬VLNæ–¹æ³•ä¸»è¦é’ˆå¯¹ç¦»æ•£ç¯å¢ƒï¼Œæˆ–æ¶‰åŠåœ¨è¿ç»­æ¨¡æ‹Ÿå™¨ç¯å¢ƒä¸­çš„æ— ç›‘ç£è®­ç»ƒï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥æ³›åŒ–å¹¶éƒ¨ç½²åˆ°çœŸå®åœºæ™¯ä¸­ã€‚ä¸ºäº†åœ¨è¿ç»­ç¯å¢ƒä¸­å®ç°å…è®­ç»ƒæ¡†æ¶ï¼Œæˆ‘ä»¬çš„æ¡†æ¶é€šè¿‡å°†æŒ‡ä»¤åˆ†è§£ä¸ºæ˜¾å¼çš„ç©ºé—´çº¦æŸï¼Œå°†å¯¼èˆªå¼•å¯¼å»ºæ¨¡ä¸ºå›¾çº¦æŸä¼˜åŒ–é—®é¢˜ã€‚è¿™ç§çº¦æŸé©±åŠ¨çš„èŒƒå¼é€šè¿‡çº¦æŸæ±‚è§£æ¥è§£ç ç©ºé—´è¯­ä¹‰ï¼Œä»è€Œå®ç°å¯¹æœªè§ç¯å¢ƒçš„é›¶æ ·æœ¬é€‚åº”ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªç©ºé—´çº¦æŸåº“ï¼Œæ¶µç›–äº†VLNæŒ‡ä»¤ä¸­æåˆ°çš„æ‰€æœ‰ç±»å‹çš„ç©ºé—´å…³ç³»ã€‚äººç±»æŒ‡ä»¤è¢«åˆ†è§£ä¸ºä¸€ä¸ªæœ‰å‘æ— ç¯å›¾ï¼ŒåŒ…å«è·¯æ ‡èŠ‚ç‚¹ã€å¯¹è±¡èŠ‚ç‚¹å’Œè¾¹ï¼Œè¿™äº›èŠ‚ç‚¹å’Œè¾¹è¢«ç”¨ä½œæŸ¥è¯¢æ¥æ£€ç´¢åº“ï¼Œä»è€Œæ„å»ºå›¾çº¦æŸã€‚å›¾çº¦æŸä¼˜åŒ–é€šè¿‡çº¦æŸæ±‚è§£å™¨æ¥ç¡®å®šè·¯æ ‡çš„ä½ç½®ï¼Œä»è€Œè·å¾—æœºå™¨äººçš„å¯¼èˆªè·¯å¾„å’Œæœ€ç»ˆç›®æ ‡ã€‚ä¸ºäº†å¤„ç†æ— è§£æˆ–å¤šè§£çš„æƒ…å†µï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¯¼èˆªæ ‘å’Œå›æº¯æœºåˆ¶ã€‚åœ¨æ ‡å‡†åŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„é›¶æ ·æœ¬VLNæ–¹æ³•ç›¸æ¯”ï¼ŒæˆåŠŸç‡å’Œå¯¼èˆªæ•ˆç‡éƒ½æœ‰æ˜¾è‘—æé«˜ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¿›è¡Œäº†çœŸå®ä¸–ç•Œçš„å®éªŒï¼Œè¡¨æ˜æˆ‘ä»¬çš„æ¡†æ¶å¯ä»¥æœ‰æ•ˆåœ°æ¨å¹¿åˆ°æ–°çš„ç¯å¢ƒå’ŒæŒ‡ä»¤é›†ï¼Œä¸ºæ›´é²æ£’å’Œè‡ªä¸»çš„å¯¼èˆªæ¡†æ¶é“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è§†è§‰è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰æ–¹æ³•ï¼Œå°¤å…¶æ˜¯é›¶æ ·æœ¬æ–¹æ³•ï¼Œåœ¨çœŸå®è¿ç»­ç¯å¢ƒä¸­æ³›åŒ–èƒ½åŠ›è¾ƒå¼±ã€‚ä¸»è¦åŸå› æ˜¯è¿™äº›æ–¹æ³•ä¾èµ–äºç¦»æ•£ç¯å¢ƒæˆ–è€…éœ€è¦åœ¨è¿ç»­æ¨¡æ‹Ÿå™¨ç¯å¢ƒä¸­è¿›è¡Œæ— ç›‘ç£è®­ç»ƒï¼Œè¿™ä¸çœŸå®ä¸–ç•Œçš„å¤æ‚æ€§å’Œå¤šæ ·æ€§å­˜åœ¨å·®è·ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨æ— éœ€è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œä½¿VLNæ¨¡å‹èƒ½å¤Ÿé€‚åº”æ–°çš„ã€æœªè§è¿‡çš„çœŸå®ç¯å¢ƒæ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¯¼èˆªæŒ‡ä»¤è½¬åŒ–ä¸ºç©ºé—´çº¦æŸï¼Œå¹¶åˆ©ç”¨å›¾çº¦æŸä¼˜åŒ–æ¥æ±‚è§£å¯¼èˆªè·¯å¾„ã€‚å…·ä½“æ¥è¯´ï¼Œå°†å¤æ‚çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤åˆ†è§£ä¸ºä¸€ç³»åˆ—æ˜ç¡®çš„ç©ºé—´å…³ç³»ï¼Œä¾‹å¦‚â€œç›´èµ°åˆ°æ¡Œå­æ—â€ã€â€œå·¦è½¬åˆ°æ¤…å­åé¢â€ç­‰ï¼Œå¹¶å°†è¿™äº›å…³ç³»è½¬åŒ–ä¸ºæœºå™¨äººè¿åŠ¨çš„çº¦æŸæ¡ä»¶ã€‚é€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«è·¯æ ‡èŠ‚ç‚¹ã€å¯¹è±¡èŠ‚ç‚¹å’Œè¾¹çš„æœ‰å‘æ— ç¯å›¾ï¼Œå°†å¯¼èˆªé—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªå›¾çº¦æŸä¼˜åŒ–é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) æŒ‡ä»¤è§£ææ¨¡å—ï¼šå°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤è§£æä¸ºåŒ…å«ç©ºé—´å…³ç³»çš„ç»“æ„åŒ–è¡¨ç¤ºï¼›2) ç©ºé—´çº¦æŸåº“ï¼šé¢„å…ˆæ„å»ºä¸€ä¸ªåŒ…å«å„ç§ç©ºé—´å…³ç³»çš„çº¦æŸåº“ï¼Œä¾‹å¦‚â€œåœ¨...æ—è¾¹â€ã€â€œåœ¨...å‰é¢â€ç­‰ï¼›3) å›¾æ„å»ºæ¨¡å—ï¼šæ ¹æ®è§£æåçš„æŒ‡ä»¤ï¼Œä»ç©ºé—´çº¦æŸåº“ä¸­æ£€ç´¢ç›¸åº”çš„çº¦æŸï¼Œæ„å»ºä¸€ä¸ªæœ‰å‘æ— ç¯å›¾ï¼Œå…¶ä¸­èŠ‚ç‚¹è¡¨ç¤ºè·¯æ ‡æˆ–å¯¹è±¡ï¼Œè¾¹è¡¨ç¤ºç©ºé—´çº¦æŸï¼›4) å›¾çº¦æŸä¼˜åŒ–æ¨¡å—ï¼šåˆ©ç”¨çº¦æŸæ±‚è§£å™¨ï¼Œæ±‚è§£å›¾çº¦æŸä¼˜åŒ–é—®é¢˜ï¼Œå¾—åˆ°è·¯æ ‡çš„ä½ç½®ï¼Œä»è€Œè§„åˆ’å‡ºå¯¼èˆªè·¯å¾„ï¼›5) å¯¼èˆªæ ‘ä¸å›æº¯æœºåˆ¶ï¼šä¸ºäº†å¤„ç†æ— è§£æˆ–å¤šè§£çš„æƒ…å†µï¼Œæ„å»ºå¯¼èˆªæ ‘ï¼Œå¹¶é‡‡ç”¨å›æº¯æœºåˆ¶è¿›è¡Œæœç´¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†å¯¼èˆªé—®é¢˜è½¬åŒ–ä¸ºå›¾çº¦æŸä¼˜åŒ–é—®é¢˜ï¼Œå¹¶åˆ©ç”¨çº¦æŸæ±‚è§£å™¨æ¥æ±‚è§£å¯¼èˆªè·¯å¾„ã€‚è¿™ç§æ–¹æ³•æ— éœ€è®­ç»ƒï¼Œå¯ä»¥ç›´æ¥åº”ç”¨äºæ–°çš„ã€æœªè§è¿‡çš„ç¯å¢ƒã€‚ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºè®­ç»ƒæ•°æ®æ¥å­¦ä¹ å¯¼èˆªç­–ç•¥ï¼Œè€Œè¯¥æ–¹æ³•åˆ™é€šè¿‡æ˜¾å¼çš„ç©ºé—´çº¦æŸæ¥æŒ‡å¯¼å¯¼èˆªã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç©ºé—´çº¦æŸåº“çš„æ„å»ºï¼Œéœ€è¦è¦†ç›–VLNæŒ‡ä»¤ä¸­å¸¸è§çš„ç©ºé—´å…³ç³»ï¼›2) å›¾çº¦æŸä¼˜åŒ–é—®é¢˜çš„å»ºæ¨¡ï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„çº¦æŸæ±‚è§£å™¨ï¼›3) å¯¼èˆªæ ‘çš„æ„å»ºå’Œå›æº¯æœºåˆ¶çš„è®¾è®¡ï¼Œéœ€è¦å¹³è¡¡æœç´¢æ•ˆç‡å’Œå¯¼èˆªç²¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ ‡å‡†VLNåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸æœ€å…ˆè¿›çš„é›¶æ ·æœ¬VLNæ–¹æ³•ç›¸æ¯”ï¼ŒæˆåŠŸç‡å’Œå¯¼èˆªæ•ˆç‡å‡æœ‰æ˜æ˜¾æé«˜ã€‚æ­¤å¤–ï¼Œåœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­çš„å®éªŒä¹ŸéªŒè¯äº†è¯¥æ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¡¨æ˜å…¶èƒ½å¤Ÿæœ‰æ•ˆåœ°é€‚åº”æ–°çš„ç¯å¢ƒå’ŒæŒ‡ä»¤é›†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººè‡ªä¸»å¯¼èˆªã€æ™ºèƒ½å®¶å±…ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½å®¶å±…ä¸­ï¼Œæœºå™¨äººå¯ä»¥æ ¹æ®ç”¨æˆ·çš„è¯­éŸ³æŒ‡ä»¤ï¼Œè‡ªä¸»å¯¼èˆªåˆ°æŒ‡å®šä½ç½®ï¼Œå®Œæˆå„ç§ä»»åŠ¡ã€‚åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”¨äºè§£æä¹˜å®¢çš„å¯¼èˆªæŒ‡ä»¤ï¼Œè§„åˆ’è¡Œé©¶è·¯çº¿ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°æ›´é²æ£’ã€æ›´è‡ªä¸»çš„å¯¼èˆªç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this paper, we propose a training-free framework for vision-and-language navigation (VLN). Existing zero-shot VLN methods are mainly designed for discrete environments or involve unsupervised training in continuous simulator environments, which makes it challenging to generalize and deploy them in real-world scenarios. To achieve a training-free framework in continuous environments, our framework formulates navigation guidance as graph constraint optimization by decomposing instructions into explicit spatial constraints. The constraint-driven paradigm decodes spatial semantics through constraint solving, enabling zero-shot adaptation to unseen environments. Specifically, we construct a spatial constraint library covering all types of spatial relationship mentioned in VLN instructions. The human instruction is decomposed into a directed acyclic graph, with waypoint nodes, object nodes and edges, which are used as queries to retrieve the library to build the graph constraints. The graph constraint optimization is solved by the constraint solver to determine the positions of waypoints, obtaining the robot's navigation path and final goal. To handle cases of no solution or multiple solutions, we construct a navigation tree and the backtracking mechanism. Extensive experiments on standard benchmarks demonstrate significant improvements in success rate and navigation efficiency compared to state-of-the-art zero-shot VLN methods. We further conduct real-world experiments to show that our framework can effectively generalize to new environments and instruction sets, paving the way for a more robust and autonomous navigation framework.

