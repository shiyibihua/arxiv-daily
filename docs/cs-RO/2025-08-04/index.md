---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-08-04
---

# cs.ROï¼ˆ2025-08-04ï¼‰

ğŸ“Š å…± **22** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (18 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (18 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250802194v1-constrained-reinforcement-learning-for-unstable-point-feet-bipedal-l.html">Constrained Reinforcement Learning for Unstable Point-Feet Bipedal Locomotion Applied to the Bolt Robot</a></td>
  <td>æå‡ºçº¦æŸå¼ºåŒ–å­¦ä¹ ä»¥è§£å†³ä¸ç¨³å®šç‚¹è¶³åŒè¶³æœºå™¨äººè¡Œèµ°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">bipedal</span> <span class="paper-tag">biped</span> <span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02194v1" data-paper-url="./papers/250802194v1-constrained-reinforcement-learning-for-unstable-point-feet-bipedal-l.html" onclick="toggleFavorite(this, '2508.02194v1', 'Constrained Reinforcement Learning for Unstable Point-Feet Bipedal Locomotion Applied to the Bolt Robot')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250802190v1-fedvla-federated-vision-language-action-learning-with-dual-gating-mi.html">FedVLA: Federated Vision-Language-Action Learning with Dual Gating Mixture-of-Experts for Robotic Manipulation</a></td>
  <td>æå‡ºFedVLAä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­çš„æ•°æ®éšç§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">representation learning</span> <span class="paper-tag">vision-language-action</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02190v1" data-paper-url="./papers/250802190v1-fedvla-federated-vision-language-action-learning-with-dual-gating-mi.html" onclick="toggleFavorite(this, '2508.02190v1', 'FedVLA: Federated Vision-Language-Action Learning with Dual Gating Mixture-of-Experts for Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250802062v1-ricl-adding-in-context-adaptability-to-pre-trained-vision-language-a.html">RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models</a></td>
  <td>æå‡ºRICLä»¥è§£å†³VLAæ¨¡å‹ç¼ºä¹ä¸Šä¸‹æ–‡é€‚åº”æ€§çš„é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">imitation learning</span> <span class="paper-tag">vision-language-action</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02062v1" data-paper-url="./papers/250802062v1-ricl-adding-in-context-adaptability-to-pre-trained-vision-language-a.html" onclick="toggleFavorite(this, '2508.02062v1', 'RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250802512v3-quadreamer-controllable-panoramic-video-generation-for-quadruped-rob.html">QuaDreamer: Controllable Panoramic Video Generation for Quadruped Robots</a></td>
  <td>æå‡ºQuaDreamerä»¥è§£å†³å››è¶³æœºå™¨äººå…¨æ™¯è§†é¢‘ç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">locomotion</span> <span class="paper-tag">dreamer</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02512v3" data-paper-url="./papers/250802512v3-quadreamer-controllable-panoramic-video-generation-for-quadruped-rob.html" onclick="toggleFavorite(this, '2508.02512v3', 'QuaDreamer: Controllable Panoramic Video Generation for Quadruped Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250802405v1-improving-generalization-of-language-conditioned-robot-manipulation.html">Improving Generalization of Language-Conditioned Robot Manipulation</a></td>
  <td>æå‡ºä¸€ç§æ–°æ¡†æ¶ä»¥æå‡è¯­è¨€æ¡ä»¶ä¸‹æœºå™¨äººæ“ä½œçš„æ³›åŒ–èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">language conditioned</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02405v1" data-paper-url="./papers/250802405v1-improving-generalization-of-language-conditioned-robot-manipulation.html" onclick="toggleFavorite(this, '2508.02405v1', 'Improving Generalization of Language-Conditioned Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250802629v2-hycodepolicy-hybrid-language-controllers-for-multimodal-monitoring-a.html">HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents</a></td>
  <td>æå‡ºHyCodePolicyä»¥è§£å†³å¤šæ¨¡æ€å†³ç­–ä¸­çš„ä»£ç æ‰§è¡Œç›‘æ§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02629v2" data-paper-url="./papers/250802629v2-hycodepolicy-hybrid-language-controllers-for-multimodal-monitoring-a.html" onclick="toggleFavorite(this, '2508.02629v2', 'HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250802505v2-would-you-let-a-humanoid-play-storytelling-with-your-child-a-usabili.html">Would you let a humanoid play storytelling with your child? A usability study on LLM-powered narrative Human-Robot Interaction</a></td>
  <td>æå‡ºä¸€ç§æ–°æ¡†æ¶ä»¥å¢å¼ºäººå½¢æœºå™¨äººåœ¨å™äº‹äº’åŠ¨ä¸­çš„ç¤¾äº¤æ„ŸçŸ¥èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02505v2" data-paper-url="./papers/250802505v2-would-you-let-a-humanoid-play-storytelling-with-your-child-a-usabili.html" onclick="toggleFavorite(this, '2508.02505v2', 'Would you let a humanoid play storytelling with your child? A usability study on LLM-powered narrative Human-Robot Interaction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250806538v1-symbolic-learning-of-interpretable-reduced-order-models-for-jumping-.html">Symbolic Learning of Interpretable Reduced-Order Models for Jumping Quadruped Robots</a></td>
  <td>æå‡ºä¸€ç§æ–°æ–¹æ³•ä»¥å®ç°è·³è·ƒå››è¶³æœºå™¨äººå¯è§£é‡Šçš„é™é˜¶æ¨¡å‹</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.06538v1" data-paper-url="./papers/250806538v1-symbolic-learning-of-interpretable-reduced-order-models-for-jumping-.html" onclick="toggleFavorite(this, '2508.06538v1', 'Symbolic Learning of Interpretable Reduced-Order Models for Jumping Quadruped Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250802287v1-framework-for-robust-motion-planning-of-tethered-multi-robot-systems.html">Framework for Robust Motion Planning of Tethered Multi-Robot Systems in Marine Environments</a></td>
  <td>æå‡ºCoralGuideæ¡†æ¶ä»¥è§£å†³æµ·æ´‹ç¯å¢ƒä¸­å¤šæœºå™¨äººç³»ç»Ÿçš„è·¯å¾„è§„åˆ’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">trajectory optimization</span> <span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02287v1" data-paper-url="./papers/250802287v1-framework-for-robust-motion-planning-of-tethered-multi-robot-systems.html" onclick="toggleFavorite(this, '2508.02287v1', 'Framework for Robust Motion Planning of Tethered Multi-Robot Systems in Marine Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250802953v1-optimal-trajectory-planning-in-a-vertically-undulating-snake-locomot.html">Optimal Trajectory Planning in a Vertically Undulating Snake Locomotion using Contact-implicit Optimization</a></td>
  <td>æå‡ºåŸºäºæ¥è§¦éšå¼ä¼˜åŒ–çš„è›‡å½¢æœºå™¨äººè½¨è¿¹è§„åˆ’æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02953v1" data-paper-url="./papers/250802953v1-optimal-trajectory-planning-in-a-vertically-undulating-snake-locomot.html" onclick="toggleFavorite(this, '2508.02953v1', 'Optimal Trajectory Planning in a Vertically Undulating Snake Locomotion using Contact-implicit Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250802649v1-manip4care-robotic-manipulation-of-human-limbs-for-solving-assistive.html">Manip4Care: Robotic Manipulation of Human Limbs for Solving Assistive Tasks</a></td>
  <td>æå‡ºManip4Careä»¥è§£å†³äººç±»è‚¢ä½“æ“æ§çš„è¾…åŠ©ä»»åŠ¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02649v1" data-paper-url="./papers/250802649v1-manip4care-robotic-manipulation-of-human-limbs-for-solving-assistive.html" onclick="toggleFavorite(this, '2508.02649v1', 'Manip4Care: Robotic Manipulation of Human Limbs for Solving Assistive Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250802350v2-adaptive-lattice-based-motion-planning.html">Adaptive Lattice-based Motion Planning</a></td>
  <td>æå‡ºè‡ªé€‚åº”æ ¼å­åŸºç¡€è¿åŠ¨è§„åˆ’ä»¥è§£å†³å¤æ‚ç¯å¢ƒä¸­çš„è½¨è¿¹ç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02350v2" data-paper-url="./papers/250802350v2-adaptive-lattice-based-motion-planning.html" onclick="toggleFavorite(this, '2508.02350v2', 'Adaptive Lattice-based Motion Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250802204v2-tacman-turbo-proactive-tactile-control-for-robust-and-efficient-arti.html">TacMan-Turbo: Proactive Tactile Control for Robust and Efficient Articulated Object Manipulation</a></td>
  <td>æå‡ºTacMan-Turboä»¥è§£å†³å…³èŠ‚ç‰©ä½“æ“æ§ä¸­çš„æ•ˆç‡ä¸æœ‰æ•ˆæ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02204v2" data-paper-url="./papers/250802204v2-tacman-turbo-proactive-tactile-control-for-robust-and-efficient-arti.html" onclick="toggleFavorite(this, '2508.02204v2', 'TacMan-Turbo: Proactive Tactile Control for Robust and Efficient Articulated Object Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250802146v2-screwsplat-an-end-to-end-method-for-articulated-object-recognition.html">ScrewSplat: An End-to-End Method for Articulated Object Recognition</a></td>
  <td>æå‡ºScrewSplatä»¥è§£å†³å…³èŠ‚ç‰©ä½“è¯†åˆ«é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">gaussian splatting</span> <span class="paper-tag">splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02146v2" data-paper-url="./papers/250802146v2-screwsplat-an-end-to-end-method-for-articulated-object-recognition.html" onclick="toggleFavorite(this, '2508.02146v2', 'ScrewSplat: An End-to-End Method for Articulated Object Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250802873v2-tunable-leg-stiffness-in-a-monopedal-hopper-for-energy-efficient-ver.html">Tunable Leg Stiffness in a Monopedal Hopper for Energy-Efficient Vertical Hopping Across Varying Ground Profiles</a></td>
  <td>æå‡ºå¯è°ƒè…¿éƒ¨åˆšåº¦çš„å•è¶³è·³è·ƒæœºå™¨äººä»¥æé«˜èƒ½æ•ˆ</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span> <span class="paper-tag">penetration</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02873v2" data-paper-url="./papers/250802873v2-tunable-leg-stiffness-in-a-monopedal-hopper-for-energy-efficient-ver.html" onclick="toggleFavorite(this, '2508.02873v2', 'Tunable Leg Stiffness in a Monopedal Hopper for Energy-Efficient Vertical Hopping Across Varying Ground Profiles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250802604v1-periodic-robust-robotic-rock-chop-via-virtual-model-control.html">Periodic robust robotic rock chop via virtual model control</a></td>
  <td>æå‡ºè™šæ‹Ÿæ¨¡å‹æ§åˆ¶æ–¹æ¡ˆä»¥å®ç°æœºå™¨äººåˆ‡å‰²çš„ç¨³å®šæ€§ä¸ç²¾ç¡®æ€§</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02604v1" data-paper-url="./papers/250802604v1-periodic-robust-robotic-rock-chop-via-virtual-model-control.html" onclick="toggleFavorite(this, '2508.02604v1', 'Periodic robust robotic rock chop via virtual model control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250802952v1-a-novel-autonomous-microplastics-surveying-robot-for-beach-environme.html">A novel autonomous microplastics surveying robot for beach environments</a></td>
  <td>æå‡ºä¸€ç§è‡ªä¸»å¾®å¡‘æ–™è°ƒæŸ¥æœºå™¨äººä»¥è§£å†³æµ·æ»©ç¯å¢ƒç›‘æµ‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02952v1" data-paper-url="./papers/250802952v1-a-novel-autonomous-microplastics-surveying-robot-for-beach-environme.html" onclick="toggleFavorite(this, '2508.02952v1', 'A novel autonomous microplastics surveying robot for beach environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250802930v1-model-agnostic-meta-learning-for-adaptive-gait-phase-and-terrain-geo.html">Model-agnostic Meta-learning for Adaptive Gait Phase and Terrain Geometry Estimation with Wearable Soft Sensors</a></td>
  <td>æå‡ºåŸºäºæ¨¡å‹æ— å…³å…ƒå­¦ä¹ çš„æ¡†æ¶ä»¥è§£å†³æ­¥æ€ç›¸ä½å’Œåœ°å½¢å‡ ä½•ä¼°è®¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02930v1" data-paper-url="./papers/250802930v1-model-agnostic-meta-learning-for-adaptive-gait-phase-and-terrain-geo.html" onclick="toggleFavorite(this, '2508.02930v1', 'Model-agnostic Meta-learning for Adaptive Gait Phase and Terrain Geometry Estimation with Wearable Soft Sensors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>19</td>
  <td><a href="./papers/250802219v1-co-rft-efficient-fine-tuning-of-vision-language-action-models-throug.html">CO-RFT: Efficient Fine-Tuning of Vision-Language-Action Models through Chunked Offline Reinforcement Learning</a></td>
  <td>æå‡ºCO-RFTä»¥è§£å†³VLAæ¨¡å‹å¾®è°ƒä¸­çš„æ ·æœ¬æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">offline RL</span> <span class="paper-tag">offline reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02219v1" data-paper-url="./papers/250802219v1-co-rft-efficient-fine-tuning-of-vision-language-action-models-throug.html" onclick="toggleFavorite(this, '2508.02219v1', 'CO-RFT: Efficient Fine-Tuning of Vision-Language-Action Models through Chunked Offline Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250802046v2-navimaster-learning-a-unified-policy-for-gui-and-embodied-navigation.html">NaviMaster: Learning a Unified Policy for GUI and Embodied Navigation Tasks</a></td>
  <td>æå‡ºNaviMasterä»¥ç»Ÿä¸€GUIä¸å®ä½“å¯¼èˆªä»»åŠ¡</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">reward design</span> <span class="paper-tag">affordance</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02046v2" data-paper-url="./papers/250802046v2-navimaster-learning-a-unified-policy-for-gui-and-embodied-navigation.html" onclick="toggleFavorite(this, '2508.02046v2', 'NaviMaster: Learning a Unified Policy for GUI and Embodied Navigation Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/250801965v1-from-photons-to-physics-autonomous-indoor-drones-and-the-future-of-o.html">From Photons to Physics: Autonomous Indoor Drones and the Future of Objective Property Assessment</a></td>
  <td>æå‡ºåŸºäºè‡ªä¸»å®¤å†…æ— äººæœºçš„å®¢è§‚ç‰©ä¸šè¯„ä¼°æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">3D gaussian splatting</span> <span class="paper-tag">gaussian splatting</span> <span class="paper-tag">splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.01965v1" data-paper-url="./papers/250801965v1-from-photons-to-physics-autonomous-indoor-drones-and-the-future-of-o.html" onclick="toggleFavorite(this, '2508.01965v1', 'From Photons to Physics: Autonomous Indoor Drones and the Future of Objective Property Assessment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>22</td>
  <td><a href="./papers/250802068v2-set-it-up-functional-object-arrangement-with-compositional-generativ.html">"Set It Up": Functional Object Arrangement with Compositional Generative Models (Journal Version)</a></td>
  <td>æå‡ºSetItUpæ¡†æ¶ä»¥è§£å†³åŠŸèƒ½æ€§ç‰©ä½“æ’åˆ—é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02068v2" data-paper-url="./papers/250802068v2-set-it-up-functional-object-arrangement-with-compositional-generativ.html" onclick="toggleFavorite(this, '2508.02068v2', '&quot;Set It Up&quot;: Functional Object Arrangement with Compositional Generative Models (Journal Version)')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)