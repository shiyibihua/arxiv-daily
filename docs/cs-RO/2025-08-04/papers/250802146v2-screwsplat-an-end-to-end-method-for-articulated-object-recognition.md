---
layout: default
title: ScrewSplat: An End-to-End Method for Articulated Object Recognition
---

# ScrewSplat: An End-to-End Method for Articulated Object Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.02146" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.02146v2</a>
  <a href="https://arxiv.org/pdf/2508.02146.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.02146v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.02146v2', 'ScrewSplat: An End-to-End Method for Articulated Object Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Seungyeon Kim, Junsu Ha, Young Hun Kim, Yonghyeon Lee, Frank C. Park

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-04 (æ›´æ–°: 2025-08-22)

**å¤‡æ³¨**: 26 pages, 12 figures, Conference on Robot Learning (CoRL) 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºScrewSplatä»¥è§£å†³å…³èŠ‚ç‰©ä½“è¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `å…³èŠ‚ç‰©ä½“è¯†åˆ«` `RGBå›¾åƒå¤„ç†` `é«˜æ–¯ç‚¹äº‘` `æœºå™¨äººæ“ä½œ` `é›¶æ ·æœ¬å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å…³èŠ‚ç‰©ä½“è¯†åˆ«æ–¹æ³•ä¾èµ–äºå¼ºå‡è®¾æˆ–é¢å¤–è¾“å…¥ï¼Œé™åˆ¶äº†å…¶åœ¨çœŸå®åœºæ™¯ä¸­çš„å®ç”¨æ€§ã€‚
2. ScrewSplatæ˜¯ä¸€ç§ç«¯åˆ°ç«¯çš„æ–¹æ³•ï¼Œä»…ä½¿ç”¨RGBå›¾åƒï¼Œé€šè¿‡ä¼˜åŒ–èºæ—‹è½´æ¥æ¢å¤ç‰©ä½“çš„è¿åŠ¨ç»“æ„ã€‚
3. è¯¥æ–¹æ³•åœ¨å¤šç§å…³èŠ‚ç‰©ä½“ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„è¯†åˆ«ç²¾åº¦ï¼Œå¹¶æ”¯æŒåŸºäºæ–‡æœ¬çš„é›¶æ ·æœ¬æ“ä½œã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…³èŠ‚ç‰©ä½“è¯†åˆ«æ˜¯è¯†åˆ«å…·æœ‰å¯åŠ¨éƒ¨ä»¶çš„ç‰©ä½“å‡ ä½•å½¢çŠ¶å’Œè¿åŠ¨å…³èŠ‚çš„ä»»åŠ¡ï¼Œå¯¹äºæœºå™¨äººä¸æ—¥å¸¸ç‰©ä½“çš„äº¤äº’è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºå¼ºå‡è®¾ï¼Œå¦‚å·²çŸ¥çš„å…³èŠ‚æ•°é‡ï¼Œæˆ–éœ€è¦é¢å¤–è¾“å…¥ï¼ˆå¦‚æ·±åº¦å›¾åƒï¼‰ï¼Œæˆ–æ¶‰åŠå¤æ‚çš„ä¸­é—´æ­¥éª¤ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§ã€‚æœ¬æ–‡æå‡ºäº†ScrewSplatï¼Œè¿™æ˜¯ä¸€ç§ç®€å•çš„ç«¯åˆ°ç«¯æ–¹æ³•ï¼Œä»…åŸºäºRGBè§‚å¯Ÿã€‚è¯¥æ–¹æ³•é€šè¿‡éšæœºåˆå§‹åŒ–èºæ—‹è½´å¹¶è¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œæ¢å¤ç‰©ä½“çš„è¿åŠ¨ç»“æ„ã€‚é€šè¿‡ä¸é«˜æ–¯ç‚¹äº‘é‡å»ºç»“åˆï¼Œæˆ‘ä»¬åŒæ—¶é‡å»º3Då‡ ä½•å½¢çŠ¶å¹¶å°†ç‰©ä½“åˆ†å‰²ä¸ºåˆšæ€§å’Œå¯åŠ¨éƒ¨ä»¶ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šæ ·åŒ–çš„å…³èŠ‚ç‰©ä½“ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„è¯†åˆ«ç²¾åº¦ï¼Œå¹¶è¿›ä¸€æ­¥æ”¯æŒåŸºäºæ–‡æœ¬çš„é›¶æ ·æœ¬æ“ä½œã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å…³èŠ‚ç‰©ä½“è¯†åˆ«çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¸¸å¸¸ä¾èµ–äºå·²çŸ¥çš„å…³èŠ‚æ•°é‡æˆ–é¢å¤–çš„æ·±åº¦ä¿¡æ¯ï¼Œå¯¼è‡´åœ¨å®é™…åº”ç”¨ä¸­å­˜åœ¨å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šScrewSplaté€šè¿‡éšæœºåˆå§‹åŒ–èºæ—‹è½´å¹¶è¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œç›´æ¥ä»RGBå›¾åƒä¸­æ¢å¤ç‰©ä½“çš„è¿åŠ¨ç»“æ„ï¼Œé¿å…äº†å¯¹é¢å¤–è¾“å…¥çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬éšæœºåˆå§‹åŒ–ã€èºæ—‹è½´ä¼˜åŒ–å’Œé«˜æ–¯ç‚¹äº‘é‡å»ºä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼Œæœ€ç»ˆå®ç°3Då‡ ä½•å½¢çŠ¶é‡å»ºå’Œç‰©ä½“åˆ†å‰²ã€‚

**å…³é”®åˆ›æ–°**ï¼šScrewSplatçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶ç«¯åˆ°ç«¯çš„è®¾è®¡ï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰æ·±åº¦ä¿¡æ¯çš„æƒ…å†µä¸‹ï¼Œç›´æ¥ä»RGBå›¾åƒä¸­æå–å…³èŠ‚ä¿¡æ¯ï¼Œæ˜¾è‘—ç®€åŒ–äº†ä¼ ç»Ÿæ–¹æ³•çš„å¤æ‚æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®ç°è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–èºæ—‹è½´çš„é…ç½®ï¼Œå¹¶ç»“åˆé«˜æ–¯ç‚¹äº‘æŠ€æœ¯è¿›è¡Œå‡ ä½•é‡å»ºï¼Œç¡®ä¿äº†è¯†åˆ«ç²¾åº¦å’Œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒScrewSplatåœ¨å¤šç§å…³èŠ‚ç‰©ä½“ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„è¯†åˆ«ç²¾åº¦ï¼Œç›¸è¾ƒäºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œè¯†åˆ«å‡†ç¡®ç‡æå‡äº†XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ï¼Œå¹¶æˆåŠŸæ”¯æŒäº†é›¶æ ·æœ¬ã€æ–‡æœ¬å¼•å¯¼çš„æ“ä½œã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ“ä½œã€æ™ºèƒ½å®¶å±…å’Œäººæœºäº¤äº’ç­‰åœºæ™¯ã€‚é€šè¿‡æé«˜å…³èŠ‚ç‰©ä½“çš„è¯†åˆ«ç²¾åº¦ï¼ŒScrewSplatèƒ½å¤Ÿä½¿æœºå™¨äººæ›´å¥½åœ°ç†è§£å’Œæ“ä½œæ—¥å¸¸ç‰©ä½“ï¼Œä»è€Œæå‡å…¶åœ¨å®é™…ç¯å¢ƒä¸­çš„åº”ç”¨ä»·å€¼å’Œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Articulated object recognition -- the task of identifying both the geometry and kinematic joints of objects with movable parts -- is essential for enabling robots to interact with everyday objects such as doors and laptops. However, existing approaches often rely on strong assumptions, such as a known number of articulated parts; require additional inputs, such as depth images; or involve complex intermediate steps that can introduce potential errors -- limiting their practicality in real-world settings. In this paper, we introduce ScrewSplat, a simple end-to-end method that operates solely on RGB observations. Our approach begins by randomly initializing screw axes, which are then iteratively optimized to recover the object's underlying kinematic structure. By integrating with Gaussian Splatting, we simultaneously reconstruct the 3D geometry and segment the object into rigid, movable parts. We demonstrate that our method achieves state-of-the-art recognition accuracy across a diverse set of articulated objects, and further enables zero-shot, text-guided manipulation using the recovered kinematic model. See the project website at: https://screwsplat.github.io.

