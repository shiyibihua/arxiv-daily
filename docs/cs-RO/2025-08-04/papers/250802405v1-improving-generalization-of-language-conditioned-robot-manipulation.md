---
layout: default
title: Improving Generalization of Language-Conditioned Robot Manipulation
---

# Improving Generalization of Language-Conditioned Robot Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.02405" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.02405v1</a>
  <a href="https://arxiv.org/pdf/2508.02405.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.02405v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.02405v1', 'Improving Generalization of Language-Conditioned Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenglin Cui, Chaoran Zhu, Changjae Oh, Andrea Cavallaro

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-04

**å¤‡æ³¨**: 7 pages,18 figures,2 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ–°æ¡†æ¶ä»¥æå‡è¯­è¨€æ¡ä»¶ä¸‹æœºå™¨äººæ“ä½œçš„æ³›åŒ–èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `è§†è§‰-è¯­è¨€æ¨¡å‹` `ç‰©ä½“æ’åˆ—` `æ³›åŒ–èƒ½åŠ›` `å®ä¾‹çº§è¯­ä¹‰èåˆ` `è‡ªç„¶è¯­è¨€æŒ‡ä»¤` `é›¶æ ·æœ¬å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æœªè§ç¯å¢ƒä¸­æ“ä½œæ—¶éœ€è¦å¤§é‡æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œé™åˆ¶äº†å…¶æ³›åŒ–èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºçš„æ¡†æ¶é€šè¿‡å°‘é‡ç¤ºä¾‹å­¦ä¹ ç‰©ä½“æ’åˆ—ä»»åŠ¡ï¼Œåˆ†ä¸ºç›®æ ‡å®šä½å’ŒåŒºåŸŸç¡®å®šä¸¤ä¸ªé˜¶æ®µã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨çœŸå®æœºå™¨äººæ“ä½œä¸­å®ç°äº†é›¶æ ·æœ¬èƒ½åŠ›ï¼Œæ˜¾è‘—æå‡äº†æ³›åŒ–æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœºå™¨äººæ“ä½œä»»åŠ¡çš„æ§åˆ¶é€šå¸¸ä¾èµ–äºè§†è§‰è¾“å…¥ã€‚è¿‘å¹´æ¥ï¼Œè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„è¿›å±•ä½¿å¾—ä½¿ç”¨è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ¥è°ƒèŠ‚è§†è§‰è¾“å…¥å¹¶æ§åˆ¶æœºå™¨äººåœ¨æ›´å¹¿æ³›çš„ç¯å¢ƒä¸­å˜å¾—å¯èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•éœ€è¦å¤§é‡æ•°æ®æ¥å¾®è°ƒVLMsï¼Œä»¥ä¾¿åœ¨æœªè§ç¯å¢ƒä¸­æ“ä½œã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œä»…é€šè¿‡å°‘é‡ç¤ºä¾‹å­¦ä¹ ç‰©ä½“æ’åˆ—ä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸¤é˜¶æ®µæ¡†æ¶ï¼Œå°†ç‰©ä½“æ’åˆ—ä»»åŠ¡åˆ†ä¸ºç›®æ ‡å®šä½é˜¶æ®µå’ŒåŒºåŸŸç¡®å®šé˜¶æ®µã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªå®ä¾‹çº§è¯­ä¹‰èåˆæ¨¡å—ï¼Œä½¿å®ä¾‹çº§å›¾åƒè£å‰ªä¸æ–‡æœ¬åµŒå…¥å¯¹é½ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿè¯†åˆ«ç”±è‡ªç„¶è¯­è¨€æŒ‡ä»¤å®šä¹‰çš„ç›®æ ‡ç‰©ä½“ã€‚æˆ‘ä»¬åœ¨ä»¿çœŸå’ŒçœŸå®æœºå™¨äººç¯å¢ƒä¸­éªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å°‘é‡ç¤ºä¾‹å¾®è°ƒåæé«˜äº†æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶åœ¨çœŸå®æœºå™¨äººæ“ä½œåœºæ™¯ä¸­å±•ç¤ºäº†é›¶æ ·æœ¬èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æœºå™¨äººæ“ä½œæ–¹æ³•åœ¨æœªè§ç¯å¢ƒä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå¤§é‡æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œå¯¼è‡´åœ¨æ–°ç¯å¢ƒä¸­çš„è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ¡†æ¶é€šè¿‡å°‘é‡ç¤ºä¾‹å­¦ä¹ ç‰©ä½“æ’åˆ—ä»»åŠ¡ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µç­–ç•¥ï¼Œåˆ†åˆ«è¿›è¡Œç›®æ ‡å®šä½å’ŒåŒºåŸŸç¡®å®šï¼Œä»¥æé«˜æ“ä½œçš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä¸ºç›®æ ‡å®šä½ï¼Œè´Ÿè´£é€‰æ‹©ç›®æ ‡ç‰©ä½“ï¼›ç¬¬äºŒé˜¶æ®µä¸ºåŒºåŸŸç¡®å®šï¼Œè´Ÿè´£å°†ç‰©ä½“æ”¾ç½®åˆ°æŒ‡å®šä½ç½®ã€‚æ­¤å¤–ï¼Œå®ä¾‹çº§è¯­ä¹‰èåˆæ¨¡å—ç”¨äºå¯¹é½å›¾åƒè£å‰ªä¸æ–‡æœ¬åµŒå…¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå®ä¾‹çº§è¯­ä¹‰èåˆæ¨¡å—çš„å¼•å…¥ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«è‡ªç„¶è¯­è¨€æŒ‡ä»¤å®šä¹‰çš„ç›®æ ‡ç‰©ä½“ï¼Œè¿™ä¸€è®¾è®¡æ˜¾è‘—æå‡äº†æ¨¡å‹çš„è¯†åˆ«èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç›®æ ‡å®šä½å’ŒåŒºåŸŸç¡®å®šçš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†å¤šå±‚æ¬¡ç‰¹å¾æå–ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹å¤æ‚åœºæ™¯çš„é€‚åº”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨çœŸå®æœºå™¨äººæ“ä½œåœºæ™¯ä¸­å®ç°äº†é›¶æ ·æœ¬èƒ½åŠ›ï¼Œæ³›åŒ–æ€§èƒ½æ˜¾è‘—æå‡ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œæ¨¡å‹åœ¨ç›®æ ‡è¯†åˆ«å’Œæ“ä½œå‡†ç¡®æ€§ä¸Šæé«˜äº†çº¦30%ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€å·¥ä¸šè‡ªåŠ¨åŒ–å’ŒæœåŠ¡æœºå™¨äººç­‰ã€‚é€šè¿‡æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œèƒ½åŠ›ï¼Œèƒ½å¤Ÿå®ç°æ›´é«˜æ•ˆçš„ç‰©ä½“å¤„ç†å’Œäººæœºäº¤äº’ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„å¸‚åœºå‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The control of robots for manipulation tasks generally relies on visual input. Recent advances in vision-language models (VLMs) enable the use of natural language instructions to condition visual input and control robots in a wider range of environments. However, existing methods require a large amount of data to fine-tune VLMs for operating in unseen environments. In this paper, we present a framework that learns object-arrangement tasks from just a few demonstrations. We propose a two-stage framework that divides object-arrangement tasks into a target localization stage, for picking the object, and a region determination stage for placing the object. We present an instance-level semantic fusion module that aligns the instance-level image crops with the text embedding, enabling the model to identify the target objects defined by the natural language instructions. We validate our method on both simulation and real-world robotic environments. Our method, fine-tuned with a few demonstrations, improves generalization capability and demonstrates zero-shot ability in real-robot manipulation scenarios.

