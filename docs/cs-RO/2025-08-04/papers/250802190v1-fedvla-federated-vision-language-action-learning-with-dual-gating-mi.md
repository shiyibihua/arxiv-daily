---
layout: default
title: FedVLA: Federated Vision-Language-Action Learning with Dual Gating Mixture-of-Experts for Robotic Manipulation
---

# FedVLA: Federated Vision-Language-Action Learning with Dual Gating Mixture-of-Experts for Robotic Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.02190" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.02190v1</a>
  <a href="https://arxiv.org/pdf/2508.02190.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.02190v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.02190v1', 'FedVLA: Federated Vision-Language-Action Learning with Dual Gating Mixture-of-Experts for Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Cui Miao, Tao Chang, Meihan Wu, Hongbin Xu, Chun Li, Ming Li, Xiaodong Wang

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-04

**å¤‡æ³¨**: Accepted by ICCV 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFedVLAä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­çš„æ•°æ®éšç§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `è§†è§‰-è¯­è¨€-åŠ¨ä½œ` `æœºå™¨äººæ“ä½œ` `æ•°æ®éšç§` `å¤šæ¨¡æ€å­¦ä¹ ` `ä»»åŠ¡æ„ŸçŸ¥` `ä¸“å®¶é€‰æ‹©` `èšåˆç­–ç•¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹è®­ç»ƒä¾èµ–äºç”¨æˆ·ç‰¹å®šæ•°æ®ï¼Œå¯¼è‡´éšç§å’Œå®‰å…¨é—®é¢˜ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚
2. æå‡ºFedVLAæ¡†æ¶ï¼Œé€šè¿‡è”é‚¦å­¦ä¹ å®ç°åˆ†å¸ƒå¼è®­ç»ƒï¼Œä¿æŠ¤æ•°æ®éšç§ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDGMoEæœºåˆ¶æ˜¾è‘—æé«˜äº†è®¡ç®—æ•ˆç‡ï¼ŒFedVLAçš„ä»»åŠ¡æˆåŠŸç‡ä¸é›†ä¸­è®­ç»ƒç›¸å½“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹åœ¨æœºå™¨äººæ“ä½œä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿç†è§£è¯­è¨€æŒ‡ä»¤ä»¥æ‰§è¡Œä»»åŠ¡ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹çš„è®­ç»ƒé€šå¸¸ä¾èµ–äºå¤§è§„æ¨¡ç”¨æˆ·ç‰¹å®šæ•°æ®ï¼Œå¸¦æ¥äº†éšç§å’Œå®‰å…¨é—®é¢˜ï¼Œä»è€Œé™åˆ¶äº†å…¶å¹¿æ³›åº”ç”¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†FedVLAï¼Œè¿™æ˜¯é¦–ä¸ªè”é‚¦VLAå­¦ä¹ æ¡†æ¶ï¼Œæ”¯æŒåˆ†å¸ƒå¼æ¨¡å‹è®­ç»ƒï¼Œä¿æŠ¤æ•°æ®éšç§è€Œä¸å½±å“æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ¡†æ¶é›†æˆäº†ä»»åŠ¡æ„ŸçŸ¥è¡¨ç¤ºå­¦ä¹ ã€è‡ªé€‚åº”ä¸“å®¶é€‰æ‹©å’Œä¸“å®¶é©±åŠ¨çš„è”é‚¦èšåˆï¼Œä¿ƒè¿›äº†VLAæ¨¡å‹çš„é«˜æ•ˆå’Œéšç§ä¿æŠ¤è®­ç»ƒã€‚æˆ‘ä»¬å¼•å…¥äº†æŒ‡ä»¤å¯¼å‘çš„åœºæ™¯è§£ææœºåˆ¶ï¼ŒåŸºäºä»»åŠ¡æŒ‡ä»¤åˆ†è§£å’Œå¢å¼ºå¯¹è±¡çº§ç‰¹å¾ï¼Œæ”¹å–„ä¸Šä¸‹æ–‡ç†è§£ã€‚ä¸ºäº†æœ‰æ•ˆå­¦ä¹ å¤šæ ·åŒ–çš„ä»»åŠ¡æ¨¡å¼ï¼Œæˆ‘ä»¬è®¾è®¡äº†åŒé—¨æ§æ··åˆä¸“å®¶ï¼ˆDGMoEï¼‰æœºåˆ¶ï¼Œä½¿è¾“å…¥æ ‡è®°å’Œè‡ªæˆ‘æ„ŸçŸ¥ä¸“å®¶èƒ½å¤Ÿè‡ªé€‚åº”å†³å®šæ¿€æ´»ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨è”é‚¦æœåŠ¡å™¨ä¸Šæå‡ºäº†ä¸“å®¶é©±åŠ¨çš„èšåˆç­–ç•¥ï¼Œç¡®ä¿æœ‰æ•ˆçš„è·¨å®¢æˆ·ç«¯çŸ¥è¯†è½¬ç§»ã€‚å¹¿æ³›çš„ä»¿çœŸå’ŒçœŸå®ä¸–ç•Œçš„æœºå™¨äººå®éªŒéªŒè¯äº†æˆ‘ä»¬ææ¡ˆçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæ“ä½œä¸­è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹è®­ç»ƒå¯¹ç”¨æˆ·ç‰¹å®šæ•°æ®çš„ä¾èµ–ï¼Œå¯¼è‡´çš„éšç§å’Œå®‰å…¨é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ•°æ®éšç§ä¿æŠ¤æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºFedVLAæ¡†æ¶ï¼Œåˆ©ç”¨è”é‚¦å­¦ä¹ å®ç°åˆ†å¸ƒå¼æ¨¡å‹è®­ç»ƒï¼Œç¡®ä¿æ•°æ®éšç§ä¸è¢«æ³„éœ²ï¼ŒåŒæ—¶é€šè¿‡ä»»åŠ¡æ„ŸçŸ¥è¡¨ç¤ºå­¦ä¹ å’Œè‡ªé€‚åº”ä¸“å®¶é€‰æ‹©æå‡æ¨¡å‹æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFedVLAæ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šä»»åŠ¡æ„ŸçŸ¥è¡¨ç¤ºå­¦ä¹ ã€åŒé—¨æ§æ··åˆä¸“å®¶ï¼ˆDGMoEï¼‰æœºåˆ¶å’Œä¸“å®¶é©±åŠ¨çš„èšåˆç­–ç•¥ã€‚ä»»åŠ¡æ„ŸçŸ¥è¡¨ç¤ºå­¦ä¹ ç”¨äºå¢å¼ºå¯¹è±¡ç‰¹å¾ï¼ŒDGMoEç”¨äºé€‰æ‹©å’Œæ¿€æ´»ä¸“å®¶ï¼Œèšåˆç­–ç•¥åˆ™åœ¨è”é‚¦æœåŠ¡å™¨ä¸Šè¿›è¡Œæ¨¡å‹æ›´æ–°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†DGMoEæœºåˆ¶ï¼Œä½¿å¾—ä¸ä»…è¾“å…¥æ ‡è®°å¯ä»¥è‡ªé€‚åº”é€‰æ‹©æ¿€æ´»çš„ä¸“å®¶ï¼ŒåŒæ—¶ä¸“å®¶æœ¬èº«ä¹Ÿå…·å¤‡è‡ªæˆ‘æ„ŸçŸ¥èƒ½åŠ›ï¼Œä»è€Œæé«˜äº†è®¡ç®—æ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨DGMoEä¸­ï¼Œä¸“å®¶çš„æ¿€æ´»æ˜¯åŸºäºè¾“å…¥ç‰¹å¾å’Œä»»åŠ¡æŒ‡ä»¤çš„ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ä»»åŠ¡æˆåŠŸç‡ï¼Œç½‘ç»œç»“æ„è®¾è®¡ä¸Šè€ƒè™‘äº†å¤šæ¨¡æ€è¾“å…¥çš„èåˆä¸å¤„ç†ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼ŒFedVLAåœ¨éšç§ä¿æŠ¤ä¸æ€§èƒ½ä¹‹é—´è¾¾æˆäº†è‰¯å¥½çš„å¹³è¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFedVLAåœ¨ä»»åŠ¡æˆåŠŸç‡ä¸Šä¸é›†ä¸­è®­ç»ƒæ–¹æ³•ç›¸å½“ï¼ŒåŒæ—¶DGMoEæœºåˆ¶ä½¿å¾—è®¡ç®—æ•ˆç‡æ˜¾è‘—æå‡ã€‚å…·ä½“è€Œè¨€ï¼ŒDGMoEåœ¨å¤„ç†é€Ÿåº¦ä¸Šæ¯”ä¼ ç»Ÿæ–¹æ³•æé«˜äº†çº¦30%ï¼Œæœ‰æ•ˆæ”¯æŒäº†å¤§è§„æ¨¡çš„æœºå™¨äººæ“ä½œä»»åŠ¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦å¤„ç†æ•æ„Ÿæ•°æ®çš„æœºå™¨äººæ“ä½œé¢†åŸŸï¼Œå¦‚å®¶åº­æœåŠ¡æœºå™¨äººã€åŒ»ç–—æœºå™¨äººç­‰ã€‚é€šè¿‡ä¿æŠ¤ç”¨æˆ·éšç§ï¼ŒFedVLAèƒ½å¤Ÿä¿ƒè¿›è¿™äº›æŠ€æœ¯çš„æ›´å¹¿æ³›åº”ç”¨ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººåœ¨å®é™…åœºæ™¯ä¸­çš„è½åœ°ä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-language-action (VLA) models have significantly advanced robotic manipulation by enabling robots to interpret language instructions for task execution. However, training these models often relies on large-scale user-specific data, raising concerns about privacy and security, which in turn limits their broader adoption. To address this, we propose FedVLA, the first federated VLA learning framework, enabling distributed model training that preserves data privacy without compromising performance. Our framework integrates task-aware representation learning, adaptive expert selection, and expert-driven federated aggregation, enabling efficient and privacy-preserving training of VLA models. Specifically, we introduce an Instruction Oriented Scene-Parsing mechanism, which decomposes and enhances object-level features based on task instructions, improving contextual understanding. To effectively learn diverse task patterns, we design a Dual Gating Mixture-of-Experts (DGMoE) mechanism, where not only input tokens but also self-aware experts adaptively decide their activation. Finally, we propose an Expert-Driven Aggregation strategy at the federated server, where model aggregation is guided by activated experts, ensuring effective cross-client knowledge transfer.Extensive simulations and real-world robotic experiments demonstrate the effectiveness of our proposals. Notably, DGMoE significantly improves computational efficiency compared to its vanilla counterpart, while FedVLA achieves task success rates comparable to centralized training, effectively preserving data privacy.

