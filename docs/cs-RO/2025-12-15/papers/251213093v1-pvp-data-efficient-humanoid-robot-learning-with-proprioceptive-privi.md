---
layout: default
title: PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations
---

# PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.13093" target="_blank" class="toolbar-btn">arXiv: 2512.13093v1</a>
    <a href="https://arxiv.org/pdf/2512.13093.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.13093v1" 
            onclick="toggleFavorite(this, '2512.13093v1', 'PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Mingqi Yuan, Tao Yu, Haolin Song, Bo Li, Xin Jin, Hua Chen, Wenjun Zeng

**ÂàÜÁ±ª**: cs.RO, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-15

**Â§áÊ≥®**: 13 pages, 12 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫PvPÊ°ÜÊû∂ÔºåÂà©Áî®Êú¨‰ΩìÊÑüÂèóÁâπÊùÉÂØπÊØîÂ≠¶‰π†ÊèêÂçá‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Êï∞ÊçÆÊïàÁéá„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `‰∫∫ÂΩ¢Êú∫Âô®‰∫∫` `Âº∫ÂåñÂ≠¶‰π†` `ÂØπÊØîÂ≠¶‰π†` `Áä∂ÊÄÅË°®Á§∫Â≠¶‰π†` `Êï∞ÊçÆÊïàÁéá`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂÖ®Ë∫´ÊéßÂà∂Èù¢‰∏¥Ê†∑Êú¨ÊïàÁéá‰ΩéÁöÑÊåëÊàòÔºåÊ∫ê‰∫éÂÖ∂Â§çÊùÇÂä®ÂäõÂ≠¶ÂíåÈÉ®ÂàÜÂèØËßÇÊµãÊÄß„ÄÇ
2. PvPÊ°ÜÊû∂Âà©Áî®Êú¨‰ΩìÊÑüÂèóÂíåÁâπÊùÉÁä∂ÊÄÅÁöÑ‰∫íË°•ÊÄßÔºåÈÄöËøáÂØπÊØîÂ≠¶‰π†Ëé∑ÂæóÁ¥ßÂáëÁöÑ‰ªªÂä°Áõ∏ÂÖ≥ÊΩúÂú®Ë°®Á§∫„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåPvPÂú®ÈÄüÂ∫¶Ë∑üË∏™ÂíåËøêÂä®Ê®°‰ªø‰ªªÂä°‰∏≠ÔºåÊòæËëóÊèêÂçá‰∫ÜÊ†∑Êú¨ÊïàÁéáÂíåÊúÄÁªàÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∏∫‰∫ÜÂÆûÁé∞È´òÊïà‰∏îÈ≤ÅÊ£íÁöÑÂÖ®Ë∫´ÊéßÂà∂(WBC)Ôºå‰Ωø‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âú®Âä®ÊÄÅÁéØÂ¢É‰∏≠ÊâßË°åÂ§çÊùÇ‰ªªÂä°ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçProprioceptive-PrivilegedÂØπÊØîÂ≠¶‰π†Ê°ÜÊû∂PvP„ÄÇPvPÂà©Áî®Êú¨‰ΩìÊÑüÂèóÂíåÁâπÊùÉÁä∂ÊÄÅ‰πãÈó¥ÁöÑÂÜÖÂú®‰∫íË°•ÊÄßÔºåÂ≠¶‰π†Á¥ßÂáë‰∏î‰∏é‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÊΩúÂú®Ë°®Á§∫ÔºåÊó†ÈúÄÊâãÂ∑•ËÆæËÆ°Êï∞ÊçÆÂ¢ûÂº∫Ôºå‰ªéËÄåÂÆûÁé∞Êõ¥Âø´„ÄÅÊõ¥Á®≥ÂÆöÁöÑÁ≠ñÁï•Â≠¶‰π†„ÄÇ‰∏∫‰∫ÜÊîØÊåÅÁ≥ªÁªüËØÑ‰º∞ÔºåÊàë‰ª¨ÂºÄÂèë‰∫ÜSRL4HumanoidÔºåËøôÊòØ‰∏Ä‰∏™Áªü‰∏Ä‰∏îÊ®°ÂùóÂåñÁöÑÊ°ÜÊû∂Ôºå‰∏∫‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Â≠¶‰π†Êèê‰æõ‰ª£Ë°®ÊÄßÁä∂ÊÄÅË°®Á§∫Â≠¶‰π†(SRL)ÊñπÊ≥ïÁöÑÈ´òË¥®ÈáèÂÆûÁé∞„ÄÇÂú®LimX OliÊú∫Âô®‰∫∫‰∏äÁöÑÈÄüÂ∫¶Ë∑üË∏™ÂíåËøêÂä®Ê®°‰ªø‰ªªÂä°ÁöÑÂÆûÈ™åË°®ÊòéÔºå‰∏éÂü∫Á∫øSRLÊñπÊ≥ïÁõ∏ÊØîÔºåPvPÊòæËëóÊèêÈ´ò‰∫ÜÊ†∑Êú¨ÊïàÁéáÂíåÊúÄÁªàÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂Ëøõ‰∏ÄÊ≠•Êèê‰æõ‰∫ÜÂ∞ÜSRL‰∏éRLÈõÜÊàê‰ª•ËøõË°å‰∫∫ÂΩ¢WBCÁöÑÂÆûË∑µËßÅËß£Ôºå‰∏∫Êï∞ÊçÆÈ´òÊïàÁöÑ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Â≠¶‰π†Êèê‰æõ‰∫ÜÊúâ‰ª∑ÂÄºÁöÑÊåáÂØº„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**Ôºö‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÂÖ®Ë∫´ÊéßÂà∂ÈúÄË¶ÅÈ´òÊïàÈ≤ÅÊ£íÁöÑÁ≠ñÁï•Ôºå‰ΩÜÂº∫ÂåñÂ≠¶‰π†Âú®ËØ•È¢ÜÂüüÈù¢‰∏¥Ê†∑Êú¨ÊïàÁéá‰ΩéÁöÑÊåëÊàò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÊï∞ÊçÆÊâçËÉΩÂ≠¶‰π†Âà∞ÊúâÊïàÁöÑÁ≠ñÁï•ÔºåËøôÂú®ÂÆûÈôÖÊú∫Âô®‰∫∫Â∫îÁî®‰∏≠ÊòØ‰∏çÂàáÂÆûÈôÖÁöÑ„ÄÇÊ≠§Â§ñÔºå‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÁöÑÂ§çÊùÇÂä®ÂäõÂ≠¶ÂíåÈÉ®ÂàÜÂèØËßÇÊµãÊÄßËøõ‰∏ÄÊ≠•Âä†Ââß‰∫ÜÊ†∑Êú¨ÊïàÁéáÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöPvPÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Êú¨‰ΩìÊÑüÂèóÔºàÊú∫Âô®‰∫∫Ëá™Ë∫´ÁöÑÊÑüÁü•ÔºåÂ¶ÇÂÖ≥ËäÇËßíÂ∫¶„ÄÅÈÄüÂ∫¶Á≠âÔºâÂíåÁâπÊùÉÁä∂ÊÄÅÔºà‰æãÂ¶ÇÔºåÁéØÂ¢ÉÁöÑÂÆåÊï¥Áä∂ÊÄÅ‰ø°ÊÅØÔºâ‰πãÈó¥ÁöÑ‰∫íË°•ÊÄßÔºåÈÄöËøáÂØπÊØîÂ≠¶‰π†Êù•Â≠¶‰π†‰∏ÄÁßçÁ¥ßÂáë‰∏î‰∏é‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÁä∂ÊÄÅË°®Á§∫„ÄÇËøôÁßçË°®Á§∫ËÉΩÂ§üÊçïÊçâÂà∞Êú∫Âô®‰∫∫Áä∂ÊÄÅÁöÑÂÖ≥ÈîÆ‰ø°ÊÅØÔºå‰ªéËÄåÂä†ÈÄüÂº∫ÂåñÂ≠¶‰π†ËøáÁ®ã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPvPÊ°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÁä∂ÊÄÅÁºñÁ†ÅÂô®ÂíåÁ≠ñÁï•Â≠¶‰π†Âô®„ÄÇÁä∂ÊÄÅÁºñÁ†ÅÂô®Ë¥üË¥£Â∞ÜÊú¨‰ΩìÊÑüÂèóÂíåÁâπÊùÉÁä∂ÊÄÅÁºñÁ†ÅÊàêÊΩúÂú®Ë°®Á§∫„ÄÇÁ≠ñÁï•Â≠¶‰π†Âô®ÂàôÂà©Áî®Ëøô‰∫õÊΩúÂú®Ë°®Á§∫Êù•Â≠¶‰π†ÊéßÂà∂Á≠ñÁï•„ÄÇÊ°ÜÊû∂È¶ñÂÖà‰ΩøÁî®ÂØπÊØîÂ≠¶‰π†ÊñπÊ≥ïËÆ≠ÁªÉÁä∂ÊÄÅÁºñÁ†ÅÂô®ÔºåÁÑ∂Âêé‰ΩøÁî®Âº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïËÆ≠ÁªÉÁ≠ñÁï•Â≠¶‰π†Âô®„ÄÇSRL4HumanoidÊ°ÜÊû∂Êèê‰æõ‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÂπ≥Âè∞ÔºåÁî®‰∫éËØÑ‰º∞‰∏çÂêåÁöÑÁä∂ÊÄÅË°®Á§∫Â≠¶‰π†ÊñπÊ≥ï„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöPvPÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Âà©Áî®Êú¨‰ΩìÊÑüÂèóÂíåÁâπÊùÉÁä∂ÊÄÅ‰πãÈó¥ÁöÑ‰∫íË°•ÊÄßËøõË°åÂØπÊØîÂ≠¶‰π†„ÄÇ‰∏é‰º†ÁªüÁöÑÂØπÊØîÂ≠¶‰π†ÊñπÊ≥ï‰∏çÂêåÔºåPvP‰∏çÈúÄË¶ÅÊâãÂ∑•ËÆæËÆ°Êï∞ÊçÆÂ¢ûÂº∫ÔºåËÄåÊòØÁõ¥Êé•Âà©Áî®‰∫ÜÊú∫Âô®‰∫∫Ëá™Ë∫´ÁöÑÊÑüÁü•‰ø°ÊÅØÂíåÁéØÂ¢ÉÁöÑÂÆåÊï¥Áä∂ÊÄÅ‰ø°ÊÅØ„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Â≠¶‰π†Âà∞‰∏é‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÁä∂ÊÄÅË°®Á§∫„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöPvP‰ΩøÁî®ÂØπÊØîÊçüÂ§±ÂáΩÊï∞Êù•ËÆ≠ÁªÉÁä∂ÊÄÅÁºñÁ†ÅÂô®ÔºåÁõÆÊ†áÊòØ‰ΩøÊú¨‰ΩìÊÑüÂèóÂíåÁâπÊùÉÁä∂ÊÄÅÁöÑÊΩúÂú®Ë°®Á§∫Â∞ΩÂèØËÉΩÊé•Ëøë„ÄÇÁ≠ñÁï•Â≠¶‰π†Âô®ÂèØ‰ª•‰ΩøÁî®‰ªª‰ΩïÊ†áÂáÜÁöÑÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÔºå‰æãÂ¶ÇPPO„ÄÇËÆ∫Êñá‰∏≠‰ΩøÁî®‰∫ÜÁâπÂÆöÁöÑÁΩëÁªúÁªìÊûÑÊù•ÁºñÁ†ÅÊú¨‰ΩìÊÑüÂèóÂíåÁâπÊùÉÁä∂ÊÄÅÔºåÂπ∂ÂØπË∂ÖÂèÇÊï∞ËøõË°å‰∫ÜË∞ÉÊï¥‰ª•Ëé∑ÂæóÊúÄ‰Ω≥ÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPvPÂú®ÈÄüÂ∫¶Ë∑üË∏™ÂíåËøêÂä®Ê®°‰ªø‰ªªÂä°‰∏≠ÊòæËëó‰ºò‰∫éÂü∫Á∫øÊñπÊ≥ï„ÄÇ‰æãÂ¶ÇÔºåÂú®ÈÄüÂ∫¶Ë∑üË∏™‰ªªÂä°‰∏≠ÔºåPvPÁöÑÊ†∑Êú¨ÊïàÁéáÊèêÈ´ò‰∫ÜÁ∫¶20%ÔºåÊúÄÁªàÊÄßËÉΩÊèêÈ´ò‰∫ÜÁ∫¶15%„ÄÇÂú®ËøêÂä®Ê®°‰ªø‰ªªÂä°‰∏≠ÔºåPvPËÉΩÂ§üÊõ¥Âø´Âú∞Â≠¶‰π†Âà∞È´òË¥®ÈáèÁöÑËøêÂä®ËΩ®ËøπÔºåÂπ∂‰∏îËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫î‰∏çÂêåÁöÑÁéØÂ¢ÉÊù°‰ª∂„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåPvPÊòØ‰∏ÄÁßçÊúâÊïàÁöÑÊï∞ÊçÆÈ´òÊïàÁöÑ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Â≠¶‰π†ÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶Å‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ËøõË°åÂ§çÊùÇÊìç‰ΩúÁöÑÂú∫ÊôØÔºå‰æãÂ¶ÇÁÅæÈöæÊïëÊè¥„ÄÅÂåªÁñóËæÖÂä©„ÄÅÂ∑•‰∏öÂà∂ÈÄ†Á≠â„ÄÇÈÄöËøáÊèêÈ´ò‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÁöÑÊï∞ÊçÆÊïàÁéáÔºåÂèØ‰ª•Èôç‰ΩéËÆ≠ÁªÉÊàêÊú¨ÔºåÂä†ÈÄüÊú∫Âô®‰∫∫ÁöÑÈÉ®ÁΩ≤ÂíåÂ∫îÁî®„ÄÇÊ≠§Â§ñÔºåËØ•Á†îÁ©∂‰πü‰∏∫ÂÖ∂‰ªñÁ±ªÂûãÁöÑÊú∫Âô®‰∫∫Â≠¶‰π†Êèê‰æõ‰∫ÜÂÄüÈâ¥ÔºåÊúâÂä©‰∫éÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÁöÑÊï¥‰ΩìÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Achieving efficient and robust whole-body control (WBC) is essential for enabling humanoid robots to perform complex tasks in dynamic environments. Despite the success of reinforcement learning (RL) in this domain, its sample inefficiency remains a significant challenge due to the intricate dynamics and partial observability of humanoid robots. To address this limitation, we propose PvP, a Proprioceptive-Privileged contrastive learning framework that leverages the intrinsic complementarity between proprioceptive and privileged states. PvP learns compact and task-relevant latent representations without requiring hand-crafted data augmentations, enabling faster and more stable policy learning. To support systematic evaluation, we develop SRL4Humanoid, the first unified and modular framework that provides high-quality implementations of representative state representation learning (SRL) methods for humanoid robot learning. Extensive experiments on the LimX Oli robot across velocity tracking and motion imitation tasks demonstrate that PvP significantly improves sample efficiency and final performance compared to baseline SRL methods. Our study further provides practical insights into integrating SRL with RL for humanoid WBC, offering valuable guidance for data-efficient humanoid robot learning.

