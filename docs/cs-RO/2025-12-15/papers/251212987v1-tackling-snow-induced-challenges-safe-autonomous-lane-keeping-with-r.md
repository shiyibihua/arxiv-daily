---
layout: default
title: Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning
---

# Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.12987" target="_blank" class="toolbar-btn">arXiv: 2512.12987v1</a>
    <a href="https://arxiv.org/pdf/2512.12987.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.12987v1" 
            onclick="toggleFavorite(this, '2512.12987v1', 'Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Amin Jalal Aghdasian, Farzaneh Abdollahi, Ali Kamali Iglie

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-15

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÈ≤ÅÊ£íÂº∫ÂåñÂ≠¶‰π†ÁöÑËΩ¶ÈÅì‰øùÊåÅÁ≥ªÁªüÔºåËß£ÂÜ≥Èõ™Âú∞Ëá™Âä®È©æÈ©∂ÈöæÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†` `Ëá™Âä®È©æÈ©∂` `ËΩ¶ÈÅì‰øùÊåÅ` `È≤ÅÊ£íÊéßÂà∂` `Èõ™Âú∞ÁéØÂ¢É`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËΩ¶ÈÅì‰øùÊåÅÁ≥ªÁªüÂú®Èõ™Âú∞Á≠âÂ§çÊùÇÁéØÂ¢É‰∏ãÔºåÊòìÂèóË∑ØÈù¢ÊªëÁßªÂíåÊÑüÁü•Âô™Â£∞ÂΩ±ÂìçÔºåÂØºËá¥ÊÄßËÉΩ‰∏ãÈôç„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Âä®‰ΩúÈ≤ÅÊ£íÁöÑÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåÂ¢ûÂº∫Á≠ñÁï•ÂØπÁéØÂ¢É‰∏çÁ°ÆÂÆöÊÄßÁöÑÈÄÇÂ∫îËÉΩÂäõÔºåÊèêÈ´òÁ≥ªÁªüÈ≤ÅÊ£íÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåAR-CADPGÊñπÊ≥ïÂú®Èõ™Âú∞Âú∫ÊôØ‰∏ãÂÖ∑ÊúâÊõ¥È´òÁöÑË∑ØÂæÑË∑üË∏™Á≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄßÔºåÈ™åËØÅ‰∫ÜÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏§ÁßçÊñ∞ÁöÑÁÆóÊ≥ïÔºåÁî®‰∫éÂú®Èõ™Âú∞Êù°‰ª∂‰∏ãËá™Âä®È©æÈ©∂ËΩ¶ËæÜ(AVs)ÁöÑËΩ¶ÈÅì‰øùÊåÅÁ≥ªÁªü(LKS)„ÄÇËøô‰∫õÁÆóÊ≥ïÂà©Áî®Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†(DRL)Êù•Â§ÑÁêÜ‰∏çÁ°ÆÂÆöÊÄßÂíåÊªëÁßª„ÄÇÂÆÉ‰ª¨ÂåÖÊã¨Âä®‰ΩúÈ≤ÅÊ£íÂæ™ÁéØÊ∑±Â∫¶Á°ÆÂÆöÊÄßÁ≠ñÁï•Ê¢ØÂ∫¶(AR-RDPG)ÂíåÁ´ØÂà∞Á´ØÂä®‰ΩúÈ≤ÅÊ£íÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÊ≥®ÊÑèÂäõÁ°ÆÂÆöÊÄßÁ≠ñÁï•Ê¢ØÂ∫¶(AR-CADPG)ÔºåËøô‰∏§ÁßçÂä®‰ΩúÈ≤ÅÊ£íÁöÑÂÜ≥Á≠ñÊñπÊ≥ï„ÄÇÂú®AR-RDPGÊñπÊ≥ï‰∏≠ÔºåÂú®ÊÑüÁü•Â±ÇÂÜÖÔºåÈ¶ñÂÖà‰ΩøÁî®Â§öÂ∞∫Â∫¶Á•ûÁªèÁΩëÁªúÂØπÁõ∏Êú∫ÂõæÂÉèËøõË°åÂéªÂô™„ÄÇÁÑ∂ÂêéÔºåÈÄöËøáÈ¢ÑËÆ≠ÁªÉÁöÑÊ∑±Â∫¶Âç∑ÁßØÁ•ûÁªèÁΩëÁªú(DCNN)ÊèêÂèñ‰∏≠ÂøÉÁ∫øÁ≥ªÊï∞„ÄÇËøô‰∫õÁ≥ªÊï∞‰∏éÈ©æÈ©∂ÁâπÊÄßËøûÊé•Ôºå‰Ωú‰∏∫ÊéßÂà∂Â±ÇÁöÑËæìÂÖ•„ÄÇAR-CADPGÊñπÊ≥ïÊèêÂá∫‰∫Ü‰∏ÄÁßçÁ´ØÂà∞Á´ØÁöÑÊñπÊ≥ïÔºåÂÖ∂‰∏≠Âç∑ÁßØÁ•ûÁªèÁΩëÁªú(CNN)ÂíåÊ≥®ÊÑèÂäõÊú∫Âà∂Ë¢´ÈõÜÊàêÂà∞DRLÊ°ÜÊû∂‰∏≠„ÄÇËøô‰∏§ÁßçÊñπÊ≥ïÈ¶ñÂÖàÂú®CARLAÊ®°ÊãüÂô®‰∏≠ËøõË°åËÆ≠ÁªÉÔºåÂπ∂Âú®ÂêÑÁßçÈõ™Âú∞Âú∫ÊôØ‰∏ãËøõË°åÈ™åËØÅ„ÄÇÂú®Âü∫‰∫éJetson NanoÁöÑËá™Âä®È©æÈ©∂ËΩ¶ËæÜ‰∏äÁöÑÁúüÂÆûÂÆûÈ™åËØÅÂÆû‰∫ÜÂ≠¶‰π†Á≠ñÁï•ÁöÑÂèØË°åÊÄßÂíåÁ®≥ÂÆöÊÄß„ÄÇÂú®‰∏§ÁßçÊ®°Âûã‰∏≠ÔºåAR-CADPGÊñπÊ≥ïË°®Áé∞Âá∫ÂçìË∂äÁöÑË∑ØÂæÑË∑üË∏™Á≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄßÔºåÁ™ÅÂá∫‰∫ÜÂú®AVs‰∏≠ÁªìÂêàÊó∂Èó¥ËÆ∞ÂøÜ„ÄÅÂØπÊäóÂºπÊÄßÂíåÊ≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÊúâÊïàÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Èõ™Âú∞ÁéØÂ¢É‰∏ãËá™Âä®È©æÈ©∂ËΩ¶ËæÜËΩ¶ÈÅì‰øùÊåÅÁ≥ªÁªüÈù¢‰∏¥ÁöÑÊåëÊàòÔºåÂåÖÊã¨Ë∑ØÈù¢ÊªëÁßªÂ∏¶Êù•ÁöÑÊéßÂà∂‰∏çÁ°ÆÂÆöÊÄß‰ª•ÂèäÊÑüÁü•Á≥ªÁªüÂèóÈôçÈõ™ÂΩ±Âìç‰∫ßÁîüÁöÑÂô™Â£∞„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂ∫îÂØπËøô‰∫õÈóÆÈ¢òÔºåÂØºËá¥ËΩ¶ÈÅì‰øùÊåÅÊÄßËÉΩ‰∏ãÈôçÔºåÁîöËá≥Âá∫Áé∞ÂÆâÂÖ®ÈöêÊÇ£„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†(DRL)Â≠¶‰π†Âú®‰∏çÁ°ÆÂÆöÁéØÂ¢É‰∏ãÁöÑÈ≤ÅÊ£íÊéßÂà∂Á≠ñÁï•„ÄÇÈÄöËøáÂºïÂÖ•Âä®‰ΩúÈ≤ÅÊ£íÊÄßÔºå‰ΩøÊô∫ËÉΩ‰ΩìËÉΩÂ§üÈÄÇÂ∫îÁéØÂ¢ÉÂèòÂåñÂíåÊÑüÁü•Âô™Â£∞Ôºå‰ªéËÄåÊèêÈ´òËΩ¶ÈÅì‰øùÊåÅÁ≥ªÁªüÁöÑÁ®≥ÂÆöÊÄßÂíåÂÆâÂÖ®ÊÄß„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÈÄöËøáÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÂºïÂÖ•ÂØπÊäóÊ†∑Êú¨Ôºå‰ΩøÁ≠ñÁï•ÂØπÂä®‰ΩúÊâ∞Âä®ÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÊäµÊäóËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏§ÁßçÁÆóÊ≥ïÔºöAR-RDPGÂíåAR-CADPG„ÄÇAR-RDPGÈ¶ñÂÖà‰ΩøÁî®Â§öÂ∞∫Â∫¶Á•ûÁªèÁΩëÁªúÂØπÂõæÂÉèËøõË°åÂéªÂô™ÔºåÁÑ∂ÂêéÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑDCNNÊèêÂèñ‰∏≠ÂøÉÁ∫øÁ≥ªÊï∞ÔºåÂπ∂Â∞ÜÂÖ∂‰∏éÈ©æÈ©∂ÁâπÂæÅÁªìÂêà‰Ωú‰∏∫RDPGÊéßÂà∂Âô®ÁöÑËæìÂÖ•„ÄÇAR-CADPGÂàôÈááÁî®Á´ØÂà∞Á´ØÁöÑÊñπÂºèÔºåÂ∞ÜCNNÂíåÊ≥®ÊÑèÂäõÊú∫Âà∂ÈõÜÊàêÂà∞DRLÊ°ÜÊû∂‰∏≠ÔºåÁõ¥Êé•‰ªéÂõæÂÉèËæìÂÖ•Â≠¶‰π†ÊéßÂà∂Á≠ñÁï•„ÄÇ‰∏§ÁßçÊñπÊ≥ïÈÉΩÂú®CARLAÊ®°ÊãüÂô®‰∏≠ËøõË°åËÆ≠ÁªÉÂíåÈ™åËØÅÔºåÂπ∂Âú®ÁúüÂÆûËΩ¶ËæÜ‰∏äËøõË°åÊµãËØï„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜÂä®‰ΩúÈ≤ÅÊ£íÊÄßÂà∞Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂‰∏≠ÔºåÂπ∂Â∞ÜÂÖ∂Â∫îÁî®‰∫éÈõ™Âú∞ÁéØÂ¢É‰∏ãÁöÑËΩ¶ÈÅì‰øùÊåÅ‰ªªÂä°„ÄÇAR-CADPGÁöÑÁ´ØÂà∞Á´ØÁªìÊûÑ‰ª•ÂèäÊ≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÂºïÂÖ•Ôºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞ÂÖ≥Ê≥®ÂÖ≥ÈîÆÁâπÂæÅÔºåÊèêÈ´òË∑ØÂæÑË∑üË∏™Á≤æÂ∫¶„ÄÇÊ≠§Â§ñÔºåÂ§öÂ∞∫Â∫¶ÂéªÂô™ÁΩëÁªúÁöÑÂ∫îÁî®‰πüÂ¢ûÂº∫‰∫ÜÊÑüÁü•Á≥ªÁªüÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAR-RDPG‰∏≠ÔºåÂ§öÂ∞∫Â∫¶ÂéªÂô™ÁΩëÁªúÈááÁî®U-NetÁªìÊûÑÔºåÁî®‰∫éÂéªÈô§ÂõæÂÉèÂô™Â£∞„ÄÇÈ¢ÑËÆ≠ÁªÉÁöÑDCNNÁî®‰∫éÊèêÂèñËΩ¶ÈÅì‰∏≠ÂøÉÁ∫øÁ≥ªÊï∞„ÄÇAR-CADPG‰∏≠ÔºåCNNÈááÁî®ResNetÁªìÊûÑÔºåÊ≥®ÊÑèÂäõÊú∫Âà∂ÈááÁî®TransformerÁªìÊûÑ„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÊéßÂà∂ÊçüÂ§±ÂíåÂä®‰ΩúÈ≤ÅÊ£íÊÄßÊçüÂ§±ÔºåÂÖ∂‰∏≠Âä®‰ΩúÈ≤ÅÊ£íÊÄßÊçüÂ§±ÈÄöËøáÂØπÊäóËÆ≠ÁªÉÂÆûÁé∞ÔºåÈºìÂä±Á≠ñÁï•ÂØπÂä®‰ΩúÊâ∞Âä®ÂÖ∑ÊúâÊäµÊäóËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAR-CADPGÊñπÊ≥ïÂú®Èõ™Âú∞Âú∫ÊôØ‰∏ãÂÖ∑ÊúâÊõ¥È´òÁöÑË∑ØÂæÑË∑üË∏™Á≤æÂ∫¶ÂíåÈ≤ÅÊ£íÊÄß„ÄÇ‰∏éAR-RDPGÁõ∏ÊØîÔºåAR-CADPGËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞Ë∑üË∏™ËΩ¶ÈÅì‰∏≠ÂøÉÁ∫øÔºåÂπ∂ÂØπÁéØÂ¢ÉÂèòÂåñÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÈÄÇÂ∫îËÉΩÂäõ„ÄÇÁúüÂÆûËΩ¶ËæÜÂÆûÈ™åÈ™åËØÅ‰∫ÜËØ•ÊñπÊ≥ïÁöÑÂèØË°åÊÄßÂíåÁ®≥ÂÆöÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊèêÂçáÊï∞ÊçÆÊú™Áü•„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÊÅ∂Âä£Â§©Ê∞îÊù°‰ª∂‰∏ãÁöÑËá™Âä®È©æÈ©∂ËΩ¶ËæÜÔºå‰æãÂ¶ÇÈõ™Âú∞„ÄÅÈõ®Â§©„ÄÅÈõæÂ§©Á≠â„ÄÇÈÄöËøáÊèêÈ´òËá™Âä®È©æÈ©∂Á≥ªÁªüÂú®Â§çÊùÇÁéØÂ¢É‰∏ãÁöÑÈ≤ÅÊ£íÊÄßÂíåÂÆâÂÖ®ÊÄßÔºåÂèØ‰ª•Âä†ÈÄüËá™Âä®È©æÈ©∂ÊäÄÊúØÁöÑÂïÜ‰∏öÂåñËêΩÂú∞ÔºåÂπ∂ÊèêÂçá‰∫§ÈÄöËøêËæìÊïàÁéáÂíåÂÆâÂÖ®ÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Êé®ÂπøÂà∞ÂÖ∂‰ªñÊú∫Âô®‰∫∫ÊéßÂà∂‰ªªÂä°‰∏≠Ôºå‰æãÂ¶ÇÊó†‰∫∫Êú∫„ÄÅÊ∞¥‰∏ãÊú∫Âô®‰∫∫Á≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> This paper proposes two new algorithms for the lane keeping system (LKS) in autonomous vehicles (AVs) operating under snowy road conditions. These algorithms use deep reinforcement learning (DRL) to handle uncertainties and slippage. They include Action-Robust Recurrent Deep Deterministic Policy Gradient (AR-RDPG) and end-to-end Action-Robust convolutional neural network Attention Deterministic Policy Gradient (AR-CADPG), two action-robust approaches for decision-making. In the AR-RDPG method, within the perception layer, camera images are first denoised using multi-scale neural networks. Then, the centerline coefficients are extracted by a pre-trained deep convolutional neural network (DCNN). These coefficients, concatenated with the driving characteristics, are used as input to the control layer. The AR-CADPG method presents an end-to-end approach in which a convolutional neural network (CNN) and an attention mechanism are integrated within a DRL framework. Both methods are first trained in the CARLA simulator and validated under various snowy scenarios. Real-world experiments on a Jetson Nano-based autonomous vehicle confirm the feasibility and stability of the learned policies. Among the two models, the AR-CADPG approach demonstrates superior path-tracking accuracy and robustness, highlighting the effectiveness of combining temporal memory, adversarial resilience, and attention mechanisms in AVs.

