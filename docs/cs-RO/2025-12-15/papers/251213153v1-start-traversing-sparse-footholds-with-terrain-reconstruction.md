---
layout: default
title: START: Traversing Sparse Footholds with Terrain Reconstruction
---

# START: Traversing Sparse Footholds with Terrain Reconstruction

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.13153" target="_blank" class="toolbar-btn">arXiv: 2512.13153v1</a>
    <a href="https://arxiv.org/pdf/2512.13153.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.13153v1" 
            onclick="toggleFavorite(this, '2512.13153v1', 'START: Traversing Sparse Footholds with Terrain Reconstruction')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Ruiqi Yu, Qianshi Wang, Hongyi Li, Zheng Jun, Zhicheng Wang, Jun Wu, Qiuguo Zhu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-15

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**STARTï¼šåŸºäºåœ°å½¢é‡å»ºçš„ç¨€ç–è½è„šç‚¹å››è¶³æœºå™¨äººè¿åŠ¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `å››è¶³æœºå™¨äºº` `ç¨€ç–åœ°å½¢` `åœ°å½¢é‡å»º` `å¼ºåŒ–å­¦ä¹ ` `é›¶æ ·æœ¬è¿ç§»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å››è¶³æœºå™¨äººæ–¹æ³•åœ¨ç¨€ç–åœ°å½¢ä¸­æ³›åŒ–æ€§å·®ï¼Œæˆ–ä¾èµ–å™ªå£°å¤§çš„é«˜åº¦å›¾ï¼Œå¯¼è‡´å­¦ä¹ æ•ˆç‡ä½å’Œæ­¥æ€åƒµç¡¬ã€‚
2. STARTæ¡†æ¶åˆ©ç”¨æ¿è½½è§†è§‰å’Œæœ¬ä½“æ„Ÿå—ï¼Œé‡å»ºå±€éƒ¨åœ°å½¢é«˜åº¦å›¾ï¼Œæ˜¾å¼è¡¨è¾¾ç¨€ç–è½è„šç‚¹ç‰¹å¾ï¼Œæå‡ç¯å¢ƒç†è§£å’Œåœ°å½¢è¯„ä¼°ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSTARTåœ¨çœŸå®åœºæ™¯ä¸­å®ç°äº†é›¶æ ·æœ¬è¿ç§»ï¼Œå±•ç°äº†ä¼˜è¶Šçš„é€‚åº”æ€§ã€ç²¾ç¡®çš„è½è„šç‚¹æ”¾ç½®å’Œé²æ£’çš„è¿åŠ¨èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯¹äºå››è¶³æœºå™¨äººè€Œè¨€ï¼Œåœ¨ç¨€ç–è½è„šç‚¹çš„åœ°å½¢ä¸Šè¡Œèµ°æ˜¯ä¸€é¡¹å……æ»¡å¸Œæœ›ä½†å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå®ƒéœ€è¦ç²¾ç¡®çš„ç¯å¢ƒæ„ŸçŸ¥å’Œæ•æ·çš„æ§åˆ¶ï¼Œä»¥ç¡®ä¿å®‰å…¨çš„è½è„šç‚¹ï¼ŒåŒæ—¶ä¿æŒåŠ¨æ€ç¨³å®šæ€§ã€‚åŸºäºæ¨¡å‹çš„å±‚çº§æ§åˆ¶å™¨åœ¨å®éªŒå®¤ç¯å¢ƒä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†æ³›åŒ–èƒ½åŠ›æœ‰é™ï¼Œè¡Œä¸ºè¿‡äºä¿å®ˆã€‚ç«¯åˆ°ç«¯å­¦ä¹ æ–¹æ³•å…·æœ‰æ›´å¤§çš„çµæ´»æ€§å’Œé€‚åº”æ€§ï¼Œä½†ç°æœ‰æ–¹æ³•ä¾èµ–äºå¼•å…¥å™ªå£°å’Œå¤æ‚ã€æ˜‚è´µæµç¨‹çš„é«˜åº¦å›¾ï¼Œæˆ–è€…ä»è‡ªæˆ‘ä¸­å¿ƒçš„æ·±åº¦å›¾åƒä¸­éšå¼åœ°æ¨æ–­åœ°å½¢ç‰¹å¾ï¼Œé€šå¸¸ä¼šé”™è¿‡å‡†ç¡®çš„å…³é”®å‡ ä½•çº¿ç´¢ï¼Œå¯¼è‡´å­¦ä¹ æ•ˆç‡ä½ä¸‹å’Œæ­¥æ€åƒµç¡¬ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†STARTï¼Œä¸€ä¸ªå•é˜¶æ®µå­¦ä¹ æ¡†æ¶ï¼Œå®ƒèƒ½å¤Ÿåœ¨é«˜åº¦ç¨€ç–å’Œéšæœºçš„è½è„šç‚¹ä¸Šå®ç°æ•æ·ã€ç¨³å®šçš„è¿åŠ¨ã€‚STARTä»…åˆ©ç”¨ä½æˆæœ¬çš„æ¿è½½è§†è§‰å’Œæœ¬ä½“æ„Ÿå—æ¥å‡†ç¡®åœ°é‡å»ºå±€éƒ¨åœ°å½¢é«˜åº¦å›¾ï¼Œæä¾›äº†ä¸€ä¸ªæ˜¾å¼çš„ä¸­é—´è¡¨ç¤ºï¼Œä»¥ä¼ è¾¾ä¸ç¨€ç–è½è„šç‚¹åŒºåŸŸç›¸å…³çš„é‡è¦ç‰¹å¾ã€‚è¿™æ”¯æŒäº†å…¨é¢çš„ç¯å¢ƒç†è§£å’Œç²¾ç¡®çš„åœ°å½¢è¯„ä¼°ï¼Œé™ä½äº†æ¢ç´¢æˆæœ¬å¹¶åŠ é€Ÿäº†æŠ€èƒ½è·å–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSTARTåœ¨å„ç§çœŸå®åœºæ™¯ä¸­å®ç°äº†é›¶æ ·æœ¬è¿ç§»ï¼Œå±•ç¤ºäº†å“è¶Šçš„é€‚åº”æ€§ã€ç²¾ç¡®çš„è½è„šç‚¹æ”¾ç½®å’Œå¼ºå¤§çš„è¿åŠ¨èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å››è¶³æœºå™¨äººåœ¨ç¨€ç–è½è„šç‚¹åœ°å½¢ä¸­è¿åŠ¨æ—¶ï¼Œç°æœ‰æ–¹æ³•æ³›åŒ–æ€§å·®ã€ä¾èµ–å™ªå£°æ•°æ®æˆ–éšå¼æ¨æ–­å¯¼è‡´å­¦ä¹ æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨çœŸå®å¤æ‚ç¯å¢ƒä¸­å®ç°ç¨³å®šã€æ•æ·çš„è¿åŠ¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä½æˆæœ¬çš„æ¿è½½è§†è§‰å’Œæœ¬ä½“æ„Ÿå—ä¿¡æ¯ï¼Œæ˜¾å¼åœ°é‡å»ºå±€éƒ¨åœ°å½¢é«˜åº¦å›¾ã€‚é€šè¿‡æ˜¾å¼åœ°è¡¨è¾¾åœ°å½¢ç‰¹å¾ï¼Œæœºå™¨äººå¯ä»¥æ›´å‡†ç¡®åœ°è¯„ä¼°åœ°å½¢ï¼Œä»è€Œå®ç°æ›´å®‰å…¨ã€æ›´é«˜æ•ˆçš„è½è„šç‚¹é€‰æ‹©å’Œè¿åŠ¨æ§åˆ¶ã€‚è¿™ç§æ˜¾å¼è¡¨è¾¾é¿å…äº†éšå¼æ¨æ–­å¸¦æ¥çš„ä¿¡æ¯æŸå¤±ï¼Œå¹¶å‡å°‘äº†å¯¹å™ªå£°æ•°æ®çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSTARTæ¡†æ¶æ˜¯ä¸€ä¸ªå•é˜¶æ®µå­¦ä¹ æ¡†æ¶ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹æ¨¡å—ï¼š1) æ„ŸçŸ¥æ¨¡å—ï¼šåˆ©ç”¨æ¿è½½è§†è§‰å’Œæœ¬ä½“æ„Ÿå—æ•°æ®ä½œä¸ºè¾“å…¥ã€‚2) åœ°å½¢é‡å»ºæ¨¡å—ï¼šåŸºäºæ„ŸçŸ¥æ•°æ®é‡å»ºå±€éƒ¨åœ°å½¢é«˜åº¦å›¾ï¼Œä½œä¸ºä¸­é—´è¡¨ç¤ºã€‚3) æ§åˆ¶æ¨¡å—ï¼šåŸºäºé‡å»ºçš„åœ°å½¢é«˜åº¦å›¾å’Œæœºå™¨äººçŠ¶æ€ï¼Œç”Ÿæˆè¿åŠ¨æ§åˆ¶æŒ‡ä»¤ã€‚æ•´ä¸ªæ¡†æ¶é€šè¿‡ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œä»¥ä¼˜åŒ–æœºå™¨äººåœ¨ç¨€ç–åœ°å½¢ä¸­çš„è¿åŠ¨æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæ˜¾å¼åœ°å½¢é‡å»ºä½œä¸ºä¸­é—´è¡¨ç¤ºã€‚ä¸ç›´æ¥ä»ä¼ æ„Ÿå™¨æ•°æ®å­¦ä¹ æ§åˆ¶ç­–ç•¥çš„æ–¹æ³•ç›¸æ¯”ï¼ŒSTARTé€šè¿‡æ˜¾å¼åœ°é‡å»ºåœ°å½¢ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç¯å¢ƒï¼Œä»è€Œæé«˜è¿åŠ¨çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå•é˜¶æ®µå­¦ä¹ æ¡†æ¶ç®€åŒ–äº†è®­ç»ƒæµç¨‹ï¼Œé™ä½äº†è®­ç»ƒæˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ°å½¢é‡å»ºæ¨¡å—å¯èƒ½é‡‡ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä¾‹å¦‚å·ç§¯ç¥ç»ç½‘ç»œæˆ–Transformerï¼Œå°†è§†è§‰å’Œæœ¬ä½“æ„Ÿå—æ•°æ®æ˜ å°„åˆ°é«˜åº¦å›¾ã€‚æŸå¤±å‡½æ•°å¯èƒ½åŒ…æ‹¬åœ°å½¢é‡å»ºæŸå¤±ï¼ˆä¾‹å¦‚ï¼Œå‡æ–¹è¯¯å·®ï¼‰å’Œè¿åŠ¨æ§åˆ¶æŸå¤±ï¼ˆä¾‹å¦‚ï¼Œå¥–åŠ±å‡½æ•°ï¼Œæƒ©ç½šæ‘”å€’æˆ–ä¸ç¨³å®šçš„è¿åŠ¨ï¼‰ã€‚æ§åˆ¶æ¨¡å—å¯èƒ½é‡‡ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œä¾‹å¦‚PPOæˆ–SACï¼Œä»¥ä¼˜åŒ–æœºå™¨äººçš„è¿åŠ¨ç­–ç•¥ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„ã€å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°æƒé‡ç­‰ç»†èŠ‚éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

STARTæ¡†æ¶åœ¨çœŸå®ä¸–ç•Œçš„ç¨€ç–è½è„šç‚¹åœ°å½¢ä¸­å®ç°äº†é›¶æ ·æœ¬è¿ç§»ï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šç¯å¢ƒè¿›è¡Œé‡æ–°è®­ç»ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSTARTèƒ½å¤Ÿå®ç°æ›´ç²¾ç¡®çš„è½è„šç‚¹æ”¾ç½®å’Œæ›´ç¨³å®šçš„è¿åŠ¨ï¼Œä¼˜äºç°æœ‰çš„åŸºäºé«˜åº¦å›¾æˆ–éšå¼åœ°å½¢æ¨æ–­çš„æ–¹æ³•ã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®ï¼ˆä¾‹å¦‚ï¼ŒæˆåŠŸç©¿è¶Šåœ°å½¢çš„æ¦‚ç‡ã€è¿åŠ¨é€Ÿåº¦ç­‰ï¼‰éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœæ•‘ã€å‹˜æ¢ã€ç‰©æµç­‰é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚ã€å´å²–æˆ–äººç±»éš¾ä»¥åˆ°è¾¾çš„ç¯å¢ƒä¸­ã€‚ä¾‹å¦‚ï¼Œåœ¨åœ°éœ‡ç¾åŒºï¼Œå››è¶³æœºå™¨äººå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯åœ¨ç“¦ç ¾å †ä¸­å®‰å…¨ç§»åŠ¨ï¼Œæœå¯»å¹¸å­˜è€…ã€‚åœ¨å·¥ä¸šåœºæ™¯ä¸­ï¼Œå¯ä»¥ç”¨äºæ£€æµ‹å’Œç»´æŠ¤ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Traversing terrains with sparse footholds like legged animals presents a promising yet challenging task for quadruped robots, as it requires precise environmental perception and agile control to secure safe foot placement while maintaining dynamic stability. Model-based hierarchical controllers excel in laboratory settings, but suffer from limited generalization and overly conservative behaviors. End-to-end learning-based approaches unlock greater flexibility and adaptability, but existing state-of-the-art methods either rely on heightmaps that introduce noise and complex, costly pipelines, or implicitly infer terrain features from egocentric depth images, often missing accurate critical geometric cues and leading to inefficient learning and rigid gaits. To overcome these limitations, we propose START, a single-stage learning framework that enables agile, stable locomotion on highly sparse and randomized footholds. START leverages only low-cost onboard vision and proprioception to accurately reconstruct local terrain heightmap, providing an explicit intermediate representation to convey essential features relevant to sparse foothold regions. This supports comprehensive environmental understanding and precise terrain assessment, reducing exploration cost and accelerating skill acquisition. Experimental results demonstrate that START achieves zero-shot transfer across diverse real-world scenarios, showcasing superior adaptability, precise foothold placement, and robust locomotion.

