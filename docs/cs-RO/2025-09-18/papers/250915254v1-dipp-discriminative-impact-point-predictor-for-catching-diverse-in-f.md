---
layout: default
title: DIPP: Discriminative Impact Point Predictor for Catching Diverse In-Flight Objects
---

# DIPP: Discriminative Impact Point Predictor for Catching Diverse In-Flight Objects

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15254" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15254v1</a>
  <a href="https://arxiv.org/pdf/2509.15254.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15254v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15254v1', 'DIPP: Discriminative Impact Point Predictor for Catching Diverse In-Flight Objects')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ngoc Huy Nguyen, Kazuki Shibata, Takamitsu Matsubara

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: 9 pages, 9 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDIPPæ¨¡å‹ï¼Œç”¨äºå››è¶³æœºå™¨äººæ¥å–ç©ºä¸­é£è¡Œç‰©ä½“çš„è½ç‚¹é¢„æµ‹ï¼Œæå‡å¤æ‚ç¯å¢ƒä¸‹çš„æ³›åŒ–æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è½ç‚¹é¢„æµ‹` `å››è¶³æœºå™¨äºº` `é£è¡Œç‰©ä½“æ¥å–` `åˆ¤åˆ«å¼ç‰¹å¾åµŒå…¥` `éç¨³æ€ç©ºæ°”åŠ¨åŠ›å­¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ç¼ºä¹åœ¨å¤æ‚ç©ºæ°”åŠ¨åŠ›å­¦æ¡ä»¶ä¸‹ï¼Œå¯¹å¤šæ ·ç‰©ä½“çš„è½ç‚¹é¢„æµ‹èƒ½åŠ›ï¼Œæ³›åŒ–æ€§ä¸è¶³ã€‚
2. æå‡ºDIPPæ¨¡å‹ï¼Œé€šè¿‡åˆ¤åˆ«å¼ç‰¹å¾åµŒå…¥åˆ†ç¦»ä¸åŒåŠ¨åŠ›å­¦è½¨è¿¹ï¼Œå®ç°æ—©æœŸå‡†ç¡®é¢„æµ‹å’Œæ³›åŒ–ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDIPPåœ¨çœŸå®æ•°æ®é›†ä¸Šä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œå¹¶åœ¨ä»¿çœŸå’ŒçœŸå®ç¯å¢ƒä¸­éªŒè¯äº†å…¶æ¥å–æˆåŠŸç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶è‡´åŠ›äºè§£å†³å››è¶³æœºå™¨äººä½¿ç”¨ç¯®ç­æ¥å–ç©ºä¸­é£è¡Œç‰©ä½“çš„ä»»åŠ¡ï¼Œæ ¸å¿ƒåœ¨äºç²¾ç¡®é¢„æµ‹ç‰©ä½“çš„è½ç‚¹ã€‚è¯¥ä»»åŠ¡é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼šç¼ºä¹åŒ…å«å¤šæ ·ç‰©ä½“å’Œéç¨³æ€ç©ºæ°”åŠ¨åŠ›å­¦å½±å“çš„å…¬å¼€æ•°æ®é›†ï¼Œè¿™å¯¹äºè®­ç»ƒå¯é çš„é¢„æµ‹å™¨è‡³å…³é‡è¦ï¼›ä»¥åŠåœ¨è½¨è¿¹ç›¸ä¼¼çš„æƒ…å†µä¸‹ï¼Œéš¾ä»¥åœ¨æ—©æœŸé˜¶æ®µå‡†ç¡®é¢„æµ‹è½ç‚¹ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«20ç§ç‰©ä½“å…±8000æ¡è½¨è¿¹çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ï¼Œä¸ºå¤æ‚ç©ºæ°”åŠ¨åŠ›å­¦æ¡ä»¶ä¸‹çš„é£è¡Œç‰©ä½“æ¥å–ç ”ç©¶å¥ å®šåŸºç¡€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†åˆ¤åˆ«å¼è½ç‚¹é¢„æµ‹å™¨ï¼ˆDIPPï¼‰ï¼Œå®ƒç”±ä¸¤ä¸ªæ¨¡å—ç»„æˆï¼šï¼ˆiï¼‰åˆ¤åˆ«å¼ç‰¹å¾åµŒå…¥ï¼ˆDFEï¼‰ï¼Œé€šè¿‡åŠ¨åŠ›å­¦åˆ†ç¦»è½¨è¿¹ï¼Œå®ç°æ—©æœŸåˆ¤åˆ«å’Œæ³›åŒ–ï¼›ï¼ˆiiï¼‰è½ç‚¹é¢„æµ‹å™¨ï¼ˆIPPï¼‰ï¼Œä»è¿™äº›ç‰¹å¾ä¸­ä¼°è®¡è½ç‚¹ã€‚IPPå®ç°äº†ä¸¤ç§å˜ä½“ï¼šåŸºäºç¥ç»åŠ é€Ÿä¼°è®¡å™¨ï¼ˆNAEï¼‰çš„æ–¹æ³•ï¼Œé¢„æµ‹è½¨è¿¹å¹¶æ¨å¯¼è½ç‚¹ï¼›ä»¥åŠåŸºäºç›´æ¥ç‚¹ä¼°è®¡å™¨ï¼ˆDPEï¼‰çš„æ–¹æ³•ï¼Œç›´æ¥è¾“å‡ºè½ç‚¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†æ¯”ç°æœ‰æ•°æ®é›†æ›´åŠ å¤šæ ·å’Œå¤æ‚ï¼Œå¹¶ä¸”æˆ‘ä»¬çš„æ–¹æ³•åœ¨15ä¸ªå·²çŸ¥ç‰©ä½“å’Œ5ä¸ªæœªçŸ¥ç‰©ä½“ä¸Šå‡ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¡¨æ˜ï¼Œæ”¹è¿›çš„æ—©æœŸé¢„æµ‹å¯ä»¥æé«˜ä»¿çœŸä¸­çš„æ¥å–æˆåŠŸç‡ï¼Œå¹¶é€šè¿‡çœŸå®ä¸–ç•Œçš„å®éªŒè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å››è¶³æœºå™¨äººæ¥å–é£è¡Œç‰©ä½“çš„è½ç‚¹é¢„æµ‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å…·æœ‰å¤æ‚ç©ºæ°”åŠ¨åŠ›å­¦ç‰¹æ€§å’Œå½¢çŠ¶å„å¼‚çš„ç‰©ä½“æ—¶ï¼Œé¢„æµ‹ç²¾åº¦è¾ƒä½ï¼Œå°¤å…¶æ˜¯åœ¨é£è¡Œè½¨è¿¹çš„æ—©æœŸé˜¶æ®µï¼Œéš¾ä»¥åŒºåˆ†ä¸åŒç‰©ä½“çš„è½¨è¿¹ï¼Œå¯¼è‡´é¢„æµ‹è¯¯å·®ç´¯ç§¯ã€‚ç¼ºä¹è¶³å¤Ÿå¤šæ ·åŒ–çš„æ•°æ®é›†ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åˆ¤åˆ«å¼ç‰¹å¾åµŒå…¥ï¼ˆDFEï¼‰æ¥åŒºåˆ†ä¸åŒåŠ¨åŠ›å­¦ç‰¹æ€§çš„ç‰©ä½“è½¨è¿¹ï¼Œä»è€Œå®ç°æ›´å‡†ç¡®çš„æ—©æœŸè½ç‚¹é¢„æµ‹ã€‚é€šè¿‡å­¦ä¹ ä¸€ä¸ªèƒ½å¤Ÿæœ‰æ•ˆåˆ†ç¦»ä¸åŒç‰©ä½“è½¨è¿¹çš„ç‰¹å¾ç©ºé—´ï¼ŒDIPPå¯ä»¥æ›´æ—©åœ°æ•æ‰åˆ°ç‰©ä½“ä¹‹é—´çš„å·®å¼‚ï¼Œå‡å°‘é¢„æµ‹è¯¯å·®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDIPPæ¨¡å‹åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šåˆ¤åˆ«å¼ç‰¹å¾åµŒå…¥ï¼ˆDFEï¼‰å’Œè½ç‚¹é¢„æµ‹å™¨ï¼ˆIPPï¼‰ã€‚é¦–å…ˆï¼ŒDFEæ¨¡å—æ¥æ”¶ç‰©ä½“çš„é£è¡Œè½¨è¿¹æ•°æ®ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å…¶åµŒå…¥åˆ°ä¸€ä¸ªåˆ¤åˆ«å¼ç‰¹å¾ç©ºé—´ä¸­ã€‚ç„¶åï¼ŒIPPæ¨¡å—åˆ©ç”¨è¿™äº›ç‰¹å¾æ¥é¢„æµ‹ç‰©ä½“çš„è½ç‚¹ã€‚IPPæ¨¡å—æœ‰ä¸¤ç§å®ç°æ–¹å¼ï¼šä¸€ç§æ˜¯åŸºäºç¥ç»åŠ é€Ÿä¼°è®¡å™¨ï¼ˆNAEï¼‰ï¼Œé€šè¿‡é¢„æµ‹è½¨è¿¹æ¥æ¨å¯¼è½ç‚¹ï¼›å¦ä¸€ç§æ˜¯åŸºäºç›´æ¥ç‚¹ä¼°è®¡å™¨ï¼ˆDPEï¼‰ï¼Œç›´æ¥é¢„æµ‹è½ç‚¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šDIPPçš„å…³é”®åˆ›æ–°åœ¨äºåˆ¤åˆ«å¼ç‰¹å¾åµŒå…¥ï¼ˆDFEï¼‰æ¨¡å—ã€‚DFEé€šè¿‡å­¦ä¹ ä¸€ä¸ªèƒ½å¤Ÿæœ‰æ•ˆåˆ†ç¦»ä¸åŒç‰©ä½“è½¨è¿¹çš„ç‰¹å¾ç©ºé—´ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨é£è¡Œè½¨è¿¹çš„æ—©æœŸé˜¶æ®µå°±å‡†ç¡®åŒºåˆ†ä¸åŒç‰©ä½“ï¼Œä»è€Œæé«˜è½ç‚¹é¢„æµ‹çš„ç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿçš„ç›´æ¥é¢„æµ‹è½ç‚¹çš„æ–¹æ³•ç›¸æ¯”ï¼ŒDIPPæ›´åŠ æ³¨é‡å¯¹ç‰©ä½“åŠ¨åŠ›å­¦ç‰¹æ€§çš„å»ºæ¨¡ã€‚

**å…³é”®è®¾è®¡**ï¼šDFEæ¨¡å—ä½¿ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥å­¦ä¹ ç‰¹å¾åµŒå…¥ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡æ—¨åœ¨æœ€å¤§åŒ–ä¸åŒç‰©ä½“è½¨è¿¹ä¹‹é—´çš„è·ç¦»ï¼ŒåŒæ—¶æœ€å°åŒ–åŒä¸€ç‰©ä½“è½¨è¿¹å†…éƒ¨çš„è·ç¦»ã€‚IPPæ¨¡å—çš„NAEå˜ä½“ä½¿ç”¨å¦ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥é¢„æµ‹ç‰©ä½“çš„åŠ é€Ÿåº¦ï¼Œç„¶åé€šè¿‡ç§¯åˆ†å¾—åˆ°è½¨è¿¹å’Œè½ç‚¹ã€‚DPEå˜ä½“åˆ™ç›´æ¥ä½¿ç”¨ç¥ç»ç½‘ç»œé¢„æµ‹è½ç‚¹åæ ‡ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDIPPæ¨¡å‹åœ¨åŒ…å«20ç§ç‰©ä½“çš„çœŸå®æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚åœ¨15ä¸ªå·²çŸ¥ç‰©ä½“å’Œ5ä¸ªæœªçŸ¥ç‰©ä½“ä¸Šçš„æµ‹è¯•è¡¨æ˜ï¼ŒDIPPå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œä»¿çœŸå’ŒçœŸå®ç¯å¢ƒä¸­çš„å®éªŒéªŒè¯äº†DIPPèƒ½å¤Ÿæé«˜å››è¶³æœºå™¨äººçš„æ¥å–æˆåŠŸç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºç‰©æµã€ä»“å‚¨ã€æ•‘æ´ç­‰é¢†åŸŸï¼Œä¾‹å¦‚ï¼Œæœºå™¨äººå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯è‡ªåŠ¨æ¥å–ä»ç©ºä¸­æŠ•æ·çš„åŒ…è£¹æˆ–æ•‘æ´ç‰©èµ„ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–éœ€è¦ç²¾ç¡®é¢„æµ‹ç‰©ä½“è¿åŠ¨è½¨è¿¹çš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼Œè¿åŠ¨åˆ†æã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this study, we address the problem of in-flight object catching using a quadruped robot with a basket. Our objective is to accurately predict the impact point, defined as the object's landing position. This task poses two key challenges: the absence of public datasets capturing diverse objects under unsteady aerodynamics, which are essential for training reliable predictors; and the difficulty of accurate early-stage impact point prediction when trajectories appear similar across objects. To overcome these issues, we construct a real-world dataset of 8,000 trajectories from 20 objects, providing a foundation for advancing in-flight object catching under complex aerodynamics. We then propose the Discriminative Impact Point Predictor (DIPP), consisting of two modules: (i) a Discriminative Feature Embedding (DFE) that separates trajectories by dynamics to enable early-stage discrimination and generalization, and (ii) an Impact Point Predictor (IPP) that estimates the impact point from these features. Two IPP variants are implemented: an Neural Acceleration Estimator (NAE)-based method that predicts trajectories and derives the impact point, and a Direct Point Estimator (DPE)-based method that directly outputs it. Experimental results show that our dataset is more diverse and complex than existing dataset, and that our method outperforms baselines on both 15 seen and 5 unseen objects. Furthermore, we show that improved early-stage prediction enhances catching success in simulation and demonstrate the effectiveness of our approach through real-world experiments. The demonstration is available at https://sites.google.com/view/robot-catching-2025.

