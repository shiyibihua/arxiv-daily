---
layout: default
title: Toward Embodiment Equivariant Vision-Language-Action Policy
---

# Toward Embodiment Equivariant Vision-Language-Action Policy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14630" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14630v1</a>
  <a href="https://arxiv.org/pdf/2509.14630.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14630v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14630v1', 'Toward Embodiment Equivariant Vision-Language-Action Policy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Anzhe Chen, Yifei Yang, Zhenjie Zhu, Kechun Xu, Zhongxiang Zhou, Rong Xiong, Yue Wang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/hhcaz/e2vla)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå…·èº«ç­‰å˜è§†è§‰-è¯­è¨€-åŠ¨ä½œç­–ç•¥ï¼Œæå‡æœºå™¨äººæ³›åŒ–èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å…·èº«æ™ºèƒ½` `è§†è§‰-è¯­è¨€-åŠ¨ä½œç­–ç•¥` `æœºå™¨äººæ³›åŒ–` `ç­‰å˜æ€§` `æœºå™¨äººæ“ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œç­–ç•¥åœ¨æœºå™¨äººé…ç½®æ³›åŒ–æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œä¸»è¦åŸå› æ˜¯ç¼ºä¹å¯¹åŠ¨ä½œç©ºé—´è®¾è®¡çš„å…³æ³¨ã€‚
2. è®ºæ–‡æ ¸å¿ƒæ€æƒ³æ˜¯å°†è·¨å…·èº«é¢„è®­ç»ƒå»ºæ¨¡ä¸ºè®¾è®¡å¯¹å…·èº«é…ç½®è½¬æ¢ç­‰å˜çš„ç­–ç•¥ï¼Œä»è€Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æé«˜äº†é¢„è®­ç»ƒçš„æœ‰æ•ˆæ€§ï¼Œå¹¶èƒ½å¯¹æ–°çš„æœºå™¨äººå…·èº«è¿›è¡Œé«˜æ•ˆå¾®è°ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œç­–ç•¥é€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒå­¦ä¹ è·¨ä»»åŠ¡ã€ç¯å¢ƒå’Œå…·èº«æœºå™¨äººçš„æ“ä½œæŠ€èƒ½ã€‚ç„¶è€Œï¼Œå®ƒä»¬æ³›åŒ–åˆ°æ–°çš„æœºå™¨äººé…ç½®çš„èƒ½åŠ›ä»ç„¶æœ‰é™ã€‚å¤§å¤šæ•°æ–¹æ³•ä¾§é‡äºæ¨¡å‹å¤§å°ã€æ•°æ®é›†è§„æ¨¡å’Œå¤šæ ·æ€§ï¼Œè€Œè¾ƒå°‘å…³æ³¨åŠ¨ä½œç©ºé—´çš„è®¾è®¡ã€‚è¿™å¯¼è‡´äº†é…ç½®æ³›åŒ–é—®é¢˜ï¼Œéœ€è¦æ˜‚è´µçš„é€‚é…ã€‚æˆ‘ä»¬é€šè¿‡å°†è·¨å…·èº«é¢„è®­ç»ƒå®šä¹‰ä¸ºè®¾è®¡å¯¹å…·èº«é…ç½®è½¬æ¢ç­‰å˜çš„ç­–ç•¥æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ï¼ˆiï¼‰ä¸ºåŠ¨ä½œç©ºé—´å’Œç­–ç•¥è®¾è®¡å»ºç«‹äº†å…·èº«ç­‰å˜ç†è®ºï¼Œï¼ˆiiï¼‰å¼•å…¥äº†ä¸€ä¸ªå¼ºåˆ¶é…ç½®ç­‰å˜çš„åŠ¨ä½œè§£ç å™¨ï¼Œä»¥åŠï¼ˆiiiï¼‰ç»“åˆäº†ä¸€ä¸ªå‡ ä½•æ„ŸçŸ¥ç½‘ç»œæ¶æ„ï¼Œä»¥å¢å¼ºå…·èº«æ— å…³çš„ç©ºé—´æ¨ç†ã€‚åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­çš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†é¢„è®­ç»ƒçš„æœ‰æ•ˆæ€§ï¼Œå¹¶èƒ½å¤Ÿå¯¹æ–°çš„æœºå™¨äººå…·èº«è¿›è¡Œé«˜æ•ˆçš„å¾®è°ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰-è¯­è¨€-åŠ¨ä½œç­–ç•¥åœ¨å­¦ä¹ æœºå™¨äººæ“ä½œæŠ€èƒ½æ—¶ï¼Œè™½ç„¶å¯ä»¥é€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒåœ¨ä¸åŒä»»åŠ¡ã€ç¯å¢ƒå’Œæœºå™¨äººä¸Šè¿›è¡Œæ³›åŒ–ï¼Œä½†å¯¹äºæ–°çš„æœºå™¨äººé…ç½®ï¼ˆä¾‹å¦‚ï¼Œä¸åŒå°ºå¯¸ã€å…³èŠ‚ç»“æ„çš„æœºå™¨äººï¼‰çš„æ³›åŒ–èƒ½åŠ›ä»ç„¶æœ‰é™ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æ¨¡å‹è§„æ¨¡å’Œæ•°æ®å¤šæ ·æ€§ï¼Œå¿½ç•¥äº†åŠ¨ä½œç©ºé—´çš„è®¾è®¡ï¼Œå¯¼è‡´éœ€è¦æ˜‚è´µçš„é€‚é…è¿‡ç¨‹æ‰èƒ½åœ¨æ–°æœºå™¨äººä¸Šå·¥ä½œã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è·¨å…·èº«é¢„è®­ç»ƒé—®é¢˜è½¬åŒ–ä¸ºè®¾è®¡å¯¹å…·èº«é…ç½®è½¬æ¢å…·æœ‰ç­‰å˜æ€§çš„ç­–ç•¥ã€‚è¿™æ„å‘³ç€ï¼Œå½“æœºå™¨äººé…ç½®å‘ç”Ÿå˜åŒ–æ—¶ï¼Œç­–ç•¥çš„è¾“å‡ºï¼ˆå³åŠ¨ä½œï¼‰åº”è¯¥ä»¥ä¸€ç§å¯é¢„æµ‹çš„æ–¹å¼è¿›è¡Œå˜æ¢ã€‚é€šè¿‡å¼ºåˆ¶ç­–ç•¥çš„ç­‰å˜æ€§ï¼Œå¯ä»¥ä½¿å…¶æ›´å¥½åœ°æ³›åŒ–åˆ°æ–°çš„æœºå™¨äººé…ç½®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼š(1) å…·èº«ç­‰å˜ç†è®ºï¼Œç”¨äºæŒ‡å¯¼åŠ¨ä½œç©ºé—´å’Œç­–ç•¥çš„è®¾è®¡ï¼›(2) ç­‰å˜åŠ¨ä½œè§£ç å™¨ï¼Œç”¨äºå¼ºåˆ¶ç­–ç•¥çš„é…ç½®ç­‰å˜æ€§ï¼›(3) å‡ ä½•æ„ŸçŸ¥ç½‘ç»œæ¶æ„ï¼Œç”¨äºå¢å¼ºå…·èº«æ— å…³çš„ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼Œé¦–å…ˆä½¿ç”¨å‡ ä½•æ„ŸçŸ¥ç½‘ç»œæå–è§†è§‰ç‰¹å¾ï¼Œç„¶åç»“åˆè¯­è¨€æŒ‡ä»¤ï¼Œé€šè¿‡ç­‰å˜åŠ¨ä½œè§£ç å™¨ç”ŸæˆåŠ¨ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†å…·èº«ç­‰å˜æ€§çš„æ¦‚å¿µï¼Œå¹¶å°†å…¶åº”ç”¨äºè§†è§‰-è¯­è¨€-åŠ¨ä½œç­–ç•¥çš„è®¾è®¡ä¸­ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä¸å†ä¾èµ–äºå¤§é‡ç‰¹å®šäºæœºå™¨äººé…ç½®çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè€Œæ˜¯é€šè¿‡å¼ºåˆ¶ç­–ç•¥çš„ç­‰å˜æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°æ³›åŒ–åˆ°æ–°çš„æœºå™¨äººé…ç½®ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) è®¾è®¡äº†ä¸€ç§ç­‰å˜åŠ¨ä½œè§£ç å™¨ï¼Œè¯¥è§£ç å™¨èƒ½å¤Ÿæ ¹æ®æœºå™¨äººé…ç½®çš„å˜åŒ–ï¼Œå¯¹åŠ¨ä½œè¿›è¡Œç›¸åº”çš„å˜æ¢ï¼›(2) æå‡ºäº†ä¸€ç§å‡ ä½•æ„ŸçŸ¥ç½‘ç»œæ¶æ„ï¼Œè¯¥æ¶æ„èƒ½å¤Ÿæå–ä¸æœºå™¨äººé…ç½®æ— å…³çš„ç©ºé—´ç‰¹å¾ï¼›(3) å®šä¹‰äº†åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œç”¨äºè®­ç»ƒç­‰å˜ç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æœºå™¨äººç¯å¢ƒä¸­è¿›è¡Œäº†å¤§é‡å®éªŒï¼Œç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æé«˜é¢„è®­ç»ƒçš„æœ‰æ•ˆæ€§ï¼Œå¹¶èƒ½å¤Ÿå¯¹æ–°çš„æœºå™¨äººå…·èº«è¿›è¡Œé«˜æ•ˆçš„å¾®è°ƒã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•åœ¨æ–°çš„æœºå™¨äººé…ç½®ä¸Šçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶ä¸”æ‰€éœ€çš„å¾®è°ƒæ•°æ®é‡æ›´å°‘ã€‚å®éªŒç»“æœéªŒè¯äº†è¯¥æ–¹æ³•åœ¨æœºå™¨äººé…ç½®æ³›åŒ–æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¿«é€Ÿéƒ¨ç½²åˆ°ä¸åŒæœºå™¨äººå¹³å°ä¸Šçš„åœºæ™¯ä¸­ã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½åˆ¶é€ ã€ä»“å‚¨ç‰©æµã€å®¶åº­æœåŠ¡ç­‰é¢†åŸŸï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•å¿«é€Ÿè®­ç»ƒå‡ºé€‚ç”¨äºä¸åŒæœºå™¨äººçš„æ“ä½œç­–ç•¥ï¼Œé™ä½éƒ¨ç½²æˆæœ¬ï¼Œæé«˜ç”Ÿäº§æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿä¸ºæœºå™¨äººé€šç”¨äººå·¥æ™ºèƒ½çš„å‘å±•å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-language-action policies learn manipulation skills across tasks, environments and embodiments through large-scale pre-training. However, their ability to generalize to novel robot configurations remains limited. Most approaches emphasize model size, dataset scale and diversity while paying less attention to the design of action spaces. This leads to the configuration generalization problem, which requires costly adaptation. We address this challenge by formulating cross-embodiment pre-training as designing policies equivariant to embodiment configuration transformations. Building on this principle, we propose a framework that (i) establishes a embodiment equivariance theory for action space and policy design, (ii) introduces an action decoder that enforces configuration equivariance, and (iii) incorporates a geometry-aware network architecture to enhance embodiment-agnostic spatial reasoning. Extensive experiments in both simulation and real-world settings demonstrate that our approach improves pre-training effectiveness and enables efficient fine-tuning on novel robot embodiments. Our code is available at https://github.com/hhcaz/e2vla

