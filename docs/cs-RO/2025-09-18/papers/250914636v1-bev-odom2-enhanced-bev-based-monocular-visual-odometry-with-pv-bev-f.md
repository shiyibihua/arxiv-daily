---
layout: default
title: BEV-ODOM2: Enhanced BEV-based Monocular Visual Odometry with PV-BEV Fusion and Dense Flow Supervision for Ground Robots
---

# BEV-ODOM2: Enhanced BEV-based Monocular Visual Odometry with PV-BEV Fusion and Dense Flow Supervision for Ground Robots

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14636" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.14636v1</a>
  <a href="https://arxiv.org/pdf/2509.14636.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14636v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14636v1', 'BEV-ODOM2: Enhanced BEV-based Monocular Visual Odometry with PV-BEV Fusion and Dense Flow Supervision for Ground Robots')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yufei Wei, Wangtao Lu, Sha Lu, Chenxiao Hu, Fuzhang Han, Rong Xiong, Yue Wang

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-18

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**BEV-ODOM2ÔºöÈù¢ÂêëÂú∞Èù¢Êú∫Âô®‰∫∫ÁöÑPV-BEVËûçÂêà‰∏éÁ®†ÂØÜÂÖâÊµÅÁõëÁù£ÂçïÁõÆËßÜËßâÈáåÁ®ãËÆ°**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `ÂçïÁõÆËßÜËßâÈáåÁ®ãËÆ°` `È∏üÁû∞Âõæ` `PV-BEVËûçÂêà` `Á®†ÂØÜÂÖâÊµÅÁõëÁù£` `Âú∞Èù¢Êú∫Âô®‰∫∫` `‰ΩçÂßø‰º∞ËÆ°` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâBEVÊñπÊ≥ïÂú®ÂçïÁõÆËßÜËßâÈáåÁ®ãËÆ°‰∏≠Èù¢‰∏¥ÁõëÁù£‰ø°Âè∑Á®ÄÁñèÂíåÈÄèËßÜÊäïÂΩ±‰ø°ÊÅØÊçüÂ§±ÁöÑÊåëÊàò„ÄÇ
2. BEV-ODOM2ÈÄöËøáÂºïÂÖ•Á®†ÂØÜBEVÂÖâÊµÅÁõëÁù£ÂíåPV-BEVËûçÂêàÊù•Â¢ûÂº∫ÁâπÂæÅË°®ËææÔºåÊèêÂçá‰ΩçÂßø‰º∞ËÆ°Á≤æÂ∫¶„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåBEV-ODOM2Âú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåRTEÈôç‰Ωé‰∫Ü40%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫BEV-ODOM2Ôºå‰∏Ä‰∏™Â¢ûÂº∫ÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®Ëß£ÂÜ≥Âü∫‰∫éÈ∏üÁû∞ÂõæÔºàBEVÔºâÁöÑÂçïÁõÆËßÜËßâÈáåÁ®ãËÆ°ÔºàMVOÔºâ‰∏≠Â≠òÂú®ÁöÑÁ®ÄÁñèÁõëÁù£‰ø°Âè∑ÂíåÈÄèËßÜ-BEVÊäïÂΩ±ËøáÁ®ã‰∏≠ÁöÑ‰ø°ÊÅØÊçüÂ§±ÈóÆÈ¢òÔºå‰∏îÊó†ÈúÄÈ¢ùÂ§ñÊ†áÊ≥®„ÄÇËØ•ÊñπÊ≥ïÂºïÂÖ•‰∫ÜÔºöÔºà1Ôºâ‰ªé3Ëá™Áî±Â∫¶Ôºà3-DoFÔºâ‰ΩçÂßøÁúüÂÄºÊûÑÂª∫ÁöÑÁ®†ÂØÜBEVÂÖâÊµÅÁõëÁù£ÔºåÁî®‰∫éÂÉèÁ¥†Á∫ßÊåáÂØºÔºõÔºà2ÔºâPV-BEVËûçÂêàÔºåÂú®ÊäïÂΩ±ÂâçËÆ°ÁÆóÁõ∏ÂÖ≥‰ΩìÁßØÔºå‰ª•‰øùÁïô6Ëá™Áî±Â∫¶Ôºà6-DoFÔºâËøêÂä®Á∫øÁ¥¢ÔºåÂêåÊó∂‰øùÊåÅÂ∞∫Â∫¶‰∏ÄËá¥ÊÄß„ÄÇËØ•Ê°ÜÊû∂ÈááÁî®‰∏âÁßç‰ªÖ‰ªé‰ΩçÂßøÊï∞ÊçÆÂØºÂá∫ÁöÑÁõëÁù£Á∫ßÂà´ÔºöÁ®†ÂØÜBEVÂÖâÊµÅ„ÄÅPVÂàÜÊîØÁöÑ5Ëá™Áî±Â∫¶Ôºà5-DoFÔºâÂíåÊúÄÁªà3Ëá™Áî±Â∫¶Ôºà3-DoFÔºâËæìÂá∫„ÄÇÂ¢ûÂº∫ÁöÑÊóãËΩ¨ÈááÊ†∑Ëøõ‰∏ÄÊ≠•Âπ≥Ë°°‰∫ÜËÆ≠ÁªÉ‰∏≠‰∏çÂêåÁöÑËøêÂä®Ê®°Âºè„ÄÇÂú®KITTI„ÄÅNCLT„ÄÅOxfordÂíåÊñ∞Êî∂ÈõÜÁöÑZJH-VOÂ§öÂ∞∫Â∫¶Êï∞ÊçÆÈõÜ‰∏äÁöÑÂ§ßÈáèËØÑ‰º∞Ë°®ÊòéÔºåËØ•ÊñπÊ≥ïËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºå‰∏é‰πãÂâçÁöÑBEVÊñπÊ≥ïÁõ∏ÊØîÔºåRTEÔºàÊóãËΩ¨Âπ≥ÁßªËØØÂ∑ÆÔºâÊèêÈ´ò‰∫Ü40%„ÄÇZJH-VOÊï∞ÊçÆÈõÜÊ∂µÁõñ‰∫Ü‰ªéÂú∞‰∏ãÂÅúËΩ¶Âú∫Âà∞ÂÆ§Â§ñÂπøÂú∫ÁöÑÂêÑÁßçÂú∞Èù¢ËΩ¶ËæÜÂú∫ÊôØÔºåÁé∞Â∑≤ÂÖ¨ÂºÄÔºå‰ª•‰øÉËøõÊú™Êù•ÁöÑÁ†îÁ©∂„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑÂü∫‰∫éBEVÁöÑÂçïÁõÆËßÜËßâÈáåÁ®ãËÆ°ÊñπÊ≥ïÔºåÂú®Â∞ÜÂõæÂÉè‰ªéÈÄèËßÜËßÜËßíËΩ¨Êç¢Âà∞È∏üÁû∞ËßÜËßíÁöÑËøáÁ®ã‰∏≠Ôºå‰ºöÈÄ†Êàê‰ø°ÊÅØÁöÑÊçüÂ§±„ÄÇÂêåÊó∂ÔºåÁî±‰∫éÁõëÁù£‰ø°Âè∑ÁöÑÁ®ÄÁñèÊÄßÔºåÂØºËá¥Ê®°ÂûãÂ≠¶‰π†Âà∞ÁöÑÁâπÂæÅË°®ËææËÉΩÂäõ‰∏çË∂≥Ôºå‰ªéËÄåÂΩ±Âìç‰ΩçÂßø‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂ∞§ÂÖ∂ÊòØÂú®Âú∞Èù¢Êú∫Âô®‰∫∫Â∫îÁî®‰∏≠ÔºåÁ≤æÁ°ÆÁöÑÈáåÁ®ãËÆ°‰ø°ÊÅØËá≥ÂÖ≥ÈáçË¶Å„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöBEV-ODOM2ÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂºïÂÖ•Á®†ÂØÜÁöÑÂÖâÊµÅÁõëÁù£ÂíåPV-BEVËûçÂêàÊù•Â¢ûÂº∫BEVÁâπÂæÅÁöÑË°®ËææËÉΩÂäõ„ÄÇÁ®†ÂØÜÂÖâÊµÅÁõëÁù£ÂèØ‰ª•Êèê‰æõÂÉèÁ¥†Á∫ßÂà´ÁöÑËøêÂä®‰ø°ÊÅØÔºå‰ªéËÄåÊõ¥ÊúâÊïàÂú∞ÊåáÂØºÊ®°ÂûãÁöÑÂ≠¶‰π†„ÄÇPV-BEVËûçÂêàÂàôÂèØ‰ª•Âú®ÊäïÂΩ±Ââç‰øùÁïôÊõ¥Â§öÁöÑ6Ëá™Áî±Â∫¶ËøêÂä®‰ø°ÊÅØÔºåÈÅøÂÖç‰ø°ÊÅØÊçüÂ§±ÔºåÂêåÊó∂‰øùÊåÅÂ∞∫Â∫¶‰∏ÄËá¥ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöBEV-ODOM2Ê°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÂàÜÊîØÔºöPVÔºàPerspective ViewÔºâÂàÜÊîØÂíåBEVÂàÜÊîØ„ÄÇPVÂàÜÊîØÂ§ÑÁêÜÂéüÂßãÂõæÂÉèÔºåÊèêÂèñÁâπÂæÅ„ÄÇBEVÂàÜÊîØÂ∞ÜPVÂàÜÊîØÊèêÂèñÁöÑÁâπÂæÅÊäïÂΩ±Âà∞BEVÁ©∫Èó¥ÔºåÂπ∂ËøõË°åÁâπÂæÅÊèêÂèñ„ÄÇÂú®ÊäïÂΩ±‰πãÂâçÔºåËÆ°ÁÆóPVÁâπÂæÅÂíåBEVÁâπÂæÅ‰πãÈó¥ÁöÑÁõ∏ÂÖ≥‰ΩìÁßØÔºåÂÆûÁé∞PV-BEVËûçÂêà„ÄÇÊúÄÂêéÔºåÂà©Áî®ËûçÂêàÂêéÁöÑBEVÁâπÂæÅËøõË°å‰ΩçÂßø‰º∞ËÆ°„ÄÇÊï¥‰∏™Ê°ÜÊû∂ÈááÁî®Â§öÂ±ÇÊ¨°ÁöÑÁõëÁù£ÔºåÂåÖÊã¨Á®†ÂØÜBEVÂÖâÊµÅÁõëÁù£„ÄÅPVÂàÜÊîØÁöÑ5Ëá™Áî±Â∫¶‰ΩçÂßøÁõëÁù£ÂíåÊúÄÁªà3Ëá™Áî±Â∫¶‰ΩçÂßøËæìÂá∫ÁõëÁù£„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºöÔºà1ÔºâÊèêÂá∫‰∫ÜÁ®†ÂØÜBEVÂÖâÊµÅÁõëÁù£Ôºå‰∏∫BEVÁâπÂæÅÁöÑÂ≠¶‰π†Êèê‰æõ‰∫ÜÊõ¥Á≤æÁªÜÁöÑÊåáÂØº‰ø°Âè∑ÔºõÔºà2ÔºâÂºïÂÖ•‰∫ÜPV-BEVËûçÂêàÔºåÂú®ÊäïÂΩ±ÂâçËÆ°ÁÆóÁõ∏ÂÖ≥‰ΩìÁßØÔºå‰øùÁïô‰∫ÜÊõ¥Â§öÁöÑ6Ëá™Áî±Â∫¶ËøêÂä®‰ø°ÊÅØÔºåÈÅøÂÖç‰∫Ü‰ø°ÊÅØÊçüÂ§±„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåBEV-ODOM2ËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®ÂõæÂÉè‰ø°ÊÅØÔºåÊèêÈ´ò‰ΩçÂßø‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®PV-BEVËûçÂêà‰∏≠Ôºå‰ΩøÁî®‰∫ÜÁõ∏ÂÖ≥‰ΩìÁßØÊù•Ë°°ÈáèPVÁâπÂæÅÂíåBEVÁâπÂæÅ‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶„ÄÇÂú®ÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÂ§öÂ±ÇÊ¨°ÁöÑÁõëÁù£Á≠ñÁï•ÔºåÂåÖÊã¨Á®†ÂØÜBEVÂÖâÊµÅÊçüÂ§±„ÄÅPVÂàÜÊîØÁöÑ5Ëá™Áî±Â∫¶‰ΩçÂßøÊçüÂ§±ÂíåÊúÄÁªà3Ëá™Áî±Â∫¶‰ΩçÂßøÊçüÂ§±„ÄÇÊ≠§Â§ñÔºåËøòÈááÁî®‰∫ÜÂ¢ûÂº∫ÁöÑÊóãËΩ¨ÈááÊ†∑Á≠ñÁï•Ôºå‰ª•Âπ≥Ë°°ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠‰∏çÂêåËøêÂä®Ê®°ÂºèÁöÑÂàÜÂ∏É„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

BEV-ODOM2Âú®KITTI„ÄÅNCLT„ÄÅOxfordÂíåZJH-VOÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂπøÊ≥õÁöÑËØÑ‰º∞ÔºåÁªìÊûúË°®ÊòéÂÖ∂ÊÄßËÉΩ‰ºò‰∫éÁé∞ÊúâÁöÑBEVÊñπÊ≥ï„ÄÇÁâπÂà´ÊòØÂú®RTEÊåáÊ†á‰∏äÔºåBEV-ODOM2Áõ∏ÊØî‰πãÂâçÁöÑBEVÊñπÊ≥ïÊèêÈ´ò‰∫Ü40%„ÄÇÊ≠§Â§ñÔºåËØ•ËÆ∫ÊñáËøòÂÖ¨ÂºÄ‰∫ÜÊñ∞Êî∂ÈõÜÁöÑZJH-VOÊï∞ÊçÆÈõÜÔºå‰∏∫Êú™Êù•ÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÂÆùË¥µÁöÑÊï∞ÊçÆËµÑÊ∫ê„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

BEV-ODOM2Âú®Âú∞Èù¢Êú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªüÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÁ≤æÁ°ÆÁöÑËßÜËßâÈáåÁ®ãËÆ°‰ø°ÊÅØÊòØËøô‰∫õÂ∫îÁî®ÁöÑÂü∫Á°ÄÔºåÂèØ‰ª•‰∏∫Ë∑ØÂæÑËßÑÂàí„ÄÅÁéØÂ¢ÉÊÑüÁü•ÂíåÂÜ≥Á≠ñÊèê‰æõÊîØÊåÅ„ÄÇËØ•Á†îÁ©∂ÊàêÊûúÊúâÂä©‰∫éÊèêÈ´òÂú∞Èù¢Êú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑËá™‰∏ªÂØºËà™ËÉΩÂäõÔºåÂπ∂Êé®Âä®Áõ∏ÂÖ≥ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Bird's-Eye-View (BEV) representation offers a metric-scaled planar workspace, facilitating the simplification of 6-DoF ego-motion to a more robust 3-DoF model for monocular visual odometry (MVO) in intelligent transportation systems. However, existing BEV methods suffer from sparse supervision signals and information loss during perspective-to-BEV projection. We present BEV-ODOM2, an enhanced framework addressing both limitations without additional annotations. Our approach introduces: (1) dense BEV optical flow supervision constructed from 3-DoF pose ground truth for pixel-level guidance; (2) PV-BEV fusion that computes correlation volumes before projection to preserve 6-DoF motion cues while maintaining scale consistency. The framework employs three supervision levels derived solely from pose data: dense BEV flow, 5-DoF for the PV branch, and final 3-DoF output. Enhanced rotation sampling further balances diverse motion patterns in training. Extensive evaluation on KITTI, NCLT, Oxford, and our newly collected ZJH-VO multi-scale dataset demonstrates state-of-the-art performance, achieving 40 improvement in RTE compared to previous BEV methods. The ZJH-VO dataset, covering diverse ground vehicle scenarios from underground parking to outdoor plazas, is publicly available to facilitate future research.

