---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-09-18
---

# cs.ROï¼ˆ2025-09-18ï¼‰

ğŸ“Š å…± **22** ç¯‡è®ºæ–‡
 | ğŸ”— **4** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (16 ğŸ”—4)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (4)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (16 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250915443v1-implicit-kinodynamic-motion-retargeting-for-human-to-humanoid-imitat.html">Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning</a></td>
  <td>æå‡ºéšå¼è¿åŠ¨åŠ¨åŠ›å­¦é‡å®šå‘(IKMR)ï¼Œå®ç°é«˜æ•ˆçš„äººå½¢æœºå™¨äººæ¨¡ä»¿å­¦ä¹ ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">whole-body control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15443v1" data-paper-url="./papers/250915443v1-implicit-kinodynamic-motion-retargeting-for-human-to-humanoid-imitat.html" onclick="toggleFavorite(this, '2509.15443v1', 'Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250914687v1-realmirror-a-comprehensive-open-source-vision-language-action-platfo.html">RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI</a></td>
  <td>RealMirrorï¼šä¸ºå…·èº«AIæ‰“é€ çš„å…¨é¢å¼€æºè§†è§‰-è¯­è¨€-åŠ¨ä½œå¹³å°</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">sim2real</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14687v1" data-paper-url="./papers/250914687v1-realmirror-a-comprehensive-open-source-vision-language-action-platfo.html" onclick="toggleFavorite(this, '2509.14687v1', 'RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250914939v1-a-novel-task-driven-diffusion-based-policy-with-affordance-learning-.html">A Novel Task-Driven Diffusion-Based Policy with Affordance Learning for Generalizable Manipulation of Articulated Objects</a></td>
  <td>æå‡ºDARTï¼šä¸€ç§åŸºäºå¯ä¾›æ€§å­¦ä¹ å’Œæ‰©æ•£ç­–ç•¥çš„é€šç”¨é“°æ¥ç‰©ä½“æ“ä½œæ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14939v1" data-paper-url="./papers/250914939v1-a-novel-task-driven-diffusion-based-policy-with-affordance-learning-.html" onclick="toggleFavorite(this, '2509.14939v1', 'A Novel Task-Driven Diffusion-Based Policy with Affordance Learning for Generalizable Manipulation of Articulated Objects')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250914980v1-m4diffuser-multi-view-diffusion-policy-with-manipulability-aware-con.html">M4Diffuser: Multi-View Diffusion Policy with Manipulability-Aware Control for Robust Mobile Manipulation</a></td>
  <td>M4Diffuserï¼šå¤šè§†è§’æ‰©æ•£ç­–ç•¥ä¸å¯æ“ä½œæ€§æ„ŸçŸ¥æ§åˆ¶ï¼Œæå‡ç§»åŠ¨æ“ä½œçš„é²æ£’æ€§</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">mobile manipulation</span> <span class="paper-tag">diffusion policy</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14980v1" data-paper-url="./papers/250914980v1-m4diffuser-multi-view-diffusion-policy-with-manipulability-aware-con.html" onclick="toggleFavorite(this, '2509.14980v1', 'M4Diffuser: Multi-View Diffusion Policy with Manipulability-Aware Control for Robust Mobile Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250914984v1-the-role-of-touch-towards-optimal-tactile-sensing-distribution-in-an.html">The Role of Touch: Towards Optimal Tactile Sensing Distribution in Anthropomorphic Hands for Dexterous In-Hand Manipulation</a></td>
  <td>ç ”ç©¶è§¦è§‰åœ¨çµå·§æ‰‹å†…æ“ä½œä¸­çš„ä½œç”¨ï¼Œä¼˜åŒ–æ‹Ÿäººæ‰‹éƒ¨çš„è§¦è§‰ä¼ æ„Ÿå™¨åˆ†å¸ƒ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">in-hand manipulation</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14984v1" data-paper-url="./papers/250914984v1-the-role-of-touch-towards-optimal-tactile-sensing-distribution-in-an.html" onclick="toggleFavorite(this, '2509.14984v1', 'The Role of Touch: Towards Optimal Tactile Sensing Distribution in Anthropomorphic Hands for Dexterous In-Hand Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250914932v1-robot-control-stack-a-lean-ecosystem-for-robot-learning-at-scale.html">Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale</a></td>
  <td>æå‡ºRobot Control Stack (RCS)ï¼Œç”¨äºå¤§è§„æ¨¡æœºå™¨äººå­¦ä¹ çš„ç²¾ç®€ç”Ÿæ€ç³»ç»Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span> <span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14932v1" data-paper-url="./papers/250914932v1-robot-control-stack-a-lean-ecosystem-for-robot-learning-at-scale.html" onclick="toggleFavorite(this, '2509.14932v1', 'Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250914630v1-toward-embodiment-equivariant-vision-language-action-policy.html">Toward Embodiment Equivariant Vision-Language-Action Policy</a></td>
  <td>æå‡ºå…·èº«ç­‰å˜è§†è§‰-è¯­è¨€-åŠ¨ä½œç­–ç•¥ï¼Œæå‡æœºå™¨äººæ³›åŒ–èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">cross-embodiment</span> <span class="paper-tag">vision-language-action</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14630v1" data-paper-url="./papers/250914630v1-toward-embodiment-equivariant-vision-language-action-policy.html" onclick="toggleFavorite(this, '2509.14630v1', 'Toward Embodiment Equivariant Vision-Language-Action Policy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250914935v1-cad-driven-co-design-for-flight-ready-jet-powered-humanoids.html">CAD-Driven Co-Design for Flight-Ready Jet-Powered Humanoids</a></td>
  <td>æå‡ºCADé©±åŠ¨çš„ååŒè®¾è®¡æ¡†æ¶ï¼Œä¼˜åŒ–å–·æ°”åŠ¨åŠ›äººå½¢æœºå™¨äººçš„é£è¡Œæ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">MPC</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14935v1" data-paper-url="./papers/250914935v1-cad-driven-co-design-for-flight-ready-jet-powered-humanoids.html" onclick="toggleFavorite(this, '2509.14935v1', 'CAD-Driven Co-Design for Flight-Ready Jet-Powered Humanoids')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250914531v1-dual-arm-hierarchical-planning-for-laboratory-automation-vibratory-s.html">Dual-Arm Hierarchical Planning for Laboratory Automation: Vibratory Sieve Shaker Operations</a></td>
  <td>æå‡ºåŒè‡‚æœºå™¨äººåˆ†å±‚è§„åˆ’æ¡†æ¶ï¼Œå®ç°æŒ¯åŠ¨ç­›åˆ†æœºæ“ä½œè‡ªåŠ¨åŒ–</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">bi-manual</span> <span class="paper-tag">dual-arm</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14531v1" data-paper-url="./papers/250914531v1-dual-arm-hierarchical-planning-for-laboratory-automation-vibratory-s.html" onclick="toggleFavorite(this, '2509.14531v1', 'Dual-Arm Hierarchical Planning for Laboratory Automation: Vibratory Sieve Shaker Operations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250914816v1-scalable-multi-objective-robot-reinforcement-learning-through-gradie.html">Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution</a></td>
  <td>æå‡ºGCR-PPOä»¥è§£å†³å¤šç›®æ ‡æœºå™¨äººå¼ºåŒ–å­¦ä¹ ä¸­çš„æ¢¯åº¦å†²çªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span> <span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14816v1" data-paper-url="./papers/250914816v1-scalable-multi-objective-robot-reinforcement-learning-through-gradie.html" onclick="toggleFavorite(this, '2509.14816v1', 'Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250914787v1-compass-confined-space-manipulation-planning-with-active-sensing-str.html">COMPASS: Confined-space Manipulation Planning with Active Sensing Strategy</a></td>
  <td>æå‡ºCOMPASSæ¡†æ¶ï¼Œè§£å†³å—é™ç©ºé—´å†…åŸºäºä¸»åŠ¨æ„ŸçŸ¥çš„æ“ä½œè§„åˆ’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14787v1" data-paper-url="./papers/250914787v1-compass-confined-space-manipulation-planning-with-active-sensing-str.html" onclick="toggleFavorite(this, '2509.14787v1', 'COMPASS: Confined-space Manipulation Planning with Active Sensing Strategy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250914530v1-learning-to-pick-a-visuomotor-policy-for-clustered-strawberry-pickin.html">Learning to Pick: A Visuomotor Policy for Clustered Strawberry Picking</a></td>
  <td>æå‡ºåŸºäºæ¨¡ä»¿å­¦ä¹ çš„è‰è“é‡‡æ‘˜ç­–ç•¥ï¼Œè§£å†³é®æŒ¡ç¯å¢ƒä¸‹æœºå™¨äººé‡‡æ‘˜éš¾é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span> <span class="paper-tag">teleoperation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14530v1" data-paper-url="./papers/250914530v1-learning-to-pick-a-visuomotor-policy-for-clustered-strawberry-pickin.html" onclick="toggleFavorite(this, '2509.14530v1', 'Learning to Pick: A Visuomotor Policy for Clustered Strawberry Picking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250914688v1-exumi-extensible-robot-teaching-system-with-action-aware-task-agnost.html">exUMI: Extensible Robot Teaching System with Action-aware Task-agnostic Tactile Representation</a></td>
  <td>exUMIï¼šåŸºäºåŠ¨ä½œæ„ŸçŸ¥çš„è§¦è§‰è¡¨ç¤ºï¼Œå¯æ‰©å±•çš„æœºå™¨äººæ•™å­¦ç³»ç»Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">imitation learning</span> <span class="paper-tag">representation learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14688v1" data-paper-url="./papers/250914688v1-exumi-extensible-robot-teaching-system-with-action-aware-task-agnost.html" onclick="toggleFavorite(this, '2509.14688v1', 'exUMI: Extensible Robot Teaching System with Action-aware Task-agnostic Tactile Representation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250914992v2-ext-towards-scalable-autonomous-excavation-via-large-scale-multi-tas.html">ExT: Towards Scalable Autonomous Excavation via Large-Scale Multi-Task Pretraining and Fine-Tuning</a></td>
  <td>ExTï¼šåŸºäºå¤§è§„æ¨¡å¤šä»»åŠ¡é¢„è®­ç»ƒå’Œå¾®è°ƒå®ç°å¯æ‰©å±•çš„è‡ªä¸»æŒ–æ˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14992v2" data-paper-url="./papers/250914992v2-ext-towards-scalable-autonomous-excavation-via-large-scale-multi-tas.html" onclick="toggleFavorite(this, '2509.14992v2', 'ExT: Towards Scalable Autonomous Excavation via Large-Scale Multi-Task Pretraining and Fine-Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250915412v1-sym2real-symbolic-dynamics-with-residual-learning-for-data-efficient.html">Sym2Real: Symbolic Dynamics with Residual Learning for Data-Efficient Adaptive Control</a></td>
  <td>Sym2Realï¼šç»“åˆç¬¦å·å›å½’ä¸æ®‹å·®å­¦ä¹ ï¼Œå®ç°æ•°æ®é«˜æ•ˆçš„è‡ªé€‚åº”æ§åˆ¶</td>
  <td class="tags-cell"><span class="paper-tag">sim2real</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15412v1" data-paper-url="./papers/250915412v1-sym2real-symbolic-dynamics-with-residual-learning-for-data-efficient.html" onclick="toggleFavorite(this, '2509.15412v1', 'Sym2Real: Symbolic Dynamics with Residual Learning for Data-Efficient Adaptive Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250915254v1-dipp-discriminative-impact-point-predictor-for-catching-diverse-in-f.html">DIPP: Discriminative Impact Point Predictor for Catching Diverse In-Flight Objects</a></td>
  <td>æå‡ºDIPPæ¨¡å‹ï¼Œç”¨äºå››è¶³æœºå™¨äººæ¥å–ç©ºä¸­é£è¡Œç‰©ä½“çš„è½ç‚¹é¢„æµ‹ï¼Œæå‡å¤æ‚ç¯å¢ƒä¸‹çš„æ³›åŒ–æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15254v1" data-paper-url="./papers/250915254v1-dipp-discriminative-impact-point-predictor-for-catching-diverse-in-f.html" onclick="toggleFavorite(this, '2509.15254v1', 'DIPP: Discriminative Impact Point Predictor for Catching Diverse In-Flight Objects')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/250914889v1-collabvla-self-reflective-vision-language-action-model-dreaming-toge.html">CollabVLA: Self-Reflective Vision-Language-Action Model Dreaming Together with Human</a></td>
  <td>CollabVLAï¼šæå‡ºè‡ªåæ€çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼Œå®ç°äººæœºååŒ</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14889v1" data-paper-url="./papers/250914889v1-collabvla-self-reflective-vision-language-action-model-dreaming-toge.html" onclick="toggleFavorite(this, '2509.14889v1', 'CollabVLA: Self-Reflective Vision-Language-Action Model Dreaming Together with Human')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250915273v2-embodied-arena-a-comprehensive-unified-and-evolving-evaluation-platf.html">Embodied Arena: A Comprehensive, Unified, and Evolving Evaluation Platform for Embodied AI</a></td>
  <td>Embodied Arenaï¼šæ„å»ºå…¨é¢ã€ç»Ÿä¸€ã€å¯æ¼”è¿›çš„å…·èº«æ™ºèƒ½è¯„ä¼°å¹³å°</td>
  <td class="tags-cell"><span class="paper-tag">embodied AI</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15273v2" data-paper-url="./papers/250915273v2-embodied-arena-a-comprehensive-unified-and-evolving-evaluation-platf.html" onclick="toggleFavorite(this, '2509.15273v2', 'Embodied Arena: A Comprehensive, Unified, and Evolving Evaluation Platform for Embodied AI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250915061v2-ask-to-clarify-resolving-instruction-ambiguity-through-multi-turn-di.html">Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue</a></td>
  <td>æå‡ºAsk-to-Clarifyæ¡†æ¶ï¼Œé€šè¿‡å¤šè½®å¯¹è¯è§£å†³å…·èº«æ™ºèƒ½ä½“æŒ‡ä»¤æ¨¡ç³Šé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15061v2" data-paper-url="./papers/250915061v2-ask-to-clarify-resolving-instruction-ambiguity-through-multi-turn-di.html" onclick="toggleFavorite(this, '2509.15061v2', 'Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250914978v1-pa-mppi-perception-aware-model-predictive-path-integral-control-for-.html">PA-MPPI: Perception-Aware Model Predictive Path Integral Control for Quadrotor Navigation in Unknown Environments</a></td>
  <td>æå‡ºæ„ŸçŸ¥é©±åŠ¨çš„MPPIç®—æ³•ï¼Œæå‡å››æ—‹ç¿¼æ— äººæœºåœ¨æœªçŸ¥ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14978v1" data-paper-url="./papers/250914978v1-pa-mppi-perception-aware-model-predictive-path-integral-control-for-.html" onclick="toggleFavorite(this, '2509.14978v1', 'PA-MPPI: Perception-Aware Model Predictive Path Integral Control for Quadrotor Navigation in Unknown Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/250914967v2-affordance-based-disambiguation-of-surgical-instructions-for-collabo.html">Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery</a></td>
  <td>æå‡ºåŸºäºå¯ä¾›æ€§çš„æ‰‹æœ¯æŒ‡ä»¤æ¶ˆæ­§æ¡†æ¶ï¼Œç”¨äºåä½œæœºå™¨äººè¾…åŠ©æ‰‹æœ¯</td>
  <td class="tags-cell"><span class="paper-tag">affordance</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14967v2" data-paper-url="./papers/250914967v2-affordance-based-disambiguation-of-surgical-instructions-for-collabo.html" onclick="toggleFavorite(this, '2509.14967v2', 'Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250914636v1-bev-odom2-enhanced-bev-based-monocular-visual-odometry-with-pv-bev-f.html">BEV-ODOM2: Enhanced BEV-based Monocular Visual Odometry with PV-BEV Fusion and Dense Flow Supervision for Ground Robots</a></td>
  <td>BEV-ODOM2ï¼šé¢å‘åœ°é¢æœºå™¨äººçš„PV-BEVèåˆä¸ç¨ å¯†å…‰æµç›‘ç£å•ç›®è§†è§‰é‡Œç¨‹è®¡</td>
  <td class="tags-cell"><span class="paper-tag">visual odometry</span> <span class="paper-tag">optical flow</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14636v1" data-paper-url="./papers/250914636v1-bev-odom2-enhanced-bev-based-monocular-visual-odometry-with-pv-bev-f.html" onclick="toggleFavorite(this, '2509.14636v1', 'BEV-ODOM2: Enhanced BEV-based Monocular Visual Odometry with PV-BEV Fusion and Dense Flow Supervision for Ground Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)