---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-12-23
---

# cs.ROï¼ˆ2025-12-23ï¼‰

ğŸ“Š å…± **7** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (6)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (6 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251220188v1-asynchronous-fast-slow-vision-language-action-policies-for-whole-bod.html">Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation</a></td>
  <td>æå‡ºDuoCore-FSå¼‚æ­¥å¿«é€Ÿ-æ…¢é€Ÿè§†è§‰-è¯­è¨€-åŠ¨ä½œç­–ç•¥ï¼Œç”¨äºå…¨èº«æœºå™¨äººæ“ä½œã€‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">whole-body manipulation</span> <span class="paper-tag">policy learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20188v1" data-paper-url="./papers/251220188v1-asynchronous-fast-slow-vision-language-action-policies-for-whole-bod.html" onclick="toggleFavorite(this, '2512.20188v1', 'Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251220014v1-bring-my-cup-personalizing-vision-language-action-models-with-visual.html">Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting</a></td>
  <td>æå‡ºè§†è§‰æ³¨æ„åŠ›æç¤ºï¼ˆVAPï¼‰ï¼Œè§£å†³VLAæ¨¡å‹åœ¨ä¸ªæ€§åŒ–æŒ‡ä»¤ä¸‹çš„ç‰©ä½“æ“ä½œéš¾é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20014v1" data-paper-url="./papers/251220014v1-bring-my-cup-personalizing-vision-language-action-models-with-visual.html" onclick="toggleFavorite(this, '2512.20014v1', 'Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251220166v1-lola-long-horizon-latent-action-learning-for-general-robot-manipulat.html">LoLA: Long Horizon Latent Action Learning for General Robot Manipulation</a></td>
  <td>LoLAï¼šç”¨äºé€šç”¨æœºå™¨äººæ“ä½œçš„é•¿ç¨‹éšç©ºé—´åŠ¨ä½œå­¦ä¹ æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">bi-manual</span> <span class="paper-tag">vision-language-action</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20166v1" data-paper-url="./papers/251220166v1-lola-long-horizon-latent-action-learning-for-general-robot-manipulat.html" onclick="toggleFavorite(this, '2512.20166v1', 'LoLA: Long Horizon Latent Action Learning for General Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251220322v1-pneumatic-bladder-links-with-wide-range-of-motion-joints-for-articul.html">Pneumatic bladder links with wide range of motion joints for articulated inflatable robots</a></td>
  <td>æå‡ºåŸºäºæ°”åŠ¨å›Šè¿æ¥å’ŒHillberryå…³èŠ‚çš„å¯å……æ°”é“°æ¥æœºå™¨äºº</td>
  <td class="tags-cell"><span class="paper-tag">legged locomotion</span> <span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20322v1" data-paper-url="./papers/251220322v1-pneumatic-bladder-links-with-wide-range-of-motion-joints-for-articul.html" onclick="toggleFavorite(this, '2512.20322v1', 'Pneumatic bladder links with wide range of motion joints for articulated inflatable robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251220591v1-lighttact-a-visual-tactile-fingertip-sensor-for-deformation-independ.html">LightTact: A Visual-Tactile Fingertip Sensor for Deformation-Independent Contact Sensing</a></td>
  <td>LightTactï¼šä¸€ç§ç”¨äºå½¢å˜æ— å…³æ¥è§¦æ„ŸçŸ¥çš„è§†è§‰-è§¦è§‰æŒ‡å°–ä¼ æ„Ÿå™¨</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20591v1" data-paper-url="./papers/251220591v1-lighttact-a-visual-tactile-fingertip-sensor-for-deformation-independ.html" onclick="toggleFavorite(this, '2512.20591v1', 'LightTact: A Visual-Tactile Fingertip Sensor for Deformation-Independent Contact Sensing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251220391v1-contingency-model-based-control-cmc-for-communicationless-cooperativ.html">Contingency Model-based Control (CMC) for Communicationless Cooperative Collision Avoidance in Robot Swarms</a></td>
  <td>æå‡ºåŸºäºåº”æ€¥æ¨¡å‹çš„æ§åˆ¶æ–¹æ³•(CMC)ï¼Œç”¨äºæœºå™¨äººé›†ç¾¤ä¸­æ— é€šä¿¡çš„ååŒé¿éšœ</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20391v1" data-paper-url="./papers/251220391v1-contingency-model-based-control-cmc-for-communicationless-cooperativ.html" onclick="toggleFavorite(this, '2512.20391v1', 'Contingency Model-based Control (CMC) for Communicationless Cooperative Collision Avoidance in Robot Swarms')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>7</td>
  <td><a href="./papers/251220475v1-drift-corrected-monocular-vio-and-perception-aware-planning-for-auto.html">Drift-Corrected Monocular VIO and Perception-Aware Planning for Autonomous Drone Racing</a></td>
  <td>é’ˆå¯¹æ— äººæœºç«é€Ÿï¼Œæå‡ºæ¼‚ç§»æ ¡æ­£çš„å•ç›®VIOä¸æ„ŸçŸ¥è§„åˆ’æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">VIO</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20475v1" data-paper-url="./papers/251220475v1-drift-corrected-monocular-vio-and-perception-aware-planning-for-auto.html" onclick="toggleFavorite(this, '2512.20475v1', 'Drift-Corrected Monocular VIO and Perception-Aware Planning for Autonomous Drone Racing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)