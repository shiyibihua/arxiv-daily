---
layout: default
title: Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration
---

# Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.08354" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.08354v1</a>
  <a href="https://arxiv.org/pdf/2509.08354.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.08354v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.08354v1', 'Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ce Guo, Xieyuanli Chen, Zhiwen Zeng, Zirui Guo, Yihong Li, Haoran Xiao, Dewen Hu, Huimin Lu

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-10

**å¤‡æ³¨**: 20 pages, 19 figures, accepted by IEEE Transactions on Robotics

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè§¦è§‰-è¿åŠ¨æ„ŸçŸ¥èåˆçš„æ¨¡ä»¿å­¦ä¹ æ¡†æ¶ï¼Œå®ç°æœºå™¨äººé€šç”¨å¤šæŒ‡çµå·§æŠ“å–**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æœºå™¨äººæŠ“å–` `æ¨¡ä»¿å­¦ä¹ ` `è§¦è§‰æ„ŸçŸ¥` `è¿åŠ¨æ„ŸçŸ¥` `æ—¶ç©ºå›¾ç½‘ç»œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººæŠ“å–æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨è§¦è§‰å’ŒåŠ¨è§‰ä¿¡æ¯ï¼Œå¯¼è‡´åœ¨å¤æ‚ç¯å¢ƒå’Œç‰©ä½“ä¸‹çš„æŠ“å–æ€§èƒ½å—é™ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§åŸºäºæ•°æ®æ‰‹å¥—çš„è§¦è§‰-è¿åŠ¨æ„ŸçŸ¥é¢„æµ‹æ¡†æ¶ï¼Œé€šè¿‡æ¨¡ä»¿å­¦ä¹ å°†äººç±»çš„æŠ“å–æŠ€èƒ½è¿ç§»åˆ°æœºå™¨äººã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é€šç”¨æŠ“å–ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ï¼ŒåŒ…æ‹¬å¯¹å¯å˜å½¢ç‰©ä½“çš„æŠ“å–ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§¦è§‰å’ŒåŠ¨è§‰æ„ŸçŸ¥å¯¹äºäººç±»çš„çµå·§æ“ä½œè‡³å…³é‡è¦ï¼Œé€šè¿‡æœ¬ä½“æ„Ÿè§‰çš„ä¼ æ„Ÿå™¨è¿åŠ¨æ•´åˆå®ç°å¯¹ç‰©ä½“çš„å¯é æŠ“å–ã€‚å¯¹äºæœºå™¨äººæ‰‹ï¼Œå³ä½¿è·å–è¿™ç§è§¦è§‰å’ŒåŠ¨è§‰åé¦ˆæ˜¯å¯è¡Œçš„ï¼Œä½†å»ºç«‹ä»è¿™ç§æ„Ÿè§‰åé¦ˆåˆ°è¿åŠ¨åŠ¨ä½œçš„ç›´æ¥æ˜ å°„ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºæ‰‹å¥—ä»‹å¯¼çš„è§¦è§‰-è¿åŠ¨æ„ŸçŸ¥é¢„æµ‹æ¡†æ¶ï¼Œç”¨äºå°†äººç±»ç›´è§‚å’Œè‡ªç„¶æ“ä½œä¸­çš„æŠ“å–æŠ€èƒ½é€šè¿‡æ¨¡ä»¿å­¦ä¹ è½¬ç§»åˆ°æœºå™¨äººæ‰§è¡Œä¸­ï¼Œå¹¶é€šè¿‡åŒ…æ‹¬æ¶‰åŠå¯å˜å½¢ç‰©ä½“çš„é€šç”¨æŠ“å–ä»»åŠ¡éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é›†æˆäº†ä¸€ä¸ªæ•°æ®æ‰‹å¥—æ¥æ•è·å…³èŠ‚å±‚é¢çš„è§¦è§‰å’ŒåŠ¨è§‰æ•°æ®ã€‚è¯¥æ‰‹å¥—é€‚ç”¨äºäººç±»å’Œæœºå™¨äººæ‰‹ï¼Œå…è®¸ä»ä¸åŒåœºæ™¯ä¸­çš„è‡ªç„¶äººæ‰‹æ¼”ç¤ºä¸­æ”¶é›†æ•°æ®ã€‚å®ƒç¡®ä¿äº†åŸå§‹æ•°æ®æ ¼å¼çš„ä¸€è‡´æ€§ï¼Œä»è€Œå¯ä»¥è¯„ä¼°äººç±»å’Œæœºå™¨äººæ‰‹çš„æŠ“å–ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬åŸºäºå…·æœ‰æåæ ‡çš„å›¾ç»“æ„ï¼Œå»ºç«‹äº†å¤šæ¨¡æ€è¾“å…¥çš„ç»Ÿä¸€è¡¨ç¤ºã€‚æˆ‘ä»¬å°†å½¢æ€å·®å¼‚æ˜¾å¼åœ°é›†æˆåˆ°è®¾è®¡çš„è¡¨ç¤ºä¸­ï¼Œä»è€Œå¢å¼ºäº†ä¸åŒæ¼”ç¤ºè€…å’Œæœºå™¨äººæ‰‹ä¹‹é—´çš„å…¼å®¹æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†è§¦è§‰-è¿åŠ¨æ—¶ç©ºå›¾ç½‘ç»œï¼ˆTK-STGNï¼‰ï¼Œå®ƒåˆ©ç”¨å¤šç»´å­å›¾å·ç§¯å’ŒåŸºäºæ³¨æ„åŠ›çš„LSTMå±‚ä»å›¾è¾“å…¥ä¸­æå–æ—¶ç©ºç‰¹å¾ï¼Œä»¥é¢„æµ‹æ¯ä¸ªæ‰‹éƒ¨å…³èŠ‚çš„åŸºäºèŠ‚ç‚¹çš„å§¿æ€ã€‚ç„¶åï¼Œè¿™äº›é¢„æµ‹é€šè¿‡åŠ›-ä½ç½®æ··åˆæ˜ å°„æ˜ å°„åˆ°æœ€ç»ˆå‘½ä»¤ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æœºå™¨äººæŠ“å–æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨è§¦è§‰å’ŒåŠ¨è§‰ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚å½¢çŠ¶æˆ–å¯å˜å½¢ç‰©ä½“æ—¶ï¼Œé²æ£’æ€§å’Œæ³›åŒ–æ€§ä¸è¶³ã€‚ç›´æ¥ä»æ„Ÿè§‰åé¦ˆåˆ°è¿åŠ¨æ§åˆ¶çš„æ˜ å°„å…³ç³»éš¾ä»¥å»ºç«‹ï¼Œå¯¼è‡´æœºå™¨äººéš¾ä»¥åƒäººç±»ä¸€æ ·è‡ªç„¶çµå·§åœ°æŠ“å–ç‰©ä½“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ¨¡ä»¿å­¦ä¹ ï¼Œå°†äººç±»çš„æŠ“å–ç»éªŒè¿ç§»åˆ°æœºå™¨äººã€‚æ ¸å¿ƒåœ¨äºåˆ©ç”¨æ•°æ®æ‰‹å¥—æ•è·äººç±»æŠ“å–è¿‡ç¨‹ä¸­çš„è§¦è§‰å’ŒåŠ¨è§‰æ•°æ®ï¼Œå¹¶å­¦ä¹ ä¸€ä¸ªä»è¿™äº›æ„Ÿè§‰è¾“å…¥åˆ°æœºå™¨äººè¿åŠ¨æ§åˆ¶çš„æ˜ å°„å…³ç³»ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæœºå™¨äººå¯ä»¥å­¦ä¹ äººç±»çš„ç›´è§‰å’Œè‡ªç„¶æ“ä½œæ–¹å¼ï¼Œä»è€Œæé«˜æŠ“å–çš„é²æ£’æ€§å’Œæ³›åŒ–æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬æ•°æ®é‡‡é›†ã€æ•°æ®è¡¨ç¤ºã€æ¨¡å‹è®­ç»ƒå’Œæœºå™¨äººæ§åˆ¶å››ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œä½¿ç”¨æ•°æ®æ‰‹å¥—é‡‡é›†äººç±»æŠ“å–è¿‡ç¨‹ä¸­çš„è§¦è§‰å’ŒåŠ¨è§‰æ•°æ®ã€‚ç„¶åï¼Œå°†è¿™äº›æ•°æ®è½¬æ¢ä¸ºåŸºäºå›¾ç»“æ„çš„ç»Ÿä¸€è¡¨ç¤ºï¼Œå¹¶æ˜¾å¼åœ°è€ƒè™‘ä¸åŒæ‰‹éƒ¨å½¢æ€çš„å·®å¼‚ã€‚æ¥ç€ï¼Œä½¿ç”¨è§¦è§‰-è¿åŠ¨æ—¶ç©ºå›¾ç½‘ç»œï¼ˆTK-STGNï¼‰å­¦ä¹ ä»å›¾è¾“å…¥åˆ°å…³èŠ‚çŠ¶æ€çš„æ˜ å°„å…³ç³»ã€‚æœ€åï¼Œé€šè¿‡åŠ›-ä½ç½®æ··åˆæ˜ å°„å°†é¢„æµ‹çš„å…³èŠ‚çŠ¶æ€è½¬æ¢ä¸ºæœºå™¨äººæ§åˆ¶æŒ‡ä»¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šä¸»è¦åˆ›æ–°ç‚¹åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§åŸºäºå›¾ç»“æ„çš„ç»Ÿä¸€è¡¨ç¤ºæ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆèåˆè§¦è§‰å’ŒåŠ¨è§‰ä¿¡æ¯ï¼Œå¹¶å¤„ç†ä¸åŒæ‰‹éƒ¨å½¢æ€çš„å·®å¼‚ï¼›2) æå‡ºäº†è§¦è§‰-è¿åŠ¨æ—¶ç©ºå›¾ç½‘ç»œï¼ˆTK-STGNï¼‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå–æ—¶ç©ºç‰¹å¾ï¼Œå¹¶é¢„æµ‹å…³èŠ‚çŠ¶æ€ï¼›3) æå‡ºäº†ä¸€ç§åŸºäºæ•°æ®æ‰‹å¥—çš„æ¨¡ä»¿å­¦ä¹ æ¡†æ¶ï¼Œèƒ½å¤Ÿå°†äººç±»çš„æŠ“å–æŠ€èƒ½è¿ç§»åˆ°æœºå™¨äººã€‚

**å…³é”®è®¾è®¡**ï¼šæ•°æ®è¡¨ç¤ºæ–¹é¢ï¼Œä½¿ç”¨æåæ ‡æ¥è¡¨ç¤ºå…³èŠ‚ä½ç½®ï¼Œå¹¶ä½¿ç”¨å›¾ç»“æ„æ¥è¡¨ç¤ºå…³èŠ‚ä¹‹é—´çš„å…³ç³»ã€‚TK-STGNç½‘ç»œä½¿ç”¨å¤šç»´å­å›¾å·ç§¯å’ŒåŸºäºæ³¨æ„åŠ›çš„LSTMå±‚æ¥æå–æ—¶ç©ºç‰¹å¾ã€‚æŸå¤±å‡½æ•°æ–¹é¢ï¼Œä½¿ç”¨äº†å‡æ–¹è¯¯å·®æŸå¤±å‡½æ•°æ¥è¡¡é‡é¢„æµ‹å…³èŠ‚çŠ¶æ€ä¸çœŸå®å…³èŠ‚çŠ¶æ€ä¹‹é—´çš„å·®å¼‚ã€‚åŠ›-ä½ç½®æ··åˆæ˜ å°„ä½¿ç”¨PDæ§åˆ¶å™¨æ¥å®ç°ç²¾ç¡®çš„åŠ›æ§åˆ¶å’Œä½ç½®æ§åˆ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é€šç”¨æŠ“å–ä»»åŠ¡ä¸­å–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¯å˜å½¢ç‰©ä½“æ—¶ï¼Œç›¸æ¯”äºä¼ ç»Ÿæ–¹æ³•å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•èƒ½å¤ŸæˆåŠŸæŠ“å–å„ç§å½¢çŠ¶å’Œæè´¨çš„ç‰©ä½“ï¼ŒåŒ…æ‹¬çƒä½“ã€ç«‹æ–¹ä½“ã€åœ†æŸ±ä½“ä»¥åŠæ¯›å·¾ã€ç»³ç´¢ç­‰å¯å˜å½¢ç‰©ä½“ã€‚æ€§èƒ½æ•°æ®ï¼ˆå…·ä½“æ•°å€¼æœªçŸ¥ï¼ŒåŸæ–‡æœªæä¾›ï¼‰è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æŠ“å–æˆåŠŸç‡å’ŒæŠ“å–ç¨³å®šæ€§æ–¹é¢å‡ä¼˜äºå¯¹æ¯”åŸºçº¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦çµå·§æ“ä½œçš„æœºå™¨äººåº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚ï¼šå·¥ä¸šè‡ªåŠ¨åŒ–ä¸­çš„ç²¾å¯†è£…é…ã€åŒ»ç–—æœºå™¨äººä¸­çš„å¾®åˆ›æ‰‹æœ¯ã€å®¶åº­æœåŠ¡æœºå™¨äººä¸­çš„ç‰©å“æ•´ç†ç­‰ã€‚é€šè¿‡å­¦ä¹ äººç±»çš„æŠ“å–æŠ€èƒ½ï¼Œæœºå™¨äººå¯ä»¥æ›´å¥½åœ°é€‚åº”å¤æ‚ç¯å¢ƒï¼Œå®Œæˆå„ç§ç²¾ç»†æ“ä½œï¼Œæé«˜å·¥ä½œæ•ˆç‡å’Œå®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Tactile and kinesthetic perceptions are crucial for human dexterous manipulation, enabling reliable grasping of objects via proprioceptive sensorimotor integration. For robotic hands, even though acquiring such tactile and kinesthetic feedback is feasible, establishing a direct mapping from this sensory feedback to motor actions remains challenging. In this paper, we propose a novel glove-mediated tactile-kinematic perception-prediction framework for grasp skill transfer from human intuitive and natural operation to robotic execution based on imitation learning, and its effectiveness is validated through generalized grasping tasks, including those involving deformable objects. Firstly, we integrate a data glove to capture tactile and kinesthetic data at the joint level. The glove is adaptable for both human and robotic hands, allowing data collection from natural human hand demonstrations across different scenarios. It ensures consistency in the raw data format, enabling evaluation of grasping for both human and robotic hands. Secondly, we establish a unified representation of multi-modal inputs based on graph structures with polar coordinates. We explicitly integrate the morphological differences into the designed representation, enhancing the compatibility across different demonstrators and robotic hands. Furthermore, we introduce the Tactile-Kinesthetic Spatio-Temporal Graph Networks (TK-STGN), which leverage multidimensional subgraph convolutions and attention-based LSTM layers to extract spatio-temporal features from graph inputs to predict node-based states for each hand joint. These predictions are then mapped to final commands through a force-position hybrid mapping.

