---
layout: default
title: Good Deep Features to Track: Self-Supervised Feature Extraction and Tracking in Visual Odometry
---

# Good Deep Features to Track: Self-Supervised Feature Extraction and Tracking in Visual Odometry

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.08333" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.08333v1</a>
  <a href="https://arxiv.org/pdf/2509.08333.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.08333v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.08333v1', 'Good Deep Features to Track: Self-Supervised Feature Extraction and Tracking in Visual Odometry')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sai Puneeth Reddy Gottam, Haoming Zhang, Eivydas Keras

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-10

**å¤‡æ³¨**: This short paper has been accepted as a workshop paper at European Conference on Mobile Robots 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªç›‘ç£ç‰¹å¾æå–ä¸è·Ÿè¸ªæ–¹æ³•ï¼Œæå‡è§†è§‰é‡Œç¨‹è®¡åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è§†è§‰é‡Œç¨‹è®¡` `è‡ªç›‘ç£å­¦ä¹ ` `ç‰¹å¾æå–` `ç‰¹å¾è·Ÿè¸ª` `æ·±åº¦å­¦ä¹ ` `æœºå™¨äººå¯¼èˆª` `è¿åŠ¨ä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰é‡Œç¨‹è®¡åœ¨å¤æ‚ç¯å¢ƒä¸‹ï¼Œç”±äºå…‰ç…§å˜åŒ–ã€åŠ¨æ€åœºæ™¯å’Œä½çº¹ç†ç­‰å› ç´ ï¼Œç‰¹å¾æå–å’Œè·Ÿè¸ªæ€§èƒ½ä¸‹é™ã€‚
2. æå‡ºä¸€ç§è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡ä»»åŠ¡ç‰¹å®šåé¦ˆæ¥å¢å¼ºæ·±åº¦ç‰¹å¾æå–å’Œè·Ÿè¸ªï¼Œæå‡ç‰¹å¾çš„ç¨³å®šæ€§å’Œä¿¡æ¯é‡ã€‚
3. è¯¥æ–¹æ³•æ—¨åœ¨æé«˜è§†è§‰é‡Œç¨‹è®¡åœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›å’Œå¯é æ€§ï¼Œä»è€Œæå‡æ•´ä½“å®šä½æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºè§†è§‰çš„å®šä½æŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å…¶æ€§èƒ½åœ¨å¤§å‹ã€æˆ·å¤–å’Œé•¿æœŸåœºæ™¯ä¸­å¸¸å¸¸ä¸‹é™ï¼Œè¿™å½’å› äºå…‰ç…§å˜åŒ–ã€åŠ¨æ€åœºæ™¯å’Œä½çº¹ç†åŒºåŸŸç­‰å› ç´ ã€‚è¿™äº›æŒ‘æˆ˜ä¼šé™ä½ç‰¹å¾æå–å’Œè·Ÿè¸ªçš„è´¨é‡ï¼Œè€Œç‰¹å¾æå–å’Œè·Ÿè¸ªå¯¹äºå‡†ç¡®çš„è¿åŠ¨ä¼°è®¡è‡³å…³é‡è¦ã€‚è™½ç„¶è¯¸å¦‚SuperPointå’ŒSuperGlueç­‰åŸºäºå­¦ä¹ çš„æ–¹æ³•æ˜¾ç¤ºå‡ºæ”¹è¿›çš„ç‰¹å¾è¦†ç›–ç‡å’Œé²æ£’æ€§ï¼Œä½†å®ƒä»¬ä»ç„¶é¢ä¸´ç€åˆ†å¸ƒå¤–æ•°æ®çš„æ³›åŒ–é—®é¢˜ã€‚æœ¬æ–‡é€šè¿‡è‡ªç›‘ç£å­¦ä¹ å’Œä»»åŠ¡ç‰¹å®šåé¦ˆæ¥å¢å¼ºæ·±åº¦ç‰¹å¾æå–å’Œè·Ÿè¸ªï¼Œä»è€Œè§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¯¥æ–¹æ³•æ—¨åœ¨ä¿ƒè¿›ç¨³å®šä¸”ä¿¡æ¯ä¸°å¯Œçš„ç‰¹å¾ï¼Œä»è€Œæé«˜åœ¨å…·æœ‰æŒ‘æˆ˜æ€§ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›å’Œå¯é æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè§†è§‰é‡Œç¨‹è®¡åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„ç‰¹å¾æå–å’Œè·Ÿè¸ªå®¹æ˜“å¤±æ•ˆï¼Œå¯¼è‡´å®šä½ç²¾åº¦ä¸‹é™ã€‚ç°æœ‰å­¦ä¹ æ–¹æ³•å¦‚SuperPointå’ŒSuperGlueåœ¨åˆ†å¸ƒå¤–æ•°æ®ä¸Šæ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹å…‰ç…§å˜åŒ–ã€åŠ¨æ€åœºæ™¯å’Œä½çº¹ç†åŒºåŸŸç­‰æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šåˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ ï¼Œæ— éœ€äººå·¥æ ‡æ³¨æ•°æ®ï¼Œé€šè¿‡ä»»åŠ¡ç›¸å…³çš„åé¦ˆä¿¡å·æ¥è®­ç»ƒç‰¹å¾æå–å™¨ï¼Œä½¿å…¶æå–æ›´ç¨³å®šã€ä¿¡æ¯é‡æ›´ä¸°å¯Œçš„ç‰¹å¾ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨æé«˜ç‰¹å¾åœ¨ä¸åŒç¯å¢ƒä¸‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œä»è€Œæå‡è§†è§‰é‡Œç¨‹è®¡çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ç‰¹å¾æå–æ¨¡å—å’Œè·Ÿè¸ªæ¨¡å—ã€‚ç‰¹å¾æå–æ¨¡å—ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œï¼Œé€šè¿‡è‡ªç›‘ç£å­¦ä¹ è¿›è¡Œè®­ç»ƒã€‚è·Ÿè¸ªæ¨¡å—åˆ©ç”¨æå–çš„ç‰¹å¾è¿›è¡Œå¸§é—´åŒ¹é…ï¼Œä¼°è®¡ç›¸æœºè¿åŠ¨ã€‚ä»»åŠ¡ç‰¹å®šåé¦ˆä¿¡å·ç”¨äºæŒ‡å¯¼ç‰¹å¾æå–å™¨çš„è®­ç»ƒï¼Œä½¿å…¶æå–çš„ç‰¹å¾æ›´é€‚åˆäºè·Ÿè¸ªä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæ ¸å¿ƒåˆ›æ–°åœ¨äºåˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ å’Œä»»åŠ¡ç‰¹å®šåé¦ˆæ¥ä¼˜åŒ–ç‰¹å¾æå–å™¨ã€‚ä¸ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œè‡ªç›‘ç£å­¦ä¹ å¯ä»¥åˆ©ç”¨å¤§é‡æ— æ ‡ç­¾æ•°æ®ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä»»åŠ¡ç‰¹å®šåé¦ˆåˆ™å¯ä»¥å¼•å¯¼æ¨¡å‹å­¦ä¹ æ›´é€‚åˆäºè·Ÿè¸ªä»»åŠ¡çš„ç‰¹å¾è¡¨ç¤ºã€‚

**å…³é”®è®¾è®¡**ï¼šå…·ä½“çš„è‡ªç›‘ç£å­¦ä¹ ä»»åŠ¡å’ŒæŸå¤±å‡½æ•°è®¾è®¡æ˜¯å…³é”®ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨å¸§é—´å‡ ä½•ä¸€è‡´æ€§ä½œä¸ºè‡ªç›‘ç£ä¿¡å·ï¼Œè®¾è®¡æŸå¤±å‡½æ•°æ¥é¼“åŠ±æå–çš„ç‰¹å¾åœ¨ç›¸é‚»å¸§ä¹‹é—´ä¿æŒä¸€è‡´æ€§ã€‚ç½‘ç»œç»“æ„çš„é€‰æ‹©ä¹Ÿå¾ˆé‡è¦ï¼Œéœ€è¦é€‰æ‹©èƒ½å¤Ÿæœ‰æ•ˆæå–å›¾åƒç‰¹å¾çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œä¾‹å¦‚å·ç§¯ç¥ç»ç½‘ç»œæˆ–Transformerç½‘ç»œã€‚æ­¤å¤–ï¼Œè¿˜éœ€è¦ä»”ç»†è°ƒæ•´è®­ç»ƒå‚æ•°ï¼Œä»¥è·å¾—æœ€ä½³çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®éªŒéªŒè¯äº†æ‰€æå‡ºçš„è‡ªç›‘ç£ç‰¹å¾æå–å’Œè·Ÿè¸ªæ–¹æ³•åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†æ‘˜è¦ä¸­æåˆ°è¯¥æ–¹æ³•èƒ½å¤Ÿæå‡ç‰¹å¾çš„ç¨³å®šæ€§å’Œä¿¡æ¯é‡ï¼Œä»è€Œæé«˜è§†è§‰é‡Œç¨‹è®¡çš„æ³›åŒ–èƒ½åŠ›å’Œå¯é æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨åˆ†å¸ƒå¤–æ•°æ®ä¸Šè¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®ç­‰é¢†åŸŸã€‚åœ¨è¿™äº›åº”ç”¨ä¸­ï¼Œè§†è§‰é‡Œç¨‹è®¡æ˜¯å®ç°è‡ªä¸»å®šä½å’Œåœ°å›¾æ„å»ºçš„å…³é”®æŠ€æœ¯ã€‚é€šè¿‡æé«˜è§†è§‰é‡Œç¨‹è®¡åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„é²æ£’æ€§ï¼Œå¯ä»¥æå‡è¿™äº›åº”ç”¨çš„å¯é æ€§å’Œæ€§èƒ½ï¼Œä¾‹å¦‚åœ¨å…‰ç…§å˜åŒ–å‰§çƒˆçš„éš§é“ä¸­ï¼Œæˆ–è€…åœ¨åŠ¨æ€çš„åŸå¸‚ç¯å¢ƒä¸­ï¼Œå®ç°æ›´ç²¾ç¡®çš„å®šä½å’Œå¯¼èˆªã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual-based localization has made significant progress, yet its performance often drops in large-scale, outdoor, and long-term settings due to factors like lighting changes, dynamic scenes, and low-texture areas. These challenges degrade feature extraction and tracking, which are critical for accurate motion estimation. While learning-based methods such as SuperPoint and SuperGlue show improved feature coverage and robustness, they still face generalization issues with out-of-distribution data. We address this by enhancing deep feature extraction and tracking through self-supervised learning with task specific feedback. Our method promotes stable and informative features, improving generalization and reliability in challenging environments.

