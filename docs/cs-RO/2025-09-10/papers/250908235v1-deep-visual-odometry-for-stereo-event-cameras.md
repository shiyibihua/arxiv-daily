---
layout: default
title: Deep Visual Odometry for Stereo Event Cameras
---

# Deep Visual Odometry for Stereo Event Cameras

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.08235" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.08235v1</a>
  <a href="https://arxiv.org/pdf/2509.08235.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.08235v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.08235v1', 'Deep Visual Odometry for Stereo Event Cameras')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sheng Zhong, Junkai Niu, Yi Zhou

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-10

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºStereo-DEVOï¼Œä¸€ç§ç”¨äºç«‹ä½“äº‹ä»¶ç›¸æœºçš„æ·±åº¦è§†è§‰é‡Œç¨‹è®¡ï¼Œæå‡äº†åœ¨HDRç¯å¢ƒä¸‹çš„ä½å§¿ä¼°è®¡ç²¾åº¦ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `äº‹ä»¶ç›¸æœº` `è§†è§‰é‡Œç¨‹è®¡` `æ·±åº¦å­¦ä¹ ` `ç«‹ä½“è§†è§‰` `ä½å§¿ä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰äº‹ä»¶ç›¸æœºè§†è§‰é‡Œç¨‹è®¡åœ¨ä½å…‰ç…§HDRç¯å¢ƒä¸‹ï¼Œç”±äºåŠ¨æ€èŒƒå›´å·¨å¤§å’Œä¿¡å™ªæ¯”æ—¶ç©ºå˜åŒ–ï¼Œæ•°æ®å…³è”ä¸å¯é ã€‚
2. Stereo-DEVOåˆ©ç”¨æ·±åº¦å­¦ä¹ ï¼Œé€šè¿‡é™æ€ç«‹ä½“å…³è”è¿›è¡Œç¨€ç–æ·±åº¦ä¼°è®¡ï¼Œå¹¶ç»“åˆç´§è€¦åˆBAä¼˜åŒ–ï¼Œæå‡ä½å§¿ä¼°è®¡ç²¾åº¦ã€‚
3. è¯¥ç³»ç»Ÿèƒ½å®æ—¶å¤„ç†VGAåˆ†è¾¨ç‡äº‹ä»¶æ•°æ®ï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†å’ŒHDRåœºæ™¯ä¸­è¡¨ç°å‡ºä¼˜äºç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå­¦ä¹ çš„ç«‹ä½“äº‹ä»¶è§†è§‰é‡Œç¨‹è®¡ï¼ˆStereo-DEVOï¼‰ï¼Œæ—¨åœ¨è§£å†³äº‹ä»¶ç›¸æœºåœ¨è¿åŠ¨æ¨¡ç³Šå’Œé«˜åŠ¨æ€èŒƒå›´ï¼ˆHDRï¼‰å…‰ç…§æ¡ä»¶ä¸‹çŠ¶æ€ä¼°è®¡ä»»åŠ¡çš„æŒ‘æˆ˜ã€‚ç°æœ‰åŸºäºæ‰‹å·¥æ•°æ®å…³è”çš„äº‹ä»¶è§†è§‰é‡Œç¨‹è®¡åœ¨ä½å…‰ç…§HDRæ¡ä»¶ä¸‹è¡¨ç°ä¸ç¨³å®šã€‚Stereo-DEVOåŸºäºæ·±åº¦äº‹ä»¶è§†è§‰é‡Œç¨‹è®¡ï¼ˆDEVOï¼‰ï¼Œå¼•å…¥äº†ä¸€ç§æ–°é¢–é«˜æ•ˆçš„é™æ€ç«‹ä½“å…³è”ç­–ç•¥ï¼Œç”¨äºç¨€ç–æ·±åº¦ä¼°è®¡ï¼Œå‡ ä¹æ²¡æœ‰é¢å¤–çš„è®¡ç®—è´Ÿæ‹…ã€‚é€šè¿‡å°†å…¶é›†æˆåˆ°ç´§è€¦åˆçš„æ†ç»‘è°ƒæ•´ï¼ˆBAï¼‰ä¼˜åŒ–æ–¹æ¡ˆä¸­ï¼Œå¹¶å—ç›Šäºå¾ªç¯ç½‘ç»œé€šè¿‡åŸºäºä½“ç´ çš„äº‹ä»¶è¡¨ç¤ºæ‰§è¡Œç²¾ç¡®å…‰æµä¼°è®¡ä»¥å»ºç«‹å¯é çš„patchå…³è”çš„èƒ½åŠ›ï¼Œè¯¥ç³»ç»Ÿå®ç°äº†é«˜ç²¾åº¦çš„åº¦é‡å°ºåº¦ä½å§¿ä¼°è®¡ã€‚ä¸DEVOçš„ç¦»çº¿æ€§èƒ½ç›¸æ¯”ï¼Œè¯¥ç³»ç»Ÿå¯ä»¥å®æ—¶å¤„ç†VGAåˆ†è¾¨ç‡çš„äº‹ä»¶æ•°æ®ã€‚åœ¨å¤šä¸ªå…¬å…±çœŸå®ä¸–ç•Œæ•°æ®é›†å’Œè‡ªé‡‡é›†æ•°æ®ä¸Šçš„å¹¿æ³›è¯„ä¼°è¯æ˜äº†è¯¥ç³»ç»Ÿçš„é€šç”¨æ€§ï¼Œä¸æœ€å…ˆè¿›çš„åŸºäºäº‹ä»¶çš„VOæ–¹æ³•ç›¸æ¯”ï¼Œè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè¯¥ç³»ç»Ÿå³ä½¿åœ¨å¤§å‹å¤œé—´HDRåœºæ™¯ä¸­ä¹Ÿèƒ½å®ç°ç¨³å®šçš„ä½å§¿ä¼°è®¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³äº‹ä»¶ç›¸æœºåœ¨å¤æ‚å…‰ç…§æ¡ä»¶ï¼ˆå°¤å…¶æ˜¯ä½å…‰ç…§HDRç¯å¢ƒï¼‰ä¸‹ï¼Œä¼ ç»Ÿè§†è§‰é‡Œç¨‹è®¡æ–¹æ³•å› æ•°æ®å…³è”ä¸å¯é è€Œå¯¼è‡´çš„ä½å§¿ä¼°è®¡ç²¾åº¦ä¸‹é™é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–æ‰‹å·¥è®¾è®¡çš„ç‰¹å¾å’Œå…³è”ç­–ç•¥ï¼Œéš¾ä»¥é€‚åº”äº‹ä»¶ç›¸æœºæ•°æ®å›ºæœ‰çš„å™ªå£°å’ŒåŠ¨æ€èŒƒå›´å˜åŒ–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¾ªç¯ç¥ç»ç½‘ç»œï¼Œå­¦ä¹ äº‹ä»¶æ•°æ®ä¸­çš„å…‰æµä¿¡æ¯ï¼Œå¹¶ç»“åˆç«‹ä½“è§†è§‰çš„å‡ ä½•çº¦æŸï¼Œå®ç°æ›´é²æ£’å’Œç²¾ç¡®çš„ä½å§¿ä¼°è®¡ã€‚é€šè¿‡å­¦ä¹ åˆ°çš„å…‰æµä¿¡æ¯ï¼Œå»ºç«‹äº‹ä»¶patchä¹‹é—´çš„å¯é å…³è”ï¼Œå…‹æœäº†æ‰‹å·¥ç‰¹å¾çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šStereo-DEVOç³»ç»Ÿä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) äº‹ä»¶æ•°æ®ä½“ç´ åŒ–è¡¨ç¤ºï¼šå°†äº‹ä»¶æµè½¬æ¢ä¸ºä½“ç´ ç½‘æ ¼ï¼›2) åŸºäºå¾ªç¯ç¥ç»ç½‘ç»œçš„å…‰æµä¼°è®¡ï¼šåˆ©ç”¨RNNå­¦ä¹ ä½“ç´ ç½‘æ ¼ä¸­çš„å…‰æµä¿¡æ¯ï¼›3) é™æ€ç«‹ä½“å…³è”ï¼šåˆ©ç”¨ç«‹ä½“ç›¸æœºä¿¡æ¯è¿›è¡Œç¨€ç–æ·±åº¦ä¼°è®¡ï¼›4) ç´§è€¦åˆæ†ç»‘è°ƒæ•´ï¼ˆBAï¼‰ï¼šå°†å…‰æµä¼°è®¡å’Œæ·±åº¦ä¼°è®¡ç»“æœèåˆåˆ°BAä¼˜åŒ–æ¡†æ¶ä¸­ï¼Œå®ç°ä½å§¿ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„é™æ€ç«‹ä½“å…³è”ç­–ç•¥ï¼Œç”¨äºç¨€ç–æ·±åº¦ä¼°è®¡ï¼Œè®¡ç®—è´Ÿæ‹…å°ï¼›2) å°†æ·±åº¦å­¦ä¹ çš„å…‰æµä¼°è®¡ä¸ç«‹ä½“è§†è§‰å‡ ä½•çº¦æŸç›¸ç»“åˆï¼Œæé«˜äº†ä½å§¿ä¼°è®¡çš„é²æ£’æ€§å’Œç²¾åº¦ï¼›3) ç³»ç»Ÿèƒ½å¤Ÿå®æ—¶å¤„ç†VGAåˆ†è¾¨ç‡çš„äº‹ä»¶æ•°æ®ï¼Œå…·æœ‰å®é™…åº”ç”¨ä»·å€¼ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„æ–¹é¢ï¼Œä½¿ç”¨äº†å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰æ¥å­¦ä¹ äº‹ä»¶æ•°æ®ä¸­çš„æ—¶åºä¿¡æ¯ï¼Œä»è€Œè¿›è¡Œå…‰æµä¼°è®¡ã€‚æŸå¤±å‡½æ•°æ–¹é¢ï¼Œå¯èƒ½ä½¿ç”¨äº†å…‰æµä¸€è‡´æ€§æŸå¤±ã€æ·±åº¦ä¸€è‡´æ€§æŸå¤±ç­‰ï¼Œä»¥çº¦æŸå…‰æµå’Œæ·±åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚é™æ€ç«‹ä½“å…³è”çš„å…·ä½“å®ç°æ–¹å¼ï¼ˆä¾‹å¦‚ï¼Œå¦‚ä½•é€‰æ‹©ç”¨äºå…³è”çš„äº‹ä»¶ï¼‰ä»¥åŠBAä¼˜åŒ–æ¡†æ¶çš„å…·ä½“å‚æ•°è®¾ç½®ï¼ˆä¾‹å¦‚ï¼Œæƒé‡åˆ†é…ï¼‰æ˜¯å½±å“ç³»ç»Ÿæ€§èƒ½çš„å…³é”®è®¾è®¡ç»†èŠ‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Stereo-DEVOåœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†å’Œè‡ªé‡‡é›†æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨ä½å§¿ä¼°è®¡ç²¾åº¦æ–¹é¢ä¼˜äºç°æœ‰çš„åŸºäºäº‹ä»¶çš„è§†è§‰é‡Œç¨‹è®¡æ–¹æ³•ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè¯¥ç³»ç»Ÿåœ¨å¤§å‹å¤œé—´HDRåœºæ™¯ä¸­å®ç°äº†ç¨³å®šçš„ä½å§¿ä¼°è®¡ï¼Œè¯æ˜äº†å…¶åœ¨å¤æ‚å…‰ç…§æ¡ä»¶ä¸‹çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿå®æ—¶å¤„ç†VGAåˆ†è¾¨ç‡çš„äº‹ä»¶æ•°æ®ï¼Œå…·æœ‰å®é™…åº”ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€æ— äººæœºç­‰é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨å…‰ç…§æ¡ä»¶æ¶åŠ£æˆ–åŠ¨æ€èŒƒå›´é«˜çš„åœºæ™¯ä¸‹ï¼Œä¾‹å¦‚å¤œé—´æˆ–éš§é“ç­‰ç¯å¢ƒã€‚Stereo-DEVOèƒ½å¤Ÿæä¾›æ›´ç¨³å®šå’Œç²¾ç¡®çš„ä½å§¿ä¼°è®¡ï¼Œä»è€Œæé«˜æœºå™¨äººçš„è‡ªä¸»æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°å¢å¼ºç°å®ã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Event-based cameras are bio-inspired sensors with pixels that independently and asynchronously respond to brightness changes at microsecond resolution, offering the potential to handle state estimation tasks involving motion blur and high dynamic range (HDR) illumination conditions. However, the versatility of event-based visual odometry (VO) relying on handcrafted data association (either direct or indirect methods) is still unreliable, especially in field robot applications under low-light HDR conditions, where the dynamic range can be enormous and the signal-to-noise ratio is spatially-and-temporally varying. Leveraging deep neural networks offers new possibilities for overcoming these challenges. In this paper, we propose a learning-based stereo event visual odometry. Building upon Deep Event Visual Odometry (DEVO), our system (called Stereo-DEVO) introduces a novel and efficient static-stereo association strategy for sparse depth estimation with almost no additional computational burden. By integrating it into a tightly coupled bundle adjustment (BA) optimization scheme, and benefiting from the recurrent network's ability to perform accurate optical flow estimation through voxel-based event representations to establish reliable patch associations, our system achieves high-precision pose estimation in metric scale. In contrast to the offline performance of DEVO, our system can process event data of \zs{Video Graphics Array} (VGA) resolution in real time. Extensive evaluations on multiple public real-world datasets and self-collected data justify our system's versatility, demonstrating superior performance compared to state-of-the-art event-based VO methods. More importantly, our system achieves stable pose estimation even in large-scale nighttime HDR scenarios.

