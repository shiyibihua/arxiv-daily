---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-10-06
---

# cs.ROï¼ˆ2025-10-06ï¼‰

ğŸ“Š å…± **15** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (9)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251005070v2-resmimic-from-general-motion-tracking-to-humanoid-whole-body-loco-ma.html">ResMimic: From General Motion Tracking to Humanoid Whole-body Loco-Manipulation via Residual Learning</a></td>
  <td>ResMimicï¼šé€šè¿‡æ®‹å·®å­¦ä¹ å®ç°ä»é€šç”¨è¿åŠ¨è·Ÿè¸ªåˆ°äººå½¢æœºå™¨äººå…¨èº«Loco-Manipulation</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.05070v2" onclick="toggleFavorite(this, '2510.05070v2', 'ResMimic: From General Motion Tracking to Humanoid Whole-body Loco-Manipulation via Residual Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251005001v1-walking-rolling-and-beyond-first-principles-and-rl-locomotion-on-a-t.html">Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot</a></td>
  <td>åŸºäºç¬¬ä¸€æ€§åŸç†ä¸å¼ºåŒ–å­¦ä¹ ï¼Œæ¢ç´¢TARSæœºå™¨äººæ–°å‹è¿åŠ¨æ¨¡å¼</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.05001v1" onclick="toggleFavorite(this, '2510.05001v1', 'Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251004592v1-mobrt-a-digital-twin-based-framework-for-scalable-learning-in-mobile.html">MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation</a></td>
  <td>MobRTï¼šåŸºäºæ•°å­—å­ªç”Ÿçš„ç§»åŠ¨æ“ä½œå¯æ‰©å±•å­¦ä¹ æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.04592v1" onclick="toggleFavorite(this, '2510.04592v1', 'MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251004696v2-building-gradient-by-gradient-decentralised-energy-functions-for-bim.html">Building Gradient by Gradient: Decentralised Energy Functions for Bimanual Robot Assembly</a></td>
  <td>æå‡ºä¸€ç§åˆ†æ•£å¼æ¢¯åº¦èƒ½é‡å‡½æ•°ï¼Œç”¨äºåŒè‡‚æœºå™¨äººè£…é…ä¸­çš„å¿«é€Ÿé‡è§„åˆ’ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.04696v2" onclick="toggleFavorite(this, '2510.04696v2', 'Building Gradient by Gradient: Decentralised Energy Functions for Bimanual Robot Assembly')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251005382v1-a-multi-modal-tactile-fingertip-design-for-robotic-hands-to-enhance-.html">A multi-modal tactile fingertip design for robotic hands to enhance dexterous manipulation</a></td>
  <td>æå‡ºä¸€ç§ä½æˆæœ¬å¤šæ¨¡æ€è§¦è§‰æŒ‡å°–è®¾è®¡ï¼Œå¢å¼ºæœºå™¨äººçµå·§æ“ä½œèƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.05382v1" onclick="toggleFavorite(this, '2510.05382v1', 'A multi-modal tactile fingertip design for robotic hands to enhance dexterous manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251004585v1-everything-grasping-eg-gripper-a-universal-gripper-with-synergistic-.html">Everything-Grasping (EG) Gripper: A Universal Gripper with Synergistic Suction-Grasping Capabilities for Cross-Scale and Cross-State Manipulation</a></td>
  <td>æå‡ºEverything-Grasping (EG) Gripperï¼Œå®ç°è·¨å°ºåº¦å’Œè·¨çŠ¶æ€ç‰©ä½“çš„é€šç”¨æŠ“å–</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.04585v1" onclick="toggleFavorite(this, '2510.04585v1', 'Everything-Grasping (EG) Gripper: A Universal Gripper with Synergistic Suction-Grasping Capabilities for Cross-Scale and Cross-State Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251004436v1-pad-tro-projection-augmented-diffusion-for-direct-trajectory-optimiz.html">PAD-TRO: Projection-Augmented Diffusion for Direct Trajectory Optimization</a></td>
  <td>æå‡ºPAD-TROï¼Œé€šè¿‡æŠ•å½±å¢å¼ºæ‰©æ•£æ¨¡å‹å®ç°ç›´æ¥è½¨è¿¹ä¼˜åŒ–ï¼Œè§£å†³åŠ¨æ€å¯è¡Œæ€§çº¦æŸéš¾é¢˜ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.04436v1" onclick="toggleFavorite(this, '2510.04436v1', 'PAD-TRO: Projection-Augmented Diffusion for Direct Trajectory Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251005443v1-ad-node-adaptive-dynamics-learning-with-neural-odes-for-mobile-robot.html">AD-NODE: Adaptive Dynamics Learning with Neural ODEs for Mobile Robots Control</a></td>
  <td>æå‡ºåŸºäºç¥ç»ODEçš„è‡ªé€‚åº”åŠ¨åŠ›å­¦å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºç§»åŠ¨æœºå™¨äººæ§åˆ¶ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.05443v1" onclick="toggleFavorite(this, '2510.05443v1', 'AD-NODE: Adaptive Dynamics Learning with Neural ODEs for Mobile Robots Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251004509v1-velocity-form-data-enabled-predictive-control-of-soft-robots-under-u.html">Velocity-Form Data-Enabled Predictive Control of Soft Robots under Unknown External Payloads</a></td>
  <td>æå‡ºåŸºäºé€Ÿåº¦å½¢å¼æ•°æ®çš„è½¯ä½“æœºå™¨äººé¢„æµ‹æ§åˆ¶ï¼Œè§£å†³æœªçŸ¥è½½è·ä¸‹çš„é²æ£’æ§åˆ¶é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.04509v1" onclick="toggleFavorite(this, '2510.04509v1', 'Velocity-Form Data-Enabled Predictive Control of Soft Robots under Unknown External Payloads')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>10</td>
  <td><a href="./papers/251200005v1-dreamer-vxs-a-latent-world-model-for-sample-efficient-agv-exploratio.html">DREAMer-VXS: A Latent World Model for Sample-Efficient AGV Exploration in Stochastic, Unobserved Environments</a></td>
  <td>æå‡ºDREAMer-VXSä»¥è§£å†³AGVåœ¨éšæœºæœªçŸ¥ç¯å¢ƒä¸­çš„æ ·æœ¬æ•ˆç‡é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.00005v1" onclick="toggleFavorite(this, '2512.00005v1', 'DREAMer-VXS: A Latent World Model for Sample-Efficient AGV Exploration in Stochastic, Unobserved Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251005213v1-ver-vision-expert-transformer-for-robot-learning-via-foundation-dist.html">VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing</a></td>
  <td>æå‡ºVERï¼Œé€šè¿‡ä¸“å®¶è’¸é¦å’ŒåŠ¨æ€è·¯ç”±å®ç°æœºå™¨äººå­¦ä¹ çš„è§†è§‰çŸ¥è¯†è¿ç§»ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.05213v1" onclick="toggleFavorite(this, '2510.05213v1', 'VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251005057v1-stamo-unsupervised-learning-of-generalizable-robot-motion-from-compa.html">StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation</a></td>
  <td>StaMoï¼šåŸºäºç´§å‡‘çŠ¶æ€è¡¨å¾æ— ç›‘ç£å­¦ä¹ é€šç”¨æœºå™¨äººè¿åŠ¨</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.05057v1" onclick="toggleFavorite(this, '2510.05057v1', 'StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/251004898v1-hypervla-efficient-inference-in-vision-language-action-models-via-hy.html">HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks</a></td>
  <td>HyperVLAï¼šé€šè¿‡è¶…ç½‘ç»œå®ç°è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„é«˜æ•ˆæ¨ç†</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.04898v1" onclick="toggleFavorite(this, '2510.04898v1', 'HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251005430v1-active-semantic-perception.html">Active Semantic Perception</a></td>
  <td>æå‡ºåŸºäºè¯­ä¹‰åœºæ™¯å›¾çš„ä¸»åŠ¨è¯­ä¹‰æ„ŸçŸ¥æ–¹æ³•ï¼Œç”¨äºé«˜æ•ˆæ¢ç´¢å¤æ‚å®¤å†…ç¯å¢ƒã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.05430v1" onclick="toggleFavorite(this, '2510.05430v1', 'Active Semantic Perception')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>15</td>
  <td><a href="./papers/251004991v2-efficient-navigation-in-unknown-indoor-environments-with-vision-lang.html">Efficient Navigation in Unknown Indoor Environments with Vision-Language Models</a></td>
  <td>æå‡ºåŸºäºè§†è§‰-è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆå¯¼èˆªæ¡†æ¶ï¼Œè§£å†³æœªçŸ¥å®¤å†…ç¯å¢ƒæ¢ç´¢é—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.04991v2" onclick="toggleFavorite(this, '2510.04991v2', 'Efficient Navigation in Unknown Indoor Environments with Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)