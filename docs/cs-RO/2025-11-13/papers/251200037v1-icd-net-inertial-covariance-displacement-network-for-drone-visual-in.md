---
layout: default
title: ICD-Net: Inertial Covariance Displacement Network for Drone Visual-Inertial SLAM
---

# ICD-Net: Inertial Covariance Displacement Network for Drone Visual-Inertial SLAM

**arXiv**: [2512.00037v1](https://arxiv.org/abs/2512.00037) | [PDF](https://arxiv.org/pdf/2512.00037.pdf)

**ä½œè€…**: Tali Orlev Shapira, Itzik Klein

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-13

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ICD-Netï¼šç”¨äºŽæ— äººæœºè§†è§‰æƒ¯æ€§SLAMçš„æƒ¯æ€§åæ–¹å·®ä½ç§»ç½‘ç»œ**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è§†è§‰æƒ¯æ€§SLAM` `æ— äººæœº` `æ·±åº¦å­¦ä¹ ` `æƒ¯æ€§å¯¼èˆª` `ä¸ç¡®å®šæ€§é‡åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†è§‰æƒ¯æ€§SLAMåœ¨æ— äººæœºåº”ç”¨ä¸­é¢ä¸´ä¼ æ„Ÿå™¨æ ¡å‡†è¯¯å·®ã€å™ªå£°ã€å¿«é€Ÿè¿åŠ¨å’Œå…‰ç…§ä¸è¶³ç­‰æŒ‘æˆ˜ã€‚
2. ICD-Neté€šè¿‡å­¦ä¹ åŽŸå§‹æƒ¯æ€§æµ‹é‡æ•°æ®ï¼Œç›´æŽ¥é¢„æµ‹ä½ç§»å’Œä¸ç¡®å®šæ€§ï¼Œæ— éœ€ä¾èµ–è§£æžæƒ¯æ€§ä¼ æ„Ÿå™¨æ¨¡åž‹ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒICD-Netæ˜¾è‘—æé«˜äº†æ— äººæœºSLAMçš„è½¨è¿¹ä¼°è®¡ç²¾åº¦ï¼Œå¹³å‡APEæå‡è¶…è¿‡38%ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºICD-Netçš„æ–°æ¡†æž¶ï¼Œæ—¨åœ¨é€šè¿‡å­¦ä¹ å¤„ç†åŽŸå§‹æƒ¯æ€§æµ‹é‡æ•°æ®å¹¶ç”Ÿæˆå¸¦æœ‰ä¸ç¡®å®šæ€§é‡åŒ–çš„ä½ç§»ä¼°è®¡ï¼Œä»Žè€Œæå‡è§†è§‰æƒ¯æ€§SLAMç³»ç»Ÿçš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•ä¸ä¾èµ–äºŽä¼ ç»Ÿæƒ¯æ€§ä¼ æ„Ÿå™¨æ¨¡åž‹çš„è§£æžå½¢å¼ï¼Œè€Œæ˜¯ç›´æŽ¥ä»Žä¼ æ„Ÿå™¨æ•°æ®ä¸­æå–ä½ç§»å›¾ï¼Œå¹¶åŒæ—¶é¢„æµ‹åæ˜ ä¼°è®¡ç½®ä¿¡åº¦çš„æµ‹é‡åæ–¹å·®ã€‚ICD-Netçš„è¾“å‡ºä½œä¸ºé™„åŠ æ®‹å·®çº¦æŸé›†æˆåˆ°VINS-Fusionä¼˜åŒ–æ¡†æž¶ä¸­ï¼Œé¢„æµ‹çš„ä¸ç¡®å®šæ€§æ ¹æ®ç¥žç»ç½‘ç»œçš„è´¡çŒ®ç¨‹åº¦ï¼Œé€‚å½“åœ°æƒè¡¡äº†ä¼ ç»Ÿè§†è§‰å’Œæƒ¯æ€§é¡¹ã€‚å­¦ä¹ åˆ°çš„ä½ç§»çº¦æŸæä¾›äº†è¡¥å……ä¿¡æ¯ï¼Œè¡¥å¿äº†SLAMæµç¨‹ä¸­çš„å„ç§è¯¯å·®æºã€‚è¯¥æ–¹æ³•æ—¢å¯ç”¨äºŽæ­£å¸¸è¿è¡Œæ¡ä»¶ï¼Œä¹Ÿå¯ç”¨äºŽç›¸æœºä¸ä¸€è‡´æˆ–è§†è§‰é€€åŒ–çš„æƒ…å†µã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„é«˜é€Ÿæ— äººæœºåºåˆ—ä¸Šçš„å®žéªŒè¯„ä¼°è¡¨æ˜Žï¼Œä¸Žæ ‡å‡†VINS-Fusionç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†è½¨è¿¹ä¼°è®¡ç²¾åº¦ï¼Œå¹³å‡APEæé«˜äº†38%ä»¥ä¸Šï¼Œå¹¶ä¸”ä¸ç¡®å®šæ€§ä¼°è®¡å¯¹äºŽä¿æŒç³»ç»Ÿé²æ£’æ€§è‡³å…³é‡è¦ã€‚è¯¥æ–¹æ³•è¡¨æ˜Žï¼Œç¥žç»ç½‘ç»œå¢žå¼ºå¯ä»¥æœ‰æ•ˆåœ°è§£å†³SLAMæ€§èƒ½ä¸‹é™çš„å¤šä¸ªæ¥æºï¼ŒåŒæ—¶ä¿æŒå®žæ—¶æ€§èƒ½è¦æ±‚ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰çš„è§†è§‰æƒ¯æ€§SLAMç³»ç»Ÿåœ¨æ— äººæœºåº”ç”¨ä¸­ï¼Œç”±äºŽä¼ æ„Ÿå™¨æ ‡å®šè¯¯å·®ã€å™ªå£°ã€å¿«é€Ÿè¿åŠ¨ã€ä½Žå…‰ç…§ä»¥åŠä¼ ç»Ÿæƒ¯æ€§å¯¼èˆªç§¯åˆ†æ–¹æ³•çš„å±€é™æ€§ï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºŽè§£æžçš„æƒ¯æ€§ä¼ æ„Ÿå™¨æ¨¡åž‹ï¼Œéš¾ä»¥åº”å¯¹çœŸå®žä¸–ç•Œä¸­ä¼ æ„Ÿå™¨çš„å„ç§ç¼ºé™·ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šICD-Netçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç¥žç»ç½‘ç»œç›´æŽ¥ä»ŽåŽŸå§‹æƒ¯æ€§æµ‹é‡æ•°æ®ä¸­å­¦ä¹ ä½ç§»ä¼°è®¡å’Œå¯¹åº”çš„ä¸ç¡®å®šæ€§ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹ç²¾ç¡®ä¼ æ„Ÿå™¨æ¨¡åž‹çš„ä¾èµ–ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å®žé™…ä¼ æ„Ÿå™¨çš„éžç†æƒ³ç‰¹æ€§ã€‚åŒæ—¶ï¼Œé¢„æµ‹çš„ä¸ç¡®å®šæ€§å¯ä»¥ç”¨äºŽæŒ‡å¯¼SLAMä¼˜åŒ–è¿‡ç¨‹ï¼Œæé«˜ç³»ç»Ÿçš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šICD-Netä½œä¸ºä¸€ä¸ªé™„åŠ æ¨¡å—é›†æˆåˆ°çŽ°æœ‰çš„VINS-Fusionæ¡†æž¶ä¸­ã€‚æ•´ä½“æµç¨‹å¦‚ä¸‹ï¼šé¦–å…ˆï¼ŒICD-NetæŽ¥æ”¶åŽŸå§‹æƒ¯æ€§æµ‹é‡æ•°æ®ä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡ç¥žç»ç½‘ç»œé¢„æµ‹ä½ç§»ä¼°è®¡å’Œåæ–¹å·®çŸ©é˜µã€‚ç„¶åŽï¼Œå°†è¿™äº›é¢„æµ‹ç»“æžœä½œä¸ºé¢å¤–çš„æ®‹å·®é¡¹æ·»åŠ åˆ°VINS-Fusionçš„ä¼˜åŒ–é—®é¢˜ä¸­ã€‚VINS-Fusionåˆ©ç”¨æ‰€æœ‰å¯ç”¨çš„ä¿¡æ¯ï¼ˆè§†è§‰ã€æƒ¯æ€§å’ŒICD-Netçš„è¾“å‡ºï¼‰è¿›è¡Œå…¨å±€ä¼˜åŒ–ï¼Œå¾—åˆ°æœ€ç»ˆçš„ä½å§¿ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šICD-Netçš„å…³é”®åˆ›æ–°åœ¨äºŽä½¿ç”¨ç¥žç»ç½‘ç»œç›´æŽ¥å­¦ä¹ æƒ¯æ€§æµ‹é‡æ•°æ®åˆ°ä½ç§»çš„æ˜ å°„ï¼Œå¹¶åŒæ—¶é¢„æµ‹ä¸ç¡®å®šæ€§ã€‚è¿™ä¸Žä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºŽè§£æžä¼ æ„Ÿå™¨æ¨¡åž‹å½¢æˆäº†é²œæ˜Žå¯¹æ¯”ã€‚é€šè¿‡å­¦ä¹ çš„æ–¹å¼ï¼ŒICD-Netèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å®žé™…ä¼ æ„Ÿå™¨çš„éžç†æƒ³ç‰¹æ€§ï¼Œå¹¶æä¾›æœ‰ç”¨çš„ä¸ç¡®å®šæ€§ä¿¡æ¯ï¼Œä»Žè€Œæé«˜SLAMç³»ç»Ÿçš„é²æ£’æ€§å’Œç²¾åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šICD-Netçš„ç½‘ç»œç»“æž„æœªçŸ¥ï¼Œä½†å¯ä»¥æŽ¨æ–­å…¶è¾“å…¥ä¸ºåŽŸå§‹IMUæ•°æ®ï¼Œè¾“å‡ºä¸ºä½ç§»ä¼°è®¡å’Œåæ–¹å·®çŸ©é˜µã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡è‡³å…³é‡è¦ï¼Œå¯èƒ½åŒ…æ‹¬ä½ç§»ä¼°è®¡çš„è¯¯å·®é¡¹å’Œåæ–¹å·®çŸ©é˜µçš„æ­£åˆ™åŒ–é¡¹ï¼Œä»¥ä¿è¯é¢„æµ‹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚åæ–¹å·®çŸ©é˜µçš„é¢„æµ‹éœ€è¦ä¿è¯å…¶æ­£å®šæ€§ï¼Œå¯èƒ½é€šè¿‡Choleskyåˆ†è§£ç­‰æ–¹æ³•å®žçŽ°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒICD-Netæ˜¾è‘—æé«˜äº†æ— äººæœºSLAMçš„è½¨è¿¹ä¼°è®¡ç²¾åº¦ï¼Œä¸Žæ ‡å‡†VINS-Fusionç›¸æ¯”ï¼Œå¹³å‡APEé™ä½Žäº†38%ä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒICD-Neté¢„æµ‹çš„ä¸ç¡®å®šæ€§ä¼°è®¡å¯¹äºŽä¿æŒç³»ç»Ÿé²æ£’æ€§è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨è§†è§‰ä¿¡æ¯ä¸è¶³æˆ–è´¨é‡è¾ƒå·®çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæŠ‘åˆ¶SLAMç³»ç»Ÿçš„æ¼‚ç§»ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

ICD-Netå¯å¹¿æ³›åº”ç”¨äºŽæ— äººæœºè‡ªä¸»å¯¼èˆªã€æœºå™¨äººå®šä½ã€å¢žå¼ºçŽ°å®žç­‰é¢†åŸŸã€‚ç‰¹åˆ«æ˜¯åœ¨é«˜åŠ¨æ€ã€ä½Žå…‰ç…§ç­‰å¤æ‚çŽ¯å¢ƒä¸‹ï¼ŒICD-Netèƒ½å¤Ÿæœ‰æ•ˆæå‡SLAMç³»ç»Ÿçš„é²æ£’æ€§å’Œç²¾åº¦ï¼Œä»Žè€Œæé«˜æ— äººæœºæˆ–æœºå™¨äººçš„è‡ªä¸»ä½œä¸šèƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºŽç‰©æµé…é€ã€çŽ¯å¢ƒç›‘æµ‹ã€ç¾å®³æ•‘æ´ç­‰åœºæ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Visual-inertial SLAM systems often exhibit suboptimal performance due to multiple confounding factors including imperfect sensor calibration, noisy measurements, rapid motion dynamics, low illumination, and the inherent limitations of traditional inertial navigation integration methods. These issues are particularly problematic in drone applications where robust and accurate state estimation is critical for safe autonomous operation. In this work, we present ICD-Net, a novel framework that enhances visual-inertial SLAM performance by learning to process raw inertial measurements and generating displacement estimates with associated uncertainty quantification. Rather than relying on analytical inertial sensor models that struggle with real-world sensor imperfections, our method directly extracts displacement maps from sensor data while simultaneously predicting measurement covariances that reflect estimation confidence. We integrate ICD-Net outputs as additional residual constraints into the VINS-Fusion optimization framework, where the predicted uncertainties appropriately weight the neural network contributions relative to traditional visual and inertial terms. The learned displacement constraints provide complementary information that compensates for various error sources in the SLAM pipeline. Our approach can be used under both normal operating conditions and in situations of camera inconsistency or visual degradation. Experimental evaluation on challenging high-speed drone sequences demonstrated that our approach significantly improved trajectory estimation accuracy compared to standard VINS-Fusion, with more than 38% improvement in mean APE and uncertainty estimates proving crucial for maintaining system robustness. Our method shows that neural network enhancement can effectively address multiple sources of SLAM degradation while maintaining real-time performance requirements.

