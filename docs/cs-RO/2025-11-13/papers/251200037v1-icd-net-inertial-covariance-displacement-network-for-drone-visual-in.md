---
layout: default
title: ICD-Net: Inertial Covariance Displacement Network for Drone Visual-Inertial SLAM
---

# ICD-Net: Inertial Covariance Displacement Network for Drone Visual-Inertial SLAM

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.00037" target="_blank" class="toolbar-btn">arXiv: 2512.00037v1</a>
    <a href="https://arxiv.org/pdf/2512.00037.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.00037v1" 
            onclick="toggleFavorite(this, '2512.00037v1', 'ICD-Net: Inertial Covariance Displacement Network for Drone Visual-Inertial SLAM')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Tali Orlev Shapira, Itzik Klein

**ÂàÜÁ±ª**: cs.RO, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-13

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ICD-NetÔºöÁî®‰∫éÊó†‰∫∫Êú∫ËßÜËßâÊÉØÊÄßSLAMÁöÑÊÉØÊÄßÂçèÊñπÂ∑Æ‰ΩçÁßªÁΩëÁªú**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâÊÉØÊÄßSLAM` `Êó†‰∫∫Êú∫` `Ê∑±Â∫¶Â≠¶‰π†` `ÊÉØÊÄßÂØºËà™` `‰∏çÁ°ÆÂÆöÊÄßÈáèÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ËßÜËßâÊÉØÊÄßSLAMÂú®Êó†‰∫∫Êú∫Â∫îÁî®‰∏≠Èù¢‰∏¥‰º†ÊÑüÂô®Ê†°ÂáÜËØØÂ∑Æ„ÄÅÂô™Â£∞„ÄÅÂø´ÈÄüËøêÂä®ÂíåÂÖâÁÖß‰∏çË∂≥Á≠âÊåëÊàò„ÄÇ
2. ICD-NetÈÄöËøáÂ≠¶‰π†ÂéüÂßãÊÉØÊÄßÊµãÈáèÊï∞ÊçÆÔºåÁõ¥Êé•È¢ÑÊµã‰ΩçÁßªÂíå‰∏çÁ°ÆÂÆöÊÄßÔºåÊó†ÈúÄ‰æùËµñËß£ÊûêÊÉØÊÄß‰º†ÊÑüÂô®Ê®°Âûã„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåICD-NetÊòæËëóÊèêÈ´ò‰∫ÜÊó†‰∫∫Êú∫SLAMÁöÑËΩ®Ëøπ‰º∞ËÆ°Á≤æÂ∫¶ÔºåÂπ≥ÂùáAPEÊèêÂçáË∂ÖËøá38%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫ICD-NetÁöÑÊñ∞Ê°ÜÊû∂ÔºåÊó®Âú®ÈÄöËøáÂ≠¶‰π†Â§ÑÁêÜÂéüÂßãÊÉØÊÄßÊµãÈáèÊï∞ÊçÆÂπ∂ÁîüÊàêÂ∏¶Êúâ‰∏çÁ°ÆÂÆöÊÄßÈáèÂåñÁöÑ‰ΩçÁßª‰º∞ËÆ°Ôºå‰ªéËÄåÊèêÂçáËßÜËßâÊÉØÊÄßSLAMÁ≥ªÁªüÁöÑÊÄßËÉΩ„ÄÇËØ•ÊñπÊ≥ï‰∏ç‰æùËµñ‰∫é‰º†ÁªüÊÉØÊÄß‰º†ÊÑüÂô®Ê®°ÂûãÁöÑËß£ÊûêÂΩ¢ÂºèÔºåËÄåÊòØÁõ¥Êé•‰ªé‰º†ÊÑüÂô®Êï∞ÊçÆ‰∏≠ÊèêÂèñ‰ΩçÁßªÂõæÔºåÂπ∂ÂêåÊó∂È¢ÑÊµãÂèçÊò†‰º∞ËÆ°ÁΩÆ‰ø°Â∫¶ÁöÑÊµãÈáèÂçèÊñπÂ∑Æ„ÄÇICD-NetÁöÑËæìÂá∫‰Ωú‰∏∫ÈôÑÂä†ÊÆãÂ∑ÆÁ∫¶ÊùüÈõÜÊàêÂà∞VINS-Fusion‰ºòÂåñÊ°ÜÊû∂‰∏≠ÔºåÈ¢ÑÊµãÁöÑ‰∏çÁ°ÆÂÆöÊÄßÊ†πÊçÆÁ•ûÁªèÁΩëÁªúÁöÑË¥°ÁåÆÁ®ãÂ∫¶ÔºåÈÄÇÂΩìÂú∞ÊùÉË°°‰∫Ü‰º†ÁªüËßÜËßâÂíåÊÉØÊÄßÈ°π„ÄÇÂ≠¶‰π†Âà∞ÁöÑ‰ΩçÁßªÁ∫¶ÊùüÊèê‰æõ‰∫ÜË°•ÂÖÖ‰ø°ÊÅØÔºåË°•ÂÅø‰∫ÜSLAMÊµÅÁ®ã‰∏≠ÁöÑÂêÑÁßçËØØÂ∑ÆÊ∫ê„ÄÇËØ•ÊñπÊ≥ïÊó¢ÂèØÁî®‰∫éÊ≠£Â∏∏ËøêË°åÊù°‰ª∂Ôºå‰πüÂèØÁî®‰∫éÁõ∏Êú∫‰∏ç‰∏ÄËá¥ÊàñËßÜËßâÈÄÄÂåñÁöÑÊÉÖÂÜµ„ÄÇÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÈ´òÈÄüÊó†‰∫∫Êú∫Â∫èÂàó‰∏äÁöÑÂÆûÈ™åËØÑ‰º∞Ë°®ÊòéÔºå‰∏éÊ†áÂáÜVINS-FusionÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÊòæËëóÊèêÈ´ò‰∫ÜËΩ®Ëøπ‰º∞ËÆ°Á≤æÂ∫¶ÔºåÂπ≥ÂùáAPEÊèêÈ´ò‰∫Ü38%‰ª•‰∏äÔºåÂπ∂‰∏î‰∏çÁ°ÆÂÆöÊÄß‰º∞ËÆ°ÂØπ‰∫é‰øùÊåÅÁ≥ªÁªüÈ≤ÅÊ£íÊÄßËá≥ÂÖ≥ÈáçË¶Å„ÄÇËØ•ÊñπÊ≥ïË°®ÊòéÔºåÁ•ûÁªèÁΩëÁªúÂ¢ûÂº∫ÂèØ‰ª•ÊúâÊïàÂú∞Ëß£ÂÜ≥SLAMÊÄßËÉΩ‰∏ãÈôçÁöÑÂ§ö‰∏™Êù•Ê∫êÔºåÂêåÊó∂‰øùÊåÅÂÆûÊó∂ÊÄßËÉΩË¶ÅÊ±Ç„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑËßÜËßâÊÉØÊÄßSLAMÁ≥ªÁªüÂú®Êó†‰∫∫Êú∫Â∫îÁî®‰∏≠ÔºåÁî±‰∫é‰º†ÊÑüÂô®Ê†áÂÆöËØØÂ∑Æ„ÄÅÂô™Â£∞„ÄÅÂø´ÈÄüËøêÂä®„ÄÅ‰ΩéÂÖâÁÖß‰ª•Âèä‰º†ÁªüÊÉØÊÄßÂØºËà™ÁßØÂàÜÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄßÔºåÂØºËá¥ÊÄßËÉΩ‰∏ç‰Ω≥„ÄÇ‰º†ÁªüÊñπÊ≥ï‰æùËµñ‰∫éËß£ÊûêÁöÑÊÉØÊÄß‰º†ÊÑüÂô®Ê®°ÂûãÔºåÈöæ‰ª•Â∫îÂØπÁúüÂÆû‰∏ñÁïå‰∏≠‰º†ÊÑüÂô®ÁöÑÂêÑÁßçÁº∫Èô∑„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöICD-NetÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÁ•ûÁªèÁΩëÁªúÁõ¥Êé•‰ªéÂéüÂßãÊÉØÊÄßÊµãÈáèÊï∞ÊçÆ‰∏≠Â≠¶‰π†‰ΩçÁßª‰º∞ËÆ°ÂíåÂØπÂ∫îÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇËøôÁßçÊñπÊ≥ïÈÅøÂÖç‰∫ÜÂØπÁ≤æÁ°Æ‰º†ÊÑüÂô®Ê®°ÂûãÁöÑ‰æùËµñÔºåËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂÆûÈôÖ‰º†ÊÑüÂô®ÁöÑÈùûÁêÜÊÉ≥ÁâπÊÄß„ÄÇÂêåÊó∂ÔºåÈ¢ÑÊµãÁöÑ‰∏çÁ°ÆÂÆöÊÄßÂèØ‰ª•Áî®‰∫éÊåáÂØºSLAM‰ºòÂåñËøáÁ®ãÔºåÊèêÈ´òÁ≥ªÁªüÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöICD-Net‰Ωú‰∏∫‰∏Ä‰∏™ÈôÑÂä†Ê®°ÂùóÈõÜÊàêÂà∞Áé∞ÊúâÁöÑVINS-FusionÊ°ÜÊû∂‰∏≠„ÄÇÊï¥‰ΩìÊµÅÁ®ãÂ¶Ç‰∏ãÔºöÈ¶ñÂÖàÔºåICD-NetÊé•Êî∂ÂéüÂßãÊÉØÊÄßÊµãÈáèÊï∞ÊçÆ‰Ωú‰∏∫ËæìÂÖ•ÔºåÈÄöËøáÁ•ûÁªèÁΩëÁªúÈ¢ÑÊµã‰ΩçÁßª‰º∞ËÆ°ÂíåÂçèÊñπÂ∑ÆÁü©Èòµ„ÄÇÁÑ∂ÂêéÔºåÂ∞ÜËøô‰∫õÈ¢ÑÊµãÁªìÊûú‰Ωú‰∏∫È¢ùÂ§ñÁöÑÊÆãÂ∑ÆÈ°πÊ∑ªÂä†Âà∞VINS-FusionÁöÑ‰ºòÂåñÈóÆÈ¢ò‰∏≠„ÄÇVINS-FusionÂà©Áî®ÊâÄÊúâÂèØÁî®ÁöÑ‰ø°ÊÅØÔºàËßÜËßâ„ÄÅÊÉØÊÄßÂíåICD-NetÁöÑËæìÂá∫ÔºâËøõË°åÂÖ®Â±Ä‰ºòÂåñÔºåÂæóÂà∞ÊúÄÁªàÁöÑ‰ΩçÂßø‰º∞ËÆ°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöICD-NetÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫é‰ΩøÁî®Á•ûÁªèÁΩëÁªúÁõ¥Êé•Â≠¶‰π†ÊÉØÊÄßÊµãÈáèÊï∞ÊçÆÂà∞‰ΩçÁßªÁöÑÊò†Â∞ÑÔºåÂπ∂ÂêåÊó∂È¢ÑÊµã‰∏çÁ°ÆÂÆöÊÄß„ÄÇËøô‰∏é‰º†ÁªüÊñπÊ≥ï‰æùËµñ‰∫éËß£Êûê‰º†ÊÑüÂô®Ê®°ÂûãÂΩ¢Êàê‰∫ÜÈ≤úÊòéÂØπÊØî„ÄÇÈÄöËøáÂ≠¶‰π†ÁöÑÊñπÂºèÔºåICD-NetËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂÆûÈôÖ‰º†ÊÑüÂô®ÁöÑÈùûÁêÜÊÉ≥ÁâπÊÄßÔºåÂπ∂Êèê‰æõÊúâÁî®ÁöÑ‰∏çÁ°ÆÂÆöÊÄß‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òSLAMÁ≥ªÁªüÁöÑÈ≤ÅÊ£íÊÄßÂíåÁ≤æÂ∫¶„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöICD-NetÁöÑÁΩëÁªúÁªìÊûÑÊú™Áü•Ôºå‰ΩÜÂèØ‰ª•Êé®Êñ≠ÂÖ∂ËæìÂÖ•‰∏∫ÂéüÂßãIMUÊï∞ÊçÆÔºåËæìÂá∫‰∏∫‰ΩçÁßª‰º∞ËÆ°ÂíåÂçèÊñπÂ∑ÆÁü©Èòµ„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÂèØËÉΩÂåÖÊã¨‰ΩçÁßª‰º∞ËÆ°ÁöÑËØØÂ∑ÆÈ°πÂíåÂçèÊñπÂ∑ÆÁü©ÈòµÁöÑÊ≠£ÂàôÂåñÈ°πÔºå‰ª•‰øùËØÅÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÂçèÊñπÂ∑ÆÁü©ÈòµÁöÑÈ¢ÑÊµãÈúÄË¶Å‰øùËØÅÂÖ∂Ê≠£ÂÆöÊÄßÔºåÂèØËÉΩÈÄöËøáCholeskyÂàÜËß£Á≠âÊñπÊ≥ïÂÆûÁé∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåICD-NetÊòæËëóÊèêÈ´ò‰∫ÜÊó†‰∫∫Êú∫SLAMÁöÑËΩ®Ëøπ‰º∞ËÆ°Á≤æÂ∫¶Ôºå‰∏éÊ†áÂáÜVINS-FusionÁõ∏ÊØîÔºåÂπ≥ÂùáAPEÈôç‰Ωé‰∫Ü38%‰ª•‰∏ä„ÄÇÊ≠§Â§ñÔºåICD-NetÈ¢ÑÊµãÁöÑ‰∏çÁ°ÆÂÆöÊÄß‰º∞ËÆ°ÂØπ‰∫é‰øùÊåÅÁ≥ªÁªüÈ≤ÅÊ£íÊÄßËá≥ÂÖ≥ÈáçË¶ÅÔºåÂ∞§ÂÖ∂ÊòØÂú®ËßÜËßâ‰ø°ÊÅØ‰∏çË∂≥ÊàñË¥®ÈáèËæÉÂ∑ÆÁöÑÊÉÖÂÜµ‰∏ãÔºåËÉΩÂ§üÊúâÊïàÊäëÂà∂SLAMÁ≥ªÁªüÁöÑÊºÇÁßª„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ICD-NetÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÊó†‰∫∫Êú∫Ëá™‰∏ªÂØºËà™„ÄÅÊú∫Âô®‰∫∫ÂÆö‰Ωç„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÁâπÂà´ÊòØÂú®È´òÂä®ÊÄÅ„ÄÅ‰ΩéÂÖâÁÖßÁ≠âÂ§çÊùÇÁéØÂ¢É‰∏ãÔºåICD-NetËÉΩÂ§üÊúâÊïàÊèêÂçáSLAMÁ≥ªÁªüÁöÑÈ≤ÅÊ£íÊÄßÂíåÁ≤æÂ∫¶Ôºå‰ªéËÄåÊèêÈ´òÊó†‰∫∫Êú∫ÊàñÊú∫Âô®‰∫∫ÁöÑËá™‰∏ª‰Ωú‰∏öËÉΩÂäõ„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂ∫îÁî®‰∫éÁâ©ÊµÅÈÖçÈÄÅ„ÄÅÁéØÂ¢ÉÁõëÊµã„ÄÅÁÅæÂÆ≥ÊïëÊè¥Á≠âÂú∫ÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Visual-inertial SLAM systems often exhibit suboptimal performance due to multiple confounding factors including imperfect sensor calibration, noisy measurements, rapid motion dynamics, low illumination, and the inherent limitations of traditional inertial navigation integration methods. These issues are particularly problematic in drone applications where robust and accurate state estimation is critical for safe autonomous operation. In this work, we present ICD-Net, a novel framework that enhances visual-inertial SLAM performance by learning to process raw inertial measurements and generating displacement estimates with associated uncertainty quantification. Rather than relying on analytical inertial sensor models that struggle with real-world sensor imperfections, our method directly extracts displacement maps from sensor data while simultaneously predicting measurement covariances that reflect estimation confidence. We integrate ICD-Net outputs as additional residual constraints into the VINS-Fusion optimization framework, where the predicted uncertainties appropriately weight the neural network contributions relative to traditional visual and inertial terms. The learned displacement constraints provide complementary information that compensates for various error sources in the SLAM pipeline. Our approach can be used under both normal operating conditions and in situations of camera inconsistency or visual degradation. Experimental evaluation on challenging high-speed drone sequences demonstrated that our approach significantly improved trajectory estimation accuracy compared to standard VINS-Fusion, with more than 38% improvement in mean APE and uncertainty estimates proving crucial for maintaining system robustness. Our method shows that neural network enhancement can effectively address multiple sources of SLAM degradation while maintaining real-time performance requirements.

