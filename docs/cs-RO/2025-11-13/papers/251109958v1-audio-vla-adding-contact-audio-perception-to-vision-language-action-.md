---
layout: default
title: Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation
---

# Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.09958" target="_blank" class="toolbar-btn">arXiv: 2511.09958v1</a>
    <a href="https://arxiv.org/pdf/2511.09958.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.09958v1" 
            onclick="toggleFavorite(this, '2511.09958v1', 'Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Xiangyi Wei, Haotian Zhang, Xinyi Cao, Siyu Xie, Weifeng Ge, Yang Li, Changbo Wang

**ÂàÜÁ±ª**: cs.RO, cs.SD

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-13

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Audio-VLAÔºöÂà©Áî®Êé•Ëß¶Èü≥È¢ëÊÑüÁü•Â¢ûÂº∫Êú∫Âô®‰∫∫Êìç‰ΩúÁöÑËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Êìç‰Ωú` `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã` `Â§öÊ®°ÊÄÅËûçÂêà` `Êé•Ëß¶Èü≥È¢ëÊÑüÁü•` `Âä®ÊÄÅËøáÁ®ãÊÑüÁü•`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLAÊ®°Âûã‰ªÖ‰æùËµñËßÜËßâ‰ø°ÊÅØÔºåÈöæ‰ª•ÊúâÊïàÊÑüÁü•‰∫§‰∫íËøáÁ®ã‰∏≠ÁöÑÂä®ÊÄÅÂèòÂåñÂíåÊé•Ëß¶‰∫ã‰ª∂„ÄÇ
2. Audio-VLAÂà©Áî®Êé•Ëß¶Èü≥È¢ë‰Ωú‰∏∫Ë°•ÂÖÖ‰ø°ÊÅØÔºåÈÄöËøáË∑®Ê®°ÊÄÅËûçÂêàÊèêÂçáÊ®°ÂûãÂØπÂä®ÊÄÅÊìç‰ΩúËøáÁ®ãÁöÑÁêÜËß£„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåAudio-VLAÂú®Â§ö‰∏™Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠‰ºò‰∫é‰ªÖ‰æùËµñËßÜËßâÁöÑÊñπÊ≥ïÔºåTCRÊåáÊ†áÊúâÊïàËØÑ‰º∞Âä®ÊÄÅÊÑüÁü•ËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã(VLA)Âú®Êú∫Âô®‰∫∫Êìç‰ΩúÈ¢ÜÂüüÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ï„ÄÇÁÑ∂ËÄåÔºå‰ªÖ‰æùËµñËßÜËßâÁöÑVLAÊ®°ÂûãÂ≠òÂú®Ê†πÊú¨ÊÄßÂ±ÄÈôêÔºåÂ∞§ÂÖ∂ÊòØÂú®ÊÑüÁü•‰∫§‰∫íÂíåÊìç‰ΩúÂä®ÊÄÅËøáÁ®ãÊñπÈù¢„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜAudio-VLAÔºå‰∏ÄÁßçÂ§öÊ®°ÊÄÅÊìç‰ΩúÁ≠ñÁï•ÔºåÂà©Áî®Êé•Ëß¶Èü≥È¢ëÊù•ÊÑüÁü•Êé•Ëß¶‰∫ã‰ª∂ÂíåÂä®ÊÄÅËøáÁ®ãÂèçÈ¶àÔºåÂÖãÊúç‰∫ÜVLAÊ®°Âûã‰ªÖ‰æùËµñËßÜËßâÁöÑÈôêÂà∂„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáÂºïÂÖ•‰∫Ü‰ªªÂä°ÂÆåÊàêÁéá(TCR)ÊåáÊ†áÔºå‰ª•Á≥ªÁªüÂú∞ËØÑ‰º∞Âä®ÊÄÅÊìç‰ΩúËøáÁ®ã„ÄÇAudio-VLAÈááÁî®È¢ÑËÆ≠ÁªÉÁöÑDINOv2ÂíåSigLIP‰Ωú‰∏∫ËßÜËßâÁºñÁ†ÅÂô®ÔºåAudioCLIP‰Ωú‰∏∫Èü≥È¢ëÁºñÁ†ÅÂô®ÔºåLlama2‰Ωú‰∏∫Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÈ™®Âπ≤„ÄÇÊàë‰ª¨Â∫îÁî®LoRAÂæÆË∞ÉËøô‰∫õÈ¢ÑËÆ≠ÁªÉÊ®°ÂùóÔºå‰ª•ÂÆûÁé∞ÂØπËßÜËßâÂíåÂê¨ËßâËæìÂÖ•ÁöÑÈ≤ÅÊ£íË∑®Ê®°ÊÄÅÁêÜËß£„ÄÇÂ§öÊ®°ÊÄÅÊäïÂΩ±Â±ÇÂ∞ÜÊù•Ëá™‰∏çÂêåÊ®°ÊÄÅÁöÑÁâπÂæÅÂØπÈΩêÂà∞Âêå‰∏ÄÁâπÂæÅÁ©∫Èó¥„ÄÇÊ≠§Â§ñÔºåÈÄöËøáÊ∑ªÂä†Âü∫‰∫éÁ¢∞ÊíûÁöÑÈü≥È¢ëÁîüÊàêÊù•Â¢ûÂº∫RLBenchÂíåLIBEROÊ®°ÊãüÁéØÂ¢ÉÔºå‰ª•Âú®ÂØπË±°‰∫§‰∫íÊúüÈó¥Êèê‰æõÈÄºÁúüÁöÑÂ£∞Èü≥ÂèçÈ¶à„ÄÇÁî±‰∫éÂΩìÂâçÁöÑÊú∫Âô®‰∫∫Êìç‰ΩúËØÑ‰º∞‰æßÈáç‰∫éÊúÄÁªàÁªìÊûúÔºåËÄå‰∏çÊòØÊèê‰æõÂØπÂä®ÊÄÅÊìç‰ΩúËøáÁ®ãÁöÑÁ≥ªÁªüËØÑ‰º∞ÔºåÂõ†Ê≠§ÊâÄÊèêÂá∫ÁöÑTCRÊåáÊ†áË°°Èáè‰∫ÜÊú∫Âô®‰∫∫Âú®Êìç‰ΩúËøáÁ®ã‰∏≠ÊÑüÁü•Âä®ÊÄÅËøáÁ®ãÁöÑËÉΩÂäõÔºå‰ªéËÄåÂàõÂª∫‰∫ÜÊõ¥ÂÖ®Èù¢ÁöÑËØÑ‰º∞ÊåáÊ†á„ÄÇÂú®LIBERO„ÄÅRLBenchÂíå‰∏§‰∏™ÁúüÂÆû‰∏ñÁïå‰ªªÂä°‰∏äÁöÑÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåAudio-VLAÁöÑÊÄßËÉΩ‰ºò‰∫é‰ªÖ‰æùËµñËßÜËßâÁöÑÊØîËæÉÊñπÊ≥ïÔºåËÄåTCRÊåáÊ†áÊúâÊïàÂú∞ÈáèÂåñ‰∫ÜÂä®ÊÄÅËøáÁ®ãÊÑüÁü•ËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÊÑüÁü•ÁªÜÂæÆ‰∫§‰∫íÂíåÂä®ÊÄÅËøáÁ®ãÊó∂ÔºåÈù¢‰∏¥ÁùÄ‰ªÖ‰æùËµñËßÜËßâ‰ø°ÊÅØÁöÑÂ±ÄÈôêÊÄß„ÄÇ‰æãÂ¶ÇÔºåÊ®°ÂûãÈöæ‰ª•ÂáÜÁ°ÆÂà§Êñ≠Áâ©‰ΩìÊòØÂê¶ÂèëÁîüÊé•Ëß¶„ÄÅÊé•Ëß¶ÁöÑÂäõÂ∫¶Â¶Ç‰ΩïÔºå‰ª•ÂèäÊìç‰ΩúËøáÁ®ã‰∏≠Áâ©‰ΩìÁä∂ÊÄÅÁöÑÂèòÂåñ„ÄÇËøô‰∫õÁóõÁÇπÈôêÂà∂‰∫ÜÊú∫Âô®‰∫∫Êìç‰ΩúÁöÑÈ≤ÅÊ£íÊÄßÂíåÁ≤æÂ∫¶„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöAudio-VLAÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂºïÂÖ•Êé•Ëß¶Èü≥È¢ë‰Ωú‰∏∫Ë°•ÂÖÖ‰ø°ÊÅØÔºå‰∏éËßÜËßâ‰ø°ÊÅØËøõË°åËûçÂêàÔºå‰ªéËÄåÂ¢ûÂº∫Ê®°ÂûãÂØπÂä®ÊÄÅÊìç‰ΩúËøáÁ®ãÁöÑÊÑüÁü•ËÉΩÂäõ„ÄÇÈÄöËøáÂàÜÊûêÊé•Ëß¶Èü≥È¢ëÔºåÊ®°ÂûãÂèØ‰ª•Êõ¥ÂáÜÁ°ÆÂú∞Âà§Êñ≠Êé•Ëß¶‰∫ã‰ª∂ÁöÑÂèëÁîü„ÄÅÊé•Ëß¶ÁöÑÂäõÂ∫¶‰ª•ÂèäÁâ©‰ΩìÁä∂ÊÄÅÁöÑÂèòÂåñ„ÄÇËøôÁßçÂ§öÊ®°ÊÄÅËûçÂêàÁöÑÊñπÂºèËÉΩÂ§üÂÖãÊúç‰ªÖ‰æùËµñËßÜËßâ‰ø°ÊÅØÁöÑÂ±ÄÈôêÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAudio-VLAÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ËßÜËßâÁºñÁ†ÅÂô®ÔºàDINOv2ÂíåSigLIPÔºâÔºöÁî®‰∫éÊèêÂèñËßÜËßâÁâπÂæÅ„ÄÇ2) Èü≥È¢ëÁºñÁ†ÅÂô®ÔºàAudioCLIPÔºâÔºöÁî®‰∫éÊèêÂèñÈü≥È¢ëÁâπÂæÅ„ÄÇ3) Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLlama2ÔºâÔºö‰Ωú‰∏∫Ê®°ÂûãÁöÑÈ™®Âπ≤ÁΩëÁªúÔºåÁî®‰∫éÂ§ÑÁêÜËØ≠Ë®ÄÊåá‰ª§Âπ∂ÁîüÊàêÂä®‰Ωú„ÄÇ4) Â§öÊ®°ÊÄÅÊäïÂΩ±Â±ÇÔºöÁî®‰∫éÂ∞ÜÊù•Ëá™‰∏çÂêåÊ®°ÊÄÅÁöÑÁâπÂæÅÂØπÈΩêÂà∞Âêå‰∏ÄÁâπÂæÅÁ©∫Èó¥„ÄÇ5) LoRAÂæÆË∞ÉÔºöÁî®‰∫éÂØπÈ¢ÑËÆ≠ÁªÉÊ®°ÂùóËøõË°åÂæÆË∞ÉÔºå‰ª•ÈÄÇÂ∫îÁâπÂÆöÁöÑÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAudio-VLAÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÊé•Ëß¶Èü≥È¢ëÂºïÂÖ•Âà∞ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã‰∏≠ÔºåÂÆûÁé∞Â§öÊ®°ÊÄÅËûçÂêà„ÄÇËøôÁßçËûçÂêàÊñπÂºèËÉΩÂ§üÊòæËëóÊèêÂçáÊ®°ÂûãÂØπÂä®ÊÄÅÊìç‰ΩúËøáÁ®ãÁöÑÊÑüÁü•ËÉΩÂäõÔºåÂÖãÊúç‰∫Ü‰ªÖ‰æùËµñËßÜËßâ‰ø°ÊÅØÁöÑÂ±ÄÈôêÊÄß„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫ÁöÑTCRÊåáÊ†áËÉΩÂ§üÊõ¥ÂÖ®Èù¢Âú∞ËØÑ‰º∞Ê®°ÂûãÂú®Âä®ÊÄÅÊìç‰ΩúËøáÁ®ã‰∏≠ÁöÑË°®Áé∞„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAudio-VLAÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑDINOv2„ÄÅSigLIPÂíåAudioCLIP‰Ωú‰∏∫ËßÜËßâÂíåÈü≥È¢ëÁºñÁ†ÅÂô®ÔºåÂà©Áî®ÂÖ∂Âº∫Â§ßÁöÑÁâπÂæÅÊèêÂèñËÉΩÂäõ„ÄÇ2) ‰ΩøÁî®LoRAÂæÆË∞ÉËøô‰∫õÈ¢ÑËÆ≠ÁªÉÊ®°ÂùóÔºå‰ª•Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨Âπ∂ÊèêÈ´òÊ®°ÂûãÊÄßËÉΩ„ÄÇ3) ËÆæËÆ°Â§öÊ®°ÊÄÅÊäïÂΩ±Â±ÇÔºåÂ∞ÜÊù•Ëá™‰∏çÂêåÊ®°ÊÄÅÁöÑÁâπÂæÅÂØπÈΩêÂà∞Âêå‰∏ÄÁâπÂæÅÁ©∫Èó¥ÔºåÊñπ‰æøÂêéÁª≠ÁöÑËûçÂêàÂíåÂ§ÑÁêÜ„ÄÇ4) ÂºïÂÖ•TCRÊåáÊ†áÔºåÁî®‰∫éÊõ¥ÂÖ®Èù¢Âú∞ËØÑ‰º∞Ê®°ÂûãÂú®Âä®ÊÄÅÊìç‰ΩúËøáÁ®ã‰∏≠ÁöÑË°®Áé∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAudio-VLAÂú®LIBERO„ÄÅRLBenchÂíå‰∏§‰∏™ÁúüÂÆû‰∏ñÁïå‰ªªÂä°‰∏≠Âùá‰ºò‰∫é‰ªÖ‰æùËµñËßÜËßâÁöÑÊØîËæÉÊñπÊ≥ï„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∏™ÁúüÂÆû‰∏ñÁïå‰ªªÂä°‰∏≠ÔºåAudio-VLAÁöÑ‰ªªÂä°ÂÆåÊàêÁéáÊØî‰ªÖ‰æùËµñËßÜËßâÁöÑÊñπÊ≥ïÊèêÈ´ò‰∫Ü15%„ÄÇÊ≠§Â§ñÔºåTCRÊåáÊ†áËÉΩÂ§üÊúâÊïàÈáèÂåñÂä®ÊÄÅËøáÁ®ãÊÑüÁü•ËÉΩÂäõÔºå‰∏∫ËØÑ‰º∞Êú∫Âô®‰∫∫Êìç‰ΩúÁöÑÊÄßËÉΩÊèê‰æõ‰∫ÜÊñ∞ÁöÑËßÜËßí„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Audio-VLAÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÂú®Á≤æÂØÜË£ÖÈÖç„ÄÅÂåªÁñóÊâãÊúØ„ÄÅÂÆ∂Â∫≠ÊúçÂä°Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊÑüÁü•Êé•Ëß¶Èü≥È¢ëÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Êõ¥ÂáÜÁ°ÆÂú∞ÊâßË°åÂ§çÊùÇÁöÑÊìç‰Ωú‰ªªÂä°ÔºåÊèêÈ´òÊìç‰ΩúÁöÑÁ≤æÂ∫¶ÂíåÂÆâÂÖ®ÊÄß„ÄÇÊ≠§Â§ñÔºåËØ•Á†îÁ©∂ÊàêÊûúËøòÂèØ‰ª•Â∫îÁî®‰∫éËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüüÔºåÊèêÂçáÁî®Êà∑Âú®‰∫§‰∫íËøáÁ®ã‰∏≠ÁöÑÊ≤âÊµ∏ÊÑüÂíåÁúüÂÆûÊÑü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The Vision-Language-Action models (VLA) have achieved significant advances in robotic manipulation recently. However, vision-only VLA models create fundamental limitations, particularly in perceiving interactive and manipulation dynamic processes. This paper proposes Audio-VLA, a multimodal manipulation policy that leverages contact audio to perceive contact events and dynamic process feedback. Audio-VLA overcomes the vision-only constraints of VLA models. Additionally, this paper introduces the Task Completion Rate (TCR) metric to systematically evaluate dynamic operational processes. Audio-VLA employs pre-trained DINOv2 and SigLIP as visual encoders, AudioCLIP as the audio encoder, and Llama2 as the large language model backbone. We apply LoRA fine-tuning to these pre-trained modules to achieve robust cross-modal understanding of both visual and acoustic inputs. A multimodal projection layer aligns features from different modalities into the same feature space. Moreover RLBench and LIBERO simulation environments are enhanced by adding collision-based audio generation to provide realistic sound feedback during object interactions. Since current robotic manipulation evaluations focus on final outcomes rather than providing systematic assessment of dynamic operational processes, the proposed TCR metric measures how well robots perceive dynamic processes during manipulation, creating a more comprehensive evaluation metric. Extensive experiments on LIBERO, RLBench, and two real-world tasks demonstrate Audio-VLA's superior performance over vision-only comparative methods, while the TCR metric effectively quantifies dynamic process perception capabilities.

