---
layout: default
title: Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning
---

# Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.10087" target="_blank" class="toolbar-btn">arXiv: 2511.10087v1</a>
    <a href="https://arxiv.org/pdf/2511.10087.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.10087v1" 
            onclick="toggleFavorite(this, '2511.10087v1', 'Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Haidong Huang, Haiyue Zhu. Jiayu Song, Xixin Zhao, Yaohua Zhou, Jiayi Zhang, Yuze Zhai, Xiaocong Li

**ÂàÜÁ±ª**: cs.RO, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-13

**Â§áÊ≥®**: Accepted by NeurIPS 2025 Workshop on Embodied World Models for Decision Making

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫UEPOÔºåÁî®‰∫éËß£ÂÜ≥Êú∫Âô®‰∫∫Á¶ªÁ∫øÂà∞Âú®Á∫øÂº∫ÂåñÂ≠¶‰π†‰∏≠ÁöÑÂ§öÊ®°ÊÄÅË°å‰∏∫Ë¶ÜÁõñÂíåÂàÜÂ∏ÉÂÅèÁßªÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Á¶ªÁ∫øÂº∫ÂåñÂ≠¶‰π†` `Âú®Á∫øÂº∫ÂåñÂ≠¶‰π†` `Êâ©Êï£Ê®°Âûã` `Êú∫Âô®‰∫∫Â≠¶‰π†` `Á≠ñÁï•‰ºòÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. O2O-RLÈù¢‰∏¥Â§öÊ®°ÊÄÅË°å‰∏∫Ë¶ÜÁõñ‰∏çË∂≥ÂíåÂú®Á∫øÈÄÇÂ∫îÊó∂ÁöÑÂàÜÂ∏ÉÂÅèÁßª‰∏§Â§ßÈöæÈ¢òÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®Êú∫Âô®‰∫∫È¢ÜÂüüÁöÑÂ∫îÁî®„ÄÇ
2. UEPOÂÄüÈâ¥Â§ßËØ≠Ë®ÄÊ®°ÂûãÊÄùË∑ØÔºåÊûÑÂª∫Áªü‰∏ÄÁîüÊàêÊ°ÜÊû∂ÔºåÂà©Áî®Êâ©Êï£Ê®°ÂûãÊèêÂçáÁ≠ñÁï•Â§öÊ†∑ÊÄßÂíåÂä®ÂäõÂ≠¶Ê®°ÂûãÊ≥õÂåñÊÄß„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåUEPOÂú®D4RLÂü∫ÂáÜÊµãËØï‰∏≠ÔºåËøêÂä®ÂíåÁÅµÂ∑ßÊìç‰Ωú‰ªªÂä°‰∏äÂùáÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂ±ïÁé∞Âá∫‰ºòË∂äÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Á¶ªÁ∫øÂà∞Âú®Á∫øÂº∫ÂåñÂ≠¶‰π†(O2O-RL)Â∑≤Êàê‰∏∫‰∏ÄÁßçÂÆâÂÖ®È´òÊïàÁöÑÊú∫Âô®‰∫∫Á≠ñÁï•ÈÉ®ÁΩ≤ËåÉÂºèÔºå‰ΩÜÈù¢‰∏¥‰∏§‰∏™Ê†πÊú¨ÊåëÊàòÔºöÂ§öÊ®°ÊÄÅË°å‰∏∫ÁöÑË¶ÜÁõñËåÉÂõ¥ÊúâÈôê‰ª•ÂèäÂú®Á∫øÈÄÇÂ∫îÊúüÈó¥ÁöÑÂàÜÂ∏ÉÂÅèÁßª„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜUEPOÔºå‰∏Ä‰∏™ÂèóÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÈ¢ÑËÆ≠ÁªÉÂíåÂæÆË∞ÉÁ≠ñÁï•ÂêØÂèëÁöÑÁªü‰∏ÄÁîüÊàêÊ°ÜÊû∂„ÄÇÊàë‰ª¨ÁöÑË¥°ÁåÆÊúâ‰∏âÊñπÈù¢Ôºö(1) ‰∏ÄÁßçÂ§öÁßçÂ≠êÂä®ÊÄÅÊÑüÁü•Êâ©Êï£Á≠ñÁï•ÔºåÂèØÊúâÊïàÊçïËé∑ÂêÑÁßçÊ®°ÊÄÅÔºåËÄåÊó†ÈúÄËÆ≠ÁªÉÂ§ö‰∏™Ê®°ÂûãÔºõ(2) ‰∏ÄÁßçÂä®ÊÄÅÊï£Â∫¶Ê≠£ÂàôÂåñÊú∫Âà∂ÔºåÂèØÂº∫Âà∂ÊâßË°åÂÖ∑ÊúâÁâ©ÁêÜÊÑè‰πâÁöÑÁ≠ñÁï•Â§öÊ†∑ÊÄßÔºõ(3) ‰∏ÄÁßçÂü∫‰∫éÊâ©Êï£ÁöÑÊï∞ÊçÆÂ¢ûÂº∫Ê®°ÂùóÔºåÂèØÂ¢ûÂº∫Âä®ÂäõÂ≠¶Ê®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÂú®D4RLÂü∫ÂáÜÊµãËØï‰∏≠ÔºåUEPOÂú®ËøêÂä®‰ªªÂä°‰∏äÊØîUni-O4ÊèêÈ´ò‰∫Ü+5.9%ÔºåÂú®ÁÅµÂ∑ßÊìç‰Ωú‰ªªÂä°‰∏äÊèêÈ´ò‰∫Ü+12.4%ÔºåËØÅÊòé‰∫ÜÂº∫Â§ßÁöÑÊ≥õÂåñÊÄßÂíåÂèØÊâ©Â±ïÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁ¶ªÁ∫øÂà∞Âú®Á∫øÂº∫ÂåñÂ≠¶‰π†(O2O-RL)Êó®Âú®Âà©Áî®Á¶ªÁ∫øÊï∞ÊçÆÈ¢ÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåÁÑ∂ÂêéÂú®Á∫øËøõË°åÂæÆË∞É‰ª•ÈÄÇÂ∫îÁúüÂÆûÁéØÂ¢É„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑO2O-RLÊñπÊ≥ïÈÄöÂ∏∏Èöæ‰ª•Ë¶ÜÁõñÂ§öÊ®°ÊÄÅË°å‰∏∫ÔºåÂπ∂‰∏îÂú®Âú®Á∫øÈÄÇÂ∫îËøáÁ®ã‰∏≠ÂÆπÊòìÂá∫Áé∞ÂàÜÂ∏ÉÂÅèÁßªÔºåÂØºËá¥ÊÄßËÉΩ‰∏ãÈôç„ÄÇËøô‰∫õÈóÆÈ¢òÊ∫ê‰∫éÁ¶ªÁ∫øÊï∞ÊçÆÈõÜÁöÑÂ±ÄÈôêÊÄßÂíåÂú®Á∫øÁéØÂ¢ÉÁöÑÊé¢Á¥¢‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöUEPOÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂÄüÈâ¥Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÈ¢ÑËÆ≠ÁªÉÂíåÂæÆË∞ÉÁ≠ñÁï•ÔºåÊûÑÂª∫‰∏Ä‰∏™Áªü‰∏ÄÁöÑÁîüÊàêÊ°ÜÊû∂„ÄÇÈÄöËøáÊâ©Êï£Ê®°ÂûãÂ≠¶‰π†Á¶ªÁ∫øÊï∞ÊçÆÁöÑÂàÜÂ∏ÉÔºåÁîüÊàêÂ§öÊ†∑ÂåñÁöÑÁ≠ñÁï•Ôºå‰ªéËÄåËß£ÂÜ≥Â§öÊ®°ÊÄÅË°å‰∏∫Ë¶ÜÁõñ‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÂêåÊó∂ÔºåÂºïÂÖ•Âä®ÊÄÅÊï£Â∫¶Ê≠£ÂàôÂåñÊú∫Âà∂ÔºåÈºìÂä±Á≠ñÁï•Êé¢Á¥¢ÂÖ∑ÊúâÁâ©ÁêÜÊÑè‰πâÁöÑË°å‰∏∫ÔºåÁºìËß£ÂàÜÂ∏ÉÂÅèÁßª„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöUEPOÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö(1) Â§öÁßçÂ≠êÂä®ÊÄÅÊÑüÁü•Êâ©Êï£Á≠ñÁï•ÔºöÂà©Áî®Â§ö‰∏™ÈöèÊú∫ÁßçÂ≠êÂàùÂßãÂåñÊâ©Êï£ËøáÁ®ãÔºåÁîüÊàêÂ§öÊ†∑ÂåñÁöÑÁ≠ñÁï•Ê†∑Êú¨Ôºå‰ªéËÄåÊçïËé∑‰∏çÂêåÁöÑÊ®°ÊÄÅ„ÄÇ(2) Âä®ÊÄÅÊï£Â∫¶Ê≠£ÂàôÂåñÊú∫Âà∂ÔºöÂú®Á≠ñÁï•‰ºòÂåñËøáÁ®ã‰∏≠ÔºåÂºïÂÖ•Âä®ÊÄÅÊï£Â∫¶Ê≠£ÂàôÂåñÈ°πÔºåÈºìÂä±Á≠ñÁï•Êé¢Á¥¢‰∏éÂΩìÂâçÁä∂ÊÄÅÁõ∏ÂÖ≥ÁöÑÂ§öÊ†∑ÂåñË°å‰∏∫„ÄÇ(3) Âü∫‰∫éÊâ©Êï£ÁöÑÊï∞ÊçÆÂ¢ûÂº∫Ê®°ÂùóÔºöÂà©Áî®Êâ©Êï£Ê®°ÂûãÁîüÊàêÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºåÂ¢ûÂº∫Âä®ÂäõÂ≠¶Ê®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØÂÖà‰ΩøÁî®Á¶ªÁ∫øÊï∞ÊçÆËÆ≠ÁªÉÊâ©Êï£Á≠ñÁï•ÂíåÂä®ÂäõÂ≠¶Ê®°ÂûãÔºåÁÑ∂ÂêéÂú®Âú®Á∫øÁéØÂ¢É‰∏≠ËøõË°åÂæÆË∞ÉÔºåÂà©Áî®Âä®ÊÄÅÊï£Â∫¶Ê≠£ÂàôÂåñÂíåÊï∞ÊçÆÂ¢ûÂº∫ÊäÄÊúØÊèêÂçáÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöUEPOÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÊâ©Êï£Ê®°ÂûãÂ∫îÁî®‰∫éO2O-RLÔºåÂπ∂ËÆæËÆ°‰∫ÜÂä®ÊÄÅÊï£Â∫¶Ê≠£ÂàôÂåñÊú∫Âà∂ÂíåÂü∫‰∫éÊâ©Êï£ÁöÑÊï∞ÊçÆÂ¢ûÂº∫Ê®°Âùó„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåUEPOËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÊçïËé∑Â§öÊ®°ÊÄÅË°å‰∏∫ÔºåÁºìËß£ÂàÜÂ∏ÉÂÅèÁßªÔºåÂπ∂ÊèêÂçáÂä®ÂäõÂ≠¶Ê®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂ§öÁßçÂ≠êÂä®ÊÄÅÊÑüÁü•Êâ©Êï£Á≠ñÁï•‰ΩøÁî®Â§ö‰∏™ÈöèÊú∫ÁßçÂ≠êÁîüÊàêÁ≠ñÁï•Ê†∑Êú¨ÔºåÁßçÂ≠êÁöÑÊï∞ÈáèÊòØ‰∏Ä‰∏™ÈáçË¶ÅÁöÑË∂ÖÂèÇÊï∞„ÄÇÂä®ÊÄÅÊï£Â∫¶Ê≠£ÂàôÂåñÊú∫Âà∂‰∏≠ÁöÑÊï£Â∫¶Â∫¶ÈáèÈááÁî®KLÊï£Â∫¶ÔºåÊ≠£ÂàôÂåñÁ≥ªÊï∞Ê†πÊçÆËÆ≠ÁªÉËøõÂ∫¶Âä®ÊÄÅË∞ÉÊï¥„ÄÇÂü∫‰∫éÊâ©Êï£ÁöÑÊï∞ÊçÆÂ¢ûÂº∫Ê®°Âùó‰ΩøÁî®ËÆ≠ÁªÉÂ•ΩÁöÑÊâ©Êï£Ê®°ÂûãÁîüÊàêÈ¢ùÂ§ñÁöÑÁä∂ÊÄÅ-Âä®‰ΩúÂØπÔºåÂπ∂Â∞ÜÂÖ∂Ê∑ªÂä†Âà∞ËÆ≠ÁªÉÊï∞ÊçÆÈõÜ‰∏≠„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

UEPOÂú®D4RLÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂú®ËøêÂä®‰ªªÂä°‰∏äÔºåUEPOÊØîUni-O4ÊèêÈ´ò‰∫Ü+5.9%„ÄÇÂú®ÁÅµÂ∑ßÊìç‰Ωú‰ªªÂä°‰∏äÔºåUEPOÊØîUni-O4ÊèêÈ´ò‰∫Ü+12.4%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåUEPOÂÖ∑ÊúâÂº∫Â§ßÁöÑÊ≥õÂåñÊÄßÂíåÂèØÊâ©Â±ïÊÄßÔºåËÉΩÂ§üÊúâÊïàÂú∞Ëß£ÂÜ≥O2O-RL‰∏≠ÁöÑÂ§öÊ®°ÊÄÅË°å‰∏∫Ë¶ÜÁõñÂíåÂàÜÂ∏ÉÂÅèÁßªÈóÆÈ¢ò„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

UEPOÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÁî®‰∫éÂêÑÁßçÊú∫Âô®‰∫∫‰ªªÂä°Ôºå‰æãÂ¶ÇÔºöËá™Âä®È©æÈ©∂„ÄÅÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öËá™Âä®ÂåñÁ≠â„ÄÇÈÄöËøáÂà©Áî®Á¶ªÁ∫øÊï∞ÊçÆËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÂπ∂Âú®Á∫øËøõË°åÂæÆË∞ÉÔºåUEPOÂèØ‰ª•ÊòæËëóÈôç‰ΩéÊú∫Âô®‰∫∫Â≠¶‰π†ÁöÑÊàêÊú¨ÂíåÈ£éÈô©ÔºåÊèêÈ´òÊú∫Âô®‰∫∫ÁöÑÊô∫ËÉΩÂåñÊ∞¥Âπ≥ÂíåÈÄÇÂ∫îËÉΩÂäõ„ÄÇËØ•Á†îÁ©∂ÂØπ‰∫éÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÁöÑËøõÊ≠•ÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Offline-to-online reinforcement learning (O2O-RL) has emerged as a promising paradigm for safe and efficient robotic policy deployment but suffers from two fundamental challenges: limited coverage of multimodal behaviors and distributional shifts during online adaptation. We propose UEPO, a unified generative framework inspired by large language model pretraining and fine-tuning strategies. Our contributions are threefold: (1) a multi-seed dynamics-aware diffusion policy that efficiently captures diverse modalities without training multiple models; (2) a dynamic divergence regularization mechanism that enforces physically meaningful policy diversity; and (3) a diffusion-based data augmentation module that enhances dynamics model generalization. On the D4RL benchmark, UEPO achieves +5.9\% absolute improvement over Uni-O4 on locomotion tasks and +12.4\% on dexterous manipulation, demonstrating strong generalization and scalability.

