---
layout: default
title: Hardware-Software Collaborative Computing of Photonic Spiking Reinforcement Learning for Robotic Continuous Control
---

# Hardware-Software Collaborative Computing of Photonic Spiking Reinforcement Learning for Robotic Continuous Control

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.00427" target="_blank" class="toolbar-btn">arXiv: 2512.00427v1</a>
    <a href="https://arxiv.org/pdf/2512.00427.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.00427v1" 
            onclick="toggleFavorite(this, '2512.00427v1', 'Hardware-Software Collaborative Computing of Photonic Spiking Reinforcement Learning for Robotic Continuous Control')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Mengting Yu, Shuiying Xiang, Changjian Xie, Yonghang Chen, Haowen Zhao, Xingxing Guo, Yahui Zhang, Yanan Han, Yue Hao

**ÂàÜÁ±ª**: cs.RO, physics.optics

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-29

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÂÖâÂ≠êËÑâÂÜ≤Á•ûÁªèÁΩëÁªúÁöÑÁ°¨‰ª∂-ËΩØ‰ª∂ÂçèÂêåËÆ°ÁÆóÊû∂ÊûÑÔºåÁî®‰∫éÊú∫Âô®‰∫∫ËøûÁª≠ÊéßÂà∂„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÂÖâÂ≠êËÆ°ÁÆó` `ËÑâÂÜ≤Á•ûÁªèÁΩëÁªú` `Âº∫ÂåñÂ≠¶‰π†` `Êú∫Âô®‰∫∫ÊéßÂà∂` `Á°¨‰ª∂-ËΩØ‰ª∂ÂçèÂêå` `TD3ÁÆóÊ≥ï` `MZIËäØÁâá`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰º†ÁªüÁîµÂ≠êËÆ°ÁÆóÂπ≥Âè∞Âú®Êú∫Âô®‰∫∫ËøûÁª≠ÊéßÂà∂‰ªªÂä°‰∏≠Èù¢‰∏¥ËÆ°ÁÆóÁì∂È¢àÔºåÈöæ‰ª•Êª°Ë∂≥È´òÁª¥Áä∂ÊÄÅÁ©∫Èó¥ÂíåÂÆûÊó∂‰∫§‰∫íÁöÑÈúÄÊ±Ç„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßçÂü∫‰∫éÂÖâÂ≠êËÑâÂÜ≤Âº∫ÂåñÂ≠¶‰π†ÁöÑËÆ°ÁÆóÊû∂ÊûÑÔºåÂà©Áî®ÂÖâÂ≠êËÆ°ÁÆóÁöÑÈ´òÊïàÊÄßÂíåSNNÁöÑÁîüÁâ©Á•ûÁªèÁâπÊÄßÔºåÂÆûÁé∞Âø´ÈÄü‰ΩéÂäüËÄóÁöÑÊéßÂà∂Á≠ñÁï•„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Êû∂ÊûÑÂú®Êú∫Âô®‰∫∫ÊéßÂà∂‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂÆûÁé∞‰∫ÜÊõ¥È´òÁöÑÂ•ñÂä±„ÄÅÊõ¥Âø´ÁöÑÊî∂ÊïõÈÄüÂ∫¶ÂíåÊõ¥‰ΩéÁöÑÂä®‰ΩúÂÅèÂ∑Æ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂÖâÂ≠êËÑâÂÜ≤Âº∫ÂåñÂ≠¶‰π†ÁöÑÊñ∞ÂûãËÆ°ÁÆóÊû∂ÊûÑÔºåÊó®Âú®Ëß£ÂÜ≥Êú∫Âô®‰∫∫ËøûÁª≠ÊéßÂà∂‰ªªÂä°‰∏≠ÂØπËÆ°ÁÆóÊû∂ÊûÑÁöÑËÉΩÊïàÂíåÂª∂ËøüÁöÑ‰∏•ËãõË¶ÅÊ±Ç„ÄÇËØ•Êû∂ÊûÑÂ∞ÜTwin Delayed Deep Deterministic policy gradient (TD3)ÁÆóÊ≥ï‰∏éËÑâÂÜ≤Á•ûÁªèÁΩëÁªú(SNN)Áõ∏ÁªìÂêàÔºåÈááÁî®ÂÖâÁîµÊ∑∑ÂêàËÆ°ÁÆóÊ®°ÂºèÔºåÂÖ∂‰∏≠Á°ÖÂÖâÂ≠êMach-ZehnderÂπ≤Ê∂â‰ª™(MZI)ËäØÁâáÊâßË°åÁ∫øÊÄßÁü©ÈòµËÆ°ÁÆóÔºåËÄåÈùûÁ∫øÊÄßËÑâÂÜ≤ÊøÄÊ¥ªÂú®ÁîµÂ≠êÂüü‰∏≠ÊâßË°å„ÄÇÂú®Pendulum-v1ÂíåHalfCheetah-v2Âü∫ÂáÜÊµãËØï‰∏äÁöÑÂÆûÈ™åÈ™åËØÅË°®ÊòéÔºåËØ•Á≥ªÁªüÂÖ∑Â§áËΩØÁ°¨‰ª∂ÂçèÂêåÊé®ÁêÜËÉΩÂäõÔºåÂú®HalfCheetah-v2‰∏äÂÆûÁé∞‰∫Ü5831ÁöÑÊéßÂà∂Á≠ñÁï•Â•ñÂä±ÔºåÊî∂ÊïõÊ≠•Êï∞ÂáèÂ∞ë‰∫Ü23.33%ÔºåÂä®‰ΩúÂÅèÂ∑Æ‰Ωé‰∫é2.2%„ÄÇËØ•Â∑•‰ΩúÈ¶ñÊ¨°Â∞ÜÂèØÁºñÁ®ãMZIÂÖâÂ≠êËÆ°ÁÆóËäØÁâáÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ËøûÁª≠ÊéßÂà∂‰ªªÂä°ÔºåÂÆûÁé∞‰∫Ü1.39 TOPS/WÁöÑËÉΩÊïàÂíå120 psÁöÑË∂Ö‰ΩéËÆ°ÁÆóÂª∂Ëøü„ÄÇËøô‰∫õÊÄßËÉΩÂá∏Êòæ‰∫ÜÂÖâÂ≠êËÑâÂÜ≤Âº∫ÂåñÂ≠¶‰π†Âú®Ëá™‰∏ªÂíåÂ∑•‰∏öÊú∫Âô®‰∫∫Á≥ªÁªüÂÆûÊó∂ÂÜ≥Á≠ñ‰∏≠ÁöÑÊΩúÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú∫Âô®‰∫∫ËøûÁª≠ÊéßÂà∂‰ªªÂä°ÈúÄË¶ÅÈ´òËÉΩÊïàÂíå‰ΩéÂª∂ËøüÁöÑËÆ°ÁÆóÊû∂ÊûÑÔºå‰º†ÁªüÁîµÂ≠êËÆ°ÁÆóÂπ≥Âè∞Èöæ‰ª•Êª°Ë∂≥ÈúÄÊ±ÇÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜÈ´òÁª¥Áä∂ÊÄÅÁ©∫Èó¥ÂíåÂÆûÊó∂‰∫§‰∫íÊó∂„ÄÇÁé∞ÊúâÁöÑÁîµÂ≠êËÆ°ÁÆóÊñπÊ≥ïÂú®ËÆ°ÁÆóËÉΩÂäõÂíåÂäüËÄóÊñπÈù¢Â≠òÂú®Áì∂È¢àÔºåÈôêÂà∂‰∫ÜÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÂ∫îÁî®„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ÂÖâÂ≠êËÆ°ÁÆóÂíåËÑâÂÜ≤Á•ûÁªèÁΩëÁªúÁöÑ‰ºòÂäøÔºåÊûÑÂª∫‰∏ÄÁßçÂÖâÁîµÊ∑∑ÂêàËÆ°ÁÆóÊû∂ÊûÑ„ÄÇÂÖâÂ≠êËÆ°ÁÆóÊìÖÈïøÊâßË°åÁ∫øÊÄßÁü©ÈòµËøêÁÆóÔºåÂÖ∑ÊúâÈ´òÂ∏¶ÂÆΩÂíå‰ΩéÂäüËÄóÁöÑÁâπÁÇπÔºõËÑâÂÜ≤Á•ûÁªèÁΩëÁªúÂÖ∑ÊúâÁîüÁâ©Á•ûÁªèÂÖÉÁöÑÁâπÊÄßÔºåÈÄÇÂêàÂ§ÑÁêÜÊó∂Â∫è‰ø°ÊÅØÂíåÂÆûÁé∞‰ΩéÂäüËÄóËÆ°ÁÆó„ÄÇÈÄöËøáÂ∞Ü‰∏§ËÄÖÁªìÂêàÔºåÂèØ‰ª•ÂÆûÁé∞È´òÊïàÁöÑÊú∫Âô®‰∫∫ÊéßÂà∂Á≠ñÁï•„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÂê´‰∏Ä‰∏™Á°ÖÂÖâÂ≠êMZIËäØÁâáÂíå‰∏Ä‰∏™ÁîµÂ≠êËÆ°ÁÆóÂçïÂÖÉ„ÄÇMZIËäØÁâáË¥üË¥£ÊâßË°åÁ∫øÊÄßÁü©ÈòµËÆ°ÁÆóÔºå‰æãÂ¶ÇÁ•ûÁªèÁΩëÁªú‰∏≠ÁöÑÊùÉÈáçÁü©Èòµ‰πòÊ≥ï„ÄÇÁîµÂ≠êËÆ°ÁÆóÂçïÂÖÉË¥üË¥£ÊâßË°åÈùûÁ∫øÊÄßËÑâÂÜ≤ÊøÄÊ¥ªÂáΩÊï∞Ôºå‰ª•ÂèäÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÁöÑÂÖ∂‰ªñÈÉ®ÂàÜÔºå‰æãÂ¶ÇTD3ÁÆóÊ≥ïÁöÑÁ≠ñÁï•Êõ¥Êñ∞Âíå‰ª∑ÂÄºÂáΩÊï∞‰º∞ËÆ°„ÄÇÊï∞ÊçÆÂú®ÂÖâÂüüÂíåÁîµÂüü‰πãÈó¥ËøõË°åËΩ¨Êç¢ÔºåÂÆûÁé∞Ê∑∑ÂêàËÆ°ÁÆó„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÂèØÁºñÁ®ãMZIÂÖâÂ≠êËÆ°ÁÆóËäØÁâáÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ËøûÁª≠ÊéßÂà∂‰ªªÂä°ÔºåÂπ∂ÁªìÂêàËÑâÂÜ≤Á•ûÁªèÁΩëÁªúÔºåÂÆûÁé∞‰∫ÜÈ´òÊïàÁöÑËΩØÁ°¨‰ª∂ÂçèÂêåÊé®ÁêÜ„ÄÇËøôÊòØÈ¶ñÊ¨°Â∞ÜÂÖâÂ≠êËÆ°ÁÆóÂ∫îÁî®‰∫éÊ≠§Á±ª‰ªªÂä°ÔºåÂπ∂È™åËØÅ‰∫ÜÂÖ∂Âú®ËÉΩÊïàÂíåÂª∂ËøüÊñπÈù¢ÁöÑ‰ºòÂäø„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáÈááÁî®‰∫ÜTwin Delayed Deep Deterministic policy gradient (TD3)ÁÆóÊ≥ï‰Ωú‰∏∫Âº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÔºåÂπ∂Â∞ÜÂÖ∂‰∏éËÑâÂÜ≤Á•ûÁªèÁΩëÁªúÁõ∏ÁªìÂêà„ÄÇMZIËäØÁâáÁöÑËÆæËÆ°ÈúÄË¶ÅËÄÉËôëÊ≥¢Èïø„ÄÅË∞ÉÂà∂Ê∑±Â∫¶ÂíåÊçüËÄóÁ≠âÂõ†Á¥†Ôºå‰ª•ÂÆûÁé∞Á≤æÁ°ÆÁöÑÁ∫øÊÄßÁü©ÈòµËÆ°ÁÆó„ÄÇËÑâÂÜ≤Á•ûÁªèÁΩëÁªúÁöÑÊøÄÊ¥ªÂáΩÊï∞ÂíåÂ≠¶‰π†ËßÑÂàô‰πüÈúÄË¶ÅËøõË°å‰ºòÂåñÔºå‰ª•ÈÄÇÂ∫îÂÖâÂ≠êËÆ°ÁÆóÁöÑÁâπÁÇπ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•Á≥ªÁªüÂú®HalfCheetah-v2Âü∫ÂáÜÊµãËØï‰∏≠ÂÆûÁé∞‰∫Ü5831ÁöÑÊéßÂà∂Á≠ñÁï•Â•ñÂä±ÔºåÊî∂ÊïõÊ≠•Êï∞ÂáèÂ∞ë‰∫Ü23.33%ÔºåÂä®‰ΩúÂÅèÂ∑Æ‰Ωé‰∫é2.2%„ÄÇÊ≠§Â§ñÔºåËØ•Êû∂ÊûÑÂÆûÁé∞‰∫Ü1.39 TOPS/WÁöÑËÉΩÊïàÂíå120 psÁöÑË∂Ö‰ΩéËÆ°ÁÆóÂª∂Ëøü„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåÂÖâÂ≠êËÑâÂÜ≤Âº∫ÂåñÂ≠¶‰π†Âú®Êú∫Âô®‰∫∫ËøûÁª≠ÊéßÂà∂‰ªªÂä°‰∏≠ÂÖ∑ÊúâÊòæËëóÁöÑ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÂÆûÊó∂ÂÜ≥Á≠ñÂíåÈ´òËÉΩÊïàÁöÑÊú∫Âô®‰∫∫Á≥ªÁªüÔºå‰æãÂ¶ÇËá™‰∏ªÂØºËà™„ÄÅÂ∑•‰∏öËá™Âä®Âåñ„ÄÅÂåªÁñóÊú∫Âô®‰∫∫Á≠â„ÄÇÂÖâÂ≠êËÑâÂÜ≤Âº∫ÂåñÂ≠¶‰π†ÊúâÊúõÊé®Âä®Êú∫Âô®‰∫∫Âú®Â§çÊùÇÂíåÂä®ÊÄÅÁéØÂ¢É‰∏≠ÁöÑÂ∫îÁî®ÔºåÂπ∂Èôç‰ΩéÊú∫Âô®‰∫∫ÁöÑÂäüËÄóÔºåÂª∂ÈïøÂÖ∂Â∑•‰ΩúÊó∂Èó¥„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØËøòÂèØËÉΩÊâ©Â±ïÂà∞ÂÖ∂‰ªñ‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÔºå‰æãÂ¶ÇÂõæÂÉèËØÜÂà´ÂíåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Robotic continuous control tasks impose stringent demands on the energy efficiency and latency of computing architectures due to their high-dimensional state spaces and real-time interaction requirements. Conventional electronic computing platforms face computational bottlenecks, whereas the fusion of photonic computing and spiking reinforcement learning (RL) offers a promising alternative. Here, we propose a novel computing architecture based on photonic spiking RL, which integrates the Twin Delayed Deep Deterministic policy gradient (TD3) algorithm with spiking neural network (SNN). The proposed architecture employs an optical-electronic hybrid computing paradigm wherein a silicon photonic Mach-Zehnder interferometer (MZI) chip executes linear matrix computations, while nonlinear spiking activations are performed in the electronic domain. Experimental validation on the Pendulum-v1 and HalfCheetah-v2 benchmarks demonstrates the system capability for software-hardware co-inference, achieving a control policy reward of 5831 on HalfCheetah-v2, a 23.33% reduction in convergence steps, and an action deviation below 2.2%. Notably, this work represents the first application of a programmable MZI photonic computing chip to robotic continuous control tasks, attaining an energy efficiency of 1.39 TOPS/W and an ultralow computational latency of 120 ps. Such performance underscores the promise of photonic spiking RL for real-time decision-making in autonomous and industrial robotic systems.

