---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-06-17
---

# cs.ROï¼ˆ2025-06-17ï¼‰

ğŸ“Š å…± **25** ç¯‡è®ºæ–‡
 | ğŸ”— **7** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (17 ğŸ”—4)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ğŸ”—2)</a>
<a href="#æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction" class="interest-badge">æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (17 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250614278v2-whole-body-control-framework-for-humanoid-robots-with-heavy-limbs-a-.html">Whole-Body Control Framework for Humanoid Robots with Heavy Limbs: A Model-Based Approach</a></td>
  <td>æå‡ºå…¨èº«æ§åˆ¶æ¡†æ¶ä»¥è§£å†³äººå½¢æœºå™¨äººé‡è‚¢ä½“çš„å¹³è¡¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">whole-body control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14278v2" data-paper-url="./papers/250614278v2-whole-body-control-framework-for-humanoid-robots-with-heavy-limbs-a-.html" onclick="toggleFavorite(this, '2506.14278v2', 'Whole-Body Control Framework for Humanoid Robots with Heavy Limbs: A Model-Based Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250614770v2-gmt-general-motion-tracking-for-humanoid-whole-body-control.html">GMT: General Motion Tracking for Humanoid Whole-Body Control</a></td>
  <td>æå‡ºGMTæ¡†æ¶ä»¥è§£å†³ç±»äººæœºå™¨äººè¿åŠ¨è·Ÿè¸ªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">humanoid</span> <span class="paper-tag">humanoid robot</span> <span class="paper-tag">whole-body control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14770v2" data-paper-url="./papers/250614770v2-gmt-general-motion-tracking-for-humanoid-whole-body-control.html" onclick="toggleFavorite(this, '2506.14770v2', 'GMT: General Motion Tracking for Humanoid Whole-Body Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250614135v4-gaf-gaussian-action-field-as-a-4d-representation-for-dynamic-world-m.html">GAF: Gaussian Action Field as a 4D Representation for Dynamic World Modeling in Robotic Manipulation</a></td>
  <td>æå‡ºGAFä»¥è§£å†³åŠ¨æ€åœºæ™¯ä¸‹æœºå™¨äººæ“ä½œçš„å‡†ç¡®æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">world model</span> <span class="paper-tag">3D gaussian splatting</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14135v4" data-paper-url="./papers/250614135v4-gaf-gaussian-action-field-as-a-4d-representation-for-dynamic-world-m.html" onclick="toggleFavorite(this, '2506.14135v4', 'GAF: Gaussian Action Field as a 4D Representation for Dynamic World Modeling in Robotic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250614608v3-latent-action-diffusion-for-cross-embodiment-manipulation.html">Latent Action Diffusion for Cross-Embodiment Manipulation</a></td>
  <td>æå‡ºæ½œåœ¨åŠ¨ä½œæ‰©æ•£æ–¹æ³•ä»¥è§£å†³è·¨å½¢æ€æ“æ§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">diffusion policy</span> <span class="paper-tag">cross-embodiment</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14608v3" data-paper-url="./papers/250614608v3-latent-action-diffusion-for-cross-embodiment-manipulation.html" onclick="toggleFavorite(this, '2506.14608v3', 'Latent Action Diffusion for Cross-Embodiment Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250614317v3-clutterdexgrasp-a-sim-to-real-system-for-general-dexterous-grasping-.html">ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes</a></td>
  <td>æå‡ºClutterDexGraspä»¥è§£å†³å¤æ‚åœºæ™¯ä¸­çš„çµå·§æŠ“å–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span> <span class="paper-tag">imitation learning</span> <span class="paper-tag">diffusion policy</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14317v3" data-paper-url="./papers/250614317v3-clutterdexgrasp-a-sim-to-real-system-for-general-dexterous-grasping-.html" onclick="toggleFavorite(this, '2506.14317v3', 'ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250615009v2-six-dof-hand-based-teleoperation-for-omnidirectional-aerial-robots.html">Six-DoF Hand-Based Teleoperation for Omnidirectional Aerial Robots</a></td>
  <td>æå‡ºåŸºäºå…­è‡ªç”±åº¦æ‰‹åŠ¨é¥æ§çš„å…¨å‘æ— äººæœºæ“ä½œç³»ç»Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">teleoperation</span> <span class="paper-tag">motion tracking</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.15009v2" data-paper-url="./papers/250615009v2-six-dof-hand-based-teleoperation-for-omnidirectional-aerial-robots.html" onclick="toggleFavorite(this, '2506.15009v2', 'Six-DoF Hand-Based Teleoperation for Omnidirectional Aerial Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250614727v2-casper-inferring-diverse-intents-for-assistive-teleoperation-with-vi.html">Casper: Inferring Diverse Intents for Assistive Teleoperation with Vision Language Models</a></td>
  <td>æå‡ºCasperä»¥è§£å†³åŠ©ç†é¥æ“ä½œä¸­çš„æ„å›¾æ¨æ–­é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">mobile manipulation</span> <span class="paper-tag">teleoperation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14727v2" data-paper-url="./papers/250614727v2-casper-inferring-diverse-intents-for-assistive-teleoperation-with-vi.html" onclick="toggleFavorite(this, '2506.14727v2', 'Casper: Inferring Diverse Intents for Assistive Teleoperation with Vision Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250614855v3-feedback-mppi-fast-sampling-based-mpc-via-rollout-differentiation-ad.html">Feedback-MPPI: Fast Sampling-Based MPC via Rollout Differentiation -- Adios low-level controllers</a></td>
  <td>æå‡ºFeedback-MPPIä»¥è§£å†³é«˜é¢‘æœºå™¨äººæ§åˆ¶ä¸­çš„è®¡ç®—ç“¶é¢ˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">quadruped</span> <span class="paper-tag">locomotion</span> <span class="paper-tag">MPC</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14855v3" data-paper-url="./papers/250614855v3-feedback-mppi-fast-sampling-based-mpc-via-rollout-differentiation-ad.html" onclick="toggleFavorite(this, '2506.14855v3', 'Feedback-MPPI: Fast Sampling-Based MPC via Rollout Differentiation -- Adios low-level controllers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250614754v1-tactile-beyond-pixels-multisensory-touch-representations-for-robot-m.html">Tactile Beyond Pixels: Multisensory Touch Representations for Robot Manipulation</a></td>
  <td>æå‡ºSparsh-Xä»¥è§£å†³æœºå™¨äººè§¦è§‰æ„ŸçŸ¥ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">dexterous manipulation</span> <span class="paper-tag">imitation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14754v1" data-paper-url="./papers/250614754v1-tactile-beyond-pixels-multisensory-touch-representations-for-robot-m.html" onclick="toggleFavorite(this, '2506.14754v1', 'Tactile Beyond Pixels: Multisensory Touch Representations for Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250614865v1-efficient-and-real-time-motion-planning-for-robotics-using-projectio.html">Efficient and Real-Time Motion Planning for Robotics Using Projection-Based Optimization</a></td>
  <td>æå‡ºALSPGæ–¹æ³•ä»¥è§£å†³æœºå™¨äººè¿åŠ¨è§„åˆ’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">motion planning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14865v1" data-paper-url="./papers/250614865v1-efficient-and-real-time-motion-planning-for-robotics-using-projectio.html" onclick="toggleFavorite(this, '2506.14865v1', 'Efficient and Real-Time Motion Planning for Robotics Using Projection-Based Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250614648v1-senior-efficient-query-selection-and-preference-guided-exploration-i.html">SENIOR: Efficient Query Selection and Preference-Guided Exploration in Preference-based Reinforcement Learning</a></td>
  <td>æå‡ºSENIORä»¥è§£å†³åå¥½å¼ºåŒ–å­¦ä¹ ä¸­çš„åé¦ˆæ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">reinforcement learning</span> <span class="paper-tag">policy learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14648v1" data-paper-url="./papers/250614648v1-senior-efficient-query-selection-and-preference-guided-exploration-i.html" onclick="toggleFavorite(this, '2506.14648v1', 'SENIOR: Efficient Query Selection and Preference-Guided Exploration in Preference-based Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250614341v1-barrier-method-for-inequality-constrained-factor-graph-optimization-.html">Barrier Method for Inequality Constrained Factor Graph Optimization with Application to Model Predictive Control</a></td>
  <td>æå‡ºéšœç¢æ³•ä»¥è§£å†³ä¸ç­‰å¼çº¦æŸçš„å› å­å›¾ä¼˜åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">MPC</span> <span class="paper-tag">model predictive control</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14341v1" data-paper-url="./papers/250614341v1-barrier-method-for-inequality-constrained-factor-graph-optimization-.html" onclick="toggleFavorite(this, '2506.14341v1', 'Barrier Method for Inequality Constrained Factor Graph Optimization with Application to Model Predictive Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250614763v1-robotsmith-generative-robotic-tool-design-for-acquisition-of-complex.html">RobotSmith: Generative Robotic Tool Design for Acquisition of Complex Manipulation Skills</a></td>
  <td>æå‡ºRobotSmithä»¥è§£å†³å¤æ‚æ“ä½œæŠ€èƒ½çš„å·¥å…·è®¾è®¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14763v1" data-paper-url="./papers/250614763v1-robotsmith-generative-robotic-tool-design-for-acquisition-of-complex.html" onclick="toggleFavorite(this, '2506.14763v1', 'RobotSmith: Generative Robotic Tool Design for Acquisition of Complex Manipulation Skills')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250614513v1-gamora-a-gesture-articulated-meta-operative-robotic-arm-for-hazardou.html">GAMORA: A Gesture Articulated Meta Operative Robotic Arm for Hazardous Material Handling in Containment-Level Environments</a></td>
  <td>æå‡ºGAMORAä»¥è§£å†³é«˜é£é™©å®éªŒå®¤ä¸­å±é™©ææ–™å¤„ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">motion planning</span> <span class="paper-tag">teleoperation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14513v1" data-paper-url="./papers/250614513v1-gamora-a-gesture-articulated-meta-operative-robotic-arm-for-hazardou.html" onclick="toggleFavorite(this, '2506.14513v1', 'GAMORA: A Gesture Articulated Meta Operative Robotic Arm for Hazardous Material Handling in Containment-Level Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250614305v1-socially-aware-robot-crowd-navigation-via-online-uncertainty-driven-.html">Socially Aware Robot Crowd Navigation via Online Uncertainty-Driven Risk Adaptation</a></td>
  <td>æå‡ºLR-MPCä»¥è§£å†³äººæœºå…±äº«æ‹¥æŒ¤ç¯å¢ƒä¸­çš„å¯¼èˆªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">MPC</span> <span class="paper-tag">model predictive control</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14305v1" data-paper-url="./papers/250614305v1-socially-aware-robot-crowd-navigation-via-online-uncertainty-driven-.html" onclick="toggleFavorite(this, '2506.14305v1', 'Socially Aware Robot Crowd Navigation via Online Uncertainty-Driven Risk Adaptation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250614487v2-ros2-fanuc-interface-design-and-evaluation-of-a-fanuc-crx-hardware-i.html">ros2 fanuc interface: Design and Evaluation of a Fanuc CRX Hardware Interface in ROS2</a></td>
  <td>æå‡ºROS2æ§åˆ¶ä¸Fanuc CRXæœºå™¨äººç¡¬ä»¶æ¥å£çš„é›†æˆæ–¹æ¡ˆ</td>
  <td class="tags-cell"><span class="paper-tag">motion planning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14487v2" data-paper-url="./papers/250614487v2-ros2-fanuc-interface-design-and-evaluation-of-a-fanuc-crx-hardware-i.html" onclick="toggleFavorite(this, '2506.14487v2', 'ros2 fanuc interface: Design and Evaluation of a Fanuc CRX Hardware Interface in ROS2')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250614186v1-hard-contacts-with-soft-gradients-refining-differentiable-simulators.html">Hard Contacts with Soft Gradients: Refining Differentiable Simulators for Learning and Control</a></td>
  <td>æå‡ºDiffMJXä¸CFDä»¥è§£å†³æœºå™¨äººåŠ¨æ€ä¼˜åŒ–ä¸­çš„æ¥è§¦åŠ›é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">sim-to-real</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14186v1" data-paper-url="./papers/250614186v1-hard-contacts-with-soft-gradients-refining-differentiable-simulators.html" onclick="toggleFavorite(this, '2506.14186v1', 'Hard Contacts with Soft Gradients: Refining Differentiable Simulators for Learning and Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>18</td>
  <td><a href="./papers/250614178v2-tacs-graphs-traversability-aware-consistent-scene-graphs-for-ground-.html">TACS-Graphs: Traversability-Aware Consistent Scene Graphs for Ground Robot Localization and Mapping</a></td>
  <td>æå‡ºTACS-Graphsä»¥è§£å†³å®¤å†…åœºæ™¯å›¾åˆ†å‰²ä¸ä¸€è‡´é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">traversability</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14178v2" data-paper-url="./papers/250614178v2-tacs-graphs-traversability-aware-consistent-scene-graphs-for-ground-.html" onclick="toggleFavorite(this, '2506.14178v2', 'TACS-Graphs: Traversability-Aware Consistent Scene Graphs for Ground Robot Localization and Mapping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250614975v2-time-optimized-safe-navigation-in-unstructured-environments-through-.html">Time-Optimized Safe Navigation in Unstructured Environments through Learning Based Depth Completion</a></td>
  <td>æå‡ºåŸºäºå­¦ä¹ çš„æ·±åº¦è¡¥å…¨æ–¹æ³•ä»¥è§£å†³æ— äººæœºåœ¨å¤æ‚ç¯å¢ƒä¸­çš„å®‰å…¨å¯¼èˆªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">depth estimation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14975v2" data-paper-url="./papers/250614975v2-time-optimized-safe-navigation-in-unstructured-environments-through-.html" onclick="toggleFavorite(this, '2506.14975v2', 'Time-Optimized Safe Navigation in Unstructured Environments through Learning Based Depth Completion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250614422v1-enhancing-object-search-in-indoor-spaces-via-personalized-object-fac.html">Enhancing Object Search in Indoor Spaces via Personalized Object-factored Ontologies</a></td>
  <td>æå‡ºä¸ªæ€§åŒ–å¯¹è±¡å› å­æœ¬ä½“ä»¥æå‡å®¤å†…ç©ºé—´ç‰©ä½“æœç´¢èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">semantic map</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14422v1" data-paper-url="./papers/250614422v1-enhancing-object-search-in-indoor-spaces-via-personalized-object-fac.html" onclick="toggleFavorite(this, '2506.14422v1', 'Enhancing Object Search in Indoor Spaces via Personalized Object-factored Ontologies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>21</td>
  <td><a href="./papers/250614507v1-can-pretrained-vision-language-embeddings-alone-guide-robot-navigati.html">Can Pretrained Vision-Language Embeddings Alone Guide Robot Navigation?</a></td>
  <td>æå‡ºä¸€ç§æœ€ç®€æ¡†æ¶ä»¥è¯„ä¼°é¢„è®­ç»ƒè§†è§‰-è¯­è¨€åµŒå…¥åœ¨æœºå™¨äººå¯¼èˆªä¸­çš„æœ‰æ•ˆæ€§</td>
  <td class="tags-cell"><span class="paper-tag">behavior cloning</span> <span class="paper-tag">foundation model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14507v1" data-paper-url="./papers/250614507v1-can-pretrained-vision-language-embeddings-alone-guide-robot-navigati.html" onclick="toggleFavorite(this, '2506.14507v1', 'Can Pretrained Vision-Language Embeddings Alone Guide Robot Navigation?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250614198v1-amplify-actionless-motion-priors-for-robot-learning-from-videos.html">AMPLIFY: Actionless Motion Priors for Robot Learning from Videos</a></td>
  <td>æå‡ºAMPLIFYæ¡†æ¶ä»¥è§£å†³æœºå™¨äººå­¦ä¹ ä¸­çš„æ•°æ®ç¨€ç¼ºé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">policy learning</span> <span class="paper-tag">world model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14198v1" data-paper-url="./papers/250614198v1-amplify-actionless-motion-priors-for-robot-learning-from-videos.html" onclick="toggleFavorite(this, '2506.14198v1', 'AMPLIFY: Actionless Motion Priors for Robot Learning from Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…­è§†é¢‘æå–ä¸åŒ¹é…-video-extraction">ğŸ”¬ æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>23</td>
  <td><a href="./papers/250614180v2-non-overlap-aware-egocentric-pose-estimation-for-collaborative-perce.html">Non-Overlap-Aware Egocentric Pose Estimation for Collaborative Perception in Connected Autonomy</a></td>
  <td>æå‡ºéé‡å æ„ŸçŸ¥çš„è‡ªæˆ‘å§¿æ€ä¼°è®¡æ–¹æ³•ä»¥è§£å†³å¤šæœºå™¨äººåä½œé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">egocentric</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14180v2" data-paper-url="./papers/250614180v2-non-overlap-aware-egocentric-pose-estimation-for-collaborative-perce.html" onclick="toggleFavorite(this, '2506.14180v2', 'Non-Overlap-Aware Egocentric Pose Estimation for Collaborative Perception in Connected Autonomy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>24</td>
  <td><a href="./papers/250614968v2-feast-a-flexible-mealtime-assistance-system-towards-in-the-wild-pers.html">FEAST: A Flexible Mealtime-Assistance System Towards In-the-Wild Personalization</a></td>
  <td>æå‡ºFEASTç³»ç»Ÿä»¥è§£å†³ä¸ªæ€§åŒ–é¤é¥®è¾…åŠ©é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14968v2" data-paper-url="./papers/250614968v2-feast-a-flexible-mealtime-assistance-system-towards-in-the-wild-pers.html" onclick="toggleFavorite(this, '2506.14968v2', 'FEAST: A Flexible Mealtime-Assistance System Towards In-the-Wild Personalization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>25</td>
  <td><a href="./papers/250614405v1-data-driven-approach-to-input-shaping-for-vibration-suppression-in-a.html">Data Driven Approach to Input Shaping for Vibration Suppression in a Flexible Robot Arm</a></td>
  <td>æå‡ºæ•°æ®é©±åŠ¨æ–¹æ³•ä»¥æŠ‘åˆ¶æŸ”æ€§æœºå™¨äººè‡‚çš„æ®‹ä½™æŒ¯åŠ¨</td>
  <td class="tags-cell"><span class="paper-tag">PULSE</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14405v1" data-paper-url="./papers/250614405v1-data-driven-approach-to-input-shaping-for-vibration-suppression-in-a.html" onclick="toggleFavorite(this, '2506.14405v1', 'Data Driven Approach to Input Shaping for Vibration Suppression in a Flexible Robot Arm')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)