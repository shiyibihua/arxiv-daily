---
layout: default
title: AMPLIFY: Actionless Motion Priors for Robot Learning from Videos
---

# AMPLIFY: Actionless Motion Priors for Robot Learning from Videos

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.14198" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.14198v1</a>
  <a href="https://arxiv.org/pdf/2506.14198.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.14198v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.14198v1', 'AMPLIFY: Actionless Motion Priors for Robot Learning from Videos')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Jeremy A. Collins, Lor√°nd Cheng, Kunal Aneja, Albert Wilcox, Benjamin Joffe, Animesh Garg

**ÂàÜÁ±ª**: cs.RO, cs.CV, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-17

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://amplify-robotics.github.io/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫AMPLIFYÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥Êú∫Âô®‰∫∫Â≠¶‰π†‰∏≠ÁöÑÊï∞ÊçÆÁ®ÄÁº∫ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Êú∫Âô®‰∫∫Â≠¶‰π†` `Êó†Âä®‰ΩúËßÜÈ¢ë` `Âä®ÊÄÅÊ®°Âûã` `ËøêÂä®È¢ÑÊµã` `Á≠ñÁï•Â≠¶‰π†` `ËßÜÈ¢ëÁêÜËß£` `Êï∞ÊçÆÁ®ÄÁº∫` `Ê®°ÂùóÂåñËÆæËÆ°`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊú∫Âô®‰∫∫Â≠¶‰π†ÊñπÊ≥ï‰æùËµñ‰∫éÁ®ÄÁº∫ÁöÑÊ†áÊ≥®Âä®‰ΩúÊï∞ÊçÆÔºåÂØºËá¥Ê≥õÂåñËÉΩÂäõ‰∏çË∂≥„ÄÇ
2. AMPLIFYÊ°ÜÊû∂ÈÄöËøá‰ªéÊó†Âä®‰ΩúËßÜÈ¢ë‰∏≠ÊèêÂèñËøêÂä®Ê†áËÆ∞ÔºåËß£ËÄ¶ËßÜËßâËøêÂä®È¢ÑÊµã‰∏éÂä®‰ΩúÊé®Êñ≠„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÊâÄÂ≠¶Âä®ÊÄÅÊ®°ÂûãÂú®‰ΩéÊï∞ÊçÆÁéØÂ¢É‰∏ãÊèêÂçá1.2-2.2ÂÄçÔºå‰∏îÂú®ËßÜÈ¢ëÈ¢ÑÊµãË¥®Èáè‰∏äË°®Áé∞‰ºòÂºÇ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú∫Âô®‰∫∫È¢ÜÂüü‰∏≠ÔºåÊ†áÊ≥®Âä®‰ΩúÁöÑÊï∞ÊçÆÁ®ÄÁº∫‰∏îÊàêÊú¨È´òÊòÇÔºåÈôêÂà∂‰∫ÜÂ≠¶‰π†Á≠ñÁï•ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÂ§ßÈáèÊó†Âä®‰ΩúÁöÑËßÜÈ¢ëÊï∞ÊçÆÊòì‰∫éËé∑ÂèñÔºå‰ΩÜÂ∞ÜËøô‰∫õËßÇÂØüËΩ¨Âåñ‰∏∫ÊúâÊïàÁ≠ñÁï•‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊàòÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫AMPLIFYÔºå‰∏Ä‰∏™Êñ∞È¢ñÁöÑÊ°ÜÊû∂ÔºåÈÄöËøáÂ∞ÜËßÜËßâÂä®ÊÄÅÁºñÁ†Å‰∏∫‰ªéÂÖ≥ÈîÆÁÇπËΩ®Ëøπ‰∏≠ÊèêÂèñÁöÑÁ¥ßÂáëÁ¶ªÊï£ËøêÂä®Ê†áËÆ∞ÔºåÂà©Áî®Â§ßËßÑÊ®°ËßÜÈ¢ëÊï∞ÊçÆ„ÄÇËØ•Ê®°ÂùóÂåñÊñπÊ≥ïÂ∞ÜËßÜËßâËøêÂä®È¢ÑÊµã‰∏éÂä®‰ΩúÊé®Êñ≠ÂàÜÁ¶ªÔºå‰ΩøÂæóÂ≠¶‰π†‰ªªÂä°ÂÆö‰πâÁöÑËøêÂä®‰∏éÊú∫Âô®‰∫∫Â¶Ç‰ΩïÊâßË°åËøô‰∫õËøêÂä®ÁöÑÊåëÊàòÂæó‰ª•Ëß£ËÄ¶„ÄÇÈÄöËøáÂú®‰∏∞ÂØåÁöÑÊó†Âä®‰ΩúËßÜÈ¢ë‰∏äËÆ≠ÁªÉÂâçÂêëÂä®ÊÄÅÊ®°ÂûãÔºåÂπ∂Âú®ÊúâÈôêÁöÑÊ†áÊ≥®Âä®‰ΩúÁ§∫‰æã‰∏äËÆ≠ÁªÉÈÄÜÂêëÂä®ÊÄÅÊ®°ÂûãÔºåÂÆûÁé∞‰∫ÜÁã¨Á´ãÊâ©Â±ï„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÂ≠¶Âä®ÊÄÅÊ®°ÂûãÂáÜÁ°ÆÊÄßÊòæËëóÊèêÂçáÔºå‰∏îÂú®‰∏ãÊ∏∏Á≠ñÁï•Â≠¶‰π†‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Êú∫Âô®‰∫∫Â≠¶‰π†‰∏≠Ê†áÊ≥®Âä®‰ΩúÊï∞ÊçÆÁ®ÄÁº∫ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰æùËµñ‰∫éÊòÇË¥µÁöÑÊ†áÊ≥®Êï∞ÊçÆÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÂíåÂ∫îÁî®ËåÉÂõ¥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫AMPLIFYÊ°ÜÊû∂ÔºåÈÄöËøá‰ªéÊó†Âä®‰ΩúËßÜÈ¢ë‰∏≠ÊèêÂèñËøêÂä®Âä®ÊÄÅÔºåÂà©Áî®Á¶ªÊï£ËøêÂä®Ê†áËÆ∞Êù•ËøõË°åÂ≠¶‰π†„ÄÇËøôÁßçËÆæËÆ°‰ΩøÂæóËßÜËßâËøêÂä®È¢ÑÊµã‰∏éÂä®‰ΩúÊé®Êñ≠Âæó‰ª•ÂàÜÁ¶ªÔºå‰ªéËÄåÁÆÄÂåñ‰∫ÜÂ≠¶‰π†ËøáÁ®ã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAMPLIFYÊ°ÜÊû∂ÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂâçÂêëÂä®ÊÄÅÊ®°ÂûãÂíåÈÄÜÂêëÂä®ÊÄÅÊ®°Âûã„ÄÇÂâçËÄÖÂú®Â§ßÈáèÊó†Âä®‰ΩúËßÜÈ¢ë‰∏äËÆ≠ÁªÉÔºåÂêéËÄÖÂàôÂú®ÊúâÈôêÁöÑÊ†áÊ≥®Êï∞ÊçÆ‰∏äËøõË°åËÆ≠ÁªÉ„ÄÇËøôÊ†∑ÁöÑËÆæËÆ°ÂÖÅËÆ∏Ê®°ÂûãÂú®‰∏çÂêåÊï∞ÊçÆÈõÜ‰∏äÁã¨Á´ãÊâ©Â±ï„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÂ∞ÜËßÜËßâÂä®ÊÄÅÁºñÁ†Å‰∏∫Á¶ªÊï£ËøêÂä®Ê†áËÆ∞ÔºåÂπ∂ÈÄöËøáÊ®°ÂùóÂåñËÆæËÆ°Ëß£ËÄ¶‰∫ÜËøêÂä®È¢ÑÊµã‰∏éÂä®‰ΩúÊé®Êñ≠„ÄÇËøô‰∏ÄÊñπÊ≥ïÊòæËëóÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÂ≠¶‰π†ÊïàÁéáÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆ≠ÁªÉ‰∏≠ÔºåÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞Êù•‰ºòÂåñÂä®ÊÄÅÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄßÔºåÂπ∂ËÆæËÆ°‰∫ÜÈÄÇÂ∫îÊÄßÂº∫ÁöÑÁΩëÁªúÁªìÊûÑÔºå‰ª•Â§ÑÁêÜ‰∏çÂêåÊù•Ê∫êÁöÑÊï∞ÊçÆ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAMPLIFYÂú®Âä®ÊÄÅÈ¢ÑÊµãÊñπÈù¢ÁöÑÂùáÊñπËØØÂ∑ÆÔºàMSEÔºâÊØîÁé∞ÊúâÊñπÊ≥ïÊèêÈ´ò‰∫Ü3.7ÂÄçÔºåÂÉèÁ¥†È¢ÑÊµãÂáÜÁ°ÆÊÄßÊèêÂçáË∂ÖËøá2.5ÂÄç„ÄÇÂú®‰ΩéÊï∞ÊçÆÁéØÂ¢É‰∏ãÔºåÁ≠ñÁï•Â≠¶‰π†ÁöÑÊÄßËÉΩÊèêÂçá‰∫Ü1.2-2.2ÂÄçÔºå‰∏îÈ¶ñÊ¨°ÂÆûÁé∞‰∫ÜÂú®Êó†Ê†áÊ≥®Âä®‰ΩúÊï∞ÊçÆ‰∏ãÂØπLIBERO‰ªªÂä°ÁöÑÊ≥õÂåñ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

AMPLIFYÊ°ÜÊû∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÁâπÂà´ÊòØÂú®Êú∫Âô®‰∫∫ÊéßÂà∂„ÄÅËßÜÈ¢ëÁêÜËß£ÂíåËá™Âä®Âåñ‰ªªÂä°‰∏≠„ÄÇÈÄöËøáÊúâÊïàÂà©Áî®Êó†Âä®‰ΩúËßÜÈ¢ëÊï∞ÊçÆÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÈôç‰ΩéÊï∞ÊçÆÊ†áÊ≥®ÊàêÊú¨ÔºåÂπ∂ÊèêÂçáÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÈÄÇÂ∫îËÉΩÂäõ„ÄÇÊú™Êù•ÔºåËØ•Ê°ÜÊû∂ÂèØËÉΩÊé®Âä®Êõ¥Â§öÈ¢ÜÂüüÁöÑÊô∫ËÉΩÁ≥ªÁªüÂèëÂ±ïÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÂø´ÈÄüÂ≠¶‰π†ÂíåÈÄÇÂ∫îÁöÑÂú∫ÊôØ‰∏≠„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Action-labeled data for robotics is scarce and expensive, limiting the generalization of learned policies. In contrast, vast amounts of action-free video data are readily available, but translating these observations into effective policies remains a challenge. We introduce AMPLIFY, a novel framework that leverages large-scale video data by encoding visual dynamics into compact, discrete motion tokens derived from keypoint trajectories. Our modular approach separates visual motion prediction from action inference, decoupling the challenges of learning what motion defines a task from how robots can perform it. We train a forward dynamics model on abundant action-free videos and an inverse dynamics model on a limited set of action-labeled examples, allowing for independent scaling. Extensive evaluations demonstrate that the learned dynamics are both accurate, achieving up to 3.7x better MSE and over 2.5x better pixel prediction accuracy compared to prior approaches, and broadly useful. In downstream policy learning, our dynamics predictions enable a 1.2-2.2x improvement in low-data regimes, a 1.4x average improvement by learning from action-free human videos, and the first generalization to LIBERO tasks from zero in-distribution action data. Beyond robotic control, we find the dynamics learned by AMPLIFY to be a versatile latent world model, enhancing video prediction quality. Our results present a novel paradigm leveraging heterogeneous data sources to build efficient, generalizable world models. More information can be found at https://amplify-robotics.github.io/.

