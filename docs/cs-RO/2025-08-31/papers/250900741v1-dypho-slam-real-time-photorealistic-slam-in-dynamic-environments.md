---
layout: default
title: DyPho-SLAM : Real-time Photorealistic SLAM in Dynamic Environments
---

# DyPho-SLAM : Real-time Photorealistic SLAM in Dynamic Environments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00741" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00741v1</a>
  <a href="https://arxiv.org/pdf/2509.00741.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00741v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00741v1', 'DyPho-SLAM : Real-time Photorealistic SLAM in Dynamic Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yi Liu, Keyu Fan, Bin Lan, Houde Liu

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-31

**å¤‡æ³¨**: Accepted by ICME 2025(Oral)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDyPho-SLAMä»¥è§£å†³åŠ¨æ€ç¯å¢ƒä¸­çš„å®æ—¶è§†è§‰SLAMé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è§†è§‰SLAM` `åŠ¨æ€ç¯å¢ƒ` `é«˜ä¿çœŸæ˜ å°„` `ç›¸æœºä½å§¿ä¼°è®¡` `è‡ªé€‚åº”ç‰¹å¾æå–` `å®æ—¶å¤„ç†` `ç¨ å¯†åœ°å›¾`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰SLAMæ–¹æ³•åœ¨é™æ€ç¯å¢ƒä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨åŠ¨æ€ç¯å¢ƒä¸­å®¹æ˜“å‡ºç°ç›¸æœºè·Ÿè¸ªæ¼‚ç§»å’Œæ¨¡ç³Šæ˜ å°„çš„é—®é¢˜ã€‚
2. DyPho-SLAMé€šè¿‡æ•´åˆå…ˆå‰å›¾åƒä¿¡æ¯ç”Ÿæˆç²¾ç»†æ©æ¨¡ï¼Œå‡å°‘åŠ¨æ€ç‰©ä½“å¯¹æ˜ å°„çš„å¹²æ‰°ï¼Œå¹¶é‡‡ç”¨è‡ªé€‚åº”ç‰¹å¾æå–ç­–ç•¥æå‡ç³»ç»Ÿçš„é²æ£’æ€§ã€‚
3. åœ¨å…¬å¼€çš„åŠ¨æ€RGB-Dæ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒDyPho-SLAMåœ¨ç›¸æœºä½å§¿ä¼°è®¡å’Œç¨ å¯†åœ°å›¾é‡å»ºæ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”èƒ½å¤Ÿå®æ—¶è¿è¡Œã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰SLAMç®—æ³•åœ¨é«˜ä¿çœŸç¨ å¯†åœ°å›¾ç”Ÿæˆæ–¹é¢å¾—åˆ°äº†å¢å¼ºï¼Œä½†åœ¨åŠ¨æ€ç¯å¢ƒä¸­ï¼Œç°æœ‰æ–¹æ³•å¸¸å¸¸é¢ä¸´ç›¸æœºè·Ÿè¸ªæ¼‚ç§»å’Œæ¨¡ç³Šæ˜ å°„çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†DyPho-SLAMï¼Œè¿™æ˜¯ä¸€ç§å®æ—¶ã€èµ„æºé«˜æ•ˆçš„è§†è§‰SLAMç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³åŠ¨æ€ç‰©ä½“ç¯å¢ƒä¸­çš„å®šä½å’Œé«˜ä¿çœŸæ˜ å°„æŒ‘æˆ˜ã€‚è¯¥ç³»ç»Ÿé€šè¿‡æ•´åˆå…ˆå‰å›¾åƒä¿¡æ¯ç”Ÿæˆç²¾ç»†æ©æ¨¡ï¼Œæœ‰æ•ˆå‡å°‘æ©æ¨¡è¯¯åˆ¤å¸¦æ¥çš„å™ªå£°ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†è‡ªé€‚åº”ç‰¹å¾æå–ç­–ç•¥ï¼Œä»¥å¢å¼ºå»é™¤åŠ¨æ€éšœç¢ç‰©åçš„ä¼˜åŒ–çº¦æŸã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨åŠ¨æ€åœºæ™¯ä¸­å®ç°äº†ç›¸æœºä½å§¿ä¼°è®¡å’Œç¨ å¯†åœ°å›¾é‡å»ºçš„æœ€å…ˆè¿›æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŠ¨æ€ç¯å¢ƒä¸­è§†è§‰SLAMç³»ç»Ÿçš„å®šä½å’Œé«˜ä¿çœŸæ˜ å°„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†åŠ¨æ€ç‰©ä½“æ—¶ï¼Œå¸¸å¸¸å‡ºç°ç›¸æœºè·Ÿè¸ªæ¼‚ç§»å’Œæ¨¡ç³Šæ˜ å°„ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDyPho-SLAMé€šè¿‡æ•´åˆå…ˆå‰å›¾åƒä¿¡æ¯ç”Ÿæˆç²¾ç»†æ©æ¨¡ï¼Œä»è€Œæœ‰æ•ˆå‡å°‘åŠ¨æ€ç‰©ä½“å¯¹æ˜ å°„çš„å¹²æ‰°ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨è‡ªé€‚åº”ç‰¹å¾æå–ç­–ç•¥æ¥å¢å¼ºä¼˜åŒ–çº¦æŸï¼Œæé«˜ç³»ç»Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDyPho-SLAMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å›¾åƒä¿¡æ¯æ•´åˆæ¨¡å—ã€æ©æ¨¡ç”Ÿæˆæ¨¡å—å’Œè‡ªé€‚åº”ç‰¹å¾æå–æ¨¡å—ã€‚ç³»ç»Ÿé€šè¿‡å®æ—¶å¤„ç†è¾“å…¥å›¾åƒï¼Œç”Ÿæˆé«˜ä¿çœŸç¨ å¯†åœ°å›¾ï¼Œå¹¶è¿›è¡Œç›¸æœºä½å§¿ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šDyPho-SLAMçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æ©æ¨¡ç”Ÿæˆç­–ç•¥å’Œè‡ªé€‚åº”ç‰¹å¾æå–æ–¹æ³•ã€‚è¿™äº›åˆ›æ–°ä½¿å¾—ç³»ç»Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘å™ªå£°ï¼Œæé«˜æ˜ å°„ç²¾åº¦ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œç³»ç»Ÿé‡‡ç”¨äº†ä¼˜åŒ–çš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡æ©æ¨¡ç”Ÿæˆå’Œç‰¹å¾æå–çš„æ•ˆæœï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”åŠ¨æ€åœºæ™¯çš„ç‰¹å¾æå–éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DyPho-SLAMåœ¨å…¬å¼€çš„åŠ¨æ€RGB-Dæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œç›¸æœºä½å§¿ä¼°è®¡å’Œç¨ å¯†åœ°å›¾é‡å»ºçš„æ€§èƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ï¼Œå…·ä½“æå‡å¹…åº¦è¶…è¿‡äº†ç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨åŠ¨æ€åœºæ™¯ä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DyPho-SLAMåœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„é«˜æ•ˆå®šä½å’Œæ˜ å°„èƒ½åŠ›ä½¿å…¶åœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œå¢å¼ºç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚è¯¥ç³»ç»Ÿçš„å®æ—¶æ€§èƒ½å’Œé«˜ä¿çœŸæ˜ å°„èƒ½åŠ›å°†æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥å’Œåº”ç”¨è½åœ°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual SLAM algorithms have been enhanced through the exploration of Gaussian Splatting representations, particularly in generating high-fidelity dense maps. While existing methods perform reliably in static environments, they often encounter camera tracking drift and fuzzy mapping when dealing with the disturbances caused by moving objects. This paper presents DyPho-SLAM, a real-time, resource-efficient visual SLAM system designed to address the challenges of localization and photorealistic mapping in environments with dynamic objects. Specifically, the proposed system integrates prior image information to generate refined masks, effectively minimizing noise from mask misjudgment. Additionally, to enhance constraints for optimization after removing dynamic obstacles, we devise adaptive feature extraction strategies significantly improving the system's resilience. Experiments conducted on publicly dynamic RGB-D datasets demonstrate that the proposed system achieves state-of-the-art performance in camera pose estimation and dense map reconstruction, while operating in real-time in dynamic scenes.

