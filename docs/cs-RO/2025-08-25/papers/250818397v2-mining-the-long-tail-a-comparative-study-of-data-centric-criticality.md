---
layout: default
title: Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning
---

# Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18397" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18397v2</a>
  <a href="https://arxiv.org/pdf/2508.18397.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18397v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18397v2', 'Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Antonio Guillen-Perez

**åˆ†ç±»**: cs.RO, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25 (æ›´æ–°: 2025-09-16)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ•°æ®é©±åŠ¨çš„å…³é”®æ€§åŠ æƒç­–ç•¥ä»¥è§£å†³ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„æ•°æ®ä¸å¹³è¡¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç¦»çº¿å¼ºåŒ–å­¦ä¹ ` `è‡ªä¸»é©¾é©¶` `æ•°æ®ä¸å¹³è¡¡` `å…³é”®æ€§åŠ æƒ` `æ¨¡å‹ä¸ç¡®å®šæ€§` `å®‰å…¨æ€§æå‡` `é•¿å°¾äº‹ä»¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†çœŸå®ä¸–ç•Œé©¾é©¶æ—¥å¿—æ—¶é¢ä¸´æ•°æ®ä¸å¹³è¡¡é—®é¢˜ï¼Œå¯¼è‡´å­¦ä¹ åˆ°çš„ç­–ç•¥ä¸å¤Ÿå®‰å…¨å’Œå¯é ã€‚
2. æœ¬æ–‡æå‡ºäº†å…­ç§å…³é”®æ€§åŠ æƒç­–ç•¥ï¼Œåˆ†ä¸ºå¯å‘å¼ã€åŸºäºä¸ç¡®å®šæ€§å’ŒåŸºäºè¡Œä¸ºä¸‰ç±»ï¼Œä»¥å¢å¼ºå­¦ä¹ è¿‡ç¨‹ä¸­çš„ä¿¡æ¯è·å–ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æœ‰æå‡ºçš„æ–¹æ³•å‡æ˜¾è‘—æå‡äº†ç­–ç•¥çš„å®‰å…¨æ€§ï¼Œç‰¹åˆ«æ˜¯åŸºäºæ¨¡å‹ä¸ç¡®å®šæ€§çš„åŠ æƒæ–¹æ³•ï¼Œç¢°æ’ç‡æ˜¾è‘—é™ä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸ºä»å¤§è§„æ¨¡çœŸå®é©¾é©¶æ—¥å¿—ä¸­è®­ç»ƒè‡ªä¸»è½¦è¾†ï¼ˆAVï¼‰è§„åˆ’ç­–ç•¥æä¾›äº†æœ‰å‰æ™¯çš„èŒƒå¼ã€‚ç„¶è€Œï¼Œè¿™äº›æ—¥å¿—ä¸­çš„æç«¯æ•°æ®ä¸å¹³è¡¡ï¼Œå¯¼è‡´å¸¸è§åœºæ™¯è¿œå¤šäºç¨€æœ‰çš„â€œé•¿å°¾â€äº‹ä»¶ï¼Œä½¿ç”¨æ ‡å‡†å‡åŒ€æ•°æ®é‡‡æ ·æ—¶ä¼šå¯¼è‡´è„†å¼±å’Œä¸å®‰å…¨çš„ç­–ç•¥ã€‚æœ¬æ–‡é€šè¿‡ç³»ç»Ÿçš„å¤§è§„æ¨¡æ¯”è¾ƒç ”ç©¶ï¼Œæå‡ºäº†å…­ç§ä¸åŒçš„å…³é”®æ€§åŠ æƒæ–¹æ¡ˆï¼Œæ—¨åœ¨å°†å­¦ä¹ è¿‡ç¨‹é›†ä¸­åœ¨ä¿¡æ¯ä¸°å¯Œçš„æ ·æœ¬ä¸Šã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ‰€æœ‰æ•°æ®ç­–åˆ’æ–¹æ³•æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œå°¤å…¶æ˜¯åŸºäºæ¨¡å‹ä¸ç¡®å®šæ€§çš„ç­–åˆ’æ–¹æ³•ï¼Œç¢°æ’ç‡é™ä½è¿‘ä¸‰å€ï¼ˆä»16.0%é™è‡³5.5%ï¼‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­å› æ•°æ®ä¸å¹³è¡¡å¯¼è‡´çš„ç­–ç•¥è„†å¼±æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç¨€æœ‰äº‹ä»¶æ—¶æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥å…­ç§å…³é”®æ€§åŠ æƒç­–ç•¥ï¼Œé›†ä¸­å­¦ä¹ ä¿¡æ¯ä¸°å¯Œçš„æ ·æœ¬ï¼Œä»¥æé«˜æ¨¡å‹åœ¨é•¿å°¾äº‹ä»¶ä¸Šçš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é‡‡æ ·ã€å…³é”®æ€§åŠ æƒã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚é‡‡ç”¨ä¸ƒä¸ªç›®æ ‡æ¡ä»¶çš„ä¿å®ˆQå­¦ä¹ ï¼ˆCQLï¼‰ä»£ç†è¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨é«˜ä¿çœŸWaymaxæ¨¡æ‹Ÿå™¨ä¸­è¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæå‡ºçš„æ•°æ®é©±åŠ¨ç­–åˆ’æ–¹æ³•åˆ©ç”¨æ¨¡å‹ä¸ç¡®å®šæ€§ä½œä¸ºä¿¡å·ï¼Œæ˜¾è‘—æå‡äº†ç­–ç•¥çš„å®‰å…¨æ€§ï¼Œä¸ä¼ ç»Ÿå‡åŒ€é‡‡æ ·æ–¹æ³•ç›¸æ¯”ï¼Œè¡¨ç°å‡ºæ›´å¥½çš„æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„æ¶æ„ï¼Œå…³é”®æ€§åŠ æƒç­–ç•¥åœ¨æ—¶é—´æ­¥å’Œåœºæ™¯å±‚é¢è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿åœ¨ä¸åŒæ—¶é—´å°ºåº¦ä¸Šä¼˜åŒ–ç­–ç•¥è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æœ‰æ•°æ®ç­–åˆ’æ–¹æ³•å‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œå°¤å…¶æ˜¯åŸºäºæ¨¡å‹ä¸ç¡®å®šæ€§çš„ç­–åˆ’æ–¹æ³•ï¼Œç¢°æ’ç‡ä»16.0%é™ä½è‡³5.5%ï¼Œå®ç°äº†è¿‘ä¸‰å€çš„å®‰å…¨æ€§æå‡ã€‚æ­¤å¤–ï¼Œæ—¶é—´æ­¥å±‚é¢çš„åŠ æƒåœ¨ååº”å®‰å…¨æ€§ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè€Œåœºæ™¯å±‚é¢çš„åŠ æƒåˆ™æ”¹å–„äº†é•¿æ—¶é—´è§„åˆ’èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œå…¶ä»–éœ€è¦é«˜å®‰å…¨æ€§çš„è‡ªä¸»ç³»ç»Ÿã€‚é€šè¿‡ä¼˜åŒ–æ•°æ®é‡‡æ ·å’Œå­¦ä¹ ç­–ç•¥ï¼Œå¯ä»¥æ˜¾è‘—æå‡è‡ªä¸»ä»£ç†åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å†³ç­–èƒ½åŠ›å’Œå®‰å…¨æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Offline Reinforcement Learning (RL) presents a promising paradigm for training autonomous vehicle (AV) planning policies from large-scale, real-world driving logs. However, the extreme data imbalance in these logs, where mundane scenarios vastly outnumber rare "long-tail" events, leads to brittle and unsafe policies when using standard uniform data sampling. In this work, we address this challenge through a systematic, large-scale comparative study of data curation strategies designed to focus the learning process on information-rich samples. We investigate six distinct criticality weighting schemes which are categorized into three families: heuristic-based, uncertainty-based, and behavior-based. These are evaluated at two temporal scales, the individual timestep and the complete scenario. We train seven goal-conditioned Conservative Q-Learning (CQL) agents with a state-of-the-art, attention-based architecture and evaluate them in the high-fidelity Waymax simulator. Our results demonstrate that all data curation methods significantly outperform the baseline. Notably, data-driven curation using model uncertainty as a signal achieves the most significant safety improvements, reducing the collision rate by nearly three-fold (from 16.0% to 5.5%). Furthermore, we identify a clear trade-off where timestep-level weighting excels at reactive safety while scenario-level weighting improves long-horizon planning. Our work provides a comprehensive framework for data curation in Offline RL and underscores that intelligent, non-uniform sampling is a critical component for building safe and reliable autonomous agents.

