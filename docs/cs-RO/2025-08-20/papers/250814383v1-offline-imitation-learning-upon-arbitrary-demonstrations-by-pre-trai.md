---
layout: default
title: Offline Imitation Learning upon Arbitrary Demonstrations by Pre-Training Dynamics Representations
---

# Offline Imitation Learning upon Arbitrary Demonstrations by Pre-Training Dynamics Representations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14383" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14383v1</a>
  <a href="https://arxiv.org/pdf/2508.14383.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14383v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14383v1', 'Offline Imitation Learning upon Arbitrary Demonstrations by Pre-Training Dynamics Representations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haitong Ma, Bo Dai, Zhaolin Ren, Yebin Wang, Na Li

**åˆ†ç±»**: cs.RO, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20

**å¤‡æ³¨**: 7 pages, 5 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡é¢„è®­ç»ƒåŠ¨æ€è¡¨ç¤ºæå‡æœ‰é™ä¸“å®¶æ•°æ®ä¸‹çš„æ¨¡ä»¿å­¦ä¹ æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç¦»çº¿æ¨¡ä»¿å­¦ä¹ ` `åŠ¨æ€è¡¨ç¤º` `é¢„è®­ç»ƒ` `ä¸“å®¶æ•°æ®` `æœºå™¨äººæ§åˆ¶` `æ•°æ®é‡ç”¨` `å™ªå£°å¯¹æ¯”ä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¦»çº¿æ¨¡ä»¿å­¦ä¹ æ–¹æ³•åœ¨æœ‰é™ä¸“å®¶æ•°æ®ä¸‹è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´å­¦ä¹ æ•ˆæœå—é™ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡é¢„è®­ç»ƒåŠ¨æ€è¡¨ç¤ºæ¥è§£å†³æ•°æ®ä¸è¶³é—®é¢˜ï¼Œä»è€Œæå‡æ¨¡ä»¿å­¦ä¹ çš„æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åœ¨ä»…æœ‰ä¸€æ¡è½¨è¿¹çš„æƒ…å†µä¸‹æˆåŠŸæ¨¡ä»¿ä¸“å®¶ç­–ç•¥ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ‰é™çš„æ•°æ®å·²æˆä¸ºæ‰©å±•ç¦»çº¿æ¨¡ä»¿å­¦ä¹ ï¼ˆILï¼‰çš„ä¸»è¦ç“¶é¢ˆã€‚æœ¬æ–‡æå‡ºé€šè¿‡å¼•å…¥é¢„è®­ç»ƒé˜¶æ®µæ¥å¢å¼ºILæ€§èƒ½ï¼Œè¯¥é˜¶æ®µå­¦ä¹ åŸºäºè½¬ç§»åŠ¨æ€çš„å› å­åˆ†è§£çš„åŠ¨æ€è¡¨ç¤ºã€‚æˆ‘ä»¬é¦–å…ˆç†è®ºä¸Šè¯æ˜äº†ç¦»çº¿ILçš„æœ€ä¼˜å†³ç­–å˜é‡ä½äºè¡¨ç¤ºç©ºé—´ä¸­ï¼Œæ˜¾è‘—å‡å°‘äº†ä¸‹æ¸¸ILä¸­éœ€è¦å­¦ä¹ çš„å‚æ•°ã€‚æ­¤å¤–ï¼ŒåŠ¨æ€è¡¨ç¤ºå¯ä»¥ä»æ”¶é›†åˆ°çš„ä»»æ„æ•°æ®ä¸­å­¦ä¹ ï¼Œè¿™äº›æ•°æ®å…·æœ‰ç›¸åŒçš„åŠ¨æ€ç‰¹æ€§ï¼Œä»è€Œå…è®¸é‡ç”¨å¤§é‡éä¸“å®¶æ•°æ®ï¼Œç¼“è§£æ•°æ®ä¸è¶³çš„é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å—å™ªå£°å¯¹æ¯”ä¼°è®¡å¯å‘çš„å¯å¤„ç†æŸå¤±å‡½æ•°ï¼Œä»¥åœ¨é¢„è®­ç»ƒé˜¶æ®µå­¦ä¹ åŠ¨æ€è¡¨ç¤ºã€‚åœ¨MuJoCoä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„ç®—æ³•å¯ä»¥ä»…ç”¨ä¸€æ¡è½¨è¿¹æ¨¡ä»¿ä¸“å®¶ç­–ç•¥ã€‚åœ¨çœŸå®å››è¶³åŠ¨ç‰©ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨æ¥è‡ªæ¨¡æ‹Ÿå™¨æ•°æ®çš„é¢„è®­ç»ƒåŠ¨æ€è¡¨ç¤ºï¼Œä»å°‘é‡çœŸå®ä¸–ç•Œæ¼”ç¤ºä¸­å­¦ä¹ è¡Œèµ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç¦»çº¿æ¨¡ä»¿å­¦ä¹ ä¸­ç”±äºä¸“å®¶æ•°æ®æœ‰é™è€Œå¯¼è‡´çš„æ€§èƒ½ç“¶é¢ˆã€‚ç°æœ‰æ–¹æ³•åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œéš¾ä»¥æœ‰æ•ˆå­¦ä¹ å’Œæ³›åŒ–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥é¢„è®­ç»ƒé˜¶æ®µï¼Œå­¦ä¹ åŠ¨æ€è¡¨ç¤ºï¼Œä»è€Œåœ¨è¡¨ç¤ºç©ºé—´ä¸­è¿›è¡Œä¼˜åŒ–ï¼Œå‡å°‘ä¸‹æ¸¸å­¦ä¹ çš„å‚æ•°æ•°é‡ï¼Œæå‡å­¦ä¹ æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¢„è®­ç»ƒé˜¶æ®µå’Œä¸‹æ¸¸æ¨¡ä»¿å­¦ä¹ é˜¶æ®µã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œåˆ©ç”¨å¤§é‡éä¸“å®¶æ•°æ®å­¦ä¹ åŠ¨æ€è¡¨ç¤ºï¼›åœ¨ä¸‹æ¸¸é˜¶æ®µï¼ŒåŸºäºè¿™äº›è¡¨ç¤ºè¿›è¡Œæ¨¡ä»¿å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºåŠ¨æ€è¡¨ç¤ºçš„å­¦ä¹ æ–¹æ³•ï¼Œå…è®¸ä»ä»»æ„æ•°æ®ä¸­æå–ä¿¡æ¯ï¼Œæ˜¾è‘—æé«˜äº†æ•°æ®çš„åˆ©ç”¨æ•ˆç‡ï¼Œå¹¶ä¸”åœ¨è¡¨ç¤ºç©ºé—´ä¸­è¿›è¡Œä¼˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šè®¾è®¡äº†ä¸€ç§å—å™ªå£°å¯¹æ¯”ä¼°è®¡å¯å‘çš„æŸå¤±å‡½æ•°ï¼Œä»¥æœ‰æ•ˆå­¦ä¹ åŠ¨æ€è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œæ¨¡å‹æ¶æ„çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥é€‚åº”åŠ¨æ€è¡¨ç¤ºçš„å­¦ä¹ éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„ç®—æ³•åœ¨MuJoCoç¯å¢ƒä¸­ä»…ç”¨ä¸€æ¡è½¨è¿¹å°±èƒ½æˆåŠŸæ¨¡ä»¿ä¸“å®¶ç­–ç•¥ï¼Œä¸”åœ¨çœŸå®å››è¶³åŠ¨ç‰©çš„è¡Œèµ°å­¦ä¹ ä¸­ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„åŠ¨æ€è¡¨ç¤ºæ˜¾è‘—æå‡äº†å­¦ä¹ æ•ˆç‡ï¼Œå±•ç¤ºäº†è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰ã€‚é€šè¿‡æœ‰æ•ˆåˆ©ç”¨æœ‰é™çš„ä¸“å®¶æ•°æ®ï¼Œèƒ½å¤Ÿåœ¨å®é™…åœºæ™¯ä¸­å®ç°æ›´é«˜æ•ˆçš„å­¦ä¹ å’Œå†³ç­–ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Limited data has become a major bottleneck in scaling up offline imitation learning (IL). In this paper, we propose enhancing IL performance under limited expert data by introducing a pre-training stage that learns dynamics representations, derived from factorizations of the transition dynamics. We first theoretically justify that the optimal decision variable of offline IL lies in the representation space, significantly reducing the parameters to learn in the downstream IL. Moreover, the dynamics representations can be learned from arbitrary data collected with the same dynamics, allowing the reuse of massive non-expert data and mitigating the limited data issues. We present a tractable loss function inspired by noise contrastive estimation to learn the dynamics representations at the pre-training stage. Experiments on MuJoCo demonstrate that our proposed algorithm can mimic expert policies with as few as a single trajectory. Experiments on real quadrupeds show that we can leverage pre-trained dynamics representations from simulator data to learn to walk from a few real-world demonstrations.

