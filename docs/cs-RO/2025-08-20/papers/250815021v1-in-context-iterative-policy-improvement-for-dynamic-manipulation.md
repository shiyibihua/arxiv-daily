---
layout: default
title: In-Context Iterative Policy Improvement for Dynamic Manipulation
---

# In-Context Iterative Policy Improvement for Dynamic Manipulation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.15021" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.15021v1</a>
  <a href="https://arxiv.org/pdf/2508.15021.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.15021v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.15021v1', 'In-Context Iterative Policy Improvement for Dynamic Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mark Van der Merwe, Devesh Jha

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20

**å¤‡æ³¨**: 14 pages. Accepted at CoRL 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºä¸Šä¸‹æ–‡çš„è¿­ä»£ç­–ç•¥æ”¹è¿›ä»¥è§£å†³åŠ¨æ€æ“æ§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŠ¨æ€æ“æ§` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `è¿­ä»£ç­–ç•¥` `æœºå™¨äººæŠ€æœ¯` `æ™ºèƒ½åˆ¶é€ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åŠ¨æ€æ“æ§é¢ä¸´é«˜ç»´åº¦ã€å¤æ‚åŠ¨æ€å’Œéƒ¨åˆ†å¯è§‚æµ‹æ€§ç­‰æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è¿™äº›æ–¹é¢è¡¨ç°ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§è¿­ä»£çš„ä¸Šä¸‹æ–‡å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡é¢„æµ‹å‚æ•°ç­–ç•¥çš„è°ƒæ•´æ¥åº”å¯¹åŠ¨æ€æ“æ§é—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå’Œç‰©ç†æœºå™¨äººä»»åŠ¡ä¸­å‡ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½æ•°æ®æƒ…å†µä¸‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºäº’è”ç½‘è§„æ¨¡è¯­è¨€æ•°æ®è®­ç»ƒçš„æ³¨æ„åŠ›æ¶æ„åœ¨å„ç§è¯­è¨€ä»»åŠ¡ä¸­å±•ç°äº†å…ˆè¿›çš„æ¨ç†èƒ½åŠ›ã€‚æœ¬æ–‡æ¢è®¨äº†å¦‚ä½•å°†ä¸Šä¸‹æ–‡å­¦ä¹ åº”ç”¨äºåŠ¨æ€æ“æ§ï¼Œè§£å†³äº†é«˜ç»´åº¦ã€å¤æ‚åŠ¨æ€å’Œéƒ¨åˆ†å¯è§‚æµ‹æ€§ç­‰æŒ‘æˆ˜ã€‚é€šè¿‡è¿­ä»£çš„æ–¹æ³•ï¼Œæˆ‘ä»¬å°†ä¸Šä¸‹æ–‡å­¦ä¹ é—®é¢˜å½¢å¼åŒ–ä¸ºåŸºäºå…ˆå‰äº¤äº’é¢„æµ‹å‚æ•°ç­–ç•¥çš„è°ƒæ•´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä½æ•°æ®ç¯å¢ƒä¸‹ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ çš„æ–¹æ³•ä¼˜äºå…¶ä»–æ›¿ä»£æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŠ¨æ€æ“æ§ä¸­çš„ä¸Šä¸‹æ–‡å­¦ä¹ é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†é«˜ç»´åº¦å’Œå¤æ‚åŠ¨æ€æ—¶æ•ˆæœä¸ä½³ï¼Œä¸”éš¾ä»¥åº”å¯¹éƒ¨åˆ†å¯è§‚æµ‹æ€§å¸¦æ¥çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡è¿­ä»£çš„æ–¹å¼ï¼Œå°†ä¸Šä¸‹æ–‡å­¦ä¹ é—®é¢˜è½¬åŒ–ä¸ºåŸºäºå†å²äº¤äº’çš„å‚æ•°ç­–ç•¥è°ƒæ•´é¢„æµ‹ï¼Œä»è€Œæé«˜åŠ¨æ€æ“æ§çš„æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€ä¸Šä¸‹æ–‡ä¿¡æ¯æå–ã€ç­–ç•¥è°ƒæ•´é¢„æµ‹å’Œæ‰§è¡Œå››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’æ”¶é›†æ•°æ®ï¼Œç„¶åæå–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ¥ç€é¢„æµ‹ç­–ç•¥è°ƒæ•´ï¼Œæœ€åæ‰§è¡Œè°ƒæ•´åçš„ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†ä¸Šä¸‹æ–‡å­¦ä¹ ä¸åŠ¨æ€æ“æ§ç›¸ç»“åˆï¼Œé€šè¿‡è¿­ä»£æ–¹å¼å®ç°ç­–ç•¥çš„è‡ªé€‚åº”è°ƒæ•´ï¼Œè¿™ä¸€æ–¹æ³•åœ¨å¤„ç†å¤æ‚åŠ¨æ€æ—¶è¡¨ç°å‡ºæ˜æ˜¾ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§å­¦ä¹ ç‡å’Œç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç­–ç•¥è°ƒæ•´çš„å‡†ç¡®æ€§ï¼Œç½‘ç»œç»“æ„ä¸Šåˆ™ä½¿ç”¨äº†å¤šå±‚æ³¨æ„åŠ›æœºåˆ¶ä»¥å¢å¼ºå¯¹ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ•æ‰èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ çš„æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸­å‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚åœ¨ä½æ•°æ®ç¯å¢ƒä¸‹ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨åŠ¨æ€æ“æ§ä¸­çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæŠ“å–ã€è‡ªåŠ¨åŒ–è£…é…å’Œäººæœºäº¤äº’ç­‰åŠ¨æ€æ“æ§åœºæ™¯ã€‚é€šè¿‡æå‡æœºå™¨äººçš„é€‚åº”èƒ½åŠ›å’Œæ“ä½œç²¾åº¦ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„ä»»åŠ¡æ‰§è¡Œï¼Œæœªæ¥å¯èƒ½å¯¹æ™ºèƒ½åˆ¶é€ å’ŒæœåŠ¡æœºå™¨äººé¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Attention-based architectures trained on internet-scale language data have demonstrated state of the art reasoning ability for various language-based tasks, such as logic problems and textual reasoning. Additionally, these Large Language Models (LLMs) have exhibited the ability to perform few-shot prediction via in-context learning, in which input-output examples provided in the prompt are generalized to new inputs. This ability furthermore extends beyond standard language tasks, enabling few-shot learning for general patterns. In this work, we consider the application of in-context learning with pre-trained language models for dynamic manipulation. Dynamic manipulation introduces several crucial challenges, including increased dimensionality, complex dynamics, and partial observability. To address this, we take an iterative approach, and formulate our in-context learning problem to predict adjustments to a parametric policy based on previous interactions. We show across several tasks in simulation and on a physical robot that utilizing in-context learning outperforms alternative methods in the low data regime. Video summary of this work and experiments can be found https://youtu.be/2inxpdrq74U?si=dAdDYsUEr25nZvRn.

