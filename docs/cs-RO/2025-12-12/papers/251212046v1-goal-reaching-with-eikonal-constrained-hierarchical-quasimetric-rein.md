---
layout: default
title: Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning
---

# Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.12046" target="_blank" class="toolbar-btn">arXiv: 2512.12046v1</a>
    <a href="https://arxiv.org/pdf/2512.12046.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.12046v1" 
            onclick="toggleFavorite(this, '2512.12046v1', 'Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Vittorio Giammarino, Ahmed H. Qureshi

**ÂàÜÁ±ª**: cs.LG, cs.RO, eess.SY, stat.ML

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-12

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Eik-HiQRLÔºåÁªìÂêàEikonalÊñπÁ®ã‰∏éÂàÜÂ±ÇÂº∫ÂåñÂ≠¶‰π†Ëß£ÂÜ≥Â§çÊùÇÁéØÂ¢É‰∏ãÁöÑÁõÆÊ†áÂØºÂêëÂØºËà™ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ÁõÆÊ†áÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†` `ÊãüÂ∫¶ÈáèÂº∫ÂåñÂ≠¶‰π†` `EikonalÊñπÁ®ã` `ÂàÜÂ±ÇÂº∫ÂåñÂ≠¶‰π†` `Êú∫Âô®‰∫∫ÂØºËà™` `Á¶ªÁ∫øÂº∫ÂåñÂ≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ‰º†ÁªüÂº∫ÂåñÂ≠¶‰π†Â•ñÂä±ËÆæËÆ°Âõ∞ÈöæÔºåÁõÆÊ†áÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†ÈÄöËøáÁõÆÊ†áÂà∞ËææÊù•ÁÆÄÂåñ‰ªªÂä°ÂÆö‰πâÔºå‰ΩÜÁé∞ÊúâÊñπÊ≥ïÂú®Â§çÊùÇÂä®ÂäõÂ≠¶‰∏ãÂ≠òÂú®Â±ÄÈôêÊÄß„ÄÇ
2. Eik-HiQRLÂ∞ÜEikonalÊñπÁ®ãÁ∫¶ÊùüÁöÑQRLËûçÂÖ•ÂàÜÂ±ÇÁªìÊûÑÔºåÂà©Áî®PDEÁöÑËøûÁª≠ÊÄßÊèêÈ´òÊ≥õÂåñËÉΩÂäõÔºåÂπ∂ÈÄöËøáÂàÜÂ±ÇÂàÜËß£Â§ÑÁêÜÂ§çÊùÇÂä®ÂäõÂ≠¶„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåEik-HiQRLÂú®Á¶ªÁ∫øÂØºËà™‰ªªÂä°‰∏≠ËææÂà∞SOTAÔºåÂπ∂Âú®Êìç‰Ωú‰ªªÂä°‰∏≠Ë∂ÖË∂äQRLÔºåÊÄßËÉΩ‰∏éÊó∂Â∫èÂ∑ÆÂàÜÊñπÊ≥ïÁõ∏ÂΩì„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éEikonalÁ∫¶ÊùüÁöÑÂàÜÂ±ÇÊãüÂ∫¶ÈáèÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºàEik-HiQRLÔºâÔºåÊó®Âú®Ëß£ÂÜ≥ÁõÆÊ†áÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†ÔºàGCRLÔºâ‰∏≠Â•ñÂä±ËÆæËÆ°Âõ∞ÈöæÁöÑÈóÆÈ¢ò„ÄÇGCRLÂ∞Ü‰ªªÂä°ÂÆö‰πâ‰∏∫ÁõÆÊ†áÂà∞ËææÔºåËÄåÈùûÊúÄÂ§ßÂåñÊâãÂ∑•ËÆæËÆ°ÁöÑÂ•ñÂä±‰ø°Âè∑„ÄÇÊúÄ‰ºòÁõÆÊ†áÊù°‰ª∂‰ª∑ÂÄºÂáΩÊï∞Ëá™ÁÑ∂ÂΩ¢ÊàêÊãüÂ∫¶ÈáèÔºå‰øÉ‰ΩøÊãüÂ∫¶ÈáèÂº∫ÂåñÂ≠¶‰π†ÔºàQRLÔºâÂ∞Ü‰ª∑ÂÄºÂ≠¶‰π†Á∫¶Êùü‰∏∫ÊãüÂ∫¶ÈáèÊò†Â∞ÑÔºåÂπ∂ÈÄöËøáÁ¶ªÊï£ÁöÑ„ÄÅÂü∫‰∫éËΩ®ËøπÁöÑÁ∫¶ÊùüÊù•Âä†Âº∫Â±ÄÈÉ®‰∏ÄËá¥ÊÄß„ÄÇEik-QRLÊòØQRLÁöÑËøûÁª≠Êó∂Èó¥ÈáçÊûÑÔºåÂü∫‰∫éEikonalÂÅèÂæÆÂàÜÊñπÁ®ãÔºàPDEÔºâ„ÄÇËøôÁßçÂü∫‰∫éPDEÁöÑÁªìÊûÑ‰ΩøEik-QRLÊó†ÈúÄËΩ®ËøπÔºå‰ªÖÈúÄÈááÊ†∑ÁöÑÁä∂ÊÄÅÂíåÁõÆÊ†áÔºåÂêåÊó∂ÊèêÈ´ò‰∫ÜÂàÜÂ∏ÉÂ§ñÊ≥õÂåñËÉΩÂäõ„ÄÇËÆ∫ÊñáÊèê‰æõ‰∫ÜEik-QRLÁöÑÁêÜËÆ∫‰øùËØÅÔºåÂπ∂ÊåáÂá∫‰∫ÜÂ§çÊùÇÂä®ÂäõÂ≠¶‰∏ãÁöÑÂ±ÄÈôêÊÄß„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÊåëÊàòÔºåEik-HiQRLÂ∞ÜEik-QRLÈõÜÊàêÂà∞ÂàÜÂ±ÇÂàÜËß£‰∏≠„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEik-HiQRLÂú®Á¶ªÁ∫øÁõÆÊ†áÊù°‰ª∂ÂØºËà™‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂπ∂Âú®Êìç‰Ωú‰ªªÂä°‰∏≠Ëé∑Âæó‰∫ÜÁõ∏ÂØπ‰∫éQRLÁöÑ‰∏ÄËá¥Â¢ûÁõäÔºå‰∏éÊó∂Â∫èÂ∑ÆÂàÜÊñπÊ≥ïÁõ∏ÂåπÈÖç„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁõÆÊ†áÊù°‰ª∂Âº∫ÂåñÂ≠¶‰π†ÔºàGCRLÔºâÊó®Âú®ÈÄöËøáÂ≠¶‰π†‰ªé‰ªªÊÑèÁä∂ÊÄÅÂà∞ËææÁõÆÊ†áÁä∂ÊÄÅÁöÑÁ≠ñÁï•Êù•Ëß£ÂÜ≥Â•ñÂä±ÂáΩÊï∞ËÆæËÆ°Âõ∞ÈöæÁöÑÈóÆÈ¢ò„ÄÇÁÑ∂ËÄåÔºåÂú®Â§çÊùÇÂä®ÂäõÂ≠¶ÁéØÂ¢É‰∏ãÔºå‰º†ÁªüÁöÑQRLÊñπÊ≥ï‰æùËµñ‰∫éËΩ®ËøπÁ∫¶ÊùüÔºåÊ≥õÂåñËÉΩÂäõÂèóÈôêÔºåÈöæ‰ª•ÈÄÇÂ∫îÂàÜÂ∏ÉÂ§ñÁöÑÁä∂ÊÄÅÂíåÁõÆÊ†á„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜQRLÊñπÊ≥ï‰∏éEikonalÂÅèÂæÆÂàÜÊñπÁ®ãÔºàPDEÔºâÁõ∏ÁªìÂêàÔºåÊûÑÂª∫ËøûÁª≠Êó∂Èó¥ÁöÑ‰ª∑ÂÄºÂáΩÊï∞Ë°®Á§∫Ôºå‰ªéËÄåÊëÜËÑ±ÂØπËΩ®ËøπÁöÑ‰æùËµñÔºåÊèêÈ´òÊ≥õÂåñËÉΩÂäõ„ÄÇÂêåÊó∂Ôºå‰∏∫‰∫ÜÂ§ÑÁêÜÂ§çÊùÇÂä®ÂäõÂ≠¶ÔºåÂºïÂÖ•ÂàÜÂ±ÇÁªìÊûÑÔºåÂ∞Ü‰ªªÂä°ÂàÜËß£‰∏∫Â§ö‰∏™Â≠ê‰ªªÂä°ÔºåÂàÜÂà´Â≠¶‰π†Â≠êÁ≠ñÁï•„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöEik-HiQRLÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÂ±ÇÊ¨°ÔºöÈ´òÂ±ÇÁ≠ñÁï•Âíå‰ΩéÂ±ÇÁ≠ñÁï•„ÄÇÈ´òÂ±ÇÁ≠ñÁï•Ë¥üË¥£ÈÄâÊã©Â≠êÁõÆÊ†áÔºå‰ΩéÂ±ÇÁ≠ñÁï•Ë¥üË¥£Âà∞ËææÈÄâÂÆöÁöÑÂ≠êÁõÆÊ†á„ÄÇEik-QRL‰Ωú‰∏∫‰ΩéÂ±ÇÁ≠ñÁï•ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåÂà©Áî®EikonalÊñπÁ®ãÁ∫¶Êùü‰ª∑ÂÄºÂáΩÊï∞ÁöÑÂ≠¶‰π†Ôºå‰ΩøÂÖ∂Êª°Ë∂≥ÊãüÂ∫¶ÈáèÊÄßË¥®„ÄÇÊï¥‰ΩìÊµÅÁ®ã‰∏∫ÔºöÈ¶ñÂÖàÔºåÈ´òÂ±ÇÁ≠ñÁï•ÈÄâÊã©‰∏Ä‰∏™Â≠êÁõÆÊ†áÔºõÁÑ∂ÂêéÔºå‰ΩéÂ±ÇÁ≠ñÁï•Âà©Áî®Eik-QRLÂ≠¶‰π†Âà∞ËææËØ•Â≠êÁõÆÊ†áÁöÑÁ≠ñÁï•ÔºõÈáçÂ§ç‰ª•‰∏äËøáÁ®ãÔºåÁõ¥Âà∞Âà∞ËææÊúÄÁªàÁõÆÊ†á„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**Ôºö‰∏ªË¶ÅÂàõÊñ∞ÁÇπÂú®‰∫éÔºö1) Â∞ÜEikonalÊñπÁ®ãÂºïÂÖ•QRLÔºåÊûÑÂª∫‰∫ÜËøûÁª≠Êó∂Èó¥ÁöÑ‰ª∑ÂÄºÂáΩÊï∞Ë°®Á§∫ÔºåÊèêÈ´ò‰∫ÜÊ≥õÂåñËÉΩÂäõÔºõ2) ÊèêÂá∫‰∫ÜÂàÜÂ±ÇÁªìÊûÑÔºåÂ∞ÜÂ§çÊùÇ‰ªªÂä°ÂàÜËß£‰∏∫Â§ö‰∏™Â≠ê‰ªªÂä°ÔºåÈôç‰Ωé‰∫ÜÂ≠¶‰π†ÈöæÂ∫¶Ôºõ3) ÁêÜËÆ∫‰∏äËØÅÊòé‰∫ÜEik-QRLÁöÑÊúâÊïàÊÄßÔºåÂπ∂ÂàÜÊûê‰∫ÜÂÖ∂Âú®Â§çÊùÇÂä®ÂäõÂ≠¶‰∏ãÁöÑÂ±ÄÈôêÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöEik-QRLÁöÑÂÖ≥ÈîÆÂú®‰∫éEikonalÊñπÁ®ãÁöÑÁ∫¶Êùü„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºå‰ª∑ÂÄºÂáΩÊï∞ÈúÄË¶ÅÊª°Ë∂≥‰ª•‰∏ãÊñπÁ®ãÔºö||‚àáV(s, g)||=f(s)ÔºåÂÖ∂‰∏≠V(s, g)ÊòØ‰ªéÁä∂ÊÄÅsÂà∞ÁõÆÊ†ágÁöÑ‰ª∑ÂÄºÔºåf(s)ÊòØÁä∂ÊÄÅsÁöÑÊàêÊú¨ÂáΩÊï∞„ÄÇËÆ∫Êñá‰ΩøÁî®Á•ûÁªèÁΩëÁªúÊù•Ëøë‰ºº‰ª∑ÂÄºÂáΩÊï∞ÔºåÂπ∂ÈÄöËøáÊúÄÂ∞èÂåñEikonalÊñπÁ®ãÁöÑÊÆãÂ∑ÆÊù•ËÆ≠ÁªÉÁΩëÁªú„ÄÇÂàÜÂ±ÇÁªìÊûÑÁöÑÂÖ≥ÈîÆÂú®‰∫éÂ≠êÁõÆÊ†áÁöÑÈÄâÊã©Á≠ñÁï•ÔºåËÆ∫ÊñáÈááÁî®‰∫Ü‰∏ÄÁßçÂü∫‰∫é‰ª∑ÂÄºÂáΩÊï∞ÁöÑÂ≠êÁõÆÊ†áÈÄâÊã©ÊñπÊ≥ï„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Eik-HiQRLÂú®Á¶ªÁ∫øÁõÆÊ†áÊù°‰ª∂ÂØºËà™‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑQRLÊñπÊ≥ïÔºåÂπ∂ËææÂà∞‰∫Ü‰∏éÊó∂Â∫èÂ∑ÆÂàÜÊñπÊ≥ïÁõ∏ÂΩìÁöÑÊ∞¥Âπ≥„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÂú®Â§ö‰∏™ÂØºËà™ÁéØÂ¢É‰∏≠ÔºåEik-HiQRLÁöÑÊàêÂäüÁéáÂíåÊïàÁéáÂùá‰ºò‰∫éQRLÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®Â§çÊùÇÁéØÂ¢É‰∏ãÁöÑÊúâÊïàÊÄß„ÄÇÂú®Êìç‰Ωú‰ªªÂä°‰∏≠ÔºåEik-HiQRL‰πüË°®Áé∞Âá∫‰∫Ü‰∏ÄËá¥ÁöÑÂ¢ûÁõä„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊ∏∏ÊàèAIÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÂ≠¶‰π†ÁõÆÊ†áÂØºÂêëÁöÑÁ≠ñÁï•ÔºåÊú∫Âô®‰∫∫ÂèØ‰ª•Âú®Â§çÊùÇÁéØÂ¢É‰∏≠Ëá™‰∏ªÂØºËà™ÔºåÂÆåÊàêÂêÑÁßç‰ªªÂä°„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Áî®‰∫éËÆ≠ÁªÉÊ∏∏ÊàèAIÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£Ê∏∏ÊàèÁõÆÊ†áÔºåÂπ∂Âà∂ÂÆöÁõ∏Â∫îÁöÑÁ≠ñÁï•„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Goal-Conditioned Reinforcement Learning (GCRL) mitigates the difficulty of reward design by framing tasks as goal reaching rather than maximizing hand-crafted reward signals. In this setting, the optimal goal-conditioned value function naturally forms a quasimetric, motivating Quasimetric RL (QRL), which constrains value learning to quasimetric mappings and enforces local consistency through discrete, trajectory-based constraints. We propose Eikonal-Constrained Quasimetric RL (Eik-QRL), a continuous-time reformulation of QRL based on the Eikonal Partial Differential Equation (PDE). This PDE-based structure makes Eik-QRL trajectory-free, requiring only sampled states and goals, while improving out-of-distribution generalization. We provide theoretical guarantees for Eik-QRL and identify limitations that arise under complex dynamics. To address these challenges, we introduce Eik-Hierarchical QRL (Eik-HiQRL), which integrates Eik-QRL into a hierarchical decomposition. Empirically, Eik-HiQRL achieves state-of-the-art performance in offline goal-conditioned navigation and yields consistent gains over QRL in manipulation tasks, matching temporal-difference methods.

