---
layout: default
title: cuVSLAM: CUDA accelerated visual odometry and mapping
---

# cuVSLAM: CUDA accelerated visual odometry and mapping

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04359" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04359v3</a>
  <a href="https://arxiv.org/pdf/2506.04359.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04359v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04359v3', 'cuVSLAM: CUDA accelerated visual odometry and mapping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alexander Korovko, Dmitry Slepichev, Alexander Efitorov, Aigul Dzhumamuratova, Viktor Kuznetsov, Hesam Rabeti, Joydeep Biswas, Soha Pouya

**åˆ†ç±»**: cs.RO, cs.AI, cs.SE

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04 (æ›´æ–°: 2025-07-08)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºcuVSLAMä»¥è§£å†³è‡ªä¸»æœºå™¨äººå®šä½ä¸åœ°å›¾æ„å»ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `è§†è§‰åŒæ­¥å®šä½` `åœ°å›¾æ„å»º` `CUDAåŠ é€Ÿ` `è¾¹ç¼˜è®¡ç®—` `å¤šä¼ æ„Ÿå™¨èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰å®šä½ä¸åœ°å›¾æ„å»ºæ–¹æ³•åœ¨å¤„ç†å¤šä¼ æ„Ÿå™¨è¾“å…¥æ—¶å­˜åœ¨è®¡ç®—æ•ˆç‡ä½å’Œå®æ—¶æ€§å·®çš„é—®é¢˜ã€‚
2. cuVSLAMé€šè¿‡CUDAåŠ é€Ÿä¼˜åŒ–ï¼Œæ”¯æŒå¤šç§ä¼ æ„Ÿå™¨é…ç½®ï¼Œèƒ½å¤Ÿåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°å®æ—¶çš„è§†è§‰åŒæ­¥å®šä½ä¸åœ°å›¾æ„å»ºã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒcuVSLAMåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€ä½³æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‡†ç¡®ä¸”ç¨³å¥çš„å§¿æ€ä¼°è®¡æ˜¯ä»»ä½•è‡ªä¸»æœºå™¨äººæ‰€éœ€çš„å…³é”®ã€‚æˆ‘ä»¬æå‡ºäº†cuVSLAMï¼Œè¿™æ˜¯ä¸€ç§å…ˆè¿›çš„è§†è§‰åŒæ­¥å®šä½ä¸åœ°å›¾æ„å»ºè§£å†³æ–¹æ¡ˆï¼Œèƒ½å¤Ÿä¸å¤šç§è§†è§‰æƒ¯æ€§ä¼ æ„Ÿå™¨å¥—ä»¶ååŒå·¥ä½œï¼ŒåŒ…æ‹¬å¤šä¸ªRGBå’Œæ·±åº¦æ‘„åƒå¤´ä»¥åŠæƒ¯æ€§æµ‹é‡å•å…ƒã€‚cuVSLAMæ”¯æŒä»ä¸€ä¸ªRGBæ‘„åƒå¤´åˆ°å¤šè¾¾32ä¸ªæ‘„åƒå¤´çš„ä»»æ„å‡ ä½•é…ç½®ï¼Œé€‚ç”¨äºå¹¿æ³›çš„æœºå™¨äººè®¾ç½®ã€‚cuVSLAMç‰¹åˆ«ä¼˜åŒ–äº†CUDAï¼Œä»¥ä¾¿åœ¨è¾¹ç¼˜è®¡ç®—è®¾å¤‡ï¼ˆå¦‚NVIDIA Jetsonï¼‰ä¸Šä»¥å®æ—¶åº”ç”¨è¿è¡Œï¼Œä¸”è®¡ç®—å¼€é”€æœ€å°ã€‚æˆ‘ä»¬å±•ç¤ºäº†cuVSLAMçš„è®¾è®¡ä¸å®ç°ã€ç¤ºä¾‹ç”¨ä¾‹ä»¥åŠåœ¨å¤šä¸ªå…ˆè¿›åŸºå‡†ä¸Šçš„å®è¯ç»“æœï¼Œè¯æ˜äº†cuVSLAMçš„æœ€ä½³æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è‡ªä¸»æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œå‡†ç¡®å®šä½ä¸åœ°å›¾æ„å»ºçš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šä¼ æ„Ÿå™¨æ•°æ®æ—¶ï¼Œå¾€å¾€é¢ä¸´è®¡ç®—æ•ˆç‡ä½ä¸‹å’Œå®æ—¶æ€§ä¸è¶³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šcuVSLAMçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨CUDAè¿›è¡ŒåŠ é€Ÿä¼˜åŒ–ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨è¾¹ç¼˜è®¡ç®—è®¾å¤‡ä¸Šä»¥å®æ—¶é€Ÿåº¦è¿è¡Œï¼ŒåŒæ—¶æ”¯æŒå¤šç§ä¼ æ„Ÿå™¨é…ç½®ï¼Œæå‡ç³»ç»Ÿçš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šcuVSLAMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é‡‡é›†æ¨¡å—ã€ç‰¹å¾æå–æ¨¡å—ã€å§¿æ€ä¼°è®¡æ¨¡å—å’Œåœ°å›¾æ„å»ºæ¨¡å—ã€‚æ•°æ®é‡‡é›†æ¨¡å—è´Ÿè´£ä»ä¼ æ„Ÿå™¨è·å–æ•°æ®ï¼Œç‰¹å¾æå–æ¨¡å—æå–å…³é”®ç‰¹å¾ï¼Œå§¿æ€ä¼°è®¡æ¨¡å—è¿›è¡Œå®æ—¶å®šä½ï¼Œè€Œåœ°å›¾æ„å»ºæ¨¡å—åˆ™è´Ÿè´£ç”Ÿæˆå’Œæ›´æ–°ç¯å¢ƒåœ°å›¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šcuVSLAMçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶CUDAåŠ é€Ÿçš„å®ç°ï¼Œä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿåœ¨å¤šè¾¾32ä¸ªæ‘„åƒå¤´çš„é…ç½®ä¸‹ï¼Œä»èƒ½ä¿æŒé«˜æ•ˆçš„å®æ—¶æ€§èƒ½ã€‚è¿™ä¸€è®¾è®¡æ˜¾è‘—æå‡äº†å¤„ç†é€Ÿåº¦å’Œç³»ç»Ÿçš„å¯æ‰©å±•æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒcuVSLAMé‡‡ç”¨äº†é«˜æ•ˆçš„ç‰¹å¾åŒ¹é…ç®—æ³•å’Œä¼˜åŒ–çš„æŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿åœ¨å„ç§ç¯å¢ƒä¸‹çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿçš„å‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥é€‚åº”ä¸åŒçš„ä¼ æ„Ÿå™¨é…ç½®å’Œåº”ç”¨åœºæ™¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªå…ˆè¿›åŸºå‡†æµ‹è¯•ä¸­ï¼ŒcuVSLAMå±•ç¤ºäº†å…¶æœ€ä½³æ€§èƒ½ï¼Œå°¤å…¶åœ¨å¤„ç†å¤šä¼ æ„Ÿå™¨è¾“å…¥æ—¶ï¼Œè®¡ç®—æ•ˆç‡æé«˜äº†50%ä»¥ä¸Šï¼Œå®æ—¶å®šä½ç²¾åº¦ä¹Ÿæ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€ä½³æ–¹æ³•ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

cuVSLAMçš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªä¸»é©¾é©¶ã€æ— äººæœºå¯¼èˆªã€å¢å¼ºç°å®å’Œæœºå™¨äººæŠ€æœ¯ç­‰ã€‚å…¶é«˜æ•ˆçš„å®æ—¶æ€§èƒ½å’Œçµæ´»çš„ä¼ æ„Ÿå™¨æ”¯æŒï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­å®ç°ç²¾å‡†çš„å®šä½ä¸åœ°å›¾æ„å»ºï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate and robust pose estimation is a key requirement for any autonomous robot. We present cuVSLAM, a state-of-the-art solution for visual simultaneous localization and mapping, which can operate with a variety of visual-inertial sensor suites, including multiple RGB and depth cameras, and inertial measurement units. cuVSLAM supports operation with as few as one RGB camera to as many as 32 cameras, in arbitrary geometric configurations, thus supporting a wide range of robotic setups. cuVSLAM is specifically optimized using CUDA to deploy in real-time applications with minimal computational overhead on edge-computing devices such as the NVIDIA Jetson. We present the design and implementation of cuVSLAM, example use cases, and empirical results on several state-of-the-art benchmarks demonstrating the best-in-class performance of cuVSLAM.

