---
layout: default
title: CARE: Enhancing Safety of Visual Navigation through Collision Avoidance via Repulsive Estimation
---

# CARE: Enhancing Safety of Visual Navigation through Collision Avoidance via Repulsive Estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.03834" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.03834v4</a>
  <a href="https://arxiv.org/pdf/2506.03834.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.03834v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.03834v4', 'CARE: Enhancing Safety of Visual Navigation through Collision Avoidance via Repulsive Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Joonkyung Kim, Joonyeol Sim, Woojun Kim, Katia Sycara, Changjoo Nam

**åˆ†ç±»**: cs.RO, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04 (æ›´æ–°: 2025-08-08)

**å¤‡æ³¨**: 16 pages, 6 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://airlab-sogang.github.io/CARE/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCAREä»¥è§£å†³è§†è§‰å¯¼èˆªä¸­çš„ç¢°æ’é¿å…é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰å¯¼èˆª` `ç¢°æ’é¿å…` `æ·±åº¦ä¼°è®¡` `æœºå™¨äººæŠ€æœ¯` `å®‰å…¨æ€§å¢å¼º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰å¯¼èˆªæ–¹æ³•åœ¨é¢å¯¹æœªè§åœºæ™¯æ—¶ï¼Œå®¹æ˜“äº§ç”Ÿç¢°æ’ï¼Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚
2. CAREæ¨¡å—é€šè¿‡åŠ¨æ€è°ƒæ•´é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆçš„è½¨è¿¹ï¼Œåˆ©ç”¨ä»RGBè¾“å…¥ç›´æ¥ä¼°è®¡çš„æ·±åº¦å›¾åƒè®¡ç®—æ’æ–¥åŠ›å‘é‡ã€‚
3. å®éªŒè¯æ˜ï¼ŒCAREåœ¨å¤šç§æœºå™¨äººå¹³å°ä¸Šæ˜¾è‘—å‡å°‘ç¢°æ’ï¼Œå¹¶æé«˜äº†æ¢ç´¢ä»»åŠ¡çš„è¡Œé©¶è·ç¦»ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†CAREï¼ˆé€šè¿‡æ’æ–¥ä¼°è®¡å®ç°ç¢°æ’é¿å…ï¼‰ï¼Œæ—¨åœ¨æé«˜åŸºäºå­¦ä¹ çš„è§†è§‰å¯¼èˆªæ–¹æ³•çš„é²æ£’æ€§ã€‚è¿‘å¹´æ¥ï¼Œè§†è§‰å¯¼èˆªæ¨¡å‹ï¼Œå°¤å…¶æ˜¯åŸºç¡€æ¨¡å‹ï¼Œé€šè¿‡ä»…ä½¿ç”¨RGBå›¾åƒç”Ÿæˆå¯è¡Œè½¨è¿¹ï¼Œè¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›ç­–ç•¥åœ¨é¢å¯¹åŒ…å«æœªè§ç‰©ä½“æˆ–ä¸åŒç›¸æœºè®¾ç½®ï¼ˆå¦‚è§†åœºå˜åŒ–ã€ç›¸æœºå§¿æ€æˆ–ç„¦è·å˜åŒ–ï¼‰çš„ç¯å¢ƒæ—¶ï¼Œæ³›åŒ–èƒ½åŠ›è¾ƒå·®ï¼Œå¯èƒ½å¯¼è‡´ç¢°æ’ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†CAREï¼Œä¸€ä¸ªå¯é™„åŠ æ¨¡å—ï¼Œå¢å¼ºè§†è§‰å¯¼èˆªçš„å®‰å…¨æ€§ï¼Œæ— éœ€é¢å¤–çš„èŒƒå›´ä¼ æ„Ÿå™¨æˆ–å¯¹é¢„è®­ç»ƒæ¨¡å‹çš„å¾®è°ƒã€‚é€šè¿‡ä¸å¤šç§æœºå™¨äººå¹³å°çš„æœ€å…ˆè¿›è§†è§‰å¯¼èˆªæ¨¡å‹é›†æˆï¼Œå®éªŒè¯æ˜CAREæ˜¾è‘—å‡å°‘ç¢°æ’ï¼ˆé«˜è¾¾100%ï¼‰ï¼ŒåŒæ—¶åœ¨ç›®æ ‡å¯¼å‘å¯¼èˆªä¸­ä¸å½±å“å¯¼èˆªæ€§èƒ½ï¼Œå¹¶åœ¨æ¢ç´¢ä»»åŠ¡ä¸­è¿›ä¸€æ­¥æé«˜æ— ç¢°æ’è¡Œé©¶è·ç¦»ï¼ˆé«˜è¾¾10.7å€ï¼‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è§†è§‰å¯¼èˆªæ¨¡å‹åœ¨æœªè§åœºæ™¯ä¸­å®¹æ˜“å¯¼è‡´ç¢°æ’çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä¸åŒç›¸æœºè®¾ç½®ä¸‹çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œå¯¼è‡´ç”Ÿæˆçš„è½¨è¿¹å­˜åœ¨å®‰å…¨éšæ‚£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCAREæ¨¡å—é€šè¿‡è®¡ç®—æ’æ–¥åŠ›å‘é‡ï¼ŒåŠ¨æ€è°ƒæ•´é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆçš„è½¨è¿¹ï¼Œä»è€Œå¢å¼ºå¯¼èˆªçš„å®‰å…¨æ€§ã€‚è¯¥è®¾è®¡ä¸éœ€è¦é¢å¤–çš„ä¼ æ„Ÿå™¨æˆ–å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œç®€åŒ–äº†åº”ç”¨è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCAREçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªå¯é™„åŠ æ¨¡å—ï¼Œèƒ½å¤Ÿä¸ä»»ä½•åŸºäºRGBçš„å¯¼èˆªæ¨¡å‹æ— ç¼é›†æˆã€‚è¯¥æ¨¡å—é€šè¿‡æ·±åº¦å›¾åƒä¼°è®¡ç”Ÿæˆæ’æ–¥åŠ›å‘é‡ï¼Œå¹¶è°ƒæ•´æœºå™¨äººè½¨è¿¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šCAREçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æ— éœ€é¢å¤–ä¼ æ„Ÿå™¨çš„è®¾è®¡ï¼Œåˆ©ç”¨RGBå›¾åƒç›´æ¥ä¼°è®¡æ·±åº¦ä¿¡æ¯ï¼Œä»è€Œå®ç°ç¢°æ’é¿å…ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿä¾èµ–äºé¢å¤–ä¼ æ„Ÿå™¨çš„æ–¹æ¡ˆæœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šCAREæ¨¡å—çš„è®¾è®¡åŒ…æ‹¬æ·±åº¦å›¾åƒçš„ä¼°è®¡æ–¹æ³•ã€æ’æ–¥åŠ›å‘é‡çš„è®¡ç®—æ–¹å¼ï¼Œä»¥åŠå¦‚ä½•å°†è¿™äº›ä¿¡æ¯æœ‰æ•ˆæ•´åˆåˆ°è½¨è¿¹ç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCAREåœ¨å¤šç§æœºå™¨äººå¹³å°ä¸Šæ˜¾è‘—å‡å°‘äº†ç¢°æ’ï¼Œæœ€é«˜å¯è¾¾100%çš„ç¢°æ’ç‡é™ä½ã€‚åŒæ—¶ï¼Œåœ¨ç›®æ ‡å¯¼å‘å¯¼èˆªä¸­ï¼Œå¯¼èˆªæ€§èƒ½æœªå—å½±å“ï¼Œå¹¶åœ¨æ¢ç´¢ä»»åŠ¡ä¸­æé«˜äº†æ— ç¢°æ’è¡Œé©¶è·ç¦»ï¼Œæœ€é«˜æå‡å¹…åº¦è¾¾åˆ°10.7å€ã€‚è¿™äº›ç»“æœè¡¨æ˜CAREçš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CAREæ¨¡å—å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªä¸»æœºå™¨äººã€æ— äººé©¾é©¶æ±½è½¦å’Œæ— äººæœºç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜è§†è§‰å¯¼èˆªçš„å®‰å…¨æ€§ï¼ŒCAREèƒ½å¤Ÿåœ¨å¤æ‚å’ŒåŠ¨æ€ç¯å¢ƒä¸­å®ç°æ›´å¯é çš„å¯¼èˆªï¼Œå‡å°‘äº‹æ•…é£é™©ï¼Œæå‡ç”¨æˆ·ä¿¡ä»»åº¦ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼ŒCAREæœ‰æœ›åœ¨æ›´å¤šå®é™…åœºæ™¯ä¸­å¾—åˆ°åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We propose CARE (Collision Avoidance via Repulsive Estimation) to improve the robustness of learning-based visual navigation methods. Recently, visual navigation models, particularly foundation models, have demonstrated promising performance by generating viable trajectories using only RGB images. However, these policies can generalize poorly to environments containing out-of-distribution (OOD) scenes characterized by unseen objects or different camera setups (e.g., variations in field of view, camera pose, or focal length). Without fine-tuning, such models could produce trajectories that lead to collisions, necessitating substantial efforts in data collection and additional training. To address this limitation, we introduce CARE, an attachable module that enhances the safety of visual navigation without requiring additional range sensors or fine-tuning of pretrained models. CARE can be integrated seamlessly into any RGB-based navigation model that generates local robot trajectories. It dynamically adjusts trajectories produced by a pretrained model using repulsive force vectors computed from depth images estimated directly from RGB inputs. We evaluate CARE by integrating it with state-of-the-art visual navigation models across diverse robot platforms. Real-world experiments show that CARE significantly reduces collisions (up to 100%) without compromising navigation performance in goal-conditioned navigation, and further improves collision-free travel distance (up to 10.7x) in exploration tasks. Project page: https://airlab-sogang.github.io/CARE/

