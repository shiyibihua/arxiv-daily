---
layout: default
title: SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models
---

# SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.03516" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.03516v1</a>
  <a href="https://arxiv.org/pdf/2506.03516.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.03516v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.03516v1', 'SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Arnab Debnath, Gregory J. Stein, Jana Kosecka

**åˆ†ç±»**: cs.RO, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04

**å¤‡æ³¨**: Accepted at CVPR 2025 workshop - Foundation Models Meet Embodied Agents

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSemNavä»¥è§£å†³é›¶-shotç›®æ ‡ç‰©ä½“å¯¼èˆªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç‰©ä½“ç›®æ ‡å¯¼èˆª` `é›¶-shotå­¦ä¹ ` `è§†è§‰åŸºç¡€æ¨¡å‹` `æ¨¡å‹è§„åˆ’` `é•¿æ—¶é—´å†³ç­–` `æ™ºèƒ½ä½“å¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç‰©ä½“ç›®æ ‡å¯¼èˆªä¸­ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œéš¾ä»¥åœ¨æ–°ç¯å¢ƒä¸­æ³›åŒ–ï¼Œé™åˆ¶äº†åº”ç”¨èŒƒå›´ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§é›¶-shotç‰©ä½“ç›®æ ‡å¯¼èˆªæ¡†æ¶ï¼Œç»“åˆè§†è§‰åŸºç¡€æ¨¡å‹ä¸åŸºäºæ¨¡å‹çš„è§„åˆ’å™¨ï¼Œå¢å¼ºäº†æ™ºèƒ½ä½“çš„å†³ç­–èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨HM3Dæ•°æ®é›†ä¸Šå®ç°äº†é›¶-shotç‰©ä½“ç›®æ ‡å¯¼èˆªçš„æœ€å…ˆè¿›æ€§èƒ½ï¼ŒæˆåŠŸç‡æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç‰©ä½“ç›®æ ‡å¯¼èˆªæ˜¯å…·èº«äººå·¥æ™ºèƒ½ä¸­çš„ä¸€é¡¹åŸºæœ¬ä»»åŠ¡ï¼Œè¦æ±‚æ™ºèƒ½ä½“åœ¨æœªæ¢ç´¢ç¯å¢ƒä¸­å®šä½ç›®æ ‡ç‰©ä½“ã€‚ä¼ ç»Ÿçš„å­¦ä¹ æ–¹æ³•ä¾èµ–äºå¤§é‡æ ‡æ³¨æ•°æ®æˆ–åœ¨å¼ºåŒ–å­¦ä¹ ç¯å¢ƒä¸­è¿›è¡Œå¹¿æ³›äº¤äº’ï¼Œå¾€å¾€æ— æ³•åœ¨æ–°ç¯å¢ƒä¸­æ³›åŒ–ï¼Œé™åˆ¶äº†å¯æ‰©å±•æ€§ã€‚ä¸ºå…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æ¢ç´¢äº†ä¸€ç§é›¶-shotè®¾ç½®ï¼Œä½¿æ™ºèƒ½ä½“åœ¨æ²¡æœ‰ç‰¹å®šä»»åŠ¡è®­ç»ƒçš„æƒ…å†µä¸‹æ“ä½œï¼Œä»è€Œå®ç°æ›´å…·å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§é›¶-shotç‰©ä½“ç›®æ ‡å¯¼èˆªæ¡†æ¶ï¼Œå°†è§†è§‰åŸºç¡€æ¨¡å‹çš„æ„ŸçŸ¥èƒ½åŠ›ä¸åŸºäºæ¨¡å‹çš„è§„åˆ’å™¨ç›¸ç»“åˆï¼Œèƒ½å¤Ÿé€šè¿‡å‰æ²¿æ¢ç´¢è¿›è¡Œé•¿æ—¶é—´å†³ç­–ã€‚æˆ‘ä»¬åœ¨HM3Dæ•°æ®é›†ä¸Šä½¿ç”¨Habitatæ¨¡æ‹Ÿå™¨è¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œç»“æœè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•åœ¨é›¶-shotç‰©ä½“ç›®æ ‡å¯¼èˆªçš„æˆåŠŸç‡å’Œè·¯å¾„é•¿åº¦åŠ æƒæ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç‰©ä½“ç›®æ ‡å¯¼èˆªä¸­çš„é›¶-shoté—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–äºå¤§é‡æ ‡æ³¨æ•°æ®å’Œç¯å¢ƒäº¤äº’ï¼Œå¯¼è‡´åœ¨æ–°ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„SemNavæ¡†æ¶é€šè¿‡ç»“åˆè§†è§‰åŸºç¡€æ¨¡å‹çš„æ„ŸçŸ¥èƒ½åŠ›ä¸æ¨¡å‹é©±åŠ¨çš„è§„åˆ’ç­–ç•¥ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨æœªè®­ç»ƒçš„ç¯å¢ƒä¸­è¿›è¡Œæœ‰æ•ˆå¯¼èˆªã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è§†è§‰åŸºç¡€æ¨¡å‹ç”¨äºåœºæ™¯ç†è§£å’Œç‰©ä½“è¯†åˆ«ï¼Œæ¨¡å‹è§„åˆ’å™¨ç”¨äºé•¿æ—¶é—´å†³ç­–å’Œå‰æ²¿æ¢ç´¢ï¼ŒäºŒè€…ååŒå·¥ä½œä»¥å®ç°ç›®æ ‡å¯¼èˆªã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†è§†è§‰åŸºç¡€æ¨¡å‹ä¸æ¨¡å‹è§„åˆ’å™¨ç»“åˆï¼Œå½¢æˆä¸€ç§æ–°çš„å¯¼èˆªç­–ç•¥ï¼Œä½¿æ™ºèƒ½ä½“åœ¨é›¶-shotè®¾ç½®ä¸‹å…·å¤‡æ›´å¼ºçš„é€‚åº”æ€§å’Œå†³ç­–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å¯¼èˆªè·¯å¾„ï¼Œå¹¶é€šè¿‡è°ƒæ•´æ¨¡å‹å‚æ•°ä»¥å¢å¼ºæ™ºèƒ½ä½“çš„ç¯å¢ƒç†è§£èƒ½åŠ›ï¼Œç¡®ä¿åœ¨ä¸åŒåœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSemNavåœ¨HM3Dæ•°æ®é›†ä¸Šå®ç°äº†é›¶-shotç‰©ä½“ç›®æ ‡å¯¼èˆªçš„æœ€å…ˆè¿›æ€§èƒ½ï¼ŒæˆåŠŸç‡ä¸è·¯å¾„é•¿åº¦åŠ æƒçš„æŒ‡æ ‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½å®¶å±…ç³»ç»Ÿä»¥åŠè‡ªåŠ¨é©¾é©¶ç­‰åœºæ™¯ã€‚é€šè¿‡å®ç°é›¶-shotç›®æ ‡å¯¼èˆªï¼Œæ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨æœªçŸ¥ç¯å¢ƒä¸­è‡ªä¸»å®šä½å’Œæ“ä½œï¼Œæå‡äº†ç³»ç»Ÿçš„çµæ´»æ€§å’Œé€‚åº”æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Object goal navigation is a fundamental task in embodied AI, where an agent is instructed to locate a target object in an unexplored environment. Traditional learning-based methods rely heavily on large-scale annotated data or require extensive interaction with the environment in a reinforcement learning setting, often failing to generalize to novel environments and limiting scalability. To overcome these challenges, we explore a zero-shot setting where the agent operates without task-specific training, enabling more scalable and adaptable solution. Recent advances in Vision Foundation Models (VFMs) offer powerful capabilities for visual understanding and reasoning, making them ideal for agents to comprehend scenes, identify relevant regions, and infer the likely locations of objects. In this work, we present a zero-shot object goal navigation framework that integrates the perceptual strength of VFMs with a model-based planner that is capable of long-horizon decision making through frontier exploration. We evaluate our approach on the HM3D dataset using the Habitat simulator and demonstrate that our method achieves state-of-the-art performance in terms of success weighted by path length for zero-shot object goal navigation.

