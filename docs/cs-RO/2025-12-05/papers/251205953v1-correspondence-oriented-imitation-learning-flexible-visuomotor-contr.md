---
layout: default
title: Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning
---

# Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.05953" target="_blank" class="toolbar-btn">arXiv: 2512.05953v1</a>
    <a href="https://arxiv.org/pdf/2512.05953.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.05953v1" 
            onclick="toggleFavorite(this, '2512.05953v1', 'Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yunhao Cao, Zubin Bhaumik, Jessie Jia, Xingyi He, Kuan Fang

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-05

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Èù¢ÂêëÂØπÂ∫îÂÖ≥Á≥ªÁöÑÊ®°‰ªøÂ≠¶‰π†Ê°ÜÊû∂COILÔºåÂÆûÁé∞ÁÅµÊ¥ªÁöÑ3DËßÜËßâËøêÂä®ÊéßÂà∂„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ê®°‰ªøÂ≠¶‰π†` `ËßÜËßâËøêÂä®ÊéßÂà∂` `ÂØπÂ∫îÂÖ≥Á≥ª` `Êó∂Á©∫Ê≥®ÊÑèÂäõ` `Êú∫Âô®‰∫∫Êìç‰Ωú`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜËßâËøêÂä®ÊéßÂà∂ÊñπÊ≥ïÈöæ‰ª•Â§ÑÁêÜ‰ªªÂä°ËßÑËåÉ‰∏≠ÂÖ≥ÈîÆÁÇπÊï∞ÈáèÂíåÊó∂Èó¥Èó¥ÈöîÂèòÂåñÁöÑÊÉÖÂÜµ„ÄÇ
2. COILÈÄöËøáÂÆö‰πâÁâ©‰ΩìÂÖ≥ÈîÆÁÇπÁöÑÈ¢ÑÊúüËøêÂä®Êù•Ë°®Á§∫‰ªªÂä°ÔºåÂπ∂Âà©Áî®Êó∂Á©∫Ê≥®ÊÑèÂäõÊú∫Âà∂ËûçÂêàÂ§öÊ®°ÊÄÅ‰ø°ÊÅØ„ÄÇ
3. COILÂú®ÁúüÂÆûÊìç‰Ωú‰ªªÂä°‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåËÉΩÂ§üÊ≥õÂåñÂà∞‰∏çÂêåÁöÑ‰ªªÂä°„ÄÅÂØπË±°ÂíåËøêÂä®Ê®°Âºè„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÈù¢ÂêëÂØπÂ∫îÂÖ≥Á≥ªÁöÑÊ®°‰ªøÂ≠¶‰π†Ê°ÜÊû∂ÔºàCOILÔºâÔºåÁî®‰∫éÂÖ∑ÊúâÁÅµÊ¥ª3D‰ªªÂä°Ë°®Á§∫ÁöÑËßÜËßâËøêÂä®ÊéßÂà∂„ÄÇËØ•ÊñπÊ≥ïÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂ∞ÜÊØè‰∏™‰ªªÂä°ÂÆö‰πâ‰∏∫Âú∫ÊôØ‰∏≠Áâ©‰Ωì‰∏äÈÄâÂÆöÂÖ≥ÈîÆÁÇπÁöÑÈ¢ÑÊúüËøêÂä®„ÄÇCOILÊîØÊåÅÂÖ∑ÊúâÂèØÂèòÁ©∫Èó¥ÂíåÊó∂Èó¥Á≤íÂ∫¶ÁöÑ‰ªªÂä°ËßÑËåÉÔºåËÉΩÂ§üÈÄÇÂ∫î‰∏çÂêåÁöÑÁî®Êà∑ÊÑèÂõæÂíå‰ªªÂä°ÈúÄÊ±ÇÔºåËÄåÊó†ÈúÄÂÅáËÆæÂõ∫ÂÆöÊï∞ÈáèÁöÑÂÖ≥ÈîÆÁÇπÊàñÂùáÂåÄÈó¥ÈöîÁöÑÊó∂Èó¥Èó¥Èöî„ÄÇ‰∏∫‰∫ÜÂ∞ÜËøôÁßçÈù¢ÂêëÂØπÂ∫îÂÖ≥Á≥ªÁöÑ‰ªªÂä°Ë°®Á§∫Á®≥ÂÅ•Âú∞ËûçÂÖ•Âà∞Âä®‰Ωú‰∏≠ÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™ÂÖ∑ÊúâÊó∂Á©∫Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÊù°‰ª∂Á≠ñÁï•ÔºåËØ•Êú∫Âà∂ÊúâÊïàÂú∞ËûçÂêà‰∫ÜË∑®Â§ö‰∏™ËæìÂÖ•Ê®°ÊÄÅÁöÑ‰ø°ÊÅØ„ÄÇËØ•Á≠ñÁï•ÈÄöËøáÂèØÊâ©Â±ïÁöÑËá™ÁõëÁù£ÊµÅÁ®ãËøõË°åËÆ≠ÁªÉÔºå‰ΩøÁî®Âú®Ê®°Êãü‰∏≠Êî∂ÈõÜÁöÑÊºîÁ§∫ÔºåÂπ∂Ëá™Âä®ÁîüÊàê‰∫ãÂêéÂØπÂ∫îÊ†áÁ≠æ„ÄÇCOILÂèØ‰ª•Ê≥õÂåñÂà∞‰∏çÂêåÁöÑ‰ªªÂä°„ÄÅÂØπË±°ÂíåËøêÂä®Ê®°ÂºèÔºåÂú®Á®ÄÁñèÂíåÂØÜÈõÜËßÑËåÉ‰∏ãÁöÑÁúüÂÆû‰∏ñÁïåÊìç‰Ωú‰ªªÂä°‰∏≠Ôºå‰∏éÂÖàÂâçÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜËßâËøêÂä®ÊéßÂà∂ÊñπÊ≥ïÈÄöÂ∏∏ÂÅáËÆæÂõ∫ÂÆöÁöÑÂÖ≥ÈîÆÁÇπÊï∞ÈáèÂíåÂùáÂåÄÁöÑÊó∂Èó¥Èó¥ÈöîÔºåËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®Â§ÑÁêÜÂÖ∑Êúâ‰∏çÂêåÁ©∫Èó¥ÂíåÊó∂Èó¥Á≤íÂ∫¶ÁöÑ‰ªªÂä°ËßÑËåÉÊó∂ÁöÑÁÅµÊ¥ªÊÄß„ÄÇÊ≠§Â§ñÔºåÂ∞Ü‰ªªÂä°Ë°®Á§∫‰∏éÂä®‰ΩúÂÖ≥ËÅîËµ∑Êù•‰πüÈù¢‰∏¥ÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®ÁúüÂÆû‰∏ñÁïåÂú∫ÊôØ‰∏≠„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöCOILÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Áâ©‰Ωì‰∏äÁöÑÂÖ≥ÈîÆÁÇπÂØπÂ∫îÂÖ≥Á≥ªÊù•ÂÆö‰πâ‰ªªÂä°ÔºåÂπ∂Â≠¶‰π†‰∏Ä‰∏™Êù°‰ª∂Á≠ñÁï•ÔºåËØ•Á≠ñÁï•ËÉΩÂ§üÊ†πÊçÆËøô‰∫õÂØπÂ∫îÂÖ≥Á≥ªÁîüÊàêÂä®‰Ωú„ÄÇÈÄöËøáÂºïÂÖ•Êó∂Á©∫Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåCOILÂèØ‰ª•ÊúâÊïàÂú∞ËûçÂêàÊù•Ëá™‰∏çÂêåÊ®°ÊÄÅÁöÑ‰ø°ÊÅØÔºå‰ªéËÄåÂÆûÁé∞Êõ¥È≤ÅÊ£íÁöÑÊéßÂà∂„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCOILÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÊ®°ÂùóÔºö1) ‰ªªÂä°Ë°®Á§∫Ê®°ÂùóÔºåÁî®‰∫éÂÆö‰πâÁâ©‰Ωì‰∏äÁöÑÂÖ≥ÈîÆÁÇπÂèäÂÖ∂È¢ÑÊúüËøêÂä®Ôºõ2) Êù°‰ª∂Á≠ñÁï•Ê®°ÂùóÔºåËØ•Á≠ñÁï•Êé•Êî∂ËßÜËßâËæìÂÖ•Âíå‰ªªÂä°Ë°®Á§∫‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂ÁîüÊàêÁõ∏Â∫îÁöÑÂä®‰ΩúÔºõ3) Êó∂Á©∫Ê≥®ÊÑèÂäõÊ®°ÂùóÔºåÁî®‰∫éËûçÂêàÊù•Ëá™‰∏çÂêåÊ®°ÊÄÅÁöÑ‰ø°ÊÅØÔºåÂπ∂ÂÖ≥Ê≥®‰∏éÂΩìÂâç‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÂÖ≥ÈîÆÁÇπÔºõ4) Ëá™ÁõëÁù£ËÆ≠ÁªÉÊµÅÁ®ãÔºåÂà©Áî®Ê®°ÊãüÊï∞ÊçÆÂíå‰∫ãÂêéÂØπÂ∫îÊ†áÁ≠æÊù•ËÆ≠ÁªÉÁ≠ñÁï•„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöCOILÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Èù¢ÂêëÂØπÂ∫îÂÖ≥Á≥ªÁöÑ‰ªªÂä°Ë°®Á§∫ÂíåÊó∂Á©∫Ê≥®ÊÑèÂäõÊú∫Âà∂„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåCOILËÉΩÂ§üÂ§ÑÁêÜÂÖ∑ÊúâÂèØÂèòÁ©∫Èó¥ÂíåÊó∂Èó¥Á≤íÂ∫¶ÁöÑ‰ªªÂä°ËßÑËåÉÔºåÂπ∂‰∏îËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®Â§öÊ®°ÊÄÅ‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåCOILÁöÑËá™ÁõëÁù£ËÆ≠ÁªÉÊµÅÁ®ã‰ΩøÂÖ∂ËÉΩÂ§üÂà©Áî®Â§ßÈáèÁöÑÊ®°ÊãüÊï∞ÊçÆËøõË°åËÆ≠ÁªÉÔºå‰ªéËÄåÊèêÈ´òÂÖ∂Ê≥õÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöCOIL‰ΩøÁî®TransformerÁΩëÁªú‰Ωú‰∏∫ÂÖ∂Êù°‰ª∂Á≠ñÁï•ÁöÑÂü∫Á°ÄÊû∂ÊûÑÔºåÂπ∂ÂºïÂÖ•‰∫ÜÊó∂Á©∫Ê≥®ÊÑèÂäõÊú∫Âà∂Êù•ËûçÂêàËßÜËßâËæìÂÖ•Âíå‰ªªÂä°Ë°®Á§∫„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨Ê®°‰ªøÂ≠¶‰π†ÊçüÂ§±ÂíåÊ≠£ÂàôÂåñÈ°πÔºå‰ª•ÈºìÂä±Á≠ñÁï•Â≠¶‰π†Âà∞Âπ≥ÊªëÁöÑÂä®‰Ωú„ÄÇËá™ÁõëÁù£ËÆ≠ÁªÉÊµÅÁ®ãÂà©Áî®‰∫ãÂêéÂØπÂ∫îÊ†áÁ≠æÊù•ÁîüÊàêËÆ≠ÁªÉÊï∞ÊçÆÔºå‰ªéËÄåÈÅøÂÖç‰∫ÜÊâãÂä®Ê†áÊ≥®ÁöÑÈúÄË¶Å„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÔºàÂ¶ÇTransformerÂ±ÇÊï∞„ÄÅÊ≥®ÊÑèÂäõÂ§¥Êï∞Á≠âÔºâÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

COILÂú®ÁúüÂÆû‰∏ñÁïåÊìç‰Ωú‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåCOILÂú®Á®ÄÁñèÂíåÂØÜÈõÜËßÑËåÉ‰∏ãÂùáË°®Áé∞Âá∫Êõ¥Âº∫ÁöÑÊ≥õÂåñËÉΩÂäõÂíåÊõ¥È´òÁöÑÊàêÂäüÁéá„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜËÆ∫ÊñáÂº∫Ë∞É‰∫ÜCOILÂú®‰∏çÂêå‰ªªÂä°„ÄÅÂØπË±°ÂíåËøêÂä®Ê®°Âºè‰∏ãÁöÑ‰ºòË∂äÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

COILÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºå‰æãÂ¶ÇÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÅËá™Âä®ÂåñË£ÖÈÖç„ÄÅ‰∫∫Êú∫Âçè‰ΩúÁ≠â„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éÊéßÂà∂Êú∫Âô®‰∫∫ÊâßË°åÂêÑÁßçÂ§çÊùÇÁöÑ‰ªªÂä°Ôºå‰æãÂ¶ÇÊäìÂèñ„ÄÅÊîæÁΩÆ„ÄÅÁªÑË£ÖÁ≠â„ÄÇÊ≠§Â§ñÔºåCOILËøòÂèØ‰ª•Áî®‰∫éÂºÄÂèëÊõ¥Êô∫ËÉΩÁöÑ‰∫∫Êú∫‰∫§‰∫íÁ≥ªÁªüÔºå‰Ωø‰∫∫Á±ªËÉΩÂ§üÊõ¥Ëá™ÁÑ∂Âú∞‰∏éÊú∫Âô®‰∫∫ËøõË°å‰∫§‰∫í„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We introduce Correspondence-Oriented Imitation Learning (COIL), a conditional policy learning framework for visuomotor control with a flexible task representation in 3D. At the core of our approach, each task is defined by the intended motion of keypoints selected on objects in the scene. Instead of assuming a fixed number of keypoints or uniformly spaced time intervals, COIL supports task specifications with variable spatial and temporal granularity, adapting to different user intents and task requirements. To robustly ground this correspondence-oriented task representation into actions, we design a conditional policy with a spatio-temporal attention mechanism that effectively fuses information across multiple input modalities. The policy is trained via a scalable self-supervised pipeline using demonstrations collected in simulation, with correspondence labels automatically generated in hindsight. COIL generalizes across tasks, objects, and motion patterns, achieving superior performance compared to prior methods on real-world manipulation tasks under both sparse and dense specifications.

