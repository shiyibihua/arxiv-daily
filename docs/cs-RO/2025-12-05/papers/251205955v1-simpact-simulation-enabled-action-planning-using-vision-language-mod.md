---
layout: default
title: SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models
---

# SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.05955" target="_blank" class="toolbar-btn">arXiv: 2512.05955v1</a>
    <a href="https://arxiv.org/pdf/2512.05955.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.05955v1" 
            onclick="toggleFavorite(this, '2512.05955v1', 'SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Haowen Liu, Shaoxiong Yao, Haonan Chen, Jiawei Gao, Jiayuan Mao, Jia-Bin Huang, Yilun Du

**ÂàÜÁ±ª**: cs.RO, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-05

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**SIMPACTÔºöÂà©Áî®ËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÂíå‰ªøÁúüËøõË°åÂä®‰ΩúËßÑÂàíÔºåËß£ÂÜ≥Êú∫Âô®‰∫∫Êìç‰Ωú‰∏≠Áâ©ÁêÜÁêÜËß£‰∏çË∂≥ÁöÑÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã` `Êú∫Âô®‰∫∫Êìç‰Ωú` `Áâ©ÁêÜ‰ªøÁúü` `Âä®‰ΩúËßÑÂàí` `ÂÖ∑Ë∫´Êô∫ËÉΩ` `Áâ©ÁêÜÊé®ÁêÜ` `‰ªøÁúüÂæ™ÁéØ` `RGB-DÊÑüÁü•`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÁº∫‰πèÂØπÁâ©ÁêÜÂä®ÊÄÅÁöÑÂÖ∑Ë∫´ÁêÜËß£ÔºåÈöæ‰ª•Â∫îÁî®‰∫éÈúÄË¶ÅÁâ©ÁêÜÊé®ÁêÜÁöÑÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°„ÄÇ
2. SIMPACTÈÄöËøáÂú®ÊµãËØïÊó∂ÊûÑÂª∫‰ªøÁúüÁéØÂ¢ÉÔºåËÆ©VLMÂú®‰ªøÁúü‰∏≠ËøõË°åÂä®‰ΩúËßÑÂàíÂíåÊé®ÁêÜÔºå‰ªéËÄåËµã‰∫àÂÖ∂Áâ©ÁêÜÁêÜËß£ËÉΩÂäõ„ÄÇ
3. SIMPACTÂú®ÁúüÂÆû‰∏ñÁïåÁöÑÂàö‰ΩìÂíåÂèØÂèòÂΩ¢‰ΩìÊìç‰Ωú‰ªªÂä°‰∏äÂèñÂæó‰∫Ü‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÁöÑÊÄßËÉΩÔºåËØÅÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËßÜËßâ-ËØ≠Ë®ÄÊ®°Âûã(VLMs)Â±ïÁé∞‰∫ÜÂçìË∂äÁöÑÂ∏∏ËØÜÂíåËØ≠‰πâÊé®ÁêÜËÉΩÂäõÔºå‰ΩÜÁº∫‰πèÂØπÁâ©ÁêÜÂä®ÊÄÅÁöÑÂÖ∑Ë∫´ÁêÜËß£„ÄÇËøôÊòØÂõ†‰∏∫VLMsÂú®ÈùôÊÄÅÁöÑ‰∫íËÅîÁΩëËßÑÊ®°ËßÜËßâ-ËØ≠Ë®ÄÊï∞ÊçÆ‰∏äËÆ≠ÁªÉÔºåËøô‰∫õÊï∞ÊçÆ‰∏çÂåÖÂê´Âõ†Êûú‰∫§‰∫íÊàñÂä®‰ΩúÊù°‰ª∂‰∏ãÁöÑÂèòÂåñ„ÄÇÂõ†Ê≠§ÔºåÂ∞ÜVLMsÁî®‰∫éÈúÄË¶ÅÁâ©ÁêÜÁêÜËß£„ÄÅÊé®ÁêÜÂíåÁõ∏Â∫îÂä®‰ΩúËßÑÂàíÁöÑÁ≤æÁªÜÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊàòÊÄß„ÄÇ‰∏∫‰∫ÜÂÖãÊúçËøô‰∏ÄÁÇπÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜSIMPACTÔºåËøôÊòØ‰∏Ä‰∏™ÊµãËØïÊó∂„ÄÅÂü∫‰∫é‰ªøÁúüÁöÑÂä®‰ΩúËßÑÂàíÊ°ÜÊû∂ÔºåÈÄöËøá‰ªøÁúüÂæ™ÁéØ‰∏ñÁïåÂª∫Ê®°Ëµã‰∫àVLMsÁâ©ÁêÜÊé®ÁêÜËÉΩÂäõÔºåËÄåÊó†ÈúÄ‰ªª‰ΩïÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉ„ÄÇ‰ªéÂçï‰∏™RGB-DËßÇÊµã‰∏≠ÔºåSIMPACTÊúâÊïàÂú∞ÊûÑÂª∫Áâ©ÁêÜ‰ªøÁúüÔºå‰ΩøVLMËÉΩÂ§üÊèêÂá∫ÊòéÊô∫ÁöÑÂä®‰ΩúÔºåËßÇÂØüÊ®°ÊãüÁöÑrolloutÔºåÂπ∂Ëø≠‰ª£Âú∞ÊîπËøõÂÖ∂Êé®ÁêÜ„ÄÇÈÄöËøáÂ∞ÜËØ≠Ë®ÄÊé®ÁêÜ‰∏éÁâ©ÁêÜÈ¢ÑÊµãÁõ∏ÁªìÂêàÔºåÊàë‰ª¨Âü∫‰∫é‰ªøÁúüÁöÑVLMËÉΩÂ§ü‰ª•Áâ©ÁêÜÂÖ∑Ë∫´ÁöÑÊñπÂºèÁêÜËß£Êé•Ëß¶Âä®ÂäõÂ≠¶ÂíåÂä®‰ΩúÁªìÊûú„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®‰∫î‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÁúüÂÆûÂàö‰ΩìÂíåÂèØÂèòÂΩ¢‰ΩìÊìç‰Ωú‰ªªÂä°‰∏äË°®Áé∞Âá∫ÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåËøô‰∫õ‰ªªÂä°ÈúÄË¶ÅÁ≤æÁªÜÁöÑÁâ©ÁêÜÊé®ÁêÜÔºå‰ºò‰∫éÁé∞ÊúâÁöÑÈÄöÁî®Êú∫Âô®‰∫∫Êìç‰ΩúÊ®°Âûã„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúË°®ÊòéÔºåÂú®ÊµãËØïÊó∂ÈÄöËøáÈ´òÊïà‰ªøÁúüÂ∞ÜÁâ©ÁêÜÁêÜËß£ÂµåÂÖ•Âà∞VLMÊé®ÁêÜ‰∏≠Ôºå‰∏∫ÂÆûÁé∞ÈÄöÁî®ÂÖ∑Ë∫´Êô∫ËÉΩÊèê‰æõ‰∫Ü‰∏ÄÊù°ÊúâÂ∏åÊúõÁöÑÈÄîÂæÑ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ËßÜËßâ-ËØ≠Ë®ÄÊ®°ÂûãÔºàVLMsÔºâÂú®Êú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°‰∏≠Áî±‰∫éÁº∫‰πèÁâ©ÁêÜ‰∏ñÁïåÁêÜËß£ËÄåË°®Áé∞‰∏ç‰Ω≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÁöÑVLMs‰∏ªË¶ÅÂú®ÈùôÊÄÅÂõæÂÉèÂíåÊñáÊú¨Êï∞ÊçÆ‰∏äËÆ≠ÁªÉÔºåÁº∫‰πèÂØπÂä®‰Ωú‰∏éÁéØÂ¢É‰∫§‰∫íÁöÑÂõ†ÊûúÂÖ≥Á≥ªÂª∫Ê®°ËÉΩÂäõÔºåÂõ†Ê≠§Èöæ‰ª•ËøõË°åÈúÄË¶ÅÁ≤æÁªÜÁâ©ÁêÜÊé®ÁêÜÁöÑÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSIMPACTÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂú®ÊµãËØïÊó∂ÔºåÂà©Áî®VLMËøõË°åÂä®‰ΩúËßÑÂàíÁöÑÂêåÊó∂ÔºåÊûÑÂª∫‰∏Ä‰∏™‰ªøÁúüÁéØÂ¢ÉÔºåËÆ©VLMÂú®‰ªøÁúüÁéØÂ¢É‰∏≠ËøõË°årolloutÔºåËßÇÂØüÂä®‰ΩúÁöÑÁâ©ÁêÜÊïàÊûúÔºåÂπ∂Ê†πÊçÆ‰ªøÁúüÁªìÊûúËø≠‰ª£‰ºòÂåñÂä®‰ΩúËßÑÂàí„ÄÇÈÄöËøáËøôÁßç‰ªøÁúüÂæ™ÁéØÁöÑÊñπÂºèÔºåËµã‰∫àVLMÁâ©ÁêÜÊé®ÁêÜËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£Âä®‰Ωú‰∏éÁéØÂ¢É‰πãÈó¥ÁöÑ‰∫§‰∫í„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSIMPACTÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ‰ªéRGB-DÂõæÂÉèÊûÑÂª∫Áâ©ÁêÜ‰ªøÁúüÁéØÂ¢ÉÔºõ2) VLMÊ†πÊçÆÂΩìÂâçÁä∂ÊÄÅÊèêÂá∫ÂÄôÈÄâÂä®‰ΩúÔºõ3) Âú®‰ªøÁúüÁéØÂ¢É‰∏≠ÊâßË°åÂÄôÈÄâÂä®‰ΩúÔºåÂπ∂ËßÇÂØürolloutÁªìÊûúÔºõ4) VLMÊ†πÊçÆrolloutÁªìÊûúËØÑ‰º∞Âä®‰ΩúÁöÑ‰ºòÂä£ÔºåÂπ∂Ëø≠‰ª£‰ºòÂåñÂä®‰ΩúËßÑÂàí„ÄÇËøô‰∏™ËøáÁ®ãÂæ™ÁéØËøõË°åÔºåÁõ¥Âà∞ÊâæÂà∞ÊúÄ‰ºòÁöÑÂä®‰ΩúÂ∫èÂàó„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSIMPACTÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜVLMÁöÑËØ≠Ë®ÄÊé®ÁêÜËÉΩÂäõ‰∏éÁâ©ÁêÜ‰ªøÁúüÁõ∏ÁªìÂêàÔºåÂú®ÊµãËØïÊó∂Ëµã‰∫àVLMÁâ©ÁêÜÁêÜËß£ËÉΩÂäõÔºåËÄåÊó†ÈúÄÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉ„ÄÇËøôÁßçÊñπÊ≥ïÂÖÖÂàÜÂà©Áî®‰∫ÜVLMÁöÑËØ≠‰πâÊé®ÁêÜËÉΩÂäõÔºåÂêåÊó∂Âº•Ë°•‰∫ÜÂÖ∂Âú®Áâ©ÁêÜÁêÜËß£ÊñπÈù¢ÁöÑ‰∏çË∂≥„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåSIMPACT‰∏çÈúÄË¶ÅÈ¢ÑÂÖàËÆ≠ÁªÉ‰∏Ä‰∏™Â§çÊùÇÁöÑÁâ©ÁêÜÊ®°ÂûãÔºåËÄåÊòØÈÄöËøáÂú®Á∫ø‰ªøÁúüÊù•Â≠¶‰π†Áâ©ÁêÜÂä®ÊÄÅ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöSIMPACTÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Â¶Ç‰ΩïÈ´òÊïàÂú∞‰ªéRGB-DÂõæÂÉèÊûÑÂª∫Áâ©ÁêÜ‰ªøÁúüÁéØÂ¢ÉÔºõ2) Â¶Ç‰ΩïËÆæËÆ°VLMÁöÑÂä®‰ΩúÊèêËÆÆÂíåËØÑ‰º∞Êú∫Âà∂Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÊúâÊïàÂú∞Âà©Áî®‰ªøÁúüÁªìÊûúËøõË°åÂä®‰ΩúËßÑÂàíÔºõ3) Â¶Ç‰ΩïÂπ≥Ë°°‰ªøÁúüÁ≤æÂ∫¶ÂíåËÆ°ÁÆóÊïàÁéáÔºå‰ª•‰øùËØÅSIMPACTÁöÑÂÆûÊó∂ÊÄß„ÄÇËÆ∫Êñá‰∏≠ÂèØËÉΩÊ∂âÂèä‰∏Ä‰∫õÁâπÂÆöÁöÑÂèÇÊï∞ËÆæÁΩÆÔºå‰æãÂ¶Ç‰ªøÁúüÊ≠•Èïø„ÄÅrolloutÈïøÂ∫¶„ÄÅVLMÁöÑpromptËÆæËÆ°Á≠âÔºå‰ΩÜÂÖ∑‰ΩìÁªÜËäÇÈúÄË¶ÅÂèÇËÄÉËÆ∫ÊñáÂéüÊñá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SIMPACTÂú®‰∫î‰∏™ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÁúüÂÆûÂàö‰ΩìÂíåÂèØÂèòÂΩ¢‰ΩìÊìç‰Ωú‰ªªÂä°‰∏äÂèñÂæó‰∫Üstate-of-the-artÁöÑÊÄßËÉΩÔºåË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÈÄöÁî®Êú∫Âô®‰∫∫Êìç‰ΩúÊ®°Âûã„ÄÇËøôË°®ÊòéÈÄöËøáÂú®ÊµãËØïÊó∂Â∞ÜÁâ©ÁêÜÁêÜËß£ÂµåÂÖ•Âà∞VLMÊé®ÁêÜ‰∏≠ÔºåÂèØ‰ª•ÊòæËëóÊèêÂçáÊú∫Âô®‰∫∫ÁöÑÊìç‰ΩúËÉΩÂäõ„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊï∞ÊçÆÂíåÊèêÂçáÂπÖÂ∫¶ÈúÄË¶ÅÂú®ËÆ∫ÊñáÂéüÊñá‰∏≠Êü•Êâæ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SIMPACTÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÁ≤æÁªÜÁâ©ÁêÜÊé®ÁêÜÁöÑÊú∫Âô®‰∫∫Êìç‰Ωú‰ªªÂä°Ôºå‰æãÂ¶ÇÔºöÂÆ∂Â∫≠ÊúçÂä°Êú∫Âô®‰∫∫„ÄÅÂ∑•‰∏öËá™Âä®Âåñ„ÄÅÂåªÁñóÊú∫Âô®‰∫∫Á≠â„ÄÇËØ•Á†îÁ©∂ÊúâÂä©‰∫éÊèêÂçáÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÈÄÇÂ∫îÊÄßÂíåÊìç‰ΩúËÉΩÂäõÔºåÊé®Âä®Êú∫Âô®‰∫∫ÊäÄÊúØÁöÑÊô∫ËÉΩÂåñÂèëÂ±ïÔºåÂπ∂ÊúÄÁªàÂÆûÁé∞ÈÄöÁî®ÂÖ∑Ë∫´Êô∫ËÉΩ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Vision-Language Models (VLMs) exhibit remarkable common-sense and semantic reasoning capabilities. However, they lack a grounded understanding of physical dynamics. This limitation arises from training VLMs on static internet-scale visual-language data that contain no causal interactions or action-conditioned changes. Consequently, it remains challenging to leverage VLMs for fine-grained robotic manipulation tasks that require physical understanding, reasoning, and corresponding action planning. To overcome this, we present SIMPACT, a test-time, SIMulation-enabled ACTion Planning framework that equips VLMs with physical reasoning through simulation-in-the-loop world modeling, without requiring any additional training. From a single RGB-D observation, SIMPACT efficiently constructs physics simulations, enabling the VLM to propose informed actions, observe simulated rollouts, and iteratively refine its reasoning. By integrating language reasoning with physics prediction, our simulation-enabled VLM can understand contact dynamics and action outcomes in a physically grounded way. Our method demonstrates state-of-the-art performance on five challenging, real-world rigid-body and deformable manipulation tasks that require fine-grained physical reasoning, outperforming existing general-purpose robotic manipulation models. Our results demonstrate that embedding physics understanding via efficient simulation into VLM reasoning at test time offers a promising path towards generalizable embodied intelligence. Project webpage can be found at https://simpact-bot.github.io

