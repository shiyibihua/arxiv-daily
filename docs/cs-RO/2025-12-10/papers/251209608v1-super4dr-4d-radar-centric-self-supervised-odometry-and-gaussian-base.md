---
layout: default
title: Super4DR: 4D Radar-centric Self-supervised Odometry and Gaussian-based Map Optimization
---

# Super4DR: 4D Radar-centric Self-supervised Odometry and Gaussian-based Map Optimization

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.09608" target="_blank" class="toolbar-btn">arXiv: 2512.09608v1</a>
    <a href="https://arxiv.org/pdf/2512.09608.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.09608v1" 
            onclick="toggleFavorite(this, '2512.09608v1', 'Super4DR: 4D Radar-centric Self-supervised Odometry and Gaussian-based Map Optimization')" title="æ”¶è—">
      â˜† æ”¶è—
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="å¤åˆ¶é“¾æ¥">
      ğŸ”— åˆ†äº«
    </button>
  </div>
</div>


**ä½œè€…**: Zhiheng Li, Weihua Wang, Qiang Shen, Yichen Zhao, Zheng Fang

**åˆ†ç±»**: cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-10

**å¤‡æ³¨**: 17 pages, 20 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Super4DRï¼šé¢å‘4Dé›·è¾¾çš„è‡ªç›‘ç£é‡Œç¨‹è®¡ä¸é«˜æ–¯ä¼˜åŒ–å»ºå›¾**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `4Dé›·è¾¾` `è‡ªç›‘ç£å­¦ä¹ ` `é‡Œç¨‹è®¡` `SLAM` `é«˜æ–¯ä¼˜åŒ–` `ç‚¹äº‘å¤„ç†` `æœºå™¨äººå¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»ŸSLAMåœ¨æ¶åŠ£ç¯å¢ƒä¸‹è¡¨ç°ä¸ä½³ï¼Œ4Dé›·è¾¾æ•°æ®è™½é€‚ç”¨ï¼Œä½†å…¶ç¨€ç–æ€§å’Œå™ªå£°é˜»ç¢äº†ç²¾ç¡®çš„é‡Œç¨‹è®¡ä¼°è®¡ã€‚
2. Super4DRåˆ©ç”¨èšç±»æ„ŸçŸ¥çš„é‡Œç¨‹è®¡ç½‘ç»œå’Œåˆ†å±‚è‡ªç›‘ç£æœºåˆ¶ï¼Œæå‡å¸§é—´åŒ¹é…ç²¾åº¦å¹¶å…‹æœå¼‚å¸¸å€¼ã€‚
3. é€šè¿‡3Dé«˜æ–¯è¡¨ç¤ºå’Œé›·è¾¾ç‰¹å®šä¼˜åŒ–ç­–ç•¥ï¼ŒSuper4DRèƒ½å¤Ÿæ¢å¤æ¨¡ç³Šå’Œæœªæ£€æµ‹åˆ°çš„åœ°å›¾åŒºåŸŸï¼Œæå‡åœ°å›¾è´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºSuper4DRï¼Œä¸€ä¸ªä»¥4Dé›·è¾¾ä¸ºä¸­å¿ƒçš„æ¡†æ¶ï¼Œç”¨äºå­¦ä¹ å‹é‡Œç¨‹è®¡ä¼°è®¡å’ŒåŸºäºé«˜æ–¯çš„åœ°å›¾ä¼˜åŒ–ã€‚é’ˆå¯¹ä¼ ç»Ÿè§†è§‰æˆ–æ¿€å…‰é›·è¾¾SLAMç³»ç»Ÿåœ¨å…‰ç…§ä¸è¶³å’Œæ¶åŠ£å¤©æ°”ä¸‹çš„å±€é™æ€§ï¼Œä»¥åŠ4Dé›·è¾¾ç‚¹äº‘çš„ç¨€ç–æ€§å’Œå™ªå£°é—®é¢˜ï¼Œæœ¬æ–‡è®¾è®¡äº†ä¸€ä¸ªèšç±»æ„ŸçŸ¥çš„é‡Œç¨‹è®¡ç½‘ç»œï¼Œè¯¥ç½‘ç»œç»“åˆäº†æ¥è‡ªèšç±»é›·è¾¾ç‚¹çš„å¯¹è±¡çº§çº¿ç´¢ç”¨äºå¸§é—´åŒ¹é…ï¼Œå¹¶é‡‡ç”¨åˆ†å±‚è‡ªç›‘ç£æœºåˆ¶ï¼Œé€šè¿‡æ—¶ç©ºä¸€è‡´æ€§ã€çŸ¥è¯†è¿ç§»å’Œç‰¹å¾å¯¹æ¯”æ¥å…‹æœå¼‚å¸¸å€¼ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡æå‡ºä½¿ç”¨3Dé«˜æ–¯ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œç»“åˆé›·è¾¾ç‰¹å®šçš„å¢é•¿ç­–ç•¥ã€é€‰æ‹©æ€§åˆ†ç¦»å’Œå¤šè§†å›¾æ­£åˆ™åŒ–ï¼Œä»¥æ¢å¤æ¨¡ç³Šåœ°å›¾åŒºåŸŸå’ŒåŸºäºå›¾åƒçº¹ç†æœªæ£€æµ‹åˆ°çš„åŒºåŸŸã€‚å®éªŒè¡¨æ˜ï¼ŒSuper4DRæ¯”å…ˆå‰çš„è‡ªç›‘ç£æ–¹æ³•æ€§èƒ½æå‡67%ï¼Œå‡ ä¹ä¸ç›‘ç£é‡Œç¨‹è®¡ç›¸åŒ¹é…ï¼Œå¹¶ç¼©å°äº†ä¸æ¿€å…‰é›·è¾¾çš„åœ°å›¾è´¨é‡å·®è·ï¼ŒåŒæ—¶å®ç°äº†å¤šæ¨¡æ€å›¾åƒæ¸²æŸ“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰å’Œæ¿€å…‰é›·è¾¾SLAMç³»ç»Ÿåœ¨å…‰ç…§æ¡ä»¶å·®å’Œæ¶åŠ£å¤©æ°”ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚4Dé›·è¾¾è™½ç„¶åœ¨è¿™äº›ç¯å¢ƒä¸‹å…·æœ‰ä¼˜åŠ¿ï¼Œä½†å…¶ç‚¹äº‘çš„ç¨€ç–æ€§å’Œå™ªå£°ä½¿å¾—é‡Œç¨‹è®¡ä¼°è®¡å˜å¾—å›°éš¾ï¼ŒåŒæ—¶é›·è¾¾åœ°å›¾çš„ç»“æ„æ¨¡ç³Šä¸”ä¸å®Œæ•´ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨4Dé›·è¾¾æ•°æ®ï¼Œå®ç°é²æ£’çš„é‡Œç¨‹è®¡ä¼°è®¡å’Œé«˜è´¨é‡åœ°å›¾æ„å»ºçš„æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSuper4DRçš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå­¦ä¹ æ–¹æ³•å’Œå‡ ä½•ä¼˜åŒ–ï¼Œå……åˆ†åˆ©ç”¨4Dé›·è¾¾æ•°æ®ä¸­çš„ä¿¡æ¯ã€‚é¦–å…ˆï¼Œé€šè¿‡å­¦ä¹ æ–¹æ³•æå–é›·è¾¾ç‚¹äº‘ä¸­çš„ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨èšç±»ä¿¡æ¯è¿›è¡Œå¸§é—´åŒ¹é…ï¼Œä»è€Œæé«˜é‡Œç¨‹è®¡ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚å…¶æ¬¡ï¼Œä½¿ç”¨3Dé«˜æ–¯ä½œä¸ºåœ°å›¾çš„ä¸­é—´è¡¨ç¤ºï¼Œå¹¶è®¾è®¡é›·è¾¾ç‰¹å®šçš„ä¼˜åŒ–ç­–ç•¥ï¼Œä»¥æ¢å¤åœ°å›¾ä¸­çš„ç¼ºå¤±å’Œæ¨¡ç³ŠåŒºåŸŸã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSuper4DRæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼šå­¦ä¹ å‹é‡Œç¨‹è®¡ä¼°è®¡æ¨¡å—å’ŒåŸºäºé«˜æ–¯çš„åœ°å›¾ä¼˜åŒ–æ¨¡å—ã€‚é‡Œç¨‹è®¡ä¼°è®¡æ¨¡å—ä½¿ç”¨ä¸€ä¸ªèšç±»æ„ŸçŸ¥çš„ç¥ç»ç½‘ç»œï¼Œè¯¥ç½‘ç»œä»¥é›·è¾¾ç‚¹äº‘ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºå¸§é—´çš„ä½å§¿å˜æ¢ã€‚åœ°å›¾ä¼˜åŒ–æ¨¡å—é¦–å…ˆå°†é›·è¾¾ç‚¹äº‘è½¬æ¢ä¸º3Dé«˜æ–¯è¡¨ç¤ºï¼Œç„¶åä½¿ç”¨é›·è¾¾ç‰¹å®šçš„å¢é•¿ç­–ç•¥ã€é€‰æ‹©æ€§åˆ†ç¦»å’Œå¤šè§†å›¾æ­£åˆ™åŒ–ç­‰æ–¹æ³•å¯¹é«˜æ–¯è¿›è¡Œä¼˜åŒ–ï¼Œæœ€ç»ˆå¾—åˆ°é«˜è´¨é‡çš„åœ°å›¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šSuper4DRçš„å…³é”®åˆ›æ–°åœ¨äºä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š1) æå‡ºäº†ä¸€ä¸ªèšç±»æ„ŸçŸ¥çš„é‡Œç¨‹è®¡ç½‘ç»œï¼Œè¯¥ç½‘ç»œèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨é›·è¾¾ç‚¹äº‘ä¸­çš„å¯¹è±¡çº§çº¿ç´¢è¿›è¡Œå¸§é—´åŒ¹é…ã€‚2) å¼•å…¥äº†åˆ†å±‚è‡ªç›‘ç£æœºåˆ¶ï¼Œé€šè¿‡æ—¶ç©ºä¸€è‡´æ€§ã€çŸ¥è¯†è¿ç§»å’Œç‰¹å¾å¯¹æ¯”æ¥å…‹æœå¼‚å¸¸å€¼ã€‚3) ä½¿ç”¨3Dé«˜æ–¯ä½œä¸ºåœ°å›¾çš„ä¸­é—´è¡¨ç¤ºï¼Œå¹¶è®¾è®¡äº†é›·è¾¾ç‰¹å®šçš„ä¼˜åŒ–ç­–ç•¥ï¼Œä»¥æ¢å¤åœ°å›¾ä¸­çš„ç¼ºå¤±å’Œæ¨¡ç³ŠåŒºåŸŸã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨é‡Œç¨‹è®¡ç½‘ç»œä¸­ï¼Œä½¿ç”¨äº†PointNet++ä½œä¸ºç‰¹å¾æå–å™¨ï¼Œå¹¶å¼•å…¥äº†æ³¨æ„åŠ›æœºåˆ¶æ¥å¢å¼ºå…³é”®ç‰¹å¾çš„æƒé‡ã€‚åœ¨è‡ªç›‘ç£å­¦ä¹ ä¸­ï¼Œä½¿ç”¨äº†ä¸‰ç§æŸå¤±å‡½æ•°ï¼šæ—¶ç©ºä¸€è‡´æ€§æŸå¤±ã€çŸ¥è¯†è¿ç§»æŸå¤±å’Œç‰¹å¾å¯¹æ¯”æŸå¤±ã€‚åœ¨åœ°å›¾ä¼˜åŒ–ä¸­ï¼Œä½¿ç”¨äº†é›·è¾¾ç‰¹å®šçš„å¢é•¿ç­–ç•¥ï¼Œè¯¥ç­–ç•¥æ ¹æ®é›·è¾¾ç‚¹çš„åå°„å¼ºåº¦å’Œå¯†åº¦æ¥æ§åˆ¶é«˜æ–¯çš„å¢é•¿é€Ÿåº¦ã€‚é€‰æ‹©æ€§åˆ†ç¦»ç­–ç•¥ç”¨äºåˆ†ç¦»é‡å çš„é«˜æ–¯ï¼Œå¤šè§†å›¾æ­£åˆ™åŒ–ç”¨äºä¿è¯åœ°å›¾çš„ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSuper4DRåœ¨é‡Œç¨‹è®¡ä¼°è®¡æ–¹é¢ï¼Œç›¸æ¯”äºå…ˆå‰çš„è‡ªç›‘ç£æ–¹æ³•ï¼Œæ€§èƒ½æå‡äº†67%ï¼Œå¹¶ä¸”å‡ ä¹è¾¾åˆ°äº†ç›‘ç£å­¦ä¹ çš„æ°´å¹³ã€‚åœ¨åœ°å›¾æ„å»ºæ–¹é¢ï¼ŒSuper4DRç¼©å°äº†ä¸æ¿€å…‰é›·è¾¾åœ°å›¾çš„è´¨é‡å·®è·ï¼Œå¹¶ä¸”èƒ½å¤Ÿç”Ÿæˆå¤šæ¨¡æ€å›¾åƒæ¸²æŸ“ï¼Œä¸ºåç»­çš„åº”ç”¨æä¾›äº†ä¾¿åˆ©ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Super4DRåœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€ç¯å¢ƒæ„ŸçŸ¥ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å°¤å…¶æ˜¯åœ¨æ¶åŠ£å¤©æ°”å’Œå…‰ç…§æ¡ä»¶å·®çš„ç¯å¢ƒä¸‹ï¼ŒSuper4DRèƒ½å¤Ÿæä¾›é²æ£’çš„å®šä½å’Œå»ºå›¾èƒ½åŠ›ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶è½¦è¾†å’Œæœºå™¨äººæä¾›å¯é çš„ç¯å¢ƒä¿¡æ¯ã€‚æ­¤å¤–ï¼ŒSuper4DRè¿˜å¯ä»¥ç”¨äºæ„å»ºé«˜ç²¾åº¦çš„é›·è¾¾åœ°å›¾ï¼Œä¸ºåŸå¸‚è§„åˆ’ã€åŸºç¡€è®¾æ–½ç»´æŠ¤ç­‰é¢†åŸŸæä¾›æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Conventional SLAM systems using visual or LiDAR data often struggle in poor lighting and severe weather. Although 4D radar is suited for such environments, its sparse and noisy point clouds hinder accurate odometry estimation, while the radar maps suffer from obscure and incomplete structures. Thus, we propose Super4DR, a 4D radar-centric framework for learning-based odometry estimation and gaussian-based map optimization. First, we design a cluster-aware odometry network that incorporates object-level cues from the clustered radar points for inter-frame matching, alongside a hierarchical self-supervision mechanism to overcome outliers through spatio-temporal consistency, knowledge transfer, and feature contrast. Second, we propose using 3D gaussians as an intermediate representation, coupled with a radar-specific growth strategy, selective separation, and multi-view regularization, to recover blurry map areas and those undetected based on image texture. Experiments show that Super4DR achieves a 67% performance gain over prior self-supervised methods, nearly matches supervised odometry, and narrows the map quality disparity with LiDAR while enabling multi-modal image rendering.

