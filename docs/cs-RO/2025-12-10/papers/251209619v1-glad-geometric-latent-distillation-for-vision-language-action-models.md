---
layout: default
title: GLaD: Geometric Latent Distillation for Vision-Language-Action Models
---

# GLaD: Geometric Latent Distillation for Vision-Language-Action Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2512.09619" target="_blank" class="toolbar-btn">arXiv: 2512.09619v1</a>
    <a href="https://arxiv.org/pdf/2512.09619.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.09619v1" 
            onclick="toggleFavorite(this, '2512.09619v1', 'GLaD: Geometric Latent Distillation for Vision-Language-Action Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Minghao Guo, Meng Cao, Jiachen Tao, Rongtao Xu, Yan Yan, Xiaodan Liang, Ivan Laptev, Xiaojun Chang

**ÂàÜÁ±ª**: cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-10

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**GLaDÔºöÂá†‰ΩïÊΩúÂú®Ëí∏È¶èÂ¢ûÂº∫ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°ÂûãÁöÑÁ©∫Èó¥Êé®ÁêÜËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã` `Âá†‰ΩïÊÑüÁü•` `Áü•ËØÜËí∏È¶è` `Á©∫Èó¥Êé®ÁêÜ` `Êú∫Âô®‰∫∫Êìç‰Ωú`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâVLAÊ®°ÂûãÂøΩÁï•‰∫ÜÂá†‰Ωï‰ø°ÊÅØÔºåÈôêÂà∂‰∫ÜÂÖ∂Á©∫Èó¥Êé®ÁêÜÂíåÊìç‰ΩúËÉΩÂäõ„ÄÇ
2. GLaDÈÄöËøáÂá†‰ΩïÊΩúÂú®Ëí∏È¶èÔºåÂ∞Ü3DÂá†‰ΩïÂÖàÈ™åÁü•ËØÜËûçÂÖ•LLMÁöÑËßÜËßâtokenË°®Á§∫‰∏≠„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåGLaDÂú®LIBERO‰ªªÂä°‰∏≠‰ºò‰∫éUniVLAÔºåÈ™åËØÅ‰∫ÜÂá†‰ΩïÊÑüÁü•È¢ÑËÆ≠ÁªÉÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Áé∞ÊúâËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°Âûã‰∏ªË¶Å‰æùËµñRGB‰ø°ÊÅØÔºåÂøΩÁï•‰∫ÜÂØπÁ©∫Èó¥Êé®ÁêÜÂíåÊìç‰ΩúËá≥ÂÖ≥ÈáçË¶ÅÁöÑÂá†‰ΩïÁ∫øÁ¥¢„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜGLaDÔºå‰∏Ä‰∏™Âá†‰ΩïÊÑüÁü•ÁöÑVLAÊ°ÜÊû∂ÔºåÈÄöËøáÁü•ËØÜËí∏È¶èÂú®È¢ÑËÆ≠ÁªÉÊúüÈó¥ËûçÂÖ•3DÂá†‰ΩïÂÖàÈ™å„ÄÇ‰∏é‰ªÖÂ∞ÜÂá†‰ΩïÁâπÂæÅËí∏È¶èÂà∞ËßÜËßâÁºñÁ†ÅÂô®‰∏çÂêåÔºåGLaDÂ∞ÜLLM‰∏≠ÂØπÂ∫î‰∫éËßÜËßâtokenÁöÑÈöêËóèÁä∂ÊÄÅ‰∏éÂÜªÁªìÁöÑÂá†‰ΩïÊÑüÁü•ËßÜËßâTransformer (VGGT)ÁöÑÁâπÂæÅÂØπÈΩêÔºåÁ°Æ‰øùÂá†‰ΩïÁêÜËß£Ë¢´Ê∑±Â∫¶ÈõÜÊàêÂà∞È©±Âä®Âä®‰ΩúÈ¢ÑÊµãÁöÑÂ§öÊ®°ÊÄÅË°®Á§∫‰∏≠„ÄÇÂú®BridgeÊï∞ÊçÆÈõÜ‰∏ä‰ΩøÁî®ËøôÁßçÂá†‰ΩïËí∏È¶èÊú∫Âà∂ËøõË°åÈ¢ÑËÆ≠ÁªÉÂêéÔºåGLaDÂú®Âõõ‰∏™LIBERO‰ªªÂä°Â•ó‰ª∂‰∏≠ÂÆûÁé∞‰∫Ü94.1%ÁöÑÂπ≥ÂùáÊàêÂäüÁéáÔºå‰ºò‰∫é‰ΩøÁî®Áõ∏ÂêåÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÁöÑUniVLA (92.5%)„ÄÇËøô‰∫õÁªìÊûúÈ™åËØÅ‰∫ÜÂá†‰ΩïÊÑüÁü•È¢ÑËÆ≠ÁªÉÂ¢ûÂº∫‰∫ÜÁ©∫Èó¥Êé®ÁêÜÂíåÁ≠ñÁï•Ê≥õÂåñËÉΩÂäõÔºåËÄåÊó†ÈúÄÊòæÂºèÊ∑±Â∫¶‰º†ÊÑüÂô®Êàñ3DÊ†áÊ≥®„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÔºàVLAÔºâÊ®°ÂûãÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰æùËµñ‰∫éRGBÂõæÂÉè‰ø°ÊÅØÔºåËÄåÂøΩÁï•‰∫ÜÂú∫ÊôØÁöÑÂá†‰ΩïÁªìÊûÑ‰ø°ÊÅØ„ÄÇËøôÁßçÂøΩÁï•ÂØºËá¥Ê®°ÂûãÂú®ÈúÄË¶ÅÂ§çÊùÇÁ©∫Èó¥Êé®ÁêÜÂíåÊìç‰ΩúÁöÑ‰ªªÂä°‰∏≠Ë°®Áé∞‰∏ç‰Ω≥„ÄÇÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèÊúâÊïàÂà©Áî®Âá†‰Ωï‰ø°ÊÅØÁöÑËÉΩÂäõÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÁöÑÊ≥õÂåñÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöGLaDÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÁü•ËØÜËí∏È¶èÔºåÂ∞ÜÂá†‰Ωï‰ø°ÊÅØ‰ªé‰∏Ä‰∏™È¢ÑËÆ≠ÁªÉÁöÑÂá†‰ΩïÊÑüÁü•ËßÜËßâTransformer (VGGT)‰º†ÈÄíÂà∞VLAÊ®°Âûã‰∏≠ÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåGLaD‰∏çÊòØÁõ¥Êé•Â∞ÜÂá†‰ΩïÁâπÂæÅËí∏È¶èÂà∞ËßÜËßâÁºñÁ†ÅÂô®ÔºåËÄåÊòØÂ∞ÜLLM‰∏≠ÂØπÂ∫î‰∫éËßÜËßâtokenÁöÑÈöêËóèÁä∂ÊÄÅ‰∏éVGGTÁöÑÁâπÂæÅÂØπÈΩê„ÄÇËøôÊ†∑ÂÅöÁöÑÁõÆÁöÑÊòØËÆ©LLMËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÂà©Áî®Âú∫ÊôØÁöÑÂá†‰Ωï‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÁ©∫Èó¥Êé®ÁêÜÂíåÊìç‰ΩúËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöGLaDÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ‰∏Ä‰∏™È¢ÑËÆ≠ÁªÉÁöÑÂá†‰ΩïÊÑüÁü•ËßÜËßâTransformer (VGGT)ÔºåÁî®‰∫éÊèêÂèñÂú∫ÊôØÁöÑÂá†‰ΩïÁâπÂæÅÔºõ2) ‰∏Ä‰∏™ËßÜËßâÁºñÁ†ÅÂô®ÔºåÁî®‰∫éÂ∞ÜRGBÂõæÂÉèÁºñÁ†ÅÊàêËßÜËßâÁâπÂæÅÔºõ3) ‰∏Ä‰∏™ËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÔºåÁî®‰∫éÂ§ÑÁêÜÊñáÊú¨Êåá‰ª§ÂíåËûçÂêàËßÜËßâÁâπÂæÅÔºõ4) ‰∏Ä‰∏™Âä®‰ΩúÈ¢ÑÊµãÊ®°ÂùóÔºåÁî®‰∫éÊ†πÊçÆËûçÂêàÂêéÁöÑÂ§öÊ®°ÊÄÅË°®Á§∫È¢ÑÊµãÂä®‰Ωú„ÄÇGLaDÁöÑÂÖ≥ÈîÆÂú®‰∫éÂ∞ÜVGGTÊèêÂèñÁöÑÂá†‰ΩïÁâπÂæÅÈÄöËøáÁü•ËØÜËí∏È¶èÁöÑÊñπÂºèËûçÂÖ•Âà∞LLM‰∏≠Ôºå‰ªéËÄåÂ¢ûÂº∫LLMÂØπÂá†‰Ωï‰ø°ÊÅØÁöÑÁêÜËß£„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöGLaDÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂÖ∂Âá†‰ΩïÊΩúÂú®Ëí∏È¶èÊú∫Âà∂„ÄÇ‰∏é‰º†ÁªüÁöÑÁü•ËØÜËí∏È¶èÊñπÊ≥ï‰∏çÂêåÔºåGLaD‰∏çÊòØÁõ¥Êé•Â∞ÜÂá†‰ΩïÁâπÂæÅËí∏È¶èÂà∞ËßÜËßâÁºñÁ†ÅÂô®ÔºåËÄåÊòØÂ∞ÜLLM‰∏≠ÂØπÂ∫î‰∫éËßÜËßâtokenÁöÑÈöêËóèÁä∂ÊÄÅ‰∏éVGGTÁöÑÁâπÂæÅÂØπÈΩê„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Â∞ÜÂá†‰Ωï‰ø°ÊÅØËûçÂÖ•Âà∞Â§öÊ®°ÊÄÅË°®Á§∫‰∏≠Ôºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÁ©∫Èó¥Êé®ÁêÜÂíåÊìç‰ΩúËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåGLaDÊó†ÈúÄÊòæÂºèÁöÑÊ∑±Â∫¶‰º†ÊÑüÂô®Êàñ3DÊ†áÊ≥®ÔºåÂç≥ÂèØÂÆûÁé∞Âá†‰ΩïÊÑüÁü•ÁöÑÈ¢ÑËÆ≠ÁªÉ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöGLaDÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑVGGTÊèêÂèñÂá†‰ΩïÁâπÂæÅÔºõ2) ‰ΩøÁî®TransformerÊû∂ÊûÑÁöÑLLMËøõË°åÂ§öÊ®°ÊÄÅËûçÂêàÔºõ3) ËÆæËÆ°ÂêàÈÄÇÁöÑÊçüÂ§±ÂáΩÊï∞ÔºåÁî®‰∫éÂ∞ÜLLMÁöÑÈöêËóèÁä∂ÊÄÅ‰∏éVGGTÁöÑÁâπÂæÅÂØπÈΩê„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂèØËÉΩÂåÖÊã¨KLÊï£Â∫¶ÊàñMSEÊçüÂ§±Á≠â„ÄÇÊ≠§Â§ñÔºåGLaDËøòÂèØËÉΩÈááÁî®‰∏Ä‰∫õÊï∞ÊçÆÂ¢ûÂº∫ÊäÄÊúØÔºå‰æãÂ¶ÇÈöèÊú∫Ë£ÅÂâ™„ÄÅÊóãËΩ¨Á≠âÔºå‰ª•ÊèêÈ´òÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠Â∫îËØ•ÊúâÊõ¥ËØ¶ÁªÜÁöÑÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

GLaDÂú®LIBERO‰ªªÂä°Â•ó‰ª∂‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂú®Âõõ‰∏™LIBERO‰ªªÂä°Â•ó‰ª∂‰∏≠ÔºåGLaDÂÆûÁé∞‰∫Ü94.1%ÁöÑÂπ≥ÂùáÊàêÂäüÁéáÔºå‰ºò‰∫é‰ΩøÁî®Áõ∏ÂêåÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÁöÑUniVLA (92.5%)„ÄÇËøô‰∏ÄÁªìÊûúË°®ÊòéÔºåÈÄöËøáÂá†‰ΩïÊΩúÂú®Ëí∏È¶èÔºåGLaDËÉΩÂ§üÊúâÊïàÂú∞Â¢ûÂº∫Ê®°ÂûãÁöÑÁ©∫Èó¥Êé®ÁêÜÂíåÁ≠ñÁï•Ê≥õÂåñËÉΩÂäõ„ÄÇËØ•ÂÆûÈ™åÁªìÊûúÈ™åËØÅ‰∫ÜÂá†‰ΩïÊÑüÁü•È¢ÑËÆ≠ÁªÉÁöÑÊúâÊïàÊÄßÔºåÂπ∂‰∏∫VLAÊ®°ÂûãÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÊñ∞ÁöÑÊÄùË∑Ø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

GLaDÁöÑÁ†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÅËá™Âä®È©æÈ©∂„ÄÅÂ¢ûÂº∫Áé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÂ¢ûÂº∫Ê®°ÂûãÂØπÁ©∫Èó¥Âá†‰Ωï‰ø°ÊÅØÁöÑÁêÜËß£ÔºåÂèØ‰ª•ÊèêÈ´òÊú∫Âô®‰∫∫Âú®Â§çÊùÇÁéØÂ¢É‰∏≠ÁöÑÊìç‰ΩúËÉΩÂäõÔºåÊèêÂçáËá™Âä®È©æÈ©∂Á≥ªÁªüÁöÑÁéØÂ¢ÉÊÑüÁü•ËÉΩÂäõÔºåÂπ∂‰∏∫ARÂ∫îÁî®Êèê‰æõÊõ¥ÁúüÂÆûÁöÑÁ©∫Èó¥‰∫§‰∫í‰ΩìÈ™å„ÄÇËØ•Á†îÁ©∂ÁöÑÊú™Êù•ÂΩ±ÂìçÂú®‰∫éÊé®Âä®VLAÊ®°ÂûãÂú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®ÔºåÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥ÂèØÈù†ÁöÑ‰∫∫Êú∫‰∫§‰∫í„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Most existing Vision-Language-Action (VLA) models rely primarily on RGB information, while ignoring geometric cues crucial for spatial reasoning and manipulation. In this work, we introduce GLaD, a geometry-aware VLA framework that incorporates 3D geometric priors during pretraining through knowledge distillation. Rather than distilling geometric features solely into the vision encoder, we align the LLM's hidden states corresponding to visual tokens with features from a frozen geometry-aware vision transformer (VGGT), ensuring that geometric understanding is deeply integrated into the multimodal representations that drive action prediction. Pretrained on the Bridge dataset with this geometry distillation mechanism, GLaD achieves 94.1% average success rate across four LIBERO task suites, outperforming UniVLA (92.5%) which uses identical pretraining data. These results validate that geometry-aware pretraining enhances spatial reasoning and policy generalization without requiring explicit depth sensors or 3D annotations.

