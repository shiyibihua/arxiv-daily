---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.RO - 2025-12-10
---

# cs.ROï¼ˆ2025-12-10ï¼‰

ğŸ“Š å…± **26** ç¯‡è®ºæ–‡
 | ğŸ”— **5** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (18 ğŸ”—4)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (7 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (18 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251209297v1-one-shot-real-world-demonstration-synthesis-for-scalable-bimanual-ma.html">One-Shot Real-World Demonstration Synthesis for Scalable Bimanual Manipulation</a></td>
  <td>BiDemoSynï¼šåŸºäºå•æ ·æœ¬çœŸå®æ¼”ç¤ºåˆæˆå¯æ‰©å±•çš„åŒè‡‚æ“ä½œæ•°æ®</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09297v1" onclick="toggleFavorite(this, '2512.09297v1', 'One-Shot Real-World Demonstration Synthesis for Scalable Bimanual Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251209656v1-remosplat-reactive-mobile-manipulation-control-on-a-gaussian-splat.html">ReMoSPLAT: Reactive Mobile Manipulation Control on a Gaussian Splat</a></td>
  <td>ReMoSPLATï¼šåŸºäºé«˜æ–¯æº…å°„çš„ç§»åŠ¨æœºæ¢°è‡‚ååº”å¼æ§åˆ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09656v1" onclick="toggleFavorite(this, '2512.09656v1', 'ReMoSPLAT: Reactive Mobile Manipulation Control on a Gaussian Splat')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251209537v1-reasan-learning-reactive-safe-navigation-for-legged-robots.html">REASAN: Learning Reactive Safe Navigation for Legged Robots</a></td>
  <td>REASANï¼šé¢å‘å¤æ‚åŠ¨æ€ç¯å¢ƒï¼Œå­¦ä¹ è…¿å¼æœºå™¨äººååº”å¼å®‰å…¨å¯¼èˆª</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09537v1" onclick="toggleFavorite(this, '2512.09537v1', 'REASAN: Learning Reactive Safe Navigation for Legged Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251209431v1-a-hierarchical-model-based-system-for-high-performance-humanoid-socc.html">A Hierarchical, Model-Based System for High-Performance Humanoid Soccer</a></td>
  <td>æå‡ºä¸€ç§åˆ†å±‚ã€åŸºäºæ¨¡å‹çš„ç³»ç»Ÿï¼Œç”¨äºé«˜æ€§èƒ½äººå½¢æœºå™¨äººè¶³çƒæ¯”èµ›ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09431v1" onclick="toggleFavorite(this, '2512.09431v1', 'A Hierarchical, Model-Based System for High-Performance Humanoid Soccer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251209310v1-scene-agnostic-hierarchical-bimanual-task-planning-via-visual-afford.html">Scene-agnostic Hierarchical Bimanual Task Planning via Visual Affordance Reasoning</a></td>
  <td>æå‡ºåŸºäºè§†è§‰å¯ä¾›æ€§çš„åœºæ™¯æ— å…³åˆ†å±‚åŒè‡‚ä»»åŠ¡è§„åˆ’æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09310v1" onclick="toggleFavorite(this, '2512.09310v1', 'Scene-agnostic Hierarchical Bimanual Task Planning via Visual Affordance Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251210099v1-push-smarter-not-harder-hierarchical-rl-diffusion-policy-for-efficie.html">Push Smarter, Not Harder: Hierarchical RL-Diffusion Policy for Efficient Nonprehensile Manipulation</a></td>
  <td>æå‡ºHeRDï¼šä¸€ç§ç”¨äºé«˜æ•ˆéæŠ“å–æ“ä½œçš„åˆ†å±‚RL-æ‰©æ•£ç­–ç•¥</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.10099v1" onclick="toggleFavorite(this, '2512.10099v1', 'Push Smarter, Not Harder: Hierarchical RL-Diffusion Policy for Efficient Nonprehensile Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251209851v1-simultaneous-tactile-visual-perception-for-learning-multimodal-robot.html">Simultaneous Tactile-Visual Perception for Learning Multimodal Robot Manipulation</a></td>
  <td>æå‡ºTacThru-UMIï¼Œç»“åˆæ–°å‹è§¦è§‰è§†è§‰ä¼ æ„Ÿå™¨ä¸Transformeræ‰©æ•£ç­–ç•¥ï¼Œæå‡æœºå™¨äººæ“ä½œç²¾åº¦ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09851v1" onclick="toggleFavorite(this, '2512.09851v1', 'Simultaneous Tactile-Visual Perception for Learning Multimodal Robot Manipulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251209607v1-urbannav-learning-language-guided-urban-navigation-from-web-scale-hu.html">UrbanNav: Learning Language-Guided Urban Navigation from Web-Scale Human Trajectories</a></td>
  <td>æå‡ºUrbanNavä»¥è§£å†³å¤æ‚åŸå¸‚ç¯å¢ƒä¸­çš„è¯­è¨€å¼•å¯¼å¯¼èˆªé—®é¢˜</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09607v1" onclick="toggleFavorite(this, '2512.09607v1', 'UrbanNav: Learning Language-Guided Urban Navigation from Web-Scale Human Trajectories')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251209462v1-development-of-a-compliant-gripper-for-safe-robot-assisted-trouser-d.html">Development of a Compliant Gripper for Safe Robot-Assisted Trouser Dressing-Undressing</a></td>
  <td>å¼€å‘ç”¨äºå®‰å…¨æœºå™¨äººè¾…åŠ©ç©¿è„±è£¤å­çš„æŸ”é¡ºå¤¹æŒå™¨</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09462v1" onclick="toggleFavorite(this, '2512.09462v1', 'Development of a Compliant Gripper for Safe Robot-Assisted Trouser Dressing-Undressing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251209406v1-h2r-grounder-a-paired-data-free-paradigm-for-translating-human-inter.html">H2R-Grounder: A Paired-Data-Free Paradigm for Translating Human Interaction Videos into Physically Grounded Robot Videos</a></td>
  <td>æå‡ºH2R-Grounderï¼Œå®ç°æ— éœ€é…å¯¹æ•°æ®çš„ç‰©ç†å¯ä¿¡äººæœºäº¤äº’è§†é¢‘è½¬æ¢ã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09406v1" onclick="toggleFavorite(this, '2512.09406v1', 'H2R-Grounder: A Paired-Data-Free Paradigm for Translating Human Interaction Videos into Physically Grounded Robot Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251210071v2-openpi-comet-competition-solution-for-2025-behavior-challenge.html">Openpi Comet: Competition Solution For 2025 BEHAVIOR Challenge</a></td>
  <td>OpenPI Cometåœ¨BEHAVIORæŒ‘æˆ˜èµ›ä¸­è·å¾—äºšå†›ï¼Œé€šè¿‡ç³»ç»Ÿæ€§ç ”ç©¶æå‡å…·èº«æ™ºèƒ½æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.10071v2" onclick="toggleFavorite(this, '2512.10071v2', 'Openpi Comet: Competition Solution For 2025 BEHAVIOR Challenge')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251209619v1-glad-geometric-latent-distillation-for-vision-language-action-models.html">GLaD: Geometric Latent Distillation for Vision-Language-Action Models</a></td>
  <td>GLaDï¼šå‡ ä½•æ½œåœ¨è’¸é¦å¢å¼ºè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„ç©ºé—´æ¨ç†èƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09619v1" onclick="toggleFavorite(this, '2512.09619v1', 'GLaD: Geometric Latent Distillation for Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251209510v1-vita-seg-vision-transformer-for-amodal-segmentation-in-robotics.html">ViTA-Seg: Vision Transformer for Amodal Segmentation in Robotics</a></td>
  <td>ViTA-Segï¼šç”¨äºæœºå™¨äººéæ¨¡æ€åˆ†å‰²çš„è§†è§‰Transformerï¼Œæå‡é®æŒ¡åœºæ™¯ä¸‹çš„æŠ“å–è§„åˆ’ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09510v1" onclick="toggleFavorite(this, '2512.09510v1', 'ViTA-Seg: Vision Transformer for Amodal Segmentation in Robotics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251211908v1-safe-learning-for-contact-rich-robot-tasks-a-survey-from-classical-l.html">Safe Learning for Contact-Rich Robot Tasks: A Survey from Classical Learning-Based Methods to Safe Foundation Models</a></td>
  <td>ç»¼è¿°ï¼šé¢å‘æ¥è§¦å¯†é›†å‹æœºå™¨äººä»»åŠ¡çš„å®‰å…¨å­¦ä¹ æ–¹æ³•ï¼Œä»ç»å…¸æ–¹æ³•åˆ°å®‰å…¨å…·èº«æ™ºèƒ½</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11908v1" onclick="toggleFavorite(this, '2512.11908v1', 'Safe Learning for Contact-Rich Robot Tasks: A Survey from Classical Learning-Based Methods to Safe Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251210116v1-fast-functionally-redundant-inverse-kinematics-for-robotic-toolpath-.html">Fast Functionally Redundant Inverse Kinematics for Robotic Toolpath Optimisation in Manufacturing Tasks</a></td>
  <td>æå‡ºå¿«é€ŸåŠŸèƒ½å†—ä½™é€†è¿åŠ¨å­¦ç®—æ³•ï¼Œä¼˜åŒ–æœºå™¨äººåˆ¶é€ ä»»åŠ¡ä¸­çš„å·¥å…·è·¯å¾„</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.10116v1" onclick="toggleFavorite(this, '2512.10116v1', 'Fast Functionally Redundant Inverse Kinematics for Robotic Toolpath Optimisation in Manufacturing Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251209928v1-hif-vla-hindsight-insight-and-foresight-through-motion-representatio.html">HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models</a></td>
  <td>HiF-VLAï¼šåˆ©ç”¨è¿åŠ¨è¡¨å¾è¿›è¡ŒåŒå‘æ—¶åºæ¨ç†ï¼Œæå‡è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„é•¿æ—¶åºæ“ä½œèƒ½åŠ›</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09928v1" onclick="toggleFavorite(this, '2512.09928v1', 'HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251209911v1-py-dismech-a-scalable-and-efficient-framework-for-discrete-different.html">Py-DiSMech: A Scalable and Efficient Framework for Discrete Differential Geometry-Based Modeling and Control of Soft Robots</a></td>
  <td>Py-DiSMechï¼šåŸºäºç¦»æ•£å¾®åˆ†å‡ ä½•çš„è½¯æœºå™¨äººå»ºæ¨¡ä¸æ§åˆ¶é«˜æ•ˆæ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09911v1" onclick="toggleFavorite(this, '2512.09911v1', 'Py-DiSMech: A Scalable and Efficient Framework for Discrete Differential Geometry-Based Modeling and Control of Soft Robots')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251209833v1-bridging-the-basilisk-astrodynamics-framework-with-ros-2-for-modular.html">Bridging the Basilisk Astrodynamics Framework with ROS 2 for Modular Spacecraft Simulation and Hardware Integration</a></td>
  <td>æå‡ºBasiliskä¸ROS 2çš„è½»é‡çº§æ¡¥æ¥æ–¹æ¡ˆï¼Œç”¨äºæ¨¡å—åŒ–èˆªå¤©å™¨ä»¿çœŸä¸ç¡¬ä»¶é›†æˆ</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09833v1" onclick="toggleFavorite(this, '2512.09833v1', 'Bridging the Basilisk Astrodynamics Framework with ROS 2 for Modular Spacecraft Simulation and Hardware Integration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (7 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>19</td>
  <td><a href="./papers/251209411v1-d2gslam-4d-dynamic-gaussian-splatting-slam.html">D$^2$GSLAM: 4D Dynamic Gaussian Splatting SLAM</a></td>
  <td>D$^2$GSLAMï¼šåŸºäºé«˜æ–¯è¡¨ç¤ºçš„åŠ¨æ€åœºæ™¯4D SLAMç³»ç»Ÿï¼Œå®ç°åŠ¨æ€ç¯å¢ƒä¸‹çš„ç²¾ç¡®é‡å»ºä¸é²æ£’è·Ÿè¸ªã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09411v1" onclick="toggleFavorite(this, '2512.09411v1', 'D$^2$GSLAM: 4D Dynamic Gaussian Splatting SLAM')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251209903v1-yopo-nav-visual-navigation-using-3dgs-graphs-from-one-pass-videos.html">YOPO-Nav: Visual Navigation using 3DGS Graphs from One-Pass Videos</a></td>
  <td>YOPO-Navï¼šåˆ©ç”¨å•æ¬¡è§†é¢‘çš„3DGSå›¾è¿›è¡Œè§†è§‰å¯¼èˆª</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09903v1" onclick="toggleFavorite(this, '2512.09903v1', 'YOPO-Nav: Visual Navigation using 3DGS Graphs from One-Pass Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/251210128v1-inertial-magnetic-slam-systems-using-low-cost-sensors.html">Inertial Magnetic SLAM Systems Using Low-Cost Sensors</a></td>
  <td>æå‡ºåŸºäºä½æˆæœ¬æƒ¯æ€§ç£ä¼ æ„Ÿå™¨çš„æƒ¯æ€§ç£SLAMç³»ç»Ÿï¼Œæå‡å¼±å…‰ç¯å¢ƒå®šä½ç²¾åº¦ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.10128v1" onclick="toggleFavorite(this, '2512.10128v1', 'Inertial Magnetic SLAM Systems Using Low-Cost Sensors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251209920v1-lisn-language-instructed-social-navigation-with-vlm-based-controller.html">LISN: Language-Instructed Social Navigation with VLM-based Controller Modulating</a></td>
  <td>æå‡ºLISN-Benchä¸Social-Nav-Modulatorï¼Œå®ç°åŸºäºè¯­è¨€æŒ‡ä»¤çš„ç¤¾äº¤å¯¼èˆªã€‚</td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09920v1" onclick="toggleFavorite(this, '2512.09920v1', 'LISN: Language-Instructed Social Navigation with VLM-based Controller Modulating')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/251209608v1-super4dr-4d-radar-centric-self-supervised-odometry-and-gaussian-base.html">Super4DR: 4D Radar-centric Self-supervised Odometry and Gaussian-based Map Optimization</a></td>
  <td>Super4DRï¼šé¢å‘4Dé›·è¾¾çš„è‡ªç›‘ç£é‡Œç¨‹è®¡ä¸é«˜æ–¯ä¼˜åŒ–å»ºå›¾</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09608v1" onclick="toggleFavorite(this, '2512.09608v1', 'Super4DR: 4D Radar-centric Self-supervised Odometry and Gaussian-based Map Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/251209798v1-high-resolution-water-sampling-via-a-solar-powered-autonomous-surfac.html">High-Resolution Water Sampling via a Solar-Powered Autonomous Surface Vehicle</a></td>
  <td>æå‡ºä¸€ç§å¤ªé˜³èƒ½è‡ªä¸»æ°´é¢èˆ¹ï¼Œå®ç°é«˜åˆ†è¾¨ç‡æ°´æ ·é‡‡é›†ä¸æ°´è´¨ç›‘æµ‹</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09798v1" onclick="toggleFavorite(this, '2512.09798v1', 'High-Resolution Water Sampling via a Solar-Powered Autonomous Surface Vehicle')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/251211903v1-aion-towards-hierarchical-4d-scene-graphs-with-temporal-flow-dynamic.html">Aion: Towards Hierarchical 4D Scene Graphs with Temporal Flow Dynamics</a></td>
  <td>æå‡ºAionï¼Œå°†æ—¶åºæµåŠ¨åŠ¨æ€åµŒå…¥åˆ†å±‚4Dåœºæ™¯å›¾ï¼Œç”¨äºåŠ¨æ€ç¯å¢ƒè‡ªä¸»å¯¼èˆªã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.11903v1" onclick="toggleFavorite(this, '2512.11903v1', 'Aion: Towards Hierarchical 4D Scene Graphs with Temporal Flow Dynamics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>26</td>
  <td><a href="./papers/251209410v1-generalizable-collaborative-search-and-capture-in-cluttered-environm.html">Generalizable Collaborative Search-and-Capture in Cluttered Environments via Path-Guided MAPPO and Directional Frontier Allocation</a></td>
  <td>æå‡ºPGF-MAPPOï¼Œè§£å†³å¤æ‚ç¯å¢ƒä¸‹çš„ååŒæœç´¢æ•è·é—®é¢˜ï¼Œå®ç°é›¶æ ·æœ¬æ³›åŒ–ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.09410v1" onclick="toggleFavorite(this, '2512.09410v1', 'Generalizable Collaborative Search-and-Capture in Cluttered Environments via Path-Guided MAPPO and Directional Frontier Allocation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.RO é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)