{
    "meta": {
        "profile": "Robotics & Animation Algorithm Engineer",
        "description": "Full-stack tracking: Control, SOTA Perception, Motion Synthesis, Embodied VLA, and Sim-to-Real.",
        "strategy": "Nine Pillars - Algorithm & Task Focused (九大支柱-算法与任务核心)",
        "version": "5.2_Multi_Domain_Optimized"
    },
    "arxiv_categories": [
        "cs.RO",
        "cs.CV",
        "cs.GR",
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "eess.SY"
    ],
    "filter_settings": {
        "min_relevance_score": 2.0,
        "title_multiplier": 3.0,
        "abstract_multiplier": 1.0,
        "logic": "OR - Match ANY category. Scores accumulate across categories."
    },
    "concept_groups": [
        {
            "id": "1_robot_core",
            "name": "支柱一：机器人控制 (Robot Control)",
            "description": "机器人本体控制：移动、操作、Sim2Real、Loco-Manipulation",
            "weight": 2.0,
            "keywords": [
                "quadruped",
                "legged robot",
                "legged locomotion",
                "humanoid",
                "humanoid robot",
                "humanoid control",
                "humanoid locomotion",
                "bipedal",
                "biped",
                "whole-body control",
                "WBC",
                "operational space control",
                "OSC",
                "locomotion",
                "locomotion policy",
                "gait control",
                "dynamic walking",
                "parkour",
                "manipulation",
                "mobile manipulation",
                "loco-manipulation",
                "locomanipulation",
                "whole-body manipulation",
                "reachability-aware",
                "dexterous hand",
                "dexterous manipulation",
                "in-hand manipulation",
                "bi-manual",
                "dual-arm",
                "bimanual manipulation",
                "sim-to-real",
                "sim2real",
                "real2sim",
                "domain randomization",
                "dynamics randomization",
                "actuator dynamics",
                "actuator network",
                "MPC",
                "model predictive control",
                "centroidal dynamics",
                "trajectory optimization",
                "motion planning",
                "recovery control",
                "fall recovery",
                "push recovery",
                "teleoperation",
                "VR teleoperation",
                "Apple Vision Pro",
                "shared control",
                "Unitree",
                "ANYmal",
                "Digit robot",
                "Figure 01",
                "Tesla Optimus"
            ]
        },
        {
            "id": "2_algo_arch",
            "name": "支柱二：RL算法与架构 (RL & Architecture)",
            "description": "强化学习、离线RL、偏好学习(DPO)、网络架构",
            "weight": 1.5,
            "keywords": [
                "reinforcement learning",
                "deep reinforcement learning",
                "DRL",
                "policy learning",
                "PPO",
                "SAC",
                "TD3",
                "offline RL",
                "offline reinforcement learning",
                "CQL",
                "IQL",
                "conservative q-learning",
                "imitation learning",
                "behavior cloning",
                "inverse reinforcement learning",
                "diffusion policy",
                "consistency policy",
                "flow matching",
                "preference learning",
                "RLHF",
                "DPO",
                "direct preference optimization",
                "world model",
                "dreamer",
                "latent dynamics",
                "predictive model",
                "model-based RL",
                "decision transformer",
                "transformer policy",
                "trajectory transformer",
                "Mamba",
                "SSM",
                "state space model",
                "linear attention",
                "representation learning",
                "masked autoencoder",
                "MAE",
                "contrastive learning",
                "visual pre-training",
                "R3M",
                "VIP",
                "Voltron",
                "curriculum learning",
                "teacher-student",
                "distillation",
                "privileged information",
                "reward design",
                "reward shaping",
                "Eureka",
                "Dr.Eureka"
            ]
        },
        {
            "id": "3_perception_slam",
            "name": "支柱三：空间感知与语义 (Perception & Semantics)",
            "description": "深度估计、SLAM、开放词汇理解、3D表征",
            "weight": 2.0,
            "keywords": [
                "visual odometry",
                "visual SLAM",
                "VIO",
                "LIO",
                "depth estimation",
                "monocular depth",
                "stereo depth",
                "metric depth",
                "Depth Anything",
                "UniDepth",
                "MoGe",
                "Metric3D",
                "ZoeDepth",
                "3D gaussian splatting",
                "3DGS",
                "gaussian splatting",
                "splatting",
                "NeRF",
                "neural radiance field",
                "implicit representation",
                "scene reconstruction",
                "scene understanding",
                "semantic mapping",
                "semantic map",
                "open-vocabulary",
                "open vocabulary",
                "CLIP-fields",
                "concept fusion",
                "VLMAP",
                "elevation map",
                "height map",
                "occupancy grid",
                "traversability",
                "affordance",
                "affordance detection",
                "grasp prediction",
                "6D pose estimation",
                "optical flow",
                "scene flow",
                "DROID-SLAM",
                "VGGT",
                "SplaTAM",
                "ConceptGraphs",
                "TartanVO"
            ]
        },
        {
            "id": "4_motion_diffusion",
            "name": "支柱四：生成式动作 (Generative Motion)",
            "description": "基于Diffusion的动作生成 (MDM系)",
            "weight": 2.5,
            "keywords": [
                "motion diffusion model",
                "MDM",
                "motion diffusion",
                "text-to-motion",
                "text-driven motion",
                "language-conditioned motion",
                "motion synthesis",
                "motion generation",
                "long-term motion generation",
                "classifier-free guidance",
                "physics-informed diffusion",
                "physically plausible",
                "contact-aware",
                "foot skating",
                "penetration",
                "MotionGPT",
                "motion latent",
                "motion tokenizer",
                "VQ-VAE",
                "T2M-GPT",
                "MoMask",
                "MotionLCM",
                "OmniControl"
            ]
        },
        {
            "id": "5_interaction_reaction",
            "name": "支柱五：交互与反应 (Interaction & Reaction)",
            "description": "人-物/人-人交互、反应合成",
            "weight": 2.5,
            "keywords": [
                "human-object interaction",
                "HOI",
                "object manipulation motion",
                "human-scene interaction",
                "HSI",
                "scene-aware motion",
                "affordance-aware",
                "multi-person interaction",
                "two-person interaction",
                "dyadic interaction",
                "reaction synthesis",
                "reactive motion",
                "duet generation",
                "mutual attention",
                "interaction transformer",
                "InterDiff",
                "ReMoS",
                "CHOIS",
                "OMOMO",
                "IMoS",
                "UniHCP"
            ]
        },
        {
            "id": "6_video_extraction",
            "name": "支柱六：视频提取与匹配 (Video Extraction)",
            "description": "从视频(含第一人称)提取数据、Motion Matching",
            "weight": 2.0,
            "keywords": [
                "video-to-motion",
                "video-to-pose",
                "video-based pose estimation",
                "human mesh recovery",
                "HMR",
                "SMPL",
                "SMPL-X",
                "MANO",
                "monocular motion capture",
                "markerless motion capture",
                "4DHumans",
                "WHAM",
                "GLAMR",
                "SLAHMR",
                "HuMoR",
                "egocentric",
                "egocentric vision",
                "first-person view",
                "Ego4D",
                "EgoHMR",
                "hand reconstruction",
                "hand-object reconstruction",
                "motion matching",
                "motion retrieval",
                "database matching",
                "feature matching",
                "IMU-based motion",
                "sparse sensors"
            ]
        },
        {
            "id": "7_retargeting",
            "name": "支柱七：动作重定向 (Motion Retargeting)",
            "description": "人类动作迁移到机器人，保持几何/动力学约束",
            "weight": 3.0,
            "keywords": [
                "motion retargeting",
                "motion adaptation",
                "human-to-humanoid",
                "human-to-robot",
                "kinematic retargeting",
                "dynamic retargeting",
                "morphology adaptation",
                "structure preservation",
                "interaction mesh",
                "spatial relationship",
                "latent optimization",
                "neural retargeting",
                "geometric consistency",
                "linkage retargeting",
                "cross-embodiment",
                "embodiment transfer",
                "OmniH2O",
                "ExBody",
                "UniTracker",
                "AnyTeleop"
            ]
        },
        {
            "id": "8_physics_animation",
            "name": "支柱八：物理动画 (Physics-based Animation)",
            "description": "图形学中的Character Control (DeepMimic, AMP系)",
            "weight": 2.0,
            "keywords": [
                "physics-based character",
                "simulated character",
                "physically simulated character",
                "character animation",
                "character control",
                "DeepMimic",
                "AMP",
                "adversarial motion priors",
                "ASE",
                "adversarial skill embeddings",
                "spatiotemporal",
                "motion tracking",
                "differentiable simulation",
                "diff-sim",
                "soft body simulation",
                "locomotion synthesis",
                "interactive character",
                "PULSE",
                "PHC",
                "SuperPADL",
                "UniCon"
            ]
        },
        {
            "id": "9_embodied_foundation",
            "name": "支柱九：具身大模型 (Embodied Foundation Models)",
            "description": "VLA, 具身智能体, 指令跟随",
            "weight": 3.0,
            "keywords": [
                "embodied AI",
                "generalist agent",
                "vision-language-action",
                "VLA",
                "vision-language-navigation",
                "VLN",
                "large language model",
                "LLM for robotics",
                "foundation model",
                "multimodal",
                "instruction following",
                "language conditioned",
                "visual grounding",
                "symbolic grounding",
                "chain-of-thought",
                "zero-shot transfer",
                "task and motion planning",
                "TAMP",
                "RT-1",
                "RT-2",
                "PaLM-E",
                "VoxPoser",
                "Code as Policies",
                "Octo",
                "OpenVLA",
                "Aloha",
                "Mobile Aloha"
            ]
        }
    ],
    "negative_keywords": [
        "medical",
        "clinical",
        "surgery",
        "surgical",
        "rehabilitation",
        "prosthesis",
        "tumor",
        "cancer",
        "lesion",
        "pathology",
        "diagnosis",
        "MRI",
        "CT scan",
        "molecular",
        "biology",
        "protein",
        "genome",
        "cell",
        "drug discovery",
        "underwater",
        "underwater robot",
        "UAV",
        "drone",
        "aerial vehicle",
        "fixed-wing",
        "autonomous driving",
        "self-driving car",
        "vehicle detection",
        "lane detection",
        "traffic sign",
        "financial",
        "stock",
        "trading",
        "blockchain",
        "cryptocurrency",
        "social network",
        "sentiment analysis",
        "fake news",
        "hate speech",
        "recommender system",
        "advertising",
        "face recognition",
        "facial recognition",
        "emotion recognition",
        "deepfake",
        "person re-identification",
        "crowd counting",
        "surveillance",
        "text-to-image",
        "image generation",
        "stable diffusion",
        "midjourney",
        "style transfer",
        "super resolution",
        "image restoration",
        "inpainting",
        "remote sensing",
        "satellite image",
        "hyperspectral",
        "speech recognition",
        "text-to-speech",
        "machine translation",
        "ASR",
        "chatbot",
        "question answering",
        "text summarization",
        "document classification"
    ]
}