#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse, json, os, re, sys, datetime
from pathlib import Path
from typing import List, Dict, Any, Tuple
from collections import defaultdict

# =============== åŸºç¡€å·¥å…· ===============

def slugify(text: str, maxlen: int = 80) -> str:
    text = re.sub(r"[^\w\s-]", "", text, flags=re.U).strip().lower()
    text = re.sub(r"[\s_-]+", "-", text)
    return text[:maxlen] if maxlen else text

def read_json(p: Path) -> Dict[str, Any]:
    with p.open("r", encoding="utf-8") as f:
        return json.load(f)

def ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)

def md_escape(s: str) -> str:
    return s.replace("|", r"\|")

def to_authors(auth_list) -> str:
    if isinstance(auth_list, list):
        return ", ".join(auth_list)
    return str(auth_list)

def load_tags(tags_file: Path) -> List[str]:
    """åŠ è½½ tags.json ä¸­çš„åˆ†ç±»åˆ—è¡¨"""
    with tags_file.open("r", encoding="utf-8") as f:
        data = json.load(f)
    return data.get("tags", [])

# =============== æ¸²æŸ“ ===============

def render_paper_md(p: Dict[str, Any]) -> str:
    """æ¸²æŸ“è®ºæ–‡è¯¦æƒ…é¡µé¢ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    title = p.get("title", "").strip()
    authors = to_authors(p.get("authors", []))
    arxiv_id = p.get("arxiv_id", "")
    headline = p.get("headline_zh", "").strip()
    intro = p.get("intro_zh", [])
    tags = p.get("tags_zh", [])
    summary = p.get("summary", "").strip()
    categories = p.get("categories", [])
    
    # æ–°å¢å­—æ®µ
    summary_zh = p.get("summary_zh", "").strip()
    method_zh = p.get("method_zh", "").strip()
    application_zh = p.get("application_zh", "").strip()
    highlight_zh = p.get("highlight_zh", "").strip()
    thumbnail = p.get("thumbnail", "").strip()
    code_links = p.get("code_links", [])
    published = p.get("published", "").strip()
    updated = p.get("updated", "").strip()
    comment = p.get("comment", "").strip()
    doi = p.get("doi", "").strip()
    journal_ref = p.get("journal_ref", "").strip()

    lines = []
    lines.append(f"# {md_escape(title)}")
    
    # åŸºç¡€ä¿¡æ¯åŒº
    if arxiv_id:
        base_id = arxiv_id.split('v')[0]
        abs_url = f"https://arxiv.org/abs/{base_id}"
        pdf_url = f"https://arxiv.org/pdf/{base_id}.pdf"
        lines.append(f"\n**arXiv**: [{arxiv_id}]({abs_url}) | [PDF]({pdf_url})")
    
    lines.append(f"\n**ä½œè€…**: {md_escape(authors)}")
    
    if categories:
        lines.append(f"\n**åˆ†ç±»**: {', '.join(categories)}")
    
    if published:
        date_info = f"**å‘å¸ƒæ—¥æœŸ**: {published}"
        if updated and updated != published:
            date_info += f" (æ›´æ–°: {updated})"
        lines.append(f"\n{date_info}")
    
    if comment:
        lines.append(f"\n**å¤‡æ³¨**: {md_escape(comment)}")
    
    if journal_ref:
        lines.append(f"\n**æœŸåˆŠ**: {md_escape(journal_ref)}")
    
    if doi:
        lines.append(f"\n**DOI**: [{doi}](https://doi.org/{doi})")
    
    # ä»£ç é“¾æ¥
    if code_links:
        links_str = " | ".join([f"[{l.get('type', 'code').upper()}]({l['url']})" for l in code_links])
        lines.append(f"\n**ğŸ”— ä»£ç /é¡¹ç›®**: {links_str}")
    
    lines.append("\n---\n")
    
    # é¢„è§ˆå›¾ç‰‡
    if thumbnail:
        lines.append(f"![è®ºæ–‡é¢„è§ˆå›¾]({thumbnail})")
        lines.append("")
    
    # ä¸€å¥è¯è¦ç‚¹
    if headline:
        lines.append(f"## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹\n")
        lines.append(f"**{md_escape(headline)}**\n")
    
    # å…³é”®è¯æ ‡ç­¾
    if tags:
        tags_html = " ".join([f"`{t}`" for t in tags])
        lines.append(f"**å…³é”®è¯**: {tags_html}\n")
    
    # æ ¸å¿ƒè¦ç‚¹ï¼ˆ3ç‚¹ç®€è¿°ï¼‰
    if intro and isinstance(intro, list):
        lines.append("## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹\n")
        for i, it in enumerate(intro, 1):
            lines.append(f"{i}. {md_escape(str(it))}")
        lines.append("")
    
    # ä¸­æ–‡æ‘˜è¦
    if summary_zh:
        lines.append("## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰\n")
        lines.append(f"{md_escape(summary_zh)}\n")
    
    # æ–¹æ³•è¯¦è§£
    if method_zh:
        lines.append("## ğŸ”¬ æ–¹æ³•è¯¦è§£\n")
        lines.append(f"{md_escape(method_zh)}\n")
    
    # å®éªŒäº®ç‚¹
    if highlight_zh:
        lines.append("## ğŸ“Š å®éªŒäº®ç‚¹\n")
        lines.append(f"{md_escape(highlight_zh)}\n")
    
    # åº”ç”¨åœºæ™¯
    if application_zh:
        lines.append("## ğŸ¯ åº”ç”¨åœºæ™¯\n")
        lines.append(f"{md_escape(application_zh)}\n")
    
    # åŸæ–‡æ‘˜è¦
    lines.append("## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰\n")
    lines.append(f"> " + "\n> ".join(md_escape(summary).splitlines()))
    lines.append("")
    
    return "\n".join(lines)

def build_tag_date_index_md(tag: str, date_label: str, papers: List[Dict[str, Any]], site_title: str) -> str:
    """ç”ŸæˆæŸåˆ†ç±»æŸæ—¥æœŸçš„ç›®å½•é¡µï¼ˆå¢å¼ºç‰ˆï¼‰"""
    lines = []
    lines.append(f"---\nlayout: default\ntitle: {site_title} - {tag} - {date_label}\n---\n")
    lines.append(f"# {tag}ï¼ˆ{date_label}ï¼‰\n")
    
    # ç»Ÿè®¡ä¿¡æ¯
    papers_with_code = sum(1 for p in papers if p.get("code_links"))
    lines.append(f"ğŸ“Š å…± **{len(papers)}** ç¯‡è®ºæ–‡")
    if papers_with_code:
        lines.append(f" | ğŸ”— **{papers_with_code}** ç¯‡æœ‰ä»£ç ")
    lines.append("\n")
    
    lines.append("| # | é¢˜ç›® | ä¸€å¥è¯è¦ç‚¹ | ğŸ”— |")
    lines.append("|---:|---|---|:---:|")
    for i, p in enumerate(papers, 1):
        title = p.get("title", "").strip()
        slug = slugify(f"{p.get('arxiv_id','')}-{title}") or f"paper-{i}"
        headline = md_escape(p.get("headline_zh", ""))
        # ä»£ç é“¾æ¥æ ‡è®°
        code_links = p.get("code_links", [])
        code_icon = "âœ…" if code_links else ""
        lines.append(f"| {i} | [{md_escape(title)}](./papers/{slug}.html) | {headline} | {code_icon} |")
    lines.append("")
    lines.append(f"[â¬…ï¸ è¿”å› {tag} é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)")
    return "\n".join(lines)

def build_tag_index_md(tag: str, dates: List[str], site_title: str) -> str:
    """ç”ŸæˆæŸåˆ†ç±»çš„é¦–é¡µï¼ˆæ—¥æœŸåˆ—è¡¨ï¼‰"""
    lines = []
    lines.append(f"---\nlayout: default\ntitle: {site_title} - {tag}\n---\n")
    lines.append(f"# {tag}\n")
    lines.append("> é€‰æ‹©æ—¥æœŸæŸ¥çœ‹è¯¥åˆ†ç±»ä¸‹çš„è®ºæ–‡\n")
    
    # ç”Ÿæˆæ—¥æœŸé€‰æ‹©å™¨
    latest_date = sorted(dates)[-1] if dates else ""
    options_html = "\n".join(
        [f'<option value="{d}/index.html" {"selected" if d == latest_date else ""}>{d}</option>'
         for d in sorted(dates, reverse=True)]
    )
    html_block = f"""
<div class="date-switcher">
  <label for="date-select"><strong>é€‰æ‹©æ—¥æœŸï¼š</strong></label>
  <select id="date-select" onchange="location.href=this.value;">
    {options_html}
  </select>
  <a class="btn" href="{latest_date}/index.html">å‰å¾€æœ€æ–°ï¼ˆ{latest_date}ï¼‰</a>
</div>
"""
    lines.append(html_block)
    lines.append("\n## æ—¥æœŸåˆ—è¡¨\n")
    for d in sorted(dates, reverse=True):
        lines.append(f"- [{d}]({d}/index.html)")
    lines.append("")
    lines.append("[è¿”å›ä¸»é¡µ](../index.html)")
    return "\n".join(lines)

def build_home_md(tags: List[str], tag_latest_dates: Dict[str, str], site_title: str) -> str:
    """
    é¦–é¡µï¼šåŒ…å«åˆ†ç±»å¯¼èˆªï¼ˆåªæ˜¾ç¤ºæœ‰æ•°æ®çš„åˆ†ç±»ï¼‰
    """
    lines = []
    lines.append(f"---\nlayout: default\ntitle: {site_title}\n---\n")
    lines.append(f"# {site_title}\n")
    lines.append("> é€‰æ‹©åˆ†ç±»æŸ¥çœ‹è®ºæ–‡\n")
    
    # åªæ˜¾ç¤ºæœ‰æ•°æ®çš„åˆ†ç±»
    active_tags = [tag for tag in tags if tag in tag_latest_dates and tag_latest_dates[tag]]
    
    # åˆ†ç±»å¡ç‰‡
    lines.append('<div class="tag-grid">')
    for tag in active_tags:
        latest = tag_latest_dates[tag]
        safe_tag = tag.replace(".", "-")
        lines.append(f'''
<div class="tag-card">
  <h3><a href="{safe_tag}/index.html">{tag}</a></h3>
  <p>æœ€æ–°æ—¥æœŸï¼š{latest}</p>
  <a class="btn" href="{safe_tag}/{latest}/index.html">æŸ¥çœ‹æœ€æ–°</a>
</div>''')
    lines.append('</div>\n')
    
    lines.append("---\n")
    lines.append("## åˆ†ç±»åˆ—è¡¨\n")
    for tag in active_tags:
        safe_tag = tag.replace(".", "-")
        latest = tag_latest_dates[tag]
        lines.append(f"- **[{tag}]({safe_tag}/index.html)**ï¼šæœ€æ–° {latest}")
    
    return "\n".join(lines)

def write_site_scaffold(docs_dir: Path):
    ensure_dir(docs_dir)
    ensure_dir(docs_dir / "assets")
    (docs_dir / "_config.yml").write_text(
        "theme: jekyll-theme-cayman\nmarkdown: kramdown\nkramdown:\n  input: GFM\n",
        encoding="utf-8"
    )
    (docs_dir / "_layouts").mkdir(exist_ok=True)
    (docs_dir / "_layouts" / "default.html").write_text(
        """<!doctype html>
<html lang="zh-CN">
<head>
<meta charset="utf-8">
<title>{{ page.title }}</title>
<link rel="stylesheet" href="{{ '/assets/style.css' | relative_url }}">
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>
<main class="container">
  {{ content }}
</main>
<footer class="footer">
  <p>Powered by GitHub Pages Â· Generated on {{ site.time | date: "%Y-%m-%d" }}</p>
</footer>
</body>
</html>
""",
        encoding="utf-8"
    )
    (docs_dir / "assets" / "style.css").write_text(
        """/* åŸºç¡€æ ·å¼ */
:root {
  --primary: #2563eb;
  --primary-dark: #1d4ed8;
  --bg: #ffffff;
  --bg-secondary: #f8fafc;
  --text: #1e293b;
  --text-secondary: #64748b;
  --border: #e2e8f0;
  --success: #22c55e;
  --code-bg: #f1f5f9;
}

.container {
  max-width: 1000px;
  margin: 2rem auto;
  padding: 0 1.5rem;
  font: 16px/1.7 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
  color: var(--text);
}

h1 { font-size: 1.75rem; font-weight: 700; margin-bottom: 1rem; line-height: 1.3; }
h2 { font-size: 1.25rem; font-weight: 600; margin: 1.5rem 0 0.75rem; color: var(--text); border-bottom: 2px solid var(--primary); padding-bottom: 0.5rem; }
h3 { font-size: 1.1rem; font-weight: 600; margin: 1rem 0 0.5rem; }

a { color: var(--primary); text-decoration: none; }
a:hover { text-decoration: underline; }

/* è¡¨æ ¼æ ·å¼ */
table { border-collapse: collapse; width: 100%; margin: 1.5rem 0; font-size: 0.9rem; }
th, td { border: 1px solid var(--border); padding: 0.75rem; vertical-align: top; text-align: left; }
th { background: var(--bg-secondary); font-weight: 600; }
tr:hover { background: var(--bg-secondary); }
td:first-child { text-align: center; font-weight: 600; color: var(--text-secondary); width: 40px; }
td:last-child { text-align: center; width: 40px; }

/* ä»£ç æ ·å¼ */
code, pre { background: var(--code-bg); padding: 0.2rem 0.5rem; border-radius: 4px; font-size: 0.85em; }
pre { padding: 1rem; overflow-x: auto; }

/* å¼•ç”¨å— - ç”¨äºåŸæ–‡æ‘˜è¦ */
blockquote {
  margin: 1rem 0;
  padding: 1rem 1.5rem;
  background: var(--bg-secondary);
  border-left: 4px solid var(--primary);
  border-radius: 0 8px 8px 0;
  color: var(--text-secondary);
  font-size: 0.9rem;
  line-height: 1.6;
}

/* é¡µè„š */
.footer { margin: 3rem 0 1rem; padding-top: 1rem; border-top: 1px solid var(--border); color: var(--text-secondary); font-size: 0.85rem; text-align: center; }

/* æ—¥æœŸé€‰æ‹©å™¨ */
.date-switcher {
  display: flex;
  gap: 0.75rem;
  align-items: center;
  margin: 1.5rem 0;
  flex-wrap: wrap;
  padding: 1rem;
  background: var(--bg-secondary);
  border-radius: 8px;
}
.date-switcher select {
  padding: 0.5rem 1rem;
  border: 1px solid var(--border);
  border-radius: 6px;
  font-size: 0.95rem;
  background: white;
}
.date-switcher .btn {
  padding: 0.5rem 1rem;
  background: var(--primary);
  color: white;
  border-radius: 6px;
  font-weight: 500;
}
.date-switcher .btn:hover { background: var(--primary-dark); text-decoration: none; }

/* åˆ†ç±»å¡ç‰‡ç½‘æ ¼ */
.tag-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(260px, 1fr));
  gap: 1.25rem;
  margin: 2rem 0;
}
.tag-card {
  border: 1px solid var(--border);
  border-radius: 12px;
  padding: 1.25rem;
  background: var(--bg);
  transition: box-shadow 0.2s, transform 0.2s;
}
.tag-card:hover { box-shadow: 0 4px 12px rgba(0,0,0,0.1); transform: translateY(-2px); }
.tag-card h3 { margin: 0 0 0.5rem; font-size: 1.2rem; }
.tag-card h3 a { color: var(--text); }
.tag-card p { margin: 0.5rem 0; color: var(--text-secondary); font-size: 0.9rem; }
.tag-card .btn {
  display: inline-block;
  margin-top: 0.75rem;
  padding: 0.5rem 1rem;
  background: var(--primary);
  color: white;
  border-radius: 6px;
  font-weight: 500;
}
.tag-card .btn:hover { background: var(--primary-dark); text-decoration: none; }

/* è®ºæ–‡è¯¦æƒ…é¡µæ ·å¼ */
img {
  max-width: 100%;
  height: auto;
  border-radius: 8px;
  margin: 1rem 0;
  box-shadow: 0 2px 8px rgba(0,0,0,0.1);
}

/* å…³é”®è¯æ ‡ç­¾ */
code {
  background: #e0f2fe;
  color: #0369a1;
  padding: 0.15rem 0.5rem;
  border-radius: 4px;
  font-size: 0.8rem;
  margin-right: 0.25rem;
}

/* ä¿¡æ¯å— */
.info-block {
  background: var(--bg-secondary);
  padding: 1rem;
  border-radius: 8px;
  margin: 1rem 0;
}

/* å“åº”å¼ */
@media (max-width: 768px) {
  .container { padding: 0 1rem; }
  h1 { font-size: 1.4rem; }
  table { font-size: 0.8rem; }
  th, td { padding: 0.5rem; }
  .tag-grid { grid-template-columns: 1fr; }
}
""",
        encoding="utf-8"
    )

# =============== ç«™ç‚¹ç”Ÿæˆ ===============

def collect_dates(data_root: Path) -> List[Tuple[str, Path]]:
    """
    æ‰«æ data/*/ai_summary*.jsonï¼Œè¿”å› [(date_label, json_path), ...]ï¼ŒæŒ‰æ—¥æœŸå‡åºã€‚
    """
    items = []
    for p in sorted(data_root.glob("*/ai_summary*.json")):
        # ä»è·¯å¾„æˆ–æ–‡ä»¶åä¸­æŠ½æ—¥æœŸ
        m = re.search(r"(\d{4}-\d{2}-\d{2})", str(p))
        if not m:
            # å…¼å®¹æ²¡æœ‰æ—¥æœŸçš„è·¯å¾„ï¼Œç”¨çˆ¶ç›®å½•åå…œåº•
            m = re.search(r"(\d{4}-\d{2}-\d{2})", p.parent.name)
        if m:
            date_label = m.group(1)
        else:
            # å®åœ¨å–ä¸åˆ°ï¼Œç”¨æ–‡ä»¶ä¿®æ”¹æ—¥æœŸ
            ts = datetime.date.fromtimestamp(p.stat().st_mtime).isoformat()
            date_label = ts
        items.append((date_label, p))
    # å»é‡ & æ’åº
    items = sorted(list({(d, str(p)): (d, Path(p)) for d, p in items}.values()), key=lambda x: x[0])
    return items

def classify_paper(paper: Dict[str, Any], target_tags: List[str]) -> List[str]:
    """
    åˆ¤æ–­è®ºæ–‡å±äºå“ªäº›ç›®æ ‡åˆ†ç±»ã€‚
    è¿”å›è®ºæ–‡æ‰€å±çš„ç›®æ ‡åˆ†ç±»åˆ—è¡¨ã€‚
    """
    paper_categories = paper.get("categories", [])
    primary_category = paper.get("primary_category", "")
    
    matched = []
    # ä¼˜å…ˆæ£€æŸ¥ primary_category
    if primary_category in target_tags:
        matched.append(primary_category)
    
    # æ£€æŸ¥å…¶ä»– categories
    for cat in paper_categories:
        if cat in target_tags and cat not in matched:
            matched.append(cat)
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆå¦‚ cs.CV å¯èƒ½åœ¨ cs.cv é‡Œï¼‰
    if not matched:
        for cat in paper_categories:
            for tag in target_tags:
                if cat.lower() == tag.lower() and tag not in matched:
                    matched.append(tag)
    
    return matched

def save_tag_date_site(docs_dir: Path, tag: str, date_label: str, papers: List[Dict[str, Any]], site_title: str):
    """ç”ŸæˆæŸåˆ†ç±»æŸæ—¥æœŸçš„ç›®å½•é¡µ + è¯¦æƒ…é¡µ"""
    safe_tag = tag.replace(".", "-")
    day_dir = docs_dir / safe_tag / date_label
    ensure_dir(day_dir)
    ensure_dir(day_dir / "papers")

    # date index
    date_md = build_tag_date_index_md(tag, date_label, papers, site_title)
    (day_dir / "index.md").write_text(date_md, encoding="utf-8")

    # per-paper pages
    for i, p in enumerate(papers, 1):
        title = p.get("title", "").strip()
        slug = slugify(f"{p.get('arxiv_id','')}-{title}") or f"paper-{i}"
        body_md = render_paper_md(p)
        md = f"---\nlayout: default\ntitle: {title}\n---\n\n{body_md}\n"
        (day_dir / "papers" / f"{slug}.md").write_text(md, encoding="utf-8")

def main():
    ap = argparse.ArgumentParser(description="Build multi-tag, multi-date GitHub Pages.")
    ap.add_argument("--data", default="data", help="æ•°æ®æ ¹ç›®å½•ï¼ˆé»˜è®¤ data/ï¼‰")
    ap.add_argument("--outdir", default="docs", help="è¾“å‡ºç«™ç‚¹ç›®å½•ï¼ˆé»˜è®¤ docs/ï¼‰")
    ap.add_argument("--tags", default="tags.json", help="åˆ†ç±»é…ç½®æ–‡ä»¶ï¼ˆé»˜è®¤ tags.jsonï¼‰")
    ap.add_argument("--title", default="arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€»ï¼ˆwith DeepSeekï¼‰", help="ç«™ç‚¹æ ‡é¢˜")
    args = ap.parse_args()

    data_root = Path(args.data)
    docs_dir = Path(args.outdir)
    tags_file = Path(args.tags)
    site_title = args.title

    # åŠ è½½ç›®æ ‡åˆ†ç±»
    target_tags = load_tags(tags_file)
    print(f"[INFO] ç›®æ ‡åˆ†ç±»: {target_tags}")

    pairs = collect_dates(data_root)
    if not pairs:
        print("[ERR] æœªæ‰¾åˆ° data/*/ai_summary*.json", file=sys.stderr)
        sys.exit(2)

    write_site_scaffold(docs_dir)

    # æŒ‰åˆ†ç±»å’Œæ—¥æœŸç»„ç»‡è®ºæ–‡
    # tag -> date -> [papers]
    tag_date_papers: Dict[str, Dict[str, List[Dict[str, Any]]]] = defaultdict(lambda: defaultdict(list))
    
    for date_label, json_path in pairs:
        data = read_json(json_path)
        papers = data.get("papers", [])
        if not isinstance(papers, list) or not papers:
            print(f"[WARN] {json_path} ä¸­ papers ä¸ºç©ºï¼Œè·³è¿‡ {date_label}")
            continue
        
        for paper in papers:
            matched_tags = classify_paper(paper, target_tags)
            if not matched_tags:
                # æ²¡æœ‰åŒ¹é…ä»»ä½•ç›®æ ‡åˆ†ç±»ï¼Œæ”¾åˆ°ç¬¬ä¸€ä¸ªåˆ†ç±»ï¼ˆä½œä¸ºé»˜è®¤ï¼‰
                matched_tags = [target_tags[0]] if target_tags else []
            
            for tag in matched_tags:
                tag_date_papers[tag][date_label].append(paper)
    
    # ç»Ÿè®¡
    tag_dates: Dict[str, List[str]] = {}
    for tag in target_tags:
        dates = sorted(tag_date_papers[tag].keys())
        if dates:
            tag_dates[tag] = dates
            print(f"[INFO] {tag}: {len(dates)} ä¸ªæ—¥æœŸ")

    if not tag_dates:
        print("[ERR] æ²¡æœ‰å¯ç”¨çš„åˆ†ç±»é¡µé¢ç”Ÿæˆ", file=sys.stderr)
        sys.exit(3)

    # ç”Ÿæˆæ¯ä¸ªåˆ†ç±»çš„é¡µé¢
    for tag in target_tags:
        if tag not in tag_dates:
            continue
        safe_tag = tag.replace(".", "-")
        
        for date_label in tag_dates[tag]:
            papers = tag_date_papers[tag][date_label]
            save_tag_date_site(docs_dir, tag, date_label, papers, site_title)
        
        # ç”Ÿæˆåˆ†ç±»é¦–é¡µ
        tag_index_md = build_tag_index_md(tag, tag_dates[tag], site_title)
        tag_dir = docs_dir / safe_tag
        ensure_dir(tag_dir)
        (tag_dir / "index.md").write_text(tag_index_md, encoding="utf-8")

    # é¦–é¡µï¼šåˆ†ç±»å¯¼èˆª
    tag_latest_dates = {tag: sorted(dates)[-1] for tag, dates in tag_dates.items()}
    home_md = build_home_md(target_tags, tag_latest_dates, site_title)
    (docs_dir / "index.md").write_text(home_md, encoding="utf-8")

    total_pages = sum(len(dates) for dates in tag_dates.values())
    print(f"[OK] ç”Ÿæˆå®Œæˆã€‚å…± {len(tag_dates)} ä¸ªåˆ†ç±»ï¼Œ{total_pages} ä¸ªæ—¥æœŸé¡µé¢ã€‚é¦–é¡µï¼š{docs_dir}/index.md")
    print("ğŸ‘‰ æ‰“å¼€ GitHub â†’ Settings â†’ Pagesï¼ŒSource é€‰ Branchï¼Œç›®å½•é€‰ docs/ï¼Œä¿å­˜å³å¯ã€‚")

if __name__ == "__main__":
    main()
